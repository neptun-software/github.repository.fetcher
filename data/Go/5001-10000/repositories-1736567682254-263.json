{
  "metadata": {
    "timestamp": 1736567682254,
    "page": 263,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "go-git/go-git",
      "stars": 6148,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.064453125,
          "content": "coverage.out\n*~\ncoverage.txt\nprofile.out\n.tmp/\n.git-dist/\n.vscode\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.1533203125,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to making participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, gender identity and expression, level of experience,\neducation, socio-economic status, nationality, personal appearance, race,\nreligion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n  advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n  address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces\nwhen an individual is representing the project or its community. Examples of\nrepresenting a project or community include using an official project e-mail\naddress, posting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event. Representation of a project may be\nfurther defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at conduct@sourced.tech. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\n"
        },
        {
          "name": "COMPATIBILITY.md",
          "type": "blob",
          "size": 21.2041015625,
          "content": "# Supported Features\n\nHere is a non-comprehensive table of git commands and features and their\ncompatibility status with go-git.\n\n## Getting and creating repositories\n\n| Feature | Sub-feature                                                                                                        | Status | Notes | Examples                                                                                                                                                                                                            |\n| ------- | ------------------------------------------------------------------------------------------------------------------ | ------ | ----- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `init`  |                                                                                                                    | ✅     |       |                                                                                                                                                                                                                     |\n| `init`  | `--bare`                                                                                                           | ✅     |       |                                                                                                                                                                                                                     |\n| `init`  | `--template` <br/> `--separate-git-dir` <br/> `--shared`                                                           | ❌     |       |                                                                                                                                                                                                                     |\n| `clone` |                                                                                                                    | ✅     |       | - [PlainClone](_examples/clone/main.go)                                                                                                                                                                             |\n| `clone` | Authentication: <br/> - none <br/> - access token <br/> - username + password <br/> - ssh                          | ✅     |       | - [clone ssh (private_key)](_examples/clone/auth/ssh/private_key/main.go) <br/> - [clone ssh (ssh_agent)](_examples/clone/auth/ssh/ssh_agent/main.go) <br/> - [clone access token](_examples/clone/auth/basic/access_token/main.go) <br/> - [clone user + password](_examples/clone/auth/basic/username_password/main.go) |\n| `clone` | `--progress` <br/> `--single-branch` <br/> `--depth` <br/> `--origin` <br/> `--recurse-submodules` <br/>`--shared` | ✅     |       | - [recurse submodules](_examples/clone/main.go) <br/> - [progress](_examples/progress/main.go)                                                                                                                      |\n\n## Basic snapshotting\n\n| Feature  | Sub-feature | Status | Notes                                                    | Examples                             |\n| -------- | ----------- | ------ | -------------------------------------------------------- | ------------------------------------ |\n| `add`    |             | ✅     | Plain add is supported. Any other flags aren't supported |                                      |\n| `status` |             | ✅     |                                                          |                                      |\n| `commit` |             | ✅     |                                                          | - [commit](_examples/commit/main.go) |\n| `reset`  |             | ✅     |                                                          |                                      |\n| `rm`     |             | ✅     |                                                          |                                      |\n| `mv`     |             | ✅     |                                                          |                                      |\n\n## Branching and merging\n\n| Feature     | Sub-feature | Status       | Notes                                   | Examples                                                                                        |\n| ----------- | ----------- | ------------ | --------------------------------------- | ----------------------------------------------------------------------------------------------- |\n| `branch`    |             | ✅           |                                         | - [branch](_examples/branch/main.go)                                                            |\n| `checkout`  |             | ✅           | Basic usages of checkout are supported. | - [checkout](_examples/checkout/main.go)                                                        |\n| `merge`     |             | ⚠️ (partial) | Fast-forward only                       |                                                                                                 |\n| `mergetool` |             | ❌           |                                         |                                                                                                 |\n| `stash`     |             | ❌           |                                         |                                                                                                 |\n| `sparse-checkout`     |             | ✅           |                                         | - [sparse-checkout](_examples/sparse-checkout/main.go)                                                                                               |\n| `tag`       |             | ✅           |                                         | - [tag](_examples/tag/main.go) <br/> - [tag create and push](_examples/tag-create-push/main.go) |\n\n## Sharing and updating projects\n\n| Feature     | Sub-feature | Status | Notes                                                                   | Examples                                   |\n| ----------- | ----------- | ------ | ----------------------------------------------------------------------- | ------------------------------------------ |\n| `fetch`     |             | ✅     |                                                                         |                                            |\n| `pull`      |             | ✅     | Only supports merges where the merge can be resolved as a fast-forward. | - [pull](_examples/pull/main.go)           |\n| `push`      |             | ✅     |                                                                         | - [push](_examples/push/main.go)           |\n| `remote`    |             | ✅     |                                                                         | - [remotes](_examples/remotes/main.go)     |\n| `submodule` |             | ✅     |                                                                         | - [submodule](_examples/submodule/main.go) |\n| `submodule` | deinit      | ❌     |                                                                         |                                            |\n\n## Inspection and comparison\n\n| Feature    | Sub-feature | Status    | Notes | Examples                       |\n| ---------- | ----------- | --------- | ----- | ------------------------------ |\n| `show`     |             | ✅        |       |                                |\n| `log`      |             | ✅        |       | - [log](_examples/log/main.go) |\n| `shortlog` |             | (see log) |       |                                |\n| `describe` |             | ❌        |       |                                |\n\n## Patching\n\n| Feature       | Sub-feature | Status | Notes                                                | Examples |\n| ------------- | ----------- | ------ | ---------------------------------------------------- | -------- |\n| `apply`       |             | ❌     |                                                      |          |\n| `cherry-pick` |             | ❌     |                                                      |          |\n| `diff`        |             | ✅     | Patch object with UnifiedDiff output representation. |          |\n| `rebase`      |             | ❌     |                                                      |          |\n| `revert`      |             | ❌     |                                                      |          |\n\n## Debugging\n\n| Feature  | Sub-feature | Status | Notes | Examples                           |\n| -------- | ----------- | ------ | ----- | ---------------------------------- |\n| `bisect` |             | ❌     |       |                                    |\n| `blame`  |             | ✅     |       | - [blame](_examples/blame/main.go) |\n| `grep`   |             | ✅     |       |                                    |\n\n## Email\n\n| Feature        | Sub-feature | Status | Notes | Examples |\n| -------------- | ----------- | ------ | ----- | -------- |\n| `am`           |             | ❌     |       |          |\n| `apply`        |             | ❌     |       |          |\n| `format-patch` |             | ❌     |       |          |\n| `send-email`   |             | ❌     |       |          |\n| `request-pull` |             | ❌     |       |          |\n\n## External systems\n\n| Feature       | Sub-feature | Status | Notes | Examples |\n| ------------- | ----------- | ------ | ----- | -------- |\n| `svn`         |             | ❌     |       |          |\n| `fast-import` |             | ❌     |       |          |\n| `lfs`         |             | ❌     |       |          |\n\n## Administration\n\n| Feature         | Sub-feature | Status | Notes | Examples |\n| --------------- | ----------- | ------ | ----- | -------- |\n| `clean`         |             | ✅     |       |          |\n| `gc`            |             | ❌     |       |          |\n| `fsck`          |             | ❌     |       |          |\n| `reflog`        |             | ❌     |       |          |\n| `filter-branch` |             | ❌     |       |          |\n| `instaweb`      |             | ❌     |       |          |\n| `archive`       |             | ❌     |       |          |\n| `bundle`        |             | ❌     |       |          |\n| `prune`         |             | ❌     |       |          |\n| `repack`        |             | ❌     |       |          |\n\n## Server admin\n\n| Feature              | Sub-feature | Status | Notes | Examples                                  |\n| -------------------- | ----------- | ------ | ----- | ----------------------------------------- |\n| `daemon`             |             | ❌     |       |                                           |\n| `update-server-info` |             | ✅     |       | [cli](./cli/go-git/update_server_info.go) |\n\n## Advanced\n\n| Feature    | Sub-feature | Status      | Notes | Examples |\n| ---------- | ----------- | ----------- | ----- | -------- |\n| `notes`    |             | ❌          |       |          |\n| `replace`  |             | ❌          |       |          |\n| `worktree` |             | ❌          |       |          |\n| `annotate` |             | (see blame) |       |          |\n\n## GPG\n\n| Feature             | Sub-feature | Status | Notes | Examples |\n| ------------------- | ----------- | ------ | ----- | -------- |\n| `git-verify-commit` |             | ✅     |       |          |\n| `git-verify-tag`    |             | ✅     |       |          |\n\n## Plumbing commands\n\n| Feature         | Sub-feature                           | Status       | Notes                                               | Examples                                     |\n| --------------- | ------------------------------------- | ------------ | --------------------------------------------------- | -------------------------------------------- |\n| `cat-file`      |                                       | ✅           |                                                     |                                              |\n| `check-ignore`  |                                       | ❌           |                                                     |                                              |\n| `commit-tree`   |                                       | ❌           |                                                     |                                              |\n| `count-objects` |                                       | ❌           |                                                     |                                              |\n| `diff-index`    |                                       | ❌           |                                                     |                                              |\n| `for-each-ref`  |                                       | ✅           |                                                     |                                              |\n| `hash-object`   |                                       | ✅           |                                                     |                                              |\n| `ls-files`      |                                       | ✅           |                                                     |                                              |\n| `ls-remote`     |                                       | ✅           |                                                     | - [ls-remote](_examples/ls-remote/main.go)   |\n| `merge-base`    | `--independent` <br/> `--is-ancestor` | ⚠️ (partial) | Calculates the merge-base only between two commits. | - [merge-base](_examples/merge_base/main.go) |\n| `merge-base`    | `--fork-point` <br/> `--octopus`      | ❌           |                                                     |                                              |\n| `read-tree`     |                                       | ❌           |                                                     |                                              |\n| `rev-list`      |                                       | ✅           |                                                     |                                              |\n| `rev-parse`     |                                       | ❌           |                                                     |                                              |\n| `show-ref`      |                                       | ✅           |                                                     |                                              |\n| `symbolic-ref`  |                                       | ✅           |                                                     |                                              |\n| `update-index`  |                                       | ❌           |                                                     |                                              |\n| `update-ref`    |                                       | ❌           |                                                     |                                              |\n| `verify-pack`   |                                       | ❌           |                                                     |                                              |\n| `write-tree`    |                                       | ❌           |                                                     |                                              |\n\n## Indexes and Git Protocols\n\n| Feature              | Version                                                                         | Status | Notes |\n| -------------------- | ------------------------------------------------------------------------------- | ------ | ----- |\n| index                | [v1](https://github.com/git/git/blob/master/Documentation/gitformat-index.txt)  | ❌     |       |\n| index                | [v2](https://github.com/git/git/blob/master/Documentation/gitformat-index.txt)  | ✅     |       |\n| index                | [v3](https://github.com/git/git/blob/master/Documentation/gitformat-index.txt)  | ❌     |       |\n| pack-protocol        | [v1](https://github.com/git/git/blob/master/Documentation/gitprotocol-pack.txt) | ✅     |       |\n| pack-protocol        | [v2](https://github.com/git/git/blob/master/Documentation/gitprotocol-v2.txt)   | ❌     |       |\n| multi-pack-index     | [v1](https://github.com/git/git/blob/master/Documentation/gitformat-pack.txt)   | ❌     |       |\n| pack-\\*.rev files    | [v1](https://github.com/git/git/blob/master/Documentation/gitformat-pack.txt)   | ❌     |       |\n| pack-\\*.mtimes files | [v1](https://github.com/git/git/blob/master/Documentation/gitformat-pack.txt)   | ❌     |       |\n| cruft packs          |                                                                                 | ❌     |       |\n\n## Capabilities\n\n| Feature                        | Status       | Notes |\n| ------------------------------ | ------------ | ----- |\n| `multi_ack`                    | ❌           |       |\n| `multi_ack_detailed`           | ❌           |       |\n| `no-done`                      | ❌           |       |\n| `thin-pack`                    | ❌           |       |\n| `side-band`                    | ⚠️ (partial) |       |\n| `side-band-64k`                | ⚠️ (partial) |       |\n| `ofs-delta`                    | ✅           |       |\n| `agent`                        | ✅           |       |\n| `object-format`                | ❌           |       |\n| `symref`                       | ✅           |       |\n| `shallow`                      | ✅           |       |\n| `deepen-since`                 | ✅           |       |\n| `deepen-not`                   | ❌           |       |\n| `deepen-relative`              | ❌           |       |\n| `no-progress`                  | ✅           |       |\n| `include-tag`                  | ✅           |       |\n| `report-status`                | ✅           |       |\n| `report-status-v2`             | ❌           |       |\n| `delete-refs`                  | ✅           |       |\n| `quiet`                        | ❌           |       |\n| `atomic`                       | ✅           |       |\n| `push-options`                 | ✅           |       |\n| `allow-tip-sha1-in-want`       | ✅           |       |\n| `allow-reachable-sha1-in-want` | ❌           |       |\n| `push-cert=<nonce>`            | ❌           |       |\n| `filter`                       | ❌           |       |\n| `session-id=<session id>`      | ❌           |       |\n\n## Transport Schemes\n\n| Scheme               | Status       | Notes                                                                  | Examples                                       |\n| -------------------- | ------------ | ---------------------------------------------------------------------- | ---------------------------------------------- |\n| `http(s)://` (dumb)  | ❌           |                                                                        |                                                |\n| `http(s)://` (smart) | ✅           |                                                                        |                                                |\n| `git://`             | ✅           |                                                                        |                                                |\n| `ssh://`             | ✅           |                                                                        |                                                |\n| `file://`            | ⚠️ (partial) | Warning: this is not pure Golang. This shells out to the `git` binary. |                                                |\n| Custom               | ✅           | All existing schemes can be replaced by custom implementations.        | - [custom_http](_examples/custom_http/main.go) |\n\n## SHA256\n\n| Feature  | Sub-feature | Status | Notes                              | Examples                             |\n| -------- | ----------- | ------ | ---------------------------------- | ------------------------------------ |\n| `init`   |             | ✅     | Requires building with tag sha256. | - [init](_examples/sha256/main.go)   |\n| `commit` |             | ✅     | Requires building with tag sha256. | - [commit](_examples/sha256/main.go) |\n| `pull`   |             | ❌     |                                    |                                      |\n| `fetch`  |             | ❌     |                                    |                                      |\n| `push`   |             | ❌     |                                    |                                      |\n\n## Other features\n\n| Feature         | Sub-feature                 | Status | Notes                                          | Examples |\n| --------------- | --------------------------- | ------ | ---------------------------------------------- | -------- |\n| `config`        | `--local`                   | ✅     | Read and write per-repository (`.git/config`). |          |\n| `config`        | `--global` <br/> `--system` | ✅     | Read-only.                                     |          |\n| `gitignore`     |                             | ✅     |                                                |          |\n| `gitattributes` |                             | ✅     |                                                |          |\n| `git-worktree`  |                             | ❌     | Multiple worktrees are not supported.          |          |\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 2.705078125,
          "content": "# Contributing Guidelines\n\nsource{d} go-git project is [Apache 2.0 licensed](LICENSE) and accepts\ncontributions via GitHub pull requests.  This document outlines some of the\nconventions on development workflow, commit message formatting, contact points,\nand other resources to make it easier to get your contribution accepted.\n\n## Support Channels\n\nThe official support channels, for both users and contributors, are:\n\n- [StackOverflow go-git tag](https://stackoverflow.com/questions/tagged/go-git) for user questions.\n- GitHub [Issues](https://github.com/src-d/go-git/issues)* for bug reports and feature requests.\n\n*Before opening a new issue or submitting a new pull request, it's helpful to\nsearch the project - it's likely that another user has already reported the\nissue you're facing, or it's a known issue that we're already aware of.\n\n\n## How to Contribute\n\nPull Requests (PRs) are the main and exclusive way to contribute to the official go-git project.\nIn order for a PR to be accepted it needs to pass a list of requirements:\n\n- You should be able to run the same query using `git`. We don't accept features that are not implemented in the official git implementation.\n- The expected behavior must match the [official git implementation](https://github.com/git/git).\n- The actual behavior must be correctly explained with natural language and providing a minimum working example in Go that reproduces it.\n- All PRs must be written in idiomatic Go, formatted according to [gofmt](https://golang.org/cmd/gofmt/), and without any warnings from [go lint](https://github.com/golang/lint) nor [go vet](https://golang.org/cmd/vet/).\n- They should in general include tests, and those shall pass.\n- If the PR is a bug fix, it has to include a suite of unit tests for the new functionality.\n- If the PR is a new feature, it has to come with a suite of unit tests, that tests the new functionality.\n- In any case, all the PRs have to pass the personal evaluation of at least one of the maintainers of go-git.\n\n### Branches\n\nThe `master` branch is currently used for maintaining the `v5` major release only. The accepted changes would\nbe dependency bumps, bug fixes and small changes that aren't needed for `v6`. New development should target the\n`v6-exp` branch, and if agreed with at least one go-git maintainer, it can be back ported to `v5` by creating \na new PR that targets `master`.\n\n### Format of the commit message\n\nEvery commit message should describe what was changed, under which context and, if applicable, the GitHub issue it relates to:\n\n```\nplumbing: packp, Skip argument validations for unknown capabilities. Fixes #623\n```\n\nThe format can be described more formally as follows:\n\n```\n<package>: <subpackage>, <what changed>. [Fixes #<issue-number>]\n```\n"
        },
        {
          "name": "EXTENDING.md",
          "type": "blob",
          "size": 3.189453125,
          "content": "# Extending go-git\n\n`go-git` was built in a highly extensible manner, which enables some of its functionalities to be changed or extended without the need of changing its codebase. Here are the key extensibility features:\n\n## Dot Git Storers\n\nDot git storers are the components responsible for storing the Git internal files, including objects and references.\n\nThe built-in storer implementations include [memory](storage/memory) and [filesystem](storage/filesystem). The `memory` storer stores all the data in memory, and its use look like this:\n\n```go\n\tr, err := git.Init(memory.NewStorage(), nil)\n```\n\nThe `filesystem` storer stores the data in the OS filesystem, and can be used as follows:\n\n```go\n    r, err := git.Init(filesystem.NewStorage(osfs.New(\"/tmp/foo\")), nil)\n```\n\nNew implementations can be created by implementing the [storage.Storer interface](storage/storer.go#L16).\n\n## Filesystem\n\nGit repository worktrees are managed using a filesystem abstraction based on [go-billy](https://github.com/go-git/go-billy). The Git operations will take place against the specific filesystem implementation. Initialising a repository in Memory can be done as follows:\n\n```go\n\tfs := memfs.New()\n\tr, err := git.Init(memory.NewStorage(), fs)\n```\n\nThe same operation can be done against the OS filesystem:\n\n```go\n    fs := osfs.New(\"/tmp/foo\")\n    r, err := git.Init(memory.NewStorage(), fs)\n```\n\nNew filesystems (e.g. cloud based storage) could be created by implementing `go-billy`'s [Filesystem interface](https://github.com/go-git/go-billy/blob/326c59f064021b821a55371d57794fbfb86d4cb3/fs.go#L52).\n\n## Transport Schemes\n\nGit supports various transport schemes, including `http`, `https`, `ssh`, `git`, `file`. `go-git` defines the [transport.Transport interface](plumbing/transport/common.go#L48) to represent them.\n\nThe built-in implementations can be replaced by calling `client.InstallProtocol`.\n\nAn example of changing the built-in `https` implementation to skip TLS could look like this:\n\n```go\n\tcustomClient := &http.Client{\n\t\tTransport: &http.Transport{\n\t\t\tTLSClientConfig: &tls.Config{InsecureSkipVerify: true},\n\t\t},\n\t}\n\n\tclient.InstallProtocol(\"https\", githttp.NewClient(customClient))\n```\n\nSome internal implementations enables code reuse amongst the different transport implementations. Some of these may be made public in the future (e.g. `plumbing/transport/internal/common`).\n\n## Cache\n\nSeveral different operations across `go-git` lean on caching of objects in order to achieve optimal performance. The caching functionality is defined by the [cache.Object interface](plumbing/cache/common.go#L17).\n\nTwo built-in implementations are `cache.ObjectLRU` and `cache.BufferLRU`. However, the caching functionality can be customized by implementing the interface `cache.Object` interface.\n\n## Hash\n\n`go-git` uses the `crypto.Hash` interface to represent hash functions. The built-in implementations are `github.com/pjbgf/sha1cd` for SHA1 and Go's `crypto/SHA256`.\n\nThe default hash functions can be changed by calling `hash.RegisterHash`.\n```go\n    func init() {\n        hash.RegisterHash(crypto.SHA1, sha1.New)\n    }\n```\n\nNew `SHA1` or `SHA256` hash functions that implement the `hash.RegisterHash` interface can be registered by calling `RegisterHash`.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.08984375,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"{}\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2018 Sourced Technologies, S.L.\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 1.4521484375,
          "content": "# General\nWORKDIR = $(PWD)\n\n# Go parameters\nGOCMD = go\nGOTEST = $(GOCMD) test \n\n# Git config\nGIT_VERSION ?=\nGIT_DIST_PATH ?= $(PWD)/.git-dist\nGIT_REPOSITORY = http://github.com/git/git.git\n\n# Coverage\nCOVERAGE_REPORT = coverage.out\nCOVERAGE_MODE = count\n\nbuild-git:\n\t@if [ -f $(GIT_DIST_PATH)/git ]; then \\\n\t\techo \"nothing to do, using cache $(GIT_DIST_PATH)\"; \\\n\telse \\\n\t\tgit clone $(GIT_REPOSITORY) -b $(GIT_VERSION) --depth 1 --single-branch $(GIT_DIST_PATH); \\\n\t\tcd $(GIT_DIST_PATH); \\\n\t\tmake configure; \\\n\t\t./configure; \\\n\t\tmake all; \\\n\tfi\n\ntest:\n\t@echo \"running against `git version`\"; \\\n\t$(GOTEST) -race ./...\n\t$(GOTEST) -v _examples/common_test.go _examples/common.go --examples\n\nTEMP_REPO := $(shell mktemp)\ntest-sha256:\n\t$(GOCMD) run -tags sha256 _examples/sha256/main.go $(TEMP_REPO)\n\tcd $(TEMP_REPO) && git fsck\n\trm -rf $(TEMP_REPO)\n\ntest-coverage:\n\t@echo \"running against `git version`\"; \\\n\techo \"\" > $(COVERAGE_REPORT); \\\n\t$(GOTEST) -coverprofile=$(COVERAGE_REPORT) -coverpkg=./... -covermode=$(COVERAGE_MODE) ./...\n\nclean:\n\trm -rf $(GIT_DIST_PATH)\n\nfuzz:\n\t@go test -fuzz=FuzzParser\t\t\t\t$(PWD)/internal/revision\n\t@go test -fuzz=FuzzDecoder\t\t\t\t$(PWD)/plumbing/format/config\n\t@go test -fuzz=FuzzPatchDelta\t\t\t$(PWD)/plumbing/format/packfile\n\t@go test -fuzz=FuzzParseSignedBytes\t\t$(PWD)/plumbing/object\n\t@go test -fuzz=FuzzDecode\t\t\t\t$(PWD)/plumbing/object\n\t@go test -fuzz=FuzzDecoder\t\t\t\t$(PWD)/plumbing/protocol/packp\n\t@go test -fuzz=FuzzNewEndpoint\t\t\t$(PWD)/plumbing/transport\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 4.7978515625,
          "content": "![go-git logo](https://cdn.rawgit.com/src-d/artwork/02036484/go-git/files/go-git-github-readme-header.png)\n[![GoDoc](https://godoc.org/github.com/go-git/go-git/v5?status.svg)](https://pkg.go.dev/github.com/go-git/go-git/v5) [![Build Status](https://github.com/go-git/go-git/workflows/Test/badge.svg)](https://github.com/go-git/go-git/actions) [![Go Report Card](https://goreportcard.com/badge/github.com/go-git/go-git)](https://goreportcard.com/report/github.com/go-git/go-git)\n\n*go-git* is a highly extensible git implementation library written in **pure Go**.\n\nIt can be used to manipulate git repositories at low level *(plumbing)* or high level *(porcelain)*, through an idiomatic Go API. It also supports several types of storage, such as in-memory filesystems, or custom implementations, thanks to the [`Storer`](https://pkg.go.dev/github.com/go-git/go-git/v5/plumbing/storer) interface.\n\nIt's being actively developed since 2015 and is being used extensively by [Keybase](https://keybase.io/blog/encrypted-git-for-everyone), [Gitea](https://gitea.io/en-us/) or [Pulumi](https://github.com/search?q=org%3Apulumi+go-git&type=Code), and by many other libraries and tools.\n\nProject Status\n--------------\n\nAfter the legal issues with the [`src-d`](https://github.com/src-d) organization, the lack of update for four months and the requirement to make a hard fork, the project is **now back to normality**.\n\nThe project is currently actively maintained by individual contributors, including several of the original authors, but also backed by a new company, [gitsight](https://github.com/gitsight), where `go-git` is a critical component used at scale.\n\n\nComparison with git\n-------------------\n\n*go-git* aims to be fully compatible with [git](https://github.com/git/git), all the *porcelain* operations are implemented to work exactly as *git* does.\n\n*git* is a humongous project with years of development by thousands of contributors, making it challenging for *go-git* to implement all the features. You can find a comparison of *go-git* vs *git* in the [compatibility documentation](COMPATIBILITY.md).\n\n\nInstallation\n------------\n\nThe recommended way to install *go-git* is:\n\n```go\nimport \"github.com/go-git/go-git/v5\" // with go modules enabled (GO111MODULE=on or outside GOPATH)\nimport \"github.com/go-git/go-git\" // with go modules disabled\n```\n\n\nExamples\n--------\n\n> Please note that the `CheckIfError` and `Info` functions  used in the examples are from the [examples package](https://github.com/go-git/go-git/blob/master/_examples/common.go#L19) just to be used in the examples.\n\n\n### Basic example\n\nA basic example that mimics the standard `git clone` command\n\n```go\n// Clone the given repository to the given directory\nInfo(\"git clone https://github.com/go-git/go-git\")\n\n_, err := git.PlainClone(\"/tmp/foo\", false, &git.CloneOptions{\n    URL:      \"https://github.com/go-git/go-git\",\n    Progress: os.Stdout,\n})\n\nCheckIfError(err)\n```\n\nOutputs:\n```\nCounting objects: 4924, done.\nCompressing objects: 100% (1333/1333), done.\nTotal 4924 (delta 530), reused 6 (delta 6), pack-reused 3533\n```\n\n### In-memory example\n\nCloning a repository into memory and printing the history of HEAD, just like `git log` does\n\n\n```go\n// Clones the given repository in memory, creating the remote, the local\n// branches and fetching the objects, exactly as:\nInfo(\"git clone https://github.com/go-git/go-billy\")\n\nr, err := git.Clone(memory.NewStorage(), nil, &git.CloneOptions{\n    URL: \"https://github.com/go-git/go-billy\",\n})\n\nCheckIfError(err)\n\n// Gets the HEAD history from HEAD, just like this command:\nInfo(\"git log\")\n\n// ... retrieves the branch pointed by HEAD\nref, err := r.Head()\nCheckIfError(err)\n\n\n// ... retrieves the commit history\ncIter, err := r.Log(&git.LogOptions{From: ref.Hash()})\nCheckIfError(err)\n\n// ... just iterates over the commits, printing it\nerr = cIter.ForEach(func(c *object.Commit) error {\n\tfmt.Println(c)\n\treturn nil\n})\nCheckIfError(err)\n```\n\nOutputs:\n```\ncommit ded8054fd0c3994453e9c8aacaf48d118d42991e\nAuthor: Santiago M. Mola <santi@mola.io>\nDate:   Sat Nov 12 21:18:41 2016 +0100\n\n    index: ReadFrom/WriteTo returns IndexReadError/IndexWriteError. (#9)\n\ncommit df707095626f384ce2dc1a83b30f9a21d69b9dfc\nAuthor: Santiago M. Mola <santi@mola.io>\nDate:   Fri Nov 11 13:23:22 2016 +0100\n\n    readwriter: fix bug when writing index. (#10)\n\n    When using ReadWriter on an existing siva file, absolute offset for\n    index entries was not being calculated correctly.\n...\n```\n\nYou can find this [example](_examples/log/main.go) and many others in the [examples](_examples) folder.\n\nContribute\n----------\n\n[Contributions](https://github.com/go-git/go-git/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22) are more than welcome, if you are interested please take a look to\nour [Contributing Guidelines](CONTRIBUTING.md).\n\nLicense\n-------\nApache License Version 2.0, see [LICENSE](LICENSE)\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 1.6748046875,
          "content": "# go-git Security Policy\n\nThe purpose of this security policy is to outline `go-git`'s process\nfor reporting, handling and disclosing security sensitive information.\n\n## Supported Versions\n\nThe project follows a version support policy where only the latest minor\nrelease is actively supported. Therefore, only issues that impact the latest\nminor release will be fixed. Users are encouraged to upgrade to the latest\nminor/patch release to benefit from the most up-to-date features, bug fixes,\nand security enhancements.​\n\nThe supported versions policy applies to both the `go-git` library and its\nassociated repositories within the `go-git` org.\n\n## Reporting Security Issues\n\nPlease report any security vulnerabilities or potential weaknesses in `go-git`\nprivately via go-git-security@googlegroups.com. Do not publicly disclose the\ndetails of the vulnerability until a fix has been implemented and released.\n\nDuring the process the project maintainers will investigate the report, so please\nprovide detailed information, including steps to reproduce, affected versions, and any mitigations if known.\n\nThe project maintainers will acknowledge the receipt of the report and work with\nthe reporter to validate and address the issue.\n\nPlease note that `go-git` does not have any bounty programs, and therefore do\nnot provide financial compensation for disclosures.\n\n## Security Disclosure Process\n\nThe project maintainers will make every effort to promptly address security issues.\n\nOnce a security vulnerability is fixed, a security advisory will be published to notify users and provide appropriate mitigation measures.\n\nAll `go-git` advisories can be found at https://github.com/go-git/go-git/security/advisories.\n"
        },
        {
          "name": "_examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "blame.go",
          "type": "blob",
          "size": 15.1474609375,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"container/heap\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"strconv\"\n\t\"time\"\n\t\"unicode/utf8\"\n\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/plumbing/object\"\n\t\"github.com/go-git/go-git/v5/utils/diff\"\n\t\"github.com/sergi/go-diff/diffmatchpatch\"\n)\n\n// BlameResult represents the result of a Blame operation.\ntype BlameResult struct {\n\t// Path is the path of the File that we're blaming.\n\tPath string\n\t// Rev (Revision) is the hash of the specified Commit used to generate this result.\n\tRev plumbing.Hash\n\t// Lines contains every line with its authorship.\n\tLines []*Line\n}\n\n// Blame returns a BlameResult with the information about the last author of\n// each line from file `path` at commit `c`.\nfunc Blame(c *object.Commit, path string) (*BlameResult, error) {\n\t// The file to blame is identified by the input arguments:\n\t// commit and path. commit is a Commit object obtained from a Repository. Path\n\t// represents a path to a specific file contained in the repository.\n\t//\n\t// Blaming a file is done by walking the tree in reverse order trying to find where each line was last modified.\n\t//\n\t// When a diff is found it cannot immediately assume it came from that commit, as it may have come from 1 of its\n\t// parents, so it will first try to resolve those diffs from its parents, if it couldn't find the change in its\n\t// parents then it will assign the change to itself.\n\t//\n\t// When encountering 2 parents that have made the same change to a file it will choose the parent that was merged\n\t// into the current branch first (this is determined by the order of the parents inside the commit).\n\t//\n\t// This currently works on a line by line basis, if performance becomes an issue it could be changed to work with\n\t// hunks rather than lines. Then when encountering diff hunks it would need to split them where necessary.\n\n\tb := new(blame)\n\tb.fRev = c\n\tb.path = path\n\tb.q = new(priorityQueue)\n\n\tfile, err := b.fRev.File(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfinalLines, err := file.Lines()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfinalLength := len(finalLines)\n\n\tneedsMap := make([]lineMap, finalLength)\n\tfor i := range needsMap {\n\t\tneedsMap[i] = lineMap{i, i, nil, -1}\n\t}\n\tcontents, err := file.Contents()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tb.q.Push(&queueItem{\n\t\tnil,\n\t\tnil,\n\t\tc,\n\t\tpath,\n\t\tcontents,\n\t\tneedsMap,\n\t\t0,\n\t\tfalse,\n\t\t0,\n\t})\n\titems := make([]*queueItem, 0)\n\tfor {\n\t\titems = items[:0]\n\t\tfor {\n\t\t\tif b.q.Len() == 0 {\n\t\t\t\treturn nil, errors.New(\"invalid state: no items left on the blame queue\")\n\t\t\t}\n\t\t\titem := b.q.Pop()\n\t\t\titems = append(items, item)\n\t\t\tnext := b.q.Peek()\n\t\t\tif next == nil || next.Hash != item.Commit.Hash {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfinished, err := b.addBlames(items)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif finished {\n\t\t\tbreak\n\t\t}\n\t}\n\n\tb.lineToCommit = make([]*object.Commit, finalLength)\n\tfor i := range needsMap {\n\t\tb.lineToCommit[i] = needsMap[i].Commit\n\t}\n\n\tlines, err := newLines(finalLines, b.lineToCommit)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &BlameResult{\n\t\tPath:  path,\n\t\tRev:   c.Hash,\n\t\tLines: lines,\n\t}, nil\n}\n\n// Line values represent the contents and author of a line in BlamedResult values.\ntype Line struct {\n\t// Author is the email address of the last author that modified the line.\n\tAuthor string\n\t// AuthorName is the name of the last author that modified the line.\n\tAuthorName string\n\t// Text is the original text of the line.\n\tText string\n\t// Date is when the original text of the line was introduced\n\tDate time.Time\n\t// Hash is the commit hash that introduced the original line\n\tHash plumbing.Hash\n}\n\nfunc newLine(author, authorName, text string, date time.Time, hash plumbing.Hash) *Line {\n\treturn &Line{\n\t\tAuthor:     author,\n\t\tAuthorName: authorName,\n\t\tText:       text,\n\t\tHash:       hash,\n\t\tDate:       date,\n\t}\n}\n\nfunc newLines(contents []string, commits []*object.Commit) ([]*Line, error) {\n\tresult := make([]*Line, 0, len(contents))\n\tfor i := range contents {\n\t\tresult = append(result, newLine(\n\t\t\tcommits[i].Author.Email, commits[i].Author.Name, contents[i],\n\t\t\tcommits[i].Author.When, commits[i].Hash,\n\t\t))\n\t}\n\n\treturn result, nil\n}\n\n// this struct is internally used by the blame function to hold its\n// inputs, outputs and state.\ntype blame struct {\n\t// the path of the file to blame\n\tpath string\n\t// the commit of the final revision of the file to blame\n\tfRev *object.Commit\n\t// resolved lines\n\tlineToCommit []*object.Commit\n\t// queue of commits that need resolving\n\tq *priorityQueue\n}\n\ntype lineMap struct {\n\tOrig, Cur    int\n\tCommit       *object.Commit\n\tFromParentNo int\n}\n\nfunc (b *blame) addBlames(curItems []*queueItem) (bool, error) {\n\tcurItem := curItems[0]\n\n\t// Simple optimisation to merge paths, there is potential to go a bit further here and check for any duplicates\n\t// not only if they are all the same.\n\tif len(curItems) == 1 {\n\t\tcurItems = nil\n\t} else if curItem.IdenticalToChild {\n\t\tallSame := true\n\t\tlenCurItems := len(curItems)\n\t\tlowestParentNo := curItem.ParentNo\n\t\tfor i := 1; i < lenCurItems; i++ {\n\t\t\tif !curItems[i].IdenticalToChild || curItem.Child != curItems[i].Child {\n\t\t\t\tallSame = false\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tlowestParentNo = min(lowestParentNo, curItems[i].ParentNo)\n\t\t}\n\t\tif allSame {\n\t\t\tcurItem.Child.numParentsNeedResolving = curItem.Child.numParentsNeedResolving - lenCurItems + 1\n\t\t\tcurItems = nil // free the memory\n\t\t\tcurItem.ParentNo = lowestParentNo\n\n\t\t\t// Now check if we can remove the parent completely\n\t\t\tfor curItem.Child.IdenticalToChild && curItem.Child.MergedChildren == nil && curItem.Child.numParentsNeedResolving == 1 {\n\t\t\t\toldChild := curItem.Child\n\t\t\t\tcurItem.Child = oldChild.Child\n\t\t\t\tcurItem.ParentNo = oldChild.ParentNo\n\t\t\t}\n\t\t}\n\t}\n\n\t// if we have more than 1 item for this commit, create a single needsMap\n\tif len(curItems) > 1 {\n\t\tcurItem.MergedChildren = make([]childToNeedsMap, len(curItems))\n\t\tfor i, c := range curItems {\n\t\t\tcurItem.MergedChildren[i] = childToNeedsMap{c.Child, c.NeedsMap, c.IdenticalToChild, c.ParentNo}\n\t\t}\n\t\tnewNeedsMap := make([]lineMap, 0, len(curItem.NeedsMap))\n\t\tnewNeedsMap = append(newNeedsMap, curItems[0].NeedsMap...)\n\n\t\tfor i := 1; i < len(curItems); i++ {\n\t\t\tcur := curItems[i].NeedsMap\n\t\t\tn := 0 // position in newNeedsMap\n\t\t\tc := 0 // position in current list\n\t\t\tfor c < len(cur) {\n\t\t\t\tif n == len(newNeedsMap) {\n\t\t\t\t\tnewNeedsMap = append(newNeedsMap, cur[c:]...)\n\t\t\t\t\tbreak\n\t\t\t\t} else if newNeedsMap[n].Cur == cur[c].Cur {\n\t\t\t\t\tn++\n\t\t\t\t\tc++\n\t\t\t\t} else if newNeedsMap[n].Cur < cur[c].Cur {\n\t\t\t\t\tn++\n\t\t\t\t} else {\n\t\t\t\t\tnewNeedsMap = append(newNeedsMap, cur[c])\n\t\t\t\t\tnewPos := len(newNeedsMap) - 1\n\t\t\t\t\tfor newPos > n {\n\t\t\t\t\t\tnewNeedsMap[newPos-1], newNeedsMap[newPos] = newNeedsMap[newPos], newNeedsMap[newPos-1]\n\t\t\t\t\t\tnewPos--\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tcurItem.NeedsMap = newNeedsMap\n\t\tcurItem.IdenticalToChild = false\n\t\tcurItem.Child = nil\n\t\tcurItems = nil // free the memory\n\t}\n\n\tparents, err := parentsContainingPath(curItem.path, curItem.Commit)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tanyPushed := false\n\tfor parnetNo, prev := range parents {\n\t\tcurrentHash, err := blobHash(curItem.path, curItem.Commit)\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\tprevHash, err := blobHash(prev.Path, prev.Commit)\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\tif currentHash == prevHash {\n\t\t\tif len(parents) == 1 && curItem.MergedChildren == nil && curItem.IdenticalToChild {\n\t\t\t\t// commit that has 1 parent and 1 child and is the same as both, bypass it completely\n\t\t\t\tb.q.Push(&queueItem{\n\t\t\t\t\tChild:            curItem.Child,\n\t\t\t\t\tCommit:           prev.Commit,\n\t\t\t\t\tpath:             prev.Path,\n\t\t\t\t\tContents:         curItem.Contents,\n\t\t\t\t\tNeedsMap:         curItem.NeedsMap, // reuse the NeedsMap as we are throwing away this item\n\t\t\t\t\tIdenticalToChild: true,\n\t\t\t\t\tParentNo:         curItem.ParentNo,\n\t\t\t\t})\n\t\t\t} else {\n\t\t\t\tb.q.Push(&queueItem{\n\t\t\t\t\tChild:            curItem,\n\t\t\t\t\tCommit:           prev.Commit,\n\t\t\t\t\tpath:             prev.Path,\n\t\t\t\t\tContents:         curItem.Contents,\n\t\t\t\t\tNeedsMap:         append([]lineMap(nil), curItem.NeedsMap...), // create new slice and copy\n\t\t\t\t\tIdenticalToChild: true,\n\t\t\t\t\tParentNo:         parnetNo,\n\t\t\t\t})\n\t\t\t\tcurItem.numParentsNeedResolving++\n\t\t\t}\n\t\t\tanyPushed = true\n\t\t\tcontinue\n\t\t}\n\n\t\t// get the contents of the file\n\t\tfile, err := prev.Commit.File(prev.Path)\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\tprevContents, err := file.Contents()\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\n\t\thunks := diff.Do(prevContents, curItem.Contents)\n\t\tprevl := -1\n\t\tcurl := -1\n\t\tneed := 0\n\t\tgetFromParent := make([]lineMap, 0)\n\tout:\n\t\tfor h := range hunks {\n\t\t\thLines := countLines(hunks[h].Text)\n\t\t\tfor hl := 0; hl < hLines; hl++ {\n\t\t\t\tswitch hunks[h].Type {\n\t\t\t\tcase diffmatchpatch.DiffEqual:\n\t\t\t\t\tprevl++\n\t\t\t\t\tcurl++\n\t\t\t\t\tif curl == curItem.NeedsMap[need].Cur {\n\t\t\t\t\t\t// add to needs\n\t\t\t\t\t\tgetFromParent = append(getFromParent, lineMap{curl, prevl, nil, -1})\n\t\t\t\t\t\t// move to next need\n\t\t\t\t\t\tneed++\n\t\t\t\t\t\tif need >= len(curItem.NeedsMap) {\n\t\t\t\t\t\t\tbreak out\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\tcase diffmatchpatch.DiffInsert:\n\t\t\t\t\tcurl++\n\t\t\t\t\tif curl == curItem.NeedsMap[need].Cur {\n\t\t\t\t\t\t// the line we want is added, it may have been added here (or by another parent), skip it for now\n\t\t\t\t\t\tneed++\n\t\t\t\t\t\tif need >= len(curItem.NeedsMap) {\n\t\t\t\t\t\t\tbreak out\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\tcase diffmatchpatch.DiffDelete:\n\t\t\t\t\tprevl += hLines\n\t\t\t\t\tcontinue out\n\t\t\t\tdefault:\n\t\t\t\t\treturn false, errors.New(\"invalid state: invalid hunk Type\")\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif len(getFromParent) > 0 {\n\t\t\tb.q.Push(&queueItem{\n\t\t\t\tcurItem,\n\t\t\t\tnil,\n\t\t\t\tprev.Commit,\n\t\t\t\tprev.Path,\n\t\t\t\tprevContents,\n\t\t\t\tgetFromParent,\n\t\t\t\t0,\n\t\t\t\tfalse,\n\t\t\t\tparnetNo,\n\t\t\t})\n\t\t\tcurItem.numParentsNeedResolving++\n\t\t\tanyPushed = true\n\t\t}\n\t}\n\n\tcurItem.Contents = \"\" // no longer need, free the memory\n\n\tif !anyPushed {\n\t\treturn finishNeeds(curItem)\n\t}\n\n\treturn false, nil\n}\n\nfunc finishNeeds(curItem *queueItem) (bool, error) {\n\t// any needs left in the needsMap must have come from this revision\n\tfor i := range curItem.NeedsMap {\n\t\tif curItem.NeedsMap[i].Commit == nil {\n\t\t\tcurItem.NeedsMap[i].Commit = curItem.Commit\n\t\t\tcurItem.NeedsMap[i].FromParentNo = -1\n\t\t}\n\t}\n\n\tif curItem.Child == nil && curItem.MergedChildren == nil {\n\t\treturn true, nil\n\t}\n\n\tif curItem.MergedChildren == nil {\n\t\treturn applyNeeds(curItem.Child, curItem.NeedsMap, curItem.IdenticalToChild, curItem.ParentNo)\n\t}\n\n\tfor _, ctn := range curItem.MergedChildren {\n\t\tm := 0 // position in merged needs map\n\t\tp := 0 // position in parent needs map\n\t\tfor p < len(ctn.NeedsMap) {\n\t\t\tif ctn.NeedsMap[p].Cur == curItem.NeedsMap[m].Cur {\n\t\t\t\tctn.NeedsMap[p].Commit = curItem.NeedsMap[m].Commit\n\t\t\t\tm++\n\t\t\t\tp++\n\t\t\t} else if ctn.NeedsMap[p].Cur < curItem.NeedsMap[m].Cur {\n\t\t\t\tp++\n\t\t\t} else {\n\t\t\t\tm++\n\t\t\t}\n\t\t}\n\t\tfinished, err := applyNeeds(ctn.Child, ctn.NeedsMap, ctn.IdenticalToChild, ctn.ParentNo)\n\t\tif finished || err != nil {\n\t\t\treturn finished, err\n\t\t}\n\t}\n\n\treturn false, nil\n}\n\nfunc applyNeeds(child *queueItem, needsMap []lineMap, identicalToChild bool, parentNo int) (bool, error) {\n\tif identicalToChild {\n\t\tfor i := range child.NeedsMap {\n\t\t\tl := &child.NeedsMap[i]\n\t\t\tif l.Cur != needsMap[i].Cur || l.Orig != needsMap[i].Orig {\n\t\t\t\treturn false, errors.New(\"needsMap isn't the same? Why not??\")\n\t\t\t}\n\t\t\tif l.Commit == nil || parentNo < l.FromParentNo {\n\t\t\t\tl.Commit = needsMap[i].Commit\n\t\t\t\tl.FromParentNo = parentNo\n\t\t\t}\n\t\t}\n\t} else {\n\t\ti := 0\n\tout:\n\t\tfor j := range child.NeedsMap {\n\t\t\tl := &child.NeedsMap[j]\n\t\t\tfor needsMap[i].Orig < l.Cur {\n\t\t\t\ti++\n\t\t\t\tif i == len(needsMap) {\n\t\t\t\t\tbreak out\n\t\t\t\t}\n\t\t\t}\n\t\t\tif l.Cur == needsMap[i].Orig {\n\t\t\t\tif l.Commit == nil || parentNo < l.FromParentNo {\n\t\t\t\t\tl.Commit = needsMap[i].Commit\n\t\t\t\t\tl.FromParentNo = parentNo\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tchild.numParentsNeedResolving--\n\tif child.numParentsNeedResolving == 0 {\n\t\tfinished, err := finishNeeds(child)\n\t\tif finished || err != nil {\n\t\t\treturn finished, err\n\t\t}\n\t}\n\n\treturn false, nil\n}\n\n// String prints the results of a Blame using git-blame's style.\nfunc (b BlameResult) String() string {\n\tvar buf bytes.Buffer\n\n\t// max line number length\n\tmlnl := len(strconv.Itoa(len(b.Lines)))\n\t// max author length\n\tmal := b.maxAuthorLength()\n\tformat := fmt.Sprintf(\"%%s (%%-%ds %%s %%%dd) %%s\\n\", mal, mlnl)\n\n\tfor ln := range b.Lines {\n\t\t_, _ = fmt.Fprintf(&buf, format, b.Lines[ln].Hash.String()[:8],\n\t\t\tb.Lines[ln].AuthorName, b.Lines[ln].Date.Format(\"2006-01-02 15:04:05 -0700\"), ln+1, b.Lines[ln].Text)\n\t}\n\treturn buf.String()\n}\n\n// utility function to calculate the number of runes needed\n// to print the longest author name in the blame of a file.\nfunc (b BlameResult) maxAuthorLength() int {\n\tm := 0\n\tfor ln := range b.Lines {\n\t\tm = max(m, utf8.RuneCountInString(b.Lines[ln].AuthorName))\n\t}\n\treturn m\n}\n\nfunc min(a, b int) int {\n\tif a < b {\n\t\treturn a\n\t}\n\treturn b\n}\n\nfunc max(a, b int) int {\n\tif a > b {\n\t\treturn a\n\t}\n\treturn b\n}\n\ntype childToNeedsMap struct {\n\tChild            *queueItem\n\tNeedsMap         []lineMap\n\tIdenticalToChild bool\n\tParentNo         int\n}\n\ntype queueItem struct {\n\tChild                   *queueItem\n\tMergedChildren          []childToNeedsMap\n\tCommit                  *object.Commit\n\tpath                    string\n\tContents                string\n\tNeedsMap                []lineMap\n\tnumParentsNeedResolving int\n\tIdenticalToChild        bool\n\tParentNo                int\n}\n\ntype priorityQueueImp []*queueItem\n\nfunc (pq *priorityQueueImp) Len() int { return len(*pq) }\nfunc (pq *priorityQueueImp) Less(i, j int) bool {\n\treturn !(*pq)[i].Commit.Less((*pq)[j].Commit)\n}\nfunc (pq *priorityQueueImp) Swap(i, j int) { (*pq)[i], (*pq)[j] = (*pq)[j], (*pq)[i] }\nfunc (pq *priorityQueueImp) Push(x any)    { *pq = append(*pq, x.(*queueItem)) }\nfunc (pq *priorityQueueImp) Pop() any {\n\tn := len(*pq)\n\tret := (*pq)[n-1]\n\t(*pq)[n-1] = nil // ovoid memory leak\n\t*pq = (*pq)[0 : n-1]\n\n\treturn ret\n}\nfunc (pq *priorityQueueImp) Peek() *object.Commit {\n\tif len(*pq) == 0 {\n\t\treturn nil\n\t}\n\treturn (*pq)[0].Commit\n}\n\ntype priorityQueue priorityQueueImp\n\nfunc (pq *priorityQueue) Init()    { heap.Init((*priorityQueueImp)(pq)) }\nfunc (pq *priorityQueue) Len() int { return (*priorityQueueImp)(pq).Len() }\nfunc (pq *priorityQueue) Push(c *queueItem) {\n\theap.Push((*priorityQueueImp)(pq), c)\n}\nfunc (pq *priorityQueue) Pop() *queueItem {\n\treturn heap.Pop((*priorityQueueImp)(pq)).(*queueItem)\n}\nfunc (pq *priorityQueue) Peek() *object.Commit { return (*priorityQueueImp)(pq).Peek() }\n\ntype parentCommit struct {\n\tCommit *object.Commit\n\tPath   string\n}\n\nfunc parentsContainingPath(path string, c *object.Commit) ([]parentCommit, error) {\n\t// TODO: benchmark this method making git.object.Commit.parent public instead of using\n\t// an iterator\n\tvar result []parentCommit\n\titer := c.Parents()\n\tfor {\n\t\tparent, err := iter.Next()\n\t\tif err == io.EOF {\n\t\t\treturn result, nil\n\t\t}\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif _, err := parent.File(path); err == nil {\n\t\t\tresult = append(result, parentCommit{parent, path})\n\t\t} else {\n\t\t\t// look for renames\n\t\t\tpatch, err := parent.Patch(c)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t} else if patch != nil {\n\t\t\t\tfor _, fp := range patch.FilePatches() {\n\t\t\t\t\tfrom, to := fp.Files()\n\t\t\t\t\tif from != nil && to != nil && to.Path() == path {\n\t\t\t\t\t\tresult = append(result, parentCommit{parent, from.Path()})\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc blobHash(path string, commit *object.Commit) (plumbing.Hash, error) {\n\tfile, err := commit.File(path)\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\treturn file.Hash, nil\n}\n"
        },
        {
          "name": "blame_test.go",
          "type": "blob",
          "size": 27.587890625,
          "content": "package git\n\nimport (\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/plumbing/object\"\n\n\tfixtures \"github.com/go-git/go-git-fixtures/v4\"\n\t. \"gopkg.in/check.v1\"\n)\n\ntype BlameSuite struct {\n\tBaseSuite\n}\n\nvar _ = Suite(&BlameSuite{})\n\nfunc (s *BlameSuite) TestNewLines(c *C) {\n\th := plumbing.NewHash(\"ce9f123d790717599aaeb76bc62510de437761be\")\n\tlines, err := newLines([]string{\"foo\"}, []*object.Commit{{\n\t\tHash:    h,\n\t\tMessage: \"foo\",\n\t}})\n\n\tc.Assert(err, IsNil)\n\tc.Assert(lines, HasLen, 1)\n\tc.Assert(lines[0].Text, Equals, \"foo\")\n\tc.Assert(lines[0].Hash, Equals, h)\n}\n\nfunc (s *BlameSuite) TestNewLinesWithNewLine(c *C) {\n\tlines, err := newLines([]string{\"foo\", \"\"}, []*object.Commit{\n\t\t{Message: \"foo\"},\n\t\t{Message: \"bar\"},\n\t})\n\n\tc.Assert(err, IsNil)\n\tc.Assert(lines, HasLen, 2)\n\tc.Assert(lines[0].Text, Equals, \"foo\")\n\tc.Assert(lines[1].Text, Equals, \"\")\n}\n\ntype blameTest struct {\n\trepo   string\n\trev    string\n\tpath   string\n\tblames []string // the commits blamed for each line\n}\n\n// run a blame on all the suite's tests\nfunc (s *BlameSuite) TestBlame(c *C) {\n\tfor _, t := range blameTests {\n\t\tr := s.NewRepositoryFromPackfile(fixtures.ByURL(t.repo).One())\n\n\t\texp := s.mockBlame(c, t, r)\n\t\tcommit, err := r.CommitObject(plumbing.NewHash(t.rev))\n\t\tc.Assert(err, IsNil)\n\n\t\tobt, err := Blame(commit, t.path)\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(obt, DeepEquals, exp)\n\n\t\tfor i, l := range obt.Lines {\n\t\t\tc.Assert(l.Hash.String(), Equals, t.blames[i])\n\t\t}\n\t}\n}\n\nfunc (s *BlameSuite) mockBlame(c *C, t blameTest, r *Repository) (blame *BlameResult) {\n\tcommit, err := r.CommitObject(plumbing.NewHash(t.rev))\n\tc.Assert(err, IsNil, Commentf(\"%v: repo=%s, rev=%s\", err, t.repo, t.rev))\n\n\tf, err := commit.File(t.path)\n\tc.Assert(err, IsNil)\n\tlines, err := f.Lines()\n\tc.Assert(err, IsNil)\n\tc.Assert(len(t.blames), Equals, len(lines), Commentf(\n\t\t\"repo=%s, path=%s, rev=%s: the number of lines in the file and the number of expected blames differ (len(blames)=%d, len(lines)=%d)\\nblames=%#q\\nlines=%#q\", t.repo, t.path, t.rev, len(t.blames), len(lines), t.blames, lines))\n\n\tblamedLines := make([]*Line, 0, len(t.blames))\n\tfor i := range t.blames {\n\t\tcommit, err := r.CommitObject(plumbing.NewHash(t.blames[i]))\n\t\tc.Assert(err, IsNil)\n\t\tl := &Line{\n\t\t\tAuthor:     commit.Author.Email,\n\t\t\tAuthorName: commit.Author.Name,\n\t\t\tText:       lines[i],\n\t\t\tDate:       commit.Author.When,\n\t\t\tHash:       commit.Hash,\n\t\t}\n\t\tblamedLines = append(blamedLines, l)\n\t}\n\n\treturn &BlameResult{\n\t\tPath:  t.path,\n\t\tRev:   plumbing.NewHash(t.rev),\n\t\tLines: blamedLines,\n\t}\n}\n\n// utility function to avoid writing so many repeated commits\nfunc repeat(s string, n int) []string {\n\tif n < 0 {\n\t\tpanic(\"repeat: n < 0\")\n\t}\n\tr := make([]string, 0, n)\n\tfor i := 0; i < n; i++ {\n\t\tr = append(r, s)\n\t}\n\n\treturn r\n}\n\n// utility function to concat slices\nfunc concat(vargs ...[]string) []string {\n\tvar r []string\n\tfor _, ss := range vargs {\n\t\tr = append(r, ss...)\n\t}\n\n\treturn r\n}\n\nvar blameTests = [...]blameTest{\n\t// use the blame2humantest.bash script to easily add more tests.\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"binary.jpg\", concat(\n\t\trepeat(\"35e85108805c84807bc66a02d91535e1e24b38b9\", 285),\n\t)},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"CHANGELOG\", concat(\n\t\trepeat(\"b8e471f58bcbca63b07bda20e428190409c2db47\", 1),\n\t)},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"go/example.go\", concat(\n\t\trepeat(\"918c48b83bd081e863dbe1b80f8998f058cd8294\", 142),\n\t)},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"json/long.json\", concat(\n\t\trepeat(\"af2d6a6954d532f8ffb47615169c8fdf9d383a1a\", 6492),\n\t)},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"json/short.json\", concat(\n\t\trepeat(\"af2d6a6954d532f8ffb47615169c8fdf9d383a1a\", 22),\n\t)},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"LICENSE\", concat(\n\t\trepeat(\"b029517f6300c2da0f4b651b8642506cd6aaf45d\", 22),\n\t)},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"php/crappy.php\", concat(\n\t\trepeat(\"918c48b83bd081e863dbe1b80f8998f058cd8294\", 259),\n\t)},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"vendor/foo.go\", concat(\n\t\trepeat(\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", 7),\n\t)},\n\t/*\n\t\t// This fails due to the different diff tool being used to create the patches.\n\t\t// For example in commit d4b48a39aba7d3bd3e8abef2274a95b112d1ae73 when \"function echo_status()\" is added:\n\t\t// - 'git diff' adds the new \"}\\n\\n\" to the end of function and keeps the \"}\\n\\n\" beforehand blamed to the previous commit\n\t\t// - our diff adds the new \"}\\n\\n\" before the function and reuses the existing \"}\\n\\n\" to close the new function\n\t\t// the resultant file is the same, but it causes blame not to match.\n\t\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"InstallSpinnaker.sh\", concat(\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 2),\n\t\t\trepeat(\"a47d0aaeda421f06df248ad65bd58230766bf118\", 1),\n\t\t\trepeat(\"23673af3ad70b50bba7fdafadc2323302f5ba520\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 29),\n\t\t\trepeat(\"9a06d3f20eabb254d0a1e2ff7735ef007ccd595e\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 4),\n\t\t\trepeat(\"a47d0aaeda421f06df248ad65bd58230766bf118\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 5),\n\t\t\trepeat(\"0c5bb1e4392e751f884f3c57de5d4aee72c40031\", 2),\n\t\t\trepeat(\"d4b48a39aba7d3bd3e8abef2274a95b112d1ae73\", 3),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 7),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"b7015a5d36990d69a054482556127b9c7404a24a\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 2),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 5),\n\t\t\trepeat(\"d4b48a39aba7d3bd3e8abef2274a95b112d1ae73\", 7),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 3),\n\t\t\trepeat(\"d4b48a39aba7d3bd3e8abef2274a95b112d1ae73\", 6),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 10),\n\t\t\trepeat(\"b7015a5d36990d69a054482556127b9c7404a24a\", 4),\n\t\t\trepeat(\"0c5bb1e4392e751f884f3c57de5d4aee72c40031\", 2),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 2),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 4),\n\t\t\trepeat(\"23673af3ad70b50bba7fdafadc2323302f5ba520\", 4),\n\t\t\trepeat(\"d4b48a39aba7d3bd3e8abef2274a95b112d1ae73\", 4),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 1),\n\t\t\trepeat(\"d4b48a39aba7d3bd3e8abef2274a95b112d1ae73\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 1),\n\t\t\trepeat(\"b7015a5d36990d69a054482556127b9c7404a24a\", 1),\n\t\t\trepeat(\"0c5bb1e4392e751f884f3c57de5d4aee72c40031\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 13),\n\t\t\trepeat(\"b7015a5d36990d69a054482556127b9c7404a24a\", 2),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 6),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 1),\n\t\t\trepeat(\"b7015a5d36990d69a054482556127b9c7404a24a\", 2),\n\t\t\trepeat(\"0c5bb1e4392e751f884f3c57de5d4aee72c40031\", 1),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 4),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 3),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 2),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 4),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 3),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 15),\n\t\t\trepeat(\"b41d7c0e5b20bbe7c8eb6606731a3ff68f4e3941\", 1),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 1),\n\t\t\trepeat(\"b41d7c0e5b20bbe7c8eb6606731a3ff68f4e3941\", 8),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 2),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 12),\n\t\t\trepeat(\"505577dc87d300cf562dc4702a05a5615d90d855\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 5),\n\t\t\trepeat(\"370d61cdbc1f3c90db6759f1599ccbabd40ad6c1\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 4),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 1),\n\t\t\trepeat(\"b41d7c0e5b20bbe7c8eb6606731a3ff68f4e3941\", 5),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 3),\n\t\t\trepeat(\"b41d7c0e5b20bbe7c8eb6606731a3ff68f4e3941\", 2),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 2),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 9),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 1),\n\t\t\trepeat(\"b41d7c0e5b20bbe7c8eb6606731a3ff68f4e3941\", 3),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 4),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 6),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 1),\n\t\t\trepeat(\"b7015a5d36990d69a054482556127b9c7404a24a\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 6),\n\t\t\trepeat(\"d2f6214b625db706384b378a29cc4c22237db97a\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 3),\n\t\t\trepeat(\"d2f6214b625db706384b378a29cc4c22237db97a\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 4),\n\t\t\trepeat(\"b7015a5d36990d69a054482556127b9c7404a24a\", 1),\n\t\t\trepeat(\"c9c2a0ec03968ab17e8b16fdec9661eb1dbea173\", 1),\n\t\t\trepeat(\"d2f6214b625db706384b378a29cc4c22237db97a\", 2),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"b7015a5d36990d69a054482556127b9c7404a24a\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 12),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 5),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 3),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"01e65d67eed8afcb67a6bdf1c962541f62b299c9\", 5),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 3),\n\t\t\trepeat(\"a47d0aaeda421f06df248ad65bd58230766bf118\", 5),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 5),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 1),\n\t\t\trepeat(\"01e65d67eed8afcb67a6bdf1c962541f62b299c9\", 2),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"01e65d67eed8afcb67a6bdf1c962541f62b299c9\", 1),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"b2c7142082d52b09ca20228606c31c7479c0833e\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 1),\n\t\t\trepeat(\"495c7118e7cf757aa04eab410b64bfb5b5149ad2\", 1),\n\t\t\trepeat(\"d4b48a39aba7d3bd3e8abef2274a95b112d1ae73\", 1),\n\t\t\trepeat(\"495c7118e7cf757aa04eab410b64bfb5b5149ad2\", 3),\n\t\t\trepeat(\"d4b48a39aba7d3bd3e8abef2274a95b112d1ae73\", 1),\n\t\t\trepeat(\"495c7118e7cf757aa04eab410b64bfb5b5149ad2\", 1),\n\t\t\trepeat(\"50d0556563599366f29cb286525780004fa5a317\", 1),\n\t\t\trepeat(\"dd2d03c19658ff96d371aef00e75e2e54702da0e\", 1),\n\t\t\trepeat(\"d4b48a39aba7d3bd3e8abef2274a95b112d1ae73\", 1),\n\t\t\trepeat(\"dd2d03c19658ff96d371aef00e75e2e54702da0e\", 2),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 2),\n\t\t\trepeat(\"01e65d67eed8afcb67a6bdf1c962541f62b299c9\", 1),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"b5c6053a46993b20d1b91e7b7206bffa54669ad7\", 1),\n\t\t\trepeat(\"9e74d009894d73dd07773ea6b3bdd8323db980f7\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 1),\n\t\t\trepeat(\"d4b48a39aba7d3bd3e8abef2274a95b112d1ae73\", 4),\n\t\t\trepeat(\"01e65d67eed8afcb67a6bdf1c962541f62b299c9\", 1),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 1),\n\t\t\trepeat(\"b7015a5d36990d69a054482556127b9c7404a24a\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 1),\n\t\t\trepeat(\"d2f6214b625db706384b378a29cc4c22237db97a\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 3),\n\t\t\trepeat(\"b41d7c0e5b20bbe7c8eb6606731a3ff68f4e3941\", 2),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 2),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 4),\n\t\t\trepeat(\"d2f6214b625db706384b378a29cc4c22237db97a\", 1),\n\t\t\trepeat(\"b7015a5d36990d69a054482556127b9c7404a24a\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 5),\n\t\t\trepeat(\"b41d7c0e5b20bbe7c8eb6606731a3ff68f4e3941\", 2),\n\t\t\trepeat(\"d2f6214b625db706384b378a29cc4c22237db97a\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 5),\n\t\t\trepeat(\"ba486de7c025457963701114c683dcd4708e1dee\", 4),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"01e65d67eed8afcb67a6bdf1c962541f62b299c9\", 1),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"01e65d67eed8afcb67a6bdf1c962541f62b299c9\", 3),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"01e65d67eed8afcb67a6bdf1c962541f62b299c9\", 3),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 2),\n\t\t\trepeat(\"01e65d67eed8afcb67a6bdf1c962541f62b299c9\", 3),\n\t\t\trepeat(\"3de4f77c105f700f50d9549d32b9a05a01b46c4b\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 2),\n\t\t\trepeat(\"370d61cdbc1f3c90db6759f1599ccbabd40ad6c1\", 6),\n\t\t\trepeat(\"dd7e66c862209e8b912694a582a09c0db3227f0d\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 2),\n\t\t\trepeat(\"dd7e66c862209e8b912694a582a09c0db3227f0d\", 3),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"dd7e66c862209e8b912694a582a09c0db3227f0d\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 3),\n\t\t)},\n\t*/\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"pylib/spinnaker/reconfigure_spinnaker.py\", concat(\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 22),\n\t\trepeat(\"c89dab0d42f1856d157357e9010f8cc6a12f5b1f\", 7),\n\t)},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"pylib/spinnaker/validate_configuration.py\", concat(\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 29),\n\t\trepeat(\"1e3d328a2cabda5d0aaddc5dec65271343e0dc37\", 19),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 15),\n\t\trepeat(\"b5d999e2986e190d81767cd3cfeda0260f9f6fb8\", 1),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 12),\n\t\trepeat(\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\", 1),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 4),\n\t\trepeat(\"b5d999e2986e190d81767cd3cfeda0260f9f6fb8\", 8),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 1),\n\t\trepeat(\"b5d999e2986e190d81767cd3cfeda0260f9f6fb8\", 4),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 46),\n\t\trepeat(\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\", 1),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 4),\n\t\trepeat(\"1e3d328a2cabda5d0aaddc5dec65271343e0dc37\", 42),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 1),\n\t\trepeat(\"1e3d328a2cabda5d0aaddc5dec65271343e0dc37\", 1),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 3),\n\t\trepeat(\"1e3d328a2cabda5d0aaddc5dec65271343e0dc37\", 1),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 1),\n\t\trepeat(\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\", 8),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 1),\n\t\trepeat(\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\", 2),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 3),\n\t\trepeat(\"1e3d328a2cabda5d0aaddc5dec65271343e0dc37\", 3),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 12),\n\t\trepeat(\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\", 10),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 69),\n\t\trepeat(\"b5d999e2986e190d81767cd3cfeda0260f9f6fb8\", 7),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 4),\n\t)},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"pylib/spinnaker/run.py\", concat(\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 185),\n\t)},\n\t/*\n\t\t// This fails due to the different diff tool being used to create the patches.\n\t\t// For commit c89dab0d42f1856d157357e9010f8cc6a12f5b1f our diff tool keeps an existing newline as moved in the file, whereas\n\t\t// 'git diff' says the existing newline was deleted and a new one created.\n\t\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"pylib/spinnaker/configurator.py\", concat(\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 53),\n\t\t\trepeat(\"c89dab0d42f1856d157357e9010f8cc6a12f5b1f\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 4),\n\t\t\trepeat(\"e805183c72f0426fb073728c01901c2fd2db1da6\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 6),\n\t\t\trepeat(\"023d4fb17b76e0fe0764971df8b8538b735a1d67\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 36),\n\t\t\trepeat(\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 3),\n\t\t\trepeat(\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\", 3),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 4),\n\t\t\trepeat(\"c89dab0d42f1856d157357e9010f8cc6a12f5b1f\", 13),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 2),\n\t\t\trepeat(\"c89dab0d42f1856d157357e9010f8cc6a12f5b1f\", 18),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 2),\n\t\t\trepeat(\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\", 1),\n\t\t\trepeat(\"023d4fb17b76e0fe0764971df8b8538b735a1d67\", 17),\n\t\t\trepeat(\"c89dab0d42f1856d157357e9010f8cc6a12f5b1f\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 43),\n\t\t)},\n\t*/\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"pylib/spinnaker/__init__.py\", []string{}},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"gradle/wrapper/gradle-wrapper.jar\", concat(\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 1),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 7),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 2),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 2),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 3),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 1),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 10),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 11),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 29),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 7),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 58),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 1),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 1),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 2),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 2),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 13),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 4),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 3),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 13),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 2),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 9),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 3),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 1),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 17),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 3),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 6),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 6),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 3),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 5),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 4),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 3),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 2),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 6),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 55),\n\t)},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"config/settings.js\", concat(\n\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 17),\n\t\trepeat(\"99534ecc895fe17a1d562bb3049d4168a04d0865\", 1),\n\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 43),\n\t\trepeat(\"d2838db9f6ef9628645e7d04cd9658a83e8708ea\", 1),\n\t\trepeat(\"637ba49300f701cfbd859c1ccf13c4f39a9ba1c8\", 1),\n\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 13),\n\t)},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"config/default-spinnaker-local.yml\", concat(\n\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 9),\n\t\trepeat(\"5e09821cbd7d710405b61cab0a795c2982a71b9c\", 2),\n\t\trepeat(\"99534ecc895fe17a1d562bb3049d4168a04d0865\", 1),\n\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 2),\n\t\trepeat(\"a596972a661d9a7deca8abd18b52ce1a39516e89\", 1),\n\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 5),\n\t\trepeat(\"5e09821cbd7d710405b61cab0a795c2982a71b9c\", 2),\n\t\trepeat(\"a596972a661d9a7deca8abd18b52ce1a39516e89\", 1),\n\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 5),\n\t\trepeat(\"5e09821cbd7d710405b61cab0a795c2982a71b9c\", 1),\n\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 25),\n\t\trepeat(\"caf6d62e8285d4681514dd8027356fb019bc97ff\", 1),\n\t\trepeat(\"eaf7614cad81e8ab5c813dd4821129d0c04ea449\", 1),\n\t\trepeat(\"caf6d62e8285d4681514dd8027356fb019bc97ff\", 1),\n\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 24),\n\t\trepeat(\"974b775a8978b120ff710cac93a21c7387b914c9\", 2),\n\t\trepeat(\"3ce7b902a51bac2f10994f7d1f251b616c975e54\", 1),\n\t\trepeat(\"5a2a845bc08974a36d599a4a4b7e25be833823b0\", 6),\n\t\trepeat(\"41e96c54a478e5d09dd07ed7feb2d8d08d8c7e3c\", 14),\n\t\trepeat(\"7c8d9a6081d9cb7a56c479bfe64d70540ea32795\", 5),\n\t\trepeat(\"5a2a845bc08974a36d599a4a4b7e25be833823b0\", 2),\n\t)},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"config/spinnaker.yml\", concat(\n\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 32),\n\t\trepeat(\"41e96c54a478e5d09dd07ed7feb2d8d08d8c7e3c\", 2),\n\t\trepeat(\"5a2a845bc08974a36d599a4a4b7e25be833823b0\", 1),\n\t\trepeat(\"41e96c54a478e5d09dd07ed7feb2d8d08d8c7e3c\", 6),\n\t\trepeat(\"5a2a845bc08974a36d599a4a4b7e25be833823b0\", 2),\n\t\trepeat(\"41e96c54a478e5d09dd07ed7feb2d8d08d8c7e3c\", 2),\n\t\trepeat(\"5a2a845bc08974a36d599a4a4b7e25be833823b0\", 2),\n\t\trepeat(\"41e96c54a478e5d09dd07ed7feb2d8d08d8c7e3c\", 3),\n\t\trepeat(\"7c8d9a6081d9cb7a56c479bfe64d70540ea32795\", 3),\n\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 50),\n\t\trepeat(\"974b775a8978b120ff710cac93a21c7387b914c9\", 2),\n\t\trepeat(\"d4553dac205023fa77652308af1a2d1cf52138fb\", 1),\n\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 9),\n\t\trepeat(\"caf6d62e8285d4681514dd8027356fb019bc97ff\", 1),\n\t\trepeat(\"eaf7614cad81e8ab5c813dd4821129d0c04ea449\", 1),\n\t\trepeat(\"caf6d62e8285d4681514dd8027356fb019bc97ff\", 1),\n\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 39),\n\t\trepeat(\"079e42e7c979541b6fab7343838f7b9fd4a360cd\", 6),\n\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 15),\n\t)},\n\t/*\n\t\t// This fails due to the different diff tool being used to create the patches\n\t\t// For commit d1ff4e13e9e0b500821aa558373878f93487e34b our diff tool keeps an existing newline as moved in the file, whereas\n\t\t// 'git diff' says the existing newline was deleted and a new one created\n\t\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"dev/install_development.sh\", concat(\n\t\t\trepeat(\"99534ecc895fe17a1d562bb3049d4168a04d0865\", 1),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 71),\n\t\t)},\n\t*/\n\t/*\n\t\t// This fails due to the different diff tool being used to create the patches\n\t\t// For commit 838aed816872c52ed435e4876a7b64dba0bed500 the diff tools assign the \"fi\\n\" to different line numbers\n\t\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"dev/bootstrap_dev.sh\", concat(\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 95),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 10),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 7),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 2),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 1),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 3),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 4),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 12),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 2),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 2),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 2),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 3),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 6),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 1),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 4),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 1),\n\t\t\trepeat(\"376599177551c3f04ccc94d71bbb4d037dec0c3f\", 2),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 17),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 2),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 2),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 2),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 3),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 3),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 5),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 5),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 8),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 4),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 1),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 6),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 1),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 4),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 10),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 2),\n\t\t\trepeat(\"fc28a378558cdb5bbc08b6dcb96ee77c5b716760\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 1),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 8),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 1),\n\t\t\trepeat(\"fc28a378558cdb5bbc08b6dcb96ee77c5b716760\", 1),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 4),\n\t\t\trepeat(\"24551a5d486969a2972ee05e87f16444890f9555\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 2),\n\t\t\trepeat(\"24551a5d486969a2972ee05e87f16444890f9555\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 8),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 13),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 5),\n\t\t\trepeat(\"24551a5d486969a2972ee05e87f16444890f9555\", 1),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 8),\n\t\t)},\n\t*/\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"dev/create_google_dev_vm.sh\", concat(\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 20),\n\t)},\n}\n"
        },
        {
          "name": "cli",
          "type": "tree",
          "content": null
        },
        {
          "name": "common.go",
          "type": "blob",
          "size": 0.4423828125,
          "content": "package git\n\nimport \"strings\"\n\n// countLines returns the number of lines in a string à la git, this is\n// The newline character is assumed to be '\\n'.  The empty string\n// contains 0 lines.  If the last line of the string doesn't end with a\n// newline, it will still be considered a line.\nfunc countLines(s string) int {\n\tif s == \"\" {\n\t\treturn 0\n\t}\n\n\tnEOL := strings.Count(s, \"\\n\")\n\tif strings.HasSuffix(s, \"\\n\") {\n\t\treturn nEOL\n\t}\n\n\treturn nEOL + 1\n}\n"
        },
        {
          "name": "common_test.go",
          "type": "blob",
          "size": 5.2109375,
          "content": "package git\n\nimport (\n\t\"os\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/plumbing/cache\"\n\t\"github.com/go-git/go-git/v5/plumbing/format/packfile\"\n\t\"github.com/go-git/go-git/v5/plumbing/object\"\n\t\"github.com/go-git/go-git/v5/storage/filesystem\"\n\t\"github.com/go-git/go-git/v5/storage/memory\"\n\n\t\"github.com/go-git/go-billy/v5\"\n\t\"github.com/go-git/go-billy/v5/memfs\"\n\t\"github.com/go-git/go-billy/v5/osfs\"\n\t\"github.com/go-git/go-billy/v5/util\"\n\tfixtures \"github.com/go-git/go-git-fixtures/v4\"\n\t. \"gopkg.in/check.v1\"\n)\n\nfunc Test(t *testing.T) { TestingT(t) }\n\ntype BaseSuite struct {\n\tfixtures.Suite\n\tRepository *Repository\n\n\tcache map[string]*Repository\n}\n\nfunc (s *BaseSuite) SetUpSuite(c *C) {\n\ts.buildBasicRepository(c)\n\n\ts.cache = make(map[string]*Repository)\n}\n\nfunc (s *BaseSuite) TearDownSuite(c *C) {\n\ts.Suite.TearDownSuite(c)\n}\n\nfunc (s *BaseSuite) buildBasicRepository(_ *C) {\n\tf := fixtures.Basic().One()\n\ts.Repository = s.NewRepository(f)\n}\n\n// NewRepository returns a new repository using the .git folder, if the fixture\n// is tagged as worktree the filesystem from fixture is used, otherwise a new\n// memfs filesystem is used as worktree.\nfunc (s *BaseSuite) NewRepository(f *fixtures.Fixture) *Repository {\n\tvar worktree, dotgit billy.Filesystem\n\tif f.Is(\"worktree\") {\n\t\tr, err := PlainOpen(f.Worktree().Root())\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\n\t\treturn r\n\t}\n\n\tdotgit = f.DotGit()\n\tworktree = memfs.New()\n\n\tst := filesystem.NewStorage(dotgit, cache.NewObjectLRUDefault())\n\n\tr, err := Open(st, worktree)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\treturn r\n}\n\n// NewRepositoryWithEmptyWorktree returns a new repository using the .git folder\n// from the fixture but without a empty memfs worktree, the index and the\n// modules are deleted from the .git folder.\nfunc (s *BaseSuite) NewRepositoryWithEmptyWorktree(f *fixtures.Fixture) *Repository {\n\tdotgit := f.DotGit()\n\terr := dotgit.Remove(\"index\")\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\terr = util.RemoveAll(dotgit, \"modules\")\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tworktree := memfs.New()\n\n\tst := filesystem.NewStorage(dotgit, cache.NewObjectLRUDefault())\n\n\tr, err := Open(st, worktree)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\treturn r\n\n}\n\nfunc (s *BaseSuite) NewRepositoryFromPackfile(f *fixtures.Fixture) *Repository {\n\th := f.PackfileHash\n\tif r, ok := s.cache[h]; ok {\n\t\treturn r\n\t}\n\n\tstorer := memory.NewStorage()\n\tp := f.Packfile()\n\tdefer func() { _ = p.Close() }()\n\n\tif err := packfile.UpdateObjectStorage(storer, p); err != nil {\n\t\tpanic(err)\n\t}\n\n\terr := storer.SetReference(plumbing.NewHashReference(plumbing.HEAD, plumbing.NewHash(f.Head)))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tr, err := Open(storer, memfs.New())\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\ts.cache[h] = r\n\treturn r\n}\n\nfunc (s *BaseSuite) GetBasicLocalRepositoryURL() string {\n\tfixture := fixtures.Basic().One()\n\treturn s.GetLocalRepositoryURL(fixture)\n}\n\nfunc (s *BaseSuite) GetLocalRepositoryURL(f *fixtures.Fixture) string {\n\treturn f.DotGit().Root()\n}\n\nfunc (s *BaseSuite) TemporalHomeDir() (path string, clean func()) {\n\thome, err := os.UserHomeDir()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tfs := osfs.New(home)\n\trelPath, err := util.TempDir(fs, \"\", \"\")\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tpath = fs.Join(fs.Root(), relPath)\n\tclean = func() {\n\t\t_ = util.RemoveAll(fs, relPath)\n\t}\n\n\treturn\n}\n\nfunc (s *BaseSuite) TemporalFilesystem(c *C) (fs billy.Filesystem) {\n\tfs = osfs.New(c.MkDir())\n\tpath, err := util.TempDir(fs, \"\", \"\")\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tfs, err = fs.Chroot(path)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\treturn\n}\n\ntype SuiteCommon struct{}\n\nvar _ = Suite(&SuiteCommon{})\n\nvar countLinesTests = [...]struct {\n\ti string // the string we want to count lines from\n\te int    // the expected number of lines in i\n}{\n\t{\"\", 0},\n\t{\"a\", 1},\n\t{\"a\\n\", 1},\n\t{\"a\\nb\", 2},\n\t{\"a\\nb\\n\", 2},\n\t{\"a\\nb\\nc\", 3},\n\t{\"a\\nb\\nc\\n\", 3},\n\t{\"a\\n\\n\\nb\\n\", 4},\n\t{\"first line\\n\\tsecond line\\nthird line\\n\", 3},\n}\n\nfunc (s *SuiteCommon) TestCountLines(c *C) {\n\tfor i, t := range countLinesTests {\n\t\to := countLines(t.i)\n\t\tc.Assert(o, Equals, t.e, Commentf(\"subtest %d, input=%q\", i, t.i))\n\t}\n}\n\nfunc AssertReferences(c *C, r *Repository, expected map[string]string) {\n\tfor name, target := range expected {\n\t\texpected := plumbing.NewReferenceFromStrings(name, target)\n\n\t\tobtained, err := r.Reference(expected.Name(), true)\n\t\tc.Assert(err, IsNil)\n\n\t\tc.Assert(obtained, DeepEquals, expected)\n\t}\n}\n\nfunc AssertReferencesMissing(c *C, r *Repository, expected []string) {\n\tfor _, name := range expected {\n\t\t_, err := r.Reference(plumbing.ReferenceName(name), false)\n\t\tc.Assert(err, NotNil)\n\t\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n\t}\n}\n\nfunc CommitNewFile(c *C, repo *Repository, fileName string) plumbing.Hash {\n\twt, err := repo.Worktree()\n\tc.Assert(err, IsNil)\n\n\tfd, err := wt.Filesystem.Create(fileName)\n\tc.Assert(err, IsNil)\n\n\t_, err = fd.Write([]byte(\"# test file\"))\n\tc.Assert(err, IsNil)\n\n\terr = fd.Close()\n\tc.Assert(err, IsNil)\n\n\t_, err = wt.Add(fileName)\n\tc.Assert(err, IsNil)\n\n\tsha, err := wt.Commit(\"test commit\", &CommitOptions{\n\t\tAuthor: &object.Signature{\n\t\t\tName:  \"test\",\n\t\t\tEmail: \"test@example.com\",\n\t\t\tWhen:  time.Now(),\n\t\t},\n\t\tCommitter: &object.Signature{\n\t\t\tName:  \"test\",\n\t\t\tEmail: \"test@example.com\",\n\t\t\tWhen:  time.Now(),\n\t\t},\n\t})\n\tc.Assert(err, IsNil)\n\n\treturn sha\n}\n"
        },
        {
          "name": "config",
          "type": "tree",
          "content": null
        },
        {
          "name": "doc.go",
          "type": "blob",
          "size": 0.46875,
          "content": "// A highly extensible git implementation in pure Go.\n//\n// go-git aims to reach the completeness of libgit2 or jgit, nowadays covers the\n// majority of the plumbing read operations and some of the main write\n// operations, but lacks the main porcelain operations such as merges.\n//\n// It is highly extensible, we have been following the open/close principle in\n// its design to facilitate extensions, mainly focusing the efforts on the\n// persistence of the objects.\npackage git\n"
        },
        {
          "name": "example_test.go",
          "type": "blob",
          "size": 4.1123046875,
          "content": "package git_test\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"os\"\n\t\"path/filepath\"\n\n\t\"github.com/go-git/go-git/v5\"\n\t\"github.com/go-git/go-git/v5/config\"\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/plumbing/transport/http\"\n\t\"github.com/go-git/go-git/v5/storage/memory\"\n\n\t\"github.com/go-git/go-billy/v5/memfs\"\n)\n\nfunc ExampleClone() {\n\t// Filesystem abstraction based on memory\n\tfs := memfs.New()\n\t// Git objects storer based on memory\n\tstorer := memory.NewStorage()\n\n\t// Clones the repository into the worktree (fs) and stores all the .git\n\t// content into the storer\n\t_, err := git.Clone(storer, fs, &git.CloneOptions{\n\t\tURL: \"https://github.com/git-fixtures/basic.git\",\n\t})\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Prints the content of the CHANGELOG file from the cloned repository\n\tchangelog, err := fs.Open(\"CHANGELOG\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tio.Copy(os.Stdout, changelog)\n\t// Output: Initial changelog\n}\n\nfunc ExamplePlainClone() {\n\t// Tempdir to clone the repository\n\tdir, err := os.MkdirTemp(\"\", \"clone-example\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tdefer os.RemoveAll(dir) // clean up\n\n\t// Clones the repository into the given dir, just as a normal git clone does\n\t_, err = git.PlainClone(dir, false, &git.CloneOptions{\n\t\tURL: \"https://github.com/git-fixtures/basic.git\",\n\t})\n\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Prints the content of the CHANGELOG file from the cloned repository\n\tchangelog, err := os.Open(filepath.Join(dir, \"CHANGELOG\"))\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tio.Copy(os.Stdout, changelog)\n\t// Output: Initial changelog\n}\n\nfunc ExamplePlainClone_usernamePassword() {\n\t// Tempdir to clone the repository\n\tdir, err := os.MkdirTemp(\"\", \"clone-example\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tdefer os.RemoveAll(dir) // clean up\n\n\t// Clones the repository into the given dir, just as a normal git clone does\n\t_, err = git.PlainClone(dir, false, &git.CloneOptions{\n\t\tURL: \"https://github.com/git-fixtures/basic.git\",\n\t\tAuth: &http.BasicAuth{\n\t\t\tUsername: \"username\",\n\t\t\tPassword: \"password\",\n\t\t},\n\t})\n\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\nfunc ExamplePlainClone_accessToken() {\n\t// Tempdir to clone the repository\n\tdir, err := os.MkdirTemp(\"\", \"clone-example\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tdefer os.RemoveAll(dir) // clean up\n\n\t// Clones the repository into the given dir, just as a normal git clone does\n\t_, err = git.PlainClone(dir, false, &git.CloneOptions{\n\t\tURL: \"https://github.com/git-fixtures/basic.git\",\n\t\tAuth: &http.BasicAuth{\n\t\t\tUsername: \"abc123\", // anything except an empty string\n\t\t\tPassword: \"github_access_token\",\n\t\t},\n\t})\n\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\nfunc ExampleRepository_References() {\n\tr, _ := git.Clone(memory.NewStorage(), nil, &git.CloneOptions{\n\t\tURL: \"https://github.com/git-fixtures/basic.git\",\n\t})\n\n\t// simulating a git show-ref\n\trefs, _ := r.References()\n\trefs.ForEach(func(ref *plumbing.Reference) error {\n\t\tif ref.Type() == plumbing.HashReference {\n\t\t\tfmt.Println(ref)\n\t\t}\n\n\t\treturn nil\n\t})\n\n\t// Example Output:\n\t// 6ecf0ef2c2dffb796033e5a02219af86ec6584e5 refs/remotes/origin/master\n\t// e8d3ffab552895c19b9fcf7aa264d277cde33881 refs/remotes/origin/branch\n\t// 6ecf0ef2c2dffb796033e5a02219af86ec6584e5 refs/heads/master\n\n}\n\nfunc ExampleRepository_Branches() {\n\tr, _ := git.Clone(memory.NewStorage(), nil, &git.CloneOptions{\n\t\tURL: \"https://github.com/git-fixtures/basic.git\",\n\t})\n\n\tbranches, _ := r.Branches()\n\tbranches.ForEach(func(branch *plumbing.Reference) error {\n\t\tfmt.Println(branch.Hash().String(), branch.Name())\n\t\treturn nil\n\t})\n\n\t// Example Output:\n\t// 6ecf0ef2c2dffb796033e5a02219af86ec6584e5 refs/heads/master\n}\n\nfunc ExampleRepository_CreateRemote() {\n\tr, _ := git.Init(memory.NewStorage(), nil)\n\n\t// Add a new remote, with the default fetch refspec\n\t_, err := r.CreateRemote(&config.RemoteConfig{\n\t\tName: \"example\",\n\t\tURLs: []string{\"https://github.com/git-fixtures/basic.git\"},\n\t})\n\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tlist, err := r.Remotes()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tfor _, r := range list {\n\t\tfmt.Println(r)\n\t}\n\n\t// Example Output:\n\t// example https://github.com/git-fixtures/basic.git (fetch)\n\t// example https://github.com/git-fixtures/basic.git (push)\n}\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 1.740234375,
          "content": "module github.com/go-git/go-git/v5\n\n// go-git supports the last 3 stable Go versions.\ngo 1.21\n\nrequire (\n\tdario.cat/mergo v1.0.0\n\tgithub.com/ProtonMail/go-crypto v1.1.4\n\tgithub.com/armon/go-socks5 v0.0.0-20160902184237-e75332964ef5\n\tgithub.com/elazarl/goproxy v1.2.3\n\tgithub.com/emirpasic/gods v1.18.1\n\tgithub.com/gliderlabs/ssh v0.3.8\n\tgithub.com/go-git/gcfg v1.5.1-0.20230307220236-3a3c6141e376\n\tgithub.com/go-git/go-billy/v5 v5.6.1\n\tgithub.com/go-git/go-git-fixtures/v4 v4.3.2-0.20231010084843-55a94097c399\n\tgithub.com/golang/groupcache v0.0.0-20210331224755-41bb18bfe9da\n\tgithub.com/google/go-cmp v0.6.0\n\tgithub.com/jbenet/go-context v0.0.0-20150711004518-d14ea06fba99\n\tgithub.com/kevinburke/ssh_config v1.2.0\n\tgithub.com/pjbgf/sha1cd v0.3.0\n\tgithub.com/sergi/go-diff v1.3.2-0.20230802210424-5b0b94c5c0d3\n\tgithub.com/skeema/knownhosts v1.3.0\n\tgithub.com/stretchr/testify v1.10.0\n\tgithub.com/xanzy/ssh-agent v0.3.3\n\tgolang.org/x/crypto v0.32.0\n\tgolang.org/x/net v0.34.0\n\tgolang.org/x/sys v0.29.0\n\tgolang.org/x/text v0.21.0\n\tgopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c\n)\n\nrequire (\n\tgithub.com/Microsoft/go-winio v0.6.1 // indirect\n\tgithub.com/anmitsu/go-shlex v0.0.0-20200514113438-38f4b401e2be // indirect\n\tgithub.com/cloudflare/circl v1.3.7 // indirect\n\tgithub.com/cyphar/filepath-securejoin v0.3.6 // indirect\n\tgithub.com/davecgh/go-spew v1.1.1 // indirect\n\tgithub.com/kr/pretty v0.3.1 // indirect\n\tgithub.com/kr/text v0.2.0 // indirect\n\tgithub.com/pmezard/go-difflib v1.0.0 // indirect\n\tgithub.com/rogpeppe/go-internal v1.12.0 // indirect\n\tgolang.org/x/mod v0.17.0 // indirect\n\tgolang.org/x/sync v0.10.0 // indirect\n\tgolang.org/x/tools v0.21.1-0.20240508182429-e35e4ccd0d2d // indirect\n\tgopkg.in/warnings.v0 v0.1.2 // indirect\n\tgopkg.in/yaml.v3 v3.0.1 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 9.8583984375,
          "content": "dario.cat/mergo v1.0.0 h1:AGCNq9Evsj31mOgNPcLyXc+4PNABt905YmuqPYYpBWk=\ndario.cat/mergo v1.0.0/go.mod h1:uNxQE+84aUszobStD9th8a29P2fMDhsBdgRYvZOxGmk=\ngithub.com/Microsoft/go-winio v0.5.2/go.mod h1:WpS1mjBmmwHBEWmogvA2mj8546UReBk4v8QkMxJ6pZY=\ngithub.com/Microsoft/go-winio v0.6.1 h1:9/kr64B9VUZrLm5YYwbGtUJnMgqWVOdUAXu6Migciow=\ngithub.com/Microsoft/go-winio v0.6.1/go.mod h1:LRdKpFKfdobln8UmuiYcKPot9D2v6svN5+sAH+4kjUM=\ngithub.com/ProtonMail/go-crypto v1.1.4 h1:G5U5asvD5N/6/36oIw3k2bOfBn5XVcZrb7PBjzzKKoE=\ngithub.com/ProtonMail/go-crypto v1.1.4/go.mod h1:rA3QumHc/FZ8pAHreoekgiAbzpNsfQAosU5td4SnOrE=\ngithub.com/anmitsu/go-shlex v0.0.0-20200514113438-38f4b401e2be h1:9AeTilPcZAjCFIImctFaOjnTIavg87rW78vTPkQqLI8=\ngithub.com/anmitsu/go-shlex v0.0.0-20200514113438-38f4b401e2be/go.mod h1:ySMOLuWl6zY27l47sB3qLNK6tF2fkHG55UZxx8oIVo4=\ngithub.com/armon/go-socks5 v0.0.0-20160902184237-e75332964ef5 h1:0CwZNZbxp69SHPdPJAN/hZIm0C4OItdklCFmMRWYpio=\ngithub.com/armon/go-socks5 v0.0.0-20160902184237-e75332964ef5/go.mod h1:wHh0iHkYZB8zMSxRWpUBQtwG5a7fFgvEO+odwuTv2gs=\ngithub.com/cloudflare/circl v1.3.7 h1:qlCDlTPz2n9fu58M0Nh1J/JzcFpfgkFHHX3O35r5vcU=\ngithub.com/cloudflare/circl v1.3.7/go.mod h1:sRTcRWXGLrKw6yIGJ+l7amYJFfAXbZG0kBSc8r4zxgA=\ngithub.com/creack/pty v1.1.9/go.mod h1:oKZEueFk5CKHvIhNR5MUki03XCEU+Q6VDXinZuGJ33E=\ngithub.com/cyphar/filepath-securejoin v0.3.6 h1:4d9N5ykBnSp5Xn2JkhocYDkOpURL/18CYMpo6xB9uWM=\ngithub.com/cyphar/filepath-securejoin v0.3.6/go.mod h1:Sdj7gXlvMcPZsbhwhQ33GguGLDGQL7h7bg04C/+u9jI=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/elazarl/goproxy v1.2.3 h1:xwIyKHbaP5yfT6O9KIeYJR5549MXRQkoQMRXGztz8YQ=\ngithub.com/elazarl/goproxy v1.2.3/go.mod h1:YfEbZtqP4AetfO6d40vWchF3znWX7C7Vd6ZMfdL8z64=\ngithub.com/emirpasic/gods v1.18.1 h1:FXtiHYKDGKCW2KzwZKx0iC0PQmdlorYgdFG9jPXJ1Bc=\ngithub.com/emirpasic/gods v1.18.1/go.mod h1:8tpGGwCnJ5H4r6BWwaV6OrWmMoPhUl5jm/FMNAnJvWQ=\ngithub.com/gliderlabs/ssh v0.3.8 h1:a4YXD1V7xMF9g5nTkdfnja3Sxy1PVDCj1Zg4Wb8vY6c=\ngithub.com/gliderlabs/ssh v0.3.8/go.mod h1:xYoytBv1sV0aL3CavoDuJIQNURXkkfPA/wxQ1pL1fAU=\ngithub.com/go-git/gcfg v1.5.1-0.20230307220236-3a3c6141e376 h1:+zs/tPmkDkHx3U66DAb0lQFJrpS6731Oaa12ikc+DiI=\ngithub.com/go-git/gcfg v1.5.1-0.20230307220236-3a3c6141e376/go.mod h1:an3vInlBmSxCcxctByoQdvwPiA7DTK7jaaFDBTtu0ic=\ngithub.com/go-git/go-billy/v5 v5.6.1 h1:u+dcrgaguSSkbjzHwelEjc0Yj300NUevrrPphk/SoRA=\ngithub.com/go-git/go-billy/v5 v5.6.1/go.mod h1:0AsLr1z2+Uksi4NlElmMblP5rPcDZNRCD8ujZCRR2BE=\ngithub.com/go-git/go-git-fixtures/v4 v4.3.2-0.20231010084843-55a94097c399 h1:eMje31YglSBqCdIqdhKBW8lokaMrL3uTkpGYlE2OOT4=\ngithub.com/go-git/go-git-fixtures/v4 v4.3.2-0.20231010084843-55a94097c399/go.mod h1:1OCfN199q1Jm3HZlxleg+Dw/mwps2Wbk9frAWm+4FII=\ngithub.com/golang/groupcache v0.0.0-20210331224755-41bb18bfe9da h1:oI5xCqsCo564l8iNU+DwB5epxmsaqB+rhGL0m5jtYqE=\ngithub.com/golang/groupcache v0.0.0-20210331224755-41bb18bfe9da/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=\ngithub.com/google/go-cmp v0.6.0 h1:ofyhxvXcZhMsU5ulbFiLKl/XBFqE1GSq7atu8tAmTRI=\ngithub.com/google/go-cmp v0.6.0/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/jbenet/go-context v0.0.0-20150711004518-d14ea06fba99 h1:BQSFePA1RWJOlocH6Fxy8MmwDt+yVQYULKfN0RoTN8A=\ngithub.com/jbenet/go-context v0.0.0-20150711004518-d14ea06fba99/go.mod h1:1lJo3i6rXxKeerYnT8Nvf0QmHCRC1n8sfWVwXF2Frvo=\ngithub.com/kevinburke/ssh_config v1.2.0 h1:x584FjTGwHzMwvHx18PXxbBVzfnxogHaAReU4gf13a4=\ngithub.com/kevinburke/ssh_config v1.2.0/go.mod h1:CT57kijsi8u/K/BOFA39wgDQJ9CxiF4nAY/ojJ6r6mM=\ngithub.com/kr/pretty v0.1.0/go.mod h1:dAy3ld7l9f0ibDNOQOHHMYYIIbhfbHSm3C4ZsoJORNo=\ngithub.com/kr/pretty v0.2.1/go.mod h1:ipq/a2n7PKx3OHsz4KJII5eveXtPO4qwEXGdVfWzfnI=\ngithub.com/kr/pretty v0.3.1 h1:flRD4NNwYAUpkphVc1HcthR4KEIFJ65n8Mw5qdRn3LE=\ngithub.com/kr/pretty v0.3.1/go.mod h1:hoEshYVHaxMs3cyo3Yncou5ZscifuDolrwPKZanG3xk=\ngithub.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=\ngithub.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=\ngithub.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=\ngithub.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=\ngithub.com/onsi/gomega v1.34.1 h1:EUMJIKUjM8sKjYbtxQI9A4z2o+rruxnzNvpknOXie6k=\ngithub.com/onsi/gomega v1.34.1/go.mod h1:kU1QgUvBDLXBJq618Xvm2LUX6rSAfRaFRTcdOeDLwwY=\ngithub.com/pjbgf/sha1cd v0.3.0 h1:4D5XXmUUBUl/xQ6IjCkEAbqXskkq/4O7LmGn0AqMDs4=\ngithub.com/pjbgf/sha1cd v0.3.0/go.mod h1:nZ1rrWOcGJ5uZgEEVL1VUM9iRQiZvWdbZjkKyFzPPsI=\ngithub.com/pkg/diff v0.0.0-20210226163009-20ebb0f2a09e/go.mod h1:pJLUxLENpZxwdsKMEsNbx1VGcRFpLqf3715MtcvvzbA=\ngithub.com/pkg/errors v0.9.1 h1:FEBLx1zS214owpjy7qsBeixbURkuhQAwrK5UwLGTwt4=\ngithub.com/pkg/errors v0.9.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/rogpeppe/go-internal v1.9.0/go.mod h1:WtVeX8xhTBvf0smdhujwtBcq4Qrzq/fJaraNFVN+nFs=\ngithub.com/rogpeppe/go-internal v1.12.0 h1:exVL4IDcn6na9z1rAb56Vxr+CgyK3nn3O+epU5NdKM8=\ngithub.com/rogpeppe/go-internal v1.12.0/go.mod h1:E+RYuTGaKKdloAfM02xzb0FW3Paa99yedzYV+kq4uf4=\ngithub.com/sergi/go-diff v1.3.2-0.20230802210424-5b0b94c5c0d3 h1:n661drycOFuPLCN3Uc8sB6B/s6Z4t2xvBgU1htSHuq8=\ngithub.com/sergi/go-diff v1.3.2-0.20230802210424-5b0b94c5c0d3/go.mod h1:A0bzQcvG0E7Rwjx0REVgAGH58e96+X0MeOfepqsbeW4=\ngithub.com/sirupsen/logrus v1.7.0/go.mod h1:yWOB1SBYBC5VeMP7gHvWumXLIWorT60ONWic61uBYv0=\ngithub.com/skeema/knownhosts v1.3.0 h1:AM+y0rI04VksttfwjkSTNQorvGqmwATnvnAHpSgc0LY=\ngithub.com/skeema/knownhosts v1.3.0/go.mod h1:sPINvnADmT/qYH1kfv+ePMmOBTH6Tbl7b5LvTDjFK7M=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/testify v1.2.2/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=\ngithub.com/stretchr/testify v1.4.0/go.mod h1:j7eGeouHqKxXV5pUuKE4zz7dFj8WfuZ+81PSLYec5m4=\ngithub.com/stretchr/testify v1.10.0 h1:Xv5erBjTwe/5IxqUQTdXv5kgmIvbHo3QQyRwhJsOfJA=\ngithub.com/stretchr/testify v1.10.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=\ngithub.com/xanzy/ssh-agent v0.3.3 h1:+/15pJfg/RsTxqYcX6fHqOXZwwMP+2VyYWJeWM2qQFM=\ngithub.com/xanzy/ssh-agent v0.3.3/go.mod h1:6dzNDKs0J9rVPHPhaGCukekBHKqfl+L3KghI1Bc68Uw=\ngolang.org/x/crypto v0.0.0-20220622213112-05595931fe9d/go.mod h1:IxCIyHEi3zRg3s0A5j5BB6A9Jmi73HwBIUl50j+osU4=\ngolang.org/x/crypto v0.32.0 h1:euUpcYgM8WcP71gNpTqQCn6rC2t6ULUPiOzfWaXVVfc=\ngolang.org/x/crypto v0.32.0/go.mod h1:ZnnJkOaASj8g0AjIduWNlq2NRxL0PlBrbKVyZ6V/Ugc=\ngolang.org/x/exp v0.0.0-20240719175910-8a7402abbf56 h1:2dVuKD2vS7b0QIHQbpyTISPd0LeHDbnYEryqj5Q1ug8=\ngolang.org/x/exp v0.0.0-20240719175910-8a7402abbf56/go.mod h1:M4RDyNAINzryxdtnbRXRL/OHtkFuWGRjvuhBJpk2IlY=\ngolang.org/x/mod v0.17.0 h1:zY54UmvipHiNd+pm+m0x9KhZ9hl1/7QNMyxXbc6ICqA=\ngolang.org/x/mod v0.17.0/go.mod h1:hTbmBsO62+eylJbnUtE2MGJUyE7QWk4xUqPFrRgJ+7c=\ngolang.org/x/net v0.0.0-20211112202133-69e39bad7dc2/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=\ngolang.org/x/net v0.34.0 h1:Mb7Mrk043xzHgnRM88suvJFwzVrRfHEHJEl5/71CKw0=\ngolang.org/x/net v0.34.0/go.mod h1:di0qlW3YNM5oh6GqDGQr92MyTozJPmybPK4Ev/Gm31k=\ngolang.org/x/sync v0.10.0 h1:3NQrjDixjgGwUOCaF8w2+VYHv0Ve/vGYSbdkTa98gmQ=\ngolang.org/x/sync v0.10.0/go.mod h1:Czt+wKu1gCyEFDUtn0jG5QVvpJ6rzVqr5aXyt9drQfk=\ngolang.org/x/sys v0.0.0-20191026070338-33540a1f6037/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210124154548-22da62e12c0c/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210423082822-04245dca01da/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210615035016-665e8c7367d1/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220715151400-c0bba94af5f8/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.29.0 h1:TPYlXGxvx1MGTn2GiZDhnjPA9wZzZeGKHHmKhHYvgaU=\ngolang.org/x/sys v0.29.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=\ngolang.org/x/term v0.28.0 h1:/Ts8HFuMR2E6IP/jlo7QVLZHggjKQbhu/7H0LJFr3Gg=\ngolang.org/x/term v0.28.0/go.mod h1:Sw/lC2IAUZ92udQNf3WodGtn4k/XoLyZoh8v/8uiwek=\ngolang.org/x/text v0.3.6/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.21.0 h1:zyQAAkrwaneQ066sspRyJaG9VNi/YJ1NfzcGB3hZ/qo=\ngolang.org/x/text v0.21.0/go.mod h1:4IBbMaMmOPCJ8SecivzSH54+73PCFmPWxNTLm+vZkEQ=\ngolang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.21.1-0.20240508182429-e35e4ccd0d2d h1:vU5i/LfpvrRCpgM/VPfJLg5KjxD3E+hfT1SH+d9zLwg=\ngolang.org/x/tools v0.21.1-0.20240508182429-e35e4ccd0d2d/go.mod h1:aiJjzUbINMkxbQROHiO6hDPo2LHcIPhhQsa9DLh0yGk=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20190902080502-41f04d3bba15/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c h1:Hei/4ADfdWqJk1ZMxUNpqntNwaWcugrBjAiHlqqRiVk=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c/go.mod h1:JHkPIbrfpd72SG/EVd6muEfDQjcINNoR0C8j2r3qZ4Q=\ngopkg.in/warnings.v0 v0.1.2 h1:wFXVbFY8DY5/xOe1ECiWdKCzZlxgshcYVNkBHstARME=\ngopkg.in/warnings.v0 v0.1.2/go.mod h1:jksf8JmL6Qr/oQM2OXTHunEvvTAsrWBLb6OOjuVWRNI=\ngopkg.in/yaml.v2 v2.2.2/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.4.0/go.mod h1:RDklbk79AGWmwhnvt/jBztapEOGDOx6ZbXqjP6csGnQ=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\n"
        },
        {
          "name": "internal",
          "type": "tree",
          "content": null
        },
        {
          "name": "object_walker.go",
          "type": "blob",
          "size": 2.7724609375,
          "content": "package git\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/plumbing/filemode\"\n\t\"github.com/go-git/go-git/v5/plumbing/object\"\n\t\"github.com/go-git/go-git/v5/storage\"\n)\n\ntype objectWalker struct {\n\tStorer storage.Storer\n\t// seen is the set of objects seen in the repo.\n\t// seen map can become huge if walking over large\n\t// repos. Thus using struct{} as the value type.\n\tseen map[plumbing.Hash]struct{}\n}\n\nfunc newObjectWalker(s storage.Storer) *objectWalker {\n\treturn &objectWalker{s, map[plumbing.Hash]struct{}{}}\n}\n\n// walkAllRefs walks all (hash) references from the repo.\nfunc (p *objectWalker) walkAllRefs() error {\n\t// Walk over all the references in the repo.\n\tit, err := p.Storer.IterReferences()\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer it.Close()\n\terr = it.ForEach(func(ref *plumbing.Reference) error {\n\t\t// Exit this iteration early for non-hash references.\n\t\tif ref.Type() != plumbing.HashReference {\n\t\t\treturn nil\n\t\t}\n\t\treturn p.walkObjectTree(ref.Hash())\n\t})\n\treturn err\n}\n\nfunc (p *objectWalker) isSeen(hash plumbing.Hash) bool {\n\t_, seen := p.seen[hash]\n\treturn seen\n}\n\nfunc (p *objectWalker) add(hash plumbing.Hash) {\n\tp.seen[hash] = struct{}{}\n}\n\n// walkObjectTree walks over all objects and remembers references\n// to them in the objectWalker. This is used instead of the revlist\n// walks because memory usage is tight with huge repos.\nfunc (p *objectWalker) walkObjectTree(hash plumbing.Hash) error {\n\t// Check if we have already seen, and mark this object\n\tif p.isSeen(hash) {\n\t\treturn nil\n\t}\n\tp.add(hash)\n\t// Fetch the object.\n\tobj, err := object.GetObject(p.Storer, hash)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"getting object %s failed: %v\", hash, err)\n\t}\n\t// Walk all children depending on object type.\n\tswitch obj := obj.(type) {\n\tcase *object.Commit:\n\t\terr = p.walkObjectTree(obj.TreeHash)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfor _, h := range obj.ParentHashes {\n\t\t\terr = p.walkObjectTree(h)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\tcase *object.Tree:\n\t\tfor i := range obj.Entries {\n\t\t\t// Shortcut for blob objects:\n\t\t\t// 'or' the lower bits of a mode and check that it\n\t\t\t// it matches a filemode.Executable. The type information\n\t\t\t// is in the higher bits, but this is the cleanest way\n\t\t\t// to handle plain files with different modes.\n\t\t\t// Other non-tree objects are somewhat rare, so they\n\t\t\t// are not special-cased.\n\t\t\tif obj.Entries[i].Mode|0755 == filemode.Executable {\n\t\t\t\tp.add(obj.Entries[i].Hash)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\t// Normal walk for sub-trees (and symlinks etc).\n\t\t\terr = p.walkObjectTree(obj.Entries[i].Hash)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\tcase *object.Tag:\n\t\treturn p.walkObjectTree(obj.Target)\n\tdefault:\n\t\t// Error out on unhandled object types.\n\t\treturn fmt.Errorf(\"unknown object %X %s %T\", obj.ID(), obj.Type(), obj)\n\t}\n\treturn nil\n}\n"
        },
        {
          "name": "options.go",
          "type": "blob",
          "size": 26.7568359375,
          "content": "package git\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"regexp\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/ProtonMail/go-crypto/openpgp\"\n\t\"github.com/go-git/go-git/v5/config\"\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\tformatcfg \"github.com/go-git/go-git/v5/plumbing/format/config\"\n\t\"github.com/go-git/go-git/v5/plumbing/object\"\n\t\"github.com/go-git/go-git/v5/plumbing/protocol/packp/sideband\"\n\t\"github.com/go-git/go-git/v5/plumbing/transport\"\n)\n\n// SubmoduleRescursivity defines how depth will affect any submodule recursive\n// operation.\ntype SubmoduleRescursivity uint\n\nconst (\n\t// DefaultRemoteName name of the default Remote, just like git command.\n\tDefaultRemoteName = \"origin\"\n\n\t// NoRecurseSubmodules disables the recursion for a submodule operation.\n\tNoRecurseSubmodules SubmoduleRescursivity = 0\n\t// DefaultSubmoduleRecursionDepth allow recursion in a submodule operation.\n\tDefaultSubmoduleRecursionDepth SubmoduleRescursivity = 10\n)\n\nvar (\n\tErrMissingURL = errors.New(\"URL field is required\")\n)\n\n// CloneOptions describes how a clone should be performed.\ntype CloneOptions struct {\n\t// The (possibly remote) repository URL to clone from.\n\tURL string\n\t// Auth credentials, if required, to use with the remote repository.\n\tAuth transport.AuthMethod\n\t// Name of the remote to be added, by default `origin`.\n\tRemoteName string\n\t// Remote branch to clone.\n\tReferenceName plumbing.ReferenceName\n\t// Fetch only ReferenceName if true.\n\tSingleBranch bool\n\t// Mirror clones the repository as a mirror.\n\t//\n\t// Compared to a bare clone, mirror not only maps local branches of the\n\t// source to local branches of the target, it maps all refs (including\n\t// remote-tracking branches, notes etc.) and sets up a refspec configuration\n\t// such that all these refs are overwritten by a git remote update in the\n\t// target repository.\n\tMirror bool\n\t// No checkout of HEAD after clone if true.\n\tNoCheckout bool\n\t// Limit fetching to the specified number of commits.\n\tDepth int\n\t// RecurseSubmodules after the clone is created, initialize all submodules\n\t// within, using their default settings. This option is ignored if the\n\t// cloned repository does not have a worktree.\n\tRecurseSubmodules SubmoduleRescursivity\n\t// ShallowSubmodules limit cloning submodules to the 1 level of depth.\n\t// It matches the git command --shallow-submodules.\n\tShallowSubmodules bool\n\t// Progress is where the human readable information sent by the server is\n\t// stored, if nil nothing is stored and the capability (if supported)\n\t// no-progress, is sent to the server to avoid send this information.\n\tProgress sideband.Progress\n\t// Tags describe how the tags will be fetched from the remote repository,\n\t// by default is AllTags.\n\tTags TagMode\n\t// InsecureSkipTLS skips ssl verify if protocol is https\n\tInsecureSkipTLS bool\n\t// CABundle specify additional ca bundle with system cert pool\n\tCABundle []byte\n\t// ProxyOptions provides info required for connecting to a proxy.\n\tProxyOptions transport.ProxyOptions\n\t// When the repository to clone is on the local machine, instead of\n\t// using hard links, automatically setup .git/objects/info/alternates\n\t// to share the objects with the source repository.\n\t// The resulting repository starts out without any object of its own.\n\t// NOTE: this is a possibly dangerous operation; do not use it unless\n\t// you understand what it does.\n\t//\n\t// [Reference]: https://git-scm.com/docs/git-clone#Documentation/git-clone.txt---shared\n\tShared bool\n}\n\n// MergeOptions describes how a merge should be performed.\ntype MergeOptions struct {\n\t// Strategy defines the merge strategy to be used.\n\tStrategy MergeStrategy\n}\n\n// MergeStrategy represents the different types of merge strategies.\ntype MergeStrategy int8\n\nconst (\n\t// FastForwardMerge represents a Git merge strategy where the current\n\t// branch can be simply updated to point to the HEAD of the branch being\n\t// merged. This is only possible if the history of the branch being merged\n\t// is a linear descendant of the current branch, with no conflicting commits.\n\t//\n\t// This is the default option.\n\tFastForwardMerge MergeStrategy = iota\n)\n\n// Validate validates the fields and sets the default values.\nfunc (o *CloneOptions) Validate() error {\n\tif o.URL == \"\" {\n\t\treturn ErrMissingURL\n\t}\n\n\tif o.RemoteName == \"\" {\n\t\to.RemoteName = DefaultRemoteName\n\t}\n\n\tif o.ReferenceName == \"\" {\n\t\to.ReferenceName = plumbing.HEAD\n\t}\n\n\tif o.Tags == InvalidTagMode {\n\t\to.Tags = AllTags\n\t}\n\n\treturn nil\n}\n\n// PullOptions describes how a pull should be performed.\ntype PullOptions struct {\n\t// Name of the remote to be pulled. If empty, uses the default.\n\tRemoteName string\n\t// RemoteURL overrides the remote repo address with a custom URL\n\tRemoteURL string\n\t// Remote branch to clone. If empty, uses HEAD.\n\tReferenceName plumbing.ReferenceName\n\t// Fetch only ReferenceName if true.\n\tSingleBranch bool\n\t// Limit fetching to the specified number of commits.\n\tDepth int\n\t// Auth credentials, if required, to use with the remote repository.\n\tAuth transport.AuthMethod\n\t// RecurseSubmodules controls if new commits of all populated submodules\n\t// should be fetched too.\n\tRecurseSubmodules SubmoduleRescursivity\n\t// Progress is where the human readable information sent by the server is\n\t// stored, if nil nothing is stored and the capability (if supported)\n\t// no-progress, is sent to the server to avoid send this information.\n\tProgress sideband.Progress\n\t// Force allows the pull to update a local branch even when the remote\n\t// branch does not descend from it.\n\tForce bool\n\t// InsecureSkipTLS skips ssl verify if protocol is https\n\tInsecureSkipTLS bool\n\t// CABundle specify additional ca bundle with system cert pool\n\tCABundle []byte\n\t// ProxyOptions provides info required for connecting to a proxy.\n\tProxyOptions transport.ProxyOptions\n}\n\n// Validate validates the fields and sets the default values.\nfunc (o *PullOptions) Validate() error {\n\tif o.RemoteName == \"\" {\n\t\to.RemoteName = DefaultRemoteName\n\t}\n\n\tif o.ReferenceName == \"\" {\n\t\to.ReferenceName = plumbing.HEAD\n\t}\n\n\treturn nil\n}\n\ntype TagMode int\n\nconst (\n\tInvalidTagMode TagMode = iota\n\t// TagFollowing any tag that points into the histories being fetched is also\n\t// fetched. TagFollowing requires a server with `include-tag` capability\n\t// in order to fetch the annotated tags objects.\n\tTagFollowing\n\t// AllTags fetch all tags from the remote (i.e., fetch remote tags\n\t// refs/tags/* into local tags with the same name)\n\tAllTags\n\t// NoTags fetch no tags from the remote at all\n\tNoTags\n)\n\n// FetchOptions describes how a fetch should be performed\ntype FetchOptions struct {\n\t// Name of the remote to fetch from. Defaults to origin.\n\tRemoteName string\n\t// RemoteURL overrides the remote repo address with a custom URL\n\tRemoteURL string\n\tRefSpecs  []config.RefSpec\n\t// Depth limit fetching to the specified number of commits from the tip of\n\t// each remote branch history.\n\tDepth int\n\t// Auth credentials, if required, to use with the remote repository.\n\tAuth transport.AuthMethod\n\t// Progress is where the human readable information sent by the server is\n\t// stored, if nil nothing is stored and the capability (if supported)\n\t// no-progress, is sent to the server to avoid send this information.\n\tProgress sideband.Progress\n\t// Tags describe how the tags will be fetched from the remote repository,\n\t// by default is TagFollowing.\n\tTags TagMode\n\t// Force allows the fetch to update a local branch even when the remote\n\t// branch does not descend from it.\n\tForce bool\n\t// InsecureSkipTLS skips ssl verify if protocol is https\n\tInsecureSkipTLS bool\n\t// CABundle specify additional ca bundle with system cert pool\n\tCABundle []byte\n\t// ProxyOptions provides info required for connecting to a proxy.\n\tProxyOptions transport.ProxyOptions\n\t// Prune specify that local refs that match given RefSpecs and that do\n\t// not exist remotely will be removed.\n\tPrune bool\n}\n\n// Validate validates the fields and sets the default values.\nfunc (o *FetchOptions) Validate() error {\n\tif o.RemoteName == \"\" {\n\t\to.RemoteName = DefaultRemoteName\n\t}\n\n\tif o.Tags == InvalidTagMode {\n\t\to.Tags = TagFollowing\n\t}\n\n\tfor _, r := range o.RefSpecs {\n\t\tif err := r.Validate(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// PushOptions describes how a push should be performed.\ntype PushOptions struct {\n\t// RemoteName is the name of the remote to be pushed to.\n\tRemoteName string\n\t// RemoteURL overrides the remote repo address with a custom URL\n\tRemoteURL string\n\t// RefSpecs specify what destination ref to update with what source object.\n\t//\n\t// The format of a <refspec> parameter is an optional plus +, followed by\n\t//  the source object <src>, followed by a colon :, followed by the destination ref <dst>.\n\t// The <src> is often the name of the branch you would want to push, but it can be a SHA-1.\n\t// The <dst> tells which ref on the remote side is updated with this push.\n\t//\n\t// A refspec with empty src can be used to delete a reference.\n\tRefSpecs []config.RefSpec\n\t// Auth credentials, if required, to use with the remote repository.\n\tAuth transport.AuthMethod\n\t// Progress is where the human readable information sent by the server is\n\t// stored, if nil nothing is stored.\n\tProgress sideband.Progress\n\t// Prune specify that remote refs that match given RefSpecs and that do\n\t// not exist locally will be removed.\n\tPrune bool\n\t// Force allows the push to update a remote branch even when the local\n\t// branch does not descend from it.\n\tForce bool\n\t// InsecureSkipTLS skips ssl verify if protocol is https\n\tInsecureSkipTLS bool\n\t// CABundle specify additional ca bundle with system cert pool\n\tCABundle []byte\n\t// RequireRemoteRefs only allows a remote ref to be updated if its current\n\t// value is the one specified here.\n\tRequireRemoteRefs []config.RefSpec\n\t// FollowTags will send any annotated tags with a commit target reachable from\n\t// the refs already being pushed\n\tFollowTags bool\n\t// ForceWithLease allows a force push as long as the remote ref adheres to a \"lease\"\n\tForceWithLease *ForceWithLease\n\t// PushOptions sets options to be transferred to the server during push.\n\tOptions map[string]string\n\t// Atomic sets option to be an atomic push\n\tAtomic bool\n\t// ProxyOptions provides info required for connecting to a proxy.\n\tProxyOptions transport.ProxyOptions\n}\n\n// ForceWithLease sets fields on the lease\n// If neither RefName nor Hash are set, ForceWithLease protects\n// all refs in the refspec by ensuring the ref of the remote in the local repsitory\n// matches the one in the ref advertisement.\ntype ForceWithLease struct {\n\t// RefName, when set will protect the ref by ensuring it matches the\n\t// hash in the ref advertisement.\n\tRefName plumbing.ReferenceName\n\t// Hash is the expected object id of RefName. The push will be rejected unless this\n\t// matches the corresponding object id of RefName in the refs advertisement.\n\tHash plumbing.Hash\n}\n\n// Validate validates the fields and sets the default values.\nfunc (o *PushOptions) Validate() error {\n\tif o.RemoteName == \"\" {\n\t\to.RemoteName = DefaultRemoteName\n\t}\n\n\tif len(o.RefSpecs) == 0 {\n\t\to.RefSpecs = []config.RefSpec{\n\t\t\tconfig.RefSpec(config.DefaultPushRefSpec),\n\t\t}\n\t}\n\n\tfor _, r := range o.RefSpecs {\n\t\tif err := r.Validate(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// SubmoduleUpdateOptions describes how a submodule update should be performed.\ntype SubmoduleUpdateOptions struct {\n\t// Init, if true initializes the submodules recorded in the index.\n\tInit bool\n\t// NoFetch tell to the update command to not fetch new objects from the\n\t// remote site.\n\tNoFetch bool\n\t// RecurseSubmodules the update is performed not only in the submodules of\n\t// the current repository but also in any nested submodules inside those\n\t// submodules (and so on). Until the SubmoduleRescursivity is reached.\n\tRecurseSubmodules SubmoduleRescursivity\n\t// Auth credentials, if required, to use with the remote repository.\n\tAuth transport.AuthMethod\n\t// Depth limit fetching to the specified number of commits from the tip of\n\t// each remote branch history.\n\tDepth int\n}\n\nvar (\n\tErrBranchHashExclusive  = errors.New(\"Branch and Hash are mutually exclusive\")\n\tErrCreateRequiresBranch = errors.New(\"Branch is mandatory when Create is used\")\n)\n\n// CheckoutOptions describes how a checkout operation should be performed.\ntype CheckoutOptions struct {\n\t// Hash is the hash of a commit or tag to be checked out. If used, HEAD\n\t// will be in detached mode. If Create is not used, Branch and Hash are\n\t// mutually exclusive.\n\tHash plumbing.Hash\n\t// Branch to be checked out, if Branch and Hash are empty is set to `master`.\n\tBranch plumbing.ReferenceName\n\t// Create a new branch named Branch and start it at Hash.\n\tCreate bool\n\t// Force, if true when switching branches, proceed even if the index or the\n\t// working tree differs from HEAD. This is used to throw away local changes\n\tForce bool\n\t// Keep, if true when switching branches, local changes (the index or the\n\t// working tree changes) will be kept so that they can be committed to the\n\t// target branch. Force and Keep are mutually exclusive, should not be both\n\t// set to true.\n\tKeep bool\n\t// SparseCheckoutDirectories\n\tSparseCheckoutDirectories []string\n}\n\n// Validate validates the fields and sets the default values.\nfunc (o *CheckoutOptions) Validate() error {\n\tif !o.Create && !o.Hash.IsZero() && o.Branch != \"\" {\n\t\treturn ErrBranchHashExclusive\n\t}\n\n\tif o.Create && o.Branch == \"\" {\n\t\treturn ErrCreateRequiresBranch\n\t}\n\n\tif o.Branch == \"\" {\n\t\to.Branch = plumbing.Master\n\t}\n\n\treturn nil\n}\n\n// ResetMode defines the mode of a reset operation.\ntype ResetMode int8\n\nconst (\n\t// MixedReset resets the index but not the working tree (i.e., the changed\n\t// files are preserved but not marked for commit) and reports what has not\n\t// been updated. This is the default action.\n\tMixedReset ResetMode = iota\n\t// HardReset resets the index and working tree. Any changes to tracked files\n\t// in the working tree are discarded.\n\tHardReset\n\t// MergeReset resets the index and updates the files in the working tree\n\t// that are different between Commit and HEAD, but keeps those which are\n\t// different between the index and working tree (i.e. which have changes\n\t// which have not been added).\n\t//\n\t// If a file that is different between Commit and the index has unstaged\n\t// changes, reset is aborted.\n\tMergeReset\n\t// SoftReset does not touch the index file or the working tree at all (but\n\t// resets the head to <commit>, just like all modes do). This leaves all\n\t// your changed files \"Changes to be committed\", as git status would put it.\n\tSoftReset\n)\n\n// ResetOptions describes how a reset operation should be performed.\ntype ResetOptions struct {\n\t// Commit, if commit is present set the current branch head (HEAD) to it.\n\tCommit plumbing.Hash\n\t// Mode, form resets the current branch head to Commit and possibly updates\n\t// the index (resetting it to the tree of Commit) and the working tree\n\t// depending on Mode. If empty MixedReset is used.\n\tMode ResetMode\n\t// Files, if not empty will constrain the reseting the index to only files\n\t// specified in this list.\n\tFiles []string\n}\n\n// Validate validates the fields and sets the default values.\nfunc (o *ResetOptions) Validate(r *Repository) error {\n\tif o.Commit == plumbing.ZeroHash {\n\t\tref, err := r.Head()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\to.Commit = ref.Hash()\n\t} else {\n\t\t_, err := r.CommitObject(o.Commit)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"invalid reset option: %w\", err)\n\t\t}\n\t}\n\n\treturn nil\n}\n\ntype LogOrder int8\n\nconst (\n\tLogOrderDefault LogOrder = iota\n\tLogOrderDFS\n\tLogOrderDFSPost\n\tLogOrderBSF\n\tLogOrderCommitterTime\n)\n\n// LogOptions describes how a log action should be performed.\ntype LogOptions struct {\n\t// When the From option is set the log will only contain commits\n\t// reachable from it. If this option is not set, HEAD will be used as\n\t// the default From.\n\tFrom plumbing.Hash\n\n\t// The default traversal algorithm is Depth-first search\n\t// set Order=LogOrderCommitterTime for ordering by committer time (more compatible with `git log`)\n\t// set Order=LogOrderBSF for Breadth-first search\n\tOrder LogOrder\n\n\t// Show only those commits in which the specified file was inserted/updated.\n\t// It is equivalent to running `git log -- <file-name>`.\n\t// this field is kept for compatibility, it can be replaced with PathFilter\n\tFileName *string\n\n\t// Filter commits based on the path of files that are updated\n\t// takes file path as argument and should return true if the file is desired\n\t// It can be used to implement `git log -- <path>`\n\t// either <path> is a file path, or directory path, or a regexp of file/directory path\n\tPathFilter func(string) bool\n\n\t// Pretend as if all the refs in refs/, along with HEAD, are listed on the command line as <commit>.\n\t// It is equivalent to running `git log --all`.\n\t// If set on true, the From option will be ignored.\n\tAll bool\n\n\t// Show commits more recent than a specific date.\n\t// It is equivalent to running `git log --since <date>` or `git log --after <date>`.\n\tSince *time.Time\n\n\t// Show commits older than a specific date.\n\t// It is equivalent to running `git log --until <date>` or `git log --before <date>`.\n\tUntil *time.Time\n}\n\nvar (\n\tErrMissingAuthor = errors.New(\"author field is required\")\n)\n\n// AddOptions describes how an `add` operation should be performed\ntype AddOptions struct {\n\t// All equivalent to `git add -A`, update the index not only where the\n\t// working tree has a file matching `Path` but also where the index already\n\t// has an entry. This adds, modifies, and removes index entries to match the\n\t// working tree.  If no `Path` nor `Glob` is given when `All` option is\n\t// used, all files in the entire working tree are updated.\n\tAll bool\n\t// Path is the exact filepath to the file or directory to be added.\n\tPath string\n\t// Glob adds all paths, matching pattern, to the index. If pattern matches a\n\t// directory path, all directory contents are added to the index recursively.\n\tGlob string\n\t// SkipStatus adds the path with no status check. This option is relevant only\n\t// when the `Path` option is specified and does not apply when the `All` option is used.\n\t// Notice that when passing an ignored path it will be added anyway.\n\t// When true it can speed up adding files to the worktree in very large repositories.\n\tSkipStatus bool\n}\n\n// Validate validates the fields and sets the default values.\nfunc (o *AddOptions) Validate(r *Repository) error {\n\tif o.Path != \"\" && o.Glob != \"\" {\n\t\treturn fmt.Errorf(\"fields Path and Glob are mutual exclusive\")\n\t}\n\n\treturn nil\n}\n\n// CommitOptions describes how a commit operation should be performed.\ntype CommitOptions struct {\n\t// All automatically stage files that have been modified and deleted, but\n\t// new files you have not told Git about are not affected.\n\tAll bool\n\t// AllowEmptyCommits enable empty commits to be created. An empty commit\n\t// is when no changes to the tree were made, but a new commit message is\n\t// provided. The default behavior is false, which results in ErrEmptyCommit.\n\tAllowEmptyCommits bool\n\t// Author is the author's signature of the commit. If Author is empty the\n\t// Name and Email is read from the config, and time.Now it's used as When.\n\tAuthor *object.Signature\n\t// Committer is the committer's signature of the commit. If Committer is\n\t// nil the Author signature is used.\n\tCommitter *object.Signature\n\t// Parents are the parents commits for the new commit, by default when\n\t// len(Parents) is zero, the hash of HEAD reference is used.\n\tParents []plumbing.Hash\n\t// SignKey denotes a key to sign the commit with. A nil value here means the\n\t// commit will not be signed. The private key must be present and already\n\t// decrypted.\n\tSignKey *openpgp.Entity\n\t// Signer denotes a cryptographic signer to sign the commit with.\n\t// A nil value here means the commit will not be signed.\n\t// Takes precedence over SignKey.\n\tSigner Signer\n\t// Amend will create a new commit object and replace the commit that HEAD currently\n\t// points to. Cannot be used with All nor Parents.\n\tAmend bool\n}\n\n// Validate validates the fields and sets the default values.\nfunc (o *CommitOptions) Validate(r *Repository) error {\n\tif o.All && o.Amend {\n\t\treturn errors.New(\"all and amend cannot be used together\")\n\t}\n\n\tif o.Amend && len(o.Parents) > 0 {\n\t\treturn errors.New(\"parents cannot be used with amend\")\n\t}\n\n\tif o.Author == nil {\n\t\tif err := o.loadConfigAuthorAndCommitter(r); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif o.Committer == nil {\n\t\to.Committer = o.Author\n\t}\n\n\tif len(o.Parents) == 0 {\n\t\thead, err := r.Head()\n\t\tif err != nil && err != plumbing.ErrReferenceNotFound {\n\t\t\treturn err\n\t\t}\n\n\t\tif head != nil {\n\t\t\to.Parents = []plumbing.Hash{head.Hash()}\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (o *CommitOptions) loadConfigAuthorAndCommitter(r *Repository) error {\n\tcfg, err := r.ConfigScoped(config.SystemScope)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif o.Author == nil && cfg.Author.Email != \"\" && cfg.Author.Name != \"\" {\n\t\to.Author = &object.Signature{\n\t\t\tName:  cfg.Author.Name,\n\t\t\tEmail: cfg.Author.Email,\n\t\t\tWhen:  time.Now(),\n\t\t}\n\t}\n\n\tif o.Committer == nil && cfg.Committer.Email != \"\" && cfg.Committer.Name != \"\" {\n\t\to.Committer = &object.Signature{\n\t\t\tName:  cfg.Committer.Name,\n\t\t\tEmail: cfg.Committer.Email,\n\t\t\tWhen:  time.Now(),\n\t\t}\n\t}\n\n\tif o.Author == nil && cfg.User.Email != \"\" && cfg.User.Name != \"\" {\n\t\to.Author = &object.Signature{\n\t\t\tName:  cfg.User.Name,\n\t\t\tEmail: cfg.User.Email,\n\t\t\tWhen:  time.Now(),\n\t\t}\n\t}\n\n\tif o.Author == nil {\n\t\treturn ErrMissingAuthor\n\t}\n\n\treturn nil\n}\n\nvar (\n\tErrMissingName    = errors.New(\"name field is required\")\n\tErrMissingTagger  = errors.New(\"tagger field is required\")\n\tErrMissingMessage = errors.New(\"message field is required\")\n)\n\n// CreateTagOptions describes how a tag object should be created.\ntype CreateTagOptions struct {\n\t// Tagger defines the signature of the tag creator. If Tagger is empty the\n\t// Name and Email is read from the config, and time.Now it's used as When.\n\tTagger *object.Signature\n\t// Message defines the annotation of the tag. It is canonicalized during\n\t// validation into the format expected by git - no leading whitespace and\n\t// ending in a newline.\n\tMessage string\n\t// SignKey denotes a key to sign the tag with. A nil value here means the tag\n\t// will not be signed. The private key must be present and already decrypted.\n\tSignKey *openpgp.Entity\n}\n\n// Validate validates the fields and sets the default values.\nfunc (o *CreateTagOptions) Validate(r *Repository, hash plumbing.Hash) error {\n\tif o.Tagger == nil {\n\t\tif err := o.loadConfigTagger(r); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif o.Message == \"\" {\n\t\treturn ErrMissingMessage\n\t}\n\n\t// Canonicalize the message into the expected message format.\n\to.Message = strings.TrimSpace(o.Message) + \"\\n\"\n\n\treturn nil\n}\n\nfunc (o *CreateTagOptions) loadConfigTagger(r *Repository) error {\n\tcfg, err := r.ConfigScoped(config.SystemScope)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif o.Tagger == nil && cfg.Author.Email != \"\" && cfg.Author.Name != \"\" {\n\t\to.Tagger = &object.Signature{\n\t\t\tName:  cfg.Author.Name,\n\t\t\tEmail: cfg.Author.Email,\n\t\t\tWhen:  time.Now(),\n\t\t}\n\t}\n\n\tif o.Tagger == nil && cfg.User.Email != \"\" && cfg.User.Name != \"\" {\n\t\to.Tagger = &object.Signature{\n\t\t\tName:  cfg.User.Name,\n\t\t\tEmail: cfg.User.Email,\n\t\t\tWhen:  time.Now(),\n\t\t}\n\t}\n\n\tif o.Tagger == nil {\n\t\treturn ErrMissingTagger\n\t}\n\n\treturn nil\n}\n\n// ListOptions describes how a remote list should be performed.\ntype ListOptions struct {\n\t// Auth credentials, if required, to use with the remote repository.\n\tAuth transport.AuthMethod\n\t// InsecureSkipTLS skips ssl verify if protocol is https\n\tInsecureSkipTLS bool\n\t// CABundle specify additional ca bundle with system cert pool\n\tCABundle []byte\n\t// PeelingOption defines how peeled objects are handled during a\n\t// remote list.\n\tPeelingOption PeelingOption\n\t// ProxyOptions provides info required for connecting to a proxy.\n\tProxyOptions transport.ProxyOptions\n\t// Timeout specifies the timeout in seconds for list operations\n\tTimeout int\n}\n\n// PeelingOption represents the different ways to handle peeled references.\n//\n// Peeled references represent the underlying object of an annotated\n// (or signed) tag. Refer to upstream documentation for more info:\n// https://github.com/git/git/blob/master/Documentation/technical/reftable.txt\ntype PeelingOption uint8\n\nconst (\n\t// IgnorePeeled ignores all peeled reference names. This is the default behavior.\n\tIgnorePeeled PeelingOption = 0\n\t// OnlyPeeled returns only peeled reference names.\n\tOnlyPeeled PeelingOption = 1\n\t// AppendPeeled appends peeled reference names to the reference list.\n\tAppendPeeled PeelingOption = 2\n)\n\n// CleanOptions describes how a clean should be performed.\ntype CleanOptions struct {\n\tDir bool\n}\n\n// GrepOptions describes how a grep should be performed.\ntype GrepOptions struct {\n\t// Patterns are compiled Regexp objects to be matched.\n\tPatterns []*regexp.Regexp\n\t// InvertMatch selects non-matching lines.\n\tInvertMatch bool\n\t// CommitHash is the hash of the commit from which worktree should be derived.\n\tCommitHash plumbing.Hash\n\t// ReferenceName is the branch or tag name from which worktree should be derived.\n\tReferenceName plumbing.ReferenceName\n\t// PathSpecs are compiled Regexp objects of pathspec to use in the matching.\n\tPathSpecs []*regexp.Regexp\n}\n\nvar (\n\tErrHashOrReference = errors.New(\"ambiguous options, only one of CommitHash or ReferenceName can be passed\")\n)\n\n// Validate validates the fields and sets the default values.\n//\n// TODO: deprecate in favor of Validate(r *Repository) in v6.\nfunc (o *GrepOptions) Validate(w *Worktree) error {\n\treturn o.validate(w.r)\n}\n\nfunc (o *GrepOptions) validate(r *Repository) error {\n\tif !o.CommitHash.IsZero() && o.ReferenceName != \"\" {\n\t\treturn ErrHashOrReference\n\t}\n\n\t// If none of CommitHash and ReferenceName are provided, set commit hash of\n\t// the repository's head.\n\tif o.CommitHash.IsZero() && o.ReferenceName == \"\" {\n\t\tref, err := r.Head()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\to.CommitHash = ref.Hash()\n\t}\n\n\treturn nil\n}\n\n// PlainOpenOptions describes how opening a plain repository should be\n// performed.\ntype PlainOpenOptions struct {\n\t// DetectDotGit defines whether parent directories should be\n\t// walked until a .git directory or file is found.\n\tDetectDotGit bool\n\t// Enable .git/commondir support (see https://git-scm.com/docs/gitrepository-layout#Documentation/gitrepository-layout.txt).\n\t// NOTE: This option will only work with the filesystem storage.\n\tEnableDotGitCommonDir bool\n}\n\n// Validate validates the fields and sets the default values.\nfunc (o *PlainOpenOptions) Validate() error { return nil }\n\ntype PlainInitOptions struct {\n\tInitOptions\n\t// Determines if the repository will have a worktree (non-bare) or not (bare).\n\tBare         bool\n\tObjectFormat formatcfg.ObjectFormat\n}\n\n// Validate validates the fields and sets the default values.\nfunc (o *PlainInitOptions) Validate() error { return nil }\n\nvar (\n\tErrNoRestorePaths = errors.New(\"you must specify path(s) to restore\")\n)\n\n// RestoreOptions describes how a restore should be performed.\ntype RestoreOptions struct {\n\t// Marks to restore the content in the index\n\tStaged bool\n\t// Marks to restore the content of the working tree\n\tWorktree bool\n\t// List of file paths that will be restored\n\tFiles []string\n}\n\n// Validate validates the fields and sets the default values.\nfunc (o *RestoreOptions) Validate() error {\n\tif len(o.Files) == 0 {\n\t\treturn ErrNoRestorePaths\n\t}\n\n\treturn nil\n}\n"
        },
        {
          "name": "options_test.go",
          "type": "blob",
          "size": 2.8046875,
          "content": "package git\n\nimport (\n\t\"os\"\n\n\t\"github.com/go-git/go-billy/v5/util\"\n\t\"github.com/go-git/go-git/v5/config\"\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/plumbing/object\"\n\t. \"gopkg.in/check.v1\"\n)\n\ntype OptionsSuite struct {\n\tBaseSuite\n}\n\nvar _ = Suite(&OptionsSuite{})\n\nfunc (s *OptionsSuite) TestCommitOptionsParentsFromHEAD(c *C) {\n\to := CommitOptions{Author: &object.Signature{}}\n\terr := o.Validate(s.Repository)\n\tc.Assert(err, IsNil)\n\tc.Assert(o.Parents, HasLen, 1)\n}\n\nfunc (s *OptionsSuite) TestResetOptionsCommitNotFound(c *C) {\n\to := ResetOptions{Commit: plumbing.NewHash(\"ab1b15c6f6487b4db16f10d8ec69bb8bf91dcabd\")}\n\terr := o.Validate(s.Repository)\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *OptionsSuite) TestCommitOptionsCommitter(c *C) {\n\tsig := &object.Signature{}\n\n\to := CommitOptions{Author: sig}\n\terr := o.Validate(s.Repository)\n\tc.Assert(err, IsNil)\n\n\tc.Assert(o.Committer, Equals, o.Author)\n}\n\nfunc (s *OptionsSuite) TestCommitOptionsLoadGlobalConfigUser(c *C) {\n\tcfg := config.NewConfig()\n\tcfg.User.Name = \"foo\"\n\tcfg.User.Email = \"foo@foo.com\"\n\n\tclean := s.writeGlobalConfig(c, cfg)\n\tdefer clean()\n\n\to := CommitOptions{}\n\terr := o.Validate(s.Repository)\n\tc.Assert(err, IsNil)\n\n\tc.Assert(o.Author.Name, Equals, \"foo\")\n\tc.Assert(o.Author.Email, Equals, \"foo@foo.com\")\n\tc.Assert(o.Committer.Name, Equals, \"foo\")\n\tc.Assert(o.Committer.Email, Equals, \"foo@foo.com\")\n}\n\nfunc (s *OptionsSuite) TestCommitOptionsLoadGlobalCommitter(c *C) {\n\tcfg := config.NewConfig()\n\tcfg.User.Name = \"foo\"\n\tcfg.User.Email = \"foo@foo.com\"\n\tcfg.Committer.Name = \"bar\"\n\tcfg.Committer.Email = \"bar@bar.com\"\n\n\tclean := s.writeGlobalConfig(c, cfg)\n\tdefer clean()\n\n\to := CommitOptions{}\n\terr := o.Validate(s.Repository)\n\tc.Assert(err, IsNil)\n\n\tc.Assert(o.Author.Name, Equals, \"foo\")\n\tc.Assert(o.Author.Email, Equals, \"foo@foo.com\")\n\tc.Assert(o.Committer.Name, Equals, \"bar\")\n\tc.Assert(o.Committer.Email, Equals, \"bar@bar.com\")\n}\n\nfunc (s *OptionsSuite) TestCreateTagOptionsLoadGlobal(c *C) {\n\tcfg := config.NewConfig()\n\tcfg.User.Name = \"foo\"\n\tcfg.User.Email = \"foo@foo.com\"\n\n\tclean := s.writeGlobalConfig(c, cfg)\n\tdefer clean()\n\n\to := CreateTagOptions{\n\t\tMessage: \"foo\",\n\t}\n\n\terr := o.Validate(s.Repository, plumbing.ZeroHash)\n\tc.Assert(err, IsNil)\n\n\tc.Assert(o.Tagger.Name, Equals, \"foo\")\n\tc.Assert(o.Tagger.Email, Equals, \"foo@foo.com\")\n}\n\nfunc (s *OptionsSuite) writeGlobalConfig(c *C, cfg *config.Config) func() {\n\tfs := s.TemporalFilesystem(c)\n\n\ttmp, err := util.TempDir(fs, \"\", \"test-options\")\n\tc.Assert(err, IsNil)\n\n\terr = fs.MkdirAll(fs.Join(tmp, \"git\"), 0777)\n\tc.Assert(err, IsNil)\n\n\tos.Setenv(\"XDG_CONFIG_HOME\", fs.Join(fs.Root(), tmp))\n\n\tcontent, err := cfg.Marshal()\n\tc.Assert(err, IsNil)\n\n\tcfgFile := fs.Join(tmp, \"git/config\")\n\terr = util.WriteFile(fs, cfgFile, content, 0777)\n\tc.Assert(err, IsNil)\n\n\treturn func() {\n\t\tos.Setenv(\"XDG_CONFIG_HOME\", \"\")\n\n\t}\n}\n"
        },
        {
          "name": "oss-fuzz.sh",
          "type": "blob",
          "size": 1.9013671875,
          "content": "#!/bin/bash -eu\n# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\n\ngo mod download\ngo get github.com/AdamKorcz/go-118-fuzz-build/testing\n\nif [ \"$SANITIZER\" != \"coverage\" ]; then\n    sed -i '/func (s \\*DecoderSuite) TestDecode(/,/^}/ s/^/\\/\\//' plumbing/format/config/decoder_test.go\n    sed -n '35,$p' plumbing/format/packfile/common_test.go >> plumbing/format/packfile/delta_test.go\n    sed -n '20,53p' plumbing/object/object_test.go >> plumbing/object/tree_test.go\n    sed -i 's|func Test|// func Test|' plumbing/transport/common_test.go\nfi\n\ncompile_native_go_fuzzer $(pwd)/internal/revision                       FuzzParser              fuzz_parser\ncompile_native_go_fuzzer $(pwd)/plumbing/format/config                  FuzzDecoder             fuzz_decoder_config\ncompile_native_go_fuzzer $(pwd)/plumbing/format/packfile                FuzzPatchDelta          fuzz_patch_delta\ncompile_native_go_fuzzer $(pwd)/plumbing/object                         FuzzParseSignedBytes    fuzz_parse_signed_bytes\ncompile_native_go_fuzzer $(pwd)/plumbing/object                         FuzzDecode              fuzz_decode\ncompile_native_go_fuzzer $(pwd)/plumbing/protocol/packp                 FuzzDecoder             fuzz_decoder_packp\ncompile_native_go_fuzzer $(pwd)/plumbing/transport                      FuzzNewEndpoint         fuzz_new_endpoint\n"
        },
        {
          "name": "plumbing",
          "type": "tree",
          "content": null
        },
        {
          "name": "prune.go",
          "type": "blob",
          "size": 1.650390625,
          "content": "package git\n\nimport (\n\t\"errors\"\n\t\"time\"\n\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/plumbing/storer\"\n)\n\ntype PruneHandler func(unreferencedObjectHash plumbing.Hash) error\ntype PruneOptions struct {\n\t// OnlyObjectsOlderThan if set to non-zero value\n\t// selects only objects older than the time provided.\n\tOnlyObjectsOlderThan time.Time\n\t// Handler is called on matching objects\n\tHandler PruneHandler\n}\n\nvar ErrLooseObjectsNotSupported = errors.New(\"loose objects not supported\")\n\n// DeleteObject deletes an object from a repository.\n// The type conveniently matches PruneHandler.\nfunc (r *Repository) DeleteObject(hash plumbing.Hash) error {\n\tlos, ok := r.Storer.(storer.LooseObjectStorer)\n\tif !ok {\n\t\treturn ErrLooseObjectsNotSupported\n\t}\n\n\treturn los.DeleteLooseObject(hash)\n}\n\nfunc (r *Repository) Prune(opt PruneOptions) error {\n\tlos, ok := r.Storer.(storer.LooseObjectStorer)\n\tif !ok {\n\t\treturn ErrLooseObjectsNotSupported\n\t}\n\n\tpw := newObjectWalker(r.Storer)\n\terr := pw.walkAllRefs()\n\tif err != nil {\n\t\treturn err\n\t}\n\t// Now walk all (loose) objects in storage.\n\treturn los.ForEachObjectHash(func(hash plumbing.Hash) error {\n\t\t// Get out if we have seen this object.\n\t\tif pw.isSeen(hash) {\n\t\t\treturn nil\n\t\t}\n\t\t// Otherwise it is a candidate for pruning.\n\t\t// Check out for too new objects next.\n\t\tif !opt.OnlyObjectsOlderThan.IsZero() {\n\t\t\t// Errors here are non-fatal. The object may be e.g. packed.\n\t\t\t// Or concurrently deleted. Skip such objects.\n\t\t\tt, err := los.LooseObjectTime(hash)\n\t\t\tif err != nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\t// Skip too new objects.\n\t\t\tif !t.Before(opt.OnlyObjectsOlderThan) {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\treturn opt.Handler(hash)\n\t})\n}\n"
        },
        {
          "name": "prune_test.go",
          "type": "blob",
          "size": 1.6796875,
          "content": "package git\n\nimport (\n\t\"time\"\n\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/plumbing/cache\"\n\t\"github.com/go-git/go-git/v5/plumbing/storer\"\n\t\"github.com/go-git/go-git/v5/storage\"\n\t\"github.com/go-git/go-git/v5/storage/filesystem\"\n\n\tfixtures \"github.com/go-git/go-git-fixtures/v4\"\n\t. \"gopkg.in/check.v1\"\n)\n\ntype PruneSuite struct {\n\tBaseSuite\n}\n\nvar _ = Suite(&PruneSuite{})\n\nfunc (s *PruneSuite) testPrune(c *C, deleteTime time.Time) {\n\tsrcFs := fixtures.ByTag(\"unpacked\").One().DotGit()\n\tvar sto storage.Storer\n\tvar err error\n\tsto = filesystem.NewStorage(srcFs, cache.NewObjectLRUDefault())\n\n\tlos := sto.(storer.LooseObjectStorer)\n\tc.Assert(los, NotNil)\n\n\tcount := 0\n\terr = los.ForEachObjectHash(func(_ plumbing.Hash) error {\n\t\tcount++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\n\tr, err := Open(sto, srcFs)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\t// Remove a branch so we can prune some objects.\n\terr = sto.RemoveReference(plumbing.ReferenceName(\"refs/heads/v4\"))\n\tc.Assert(err, IsNil)\n\terr = sto.RemoveReference(plumbing.ReferenceName(\"refs/remotes/origin/v4\"))\n\tc.Assert(err, IsNil)\n\n\terr = r.Prune(PruneOptions{\n\t\tOnlyObjectsOlderThan: deleteTime,\n\t\tHandler:              r.DeleteObject,\n\t})\n\tc.Assert(err, IsNil)\n\n\tnewCount := 0\n\terr = los.ForEachObjectHash(func(_ plumbing.Hash) error {\n\t\tnewCount++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\n\tif deleteTime.IsZero() {\n\t\tc.Assert(newCount < count, Equals, true)\n\t} else {\n\t\t// Assume a delete time older than any of the objects was passed in.\n\t\tc.Assert(newCount, Equals, count)\n\t}\n}\n\nfunc (s *PruneSuite) TestPrune(c *C) {\n\ts.testPrune(c, time.Time{})\n}\n\nfunc (s *PruneSuite) TestPruneWithNoDelete(c *C) {\n\ts.testPrune(c, time.Unix(0, 1))\n}\n"
        },
        {
          "name": "remote.go",
          "type": "blob",
          "size": 35.87890625,
          "content": "package git\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/go-git/go-billy/v5/osfs\"\n\n\t\"github.com/go-git/go-git/v5/config\"\n\t\"github.com/go-git/go-git/v5/internal/url\"\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/plumbing/cache\"\n\t\"github.com/go-git/go-git/v5/plumbing/format/packfile\"\n\t\"github.com/go-git/go-git/v5/plumbing/object\"\n\t\"github.com/go-git/go-git/v5/plumbing/protocol/packp\"\n\t\"github.com/go-git/go-git/v5/plumbing/protocol/packp/capability\"\n\t\"github.com/go-git/go-git/v5/plumbing/protocol/packp/sideband\"\n\t\"github.com/go-git/go-git/v5/plumbing/revlist\"\n\t\"github.com/go-git/go-git/v5/plumbing/storer\"\n\t\"github.com/go-git/go-git/v5/plumbing/transport\"\n\t\"github.com/go-git/go-git/v5/plumbing/transport/client\"\n\t\"github.com/go-git/go-git/v5/storage\"\n\t\"github.com/go-git/go-git/v5/storage/filesystem\"\n\t\"github.com/go-git/go-git/v5/storage/memory\"\n\t\"github.com/go-git/go-git/v5/utils/ioutil\"\n)\n\nvar (\n\tNoErrAlreadyUpToDate     = errors.New(\"already up-to-date\")\n\tErrDeleteRefNotSupported = errors.New(\"server does not support delete-refs\")\n\tErrForceNeeded           = errors.New(\"some refs were not updated\")\n\tErrExactSHA1NotSupported = errors.New(\"server does not support exact SHA1 refspec\")\n\tErrEmptyUrls             = errors.New(\"URLs cannot be empty\")\n)\n\ntype NoMatchingRefSpecError struct {\n\trefSpec config.RefSpec\n}\n\nfunc (e NoMatchingRefSpecError) Error() string {\n\treturn fmt.Sprintf(\"couldn't find remote ref %q\", e.refSpec.Src())\n}\n\nfunc (e NoMatchingRefSpecError) Is(target error) bool {\n\t_, ok := target.(NoMatchingRefSpecError)\n\treturn ok\n}\n\nconst (\n\t// This describes the maximum number of commits to walk when\n\t// computing the haves to send to a server, for each ref in the\n\t// repo containing this remote, when not using the multi-ack\n\t// protocol.  Setting this to 0 means there is no limit.\n\tmaxHavesToVisitPerRef = 100\n\n\t// peeledSuffix is the suffix used to build peeled reference names.\n\tpeeledSuffix = \"^{}\"\n)\n\n// Remote represents a connection to a remote repository.\ntype Remote struct {\n\tc *config.RemoteConfig\n\ts storage.Storer\n}\n\n// NewRemote creates a new Remote.\n// The intended purpose is to use the Remote for tasks such as listing remote references (like using git ls-remote).\n// Otherwise Remotes should be created via the use of a Repository.\nfunc NewRemote(s storage.Storer, c *config.RemoteConfig) *Remote {\n\treturn &Remote{s: s, c: c}\n}\n\n// Config returns the RemoteConfig object used to instantiate this Remote.\nfunc (r *Remote) Config() *config.RemoteConfig {\n\treturn r.c\n}\n\nfunc (r *Remote) String() string {\n\tvar fetch, push string\n\tif len(r.c.URLs) > 0 {\n\t\tfetch = r.c.URLs[0]\n\t\tpush = r.c.URLs[len(r.c.URLs)-1]\n\t}\n\n\treturn fmt.Sprintf(\"%s\\t%s (fetch)\\n%[1]s\\t%[3]s (push)\", r.c.Name, fetch, push)\n}\n\n// Push performs a push to the remote. Returns NoErrAlreadyUpToDate if the\n// remote was already up-to-date.\nfunc (r *Remote) Push(o *PushOptions) error {\n\treturn r.PushContext(context.Background(), o)\n}\n\n// PushContext performs a push to the remote. Returns NoErrAlreadyUpToDate if\n// the remote was already up-to-date.\n//\n// The provided Context must be non-nil. If the context expires before the\n// operation is complete, an error is returned. The context only affects the\n// transport operations.\nfunc (r *Remote) PushContext(ctx context.Context, o *PushOptions) (err error) {\n\tif err := o.Validate(); err != nil {\n\t\treturn err\n\t}\n\n\tif o.RemoteName != r.c.Name {\n\t\treturn fmt.Errorf(\"remote names don't match: %s != %s\", o.RemoteName, r.c.Name)\n\t}\n\n\tif o.RemoteURL == \"\" && len(r.c.URLs) > 0 {\n\t\to.RemoteURL = r.c.URLs[len(r.c.URLs)-1]\n\t}\n\n\ts, err := newSendPackSession(o.RemoteURL, o.Auth, o.InsecureSkipTLS, o.CABundle, o.ProxyOptions)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdefer ioutil.CheckClose(s, &err)\n\n\tar, err := s.AdvertisedReferencesContext(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tremoteRefs, err := ar.AllReferences()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := r.checkRequireRemoteRefs(o.RequireRemoteRefs, remoteRefs); err != nil {\n\t\treturn err\n\t}\n\n\tisDelete := false\n\tallDelete := true\n\tfor _, rs := range o.RefSpecs {\n\t\tif rs.IsDelete() {\n\t\t\tisDelete = true\n\t\t} else {\n\t\t\tallDelete = false\n\t\t}\n\t\tif isDelete && !allDelete {\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif isDelete && !ar.Capabilities.Supports(capability.DeleteRefs) {\n\t\treturn ErrDeleteRefNotSupported\n\t}\n\n\tif o.Force {\n\t\tfor i := 0; i < len(o.RefSpecs); i++ {\n\t\t\trs := &o.RefSpecs[i]\n\t\t\tif !rs.IsForceUpdate() && !rs.IsDelete() {\n\t\t\t\to.RefSpecs[i] = config.RefSpec(\"+\" + rs.String())\n\t\t\t}\n\t\t}\n\t}\n\n\tlocalRefs, err := r.references()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treq, err := r.newReferenceUpdateRequest(o, localRefs, remoteRefs, ar)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif len(req.Commands) == 0 {\n\t\treturn NoErrAlreadyUpToDate\n\t}\n\n\tobjects := objectsToPush(req.Commands)\n\n\thaves, err := referencesToHashes(remoteRefs)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tstop, err := r.s.Shallow()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// if we have shallow we should include this as part of the objects that\n\t// we are aware.\n\thaves = append(haves, stop...)\n\n\tvar hashesToPush []plumbing.Hash\n\t// Avoid the expensive revlist operation if we're only doing deletes.\n\tif !allDelete {\n\t\tif url.IsLocalEndpoint(o.RemoteURL) {\n\t\t\t// If we're are pushing to a local repo, it might be much\n\t\t\t// faster to use a local storage layer to get the commits\n\t\t\t// to ignore, when calculating the object revlist.\n\t\t\tlocalStorer := filesystem.NewStorage(\n\t\t\t\tosfs.New(o.RemoteURL), cache.NewObjectLRUDefault())\n\t\t\thashesToPush, err = revlist.ObjectsWithStorageForIgnores(\n\t\t\t\tr.s, localStorer, objects, haves)\n\t\t} else {\n\t\t\thashesToPush, err = revlist.Objects(r.s, objects, haves)\n\t\t}\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif len(hashesToPush) == 0 {\n\t\tallDelete = true\n\t\tfor _, command := range req.Commands {\n\t\t\tif command.Action() != packp.Delete {\n\t\t\t\tallDelete = false\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\trs, err := pushHashes(ctx, s, r.s, req, hashesToPush, r.useRefDeltas(ar), allDelete)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif rs != nil {\n\t\tif err = rs.Error(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn r.updateRemoteReferenceStorage(req)\n}\n\nfunc (r *Remote) useRefDeltas(ar *packp.AdvRefs) bool {\n\treturn !ar.Capabilities.Supports(capability.OFSDelta)\n}\n\nfunc (r *Remote) addReachableTags(localRefs []*plumbing.Reference, remoteRefs storer.ReferenceStorer, req *packp.ReferenceUpdateRequest) error {\n\ttags := make(map[plumbing.Reference]struct{})\n\t// get a list of all tags locally\n\tfor _, ref := range localRefs {\n\t\tif strings.HasPrefix(string(ref.Name()), \"refs/tags\") {\n\t\t\ttags[*ref] = struct{}{}\n\t\t}\n\t}\n\n\tremoteRefIter, err := remoteRefs.IterReferences()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// remove any that are already on the remote\n\tif err := remoteRefIter.ForEach(func(reference *plumbing.Reference) error {\n\t\tdelete(tags, *reference)\n\t\treturn nil\n\t}); err != nil {\n\t\treturn err\n\t}\n\n\tfor tag := range tags {\n\t\ttagObject, err := object.GetObject(r.s, tag.Hash())\n\t\tvar tagCommit *object.Commit\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"get tag object: %w\", err)\n\t\t}\n\n\t\tif tagObject.Type() != plumbing.TagObject {\n\t\t\tcontinue\n\t\t}\n\n\t\tannotatedTag, ok := tagObject.(*object.Tag)\n\t\tif !ok {\n\t\t\treturn errors.New(\"could not get annotated tag object\")\n\t\t}\n\n\t\ttagCommit, err = object.GetCommit(r.s, annotatedTag.Target)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"get annotated tag commit: %w\", err)\n\t\t}\n\n\t\t// only include tags that are reachable from one of the refs\n\t\t// already being pushed\n\t\tfor _, cmd := range req.Commands {\n\t\t\tif tag.Name() == cmd.Name {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif strings.HasPrefix(cmd.Name.String(), \"refs/tags\") {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tc, err := object.GetCommit(r.s, cmd.New)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"get commit %v: %w\", cmd.Name, err)\n\t\t\t}\n\n\t\t\tif isAncestor, err := tagCommit.IsAncestor(c); err == nil && isAncestor {\n\t\t\t\treq.Commands = append(req.Commands, &packp.Command{Name: tag.Name(), New: tag.Hash()})\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (r *Remote) newReferenceUpdateRequest(\n\to *PushOptions,\n\tlocalRefs []*plumbing.Reference,\n\tremoteRefs storer.ReferenceStorer,\n\tar *packp.AdvRefs,\n) (*packp.ReferenceUpdateRequest, error) {\n\treq := packp.NewReferenceUpdateRequestFromCapabilities(ar.Capabilities)\n\n\tif o.Progress != nil {\n\t\treq.Progress = o.Progress\n\t\tif ar.Capabilities.Supports(capability.Sideband64k) {\n\t\t\t_ = req.Capabilities.Set(capability.Sideband64k)\n\t\t} else if ar.Capabilities.Supports(capability.Sideband) {\n\t\t\t_ = req.Capabilities.Set(capability.Sideband)\n\t\t}\n\t}\n\n\tif ar.Capabilities.Supports(capability.PushOptions) {\n\t\t_ = req.Capabilities.Set(capability.PushOptions)\n\t\tfor k, v := range o.Options {\n\t\t\treq.Options = append(req.Options, &packp.Option{Key: k, Value: v})\n\t\t}\n\t}\n\n\tif o.Atomic && ar.Capabilities.Supports(capability.Atomic) {\n\t\t_ = req.Capabilities.Set(capability.Atomic)\n\t}\n\n\tif err := r.addReferencesToUpdate(o.RefSpecs, localRefs, remoteRefs, req, o.Prune, o.ForceWithLease); err != nil {\n\n\t\treturn nil, err\n\t}\n\n\tif o.FollowTags {\n\t\tif err := r.addReachableTags(localRefs, remoteRefs, req); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn req, nil\n}\n\nfunc (r *Remote) updateRemoteReferenceStorage(\n\treq *packp.ReferenceUpdateRequest,\n) error {\n\n\tfor _, spec := range r.c.Fetch {\n\t\tfor _, c := range req.Commands {\n\t\t\tif !spec.Match(c.Name) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tlocal := spec.Dst(c.Name)\n\t\t\tref := plumbing.NewHashReference(local, c.New)\n\t\t\tswitch c.Action() {\n\t\t\tcase packp.Create, packp.Update:\n\t\t\t\tif err := r.s.SetReference(ref); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\tcase packp.Delete:\n\t\t\t\tif err := r.s.RemoveReference(local); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// FetchContext fetches references along with the objects necessary to complete\n// their histories.\n//\n// Returns nil if the operation is successful, NoErrAlreadyUpToDate if there are\n// no changes to be fetched, or an error.\n//\n// The provided Context must be non-nil. If the context expires before the\n// operation is complete, an error is returned. The context only affects the\n// transport operations.\nfunc (r *Remote) FetchContext(ctx context.Context, o *FetchOptions) error {\n\t_, err := r.fetch(ctx, o)\n\treturn err\n}\n\n// Fetch fetches references along with the objects necessary to complete their\n// histories.\n//\n// Returns nil if the operation is successful, NoErrAlreadyUpToDate if there are\n// no changes to be fetched, or an error.\nfunc (r *Remote) Fetch(o *FetchOptions) error {\n\treturn r.FetchContext(context.Background(), o)\n}\n\nfunc (r *Remote) fetch(ctx context.Context, o *FetchOptions) (sto storer.ReferenceStorer, err error) {\n\tif o.RemoteName == \"\" {\n\t\to.RemoteName = r.c.Name\n\t}\n\n\tif err = o.Validate(); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif len(o.RefSpecs) == 0 {\n\t\to.RefSpecs = r.c.Fetch\n\t}\n\n\tif o.RemoteURL == \"\" {\n\t\to.RemoteURL = r.c.URLs[0]\n\t}\n\n\ts, err := newUploadPackSession(o.RemoteURL, o.Auth, o.InsecureSkipTLS, o.CABundle, o.ProxyOptions)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdefer ioutil.CheckClose(s, &err)\n\n\tar, err := s.AdvertisedReferencesContext(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treq, err := r.newUploadPackRequest(o, ar)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := r.isSupportedRefSpec(o.RefSpecs, ar); err != nil {\n\t\treturn nil, err\n\t}\n\n\tremoteRefs, err := ar.AllReferences()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tlocalRefs, err := r.references()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\trefs, specToRefs, err := calculateRefs(o.RefSpecs, remoteRefs, o.Tags)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif !req.Depth.IsZero() {\n\t\treq.Shallows, err = r.s.Shallow()\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"existing checkout is not shallow\")\n\t\t}\n\t}\n\n\treq.Wants, err = getWants(r.s, refs, o.Depth)\n\tif len(req.Wants) > 0 {\n\t\treq.Haves, err = getHaves(localRefs, remoteRefs, r.s, o.Depth)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tif err = r.fetchPack(ctx, o, s, req); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tvar updatedPrune bool\n\tif o.Prune {\n\t\tupdatedPrune, err = r.pruneRemotes(o.RefSpecs, localRefs, remoteRefs)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tupdated, err := r.updateLocalReferenceStorage(o.RefSpecs, refs, remoteRefs, specToRefs, o.Tags, o.Force)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif !updated {\n\t\tupdated, err = depthChanged(req.Shallows, r.s)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error checking depth change: %v\", err)\n\t\t}\n\t}\n\n\tif !updated && !updatedPrune {\n\t\t// No references updated, but may have fetched new objects, check if we now have any of our wants\n\t\tfor _, hash := range req.Wants {\n\t\t\texists, _ := objectExists(r.s, hash)\n\t\t\tif exists {\n\t\t\t\tupdated = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !updated {\n\t\t\treturn remoteRefs, NoErrAlreadyUpToDate\n\t\t}\n\t}\n\n\treturn remoteRefs, nil\n}\n\nfunc depthChanged(before []plumbing.Hash, s storage.Storer) (bool, error) {\n\tafter, err := s.Shallow()\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tif len(before) != len(after) {\n\t\treturn true, nil\n\t}\n\n\tbm := make(map[plumbing.Hash]bool, len(before))\n\tfor _, b := range before {\n\t\tbm[b] = true\n\t}\n\tfor _, a := range after {\n\t\tif _, ok := bm[a]; !ok {\n\t\t\treturn true, nil\n\t\t}\n\t}\n\n\treturn false, nil\n}\n\nfunc newUploadPackSession(url string, auth transport.AuthMethod, insecure bool, cabundle []byte, proxyOpts transport.ProxyOptions) (transport.UploadPackSession, error) {\n\tc, ep, err := newClient(url, insecure, cabundle, proxyOpts)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn c.NewUploadPackSession(ep, auth)\n}\n\nfunc newSendPackSession(url string, auth transport.AuthMethod, insecure bool, cabundle []byte, proxyOpts transport.ProxyOptions) (transport.ReceivePackSession, error) {\n\tc, ep, err := newClient(url, insecure, cabundle, proxyOpts)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn c.NewReceivePackSession(ep, auth)\n}\n\nfunc newClient(url string, insecure bool, cabundle []byte, proxyOpts transport.ProxyOptions) (transport.Transport, *transport.Endpoint, error) {\n\tep, err := transport.NewEndpoint(url)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tep.InsecureSkipTLS = insecure\n\tep.CaBundle = cabundle\n\tep.Proxy = proxyOpts\n\n\tc, err := client.NewClient(ep)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\treturn c, ep, err\n}\n\nfunc (r *Remote) fetchPack(ctx context.Context, o *FetchOptions, s transport.UploadPackSession,\n\treq *packp.UploadPackRequest) (err error) {\n\n\treader, err := s.UploadPack(ctx, req)\n\tif err != nil {\n\t\tif errors.Is(err, transport.ErrEmptyUploadPackRequest) {\n\t\t\t// XXX: no packfile provided, everything is up-to-date.\n\t\t\treturn nil\n\t\t}\n\t\treturn err\n\t}\n\n\tdefer ioutil.CheckClose(reader, &err)\n\n\tif err = r.updateShallow(o, reader); err != nil {\n\t\treturn err\n\t}\n\n\tif err = packfile.UpdateObjectStorage(r.s,\n\t\tbuildSidebandIfSupported(req.Capabilities, reader, o.Progress),\n\t); err != nil {\n\t\treturn err\n\t}\n\n\treturn err\n}\n\nfunc (r *Remote) pruneRemotes(specs []config.RefSpec, localRefs []*plumbing.Reference, remoteRefs memory.ReferenceStorage) (bool, error) {\n\tvar updatedPrune bool\n\tfor _, spec := range specs {\n\t\trev := spec.Reverse()\n\t\tfor _, ref := range localRefs {\n\t\t\tif !rev.Match(ref.Name()) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\t_, err := remoteRefs.Reference(rev.Dst(ref.Name()))\n\t\t\tif errors.Is(err, plumbing.ErrReferenceNotFound) {\n\t\t\t\tupdatedPrune = true\n\t\t\t\terr := r.s.RemoveReference(ref.Name())\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn false, err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn updatedPrune, nil\n}\n\nfunc (r *Remote) addReferencesToUpdate(\n\trefspecs []config.RefSpec,\n\tlocalRefs []*plumbing.Reference,\n\tremoteRefs storer.ReferenceStorer,\n\treq *packp.ReferenceUpdateRequest,\n\tprune bool,\n\tforceWithLease *ForceWithLease,\n) error {\n\t// This references dictionary will be used to search references by name.\n\trefsDict := make(map[string]*plumbing.Reference)\n\tfor _, ref := range localRefs {\n\t\trefsDict[ref.Name().String()] = ref\n\t}\n\n\tfor _, rs := range refspecs {\n\t\tif rs.IsDelete() {\n\t\t\tif err := r.deleteReferences(rs, remoteRefs, refsDict, req, false); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t} else {\n\t\t\terr := r.addOrUpdateReferences(rs, localRefs, refsDict, remoteRefs, req, forceWithLease)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tif prune {\n\t\t\t\tif err := r.deleteReferences(rs, remoteRefs, refsDict, req, true); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (r *Remote) addOrUpdateReferences(\n\trs config.RefSpec,\n\tlocalRefs []*plumbing.Reference,\n\trefsDict map[string]*plumbing.Reference,\n\tremoteRefs storer.ReferenceStorer,\n\treq *packp.ReferenceUpdateRequest,\n\tforceWithLease *ForceWithLease,\n) error {\n\t// If it is not a wildcard refspec we can directly search for the reference\n\t// in the references dictionary.\n\tif !rs.IsWildcard() {\n\t\tref, ok := refsDict[rs.Src()]\n\t\tif !ok {\n\t\t\tcommit, err := object.GetCommit(r.s, plumbing.NewHash(rs.Src()))\n\t\t\tif err == nil {\n\t\t\t\treturn r.addCommit(rs, remoteRefs, commit.Hash, req)\n\t\t\t}\n\t\t\treturn nil\n\t\t}\n\n\t\treturn r.addReferenceIfRefSpecMatches(rs, remoteRefs, ref, req, forceWithLease)\n\t}\n\n\tfor _, ref := range localRefs {\n\t\terr := r.addReferenceIfRefSpecMatches(rs, remoteRefs, ref, req, forceWithLease)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (r *Remote) deleteReferences(rs config.RefSpec,\n\tremoteRefs storer.ReferenceStorer,\n\trefsDict map[string]*plumbing.Reference,\n\treq *packp.ReferenceUpdateRequest,\n\tprune bool) error {\n\titer, err := remoteRefs.IterReferences()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn iter.ForEach(func(ref *plumbing.Reference) error {\n\t\tif ref.Type() != plumbing.HashReference {\n\t\t\treturn nil\n\t\t}\n\n\t\tif prune {\n\t\t\trs := rs.Reverse()\n\t\t\tif !rs.Match(ref.Name()) {\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\tif _, ok := refsDict[rs.Dst(ref.Name()).String()]; ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t} else if rs.Dst(\"\") != ref.Name() {\n\t\t\treturn nil\n\t\t}\n\n\t\tcmd := &packp.Command{\n\t\t\tName: ref.Name(),\n\t\t\tOld:  ref.Hash(),\n\t\t\tNew:  plumbing.ZeroHash,\n\t\t}\n\t\treq.Commands = append(req.Commands, cmd)\n\t\treturn nil\n\t})\n}\n\nfunc (r *Remote) addCommit(rs config.RefSpec,\n\tremoteRefs storer.ReferenceStorer, localCommit plumbing.Hash,\n\treq *packp.ReferenceUpdateRequest) error {\n\n\tif rs.IsWildcard() {\n\t\treturn errors.New(\"can't use wildcard together with hash refspecs\")\n\t}\n\n\tcmd := &packp.Command{\n\t\tName: rs.Dst(\"\"),\n\t\tOld:  plumbing.ZeroHash,\n\t\tNew:  localCommit,\n\t}\n\tremoteRef, err := remoteRefs.Reference(cmd.Name)\n\tif err == nil {\n\t\tif remoteRef.Type() != plumbing.HashReference {\n\t\t\t// TODO: check actual git behavior here\n\t\t\treturn nil\n\t\t}\n\n\t\tcmd.Old = remoteRef.Hash()\n\t} else if err != plumbing.ErrReferenceNotFound {\n\t\treturn err\n\t}\n\tif cmd.Old == cmd.New {\n\t\treturn nil\n\t}\n\tif !rs.IsForceUpdate() {\n\t\tif err := checkFastForwardUpdate(r.s, remoteRefs, cmd); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treq.Commands = append(req.Commands, cmd)\n\treturn nil\n}\n\nfunc (r *Remote) addReferenceIfRefSpecMatches(rs config.RefSpec,\n\tremoteRefs storer.ReferenceStorer, localRef *plumbing.Reference,\n\treq *packp.ReferenceUpdateRequest, forceWithLease *ForceWithLease) error {\n\n\tif localRef.Type() != plumbing.HashReference {\n\t\treturn nil\n\t}\n\n\tif !rs.Match(localRef.Name()) {\n\t\treturn nil\n\t}\n\n\tcmd := &packp.Command{\n\t\tName: rs.Dst(localRef.Name()),\n\t\tOld:  plumbing.ZeroHash,\n\t\tNew:  localRef.Hash(),\n\t}\n\n\tremoteRef, err := remoteRefs.Reference(cmd.Name)\n\tif err == nil {\n\t\tif remoteRef.Type() != plumbing.HashReference {\n\t\t\t// TODO: check actual git behavior here\n\t\t\treturn nil\n\t\t}\n\n\t\tcmd.Old = remoteRef.Hash()\n\t} else if err != plumbing.ErrReferenceNotFound {\n\t\treturn err\n\t}\n\n\tif cmd.Old == cmd.New {\n\t\treturn nil\n\t}\n\n\tif forceWithLease != nil {\n\t\tif err = r.checkForceWithLease(localRef, cmd, forceWithLease); err != nil {\n\t\t\treturn err\n\t\t}\n\t} else if !rs.IsForceUpdate() {\n\t\tif err := checkFastForwardUpdate(r.s, remoteRefs, cmd); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treq.Commands = append(req.Commands, cmd)\n\treturn nil\n}\n\nfunc (r *Remote) checkForceWithLease(localRef *plumbing.Reference, cmd *packp.Command, forceWithLease *ForceWithLease) error {\n\tremotePrefix := fmt.Sprintf(\"refs/remotes/%s/\", r.Config().Name)\n\n\tref, err := storer.ResolveReference(\n\t\tr.s,\n\t\tplumbing.ReferenceName(remotePrefix+strings.Replace(localRef.Name().String(), \"refs/heads/\", \"\", -1)))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif forceWithLease.RefName.String() == \"\" || (forceWithLease.RefName == cmd.Name) {\n\t\texpectedOID := ref.Hash()\n\n\t\tif !forceWithLease.Hash.IsZero() {\n\t\t\texpectedOID = forceWithLease.Hash\n\t\t}\n\n\t\tif cmd.Old != expectedOID {\n\t\t\treturn fmt.Errorf(\"non-fast-forward update: %s\", cmd.Name.String())\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (r *Remote) references() ([]*plumbing.Reference, error) {\n\tvar localRefs []*plumbing.Reference\n\n\titer, err := r.s.IterReferences()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor {\n\t\tref, err := iter.Next()\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tlocalRefs = append(localRefs, ref)\n\t}\n\n\treturn localRefs, nil\n}\n\nfunc getRemoteRefsFromStorer(remoteRefStorer storer.ReferenceStorer) (\n\tmap[plumbing.Hash]bool, error) {\n\tremoteRefs := map[plumbing.Hash]bool{}\n\titer, err := remoteRefStorer.IterReferences()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = iter.ForEach(func(ref *plumbing.Reference) error {\n\t\tif ref.Type() != plumbing.HashReference {\n\t\t\treturn nil\n\t\t}\n\t\tremoteRefs[ref.Hash()] = true\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn remoteRefs, nil\n}\n\n// getHavesFromRef populates the given `haves` map with the given\n// reference, and up to `maxHavesToVisitPerRef` ancestor commits.\nfunc getHavesFromRef(\n\tref *plumbing.Reference,\n\tremoteRefs map[plumbing.Hash]bool,\n\ts storage.Storer,\n\thaves map[plumbing.Hash]bool,\n\tdepth int,\n) error {\n\th := ref.Hash()\n\tif haves[h] {\n\t\treturn nil\n\t}\n\n\tcommit, err := object.GetCommit(s, h)\n\tif err != nil {\n\t\tif !errors.Is(err, plumbing.ErrObjectNotFound) {\n\t\t\t// Ignore the error if this isn't a commit.\n\t\t\thaves[ref.Hash()] = true\n\t\t}\n\t\treturn nil\n\t}\n\n\t// Until go-git supports proper commit negotiation during an\n\t// upload pack request, include up to `maxHavesToVisitPerRef`\n\t// commits from the history of each ref.\n\twalker := object.NewCommitPreorderIter(commit, haves, nil)\n\ttoVisit := maxHavesToVisitPerRef\n\t// But only need up to the requested depth\n\tif depth > 0 && depth < maxHavesToVisitPerRef {\n\t\ttoVisit = depth\n\t}\n\t// It is safe to ignore any error here as we are just trying to find the references that we already have\n\t// An example of a legitimate failure is we have a shallow clone and don't have the previous commit(s)\n\t_ = walker.ForEach(func(c *object.Commit) error {\n\t\thaves[c.Hash] = true\n\t\ttoVisit--\n\t\t// If toVisit starts out at 0 (indicating there is no\n\t\t// max), then it will be negative here and we won't stop\n\t\t// early.\n\t\tif toVisit == 0 || remoteRefs[c.Hash] {\n\t\t\treturn storer.ErrStop\n\t\t}\n\t\treturn nil\n\t})\n\n\treturn nil\n}\n\nfunc getHaves(\n\tlocalRefs []*plumbing.Reference,\n\tremoteRefStorer storer.ReferenceStorer,\n\ts storage.Storer,\n\tdepth int,\n) ([]plumbing.Hash, error) {\n\thaves := map[plumbing.Hash]bool{}\n\n\t// Build a map of all the remote references, to avoid loading too\n\t// many parent commits for references we know don't need to be\n\t// transferred.\n\tremoteRefs, err := getRemoteRefsFromStorer(remoteRefStorer)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, ref := range localRefs {\n\t\tif haves[ref.Hash()] {\n\t\t\tcontinue\n\t\t}\n\n\t\tif ref.Type() != plumbing.HashReference {\n\t\t\tcontinue\n\t\t}\n\n\t\terr = getHavesFromRef(ref, remoteRefs, s, haves, depth)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tvar result []plumbing.Hash\n\tfor h := range haves {\n\t\tresult = append(result, h)\n\t}\n\n\treturn result, nil\n}\n\nconst refspecAllTags = \"+refs/tags/*:refs/tags/*\"\n\nfunc calculateRefs(\n\tspec []config.RefSpec,\n\tremoteRefs storer.ReferenceStorer,\n\ttagMode TagMode,\n) (memory.ReferenceStorage, [][]*plumbing.Reference, error) {\n\tif tagMode == AllTags {\n\t\tspec = append(spec, refspecAllTags)\n\t}\n\n\trefs := make(memory.ReferenceStorage)\n\t// list of references matched for each spec\n\tspecToRefs := make([][]*plumbing.Reference, len(spec))\n\tfor i := range spec {\n\t\tvar err error\n\t\tspecToRefs[i], err = doCalculateRefs(spec[i], remoteRefs, refs)\n\t\tif err != nil {\n\t\t\treturn nil, nil, err\n\t\t}\n\t}\n\n\treturn refs, specToRefs, nil\n}\n\nfunc doCalculateRefs(\n\ts config.RefSpec,\n\tremoteRefs storer.ReferenceStorer,\n\trefs memory.ReferenceStorage,\n) ([]*plumbing.Reference, error) {\n\tvar refList []*plumbing.Reference\n\n\tif s.IsExactSHA1() {\n\t\tref := plumbing.NewHashReference(s.Dst(\"\"), plumbing.NewHash(s.Src()))\n\n\t\trefList = append(refList, ref)\n\t\treturn refList, refs.SetReference(ref)\n\t}\n\n\tvar matched bool\n\tonMatched := func(ref *plumbing.Reference) error {\n\t\tif ref.Type() == plumbing.SymbolicReference {\n\t\t\ttarget, err := storer.ResolveReference(remoteRefs, ref.Name())\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tref = plumbing.NewHashReference(ref.Name(), target.Hash())\n\t\t}\n\n\t\tif ref.Type() != plumbing.HashReference {\n\t\t\treturn nil\n\t\t}\n\n\t\tmatched = true\n\t\trefList = append(refList, ref)\n\t\treturn refs.SetReference(ref)\n\t}\n\n\tvar ret error\n\tif s.IsWildcard() {\n\t\titer, err := remoteRefs.IterReferences()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tret = iter.ForEach(func(ref *plumbing.Reference) error {\n\t\t\tif !s.Match(ref.Name()) {\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\treturn onMatched(ref)\n\t\t})\n\t} else {\n\t\tvar resolvedRef *plumbing.Reference\n\t\tsrc := s.Src()\n\t\tresolvedRef, ret = expand_ref(remoteRefs, plumbing.ReferenceName(src))\n\t\tif ret == nil {\n\t\t\tret = onMatched(resolvedRef)\n\t\t}\n\t}\n\n\tif !matched && !s.IsWildcard() {\n\t\treturn nil, NoMatchingRefSpecError{refSpec: s}\n\t}\n\n\treturn refList, ret\n}\n\nfunc getWants(localStorer storage.Storer, refs memory.ReferenceStorage, depth int) ([]plumbing.Hash, error) {\n\t// If depth is anything other than 1 and the repo has shallow commits then just because we have the commit\n\t// at the reference doesn't mean that we don't still need to fetch the parents\n\tshallow := false\n\tif depth != 1 {\n\t\tif s, _ := localStorer.Shallow(); len(s) > 0 {\n\t\t\tshallow = true\n\t\t}\n\t}\n\n\twants := map[plumbing.Hash]bool{}\n\tfor _, ref := range refs {\n\t\thash := ref.Hash()\n\t\texists, err := objectExists(localStorer, ref.Hash())\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tif !exists || shallow {\n\t\t\twants[hash] = true\n\t\t}\n\t}\n\n\tvar result []plumbing.Hash\n\tfor h := range wants {\n\t\tresult = append(result, h)\n\t}\n\n\treturn result, nil\n}\n\nfunc objectExists(s storer.EncodedObjectStorer, h plumbing.Hash) (bool, error) {\n\t_, err := s.EncodedObject(plumbing.AnyObject, h)\n\tif err == plumbing.ErrObjectNotFound {\n\t\treturn false, nil\n\t}\n\n\treturn true, err\n}\n\nfunc checkFastForwardUpdate(s storer.EncodedObjectStorer, remoteRefs storer.ReferenceStorer, cmd *packp.Command) error {\n\tif cmd.Old == plumbing.ZeroHash {\n\t\t_, err := remoteRefs.Reference(cmd.Name)\n\t\tif err == plumbing.ErrReferenceNotFound {\n\t\t\treturn nil\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn fmt.Errorf(\"non-fast-forward update: %s\", cmd.Name.String())\n\t}\n\n\tff, err := isFastForward(s, cmd.Old, cmd.New, nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif !ff {\n\t\treturn fmt.Errorf(\"non-fast-forward update: %s\", cmd.Name.String())\n\t}\n\n\treturn nil\n}\n\nfunc isFastForward(s storer.EncodedObjectStorer, old, new plumbing.Hash, earliestShallow *plumbing.Hash) (bool, error) {\n\tc, err := object.GetCommit(s, new)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tparentsToIgnore := []plumbing.Hash{}\n\tif earliestShallow != nil {\n\t\tearliestCommit, err := object.GetCommit(s, *earliestShallow)\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\n\t\tparentsToIgnore = earliestCommit.ParentHashes\n\t}\n\n\tfound := false\n\t// stop iterating at the earliest shallow commit, ignoring its parents\n\t// note: when pull depth is smaller than the number of new changes on the remote, this fails due to missing parents.\n\t//       as far as i can tell, without the commits in-between the shallow pull and the earliest shallow, there's no\n\t//       real way of telling whether it will be a fast-forward merge.\n\titer := object.NewCommitPreorderIter(c, nil, parentsToIgnore)\n\terr = iter.ForEach(func(c *object.Commit) error {\n\t\tif c.Hash != old {\n\t\t\treturn nil\n\t\t}\n\n\t\tfound = true\n\t\treturn storer.ErrStop\n\t})\n\treturn found, err\n}\n\nfunc (r *Remote) newUploadPackRequest(o *FetchOptions,\n\tar *packp.AdvRefs) (*packp.UploadPackRequest, error) {\n\n\treq := packp.NewUploadPackRequestFromCapabilities(ar.Capabilities)\n\n\tif o.Depth != 0 {\n\t\treq.Depth = packp.DepthCommits(o.Depth)\n\t\tif err := req.Capabilities.Set(capability.Shallow); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif o.Progress == nil && ar.Capabilities.Supports(capability.NoProgress) {\n\t\tif err := req.Capabilities.Set(capability.NoProgress); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tisWildcard := true\n\tfor _, s := range o.RefSpecs {\n\t\tif !s.IsWildcard() {\n\t\t\tisWildcard = false\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif isWildcard && o.Tags == TagFollowing && ar.Capabilities.Supports(capability.IncludeTag) {\n\t\tif err := req.Capabilities.Set(capability.IncludeTag); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn req, nil\n}\n\nfunc (r *Remote) isSupportedRefSpec(refs []config.RefSpec, ar *packp.AdvRefs) error {\n\tvar containsIsExact bool\n\tfor _, ref := range refs {\n\t\tif ref.IsExactSHA1() {\n\t\t\tcontainsIsExact = true\n\t\t}\n\t}\n\n\tif !containsIsExact {\n\t\treturn nil\n\t}\n\n\tif ar.Capabilities.Supports(capability.AllowReachableSHA1InWant) ||\n\t\tar.Capabilities.Supports(capability.AllowTipSHA1InWant) {\n\t\treturn nil\n\t}\n\n\treturn ErrExactSHA1NotSupported\n}\n\nfunc buildSidebandIfSupported(l *capability.List, reader io.Reader, p sideband.Progress) io.Reader {\n\tvar t sideband.Type\n\n\tswitch {\n\tcase l.Supports(capability.Sideband):\n\t\tt = sideband.Sideband\n\tcase l.Supports(capability.Sideband64k):\n\t\tt = sideband.Sideband64k\n\tdefault:\n\t\treturn reader\n\t}\n\n\td := sideband.NewDemuxer(t, reader)\n\td.Progress = p\n\n\treturn d\n}\n\nfunc (r *Remote) updateLocalReferenceStorage(\n\tspecs []config.RefSpec,\n\tfetchedRefs, remoteRefs memory.ReferenceStorage,\n\tspecToRefs [][]*plumbing.Reference,\n\ttagMode TagMode,\n\tforce bool,\n) (updated bool, err error) {\n\tisWildcard := true\n\tforceNeeded := false\n\n\tfor i, spec := range specs {\n\t\tif !spec.IsWildcard() {\n\t\t\tisWildcard = false\n\t\t}\n\n\t\tfor _, ref := range specToRefs[i] {\n\t\t\tif ref.Type() != plumbing.HashReference {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tlocalName := spec.Dst(ref.Name())\n\t\t\t// If localName doesn't start with \"refs/\" then treat as a branch.\n\t\t\tif !strings.HasPrefix(localName.String(), \"refs/\") {\n\t\t\t\tlocalName = plumbing.NewBranchReferenceName(localName.String())\n\t\t\t}\n\t\t\told, _ := storer.ResolveReference(r.s, localName)\n\t\t\tnew := plumbing.NewHashReference(localName, ref.Hash())\n\n\t\t\t// If the ref exists locally as a non-tag and force is not\n\t\t\t// specified, only update if the new ref is an ancestor of the old\n\t\t\tif old != nil && !old.Name().IsTag() && !force && !spec.IsForceUpdate() {\n\t\t\t\tff, err := isFastForward(r.s, old.Hash(), new.Hash(), nil)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn updated, err\n\t\t\t\t}\n\n\t\t\t\tif !ff {\n\t\t\t\t\tforceNeeded = true\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\n\t\t\trefUpdated, err := checkAndUpdateReferenceStorerIfNeeded(r.s, new, old)\n\t\t\tif err != nil {\n\t\t\t\treturn updated, err\n\t\t\t}\n\n\t\t\tif refUpdated {\n\t\t\t\tupdated = true\n\t\t\t}\n\t\t}\n\t}\n\n\tif tagMode == NoTags {\n\t\treturn updated, nil\n\t}\n\n\ttags := fetchedRefs\n\tif isWildcard {\n\t\ttags = remoteRefs\n\t}\n\ttagUpdated, err := r.buildFetchedTags(tags)\n\tif err != nil {\n\t\treturn updated, err\n\t}\n\n\tif tagUpdated {\n\t\tupdated = true\n\t}\n\n\tif forceNeeded {\n\t\terr = ErrForceNeeded\n\t}\n\n\treturn\n}\n\nfunc (r *Remote) buildFetchedTags(refs memory.ReferenceStorage) (updated bool, err error) {\n\tfor _, ref := range refs {\n\t\tif !ref.Name().IsTag() {\n\t\t\tcontinue\n\t\t}\n\n\t\t_, err := r.s.EncodedObject(plumbing.AnyObject, ref.Hash())\n\t\tif err == plumbing.ErrObjectNotFound {\n\t\t\tcontinue\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\n\t\trefUpdated, err := updateReferenceStorerIfNeeded(r.s, ref)\n\t\tif err != nil {\n\t\t\treturn updated, err\n\t\t}\n\n\t\tif refUpdated {\n\t\t\tupdated = true\n\t\t}\n\t}\n\n\treturn\n}\n\n// List the references on the remote repository.\n// The provided Context must be non-nil. If the context expires before the\n// operation is complete, an error is returned. The context only affects to the\n// transport operations.\nfunc (r *Remote) ListContext(ctx context.Context, o *ListOptions) (rfs []*plumbing.Reference, err error) {\n\treturn r.list(ctx, o)\n}\n\nfunc (r *Remote) List(o *ListOptions) (rfs []*plumbing.Reference, err error) {\n\ttimeout := o.Timeout\n\t// Default to the old hardcoded 10s value if a timeout is not explicitly set.\n\tif timeout == 0 {\n\t\ttimeout = 10\n\t}\n\tif timeout < 0 {\n\t\treturn nil, fmt.Errorf(\"invalid timeout: %d\", timeout)\n\t}\n\tctx, cancel := context.WithTimeout(context.Background(), time.Duration(timeout)*time.Second)\n\tdefer cancel()\n\treturn r.ListContext(ctx, o)\n}\n\nfunc (r *Remote) list(ctx context.Context, o *ListOptions) (rfs []*plumbing.Reference, err error) {\n\tif r.c == nil || len(r.c.URLs) == 0 {\n\t\treturn nil, ErrEmptyUrls\n\t}\n\n\ts, err := newUploadPackSession(r.c.URLs[0], o.Auth, o.InsecureSkipTLS, o.CABundle, o.ProxyOptions)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdefer ioutil.CheckClose(s, &err)\n\n\tar, err := s.AdvertisedReferencesContext(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tallRefs, err := ar.AllReferences()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\trefs, err := allRefs.IterReferences()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar resultRefs []*plumbing.Reference\n\tif o.PeelingOption == AppendPeeled || o.PeelingOption == IgnorePeeled {\n\t\terr = refs.ForEach(func(ref *plumbing.Reference) error {\n\t\t\tresultRefs = append(resultRefs, ref)\n\t\t\treturn nil\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif o.PeelingOption == AppendPeeled || o.PeelingOption == OnlyPeeled {\n\t\tfor k, v := range ar.Peeled {\n\t\t\tresultRefs = append(resultRefs, plumbing.NewReferenceFromStrings(k+\"^{}\", v.String()))\n\t\t}\n\t}\n\n\treturn resultRefs, nil\n}\n\nfunc objectsToPush(commands []*packp.Command) []plumbing.Hash {\n\tobjects := make([]plumbing.Hash, 0, len(commands))\n\tfor _, cmd := range commands {\n\t\tif cmd.New == plumbing.ZeroHash {\n\t\t\tcontinue\n\t\t}\n\t\tobjects = append(objects, cmd.New)\n\t}\n\treturn objects\n}\n\nfunc referencesToHashes(refs storer.ReferenceStorer) ([]plumbing.Hash, error) {\n\titer, err := refs.IterReferences()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar hs []plumbing.Hash\n\terr = iter.ForEach(func(ref *plumbing.Reference) error {\n\t\tif ref.Type() != plumbing.HashReference {\n\t\t\treturn nil\n\t\t}\n\n\t\ths = append(hs, ref.Hash())\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn hs, nil\n}\n\nfunc pushHashes(\n\tctx context.Context,\n\tsess transport.ReceivePackSession,\n\ts storage.Storer,\n\treq *packp.ReferenceUpdateRequest,\n\ths []plumbing.Hash,\n\tuseRefDeltas bool,\n\tallDelete bool,\n) (*packp.ReportStatus, error) {\n\trd, wr := io.Pipe()\n\n\tconfig, err := s.Config()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Set buffer size to 1 so the error message can be written when\n\t// ReceivePack fails. Otherwise the goroutine will be blocked writing\n\t// to the channel.\n\tdone := make(chan error, 1)\n\n\tif !allDelete {\n\t\treq.Packfile = rd\n\t\tgo func() {\n\t\t\te := packfile.NewEncoder(wr, s, useRefDeltas)\n\t\t\tif _, err := e.Encode(hs, config.Pack.Window); err != nil {\n\t\t\t\tdone <- wr.CloseWithError(err)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tdone <- wr.Close()\n\t\t}()\n\t} else {\n\t\tclose(done)\n\t}\n\n\trs, err := sess.ReceivePack(ctx, req)\n\tif err != nil {\n\t\t// close the pipe to unlock encode write\n\t\t_ = rd.Close()\n\t\treturn nil, err\n\t}\n\n\tif err := <-done; err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn rs, nil\n}\n\nfunc (r *Remote) updateShallow(o *FetchOptions, resp *packp.UploadPackResponse) error {\n\tif o.Depth == 0 || len(resp.Shallows) == 0 {\n\t\treturn nil\n\t}\n\n\tshallows, err := r.s.Shallow()\n\tif err != nil {\n\t\treturn err\n\t}\n\nouter:\n\tfor _, s := range resp.Shallows {\n\t\tfor _, oldS := range shallows {\n\t\t\tif s == oldS {\n\t\t\t\tcontinue outer\n\t\t\t}\n\t\t}\n\t\tshallows = append(shallows, s)\n\t}\n\n\treturn r.s.SetShallow(shallows)\n}\n\nfunc (r *Remote) checkRequireRemoteRefs(requires []config.RefSpec, remoteRefs storer.ReferenceStorer) error {\n\tfor _, require := range requires {\n\t\tif require.IsWildcard() {\n\t\t\treturn fmt.Errorf(\"wildcards not supported in RequireRemoteRefs, got %s\", require.String())\n\t\t}\n\n\t\tname := require.Dst(\"\")\n\t\tremote, err := remoteRefs.Reference(name)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"remote ref %s required to be %s but is absent\", name.String(), require.Src())\n\t\t}\n\n\t\tvar requireHash string\n\t\tif require.IsExactSHA1() {\n\t\t\trequireHash = require.Src()\n\t\t} else {\n\t\t\ttarget, err := storer.ResolveReference(remoteRefs, plumbing.ReferenceName(require.Src()))\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"could not resolve ref %s in RequireRemoteRefs\", require.Src())\n\t\t\t}\n\t\t\trequireHash = target.Hash().String()\n\t\t}\n\n\t\tif remote.Hash().String() != requireHash {\n\t\t\treturn fmt.Errorf(\"remote ref %s required to be %s but is %s\", name.String(), requireHash, remote.Hash().String())\n\t\t}\n\t}\n\treturn nil\n}\n"
        },
        {
          "name": "remote_test.go",
          "type": "blob",
          "size": 51.498046875,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/go-git/go-billy/v5/memfs\"\n\t\"github.com/go-git/go-billy/v5/osfs\"\n\t\"github.com/go-git/go-billy/v5/util\"\n\n\t\"github.com/go-git/go-git/v5/config\"\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/plumbing/cache\"\n\t\"github.com/go-git/go-git/v5/plumbing/object\"\n\t\"github.com/go-git/go-git/v5/plumbing/protocol/packp\"\n\t\"github.com/go-git/go-git/v5/plumbing/protocol/packp/capability\"\n\t\"github.com/go-git/go-git/v5/plumbing/storer\"\n\t\"github.com/go-git/go-git/v5/storage\"\n\t\"github.com/go-git/go-git/v5/storage/filesystem\"\n\t\"github.com/go-git/go-git/v5/storage/memory\"\n\n\tfixtures \"github.com/go-git/go-git-fixtures/v4\"\n\t. \"gopkg.in/check.v1\"\n)\n\ntype RemoteSuite struct {\n\tBaseSuite\n}\n\nvar _ = Suite(&RemoteSuite{})\n\nfunc (s *RemoteSuite) TestFetchInvalidEndpoint(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{Name: \"foo\", URLs: []string{\"http://\\\\\"}})\n\terr := r.Fetch(&FetchOptions{RemoteName: \"foo\"})\n\tc.Assert(err, ErrorMatches, \".*invalid character.*\")\n}\n\nfunc (s *RemoteSuite) TestFetchNonExistentEndpoint(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{Name: \"foo\", URLs: []string{\"ssh://non-existent/foo.git\"}})\n\terr := r.Fetch(&FetchOptions{})\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *RemoteSuite) TestFetchInvalidSchemaEndpoint(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{Name: \"foo\", URLs: []string{\"qux://foo\"}})\n\terr := r.Fetch(&FetchOptions{})\n\tc.Assert(err, ErrorMatches, \".*unsupported scheme.*\")\n}\n\nfunc (s *RemoteSuite) TestFetchOverriddenEndpoint(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{Name: \"foo\", URLs: []string{\"http://perfectly-valid-url.example.com\"}})\n\terr := r.Fetch(&FetchOptions{RemoteURL: \"http://\\\\\"})\n\tc.Assert(err, ErrorMatches, \".*invalid character.*\")\n}\n\nfunc (s *RemoteSuite) TestFetchInvalidFetchOptions(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{Name: \"foo\", URLs: []string{\"qux://foo\"}})\n\tinvalid := config.RefSpec(\"^*$ñ\")\n\terr := r.Fetch(&FetchOptions{RefSpecs: []config.RefSpec{invalid}})\n\tc.Assert(err, Equals, config.ErrRefSpecMalformedSeparator)\n}\n\nfunc (s *RemoteSuite) TestFetchWildcard(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\n\ts.testFetch(c, r, &FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/*:refs/remotes/origin/*\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/remotes/origin/master\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/remotes/origin/branch\", \"e8d3ffab552895c19b9fcf7aa264d277cde33881\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/v1.0.0\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t})\n}\n\nfunc (s *RemoteSuite) TestFetchExactSHA1(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{\"https://github.com/git-fixtures/basic.git\"},\n\t})\n\n\ts.testFetch(c, r, &FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"35e85108805c84807bc66a02d91535e1e24b38b9:refs/heads/foo\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/heads/foo\", \"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t})\n}\n\nfunc (s *RemoteSuite) TestFetchExactSHA1_NotSoported(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\n\terr := r.Fetch(&FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"35e85108805c84807bc66a02d91535e1e24b38b9:refs/heads/foo\"),\n\t\t},\n\t})\n\n\tc.Assert(err, Equals, ErrExactSHA1NotSupported)\n\n}\n\nfunc (s *RemoteSuite) TestFetchWildcardTags(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetLocalRepositoryURL(fixtures.ByTag(\"tags\").One())},\n\t})\n\n\ts.testFetch(c, r, &FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/*:refs/remotes/origin/*\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/remotes/origin/master\", \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/annotated-tag\", \"b742a2a9fa0afcfa9a6fad080980fbc26b007c69\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/tree-tag\", \"152175bf7e5580299fa1f0ba41ef6474cc043b70\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/commit-tag\", \"ad7897c0fb8e7d9a9ba41fa66072cf06095a6cfc\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/blob-tag\", \"fe6cb94756faa81e5ed9240f9191b833db5f40ae\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/lightweight-tag\", \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\"),\n\t})\n}\n\nfunc (s *RemoteSuite) TestFetch(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetLocalRepositoryURL(fixtures.ByTag(\"tags\").One())},\n\t})\n\n\ts.testFetch(c, r, &FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/master:refs/remotes/origin/master\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/remotes/origin/master\", \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\"),\n\t})\n}\n\nfunc (s *RemoteSuite) TestFetchToNewBranch(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetLocalRepositoryURL(fixtures.ByTag(\"tags\").One())},\n\t})\n\n\ts.testFetch(c, r, &FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\t// qualified branch to unqualified branch\n\t\t\t\"refs/heads/master:foo\",\n\t\t\t// unqualified branch to unqualified branch\n\t\t\t\"+master:bar\",\n\t\t\t// unqualified tag to unqualified branch\n\t\t\tconfig.RefSpec(\"tree-tag:tree-tag\"),\n\t\t\t// unqualified tag to qualified tag\n\t\t\tconfig.RefSpec(\"+commit-tag:refs/tags/renamed-tag\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/heads/foo\", \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/heads/bar\", \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/heads/tree-tag\", \"152175bf7e5580299fa1f0ba41ef6474cc043b70\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/tree-tag\", \"152175bf7e5580299fa1f0ba41ef6474cc043b70\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/renamed-tag\", \"ad7897c0fb8e7d9a9ba41fa66072cf06095a6cfc\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/commit-tag\", \"ad7897c0fb8e7d9a9ba41fa66072cf06095a6cfc\"),\n\t})\n}\n\nfunc (s *RemoteSuite) TestFetchToNewBranchWithAllTags(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetLocalRepositoryURL(fixtures.ByTag(\"tags\").One())},\n\t})\n\n\ts.testFetch(c, r, &FetchOptions{\n\t\tTags: AllTags,\n\t\tRefSpecs: []config.RefSpec{\n\t\t\t// qualified branch to unqualified branch\n\t\t\t\"+refs/heads/master:foo\",\n\t\t\t// unqualified branch to unqualified branch\n\t\t\t\"master:bar\",\n\t\t\t// unqualified tag to unqualified branch\n\t\t\tconfig.RefSpec(\"+tree-tag:tree-tag\"),\n\t\t\t// unqualified tag to qualified tag\n\t\t\tconfig.RefSpec(\"commit-tag:refs/tags/renamed-tag\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/heads/foo\", \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/heads/bar\", \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/heads/tree-tag\", \"152175bf7e5580299fa1f0ba41ef6474cc043b70\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/tree-tag\", \"152175bf7e5580299fa1f0ba41ef6474cc043b70\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/renamed-tag\", \"ad7897c0fb8e7d9a9ba41fa66072cf06095a6cfc\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/commit-tag\", \"ad7897c0fb8e7d9a9ba41fa66072cf06095a6cfc\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/annotated-tag\", \"b742a2a9fa0afcfa9a6fad080980fbc26b007c69\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/blob-tag\", \"fe6cb94756faa81e5ed9240f9191b833db5f40ae\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/lightweight-tag\", \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\"),\n\t})\n}\n\nfunc (s *RemoteSuite) TestFetchNonExistentReference(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetLocalRepositoryURL(fixtures.ByTag(\"tags\").One())},\n\t})\n\n\terr := r.Fetch(&FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/foo:refs/remotes/origin/foo\"),\n\t\t},\n\t})\n\n\tc.Assert(err, ErrorMatches, \"couldn't find remote ref.*\")\n\tc.Assert(errors.Is(err, NoMatchingRefSpecError{}), Equals, true)\n}\n\nfunc (s *RemoteSuite) TestFetchContext(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetLocalRepositoryURL(fixtures.ByTag(\"tags\").One())},\n\t})\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\n\terr := r.FetchContext(ctx, &FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/master:refs/remotes/origin/master\"),\n\t\t},\n\t})\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *RemoteSuite) TestFetchContextCanceled(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetLocalRepositoryURL(fixtures.ByTag(\"tags\").One())},\n\t})\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\n\terr := r.FetchContext(ctx, &FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/master:refs/remotes/origin/master\"),\n\t\t},\n\t})\n\tc.Assert(err, Equals, context.Canceled)\n}\n\nfunc (s *RemoteSuite) TestFetchWithAllTags(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetLocalRepositoryURL(fixtures.ByTag(\"tags\").One())},\n\t})\n\n\ts.testFetch(c, r, &FetchOptions{\n\t\tTags: AllTags,\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/master:refs/remotes/origin/master\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/remotes/origin/master\", \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/annotated-tag\", \"b742a2a9fa0afcfa9a6fad080980fbc26b007c69\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/tree-tag\", \"152175bf7e5580299fa1f0ba41ef6474cc043b70\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/commit-tag\", \"ad7897c0fb8e7d9a9ba41fa66072cf06095a6cfc\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/blob-tag\", \"fe6cb94756faa81e5ed9240f9191b833db5f40ae\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/lightweight-tag\", \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\"),\n\t})\n}\n\nfunc (s *RemoteSuite) TestFetchWithNoTags(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetLocalRepositoryURL(fixtures.ByTag(\"tags\").One())},\n\t})\n\n\ts.testFetch(c, r, &FetchOptions{\n\t\tTags: NoTags,\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/*:refs/remotes/origin/*\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/remotes/origin/master\", \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\"),\n\t})\n\n}\n\nfunc (s *RemoteSuite) TestFetchWithDepth(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\n\ts.testFetch(c, r, &FetchOptions{\n\t\tDepth: 1,\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/*:refs/remotes/origin/*\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/remotes/origin/master\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/remotes/origin/branch\", \"e8d3ffab552895c19b9fcf7aa264d277cde33881\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/v1.0.0\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t})\n\n\tc.Assert(r.s.(*memory.Storage).Objects, HasLen, 18)\n}\n\nfunc (s *RemoteSuite) TestFetchWithDepthChange(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\n\ts.testFetch(c, r, &FetchOptions{\n\t\tDepth: 1,\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"refs/heads/master:refs/heads/master\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/heads/master\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t})\n\tc.Assert(r.s.(*memory.Storage).Commits, HasLen, 1)\n\n\ts.testFetch(c, r, &FetchOptions{\n\t\tDepth: 3,\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"refs/heads/master:refs/heads/master\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/heads/master\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t})\n\tc.Assert(r.s.(*memory.Storage).Commits, HasLen, 3)\n}\n\nfunc (s *RemoteSuite) testFetch(c *C, r *Remote, o *FetchOptions, expected []*plumbing.Reference) {\n\terr := r.Fetch(o)\n\tc.Assert(err, IsNil)\n\n\tvar refs int\n\tl, err := r.s.IterReferences()\n\tc.Assert(err, IsNil)\n\tl.ForEach(func(r *plumbing.Reference) error { refs++; return nil })\n\n\tc.Assert(refs, Equals, len(expected))\n\n\tfor _, exp := range expected {\n\t\tr, err := r.s.Reference(exp.Name())\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(exp.String(), Equals, r.String())\n\t}\n}\n\nfunc (s *RemoteSuite) TestFetchOfMissingObjects(c *C) {\n\ttmp := c.MkDir()\n\n\t// clone to a local temp folder\n\t_, err := PlainClone(tmp, true, &CloneOptions{\n\t\tURL: fixtures.Basic().One().DotGit().Root(),\n\t})\n\tc.Assert(err, IsNil)\n\n\t// Delete the pack files\n\tfsTmp := osfs.New(tmp)\n\terr = util.RemoveAll(fsTmp, \"objects/pack\")\n\tc.Assert(err, IsNil)\n\n\t// Reopen the repo from the filesystem (with missing objects)\n\tr, err := Open(filesystem.NewStorage(fsTmp, cache.NewObjectLRUDefault()), nil)\n\tc.Assert(err, IsNil)\n\n\t// Confirm we are missing a commit\n\t_, err = r.CommitObject(plumbing.NewHash(\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"))\n\tc.Assert(err, Equals, plumbing.ErrObjectNotFound)\n\n\t// Refetch to get all the missing objects\n\terr = r.Fetch(&FetchOptions{})\n\tc.Assert(err, IsNil)\n\n\t// Confirm we now have the commit\n\t_, err = r.CommitObject(plumbing.NewHash(\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"))\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *RemoteSuite) TestFetchWithProgress(c *C) {\n\turl := s.GetBasicLocalRepositoryURL()\n\tsto := memory.NewStorage()\n\tbuf := bytes.NewBuffer(nil)\n\n\tr := NewRemote(sto, &config.RemoteConfig{Name: \"foo\", URLs: []string{url}})\n\n\trefspec := config.RefSpec(\"+refs/heads/*:refs/remotes/origin/*\")\n\terr := r.Fetch(&FetchOptions{\n\t\tRefSpecs: []config.RefSpec{refspec},\n\t\tProgress: buf,\n\t})\n\n\tc.Assert(err, IsNil)\n\tc.Assert(sto.Objects, HasLen, 31)\n\n\tc.Assert(buf.Len(), Not(Equals), 0)\n}\n\ntype mockPackfileWriter struct {\n\tstorage.Storer\n\tPackfileWriterCalled bool\n}\n\nfunc (m *mockPackfileWriter) PackfileWriter() (io.WriteCloser, error) {\n\tm.PackfileWriterCalled = true\n\treturn m.Storer.(storer.PackfileWriter).PackfileWriter()\n}\n\nfunc (s *RemoteSuite) TestFetchWithPackfileWriter(c *C) {\n\tfs := s.TemporalFilesystem(c)\n\n\tfss := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\tmock := &mockPackfileWriter{Storer: fss}\n\n\turl := s.GetBasicLocalRepositoryURL()\n\tr := NewRemote(mock, &config.RemoteConfig{Name: \"foo\", URLs: []string{url}})\n\n\trefspec := config.RefSpec(\"+refs/heads/*:refs/remotes/origin/*\")\n\terr := r.Fetch(&FetchOptions{\n\t\tRefSpecs: []config.RefSpec{refspec},\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tvar count int\n\titer, err := mock.IterEncodedObjects(plumbing.AnyObject)\n\tc.Assert(err, IsNil)\n\n\titer.ForEach(func(plumbing.EncodedObject) error {\n\t\tcount++\n\t\treturn nil\n\t})\n\n\tc.Assert(count, Equals, 31)\n\tc.Assert(mock.PackfileWriterCalled, Equals, true)\n}\n\nfunc (s *RemoteSuite) TestFetchNoErrAlreadyUpToDate(c *C) {\n\turl := s.GetBasicLocalRepositoryURL()\n\ts.doTestFetchNoErrAlreadyUpToDate(c, url)\n}\n\nfunc (s *RemoteSuite) TestFetchNoErrAlreadyUpToDateButStillUpdateLocalRemoteRefs(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\n\to := &FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/*:refs/remotes/origin/*\"),\n\t\t},\n\t}\n\n\terr := r.Fetch(o)\n\tc.Assert(err, IsNil)\n\n\t// Simulate an out of date remote ref even though we have the new commit locally\n\tr.s.SetReference(plumbing.NewReferenceFromStrings(\n\t\t\"refs/remotes/origin/master\", \"918c48b83bd081e863dbe1b80f8998f058cd8294\",\n\t))\n\n\terr = r.Fetch(o)\n\tc.Assert(err, IsNil)\n\n\texp := plumbing.NewReferenceFromStrings(\n\t\t\"refs/remotes/origin/master\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t)\n\n\tref, err := r.s.Reference(\"refs/remotes/origin/master\")\n\tc.Assert(err, IsNil)\n\tc.Assert(exp.String(), Equals, ref.String())\n}\n\nfunc (s *RemoteSuite) TestFetchNoErrAlreadyUpToDateWithNonCommitObjects(c *C) {\n\tfixture := fixtures.ByTag(\"tags\").One()\n\turl := s.GetLocalRepositoryURL(fixture)\n\ts.doTestFetchNoErrAlreadyUpToDate(c, url)\n}\n\nfunc (s *RemoteSuite) doTestFetchNoErrAlreadyUpToDate(c *C, url string) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{URLs: []string{url}})\n\n\to := &FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/*:refs/remotes/origin/*\"),\n\t\t},\n\t}\n\n\terr := r.Fetch(o)\n\tc.Assert(err, IsNil)\n\terr = r.Fetch(o)\n\tc.Assert(err, Equals, NoErrAlreadyUpToDate)\n}\n\nfunc (s *RemoteSuite) testFetchFastForward(c *C, sto storage.Storer) {\n\tr := NewRemote(sto, &config.RemoteConfig{\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\n\ts.testFetch(c, r, &FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/master:refs/heads/master\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/heads/master\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t})\n\n\t// First make sure that we error correctly when a force is required.\n\terr := r.Fetch(&FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"refs/heads/branch:refs/heads/master\"),\n\t\t},\n\t})\n\tc.Assert(err, Equals, ErrForceNeeded)\n\n\t// And that forcing it fixes the problem.\n\terr = r.Fetch(&FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/branch:refs/heads/master\"),\n\t\t},\n\t})\n\tc.Assert(err, IsNil)\n\n\t// Now test that a fast-forward, non-force fetch works.\n\tr.s.SetReference(plumbing.NewReferenceFromStrings(\n\t\t\"refs/heads/master\", \"918c48b83bd081e863dbe1b80f8998f058cd8294\",\n\t))\n\ts.testFetch(c, r, &FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"refs/heads/master:refs/heads/master\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/heads/master\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t})\n}\n\nfunc (s *RemoteSuite) TestFetchFastForwardMem(c *C) {\n\ts.testFetchFastForward(c, memory.NewStorage())\n}\n\nfunc (s *RemoteSuite) TestFetchFastForwardFS(c *C) {\n\tfs := s.TemporalFilesystem(c)\n\n\tfss := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\n\t// This exercises `storage.filesystem.Storage.CheckAndSetReference()`.\n\ts.testFetchFastForward(c, fss)\n}\n\nfunc (s *RemoteSuite) TestString(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{\n\t\tName: \"foo\",\n\t\tURLs: []string{\"https://github.com/git-fixtures/basic.git\"},\n\t})\n\n\tc.Assert(r.String(), Equals, \"\"+\n\t\t\"foo\\thttps://github.com/git-fixtures/basic.git (fetch)\\n\"+\n\t\t\"foo\\thttps://github.com/git-fixtures/basic.git (push)\",\n\t)\n}\n\nfunc (s *RemoteSuite) TestPushToEmptyRepository(c *C) {\n\turl := c.MkDir()\n\n\tserver, err := PlainInit(url, true)\n\tc.Assert(err, IsNil)\n\n\tsrcFs := fixtures.Basic().One().DotGit()\n\tsto := filesystem.NewStorage(srcFs, cache.NewObjectLRUDefault())\n\n\tr := NewRemote(sto, &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{url},\n\t})\n\n\trs := config.RefSpec(\"refs/heads/*:refs/heads/*\")\n\terr = r.Push(&PushOptions{\n\t\tRefSpecs: []config.RefSpec{rs},\n\t})\n\tc.Assert(err, IsNil)\n\n\titer, err := r.s.IterReferences()\n\tc.Assert(err, IsNil)\n\n\texpected := make(map[string]string)\n\titer.ForEach(func(ref *plumbing.Reference) error {\n\t\tif !ref.Name().IsBranch() {\n\t\t\treturn nil\n\t\t}\n\n\t\texpected[ref.Name().String()] = ref.Hash().String()\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, server, expected)\n\n}\n\nfunc (s *RemoteSuite) TestPushContext(c *C) {\n\turl := c.MkDir()\n\n\t_, err := PlainInit(url, true)\n\tc.Assert(err, IsNil)\n\n\tfs := fixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One().DotGit()\n\tsto := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\n\tr := NewRemote(sto, &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{url},\n\t})\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\n\tnumGoroutines := runtime.NumGoroutine()\n\n\terr = r.PushContext(ctx, &PushOptions{\n\t\tRefSpecs: []config.RefSpec{\"refs/tags/*:refs/tags/*\"},\n\t})\n\tc.Assert(err, IsNil)\n\n\teventually(c, func() bool {\n\t\treturn runtime.NumGoroutine() <= numGoroutines\n\t})\n}\n\nfunc eventually(c *C, condition func() bool) {\n\tselect {\n\tcase <-time.After(5 * time.Second):\n\tdefault:\n\t\tif condition() {\n\t\t\tbreak\n\t\t}\n\t\ttime.Sleep(100 * time.Millisecond)\n\t}\n\n\tc.Assert(condition(), Equals, true)\n}\n\nfunc (s *RemoteSuite) TestPushContextCanceled(c *C) {\n\turl := c.MkDir()\n\n\t_, err := PlainInit(url, true)\n\tc.Assert(err, IsNil)\n\n\tfs := fixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One().DotGit()\n\tsto := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\n\tr := NewRemote(sto, &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{url},\n\t})\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\n\tnumGoroutines := runtime.NumGoroutine()\n\n\terr = r.PushContext(ctx, &PushOptions{\n\t\tRefSpecs: []config.RefSpec{\"refs/tags/*:refs/tags/*\"},\n\t})\n\tc.Assert(err, Equals, context.Canceled)\n\n\teventually(c, func() bool {\n\t\treturn runtime.NumGoroutine() <= numGoroutines\n\t})\n}\n\nfunc (s *RemoteSuite) TestPushTags(c *C) {\n\turl := c.MkDir()\n\n\tserver, err := PlainInit(url, true)\n\tc.Assert(err, IsNil)\n\n\tfs := fixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One().DotGit()\n\tsto := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\n\tr := NewRemote(sto, &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{url},\n\t})\n\n\terr = r.Push(&PushOptions{\n\t\tRefSpecs: []config.RefSpec{\"refs/tags/*:refs/tags/*\"},\n\t})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, server, map[string]string{\n\t\t\"refs/tags/lightweight-tag\": \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\",\n\t\t\"refs/tags/annotated-tag\":   \"b742a2a9fa0afcfa9a6fad080980fbc26b007c69\",\n\t\t\"refs/tags/commit-tag\":      \"ad7897c0fb8e7d9a9ba41fa66072cf06095a6cfc\",\n\t\t\"refs/tags/blob-tag\":        \"fe6cb94756faa81e5ed9240f9191b833db5f40ae\",\n\t\t\"refs/tags/tree-tag\":        \"152175bf7e5580299fa1f0ba41ef6474cc043b70\",\n\t})\n}\n\nfunc (s *RemoteSuite) TestPushFollowTags(c *C) {\n\turl := c.MkDir()\n\n\tserver, err := PlainInit(url, true)\n\tc.Assert(err, IsNil)\n\n\tfs := fixtures.ByURL(\"https://github.com/git-fixtures/basic.git\").One().DotGit()\n\tsto := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\n\tr := NewRemote(sto, &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{url},\n\t})\n\n\tlocalRepo := newRepository(sto, fs)\n\ttipTag, err := localRepo.CreateTag(\n\t\t\"tip\",\n\t\tplumbing.NewHash(\"e8d3ffab552895c19b9fcf7aa264d277cde33881\"),\n\t\t&CreateTagOptions{\n\t\t\tMessage: \"an annotated tag\",\n\t\t},\n\t)\n\tc.Assert(err, IsNil)\n\n\tinitialTag, err := localRepo.CreateTag(\n\t\t\"initial-commit\",\n\t\tplumbing.NewHash(\"b029517f6300c2da0f4b651b8642506cd6aaf45d\"),\n\t\t&CreateTagOptions{\n\t\t\tMessage: \"a tag for the initial commit\",\n\t\t},\n\t)\n\tc.Assert(err, IsNil)\n\n\t_, err = localRepo.CreateTag(\n\t\t\"master-tag\",\n\t\tplumbing.NewHash(\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t\t&CreateTagOptions{\n\t\t\tMessage: \"a tag with a commit not reachable from branch\",\n\t\t},\n\t)\n\tc.Assert(err, IsNil)\n\n\terr = r.Push(&PushOptions{\n\t\tRefSpecs:   []config.RefSpec{\"+refs/heads/branch:refs/heads/branch\"},\n\t\tFollowTags: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, server, map[string]string{\n\t\t\"refs/heads/branch\":        \"e8d3ffab552895c19b9fcf7aa264d277cde33881\",\n\t\t\"refs/tags/tip\":            tipTag.Hash().String(),\n\t\t\"refs/tags/initial-commit\": initialTag.Hash().String(),\n\t})\n\n\tAssertReferencesMissing(c, server, []string{\n\t\t\"refs/tags/master-tag\",\n\t})\n}\n\nfunc (s *RemoteSuite) TestPushNoErrAlreadyUpToDate(c *C) {\n\tfs := fixtures.Basic().One().DotGit()\n\tsto := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\n\tr := NewRemote(sto, &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{fs.Root()},\n\t})\n\n\terr := r.Push(&PushOptions{\n\t\tRefSpecs: []config.RefSpec{\"refs/heads/*:refs/heads/*\"},\n\t})\n\tc.Assert(err, Equals, NoErrAlreadyUpToDate)\n}\n\nfunc (s *RemoteSuite) TestPushDeleteReference(c *C) {\n\tfs := fixtures.Basic().One().DotGit()\n\tsto := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\n\turl := c.MkDir()\n\n\tr, err := PlainClone(url, true, &CloneOptions{\n\t\tURL: fs.Root(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tremote, err := r.Remote(DefaultRemoteName)\n\tc.Assert(err, IsNil)\n\n\terr = remote.Push(&PushOptions{\n\t\tRefSpecs: []config.RefSpec{\":refs/heads/branch\"},\n\t})\n\tc.Assert(err, IsNil)\n\n\t_, err = sto.Reference(plumbing.ReferenceName(\"refs/heads/branch\"))\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n\n\t_, err = r.Storer.Reference(plumbing.ReferenceName(\"refs/heads/branch\"))\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n}\n\nfunc (s *RemoteSuite) TestForcePushDeleteReference(c *C) {\n\tfs := fixtures.Basic().One().DotGit()\n\tsto := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\n\turl := c.MkDir()\n\n\tr, err := PlainClone(url, true, &CloneOptions{\n\t\tURL: fs.Root(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tremote, err := r.Remote(DefaultRemoteName)\n\tc.Assert(err, IsNil)\n\n\terr = remote.Push(&PushOptions{\n\t\tRefSpecs: []config.RefSpec{\":refs/heads/branch\"},\n\t\tForce:    true,\n\t})\n\tc.Assert(err, IsNil)\n\n\t_, err = sto.Reference(plumbing.ReferenceName(\"refs/heads/branch\"))\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n\n\t_, err = r.Storer.Reference(plumbing.ReferenceName(\"refs/heads/branch\"))\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n}\n\nfunc (s *RemoteSuite) TestPushRejectNonFastForward(c *C) {\n\tfs := fixtures.Basic().One().DotGit()\n\tserver := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\n\turl := c.MkDir()\n\n\tr, err := PlainClone(url, true, &CloneOptions{\n\t\tURL: fs.Root(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tremote, err := r.Remote(DefaultRemoteName)\n\tc.Assert(err, IsNil)\n\n\tbranch := plumbing.ReferenceName(\"refs/heads/branch\")\n\toldRef, err := server.Reference(branch)\n\tc.Assert(err, IsNil)\n\tc.Assert(oldRef, NotNil)\n\n\terr = remote.Push(&PushOptions{RefSpecs: []config.RefSpec{\n\t\t\"refs/heads/master:refs/heads/branch\",\n\t}})\n\tc.Assert(err, ErrorMatches, \"non-fast-forward update: refs/heads/branch\")\n\n\tnewRef, err := server.Reference(branch)\n\tc.Assert(err, IsNil)\n\tc.Assert(newRef, DeepEquals, oldRef)\n}\n\nfunc (s *RemoteSuite) TestPushForce(c *C) {\n\tf := fixtures.Basic().One()\n\tsto := filesystem.NewStorage(f.DotGit(), cache.NewObjectLRUDefault())\n\n\tdstFs := f.DotGit()\n\tdstSto := filesystem.NewStorage(dstFs, cache.NewObjectLRUDefault())\n\n\turl := dstFs.Root()\n\tr := NewRemote(sto, &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{url},\n\t})\n\n\toldRef, err := dstSto.Reference(plumbing.ReferenceName(\"refs/heads/branch\"))\n\tc.Assert(err, IsNil)\n\tc.Assert(oldRef, NotNil)\n\n\terr = r.Push(&PushOptions{RefSpecs: []config.RefSpec{\n\t\tconfig.RefSpec(\"+refs/heads/master:refs/heads/branch\"),\n\t}})\n\tc.Assert(err, IsNil)\n\n\tnewRef, err := dstSto.Reference(plumbing.ReferenceName(\"refs/heads/branch\"))\n\tc.Assert(err, IsNil)\n\tc.Assert(newRef, Not(DeepEquals), oldRef)\n}\n\nfunc (s *RemoteSuite) TestPushForceWithOption(c *C) {\n\tf := fixtures.Basic().One()\n\tsto := filesystem.NewStorage(f.DotGit(), cache.NewObjectLRUDefault())\n\n\tdstFs := f.DotGit()\n\tdstSto := filesystem.NewStorage(dstFs, cache.NewObjectLRUDefault())\n\n\turl := dstFs.Root()\n\tr := NewRemote(sto, &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{url},\n\t})\n\n\toldRef, err := dstSto.Reference(plumbing.ReferenceName(\"refs/heads/branch\"))\n\tc.Assert(err, IsNil)\n\tc.Assert(oldRef, NotNil)\n\n\terr = r.Push(&PushOptions{\n\t\tRefSpecs: []config.RefSpec{\"refs/heads/master:refs/heads/branch\"},\n\t\tForce:    true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tnewRef, err := dstSto.Reference(plumbing.ReferenceName(\"refs/heads/branch\"))\n\tc.Assert(err, IsNil)\n\tc.Assert(newRef, Not(DeepEquals), oldRef)\n}\n\nfunc (s *RemoteSuite) TestPushForceWithLease_success(c *C) {\n\ttestCases := []struct {\n\t\tdesc           string\n\t\tforceWithLease ForceWithLease\n\t}{\n\t\t{\n\t\t\tdesc:           \"no arguments\",\n\t\t\tforceWithLease: ForceWithLease{},\n\t\t},\n\t\t{\n\t\t\tdesc: \"ref name\",\n\t\t\tforceWithLease: ForceWithLease{\n\t\t\t\tRefName: plumbing.ReferenceName(\"refs/heads/branch\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tdesc: \"ref name and sha\",\n\t\t\tforceWithLease: ForceWithLease{\n\t\t\t\tRefName: plumbing.ReferenceName(\"refs/heads/branch\"),\n\t\t\t\tHash:    plumbing.NewHash(\"e8d3ffab552895c19b9fcf7aa264d277cde33881\"),\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tc.Log(\"Executing test cases:\", tc.desc)\n\n\t\tf := fixtures.Basic().One()\n\t\tsto := filesystem.NewStorage(f.DotGit(), cache.NewObjectLRUDefault())\n\t\tdstFs := f.DotGit()\n\t\tdstSto := filesystem.NewStorage(dstFs, cache.NewObjectLRUDefault())\n\n\t\tnewCommit := plumbing.NewHashReference(\n\t\t\t\"refs/heads/branch\", plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t\t)\n\t\tc.Assert(sto.SetReference(newCommit), IsNil)\n\n\t\tref, err := sto.Reference(\"refs/heads/branch\")\n\t\tc.Assert(err, IsNil)\n\t\tc.Log(ref.String())\n\n\t\turl := dstFs.Root()\n\t\tr := NewRemote(sto, &config.RemoteConfig{\n\t\t\tName: DefaultRemoteName,\n\t\t\tURLs: []string{url},\n\t\t})\n\n\t\toldRef, err := dstSto.Reference(\"refs/heads/branch\")\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(oldRef, NotNil)\n\n\t\tc.Assert(r.Push(&PushOptions{\n\t\t\tRefSpecs:       []config.RefSpec{\"refs/heads/branch:refs/heads/branch\"},\n\t\t\tForceWithLease: &ForceWithLease{},\n\t\t}), IsNil)\n\n\t\tnewRef, err := dstSto.Reference(\"refs/heads/branch\")\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(newRef, DeepEquals, newCommit)\n\t}\n}\n\nfunc (s *RemoteSuite) TestPushForceWithLease_failure(c *C) {\n\ttestCases := []struct {\n\t\tdesc           string\n\t\tforceWithLease ForceWithLease\n\t}{\n\t\t{\n\t\t\tdesc:           \"no arguments\",\n\t\t\tforceWithLease: ForceWithLease{},\n\t\t},\n\t\t{\n\t\t\tdesc: \"ref name\",\n\t\t\tforceWithLease: ForceWithLease{\n\t\t\t\tRefName: plumbing.ReferenceName(\"refs/heads/branch\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tdesc: \"ref name and sha\",\n\t\t\tforceWithLease: ForceWithLease{\n\t\t\t\tRefName: plumbing.ReferenceName(\"refs/heads/branch\"),\n\t\t\t\tHash:    plumbing.NewHash(\"152175bf7e5580299fa1f0ba41ef6474cc043b70\"),\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tc.Log(\"Executing test cases:\", tc.desc)\n\n\t\tf := fixtures.Basic().One()\n\t\tsto := filesystem.NewStorage(f.DotGit(), cache.NewObjectLRUDefault())\n\t\tc.Assert(sto.SetReference(\n\t\t\tplumbing.NewHashReference(\n\t\t\t\t\"refs/heads/branch\", plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t\t\t),\n\t\t), IsNil)\n\n\t\tdstFs := f.DotGit()\n\t\tdstSto := filesystem.NewStorage(dstFs, cache.NewObjectLRUDefault())\n\t\tc.Assert(dstSto.SetReference(\n\t\t\tplumbing.NewHashReference(\n\t\t\t\t\"refs/heads/branch\", plumbing.NewHash(\"ad7897c0fb8e7d9a9ba41fa66072cf06095a6cfc\"),\n\t\t\t),\n\t\t), IsNil)\n\n\t\turl := dstFs.Root()\n\t\tr := NewRemote(sto, &config.RemoteConfig{\n\t\t\tName: DefaultRemoteName,\n\t\t\tURLs: []string{url},\n\t\t})\n\n\t\toldRef, err := dstSto.Reference(\"refs/heads/branch\")\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(oldRef, NotNil)\n\n\t\terr = r.Push(&PushOptions{\n\t\t\tRefSpecs:       []config.RefSpec{\"refs/heads/branch:refs/heads/branch\"},\n\t\t\tForceWithLease: &ForceWithLease{},\n\t\t})\n\n\t\tc.Assert(err, DeepEquals, errors.New(\"non-fast-forward update: refs/heads/branch\"))\n\n\t\tnewRef, err := dstSto.Reference(\"refs/heads/branch\")\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(newRef, Not(DeepEquals), plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"))\n\t}\n}\n\nfunc (s *RemoteSuite) TestPushPrune(c *C) {\n\tfs := fixtures.Basic().One().DotGit()\n\n\turl := c.MkDir()\n\n\tserver, err := PlainClone(url, true, &CloneOptions{\n\t\tURL: fs.Root(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tdir := c.MkDir()\n\n\tr, err := PlainClone(dir, true, &CloneOptions{\n\t\tURL: url,\n\t})\n\tc.Assert(err, IsNil)\n\n\ttag, err := r.Reference(plumbing.ReferenceName(\"refs/tags/v1.0.0\"), true)\n\tc.Assert(err, IsNil)\n\n\terr = r.DeleteTag(\"v1.0.0\")\n\tc.Assert(err, IsNil)\n\n\tremote, err := r.Remote(DefaultRemoteName)\n\tc.Assert(err, IsNil)\n\n\tref, err := r.Reference(plumbing.ReferenceName(\"refs/heads/master\"), true)\n\tc.Assert(err, IsNil)\n\n\terr = remote.Push(&PushOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"refs/heads/*:refs/heads/*\"),\n\t\t},\n\t\tPrune: true,\n\t})\n\tc.Assert(err, Equals, NoErrAlreadyUpToDate)\n\n\tAssertReferences(c, server, map[string]string{\n\t\t\"refs/tags/v1.0.0\": tag.Hash().String(),\n\t})\n\n\terr = remote.Push(&PushOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"*:*\"),\n\t\t},\n\t\tPrune: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, server, map[string]string{\n\t\t\"refs/remotes/origin/master\": ref.Hash().String(),\n\t})\n\n\tAssertReferences(c, server, map[string]string{\n\t\t\"refs/remotes/origin/master\": ref.Hash().String(),\n\t})\n\n\t_, err = server.Reference(plumbing.ReferenceName(\"refs/tags/v1.0.0\"), true)\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n}\n\nfunc (s *RemoteSuite) TestPushNewReference(c *C) {\n\tfs := fixtures.Basic().One().DotGit()\n\n\turl := c.MkDir()\n\n\tserver, err := PlainClone(url, true, &CloneOptions{\n\t\tURL: fs.Root(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tdir := c.MkDir()\n\n\tr, err := PlainClone(dir, true, &CloneOptions{\n\t\tURL: url,\n\t})\n\tc.Assert(err, IsNil)\n\n\tremote, err := r.Remote(DefaultRemoteName)\n\tc.Assert(err, IsNil)\n\n\tref, err := r.Reference(plumbing.ReferenceName(\"refs/heads/master\"), true)\n\tc.Assert(err, IsNil)\n\n\terr = remote.Push(&PushOptions{RefSpecs: []config.RefSpec{\n\t\t\"refs/heads/master:refs/heads/branch2\",\n\t}})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, server, map[string]string{\n\t\t\"refs/heads/branch2\": ref.Hash().String(),\n\t})\n\n\tAssertReferences(c, r, map[string]string{\n\t\t\"refs/remotes/origin/branch2\": ref.Hash().String(),\n\t})\n}\n\nfunc (s *RemoteSuite) TestPushNewReferenceAndDeleteInBatch(c *C) {\n\tfs := fixtures.Basic().One().DotGit()\n\n\turl := c.MkDir()\n\n\tserver, err := PlainClone(url, true, &CloneOptions{\n\t\tURL: fs.Root(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tdir := c.MkDir()\n\n\tr, err := PlainClone(dir, true, &CloneOptions{\n\t\tURL: url,\n\t})\n\tc.Assert(err, IsNil)\n\n\tremote, err := r.Remote(DefaultRemoteName)\n\tc.Assert(err, IsNil)\n\n\tref, err := r.Reference(plumbing.ReferenceName(\"refs/heads/master\"), true)\n\tc.Assert(err, IsNil)\n\n\terr = remote.Push(&PushOptions{RefSpecs: []config.RefSpec{\n\t\t\"refs/heads/master:refs/heads/branch2\",\n\t\t\":refs/heads/branch\",\n\t}})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, server, map[string]string{\n\t\t\"refs/heads/branch2\": ref.Hash().String(),\n\t})\n\n\tAssertReferences(c, r, map[string]string{\n\t\t\"refs/remotes/origin/branch2\": ref.Hash().String(),\n\t})\n\n\t_, err = server.Storer.Reference(plumbing.ReferenceName(\"refs/heads/branch\"))\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n}\n\nfunc (s *RemoteSuite) TestPushInvalidEndpoint(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{Name: \"foo\", URLs: []string{\"http://\\\\\"}})\n\terr := r.Push(&PushOptions{RemoteName: \"foo\"})\n\tc.Assert(err, ErrorMatches, \".*invalid character.*\")\n}\n\nfunc (s *RemoteSuite) TestPushNonExistentEndpoint(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{Name: \"foo\", URLs: []string{\"ssh://non-existent/foo.git\"}})\n\terr := r.Push(&PushOptions{})\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *RemoteSuite) TestPushOverriddenEndpoint(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{Name: \"origin\", URLs: []string{\"http://perfectly-valid-url.example.com\"}})\n\terr := r.Push(&PushOptions{RemoteURL: \"http://\\\\\"})\n\tc.Assert(err, ErrorMatches, \".*invalid character.*\")\n}\n\nfunc (s *RemoteSuite) TestPushInvalidSchemaEndpoint(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{Name: \"origin\", URLs: []string{\"qux://foo\"}})\n\terr := r.Push(&PushOptions{})\n\tc.Assert(err, ErrorMatches, \".*unsupported scheme.*\")\n}\n\nfunc (s *RemoteSuite) TestPushInvalidFetchOptions(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{Name: \"foo\", URLs: []string{\"qux://foo\"}})\n\tinvalid := config.RefSpec(\"^*$ñ\")\n\terr := r.Push(&PushOptions{RefSpecs: []config.RefSpec{invalid}})\n\tc.Assert(err, Equals, config.ErrRefSpecMalformedSeparator)\n}\n\nfunc (s *RemoteSuite) TestPushInvalidRefSpec(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{\"some-url\"},\n\t})\n\n\trs := config.RefSpec(\"^*$**\")\n\terr := r.Push(&PushOptions{\n\t\tRefSpecs: []config.RefSpec{rs},\n\t})\n\tc.Assert(err, Equals, config.ErrRefSpecMalformedSeparator)\n}\n\nfunc (s *RemoteSuite) TestPushWrongRemoteName(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{\"some-url\"},\n\t})\n\n\terr := r.Push(&PushOptions{\n\t\tRemoteName: \"other-remote\",\n\t})\n\tc.Assert(err, ErrorMatches, \".*remote names don't match.*\")\n}\n\nfunc (s *RemoteSuite) TestGetHaves(c *C) {\n\tf := fixtures.Basic().One()\n\tsto := filesystem.NewStorage(f.DotGit(), cache.NewObjectLRUDefault())\n\n\tvar localRefs = []*plumbing.Reference{\n\t\t// Exists\n\t\tplumbing.NewReferenceFromStrings(\n\t\t\t\"foo\",\n\t\t\t\"b029517f6300c2da0f4b651b8642506cd6aaf45d\",\n\t\t),\n\t\t// Exists\n\t\tplumbing.NewReferenceFromStrings(\n\t\t\t\"bar\",\n\t\t\t\"b8e471f58bcbca63b07bda20e428190409c2db47\",\n\t\t),\n\t\t// Doesn't Exist\n\t\tplumbing.NewReferenceFromStrings(\n\t\t\t\"qux\",\n\t\t\t\"0000000\",\n\t\t),\n\t}\n\n\tl, err := getHaves(localRefs, memory.NewStorage(), sto, 0)\n\tc.Assert(err, IsNil)\n\tc.Assert(l, HasLen, 2)\n}\n\nfunc (s *RemoteSuite) TestList(c *C) {\n\trepo := fixtures.Basic().One()\n\tremote := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{repo.URL},\n\t})\n\n\trefs, err := remote.List(&ListOptions{})\n\tc.Assert(err, IsNil)\n\n\texpected := []*plumbing.Reference{\n\t\tplumbing.NewSymbolicReference(\"HEAD\", \"refs/heads/master\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/heads/master\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/heads/branch\", \"e8d3ffab552895c19b9fcf7aa264d277cde33881\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/pull/1/head\", \"b8e471f58bcbca63b07bda20e428190409c2db47\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/pull/2/head\", \"9632f02833b2f9613afb5e75682132b0b22e4a31\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/pull/2/merge\", \"c37f58a130ca555e42ff96a071cb9ccb3f437504\"),\n\t}\n\tc.Assert(len(refs), Equals, len(expected))\n\tfor _, e := range expected {\n\t\tfound := false\n\t\tfor _, r := range refs {\n\t\t\tif r.Name() == e.Name() {\n\t\t\t\tfound = true\n\t\t\t\tc.Assert(r, DeepEquals, e)\n\t\t\t}\n\t\t}\n\t\tc.Assert(found, Equals, true)\n\t}\n}\n\nfunc (s *RemoteSuite) TestListPeeling(c *C) {\n\tremote := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{\"https://github.com/git-fixtures/tags.git\"},\n\t})\n\n\tfor _, tc := range []struct {\n\t\tpeelingOption   PeelingOption\n\t\texpectPeeled    bool\n\t\texpectNonPeeled bool\n\t}{\n\t\t{peelingOption: AppendPeeled, expectPeeled: true, expectNonPeeled: true},\n\t\t{peelingOption: IgnorePeeled, expectPeeled: false, expectNonPeeled: true},\n\t\t{peelingOption: OnlyPeeled, expectPeeled: true, expectNonPeeled: false},\n\t} {\n\t\trefs, err := remote.List(&ListOptions{\n\t\t\tPeelingOption: tc.peelingOption,\n\t\t})\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(len(refs) > 0, Equals, true)\n\n\t\tfoundPeeled, foundNonPeeled := false, false\n\t\tfor _, ref := range refs {\n\t\t\tif strings.HasSuffix(ref.Name().String(), peeledSuffix) {\n\t\t\t\tfoundPeeled = true\n\t\t\t} else {\n\t\t\t\tfoundNonPeeled = true\n\t\t\t}\n\t\t}\n\n\t\tc.Assert(foundPeeled, Equals, tc.expectPeeled)\n\t\tc.Assert(foundNonPeeled, Equals, tc.expectNonPeeled)\n\t}\n}\n\nfunc (s *RemoteSuite) TestListTimeout(c *C) {\n\tremote := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{\"https://deelay.me/60000/https://httpstat.us/503\"},\n\t})\n\n\t_, err := remote.List(&ListOptions{})\n\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *RemoteSuite) TestUpdateShallows(c *C) {\n\thashes := []plumbing.Hash{\n\t\tplumbing.NewHash(\"0000000000000000000000000000000000000001\"),\n\t\tplumbing.NewHash(\"0000000000000000000000000000000000000002\"),\n\t\tplumbing.NewHash(\"0000000000000000000000000000000000000003\"),\n\t\tplumbing.NewHash(\"0000000000000000000000000000000000000004\"),\n\t\tplumbing.NewHash(\"0000000000000000000000000000000000000005\"),\n\t\tplumbing.NewHash(\"0000000000000000000000000000000000000006\"),\n\t}\n\n\ttests := []struct {\n\t\thashes []plumbing.Hash\n\t\tresult []plumbing.Hash\n\t}{\n\t\t// add to empty shallows\n\t\t{hashes[0:2], hashes[0:2]},\n\t\t// add new hashes\n\t\t{hashes[2:4], hashes[0:4]},\n\t\t// add some hashes already in shallow list\n\t\t{hashes[2:6], hashes[0:6]},\n\t\t// add all hashes\n\t\t{hashes[0:6], hashes[0:6]},\n\t\t// add empty list\n\t\t{nil, hashes[0:6]},\n\t}\n\n\tremote := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t})\n\n\tshallows, err := remote.s.Shallow()\n\tc.Assert(err, IsNil)\n\tc.Assert(len(shallows), Equals, 0)\n\n\tresp := new(packp.UploadPackResponse)\n\to := &FetchOptions{\n\t\tDepth: 1,\n\t}\n\n\tfor _, t := range tests {\n\t\tresp.Shallows = t.hashes\n\t\terr = remote.updateShallow(o, resp)\n\t\tc.Assert(err, IsNil)\n\n\t\tshallow, err := remote.s.Shallow()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(len(shallow), Equals, len(t.result))\n\t\tc.Assert(shallow, DeepEquals, t.result)\n\t}\n}\n\nfunc (s *RemoteSuite) TestUseRefDeltas(c *C) {\n\turl := c.MkDir()\n\n\t_, err := PlainInit(url, true)\n\tc.Assert(err, IsNil)\n\n\tfs := fixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One().DotGit()\n\tsto := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\n\tr := NewRemote(sto, &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{url},\n\t})\n\n\tar := packp.NewAdvRefs()\n\n\tar.Capabilities.Add(capability.OFSDelta)\n\tc.Assert(r.useRefDeltas(ar), Equals, false)\n\n\tar.Capabilities.Delete(capability.OFSDelta)\n\tc.Assert(r.useRefDeltas(ar), Equals, true)\n}\n\nfunc (s *RemoteSuite) TestPushRequireRemoteRefs(c *C) {\n\tf := fixtures.Basic().One()\n\tsto := filesystem.NewStorage(f.DotGit(), cache.NewObjectLRUDefault())\n\n\tdstFs := f.DotGit()\n\tdstSto := filesystem.NewStorage(dstFs, cache.NewObjectLRUDefault())\n\n\turl := dstFs.Root()\n\tr := NewRemote(sto, &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{url},\n\t})\n\n\toldRef, err := dstSto.Reference(plumbing.ReferenceName(\"refs/heads/branch\"))\n\tc.Assert(err, IsNil)\n\tc.Assert(oldRef, NotNil)\n\n\totherRef, err := dstSto.Reference(plumbing.ReferenceName(\"refs/heads/master\"))\n\tc.Assert(err, IsNil)\n\tc.Assert(otherRef, NotNil)\n\n\terr = r.Push(&PushOptions{\n\t\tRefSpecs:          []config.RefSpec{\"refs/heads/master:refs/heads/branch\"},\n\t\tRequireRemoteRefs: []config.RefSpec{config.RefSpec(otherRef.Hash().String() + \":refs/heads/branch\")},\n\t})\n\tc.Assert(err, ErrorMatches, \"remote ref refs/heads/branch required to be .* but is .*\")\n\n\tnewRef, err := dstSto.Reference(plumbing.ReferenceName(\"refs/heads/branch\"))\n\tc.Assert(err, IsNil)\n\tc.Assert(newRef, DeepEquals, oldRef)\n\n\terr = r.Push(&PushOptions{\n\t\tRefSpecs:          []config.RefSpec{\"refs/heads/master:refs/heads/branch\"},\n\t\tRequireRemoteRefs: []config.RefSpec{config.RefSpec(oldRef.Hash().String() + \":refs/heads/branch\")},\n\t})\n\tc.Assert(err, ErrorMatches, \"non-fast-forward update: .*\")\n\n\tnewRef, err = dstSto.Reference(plumbing.ReferenceName(\"refs/heads/branch\"))\n\tc.Assert(err, IsNil)\n\tc.Assert(newRef, DeepEquals, oldRef)\n\n\terr = r.Push(&PushOptions{\n\t\tRefSpecs:          []config.RefSpec{\"refs/heads/master:refs/heads/branch\"},\n\t\tRequireRemoteRefs: []config.RefSpec{config.RefSpec(oldRef.Hash().String() + \":refs/heads/branch\")},\n\t\tForce:             true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tnewRef, err = dstSto.Reference(plumbing.ReferenceName(\"refs/heads/branch\"))\n\tc.Assert(err, IsNil)\n\tc.Assert(newRef, Not(DeepEquals), oldRef)\n}\n\nfunc (s *RemoteSuite) TestFetchPrune(c *C) {\n\tfs := fixtures.Basic().One().DotGit()\n\n\turl := c.MkDir()\n\n\t_, err := PlainClone(url, true, &CloneOptions{\n\t\tURL: fs.Root(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tdir := c.MkDir()\n\n\tr, err := PlainClone(dir, true, &CloneOptions{\n\t\tURL: url,\n\t})\n\tc.Assert(err, IsNil)\n\n\tremote, err := r.Remote(DefaultRemoteName)\n\tc.Assert(err, IsNil)\n\n\tref, err := r.Reference(plumbing.ReferenceName(\"refs/heads/master\"), true)\n\tc.Assert(err, IsNil)\n\n\terr = remote.Push(&PushOptions{RefSpecs: []config.RefSpec{\n\t\t\"refs/heads/master:refs/heads/branch\",\n\t}})\n\tc.Assert(err, IsNil)\n\n\tdirSave := c.MkDir()\n\n\trSave, err := PlainClone(dirSave, true, &CloneOptions{\n\t\tURL: url,\n\t})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, rSave, map[string]string{\n\t\t\"refs/remotes/origin/branch\": ref.Hash().String(),\n\t})\n\n\terr = remote.Push(&PushOptions{RefSpecs: []config.RefSpec{\n\t\t\":refs/heads/branch\",\n\t}})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, rSave, map[string]string{\n\t\t\"refs/remotes/origin/branch\": ref.Hash().String(),\n\t})\n\n\terr = rSave.Fetch(&FetchOptions{Prune: true})\n\tc.Assert(err, IsNil)\n\n\t_, err = rSave.Reference(\"refs/remotes/origin/branch\", true)\n\tc.Assert(err, ErrorMatches, \"reference not found\")\n}\n\nfunc (s *RemoteSuite) TestFetchPruneTags(c *C) {\n\tfs := fixtures.Basic().One().DotGit()\n\n\turl := c.MkDir()\n\n\t_, err := PlainClone(url, true, &CloneOptions{\n\t\tURL: fs.Root(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tdir := c.MkDir()\n\n\tr, err := PlainClone(dir, true, &CloneOptions{\n\t\tURL: url,\n\t})\n\tc.Assert(err, IsNil)\n\n\tremote, err := r.Remote(DefaultRemoteName)\n\tc.Assert(err, IsNil)\n\n\tref, err := r.Reference(plumbing.ReferenceName(\"refs/heads/master\"), true)\n\tc.Assert(err, IsNil)\n\n\terr = remote.Push(&PushOptions{RefSpecs: []config.RefSpec{\n\t\t\"refs/heads/master:refs/tags/v1\",\n\t}})\n\tc.Assert(err, IsNil)\n\n\tdirSave := c.MkDir()\n\n\trSave, err := PlainClone(dirSave, true, &CloneOptions{\n\t\tURL: url,\n\t})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, rSave, map[string]string{\n\t\t\"refs/tags/v1\": ref.Hash().String(),\n\t})\n\n\terr = remote.Push(&PushOptions{RefSpecs: []config.RefSpec{\n\t\t\":refs/tags/v1\",\n\t}})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, rSave, map[string]string{\n\t\t\"refs/tags/v1\": ref.Hash().String(),\n\t})\n\n\terr = rSave.Fetch(&FetchOptions{Prune: true, RefSpecs: []config.RefSpec{\"refs/tags/*:refs/tags/*\"}})\n\tc.Assert(err, IsNil)\n\n\t_, err = rSave.Reference(\"refs/tags/v1\", true)\n\tc.Assert(err, ErrorMatches, \"reference not found\")\n}\n\nfunc (s *RemoteSuite) TestCanPushShasToReference(c *C) {\n\td := c.MkDir()\n\td, err := os.MkdirTemp(d, \"TestCanPushShasToReference\")\n\tc.Assert(err, IsNil)\n\tif err != nil {\n\t\treturn\n\t}\n\n\t// remote currently forces a plain path for path based remotes inside the PushContext function.\n\t// This makes it impossible, in the current state to use memfs.\n\t// For the sake of readability, use the same osFS everywhere and use plain git repositories on temporary files\n\tremote, err := PlainInit(filepath.Join(d, \"remote\"), true)\n\tc.Assert(err, IsNil)\n\tc.Assert(remote, NotNil)\n\n\trepo, err := PlainInit(filepath.Join(d, \"repo\"), false)\n\tc.Assert(err, IsNil)\n\tc.Assert(repo, NotNil)\n\n\tsha := CommitNewFile(c, repo, \"README.md\")\n\n\tgitremote, err := repo.CreateRemote(&config.RemoteConfig{\n\t\tName: \"local\",\n\t\tURLs: []string{filepath.Join(d, \"remote\")},\n\t})\n\tc.Assert(err, IsNil)\n\tif err != nil {\n\t\treturn\n\t}\n\n\terr = gitremote.Push(&PushOptions{\n\t\tRemoteName: \"local\",\n\t\tRefSpecs: []config.RefSpec{\n\t\t\t// TODO: check with short hashes that this is still respected\n\t\t\tconfig.RefSpec(sha.String() + \":refs/heads/branch\"),\n\t\t},\n\t})\n\tc.Assert(err, IsNil)\n\tif err != nil {\n\t\treturn\n\t}\n\n\tref, err := remote.Reference(plumbing.ReferenceName(\"refs/heads/branch\"), false)\n\tc.Assert(err, IsNil)\n\tif err != nil {\n\t\treturn\n\t}\n\tc.Assert(ref.Hash().String(), Equals, sha.String())\n}\n\nfunc (s *RemoteSuite) TestFetchAfterShallowClone(c *C) {\n\ttempDir := c.MkDir()\n\tremoteUrl := filepath.Join(tempDir, \"remote\")\n\trepoDir := filepath.Join(tempDir, \"repo\")\n\n\t// Create a new repo and add more than 1 commit (so we can have a shallow commit)\n\tremote, err := PlainInit(remoteUrl, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(remote, NotNil)\n\n\t_ = CommitNewFile(c, remote, \"File1\")\n\t_ = CommitNewFile(c, remote, \"File2\")\n\n\t// Clone the repo with a depth of 1\n\trepo, err := PlainClone(repoDir, false, &CloneOptions{\n\t\tURL:           remoteUrl,\n\t\tDepth:         1,\n\t\tTags:          NoTags,\n\t\tSingleBranch:  true,\n\t\tReferenceName: \"master\",\n\t})\n\tc.Assert(err, IsNil)\n\n\t// Add new commits to the origin (more than 1 so that our next test hits a missing commit)\n\t_ = CommitNewFile(c, remote, \"File3\")\n\tsha4 := CommitNewFile(c, remote, \"File4\")\n\n\t// Try fetch with depth of 1 again (note, we need to ensure no remote branch remains pointing at the old commit)\n\tr, err := repo.Remote(DefaultRemoteName)\n\tc.Assert(err, IsNil)\n\ts.testFetch(c, r, &FetchOptions{\n\t\tDepth: 2,\n\t\tTags:  NoTags,\n\n\t\tRefSpecs: []config.RefSpec{\n\t\t\t\"+refs/heads/master:refs/heads/master\",\n\t\t\t\"+refs/heads/master:refs/remotes/origin/master\",\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/heads/master\", sha4.String()),\n\t\tplumbing.NewReferenceFromStrings(\"refs/remotes/origin/master\", sha4.String()),\n\t\tplumbing.NewSymbolicReference(\"HEAD\", \"refs/heads/master\"),\n\t})\n\n\t// Add another commit to the origin\n\tsha5 := CommitNewFile(c, remote, \"File5\")\n\n\t// Try fetch with depth of 2 this time (to reach a commit that we don't have locally)\n\tr, err = repo.Remote(DefaultRemoteName)\n\tc.Assert(err, IsNil)\n\ts.testFetch(c, r, &FetchOptions{\n\t\tDepth: 1,\n\t\tTags:  NoTags,\n\n\t\tRefSpecs: []config.RefSpec{\n\t\t\t\"+refs/heads/master:refs/heads/master\",\n\t\t\t\"+refs/heads/master:refs/remotes/origin/master\",\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/heads/master\", sha5.String()),\n\t\tplumbing.NewReferenceFromStrings(\"refs/remotes/origin/master\", sha5.String()),\n\t\tplumbing.NewSymbolicReference(\"HEAD\", \"refs/heads/master\"),\n\t})\n}\n\nfunc TestFetchFastForwardForCustomRef(t *testing.T) {\n\tcustomRef := \"refs/custom/branch\"\n\t// 1. Set up a remote with a URL\n\tremoteURL := t.TempDir()\n\tremoteRepo, err := PlainInit(remoteURL, true)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// 2. Add a commit with an empty tree to master and custom ref, also set HEAD\n\temptyTreeID := writeEmptyTree(t, remoteRepo)\n\twriteCommitToRef(t, remoteRepo, \"refs/heads/master\", emptyTreeID, time.Now())\n\twriteCommitToRef(t, remoteRepo, customRef, emptyTreeID, time.Now())\n\tif err := remoteRepo.Storer.SetReference(plumbing.NewSymbolicReference(plumbing.HEAD, \"refs/heads/master\")); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// 3. Clone repo, then fetch the custom ref\n\t// Note that using custom ref in ReferenceName has an IsBranch issue\n\tlocalRepo, err := Clone(memory.NewStorage(), memfs.New(), &CloneOptions{\n\t\tURL: remoteURL,\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif err := localRepo.Fetch(&FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(fmt.Sprintf(\"%s:%s\", customRef, customRef)),\n\t\t},\n\t}); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// 4. Make divergent changes\n\tremoteCommitID := writeCommitToRef(t, remoteRepo, customRef, emptyTreeID, time.Now())\n\t// Consecutive calls to writeCommitToRef with time.Now() might have the same\n\t// time value, explicitly set distinct ones to ensure the commit hashes\n\t// differ\n\twriteCommitToRef(t, localRepo, customRef, emptyTreeID, time.Now().Add(time.Second))\n\n\t// 5. Try to fetch with fast-forward only mode\n\tremote, err := localRepo.Remote(DefaultRemoteName)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\terr = remote.Fetch(&FetchOptions{RefSpecs: []config.RefSpec{\n\t\tconfig.RefSpec(fmt.Sprintf(\"%s:%s\", customRef, customRef)),\n\t}})\n\tif !errors.Is(err, ErrForceNeeded) {\n\t\tt.Errorf(\"expected %v, got %v\", ErrForceNeeded, err)\n\t}\n\n\t// 6. Fetch with force\n\terr = remote.Fetch(&FetchOptions{RefSpecs: []config.RefSpec{\n\t\tconfig.RefSpec(fmt.Sprintf(\"+%s:%s\", customRef, customRef)),\n\t}})\n\tif err != nil {\n\t\tt.Errorf(\"unexpected error %v\", err)\n\t}\n\n\t// 7. Assert commit ID matches\n\tref, err := localRepo.Reference(plumbing.ReferenceName(customRef), true)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif remoteCommitID != ref.Hash() {\n\t\tt.Errorf(\"expected %s, got %s\", remoteCommitID.String(), ref.Hash().String())\n\t}\n}\n\nfunc writeEmptyTree(t *testing.T, repo *Repository) plumbing.Hash {\n\tt.Helper()\n\n\tobj := repo.Storer.NewEncodedObject()\n\tobj.SetType(plumbing.TreeObject)\n\n\ttree := object.Tree{Entries: nil}\n\tif err := tree.Encode(obj); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\ttreeID, err := repo.Storer.SetEncodedObject(obj)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\treturn treeID\n}\n\nfunc writeCommitToRef(t *testing.T, repo *Repository, refName string, treeID plumbing.Hash, when time.Time) plumbing.Hash {\n\tt.Helper()\n\n\tref, err := repo.Reference(plumbing.ReferenceName(refName), true)\n\tif err != nil {\n\t\tif errors.Is(err, plumbing.ErrReferenceNotFound) {\n\t\t\tif err := repo.Storer.SetReference(plumbing.NewHashReference(plumbing.ReferenceName(refName), plumbing.ZeroHash)); err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\tref, err = repo.Reference(plumbing.ReferenceName(refName), true)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t} else {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n\n\tcommit := &object.Commit{\n\t\tTreeHash: treeID,\n\t\tAuthor: object.Signature{\n\t\t\tWhen: when,\n\t\t},\n\t}\n\tif !ref.Hash().IsZero() {\n\t\tcommit.ParentHashes = []plumbing.Hash{ref.Hash()}\n\t}\n\n\tobj := repo.Storer.NewEncodedObject()\n\tif err := commit.Encode(obj); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tcommitID, err := repo.Storer.SetEncodedObject(obj)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tnewRef := plumbing.NewHashReference(plumbing.ReferenceName(refName), commitID)\n\tif err := repo.Storer.CheckAndSetReference(newRef, ref); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\treturn commitID\n}\n"
        },
        {
          "name": "repository.go",
          "type": "blob",
          "size": 47.1689453125,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto\"\n\t\"encoding/hex\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"time\"\n\n\t\"dario.cat/mergo\"\n\t\"github.com/ProtonMail/go-crypto/openpgp\"\n\t\"github.com/go-git/go-billy/v5\"\n\t\"github.com/go-git/go-billy/v5/osfs\"\n\t\"github.com/go-git/go-billy/v5/util\"\n\t\"github.com/go-git/go-git/v5/config\"\n\t\"github.com/go-git/go-git/v5/internal/path_util\"\n\t\"github.com/go-git/go-git/v5/internal/revision\"\n\t\"github.com/go-git/go-git/v5/internal/url\"\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/plumbing/cache\"\n\tformatcfg \"github.com/go-git/go-git/v5/plumbing/format/config\"\n\t\"github.com/go-git/go-git/v5/plumbing/format/packfile\"\n\t\"github.com/go-git/go-git/v5/plumbing/hash\"\n\t\"github.com/go-git/go-git/v5/plumbing/object\"\n\t\"github.com/go-git/go-git/v5/plumbing/storer\"\n\t\"github.com/go-git/go-git/v5/storage\"\n\t\"github.com/go-git/go-git/v5/storage/filesystem\"\n\t\"github.com/go-git/go-git/v5/storage/filesystem/dotgit\"\n\t\"github.com/go-git/go-git/v5/utils/ioutil\"\n)\n\n// GitDirName this is a special folder where all the git stuff is.\nconst GitDirName = \".git\"\n\nvar (\n\t// ErrBranchExists an error stating the specified branch already exists\n\tErrBranchExists = errors.New(\"branch already exists\")\n\t// ErrBranchNotFound an error stating the specified branch does not exist\n\tErrBranchNotFound = errors.New(\"branch not found\")\n\t// ErrTagExists an error stating the specified tag already exists\n\tErrTagExists = errors.New(\"tag already exists\")\n\t// ErrTagNotFound an error stating the specified tag does not exist\n\tErrTagNotFound = errors.New(\"tag not found\")\n\t// ErrFetching is returned when the packfile could not be downloaded\n\tErrFetching = errors.New(\"unable to fetch packfile\")\n\n\tErrInvalidReference            = errors.New(\"invalid reference, should be a tag or a branch\")\n\tErrRepositoryNotExists         = errors.New(\"repository does not exist\")\n\tErrRepositoryIncomplete        = errors.New(\"repository's commondir path does not exist\")\n\tErrRepositoryAlreadyExists     = errors.New(\"repository already exists\")\n\tErrRemoteNotFound              = errors.New(\"remote not found\")\n\tErrRemoteExists                = errors.New(\"remote already exists\")\n\tErrAnonymousRemoteName         = errors.New(\"anonymous remote name must be 'anonymous'\")\n\tErrWorktreeNotProvided         = errors.New(\"worktree should be provided\")\n\tErrIsBareRepository            = errors.New(\"worktree not available in a bare repository\")\n\tErrUnableToResolveCommit       = errors.New(\"unable to resolve commit\")\n\tErrPackedObjectsNotSupported   = errors.New(\"packed objects not supported\")\n\tErrSHA256NotSupported          = errors.New(\"go-git was not compiled with SHA256 support\")\n\tErrAlternatePathNotSupported   = errors.New(\"alternate path must use the file scheme\")\n\tErrUnsupportedMergeStrategy    = errors.New(\"unsupported merge strategy\")\n\tErrFastForwardMergeNotPossible = errors.New(\"not possible to fast-forward merge changes\")\n)\n\n// Repository represents a git repository\ntype Repository struct {\n\tStorer storage.Storer\n\n\tr  map[string]*Remote\n\twt billy.Filesystem\n}\n\ntype InitOptions struct {\n\t// The default branch (e.g. \"refs/heads/master\")\n\tDefaultBranch plumbing.ReferenceName\n}\n\n// Init creates an empty git repository, based on the given Storer and worktree.\n// The worktree Filesystem is optional, if nil a bare repository is created. If\n// the given storer is not empty ErrRepositoryAlreadyExists is returned\nfunc Init(s storage.Storer, worktree billy.Filesystem) (*Repository, error) {\n\toptions := InitOptions{\n\t\tDefaultBranch: plumbing.Master,\n\t}\n\treturn InitWithOptions(s, worktree, options)\n}\n\nfunc InitWithOptions(s storage.Storer, worktree billy.Filesystem, options InitOptions) (*Repository, error) {\n\tif err := initStorer(s); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif options.DefaultBranch == \"\" {\n\t\toptions.DefaultBranch = plumbing.Master\n\t}\n\n\tif err := options.DefaultBranch.Validate(); err != nil {\n\t\treturn nil, err\n\t}\n\n\tr := newRepository(s, worktree)\n\t_, err := r.Reference(plumbing.HEAD, false)\n\tswitch err {\n\tcase plumbing.ErrReferenceNotFound:\n\tcase nil:\n\t\treturn nil, ErrRepositoryAlreadyExists\n\tdefault:\n\t\treturn nil, err\n\t}\n\n\th := plumbing.NewSymbolicReference(plumbing.HEAD, options.DefaultBranch)\n\tif err := s.SetReference(h); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif worktree == nil {\n\t\t_ = r.setIsBare(true)\n\t\treturn r, nil\n\t}\n\n\treturn r, setWorktreeAndStoragePaths(r, worktree)\n}\n\nfunc initStorer(s storer.Storer) error {\n\ti, ok := s.(storer.Initializer)\n\tif !ok {\n\t\treturn nil\n\t}\n\n\treturn i.Init()\n}\n\nfunc setWorktreeAndStoragePaths(r *Repository, worktree billy.Filesystem) error {\n\ttype fsBased interface {\n\t\tFilesystem() billy.Filesystem\n\t}\n\n\t// .git file is only created if the storage is file based and the file\n\t// system is osfs.OS\n\tfs, isFSBased := r.Storer.(fsBased)\n\tif !isFSBased {\n\t\treturn nil\n\t}\n\n\tif err := createDotGitFile(worktree, fs.Filesystem()); err != nil {\n\t\treturn err\n\t}\n\n\treturn setConfigWorktree(r, worktree, fs.Filesystem())\n}\n\nfunc createDotGitFile(worktree, storage billy.Filesystem) error {\n\tpath, err := filepath.Rel(worktree.Root(), storage.Root())\n\tif err != nil {\n\t\tpath = storage.Root()\n\t}\n\n\tif path == GitDirName {\n\t\t// not needed, since the folder is the default place\n\t\treturn nil\n\t}\n\n\tf, err := worktree.Create(GitDirName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdefer f.Close()\n\t_, err = fmt.Fprintf(f, \"gitdir: %s\\n\", path)\n\treturn err\n}\n\nfunc setConfigWorktree(r *Repository, worktree, storage billy.Filesystem) error {\n\tpath, err := filepath.Rel(storage.Root(), worktree.Root())\n\tif err != nil {\n\t\tpath = worktree.Root()\n\t}\n\n\tif path == \"..\" {\n\t\t// not needed, since the folder is the default place\n\t\treturn nil\n\t}\n\n\tcfg, err := r.Config()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tcfg.Core.Worktree = path\n\treturn r.Storer.SetConfig(cfg)\n}\n\n// Open opens a git repository using the given Storer and worktree filesystem,\n// if the given storer is complete empty ErrRepositoryNotExists is returned.\n// The worktree can be nil when the repository being opened is bare, if the\n// repository is a normal one (not bare) and worktree is nil the err\n// ErrWorktreeNotProvided is returned\nfunc Open(s storage.Storer, worktree billy.Filesystem) (*Repository, error) {\n\t_, err := s.Reference(plumbing.HEAD)\n\tif err == plumbing.ErrReferenceNotFound {\n\t\treturn nil, ErrRepositoryNotExists\n\t}\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn newRepository(s, worktree), nil\n}\n\n// Clone a repository into the given Storer and worktree Filesystem with the\n// given options, if worktree is nil a bare repository is created. If the given\n// storer is not empty ErrRepositoryAlreadyExists is returned.\nfunc Clone(s storage.Storer, worktree billy.Filesystem, o *CloneOptions) (*Repository, error) {\n\treturn CloneContext(context.Background(), s, worktree, o)\n}\n\n// CloneContext a repository into the given Storer and worktree Filesystem with\n// the given options, if worktree is nil a bare repository is created. If the\n// given storer is not empty ErrRepositoryAlreadyExists is returned.\n//\n// The provided Context must be non-nil. If the context expires before the\n// operation is complete, an error is returned. The context only affects the\n// transport operations.\nfunc CloneContext(\n\tctx context.Context, s storage.Storer, worktree billy.Filesystem, o *CloneOptions,\n) (*Repository, error) {\n\tr, err := Init(s, worktree)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn r, r.clone(ctx, o)\n}\n\n// PlainInit create an empty git repository at the given path. isBare defines\n// if the repository will have worktree (non-bare) or not (bare), if the path\n// is not empty ErrRepositoryAlreadyExists is returned.\nfunc PlainInit(path string, isBare bool) (*Repository, error) {\n\treturn PlainInitWithOptions(path, &PlainInitOptions{\n\t\tBare: isBare,\n\t})\n}\n\nfunc PlainInitWithOptions(path string, opts *PlainInitOptions) (*Repository, error) {\n\tif opts == nil {\n\t\topts = &PlainInitOptions{}\n\t}\n\n\tvar wt, dot billy.Filesystem\n\n\tif opts.Bare {\n\t\tdot = osfs.New(path)\n\t} else {\n\t\twt = osfs.New(path)\n\t\tdot, _ = wt.Chroot(GitDirName)\n\t}\n\n\ts := filesystem.NewStorage(dot, cache.NewObjectLRUDefault())\n\n\tr, err := InitWithOptions(s, wt, opts.InitOptions)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcfg, err := r.Config()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif opts.ObjectFormat != \"\" {\n\t\tif opts.ObjectFormat == formatcfg.SHA256 && hash.CryptoType != crypto.SHA256 {\n\t\t\treturn nil, ErrSHA256NotSupported\n\t\t}\n\n\t\tcfg.Core.RepositoryFormatVersion = formatcfg.Version_1\n\t\tcfg.Extensions.ObjectFormat = opts.ObjectFormat\n\t}\n\n\terr = r.Storer.SetConfig(cfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn r, err\n}\n\n// PlainOpen opens a git repository from the given path. It detects if the\n// repository is bare or a normal one. If the path doesn't contain a valid\n// repository ErrRepositoryNotExists is returned\nfunc PlainOpen(path string) (*Repository, error) {\n\treturn PlainOpenWithOptions(path, &PlainOpenOptions{})\n}\n\n// PlainOpenWithOptions opens a git repository from the given path with specific\n// options. See PlainOpen for more info.\nfunc PlainOpenWithOptions(path string, o *PlainOpenOptions) (*Repository, error) {\n\tdot, wt, err := dotGitToOSFilesystems(path, o.DetectDotGit)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif _, err := dot.Stat(\"\"); err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\treturn nil, ErrRepositoryNotExists\n\t\t}\n\n\t\treturn nil, err\n\t}\n\n\tvar repositoryFs billy.Filesystem\n\n\tif o.EnableDotGitCommonDir {\n\t\tdotGitCommon, err := dotGitCommonDirectory(dot)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\trepositoryFs = dotgit.NewRepositoryFilesystem(dot, dotGitCommon)\n\t} else {\n\t\trepositoryFs = dot\n\t}\n\n\ts := filesystem.NewStorage(repositoryFs, cache.NewObjectLRUDefault())\n\n\treturn Open(s, wt)\n}\n\nfunc dotGitToOSFilesystems(path string, detect bool) (dot, wt billy.Filesystem, err error) {\n\tpath, err = path_util.ReplaceTildeWithHome(path)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tif path, err = filepath.Abs(path); err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tvar fs billy.Filesystem\n\tvar fi os.FileInfo\n\tfor {\n\t\tfs = osfs.New(path)\n\n\t\tpathinfo, err := fs.Stat(\"/\")\n\t\tif !os.IsNotExist(err) {\n\t\t\tif pathinfo == nil {\n\t\t\t\treturn nil, nil, err\n\t\t\t}\n\t\t\tif !pathinfo.IsDir() && detect {\n\t\t\t\tfs = osfs.New(filepath.Dir(path))\n\t\t\t}\n\t\t}\n\n\t\tfi, err = fs.Stat(GitDirName)\n\t\tif err == nil {\n\t\t\t// no error; stop\n\t\t\tbreak\n\t\t}\n\t\tif !os.IsNotExist(err) {\n\t\t\t// unknown error; stop\n\t\t\treturn nil, nil, err\n\t\t}\n\t\tif detect {\n\t\t\t// try its parent as long as we haven't reached\n\t\t\t// the root dir\n\t\t\tif dir := filepath.Dir(path); dir != path {\n\t\t\t\tpath = dir\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\t// not detecting via parent dirs and the dir does not exist;\n\t\t// stop\n\t\treturn fs, nil, nil\n\t}\n\n\tif fi.IsDir() {\n\t\tdot, err = fs.Chroot(GitDirName)\n\t\treturn dot, fs, err\n\t}\n\n\tdot, err = dotGitFileToOSFilesystem(path, fs)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\treturn dot, fs, nil\n}\n\nfunc dotGitFileToOSFilesystem(path string, fs billy.Filesystem) (bfs billy.Filesystem, err error) {\n\tf, err := fs.Open(GitDirName)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer ioutil.CheckClose(f, &err)\n\n\tb, err := io.ReadAll(f)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tline := string(b)\n\tconst prefix = \"gitdir: \"\n\tif !strings.HasPrefix(line, prefix) {\n\t\treturn nil, fmt.Errorf(\".git file has no %s prefix\", prefix)\n\t}\n\n\tgitdir := strings.Split(line[len(prefix):], \"\\n\")[0]\n\tgitdir = strings.TrimSpace(gitdir)\n\tif filepath.IsAbs(gitdir) {\n\t\treturn osfs.New(gitdir), nil\n\t}\n\n\treturn osfs.New(fs.Join(path, gitdir)), nil\n}\n\nfunc dotGitCommonDirectory(fs billy.Filesystem) (commonDir billy.Filesystem, err error) {\n\tf, err := fs.Open(\"commondir\")\n\tif os.IsNotExist(err) {\n\t\treturn nil, nil\n\t}\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tb, err := io.ReadAll(f)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(b) > 0 {\n\t\tpath := strings.TrimSpace(string(b))\n\t\tif filepath.IsAbs(path) {\n\t\t\tcommonDir = osfs.New(path)\n\t\t} else {\n\t\t\tcommonDir = osfs.New(filepath.Join(fs.Root(), path))\n\t\t}\n\t\tif _, err := commonDir.Stat(\"\"); err != nil {\n\t\t\tif os.IsNotExist(err) {\n\t\t\t\treturn nil, ErrRepositoryIncomplete\n\t\t\t}\n\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn commonDir, nil\n}\n\n// PlainClone a repository into the path with the given options, isBare defines\n// if the new repository will be bare or normal. If the path is not empty\n// ErrRepositoryAlreadyExists is returned.\n//\n// TODO(mcuadros): move isBare to CloneOptions in v5\nfunc PlainClone(path string, isBare bool, o *CloneOptions) (*Repository, error) {\n\treturn PlainCloneContext(context.Background(), path, isBare, o)\n}\n\n// PlainCloneContext a repository into the path with the given options, isBare\n// defines if the new repository will be bare or normal. If the path is not empty\n// ErrRepositoryAlreadyExists is returned.\n//\n// The provided Context must be non-nil. If the context expires before the\n// operation is complete, an error is returned. The context only affects the\n// transport operations.\n//\n// TODO(mcuadros): move isBare to CloneOptions in v5\n// TODO(smola): refuse upfront to clone on a non-empty directory in v5, see #1027\nfunc PlainCloneContext(ctx context.Context, path string, isBare bool, o *CloneOptions) (*Repository, error) {\n\tcleanup, cleanupParent, err := checkIfCleanupIsNeeded(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif o.Mirror {\n\t\tisBare = true\n\t}\n\tr, err := PlainInit(path, isBare)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\terr = r.clone(ctx, o)\n\tif err != nil && err != ErrRepositoryAlreadyExists {\n\t\tif cleanup {\n\t\t\t_ = cleanUpDir(path, cleanupParent)\n\t\t}\n\t}\n\n\treturn r, err\n}\n\nfunc newRepository(s storage.Storer, worktree billy.Filesystem) *Repository {\n\treturn &Repository{\n\t\tStorer: s,\n\t\twt:     worktree,\n\t\tr:      make(map[string]*Remote),\n\t}\n}\n\nfunc checkIfCleanupIsNeeded(path string) (cleanup bool, cleanParent bool, err error) {\n\tfi, err := osfs.Default.Stat(path)\n\tif err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\treturn true, true, nil\n\t\t}\n\n\t\treturn false, false, err\n\t}\n\n\tif !fi.IsDir() {\n\t\treturn false, false, fmt.Errorf(\"path is not a directory: %s\", path)\n\t}\n\n\tfiles, err := osfs.Default.ReadDir(path)\n\tif err != nil {\n\t\treturn false, false, err\n\t}\n\n\tif len(files) == 0 {\n\t\treturn true, false, nil\n\t}\n\n\treturn false, false, nil\n}\n\nfunc cleanUpDir(path string, all bool) error {\n\tif all {\n\t\treturn util.RemoveAll(osfs.Default, path)\n\t}\n\n\tfiles, err := osfs.Default.ReadDir(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, fi := range files {\n\t\tif err := util.RemoveAll(osfs.Default, osfs.Default.Join(path, fi.Name())); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn err\n}\n\n// Config return the repository config. In a filesystem backed repository this\n// means read the `.git/config`.\nfunc (r *Repository) Config() (*config.Config, error) {\n\treturn r.Storer.Config()\n}\n\n// SetConfig marshall and writes the repository config. In a filesystem backed\n// repository this means write the `.git/config`. This function should be called\n// with the result of `Repository.Config` and never with the output of\n// `Repository.ConfigScoped`.\nfunc (r *Repository) SetConfig(cfg *config.Config) error {\n\treturn r.Storer.SetConfig(cfg)\n}\n\n// ConfigScoped returns the repository config, merged with requested scope and\n// lower. For example if, config.GlobalScope is given the local and global config\n// are returned merged in one config value.\nfunc (r *Repository) ConfigScoped(scope config.Scope) (*config.Config, error) {\n\t// TODO(mcuadros): v6, add this as ConfigOptions.Scoped\n\n\tvar err error\n\tsystem := config.NewConfig()\n\tif scope >= config.SystemScope {\n\t\tsystem, err = config.LoadConfig(config.SystemScope)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tglobal := config.NewConfig()\n\tif scope >= config.GlobalScope {\n\t\tglobal, err = config.LoadConfig(config.GlobalScope)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tlocal, err := r.Storer.Config()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t_ = mergo.Merge(global, system)\n\t_ = mergo.Merge(local, global)\n\treturn local, nil\n}\n\n// Remote return a remote if exists\nfunc (r *Repository) Remote(name string) (*Remote, error) {\n\tcfg, err := r.Config()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tc, ok := cfg.Remotes[name]\n\tif !ok {\n\t\treturn nil, ErrRemoteNotFound\n\t}\n\n\treturn NewRemote(r.Storer, c), nil\n}\n\n// Remotes returns a list with all the remotes\nfunc (r *Repository) Remotes() ([]*Remote, error) {\n\tcfg, err := r.Config()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tremotes := make([]*Remote, len(cfg.Remotes))\n\n\tvar i int\n\tfor _, c := range cfg.Remotes {\n\t\tremotes[i] = NewRemote(r.Storer, c)\n\t\ti++\n\t}\n\n\treturn remotes, nil\n}\n\n// CreateRemote creates a new remote\nfunc (r *Repository) CreateRemote(c *config.RemoteConfig) (*Remote, error) {\n\tif err := c.Validate(); err != nil {\n\t\treturn nil, err\n\t}\n\n\tremote := NewRemote(r.Storer, c)\n\n\tcfg, err := r.Config()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif _, ok := cfg.Remotes[c.Name]; ok {\n\t\treturn nil, ErrRemoteExists\n\t}\n\n\tcfg.Remotes[c.Name] = c\n\treturn remote, r.Storer.SetConfig(cfg)\n}\n\n// CreateRemoteAnonymous creates a new anonymous remote. c.Name must be \"anonymous\".\n// It's used like 'git fetch git@github.com:src-d/go-git.git master:master'.\nfunc (r *Repository) CreateRemoteAnonymous(c *config.RemoteConfig) (*Remote, error) {\n\tif err := c.Validate(); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif c.Name != \"anonymous\" {\n\t\treturn nil, ErrAnonymousRemoteName\n\t}\n\n\tremote := NewRemote(r.Storer, c)\n\n\treturn remote, nil\n}\n\n// DeleteRemote delete a remote from the repository and delete the config\nfunc (r *Repository) DeleteRemote(name string) error {\n\tcfg, err := r.Config()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif _, ok := cfg.Remotes[name]; !ok {\n\t\treturn ErrRemoteNotFound\n\t}\n\n\tdelete(cfg.Remotes, name)\n\treturn r.Storer.SetConfig(cfg)\n}\n\n// Branch return a Branch if exists\nfunc (r *Repository) Branch(name string) (*config.Branch, error) {\n\tcfg, err := r.Config()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tb, ok := cfg.Branches[name]\n\tif !ok {\n\t\treturn nil, ErrBranchNotFound\n\t}\n\n\treturn b, nil\n}\n\n// CreateBranch creates a new Branch\nfunc (r *Repository) CreateBranch(c *config.Branch) error {\n\tif err := c.Validate(); err != nil {\n\t\treturn err\n\t}\n\n\tcfg, err := r.Config()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif _, ok := cfg.Branches[c.Name]; ok {\n\t\treturn ErrBranchExists\n\t}\n\n\tcfg.Branches[c.Name] = c\n\treturn r.Storer.SetConfig(cfg)\n}\n\n// DeleteBranch delete a Branch from the repository and delete the config\nfunc (r *Repository) DeleteBranch(name string) error {\n\tcfg, err := r.Config()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif _, ok := cfg.Branches[name]; !ok {\n\t\treturn ErrBranchNotFound\n\t}\n\n\tdelete(cfg.Branches, name)\n\treturn r.Storer.SetConfig(cfg)\n}\n\n// CreateTag creates a tag. If opts is included, the tag is an annotated tag,\n// otherwise a lightweight tag is created.\nfunc (r *Repository) CreateTag(name string, hash plumbing.Hash, opts *CreateTagOptions) (*plumbing.Reference, error) {\n\trname := plumbing.NewTagReferenceName(name)\n\tif err := rname.Validate(); err != nil {\n\t\treturn nil, err\n\t}\n\n\t_, err := r.Storer.Reference(rname)\n\tswitch err {\n\tcase nil:\n\t\t// Tag exists, this is an error\n\t\treturn nil, ErrTagExists\n\tcase plumbing.ErrReferenceNotFound:\n\t\t// Tag missing, available for creation, pass this\n\tdefault:\n\t\t// Some other error\n\t\treturn nil, err\n\t}\n\n\tvar target plumbing.Hash\n\tif opts != nil {\n\t\ttarget, err = r.createTagObject(name, hash, opts)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t} else {\n\t\ttarget = hash\n\t}\n\n\tref := plumbing.NewHashReference(rname, target)\n\tif err = r.Storer.SetReference(ref); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn ref, nil\n}\n\nfunc (r *Repository) createTagObject(name string, hash plumbing.Hash, opts *CreateTagOptions) (plumbing.Hash, error) {\n\tif err := opts.Validate(r, hash); err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\trawobj, err := object.GetObject(r.Storer, hash)\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\ttag := &object.Tag{\n\t\tName:       name,\n\t\tTagger:     *opts.Tagger,\n\t\tMessage:    opts.Message,\n\t\tTargetType: rawobj.Type(),\n\t\tTarget:     hash,\n\t}\n\n\tif opts.SignKey != nil {\n\t\tsig, err := r.buildTagSignature(tag, opts.SignKey)\n\t\tif err != nil {\n\t\t\treturn plumbing.ZeroHash, err\n\t\t}\n\n\t\ttag.PGPSignature = sig\n\t}\n\n\tobj := r.Storer.NewEncodedObject()\n\tif err := tag.Encode(obj); err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\treturn r.Storer.SetEncodedObject(obj)\n}\n\nfunc (r *Repository) buildTagSignature(tag *object.Tag, signKey *openpgp.Entity) (string, error) {\n\tencoded := &plumbing.MemoryObject{}\n\tif err := tag.Encode(encoded); err != nil {\n\t\treturn \"\", err\n\t}\n\n\trdr, err := encoded.Reader()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tvar b bytes.Buffer\n\tif err := openpgp.ArmoredDetachSign(&b, signKey, rdr, nil); err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn b.String(), nil\n}\n\n// Tag returns a tag from the repository.\n//\n// If you want to check to see if the tag is an annotated tag, you can call\n// TagObject on the hash of the reference in ForEach:\n//\n//\tref, err := r.Tag(\"v0.1.0\")\n//\tif err != nil {\n//\t  // Handle error\n//\t}\n//\n//\tobj, err := r.TagObject(ref.Hash())\n//\tswitch err {\n//\tcase nil:\n//\t  // Tag object present\n//\tcase plumbing.ErrObjectNotFound:\n//\t  // Not a tag object\n//\tdefault:\n//\t  // Some other error\n//\t}\nfunc (r *Repository) Tag(name string) (*plumbing.Reference, error) {\n\tref, err := r.Reference(plumbing.ReferenceName(path.Join(\"refs\", \"tags\", name)), false)\n\tif err != nil {\n\t\tif err == plumbing.ErrReferenceNotFound {\n\t\t\t// Return a friendly error for this one, versus just ReferenceNotFound.\n\t\t\treturn nil, ErrTagNotFound\n\t\t}\n\n\t\treturn nil, err\n\t}\n\n\treturn ref, nil\n}\n\n// DeleteTag deletes a tag from the repository.\nfunc (r *Repository) DeleteTag(name string) error {\n\t_, err := r.Tag(name)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn r.Storer.RemoveReference(plumbing.ReferenceName(path.Join(\"refs\", \"tags\", name)))\n}\n\nfunc (r *Repository) resolveToCommitHash(h plumbing.Hash) (plumbing.Hash, error) {\n\tobj, err := r.Storer.EncodedObject(plumbing.AnyObject, h)\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\tswitch obj.Type() {\n\tcase plumbing.TagObject:\n\t\tt, err := object.DecodeTag(r.Storer, obj)\n\t\tif err != nil {\n\t\t\treturn plumbing.ZeroHash, err\n\t\t}\n\t\treturn r.resolveToCommitHash(t.Target)\n\tcase plumbing.CommitObject:\n\t\treturn h, nil\n\tdefault:\n\t\treturn plumbing.ZeroHash, ErrUnableToResolveCommit\n\t}\n}\n\n// Clone clones a remote repository\nfunc (r *Repository) clone(ctx context.Context, o *CloneOptions) error {\n\tif err := o.Validate(); err != nil {\n\t\treturn err\n\t}\n\n\tc := &config.RemoteConfig{\n\t\tName:   o.RemoteName,\n\t\tURLs:   []string{o.URL},\n\t\tFetch:  r.cloneRefSpec(o),\n\t\tMirror: o.Mirror,\n\t}\n\n\tif _, err := r.CreateRemote(c); err != nil {\n\t\treturn err\n\t}\n\n\t// When the repository to clone is on the local machine,\n\t// instead of using hard links, automatically setup .git/objects/info/alternates\n\t// to share the objects with the source repository\n\tif o.Shared {\n\t\tif !url.IsLocalEndpoint(o.URL) {\n\t\t\treturn ErrAlternatePathNotSupported\n\t\t}\n\t\taltpath := o.URL\n\t\tremoteRepo, err := PlainOpen(o.URL)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to open remote repository: %w\", err)\n\t\t}\n\t\tconf, err := remoteRepo.Config()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to read remote repository configuration: %w\", err)\n\t\t}\n\t\tif !conf.Core.IsBare {\n\t\t\taltpath = path.Join(altpath, GitDirName)\n\t\t}\n\t\tif err := r.Storer.AddAlternate(altpath); err != nil {\n\t\t\treturn fmt.Errorf(\"failed to add alternate file to git objects dir: %w\", err)\n\t\t}\n\t}\n\n\tref, err := r.fetchAndUpdateReferences(ctx, &FetchOptions{\n\t\tRefSpecs:        c.Fetch,\n\t\tDepth:           o.Depth,\n\t\tAuth:            o.Auth,\n\t\tProgress:        o.Progress,\n\t\tTags:            o.Tags,\n\t\tRemoteName:      o.RemoteName,\n\t\tInsecureSkipTLS: o.InsecureSkipTLS,\n\t\tCABundle:        o.CABundle,\n\t\tProxyOptions:    o.ProxyOptions,\n\t}, o.ReferenceName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif r.wt != nil && !o.NoCheckout {\n\t\tw, err := r.Worktree()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\thead, err := r.Head()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif err := w.Reset(&ResetOptions{\n\t\t\tMode:   MergeReset,\n\t\t\tCommit: head.Hash(),\n\t\t}); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif o.RecurseSubmodules != NoRecurseSubmodules {\n\t\t\tif err := w.updateSubmodules(ctx, &SubmoduleUpdateOptions{\n\t\t\t\tRecurseSubmodules: o.RecurseSubmodules,\n\t\t\t\tDepth: func() int {\n\t\t\t\t\tif o.ShallowSubmodules {\n\t\t\t\t\t\treturn 1\n\t\t\t\t\t}\n\t\t\t\t\treturn 0\n\t\t\t\t}(),\n\t\t\t\tAuth: o.Auth,\n\t\t\t}); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\tif err := r.updateRemoteConfigIfNeeded(o, c, ref); err != nil {\n\t\treturn err\n\t}\n\n\tif !o.Mirror && ref.Name().IsBranch() {\n\t\tbranchRef := ref.Name()\n\t\tbranchName := strings.Split(string(branchRef), \"refs/heads/\")[1]\n\n\t\tb := &config.Branch{\n\t\t\tName:  branchName,\n\t\t\tMerge: branchRef,\n\t\t}\n\n\t\tif o.RemoteName == \"\" {\n\t\t\tb.Remote = \"origin\"\n\t\t} else {\n\t\t\tb.Remote = o.RemoteName\n\t\t}\n\n\t\tif err := r.CreateBranch(b); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\nconst (\n\trefspecTag              = \"+refs/tags/%s:refs/tags/%[1]s\"\n\trefspecSingleBranch     = \"+refs/heads/%s:refs/remotes/%s/%[1]s\"\n\trefspecSingleBranchHEAD = \"+HEAD:refs/remotes/%s/HEAD\"\n)\n\nfunc (r *Repository) cloneRefSpec(o *CloneOptions) []config.RefSpec {\n\tswitch {\n\tcase o.Mirror:\n\t\treturn []config.RefSpec{\"+refs/*:refs/*\"}\n\tcase o.ReferenceName.IsTag():\n\t\treturn []config.RefSpec{\n\t\t\tconfig.RefSpec(fmt.Sprintf(refspecTag, o.ReferenceName.Short())),\n\t\t}\n\tcase o.SingleBranch && o.ReferenceName == plumbing.HEAD:\n\t\treturn []config.RefSpec{\n\t\t\tconfig.RefSpec(fmt.Sprintf(refspecSingleBranchHEAD, o.RemoteName)),\n\t\t}\n\tcase o.SingleBranch:\n\t\treturn []config.RefSpec{\n\t\t\tconfig.RefSpec(fmt.Sprintf(refspecSingleBranch, o.ReferenceName.Short(), o.RemoteName)),\n\t\t}\n\tdefault:\n\t\treturn []config.RefSpec{\n\t\t\tconfig.RefSpec(fmt.Sprintf(config.DefaultFetchRefSpec, o.RemoteName)),\n\t\t}\n\t}\n}\n\nfunc (r *Repository) setIsBare(isBare bool) error {\n\tcfg, err := r.Config()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tcfg.Core.IsBare = isBare\n\treturn r.Storer.SetConfig(cfg)\n}\n\nfunc (r *Repository) updateRemoteConfigIfNeeded(o *CloneOptions, c *config.RemoteConfig, _ *plumbing.Reference) error {\n\tif !o.SingleBranch {\n\t\treturn nil\n\t}\n\n\tc.Fetch = r.cloneRefSpec(o)\n\n\tcfg, err := r.Config()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tcfg.Remotes[c.Name] = c\n\treturn r.Storer.SetConfig(cfg)\n}\n\nfunc (r *Repository) fetchAndUpdateReferences(\n\tctx context.Context, o *FetchOptions, ref plumbing.ReferenceName,\n) (*plumbing.Reference, error) {\n\n\tif err := o.Validate(); err != nil {\n\t\treturn nil, err\n\t}\n\n\tremote, err := r.Remote(o.RemoteName)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tobjsUpdated := true\n\tremoteRefs, err := remote.fetch(ctx, o)\n\tif err == NoErrAlreadyUpToDate {\n\t\tobjsUpdated = false\n\t} else if err == packfile.ErrEmptyPackfile {\n\t\treturn nil, ErrFetching\n\t} else if err != nil {\n\t\treturn nil, err\n\t}\n\n\tresolvedRef, err := expand_ref(remoteRefs, ref)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\trefsUpdated, err := r.updateReferences(remote.c.Fetch, resolvedRef)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif !objsUpdated && !refsUpdated {\n\t\treturn nil, NoErrAlreadyUpToDate\n\t}\n\n\treturn resolvedRef, nil\n}\n\nfunc (r *Repository) updateReferences(spec []config.RefSpec,\n\tresolvedRef *plumbing.Reference) (updated bool, err error) {\n\n\tif !resolvedRef.Name().IsBranch() {\n\t\t// Detached HEAD mode\n\t\th, err := r.resolveToCommitHash(resolvedRef.Hash())\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\thead := plumbing.NewHashReference(plumbing.HEAD, h)\n\t\treturn updateReferenceStorerIfNeeded(r.Storer, head)\n\t}\n\n\trefs := []*plumbing.Reference{\n\t\t// Create local reference for the resolved ref\n\t\tresolvedRef,\n\t\t// Create local symbolic HEAD\n\t\tplumbing.NewSymbolicReference(plumbing.HEAD, resolvedRef.Name()),\n\t}\n\n\trefs = append(refs, r.calculateRemoteHeadReference(spec, resolvedRef)...)\n\n\tfor _, ref := range refs {\n\t\tu, err := updateReferenceStorerIfNeeded(r.Storer, ref)\n\t\tif err != nil {\n\t\t\treturn updated, err\n\t\t}\n\n\t\tif u {\n\t\t\tupdated = true\n\t\t}\n\t}\n\n\treturn\n}\n\nfunc (r *Repository) calculateRemoteHeadReference(spec []config.RefSpec,\n\tresolvedHead *plumbing.Reference) []*plumbing.Reference {\n\n\tvar refs []*plumbing.Reference\n\n\t// Create resolved HEAD reference with remote prefix if it does not\n\t// exist. This is needed when using single branch and HEAD.\n\tfor _, rs := range spec {\n\t\tname := resolvedHead.Name()\n\t\tif !rs.Match(name) {\n\t\t\tcontinue\n\t\t}\n\n\t\tname = rs.Dst(name)\n\t\t_, err := r.Storer.Reference(name)\n\t\tif err == plumbing.ErrReferenceNotFound {\n\t\t\trefs = append(refs, plumbing.NewHashReference(name, resolvedHead.Hash()))\n\t\t}\n\t}\n\n\treturn refs\n}\n\nfunc checkAndUpdateReferenceStorerIfNeeded(\n\ts storer.ReferenceStorer, r, old *plumbing.Reference) (\n\tupdated bool, err error) {\n\tp, err := s.Reference(r.Name())\n\tif err != nil && err != plumbing.ErrReferenceNotFound {\n\t\treturn false, err\n\t}\n\n\t// we use the string method to compare references, is the easiest way\n\tif err == plumbing.ErrReferenceNotFound || r.String() != p.String() {\n\t\tif err := s.CheckAndSetReference(r, old); err != nil {\n\t\t\treturn false, err\n\t\t}\n\n\t\treturn true, nil\n\t}\n\n\treturn false, nil\n}\n\nfunc updateReferenceStorerIfNeeded(\n\ts storer.ReferenceStorer, r *plumbing.Reference) (updated bool, err error) {\n\treturn checkAndUpdateReferenceStorerIfNeeded(s, r, nil)\n}\n\n// Fetch fetches references along with the objects necessary to complete\n// their histories, from the remote named as FetchOptions.RemoteName.\n//\n// Returns nil if the operation is successful, NoErrAlreadyUpToDate if there are\n// no changes to be fetched, or an error.\nfunc (r *Repository) Fetch(o *FetchOptions) error {\n\treturn r.FetchContext(context.Background(), o)\n}\n\n// FetchContext fetches references along with the objects necessary to complete\n// their histories, from the remote named as FetchOptions.RemoteName.\n//\n// Returns nil if the operation is successful, NoErrAlreadyUpToDate if there are\n// no changes to be fetched, or an error.\n//\n// The provided Context must be non-nil. If the context expires before the\n// operation is complete, an error is returned. The context only affects the\n// transport operations.\nfunc (r *Repository) FetchContext(ctx context.Context, o *FetchOptions) error {\n\tif err := o.Validate(); err != nil {\n\t\treturn err\n\t}\n\n\tremote, err := r.Remote(o.RemoteName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn remote.FetchContext(ctx, o)\n}\n\n// Push performs a push to the remote. Returns NoErrAlreadyUpToDate if\n// the remote was already up-to-date, from the remote named as\n// FetchOptions.RemoteName.\nfunc (r *Repository) Push(o *PushOptions) error {\n\treturn r.PushContext(context.Background(), o)\n}\n\n// PushContext performs a push to the remote. Returns NoErrAlreadyUpToDate if\n// the remote was already up-to-date, from the remote named as\n// FetchOptions.RemoteName.\n//\n// The provided Context must be non-nil. If the context expires before the\n// operation is complete, an error is returned. The context only affects the\n// transport operations.\nfunc (r *Repository) PushContext(ctx context.Context, o *PushOptions) error {\n\tif err := o.Validate(); err != nil {\n\t\treturn err\n\t}\n\n\tremote, err := r.Remote(o.RemoteName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn remote.PushContext(ctx, o)\n}\n\n// Log returns the commit history from the given LogOptions.\nfunc (r *Repository) Log(o *LogOptions) (object.CommitIter, error) {\n\tfn := commitIterFunc(o.Order)\n\tif fn == nil {\n\t\treturn nil, fmt.Errorf(\"invalid Order=%v\", o.Order)\n\t}\n\n\tvar (\n\t\tit  object.CommitIter\n\t\terr error\n\t)\n\tif o.All {\n\t\tit, err = r.logAll(fn)\n\t} else {\n\t\tit, err = r.log(o.From, fn)\n\t}\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif o.FileName != nil {\n\t\t// for `git log --all` also check parent (if the next commit comes from the real parent)\n\t\tit = r.logWithFile(*o.FileName, it, o.All)\n\t}\n\tif o.PathFilter != nil {\n\t\tit = r.logWithPathFilter(o.PathFilter, it, o.All)\n\t}\n\n\tif o.Since != nil || o.Until != nil {\n\t\tlimitOptions := object.LogLimitOptions{Since: o.Since, Until: o.Until}\n\t\tit = r.logWithLimit(it, limitOptions)\n\t}\n\n\treturn it, nil\n}\n\nfunc (r *Repository) log(from plumbing.Hash, commitIterFunc func(*object.Commit) object.CommitIter) (object.CommitIter, error) {\n\th := from\n\tif from == plumbing.ZeroHash {\n\t\thead, err := r.Head()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\th = head.Hash()\n\t}\n\n\tcommit, err := r.CommitObject(h)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn commitIterFunc(commit), nil\n}\n\nfunc (r *Repository) logAll(commitIterFunc func(*object.Commit) object.CommitIter) (object.CommitIter, error) {\n\treturn object.NewCommitAllIter(r.Storer, commitIterFunc)\n}\n\nfunc (*Repository) logWithFile(fileName string, commitIter object.CommitIter, checkParent bool) object.CommitIter {\n\treturn object.NewCommitPathIterFromIter(\n\t\tfunc(path string) bool {\n\t\t\treturn path == fileName\n\t\t},\n\t\tcommitIter,\n\t\tcheckParent,\n\t)\n}\n\nfunc (*Repository) logWithPathFilter(pathFilter func(string) bool, commitIter object.CommitIter, checkParent bool) object.CommitIter {\n\treturn object.NewCommitPathIterFromIter(\n\t\tpathFilter,\n\t\tcommitIter,\n\t\tcheckParent,\n\t)\n}\n\nfunc (*Repository) logWithLimit(commitIter object.CommitIter, limitOptions object.LogLimitOptions) object.CommitIter {\n\treturn object.NewCommitLimitIterFromIter(commitIter, limitOptions)\n}\n\nfunc commitIterFunc(order LogOrder) func(c *object.Commit) object.CommitIter {\n\tswitch order {\n\tcase LogOrderDefault:\n\t\treturn func(c *object.Commit) object.CommitIter {\n\t\t\treturn object.NewCommitPreorderIter(c, nil, nil)\n\t\t}\n\tcase LogOrderDFS:\n\t\treturn func(c *object.Commit) object.CommitIter {\n\t\t\treturn object.NewCommitPreorderIter(c, nil, nil)\n\t\t}\n\tcase LogOrderDFSPost:\n\t\treturn func(c *object.Commit) object.CommitIter {\n\t\t\treturn object.NewCommitPostorderIter(c, nil)\n\t\t}\n\tcase LogOrderBSF:\n\t\treturn func(c *object.Commit) object.CommitIter {\n\t\t\treturn object.NewCommitIterBSF(c, nil, nil)\n\t\t}\n\tcase LogOrderCommitterTime:\n\t\treturn func(c *object.Commit) object.CommitIter {\n\t\t\treturn object.NewCommitIterCTime(c, nil, nil)\n\t\t}\n\t}\n\treturn nil\n}\n\n// Tags returns all the tag References in a repository.\n//\n// If you want to check to see if the tag is an annotated tag, you can call\n// TagObject on the hash Reference passed in through ForEach:\n//\n//\titer, err := r.Tags()\n//\tif err != nil {\n//\t  // Handle error\n//\t}\n//\n//\tif err := iter.ForEach(func (ref *plumbing.Reference) error {\n//\t  obj, err := r.TagObject(ref.Hash())\n//\t  switch err {\n//\t  case nil:\n//\t    // Tag object present\n//\t  case plumbing.ErrObjectNotFound:\n//\t    // Not a tag object\n//\t  default:\n//\t    // Some other error\n//\t    return err\n//\t  }\n//\t}); err != nil {\n//\t  // Handle outer iterator error\n//\t}\nfunc (r *Repository) Tags() (storer.ReferenceIter, error) {\n\trefIter, err := r.Storer.IterReferences()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn storer.NewReferenceFilteredIter(\n\t\tfunc(r *plumbing.Reference) bool {\n\t\t\treturn r.Name().IsTag()\n\t\t}, refIter), nil\n}\n\n// Branches returns all the References that are Branches.\nfunc (r *Repository) Branches() (storer.ReferenceIter, error) {\n\trefIter, err := r.Storer.IterReferences()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn storer.NewReferenceFilteredIter(\n\t\tfunc(r *plumbing.Reference) bool {\n\t\t\treturn r.Name().IsBranch()\n\t\t}, refIter), nil\n}\n\n// Notes returns all the References that are notes. For more information:\n// https://git-scm.com/docs/git-notes\nfunc (r *Repository) Notes() (storer.ReferenceIter, error) {\n\trefIter, err := r.Storer.IterReferences()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn storer.NewReferenceFilteredIter(\n\t\tfunc(r *plumbing.Reference) bool {\n\t\t\treturn r.Name().IsNote()\n\t\t}, refIter), nil\n}\n\n// TreeObject return a Tree with the given hash. If not found\n// plumbing.ErrObjectNotFound is returned\nfunc (r *Repository) TreeObject(h plumbing.Hash) (*object.Tree, error) {\n\treturn object.GetTree(r.Storer, h)\n}\n\n// TreeObjects returns an unsorted TreeIter with all the trees in the repository\nfunc (r *Repository) TreeObjects() (*object.TreeIter, error) {\n\titer, err := r.Storer.IterEncodedObjects(plumbing.TreeObject)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn object.NewTreeIter(r.Storer, iter), nil\n}\n\n// CommitObject return a Commit with the given hash. If not found\n// plumbing.ErrObjectNotFound is returned.\nfunc (r *Repository) CommitObject(h plumbing.Hash) (*object.Commit, error) {\n\treturn object.GetCommit(r.Storer, h)\n}\n\n// CommitObjects returns an unsorted CommitIter with all the commits in the repository.\nfunc (r *Repository) CommitObjects() (object.CommitIter, error) {\n\titer, err := r.Storer.IterEncodedObjects(plumbing.CommitObject)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn object.NewCommitIter(r.Storer, iter), nil\n}\n\n// BlobObject returns a Blob with the given hash. If not found\n// plumbing.ErrObjectNotFound is returned.\nfunc (r *Repository) BlobObject(h plumbing.Hash) (*object.Blob, error) {\n\treturn object.GetBlob(r.Storer, h)\n}\n\n// BlobObjects returns an unsorted BlobIter with all the blobs in the repository.\nfunc (r *Repository) BlobObjects() (*object.BlobIter, error) {\n\titer, err := r.Storer.IterEncodedObjects(plumbing.BlobObject)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn object.NewBlobIter(r.Storer, iter), nil\n}\n\n// TagObject returns a Tag with the given hash. If not found\n// plumbing.ErrObjectNotFound is returned. This method only returns\n// annotated Tags, no lightweight Tags.\nfunc (r *Repository) TagObject(h plumbing.Hash) (*object.Tag, error) {\n\treturn object.GetTag(r.Storer, h)\n}\n\n// TagObjects returns a unsorted TagIter that can step through all of the annotated\n// tags in the repository.\nfunc (r *Repository) TagObjects() (*object.TagIter, error) {\n\titer, err := r.Storer.IterEncodedObjects(plumbing.TagObject)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn object.NewTagIter(r.Storer, iter), nil\n}\n\n// Object returns an Object with the given hash. If not found\n// plumbing.ErrObjectNotFound is returned.\nfunc (r *Repository) Object(t plumbing.ObjectType, h plumbing.Hash) (object.Object, error) {\n\tobj, err := r.Storer.EncodedObject(t, h)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn object.DecodeObject(r.Storer, obj)\n}\n\n// Objects returns an unsorted ObjectIter with all the objects in the repository.\nfunc (r *Repository) Objects() (*object.ObjectIter, error) {\n\titer, err := r.Storer.IterEncodedObjects(plumbing.AnyObject)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn object.NewObjectIter(r.Storer, iter), nil\n}\n\n// Head returns the reference where HEAD is pointing to.\nfunc (r *Repository) Head() (*plumbing.Reference, error) {\n\treturn storer.ResolveReference(r.Storer, plumbing.HEAD)\n}\n\n// Reference returns the reference for a given reference name. If resolved is\n// true, any symbolic reference will be resolved.\nfunc (r *Repository) Reference(name plumbing.ReferenceName, resolved bool) (\n\t*plumbing.Reference, error) {\n\n\tif resolved {\n\t\treturn storer.ResolveReference(r.Storer, name)\n\t}\n\n\treturn r.Storer.Reference(name)\n}\n\n// References returns an unsorted ReferenceIter for all references.\nfunc (r *Repository) References() (storer.ReferenceIter, error) {\n\treturn r.Storer.IterReferences()\n}\n\n// Worktree returns a worktree based on the given fs, if nil the default\n// worktree will be used.\nfunc (r *Repository) Worktree() (*Worktree, error) {\n\tif r.wt == nil {\n\t\treturn nil, ErrIsBareRepository\n\t}\n\n\treturn &Worktree{r: r, Filesystem: r.wt}, nil\n}\n\nfunc expand_ref(s storer.ReferenceStorer, ref plumbing.ReferenceName) (*plumbing.Reference, error) {\n\t// For improving troubleshooting, this preserves the error for the provided `ref`,\n\t// and returns the error for that specific ref in case all parse rules fails.\n\tvar ret error\n\tfor _, rule := range plumbing.RefRevParseRules {\n\t\tresolvedRef, err := storer.ResolveReference(s, plumbing.ReferenceName(fmt.Sprintf(rule, ref)))\n\n\t\tif err == nil {\n\t\t\treturn resolvedRef, nil\n\t\t} else if ret == nil {\n\t\t\tret = err\n\t\t}\n\t}\n\n\treturn nil, ret\n}\n\n// ResolveRevision resolves revision to corresponding hash. It will always\n// resolve to a commit hash, not a tree or annotated tag.\n//\n// Implemented resolvers : HEAD, branch, tag, heads/branch, refs/heads/branch,\n// refs/tags/tag, refs/remotes/origin/branch, refs/remotes/origin/HEAD, tilde and caret (HEAD~1, master~^, tag~2, ref/heads/master~1, ...), selection by text (HEAD^{/fix nasty bug}), hash (prefix and full)\nfunc (r *Repository) ResolveRevision(in plumbing.Revision) (*plumbing.Hash, error) {\n\trev := in.String()\n\tif rev == \"\" {\n\t\treturn &plumbing.ZeroHash, plumbing.ErrReferenceNotFound\n\t}\n\n\tp := revision.NewParserFromString(rev)\n\titems, err := p.Parse()\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar commit *object.Commit\n\n\tfor _, item := range items {\n\t\tswitch item := item.(type) {\n\t\tcase revision.Ref:\n\t\t\trevisionRef := item\n\n\t\t\tvar tryHashes []plumbing.Hash\n\n\t\t\ttryHashes = append(tryHashes, r.resolveHashPrefix(string(revisionRef))...)\n\n\t\t\tref, err := expand_ref(r.Storer, plumbing.ReferenceName(revisionRef))\n\t\t\tif err == nil {\n\t\t\t\ttryHashes = append(tryHashes, ref.Hash())\n\t\t\t}\n\n\t\t\t// in ambiguous cases, `git rev-parse` will emit a warning, but\n\t\t\t// will always return the oid in preference to a ref; we don't have\n\t\t\t// the ability to emit a warning here, so (for speed purposes)\n\t\t\t// don't bother to detect the ambiguity either, just return in the\n\t\t\t// priority that git would.\n\t\t\tgotOne := false\n\t\t\tfor _, hash := range tryHashes {\n\t\t\t\tcommitObj, err := r.CommitObject(hash)\n\t\t\t\tif err == nil {\n\t\t\t\t\tcommit = commitObj\n\t\t\t\t\tgotOne = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\n\t\t\t\ttagObj, err := r.TagObject(hash)\n\t\t\t\tif err == nil {\n\t\t\t\t\t// If the tag target lookup fails here, this most likely\n\t\t\t\t\t// represents some sort of repo corruption, so let the\n\t\t\t\t\t// error bubble up.\n\t\t\t\t\ttagCommit, err := tagObj.Commit()\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn &plumbing.ZeroHash, err\n\t\t\t\t\t}\n\t\t\t\t\tcommit = tagCommit\n\t\t\t\t\tgotOne = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif !gotOne {\n\t\t\t\treturn &plumbing.ZeroHash, plumbing.ErrReferenceNotFound\n\t\t\t}\n\n\t\tcase revision.CaretPath:\n\t\t\tdepth := item.Depth\n\n\t\t\tif depth == 0 {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\titer := commit.Parents()\n\n\t\t\tc, err := iter.Next()\n\n\t\t\tif err != nil {\n\t\t\t\treturn &plumbing.ZeroHash, err\n\t\t\t}\n\n\t\t\tif depth == 1 {\n\t\t\t\tcommit = c\n\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\tc, err = iter.Next()\n\n\t\t\tif err != nil {\n\t\t\t\treturn &plumbing.ZeroHash, err\n\t\t\t}\n\n\t\t\tcommit = c\n\t\tcase revision.TildePath:\n\t\t\tfor i := 0; i < item.Depth; i++ {\n\t\t\t\tc, err := commit.Parents().Next()\n\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn &plumbing.ZeroHash, err\n\t\t\t\t}\n\n\t\t\t\tcommit = c\n\t\t\t}\n\t\tcase revision.CaretReg:\n\t\t\thistory := object.NewCommitPreorderIter(commit, nil, nil)\n\n\t\t\tre := item.Regexp\n\t\t\tnegate := item.Negate\n\n\t\t\tvar c *object.Commit\n\n\t\t\terr := history.ForEach(func(hc *object.Commit) error {\n\t\t\t\tif !negate && re.MatchString(hc.Message) {\n\t\t\t\t\tc = hc\n\t\t\t\t\treturn storer.ErrStop\n\t\t\t\t}\n\n\t\t\t\tif negate && !re.MatchString(hc.Message) {\n\t\t\t\t\tc = hc\n\t\t\t\t\treturn storer.ErrStop\n\t\t\t\t}\n\n\t\t\t\treturn nil\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\treturn &plumbing.ZeroHash, err\n\t\t\t}\n\n\t\t\tif c == nil {\n\t\t\t\treturn &plumbing.ZeroHash, fmt.Errorf(\"no commit message match regexp: %q\", re.String())\n\t\t\t}\n\n\t\t\tcommit = c\n\t\t}\n\t}\n\n\tif commit == nil {\n\t\treturn &plumbing.ZeroHash, plumbing.ErrReferenceNotFound\n\t}\n\n\treturn &commit.Hash, nil\n}\n\n// resolveHashPrefix returns a list of potential hashes that the given string\n// is a prefix of. It quietly swallows errors, returning nil.\nfunc (r *Repository) resolveHashPrefix(hashStr string) []plumbing.Hash {\n\t// Handle complete and partial hashes.\n\t// plumbing.NewHash forces args into a full 20 byte hash, which isn't suitable\n\t// for partial hashes since they will become zero-filled.\n\n\tif hashStr == \"\" {\n\t\treturn nil\n\t}\n\tif len(hashStr) == len(plumbing.ZeroHash)*2 {\n\t\t// Only a full hash is possible.\n\t\thexb, err := hex.DecodeString(hashStr)\n\t\tif err != nil {\n\t\t\treturn nil\n\t\t}\n\t\tvar h plumbing.Hash\n\t\tcopy(h[:], hexb)\n\t\treturn []plumbing.Hash{h}\n\t}\n\n\t// Partial hash.\n\t// hex.DecodeString only decodes to complete bytes, so only works with pairs of hex digits.\n\tevenHex := hashStr[:len(hashStr)&^1]\n\thexb, err := hex.DecodeString(evenHex)\n\tif err != nil {\n\t\treturn nil\n\t}\n\tcandidates := expandPartialHash(r.Storer, hexb)\n\tif len(evenHex) == len(hashStr) {\n\t\t// The prefix was an exact number of bytes.\n\t\treturn candidates\n\t}\n\t// Do another prefix check to ensure the dangling nybble is correct.\n\tvar hashes []plumbing.Hash\n\tfor _, h := range candidates {\n\t\tif strings.HasPrefix(h.String(), hashStr) {\n\t\t\thashes = append(hashes, h)\n\t\t}\n\t}\n\treturn hashes\n}\n\ntype RepackConfig struct {\n\t// UseRefDeltas configures whether packfile encoder will use reference deltas.\n\t// By default OFSDeltaObject is used.\n\tUseRefDeltas bool\n\t// OnlyDeletePacksOlderThan if set to non-zero value\n\t// selects only objects older than the time provided.\n\tOnlyDeletePacksOlderThan time.Time\n}\n\nfunc (r *Repository) RepackObjects(cfg *RepackConfig) (err error) {\n\tpos, ok := r.Storer.(storer.PackedObjectStorer)\n\tif !ok {\n\t\treturn ErrPackedObjectsNotSupported\n\t}\n\n\t// Get the existing object packs.\n\ths, err := pos.ObjectPacks()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Create a new pack.\n\tnh, err := r.createNewObjectPack(cfg)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Delete old packs.\n\tfor _, h := range hs {\n\t\t// Skip if new hash is the same as an old one.\n\t\tif h == nh {\n\t\t\tcontinue\n\t\t}\n\t\terr = pos.DeleteOldObjectPackAndIndex(h, cfg.OnlyDeletePacksOlderThan)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// Merge merges the reference branch into the current branch.\n//\n// If the merge is not possible (or supported) returns an error without changing\n// the HEAD for the current branch. Possible errors include:\n//   - The merge strategy is not supported.\n//   - The specific strategy cannot be used (e.g. using FastForwardMerge when one is not possible).\nfunc (r *Repository) Merge(ref plumbing.Reference, opts MergeOptions) error {\n\tif opts.Strategy != FastForwardMerge {\n\t\treturn ErrUnsupportedMergeStrategy\n\t}\n\n\t// Ignore error as not having a shallow list is optional here.\n\tshallowList, _ := r.Storer.Shallow()\n\tvar earliestShallow *plumbing.Hash\n\tif len(shallowList) > 0 {\n\t\tearliestShallow = &shallowList[0]\n\t}\n\n\thead, err := r.Head()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tff, err := isFastForward(r.Storer, head.Hash(), ref.Hash(), earliestShallow)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif !ff {\n\t\treturn ErrFastForwardMergeNotPossible\n\t}\n\n\treturn r.Storer.SetReference(plumbing.NewHashReference(head.Name(), ref.Hash()))\n}\n\n// createNewObjectPack is a helper for RepackObjects taking care\n// of creating a new pack. It is used so the PackfileWriter\n// deferred close has the right scope.\nfunc (r *Repository) createNewObjectPack(cfg *RepackConfig) (h plumbing.Hash, err error) {\n\tow := newObjectWalker(r.Storer)\n\terr = ow.walkAllRefs()\n\tif err != nil {\n\t\treturn h, err\n\t}\n\tobjs := make([]plumbing.Hash, 0, len(ow.seen))\n\tfor h := range ow.seen {\n\t\tobjs = append(objs, h)\n\t}\n\tpfw, ok := r.Storer.(storer.PackfileWriter)\n\tif !ok {\n\t\treturn h, fmt.Errorf(\"Repository storer is not a storer.PackfileWriter\")\n\t}\n\twc, err := pfw.PackfileWriter()\n\tif err != nil {\n\t\treturn h, err\n\t}\n\tdefer ioutil.CheckClose(wc, &err)\n\tscfg, err := r.Config()\n\tif err != nil {\n\t\treturn h, err\n\t}\n\tenc := packfile.NewEncoder(wc, r.Storer, cfg.UseRefDeltas)\n\th, err = enc.Encode(objs, scfg.Pack.Window)\n\tif err != nil {\n\t\treturn h, err\n\t}\n\n\t// Delete the packed, loose objects.\n\tif los, ok := r.Storer.(storer.LooseObjectStorer); ok {\n\t\terr = los.ForEachObjectHash(func(hash plumbing.Hash) error {\n\t\t\tif ow.isSeen(hash) {\n\t\t\t\terr = los.DeleteLooseObject(hash)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t\tif err != nil {\n\t\t\treturn h, err\n\t\t}\n\t}\n\n\treturn h, err\n}\n\nfunc expandPartialHash(st storer.EncodedObjectStorer, prefix []byte) (hashes []plumbing.Hash) {\n\t// The fast version is implemented by storage/filesystem.ObjectStorage.\n\ttype fastIter interface {\n\t\tHashesWithPrefix(prefix []byte) ([]plumbing.Hash, error)\n\t}\n\tif fi, ok := st.(fastIter); ok {\n\t\th, err := fi.HashesWithPrefix(prefix)\n\t\tif err != nil {\n\t\t\treturn nil\n\t\t}\n\t\treturn h\n\t}\n\n\t// Slow path.\n\titer, err := st.IterEncodedObjects(plumbing.AnyObject)\n\tif err != nil {\n\t\treturn nil\n\t}\n\titer.ForEach(func(obj plumbing.EncodedObject) error {\n\t\th := obj.Hash()\n\t\tif bytes.HasPrefix(h[:], prefix) {\n\t\t\thashes = append(hashes, h)\n\t\t}\n\t\treturn nil\n\t})\n\treturn\n}\n"
        },
        {
          "name": "repository_plan9_test.go",
          "type": "blob",
          "size": 0.9384765625,
          "content": "package git\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n)\n\n// preReceiveHook returns the bytes of a pre-receive hook script\n// that prints m before exiting successfully\nfunc preReceiveHook(m string) []byte {\n\treturn []byte(fmt.Sprintf(\"#!/bin/rc\\necho -n %s\\n\", quote(m)))\n}\n\nconst quoteChar = '\\''\n\nfunc needsQuote(s string) bool {\n\tfor i := 0; i < len(s); i++ {\n\t\tc := s[i]\n\t\tif c == quoteChar || c <= ' ' { // quote, blanks, or control characters\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// Quote adds single quotes to s in the style of rc(1) if they are needed.\n// The behaviour should be identical to Plan 9's quote(3).\nfunc quote(s string) string {\n\tif s == \"\" {\n\t\treturn \"''\"\n\t}\n\tif !needsQuote(s) {\n\t\treturn s\n\t}\n\tvar b strings.Builder\n\tb.Grow(10 + len(s)) // Enough room for few quotes\n\tb.WriteByte(quoteChar)\n\tfor i := 0; i < len(s); i++ {\n\t\tc := s[i]\n\t\tif c == quoteChar {\n\t\t\tb.WriteByte(quoteChar)\n\t\t}\n\t\tb.WriteByte(c)\n\t}\n\tb.WriteByte(quoteChar)\n\treturn b.String()\n}\n"
        },
        {
          "name": "repository_test.go",
          "type": "blob",
          "size": 87.4609375,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"os/exec\"\n\t\"os/user\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\tfixtures \"github.com/go-git/go-git-fixtures/v4\"\n\n\t\"github.com/ProtonMail/go-crypto/openpgp\"\n\t\"github.com/ProtonMail/go-crypto/openpgp/armor\"\n\topenpgperr \"github.com/ProtonMail/go-crypto/openpgp/errors\"\n\n\t\"github.com/go-git/go-git/v5/config\"\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/plumbing/cache\"\n\t\"github.com/go-git/go-git/v5/plumbing/object\"\n\t\"github.com/go-git/go-git/v5/plumbing/storer\"\n\t\"github.com/go-git/go-git/v5/plumbing/transport\"\n\t\"github.com/go-git/go-git/v5/storage\"\n\t\"github.com/go-git/go-git/v5/storage/filesystem\"\n\t\"github.com/go-git/go-git/v5/storage/memory\"\n\n\t\"github.com/go-git/go-billy/v5\"\n\t\"github.com/go-git/go-billy/v5/memfs\"\n\t\"github.com/go-git/go-billy/v5/osfs\"\n\t\"github.com/go-git/go-billy/v5/util\"\n\t. \"gopkg.in/check.v1\"\n)\n\ntype RepositorySuite struct {\n\tBaseSuite\n}\n\nvar _ = Suite(&RepositorySuite{})\n\nfunc (s *RepositorySuite) TestInit(c *C) {\n\tr, err := Init(memory.NewStorage(), memfs.New())\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Core.IsBare, Equals, false)\n\n\t// check the HEAD to see what the default branch is\n\tcreateCommit(c, r)\n\tref, err := r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(ref.Name().String(), Equals, plumbing.Master.String())\n}\n\nfunc (s *RepositorySuite) TestInitWithOptions(c *C) {\n\tr, err := InitWithOptions(memory.NewStorage(), memfs.New(), InitOptions{\n\t\tDefaultBranch: \"refs/heads/foo\",\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\tcreateCommit(c, r)\n\n\tref, err := r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(ref.Name().String(), Equals, \"refs/heads/foo\")\n\n}\n\nfunc (s *RepositorySuite) TestInitWithInvalidDefaultBranch(c *C) {\n\t_, err := InitWithOptions(memory.NewStorage(), memfs.New(), InitOptions{\n\t\tDefaultBranch: \"foo\",\n\t})\n\tc.Assert(err, NotNil)\n}\n\nfunc createCommit(c *C, r *Repository) plumbing.Hash {\n\t// Create a commit so there is a HEAD to check\n\twt, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\trm, err := wt.Filesystem.Create(\"foo.txt\")\n\tc.Assert(err, IsNil)\n\n\t_, err = rm.Write([]byte(\"foo text\"))\n\tc.Assert(err, IsNil)\n\n\t_, err = wt.Add(\"foo.txt\")\n\tc.Assert(err, IsNil)\n\n\tauthor := object.Signature{\n\t\tName:  \"go-git\",\n\t\tEmail: \"go-git@fake.local\",\n\t\tWhen:  time.Now(),\n\t}\n\n\th, err := wt.Commit(\"test commit message\", &CommitOptions{\n\t\tAll:               true,\n\t\tAuthor:            &author,\n\t\tCommitter:         &author,\n\t\tAllowEmptyCommits: true,\n\t})\n\tc.Assert(err, IsNil)\n\treturn h\n}\n\nfunc (s *RepositorySuite) TestInitNonStandardDotGit(c *C) {\n\tdir := c.MkDir()\n\n\tfs := osfs.New(dir)\n\tdot, _ := fs.Chroot(\"storage\")\n\tst := filesystem.NewStorage(dot, cache.NewObjectLRUDefault())\n\n\twt, _ := fs.Chroot(\"worktree\")\n\tr, err := Init(st, wt)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tf, err := fs.Open(fs.Join(\"worktree\", \".git\"))\n\tc.Assert(err, IsNil)\n\tdefer func() { _ = f.Close() }()\n\n\tall, err := io.ReadAll(f)\n\tc.Assert(err, IsNil)\n\tc.Assert(string(all), Equals, fmt.Sprintf(\"gitdir: %s\\n\", filepath.Join(\"..\", \"storage\")))\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Core.Worktree, Equals, filepath.Join(\"..\", \"worktree\"))\n}\n\nfunc (s *RepositorySuite) TestInitStandardDotGit(c *C) {\n\tdir := c.MkDir()\n\n\tfs := osfs.New(dir)\n\tdot, _ := fs.Chroot(\".git\")\n\tst := filesystem.NewStorage(dot, cache.NewObjectLRUDefault())\n\n\tr, err := Init(st, fs)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tl, err := fs.ReadDir(\".git\")\n\tc.Assert(err, IsNil)\n\tc.Assert(len(l) > 0, Equals, true)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Core.Worktree, Equals, \"\")\n}\n\nfunc (s *RepositorySuite) TestInitBare(c *C) {\n\tr, err := Init(memory.NewStorage(), nil)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Core.IsBare, Equals, true)\n\n}\n\nfunc (s *RepositorySuite) TestInitAlreadyExists(c *C) {\n\tst := memory.NewStorage()\n\n\tr, err := Init(st, nil)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tr, err = Init(st, nil)\n\tc.Assert(err, Equals, ErrRepositoryAlreadyExists)\n\tc.Assert(r, IsNil)\n}\n\nfunc (s *RepositorySuite) TestOpen(c *C) {\n\tst := memory.NewStorage()\n\n\tr, err := Init(st, memfs.New())\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tr, err = Open(st, memfs.New())\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n}\n\nfunc (s *RepositorySuite) TestOpenBare(c *C) {\n\tst := memory.NewStorage()\n\n\tr, err := Init(st, nil)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tr, err = Open(st, nil)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n}\n\nfunc (s *RepositorySuite) TestOpenBareMissingWorktree(c *C) {\n\tst := memory.NewStorage()\n\n\tr, err := Init(st, memfs.New())\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tr, err = Open(st, nil)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n}\n\nfunc (s *RepositorySuite) TestOpenNotExists(c *C) {\n\tr, err := Open(memory.NewStorage(), nil)\n\tc.Assert(err, Equals, ErrRepositoryNotExists)\n\tc.Assert(r, IsNil)\n}\n\nfunc (s *RepositorySuite) TestClone(c *C) {\n\tr, err := Clone(memory.NewStorage(), nil, &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tremotes, err := r.Remotes()\n\tc.Assert(err, IsNil)\n\tc.Assert(remotes, HasLen, 1)\n}\n\nfunc (s *RepositorySuite) TestCloneContext(c *C) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\n\tr, err := CloneContext(ctx, memory.NewStorage(), nil, &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(r, NotNil)\n\tc.Assert(err, Equals, context.Canceled)\n}\n\nfunc (s *RepositorySuite) TestCloneMirror(c *C) {\n\tr, err := Clone(memory.NewStorage(), nil, &CloneOptions{\n\t\tURL:    fixtures.Basic().One().URL,\n\t\tMirror: true,\n\t})\n\n\tc.Assert(err, IsNil)\n\n\trefs, err := r.References()\n\tvar count int\n\trefs.ForEach(func(r *plumbing.Reference) error { c.Log(r); count++; return nil })\n\tc.Assert(err, IsNil)\n\t// 6 refs total from github.com/git-fixtures/basic.git:\n\t//  - HEAD\n\t//  - refs/heads/master\n\t//  - refs/heads/branch\n\t//  - refs/pull/1/head\n\t//  - refs/pull/2/head\n\t//  - refs/pull/2/merge\n\tc.Assert(count, Equals, 6)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\n\tc.Assert(cfg.Core.IsBare, Equals, true)\n\tc.Assert(cfg.Remotes[DefaultRemoteName].Validate(), IsNil)\n\tc.Assert(cfg.Remotes[DefaultRemoteName].Mirror, Equals, true)\n}\n\nfunc (s *RepositorySuite) TestCloneWithTags(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, err := Clone(memory.NewStorage(), nil, &CloneOptions{URL: url, Tags: NoTags})\n\tc.Assert(err, IsNil)\n\n\tremotes, err := r.Remotes()\n\tc.Assert(err, IsNil)\n\tc.Assert(remotes, HasLen, 1)\n\n\ti, err := r.References()\n\tc.Assert(err, IsNil)\n\n\tvar count int\n\ti.ForEach(func(r *plumbing.Reference) error { count++; return nil })\n\n\tc.Assert(count, Equals, 3)\n}\n\nfunc (s *RepositorySuite) TestCloneSparse(c *C) {\n\tfs := memfs.New()\n\tr, err := Clone(memory.NewStorage(), fs, &CloneOptions{\n\t\tURL:        s.GetBasicLocalRepositoryURL(),\n\t\tNoCheckout: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tsparseCheckoutDirectories := []string{\"go\", \"json\", \"php\"}\n\tc.Assert(w.Checkout(&CheckoutOptions{\n\t\tBranch:                    \"refs/heads/master\",\n\t\tSparseCheckoutDirectories: sparseCheckoutDirectories,\n\t}), IsNil)\n\n\tfis, err := fs.ReadDir(\".\")\n\tc.Assert(err, IsNil)\n\tfor _, fi := range fis {\n\t\tc.Assert(fi.IsDir(), Equals, true)\n\t\tvar oneOfSparseCheckoutDirs bool\n\n\t\tfor _, sparseCheckoutDirectory := range sparseCheckoutDirectories {\n\t\t\tif strings.HasPrefix(fi.Name(), sparseCheckoutDirectory) {\n\t\t\t\toneOfSparseCheckoutDirs = true\n\t\t\t}\n\t\t}\n\t\tc.Assert(oneOfSparseCheckoutDirs, Equals, true)\n\t}\n}\n\nfunc (s *RepositorySuite) TestCreateRemoteAndRemote(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\tremote, err := r.CreateRemote(&config.RemoteConfig{\n\t\tName: \"foo\",\n\t\tURLs: []string{\"http://foo/foo.git\"},\n\t})\n\n\tc.Assert(err, IsNil)\n\tc.Assert(remote.Config().Name, Equals, \"foo\")\n\n\talt, err := r.Remote(\"foo\")\n\tc.Assert(err, IsNil)\n\tc.Assert(alt, Not(Equals), remote)\n\tc.Assert(alt.Config().Name, Equals, \"foo\")\n}\n\nfunc (s *RepositorySuite) TestCreateRemoteInvalid(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\tremote, err := r.CreateRemote(&config.RemoteConfig{})\n\n\tc.Assert(err, Equals, config.ErrRemoteConfigEmptyName)\n\tc.Assert(remote, IsNil)\n}\n\nfunc (s *RepositorySuite) TestCreateRemoteAnonymous(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\tremote, err := r.CreateRemoteAnonymous(&config.RemoteConfig{\n\t\tName: \"anonymous\",\n\t\tURLs: []string{\"http://foo/foo.git\"},\n\t})\n\n\tc.Assert(err, IsNil)\n\tc.Assert(remote.Config().Name, Equals, \"anonymous\")\n}\n\nfunc (s *RepositorySuite) TestCreateRemoteAnonymousInvalidName(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\tremote, err := r.CreateRemoteAnonymous(&config.RemoteConfig{\n\t\tName: \"not_anonymous\",\n\t\tURLs: []string{\"http://foo/foo.git\"},\n\t})\n\n\tc.Assert(err, Equals, ErrAnonymousRemoteName)\n\tc.Assert(remote, IsNil)\n}\n\nfunc (s *RepositorySuite) TestCreateRemoteAnonymousInvalid(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\tremote, err := r.CreateRemoteAnonymous(&config.RemoteConfig{})\n\n\tc.Assert(err, Equals, config.ErrRemoteConfigEmptyName)\n\tc.Assert(remote, IsNil)\n}\n\nfunc (s *RepositorySuite) TestDeleteRemote(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\t_, err := r.CreateRemote(&config.RemoteConfig{\n\t\tName: \"foo\",\n\t\tURLs: []string{\"http://foo/foo.git\"},\n\t})\n\n\tc.Assert(err, IsNil)\n\n\terr = r.DeleteRemote(\"foo\")\n\tc.Assert(err, IsNil)\n\n\talt, err := r.Remote(\"foo\")\n\tc.Assert(err, Equals, ErrRemoteNotFound)\n\tc.Assert(alt, IsNil)\n}\n\nfunc (s *RepositorySuite) TestEmptyCreateBranch(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.CreateBranch(&config.Branch{})\n\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *RepositorySuite) TestInvalidCreateBranch(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.CreateBranch(&config.Branch{\n\t\tName: \"-foo\",\n\t})\n\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *RepositorySuite) TestCreateBranchAndBranch(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\ttestBranch := &config.Branch{\n\t\tName:   \"foo\",\n\t\tRemote: \"origin\",\n\t\tMerge:  \"refs/heads/foo\",\n\t}\n\terr := r.CreateBranch(testBranch)\n\n\tc.Assert(err, IsNil)\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(len(cfg.Branches), Equals, 1)\n\tbranch := cfg.Branches[\"foo\"]\n\tc.Assert(branch.Name, Equals, testBranch.Name)\n\tc.Assert(branch.Remote, Equals, testBranch.Remote)\n\tc.Assert(branch.Merge, Equals, testBranch.Merge)\n\n\tbranch, err = r.Branch(\"foo\")\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Name, Equals, testBranch.Name)\n\tc.Assert(branch.Remote, Equals, testBranch.Remote)\n\tc.Assert(branch.Merge, Equals, testBranch.Merge)\n}\n\nfunc (s *RepositorySuite) TestMergeFF(c *C) {\n\tr, err := Init(memory.NewStorage(), memfs.New())\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tcreateCommit(c, r)\n\tcreateCommit(c, r)\n\tcreateCommit(c, r)\n\tlastCommit := createCommit(c, r)\n\n\twt, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\ttargetBranch := plumbing.NewBranchReferenceName(\"foo\")\n\terr = wt.Checkout(&CheckoutOptions{\n\t\tHash:   lastCommit,\n\t\tCreate: true,\n\t\tBranch: targetBranch,\n\t})\n\tc.Assert(err, IsNil)\n\n\tcreateCommit(c, r)\n\tfooHash := createCommit(c, r)\n\n\t// Checkout the master branch so that we can try to merge foo into it.\n\terr = wt.Checkout(&CheckoutOptions{\n\t\tBranch: plumbing.Master,\n\t})\n\tc.Assert(err, IsNil)\n\n\thead, err := r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Hash(), Equals, lastCommit)\n\n\ttargetRef := plumbing.NewHashReference(targetBranch, fooHash)\n\tc.Assert(targetRef, NotNil)\n\n\terr = r.Merge(*targetRef, MergeOptions{\n\t\tStrategy: FastForwardMerge,\n\t})\n\tc.Assert(err, IsNil)\n\n\thead, err = r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Hash(), Equals, fooHash)\n}\n\nfunc (s *RepositorySuite) TestMergeFF_Invalid(c *C) {\n\tr, err := Init(memory.NewStorage(), memfs.New())\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\t// Keep track of the first commit, which will be the\n\t// reference to create the target branch so that we\n\t// can simulate a non-ff merge.\n\tfirstCommit := createCommit(c, r)\n\tcreateCommit(c, r)\n\tcreateCommit(c, r)\n\tlastCommit := createCommit(c, r)\n\n\twt, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\ttargetBranch := plumbing.NewBranchReferenceName(\"foo\")\n\terr = wt.Checkout(&CheckoutOptions{\n\t\tHash:   firstCommit,\n\t\tCreate: true,\n\t\tBranch: targetBranch,\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tcreateCommit(c, r)\n\th := createCommit(c, r)\n\n\t// Checkout the master branch so that we can try to merge foo into it.\n\terr = wt.Checkout(&CheckoutOptions{\n\t\tBranch: plumbing.Master,\n\t})\n\tc.Assert(err, IsNil)\n\n\thead, err := r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Hash(), Equals, lastCommit)\n\n\ttargetRef := plumbing.NewHashReference(targetBranch, h)\n\tc.Assert(targetRef, NotNil)\n\n\terr = r.Merge(*targetRef, MergeOptions{\n\t\tStrategy: MergeStrategy(10),\n\t})\n\tc.Assert(err, Equals, ErrUnsupportedMergeStrategy)\n\n\t// Failed merge operations must not change HEAD.\n\thead, err = r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Hash(), Equals, lastCommit)\n\n\terr = r.Merge(*targetRef, MergeOptions{})\n\tc.Assert(err, Equals, ErrFastForwardMergeNotPossible)\n\n\thead, err = r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Hash(), Equals, lastCommit)\n}\n\nfunc (s *RepositorySuite) TestCreateBranchUnmarshal(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\n\texpected := []byte(`[core]\n\tbare = true\n[remote \"foo\"]\n\turl = http://foo/foo.git\n\tfetch = +refs/heads/*:refs/remotes/foo/*\n[branch \"foo\"]\n\tremote = origin\n\tmerge = refs/heads/foo\n[branch \"master\"]\n\tremote = origin\n\tmerge = refs/heads/master\n`)\n\n\t_, err := r.CreateRemote(&config.RemoteConfig{\n\t\tName: \"foo\",\n\t\tURLs: []string{\"http://foo/foo.git\"},\n\t})\n\tc.Assert(err, IsNil)\n\ttestBranch1 := &config.Branch{\n\t\tName:   \"master\",\n\t\tRemote: \"origin\",\n\t\tMerge:  \"refs/heads/master\",\n\t}\n\ttestBranch2 := &config.Branch{\n\t\tName:   \"foo\",\n\t\tRemote: \"origin\",\n\t\tMerge:  \"refs/heads/foo\",\n\t}\n\terr = r.CreateBranch(testBranch1)\n\tc.Assert(err, IsNil)\n\terr = r.CreateBranch(testBranch2)\n\tc.Assert(err, IsNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tmarshaled, err := cfg.Marshal()\n\tc.Assert(err, IsNil)\n\tc.Assert(string(expected), Equals, string(marshaled))\n}\n\nfunc (s *RepositorySuite) TestBranchInvalid(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\tbranch, err := r.Branch(\"foo\")\n\n\tc.Assert(err, NotNil)\n\tc.Assert(branch, IsNil)\n}\n\nfunc (s *RepositorySuite) TestCreateBranchInvalid(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.CreateBranch(&config.Branch{})\n\n\tc.Assert(err, NotNil)\n\n\ttestBranch := &config.Branch{\n\t\tName:   \"foo\",\n\t\tRemote: \"origin\",\n\t\tMerge:  \"refs/heads/foo\",\n\t}\n\terr = r.CreateBranch(testBranch)\n\tc.Assert(err, IsNil)\n\terr = r.CreateBranch(testBranch)\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *RepositorySuite) TestDeleteBranch(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\ttestBranch := &config.Branch{\n\t\tName:   \"foo\",\n\t\tRemote: \"origin\",\n\t\tMerge:  \"refs/heads/foo\",\n\t}\n\terr := r.CreateBranch(testBranch)\n\n\tc.Assert(err, IsNil)\n\n\terr = r.DeleteBranch(\"foo\")\n\tc.Assert(err, IsNil)\n\n\tb, err := r.Branch(\"foo\")\n\tc.Assert(err, Equals, ErrBranchNotFound)\n\tc.Assert(b, IsNil)\n\n\terr = r.DeleteBranch(\"foo\")\n\tc.Assert(err, Equals, ErrBranchNotFound)\n}\n\nfunc (s *RepositorySuite) TestPlainInit(c *C) {\n\tdir := c.MkDir()\n\n\tr, err := PlainInit(dir, true)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Core.IsBare, Equals, true)\n}\n\nfunc (s *RepositorySuite) TestPlainInitWithOptions(c *C) {\n\tdir := c.MkDir()\n\n\tr, err := PlainInitWithOptions(dir, &PlainInitOptions{\n\t\tInitOptions: InitOptions{\n\t\t\tDefaultBranch: \"refs/heads/foo\",\n\t\t},\n\t\tBare: false,\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Core.IsBare, Equals, false)\n\n\tcreateCommit(c, r)\n\n\tref, err := r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(ref.Name().String(), Equals, \"refs/heads/foo\")\n}\n\nfunc (s *RepositorySuite) TestPlainInitAlreadyExists(c *C) {\n\tdir := c.MkDir()\n\n\tr, err := PlainInit(dir, true)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tr, err = PlainInit(dir, true)\n\tc.Assert(err, Equals, ErrRepositoryAlreadyExists)\n\tc.Assert(r, IsNil)\n}\n\nfunc (s *RepositorySuite) TestPlainOpen(c *C) {\n\tdir := c.MkDir()\n\n\tr, err := PlainInit(dir, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tr, err = PlainOpen(dir)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n}\n\nfunc (s *RepositorySuite) TestPlainOpenTildePath(c *C) {\n\tdir, clean := s.TemporalHomeDir()\n\tdefer clean()\n\n\tr, err := PlainInit(dir, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tcurrentUser, err := user.Current()\n\tc.Assert(err, IsNil)\n\t// remove domain for windows\n\tusername := currentUser.Username[strings.Index(currentUser.Username, \"\\\\\")+1:]\n\n\thomes := []string{\"~/\", \"~\" + username + \"/\"}\n\tfor _, home := range homes {\n\t\tpath := strings.Replace(dir, strings.Split(dir, \".tmp\")[0], home, 1)\n\n\t\tr, err = PlainOpen(path)\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(r, NotNil)\n\t}\n}\n\nfunc (s *RepositorySuite) TestPlainOpenBare(c *C) {\n\tdir := c.MkDir()\n\n\tr, err := PlainInit(dir, true)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tr, err = PlainOpen(dir)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n}\n\nfunc (s *RepositorySuite) TestPlainOpenNotBare(c *C) {\n\tdir := c.MkDir()\n\n\tr, err := PlainInit(dir, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tr, err = PlainOpen(filepath.Join(dir, \".git\"))\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n}\n\nfunc (s *RepositorySuite) testPlainOpenGitFile(c *C, f func(string, string) string) {\n\tfs := s.TemporalFilesystem(c)\n\n\tdir, err := util.TempDir(fs, \"\", \"plain-open\")\n\tc.Assert(err, IsNil)\n\n\tr, err := PlainInit(fs.Join(fs.Root(), dir), true)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\taltDir, err := util.TempDir(fs, \"\", \"plain-open\")\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(fs, fs.Join(altDir, \".git\"),\n\t\t[]byte(f(fs.Join(fs.Root(), dir), fs.Join(fs.Root(), altDir))),\n\t\t0644,\n\t)\n\n\tc.Assert(err, IsNil)\n\n\tr, err = PlainOpen(fs.Join(fs.Root(), altDir))\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n}\n\nfunc (s *RepositorySuite) TestPlainOpenBareAbsoluteGitDirFile(c *C) {\n\ts.testPlainOpenGitFile(c, func(dir, altDir string) string {\n\t\treturn fmt.Sprintf(\"gitdir: %s\\n\", dir)\n\t})\n}\n\nfunc (s *RepositorySuite) TestPlainOpenBareAbsoluteGitDirFileNoEOL(c *C) {\n\ts.testPlainOpenGitFile(c, func(dir, altDir string) string {\n\t\treturn fmt.Sprintf(\"gitdir: %s\", dir)\n\t})\n}\n\nfunc (s *RepositorySuite) TestPlainOpenBareRelativeGitDirFile(c *C) {\n\ts.testPlainOpenGitFile(c, func(dir, altDir string) string {\n\t\tdir, err := filepath.Rel(altDir, dir)\n\t\tc.Assert(err, IsNil)\n\t\treturn fmt.Sprintf(\"gitdir: %s\\n\", dir)\n\t})\n}\n\nfunc (s *RepositorySuite) TestPlainOpenBareRelativeGitDirFileNoEOL(c *C) {\n\ts.testPlainOpenGitFile(c, func(dir, altDir string) string {\n\t\tdir, err := filepath.Rel(altDir, dir)\n\t\tc.Assert(err, IsNil)\n\t\treturn fmt.Sprintf(\"gitdir: %s\\n\", dir)\n\t})\n}\n\nfunc (s *RepositorySuite) TestPlainOpenBareRelativeGitDirFileTrailingGarbage(c *C) {\n\tfs := s.TemporalFilesystem(c)\n\n\tdir, err := util.TempDir(fs, \"\", \"\")\n\tc.Assert(err, IsNil)\n\n\tr, err := PlainInit(dir, true)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\taltDir, err := util.TempDir(fs, \"\", \"\")\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(fs, fs.Join(altDir, \".git\"),\n\t\t[]byte(fmt.Sprintf(\"gitdir: %s\\nTRAILING\", fs.Join(fs.Root(), altDir))),\n\t\t0644,\n\t)\n\tc.Assert(err, IsNil)\n\n\tr, err = PlainOpen(altDir)\n\tc.Assert(err, Equals, ErrRepositoryNotExists)\n\tc.Assert(r, IsNil)\n}\n\nfunc (s *RepositorySuite) TestPlainOpenBareRelativeGitDirFileBadPrefix(c *C) {\n\tfs := s.TemporalFilesystem(c)\n\n\tdir, err := util.TempDir(fs, \"\", \"\")\n\tc.Assert(err, IsNil)\n\n\tr, err := PlainInit(fs.Join(fs.Root(), dir), true)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\taltDir, err := util.TempDir(fs, \"\", \"\")\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(fs, fs.Join(altDir, \".git\"), []byte(\n\t\tfmt.Sprintf(\"xgitdir: %s\\n\", fs.Join(fs.Root(), dir)),\n\t), 0644)\n\n\tc.Assert(err, IsNil)\n\n\tr, err = PlainOpen(fs.Join(fs.Root(), altDir))\n\tc.Assert(err, ErrorMatches, \".*gitdir.*\")\n\tc.Assert(r, IsNil)\n}\n\nfunc (s *RepositorySuite) TestPlainOpenNotExists(c *C) {\n\tr, err := PlainOpen(\"/not-exists/\")\n\tc.Assert(err, Equals, ErrRepositoryNotExists)\n\tc.Assert(r, IsNil)\n}\n\nfunc (s *RepositorySuite) TestPlainOpenDetectDotGit(c *C) {\n\tfs := s.TemporalFilesystem(c)\n\n\tdir, err := util.TempDir(fs, \"\", \"\")\n\tc.Assert(err, IsNil)\n\n\tsubdir := filepath.Join(dir, \"a\", \"b\")\n\terr = fs.MkdirAll(subdir, 0755)\n\tc.Assert(err, IsNil)\n\n\tfile := fs.Join(subdir, \"file.txt\")\n\tf, err := fs.Create(file)\n\tc.Assert(err, IsNil)\n\tf.Close()\n\n\tr, err := PlainInit(fs.Join(fs.Root(), dir), false)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\topt := &PlainOpenOptions{DetectDotGit: true}\n\tr, err = PlainOpenWithOptions(fs.Join(fs.Root(), subdir), opt)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tr, err = PlainOpenWithOptions(fs.Join(fs.Root(), file), opt)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\toptnodetect := &PlainOpenOptions{DetectDotGit: false}\n\tr, err = PlainOpenWithOptions(fs.Join(fs.Root(), file), optnodetect)\n\tc.Assert(err, NotNil)\n\tc.Assert(r, IsNil)\n}\n\nfunc (s *RepositorySuite) TestPlainOpenNotExistsDetectDotGit(c *C) {\n\tdir := c.MkDir()\n\n\topt := &PlainOpenOptions{DetectDotGit: true}\n\tr, err := PlainOpenWithOptions(dir, opt)\n\tc.Assert(err, Equals, ErrRepositoryNotExists)\n\tc.Assert(r, IsNil)\n}\n\nfunc (s *RepositorySuite) TestPlainClone(c *C) {\n\tdir := c.MkDir()\n\n\tr, err := PlainClone(dir, false, &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tremotes, err := r.Remotes()\n\tc.Assert(err, IsNil)\n\tc.Assert(remotes, HasLen, 1)\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Branches, HasLen, 1)\n\tc.Assert(cfg.Branches[\"master\"].Name, Equals, \"master\")\n}\n\nfunc (s *RepositorySuite) TestPlainCloneBareAndShared(c *C) {\n\tdir := c.MkDir()\n\n\tremote := s.GetBasicLocalRepositoryURL()\n\n\tr, err := PlainClone(dir, true, &CloneOptions{\n\t\tURL:    remote,\n\t\tShared: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\taltpath := path.Join(dir, \"objects\", \"info\", \"alternates\")\n\t_, err = os.Stat(altpath)\n\tc.Assert(err, IsNil)\n\n\tdata, err := os.ReadFile(altpath)\n\tc.Assert(err, IsNil)\n\n\tline := path.Join(remote, GitDirName, \"objects\") + \"\\n\"\n\tc.Assert(string(data), Equals, line)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Branches, HasLen, 1)\n\tc.Assert(cfg.Branches[\"master\"].Name, Equals, \"master\")\n}\n\nfunc (s *RepositorySuite) TestPlainCloneShared(c *C) {\n\tdir := c.MkDir()\n\n\tremote := s.GetBasicLocalRepositoryURL()\n\n\tr, err := PlainClone(dir, false, &CloneOptions{\n\t\tURL:    remote,\n\t\tShared: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\taltpath := path.Join(dir, GitDirName, \"objects\", \"info\", \"alternates\")\n\t_, err = os.Stat(altpath)\n\tc.Assert(err, IsNil)\n\n\tdata, err := os.ReadFile(altpath)\n\tc.Assert(err, IsNil)\n\n\tline := path.Join(remote, GitDirName, \"objects\") + \"\\n\"\n\tc.Assert(string(data), Equals, line)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Branches, HasLen, 1)\n\tc.Assert(cfg.Branches[\"master\"].Name, Equals, \"master\")\n}\n\nfunc (s *RepositorySuite) TestPlainCloneSharedHttpShouldReturnError(c *C) {\n\tdir := c.MkDir()\n\n\tremote := \"http://somerepo\"\n\n\t_, err := PlainClone(dir, false, &CloneOptions{\n\t\tURL:    remote,\n\t\tShared: true,\n\t})\n\tc.Assert(err, Equals, ErrAlternatePathNotSupported)\n}\n\nfunc (s *RepositorySuite) TestPlainCloneSharedHttpsShouldReturnError(c *C) {\n\tdir := c.MkDir()\n\n\tremote := \"https://somerepo\"\n\n\t_, err := PlainClone(dir, false, &CloneOptions{\n\t\tURL:    remote,\n\t\tShared: true,\n\t})\n\tc.Assert(err, Equals, ErrAlternatePathNotSupported)\n}\n\nfunc (s *RepositorySuite) TestPlainCloneSharedSSHShouldReturnError(c *C) {\n\tdir := c.MkDir()\n\n\tremote := \"ssh://somerepo\"\n\n\t_, err := PlainClone(dir, false, &CloneOptions{\n\t\tURL:    remote,\n\t\tShared: true,\n\t})\n\tc.Assert(err, Equals, ErrAlternatePathNotSupported)\n}\n\nfunc (s *RepositorySuite) TestPlainCloneWithRemoteName(c *C) {\n\tdir := c.MkDir()\n\n\tr, err := PlainClone(dir, false, &CloneOptions{\n\t\tURL:        s.GetBasicLocalRepositoryURL(),\n\t\tRemoteName: \"test\",\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tremote, err := r.Remote(\"test\")\n\tc.Assert(err, IsNil)\n\tc.Assert(remote, NotNil)\n}\n\nfunc (s *RepositorySuite) TestPlainCloneOverExistingGitDirectory(c *C) {\n\tdir := c.MkDir()\n\n\tr, err := PlainInit(dir, false)\n\tc.Assert(r, NotNil)\n\tc.Assert(err, IsNil)\n\n\tr, err = PlainClone(dir, false, &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(r, IsNil)\n\tc.Assert(err, Equals, ErrRepositoryAlreadyExists)\n}\n\nfunc (s *RepositorySuite) TestPlainCloneContextCancel(c *C) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\n\tdir := c.MkDir()\n\n\tr, err := PlainCloneContext(ctx, dir, false, &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(r, NotNil)\n\tc.Assert(err, Equals, context.Canceled)\n}\n\nfunc (s *RepositorySuite) TestPlainCloneContextNonExistentWithExistentDir(c *C) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\n\tfs := s.TemporalFilesystem(c)\n\n\tdir, err := util.TempDir(fs, \"\", \"\")\n\tc.Assert(err, IsNil)\n\n\tr, err := PlainCloneContext(ctx, dir, false, &CloneOptions{\n\t\tURL: \"incorrectOnPurpose\",\n\t})\n\tc.Assert(r, NotNil)\n\tc.Assert(err, Equals, transport.ErrRepositoryNotFound)\n\n\t_, err = fs.Stat(dir)\n\tc.Assert(os.IsNotExist(err), Equals, false)\n\n\tnames, err := fs.ReadDir(dir)\n\tc.Assert(err, IsNil)\n\tc.Assert(names, HasLen, 0)\n}\n\nfunc (s *RepositorySuite) TestPlainCloneContextNonExistentWithNonExistentDir(c *C) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\n\tfs := s.TemporalFilesystem(c)\n\n\ttmpDir, err := util.TempDir(fs, \"\", \"\")\n\tc.Assert(err, IsNil)\n\n\trepoDir := filepath.Join(tmpDir, \"repoDir\")\n\n\tr, err := PlainCloneContext(ctx, repoDir, false, &CloneOptions{\n\t\tURL: \"incorrectOnPurpose\",\n\t})\n\tc.Assert(r, NotNil)\n\tc.Assert(err, Equals, transport.ErrRepositoryNotFound)\n\n\t_, err = fs.Stat(repoDir)\n\tc.Assert(os.IsNotExist(err), Equals, true)\n}\n\nfunc (s *RepositorySuite) TestPlainCloneContextNonExistentWithNotDir(c *C) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\n\tfs := s.TemporalFilesystem(c)\n\n\ttmpDir, err := util.TempDir(fs, \"\", \"\")\n\tc.Assert(err, IsNil)\n\n\trepoDir := fs.Join(tmpDir, \"repoDir\")\n\n\tf, err := fs.Create(repoDir)\n\tc.Assert(err, IsNil)\n\tc.Assert(f.Close(), IsNil)\n\n\tr, err := PlainCloneContext(ctx, fs.Join(fs.Root(), repoDir), false, &CloneOptions{\n\t\tURL: \"incorrectOnPurpose\",\n\t})\n\tc.Assert(r, IsNil)\n\tc.Assert(err, ErrorMatches, \".*not a directory.*\")\n\n\tfi, err := fs.Stat(repoDir)\n\tc.Assert(err, IsNil)\n\tc.Assert(fi.IsDir(), Equals, false)\n}\n\nfunc (s *RepositorySuite) TestPlainCloneContextNonExistentWithNotEmptyDir(c *C) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\n\tfs := s.TemporalFilesystem(c)\n\n\ttmpDir, err := util.TempDir(fs, \"\", \"\")\n\tc.Assert(err, IsNil)\n\n\trepoDir := filepath.Join(tmpDir, \"repoDir\")\n\terr = fs.MkdirAll(repoDir, 0777)\n\tc.Assert(err, IsNil)\n\n\tdummyFile := filepath.Join(repoDir, \"dummyFile\")\n\terr = util.WriteFile(fs, dummyFile, []byte(\"dummyContent\"), 0644)\n\tc.Assert(err, IsNil)\n\n\tr, err := PlainCloneContext(ctx, fs.Join(fs.Root(), repoDir), false, &CloneOptions{\n\t\tURL: \"incorrectOnPurpose\",\n\t})\n\tc.Assert(r, NotNil)\n\tc.Assert(err, Equals, transport.ErrRepositoryNotFound)\n\n\t_, err = fs.Stat(dummyFile)\n\tc.Assert(err, IsNil)\n\n}\n\nfunc (s *RepositorySuite) TestPlainCloneContextNonExistingOverExistingGitDirectory(c *C) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\n\tdir := c.MkDir()\n\n\tr, err := PlainInit(dir, false)\n\tc.Assert(r, NotNil)\n\tc.Assert(err, IsNil)\n\n\tr, err = PlainCloneContext(ctx, dir, false, &CloneOptions{\n\t\tURL: \"incorrectOnPurpose\",\n\t})\n\tc.Assert(r, IsNil)\n\tc.Assert(err, Equals, ErrRepositoryAlreadyExists)\n}\n\nfunc (s *RepositorySuite) TestPlainCloneWithRecurseSubmodules(c *C) {\n\tif testing.Short() {\n\t\tc.Skip(\"skipping test in short mode.\")\n\t}\n\n\tdir := c.MkDir()\n\n\tpath := fixtures.ByTag(\"submodule\").One().Worktree().Root()\n\tr, err := PlainClone(dir, false, &CloneOptions{\n\t\tURL:               path,\n\t\tRecurseSubmodules: DefaultSubmoduleRecursionDepth,\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Remotes, HasLen, 1)\n\tc.Assert(cfg.Branches, HasLen, 1)\n\tc.Assert(cfg.Submodules, HasLen, 2)\n}\n\nfunc (s *RepositorySuite) TestPlainCloneWithShallowSubmodules(c *C) {\n\tif testing.Short() {\n\t\tc.Skip(\"skipping test in short mode.\")\n\t}\n\n\tdir := c.MkDir()\n\n\tpath := fixtures.ByTag(\"submodule\").One().Worktree().Root()\n\tmainRepo, err := PlainClone(dir, false, &CloneOptions{\n\t\tURL:               path,\n\t\tRecurseSubmodules: 1,\n\t\tShallowSubmodules: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tmainWorktree, err := mainRepo.Worktree()\n\tc.Assert(err, IsNil)\n\n\tsubmodule, err := mainWorktree.Submodule(\"basic\")\n\tc.Assert(err, IsNil)\n\n\tsubRepo, err := submodule.Repository()\n\tc.Assert(err, IsNil)\n\n\tlr, err := subRepo.Log(&LogOptions{})\n\tc.Assert(err, IsNil)\n\n\tcommitCount := 0\n\tfor _, err := lr.Next(); err == nil; _, err = lr.Next() {\n\t\tcommitCount++\n\t}\n\tc.Assert(err, IsNil)\n\n\tc.Assert(commitCount, Equals, 1)\n}\n\nfunc (s *RepositorySuite) TestPlainCloneNoCheckout(c *C) {\n\tdir := c.MkDir()\n\n\tpath := fixtures.ByTag(\"submodule\").One().Worktree().Root()\n\tr, err := PlainClone(dir, false, &CloneOptions{\n\t\tURL:               path,\n\t\tNoCheckout:        true,\n\t\tRecurseSubmodules: DefaultSubmoduleRecursionDepth,\n\t})\n\tc.Assert(err, IsNil)\n\n\th, err := r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(h.Hash().String(), Equals, \"b685400c1f9316f350965a5993d350bc746b0bf4\")\n\n\tfi, err := osfs.New(dir).ReadDir(\"\")\n\tc.Assert(err, IsNil)\n\tc.Assert(fi, HasLen, 1) // .git\n}\n\nfunc (s *RepositorySuite) TestFetch(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\t_, err := r.CreateRemote(&config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(r.Fetch(&FetchOptions{}), IsNil)\n\n\tremotes, err := r.Remotes()\n\tc.Assert(err, IsNil)\n\tc.Assert(remotes, HasLen, 1)\n\n\t_, err = r.Head()\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n\n\tbranch, err := r.Reference(\"refs/remotes/origin/master\", false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch, NotNil)\n\tc.Assert(branch.Type(), Equals, plumbing.HashReference)\n\tc.Assert(branch.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n}\n\nfunc (s *RepositorySuite) TestFetchContext(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\t_, err := r.CreateRemote(&config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\tc.Assert(err, IsNil)\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\n\tc.Assert(r.FetchContext(ctx, &FetchOptions{}), NotNil)\n}\n\nfunc (s *RepositorySuite) TestCloneWithProgress(c *C) {\n\tfs := memfs.New()\n\n\tbuf := bytes.NewBuffer(nil)\n\t_, err := Clone(memory.NewStorage(), fs, &CloneOptions{\n\t\tURL:      s.GetBasicLocalRepositoryURL(),\n\t\tProgress: buf,\n\t})\n\n\tc.Assert(err, IsNil)\n\tc.Assert(buf.Len(), Not(Equals), 0)\n}\n\nfunc (s *RepositorySuite) TestCloneDeep(c *C) {\n\tfs := memfs.New()\n\tr, _ := Init(memory.NewStorage(), fs)\n\n\thead, err := r.Head()\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n\tc.Assert(head, IsNil)\n\n\terr = r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tremotes, err := r.Remotes()\n\tc.Assert(err, IsNil)\n\tc.Assert(remotes, HasLen, 1)\n\n\thead, err = r.Reference(plumbing.HEAD, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(head, NotNil)\n\tc.Assert(head.Type(), Equals, plumbing.SymbolicReference)\n\tc.Assert(head.Target().String(), Equals, \"refs/heads/master\")\n\n\tbranch, err := r.Reference(head.Target(), false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch, NotNil)\n\tc.Assert(branch.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\tbranch, err = r.Reference(\"refs/remotes/origin/master\", false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch, NotNil)\n\tc.Assert(branch.Type(), Equals, plumbing.HashReference)\n\tc.Assert(branch.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\tfi, err := fs.ReadDir(\"\")\n\tc.Assert(err, IsNil)\n\tc.Assert(fi, HasLen, 8)\n}\n\nfunc (s *RepositorySuite) TestCloneConfig(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\n\thead, err := r.Head()\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n\tc.Assert(head, IsNil)\n\n\terr = r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\n\tc.Assert(cfg.Core.IsBare, Equals, true)\n\tc.Assert(cfg.Remotes, HasLen, 1)\n\tc.Assert(cfg.Remotes[\"origin\"].Name, Equals, \"origin\")\n\tc.Assert(cfg.Remotes[\"origin\"].URLs, HasLen, 1)\n\tc.Assert(cfg.Branches, HasLen, 1)\n\tc.Assert(cfg.Branches[\"master\"].Name, Equals, \"master\")\n}\n\nfunc (s *RepositorySuite) TestCloneSingleBranchAndNonHEAD(c *C) {\n\ts.testCloneSingleBranchAndNonHEADReference(c, \"refs/heads/branch\")\n}\n\nfunc (s *RepositorySuite) TestCloneSingleBranchAndNonHEADAndNonFull(c *C) {\n\ts.testCloneSingleBranchAndNonHEADReference(c, \"branch\")\n}\n\nfunc (s *RepositorySuite) testCloneSingleBranchAndNonHEADReference(c *C, ref string) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\n\thead, err := r.Head()\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n\tc.Assert(head, IsNil)\n\n\terr = r.clone(context.Background(), &CloneOptions{\n\t\tURL:           s.GetBasicLocalRepositoryURL(),\n\t\tReferenceName: plumbing.ReferenceName(ref),\n\t\tSingleBranch:  true,\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tremotes, err := r.Remotes()\n\tc.Assert(err, IsNil)\n\tc.Assert(remotes, HasLen, 1)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Branches, HasLen, 1)\n\tc.Assert(cfg.Branches[\"branch\"].Name, Equals, \"branch\")\n\tc.Assert(cfg.Branches[\"branch\"].Remote, Equals, \"origin\")\n\tc.Assert(cfg.Branches[\"branch\"].Merge, Equals, plumbing.ReferenceName(\"refs/heads/branch\"))\n\n\thead, err = r.Reference(plumbing.HEAD, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(head, NotNil)\n\tc.Assert(head.Type(), Equals, plumbing.SymbolicReference)\n\tc.Assert(head.Target().String(), Equals, \"refs/heads/branch\")\n\n\tbranch, err := r.Reference(head.Target(), false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch, NotNil)\n\tc.Assert(branch.Hash().String(), Equals, \"e8d3ffab552895c19b9fcf7aa264d277cde33881\")\n\n\tbranch, err = r.Reference(\"refs/remotes/origin/branch\", false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch, NotNil)\n\tc.Assert(branch.Type(), Equals, plumbing.HashReference)\n\tc.Assert(branch.Hash().String(), Equals, \"e8d3ffab552895c19b9fcf7aa264d277cde33881\")\n}\n\nfunc (s *RepositorySuite) TestCloneSingleBranchHEADMain(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\n\thead, err := r.Head()\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n\tc.Assert(head, IsNil)\n\n\terr = r.clone(context.Background(), &CloneOptions{\n\t\tURL:          s.GetLocalRepositoryURL(fixtures.ByTag(\"no-master-head\").One()),\n\t\tSingleBranch: true,\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tremotes, err := r.Remotes()\n\tc.Assert(err, IsNil)\n\tc.Assert(remotes, HasLen, 1)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Branches, HasLen, 1)\n\tc.Assert(cfg.Branches[\"main\"].Name, Equals, \"main\")\n\tc.Assert(cfg.Branches[\"main\"].Remote, Equals, \"origin\")\n\tc.Assert(cfg.Branches[\"main\"].Merge, Equals, plumbing.ReferenceName(\"refs/heads/main\"))\n\n\thead, err = r.Reference(plumbing.HEAD, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(head, NotNil)\n\tc.Assert(head.Type(), Equals, plumbing.SymbolicReference)\n\tc.Assert(head.Target().String(), Equals, \"refs/heads/main\")\n\n\tbranch, err := r.Reference(head.Target(), false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch, NotNil)\n\tc.Assert(branch.Hash().String(), Equals, \"786dafbd351e587da1ae97e5fb9fbdf868b4a28f\")\n\n\tbranch, err = r.Reference(\"refs/remotes/origin/HEAD\", false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch, NotNil)\n\tc.Assert(branch.Type(), Equals, plumbing.HashReference)\n\tc.Assert(branch.Hash().String(), Equals, \"786dafbd351e587da1ae97e5fb9fbdf868b4a28f\")\n}\n\nfunc (s *RepositorySuite) TestCloneSingleBranch(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\n\thead, err := r.Head()\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n\tc.Assert(head, IsNil)\n\n\terr = r.clone(context.Background(), &CloneOptions{\n\t\tURL:          s.GetBasicLocalRepositoryURL(),\n\t\tSingleBranch: true,\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tremotes, err := r.Remotes()\n\tc.Assert(err, IsNil)\n\tc.Assert(remotes, HasLen, 1)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Branches, HasLen, 1)\n\tc.Assert(cfg.Branches[\"master\"].Name, Equals, \"master\")\n\tc.Assert(cfg.Branches[\"master\"].Remote, Equals, \"origin\")\n\tc.Assert(cfg.Branches[\"master\"].Merge, Equals, plumbing.ReferenceName(\"refs/heads/master\"))\n\n\thead, err = r.Reference(plumbing.HEAD, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(head, NotNil)\n\tc.Assert(head.Type(), Equals, plumbing.SymbolicReference)\n\tc.Assert(head.Target().String(), Equals, \"refs/heads/master\")\n\n\tbranch, err := r.Reference(head.Target(), false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch, NotNil)\n\tc.Assert(branch.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n}\n\nfunc (s *RepositorySuite) TestCloneSingleTag(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL:           url,\n\t\tSingleBranch:  true,\n\t\tReferenceName: plumbing.ReferenceName(\"refs/tags/commit-tag\"),\n\t})\n\tc.Assert(err, IsNil)\n\n\tbranch, err := r.Reference(\"refs/tags/commit-tag\", false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch, NotNil)\n\n\tconf, err := r.Config()\n\tc.Assert(err, IsNil)\n\toriginRemote := conf.Remotes[\"origin\"]\n\tc.Assert(originRemote, NotNil)\n\tc.Assert(originRemote.Fetch, HasLen, 1)\n\tc.Assert(originRemote.Fetch[0].String(), Equals, \"+refs/tags/commit-tag:refs/tags/commit-tag\")\n}\n\nfunc (s *RepositorySuite) TestCloneDetachedHEAD(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL:           s.GetBasicLocalRepositoryURL(),\n\t\tReferenceName: plumbing.ReferenceName(\"refs/tags/v1.0.0\"),\n\t})\n\tc.Assert(err, IsNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Branches, HasLen, 0)\n\n\thead, err := r.Reference(plumbing.HEAD, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(head, NotNil)\n\tc.Assert(head.Type(), Equals, plumbing.HashReference)\n\tc.Assert(head.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\tcount := 0\n\tobjects, err := r.Objects()\n\tc.Assert(err, IsNil)\n\tobjects.ForEach(func(object.Object) error { count++; return nil })\n\tc.Assert(count, Equals, 28)\n}\n\nfunc (s *RepositorySuite) TestCloneDetachedHEADAndSingle(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL:           s.GetBasicLocalRepositoryURL(),\n\t\tReferenceName: plumbing.ReferenceName(\"refs/tags/v1.0.0\"),\n\t\tSingleBranch:  true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Branches, HasLen, 0)\n\n\thead, err := r.Reference(plumbing.HEAD, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(head, NotNil)\n\tc.Assert(head.Type(), Equals, plumbing.HashReference)\n\tc.Assert(head.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\tcount := 0\n\tobjects, err := r.Objects()\n\tc.Assert(err, IsNil)\n\tobjects.ForEach(func(object.Object) error { count++; return nil })\n\tc.Assert(count, Equals, 28)\n}\n\nfunc (s *RepositorySuite) TestCloneDetachedHEADAndShallow(c *C) {\n\tr, _ := Init(memory.NewStorage(), memfs.New())\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL:           s.GetBasicLocalRepositoryURL(),\n\t\tReferenceName: plumbing.ReferenceName(\"refs/tags/v1.0.0\"),\n\t\tDepth:         1,\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Branches, HasLen, 0)\n\n\thead, err := r.Reference(plumbing.HEAD, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(head, NotNil)\n\tc.Assert(head.Type(), Equals, plumbing.HashReference)\n\tc.Assert(head.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\tcount := 0\n\tobjects, err := r.Objects()\n\tc.Assert(err, IsNil)\n\tobjects.ForEach(func(object.Object) error { count++; return nil })\n\tc.Assert(count, Equals, 15)\n}\n\nfunc (s *RepositorySuite) TestCloneDetachedHEADAnnotatedTag(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL:           s.GetLocalRepositoryURL(fixtures.ByTag(\"tags\").One()),\n\t\tReferenceName: plumbing.ReferenceName(\"refs/tags/annotated-tag\"),\n\t})\n\tc.Assert(err, IsNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Branches, HasLen, 0)\n\n\thead, err := r.Reference(plumbing.HEAD, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(head, NotNil)\n\tc.Assert(head.Type(), Equals, plumbing.HashReference)\n\tc.Assert(head.Hash().String(), Equals, \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\")\n\n\tcount := 0\n\tobjects, err := r.Objects()\n\tc.Assert(err, IsNil)\n\tobjects.ForEach(func(object.Object) error { count++; return nil })\n\tc.Assert(count, Equals, 7)\n}\n\nfunc (s *RepositorySuite) TestPush(c *C) {\n\turl := c.MkDir()\n\n\tserver, err := PlainInit(url, true)\n\tc.Assert(err, IsNil)\n\n\t_, err = s.Repository.CreateRemote(&config.RemoteConfig{\n\t\tName: \"test\",\n\t\tURLs: []string{url},\n\t})\n\tc.Assert(err, IsNil)\n\n\terr = s.Repository.Push(&PushOptions{\n\t\tRemoteName: \"test\",\n\t})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, server, map[string]string{\n\t\t\"refs/heads/master\": \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"refs/heads/branch\": \"e8d3ffab552895c19b9fcf7aa264d277cde33881\",\n\t})\n\n\tAssertReferences(c, s.Repository, map[string]string{\n\t\t\"refs/remotes/test/master\": \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"refs/remotes/test/branch\": \"e8d3ffab552895c19b9fcf7aa264d277cde33881\",\n\t})\n}\n\nfunc (s *RepositorySuite) TestPushContext(c *C) {\n\turl := c.MkDir()\n\n\t_, err := PlainInit(url, true)\n\tc.Assert(err, IsNil)\n\n\t_, err = s.Repository.CreateRemote(&config.RemoteConfig{\n\t\tName: \"foo\",\n\t\tURLs: []string{url},\n\t})\n\tc.Assert(err, IsNil)\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\n\terr = s.Repository.PushContext(ctx, &PushOptions{\n\t\tRemoteName: \"foo\",\n\t})\n\tc.Assert(err, NotNil)\n}\n\n// installPreReceiveHook installs a pre-receive hook in the .git\n// directory at path which prints message m before exiting\n// successfully.\nfunc installPreReceiveHook(c *C, fs billy.Filesystem, path, m string) {\n\thooks := fs.Join(path, \"hooks\")\n\terr := fs.MkdirAll(hooks, 0777)\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(fs, fs.Join(hooks, \"pre-receive\"), preReceiveHook(m), 0777)\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *RepositorySuite) TestPushWithProgress(c *C) {\n\tfs := s.TemporalFilesystem(c)\n\n\tpath, err := util.TempDir(fs, \"\", \"\")\n\tc.Assert(err, IsNil)\n\n\turl := fs.Join(fs.Root(), path)\n\n\tserver, err := PlainInit(url, true)\n\tc.Assert(err, IsNil)\n\n\tm := \"Receiving...\"\n\tinstallPreReceiveHook(c, fs, path, m)\n\n\t_, err = s.Repository.CreateRemote(&config.RemoteConfig{\n\t\tName: \"bar\",\n\t\tURLs: []string{url},\n\t})\n\tc.Assert(err, IsNil)\n\n\tvar p bytes.Buffer\n\terr = s.Repository.Push(&PushOptions{\n\t\tRemoteName: \"bar\",\n\t\tProgress:   &p,\n\t})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, server, map[string]string{\n\t\t\"refs/heads/master\": \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"refs/heads/branch\": \"e8d3ffab552895c19b9fcf7aa264d277cde33881\",\n\t})\n\n\tc.Assert((&p).Bytes(), DeepEquals, []byte(m))\n}\n\nfunc (s *RepositorySuite) TestPushDepth(c *C) {\n\turl := c.MkDir()\n\n\tserver, err := PlainClone(url, true, &CloneOptions{\n\t\tURL: fixtures.Basic().One().DotGit().Root(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tr, err := Clone(memory.NewStorage(), memfs.New(), &CloneOptions{\n\t\tURL:   url,\n\t\tDepth: 1,\n\t})\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(r.wt, \"foo\", nil, 0755)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\t_, err = w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Commit(\"foo\", &CommitOptions{\n\t\tAuthor:    defaultSignature(),\n\t\tCommitter: defaultSignature(),\n\t})\n\tc.Assert(err, IsNil)\n\n\terr = r.Push(&PushOptions{})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, server, map[string]string{\n\t\t\"refs/heads/master\": hash.String(),\n\t})\n\n\tAssertReferences(c, r, map[string]string{\n\t\t\"refs/remotes/origin/master\": hash.String(),\n\t})\n}\n\nfunc (s *RepositorySuite) TestPushNonExistentRemote(c *C) {\n\tsrcFs := fixtures.Basic().One().DotGit()\n\tsto := filesystem.NewStorage(srcFs, cache.NewObjectLRUDefault())\n\n\tr, err := Open(sto, srcFs)\n\tc.Assert(err, IsNil)\n\n\terr = r.Push(&PushOptions{RemoteName: \"myremote\"})\n\tc.Assert(err, ErrorMatches, \".*remote not found.*\")\n}\n\nfunc (s *RepositorySuite) TestLog(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tcIter, err := r.Log(&LogOptions{\n\t\tFrom: plumbing.NewHash(\"b8e471f58bcbca63b07bda20e428190409c2db47\"),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"b8e471f58bcbca63b07bda20e428190409c2db47\"),\n\t\tplumbing.NewHash(\"b029517f6300c2da0f4b651b8642506cd6aaf45d\"),\n\t}\n\n\tfor _, o := range commitOrder {\n\t\tcommit, err := cIter.Next()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(commit.Hash, Equals, o)\n\t}\n\t_, err = cIter.Next()\n\tc.Assert(err, Equals, io.EOF)\n}\n\nfunc (s *RepositorySuite) TestLogAll(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(err, IsNil)\n\n\trIter, err := r.Storer.IterReferences()\n\tc.Assert(err, IsNil)\n\n\trefCount := 0\n\terr = rIter.ForEach(func(ref *plumbing.Reference) error {\n\t\trefCount++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(refCount, Equals, 5)\n\n\tcIter, err := r.Log(&LogOptions{\n\t\tAll: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t\tplumbing.NewHash(\"e8d3ffab552895c19b9fcf7aa264d277cde33881\"),\n\t\tplumbing.NewHash(\"918c48b83bd081e863dbe1b80f8998f058cd8294\"),\n\t\tplumbing.NewHash(\"af2d6a6954d532f8ffb47615169c8fdf9d383a1a\"),\n\t\tplumbing.NewHash(\"1669dce138d9b841a518c64b10914d88f5e488ea\"),\n\t\tplumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t\tplumbing.NewHash(\"b029517f6300c2da0f4b651b8642506cd6aaf45d\"),\n\t\tplumbing.NewHash(\"a5b8b09e2f8fcb0bb99d3ccb0958157b40890d69\"),\n\t\tplumbing.NewHash(\"b8e471f58bcbca63b07bda20e428190409c2db47\"),\n\t}\n\n\tfor _, o := range commitOrder {\n\t\tcommit, err := cIter.Next()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(commit.Hash, Equals, o)\n\t}\n\t_, err = cIter.Next()\n\tc.Assert(err, Equals, io.EOF)\n\tcIter.Close()\n}\n\nfunc (s *RepositorySuite) TestLogAllMissingReferences(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(err, IsNil)\n\terr = r.Storer.RemoveReference(plumbing.HEAD)\n\tc.Assert(err, IsNil)\n\n\trIter, err := r.Storer.IterReferences()\n\tc.Assert(err, IsNil)\n\n\trefCount := 0\n\terr = rIter.ForEach(func(ref *plumbing.Reference) error {\n\t\trefCount++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(refCount, Equals, 4)\n\n\terr = r.Storer.SetReference(plumbing.NewHashReference(plumbing.ReferenceName(\"DUMMY\"), plumbing.NewHash(\"DUMMY\")))\n\tc.Assert(err, IsNil)\n\n\trIter, err = r.Storer.IterReferences()\n\tc.Assert(err, IsNil)\n\n\trefCount = 0\n\terr = rIter.ForEach(func(ref *plumbing.Reference) error {\n\t\trefCount++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(refCount, Equals, 5)\n\n\tcIter, err := r.Log(&LogOptions{\n\t\tAll: true,\n\t})\n\tc.Assert(cIter, NotNil)\n\tc.Assert(err, IsNil)\n\n\tcCount := 0\n\tcIter.ForEach(func(c *object.Commit) error {\n\t\tcCount++\n\t\treturn nil\n\t})\n\tc.Assert(cCount, Equals, 9)\n\n\t_, err = cIter.Next()\n\tc.Assert(err, Equals, io.EOF)\n\tcIter.Close()\n}\n\nfunc (s *RepositorySuite) TestLogAllOrderByTime(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tcIter, err := r.Log(&LogOptions{\n\t\tOrder: LogOrderCommitterTime,\n\t\tAll:   true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t\tplumbing.NewHash(\"e8d3ffab552895c19b9fcf7aa264d277cde33881\"),\n\t\tplumbing.NewHash(\"918c48b83bd081e863dbe1b80f8998f058cd8294\"),\n\t\tplumbing.NewHash(\"af2d6a6954d532f8ffb47615169c8fdf9d383a1a\"),\n\t\tplumbing.NewHash(\"1669dce138d9b841a518c64b10914d88f5e488ea\"),\n\t\tplumbing.NewHash(\"a5b8b09e2f8fcb0bb99d3ccb0958157b40890d69\"),\n\t\tplumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t\tplumbing.NewHash(\"b8e471f58bcbca63b07bda20e428190409c2db47\"),\n\t\tplumbing.NewHash(\"b029517f6300c2da0f4b651b8642506cd6aaf45d\"),\n\t}\n\n\tfor _, o := range commitOrder {\n\t\tcommit, err := cIter.Next()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(commit.Hash, Equals, o)\n\t}\n\t_, err = cIter.Next()\n\tc.Assert(err, Equals, io.EOF)\n\tcIter.Close()\n}\n\nfunc (s *RepositorySuite) TestLogHead(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tcIter, err := r.Log(&LogOptions{})\n\n\tc.Assert(err, IsNil)\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t\tplumbing.NewHash(\"918c48b83bd081e863dbe1b80f8998f058cd8294\"),\n\t\tplumbing.NewHash(\"af2d6a6954d532f8ffb47615169c8fdf9d383a1a\"),\n\t\tplumbing.NewHash(\"1669dce138d9b841a518c64b10914d88f5e488ea\"),\n\t\tplumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t\tplumbing.NewHash(\"b029517f6300c2da0f4b651b8642506cd6aaf45d\"),\n\t\tplumbing.NewHash(\"a5b8b09e2f8fcb0bb99d3ccb0958157b40890d69\"),\n\t\tplumbing.NewHash(\"b8e471f58bcbca63b07bda20e428190409c2db47\"),\n\t}\n\n\tfor _, o := range commitOrder {\n\t\tcommit, err := cIter.Next()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(commit.Hash, Equals, o)\n\t}\n\t_, err = cIter.Next()\n\tc.Assert(err, Equals, io.EOF)\n}\n\nfunc (s *RepositorySuite) TestLogError(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\t_, err = r.Log(&LogOptions{\n\t\tFrom: plumbing.NewHash(\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"),\n\t})\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *RepositorySuite) TestLogFileNext(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tfileName := \"vendor/foo.go\"\n\tcIter, err := r.Log(&LogOptions{FileName: &fileName})\n\n\tc.Assert(err, IsNil)\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t}\n\n\tfor _, o := range commitOrder {\n\t\tcommit, err := cIter.Next()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(commit.Hash, Equals, o)\n\t}\n\t_, err = cIter.Next()\n\tc.Assert(err, Equals, io.EOF)\n}\n\nfunc (s *RepositorySuite) TestLogFileForEach(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tfileName := \"php/crappy.php\"\n\tcIter, err := r.Log(&LogOptions{FileName: &fileName})\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"918c48b83bd081e863dbe1b80f8998f058cd8294\"),\n\t}\n\n\texpectedIndex := 0\n\terr = cIter.ForEach(func(commit *object.Commit) error {\n\t\texpectedCommitHash := commitOrder[expectedIndex]\n\t\tc.Assert(commit.Hash.String(), Equals, expectedCommitHash.String())\n\t\texpectedIndex++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(expectedIndex, Equals, 1)\n}\n\nfunc (s *RepositorySuite) TestLogNonHeadFile(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tfileName := \"README\"\n\tcIter, err := r.Log(&LogOptions{FileName: &fileName})\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\t_, err = cIter.Next()\n\tc.Assert(err, Equals, io.EOF)\n}\n\nfunc (s *RepositorySuite) TestLogAllFileForEach(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tfileName := \"README\"\n\tcIter, err := r.Log(&LogOptions{FileName: &fileName, All: true})\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"e8d3ffab552895c19b9fcf7aa264d277cde33881\"),\n\t}\n\n\texpectedIndex := 0\n\terr = cIter.ForEach(func(commit *object.Commit) error {\n\t\texpectedCommitHash := commitOrder[expectedIndex]\n\t\tc.Assert(commit.Hash.String(), Equals, expectedCommitHash.String())\n\t\texpectedIndex++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(expectedIndex, Equals, 1)\n}\n\nfunc (s *RepositorySuite) TestLogInvalidFile(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(err, IsNil)\n\n\t// Throwing in a file that does not exist\n\tfileName := \"vendor/foo12.go\"\n\tcIter, err := r.Log(&LogOptions{FileName: &fileName})\n\t// Not raising an error since `git log -- vendor/foo12.go` responds silently\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\t_, err = cIter.Next()\n\tc.Assert(err, Equals, io.EOF)\n}\n\nfunc (s *RepositorySuite) TestLogFileInitialCommit(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tfileName := \"LICENSE\"\n\tcIter, err := r.Log(&LogOptions{\n\t\tOrder:    LogOrderCommitterTime,\n\t\tFileName: &fileName,\n\t})\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"b029517f6300c2da0f4b651b8642506cd6aaf45d\"),\n\t}\n\n\texpectedIndex := 0\n\terr = cIter.ForEach(func(commit *object.Commit) error {\n\t\texpectedCommitHash := commitOrder[expectedIndex]\n\t\tc.Assert(commit.Hash.String(), Equals, expectedCommitHash.String())\n\t\texpectedIndex++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(expectedIndex, Equals, 1)\n}\n\nfunc (s *RepositorySuite) TestLogFileWithOtherParamsFail(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tfileName := \"vendor/foo.go\"\n\tcIter, err := r.Log(&LogOptions{\n\t\tOrder:    LogOrderCommitterTime,\n\t\tFileName: &fileName,\n\t\tFrom:     plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t})\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\t_, iterErr := cIter.Next()\n\tc.Assert(iterErr, Equals, io.EOF)\n}\n\nfunc (s *RepositorySuite) TestLogFileWithOtherParamsPass(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tfileName := \"LICENSE\"\n\tcIter, err := r.Log(&LogOptions{\n\t\tOrder:    LogOrderCommitterTime,\n\t\tFileName: &fileName,\n\t\tFrom:     plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t})\n\tc.Assert(err, IsNil)\n\tcommitVal, iterErr := cIter.Next()\n\tc.Assert(iterErr, Equals, nil)\n\tc.Assert(commitVal.Hash.String(), Equals, \"b029517f6300c2da0f4b651b8642506cd6aaf45d\")\n\n\t_, iterErr = cIter.Next()\n\tc.Assert(iterErr, Equals, io.EOF)\n}\n\ntype mockErrCommitIter struct{}\n\nfunc (m *mockErrCommitIter) Next() (*object.Commit, error) {\n\treturn nil, errors.New(\"mock next error\")\n}\nfunc (m *mockErrCommitIter) ForEach(func(*object.Commit) error) error {\n\treturn errors.New(\"mock foreach error\")\n}\n\nfunc (m *mockErrCommitIter) Close() {}\n\nfunc (s *RepositorySuite) TestLogFileWithError(c *C) {\n\tfileName := \"README\"\n\tcIter := object.NewCommitFileIterFromIter(fileName, &mockErrCommitIter{}, false)\n\tdefer cIter.Close()\n\n\terr := cIter.ForEach(func(commit *object.Commit) error {\n\t\treturn nil\n\t})\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *RepositorySuite) TestLogPathWithError(c *C) {\n\tfileName := \"README\"\n\tpathIter := func(path string) bool {\n\t\treturn path == fileName\n\t}\n\tcIter := object.NewCommitPathIterFromIter(pathIter, &mockErrCommitIter{}, false)\n\tdefer cIter.Close()\n\n\terr := cIter.ForEach(func(commit *object.Commit) error {\n\t\treturn nil\n\t})\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *RepositorySuite) TestLogPathRegexpWithError(c *C) {\n\tpathRE := regexp.MustCompile(\"R.*E\")\n\tpathIter := func(path string) bool {\n\t\treturn pathRE.MatchString(path)\n\t}\n\tcIter := object.NewCommitPathIterFromIter(pathIter, &mockErrCommitIter{}, false)\n\tdefer cIter.Close()\n\n\terr := cIter.ForEach(func(commit *object.Commit) error {\n\t\treturn nil\n\t})\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *RepositorySuite) TestLogPathFilterRegexp(c *C) {\n\tpathRE := regexp.MustCompile(`.*\\.go`)\n\tpathIter := func(path string) bool {\n\t\treturn pathRE.MatchString(path)\n\t}\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(err, IsNil)\n\n\texpectedCommitIDs := []string{\n\t\t\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"918c48b83bd081e863dbe1b80f8998f058cd8294\",\n\t}\n\tcommitIDs := []string{}\n\n\tcIter, err := r.Log(&LogOptions{\n\t\tPathFilter: pathIter,\n\t\tFrom:       plumbing.NewHash(\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t})\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\tcIter.ForEach(func(commit *object.Commit) error {\n\t\tcommitIDs = append(commitIDs, commit.ID().String())\n\t\treturn nil\n\t})\n\tc.Assert(\n\t\tstrings.Join(commitIDs, \", \"),\n\t\tEquals,\n\t\tstrings.Join(expectedCommitIDs, \", \"),\n\t)\n}\n\nfunc (s *RepositorySuite) TestLogLimitNext(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tsince := time.Date(2015, 4, 1, 0, 0, 0, 0, time.UTC)\n\tcIter, err := r.Log(&LogOptions{Since: &since})\n\n\tc.Assert(err, IsNil)\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t}\n\n\tfor _, o := range commitOrder {\n\t\tcommit, err := cIter.Next()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(commit.Hash, Equals, o)\n\t}\n\t_, err = cIter.Next()\n\tc.Assert(err, Equals, io.EOF)\n}\n\nfunc (s *RepositorySuite) TestLogLimitForEach(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tsince := time.Date(2015, 3, 31, 11, 54, 0, 0, time.UTC)\n\tuntil := time.Date(2015, 4, 1, 0, 0, 0, 0, time.UTC)\n\tcIter, err := r.Log(&LogOptions{Since: &since, Until: &until})\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"918c48b83bd081e863dbe1b80f8998f058cd8294\"),\n\t}\n\n\texpectedIndex := 0\n\terr = cIter.ForEach(func(commit *object.Commit) error {\n\t\texpectedCommitHash := commitOrder[expectedIndex]\n\t\tc.Assert(commit.Hash.String(), Equals, expectedCommitHash.String())\n\t\texpectedIndex++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(expectedIndex, Equals, 1)\n}\n\nfunc (s *RepositorySuite) TestLogAllLimitForEach(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tsince := time.Date(2015, 3, 31, 11, 54, 0, 0, time.UTC)\n\tuntil := time.Date(2015, 4, 1, 0, 0, 0, 0, time.UTC)\n\tcIter, err := r.Log(&LogOptions{Since: &since, Until: &until, All: true})\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"e8d3ffab552895c19b9fcf7aa264d277cde33881\"),\n\t\tplumbing.NewHash(\"918c48b83bd081e863dbe1b80f8998f058cd8294\"),\n\t}\n\n\texpectedIndex := 0\n\terr = cIter.ForEach(func(commit *object.Commit) error {\n\t\texpectedCommitHash := commitOrder[expectedIndex]\n\t\tc.Assert(commit.Hash.String(), Equals, expectedCommitHash.String())\n\t\texpectedIndex++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(expectedIndex, Equals, 2)\n}\n\nfunc (s *RepositorySuite) TestLogLimitWithOtherParamsFail(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tsince := time.Date(2015, 3, 31, 11, 54, 0, 0, time.UTC)\n\tcIter, err := r.Log(&LogOptions{\n\t\tOrder: LogOrderCommitterTime,\n\t\tSince: &since,\n\t\tFrom:  plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t})\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\t_, iterErr := cIter.Next()\n\tc.Assert(iterErr, Equals, io.EOF)\n}\n\nfunc (s *RepositorySuite) TestLogLimitWithOtherParamsPass(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tuntil := time.Date(2015, 3, 31, 11, 43, 0, 0, time.UTC)\n\tcIter, err := r.Log(&LogOptions{\n\t\tOrder: LogOrderCommitterTime,\n\t\tUntil: &until,\n\t\tFrom:  plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t})\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\tcommitVal, iterErr := cIter.Next()\n\tc.Assert(iterErr, Equals, nil)\n\tc.Assert(commitVal.Hash.String(), Equals, \"b029517f6300c2da0f4b651b8642506cd6aaf45d\")\n\n\t_, iterErr = cIter.Next()\n\tc.Assert(iterErr, Equals, io.EOF)\n}\n\nfunc (s *RepositorySuite) TestConfigScoped(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tcfg, err := r.ConfigScoped(config.LocalScope)\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.User.Email, Equals, \"\")\n\n\tcfg, err = r.ConfigScoped(config.SystemScope)\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.User.Email, Not(Equals), \"\")\n}\n\nfunc (s *RepositorySuite) TestCommit(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\thash := plumbing.NewHash(\"b8e471f58bcbca63b07bda20e428190409c2db47\")\n\tcommit, err := r.CommitObject(hash)\n\tc.Assert(err, IsNil)\n\n\tc.Assert(commit.Hash.IsZero(), Equals, false)\n\tc.Assert(commit.Hash, Equals, commit.ID())\n\tc.Assert(commit.Hash, Equals, hash)\n\tc.Assert(commit.Type(), Equals, plumbing.CommitObject)\n\n\ttree, err := commit.Tree()\n\tc.Assert(err, IsNil)\n\tc.Assert(tree.Hash.IsZero(), Equals, false)\n\n\tc.Assert(commit.Author.Email, Equals, \"daniel@lordran.local\")\n}\n\nfunc (s *RepositorySuite) TestCommits(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: s.GetBasicLocalRepositoryURL()})\n\tc.Assert(err, IsNil)\n\n\tcount := 0\n\tcommits, err := r.CommitObjects()\n\tc.Assert(err, IsNil)\n\tfor {\n\t\tcommit, err := commits.Next()\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n\n\t\tcount++\n\t\tc.Assert(commit.Hash.IsZero(), Equals, false)\n\t\tc.Assert(commit.Hash, Equals, commit.ID())\n\t\tc.Assert(commit.Type(), Equals, plumbing.CommitObject)\n\t}\n\n\tc.Assert(count, Equals, 9)\n}\n\nfunc (s *RepositorySuite) TestBlob(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tblob, err := r.BlobObject(plumbing.NewHash(\"b8e471f58bcbca63b07bda20e428190409c2db47\"))\n\tc.Assert(err, NotNil)\n\tc.Assert(blob, IsNil)\n\n\tblobHash := plumbing.NewHash(\"9a48f23120e880dfbe41f7c9b7b708e9ee62a492\")\n\tblob, err = r.BlobObject(blobHash)\n\tc.Assert(err, IsNil)\n\n\tc.Assert(blob.Hash.IsZero(), Equals, false)\n\tc.Assert(blob.Hash, Equals, blob.ID())\n\tc.Assert(blob.Hash, Equals, blobHash)\n\tc.Assert(blob.Type(), Equals, plumbing.BlobObject)\n}\n\nfunc (s *RepositorySuite) TestBlobs(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: s.GetBasicLocalRepositoryURL()})\n\tc.Assert(err, IsNil)\n\n\tcount := 0\n\tblobs, err := r.BlobObjects()\n\tc.Assert(err, IsNil)\n\tfor {\n\t\tblob, err := blobs.Next()\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n\n\t\tcount++\n\t\tc.Assert(blob.Hash.IsZero(), Equals, false)\n\t\tc.Assert(blob.Hash, Equals, blob.ID())\n\t\tc.Assert(blob.Type(), Equals, plumbing.BlobObject)\n\t}\n\n\tc.Assert(count, Equals, 10)\n}\n\nfunc (s *RepositorySuite) TestTagObject(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\thash := plumbing.NewHash(\"ad7897c0fb8e7d9a9ba41fa66072cf06095a6cfc\")\n\ttag, err := r.TagObject(hash)\n\tc.Assert(err, IsNil)\n\n\tc.Assert(tag.Hash.IsZero(), Equals, false)\n\tc.Assert(tag.Hash, Equals, hash)\n\tc.Assert(tag.Type(), Equals, plumbing.TagObject)\n}\n\nfunc (s *RepositorySuite) TestTags(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\tcount := 0\n\ttags, err := r.Tags()\n\tc.Assert(err, IsNil)\n\n\ttags.ForEach(func(tag *plumbing.Reference) error {\n\t\tcount++\n\t\tc.Assert(tag.Hash().IsZero(), Equals, false)\n\t\tc.Assert(tag.Name().IsTag(), Equals, true)\n\t\treturn nil\n\t})\n\n\tc.Assert(count, Equals, 5)\n}\n\nfunc (s *RepositorySuite) TestCreateTagLightweight(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\texpected, err := r.Head()\n\tc.Assert(err, IsNil)\n\n\tref, err := r.CreateTag(\"foobar\", expected.Hash(), nil)\n\tc.Assert(err, IsNil)\n\tc.Assert(ref, NotNil)\n\n\tactual, err := r.Tag(\"foobar\")\n\tc.Assert(err, IsNil)\n\n\tc.Assert(expected.Hash(), Equals, actual.Hash())\n}\n\nfunc (s *RepositorySuite) TestCreateTagLightweightExists(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\texpected, err := r.Head()\n\tc.Assert(err, IsNil)\n\n\tref, err := r.CreateTag(\"lightweight-tag\", expected.Hash(), nil)\n\tc.Assert(ref, IsNil)\n\tc.Assert(err, Equals, ErrTagExists)\n}\n\nfunc (s *RepositorySuite) TestCreateTagAnnotated(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\th, err := r.Head()\n\tc.Assert(err, IsNil)\n\n\texpectedHash := h.Hash()\n\n\tref, err := r.CreateTag(\"foobar\", expectedHash, &CreateTagOptions{\n\t\tTagger:  defaultSignature(),\n\t\tMessage: \"foo bar baz qux\",\n\t})\n\tc.Assert(err, IsNil)\n\n\ttag, err := r.Tag(\"foobar\")\n\tc.Assert(err, IsNil)\n\n\tobj, err := r.TagObject(tag.Hash())\n\tc.Assert(err, IsNil)\n\n\tc.Assert(ref, DeepEquals, tag)\n\tc.Assert(obj.Hash, Equals, ref.Hash())\n\tc.Assert(obj.Type(), Equals, plumbing.TagObject)\n\tc.Assert(obj.Target, Equals, expectedHash)\n}\n\nfunc (s *RepositorySuite) TestCreateTagAnnotatedBadOpts(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\th, err := r.Head()\n\tc.Assert(err, IsNil)\n\n\texpectedHash := h.Hash()\n\n\tref, err := r.CreateTag(\"foobar\", expectedHash, &CreateTagOptions{})\n\tc.Assert(ref, IsNil)\n\tc.Assert(err, Equals, ErrMissingMessage)\n}\n\nfunc (s *RepositorySuite) TestCreateTagAnnotatedBadHash(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\tref, err := r.CreateTag(\"foobar\", plumbing.ZeroHash, &CreateTagOptions{\n\t\tTagger:  defaultSignature(),\n\t\tMessage: \"foo bar baz qux\",\n\t})\n\tc.Assert(ref, IsNil)\n\tc.Assert(err, Equals, plumbing.ErrObjectNotFound)\n}\n\nfunc (s *RepositorySuite) TestCreateTagSigned(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\th, err := r.Head()\n\tc.Assert(err, IsNil)\n\n\tkey := commitSignKey(c, true)\n\t_, err = r.CreateTag(\"foobar\", h.Hash(), &CreateTagOptions{\n\t\tTagger:  defaultSignature(),\n\t\tMessage: \"foo bar baz qux\",\n\t\tSignKey: key,\n\t})\n\tc.Assert(err, IsNil)\n\n\ttag, err := r.Tag(\"foobar\")\n\tc.Assert(err, IsNil)\n\n\tobj, err := r.TagObject(tag.Hash())\n\tc.Assert(err, IsNil)\n\n\t// Verify the tag.\n\tpks := new(bytes.Buffer)\n\tpkw, err := armor.Encode(pks, openpgp.PublicKeyType, nil)\n\tc.Assert(err, IsNil)\n\n\terr = key.Serialize(pkw)\n\tc.Assert(err, IsNil)\n\terr = pkw.Close()\n\tc.Assert(err, IsNil)\n\n\tactual, err := obj.Verify(pks.String())\n\tc.Assert(err, IsNil)\n\tc.Assert(actual.PrimaryKey, DeepEquals, key.PrimaryKey)\n}\n\nfunc (s *RepositorySuite) TestCreateTagSignedBadKey(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\th, err := r.Head()\n\tc.Assert(err, IsNil)\n\n\tkey := commitSignKey(c, false)\n\t_, err = r.CreateTag(\"foobar\", h.Hash(), &CreateTagOptions{\n\t\tTagger:  defaultSignature(),\n\t\tMessage: \"foo bar baz qux\",\n\t\tSignKey: key,\n\t})\n\tc.Assert(err, Equals, openpgperr.InvalidArgumentError(\"signing key is encrypted\"))\n}\n\nfunc (s *RepositorySuite) TestCreateTagCanonicalize(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\th, err := r.Head()\n\tc.Assert(err, IsNil)\n\n\tkey := commitSignKey(c, true)\n\t_, err = r.CreateTag(\"foobar\", h.Hash(), &CreateTagOptions{\n\t\tTagger:  defaultSignature(),\n\t\tMessage: \"\\n\\nfoo bar baz qux\\n\\nsome message here\",\n\t\tSignKey: key,\n\t})\n\tc.Assert(err, IsNil)\n\n\ttag, err := r.Tag(\"foobar\")\n\tc.Assert(err, IsNil)\n\n\tobj, err := r.TagObject(tag.Hash())\n\tc.Assert(err, IsNil)\n\n\t// Assert the new canonicalized message.\n\tc.Assert(obj.Message, Equals, \"foo bar baz qux\\n\\nsome message here\\n\")\n\n\t// Verify the tag.\n\tpks := new(bytes.Buffer)\n\tpkw, err := armor.Encode(pks, openpgp.PublicKeyType, nil)\n\tc.Assert(err, IsNil)\n\n\terr = key.Serialize(pkw)\n\tc.Assert(err, IsNil)\n\terr = pkw.Close()\n\tc.Assert(err, IsNil)\n\n\tactual, err := obj.Verify(pks.String())\n\tc.Assert(err, IsNil)\n\tc.Assert(actual.PrimaryKey, DeepEquals, key.PrimaryKey)\n}\n\nfunc (s *RepositorySuite) TestTagLightweight(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\texpected := plumbing.NewHash(\"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\")\n\n\ttag, err := r.Tag(\"lightweight-tag\")\n\tc.Assert(err, IsNil)\n\n\tactual := tag.Hash()\n\tc.Assert(expected, Equals, actual)\n}\n\nfunc (s *RepositorySuite) TestTagLightweightMissingTag(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\ttag, err := r.Tag(\"lightweight-tag-tag\")\n\tc.Assert(tag, IsNil)\n\tc.Assert(err, Equals, ErrTagNotFound)\n}\n\nfunc (s *RepositorySuite) TestDeleteTag(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\terr = r.DeleteTag(\"lightweight-tag\")\n\tc.Assert(err, IsNil)\n\n\t_, err = r.Tag(\"lightweight-tag\")\n\tc.Assert(err, Equals, ErrTagNotFound)\n}\n\nfunc (s *RepositorySuite) TestDeleteTagMissingTag(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\terr = r.DeleteTag(\"lightweight-tag-tag\")\n\tc.Assert(err, Equals, ErrTagNotFound)\n}\n\nfunc (s *RepositorySuite) TestDeleteTagAnnotated(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tfs := s.TemporalFilesystem(c)\n\n\tfss := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\n\tr, _ := Init(fss, nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\tref, err := r.Tag(\"annotated-tag\")\n\tc.Assert(ref, NotNil)\n\tc.Assert(err, IsNil)\n\n\tobj, err := r.TagObject(ref.Hash())\n\tc.Assert(obj, NotNil)\n\tc.Assert(err, IsNil)\n\n\terr = r.DeleteTag(\"annotated-tag\")\n\tc.Assert(err, IsNil)\n\n\t_, err = r.Tag(\"annotated-tag\")\n\tc.Assert(err, Equals, ErrTagNotFound)\n\n\t// Run a prune (and repack, to ensure that we are GCing everything regardless\n\t// of the fixture in use) and try to get the tag object again.\n\t//\n\t// The repo needs to be re-opened after the repack.\n\terr = r.Prune(PruneOptions{Handler: r.DeleteObject})\n\tc.Assert(err, IsNil)\n\n\terr = r.RepackObjects(&RepackConfig{})\n\tc.Assert(err, IsNil)\n\n\tr, err = PlainOpen(fs.Root())\n\tc.Assert(r, NotNil)\n\tc.Assert(err, IsNil)\n\n\t// Now check to see if the GC was effective in removing the tag object.\n\tobj, err = r.TagObject(ref.Hash())\n\tc.Assert(obj, IsNil)\n\tc.Assert(err, Equals, plumbing.ErrObjectNotFound)\n}\n\nfunc (s *RepositorySuite) TestDeleteTagAnnotatedUnpacked(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tfs := s.TemporalFilesystem(c)\n\n\tfss := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\n\tr, _ := Init(fss, nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\t// Create a tag for the deletion test. This ensures that the ultimate loose\n\t// object will be unpacked (as we aren't doing anything that should pack it),\n\t// so that we can effectively test that a prune deletes it, without having to\n\t// resort to a repack.\n\th, err := r.Head()\n\tc.Assert(err, IsNil)\n\n\texpectedHash := h.Hash()\n\n\tref, err := r.CreateTag(\"foobar\", expectedHash, &CreateTagOptions{\n\t\tTagger:  defaultSignature(),\n\t\tMessage: \"foo bar baz qux\",\n\t})\n\tc.Assert(err, IsNil)\n\n\ttag, err := r.Tag(\"foobar\")\n\tc.Assert(err, IsNil)\n\n\tobj, err := r.TagObject(tag.Hash())\n\tc.Assert(obj, NotNil)\n\tc.Assert(err, IsNil)\n\n\terr = r.DeleteTag(\"foobar\")\n\tc.Assert(err, IsNil)\n\n\t_, err = r.Tag(\"foobar\")\n\tc.Assert(err, Equals, ErrTagNotFound)\n\n\t// As mentioned, only run a prune. We are not testing for packed objects\n\t// here.\n\terr = r.Prune(PruneOptions{Handler: r.DeleteObject})\n\tc.Assert(err, IsNil)\n\n\t// Now check to see if the GC was effective in removing the tag object.\n\tobj, err = r.TagObject(ref.Hash())\n\tc.Assert(obj, IsNil)\n\tc.Assert(err, Equals, plumbing.ErrObjectNotFound)\n}\n\nfunc (s *RepositorySuite) TestInvalidTagName(c *C) {\n\tr, err := Init(memory.NewStorage(), nil)\n\tc.Assert(err, IsNil)\n\tfor i, name := range []string{\n\t\t\"\",\n\t\t\"foo bar\",\n\t\t\"foo\\tbar\",\n\t\t\"foo\\nbar\",\n\t} {\n\t\t_, err = r.CreateTag(name, plumbing.ZeroHash, nil)\n\t\tc.Assert(err, NotNil, Commentf(\"case %d %q\", i, name))\n\t}\n}\n\nfunc (s *RepositorySuite) TestBranches(c *C) {\n\tf := fixtures.ByURL(\"https://github.com/git-fixtures/root-references.git\").One()\n\tsto := filesystem.NewStorage(f.DotGit(), cache.NewObjectLRUDefault())\n\tr, err := Open(sto, f.DotGit())\n\tc.Assert(err, IsNil)\n\n\tcount := 0\n\tbranches, err := r.Branches()\n\tc.Assert(err, IsNil)\n\n\tbranches.ForEach(func(branch *plumbing.Reference) error {\n\t\tcount++\n\t\tc.Assert(branch.Hash().IsZero(), Equals, false)\n\t\tc.Assert(branch.Name().IsBranch(), Equals, true)\n\t\treturn nil\n\t})\n\n\tc.Assert(count, Equals, 8)\n}\n\nfunc (s *RepositorySuite) TestNotes(c *C) {\n\t// TODO add fixture with Notes\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\tcount := 0\n\tnotes, err := r.Notes()\n\tc.Assert(err, IsNil)\n\n\tnotes.ForEach(func(note *plumbing.Reference) error {\n\t\tcount++\n\t\tc.Assert(note.Hash().IsZero(), Equals, false)\n\t\tc.Assert(note.Name().IsNote(), Equals, true)\n\t\treturn nil\n\t})\n\n\tc.Assert(count, Equals, 0)\n}\n\nfunc (s *RepositorySuite) TestTree(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tinvalidHash := plumbing.NewHash(\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\")\n\ttree, err := r.TreeObject(invalidHash)\n\tc.Assert(tree, IsNil)\n\tc.Assert(err, NotNil)\n\n\thash := plumbing.NewHash(\"dbd3641b371024f44d0e469a9c8f5457b0660de1\")\n\ttree, err = r.TreeObject(hash)\n\tc.Assert(err, IsNil)\n\n\tc.Assert(tree.Hash.IsZero(), Equals, false)\n\tc.Assert(tree.Hash, Equals, tree.ID())\n\tc.Assert(tree.Hash, Equals, hash)\n\tc.Assert(tree.Type(), Equals, plumbing.TreeObject)\n\tc.Assert(len(tree.Entries), Not(Equals), 0)\n}\n\nfunc (s *RepositorySuite) TestTrees(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: s.GetBasicLocalRepositoryURL()})\n\tc.Assert(err, IsNil)\n\n\tcount := 0\n\ttrees, err := r.TreeObjects()\n\tc.Assert(err, IsNil)\n\tfor {\n\t\ttree, err := trees.Next()\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n\n\t\tcount++\n\t\tc.Assert(tree.Hash.IsZero(), Equals, false)\n\t\tc.Assert(tree.Hash, Equals, tree.ID())\n\t\tc.Assert(tree.Type(), Equals, plumbing.TreeObject)\n\t\tc.Assert(len(tree.Entries), Not(Equals), 0)\n\t}\n\n\tc.Assert(count, Equals, 12)\n}\n\nfunc (s *RepositorySuite) TestTagObjects(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\tcount := 0\n\ttags, err := r.TagObjects()\n\tc.Assert(err, IsNil)\n\n\ttags.ForEach(func(tag *object.Tag) error {\n\t\tcount++\n\n\t\tc.Assert(tag.Hash.IsZero(), Equals, false)\n\t\tc.Assert(tag.Type(), Equals, plumbing.TagObject)\n\t\treturn nil\n\t})\n\n\trefs, _ := r.References()\n\trefs.ForEach(func(ref *plumbing.Reference) error {\n\t\treturn nil\n\t})\n\n\tc.Assert(count, Equals, 4)\n}\n\nfunc (s *RepositorySuite) TestCommitIterClosePanic(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: s.GetBasicLocalRepositoryURL()})\n\tc.Assert(err, IsNil)\n\n\tcommits, err := r.CommitObjects()\n\tc.Assert(err, IsNil)\n\tcommits.Close()\n}\n\nfunc (s *RepositorySuite) TestRef(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: s.GetBasicLocalRepositoryURL()})\n\tc.Assert(err, IsNil)\n\n\tref, err := r.Reference(plumbing.HEAD, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(ref.Name(), Equals, plumbing.HEAD)\n\n\tref, err = r.Reference(plumbing.HEAD, true)\n\tc.Assert(err, IsNil)\n\tc.Assert(ref.Name(), Equals, plumbing.ReferenceName(\"refs/heads/master\"))\n}\n\nfunc (s *RepositorySuite) TestRefs(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: s.GetBasicLocalRepositoryURL()})\n\tc.Assert(err, IsNil)\n\n\tc.Assert(err, IsNil)\n\n\titer, err := r.References()\n\tc.Assert(err, IsNil)\n\tc.Assert(iter, NotNil)\n}\n\nfunc (s *RepositorySuite) TestObject(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: s.GetBasicLocalRepositoryURL()})\n\tc.Assert(err, IsNil)\n\n\thash := plumbing.NewHash(\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\to, err := r.Object(plumbing.CommitObject, hash)\n\tc.Assert(err, IsNil)\n\n\tc.Assert(o.ID().IsZero(), Equals, false)\n\tc.Assert(o.Type(), Equals, plumbing.CommitObject)\n}\n\nfunc (s *RepositorySuite) TestObjects(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: s.GetBasicLocalRepositoryURL()})\n\tc.Assert(err, IsNil)\n\n\tcount := 0\n\tobjects, err := r.Objects()\n\tc.Assert(err, IsNil)\n\tfor {\n\t\to, err := objects.Next()\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n\n\t\tcount++\n\t\tc.Assert(o.ID().IsZero(), Equals, false)\n\t\tc.Assert(o.Type(), Not(Equals), plumbing.AnyObject)\n\t}\n\n\tc.Assert(count, Equals, 31)\n}\n\nfunc (s *RepositorySuite) TestObjectNotFound(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: s.GetBasicLocalRepositoryURL()})\n\tc.Assert(err, IsNil)\n\n\thash := plumbing.NewHash(\"0a3fb06ff80156fb153bcdcc58b5e16c2d27625c\")\n\ttag, err := r.Object(plumbing.TagObject, hash)\n\tc.Assert(err, DeepEquals, plumbing.ErrObjectNotFound)\n\tc.Assert(tag, IsNil)\n}\n\nfunc (s *RepositorySuite) TestWorktree(c *C) {\n\tdef := memfs.New()\n\tr, _ := Init(memory.NewStorage(), def)\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\tc.Assert(w.Filesystem, Equals, def)\n}\n\nfunc (s *RepositorySuite) TestWorktreeBare(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\tw, err := r.Worktree()\n\tc.Assert(err, Equals, ErrIsBareRepository)\n\tc.Assert(w, IsNil)\n}\n\nfunc (s *RepositorySuite) TestResolveRevision(c *C) {\n\tf := fixtures.ByURL(\"https://github.com/git-fixtures/basic.git\").One()\n\tsto := filesystem.NewStorage(f.DotGit(), cache.NewObjectLRUDefault())\n\tr, err := Open(sto, f.DotGit())\n\tc.Assert(err, IsNil)\n\n\tdatas := map[string]string{\n\t\t\"HEAD\":                       \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"heads/master\":               \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"heads/master~1\":             \"918c48b83bd081e863dbe1b80f8998f058cd8294\",\n\t\t\"refs/heads/master\":          \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"refs/heads/master~2^^~\":     \"b029517f6300c2da0f4b651b8642506cd6aaf45d\",\n\t\t\"refs/tags/v1.0.0\":           \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"refs/remotes/origin/master\": \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"refs/remotes/origin/HEAD\":   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"HEAD~2^^~\":                  \"b029517f6300c2da0f4b651b8642506cd6aaf45d\",\n\t\t\"HEAD~3^2\":                   \"a5b8b09e2f8fcb0bb99d3ccb0958157b40890d69\",\n\t\t\"HEAD~3^2^0\":                 \"a5b8b09e2f8fcb0bb99d3ccb0958157b40890d69\",\n\t\t\"HEAD~2^{/binary file}\":      \"35e85108805c84807bc66a02d91535e1e24b38b9\",\n\t\t\"HEAD~^{/!-some}\":            \"1669dce138d9b841a518c64b10914d88f5e488ea\",\n\t\t\"master\":                     \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"branch\":                     \"e8d3ffab552895c19b9fcf7aa264d277cde33881\",\n\t\t\"v1.0.0\":                     \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"branch~1\":                   \"918c48b83bd081e863dbe1b80f8998f058cd8294\",\n\t\t\"v1.0.0~1\":                   \"918c48b83bd081e863dbe1b80f8998f058cd8294\",\n\t\t\"master~1\":                   \"918c48b83bd081e863dbe1b80f8998f058cd8294\",\n\t\t\"918c48b83bd081e863dbe1b80f8998f058cd8294\": \"918c48b83bd081e863dbe1b80f8998f058cd8294\",\n\t\t\"918c48b\": \"918c48b83bd081e863dbe1b80f8998f058cd8294\", // odd number of hex digits\n\t}\n\n\tfor rev, hash := range datas {\n\t\th, err := r.ResolveRevision(plumbing.Revision(rev))\n\n\t\tc.Assert(err, IsNil, Commentf(\"while checking %s\", rev))\n\t\tc.Check(h.String(), Equals, hash, Commentf(\"while checking %s\", rev))\n\t}\n}\n\nfunc (s *RepositorySuite) TestResolveRevisionAnnotated(c *C) {\n\tf := fixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One()\n\tsto := filesystem.NewStorage(f.DotGit(), cache.NewObjectLRUDefault())\n\tr, err := Open(sto, f.DotGit())\n\tc.Assert(err, IsNil)\n\n\tdatas := map[string]string{\n\t\t\"refs/tags/annotated-tag\":                  \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\",\n\t\t\"b742a2a9fa0afcfa9a6fad080980fbc26b007c69\": \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\",\n\t}\n\n\tfor rev, hash := range datas {\n\t\th, err := r.ResolveRevision(plumbing.Revision(rev))\n\n\t\tc.Assert(err, IsNil, Commentf(\"while checking %s\", rev))\n\t\tc.Check(h.String(), Equals, hash, Commentf(\"while checking %s\", rev))\n\t}\n}\n\nfunc (s *RepositorySuite) TestResolveRevisionWithErrors(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/basic.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\theadRef, err := r.Head()\n\tc.Assert(err, IsNil)\n\n\tref := plumbing.NewHashReference(\"refs/heads/918c48b83bd081e863dbe1b80f8998f058cd8294\", headRef.Hash())\n\terr = r.Storer.SetReference(ref)\n\tc.Assert(err, IsNil)\n\n\tdatas := map[string]string{\n\t\t\"efs/heads/master~\": \"reference not found\",\n\t\t\"HEAD^3\":            `Revision invalid : \"3\" found must be 0, 1 or 2 after \"^\"`,\n\t\t\"HEAD^{/whatever}\":  `no commit message match regexp: \"whatever\"`,\n\t\t\"4e1243bd22c66e76c2ba9eddc1f91394e57f9f83\": \"reference not found\",\n\t}\n\n\tfor rev, rerr := range datas {\n\t\t_, err := r.ResolveRevision(plumbing.Revision(rev))\n\t\tc.Assert(err, NotNil)\n\t\tc.Assert(err.Error(), Equals, rerr)\n\t}\n}\n\nfunc (s *RepositorySuite) testRepackObjects(\n\tc *C, deleteTime time.Time, expectedPacks int) {\n\tsrcFs := fixtures.ByTag(\"unpacked\").One().DotGit()\n\tvar sto storage.Storer\n\tvar err error\n\tsto = filesystem.NewStorage(srcFs, cache.NewObjectLRUDefault())\n\n\tlos := sto.(storer.LooseObjectStorer)\n\tc.Assert(los, NotNil)\n\n\tnumLooseStart := 0\n\terr = los.ForEachObjectHash(func(_ plumbing.Hash) error {\n\t\tnumLooseStart++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(numLooseStart > 0, Equals, true)\n\n\tpos := sto.(storer.PackedObjectStorer)\n\tc.Assert(los, NotNil)\n\n\tpacks, err := pos.ObjectPacks()\n\tc.Assert(err, IsNil)\n\tnumPacksStart := len(packs)\n\tc.Assert(numPacksStart > 1, Equals, true)\n\n\tr, err := Open(sto, srcFs)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\terr = r.RepackObjects(&RepackConfig{\n\t\tOnlyDeletePacksOlderThan: deleteTime,\n\t})\n\tc.Assert(err, IsNil)\n\n\tnumLooseEnd := 0\n\terr = los.ForEachObjectHash(func(_ plumbing.Hash) error {\n\t\tnumLooseEnd++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(numLooseEnd, Equals, 0)\n\n\tpacks, err = pos.ObjectPacks()\n\tc.Assert(err, IsNil)\n\tnumPacksEnd := len(packs)\n\tc.Assert(numPacksEnd, Equals, expectedPacks)\n}\n\nfunc (s *RepositorySuite) TestRepackObjects(c *C) {\n\tif testing.Short() {\n\t\tc.Skip(\"skipping test in short mode.\")\n\t}\n\n\ts.testRepackObjects(c, time.Time{}, 1)\n}\n\nfunc (s *RepositorySuite) TestRepackObjectsWithNoDelete(c *C) {\n\tif testing.Short() {\n\t\tc.Skip(\"skipping test in short mode.\")\n\t}\n\n\ts.testRepackObjects(c, time.Unix(0, 1), 3)\n}\n\nfunc ExecuteOnPath(c *C, path string, cmds ...string) error {\n\tfor _, cmd := range cmds {\n\t\terr := executeOnPath(path, cmd)\n\t\tc.Assert(err, IsNil)\n\t}\n\n\treturn nil\n}\n\nfunc executeOnPath(path, cmd string) error {\n\targs := strings.Split(cmd, \" \")\n\tc := exec.Command(args[0], args[1:]...)\n\tc.Dir = path\n\tc.Env = os.Environ()\n\n\tbuf := bytes.NewBuffer(nil)\n\tc.Stderr = buf\n\tc.Stdout = buf\n\n\treturn c.Run()\n}\n\nfunc (s *RepositorySuite) TestBrokenMultipleShallowFetch(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\t_, err := r.CreateRemote(&config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\tc.Assert(err, IsNil)\n\n\tc.Assert(r.Fetch(&FetchOptions{\n\t\tDepth:    2,\n\t\tRefSpecs: []config.RefSpec{config.RefSpec(\"refs/heads/master:refs/heads/master\")},\n\t}), IsNil)\n\n\tshallows, err := r.Storer.Shallow()\n\tc.Assert(err, IsNil)\n\tc.Assert(len(shallows), Equals, 1)\n\n\tref, err := r.Reference(\"refs/heads/master\", true)\n\tc.Assert(err, IsNil)\n\tcobj, err := r.CommitObject(ref.Hash())\n\tc.Assert(err, IsNil)\n\tc.Assert(cobj, NotNil)\n\terr = object.NewCommitPreorderIter(cobj, nil, nil).ForEach(func(c *object.Commit) error {\n\t\tfor _, ph := range c.ParentHashes {\n\t\t\tfor _, h := range shallows {\n\t\t\t\tif ph == h {\n\t\t\t\t\treturn storer.ErrStop\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\n\tc.Assert(r.Fetch(&FetchOptions{\n\t\tDepth:    5,\n\t\tRefSpecs: []config.RefSpec{config.RefSpec(\"refs/heads/*:refs/heads/*\")},\n\t}), IsNil)\n\n\tshallows, err = r.Storer.Shallow()\n\tc.Assert(err, IsNil)\n\tc.Assert(len(shallows), Equals, 3)\n\n\tref, err = r.Reference(\"refs/heads/master\", true)\n\tc.Assert(err, IsNil)\n\tcobj, err = r.CommitObject(ref.Hash())\n\tc.Assert(err, IsNil)\n\tc.Assert(cobj, NotNil)\n\terr = object.NewCommitPreorderIter(cobj, nil, nil).ForEach(func(c *object.Commit) error {\n\t\tfor _, ph := range c.ParentHashes {\n\t\t\tfor _, h := range shallows {\n\t\t\t\tif ph == h {\n\t\t\t\t\treturn storer.ErrStop\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *RepositorySuite) TestDotGitToOSFilesystemsInvalidPath(c *C) {\n\t_, _, err := dotGitToOSFilesystems(\"\\000\", false)\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *RepositorySuite) TestIssue674(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\th, err := r.ResolveRevision(plumbing.Revision(\"\"))\n\n\tc.Assert(err, NotNil)\n\tc.Assert(h, NotNil)\n\tc.Check(h.IsZero(), Equals, true)\n}\n\nfunc BenchmarkObjects(b *testing.B) {\n\tdefer fixtures.Clean()\n\n\tfor _, f := range fixtures.ByTag(\"packfile\") {\n\t\tif f.DotGitHash == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\tb.Run(f.URL, func(b *testing.B) {\n\t\t\tfs := f.DotGit()\n\t\t\tst := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\n\t\t\tworktree, err := fs.Chroot(filepath.Dir(fs.Root()))\n\t\t\tif err != nil {\n\t\t\t\tb.Fatal(err)\n\t\t\t}\n\n\t\t\trepo, err := Open(st, worktree)\n\t\t\tif err != nil {\n\t\t\t\tb.Fatal(err)\n\t\t\t}\n\n\t\t\tfor i := 0; i < b.N; i++ {\n\t\t\t\titer, err := repo.Objects()\n\t\t\t\tif err != nil {\n\t\t\t\t\tb.Fatal(err)\n\t\t\t\t}\n\n\t\t\t\tfor {\n\t\t\t\t\t_, err := iter.Next()\n\t\t\t\t\tif err == io.EOF {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tb.Fatal(err)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\titer.Close()\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc BenchmarkPlainClone(b *testing.B) {\n\tb.StopTimer()\n\tclone := func(b *testing.B) {\n\t\t_, err := PlainClone(b.TempDir(), true, &CloneOptions{\n\t\t\tURL:          \"https://github.com/go-git/go-git.git\",\n\t\t\tDepth:        1,\n\t\t\tTags:         NoTags,\n\t\t\tSingleBranch: true,\n\t\t})\n\t\tif err != nil {\n\t\t\tb.Error(err)\n\t\t}\n\t}\n\n\t// Warm-up as the initial clone could have a higher cost which\n\t// may skew results.\n\tclone(b)\n\n\tb.StartTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tclone(b)\n\t}\n}\n"
        },
        {
          "name": "repository_unix_test.go",
          "type": "blob",
          "size": 0.2578125,
          "content": "// +build !plan9,!windows\n\npackage git\n\nimport \"fmt\"\n\n// preReceiveHook returns the bytes of a pre-receive hook script\n// that prints m before exiting successfully\nfunc preReceiveHook(m string) []byte {\n\treturn []byte(fmt.Sprintf(\"#!/bin/sh\\nprintf '%s'\\n\", m))\n}\n"
        },
        {
          "name": "repository_windows_test.go",
          "type": "blob",
          "size": 1,
          "content": "package git\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n\n\t\"github.com/go-git/go-billy/v5/util\"\n\t\"github.com/go-git/go-git/v5/storage/memory\"\n\t. \"gopkg.in/check.v1\"\n)\n\n// preReceiveHook returns the bytes of a pre-receive hook script\n// that prints m before exiting successfully\nfunc preReceiveHook(m string) []byte {\n\treturn []byte(fmt.Sprintf(\"#!C:/Program\\\\ Files/Git/usr/bin/sh.exe\\nprintf '%s'\\n\", m))\n}\n\nfunc (s *RepositorySuite) TestCloneFileUrlWindows(c *C) {\n\tdir := c.MkDir()\n\n\tr, err := PlainInit(dir, false)\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(r.wt, \"foo\", nil, 0755)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\t_, err = w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\n\t_, err = w.Commit(\"foo\", &CommitOptions{\n\t\tAuthor:    defaultSignature(),\n\t\tCommitter: defaultSignature(),\n\t})\n\tc.Assert(err, IsNil)\n\n\turl := \"file:///\" + strings.ReplaceAll(dir, \"\\\\\", \"/\")\n\tc.Assert(url, Matches, \"file:///[A-Za-z]:/.*\")\n\t_, err = Clone(memory.NewStorage(), nil, &CloneOptions{\n\t\tURL: url,\n\t})\n\n\tc.Assert(err, IsNil)\n}\n"
        },
        {
          "name": "signer.go",
          "type": "blob",
          "size": 0.80859375,
          "content": "package git\n\nimport (\n\t\"io\"\n\n\t\"github.com/go-git/go-git/v5/plumbing\"\n)\n\n// signableObject is an object which can be signed.\ntype signableObject interface {\n\tEncodeWithoutSignature(o plumbing.EncodedObject) error\n}\n\n// Signer is an interface for signing git objects.\n// message is a reader containing the encoded object to be signed.\n// Implementors should return the encoded signature and an error if any.\n// See https://git-scm.com/docs/gitformat-signature for more information.\ntype Signer interface {\n\tSign(message io.Reader) ([]byte, error)\n}\n\nfunc signObject(signer Signer, obj signableObject) ([]byte, error) {\n\tencoded := &plumbing.MemoryObject{}\n\tif err := obj.EncodeWithoutSignature(encoded); err != nil {\n\t\treturn nil, err\n\t}\n\tr, err := encoded.Reader()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn signer.Sign(r)\n}\n"
        },
        {
          "name": "signer_test.go",
          "type": "blob",
          "size": 1.318359375,
          "content": "package git\n\nimport (\n\t\"encoding/base64\"\n\t\"fmt\"\n\t\"io\"\n\t\"time\"\n\n\t\"github.com/go-git/go-billy/v5/memfs\"\n\t\"github.com/go-git/go-git/v5/plumbing/object\"\n\t\"github.com/go-git/go-git/v5/storage/memory\"\n)\n\ntype b64signer struct{}\n\n// This is not secure, and is only used as an example for testing purposes.\n// Please don't do this.\nfunc (b64signer) Sign(message io.Reader) ([]byte, error) {\n\tb, err := io.ReadAll(message)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tout := make([]byte, base64.StdEncoding.EncodedLen(len(b)))\n\tbase64.StdEncoding.Encode(out, b)\n\treturn out, nil\n}\n\nfunc ExampleSigner() {\n\trepo, err := Init(memory.NewStorage(), memfs.New())\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tw, err := repo.Worktree()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tcommit, err := w.Commit(\"example commit\", &CommitOptions{\n\t\tAuthor: &object.Signature{\n\t\t\tName:  \"John Doe\",\n\t\t\tEmail: \"john@example.com\",\n\t\t\tWhen:  time.UnixMicro(1234567890).UTC(),\n\t\t},\n\t\tSigner:            b64signer{},\n\t\tAllowEmptyCommits: true,\n\t})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tobj, err := repo.CommitObject(commit)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tfmt.Println(obj.PGPSignature)\n\t// Output: dHJlZSA0YjgyNWRjNjQyY2I2ZWI5YTA2MGU1NGJmOGQ2OTI4OGZiZWU0OTA0CmF1dGhvciBKb2huIERvZSA8am9obkBleGFtcGxlLmNvbT4gMTIzNCArMDAwMApjb21taXR0ZXIgSm9obiBEb2UgPGpvaG5AZXhhbXBsZS5jb20+IDEyMzQgKzAwMDAKCmV4YW1wbGUgY29tbWl0\n}\n"
        },
        {
          "name": "status.go",
          "type": "blob",
          "size": 4.0107421875,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"path/filepath\"\n\n\tmindex \"github.com/go-git/go-git/v5/utils/merkletrie/index\"\n\t\"github.com/go-git/go-git/v5/utils/merkletrie/noder\"\n)\n\n// Status represents the current status of a Worktree.\n// The key of the map is the path of the file.\ntype Status map[string]*FileStatus\n\n// File returns the FileStatus for a given path, if the FileStatus doesn't\n// exists a new FileStatus is added to the map using the path as key.\nfunc (s Status) File(path string) *FileStatus {\n\tif _, ok := (s)[path]; !ok {\n\t\ts[path] = &FileStatus{Worktree: Untracked, Staging: Untracked}\n\t}\n\n\treturn s[path]\n}\n\n// IsUntracked checks if file for given path is 'Untracked'\nfunc (s Status) IsUntracked(path string) bool {\n\tstat, ok := (s)[filepath.ToSlash(path)]\n\treturn ok && stat.Worktree == Untracked\n}\n\n// IsClean returns true if all the files are in Unmodified status.\nfunc (s Status) IsClean() bool {\n\tfor _, status := range s {\n\t\tif status.Worktree != Unmodified || status.Staging != Unmodified {\n\t\t\treturn false\n\t\t}\n\t}\n\n\treturn true\n}\n\nfunc (s Status) String() string {\n\tbuf := bytes.NewBuffer(nil)\n\tfor path, status := range s {\n\t\tif status.Staging == Unmodified && status.Worktree == Unmodified {\n\t\t\tcontinue\n\t\t}\n\n\t\tif status.Staging == Renamed {\n\t\t\tpath = fmt.Sprintf(\"%s -> %s\", path, status.Extra)\n\t\t}\n\n\t\tfmt.Fprintf(buf, \"%c%c %s\\n\", status.Staging, status.Worktree, path)\n\t}\n\n\treturn buf.String()\n}\n\n// FileStatus contains the status of a file in the worktree\ntype FileStatus struct {\n\t// Staging is the status of a file in the staging area\n\tStaging StatusCode\n\t// Worktree is the status of a file in the worktree\n\tWorktree StatusCode\n\t// Extra contains extra information, such as the previous name in a rename\n\tExtra string\n}\n\n// StatusCode status code of a file in the Worktree\ntype StatusCode byte\n\nconst (\n\tUnmodified         StatusCode = ' '\n\tUntracked          StatusCode = '?'\n\tModified           StatusCode = 'M'\n\tAdded              StatusCode = 'A'\n\tDeleted            StatusCode = 'D'\n\tRenamed            StatusCode = 'R'\n\tCopied             StatusCode = 'C'\n\tUpdatedButUnmerged StatusCode = 'U'\n)\n\n// StatusStrategy defines the different types of strategies when processing\n// the worktree status.\ntype StatusStrategy int\n\nconst (\n\t// TODO: (V6) Review the default status strategy.\n\t// TODO: (V6) Review the type used to represent Status, to enable lazy\n\t// processing of statuses going direct to the backing filesystem.\n\tdefaultStatusStrategy = Empty\n\n\t// Empty starts its status map from empty. Missing entries for a given\n\t// path means that the file is untracked. This causes a known issue (#119)\n\t// whereby unmodified files can be incorrectly reported as untracked.\n\t//\n\t// This can be used when returning the changed state within a modified Worktree.\n\t// For example, to check whether the current worktree is clean.\n\tEmpty StatusStrategy = 0\n\t// Preload goes through all existing nodes from the index and add them to the\n\t// status map as unmodified. This is currently the most reliable strategy\n\t// although it comes at a performance cost in large repositories.\n\t//\n\t// This method is recommended when fetching the status of unmodified files.\n\t// For example, to confirm the status of a specific file that is either\n\t// untracked or unmodified.\n\tPreload StatusStrategy = 1\n)\n\nfunc (s StatusStrategy) new(w *Worktree) (Status, error) {\n\tswitch s {\n\tcase Preload:\n\t\treturn preloadStatus(w)\n\tcase Empty:\n\t\treturn make(Status), nil\n\t}\n\treturn nil, fmt.Errorf(\"%w: %+v\", ErrUnsupportedStatusStrategy, s)\n}\n\nfunc preloadStatus(w *Worktree) (Status, error) {\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tidxRoot := mindex.NewRootNode(idx)\n\tnodes := []noder.Noder{idxRoot}\n\n\tstatus := make(Status)\n\tfor len(nodes) > 0 {\n\t\tvar node noder.Noder\n\t\tnode, nodes = nodes[0], nodes[1:]\n\t\tif node.IsDir() {\n\t\t\tchildren, err := node.Children()\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tnodes = append(nodes, children...)\n\t\t\tcontinue\n\t\t}\n\t\tfs := status.File(node.Name())\n\t\tfs.Worktree = Unmodified\n\t\tfs.Staging = Unmodified\n\t}\n\n\treturn status, nil\n}\n"
        },
        {
          "name": "storage",
          "type": "tree",
          "content": null
        },
        {
          "name": "submodule.go",
          "type": "blob",
          "size": 8.92578125,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"path\"\n\n\t\"github.com/go-git/go-billy/v5\"\n\t\"github.com/go-git/go-git/v5/config\"\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/plumbing/format/index\"\n\t\"github.com/go-git/go-git/v5/plumbing/transport\"\n)\n\nvar (\n\tErrSubmoduleAlreadyInitialized = errors.New(\"submodule already initialized\")\n\tErrSubmoduleNotInitialized     = errors.New(\"submodule not initialized\")\n)\n\n// Submodule a submodule allows you to keep another Git repository in a\n// subdirectory of your repository.\ntype Submodule struct {\n\t// initialized defines if a submodule was already initialized.\n\tinitialized bool\n\n\tc *config.Submodule\n\tw *Worktree\n}\n\n// Config returns the submodule config\nfunc (s *Submodule) Config() *config.Submodule {\n\treturn s.c\n}\n\n// Init initialize the submodule reading the recorded Entry in the index for\n// the given submodule\nfunc (s *Submodule) Init() error {\n\tcfg, err := s.w.r.Config()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t_, ok := cfg.Submodules[s.c.Name]\n\tif ok {\n\t\treturn ErrSubmoduleAlreadyInitialized\n\t}\n\n\ts.initialized = true\n\n\tcfg.Submodules[s.c.Name] = s.c\n\treturn s.w.r.Storer.SetConfig(cfg)\n}\n\n// Status returns the status of the submodule.\nfunc (s *Submodule) Status() (*SubmoduleStatus, error) {\n\tidx, err := s.w.r.Storer.Index()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn s.status(idx)\n}\n\nfunc (s *Submodule) status(idx *index.Index) (*SubmoduleStatus, error) {\n\tstatus := &SubmoduleStatus{\n\t\tPath: s.c.Path,\n\t}\n\n\te, err := idx.Entry(s.c.Path)\n\tif err != nil && err != index.ErrEntryNotFound {\n\t\treturn nil, err\n\t}\n\n\tif e != nil {\n\t\tstatus.Expected = e.Hash\n\t}\n\n\tif !s.initialized {\n\t\treturn status, nil\n\t}\n\n\tr, err := s.Repository()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\thead, err := r.Head()\n\tif err == nil {\n\t\tstatus.Current = head.Hash()\n\t}\n\n\tif err != nil && err == plumbing.ErrReferenceNotFound {\n\t\terr = nil\n\t}\n\n\treturn status, err\n}\n\n// Repository returns the Repository represented by this submodule\nfunc (s *Submodule) Repository() (*Repository, error) {\n\tif !s.initialized {\n\t\treturn nil, ErrSubmoduleNotInitialized\n\t}\n\n\tstorer, err := s.w.r.Storer.Module(s.c.Name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t_, err = storer.Reference(plumbing.HEAD)\n\tif err != nil && err != plumbing.ErrReferenceNotFound {\n\t\treturn nil, err\n\t}\n\n\tvar exists bool\n\tif err == nil {\n\t\texists = true\n\t}\n\n\tvar worktree billy.Filesystem\n\tif worktree, err = s.w.Filesystem.Chroot(s.c.Path); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif exists {\n\t\treturn Open(storer, worktree)\n\t}\n\n\tr, err := Init(storer, worktree)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmoduleEndpoint, err := transport.NewEndpoint(s.c.URL)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif !path.IsAbs(moduleEndpoint.Path) && moduleEndpoint.Protocol == \"file\" {\n\t\tremotes, err := s.w.r.Remotes()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\trootEndpoint, err := transport.NewEndpoint(remotes[0].c.URLs[0])\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\trootEndpoint.Path = path.Join(rootEndpoint.Path, moduleEndpoint.Path)\n\t\t*moduleEndpoint = *rootEndpoint\n\t}\n\n\t_, err = r.CreateRemote(&config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{moduleEndpoint.String()},\n\t})\n\n\treturn r, err\n}\n\n// Update the registered submodule to match what the superproject expects, the\n// submodule should be initialized first calling the Init method or setting in\n// the options SubmoduleUpdateOptions.Init equals true\nfunc (s *Submodule) Update(o *SubmoduleUpdateOptions) error {\n\treturn s.UpdateContext(context.Background(), o)\n}\n\n// UpdateContext the registered submodule to match what the superproject\n// expects, the submodule should be initialized first calling the Init method or\n// setting in the options SubmoduleUpdateOptions.Init equals true.\n//\n// The provided Context must be non-nil. If the context expires before the\n// operation is complete, an error is returned. The context only affects the\n// transport operations.\nfunc (s *Submodule) UpdateContext(ctx context.Context, o *SubmoduleUpdateOptions) error {\n\treturn s.update(ctx, o, plumbing.ZeroHash)\n}\n\nfunc (s *Submodule) update(ctx context.Context, o *SubmoduleUpdateOptions, forceHash plumbing.Hash) error {\n\tif !s.initialized && !o.Init {\n\t\treturn ErrSubmoduleNotInitialized\n\t}\n\n\tif !s.initialized && o.Init {\n\t\tif err := s.Init(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tidx, err := s.w.r.Storer.Index()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\thash := forceHash\n\tif hash.IsZero() {\n\t\te, err := idx.Entry(s.c.Path)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\thash = e.Hash\n\t}\n\n\tr, err := s.Repository()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := s.fetchAndCheckout(ctx, r, o, hash); err != nil {\n\t\treturn err\n\t}\n\n\treturn s.doRecursiveUpdate(ctx, r, o)\n}\n\nfunc (s *Submodule) doRecursiveUpdate(ctx context.Context, r *Repository, o *SubmoduleUpdateOptions) error {\n\tif o.RecurseSubmodules == NoRecurseSubmodules {\n\t\treturn nil\n\t}\n\n\tw, err := r.Worktree()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tl, err := w.Submodules()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tnew := &SubmoduleUpdateOptions{}\n\t*new = *o\n\n\tnew.RecurseSubmodules--\n\treturn l.UpdateContext(ctx, new)\n}\n\nfunc (s *Submodule) fetchAndCheckout(\n\tctx context.Context, r *Repository, o *SubmoduleUpdateOptions, hash plumbing.Hash,\n) error {\n\tif !o.NoFetch {\n\t\terr := r.FetchContext(ctx, &FetchOptions{Auth: o.Auth, Depth: o.Depth})\n\t\tif err != nil && err != NoErrAlreadyUpToDate {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tw, err := r.Worktree()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Handle a case when submodule refers to an orphaned commit that's still reachable\n\t// through Git server using a special protocol capability[1].\n\t//\n\t// [1]: https://git-scm.com/docs/protocol-capabilities#_allow_reachable_sha1_in_want\n\tif !o.NoFetch {\n\t\tif _, err := w.r.Object(plumbing.AnyObject, hash); err != nil {\n\t\t\trefSpec := config.RefSpec(\"+\" + hash.String() + \":\" + hash.String())\n\n\t\t\terr := r.FetchContext(ctx, &FetchOptions{\n\t\t\t\tAuth:     o.Auth,\n\t\t\t\tRefSpecs: []config.RefSpec{refSpec},\n\t\t\t\tDepth:    o.Depth,\n\t\t\t})\n\t\t\tif err != nil && err != NoErrAlreadyUpToDate && err != ErrExactSHA1NotSupported {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\tif err := w.Checkout(&CheckoutOptions{Hash: hash}); err != nil {\n\t\treturn err\n\t}\n\n\thead := plumbing.NewHashReference(plumbing.HEAD, hash)\n\treturn r.Storer.SetReference(head)\n}\n\n// Submodules list of several submodules from the same repository.\ntype Submodules []*Submodule\n\n// Init initializes the submodules in this list.\nfunc (s Submodules) Init() error {\n\tfor _, sub := range s {\n\t\tif err := sub.Init(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// Update updates all the submodules in this list.\nfunc (s Submodules) Update(o *SubmoduleUpdateOptions) error {\n\treturn s.UpdateContext(context.Background(), o)\n}\n\n// UpdateContext updates all the submodules in this list.\n//\n// The provided Context must be non-nil. If the context expires before the\n// operation is complete, an error is returned. The context only affects the\n// transport operations.\nfunc (s Submodules) UpdateContext(ctx context.Context, o *SubmoduleUpdateOptions) error {\n\tfor _, sub := range s {\n\t\tif err := sub.UpdateContext(ctx, o); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// Status returns the status of the submodules.\nfunc (s Submodules) Status() (SubmodulesStatus, error) {\n\tvar list SubmodulesStatus\n\n\tvar r *Repository\n\tfor _, sub := range s {\n\t\tif r == nil {\n\t\t\tr = sub.w.r\n\t\t}\n\n\t\tidx, err := r.Storer.Index()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tstatus, err := sub.status(idx)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tlist = append(list, status)\n\t}\n\n\treturn list, nil\n}\n\n// SubmodulesStatus contains the status for all submodiles in the worktree\ntype SubmodulesStatus []*SubmoduleStatus\n\n// String is equivalent to `git submodule status`\nfunc (s SubmodulesStatus) String() string {\n\tbuf := bytes.NewBuffer(nil)\n\tfor _, sub := range s {\n\t\tfmt.Fprintln(buf, sub)\n\t}\n\n\treturn buf.String()\n}\n\n// SubmoduleStatus contains the status for a submodule in the worktree\ntype SubmoduleStatus struct {\n\tPath     string\n\tCurrent  plumbing.Hash\n\tExpected plumbing.Hash\n\tBranch   plumbing.ReferenceName\n}\n\n// IsClean is the HEAD of the submodule is equals to the expected commit\nfunc (s *SubmoduleStatus) IsClean() bool {\n\treturn s.Current == s.Expected\n}\n\n// String is equivalent to `git submodule status <submodule>`\n//\n// This will print the SHA-1 of the currently checked out commit for a\n// submodule, along with the submodule path and the output of git describe fo\n// the SHA-1. Each SHA-1 will be prefixed with - if the submodule is not\n// initialized, + if the currently checked out submodule commit does not match\n// the SHA-1 found in the index of the containing repository.\nfunc (s *SubmoduleStatus) String() string {\n\tvar extra string\n\tvar status = ' '\n\n\tif s.Current.IsZero() {\n\t\tstatus = '-'\n\t} else if !s.IsClean() {\n\t\tstatus = '+'\n\t}\n\n\tif len(s.Branch) != 0 {\n\t\textra = string(s.Branch[5:])\n\t} else if !s.Current.IsZero() {\n\t\textra = s.Current.String()[:7]\n\t}\n\n\tif extra != \"\" {\n\t\textra = fmt.Sprintf(\" (%s)\", extra)\n\t}\n\n\treturn fmt.Sprintf(\"%c%s %s%s\", status, s.Expected, s.Path, extra)\n}\n"
        },
        {
          "name": "submodule_test.go",
          "type": "blob",
          "size": 5.8359375,
          "content": "package git\n\nimport (\n\t\"context\"\n\t\"path/filepath\"\n\t\"testing\"\n\n\t\"github.com/go-git/go-billy/v5/memfs\"\n\t\"github.com/go-git/go-git/v5/config\"\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/storage/memory\"\n\n\tfixtures \"github.com/go-git/go-git-fixtures/v4\"\n\t. \"gopkg.in/check.v1\"\n)\n\ntype SubmoduleSuite struct {\n\tBaseSuite\n\tWorktree *Worktree\n}\n\nvar _ = Suite(&SubmoduleSuite{})\n\nfunc (s *SubmoduleSuite) SetUpTest(c *C) {\n\tpath := fixtures.ByTag(\"submodule\").One().Worktree().Root()\n\n\tdir := c.MkDir()\n\n\tr, err := PlainClone(filepath.Join(dir, \"worktree\"), false, &CloneOptions{\n\t\tURL: path,\n\t})\n\n\tc.Assert(err, IsNil)\n\n\ts.Repository = r\n\ts.Worktree, err = r.Worktree()\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *SubmoduleSuite) TestInit(c *C) {\n\tsm, err := s.Worktree.Submodule(\"basic\")\n\tc.Assert(err, IsNil)\n\n\tc.Assert(sm.initialized, Equals, false)\n\terr = sm.Init()\n\tc.Assert(err, IsNil)\n\n\tc.Assert(sm.initialized, Equals, true)\n\n\tcfg, err := s.Repository.Config()\n\tc.Assert(err, IsNil)\n\n\tc.Assert(cfg.Submodules, HasLen, 1)\n\tc.Assert(cfg.Submodules[\"basic\"], NotNil)\n\n\tstatus, err := sm.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, false)\n}\n\nfunc (s *SubmoduleSuite) TestUpdate(c *C) {\n\tif testing.Short() {\n\t\tc.Skip(\"skipping test in short mode.\")\n\t}\n\n\tsm, err := s.Worktree.Submodule(\"basic\")\n\tc.Assert(err, IsNil)\n\n\terr = sm.Update(&SubmoduleUpdateOptions{\n\t\tInit: true,\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tr, err := sm.Repository()\n\tc.Assert(err, IsNil)\n\n\tref, err := r.Reference(plumbing.HEAD, true)\n\tc.Assert(err, IsNil)\n\tc.Assert(ref.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\tstatus, err := sm.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *SubmoduleSuite) TestRepositoryWithoutInit(c *C) {\n\tsm, err := s.Worktree.Submodule(\"basic\")\n\tc.Assert(err, IsNil)\n\n\tr, err := sm.Repository()\n\tc.Assert(err, Equals, ErrSubmoduleNotInitialized)\n\tc.Assert(r, IsNil)\n}\n\nfunc (s *SubmoduleSuite) TestUpdateWithoutInit(c *C) {\n\tsm, err := s.Worktree.Submodule(\"basic\")\n\tc.Assert(err, IsNil)\n\n\terr = sm.Update(&SubmoduleUpdateOptions{})\n\tc.Assert(err, Equals, ErrSubmoduleNotInitialized)\n}\n\nfunc (s *SubmoduleSuite) TestUpdateWithNotFetch(c *C) {\n\tsm, err := s.Worktree.Submodule(\"basic\")\n\tc.Assert(err, IsNil)\n\n\terr = sm.Update(&SubmoduleUpdateOptions{\n\t\tInit:    true,\n\t\tNoFetch: true,\n\t})\n\n\t// Since we are not fetching, the object is not there\n\tc.Assert(err, Equals, plumbing.ErrObjectNotFound)\n}\n\nfunc (s *SubmoduleSuite) TestUpdateWithRecursion(c *C) {\n\tif testing.Short() {\n\t\tc.Skip(\"skipping test in short mode.\")\n\t}\n\n\tsm, err := s.Worktree.Submodule(\"itself\")\n\tc.Assert(err, IsNil)\n\n\terr = sm.Update(&SubmoduleUpdateOptions{\n\t\tInit:              true,\n\t\tRecurseSubmodules: 2,\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tfs := s.Worktree.Filesystem\n\t_, err = fs.Stat(fs.Join(\"itself\", \"basic\", \"LICENSE\"))\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *SubmoduleSuite) TestUpdateWithInitAndUpdate(c *C) {\n\tif testing.Short() {\n\t\tc.Skip(\"skipping test in short mode.\")\n\t}\n\n\tsm, err := s.Worktree.Submodule(\"basic\")\n\tc.Assert(err, IsNil)\n\n\terr = sm.Update(&SubmoduleUpdateOptions{\n\t\tInit: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tidx, err := s.Repository.Storer.Index()\n\tc.Assert(err, IsNil)\n\n\tfor i, e := range idx.Entries {\n\t\tif e.Name == \"basic\" {\n\t\t\te.Hash = plumbing.NewHash(\"b029517f6300c2da0f4b651b8642506cd6aaf45d\")\n\t\t}\n\n\t\tidx.Entries[i] = e\n\t}\n\n\terr = s.Repository.Storer.SetIndex(idx)\n\tc.Assert(err, IsNil)\n\n\terr = sm.Update(&SubmoduleUpdateOptions{})\n\tc.Assert(err, IsNil)\n\n\tr, err := sm.Repository()\n\tc.Assert(err, IsNil)\n\n\tref, err := r.Reference(plumbing.HEAD, true)\n\tc.Assert(err, IsNil)\n\tc.Assert(ref.Hash().String(), Equals, \"b029517f6300c2da0f4b651b8642506cd6aaf45d\")\n\n}\n\nfunc (s *SubmoduleSuite) TestSubmodulesInit(c *C) {\n\tsm, err := s.Worktree.Submodules()\n\tc.Assert(err, IsNil)\n\n\terr = sm.Init()\n\tc.Assert(err, IsNil)\n\n\tsm, err = s.Worktree.Submodules()\n\tc.Assert(err, IsNil)\n\n\tfor _, m := range sm {\n\t\tc.Assert(m.initialized, Equals, true)\n\t}\n}\n\nfunc (s *SubmoduleSuite) TestGitSubmodulesSymlink(c *C) {\n\tf, err := s.Worktree.Filesystem.Create(\"badfile\")\n\tc.Assert(err, IsNil)\n\tdefer func() { _ = f.Close() }()\n\n\terr = s.Worktree.Filesystem.Remove(gitmodulesFile)\n\tc.Assert(err, IsNil)\n\n\terr = s.Worktree.Filesystem.Symlink(\"badfile\", gitmodulesFile)\n\tc.Assert(err, IsNil)\n\n\t_, err = s.Worktree.Submodules()\n\tc.Assert(err, Equals, ErrGitModulesSymlink)\n}\n\nfunc (s *SubmoduleSuite) TestSubmodulesStatus(c *C) {\n\tsm, err := s.Worktree.Submodules()\n\tc.Assert(err, IsNil)\n\n\tstatus, err := sm.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 2)\n}\n\nfunc (s *SubmoduleSuite) TestSubmodulesUpdateContext(c *C) {\n\tif testing.Short() {\n\t\tc.Skip(\"skipping test in short mode.\")\n\t}\n\n\tsm, err := s.Worktree.Submodules()\n\tc.Assert(err, IsNil)\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\n\terr = sm.UpdateContext(ctx, &SubmoduleUpdateOptions{Init: true})\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *SubmoduleSuite) TestSubmodulesFetchDepth(c *C) {\n\tif testing.Short() {\n\t\tc.Skip(\"skipping test in short mode.\")\n\t}\n\n\tsm, err := s.Worktree.Submodule(\"basic\")\n\tc.Assert(err, IsNil)\n\n\terr = sm.Update(&SubmoduleUpdateOptions{\n\t\tInit:  true,\n\t\tDepth: 1,\n\t})\n\tc.Assert(err, IsNil)\n\n\tr, err := sm.Repository()\n\tc.Assert(err, IsNil)\n\n\tlr, err := r.Log(&LogOptions{})\n\tc.Assert(err, IsNil)\n\n\tcommitCount := 0\n\tfor _, err := lr.Next(); err == nil; _, err = lr.Next() {\n\t\tcommitCount++\n\t}\n\tc.Assert(err, IsNil)\n\n\tc.Assert(commitCount, Equals, 1)\n}\n\nfunc (s *SubmoduleSuite) TestSubmoduleParseScp(c *C) {\n\trepo := &Repository{\n\t\tStorer: memory.NewStorage(),\n\t\twt:     memfs.New(),\n\t}\n\tworktree := &Worktree{\n\t\tFilesystem: memfs.New(),\n\t\tr:          repo,\n\t}\n\tsubmodule := &Submodule{\n\t\tinitialized: true,\n\t\tc:           nil,\n\t\tw:           worktree,\n\t}\n\n\tsubmodule.c = &config.Submodule{\n\t\tURL: \"git@github.com:username/submodule_repo\",\n\t}\n\n\t_, err := submodule.Repository()\n\tc.Assert(err, IsNil)\n}\n"
        },
        {
          "name": "utils",
          "type": "tree",
          "content": null
        },
        {
          "name": "worktree.go",
          "type": "blob",
          "size": 26.6181640625,
          "content": "package git\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"strings\"\n\n\t\"github.com/go-git/go-billy/v5\"\n\t\"github.com/go-git/go-billy/v5/util\"\n\t\"github.com/go-git/go-git/v5/config\"\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/plumbing/filemode\"\n\t\"github.com/go-git/go-git/v5/plumbing/format/gitignore\"\n\t\"github.com/go-git/go-git/v5/plumbing/format/index\"\n\t\"github.com/go-git/go-git/v5/plumbing/object\"\n\t\"github.com/go-git/go-git/v5/plumbing/storer\"\n\t\"github.com/go-git/go-git/v5/utils/ioutil\"\n\t\"github.com/go-git/go-git/v5/utils/merkletrie\"\n\t\"github.com/go-git/go-git/v5/utils/sync\"\n)\n\nvar (\n\tErrWorktreeNotClean                = errors.New(\"worktree is not clean\")\n\tErrSubmoduleNotFound               = errors.New(\"submodule not found\")\n\tErrUnstagedChanges                 = errors.New(\"worktree contains unstaged changes\")\n\tErrGitModulesSymlink               = errors.New(gitmodulesFile + \" is a symlink\")\n\tErrNonFastForwardUpdate            = errors.New(\"non-fast-forward update\")\n\tErrRestoreWorktreeOnlyNotSupported = errors.New(\"worktree only is not supported\")\n)\n\n// Worktree represents a git worktree.\ntype Worktree struct {\n\t// Filesystem underlying filesystem.\n\tFilesystem billy.Filesystem\n\t// External excludes not found in the repository .gitignore\n\tExcludes []gitignore.Pattern\n\n\tr *Repository\n}\n\n// Pull incorporates changes from a remote repository into the current branch.\n// Returns nil if the operation is successful, NoErrAlreadyUpToDate if there are\n// no changes to be fetched, or an error.\n//\n// Pull only supports merges where the can be resolved as a fast-forward.\nfunc (w *Worktree) Pull(o *PullOptions) error {\n\treturn w.PullContext(context.Background(), o)\n}\n\n// PullContext incorporates changes from a remote repository into the current\n// branch. Returns nil if the operation is successful, NoErrAlreadyUpToDate if\n// there are no changes to be fetched, or an error.\n//\n// Pull only supports merges where the can be resolved as a fast-forward.\n//\n// The provided Context must be non-nil. If the context expires before the\n// operation is complete, an error is returned. The context only affects the\n// transport operations.\nfunc (w *Worktree) PullContext(ctx context.Context, o *PullOptions) error {\n\tif err := o.Validate(); err != nil {\n\t\treturn err\n\t}\n\n\tremote, err := w.r.Remote(o.RemoteName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfetchHead, err := remote.fetch(ctx, &FetchOptions{\n\t\tRemoteName:      o.RemoteName,\n\t\tRemoteURL:       o.RemoteURL,\n\t\tDepth:           o.Depth,\n\t\tAuth:            o.Auth,\n\t\tProgress:        o.Progress,\n\t\tForce:           o.Force,\n\t\tInsecureSkipTLS: o.InsecureSkipTLS,\n\t\tCABundle:        o.CABundle,\n\t\tProxyOptions:    o.ProxyOptions,\n\t})\n\n\tupdated := true\n\tif err == NoErrAlreadyUpToDate {\n\t\tupdated = false\n\t} else if err != nil {\n\t\treturn err\n\t}\n\n\tref, err := storer.ResolveReference(fetchHead, o.ReferenceName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\thead, err := w.r.Head()\n\tif err == nil {\n\t\t// if we don't have a shallows list, just ignore it\n\t\tshallowList, _ := w.r.Storer.Shallow()\n\n\t\tvar earliestShallow *plumbing.Hash\n\t\tif len(shallowList) > 0 {\n\t\t\tearliestShallow = &shallowList[0]\n\t\t}\n\n\t\theadAheadOfRef, err := isFastForward(w.r.Storer, ref.Hash(), head.Hash(), earliestShallow)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif !updated && headAheadOfRef {\n\t\t\treturn NoErrAlreadyUpToDate\n\t\t}\n\n\t\tff, err := isFastForward(w.r.Storer, head.Hash(), ref.Hash(), earliestShallow)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif !ff {\n\t\t\treturn ErrNonFastForwardUpdate\n\t\t}\n\t}\n\n\tif err != nil && err != plumbing.ErrReferenceNotFound {\n\t\treturn err\n\t}\n\n\tif err := w.updateHEAD(ref.Hash()); err != nil {\n\t\treturn err\n\t}\n\n\tif err := w.Reset(&ResetOptions{\n\t\tMode:   MergeReset,\n\t\tCommit: ref.Hash(),\n\t}); err != nil {\n\t\treturn err\n\t}\n\n\tif o.RecurseSubmodules != NoRecurseSubmodules {\n\t\treturn w.updateSubmodules(ctx, &SubmoduleUpdateOptions{\n\t\t\tRecurseSubmodules: o.RecurseSubmodules,\n\t\t\tAuth:              o.Auth,\n\t\t})\n\t}\n\n\treturn nil\n}\n\nfunc (w *Worktree) updateSubmodules(ctx context.Context, o *SubmoduleUpdateOptions) error {\n\ts, err := w.Submodules()\n\tif err != nil {\n\t\treturn err\n\t}\n\to.Init = true\n\treturn s.UpdateContext(ctx, o)\n}\n\n// Checkout switch branches or restore working tree files.\nfunc (w *Worktree) Checkout(opts *CheckoutOptions) error {\n\tif err := opts.Validate(); err != nil {\n\t\treturn err\n\t}\n\n\tif opts.Create {\n\t\tif err := w.createBranch(opts); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tc, err := w.getCommitFromCheckoutOptions(opts)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tro := &ResetOptions{Commit: c, Mode: MergeReset}\n\tif opts.Force {\n\t\tro.Mode = HardReset\n\t} else if opts.Keep {\n\t\tro.Mode = SoftReset\n\t}\n\n\tif !opts.Hash.IsZero() && !opts.Create {\n\t\terr = w.setHEADToCommit(opts.Hash)\n\t} else {\n\t\terr = w.setHEADToBranch(opts.Branch, c)\n\t}\n\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif len(opts.SparseCheckoutDirectories) > 0 {\n\t\treturn w.ResetSparsely(ro, opts.SparseCheckoutDirectories)\n\t}\n\n\treturn w.Reset(ro)\n}\n\nfunc (w *Worktree) createBranch(opts *CheckoutOptions) error {\n\tif err := opts.Branch.Validate(); err != nil {\n\t\treturn err\n\t}\n\n\t_, err := w.r.Storer.Reference(opts.Branch)\n\tif err == nil {\n\t\treturn fmt.Errorf(\"a branch named %q already exists\", opts.Branch)\n\t}\n\n\tif err != plumbing.ErrReferenceNotFound {\n\t\treturn err\n\t}\n\n\tif opts.Hash.IsZero() {\n\t\tref, err := w.r.Head()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\topts.Hash = ref.Hash()\n\t}\n\n\treturn w.r.Storer.SetReference(\n\t\tplumbing.NewHashReference(opts.Branch, opts.Hash),\n\t)\n}\n\nfunc (w *Worktree) getCommitFromCheckoutOptions(opts *CheckoutOptions) (plumbing.Hash, error) {\n\thash := opts.Hash\n\tif hash.IsZero() {\n\t\tb, err := w.r.Reference(opts.Branch, true)\n\t\tif err != nil {\n\t\t\treturn plumbing.ZeroHash, err\n\t\t}\n\n\t\thash = b.Hash()\n\t}\n\n\to, err := w.r.Object(plumbing.AnyObject, hash)\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\tswitch o := o.(type) {\n\tcase *object.Tag:\n\t\tif o.TargetType != plumbing.CommitObject {\n\t\t\treturn plumbing.ZeroHash, fmt.Errorf(\"%w: tag target %q\", object.ErrUnsupportedObject, o.TargetType)\n\t\t}\n\n\t\treturn o.Target, nil\n\tcase *object.Commit:\n\t\treturn o.Hash, nil\n\t}\n\n\treturn plumbing.ZeroHash, fmt.Errorf(\"%w: %q\", object.ErrUnsupportedObject, o.Type())\n}\n\nfunc (w *Worktree) setHEADToCommit(commit plumbing.Hash) error {\n\thead := plumbing.NewHashReference(plumbing.HEAD, commit)\n\treturn w.r.Storer.SetReference(head)\n}\n\nfunc (w *Worktree) setHEADToBranch(branch plumbing.ReferenceName, commit plumbing.Hash) error {\n\ttarget, err := w.r.Storer.Reference(branch)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvar head *plumbing.Reference\n\tif target.Name().IsBranch() {\n\t\thead = plumbing.NewSymbolicReference(plumbing.HEAD, target.Name())\n\t} else {\n\t\thead = plumbing.NewHashReference(plumbing.HEAD, commit)\n\t}\n\n\treturn w.r.Storer.SetReference(head)\n}\n\nfunc (w *Worktree) ResetSparsely(opts *ResetOptions, dirs []string) error {\n\tif err := opts.Validate(w.r); err != nil {\n\t\treturn err\n\t}\n\n\tif opts.Mode == MergeReset {\n\t\tunstaged, err := w.containsUnstagedChanges()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif unstaged {\n\t\t\treturn ErrUnstagedChanges\n\t\t}\n\t}\n\n\tif err := w.setHEADCommit(opts.Commit); err != nil {\n\t\treturn err\n\t}\n\n\tif opts.Mode == SoftReset {\n\t\treturn nil\n\t}\n\n\tt, err := w.r.getTreeFromCommitHash(opts.Commit)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif opts.Mode == MixedReset || opts.Mode == MergeReset || opts.Mode == HardReset {\n\t\tif err := w.resetIndex(t, dirs, opts.Files); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif opts.Mode == MergeReset || opts.Mode == HardReset {\n\t\tif err := w.resetWorktree(t, opts.Files); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// Restore restores specified files in the working tree or stage with contents from\n// a restore source. If a path is tracked but does not exist in the restore,\n// source, it will be removed to match the source.\n//\n// If Staged and Worktree are true, then the restore source will be the index.\n// If only Staged is true, then the restore source will be HEAD.\n// If only Worktree is true or neither Staged nor Worktree are true, will\n// result in ErrRestoreWorktreeOnlyNotSupported because restoring the working\n// tree while leaving the stage untouched is not currently supported.\n//\n// Restore with no files specified will return ErrNoRestorePaths.\nfunc (w *Worktree) Restore(o *RestoreOptions) error {\n\tif err := o.Validate(); err != nil {\n\t\treturn err\n\t}\n\n\tif o.Staged {\n\t\topts := &ResetOptions{\n\t\t\tFiles: o.Files,\n\t\t}\n\n\t\tif o.Worktree {\n\t\t\t// If we are doing both Worktree and Staging then it is a hard reset\n\t\t\topts.Mode = HardReset\n\t\t} else {\n\t\t\t// If we are doing just staging then it is a mixed reset\n\t\t\topts.Mode = MixedReset\n\t\t}\n\n\t\treturn w.Reset(opts)\n\t}\n\n\treturn ErrRestoreWorktreeOnlyNotSupported\n}\n\n// Reset the worktree to a specified state.\nfunc (w *Worktree) Reset(opts *ResetOptions) error {\n\treturn w.ResetSparsely(opts, nil)\n}\n\nfunc (w *Worktree) resetIndex(t *object.Tree, dirs []string, files []string) error {\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tb := newIndexBuilder(idx)\n\n\tchanges, err := w.diffTreeWithStaging(t, true)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, ch := range changes {\n\t\ta, err := ch.Action()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tvar name string\n\t\tvar e *object.TreeEntry\n\n\t\tswitch a {\n\t\tcase merkletrie.Modify, merkletrie.Insert:\n\t\t\tname = ch.To.String()\n\t\t\te, err = t.FindEntry(name)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\tcase merkletrie.Delete:\n\t\t\tname = ch.From.String()\n\t\t}\n\n\t\tif len(files) > 0 {\n\t\t\tcontains := inFiles(files, name)\n\t\t\tif !contains {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tb.Remove(name)\n\t\tif e == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tb.Add(&index.Entry{\n\t\t\tName: name,\n\t\t\tHash: e.Hash,\n\t\t\tMode: e.Mode,\n\t\t})\n\n\t}\n\n\tb.Write(idx)\n\n\tif len(dirs) > 0 {\n\t\tidx.SkipUnless(dirs)\n\t}\n\n\treturn w.r.Storer.SetIndex(idx)\n}\n\nfunc inFiles(files []string, v string) bool {\n\tfor _, s := range files {\n\t\tif s == v {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}\n\nfunc (w *Worktree) resetWorktree(t *object.Tree, files []string) error {\n\tchanges, err := w.diffStagingWithWorktree(true, false)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn err\n\t}\n\tb := newIndexBuilder(idx)\n\n\tfor _, ch := range changes {\n\t\tif err := w.validChange(ch); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif len(files) > 0 {\n\t\t\tfile := \"\"\n\t\t\tif ch.From != nil {\n\t\t\t\tfile = ch.From.String()\n\t\t\t} else if ch.To != nil {\n\t\t\t\tfile = ch.To.String()\n\t\t\t}\n\n\t\t\tif file == \"\" {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tcontains := inFiles(files, file)\n\t\t\tif !contains {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tif err := w.checkoutChange(ch, t, b); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tb.Write(idx)\n\treturn w.r.Storer.SetIndex(idx)\n}\n\n// worktreeDeny is a list of paths that are not allowed\n// to be used when resetting the worktree.\nvar worktreeDeny = map[string]struct{}{\n\t// .git\n\tGitDirName: {},\n\n\t// For other historical reasons, file names that do not conform to the 8.3\n\t// format (up to eight characters for the basename, three for the file\n\t// extension, certain characters not allowed such as `+`, etc) are associated\n\t// with a so-called \"short name\", at least on the `C:` drive by default.\n\t// Which means that `git~1/` is a valid way to refer to `.git/`.\n\t\"git~1\": {},\n}\n\n// validPath checks whether paths are valid.\n// The rules around invalid paths could differ from upstream based on how\n// filesystems are managed within go-git, but they are largely the same.\n//\n// For upstream rules:\n// https://github.com/git/git/blob/564d0252ca632e0264ed670534a51d18a689ef5d/read-cache.c#L946\n// https://github.com/git/git/blob/564d0252ca632e0264ed670534a51d18a689ef5d/path.c#L1383\nfunc validPath(paths ...string) error {\n\tfor _, p := range paths {\n\t\tparts := strings.FieldsFunc(p, func(r rune) bool { return (r == '\\\\' || r == '/') })\n\t\tif len(parts) == 0 {\n\t\t\treturn fmt.Errorf(\"invalid path: %q\", p)\n\t\t}\n\n\t\tif _, denied := worktreeDeny[strings.ToLower(parts[0])]; denied {\n\t\t\treturn fmt.Errorf(\"invalid path prefix: %q\", p)\n\t\t}\n\n\t\tif runtime.GOOS == \"windows\" {\n\t\t\t// Volume names are not supported, in both formats: \\\\ and <DRIVE_LETTER>:.\n\t\t\tif vol := filepath.VolumeName(p); vol != \"\" {\n\t\t\t\treturn fmt.Errorf(\"invalid path: %q\", p)\n\t\t\t}\n\n\t\t\tif !windowsValidPath(parts[0]) {\n\t\t\t\treturn fmt.Errorf(\"invalid path: %q\", p)\n\t\t\t}\n\t\t}\n\n\t\tfor _, part := range parts {\n\t\t\tif part == \"..\" {\n\t\t\t\treturn fmt.Errorf(\"invalid path %q: cannot use '..'\", p)\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}\n\n// windowsPathReplacer defines the chars that need to be replaced\n// as part of windowsValidPath.\nvar windowsPathReplacer *strings.Replacer\n\nfunc init() {\n\twindowsPathReplacer = strings.NewReplacer(\" \", \"\", \".\", \"\")\n}\n\nfunc windowsValidPath(part string) bool {\n\tif len(part) > 3 && strings.EqualFold(part[:4], GitDirName) {\n\t\t// For historical reasons, file names that end in spaces or periods are\n\t\t// automatically trimmed. Therefore, `.git . . ./` is a valid way to refer\n\t\t// to `.git/`.\n\t\tif windowsPathReplacer.Replace(part[4:]) == \"\" {\n\t\t\treturn false\n\t\t}\n\n\t\t// For yet other historical reasons, NTFS supports so-called \"Alternate Data\n\t\t// Streams\", i.e. metadata associated with a given file, referred to via\n\t\t// `<filename>:<stream-name>:<stream-type>`. There exists a default stream\n\t\t// type for directories, allowing `.git/` to be accessed via\n\t\t// `.git::$INDEX_ALLOCATION/`.\n\t\t//\n\t\t// For performance reasons, _all_ Alternate Data Streams of `.git/` are\n\t\t// forbidden, not just `::$INDEX_ALLOCATION`.\n\t\tif len(part) > 4 && part[4:5] == \":\" {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\nfunc (w *Worktree) validChange(ch merkletrie.Change) error {\n\taction, err := ch.Action()\n\tif err != nil {\n\t\treturn nil\n\t}\n\n\tswitch action {\n\tcase merkletrie.Delete:\n\t\treturn validPath(ch.From.String())\n\tcase merkletrie.Insert:\n\t\treturn validPath(ch.To.String())\n\tcase merkletrie.Modify:\n\t\treturn validPath(ch.From.String(), ch.To.String())\n\t}\n\n\treturn nil\n}\n\nfunc (w *Worktree) checkoutChange(ch merkletrie.Change, t *object.Tree, idx *indexBuilder) error {\n\ta, err := ch.Action()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvar e *object.TreeEntry\n\tvar name string\n\tvar isSubmodule bool\n\n\tswitch a {\n\tcase merkletrie.Modify, merkletrie.Insert:\n\t\tname = ch.To.String()\n\t\te, err = t.FindEntry(name)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tisSubmodule = e.Mode == filemode.Submodule\n\tcase merkletrie.Delete:\n\t\treturn rmFileAndDirsIfEmpty(w.Filesystem, ch.From.String())\n\t}\n\n\tif isSubmodule {\n\t\treturn w.checkoutChangeSubmodule(name, a, e, idx)\n\t}\n\n\treturn w.checkoutChangeRegularFile(name, a, t, e, idx)\n}\n\nfunc (w *Worktree) containsUnstagedChanges() (bool, error) {\n\tch, err := w.diffStagingWithWorktree(false, true)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tfor _, c := range ch {\n\t\ta, err := c.Action()\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\n\t\tif a == merkletrie.Insert {\n\t\t\tcontinue\n\t\t}\n\n\t\treturn true, nil\n\t}\n\n\treturn false, nil\n}\n\nfunc (w *Worktree) setHEADCommit(commit plumbing.Hash) error {\n\thead, err := w.r.Reference(plumbing.HEAD, false)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif head.Type() == plumbing.HashReference {\n\t\thead = plumbing.NewHashReference(plumbing.HEAD, commit)\n\t\treturn w.r.Storer.SetReference(head)\n\t}\n\n\tbranch, err := w.r.Reference(head.Target(), false)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif !branch.Name().IsBranch() {\n\t\treturn fmt.Errorf(\"invalid HEAD target should be a branch, found %s\", branch.Type())\n\t}\n\n\tbranch = plumbing.NewHashReference(branch.Name(), commit)\n\treturn w.r.Storer.SetReference(branch)\n}\n\nfunc (w *Worktree) checkoutChangeSubmodule(name string,\n\ta merkletrie.Action,\n\te *object.TreeEntry,\n\tidx *indexBuilder,\n) error {\n\tswitch a {\n\tcase merkletrie.Modify:\n\t\tsub, err := w.Submodule(name)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif !sub.initialized {\n\t\t\treturn nil\n\t\t}\n\n\t\treturn w.addIndexFromTreeEntry(name, e, idx)\n\tcase merkletrie.Insert:\n\t\tmode, err := e.Mode.ToOSFileMode()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif err := w.Filesystem.MkdirAll(name, mode); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn w.addIndexFromTreeEntry(name, e, idx)\n\t}\n\n\treturn nil\n}\n\nfunc (w *Worktree) checkoutChangeRegularFile(name string,\n\ta merkletrie.Action,\n\tt *object.Tree,\n\te *object.TreeEntry,\n\tidx *indexBuilder,\n) error {\n\tswitch a {\n\tcase merkletrie.Modify:\n\t\tidx.Remove(name)\n\n\t\t// to apply perm changes the file is deleted, billy doesn't implement\n\t\t// chmod\n\t\tif err := w.Filesystem.Remove(name); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tfallthrough\n\tcase merkletrie.Insert:\n\t\tf, err := t.File(name)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif err := w.checkoutFile(f); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn w.addIndexFromFile(name, e.Hash, f.Mode, idx)\n\t}\n\n\treturn nil\n}\n\nfunc (w *Worktree) checkoutFile(f *object.File) (err error) {\n\tmode, err := f.Mode.ToOSFileMode()\n\tif err != nil {\n\t\treturn\n\t}\n\n\tif mode&os.ModeSymlink != 0 {\n\t\treturn w.checkoutFileSymlink(f)\n\t}\n\n\tfrom, err := f.Reader()\n\tif err != nil {\n\t\treturn\n\t}\n\n\tdefer ioutil.CheckClose(from, &err)\n\n\tto, err := w.Filesystem.OpenFile(f.Name, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, mode.Perm())\n\tif err != nil {\n\t\treturn\n\t}\n\n\tdefer ioutil.CheckClose(to, &err)\n\tbuf := sync.GetByteSlice()\n\t_, err = io.CopyBuffer(to, from, *buf)\n\tsync.PutByteSlice(buf)\n\treturn\n}\n\nfunc (w *Worktree) checkoutFileSymlink(f *object.File) (err error) {\n\t// https://github.com/git/git/commit/10ecfa76491e4923988337b2e2243b05376b40de\n\tif strings.EqualFold(f.Name, gitmodulesFile) {\n\t\treturn ErrGitModulesSymlink\n\t}\n\n\tfrom, err := f.Reader()\n\tif err != nil {\n\t\treturn\n\t}\n\n\tdefer ioutil.CheckClose(from, &err)\n\n\tbytes, err := io.ReadAll(from)\n\tif err != nil {\n\t\treturn\n\t}\n\n\terr = w.Filesystem.Symlink(string(bytes), f.Name)\n\n\t// On windows, this might fail.\n\t// Follow Git on Windows behavior by writing the link as it is.\n\tif err != nil && isSymlinkWindowsNonAdmin(err) {\n\t\tmode, _ := f.Mode.ToOSFileMode()\n\n\t\tto, err := w.Filesystem.OpenFile(f.Name, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, mode.Perm())\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tdefer ioutil.CheckClose(to, &err)\n\n\t\t_, err = to.Write(bytes)\n\t\treturn err\n\t}\n\treturn\n}\n\nfunc (w *Worktree) addIndexFromTreeEntry(name string, f *object.TreeEntry, idx *indexBuilder) error {\n\tidx.Remove(name)\n\tidx.Add(&index.Entry{\n\t\tHash: f.Hash,\n\t\tName: name,\n\t\tMode: filemode.Submodule,\n\t})\n\treturn nil\n}\n\nfunc (w *Worktree) addIndexFromFile(name string, h plumbing.Hash, mode filemode.FileMode, idx *indexBuilder) error {\n\tidx.Remove(name)\n\tfi, err := w.Filesystem.Lstat(name)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\te := &index.Entry{\n\t\tHash:       h,\n\t\tName:       name,\n\t\tMode:       mode,\n\t\tModifiedAt: fi.ModTime(),\n\t\tSize:       uint32(fi.Size()),\n\t}\n\n\t// if the FileInfo.Sys() comes from os the ctime, dev, inode, uid and gid\n\t// can be retrieved, otherwise this doesn't apply\n\tif fillSystemInfo != nil {\n\t\tfillSystemInfo(e, fi.Sys())\n\t}\n\tidx.Add(e)\n\treturn nil\n}\n\nfunc (r *Repository) getTreeFromCommitHash(commit plumbing.Hash) (*object.Tree, error) {\n\tc, err := r.CommitObject(commit)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn c.Tree()\n}\n\nvar fillSystemInfo func(e *index.Entry, sys interface{})\n\nconst gitmodulesFile = \".gitmodules\"\n\n// Submodule returns the submodule with the given name\nfunc (w *Worktree) Submodule(name string) (*Submodule, error) {\n\tl, err := w.Submodules()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, m := range l {\n\t\tif m.Config().Name == name {\n\t\t\treturn m, nil\n\t\t}\n\t}\n\n\treturn nil, ErrSubmoduleNotFound\n}\n\n// Submodules returns all the available submodules\nfunc (w *Worktree) Submodules() (Submodules, error) {\n\tl := make(Submodules, 0)\n\tm, err := w.readGitmodulesFile()\n\tif err != nil || m == nil {\n\t\treturn l, err\n\t}\n\n\tc, err := w.r.Config()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, s := range m.Submodules {\n\t\tl = append(l, w.newSubmodule(s, c.Submodules[s.Name]))\n\t}\n\n\treturn l, nil\n}\n\nfunc (w *Worktree) newSubmodule(fromModules, fromConfig *config.Submodule) *Submodule {\n\tm := &Submodule{w: w}\n\tm.initialized = fromConfig != nil\n\n\tif !m.initialized {\n\t\tm.c = fromModules\n\t\treturn m\n\t}\n\n\tm.c = fromConfig\n\tm.c.Path = fromModules.Path\n\treturn m\n}\n\nfunc (w *Worktree) isSymlink(path string) bool {\n\tif s, err := w.Filesystem.Lstat(path); err == nil {\n\t\treturn s.Mode()&os.ModeSymlink != 0\n\t}\n\treturn false\n}\n\nfunc (w *Worktree) readGitmodulesFile() (*config.Modules, error) {\n\tif w.isSymlink(gitmodulesFile) {\n\t\treturn nil, ErrGitModulesSymlink\n\t}\n\n\tf, err := w.Filesystem.Open(gitmodulesFile)\n\tif err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\treturn nil, nil\n\t\t}\n\n\t\treturn nil, err\n\t}\n\n\tdefer f.Close()\n\tinput, err := io.ReadAll(f)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tm := config.NewModules()\n\tif err := m.Unmarshal(input); err != nil {\n\t\treturn m, err\n\t}\n\n\treturn m, nil\n}\n\n// Clean the worktree by removing untracked files.\n// An empty dir could be removed - this is what  `git clean -f -d .` does.\nfunc (w *Worktree) Clean(opts *CleanOptions) error {\n\ts, err := w.Status()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\troot := \"\"\n\tfiles, err := w.Filesystem.ReadDir(root)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn w.doClean(s, opts, root, files)\n}\n\nfunc (w *Worktree) doClean(status Status, opts *CleanOptions, dir string, files []os.FileInfo) error {\n\tfor _, fi := range files {\n\t\tif fi.Name() == GitDirName {\n\t\t\tcontinue\n\t\t}\n\n\t\t// relative path under the root\n\t\tpath := filepath.Join(dir, fi.Name())\n\t\tif fi.IsDir() {\n\t\t\tif !opts.Dir {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tsubfiles, err := w.Filesystem.ReadDir(path)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\terr = w.doClean(status, opts, path, subfiles)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t} else {\n\t\t\tif status.IsUntracked(path) {\n\t\t\t\tif err := w.Filesystem.Remove(path); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif opts.Dir && dir != \"\" {\n\t\t_, err := removeDirIfEmpty(w.Filesystem, dir)\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\n// GrepResult is structure of a grep result.\ntype GrepResult struct {\n\t// FileName is the name of file which contains match.\n\tFileName string\n\t// LineNumber is the line number of a file at which a match was found.\n\tLineNumber int\n\t// Content is the content of the file at the matching line.\n\tContent string\n\t// TreeName is the name of the tree (reference name/commit hash) at\n\t// which the match was performed.\n\tTreeName string\n}\n\nfunc (gr GrepResult) String() string {\n\treturn fmt.Sprintf(\"%s:%s:%d:%s\", gr.TreeName, gr.FileName, gr.LineNumber, gr.Content)\n}\n\n// Grep performs grep on a repository.\nfunc (r *Repository) Grep(opts *GrepOptions) ([]GrepResult, error) {\n\tif err := opts.validate(r); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Obtain commit hash from options (CommitHash or ReferenceName).\n\tvar commitHash plumbing.Hash\n\t// treeName contains the value of TreeName in GrepResult.\n\tvar treeName string\n\n\tif opts.ReferenceName != \"\" {\n\t\tref, err := r.Reference(opts.ReferenceName, true)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tcommitHash = ref.Hash()\n\t\ttreeName = opts.ReferenceName.String()\n\t} else if !opts.CommitHash.IsZero() {\n\t\tcommitHash = opts.CommitHash\n\t\ttreeName = opts.CommitHash.String()\n\t}\n\n\t// Obtain a tree from the commit hash and get a tracked files iterator from\n\t// the tree.\n\ttree, err := r.getTreeFromCommitHash(commitHash)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfileiter := tree.Files()\n\n\treturn findMatchInFiles(fileiter, treeName, opts)\n}\n\n// Grep performs grep on a worktree.\nfunc (w *Worktree) Grep(opts *GrepOptions) ([]GrepResult, error) {\n\treturn w.r.Grep(opts)\n}\n\n// findMatchInFiles takes a FileIter, worktree name and GrepOptions, and\n// returns a slice of GrepResult containing the result of regex pattern matching\n// in content of all the files.\nfunc findMatchInFiles(fileiter *object.FileIter, treeName string, opts *GrepOptions) ([]GrepResult, error) {\n\tvar results []GrepResult\n\n\terr := fileiter.ForEach(func(file *object.File) error {\n\t\tvar fileInPathSpec bool\n\n\t\t// When no pathspecs are provided, search all the files.\n\t\tif len(opts.PathSpecs) == 0 {\n\t\t\tfileInPathSpec = true\n\t\t}\n\n\t\t// Check if the file name matches with the pathspec. Break out of the\n\t\t// loop once a match is found.\n\t\tfor _, pathSpec := range opts.PathSpecs {\n\t\t\tif pathSpec != nil && pathSpec.MatchString(file.Name) {\n\t\t\t\tfileInPathSpec = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\t// If the file does not match with any of the pathspec, skip it.\n\t\tif !fileInPathSpec {\n\t\t\treturn nil\n\t\t}\n\n\t\tgrepResults, err := findMatchInFile(file, treeName, opts)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tresults = append(results, grepResults...)\n\n\t\treturn nil\n\t})\n\n\treturn results, err\n}\n\n// findMatchInFile takes a single File, worktree name and GrepOptions,\n// and returns a slice of GrepResult containing the result of regex pattern\n// matching in the given file.\nfunc findMatchInFile(file *object.File, treeName string, opts *GrepOptions) ([]GrepResult, error) {\n\tvar grepResults []GrepResult\n\n\tcontent, err := file.Contents()\n\tif err != nil {\n\t\treturn grepResults, err\n\t}\n\n\t// Split the file content and parse line-by-line.\n\tcontentByLine := strings.Split(content, \"\\n\")\n\tfor lineNum, cnt := range contentByLine {\n\t\taddToResult := false\n\n\t\t// Match the patterns and content. Break out of the loop once a\n\t\t// match is found.\n\t\tfor _, pattern := range opts.Patterns {\n\t\t\tif pattern != nil && pattern.MatchString(cnt) {\n\t\t\t\t// Add to result only if invert match is not enabled.\n\t\t\t\tif !opts.InvertMatch {\n\t\t\t\t\taddToResult = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t} else if opts.InvertMatch {\n\t\t\t\t// If matching fails, and invert match is enabled, add to\n\t\t\t\t// results.\n\t\t\t\taddToResult = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif addToResult {\n\t\t\tgrepResults = append(grepResults, GrepResult{\n\t\t\t\tFileName:   file.Name,\n\t\t\t\tLineNumber: lineNum + 1,\n\t\t\t\tContent:    cnt,\n\t\t\t\tTreeName:   treeName,\n\t\t\t})\n\t\t}\n\t}\n\n\treturn grepResults, nil\n}\n\n// will walk up the directory tree removing all encountered empty\n// directories, not just the one containing this file\nfunc rmFileAndDirsIfEmpty(fs billy.Filesystem, name string) error {\n\tif err := util.RemoveAll(fs, name); err != nil {\n\t\treturn err\n\t}\n\n\tdir := filepath.Dir(name)\n\tfor {\n\t\tremoved, err := removeDirIfEmpty(fs, dir)\n\t\tif err != nil && !os.IsNotExist(err) {\n\t\t\treturn err\n\t\t}\n\n\t\tif !removed {\n\t\t\t// directory was not empty and not removed,\n\t\t\t// stop checking parents\n\t\t\tbreak\n\t\t}\n\n\t\t// move to parent directory\n\t\tdir = filepath.Dir(dir)\n\t}\n\n\treturn nil\n}\n\n// removeDirIfEmpty will remove the supplied directory `dir` if\n// `dir` is empty\n// returns true if the directory was removed\nfunc removeDirIfEmpty(fs billy.Filesystem, dir string) (bool, error) {\n\tfiles, err := fs.ReadDir(dir)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tif len(files) > 0 {\n\t\treturn false, nil\n\t}\n\n\terr = fs.Remove(dir)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\treturn true, nil\n}\n\ntype indexBuilder struct {\n\tentries map[string]*index.Entry\n}\n\nfunc newIndexBuilder(idx *index.Index) *indexBuilder {\n\tentries := make(map[string]*index.Entry, len(idx.Entries))\n\tfor _, e := range idx.Entries {\n\t\tentries[e.Name] = e\n\t}\n\treturn &indexBuilder{\n\t\tentries: entries,\n\t}\n}\n\nfunc (b *indexBuilder) Write(idx *index.Index) {\n\tidx.Entries = idx.Entries[:0]\n\tfor _, e := range b.entries {\n\t\tidx.Entries = append(idx.Entries, e)\n\t}\n}\n\nfunc (b *indexBuilder) Add(e *index.Entry) {\n\tb.entries[e.Name] = e\n}\n\nfunc (b *indexBuilder) Remove(name string) {\n\tdelete(b.entries, filepath.ToSlash(name))\n}\n"
        },
        {
          "name": "worktree_bsd.go",
          "type": "blob",
          "size": 0.447265625,
          "content": "// +build darwin freebsd netbsd\n\npackage git\n\nimport (\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/go-git/go-git/v5/plumbing/format/index\"\n)\n\nfunc init() {\n\tfillSystemInfo = func(e *index.Entry, sys interface{}) {\n\t\tif os, ok := sys.(*syscall.Stat_t); ok {\n\t\t\te.CreatedAt = time.Unix(os.Atimespec.Unix())\n\t\t\te.Dev = uint32(os.Dev)\n\t\t\te.Inode = uint32(os.Ino)\n\t\t\te.GID = os.Gid\n\t\t\te.UID = os.Uid\n\t\t}\n\t}\n}\n\nfunc isSymlinkWindowsNonAdmin(err error) bool {\n\treturn false\n}\n"
        },
        {
          "name": "worktree_commit.go",
          "type": "blob",
          "size": 7.1337890625,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"io\"\n\t\"path\"\n\t\"regexp\"\n\t\"sort\"\n\t\"strings\"\n\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/plumbing/filemode\"\n\t\"github.com/go-git/go-git/v5/plumbing/format/index\"\n\t\"github.com/go-git/go-git/v5/plumbing/object\"\n\t\"github.com/go-git/go-git/v5/storage\"\n\n\t\"github.com/ProtonMail/go-crypto/openpgp\"\n\t\"github.com/ProtonMail/go-crypto/openpgp/packet\"\n\t\"github.com/go-git/go-billy/v5\"\n)\n\nvar (\n\t// ErrEmptyCommit occurs when a commit is attempted using a clean\n\t// working tree, with no changes to be committed.\n\tErrEmptyCommit = errors.New(\"cannot create empty commit: clean working tree\")\n\n\t// characters to be removed from user name and/or email before using them to build a commit object\n\t// See https://git-scm.com/docs/git-commit#_commit_information\n\tinvalidCharactersRe = regexp.MustCompile(`[<>\\n]`)\n)\n\n// Commit stores the current contents of the index in a new commit along with\n// a log message from the user describing the changes.\nfunc (w *Worktree) Commit(msg string, opts *CommitOptions) (plumbing.Hash, error) {\n\tif err := opts.Validate(w.r); err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\tif opts.All {\n\t\tif err := w.autoAddModifiedAndDeleted(); err != nil {\n\t\t\treturn plumbing.ZeroHash, err\n\t\t}\n\t}\n\n\tif opts.Amend {\n\t\thead, err := w.r.Head()\n\t\tif err != nil {\n\t\t\treturn plumbing.ZeroHash, err\n\t\t}\n\t\theadCommit, err := w.r.CommitObject(head.Hash())\n\t\tif err != nil {\n\t\t\treturn plumbing.ZeroHash, err\n\t\t}\n\n\t\topts.Parents = nil\n\t\tif len(headCommit.ParentHashes) != 0 {\n\t\t\topts.Parents = []plumbing.Hash{headCommit.ParentHashes[0]}\n\t\t}\n\t}\n\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\t// First handle the case of the first commit in the repository being empty.\n\tif len(opts.Parents) == 0 && len(idx.Entries) == 0 && !opts.AllowEmptyCommits {\n\t\treturn plumbing.ZeroHash, ErrEmptyCommit\n\t}\n\n\th := &buildTreeHelper{\n\t\tfs: w.Filesystem,\n\t\ts:  w.r.Storer,\n\t}\n\n\ttreeHash, err := h.BuildTree(idx, opts)\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\tpreviousTree := plumbing.ZeroHash\n\tif len(opts.Parents) > 0 {\n\t\tparentCommit, err := w.r.CommitObject(opts.Parents[0])\n\t\tif err != nil {\n\t\t\treturn plumbing.ZeroHash, err\n\t\t}\n\t\tpreviousTree = parentCommit.TreeHash\n\t}\n\n\tif treeHash == previousTree && !opts.AllowEmptyCommits {\n\t\treturn plumbing.ZeroHash, ErrEmptyCommit\n\t}\n\n\tcommit, err := w.buildCommitObject(msg, opts, treeHash)\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\treturn commit, w.updateHEAD(commit)\n}\n\nfunc (w *Worktree) autoAddModifiedAndDeleted() error {\n\ts, err := w.Status()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor path, fs := range s {\n\t\tif fs.Worktree != Modified && fs.Worktree != Deleted {\n\t\t\tcontinue\n\t\t}\n\n\t\tif _, _, err := w.doAddFile(idx, s, path, nil); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t}\n\n\treturn w.r.Storer.SetIndex(idx)\n}\n\nfunc (w *Worktree) updateHEAD(commit plumbing.Hash) error {\n\thead, err := w.r.Storer.Reference(plumbing.HEAD)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tname := plumbing.HEAD\n\tif head.Type() != plumbing.HashReference {\n\t\tname = head.Target()\n\t}\n\n\tref := plumbing.NewHashReference(name, commit)\n\treturn w.r.Storer.SetReference(ref)\n}\n\nfunc (w *Worktree) buildCommitObject(msg string, opts *CommitOptions, tree plumbing.Hash) (plumbing.Hash, error) {\n\tcommit := &object.Commit{\n\t\tAuthor:       w.sanitize(*opts.Author),\n\t\tCommitter:    w.sanitize(*opts.Committer),\n\t\tMessage:      msg,\n\t\tTreeHash:     tree,\n\t\tParentHashes: opts.Parents,\n\t}\n\n\t// Convert SignKey into a Signer if set. Existing Signer should take priority.\n\tsigner := opts.Signer\n\tif signer == nil && opts.SignKey != nil {\n\t\tsigner = &gpgSigner{key: opts.SignKey}\n\t}\n\tif signer != nil {\n\t\tsig, err := signObject(signer, commit)\n\t\tif err != nil {\n\t\t\treturn plumbing.ZeroHash, err\n\t\t}\n\t\tcommit.PGPSignature = string(sig)\n\t}\n\n\tobj := w.r.Storer.NewEncodedObject()\n\tif err := commit.Encode(obj); err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\treturn w.r.Storer.SetEncodedObject(obj)\n}\n\nfunc (w *Worktree) sanitize(signature object.Signature) object.Signature {\n\treturn object.Signature{\n\t\tName:  invalidCharactersRe.ReplaceAllString(signature.Name, \"\"),\n\t\tEmail: invalidCharactersRe.ReplaceAllString(signature.Email, \"\"),\n\t\tWhen:  signature.When,\n\t}\n}\n\ntype gpgSigner struct {\n\tkey *openpgp.Entity\n\tcfg *packet.Config\n}\n\nfunc (s *gpgSigner) Sign(message io.Reader) ([]byte, error) {\n\tvar b bytes.Buffer\n\tif err := openpgp.ArmoredDetachSign(&b, s.key, message, s.cfg); err != nil {\n\t\treturn nil, err\n\t}\n\treturn b.Bytes(), nil\n}\n\n// buildTreeHelper converts a given index.Index file into multiple git objects\n// reading the blobs from the given filesystem and creating the trees from the\n// index structure. The created objects are pushed to a given Storer.\ntype buildTreeHelper struct {\n\tfs billy.Filesystem\n\ts  storage.Storer\n\n\ttrees   map[string]*object.Tree\n\tentries map[string]*object.TreeEntry\n}\n\n// BuildTree builds the tree objects and push its to the storer, the hash\n// of the root tree is returned.\nfunc (h *buildTreeHelper) BuildTree(idx *index.Index, opts *CommitOptions) (plumbing.Hash, error) {\n\tconst rootNode = \"\"\n\th.trees = map[string]*object.Tree{rootNode: {}}\n\th.entries = map[string]*object.TreeEntry{}\n\n\tfor _, e := range idx.Entries {\n\t\tif err := h.commitIndexEntry(e); err != nil {\n\t\t\treturn plumbing.ZeroHash, err\n\t\t}\n\t}\n\n\treturn h.copyTreeToStorageRecursive(rootNode, h.trees[rootNode])\n}\n\nfunc (h *buildTreeHelper) commitIndexEntry(e *index.Entry) error {\n\tparts := strings.Split(e.Name, \"/\")\n\n\tvar fullpath string\n\tfor _, part := range parts {\n\t\tparent := fullpath\n\t\tfullpath = path.Join(fullpath, part)\n\n\t\th.doBuildTree(e, parent, fullpath)\n\t}\n\n\treturn nil\n}\n\nfunc (h *buildTreeHelper) doBuildTree(e *index.Entry, parent, fullpath string) {\n\tif _, ok := h.trees[fullpath]; ok {\n\t\treturn\n\t}\n\n\tif _, ok := h.entries[fullpath]; ok {\n\t\treturn\n\t}\n\n\tte := object.TreeEntry{Name: path.Base(fullpath)}\n\n\tif fullpath == e.Name {\n\t\tte.Mode = e.Mode\n\t\tte.Hash = e.Hash\n\t} else {\n\t\tte.Mode = filemode.Dir\n\t\th.trees[fullpath] = &object.Tree{}\n\t}\n\n\th.trees[parent].Entries = append(h.trees[parent].Entries, te)\n}\n\ntype sortableEntries []object.TreeEntry\n\nfunc (sortableEntries) sortName(te object.TreeEntry) string {\n\tif te.Mode == filemode.Dir {\n\t\treturn te.Name + \"/\"\n\t}\n\treturn te.Name\n}\nfunc (se sortableEntries) Len() int               { return len(se) }\nfunc (se sortableEntries) Less(i int, j int) bool { return se.sortName(se[i]) < se.sortName(se[j]) }\nfunc (se sortableEntries) Swap(i int, j int)      { se[i], se[j] = se[j], se[i] }\n\nfunc (h *buildTreeHelper) copyTreeToStorageRecursive(parent string, t *object.Tree) (plumbing.Hash, error) {\n\tsort.Sort(sortableEntries(t.Entries))\n\tfor i, e := range t.Entries {\n\t\tif e.Mode != filemode.Dir && !e.Hash.IsZero() {\n\t\t\tcontinue\n\t\t}\n\n\t\tpath := path.Join(parent, e.Name)\n\n\t\tvar err error\n\t\te.Hash, err = h.copyTreeToStorageRecursive(path, h.trees[path])\n\t\tif err != nil {\n\t\t\treturn plumbing.ZeroHash, err\n\t\t}\n\n\t\tt.Entries[i] = e\n\t}\n\n\to := h.s.NewEncodedObject()\n\tif err := t.Encode(o); err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\thash := o.Hash()\n\tif h.s.HasEncodedObject(hash) == nil {\n\t\treturn hash, nil\n\t}\n\treturn h.s.SetEncodedObject(o)\n}\n"
        },
        {
          "name": "worktree_commit_test.go",
          "type": "blob",
          "size": 21.865234375,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"log\"\n\t\"os\"\n\t\"os/exec\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"strings\"\n\t\"time\"\n\n\tfixtures \"github.com/go-git/go-git-fixtures/v4\"\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/plumbing/cache\"\n\t\"github.com/go-git/go-git/v5/plumbing/object\"\n\t\"github.com/go-git/go-git/v5/plumbing/storer\"\n\t\"github.com/go-git/go-git/v5/storage/filesystem\"\n\t\"github.com/go-git/go-git/v5/storage/memory\"\n\n\t\"github.com/ProtonMail/go-crypto/openpgp\"\n\t\"github.com/ProtonMail/go-crypto/openpgp/armor\"\n\t\"github.com/ProtonMail/go-crypto/openpgp/errors\"\n\t\"github.com/go-git/go-billy/v5/memfs\"\n\t\"github.com/go-git/go-billy/v5/util\"\n\t. \"gopkg.in/check.v1\"\n)\n\nfunc (s *WorktreeSuite) TestCommitEmptyOptions(c *C) {\n\tfs := memfs.New()\n\tr, err := Init(memory.NewStorage(), fs)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tutil.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\n\t_, err = w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Commit(\"foo\", &CommitOptions{})\n\tc.Assert(err, IsNil)\n\tc.Assert(hash.IsZero(), Equals, false)\n\n\tcommit, err := r.CommitObject(hash)\n\tc.Assert(err, IsNil)\n\tc.Assert(commit.Author.Name, Not(Equals), \"\")\n}\n\nfunc (s *WorktreeSuite) TestCommitInitial(c *C) {\n\texpected := plumbing.NewHash(\"98c4ac7c29c913f7461eae06e024dc18e80d23a4\")\n\n\tfs := memfs.New()\n\tstorage := memory.NewStorage()\n\n\tr, err := Init(storage, fs)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tutil.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\n\t_, err = w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Commit(\"foo\\n\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(hash, Equals, expected)\n\tc.Assert(err, IsNil)\n\n\tassertStorageStatus(c, r, 1, 1, 1, expected)\n}\n\nfunc (s *WorktreeSuite) TestNothingToCommit(c *C) {\n\texpected := plumbing.NewHash(\"838ea833ce893e8555907e5ef224aa076f5e274a\")\n\n\tr, err := Init(memory.NewStorage(), memfs.New())\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Commit(\"failed empty commit\\n\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(hash, Equals, plumbing.ZeroHash)\n\tc.Assert(err, Equals, ErrEmptyCommit)\n\n\thash, err = w.Commit(\"enable empty commits\\n\", &CommitOptions{Author: defaultSignature(), AllowEmptyCommits: true})\n\tc.Assert(hash, Equals, expected)\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *WorktreeSuite) TestNothingToCommitNonEmptyRepo(c *C) {\n\tfs := memfs.New()\n\tr, err := Init(memory.NewStorage(), fs)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\tc.Assert(err, IsNil)\n\n\tw.Add(\"foo\")\n\t_, err = w.Commit(\"previous commit\\n\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Commit(\"failed empty commit\\n\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(hash, Equals, plumbing.ZeroHash)\n\tc.Assert(err, Equals, ErrEmptyCommit)\n\n\t_, err = w.Commit(\"enable empty commits\\n\", &CommitOptions{Author: defaultSignature(), AllowEmptyCommits: true})\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *WorktreeSuite) TestRemoveAndCommitToMakeEmptyRepo(c *C) {\n\tfs := memfs.New()\n\tr, err := Init(memory.NewStorage(), fs)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\tc.Assert(err, IsNil)\n\n\t_, err = w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\n\t_, err = w.Commit(\"Add in Repo\\n\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(err, IsNil)\n\n\terr = fs.Remove(\"foo\")\n\tc.Assert(err, IsNil)\n\n\t_, err = w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\n\t_, err = w.Commit(\"Remove foo\\n\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *WorktreeSuite) TestCommitParent(c *C) {\n\texpected := plumbing.NewHash(\"ef3ca05477530b37f48564be33ddd48063fc7a22\")\n\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\tc.Assert(err, IsNil)\n\n\t_, err = w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Commit(\"foo\\n\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(hash, Equals, expected)\n\tc.Assert(err, IsNil)\n\n\tassertStorageStatus(c, s.Repository, 13, 11, 10, expected)\n}\n\nfunc (s *WorktreeSuite) TestCommitAmendWithoutChanges(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\tc.Assert(err, IsNil)\n\n\t_, err = w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\n\tprevHash, err := w.Commit(\"foo\\n\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(err, IsNil)\n\n\tamendedHash, err := w.Commit(\"foo\\n\", &CommitOptions{Author: defaultSignature(), Amend: true})\n\tc.Assert(err, IsNil)\n\n\theadRef, err := w.r.Head()\n\tc.Assert(err, IsNil)\n\n\tc.Assert(amendedHash, Equals, headRef.Hash())\n\tc.Assert(amendedHash, Equals, prevHash)\n\n\tcommit, err := w.r.CommitObject(headRef.Hash())\n\tc.Assert(err, IsNil)\n\tc.Assert(commit.Message, Equals, \"foo\\n\")\n\n\tassertStorageStatus(c, s.Repository, 13, 11, 10, amendedHash)\n}\n\nfunc (s *WorktreeSuite) TestCommitAmendWithChanges(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tutil.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\n\t_, err = w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\n\t_, err = w.Commit(\"foo\\n\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(err, IsNil)\n\n\tutil.WriteFile(fs, \"bar\", []byte(\"bar\"), 0644)\n\n\t_, err = w.Add(\"bar\")\n\tc.Assert(err, IsNil)\n\n\tamendedHash, err := w.Commit(\"bar\\n\", &CommitOptions{Amend: true})\n\tc.Assert(err, IsNil)\n\n\theadRef, err := w.r.Head()\n\tc.Assert(err, IsNil)\n\n\tc.Assert(amendedHash, Equals, headRef.Hash())\n\n\tcommit, err := w.r.CommitObject(headRef.Hash())\n\tc.Assert(err, IsNil)\n\tc.Assert(commit.Message, Equals, \"bar\\n\")\n\tc.Assert(commit.NumParents(), Equals, 1)\n\n\tstats, err := commit.Stats()\n\tc.Assert(err, IsNil)\n\tc.Assert(stats, HasLen, 2)\n\tc.Assert(stats[0], Equals, object.FileStat{\n\t\tName:     \"bar\",\n\t\tAddition: 1,\n\t})\n\tc.Assert(stats[1], Equals, object.FileStat{\n\t\tName:     \"foo\",\n\t\tAddition: 1,\n\t})\n\n\tassertStorageStatus(c, s.Repository, 14, 12, 11, amendedHash)\n}\n\nfunc (s *WorktreeSuite) TestCommitAmendNothingToCommit(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\tc.Assert(err, IsNil)\n\n\t_, err = w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\n\tprevHash, err := w.Commit(\"foo\\n\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(err, IsNil)\n\n\t_, err = w.Commit(\"bar\\n\", &CommitOptions{Author: defaultSignature(), AllowEmptyCommits: true})\n\tc.Assert(err, IsNil)\n\n\tamendedHash, err := w.Commit(\"foo\\n\", &CommitOptions{Author: defaultSignature(), Amend: true})\n\tc.Log(prevHash, amendedHash)\n\tc.Assert(err, Equals, ErrEmptyCommit)\n\tc.Assert(amendedHash, Equals, plumbing.ZeroHash)\n}\n\nfunc (s *WorktreeSuite) TestAddAndCommitWithSkipStatus(c *C) {\n\texpected := plumbing.NewHash(\"375a3808ffde7f129cdd3c8c252fd0fe37cfd13b\")\n\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tutil.WriteFile(fs, \"LICENSE\", []byte(\"foo\"), 0644)\n\tutil.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\n\terr = w.AddWithOptions(&AddOptions{\n\t\tPath:       \"foo\",\n\t\tSkipStatus: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Commit(\"commit foo only\\n\", &CommitOptions{\n\t\tAuthor: defaultSignature(),\n\t})\n\n\tc.Assert(hash, Equals, expected)\n\tc.Assert(err, IsNil)\n\n\tassertStorageStatus(c, s.Repository, 13, 11, 10, expected)\n}\n\nfunc (s *WorktreeSuite) TestAddAndCommitWithSkipStatusPathNotModified(c *C) {\n\texpected := plumbing.NewHash(\"375a3808ffde7f129cdd3c8c252fd0fe37cfd13b\")\n\texpected2 := plumbing.NewHash(\"8691273baf8f6ee2cccfc05e910552c04d02d472\")\n\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tutil.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tfoo := status.File(\"foo\")\n\tc.Assert(foo.Staging, Equals, Untracked)\n\tc.Assert(foo.Worktree, Equals, Untracked)\n\n\terr = w.AddWithOptions(&AddOptions{\n\t\tPath:       \"foo\",\n\t\tSkipStatus: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tstatus, err = w.Status()\n\tc.Assert(err, IsNil)\n\tfoo = status.File(\"foo\")\n\tc.Assert(foo.Staging, Equals, Added)\n\tc.Assert(foo.Worktree, Equals, Unmodified)\n\n\thash, err := w.Commit(\"commit foo only\\n\", &CommitOptions{All: true,\n\t\tAuthor: defaultSignature(),\n\t})\n\tc.Assert(hash, Equals, expected)\n\tc.Assert(err, IsNil)\n\n\tcommit1, err := w.r.CommitObject(hash)\n\tc.Assert(err, IsNil)\n\n\tstatus, err = w.Status()\n\tc.Assert(err, IsNil)\n\tfoo = status.File(\"foo\")\n\tc.Assert(foo.Staging, Equals, Untracked)\n\tc.Assert(foo.Worktree, Equals, Untracked)\n\n\tassertStorageStatus(c, s.Repository, 13, 11, 10, expected)\n\n\terr = w.AddWithOptions(&AddOptions{\n\t\tPath:       \"foo\",\n\t\tSkipStatus: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tstatus, err = w.Status()\n\tc.Assert(err, IsNil)\n\tfoo = status.File(\"foo\")\n\tc.Assert(foo.Staging, Equals, Untracked)\n\tc.Assert(foo.Worktree, Equals, Untracked)\n\n\thash, err = w.Commit(\"commit with no changes\\n\", &CommitOptions{\n\t\tAuthor:            defaultSignature(),\n\t\tAllowEmptyCommits: true,\n\t})\n\tc.Assert(hash, Equals, expected2)\n\tc.Assert(err, IsNil)\n\n\tcommit2, err := w.r.CommitObject(hash)\n\tc.Assert(err, IsNil)\n\n\tstatus, err = w.Status()\n\tc.Assert(err, IsNil)\n\tfoo = status.File(\"foo\")\n\tc.Assert(foo.Staging, Equals, Untracked)\n\tc.Assert(foo.Worktree, Equals, Untracked)\n\n\tpatch, err := commit2.Patch(commit1)\n\tc.Assert(err, IsNil)\n\tfiles := patch.FilePatches()\n\tc.Assert(files, IsNil)\n\n\tassertStorageStatus(c, s.Repository, 13, 11, 11, expected2)\n}\n\nfunc (s *WorktreeSuite) TestCommitAll(c *C) {\n\texpected := plumbing.NewHash(\"aede6f8c9c1c7ec9ca8d287c64b8ed151276fa28\")\n\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tutil.WriteFile(fs, \"LICENSE\", []byte(\"foo\"), 0644)\n\tutil.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\n\thash, err := w.Commit(\"foo\\n\", &CommitOptions{\n\t\tAll:    true,\n\t\tAuthor: defaultSignature(),\n\t})\n\n\tc.Assert(hash, Equals, expected)\n\tc.Assert(err, IsNil)\n\n\tassertStorageStatus(c, s.Repository, 13, 11, 10, expected)\n}\n\nfunc (s *WorktreeSuite) TestRemoveAndCommitAll(c *C) {\n\texpected := plumbing.NewHash(\"907cd576c6ced2ecd3dab34a72bf9cf65944b9a9\")\n\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tutil.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\t_, err = w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\n\t_, errFirst := w.Commit(\"Add in Repo\\n\", &CommitOptions{\n\t\tAuthor: defaultSignature(),\n\t})\n\tc.Assert(errFirst, IsNil)\n\n\terrRemove := fs.Remove(\"foo\")\n\tc.Assert(errRemove, IsNil)\n\n\thash, errSecond := w.Commit(\"Remove foo\\n\", &CommitOptions{\n\t\tAll:    true,\n\t\tAuthor: defaultSignature(),\n\t})\n\tc.Assert(errSecond, IsNil)\n\n\tc.Assert(hash, Equals, expected)\n\tc.Assert(err, IsNil)\n\n\tassertStorageStatus(c, s.Repository, 13, 11, 11, expected)\n}\n\nfunc (s *WorktreeSuite) TestCommitSign(c *C) {\n\tfs := memfs.New()\n\tstorage := memory.NewStorage()\n\n\tr, err := Init(storage, fs)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tutil.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\n\t_, err = w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\n\tkey := commitSignKey(c, true)\n\thash, err := w.Commit(\"foo\\n\", &CommitOptions{Author: defaultSignature(), SignKey: key})\n\tc.Assert(err, IsNil)\n\n\t// Verify the commit.\n\tpks := new(bytes.Buffer)\n\tpkw, err := armor.Encode(pks, openpgp.PublicKeyType, nil)\n\tc.Assert(err, IsNil)\n\n\terr = key.Serialize(pkw)\n\tc.Assert(err, IsNil)\n\terr = pkw.Close()\n\tc.Assert(err, IsNil)\n\n\texpectedCommit, err := r.CommitObject(hash)\n\tc.Assert(err, IsNil)\n\tactual, err := expectedCommit.Verify(pks.String())\n\tc.Assert(err, IsNil)\n\tc.Assert(actual.PrimaryKey, DeepEquals, key.PrimaryKey)\n}\n\nfunc (s *WorktreeSuite) TestCommitSignBadKey(c *C) {\n\tfs := memfs.New()\n\tstorage := memory.NewStorage()\n\n\tr, err := Init(storage, fs)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tutil.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\n\t_, err = w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\n\tkey := commitSignKey(c, false)\n\t_, err = w.Commit(\"foo\\n\", &CommitOptions{Author: defaultSignature(), SignKey: key})\n\tc.Assert(err, Equals, errors.InvalidArgumentError(\"signing key is encrypted\"))\n}\n\nfunc (s *WorktreeSuite) TestCommitTreeSort(c *C) {\n\tfs := s.TemporalFilesystem(c)\n\n\tst := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\t_, err := Init(st, nil)\n\tc.Assert(err, IsNil)\n\n\tr, _ := Clone(memory.NewStorage(), memfs.New(), &CloneOptions{\n\t\tURL: fs.Root(),\n\t})\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tmfs := w.Filesystem\n\n\terr = mfs.MkdirAll(\"delta\", 0755)\n\tc.Assert(err, IsNil)\n\n\tfor _, p := range []string{\"delta_last\", \"Gamma\", \"delta/middle\", \"Beta\", \"delta-first\", \"alpha\"} {\n\t\tutil.WriteFile(mfs, p, []byte(\"foo\"), 0644)\n\t\t_, err = w.Add(p)\n\t\tc.Assert(err, IsNil)\n\t}\n\n\t_, err = w.Commit(\"foo\\n\", &CommitOptions{\n\t\tAll:    true,\n\t\tAuthor: defaultSignature(),\n\t})\n\tc.Assert(err, IsNil)\n\n\terr = r.Push(&PushOptions{})\n\tc.Assert(err, IsNil)\n\n\tcmd := exec.Command(\"git\", \"fsck\")\n\tcmd.Dir = fs.Root()\n\tcmd.Env = os.Environ()\n\tbuf := &bytes.Buffer{}\n\tcmd.Stderr = buf\n\tcmd.Stdout = buf\n\n\terr = cmd.Run()\n\n\tc.Assert(err, IsNil, Commentf(\"%s\", buf.Bytes()))\n}\n\n// https://github.com/go-git/go-git/pull/224\nfunc (s *WorktreeSuite) TestJustStoreObjectsNotAlreadyStored(c *C) {\n\tfs := s.TemporalFilesystem(c)\n\n\tfsDotgit, err := fs.Chroot(\".git\") // real fs to get modified timestamps\n\tc.Assert(err, IsNil)\n\tstorage := filesystem.NewStorage(fsDotgit, cache.NewObjectLRUDefault())\n\n\tr, err := Init(storage, fs)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\t// Step 1: Write LICENSE\n\tutil.WriteFile(fs, \"LICENSE\", []byte(\"license\"), 0644)\n\thLicense, err := w.Add(\"LICENSE\")\n\tc.Assert(err, IsNil)\n\tc.Assert(hLicense, Equals, plumbing.NewHash(\"0484eba0d41636ba71fa612c78559cd6c3006cde\"))\n\n\thash, err := w.Commit(\"commit 1\\n\", &CommitOptions{\n\t\tAll:    true,\n\t\tAuthor: defaultSignature(),\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(hash, Equals, plumbing.NewHash(\"7a7faee4630d2664a6869677cc8ab614f3fd4a18\"))\n\n\tinfoLicense, err := fsDotgit.Stat(filepath.Join(\"objects\", \"04\", \"84eba0d41636ba71fa612c78559cd6c3006cde\"))\n\tc.Assert(err, IsNil) // checking objects file exists\n\n\t// Step 2: Write foo.\n\ttime.Sleep(5 * time.Millisecond) // uncool, but we need to get different timestamps...\n\tutil.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\thFoo, err := w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\tc.Assert(hFoo, Equals, plumbing.NewHash(\"19102815663d23f8b75a47e7a01965dcdc96468c\"))\n\n\thash, err = w.Commit(\"commit 2\\n\", &CommitOptions{\n\t\tAll:    true,\n\t\tAuthor: defaultSignature(),\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(hash, Equals, plumbing.NewHash(\"97c0c5177e6ac57d10e8ea0017f2d39b91e2b364\"))\n\n\t// Step 3: Check\n\t// There is no need to overwrite the object of LICENSE, because its content\n\t// was not changed. Just a write on the object of foo is required. This behaviour\n\t// is fixed by #224 and tested by comparing the timestamps of the stored objects.\n\tinfoFoo, err := fsDotgit.Stat(filepath.Join(\"objects\", \"19\", \"102815663d23f8b75a47e7a01965dcdc96468c\"))\n\tc.Assert(err, IsNil)                                                    // checking objects file exists\n\tc.Assert(infoLicense.ModTime().Before(infoFoo.ModTime()), Equals, true) // object of foo has another/greaterThan timestamp than LICENSE\n\n\tinfoLicenseSecond, err := fsDotgit.Stat(filepath.Join(\"objects\", \"04\", \"84eba0d41636ba71fa612c78559cd6c3006cde\"))\n\tc.Assert(err, IsNil)\n\n\tlog.Printf(\"comparing mod time: %v == %v on %v (%v)\", infoLicenseSecond.ModTime(), infoLicense.ModTime(), runtime.GOOS, runtime.GOARCH)\n\tc.Assert(infoLicenseSecond.ModTime(), Equals, infoLicense.ModTime()) // object of LICENSE should have the same timestamp because no additional write operation was performed\n}\n\nfunc (s *WorktreeSuite) TestCommitInvalidCharactersInAuthorInfos(c *C) {\n\tf := fixtures.Basic().One()\n\ts.Repository = s.NewRepositoryWithEmptyWorktree(f)\n\n\texpected := plumbing.NewHash(\"e8eecef2524c3a37cf0f0996603162f81e0373f1\")\n\n\tfs := memfs.New()\n\tstorage := memory.NewStorage()\n\n\tr, err := Init(storage, fs)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tutil.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\n\t_, err = w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Commit(\"foo\\n\", &CommitOptions{Author: invalidSignature()})\n\tc.Assert(hash, Equals, expected)\n\tc.Assert(err, IsNil)\n\n\tassertStorageStatus(c, r, 1, 1, 1, expected)\n\n\t// Check HEAD commit contains author informations with '<', '>' and '\\n' stripped\n\tlr, err := r.Log(&LogOptions{})\n\tc.Assert(err, IsNil)\n\n\tcommit, err := lr.Next()\n\tc.Assert(err, IsNil)\n\n\tc.Assert(commit.Author.Name, Equals, \"foo bad\")\n\tc.Assert(commit.Author.Email, Equals, \"badfoo@foo.foo\")\n\n}\n\nfunc assertStorageStatus(\n\tc *C, r *Repository,\n\ttreesCount, blobCount, commitCount int, head plumbing.Hash,\n) {\n\ttrees, err := r.Storer.IterEncodedObjects(plumbing.TreeObject)\n\tc.Assert(err, IsNil)\n\tblobs, err := r.Storer.IterEncodedObjects(plumbing.BlobObject)\n\tc.Assert(err, IsNil)\n\tcommits, err := r.Storer.IterEncodedObjects(plumbing.CommitObject)\n\tc.Assert(err, IsNil)\n\n\tc.Assert(lenIterEncodedObjects(trees), Equals, treesCount)\n\tc.Assert(lenIterEncodedObjects(blobs), Equals, blobCount)\n\tc.Assert(lenIterEncodedObjects(commits), Equals, commitCount)\n\n\tref, err := r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(ref.Hash(), Equals, head)\n}\n\nfunc lenIterEncodedObjects(iter storer.EncodedObjectIter) int {\n\tcount := 0\n\titer.ForEach(func(plumbing.EncodedObject) error {\n\t\tcount++\n\t\treturn nil\n\t})\n\n\treturn count\n}\n\nfunc defaultSignature() *object.Signature {\n\twhen, _ := time.Parse(object.DateFormat, \"Thu May 04 00:03:43 2017 +0200\")\n\treturn &object.Signature{\n\t\tName:  \"foo\",\n\t\tEmail: \"foo@foo.foo\",\n\t\tWhen:  when,\n\t}\n}\n\nfunc invalidSignature() *object.Signature {\n\twhen, _ := time.Parse(object.DateFormat, \"Thu May 04 00:03:43 2017 +0200\")\n\treturn &object.Signature{\n\t\tName:  \"foo <bad>\\n\",\n\t\tEmail: \"<bad>\\nfoo@foo.foo\",\n\t\tWhen:  when,\n\t}\n}\n\nfunc commitSignKey(c *C, decrypt bool) *openpgp.Entity {\n\ts := strings.NewReader(armoredKeyRing)\n\tes, err := openpgp.ReadArmoredKeyRing(s)\n\tc.Assert(err, IsNil)\n\n\tc.Assert(es, HasLen, 1)\n\tc.Assert(es[0].Identities, HasLen, 1)\n\t_, ok := es[0].Identities[\"foo bar <foo@foo.foo>\"]\n\tc.Assert(ok, Equals, true)\n\n\tkey := es[0]\n\tif decrypt {\n\t\terr = key.PrivateKey.Decrypt([]byte(keyPassphrase))\n\t\tc.Assert(err, IsNil)\n\t}\n\n\treturn key\n}\n\nconst armoredKeyRing = `\n-----BEGIN PGP PRIVATE KEY BLOCK-----\n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\nCgLH6twOqdSFWqB/4ASDMsNeLeKX3WOYKYYMlE01cj3T1m6dpRUO\n=gIM9\n-----END PGP PRIVATE KEY BLOCK-----\n`\n\nconst keyPassphrase = \"abcdef0123456789\"\n"
        },
        {
          "name": "worktree_js.go",
          "type": "blob",
          "size": 0.4453125,
          "content": "// +build js\n\npackage git\n\nimport (\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/go-git/go-git/v5/plumbing/format/index\"\n)\n\nfunc init() {\n\tfillSystemInfo = func(e *index.Entry, sys interface{}) {\n\t\tif os, ok := sys.(*syscall.Stat_t); ok {\n\t\t\te.CreatedAt = time.Unix(int64(os.Ctime), int64(os.CtimeNsec))\n\t\t\te.Dev = uint32(os.Dev)\n\t\t\te.Inode = uint32(os.Ino)\n\t\t\te.GID = os.Gid\n\t\t\te.UID = os.Uid\n\t\t}\n\t}\n}\n\nfunc isSymlinkWindowsNonAdmin(err error) bool {\n\treturn false\n}\n"
        },
        {
          "name": "worktree_linux.go",
          "type": "blob",
          "size": 0.44140625,
          "content": "//go:build linux\n// +build linux\n\npackage git\n\nimport (\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/go-git/go-git/v5/plumbing/format/index\"\n)\n\nfunc init() {\n\tfillSystemInfo = func(e *index.Entry, sys interface{}) {\n\t\tif os, ok := sys.(*syscall.Stat_t); ok {\n\t\t\te.CreatedAt = time.Unix(os.Ctim.Unix())\n\t\t\te.Dev = uint32(os.Dev)\n\t\t\te.Inode = uint32(os.Ino)\n\t\t\te.GID = os.Gid\n\t\t\te.UID = os.Uid\n\t\t}\n\t}\n}\n\nfunc isSymlinkWindowsNonAdmin(_ error) bool {\n\treturn false\n}\n"
        },
        {
          "name": "worktree_plan9.go",
          "type": "blob",
          "size": 0.5615234375,
          "content": "package git\n\nimport (\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/go-git/go-git/v5/plumbing/format/index\"\n)\n\nfunc init() {\n\tfillSystemInfo = func(e *index.Entry, sys interface{}) {\n\t\tif os, ok := sys.(*syscall.Dir); ok {\n\t\t\t// Plan 9 doesn't have a CreatedAt field.\n\t\t\te.CreatedAt = time.Unix(int64(os.Mtime), 0)\n\n\t\t\te.Dev = uint32(os.Dev)\n\n\t\t\t// Plan 9 has no Inode.\n\t\t\t// ext2srv(4) appears to store Inode in Qid.Path.\n\t\t\te.Inode = uint32(os.Qid.Path)\n\n\t\t\t// Plan 9 has string UID/GID\n\t\t\te.GID = 0\n\t\t\te.UID = 0\n\t\t}\n\t}\n}\n\nfunc isSymlinkWindowsNonAdmin(err error) bool {\n\treturn true\n}\n"
        },
        {
          "name": "worktree_status.go",
          "type": "blob",
          "size": 16.630859375,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"io\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"strings\"\n\n\t\"github.com/go-git/go-billy/v5/util\"\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/plumbing/filemode\"\n\t\"github.com/go-git/go-git/v5/plumbing/format/gitignore\"\n\t\"github.com/go-git/go-git/v5/plumbing/format/index\"\n\t\"github.com/go-git/go-git/v5/plumbing/object\"\n\t\"github.com/go-git/go-git/v5/utils/ioutil\"\n\t\"github.com/go-git/go-git/v5/utils/merkletrie\"\n\t\"github.com/go-git/go-git/v5/utils/merkletrie/filesystem\"\n\tmindex \"github.com/go-git/go-git/v5/utils/merkletrie/index\"\n\t\"github.com/go-git/go-git/v5/utils/merkletrie/noder\"\n)\n\nvar (\n\t// ErrDestinationExists in an Move operation means that the target exists on\n\t// the worktree.\n\tErrDestinationExists = errors.New(\"destination exists\")\n\t// ErrGlobNoMatches in an AddGlob if the glob pattern does not match any\n\t// files in the worktree.\n\tErrGlobNoMatches = errors.New(\"glob pattern did not match any files\")\n\t// ErrUnsupportedStatusStrategy occurs when an invalid StatusStrategy is used\n\t// when processing the Worktree status.\n\tErrUnsupportedStatusStrategy = errors.New(\"unsupported status strategy\")\n)\n\n// Status returns the working tree status.\nfunc (w *Worktree) Status() (Status, error) {\n\treturn w.StatusWithOptions(StatusOptions{Strategy: defaultStatusStrategy})\n}\n\n// StatusOptions defines the options for Worktree.StatusWithOptions().\ntype StatusOptions struct {\n\tStrategy StatusStrategy\n}\n\n// StatusWithOptions returns the working tree status.\nfunc (w *Worktree) StatusWithOptions(o StatusOptions) (Status, error) {\n\tvar hash plumbing.Hash\n\n\tref, err := w.r.Head()\n\tif err != nil && err != plumbing.ErrReferenceNotFound {\n\t\treturn nil, err\n\t}\n\n\tif err == nil {\n\t\thash = ref.Hash()\n\t}\n\n\treturn w.status(o.Strategy, hash)\n}\n\nfunc (w *Worktree) status(ss StatusStrategy, commit plumbing.Hash) (Status, error) {\n\ts, err := ss.new(w)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tleft, err := w.diffCommitWithStaging(commit, false)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, ch := range left {\n\t\ta, err := ch.Action()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tfs := s.File(nameFromAction(&ch))\n\t\tfs.Worktree = Unmodified\n\n\t\tswitch a {\n\t\tcase merkletrie.Delete:\n\t\t\ts.File(ch.From.String()).Staging = Deleted\n\t\tcase merkletrie.Insert:\n\t\t\ts.File(ch.To.String()).Staging = Added\n\t\tcase merkletrie.Modify:\n\t\t\ts.File(ch.To.String()).Staging = Modified\n\t\t}\n\t}\n\n\tright, err := w.diffStagingWithWorktree(false, true)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, ch := range right {\n\t\ta, err := ch.Action()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tfs := s.File(nameFromAction(&ch))\n\t\tif fs.Staging == Untracked {\n\t\t\tfs.Staging = Unmodified\n\t\t}\n\n\t\tswitch a {\n\t\tcase merkletrie.Delete:\n\t\t\tfs.Worktree = Deleted\n\t\tcase merkletrie.Insert:\n\t\t\tfs.Worktree = Untracked\n\t\t\tfs.Staging = Untracked\n\t\tcase merkletrie.Modify:\n\t\t\tfs.Worktree = Modified\n\t\t}\n\t}\n\n\treturn s, nil\n}\n\nfunc nameFromAction(ch *merkletrie.Change) string {\n\tname := ch.To.String()\n\tif name == \"\" {\n\t\treturn ch.From.String()\n\t}\n\n\treturn name\n}\n\nfunc (w *Worktree) diffStagingWithWorktree(reverse, excludeIgnoredChanges bool) (merkletrie.Changes, error) {\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfrom := mindex.NewRootNode(idx)\n\tsubmodules, err := w.getSubmodulesStatus()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tto := filesystem.NewRootNode(w.Filesystem, submodules)\n\n\tvar c merkletrie.Changes\n\tif reverse {\n\t\tc, err = merkletrie.DiffTree(to, from, diffTreeIsEquals)\n\t} else {\n\t\tc, err = merkletrie.DiffTree(from, to, diffTreeIsEquals)\n\t}\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif excludeIgnoredChanges {\n\t\treturn w.excludeIgnoredChanges(c), nil\n\t}\n\treturn c, nil\n}\n\nfunc (w *Worktree) excludeIgnoredChanges(changes merkletrie.Changes) merkletrie.Changes {\n\tpatterns, err := gitignore.ReadPatterns(w.Filesystem, nil)\n\tif err != nil {\n\t\treturn changes\n\t}\n\n\tpatterns = append(patterns, w.Excludes...)\n\n\tif len(patterns) == 0 {\n\t\treturn changes\n\t}\n\n\tm := gitignore.NewMatcher(patterns)\n\n\tvar res merkletrie.Changes\n\tfor _, ch := range changes {\n\t\tvar path []string\n\t\tfor _, n := range ch.To {\n\t\t\tpath = append(path, n.Name())\n\t\t}\n\t\tif len(path) == 0 {\n\t\t\tfor _, n := range ch.From {\n\t\t\t\tpath = append(path, n.Name())\n\t\t\t}\n\t\t}\n\t\tif len(path) != 0 {\n\t\t\tisDir := (len(ch.To) > 0 && ch.To.IsDir()) || (len(ch.From) > 0 && ch.From.IsDir())\n\t\t\tif m.Match(path, isDir) {\n\t\t\t\tif len(ch.From) == 0 {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tres = append(res, ch)\n\t}\n\treturn res\n}\n\nfunc (w *Worktree) getSubmodulesStatus() (map[string]plumbing.Hash, error) {\n\to := map[string]plumbing.Hash{}\n\n\tsub, err := w.Submodules()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tstatus, err := sub.Status()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, s := range status {\n\t\tif s.Current.IsZero() {\n\t\t\to[s.Path] = s.Expected\n\t\t\tcontinue\n\t\t}\n\n\t\to[s.Path] = s.Current\n\t}\n\n\treturn o, nil\n}\n\nfunc (w *Worktree) diffCommitWithStaging(commit plumbing.Hash, reverse bool) (merkletrie.Changes, error) {\n\tvar t *object.Tree\n\tif !commit.IsZero() {\n\t\tc, err := w.r.CommitObject(commit)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tt, err = c.Tree()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn w.diffTreeWithStaging(t, reverse)\n}\n\nfunc (w *Worktree) diffTreeWithStaging(t *object.Tree, reverse bool) (merkletrie.Changes, error) {\n\tvar from noder.Noder\n\tif t != nil {\n\t\tfrom = object.NewTreeRootNode(t)\n\t}\n\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tto := mindex.NewRootNode(idx)\n\n\tif reverse {\n\t\treturn merkletrie.DiffTree(to, from, diffTreeIsEquals)\n\t}\n\n\treturn merkletrie.DiffTree(from, to, diffTreeIsEquals)\n}\n\nvar emptyNoderHash = make([]byte, 24)\n\n// diffTreeIsEquals is a implementation of noder.Equals, used to compare\n// noder.Noder, it compare the content and the length of the hashes.\n//\n// Since some of the noder.Noder implementations doesn't compute a hash for\n// some directories, if any of the hashes is a 24-byte slice of zero values\n// the comparison is not done and the hashes are take as different.\nfunc diffTreeIsEquals(a, b noder.Hasher) bool {\n\thashA := a.Hash()\n\thashB := b.Hash()\n\n\tif bytes.Equal(hashA, emptyNoderHash) || bytes.Equal(hashB, emptyNoderHash) {\n\t\treturn false\n\t}\n\n\treturn bytes.Equal(hashA, hashB)\n}\n\n// Add adds the file contents of a file in the worktree to the index. if the\n// file is already staged in the index no error is returned. If a file deleted\n// from the Workspace is given, the file is removed from the index. If a\n// directory given, adds the files and all his sub-directories recursively in\n// the worktree to the index. If any of the files is already staged in the index\n// no error is returned. When path is a file, the blob.Hash is returned.\nfunc (w *Worktree) Add(path string) (plumbing.Hash, error) {\n\t// TODO(mcuadros): deprecate in favor of AddWithOption in v6.\n\treturn w.doAdd(path, make([]gitignore.Pattern, 0), false)\n}\n\nfunc (w *Worktree) doAddDirectory(idx *index.Index, s Status, directory string, ignorePattern []gitignore.Pattern) (added bool, err error) {\n\tif len(ignorePattern) > 0 {\n\t\tm := gitignore.NewMatcher(ignorePattern)\n\t\tmatchPath := strings.Split(directory, string(os.PathSeparator))\n\t\tif m.Match(matchPath, true) {\n\t\t\t// ignore\n\t\t\treturn false, nil\n\t\t}\n\t}\n\n\tdirectory = filepath.ToSlash(filepath.Clean(directory))\n\n\tfor name := range s {\n\t\tif !isPathInDirectory(name, directory) {\n\t\t\tcontinue\n\t\t}\n\n\t\tvar a bool\n\t\ta, _, err = w.doAddFile(idx, s, name, ignorePattern)\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\n\t\tadded = added || a\n\t}\n\n\treturn\n}\n\nfunc isPathInDirectory(path, directory string) bool {\n\treturn directory == \".\" || strings.HasPrefix(path, directory+\"/\")\n}\n\n// AddWithOptions file contents to the index,  updates the index using the\n// current content found in the working tree, to prepare the content staged for\n// the next commit.\n//\n// It typically adds the current content of existing paths as a whole, but with\n// some options it can also be used to add content with only part of the changes\n// made to the working tree files applied, or remove paths that do not exist in\n// the working tree anymore.\nfunc (w *Worktree) AddWithOptions(opts *AddOptions) error {\n\tif err := opts.Validate(w.r); err != nil {\n\t\treturn err\n\t}\n\n\tif opts.All {\n\t\t_, err := w.doAdd(\".\", w.Excludes, false)\n\t\treturn err\n\t}\n\n\tif opts.Glob != \"\" {\n\t\treturn w.AddGlob(opts.Glob)\n\t}\n\n\t_, err := w.doAdd(opts.Path, make([]gitignore.Pattern, 0), opts.SkipStatus)\n\treturn err\n}\n\nfunc (w *Worktree) doAdd(path string, ignorePattern []gitignore.Pattern, skipStatus bool) (plumbing.Hash, error) {\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\tvar h plumbing.Hash\n\tvar added bool\n\n\tfi, err := w.Filesystem.Lstat(path)\n\n\t// status is required for doAddDirectory\n\tvar s Status\n\tvar err2 error\n\tif !skipStatus || fi == nil || fi.IsDir() {\n\t\ts, err2 = w.Status()\n\t\tif err2 != nil {\n\t\t\treturn plumbing.ZeroHash, err2\n\t\t}\n\t}\n\n\tif err != nil || !fi.IsDir() {\n\t\tadded, h, err = w.doAddFile(idx, s, path, ignorePattern)\n\t} else {\n\t\tadded, err = w.doAddDirectory(idx, s, path, ignorePattern)\n\t}\n\n\tif err != nil {\n\t\treturn h, err\n\t}\n\n\tif !added {\n\t\treturn h, nil\n\t}\n\n\treturn h, w.r.Storer.SetIndex(idx)\n}\n\n// AddGlob adds all paths, matching pattern, to the index. If pattern matches a\n// directory path, all directory contents are added to the index recursively. No\n// error is returned if all matching paths are already staged in index.\nfunc (w *Worktree) AddGlob(pattern string) error {\n\t// TODO(mcuadros): deprecate in favor of AddWithOption in v6.\n\tfiles, err := util.Glob(w.Filesystem, pattern)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif len(files) == 0 {\n\t\treturn ErrGlobNoMatches\n\t}\n\n\ts, err := w.Status()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvar saveIndex bool\n\tfor _, file := range files {\n\t\tfi, err := w.Filesystem.Lstat(file)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tvar added bool\n\t\tif fi.IsDir() {\n\t\t\tadded, err = w.doAddDirectory(idx, s, file, make([]gitignore.Pattern, 0))\n\t\t} else {\n\t\t\tadded, _, err = w.doAddFile(idx, s, file, make([]gitignore.Pattern, 0))\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif !saveIndex && added {\n\t\t\tsaveIndex = true\n\t\t}\n\t}\n\n\tif saveIndex {\n\t\treturn w.r.Storer.SetIndex(idx)\n\t}\n\n\treturn nil\n}\n\n// doAddFile create a new blob from path and update the index, added is true if\n// the file added is different from the index.\n// if s status is nil will skip the status check and update the index anyway\nfunc (w *Worktree) doAddFile(idx *index.Index, s Status, path string, ignorePattern []gitignore.Pattern) (added bool, h plumbing.Hash, err error) {\n\tif s != nil && s.File(path).Worktree == Unmodified {\n\t\treturn false, h, nil\n\t}\n\tif len(ignorePattern) > 0 {\n\t\tm := gitignore.NewMatcher(ignorePattern)\n\t\tmatchPath := strings.Split(path, string(os.PathSeparator))\n\t\tif m.Match(matchPath, true) {\n\t\t\t// ignore\n\t\t\treturn false, h, nil\n\t\t}\n\t}\n\n\th, err = w.copyFileToStorage(path)\n\tif err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\tadded = true\n\t\t\th, err = w.deleteFromIndex(idx, path)\n\t\t}\n\n\t\treturn\n\t}\n\n\tif err := w.addOrUpdateFileToIndex(idx, path, h); err != nil {\n\t\treturn false, h, err\n\t}\n\n\treturn true, h, err\n}\n\nfunc (w *Worktree) copyFileToStorage(path string) (hash plumbing.Hash, err error) {\n\tfi, err := w.Filesystem.Lstat(path)\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\tobj := w.r.Storer.NewEncodedObject()\n\tobj.SetType(plumbing.BlobObject)\n\tobj.SetSize(fi.Size())\n\n\twriter, err := obj.Writer()\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\tdefer ioutil.CheckClose(writer, &err)\n\n\tif fi.Mode()&os.ModeSymlink != 0 {\n\t\terr = w.fillEncodedObjectFromSymlink(writer, path, fi)\n\t} else {\n\t\terr = w.fillEncodedObjectFromFile(writer, path, fi)\n\t}\n\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\treturn w.r.Storer.SetEncodedObject(obj)\n}\n\nfunc (w *Worktree) fillEncodedObjectFromFile(dst io.Writer, path string, _ os.FileInfo) (err error) {\n\tsrc, err := w.Filesystem.Open(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdefer ioutil.CheckClose(src, &err)\n\n\tif _, err := io.Copy(dst, src); err != nil {\n\t\treturn err\n\t}\n\n\treturn err\n}\n\nfunc (w *Worktree) fillEncodedObjectFromSymlink(dst io.Writer, path string, _ os.FileInfo) error {\n\ttarget, err := w.Filesystem.Readlink(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t_, err = dst.Write([]byte(target))\n\treturn err\n}\n\nfunc (w *Worktree) addOrUpdateFileToIndex(idx *index.Index, filename string, h plumbing.Hash) error {\n\te, err := idx.Entry(filename)\n\tif err != nil && err != index.ErrEntryNotFound {\n\t\treturn err\n\t}\n\n\tif err == index.ErrEntryNotFound {\n\t\treturn w.doAddFileToIndex(idx, filename, h)\n\t}\n\n\treturn w.doUpdateFileToIndex(e, filename, h)\n}\n\nfunc (w *Worktree) doAddFileToIndex(idx *index.Index, filename string, h plumbing.Hash) error {\n\treturn w.doUpdateFileToIndex(idx.Add(filename), filename, h)\n}\n\nfunc (w *Worktree) doUpdateFileToIndex(e *index.Entry, filename string, h plumbing.Hash) error {\n\tinfo, err := w.Filesystem.Lstat(filename)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\te.Hash = h\n\te.ModifiedAt = info.ModTime()\n\te.Mode, err = filemode.NewFromOSFileMode(info.Mode())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// The entry size must always reflect the current state, otherwise\n\t// it will cause go-git's Worktree.Status() to divert from \"git status\".\n\t// The size of a symlink is the length of the path to the target.\n\t// The size of Regular and Executable files is the size of the files.\n\te.Size = uint32(info.Size())\n\n\tfillSystemInfo(e, info.Sys())\n\treturn nil\n}\n\n// Remove removes files from the working tree and from the index.\nfunc (w *Worktree) Remove(path string) (plumbing.Hash, error) {\n\t// TODO(mcuadros): remove plumbing.Hash from signature at v5.\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\tvar h plumbing.Hash\n\n\tfi, err := w.Filesystem.Lstat(path)\n\tif err != nil || !fi.IsDir() {\n\t\th, err = w.doRemoveFile(idx, path)\n\t} else {\n\t\t_, err = w.doRemoveDirectory(idx, path)\n\t}\n\tif err != nil {\n\t\treturn h, err\n\t}\n\n\treturn h, w.r.Storer.SetIndex(idx)\n}\n\nfunc (w *Worktree) doRemoveDirectory(idx *index.Index, directory string) (removed bool, err error) {\n\tfiles, err := w.Filesystem.ReadDir(directory)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tfor _, file := range files {\n\t\tname := path.Join(directory, file.Name())\n\n\t\tvar r bool\n\t\tif file.IsDir() {\n\t\t\tr, err = w.doRemoveDirectory(idx, name)\n\t\t} else {\n\t\t\t_, err = w.doRemoveFile(idx, name)\n\t\t\tif err == index.ErrEntryNotFound {\n\t\t\t\terr = nil\n\t\t\t}\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\n\t\tif !removed && r {\n\t\t\tremoved = true\n\t\t}\n\t}\n\n\terr = w.removeEmptyDirectory(directory)\n\treturn\n}\n\nfunc (w *Worktree) removeEmptyDirectory(path string) error {\n\tfiles, err := w.Filesystem.ReadDir(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif len(files) != 0 {\n\t\treturn nil\n\t}\n\n\treturn w.Filesystem.Remove(path)\n}\n\nfunc (w *Worktree) doRemoveFile(idx *index.Index, path string) (plumbing.Hash, error) {\n\thash, err := w.deleteFromIndex(idx, path)\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\treturn hash, w.deleteFromFilesystem(path)\n}\n\nfunc (w *Worktree) deleteFromIndex(idx *index.Index, path string) (plumbing.Hash, error) {\n\te, err := idx.Remove(path)\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\treturn e.Hash, nil\n}\n\nfunc (w *Worktree) deleteFromFilesystem(path string) error {\n\terr := w.Filesystem.Remove(path)\n\tif os.IsNotExist(err) {\n\t\treturn nil\n\t}\n\n\treturn err\n}\n\n// RemoveGlob removes all paths, matching pattern, from the index. If pattern\n// matches a directory path, all directory contents are removed from the index\n// recursively.\nfunc (w *Worktree) RemoveGlob(pattern string) error {\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tentries, err := idx.Glob(pattern)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, e := range entries {\n\t\tfile := filepath.FromSlash(e.Name)\n\t\tif _, err := w.Filesystem.Lstat(file); err != nil && !os.IsNotExist(err) {\n\t\t\treturn err\n\t\t}\n\n\t\tif _, err := w.doRemoveFile(idx, file); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tdir, _ := filepath.Split(file)\n\t\tif err := w.removeEmptyDirectory(dir); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn w.r.Storer.SetIndex(idx)\n}\n\n// Move moves or rename a file in the worktree and the index, directories are\n// not supported.\nfunc (w *Worktree) Move(from, to string) (plumbing.Hash, error) {\n\t// TODO(mcuadros): support directories and/or implement support for glob\n\tif _, err := w.Filesystem.Lstat(from); err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\tif _, err := w.Filesystem.Lstat(to); err == nil {\n\t\treturn plumbing.ZeroHash, ErrDestinationExists\n\t}\n\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\thash, err := w.deleteFromIndex(idx, from)\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\tif err := w.Filesystem.Rename(from, to); err != nil {\n\t\treturn hash, err\n\t}\n\n\tif err := w.addOrUpdateFileToIndex(idx, to, hash); err != nil {\n\t\treturn hash, err\n\t}\n\n\treturn hash, w.r.Storer.SetIndex(idx)\n}\n"
        },
        {
          "name": "worktree_status_test.go",
          "type": "blob",
          "size": 2.3837890625,
          "content": "package git\n\nimport (\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/go-git/go-billy/v5/osfs\"\n\t\"github.com/go-git/go-git/v5/plumbing/cache\"\n\t\"github.com/go-git/go-git/v5/storage/filesystem\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n)\n\n// For additional context: #1159.\nfunc TestIndexEntrySizeUpdatedForNonRegularFiles(t *testing.T) {\n\tw := osfs.New(t.TempDir(), osfs.WithBoundOS())\n\tdot, err := w.Chroot(GitDirName)\n\trequire.NoError(t, err)\n\n\ts := filesystem.NewStorage(dot, cache.NewObjectLRUDefault())\n\tr, err := Init(s, w)\n\trequire.NoError(t, err)\n\trequire.NotNil(t, r)\n\n\twt, err := r.Worktree()\n\trequire.NoError(t, err)\n\trequire.NotNil(t, wt)\n\n\tfile := \"LICENSE\"\n\tf, err := w.OpenFile(file, os.O_CREATE|os.O_WRONLY, 0o666)\n\trequire.NoError(t, err)\n\trequire.NotNil(t, f)\n\n\tcontent := []byte(strings.Repeat(\"a\\n\", 1000))\n\t_, err = f.Write(content)\n\trequire.NoError(t, err)\n\terr = f.Close()\n\trequire.NoError(t, err)\n\n\t_, err = wt.Add(file)\n\trequire.NoError(t, err)\n\n\t_, err = wt.Commit(\"add file\", &CommitOptions{})\n\trequire.NoError(t, err)\n\n\tst, err := wt.StatusWithOptions(StatusOptions{Strategy: Preload})\n\trequire.NoError(t, err)\n\tassert.Equal(t,\n\t\t&FileStatus{Worktree: Unmodified, Staging: Unmodified},\n\t\tst.File(file))\n\n\t// Make the file not regular. The same would apply to a transition\n\t// from regular file to symlink.\n\terr = os.Chmod(filepath.Join(w.Root(), file), 0o777)\n\trequire.NoError(t, err)\n\n\tf, err = w.OpenFile(file, os.O_APPEND|os.O_RDWR, 0o777)\n\trequire.NoError(t, err)\n\trequire.NotNil(t, f)\n\n\t_, err = f.Write([]byte(\"\\n\\n\"))\n\trequire.NoError(t, err)\n\terr = f.Close()\n\trequire.NoError(t, err)\n\n\t_, err = wt.Add(file)\n\tassert.NoError(t, err)\n\n\t// go-git's Status diverges from \"git status\", so this check does not\n\t// fail, even when the issue is present. As at this point \"git status\"\n\t// reports the unstaged file was modified while \"git diff\" would return\n\t// empty, as the files are the same but the index has the incorrect file\n\t// size.\n\tst, err = wt.StatusWithOptions(StatusOptions{Strategy: Preload})\n\tassert.NoError(t, err)\n\tassert.Equal(t,\n\t\t&FileStatus{Worktree: Unmodified, Staging: Modified},\n\t\tst.File(file))\n\n\tidx, err := wt.r.Storer.Index()\n\tassert.NoError(t, err)\n\trequire.NotNil(t, idx)\n\trequire.Len(t, idx.Entries, 1)\n\n\t// Check whether the index was updated with the two new line breaks.\n\tassert.Equal(t, uint32(len(content)+2), idx.Entries[0].Size)\n}\n"
        },
        {
          "name": "worktree_test.go",
          "type": "blob",
          "size": 81.3056640625,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"runtime\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\tfixtures \"github.com/go-git/go-git-fixtures/v4\"\n\t\"github.com/go-git/go-git/v5/config\"\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/plumbing/cache\"\n\t\"github.com/go-git/go-git/v5/plumbing/filemode\"\n\t\"github.com/go-git/go-git/v5/plumbing/format/gitignore\"\n\t\"github.com/go-git/go-git/v5/plumbing/format/index\"\n\t\"github.com/go-git/go-git/v5/plumbing/object\"\n\t\"github.com/go-git/go-git/v5/storage/filesystem\"\n\t\"github.com/go-git/go-git/v5/storage/memory\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/go-git/go-billy/v5\"\n\t\"github.com/go-git/go-billy/v5/memfs\"\n\t\"github.com/go-git/go-billy/v5/osfs\"\n\t\"github.com/go-git/go-billy/v5/util\"\n\t\"golang.org/x/text/unicode/norm\"\n\t. \"gopkg.in/check.v1\"\n)\n\nfunc defaultTestCommitOptions() *CommitOptions {\n\treturn &CommitOptions{\n\t\tAuthor: &object.Signature{Name: \"testuser\", Email: \"testemail\"},\n\t}\n}\n\ntype WorktreeSuite struct {\n\tBaseSuite\n}\n\nvar _ = Suite(&WorktreeSuite{})\n\nfunc (s *WorktreeSuite) SetUpTest(c *C) {\n\tf := fixtures.Basic().One()\n\ts.Repository = s.NewRepositoryWithEmptyWorktree(f)\n}\n\nfunc (s *WorktreeSuite) TestPullCheckout(c *C) {\n\tfs := memfs.New()\n\tr, _ := Init(memory.NewStorage(), fs)\n\tr.CreateRemote(&config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\terr = w.Pull(&PullOptions{})\n\tc.Assert(err, IsNil)\n\n\tfi, err := fs.ReadDir(\"\")\n\tc.Assert(err, IsNil)\n\tc.Assert(fi, HasLen, 8)\n}\n\nfunc (s *WorktreeSuite) TestPullFastForward(c *C) {\n\turl := c.MkDir()\n\n\tpath := fixtures.Basic().ByTag(\"worktree\").One().Worktree().Root()\n\n\tserver, err := PlainClone(url, false, &CloneOptions{\n\t\tURL: path,\n\t})\n\tc.Assert(err, IsNil)\n\n\tdir := c.MkDir()\n\n\tr, err := PlainClone(dir, false, &CloneOptions{\n\t\tURL: url,\n\t})\n\tc.Assert(err, IsNil)\n\n\tw, err := server.Worktree()\n\tc.Assert(err, IsNil)\n\terr = os.WriteFile(filepath.Join(url, \"foo\"), []byte(\"foo\"), 0755)\n\tc.Assert(err, IsNil)\n\tw.Add(\"foo\")\n\thash, err := w.Commit(\"foo\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(err, IsNil)\n\n\tw, err = r.Worktree()\n\tc.Assert(err, IsNil)\n\n\terr = w.Pull(&PullOptions{})\n\tc.Assert(err, IsNil)\n\n\thead, err := r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Hash(), Equals, hash)\n}\n\nfunc (s *WorktreeSuite) TestPullNonFastForward(c *C) {\n\turl := c.MkDir()\n\n\tpath := fixtures.Basic().ByTag(\"worktree\").One().Worktree().Root()\n\n\tserver, err := PlainClone(url, false, &CloneOptions{\n\t\tURL: path,\n\t})\n\tc.Assert(err, IsNil)\n\n\tdir := c.MkDir()\n\n\tr, err := PlainClone(dir, false, &CloneOptions{\n\t\tURL: url,\n\t})\n\tc.Assert(err, IsNil)\n\n\tw, err := server.Worktree()\n\tc.Assert(err, IsNil)\n\terr = os.WriteFile(filepath.Join(url, \"foo\"), []byte(\"foo\"), 0755)\n\tc.Assert(err, IsNil)\n\tw.Add(\"foo\")\n\t_, err = w.Commit(\"foo\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(err, IsNil)\n\n\tw, err = r.Worktree()\n\tc.Assert(err, IsNil)\n\terr = os.WriteFile(filepath.Join(dir, \"bar\"), []byte(\"bar\"), 0755)\n\tc.Assert(err, IsNil)\n\tw.Add(\"bar\")\n\t_, err = w.Commit(\"bar\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(err, IsNil)\n\n\terr = w.Pull(&PullOptions{})\n\tc.Assert(err, Equals, ErrNonFastForwardUpdate)\n}\n\nfunc (s *WorktreeSuite) TestPullUpdateReferencesIfNeeded(c *C) {\n\tr, _ := Init(memory.NewStorage(), memfs.New())\n\tr.CreateRemote(&config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\n\terr := r.Fetch(&FetchOptions{})\n\tc.Assert(err, IsNil)\n\n\t_, err = r.Reference(\"refs/heads/master\", false)\n\tc.Assert(err, NotNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\terr = w.Pull(&PullOptions{})\n\tc.Assert(err, IsNil)\n\n\thead, err := r.Reference(plumbing.HEAD, true)\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\tbranch, err := r.Reference(\"refs/heads/master\", false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\terr = w.Pull(&PullOptions{})\n\tc.Assert(err, Equals, NoErrAlreadyUpToDate)\n}\n\nfunc (s *WorktreeSuite) TestPullInSingleBranch(c *C) {\n\tr, _ := Init(memory.NewStorage(), memfs.New())\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL:          s.GetBasicLocalRepositoryURL(),\n\t\tSingleBranch: true,\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\terr = w.Pull(&PullOptions{})\n\tc.Assert(err, Equals, NoErrAlreadyUpToDate)\n\n\tbranch, err := r.Reference(\"refs/heads/master\", false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\t_, err = r.Reference(\"refs/remotes/foo/branch\", false)\n\tc.Assert(err, NotNil)\n\n\tstorage := r.Storer.(*memory.Storage)\n\tc.Assert(storage.Objects, HasLen, 28)\n}\n\nfunc (s *WorktreeSuite) TestPullProgress(c *C) {\n\tr, _ := Init(memory.NewStorage(), memfs.New())\n\n\tr.CreateRemote(&config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tbuf := bytes.NewBuffer(nil)\n\terr = w.Pull(&PullOptions{\n\t\tProgress: buf,\n\t})\n\n\tc.Assert(err, IsNil)\n\tc.Assert(buf.Len(), Not(Equals), 0)\n}\n\nfunc (s *WorktreeSuite) TestPullProgressWithRecursion(c *C) {\n\tif testing.Short() {\n\t\tc.Skip(\"skipping test in short mode.\")\n\t}\n\n\tpath := fixtures.ByTag(\"submodule\").One().Worktree().Root()\n\n\tdir := c.MkDir()\n\n\tr, _ := PlainInit(dir, false)\n\tr.CreateRemote(&config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{path},\n\t})\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\terr = w.Pull(&PullOptions{\n\t\tRecurseSubmodules: DefaultSubmoduleRecursionDepth,\n\t})\n\tc.Assert(err, IsNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Submodules, HasLen, 2)\n}\n\nfunc (s *RepositorySuite) TestPullAdd(c *C) {\n\tpath := fixtures.Basic().ByTag(\"worktree\").One().Worktree().Root()\n\n\tr, err := Clone(memory.NewStorage(), memfs.New(), &CloneOptions{\n\t\tURL: filepath.Join(path, \".git\"),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tstorage := r.Storer.(*memory.Storage)\n\tc.Assert(storage.Objects, HasLen, 28)\n\n\tbranch, err := r.Reference(\"refs/heads/master\", false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\tExecuteOnPath(c, path,\n\t\t\"touch foo\",\n\t\t\"git add foo\",\n\t\t\"git commit --no-gpg-sign -m foo foo\",\n\t)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\terr = w.Pull(&PullOptions{RemoteName: \"origin\"})\n\tc.Assert(err, IsNil)\n\n\t// the commit command has introduced a new commit, tree and blob\n\tc.Assert(storage.Objects, HasLen, 31)\n\n\tbranch, err = r.Reference(\"refs/heads/master\", false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash().String(), Not(Equals), \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n}\n\nfunc (s *WorktreeSuite) TestPullAlreadyUptodate(c *C) {\n\tpath := fixtures.Basic().ByTag(\"worktree\").One().Worktree().Root()\n\n\tfs := memfs.New()\n\tr, err := Clone(memory.NewStorage(), fs, &CloneOptions{\n\t\tURL: filepath.Join(path, \".git\"),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\terr = util.WriteFile(fs, \"bar\", []byte(\"bar\"), 0755)\n\tc.Assert(err, IsNil)\n\tw.Add(\"bar\")\n\t_, err = w.Commit(\"bar\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(err, IsNil)\n\n\terr = w.Pull(&PullOptions{})\n\tc.Assert(err, Equals, NoErrAlreadyUpToDate)\n}\n\nfunc (s *WorktreeSuite) TestPullDepth(c *C) {\n\tr, err := Clone(memory.NewStorage(), memfs.New(), &CloneOptions{\n\t\tURL:   fixtures.Basic().One().URL,\n\t\tDepth: 1,\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\terr = w.Pull(&PullOptions{})\n\tc.Assert(err, Equals, nil)\n}\n\nfunc (s *WorktreeSuite) TestPullAfterShallowClone(c *C) {\n\ttempDir := c.MkDir()\n\tremoteURL := filepath.Join(tempDir, \"remote\")\n\trepoDir := filepath.Join(tempDir, \"repo\")\n\n\tremote, err := PlainInit(remoteURL, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(remote, NotNil)\n\n\t_ = CommitNewFile(c, remote, \"File1\")\n\t_ = CommitNewFile(c, remote, \"File2\")\n\n\trepo, err := PlainClone(repoDir, false, &CloneOptions{\n\t\tURL:           remoteURL,\n\t\tDepth:         1,\n\t\tTags:          NoTags,\n\t\tSingleBranch:  true,\n\t\tReferenceName: \"master\",\n\t})\n\tc.Assert(err, IsNil)\n\n\t_ = CommitNewFile(c, remote, \"File3\")\n\t_ = CommitNewFile(c, remote, \"File4\")\n\n\tw, err := repo.Worktree()\n\tc.Assert(err, IsNil)\n\n\terr = w.Pull(&PullOptions{\n\t\tRemoteName:    DefaultRemoteName,\n\t\tSingleBranch:  true,\n\t\tReferenceName: plumbing.NewBranchReferenceName(\"master\"),\n\t})\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *WorktreeSuite) TestCheckout(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{\n\t\tForce: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tentries, err := fs.ReadDir(\"/\")\n\tc.Assert(err, IsNil)\n\n\tc.Assert(entries, HasLen, 8)\n\tch, err := fs.Open(\"CHANGELOG\")\n\tc.Assert(err, IsNil)\n\n\tcontent, err := io.ReadAll(ch)\n\tc.Assert(err, IsNil)\n\tc.Assert(string(content), Equals, \"Initial changelog\\n\")\n\n\tidx, err := s.Repository.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutForce(c *C) {\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: memfs.New(),\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tw.Filesystem = memfs.New()\n\n\terr = w.Checkout(&CheckoutOptions{\n\t\tForce: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tentries, err := w.Filesystem.ReadDir(\"/\")\n\tc.Assert(err, IsNil)\n\tc.Assert(entries, HasLen, 8)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutKeep(c *C) {\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: memfs.New(),\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{\n\t\tForce: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\t// Create a new branch and create a new file.\n\terr = w.Checkout(&CheckoutOptions{\n\t\tBranch: plumbing.NewBranchReferenceName(\"new-branch\"),\n\t\tCreate: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tw.Filesystem = memfs.New()\n\tf, err := w.Filesystem.Create(\"new-file.txt\")\n\tc.Assert(err, IsNil)\n\t_, err = f.Write([]byte(\"DUMMY\"))\n\tc.Assert(err, IsNil)\n\tc.Assert(f.Close(), IsNil)\n\n\t// Add the file to staging.\n\t_, err = w.Add(\"new-file.txt\")\n\tc.Assert(err, IsNil)\n\n\t// Switch branch to master, and verify that the new file was kept in staging.\n\terr = w.Checkout(&CheckoutOptions{\n\t\tKeep: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tfi, err := w.Filesystem.Stat(\"new-file.txt\")\n\tc.Assert(err, IsNil)\n\tc.Assert(fi.Size(), Equals, int64(5))\n}\n\nfunc (s *WorktreeSuite) TestCheckoutSymlink(c *C) {\n\tif runtime.GOOS == \"windows\" {\n\t\tc.Skip(\"git doesn't support symlinks by default in windows\")\n\t}\n\n\tdir := c.MkDir()\n\n\tr, err := PlainInit(dir, false)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tw.Filesystem.Symlink(\"not-exists\", \"bar\")\n\tw.Add(\"bar\")\n\tw.Commit(\"foo\", &CommitOptions{Author: defaultSignature()})\n\n\tr.Storer.SetIndex(&index.Index{Version: 2})\n\tw.Filesystem = osfs.New(filepath.Join(dir, \"worktree-empty\"))\n\n\terr = w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n\n\ttarget, err := w.Filesystem.Readlink(\"bar\")\n\tc.Assert(target, Equals, \"not-exists\")\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutSparse(c *C) {\n\tfs := memfs.New()\n\tr, err := Clone(memory.NewStorage(), fs, &CloneOptions{\n\t\tURL:        s.GetBasicLocalRepositoryURL(),\n\t\tNoCheckout: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tsparseCheckoutDirectories := []string{\"go\", \"json\", \"php\"}\n\tc.Assert(w.Checkout(&CheckoutOptions{\n\t\tSparseCheckoutDirectories: sparseCheckoutDirectories,\n\t}), IsNil)\n\n\tfis, err := fs.ReadDir(\"/\")\n\tc.Assert(err, IsNil)\n\n\tfor _, fi := range fis {\n\t\tc.Assert(fi.IsDir(), Equals, true)\n\t\tvar oneOfSparseCheckoutDirs bool\n\n\t\tfor _, sparseCheckoutDirectory := range sparseCheckoutDirectories {\n\t\t\tif strings.HasPrefix(fi.Name(), sparseCheckoutDirectory) {\n\t\t\t\toneOfSparseCheckoutDirs = true\n\t\t\t}\n\t\t}\n\t\tc.Assert(oneOfSparseCheckoutDirs, Equals, true)\n\t}\n}\n\nfunc (s *WorktreeSuite) TestFilenameNormalization(c *C) {\n\tif runtime.GOOS == \"windows\" {\n\t\tc.Skip(\"windows paths may contain non utf-8 sequences\")\n\t}\n\n\turl := c.MkDir()\n\n\tpath := fixtures.Basic().ByTag(\"worktree\").One().Worktree().Root()\n\n\tserver, err := PlainClone(url, false, &CloneOptions{\n\t\tURL: path,\n\t})\n\tc.Assert(err, IsNil)\n\n\tfilename := \"페\"\n\n\tw, err := server.Worktree()\n\tc.Assert(err, IsNil)\n\n\twriteFile := func(path string) {\n\t\terr := util.WriteFile(w.Filesystem, path, []byte(\"foo\"), 0755)\n\t\tc.Assert(err, IsNil)\n\t}\n\n\twriteFile(filename)\n\torigHash, err := w.Add(filename)\n\tc.Assert(err, IsNil)\n\t_, err = w.Commit(\"foo\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(err, IsNil)\n\n\tr, err := Clone(memory.NewStorage(), memfs.New(), &CloneOptions{\n\t\tURL: url,\n\t})\n\tc.Assert(err, IsNil)\n\n\tw, err = r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n\n\terr = w.Filesystem.Remove(filename)\n\tc.Assert(err, IsNil)\n\n\tmodFilename := norm.NFKD.String(filename)\n\twriteFile(modFilename)\n\n\t_, err = w.Add(filename)\n\tc.Assert(err, IsNil)\n\tmodHash, err := w.Add(modFilename)\n\tc.Assert(err, IsNil)\n\t// At this point we've got two files with the same content.\n\t// Hence their hashes must be the same.\n\tc.Assert(origHash == modHash, Equals, true)\n\n\tstatus, err = w.Status()\n\tc.Assert(err, IsNil)\n\t// However, their names are different and the work tree is still dirty.\n\tc.Assert(status.IsClean(), Equals, false)\n\n\t// Revert back the deletion of the first file.\n\twriteFile(filename)\n\t_, err = w.Add(filename)\n\tc.Assert(err, IsNil)\n\n\tstatus, err = w.Status()\n\tc.Assert(err, IsNil)\n\t// Still dirty - the second file is added.\n\tc.Assert(status.IsClean(), Equals, false)\n\n\t_, err = w.Remove(modFilename)\n\tc.Assert(err, IsNil)\n\n\tstatus, err = w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutSubmodule(c *C) {\n\turl := \"https://github.com/git-fixtures/submodule.git\"\n\tr := s.NewRepositoryWithEmptyWorktree(fixtures.ByURL(url).One())\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\terr = w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutSubmoduleInitialized(c *C) {\n\turl := \"https://github.com/git-fixtures/submodule.git\"\n\tr := s.NewRepository(fixtures.ByURL(url).One())\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tsub, err := w.Submodules()\n\tc.Assert(err, IsNil)\n\n\terr = sub.Update(&SubmoduleUpdateOptions{Init: true})\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutRelativePathSubmoduleInitialized(c *C) {\n\turl := \"https://github.com/git-fixtures/submodule.git\"\n\tr := s.NewRepository(fixtures.ByURL(url).One())\n\n\t// modify the .gitmodules from original one\n\tfile, err := r.wt.OpenFile(\".gitmodules\", os.O_WRONLY|os.O_TRUNC, 0666)\n\tc.Assert(err, IsNil)\n\n\tn, err := io.WriteString(file, `[submodule \"basic\"]\n\tpath = basic\n\turl = ../basic.git\n[submodule \"itself\"]\n\tpath = itself\n\turl = ../submodule.git`)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Not(Equals), 0)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tw.Add(\".gitmodules\")\n\tw.Commit(\"test\", &CommitOptions{})\n\n\t// test submodule path\n\tmodules, err := w.readGitmodulesFile()\n\tc.Assert(err, IsNil)\n\n\tc.Assert(modules.Submodules[\"basic\"].URL, Equals, \"../basic.git\")\n\tc.Assert(modules.Submodules[\"itself\"].URL, Equals, \"../submodule.git\")\n\n\tbasicSubmodule, err := w.Submodule(\"basic\")\n\tc.Assert(err, IsNil)\n\tbasicRepo, err := basicSubmodule.Repository()\n\tc.Assert(err, IsNil)\n\tbasicRemotes, err := basicRepo.Remotes()\n\tc.Assert(err, IsNil)\n\tc.Assert(basicRemotes[0].Config().URLs[0], Equals, \"https://github.com/git-fixtures/basic.git\")\n\n\titselfSubmodule, err := w.Submodule(\"itself\")\n\tc.Assert(err, IsNil)\n\titselfRepo, err := itselfSubmodule.Repository()\n\tc.Assert(err, IsNil)\n\titselfRemotes, err := itselfRepo.Remotes()\n\tc.Assert(err, IsNil)\n\tc.Assert(itselfRemotes[0].Config().URLs[0], Equals, \"https://github.com/git-fixtures/submodule.git\")\n\n\tsub, err := w.Submodules()\n\tc.Assert(err, IsNil)\n\n\terr = sub.Update(&SubmoduleUpdateOptions{Init: true, RecurseSubmodules: DefaultSubmoduleRecursionDepth})\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutIndexMem(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tidx, err := s.Repository.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\tc.Assert(idx.Entries[0].Hash.String(), Equals, \"32858aad3c383ed1ff0a0f9bdf231d54a00c9e88\")\n\tc.Assert(idx.Entries[0].Name, Equals, \".gitignore\")\n\tc.Assert(idx.Entries[0].Mode, Equals, filemode.Regular)\n\tc.Assert(idx.Entries[0].ModifiedAt.IsZero(), Equals, false)\n\tc.Assert(idx.Entries[0].Size, Equals, uint32(189))\n\n\t// ctime, dev, inode, uid and gid are not supported on memfs fs\n\tc.Assert(idx.Entries[0].CreatedAt.IsZero(), Equals, true)\n\tc.Assert(idx.Entries[0].Dev, Equals, uint32(0))\n\tc.Assert(idx.Entries[0].Inode, Equals, uint32(0))\n\tc.Assert(idx.Entries[0].UID, Equals, uint32(0))\n\tc.Assert(idx.Entries[0].GID, Equals, uint32(0))\n}\n\nfunc (s *WorktreeSuite) TestCheckoutIndexOS(c *C) {\n\tfs := s.TemporalFilesystem(c)\n\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tidx, err := s.Repository.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\tc.Assert(idx.Entries[0].Hash.String(), Equals, \"32858aad3c383ed1ff0a0f9bdf231d54a00c9e88\")\n\tc.Assert(idx.Entries[0].Name, Equals, \".gitignore\")\n\tc.Assert(idx.Entries[0].Mode, Equals, filemode.Regular)\n\tc.Assert(idx.Entries[0].ModifiedAt.IsZero(), Equals, false)\n\tc.Assert(idx.Entries[0].Size, Equals, uint32(189))\n\n\tc.Assert(idx.Entries[0].CreatedAt.IsZero(), Equals, false)\n\tif runtime.GOOS != \"windows\" {\n\t\tc.Assert(idx.Entries[0].Dev, Not(Equals), uint32(0))\n\t\tc.Assert(idx.Entries[0].Inode, Not(Equals), uint32(0))\n\t\tc.Assert(idx.Entries[0].UID, Not(Equals), uint32(0))\n\t\tc.Assert(idx.Entries[0].GID, Not(Equals), uint32(0))\n\t}\n}\n\nfunc (s *WorktreeSuite) TestCheckoutBranch(c *C) {\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: memfs.New(),\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{\n\t\tBranch: \"refs/heads/branch\",\n\t})\n\tc.Assert(err, IsNil)\n\n\thead, err := w.r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Name().String(), Equals, \"refs/heads/branch\")\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutCreateWithHash(c *C) {\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: memfs.New(),\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{\n\t\tCreate: true,\n\t\tBranch: \"refs/heads/foo\",\n\t\tHash:   plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t})\n\tc.Assert(err, IsNil)\n\n\thead, err := w.r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Name().String(), Equals, \"refs/heads/foo\")\n\tc.Assert(head.Hash(), Equals, plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"))\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutCreate(c *C) {\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: memfs.New(),\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{\n\t\tCreate: true,\n\t\tBranch: \"refs/heads/foo\",\n\t})\n\tc.Assert(err, IsNil)\n\n\thead, err := w.r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Name().String(), Equals, \"refs/heads/foo\")\n\tc.Assert(head.Hash(), Equals, plumbing.NewHash(\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"))\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutBranchAndHash(c *C) {\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: memfs.New(),\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{\n\t\tBranch: \"refs/heads/foo\",\n\t\tHash:   plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t})\n\n\tc.Assert(err, Equals, ErrBranchHashExclusive)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutCreateMissingBranch(c *C) {\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: memfs.New(),\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{\n\t\tCreate: true,\n\t})\n\n\tc.Assert(err, Equals, ErrCreateRequiresBranch)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutCreateInvalidBranch(c *C) {\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: memfs.New(),\n\t}\n\n\tfor _, name := range []plumbing.ReferenceName{\n\t\t\"foo\",\n\t\t\"-\",\n\t\t\"-foo\",\n\t\t\"refs/heads//\",\n\t\t\"refs/heads/..\",\n\t\t\"refs/heads/a..b\",\n\t\t\"refs/heads/.\",\n\t} {\n\t\terr := w.Checkout(&CheckoutOptions{\n\t\t\tCreate: true,\n\t\t\tBranch: name,\n\t\t})\n\n\t\tc.Assert(err, Equals, plumbing.ErrInvalidReferenceName)\n\t}\n}\n\nfunc (s *WorktreeSuite) TestCheckoutTag(c *C) {\n\tf := fixtures.ByTag(\"tags\").One()\n\tr := s.NewRepositoryWithEmptyWorktree(f)\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\terr = w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\thead, err := w.r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Name().String(), Equals, \"refs/heads/master\")\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n\n\terr = w.Checkout(&CheckoutOptions{Branch: \"refs/tags/lightweight-tag\"})\n\tc.Assert(err, IsNil)\n\thead, err = w.r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Name().String(), Equals, \"HEAD\")\n\tc.Assert(head.Hash().String(), Equals, \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\")\n\n\terr = w.Checkout(&CheckoutOptions{Branch: \"refs/tags/commit-tag\"})\n\tc.Assert(err, IsNil)\n\thead, err = w.r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Name().String(), Equals, \"HEAD\")\n\tc.Assert(head.Hash().String(), Equals, \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\")\n\n\terr = w.Checkout(&CheckoutOptions{Branch: \"refs/tags/tree-tag\"})\n\tc.Assert(err, NotNil)\n\thead, err = w.r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Name().String(), Equals, \"HEAD\")\n}\n\nfunc (s *WorktreeSuite) TestCheckoutTagHash(c *C) {\n\tf := fixtures.ByTag(\"tags\").One()\n\tr := s.NewRepositoryWithEmptyWorktree(f)\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tfor _, hash := range []string{\n\t\t\"b742a2a9fa0afcfa9a6fad080980fbc26b007c69\", // annotated tag\n\t\t\"ad7897c0fb8e7d9a9ba41fa66072cf06095a6cfc\", // commit tag\n\t\t\"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\", // lightweight tag\n\t} {\n\t\terr = w.Checkout(&CheckoutOptions{\n\t\t\tHash: plumbing.NewHash(hash),\n\t\t})\n\t\tc.Assert(err, IsNil)\n\t\thead, err := w.r.Head()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(head.Name().String(), Equals, \"HEAD\")\n\n\t\tstatus, err := w.Status()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(status.IsClean(), Equals, true)\n\t}\n\n\tfor _, hash := range []string{\n\t\t\"fe6cb94756faa81e5ed9240f9191b833db5f40ae\", // blob tag\n\t\t\"152175bf7e5580299fa1f0ba41ef6474cc043b70\", // tree tag\n\t} {\n\t\terr = w.Checkout(&CheckoutOptions{\n\t\t\tHash: plumbing.NewHash(hash),\n\t\t})\n\t\tc.Assert(err, NotNil)\n\t}\n}\n\nfunc (s *WorktreeSuite) TestCheckoutBisect(c *C) {\n\tif testing.Short() {\n\t\tc.Skip(\"skipping test in short mode.\")\n\t}\n\n\ts.testCheckoutBisect(c, \"https://github.com/src-d/go-git.git\")\n}\n\nfunc (s *WorktreeSuite) TestCheckoutBisectSubmodules(c *C) {\n\ts.testCheckoutBisect(c, \"https://github.com/git-fixtures/submodule.git\")\n}\n\n// TestCheckoutBisect simulates a git bisect going through the git history and\n// checking every commit over the previous commit\nfunc (s *WorktreeSuite) testCheckoutBisect(c *C, url string) {\n\tf := fixtures.ByURL(url).One()\n\tr := s.NewRepositoryWithEmptyWorktree(f)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\titer, err := w.r.Log(&LogOptions{})\n\tc.Assert(err, IsNil)\n\n\titer.ForEach(func(commit *object.Commit) error {\n\t\terr := w.Checkout(&CheckoutOptions{Hash: commit.Hash})\n\t\tc.Assert(err, IsNil)\n\n\t\tstatus, err := w.Status()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(status.IsClean(), Equals, true)\n\n\t\treturn nil\n\t})\n}\n\nfunc (s *WorktreeSuite) TestStatus(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\n\tc.Assert(status.IsClean(), Equals, false)\n\tc.Assert(status, HasLen, 9)\n}\n\nfunc (s *WorktreeSuite) TestStatusEmpty(c *C) {\n\tfs := memfs.New()\n\tstorage := memory.NewStorage()\n\n\tr, err := Init(storage, fs)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n\tc.Assert(status, NotNil)\n}\n\nfunc (s *WorktreeSuite) TestStatusCheckedInBeforeIgnored(c *C) {\n\tfs := memfs.New()\n\tstorage := memory.NewStorage()\n\n\tr, err := Init(storage, fs)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(fs, \"fileToIgnore\", []byte(\"Initial data\"), 0755)\n\tc.Assert(err, IsNil)\n\t_, err = w.Add(\"fileToIgnore\")\n\tc.Assert(err, IsNil)\n\n\t_, err = w.Commit(\"Added file that will be ignored later\", defaultTestCommitOptions())\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(fs, \".gitignore\", []byte(\"fileToIgnore\\nsecondIgnoredFile\"), 0755)\n\tc.Assert(err, IsNil)\n\t_, err = w.Add(\".gitignore\")\n\tc.Assert(err, IsNil)\n\t_, err = w.Commit(\"Added .gitignore\", defaultTestCommitOptions())\n\tc.Assert(err, IsNil)\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n\tc.Assert(status, NotNil)\n\n\terr = util.WriteFile(fs, \"secondIgnoredFile\", []byte(\"Should be completely ignored\"), 0755)\n\tc.Assert(err, IsNil)\n\tstatus = nil\n\tstatus, err = w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n\tc.Assert(status, NotNil)\n\n\terr = util.WriteFile(fs, \"fileToIgnore\", []byte(\"Updated data\"), 0755)\n\tc.Assert(err, IsNil)\n\tstatus = nil\n\tstatus, err = w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, false)\n\tc.Assert(status, NotNil)\n}\n\nfunc (s *WorktreeSuite) TestStatusEmptyDirty(c *C) {\n\tfs := memfs.New()\n\terr := util.WriteFile(fs, \"foo\", []byte(\"foo\"), 0755)\n\tc.Assert(err, IsNil)\n\n\tstorage := memory.NewStorage()\n\n\tr, err := Init(storage, fs)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, false)\n\tc.Assert(status, HasLen, 1)\n}\n\nfunc (s *WorktreeSuite) TestStatusUnmodified(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.StatusWithOptions(StatusOptions{Strategy: Preload})\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n\tc.Assert(status.IsUntracked(\"LICENSE\"), Equals, false)\n\n\tc.Assert(status.File(\"LICENSE\").Staging, Equals, Unmodified)\n\tc.Assert(status.File(\"LICENSE\").Worktree, Equals, Unmodified)\n\n\tstatus, err = w.StatusWithOptions(StatusOptions{Strategy: Empty})\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n\tc.Assert(status.IsUntracked(\"LICENSE\"), Equals, false)\n\n\tc.Assert(status.File(\"LICENSE\").Staging, Equals, Untracked)\n\tc.Assert(status.File(\"LICENSE\").Worktree, Equals, Untracked)\n}\n\nfunc (s *WorktreeSuite) TestReset(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\tcommit := plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\")\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tbranch, err := w.r.Reference(plumbing.Master, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash(), Not(Equals), commit)\n\n\terr = w.Reset(&ResetOptions{Mode: MergeReset, Commit: commit})\n\tc.Assert(err, IsNil)\n\n\tbranch, err = w.r.Reference(plumbing.Master, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash(), Equals, commit)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestResetWithUntracked(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\tcommit := plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\")\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(fs, \"foo\", nil, 0755)\n\tc.Assert(err, IsNil)\n\n\terr = w.Reset(&ResetOptions{Mode: MergeReset, Commit: commit})\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestResetSoft(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\tcommit := plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\")\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\terr = w.Reset(&ResetOptions{Mode: SoftReset, Commit: commit})\n\tc.Assert(err, IsNil)\n\n\tbranch, err := w.r.Reference(plumbing.Master, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash(), Equals, commit)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, false)\n\tc.Assert(status.File(\"CHANGELOG\").Staging, Equals, Added)\n}\n\nfunc (s *WorktreeSuite) TestResetMixed(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\tcommit := plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\")\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\terr = w.Reset(&ResetOptions{Mode: MixedReset, Commit: commit})\n\tc.Assert(err, IsNil)\n\n\tbranch, err := w.r.Reference(plumbing.Master, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash(), Equals, commit)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, false)\n\tc.Assert(status.File(\"CHANGELOG\").Staging, Equals, Untracked)\n}\n\nfunc (s *WorktreeSuite) TestResetMerge(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\tcommitA := plumbing.NewHash(\"918c48b83bd081e863dbe1b80f8998f058cd8294\")\n\tcommitB := plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\")\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\terr = w.Reset(&ResetOptions{Mode: MergeReset, Commit: commitA})\n\tc.Assert(err, IsNil)\n\n\tbranch, err := w.r.Reference(plumbing.Master, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash(), Equals, commitA)\n\n\tf, err := fs.Create(\".gitignore\")\n\tc.Assert(err, IsNil)\n\t_, err = f.Write([]byte(\"foo\"))\n\tc.Assert(err, IsNil)\n\terr = f.Close()\n\tc.Assert(err, IsNil)\n\n\terr = w.Reset(&ResetOptions{Mode: MergeReset, Commit: commitB})\n\tc.Assert(err, Equals, ErrUnstagedChanges)\n\n\tbranch, err = w.r.Reference(plumbing.Master, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash(), Equals, commitA)\n}\n\nfunc (s *WorktreeSuite) TestResetHard(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\tcommit := plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\")\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tf, err := fs.Create(\".gitignore\")\n\tc.Assert(err, IsNil)\n\t_, err = f.Write([]byte(\"foo\"))\n\tc.Assert(err, IsNil)\n\terr = f.Close()\n\tc.Assert(err, IsNil)\n\n\terr = w.Reset(&ResetOptions{Mode: HardReset, Commit: commit})\n\tc.Assert(err, IsNil)\n\n\tbranch, err := w.r.Reference(plumbing.Master, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash(), Equals, commit)\n}\n\nfunc (s *WorktreeSuite) TestResetHardSubFolders(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\terr = fs.MkdirAll(\"dir\", os.ModePerm)\n\tc.Assert(err, IsNil)\n\ttf, err := fs.Create(\"dir/testfile.txt\")\n\tc.Assert(err, IsNil)\n\t_, err = tf.Write([]byte(\"testfile content\"))\n\tc.Assert(err, IsNil)\n\terr = tf.Close()\n\tc.Assert(err, IsNil)\n\t_, err = w.Add(\"dir/testfile.txt\")\n\tc.Assert(err, IsNil)\n\t_, err = w.Commit(\"testcommit\", &CommitOptions{Author: &object.Signature{Name: \"name\", Email: \"email\"}})\n\tc.Assert(err, IsNil)\n\n\terr = fs.Remove(\"dir/testfile.txt\")\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, false)\n\n\terr = w.Reset(&ResetOptions{Files: []string{\"dir/testfile.txt\"}, Mode: HardReset})\n\tc.Assert(err, IsNil)\n\n\tstatus, err = w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestResetHardWithGitIgnore(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\ttf, err := fs.Create(\"newTestFile.txt\")\n\tc.Assert(err, IsNil)\n\t_, err = tf.Write([]byte(\"testfile content\"))\n\tc.Assert(err, IsNil)\n\terr = tf.Close()\n\tc.Assert(err, IsNil)\n\t_, err = w.Add(\"newTestFile.txt\")\n\tc.Assert(err, IsNil)\n\t_, err = w.Commit(\"testcommit\", &CommitOptions{Author: &object.Signature{Name: \"name\", Email: \"email\"}})\n\tc.Assert(err, IsNil)\n\n\terr = fs.Remove(\"newTestFile.txt\")\n\tc.Assert(err, IsNil)\n\tf, err := fs.Create(\".gitignore\")\n\tc.Assert(err, IsNil)\n\t_, err = f.Write([]byte(\"foo\\n\"))\n\tc.Assert(err, IsNil)\n\t_, err = f.Write([]byte(\"newTestFile.txt\\n\"))\n\tc.Assert(err, IsNil)\n\terr = f.Close()\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, false)\n\n\terr = w.Reset(&ResetOptions{Mode: HardReset})\n\tc.Assert(err, IsNil)\n\n\tstatus, err = w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestResetSparsely(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\tsparseResetDirs := []string{\"php\"}\n\n\terr := w.ResetSparsely(&ResetOptions{Mode: HardReset}, sparseResetDirs)\n\tc.Assert(err, IsNil)\n\n\tfiles, err := fs.ReadDir(\"/\")\n\tc.Assert(err, IsNil)\n\tc.Assert(files, HasLen, 1)\n\tc.Assert(files[0].Name(), Equals, \"php\")\n\n\tfiles, err = fs.ReadDir(\"/php\")\n\tc.Assert(err, IsNil)\n\tc.Assert(files, HasLen, 1)\n\tc.Assert(files[0].Name(), Equals, \"crappy.php\")\n}\n\nfunc (s *WorktreeSuite) TestStatusAfterCheckout(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n\n}\n\nfunc (s *WorktreeSuite) TestStatusModified(c *C) {\n\tfs := s.TemporalFilesystem(c)\n\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tf, err := fs.Create(\".gitignore\")\n\tc.Assert(err, IsNil)\n\t_, err = f.Write([]byte(\"foo\"))\n\tc.Assert(err, IsNil)\n\terr = f.Close()\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, false)\n\tc.Assert(status.File(\".gitignore\").Worktree, Equals, Modified)\n}\n\nfunc (s *WorktreeSuite) TestStatusIgnored(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\tw.Checkout(&CheckoutOptions{})\n\n\tfs.MkdirAll(\"another\", os.ModePerm)\n\tf, _ := fs.Create(\"another/file\")\n\tf.Close()\n\tfs.MkdirAll(\"vendor/github.com\", os.ModePerm)\n\tf, _ = fs.Create(\"vendor/github.com/file\")\n\tf.Close()\n\tfs.MkdirAll(\"vendor/gopkg.in\", os.ModePerm)\n\tf, _ = fs.Create(\"vendor/gopkg.in/file\")\n\tf.Close()\n\n\tstatus, _ := w.Status()\n\tc.Assert(len(status), Equals, 3)\n\t_, ok := status[\"another/file\"]\n\tc.Assert(ok, Equals, true)\n\t_, ok = status[\"vendor/github.com/file\"]\n\tc.Assert(ok, Equals, true)\n\t_, ok = status[\"vendor/gopkg.in/file\"]\n\tc.Assert(ok, Equals, true)\n\n\tf, _ = fs.Create(\".gitignore\")\n\tf.Write([]byte(\"vendor/g*/\"))\n\tf.Close()\n\tf, _ = fs.Create(\"vendor/.gitignore\")\n\tf.Write([]byte(\"!github.com/\\n\"))\n\tf.Close()\n\n\tstatus, _ = w.Status()\n\tc.Assert(len(status), Equals, 4)\n\t_, ok = status[\".gitignore\"]\n\tc.Assert(ok, Equals, true)\n\t_, ok = status[\"another/file\"]\n\tc.Assert(ok, Equals, true)\n\t_, ok = status[\"vendor/.gitignore\"]\n\tc.Assert(ok, Equals, true)\n\t_, ok = status[\"vendor/github.com/file\"]\n\tc.Assert(ok, Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestStatusUntracked(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tf, err := w.Filesystem.Create(\"foo\")\n\tc.Assert(err, IsNil)\n\tc.Assert(f.Close(), IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.File(\"foo\").Staging, Equals, Untracked)\n\tc.Assert(status.File(\"foo\").Worktree, Equals, Untracked)\n}\n\nfunc (s *WorktreeSuite) TestStatusDeleted(c *C) {\n\tfs := s.TemporalFilesystem(c)\n\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\terr = fs.Remove(\".gitignore\")\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, false)\n\tc.Assert(status.File(\".gitignore\").Worktree, Equals, Deleted)\n}\n\nfunc (s *WorktreeSuite) TestSubmodule(c *C) {\n\tpath := fixtures.ByTag(\"submodule\").One().Worktree().Root()\n\tr, err := PlainOpen(path)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tm, err := w.Submodule(\"basic\")\n\tc.Assert(err, IsNil)\n\n\tc.Assert(m.Config().Name, Equals, \"basic\")\n}\n\nfunc (s *WorktreeSuite) TestSubmodules(c *C) {\n\tpath := fixtures.ByTag(\"submodule\").One().Worktree().Root()\n\tr, err := PlainOpen(path)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tl, err := w.Submodules()\n\tc.Assert(err, IsNil)\n\n\tc.Assert(l, HasLen, 2)\n}\n\nfunc (s *WorktreeSuite) TestAddUntracked(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err := w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\terr = util.WriteFile(w.Filesystem, \"foo\", []byte(\"FOO\"), 0755)\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Add(\"foo\")\n\tc.Assert(hash.String(), Equals, \"d96c7efbfec2814ae0301ad054dc8d9fc416c9b5\")\n\tc.Assert(err, IsNil)\n\n\tidx, err = w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 10)\n\n\te, err := idx.Entry(\"foo\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Hash, Equals, hash)\n\tc.Assert(e.Mode, Equals, filemode.Executable)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 1)\n\n\tfile := status.File(\"foo\")\n\tc.Assert(file.Staging, Equals, Added)\n\tc.Assert(file.Worktree, Equals, Unmodified)\n\n\tobj, err := w.r.Storer.EncodedObject(plumbing.BlobObject, hash)\n\tc.Assert(err, IsNil)\n\tc.Assert(obj, NotNil)\n\tc.Assert(obj.Size(), Equals, int64(3))\n}\n\nfunc (s *WorktreeSuite) TestIgnored(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\tw.Excludes = make([]gitignore.Pattern, 0)\n\tw.Excludes = append(w.Excludes, gitignore.ParsePattern(\"foo\", nil))\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err := w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\terr = util.WriteFile(w.Filesystem, \"foo\", []byte(\"FOO\"), 0755)\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 0)\n\n\tfile := status.File(\"foo\")\n\tc.Assert(file.Staging, Equals, Untracked)\n\tc.Assert(file.Worktree, Equals, Untracked)\n}\n\nfunc (s *WorktreeSuite) TestExcludedNoGitignore(c *C) {\n\tf := fixtures.ByTag(\"empty\").One()\n\tr := s.NewRepository(f)\n\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          r,\n\t\tFilesystem: fs,\n\t}\n\n\t_, err := fs.Open(\".gitignore\")\n\tc.Assert(err, Equals, os.ErrNotExist)\n\n\tw.Excludes = make([]gitignore.Pattern, 0)\n\tw.Excludes = append(w.Excludes, gitignore.ParsePattern(\"foo\", nil))\n\n\terr = util.WriteFile(w.Filesystem, \"foo\", []byte(\"FOO\"), 0755)\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 0)\n\n\tfile := status.File(\"foo\")\n\tc.Assert(file.Staging, Equals, Untracked)\n\tc.Assert(file.Worktree, Equals, Untracked)\n}\n\nfunc (s *WorktreeSuite) TestAddModified(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err := w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\terr = util.WriteFile(w.Filesystem, \"LICENSE\", []byte(\"FOO\"), 0644)\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Add(\"LICENSE\")\n\tc.Assert(err, IsNil)\n\tc.Assert(hash.String(), Equals, \"d96c7efbfec2814ae0301ad054dc8d9fc416c9b5\")\n\n\tidx, err = w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\te, err := idx.Entry(\"LICENSE\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Hash, Equals, hash)\n\tc.Assert(e.Mode, Equals, filemode.Regular)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 1)\n\n\tfile := status.File(\"LICENSE\")\n\tc.Assert(file.Staging, Equals, Modified)\n\tc.Assert(file.Worktree, Equals, Unmodified)\n}\n\nfunc (s *WorktreeSuite) TestAddUnmodified(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Add(\"LICENSE\")\n\tc.Assert(hash.String(), Equals, \"c192bd6a24ea1ab01d78686e417c8bdc7c3d197f\")\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *WorktreeSuite) TestAddRemoved(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err := w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\terr = w.Filesystem.Remove(\"LICENSE\")\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Add(\"LICENSE\")\n\tc.Assert(err, IsNil)\n\tc.Assert(hash.String(), Equals, \"c192bd6a24ea1ab01d78686e417c8bdc7c3d197f\")\n\n\te, err := idx.Entry(\"LICENSE\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Hash, Equals, hash)\n\tc.Assert(e.Mode, Equals, filemode.Regular)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 1)\n\n\tfile := status.File(\"LICENSE\")\n\tc.Assert(file.Staging, Equals, Deleted)\n}\n\nfunc (s *WorktreeSuite) TestAddRemovedInDirectory(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err := w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\terr = w.Filesystem.Remove(\"go/example.go\")\n\tc.Assert(err, IsNil)\n\n\terr = w.Filesystem.Remove(\"json/short.json\")\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Add(\"go\")\n\tc.Assert(err, IsNil)\n\tc.Assert(hash.IsZero(), Equals, true)\n\n\te, err := idx.Entry(\"go/example.go\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Hash, Equals, plumbing.NewHash(\"880cd14280f4b9b6ed3986d6671f907d7cc2a198\"))\n\tc.Assert(e.Mode, Equals, filemode.Regular)\n\n\te, err = idx.Entry(\"json/short.json\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Hash, Equals, plumbing.NewHash(\"c8f1d8c61f9da76f4cb49fd86322b6e685dba956\"))\n\tc.Assert(e.Mode, Equals, filemode.Regular)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 2)\n\n\tfile := status.File(\"go/example.go\")\n\tc.Assert(file.Staging, Equals, Deleted)\n\n\tfile = status.File(\"json/short.json\")\n\tc.Assert(file.Staging, Equals, Unmodified)\n}\n\nfunc (s *WorktreeSuite) TestAddRemovedInDirectoryWithTrailingSlash(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err := w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\terr = w.Filesystem.Remove(\"go/example.go\")\n\tc.Assert(err, IsNil)\n\n\terr = w.Filesystem.Remove(\"json/short.json\")\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Add(\"go/\")\n\tc.Assert(err, IsNil)\n\tc.Assert(hash.IsZero(), Equals, true)\n\n\te, err := idx.Entry(\"go/example.go\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Hash, Equals, plumbing.NewHash(\"880cd14280f4b9b6ed3986d6671f907d7cc2a198\"))\n\tc.Assert(e.Mode, Equals, filemode.Regular)\n\n\te, err = idx.Entry(\"json/short.json\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Hash, Equals, plumbing.NewHash(\"c8f1d8c61f9da76f4cb49fd86322b6e685dba956\"))\n\tc.Assert(e.Mode, Equals, filemode.Regular)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 2)\n\n\tfile := status.File(\"go/example.go\")\n\tc.Assert(file.Staging, Equals, Deleted)\n\n\tfile = status.File(\"json/short.json\")\n\tc.Assert(file.Staging, Equals, Unmodified)\n}\n\nfunc (s *WorktreeSuite) TestAddRemovedInDirectoryDot(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err := w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\terr = w.Filesystem.Remove(\"go/example.go\")\n\tc.Assert(err, IsNil)\n\n\terr = w.Filesystem.Remove(\"json/short.json\")\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Add(\".\")\n\tc.Assert(err, IsNil)\n\tc.Assert(hash.IsZero(), Equals, true)\n\n\te, err := idx.Entry(\"go/example.go\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Hash, Equals, plumbing.NewHash(\"880cd14280f4b9b6ed3986d6671f907d7cc2a198\"))\n\tc.Assert(e.Mode, Equals, filemode.Regular)\n\n\te, err = idx.Entry(\"json/short.json\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Hash, Equals, plumbing.NewHash(\"c8f1d8c61f9da76f4cb49fd86322b6e685dba956\"))\n\tc.Assert(e.Mode, Equals, filemode.Regular)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 2)\n\n\tfile := status.File(\"go/example.go\")\n\tc.Assert(file.Staging, Equals, Deleted)\n\n\tfile = status.File(\"json/short.json\")\n\tc.Assert(file.Staging, Equals, Deleted)\n}\n\nfunc (s *WorktreeSuite) TestAddSymlink(c *C) {\n\tdir := c.MkDir()\n\n\tr, err := PlainInit(dir, false)\n\tc.Assert(err, IsNil)\n\terr = util.WriteFile(r.wt, \"foo\", []byte(\"qux\"), 0644)\n\tc.Assert(err, IsNil)\n\terr = r.wt.Symlink(\"foo\", \"bar\")\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\th, err := w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\tc.Assert(h, Not(Equals), plumbing.NewHash(\"19102815663d23f8b75a47e7a01965dcdc96468c\"))\n\n\th, err = w.Add(\"bar\")\n\tc.Assert(err, IsNil)\n\tc.Assert(h, Equals, plumbing.NewHash(\"19102815663d23f8b75a47e7a01965dcdc96468c\"))\n\n\tobj, err := w.r.Storer.EncodedObject(plumbing.BlobObject, h)\n\tc.Assert(err, IsNil)\n\tc.Assert(obj, NotNil)\n\tc.Assert(obj.Size(), Equals, int64(3))\n}\n\nfunc (s *WorktreeSuite) TestAddDirectory(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err := w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\terr = util.WriteFile(w.Filesystem, \"qux/foo\", []byte(\"FOO\"), 0755)\n\tc.Assert(err, IsNil)\n\terr = util.WriteFile(w.Filesystem, \"qux/baz/bar\", []byte(\"BAR\"), 0755)\n\tc.Assert(err, IsNil)\n\n\th, err := w.Add(\"qux\")\n\tc.Assert(err, IsNil)\n\tc.Assert(h.IsZero(), Equals, true)\n\n\tidx, err = w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 11)\n\n\te, err := idx.Entry(\"qux/foo\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Mode, Equals, filemode.Executable)\n\n\te, err = idx.Entry(\"qux/baz/bar\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Mode, Equals, filemode.Executable)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 2)\n\n\tfile := status.File(\"qux/foo\")\n\tc.Assert(file.Staging, Equals, Added)\n\tc.Assert(file.Worktree, Equals, Unmodified)\n\n\tfile = status.File(\"qux/baz/bar\")\n\tc.Assert(file.Staging, Equals, Added)\n\tc.Assert(file.Worktree, Equals, Unmodified)\n}\n\nfunc (s *WorktreeSuite) TestAddDirectoryErrorNotFound(c *C) {\n\tr, _ := Init(memory.NewStorage(), memfs.New())\n\tw, _ := r.Worktree()\n\n\th, err := w.Add(\"foo\")\n\tc.Assert(err, NotNil)\n\tc.Assert(h.IsZero(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestAddAll(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err := w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\terr = util.WriteFile(w.Filesystem, \"file1\", []byte(\"file1\"), 0644)\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(w.Filesystem, \"file2\", []byte(\"file2\"), 0644)\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(w.Filesystem, \"file3\", []byte(\"ignore me\"), 0644)\n\tc.Assert(err, IsNil)\n\n\tw.Excludes = make([]gitignore.Pattern, 0)\n\tw.Excludes = append(w.Excludes, gitignore.ParsePattern(\"file3\", nil))\n\n\terr = w.AddWithOptions(&AddOptions{All: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err = w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 11)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 2)\n\n\tfile1 := status.File(\"file1\")\n\tc.Assert(file1.Staging, Equals, Added)\n\tfile2 := status.File(\"file2\")\n\tc.Assert(file2.Staging, Equals, Added)\n\tfile3 := status.File(\"file3\")\n\tc.Assert(file3.Staging, Equals, Untracked)\n\tc.Assert(file3.Worktree, Equals, Untracked)\n}\n\nfunc (s *WorktreeSuite) TestAddGlob(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err := w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\terr = util.WriteFile(w.Filesystem, \"qux/qux\", []byte(\"QUX\"), 0755)\n\tc.Assert(err, IsNil)\n\terr = util.WriteFile(w.Filesystem, \"qux/baz\", []byte(\"BAZ\"), 0755)\n\tc.Assert(err, IsNil)\n\terr = util.WriteFile(w.Filesystem, \"qux/bar/baz\", []byte(\"BAZ\"), 0755)\n\tc.Assert(err, IsNil)\n\n\terr = w.AddWithOptions(&AddOptions{Glob: w.Filesystem.Join(\"qux\", \"b*\")})\n\tc.Assert(err, IsNil)\n\n\tidx, err = w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 11)\n\n\te, err := idx.Entry(\"qux/baz\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Mode, Equals, filemode.Executable)\n\n\te, err = idx.Entry(\"qux/bar/baz\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Mode, Equals, filemode.Executable)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 3)\n\n\tfile := status.File(\"qux/qux\")\n\tc.Assert(file.Staging, Equals, Untracked)\n\tc.Assert(file.Worktree, Equals, Untracked)\n\n\tfile = status.File(\"qux/baz\")\n\tc.Assert(file.Staging, Equals, Added)\n\tc.Assert(file.Worktree, Equals, Unmodified)\n\n\tfile = status.File(\"qux/bar/baz\")\n\tc.Assert(file.Staging, Equals, Added)\n\tc.Assert(file.Worktree, Equals, Unmodified)\n}\n\nfunc (s *WorktreeSuite) TestAddGlobErrorNoMatches(c *C) {\n\tr, _ := Init(memory.NewStorage(), memfs.New())\n\tw, _ := r.Worktree()\n\n\terr := w.AddGlob(\"foo\")\n\tc.Assert(err, Equals, ErrGlobNoMatches)\n}\n\nfunc (s *WorktreeSuite) TestAddSkipStatusAddedPath(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err := w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\terr = util.WriteFile(w.Filesystem, \"file1\", []byte(\"file1\"), 0644)\n\tc.Assert(err, IsNil)\n\n\terr = w.AddWithOptions(&AddOptions{Path: \"file1\", SkipStatus: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err = w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 10)\n\n\te, err := idx.Entry(\"file1\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Mode, Equals, filemode.Regular)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 1)\n\n\tfile := status.File(\"file1\")\n\tc.Assert(file.Staging, Equals, Added)\n\tc.Assert(file.Worktree, Equals, Unmodified)\n}\n\nfunc (s *WorktreeSuite) TestAddSkipStatusModifiedPath(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err := w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\terr = util.WriteFile(w.Filesystem, \"LICENSE\", []byte(\"file1\"), 0644)\n\tc.Assert(err, IsNil)\n\n\terr = w.AddWithOptions(&AddOptions{Path: \"LICENSE\", SkipStatus: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err = w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\te, err := idx.Entry(\"LICENSE\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Mode, Equals, filemode.Regular)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 1)\n\n\tfile := status.File(\"LICENSE\")\n\tc.Assert(file.Staging, Equals, Modified)\n\tc.Assert(file.Worktree, Equals, Unmodified)\n}\n\nfunc (s *WorktreeSuite) TestAddSkipStatusNonModifiedPath(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err := w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\terr = w.AddWithOptions(&AddOptions{Path: \"LICENSE\", SkipStatus: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err = w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\te, err := idx.Entry(\"LICENSE\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Mode, Equals, filemode.Regular)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 0)\n\n\tfile := status.File(\"LICENSE\")\n\tc.Assert(file.Staging, Equals, Untracked)\n\tc.Assert(file.Worktree, Equals, Untracked)\n}\n\nfunc (s *WorktreeSuite) TestAddSkipStatusWithIgnoredPath(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err := w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\terr = util.WriteFile(fs, \".gitignore\", []byte(\"fileToIgnore\\n\"), 0755)\n\tc.Assert(err, IsNil)\n\t_, err = w.Add(\".gitignore\")\n\tc.Assert(err, IsNil)\n\t_, err = w.Commit(\"Added .gitignore\", defaultTestCommitOptions())\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(fs, \"fileToIgnore\", []byte(\"file to ignore\"), 0644)\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 0)\n\n\tfile := status.File(\"fileToIgnore\")\n\tc.Assert(file.Staging, Equals, Untracked)\n\tc.Assert(file.Worktree, Equals, Untracked)\n\n\terr = w.AddWithOptions(&AddOptions{Path: \"fileToIgnore\", SkipStatus: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err = w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 10)\n\n\te, err := idx.Entry(\"fileToIgnore\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Mode, Equals, filemode.Regular)\n\n\tstatus, err = w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 1)\n\n\tfile = status.File(\"fileToIgnore\")\n\tc.Assert(file.Staging, Equals, Added)\n\tc.Assert(file.Worktree, Equals, Unmodified)\n}\n\nfunc (s *WorktreeSuite) TestRemove(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Remove(\"LICENSE\")\n\tc.Assert(hash.String(), Equals, \"c192bd6a24ea1ab01d78686e417c8bdc7c3d197f\")\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 1)\n\tc.Assert(status.File(\"LICENSE\").Staging, Equals, Deleted)\n}\n\nfunc (s *WorktreeSuite) TestRemoveNotExistentEntry(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Remove(\"not-exists\")\n\tc.Assert(hash.IsZero(), Equals, true)\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *WorktreeSuite) TestRemoveDirectory(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Remove(\"json\")\n\tc.Assert(hash.IsZero(), Equals, true)\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 2)\n\tc.Assert(status.File(\"json/long.json\").Staging, Equals, Deleted)\n\tc.Assert(status.File(\"json/short.json\").Staging, Equals, Deleted)\n\n\t_, err = w.Filesystem.Stat(\"json\")\n\tc.Assert(os.IsNotExist(err), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestRemoveDirectoryUntracked(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(w.Filesystem, \"json/foo\", []byte(\"FOO\"), 0755)\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Remove(\"json\")\n\tc.Assert(hash.IsZero(), Equals, true)\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 3)\n\tc.Assert(status.File(\"json/long.json\").Staging, Equals, Deleted)\n\tc.Assert(status.File(\"json/short.json\").Staging, Equals, Deleted)\n\tc.Assert(status.File(\"json/foo\").Staging, Equals, Untracked)\n\n\t_, err = w.Filesystem.Stat(\"json\")\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *WorktreeSuite) TestRemoveDeletedFromWorktree(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\terr = fs.Remove(\"LICENSE\")\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Remove(\"LICENSE\")\n\tc.Assert(hash.String(), Equals, \"c192bd6a24ea1ab01d78686e417c8bdc7c3d197f\")\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 1)\n\tc.Assert(status.File(\"LICENSE\").Staging, Equals, Deleted)\n}\n\nfunc (s *WorktreeSuite) TestRemoveGlob(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\terr = w.RemoveGlob(w.Filesystem.Join(\"json\", \"l*\"))\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 1)\n\tc.Assert(status.File(\"json/long.json\").Staging, Equals, Deleted)\n}\n\nfunc (s *WorktreeSuite) TestRemoveGlobDirectory(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\terr = w.RemoveGlob(\"js*\")\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 2)\n\tc.Assert(status.File(\"json/short.json\").Staging, Equals, Deleted)\n\tc.Assert(status.File(\"json/long.json\").Staging, Equals, Deleted)\n\n\t_, err = w.Filesystem.Stat(\"json\")\n\tc.Assert(os.IsNotExist(err), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestRemoveGlobDirectoryDeleted(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\terr = fs.Remove(\"json/short.json\")\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(w.Filesystem, \"json/foo\", []byte(\"FOO\"), 0755)\n\tc.Assert(err, IsNil)\n\n\terr = w.RemoveGlob(\"js*\")\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 3)\n\tc.Assert(status.File(\"json/short.json\").Staging, Equals, Deleted)\n\tc.Assert(status.File(\"json/long.json\").Staging, Equals, Deleted)\n}\n\nfunc (s *WorktreeSuite) TestMove(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Move(\"LICENSE\", \"foo\")\n\tc.Check(hash.String(), Equals, \"c192bd6a24ea1ab01d78686e417c8bdc7c3d197f\")\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 2)\n\tc.Assert(status.File(\"LICENSE\").Staging, Equals, Deleted)\n\tc.Assert(status.File(\"foo\").Staging, Equals, Added)\n\n}\n\nfunc (s *WorktreeSuite) TestMoveNotExistentEntry(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Move(\"not-exists\", \"foo\")\n\tc.Assert(hash.IsZero(), Equals, true)\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *WorktreeSuite) TestMoveToExistent(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Move(\".gitignore\", \"LICENSE\")\n\tc.Assert(hash.IsZero(), Equals, true)\n\tc.Assert(err, Equals, ErrDestinationExists)\n}\n\nfunc (s *WorktreeSuite) TestClean(c *C) {\n\tfs := fixtures.ByTag(\"dirty\").One().Worktree()\n\n\t// Open the repo.\n\tfs, err := fs.Chroot(\"repo\")\n\tc.Assert(err, IsNil)\n\tr, err := PlainOpen(fs.Root())\n\tc.Assert(err, IsNil)\n\n\twt, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\t// Status before cleaning.\n\tstatus, err := wt.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(len(status), Equals, 2)\n\n\terr = wt.Clean(&CleanOptions{})\n\tc.Assert(err, IsNil)\n\n\t// Status after cleaning.\n\tstatus, err = wt.Status()\n\tc.Assert(err, IsNil)\n\n\tc.Assert(len(status), Equals, 1)\n\n\tfi, err := fs.Lstat(\"pkgA\")\n\tc.Assert(err, IsNil)\n\tc.Assert(fi.IsDir(), Equals, true)\n\n\t// Clean with Dir: true.\n\terr = wt.Clean(&CleanOptions{Dir: true})\n\tc.Assert(err, IsNil)\n\n\tstatus, err = wt.Status()\n\tc.Assert(err, IsNil)\n\n\tc.Assert(len(status), Equals, 0)\n\n\t// An empty dir should be deleted, as well.\n\t_, err = fs.Lstat(\"pkgA\")\n\tc.Assert(err, ErrorMatches, \".*(no such file or directory.*|.*file does not exist)*.\")\n}\n\nfunc (s *WorktreeSuite) TestCleanBare(c *C) {\n\tstorer := memory.NewStorage()\n\n\tr, err := Init(storer, nil)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\twtfs := memfs.New()\n\n\terr = wtfs.MkdirAll(\"worktree\", os.ModePerm)\n\tc.Assert(err, IsNil)\n\n\twtfs, err = wtfs.Chroot(\"worktree\")\n\tc.Assert(err, IsNil)\n\n\tr, err = Open(storer, wtfs)\n\tc.Assert(err, IsNil)\n\n\twt, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\t_, err = wt.Filesystem.Lstat(\".\")\n\tc.Assert(err, IsNil)\n\n\t// Clean with Dir: true.\n\terr = wt.Clean(&CleanOptions{Dir: true})\n\tc.Assert(err, IsNil)\n\n\t// Root worktree directory must remain after cleaning\n\t_, err = wt.Filesystem.Lstat(\".\")\n\tc.Assert(err, IsNil)\n}\n\nfunc TestAlternatesRepo(t *testing.T) {\n\tfs := fixtures.ByTag(\"alternates\").One().Worktree()\n\n\t// Open 1st repo.\n\trep1fs, err := fs.Chroot(\"rep1\")\n\tassert.NoError(t, err)\n\trep1, err := PlainOpen(rep1fs.Root())\n\tassert.NoError(t, err)\n\n\t// Open 2nd repo.\n\trep2fs, err := fs.Chroot(\"rep2\")\n\tassert.NoError(t, err)\n\td, _ := rep2fs.Chroot(GitDirName)\n\tstorer := filesystem.NewStorageWithOptions(d,\n\t\tcache.NewObjectLRUDefault(), filesystem.Options{\n\t\t\tAlternatesFS: fs,\n\t\t})\n\trep2, err := Open(storer, rep2fs)\n\n\tassert.NoError(t, err)\n\n\t// Get the HEAD commit from the main repo.\n\th, err := rep1.Head()\n\tassert.NoError(t, err)\n\tcommit1, err := rep1.CommitObject(h.Hash())\n\tassert.NoError(t, err)\n\n\t// Get the HEAD commit from the shared repo.\n\th, err = rep2.Head()\n\tassert.NoError(t, err)\n\tcommit2, err := rep2.CommitObject(h.Hash())\n\tassert.NoError(t, err)\n\n\tassert.Equal(t, commit1.String(), commit2.String())\n}\n\nfunc (s *WorktreeSuite) TestGrep(c *C) {\n\tcases := []struct {\n\t\tname           string\n\t\toptions        GrepOptions\n\t\twantResult     []GrepResult\n\t\tdontWantResult []GrepResult\n\t\twantError      error\n\t}{\n\t\t{\n\t\t\tname: \"basic word match\",\n\t\t\toptions: GrepOptions{\n\t\t\t\tPatterns: []*regexp.Regexp{regexp.MustCompile(\"import\")},\n\t\t\t},\n\t\t\twantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"go/example.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import (\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"vendor/foo.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import \\\"fmt\\\"\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t},\n\t\t}, {\n\t\t\tname: \"case insensitive match\",\n\t\t\toptions: GrepOptions{\n\t\t\t\tPatterns: []*regexp.Regexp{regexp.MustCompile(`(?i)IMport`)},\n\t\t\t},\n\t\t\twantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"go/example.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import (\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"vendor/foo.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import \\\"fmt\\\"\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t},\n\t\t}, {\n\t\t\tname: \"invert match\",\n\t\t\toptions: GrepOptions{\n\t\t\t\tPatterns:    []*regexp.Regexp{regexp.MustCompile(\"import\")},\n\t\t\t\tInvertMatch: true,\n\t\t\t},\n\t\t\tdontWantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"go/example.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import (\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"vendor/foo.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import \\\"fmt\\\"\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t},\n\t\t}, {\n\t\t\tname: \"match at a given commit hash\",\n\t\t\toptions: GrepOptions{\n\t\t\t\tPatterns:   []*regexp.Regexp{regexp.MustCompile(\"The MIT License\")},\n\t\t\t\tCommitHash: plumbing.NewHash(\"b029517f6300c2da0f4b651b8642506cd6aaf45d\"),\n\t\t\t},\n\t\t\twantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"LICENSE\",\n\t\t\t\t\tLineNumber: 1,\n\t\t\t\t\tContent:    \"The MIT License (MIT)\",\n\t\t\t\t\tTreeName:   \"b029517f6300c2da0f4b651b8642506cd6aaf45d\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tdontWantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"go/example.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import (\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t},\n\t\t}, {\n\t\t\tname: \"match for a given pathspec\",\n\t\t\toptions: GrepOptions{\n\t\t\t\tPatterns:  []*regexp.Regexp{regexp.MustCompile(\"import\")},\n\t\t\t\tPathSpecs: []*regexp.Regexp{regexp.MustCompile(\"go/\")},\n\t\t\t},\n\t\t\twantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"go/example.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import (\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tdontWantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"vendor/foo.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import \\\"fmt\\\"\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t},\n\t\t}, {\n\t\t\tname: \"match at a given reference name\",\n\t\t\toptions: GrepOptions{\n\t\t\t\tPatterns:      []*regexp.Regexp{regexp.MustCompile(\"import\")},\n\t\t\t\tReferenceName: \"refs/heads/master\",\n\t\t\t},\n\t\t\twantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"go/example.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import (\",\n\t\t\t\t\tTreeName:   \"refs/heads/master\",\n\t\t\t\t},\n\t\t\t},\n\t\t}, {\n\t\t\tname: \"ambiguous options\",\n\t\t\toptions: GrepOptions{\n\t\t\t\tPatterns:      []*regexp.Regexp{regexp.MustCompile(\"import\")},\n\t\t\t\tCommitHash:    plumbing.NewHash(\"2d55a722f3c3ecc36da919dfd8b6de38352f3507\"),\n\t\t\t\tReferenceName: \"somereferencename\",\n\t\t\t},\n\t\t\twantError: ErrHashOrReference,\n\t\t}, {\n\t\t\tname: \"multiple patterns\",\n\t\t\toptions: GrepOptions{\n\t\t\t\tPatterns: []*regexp.Regexp{\n\t\t\t\t\tregexp.MustCompile(\"import\"),\n\t\t\t\t\tregexp.MustCompile(\"License\"),\n\t\t\t\t},\n\t\t\t},\n\t\t\twantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"go/example.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import (\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"vendor/foo.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import \\\"fmt\\\"\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"LICENSE\",\n\t\t\t\t\tLineNumber: 1,\n\t\t\t\t\tContent:    \"The MIT License (MIT)\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t},\n\t\t}, {\n\t\t\tname: \"multiple pathspecs\",\n\t\t\toptions: GrepOptions{\n\t\t\t\tPatterns: []*regexp.Regexp{regexp.MustCompile(\"import\")},\n\t\t\t\tPathSpecs: []*regexp.Regexp{\n\t\t\t\t\tregexp.MustCompile(\"go/\"),\n\t\t\t\t\tregexp.MustCompile(\"vendor/\"),\n\t\t\t\t},\n\t\t\t},\n\t\t\twantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"go/example.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import (\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"vendor/foo.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import \\\"fmt\\\"\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tpath := fixtures.Basic().ByTag(\"worktree\").One().Worktree().Root()\n\n\tdir := c.MkDir()\n\n\tserver, err := PlainClone(dir, false, &CloneOptions{\n\t\tURL: path,\n\t})\n\tc.Assert(err, IsNil)\n\n\tw, err := server.Worktree()\n\tc.Assert(err, IsNil)\n\n\tfor _, tc := range cases {\n\t\tgr, err := w.Grep(&tc.options)\n\t\tif tc.wantError != nil {\n\t\t\tc.Assert(err, Equals, tc.wantError)\n\t\t} else {\n\t\t\tc.Assert(err, IsNil)\n\t\t}\n\n\t\t// Iterate through the results and check if the wanted result is present\n\t\t// in the got result.\n\t\tfor _, wantResult := range tc.wantResult {\n\t\t\tfound := false\n\t\t\tfor _, gotResult := range gr {\n\t\t\t\tif wantResult == gotResult {\n\t\t\t\t\tfound = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !found {\n\t\t\t\tc.Errorf(\"unexpected grep results for %q, expected result to contain: %v\", tc.name, wantResult)\n\t\t\t}\n\t\t}\n\n\t\t// Iterate through the results and check if the not wanted result is\n\t\t// present in the got result.\n\t\tfor _, dontWantResult := range tc.dontWantResult {\n\t\t\tfound := false\n\t\t\tfor _, gotResult := range gr {\n\t\t\t\tif dontWantResult == gotResult {\n\t\t\t\t\tfound = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif found {\n\t\t\t\tc.Errorf(\"unexpected grep results for %q, expected result to NOT contain: %v\", tc.name, dontWantResult)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (s *WorktreeSuite) TestGrepBare(c *C) {\n\tcases := []struct {\n\t\tname           string\n\t\toptions        GrepOptions\n\t\twantResult     []GrepResult\n\t\tdontWantResult []GrepResult\n\t\twantError      error\n\t}{\n\t\t{\n\t\t\tname: \"basic word match\",\n\t\t\toptions: GrepOptions{\n\t\t\t\tPatterns:   []*regexp.Regexp{regexp.MustCompile(\"import\")},\n\t\t\t\tCommitHash: plumbing.ZeroHash,\n\t\t\t},\n\t\t\twantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"go/example.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import (\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"vendor/foo.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import \\\"fmt\\\"\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tpath := fixtures.Basic().ByTag(\"worktree\").One().Worktree().Root()\n\n\tdir := c.MkDir()\n\n\tr, err := PlainClone(dir, true, &CloneOptions{\n\t\tURL: path,\n\t})\n\tc.Assert(err, IsNil)\n\n\tfor _, tc := range cases {\n\t\tgr, err := r.Grep(&tc.options)\n\t\tif tc.wantError != nil {\n\t\t\tc.Assert(err, Equals, tc.wantError)\n\t\t} else {\n\t\t\tc.Assert(err, IsNil)\n\t\t}\n\n\t\t// Iterate through the results and check if the wanted result is present\n\t\t// in the got result.\n\t\tfor _, wantResult := range tc.wantResult {\n\t\t\tfound := false\n\t\t\tfor _, gotResult := range gr {\n\t\t\t\tif wantResult == gotResult {\n\t\t\t\t\tfound = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !found {\n\t\t\t\tc.Errorf(\"unexpected grep results for %q, expected result to contain: %v\", tc.name, wantResult)\n\t\t\t}\n\t\t}\n\n\t\t// Iterate through the results and check if the not wanted result is\n\t\t// present in the got result.\n\t\tfor _, dontWantResult := range tc.dontWantResult {\n\t\t\tfound := false\n\t\t\tfor _, gotResult := range gr {\n\t\t\t\tif dontWantResult == gotResult {\n\t\t\t\t\tfound = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif found {\n\t\t\t\tc.Errorf(\"unexpected grep results for %q, expected result to NOT contain: %v\", tc.name, dontWantResult)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (s *WorktreeSuite) TestResetLingeringDirectories(c *C) {\n\tdir := c.MkDir()\n\n\tcommitOpts := &CommitOptions{Author: &object.Signature{\n\t\tName:  \"foo\",\n\t\tEmail: \"foo@foo.foo\",\n\t\tWhen:  time.Now(),\n\t}}\n\n\trepo, err := PlainInit(dir, false)\n\tc.Assert(err, IsNil)\n\n\tw, err := repo.Worktree()\n\tc.Assert(err, IsNil)\n\n\tos.WriteFile(filepath.Join(dir, \"README\"), []byte(\"placeholder\"), 0o644)\n\n\t_, err = w.Add(\".\")\n\tc.Assert(err, IsNil)\n\n\tinitialHash, err := w.Commit(\"Initial commit\", commitOpts)\n\tc.Assert(err, IsNil)\n\n\tos.MkdirAll(filepath.Join(dir, \"a\", \"b\"), 0o755)\n\tos.WriteFile(filepath.Join(dir, \"a\", \"b\", \"1\"), []byte(\"1\"), 0o644)\n\n\t_, err = w.Add(\".\")\n\tc.Assert(err, IsNil)\n\n\t_, err = w.Commit(\"Add file in nested sub-directories\", commitOpts)\n\tc.Assert(err, IsNil)\n\n\t// reset to initial commit, which should remove a/b/1, a/b, and a\n\terr = w.Reset(&ResetOptions{\n\t\tCommit: initialHash,\n\t\tMode:   HardReset,\n\t})\n\tc.Assert(err, IsNil)\n\n\t_, err = os.Stat(filepath.Join(dir, \"a\", \"b\", \"1\"))\n\tc.Assert(errors.Is(err, os.ErrNotExist), Equals, true)\n\n\t_, err = os.Stat(filepath.Join(dir, \"a\", \"b\"))\n\tc.Assert(errors.Is(err, os.ErrNotExist), Equals, true)\n\n\t_, err = os.Stat(filepath.Join(dir, \"a\"))\n\tc.Assert(errors.Is(err, os.ErrNotExist), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestAddAndCommit(c *C) {\n\texpectedFiles := 2\n\n\tdir := c.MkDir()\n\n\trepo, err := PlainInit(dir, false)\n\tc.Assert(err, IsNil)\n\n\tw, err := repo.Worktree()\n\tc.Assert(err, IsNil)\n\n\tos.WriteFile(filepath.Join(dir, \"foo\"), []byte(\"bar\"), 0o644)\n\tos.WriteFile(filepath.Join(dir, \"bar\"), []byte(\"foo\"), 0o644)\n\n\t_, err = w.Add(\".\")\n\tc.Assert(err, IsNil)\n\n\t_, err = w.Commit(\"Test Add And Commit\", &CommitOptions{Author: &object.Signature{\n\t\tName:  \"foo\",\n\t\tEmail: \"foo@foo.foo\",\n\t\tWhen:  time.Now(),\n\t}})\n\tc.Assert(err, IsNil)\n\n\titer, err := w.r.Log(&LogOptions{})\n\tc.Assert(err, IsNil)\n\n\tfilesFound := 0\n\terr = iter.ForEach(func(c *object.Commit) error {\n\t\tfiles, err := c.Files()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\terr = files.ForEach(func(f *object.File) error {\n\t\t\tfilesFound++\n\t\t\treturn nil\n\t\t})\n\t\treturn err\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(filesFound, Equals, expectedFiles)\n}\n\nfunc (s *WorktreeSuite) TestAddAndCommitEmpty(c *C) {\n\tdir := c.MkDir()\n\n\trepo, err := PlainInit(dir, false)\n\tc.Assert(err, IsNil)\n\n\tw, err := repo.Worktree()\n\tc.Assert(err, IsNil)\n\n\t_, err = w.Add(\".\")\n\tc.Assert(err, IsNil)\n\n\t_, err = w.Commit(\"Test Add And Commit\", &CommitOptions{Author: &object.Signature{\n\t\tName:  \"foo\",\n\t\tEmail: \"foo@foo.foo\",\n\t\tWhen:  time.Now(),\n\t}})\n\tc.Assert(err, Equals, ErrEmptyCommit)\n}\n\nfunc (s *WorktreeSuite) TestLinkedWorktree(c *C) {\n\tfs := fixtures.ByTag(\"linked-worktree\").One().Worktree()\n\n\t// Open main repo.\n\t{\n\t\tfs, err := fs.Chroot(\"main\")\n\t\tc.Assert(err, IsNil)\n\t\trepo, err := PlainOpenWithOptions(fs.Root(), &PlainOpenOptions{EnableDotGitCommonDir: true})\n\t\tc.Assert(err, IsNil)\n\n\t\twt, err := repo.Worktree()\n\t\tc.Assert(err, IsNil)\n\n\t\tstatus, err := wt.Status()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(len(status), Equals, 2) // 2 files\n\n\t\thead, err := repo.Head()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(string(head.Name()), Equals, \"refs/heads/master\")\n\t}\n\n\t// Open linked-worktree #1.\n\t{\n\t\tfs, err := fs.Chroot(\"linked-worktree-1\")\n\t\tc.Assert(err, IsNil)\n\t\trepo, err := PlainOpenWithOptions(fs.Root(), &PlainOpenOptions{EnableDotGitCommonDir: true})\n\t\tc.Assert(err, IsNil)\n\n\t\twt, err := repo.Worktree()\n\t\tc.Assert(err, IsNil)\n\n\t\tstatus, err := wt.Status()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(len(status), Equals, 3) // 3 files\n\n\t\t_, ok := status[\"linked-worktree-1-unique-file.txt\"]\n\t\tc.Assert(ok, Equals, true)\n\n\t\thead, err := repo.Head()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(string(head.Name()), Equals, \"refs/heads/linked-worktree-1\")\n\t}\n\n\t// Open linked-worktree #2.\n\t{\n\t\tfs, err := fs.Chroot(\"linked-worktree-2\")\n\t\tc.Assert(err, IsNil)\n\t\trepo, err := PlainOpenWithOptions(fs.Root(), &PlainOpenOptions{EnableDotGitCommonDir: true})\n\t\tc.Assert(err, IsNil)\n\n\t\twt, err := repo.Worktree()\n\t\tc.Assert(err, IsNil)\n\n\t\tstatus, err := wt.Status()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(len(status), Equals, 3) // 3 files\n\n\t\t_, ok := status[\"linked-worktree-2-unique-file.txt\"]\n\t\tc.Assert(ok, Equals, true)\n\n\t\thead, err := repo.Head()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(string(head.Name()), Equals, \"refs/heads/branch-with-different-name\")\n\t}\n\n\t// Open linked-worktree #2.\n\t{\n\t\tfs, err := fs.Chroot(\"linked-worktree-invalid-commondir\")\n\t\tc.Assert(err, IsNil)\n\t\t_, err = PlainOpenWithOptions(fs.Root(), &PlainOpenOptions{EnableDotGitCommonDir: true})\n\t\tc.Assert(err, Equals, ErrRepositoryIncomplete)\n\t}\n}\n\nfunc TestValidPath(t *testing.T) {\n\ttype testcase struct {\n\t\tpath    string\n\t\twantErr bool\n\t}\n\n\ttests := []testcase{\n\t\t{\".git\", true},\n\t\t{\".git/b\", true},\n\t\t{\".git\\\\b\", true},\n\t\t{\"git~1\", true},\n\t\t{\"a/../b\", true},\n\t\t{\"a\\\\..\\\\b\", true},\n\t\t{\"/\", true},\n\t\t{\"\", true},\n\t\t{\".gitmodules\", false},\n\t\t{\".gitignore\", false},\n\t\t{\"a..b\", false},\n\t\t{\".\", false},\n\t\t{\"a/.git\", false},\n\t\t{\"a\\\\.git\", false},\n\t\t{\"a/.git/b\", false},\n\t\t{\"a\\\\.git\\\\b\", false},\n\t}\n\n\tif runtime.GOOS == \"windows\" {\n\t\ttests = append(tests, []testcase{\n\t\t\t{\"\\\\\\\\a\\\\b\", true},\n\t\t\t{\"C:\\\\a\\\\b\", true},\n\t\t\t{\".git . . .\", true},\n\t\t\t{\".git . . \", true},\n\t\t\t{\".git \", true},\n\t\t\t{\".git.\", true},\n\t\t\t{\".git::$INDEX_ALLOCATION\", true},\n\t\t}...)\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.path, func(t *testing.T) {\n\t\t\terr := validPath(tc.path)\n\t\t\tif tc.wantErr {\n\t\t\t\tassert.Error(t, err)\n\t\t\t} else {\n\t\t\t\tassert.NoError(t, err)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestWindowsValidPath(t *testing.T) {\n\ttests := []struct {\n\t\tpath string\n\t\twant bool\n\t}{\n\t\t{\".git\", false},\n\t\t{\".git . . .\", false},\n\t\t{\".git \", false},\n\t\t{\".git  \", false},\n\t\t{\".git . .\", false},\n\t\t{\".git . .\", false},\n\t\t{\".git::$INDEX_ALLOCATION\", false},\n\t\t{\".git:\", false},\n\t\t{\"a\", true},\n\t\t{\"a\\\\b\", true},\n\t\t{\"a/b\", true},\n\t\t{\".gitm\", true},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.path, func(t *testing.T) {\n\t\t\tgot := windowsValidPath(tc.path)\n\t\t\tassert.Equal(t, tc.want, got)\n\t\t})\n\t}\n}\n\nvar statusCodeNames = map[StatusCode]string{\n\tUnmodified:         \"Unmodified\",\n\tUntracked:          \"Untracked\",\n\tModified:           \"Modified\",\n\tAdded:              \"Added\",\n\tDeleted:            \"Deleted\",\n\tRenamed:            \"Renamed\",\n\tCopied:             \"Copied\",\n\tUpdatedButUnmerged: \"UpdatedButUnmerged\",\n}\n\nfunc setupForRestore(c *C, s *WorktreeSuite) (fs billy.Filesystem, w *Worktree, names []string) {\n\tfs = memfs.New()\n\tw = &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tnames = []string{\"foo\", \"CHANGELOG\", \"LICENSE\", \"binary.jpg\"}\n\tverifyStatus(c, \"Checkout\", w, names, []FileStatus{\n\t\t{Worktree: Untracked, Staging: Untracked},\n\t\t{Worktree: Untracked, Staging: Untracked},\n\t\t{Worktree: Untracked, Staging: Untracked},\n\t\t{Worktree: Untracked, Staging: Untracked},\n\t})\n\n\t// Touch of bunch of files including create a new file and delete an exsiting file\n\tfor _, name := range names {\n\t\terr = util.WriteFile(fs, name, []byte(\"Foo Bar\"), 0755)\n\t\tc.Assert(err, IsNil)\n\t}\n\terr = util.RemoveAll(fs, names[3])\n\tc.Assert(err, IsNil)\n\n\t// Confirm the status after doing the edits without staging anything\n\tverifyStatus(c, \"Edits\", w, names, []FileStatus{\n\t\t{Worktree: Untracked, Staging: Untracked},\n\t\t{Worktree: Modified, Staging: Unmodified},\n\t\t{Worktree: Modified, Staging: Unmodified},\n\t\t{Worktree: Deleted, Staging: Unmodified},\n\t})\n\n\t// Stage all files and verify the updated status\n\tfor _, name := range names {\n\t\t_, err = w.Add(name)\n\t\tc.Assert(err, IsNil)\n\t}\n\tverifyStatus(c, \"Staged\", w, names, []FileStatus{\n\t\t{Worktree: Unmodified, Staging: Added},\n\t\t{Worktree: Unmodified, Staging: Modified},\n\t\t{Worktree: Unmodified, Staging: Modified},\n\t\t{Worktree: Unmodified, Staging: Deleted},\n\t})\n\n\t// Add secondary changes to a file to make sure we only restore the staged file\n\terr = util.WriteFile(fs, names[1], []byte(\"Foo Bar:11\"), 0755)\n\tc.Assert(err, IsNil)\n\terr = util.WriteFile(fs, names[2], []byte(\"Foo Bar:22\"), 0755)\n\tc.Assert(err, IsNil)\n\n\tverifyStatus(c, \"Secondary Edits\", w, names, []FileStatus{\n\t\t{Worktree: Unmodified, Staging: Added},\n\t\t{Worktree: Modified, Staging: Modified},\n\t\t{Worktree: Modified, Staging: Modified},\n\t\t{Worktree: Unmodified, Staging: Deleted},\n\t})\n\n\treturn\n}\n\nfunc verifyStatus(c *C, marker string, w *Worktree, files []string, statuses []FileStatus) {\n\tc.Assert(len(files), Equals, len(statuses))\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\n\tfor i, file := range files {\n\t\tcurrent := status.File(file)\n\t\texpected := statuses[i]\n\t\tc.Assert(current.Worktree, Equals, expected.Worktree, Commentf(\"%s - [%d] : %s Worktree %s != %s\", marker, i, file, statusCodeNames[current.Worktree], statusCodeNames[expected.Worktree]))\n\t\tc.Assert(current.Staging, Equals, expected.Staging, Commentf(\"%s - [%d] : %s Staging %s != %s\", marker, i, file, statusCodeNames[current.Staging], statusCodeNames[expected.Staging]))\n\t}\n}\n\nfunc (s *WorktreeSuite) TestRestoreStaged(c *C) {\n\tfs, w, names := setupForRestore(c, s)\n\n\t// Attempt without files should throw an error like the git restore --staged\n\topts := RestoreOptions{Staged: true}\n\terr := w.Restore(&opts)\n\tc.Assert(err, Equals, ErrNoRestorePaths)\n\n\t// Restore Staged files in 2 groups and confirm status\n\topts.Files = []string{names[0], names[1]}\n\terr = w.Restore(&opts)\n\tc.Assert(err, IsNil)\n\tverifyStatus(c, \"Restored First\", w, names, []FileStatus{\n\t\t{Worktree: Untracked, Staging: Untracked},\n\t\t{Worktree: Modified, Staging: Unmodified},\n\t\t{Worktree: Modified, Staging: Modified},\n\t\t{Worktree: Unmodified, Staging: Deleted},\n\t})\n\n\t// Make sure the restore didn't overwrite our secondary changes\n\tcontents, err := util.ReadFile(fs, names[1])\n\tc.Assert(err, IsNil)\n\tc.Assert(string(contents), Equals, \"Foo Bar:11\")\n\n\topts.Files = []string{names[2], names[3]}\n\terr = w.Restore(&opts)\n\tc.Assert(err, IsNil)\n\tverifyStatus(c, \"Restored Second\", w, names, []FileStatus{\n\t\t{Worktree: Untracked, Staging: Untracked},\n\t\t{Worktree: Modified, Staging: Unmodified},\n\t\t{Worktree: Modified, Staging: Unmodified},\n\t\t{Worktree: Deleted, Staging: Unmodified},\n\t})\n\n\t// Make sure the restore didn't overwrite our secondary changes\n\tcontents, err = util.ReadFile(fs, names[2])\n\tc.Assert(err, IsNil)\n\tc.Assert(string(contents), Equals, \"Foo Bar:22\")\n}\n\nfunc (s *WorktreeSuite) TestRestoreWorktree(c *C) {\n\t_, w, names := setupForRestore(c, s)\n\n\t// Attempt without files should throw an error like the git restore\n\topts := RestoreOptions{}\n\terr := w.Restore(&opts)\n\tc.Assert(err, Equals, ErrNoRestorePaths)\n\n\topts.Files = []string{names[0], names[1]}\n\terr = w.Restore(&opts)\n\tc.Assert(err, Equals, ErrRestoreWorktreeOnlyNotSupported)\n}\n\nfunc (s *WorktreeSuite) TestRestoreBoth(c *C) {\n\t_, w, names := setupForRestore(c, s)\n\n\t// Attempt without files should throw an error like the git restore --staged --worktree\n\topts := RestoreOptions{Staged: true, Worktree: true}\n\terr := w.Restore(&opts)\n\tc.Assert(err, Equals, ErrNoRestorePaths)\n\n\t// Restore Staged files in 2 groups and confirm status\n\topts.Files = []string{names[0], names[1]}\n\terr = w.Restore(&opts)\n\tc.Assert(err, IsNil)\n\tverifyStatus(c, \"Restored First\", w, names, []FileStatus{\n\t\t{Worktree: Untracked, Staging: Untracked},\n\t\t{Worktree: Untracked, Staging: Untracked},\n\t\t{Worktree: Modified, Staging: Modified},\n\t\t{Worktree: Unmodified, Staging: Deleted},\n\t})\n\n\topts.Files = []string{names[2], names[3]}\n\terr = w.Restore(&opts)\n\tc.Assert(err, IsNil)\n\tverifyStatus(c, \"Restored Second\", w, names, []FileStatus{\n\t\t{Worktree: Untracked, Staging: Untracked},\n\t\t{Worktree: Untracked, Staging: Untracked},\n\t\t{Worktree: Untracked, Staging: Untracked},\n\t\t{Worktree: Untracked, Staging: Untracked},\n\t})\n}\n\nfunc TestFilePermissions(t *testing.T) {\n\n\t// Initialize an in memory repository\n\tremoteUrl := t.TempDir()\n\n\tinMemoryFs := memfs.New()\n\tremoteFs := osfs.New(remoteUrl)\n\tremoteStorage := filesystem.NewStorage(remoteFs, cache.NewObjectLRUDefault())\n\n\tremoteRepository, err := Init(remoteStorage, inMemoryFs)\n\tassert.NoError(t, err)\n\n\terr = util.WriteFile(inMemoryFs, \"fileWithExecuteBit\", []byte(\"Initial data\"), 0755)\n\tassert.NoError(t, err)\n\n\terr = util.WriteFile(inMemoryFs, \"regularFile\", []byte(\"Initial data\"), 0644)\n\tassert.NoError(t, err)\n\n\tremoteWorktree, err := remoteRepository.Worktree()\n\tassert.NoError(t, err)\n\n\t_, err = remoteWorktree.Add(\"fileWithExecuteBit\")\n\tassert.NoError(t, err)\n\n\t_, err = remoteWorktree.Add(\"regularFile\")\n\tassert.NoError(t, err)\n\n\t_, err = remoteWorktree.Commit(\"my commit\", &CommitOptions{})\n\tassert.NoError(t, err)\n\n\tworktreePath := t.TempDir()\n\n\tlocalRepo, err := PlainClone(worktreePath, false, &CloneOptions{URL: remoteUrl})\n\tassert.NoError(t, err)\n\n\tlocalWorktree, err := localRepo.Worktree()\n\tassert.NoError(t, err)\n\n\tidx, err := localWorktree.r.Storer.Index()\n\tassert.NoError(t, err)\n\n\texpectedEntries := []index.Entry{\n\t\t{\n\t\t\tName: \"fileWithExecuteBit\",\n\t\t\tMode: filemode.Executable,\n\t\t},\n\t\t{\n\t\t\tName: \"regularFile\",\n\t\t\tMode: filemode.Regular,\n\t\t},\n\t}\n\n\tassert.Len(t, idx.Entries, len(expectedEntries))\n\n\tfor i, expectedEntry := range expectedEntries {\n\t\tassert.Equal(t, expectedEntry.Name, idx.Entries[i].Name)\n\t\tassert.Equal(t, expectedEntry.Mode, idx.Entries[i].Mode)\n\t}\n\n}\n"
        },
        {
          "name": "worktree_unix_other.go",
          "type": "blob",
          "size": 0.4462890625,
          "content": "// +build openbsd dragonfly solaris\n\npackage git\n\nimport (\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/go-git/go-git/v5/plumbing/format/index\"\n)\n\nfunc init() {\n\tfillSystemInfo = func(e *index.Entry, sys interface{}) {\n\t\tif os, ok := sys.(*syscall.Stat_t); ok {\n\t\t\te.CreatedAt = time.Unix(os.Atim.Unix())\n\t\t\te.Dev = uint32(os.Dev)\n\t\t\te.Inode = uint32(os.Ino)\n\t\t\te.GID = os.Gid\n\t\t\te.UID = os.Uid\n\t\t}\n\t}\n}\n\nfunc isSymlinkWindowsNonAdmin(err error) bool {\n\treturn false\n}\n"
        },
        {
          "name": "worktree_windows.go",
          "type": "blob",
          "size": 0.7138671875,
          "content": "// +build windows\n\npackage git\n\nimport (\n\t\"os\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/go-git/go-git/v5/plumbing/format/index\"\n)\n\nfunc init() {\n\tfillSystemInfo = func(e *index.Entry, sys interface{}) {\n\t\tif os, ok := sys.(*syscall.Win32FileAttributeData); ok {\n\t\t\tseconds := os.CreationTime.Nanoseconds() / 1000000000\n\t\t\tnanoseconds := os.CreationTime.Nanoseconds() - seconds*1000000000\n\t\t\te.CreatedAt = time.Unix(seconds, nanoseconds)\n\t\t}\n\t}\n}\n\nfunc isSymlinkWindowsNonAdmin(err error) bool {\n\tconst ERROR_PRIVILEGE_NOT_HELD syscall.Errno = 1314\n\n\tif err != nil {\n\t\tif errLink, ok := err.(*os.LinkError); ok {\n\t\t\tif errNo, ok := errLink.Err.(syscall.Errno); ok {\n\t\t\t\treturn errNo == ERROR_PRIVILEGE_NOT_HELD\n\t\t\t}\n\t\t}\n\t}\n\n\treturn false\n}\n"
        }
      ]
    }
  ]
}