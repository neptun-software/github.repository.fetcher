{
  "metadata": {
    "timestamp": 1736567705306,
    "page": 290,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "tidwall/evio",
      "stars": 5917,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0556640625,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2017 Joshua J Baker\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\nthe Software, and to permit persons to whom the Software is furnished to do so,\nsubject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\nCONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 6.08984375,
          "content": "<p align=\"center\">\n<img \n    src=\"logo.png\" \n    width=\"213\" height=\"75\" border=\"0\" alt=\"evio\">\n<br>\n<a href=\"https://godoc.org/github.com/tidwall/evio\"><img src=\"https://img.shields.io/badge/api-reference-blue.svg?style=flat-square\" alt=\"GoDoc\"></a>\n</p>\n\n`evio` is an event loop networking framework that is fast and small. It makes direct [epoll](https://en.wikipedia.org/wiki/Epoll) and [kqueue](https://en.wikipedia.org/wiki/Kqueue) syscalls rather than using the standard Go [net](https://golang.org/pkg/net/) package, and works in a similar manner as [libuv](https://github.com/libuv/libuv) and [libevent](https://github.com/libevent/libevent).\n\nThe goal of this project is to create a server framework for Go that performs on par with [Redis](http://redis.io) and [Haproxy](http://www.haproxy.org) for packet handling. It was built to be the foundation for [Tile38](https://github.com/tidwall/tile38) and a future L7 proxy for Go.\n\n*Please note: Evio should not be considered as a drop-in replacement for the standard Go net or net/http packages.*\n\n## Features\n\n- [Fast](#performance) single-threaded or [multithreaded](#multithreaded) event loop\n- Built-in [load balancing](#load-balancing) options\n- Simple API\n- Low memory usage\n- Supports tcp, [udp](#udp), and unix sockets\n- Allows [multiple network binding](#multiple-addresses) on the same event loop\n- Flexible [ticker](#ticker) event\n- Fallback for non-epoll/kqueue operating systems by simulating events with the [net](https://golang.org/pkg/net/) package\n- [SO_REUSEPORT](#so_reuseport) socket option\n\n## Getting Started\n\n### Installing\n\nTo start using evio, install Go and run `go get`:\n\n```sh\n$ go get -u github.com/tidwall/evio\n```\n\nThis will retrieve the library.\n\n### Usage\n\nStarting a server is easy with `evio`. Just set up your events and pass them to the `Serve` function along with the binding address(es). Each connections is represented as an `evio.Conn` object that is passed to various events to differentiate the clients. At any point you can close a client or shutdown the server by return a `Close` or `Shutdown` action from an event.\n\nExample echo server that binds to port 5000:\n\n```go\npackage main\n\nimport \"github.com/tidwall/evio\"\n\nfunc main() {\n\tvar events evio.Events\n\tevents.Data = func(c evio.Conn, in []byte) (out []byte, action evio.Action) {\n\t\tout = in\n\t\treturn\n\t}\n\tif err := evio.Serve(events, \"tcp://localhost:5000\"); err != nil {\n\t\tpanic(err.Error())\n\t}\n}\n```\n\nHere the only event being used is `Data`, which fires when the server receives input data from a client.\nThe exact same input data is then passed through the output return value, which is then sent back to the client. \n\nConnect to the echo server:\n\n```sh\n$ telnet localhost 5000\n```\n\n### Events\n\nThe event type has a bunch of handy events:\n\n- `Serving` fires when the server is ready to accept new connections.\n- `Opened` fires when a connection has opened.\n- `Closed` fires when a connection has closed.\n- `Detach` fires when a connection has been detached using the `Detach` return action.\n- `Data` fires when the server receives new data from a connection.\n- `Tick` fires immediately after the server starts and will fire again after a specified interval.\n\n### Multiple addresses\n\nA server can bind to multiple addresses and share the same event loop.\n\n```go\nevio.Serve(events, \"tcp://192.168.0.10:5000\", \"unix://socket\")\n```\n\n### Ticker\n\nThe `Tick` event fires ticks at a specified interval. \nThe first tick fires immediately after the `Serving` events.\n\n```go\nevents.Tick = func() (delay time.Duration, action Action){\n\tlog.Printf(\"tick\")\n\tdelay = time.Second\n\treturn\n}\n```\n\n## UDP\n\nThe `Serve` function can bind to UDP addresses. \n\n- All incoming and outgoing packets are not buffered and sent individually.\n- The `Opened` and `Closed` events are not availble for UDP sockets, only the `Data` event.\n\n## Multithreaded\n\nThe `events.NumLoops` options sets the number of loops to use for the server. \nA value greater than 1 will effectively make the server multithreaded for multi-core machines. \nWhich means you must take care when synchonizing memory between event callbacks. \nSetting to 0 or 1 will run the server as single-threaded. \nSetting to -1 will automatically assign this value equal to `runtime.NumProcs()`.\n\n## Load balancing\n\nThe `events.LoadBalance` options sets the load balancing method. \nLoad balancing is always a best effort to attempt to distribute the incoming connections between multiple loops.\nThis option is only available when `events.NumLoops` is set.\n\n- `Random` requests that connections are randomly distributed.\n- `RoundRobin` requests that connections are distributed to a loop in a round-robin fashion.\n- `LeastConnections` assigns the next accepted connection to the loop with the least number of active connections.\n\n## SO_REUSEPORT\n\nServers can utilize the [SO_REUSEPORT](https://lwn.net/Articles/542629/) option which allows multiple sockets on the same host to bind to the same port.\n\nJust provide `reuseport=true` to an address:\n\n```go\nevio.Serve(events, \"tcp://0.0.0.0:1234?reuseport=true\"))\n```\n\n## More examples\n\nPlease check out the [examples](examples) subdirectory for a simplified [redis](examples/redis-server/main.go) clone, an [echo](examples/echo-server/main.go) server, and a very basic [http](examples/http-server/main.go) server.\n\nTo run an example:\n\n```sh\n$ go run examples/http-server/main.go\n$ go run examples/redis-server/main.go\n$ go run examples/echo-server/main.go\n```\n\n## Performance\n\n### Benchmarks\n\nThese benchmarks were run on an ec2 c4.xlarge instance in single-threaded mode (GOMAXPROC=1) over Ipv4 localhost.\nCheck out [benchmarks](benchmarks) for more info.\n\n<img src=\"benchmarks/out/echo.png\" width=\"336\" height=\"144\" border=\"0\" alt=\"echo benchmark\"><img src=\"benchmarks/out/http.png\" width=\"336\" height=\"144\" border=\"0\" alt=\"http benchmark\"><img src=\"benchmarks/out/redis_pipeline_1.png\" width=\"336\" height=\"144\" border=\"0\" alt=\"redis 1 benchmark\"><img src=\"benchmarks/out/redis_pipeline_8.png\" width=\"336\" height=\"144\" border=\"0\" alt=\"redis 8 benchmark\">\n\n\n## Contact\n\nJosh Baker [@tidwall](http://twitter.com/tidwall)\n\n## License\n\n`evio` source code is available under the MIT [License](/LICENSE).\n\n"
        },
        {
          "name": "benchmarks",
          "type": "tree",
          "content": null
        },
        {
          "name": "evio.go",
          "type": "blob",
          "size": 7.791015625,
          "content": "// Copyright 2018 Joshua J Baker. All rights reserved.\n// Use of this source code is governed by an MIT-style\n// license that can be found in the LICENSE file.\n\npackage evio\n\nimport (\n\t\"io\"\n\t\"net\"\n\t\"os\"\n\t\"strings\"\n\t\"time\"\n)\n\n// Action is an action that occurs after the completion of an event.\ntype Action int\n\nconst (\n\t// None indicates that no action should occur following an event.\n\tNone Action = iota\n\t// Detach detaches a connection. Not available for UDP connections.\n\tDetach\n\t// Close closes the connection.\n\tClose\n\t// Shutdown shutdowns the server.\n\tShutdown\n)\n\n// Options are set when the client opens.\ntype Options struct {\n\t// TCPKeepAlive (SO_KEEPALIVE) socket option.\n\tTCPKeepAlive time.Duration\n\t// ReuseInputBuffer will forces the connection to share and reuse the\n\t// same input packet buffer with all other connections that also use\n\t// this option.\n\t// Default value is false, which means that all input data which is\n\t// passed to the Data event will be a uniquely copied []byte slice.\n\tReuseInputBuffer bool\n}\n\n// Server represents a server context which provides information about the\n// running server and has control functions for managing state.\ntype Server struct {\n\t// The addrs parameter is an array of listening addresses that align\n\t// with the addr strings passed to the Serve function.\n\tAddrs []net.Addr\n\t// NumLoops is the number of loops that the server is using.\n\tNumLoops int\n}\n\n// Conn is an evio connection.\ntype Conn interface {\n\t// Context returns a user-defined context.\n\tContext() interface{}\n\t// SetContext sets a user-defined context.\n\tSetContext(interface{})\n\t// AddrIndex is the index of server address that was passed to the Serve call.\n\tAddrIndex() int\n\t// LocalAddr is the connection's local socket address.\n\tLocalAddr() net.Addr\n\t// RemoteAddr is the connection's remote peer address.\n\tRemoteAddr() net.Addr\n\t// Wake triggers a Data event for this connection.\n\tWake()\n}\n\n// LoadBalance sets the load balancing method.\ntype LoadBalance int\n\nconst (\n\t// Random requests that connections are randomly distributed.\n\tRandom LoadBalance = iota\n\t// RoundRobin requests that connections are distributed to a loop in a\n\t// round-robin fashion.\n\tRoundRobin\n\t// LeastConnections assigns the next accepted connection to the loop with\n\t// the least number of active connections.\n\tLeastConnections\n)\n\n// Events represents the server events for the Serve call.\n// Each event has an Action return value that is used manage the state\n// of the connection and server.\ntype Events struct {\n\t// NumLoops sets the number of loops to use for the server. Setting this\n\t// to a value greater than 1 will effectively make the server\n\t// multithreaded for multi-core machines. Which means you must take care\n\t// with synchonizing memory between all event callbacks. Setting to 0 or 1\n\t// will run the server single-threaded. Setting to -1 will automatically\n\t// assign this value equal to runtime.NumProcs().\n\tNumLoops int\n\t// LoadBalance sets the load balancing method. Load balancing is always a\n\t// best effort to attempt to distribute the incoming connections between\n\t// multiple loops. This option is only works when NumLoops is set.\n\tLoadBalance LoadBalance\n\t// Serving fires when the server can accept connections. The server\n\t// parameter has information and various utilities.\n\tServing func(server Server) (action Action)\n\t// Opened fires when a new connection has opened.\n\t// The info parameter has information about the connection such as\n\t// it's local and remote address.\n\t// Use the out return value to write data to the connection.\n\t// The opts return value is used to set connection options.\n\tOpened func(c Conn) (out []byte, opts Options, action Action)\n\t// Closed fires when a connection has closed.\n\t// The err parameter is the last known connection error.\n\tClosed func(c Conn, err error) (action Action)\n\t// Detached fires when a connection has been previously detached.\n\t// Once detached it's up to the receiver of this event to manage the\n\t// state of the connection. The Closed event will not be called for\n\t// this connection.\n\t// The conn parameter is a ReadWriteCloser that represents the\n\t// underlying socket connection. It can be freely used in goroutines\n\t// and should be closed when it's no longer needed.\n\tDetached func(c Conn, rwc io.ReadWriteCloser) (action Action)\n\t// PreWrite fires just before any data is written to any client socket.\n\tPreWrite func()\n\t// Data fires when a connection sends the server data.\n\t// The in parameter is the incoming data.\n\t// Use the out return value to write data to the connection.\n\tData func(c Conn, in []byte) (out []byte, action Action)\n\t// Tick fires immediately after the server starts and will fire again\n\t// following the duration specified by the delay return value.\n\tTick func() (delay time.Duration, action Action)\n}\n\n// Serve starts handling events for the specified addresses.\n//\n// Addresses should use a scheme prefix and be formatted\n// like `tcp://192.168.0.10:9851` or `unix://socket`.\n// Valid network schemes:\n//  tcp   - bind to both IPv4 and IPv6\n//  tcp4  - IPv4\n//  tcp6  - IPv6\n//  udp   - bind to both IPv4 and IPv6\n//  udp4  - IPv4\n//  udp6  - IPv6\n//  unix  - Unix Domain Socket\n//\n// The \"tcp\" network scheme is assumed when one is not specified.\nfunc Serve(events Events, addr ...string) error {\n\tvar lns []*listener\n\tdefer func() {\n\t\tfor _, ln := range lns {\n\t\t\tln.close()\n\t\t}\n\t}()\n\tvar stdlib bool\n\tfor _, addr := range addr {\n\t\tvar ln listener\n\t\tvar stdlibt bool\n\t\tln.network, ln.addr, ln.opts, stdlibt = parseAddr(addr)\n\t\tif stdlibt {\n\t\t\tstdlib = true\n\t\t}\n\t\tif ln.network == \"unix\" {\n\t\t\tos.RemoveAll(ln.addr)\n\t\t}\n\t\tvar err error\n\t\tif ln.network == \"udp\" {\n\t\t\tif ln.opts.reusePort {\n\t\t\t\tln.pconn, err = reuseportListenPacket(ln.network, ln.addr)\n\t\t\t} else {\n\t\t\t\tln.pconn, err = net.ListenPacket(ln.network, ln.addr)\n\t\t\t}\n\t\t} else {\n\t\t\tif ln.opts.reusePort {\n\t\t\t\tln.ln, err = reuseportListen(ln.network, ln.addr)\n\t\t\t} else {\n\t\t\t\tln.ln, err = net.Listen(ln.network, ln.addr)\n\t\t\t}\n\t\t}\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif ln.pconn != nil {\n\t\t\tln.lnaddr = ln.pconn.LocalAddr()\n\t\t} else {\n\t\t\tln.lnaddr = ln.ln.Addr()\n\t\t}\n\t\tif !stdlib {\n\t\t\tif err := ln.system(); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tlns = append(lns, &ln)\n\t}\n\tif stdlib {\n\t\treturn stdserve(events, lns)\n\t}\n\treturn serve(events, lns)\n}\n\n// InputStream is a helper type for managing input streams from inside\n// the Data event.\ntype InputStream struct{ b []byte }\n\n// Begin accepts a new packet and returns a working sequence of\n// unprocessed bytes.\nfunc (is *InputStream) Begin(packet []byte) (data []byte) {\n\tdata = packet\n\tif len(is.b) > 0 {\n\t\tis.b = append(is.b, data...)\n\t\tdata = is.b\n\t}\n\treturn data\n}\n\n// End shifts the stream to match the unprocessed data.\nfunc (is *InputStream) End(data []byte) {\n\tif len(data) > 0 {\n\t\tif len(data) != len(is.b) {\n\t\t\tis.b = append(is.b[:0], data...)\n\t\t}\n\t} else if len(is.b) > 0 {\n\t\tis.b = is.b[:0]\n\t}\n}\n\ntype listener struct {\n\tln      net.Listener\n\tlnaddr  net.Addr\n\tpconn   net.PacketConn\n\topts    addrOpts\n\tf       *os.File\n\tfd      int\n\tnetwork string\n\taddr    string\n}\n\ntype addrOpts struct {\n\treusePort bool\n}\n\nfunc parseAddr(addr string) (network, address string, opts addrOpts, stdlib bool) {\n\tnetwork = \"tcp\"\n\taddress = addr\n\topts.reusePort = false\n\tif strings.Contains(address, \"://\") {\n\t\tnetwork = strings.Split(address, \"://\")[0]\n\t\taddress = strings.Split(address, \"://\")[1]\n\t}\n\tif strings.HasSuffix(network, \"-net\") {\n\t\tstdlib = true\n\t\tnetwork = network[:len(network)-4]\n\t}\n\tq := strings.Index(address, \"?\")\n\tif q != -1 {\n\t\tfor _, part := range strings.Split(address[q+1:], \"&\") {\n\t\t\tkv := strings.Split(part, \"=\")\n\t\t\tif len(kv) == 2 {\n\t\t\t\tswitch kv[0] {\n\t\t\t\tcase \"reuseport\":\n\t\t\t\t\tif len(kv[1]) != 0 {\n\t\t\t\t\t\tswitch kv[1][0] {\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\topts.reusePort = kv[1][0] >= '1' && kv[1][0] <= '9'\n\t\t\t\t\t\tcase 'T', 't', 'Y', 'y':\n\t\t\t\t\t\t\topts.reusePort = true\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\taddress = address[:q]\n\t}\n\treturn\n}\n"
        },
        {
          "name": "evio_other.go",
          "type": "blob",
          "size": 0.8330078125,
          "content": "// Copyright 2018 Joshua J Baker. All rights reserved.\n// Use of this source code is governed by an MIT-style\n// license that can be found in the LICENSE file.\n\n// +build !darwin,!netbsd,!freebsd,!openbsd,!dragonfly,!linux\n\npackage evio\n\nimport (\n\t\"errors\"\n\t\"net\"\n\t\"os\"\n)\n\nfunc (ln *listener) close() {\n\tif ln.ln != nil {\n\t\tln.ln.Close()\n\t}\n\tif ln.pconn != nil {\n\t\tln.pconn.Close()\n\t}\n\tif ln.network == \"unix\" {\n\t\tos.RemoveAll(ln.addr)\n\t}\n}\n\nfunc (ln *listener) system() error {\n\treturn nil\n}\n\nfunc serve(events Events, listeners []*listener) error {\n\treturn stdserve(events, listeners)\n}\n\nfunc reuseportListenPacket(proto, addr string) (l net.PacketConn, err error) {\n\treturn nil, errors.New(\"reuseport is not available\")\n}\n\nfunc reuseportListen(proto, addr string) (l net.Listener, err error) {\n\treturn nil, errors.New(\"reuseport is not available\")\n}\n"
        },
        {
          "name": "evio_std.go",
          "type": "blob",
          "size": 9.6337890625,
          "content": "// Copyright 2018 Joshua J Baker. All rights reserved.\n// Use of this source code is governed by an MIT-style\n// license that can be found in the LICENSE file.\n\npackage evio\n\nimport (\n\t\"errors\"\n\t\"io\"\n\t\"net\"\n\t\"runtime\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n)\n\nvar errClosing = errors.New(\"closing\")\nvar errCloseConns = errors.New(\"close conns\")\n\ntype stdserver struct {\n\tevents   Events         // user events\n\tloops    []*stdloop     // all the loops\n\tlns      []*listener    // all the listeners\n\tloopwg   sync.WaitGroup // loop close waitgroup\n\tlnwg     sync.WaitGroup // listener close waitgroup\n\tcond     *sync.Cond     // shutdown signaler\n\tserr     error          // signal error\n\taccepted uintptr        // accept counter\n}\n\ntype stdudpconn struct {\n\taddrIndex  int\n\tlocalAddr  net.Addr\n\tremoteAddr net.Addr\n\tin         []byte\n}\n\nfunc (c *stdudpconn) Context() interface{}       { return nil }\nfunc (c *stdudpconn) SetContext(ctx interface{}) {}\nfunc (c *stdudpconn) AddrIndex() int             { return c.addrIndex }\nfunc (c *stdudpconn) LocalAddr() net.Addr        { return c.localAddr }\nfunc (c *stdudpconn) RemoteAddr() net.Addr       { return c.remoteAddr }\nfunc (c *stdudpconn) Wake()                      {}\n\ntype stdloop struct {\n\tidx   int               // loop index\n\tch    chan interface{}  // command channel\n\tconns map[*stdconn]bool // track all the conns bound to this loop\n}\n\ntype stdconn struct {\n\taddrIndex  int\n\tlocalAddr  net.Addr\n\tremoteAddr net.Addr\n\tconn       net.Conn    // original connection\n\tctx        interface{} // user-defined context\n\tloop       *stdloop    // owner loop\n\tlnidx      int         // index of listener\n\tdonein     []byte      // extra data for done connection\n\tdone       int32       // 0: attached, 1: closed, 2: detached\n}\n\ntype wakeReq struct {\n\tc *stdconn\n}\n\nfunc (c *stdconn) Context() interface{}       { return c.ctx }\nfunc (c *stdconn) SetContext(ctx interface{}) { c.ctx = ctx }\nfunc (c *stdconn) AddrIndex() int             { return c.addrIndex }\nfunc (c *stdconn) LocalAddr() net.Addr        { return c.localAddr }\nfunc (c *stdconn) RemoteAddr() net.Addr       { return c.remoteAddr }\nfunc (c *stdconn) Wake()                      { c.loop.ch <- wakeReq{c} }\n\ntype stdin struct {\n\tc  *stdconn\n\tin []byte\n}\n\ntype stderr struct {\n\tc   *stdconn\n\terr error\n}\n\n// waitForShutdown waits for a signal to shutdown\nfunc (s *stdserver) waitForShutdown() error {\n\ts.cond.L.Lock()\n\ts.cond.Wait()\n\terr := s.serr\n\ts.cond.L.Unlock()\n\treturn err\n}\n\n// signalShutdown signals a shutdown an begins server closing\nfunc (s *stdserver) signalShutdown(err error) {\n\ts.cond.L.Lock()\n\ts.serr = err\n\ts.cond.Signal()\n\ts.cond.L.Unlock()\n}\n\nfunc stdserve(events Events, listeners []*listener) error {\n\tnumLoops := events.NumLoops\n\tif numLoops <= 0 {\n\t\tif numLoops == 0 {\n\t\t\tnumLoops = 1\n\t\t} else {\n\t\t\tnumLoops = runtime.NumCPU()\n\t\t}\n\t}\n\n\ts := &stdserver{}\n\ts.events = events\n\ts.lns = listeners\n\ts.cond = sync.NewCond(&sync.Mutex{})\n\n\t//println(\"-- server starting\")\n\tif events.Serving != nil {\n\t\tvar svr Server\n\t\tsvr.NumLoops = numLoops\n\t\tsvr.Addrs = make([]net.Addr, len(listeners))\n\t\tfor i, ln := range listeners {\n\t\t\tsvr.Addrs[i] = ln.lnaddr\n\t\t}\n\t\taction := events.Serving(svr)\n\t\tswitch action {\n\t\tcase Shutdown:\n\t\t\treturn nil\n\t\t}\n\t}\n\tfor i := 0; i < numLoops; i++ {\n\t\ts.loops = append(s.loops, &stdloop{\n\t\t\tidx:   i,\n\t\t\tch:    make(chan interface{}),\n\t\t\tconns: make(map[*stdconn]bool),\n\t\t})\n\t}\n\tvar ferr error\n\tdefer func() {\n\t\t// wait on a signal for shutdown\n\t\tferr = s.waitForShutdown()\n\n\t\t// notify all loops to close by closing all listeners\n\t\tfor _, l := range s.loops {\n\t\t\tl.ch <- errClosing\n\t\t}\n\n\t\t// wait on all loops to main loop channel events\n\t\ts.loopwg.Wait()\n\n\t\t// shutdown all listeners\n\t\tfor i := 0; i < len(s.lns); i++ {\n\t\t\ts.lns[i].close()\n\t\t}\n\n\t\t// wait on all listeners to complete\n\t\ts.lnwg.Wait()\n\n\t\t// close all connections\n\t\ts.loopwg.Add(len(s.loops))\n\t\tfor _, l := range s.loops {\n\t\t\tl.ch <- errCloseConns\n\t\t}\n\t\ts.loopwg.Wait()\n\n\t}()\n\ts.loopwg.Add(numLoops)\n\tfor i := 0; i < numLoops; i++ {\n\t\tgo stdloopRun(s, s.loops[i])\n\t}\n\ts.lnwg.Add(len(listeners))\n\tfor i := 0; i < len(listeners); i++ {\n\t\tgo stdlistenerRun(s, listeners[i], i)\n\t}\n\treturn ferr\n}\n\nfunc stdlistenerRun(s *stdserver, ln *listener, lnidx int) {\n\tvar ferr error\n\tdefer func() {\n\t\ts.signalShutdown(ferr)\n\t\ts.lnwg.Done()\n\t}()\n\tvar packet [0xFFFF]byte\n\tfor {\n\t\tif ln.pconn != nil {\n\t\t\t// udp\n\t\t\tn, addr, err := ln.pconn.ReadFrom(packet[:])\n\t\t\tif err != nil {\n\t\t\t\tferr = err\n\t\t\t\treturn\n\t\t\t}\n\t\t\tl := s.loops[int(atomic.AddUintptr(&s.accepted, 1))%len(s.loops)]\n\t\t\tl.ch <- &stdudpconn{\n\t\t\t\taddrIndex:  lnidx,\n\t\t\t\tlocalAddr:  ln.lnaddr,\n\t\t\t\tremoteAddr: addr,\n\t\t\t\tin:         append([]byte{}, packet[:n]...),\n\t\t\t}\n\t\t} else {\n\t\t\t// tcp\n\t\t\tconn, err := ln.ln.Accept()\n\t\t\tif err != nil {\n\t\t\t\tferr = err\n\t\t\t\treturn\n\t\t\t}\n\t\t\tl := s.loops[int(atomic.AddUintptr(&s.accepted, 1))%len(s.loops)]\n\t\t\tc := &stdconn{conn: conn, loop: l, lnidx: lnidx}\n\t\t\tl.ch <- c\n\t\t\tgo func(c *stdconn) {\n\t\t\t\tvar packet [0xFFFF]byte\n\t\t\t\tfor {\n\t\t\t\t\tn, err := c.conn.Read(packet[:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tc.conn.SetReadDeadline(time.Time{})\n\t\t\t\t\t\tl.ch <- &stderr{c, err}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tl.ch <- &stdin{c, append([]byte{}, packet[:n]...)}\n\t\t\t\t}\n\t\t\t}(c)\n\t\t}\n\t}\n}\n\nfunc stdloopRun(s *stdserver, l *stdloop) {\n\tvar err error\n\ttick := make(chan bool)\n\ttock := make(chan time.Duration)\n\tdefer func() {\n\t\t//fmt.Println(\"-- loop stopped --\", l.idx)\n\t\tif l.idx == 0 && s.events.Tick != nil {\n\t\t\tclose(tock)\n\t\t\tgo func() {\n\t\t\t\tfor range tick {\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\ts.signalShutdown(err)\n\t\ts.loopwg.Done()\n\t\tstdloopEgress(s, l)\n\t\ts.loopwg.Done()\n\t}()\n\tif l.idx == 0 && s.events.Tick != nil {\n\t\tgo func() {\n\t\t\tfor {\n\t\t\t\ttick <- true\n\t\t\t\tdelay, ok := <-tock\n\t\t\t\tif !ok {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\ttime.Sleep(delay)\n\t\t\t}\n\t\t}()\n\t}\n\t//fmt.Println(\"-- loop started --\", l.idx)\n\tfor {\n\t\tselect {\n\t\tcase <-tick:\n\t\t\tdelay, action := s.events.Tick()\n\t\t\tswitch action {\n\t\t\tcase Shutdown:\n\t\t\t\terr = errClosing\n\t\t\t}\n\t\t\ttock <- delay\n\t\tcase v := <-l.ch:\n\t\t\tswitch v := v.(type) {\n\t\t\tcase error:\n\t\t\t\terr = v\n\t\t\tcase *stdconn:\n\t\t\t\terr = stdloopAccept(s, l, v)\n\t\t\tcase *stdin:\n\t\t\t\terr = stdloopRead(s, l, v.c, v.in)\n\t\t\tcase *stdudpconn:\n\t\t\t\terr = stdloopReadUDP(s, l, v)\n\t\t\tcase *stderr:\n\t\t\t\terr = stdloopError(s, l, v.c, v.err)\n\t\t\tcase wakeReq:\n\t\t\t\terr = stdloopRead(s, l, v.c, nil)\n\t\t\t}\n\t\t}\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t}\n}\n\nfunc stdloopEgress(s *stdserver, l *stdloop) {\n\tvar closed bool\nloop:\n\tfor v := range l.ch {\n\t\tswitch v := v.(type) {\n\t\tcase error:\n\t\t\tif v == errCloseConns {\n\t\t\t\tclosed = true\n\t\t\t\tfor c := range l.conns {\n\t\t\t\t\tstdloopClose(s, l, c)\n\t\t\t\t}\n\t\t\t}\n\t\tcase *stderr:\n\t\t\tstdloopError(s, l, v.c, v.err)\n\t\t}\n\t\tif len(l.conns) == 0 && closed {\n\t\t\tbreak loop\n\t\t}\n\t}\n}\n\nfunc stdloopError(s *stdserver, l *stdloop, c *stdconn, err error) error {\n\tdelete(l.conns, c)\n\tcloseEvent := true\n\tswitch atomic.LoadInt32(&c.done) {\n\tcase 0: // read error\n\t\tc.conn.Close()\n\t\tif err == io.EOF {\n\t\t\terr = nil\n\t\t}\n\tcase 1: // closed\n\t\tc.conn.Close()\n\t\terr = nil\n\tcase 2: // detached\n\t\terr = nil\n\t\tif s.events.Detached == nil {\n\t\t\tc.conn.Close()\n\t\t} else {\n\t\t\tcloseEvent = false\n\t\t\tswitch s.events.Detached(c, &stddetachedConn{c.conn, c.donein}) {\n\t\t\tcase Shutdown:\n\t\t\t\treturn errClosing\n\t\t\t}\n\t\t}\n\t}\n\tif closeEvent {\n\t\tif s.events.Closed != nil {\n\t\t\tswitch s.events.Closed(c, err) {\n\t\t\tcase Shutdown:\n\t\t\t\treturn errClosing\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}\n\ntype stddetachedConn struct {\n\tconn net.Conn // original conn\n\tin   []byte   // extra input data\n}\n\nfunc (c *stddetachedConn) Read(p []byte) (n int, err error) {\n\tif len(c.in) > 0 {\n\t\tif len(c.in) <= len(p) {\n\t\t\tcopy(p, c.in)\n\t\t\tn = len(c.in)\n\t\t\tc.in = nil\n\t\t\treturn\n\t\t}\n\t\tcopy(p, c.in[:len(p)])\n\t\tn = len(p)\n\t\tc.in = c.in[n:]\n\t\treturn\n\t}\n\treturn c.conn.Read(p)\n}\n\nfunc (c *stddetachedConn) Write(p []byte) (n int, err error) {\n\treturn c.conn.Write(p)\n}\n\nfunc (c *stddetachedConn) Close() error {\n\treturn c.conn.Close()\n}\n\nfunc (c *stddetachedConn) Wake() {}\n\nfunc stdloopRead(s *stdserver, l *stdloop, c *stdconn, in []byte) error {\n\tif atomic.LoadInt32(&c.done) == 2 {\n\t\t// should not ignore reads for detached connections\n\t\tc.donein = append(c.donein, in...)\n\t\treturn nil\n\t}\n\tif s.events.Data != nil {\n\t\tout, action := s.events.Data(c, in)\n\t\tif len(out) > 0 {\n\t\t\tif s.events.PreWrite != nil {\n\t\t\t\ts.events.PreWrite()\n\t\t\t}\n\t\t\tc.conn.Write(out)\n\t\t}\n\t\tswitch action {\n\t\tcase Shutdown:\n\t\t\treturn errClosing\n\t\tcase Detach:\n\t\t\treturn stdloopDetach(s, l, c)\n\t\tcase Close:\n\t\t\treturn stdloopClose(s, l, c)\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc stdloopReadUDP(s *stdserver, l *stdloop, c *stdudpconn) error {\n\tif s.events.Data != nil {\n\t\tout, action := s.events.Data(c, c.in)\n\t\tif len(out) > 0 {\n\t\t\tif s.events.PreWrite != nil {\n\t\t\t\ts.events.PreWrite()\n\t\t\t}\n\t\t\ts.lns[c.addrIndex].pconn.WriteTo(out, c.remoteAddr)\n\t\t}\n\t\tswitch action {\n\t\tcase Shutdown:\n\t\t\treturn errClosing\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc stdloopDetach(s *stdserver, l *stdloop, c *stdconn) error {\n\tatomic.StoreInt32(&c.done, 2)\n\tc.conn.SetReadDeadline(time.Now())\n\treturn nil\n}\n\nfunc stdloopClose(s *stdserver, l *stdloop, c *stdconn) error {\n\tatomic.StoreInt32(&c.done, 1)\n\tc.conn.SetReadDeadline(time.Now())\n\treturn nil\n}\n\nfunc stdloopAccept(s *stdserver, l *stdloop, c *stdconn) error {\n\tl.conns[c] = true\n\tc.addrIndex = c.lnidx\n\tc.localAddr = s.lns[c.lnidx].lnaddr\n\tc.remoteAddr = c.conn.RemoteAddr()\n\n\tif s.events.Opened != nil {\n\t\tout, opts, action := s.events.Opened(c)\n\t\tif len(out) > 0 {\n\t\t\tif s.events.PreWrite != nil {\n\t\t\t\ts.events.PreWrite()\n\t\t\t}\n\t\t\tc.conn.Write(out)\n\t\t}\n\t\tif opts.TCPKeepAlive > 0 {\n\t\t\tif c, ok := c.conn.(*net.TCPConn); ok {\n\t\t\t\tc.SetKeepAlive(true)\n\t\t\t\tc.SetKeepAlivePeriod(opts.TCPKeepAlive)\n\t\t\t}\n\t\t}\n\t\tswitch action {\n\t\tcase Shutdown:\n\t\t\treturn errClosing\n\t\tcase Detach:\n\t\t\treturn stdloopDetach(s, l, c)\n\t\tcase Close:\n\t\t\treturn stdloopClose(s, l, c)\n\t\t}\n\t}\n\treturn nil\n}\n"
        },
        {
          "name": "evio_test.go",
          "type": "blob",
          "size": 10.779296875,
          "content": "// Copyright 2017 Joshua J Baker. All rights reserved.\n// Use of this source code is governed by an MIT-style\n// license that can be found in the LICENSE file.\n\npackage evio\n\nimport (\n\t\"bufio\"\n\t\"fmt\"\n\t\"io\"\n\t\"math/rand\"\n\t\"net\"\n\t\"os\"\n\t\"strings\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestServe(t *testing.T) {\n\t// start a server\n\t// connect 10 clients\n\t// each client will pipe random data for 1-3 seconds.\n\t// the writes to the server will be random sizes. 0KB - 1MB.\n\t// the server will echo back the data.\n\t// waits for graceful connection closing.\n\tt.Run(\"stdlib\", func(t *testing.T) {\n\t\tt.Run(\"tcp\", func(t *testing.T) {\n\t\t\tt.Run(\"1-loop\", func(t *testing.T) {\n\t\t\t\ttestServe(\"tcp-net\", \":9997\", false, 10, 1, Random)\n\t\t\t})\n\t\t\tt.Run(\"5-loop\", func(t *testing.T) {\n\t\t\t\ttestServe(\"tcp-net\", \":9998\", false, 10, 5, LeastConnections)\n\t\t\t})\n\t\t\tt.Run(\"N-loop\", func(t *testing.T) {\n\t\t\t\ttestServe(\"tcp-net\", \":9999\", false, 10, -1, RoundRobin)\n\t\t\t})\n\t\t})\n\t\tt.Run(\"unix\", func(t *testing.T) {\n\t\t\tt.Run(\"1-loop\", func(t *testing.T) {\n\t\t\t\ttestServe(\"tcp-net\", \":9989\", true, 10, 1, Random)\n\t\t\t})\n\t\t\tt.Run(\"5-loop\", func(t *testing.T) {\n\t\t\t\ttestServe(\"tcp-net\", \":9988\", true, 10, 5, LeastConnections)\n\t\t\t})\n\t\t\tt.Run(\"N-loop\", func(t *testing.T) {\n\t\t\t\ttestServe(\"tcp-net\", \":9987\", true, 10, -1, RoundRobin)\n\t\t\t})\n\t\t})\n\t})\n\tt.Run(\"poll\", func(t *testing.T) {\n\t\tt.Run(\"tcp\", func(t *testing.T) {\n\t\t\tt.Run(\"1-loop\", func(t *testing.T) {\n\t\t\t\ttestServe(\"tcp\", \":9991\", false, 10, 1, Random)\n\t\t\t})\n\t\t\tt.Run(\"5-loop\", func(t *testing.T) {\n\t\t\t\ttestServe(\"tcp\", \":9992\", false, 10, 5, LeastConnections)\n\t\t\t})\n\t\t\tt.Run(\"N-loop\", func(t *testing.T) {\n\t\t\t\ttestServe(\"tcp\", \":9993\", false, 10, -1, RoundRobin)\n\t\t\t})\n\t\t})\n\t\tt.Run(\"unix\", func(t *testing.T) {\n\t\t\tt.Run(\"1-loop\", func(t *testing.T) {\n\t\t\t\ttestServe(\"tcp\", \":9994\", true, 10, 1, Random)\n\t\t\t})\n\t\t\tt.Run(\"5-loop\", func(t *testing.T) {\n\t\t\t\ttestServe(\"tcp\", \":9995\", true, 10, 5, LeastConnections)\n\t\t\t})\n\t\t\tt.Run(\"N-loop\", func(t *testing.T) {\n\t\t\t\ttestServe(\"tcp\", \":9996\", true, 10, -1, RoundRobin)\n\t\t\t})\n\t\t})\n\t})\n\n}\n\nfunc testServe(network, addr string, unix bool, nclients, nloops int, balance LoadBalance) {\n\tvar started int32\n\tvar connected int32\n\tvar disconnected int32\n\n\tvar events Events\n\tevents.LoadBalance = balance\n\tevents.NumLoops = nloops\n\tevents.Serving = func(srv Server) (action Action) {\n\t\treturn\n\t}\n\tevents.Opened = func(c Conn) (out []byte, opts Options, action Action) {\n\t\tc.SetContext(c)\n\t\tatomic.AddInt32(&connected, 1)\n\t\tout = []byte(\"sweetness\\r\\n\")\n\t\topts.TCPKeepAlive = time.Minute * 5\n\t\tif c.LocalAddr() == nil {\n\t\t\tpanic(\"nil local addr\")\n\t\t}\n\t\tif c.RemoteAddr() == nil {\n\t\t\tpanic(\"nil local addr\")\n\t\t}\n\t\treturn\n\t}\n\tevents.Closed = func(c Conn, err error) (action Action) {\n\t\tif c.Context() != c {\n\t\t\tpanic(\"invalid context\")\n\t\t}\n\t\tatomic.AddInt32(&disconnected, 1)\n\t\tif atomic.LoadInt32(&connected) == atomic.LoadInt32(&disconnected) &&\n\t\t\tatomic.LoadInt32(&disconnected) == int32(nclients) {\n\t\t\taction = Shutdown\n\t\t}\n\t\treturn\n\t}\n\tevents.Data = func(c Conn, in []byte) (out []byte, action Action) {\n\t\tout = in\n\t\treturn\n\t}\n\tevents.Tick = func() (delay time.Duration, action Action) {\n\t\tif atomic.LoadInt32(&started) == 0 {\n\t\t\tfor i := 0; i < nclients; i++ {\n\t\t\t\tgo startClient(network, addr, nloops)\n\t\t\t}\n\t\t\tatomic.StoreInt32(&started, 1)\n\t\t}\n\t\tdelay = time.Second / 5\n\t\treturn\n\t}\n\tvar err error\n\tif unix {\n\t\tsocket := strings.Replace(addr, \":\", \"socket\", 1)\n\t\tos.RemoveAll(socket)\n\t\tdefer os.RemoveAll(socket)\n\t\terr = Serve(events, network+\"://\"+addr, \"unix://\"+socket)\n\t} else {\n\t\terr = Serve(events, network+\"://\"+addr)\n\t}\n\tif err != nil {\n\t\tpanic(err)\n\t}\n}\n\nfunc startClient(network, addr string, nloops int) {\n\tonetwork := network\n\tnetwork = strings.Replace(network, \"-net\", \"\", -1)\n\trand.Seed(time.Now().UnixNano())\n\tc, err := net.Dial(network, addr)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer c.Close()\n\trd := bufio.NewReader(c)\n\tmsg, err := rd.ReadBytes('\\n')\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tif string(msg) != \"sweetness\\r\\n\" {\n\t\tpanic(\"bad header\")\n\t}\n\tduration := time.Duration((rand.Float64()*2+1)*float64(time.Second)) / 8\n\tstart := time.Now()\n\tfor time.Since(start) < duration {\n\t\tsz := rand.Int() % (1024 * 1024)\n\t\tdata := make([]byte, sz)\n\t\tif _, err := rand.Read(data); err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\tif _, err := c.Write(data); err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\tdata2 := make([]byte, len(data))\n\t\tif _, err := io.ReadFull(rd, data2); err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\tif string(data) != string(data2) {\n\t\t\tfmt.Printf(\"mismatch %s/%d: %d vs %d bytes\\n\", onetwork, nloops, len(data), len(data2))\n\t\t\t//panic(\"mismatch\")\n\t\t}\n\t}\n}\n\nfunc must(err error) {\n\tif err != nil {\n\t\tpanic(err)\n\t}\n}\nfunc TestTick(t *testing.T) {\n\tvar wg sync.WaitGroup\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\ttestTick(\"tcp\", \":9991\", false)\n\t}()\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\ttestTick(\"tcp\", \":9992\", true)\n\t}()\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\ttestTick(\"unix\", \"socket1\", false)\n\t}()\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\ttestTick(\"unix\", \"socket2\", true)\n\t}()\n\twg.Wait()\n}\nfunc testTick(network, addr string, stdlib bool) {\n\tvar events Events\n\tvar count int\n\tstart := time.Now()\n\tevents.Tick = func() (delay time.Duration, action Action) {\n\t\tif count == 25 {\n\t\t\taction = Shutdown\n\t\t\treturn\n\t\t}\n\t\tcount++\n\t\tdelay = time.Millisecond * 10\n\t\treturn\n\t}\n\tif stdlib {\n\t\tmust(Serve(events, network+\"-net://\"+addr))\n\t} else {\n\t\tmust(Serve(events, network+\"://\"+addr))\n\t}\n\tdur := time.Since(start)\n\tif dur < 250&time.Millisecond || dur > time.Second {\n\t\tpanic(\"bad ticker timing\")\n\t}\n}\n\nfunc TestShutdown(t *testing.T) {\n\tvar wg sync.WaitGroup\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\ttestShutdown(\"tcp\", \":9991\", false)\n\t}()\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\ttestShutdown(\"tcp\", \":9992\", true)\n\t}()\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\ttestShutdown(\"unix\", \"socket1\", false)\n\t}()\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\ttestShutdown(\"unix\", \"socket2\", true)\n\t}()\n\twg.Wait()\n}\nfunc testShutdown(network, addr string, stdlib bool) {\n\tvar events Events\n\tvar count int\n\tvar clients int64\n\tvar N = 10\n\tevents.Opened = func(c Conn) (out []byte, opts Options, action Action) {\n\t\tatomic.AddInt64(&clients, 1)\n\t\treturn\n\t}\n\tevents.Closed = func(c Conn, err error) (action Action) {\n\t\tatomic.AddInt64(&clients, -1)\n\t\treturn\n\t}\n\tevents.Tick = func() (delay time.Duration, action Action) {\n\t\tif count == 0 {\n\t\t\t// start clients\n\t\t\tfor i := 0; i < N; i++ {\n\t\t\t\tgo func() {\n\t\t\t\t\tconn, err := net.Dial(network, addr)\n\t\t\t\t\tmust(err)\n\t\t\t\t\tdefer conn.Close()\n\t\t\t\t\t_, err = conn.Read([]byte{0})\n\t\t\t\t\tif err == nil {\n\t\t\t\t\t\tpanic(\"expected error\")\n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t}\n\t\t} else {\n\t\t\tif int(atomic.LoadInt64(&clients)) == N {\n\t\t\t\taction = Shutdown\n\t\t\t}\n\t\t}\n\t\tcount++\n\t\tdelay = time.Second / 20\n\t\treturn\n\t}\n\tif stdlib {\n\t\tmust(Serve(events, network+\"-net://\"+addr))\n\t} else {\n\t\tmust(Serve(events, network+\"://\"+addr))\n\t}\n\tif clients != 0 {\n\t\tpanic(\"did not call close on all clients\")\n\t}\n}\n\nfunc TestDetach(t *testing.T) {\n\tt.Run(\"poll\", func(t *testing.T) {\n\t\tt.Run(\"tcp\", func(t *testing.T) {\n\t\t\ttestDetach(\"tcp\", \":9991\", false)\n\t\t})\n\t\tt.Run(\"unix\", func(t *testing.T) {\n\t\t\ttestDetach(\"unix\", \"socket1\", false)\n\t\t})\n\t})\n\tt.Run(\"stdlib\", func(t *testing.T) {\n\t\tt.Run(\"tcp\", func(t *testing.T) {\n\t\t\ttestDetach(\"tcp\", \":9992\", true)\n\t\t})\n\t\tt.Run(\"unix\", func(t *testing.T) {\n\t\t\ttestDetach(\"unix\", \"socket2\", true)\n\t\t})\n\t})\n}\n\nfunc testDetach(network, addr string, stdlib bool) {\n\t// we will write a bunch of data with the text \"--detached--\" in the\n\t// middle followed by a bunch of data.\n\trand.Seed(time.Now().UnixNano())\n\trdat := make([]byte, 10*1024)\n\tif _, err := rand.Read(rdat); err != nil {\n\t\tpanic(\"random error: \" + err.Error())\n\t}\n\texpected := []byte(string(rdat) + \"--detached--\" + string(rdat))\n\tvar cin []byte\n\tvar events Events\n\tevents.Data = func(c Conn, in []byte) (out []byte, action Action) {\n\t\tcin = append(cin, in...)\n\t\tif len(cin) >= len(expected) {\n\t\t\tif string(cin) != string(expected) {\n\t\t\t\tpanic(\"mismatch client -> server\")\n\t\t\t}\n\t\t\treturn cin, Detach\n\t\t}\n\t\treturn\n\t}\n\n\tvar done int64\n\tevents.Detached = func(c Conn, conn io.ReadWriteCloser) (action Action) {\n\t\tgo func() {\n\t\t\tp := make([]byte, len(expected))\n\t\t\tdefer conn.Close()\n\t\t\t_, err := io.ReadFull(conn, p)\n\t\t\tmust(err)\n\t\t\tconn.Write(expected)\n\t\t}()\n\t\treturn\n\t}\n\n\tevents.Serving = func(srv Server) (action Action) {\n\t\tgo func() {\n\t\t\tp := make([]byte, len(expected))\n\t\t\t_ = expected\n\t\t\tconn, err := net.Dial(network, addr)\n\t\t\tmust(err)\n\t\t\tdefer conn.Close()\n\t\t\tconn.Write(expected)\n\t\t\t_, err = io.ReadFull(conn, p)\n\t\t\tmust(err)\n\t\t\tconn.Write(expected)\n\t\t\t_, err = io.ReadFull(conn, p)\n\t\t\tmust(err)\n\t\t\tatomic.StoreInt64(&done, 1)\n\t\t}()\n\t\treturn\n\t}\n\tevents.Tick = func() (delay time.Duration, action Action) {\n\t\tdelay = time.Second / 5\n\t\tif atomic.LoadInt64(&done) == 1 {\n\t\t\taction = Shutdown\n\t\t}\n\t\treturn\n\t}\n\tif stdlib {\n\t\tmust(Serve(events, network+\"-net://\"+addr))\n\t} else {\n\t\tmust(Serve(events, network+\"://\"+addr))\n\t}\n}\n\nfunc TestBadAddresses(t *testing.T) {\n\tvar events Events\n\tevents.Serving = func(srv Server) (action Action) {\n\t\treturn Shutdown\n\t}\n\tif err := Serve(events, \"tulip://howdy\"); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n\tif err := Serve(events, \"howdy\"); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n\tif err := Serve(events, \"tcp://\"); err != nil {\n\t\tt.Fatalf(\"expected nil, got '%v'\", err)\n\t}\n}\n\nfunc TestInputStream(t *testing.T) {\n\tvar s InputStream\n\tin := []byte(\"HELLO\")\n\tdata := s.Begin(in)\n\tif string(data) != string(in) {\n\t\tt.Fatalf(\"expected '%v', got '%v'\", in, data)\n\t}\n\ts.End(in[3:])\n\tdata = s.Begin([]byte(\"WLY\"))\n\tif string(data) != \"LOWLY\" {\n\t\tt.Fatalf(\"expected '%v', got '%v'\", \"LOWLY\", data)\n\t}\n\ts.End(nil)\n\tdata = s.Begin([]byte(\"PLAYER\"))\n\tif string(data) != \"PLAYER\" {\n\t\tt.Fatalf(\"expected '%v', got '%v'\", \"PLAYER\", data)\n\t}\n}\n\nfunc TestReuseInputBuffer(t *testing.T) {\n\treuses := []bool{true, false}\n\tfor _, reuse := range reuses {\n\t\tvar events Events\n\t\tevents.Opened = func(c Conn) (out []byte, opts Options, action Action) {\n\t\t\topts.ReuseInputBuffer = reuse\n\t\t\treturn\n\t\t}\n\t\tvar prev []byte\n\t\tevents.Data = func(c Conn, in []byte) (out []byte, action Action) {\n\t\t\tif prev == nil {\n\t\t\t\tprev = in\n\t\t\t} else {\n\t\t\t\treused := string(in) == string(prev)\n\t\t\t\tif reused != reuse {\n\t\t\t\t\tt.Fatalf(\"expected %v, got %v\", reuse, reused)\n\t\t\t\t}\n\t\t\t\taction = Shutdown\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tevents.Serving = func(_ Server) (action Action) {\n\t\t\tgo func() {\n\t\t\t\tc, err := net.Dial(\"tcp\", \":9991\")\n\t\t\t\tmust(err)\n\t\t\t\tdefer c.Close()\n\t\t\t\tc.Write([]byte(\"packet1\"))\n\t\t\t\ttime.Sleep(time.Second / 5)\n\t\t\t\tc.Write([]byte(\"packet2\"))\n\t\t\t}()\n\t\t\treturn\n\t\t}\n\t\tmust(Serve(events, \"tcp://:9991\"))\n\t}\n\n}\n\nfunc TestReuseport(t *testing.T) {\n\tvar events Events\n\tevents.Serving = func(s Server) (action Action) {\n\t\treturn Shutdown\n\t}\n\tvar wg sync.WaitGroup\n\twg.Add(5)\n\tfor i := 0; i < 5; i++ {\n\t\tvar t = \"1\"\n\t\tif i%2 == 0 {\n\t\t\tt = \"true\"\n\t\t}\n\t\tgo func(t string) {\n\t\t\tdefer wg.Done()\n\t\t\tmust(Serve(events, \"tcp://:9991?reuseport=\"+t))\n\t\t}(t)\n\t}\n\twg.Wait()\n}\n"
        },
        {
          "name": "evio_unix.go",
          "type": "blob",
          "size": 11.63671875,
          "content": "// Copyright 2018 Joshua J Baker. All rights reserved.\n// Use of this source code is governed by an MIT-style\n// license that can be found in the LICENSE file.\n\n// +build darwin netbsd freebsd openbsd dragonfly linux\n\npackage evio\n\nimport (\n\t\"io\"\n\t\"net\"\n\t\"os\"\n\t\"runtime\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"syscall\"\n\t\"time\"\n\n\treuseport \"github.com/kavu/go_reuseport\"\n\t\"github.com/tidwall/evio/internal\"\n)\n\ntype conn struct {\n\tfd         int              // file descriptor\n\tlnidx      int              // listener index in the server lns list\n\tout        []byte           // write buffer\n\tsa         syscall.Sockaddr // remote socket address\n\treuse      bool             // should reuse input buffer\n\topened     bool             // connection opened event fired\n\taction     Action           // next user action\n\tctx        interface{}      // user-defined context\n\taddrIndex  int              // index of listening address\n\tlocalAddr  net.Addr         // local addre\n\tremoteAddr net.Addr         // remote addr\n\tloop       *loop            // connected loop\n}\n\nfunc (c *conn) Context() interface{}       { return c.ctx }\nfunc (c *conn) SetContext(ctx interface{}) { c.ctx = ctx }\nfunc (c *conn) AddrIndex() int             { return c.addrIndex }\nfunc (c *conn) LocalAddr() net.Addr        { return c.localAddr }\nfunc (c *conn) RemoteAddr() net.Addr       { return c.remoteAddr }\nfunc (c *conn) Wake() {\n\tif c.loop != nil {\n\t\tc.loop.poll.Trigger(c)\n\t}\n}\n\ntype server struct {\n\tevents   Events             // user events\n\tloops    []*loop            // all the loops\n\tlns      []*listener        // all the listeners\n\twg       sync.WaitGroup     // loop close waitgroup\n\tcond     *sync.Cond         // shutdown signaler\n\tbalance  LoadBalance        // load balancing method\n\taccepted uintptr            // accept counter\n\ttch      chan time.Duration // ticker channel\n\n\t//ticktm   time.Time      // next tick time\n}\n\ntype loop struct {\n\tidx     int            // loop index in the server loops list\n\tpoll    *internal.Poll // epoll or kqueue\n\tpacket  []byte         // read packet buffer\n\tfdconns map[int]*conn  // loop connections fd -> conn\n\tcount   int32          // connection count\n}\n\n// waitForShutdown waits for a signal to shutdown\nfunc (s *server) waitForShutdown() {\n\ts.cond.L.Lock()\n\ts.cond.Wait()\n\ts.cond.L.Unlock()\n}\n\n// signalShutdown signals a shutdown an begins server closing\nfunc (s *server) signalShutdown() {\n\ts.cond.L.Lock()\n\ts.cond.Signal()\n\ts.cond.L.Unlock()\n}\n\nfunc serve(events Events, listeners []*listener) error {\n\t// figure out the correct number of loops/goroutines to use.\n\tnumLoops := events.NumLoops\n\tif numLoops <= 0 {\n\t\tif numLoops == 0 {\n\t\t\tnumLoops = 1\n\t\t} else {\n\t\t\tnumLoops = runtime.NumCPU()\n\t\t}\n\t}\n\n\ts := &server{}\n\ts.events = events\n\ts.lns = listeners\n\ts.cond = sync.NewCond(&sync.Mutex{})\n\ts.balance = events.LoadBalance\n\ts.tch = make(chan time.Duration)\n\n\t//println(\"-- server starting\")\n\tif s.events.Serving != nil {\n\t\tvar svr Server\n\t\tsvr.NumLoops = numLoops\n\t\tsvr.Addrs = make([]net.Addr, len(listeners))\n\t\tfor i, ln := range listeners {\n\t\t\tsvr.Addrs[i] = ln.lnaddr\n\t\t}\n\t\taction := s.events.Serving(svr)\n\t\tswitch action {\n\t\tcase None:\n\t\tcase Shutdown:\n\t\t\treturn nil\n\t\t}\n\t}\n\n\tdefer func() {\n\t\t// wait on a signal for shutdown\n\t\ts.waitForShutdown()\n\n\t\t// notify all loops to close by closing all listeners\n\t\tfor _, l := range s.loops {\n\t\t\tl.poll.Trigger(errClosing)\n\t\t}\n\n\t\t// wait on all loops to complete reading events\n\t\ts.wg.Wait()\n\n\t\t// close loops and all outstanding connections\n\t\tfor _, l := range s.loops {\n\t\t\tfor _, c := range l.fdconns {\n\t\t\t\tloopCloseConn(s, l, c, nil)\n\t\t\t}\n\t\t\tl.poll.Close()\n\t\t}\n\t\t//println(\"-- server stopped\")\n\t}()\n\n\t// create loops locally and bind the listeners.\n\tfor i := 0; i < numLoops; i++ {\n\t\tl := &loop{\n\t\t\tidx:     i,\n\t\t\tpoll:    internal.OpenPoll(),\n\t\t\tpacket:  make([]byte, 0xFFFF),\n\t\t\tfdconns: make(map[int]*conn),\n\t\t}\n\t\tfor _, ln := range listeners {\n\t\t\tl.poll.AddRead(ln.fd)\n\t\t}\n\t\ts.loops = append(s.loops, l)\n\t}\n\t// start loops in background\n\ts.wg.Add(len(s.loops))\n\tfor _, l := range s.loops {\n\t\tgo loopRun(s, l)\n\t}\n\treturn nil\n}\n\nfunc loopCloseConn(s *server, l *loop, c *conn, err error) error {\n\tatomic.AddInt32(&l.count, -1)\n\tdelete(l.fdconns, c.fd)\n\tsyscall.Close(c.fd)\n\tif s.events.Closed != nil {\n\t\tswitch s.events.Closed(c, err) {\n\t\tcase None:\n\t\tcase Shutdown:\n\t\t\treturn errClosing\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc loopDetachConn(s *server, l *loop, c *conn, err error) error {\n\tif s.events.Detached == nil {\n\t\treturn loopCloseConn(s, l, c, err)\n\t}\n\tl.poll.ModDetach(c.fd)\n\n\tatomic.AddInt32(&l.count, -1)\n\tdelete(l.fdconns, c.fd)\n\tif err := syscall.SetNonblock(c.fd, false); err != nil {\n\t\treturn err\n\t}\n\tswitch s.events.Detached(c, &detachedConn{fd: c.fd}) {\n\tcase None:\n\tcase Shutdown:\n\t\treturn errClosing\n\t}\n\treturn nil\n}\n\nfunc loopNote(s *server, l *loop, note interface{}) error {\n\tvar err error\n\tswitch v := note.(type) {\n\tcase time.Duration:\n\t\tdelay, action := s.events.Tick()\n\t\tswitch action {\n\t\tcase None:\n\t\tcase Shutdown:\n\t\t\terr = errClosing\n\t\t}\n\t\ts.tch <- delay\n\tcase error: // shutdown\n\t\terr = v\n\tcase *conn:\n\t\t// Wake called for connection\n\t\tif l.fdconns[v.fd] != v {\n\t\t\treturn nil // ignore stale wakes\n\t\t}\n\t\treturn loopWake(s, l, v)\n\t}\n\treturn err\n}\n\nfunc loopRun(s *server, l *loop) {\n\tdefer func() {\n\t\t//fmt.Println(\"-- loop stopped --\", l.idx)\n\t\ts.signalShutdown()\n\t\ts.wg.Done()\n\t}()\n\n\tif l.idx == 0 && s.events.Tick != nil {\n\t\tgo loopTicker(s, l)\n\t}\n\n\t//fmt.Println(\"-- loop started --\", l.idx)\n\tl.poll.Wait(func(fd int, note interface{}) error {\n\t\tif fd == 0 {\n\t\t\treturn loopNote(s, l, note)\n\t\t}\n\t\tc := l.fdconns[fd]\n\t\tswitch {\n\t\tcase c == nil:\n\t\t\treturn loopAccept(s, l, fd)\n\t\tcase !c.opened:\n\t\t\treturn loopOpened(s, l, c)\n\t\tcase len(c.out) > 0:\n\t\t\treturn loopWrite(s, l, c)\n\t\tcase c.action != None:\n\t\t\treturn loopAction(s, l, c)\n\t\tdefault:\n\t\t\treturn loopRead(s, l, c)\n\t\t}\n\t})\n}\n\nfunc loopTicker(s *server, l *loop) {\n\tfor {\n\t\tif err := l.poll.Trigger(time.Duration(0)); err != nil {\n\t\t\tbreak\n\t\t}\n\t\ttime.Sleep(<-s.tch)\n\t}\n}\n\nfunc loopAccept(s *server, l *loop, fd int) error {\n\tfor i, ln := range s.lns {\n\t\tif ln.fd == fd {\n\t\t\tif len(s.loops) > 1 {\n\t\t\t\tswitch s.balance {\n\t\t\t\tcase LeastConnections:\n\t\t\t\t\tn := atomic.LoadInt32(&l.count)\n\t\t\t\t\tfor _, lp := range s.loops {\n\t\t\t\t\t\tif lp.idx != l.idx {\n\t\t\t\t\t\t\tif atomic.LoadInt32(&lp.count) < n {\n\t\t\t\t\t\t\t\treturn nil // do not accept\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\tcase RoundRobin:\n\t\t\t\t\tidx := int(atomic.LoadUintptr(&s.accepted)) % len(s.loops)\n\t\t\t\t\tif idx != l.idx {\n\t\t\t\t\t\treturn nil // do not accept\n\t\t\t\t\t}\n\t\t\t\t\tatomic.AddUintptr(&s.accepted, 1)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif ln.pconn != nil {\n\t\t\t\treturn loopUDPRead(s, l, i, fd)\n\t\t\t}\n\t\t\tnfd, sa, err := syscall.Accept(fd)\n\t\t\tif err != nil {\n\t\t\t\tif err == syscall.EAGAIN {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err := syscall.SetNonblock(nfd, true); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tc := &conn{fd: nfd, sa: sa, lnidx: i, loop: l}\n\t\t\tc.out = nil\n\t\t\tl.fdconns[c.fd] = c\n\t\t\tl.poll.AddReadWrite(c.fd)\n\t\t\tatomic.AddInt32(&l.count, 1)\n\t\t\tbreak\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc loopUDPRead(s *server, l *loop, lnidx, fd int) error {\n\tn, sa, err := syscall.Recvfrom(fd, l.packet, 0)\n\tif err != nil || n == 0 {\n\t\treturn nil\n\t}\n\tif s.events.Data != nil {\n\t\tvar sa6 syscall.SockaddrInet6\n\t\tswitch sa := sa.(type) {\n\t\tcase *syscall.SockaddrInet4:\n\t\t\tsa6.ZoneId = 0\n\t\t\tsa6.Port = sa.Port\n\t\t\tfor i := 0; i < 12; i++ {\n\t\t\t\tsa6.Addr[i] = 0\n\t\t\t}\n\t\t\tsa6.Addr[12] = sa.Addr[0]\n\t\t\tsa6.Addr[13] = sa.Addr[1]\n\t\t\tsa6.Addr[14] = sa.Addr[2]\n\t\t\tsa6.Addr[15] = sa.Addr[3]\n\t\tcase *syscall.SockaddrInet6:\n\t\t\tsa6 = *sa\n\t\t}\n\t\tc := &conn{}\n\t\tc.addrIndex = lnidx\n\t\tc.localAddr = s.lns[lnidx].lnaddr\n\t\tc.remoteAddr = internal.SockaddrToAddr(&sa6)\n\t\tin := append([]byte{}, l.packet[:n]...)\n\t\tout, action := s.events.Data(c, in)\n\t\tif len(out) > 0 {\n\t\t\tif s.events.PreWrite != nil {\n\t\t\t\ts.events.PreWrite()\n\t\t\t}\n\t\t\tsyscall.Sendto(fd, out, 0, sa)\n\t\t}\n\t\tswitch action {\n\t\tcase Shutdown:\n\t\t\treturn errClosing\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc loopOpened(s *server, l *loop, c *conn) error {\n\tc.opened = true\n\tc.addrIndex = c.lnidx\n\tc.localAddr = s.lns[c.lnidx].lnaddr\n\tc.remoteAddr = internal.SockaddrToAddr(c.sa)\n\tif s.events.Opened != nil {\n\t\tout, opts, action := s.events.Opened(c)\n\t\tif len(out) > 0 {\n\t\t\tc.out = append([]byte{}, out...)\n\t\t}\n\t\tc.action = action\n\t\tc.reuse = opts.ReuseInputBuffer\n\t\tif opts.TCPKeepAlive > 0 {\n\t\t\tif _, ok := s.lns[c.lnidx].ln.(*net.TCPListener); ok {\n\t\t\t\tinternal.SetKeepAlive(c.fd, int(opts.TCPKeepAlive/time.Second))\n\t\t\t}\n\t\t}\n\t}\n\tif len(c.out) == 0 && c.action == None {\n\t\tl.poll.ModRead(c.fd)\n\t}\n\treturn nil\n}\n\nfunc loopWrite(s *server, l *loop, c *conn) error {\n\tif s.events.PreWrite != nil {\n\t\ts.events.PreWrite()\n\t}\n\tn, err := syscall.Write(c.fd, c.out)\n\tif err != nil {\n\t\tif err == syscall.EAGAIN {\n\t\t\treturn nil\n\t\t}\n\t\treturn loopCloseConn(s, l, c, err)\n\t}\n\tif n == len(c.out) {\n\t\t// release the connection output page if it goes over page size,\n\t\t// otherwise keep reusing existing page.\n\t\tif cap(c.out) > 4096 {\n\t\t\tc.out = nil\n\t\t} else {\n\t\t\tc.out = c.out[:0]\n\t\t}\n\t} else {\n\t\tc.out = c.out[n:]\n\t}\n\tif len(c.out) == 0 && c.action == None {\n\t\tl.poll.ModRead(c.fd)\n\t}\n\treturn nil\n}\n\nfunc loopAction(s *server, l *loop, c *conn) error {\n\tswitch c.action {\n\tdefault:\n\t\tc.action = None\n\tcase Close:\n\t\treturn loopCloseConn(s, l, c, nil)\n\tcase Shutdown:\n\t\treturn errClosing\n\tcase Detach:\n\t\treturn loopDetachConn(s, l, c, nil)\n\t}\n\tif len(c.out) == 0 && c.action == None {\n\t\tl.poll.ModRead(c.fd)\n\t}\n\treturn nil\n}\n\nfunc loopWake(s *server, l *loop, c *conn) error {\n\tif s.events.Data == nil {\n\t\treturn nil\n\t}\n\tout, action := s.events.Data(c, nil)\n\tc.action = action\n\tif len(out) > 0 {\n\t\tc.out = append([]byte{}, out...)\n\t}\n\tif len(c.out) != 0 || c.action != None {\n\t\tl.poll.ModReadWrite(c.fd)\n\t}\n\treturn nil\n}\n\nfunc loopRead(s *server, l *loop, c *conn) error {\n\tvar in []byte\n\tn, err := syscall.Read(c.fd, l.packet)\n\tif n == 0 || err != nil {\n\t\tif err == syscall.EAGAIN {\n\t\t\treturn nil\n\t\t}\n\t\treturn loopCloseConn(s, l, c, err)\n\t}\n\tin = l.packet[:n]\n\tif !c.reuse {\n\t\tin = append([]byte{}, in...)\n\t}\n\tif s.events.Data != nil {\n\t\tout, action := s.events.Data(c, in)\n\t\tc.action = action\n\t\tif len(out) > 0 {\n\t\t\tc.out = append(c.out[:0], out...)\n\t\t}\n\t}\n\tif len(c.out) != 0 || c.action != None {\n\t\tl.poll.ModReadWrite(c.fd)\n\t}\n\treturn nil\n}\n\ntype detachedConn struct {\n\tfd int\n}\n\nfunc (c *detachedConn) Close() error {\n\terr := syscall.Close(c.fd)\n\tif err != nil {\n\t\treturn err\n\t}\n\tc.fd = -1\n\treturn nil\n}\n\nfunc (c *detachedConn) Read(p []byte) (n int, err error) {\n\tn, err = syscall.Read(c.fd, p)\n\tif err != nil {\n\t\treturn n, err\n\t}\n\tif n == 0 {\n\t\tif len(p) == 0 {\n\t\t\treturn 0, nil\n\t\t}\n\t\treturn 0, io.EOF\n\t}\n\treturn n, nil\n}\n\nfunc (c *detachedConn) Write(p []byte) (n int, err error) {\n\tn = len(p)\n\tfor len(p) > 0 {\n\t\tnn, err := syscall.Write(c.fd, p)\n\t\tif err != nil {\n\t\t\treturn n, err\n\t\t}\n\t\tp = p[nn:]\n\t}\n\treturn n, nil\n}\n\nfunc (ln *listener) close() {\n\tif ln.fd != 0 {\n\t\tsyscall.Close(ln.fd)\n\t}\n\tif ln.f != nil {\n\t\tln.f.Close()\n\t}\n\tif ln.ln != nil {\n\t\tln.ln.Close()\n\t}\n\tif ln.pconn != nil {\n\t\tln.pconn.Close()\n\t}\n\tif ln.network == \"unix\" {\n\t\tos.RemoveAll(ln.addr)\n\t}\n}\n\n// system takes the net listener and detaches it from it's parent\n// event loop, grabs the file descriptor, and makes it non-blocking.\nfunc (ln *listener) system() error {\n\tvar err error\n\tswitch netln := ln.ln.(type) {\n\tcase nil:\n\t\tswitch pconn := ln.pconn.(type) {\n\t\tcase *net.UDPConn:\n\t\t\tln.f, err = pconn.File()\n\t\t}\n\tcase *net.TCPListener:\n\t\tln.f, err = netln.File()\n\tcase *net.UnixListener:\n\t\tln.f, err = netln.File()\n\t}\n\tif err != nil {\n\t\tln.close()\n\t\treturn err\n\t}\n\tln.fd = int(ln.f.Fd())\n\treturn syscall.SetNonblock(ln.fd, true)\n}\n\nfunc reuseportListenPacket(proto, addr string) (l net.PacketConn, err error) {\n\treturn reuseport.ListenPacket(proto, addr)\n}\n\nfunc reuseportListen(proto, addr string) (l net.Listener, err error) {\n\treturn reuseport.Listen(proto, addr)\n}\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.0830078125,
          "content": "module github.com/tidwall/evio\n\ngo 1.15\n\nrequire github.com/kavu/go_reuseport v1.5.0\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 0.1708984375,
          "content": "github.com/kavu/go_reuseport v1.5.0 h1:UNuiY2OblcqAtVDE8Gsg1kZz8zbBWg907sP1ceBV+bk=\ngithub.com/kavu/go_reuseport v1.5.0/go.mod h1:CG8Ee7ceMFSMnx/xr25Vm0qXaj2Z4i5PWoUx+JZ5/CU=\n"
        },
        {
          "name": "internal",
          "type": "tree",
          "content": null
        },
        {
          "name": "logo.png",
          "type": "blob",
          "size": 25.0791015625,
          "content": null
        }
      ]
    }
  ]
}