{
  "metadata": {
    "timestamp": 1736567790778,
    "page": 375,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjM4MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "hashicorp/hcl",
      "stars": 5333,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".copywrite.hcl",
          "type": "blob",
          "size": 0.4169921875,
          "content": "schema_version = 1\n\nproject {\n  license        = \"MPL-2.0\"\n  copyright_year = 2014\n\n  # (OPTIONAL) A list of globs that should not have copyright/license headers.\n  # Supports doublestar glob patterns for more flexibility in defining which\n  # files or folders should be ignored\n  header_ignore = [\n    \"hclsyntax/fuzz/testdata/**\",\n    \"hclwrite/fuzz/testdata/**\",\n    \"json/fuzz/testdata/**\",\n    \"specsuite/tests/**\",\n  ]\n}\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 25.16796875,
          "content": "# HCL Changelog\n\n## v2.24.0 (Unreleased)\n\n### Enhancements\n\n* Add support for decoding block and attribute source ranges when using `gohcl`. ([#703](https://github.com/hashicorp/hcl/pull/703))\n\n## v2.23.0 (November 15, 2024)\n\n### Bugs Fixed\n\n* Preserve marks when traversing through unknown values. ([#699](https://github.com/hashicorp/hcl/pull/699))\n* Retain marks through conditional and for expressions. ([#710](https://github.com/hashicorp/hcl/pull/710))\n\n## v2.22.0 (August 26, 2024)\n\n### Enhancements\n\n* feat: return an ExprSyntaxError for invalid references that end in a dot ([#692](https://github.com/hashicorp/hcl/pull/692))\n\n## v2.21.0 (June 19, 2024)\n\n### Enhancements\n\n* Introduce `ParseTraversalPartial`, which allows traversals that include the splat (`[*]`) index operator.  ([#673](https://github.com/hashicorp/hcl/pull/673))\n* ext/dynblock: Now accepts marked values in `for_each`, and will transfer those marks (as much as technically possible) to values in the generated blocks. ([#679](https://github.com/hashicorp/hcl/pull/679))\n\n### Bugs Fixed\n\n* Expression evaluation will no longer panic if the splat operator is applied to an unknown value that has cty marks. ([#678](https://github.com/hashicorp/hcl/pull/678))\n\n## v2.20.1 (March 26, 2024)\n\n### Bugs Fixed\n\n* Return `ExprSyntaxError` when an invalid namespaced function is encountered during parsing ([#668](https://github.com/hashicorp/hcl/pull/668))\n\n### Internal\n\n* Standardize on only two value dumping/diffing libraries ([#669](https://github.com/hashicorp/hcl/pull/669))\n\n## v2.20.0 (February 29, 2024)\n\n### Enhancements\n\n* Support for namespaced functions ([#639](https://github.com/hashicorp/hcl/pull/639))\n\n### Bugs Fixed\n\n* ext/dynblock: if `iterator` is invalid return this error instead of consequential errors ([#656](https://github.com/hashicorp/hcl/pull/656))\n\n## v2.19.0 (October 16, 2023)\n\n### Enhancements\n\n* ext/dynblock: `dynblock.Expand` now supports an optional hook for calling applications to check and potentially veto (by returning error diagnostics) particular `for_each` values. The behavior is unchanged for callers that don't set the new option. ([#634](https://github.com/hashicorp/hcl/pull/634))\n\n### Bugs Fixed\n\n* hclsyntax: Further fixes for treatment of \"marked\" values in the conditional expression, and better tracking of refined values into the conditional expression results, building on the fixes from v2.18.1. ([#633](https://github.com/hashicorp/hcl/pull/633))\n\n## v2.18.1 (October 5, 2023)\n\n### Bugs Fixed\n\n* hclsyntax: Conditional expressions will no longer panic when one or both of their results are \"marked\", as is the case for situations like how HashiCorp Terraform tracks its concept of \"sensitive values\". ([#630](https://github.com/hashicorp/hcl/pull/630))\n\n## v2.18.0 (August 30, 2023)\n\n### Enhancements\n\n* HCL now uses the tables from Unicode 15 when performing string normalization and character segmentation. HCL was previously using the Unicode 13 tables.\n\n    For calling applications where consistent Unicode support is important, consider also upgrading to Go 1.21 at the same time as adopting HCL v2.18.0 so that the standard library unicode tables (used for case folding, etc) will also be from Unicode 15.\n\n## v2.17.1 (August 30, 2023)\n\n### Enhancements\n\n* hclsyntax: When evaluating string templates that have a long known constant prefix, HCL will truncate the known prefix to avoid creating excessively-large refinements. String prefix refinements are intended primarily for relatively-short fixed prefixes, such as `https://` at the start of a URL known to use that scheme. ([#617](https://github.com/hashicorp/hcl/pull/617))\n* ext/tryfunc: The \"try\" and \"can\" functions now handle unknown values slightly more precisely, and so can return known values in more situations when given expressions referring to unknown symbols. ([#622](https://github.com/hashicorp/hcl/pull/622))\n\n### Bugs Fixed\n\n* ext/typeexpr: Will no longer try to refine unknown values of unknown type when dealing with a user-specified type constraint containing the `any` keyword, avoiding an incorrect panic at runtime. ([#625](https://github.com/hashicorp/hcl/pull/625))\n* ext/typeexpr: Now correctly handles attempts to declare the same object type attribute multiple times by returning an error. Previously this could potentially panic by creating an incoherent internal state. ([#624](https://github.com/hashicorp/hcl/pull/624))\n\n## v2.17.0 (May 31, 2023)\n\n### Enhancements\n\n* HCL now uses a newer version of the upstream `cty` library which has improved treatment of unknown values: it can now track additional optional information that reduces the range of an unknown value, which allows some operations against unknown values to return known or partially-known results. ([#590](https://github.com/hashicorp/hcl/pull/590))\n\n    **Note:** This change effectively passes on [`cty`'s notion of backward compatibility](https://github.com/zclconf/go-cty/blob/main/COMPATIBILITY.md) whereby unknown values can become \"more known\" in later releases. In particular, if your caller is using `cty.Value.RawEquals` in its tests against the results of operations with unknown values then you may see those tests begin failing after upgrading, due to the values now being more \"refined\".\n\n    If so, you should review the refinements with consideration to [the `cty` refinements docs](https://github.com/zclconf/go-cty/blob/7dcbae46a6f247e983efb1fa774d2bb68781a333/docs/refinements.md) and update your expected results to match only if the reported refinements seem correct for the given situation. The `RawEquals` method is intended only for making exact value comparisons in test cases, so main application code should not use it; use `Equals` instead for real logic, which will take refinements into account automatically.\n\n## v2.16.2 (March 9, 2023)\n\n### Bugs Fixed\n\n* ext/typeexpr: Verify type assumptions when applying default values, and ignore input values that do not match type assumptions. ([#594](https://github.com/hashicorp/hcl/pull/594))\n\n## v2.16.1 (February 13, 2023)\n\n### Bugs Fixed\n\n* hclsyntax: Report correct `Range.End` for `FunctionCall` with incomplete argument ([#588](https://github.com/hashicorp/hcl/pull/588))\n\n## v2.16.0 (January 30, 2023)\n\n### Enhancements\n\n* ext/typeexpr: Modify the `Defaults` functionality to implement additional flexibility. HCL will now upcast lists and sets into tuples, and maps into objects, when applying default values if the applied defaults cause the elements within a target collection to have differing types. Previously, this would have resulted in a panic, now HCL will return a modified overall type. ([#574](https://github.com/hashicorp/hcl/pull/574))\n\n    Users should return to the advice provided by v2.14.0, and apply the go-cty convert functionality *after* setting defaults on a given `cty.Value`, rather than before.\n* hclfmt: Avoid rewriting unchanged files. ([#576](https://github.com/hashicorp/hcl/pull/576))\n* hclsyntax: Simplify the AST for certain string expressions. ([#584](https://github.com/hashicorp/hcl/pull/584))\n\n### Bugs Fixed\n\n* hclwrite: Fix data race in `formatSpaces`. ([#511](https://github.com/hashicorp/hcl/pull/511))\n\n## v2.15.0 (November 10, 2022)\n\n### Bugs Fixed\n\n* ext/typeexpr: Skip null objects when applying defaults. This prevents crashes when null objects are creating inside collections, and stops incomplete objects being created with only optional attributes set. ([#567](https://github.com/hashicorp/hcl/pull/567))\n* ext/typeexpr: Ensure default values do not have optional metadata attached. This prevents crashes when default values are inserted into concrete go-cty values that have also been stripped of their optional metadata. ([#568](https://github.com/hashicorp/hcl/pull/568))\n\n### Enhancements\n\n* ext/typeexpr: With the [go-cty](https://github.com/zclconf/go-cty) upstream depenendency updated to v1.12.0, the `Defaults` struct and associated functions can apply additional and more flexible 'unsafe' conversions (examples include tuples into collections such as lists and sets, and additional safety around null and dynamic values). ([#564](https://github.com/hashicorp/hcl/pull/564))\n* ext/typeexpr: With the [go-cty](https://github.com/zclconf/go-cty) upstream depenendency updated to v1.12.0, users should now apply the go-cty convert functionality *before* setting defaults on a given `cty.Value`, rather than after, if they require a specific `cty.Type`.  ([#564](https://github.com/hashicorp/hcl/pull/564))\n\n## v2.14.1 (September 23, 2022)\n\n### Bugs Fixed\n\n* ext/typeexpr: Type convert defaults for optional object attributes when applying them. This prevents crashes in certain cases when the objects in question are part of a collection. ([#555](https://github.com/hashicorp/hcl/pull/555))\n\n## v2.14.0 (September 1, 2022)\n\n### Enhancements\n\n* ext/typeexpr: Added support for optional object attributes to `TypeConstraint`. Attributes can be wrapped in the special `optional(…)` modifier, allowing the attribute to be omitted while still meeting the type constraint. For more information, [cty's documentation on conversion between object types](https://github.com/zclconf/go-cty/blob/main/docs/convert.md#conversion-between-object-types). ([#549](https://github.com/hashicorp/hcl/pull/549))\n* ext/typeexpr: New function: `TypeConstraintWithDefaults`. In this mode, the `optional(…)` modifier accepts a second argument which can be used as the default value for omitted object attributes. The function returns both a `cty.Type` and associated `Defaults`, the latter of which has an `Apply` method to apply defaults to a given value. ([#549](https://github.com/hashicorp/hcl/pull/549))\n\n## v2.13.0 (June 22, 2022)\n\n### Enhancements\n\n* hcl: `hcl.Diagnostic` now has an additional field `Extra` which is intended for carrying arbitrary supporting data (\"extra information\") related to the diagnostic message, intended to allow diagnostic renderers to optionally tailor the presentation of messages for particular situations. ([#539](https://github.com/hashicorp/hcl/pull/539))\n* hclsyntax: When an error occurs during a function call, the returned diagnostics will include _extra information_ (as described in the previous point) about which function was being called and, if the message is about an error returned by the function itself, that raw `error` value without any post-processing. ([#539](https://github.com/hashicorp/hcl/pull/539))\n\n### Bugs Fixed\n\n* hclwrite: Fixed a potential data race for any situation where `hclwrite.Format` runs concurrently with itself. ([#534](https://github.com/hashicorp/hcl/pull/534))\n\n## v2.12.0 (April 22, 2022)\n\n### Enhancements\n\n* hclsyntax: Evaluation of conditional expressions will now produce more precise error messages about inconsistencies between the types of the true and false result expressions, particularly in cases where both are of the same structural type kind but differ in their nested elements. ([#530](https://github.com/hashicorp/hcl/pull/530))\n* hclsyntax: The lexer will no longer allocate a small object on the heap for each token. Instead, in that situation it will allocate only when needed to return a diagnostic message with source location information. ([#490](https://github.com/hashicorp/hcl/pull/490))\n* hclwrite: New functions `TokensForTuple`, `TokensForObject`, and `TokensForFunctionCall` allow for more easily constructing the three constructs which are supported for static analysis and which HCL-based languages typically use in contexts where an expression is used only for its syntax, and not evaluated to produce a real value. For example, these new functions together are sufficient to construct all valid type constraint expressions from [the Type Expressions Extension](./ext/typeexpr/), which is the basis of variable type constraints in the Terraform language at the time of writing. ([#502](https://github.com/hashicorp/hcl/pull/502))\n* json: New functions `IsJSONExpression` and `IsJSONBody` to determine if a given expression or body was created by the JSON syntax parser. In normal situations it's better not to worry about what syntax a particular expression/body originated in, but this can be useful in some trickier cases where an application needs to shim for backwards-compatibility or for static analysis that needs to have special handling of the JSON syntax's embedded expression/template conventions. ([#524](https://github.com/hashicorp/hcl/pull/524))\n\n### Bugs Fixed\n\n* gohcl: Fix docs about supported types for blocks. ([#507](https://github.com/hashicorp/hcl/pull/507))\n\n## v2.11.1 (December 1, 2021)\n\n### Bugs Fixed\n\n* hclsyntax: The type for an upgraded unknown value with a splat expression cannot be known ([#495](https://github.com/hashicorp/hcl/pull/495))\n\n## v2.11.0 (December 1, 2021)\n\n### Enhancements\n\n* hclsyntax: Various error messages related to unexpectedly reaching end of file while parsing a delimited subtree will now return specialized messages describing the opening tokens as \"unclosed\", instead of returning a generic diagnostic that just happens to refer to the empty source range at the end of the file. This gives better feedback when error messages are being presented alongside a source code snippet, as is common in HCL-based applications, because it shows which innermost container the parser was working on when it encountered the error. ([#492](https://github.com/hashicorp/hcl/pull/492))\n\n### Bugs Fixed\n\n* hclsyntax: Upgrading an unknown single value to a list using a splat expression must return unknown ([#493](https://github.com/hashicorp/hcl/pull/493))\n\n## v2.10.1 (July 21, 2021)\n\n* dynblock: Decode unknown dynamic blocks in order to obtain any diagnostics even though the decoded value is not used ([#476](https://github.com/hashicorp/hcl/pull/476))\n* hclsyntax: Calling functions is now more robust in the face of an incorrectly-implemented function which returns a `function.ArgError` whose argument index is out of range for the length of the arguments. Previously this would often lead to a panic, but now it'll return a less-precice error message instead. Functions that return out-of-bounds argument indices still ought to be fixed so that the resulting error diagnostics can be as precise as possible. ([#472](https://github.com/hashicorp/hcl/pull/472))\n* hclsyntax: Ensure marks on unknown values are maintained when processing string templates. ([#478](https://github.com/hashicorp/hcl/pull/478))\n* hcl: Improved error messages for various common error situtions in `hcl.Index` and `hcl.GetAttr`. These are part of the implementation of indexing and attribute lookup in the native syntax expression language too, so the new error messages will apply to problems using those operators. ([#474](https://github.com/hashicorp/hcl/pull/474))\n\n## v2.10.0 (April 20, 2021)\n\n### Enhancements\n\n* dynblock,hcldec: Using dynblock in conjunction with hcldec can now decode blocks with unknown dynamic for_each arguments as entirely unknown values ([#461](https://github.com/hashicorp/hcl/pull/461))\n* hclsyntax: Some syntax errors during parsing of the inside of `${` ... `}` template interpolation sequences will now produce an extra hint message about the need to escape as `$${` when trying to include interpolation syntax for other languages like shell scripting, AWS IAM policies, etc. ([#462](https://github.com/hashicorp/hcl/pull/462))\n\n## v2.9.1 (March 10, 2021)\n\n### Bugs Fixed\n\n* hclsyntax: Fix panic for marked index value. ([#451](https://github.com/hashicorp/hcl/pull/451))\n\n## v2.9.0 (February 23, 2021)\n\n### Enhancements\n\n* HCL's native syntax and JSON scanners -- and thus all of the other parsing components that build on top of them -- are now using Unicode 13 rules for text segmentation when counting text characters for the purpose of reporting source location columns. Previously HCL was using Unicode 12. Unicode 13 still uses the same algorithm but includes some additions to the character tables the algorithm is defined in terms of, to properly categorize new characters defined in Unicode 13.\n\n## v2.8.2 (January 6, 2021)\n\n### Bugs Fixed\n\n* hclsyntax: Fix panic for marked collection splat. ([#436](https://github.com/hashicorp/hcl/pull/436))\n* hclsyntax: Fix panic for marked template loops. ([#437](https://github.com/hashicorp/hcl/pull/437))\n* hclsyntax: Fix `for` expression marked conditional. ([#438](https://github.com/hashicorp/hcl/pull/438))\n* hclsyntax: Mark objects with keys that are sensitive. ([#440](https://github.com/hashicorp/hcl/pull/440))\n\n## v2.8.1 (December 17, 2020)\n\n### Bugs Fixed\n\n* hclsyntax: Fix panic when expanding marked function arguments. ([#429](https://github.com/hashicorp/hcl/pull/429))\n* hclsyntax: Error when attempting to use a marked value as an object key. ([#434](https://github.com/hashicorp/hcl/pull/434))\n* hclsyntax: Error when attempting to use a marked value as an object key in expressions. ([#433](https://github.com/hashicorp/hcl/pull/433))\n\n## v2.8.0 (December 7, 2020)\n\n### Enhancements\n\n* hclsyntax: Expression grouping parentheses will now be reflected by an explicit node in the AST, whereas before they were only considered during parsing. ([#426](https://github.com/hashicorp/hcl/pull/426))\n\n### Bugs Fixed\n\n* hclwrite: The parser will now correctly include the `(` and `)` tokens when an expression is surrounded by parentheses. Previously it would incorrectly recognize those tokens as being extraneous tokens outside of the expression. ([#426](https://github.com/hashicorp/hcl/pull/426))\n* hclwrite: The formatter will now remove (rather than insert) spaces between the `!` (unary boolean \"not\") operator and its subsequent operand. ([#403](https://github.com/hashicorp/hcl/pull/403))\n* hclsyntax: Unmark conditional values in expressions before checking their truthfulness ([#427](https://github.com/hashicorp/hcl/pull/427))\n\n## v2.7.2 (November 30, 2020)\n\n### Bugs Fixed\n\n* gohcl: Fix panic when decoding into type containing value slices. ([#335](https://github.com/hashicorp/hcl/pull/335))\n* hclsyntax: The unusual expression `null[*]` was previously always returning an unknown value, even though the rules for `[*]` normally call for it to return an empty tuple when applied to a null. As well as being a surprising result, it was particularly problematic because it violated the rule that a calling application may assume that an expression result will always be known unless the application itself introduces unknown values via the evaluation context. `null[*]` will now produce an empty tuple. ([#416](https://github.com/hashicorp/hcl/pull/416))\n* hclsyntax: Fix panic when traversing a list, tuple, or map with cty \"marks\" ([#424](https://github.com/hashicorp/hcl/pull/424))\n\n## v2.7.1 (November 18, 2020)\n\n### Bugs Fixed\n\n* hclwrite: Correctly handle blank quoted string block labels, instead of dropping them ([#422](https://github.com/hashicorp/hcl/pull/422))\n\n## v2.7.0 (October 14, 2020)\n\n### Enhancements\n\n* json: There is a new function `ParseWithStartPos`, which allows overriding the starting position for parsing in case the given JSON bytes are a fragment of a larger document, such as might happen when decoding with `encoding/json` into a `json.RawMessage`. ([#389](https://github.com/hashicorp/hcl/pull/389))\n* json: There is a new function `ParseExpression`, which allows parsing a JSON string directly in expression mode, whereas previously it was only possible to parse a JSON string in body mode. ([#381](https://github.com/hashicorp/hcl/pull/381))\n* hclwrite: `Block` type now supports `SetType` and `SetLabels`, allowing surgical changes to the type and labels of an existing block without having to reconstruct the entire block. ([#340](https://github.com/hashicorp/hcl/pull/340))\n\n### Bugs Fixed\n\n* hclsyntax: Fix confusing error message for bitwise OR operator ([#380](https://github.com/hashicorp/hcl/pull/380))\n* hclsyntax: Several bug fixes for using HCL with values containing cty \"marks\" ([#404](https://github.com/hashicorp/hcl/pull/404), [#406](https://github.com/hashicorp/hcl/pull/404), [#407](https://github.com/hashicorp/hcl/pull/404))\n\n## v2.6.0 (June 4, 2020)\n\n### Enhancements\n\n* hcldec: Add a new `Spec`, `ValidateSpec`, which allows custom validation of values at decode-time. ([#387](https://github.com/hashicorp/hcl/pull/387))\n\n### Bugs Fixed\n\n* hclsyntax: Fix panic with combination of sequences and null arguments ([#386](https://github.com/hashicorp/hcl/pull/386))\n* hclsyntax: Fix handling of unknown values and sequences ([#386](https://github.com/hashicorp/hcl/pull/386))\n\n## v2.5.1 (May 14, 2020)\n\n### Bugs Fixed\n\n* hclwrite: handle legacy dot access of numeric indexes. ([#369](https://github.com/hashicorp/hcl/pull/369))\n* hclwrite: Fix panic for dotted full splat (`foo.*`) ([#374](https://github.com/hashicorp/hcl/pull/374))\n\n## v2.5.0 (May 6, 2020)\n\n### Enhancements\n\n* hclwrite: Generate multi-line objects and maps. ([#372](https://github.com/hashicorp/hcl/pull/372))\n\n## v2.4.0 (Apr 13, 2020)\n\n### Enhancements\n\n* The Unicode data tables that HCL uses to produce user-perceived \"column\" positions in diagnostics and other source ranges are now updated to Unicode 12.0.0, which will cause HCL to produce more accurate column numbers for combining characters introduced to Unicode since Unicode 9.0.0.\n\n### Bugs Fixed\n\n* json: Fix panic when parsing malformed JSON. ([#358](https://github.com/hashicorp/hcl/pull/358))\n\n## v2.3.0 (Jan 3, 2020)\n\n### Enhancements\n\n* ext/tryfunc: Optional functions `try` and `can` to include in your `hcl.EvalContext` when evaluating expressions, which allow users to make decisions based on the success of expressions. ([#330](https://github.com/hashicorp/hcl/pull/330))\n* ext/typeexpr: Now has an optional function `convert` which you can include in your `hcl.EvalContext` when evaluating expressions, allowing users to convert values to specific type constraints using the type constraint expression syntax. ([#330](https://github.com/hashicorp/hcl/pull/330))\n* ext/typeexpr: A new `cty` capsule type `typeexpr.TypeConstraintType` which, when used as either a type constraint for a function parameter or as a type constraint for a `hcldec` attribute specification will cause the given expression to be interpreted as a type constraint expression rather than a value expression. ([#330](https://github.com/hashicorp/hcl/pull/330))\n* ext/customdecode: An optional extension that allows overriding the static decoding behavior for expressions either in function arguments or `hcldec` attribute specifications. ([#330](https://github.com/hashicorp/hcl/pull/330))\n* ext/customdecode: New `cty` capsuletypes `customdecode.ExpressionType` and `customdecode.ExpressionClosureType` which, when used as either a type constraint for a function parameter or as a type constraint for a `hcldec` attribute specification will cause the given expression (and, for the closure type, also the `hcl.EvalContext` it was evaluated in) to be captured for later analysis, rather than immediately evaluated. ([#330](https://github.com/hashicorp/hcl/pull/330))\n\n## v2.2.0 (Dec 11, 2019)\n\n### Enhancements\n\n* hcldec: Attribute evaluation (as part of `AttrSpec` or `BlockAttrsSpec`) now captures expression evaluation metadata in any errors it produces during type conversions, allowing for better feedback in calling applications that are able to make use of this metadata when printing diagnostic messages. ([#329](https://github.com/hashicorp/hcl/pull/329))\n\n### Bugs Fixed\n\n* hclsyntax: `IndexExpr`, `SplatExpr`, and `RelativeTraversalExpr` will now report a source range that covers all of their child expression  nodes. Previously they would report only the operator part, such as `[\"foo\"]`, `[*]`, or `.foo`, which was problematic for callers using source ranges for code analysis. ([#328](https://github.com/hashicorp/hcl/pull/328))\n* hclwrite: Parser will no longer panic when the input includes index, splat, or relative traversal syntax.  ([#328](https://github.com/hashicorp/hcl/pull/328))\n\n## v2.1.0 (Nov 19, 2019)\n\n### Enhancements\n\n* gohcl: When decoding into a struct value with some fields already populated, those values will be retained if not explicitly overwritten in the given HCL body, with similar overriding/merging behavior as `json.Unmarshal` in the Go standard library.\n* hclwrite: New interface to set the expression for an attribute to be a raw token sequence, with no special processing. This has some caveats, so if you intend to use it please refer to the godoc comments. ([#320](https://github.com/hashicorp/hcl/pull/320))\n\n### Bugs Fixed\n\n* hclwrite: The `Body.Blocks` method was returing the blocks in an indefined order, rather than preserving the order of declaration in the source input. ([#313](https://github.com/hashicorp/hcl/pull/313))\n* hclwrite: The `TokensForTraversal` function (and thus in turn the `Body.SetAttributeTraversal` method) was not correctly handling index steps in traversals, and thus producing invalid results. ([#319](https://github.com/hashicorp/hcl/pull/319))\n\n## v2.0.0 (Oct 2, 2019)\n\nInitial release of HCL 2, which is a new implementating combining the HCL 1\nlanguage with the HIL expression language to produce a single language\nsupporting both nested configuration structures and arbitrary expressions.\n\nHCL 2 has an entirely new Go library API and so is _not_ a drop-in upgrade\nrelative to HCL 1. It's possible to import both versions of HCL into a single\nprogram using Go's _semantic import versioning_ mechanism:\n\n```\nimport (\n    hcl1 \"github.com/hashicorp/hcl\"\n    hcl2 \"github.com/hashicorp/hcl/v2\"\n)\n```\n\n---\n\nPrior to v2.0.0 there was not a curated changelog. Consult the git history\nfrom the latest v1.x.x tag for information on the changes to HCL 1.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 15.63671875,
          "content": "Copyright (c) 2014 HashiCorp, Inc.\n\nMozilla Public License, version 2.0\n\n1. Definitions\n\n1.1. “Contributor”\n\n     means each individual or legal entity that creates, contributes to the\n     creation of, or owns Covered Software.\n\n1.2. “Contributor Version”\n\n     means the combination of the Contributions of others (if any) used by a\n     Contributor and that particular Contributor’s Contribution.\n\n1.3. “Contribution”\n\n     means Covered Software of a particular Contributor.\n\n1.4. “Covered Software”\n\n     means Source Code Form to which the initial Contributor has attached the\n     notice in Exhibit A, the Executable Form of such Source Code Form, and\n     Modifications of such Source Code Form, in each case including portions\n     thereof.\n\n1.5. “Incompatible With Secondary Licenses”\n     means\n\n     a. that the initial Contributor has attached the notice described in\n        Exhibit B to the Covered Software; or\n\n     b. that the Covered Software was made available under the terms of version\n        1.1 or earlier of the License, but not also under the terms of a\n        Secondary License.\n\n1.6. “Executable Form”\n\n     means any form of the work other than Source Code Form.\n\n1.7. “Larger Work”\n\n     means a work that combines Covered Software with other material, in a separate\n     file or files, that is not Covered Software.\n\n1.8. “License”\n\n     means this document.\n\n1.9. “Licensable”\n\n     means having the right to grant, to the maximum extent possible, whether at the\n     time of the initial grant or subsequently, any and all of the rights conveyed by\n     this License.\n\n1.10. “Modifications”\n\n     means any of the following:\n\n     a. any file in Source Code Form that results from an addition to, deletion\n        from, or modification of the contents of Covered Software; or\n\n     b. any new file in Source Code Form that contains any Covered Software.\n\n1.11. “Patent Claims” of a Contributor\n\n      means any patent claim(s), including without limitation, method, process,\n      and apparatus claims, in any patent Licensable by such Contributor that\n      would be infringed, but for the grant of the License, by the making,\n      using, selling, offering for sale, having made, import, or transfer of\n      either its Contributions or its Contributor Version.\n\n1.12. “Secondary License”\n\n      means either the GNU General Public License, Version 2.0, the GNU Lesser\n      General Public License, Version 2.1, the GNU Affero General Public\n      License, Version 3.0, or any later versions of those licenses.\n\n1.13. “Source Code Form”\n\n      means the form of the work preferred for making modifications.\n\n1.14. “You” (or “Your”)\n\n      means an individual or a legal entity exercising rights under this\n      License. For legal entities, “You” includes any entity that controls, is\n      controlled by, or is under common control with You. For purposes of this\n      definition, “control” means (a) the power, direct or indirect, to cause\n      the direction or management of such entity, whether by contract or\n      otherwise, or (b) ownership of more than fifty percent (50%) of the\n      outstanding shares or beneficial ownership of such entity.\n\n\n2. License Grants and Conditions\n\n2.1. Grants\n\n     Each Contributor hereby grants You a world-wide, royalty-free,\n     non-exclusive license:\n\n     a. under intellectual property rights (other than patent or trademark)\n        Licensable by such Contributor to use, reproduce, make available,\n        modify, display, perform, distribute, and otherwise exploit its\n        Contributions, either on an unmodified basis, with Modifications, or as\n        part of a Larger Work; and\n\n     b. under Patent Claims of such Contributor to make, use, sell, offer for\n        sale, have made, import, and otherwise transfer either its Contributions\n        or its Contributor Version.\n\n2.2. Effective Date\n\n     The licenses granted in Section 2.1 with respect to any Contribution become\n     effective for each Contribution on the date the Contributor first distributes\n     such Contribution.\n\n2.3. Limitations on Grant Scope\n\n     The licenses granted in this Section 2 are the only rights granted under this\n     License. No additional rights or licenses will be implied from the distribution\n     or licensing of Covered Software under this License. Notwithstanding Section\n     2.1(b) above, no patent license is granted by a Contributor:\n\n     a. for any code that a Contributor has removed from Covered Software; or\n\n     b. for infringements caused by: (i) Your and any other third party’s\n        modifications of Covered Software, or (ii) the combination of its\n        Contributions with other software (except as part of its Contributor\n        Version); or\n\n     c. under Patent Claims infringed by Covered Software in the absence of its\n        Contributions.\n\n     This License does not grant any rights in the trademarks, service marks, or\n     logos of any Contributor (except as may be necessary to comply with the\n     notice requirements in Section 3.4).\n\n2.4. Subsequent Licenses\n\n     No Contributor makes additional grants as a result of Your choice to\n     distribute the Covered Software under a subsequent version of this License\n     (see Section 10.2) or under the terms of a Secondary License (if permitted\n     under the terms of Section 3.3).\n\n2.5. Representation\n\n     Each Contributor represents that the Contributor believes its Contributions\n     are its original creation(s) or it has sufficient rights to grant the\n     rights to its Contributions conveyed by this License.\n\n2.6. Fair Use\n\n     This License is not intended to limit any rights You have under applicable\n     copyright doctrines of fair use, fair dealing, or other equivalents.\n\n2.7. Conditions\n\n     Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in\n     Section 2.1.\n\n\n3. Responsibilities\n\n3.1. Distribution of Source Form\n\n     All distribution of Covered Software in Source Code Form, including any\n     Modifications that You create or to which You contribute, must be under the\n     terms of this License. You must inform recipients that the Source Code Form\n     of the Covered Software is governed by the terms of this License, and how\n     they can obtain a copy of this License. You may not attempt to alter or\n     restrict the recipients’ rights in the Source Code Form.\n\n3.2. Distribution of Executable Form\n\n     If You distribute Covered Software in Executable Form then:\n\n     a. such Covered Software must also be made available in Source Code Form,\n        as described in Section 3.1, and You must inform recipients of the\n        Executable Form how they can obtain a copy of such Source Code Form by\n        reasonable means in a timely manner, at a charge no more than the cost\n        of distribution to the recipient; and\n\n     b. You may distribute such Executable Form under the terms of this License,\n        or sublicense it under different terms, provided that the license for\n        the Executable Form does not attempt to limit or alter the recipients’\n        rights in the Source Code Form under this License.\n\n3.3. Distribution of a Larger Work\n\n     You may create and distribute a Larger Work under terms of Your choice,\n     provided that You also comply with the requirements of this License for the\n     Covered Software. If the Larger Work is a combination of Covered Software\n     with a work governed by one or more Secondary Licenses, and the Covered\n     Software is not Incompatible With Secondary Licenses, this License permits\n     You to additionally distribute such Covered Software under the terms of\n     such Secondary License(s), so that the recipient of the Larger Work may, at\n     their option, further distribute the Covered Software under the terms of\n     either this License or such Secondary License(s).\n\n3.4. Notices\n\n     You may not remove or alter the substance of any license notices (including\n     copyright notices, patent notices, disclaimers of warranty, or limitations\n     of liability) contained within the Source Code Form of the Covered\n     Software, except that You may alter any license notices to the extent\n     required to remedy known factual inaccuracies.\n\n3.5. Application of Additional Terms\n\n     You may choose to offer, and to charge a fee for, warranty, support,\n     indemnity or liability obligations to one or more recipients of Covered\n     Software. However, You may do so only on Your own behalf, and not on behalf\n     of any Contributor. You must make it absolutely clear that any such\n     warranty, support, indemnity, or liability obligation is offered by You\n     alone, and You hereby agree to indemnify every Contributor for any\n     liability incurred by such Contributor as a result of warranty, support,\n     indemnity or liability terms You offer. You may include additional\n     disclaimers of warranty and limitations of liability specific to any\n     jurisdiction.\n\n4. Inability to Comply Due to Statute or Regulation\n\n   If it is impossible for You to comply with any of the terms of this License\n   with respect to some or all of the Covered Software due to statute, judicial\n   order, or regulation then You must: (a) comply with the terms of this License\n   to the maximum extent possible; and (b) describe the limitations and the code\n   they affect. Such description must be placed in a text file included with all\n   distributions of the Covered Software under this License. Except to the\n   extent prohibited by statute or regulation, such description must be\n   sufficiently detailed for a recipient of ordinary skill to be able to\n   understand it.\n\n5. Termination\n\n5.1. The rights granted under this License will terminate automatically if You\n     fail to comply with any of its terms. However, if You become compliant,\n     then the rights granted under this License from a particular Contributor\n     are reinstated (a) provisionally, unless and until such Contributor\n     explicitly and finally terminates Your grants, and (b) on an ongoing basis,\n     if such Contributor fails to notify You of the non-compliance by some\n     reasonable means prior to 60 days after You have come back into compliance.\n     Moreover, Your grants from a particular Contributor are reinstated on an\n     ongoing basis if such Contributor notifies You of the non-compliance by\n     some reasonable means, this is the first time You have received notice of\n     non-compliance with this License from such Contributor, and You become\n     compliant prior to 30 days after Your receipt of the notice.\n\n5.2. If You initiate litigation against any entity by asserting a patent\n     infringement claim (excluding declaratory judgment actions, counter-claims,\n     and cross-claims) alleging that a Contributor Version directly or\n     indirectly infringes any patent, then the rights granted to You by any and\n     all Contributors for the Covered Software under Section 2.1 of this License\n     shall terminate.\n\n5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user\n     license agreements (excluding distributors and resellers) which have been\n     validly granted by You or Your distributors under this License prior to\n     termination shall survive termination.\n\n6. Disclaimer of Warranty\n\n   Covered Software is provided under this License on an “as is” basis, without\n   warranty of any kind, either expressed, implied, or statutory, including,\n   without limitation, warranties that the Covered Software is free of defects,\n   merchantable, fit for a particular purpose or non-infringing. The entire\n   risk as to the quality and performance of the Covered Software is with You.\n   Should any Covered Software prove defective in any respect, You (not any\n   Contributor) assume the cost of any necessary servicing, repair, or\n   correction. This disclaimer of warranty constitutes an essential part of this\n   License. No use of  any Covered Software is authorized under this License\n   except under this disclaimer.\n\n7. Limitation of Liability\n\n   Under no circumstances and under no legal theory, whether tort (including\n   negligence), contract, or otherwise, shall any Contributor, or anyone who\n   distributes Covered Software as permitted above, be liable to You for any\n   direct, indirect, special, incidental, or consequential damages of any\n   character including, without limitation, damages for lost profits, loss of\n   goodwill, work stoppage, computer failure or malfunction, or any and all\n   other commercial damages or losses, even if such party shall have been\n   informed of the possibility of such damages. This limitation of liability\n   shall not apply to liability for death or personal injury resulting from such\n   party’s negligence to the extent applicable law prohibits such limitation.\n   Some jurisdictions do not allow the exclusion or limitation of incidental or\n   consequential damages, so this exclusion and limitation may not apply to You.\n\n8. Litigation\n\n   Any litigation relating to this License may be brought only in the courts of\n   a jurisdiction where the defendant maintains its principal place of business\n   and such litigation shall be governed by laws of that jurisdiction, without\n   reference to its conflict-of-law provisions. Nothing in this Section shall\n   prevent a party’s ability to bring cross-claims or counter-claims.\n\n9. Miscellaneous\n\n   This License represents the complete agreement concerning the subject matter\n   hereof. If any provision of this License is held to be unenforceable, such\n   provision shall be reformed only to the extent necessary to make it\n   enforceable. Any law or regulation which provides that the language of a\n   contract shall be construed against the drafter shall not be used to construe\n   this License against a Contributor.\n\n\n10. Versions of the License\n\n10.1. New Versions\n\n      Mozilla Foundation is the license steward. Except as provided in Section\n      10.3, no one other than the license steward has the right to modify or\n      publish new versions of this License. Each version will be given a\n      distinguishing version number.\n\n10.2. Effect of New Versions\n\n      You may distribute the Covered Software under the terms of the version of\n      the License under which You originally received the Covered Software, or\n      under the terms of any subsequent version published by the license\n      steward.\n\n10.3. Modified Versions\n\n      If you create software not governed by this License, and you want to\n      create a new license for such software, you may create and use a modified\n      version of this License if you rename the license and remove any\n      references to the name of the license steward (except to note that such\n      modified license differs from this License).\n\n10.4. Distributing Source Code Form that is Incompatible With Secondary Licenses\n      If You choose to distribute Source Code Form that is Incompatible With\n      Secondary Licenses under the terms of this version of the License, the\n      notice described in Exhibit B of this License must be attached.\n\nExhibit A - Source Code Form License Notice\n\n      This Source Code Form is subject to the\n      terms of the Mozilla Public License, v.\n      2.0. If a copy of the MPL was not\n      distributed with this file, You can\n      obtain one at\n      http://mozilla.org/MPL/2.0/.\n\nIf it is not possible or desirable to put the notice in a particular file, then\nYou may include the notice in a location (such as a LICENSE file in a relevant\ndirectory) where a recipient would be likely to look for such a notice.\n\nYou may add additional accurate notices of copyright ownership.\n\nExhibit B - “Incompatible With Secondary Licenses” Notice\n\n      This Source Code Form is “Incompatible\n      With Secondary Licenses”, as defined by\n      the Mozilla Public License, v. 2.0.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.298828125,
          "content": "fmtcheck:\n\t\"$(CURDIR)/scripts/gofmtcheck.sh\"\n\nfmtfix:\n\tgofmt -w ./\n\nvetcheck:\n\tgo vet ./...\n\ncopyrightcheck:\n\tgo run github.com/hashicorp/copywrite@latest headers --plan\n\ncopyrightfix:\n\tgo run github.com/hashicorp/copywrite@latest headers\n\ncheck: copyrightcheck vetcheck fmtcheck\n\nfix: copyrightfix fmtfix\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.181640625,
          "content": "# HCL\n\nHCL is a toolkit for creating structured configuration languages that are\nboth human- and machine-friendly, for use with command-line tools.\nAlthough intended to be generally useful, it is primarily targeted\ntowards devops tools, servers, etc.\n\n> **NOTE:** This is major version 2 of HCL, whose Go API is incompatible with\n> major version 1. Both versions are available for selection in Go Modules\n> projects. HCL 2 _cannot_ be imported from Go projects that are not using Go Modules. For more information, see\n> [our version selection guide](https://github.com/hashicorp/hcl/wiki/Version-Selection).\n\nHCL has both a _native syntax_, intended to be pleasant to read and write for\nhumans, and a JSON-based variant that is easier for machines to generate\nand parse.\n\nThe HCL native syntax is inspired by [libucl](https://github.com/vstakhov/libucl),\n[nginx configuration](http://nginx.org/en/docs/beginners_guide.html#conf_structure),\nand others.\n\nIt includes an expression syntax that allows basic inline computation and,\nwith support from the calling application, use of variables and functions\nfor more dynamic configuration languages.\n\nHCL provides a set of constructs that can be used by a calling application to\nconstruct a configuration language. The application defines which attribute\nnames and nested block types are expected, and HCL parses the configuration\nfile, verifies that it conforms to the expected structure, and returns\nhigh-level objects that the application can use for further processing.\n\n```go\npackage main\n\nimport (\n\t\"log\"\n\n\t\"github.com/hashicorp/hcl/v2/hclsimple\"\n)\n\ntype Config struct {\n\tIOMode  string        `hcl:\"io_mode\"`\n\tService ServiceConfig `hcl:\"service,block\"`\n}\n\ntype ServiceConfig struct {\n\tProtocol   string          `hcl:\"protocol,label\"`\n\tType       string          `hcl:\"type,label\"`\n\tListenAddr string          `hcl:\"listen_addr\"`\n\tProcesses  []ProcessConfig `hcl:\"process,block\"`\n}\n\ntype ProcessConfig struct {\n\tType    string   `hcl:\"type,label\"`\n\tCommand []string `hcl:\"command\"`\n}\n\nfunc main() {\n\tvar config Config\n\terr := hclsimple.DecodeFile(\"config.hcl\", nil, &config)\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to load configuration: %s\", err)\n\t}\n\tlog.Printf(\"Configuration is %#v\", config)\n}\n```\n\nA lower-level API is available for applications that need more control over\nthe parsing, decoding, and evaluation of configuration. For more information,\nsee [the package documentation](https://pkg.go.dev/github.com/hashicorp/hcl/v2).\n\n## Why?\n\nNewcomers to HCL often ask: why not JSON, YAML, etc?\n\nWhereas JSON and YAML are formats for serializing data structures, HCL is\na syntax and API specifically designed for building structured configuration\nformats.\n\nHCL attempts to strike a compromise between generic serialization formats\nsuch as JSON and configuration formats built around full programming languages\nsuch as Ruby. HCL syntax is designed to be easily read and written by humans,\nand allows _declarative_ logic to permit its use in more complex applications.\n\nHCL is intended as a base syntax for configuration formats built\naround key-value pairs and hierarchical blocks whose structure is well-defined\nby the calling application, and this definition of the configuration structure\nallows for better error messages and more convenient definition within the\ncalling application.\n\nIt can't be denied that JSON is very convenient as a _lingua franca_\nfor interoperability between different pieces of software. Because of this,\nHCL defines a common configuration model that can be parsed from either its\nnative syntax or from a well-defined equivalent JSON structure. This allows\nconfiguration to be provided as a mixture of human-authored configuration\nfiles in the native syntax and machine-generated files in JSON.\n\n## Information Model and Syntax\n\nHCL is built around two primary concepts: _attributes_ and _blocks_. In\nnative syntax, a configuration file for a hypothetical application might look\nsomething like this:\n\n```hcl\nio_mode = \"async\"\n\nservice \"http\" \"web_proxy\" {\n  listen_addr = \"127.0.0.1:8080\"\n  \n  process \"main\" {\n    command = [\"/usr/local/bin/awesome-app\", \"server\"]\n  }\n\n  process \"mgmt\" {\n    command = [\"/usr/local/bin/awesome-app\", \"mgmt\"]\n  }\n}\n```\n\nThe JSON equivalent of this configuration is the following:\n\n```json\n{\n  \"io_mode\": \"async\",\n  \"service\": {\n    \"http\": {\n      \"web_proxy\": {\n        \"listen_addr\": \"127.0.0.1:8080\",\n        \"process\": {\n          \"main\": {\n            \"command\": [\"/usr/local/bin/awesome-app\", \"server\"]\n          },\n          \"mgmt\": {\n            \"command\": [\"/usr/local/bin/awesome-app\", \"mgmt\"]\n          },\n        }\n      }\n    }\n  }\n}\n```\n\nRegardless of which syntax is used, the API within the calling application\nis the same. It can either work directly with the low-level attributes and\nblocks, for more advanced use-cases, or it can use one of the _decoder_\npackages to declaratively extract into either Go structs or dynamic value\nstructures.\n\nAttribute values can be expressions as well as just literal values:\n\n```hcl\n# Arithmetic with literals and application-provided variables\nsum = 1 + addend\n\n# String interpolation and templates\nmessage = \"Hello, ${name}!\"\n\n# Application-provided functions\nshouty_message = upper(message)\n```\n\nAlthough JSON syntax doesn't permit direct use of expressions, the interpolation\nsyntax allows use of arbitrary expressions within JSON strings:\n\n```json\n{\n  \"sum\": \"${1 + addend}\",\n  \"message\": \"Hello, ${name}!\",\n  \"shouty_message\": \"${upper(message)}\"\n}\n```\n\nFor more information, see the detailed specifications:\n\n* [Syntax-agnostic Information Model](spec.md)\n* [HCL Native Syntax](hclsyntax/spec.md)\n* [JSON Representation](json/spec.md)\n\n## Changes in 2.0\n\nVersion 2.0 of HCL combines the features of HCL 1.0 with those of the\ninterpolation language HIL to produce a single configuration language that\nsupports arbitrary expressions.\n\nThis new version has a completely new parser and Go API, with no direct\nmigration path. Although the syntax is similar, the implementation takes some\nvery different approaches to improve on some \"rough edges\" that existed with\nthe original implementation and to allow for more robust error handling.\n\nIt's possible to import both HCL 1 and HCL 2 into the same program using Go's\n_semantic import versioning_ mechanism:\n\n```go\nimport (\n    hcl1 \"github.com/hashicorp/hcl\"\n    hcl2 \"github.com/hashicorp/hcl/v2\"\n)\n```\n\n## Acknowledgements\n\nHCL was heavily inspired by [libucl](https://github.com/vstakhov/libucl),\nby [Vsevolod Stakhov](https://github.com/vstakhov).\n\nHCL and HIL originate in [HashiCorp Terraform](https://terraform.io/),\nwith the original parsers for each written by\n[Mitchell Hashimoto](https://github.com/mitchellh).\n\nThe original HCL parser was ported to pure Go (from yacc) by\n[Fatih Arslan](https://github.com/fatih). The structure-related portions of\nthe new native syntax parser build on that work.\n\nThe original HIL parser was ported to pure Go (from yacc) by\n[Martin Atkins](https://github.com/apparentlymart). The expression-related\nportions of the new native syntax parser build on that work.\n\nHCL 2, which merged the original HCL and HIL languages into this single new\nlanguage, builds on design and prototyping work by\n[Martin Atkins](https://github.com/apparentlymart) in\n[zcl](https://github.com/zclconf/go-zcl).\n"
        },
        {
          "name": "cmd",
          "type": "tree",
          "content": null
        },
        {
          "name": "diagnostic.go",
          "type": "blob",
          "size": 6.86328125,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\nimport (\n\t\"fmt\"\n)\n\n// DiagnosticSeverity represents the severity of a diagnostic.\ntype DiagnosticSeverity int\n\nconst (\n\t// DiagInvalid is the invalid zero value of DiagnosticSeverity\n\tDiagInvalid DiagnosticSeverity = iota\n\n\t// DiagError indicates that the problem reported by a diagnostic prevents\n\t// further progress in parsing and/or evaluating the subject.\n\tDiagError\n\n\t// DiagWarning indicates that the problem reported by a diagnostic warrants\n\t// user attention but does not prevent further progress. It is most\n\t// commonly used for showing deprecation notices.\n\tDiagWarning\n)\n\n// Diagnostic represents information to be presented to a user about an\n// error or anomaly in parsing or evaluating configuration.\ntype Diagnostic struct {\n\tSeverity DiagnosticSeverity\n\n\t// Summary and Detail contain the English-language description of the\n\t// problem. Summary is a terse description of the general problem and\n\t// detail is a more elaborate, often-multi-sentence description of\n\t// the problem and what might be done to solve it.\n\tSummary string\n\tDetail  string\n\n\t// Subject and Context are both source ranges relating to the diagnostic.\n\t//\n\t// Subject is a tight range referring to exactly the construct that\n\t// is problematic, while Context is an optional broader range (which should\n\t// fully contain Subject) that ought to be shown around Subject when\n\t// generating isolated source-code snippets in diagnostic messages.\n\t// If Context is nil, the Subject is also the Context.\n\t//\n\t// Some diagnostics have no source ranges at all. If Context is set then\n\t// Subject should always also be set.\n\tSubject *Range\n\tContext *Range\n\n\t// For diagnostics that occur when evaluating an expression, Expression\n\t// may refer to that expression and EvalContext may point to the\n\t// EvalContext that was active when evaluating it. This may allow for the\n\t// inclusion of additional useful information when rendering a diagnostic\n\t// message to the user.\n\t//\n\t// It is not always possible to select a single EvalContext for a\n\t// diagnostic, and so in some cases this field may be nil even when an\n\t// expression causes a problem.\n\t//\n\t// EvalContexts form a tree, so the given EvalContext may refer to a parent\n\t// which in turn refers to another parent, etc. For a full picture of all\n\t// of the active variables and functions the caller must walk up this\n\t// chain, preferring definitions that are \"closer\" to the expression in\n\t// case of colliding names.\n\tExpression  Expression\n\tEvalContext *EvalContext\n\n\t// Extra is an extension point for additional machine-readable information\n\t// about this problem.\n\t//\n\t// Recipients of diagnostic objects may type-assert this value with\n\t// specific interface types they know about to discover if any additional\n\t// information is available that is interesting for their use-case.\n\t//\n\t// Extra is always considered to be optional extra information and so a\n\t// diagnostic message should still always be fully described (from the\n\t// perspective of a human who understands the language the messages are\n\t// written in) by the other fields in case a particular recipient.\n\t//\n\t// Functions that return diagnostics with Extra populated should typically\n\t// document that they place values implementing a particular interface,\n\t// rather than a concrete type, and define that interface such that its\n\t// methods can dynamically indicate a lack of support at runtime even\n\t// if the interface happens to be statically available. An Extra\n\t// type that wraps other Extra values should additionally implement\n\t// interface DiagnosticExtraUnwrapper to return the value they are wrapping\n\t// so that callers can access inner values to type-assert against.\n\tExtra interface{}\n}\n\n// Diagnostics is a list of Diagnostic instances.\ntype Diagnostics []*Diagnostic\n\n// error implementation, so that diagnostics can be returned via APIs\n// that normally deal in vanilla Go errors.\n//\n// This presents only minimal context about the error, for compatibility\n// with usual expectations about how errors will present as strings.\nfunc (d *Diagnostic) Error() string {\n\treturn fmt.Sprintf(\"%s: %s; %s\", d.Subject, d.Summary, d.Detail)\n}\n\n// error implementation, so that sets of diagnostics can be returned via\n// APIs that normally deal in vanilla Go errors.\nfunc (d Diagnostics) Error() string {\n\tcount := len(d)\n\tswitch {\n\tcase count == 0:\n\t\treturn \"no diagnostics\"\n\tcase count == 1:\n\t\treturn d[0].Error()\n\tdefault:\n\t\treturn fmt.Sprintf(\"%s, and %d other diagnostic(s)\", d[0].Error(), count-1)\n\t}\n}\n\n// Append appends a new error to a Diagnostics and return the whole Diagnostics.\n//\n// This is provided as a convenience for returning from a function that\n// collects and then returns a set of diagnostics:\n//\n//     return nil, diags.Append(&hcl.Diagnostic{ ... })\n//\n// Note that this modifies the array underlying the diagnostics slice, so\n// must be used carefully within a single codepath. It is incorrect (and rude)\n// to extend a diagnostics created by a different subsystem.\nfunc (d Diagnostics) Append(diag *Diagnostic) Diagnostics {\n\treturn append(d, diag)\n}\n\n// Extend concatenates the given Diagnostics with the receiver and returns\n// the whole new Diagnostics.\n//\n// This is similar to Append but accepts multiple diagnostics to add. It has\n// all the same caveats and constraints.\nfunc (d Diagnostics) Extend(diags Diagnostics) Diagnostics {\n\treturn append(d, diags...)\n}\n\n// HasErrors returns true if the receiver contains any diagnostics of\n// severity DiagError.\nfunc (d Diagnostics) HasErrors() bool {\n\tfor _, diag := range d {\n\t\tif diag.Severity == DiagError {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (d Diagnostics) Errs() []error {\n\tvar errs []error\n\tfor _, diag := range d {\n\t\tif diag.Severity == DiagError {\n\t\t\terrs = append(errs, diag)\n\t\t}\n\t}\n\n\treturn errs\n}\n\n// A DiagnosticWriter emits diagnostics somehow.\ntype DiagnosticWriter interface {\n\tWriteDiagnostic(*Diagnostic) error\n\tWriteDiagnostics(Diagnostics) error\n}\n\n// DiagnosticExtraUnwrapper is an interface implemented by values in the\n// Extra field of Diagnostic when they are wrapping another \"Extra\" value that\n// was generated downstream.\n//\n// Diagnostic recipients which want to examine \"Extra\" values to sniff for\n// particular types of extra data can either type-assert this interface\n// directly and repeatedly unwrap until they recieve nil, or can use the\n// helper function DiagnosticExtra.\ntype DiagnosticExtraUnwrapper interface {\n\t// If the reciever is wrapping another \"diagnostic extra\" value, returns\n\t// that value. Otherwise returns nil to indicate dynamically that nothing\n\t// is wrapped.\n\t//\n\t// The \"nothing is wrapped\" condition can be signalled either by this\n\t// method returning nil or by a type not implementing this interface at all.\n\t//\n\t// Implementers should never create unwrap \"cycles\" where a nested extra\n\t// value returns a value that was also wrapping it.\n\tUnwrapDiagnosticExtra() interface{}\n}\n"
        },
        {
          "name": "diagnostic_text.go",
          "type": "blob",
          "size": 8.3642578125,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"sort\"\n\n\twordwrap \"github.com/mitchellh/go-wordwrap\"\n\t\"github.com/zclconf/go-cty/cty\"\n)\n\ntype diagnosticTextWriter struct {\n\tfiles map[string]*File\n\twr    io.Writer\n\twidth uint\n\tcolor bool\n}\n\n// NewDiagnosticTextWriter creates a DiagnosticWriter that writes diagnostics\n// to the given writer as formatted text.\n//\n// It is designed to produce text appropriate to print in a monospaced font\n// in a terminal of a particular width, or optionally with no width limit.\n//\n// The given width may be zero to disable word-wrapping of the detail text\n// and truncation of source code snippets.\n//\n// If color is set to true, the output will include VT100 escape sequences to\n// color-code the severity indicators. It is suggested to turn this off if\n// the target writer is not a terminal.\nfunc NewDiagnosticTextWriter(wr io.Writer, files map[string]*File, width uint, color bool) DiagnosticWriter {\n\treturn &diagnosticTextWriter{\n\t\tfiles: files,\n\t\twr:    wr,\n\t\twidth: width,\n\t\tcolor: color,\n\t}\n}\n\nfunc (w *diagnosticTextWriter) WriteDiagnostic(diag *Diagnostic) error {\n\tif diag == nil {\n\t\treturn errors.New(\"nil diagnostic\")\n\t}\n\n\tvar colorCode, highlightCode, resetCode string\n\tif w.color {\n\t\tswitch diag.Severity {\n\t\tcase DiagError:\n\t\t\tcolorCode = \"\\x1b[31m\"\n\t\tcase DiagWarning:\n\t\t\tcolorCode = \"\\x1b[33m\"\n\t\t}\n\t\tresetCode = \"\\x1b[0m\"\n\t\thighlightCode = \"\\x1b[1;4m\"\n\t}\n\n\tvar severityStr string\n\tswitch diag.Severity {\n\tcase DiagError:\n\t\tseverityStr = \"Error\"\n\tcase DiagWarning:\n\t\tseverityStr = \"Warning\"\n\tdefault:\n\t\t// should never happen\n\t\tseverityStr = \"???????\"\n\t}\n\n\tfmt.Fprintf(w.wr, \"%s%s%s: %s\\n\\n\", colorCode, severityStr, resetCode, diag.Summary)\n\n\tif diag.Subject != nil {\n\t\tsnipRange := *diag.Subject\n\t\thighlightRange := snipRange\n\t\tif diag.Context != nil {\n\t\t\t// Show enough of the source code to include both the subject\n\t\t\t// and context ranges, which overlap in all reasonable\n\t\t\t// situations.\n\t\t\tsnipRange = RangeOver(snipRange, *diag.Context)\n\t\t}\n\t\t// We can't illustrate an empty range, so we'll turn such ranges into\n\t\t// single-character ranges, which might not be totally valid (may point\n\t\t// off the end of a line, or off the end of the file) but are good\n\t\t// enough for the bounds checks we do below.\n\t\tif snipRange.Empty() {\n\t\t\tsnipRange.End.Byte++\n\t\t\tsnipRange.End.Column++\n\t\t}\n\t\tif highlightRange.Empty() {\n\t\t\thighlightRange.End.Byte++\n\t\t\thighlightRange.End.Column++\n\t\t}\n\n\t\tfile := w.files[diag.Subject.Filename]\n\t\tif file == nil || file.Bytes == nil {\n\t\t\tfmt.Fprintf(w.wr, \"  on %s line %d:\\n  (source code not available)\\n\\n\", diag.Subject.Filename, diag.Subject.Start.Line)\n\t\t} else {\n\n\t\t\tvar contextLine string\n\t\t\tif diag.Subject != nil {\n\t\t\t\tcontextLine = contextString(file, diag.Subject.Start.Byte)\n\t\t\t\tif contextLine != \"\" {\n\t\t\t\t\tcontextLine = \", in \" + contextLine\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tfmt.Fprintf(w.wr, \"  on %s line %d%s:\\n\", diag.Subject.Filename, diag.Subject.Start.Line, contextLine)\n\n\t\t\tsrc := file.Bytes\n\t\t\tsc := NewRangeScanner(src, diag.Subject.Filename, bufio.ScanLines)\n\n\t\t\tfor sc.Scan() {\n\t\t\t\tlineRange := sc.Range()\n\t\t\t\tif !lineRange.Overlaps(snipRange) {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tbeforeRange, highlightedRange, afterRange := lineRange.PartitionAround(highlightRange)\n\t\t\t\tif highlightedRange.Empty() {\n\t\t\t\t\tfmt.Fprintf(w.wr, \"%4d: %s\\n\", lineRange.Start.Line, sc.Bytes())\n\t\t\t\t} else {\n\t\t\t\t\tbefore := beforeRange.SliceBytes(src)\n\t\t\t\t\thighlighted := highlightedRange.SliceBytes(src)\n\t\t\t\t\tafter := afterRange.SliceBytes(src)\n\t\t\t\t\tfmt.Fprintf(\n\t\t\t\t\t\tw.wr, \"%4d: %s%s%s%s%s\\n\",\n\t\t\t\t\t\tlineRange.Start.Line,\n\t\t\t\t\t\tbefore,\n\t\t\t\t\t\thighlightCode, highlighted, resetCode,\n\t\t\t\t\t\tafter,\n\t\t\t\t\t)\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tw.wr.Write([]byte{'\\n'})\n\t\t}\n\n\t\tif diag.Expression != nil && diag.EvalContext != nil {\n\t\t\t// We will attempt to render the values for any variables\n\t\t\t// referenced in the given expression as additional context, for\n\t\t\t// situations where the same expression is evaluated multiple\n\t\t\t// times in different scopes.\n\t\t\texpr := diag.Expression\n\t\t\tctx := diag.EvalContext\n\n\t\t\tvars := expr.Variables()\n\t\t\tstmts := make([]string, 0, len(vars))\n\t\t\tseen := make(map[string]struct{}, len(vars))\n\t\t\tfor _, traversal := range vars {\n\t\t\t\tval, diags := traversal.TraverseAbs(ctx)\n\t\t\t\tif diags.HasErrors() {\n\t\t\t\t\t// Skip anything that generates errors, since we probably\n\t\t\t\t\t// already have the same error in our diagnostics set\n\t\t\t\t\t// already.\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\ttraversalStr := w.traversalStr(traversal)\n\t\t\t\tif _, exists := seen[traversalStr]; exists {\n\t\t\t\t\tcontinue // don't show duplicates when the same variable is referenced multiple times\n\t\t\t\t}\n\t\t\t\tswitch {\n\t\t\t\tcase !val.IsKnown():\n\t\t\t\t\t// Can't say anything about this yet, then.\n\t\t\t\t\tcontinue\n\t\t\t\tcase val.IsNull():\n\t\t\t\t\tstmts = append(stmts, fmt.Sprintf(\"%s set to null\", traversalStr))\n\t\t\t\tdefault:\n\t\t\t\t\tstmts = append(stmts, fmt.Sprintf(\"%s as %s\", traversalStr, w.valueStr(val)))\n\t\t\t\t}\n\t\t\t\tseen[traversalStr] = struct{}{}\n\t\t\t}\n\n\t\t\tsort.Strings(stmts) // FIXME: Should maybe use a traversal-aware sort that can sort numeric indexes properly?\n\t\t\tlast := len(stmts) - 1\n\n\t\t\tfor i, stmt := range stmts {\n\t\t\t\tswitch i {\n\t\t\t\tcase 0:\n\t\t\t\t\tw.wr.Write([]byte{'w', 'i', 't', 'h', ' '})\n\t\t\t\tdefault:\n\t\t\t\t\tw.wr.Write([]byte{' ', ' ', ' ', ' ', ' '})\n\t\t\t\t}\n\t\t\t\tw.wr.Write([]byte(stmt))\n\t\t\t\tswitch i {\n\t\t\t\tcase last:\n\t\t\t\t\tw.wr.Write([]byte{'.', '\\n', '\\n'})\n\t\t\t\tdefault:\n\t\t\t\t\tw.wr.Write([]byte{',', '\\n'})\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif diag.Detail != \"\" {\n\t\tdetail := diag.Detail\n\t\tif w.width != 0 {\n\t\t\tdetail = wordwrap.WrapString(detail, w.width)\n\t\t}\n\t\tfmt.Fprintf(w.wr, \"%s\\n\\n\", detail)\n\t}\n\n\treturn nil\n}\n\nfunc (w *diagnosticTextWriter) WriteDiagnostics(diags Diagnostics) error {\n\tfor _, diag := range diags {\n\t\terr := w.WriteDiagnostic(diag)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (w *diagnosticTextWriter) traversalStr(traversal Traversal) string {\n\t// This is a specialized subset of traversal rendering tailored to\n\t// producing helpful contextual messages in diagnostics. It is not\n\t// comprehensive nor intended to be used for other purposes.\n\n\tvar buf bytes.Buffer\n\tfor _, step := range traversal {\n\t\tswitch tStep := step.(type) {\n\t\tcase TraverseRoot:\n\t\t\tbuf.WriteString(tStep.Name)\n\t\tcase TraverseAttr:\n\t\t\tbuf.WriteByte('.')\n\t\t\tbuf.WriteString(tStep.Name)\n\t\tcase TraverseIndex:\n\t\t\tbuf.WriteByte('[')\n\t\t\tif keyTy := tStep.Key.Type(); keyTy.IsPrimitiveType() {\n\t\t\t\tbuf.WriteString(w.valueStr(tStep.Key))\n\t\t\t} else {\n\t\t\t\t// We'll just use a placeholder for more complex values,\n\t\t\t\t// since otherwise our result could grow ridiculously long.\n\t\t\t\tbuf.WriteString(\"...\")\n\t\t\t}\n\t\t\tbuf.WriteByte(']')\n\t\t}\n\t}\n\treturn buf.String()\n}\n\nfunc (w *diagnosticTextWriter) valueStr(val cty.Value) string {\n\t// This is a specialized subset of value rendering tailored to producing\n\t// helpful but concise messages in diagnostics. It is not comprehensive\n\t// nor intended to be used for other purposes.\n\n\tty := val.Type()\n\tswitch {\n\tcase val.IsNull():\n\t\treturn \"null\"\n\tcase !val.IsKnown():\n\t\t// Should never happen here because we should filter before we get\n\t\t// in here, but we'll do something reasonable rather than panic.\n\t\treturn \"(not yet known)\"\n\tcase ty == cty.Bool:\n\t\tif val.True() {\n\t\t\treturn \"true\"\n\t\t}\n\t\treturn \"false\"\n\tcase ty == cty.Number:\n\t\tbf := val.AsBigFloat()\n\t\treturn bf.Text('g', 10)\n\tcase ty == cty.String:\n\t\t// Go string syntax is not exactly the same as HCL native string syntax,\n\t\t// but we'll accept the minor edge-cases where this is different here\n\t\t// for now, just to get something reasonable here.\n\t\treturn fmt.Sprintf(\"%q\", val.AsString())\n\tcase ty.IsCollectionType() || ty.IsTupleType():\n\t\tl := val.LengthInt()\n\t\tswitch l {\n\t\tcase 0:\n\t\t\treturn \"empty \" + ty.FriendlyName()\n\t\tcase 1:\n\t\t\treturn ty.FriendlyName() + \" with 1 element\"\n\t\tdefault:\n\t\t\treturn fmt.Sprintf(\"%s with %d elements\", ty.FriendlyName(), l)\n\t\t}\n\tcase ty.IsObjectType():\n\t\tatys := ty.AttributeTypes()\n\t\tl := len(atys)\n\t\tswitch l {\n\t\tcase 0:\n\t\t\treturn \"object with no attributes\"\n\t\tcase 1:\n\t\t\tvar name string\n\t\t\tfor k := range atys {\n\t\t\t\tname = k\n\t\t\t}\n\t\t\treturn fmt.Sprintf(\"object with 1 attribute %q\", name)\n\t\tdefault:\n\t\t\treturn fmt.Sprintf(\"object with %d attributes\", l)\n\t\t}\n\tdefault:\n\t\treturn ty.FriendlyName()\n\t}\n}\n\nfunc contextString(file *File, offset int) string {\n\ttype contextStringer interface {\n\t\tContextString(offset int) string\n\t}\n\n\tif cser, ok := file.Nav.(contextStringer); ok {\n\t\treturn cser.ContextString(offset)\n\t}\n\treturn \"\"\n}\n"
        },
        {
          "name": "diagnostic_text_test.go",
          "type": "blob",
          "size": 4.328125,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"testing\"\n\n\t\"github.com/zclconf/go-cty/cty\"\n)\n\nfunc TestDiagnosticTextWriter(t *testing.T) {\n\ttests := []struct {\n\t\tInput *Diagnostic\n\t\tWant  string\n\t}{\n\t\t{\n\t\t\t&Diagnostic{\n\t\t\t\tSeverity: DiagError,\n\t\t\t\tSummary:  \"Splines not reticulated\",\n\t\t\t\tDetail:   \"All splines must be pre-reticulated.\",\n\t\t\t\tSubject: &Range{\n\t\t\t\t\tStart: Pos{\n\t\t\t\t\t\tByte:   0,\n\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t\tLine:   1,\n\t\t\t\t\t},\n\t\t\t\t\tEnd: Pos{\n\t\t\t\t\t\tByte:   3,\n\t\t\t\t\t\tColumn: 4,\n\t\t\t\t\t\tLine:   1,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t`Error: Splines not reticulated\n\n  on  line 1, in hardcoded-context:\n   1: foo = 1\n\nAll splines must be pre-reticulated.\n\n`,\n\t\t},\n\t\t{\n\t\t\t&Diagnostic{\n\t\t\t\tSeverity: DiagError,\n\t\t\t\tSummary:  \"Unsupported attribute\",\n\t\t\t\tDetail:   `\"baz\" is not a supported top-level attribute. Did you mean \"bam\"?`,\n\t\t\t\tSubject: &Range{\n\t\t\t\t\tStart: Pos{\n\t\t\t\t\t\tByte:   16,\n\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t\tLine:   3,\n\t\t\t\t\t},\n\t\t\t\t\tEnd: Pos{\n\t\t\t\t\t\tByte:   19,\n\t\t\t\t\t\tColumn: 4,\n\t\t\t\t\t\tLine:   3,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t`Error: Unsupported attribute\n\n  on  line 3, in hardcoded-context:\n   3: baz = 3\n\n\"baz\" is not a supported top-level\nattribute. Did you mean \"bam\"?\n\n`,\n\t\t},\n\t\t{\n\t\t\t&Diagnostic{\n\t\t\t\tSeverity: DiagError,\n\t\t\t\tSummary:  \"Unsupported attribute\",\n\t\t\t\tDetail:   `\"pizza\" is not a supported attribute. Did you mean \"pizzetta\"?`,\n\t\t\t\tSubject: &Range{\n\t\t\t\t\tStart: Pos{\n\t\t\t\t\t\tByte:   42,\n\t\t\t\t\t\tColumn: 3,\n\t\t\t\t\t\tLine:   5,\n\t\t\t\t\t},\n\t\t\t\t\tEnd: Pos{\n\t\t\t\t\t\tByte:   47,\n\t\t\t\t\t\tColumn: 8,\n\t\t\t\t\t\tLine:   5,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t// This is actually not a great example of a context, but is here to test\n\t\t\t\t// whether we're able to show a multi-line context when needed.\n\t\t\t\tContext: &Range{\n\t\t\t\t\tStart: Pos{\n\t\t\t\t\t\tByte:   24,\n\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t\tLine:   4,\n\t\t\t\t\t},\n\t\t\t\t\tEnd: Pos{\n\t\t\t\t\t\tByte:   60,\n\t\t\t\t\t\tColumn: 2,\n\t\t\t\t\t\tLine:   6,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t`Error: Unsupported attribute\n\n  on  line 5, in hardcoded-context:\n   4: block \"party\" {\n   5:   pizza = \"cheese\"\n   6: }\n\n\"pizza\" is not a supported attribute.\nDid you mean \"pizzetta\"?\n\n`,\n\t\t},\n\t\t{\n\t\t\t&Diagnostic{\n\t\t\t\tSeverity: DiagError,\n\t\t\t\tSummary:  \"Test of including relevant variable values\",\n\t\t\t\tDetail:   `This diagnostic includes an expression and an evalcontext.`,\n\t\t\t\tSubject: &Range{\n\t\t\t\t\tStart: Pos{\n\t\t\t\t\t\tByte:   42,\n\t\t\t\t\t\tColumn: 3,\n\t\t\t\t\t\tLine:   5,\n\t\t\t\t\t},\n\t\t\t\t\tEnd: Pos{\n\t\t\t\t\t\tByte:   47,\n\t\t\t\t\t\tColumn: 8,\n\t\t\t\t\t\tLine:   5,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tExpression: &diagnosticTestExpr{\n\t\t\t\t\tvars: []Traversal{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tTraverseRoot{\n\t\t\t\t\t\t\t\tName: \"foo\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tTraverseRoot{\n\t\t\t\t\t\t\t\tName: \"bar\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tTraverseAttr{\n\t\t\t\t\t\t\t\tName: \"baz\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tTraverseRoot{\n\t\t\t\t\t\t\t\tName: \"missing\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tTraverseRoot{\n\t\t\t\t\t\t\t\tName: \"boz\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tEvalContext: &EvalContext{\n\t\t\t\t\tparent: &EvalContext{\n\t\t\t\t\t\tVariables: map[string]cty.Value{\n\t\t\t\t\t\t\t\"foo\": cty.StringVal(\"foo value\"),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tVariables: map[string]cty.Value{\n\t\t\t\t\t\t\"bar\": cty.ObjectVal(map[string]cty.Value{\n\t\t\t\t\t\t\t\"baz\": cty.ListValEmpty(cty.String),\n\t\t\t\t\t\t}),\n\t\t\t\t\t\t\"boz\":    cty.NumberIntVal(5),\n\t\t\t\t\t\t\"unused\": cty.True,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t`Error: Test of including relevant variable values\n\n  on  line 5, in hardcoded-context:\n   5:   pizza = \"cheese\"\n\nwith bar.baz as empty list of string,\n     boz as 5,\n     foo as \"foo value\".\n\nThis diagnostic includes an expression\nand an evalcontext.\n\n`,\n\t\t},\n\t}\n\n\tfiles := map[string]*File{\n\t\t\"\": &File{\n\t\t\tBytes: []byte(testDiagnosticTextWriterSource),\n\t\t\tNav:   &diagnosticTestNav{},\n\t\t},\n\t}\n\n\tfor i, test := range tests {\n\t\tt.Run(fmt.Sprintf(\"%02d\", i), func(t *testing.T) {\n\t\t\tbwr := &bytes.Buffer{}\n\t\t\tdwr := NewDiagnosticTextWriter(bwr, files, 40, false)\n\t\t\terr := dwr.WriteDiagnostic(test.Input)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"unexpected error: %s\", err)\n\t\t\t}\n\t\t\tgot := bwr.String()\n\t\t\tif got != test.Want {\n\t\t\t\tt.Errorf(\"wrong result\\n\\ngot:\\n%swant:\\n%s\", got, test.Want)\n\t\t\t}\n\t\t})\n\t}\n}\n\nconst testDiagnosticTextWriterSource = `foo = 1\nbar = 2\nbaz = 3\nblock \"party\" {\n  pizza = \"cheese\"\n}\n`\n\ntype diagnosticTestNav struct {\n}\n\nfunc (tn *diagnosticTestNav) ContextString(offset int) string {\n\treturn \"hardcoded-context\"\n}\n\ntype diagnosticTestExpr struct {\n\tvars []Traversal\n\tstaticExpr\n}\n\nfunc (e *diagnosticTestExpr) Variables() []Traversal {\n\treturn e.vars\n}\n"
        },
        {
          "name": "diagnostic_typeparams.go",
          "type": "blob",
          "size": 1.3046875,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\n//go:build go1.18\n// +build go1.18\n\npackage hcl\n\n// This file contains additional diagnostics-related symbols that use the\n// Go 1.18 type parameters syntax and would therefore be incompatible with\n// Go 1.17 and earlier.\n\n// DiagnosticExtra attempts to retrieve an \"extra value\" of type T from the\n// given diagnostic, if either the diag.Extra field directly contains a value\n// of that type or the value implements DiagnosticExtraUnwrapper and directly\n// or indirectly returns a value of that type.\n//\n// Type T should typically be an interface type, so that code which generates\n// diagnostics can potentially return different implementations of the same\n// interface dynamically as needed.\n//\n// If a value of type T is found, returns that value and true to indicate\n// success. Otherwise, returns the zero value of T and false to indicate\n// failure.\nfunc DiagnosticExtra[T any](diag *Diagnostic) (T, bool) {\n\textra := diag.Extra\n\tvar zero T\n\n\tfor {\n\t\tif ret, ok := extra.(T); ok {\n\t\t\treturn ret, true\n\t\t}\n\n\t\tif unwrap, ok := extra.(DiagnosticExtraUnwrapper); ok {\n\t\t\t// If our \"extra\" implements DiagnosticExtraUnwrapper then we'll\n\t\t\t// unwrap one level and try this again.\n\t\t\textra = unwrap.UnwrapDiagnosticExtra()\n\t\t} else {\n\t\t\treturn zero, false\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "didyoumean.go",
          "type": "blob",
          "size": 0.8564453125,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\nimport (\n\t\"github.com/agext/levenshtein\"\n)\n\n// nameSuggestion tries to find a name from the given slice of suggested names\n// that is close to the given name and returns it if found. If no suggestion\n// is close enough, returns the empty string.\n//\n// The suggestions are tried in order, so earlier suggestions take precedence\n// if the given string is similar to two or more suggestions.\n//\n// This function is intended to be used with a relatively-small number of\n// suggestions. It's not optimized for hundreds or thousands of them.\nfunc nameSuggestion(given string, suggestions []string) string {\n\tfor _, suggestion := range suggestions {\n\t\tdist := levenshtein.Distance(given, suggestion, nil)\n\t\tif dist < 3 { // threshold determined experimentally\n\t\t\treturn suggestion\n\t\t}\n\t}\n\treturn \"\"\n}\n"
        },
        {
          "name": "doc.go",
          "type": "blob",
          "size": 1.2197265625,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\n// Package hcl contains the main modelling types and general utility functions\n// for HCL.\n//\n// For a simple entry point into HCL, see the package in the subdirectory\n// \"hclsimple\", which has an opinionated function Decode that can decode HCL\n// configurations in either native HCL syntax or JSON syntax into a Go struct\n// type:\n//\n//     package main\n//\n//     import (\n//     \t\"log\"\n//     \t\"github.com/hashicorp/hcl/v2/hclsimple\"\n//     )\n//\n//     type Config struct {\n//     \tLogLevel string `hcl:\"log_level\"`\n//     }\n//\n//     func main() {\n//     \tvar config Config\n//     \terr := hclsimple.DecodeFile(\"config.hcl\", nil, &config)\n//     \tif err != nil {\n//     \t\tlog.Fatalf(\"Failed to load configuration: %s\", err)\n//     \t}\n//     \tlog.Printf(\"Configuration is %#v\", config)\n//     }\n//\n// If your application needs more control over the evaluation of the\n// configuration, you can use the functions in the subdirectories hclparse,\n// gohcl, hcldec, etc. Splitting the handling of configuration into multiple\n// phases allows for advanced patterns such as allowing expressions in one\n// part of the configuration to refer to data defined in another part.\npackage hcl\n"
        },
        {
          "name": "eval_context.go",
          "type": "blob",
          "size": 0.697265625,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\nimport (\n\t\"github.com/zclconf/go-cty/cty\"\n\t\"github.com/zclconf/go-cty/cty/function\"\n)\n\n// An EvalContext provides the variables and functions that should be used\n// to evaluate an expression.\ntype EvalContext struct {\n\tVariables map[string]cty.Value\n\tFunctions map[string]function.Function\n\tparent    *EvalContext\n}\n\n// NewChild returns a new EvalContext that is a child of the receiver.\nfunc (ctx *EvalContext) NewChild() *EvalContext {\n\treturn &EvalContext{parent: ctx}\n}\n\n// Parent returns the parent of the receiver, or nil if the receiver has\n// no parent.\nfunc (ctx *EvalContext) Parent() *EvalContext {\n\treturn ctx.parent\n}\n"
        },
        {
          "name": "expr_call.go",
          "type": "blob",
          "size": 1.453125,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\n// ExprCall tests if the given expression is a function call and,\n// if so, extracts the function name and the expressions that represent\n// the arguments. If the given expression is not statically a function call,\n// error diagnostics are returned.\n//\n// A particular Expression implementation can support this function by\n// offering a method called ExprCall that takes no arguments and returns\n// *StaticCall. This method should return nil if a static call cannot\n// be extracted.  Alternatively, an implementation can support\n// UnwrapExpression to delegate handling of this function to a wrapped\n// Expression object.\nfunc ExprCall(expr Expression) (*StaticCall, Diagnostics) {\n\ttype exprCall interface {\n\t\tExprCall() *StaticCall\n\t}\n\n\tphysExpr := UnwrapExpressionUntil(expr, func(expr Expression) bool {\n\t\t_, supported := expr.(exprCall)\n\t\treturn supported\n\t})\n\n\tif exC, supported := physExpr.(exprCall); supported {\n\t\tif call := exC.ExprCall(); call != nil {\n\t\t\treturn call, nil\n\t\t}\n\t}\n\treturn nil, Diagnostics{\n\t\t&Diagnostic{\n\t\t\tSeverity: DiagError,\n\t\t\tSummary:  \"Invalid expression\",\n\t\t\tDetail:   \"A static function call is required.\",\n\t\t\tSubject:  expr.StartRange().Ptr(),\n\t\t},\n\t}\n}\n\n// StaticCall represents a function call that was extracted statically from\n// an expression using ExprCall.\ntype StaticCall struct {\n\tName      string\n\tNameRange Range\n\tArguments []Expression\n\tArgsRange Range\n}\n"
        },
        {
          "name": "expr_list.go",
          "type": "blob",
          "size": 1.2275390625,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\n// ExprList tests if the given expression is a static list construct and,\n// if so, extracts the expressions that represent the list elements.\n// If the given expression is not a static list, error diagnostics are\n// returned.\n//\n// A particular Expression implementation can support this function by\n// offering a method called ExprList that takes no arguments and returns\n// []Expression. This method should return nil if a static list cannot\n// be extracted.  Alternatively, an implementation can support\n// UnwrapExpression to delegate handling of this function to a wrapped\n// Expression object.\nfunc ExprList(expr Expression) ([]Expression, Diagnostics) {\n\ttype exprList interface {\n\t\tExprList() []Expression\n\t}\n\n\tphysExpr := UnwrapExpressionUntil(expr, func(expr Expression) bool {\n\t\t_, supported := expr.(exprList)\n\t\treturn supported\n\t})\n\n\tif exL, supported := physExpr.(exprList); supported {\n\t\tif list := exL.ExprList(); list != nil {\n\t\t\treturn list, nil\n\t\t}\n\t}\n\treturn nil, Diagnostics{\n\t\t&Diagnostic{\n\t\t\tSeverity: DiagError,\n\t\t\tSummary:  \"Invalid expression\",\n\t\t\tDetail:   \"A static list expression is required.\",\n\t\t\tSubject:  expr.StartRange().Ptr(),\n\t\t},\n\t}\n}\n"
        },
        {
          "name": "expr_map.go",
          "type": "blob",
          "size": 1.41015625,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\n// ExprMap tests if the given expression is a static map construct and,\n// if so, extracts the expressions that represent the map elements.\n// If the given expression is not a static map, error diagnostics are\n// returned.\n//\n// A particular Expression implementation can support this function by\n// offering a method called ExprMap that takes no arguments and returns\n// []KeyValuePair. This method should return nil if a static map cannot\n// be extracted.  Alternatively, an implementation can support\n// UnwrapExpression to delegate handling of this function to a wrapped\n// Expression object.\nfunc ExprMap(expr Expression) ([]KeyValuePair, Diagnostics) {\n\ttype exprMap interface {\n\t\tExprMap() []KeyValuePair\n\t}\n\n\tphysExpr := UnwrapExpressionUntil(expr, func(expr Expression) bool {\n\t\t_, supported := expr.(exprMap)\n\t\treturn supported\n\t})\n\n\tif exM, supported := physExpr.(exprMap); supported {\n\t\tif pairs := exM.ExprMap(); pairs != nil {\n\t\t\treturn pairs, nil\n\t\t}\n\t}\n\treturn nil, Diagnostics{\n\t\t&Diagnostic{\n\t\t\tSeverity: DiagError,\n\t\t\tSummary:  \"Invalid expression\",\n\t\t\tDetail:   \"A static map expression is required.\",\n\t\t\tSubject:  expr.StartRange().Ptr(),\n\t\t},\n\t}\n}\n\n// KeyValuePair represents a pair of expressions that serve as a single item\n// within a map or object definition construct.\ntype KeyValuePair struct {\n\tKey   Expression\n\tValue Expression\n}\n"
        },
        {
          "name": "expr_unwrap.go",
          "type": "blob",
          "size": 2.5146484375,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\ntype unwrapExpression interface {\n\tUnwrapExpression() Expression\n}\n\n// UnwrapExpression removes any \"wrapper\" expressions from the given expression,\n// to recover the representation of the physical expression given in source\n// code.\n//\n// Sometimes wrapping expressions are used to modify expression behavior, e.g.\n// in extensions that need to make some local variables available to certain\n// sub-trees of the configuration. This can make it difficult to reliably\n// type-assert on the physical AST types used by the underlying syntax.\n//\n// Unwrapping an expression may modify its behavior by stripping away any\n// additional constraints or capabilities being applied to the Value and\n// Variables methods, so this function should generally only be used prior\n// to operations that concern themselves with the static syntax of the input\n// configuration, and not with the effective value of the expression.\n//\n// Wrapper expression types must support unwrapping by implementing a method\n// called UnwrapExpression that takes no arguments and returns the embedded\n// Expression. Implementations of this method should peel away only one level\n// of wrapping, if multiple are present. This method may return nil to\n// indicate _dynamically_ that no wrapped expression is available, for\n// expression types that might only behave as wrappers in certain cases.\nfunc UnwrapExpression(expr Expression) Expression {\n\tfor {\n\t\tunwrap, wrapped := expr.(unwrapExpression)\n\t\tif !wrapped {\n\t\t\treturn expr\n\t\t}\n\t\tinnerExpr := unwrap.UnwrapExpression()\n\t\tif innerExpr == nil {\n\t\t\treturn expr\n\t\t}\n\t\texpr = innerExpr\n\t}\n}\n\n// UnwrapExpressionUntil is similar to UnwrapExpression except it gives the\n// caller an opportunity to test each level of unwrapping to see each a\n// particular expression is accepted.\n//\n// This could be used, for example, to unwrap until a particular other\n// interface is satisfied, regardless of wrap wrapping level it is satisfied\n// at.\n//\n// The given callback function must return false to continue wrapping, or\n// true to accept and return the proposed expression given. If the callback\n// function rejects even the final, physical expression then the result of\n// this function is nil.\nfunc UnwrapExpressionUntil(expr Expression, until func(Expression) bool) Expression {\n\tfor {\n\t\tif until(expr) {\n\t\t\treturn expr\n\t\t}\n\t\tunwrap, wrapped := expr.(unwrapExpression)\n\t\tif !wrapped {\n\t\t\treturn nil\n\t\t}\n\t\texpr = unwrap.UnwrapExpression()\n\t\tif expr == nil {\n\t\t\treturn nil\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "ext",
          "type": "tree",
          "content": null
        },
        {
          "name": "fuzz",
          "type": "tree",
          "content": null
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.765625,
          "content": "module github.com/hashicorp/hcl/v2\n\ngo 1.18\n\nrequire (\n\tgithub.com/agext/levenshtein v1.2.1\n\tgithub.com/apparentlymart/go-textseg/v15 v15.0.0\n\tgithub.com/davecgh/go-spew v1.1.1\n\tgithub.com/go-test/deep v1.0.3\n\tgithub.com/google/go-cmp v0.6.0\n\tgithub.com/mitchellh/go-wordwrap v0.0.0-20150314170334-ad45545899c7\n\tgithub.com/spf13/pflag v1.0.2\n\tgithub.com/zclconf/go-cty v1.13.0\n\tgithub.com/zclconf/go-cty-debug v0.0.0-20240509010212-0d6042c53940\n\tgolang.org/x/crypto v0.0.0-20220517005047-85d78b3ac167\n\tgolang.org/x/tools v0.6.0\n)\n\nrequire (\n\tgithub.com/apparentlymart/go-textseg/v13 v13.0.0 // indirect\n\tgolang.org/x/mod v0.8.0 // indirect\n\tgolang.org/x/sys v0.5.0 // indirect\n\tgolang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1 // indirect\n\tgolang.org/x/text v0.11.0 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 4.7890625,
          "content": "github.com/agext/levenshtein v1.2.1 h1:QmvMAjj2aEICytGiWzmxoE0x2KZvE0fvmqMOfy2tjT8=\ngithub.com/agext/levenshtein v1.2.1/go.mod h1:JEDfjyjHDjOF/1e4FlBE/PkbqA9OfWu2ki2W0IB5558=\ngithub.com/apparentlymart/go-textseg v1.0.0/go.mod h1:z96Txxhf3xSFMPmb5X/1W05FF/Nj9VFpLOpjS5yuumk=\ngithub.com/apparentlymart/go-textseg/v13 v13.0.0 h1:Y+KvPE1NYz0xl601PVImeQfFyEy6iT90AvPUL1NNfNw=\ngithub.com/apparentlymart/go-textseg/v13 v13.0.0/go.mod h1:ZK2fH7c4NqDTLtiYLvIkEghdlcqw7yxLeM89kiTRPUo=\ngithub.com/apparentlymart/go-textseg/v15 v15.0.0 h1:uYvfpb3DyLSCGWnctWKGj857c6ew1u1fNQOlOtuGxQY=\ngithub.com/apparentlymart/go-textseg/v15 v15.0.0/go.mod h1:K8XmNZdhEBkdlyDdvbmmsvpAG721bKi0joRfFdHIWJ4=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/go-test/deep v1.0.3 h1:ZrJSEWsXzPOxaZnFteGEfooLba+ju3FYIbOrS+rQd68=\ngithub.com/go-test/deep v1.0.3/go.mod h1:wGDj63lr65AM2AQyKZd/NYHGb0R+1RLqB8NKt3aSFNA=\ngithub.com/golang/protobuf v1.1.0/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/google/go-cmp v0.3.1/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.6.0 h1:ofyhxvXcZhMsU5ulbFiLKl/XBFqE1GSq7atu8tAmTRI=\ngithub.com/google/go-cmp v0.6.0/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/kr/pretty v0.1.0/go.mod h1:dAy3ld7l9f0ibDNOQOHHMYYIIbhfbHSm3C4ZsoJORNo=\ngithub.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=\ngithub.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=\ngithub.com/kylelemons/godebug v0.0.0-20170820004349-d65d576e9348/go.mod h1:B69LEHPfb2qLo0BaaOLcbitczOKLWTsrBG9LczfCD4k=\ngithub.com/mitchellh/go-wordwrap v0.0.0-20150314170334-ad45545899c7 h1:DpOJ2HYzCv8LZP15IdmG+YdwD2luVPHITV96TkirNBM=\ngithub.com/mitchellh/go-wordwrap v0.0.0-20150314170334-ad45545899c7/go.mod h1:ZXFpozHsX6DPmq2I0TCekCxypsnAUbP2oI0UX1GXzOo=\ngithub.com/spf13/pflag v1.0.2 h1:Fy0orTDgHdbnzHcsOgfCN4LtHf0ec3wwtiwJqwvf3Gc=\ngithub.com/spf13/pflag v1.0.2/go.mod h1:DYY7MBk1bdzusC3SYhjObp+wFpr4gzcvqqNjLnInEg4=\ngithub.com/vmihailenco/msgpack v3.3.3+incompatible/go.mod h1:fy3FlTQTDXWkZ7Bh6AcGMlsjHatGryHQYUTf1ShIgkk=\ngithub.com/zclconf/go-cty v1.2.0/go.mod h1:hOPWgoHbaTUnI5k4D2ld+GRpFJSCe6bCM7m1q/N4PQ8=\ngithub.com/zclconf/go-cty v1.13.0 h1:It5dfKTTZHe9aeppbNOda3mN7Ag7sg6QkBNm6TkyFa0=\ngithub.com/zclconf/go-cty v1.13.0/go.mod h1:YKQzy/7pZ7iq2jNFzy5go57xdxdWoLLpaEp4u238AE0=\ngithub.com/zclconf/go-cty-debug v0.0.0-20191215020915-b22d67c1ba0b h1:FosyBZYxY34Wul7O/MSKey3txpPYyCqVO5ZyceuQJEI=\ngithub.com/zclconf/go-cty-debug v0.0.0-20191215020915-b22d67c1ba0b/go.mod h1:ZRKQfBXbGkpdV6QMzT3rU1kSTAnfu1dO8dPKjYprgj8=\ngithub.com/zclconf/go-cty-debug v0.0.0-20240417160409-8c45e122ae1a h1:/o/Emn22dZIQ7AhyA0aLOKo528WG/WRAM5tqzIoQIOs=\ngithub.com/zclconf/go-cty-debug v0.0.0-20240417160409-8c45e122ae1a/go.mod h1:CmBdvvj3nqzfzJ6nTCIwDTPZ56aVGvDrmztiO5g3qrM=\ngithub.com/zclconf/go-cty-debug v0.0.0-20240509010212-0d6042c53940 h1:4r45xpDWB6ZMSMNJFMOjqrGHynW3DIBuR2H9j0ug+Mo=\ngithub.com/zclconf/go-cty-debug v0.0.0-20240509010212-0d6042c53940/go.mod h1:CmBdvvj3nqzfzJ6nTCIwDTPZ56aVGvDrmztiO5g3qrM=\ngolang.org/x/crypto v0.0.0-20220517005047-85d78b3ac167 h1:O8uGbHCqlTp2P6QJSLmCojM4mN6UemYv8K+dCnmHmu0=\ngolang.org/x/crypto v0.0.0-20220517005047-85d78b3ac167/go.mod h1:IxCIyHEi3zRg3s0A5j5BB6A9Jmi73HwBIUl50j+osU4=\ngolang.org/x/mod v0.8.0 h1:LUYupSeNrTNCGzR/hVBk2NHZO4hXcVaW1k4Qx7rjPx8=\ngolang.org/x/mod v0.8.0/go.mod h1:iBbtSCu2XBx23ZKBPSOrRkjjQPZFPuis4dIYUhu/chs=\ngolang.org/x/net v0.0.0-20180811021610-c39426892332/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/sync v0.0.0-20180314180146-1d60e4601c6f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.1.0 h1:wsuoTGHzEhffawBOhz5CYhcrV4IdKZbEyZjBMuTp12o=\ngolang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.5.0 h1:MUK/U/4lj1t1oPg0HfuXDN/Z1wv31ZJ/YcPiGccS4DU=\ngolang.org/x/sys v0.5.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1 h1:v+OssWQX+hTHEmOBgwxdZxK4zHq3yOs8F9J7mk0PY8E=\ngolang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.11.0 h1:LAntKIrcmeSKERyiOh0XMV39LXS8IE9UL2yP7+f5ij4=\ngolang.org/x/text v0.11.0/go.mod h1:TvPlkZtksWOMsz7fbANvkp4WM8x/WCo/om8BMLbz+aE=\ngolang.org/x/tools v0.6.0 h1:BOw41kyTf3PuCW1pVQf8+Cyg8pMlkYB1oo9iJ6D/lKM=\ngolang.org/x/tools v0.6.0/go.mod h1:Xwgl3UAJ/d3gWutnCtw505GrjyAbvKui8lOU390QaIU=\ngoogle.golang.org/appengine v1.1.0/go.mod h1:EbEs0AVv82hx2wNQdGPgUI5lhzA/G0D9YwlJXL52JkM=\ngopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\n"
        },
        {
          "name": "gohcl",
          "type": "tree",
          "content": null
        },
        {
          "name": "guide",
          "type": "tree",
          "content": null
        },
        {
          "name": "hcldec",
          "type": "tree",
          "content": null
        },
        {
          "name": "hcled",
          "type": "tree",
          "content": null
        },
        {
          "name": "hclparse",
          "type": "tree",
          "content": null
        },
        {
          "name": "hclsimple",
          "type": "tree",
          "content": null
        },
        {
          "name": "hclsyntax",
          "type": "tree",
          "content": null
        },
        {
          "name": "hcltest",
          "type": "tree",
          "content": null
        },
        {
          "name": "hclwrite",
          "type": "tree",
          "content": null
        },
        {
          "name": "integrationtest",
          "type": "tree",
          "content": null
        },
        {
          "name": "json",
          "type": "tree",
          "content": null
        },
        {
          "name": "merged.go",
          "type": "blob",
          "size": 6.361328125,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\nimport (\n\t\"fmt\"\n)\n\n// MergeFiles combines the given files to produce a single body that contains\n// configuration from all of the given files.\n//\n// The ordering of the given files decides the order in which contained\n// elements will be returned. If any top-level attributes are defined with\n// the same name across multiple files, a diagnostic will be produced from\n// the Content and PartialContent methods describing this error in a\n// user-friendly way.\nfunc MergeFiles(files []*File) Body {\n\tvar bodies []Body\n\tfor _, file := range files {\n\t\tbodies = append(bodies, file.Body)\n\t}\n\treturn MergeBodies(bodies)\n}\n\n// MergeBodies is like MergeFiles except it deals directly with bodies, rather\n// than with entire files.\nfunc MergeBodies(bodies []Body) Body {\n\tif len(bodies) == 0 {\n\t\t// Swap out for our singleton empty body, to reduce the number of\n\t\t// empty slices we have hanging around.\n\t\treturn emptyBody\n\t}\n\n\t// If any of the given bodies are already merged bodies, we'll unpack\n\t// to flatten to a single mergedBodies, since that's conceptually simpler.\n\t// This also, as a side-effect, eliminates any empty bodies, since\n\t// empties are merged bodies with no inner bodies.\n\tvar newLen int\n\tvar flatten bool\n\tfor _, body := range bodies {\n\t\tif children, merged := body.(mergedBodies); merged {\n\t\t\tnewLen += len(children)\n\t\t\tflatten = true\n\t\t} else {\n\t\t\tnewLen++\n\t\t}\n\t}\n\n\tif !flatten { // not just newLen == len, because we might have mergedBodies with single bodies inside\n\t\treturn mergedBodies(bodies)\n\t}\n\n\tif newLen == 0 {\n\t\t// Don't allocate a new empty when we already have one\n\t\treturn emptyBody\n\t}\n\n\tnew := make([]Body, 0, newLen)\n\tfor _, body := range bodies {\n\t\tif children, merged := body.(mergedBodies); merged {\n\t\t\tnew = append(new, children...)\n\t\t} else {\n\t\t\tnew = append(new, body)\n\t\t}\n\t}\n\treturn mergedBodies(new)\n}\n\nvar emptyBody = mergedBodies([]Body{})\n\n// EmptyBody returns a body with no content. This body can be used as a\n// placeholder when a body is required but no body content is available.\nfunc EmptyBody() Body {\n\treturn emptyBody\n}\n\ntype mergedBodies []Body\n\n// Content returns the content produced by applying the given schema to all\n// of the merged bodies and merging the result.\n//\n// Although required attributes _are_ supported, they should be used sparingly\n// with merged bodies since in this case there is no contextual information\n// with which to return good diagnostics. Applications working with merged\n// bodies may wish to mark all attributes as optional and then check for\n// required attributes afterwards, to produce better diagnostics.\nfunc (mb mergedBodies) Content(schema *BodySchema) (*BodyContent, Diagnostics) {\n\t// the returned body will always be empty in this case, because mergedContent\n\t// will only ever call Content on the child bodies.\n\tcontent, _, diags := mb.mergedContent(schema, false)\n\treturn content, diags\n}\n\nfunc (mb mergedBodies) PartialContent(schema *BodySchema) (*BodyContent, Body, Diagnostics) {\n\treturn mb.mergedContent(schema, true)\n}\n\nfunc (mb mergedBodies) JustAttributes() (Attributes, Diagnostics) {\n\tattrs := make(map[string]*Attribute)\n\tvar diags Diagnostics\n\n\tfor _, body := range mb {\n\t\tthisAttrs, thisDiags := body.JustAttributes()\n\n\t\tif len(thisDiags) != 0 {\n\t\t\tdiags = append(diags, thisDiags...)\n\t\t}\n\n\t\tif thisAttrs != nil {\n\t\t\tfor name, attr := range thisAttrs {\n\t\t\t\tif existing := attrs[name]; existing != nil {\n\t\t\t\t\tdiags = diags.Append(&Diagnostic{\n\t\t\t\t\t\tSeverity: DiagError,\n\t\t\t\t\t\tSummary:  \"Duplicate argument\",\n\t\t\t\t\t\tDetail: fmt.Sprintf(\n\t\t\t\t\t\t\t\"Argument %q was already set at %s\",\n\t\t\t\t\t\t\tname, existing.NameRange.String(),\n\t\t\t\t\t\t),\n\t\t\t\t\t\tSubject: &attr.NameRange,\n\t\t\t\t\t})\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tattrs[name] = attr\n\t\t\t}\n\t\t}\n\t}\n\n\treturn attrs, diags\n}\n\nfunc (mb mergedBodies) MissingItemRange() Range {\n\tif len(mb) == 0 {\n\t\t// Nothing useful to return here, so we'll return some garbage.\n\t\treturn Range{\n\t\t\tFilename: \"<empty>\",\n\t\t}\n\t}\n\n\t// arbitrarily use the first body's missing item range\n\treturn mb[0].MissingItemRange()\n}\n\nfunc (mb mergedBodies) mergedContent(schema *BodySchema, partial bool) (*BodyContent, Body, Diagnostics) {\n\t// We need to produce a new schema with none of the attributes marked as\n\t// required, since _any one_ of our bodies can contribute an attribute value.\n\t// We'll separately check that all required attributes are present at\n\t// the end.\n\tmergedSchema := &BodySchema{\n\t\tBlocks: schema.Blocks,\n\t}\n\tfor _, attrS := range schema.Attributes {\n\t\tmergedAttrS := attrS\n\t\tmergedAttrS.Required = false\n\t\tmergedSchema.Attributes = append(mergedSchema.Attributes, mergedAttrS)\n\t}\n\n\tvar mergedLeftovers []Body\n\tcontent := &BodyContent{\n\t\tAttributes: map[string]*Attribute{},\n\t}\n\n\tvar diags Diagnostics\n\tfor _, body := range mb {\n\t\tvar thisContent *BodyContent\n\t\tvar thisLeftovers Body\n\t\tvar thisDiags Diagnostics\n\n\t\tif partial {\n\t\t\tthisContent, thisLeftovers, thisDiags = body.PartialContent(mergedSchema)\n\t\t} else {\n\t\t\tthisContent, thisDiags = body.Content(mergedSchema)\n\t\t}\n\n\t\tif thisLeftovers != nil {\n\t\t\tmergedLeftovers = append(mergedLeftovers, thisLeftovers)\n\t\t}\n\t\tif len(thisDiags) != 0 {\n\t\t\tdiags = append(diags, thisDiags...)\n\t\t}\n\n\t\tif thisContent.Attributes != nil {\n\t\t\tfor name, attr := range thisContent.Attributes {\n\t\t\t\tif existing := content.Attributes[name]; existing != nil {\n\t\t\t\t\tdiags = diags.Append(&Diagnostic{\n\t\t\t\t\t\tSeverity: DiagError,\n\t\t\t\t\t\tSummary:  \"Duplicate argument\",\n\t\t\t\t\t\tDetail: fmt.Sprintf(\n\t\t\t\t\t\t\t\"Argument %q was already set at %s\",\n\t\t\t\t\t\t\tname, existing.NameRange.String(),\n\t\t\t\t\t\t),\n\t\t\t\t\t\tSubject: &attr.NameRange,\n\t\t\t\t\t})\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tcontent.Attributes[name] = attr\n\t\t\t}\n\t\t}\n\n\t\tif len(thisContent.Blocks) != 0 {\n\t\t\tcontent.Blocks = append(content.Blocks, thisContent.Blocks...)\n\t\t}\n\t}\n\n\t// Finally, we check for required attributes.\n\tfor _, attrS := range schema.Attributes {\n\t\tif !attrS.Required {\n\t\t\tcontinue\n\t\t}\n\n\t\tif content.Attributes[attrS.Name] == nil {\n\t\t\t// We don't have any context here to produce a good diagnostic,\n\t\t\t// which is why we warn in the Content docstring to minimize the\n\t\t\t// use of required attributes on merged bodies.\n\t\t\tdiags = diags.Append(&Diagnostic{\n\t\t\t\tSeverity: DiagError,\n\t\t\t\tSummary:  \"Missing required argument\",\n\t\t\t\tDetail: fmt.Sprintf(\n\t\t\t\t\t\"The argument %q is required, but was not set.\",\n\t\t\t\t\tattrS.Name,\n\t\t\t\t),\n\t\t\t})\n\t\t}\n\t}\n\n\tleftoverBody := MergeBodies(mergedLeftovers)\n\treturn content, leftoverBody, diags\n}\n"
        },
        {
          "name": "merged_test.go",
          "type": "blob",
          "size": 12.1357421875,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n\t\"testing\"\n\n\t\"github.com/davecgh/go-spew/spew\"\n)\n\nfunc TestMergedBodiesContent(t *testing.T) {\n\ttests := []struct {\n\t\tBodies    []Body\n\t\tSchema    *BodySchema\n\t\tWant      *BodyContent\n\t\tDiagCount int\n\t}{\n\t\t{\n\t\t\t[]Body{},\n\t\t\t&BodySchema{},\n\t\t\t&BodyContent{\n\t\t\t\tAttributes: map[string]*Attribute{},\n\t\t\t},\n\t\t\t0,\n\t\t},\n\t\t{\n\t\t\t[]Body{},\n\t\t\t&BodySchema{\n\t\t\t\tAttributes: []AttributeSchema{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodyContent{\n\t\t\t\tAttributes: map[string]*Attribute{},\n\t\t\t},\n\t\t\t0,\n\t\t},\n\t\t{\n\t\t\t[]Body{},\n\t\t\t&BodySchema{\n\t\t\t\tAttributes: []AttributeSchema{\n\t\t\t\t\t{\n\t\t\t\t\t\tName:     \"name\",\n\t\t\t\t\t\tRequired: true,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodyContent{\n\t\t\t\tAttributes: map[string]*Attribute{},\n\t\t\t},\n\t\t\t1,\n\t\t},\n\t\t{\n\t\t\t[]Body{\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tHasAttributes: []string{\"name\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodySchema{\n\t\t\t\tAttributes: []AttributeSchema{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodyContent{\n\t\t\t\tAttributes: map[string]*Attribute{\n\t\t\t\t\t\"name\": &Attribute{\n\t\t\t\t\t\tName: \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t0,\n\t\t},\n\t\t{\n\t\t\t[]Body{\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName:          \"first\",\n\t\t\t\t\tHasAttributes: []string{\"name\"},\n\t\t\t\t},\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName:          \"second\",\n\t\t\t\t\tHasAttributes: []string{\"name\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodySchema{\n\t\t\t\tAttributes: []AttributeSchema{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodyContent{\n\t\t\t\tAttributes: map[string]*Attribute{\n\t\t\t\t\t\"name\": &Attribute{\n\t\t\t\t\t\tName:      \"name\",\n\t\t\t\t\t\tNameRange: Range{Filename: \"first\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t1,\n\t\t},\n\t\t{\n\t\t\t[]Body{\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName:          \"first\",\n\t\t\t\t\tHasAttributes: []string{\"name\"},\n\t\t\t\t},\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName:          \"second\",\n\t\t\t\t\tHasAttributes: []string{\"age\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodySchema{\n\t\t\t\tAttributes: []AttributeSchema{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"name\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"age\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodyContent{\n\t\t\t\tAttributes: map[string]*Attribute{\n\t\t\t\t\t\"name\": &Attribute{\n\t\t\t\t\t\tName:      \"name\",\n\t\t\t\t\t\tNameRange: Range{Filename: \"first\"},\n\t\t\t\t\t},\n\t\t\t\t\t\"age\": &Attribute{\n\t\t\t\t\t\tName:      \"age\",\n\t\t\t\t\t\tNameRange: Range{Filename: \"second\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t0,\n\t\t},\n\t\t{\n\t\t\t[]Body{},\n\t\t\t&BodySchema{\n\t\t\t\tBlocks: []BlockHeaderSchema{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"pizza\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodyContent{\n\t\t\t\tAttributes: map[string]*Attribute{},\n\t\t\t},\n\t\t\t0,\n\t\t},\n\t\t{\n\t\t\t[]Body{\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tHasBlocks: map[string]int{\n\t\t\t\t\t\t\"pizza\": 1,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodySchema{\n\t\t\t\tBlocks: []BlockHeaderSchema{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"pizza\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodyContent{\n\t\t\t\tAttributes: map[string]*Attribute{},\n\t\t\t\tBlocks: Blocks{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"pizza\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t0,\n\t\t},\n\t\t{\n\t\t\t[]Body{\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tHasBlocks: map[string]int{\n\t\t\t\t\t\t\"pizza\": 2,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodySchema{\n\t\t\t\tBlocks: []BlockHeaderSchema{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"pizza\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodyContent{\n\t\t\t\tAttributes: map[string]*Attribute{},\n\t\t\t\tBlocks: Blocks{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"pizza\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"pizza\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t0,\n\t\t},\n\t\t{\n\t\t\t[]Body{\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName: \"first\",\n\t\t\t\t\tHasBlocks: map[string]int{\n\t\t\t\t\t\t\"pizza\": 1,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName: \"second\",\n\t\t\t\t\tHasBlocks: map[string]int{\n\t\t\t\t\t\t\"pizza\": 1,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodySchema{\n\t\t\t\tBlocks: []BlockHeaderSchema{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"pizza\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodyContent{\n\t\t\t\tAttributes: map[string]*Attribute{},\n\t\t\t\tBlocks: Blocks{\n\t\t\t\t\t{\n\t\t\t\t\t\tType:     \"pizza\",\n\t\t\t\t\t\tDefRange: Range{Filename: \"first\"},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tType:     \"pizza\",\n\t\t\t\t\t\tDefRange: Range{Filename: \"second\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t0,\n\t\t},\n\t\t{\n\t\t\t[]Body{\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName: \"first\",\n\t\t\t\t},\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName: \"second\",\n\t\t\t\t\tHasBlocks: map[string]int{\n\t\t\t\t\t\t\"pizza\": 2,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodySchema{\n\t\t\t\tBlocks: []BlockHeaderSchema{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"pizza\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodyContent{\n\t\t\t\tAttributes: map[string]*Attribute{},\n\t\t\t\tBlocks: Blocks{\n\t\t\t\t\t{\n\t\t\t\t\t\tType:     \"pizza\",\n\t\t\t\t\t\tDefRange: Range{Filename: \"second\"},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tType:     \"pizza\",\n\t\t\t\t\t\tDefRange: Range{Filename: \"second\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t0,\n\t\t},\n\t\t{\n\t\t\t[]Body{\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName: \"first\",\n\t\t\t\t\tHasBlocks: map[string]int{\n\t\t\t\t\t\t\"pizza\": 2,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName: \"second\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodySchema{\n\t\t\t\tBlocks: []BlockHeaderSchema{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"pizza\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodyContent{\n\t\t\t\tAttributes: map[string]*Attribute{},\n\t\t\t\tBlocks: Blocks{\n\t\t\t\t\t{\n\t\t\t\t\t\tType:     \"pizza\",\n\t\t\t\t\t\tDefRange: Range{Filename: \"first\"},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tType:     \"pizza\",\n\t\t\t\t\t\tDefRange: Range{Filename: \"first\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t0,\n\t\t},\n\t\t{\n\t\t\t[]Body{\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName: \"first\",\n\t\t\t\t},\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName: \"second\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodySchema{\n\t\t\t\tBlocks: []BlockHeaderSchema{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"pizza\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodyContent{\n\t\t\t\tAttributes: map[string]*Attribute{},\n\t\t\t},\n\t\t\t0,\n\t\t},\n\t}\n\n\tfor i, test := range tests {\n\t\tt.Run(fmt.Sprintf(\"%02d\", i), func(t *testing.T) {\n\t\t\tmerged := MergeBodies(test.Bodies)\n\t\t\tgot, diags := merged.Content(test.Schema)\n\n\t\t\tif len(diags) != test.DiagCount {\n\t\t\t\tt.Errorf(\"Wrong number of diagnostics %d; want %d\", len(diags), test.DiagCount)\n\t\t\t\tfor _, diag := range diags {\n\t\t\t\t\tt.Logf(\" - %s\", diag)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif !reflect.DeepEqual(got, test.Want) {\n\t\t\t\tt.Errorf(\"wrong result\\ngot:  %s\\nwant: %s\", spew.Sdump(got), spew.Sdump(test.Want))\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestMergeBodiesPartialContent(t *testing.T) {\n\ttests := []struct {\n\t\tBodies      []Body\n\t\tSchema      *BodySchema\n\t\tWantContent *BodyContent\n\t\tWantRemain  Body\n\t\tDiagCount   int\n\t}{\n\t\t{\n\t\t\t[]Body{},\n\t\t\t&BodySchema{},\n\t\t\t&BodyContent{\n\t\t\t\tAttributes: map[string]*Attribute{},\n\t\t\t},\n\t\t\tmergedBodies{},\n\t\t\t0,\n\t\t},\n\t\t{\n\t\t\t[]Body{\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName:          \"first\",\n\t\t\t\t\tHasAttributes: []string{\"name\", \"age\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodySchema{\n\t\t\t\tAttributes: []AttributeSchema{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodyContent{\n\t\t\t\tAttributes: map[string]*Attribute{\n\t\t\t\t\t\"name\": &Attribute{\n\t\t\t\t\t\tName:      \"name\",\n\t\t\t\t\t\tNameRange: Range{Filename: \"first\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmergedBodies{\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName:          \"first\",\n\t\t\t\t\tHasAttributes: []string{\"age\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\t0,\n\t\t},\n\t\t{\n\t\t\t[]Body{\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName:          \"first\",\n\t\t\t\t\tHasAttributes: []string{\"name\", \"age\"},\n\t\t\t\t},\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName:          \"second\",\n\t\t\t\t\tHasAttributes: []string{\"name\", \"pizza\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodySchema{\n\t\t\t\tAttributes: []AttributeSchema{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodyContent{\n\t\t\t\tAttributes: map[string]*Attribute{\n\t\t\t\t\t\"name\": &Attribute{\n\t\t\t\t\t\tName:      \"name\",\n\t\t\t\t\t\tNameRange: Range{Filename: \"first\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmergedBodies{\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName:          \"first\",\n\t\t\t\t\tHasAttributes: []string{\"age\"},\n\t\t\t\t},\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName:          \"second\",\n\t\t\t\t\tHasAttributes: []string{\"pizza\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\t1,\n\t\t},\n\t\t{\n\t\t\t[]Body{\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName:          \"first\",\n\t\t\t\t\tHasAttributes: []string{\"name\", \"age\"},\n\t\t\t\t},\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName:          \"second\",\n\t\t\t\t\tHasAttributes: []string{\"pizza\", \"soda\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodySchema{\n\t\t\t\tAttributes: []AttributeSchema{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"name\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"soda\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodyContent{\n\t\t\t\tAttributes: map[string]*Attribute{\n\t\t\t\t\t\"name\": &Attribute{\n\t\t\t\t\t\tName:      \"name\",\n\t\t\t\t\t\tNameRange: Range{Filename: \"first\"},\n\t\t\t\t\t},\n\t\t\t\t\t\"soda\": &Attribute{\n\t\t\t\t\t\tName:      \"soda\",\n\t\t\t\t\t\tNameRange: Range{Filename: \"second\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmergedBodies{\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName:          \"first\",\n\t\t\t\t\tHasAttributes: []string{\"age\"},\n\t\t\t\t},\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName:          \"second\",\n\t\t\t\t\tHasAttributes: []string{\"pizza\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\t0,\n\t\t},\n\t\t{\n\t\t\t[]Body{\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName: \"first\",\n\t\t\t\t\tHasBlocks: map[string]int{\n\t\t\t\t\t\t\"pizza\": 1,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName: \"second\",\n\t\t\t\t\tHasBlocks: map[string]int{\n\t\t\t\t\t\t\"pizza\": 1,\n\t\t\t\t\t\t\"soda\":  2,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodySchema{\n\t\t\t\tBlocks: []BlockHeaderSchema{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"pizza\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t&BodyContent{\n\t\t\t\tAttributes: map[string]*Attribute{},\n\t\t\t\tBlocks: Blocks{\n\t\t\t\t\t{\n\t\t\t\t\t\tType:     \"pizza\",\n\t\t\t\t\t\tDefRange: Range{Filename: \"first\"},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tType:     \"pizza\",\n\t\t\t\t\t\tDefRange: Range{Filename: \"second\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmergedBodies{\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName:          \"first\",\n\t\t\t\t\tHasAttributes: []string{},\n\t\t\t\t\tHasBlocks:     map[string]int{},\n\t\t\t\t},\n\t\t\t\t&testMergedBodiesVictim{\n\t\t\t\t\tName:          \"second\",\n\t\t\t\t\tHasAttributes: []string{},\n\t\t\t\t\tHasBlocks: map[string]int{\n\t\t\t\t\t\t\"soda\": 2,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t0,\n\t\t},\n\t}\n\n\tfor i, test := range tests {\n\t\tt.Run(fmt.Sprintf(\"%02d\", i), func(t *testing.T) {\n\t\t\tmerged := MergeBodies(test.Bodies)\n\t\t\tgot, gotRemain, diags := merged.PartialContent(test.Schema)\n\n\t\t\tif len(diags) != test.DiagCount {\n\t\t\t\tt.Errorf(\"Wrong number of diagnostics %d; want %d\", len(diags), test.DiagCount)\n\t\t\t\tfor _, diag := range diags {\n\t\t\t\t\tt.Logf(\" - %s\", diag)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif !reflect.DeepEqual(got, test.WantContent) {\n\t\t\t\tt.Errorf(\"wrong content result\\ngot:  %s\\nwant: %s\", spew.Sdump(got), spew.Sdump(test.WantContent))\n\t\t\t}\n\n\t\t\tif !reflect.DeepEqual(gotRemain, test.WantRemain) {\n\t\t\t\tt.Errorf(\"wrong remaining result\\ngot:  %s\\nwant: %s\", spew.Sdump(gotRemain), spew.Sdump(test.WantRemain))\n\t\t\t}\n\t\t})\n\t}\n}\n\ntype testMergedBodiesVictim struct {\n\tName          string\n\tHasAttributes []string\n\tHasBlocks     map[string]int\n\tDiagCount     int\n}\n\nfunc (v *testMergedBodiesVictim) Content(schema *BodySchema) (*BodyContent, Diagnostics) {\n\tc, _, d := v.PartialContent(schema)\n\treturn c, d\n}\n\nfunc (v *testMergedBodiesVictim) PartialContent(schema *BodySchema) (*BodyContent, Body, Diagnostics) {\n\tremain := &testMergedBodiesVictim{\n\t\tName:          v.Name,\n\t\tHasAttributes: []string{},\n\t}\n\n\thasAttrs := map[string]struct{}{}\n\tfor _, n := range v.HasAttributes {\n\t\thasAttrs[n] = struct{}{}\n\n\t\tvar found bool\n\t\tfor _, attrS := range schema.Attributes {\n\t\t\tif n == attrS.Name {\n\t\t\t\tfound = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif !found {\n\t\t\tremain.HasAttributes = append(remain.HasAttributes, n)\n\t\t}\n\t}\n\n\tcontent := &BodyContent{\n\t\tAttributes: map[string]*Attribute{},\n\t}\n\n\trng := Range{\n\t\tFilename: v.Name,\n\t}\n\n\tfor _, attrS := range schema.Attributes {\n\t\t_, has := hasAttrs[attrS.Name]\n\t\tif has {\n\t\t\tcontent.Attributes[attrS.Name] = &Attribute{\n\t\t\t\tName:      attrS.Name,\n\t\t\t\tNameRange: rng,\n\t\t\t}\n\t\t}\n\t}\n\n\tif v.HasBlocks != nil {\n\t\tfor _, blockS := range schema.Blocks {\n\t\t\tnum := v.HasBlocks[blockS.Type]\n\t\t\tfor i := 0; i < num; i++ {\n\t\t\t\tcontent.Blocks = append(content.Blocks, &Block{\n\t\t\t\t\tType:     blockS.Type,\n\t\t\t\t\tDefRange: rng,\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\n\t\tremain.HasBlocks = map[string]int{}\n\t\tfor n := range v.HasBlocks {\n\t\t\tvar found bool\n\t\t\tfor _, blockS := range schema.Blocks {\n\t\t\t\tif blockS.Type == n {\n\t\t\t\t\tfound = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !found {\n\t\t\t\tremain.HasBlocks[n] = v.HasBlocks[n]\n\t\t\t}\n\t\t}\n\t}\n\n\tdiags := make(Diagnostics, v.DiagCount)\n\tfor i := range diags {\n\t\tdiags[i] = &Diagnostic{\n\t\t\tSeverity: DiagError,\n\t\t\tSummary:  fmt.Sprintf(\"Fake diagnostic %d\", i),\n\t\t\tDetail:   \"For testing only.\",\n\t\t\tContext:  &rng,\n\t\t}\n\t}\n\n\treturn content, remain, diags\n}\n\nfunc (v *testMergedBodiesVictim) JustAttributes() (Attributes, Diagnostics) {\n\tattrs := make(map[string]*Attribute)\n\n\trng := Range{\n\t\tFilename: v.Name,\n\t}\n\n\tfor _, name := range v.HasAttributes {\n\t\tattrs[name] = &Attribute{\n\t\t\tName:      name,\n\t\t\tNameRange: rng,\n\t\t}\n\t}\n\n\tdiags := make(Diagnostics, v.DiagCount)\n\tfor i := range diags {\n\t\tdiags[i] = &Diagnostic{\n\t\t\tSeverity: DiagError,\n\t\t\tSummary:  fmt.Sprintf(\"Fake diagnostic %d\", i),\n\t\t\tDetail:   \"For testing only.\",\n\t\t\tContext:  &rng,\n\t\t}\n\t}\n\n\treturn attrs, diags\n}\n\nfunc (v *testMergedBodiesVictim) MissingItemRange() Range {\n\treturn Range{\n\t\tFilename: v.Name,\n\t}\n}\n"
        },
        {
          "name": "ops.go",
          "type": "blob",
          "size": 13.908203125,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\nimport (\n\t\"fmt\"\n\t\"math/big\"\n\n\t\"github.com/zclconf/go-cty/cty\"\n\t\"github.com/zclconf/go-cty/cty/convert\"\n)\n\n// Index is a helper function that performs the same operation as the index\n// operator in the HCL expression language. That is, the result is the\n// same as it would be for collection[key] in a configuration expression.\n//\n// This is exported so that applications can perform indexing in a manner\n// consistent with how the language does it, including handling of null and\n// unknown values, etc.\n//\n// Diagnostics are produced if the given combination of values is not valid.\n// Therefore a pointer to a source range must be provided to use in diagnostics,\n// though nil can be provided if the calling application is going to\n// ignore the subject of the returned diagnostics anyway.\nfunc Index(collection, key cty.Value, srcRange *Range) (cty.Value, Diagnostics) {\n\tconst invalidIndex = \"Invalid index\"\n\n\tif collection.IsNull() {\n\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t{\n\t\t\t\tSeverity: DiagError,\n\t\t\t\tSummary:  \"Attempt to index null value\",\n\t\t\t\tDetail:   \"This value is null, so it does not have any indices.\",\n\t\t\t\tSubject:  srcRange,\n\t\t\t},\n\t\t}\n\t}\n\tif key.IsNull() {\n\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t{\n\t\t\t\tSeverity: DiagError,\n\t\t\t\tSummary:  invalidIndex,\n\t\t\t\tDetail:   \"Can't use a null value as an indexing key.\",\n\t\t\t\tSubject:  srcRange,\n\t\t\t},\n\t\t}\n\t}\n\tty := collection.Type()\n\tkty := key.Type()\n\tif kty == cty.DynamicPseudoType || ty == cty.DynamicPseudoType {\n\t\treturn cty.DynamicVal.WithSameMarks(collection), nil\n\t}\n\n\tswitch {\n\n\tcase ty.IsListType() || ty.IsTupleType() || ty.IsMapType():\n\t\tvar wantType cty.Type\n\t\tswitch {\n\t\tcase ty.IsListType() || ty.IsTupleType():\n\t\t\twantType = cty.Number\n\t\tcase ty.IsMapType():\n\t\t\twantType = cty.String\n\t\tdefault:\n\t\t\t// should never happen\n\t\t\tpanic(\"don't know what key type we want\")\n\t\t}\n\n\t\tkey, keyErr := convert.Convert(key, wantType)\n\t\tif keyErr != nil {\n\t\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t\t{\n\t\t\t\t\tSeverity: DiagError,\n\t\t\t\t\tSummary:  invalidIndex,\n\t\t\t\t\tDetail: fmt.Sprintf(\n\t\t\t\t\t\t\"The given key does not identify an element in this collection value: %s.\",\n\t\t\t\t\t\tkeyErr.Error(),\n\t\t\t\t\t),\n\t\t\t\t\tSubject: srcRange,\n\t\t\t\t},\n\t\t\t}\n\t\t}\n\n\t\t// Here we drop marks from HasIndex result, in order to allow basic\n\t\t// traversal of a marked list, tuple, or map in the same way we can\n\t\t// traverse a marked object\n\t\thas, _ := collection.HasIndex(key).Unmark()\n\t\tif !has.IsKnown() {\n\t\t\tif ty.IsTupleType() {\n\t\t\t\treturn cty.DynamicVal.WithSameMarks(collection), nil\n\t\t\t} else {\n\t\t\t\treturn cty.UnknownVal(ty.ElementType()).WithSameMarks(collection), nil\n\t\t\t}\n\t\t}\n\t\tif has.False() {\n\t\t\tif (ty.IsListType() || ty.IsTupleType()) && key.Type().Equals(cty.Number) {\n\t\t\t\tif key.IsKnown() && !key.IsNull() {\n\t\t\t\t\t// NOTE: we don't know what any marks might've represented\n\t\t\t\t\t// up at the calling application layer, so we must avoid\n\t\t\t\t\t// showing the literal number value in these error messages\n\t\t\t\t\t// in case the mark represents something important, such as\n\t\t\t\t\t// a value being \"sensitive\".\n\t\t\t\t\tkey, _ := key.Unmark()\n\t\t\t\t\tbf := key.AsBigFloat()\n\t\t\t\t\tif _, acc := bf.Int(nil); acc != big.Exact {\n\t\t\t\t\t\t// We have a more specialized error message for the\n\t\t\t\t\t\t// situation of using a fractional number to index into\n\t\t\t\t\t\t// a sequence, because that will tend to happen if the\n\t\t\t\t\t\t// user is trying to use division to calculate an index\n\t\t\t\t\t\t// and not realizing that HCL does float division\n\t\t\t\t\t\t// rather than integer division.\n\t\t\t\t\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tSeverity: DiagError,\n\t\t\t\t\t\t\t\tSummary:  invalidIndex,\n\t\t\t\t\t\t\t\tDetail:   \"The given key does not identify an element in this collection value: indexing a sequence requires a whole number, but the given index has a fractional part.\",\n\t\t\t\t\t\t\t\tSubject:  srcRange,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tif bf.Sign() < 0 {\n\t\t\t\t\t\t// Some other languages allow negative indices to\n\t\t\t\t\t\t// select \"backwards\" from the end of the sequence,\n\t\t\t\t\t\t// but HCL doesn't do that in order to give better\n\t\t\t\t\t\t// feedback if a dynamic index is calculated\n\t\t\t\t\t\t// incorrectly.\n\t\t\t\t\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tSeverity: DiagError,\n\t\t\t\t\t\t\t\tSummary:  invalidIndex,\n\t\t\t\t\t\t\t\tDetail:   \"The given key does not identify an element in this collection value: a negative number is not a valid index for a sequence.\",\n\t\t\t\t\t\t\t\tSubject:  srcRange,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif lenVal := collection.Length(); lenVal.IsKnown() && !lenVal.IsMarked() {\n\t\t\t\t\t\t// Length always returns a number, and we already\n\t\t\t\t\t\t// checked that it's a known number, so this is safe.\n\t\t\t\t\t\tlenBF := lenVal.AsBigFloat()\n\t\t\t\t\t\tvar result big.Float\n\t\t\t\t\t\tresult.Sub(bf, lenBF)\n\t\t\t\t\t\tif result.Sign() < 1 {\n\t\t\t\t\t\t\tif lenBF.Sign() == 0 {\n\t\t\t\t\t\t\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tSeverity: DiagError,\n\t\t\t\t\t\t\t\t\t\tSummary:  invalidIndex,\n\t\t\t\t\t\t\t\t\t\tDetail:   \"The given key does not identify an element in this collection value: the collection has no elements.\",\n\t\t\t\t\t\t\t\t\t\tSubject:  srcRange,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tSeverity: DiagError,\n\t\t\t\t\t\t\t\t\t\tSummary:  invalidIndex,\n\t\t\t\t\t\t\t\t\t\tDetail:   \"The given key does not identify an element in this collection value: the given index is greater than or equal to the length of the collection.\",\n\t\t\t\t\t\t\t\t\t\tSubject:  srcRange,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// If this is not one of the special situations we handled above\n\t\t\t// then we'll fall back on a very generic message.\n\t\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t\t{\n\t\t\t\t\tSeverity: DiagError,\n\t\t\t\t\tSummary:  invalidIndex,\n\t\t\t\t\tDetail:   \"The given key does not identify an element in this collection value.\",\n\t\t\t\t\tSubject:  srcRange,\n\t\t\t\t},\n\t\t\t}\n\t\t}\n\n\t\treturn collection.Index(key), nil\n\n\tcase ty.IsObjectType():\n\t\twasNumber := key.Type() == cty.Number\n\t\tkey, keyErr := convert.Convert(key, cty.String)\n\t\tif keyErr != nil {\n\t\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t\t{\n\t\t\t\t\tSeverity: DiagError,\n\t\t\t\t\tSummary:  invalidIndex,\n\t\t\t\t\tDetail: fmt.Sprintf(\n\t\t\t\t\t\t\"The given key does not identify an element in this collection value: %s.\",\n\t\t\t\t\t\tkeyErr.Error(),\n\t\t\t\t\t),\n\t\t\t\t\tSubject: srcRange,\n\t\t\t\t},\n\t\t\t}\n\t\t}\n\t\tif !collection.IsKnown() {\n\t\t\treturn cty.DynamicVal.WithSameMarks(collection), nil\n\t\t}\n\t\tif !key.IsKnown() {\n\t\t\treturn cty.DynamicVal.WithSameMarks(collection), nil\n\t\t}\n\n\t\tkey, _ = key.Unmark()\n\t\tattrName := key.AsString()\n\n\t\tif !ty.HasAttribute(attrName) {\n\t\t\tvar suggestion string\n\t\t\tif wasNumber {\n\t\t\t\t// We note this only as an addendum to an error we would've\n\t\t\t\t// already returned anyway, because it is valid (albeit weird)\n\t\t\t\t// to have an attribute whose name is just decimal digits\n\t\t\t\t// and then access that attribute using a number whose\n\t\t\t\t// decimal representation is the same digits.\n\t\t\t\tsuggestion = \" An object only supports looking up attributes by name, not by numeric index.\"\n\t\t\t}\n\t\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t\t{\n\t\t\t\t\tSeverity: DiagError,\n\t\t\t\t\tSummary:  invalidIndex,\n\t\t\t\t\tDetail:   fmt.Sprintf(\"The given key does not identify an element in this collection value.%s\", suggestion),\n\t\t\t\t\tSubject:  srcRange,\n\t\t\t\t},\n\t\t\t}\n\t\t}\n\n\t\treturn collection.GetAttr(attrName), nil\n\n\tcase ty.IsSetType():\n\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t{\n\t\t\t\tSeverity: DiagError,\n\t\t\t\tSummary:  invalidIndex,\n\t\t\t\tDetail:   \"Elements of a set are identified only by their value and don't have any separate index or key to select with, so it's only possible to perform operations across all elements of the set.\",\n\t\t\t\tSubject:  srcRange,\n\t\t\t},\n\t\t}\n\n\tdefault:\n\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t{\n\t\t\t\tSeverity: DiagError,\n\t\t\t\tSummary:  invalidIndex,\n\t\t\t\tDetail:   \"This value does not have any indices.\",\n\t\t\t\tSubject:  srcRange,\n\t\t\t},\n\t\t}\n\t}\n\n}\n\n// GetAttr is a helper function that performs the same operation as the\n// attribute access in the HCL expression language. That is, the result is the\n// same as it would be for obj.attr in a configuration expression.\n//\n// This is exported so that applications can access attributes in a manner\n// consistent with how the language does it, including handling of null and\n// unknown values, etc.\n//\n// Diagnostics are produced if the given combination of values is not valid.\n// Therefore a pointer to a source range must be provided to use in diagnostics,\n// though nil can be provided if the calling application is going to\n// ignore the subject of the returned diagnostics anyway.\nfunc GetAttr(obj cty.Value, attrName string, srcRange *Range) (cty.Value, Diagnostics) {\n\tif obj.IsNull() {\n\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t{\n\t\t\t\tSeverity: DiagError,\n\t\t\t\tSummary:  \"Attempt to get attribute from null value\",\n\t\t\t\tDetail:   \"This value is null, so it does not have any attributes.\",\n\t\t\t\tSubject:  srcRange,\n\t\t\t},\n\t\t}\n\t}\n\n\tconst unsupportedAttr = \"Unsupported attribute\"\n\n\tty := obj.Type()\n\tswitch {\n\tcase ty.IsObjectType():\n\t\tif !ty.HasAttribute(attrName) {\n\t\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t\t{\n\t\t\t\t\tSeverity: DiagError,\n\t\t\t\t\tSummary:  unsupportedAttr,\n\t\t\t\t\tDetail:   fmt.Sprintf(\"This object does not have an attribute named %q.\", attrName),\n\t\t\t\t\tSubject:  srcRange,\n\t\t\t\t},\n\t\t\t}\n\t\t}\n\n\t\tif !obj.IsKnown() {\n\t\t\treturn cty.UnknownVal(ty.AttributeType(attrName)).WithSameMarks(obj), nil\n\t\t}\n\n\t\treturn obj.GetAttr(attrName), nil\n\tcase ty.IsMapType():\n\t\tif !obj.IsKnown() {\n\t\t\treturn cty.UnknownVal(ty.ElementType()).WithSameMarks(obj), nil\n\t\t}\n\n\t\tidx := cty.StringVal(attrName)\n\n\t\t// Here we drop marks from HasIndex result, in order to allow basic\n\t\t// traversal of a marked map in the same way we can traverse a marked\n\t\t// object\n\t\thasIndex, _ := obj.HasIndex(idx).Unmark()\n\t\tif hasIndex.False() {\n\t\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t\t{\n\t\t\t\t\tSeverity: DiagError,\n\t\t\t\t\tSummary:  \"Missing map element\",\n\t\t\t\t\tDetail:   fmt.Sprintf(\"This map does not have an element with the key %q.\", attrName),\n\t\t\t\t\tSubject:  srcRange,\n\t\t\t\t},\n\t\t\t}\n\t\t}\n\n\t\treturn obj.Index(idx), nil\n\tcase ty == cty.DynamicPseudoType:\n\t\treturn cty.DynamicVal.WithSameMarks(obj), nil\n\tcase ty.IsListType() && ty.ElementType().IsObjectType():\n\t\t// It seems a common mistake to try to access attributes on a whole\n\t\t// list of objects rather than on a specific individual element, so\n\t\t// we have some extra hints for that case.\n\n\t\tswitch {\n\t\tcase ty.ElementType().HasAttribute(attrName):\n\t\t\t// This is a very strong indication that the user mistook the list\n\t\t\t// of objects for a single object, so we can be a little more\n\t\t\t// direct in our suggestion here.\n\t\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t\t{\n\t\t\t\t\tSeverity: DiagError,\n\t\t\t\t\tSummary:  unsupportedAttr,\n\t\t\t\t\tDetail:   fmt.Sprintf(\"Can't access attributes on a list of objects. Did you mean to access attribute %q for a specific element of the list, or across all elements of the list?\", attrName),\n\t\t\t\t\tSubject:  srcRange,\n\t\t\t\t},\n\t\t\t}\n\t\tdefault:\n\t\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t\t{\n\t\t\t\t\tSeverity: DiagError,\n\t\t\t\t\tSummary:  unsupportedAttr,\n\t\t\t\t\tDetail:   \"Can't access attributes on a list of objects. Did you mean to access an attribute for a specific element of the list, or across all elements of the list?\",\n\t\t\t\t\tSubject:  srcRange,\n\t\t\t\t},\n\t\t\t}\n\t\t}\n\n\tcase ty.IsSetType() && ty.ElementType().IsObjectType():\n\t\t// This is similar to the previous case, but we can't give such a\n\t\t// direct suggestion because there is no mechanism to select a single\n\t\t// item from a set.\n\t\t// We could potentially suggest using a for expression or splat\n\t\t// operator here, but we typically don't get into syntax specifics\n\t\t// in hcl.GetAttr suggestions because it's a general function used in\n\t\t// various other situations, such as in application-specific operations\n\t\t// that might have a more constraint set of alternative approaches.\n\n\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t{\n\t\t\t\tSeverity: DiagError,\n\t\t\t\tSummary:  unsupportedAttr,\n\t\t\t\tDetail:   \"Can't access attributes on a set of objects. Did you mean to access an attribute across all elements of the set?\",\n\t\t\t\tSubject:  srcRange,\n\t\t\t},\n\t\t}\n\n\tcase ty.IsPrimitiveType():\n\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t{\n\t\t\t\tSeverity: DiagError,\n\t\t\t\tSummary:  unsupportedAttr,\n\t\t\t\tDetail:   fmt.Sprintf(\"Can't access attributes on a primitive-typed value (%s).\", ty.FriendlyName()),\n\t\t\t\tSubject:  srcRange,\n\t\t\t},\n\t\t}\n\n\tdefault:\n\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t{\n\t\t\t\tSeverity: DiagError,\n\t\t\t\tSummary:  unsupportedAttr,\n\t\t\t\tDetail:   \"This value does not have any attributes.\",\n\t\t\t\tSubject:  srcRange,\n\t\t\t},\n\t\t}\n\t}\n\n}\n\n// ApplyPath is a helper function that applies a cty.Path to a value using the\n// indexing and attribute access operations from HCL.\n//\n// This is similar to calling the path's own Apply method, but ApplyPath uses\n// the more relaxed typing rules that apply to these operations in HCL, rather\n// than cty's relatively-strict rules. ApplyPath is implemented in terms of\n// Index and GetAttr, and so it has the same behavior for individual steps\n// but will stop and return any errors returned by intermediate steps.\n//\n// Diagnostics are produced if the given path cannot be applied to the given\n// value. Therefore a pointer to a source range must be provided to use in\n// diagnostics, though nil can be provided if the calling application is going\n// to ignore the subject of the returned diagnostics anyway.\nfunc ApplyPath(val cty.Value, path cty.Path, srcRange *Range) (cty.Value, Diagnostics) {\n\tvar diags Diagnostics\n\n\tfor _, step := range path {\n\t\tvar stepDiags Diagnostics\n\t\tswitch ts := step.(type) {\n\t\tcase cty.IndexStep:\n\t\t\tval, stepDiags = Index(val, ts.Key, srcRange)\n\t\tcase cty.GetAttrStep:\n\t\t\tval, stepDiags = GetAttr(val, ts.Name, srcRange)\n\t\tdefault:\n\t\t\t// Should never happen because the above are all of the step types.\n\t\t\tdiags = diags.Append(&Diagnostic{\n\t\t\t\tSeverity: DiagError,\n\t\t\t\tSummary:  \"Invalid path step\",\n\t\t\t\tDetail:   fmt.Sprintf(\"Go type %T is not a valid path step. This is a bug in this program.\", step),\n\t\t\t\tSubject:  srcRange,\n\t\t\t})\n\t\t\treturn cty.DynamicVal, diags\n\t\t}\n\n\t\tdiags = append(diags, stepDiags...)\n\t\tif stepDiags.HasErrors() {\n\t\t\treturn cty.DynamicVal, diags\n\t\t}\n\t}\n\n\treturn val, diags\n}\n"
        },
        {
          "name": "ops_test.go",
          "type": "blob",
          "size": 13.87109375,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\nimport (\n\t\"fmt\"\n\t\"testing\"\n\n\t\"github.com/zclconf/go-cty/cty\"\n)\n\nfunc TestApplyPath(t *testing.T) {\n\ttests := []struct {\n\t\tStart   cty.Value\n\t\tPath    cty.Path\n\t\tWant    cty.Value\n\t\tWantErr string\n\t}{\n\t\t{\n\t\t\tcty.StringVal(\"hello\"),\n\t\t\tnil,\n\t\t\tcty.StringVal(\"hello\"),\n\t\t\t``,\n\t\t},\n\t\t{\n\t\t\tcty.StringVal(\"hello\"),\n\t\t\t(cty.Path)(nil).Index(cty.StringVal(\"boop\")),\n\t\t\tcty.NilVal,\n\t\t\t`Invalid index: This value does not have any indices.`,\n\t\t},\n\t\t{\n\t\t\tcty.StringVal(\"hello\"),\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(0)),\n\t\t\tcty.NilVal,\n\t\t\t`Invalid index: This value does not have any indices.`,\n\t\t},\n\t\t{\n\t\t\tcty.ListVal([]cty.Value{\n\t\t\t\tcty.StringVal(\"hello\"),\n\t\t\t}),\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(0)),\n\t\t\tcty.StringVal(\"hello\"),\n\t\t\t``,\n\t\t},\n\t\t{\n\t\t\tcty.ListVal([]cty.Value{\n\t\t\t\tcty.StringVal(\"hello\"),\n\t\t\t}).Mark(\"x\"),\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(0)),\n\t\t\tcty.StringVal(\"hello\").Mark(\"x\"),\n\t\t\t``,\n\t\t},\n\t\t{\n\t\t\tcty.TupleVal([]cty.Value{\n\t\t\t\tcty.StringVal(\"hello\"),\n\t\t\t}),\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(0)),\n\t\t\tcty.StringVal(\"hello\"),\n\t\t\t``,\n\t\t},\n\t\t{\n\t\t\tcty.MapVal(map[string]cty.Value{\n\t\t\t\t\"a\": cty.StringVal(\"foo\").Mark(\"x\"),\n\t\t\t\t\"b\": cty.StringVal(\"bar\").Mark(\"x\"),\n\t\t\t}).Mark(\"x\"),\n\t\t\tcty.GetAttrPath(\"a\"),\n\t\t\tcty.StringVal(\"foo\").Mark(\"x\"),\n\t\t\t``,\n\t\t},\n\n\t\t{\n\t\t\tcty.ListValEmpty(cty.String),\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(0)),\n\t\t\tcty.NilVal,\n\t\t\t`Invalid index: The given key does not identify an element in this collection value: the collection has no elements.`,\n\t\t},\n\t\t{\n\t\t\tcty.ListVal([]cty.Value{\n\t\t\t\tcty.StringVal(\"hello\"),\n\t\t\t}),\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(1)),\n\t\t\tcty.NilVal,\n\t\t\t`Invalid index: The given key does not identify an element in this collection value: the given index is greater than or equal to the length of the collection.`,\n\t\t},\n\t\t{\n\t\t\tcty.ListVal([]cty.Value{\n\t\t\t\tcty.StringVal(\"hello\"),\n\t\t\t}).Mark(\"boop\"), // prevents us from making statements about the length of the list\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(1)),\n\t\t\tcty.NilVal,\n\t\t\t`Invalid index: The given key does not identify an element in this collection value.`,\n\t\t},\n\t\t{\n\t\t\tcty.ListVal([]cty.Value{\n\t\t\t\tcty.StringVal(\"hello\"),\n\t\t\t}),\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(-1)),\n\t\t\tcty.NilVal,\n\t\t\t`Invalid index: The given key does not identify an element in this collection value: a negative number is not a valid index for a sequence.`,\n\t\t},\n\t\t{\n\t\t\tcty.ListVal([]cty.Value{\n\t\t\t\tcty.StringVal(\"hello\"),\n\t\t\t}),\n\t\t\t(cty.Path)(nil).Index(cty.NumberFloatVal(0.5)),\n\t\t\tcty.NilVal,\n\t\t\t`Invalid index: The given key does not identify an element in this collection value: indexing a sequence requires a whole number, but the given index has a fractional part.`,\n\t\t},\n\t\t{\n\t\t\tcty.ListVal([]cty.Value{\n\t\t\t\tcty.StringVal(\"hello\"),\n\t\t\t}),\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(0)).GetAttr(\"foo\"),\n\t\t\tcty.NilVal,\n\t\t\t`Unsupported attribute: Can't access attributes on a primitive-typed value (string).`,\n\t\t},\n\t\t{\n\t\t\tcty.ListVal([]cty.Value{\n\t\t\t\tcty.EmptyObjectVal,\n\t\t\t}),\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(0)).GetAttr(\"foo\"),\n\t\t\tcty.NilVal,\n\t\t\t`Unsupported attribute: This object does not have an attribute named \"foo\".`,\n\t\t},\n\t\t{\n\t\t\tcty.ListVal([]cty.Value{\n\t\t\t\tcty.EmptyObjectVal,\n\t\t\t}),\n\t\t\t(cty.Path)(nil).GetAttr(\"foo\"),\n\t\t\tcty.NilVal,\n\t\t\t`Unsupported attribute: Can't access attributes on a list of objects. Did you mean to access an attribute for a specific element of the list, or across all elements of the list?`,\n\t\t},\n\t\t{\n\t\t\tcty.ListVal([]cty.Value{\n\t\t\t\tcty.ObjectVal(map[string]cty.Value{\n\t\t\t\t\t\"foo\": cty.True,\n\t\t\t\t}),\n\t\t\t}),\n\t\t\t(cty.Path)(nil).GetAttr(\"foo\"),\n\t\t\tcty.NilVal,\n\t\t\t`Unsupported attribute: Can't access attributes on a list of objects. Did you mean to access attribute \"foo\" for a specific element of the list, or across all elements of the list?`,\n\t\t},\n\n\t\t{\n\t\t\tcty.EmptyTupleVal,\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(0)),\n\t\t\tcty.NilVal,\n\t\t\t`Invalid index: The given key does not identify an element in this collection value: the collection has no elements.`,\n\t\t},\n\t\t{\n\t\t\tcty.TupleVal([]cty.Value{\n\t\t\t\tcty.StringVal(\"hello\"),\n\t\t\t}),\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(1)),\n\t\t\tcty.NilVal,\n\t\t\t`Invalid index: The given key does not identify an element in this collection value: the given index is greater than or equal to the length of the collection.`,\n\t\t},\n\t\t{\n\t\t\tcty.TupleVal([]cty.Value{\n\t\t\t\tcty.StringVal(\"hello\"),\n\t\t\t}).Mark(\"boop\"),\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(1)),\n\t\t\tcty.NilVal,\n\t\t\t`Invalid index: The given key does not identify an element in this collection value.`,\n\t\t},\n\t\t{\n\t\t\tcty.TupleVal([]cty.Value{\n\t\t\t\tcty.StringVal(\"hello\"),\n\t\t\t}),\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(-1)),\n\t\t\tcty.NilVal,\n\t\t\t`Invalid index: The given key does not identify an element in this collection value: a negative number is not a valid index for a sequence.`,\n\t\t},\n\t\t{\n\t\t\tcty.TupleVal([]cty.Value{\n\t\t\t\tcty.StringVal(\"hello\"),\n\t\t\t}),\n\t\t\t(cty.Path)(nil).Index(cty.NumberFloatVal(0.5)),\n\t\t\tcty.NilVal,\n\t\t\t`Invalid index: The given key does not identify an element in this collection value: indexing a sequence requires a whole number, but the given index has a fractional part.`,\n\t\t},\n\t\t{\n\t\t\tcty.TupleVal([]cty.Value{\n\t\t\t\tcty.StringVal(\"hello\"),\n\t\t\t}),\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(0)).GetAttr(\"foo\"),\n\t\t\tcty.NilVal,\n\t\t\t`Unsupported attribute: Can't access attributes on a primitive-typed value (string).`,\n\t\t},\n\t\t{\n\t\t\tcty.TupleVal([]cty.Value{\n\t\t\t\tcty.EmptyObjectVal,\n\t\t\t}),\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(0)).GetAttr(\"foo\"),\n\t\t\tcty.NilVal,\n\t\t\t`Unsupported attribute: This object does not have an attribute named \"foo\".`,\n\t\t},\n\t\t{\n\t\t\tcty.TupleVal([]cty.Value{\n\t\t\t\tcty.EmptyObjectVal,\n\t\t\t}),\n\t\t\t(cty.Path)(nil).GetAttr(\"foo\"),\n\t\t\tcty.NilVal,\n\t\t\t`Unsupported attribute: This value does not have any attributes.`,\n\t\t},\n\t\t{\n\t\t\tcty.TupleVal([]cty.Value{\n\t\t\t\tcty.ObjectVal(map[string]cty.Value{\n\t\t\t\t\t\"foo\": cty.True,\n\t\t\t\t}),\n\t\t\t}),\n\t\t\t(cty.Path)(nil).GetAttr(\"foo\"),\n\t\t\tcty.NilVal,\n\t\t\t`Unsupported attribute: This value does not have any attributes.`,\n\t\t},\n\n\t\t{\n\t\t\tcty.SetVal([]cty.Value{\n\t\t\t\tcty.StringVal(\"hello\"),\n\t\t\t}),\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(1)),\n\t\t\tcty.NilVal,\n\t\t\t`Invalid index: Elements of a set are identified only by their value and don't have any separate index or key to select with, so it's only possible to perform operations across all elements of the set.`,\n\t\t},\n\t\t{\n\t\t\tcty.SetVal([]cty.Value{\n\t\t\t\tcty.EmptyObjectVal,\n\t\t\t}),\n\t\t\t(cty.Path)(nil).GetAttr(\"foo\"),\n\t\t\tcty.NilVal,\n\t\t\t`Unsupported attribute: Can't access attributes on a set of objects. Did you mean to access an attribute across all elements of the set?`,\n\t\t},\n\t\t{\n\t\t\tcty.NullVal(cty.List(cty.String)),\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(0)),\n\t\t\tcty.NilVal,\n\t\t\t`Attempt to index null value: This value is null, so it does not have any indices.`,\n\t\t},\n\t\t{\n\t\t\tcty.NullVal(cty.Map(cty.String)),\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(0)),\n\t\t\tcty.NilVal,\n\t\t\t`Attempt to index null value: This value is null, so it does not have any indices.`,\n\t\t},\n\t\t{\n\t\t\tcty.NullVal(cty.EmptyObject),\n\t\t\t(cty.Path)(nil).GetAttr(\"foo\"),\n\t\t\tcty.NilVal,\n\t\t\t`Attempt to get attribute from null value: This value is null, so it does not have any attributes.`,\n\t\t},\n\n\t\t// Marks should be retained during index and getattr ops, even when\n\t\t// types and values are unknown. This reflects the same behavior when\n\t\t// using cty to directly call GetAttr and Index methods.\n\t\t{\n\t\t\tcty.DynamicVal.Mark(\"marked\"),\n\t\t\t(cty.Path)(nil).GetAttr(\"foo\"),\n\t\t\tcty.DynamicVal.Mark(\"marked\"),\n\t\t\t``,\n\t\t},\n\t\t{\n\t\t\tcty.ObjectVal(map[string]cty.Value{\n\t\t\t\t\"foo\": cty.StringVal(\"should be marked\"),\n\t\t\t}).Mark(\"marked\"),\n\t\t\t(cty.Path)(nil).GetAttr(\"foo\"),\n\t\t\tcty.StringVal(\"should be marked\").Mark(\"marked\"),\n\t\t\t``,\n\t\t},\n\t\t{\n\t\t\tcty.UnknownVal(cty.Object(map[string]cty.Type{\n\t\t\t\t\"foo\": cty.DynamicPseudoType,\n\t\t\t})).Mark(\"marked\"),\n\t\t\t(cty.Path)(nil).GetAttr(\"foo\"),\n\t\t\tcty.DynamicVal.Mark(\"marked\"),\n\t\t\t``,\n\t\t},\n\t\t{\n\t\t\tcty.DynamicVal.Mark(\"marked\"),\n\t\t\t(cty.Path)(nil).Index(cty.StringVal(\"foo\")),\n\t\t\tcty.DynamicVal.Mark(\"marked\"),\n\t\t\t``,\n\t\t},\n\t\t{\n\t\t\tcty.ObjectVal(map[string]cty.Value{\n\t\t\t\t\"foo\": cty.StringVal(\"should be marked\"),\n\t\t\t}).Mark(\"marked\"),\n\t\t\t(cty.Path)(nil).Index(cty.StringVal(\"foo\")),\n\t\t\tcty.StringVal(\"should be marked\").Mark(\"marked\"),\n\t\t\t``,\n\t\t},\n\t\t{\n\t\t\tcty.UnknownVal(cty.Object(map[string]cty.Type{\n\t\t\t\t\"foo\": cty.DynamicPseudoType,\n\t\t\t})).Mark(\"marked\"),\n\t\t\t(cty.Path)(nil).Index(cty.StringVal(\"foo\")),\n\t\t\tcty.DynamicVal.Mark(\"marked\"),\n\t\t\t``,\n\t\t},\n\t\t{\n\t\t\tcty.DynamicVal.Mark(\"marked\"),\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(0)),\n\t\t\tcty.DynamicVal.Mark(\"marked\"),\n\t\t\t``,\n\t\t},\n\t\t{\n\t\t\tcty.ListVal([]cty.Value{cty.StringVal(\"should be marked\")}).Mark(\"marked\"),\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(0)),\n\t\t\tcty.StringVal(\"should be marked\").Mark(\"marked\"),\n\t\t\t``,\n\t\t},\n\t\t{\n\t\t\tcty.UnknownVal(cty.List(cty.String)).Mark(\"marked\"),\n\t\t\t(cty.Path)(nil).Index(cty.NumberIntVal(0)),\n\t\t\tcty.UnknownVal(cty.String).Mark(\"marked\"),\n\t\t\t``,\n\t\t},\n\n\t\t{\n\t\t\tcty.DynamicVal.Mark(\"marked\"),\n\t\t\t(cty.Path)(nil).Index(cty.UnknownVal(cty.String)),\n\t\t\tcty.DynamicVal.Mark(\"marked\"),\n\t\t\t``,\n\t\t},\n\t\t{\n\t\t\tcty.ObjectVal(map[string]cty.Value{\n\t\t\t\t\"foo\": cty.StringVal(\"should be marked\"),\n\t\t\t}).Mark(\"marked\"),\n\t\t\t(cty.Path)(nil).Index(cty.UnknownVal(cty.String)),\n\t\t\tcty.DynamicVal.Mark(\"marked\"),\n\t\t\t``,\n\t\t},\n\t\t{\n\t\t\tcty.UnknownVal(cty.Object(map[string]cty.Type{\n\t\t\t\t\"foo\": cty.DynamicPseudoType,\n\t\t\t})).Mark(\"marked\"),\n\t\t\t(cty.Path)(nil).Index(cty.UnknownVal(cty.String)),\n\t\t\tcty.DynamicVal.Mark(\"marked\"),\n\t\t\t``,\n\t\t},\n\t\t{\n\t\t\tcty.DynamicVal.Mark(\"marked\"),\n\t\t\t(cty.Path)(nil).Index(cty.UnknownVal(cty.Number)),\n\t\t\tcty.DynamicVal.Mark(\"marked\"),\n\t\t\t``,\n\t\t},\n\t\t{\n\t\t\tcty.ListVal([]cty.Value{cty.StringVal(\"should be marked\")}).Mark(\"marked\"),\n\t\t\t(cty.Path)(nil).Index(cty.UnknownVal(cty.Number)),\n\t\t\tcty.UnknownVal(cty.String).Mark(\"marked\"),\n\t\t\t``,\n\t\t},\n\t\t{\n\t\t\tcty.UnknownVal(cty.List(cty.String)).Mark(\"marked\"),\n\t\t\t(cty.Path)(nil).Index(cty.UnknownVal(cty.Number)),\n\t\t\tcty.UnknownVal(cty.String).Mark(\"marked\"),\n\t\t\t``,\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tt.Run(fmt.Sprintf(\"%#v %#v\", test.Start, test.Path), func(t *testing.T) {\n\t\t\tgot, diags := ApplyPath(test.Start, test.Path, nil)\n\t\t\tt.Logf(\"testing ApplyPath\\nstart: %#v\\npath:  %#v\", test.Start, test.Path)\n\n\t\t\tfor _, diag := range diags {\n\t\t\t\tt.Log(diag.Error())\n\t\t\t}\n\n\t\t\tif test.WantErr != \"\" {\n\t\t\t\tif !diags.HasErrors() {\n\t\t\t\t\tt.Fatalf(\"succeeded, but want error\\nwant error: %s\", test.WantErr)\n\t\t\t\t}\n\t\t\t\tif len(diags) != 1 {\n\t\t\t\t\tt.Fatalf(\"wrong number of diagnostics %d; want 1\", len(diags))\n\t\t\t\t}\n\n\t\t\t\tif gotErrStr := diags[0].Summary + \": \" + diags[0].Detail; gotErrStr != test.WantErr {\n\t\t\t\t\tt.Fatalf(\"wrong error\\ngot error:  %s\\nwant error: %s\", gotErrStr, test.WantErr)\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tif diags.HasErrors() {\n\t\t\t\tt.Fatalf(\"failed, but want success\\ngot diagnostics:\\n%s\", diags.Error())\n\t\t\t}\n\t\t\tif !test.Want.RawEquals(got) {\n\t\t\t\tt.Fatalf(\"wrong result\\ngot:  %#v\\nwant: %#v\", got, test.Want)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestIndex(t *testing.T) {\n\ttests := map[string]struct {\n\t\tcoll cty.Value\n\t\tkey  cty.Value\n\t\twant cty.Value\n\t\terr  string\n\t}{\n\t\t\"marked key to maked value\": {\n\t\t\tcoll: cty.ListVal([]cty.Value{\n\t\t\t\tcty.StringVal(\"a\"),\n\t\t\t}),\n\t\t\tkey:  cty.NumberIntVal(0).Mark(\"marked\"),\n\t\t\twant: cty.StringVal(\"a\").Mark(\"marked\"),\n\t\t},\n\t\t\"missing list key\": {\n\t\t\tcoll: cty.ListVal([]cty.Value{\n\t\t\t\tcty.StringVal(\"a\"),\n\t\t\t}),\n\t\t\tkey:  cty.NumberIntVal(1).Mark(\"marked\"),\n\t\t\twant: cty.DynamicVal,\n\t\t\terr:  \"Invalid index\",\n\t\t},\n\t\t\"null marked key\": {\n\t\t\tcoll: cty.ListVal([]cty.Value{\n\t\t\t\tcty.StringVal(\"a\"),\n\t\t\t}),\n\t\t\tkey:  cty.NullVal(cty.Number).Mark(\"marked\"),\n\t\t\twant: cty.DynamicVal,\n\t\t\terr:  \"Invalid index\",\n\t\t},\n\t\t\"dynamic key\": {\n\t\t\tcoll: cty.ListVal([]cty.Value{\n\t\t\t\tcty.StringVal(\"a\"),\n\t\t\t}),\n\t\t\tkey:  cty.DynamicVal,\n\t\t\twant: cty.DynamicVal,\n\t\t},\n\t\t\"invalid marked key type\": {\n\t\t\tcoll: cty.ListVal([]cty.Value{\n\t\t\t\tcty.StringVal(\"a\"),\n\t\t\t}),\n\t\t\tkey:  cty.StringVal(\"foo\").Mark(\"marked\"),\n\t\t\twant: cty.DynamicVal,\n\t\t\terr:  \"Invalid index\",\n\t\t},\n\t\t\"marked map key\": {\n\t\t\tcoll: cty.MapVal(map[string]cty.Value{\n\t\t\t\t\"foo\": cty.StringVal(\"a\"),\n\t\t\t}),\n\t\t\tkey:  cty.StringVal(\"foo\").Mark(\"marked\"),\n\t\t\twant: cty.StringVal(\"a\").Mark(\"marked\"),\n\t\t},\n\t\t\"missing marked map key\": {\n\t\t\tcoll: cty.MapVal(map[string]cty.Value{\n\t\t\t\t\"foo\": cty.StringVal(\"a\"),\n\t\t\t}),\n\t\t\tkey:  cty.StringVal(\"bar\").Mark(\"mark\"),\n\t\t\twant: cty.DynamicVal,\n\t\t\terr:  \"Invalid index\",\n\t\t},\n\t\t\"marked object key\": {\n\t\t\tcoll: cty.ObjectVal(map[string]cty.Value{\n\t\t\t\t\"foo\": cty.StringVal(\"a\"),\n\t\t\t}),\n\t\t\tkey: cty.StringVal(\"foo\").Mark(\"marked\"),\n\t\t\t// an object attribute is fetched by string index, and the marks\n\t\t\t// are not maintained\n\t\t\twant: cty.StringVal(\"a\"),\n\t\t},\n\t\t\"invalid marked object key type\": {\n\t\t\tcoll: cty.ObjectVal(map[string]cty.Value{\n\t\t\t\t\"foo\": cty.StringVal(\"a\"),\n\t\t\t}),\n\t\t\tkey:  cty.ListVal([]cty.Value{cty.NullVal(cty.String)}).Mark(\"marked\"),\n\t\t\twant: cty.DynamicVal,\n\t\t\terr:  \"Invalid index\",\n\t\t},\n\t\t\"invalid marked object key\": {\n\t\t\tcoll: cty.ObjectVal(map[string]cty.Value{\n\t\t\t\t\"foo\": cty.StringVal(\"a\"),\n\t\t\t}),\n\t\t\tkey:  cty.NumberIntVal(0).Mark(\"marked\"),\n\t\t\twant: cty.DynamicVal,\n\t\t\terr:  \"Invalid index\",\n\t\t},\n\t}\n\n\tfor name, tc := range tests {\n\t\tt.Run(name, func(t *testing.T) {\n\t\t\tt.Logf(\"testing Index\\ncollection: %#v\\nkey:  %#v\", tc.coll, tc.key)\n\n\t\t\tgot, diags := Index(tc.coll, tc.key, nil)\n\n\t\t\tfor _, diag := range diags {\n\t\t\t\tt.Logf(diag.Error())\n\t\t\t}\n\n\t\t\tif tc.err != \"\" {\n\t\t\t\tif !diags.HasErrors() {\n\t\t\t\t\tt.Fatalf(\"succeeded, but want error\\nwant error: %s\", tc.err)\n\t\t\t\t}\n\t\t\t\tif len(diags) != 1 {\n\t\t\t\t\tt.Fatalf(\"wrong number of diagnostics %d; want 1\", len(diags))\n\t\t\t\t}\n\n\t\t\t\tif gotErrStr := diags[0].Summary; gotErrStr != tc.err {\n\t\t\t\t\tt.Fatalf(\"wrong error\\ngot error:  %s\\nwant error: %s\", gotErrStr, tc.err)\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tif diags.HasErrors() {\n\t\t\t\tt.Fatalf(\"failed, but want success\\ngot diagnostics:\\n%s\", diags.Error())\n\t\t\t}\n\t\t\tif !tc.want.RawEquals(got) {\n\t\t\t\tt.Fatalf(\"wrong result\\ngot:  %#v\\nwant: %#v\", got, tc.want)\n\t\t\t}\n\t\t})\n\t}\n}\n"
        },
        {
          "name": "pos.go",
          "type": "blob",
          "size": 7.951171875,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\nimport \"fmt\"\n\n// Pos represents a single position in a source file, by addressing the\n// start byte of a unicode character encoded in UTF-8.\n//\n// Pos is generally used only in the context of a Range, which then defines\n// which source file the position is within.\ntype Pos struct {\n\t// Line is the source code line where this position points. Lines are\n\t// counted starting at 1 and incremented for each newline character\n\t// encountered.\n\tLine int\n\n\t// Column is the source code column where this position points, in\n\t// unicode characters, with counting starting at 1.\n\t//\n\t// Column counts characters as they appear visually, so for example a\n\t// latin letter with a combining diacritic mark counts as one character.\n\t// This is intended for rendering visual markers against source code in\n\t// contexts where these diacritics would be rendered in a single character\n\t// cell. Technically speaking, Column is counting grapheme clusters as\n\t// used in unicode normalization.\n\tColumn int\n\n\t// Byte is the byte offset into the file where the indicated character\n\t// begins. This is a zero-based offset to the first byte of the first\n\t// UTF-8 codepoint sequence in the character, and thus gives a position\n\t// that can be resolved _without_ awareness of Unicode characters.\n\tByte int\n}\n\n// InitialPos is a suitable position to use to mark the start of a file.\nvar InitialPos = Pos{Byte: 0, Line: 1, Column: 1}\n\n// Range represents a span of characters between two positions in a source\n// file.\n//\n// This struct is usually used by value in types that represent AST nodes,\n// but by pointer in types that refer to the positions of other objects,\n// such as in diagnostics.\ntype Range struct {\n\t// Filename is the name of the file into which this range's positions\n\t// point.\n\tFilename string\n\n\t// Start and End represent the bounds of this range. Start is inclusive\n\t// and End is exclusive.\n\tStart, End Pos\n}\n\n// RangeBetween returns a new range that spans from the beginning of the\n// start range to the end of the end range.\n//\n// The result is meaningless if the two ranges do not belong to the same\n// source file or if the end range appears before the start range.\nfunc RangeBetween(start, end Range) Range {\n\treturn Range{\n\t\tFilename: start.Filename,\n\t\tStart:    start.Start,\n\t\tEnd:      end.End,\n\t}\n}\n\n// RangeOver returns a new range that covers both of the given ranges and\n// possibly additional content between them if the two ranges do not overlap.\n//\n// If either range is empty then it is ignored. The result is empty if both\n// given ranges are empty.\n//\n// The result is meaningless if the two ranges to not belong to the same\n// source file.\nfunc RangeOver(a, b Range) Range {\n\tif a.Empty() {\n\t\treturn b\n\t}\n\tif b.Empty() {\n\t\treturn a\n\t}\n\n\tvar start, end Pos\n\tif a.Start.Byte < b.Start.Byte {\n\t\tstart = a.Start\n\t} else {\n\t\tstart = b.Start\n\t}\n\tif a.End.Byte > b.End.Byte {\n\t\tend = a.End\n\t} else {\n\t\tend = b.End\n\t}\n\treturn Range{\n\t\tFilename: a.Filename,\n\t\tStart:    start,\n\t\tEnd:      end,\n\t}\n}\n\n// ContainsPos returns true if and only if the given position is contained within\n// the receiving range.\n//\n// In the unlikely case that the line/column information disagree with the byte\n// offset information in the given position or receiving range, the byte\n// offsets are given priority.\nfunc (r Range) ContainsPos(pos Pos) bool {\n\treturn r.ContainsOffset(pos.Byte)\n}\n\n// ContainsOffset returns true if and only if the given byte offset is within\n// the receiving Range.\nfunc (r Range) ContainsOffset(offset int) bool {\n\treturn offset >= r.Start.Byte && offset < r.End.Byte\n}\n\n// Ptr returns a pointer to a copy of the receiver. This is a convenience when\n// ranges in places where pointers are required, such as in Diagnostic, but\n// the range in question is returned from a method. Go would otherwise not\n// allow one to take the address of a function call.\nfunc (r Range) Ptr() *Range {\n\treturn &r\n}\n\n// String returns a compact string representation of the receiver.\n// Callers should generally prefer to present a range more visually,\n// e.g. via markers directly on the relevant portion of source code.\nfunc (r Range) String() string {\n\tif r.Start.Line == r.End.Line {\n\t\treturn fmt.Sprintf(\n\t\t\t\"%s:%d,%d-%d\",\n\t\t\tr.Filename,\n\t\t\tr.Start.Line, r.Start.Column,\n\t\t\tr.End.Column,\n\t\t)\n\t} else {\n\t\treturn fmt.Sprintf(\n\t\t\t\"%s:%d,%d-%d,%d\",\n\t\t\tr.Filename,\n\t\t\tr.Start.Line, r.Start.Column,\n\t\t\tr.End.Line, r.End.Column,\n\t\t)\n\t}\n}\n\nfunc (r Range) Empty() bool {\n\treturn r.Start.Byte == r.End.Byte\n}\n\n// CanSliceBytes returns true if SliceBytes could return an accurate\n// sub-slice of the given slice.\n//\n// This effectively tests whether the start and end offsets of the range\n// are within the bounds of the slice, and thus whether SliceBytes can be\n// trusted to produce an accurate start and end position within that slice.\nfunc (r Range) CanSliceBytes(b []byte) bool {\n\tswitch {\n\tcase r.Start.Byte < 0 || r.Start.Byte > len(b):\n\t\treturn false\n\tcase r.End.Byte < 0 || r.End.Byte > len(b):\n\t\treturn false\n\tcase r.End.Byte < r.Start.Byte:\n\t\treturn false\n\tdefault:\n\t\treturn true\n\t}\n}\n\n// SliceBytes returns a sub-slice of the given slice that is covered by the\n// receiving range, assuming that the given slice is the source code of the\n// file indicated by r.Filename.\n//\n// If the receiver refers to any byte offsets that are outside of the slice\n// then the result is constrained to the overlapping portion only, to avoid\n// a panic. Use CanSliceBytes to determine if the result is guaranteed to\n// be an accurate span of the requested range.\nfunc (r Range) SliceBytes(b []byte) []byte {\n\tstart := r.Start.Byte\n\tend := r.End.Byte\n\tif start < 0 {\n\t\tstart = 0\n\t} else if start > len(b) {\n\t\tstart = len(b)\n\t}\n\tif end < 0 {\n\t\tend = 0\n\t} else if end > len(b) {\n\t\tend = len(b)\n\t}\n\tif end < start {\n\t\tend = start\n\t}\n\treturn b[start:end]\n}\n\n// Overlaps returns true if the receiver and the other given range share any\n// characters in common.\nfunc (r Range) Overlaps(other Range) bool {\n\tswitch {\n\tcase r.Filename != other.Filename:\n\t\t// If the ranges are in different files then they can't possibly overlap\n\t\treturn false\n\tcase r.Empty() || other.Empty():\n\t\t// Empty ranges can never overlap\n\t\treturn false\n\tcase r.ContainsOffset(other.Start.Byte) || r.ContainsOffset(other.End.Byte):\n\t\treturn true\n\tcase other.ContainsOffset(r.Start.Byte) || other.ContainsOffset(r.End.Byte):\n\t\treturn true\n\tdefault:\n\t\treturn false\n\t}\n}\n\n// Overlap finds a range that is either identical to or a sub-range of both\n// the receiver and the other given range. It returns an empty range\n// within the receiver if there is no overlap between the two ranges.\n//\n// A non-empty result is either identical to or a subset of the receiver.\nfunc (r Range) Overlap(other Range) Range {\n\tif !r.Overlaps(other) {\n\t\t// Start == End indicates an empty range\n\t\treturn Range{\n\t\t\tFilename: r.Filename,\n\t\t\tStart:    r.Start,\n\t\t\tEnd:      r.Start,\n\t\t}\n\t}\n\n\tvar start, end Pos\n\tif r.Start.Byte > other.Start.Byte {\n\t\tstart = r.Start\n\t} else {\n\t\tstart = other.Start\n\t}\n\tif r.End.Byte < other.End.Byte {\n\t\tend = r.End\n\t} else {\n\t\tend = other.End\n\t}\n\n\treturn Range{\n\t\tFilename: r.Filename,\n\t\tStart:    start,\n\t\tEnd:      end,\n\t}\n}\n\n// PartitionAround finds the portion of the given range that overlaps with\n// the reciever and returns three ranges: the portion of the reciever that\n// precedes the overlap, the overlap itself, and then the portion of the\n// reciever that comes after the overlap.\n//\n// If the two ranges do not overlap then all three returned ranges are empty.\n//\n// If the given range aligns with or extends beyond either extent of the\n// reciever then the corresponding outer range will be empty.\nfunc (r Range) PartitionAround(other Range) (before, overlap, after Range) {\n\toverlap = r.Overlap(other)\n\tif overlap.Empty() {\n\t\treturn overlap, overlap, overlap\n\t}\n\n\tbefore = Range{\n\t\tFilename: r.Filename,\n\t\tStart:    r.Start,\n\t\tEnd:      overlap.Start,\n\t}\n\tafter = Range{\n\t\tFilename: r.Filename,\n\t\tStart:    overlap.End,\n\t\tEnd:      r.End,\n\t}\n\n\treturn before, overlap, after\n}\n"
        },
        {
          "name": "pos_scanner.go",
          "type": "blob",
          "size": 4.712890625,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\n\t\"github.com/apparentlymart/go-textseg/v15/textseg\"\n)\n\n// RangeScanner is a helper that will scan over a buffer using a bufio.SplitFunc\n// and visit a source range for each token matched.\n//\n// For example, this can be used with bufio.ScanLines to find the source range\n// for each line in the file, skipping over the actual newline characters, which\n// may be useful when printing source code snippets as part of diagnostic\n// messages.\n//\n// The line and column information in the returned ranges is produced by\n// counting newline characters and grapheme clusters respectively, which\n// mimics the behavior we expect from a parser when producing ranges.\ntype RangeScanner struct {\n\tfilename string\n\tb        []byte\n\tcb       bufio.SplitFunc\n\n\tpos Pos    // position of next byte to process in b\n\tcur Range  // latest range\n\ttok []byte // slice of b that is covered by cur\n\terr error  // error from last scan, if any\n}\n\n// NewRangeScanner creates a new RangeScanner for the given buffer, producing\n// ranges for the given filename.\n//\n// Since ranges have grapheme-cluster granularity rather than byte granularity,\n// the scanner will produce incorrect results if the given SplitFunc creates\n// tokens between grapheme cluster boundaries. In particular, it is incorrect\n// to use RangeScanner with bufio.ScanRunes because it will produce tokens\n// around individual UTF-8 sequences, which will split any multi-sequence\n// grapheme clusters.\nfunc NewRangeScanner(b []byte, filename string, cb bufio.SplitFunc) *RangeScanner {\n\treturn NewRangeScannerFragment(b, filename, InitialPos, cb)\n}\n\n// NewRangeScannerFragment is like NewRangeScanner but the ranges it produces\n// will be offset by the given starting position, which is appropriate for\n// sub-slices of a file, whereas NewRangeScanner assumes it is scanning an\n// entire file.\nfunc NewRangeScannerFragment(b []byte, filename string, start Pos, cb bufio.SplitFunc) *RangeScanner {\n\treturn &RangeScanner{\n\t\tfilename: filename,\n\t\tb:        b,\n\t\tcb:       cb,\n\t\tpos:      start,\n\t}\n}\n\nfunc (sc *RangeScanner) Scan() bool {\n\tif sc.pos.Byte >= len(sc.b) || sc.err != nil {\n\t\t// All done\n\t\treturn false\n\t}\n\n\t// Since we're operating on an in-memory buffer, we always pass the whole\n\t// remainder of the buffer to our SplitFunc and set isEOF to let it know\n\t// that it has the whole thing.\n\tadvance, token, err := sc.cb(sc.b[sc.pos.Byte:], true)\n\n\t// Since we are setting isEOF to true this should never happen, but\n\t// if it does we will just abort and assume the SplitFunc is misbehaving.\n\tif advance == 0 && token == nil && err == nil {\n\t\treturn false\n\t}\n\n\tif err != nil {\n\t\tsc.err = err\n\t\tsc.cur = Range{\n\t\t\tFilename: sc.filename,\n\t\t\tStart:    sc.pos,\n\t\t\tEnd:      sc.pos,\n\t\t}\n\t\tsc.tok = nil\n\t\treturn false\n\t}\n\n\tsc.tok = token\n\tstart := sc.pos\n\tend := sc.pos\n\tnew := sc.pos\n\n\t// adv is similar to token but it also includes any subsequent characters\n\t// we're being asked to skip over by the SplitFunc.\n\t// adv is a slice covering any additional bytes we are skipping over, based\n\t// on what the SplitFunc told us to do with advance.\n\tadv := sc.b[sc.pos.Byte : sc.pos.Byte+advance]\n\n\t// We now need to scan over our token to count the grapheme clusters\n\t// so we can correctly advance Column, and count the newlines so we\n\t// can correctly advance Line.\n\tadvR := bytes.NewReader(adv)\n\tgsc := bufio.NewScanner(advR)\n\tadvanced := 0\n\tgsc.Split(textseg.ScanGraphemeClusters)\n\tfor gsc.Scan() {\n\t\tgr := gsc.Bytes()\n\t\tnew.Byte += len(gr)\n\t\tnew.Column++\n\n\t\t// We rely here on the fact that \\r\\n is considered a grapheme cluster\n\t\t// and so we don't need to worry about miscounting additional lines\n\t\t// on files with Windows-style line endings.\n\t\tif len(gr) != 0 && (gr[0] == '\\r' || gr[0] == '\\n') {\n\t\t\tnew.Column = 1\n\t\t\tnew.Line++\n\t\t}\n\n\t\tif advanced < len(token) {\n\t\t\t// If we've not yet found the end of our token then we'll\n\t\t\t// also push our \"end\" marker along.\n\t\t\t// (if advance > len(token) then we'll stop moving \"end\" early\n\t\t\t// so that the caller only sees the range covered by token.)\n\t\t\tend = new\n\t\t}\n\t\tadvanced += len(gr)\n\t}\n\n\tsc.cur = Range{\n\t\tFilename: sc.filename,\n\t\tStart:    start,\n\t\tEnd:      end,\n\t}\n\tsc.pos = new\n\treturn true\n}\n\n// Range returns a range that covers the latest token obtained after a call\n// to Scan returns true.\nfunc (sc *RangeScanner) Range() Range {\n\treturn sc.cur\n}\n\n// Bytes returns the slice of the input buffer that is covered by the range\n// that would be returned by Range.\nfunc (sc *RangeScanner) Bytes() []byte {\n\treturn sc.tok\n}\n\n// Err can be called after Scan returns false to determine if the latest read\n// resulted in an error, and obtain that error if so.\nfunc (sc *RangeScanner) Err() error {\n\treturn sc.err\n}\n"
        },
        {
          "name": "pos_scanner_test.go",
          "type": "blob",
          "size": 4.0712890625,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\nimport (\n\t\"bufio\"\n\t\"reflect\"\n\t\"testing\"\n\n\t\"github.com/davecgh/go-spew/spew\"\n)\n\nfunc TestPosScanner(t *testing.T) {\n\ttests := map[string]struct {\n\t\tInput    string\n\t\tWant     []Range\n\t\tWantToks [][]byte\n\t}{\n\t\t\"empty\": {\n\t\t\t\"\",\n\t\t\t[]Range{},\n\t\t\t[][]byte{},\n\t\t},\n\t\t\"single line\": {\n\t\t\t\"hello\",\n\t\t\t[]Range{\n\t\t\t\t{\n\t\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t\t},\n\t\t\t},\n\t\t\t[][]byte{\n\t\t\t\t[]byte(\"hello\"),\n\t\t\t},\n\t\t},\n\t\t\"single line with trailing UNIX newline\": {\n\t\t\t\"hello\\n\",\n\t\t\t[]Range{\n\t\t\t\t{\n\t\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t\t},\n\t\t\t},\n\t\t\t[][]byte{\n\t\t\t\t[]byte(\"hello\"),\n\t\t\t},\n\t\t},\n\t\t\"single line with trailing Windows newline\": {\n\t\t\t\"hello\\r\\n\",\n\t\t\t[]Range{\n\t\t\t\t{\n\t\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t\t},\n\t\t\t},\n\t\t\t[][]byte{\n\t\t\t\t[]byte(\"hello\"),\n\t\t\t},\n\t\t},\n\t\t\"two lines with UNIX newline\": {\n\t\t\t\"hello\\nworld\",\n\t\t\t[]Range{\n\t\t\t\t{\n\t\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tStart: Pos{Byte: 6, Line: 2, Column: 1},\n\t\t\t\t\tEnd:   Pos{Byte: 11, Line: 2, Column: 6},\n\t\t\t\t},\n\t\t\t},\n\t\t\t[][]byte{\n\t\t\t\t[]byte(\"hello\"),\n\t\t\t\t[]byte(\"world\"),\n\t\t\t},\n\t\t},\n\t\t\"two lines with Windows newline\": {\n\t\t\t\"hello\\r\\nworld\",\n\t\t\t[]Range{\n\t\t\t\t{\n\t\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tStart: Pos{Byte: 7, Line: 2, Column: 1},\n\t\t\t\t\tEnd:   Pos{Byte: 12, Line: 2, Column: 6},\n\t\t\t\t},\n\t\t\t},\n\t\t\t[][]byte{\n\t\t\t\t[]byte(\"hello\"),\n\t\t\t\t[]byte(\"world\"),\n\t\t\t},\n\t\t},\n\t\t\"blank line with UNIX newlines\": {\n\t\t\t\"hello\\n\\nworld\",\n\t\t\t[]Range{\n\t\t\t\t{\n\t\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tStart: Pos{Byte: 6, Line: 2, Column: 1},\n\t\t\t\t\tEnd:   Pos{Byte: 6, Line: 2, Column: 1},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tStart: Pos{Byte: 7, Line: 3, Column: 1},\n\t\t\t\t\tEnd:   Pos{Byte: 12, Line: 3, Column: 6},\n\t\t\t\t},\n\t\t\t},\n\t\t\t[][]byte{\n\t\t\t\t[]byte(\"hello\"),\n\t\t\t\t[]byte(\"\"),\n\t\t\t\t[]byte(\"world\"),\n\t\t\t},\n\t\t},\n\t\t\"blank line with Windows newlines\": {\n\t\t\t\"hello\\r\\n\\r\\nworld\",\n\t\t\t[]Range{\n\t\t\t\t{\n\t\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tStart: Pos{Byte: 7, Line: 2, Column: 1},\n\t\t\t\t\tEnd:   Pos{Byte: 7, Line: 2, Column: 1},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tStart: Pos{Byte: 9, Line: 3, Column: 1},\n\t\t\t\t\tEnd:   Pos{Byte: 14, Line: 3, Column: 6},\n\t\t\t\t},\n\t\t\t},\n\t\t\t[][]byte{\n\t\t\t\t[]byte(\"hello\"),\n\t\t\t\t[]byte(\"\"),\n\t\t\t\t[]byte(\"world\"),\n\t\t\t},\n\t\t},\n\t\t\"two lines with combiner and UNIX newline\": {\n\t\t\t\"foo \\U0001f469\\U0001f3ff bar\\nbaz\",\n\t\t\t[]Range{\n\t\t\t\t{\n\t\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\t\tEnd:   Pos{Byte: 16, Line: 1, Column: 10},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tStart: Pos{Byte: 17, Line: 2, Column: 1},\n\t\t\t\t\tEnd:   Pos{Byte: 20, Line: 2, Column: 4},\n\t\t\t\t},\n\t\t\t},\n\t\t\t[][]byte{\n\t\t\t\t[]byte(\"foo \\U0001f469\\U0001f3ff bar\"),\n\t\t\t\t[]byte(\"baz\"),\n\t\t\t},\n\t\t},\n\t\t\"two lines with combiner and Windows newline\": {\n\t\t\t\"foo \\U0001f469\\U0001f3ff bar\\r\\nbaz\",\n\t\t\t[]Range{\n\t\t\t\t{\n\t\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\t\tEnd:   Pos{Byte: 16, Line: 1, Column: 10},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tStart: Pos{Byte: 18, Line: 2, Column: 1},\n\t\t\t\t\tEnd:   Pos{Byte: 21, Line: 2, Column: 4},\n\t\t\t\t},\n\t\t\t},\n\t\t\t[][]byte{\n\t\t\t\t[]byte(\"foo \\U0001f469\\U0001f3ff bar\"),\n\t\t\t\t[]byte(\"baz\"),\n\t\t\t},\n\t\t},\n\t}\n\n\tfor name, test := range tests {\n\t\tt.Run(name, func(t *testing.T) {\n\t\t\tsrc := []byte(test.Input)\n\t\t\tsc := NewRangeScanner(src, \"\", bufio.ScanLines)\n\t\t\tgot := make([]Range, 0)\n\t\t\tgotToks := make([][]byte, 0)\n\t\t\tfor sc.Scan() {\n\t\t\t\tgot = append(got, sc.Range())\n\t\t\t\tgotToks = append(gotToks, sc.Bytes())\n\t\t\t}\n\t\t\tif sc.Err() != nil {\n\t\t\t\tt.Fatalf(\"unexpected error: %s\", sc.Err())\n\t\t\t}\n\t\t\tif !reflect.DeepEqual(got, test.Want) {\n\t\t\t\tt.Errorf(\"incorrect ranges\\ngot: %swant: %s\", spew.Sdump(got), spew.Sdump(test.Want))\n\t\t\t}\n\t\t\tif !reflect.DeepEqual(gotToks, test.WantToks) {\n\t\t\t\tt.Errorf(\"incorrect tokens\\ngot: %swant: %s\", spew.Sdump(gotToks), spew.Sdump(test.WantToks))\n\t\t\t}\n\t\t})\n\t}\n}\n"
        },
        {
          "name": "pos_test.go",
          "type": "blob",
          "size": 11.880859375,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"reflect\"\n\t\"testing\"\n)\n\nfunc TestRangeOver(t *testing.T) {\n\ttests := []struct {\n\t\tA    Range\n\t\tB    Range\n\t\tWant Range\n\t}{\n\t\t{\n\t\t\tRange{ //   ##\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tRange{ // ####\n\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ // #####\n\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tRange{ //   ####\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 6, Line: 1, Column: 7},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //  #####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 6, Line: 1, Column: 7},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //   ##\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tRange{ //  ###\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tRange{ //   ###\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tRange{ // ##\n\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\tEnd:   Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t},\n\t\t\tRange{ //     ##\n\t\t\t\tStart: Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t\tEnd:   Pos{Byte: 6, Line: 1, Column: 7},\n\t\t\t},\n\t\t\tRange{ // ######\n\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\tEnd:   Pos{Byte: 6, Line: 1, Column: 7},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tRange{ //     ##\n\t\t\t\tStart: Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t\tEnd:   Pos{Byte: 6, Line: 1, Column: 7},\n\t\t\t},\n\t\t\tRange{ // ##\n\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\tEnd:   Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t},\n\t\t\tRange{ // ######\n\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\tEnd:   Pos{Byte: 6, Line: 1, Column: 7},\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tt.Run(fmt.Sprintf(\"%s<=>%s\", test.A, test.B), func(t *testing.T) {\n\t\t\tgot := RangeOver(test.A, test.B)\n\t\t\tif !reflect.DeepEqual(got, test.Want) {\n\t\t\t\tt.Errorf(\n\t\t\t\t\t\"wrong result\\nA   : %-10s %s\\nB   : %-10s %s\\ngot : %-10s %s\\nwant: %-10s %s\",\n\t\t\t\t\tvisRangeOffsets(test.A), test.A,\n\t\t\t\t\tvisRangeOffsets(test.B), test.B,\n\t\t\t\t\tvisRangeOffsets(got), got,\n\t\t\t\t\tvisRangeOffsets(test.Want), test.Want,\n\t\t\t\t)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestPosOverlap(t *testing.T) {\n\ttests := []struct {\n\t\tA    Range\n\t\tB    Range\n\t\tWant Range\n\t}{\n\t\t{\n\t\t\tRange{ //   ##\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //   ##\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tRange{ // ####\n\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //  ###\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tRange{ //   ####\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 6, Line: 1, Column: 7},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //   ###\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //   ##\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t\tRange{ //   ##\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tRange{ //  ###\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //  ###\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tRange{ //   ###\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //   ###\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tRange{ // ##\n\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\tEnd:   Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t},\n\t\t\tRange{ //     ##\n\t\t\t\tStart: Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t\tEnd:   Pos{Byte: 6, Line: 1, Column: 7},\n\t\t\t},\n\t\t\tRange{ // (no overlap)\n\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\tEnd:   Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tRange{ //     ##\n\t\t\t\tStart: Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t\tEnd:   Pos{Byte: 6, Line: 1, Column: 7},\n\t\t\t},\n\t\t\tRange{ // ##\n\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\tEnd:   Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t},\n\t\t\tRange{ // (no overlap)\n\t\t\t\tStart: Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tt.Run(fmt.Sprintf(\"%s<=>%s\", test.A, test.B), func(t *testing.T) {\n\t\t\tgot := test.A.Overlap(test.B)\n\t\t\tif !reflect.DeepEqual(got, test.Want) {\n\t\t\t\tt.Errorf(\n\t\t\t\t\t\"wrong result\\nA   : %-10s %s\\nB   : %-10s %s\\ngot : %-10s %s\\nwant: %-10s %s\",\n\t\t\t\t\tvisRangeOffsets(test.A), test.A,\n\t\t\t\t\tvisRangeOffsets(test.B), test.B,\n\t\t\t\t\tvisRangeOffsets(got), got,\n\t\t\t\t\tvisRangeOffsets(test.Want), test.Want,\n\t\t\t\t)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestRangePartitionAround(t *testing.T) {\n\ttests := []struct {\n\t\tOuter       Range\n\t\tInner       Range\n\t\tWantBefore  Range\n\t\tWantOverlap Range\n\t\tWantAfter   Range\n\t}{\n\t\t{\n\t\t\tRange{ //   ##\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ // (empty)\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t},\n\t\t\tRange{ //   ##\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t\tRange{ // (empty)\n\t\t\t\tStart: Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tRange{ // ####\n\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ // #\n\t\t\t\tStart: Pos{Byte: 0, Line: 1, Column: 1},\n\t\t\t\tEnd:   Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t},\n\t\t\tRange{ //  ###\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t\tRange{ // (empty)\n\t\t\t\tStart: Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tRange{ //   ####\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //  (empty)\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t},\n\t\t\tRange{ //   ###\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //      #\n\t\t\t\tStart: Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tRange{ //  ####\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t\tRange{ //   ##\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t\tRange{ //  #\n\t\t\t\tStart: Pos{Byte: 1, Line: 1, Column: 2},\n\t\t\t\tEnd:   Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t},\n\t\t\tRange{ //   ##\n\t\t\t\tStart: Pos{Byte: 2, Line: 1, Column: 3},\n\t\t\t\tEnd:   Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t},\n\t\t\tRange{ //     #\n\t\t\t\tStart: Pos{Byte: 4, Line: 1, Column: 5},\n\t\t\t\tEnd:   Pos{Byte: 5, Line: 1, Column: 6},\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tt.Run(fmt.Sprintf(\"%s around %s\", test.Outer, test.Inner), func(t *testing.T) {\n\t\t\tgotBefore, gotOverlap, gotAfter := test.Outer.PartitionAround(test.Inner)\n\t\t\tif !reflect.DeepEqual(gotBefore, test.WantBefore) {\n\t\t\t\tt.Errorf(\n\t\t\t\t\t\"wrong before\\nA   : %-10s %s\\nB   : %-10s %s\\ngot : %-10s %s\\nwant: %-10s %s\",\n\t\t\t\t\tvisRangeOffsets(test.Outer), test.Outer,\n\t\t\t\t\tvisRangeOffsets(test.Inner), test.Inner,\n\t\t\t\t\tvisRangeOffsets(gotBefore), gotBefore,\n\t\t\t\t\tvisRangeOffsets(test.WantBefore), test.WantBefore,\n\t\t\t\t)\n\t\t\t}\n\t\t\tif !reflect.DeepEqual(gotOverlap, test.WantOverlap) {\n\t\t\t\tt.Errorf(\n\t\t\t\t\t\"wrong overlap\\nA   : %-10s %s\\nB   : %-10s %s\\ngot : %-10s %s\\nwant: %-10s %s\",\n\t\t\t\t\tvisRangeOffsets(test.Outer), test.Outer,\n\t\t\t\t\tvisRangeOffsets(test.Inner), test.Inner,\n\t\t\t\t\tvisRangeOffsets(gotOverlap), gotOverlap,\n\t\t\t\t\tvisRangeOffsets(test.WantOverlap), test.WantOverlap,\n\t\t\t\t)\n\t\t\t}\n\t\t\tif !reflect.DeepEqual(gotAfter, test.WantAfter) {\n\t\t\t\tt.Errorf(\n\t\t\t\t\t\"wrong after\\nA   : %-10s %s\\nB   : %-10s %s\\ngot : %-10s %s\\nwant: %-10s %s\",\n\t\t\t\t\tvisRangeOffsets(test.Outer), test.Outer,\n\t\t\t\t\tvisRangeOffsets(test.Inner), test.Inner,\n\t\t\t\t\tvisRangeOffsets(gotAfter), gotAfter,\n\t\t\t\t\tvisRangeOffsets(test.WantAfter), test.WantAfter,\n\t\t\t\t)\n\t\t\t}\n\t\t})\n\t}\n}\n\n// visRangeOffsets is a helper that produces a visual representation of the\n// start and end byte offsets of the given range, which can then be stacked\n// with the same for other ranges to more easily see how the ranges relate\n// to one another.\nfunc visRangeOffsets(rng Range) string {\n\tvar buf bytes.Buffer\n\tif rng.End.Byte < rng.Start.Byte {\n\t\t// Should never happen, but we'll visualize it anyway so we can\n\t\t// more easily debug failing tests.\n\t\tfor i := 0; i < rng.End.Byte; i++ {\n\t\t\tbuf.WriteByte(' ')\n\t\t}\n\t\tfor i := rng.End.Byte; i < rng.Start.Byte; i++ {\n\t\t\tbuf.WriteByte('!')\n\t\t}\n\t\treturn buf.String()\n\t}\n\n\tfor i := 0; i < rng.Start.Byte; i++ {\n\t\tbuf.WriteByte(' ')\n\t}\n\tfor i := rng.Start.Byte; i < rng.End.Byte; i++ {\n\t\tbuf.WriteByte('#')\n\t}\n\treturn buf.String()\n}\n"
        },
        {
          "name": "schema.go",
          "type": "blob",
          "size": 0.59375,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\n// BlockHeaderSchema represents the shape of a block header, and is\n// used for matching blocks within bodies.\ntype BlockHeaderSchema struct {\n\tType       string\n\tLabelNames []string\n}\n\n// AttributeSchema represents the requirements for an attribute, and is used\n// for matching attributes within bodies.\ntype AttributeSchema struct {\n\tName     string\n\tRequired bool\n}\n\n// BodySchema represents the desired shallow structure of a body.\ntype BodySchema struct {\n\tAttributes []AttributeSchema\n\tBlocks     []BlockHeaderSchema\n}\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "spec.md",
          "type": "blob",
          "size": 31.8125,
          "content": "# HCL Syntax-Agnostic Information Model\n\nThis is the specification for the general information model (abstract types and\nsemantics) for hcl. HCL is a system for defining configuration languages for\napplications. The HCL information model is designed to support multiple\nconcrete syntaxes for configuration, each with a mapping to the model defined\nin this specification.\n\nThe two primary syntaxes intended for use in conjunction with this model are\n[the HCL native syntax](./hclsyntax/spec.md) and [the JSON syntax](./json/spec.md).\nIn principle other syntaxes are possible as long as either their language model\nis sufficiently rich to express the concepts described in this specification\nor the language targets a well-defined subset of the specification.\n\n## Structural Elements\n\nThe primary structural element is the _body_, which is a container representing\na set of zero or more _attributes_ and a set of zero or more _blocks_.\n\nA _configuration file_ is the top-level object, and will usually be produced\nby reading a file from disk and parsing it as a particular syntax. A\nconfiguration file has its own _body_, representing the top-level attributes\nand blocks.\n\nAn _attribute_ is a name and value pair associated with a body. Attribute names\nare unique within a given body. Attribute values are provided as _expressions_,\nwhich are discussed in detail in a later section.\n\nA _block_ is a nested structure that has a _type name_, zero or more string\n_labels_ (e.g. identifiers), and a nested body.\n\nTogether the structural elements create a hierarchical data structure, with\nattributes intended to represent the direct properties of a particular object\nin the calling application, and blocks intended to represent child objects\nof a particular object.\n\n## Body Content\n\nTo support the expression of the HCL concepts in languages whose information\nmodel is a subset of HCL's, such as JSON, a _body_ is an opaque container\nwhose content can only be accessed by providing information on the expected\nstructure of the content.\n\nThe specification for each syntax must describe how its physical constructs\nare mapped on to body content given a schema. For syntaxes that have\nfirst-class syntax distinguishing attributes and bodies this can be relatively\nstraightforward, while more detailed mapping rules may be required in syntaxes\nwhere the representation of attributes vs. blocks is ambiguous.\n\n### Schema-driven Processing\n\nSchema-driven processing is the primary way to access body content.\nA _body schema_ is a description of what is expected within a particular body,\nwhich can then be used to extract the _body content_, which then provides\naccess to the specific attributes and blocks requested.\n\nA _body schema_ consists of a list of _attribute schemata_ and\n_block header schemata_:\n\n- An _attribute schema_ provides the name of an attribute and whether its\n  presence is required.\n\n- A _block header schema_ provides a block type name and the semantic names\n  assigned to each of the labels of that block type, if any.\n\nWithin a schema, it is an error to request the same attribute name twice or\nto request a block type whose name is also an attribute name. While this can\nin principle be supported in some syntaxes, in other syntaxes the attribute\nand block namespaces are combined and so an attribute cannot coexist with\na block whose type name is identical to the attribute name.\n\nThe result of applying a body schema to a body is _body content_, which\nconsists of an _attribute map_ and a _block sequence_:\n\n- The _attribute map_ is a map data structure whose keys are attribute names\n  and whose values are _expressions_ that represent the corresponding attribute\n  values.\n\n- The _block sequence_ is an ordered sequence of blocks, with each specifying\n  a block _type name_, the sequence of _labels_ specified for the block,\n  and the body object (not body _content_) representing the block's own body.\n\nAfter obtaining _body content_, the calling application may continue processing\nby evaluating attribute expressions and/or recursively applying further\nschema-driven processing to the child block bodies.\n\n**Note:** The _body schema_ is intentionally minimal, to reduce the set of\nmapping rules that must be defined for each syntax. Higher-level utility\nlibraries may be provided to assist in the construction of a schema and\nperform additional processing, such as automatically evaluating attribute\nexpressions and assigning their result values into a data structure, or\nrecursively applying a schema to child blocks. Such utilities are not part of\nthis core specification and will vary depending on the capabilities and idiom\nof the implementation language.\n\n### _Dynamic Attributes_ Processing\n\nThe _schema-driven_ processing model is useful when the expected structure\nof a body is known by the calling application. Some blocks are\ninstead more free-form, such as a user-provided set of arbitrary key/value\npairs.\n\nThe alternative _dynamic attributes_ processing mode allows for this more\nad-hoc approach. Processing in this mode behaves as if a schema had been\nconstructed without any _block header schemata_ and with an attribute\nschema for each distinct key provided within the physical representation\nof the body.\n\nThe means by which _distinct keys_ are identified is dependent on the\nphysical syntax; this processing mode assumes that the syntax has a way\nto enumerate keys provided by the author and identify expressions that\ncorrespond with those keys, but does not define the means by which this is\ndone.\n\nThe result of _dynamic attributes_ processing is an _attribute map_ as\ndefined in the previous section. No _block sequence_ is produced in this\nprocessing mode.\n\n### Partial Processing of Body Content\n\nUnder _schema-driven processing_, by default the given schema is assumed\nto be exhaustive, such that any attribute or block not matched by schema\nelements is considered an error. This allows feedback about unsupported\nattributes and blocks (such as typos) to be provided.\n\nAn alternative is _partial processing_, where any additional elements within\nthe body are not considered an error.\n\nUnder partial processing, the result is both body content as described\nabove _and_ a new body that represents any body elements that remain after\nthe schema has been processed.\n\nSpecifically:\n\n- Any attribute whose name is specified in the schema is returned in body\n  content and elided from the new body.\n\n- Any block whose type is specified in the schema is returned in body content\n  and elided from the new body.\n\n- Any attribute or block _not_ meeting the above conditions is placed into\n  the new body, unmodified.\n\nThe new body can then be recursively processed using any of the body\nprocessing models. This facility allows different subsets of body content\nto be processed by different parts of the calling application.\n\nProcessing a body in two steps — first partial processing of a source body,\nthen exhaustive processing of the returned body — is equivalent to single-step\nprocessing with a schema that is the union of the schemata used\nacross the two steps.\n\n## Expressions\n\nAttribute values are represented by _expressions_. Depending on the concrete\nsyntax in use, an expression may just be a literal value or it may describe\na computation in terms of literal values, variables, and functions.\n\nEach syntax defines its own representation of expressions. For syntaxes based\nin languages that do not have any non-literal expression syntax, it is\nrecommended to embed the template language from\n[the native syntax](./hclsyntax/spec.md) e.g. as a post-processing step on\nstring literals.\n\n### Expression Evaluation\n\nIn order to obtain a concrete value, each expression must be _evaluated_.\nEvaluation is performed in terms of an evaluation context, which\nconsists of the following:\n\n- An _evaluation mode_, which is defined below.\n- A _variable scope_, which provides a set of named variables for use in\n  expressions.\n- A _function table_, which provides a set of named functions for use in\n  expressions.\n\nThe _evaluation mode_ allows for two different interpretations of an\nexpression:\n\n- In _literal-only mode_, variables and functions are not available and it\n  is assumed that the calling application's intent is to treat the attribute\n  value as a literal.\n\n- In _full expression mode_, variables and functions are defined and it is\n  assumed that the calling application wishes to provide a full expression\n  language for definition of the attribute value.\n\nThe actual behavior of these two modes depends on the syntax in use. For\nlanguages with first-class expression syntax, these two modes may be considered\nequivalent, with _literal-only mode_ simply not defining any variables or\nfunctions. For languages that embed arbitrary expressions via string templates,\n_literal-only mode_ may disable such processing, allowing literal strings to\npass through without interpretation as templates.\n\nSince literal-only mode does not support variables and functions, it is an\nerror for the calling application to enable this mode and yet provide a\nvariable scope and/or function table.\n\n## Values and Value Types\n\nThe result of expression evaluation is a _value_. Each value has a _type_,\nwhich is dynamically determined during evaluation. The _variable scope_ in\nthe evaluation context is a map from variable name to value, using the same\ndefinition of value.\n\nThe type system for HCL values is intended to be of a level abstraction\nsuitable for configuration of various applications. A well-defined,\nimplementation-language-agnostic type system is defined to allow for\nconsistent processing of configuration across many implementation languages.\nConcrete implementations may provide additional functionality to lower\nHCL values and types to corresponding native language types, which may then\nimpose additional constraints on the values outside of the scope of this\nspecification.\n\nTwo values are _equal_ if and only if they have identical types and their\nvalues are equal according to the rules of their shared type.\n\n### Primitive Types\n\nThe primitive types are _string_, _bool_, and _number_.\n\nA _string_ is a sequence of unicode characters. Two strings are equal if\nNFC normalization ([UAX#15](http://unicode.org/reports/tr15/)\nof each string produces two identical sequences of characters.\nNFC normalization ensures that, for example, a precomposed combination of a\nlatin letter and a diacritic compares equal with the letter followed by\na combining diacritic.\n\nThe _bool_ type has only two non-null values: _true_ and _false_. Two bool\nvalues are equal if and only if they are either both true or both false.\n\nA _number_ is an arbitrary-precision floating point value. An implementation\n_must_ make the full-precision values available to the calling application\nfor interpretation into any suitable number representation. An implementation\nmay in practice implement numbers with limited precision so long as the\nfollowing constraints are met:\n\n- Integers are represented with at least 256 bits.\n- Non-integer numbers are represented as floating point values with a\n  mantissa of at least 256 bits and a signed binary exponent of at least\n  16 bits.\n- An error is produced if an integer value given in source cannot be\n  represented precisely.\n- An error is produced if a non-integer value cannot be represented due to\n  overflow.\n- A non-integer number is rounded to the nearest possible value when a\n  value is of too high a precision to be represented.\n\nThe _number_ type also requires representation of both positive and negative\ninfinity. A \"not a number\" (NaN) value is _not_ provided nor used.\n\nTwo number values are equal if they are numerically equal to the precision\nassociated with the number. Positive infinity and negative infinity are\nequal to themselves but not to each other. Positive infinity is greater than\nany other number value, and negative infinity is less than any other number\nvalue.\n\nSome syntaxes may be unable to represent numeric literals of arbitrary\nprecision. This must be defined in the syntax specification as part of its\ndescription of mapping numeric literals to HCL values.\n\n### Structural Types\n\n_Structural types_ are types that are constructed by combining other types.\nEach distinct combination of other types is itself a distinct type. There\nare two structural type _kinds_:\n\n- _Object types_ are constructed of a set of named attributes, each of which\n  has a type. Attribute names are always strings. (_Object_ attributes are a\n  distinct idea from _body_ attributes, though calling applications\n  may choose to blur the distinction by use of common naming schemes.)\n- _Tuple types_ are constructed of a sequence of elements, each of which\n  has a type.\n\nValues of structural types are compared for equality in terms of their\nattributes or elements. A structural type value is equal to another if and\nonly if all of the corresponding attributes or elements are equal.\n\nTwo structural types are identical if they are of the same kind and\nhave attributes or elements with identical types.\n\n### Collection Types\n\n_Collection types_ are types that combine together an arbitrary number of\nvalues of some other single type. There are three collection type _kinds_:\n\n- _List types_ represent ordered sequences of values of their element type.\n- _Map types_ represent values of their element type accessed via string keys.\n- _Set types_ represent unordered sets of distinct values of their element type.\n\nFor each of these kinds and each distinct element type there is a distinct\ncollection type. For example, \"list of string\" is a distinct type from\n\"set of string\", and \"list of number\" is a distinct type from \"list of string\".\n\nValues of collection types are compared for equality in terms of their\nelements. A collection type value is equal to another if and only if both\nhave the same number of elements and their corresponding elements are equal.\n\nTwo collection types are identical if they are of the same kind and have\nthe same element type.\n\n### Null values\n\nEach type has a null value. The null value of a type represents the absence\nof a value, but with type information retained to allow for type checking.\n\nNull values are used primarily to represent the conditional absence of a\nbody attribute. In a syntax with a conditional operator, one of the result\nvalues of that conditional may be null to indicate that the attribute should be\nconsidered not present in that case.\n\nCalling applications _should_ consider an attribute with a null value as\nequivalent to the value not being present at all.\n\nA null value of a particular type is equal to itself.\n\n### Unknown Values and the Dynamic Pseudo-type\n\nAn _unknown value_ is a placeholder for a value that is not yet known.\nOperations on unknown values themselves return unknown values that have a\ntype appropriate to the operation. For example, adding together two unknown\nnumbers yields an unknown number, while comparing two unknown values of any\ntype for equality yields an unknown bool.\n\nEach type has a distinct unknown value. For example, an unknown _number_ is\na distinct value from an unknown _string_.\n\n_The dynamic pseudo-type_ is a placeholder for a type that is not yet known.\nThe only values of this type are its null value and its unknown value. It is\nreferred to as a _pseudo-type_ because it should not be considered a type in\nits own right, but rather as a placeholder for a type yet to be established.\nThe unknown value of the dynamic pseudo-type is referred to as _the dynamic\nvalue_.\n\nOperations on values of the dynamic pseudo-type behave as if it is a value\nof the expected type, optimistically assuming that once the value and type\nare known they will be valid for the operation. For example, adding together\na number and the dynamic value produces an unknown number.\n\nUnknown values and the dynamic pseudo-type can be used as a mechanism for\npartial type checking and semantic checking: by evaluating an expression with\nall variables set to an unknown value, the expression can be evaluated to\nproduce an unknown value of a given type, or produce an error if any operation\nis provably invalid with only type information.\n\nUnknown values and the dynamic pseudo-type must never be returned from\noperations unless at least one operand is unknown or dynamic. Calling\napplications are guaranteed that unless the global scope includes unknown\nvalues, or the function table includes functions that return unknown values,\nno expression will evaluate to an unknown value. The calling application is\nthus in total control over the use and meaning of unknown values.\n\nThe dynamic pseudo-type is identical only to itself.\n\n### Capsule Types\n\nA _capsule type_ is a custom type defined by the calling application. A value\nof a capsule type is considered opaque to HCL, but may be accepted\nby functions provided by the calling application.\n\nA particular capsule type is identical only to itself. The equality of two\nvalues of the same capsule type is defined by the calling application. No\nother operations are supported for values of capsule types.\n\nSupport for capsule types in a HCL implementation is optional. Capsule types\nare intended to allow calling applications to pass through values that are\nnot part of the standard type system. For example, an application that\ndeals with raw binary data may define a capsule type representing a byte\narray, and provide functions that produce or operate on byte arrays.\n\n### Type Specifications\n\nIn certain situations it is necessary to define expectations about the expected\ntype of a value. Whereas two _types_ have a commutative _identity_ relationship,\na type has a non-commutative _matches_ relationship with a _type specification_.\nA type specification is, in practice, just a different interpretation of a\ntype such that:\n\n- Any type _matches_ any type that it is identical to.\n\n- Any type _matches_ the dynamic pseudo-type.\n\nFor example, given a type specification \"list of dynamic pseudo-type\", the\nconcrete types \"list of string\" and \"list of map\" match, but the\ntype \"set of string\" does not.\n\n## Functions and Function Calls\n\nThe evaluation context used to evaluate an expression includes a function\ntable, which represents an application-defined set of named functions\navailable for use in expressions.\n\nEach syntax defines whether function calls are supported and how they are\nphysically represented in source code, but the semantics of function calls are\ndefined here to ensure consistent results across syntaxes and to allow\napplications to provide functions that are interoperable with all syntaxes.\n\nA _function_ is defined from the following elements:\n\n- Zero or more _positional parameters_, each with a name used for documentation,\n  a type specification for expected argument values, and a flag for whether\n  each of null values, unknown values, and values of the dynamic pseudo-type\n  are accepted.\n\n- Zero or one _variadic parameters_, with the same structure as the _positional_\n  parameters, which if present collects any additional arguments provided at\n  the function call site.\n\n- A _result type definition_, which specifies the value type returned for each\n  valid sequence of argument values.\n\n- A _result value definition_, which specifies the value returned for each\n  valid sequence of argument values.\n\nA _function call_, regardless of source syntax, consists of a sequence of\nargument values. The argument values are each mapped to a corresponding\nparameter as follows:\n\n- For each of the function's positional parameters in sequence, take the next\n  argument. If there are no more arguments, the call is erroneous.\n\n- If the function has a variadic parameter, take all remaining arguments that\n  where not yet assigned to a positional parameter and collect them into\n  a sequence of variadic arguments that each correspond to the variadic\n  parameter.\n\n- If the function has _no_ variadic parameter, it is an error if any arguments\n  remain after taking one argument for each positional parameter.\n\nAfter mapping each argument to a parameter, semantic checking proceeds\nfor each argument:\n\n- If the argument value corresponding to a parameter does not match the\n  parameter's type specification, the call is erroneous.\n\n- If the argument value corresponding to a parameter is null and the parameter\n  is not specified as accepting nulls, the call is erroneous.\n\n- If the argument value corresponding to a parameter is the dynamic value\n  and the parameter is not specified as accepting values of the dynamic\n  pseudo-type, the call is valid but its _result type_ is forced to be the\n  dynamic pseudo type.\n\n- If neither of the above conditions holds for any argument, the call is\n  valid and the function's value type definition is used to determine the\n  call's _result type_. A function _may_ vary its result type depending on\n  the argument _values_ as well as the argument _types_; for example, a\n  function that decodes a JSON value will return a different result type\n  depending on the data structure described by the given JSON source code.\n\nIf semantic checking succeeds without error, the call is _executed_:\n\n- For each argument, if its value is unknown and its corresponding parameter\n  is not specified as accepting unknowns, the _result value_ is forced to be an\n  unknown value of the result type.\n\n- If the previous condition does not apply, the function's result value\n  definition is used to determine the call's _result value_.\n\nThe result of a function call expression is either an error, if one of the\nerroneous conditions above applies, or the _result value_.\n\n## Type Conversions and Unification\n\nValues given in configuration may not always match the expectations of the\noperations applied to them or to the calling application. In such situations,\nautomatic type conversion is attempted as a convenience to the user.\n\nAlong with conversions to a _specified_ type, it is sometimes necessary to\nensure that a selection of values are all of the _same_ type, without any\nconstraint on which type that is. This is the process of _type unification_,\nwhich attempts to find the most general type that all of the given types can\nbe converted to.\n\nBoth type conversions and unification are defined in the syntax-agnostic\nmodel to ensure consistency of behavior between syntaxes.\n\nType conversions are broadly characterized into two categories: _safe_ and\n_unsafe_. A conversion is \"safe\" if any distinct value of the source type\nhas a corresponding distinct value in the target type. A conversion is\n\"unsafe\" if either the target type values are _not_ distinct (information\nmay be lost in conversion) or if some values of the source type do not have\nany corresponding value in the target type. An unsafe conversion may result\nin an error.\n\nA given type can always be converted to itself, which is a no-op.\n\n### Conversion of Null Values\n\nAll null values are safely convertable to a null value of any other type,\nregardless of other type-specific rules specified in the sections below.\n\n### Conversion to and from the Dynamic Pseudo-type\n\nConversion _from_ the dynamic pseudo-type _to_ any other type always succeeds,\nproducing an unknown value of the target type.\n\nConversion of any value _to_ the dynamic pseudo-type is a no-op. The result\nis the input value, verbatim. This is the only situation where the conversion\nresult value is not of the given target type.\n\n### Primitive Type Conversions\n\nBidirectional conversions are available between the string and number types,\nand between the string and boolean types.\n\nThe bool value true corresponds to the string containing the characters \"true\",\nwhile the bool value false corresponds to the string containing the characters\n\"false\". Conversion from bool to string is safe, while the converse is\nunsafe. The strings \"1\" and \"0\" are alternative string representations\nof true and false respectively. It is an error to convert a string other than\nthe four in this paragraph to type bool.\n\nA number value is converted to string by translating its integer portion\ninto a sequence of decimal digits (`0` through `9`), and then if it has a\nnon-zero fractional part, a period `.` followed by a sequence of decimal\ndigits representing its fractional part. No exponent portion is included.\nThe number is converted at its full precision. Conversion from number to\nstring is safe.\n\nA string is converted to a number value by reversing the above mapping.\nNo exponent portion is allowed. Conversion from string to number is unsafe.\nIt is an error to convert a string that does not comply with the expected\nsyntax to type number.\n\nNo direct conversion is available between the bool and number types.\n\n### Collection and Structural Type Conversions\n\nConversion from set types to list types is _safe_, as long as their\nelement types are safely convertable. If the element types are _unsafely_\nconvertable, then the collection conversion is also unsafe. Each set element\nbecomes a corresponding list element, in an undefined order. Although no\nparticular ordering is required, implementations _should_ produce list\nelements in a consistent order for a given input set, as a convenience\nto calling applications.\n\nConversion from list types to set types is _unsafe_, as long as their element\ntypes are convertable. Each distinct list item becomes a distinct set item.\nIf two list items are equal, one of the two is lost in the conversion.\n\nConversion from tuple types to list types permitted if all of the\ntuple element types are convertable to the target list element type.\nThe safety of the conversion depends on the safety of each of the element\nconversions. Each element in turn is converted to the list element type,\nproducing a list of identical length.\n\nConversion from tuple types to set types is permitted, behaving as if the\ntuple type was first converted to a list of the same element type and then\nthat list converted to the target set type.\n\nConversion from object types to map types is permitted if all of the object\nattribute types are convertable to the target map element type. The safety\nof the conversion depends on the safety of each of the attribute conversions.\nEach attribute in turn is converted to the map element type, and map element\nkeys are set to the name of each corresponding object attribute.\n\nConversion from list and set types to tuple types is permitted, following\nthe opposite steps as the converse conversions. Such conversions are _unsafe_.\nIt is an error to convert a list or set to a tuple type whose number of\nelements does not match the list or set length.\n\nConversion from map types to object types is permitted if each map key\ncorresponds to an attribute in the target object type. It is an error to\nconvert from a map value whose set of keys does not exactly match the target\ntype's attributes. The conversion takes the opposite steps of the converse\nconversion.\n\nConversion from one object type to another is permitted as long as the\ncommon attribute names have convertable types. Any attribute present in the\ntarget type but not in the source type is populated with a null value of\nthe appropriate type.\n\nConversion from one tuple type to another is permitted as long as the\ntuples have the same length and the elements have convertable types.\n\n### Type Unification\n\nType unification is an operation that takes a list of types and attempts\nto find a single type to which they can all be converted. Since some\ntype pairs have bidirectional conversions, preference is given to _safe_\nconversions. In technical terms, all possible types are arranged into\na lattice, from which a most general supertype is selected where possible.\n\nThe type resulting from type unification may be one of the input types, or\nit may be an entirely new type produced by combination of two or more\ninput types.\n\nThe following rules do not guarantee a valid result. In addition to these\nrules, unification fails if any of the given types are not convertable\n(per the above rules) to the selected result type.\n\nThe following unification rules apply transitively. That is, if a rule is\ndefined from A to B, and one from B to C, then A can unify to C.\n\nNumber and bool types both unify with string by preferring string.\n\nTwo collection types of the same kind unify according to the unification\nof their element types.\n\nList and set types unify by preferring the list type.\n\nMap and object types unify by preferring the object type.\n\nList, set and tuple types unify by preferring the tuple type.\n\nThe dynamic pseudo-type unifies with any other type by selecting that other\ntype. The dynamic pseudo-type is the result type only if _all_ input types\nare the dynamic pseudo-type.\n\nTwo object types unify by constructing a new type whose attributes are\nthe union of those of the two input types. Any common attributes themselves\nhave their types unified.\n\nTwo tuple types of the same length unify constructing a new type of the\nsame length whose elements are the unification of the corresponding elements\nin the two input types.\n\n## Static Analysis\n\nIn most applications, full expression evaluation is sufficient for understanding\nthe provided configuration. However, some specialized applications require more\ndirect access to the physical structures in the expressions, which can for\nexample allow the construction of new language constructs in terms of the\nexisting syntax elements.\n\nSince static analysis analyses the physical structure of configuration, the\ndetails will vary depending on syntax. Each syntax must decide which of its\nphysical structures corresponds to the following analyses, producing error\ndiagnostics if they are applied to inappropriate expressions.\n\nThe following are the required static analysis functions:\n\n- **Static List**: Require list/tuple construction syntax to be used and\n  return a list of expressions for each of the elements given.\n\n- **Static Map**: Require map/object construction syntax to be used and\n  return a list of key/value pairs -- both expressions -- for each of\n  the elements given. The usual constraint that a map key must be a string\n  must not apply to this analysis, thus allowing applications to interpret\n  arbitrary keys as they see fit.\n\n- **Static Call**: Require function call syntax to be used and return an\n  object describing the called function name and a list of expressions\n  representing each of the call arguments.\n\n- **Static Traversal**: Require a reference to a symbol in the variable\n  scope and return a description of the path from the root scope to the\n  accessed attribute or index.\n\nThe intent of a calling application using these features is to require a more\nrigid interpretation of the configuration than in expression evaluation.\nSyntax implementations should make use of the extra contextual information\nprovided in order to make an intuitive mapping onto the constructs of the\nunderlying syntax, possibly interpreting the expression slightly differently\nthan it would be interpreted in normal evaluation.\n\nEach syntax must define which of its expression elements each of the analyses\nabove applies to, and how those analyses behave given those expression elements.\n\n## Implementation Considerations\n\nImplementations of this specification are free to adopt any strategy that\nproduces behavior consistent with the specification. This non-normative\nsection describes some possible implementation strategies that are consistent\nwith the goals of this specification.\n\n### Language-agnosticism\n\nThe language-agnosticism of this specification assumes that certain behaviors\nare implemented separately for each syntax:\n\n- Matching of a body schema with the physical elements of a body in the\n  source language, to determine correspondence between physical constructs\n  and schema elements.\n\n- Implementing the _dynamic attributes_ body processing mode by either\n  interpreting all physical constructs as attributes or producing an error\n  if non-attribute constructs are present.\n\n- Providing an evaluation function for all possible expressions that produces\n  a value given an evaluation context.\n\n- Providing the static analysis functionality described above in a manner that\n  makes sense within the convention of the syntax.\n\nThe suggested implementation strategy is to use an implementation language's\nclosest concept to an _abstract type_, _virtual type_ or _interface type_\nto represent both Body and Expression. Each language-specific implementation\ncan then provide an implementation of each of these types wrapping AST nodes\nor other physical constructs from the language parser.\n"
        },
        {
          "name": "specsuite",
          "type": "tree",
          "content": null
        },
        {
          "name": "static_expr.go",
          "type": "blob",
          "size": 1.0009765625,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\nimport (\n\t\"github.com/zclconf/go-cty/cty\"\n)\n\ntype staticExpr struct {\n\tval cty.Value\n\trng Range\n}\n\n// StaticExpr returns an Expression that always evaluates to the given value.\n//\n// This is useful to substitute default values for expressions that are\n// not explicitly given in configuration and thus would otherwise have no\n// Expression to return.\n//\n// Since expressions are expected to have a source range, the caller must\n// provide one. Ideally this should be a real source range, but it can\n// be a synthetic one (with an empty-string filename) if no suitable range\n// is available.\nfunc StaticExpr(val cty.Value, rng Range) Expression {\n\treturn staticExpr{val, rng}\n}\n\nfunc (e staticExpr) Value(ctx *EvalContext) (cty.Value, Diagnostics) {\n\treturn e.val, nil\n}\n\nfunc (e staticExpr) Variables() []Traversal {\n\treturn nil\n}\n\nfunc (e staticExpr) Range() Range {\n\treturn e.rng\n}\n\nfunc (e staticExpr) StartRange() Range {\n\treturn e.rng\n}\n"
        },
        {
          "name": "structure.go",
          "type": "blob",
          "size": 5.3115234375,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\nimport (\n\t\"github.com/zclconf/go-cty/cty\"\n)\n\n// File is the top-level node that results from parsing a HCL file.\ntype File struct {\n\tBody  Body\n\tBytes []byte\n\n\t// Nav is used to integrate with the \"hcled\" editor integration package,\n\t// and with diagnostic information formatters. It is not for direct use\n\t// by a calling application.\n\tNav interface{}\n}\n\n// Block represents a nested block within a Body.\ntype Block struct {\n\tType   string\n\tLabels []string\n\tBody   Body\n\n\tDefRange    Range   // Range that can be considered the \"definition\" for seeking in an editor\n\tTypeRange   Range   // Range for the block type declaration specifically.\n\tLabelRanges []Range // Ranges for the label values specifically.\n}\n\n// Blocks is a sequence of Block.\ntype Blocks []*Block\n\n// Attributes is a set of attributes keyed by their names.\ntype Attributes map[string]*Attribute\n\n// Body is a container for attributes and blocks. It serves as the primary\n// unit of hierarchical structure within configuration.\n//\n// The content of a body cannot be meaningfully interpreted without a schema,\n// so Body represents the raw body content and has methods that allow the\n// content to be extracted in terms of a given schema.\ntype Body interface {\n\t// Content verifies that the entire body content conforms to the given\n\t// schema and then returns it, and/or returns diagnostics. The returned\n\t// body content is valid if non-nil, regardless of whether Diagnostics\n\t// are provided, but diagnostics should still be eventually shown to\n\t// the user.\n\tContent(schema *BodySchema) (*BodyContent, Diagnostics)\n\n\t// PartialContent is like Content except that it permits the configuration\n\t// to contain additional blocks or attributes not specified in the\n\t// schema. If any are present, the returned Body is non-nil and contains\n\t// the remaining items from the body that were not selected by the schema.\n\tPartialContent(schema *BodySchema) (*BodyContent, Body, Diagnostics)\n\n\t// JustAttributes attempts to interpret all of the contents of the body\n\t// as attributes, allowing for the contents to be accessed without a priori\n\t// knowledge of the structure.\n\t//\n\t// The behavior of this method depends on the body's source language.\n\t// Some languages, like JSON, can't distinguish between attributes and\n\t// blocks without schema hints, but for languages that _can_ error\n\t// diagnostics will be generated if any blocks are present in the body.\n\t//\n\t// Diagnostics may be produced for other reasons too, such as duplicate\n\t// declarations of the same attribute.\n\tJustAttributes() (Attributes, Diagnostics)\n\n\t// MissingItemRange returns a range that represents where a missing item\n\t// might hypothetically be inserted. This is used when producing\n\t// diagnostics about missing required attributes or blocks. Not all bodies\n\t// will have an obvious single insertion point, so the result here may\n\t// be rather arbitrary.\n\tMissingItemRange() Range\n}\n\n// BodyContent is the result of applying a BodySchema to a Body.\ntype BodyContent struct {\n\tAttributes Attributes\n\tBlocks     Blocks\n\n\tMissingItemRange Range\n}\n\n// Attribute represents an attribute from within a body.\ntype Attribute struct {\n\tName string\n\tExpr Expression\n\n\tRange     Range\n\tNameRange Range\n}\n\n// Expression is a literal value or an expression provided in the\n// configuration, which can be evaluated within a scope to produce a value.\ntype Expression interface {\n\t// Value returns the value resulting from evaluating the expression\n\t// in the given evaluation context.\n\t//\n\t// The context may be nil, in which case the expression may contain\n\t// only constants and diagnostics will be produced for any non-constant\n\t// sub-expressions. (The exact definition of this depends on the source\n\t// language.)\n\t//\n\t// The context may instead be set but have either its Variables or\n\t// Functions maps set to nil, in which case only use of these features\n\t// will return diagnostics.\n\t//\n\t// Different diagnostics are provided depending on whether the given\n\t// context maps are nil or empty. In the former case, the message\n\t// tells the user that variables/functions are not permitted at all,\n\t// while in the latter case usage will produce a \"not found\" error for\n\t// the specific symbol in question.\n\tValue(ctx *EvalContext) (cty.Value, Diagnostics)\n\n\t// Variables returns a list of variables referenced in the receiving\n\t// expression. These are expressed as absolute Traversals, so may include\n\t// additional information about how the variable is used, such as\n\t// attribute lookups, which the calling application can potentially use\n\t// to only selectively populate the scope.\n\tVariables() []Traversal\n\n\tRange() Range\n\tStartRange() Range\n}\n\n// OfType filters the receiving block sequence by block type name,\n// returning a new block sequence including only the blocks of the\n// requested type.\nfunc (els Blocks) OfType(typeName string) Blocks {\n\tret := make(Blocks, 0)\n\tfor _, el := range els {\n\t\tif el.Type == typeName {\n\t\t\tret = append(ret, el)\n\t\t}\n\t}\n\treturn ret\n}\n\n// ByType transforms the receiving block sequence into a map from type\n// name to block sequences of only that type.\nfunc (els Blocks) ByType() map[string]Blocks {\n\tret := make(map[string]Blocks)\n\tfor _, el := range els {\n\t\tty := el.Type\n\t\tif ret[ty] == nil {\n\t\t\tret[ty] = make(Blocks, 0, 1)\n\t\t}\n\t\tret[ty] = append(ret[ty], el)\n\t}\n\treturn ret\n}\n"
        },
        {
          "name": "structure_at_pos.go",
          "type": "blob",
          "size": 4.296875,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\n// -----------------------------------------------------------------------------\n// The methods in this file all have the general pattern of making a best-effort\n// to find one or more constructs that contain a given source position.\n//\n// These all operate by delegating to an optional method of the same name and\n// signature on the file's root body, allowing each syntax to potentially\n// provide its own implementations of these. For syntaxes that don't implement\n// them, the result is always nil.\n// -----------------------------------------------------------------------------\n\n// BlocksAtPos attempts to find all of the blocks that contain the given\n// position, ordered so that the outermost block is first and the innermost\n// block is last. This is a best-effort method that may not be able to produce\n// a complete result for all positions or for all HCL syntaxes.\n//\n// If the returned slice is non-empty, the first element is guaranteed to\n// represent the same block as would be the result of OutermostBlockAtPos and\n// the last element the result of InnermostBlockAtPos. However, the\n// implementation may return two different objects describing the same block,\n// so comparison by pointer identity is not possible.\n//\n// The result is nil if no blocks at all contain the given position.\nfunc (f *File) BlocksAtPos(pos Pos) []*Block {\n\t// The root body of the file must implement this interface in order\n\t// to support BlocksAtPos.\n\ttype Interface interface {\n\t\tBlocksAtPos(pos Pos) []*Block\n\t}\n\n\timpl, ok := f.Body.(Interface)\n\tif !ok {\n\t\treturn nil\n\t}\n\treturn impl.BlocksAtPos(pos)\n}\n\n// OutermostBlockAtPos attempts to find a top-level block in the receiving file\n// that contains the given position. This is a best-effort method that may not\n// be able to produce a result for all positions or for all HCL syntaxes.\n//\n// The result is nil if no single block could be selected for any reason.\nfunc (f *File) OutermostBlockAtPos(pos Pos) *Block {\n\t// The root body of the file must implement this interface in order\n\t// to support OutermostBlockAtPos.\n\ttype Interface interface {\n\t\tOutermostBlockAtPos(pos Pos) *Block\n\t}\n\n\timpl, ok := f.Body.(Interface)\n\tif !ok {\n\t\treturn nil\n\t}\n\treturn impl.OutermostBlockAtPos(pos)\n}\n\n// InnermostBlockAtPos attempts to find the most deeply-nested block in the\n// receiving file that contains the given position. This is a best-effort\n// method that may not be able to produce a result for all positions or for\n// all HCL syntaxes.\n//\n// The result is nil if no single block could be selected for any reason.\nfunc (f *File) InnermostBlockAtPos(pos Pos) *Block {\n\t// The root body of the file must implement this interface in order\n\t// to support InnermostBlockAtPos.\n\ttype Interface interface {\n\t\tInnermostBlockAtPos(pos Pos) *Block\n\t}\n\n\timpl, ok := f.Body.(Interface)\n\tif !ok {\n\t\treturn nil\n\t}\n\treturn impl.InnermostBlockAtPos(pos)\n}\n\n// OutermostExprAtPos attempts to find an expression in the receiving file\n// that contains the given position. This is a best-effort method that may not\n// be able to produce a result for all positions or for all HCL syntaxes.\n//\n// Since expressions are often nested inside one another, this method returns\n// the outermost \"root\" expression that is not contained by any other.\n//\n// The result is nil if no single expression could be selected for any reason.\nfunc (f *File) OutermostExprAtPos(pos Pos) Expression {\n\t// The root body of the file must implement this interface in order\n\t// to support OutermostExprAtPos.\n\ttype Interface interface {\n\t\tOutermostExprAtPos(pos Pos) Expression\n\t}\n\n\timpl, ok := f.Body.(Interface)\n\tif !ok {\n\t\treturn nil\n\t}\n\treturn impl.OutermostExprAtPos(pos)\n}\n\n// AttributeAtPos attempts to find an attribute definition in the receiving\n// file that contains the given position. This is a best-effort method that may\n// not be able to produce a result for all positions or for all HCL syntaxes.\n//\n// The result is nil if no single attribute could be selected for any reason.\nfunc (f *File) AttributeAtPos(pos Pos) *Attribute {\n\t// The root body of the file must implement this interface in order\n\t// to support OutermostExprAtPos.\n\ttype Interface interface {\n\t\tAttributeAtPos(pos Pos) *Attribute\n\t}\n\n\timpl, ok := f.Body.(Interface)\n\tif !ok {\n\t\treturn nil\n\t}\n\treturn impl.AttributeAtPos(pos)\n}\n"
        },
        {
          "name": "tools.go",
          "type": "blob",
          "size": 0.1611328125,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\n//go:build tools\n// +build tools\n\npackage hcl\n\nimport (\n\t_ \"golang.org/x/tools/cmd/stringer\"\n)\n"
        },
        {
          "name": "traversal.go",
          "type": "blob",
          "size": 8.0029296875,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/zclconf/go-cty/cty\"\n)\n\n// A Traversal is a description of traversing through a value through a\n// series of operations such as attribute lookup, index lookup, etc.\n//\n// It is used to look up values in scopes, for example.\n//\n// The traversal operations are implementations of interface Traverser.\n// This is a closed set of implementations, so the interface cannot be\n// implemented from outside this package.\n//\n// A traversal can be absolute (its first value is a symbol name) or relative\n// (starts from an existing value).\ntype Traversal []Traverser\n\n// TraversalJoin appends a relative traversal to an absolute traversal to\n// produce a new absolute traversal.\nfunc TraversalJoin(abs Traversal, rel Traversal) Traversal {\n\tif abs.IsRelative() {\n\t\tpanic(\"first argument to TraversalJoin must be absolute\")\n\t}\n\tif !rel.IsRelative() {\n\t\tpanic(\"second argument to TraversalJoin must be relative\")\n\t}\n\n\tret := make(Traversal, len(abs)+len(rel))\n\tcopy(ret, abs)\n\tcopy(ret[len(abs):], rel)\n\treturn ret\n}\n\n// TraverseRel applies the receiving traversal to the given value, returning\n// the resulting value. This is supported only for relative traversals,\n// and will panic if applied to an absolute traversal.\nfunc (t Traversal) TraverseRel(val cty.Value) (cty.Value, Diagnostics) {\n\tif !t.IsRelative() {\n\t\tpanic(\"can't use TraverseRel on an absolute traversal\")\n\t}\n\n\tcurrent := val\n\tvar diags Diagnostics\n\tfor _, tr := range t {\n\t\tvar newDiags Diagnostics\n\t\tcurrent, newDiags = tr.TraversalStep(current)\n\t\tdiags = append(diags, newDiags...)\n\t\tif newDiags.HasErrors() {\n\t\t\treturn cty.DynamicVal, diags\n\t\t}\n\t}\n\treturn current, diags\n}\n\n// TraverseAbs applies the receiving traversal to the given eval context,\n// returning the resulting value. This is supported only for absolute\n// traversals, and will panic if applied to a relative traversal.\nfunc (t Traversal) TraverseAbs(ctx *EvalContext) (cty.Value, Diagnostics) {\n\tif t.IsRelative() {\n\t\tpanic(\"can't use TraverseAbs on a relative traversal\")\n\t}\n\n\tsplit := t.SimpleSplit()\n\troot := split.Abs[0].(TraverseRoot)\n\tname := root.Name\n\n\tthisCtx := ctx\n\thasNonNil := false\n\tfor thisCtx != nil {\n\t\tif thisCtx.Variables == nil {\n\t\t\tthisCtx = thisCtx.parent\n\t\t\tcontinue\n\t\t}\n\t\thasNonNil = true\n\t\tval, exists := thisCtx.Variables[name]\n\t\tif exists {\n\t\t\treturn split.Rel.TraverseRel(val)\n\t\t}\n\t\tthisCtx = thisCtx.parent\n\t}\n\n\tif !hasNonNil {\n\t\treturn cty.DynamicVal, Diagnostics{\n\t\t\t{\n\t\t\t\tSeverity: DiagError,\n\t\t\t\tSummary:  \"Variables not allowed\",\n\t\t\t\tDetail:   \"Variables may not be used here.\",\n\t\t\t\tSubject:  &root.SrcRange,\n\t\t\t},\n\t\t}\n\t}\n\n\tsuggestions := make([]string, 0, len(ctx.Variables))\n\tthisCtx = ctx\n\tfor thisCtx != nil {\n\t\tfor k := range thisCtx.Variables {\n\t\t\tsuggestions = append(suggestions, k)\n\t\t}\n\t\tthisCtx = thisCtx.parent\n\t}\n\tsuggestion := nameSuggestion(name, suggestions)\n\tif suggestion != \"\" {\n\t\tsuggestion = fmt.Sprintf(\" Did you mean %q?\", suggestion)\n\t}\n\n\treturn cty.DynamicVal, Diagnostics{\n\t\t{\n\t\t\tSeverity: DiagError,\n\t\t\tSummary:  \"Unknown variable\",\n\t\t\tDetail:   fmt.Sprintf(\"There is no variable named %q.%s\", name, suggestion),\n\t\t\tSubject:  &root.SrcRange,\n\t\t},\n\t}\n}\n\n// IsRelative returns true if the receiver is a relative traversal, or false\n// otherwise.\nfunc (t Traversal) IsRelative() bool {\n\tif len(t) == 0 {\n\t\treturn true\n\t}\n\tif _, firstIsRoot := t[0].(TraverseRoot); firstIsRoot {\n\t\treturn false\n\t}\n\treturn true\n}\n\n// SimpleSplit returns a TraversalSplit where the name lookup is the absolute\n// part and the remainder is the relative part. Supported only for\n// absolute traversals, and will panic if applied to a relative traversal.\n//\n// This can be used by applications that have a relatively-simple variable\n// namespace where only the top-level is directly populated in the scope, with\n// everything else handled by relative lookups from those initial values.\nfunc (t Traversal) SimpleSplit() TraversalSplit {\n\tif t.IsRelative() {\n\t\tpanic(\"can't use SimpleSplit on a relative traversal\")\n\t}\n\treturn TraversalSplit{\n\t\tAbs: t[0:1],\n\t\tRel: t[1:],\n\t}\n}\n\n// RootName returns the root name for a absolute traversal. Will panic if\n// called on a relative traversal.\nfunc (t Traversal) RootName() string {\n\tif t.IsRelative() {\n\t\tpanic(\"can't use RootName on a relative traversal\")\n\n\t}\n\treturn t[0].(TraverseRoot).Name\n}\n\n// SourceRange returns the source range for the traversal.\nfunc (t Traversal) SourceRange() Range {\n\tif len(t) == 0 {\n\t\t// Nothing useful to return here, but we'll return something\n\t\t// that's correctly-typed at least.\n\t\treturn Range{}\n\t}\n\n\treturn RangeBetween(t[0].SourceRange(), t[len(t)-1].SourceRange())\n}\n\n// TraversalSplit represents a pair of traversals, the first of which is\n// an absolute traversal and the second of which is relative to the first.\n//\n// This is used by calling applications that only populate prefixes of the\n// traversals in the scope, with Abs representing the part coming from the\n// scope and Rel representing the remaining steps once that part is\n// retrieved.\ntype TraversalSplit struct {\n\tAbs Traversal\n\tRel Traversal\n}\n\n// TraverseAbs traverses from a scope to the value resulting from the\n// absolute traversal.\nfunc (t TraversalSplit) TraverseAbs(ctx *EvalContext) (cty.Value, Diagnostics) {\n\treturn t.Abs.TraverseAbs(ctx)\n}\n\n// TraverseRel traverses from a given value, assumed to be the result of\n// TraverseAbs on some scope, to a final result for the entire split traversal.\nfunc (t TraversalSplit) TraverseRel(val cty.Value) (cty.Value, Diagnostics) {\n\treturn t.Rel.TraverseRel(val)\n}\n\n// Traverse is a convenience function to apply TraverseAbs followed by\n// TraverseRel.\nfunc (t TraversalSplit) Traverse(ctx *EvalContext) (cty.Value, Diagnostics) {\n\tv1, diags := t.TraverseAbs(ctx)\n\tif diags.HasErrors() {\n\t\treturn cty.DynamicVal, diags\n\t}\n\tv2, newDiags := t.TraverseRel(v1)\n\tdiags = append(diags, newDiags...)\n\treturn v2, diags\n}\n\n// Join concatenates together the Abs and Rel parts to produce a single\n// absolute traversal.\nfunc (t TraversalSplit) Join() Traversal {\n\treturn TraversalJoin(t.Abs, t.Rel)\n}\n\n// RootName returns the root name for the absolute part of the split.\nfunc (t TraversalSplit) RootName() string {\n\treturn t.Abs.RootName()\n}\n\n// A Traverser is a step within a Traversal.\ntype Traverser interface {\n\tTraversalStep(cty.Value) (cty.Value, Diagnostics)\n\tSourceRange() Range\n\tisTraverserSigil() isTraverser\n}\n\n// Embed this in a struct to declare it as a Traverser\ntype isTraverser struct {\n}\n\nfunc (tr isTraverser) isTraverserSigil() isTraverser {\n\treturn isTraverser{}\n}\n\n// TraverseRoot looks up a root name in a scope. It is used as the first step\n// of an absolute Traversal, and cannot itself be traversed directly.\ntype TraverseRoot struct {\n\tisTraverser\n\tName     string\n\tSrcRange Range\n}\n\n// TraversalStep on a TraverseName immediately panics, because absolute\n// traversals cannot be directly traversed.\nfunc (tn TraverseRoot) TraversalStep(cty.Value) (cty.Value, Diagnostics) {\n\tpanic(\"Cannot traverse an absolute traversal\")\n}\n\nfunc (tn TraverseRoot) SourceRange() Range {\n\treturn tn.SrcRange\n}\n\n// TraverseAttr looks up an attribute in its initial value.\ntype TraverseAttr struct {\n\tisTraverser\n\tName     string\n\tSrcRange Range\n}\n\nfunc (tn TraverseAttr) TraversalStep(val cty.Value) (cty.Value, Diagnostics) {\n\treturn GetAttr(val, tn.Name, &tn.SrcRange)\n}\n\nfunc (tn TraverseAttr) SourceRange() Range {\n\treturn tn.SrcRange\n}\n\n// TraverseIndex applies the index operation to its initial value.\ntype TraverseIndex struct {\n\tisTraverser\n\tKey      cty.Value\n\tSrcRange Range\n}\n\nfunc (tn TraverseIndex) TraversalStep(val cty.Value) (cty.Value, Diagnostics) {\n\treturn Index(val, tn.Key, &tn.SrcRange)\n}\n\nfunc (tn TraverseIndex) SourceRange() Range {\n\treturn tn.SrcRange\n}\n\n// TraverseSplat applies the splat operation to its initial value.\ntype TraverseSplat struct {\n\tisTraverser\n\tEach     Traversal\n\tSrcRange Range\n}\n\nfunc (tn TraverseSplat) TraversalStep(val cty.Value) (cty.Value, Diagnostics) {\n\tpanic(\"TraverseSplat not yet implemented\")\n}\n\nfunc (tn TraverseSplat) SourceRange() Range {\n\treturn tn.SrcRange\n}\n"
        },
        {
          "name": "traversal_for_expr.go",
          "type": "blob",
          "size": 4.705078125,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\n// AbsTraversalForExpr attempts to interpret the given expression as\n// an absolute traversal, or returns error diagnostic(s) if that is\n// not possible for the given expression.\n//\n// A particular Expression implementation can support this function by\n// offering a method called AsTraversal that takes no arguments and\n// returns either a valid absolute traversal or nil to indicate that\n// no traversal is possible. Alternatively, an implementation can support\n// UnwrapExpression to delegate handling of this function to a wrapped\n// Expression object.\n//\n// In most cases the calling application is interested in the value\n// that results from an expression, but in rarer cases the application\n// needs to see the name of the variable and subsequent\n// attributes/indexes itself, for example to allow users to give references\n// to the variables themselves rather than to their values. An implementer\n// of this function should at least support attribute and index steps.\nfunc AbsTraversalForExpr(expr Expression) (Traversal, Diagnostics) {\n\ttype asTraversal interface {\n\t\tAsTraversal() Traversal\n\t}\n\n\tphysExpr := UnwrapExpressionUntil(expr, func(expr Expression) bool {\n\t\t_, supported := expr.(asTraversal)\n\t\treturn supported\n\t})\n\n\tif asT, supported := physExpr.(asTraversal); supported {\n\t\tif traversal := asT.AsTraversal(); traversal != nil {\n\t\t\treturn traversal, nil\n\t\t}\n\t}\n\treturn nil, Diagnostics{\n\t\t&Diagnostic{\n\t\t\tSeverity: DiagError,\n\t\t\tSummary:  \"Invalid expression\",\n\t\t\tDetail:   \"A single static variable reference is required: only attribute access and indexing with constant keys. No calculations, function calls, template expressions, etc are allowed here.\",\n\t\t\tSubject:  expr.Range().Ptr(),\n\t\t},\n\t}\n}\n\n// RelTraversalForExpr is similar to AbsTraversalForExpr but it returns\n// a relative traversal instead. Due to the nature of HCL expressions, the\n// first element of the returned traversal is always a TraverseAttr, and\n// then it will be followed by zero or more other expressions.\n//\n// Any expression accepted by AbsTraversalForExpr is also accepted by\n// RelTraversalForExpr.\nfunc RelTraversalForExpr(expr Expression) (Traversal, Diagnostics) {\n\ttraversal, diags := AbsTraversalForExpr(expr)\n\tif len(traversal) > 0 {\n\t\tret := make(Traversal, len(traversal))\n\t\tcopy(ret, traversal)\n\t\troot := traversal[0].(TraverseRoot)\n\t\tret[0] = TraverseAttr{\n\t\t\tName:     root.Name,\n\t\t\tSrcRange: root.SrcRange,\n\t\t}\n\t\treturn ret, diags\n\t}\n\treturn traversal, diags\n}\n\n// ExprAsKeyword attempts to interpret the given expression as a static keyword,\n// returning the keyword string if possible, and the empty string if not.\n//\n// A static keyword, for the sake of this function, is a single identifier.\n// For example, the following attribute has an expression that would produce\n// the keyword \"foo\":\n//\n//     example = foo\n//\n// This function is a variant of AbsTraversalForExpr, which uses the same\n// interface on the given expression. This helper constrains the result\n// further by requiring only a single root identifier.\n//\n// This function is intended to be used with the following idiom, to recognize\n// situations where one of a fixed set of keywords is required and arbitrary\n// expressions are not allowed:\n//\n//     switch hcl.ExprAsKeyword(expr) {\n//     case \"allow\":\n//         // (take suitable action for keyword \"allow\")\n//     case \"deny\":\n//         // (take suitable action for keyword \"deny\")\n//     default:\n//         diags = append(diags, &hcl.Diagnostic{\n//             // ... \"invalid keyword\" diagnostic message ...\n//         })\n//     }\n//\n// The above approach will generate the same message for both the use of an\n// unrecognized keyword and for not using a keyword at all, which is usually\n// reasonable if the message specifies that the given value must be a keyword\n// from that fixed list.\n//\n// Note that in the native syntax the keywords \"true\", \"false\", and \"null\" are\n// recognized as literal values during parsing and so these reserved words\n// cannot not be accepted as keywords by this function.\n//\n// Since interpreting an expression as a keyword bypasses usual expression\n// evaluation, it should be used sparingly for situations where e.g. one of\n// a fixed set of keywords is used in a structural way in a special attribute\n// to affect the further processing of a block.\nfunc ExprAsKeyword(expr Expression) string {\n\ttype asTraversal interface {\n\t\tAsTraversal() Traversal\n\t}\n\n\tphysExpr := UnwrapExpressionUntil(expr, func(expr Expression) bool {\n\t\t_, supported := expr.(asTraversal)\n\t\treturn supported\n\t})\n\n\tif asT, supported := physExpr.(asTraversal); supported {\n\t\tif traversal := asT.AsTraversal(); len(traversal) == 1 {\n\t\t\treturn traversal.RootName()\n\t\t}\n\t}\n\treturn \"\"\n}\n"
        },
        {
          "name": "traversal_for_expr_test.go",
          "type": "blob",
          "size": 4.123046875,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage hcl\n\nimport (\n\t\"testing\"\n)\n\ntype asTraversalSupported struct {\n\tstaticExpr\n\tRootName string\n}\n\ntype asTraversalSupportedAttr struct {\n\tstaticExpr\n\tRootName string\n\tAttrName string\n}\n\ntype asTraversalNotSupported struct {\n\tstaticExpr\n}\n\ntype asTraversalDeclined struct {\n\tstaticExpr\n}\n\ntype asTraversalWrappedDelegated struct {\n\toriginal Expression\n\tstaticExpr\n}\n\nfunc (e asTraversalSupported) AsTraversal() Traversal {\n\treturn Traversal{\n\t\tTraverseRoot{\n\t\t\tName: e.RootName,\n\t\t},\n\t}\n}\n\nfunc (e asTraversalSupportedAttr) AsTraversal() Traversal {\n\treturn Traversal{\n\t\tTraverseRoot{\n\t\t\tName: e.RootName,\n\t\t},\n\t\tTraverseAttr{\n\t\t\tName: e.AttrName,\n\t\t},\n\t}\n}\n\nfunc (e asTraversalDeclined) AsTraversal() Traversal {\n\treturn nil\n}\n\nfunc (e asTraversalWrappedDelegated) UnwrapExpression() Expression {\n\treturn e.original\n}\n\nfunc TestAbsTraversalForExpr(t *testing.T) {\n\ttests := []struct {\n\t\tExpr         Expression\n\t\tWantRootName string\n\t}{\n\t\t{\n\t\t\tasTraversalSupported{RootName: \"foo\"},\n\t\t\t\"foo\",\n\t\t},\n\t\t{\n\t\t\tasTraversalNotSupported{},\n\t\t\t\"\",\n\t\t},\n\t\t{\n\t\t\tasTraversalDeclined{},\n\t\t\t\"\",\n\t\t},\n\t\t{\n\t\t\tasTraversalWrappedDelegated{\n\t\t\t\toriginal: asTraversalSupported{RootName: \"foo\"},\n\t\t\t},\n\t\t\t\"foo\",\n\t\t},\n\t\t{\n\t\t\tasTraversalWrappedDelegated{\n\t\t\t\toriginal: asTraversalWrappedDelegated{\n\t\t\t\t\toriginal: asTraversalSupported{RootName: \"foo\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"foo\",\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tt.Run(\"\", func(t *testing.T) {\n\t\t\tgot, diags := AbsTraversalForExpr(test.Expr)\n\t\t\tswitch {\n\t\t\tcase got != nil:\n\t\t\t\tif test.WantRootName == \"\" {\n\t\t\t\t\tt.Fatalf(\"traversal was returned; want error\")\n\t\t\t\t}\n\t\t\t\tif len(got) != 1 {\n\t\t\t\t\tt.Fatalf(\"wrong traversal length %d; want 1\", len(got))\n\t\t\t\t}\n\t\t\t\tgotRoot, ok := got[0].(TraverseRoot)\n\t\t\t\tif !ok {\n\t\t\t\t\tt.Fatalf(\"first traversal step is %T; want hcl.TraverseRoot\", got[0])\n\t\t\t\t}\n\t\t\t\tif gotRoot.Name != test.WantRootName {\n\t\t\t\t\tt.Errorf(\"wrong root name %q; want %q\", gotRoot.Name, test.WantRootName)\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\tif !diags.HasErrors() {\n\t\t\t\t\tt.Errorf(\"returned nil traversal without error diagnostics\")\n\t\t\t\t}\n\t\t\t\tif test.WantRootName != \"\" {\n\t\t\t\t\tt.Errorf(\"traversal was not returned; want TraverseRoot(%q)\", test.WantRootName)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestRelTraversalForExpr(t *testing.T) {\n\ttests := []struct {\n\t\tExpr          Expression\n\t\tWantFirstName string\n\t}{\n\t\t{\n\t\t\tasTraversalSupported{RootName: \"foo\"},\n\t\t\t\"foo\",\n\t\t},\n\t\t{\n\t\t\tasTraversalNotSupported{},\n\t\t\t\"\",\n\t\t},\n\t\t{\n\t\t\tasTraversalDeclined{},\n\t\t\t\"\",\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tt.Run(\"\", func(t *testing.T) {\n\t\t\tgot, diags := RelTraversalForExpr(test.Expr)\n\t\t\tswitch {\n\t\t\tcase got != nil:\n\t\t\t\tif test.WantFirstName == \"\" {\n\t\t\t\t\tt.Fatalf(\"traversal was returned; want error\")\n\t\t\t\t}\n\t\t\t\tif len(got) != 1 {\n\t\t\t\t\tt.Fatalf(\"wrong traversal length %d; want 1\", len(got))\n\t\t\t\t}\n\t\t\t\tgotRoot, ok := got[0].(TraverseAttr)\n\t\t\t\tif !ok {\n\t\t\t\t\tt.Fatalf(\"first traversal step is %T; want hcl.TraverseAttr\", got[0])\n\t\t\t\t}\n\t\t\t\tif gotRoot.Name != test.WantFirstName {\n\t\t\t\t\tt.Errorf(\"wrong root name %q; want %q\", gotRoot.Name, test.WantFirstName)\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\tif !diags.HasErrors() {\n\t\t\t\t\tt.Errorf(\"returned nil traversal without error diagnostics\")\n\t\t\t\t}\n\t\t\t\tif test.WantFirstName != \"\" {\n\t\t\t\t\tt.Errorf(\"traversal was not returned; want TraverseAttr(%q)\", test.WantFirstName)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestExprAsKeyword(t *testing.T) {\n\ttests := []struct {\n\t\tExpr Expression\n\t\tWant string\n\t}{\n\t\t{\n\t\t\tasTraversalSupported{RootName: \"foo\"},\n\t\t\t\"foo\",\n\t\t},\n\t\t{\n\t\t\tasTraversalSupportedAttr{\n\t\t\t\tRootName: \"foo\",\n\t\t\t\tAttrName: \"bar\",\n\t\t\t},\n\t\t\t\"\",\n\t\t},\n\t\t{\n\t\t\tasTraversalNotSupported{},\n\t\t\t\"\",\n\t\t},\n\t\t{\n\t\t\tasTraversalDeclined{},\n\t\t\t\"\",\n\t\t},\n\t\t{\n\t\t\tasTraversalWrappedDelegated{\n\t\t\t\toriginal: asTraversalSupported{RootName: \"foo\"},\n\t\t\t},\n\t\t\t\"foo\",\n\t\t},\n\t\t{\n\t\t\tasTraversalWrappedDelegated{\n\t\t\t\toriginal: asTraversalWrappedDelegated{\n\t\t\t\t\toriginal: asTraversalSupported{RootName: \"foo\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"foo\",\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tt.Run(\"\", func(t *testing.T) {\n\t\t\tgot := ExprAsKeyword(test.Expr)\n\t\t\tif got != test.Want {\n\t\t\t\tt.Errorf(\"wrong result %q; want %q\\ninput: %T\", got, test.Want, test.Expr)\n\t\t\t}\n\t\t})\n\t}\n}\n"
        }
      ]
    }
  ]
}