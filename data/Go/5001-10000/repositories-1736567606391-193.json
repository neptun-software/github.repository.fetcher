{
  "metadata": {
    "timestamp": 1736567606391,
    "page": 193,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "go-yaml/yaml",
      "stars": 6943,
      "defaultBranch": "v3",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 2.1005859375,
          "content": "\nThis project is covered by two different licenses: MIT and Apache.\n\n#### MIT License ####\n\nThe following files were ported to Go from C files of libyaml, and thus\nare still covered by their original MIT license, with the additional\ncopyright staring in 2011 when the project was ported over:\n\n    apic.go emitterc.go parserc.go readerc.go scannerc.go\n    writerc.go yamlh.go yamlprivateh.go\n\nCopyright (c) 2006-2010 Kirill Simonov\nCopyright (c) 2006-2011 Kirill Simonov\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\nof the Software, and to permit persons to whom the Software is furnished to do\nso, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n### Apache License ###\n\nAll the remaining project files are covered by the Apache license:\n\nCopyright (c) 2011-2019 Canonical Ltd\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n"
        },
        {
          "name": "NOTICE",
          "type": "blob",
          "size": 0.546875,
          "content": "Copyright 2011-2016 Canonical Ltd.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 3.3720703125,
          "content": "# YAML support for the Go language\n\nIntroduction\n------------\n\nThe yaml package enables Go programs to comfortably encode and decode YAML\nvalues. It was developed within [Canonical](https://www.canonical.com) as\npart of the [juju](https://juju.ubuntu.com) project, and is based on a\npure Go port of the well-known [libyaml](http://pyyaml.org/wiki/LibYAML)\nC library to parse and generate YAML data quickly and reliably.\n\nCompatibility\n-------------\n\nThe yaml package supports most of YAML 1.2, but preserves some behavior\nfrom 1.1 for backwards compatibility.\n\nSpecifically, as of v3 of the yaml package:\n\n - YAML 1.1 bools (_yes/no, on/off_) are supported as long as they are being\n   decoded into a typed bool value. Otherwise they behave as a string. Booleans\n   in YAML 1.2 are _true/false_ only.\n - Octals encode and decode as _0777_ per YAML 1.1, rather than _0o777_\n   as specified in YAML 1.2, because most parsers still use the old format.\n   Octals in the  _0o777_ format are supported though, so new files work.\n - Does not support base-60 floats. These are gone from YAML 1.2, and were\n   actually never supported by this package as it's clearly a poor choice.\n\nand offers backwards\ncompatibility with YAML 1.1 in some cases.\n1.2, including support for\nanchors, tags, map merging, etc. Multi-document unmarshalling is not yet\nimplemented, and base-60 floats from YAML 1.1 are purposefully not\nsupported since they're a poor design and are gone in YAML 1.2.\n\nInstallation and usage\n----------------------\n\nThe import path for the package is *gopkg.in/yaml.v3*.\n\nTo install it, run:\n\n    go get gopkg.in/yaml.v3\n\nAPI documentation\n-----------------\n\nIf opened in a browser, the import path itself leads to the API documentation:\n\n  - [https://gopkg.in/yaml.v3](https://gopkg.in/yaml.v3)\n\nAPI stability\n-------------\n\nThe package API for yaml v3 will remain stable as described in [gopkg.in](https://gopkg.in).\n\n\nLicense\n-------\n\nThe yaml package is licensed under the MIT and Apache License 2.0 licenses.\nPlease see the LICENSE file for details.\n\n\nExample\n-------\n\n```Go\npackage main\n\nimport (\n        \"fmt\"\n        \"log\"\n\n        \"gopkg.in/yaml.v3\"\n)\n\nvar data = `\na: Easy!\nb:\n  c: 2\n  d: [3, 4]\n`\n\n// Note: struct fields must be public in order for unmarshal to\n// correctly populate the data.\ntype T struct {\n        A string\n        B struct {\n                RenamedC int   `yaml:\"c\"`\n                D        []int `yaml:\",flow\"`\n        }\n}\n\nfunc main() {\n        t := T{}\n    \n        err := yaml.Unmarshal([]byte(data), &t)\n        if err != nil {\n                log.Fatalf(\"error: %v\", err)\n        }\n        fmt.Printf(\"--- t:\\n%v\\n\\n\", t)\n    \n        d, err := yaml.Marshal(&t)\n        if err != nil {\n                log.Fatalf(\"error: %v\", err)\n        }\n        fmt.Printf(\"--- t dump:\\n%s\\n\\n\", string(d))\n    \n        m := make(map[interface{}]interface{})\n    \n        err = yaml.Unmarshal([]byte(data), &m)\n        if err != nil {\n                log.Fatalf(\"error: %v\", err)\n        }\n        fmt.Printf(\"--- m:\\n%v\\n\\n\", m)\n    \n        d, err = yaml.Marshal(&m)\n        if err != nil {\n                log.Fatalf(\"error: %v\", err)\n        }\n        fmt.Printf(\"--- m dump:\\n%s\\n\\n\", string(d))\n}\n```\n\nThis example will generate the following output:\n\n```\n--- t:\n{Easy! {2 [3 4]}}\n\n--- t dump:\na: Easy!\nb:\n  c: 2\n  d: [3, 4]\n\n\n--- m:\nmap[a:Easy! b:map[c:2 d:[3 4]]]\n\n--- m dump:\na: Easy!\nb:\n  c: 2\n  d:\n  - 3\n  - 4\n```\n\n"
        },
        {
          "name": "apic.go",
          "type": "blob",
          "size": 21.4833984375,
          "content": "// \n// Copyright (c) 2011-2019 Canonical Ltd\n// Copyright (c) 2006-2010 Kirill Simonov\n// \n// Permission is hereby granted, free of charge, to any person obtaining a copy of\n// this software and associated documentation files (the \"Software\"), to deal in\n// the Software without restriction, including without limitation the rights to\n// use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\n// of the Software, and to permit persons to whom the Software is furnished to do\n// so, subject to the following conditions:\n// \n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n// \n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\npackage yaml\n\nimport (\n\t\"io\"\n)\n\nfunc yaml_insert_token(parser *yaml_parser_t, pos int, token *yaml_token_t) {\n\t//fmt.Println(\"yaml_insert_token\", \"pos:\", pos, \"typ:\", token.typ, \"head:\", parser.tokens_head, \"len:\", len(parser.tokens))\n\n\t// Check if we can move the queue at the beginning of the buffer.\n\tif parser.tokens_head > 0 && len(parser.tokens) == cap(parser.tokens) {\n\t\tif parser.tokens_head != len(parser.tokens) {\n\t\t\tcopy(parser.tokens, parser.tokens[parser.tokens_head:])\n\t\t}\n\t\tparser.tokens = parser.tokens[:len(parser.tokens)-parser.tokens_head]\n\t\tparser.tokens_head = 0\n\t}\n\tparser.tokens = append(parser.tokens, *token)\n\tif pos < 0 {\n\t\treturn\n\t}\n\tcopy(parser.tokens[parser.tokens_head+pos+1:], parser.tokens[parser.tokens_head+pos:])\n\tparser.tokens[parser.tokens_head+pos] = *token\n}\n\n// Create a new parser object.\nfunc yaml_parser_initialize(parser *yaml_parser_t) bool {\n\t*parser = yaml_parser_t{\n\t\traw_buffer: make([]byte, 0, input_raw_buffer_size),\n\t\tbuffer:     make([]byte, 0, input_buffer_size),\n\t}\n\treturn true\n}\n\n// Destroy a parser object.\nfunc yaml_parser_delete(parser *yaml_parser_t) {\n\t*parser = yaml_parser_t{}\n}\n\n// String read handler.\nfunc yaml_string_read_handler(parser *yaml_parser_t, buffer []byte) (n int, err error) {\n\tif parser.input_pos == len(parser.input) {\n\t\treturn 0, io.EOF\n\t}\n\tn = copy(buffer, parser.input[parser.input_pos:])\n\tparser.input_pos += n\n\treturn n, nil\n}\n\n// Reader read handler.\nfunc yaml_reader_read_handler(parser *yaml_parser_t, buffer []byte) (n int, err error) {\n\treturn parser.input_reader.Read(buffer)\n}\n\n// Set a string input.\nfunc yaml_parser_set_input_string(parser *yaml_parser_t, input []byte) {\n\tif parser.read_handler != nil {\n\t\tpanic(\"must set the input source only once\")\n\t}\n\tparser.read_handler = yaml_string_read_handler\n\tparser.input = input\n\tparser.input_pos = 0\n}\n\n// Set a file input.\nfunc yaml_parser_set_input_reader(parser *yaml_parser_t, r io.Reader) {\n\tif parser.read_handler != nil {\n\t\tpanic(\"must set the input source only once\")\n\t}\n\tparser.read_handler = yaml_reader_read_handler\n\tparser.input_reader = r\n}\n\n// Set the source encoding.\nfunc yaml_parser_set_encoding(parser *yaml_parser_t, encoding yaml_encoding_t) {\n\tif parser.encoding != yaml_ANY_ENCODING {\n\t\tpanic(\"must set the encoding only once\")\n\t}\n\tparser.encoding = encoding\n}\n\n// Create a new emitter object.\nfunc yaml_emitter_initialize(emitter *yaml_emitter_t) {\n\t*emitter = yaml_emitter_t{\n\t\tbuffer:     make([]byte, output_buffer_size),\n\t\traw_buffer: make([]byte, 0, output_raw_buffer_size),\n\t\tstates:     make([]yaml_emitter_state_t, 0, initial_stack_size),\n\t\tevents:     make([]yaml_event_t, 0, initial_queue_size),\n\t\tbest_width: -1,\n\t}\n}\n\n// Destroy an emitter object.\nfunc yaml_emitter_delete(emitter *yaml_emitter_t) {\n\t*emitter = yaml_emitter_t{}\n}\n\n// String write handler.\nfunc yaml_string_write_handler(emitter *yaml_emitter_t, buffer []byte) error {\n\t*emitter.output_buffer = append(*emitter.output_buffer, buffer...)\n\treturn nil\n}\n\n// yaml_writer_write_handler uses emitter.output_writer to write the\n// emitted text.\nfunc yaml_writer_write_handler(emitter *yaml_emitter_t, buffer []byte) error {\n\t_, err := emitter.output_writer.Write(buffer)\n\treturn err\n}\n\n// Set a string output.\nfunc yaml_emitter_set_output_string(emitter *yaml_emitter_t, output_buffer *[]byte) {\n\tif emitter.write_handler != nil {\n\t\tpanic(\"must set the output target only once\")\n\t}\n\temitter.write_handler = yaml_string_write_handler\n\temitter.output_buffer = output_buffer\n}\n\n// Set a file output.\nfunc yaml_emitter_set_output_writer(emitter *yaml_emitter_t, w io.Writer) {\n\tif emitter.write_handler != nil {\n\t\tpanic(\"must set the output target only once\")\n\t}\n\temitter.write_handler = yaml_writer_write_handler\n\temitter.output_writer = w\n}\n\n// Set the output encoding.\nfunc yaml_emitter_set_encoding(emitter *yaml_emitter_t, encoding yaml_encoding_t) {\n\tif emitter.encoding != yaml_ANY_ENCODING {\n\t\tpanic(\"must set the output encoding only once\")\n\t}\n\temitter.encoding = encoding\n}\n\n// Set the canonical output style.\nfunc yaml_emitter_set_canonical(emitter *yaml_emitter_t, canonical bool) {\n\temitter.canonical = canonical\n}\n\n// Set the indentation increment.\nfunc yaml_emitter_set_indent(emitter *yaml_emitter_t, indent int) {\n\tif indent < 2 || indent > 9 {\n\t\tindent = 2\n\t}\n\temitter.best_indent = indent\n}\n\n// Set the preferred line width.\nfunc yaml_emitter_set_width(emitter *yaml_emitter_t, width int) {\n\tif width < 0 {\n\t\twidth = -1\n\t}\n\temitter.best_width = width\n}\n\n// Set if unescaped non-ASCII characters are allowed.\nfunc yaml_emitter_set_unicode(emitter *yaml_emitter_t, unicode bool) {\n\temitter.unicode = unicode\n}\n\n// Set the preferred line break character.\nfunc yaml_emitter_set_break(emitter *yaml_emitter_t, line_break yaml_break_t) {\n\temitter.line_break = line_break\n}\n\n///*\n// * Destroy a token object.\n// */\n//\n//YAML_DECLARE(void)\n//yaml_token_delete(yaml_token_t *token)\n//{\n//    assert(token);  // Non-NULL token object expected.\n//\n//    switch (token.type)\n//    {\n//        case YAML_TAG_DIRECTIVE_TOKEN:\n//            yaml_free(token.data.tag_directive.handle);\n//            yaml_free(token.data.tag_directive.prefix);\n//            break;\n//\n//        case YAML_ALIAS_TOKEN:\n//            yaml_free(token.data.alias.value);\n//            break;\n//\n//        case YAML_ANCHOR_TOKEN:\n//            yaml_free(token.data.anchor.value);\n//            break;\n//\n//        case YAML_TAG_TOKEN:\n//            yaml_free(token.data.tag.handle);\n//            yaml_free(token.data.tag.suffix);\n//            break;\n//\n//        case YAML_SCALAR_TOKEN:\n//            yaml_free(token.data.scalar.value);\n//            break;\n//\n//        default:\n//            break;\n//    }\n//\n//    memset(token, 0, sizeof(yaml_token_t));\n//}\n//\n///*\n// * Check if a string is a valid UTF-8 sequence.\n// *\n// * Check 'reader.c' for more details on UTF-8 encoding.\n// */\n//\n//static int\n//yaml_check_utf8(yaml_char_t *start, size_t length)\n//{\n//    yaml_char_t *end = start+length;\n//    yaml_char_t *pointer = start;\n//\n//    while (pointer < end) {\n//        unsigned char octet;\n//        unsigned int width;\n//        unsigned int value;\n//        size_t k;\n//\n//        octet = pointer[0];\n//        width = (octet & 0x80) == 0x00 ? 1 :\n//                (octet & 0xE0) == 0xC0 ? 2 :\n//                (octet & 0xF0) == 0xE0 ? 3 :\n//                (octet & 0xF8) == 0xF0 ? 4 : 0;\n//        value = (octet & 0x80) == 0x00 ? octet & 0x7F :\n//                (octet & 0xE0) == 0xC0 ? octet & 0x1F :\n//                (octet & 0xF0) == 0xE0 ? octet & 0x0F :\n//                (octet & 0xF8) == 0xF0 ? octet & 0x07 : 0;\n//        if (!width) return 0;\n//        if (pointer+width > end) return 0;\n//        for (k = 1; k < width; k ++) {\n//            octet = pointer[k];\n//            if ((octet & 0xC0) != 0x80) return 0;\n//            value = (value << 6) + (octet & 0x3F);\n//        }\n//        if (!((width == 1) ||\n//            (width == 2 && value >= 0x80) ||\n//            (width == 3 && value >= 0x800) ||\n//            (width == 4 && value >= 0x10000))) return 0;\n//\n//        pointer += width;\n//    }\n//\n//    return 1;\n//}\n//\n\n// Create STREAM-START.\nfunc yaml_stream_start_event_initialize(event *yaml_event_t, encoding yaml_encoding_t) {\n\t*event = yaml_event_t{\n\t\ttyp:      yaml_STREAM_START_EVENT,\n\t\tencoding: encoding,\n\t}\n}\n\n// Create STREAM-END.\nfunc yaml_stream_end_event_initialize(event *yaml_event_t) {\n\t*event = yaml_event_t{\n\t\ttyp: yaml_STREAM_END_EVENT,\n\t}\n}\n\n// Create DOCUMENT-START.\nfunc yaml_document_start_event_initialize(\n\tevent *yaml_event_t,\n\tversion_directive *yaml_version_directive_t,\n\ttag_directives []yaml_tag_directive_t,\n\timplicit bool,\n) {\n\t*event = yaml_event_t{\n\t\ttyp:               yaml_DOCUMENT_START_EVENT,\n\t\tversion_directive: version_directive,\n\t\ttag_directives:    tag_directives,\n\t\timplicit:          implicit,\n\t}\n}\n\n// Create DOCUMENT-END.\nfunc yaml_document_end_event_initialize(event *yaml_event_t, implicit bool) {\n\t*event = yaml_event_t{\n\t\ttyp:      yaml_DOCUMENT_END_EVENT,\n\t\timplicit: implicit,\n\t}\n}\n\n// Create ALIAS.\nfunc yaml_alias_event_initialize(event *yaml_event_t, anchor []byte) bool {\n\t*event = yaml_event_t{\n\t\ttyp:    yaml_ALIAS_EVENT,\n\t\tanchor: anchor,\n\t}\n\treturn true\n}\n\n// Create SCALAR.\nfunc yaml_scalar_event_initialize(event *yaml_event_t, anchor, tag, value []byte, plain_implicit, quoted_implicit bool, style yaml_scalar_style_t) bool {\n\t*event = yaml_event_t{\n\t\ttyp:             yaml_SCALAR_EVENT,\n\t\tanchor:          anchor,\n\t\ttag:             tag,\n\t\tvalue:           value,\n\t\timplicit:        plain_implicit,\n\t\tquoted_implicit: quoted_implicit,\n\t\tstyle:           yaml_style_t(style),\n\t}\n\treturn true\n}\n\n// Create SEQUENCE-START.\nfunc yaml_sequence_start_event_initialize(event *yaml_event_t, anchor, tag []byte, implicit bool, style yaml_sequence_style_t) bool {\n\t*event = yaml_event_t{\n\t\ttyp:      yaml_SEQUENCE_START_EVENT,\n\t\tanchor:   anchor,\n\t\ttag:      tag,\n\t\timplicit: implicit,\n\t\tstyle:    yaml_style_t(style),\n\t}\n\treturn true\n}\n\n// Create SEQUENCE-END.\nfunc yaml_sequence_end_event_initialize(event *yaml_event_t) bool {\n\t*event = yaml_event_t{\n\t\ttyp: yaml_SEQUENCE_END_EVENT,\n\t}\n\treturn true\n}\n\n// Create MAPPING-START.\nfunc yaml_mapping_start_event_initialize(event *yaml_event_t, anchor, tag []byte, implicit bool, style yaml_mapping_style_t) {\n\t*event = yaml_event_t{\n\t\ttyp:      yaml_MAPPING_START_EVENT,\n\t\tanchor:   anchor,\n\t\ttag:      tag,\n\t\timplicit: implicit,\n\t\tstyle:    yaml_style_t(style),\n\t}\n}\n\n// Create MAPPING-END.\nfunc yaml_mapping_end_event_initialize(event *yaml_event_t) {\n\t*event = yaml_event_t{\n\t\ttyp: yaml_MAPPING_END_EVENT,\n\t}\n}\n\n// Destroy an event object.\nfunc yaml_event_delete(event *yaml_event_t) {\n\t*event = yaml_event_t{}\n}\n\n///*\n// * Create a document object.\n// */\n//\n//YAML_DECLARE(int)\n//yaml_document_initialize(document *yaml_document_t,\n//        version_directive *yaml_version_directive_t,\n//        tag_directives_start *yaml_tag_directive_t,\n//        tag_directives_end *yaml_tag_directive_t,\n//        start_implicit int, end_implicit int)\n//{\n//    struct {\n//        error yaml_error_type_t\n//    } context\n//    struct {\n//        start *yaml_node_t\n//        end *yaml_node_t\n//        top *yaml_node_t\n//    } nodes = { NULL, NULL, NULL }\n//    version_directive_copy *yaml_version_directive_t = NULL\n//    struct {\n//        start *yaml_tag_directive_t\n//        end *yaml_tag_directive_t\n//        top *yaml_tag_directive_t\n//    } tag_directives_copy = { NULL, NULL, NULL }\n//    value yaml_tag_directive_t = { NULL, NULL }\n//    mark yaml_mark_t = { 0, 0, 0 }\n//\n//    assert(document) // Non-NULL document object is expected.\n//    assert((tag_directives_start && tag_directives_end) ||\n//            (tag_directives_start == tag_directives_end))\n//                            // Valid tag directives are expected.\n//\n//    if (!STACK_INIT(&context, nodes, INITIAL_STACK_SIZE)) goto error\n//\n//    if (version_directive) {\n//        version_directive_copy = yaml_malloc(sizeof(yaml_version_directive_t))\n//        if (!version_directive_copy) goto error\n//        version_directive_copy.major = version_directive.major\n//        version_directive_copy.minor = version_directive.minor\n//    }\n//\n//    if (tag_directives_start != tag_directives_end) {\n//        tag_directive *yaml_tag_directive_t\n//        if (!STACK_INIT(&context, tag_directives_copy, INITIAL_STACK_SIZE))\n//            goto error\n//        for (tag_directive = tag_directives_start\n//                tag_directive != tag_directives_end; tag_directive ++) {\n//            assert(tag_directive.handle)\n//            assert(tag_directive.prefix)\n//            if (!yaml_check_utf8(tag_directive.handle,\n//                        strlen((char *)tag_directive.handle)))\n//                goto error\n//            if (!yaml_check_utf8(tag_directive.prefix,\n//                        strlen((char *)tag_directive.prefix)))\n//                goto error\n//            value.handle = yaml_strdup(tag_directive.handle)\n//            value.prefix = yaml_strdup(tag_directive.prefix)\n//            if (!value.handle || !value.prefix) goto error\n//            if (!PUSH(&context, tag_directives_copy, value))\n//                goto error\n//            value.handle = NULL\n//            value.prefix = NULL\n//        }\n//    }\n//\n//    DOCUMENT_INIT(*document, nodes.start, nodes.end, version_directive_copy,\n//            tag_directives_copy.start, tag_directives_copy.top,\n//            start_implicit, end_implicit, mark, mark)\n//\n//    return 1\n//\n//error:\n//    STACK_DEL(&context, nodes)\n//    yaml_free(version_directive_copy)\n//    while (!STACK_EMPTY(&context, tag_directives_copy)) {\n//        value yaml_tag_directive_t = POP(&context, tag_directives_copy)\n//        yaml_free(value.handle)\n//        yaml_free(value.prefix)\n//    }\n//    STACK_DEL(&context, tag_directives_copy)\n//    yaml_free(value.handle)\n//    yaml_free(value.prefix)\n//\n//    return 0\n//}\n//\n///*\n// * Destroy a document object.\n// */\n//\n//YAML_DECLARE(void)\n//yaml_document_delete(document *yaml_document_t)\n//{\n//    struct {\n//        error yaml_error_type_t\n//    } context\n//    tag_directive *yaml_tag_directive_t\n//\n//    context.error = YAML_NO_ERROR // Eliminate a compiler warning.\n//\n//    assert(document) // Non-NULL document object is expected.\n//\n//    while (!STACK_EMPTY(&context, document.nodes)) {\n//        node yaml_node_t = POP(&context, document.nodes)\n//        yaml_free(node.tag)\n//        switch (node.type) {\n//            case YAML_SCALAR_NODE:\n//                yaml_free(node.data.scalar.value)\n//                break\n//            case YAML_SEQUENCE_NODE:\n//                STACK_DEL(&context, node.data.sequence.items)\n//                break\n//            case YAML_MAPPING_NODE:\n//                STACK_DEL(&context, node.data.mapping.pairs)\n//                break\n//            default:\n//                assert(0) // Should not happen.\n//        }\n//    }\n//    STACK_DEL(&context, document.nodes)\n//\n//    yaml_free(document.version_directive)\n//    for (tag_directive = document.tag_directives.start\n//            tag_directive != document.tag_directives.end\n//            tag_directive++) {\n//        yaml_free(tag_directive.handle)\n//        yaml_free(tag_directive.prefix)\n//    }\n//    yaml_free(document.tag_directives.start)\n//\n//    memset(document, 0, sizeof(yaml_document_t))\n//}\n//\n///**\n// * Get a document node.\n// */\n//\n//YAML_DECLARE(yaml_node_t *)\n//yaml_document_get_node(document *yaml_document_t, index int)\n//{\n//    assert(document) // Non-NULL document object is expected.\n//\n//    if (index > 0 && document.nodes.start + index <= document.nodes.top) {\n//        return document.nodes.start + index - 1\n//    }\n//    return NULL\n//}\n//\n///**\n// * Get the root object.\n// */\n//\n//YAML_DECLARE(yaml_node_t *)\n//yaml_document_get_root_node(document *yaml_document_t)\n//{\n//    assert(document) // Non-NULL document object is expected.\n//\n//    if (document.nodes.top != document.nodes.start) {\n//        return document.nodes.start\n//    }\n//    return NULL\n//}\n//\n///*\n// * Add a scalar node to a document.\n// */\n//\n//YAML_DECLARE(int)\n//yaml_document_add_scalar(document *yaml_document_t,\n//        tag *yaml_char_t, value *yaml_char_t, length int,\n//        style yaml_scalar_style_t)\n//{\n//    struct {\n//        error yaml_error_type_t\n//    } context\n//    mark yaml_mark_t = { 0, 0, 0 }\n//    tag_copy *yaml_char_t = NULL\n//    value_copy *yaml_char_t = NULL\n//    node yaml_node_t\n//\n//    assert(document) // Non-NULL document object is expected.\n//    assert(value) // Non-NULL value is expected.\n//\n//    if (!tag) {\n//        tag = (yaml_char_t *)YAML_DEFAULT_SCALAR_TAG\n//    }\n//\n//    if (!yaml_check_utf8(tag, strlen((char *)tag))) goto error\n//    tag_copy = yaml_strdup(tag)\n//    if (!tag_copy) goto error\n//\n//    if (length < 0) {\n//        length = strlen((char *)value)\n//    }\n//\n//    if (!yaml_check_utf8(value, length)) goto error\n//    value_copy = yaml_malloc(length+1)\n//    if (!value_copy) goto error\n//    memcpy(value_copy, value, length)\n//    value_copy[length] = '\\0'\n//\n//    SCALAR_NODE_INIT(node, tag_copy, value_copy, length, style, mark, mark)\n//    if (!PUSH(&context, document.nodes, node)) goto error\n//\n//    return document.nodes.top - document.nodes.start\n//\n//error:\n//    yaml_free(tag_copy)\n//    yaml_free(value_copy)\n//\n//    return 0\n//}\n//\n///*\n// * Add a sequence node to a document.\n// */\n//\n//YAML_DECLARE(int)\n//yaml_document_add_sequence(document *yaml_document_t,\n//        tag *yaml_char_t, style yaml_sequence_style_t)\n//{\n//    struct {\n//        error yaml_error_type_t\n//    } context\n//    mark yaml_mark_t = { 0, 0, 0 }\n//    tag_copy *yaml_char_t = NULL\n//    struct {\n//        start *yaml_node_item_t\n//        end *yaml_node_item_t\n//        top *yaml_node_item_t\n//    } items = { NULL, NULL, NULL }\n//    node yaml_node_t\n//\n//    assert(document) // Non-NULL document object is expected.\n//\n//    if (!tag) {\n//        tag = (yaml_char_t *)YAML_DEFAULT_SEQUENCE_TAG\n//    }\n//\n//    if (!yaml_check_utf8(tag, strlen((char *)tag))) goto error\n//    tag_copy = yaml_strdup(tag)\n//    if (!tag_copy) goto error\n//\n//    if (!STACK_INIT(&context, items, INITIAL_STACK_SIZE)) goto error\n//\n//    SEQUENCE_NODE_INIT(node, tag_copy, items.start, items.end,\n//            style, mark, mark)\n//    if (!PUSH(&context, document.nodes, node)) goto error\n//\n//    return document.nodes.top - document.nodes.start\n//\n//error:\n//    STACK_DEL(&context, items)\n//    yaml_free(tag_copy)\n//\n//    return 0\n//}\n//\n///*\n// * Add a mapping node to a document.\n// */\n//\n//YAML_DECLARE(int)\n//yaml_document_add_mapping(document *yaml_document_t,\n//        tag *yaml_char_t, style yaml_mapping_style_t)\n//{\n//    struct {\n//        error yaml_error_type_t\n//    } context\n//    mark yaml_mark_t = { 0, 0, 0 }\n//    tag_copy *yaml_char_t = NULL\n//    struct {\n//        start *yaml_node_pair_t\n//        end *yaml_node_pair_t\n//        top *yaml_node_pair_t\n//    } pairs = { NULL, NULL, NULL }\n//    node yaml_node_t\n//\n//    assert(document) // Non-NULL document object is expected.\n//\n//    if (!tag) {\n//        tag = (yaml_char_t *)YAML_DEFAULT_MAPPING_TAG\n//    }\n//\n//    if (!yaml_check_utf8(tag, strlen((char *)tag))) goto error\n//    tag_copy = yaml_strdup(tag)\n//    if (!tag_copy) goto error\n//\n//    if (!STACK_INIT(&context, pairs, INITIAL_STACK_SIZE)) goto error\n//\n//    MAPPING_NODE_INIT(node, tag_copy, pairs.start, pairs.end,\n//            style, mark, mark)\n//    if (!PUSH(&context, document.nodes, node)) goto error\n//\n//    return document.nodes.top - document.nodes.start\n//\n//error:\n//    STACK_DEL(&context, pairs)\n//    yaml_free(tag_copy)\n//\n//    return 0\n//}\n//\n///*\n// * Append an item to a sequence node.\n// */\n//\n//YAML_DECLARE(int)\n//yaml_document_append_sequence_item(document *yaml_document_t,\n//        sequence int, item int)\n//{\n//    struct {\n//        error yaml_error_type_t\n//    } context\n//\n//    assert(document) // Non-NULL document is required.\n//    assert(sequence > 0\n//            && document.nodes.start + sequence <= document.nodes.top)\n//                            // Valid sequence id is required.\n//    assert(document.nodes.start[sequence-1].type == YAML_SEQUENCE_NODE)\n//                            // A sequence node is required.\n//    assert(item > 0 && document.nodes.start + item <= document.nodes.top)\n//                            // Valid item id is required.\n//\n//    if (!PUSH(&context,\n//                document.nodes.start[sequence-1].data.sequence.items, item))\n//        return 0\n//\n//    return 1\n//}\n//\n///*\n// * Append a pair of a key and a value to a mapping node.\n// */\n//\n//YAML_DECLARE(int)\n//yaml_document_append_mapping_pair(document *yaml_document_t,\n//        mapping int, key int, value int)\n//{\n//    struct {\n//        error yaml_error_type_t\n//    } context\n//\n//    pair yaml_node_pair_t\n//\n//    assert(document) // Non-NULL document is required.\n//    assert(mapping > 0\n//            && document.nodes.start + mapping <= document.nodes.top)\n//                            // Valid mapping id is required.\n//    assert(document.nodes.start[mapping-1].type == YAML_MAPPING_NODE)\n//                            // A mapping node is required.\n//    assert(key > 0 && document.nodes.start + key <= document.nodes.top)\n//                            // Valid key id is required.\n//    assert(value > 0 && document.nodes.start + value <= document.nodes.top)\n//                            // Valid value id is required.\n//\n//    pair.key = key\n//    pair.value = value\n//\n//    if (!PUSH(&context,\n//                document.nodes.start[mapping-1].data.mapping.pairs, pair))\n//        return 0\n//\n//    return 1\n//}\n//\n//\n"
        },
        {
          "name": "decode.go",
          "type": "blob",
          "size": 24.3681640625,
          "content": "//\n// Copyright (c) 2011-2019 Canonical Ltd\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage yaml\n\nimport (\n\t\"encoding\"\n\t\"encoding/base64\"\n\t\"fmt\"\n\t\"io\"\n\t\"math\"\n\t\"reflect\"\n\t\"strconv\"\n\t\"time\"\n)\n\n// ----------------------------------------------------------------------------\n// Parser, produces a node tree out of a libyaml event stream.\n\ntype parser struct {\n\tparser   yaml_parser_t\n\tevent    yaml_event_t\n\tdoc      *Node\n\tanchors  map[string]*Node\n\tdoneInit bool\n\ttextless bool\n}\n\nfunc newParser(b []byte) *parser {\n\tp := parser{}\n\tif !yaml_parser_initialize(&p.parser) {\n\t\tpanic(\"failed to initialize YAML emitter\")\n\t}\n\tif len(b) == 0 {\n\t\tb = []byte{'\\n'}\n\t}\n\tyaml_parser_set_input_string(&p.parser, b)\n\treturn &p\n}\n\nfunc newParserFromReader(r io.Reader) *parser {\n\tp := parser{}\n\tif !yaml_parser_initialize(&p.parser) {\n\t\tpanic(\"failed to initialize YAML emitter\")\n\t}\n\tyaml_parser_set_input_reader(&p.parser, r)\n\treturn &p\n}\n\nfunc (p *parser) init() {\n\tif p.doneInit {\n\t\treturn\n\t}\n\tp.anchors = make(map[string]*Node)\n\tp.expect(yaml_STREAM_START_EVENT)\n\tp.doneInit = true\n}\n\nfunc (p *parser) destroy() {\n\tif p.event.typ != yaml_NO_EVENT {\n\t\tyaml_event_delete(&p.event)\n\t}\n\tyaml_parser_delete(&p.parser)\n}\n\n// expect consumes an event from the event stream and\n// checks that it's of the expected type.\nfunc (p *parser) expect(e yaml_event_type_t) {\n\tif p.event.typ == yaml_NO_EVENT {\n\t\tif !yaml_parser_parse(&p.parser, &p.event) {\n\t\t\tp.fail()\n\t\t}\n\t}\n\tif p.event.typ == yaml_STREAM_END_EVENT {\n\t\tfailf(\"attempted to go past the end of stream; corrupted value?\")\n\t}\n\tif p.event.typ != e {\n\t\tp.parser.problem = fmt.Sprintf(\"expected %s event but got %s\", e, p.event.typ)\n\t\tp.fail()\n\t}\n\tyaml_event_delete(&p.event)\n\tp.event.typ = yaml_NO_EVENT\n}\n\n// peek peeks at the next event in the event stream,\n// puts the results into p.event and returns the event type.\nfunc (p *parser) peek() yaml_event_type_t {\n\tif p.event.typ != yaml_NO_EVENT {\n\t\treturn p.event.typ\n\t}\n\t// It's curious choice from the underlying API to generally return a\n\t// positive result on success, but on this case return true in an error\n\t// scenario. This was the source of bugs in the past (issue #666).\n\tif !yaml_parser_parse(&p.parser, &p.event) || p.parser.error != yaml_NO_ERROR {\n\t\tp.fail()\n\t}\n\treturn p.event.typ\n}\n\nfunc (p *parser) fail() {\n\tvar where string\n\tvar line int\n\tif p.parser.context_mark.line != 0 {\n\t\tline = p.parser.context_mark.line\n\t\t// Scanner errors don't iterate line before returning error\n\t\tif p.parser.error == yaml_SCANNER_ERROR {\n\t\t\tline++\n\t\t}\n\t} else if p.parser.problem_mark.line != 0 {\n\t\tline = p.parser.problem_mark.line\n\t\t// Scanner errors don't iterate line before returning error\n\t\tif p.parser.error == yaml_SCANNER_ERROR {\n\t\t\tline++\n\t\t}\n\t}\n\tif line != 0 {\n\t\twhere = \"line \" + strconv.Itoa(line) + \": \"\n\t}\n\tvar msg string\n\tif len(p.parser.problem) > 0 {\n\t\tmsg = p.parser.problem\n\t} else {\n\t\tmsg = \"unknown problem parsing YAML content\"\n\t}\n\tfailf(\"%s%s\", where, msg)\n}\n\nfunc (p *parser) anchor(n *Node, anchor []byte) {\n\tif anchor != nil {\n\t\tn.Anchor = string(anchor)\n\t\tp.anchors[n.Anchor] = n\n\t}\n}\n\nfunc (p *parser) parse() *Node {\n\tp.init()\n\tswitch p.peek() {\n\tcase yaml_SCALAR_EVENT:\n\t\treturn p.scalar()\n\tcase yaml_ALIAS_EVENT:\n\t\treturn p.alias()\n\tcase yaml_MAPPING_START_EVENT:\n\t\treturn p.mapping()\n\tcase yaml_SEQUENCE_START_EVENT:\n\t\treturn p.sequence()\n\tcase yaml_DOCUMENT_START_EVENT:\n\t\treturn p.document()\n\tcase yaml_STREAM_END_EVENT:\n\t\t// Happens when attempting to decode an empty buffer.\n\t\treturn nil\n\tcase yaml_TAIL_COMMENT_EVENT:\n\t\tpanic(\"internal error: unexpected tail comment event (please report)\")\n\tdefault:\n\t\tpanic(\"internal error: attempted to parse unknown event (please report): \" + p.event.typ.String())\n\t}\n}\n\nfunc (p *parser) node(kind Kind, defaultTag, tag, value string) *Node {\n\tvar style Style\n\tif tag != \"\" && tag != \"!\" {\n\t\ttag = shortTag(tag)\n\t\tstyle = TaggedStyle\n\t} else if defaultTag != \"\" {\n\t\ttag = defaultTag\n\t} else if kind == ScalarNode {\n\t\ttag, _ = resolve(\"\", value)\n\t}\n\tn := &Node{\n\t\tKind:  kind,\n\t\tTag:   tag,\n\t\tValue: value,\n\t\tStyle: style,\n\t}\n\tif !p.textless {\n\t\tn.Line = p.event.start_mark.line + 1\n\t\tn.Column = p.event.start_mark.column + 1\n\t\tn.HeadComment = string(p.event.head_comment)\n\t\tn.LineComment = string(p.event.line_comment)\n\t\tn.FootComment = string(p.event.foot_comment)\n\t}\n\treturn n\n}\n\nfunc (p *parser) parseChild(parent *Node) *Node {\n\tchild := p.parse()\n\tparent.Content = append(parent.Content, child)\n\treturn child\n}\n\nfunc (p *parser) document() *Node {\n\tn := p.node(DocumentNode, \"\", \"\", \"\")\n\tp.doc = n\n\tp.expect(yaml_DOCUMENT_START_EVENT)\n\tp.parseChild(n)\n\tif p.peek() == yaml_DOCUMENT_END_EVENT {\n\t\tn.FootComment = string(p.event.foot_comment)\n\t}\n\tp.expect(yaml_DOCUMENT_END_EVENT)\n\treturn n\n}\n\nfunc (p *parser) alias() *Node {\n\tn := p.node(AliasNode, \"\", \"\", string(p.event.anchor))\n\tn.Alias = p.anchors[n.Value]\n\tif n.Alias == nil {\n\t\tfailf(\"unknown anchor '%s' referenced\", n.Value)\n\t}\n\tp.expect(yaml_ALIAS_EVENT)\n\treturn n\n}\n\nfunc (p *parser) scalar() *Node {\n\tvar parsedStyle = p.event.scalar_style()\n\tvar nodeStyle Style\n\tswitch {\n\tcase parsedStyle&yaml_DOUBLE_QUOTED_SCALAR_STYLE != 0:\n\t\tnodeStyle = DoubleQuotedStyle\n\tcase parsedStyle&yaml_SINGLE_QUOTED_SCALAR_STYLE != 0:\n\t\tnodeStyle = SingleQuotedStyle\n\tcase parsedStyle&yaml_LITERAL_SCALAR_STYLE != 0:\n\t\tnodeStyle = LiteralStyle\n\tcase parsedStyle&yaml_FOLDED_SCALAR_STYLE != 0:\n\t\tnodeStyle = FoldedStyle\n\t}\n\tvar nodeValue = string(p.event.value)\n\tvar nodeTag = string(p.event.tag)\n\tvar defaultTag string\n\tif nodeStyle == 0 {\n\t\tif nodeValue == \"<<\" {\n\t\t\tdefaultTag = mergeTag\n\t\t}\n\t} else {\n\t\tdefaultTag = strTag\n\t}\n\tn := p.node(ScalarNode, defaultTag, nodeTag, nodeValue)\n\tn.Style |= nodeStyle\n\tp.anchor(n, p.event.anchor)\n\tp.expect(yaml_SCALAR_EVENT)\n\treturn n\n}\n\nfunc (p *parser) sequence() *Node {\n\tn := p.node(SequenceNode, seqTag, string(p.event.tag), \"\")\n\tif p.event.sequence_style()&yaml_FLOW_SEQUENCE_STYLE != 0 {\n\t\tn.Style |= FlowStyle\n\t}\n\tp.anchor(n, p.event.anchor)\n\tp.expect(yaml_SEQUENCE_START_EVENT)\n\tfor p.peek() != yaml_SEQUENCE_END_EVENT {\n\t\tp.parseChild(n)\n\t}\n\tn.LineComment = string(p.event.line_comment)\n\tn.FootComment = string(p.event.foot_comment)\n\tp.expect(yaml_SEQUENCE_END_EVENT)\n\treturn n\n}\n\nfunc (p *parser) mapping() *Node {\n\tn := p.node(MappingNode, mapTag, string(p.event.tag), \"\")\n\tblock := true\n\tif p.event.mapping_style()&yaml_FLOW_MAPPING_STYLE != 0 {\n\t\tblock = false\n\t\tn.Style |= FlowStyle\n\t}\n\tp.anchor(n, p.event.anchor)\n\tp.expect(yaml_MAPPING_START_EVENT)\n\tfor p.peek() != yaml_MAPPING_END_EVENT {\n\t\tk := p.parseChild(n)\n\t\tif block && k.FootComment != \"\" {\n\t\t\t// Must be a foot comment for the prior value when being dedented.\n\t\t\tif len(n.Content) > 2 {\n\t\t\t\tn.Content[len(n.Content)-3].FootComment = k.FootComment\n\t\t\t\tk.FootComment = \"\"\n\t\t\t}\n\t\t}\n\t\tv := p.parseChild(n)\n\t\tif k.FootComment == \"\" && v.FootComment != \"\" {\n\t\t\tk.FootComment = v.FootComment\n\t\t\tv.FootComment = \"\"\n\t\t}\n\t\tif p.peek() == yaml_TAIL_COMMENT_EVENT {\n\t\t\tif k.FootComment == \"\" {\n\t\t\t\tk.FootComment = string(p.event.foot_comment)\n\t\t\t}\n\t\t\tp.expect(yaml_TAIL_COMMENT_EVENT)\n\t\t}\n\t}\n\tn.LineComment = string(p.event.line_comment)\n\tn.FootComment = string(p.event.foot_comment)\n\tif n.Style&FlowStyle == 0 && n.FootComment != \"\" && len(n.Content) > 1 {\n\t\tn.Content[len(n.Content)-2].FootComment = n.FootComment\n\t\tn.FootComment = \"\"\n\t}\n\tp.expect(yaml_MAPPING_END_EVENT)\n\treturn n\n}\n\n// ----------------------------------------------------------------------------\n// Decoder, unmarshals a node into a provided value.\n\ntype decoder struct {\n\tdoc     *Node\n\taliases map[*Node]bool\n\tterrors []string\n\n\tstringMapType  reflect.Type\n\tgeneralMapType reflect.Type\n\n\tknownFields bool\n\tuniqueKeys  bool\n\tdecodeCount int\n\taliasCount  int\n\taliasDepth  int\n\n\tmergedFields map[interface{}]bool\n}\n\nvar (\n\tnodeType       = reflect.TypeOf(Node{})\n\tdurationType   = reflect.TypeOf(time.Duration(0))\n\tstringMapType  = reflect.TypeOf(map[string]interface{}{})\n\tgeneralMapType = reflect.TypeOf(map[interface{}]interface{}{})\n\tifaceType      = generalMapType.Elem()\n\ttimeType       = reflect.TypeOf(time.Time{})\n\tptrTimeType    = reflect.TypeOf(&time.Time{})\n)\n\nfunc newDecoder() *decoder {\n\td := &decoder{\n\t\tstringMapType:  stringMapType,\n\t\tgeneralMapType: generalMapType,\n\t\tuniqueKeys:     true,\n\t}\n\td.aliases = make(map[*Node]bool)\n\treturn d\n}\n\nfunc (d *decoder) terror(n *Node, tag string, out reflect.Value) {\n\tif n.Tag != \"\" {\n\t\ttag = n.Tag\n\t}\n\tvalue := n.Value\n\tif tag != seqTag && tag != mapTag {\n\t\tif len(value) > 10 {\n\t\t\tvalue = \" `\" + value[:7] + \"...`\"\n\t\t} else {\n\t\t\tvalue = \" `\" + value + \"`\"\n\t\t}\n\t}\n\td.terrors = append(d.terrors, fmt.Sprintf(\"line %d: cannot unmarshal %s%s into %s\", n.Line, shortTag(tag), value, out.Type()))\n}\n\nfunc (d *decoder) callUnmarshaler(n *Node, u Unmarshaler) (good bool) {\n\terr := u.UnmarshalYAML(n)\n\tif e, ok := err.(*TypeError); ok {\n\t\td.terrors = append(d.terrors, e.Errors...)\n\t\treturn false\n\t}\n\tif err != nil {\n\t\tfail(err)\n\t}\n\treturn true\n}\n\nfunc (d *decoder) callObsoleteUnmarshaler(n *Node, u obsoleteUnmarshaler) (good bool) {\n\tterrlen := len(d.terrors)\n\terr := u.UnmarshalYAML(func(v interface{}) (err error) {\n\t\tdefer handleErr(&err)\n\t\td.unmarshal(n, reflect.ValueOf(v))\n\t\tif len(d.terrors) > terrlen {\n\t\t\tissues := d.terrors[terrlen:]\n\t\t\td.terrors = d.terrors[:terrlen]\n\t\t\treturn &TypeError{issues}\n\t\t}\n\t\treturn nil\n\t})\n\tif e, ok := err.(*TypeError); ok {\n\t\td.terrors = append(d.terrors, e.Errors...)\n\t\treturn false\n\t}\n\tif err != nil {\n\t\tfail(err)\n\t}\n\treturn true\n}\n\n// d.prepare initializes and dereferences pointers and calls UnmarshalYAML\n// if a value is found to implement it.\n// It returns the initialized and dereferenced out value, whether\n// unmarshalling was already done by UnmarshalYAML, and if so whether\n// its types unmarshalled appropriately.\n//\n// If n holds a null value, prepare returns before doing anything.\nfunc (d *decoder) prepare(n *Node, out reflect.Value) (newout reflect.Value, unmarshaled, good bool) {\n\tif n.ShortTag() == nullTag {\n\t\treturn out, false, false\n\t}\n\tagain := true\n\tfor again {\n\t\tagain = false\n\t\tif out.Kind() == reflect.Ptr {\n\t\t\tif out.IsNil() {\n\t\t\t\tout.Set(reflect.New(out.Type().Elem()))\n\t\t\t}\n\t\t\tout = out.Elem()\n\t\t\tagain = true\n\t\t}\n\t\tif out.CanAddr() {\n\t\t\touti := out.Addr().Interface()\n\t\t\tif u, ok := outi.(Unmarshaler); ok {\n\t\t\t\tgood = d.callUnmarshaler(n, u)\n\t\t\t\treturn out, true, good\n\t\t\t}\n\t\t\tif u, ok := outi.(obsoleteUnmarshaler); ok {\n\t\t\t\tgood = d.callObsoleteUnmarshaler(n, u)\n\t\t\t\treturn out, true, good\n\t\t\t}\n\t\t}\n\t}\n\treturn out, false, false\n}\n\nfunc (d *decoder) fieldByIndex(n *Node, v reflect.Value, index []int) (field reflect.Value) {\n\tif n.ShortTag() == nullTag {\n\t\treturn reflect.Value{}\n\t}\n\tfor _, num := range index {\n\t\tfor {\n\t\t\tif v.Kind() == reflect.Ptr {\n\t\t\t\tif v.IsNil() {\n\t\t\t\t\tv.Set(reflect.New(v.Type().Elem()))\n\t\t\t\t}\n\t\t\t\tv = v.Elem()\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t\tv = v.Field(num)\n\t}\n\treturn v\n}\n\nconst (\n\t// 400,000 decode operations is ~500kb of dense object declarations, or\n\t// ~5kb of dense object declarations with 10000% alias expansion\n\talias_ratio_range_low = 400000\n\n\t// 4,000,000 decode operations is ~5MB of dense object declarations, or\n\t// ~4.5MB of dense object declarations with 10% alias expansion\n\talias_ratio_range_high = 4000000\n\n\t// alias_ratio_range is the range over which we scale allowed alias ratios\n\talias_ratio_range = float64(alias_ratio_range_high - alias_ratio_range_low)\n)\n\nfunc allowedAliasRatio(decodeCount int) float64 {\n\tswitch {\n\tcase decodeCount <= alias_ratio_range_low:\n\t\t// allow 99% to come from alias expansion for small-to-medium documents\n\t\treturn 0.99\n\tcase decodeCount >= alias_ratio_range_high:\n\t\t// allow 10% to come from alias expansion for very large documents\n\t\treturn 0.10\n\tdefault:\n\t\t// scale smoothly from 99% down to 10% over the range.\n\t\t// this maps to 396,000 - 400,000 allowed alias-driven decodes over the range.\n\t\t// 400,000 decode operations is ~100MB of allocations in worst-case scenarios (single-item maps).\n\t\treturn 0.99 - 0.89*(float64(decodeCount-alias_ratio_range_low)/alias_ratio_range)\n\t}\n}\n\nfunc (d *decoder) unmarshal(n *Node, out reflect.Value) (good bool) {\n\td.decodeCount++\n\tif d.aliasDepth > 0 {\n\t\td.aliasCount++\n\t}\n\tif d.aliasCount > 100 && d.decodeCount > 1000 && float64(d.aliasCount)/float64(d.decodeCount) > allowedAliasRatio(d.decodeCount) {\n\t\tfailf(\"document contains excessive aliasing\")\n\t}\n\tif out.Type() == nodeType {\n\t\tout.Set(reflect.ValueOf(n).Elem())\n\t\treturn true\n\t}\n\tswitch n.Kind {\n\tcase DocumentNode:\n\t\treturn d.document(n, out)\n\tcase AliasNode:\n\t\treturn d.alias(n, out)\n\t}\n\tout, unmarshaled, good := d.prepare(n, out)\n\tif unmarshaled {\n\t\treturn good\n\t}\n\tswitch n.Kind {\n\tcase ScalarNode:\n\t\tgood = d.scalar(n, out)\n\tcase MappingNode:\n\t\tgood = d.mapping(n, out)\n\tcase SequenceNode:\n\t\tgood = d.sequence(n, out)\n\tcase 0:\n\t\tif n.IsZero() {\n\t\t\treturn d.null(out)\n\t\t}\n\t\tfallthrough\n\tdefault:\n\t\tfailf(\"cannot decode node with unknown kind %d\", n.Kind)\n\t}\n\treturn good\n}\n\nfunc (d *decoder) document(n *Node, out reflect.Value) (good bool) {\n\tif len(n.Content) == 1 {\n\t\td.doc = n\n\t\td.unmarshal(n.Content[0], out)\n\t\treturn true\n\t}\n\treturn false\n}\n\nfunc (d *decoder) alias(n *Node, out reflect.Value) (good bool) {\n\tif d.aliases[n] {\n\t\t// TODO this could actually be allowed in some circumstances.\n\t\tfailf(\"anchor '%s' value contains itself\", n.Value)\n\t}\n\td.aliases[n] = true\n\td.aliasDepth++\n\tgood = d.unmarshal(n.Alias, out)\n\td.aliasDepth--\n\tdelete(d.aliases, n)\n\treturn good\n}\n\nvar zeroValue reflect.Value\n\nfunc resetMap(out reflect.Value) {\n\tfor _, k := range out.MapKeys() {\n\t\tout.SetMapIndex(k, zeroValue)\n\t}\n}\n\nfunc (d *decoder) null(out reflect.Value) bool {\n\tif out.CanAddr() {\n\t\tswitch out.Kind() {\n\t\tcase reflect.Interface, reflect.Ptr, reflect.Map, reflect.Slice:\n\t\t\tout.Set(reflect.Zero(out.Type()))\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (d *decoder) scalar(n *Node, out reflect.Value) bool {\n\tvar tag string\n\tvar resolved interface{}\n\tif n.indicatedString() {\n\t\ttag = strTag\n\t\tresolved = n.Value\n\t} else {\n\t\ttag, resolved = resolve(n.Tag, n.Value)\n\t\tif tag == binaryTag {\n\t\t\tdata, err := base64.StdEncoding.DecodeString(resolved.(string))\n\t\t\tif err != nil {\n\t\t\t\tfailf(\"!!binary value contains invalid base64 data\")\n\t\t\t}\n\t\t\tresolved = string(data)\n\t\t}\n\t}\n\tif resolved == nil {\n\t\treturn d.null(out)\n\t}\n\tif resolvedv := reflect.ValueOf(resolved); out.Type() == resolvedv.Type() {\n\t\t// We've resolved to exactly the type we want, so use that.\n\t\tout.Set(resolvedv)\n\t\treturn true\n\t}\n\t// Perhaps we can use the value as a TextUnmarshaler to\n\t// set its value.\n\tif out.CanAddr() {\n\t\tu, ok := out.Addr().Interface().(encoding.TextUnmarshaler)\n\t\tif ok {\n\t\t\tvar text []byte\n\t\t\tif tag == binaryTag {\n\t\t\t\ttext = []byte(resolved.(string))\n\t\t\t} else {\n\t\t\t\t// We let any value be unmarshaled into TextUnmarshaler.\n\t\t\t\t// That might be more lax than we'd like, but the\n\t\t\t\t// TextUnmarshaler itself should bowl out any dubious values.\n\t\t\t\ttext = []byte(n.Value)\n\t\t\t}\n\t\t\terr := u.UnmarshalText(text)\n\t\t\tif err != nil {\n\t\t\t\tfail(err)\n\t\t\t}\n\t\t\treturn true\n\t\t}\n\t}\n\tswitch out.Kind() {\n\tcase reflect.String:\n\t\tif tag == binaryTag {\n\t\t\tout.SetString(resolved.(string))\n\t\t\treturn true\n\t\t}\n\t\tout.SetString(n.Value)\n\t\treturn true\n\tcase reflect.Interface:\n\t\tout.Set(reflect.ValueOf(resolved))\n\t\treturn true\n\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\n\t\t// This used to work in v2, but it's very unfriendly.\n\t\tisDuration := out.Type() == durationType\n\n\t\tswitch resolved := resolved.(type) {\n\t\tcase int:\n\t\t\tif !isDuration && !out.OverflowInt(int64(resolved)) {\n\t\t\t\tout.SetInt(int64(resolved))\n\t\t\t\treturn true\n\t\t\t}\n\t\tcase int64:\n\t\t\tif !isDuration && !out.OverflowInt(resolved) {\n\t\t\t\tout.SetInt(resolved)\n\t\t\t\treturn true\n\t\t\t}\n\t\tcase uint64:\n\t\t\tif !isDuration && resolved <= math.MaxInt64 && !out.OverflowInt(int64(resolved)) {\n\t\t\t\tout.SetInt(int64(resolved))\n\t\t\t\treturn true\n\t\t\t}\n\t\tcase float64:\n\t\t\tif !isDuration && resolved <= math.MaxInt64 && !out.OverflowInt(int64(resolved)) {\n\t\t\t\tout.SetInt(int64(resolved))\n\t\t\t\treturn true\n\t\t\t}\n\t\tcase string:\n\t\t\tif out.Type() == durationType {\n\t\t\t\td, err := time.ParseDuration(resolved)\n\t\t\t\tif err == nil {\n\t\t\t\t\tout.SetInt(int64(d))\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\tcase reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64, reflect.Uintptr:\n\t\tswitch resolved := resolved.(type) {\n\t\tcase int:\n\t\t\tif resolved >= 0 && !out.OverflowUint(uint64(resolved)) {\n\t\t\t\tout.SetUint(uint64(resolved))\n\t\t\t\treturn true\n\t\t\t}\n\t\tcase int64:\n\t\t\tif resolved >= 0 && !out.OverflowUint(uint64(resolved)) {\n\t\t\t\tout.SetUint(uint64(resolved))\n\t\t\t\treturn true\n\t\t\t}\n\t\tcase uint64:\n\t\t\tif !out.OverflowUint(uint64(resolved)) {\n\t\t\t\tout.SetUint(uint64(resolved))\n\t\t\t\treturn true\n\t\t\t}\n\t\tcase float64:\n\t\t\tif resolved <= math.MaxUint64 && !out.OverflowUint(uint64(resolved)) {\n\t\t\t\tout.SetUint(uint64(resolved))\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\tcase reflect.Bool:\n\t\tswitch resolved := resolved.(type) {\n\t\tcase bool:\n\t\t\tout.SetBool(resolved)\n\t\t\treturn true\n\t\tcase string:\n\t\t\t// This offers some compatibility with the 1.1 spec (https://yaml.org/type/bool.html).\n\t\t\t// It only works if explicitly attempting to unmarshal into a typed bool value.\n\t\t\tswitch resolved {\n\t\t\tcase \"y\", \"Y\", \"yes\", \"Yes\", \"YES\", \"on\", \"On\", \"ON\":\n\t\t\t\tout.SetBool(true)\n\t\t\t\treturn true\n\t\t\tcase \"n\", \"N\", \"no\", \"No\", \"NO\", \"off\", \"Off\", \"OFF\":\n\t\t\t\tout.SetBool(false)\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\tcase reflect.Float32, reflect.Float64:\n\t\tswitch resolved := resolved.(type) {\n\t\tcase int:\n\t\t\tout.SetFloat(float64(resolved))\n\t\t\treturn true\n\t\tcase int64:\n\t\t\tout.SetFloat(float64(resolved))\n\t\t\treturn true\n\t\tcase uint64:\n\t\t\tout.SetFloat(float64(resolved))\n\t\t\treturn true\n\t\tcase float64:\n\t\t\tout.SetFloat(resolved)\n\t\t\treturn true\n\t\t}\n\tcase reflect.Struct:\n\t\tif resolvedv := reflect.ValueOf(resolved); out.Type() == resolvedv.Type() {\n\t\t\tout.Set(resolvedv)\n\t\t\treturn true\n\t\t}\n\tcase reflect.Ptr:\n\t\tpanic(\"yaml internal error: please report the issue\")\n\t}\n\td.terror(n, tag, out)\n\treturn false\n}\n\nfunc settableValueOf(i interface{}) reflect.Value {\n\tv := reflect.ValueOf(i)\n\tsv := reflect.New(v.Type()).Elem()\n\tsv.Set(v)\n\treturn sv\n}\n\nfunc (d *decoder) sequence(n *Node, out reflect.Value) (good bool) {\n\tl := len(n.Content)\n\n\tvar iface reflect.Value\n\tswitch out.Kind() {\n\tcase reflect.Slice:\n\t\tout.Set(reflect.MakeSlice(out.Type(), l, l))\n\tcase reflect.Array:\n\t\tif l != out.Len() {\n\t\t\tfailf(\"invalid array: want %d elements but got %d\", out.Len(), l)\n\t\t}\n\tcase reflect.Interface:\n\t\t// No type hints. Will have to use a generic sequence.\n\t\tiface = out\n\t\tout = settableValueOf(make([]interface{}, l))\n\tdefault:\n\t\td.terror(n, seqTag, out)\n\t\treturn false\n\t}\n\tet := out.Type().Elem()\n\n\tj := 0\n\tfor i := 0; i < l; i++ {\n\t\te := reflect.New(et).Elem()\n\t\tif ok := d.unmarshal(n.Content[i], e); ok {\n\t\t\tout.Index(j).Set(e)\n\t\t\tj++\n\t\t}\n\t}\n\tif out.Kind() != reflect.Array {\n\t\tout.Set(out.Slice(0, j))\n\t}\n\tif iface.IsValid() {\n\t\tiface.Set(out)\n\t}\n\treturn true\n}\n\nfunc (d *decoder) mapping(n *Node, out reflect.Value) (good bool) {\n\tl := len(n.Content)\n\tif d.uniqueKeys {\n\t\tnerrs := len(d.terrors)\n\t\tfor i := 0; i < l; i += 2 {\n\t\t\tni := n.Content[i]\n\t\t\tfor j := i + 2; j < l; j += 2 {\n\t\t\t\tnj := n.Content[j]\n\t\t\t\tif ni.Kind == nj.Kind && ni.Value == nj.Value {\n\t\t\t\t\td.terrors = append(d.terrors, fmt.Sprintf(\"line %d: mapping key %#v already defined at line %d\", nj.Line, nj.Value, ni.Line))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif len(d.terrors) > nerrs {\n\t\t\treturn false\n\t\t}\n\t}\n\tswitch out.Kind() {\n\tcase reflect.Struct:\n\t\treturn d.mappingStruct(n, out)\n\tcase reflect.Map:\n\t\t// okay\n\tcase reflect.Interface:\n\t\tiface := out\n\t\tif isStringMap(n) {\n\t\t\tout = reflect.MakeMap(d.stringMapType)\n\t\t} else {\n\t\t\tout = reflect.MakeMap(d.generalMapType)\n\t\t}\n\t\tiface.Set(out)\n\tdefault:\n\t\td.terror(n, mapTag, out)\n\t\treturn false\n\t}\n\n\toutt := out.Type()\n\tkt := outt.Key()\n\tet := outt.Elem()\n\n\tstringMapType := d.stringMapType\n\tgeneralMapType := d.generalMapType\n\tif outt.Elem() == ifaceType {\n\t\tif outt.Key().Kind() == reflect.String {\n\t\t\td.stringMapType = outt\n\t\t} else if outt.Key() == ifaceType {\n\t\t\td.generalMapType = outt\n\t\t}\n\t}\n\n\tmergedFields := d.mergedFields\n\td.mergedFields = nil\n\n\tvar mergeNode *Node\n\n\tmapIsNew := false\n\tif out.IsNil() {\n\t\tout.Set(reflect.MakeMap(outt))\n\t\tmapIsNew = true\n\t}\n\tfor i := 0; i < l; i += 2 {\n\t\tif isMerge(n.Content[i]) {\n\t\t\tmergeNode = n.Content[i+1]\n\t\t\tcontinue\n\t\t}\n\t\tk := reflect.New(kt).Elem()\n\t\tif d.unmarshal(n.Content[i], k) {\n\t\t\tif mergedFields != nil {\n\t\t\t\tki := k.Interface()\n\t\t\t\tif mergedFields[ki] {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tmergedFields[ki] = true\n\t\t\t}\n\t\t\tkkind := k.Kind()\n\t\t\tif kkind == reflect.Interface {\n\t\t\t\tkkind = k.Elem().Kind()\n\t\t\t}\n\t\t\tif kkind == reflect.Map || kkind == reflect.Slice {\n\t\t\t\tfailf(\"invalid map key: %#v\", k.Interface())\n\t\t\t}\n\t\t\te := reflect.New(et).Elem()\n\t\t\tif d.unmarshal(n.Content[i+1], e) || n.Content[i+1].ShortTag() == nullTag && (mapIsNew || !out.MapIndex(k).IsValid()) {\n\t\t\t\tout.SetMapIndex(k, e)\n\t\t\t}\n\t\t}\n\t}\n\n\td.mergedFields = mergedFields\n\tif mergeNode != nil {\n\t\td.merge(n, mergeNode, out)\n\t}\n\n\td.stringMapType = stringMapType\n\td.generalMapType = generalMapType\n\treturn true\n}\n\nfunc isStringMap(n *Node) bool {\n\tif n.Kind != MappingNode {\n\t\treturn false\n\t}\n\tl := len(n.Content)\n\tfor i := 0; i < l; i += 2 {\n\t\tshortTag := n.Content[i].ShortTag()\n\t\tif shortTag != strTag && shortTag != mergeTag {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\nfunc (d *decoder) mappingStruct(n *Node, out reflect.Value) (good bool) {\n\tsinfo, err := getStructInfo(out.Type())\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tvar inlineMap reflect.Value\n\tvar elemType reflect.Type\n\tif sinfo.InlineMap != -1 {\n\t\tinlineMap = out.Field(sinfo.InlineMap)\n\t\telemType = inlineMap.Type().Elem()\n\t}\n\n\tfor _, index := range sinfo.InlineUnmarshalers {\n\t\tfield := d.fieldByIndex(n, out, index)\n\t\td.prepare(n, field)\n\t}\n\n\tmergedFields := d.mergedFields\n\td.mergedFields = nil\n\tvar mergeNode *Node\n\tvar doneFields []bool\n\tif d.uniqueKeys {\n\t\tdoneFields = make([]bool, len(sinfo.FieldsList))\n\t}\n\tname := settableValueOf(\"\")\n\tl := len(n.Content)\n\tfor i := 0; i < l; i += 2 {\n\t\tni := n.Content[i]\n\t\tif isMerge(ni) {\n\t\t\tmergeNode = n.Content[i+1]\n\t\t\tcontinue\n\t\t}\n\t\tif !d.unmarshal(ni, name) {\n\t\t\tcontinue\n\t\t}\n\t\tsname := name.String()\n\t\tif mergedFields != nil {\n\t\t\tif mergedFields[sname] {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tmergedFields[sname] = true\n\t\t}\n\t\tif info, ok := sinfo.FieldsMap[sname]; ok {\n\t\t\tif d.uniqueKeys {\n\t\t\t\tif doneFields[info.Id] {\n\t\t\t\t\td.terrors = append(d.terrors, fmt.Sprintf(\"line %d: field %s already set in type %s\", ni.Line, name.String(), out.Type()))\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tdoneFields[info.Id] = true\n\t\t\t}\n\t\t\tvar field reflect.Value\n\t\t\tif info.Inline == nil {\n\t\t\t\tfield = out.Field(info.Num)\n\t\t\t} else {\n\t\t\t\tfield = d.fieldByIndex(n, out, info.Inline)\n\t\t\t}\n\t\t\td.unmarshal(n.Content[i+1], field)\n\t\t} else if sinfo.InlineMap != -1 {\n\t\t\tif inlineMap.IsNil() {\n\t\t\t\tinlineMap.Set(reflect.MakeMap(inlineMap.Type()))\n\t\t\t}\n\t\t\tvalue := reflect.New(elemType).Elem()\n\t\t\td.unmarshal(n.Content[i+1], value)\n\t\t\tinlineMap.SetMapIndex(name, value)\n\t\t} else if d.knownFields {\n\t\t\td.terrors = append(d.terrors, fmt.Sprintf(\"line %d: field %s not found in type %s\", ni.Line, name.String(), out.Type()))\n\t\t}\n\t}\n\n\td.mergedFields = mergedFields\n\tif mergeNode != nil {\n\t\td.merge(n, mergeNode, out)\n\t}\n\treturn true\n}\n\nfunc failWantMap() {\n\tfailf(\"map merge requires map or sequence of maps as the value\")\n}\n\nfunc (d *decoder) merge(parent *Node, merge *Node, out reflect.Value) {\n\tmergedFields := d.mergedFields\n\tif mergedFields == nil {\n\t\td.mergedFields = make(map[interface{}]bool)\n\t\tfor i := 0; i < len(parent.Content); i += 2 {\n\t\t\tk := reflect.New(ifaceType).Elem()\n\t\t\tif d.unmarshal(parent.Content[i], k) {\n\t\t\t\td.mergedFields[k.Interface()] = true\n\t\t\t}\n\t\t}\n\t}\n\n\tswitch merge.Kind {\n\tcase MappingNode:\n\t\td.unmarshal(merge, out)\n\tcase AliasNode:\n\t\tif merge.Alias != nil && merge.Alias.Kind != MappingNode {\n\t\t\tfailWantMap()\n\t\t}\n\t\td.unmarshal(merge, out)\n\tcase SequenceNode:\n\t\tfor i := 0; i < len(merge.Content); i++ {\n\t\t\tni := merge.Content[i]\n\t\t\tif ni.Kind == AliasNode {\n\t\t\t\tif ni.Alias != nil && ni.Alias.Kind != MappingNode {\n\t\t\t\t\tfailWantMap()\n\t\t\t\t}\n\t\t\t} else if ni.Kind != MappingNode {\n\t\t\t\tfailWantMap()\n\t\t\t}\n\t\t\td.unmarshal(ni, out)\n\t\t}\n\tdefault:\n\t\tfailWantMap()\n\t}\n\n\td.mergedFields = mergedFields\n}\n\nfunc isMerge(n *Node) bool {\n\treturn n.Kind == ScalarNode && n.Value == \"<<\" && (n.Tag == \"\" || n.Tag == \"!\" || shortTag(n.Tag) == mergeTag)\n}\n"
        },
        {
          "name": "decode_test.go",
          "type": "blob",
          "size": 41.328125,
          "content": "//\n// Copyright (c) 2011-2019 Canonical Ltd\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage yaml_test\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"math\"\n\t\"reflect\"\n\t\"strings\"\n\t\"time\"\n\n\t. \"gopkg.in/check.v1\"\n\t\"gopkg.in/yaml.v3\"\n)\n\nvar unmarshalIntTest = 123\n\nvar unmarshalTests = []struct {\n\tdata  string\n\tvalue interface{}\n}{\n\t{\n\t\t\"\",\n\t\t(*struct{})(nil),\n\t},\n\t{\n\t\t\"{}\", &struct{}{},\n\t}, {\n\t\t\"v: hi\",\n\t\tmap[string]string{\"v\": \"hi\"},\n\t}, {\n\t\t\"v: hi\", map[string]interface{}{\"v\": \"hi\"},\n\t}, {\n\t\t\"v: true\",\n\t\tmap[string]string{\"v\": \"true\"},\n\t}, {\n\t\t\"v: true\",\n\t\tmap[string]interface{}{\"v\": true},\n\t}, {\n\t\t\"v: 10\",\n\t\tmap[string]interface{}{\"v\": 10},\n\t}, {\n\t\t\"v: 0b10\",\n\t\tmap[string]interface{}{\"v\": 2},\n\t}, {\n\t\t\"v: 0xA\",\n\t\tmap[string]interface{}{\"v\": 10},\n\t}, {\n\t\t\"v: 4294967296\",\n\t\tmap[string]int64{\"v\": 4294967296},\n\t}, {\n\t\t\"v: 0.1\",\n\t\tmap[string]interface{}{\"v\": 0.1},\n\t}, {\n\t\t\"v: .1\",\n\t\tmap[string]interface{}{\"v\": 0.1},\n\t}, {\n\t\t\"v: .Inf\",\n\t\tmap[string]interface{}{\"v\": math.Inf(+1)},\n\t}, {\n\t\t\"v: -.Inf\",\n\t\tmap[string]interface{}{\"v\": math.Inf(-1)},\n\t}, {\n\t\t\"v: -10\",\n\t\tmap[string]interface{}{\"v\": -10},\n\t}, {\n\t\t\"v: -.1\",\n\t\tmap[string]interface{}{\"v\": -0.1},\n\t},\n\n\t// Simple values.\n\t{\n\t\t\"123\",\n\t\t&unmarshalIntTest,\n\t},\n\n\t// Floats from spec\n\t{\n\t\t\"canonical: 6.8523e+5\",\n\t\tmap[string]interface{}{\"canonical\": 6.8523e+5},\n\t}, {\n\t\t\"expo: 685.230_15e+03\",\n\t\tmap[string]interface{}{\"expo\": 685.23015e+03},\n\t}, {\n\t\t\"fixed: 685_230.15\",\n\t\tmap[string]interface{}{\"fixed\": 685230.15},\n\t}, {\n\t\t\"neginf: -.inf\",\n\t\tmap[string]interface{}{\"neginf\": math.Inf(-1)},\n\t}, {\n\t\t\"fixed: 685_230.15\",\n\t\tmap[string]float64{\"fixed\": 685230.15},\n\t},\n\t//{\"sexa: 190:20:30.15\", map[string]interface{}{\"sexa\": 0}}, // Unsupported\n\t//{\"notanum: .NaN\", map[string]interface{}{\"notanum\": math.NaN()}}, // Equality of NaN fails.\n\n\t// Bools are per 1.2 spec.\n\t{\n\t\t\"canonical: true\",\n\t\tmap[string]interface{}{\"canonical\": true},\n\t}, {\n\t\t\"canonical: false\",\n\t\tmap[string]interface{}{\"canonical\": false},\n\t}, {\n\t\t\"bool: True\",\n\t\tmap[string]interface{}{\"bool\": true},\n\t}, {\n\t\t\"bool: False\",\n\t\tmap[string]interface{}{\"bool\": false},\n\t}, {\n\t\t\"bool: TRUE\",\n\t\tmap[string]interface{}{\"bool\": true},\n\t}, {\n\t\t\"bool: FALSE\",\n\t\tmap[string]interface{}{\"bool\": false},\n\t},\n\t// For backwards compatibility with 1.1, decoding old strings into typed values still works.\n\t{\n\t\t\"option: on\",\n\t\tmap[string]bool{\"option\": true},\n\t}, {\n\t\t\"option: y\",\n\t\tmap[string]bool{\"option\": true},\n\t}, {\n\t\t\"option: Off\",\n\t\tmap[string]bool{\"option\": false},\n\t}, {\n\t\t\"option: No\",\n\t\tmap[string]bool{\"option\": false},\n\t}, {\n\t\t\"option: other\",\n\t\tmap[string]bool{},\n\t},\n\t// Ints from spec\n\t{\n\t\t\"canonical: 685230\",\n\t\tmap[string]interface{}{\"canonical\": 685230},\n\t}, {\n\t\t\"decimal: +685_230\",\n\t\tmap[string]interface{}{\"decimal\": 685230},\n\t}, {\n\t\t\"octal: 02472256\",\n\t\tmap[string]interface{}{\"octal\": 685230},\n\t}, {\n\t\t\"octal: -02472256\",\n\t\tmap[string]interface{}{\"octal\": -685230},\n\t}, {\n\t\t\"octal: 0o2472256\",\n\t\tmap[string]interface{}{\"octal\": 685230},\n\t}, {\n\t\t\"octal: -0o2472256\",\n\t\tmap[string]interface{}{\"octal\": -685230},\n\t}, {\n\t\t\"hexa: 0x_0A_74_AE\",\n\t\tmap[string]interface{}{\"hexa\": 685230},\n\t}, {\n\t\t\"bin: 0b1010_0111_0100_1010_1110\",\n\t\tmap[string]interface{}{\"bin\": 685230},\n\t}, {\n\t\t\"bin: -0b101010\",\n\t\tmap[string]interface{}{\"bin\": -42},\n\t}, {\n\t\t\"bin: -0b1000000000000000000000000000000000000000000000000000000000000000\",\n\t\tmap[string]interface{}{\"bin\": -9223372036854775808},\n\t}, {\n\t\t\"decimal: +685_230\",\n\t\tmap[string]int{\"decimal\": 685230},\n\t},\n\n\t//{\"sexa: 190:20:30\", map[string]interface{}{\"sexa\": 0}}, // Unsupported\n\n\t// Nulls from spec\n\t{\n\t\t\"empty:\",\n\t\tmap[string]interface{}{\"empty\": nil},\n\t}, {\n\t\t\"canonical: ~\",\n\t\tmap[string]interface{}{\"canonical\": nil},\n\t}, {\n\t\t\"english: null\",\n\t\tmap[string]interface{}{\"english\": nil},\n\t}, {\n\t\t\"~: null key\",\n\t\tmap[interface{}]string{nil: \"null key\"},\n\t}, {\n\t\t\"empty:\",\n\t\tmap[string]*bool{\"empty\": nil},\n\t},\n\n\t// Flow sequence\n\t{\n\t\t\"seq: [A,B]\",\n\t\tmap[string]interface{}{\"seq\": []interface{}{\"A\", \"B\"}},\n\t}, {\n\t\t\"seq: [A,B,C,]\",\n\t\tmap[string][]string{\"seq\": []string{\"A\", \"B\", \"C\"}},\n\t}, {\n\t\t\"seq: [A,1,C]\",\n\t\tmap[string][]string{\"seq\": []string{\"A\", \"1\", \"C\"}},\n\t}, {\n\t\t\"seq: [A,1,C]\",\n\t\tmap[string][]int{\"seq\": []int{1}},\n\t}, {\n\t\t\"seq: [A,1,C]\",\n\t\tmap[string]interface{}{\"seq\": []interface{}{\"A\", 1, \"C\"}},\n\t},\n\t// Block sequence\n\t{\n\t\t\"seq:\\n - A\\n - B\",\n\t\tmap[string]interface{}{\"seq\": []interface{}{\"A\", \"B\"}},\n\t}, {\n\t\t\"seq:\\n - A\\n - B\\n - C\",\n\t\tmap[string][]string{\"seq\": []string{\"A\", \"B\", \"C\"}},\n\t}, {\n\t\t\"seq:\\n - A\\n - 1\\n - C\",\n\t\tmap[string][]string{\"seq\": []string{\"A\", \"1\", \"C\"}},\n\t}, {\n\t\t\"seq:\\n - A\\n - 1\\n - C\",\n\t\tmap[string][]int{\"seq\": []int{1}},\n\t}, {\n\t\t\"seq:\\n - A\\n - 1\\n - C\",\n\t\tmap[string]interface{}{\"seq\": []interface{}{\"A\", 1, \"C\"}},\n\t},\n\n\t// Literal block scalar\n\t{\n\t\t\"scalar: | # Comment\\n\\n literal\\n\\n \\ttext\\n\\n\",\n\t\tmap[string]string{\"scalar\": \"\\nliteral\\n\\n\\ttext\\n\"},\n\t},\n\n\t// Folded block scalar\n\t{\n\t\t\"scalar: > # Comment\\n\\n folded\\n line\\n \\n next\\n line\\n  * one\\n  * two\\n\\n last\\n line\\n\\n\",\n\t\tmap[string]string{\"scalar\": \"\\nfolded line\\nnext line\\n * one\\n * two\\n\\nlast line\\n\"},\n\t},\n\n\t// Map inside interface with no type hints.\n\t{\n\t\t\"a: {b: c}\",\n\t\tmap[interface{}]interface{}{\"a\": map[string]interface{}{\"b\": \"c\"}},\n\t},\n\t// Non-string map inside interface with no type hints.\n\t{\n\t\t\"a: {b: c, 1: d}\",\n\t\tmap[interface{}]interface{}{\"a\": map[interface{}]interface{}{\"b\": \"c\", 1: \"d\"}},\n\t},\n\n\t// Structs and type conversions.\n\t{\n\t\t\"hello: world\",\n\t\t&struct{ Hello string }{\"world\"},\n\t}, {\n\t\t\"a: {b: c}\",\n\t\t&struct{ A struct{ B string } }{struct{ B string }{\"c\"}},\n\t}, {\n\t\t\"a: {b: c}\",\n\t\t&struct{ A *struct{ B string } }{&struct{ B string }{\"c\"}},\n\t}, {\n\t\t\"a: 'null'\",\n\t\t&struct{ A *unmarshalerType }{&unmarshalerType{\"null\"}},\n\t}, {\n\t\t\"a: {b: c}\",\n\t\t&struct{ A map[string]string }{map[string]string{\"b\": \"c\"}},\n\t}, {\n\t\t\"a: {b: c}\",\n\t\t&struct{ A *map[string]string }{&map[string]string{\"b\": \"c\"}},\n\t}, {\n\t\t\"a:\",\n\t\t&struct{ A map[string]string }{},\n\t}, {\n\t\t\"a: 1\",\n\t\t&struct{ A int }{1},\n\t}, {\n\t\t\"a: 1\",\n\t\t&struct{ A float64 }{1},\n\t}, {\n\t\t\"a: 1.0\",\n\t\t&struct{ A int }{1},\n\t}, {\n\t\t\"a: 1.0\",\n\t\t&struct{ A uint }{1},\n\t}, {\n\t\t\"a: [1, 2]\",\n\t\t&struct{ A []int }{[]int{1, 2}},\n\t}, {\n\t\t\"a: [1, 2]\",\n\t\t&struct{ A [2]int }{[2]int{1, 2}},\n\t}, {\n\t\t\"a: 1\",\n\t\t&struct{ B int }{0},\n\t}, {\n\t\t\"a: 1\",\n\t\t&struct {\n\t\t\tB int \"a\"\n\t\t}{1},\n\t}, {\n\t\t// Some limited backwards compatibility with the 1.1 spec.\n\t\t\"a: YES\",\n\t\t&struct{ A bool }{true},\n\t},\n\n\t// Some cross type conversions\n\t{\n\t\t\"v: 42\",\n\t\tmap[string]uint{\"v\": 42},\n\t}, {\n\t\t\"v: -42\",\n\t\tmap[string]uint{},\n\t}, {\n\t\t\"v: 4294967296\",\n\t\tmap[string]uint64{\"v\": 4294967296},\n\t}, {\n\t\t\"v: -4294967296\",\n\t\tmap[string]uint64{},\n\t},\n\n\t// int\n\t{\n\t\t\"int_max: 2147483647\",\n\t\tmap[string]int{\"int_max\": math.MaxInt32},\n\t},\n\t{\n\t\t\"int_min: -2147483648\",\n\t\tmap[string]int{\"int_min\": math.MinInt32},\n\t},\n\t{\n\t\t\"int_overflow: 9223372036854775808\", // math.MaxInt64 + 1\n\t\tmap[string]int{},\n\t},\n\n\t// int64\n\t{\n\t\t\"int64_max: 9223372036854775807\",\n\t\tmap[string]int64{\"int64_max\": math.MaxInt64},\n\t},\n\t{\n\t\t\"int64_max_base2: 0b111111111111111111111111111111111111111111111111111111111111111\",\n\t\tmap[string]int64{\"int64_max_base2\": math.MaxInt64},\n\t},\n\t{\n\t\t\"int64_min: -9223372036854775808\",\n\t\tmap[string]int64{\"int64_min\": math.MinInt64},\n\t},\n\t{\n\t\t\"int64_neg_base2: -0b111111111111111111111111111111111111111111111111111111111111111\",\n\t\tmap[string]int64{\"int64_neg_base2\": -math.MaxInt64},\n\t},\n\t{\n\t\t\"int64_overflow: 9223372036854775808\", // math.MaxInt64 + 1\n\t\tmap[string]int64{},\n\t},\n\n\t// uint\n\t{\n\t\t\"uint_min: 0\",\n\t\tmap[string]uint{\"uint_min\": 0},\n\t},\n\t{\n\t\t\"uint_max: 4294967295\",\n\t\tmap[string]uint{\"uint_max\": math.MaxUint32},\n\t},\n\t{\n\t\t\"uint_underflow: -1\",\n\t\tmap[string]uint{},\n\t},\n\n\t// uint64\n\t{\n\t\t\"uint64_min: 0\",\n\t\tmap[string]uint{\"uint64_min\": 0},\n\t},\n\t{\n\t\t\"uint64_max: 18446744073709551615\",\n\t\tmap[string]uint64{\"uint64_max\": math.MaxUint64},\n\t},\n\t{\n\t\t\"uint64_max_base2: 0b1111111111111111111111111111111111111111111111111111111111111111\",\n\t\tmap[string]uint64{\"uint64_max_base2\": math.MaxUint64},\n\t},\n\t{\n\t\t\"uint64_maxint64: 9223372036854775807\",\n\t\tmap[string]uint64{\"uint64_maxint64\": math.MaxInt64},\n\t},\n\t{\n\t\t\"uint64_underflow: -1\",\n\t\tmap[string]uint64{},\n\t},\n\n\t// float32\n\t{\n\t\t\"float32_max: 3.40282346638528859811704183484516925440e+38\",\n\t\tmap[string]float32{\"float32_max\": math.MaxFloat32},\n\t},\n\t{\n\t\t\"float32_nonzero: 1.401298464324817070923729583289916131280e-45\",\n\t\tmap[string]float32{\"float32_nonzero\": math.SmallestNonzeroFloat32},\n\t},\n\t{\n\t\t\"float32_maxuint64: 18446744073709551615\",\n\t\tmap[string]float32{\"float32_maxuint64\": float32(math.MaxUint64)},\n\t},\n\t{\n\t\t\"float32_maxuint64+1: 18446744073709551616\",\n\t\tmap[string]float32{\"float32_maxuint64+1\": float32(math.MaxUint64 + 1)},\n\t},\n\n\t// float64\n\t{\n\t\t\"float64_max: 1.797693134862315708145274237317043567981e+308\",\n\t\tmap[string]float64{\"float64_max\": math.MaxFloat64},\n\t},\n\t{\n\t\t\"float64_nonzero: 4.940656458412465441765687928682213723651e-324\",\n\t\tmap[string]float64{\"float64_nonzero\": math.SmallestNonzeroFloat64},\n\t},\n\t{\n\t\t\"float64_maxuint64: 18446744073709551615\",\n\t\tmap[string]float64{\"float64_maxuint64\": float64(math.MaxUint64)},\n\t},\n\t{\n\t\t\"float64_maxuint64+1: 18446744073709551616\",\n\t\tmap[string]float64{\"float64_maxuint64+1\": float64(math.MaxUint64 + 1)},\n\t},\n\n\t// Overflow cases.\n\t{\n\t\t\"v: 4294967297\",\n\t\tmap[string]int32{},\n\t}, {\n\t\t\"v: 128\",\n\t\tmap[string]int8{},\n\t},\n\n\t// Quoted values.\n\t{\n\t\t\"'1': '\\\"2\\\"'\",\n\t\tmap[interface{}]interface{}{\"1\": \"\\\"2\\\"\"},\n\t}, {\n\t\t\"v:\\n- A\\n- 'B\\n\\n  C'\\n\",\n\t\tmap[string][]string{\"v\": []string{\"A\", \"B\\nC\"}},\n\t},\n\n\t// Explicit tags.\n\t{\n\t\t\"v: !!float '1.1'\",\n\t\tmap[string]interface{}{\"v\": 1.1},\n\t}, {\n\t\t\"v: !!float 0\",\n\t\tmap[string]interface{}{\"v\": float64(0)},\n\t}, {\n\t\t\"v: !!float -1\",\n\t\tmap[string]interface{}{\"v\": float64(-1)},\n\t}, {\n\t\t\"v: !!null ''\",\n\t\tmap[string]interface{}{\"v\": nil},\n\t}, {\n\t\t\"%TAG !y! tag:yaml.org,2002:\\n---\\nv: !y!int '1'\",\n\t\tmap[string]interface{}{\"v\": 1},\n\t},\n\n\t// Non-specific tag (Issue #75)\n\t{\n\t\t\"v: ! test\",\n\t\tmap[string]interface{}{\"v\": \"test\"},\n\t},\n\n\t// Anchors and aliases.\n\t{\n\t\t\"a: &x 1\\nb: &y 2\\nc: *x\\nd: *y\\n\",\n\t\t&struct{ A, B, C, D int }{1, 2, 1, 2},\n\t}, {\n\t\t\"a: &a {c: 1}\\nb: *a\",\n\t\t&struct {\n\t\t\tA, B struct {\n\t\t\t\tC int\n\t\t\t}\n\t\t}{struct{ C int }{1}, struct{ C int }{1}},\n\t}, {\n\t\t\"a: &a [1, 2]\\nb: *a\",\n\t\t&struct{ B []int }{[]int{1, 2}},\n\t},\n\n\t// Bug #1133337\n\t{\n\t\t\"foo: ''\",\n\t\tmap[string]*string{\"foo\": new(string)},\n\t}, {\n\t\t\"foo: null\",\n\t\tmap[string]*string{\"foo\": nil},\n\t}, {\n\t\t\"foo: null\",\n\t\tmap[string]string{\"foo\": \"\"},\n\t}, {\n\t\t\"foo: null\",\n\t\tmap[string]interface{}{\"foo\": nil},\n\t},\n\n\t// Support for ~\n\t{\n\t\t\"foo: ~\",\n\t\tmap[string]*string{\"foo\": nil},\n\t}, {\n\t\t\"foo: ~\",\n\t\tmap[string]string{\"foo\": \"\"},\n\t}, {\n\t\t\"foo: ~\",\n\t\tmap[string]interface{}{\"foo\": nil},\n\t},\n\n\t// Ignored field\n\t{\n\t\t\"a: 1\\nb: 2\\n\",\n\t\t&struct {\n\t\t\tA int\n\t\t\tB int \"-\"\n\t\t}{1, 0},\n\t},\n\n\t// Bug #1191981\n\t{\n\t\t\"\" +\n\t\t\t\"%YAML 1.1\\n\" +\n\t\t\t\"--- !!str\\n\" +\n\t\t\t`\"Generic line break (no glyph)\\n\\` + \"\\n\" +\n\t\t\t` Generic line break (glyphed)\\n\\` + \"\\n\" +\n\t\t\t` Line separator\\u2028\\` + \"\\n\" +\n\t\t\t` Paragraph separator\\u2029\"` + \"\\n\",\n\t\t\"\" +\n\t\t\t\"Generic line break (no glyph)\\n\" +\n\t\t\t\"Generic line break (glyphed)\\n\" +\n\t\t\t\"Line separator\\u2028Paragraph separator\\u2029\",\n\t},\n\n\t// Struct inlining\n\t{\n\t\t\"a: 1\\nb: 2\\nc: 3\\n\",\n\t\t&struct {\n\t\t\tA int\n\t\t\tC inlineB `yaml:\",inline\"`\n\t\t}{1, inlineB{2, inlineC{3}}},\n\t},\n\n\t// Struct inlining as a pointer.\n\t{\n\t\t\"a: 1\\nb: 2\\nc: 3\\n\",\n\t\t&struct {\n\t\t\tA int\n\t\t\tC *inlineB `yaml:\",inline\"`\n\t\t}{1, &inlineB{2, inlineC{3}}},\n\t}, {\n\t\t\"a: 1\\n\",\n\t\t&struct {\n\t\t\tA int\n\t\t\tC *inlineB `yaml:\",inline\"`\n\t\t}{1, nil},\n\t}, {\n\t\t\"a: 1\\nc: 3\\nd: 4\\n\",\n\t\t&struct {\n\t\t\tA int\n\t\t\tC *inlineD `yaml:\",inline\"`\n\t\t}{1, &inlineD{&inlineC{3}, 4}},\n\t},\n\n\t// Map inlining\n\t{\n\t\t\"a: 1\\nb: 2\\nc: 3\\n\",\n\t\t&struct {\n\t\t\tA int\n\t\t\tC map[string]int `yaml:\",inline\"`\n\t\t}{1, map[string]int{\"b\": 2, \"c\": 3}},\n\t},\n\n\t// bug 1243827\n\t{\n\t\t\"a: -b_c\",\n\t\tmap[string]interface{}{\"a\": \"-b_c\"},\n\t},\n\t{\n\t\t\"a: +b_c\",\n\t\tmap[string]interface{}{\"a\": \"+b_c\"},\n\t},\n\t{\n\t\t\"a: 50cent_of_dollar\",\n\t\tmap[string]interface{}{\"a\": \"50cent_of_dollar\"},\n\t},\n\n\t// issue #295 (allow scalars with colons in flow mappings and sequences)\n\t{\n\t\t\"a: {b: https://github.com/go-yaml/yaml}\",\n\t\tmap[string]interface{}{\"a\": map[string]interface{}{\n\t\t\t\"b\": \"https://github.com/go-yaml/yaml\",\n\t\t}},\n\t},\n\t{\n\t\t\"a: [https://github.com/go-yaml/yaml]\",\n\t\tmap[string]interface{}{\"a\": []interface{}{\"https://github.com/go-yaml/yaml\"}},\n\t},\n\n\t// Duration\n\t{\n\t\t\"a: 3s\",\n\t\tmap[string]time.Duration{\"a\": 3 * time.Second},\n\t},\n\n\t// Issue #24.\n\t{\n\t\t\"a: <foo>\",\n\t\tmap[string]string{\"a\": \"<foo>\"},\n\t},\n\n\t// Base 60 floats are obsolete and unsupported.\n\t{\n\t\t\"a: 1:1\\n\",\n\t\tmap[string]string{\"a\": \"1:1\"},\n\t},\n\n\t// Binary data.\n\t{\n\t\t\"a: !!binary gIGC\\n\",\n\t\tmap[string]string{\"a\": \"\\x80\\x81\\x82\"},\n\t}, {\n\t\t\"a: !!binary |\\n  \" + strings.Repeat(\"kJCQ\", 17) + \"kJ\\n  CQ\\n\",\n\t\tmap[string]string{\"a\": strings.Repeat(\"\\x90\", 54)},\n\t}, {\n\t\t\"a: !!binary |\\n  \" + strings.Repeat(\"A\", 70) + \"\\n  ==\\n\",\n\t\tmap[string]string{\"a\": strings.Repeat(\"\\x00\", 52)},\n\t},\n\n\t// Issue #39.\n\t{\n\t\t\"a:\\n b:\\n  c: d\\n\",\n\t\tmap[string]struct{ B interface{} }{\"a\": {map[string]interface{}{\"c\": \"d\"}}},\n\t},\n\n\t// Custom map type.\n\t{\n\t\t\"a: {b: c}\",\n\t\tM{\"a\": M{\"b\": \"c\"}},\n\t},\n\n\t// Support encoding.TextUnmarshaler.\n\t{\n\t\t\"a: 1.2.3.4\\n\",\n\t\tmap[string]textUnmarshaler{\"a\": textUnmarshaler{S: \"1.2.3.4\"}},\n\t},\n\t{\n\t\t\"a: 2015-02-24T18:19:39Z\\n\",\n\t\tmap[string]textUnmarshaler{\"a\": textUnmarshaler{\"2015-02-24T18:19:39Z\"}},\n\t},\n\n\t// Timestamps\n\t{\n\t\t// Date only.\n\t\t\"a: 2015-01-01\\n\",\n\t\tmap[string]time.Time{\"a\": time.Date(2015, 1, 1, 0, 0, 0, 0, time.UTC)},\n\t},\n\t{\n\t\t// RFC3339\n\t\t\"a: 2015-02-24T18:19:39.12Z\\n\",\n\t\tmap[string]time.Time{\"a\": time.Date(2015, 2, 24, 18, 19, 39, .12e9, time.UTC)},\n\t},\n\t{\n\t\t// RFC3339 with short dates.\n\t\t\"a: 2015-2-3T3:4:5Z\",\n\t\tmap[string]time.Time{\"a\": time.Date(2015, 2, 3, 3, 4, 5, 0, time.UTC)},\n\t},\n\t{\n\t\t// ISO8601 lower case t\n\t\t\"a: 2015-02-24t18:19:39Z\\n\",\n\t\tmap[string]time.Time{\"a\": time.Date(2015, 2, 24, 18, 19, 39, 0, time.UTC)},\n\t},\n\t{\n\t\t// space separate, no time zone\n\t\t\"a: 2015-02-24 18:19:39\\n\",\n\t\tmap[string]time.Time{\"a\": time.Date(2015, 2, 24, 18, 19, 39, 0, time.UTC)},\n\t},\n\t// Some cases not currently handled. Uncomment these when\n\t// the code is fixed.\n\t//\t{\n\t//\t\t// space separated with time zone\n\t//\t\t\"a: 2001-12-14 21:59:43.10 -5\",\n\t//\t\tmap[string]interface{}{\"a\": time.Date(2001, 12, 14, 21, 59, 43, .1e9, time.UTC)},\n\t//\t},\n\t//\t{\n\t//\t\t// arbitrary whitespace between fields\n\t//\t\t\"a: 2001-12-14 \\t\\t \\t21:59:43.10 \\t Z\",\n\t//\t\tmap[string]interface{}{\"a\": time.Date(2001, 12, 14, 21, 59, 43, .1e9, time.UTC)},\n\t//\t},\n\t{\n\t\t// explicit string tag\n\t\t\"a: !!str 2015-01-01\",\n\t\tmap[string]interface{}{\"a\": \"2015-01-01\"},\n\t},\n\t{\n\t\t// explicit timestamp tag on quoted string\n\t\t\"a: !!timestamp \\\"2015-01-01\\\"\",\n\t\tmap[string]time.Time{\"a\": time.Date(2015, 1, 1, 0, 0, 0, 0, time.UTC)},\n\t},\n\t{\n\t\t// explicit timestamp tag on unquoted string\n\t\t\"a: !!timestamp 2015-01-01\",\n\t\tmap[string]time.Time{\"a\": time.Date(2015, 1, 1, 0, 0, 0, 0, time.UTC)},\n\t},\n\t{\n\t\t// quoted string that's a valid timestamp\n\t\t\"a: \\\"2015-01-01\\\"\",\n\t\tmap[string]interface{}{\"a\": \"2015-01-01\"},\n\t},\n\t{\n\t\t// explicit timestamp tag into interface.\n\t\t\"a: !!timestamp \\\"2015-01-01\\\"\",\n\t\tmap[string]interface{}{\"a\": time.Date(2015, 1, 1, 0, 0, 0, 0, time.UTC)},\n\t},\n\t{\n\t\t// implicit timestamp tag into interface.\n\t\t\"a: 2015-01-01\",\n\t\tmap[string]interface{}{\"a\": time.Date(2015, 1, 1, 0, 0, 0, 0, time.UTC)},\n\t},\n\n\t// Encode empty lists as zero-length slices.\n\t{\n\t\t\"a: []\",\n\t\t&struct{ A []int }{[]int{}},\n\t},\n\n\t// UTF-16-LE\n\t{\n\t\t\"\\xff\\xfe\\xf1\\x00o\\x00\\xf1\\x00o\\x00:\\x00 \\x00v\\x00e\\x00r\\x00y\\x00 \\x00y\\x00e\\x00s\\x00\\n\\x00\",\n\t\tM{\"oo\": \"very yes\"},\n\t},\n\t// UTF-16-LE with surrogate.\n\t{\n\t\t\"\\xff\\xfe\\xf1\\x00o\\x00\\xf1\\x00o\\x00:\\x00 \\x00v\\x00e\\x00r\\x00y\\x00 \\x00y\\x00e\\x00s\\x00 \\x00=\\xd8\\xd4\\xdf\\n\\x00\",\n\t\tM{\"oo\": \"very yes \"},\n\t},\n\n\t// UTF-16-BE\n\t{\n\t\t\"\\xfe\\xff\\x00\\xf1\\x00o\\x00\\xf1\\x00o\\x00:\\x00 \\x00v\\x00e\\x00r\\x00y\\x00 \\x00y\\x00e\\x00s\\x00\\n\",\n\t\tM{\"oo\": \"very yes\"},\n\t},\n\t// UTF-16-BE with surrogate.\n\t{\n\t\t\"\\xfe\\xff\\x00\\xf1\\x00o\\x00\\xf1\\x00o\\x00:\\x00 \\x00v\\x00e\\x00r\\x00y\\x00 \\x00y\\x00e\\x00s\\x00 \\xd8=\\xdf\\xd4\\x00\\n\",\n\t\tM{\"oo\": \"very yes \"},\n\t},\n\n\t// This *is* in fact a float number, per the spec. #171 was a mistake.\n\t{\n\t\t\"a: 123456e1\\n\",\n\t\tM{\"a\": 123456e1},\n\t}, {\n\t\t\"a: 123456E1\\n\",\n\t\tM{\"a\": 123456e1},\n\t},\n\t// yaml-test-suite 3GZX: Spec Example 7.1. Alias Nodes\n\t{\n\t\t\"First occurrence: &anchor Foo\\nSecond occurrence: *anchor\\nOverride anchor: &anchor Bar\\nReuse anchor: *anchor\\n\",\n\t\tmap[string]interface{}{\n\t\t\t\"First occurrence\":  \"Foo\",\n\t\t\t\"Second occurrence\": \"Foo\",\n\t\t\t\"Override anchor\":   \"Bar\",\n\t\t\t\"Reuse anchor\":      \"Bar\",\n\t\t},\n\t},\n\t// Single document with garbage following it.\n\t{\n\t\t\"---\\nhello\\n...\\n}not yaml\",\n\t\t\"hello\",\n\t},\n\n\t// Comment scan exhausting the input buffer (issue #469).\n\t{\n\t\t\"true\\n#\" + strings.Repeat(\" \", 512*3),\n\t\t\"true\",\n\t}, {\n\t\t\"true #\" + strings.Repeat(\" \", 512*3),\n\t\t\"true\",\n\t},\n\n\t// CRLF\n\t{\n\t\t\"a: b\\r\\nc:\\r\\n- d\\r\\n- e\\r\\n\",\n\t\tmap[string]interface{}{\n\t\t\t\"a\": \"b\",\n\t\t\t\"c\": []interface{}{\"d\", \"e\"},\n\t\t},\n\t},\n}\n\ntype M map[string]interface{}\n\ntype inlineB struct {\n\tB       int\n\tinlineC `yaml:\",inline\"`\n}\n\ntype inlineC struct {\n\tC int\n}\n\ntype inlineD struct {\n\tC *inlineC `yaml:\",inline\"`\n\tD int\n}\n\nfunc (s *S) TestUnmarshal(c *C) {\n\tfor i, item := range unmarshalTests {\n\t\tc.Logf(\"test %d: %q\", i, item.data)\n\t\tt := reflect.ValueOf(item.value).Type()\n\t\tvalue := reflect.New(t)\n\t\terr := yaml.Unmarshal([]byte(item.data), value.Interface())\n\t\tif _, ok := err.(*yaml.TypeError); !ok {\n\t\t\tc.Assert(err, IsNil)\n\t\t}\n\t\tc.Assert(value.Elem().Interface(), DeepEquals, item.value, Commentf(\"error: %v\", err))\n\t}\n}\n\nfunc (s *S) TestUnmarshalFullTimestamp(c *C) {\n\t// Full timestamp in same format as encoded. This is confirmed to be\n\t// properly decoded by Python as a timestamp as well.\n\tvar str = \"2015-02-24T18:19:39.123456789-03:00\"\n\tvar t interface{}\n\terr := yaml.Unmarshal([]byte(str), &t)\n\tc.Assert(err, IsNil)\n\tc.Assert(t, Equals, time.Date(2015, 2, 24, 18, 19, 39, 123456789, t.(time.Time).Location()))\n\tc.Assert(t.(time.Time).In(time.UTC), Equals, time.Date(2015, 2, 24, 21, 19, 39, 123456789, time.UTC))\n}\n\nfunc (s *S) TestDecoderSingleDocument(c *C) {\n\t// Test that Decoder.Decode works as expected on\n\t// all the unmarshal tests.\n\tfor i, item := range unmarshalTests {\n\t\tc.Logf(\"test %d: %q\", i, item.data)\n\t\tif item.data == \"\" {\n\t\t\t// Behaviour differs when there's no YAML.\n\t\t\tcontinue\n\t\t}\n\t\tt := reflect.ValueOf(item.value).Type()\n\t\tvalue := reflect.New(t)\n\t\terr := yaml.NewDecoder(strings.NewReader(item.data)).Decode(value.Interface())\n\t\tif _, ok := err.(*yaml.TypeError); !ok {\n\t\t\tc.Assert(err, IsNil)\n\t\t}\n\t\tc.Assert(value.Elem().Interface(), DeepEquals, item.value)\n\t}\n}\n\nvar decoderTests = []struct {\n\tdata   string\n\tvalues []interface{}\n}{{\n\t\"\",\n\tnil,\n}, {\n\t\"a: b\",\n\t[]interface{}{\n\t\tmap[string]interface{}{\"a\": \"b\"},\n\t},\n}, {\n\t\"---\\na: b\\n...\\n\",\n\t[]interface{}{\n\t\tmap[string]interface{}{\"a\": \"b\"},\n\t},\n}, {\n\t\"---\\n'hello'\\n...\\n---\\ngoodbye\\n...\\n\",\n\t[]interface{}{\n\t\t\"hello\",\n\t\t\"goodbye\",\n\t},\n}}\n\nfunc (s *S) TestDecoder(c *C) {\n\tfor i, item := range decoderTests {\n\t\tc.Logf(\"test %d: %q\", i, item.data)\n\t\tvar values []interface{}\n\t\tdec := yaml.NewDecoder(strings.NewReader(item.data))\n\t\tfor {\n\t\t\tvar value interface{}\n\t\t\terr := dec.Decode(&value)\n\t\t\tif err == io.EOF {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tc.Assert(err, IsNil)\n\t\t\tvalues = append(values, value)\n\t\t}\n\t\tc.Assert(values, DeepEquals, item.values)\n\t}\n}\n\ntype errReader struct{}\n\nfunc (errReader) Read([]byte) (int, error) {\n\treturn 0, errors.New(\"some read error\")\n}\n\nfunc (s *S) TestDecoderReadError(c *C) {\n\terr := yaml.NewDecoder(errReader{}).Decode(&struct{}{})\n\tc.Assert(err, ErrorMatches, `yaml: input error: some read error`)\n}\n\nfunc (s *S) TestUnmarshalNaN(c *C) {\n\tvalue := map[string]interface{}{}\n\terr := yaml.Unmarshal([]byte(\"notanum: .NaN\"), &value)\n\tc.Assert(err, IsNil)\n\tc.Assert(math.IsNaN(value[\"notanum\"].(float64)), Equals, true)\n}\n\nfunc (s *S) TestUnmarshalDurationInt(c *C) {\n\t// Don't accept plain ints as durations as it's unclear (issue #200).\n\tvar d time.Duration\n\terr := yaml.Unmarshal([]byte(\"123\"), &d)\n\tc.Assert(err, ErrorMatches, \"(?s).* line 1: cannot unmarshal !!int `123` into time.Duration\")\n}\n\nvar unmarshalErrorTests = []struct {\n\tdata, error string\n}{\n\t{\"v: !!float 'error'\", \"yaml: cannot decode !!str `error` as a !!float\"},\n\t{\"v: [A,\", \"yaml: line 1: did not find expected node content\"},\n\t{\"v:\\n- [A,\", \"yaml: line 2: did not find expected node content\"},\n\t{\"a:\\n- b: *,\", \"yaml: line 2: did not find expected alphabetic or numeric character\"},\n\t{\"a: *b\\n\", \"yaml: unknown anchor 'b' referenced\"},\n\t{\"a: &a\\n  b: *a\\n\", \"yaml: anchor 'a' value contains itself\"},\n\t{\"value: -\", \"yaml: block sequence entries are not allowed in this context\"},\n\t{\"a: !!binary ==\", \"yaml: !!binary value contains invalid base64 data\"},\n\t{\"{[.]}\", `yaml: invalid map key: \\[\\]interface \\{\\}\\{\"\\.\"\\}`},\n\t{\"{{.}}\", `yaml: invalid map key: map\\[string]interface \\{\\}\\{\".\":interface \\{\\}\\(nil\\)\\}`},\n\t{\"b: *a\\na: &a {c: 1}\", `yaml: unknown anchor 'a' referenced`},\n\t{\"%TAG !%79! tag:yaml.org,2002:\\n---\\nv: !%79!int '1'\", \"yaml: did not find expected whitespace\"},\n\t{\"a:\\n  1:\\nb\\n  2:\", \".*could not find expected ':'\"},\n\t{\"a: 1\\nb: 2\\nc 2\\nd: 3\\n\", \"^yaml: line 3: could not find expected ':'$\"},\n\t{\"#\\n-\\n{\", \"yaml: line 3: could not find expected ':'\"}, // Issue #665\n\t{\"0: [:!00 \\xef\", \"yaml: incomplete UTF-8 octet sequence\"}, // Issue #666\n\t{\n\t\t\"a: &a [00,00,00,00,00,00,00,00,00]\\n\" +\n\t\t\t\"b: &b [*a,*a,*a,*a,*a,*a,*a,*a,*a]\\n\" +\n\t\t\t\"c: &c [*b,*b,*b,*b,*b,*b,*b,*b,*b]\\n\" +\n\t\t\t\"d: &d [*c,*c,*c,*c,*c,*c,*c,*c,*c]\\n\" +\n\t\t\t\"e: &e [*d,*d,*d,*d,*d,*d,*d,*d,*d]\\n\" +\n\t\t\t\"f: &f [*e,*e,*e,*e,*e,*e,*e,*e,*e]\\n\" +\n\t\t\t\"g: &g [*f,*f,*f,*f,*f,*f,*f,*f,*f]\\n\" +\n\t\t\t\"h: &h [*g,*g,*g,*g,*g,*g,*g,*g,*g]\\n\" +\n\t\t\t\"i: &i [*h,*h,*h,*h,*h,*h,*h,*h,*h]\\n\",\n\t\t\"yaml: document contains excessive aliasing\",\n\t},\n}\n\nfunc (s *S) TestUnmarshalErrors(c *C) {\n\tfor i, item := range unmarshalErrorTests {\n\t\tc.Logf(\"test %d: %q\", i, item.data)\n\t\tvar value interface{}\n\t\terr := yaml.Unmarshal([]byte(item.data), &value)\n\t\tc.Assert(err, ErrorMatches, item.error, Commentf(\"Partial unmarshal: %#v\", value))\n\t}\n}\n\nfunc (s *S) TestDecoderErrors(c *C) {\n\tfor _, item := range unmarshalErrorTests {\n\t\tvar value interface{}\n\t\terr := yaml.NewDecoder(strings.NewReader(item.data)).Decode(&value)\n\t\tc.Assert(err, ErrorMatches, item.error, Commentf(\"Partial unmarshal: %#v\", value))\n\t}\n}\n\nvar unmarshalerTests = []struct {\n\tdata, tag string\n\tvalue     interface{}\n}{\n\t{\"_: {hi: there}\", \"!!map\", map[string]interface{}{\"hi\": \"there\"}},\n\t{\"_: [1,A]\", \"!!seq\", []interface{}{1, \"A\"}},\n\t{\"_: 10\", \"!!int\", 10},\n\t{\"_: null\", \"!!null\", nil},\n\t{`_: BAR!`, \"!!str\", \"BAR!\"},\n\t{`_: \"BAR!\"`, \"!!str\", \"BAR!\"},\n\t{\"_: !!foo 'BAR!'\", \"!!foo\", \"BAR!\"},\n\t{`_: \"\"`, \"!!str\", \"\"},\n}\n\nvar unmarshalerResult = map[int]error{}\n\ntype unmarshalerType struct {\n\tvalue interface{}\n}\n\nfunc (o *unmarshalerType) UnmarshalYAML(value *yaml.Node) error {\n\tif err := value.Decode(&o.value); err != nil {\n\t\treturn err\n\t}\n\tif i, ok := o.value.(int); ok {\n\t\tif result, ok := unmarshalerResult[i]; ok {\n\t\t\treturn result\n\t\t}\n\t}\n\treturn nil\n}\n\ntype unmarshalerPointer struct {\n\tField *unmarshalerType \"_\"\n}\n\ntype unmarshalerValue struct {\n\tField unmarshalerType \"_\"\n}\n\ntype unmarshalerInlined struct {\n\tField   *unmarshalerType \"_\"\n\tInlined unmarshalerType  `yaml:\",inline\"`\n}\n\ntype unmarshalerInlinedTwice struct {\n\tInlinedTwice unmarshalerInlined `yaml:\",inline\"`\n}\n\ntype obsoleteUnmarshalerType struct {\n\tvalue interface{}\n}\n\nfunc (o *obsoleteUnmarshalerType) UnmarshalYAML(unmarshal func(v interface{}) error) error {\n\tif err := unmarshal(&o.value); err != nil {\n\t\treturn err\n\t}\n\tif i, ok := o.value.(int); ok {\n\t\tif result, ok := unmarshalerResult[i]; ok {\n\t\t\treturn result\n\t\t}\n\t}\n\treturn nil\n}\n\ntype obsoleteUnmarshalerPointer struct {\n\tField *obsoleteUnmarshalerType \"_\"\n}\n\ntype obsoleteUnmarshalerValue struct {\n\tField obsoleteUnmarshalerType \"_\"\n}\n\nfunc (s *S) TestUnmarshalerPointerField(c *C) {\n\tfor _, item := range unmarshalerTests {\n\t\tobj := &unmarshalerPointer{}\n\t\terr := yaml.Unmarshal([]byte(item.data), obj)\n\t\tc.Assert(err, IsNil)\n\t\tif item.value == nil {\n\t\t\tc.Assert(obj.Field, IsNil)\n\t\t} else {\n\t\t\tc.Assert(obj.Field, NotNil, Commentf(\"Pointer not initialized (%#v)\", item.value))\n\t\t\tc.Assert(obj.Field.value, DeepEquals, item.value)\n\t\t}\n\t}\n\tfor _, item := range unmarshalerTests {\n\t\tobj := &obsoleteUnmarshalerPointer{}\n\t\terr := yaml.Unmarshal([]byte(item.data), obj)\n\t\tc.Assert(err, IsNil)\n\t\tif item.value == nil {\n\t\t\tc.Assert(obj.Field, IsNil)\n\t\t} else {\n\t\t\tc.Assert(obj.Field, NotNil, Commentf(\"Pointer not initialized (%#v)\", item.value))\n\t\t\tc.Assert(obj.Field.value, DeepEquals, item.value)\n\t\t}\n\t}\n}\n\nfunc (s *S) TestUnmarshalerValueField(c *C) {\n\tfor _, item := range unmarshalerTests {\n\t\tobj := &obsoleteUnmarshalerValue{}\n\t\terr := yaml.Unmarshal([]byte(item.data), obj)\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(obj.Field, NotNil, Commentf(\"Pointer not initialized (%#v)\", item.value))\n\t\tc.Assert(obj.Field.value, DeepEquals, item.value)\n\t}\n}\n\nfunc (s *S) TestUnmarshalerInlinedField(c *C) {\n\tobj := &unmarshalerInlined{}\n\terr := yaml.Unmarshal([]byte(\"_: a\\ninlined: b\\n\"), obj)\n\tc.Assert(err, IsNil)\n\tc.Assert(obj.Field, DeepEquals, &unmarshalerType{\"a\"})\n\tc.Assert(obj.Inlined, DeepEquals, unmarshalerType{map[string]interface{}{\"_\": \"a\", \"inlined\": \"b\"}})\n\n\ttwc := &unmarshalerInlinedTwice{}\n\terr = yaml.Unmarshal([]byte(\"_: a\\ninlined: b\\n\"), twc)\n\tc.Assert(err, IsNil)\n\tc.Assert(twc.InlinedTwice.Field, DeepEquals, &unmarshalerType{\"a\"})\n\tc.Assert(twc.InlinedTwice.Inlined, DeepEquals, unmarshalerType{map[string]interface{}{\"_\": \"a\", \"inlined\": \"b\"}})\n}\n\nfunc (s *S) TestUnmarshalerWholeDocument(c *C) {\n\tobj := &obsoleteUnmarshalerType{}\n\terr := yaml.Unmarshal([]byte(unmarshalerTests[0].data), obj)\n\tc.Assert(err, IsNil)\n\tvalue, ok := obj.value.(map[string]interface{})\n\tc.Assert(ok, Equals, true, Commentf(\"value: %#v\", obj.value))\n\tc.Assert(value[\"_\"], DeepEquals, unmarshalerTests[0].value)\n}\n\nfunc (s *S) TestUnmarshalerTypeError(c *C) {\n\tunmarshalerResult[2] = &yaml.TypeError{[]string{\"foo\"}}\n\tunmarshalerResult[4] = &yaml.TypeError{[]string{\"bar\"}}\n\tdefer func() {\n\t\tdelete(unmarshalerResult, 2)\n\t\tdelete(unmarshalerResult, 4)\n\t}()\n\n\ttype T struct {\n\t\tBefore int\n\t\tAfter  int\n\t\tM      map[string]*unmarshalerType\n\t}\n\tvar v T\n\tdata := `{before: A, m: {abc: 1, def: 2, ghi: 3, jkl: 4}, after: B}`\n\terr := yaml.Unmarshal([]byte(data), &v)\n\tc.Assert(err, ErrorMatches, \"\"+\n\t\t\"yaml: unmarshal errors:\\n\"+\n\t\t\"  line 1: cannot unmarshal !!str `A` into int\\n\"+\n\t\t\"  foo\\n\"+\n\t\t\"  bar\\n\"+\n\t\t\"  line 1: cannot unmarshal !!str `B` into int\")\n\tc.Assert(v.M[\"abc\"], NotNil)\n\tc.Assert(v.M[\"def\"], IsNil)\n\tc.Assert(v.M[\"ghi\"], NotNil)\n\tc.Assert(v.M[\"jkl\"], IsNil)\n\n\tc.Assert(v.M[\"abc\"].value, Equals, 1)\n\tc.Assert(v.M[\"ghi\"].value, Equals, 3)\n}\n\nfunc (s *S) TestObsoleteUnmarshalerTypeError(c *C) {\n\tunmarshalerResult[2] = &yaml.TypeError{[]string{\"foo\"}}\n\tunmarshalerResult[4] = &yaml.TypeError{[]string{\"bar\"}}\n\tdefer func() {\n\t\tdelete(unmarshalerResult, 2)\n\t\tdelete(unmarshalerResult, 4)\n\t}()\n\n\ttype T struct {\n\t\tBefore int\n\t\tAfter  int\n\t\tM      map[string]*obsoleteUnmarshalerType\n\t}\n\tvar v T\n\tdata := `{before: A, m: {abc: 1, def: 2, ghi: 3, jkl: 4}, after: B}`\n\terr := yaml.Unmarshal([]byte(data), &v)\n\tc.Assert(err, ErrorMatches, \"\"+\n\t\t\"yaml: unmarshal errors:\\n\"+\n\t\t\"  line 1: cannot unmarshal !!str `A` into int\\n\"+\n\t\t\"  foo\\n\"+\n\t\t\"  bar\\n\"+\n\t\t\"  line 1: cannot unmarshal !!str `B` into int\")\n\tc.Assert(v.M[\"abc\"], NotNil)\n\tc.Assert(v.M[\"def\"], IsNil)\n\tc.Assert(v.M[\"ghi\"], NotNil)\n\tc.Assert(v.M[\"jkl\"], IsNil)\n\n\tc.Assert(v.M[\"abc\"].value, Equals, 1)\n\tc.Assert(v.M[\"ghi\"].value, Equals, 3)\n}\n\ntype proxyTypeError struct{}\n\nfunc (v *proxyTypeError) UnmarshalYAML(node *yaml.Node) error {\n\tvar s string\n\tvar a int32\n\tvar b int64\n\tif err := node.Decode(&s); err != nil {\n\t\tpanic(err)\n\t}\n\tif s == \"a\" {\n\t\tif err := node.Decode(&b); err == nil {\n\t\t\tpanic(\"should have failed\")\n\t\t}\n\t\treturn node.Decode(&a)\n\t}\n\tif err := node.Decode(&a); err == nil {\n\t\tpanic(\"should have failed\")\n\t}\n\treturn node.Decode(&b)\n}\n\nfunc (s *S) TestUnmarshalerTypeErrorProxying(c *C) {\n\ttype T struct {\n\t\tBefore int\n\t\tAfter  int\n\t\tM      map[string]*proxyTypeError\n\t}\n\tvar v T\n\tdata := `{before: A, m: {abc: a, def: b}, after: B}`\n\terr := yaml.Unmarshal([]byte(data), &v)\n\tc.Assert(err, ErrorMatches, \"\"+\n\t\t\"yaml: unmarshal errors:\\n\"+\n\t\t\"  line 1: cannot unmarshal !!str `A` into int\\n\"+\n\t\t\"  line 1: cannot unmarshal !!str `a` into int32\\n\"+\n\t\t\"  line 1: cannot unmarshal !!str `b` into int64\\n\"+\n\t\t\"  line 1: cannot unmarshal !!str `B` into int\")\n}\n\ntype obsoleteProxyTypeError struct{}\n\nfunc (v *obsoleteProxyTypeError) UnmarshalYAML(unmarshal func(interface{}) error) error {\n\tvar s string\n\tvar a int32\n\tvar b int64\n\tif err := unmarshal(&s); err != nil {\n\t\tpanic(err)\n\t}\n\tif s == \"a\" {\n\t\tif err := unmarshal(&b); err == nil {\n\t\t\tpanic(\"should have failed\")\n\t\t}\n\t\treturn unmarshal(&a)\n\t}\n\tif err := unmarshal(&a); err == nil {\n\t\tpanic(\"should have failed\")\n\t}\n\treturn unmarshal(&b)\n}\n\nfunc (s *S) TestObsoleteUnmarshalerTypeErrorProxying(c *C) {\n\ttype T struct {\n\t\tBefore int\n\t\tAfter  int\n\t\tM      map[string]*obsoleteProxyTypeError\n\t}\n\tvar v T\n\tdata := `{before: A, m: {abc: a, def: b}, after: B}`\n\terr := yaml.Unmarshal([]byte(data), &v)\n\tc.Assert(err, ErrorMatches, \"\"+\n\t\t\"yaml: unmarshal errors:\\n\"+\n\t\t\"  line 1: cannot unmarshal !!str `A` into int\\n\"+\n\t\t\"  line 1: cannot unmarshal !!str `a` into int32\\n\"+\n\t\t\"  line 1: cannot unmarshal !!str `b` into int64\\n\"+\n\t\t\"  line 1: cannot unmarshal !!str `B` into int\")\n}\n\nvar failingErr = errors.New(\"failingErr\")\n\ntype failingUnmarshaler struct{}\n\nfunc (ft *failingUnmarshaler) UnmarshalYAML(node *yaml.Node) error {\n\treturn failingErr\n}\n\nfunc (s *S) TestUnmarshalerError(c *C) {\n\terr := yaml.Unmarshal([]byte(\"a: b\"), &failingUnmarshaler{})\n\tc.Assert(err, Equals, failingErr)\n}\n\ntype obsoleteFailingUnmarshaler struct{}\n\nfunc (ft *obsoleteFailingUnmarshaler) UnmarshalYAML(unmarshal func(interface{}) error) error {\n\treturn failingErr\n}\n\nfunc (s *S) TestObsoleteUnmarshalerError(c *C) {\n\terr := yaml.Unmarshal([]byte(\"a: b\"), &obsoleteFailingUnmarshaler{})\n\tc.Assert(err, Equals, failingErr)\n}\n\ntype sliceUnmarshaler []int\n\nfunc (su *sliceUnmarshaler) UnmarshalYAML(node *yaml.Node) error {\n\tvar slice []int\n\terr := node.Decode(&slice)\n\tif err == nil {\n\t\t*su = slice\n\t\treturn nil\n\t}\n\n\tvar intVal int\n\terr = node.Decode(&intVal)\n\tif err == nil {\n\t\t*su = []int{intVal}\n\t\treturn nil\n\t}\n\n\treturn err\n}\n\nfunc (s *S) TestUnmarshalerRetry(c *C) {\n\tvar su sliceUnmarshaler\n\terr := yaml.Unmarshal([]byte(\"[1, 2, 3]\"), &su)\n\tc.Assert(err, IsNil)\n\tc.Assert(su, DeepEquals, sliceUnmarshaler([]int{1, 2, 3}))\n\n\terr = yaml.Unmarshal([]byte(\"1\"), &su)\n\tc.Assert(err, IsNil)\n\tc.Assert(su, DeepEquals, sliceUnmarshaler([]int{1}))\n}\n\ntype obsoleteSliceUnmarshaler []int\n\nfunc (su *obsoleteSliceUnmarshaler) UnmarshalYAML(unmarshal func(interface{}) error) error {\n\tvar slice []int\n\terr := unmarshal(&slice)\n\tif err == nil {\n\t\t*su = slice\n\t\treturn nil\n\t}\n\n\tvar intVal int\n\terr = unmarshal(&intVal)\n\tif err == nil {\n\t\t*su = []int{intVal}\n\t\treturn nil\n\t}\n\n\treturn err\n}\n\nfunc (s *S) TestObsoleteUnmarshalerRetry(c *C) {\n\tvar su obsoleteSliceUnmarshaler\n\terr := yaml.Unmarshal([]byte(\"[1, 2, 3]\"), &su)\n\tc.Assert(err, IsNil)\n\tc.Assert(su, DeepEquals, obsoleteSliceUnmarshaler([]int{1, 2, 3}))\n\n\terr = yaml.Unmarshal([]byte(\"1\"), &su)\n\tc.Assert(err, IsNil)\n\tc.Assert(su, DeepEquals, obsoleteSliceUnmarshaler([]int{1}))\n}\n\n// From http://yaml.org/type/merge.html\nvar mergeTests = `\nanchors:\n  list:\n    - &CENTER { \"x\": 1, \"y\": 2 }\n    - &LEFT   { \"x\": 0, \"y\": 2 }\n    - &BIG    { \"r\": 10 }\n    - &SMALL  { \"r\": 1 }\n\n# All the following maps are equal:\n\nplain:\n  # Explicit keys\n  \"x\": 1\n  \"y\": 2\n  \"r\": 10\n  label: center/big\n\nmergeOne:\n  # Merge one map\n  << : *CENTER\n  \"r\": 10\n  label: center/big\n\nmergeMultiple:\n  # Merge multiple maps\n  << : [ *CENTER, *BIG ]\n  label: center/big\n\noverride:\n  # Override\n  << : [ *BIG, *LEFT, *SMALL ]\n  \"x\": 1\n  label: center/big\n\nshortTag:\n  # Explicit short merge tag\n  !!merge \"<<\" : [ *CENTER, *BIG ]\n  label: center/big\n\nlongTag:\n  # Explicit merge long tag\n  !<tag:yaml.org,2002:merge> \"<<\" : [ *CENTER, *BIG ]\n  label: center/big\n\ninlineMap:\n  # Inlined map \n  << : {\"x\": 1, \"y\": 2, \"r\": 10}\n  label: center/big\n\ninlineSequenceMap:\n  # Inlined map in sequence\n  << : [ *CENTER, {\"r\": 10} ]\n  label: center/big\n`\n\nfunc (s *S) TestMerge(c *C) {\n\tvar want = map[string]interface{}{\n\t\t\"x\":     1,\n\t\t\"y\":     2,\n\t\t\"r\":     10,\n\t\t\"label\": \"center/big\",\n\t}\n\n\twantStringMap := make(map[string]interface{})\n\tfor k, v := range want {\n\t\twantStringMap[fmt.Sprintf(\"%v\", k)] = v\n\t}\n\n\tvar m map[interface{}]interface{}\n\terr := yaml.Unmarshal([]byte(mergeTests), &m)\n\tc.Assert(err, IsNil)\n\tfor name, test := range m {\n\t\tif name == \"anchors\" {\n\t\t\tcontinue\n\t\t}\n\t\tif name == \"plain\" {\n\t\t\tc.Assert(test, DeepEquals, wantStringMap, Commentf(\"test %q failed\", name))\n\t\t\tcontinue\n\t\t}\n\t\tc.Assert(test, DeepEquals, want, Commentf(\"test %q failed\", name))\n\t}\n}\n\nfunc (s *S) TestMergeStruct(c *C) {\n\ttype Data struct {\n\t\tX, Y, R int\n\t\tLabel   string\n\t}\n\twant := Data{1, 2, 10, \"center/big\"}\n\n\tvar m map[string]Data\n\terr := yaml.Unmarshal([]byte(mergeTests), &m)\n\tc.Assert(err, IsNil)\n\tfor name, test := range m {\n\t\tif name == \"anchors\" {\n\t\t\tcontinue\n\t\t}\n\t\tc.Assert(test, Equals, want, Commentf(\"test %q failed\", name))\n\t}\n}\n\nvar mergeTestsNested = `\nmergeouter1: &mergeouter1\n    d: 40\n    e: 50\n\nmergeouter2: &mergeouter2\n    e: 5\n    f: 6\n    g: 70\n\nmergeinner1: &mergeinner1\n    <<: *mergeouter1\n    inner:\n        a: 1\n        b: 2\n\nmergeinner2: &mergeinner2\n    <<: *mergeouter2\n    inner:\n        a: -1\n        b: -2\n\nouter:\n    <<: [*mergeinner1, *mergeinner2]\n    f: 60\n    inner:\n        a: 10\n`\n\nfunc (s *S) TestMergeNestedStruct(c *C) {\n\t// Issue #818: Merging used to just unmarshal twice on the target\n\t// value, which worked for maps as these were replaced by the new map,\n\t// but not on struct values as these are preserved. This resulted in\n\t// the nested data from the merged map to be mixed up with the data\n\t// from the map being merged into.\n\t//\n\t// This test also prevents two potential bugs from showing up:\n\t//\n\t// 1) A simple implementation might just zero out the nested value\n\t//    before unmarshaling the second time, but this would clobber previous\n\t//    data that is usually respected ({C: 30} below).\n\t//\n\t// 2) A simple implementation might attempt to handle the key skipping\n\t//    directly by iterating over the merging map without recursion, but\n\t//    there are more complex cases that require recursion.\n\t// \n\t// Quick summary of the fields:\n\t//\n\t// - A must come from outer and not overriden\n\t// - B must not be set as its in the ignored merge\n\t// - C should still be set as it's preset in the value\n\t// - D should be set from the recursive merge\n\t// - E should be set from the first recursive merge, ignored on the second\n\t// - F should be set in the inlined map from outer, ignored later\n\t// - G should be set in the inlined map from the second recursive merge\n\t//\n\n\ttype Inner struct {\n\t\tA, B, C int\n\t}\n\ttype Outer struct {\n\t\tD, E      int\n\t\tInner  Inner\n\t\tInline map[string]int `yaml:\",inline\"`\n\t}\n\ttype Data struct {\n\t\tOuter Outer\n\t}\n\n\ttest := Data{Outer{0, 0, Inner{C: 30}, nil}}\n\twant := Data{Outer{40, 50, Inner{A: 10, C: 30}, map[string]int{\"f\": 60, \"g\": 70}}}\n\n\terr := yaml.Unmarshal([]byte(mergeTestsNested), &test)\n\tc.Assert(err, IsNil)\n\tc.Assert(test, DeepEquals, want)\n\n\t// Repeat test with a map.\n\n\tvar testm map[string]interface{}\n\tvar wantm = map[string]interface {} {\n\t\t\"f\":     60,\n\t\t\"inner\": map[string]interface{}{\n\t\t    \"a\": 10,\n\t\t},\n\t\t\"d\": 40,\n\t\t\"e\": 50,\n\t\t\"g\": 70,\n\t}\n\terr = yaml.Unmarshal([]byte(mergeTestsNested), &testm)\n\tc.Assert(err, IsNil)\n\tc.Assert(testm[\"outer\"], DeepEquals, wantm)\n}\n\nvar unmarshalNullTests = []struct {\n\tinput              string\n\tpristine, expected func() interface{}\n}{{\n\t\"null\",\n\tfunc() interface{} { var v interface{}; v = \"v\"; return &v },\n\tfunc() interface{} { var v interface{}; v = nil; return &v },\n}, {\n\t\"null\",\n\tfunc() interface{} { var s = \"s\"; return &s },\n\tfunc() interface{} { var s = \"s\"; return &s },\n}, {\n\t\"null\",\n\tfunc() interface{} { var s = \"s\"; sptr := &s; return &sptr },\n\tfunc() interface{} { var sptr *string; return &sptr },\n}, {\n\t\"null\",\n\tfunc() interface{} { var i = 1; return &i },\n\tfunc() interface{} { var i = 1; return &i },\n}, {\n\t\"null\",\n\tfunc() interface{} { var i = 1; iptr := &i; return &iptr },\n\tfunc() interface{} { var iptr *int; return &iptr },\n}, {\n\t\"null\",\n\tfunc() interface{} { var m = map[string]int{\"s\": 1}; return &m },\n\tfunc() interface{} { var m map[string]int; return &m },\n}, {\n\t\"null\",\n\tfunc() interface{} { var m = map[string]int{\"s\": 1}; return m },\n\tfunc() interface{} { var m = map[string]int{\"s\": 1}; return m },\n}, {\n\t\"s2: null\\ns3: null\",\n\tfunc() interface{} { var m = map[string]int{\"s1\": 1, \"s2\": 2}; return m },\n\tfunc() interface{} { var m = map[string]int{\"s1\": 1, \"s2\": 2, \"s3\": 0}; return m },\n}, {\n\t\"s2: null\\ns3: null\",\n\tfunc() interface{} { var m = map[string]interface{}{\"s1\": 1, \"s2\": 2}; return m },\n\tfunc() interface{} { var m = map[string]interface{}{\"s1\": 1, \"s2\": nil, \"s3\": nil}; return m },\n}}\n\nfunc (s *S) TestUnmarshalNull(c *C) {\n\tfor _, test := range unmarshalNullTests {\n\t\tpristine := test.pristine()\n\t\texpected := test.expected()\n\t\terr := yaml.Unmarshal([]byte(test.input), pristine)\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(pristine, DeepEquals, expected)\n\t}\n}\n\nfunc (s *S) TestUnmarshalPreservesData(c *C) {\n\tvar v struct {\n\t\tA, B int\n\t\tC    int `yaml:\"-\"`\n\t}\n\tv.A = 42\n\tv.C = 88\n\terr := yaml.Unmarshal([]byte(\"---\"), &v)\n\tc.Assert(err, IsNil)\n\tc.Assert(v.A, Equals, 42)\n\tc.Assert(v.B, Equals, 0)\n\tc.Assert(v.C, Equals, 88)\n\n\terr = yaml.Unmarshal([]byte(\"b: 21\\nc: 99\"), &v)\n\tc.Assert(err, IsNil)\n\tc.Assert(v.A, Equals, 42)\n\tc.Assert(v.B, Equals, 21)\n\tc.Assert(v.C, Equals, 88)\n}\n\nfunc (s *S) TestUnmarshalSliceOnPreset(c *C) {\n\t// Issue #48.\n\tv := struct{ A []int }{[]int{1}}\n\tyaml.Unmarshal([]byte(\"a: [2]\"), &v)\n\tc.Assert(v.A, DeepEquals, []int{2})\n}\n\nvar unmarshalStrictTests = []struct {\n\tknown  bool\n\tunique bool\n\tdata   string\n\tvalue  interface{}\n\terror  string\n}{{\n\tknown: true,\n\tdata:  \"a: 1\\nc: 2\\n\",\n\tvalue: struct{ A, B int }{A: 1},\n\terror: `yaml: unmarshal errors:\\n  line 2: field c not found in type struct { A int; B int }`,\n}, {\n\tunique: true,\n\tdata:   \"a: 1\\nb: 2\\na: 3\\n\",\n\tvalue:  struct{ A, B int }{A: 3, B: 2},\n\terror:  `yaml: unmarshal errors:\\n  line 3: mapping key \"a\" already defined at line 1`,\n}, {\n\tunique: true,\n\tdata:   \"c: 3\\na: 1\\nb: 2\\nc: 4\\n\",\n\tvalue: struct {\n\t\tA       int\n\t\tinlineB `yaml:\",inline\"`\n\t}{\n\t\tA: 1,\n\t\tinlineB: inlineB{\n\t\t\tB: 2,\n\t\t\tinlineC: inlineC{\n\t\t\t\tC: 4,\n\t\t\t},\n\t\t},\n\t},\n\terror: `yaml: unmarshal errors:\\n  line 4: mapping key \"c\" already defined at line 1`,\n}, {\n\tunique: true,\n\tdata:   \"c: 0\\na: 1\\nb: 2\\nc: 1\\n\",\n\tvalue: struct {\n\t\tA       int\n\t\tinlineB `yaml:\",inline\"`\n\t}{\n\t\tA: 1,\n\t\tinlineB: inlineB{\n\t\t\tB: 2,\n\t\t\tinlineC: inlineC{\n\t\t\t\tC: 1,\n\t\t\t},\n\t\t},\n\t},\n\terror: `yaml: unmarshal errors:\\n  line 4: mapping key \"c\" already defined at line 1`,\n}, {\n\tunique: true,\n\tdata:   \"c: 1\\na: 1\\nb: 2\\nc: 3\\n\",\n\tvalue: struct {\n\t\tA int\n\t\tM map[string]interface{} `yaml:\",inline\"`\n\t}{\n\t\tA: 1,\n\t\tM: map[string]interface{}{\n\t\t\t\"b\": 2,\n\t\t\t\"c\": 3,\n\t\t},\n\t},\n\terror: `yaml: unmarshal errors:\\n  line 4: mapping key \"c\" already defined at line 1`,\n}, {\n\tunique: true,\n\tdata:   \"a: 1\\n9: 2\\nnull: 3\\n9: 4\",\n\tvalue: map[interface{}]interface{}{\n\t\t\"a\": 1,\n\t\tnil: 3,\n\t\t9:   4,\n\t},\n\terror: `yaml: unmarshal errors:\\n  line 4: mapping key \"9\" already defined at line 2`,\n}}\n\nfunc (s *S) TestUnmarshalKnownFields(c *C) {\n\tfor i, item := range unmarshalStrictTests {\n\t\tc.Logf(\"test %d: %q\", i, item.data)\n\t\t// First test that normal Unmarshal unmarshals to the expected value.\n\t\tif !item.unique {\n\t\t\tt := reflect.ValueOf(item.value).Type()\n\t\t\tvalue := reflect.New(t)\n\t\t\terr := yaml.Unmarshal([]byte(item.data), value.Interface())\n\t\t\tc.Assert(err, Equals, nil)\n\t\t\tc.Assert(value.Elem().Interface(), DeepEquals, item.value)\n\t\t}\n\n\t\t// Then test that it fails on the same thing with KnownFields on.\n\t\tt := reflect.ValueOf(item.value).Type()\n\t\tvalue := reflect.New(t)\n\t\tdec := yaml.NewDecoder(bytes.NewBuffer([]byte(item.data)))\n\t\tdec.KnownFields(item.known)\n\t\terr := dec.Decode(value.Interface())\n\t\tc.Assert(err, ErrorMatches, item.error)\n\t}\n}\n\ntype textUnmarshaler struct {\n\tS string\n}\n\nfunc (t *textUnmarshaler) UnmarshalText(s []byte) error {\n\tt.S = string(s)\n\treturn nil\n}\n\nfunc (s *S) TestFuzzCrashers(c *C) {\n\tcases := []string{\n\t\t// runtime error: index out of range\n\t\t\"\\\"\\\\0\\\\\\r\\n\",\n\n\t\t// should not happen\n\t\t\"  0: [\\n] 0\",\n\t\t\"? ? \\\"\\n\\\" 0\",\n\t\t\"    - {\\n000}0\",\n\t\t\"0:\\n  0: [0\\n] 0\",\n\t\t\"    - \\\"\\n000\\\"0\",\n\t\t\"    - \\\"\\n000\\\"\\\"\",\n\t\t\"0:\\n    - {\\n000}0\",\n\t\t\"0:\\n    - \\\"\\n000\\\"0\",\n\t\t\"0:\\n    - \\\"\\n000\\\"\\\"\",\n\n\t\t// runtime error: index out of range\n\t\t\" \\ufeff\\n\",\n\t\t\"? \\ufeff\\n\",\n\t\t\"? \\ufeff:\\n\",\n\t\t\"0: \\ufeff\\n\",\n\t\t\"? \\ufeff: \\ufeff\\n\",\n\t}\n\tfor _, data := range cases {\n\t\tvar v interface{}\n\t\t_ = yaml.Unmarshal([]byte(data), &v)\n\t}\n}\n\n//var data []byte\n//func init() {\n//\tvar err error\n//\tdata, err = ioutil.ReadFile(\"/tmp/file.yaml\")\n//\tif err != nil {\n//\t\tpanic(err)\n//\t}\n//}\n//\n//func (s *S) BenchmarkUnmarshal(c *C) {\n//\tvar err error\n//\tfor i := 0; i < c.N; i++ {\n//\t\tvar v map[string]interface{}\n//\t\terr = yaml.Unmarshal(data, &v)\n//\t}\n//\tif err != nil {\n//\t\tpanic(err)\n//\t}\n//}\n//\n//func (s *S) BenchmarkMarshal(c *C) {\n//\tvar v map[string]interface{}\n//\tyaml.Unmarshal(data, &v)\n//\tc.ResetTimer()\n//\tfor i := 0; i < c.N; i++ {\n//\t\tyaml.Marshal(&v)\n//\t}\n//}\n"
        },
        {
          "name": "emitterc.go",
          "type": "blob",
          "size": 53.8935546875,
          "content": "//\n// Copyright (c) 2011-2019 Canonical Ltd\n// Copyright (c) 2006-2010 Kirill Simonov\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy of\n// this software and associated documentation files (the \"Software\"), to deal in\n// the Software without restriction, including without limitation the rights to\n// use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\n// of the Software, and to permit persons to whom the Software is furnished to do\n// so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\npackage yaml\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n)\n\n// Flush the buffer if needed.\nfunc flush(emitter *yaml_emitter_t) bool {\n\tif emitter.buffer_pos+5 >= len(emitter.buffer) {\n\t\treturn yaml_emitter_flush(emitter)\n\t}\n\treturn true\n}\n\n// Put a character to the output buffer.\nfunc put(emitter *yaml_emitter_t, value byte) bool {\n\tif emitter.buffer_pos+5 >= len(emitter.buffer) && !yaml_emitter_flush(emitter) {\n\t\treturn false\n\t}\n\temitter.buffer[emitter.buffer_pos] = value\n\temitter.buffer_pos++\n\temitter.column++\n\treturn true\n}\n\n// Put a line break to the output buffer.\nfunc put_break(emitter *yaml_emitter_t) bool {\n\tif emitter.buffer_pos+5 >= len(emitter.buffer) && !yaml_emitter_flush(emitter) {\n\t\treturn false\n\t}\n\tswitch emitter.line_break {\n\tcase yaml_CR_BREAK:\n\t\temitter.buffer[emitter.buffer_pos] = '\\r'\n\t\temitter.buffer_pos += 1\n\tcase yaml_LN_BREAK:\n\t\temitter.buffer[emitter.buffer_pos] = '\\n'\n\t\temitter.buffer_pos += 1\n\tcase yaml_CRLN_BREAK:\n\t\temitter.buffer[emitter.buffer_pos+0] = '\\r'\n\t\temitter.buffer[emitter.buffer_pos+1] = '\\n'\n\t\temitter.buffer_pos += 2\n\tdefault:\n\t\tpanic(\"unknown line break setting\")\n\t}\n\tif emitter.column == 0 {\n\t\temitter.space_above = true\n\t}\n\temitter.column = 0\n\temitter.line++\n\t// [Go] Do this here and below and drop from everywhere else (see commented lines).\n\temitter.indention = true\n\treturn true\n}\n\n// Copy a character from a string into buffer.\nfunc write(emitter *yaml_emitter_t, s []byte, i *int) bool {\n\tif emitter.buffer_pos+5 >= len(emitter.buffer) && !yaml_emitter_flush(emitter) {\n\t\treturn false\n\t}\n\tp := emitter.buffer_pos\n\tw := width(s[*i])\n\tswitch w {\n\tcase 4:\n\t\temitter.buffer[p+3] = s[*i+3]\n\t\tfallthrough\n\tcase 3:\n\t\temitter.buffer[p+2] = s[*i+2]\n\t\tfallthrough\n\tcase 2:\n\t\temitter.buffer[p+1] = s[*i+1]\n\t\tfallthrough\n\tcase 1:\n\t\temitter.buffer[p+0] = s[*i+0]\n\tdefault:\n\t\tpanic(\"unknown character width\")\n\t}\n\temitter.column++\n\temitter.buffer_pos += w\n\t*i += w\n\treturn true\n}\n\n// Write a whole string into buffer.\nfunc write_all(emitter *yaml_emitter_t, s []byte) bool {\n\tfor i := 0; i < len(s); {\n\t\tif !write(emitter, s, &i) {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\n// Copy a line break character from a string into buffer.\nfunc write_break(emitter *yaml_emitter_t, s []byte, i *int) bool {\n\tif s[*i] == '\\n' {\n\t\tif !put_break(emitter) {\n\t\t\treturn false\n\t\t}\n\t\t*i++\n\t} else {\n\t\tif !write(emitter, s, i) {\n\t\t\treturn false\n\t\t}\n\t\tif emitter.column == 0 {\n\t\t\temitter.space_above = true\n\t\t}\n\t\temitter.column = 0\n\t\temitter.line++\n\t\t// [Go] Do this here and above and drop from everywhere else (see commented lines).\n\t\temitter.indention = true\n\t}\n\treturn true\n}\n\n// Set an emitter error and return false.\nfunc yaml_emitter_set_emitter_error(emitter *yaml_emitter_t, problem string) bool {\n\temitter.error = yaml_EMITTER_ERROR\n\temitter.problem = problem\n\treturn false\n}\n\n// Emit an event.\nfunc yaml_emitter_emit(emitter *yaml_emitter_t, event *yaml_event_t) bool {\n\temitter.events = append(emitter.events, *event)\n\tfor !yaml_emitter_need_more_events(emitter) {\n\t\tevent := &emitter.events[emitter.events_head]\n\t\tif !yaml_emitter_analyze_event(emitter, event) {\n\t\t\treturn false\n\t\t}\n\t\tif !yaml_emitter_state_machine(emitter, event) {\n\t\t\treturn false\n\t\t}\n\t\tyaml_event_delete(event)\n\t\temitter.events_head++\n\t}\n\treturn true\n}\n\n// Check if we need to accumulate more events before emitting.\n//\n// We accumulate extra\n//  - 1 event for DOCUMENT-START\n//  - 2 events for SEQUENCE-START\n//  - 3 events for MAPPING-START\n//\nfunc yaml_emitter_need_more_events(emitter *yaml_emitter_t) bool {\n\tif emitter.events_head == len(emitter.events) {\n\t\treturn true\n\t}\n\tvar accumulate int\n\tswitch emitter.events[emitter.events_head].typ {\n\tcase yaml_DOCUMENT_START_EVENT:\n\t\taccumulate = 1\n\t\tbreak\n\tcase yaml_SEQUENCE_START_EVENT:\n\t\taccumulate = 2\n\t\tbreak\n\tcase yaml_MAPPING_START_EVENT:\n\t\taccumulate = 3\n\t\tbreak\n\tdefault:\n\t\treturn false\n\t}\n\tif len(emitter.events)-emitter.events_head > accumulate {\n\t\treturn false\n\t}\n\tvar level int\n\tfor i := emitter.events_head; i < len(emitter.events); i++ {\n\t\tswitch emitter.events[i].typ {\n\t\tcase yaml_STREAM_START_EVENT, yaml_DOCUMENT_START_EVENT, yaml_SEQUENCE_START_EVENT, yaml_MAPPING_START_EVENT:\n\t\t\tlevel++\n\t\tcase yaml_STREAM_END_EVENT, yaml_DOCUMENT_END_EVENT, yaml_SEQUENCE_END_EVENT, yaml_MAPPING_END_EVENT:\n\t\t\tlevel--\n\t\t}\n\t\tif level == 0 {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\n// Append a directive to the directives stack.\nfunc yaml_emitter_append_tag_directive(emitter *yaml_emitter_t, value *yaml_tag_directive_t, allow_duplicates bool) bool {\n\tfor i := 0; i < len(emitter.tag_directives); i++ {\n\t\tif bytes.Equal(value.handle, emitter.tag_directives[i].handle) {\n\t\t\tif allow_duplicates {\n\t\t\t\treturn true\n\t\t\t}\n\t\t\treturn yaml_emitter_set_emitter_error(emitter, \"duplicate %TAG directive\")\n\t\t}\n\t}\n\n\t// [Go] Do we actually need to copy this given garbage collection\n\t// and the lack of deallocating destructors?\n\ttag_copy := yaml_tag_directive_t{\n\t\thandle: make([]byte, len(value.handle)),\n\t\tprefix: make([]byte, len(value.prefix)),\n\t}\n\tcopy(tag_copy.handle, value.handle)\n\tcopy(tag_copy.prefix, value.prefix)\n\temitter.tag_directives = append(emitter.tag_directives, tag_copy)\n\treturn true\n}\n\n// Increase the indentation level.\nfunc yaml_emitter_increase_indent(emitter *yaml_emitter_t, flow, indentless bool) bool {\n\temitter.indents = append(emitter.indents, emitter.indent)\n\tif emitter.indent < 0 {\n\t\tif flow {\n\t\t\temitter.indent = emitter.best_indent\n\t\t} else {\n\t\t\temitter.indent = 0\n\t\t}\n\t} else if !indentless {\n\t\t// [Go] This was changed so that indentations are more regular.\n\t\tif emitter.states[len(emitter.states)-1] == yaml_EMIT_BLOCK_SEQUENCE_ITEM_STATE {\n\t\t\t// The first indent inside a sequence will just skip the \"- \" indicator.\n\t\t\temitter.indent += 2\n\t\t} else {\n\t\t\t// Everything else aligns to the chosen indentation.\n\t\t\temitter.indent = emitter.best_indent*((emitter.indent+emitter.best_indent)/emitter.best_indent)\n\t\t}\n\t}\n\treturn true\n}\n\n// State dispatcher.\nfunc yaml_emitter_state_machine(emitter *yaml_emitter_t, event *yaml_event_t) bool {\n\tswitch emitter.state {\n\tdefault:\n\tcase yaml_EMIT_STREAM_START_STATE:\n\t\treturn yaml_emitter_emit_stream_start(emitter, event)\n\n\tcase yaml_EMIT_FIRST_DOCUMENT_START_STATE:\n\t\treturn yaml_emitter_emit_document_start(emitter, event, true)\n\n\tcase yaml_EMIT_DOCUMENT_START_STATE:\n\t\treturn yaml_emitter_emit_document_start(emitter, event, false)\n\n\tcase yaml_EMIT_DOCUMENT_CONTENT_STATE:\n\t\treturn yaml_emitter_emit_document_content(emitter, event)\n\n\tcase yaml_EMIT_DOCUMENT_END_STATE:\n\t\treturn yaml_emitter_emit_document_end(emitter, event)\n\n\tcase yaml_EMIT_FLOW_SEQUENCE_FIRST_ITEM_STATE:\n\t\treturn yaml_emitter_emit_flow_sequence_item(emitter, event, true, false)\n\n\tcase yaml_EMIT_FLOW_SEQUENCE_TRAIL_ITEM_STATE:\n\t\treturn yaml_emitter_emit_flow_sequence_item(emitter, event, false, true)\n\n\tcase yaml_EMIT_FLOW_SEQUENCE_ITEM_STATE:\n\t\treturn yaml_emitter_emit_flow_sequence_item(emitter, event, false, false)\n\n\tcase yaml_EMIT_FLOW_MAPPING_FIRST_KEY_STATE:\n\t\treturn yaml_emitter_emit_flow_mapping_key(emitter, event, true, false)\n\n\tcase yaml_EMIT_FLOW_MAPPING_TRAIL_KEY_STATE:\n\t\treturn yaml_emitter_emit_flow_mapping_key(emitter, event, false, true)\n\n\tcase yaml_EMIT_FLOW_MAPPING_KEY_STATE:\n\t\treturn yaml_emitter_emit_flow_mapping_key(emitter, event, false, false)\n\n\tcase yaml_EMIT_FLOW_MAPPING_SIMPLE_VALUE_STATE:\n\t\treturn yaml_emitter_emit_flow_mapping_value(emitter, event, true)\n\n\tcase yaml_EMIT_FLOW_MAPPING_VALUE_STATE:\n\t\treturn yaml_emitter_emit_flow_mapping_value(emitter, event, false)\n\n\tcase yaml_EMIT_BLOCK_SEQUENCE_FIRST_ITEM_STATE:\n\t\treturn yaml_emitter_emit_block_sequence_item(emitter, event, true)\n\n\tcase yaml_EMIT_BLOCK_SEQUENCE_ITEM_STATE:\n\t\treturn yaml_emitter_emit_block_sequence_item(emitter, event, false)\n\n\tcase yaml_EMIT_BLOCK_MAPPING_FIRST_KEY_STATE:\n\t\treturn yaml_emitter_emit_block_mapping_key(emitter, event, true)\n\n\tcase yaml_EMIT_BLOCK_MAPPING_KEY_STATE:\n\t\treturn yaml_emitter_emit_block_mapping_key(emitter, event, false)\n\n\tcase yaml_EMIT_BLOCK_MAPPING_SIMPLE_VALUE_STATE:\n\t\treturn yaml_emitter_emit_block_mapping_value(emitter, event, true)\n\n\tcase yaml_EMIT_BLOCK_MAPPING_VALUE_STATE:\n\t\treturn yaml_emitter_emit_block_mapping_value(emitter, event, false)\n\n\tcase yaml_EMIT_END_STATE:\n\t\treturn yaml_emitter_set_emitter_error(emitter, \"expected nothing after STREAM-END\")\n\t}\n\tpanic(\"invalid emitter state\")\n}\n\n// Expect STREAM-START.\nfunc yaml_emitter_emit_stream_start(emitter *yaml_emitter_t, event *yaml_event_t) bool {\n\tif event.typ != yaml_STREAM_START_EVENT {\n\t\treturn yaml_emitter_set_emitter_error(emitter, \"expected STREAM-START\")\n\t}\n\tif emitter.encoding == yaml_ANY_ENCODING {\n\t\temitter.encoding = event.encoding\n\t\tif emitter.encoding == yaml_ANY_ENCODING {\n\t\t\temitter.encoding = yaml_UTF8_ENCODING\n\t\t}\n\t}\n\tif emitter.best_indent < 2 || emitter.best_indent > 9 {\n\t\temitter.best_indent = 2\n\t}\n\tif emitter.best_width >= 0 && emitter.best_width <= emitter.best_indent*2 {\n\t\temitter.best_width = 80\n\t}\n\tif emitter.best_width < 0 {\n\t\temitter.best_width = 1<<31 - 1\n\t}\n\tif emitter.line_break == yaml_ANY_BREAK {\n\t\temitter.line_break = yaml_LN_BREAK\n\t}\n\n\temitter.indent = -1\n\temitter.line = 0\n\temitter.column = 0\n\temitter.whitespace = true\n\temitter.indention = true\n\temitter.space_above = true\n\temitter.foot_indent = -1\n\n\tif emitter.encoding != yaml_UTF8_ENCODING {\n\t\tif !yaml_emitter_write_bom(emitter) {\n\t\t\treturn false\n\t\t}\n\t}\n\temitter.state = yaml_EMIT_FIRST_DOCUMENT_START_STATE\n\treturn true\n}\n\n// Expect DOCUMENT-START or STREAM-END.\nfunc yaml_emitter_emit_document_start(emitter *yaml_emitter_t, event *yaml_event_t, first bool) bool {\n\n\tif event.typ == yaml_DOCUMENT_START_EVENT {\n\n\t\tif event.version_directive != nil {\n\t\t\tif !yaml_emitter_analyze_version_directive(emitter, event.version_directive) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\n\t\tfor i := 0; i < len(event.tag_directives); i++ {\n\t\t\ttag_directive := &event.tag_directives[i]\n\t\t\tif !yaml_emitter_analyze_tag_directive(emitter, tag_directive) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tif !yaml_emitter_append_tag_directive(emitter, tag_directive, false) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\n\t\tfor i := 0; i < len(default_tag_directives); i++ {\n\t\t\ttag_directive := &default_tag_directives[i]\n\t\t\tif !yaml_emitter_append_tag_directive(emitter, tag_directive, true) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\n\t\timplicit := event.implicit\n\t\tif !first || emitter.canonical {\n\t\t\timplicit = false\n\t\t}\n\n\t\tif emitter.open_ended && (event.version_directive != nil || len(event.tag_directives) > 0) {\n\t\t\tif !yaml_emitter_write_indicator(emitter, []byte(\"...\"), true, false, false) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\n\t\tif event.version_directive != nil {\n\t\t\timplicit = false\n\t\t\tif !yaml_emitter_write_indicator(emitter, []byte(\"%YAML\"), true, false, false) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tif !yaml_emitter_write_indicator(emitter, []byte(\"1.1\"), true, false, false) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\n\t\tif len(event.tag_directives) > 0 {\n\t\t\timplicit = false\n\t\t\tfor i := 0; i < len(event.tag_directives); i++ {\n\t\t\t\ttag_directive := &event.tag_directives[i]\n\t\t\t\tif !yaml_emitter_write_indicator(emitter, []byte(\"%TAG\"), true, false, false) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\tif !yaml_emitter_write_tag_handle(emitter, tag_directive.handle) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\tif !yaml_emitter_write_tag_content(emitter, tag_directive.prefix, true) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif yaml_emitter_check_empty_document(emitter) {\n\t\t\timplicit = false\n\t\t}\n\t\tif !implicit {\n\t\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tif !yaml_emitter_write_indicator(emitter, []byte(\"---\"), true, false, false) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tif emitter.canonical || true {\n\t\t\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif len(emitter.head_comment) > 0 {\n\t\t\tif !yaml_emitter_process_head_comment(emitter) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tif !put_break(emitter) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\n\t\temitter.state = yaml_EMIT_DOCUMENT_CONTENT_STATE\n\t\treturn true\n\t}\n\n\tif event.typ == yaml_STREAM_END_EVENT {\n\t\tif emitter.open_ended {\n\t\t\tif !yaml_emitter_write_indicator(emitter, []byte(\"...\"), true, false, false) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\tif !yaml_emitter_flush(emitter) {\n\t\t\treturn false\n\t\t}\n\t\temitter.state = yaml_EMIT_END_STATE\n\t\treturn true\n\t}\n\n\treturn yaml_emitter_set_emitter_error(emitter, \"expected DOCUMENT-START or STREAM-END\")\n}\n\n// Expect the root node.\nfunc yaml_emitter_emit_document_content(emitter *yaml_emitter_t, event *yaml_event_t) bool {\n\temitter.states = append(emitter.states, yaml_EMIT_DOCUMENT_END_STATE)\n\n\tif !yaml_emitter_process_head_comment(emitter) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_emit_node(emitter, event, true, false, false, false) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_process_line_comment(emitter) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_process_foot_comment(emitter) {\n\t\treturn false\n\t}\n\treturn true\n}\n\n// Expect DOCUMENT-END.\nfunc yaml_emitter_emit_document_end(emitter *yaml_emitter_t, event *yaml_event_t) bool {\n\tif event.typ != yaml_DOCUMENT_END_EVENT {\n\t\treturn yaml_emitter_set_emitter_error(emitter, \"expected DOCUMENT-END\")\n\t}\n\t// [Go] Force document foot separation.\n\temitter.foot_indent = 0\n\tif !yaml_emitter_process_foot_comment(emitter) {\n\t\treturn false\n\t}\n\temitter.foot_indent = -1\n\tif !yaml_emitter_write_indent(emitter) {\n\t\treturn false\n\t}\n\tif !event.implicit {\n\t\t// [Go] Allocate the slice elsewhere.\n\t\tif !yaml_emitter_write_indicator(emitter, []byte(\"...\"), true, false, false) {\n\t\t\treturn false\n\t\t}\n\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\treturn false\n\t\t}\n\t}\n\tif !yaml_emitter_flush(emitter) {\n\t\treturn false\n\t}\n\temitter.state = yaml_EMIT_DOCUMENT_START_STATE\n\temitter.tag_directives = emitter.tag_directives[:0]\n\treturn true\n}\n\n// Expect a flow item node.\nfunc yaml_emitter_emit_flow_sequence_item(emitter *yaml_emitter_t, event *yaml_event_t, first, trail bool) bool {\n\tif first {\n\t\tif !yaml_emitter_write_indicator(emitter, []byte{'['}, true, true, false) {\n\t\t\treturn false\n\t\t}\n\t\tif !yaml_emitter_increase_indent(emitter, true, false) {\n\t\t\treturn false\n\t\t}\n\t\temitter.flow_level++\n\t}\n\n\tif event.typ == yaml_SEQUENCE_END_EVENT {\n\t\tif emitter.canonical && !first && !trail {\n\t\t\tif !yaml_emitter_write_indicator(emitter, []byte{','}, false, false, false) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\temitter.flow_level--\n\t\temitter.indent = emitter.indents[len(emitter.indents)-1]\n\t\temitter.indents = emitter.indents[:len(emitter.indents)-1]\n\t\tif emitter.column == 0 || emitter.canonical && !first {\n\t\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\tif !yaml_emitter_write_indicator(emitter, []byte{']'}, false, false, false) {\n\t\t\treturn false\n\t\t}\n\t\tif !yaml_emitter_process_line_comment(emitter) {\n\t\t\treturn false\n\t\t}\n\t\tif !yaml_emitter_process_foot_comment(emitter) {\n\t\t\treturn false\n\t\t}\n\t\temitter.state = emitter.states[len(emitter.states)-1]\n\t\temitter.states = emitter.states[:len(emitter.states)-1]\n\n\t\treturn true\n\t}\n\n\tif !first && !trail {\n\t\tif !yaml_emitter_write_indicator(emitter, []byte{','}, false, false, false) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\tif !yaml_emitter_process_head_comment(emitter) {\n\t\treturn false\n\t}\n\tif emitter.column == 0 {\n\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\tif emitter.canonical || emitter.column > emitter.best_width {\n\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\treturn false\n\t\t}\n\t}\n\tif len(emitter.line_comment)+len(emitter.foot_comment)+len(emitter.tail_comment) > 0 {\n\t\temitter.states = append(emitter.states, yaml_EMIT_FLOW_SEQUENCE_TRAIL_ITEM_STATE)\n\t} else {\n\t\temitter.states = append(emitter.states, yaml_EMIT_FLOW_SEQUENCE_ITEM_STATE)\n\t}\n\tif !yaml_emitter_emit_node(emitter, event, false, true, false, false) {\n\t\treturn false\n\t}\n\tif len(emitter.line_comment)+len(emitter.foot_comment)+len(emitter.tail_comment) > 0 {\n\t\tif !yaml_emitter_write_indicator(emitter, []byte{','}, false, false, false) {\n\t\t\treturn false\n\t\t}\n\t}\n\tif !yaml_emitter_process_line_comment(emitter) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_process_foot_comment(emitter) {\n\t\treturn false\n\t}\n\treturn true\n}\n\n// Expect a flow key node.\nfunc yaml_emitter_emit_flow_mapping_key(emitter *yaml_emitter_t, event *yaml_event_t, first, trail bool) bool {\n\tif first {\n\t\tif !yaml_emitter_write_indicator(emitter, []byte{'{'}, true, true, false) {\n\t\t\treturn false\n\t\t}\n\t\tif !yaml_emitter_increase_indent(emitter, true, false) {\n\t\t\treturn false\n\t\t}\n\t\temitter.flow_level++\n\t}\n\n\tif event.typ == yaml_MAPPING_END_EVENT {\n\t\tif (emitter.canonical || len(emitter.head_comment)+len(emitter.foot_comment)+len(emitter.tail_comment) > 0) && !first && !trail {\n\t\t\tif !yaml_emitter_write_indicator(emitter, []byte{','}, false, false, false) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\tif !yaml_emitter_process_head_comment(emitter) {\n\t\t\treturn false\n\t\t}\n\t\temitter.flow_level--\n\t\temitter.indent = emitter.indents[len(emitter.indents)-1]\n\t\temitter.indents = emitter.indents[:len(emitter.indents)-1]\n\t\tif emitter.canonical && !first {\n\t\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\tif !yaml_emitter_write_indicator(emitter, []byte{'}'}, false, false, false) {\n\t\t\treturn false\n\t\t}\n\t\tif !yaml_emitter_process_line_comment(emitter) {\n\t\t\treturn false\n\t\t}\n\t\tif !yaml_emitter_process_foot_comment(emitter) {\n\t\t\treturn false\n\t\t}\n\t\temitter.state = emitter.states[len(emitter.states)-1]\n\t\temitter.states = emitter.states[:len(emitter.states)-1]\n\t\treturn true\n\t}\n\n\tif !first && !trail {\n\t\tif !yaml_emitter_write_indicator(emitter, []byte{','}, false, false, false) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\tif !yaml_emitter_process_head_comment(emitter) {\n\t\treturn false\n\t}\n\n\tif emitter.column == 0 {\n\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\tif emitter.canonical || emitter.column > emitter.best_width {\n\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\tif !emitter.canonical && yaml_emitter_check_simple_key(emitter) {\n\t\temitter.states = append(emitter.states, yaml_EMIT_FLOW_MAPPING_SIMPLE_VALUE_STATE)\n\t\treturn yaml_emitter_emit_node(emitter, event, false, false, true, true)\n\t}\n\tif !yaml_emitter_write_indicator(emitter, []byte{'?'}, true, false, false) {\n\t\treturn false\n\t}\n\temitter.states = append(emitter.states, yaml_EMIT_FLOW_MAPPING_VALUE_STATE)\n\treturn yaml_emitter_emit_node(emitter, event, false, false, true, false)\n}\n\n// Expect a flow value node.\nfunc yaml_emitter_emit_flow_mapping_value(emitter *yaml_emitter_t, event *yaml_event_t, simple bool) bool {\n\tif simple {\n\t\tif !yaml_emitter_write_indicator(emitter, []byte{':'}, false, false, false) {\n\t\t\treturn false\n\t\t}\n\t} else {\n\t\tif emitter.canonical || emitter.column > emitter.best_width {\n\t\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\tif !yaml_emitter_write_indicator(emitter, []byte{':'}, true, false, false) {\n\t\t\treturn false\n\t\t}\n\t}\n\tif len(emitter.line_comment)+len(emitter.foot_comment)+len(emitter.tail_comment) > 0 {\n\t\temitter.states = append(emitter.states, yaml_EMIT_FLOW_MAPPING_TRAIL_KEY_STATE)\n\t} else {\n\t\temitter.states = append(emitter.states, yaml_EMIT_FLOW_MAPPING_KEY_STATE)\n\t}\n\tif !yaml_emitter_emit_node(emitter, event, false, false, true, false) {\n\t\treturn false\n\t}\n\tif len(emitter.line_comment)+len(emitter.foot_comment)+len(emitter.tail_comment) > 0 {\n\t\tif !yaml_emitter_write_indicator(emitter, []byte{','}, false, false, false) {\n\t\t\treturn false\n\t\t}\n\t}\n\tif !yaml_emitter_process_line_comment(emitter) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_process_foot_comment(emitter) {\n\t\treturn false\n\t}\n\treturn true\n}\n\n// Expect a block item node.\nfunc yaml_emitter_emit_block_sequence_item(emitter *yaml_emitter_t, event *yaml_event_t, first bool) bool {\n\tif first {\n\t\tif !yaml_emitter_increase_indent(emitter, false, false) {\n\t\t\treturn false\n\t\t}\n\t}\n\tif event.typ == yaml_SEQUENCE_END_EVENT {\n\t\temitter.indent = emitter.indents[len(emitter.indents)-1]\n\t\temitter.indents = emitter.indents[:len(emitter.indents)-1]\n\t\temitter.state = emitter.states[len(emitter.states)-1]\n\t\temitter.states = emitter.states[:len(emitter.states)-1]\n\t\treturn true\n\t}\n\tif !yaml_emitter_process_head_comment(emitter) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_write_indent(emitter) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_write_indicator(emitter, []byte{'-'}, true, false, true) {\n\t\treturn false\n\t}\n\temitter.states = append(emitter.states, yaml_EMIT_BLOCK_SEQUENCE_ITEM_STATE)\n\tif !yaml_emitter_emit_node(emitter, event, false, true, false, false) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_process_line_comment(emitter) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_process_foot_comment(emitter) {\n\t\treturn false\n\t}\n\treturn true\n}\n\n// Expect a block key node.\nfunc yaml_emitter_emit_block_mapping_key(emitter *yaml_emitter_t, event *yaml_event_t, first bool) bool {\n\tif first {\n\t\tif !yaml_emitter_increase_indent(emitter, false, false) {\n\t\t\treturn false\n\t\t}\n\t}\n\tif !yaml_emitter_process_head_comment(emitter) {\n\t\treturn false\n\t}\n\tif event.typ == yaml_MAPPING_END_EVENT {\n\t\temitter.indent = emitter.indents[len(emitter.indents)-1]\n\t\temitter.indents = emitter.indents[:len(emitter.indents)-1]\n\t\temitter.state = emitter.states[len(emitter.states)-1]\n\t\temitter.states = emitter.states[:len(emitter.states)-1]\n\t\treturn true\n\t}\n\tif !yaml_emitter_write_indent(emitter) {\n\t\treturn false\n\t}\n\tif len(emitter.line_comment) > 0 {\n\t\t// [Go] A line comment was provided for the key. That's unusual as the\n\t\t//      scanner associates line comments with the value. Either way,\n\t\t//      save the line comment and render it appropriately later.\n\t\temitter.key_line_comment = emitter.line_comment\n\t\temitter.line_comment = nil\n\t}\n\tif yaml_emitter_check_simple_key(emitter) {\n\t\temitter.states = append(emitter.states, yaml_EMIT_BLOCK_MAPPING_SIMPLE_VALUE_STATE)\n\t\treturn yaml_emitter_emit_node(emitter, event, false, false, true, true)\n\t}\n\tif !yaml_emitter_write_indicator(emitter, []byte{'?'}, true, false, true) {\n\t\treturn false\n\t}\n\temitter.states = append(emitter.states, yaml_EMIT_BLOCK_MAPPING_VALUE_STATE)\n\treturn yaml_emitter_emit_node(emitter, event, false, false, true, false)\n}\n\n// Expect a block value node.\nfunc yaml_emitter_emit_block_mapping_value(emitter *yaml_emitter_t, event *yaml_event_t, simple bool) bool {\n\tif simple {\n\t\tif !yaml_emitter_write_indicator(emitter, []byte{':'}, false, false, false) {\n\t\t\treturn false\n\t\t}\n\t} else {\n\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\treturn false\n\t\t}\n\t\tif !yaml_emitter_write_indicator(emitter, []byte{':'}, true, false, true) {\n\t\t\treturn false\n\t\t}\n\t}\n\tif len(emitter.key_line_comment) > 0 {\n\t\t// [Go] Line comments are generally associated with the value, but when there's\n\t\t//      no value on the same line as a mapping key they end up attached to the\n\t\t//      key itself.\n\t\tif event.typ == yaml_SCALAR_EVENT {\n\t\t\tif len(emitter.line_comment) == 0 {\n\t\t\t\t// A scalar is coming and it has no line comments by itself yet,\n\t\t\t\t// so just let it handle the line comment as usual. If it has a\n\t\t\t\t// line comment, we can't have both so the one from the key is lost.\n\t\t\t\temitter.line_comment = emitter.key_line_comment\n\t\t\t\temitter.key_line_comment = nil\n\t\t\t}\n\t\t} else if event.sequence_style() != yaml_FLOW_SEQUENCE_STYLE && (event.typ == yaml_MAPPING_START_EVENT || event.typ == yaml_SEQUENCE_START_EVENT) {\n\t\t\t// An indented block follows, so write the comment right now.\n\t\t\temitter.line_comment, emitter.key_line_comment = emitter.key_line_comment, emitter.line_comment\n\t\t\tif !yaml_emitter_process_line_comment(emitter) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\temitter.line_comment, emitter.key_line_comment = emitter.key_line_comment, emitter.line_comment\n\t\t}\n\t}\n\temitter.states = append(emitter.states, yaml_EMIT_BLOCK_MAPPING_KEY_STATE)\n\tif !yaml_emitter_emit_node(emitter, event, false, false, true, false) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_process_line_comment(emitter) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_process_foot_comment(emitter) {\n\t\treturn false\n\t}\n\treturn true\n}\n\nfunc yaml_emitter_silent_nil_event(emitter *yaml_emitter_t, event *yaml_event_t) bool {\n\treturn event.typ == yaml_SCALAR_EVENT && event.implicit && !emitter.canonical && len(emitter.scalar_data.value) == 0\n}\n\n// Expect a node.\nfunc yaml_emitter_emit_node(emitter *yaml_emitter_t, event *yaml_event_t,\n\troot bool, sequence bool, mapping bool, simple_key bool) bool {\n\n\temitter.root_context = root\n\temitter.sequence_context = sequence\n\temitter.mapping_context = mapping\n\temitter.simple_key_context = simple_key\n\n\tswitch event.typ {\n\tcase yaml_ALIAS_EVENT:\n\t\treturn yaml_emitter_emit_alias(emitter, event)\n\tcase yaml_SCALAR_EVENT:\n\t\treturn yaml_emitter_emit_scalar(emitter, event)\n\tcase yaml_SEQUENCE_START_EVENT:\n\t\treturn yaml_emitter_emit_sequence_start(emitter, event)\n\tcase yaml_MAPPING_START_EVENT:\n\t\treturn yaml_emitter_emit_mapping_start(emitter, event)\n\tdefault:\n\t\treturn yaml_emitter_set_emitter_error(emitter,\n\t\t\tfmt.Sprintf(\"expected SCALAR, SEQUENCE-START, MAPPING-START, or ALIAS, but got %v\", event.typ))\n\t}\n}\n\n// Expect ALIAS.\nfunc yaml_emitter_emit_alias(emitter *yaml_emitter_t, event *yaml_event_t) bool {\n\tif !yaml_emitter_process_anchor(emitter) {\n\t\treturn false\n\t}\n\temitter.state = emitter.states[len(emitter.states)-1]\n\temitter.states = emitter.states[:len(emitter.states)-1]\n\treturn true\n}\n\n// Expect SCALAR.\nfunc yaml_emitter_emit_scalar(emitter *yaml_emitter_t, event *yaml_event_t) bool {\n\tif !yaml_emitter_select_scalar_style(emitter, event) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_process_anchor(emitter) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_process_tag(emitter) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_increase_indent(emitter, true, false) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_process_scalar(emitter) {\n\t\treturn false\n\t}\n\temitter.indent = emitter.indents[len(emitter.indents)-1]\n\temitter.indents = emitter.indents[:len(emitter.indents)-1]\n\temitter.state = emitter.states[len(emitter.states)-1]\n\temitter.states = emitter.states[:len(emitter.states)-1]\n\treturn true\n}\n\n// Expect SEQUENCE-START.\nfunc yaml_emitter_emit_sequence_start(emitter *yaml_emitter_t, event *yaml_event_t) bool {\n\tif !yaml_emitter_process_anchor(emitter) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_process_tag(emitter) {\n\t\treturn false\n\t}\n\tif emitter.flow_level > 0 || emitter.canonical || event.sequence_style() == yaml_FLOW_SEQUENCE_STYLE ||\n\t\tyaml_emitter_check_empty_sequence(emitter) {\n\t\temitter.state = yaml_EMIT_FLOW_SEQUENCE_FIRST_ITEM_STATE\n\t} else {\n\t\temitter.state = yaml_EMIT_BLOCK_SEQUENCE_FIRST_ITEM_STATE\n\t}\n\treturn true\n}\n\n// Expect MAPPING-START.\nfunc yaml_emitter_emit_mapping_start(emitter *yaml_emitter_t, event *yaml_event_t) bool {\n\tif !yaml_emitter_process_anchor(emitter) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_process_tag(emitter) {\n\t\treturn false\n\t}\n\tif emitter.flow_level > 0 || emitter.canonical || event.mapping_style() == yaml_FLOW_MAPPING_STYLE ||\n\t\tyaml_emitter_check_empty_mapping(emitter) {\n\t\temitter.state = yaml_EMIT_FLOW_MAPPING_FIRST_KEY_STATE\n\t} else {\n\t\temitter.state = yaml_EMIT_BLOCK_MAPPING_FIRST_KEY_STATE\n\t}\n\treturn true\n}\n\n// Check if the document content is an empty scalar.\nfunc yaml_emitter_check_empty_document(emitter *yaml_emitter_t) bool {\n\treturn false // [Go] Huh?\n}\n\n// Check if the next events represent an empty sequence.\nfunc yaml_emitter_check_empty_sequence(emitter *yaml_emitter_t) bool {\n\tif len(emitter.events)-emitter.events_head < 2 {\n\t\treturn false\n\t}\n\treturn emitter.events[emitter.events_head].typ == yaml_SEQUENCE_START_EVENT &&\n\t\temitter.events[emitter.events_head+1].typ == yaml_SEQUENCE_END_EVENT\n}\n\n// Check if the next events represent an empty mapping.\nfunc yaml_emitter_check_empty_mapping(emitter *yaml_emitter_t) bool {\n\tif len(emitter.events)-emitter.events_head < 2 {\n\t\treturn false\n\t}\n\treturn emitter.events[emitter.events_head].typ == yaml_MAPPING_START_EVENT &&\n\t\temitter.events[emitter.events_head+1].typ == yaml_MAPPING_END_EVENT\n}\n\n// Check if the next node can be expressed as a simple key.\nfunc yaml_emitter_check_simple_key(emitter *yaml_emitter_t) bool {\n\tlength := 0\n\tswitch emitter.events[emitter.events_head].typ {\n\tcase yaml_ALIAS_EVENT:\n\t\tlength += len(emitter.anchor_data.anchor)\n\tcase yaml_SCALAR_EVENT:\n\t\tif emitter.scalar_data.multiline {\n\t\t\treturn false\n\t\t}\n\t\tlength += len(emitter.anchor_data.anchor) +\n\t\t\tlen(emitter.tag_data.handle) +\n\t\t\tlen(emitter.tag_data.suffix) +\n\t\t\tlen(emitter.scalar_data.value)\n\tcase yaml_SEQUENCE_START_EVENT:\n\t\tif !yaml_emitter_check_empty_sequence(emitter) {\n\t\t\treturn false\n\t\t}\n\t\tlength += len(emitter.anchor_data.anchor) +\n\t\t\tlen(emitter.tag_data.handle) +\n\t\t\tlen(emitter.tag_data.suffix)\n\tcase yaml_MAPPING_START_EVENT:\n\t\tif !yaml_emitter_check_empty_mapping(emitter) {\n\t\t\treturn false\n\t\t}\n\t\tlength += len(emitter.anchor_data.anchor) +\n\t\t\tlen(emitter.tag_data.handle) +\n\t\t\tlen(emitter.tag_data.suffix)\n\tdefault:\n\t\treturn false\n\t}\n\treturn length <= 128\n}\n\n// Determine an acceptable scalar style.\nfunc yaml_emitter_select_scalar_style(emitter *yaml_emitter_t, event *yaml_event_t) bool {\n\n\tno_tag := len(emitter.tag_data.handle) == 0 && len(emitter.tag_data.suffix) == 0\n\tif no_tag && !event.implicit && !event.quoted_implicit {\n\t\treturn yaml_emitter_set_emitter_error(emitter, \"neither tag nor implicit flags are specified\")\n\t}\n\n\tstyle := event.scalar_style()\n\tif style == yaml_ANY_SCALAR_STYLE {\n\t\tstyle = yaml_PLAIN_SCALAR_STYLE\n\t}\n\tif emitter.canonical {\n\t\tstyle = yaml_DOUBLE_QUOTED_SCALAR_STYLE\n\t}\n\tif emitter.simple_key_context && emitter.scalar_data.multiline {\n\t\tstyle = yaml_DOUBLE_QUOTED_SCALAR_STYLE\n\t}\n\n\tif style == yaml_PLAIN_SCALAR_STYLE {\n\t\tif emitter.flow_level > 0 && !emitter.scalar_data.flow_plain_allowed ||\n\t\t\temitter.flow_level == 0 && !emitter.scalar_data.block_plain_allowed {\n\t\t\tstyle = yaml_SINGLE_QUOTED_SCALAR_STYLE\n\t\t}\n\t\tif len(emitter.scalar_data.value) == 0 && (emitter.flow_level > 0 || emitter.simple_key_context) {\n\t\t\tstyle = yaml_SINGLE_QUOTED_SCALAR_STYLE\n\t\t}\n\t\tif no_tag && !event.implicit {\n\t\t\tstyle = yaml_SINGLE_QUOTED_SCALAR_STYLE\n\t\t}\n\t}\n\tif style == yaml_SINGLE_QUOTED_SCALAR_STYLE {\n\t\tif !emitter.scalar_data.single_quoted_allowed {\n\t\t\tstyle = yaml_DOUBLE_QUOTED_SCALAR_STYLE\n\t\t}\n\t}\n\tif style == yaml_LITERAL_SCALAR_STYLE || style == yaml_FOLDED_SCALAR_STYLE {\n\t\tif !emitter.scalar_data.block_allowed || emitter.flow_level > 0 || emitter.simple_key_context {\n\t\t\tstyle = yaml_DOUBLE_QUOTED_SCALAR_STYLE\n\t\t}\n\t}\n\n\tif no_tag && !event.quoted_implicit && style != yaml_PLAIN_SCALAR_STYLE {\n\t\temitter.tag_data.handle = []byte{'!'}\n\t}\n\temitter.scalar_data.style = style\n\treturn true\n}\n\n// Write an anchor.\nfunc yaml_emitter_process_anchor(emitter *yaml_emitter_t) bool {\n\tif emitter.anchor_data.anchor == nil {\n\t\treturn true\n\t}\n\tc := []byte{'&'}\n\tif emitter.anchor_data.alias {\n\t\tc[0] = '*'\n\t}\n\tif !yaml_emitter_write_indicator(emitter, c, true, false, false) {\n\t\treturn false\n\t}\n\treturn yaml_emitter_write_anchor(emitter, emitter.anchor_data.anchor)\n}\n\n// Write a tag.\nfunc yaml_emitter_process_tag(emitter *yaml_emitter_t) bool {\n\tif len(emitter.tag_data.handle) == 0 && len(emitter.tag_data.suffix) == 0 {\n\t\treturn true\n\t}\n\tif len(emitter.tag_data.handle) > 0 {\n\t\tif !yaml_emitter_write_tag_handle(emitter, emitter.tag_data.handle) {\n\t\t\treturn false\n\t\t}\n\t\tif len(emitter.tag_data.suffix) > 0 {\n\t\t\tif !yaml_emitter_write_tag_content(emitter, emitter.tag_data.suffix, false) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t} else {\n\t\t// [Go] Allocate these slices elsewhere.\n\t\tif !yaml_emitter_write_indicator(emitter, []byte(\"!<\"), true, false, false) {\n\t\t\treturn false\n\t\t}\n\t\tif !yaml_emitter_write_tag_content(emitter, emitter.tag_data.suffix, false) {\n\t\t\treturn false\n\t\t}\n\t\tif !yaml_emitter_write_indicator(emitter, []byte{'>'}, false, false, false) {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\n// Write a scalar.\nfunc yaml_emitter_process_scalar(emitter *yaml_emitter_t) bool {\n\tswitch emitter.scalar_data.style {\n\tcase yaml_PLAIN_SCALAR_STYLE:\n\t\treturn yaml_emitter_write_plain_scalar(emitter, emitter.scalar_data.value, !emitter.simple_key_context)\n\n\tcase yaml_SINGLE_QUOTED_SCALAR_STYLE:\n\t\treturn yaml_emitter_write_single_quoted_scalar(emitter, emitter.scalar_data.value, !emitter.simple_key_context)\n\n\tcase yaml_DOUBLE_QUOTED_SCALAR_STYLE:\n\t\treturn yaml_emitter_write_double_quoted_scalar(emitter, emitter.scalar_data.value, !emitter.simple_key_context)\n\n\tcase yaml_LITERAL_SCALAR_STYLE:\n\t\treturn yaml_emitter_write_literal_scalar(emitter, emitter.scalar_data.value)\n\n\tcase yaml_FOLDED_SCALAR_STYLE:\n\t\treturn yaml_emitter_write_folded_scalar(emitter, emitter.scalar_data.value)\n\t}\n\tpanic(\"unknown scalar style\")\n}\n\n// Write a head comment.\nfunc yaml_emitter_process_head_comment(emitter *yaml_emitter_t) bool {\n\tif len(emitter.tail_comment) > 0 {\n\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\treturn false\n\t\t}\n\t\tif !yaml_emitter_write_comment(emitter, emitter.tail_comment) {\n\t\t\treturn false\n\t\t}\n\t\temitter.tail_comment = emitter.tail_comment[:0]\n\t\temitter.foot_indent = emitter.indent\n\t\tif emitter.foot_indent < 0 {\n\t\t\temitter.foot_indent = 0\n\t\t}\n\t}\n\n\tif len(emitter.head_comment) == 0 {\n\t\treturn true\n\t}\n\tif !yaml_emitter_write_indent(emitter) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_write_comment(emitter, emitter.head_comment) {\n\t\treturn false\n\t}\n\temitter.head_comment = emitter.head_comment[:0]\n\treturn true\n}\n\n// Write an line comment.\nfunc yaml_emitter_process_line_comment(emitter *yaml_emitter_t) bool {\n\tif len(emitter.line_comment) == 0 {\n\t\treturn true\n\t}\n\tif !emitter.whitespace {\n\t\tif !put(emitter, ' ') {\n\t\t\treturn false\n\t\t}\n\t}\n\tif !yaml_emitter_write_comment(emitter, emitter.line_comment) {\n\t\treturn false\n\t}\n\temitter.line_comment = emitter.line_comment[:0]\n\treturn true\n}\n\n// Write a foot comment.\nfunc yaml_emitter_process_foot_comment(emitter *yaml_emitter_t) bool {\n\tif len(emitter.foot_comment) == 0 {\n\t\treturn true\n\t}\n\tif !yaml_emitter_write_indent(emitter) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_write_comment(emitter, emitter.foot_comment) {\n\t\treturn false\n\t}\n\temitter.foot_comment = emitter.foot_comment[:0]\n\temitter.foot_indent = emitter.indent\n\tif emitter.foot_indent < 0 {\n\t\temitter.foot_indent = 0\n\t}\n\treturn true\n}\n\n// Check if a %YAML directive is valid.\nfunc yaml_emitter_analyze_version_directive(emitter *yaml_emitter_t, version_directive *yaml_version_directive_t) bool {\n\tif version_directive.major != 1 || version_directive.minor != 1 {\n\t\treturn yaml_emitter_set_emitter_error(emitter, \"incompatible %YAML directive\")\n\t}\n\treturn true\n}\n\n// Check if a %TAG directive is valid.\nfunc yaml_emitter_analyze_tag_directive(emitter *yaml_emitter_t, tag_directive *yaml_tag_directive_t) bool {\n\thandle := tag_directive.handle\n\tprefix := tag_directive.prefix\n\tif len(handle) == 0 {\n\t\treturn yaml_emitter_set_emitter_error(emitter, \"tag handle must not be empty\")\n\t}\n\tif handle[0] != '!' {\n\t\treturn yaml_emitter_set_emitter_error(emitter, \"tag handle must start with '!'\")\n\t}\n\tif handle[len(handle)-1] != '!' {\n\t\treturn yaml_emitter_set_emitter_error(emitter, \"tag handle must end with '!'\")\n\t}\n\tfor i := 1; i < len(handle)-1; i += width(handle[i]) {\n\t\tif !is_alpha(handle, i) {\n\t\t\treturn yaml_emitter_set_emitter_error(emitter, \"tag handle must contain alphanumerical characters only\")\n\t\t}\n\t}\n\tif len(prefix) == 0 {\n\t\treturn yaml_emitter_set_emitter_error(emitter, \"tag prefix must not be empty\")\n\t}\n\treturn true\n}\n\n// Check if an anchor is valid.\nfunc yaml_emitter_analyze_anchor(emitter *yaml_emitter_t, anchor []byte, alias bool) bool {\n\tif len(anchor) == 0 {\n\t\tproblem := \"anchor value must not be empty\"\n\t\tif alias {\n\t\t\tproblem = \"alias value must not be empty\"\n\t\t}\n\t\treturn yaml_emitter_set_emitter_error(emitter, problem)\n\t}\n\tfor i := 0; i < len(anchor); i += width(anchor[i]) {\n\t\tif !is_alpha(anchor, i) {\n\t\t\tproblem := \"anchor value must contain alphanumerical characters only\"\n\t\t\tif alias {\n\t\t\t\tproblem = \"alias value must contain alphanumerical characters only\"\n\t\t\t}\n\t\t\treturn yaml_emitter_set_emitter_error(emitter, problem)\n\t\t}\n\t}\n\temitter.anchor_data.anchor = anchor\n\temitter.anchor_data.alias = alias\n\treturn true\n}\n\n// Check if a tag is valid.\nfunc yaml_emitter_analyze_tag(emitter *yaml_emitter_t, tag []byte) bool {\n\tif len(tag) == 0 {\n\t\treturn yaml_emitter_set_emitter_error(emitter, \"tag value must not be empty\")\n\t}\n\tfor i := 0; i < len(emitter.tag_directives); i++ {\n\t\ttag_directive := &emitter.tag_directives[i]\n\t\tif bytes.HasPrefix(tag, tag_directive.prefix) {\n\t\t\temitter.tag_data.handle = tag_directive.handle\n\t\t\temitter.tag_data.suffix = tag[len(tag_directive.prefix):]\n\t\t\treturn true\n\t\t}\n\t}\n\temitter.tag_data.suffix = tag\n\treturn true\n}\n\n// Check if a scalar is valid.\nfunc yaml_emitter_analyze_scalar(emitter *yaml_emitter_t, value []byte) bool {\n\tvar (\n\t\tblock_indicators   = false\n\t\tflow_indicators    = false\n\t\tline_breaks        = false\n\t\tspecial_characters = false\n\t\ttab_characters     = false\n\n\t\tleading_space  = false\n\t\tleading_break  = false\n\t\ttrailing_space = false\n\t\ttrailing_break = false\n\t\tbreak_space    = false\n\t\tspace_break    = false\n\n\t\tpreceded_by_whitespace = false\n\t\tfollowed_by_whitespace = false\n\t\tprevious_space         = false\n\t\tprevious_break         = false\n\t)\n\n\temitter.scalar_data.value = value\n\n\tif len(value) == 0 {\n\t\temitter.scalar_data.multiline = false\n\t\temitter.scalar_data.flow_plain_allowed = false\n\t\temitter.scalar_data.block_plain_allowed = true\n\t\temitter.scalar_data.single_quoted_allowed = true\n\t\temitter.scalar_data.block_allowed = false\n\t\treturn true\n\t}\n\n\tif len(value) >= 3 && ((value[0] == '-' && value[1] == '-' && value[2] == '-') || (value[0] == '.' && value[1] == '.' && value[2] == '.')) {\n\t\tblock_indicators = true\n\t\tflow_indicators = true\n\t}\n\n\tpreceded_by_whitespace = true\n\tfor i, w := 0, 0; i < len(value); i += w {\n\t\tw = width(value[i])\n\t\tfollowed_by_whitespace = i+w >= len(value) || is_blank(value, i+w)\n\n\t\tif i == 0 {\n\t\t\tswitch value[i] {\n\t\t\tcase '#', ',', '[', ']', '{', '}', '&', '*', '!', '|', '>', '\\'', '\"', '%', '@', '`':\n\t\t\t\tflow_indicators = true\n\t\t\t\tblock_indicators = true\n\t\t\tcase '?', ':':\n\t\t\t\tflow_indicators = true\n\t\t\t\tif followed_by_whitespace {\n\t\t\t\t\tblock_indicators = true\n\t\t\t\t}\n\t\t\tcase '-':\n\t\t\t\tif followed_by_whitespace {\n\t\t\t\t\tflow_indicators = true\n\t\t\t\t\tblock_indicators = true\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tswitch value[i] {\n\t\t\tcase ',', '?', '[', ']', '{', '}':\n\t\t\t\tflow_indicators = true\n\t\t\tcase ':':\n\t\t\t\tflow_indicators = true\n\t\t\t\tif followed_by_whitespace {\n\t\t\t\t\tblock_indicators = true\n\t\t\t\t}\n\t\t\tcase '#':\n\t\t\t\tif preceded_by_whitespace {\n\t\t\t\t\tflow_indicators = true\n\t\t\t\t\tblock_indicators = true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif value[i] == '\\t' {\n\t\t\ttab_characters = true\n\t\t} else if !is_printable(value, i) || !is_ascii(value, i) && !emitter.unicode {\n\t\t\tspecial_characters = true\n\t\t}\n\t\tif is_space(value, i) {\n\t\t\tif i == 0 {\n\t\t\t\tleading_space = true\n\t\t\t}\n\t\t\tif i+width(value[i]) == len(value) {\n\t\t\t\ttrailing_space = true\n\t\t\t}\n\t\t\tif previous_break {\n\t\t\t\tbreak_space = true\n\t\t\t}\n\t\t\tprevious_space = true\n\t\t\tprevious_break = false\n\t\t} else if is_break(value, i) {\n\t\t\tline_breaks = true\n\t\t\tif i == 0 {\n\t\t\t\tleading_break = true\n\t\t\t}\n\t\t\tif i+width(value[i]) == len(value) {\n\t\t\t\ttrailing_break = true\n\t\t\t}\n\t\t\tif previous_space {\n\t\t\t\tspace_break = true\n\t\t\t}\n\t\t\tprevious_space = false\n\t\t\tprevious_break = true\n\t\t} else {\n\t\t\tprevious_space = false\n\t\t\tprevious_break = false\n\t\t}\n\n\t\t// [Go]: Why 'z'? Couldn't be the end of the string as that's the loop condition.\n\t\tpreceded_by_whitespace = is_blankz(value, i)\n\t}\n\n\temitter.scalar_data.multiline = line_breaks\n\temitter.scalar_data.flow_plain_allowed = true\n\temitter.scalar_data.block_plain_allowed = true\n\temitter.scalar_data.single_quoted_allowed = true\n\temitter.scalar_data.block_allowed = true\n\n\tif leading_space || leading_break || trailing_space || trailing_break {\n\t\temitter.scalar_data.flow_plain_allowed = false\n\t\temitter.scalar_data.block_plain_allowed = false\n\t}\n\tif trailing_space {\n\t\temitter.scalar_data.block_allowed = false\n\t}\n\tif break_space {\n\t\temitter.scalar_data.flow_plain_allowed = false\n\t\temitter.scalar_data.block_plain_allowed = false\n\t\temitter.scalar_data.single_quoted_allowed = false\n\t}\n\tif space_break || tab_characters || special_characters {\n\t\temitter.scalar_data.flow_plain_allowed = false\n\t\temitter.scalar_data.block_plain_allowed = false\n\t\temitter.scalar_data.single_quoted_allowed = false\n\t}\n\tif space_break || special_characters {\n\t\temitter.scalar_data.block_allowed = false\n\t}\n\tif line_breaks {\n\t\temitter.scalar_data.flow_plain_allowed = false\n\t\temitter.scalar_data.block_plain_allowed = false\n\t}\n\tif flow_indicators {\n\t\temitter.scalar_data.flow_plain_allowed = false\n\t}\n\tif block_indicators {\n\t\temitter.scalar_data.block_plain_allowed = false\n\t}\n\treturn true\n}\n\n// Check if the event data is valid.\nfunc yaml_emitter_analyze_event(emitter *yaml_emitter_t, event *yaml_event_t) bool {\n\n\temitter.anchor_data.anchor = nil\n\temitter.tag_data.handle = nil\n\temitter.tag_data.suffix = nil\n\temitter.scalar_data.value = nil\n\n\tif len(event.head_comment) > 0 {\n\t\temitter.head_comment = event.head_comment\n\t}\n\tif len(event.line_comment) > 0 {\n\t\temitter.line_comment = event.line_comment\n\t}\n\tif len(event.foot_comment) > 0 {\n\t\temitter.foot_comment = event.foot_comment\n\t}\n\tif len(event.tail_comment) > 0 {\n\t\temitter.tail_comment = event.tail_comment\n\t}\n\n\tswitch event.typ {\n\tcase yaml_ALIAS_EVENT:\n\t\tif !yaml_emitter_analyze_anchor(emitter, event.anchor, true) {\n\t\t\treturn false\n\t\t}\n\n\tcase yaml_SCALAR_EVENT:\n\t\tif len(event.anchor) > 0 {\n\t\t\tif !yaml_emitter_analyze_anchor(emitter, event.anchor, false) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\tif len(event.tag) > 0 && (emitter.canonical || (!event.implicit && !event.quoted_implicit)) {\n\t\t\tif !yaml_emitter_analyze_tag(emitter, event.tag) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\tif !yaml_emitter_analyze_scalar(emitter, event.value) {\n\t\t\treturn false\n\t\t}\n\n\tcase yaml_SEQUENCE_START_EVENT:\n\t\tif len(event.anchor) > 0 {\n\t\t\tif !yaml_emitter_analyze_anchor(emitter, event.anchor, false) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\tif len(event.tag) > 0 && (emitter.canonical || !event.implicit) {\n\t\t\tif !yaml_emitter_analyze_tag(emitter, event.tag) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\n\tcase yaml_MAPPING_START_EVENT:\n\t\tif len(event.anchor) > 0 {\n\t\t\tif !yaml_emitter_analyze_anchor(emitter, event.anchor, false) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\tif len(event.tag) > 0 && (emitter.canonical || !event.implicit) {\n\t\t\tif !yaml_emitter_analyze_tag(emitter, event.tag) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t}\n\treturn true\n}\n\n// Write the BOM character.\nfunc yaml_emitter_write_bom(emitter *yaml_emitter_t) bool {\n\tif !flush(emitter) {\n\t\treturn false\n\t}\n\tpos := emitter.buffer_pos\n\temitter.buffer[pos+0] = '\\xEF'\n\temitter.buffer[pos+1] = '\\xBB'\n\temitter.buffer[pos+2] = '\\xBF'\n\temitter.buffer_pos += 3\n\treturn true\n}\n\nfunc yaml_emitter_write_indent(emitter *yaml_emitter_t) bool {\n\tindent := emitter.indent\n\tif indent < 0 {\n\t\tindent = 0\n\t}\n\tif !emitter.indention || emitter.column > indent || (emitter.column == indent && !emitter.whitespace) {\n\t\tif !put_break(emitter) {\n\t\t\treturn false\n\t\t}\n\t}\n\tif emitter.foot_indent == indent {\n\t\tif !put_break(emitter) {\n\t\t\treturn false\n\t\t}\n\t}\n\tfor emitter.column < indent {\n\t\tif !put(emitter, ' ') {\n\t\t\treturn false\n\t\t}\n\t}\n\temitter.whitespace = true\n\t//emitter.indention = true\n\temitter.space_above = false\n\temitter.foot_indent = -1\n\treturn true\n}\n\nfunc yaml_emitter_write_indicator(emitter *yaml_emitter_t, indicator []byte, need_whitespace, is_whitespace, is_indention bool) bool {\n\tif need_whitespace && !emitter.whitespace {\n\t\tif !put(emitter, ' ') {\n\t\t\treturn false\n\t\t}\n\t}\n\tif !write_all(emitter, indicator) {\n\t\treturn false\n\t}\n\temitter.whitespace = is_whitespace\n\temitter.indention = (emitter.indention && is_indention)\n\temitter.open_ended = false\n\treturn true\n}\n\nfunc yaml_emitter_write_anchor(emitter *yaml_emitter_t, value []byte) bool {\n\tif !write_all(emitter, value) {\n\t\treturn false\n\t}\n\temitter.whitespace = false\n\temitter.indention = false\n\treturn true\n}\n\nfunc yaml_emitter_write_tag_handle(emitter *yaml_emitter_t, value []byte) bool {\n\tif !emitter.whitespace {\n\t\tif !put(emitter, ' ') {\n\t\t\treturn false\n\t\t}\n\t}\n\tif !write_all(emitter, value) {\n\t\treturn false\n\t}\n\temitter.whitespace = false\n\temitter.indention = false\n\treturn true\n}\n\nfunc yaml_emitter_write_tag_content(emitter *yaml_emitter_t, value []byte, need_whitespace bool) bool {\n\tif need_whitespace && !emitter.whitespace {\n\t\tif !put(emitter, ' ') {\n\t\t\treturn false\n\t\t}\n\t}\n\tfor i := 0; i < len(value); {\n\t\tvar must_write bool\n\t\tswitch value[i] {\n\t\tcase ';', '/', '?', ':', '@', '&', '=', '+', '$', ',', '_', '.', '~', '*', '\\'', '(', ')', '[', ']':\n\t\t\tmust_write = true\n\t\tdefault:\n\t\t\tmust_write = is_alpha(value, i)\n\t\t}\n\t\tif must_write {\n\t\t\tif !write(emitter, value, &i) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t} else {\n\t\t\tw := width(value[i])\n\t\t\tfor k := 0; k < w; k++ {\n\t\t\t\toctet := value[i]\n\t\t\t\ti++\n\t\t\t\tif !put(emitter, '%') {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\n\t\t\t\tc := octet >> 4\n\t\t\t\tif c < 10 {\n\t\t\t\t\tc += '0'\n\t\t\t\t} else {\n\t\t\t\t\tc += 'A' - 10\n\t\t\t\t}\n\t\t\t\tif !put(emitter, c) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\n\t\t\t\tc = octet & 0x0f\n\t\t\t\tif c < 10 {\n\t\t\t\t\tc += '0'\n\t\t\t\t} else {\n\t\t\t\t\tc += 'A' - 10\n\t\t\t\t}\n\t\t\t\tif !put(emitter, c) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\temitter.whitespace = false\n\temitter.indention = false\n\treturn true\n}\n\nfunc yaml_emitter_write_plain_scalar(emitter *yaml_emitter_t, value []byte, allow_breaks bool) bool {\n\tif len(value) > 0 && !emitter.whitespace {\n\t\tif !put(emitter, ' ') {\n\t\t\treturn false\n\t\t}\n\t}\n\n\tspaces := false\n\tbreaks := false\n\tfor i := 0; i < len(value); {\n\t\tif is_space(value, i) {\n\t\t\tif allow_breaks && !spaces && emitter.column > emitter.best_width && !is_space(value, i+1) {\n\t\t\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\ti += width(value[i])\n\t\t\t} else {\n\t\t\t\tif !write(emitter, value, &i) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t}\n\t\t\tspaces = true\n\t\t} else if is_break(value, i) {\n\t\t\tif !breaks && value[i] == '\\n' {\n\t\t\t\tif !put_break(emitter) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !write_break(emitter, value, &i) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\t//emitter.indention = true\n\t\t\tbreaks = true\n\t\t} else {\n\t\t\tif breaks {\n\t\t\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !write(emitter, value, &i) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\temitter.indention = false\n\t\t\tspaces = false\n\t\t\tbreaks = false\n\t\t}\n\t}\n\n\tif len(value) > 0 {\n\t\temitter.whitespace = false\n\t}\n\temitter.indention = false\n\tif emitter.root_context {\n\t\temitter.open_ended = true\n\t}\n\n\treturn true\n}\n\nfunc yaml_emitter_write_single_quoted_scalar(emitter *yaml_emitter_t, value []byte, allow_breaks bool) bool {\n\n\tif !yaml_emitter_write_indicator(emitter, []byte{'\\''}, true, false, false) {\n\t\treturn false\n\t}\n\n\tspaces := false\n\tbreaks := false\n\tfor i := 0; i < len(value); {\n\t\tif is_space(value, i) {\n\t\t\tif allow_breaks && !spaces && emitter.column > emitter.best_width && i > 0 && i < len(value)-1 && !is_space(value, i+1) {\n\t\t\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\ti += width(value[i])\n\t\t\t} else {\n\t\t\t\tif !write(emitter, value, &i) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t}\n\t\t\tspaces = true\n\t\t} else if is_break(value, i) {\n\t\t\tif !breaks && value[i] == '\\n' {\n\t\t\t\tif !put_break(emitter) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !write_break(emitter, value, &i) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\t//emitter.indention = true\n\t\t\tbreaks = true\n\t\t} else {\n\t\t\tif breaks {\n\t\t\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t}\n\t\t\tif value[i] == '\\'' {\n\t\t\t\tif !put(emitter, '\\'') {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !write(emitter, value, &i) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\temitter.indention = false\n\t\t\tspaces = false\n\t\t\tbreaks = false\n\t\t}\n\t}\n\tif !yaml_emitter_write_indicator(emitter, []byte{'\\''}, false, false, false) {\n\t\treturn false\n\t}\n\temitter.whitespace = false\n\temitter.indention = false\n\treturn true\n}\n\nfunc yaml_emitter_write_double_quoted_scalar(emitter *yaml_emitter_t, value []byte, allow_breaks bool) bool {\n\tspaces := false\n\tif !yaml_emitter_write_indicator(emitter, []byte{'\"'}, true, false, false) {\n\t\treturn false\n\t}\n\n\tfor i := 0; i < len(value); {\n\t\tif !is_printable(value, i) || (!emitter.unicode && !is_ascii(value, i)) ||\n\t\t\tis_bom(value, i) || is_break(value, i) ||\n\t\t\tvalue[i] == '\"' || value[i] == '\\\\' {\n\n\t\t\toctet := value[i]\n\n\t\t\tvar w int\n\t\t\tvar v rune\n\t\t\tswitch {\n\t\t\tcase octet&0x80 == 0x00:\n\t\t\t\tw, v = 1, rune(octet&0x7F)\n\t\t\tcase octet&0xE0 == 0xC0:\n\t\t\t\tw, v = 2, rune(octet&0x1F)\n\t\t\tcase octet&0xF0 == 0xE0:\n\t\t\t\tw, v = 3, rune(octet&0x0F)\n\t\t\tcase octet&0xF8 == 0xF0:\n\t\t\t\tw, v = 4, rune(octet&0x07)\n\t\t\t}\n\t\t\tfor k := 1; k < w; k++ {\n\t\t\t\toctet = value[i+k]\n\t\t\t\tv = (v << 6) + (rune(octet) & 0x3F)\n\t\t\t}\n\t\t\ti += w\n\n\t\t\tif !put(emitter, '\\\\') {\n\t\t\t\treturn false\n\t\t\t}\n\n\t\t\tvar ok bool\n\t\t\tswitch v {\n\t\t\tcase 0x00:\n\t\t\t\tok = put(emitter, '0')\n\t\t\tcase 0x07:\n\t\t\t\tok = put(emitter, 'a')\n\t\t\tcase 0x08:\n\t\t\t\tok = put(emitter, 'b')\n\t\t\tcase 0x09:\n\t\t\t\tok = put(emitter, 't')\n\t\t\tcase 0x0A:\n\t\t\t\tok = put(emitter, 'n')\n\t\t\tcase 0x0b:\n\t\t\t\tok = put(emitter, 'v')\n\t\t\tcase 0x0c:\n\t\t\t\tok = put(emitter, 'f')\n\t\t\tcase 0x0d:\n\t\t\t\tok = put(emitter, 'r')\n\t\t\tcase 0x1b:\n\t\t\t\tok = put(emitter, 'e')\n\t\t\tcase 0x22:\n\t\t\t\tok = put(emitter, '\"')\n\t\t\tcase 0x5c:\n\t\t\t\tok = put(emitter, '\\\\')\n\t\t\tcase 0x85:\n\t\t\t\tok = put(emitter, 'N')\n\t\t\tcase 0xA0:\n\t\t\t\tok = put(emitter, '_')\n\t\t\tcase 0x2028:\n\t\t\t\tok = put(emitter, 'L')\n\t\t\tcase 0x2029:\n\t\t\t\tok = put(emitter, 'P')\n\t\t\tdefault:\n\t\t\t\tif v <= 0xFF {\n\t\t\t\t\tok = put(emitter, 'x')\n\t\t\t\t\tw = 2\n\t\t\t\t} else if v <= 0xFFFF {\n\t\t\t\t\tok = put(emitter, 'u')\n\t\t\t\t\tw = 4\n\t\t\t\t} else {\n\t\t\t\t\tok = put(emitter, 'U')\n\t\t\t\t\tw = 8\n\t\t\t\t}\n\t\t\t\tfor k := (w - 1) * 4; ok && k >= 0; k -= 4 {\n\t\t\t\t\tdigit := byte((v >> uint(k)) & 0x0F)\n\t\t\t\t\tif digit < 10 {\n\t\t\t\t\t\tok = put(emitter, digit+'0')\n\t\t\t\t\t} else {\n\t\t\t\t\t\tok = put(emitter, digit+'A'-10)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !ok {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tspaces = false\n\t\t} else if is_space(value, i) {\n\t\t\tif allow_breaks && !spaces && emitter.column > emitter.best_width && i > 0 && i < len(value)-1 {\n\t\t\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\tif is_space(value, i+1) {\n\t\t\t\t\tif !put(emitter, '\\\\') {\n\t\t\t\t\t\treturn false\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ti += width(value[i])\n\t\t\t} else if !write(emitter, value, &i) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tspaces = true\n\t\t} else {\n\t\t\tif !write(emitter, value, &i) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tspaces = false\n\t\t}\n\t}\n\tif !yaml_emitter_write_indicator(emitter, []byte{'\"'}, false, false, false) {\n\t\treturn false\n\t}\n\temitter.whitespace = false\n\temitter.indention = false\n\treturn true\n}\n\nfunc yaml_emitter_write_block_scalar_hints(emitter *yaml_emitter_t, value []byte) bool {\n\tif is_space(value, 0) || is_break(value, 0) {\n\t\tindent_hint := []byte{'0' + byte(emitter.best_indent)}\n\t\tif !yaml_emitter_write_indicator(emitter, indent_hint, false, false, false) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\temitter.open_ended = false\n\n\tvar chomp_hint [1]byte\n\tif len(value) == 0 {\n\t\tchomp_hint[0] = '-'\n\t} else {\n\t\ti := len(value) - 1\n\t\tfor value[i]&0xC0 == 0x80 {\n\t\t\ti--\n\t\t}\n\t\tif !is_break(value, i) {\n\t\t\tchomp_hint[0] = '-'\n\t\t} else if i == 0 {\n\t\t\tchomp_hint[0] = '+'\n\t\t\temitter.open_ended = true\n\t\t} else {\n\t\t\ti--\n\t\t\tfor value[i]&0xC0 == 0x80 {\n\t\t\t\ti--\n\t\t\t}\n\t\t\tif is_break(value, i) {\n\t\t\t\tchomp_hint[0] = '+'\n\t\t\t\temitter.open_ended = true\n\t\t\t}\n\t\t}\n\t}\n\tif chomp_hint[0] != 0 {\n\t\tif !yaml_emitter_write_indicator(emitter, chomp_hint[:], false, false, false) {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\nfunc yaml_emitter_write_literal_scalar(emitter *yaml_emitter_t, value []byte) bool {\n\tif !yaml_emitter_write_indicator(emitter, []byte{'|'}, true, false, false) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_write_block_scalar_hints(emitter, value) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_process_line_comment(emitter) {\n\t\treturn false\n\t}\n\t//emitter.indention = true\n\temitter.whitespace = true\n\tbreaks := true\n\tfor i := 0; i < len(value); {\n\t\tif is_break(value, i) {\n\t\t\tif !write_break(emitter, value, &i) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\t//emitter.indention = true\n\t\t\tbreaks = true\n\t\t} else {\n\t\t\tif breaks {\n\t\t\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !write(emitter, value, &i) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\temitter.indention = false\n\t\t\tbreaks = false\n\t\t}\n\t}\n\n\treturn true\n}\n\nfunc yaml_emitter_write_folded_scalar(emitter *yaml_emitter_t, value []byte) bool {\n\tif !yaml_emitter_write_indicator(emitter, []byte{'>'}, true, false, false) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_write_block_scalar_hints(emitter, value) {\n\t\treturn false\n\t}\n\tif !yaml_emitter_process_line_comment(emitter) {\n\t\treturn false\n\t}\n\n\t//emitter.indention = true\n\temitter.whitespace = true\n\n\tbreaks := true\n\tleading_spaces := true\n\tfor i := 0; i < len(value); {\n\t\tif is_break(value, i) {\n\t\t\tif !breaks && !leading_spaces && value[i] == '\\n' {\n\t\t\t\tk := 0\n\t\t\t\tfor is_break(value, k) {\n\t\t\t\t\tk += width(value[k])\n\t\t\t\t}\n\t\t\t\tif !is_blankz(value, k) {\n\t\t\t\t\tif !put_break(emitter) {\n\t\t\t\t\t\treturn false\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !write_break(emitter, value, &i) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\t//emitter.indention = true\n\t\t\tbreaks = true\n\t\t} else {\n\t\t\tif breaks {\n\t\t\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\tleading_spaces = is_blank(value, i)\n\t\t\t}\n\t\t\tif !breaks && is_space(value, i) && !is_space(value, i+1) && emitter.column > emitter.best_width {\n\t\t\t\tif !yaml_emitter_write_indent(emitter) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\ti += width(value[i])\n\t\t\t} else {\n\t\t\t\tif !write(emitter, value, &i) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t}\n\t\t\temitter.indention = false\n\t\t\tbreaks = false\n\t\t}\n\t}\n\treturn true\n}\n\nfunc yaml_emitter_write_comment(emitter *yaml_emitter_t, comment []byte) bool {\n\tbreaks := false\n\tpound := false\n\tfor i := 0; i < len(comment); {\n\t\tif is_break(comment, i) {\n\t\t\tif !write_break(emitter, comment, &i) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\t//emitter.indention = true\n\t\t\tbreaks = true\n\t\t\tpound = false\n\t\t} else {\n\t\t\tif breaks && !yaml_emitter_write_indent(emitter) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tif !pound {\n\t\t\t\tif comment[i] != '#' && (!put(emitter, '#') || !put(emitter, ' ')) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\tpound = true\n\t\t\t}\n\t\t\tif !write(emitter, comment, &i) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\temitter.indention = false\n\t\t\tbreaks = false\n\t\t}\n\t}\n\tif !breaks && !put_break(emitter) {\n\t\treturn false\n\t}\n\n\temitter.whitespace = true\n\t//emitter.indention = true\n\treturn true\n}\n"
        },
        {
          "name": "encode.go",
          "type": "blob",
          "size": 14.4423828125,
          "content": "//\n// Copyright (c) 2011-2019 Canonical Ltd\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage yaml\n\nimport (\n\t\"encoding\"\n\t\"fmt\"\n\t\"io\"\n\t\"reflect\"\n\t\"regexp\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\t\"unicode/utf8\"\n)\n\ntype encoder struct {\n\temitter  yaml_emitter_t\n\tevent    yaml_event_t\n\tout      []byte\n\tflow     bool\n\tindent   int\n\tdoneInit bool\n}\n\nfunc newEncoder() *encoder {\n\te := &encoder{}\n\tyaml_emitter_initialize(&e.emitter)\n\tyaml_emitter_set_output_string(&e.emitter, &e.out)\n\tyaml_emitter_set_unicode(&e.emitter, true)\n\treturn e\n}\n\nfunc newEncoderWithWriter(w io.Writer) *encoder {\n\te := &encoder{}\n\tyaml_emitter_initialize(&e.emitter)\n\tyaml_emitter_set_output_writer(&e.emitter, w)\n\tyaml_emitter_set_unicode(&e.emitter, true)\n\treturn e\n}\n\nfunc (e *encoder) init() {\n\tif e.doneInit {\n\t\treturn\n\t}\n\tif e.indent == 0 {\n\t\te.indent = 4\n\t}\n\te.emitter.best_indent = e.indent\n\tyaml_stream_start_event_initialize(&e.event, yaml_UTF8_ENCODING)\n\te.emit()\n\te.doneInit = true\n}\n\nfunc (e *encoder) finish() {\n\te.emitter.open_ended = false\n\tyaml_stream_end_event_initialize(&e.event)\n\te.emit()\n}\n\nfunc (e *encoder) destroy() {\n\tyaml_emitter_delete(&e.emitter)\n}\n\nfunc (e *encoder) emit() {\n\t// This will internally delete the e.event value.\n\te.must(yaml_emitter_emit(&e.emitter, &e.event))\n}\n\nfunc (e *encoder) must(ok bool) {\n\tif !ok {\n\t\tmsg := e.emitter.problem\n\t\tif msg == \"\" {\n\t\t\tmsg = \"unknown problem generating YAML content\"\n\t\t}\n\t\tfailf(\"%s\", msg)\n\t}\n}\n\nfunc (e *encoder) marshalDoc(tag string, in reflect.Value) {\n\te.init()\n\tvar node *Node\n\tif in.IsValid() {\n\t\tnode, _ = in.Interface().(*Node)\n\t}\n\tif node != nil && node.Kind == DocumentNode {\n\t\te.nodev(in)\n\t} else {\n\t\tyaml_document_start_event_initialize(&e.event, nil, nil, true)\n\t\te.emit()\n\t\te.marshal(tag, in)\n\t\tyaml_document_end_event_initialize(&e.event, true)\n\t\te.emit()\n\t}\n}\n\nfunc (e *encoder) marshal(tag string, in reflect.Value) {\n\ttag = shortTag(tag)\n\tif !in.IsValid() || in.Kind() == reflect.Ptr && in.IsNil() {\n\t\te.nilv()\n\t\treturn\n\t}\n\tiface := in.Interface()\n\tswitch value := iface.(type) {\n\tcase *Node:\n\t\te.nodev(in)\n\t\treturn\n\tcase Node:\n\t\tif !in.CanAddr() {\n\t\t\tvar n = reflect.New(in.Type()).Elem()\n\t\t\tn.Set(in)\n\t\t\tin = n\n\t\t}\n\t\te.nodev(in.Addr())\n\t\treturn\n\tcase time.Time:\n\t\te.timev(tag, in)\n\t\treturn\n\tcase *time.Time:\n\t\te.timev(tag, in.Elem())\n\t\treturn\n\tcase time.Duration:\n\t\te.stringv(tag, reflect.ValueOf(value.String()))\n\t\treturn\n\tcase Marshaler:\n\t\tv, err := value.MarshalYAML()\n\t\tif err != nil {\n\t\t\tfail(err)\n\t\t}\n\t\tif v == nil {\n\t\t\te.nilv()\n\t\t\treturn\n\t\t}\n\t\te.marshal(tag, reflect.ValueOf(v))\n\t\treturn\n\tcase encoding.TextMarshaler:\n\t\ttext, err := value.MarshalText()\n\t\tif err != nil {\n\t\t\tfail(err)\n\t\t}\n\t\tin = reflect.ValueOf(string(text))\n\tcase nil:\n\t\te.nilv()\n\t\treturn\n\t}\n\tswitch in.Kind() {\n\tcase reflect.Interface:\n\t\te.marshal(tag, in.Elem())\n\tcase reflect.Map:\n\t\te.mapv(tag, in)\n\tcase reflect.Ptr:\n\t\te.marshal(tag, in.Elem())\n\tcase reflect.Struct:\n\t\te.structv(tag, in)\n\tcase reflect.Slice, reflect.Array:\n\t\te.slicev(tag, in)\n\tcase reflect.String:\n\t\te.stringv(tag, in)\n\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\n\t\te.intv(tag, in)\n\tcase reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64, reflect.Uintptr:\n\t\te.uintv(tag, in)\n\tcase reflect.Float32, reflect.Float64:\n\t\te.floatv(tag, in)\n\tcase reflect.Bool:\n\t\te.boolv(tag, in)\n\tdefault:\n\t\tpanic(\"cannot marshal type: \" + in.Type().String())\n\t}\n}\n\nfunc (e *encoder) mapv(tag string, in reflect.Value) {\n\te.mappingv(tag, func() {\n\t\tkeys := keyList(in.MapKeys())\n\t\tsort.Sort(keys)\n\t\tfor _, k := range keys {\n\t\t\te.marshal(\"\", k)\n\t\t\te.marshal(\"\", in.MapIndex(k))\n\t\t}\n\t})\n}\n\nfunc (e *encoder) fieldByIndex(v reflect.Value, index []int) (field reflect.Value) {\n\tfor _, num := range index {\n\t\tfor {\n\t\t\tif v.Kind() == reflect.Ptr {\n\t\t\t\tif v.IsNil() {\n\t\t\t\t\treturn reflect.Value{}\n\t\t\t\t}\n\t\t\t\tv = v.Elem()\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t\tv = v.Field(num)\n\t}\n\treturn v\n}\n\nfunc (e *encoder) structv(tag string, in reflect.Value) {\n\tsinfo, err := getStructInfo(in.Type())\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\te.mappingv(tag, func() {\n\t\tfor _, info := range sinfo.FieldsList {\n\t\t\tvar value reflect.Value\n\t\t\tif info.Inline == nil {\n\t\t\t\tvalue = in.Field(info.Num)\n\t\t\t} else {\n\t\t\t\tvalue = e.fieldByIndex(in, info.Inline)\n\t\t\t\tif !value.IsValid() {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\t\t\tif info.OmitEmpty && isZero(value) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\te.marshal(\"\", reflect.ValueOf(info.Key))\n\t\t\te.flow = info.Flow\n\t\t\te.marshal(\"\", value)\n\t\t}\n\t\tif sinfo.InlineMap >= 0 {\n\t\t\tm := in.Field(sinfo.InlineMap)\n\t\t\tif m.Len() > 0 {\n\t\t\t\te.flow = false\n\t\t\t\tkeys := keyList(m.MapKeys())\n\t\t\t\tsort.Sort(keys)\n\t\t\t\tfor _, k := range keys {\n\t\t\t\t\tif _, found := sinfo.FieldsMap[k.String()]; found {\n\t\t\t\t\t\tpanic(fmt.Sprintf(\"cannot have key %q in inlined map: conflicts with struct field\", k.String()))\n\t\t\t\t\t}\n\t\t\t\t\te.marshal(\"\", k)\n\t\t\t\t\te.flow = false\n\t\t\t\t\te.marshal(\"\", m.MapIndex(k))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc (e *encoder) mappingv(tag string, f func()) {\n\timplicit := tag == \"\"\n\tstyle := yaml_BLOCK_MAPPING_STYLE\n\tif e.flow {\n\t\te.flow = false\n\t\tstyle = yaml_FLOW_MAPPING_STYLE\n\t}\n\tyaml_mapping_start_event_initialize(&e.event, nil, []byte(tag), implicit, style)\n\te.emit()\n\tf()\n\tyaml_mapping_end_event_initialize(&e.event)\n\te.emit()\n}\n\nfunc (e *encoder) slicev(tag string, in reflect.Value) {\n\timplicit := tag == \"\"\n\tstyle := yaml_BLOCK_SEQUENCE_STYLE\n\tif e.flow {\n\t\te.flow = false\n\t\tstyle = yaml_FLOW_SEQUENCE_STYLE\n\t}\n\te.must(yaml_sequence_start_event_initialize(&e.event, nil, []byte(tag), implicit, style))\n\te.emit()\n\tn := in.Len()\n\tfor i := 0; i < n; i++ {\n\t\te.marshal(\"\", in.Index(i))\n\t}\n\te.must(yaml_sequence_end_event_initialize(&e.event))\n\te.emit()\n}\n\n// isBase60 returns whether s is in base 60 notation as defined in YAML 1.1.\n//\n// The base 60 float notation in YAML 1.1 is a terrible idea and is unsupported\n// in YAML 1.2 and by this package, but these should be marshalled quoted for\n// the time being for compatibility with other parsers.\nfunc isBase60Float(s string) (result bool) {\n\t// Fast path.\n\tif s == \"\" {\n\t\treturn false\n\t}\n\tc := s[0]\n\tif !(c == '+' || c == '-' || c >= '0' && c <= '9') || strings.IndexByte(s, ':') < 0 {\n\t\treturn false\n\t}\n\t// Do the full match.\n\treturn base60float.MatchString(s)\n}\n\n// From http://yaml.org/type/float.html, except the regular expression there\n// is bogus. In practice parsers do not enforce the \"\\.[0-9_]*\" suffix.\nvar base60float = regexp.MustCompile(`^[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+(?:\\.[0-9_]*)?$`)\n\n// isOldBool returns whether s is bool notation as defined in YAML 1.1.\n//\n// We continue to force strings that YAML 1.1 would interpret as booleans to be\n// rendered as quotes strings so that the marshalled output valid for YAML 1.1\n// parsing.\nfunc isOldBool(s string) (result bool) {\n\tswitch s {\n\tcase \"y\", \"Y\", \"yes\", \"Yes\", \"YES\", \"on\", \"On\", \"ON\",\n\t\t\"n\", \"N\", \"no\", \"No\", \"NO\", \"off\", \"Off\", \"OFF\":\n\t\treturn true\n\tdefault:\n\t\treturn false\n\t}\n}\n\nfunc (e *encoder) stringv(tag string, in reflect.Value) {\n\tvar style yaml_scalar_style_t\n\ts := in.String()\n\tcanUsePlain := true\n\tswitch {\n\tcase !utf8.ValidString(s):\n\t\tif tag == binaryTag {\n\t\t\tfailf(\"explicitly tagged !!binary data must be base64-encoded\")\n\t\t}\n\t\tif tag != \"\" {\n\t\t\tfailf(\"cannot marshal invalid UTF-8 data as %s\", shortTag(tag))\n\t\t}\n\t\t// It can't be encoded directly as YAML so use a binary tag\n\t\t// and encode it as base64.\n\t\ttag = binaryTag\n\t\ts = encodeBase64(s)\n\tcase tag == \"\":\n\t\t// Check to see if it would resolve to a specific\n\t\t// tag when encoded unquoted. If it doesn't,\n\t\t// there's no need to quote it.\n\t\trtag, _ := resolve(\"\", s)\n\t\tcanUsePlain = rtag == strTag && !(isBase60Float(s) || isOldBool(s))\n\t}\n\t// Note: it's possible for user code to emit invalid YAML\n\t// if they explicitly specify a tag and a string containing\n\t// text that's incompatible with that tag.\n\tswitch {\n\tcase strings.Contains(s, \"\\n\"):\n\t\tif e.flow {\n\t\t\tstyle = yaml_DOUBLE_QUOTED_SCALAR_STYLE\n\t\t} else {\n\t\t\tstyle = yaml_LITERAL_SCALAR_STYLE\n\t\t}\n\tcase canUsePlain:\n\t\tstyle = yaml_PLAIN_SCALAR_STYLE\n\tdefault:\n\t\tstyle = yaml_DOUBLE_QUOTED_SCALAR_STYLE\n\t}\n\te.emitScalar(s, \"\", tag, style, nil, nil, nil, nil)\n}\n\nfunc (e *encoder) boolv(tag string, in reflect.Value) {\n\tvar s string\n\tif in.Bool() {\n\t\ts = \"true\"\n\t} else {\n\t\ts = \"false\"\n\t}\n\te.emitScalar(s, \"\", tag, yaml_PLAIN_SCALAR_STYLE, nil, nil, nil, nil)\n}\n\nfunc (e *encoder) intv(tag string, in reflect.Value) {\n\ts := strconv.FormatInt(in.Int(), 10)\n\te.emitScalar(s, \"\", tag, yaml_PLAIN_SCALAR_STYLE, nil, nil, nil, nil)\n}\n\nfunc (e *encoder) uintv(tag string, in reflect.Value) {\n\ts := strconv.FormatUint(in.Uint(), 10)\n\te.emitScalar(s, \"\", tag, yaml_PLAIN_SCALAR_STYLE, nil, nil, nil, nil)\n}\n\nfunc (e *encoder) timev(tag string, in reflect.Value) {\n\tt := in.Interface().(time.Time)\n\ts := t.Format(time.RFC3339Nano)\n\te.emitScalar(s, \"\", tag, yaml_PLAIN_SCALAR_STYLE, nil, nil, nil, nil)\n}\n\nfunc (e *encoder) floatv(tag string, in reflect.Value) {\n\t// Issue #352: When formatting, use the precision of the underlying value\n\tprecision := 64\n\tif in.Kind() == reflect.Float32 {\n\t\tprecision = 32\n\t}\n\n\ts := strconv.FormatFloat(in.Float(), 'g', -1, precision)\n\tswitch s {\n\tcase \"+Inf\":\n\t\ts = \".inf\"\n\tcase \"-Inf\":\n\t\ts = \"-.inf\"\n\tcase \"NaN\":\n\t\ts = \".nan\"\n\t}\n\te.emitScalar(s, \"\", tag, yaml_PLAIN_SCALAR_STYLE, nil, nil, nil, nil)\n}\n\nfunc (e *encoder) nilv() {\n\te.emitScalar(\"null\", \"\", \"\", yaml_PLAIN_SCALAR_STYLE, nil, nil, nil, nil)\n}\n\nfunc (e *encoder) emitScalar(value, anchor, tag string, style yaml_scalar_style_t, head, line, foot, tail []byte) {\n\t// TODO Kill this function. Replace all initialize calls by their underlining Go literals.\n\timplicit := tag == \"\"\n\tif !implicit {\n\t\ttag = longTag(tag)\n\t}\n\te.must(yaml_scalar_event_initialize(&e.event, []byte(anchor), []byte(tag), []byte(value), implicit, implicit, style))\n\te.event.head_comment = head\n\te.event.line_comment = line\n\te.event.foot_comment = foot\n\te.event.tail_comment = tail\n\te.emit()\n}\n\nfunc (e *encoder) nodev(in reflect.Value) {\n\te.node(in.Interface().(*Node), \"\")\n}\n\nfunc (e *encoder) node(node *Node, tail string) {\n\t// Zero nodes behave as nil.\n\tif node.Kind == 0 && node.IsZero() {\n\t\te.nilv()\n\t\treturn\n\t}\n\n\t// If the tag was not explicitly requested, and dropping it won't change the\n\t// implicit tag of the value, don't include it in the presentation.\n\tvar tag = node.Tag\n\tvar stag = shortTag(tag)\n\tvar forceQuoting bool\n\tif tag != \"\" && node.Style&TaggedStyle == 0 {\n\t\tif node.Kind == ScalarNode {\n\t\t\tif stag == strTag && node.Style&(SingleQuotedStyle|DoubleQuotedStyle|LiteralStyle|FoldedStyle) != 0 {\n\t\t\t\ttag = \"\"\n\t\t\t} else {\n\t\t\t\trtag, _ := resolve(\"\", node.Value)\n\t\t\t\tif rtag == stag {\n\t\t\t\t\ttag = \"\"\n\t\t\t\t} else if stag == strTag {\n\t\t\t\t\ttag = \"\"\n\t\t\t\t\tforceQuoting = true\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tvar rtag string\n\t\t\tswitch node.Kind {\n\t\t\tcase MappingNode:\n\t\t\t\trtag = mapTag\n\t\t\tcase SequenceNode:\n\t\t\t\trtag = seqTag\n\t\t\t}\n\t\t\tif rtag == stag {\n\t\t\t\ttag = \"\"\n\t\t\t}\n\t\t}\n\t}\n\n\tswitch node.Kind {\n\tcase DocumentNode:\n\t\tyaml_document_start_event_initialize(&e.event, nil, nil, true)\n\t\te.event.head_comment = []byte(node.HeadComment)\n\t\te.emit()\n\t\tfor _, node := range node.Content {\n\t\t\te.node(node, \"\")\n\t\t}\n\t\tyaml_document_end_event_initialize(&e.event, true)\n\t\te.event.foot_comment = []byte(node.FootComment)\n\t\te.emit()\n\n\tcase SequenceNode:\n\t\tstyle := yaml_BLOCK_SEQUENCE_STYLE\n\t\tif node.Style&FlowStyle != 0 {\n\t\t\tstyle = yaml_FLOW_SEQUENCE_STYLE\n\t\t}\n\t\te.must(yaml_sequence_start_event_initialize(&e.event, []byte(node.Anchor), []byte(longTag(tag)), tag == \"\", style))\n\t\te.event.head_comment = []byte(node.HeadComment)\n\t\te.emit()\n\t\tfor _, node := range node.Content {\n\t\t\te.node(node, \"\")\n\t\t}\n\t\te.must(yaml_sequence_end_event_initialize(&e.event))\n\t\te.event.line_comment = []byte(node.LineComment)\n\t\te.event.foot_comment = []byte(node.FootComment)\n\t\te.emit()\n\n\tcase MappingNode:\n\t\tstyle := yaml_BLOCK_MAPPING_STYLE\n\t\tif node.Style&FlowStyle != 0 {\n\t\t\tstyle = yaml_FLOW_MAPPING_STYLE\n\t\t}\n\t\tyaml_mapping_start_event_initialize(&e.event, []byte(node.Anchor), []byte(longTag(tag)), tag == \"\", style)\n\t\te.event.tail_comment = []byte(tail)\n\t\te.event.head_comment = []byte(node.HeadComment)\n\t\te.emit()\n\n\t\t// The tail logic below moves the foot comment of prior keys to the following key,\n\t\t// since the value for each key may be a nested structure and the foot needs to be\n\t\t// processed only the entirety of the value is streamed. The last tail is processed\n\t\t// with the mapping end event.\n\t\tvar tail string\n\t\tfor i := 0; i+1 < len(node.Content); i += 2 {\n\t\t\tk := node.Content[i]\n\t\t\tfoot := k.FootComment\n\t\t\tif foot != \"\" {\n\t\t\t\tkopy := *k\n\t\t\t\tkopy.FootComment = \"\"\n\t\t\t\tk = &kopy\n\t\t\t}\n\t\t\te.node(k, tail)\n\t\t\ttail = foot\n\n\t\t\tv := node.Content[i+1]\n\t\t\te.node(v, \"\")\n\t\t}\n\n\t\tyaml_mapping_end_event_initialize(&e.event)\n\t\te.event.tail_comment = []byte(tail)\n\t\te.event.line_comment = []byte(node.LineComment)\n\t\te.event.foot_comment = []byte(node.FootComment)\n\t\te.emit()\n\n\tcase AliasNode:\n\t\tyaml_alias_event_initialize(&e.event, []byte(node.Value))\n\t\te.event.head_comment = []byte(node.HeadComment)\n\t\te.event.line_comment = []byte(node.LineComment)\n\t\te.event.foot_comment = []byte(node.FootComment)\n\t\te.emit()\n\n\tcase ScalarNode:\n\t\tvalue := node.Value\n\t\tif !utf8.ValidString(value) {\n\t\t\tif stag == binaryTag {\n\t\t\t\tfailf(\"explicitly tagged !!binary data must be base64-encoded\")\n\t\t\t}\n\t\t\tif stag != \"\" {\n\t\t\t\tfailf(\"cannot marshal invalid UTF-8 data as %s\", stag)\n\t\t\t}\n\t\t\t// It can't be encoded directly as YAML so use a binary tag\n\t\t\t// and encode it as base64.\n\t\t\ttag = binaryTag\n\t\t\tvalue = encodeBase64(value)\n\t\t}\n\n\t\tstyle := yaml_PLAIN_SCALAR_STYLE\n\t\tswitch {\n\t\tcase node.Style&DoubleQuotedStyle != 0:\n\t\t\tstyle = yaml_DOUBLE_QUOTED_SCALAR_STYLE\n\t\tcase node.Style&SingleQuotedStyle != 0:\n\t\t\tstyle = yaml_SINGLE_QUOTED_SCALAR_STYLE\n\t\tcase node.Style&LiteralStyle != 0:\n\t\t\tstyle = yaml_LITERAL_SCALAR_STYLE\n\t\tcase node.Style&FoldedStyle != 0:\n\t\t\tstyle = yaml_FOLDED_SCALAR_STYLE\n\t\tcase strings.Contains(value, \"\\n\"):\n\t\t\tstyle = yaml_LITERAL_SCALAR_STYLE\n\t\tcase forceQuoting:\n\t\t\tstyle = yaml_DOUBLE_QUOTED_SCALAR_STYLE\n\t\t}\n\n\t\te.emitScalar(value, node.Anchor, tag, style, []byte(node.HeadComment), []byte(node.LineComment), []byte(node.FootComment), []byte(tail))\n\tdefault:\n\t\tfailf(\"cannot encode node with unknown kind %d\", node.Kind)\n\t}\n}\n"
        },
        {
          "name": "encode_test.go",
          "type": "blob",
          "size": 14.4462890625,
          "content": "//\n// Copyright (c) 2011-2019 Canonical Ltd\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage yaml_test\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"math\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"net\"\n\t\"os\"\n\n\t. \"gopkg.in/check.v1\"\n\t\"gopkg.in/yaml.v3\"\n)\n\nvar marshalIntTest = 123\n\nvar marshalTests = []struct {\n\tvalue interface{}\n\tdata  string\n}{\n\t{\n\t\tnil,\n\t\t\"null\\n\",\n\t}, {\n\t\t(*marshalerType)(nil),\n\t\t\"null\\n\",\n\t}, {\n\t\t&struct{}{},\n\t\t\"{}\\n\",\n\t}, {\n\t\tmap[string]string{\"v\": \"hi\"},\n\t\t\"v: hi\\n\",\n\t}, {\n\t\tmap[string]interface{}{\"v\": \"hi\"},\n\t\t\"v: hi\\n\",\n\t}, {\n\t\tmap[string]string{\"v\": \"true\"},\n\t\t\"v: \\\"true\\\"\\n\",\n\t}, {\n\t\tmap[string]string{\"v\": \"false\"},\n\t\t\"v: \\\"false\\\"\\n\",\n\t}, {\n\t\tmap[string]interface{}{\"v\": true},\n\t\t\"v: true\\n\",\n\t}, {\n\t\tmap[string]interface{}{\"v\": false},\n\t\t\"v: false\\n\",\n\t}, {\n\t\tmap[string]interface{}{\"v\": 10},\n\t\t\"v: 10\\n\",\n\t}, {\n\t\tmap[string]interface{}{\"v\": -10},\n\t\t\"v: -10\\n\",\n\t}, {\n\t\tmap[string]uint{\"v\": 42},\n\t\t\"v: 42\\n\",\n\t}, {\n\t\tmap[string]interface{}{\"v\": int64(4294967296)},\n\t\t\"v: 4294967296\\n\",\n\t}, {\n\t\tmap[string]int64{\"v\": int64(4294967296)},\n\t\t\"v: 4294967296\\n\",\n\t}, {\n\t\tmap[string]uint64{\"v\": 4294967296},\n\t\t\"v: 4294967296\\n\",\n\t}, {\n\t\tmap[string]interface{}{\"v\": \"10\"},\n\t\t\"v: \\\"10\\\"\\n\",\n\t}, {\n\t\tmap[string]interface{}{\"v\": 0.1},\n\t\t\"v: 0.1\\n\",\n\t}, {\n\t\tmap[string]interface{}{\"v\": float64(0.1)},\n\t\t\"v: 0.1\\n\",\n\t}, {\n\t\tmap[string]interface{}{\"v\": float32(0.99)},\n\t\t\"v: 0.99\\n\",\n\t}, {\n\t\tmap[string]interface{}{\"v\": -0.1},\n\t\t\"v: -0.1\\n\",\n\t}, {\n\t\tmap[string]interface{}{\"v\": math.Inf(+1)},\n\t\t\"v: .inf\\n\",\n\t}, {\n\t\tmap[string]interface{}{\"v\": math.Inf(-1)},\n\t\t\"v: -.inf\\n\",\n\t}, {\n\t\tmap[string]interface{}{\"v\": math.NaN()},\n\t\t\"v: .nan\\n\",\n\t}, {\n\t\tmap[string]interface{}{\"v\": nil},\n\t\t\"v: null\\n\",\n\t}, {\n\t\tmap[string]interface{}{\"v\": \"\"},\n\t\t\"v: \\\"\\\"\\n\",\n\t}, {\n\t\tmap[string][]string{\"v\": []string{\"A\", \"B\"}},\n\t\t\"v:\\n    - A\\n    - B\\n\",\n\t}, {\n\t\tmap[string][]string{\"v\": []string{\"A\", \"B\\nC\"}},\n\t\t\"v:\\n    - A\\n    - |-\\n      B\\n      C\\n\",\n\t}, {\n\t\tmap[string][]interface{}{\"v\": []interface{}{\"A\", 1, map[string][]int{\"B\": []int{2, 3}}}},\n\t\t\"v:\\n    - A\\n    - 1\\n    - B:\\n        - 2\\n        - 3\\n\",\n\t}, {\n\t\tmap[string]interface{}{\"a\": map[interface{}]interface{}{\"b\": \"c\"}},\n\t\t\"a:\\n    b: c\\n\",\n\t}, {\n\t\tmap[string]interface{}{\"a\": \"-\"},\n\t\t\"a: '-'\\n\",\n\t},\n\n\t// Simple values.\n\t{\n\t\t&marshalIntTest,\n\t\t\"123\\n\",\n\t},\n\n\t// Structures\n\t{\n\t\t&struct{ Hello string }{\"world\"},\n\t\t\"hello: world\\n\",\n\t}, {\n\t\t&struct {\n\t\t\tA struct {\n\t\t\t\tB string\n\t\t\t}\n\t\t}{struct{ B string }{\"c\"}},\n\t\t\"a:\\n    b: c\\n\",\n\t}, {\n\t\t&struct {\n\t\t\tA *struct {\n\t\t\t\tB string\n\t\t\t}\n\t\t}{&struct{ B string }{\"c\"}},\n\t\t\"a:\\n    b: c\\n\",\n\t}, {\n\t\t&struct {\n\t\t\tA *struct {\n\t\t\t\tB string\n\t\t\t}\n\t\t}{},\n\t\t\"a: null\\n\",\n\t}, {\n\t\t&struct{ A int }{1},\n\t\t\"a: 1\\n\",\n\t}, {\n\t\t&struct{ A []int }{[]int{1, 2}},\n\t\t\"a:\\n    - 1\\n    - 2\\n\",\n\t}, {\n\t\t&struct{ A [2]int }{[2]int{1, 2}},\n\t\t\"a:\\n    - 1\\n    - 2\\n\",\n\t}, {\n\t\t&struct {\n\t\t\tB int \"a\"\n\t\t}{1},\n\t\t\"a: 1\\n\",\n\t}, {\n\t\t&struct{ A bool }{true},\n\t\t\"a: true\\n\",\n\t}, {\n\t\t&struct{ A string }{\"true\"},\n\t\t\"a: \\\"true\\\"\\n\",\n\t}, {\n\t\t&struct{ A string }{\"off\"},\n\t\t\"a: \\\"off\\\"\\n\",\n\t},\n\n\t// Conditional flag\n\t{\n\t\t&struct {\n\t\t\tA int \"a,omitempty\"\n\t\t\tB int \"b,omitempty\"\n\t\t}{1, 0},\n\t\t\"a: 1\\n\",\n\t}, {\n\t\t&struct {\n\t\t\tA int \"a,omitempty\"\n\t\t\tB int \"b,omitempty\"\n\t\t}{0, 0},\n\t\t\"{}\\n\",\n\t}, {\n\t\t&struct {\n\t\t\tA *struct{ X, y int } \"a,omitempty,flow\"\n\t\t}{&struct{ X, y int }{1, 2}},\n\t\t\"a: {x: 1}\\n\",\n\t}, {\n\t\t&struct {\n\t\t\tA *struct{ X, y int } \"a,omitempty,flow\"\n\t\t}{nil},\n\t\t\"{}\\n\",\n\t}, {\n\t\t&struct {\n\t\t\tA *struct{ X, y int } \"a,omitempty,flow\"\n\t\t}{&struct{ X, y int }{}},\n\t\t\"a: {x: 0}\\n\",\n\t}, {\n\t\t&struct {\n\t\t\tA struct{ X, y int } \"a,omitempty,flow\"\n\t\t}{struct{ X, y int }{1, 2}},\n\t\t\"a: {x: 1}\\n\",\n\t}, {\n\t\t&struct {\n\t\t\tA struct{ X, y int } \"a,omitempty,flow\"\n\t\t}{struct{ X, y int }{0, 1}},\n\t\t\"{}\\n\",\n\t}, {\n\t\t&struct {\n\t\t\tA float64 \"a,omitempty\"\n\t\t\tB float64 \"b,omitempty\"\n\t\t}{1, 0},\n\t\t\"a: 1\\n\",\n\t},\n\t{\n\t\t&struct {\n\t\t\tT1 time.Time  \"t1,omitempty\"\n\t\t\tT2 time.Time  \"t2,omitempty\"\n\t\t\tT3 *time.Time \"t3,omitempty\"\n\t\t\tT4 *time.Time \"t4,omitempty\"\n\t\t}{\n\t\t\tT2: time.Date(2018, 1, 9, 10, 40, 47, 0, time.UTC),\n\t\t\tT4: newTime(time.Date(2098, 1, 9, 10, 40, 47, 0, time.UTC)),\n\t\t},\n\t\t\"t2: 2018-01-09T10:40:47Z\\nt4: 2098-01-09T10:40:47Z\\n\",\n\t},\n\t// Nil interface that implements Marshaler.\n\t{\n\t\tmap[string]yaml.Marshaler{\n\t\t\t\"a\": nil,\n\t\t},\n\t\t\"a: null\\n\",\n\t},\n\n\t// Flow flag\n\t{\n\t\t&struct {\n\t\t\tA []int \"a,flow\"\n\t\t}{[]int{1, 2}},\n\t\t\"a: [1, 2]\\n\",\n\t}, {\n\t\t&struct {\n\t\t\tA map[string]string \"a,flow\"\n\t\t}{map[string]string{\"b\": \"c\", \"d\": \"e\"}},\n\t\t\"a: {b: c, d: e}\\n\",\n\t}, {\n\t\t&struct {\n\t\t\tA struct {\n\t\t\t\tB, D string\n\t\t\t} \"a,flow\"\n\t\t}{struct{ B, D string }{\"c\", \"e\"}},\n\t\t\"a: {b: c, d: e}\\n\",\n\t}, {\n\t\t&struct {\n\t\t\tA string \"a,flow\"\n\t\t}{\"b\\nc\"},\n\t\t\"a: \\\"b\\\\nc\\\"\\n\",\n\t},\n\n\t// Unexported field\n\t{\n\t\t&struct {\n\t\t\tu int\n\t\t\tA int\n\t\t}{0, 1},\n\t\t\"a: 1\\n\",\n\t},\n\n\t// Ignored field\n\t{\n\t\t&struct {\n\t\t\tA int\n\t\t\tB int \"-\"\n\t\t}{1, 2},\n\t\t\"a: 1\\n\",\n\t},\n\n\t// Struct inlining\n\t{\n\t\t&struct {\n\t\t\tA int\n\t\t\tC inlineB `yaml:\",inline\"`\n\t\t}{1, inlineB{2, inlineC{3}}},\n\t\t\"a: 1\\nb: 2\\nc: 3\\n\",\n\t},\n\t// Struct inlining as a pointer\n\t{\n\t\t&struct {\n\t\t\tA int\n\t\t\tC *inlineB `yaml:\",inline\"`\n\t\t}{1, &inlineB{2, inlineC{3}}},\n\t\t\"a: 1\\nb: 2\\nc: 3\\n\",\n\t}, {\n\t\t&struct {\n\t\t\tA int\n\t\t\tC *inlineB `yaml:\",inline\"`\n\t\t}{1, nil},\n\t\t\"a: 1\\n\",\n\t}, {\n\t\t&struct {\n\t\t\tA int\n\t\t\tD *inlineD `yaml:\",inline\"`\n\t\t}{1, &inlineD{&inlineC{3}, 4}},\n\t\t\"a: 1\\nc: 3\\nd: 4\\n\",\n\t},\n\n\t// Map inlining\n\t{\n\t\t&struct {\n\t\t\tA int\n\t\t\tC map[string]int `yaml:\",inline\"`\n\t\t}{1, map[string]int{\"b\": 2, \"c\": 3}},\n\t\t\"a: 1\\nb: 2\\nc: 3\\n\",\n\t},\n\n\t// Duration\n\t{\n\t\tmap[string]time.Duration{\"a\": 3 * time.Second},\n\t\t\"a: 3s\\n\",\n\t},\n\n\t// Issue #24: bug in map merging logic.\n\t{\n\t\tmap[string]string{\"a\": \"<foo>\"},\n\t\t\"a: <foo>\\n\",\n\t},\n\n\t// Issue #34: marshal unsupported base 60 floats quoted for compatibility\n\t// with old YAML 1.1 parsers.\n\t{\n\t\tmap[string]string{\"a\": \"1:1\"},\n\t\t\"a: \\\"1:1\\\"\\n\",\n\t},\n\n\t// Binary data.\n\t{\n\t\tmap[string]string{\"a\": \"\\x00\"},\n\t\t\"a: \\\"\\\\0\\\"\\n\",\n\t}, {\n\t\tmap[string]string{\"a\": \"\\x80\\x81\\x82\"},\n\t\t\"a: !!binary gIGC\\n\",\n\t}, {\n\t\tmap[string]string{\"a\": strings.Repeat(\"\\x90\", 54)},\n\t\t\"a: !!binary |\\n    \" + strings.Repeat(\"kJCQ\", 17) + \"kJ\\n    CQ\\n\",\n\t},\n\n\t// Encode unicode as utf-8 rather than in escaped form.\n\t{\n\t\tmap[string]string{\"a\": \"\"},\n\t\t\"a: \\n\",\n\t},\n\n\t// Support encoding.TextMarshaler.\n\t{\n\t\tmap[string]net.IP{\"a\": net.IPv4(1, 2, 3, 4)},\n\t\t\"a: 1.2.3.4\\n\",\n\t},\n\t// time.Time gets a timestamp tag.\n\t{\n\t\tmap[string]time.Time{\"a\": time.Date(2015, 2, 24, 18, 19, 39, 0, time.UTC)},\n\t\t\"a: 2015-02-24T18:19:39Z\\n\",\n\t},\n\t{\n\t\tmap[string]*time.Time{\"a\": newTime(time.Date(2015, 2, 24, 18, 19, 39, 0, time.UTC))},\n\t\t\"a: 2015-02-24T18:19:39Z\\n\",\n\t},\n\t{\n\t\t// This is confirmed to be properly decoded in Python (libyaml) without a timestamp tag.\n\t\tmap[string]time.Time{\"a\": time.Date(2015, 2, 24, 18, 19, 39, 123456789, time.FixedZone(\"FOO\", -3*60*60))},\n\t\t\"a: 2015-02-24T18:19:39.123456789-03:00\\n\",\n\t},\n\t// Ensure timestamp-like strings are quoted.\n\t{\n\t\tmap[string]string{\"a\": \"2015-02-24T18:19:39Z\"},\n\t\t\"a: \\\"2015-02-24T18:19:39Z\\\"\\n\",\n\t},\n\n\t// Ensure strings containing \": \" are quoted (reported as PR #43, but not reproducible).\n\t{\n\t\tmap[string]string{\"a\": \"b: c\"},\n\t\t\"a: 'b: c'\\n\",\n\t},\n\n\t// Containing hash mark ('#') in string should be quoted\n\t{\n\t\tmap[string]string{\"a\": \"Hello #comment\"},\n\t\t\"a: 'Hello #comment'\\n\",\n\t},\n\t{\n\t\tmap[string]string{\"a\": \" #comment\"},\n\t\t\"a: ' #comment'\\n\",\n\t},\n\n\t// Ensure MarshalYAML also gets called on the result of MarshalYAML itself.\n\t{\n\t\t&marshalerType{marshalerType{true}},\n\t\t\"true\\n\",\n\t}, {\n\t\t&marshalerType{&marshalerType{true}},\n\t\t\"true\\n\",\n\t},\n\n\t// Check indentation of maps inside sequences inside maps.\n\t{\n\t\tmap[string]interface{}{\"a\": map[string]interface{}{\"b\": []map[string]int{{\"c\": 1, \"d\": 2}}}},\n\t\t\"a:\\n    b:\\n        - c: 1\\n          d: 2\\n\",\n\t},\n\n\t// Strings with tabs were disallowed as literals (issue #471).\n\t{\n\t\tmap[string]string{\"a\": \"\\tB\\n\\tC\\n\"},\n\t\t\"a: |\\n    \\tB\\n    \\tC\\n\",\n\t},\n\n\t// Ensure that strings do not wrap\n\t{\n\t\tmap[string]string{\"a\": \"abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ 1234567890 abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ 1234567890 \"},\n\t\t\"a: 'abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ 1234567890 abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ 1234567890 '\\n\",\n\t},\n\n\t// yaml.Node\n\t{\n\t\t&struct {\n\t\t\tValue yaml.Node\n\t\t}{\n\t\t\tyaml.Node{\n\t\t\t\tKind:  yaml.ScalarNode,\n\t\t\t\tTag:   \"!!str\",\n\t\t\t\tValue: \"foo\",\n\t\t\t\tStyle: yaml.SingleQuotedStyle,\n\t\t\t},\n\t\t},\n\t\t\"value: 'foo'\\n\",\n\t}, {\n\t\tyaml.Node{\n\t\t\tKind:  yaml.ScalarNode,\n\t\t\tTag:   \"!!str\",\n\t\t\tValue: \"foo\",\n\t\t\tStyle: yaml.SingleQuotedStyle,\n\t\t},\n\t\t\"'foo'\\n\",\n\t},\n\n\t// Enforced tagging with shorthand notation (issue #616).\n\t{\n\t\t&struct {\n\t\t\tValue yaml.Node\n\t\t}{\n\t\t\tyaml.Node{\n\t\t\t\tKind:  yaml.ScalarNode,\n\t\t\t\tStyle: yaml.TaggedStyle,\n\t\t\t\tValue: \"foo\",\n\t\t\t\tTag:   \"!!str\",\n\t\t\t},\n\t\t},\n\t\t\"value: !!str foo\\n\",\n\t}, {\n\t\t&struct {\n\t\t\tValue yaml.Node\n\t\t}{\n\t\t\tyaml.Node{\n\t\t\t\tKind:  yaml.MappingNode,\n\t\t\t\tStyle: yaml.TaggedStyle,\n\t\t\t\tTag:   \"!!map\",\n\t\t\t},\n\t\t},\n\t\t\"value: !!map {}\\n\",\n\t}, {\n\t\t&struct {\n\t\t\tValue yaml.Node\n\t\t}{\n\t\t\tyaml.Node{\n\t\t\t\tKind:  yaml.SequenceNode,\n\t\t\t\tStyle: yaml.TaggedStyle,\n\t\t\t\tTag:   \"!!seq\",\n\t\t\t},\n\t\t},\n\t\t\"value: !!seq []\\n\",\n\t},\n}\n\nfunc (s *S) TestMarshal(c *C) {\n\tdefer os.Setenv(\"TZ\", os.Getenv(\"TZ\"))\n\tos.Setenv(\"TZ\", \"UTC\")\n\tfor i, item := range marshalTests {\n\t\tc.Logf(\"test %d: %q\", i, item.data)\n\t\tdata, err := yaml.Marshal(item.value)\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(string(data), Equals, item.data)\n\t}\n}\n\nfunc (s *S) TestEncoderSingleDocument(c *C) {\n\tfor i, item := range marshalTests {\n\t\tc.Logf(\"test %d. %q\", i, item.data)\n\t\tvar buf bytes.Buffer\n\t\tenc := yaml.NewEncoder(&buf)\n\t\terr := enc.Encode(item.value)\n\t\tc.Assert(err, Equals, nil)\n\t\terr = enc.Close()\n\t\tc.Assert(err, Equals, nil)\n\t\tc.Assert(buf.String(), Equals, item.data)\n\t}\n}\n\nfunc (s *S) TestEncoderMultipleDocuments(c *C) {\n\tvar buf bytes.Buffer\n\tenc := yaml.NewEncoder(&buf)\n\terr := enc.Encode(map[string]string{\"a\": \"b\"})\n\tc.Assert(err, Equals, nil)\n\terr = enc.Encode(map[string]string{\"c\": \"d\"})\n\tc.Assert(err, Equals, nil)\n\terr = enc.Close()\n\tc.Assert(err, Equals, nil)\n\tc.Assert(buf.String(), Equals, \"a: b\\n---\\nc: d\\n\")\n}\n\nfunc (s *S) TestEncoderWriteError(c *C) {\n\tenc := yaml.NewEncoder(errorWriter{})\n\terr := enc.Encode(map[string]string{\"a\": \"b\"})\n\tc.Assert(err, ErrorMatches, `yaml: write error: some write error`) // Data not flushed yet\n}\n\ntype errorWriter struct{}\n\nfunc (errorWriter) Write([]byte) (int, error) {\n\treturn 0, fmt.Errorf(\"some write error\")\n}\n\nvar marshalErrorTests = []struct {\n\tvalue interface{}\n\terror string\n\tpanic string\n}{{\n\tvalue: &struct {\n\t\tB       int\n\t\tinlineB \",inline\"\n\t}{1, inlineB{2, inlineC{3}}},\n\tpanic: `duplicated key 'b' in struct struct \\{ B int; .*`,\n}, {\n\tvalue: &struct {\n\t\tA int\n\t\tB map[string]int \",inline\"\n\t}{1, map[string]int{\"a\": 2}},\n\tpanic: `cannot have key \"a\" in inlined map: conflicts with struct field`,\n}}\n\nfunc (s *S) TestMarshalErrors(c *C) {\n\tfor _, item := range marshalErrorTests {\n\t\tif item.panic != \"\" {\n\t\t\tc.Assert(func() { yaml.Marshal(item.value) }, PanicMatches, item.panic)\n\t\t} else {\n\t\t\t_, err := yaml.Marshal(item.value)\n\t\t\tc.Assert(err, ErrorMatches, item.error)\n\t\t}\n\t}\n}\n\nfunc (s *S) TestMarshalTypeCache(c *C) {\n\tvar data []byte\n\tvar err error\n\tfunc() {\n\t\ttype T struct{ A int }\n\t\tdata, err = yaml.Marshal(&T{})\n\t\tc.Assert(err, IsNil)\n\t}()\n\tfunc() {\n\t\ttype T struct{ B int }\n\t\tdata, err = yaml.Marshal(&T{})\n\t\tc.Assert(err, IsNil)\n\t}()\n\tc.Assert(string(data), Equals, \"b: 0\\n\")\n}\n\nvar marshalerTests = []struct {\n\tdata  string\n\tvalue interface{}\n}{\n\t{\"_:\\n    hi: there\\n\", map[interface{}]interface{}{\"hi\": \"there\"}},\n\t{\"_:\\n    - 1\\n    - A\\n\", []interface{}{1, \"A\"}},\n\t{\"_: 10\\n\", 10},\n\t{\"_: null\\n\", nil},\n\t{\"_: BAR!\\n\", \"BAR!\"},\n}\n\ntype marshalerType struct {\n\tvalue interface{}\n}\n\nfunc (o marshalerType) MarshalText() ([]byte, error) {\n\tpanic(\"MarshalText called on type with MarshalYAML\")\n}\n\nfunc (o marshalerType) MarshalYAML() (interface{}, error) {\n\treturn o.value, nil\n}\n\ntype marshalerValue struct {\n\tField marshalerType \"_\"\n}\n\nfunc (s *S) TestMarshaler(c *C) {\n\tfor _, item := range marshalerTests {\n\t\tobj := &marshalerValue{}\n\t\tobj.Field.value = item.value\n\t\tdata, err := yaml.Marshal(obj)\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(string(data), Equals, string(item.data))\n\t}\n}\n\nfunc (s *S) TestMarshalerWholeDocument(c *C) {\n\tobj := &marshalerType{}\n\tobj.value = map[string]string{\"hello\": \"world!\"}\n\tdata, err := yaml.Marshal(obj)\n\tc.Assert(err, IsNil)\n\tc.Assert(string(data), Equals, \"hello: world!\\n\")\n}\n\ntype failingMarshaler struct{}\n\nfunc (ft *failingMarshaler) MarshalYAML() (interface{}, error) {\n\treturn nil, failingErr\n}\n\nfunc (s *S) TestMarshalerError(c *C) {\n\t_, err := yaml.Marshal(&failingMarshaler{})\n\tc.Assert(err, Equals, failingErr)\n}\n\nfunc (s *S) TestSetIndent(c *C) {\n\tvar buf bytes.Buffer\n\tenc := yaml.NewEncoder(&buf)\n\tenc.SetIndent(8)\n\terr := enc.Encode(map[string]interface{}{\"a\": map[string]interface{}{\"b\": map[string]string{\"c\": \"d\"}}})\n\tc.Assert(err, Equals, nil)\n\terr = enc.Close()\n\tc.Assert(err, Equals, nil)\n\tc.Assert(buf.String(), Equals, \"a:\\n        b:\\n                c: d\\n\")\n}\n\nfunc (s *S) TestSortedOutput(c *C) {\n\torder := []interface{}{\n\t\tfalse,\n\t\ttrue,\n\t\t1,\n\t\tuint(1),\n\t\t1.0,\n\t\t1.1,\n\t\t1.2,\n\t\t2,\n\t\tuint(2),\n\t\t2.0,\n\t\t2.1,\n\t\t\"\",\n\t\t\".1\",\n\t\t\".2\",\n\t\t\".a\",\n\t\t\"1\",\n\t\t\"2\",\n\t\t\"a!10\",\n\t\t\"a/0001\",\n\t\t\"a/002\",\n\t\t\"a/3\",\n\t\t\"a/10\",\n\t\t\"a/11\",\n\t\t\"a/0012\",\n\t\t\"a/100\",\n\t\t\"a~10\",\n\t\t\"ab/1\",\n\t\t\"b/1\",\n\t\t\"b/01\",\n\t\t\"b/2\",\n\t\t\"b/02\",\n\t\t\"b/3\",\n\t\t\"b/03\",\n\t\t\"b1\",\n\t\t\"b01\",\n\t\t\"b3\",\n\t\t\"c2.10\",\n\t\t\"c10.2\",\n\t\t\"d1\",\n\t\t\"d7\",\n\t\t\"d7abc\",\n\t\t\"d12\",\n\t\t\"d12a\",\n\t\t\"e2b\",\n\t\t\"e4b\",\n\t\t\"e21a\",\n\t}\n\tm := make(map[interface{}]int)\n\tfor _, k := range order {\n\t\tm[k] = 1\n\t}\n\tdata, err := yaml.Marshal(m)\n\tc.Assert(err, IsNil)\n\tout := \"\\n\" + string(data)\n\tlast := 0\n\tfor i, k := range order {\n\t\trepr := fmt.Sprint(k)\n\t\tif s, ok := k.(string); ok {\n\t\t\tif _, err = strconv.ParseFloat(repr, 32); s == \"\" || err == nil {\n\t\t\t\trepr = `\"` + repr + `\"`\n\t\t\t}\n\t\t}\n\t\tindex := strings.Index(out, \"\\n\"+repr+\":\")\n\t\tif index == -1 {\n\t\t\tc.Fatalf(\"%#v is not in the output: %#v\", k, out)\n\t\t}\n\t\tif index < last {\n\t\t\tc.Fatalf(\"%#v was generated before %#v: %q\", k, order[i-1], out)\n\t\t}\n\t\tlast = index\n\t}\n}\n\nfunc newTime(t time.Time) *time.Time {\n\treturn &t\n}\n"
        },
        {
          "name": "example_embedded_test.go",
          "type": "blob",
          "size": 1.2841796875,
          "content": "//\n// Copyright (c) 2011-2019 Canonical Ltd\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage yaml_test\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\n\t\"gopkg.in/yaml.v3\"\n)\n\n// An example showing how to unmarshal embedded\n// structs from YAML.\n\ntype StructA struct {\n\tA string `yaml:\"a\"`\n}\n\ntype StructB struct {\n\t// Embedded structs are not treated as embedded in YAML by default. To do that,\n\t// add the \",inline\" annotation below\n\tStructA `yaml:\",inline\"`\n\tB       string `yaml:\"b\"`\n}\n\nvar data = `\na: a string from struct A\nb: a string from struct B\n`\n\nfunc ExampleUnmarshal_embedded() {\n\tvar b StructB\n\n\terr := yaml.Unmarshal([]byte(data), &b)\n\tif err != nil {\n\t\tlog.Fatalf(\"cannot unmarshal data: %v\", err)\n\t}\n\tfmt.Println(b.A)\n\tfmt.Println(b.B)\n\t// Output:\n\t// a string from struct A\n\t// a string from struct B\n}\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.0927734375,
          "content": "module \"gopkg.in/yaml.v3\"\n\nrequire (\n\t\"gopkg.in/check.v1\" v0.0.0-20161208181325-20d25e280405\n)\n"
        },
        {
          "name": "limit_test.go",
          "type": "blob",
          "size": 3.7841796875,
          "content": "package yaml_test\n\nimport (\n\t\"strings\"\n\t\"testing\"\n\n\t. \"gopkg.in/check.v1\"\n\t\"gopkg.in/yaml.v3\"\n)\n\nvar limitTests = []struct {\n\tname  string\n\tdata  []byte\n\terror string\n}{\n\t{\n\t\tname:  \"1000kb of maps with 100 aliases\",\n\t\tdata:  []byte(`{a: &a [{a}` + strings.Repeat(`,{a}`, 1000*1024/4-100) + `], b: &b [*a` + strings.Repeat(`,*a`, 99) + `]}`),\n\t\terror: \"yaml: document contains excessive aliasing\",\n\t}, {\n\t\tname:  \"1000kb of deeply nested slices\",\n\t\tdata:  []byte(strings.Repeat(`[`, 1000*1024)),\n\t\terror: \"yaml: exceeded max depth of 10000\",\n\t}, {\n\t\tname:  \"1000kb of deeply nested maps\",\n\t\tdata:  []byte(\"x: \" + strings.Repeat(`{`, 1000*1024)),\n\t\terror: \"yaml: exceeded max depth of 10000\",\n\t}, {\n\t\tname:  \"1000kb of deeply nested indents\",\n\t\tdata:  []byte(strings.Repeat(`- `, 1000*1024)),\n\t\terror: \"yaml: exceeded max depth of 10000\",\n\t}, {\n\t\tname: \"1000kb of 1000-indent lines\",\n\t\tdata: []byte(strings.Repeat(strings.Repeat(`- `, 1000)+\"\\n\", 1024/2)),\n\t},\n\t{name: \"1kb of maps\", data: []byte(`a: &a [{a}` + strings.Repeat(`,{a}`, 1*1024/4-1) + `]`)},\n\t{name: \"10kb of maps\", data: []byte(`a: &a [{a}` + strings.Repeat(`,{a}`, 10*1024/4-1) + `]`)},\n\t{name: \"100kb of maps\", data: []byte(`a: &a [{a}` + strings.Repeat(`,{a}`, 100*1024/4-1) + `]`)},\n\t{name: \"1000kb of maps\", data: []byte(`a: &a [{a}` + strings.Repeat(`,{a}`, 1000*1024/4-1) + `]`)},\n\t{name: \"1000kb slice nested at max-depth\", data: []byte(strings.Repeat(`[`, 10000) + `1` + strings.Repeat(`,1`, 1000*1024/2-20000-1) + strings.Repeat(`]`, 10000))},\n\t{name: \"1000kb slice nested in maps at max-depth\", data: []byte(\"{a,b:\\n\" + strings.Repeat(\" {a,b:\", 10000-2) + ` [1` + strings.Repeat(\",1\", 1000*1024/2-6*10000-1) + `]` + strings.Repeat(`}`, 10000-1))},\n\t{name: \"1000kb of 10000-nested lines\", data: []byte(strings.Repeat(`- `+strings.Repeat(`[`, 10000)+strings.Repeat(`]`, 10000)+\"\\n\", 1000*1024/20000))},\n}\n\nfunc (s *S) TestLimits(c *C) {\n\tif testing.Short() {\n\t\treturn\n\t}\n\tfor _, tc := range limitTests {\n\t\tvar v interface{}\n\t\terr := yaml.Unmarshal(tc.data, &v)\n\t\tif len(tc.error) > 0 {\n\t\t\tc.Assert(err, ErrorMatches, tc.error, Commentf(\"testcase: %s\", tc.name))\n\t\t} else {\n\t\t\tc.Assert(err, IsNil, Commentf(\"testcase: %s\", tc.name))\n\t\t}\n\t}\n}\n\nfunc Benchmark1000KB100Aliases(b *testing.B) {\n\tbenchmark(b, \"1000kb of maps with 100 aliases\")\n}\nfunc Benchmark1000KBDeeplyNestedSlices(b *testing.B) {\n\tbenchmark(b, \"1000kb of deeply nested slices\")\n}\nfunc Benchmark1000KBDeeplyNestedMaps(b *testing.B) {\n\tbenchmark(b, \"1000kb of deeply nested maps\")\n}\nfunc Benchmark1000KBDeeplyNestedIndents(b *testing.B) {\n\tbenchmark(b, \"1000kb of deeply nested indents\")\n}\nfunc Benchmark1000KB1000IndentLines(b *testing.B) {\n\tbenchmark(b, \"1000kb of 1000-indent lines\")\n}\nfunc Benchmark1KBMaps(b *testing.B) {\n\tbenchmark(b, \"1kb of maps\")\n}\nfunc Benchmark10KBMaps(b *testing.B) {\n\tbenchmark(b, \"10kb of maps\")\n}\nfunc Benchmark100KBMaps(b *testing.B) {\n\tbenchmark(b, \"100kb of maps\")\n}\nfunc Benchmark1000KBMaps(b *testing.B) {\n\tbenchmark(b, \"1000kb of maps\")\n}\n\nfunc BenchmarkDeepSlice(b *testing.B) {\n\tbenchmark(b, \"1000kb slice nested at max-depth\")\n}\n\nfunc BenchmarkDeepFlow(b *testing.B) {\n\tbenchmark(b, \"1000kb slice nested in maps at max-depth\")\n}\n\nfunc Benchmark1000KBMaxDepthNested(b *testing.B) {\n\tbenchmark(b, \"1000kb of 10000-nested lines\")\n}\n\nfunc benchmark(b *testing.B, name string) {\n\tfor _, t := range limitTests {\n\t\tif t.name != name {\n\t\t\tcontinue\n\t\t}\n\n\t\tb.ResetTimer()\n\n\t\tfor i := 0; i < b.N; i++ {\n\t\t\tvar v interface{}\n\t\t\terr := yaml.Unmarshal(t.data, &v)\n\t\t\tif len(t.error) > 0 {\n\t\t\t\tif err == nil {\n\t\t\t\t\tb.Errorf(\"expected error, got none\")\n\t\t\t\t} else if err.Error() != t.error {\n\t\t\t\t\tb.Errorf(\"expected error '%s', got '%s'\", t.error, err.Error())\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif err != nil {\n\t\t\t\t\tb.Errorf(\"unexpected error: %v\", err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn\n\t}\n\n\tb.Errorf(\"testcase %q not found\", name)\n}\n"
        },
        {
          "name": "node_test.go",
          "type": "blob",
          "size": 61.7822265625,
          "content": "//\n// Copyright (c) 2011-2019 Canonical Ltd\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage yaml_test\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"os\"\n\n\t. \"gopkg.in/check.v1\"\n\t\"gopkg.in/yaml.v3\"\n\t\"io\"\n\t\"strings\"\n)\n\nvar nodeTests = []struct {\n\tyaml string\n\tnode yaml.Node\n}{\n\t{\n\t\t\"null\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\tValue:  \"null\",\n\t\t\t\tTag:    \"!!null\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"[encode]null\\n\",\n\t\tyaml.Node{},\n\t}, {\n\t\t\"foo\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\tValue:  \"foo\",\n\t\t\t\tTag:    \"!!str\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"\\\"foo\\\"\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\tStyle:  yaml.DoubleQuotedStyle,\n\t\t\t\tValue:  \"foo\",\n\t\t\t\tTag:    \"!!str\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"'foo'\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\tStyle:  yaml.SingleQuotedStyle,\n\t\t\t\tValue:  \"foo\",\n\t\t\t\tTag:    \"!!str\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"!!str 123\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\tStyle:  yaml.TaggedStyle,\n\t\t\t\tValue:  \"123\",\n\t\t\t\tTag:    \"!!str\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t// Although the node isn't TaggedStyle, dropping the tag would change the value.\n\t\t\"[encode]!!binary gIGC\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\tValue:  \"gIGC\",\n\t\t\t\tTag:    \"!!binary\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t// Item doesn't have a tag, but needs to be binary encoded due to its content.\n\t\t\"[encode]!!binary gIGC\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\tValue:  \"\\x80\\x81\\x82\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t// Same, but with strings we can just quote them.\n\t\t\"[encode]\\\"123\\\"\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\tValue:  \"123\",\n\t\t\t\tTag:    \"!!str\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"!tag:something 123\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\tStyle:  yaml.TaggedStyle,\n\t\t\t\tValue:  \"123\",\n\t\t\t\tTag:    \"!tag:something\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"[encode]!tag:something 123\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\tValue:  \"123\",\n\t\t\t\tTag:    \"!tag:something\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"!tag:something {}\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tStyle:  yaml.TaggedStyle | yaml.FlowStyle,\n\t\t\t\tTag:    \"!tag:something\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"[encode]!tag:something {}\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tStyle:  yaml.FlowStyle,\n\t\t\t\tTag:    \"!tag:something\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"!tag:something []\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\tStyle:  yaml.TaggedStyle | yaml.FlowStyle,\n\t\t\t\tTag:    \"!tag:something\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"[encode]!tag:something []\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\tStyle:  yaml.FlowStyle,\n\t\t\t\tTag:    \"!tag:something\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"''\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\tStyle:  yaml.SingleQuotedStyle,\n\t\t\t\tValue:  \"\",\n\t\t\t\tTag:    \"!!str\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"|\\n  foo\\n  bar\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\tStyle:  yaml.LiteralStyle,\n\t\t\t\tValue:  \"foo\\nbar\\n\",\n\t\t\t\tTag:    \"!!str\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"true\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\tValue:  \"true\",\n\t\t\t\tTag:    \"!!bool\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"-10\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\tValue:  \"-10\",\n\t\t\t\tTag:    \"!!int\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"4294967296\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\tValue:  \"4294967296\",\n\t\t\t\tTag:    \"!!int\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"0.1000\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\tValue:  \"0.1000\",\n\t\t\t\tTag:    \"!!float\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"-.inf\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\tValue:  \"-.inf\",\n\t\t\t\tTag:    \"!!float\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\".nan\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\tValue:  \".nan\",\n\t\t\t\tTag:    \"!!float\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"{}\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tStyle:  yaml.FlowStyle,\n\t\t\t\tValue:  \"\",\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"a: b c\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tValue:  \"\",\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tValue:  \"a\",\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tLine:   1,\n\t\t\t\t\tColumn: 1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tValue:  \"b c\",\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tLine:   1,\n\t\t\t\t\tColumn: 4,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"a:\\n  b: c\\n  d: e\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tValue:  \"a\",\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tLine:   1,\n\t\t\t\t\tColumn: 1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\tLine:   2,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tValue:  \"b\",\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\tColumn: 3,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tValue:  \"c\",\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\tColumn: 6,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tValue:  \"d\",\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tLine:   3,\n\t\t\t\t\t\tColumn: 3,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tValue:  \"e\",\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tLine:   3,\n\t\t\t\t\t\tColumn: 6,\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"a:\\n  - b: c\\n    d: e\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tValue:  \"a\",\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tLine:   1,\n\t\t\t\t\tColumn: 1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\t\tTag:    \"!!seq\",\n\t\t\t\t\tLine:   2,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\t\tValue:  \"b\",\n\t\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t}, {\n\t\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\t\tValue:  \"c\",\n\t\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\t\tColumn: 8,\n\t\t\t\t\t\t}, {\n\t\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\t\tValue:  \"d\",\n\t\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\t\tLine:   3,\n\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t}, {\n\t\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\t\tValue:  \"e\",\n\t\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\t\tLine:   3,\n\t\t\t\t\t\t\tColumn: 8,\n\t\t\t\t\t\t}},\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"a: # AI\\n  - b\\nc:\\n  - d\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"a\",\n\t\t\t\t\tLineComment: \"# AI\",\n\t\t\t\t\tLine:        1,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t}, {\n\t\t\t\t\tKind: yaml.SequenceNode,\n\t\t\t\t\tTag:  \"!!seq\",\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"b\",\n\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t}},\n\t\t\t\t\tLine:   2,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tValue:  \"c\",\n\t\t\t\t\tLine:   3,\n\t\t\t\t\tColumn: 1,\n\t\t\t\t}, {\n\t\t\t\t\tKind: yaml.SequenceNode,\n\t\t\t\t\tTag:  \"!!seq\",\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"d\",\n\t\t\t\t\t\tLine:   4,\n\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t}},\n\t\t\t\t\tLine:   4,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"[decode]a:\\n  # HM\\n  - # HB1\\n    # HB2\\n    b: # IB\\n      c # IC\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tStyle:  0x0,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tValue:  \"a\",\n\t\t\t\t\tLine:   1,\n\t\t\t\t\tColumn: 1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\t\tTag:    \"!!seq\",\n\t\t\t\t\tLine:   3,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:        yaml.MappingNode,\n\t\t\t\t\t\tTag:         \"!!map\",\n\t\t\t\t\t\tHeadComment: \"# HM\",\n\t\t\t\t\t\tLine:        5,\n\t\t\t\t\t\tColumn:      5,\n\t\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\t\tValue:       \"b\",\n\t\t\t\t\t\t\tHeadComment: \"# HB1\\n# HB2\",\n\t\t\t\t\t\t\tLineComment: \"# IB\",\n\t\t\t\t\t\t\tLine:        5,\n\t\t\t\t\t\t\tColumn:      5,\n\t\t\t\t\t\t}, {\n\t\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\t\tValue:       \"c\",\n\t\t\t\t\t\t\tLineComment: \"# IC\",\n\t\t\t\t\t\t\tLine:        6,\n\t\t\t\t\t\t\tColumn:      7,\n\t\t\t\t\t\t}},\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t// When encoding the value above, it loses b's inline comment.\n\t\t\"[encode]a:\\n  # HM\\n  - # HB1\\n    # HB2\\n    b: c # IC\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tStyle:  0x0,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tValue:  \"a\",\n\t\t\t\t\tLine:   1,\n\t\t\t\t\tColumn: 1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\t\tTag:    \"!!seq\",\n\t\t\t\t\tLine:   3,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:        yaml.MappingNode,\n\t\t\t\t\t\tTag:         \"!!map\",\n\t\t\t\t\t\tHeadComment: \"# HM\",\n\t\t\t\t\t\tLine:        5,\n\t\t\t\t\t\tColumn:      5,\n\t\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\t\tValue:       \"b\",\n\t\t\t\t\t\t\tHeadComment: \"# HB1\\n# HB2\",\n\t\t\t\t\t\t\tLineComment: \"# IB\",\n\t\t\t\t\t\t\tLine:        5,\n\t\t\t\t\t\t\tColumn:      5,\n\t\t\t\t\t\t}, {\n\t\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\t\tValue:       \"c\",\n\t\t\t\t\t\t\tLineComment: \"# IC\",\n\t\t\t\t\t\t\tLine:        6,\n\t\t\t\t\t\t\tColumn:      7,\n\t\t\t\t\t\t}},\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t// Multiple cases of comment inlining next to mapping keys.\n\t\t\"a: | # IA\\n  str\\nb: >- # IB\\n  str\\nc: # IC\\n  - str\\nd: # ID\\n  str:\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tValue:  \"a\",\n\t\t\t\t\tLine:   1,\n\t\t\t\t\tColumn: 1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tStyle:       yaml.LiteralStyle,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"str\\n\",\n\t\t\t\t\tLineComment: \"# IA\",\n\t\t\t\t\tLine:        1,\n\t\t\t\t\tColumn:      4,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tValue:  \"b\",\n\t\t\t\t\tLine:   3,\n\t\t\t\t\tColumn: 1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tStyle:       yaml.FoldedStyle,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"str\",\n\t\t\t\t\tLineComment: \"# IB\",\n\t\t\t\t\tLine:        3,\n\t\t\t\t\tColumn:      4,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tValue:  \"c\",\n\t\t\t\t\tLineComment: \"# IC\",\n\t\t\t\t\tLine:   5,\n\t\t\t\t\tColumn: 1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.SequenceNode,\n\t\t\t\t\tTag:         \"!!seq\",\n\t\t\t\t\tLine:        6,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"str\",\n\t\t\t\t\t\tLine:   6,\n\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t}},\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tValue:  \"d\",\n\t\t\t\t\tLineComment: \"# ID\",\n\t\t\t\t\tLine:   7,\n\t\t\t\t\tColumn: 1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.MappingNode,\n\t\t\t\t\tTag:         \"!!map\",\n\t\t\t\t\tLine:        8,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"str\",\n\t\t\t\t\t\tLine:   8,\n\t\t\t\t\t\tColumn: 3,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!null\",\n\t\t\t\t\t\tLine:   8,\n\t\t\t\t\t\tColumn: 7,\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t// Indentless sequence.\n\t\t\"[decode]a:\\n# HM\\n- # HB1\\n  # HB2\\n  b: # IB\\n    c # IC\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tValue:  \"a\",\n\t\t\t\t\tLine:   1,\n\t\t\t\t\tColumn: 1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\t\tTag:    \"!!seq\",\n\t\t\t\t\tLine:   3,\n\t\t\t\t\tColumn: 1,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:        yaml.MappingNode,\n\t\t\t\t\t\tTag:         \"!!map\",\n\t\t\t\t\t\tHeadComment: \"# HM\",\n\t\t\t\t\t\tLine:        5,\n\t\t\t\t\t\tColumn:      3,\n\t\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\t\tValue:       \"b\",\n\t\t\t\t\t\t\tHeadComment: \"# HB1\\n# HB2\",\n\t\t\t\t\t\t\tLineComment: \"# IB\",\n\t\t\t\t\t\t\tLine:        5,\n\t\t\t\t\t\t\tColumn:      3,\n\t\t\t\t\t\t}, {\n\t\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\t\tValue:       \"c\",\n\t\t\t\t\t\t\tLineComment: \"# IC\",\n\t\t\t\t\t\t\tLine:        6,\n\t\t\t\t\t\t\tColumn:      5,\n\t\t\t\t\t\t}},\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"- a\\n- b\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\tValue:  \"\",\n\t\t\t\tTag:    \"!!seq\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tValue:  \"a\",\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tLine:   1,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tValue:  \"b\",\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tLine:   2,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"- a\\n- - b\\n  - c\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\tTag:    \"!!seq\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tValue:  \"a\",\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tLine:   1,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\t\tTag:    \"!!seq\",\n\t\t\t\t\tLine:   2,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tValue:  \"b\",\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tValue:  \"c\",\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tLine:   3,\n\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"[a, b]\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\tStyle:  yaml.FlowStyle,\n\t\t\t\tValue:  \"\",\n\t\t\t\tTag:    \"!!seq\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tValue:  \"a\",\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tLine:   1,\n\t\t\t\t\tColumn: 2,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tValue:  \"b\",\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tLine:   1,\n\t\t\t\t\tColumn: 5,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"- a\\n- [b, c]\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\tTag:    \"!!seq\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tValue:  \"a\",\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tLine:   1,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\t\tTag:    \"!!seq\",\n\t\t\t\t\tStyle:  yaml.FlowStyle,\n\t\t\t\t\tLine:   2,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tValue:  \"b\",\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\tColumn: 4,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tValue:  \"c\",\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\tColumn: 7,\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"a: &x 1\\nb: &y 2\\nc: *x\\nd: *y\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tValue:  \"a\",\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tLine:   1,\n\t\t\t\t\tColumn: 1,\n\t\t\t\t},\n\t\t\t\t\tsaveNode(\"x\", &yaml.Node{\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tValue:  \"1\",\n\t\t\t\t\t\tTag:    \"!!int\",\n\t\t\t\t\t\tAnchor: \"x\",\n\t\t\t\t\t\tLine:   1,\n\t\t\t\t\t\tColumn: 4,\n\t\t\t\t\t}),\n\t\t\t\t\t{\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tValue:  \"b\",\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t},\n\t\t\t\t\tsaveNode(\"y\", &yaml.Node{\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tValue:  \"2\",\n\t\t\t\t\t\tTag:    \"!!int\",\n\t\t\t\t\t\tAnchor: \"y\",\n\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\tColumn: 4,\n\t\t\t\t\t}),\n\t\t\t\t\t{\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tValue:  \"c\",\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tLine:   3,\n\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.AliasNode,\n\t\t\t\t\t\tValue:  \"x\",\n\t\t\t\t\t\tAlias:  dropNode(\"x\"),\n\t\t\t\t\t\tLine:   3,\n\t\t\t\t\t\tColumn: 4,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tValue:  \"d\",\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tLine:   4,\n\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.AliasNode,\n\t\t\t\t\t\tValue:  \"y\",\n\t\t\t\t\t\tTag:    \"\",\n\t\t\t\t\t\tAlias:  dropNode(\"y\"),\n\t\t\t\t\t\tLine:   4,\n\t\t\t\t\t\tColumn: 4,\n\t\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\n\t\t\"# One\\n# Two\\ntrue # Three\\n# Four\\n# Five\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   3,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\tValue:       \"true\",\n\t\t\t\tTag:         \"!!bool\",\n\t\t\t\tLine:        3,\n\t\t\t\tColumn:      1,\n\t\t\t\tHeadComment: \"# One\\n# Two\",\n\t\t\t\tLineComment: \"# Three\",\n\t\t\t\tFootComment: \"# Four\\n# Five\",\n\t\t\t}},\n\t\t},\n\t}, {\n\n\t\t\"# \\ntrue # \\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   2,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\tValue:       \"true\",\n\t\t\t\tTag:         \"!!bool\",\n\t\t\t\tLine:        2,\n\t\t\t\tColumn:      1,\n\t\t\t\tHeadComment: \"# \",\n\t\t\t\tLineComment: \"# \",\n\t\t\t}},\n\t\t},\n\t}, {\n\n\t\t\"[decode]\\n# One\\n\\n# Two\\n\\n# Three\\ntrue # Four\\n# Five\\n\\n# Six\\n\\n# Seven\\n\",\n\t\tyaml.Node{\n\t\t\tKind:        yaml.DocumentNode,\n\t\t\tLine:        7,\n\t\t\tColumn:      1,\n\t\t\tHeadComment: \"# One\\n\\n# Two\",\n\t\t\tFootComment: \"# Six\\n\\n# Seven\",\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\tValue:       \"true\",\n\t\t\t\tTag:         \"!!bool\",\n\t\t\t\tLine:        7,\n\t\t\t\tColumn:      1,\n\t\t\t\tHeadComment: \"# Three\",\n\t\t\t\tLineComment: \"# Four\",\n\t\t\t\tFootComment: \"# Five\",\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t// Write out the pound character if missing from comments.\n\t\t\"[encode]# One\\n# Two\\ntrue # Three\\n# Four\\n# Five\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   3,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\tValue:       \"true\",\n\t\t\t\tTag:         \"!!bool\",\n\t\t\t\tLine:        3,\n\t\t\t\tColumn:      1,\n\t\t\t\tHeadComment: \"One\\nTwo\\n\",\n\t\t\t\tLineComment: \"Three\\n\",\n\t\t\t\tFootComment: \"Four\\nFive\\n\",\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"[encode]#   One\\n#   Two\\ntrue #   Three\\n#   Four\\n#   Five\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   3,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\tValue:       \"true\",\n\t\t\t\tTag:         \"!!bool\",\n\t\t\t\tLine:        3,\n\t\t\t\tColumn:      1,\n\t\t\t\tHeadComment: \"  One\\n  Two\",\n\t\t\t\tLineComment: \"  Three\",\n\t\t\t\tFootComment: \"  Four\\n  Five\",\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"# DH1\\n\\n# DH2\\n\\n# H1\\n# H2\\ntrue # I\\n# F1\\n# F2\\n\\n# DF1\\n\\n# DF2\\n\",\n\t\tyaml.Node{\n\t\t\tKind:        yaml.DocumentNode,\n\t\t\tLine:        7,\n\t\t\tColumn:      1,\n\t\t\tHeadComment: \"# DH1\\n\\n# DH2\",\n\t\t\tFootComment: \"# DF1\\n\\n# DF2\",\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\tValue:       \"true\",\n\t\t\t\tTag:         \"!!bool\",\n\t\t\t\tLine:        7,\n\t\t\t\tColumn:      1,\n\t\t\t\tHeadComment: \"# H1\\n# H2\",\n\t\t\t\tLineComment: \"# I\",\n\t\t\t\tFootComment: \"# F1\\n# F2\",\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"# DH1\\n\\n# DH2\\n\\n# HA1\\n# HA2\\nka: va # IA\\n# FA1\\n# FA2\\n\\n# HB1\\n# HB2\\nkb: vb # IB\\n# FB1\\n# FB2\\n\\n# DF1\\n\\n# DF2\\n\",\n\t\tyaml.Node{\n\t\t\tKind:        yaml.DocumentNode,\n\t\t\tLine:        7,\n\t\t\tColumn:      1,\n\t\t\tHeadComment: \"# DH1\\n\\n# DH2\",\n\t\t\tFootComment: \"# DF1\\n\\n# DF2\",\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   7,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tLine:        7,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"ka\",\n\t\t\t\t\tHeadComment: \"# HA1\\n# HA2\",\n\t\t\t\t\tFootComment: \"# FA1\\n# FA2\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tLine:        7,\n\t\t\t\t\tColumn:      5,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"va\",\n\t\t\t\t\tLineComment: \"# IA\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tLine:        13,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"kb\",\n\t\t\t\t\tHeadComment: \"# HB1\\n# HB2\",\n\t\t\t\t\tFootComment: \"# FB1\\n# FB2\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tLine:        13,\n\t\t\t\t\tColumn:      5,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"vb\",\n\t\t\t\t\tLineComment: \"# IB\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"# DH1\\n\\n# DH2\\n\\n# HA1\\n# HA2\\n- la # IA\\n# FA1\\n# FA2\\n\\n# HB1\\n# HB2\\n- lb # IB\\n# FB1\\n# FB2\\n\\n# DF1\\n\\n# DF2\\n\",\n\t\tyaml.Node{\n\t\t\tKind:        yaml.DocumentNode,\n\t\t\tLine:        7,\n\t\t\tColumn:      1,\n\t\t\tHeadComment: \"# DH1\\n\\n# DH2\",\n\t\t\tFootComment: \"# DF1\\n\\n# DF2\",\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\tTag:    \"!!seq\",\n\t\t\t\tLine:   7,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        7,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tValue:       \"la\",\n\t\t\t\t\tHeadComment: \"# HA1\\n# HA2\",\n\t\t\t\t\tLineComment: \"# IA\",\n\t\t\t\t\tFootComment: \"# FA1\\n# FA2\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        13,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tValue:       \"lb\",\n\t\t\t\t\tHeadComment: \"# HB1\\n# HB2\",\n\t\t\t\t\tLineComment: \"# IB\",\n\t\t\t\t\tFootComment: \"# FB1\\n# FB2\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"# DH1\\n\\n- la # IA\\n# HB1\\n- lb\\n\",\n\t\tyaml.Node{\n\t\t\tKind:        yaml.DocumentNode,\n\t\t\tLine:        3,\n\t\t\tColumn:      1,\n\t\t\tHeadComment: \"# DH1\",\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\tTag:    \"!!seq\",\n\t\t\t\tLine:   3,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        3,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tValue:       \"la\",\n\t\t\t\t\tLineComment: \"# IA\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        5,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tValue:       \"lb\",\n\t\t\t\t\tHeadComment: \"# HB1\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"- la # IA\\n- lb # IB\\n- lc # IC\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\tTag:    \"!!seq\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        1,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tValue:       \"la\",\n\t\t\t\t\tLineComment: \"# IA\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        2,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tValue:       \"lb\",\n\t\t\t\t\tLineComment: \"# IB\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        3,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tValue:       \"lc\",\n\t\t\t\t\tLineComment: \"# IC\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"# DH1\\n\\n# HL1\\n- - la\\n  # HB1\\n  - lb\\n\",\n\t\tyaml.Node{\n\t\t\tKind:        yaml.DocumentNode,\n\t\t\tLine:        4,\n\t\t\tColumn:      1,\n\t\t\tHeadComment: \"# DH1\",\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\tTag:    \"!!seq\",\n\t\t\t\tLine:   4,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.SequenceNode,\n\t\t\t\t\tTag:         \"!!seq\",\n\t\t\t\t\tLine:        4,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tHeadComment: \"# HL1\",\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tLine:   4,\n\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\tValue:  \"la\",\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\tLine:        6,\n\t\t\t\t\t\tColumn:      5,\n\t\t\t\t\t\tValue:       \"lb\",\n\t\t\t\t\t\tHeadComment: \"# HB1\",\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"# DH1\\n\\n# HL1\\n- # HA1\\n  - la\\n  # HB1\\n  - lb\\n\",\n\t\tyaml.Node{\n\t\t\tKind:        yaml.DocumentNode,\n\t\t\tLine:        4,\n\t\t\tColumn:      1,\n\t\t\tHeadComment: \"# DH1\",\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\tTag:    \"!!seq\",\n\t\t\t\tLine:   4,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.SequenceNode,\n\t\t\t\t\tTag:         \"!!seq\",\n\t\t\t\t\tLine:        5,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tHeadComment: \"# HL1\",\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\tLine:        5,\n\t\t\t\t\t\tColumn:      5,\n\t\t\t\t\t\tValue:       \"la\",\n\t\t\t\t\t\tHeadComment: \"# HA1\",\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\tLine:        7,\n\t\t\t\t\t\tColumn:      5,\n\t\t\t\t\t\tValue:       \"lb\",\n\t\t\t\t\t\tHeadComment: \"# HB1\",\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"[decode]# DH1\\n\\n# HL1\\n- # HA1\\n\\n  - la\\n  # HB1\\n  - lb\\n\",\n\t\tyaml.Node{\n\t\t\tKind:        yaml.DocumentNode,\n\t\t\tLine:        4,\n\t\t\tColumn:      1,\n\t\t\tHeadComment: \"# DH1\",\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\tTag:    \"!!seq\",\n\t\t\t\tLine:   4,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.SequenceNode,\n\t\t\t\t\tTag:         \"!!seq\",\n\t\t\t\t\tLine:        6,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tHeadComment: \"# HL1\",\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\tLine:        6,\n\t\t\t\t\t\tColumn:      5,\n\t\t\t\t\t\tValue:       \"la\",\n\t\t\t\t\t\tHeadComment: \"# HA1\\n\",\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\tLine:        8,\n\t\t\t\t\t\tColumn:      5,\n\t\t\t\t\t\tValue:       \"lb\",\n\t\t\t\t\t\tHeadComment: \"# HB1\",\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"# DH1\\n\\n# HA1\\nka:\\n  # HB1\\n  kb:\\n    # HC1\\n    # HC2\\n    - lc # IC\\n    # FC1\\n    # FC2\\n\\n    # HD1\\n    - ld # ID\\n    # FD1\\n\\n# DF1\\n\",\n\t\tyaml.Node{\n\t\t\tKind:        yaml.DocumentNode,\n\t\t\tLine:        4,\n\t\t\tColumn:      1,\n\t\t\tHeadComment: \"# DH1\",\n\t\t\tFootComment: \"# DF1\",\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   4,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        4,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t\tValue:       \"ka\",\n\t\t\t\t\tHeadComment: \"# HA1\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\tLine:   6,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\tLine:        6,\n\t\t\t\t\t\tColumn:      3,\n\t\t\t\t\t\tValue:       \"kb\",\n\t\t\t\t\t\tHeadComment: \"# HB1\",\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\t\t\tLine:   9,\n\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\tTag:    \"!!seq\",\n\t\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\t\tLine:        9,\n\t\t\t\t\t\t\tColumn:      7,\n\t\t\t\t\t\t\tValue:       \"lc\",\n\t\t\t\t\t\t\tHeadComment: \"# HC1\\n# HC2\",\n\t\t\t\t\t\t\tLineComment: \"# IC\",\n\t\t\t\t\t\t\tFootComment: \"# FC1\\n# FC2\",\n\t\t\t\t\t\t}, {\n\t\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\t\tLine:        14,\n\t\t\t\t\t\t\tColumn:      7,\n\t\t\t\t\t\t\tValue:       \"ld\",\n\t\t\t\t\t\t\tHeadComment: \"# HD1\",\n\n\t\t\t\t\t\t\tLineComment: \"# ID\",\n\t\t\t\t\t\t\tFootComment: \"# FD1\",\n\t\t\t\t\t\t}},\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"# DH1\\n\\n# HA1\\nka:\\n  # HB1\\n  kb:\\n    # HC1\\n    # HC2\\n    - lc # IC\\n    # FC1\\n    # FC2\\n\\n    # HD1\\n    - ld # ID\\n    # FD1\\nke: ve\\n\\n# DF1\\n\",\n\t\tyaml.Node{\n\t\t\tKind:        yaml.DocumentNode,\n\t\t\tLine:        4,\n\t\t\tColumn:      1,\n\t\t\tHeadComment: \"# DH1\",\n\t\t\tFootComment: \"# DF1\",\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   4,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        4,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t\tValue:       \"ka\",\n\t\t\t\t\tHeadComment: \"# HA1\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\tLine:   6,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\tLine:        6,\n\t\t\t\t\t\tColumn:      3,\n\t\t\t\t\t\tValue:       \"kb\",\n\t\t\t\t\t\tHeadComment: \"# HB1\",\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\t\t\tLine:   9,\n\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\tTag:    \"!!seq\",\n\t\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\t\tLine:        9,\n\t\t\t\t\t\t\tColumn:      7,\n\t\t\t\t\t\t\tValue:       \"lc\",\n\t\t\t\t\t\t\tHeadComment: \"# HC1\\n# HC2\",\n\t\t\t\t\t\t\tLineComment: \"# IC\",\n\t\t\t\t\t\t\tFootComment: \"# FC1\\n# FC2\",\n\t\t\t\t\t\t}, {\n\t\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\t\tLine:        14,\n\t\t\t\t\t\t\tColumn:      7,\n\t\t\t\t\t\t\tValue:       \"ld\",\n\t\t\t\t\t\t\tHeadComment: \"# HD1\",\n\t\t\t\t\t\t\tLineComment: \"# ID\",\n\t\t\t\t\t\t\tFootComment: \"# FD1\",\n\t\t\t\t\t\t}},\n\t\t\t\t\t}},\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tLine:   16,\n\t\t\t\t\tColumn: 1,\n\t\t\t\t\tValue:  \"ke\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tLine:   16,\n\t\t\t\t\tColumn: 5,\n\t\t\t\t\tValue:  \"ve\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"# DH1\\n\\n# DH2\\n\\n# HA1\\n# HA2\\nka:\\n  # HB1\\n  # HB2\\n  kb:\\n\" +\n\t\t\t\"    # HC1\\n    # HC2\\n    kc:\\n      # HD1\\n      # HD2\\n      kd: vd\\n      # FD1\\n      # FD2\\n\" +\n\t\t\t\"    # FC1\\n    # FC2\\n  # FB1\\n  # FB2\\n# FA1\\n# FA2\\n\\n# HE1\\n# HE2\\nke: ve\\n# FE1\\n# FE2\\n\\n# DF1\\n\\n# DF2\\n\",\n\t\tyaml.Node{\n\t\t\tKind:        yaml.DocumentNode,\n\t\t\tHeadComment: \"# DH1\\n\\n# DH2\",\n\t\t\tFootComment: \"# DF1\\n\\n# DF2\",\n\t\t\tLine:        7,\n\t\t\tColumn:      1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   7,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"ka\",\n\t\t\t\t\tHeadComment: \"# HA1\\n# HA2\",\n\t\t\t\t\tFootComment: \"# FA1\\n# FA2\",\n\t\t\t\t\tLine:        7,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\tLine:   10,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\tValue:       \"kb\",\n\t\t\t\t\t\tHeadComment: \"# HB1\\n# HB2\",\n\t\t\t\t\t\tFootComment: \"# FB1\\n# FB2\",\n\t\t\t\t\t\tLine:        10,\n\t\t\t\t\t\tColumn:      3,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\t\tLine:   13,\n\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\t\tValue:       \"kc\",\n\t\t\t\t\t\t\tHeadComment: \"# HC1\\n# HC2\",\n\t\t\t\t\t\t\tFootComment: \"# FC1\\n# FC2\",\n\t\t\t\t\t\t\tLine:        13,\n\t\t\t\t\t\t\tColumn:      5,\n\t\t\t\t\t\t}, {\n\t\t\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\tColumn: 7,\n\t\t\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\t\t\tValue:       \"kd\",\n\t\t\t\t\t\t\t\tHeadComment: \"# HD1\\n# HD2\",\n\t\t\t\t\t\t\t\tFootComment: \"# FD1\\n# FD2\",\n\t\t\t\t\t\t\t\tLine:        16,\n\t\t\t\t\t\t\t\tColumn:      7,\n\t\t\t\t\t\t\t}, {\n\t\t\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\t\t\tValue:  \"vd\",\n\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\tColumn: 11,\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t}},\n\t\t\t\t\t}},\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"ke\",\n\t\t\t\t\tHeadComment: \"# HE1\\n# HE2\",\n\t\t\t\t\tFootComment: \"# FE1\\n# FE2\",\n\t\t\t\t\tLine:        28,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tValue:  \"ve\",\n\t\t\t\t\tLine:   28,\n\t\t\t\t\tColumn: 5,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t// Same as above but indenting ke in so it's also part of ka's value.\n\t\t\"# DH1\\n\\n# DH2\\n\\n# HA1\\n# HA2\\nka:\\n  # HB1\\n  # HB2\\n  kb:\\n\" +\n\t\t\t\"    # HC1\\n    # HC2\\n    kc:\\n      # HD1\\n      # HD2\\n      kd: vd\\n      # FD1\\n      # FD2\\n\" +\n\t\t\t\"    # FC1\\n    # FC2\\n  # FB1\\n  # FB2\\n\\n  # HE1\\n  # HE2\\n  ke: ve\\n  # FE1\\n  # FE2\\n# FA1\\n# FA2\\n\\n# DF1\\n\\n# DF2\\n\",\n\t\tyaml.Node{\n\t\t\tKind:        yaml.DocumentNode,\n\t\t\tHeadComment: \"# DH1\\n\\n# DH2\",\n\t\t\tFootComment: \"# DF1\\n\\n# DF2\",\n\t\t\tLine:        7,\n\t\t\tColumn:      1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   7,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"ka\",\n\t\t\t\t\tHeadComment: \"# HA1\\n# HA2\",\n\t\t\t\t\tFootComment: \"# FA1\\n# FA2\",\n\t\t\t\t\tLine:        7,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\tLine:   10,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\tValue:       \"kb\",\n\t\t\t\t\t\tHeadComment: \"# HB1\\n# HB2\",\n\t\t\t\t\t\tFootComment: \"# FB1\\n# FB2\",\n\t\t\t\t\t\tLine:        10,\n\t\t\t\t\t\tColumn:      3,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\t\tLine:   13,\n\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\t\tValue:       \"kc\",\n\t\t\t\t\t\t\tHeadComment: \"# HC1\\n# HC2\",\n\t\t\t\t\t\t\tFootComment: \"# FC1\\n# FC2\",\n\t\t\t\t\t\t\tLine:        13,\n\t\t\t\t\t\t\tColumn:      5,\n\t\t\t\t\t\t}, {\n\t\t\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\tColumn: 7,\n\t\t\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\t\t\tValue:       \"kd\",\n\t\t\t\t\t\t\t\tHeadComment: \"# HD1\\n# HD2\",\n\t\t\t\t\t\t\t\tFootComment: \"# FD1\\n# FD2\",\n\t\t\t\t\t\t\t\tLine:        16,\n\t\t\t\t\t\t\t\tColumn:      7,\n\t\t\t\t\t\t\t}, {\n\t\t\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\t\t\tValue:  \"vd\",\n\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\tColumn: 11,\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t}},\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\tValue:       \"ke\",\n\t\t\t\t\t\tHeadComment: \"# HE1\\n# HE2\",\n\t\t\t\t\t\tFootComment: \"# FE1\\n# FE2\",\n\t\t\t\t\t\tLine:        26,\n\t\t\t\t\t\tColumn:      3,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"ve\",\n\t\t\t\t\t\tLine:   26,\n\t\t\t\t\t\tColumn: 7,\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t// Decode only due to lack of newline at the end.\n\t\t\"[decode]# HA1\\nka:\\n  # HB1\\n  kb: vb\\n  # FB1\\n# FA1\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   2,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   2,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"ka\",\n\t\t\t\t\tHeadComment: \"# HA1\",\n\t\t\t\t\tFootComment: \"# FA1\",\n\t\t\t\t\tLine:        2,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\tLine:   4,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\tValue:       \"kb\",\n\t\t\t\t\t\tHeadComment: \"# HB1\",\n\t\t\t\t\t\tFootComment: \"# FB1\",\n\t\t\t\t\t\tLine:        4,\n\t\t\t\t\t\tColumn:      3,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"vb\",\n\t\t\t\t\t\tLine:   4,\n\t\t\t\t\t\tColumn: 7,\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t// Same as above, but with newline at the end.\n\t\t\"# HA1\\nka:\\n  # HB1\\n  kb: vb\\n  # FB1\\n# FA1\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   2,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   2,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"ka\",\n\t\t\t\t\tHeadComment: \"# HA1\",\n\t\t\t\t\tFootComment: \"# FA1\",\n\t\t\t\t\tLine:        2,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\tLine:   4,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\tValue:       \"kb\",\n\t\t\t\t\t\tHeadComment: \"# HB1\",\n\t\t\t\t\t\tFootComment: \"# FB1\",\n\t\t\t\t\t\tLine:        4,\n\t\t\t\t\t\tColumn:      3,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"vb\",\n\t\t\t\t\t\tLine:   4,\n\t\t\t\t\t\tColumn: 7,\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t// Same as above, but without FB1.\n\t\t\"# HA1\\nka:\\n  # HB1\\n  kb: vb\\n# FA1\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   2,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   2,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"ka\",\n\t\t\t\t\tHeadComment: \"# HA1\",\n\t\t\t\t\tFootComment: \"# FA1\",\n\t\t\t\t\tLine:        2,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\tLine:   4,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\tValue:       \"kb\",\n\t\t\t\t\t\tHeadComment: \"# HB1\",\n\t\t\t\t\t\tLine:        4,\n\t\t\t\t\t\tColumn:      3,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"vb\",\n\t\t\t\t\t\tLine:   4,\n\t\t\t\t\t\tColumn: 7,\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t// Same as above, but with two newlines at the end. Decode-only for that.\n\t\t\"[decode]# HA1\\nka:\\n  # HB1\\n  kb: vb\\n  # FB1\\n# FA1\\n\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   2,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   2,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"ka\",\n\t\t\t\t\tHeadComment: \"# HA1\",\n\t\t\t\t\tFootComment: \"# FA1\",\n\t\t\t\t\tLine:        2,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\tLine:   4,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\tValue:       \"kb\",\n\t\t\t\t\t\tHeadComment: \"# HB1\",\n\t\t\t\t\t\tFootComment: \"# FB1\",\n\t\t\t\t\t\tLine:        4,\n\t\t\t\t\t\tColumn:      3,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"vb\",\n\t\t\t\t\t\tLine:   4,\n\t\t\t\t\t\tColumn: 7,\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t// Similar to above, but make HB1 look more like a footer of ka.\n\t\t\"[decode]# HA1\\nka:\\n# HB1\\n\\n  kb: vb\\n# FA1\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   2,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   2,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"ka\",\n\t\t\t\t\tHeadComment: \"# HA1\",\n\t\t\t\t\tFootComment: \"# FA1\",\n\t\t\t\t\tLine:        2,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\tLine:   5,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\tValue:       \"kb\",\n\t\t\t\t\t\tHeadComment: \"# HB1\\n\",\n\t\t\t\t\t\tLine:        5,\n\t\t\t\t\t\tColumn:      3,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"vb\",\n\t\t\t\t\t\tLine:   5,\n\t\t\t\t\t\tColumn: 7,\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"ka:\\n  kb: vb\\n# FA1\\n\\nkc: vc\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"ka\",\n\t\t\t\t\tLine:        1,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t\tFootComment: \"# FA1\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\tLine:   2,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"kb\",\n\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\tColumn: 3,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"vb\",\n\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\tColumn: 7,\n\t\t\t\t\t}},\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tValue:  \"kc\",\n\t\t\t\t\tLine:   5,\n\t\t\t\t\tColumn: 1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tValue:  \"vc\",\n\t\t\t\t\tLine:   5,\n\t\t\t\t\tColumn: 5,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"ka:\\n  kb: vb\\n# HC1\\nkc: vc\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tValue:  \"ka\",\n\t\t\t\t\tLine:   1,\n\t\t\t\t\tColumn: 1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\tLine:   2,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"kb\",\n\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\tColumn: 3,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"vb\",\n\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\tColumn: 7,\n\t\t\t\t\t}},\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"kc\",\n\t\t\t\t\tHeadComment: \"# HC1\",\n\t\t\t\t\tLine:        4,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tValue:  \"vc\",\n\t\t\t\t\tLine:   4,\n\t\t\t\t\tColumn: 5,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t// Decode only due to empty line before HC1.\n\t\t\"[decode]ka:\\n  kb: vb\\n\\n# HC1\\nkc: vc\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tValue:  \"ka\",\n\t\t\t\t\tLine:   1,\n\t\t\t\t\tColumn: 1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\tLine:   2,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"kb\",\n\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\tColumn: 3,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"vb\",\n\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\tColumn: 7,\n\t\t\t\t\t}},\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"kc\",\n\t\t\t\t\tHeadComment: \"# HC1\",\n\t\t\t\t\tLine:        5,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tValue:  \"vc\",\n\t\t\t\t\tLine:   5,\n\t\t\t\t\tColumn: 5,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t// Decode-only due to empty lines around HC1.\n\t\t\"[decode]ka:\\n  kb: vb\\n\\n# HC1\\n\\nkc: vc\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tValue:  \"ka\",\n\t\t\t\t\tLine:   1,\n\t\t\t\t\tColumn: 1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\tLine:   2,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"kb\",\n\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\tColumn: 3,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"vb\",\n\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\tColumn: 7,\n\t\t\t\t\t}},\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"kc\",\n\t\t\t\t\tHeadComment: \"# HC1\\n\",\n\t\t\t\t\tLine:        6,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tValue:  \"vc\",\n\t\t\t\t\tLine:   6,\n\t\t\t\t\tColumn: 5,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"ka: # IA\\n  kb: # IB\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"ka\",\n\t\t\t\t\tLine:        1,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t\tLineComment: \"# IA\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\tLine:   2,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\tValue:       \"kb\",\n\t\t\t\t\t\tLine:        2,\n\t\t\t\t\t\tColumn:      3,\n\t\t\t\t\t\tLineComment: \"# IB\",\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!null\",\n\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\tColumn: 6,\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"# HA1\\nka:\\n  # HB1\\n  kb: vb\\n  # FB1\\n# HC1\\n# HC2\\nkc: vc\\n# FC1\\n# FC2\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   2,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   2,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"ka\",\n\t\t\t\t\tHeadComment: \"# HA1\",\n\t\t\t\t\tLine:        2,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\tLine:   4,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\tValue:       \"kb\",\n\t\t\t\t\t\tHeadComment: \"# HB1\",\n\t\t\t\t\t\tFootComment: \"# FB1\",\n\t\t\t\t\t\tLine:        4,\n\t\t\t\t\t\tColumn:      3,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"vb\",\n\t\t\t\t\t\tLine:   4,\n\t\t\t\t\t\tColumn: 7,\n\t\t\t\t\t}},\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"kc\",\n\t\t\t\t\tHeadComment: \"# HC1\\n# HC2\",\n\t\t\t\t\tFootComment: \"# FC1\\n# FC2\",\n\t\t\t\t\tLine:        8,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tValue:  \"vc\",\n\t\t\t\t\tLine:   8,\n\t\t\t\t\tColumn: 5,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t// Same as above, but decode only due to empty line between ka's value and kc's headers.\n\t\t\"[decode]# HA1\\nka:\\n  # HB1\\n  kb: vb\\n  # FB1\\n\\n# HC1\\n# HC2\\nkc: vc\\n# FC1\\n# FC2\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   2,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   2,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"ka\",\n\t\t\t\t\tHeadComment: \"# HA1\",\n\t\t\t\t\tLine:        2,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\tLine:   4,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\tValue:       \"kb\",\n\t\t\t\t\t\tHeadComment: \"# HB1\",\n\t\t\t\t\t\tFootComment: \"# FB1\",\n\t\t\t\t\t\tLine:        4,\n\t\t\t\t\t\tColumn:      3,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"vb\",\n\t\t\t\t\t\tLine:   4,\n\t\t\t\t\t\tColumn: 7,\n\t\t\t\t\t}},\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tValue:       \"kc\",\n\t\t\t\t\tHeadComment: \"# HC1\\n# HC2\",\n\t\t\t\t\tFootComment: \"# FC1\\n# FC2\",\n\t\t\t\t\tLine:        9,\n\t\t\t\t\tColumn:      1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tValue:  \"vc\",\n\t\t\t\t\tLine:   9,\n\t\t\t\t\tColumn: 5,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"# H1\\n[la, lb] # I\\n# F1\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   2,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:        yaml.SequenceNode,\n\t\t\t\tTag:         \"!!seq\",\n\t\t\t\tStyle:       yaml.FlowStyle,\n\t\t\t\tLine:        2,\n\t\t\t\tColumn:      1,\n\t\t\t\tHeadComment: \"# H1\",\n\t\t\t\tLineComment: \"# I\",\n\t\t\t\tFootComment: \"# F1\",\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tLine:   2,\n\t\t\t\t\tColumn: 2,\n\t\t\t\t\tValue:  \"la\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tLine:   2,\n\t\t\t\t\tColumn: 6,\n\t\t\t\t\tValue:  \"lb\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"# DH1\\n\\n# SH1\\n[\\n  # HA1\\n  la, # IA\\n  # FA1\\n\\n  # HB1\\n  lb, # IB\\n  # FB1\\n]\\n# SF1\\n\\n# DF1\\n\",\n\t\tyaml.Node{\n\t\t\tKind:        yaml.DocumentNode,\n\t\t\tLine:        4,\n\t\t\tColumn:      1,\n\t\t\tHeadComment: \"# DH1\",\n\t\t\tFootComment: \"# DF1\",\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:        yaml.SequenceNode,\n\t\t\t\tTag:         \"!!seq\",\n\t\t\t\tStyle:       yaml.FlowStyle,\n\t\t\t\tLine:        4,\n\t\t\t\tColumn:      1,\n\t\t\t\tHeadComment: \"# SH1\",\n\t\t\t\tFootComment: \"# SF1\",\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        6,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tValue:       \"la\",\n\t\t\t\t\tHeadComment: \"# HA1\",\n\t\t\t\t\tLineComment: \"# IA\",\n\t\t\t\t\tFootComment: \"# FA1\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        10,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tValue:       \"lb\",\n\t\t\t\t\tHeadComment: \"# HB1\",\n\t\t\t\t\tLineComment: \"# IB\",\n\t\t\t\t\tFootComment: \"# FB1\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t// Same as above, but with extra newlines before FB1 and FB2\n\t\t\"[decode]# DH1\\n\\n# SH1\\n[\\n  # HA1\\n  la, # IA\\n  # FA1\\n\\n  # HB1\\n  lb, # IB\\n\\n\\n  # FB1\\n\\n# FB2\\n]\\n# SF1\\n\\n# DF1\\n\",\n\t\tyaml.Node{\n\t\t\tKind:        yaml.DocumentNode,\n\t\t\tLine:        4,\n\t\t\tColumn:      1,\n\t\t\tHeadComment: \"# DH1\",\n\t\t\tFootComment: \"# DF1\",\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:        yaml.SequenceNode,\n\t\t\t\tTag:         \"!!seq\",\n\t\t\t\tStyle:       yaml.FlowStyle,\n\t\t\t\tLine:        4,\n\t\t\t\tColumn:      1,\n\t\t\t\tHeadComment: \"# SH1\",\n\t\t\t\tFootComment: \"# SF1\",\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        6,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tValue:       \"la\",\n\t\t\t\t\tHeadComment: \"# HA1\",\n\t\t\t\t\tLineComment: \"# IA\",\n\t\t\t\t\tFootComment: \"# FA1\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        10,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tValue:       \"lb\",\n\t\t\t\t\tHeadComment: \"# HB1\",\n\t\t\t\t\tLineComment: \"# IB\",\n\t\t\t\t\tFootComment: \"# FB1\\n\\n# FB2\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"# DH1\\n\\n# SH1\\n[\\n  # HA1\\n  la,\\n  # FA1\\n\\n  # HB1\\n  lb,\\n  # FB1\\n]\\n# SF1\\n\\n# DF1\\n\",\n\t\tyaml.Node{\n\t\t\tKind:        yaml.DocumentNode,\n\t\t\tLine:        4,\n\t\t\tColumn:      1,\n\t\t\tHeadComment: \"# DH1\",\n\t\t\tFootComment: \"# DF1\",\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:        yaml.SequenceNode,\n\t\t\t\tTag:         \"!!seq\",\n\t\t\t\tStyle:       yaml.FlowStyle,\n\t\t\t\tLine:        4,\n\t\t\t\tColumn:      1,\n\t\t\t\tHeadComment: \"# SH1\",\n\t\t\t\tFootComment: \"# SF1\",\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        6,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tValue:       \"la\",\n\t\t\t\t\tHeadComment: \"# HA1\",\n\t\t\t\t\tFootComment: \"# FA1\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        10,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tValue:       \"lb\",\n\t\t\t\t\tHeadComment: \"# HB1\",\n\t\t\t\t\tFootComment: \"# FB1\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"ka:\\n  kb: [\\n    # HA1\\n    la,\\n    # FA1\\n\\n    # HB1\\n    lb,\\n    # FB1\\n  ]\\n\",\n\t\tyaml.Node{\n\t\t\tKind:   yaml.DocumentNode,\n\t\t\tLine:   1,\n\t\t\tColumn: 1,\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.MappingNode,\n\t\t\t\tTag:    \"!!map\",\n\t\t\t\tLine:   1,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tValue:  \"ka\",\n\t\t\t\t\tLine:   1,\n\t\t\t\t\tColumn: 1,\n\t\t\t\t}, {\n\t\t\t\t\tKind:   0x4,\n\t\t\t\t\tTag:    \"!!map\",\n\t\t\t\t\tLine:   2,\n\t\t\t\t\tColumn: 3,\n\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\t\tValue:  \"kb\",\n\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\tColumn: 3,\n\t\t\t\t\t}, {\n\t\t\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\t\t\tStyle:  0x20,\n\t\t\t\t\t\tTag:    \"!!seq\",\n\t\t\t\t\t\tLine:   2,\n\t\t\t\t\t\tColumn: 7,\n\t\t\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\t\tValue:       \"la\",\n\t\t\t\t\t\t\tHeadComment: \"# HA1\",\n\t\t\t\t\t\t\tFootComment: \"# FA1\",\n\t\t\t\t\t\t\tLine:        4,\n\t\t\t\t\t\t\tColumn:      5,\n\t\t\t\t\t\t}, {\n\t\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\t\tValue:       \"lb\",\n\t\t\t\t\t\t\tHeadComment: \"# HB1\",\n\t\t\t\t\t\t\tFootComment: \"# FB1\",\n\t\t\t\t\t\t\tLine:        8,\n\t\t\t\t\t\t\tColumn:      5,\n\t\t\t\t\t\t}},\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"# DH1\\n\\n# MH1\\n{\\n  # HA1\\n  ka: va, # IA\\n  # FA1\\n\\n  # HB1\\n  kb: vb, # IB\\n  # FB1\\n}\\n# MF1\\n\\n# DF1\\n\",\n\t\tyaml.Node{\n\t\t\tKind:        yaml.DocumentNode,\n\t\t\tLine:        4,\n\t\t\tColumn:      1,\n\t\t\tHeadComment: \"# DH1\",\n\t\t\tFootComment: \"# DF1\",\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:        yaml.MappingNode,\n\t\t\t\tTag:         \"!!map\",\n\t\t\t\tStyle:       yaml.FlowStyle,\n\t\t\t\tLine:        4,\n\t\t\t\tColumn:      1,\n\t\t\t\tHeadComment: \"# MH1\",\n\t\t\t\tFootComment: \"# MF1\",\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        6,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tValue:       \"ka\",\n\t\t\t\t\tHeadComment: \"# HA1\",\n\t\t\t\t\tFootComment: \"# FA1\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        6,\n\t\t\t\t\tColumn:      7,\n\t\t\t\t\tValue:       \"va\",\n\t\t\t\t\tLineComment: \"# IA\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        10,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tValue:       \"kb\",\n\t\t\t\t\tHeadComment: \"# HB1\",\n\t\t\t\t\tFootComment: \"# FB1\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        10,\n\t\t\t\t\tColumn:      7,\n\t\t\t\t\tValue:       \"vb\",\n\t\t\t\t\tLineComment: \"# IB\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"# DH1\\n\\n# MH1\\n{\\n  # HA1\\n  ka: va,\\n  # FA1\\n\\n  # HB1\\n  kb: vb,\\n  # FB1\\n}\\n# MF1\\n\\n# DF1\\n\",\n\t\tyaml.Node{\n\t\t\tKind:        yaml.DocumentNode,\n\t\t\tLine:        4,\n\t\t\tColumn:      1,\n\t\t\tHeadComment: \"# DH1\",\n\t\t\tFootComment: \"# DF1\",\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:        yaml.MappingNode,\n\t\t\t\tTag:         \"!!map\",\n\t\t\t\tStyle:       yaml.FlowStyle,\n\t\t\t\tLine:        4,\n\t\t\t\tColumn:      1,\n\t\t\t\tHeadComment: \"# MH1\",\n\t\t\t\tFootComment: \"# MF1\",\n\t\t\t\tContent: []*yaml.Node{{\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        6,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tValue:       \"ka\",\n\t\t\t\t\tHeadComment: \"# HA1\",\n\t\t\t\t\tFootComment: \"# FA1\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tLine:   6,\n\t\t\t\t\tColumn: 7,\n\t\t\t\t\tValue:  \"va\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\tLine:        10,\n\t\t\t\t\tColumn:      3,\n\t\t\t\t\tValue:       \"kb\",\n\t\t\t\t\tHeadComment: \"# HB1\",\n\t\t\t\t\tFootComment: \"# FB1\",\n\t\t\t\t}, {\n\t\t\t\t\tKind:   yaml.ScalarNode,\n\t\t\t\t\tTag:    \"!!str\",\n\t\t\t\t\tLine:   10,\n\t\t\t\t\tColumn: 7,\n\t\t\t\t\tValue:  \"vb\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}, {\n\t\t\"# DH1\\n\\n# DH2\\n\\n# HA1\\n# HA2\\n- &x la # IA\\n# FA1\\n# FA2\\n\\n# HB1\\n# HB2\\n- *x # IB\\n# FB1\\n# FB2\\n\\n# DF1\\n\\n# DF2\\n\",\n\t\tyaml.Node{\n\t\t\tKind:        yaml.DocumentNode,\n\t\t\tLine:        7,\n\t\t\tColumn:      1,\n\t\t\tHeadComment: \"# DH1\\n\\n# DH2\",\n\t\t\tFootComment: \"# DF1\\n\\n# DF2\",\n\t\t\tContent: []*yaml.Node{{\n\t\t\t\tKind:   yaml.SequenceNode,\n\t\t\t\tTag:    \"!!seq\",\n\t\t\t\tLine:   7,\n\t\t\t\tColumn: 1,\n\t\t\t\tContent: []*yaml.Node{\n\t\t\t\t\tsaveNode(\"x\", &yaml.Node{\n\t\t\t\t\t\tKind:        yaml.ScalarNode,\n\t\t\t\t\t\tTag:         \"!!str\",\n\t\t\t\t\t\tLine:        7,\n\t\t\t\t\t\tColumn:      3,\n\t\t\t\t\t\tValue:       \"la\",\n\t\t\t\t\t\tHeadComment: \"# HA1\\n# HA2\",\n\t\t\t\t\t\tLineComment: \"# IA\",\n\t\t\t\t\t\tFootComment: \"# FA1\\n# FA2\",\n\t\t\t\t\t\tAnchor:      \"x\",\n\t\t\t\t\t}), {\n\t\t\t\t\t\tKind:        yaml.AliasNode,\n\t\t\t\t\t\tLine:        13,\n\t\t\t\t\t\tColumn:      3,\n\t\t\t\t\t\tValue:       \"x\",\n\t\t\t\t\t\tAlias:       dropNode(\"x\"),\n\t\t\t\t\t\tHeadComment: \"# HB1\\n# HB2\",\n\t\t\t\t\t\tLineComment: \"# IB\",\n\t\t\t\t\t\tFootComment: \"# FB1\\n# FB2\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}},\n\t\t},\n\t},\n}\n\nfunc (s *S) TestNodeRoundtrip(c *C) {\n\tdefer os.Setenv(\"TZ\", os.Getenv(\"TZ\"))\n\tos.Setenv(\"TZ\", \"UTC\")\n\tfor i, item := range nodeTests {\n\t\tc.Logf(\"test %d: %q\", i, item.yaml)\n\n\t\tif strings.Contains(item.yaml, \"#\") {\n\t\t\tvar buf bytes.Buffer\n\t\t\tfprintComments(&buf, &item.node, \"    \")\n\t\t\tc.Logf(\"  expected comments:\\n%s\", buf.Bytes())\n\t\t}\n\n\t\tdecode := true\n\t\tencode := true\n\n\t\ttestYaml := item.yaml\n\t\tif s := strings.TrimPrefix(testYaml, \"[decode]\"); s != testYaml {\n\t\t\tencode = false\n\t\t\ttestYaml = s\n\t\t}\n\t\tif s := strings.TrimPrefix(testYaml, \"[encode]\"); s != testYaml {\n\t\t\tdecode = false\n\t\t\ttestYaml = s\n\t\t}\n\n\t\tif decode {\n\t\t\tvar node yaml.Node\n\t\t\terr := yaml.Unmarshal([]byte(testYaml), &node)\n\t\t\tc.Assert(err, IsNil)\n\t\t\tif strings.Contains(item.yaml, \"#\") {\n\t\t\t\tvar buf bytes.Buffer\n\t\t\t\tfprintComments(&buf, &node, \"    \")\n\t\t\t\tc.Logf(\"  obtained comments:\\n%s\", buf.Bytes())\n\t\t\t}\n\t\t\tc.Assert(&node, DeepEquals, &item.node)\n\t\t}\n\t\tif encode {\n\t\t\tnode := deepCopyNode(&item.node, nil)\n\t\t\tbuf := bytes.Buffer{}\n\t\t\tenc := yaml.NewEncoder(&buf)\n\t\t\tenc.SetIndent(2)\n\t\t\terr := enc.Encode(node)\n\t\t\tc.Assert(err, IsNil)\n\t\t\terr = enc.Close()\n\t\t\tc.Assert(err, IsNil)\n\t\t\tc.Assert(buf.String(), Equals, testYaml)\n\n\t\t\t// Ensure there were no mutations to the tree.\n\t\t\tc.Assert(node, DeepEquals, &item.node)\n\t\t}\n\t}\n}\n\nfunc deepCopyNode(node *yaml.Node, cache map[*yaml.Node]*yaml.Node) *yaml.Node {\n\tif n, ok := cache[node]; ok {\n\t\treturn n\n\t}\n\tif cache == nil {\n\t\tcache = make(map[*yaml.Node]*yaml.Node)\n\t}\n\tcopy := *node\n\tcache[node] = &copy\n\tcopy.Content = nil\n\tfor _, elem := range node.Content {\n\t\tcopy.Content = append(copy.Content, deepCopyNode(elem, cache))\n\t}\n\tif node.Alias != nil {\n\t\tcopy.Alias = deepCopyNode(node.Alias, cache)\n\t}\n\treturn &copy\n}\n\nvar savedNodes = make(map[string]*yaml.Node)\n\nfunc saveNode(name string, node *yaml.Node) *yaml.Node {\n\tsavedNodes[name] = node\n\treturn node\n}\n\nfunc peekNode(name string) *yaml.Node {\n\treturn savedNodes[name]\n}\n\nfunc dropNode(name string) *yaml.Node {\n\tnode := savedNodes[name]\n\tdelete(savedNodes, name)\n\treturn node\n}\n\nvar setStringTests = []struct {\n\tstr  string\n\tyaml string\n\tnode yaml.Node\n}{\n\t{\n\t\t\"something simple\",\n\t\t\"something simple\\n\",\n\t\tyaml.Node{\n\t\t\tKind:  yaml.ScalarNode,\n\t\t\tValue: \"something simple\",\n\t\t\tTag:   \"!!str\",\n\t\t},\n\t}, {\n\t\t`\"quoted value\"`,\n\t\t\"'\\\"quoted value\\\"'\\n\",\n\t\tyaml.Node{\n\t\t\tKind:  yaml.ScalarNode,\n\t\t\tValue: `\"quoted value\"`,\n\t\t\tTag:   \"!!str\",\n\t\t},\n\t}, {\n\t\t\"multi\\nline\",\n\t\t\"|-\\n  multi\\n  line\\n\",\n\t\tyaml.Node{\n\t\t\tKind:  yaml.ScalarNode,\n\t\t\tValue: \"multi\\nline\",\n\t\t\tTag:   \"!!str\",\n\t\t\tStyle: yaml.LiteralStyle,\n\t\t},\n\t}, {\n\t\t\"123\",\n\t\t\"\\\"123\\\"\\n\",\n\t\tyaml.Node{\n\t\t\tKind:  yaml.ScalarNode,\n\t\t\tValue: \"123\",\n\t\t\tTag:   \"!!str\",\n\t\t},\n\t}, {\n\t\t\"multi\\nline\\n\",\n\t\t\"|\\n  multi\\n  line\\n\",\n\t\tyaml.Node{\n\t\t\tKind:  yaml.ScalarNode,\n\t\t\tValue: \"multi\\nline\\n\",\n\t\t\tTag:   \"!!str\",\n\t\t\tStyle: yaml.LiteralStyle,\n\t\t},\n\t}, {\n\t\t\"\\x80\\x81\\x82\",\n\t\t\"!!binary gIGC\\n\",\n\t\tyaml.Node{\n\t\t\tKind:  yaml.ScalarNode,\n\t\t\tValue: \"gIGC\",\n\t\t\tTag:   \"!!binary\",\n\t\t},\n\t},\n}\n\nfunc (s *S) TestSetString(c *C) {\n\tdefer os.Setenv(\"TZ\", os.Getenv(\"TZ\"))\n\tos.Setenv(\"TZ\", \"UTC\")\n\tfor i, item := range setStringTests {\n\t\tc.Logf(\"test %d: %q\", i, item.str)\n\n\t\tvar node yaml.Node\n\n\t\tnode.SetString(item.str)\n\n\t\tc.Assert(node, DeepEquals, item.node)\n\n\t\tbuf := bytes.Buffer{}\n\t\tenc := yaml.NewEncoder(&buf)\n\t\tenc.SetIndent(2)\n\t\terr := enc.Encode(&item.node)\n\t\tc.Assert(err, IsNil)\n\t\terr = enc.Close()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(buf.String(), Equals, item.yaml)\n\n\t\tvar doc yaml.Node\n\t\terr = yaml.Unmarshal([]byte(item.yaml), &doc)\n\t\tc.Assert(err, IsNil)\n\n\t\tvar str string\n\t\terr = node.Decode(&str)\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(str, Equals, item.str)\n\t}\n}\n\nvar nodeEncodeDecodeTests = []struct {\n\tvalue interface{}\n\tyaml  string\n\tnode  yaml.Node\n}{{\n\t\"something simple\",\n\t\"something simple\\n\",\n\tyaml.Node{\n\t\tKind:  yaml.ScalarNode,\n\t\tValue: \"something simple\",\n\t\tTag:   \"!!str\",\n\t},\n}, {\n\t`\"quoted value\"`,\n\t\"'\\\"quoted value\\\"'\\n\",\n\tyaml.Node{\n\t\tKind:  yaml.ScalarNode,\n\t\tStyle: yaml.SingleQuotedStyle,\n\t\tValue: `\"quoted value\"`,\n\t\tTag:   \"!!str\",\n\t},\n}, {\n\t123,\n\t\"123\",\n\tyaml.Node{\n\t\tKind:  yaml.ScalarNode,\n\t\tValue: `123`,\n\t\tTag:   \"!!int\",\n\t},\n}, {\n\t[]interface{}{1, 2},\n\t\"[1, 2]\",\n\tyaml.Node{\n\t\tKind: yaml.SequenceNode,\n\t\tTag:  \"!!seq\",\n\t\tContent: []*yaml.Node{{\n\t\t\tKind:  yaml.ScalarNode,\n\t\t\tValue: \"1\",\n\t\t\tTag:   \"!!int\",\n\t\t}, {\n\t\t\tKind:  yaml.ScalarNode,\n\t\t\tValue: \"2\",\n\t\t\tTag:   \"!!int\",\n\t\t}},\n\t},\n}, {\n\tmap[string]interface{}{\"a\": \"b\"},\n\t\"a: b\",\n\tyaml.Node{\n\t\tKind: yaml.MappingNode,\n\t\tTag:  \"!!map\",\n\t\tContent: []*yaml.Node{{\n\t\t\tKind:  yaml.ScalarNode,\n\t\t\tValue: \"a\",\n\t\t\tTag:   \"!!str\",\n\t\t}, {\n\t\t\tKind:  yaml.ScalarNode,\n\t\t\tValue: \"b\",\n\t\t\tTag:   \"!!str\",\n\t\t}},\n\t},\n}}\n\nfunc (s *S) TestNodeEncodeDecode(c *C) {\n\tfor i, item := range nodeEncodeDecodeTests {\n\t\tc.Logf(\"Encode/Decode test value #%d: %#v\", i, item.value)\n\n\t\tvar v interface{}\n\t\terr := item.node.Decode(&v)\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(v, DeepEquals, item.value)\n\n\t\tvar n yaml.Node\n\t\terr = n.Encode(item.value)\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(n, DeepEquals, item.node)\n\t}\n}\n\nfunc (s *S) TestNodeZeroEncodeDecode(c *C) {\n\t// Zero node value behaves as nil when encoding...\n\tvar n yaml.Node\n\tdata, err := yaml.Marshal(&n)\n\tc.Assert(err, IsNil)\n\tc.Assert(string(data), Equals, \"null\\n\")\n\n\t// ... and decoding.\n\tvar v *struct{} = &struct{}{}\n\tc.Assert(n.Decode(&v), IsNil)\n\tc.Assert(v, IsNil)\n\n\t// ... and even when looking for its tag.\n\tc.Assert(n.ShortTag(), Equals, \"!!null\")\n\n\t// Kind zero is still unknown, though.\n\tn.Line = 1\n\t_, err = yaml.Marshal(&n)\n\tc.Assert(err, ErrorMatches, \"yaml: cannot encode node with unknown kind 0\")\n\tc.Assert(n.Decode(&v), ErrorMatches, \"yaml: cannot decode node with unknown kind 0\")\n}\n\nfunc (s *S) TestNodeOmitEmpty(c *C) {\n\tvar v struct {\n\t\tA int\n\t\tB yaml.Node \",omitempty\"\n\t}\n\tv.A = 1\n\tdata, err := yaml.Marshal(&v)\n\tc.Assert(err, IsNil)\n\tc.Assert(string(data), Equals, \"a: 1\\n\")\n\n\tv.B.Line = 1\n\t_, err = yaml.Marshal(&v)\n\tc.Assert(err, ErrorMatches, \"yaml: cannot encode node with unknown kind 0\")\n}\n\nfunc fprintComments(out io.Writer, node *yaml.Node, indent string) {\n\tswitch node.Kind {\n\tcase yaml.ScalarNode:\n\t\tfmt.Fprintf(out, \"%s<%s> \", indent, node.Value)\n\t\tfprintCommentSet(out, node)\n\t\tfmt.Fprintf(out, \"\\n\")\n\tcase yaml.DocumentNode:\n\t\tfmt.Fprintf(out, \"%s<DOC> \", indent)\n\t\tfprintCommentSet(out, node)\n\t\tfmt.Fprintf(out, \"\\n\")\n\t\tfor i := 0; i < len(node.Content); i++ {\n\t\t\tfprintComments(out, node.Content[i], indent+\"  \")\n\t\t}\n\tcase yaml.MappingNode:\n\t\tfmt.Fprintf(out, \"%s<MAP> \", indent)\n\t\tfprintCommentSet(out, node)\n\t\tfmt.Fprintf(out, \"\\n\")\n\t\tfor i := 0; i < len(node.Content); i += 2 {\n\t\t\tfprintComments(out, node.Content[i], indent+\"  \")\n\t\t\tfprintComments(out, node.Content[i+1], indent+\"  \")\n\t\t}\n\tcase yaml.SequenceNode:\n\t\tfmt.Fprintf(out, \"%s<SEQ> \", indent)\n\t\tfprintCommentSet(out, node)\n\t\tfmt.Fprintf(out, \"\\n\")\n\t\tfor i := 0; i < len(node.Content); i++ {\n\t\t\tfprintComments(out, node.Content[i], indent+\"  \")\n\t\t}\n\t}\n}\n\nfunc fprintCommentSet(out io.Writer, node *yaml.Node) {\n\tif len(node.HeadComment)+len(node.LineComment)+len(node.FootComment) > 0 {\n\t\tfmt.Fprintf(out, \"%q / %q / %q\", node.HeadComment, node.LineComment, node.FootComment)\n\t}\n}\n"
        },
        {
          "name": "parserc.go",
          "type": "blob",
          "size": 39.865234375,
          "content": "//\n// Copyright (c) 2011-2019 Canonical Ltd\n// Copyright (c) 2006-2010 Kirill Simonov\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy of\n// this software and associated documentation files (the \"Software\"), to deal in\n// the Software without restriction, including without limitation the rights to\n// use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\n// of the Software, and to permit persons to whom the Software is furnished to do\n// so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\npackage yaml\n\nimport (\n\t\"bytes\"\n)\n\n// The parser implements the following grammar:\n//\n// stream               ::= STREAM-START implicit_document? explicit_document* STREAM-END\n// implicit_document    ::= block_node DOCUMENT-END*\n// explicit_document    ::= DIRECTIVE* DOCUMENT-START block_node? DOCUMENT-END*\n// block_node_or_indentless_sequence    ::=\n//                          ALIAS\n//                          | properties (block_content | indentless_block_sequence)?\n//                          | block_content\n//                          | indentless_block_sequence\n// block_node           ::= ALIAS\n//                          | properties block_content?\n//                          | block_content\n// flow_node            ::= ALIAS\n//                          | properties flow_content?\n//                          | flow_content\n// properties           ::= TAG ANCHOR? | ANCHOR TAG?\n// block_content        ::= block_collection | flow_collection | SCALAR\n// flow_content         ::= flow_collection | SCALAR\n// block_collection     ::= block_sequence | block_mapping\n// flow_collection      ::= flow_sequence | flow_mapping\n// block_sequence       ::= BLOCK-SEQUENCE-START (BLOCK-ENTRY block_node?)* BLOCK-END\n// indentless_sequence  ::= (BLOCK-ENTRY block_node?)+\n// block_mapping        ::= BLOCK-MAPPING_START\n//                          ((KEY block_node_or_indentless_sequence?)?\n//                          (VALUE block_node_or_indentless_sequence?)?)*\n//                          BLOCK-END\n// flow_sequence        ::= FLOW-SEQUENCE-START\n//                          (flow_sequence_entry FLOW-ENTRY)*\n//                          flow_sequence_entry?\n//                          FLOW-SEQUENCE-END\n// flow_sequence_entry  ::= flow_node | KEY flow_node? (VALUE flow_node?)?\n// flow_mapping         ::= FLOW-MAPPING-START\n//                          (flow_mapping_entry FLOW-ENTRY)*\n//                          flow_mapping_entry?\n//                          FLOW-MAPPING-END\n// flow_mapping_entry   ::= flow_node | KEY flow_node? (VALUE flow_node?)?\n\n// Peek the next token in the token queue.\nfunc peek_token(parser *yaml_parser_t) *yaml_token_t {\n\tif parser.token_available || yaml_parser_fetch_more_tokens(parser) {\n\t\ttoken := &parser.tokens[parser.tokens_head]\n\t\tyaml_parser_unfold_comments(parser, token)\n\t\treturn token\n\t}\n\treturn nil\n}\n\n// yaml_parser_unfold_comments walks through the comments queue and joins all\n// comments behind the position of the provided token into the respective\n// top-level comment slices in the parser.\nfunc yaml_parser_unfold_comments(parser *yaml_parser_t, token *yaml_token_t) {\n\tfor parser.comments_head < len(parser.comments) && token.start_mark.index >= parser.comments[parser.comments_head].token_mark.index {\n\t\tcomment := &parser.comments[parser.comments_head]\n\t\tif len(comment.head) > 0 {\n\t\t\tif token.typ == yaml_BLOCK_END_TOKEN {\n\t\t\t\t// No heads on ends, so keep comment.head for a follow up token.\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tif len(parser.head_comment) > 0 {\n\t\t\t\tparser.head_comment = append(parser.head_comment, '\\n')\n\t\t\t}\n\t\t\tparser.head_comment = append(parser.head_comment, comment.head...)\n\t\t}\n\t\tif len(comment.foot) > 0 {\n\t\t\tif len(parser.foot_comment) > 0 {\n\t\t\t\tparser.foot_comment = append(parser.foot_comment, '\\n')\n\t\t\t}\n\t\t\tparser.foot_comment = append(parser.foot_comment, comment.foot...)\n\t\t}\n\t\tif len(comment.line) > 0 {\n\t\t\tif len(parser.line_comment) > 0 {\n\t\t\t\tparser.line_comment = append(parser.line_comment, '\\n')\n\t\t\t}\n\t\t\tparser.line_comment = append(parser.line_comment, comment.line...)\n\t\t}\n\t\t*comment = yaml_comment_t{}\n\t\tparser.comments_head++\n\t}\n}\n\n// Remove the next token from the queue (must be called after peek_token).\nfunc skip_token(parser *yaml_parser_t) {\n\tparser.token_available = false\n\tparser.tokens_parsed++\n\tparser.stream_end_produced = parser.tokens[parser.tokens_head].typ == yaml_STREAM_END_TOKEN\n\tparser.tokens_head++\n}\n\n// Get the next event.\nfunc yaml_parser_parse(parser *yaml_parser_t, event *yaml_event_t) bool {\n\t// Erase the event object.\n\t*event = yaml_event_t{}\n\n\t// No events after the end of the stream or error.\n\tif parser.stream_end_produced || parser.error != yaml_NO_ERROR || parser.state == yaml_PARSE_END_STATE {\n\t\treturn true\n\t}\n\n\t// Generate the next event.\n\treturn yaml_parser_state_machine(parser, event)\n}\n\n// Set parser error.\nfunc yaml_parser_set_parser_error(parser *yaml_parser_t, problem string, problem_mark yaml_mark_t) bool {\n\tparser.error = yaml_PARSER_ERROR\n\tparser.problem = problem\n\tparser.problem_mark = problem_mark\n\treturn false\n}\n\nfunc yaml_parser_set_parser_error_context(parser *yaml_parser_t, context string, context_mark yaml_mark_t, problem string, problem_mark yaml_mark_t) bool {\n\tparser.error = yaml_PARSER_ERROR\n\tparser.context = context\n\tparser.context_mark = context_mark\n\tparser.problem = problem\n\tparser.problem_mark = problem_mark\n\treturn false\n}\n\n// State dispatcher.\nfunc yaml_parser_state_machine(parser *yaml_parser_t, event *yaml_event_t) bool {\n\t//trace(\"yaml_parser_state_machine\", \"state:\", parser.state.String())\n\n\tswitch parser.state {\n\tcase yaml_PARSE_STREAM_START_STATE:\n\t\treturn yaml_parser_parse_stream_start(parser, event)\n\n\tcase yaml_PARSE_IMPLICIT_DOCUMENT_START_STATE:\n\t\treturn yaml_parser_parse_document_start(parser, event, true)\n\n\tcase yaml_PARSE_DOCUMENT_START_STATE:\n\t\treturn yaml_parser_parse_document_start(parser, event, false)\n\n\tcase yaml_PARSE_DOCUMENT_CONTENT_STATE:\n\t\treturn yaml_parser_parse_document_content(parser, event)\n\n\tcase yaml_PARSE_DOCUMENT_END_STATE:\n\t\treturn yaml_parser_parse_document_end(parser, event)\n\n\tcase yaml_PARSE_BLOCK_NODE_STATE:\n\t\treturn yaml_parser_parse_node(parser, event, true, false)\n\n\tcase yaml_PARSE_BLOCK_NODE_OR_INDENTLESS_SEQUENCE_STATE:\n\t\treturn yaml_parser_parse_node(parser, event, true, true)\n\n\tcase yaml_PARSE_FLOW_NODE_STATE:\n\t\treturn yaml_parser_parse_node(parser, event, false, false)\n\n\tcase yaml_PARSE_BLOCK_SEQUENCE_FIRST_ENTRY_STATE:\n\t\treturn yaml_parser_parse_block_sequence_entry(parser, event, true)\n\n\tcase yaml_PARSE_BLOCK_SEQUENCE_ENTRY_STATE:\n\t\treturn yaml_parser_parse_block_sequence_entry(parser, event, false)\n\n\tcase yaml_PARSE_INDENTLESS_SEQUENCE_ENTRY_STATE:\n\t\treturn yaml_parser_parse_indentless_sequence_entry(parser, event)\n\n\tcase yaml_PARSE_BLOCK_MAPPING_FIRST_KEY_STATE:\n\t\treturn yaml_parser_parse_block_mapping_key(parser, event, true)\n\n\tcase yaml_PARSE_BLOCK_MAPPING_KEY_STATE:\n\t\treturn yaml_parser_parse_block_mapping_key(parser, event, false)\n\n\tcase yaml_PARSE_BLOCK_MAPPING_VALUE_STATE:\n\t\treturn yaml_parser_parse_block_mapping_value(parser, event)\n\n\tcase yaml_PARSE_FLOW_SEQUENCE_FIRST_ENTRY_STATE:\n\t\treturn yaml_parser_parse_flow_sequence_entry(parser, event, true)\n\n\tcase yaml_PARSE_FLOW_SEQUENCE_ENTRY_STATE:\n\t\treturn yaml_parser_parse_flow_sequence_entry(parser, event, false)\n\n\tcase yaml_PARSE_FLOW_SEQUENCE_ENTRY_MAPPING_KEY_STATE:\n\t\treturn yaml_parser_parse_flow_sequence_entry_mapping_key(parser, event)\n\n\tcase yaml_PARSE_FLOW_SEQUENCE_ENTRY_MAPPING_VALUE_STATE:\n\t\treturn yaml_parser_parse_flow_sequence_entry_mapping_value(parser, event)\n\n\tcase yaml_PARSE_FLOW_SEQUENCE_ENTRY_MAPPING_END_STATE:\n\t\treturn yaml_parser_parse_flow_sequence_entry_mapping_end(parser, event)\n\n\tcase yaml_PARSE_FLOW_MAPPING_FIRST_KEY_STATE:\n\t\treturn yaml_parser_parse_flow_mapping_key(parser, event, true)\n\n\tcase yaml_PARSE_FLOW_MAPPING_KEY_STATE:\n\t\treturn yaml_parser_parse_flow_mapping_key(parser, event, false)\n\n\tcase yaml_PARSE_FLOW_MAPPING_VALUE_STATE:\n\t\treturn yaml_parser_parse_flow_mapping_value(parser, event, false)\n\n\tcase yaml_PARSE_FLOW_MAPPING_EMPTY_VALUE_STATE:\n\t\treturn yaml_parser_parse_flow_mapping_value(parser, event, true)\n\n\tdefault:\n\t\tpanic(\"invalid parser state\")\n\t}\n}\n\n// Parse the production:\n// stream   ::= STREAM-START implicit_document? explicit_document* STREAM-END\n//              ************\nfunc yaml_parser_parse_stream_start(parser *yaml_parser_t, event *yaml_event_t) bool {\n\ttoken := peek_token(parser)\n\tif token == nil {\n\t\treturn false\n\t}\n\tif token.typ != yaml_STREAM_START_TOKEN {\n\t\treturn yaml_parser_set_parser_error(parser, \"did not find expected <stream-start>\", token.start_mark)\n\t}\n\tparser.state = yaml_PARSE_IMPLICIT_DOCUMENT_START_STATE\n\t*event = yaml_event_t{\n\t\ttyp:        yaml_STREAM_START_EVENT,\n\t\tstart_mark: token.start_mark,\n\t\tend_mark:   token.end_mark,\n\t\tencoding:   token.encoding,\n\t}\n\tskip_token(parser)\n\treturn true\n}\n\n// Parse the productions:\n// implicit_document    ::= block_node DOCUMENT-END*\n//                          *\n// explicit_document    ::= DIRECTIVE* DOCUMENT-START block_node? DOCUMENT-END*\n//                          *************************\nfunc yaml_parser_parse_document_start(parser *yaml_parser_t, event *yaml_event_t, implicit bool) bool {\n\n\ttoken := peek_token(parser)\n\tif token == nil {\n\t\treturn false\n\t}\n\n\t// Parse extra document end indicators.\n\tif !implicit {\n\t\tfor token.typ == yaml_DOCUMENT_END_TOKEN {\n\t\t\tskip_token(parser)\n\t\t\ttoken = peek_token(parser)\n\t\t\tif token == nil {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t}\n\n\tif implicit && token.typ != yaml_VERSION_DIRECTIVE_TOKEN &&\n\t\ttoken.typ != yaml_TAG_DIRECTIVE_TOKEN &&\n\t\ttoken.typ != yaml_DOCUMENT_START_TOKEN &&\n\t\ttoken.typ != yaml_STREAM_END_TOKEN {\n\t\t// Parse an implicit document.\n\t\tif !yaml_parser_process_directives(parser, nil, nil) {\n\t\t\treturn false\n\t\t}\n\t\tparser.states = append(parser.states, yaml_PARSE_DOCUMENT_END_STATE)\n\t\tparser.state = yaml_PARSE_BLOCK_NODE_STATE\n\n\t\tvar head_comment []byte\n\t\tif len(parser.head_comment) > 0 {\n\t\t\t// [Go] Scan the header comment backwards, and if an empty line is found, break\n\t\t\t//      the header so the part before the last empty line goes into the\n\t\t\t//      document header, while the bottom of it goes into a follow up event.\n\t\t\tfor i := len(parser.head_comment) - 1; i > 0; i-- {\n\t\t\t\tif parser.head_comment[i] == '\\n' {\n\t\t\t\t\tif i == len(parser.head_comment)-1 {\n\t\t\t\t\t\thead_comment = parser.head_comment[:i]\n\t\t\t\t\t\tparser.head_comment = parser.head_comment[i+1:]\n\t\t\t\t\t\tbreak\n\t\t\t\t\t} else if parser.head_comment[i-1] == '\\n' {\n\t\t\t\t\t\thead_comment = parser.head_comment[:i-1]\n\t\t\t\t\t\tparser.head_comment = parser.head_comment[i+1:]\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t*event = yaml_event_t{\n\t\t\ttyp:        yaml_DOCUMENT_START_EVENT,\n\t\t\tstart_mark: token.start_mark,\n\t\t\tend_mark:   token.end_mark,\n\n\t\t\thead_comment: head_comment,\n\t\t}\n\n\t} else if token.typ != yaml_STREAM_END_TOKEN {\n\t\t// Parse an explicit document.\n\t\tvar version_directive *yaml_version_directive_t\n\t\tvar tag_directives []yaml_tag_directive_t\n\t\tstart_mark := token.start_mark\n\t\tif !yaml_parser_process_directives(parser, &version_directive, &tag_directives) {\n\t\t\treturn false\n\t\t}\n\t\ttoken = peek_token(parser)\n\t\tif token == nil {\n\t\t\treturn false\n\t\t}\n\t\tif token.typ != yaml_DOCUMENT_START_TOKEN {\n\t\t\tyaml_parser_set_parser_error(parser,\n\t\t\t\t\"did not find expected <document start>\", token.start_mark)\n\t\t\treturn false\n\t\t}\n\t\tparser.states = append(parser.states, yaml_PARSE_DOCUMENT_END_STATE)\n\t\tparser.state = yaml_PARSE_DOCUMENT_CONTENT_STATE\n\t\tend_mark := token.end_mark\n\n\t\t*event = yaml_event_t{\n\t\t\ttyp:               yaml_DOCUMENT_START_EVENT,\n\t\t\tstart_mark:        start_mark,\n\t\t\tend_mark:          end_mark,\n\t\t\tversion_directive: version_directive,\n\t\t\ttag_directives:    tag_directives,\n\t\t\timplicit:          false,\n\t\t}\n\t\tskip_token(parser)\n\n\t} else {\n\t\t// Parse the stream end.\n\t\tparser.state = yaml_PARSE_END_STATE\n\t\t*event = yaml_event_t{\n\t\t\ttyp:        yaml_STREAM_END_EVENT,\n\t\t\tstart_mark: token.start_mark,\n\t\t\tend_mark:   token.end_mark,\n\t\t}\n\t\tskip_token(parser)\n\t}\n\n\treturn true\n}\n\n// Parse the productions:\n// explicit_document    ::= DIRECTIVE* DOCUMENT-START block_node? DOCUMENT-END*\n//                                                    ***********\n//\nfunc yaml_parser_parse_document_content(parser *yaml_parser_t, event *yaml_event_t) bool {\n\ttoken := peek_token(parser)\n\tif token == nil {\n\t\treturn false\n\t}\n\n\tif token.typ == yaml_VERSION_DIRECTIVE_TOKEN ||\n\t\ttoken.typ == yaml_TAG_DIRECTIVE_TOKEN ||\n\t\ttoken.typ == yaml_DOCUMENT_START_TOKEN ||\n\t\ttoken.typ == yaml_DOCUMENT_END_TOKEN ||\n\t\ttoken.typ == yaml_STREAM_END_TOKEN {\n\t\tparser.state = parser.states[len(parser.states)-1]\n\t\tparser.states = parser.states[:len(parser.states)-1]\n\t\treturn yaml_parser_process_empty_scalar(parser, event,\n\t\t\ttoken.start_mark)\n\t}\n\treturn yaml_parser_parse_node(parser, event, true, false)\n}\n\n// Parse the productions:\n// implicit_document    ::= block_node DOCUMENT-END*\n//                                     *************\n// explicit_document    ::= DIRECTIVE* DOCUMENT-START block_node? DOCUMENT-END*\n//\nfunc yaml_parser_parse_document_end(parser *yaml_parser_t, event *yaml_event_t) bool {\n\ttoken := peek_token(parser)\n\tif token == nil {\n\t\treturn false\n\t}\n\n\tstart_mark := token.start_mark\n\tend_mark := token.start_mark\n\n\timplicit := true\n\tif token.typ == yaml_DOCUMENT_END_TOKEN {\n\t\tend_mark = token.end_mark\n\t\tskip_token(parser)\n\t\timplicit = false\n\t}\n\n\tparser.tag_directives = parser.tag_directives[:0]\n\n\tparser.state = yaml_PARSE_DOCUMENT_START_STATE\n\t*event = yaml_event_t{\n\t\ttyp:        yaml_DOCUMENT_END_EVENT,\n\t\tstart_mark: start_mark,\n\t\tend_mark:   end_mark,\n\t\timplicit:   implicit,\n\t}\n\tyaml_parser_set_event_comments(parser, event)\n\tif len(event.head_comment) > 0 && len(event.foot_comment) == 0 {\n\t\tevent.foot_comment = event.head_comment\n\t\tevent.head_comment = nil\n\t}\n\treturn true\n}\n\nfunc yaml_parser_set_event_comments(parser *yaml_parser_t, event *yaml_event_t) {\n\tevent.head_comment = parser.head_comment\n\tevent.line_comment = parser.line_comment\n\tevent.foot_comment = parser.foot_comment\n\tparser.head_comment = nil\n\tparser.line_comment = nil\n\tparser.foot_comment = nil\n\tparser.tail_comment = nil\n\tparser.stem_comment = nil\n}\n\n// Parse the productions:\n// block_node_or_indentless_sequence    ::=\n//                          ALIAS\n//                          *****\n//                          | properties (block_content | indentless_block_sequence)?\n//                            **********  *\n//                          | block_content | indentless_block_sequence\n//                            *\n// block_node           ::= ALIAS\n//                          *****\n//                          | properties block_content?\n//                            ********** *\n//                          | block_content\n//                            *\n// flow_node            ::= ALIAS\n//                          *****\n//                          | properties flow_content?\n//                            ********** *\n//                          | flow_content\n//                            *\n// properties           ::= TAG ANCHOR? | ANCHOR TAG?\n//                          *************************\n// block_content        ::= block_collection | flow_collection | SCALAR\n//                                                               ******\n// flow_content         ::= flow_collection | SCALAR\n//                                            ******\nfunc yaml_parser_parse_node(parser *yaml_parser_t, event *yaml_event_t, block, indentless_sequence bool) bool {\n\t//defer trace(\"yaml_parser_parse_node\", \"block:\", block, \"indentless_sequence:\", indentless_sequence)()\n\n\ttoken := peek_token(parser)\n\tif token == nil {\n\t\treturn false\n\t}\n\n\tif token.typ == yaml_ALIAS_TOKEN {\n\t\tparser.state = parser.states[len(parser.states)-1]\n\t\tparser.states = parser.states[:len(parser.states)-1]\n\t\t*event = yaml_event_t{\n\t\t\ttyp:        yaml_ALIAS_EVENT,\n\t\t\tstart_mark: token.start_mark,\n\t\t\tend_mark:   token.end_mark,\n\t\t\tanchor:     token.value,\n\t\t}\n\t\tyaml_parser_set_event_comments(parser, event)\n\t\tskip_token(parser)\n\t\treturn true\n\t}\n\n\tstart_mark := token.start_mark\n\tend_mark := token.start_mark\n\n\tvar tag_token bool\n\tvar tag_handle, tag_suffix, anchor []byte\n\tvar tag_mark yaml_mark_t\n\tif token.typ == yaml_ANCHOR_TOKEN {\n\t\tanchor = token.value\n\t\tstart_mark = token.start_mark\n\t\tend_mark = token.end_mark\n\t\tskip_token(parser)\n\t\ttoken = peek_token(parser)\n\t\tif token == nil {\n\t\t\treturn false\n\t\t}\n\t\tif token.typ == yaml_TAG_TOKEN {\n\t\t\ttag_token = true\n\t\t\ttag_handle = token.value\n\t\t\ttag_suffix = token.suffix\n\t\t\ttag_mark = token.start_mark\n\t\t\tend_mark = token.end_mark\n\t\t\tskip_token(parser)\n\t\t\ttoken = peek_token(parser)\n\t\t\tif token == nil {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t} else if token.typ == yaml_TAG_TOKEN {\n\t\ttag_token = true\n\t\ttag_handle = token.value\n\t\ttag_suffix = token.suffix\n\t\tstart_mark = token.start_mark\n\t\ttag_mark = token.start_mark\n\t\tend_mark = token.end_mark\n\t\tskip_token(parser)\n\t\ttoken = peek_token(parser)\n\t\tif token == nil {\n\t\t\treturn false\n\t\t}\n\t\tif token.typ == yaml_ANCHOR_TOKEN {\n\t\t\tanchor = token.value\n\t\t\tend_mark = token.end_mark\n\t\t\tskip_token(parser)\n\t\t\ttoken = peek_token(parser)\n\t\t\tif token == nil {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t}\n\n\tvar tag []byte\n\tif tag_token {\n\t\tif len(tag_handle) == 0 {\n\t\t\ttag = tag_suffix\n\t\t\ttag_suffix = nil\n\t\t} else {\n\t\t\tfor i := range parser.tag_directives {\n\t\t\t\tif bytes.Equal(parser.tag_directives[i].handle, tag_handle) {\n\t\t\t\t\ttag = append([]byte(nil), parser.tag_directives[i].prefix...)\n\t\t\t\t\ttag = append(tag, tag_suffix...)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif len(tag) == 0 {\n\t\t\t\tyaml_parser_set_parser_error_context(parser,\n\t\t\t\t\t\"while parsing a node\", start_mark,\n\t\t\t\t\t\"found undefined tag handle\", tag_mark)\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t}\n\n\timplicit := len(tag) == 0\n\tif indentless_sequence && token.typ == yaml_BLOCK_ENTRY_TOKEN {\n\t\tend_mark = token.end_mark\n\t\tparser.state = yaml_PARSE_INDENTLESS_SEQUENCE_ENTRY_STATE\n\t\t*event = yaml_event_t{\n\t\t\ttyp:        yaml_SEQUENCE_START_EVENT,\n\t\t\tstart_mark: start_mark,\n\t\t\tend_mark:   end_mark,\n\t\t\tanchor:     anchor,\n\t\t\ttag:        tag,\n\t\t\timplicit:   implicit,\n\t\t\tstyle:      yaml_style_t(yaml_BLOCK_SEQUENCE_STYLE),\n\t\t}\n\t\treturn true\n\t}\n\tif token.typ == yaml_SCALAR_TOKEN {\n\t\tvar plain_implicit, quoted_implicit bool\n\t\tend_mark = token.end_mark\n\t\tif (len(tag) == 0 && token.style == yaml_PLAIN_SCALAR_STYLE) || (len(tag) == 1 && tag[0] == '!') {\n\t\t\tplain_implicit = true\n\t\t} else if len(tag) == 0 {\n\t\t\tquoted_implicit = true\n\t\t}\n\t\tparser.state = parser.states[len(parser.states)-1]\n\t\tparser.states = parser.states[:len(parser.states)-1]\n\n\t\t*event = yaml_event_t{\n\t\t\ttyp:             yaml_SCALAR_EVENT,\n\t\t\tstart_mark:      start_mark,\n\t\t\tend_mark:        end_mark,\n\t\t\tanchor:          anchor,\n\t\t\ttag:             tag,\n\t\t\tvalue:           token.value,\n\t\t\timplicit:        plain_implicit,\n\t\t\tquoted_implicit: quoted_implicit,\n\t\t\tstyle:           yaml_style_t(token.style),\n\t\t}\n\t\tyaml_parser_set_event_comments(parser, event)\n\t\tskip_token(parser)\n\t\treturn true\n\t}\n\tif token.typ == yaml_FLOW_SEQUENCE_START_TOKEN {\n\t\t// [Go] Some of the events below can be merged as they differ only on style.\n\t\tend_mark = token.end_mark\n\t\tparser.state = yaml_PARSE_FLOW_SEQUENCE_FIRST_ENTRY_STATE\n\t\t*event = yaml_event_t{\n\t\t\ttyp:        yaml_SEQUENCE_START_EVENT,\n\t\t\tstart_mark: start_mark,\n\t\t\tend_mark:   end_mark,\n\t\t\tanchor:     anchor,\n\t\t\ttag:        tag,\n\t\t\timplicit:   implicit,\n\t\t\tstyle:      yaml_style_t(yaml_FLOW_SEQUENCE_STYLE),\n\t\t}\n\t\tyaml_parser_set_event_comments(parser, event)\n\t\treturn true\n\t}\n\tif token.typ == yaml_FLOW_MAPPING_START_TOKEN {\n\t\tend_mark = token.end_mark\n\t\tparser.state = yaml_PARSE_FLOW_MAPPING_FIRST_KEY_STATE\n\t\t*event = yaml_event_t{\n\t\t\ttyp:        yaml_MAPPING_START_EVENT,\n\t\t\tstart_mark: start_mark,\n\t\t\tend_mark:   end_mark,\n\t\t\tanchor:     anchor,\n\t\t\ttag:        tag,\n\t\t\timplicit:   implicit,\n\t\t\tstyle:      yaml_style_t(yaml_FLOW_MAPPING_STYLE),\n\t\t}\n\t\tyaml_parser_set_event_comments(parser, event)\n\t\treturn true\n\t}\n\tif block && token.typ == yaml_BLOCK_SEQUENCE_START_TOKEN {\n\t\tend_mark = token.end_mark\n\t\tparser.state = yaml_PARSE_BLOCK_SEQUENCE_FIRST_ENTRY_STATE\n\t\t*event = yaml_event_t{\n\t\t\ttyp:        yaml_SEQUENCE_START_EVENT,\n\t\t\tstart_mark: start_mark,\n\t\t\tend_mark:   end_mark,\n\t\t\tanchor:     anchor,\n\t\t\ttag:        tag,\n\t\t\timplicit:   implicit,\n\t\t\tstyle:      yaml_style_t(yaml_BLOCK_SEQUENCE_STYLE),\n\t\t}\n\t\tif parser.stem_comment != nil {\n\t\t\tevent.head_comment = parser.stem_comment\n\t\t\tparser.stem_comment = nil\n\t\t}\n\t\treturn true\n\t}\n\tif block && token.typ == yaml_BLOCK_MAPPING_START_TOKEN {\n\t\tend_mark = token.end_mark\n\t\tparser.state = yaml_PARSE_BLOCK_MAPPING_FIRST_KEY_STATE\n\t\t*event = yaml_event_t{\n\t\t\ttyp:        yaml_MAPPING_START_EVENT,\n\t\t\tstart_mark: start_mark,\n\t\t\tend_mark:   end_mark,\n\t\t\tanchor:     anchor,\n\t\t\ttag:        tag,\n\t\t\timplicit:   implicit,\n\t\t\tstyle:      yaml_style_t(yaml_BLOCK_MAPPING_STYLE),\n\t\t}\n\t\tif parser.stem_comment != nil {\n\t\t\tevent.head_comment = parser.stem_comment\n\t\t\tparser.stem_comment = nil\n\t\t}\n\t\treturn true\n\t}\n\tif len(anchor) > 0 || len(tag) > 0 {\n\t\tparser.state = parser.states[len(parser.states)-1]\n\t\tparser.states = parser.states[:len(parser.states)-1]\n\n\t\t*event = yaml_event_t{\n\t\t\ttyp:             yaml_SCALAR_EVENT,\n\t\t\tstart_mark:      start_mark,\n\t\t\tend_mark:        end_mark,\n\t\t\tanchor:          anchor,\n\t\t\ttag:             tag,\n\t\t\timplicit:        implicit,\n\t\t\tquoted_implicit: false,\n\t\t\tstyle:           yaml_style_t(yaml_PLAIN_SCALAR_STYLE),\n\t\t}\n\t\treturn true\n\t}\n\n\tcontext := \"while parsing a flow node\"\n\tif block {\n\t\tcontext = \"while parsing a block node\"\n\t}\n\tyaml_parser_set_parser_error_context(parser, context, start_mark,\n\t\t\"did not find expected node content\", token.start_mark)\n\treturn false\n}\n\n// Parse the productions:\n// block_sequence ::= BLOCK-SEQUENCE-START (BLOCK-ENTRY block_node?)* BLOCK-END\n//                    ********************  *********** *             *********\n//\nfunc yaml_parser_parse_block_sequence_entry(parser *yaml_parser_t, event *yaml_event_t, first bool) bool {\n\tif first {\n\t\ttoken := peek_token(parser)\n\t\tif token == nil {\n\t\t\treturn false\n\t\t}\n\t\tparser.marks = append(parser.marks, token.start_mark)\n\t\tskip_token(parser)\n\t}\n\n\ttoken := peek_token(parser)\n\tif token == nil {\n\t\treturn false\n\t}\n\n\tif token.typ == yaml_BLOCK_ENTRY_TOKEN {\n\t\tmark := token.end_mark\n\t\tprior_head_len := len(parser.head_comment)\n\t\tskip_token(parser)\n\t\tyaml_parser_split_stem_comment(parser, prior_head_len)\n\t\ttoken = peek_token(parser)\n\t\tif token == nil {\n\t\t\treturn false\n\t\t}\n\t\tif token.typ != yaml_BLOCK_ENTRY_TOKEN && token.typ != yaml_BLOCK_END_TOKEN {\n\t\t\tparser.states = append(parser.states, yaml_PARSE_BLOCK_SEQUENCE_ENTRY_STATE)\n\t\t\treturn yaml_parser_parse_node(parser, event, true, false)\n\t\t} else {\n\t\t\tparser.state = yaml_PARSE_BLOCK_SEQUENCE_ENTRY_STATE\n\t\t\treturn yaml_parser_process_empty_scalar(parser, event, mark)\n\t\t}\n\t}\n\tif token.typ == yaml_BLOCK_END_TOKEN {\n\t\tparser.state = parser.states[len(parser.states)-1]\n\t\tparser.states = parser.states[:len(parser.states)-1]\n\t\tparser.marks = parser.marks[:len(parser.marks)-1]\n\n\t\t*event = yaml_event_t{\n\t\t\ttyp:        yaml_SEQUENCE_END_EVENT,\n\t\t\tstart_mark: token.start_mark,\n\t\t\tend_mark:   token.end_mark,\n\t\t}\n\n\t\tskip_token(parser)\n\t\treturn true\n\t}\n\n\tcontext_mark := parser.marks[len(parser.marks)-1]\n\tparser.marks = parser.marks[:len(parser.marks)-1]\n\treturn yaml_parser_set_parser_error_context(parser,\n\t\t\"while parsing a block collection\", context_mark,\n\t\t\"did not find expected '-' indicator\", token.start_mark)\n}\n\n// Parse the productions:\n// indentless_sequence  ::= (BLOCK-ENTRY block_node?)+\n//                           *********** *\nfunc yaml_parser_parse_indentless_sequence_entry(parser *yaml_parser_t, event *yaml_event_t) bool {\n\ttoken := peek_token(parser)\n\tif token == nil {\n\t\treturn false\n\t}\n\n\tif token.typ == yaml_BLOCK_ENTRY_TOKEN {\n\t\tmark := token.end_mark\n\t\tprior_head_len := len(parser.head_comment)\n\t\tskip_token(parser)\n\t\tyaml_parser_split_stem_comment(parser, prior_head_len)\n\t\ttoken = peek_token(parser)\n\t\tif token == nil {\n\t\t\treturn false\n\t\t}\n\t\tif token.typ != yaml_BLOCK_ENTRY_TOKEN &&\n\t\t\ttoken.typ != yaml_KEY_TOKEN &&\n\t\t\ttoken.typ != yaml_VALUE_TOKEN &&\n\t\t\ttoken.typ != yaml_BLOCK_END_TOKEN {\n\t\t\tparser.states = append(parser.states, yaml_PARSE_INDENTLESS_SEQUENCE_ENTRY_STATE)\n\t\t\treturn yaml_parser_parse_node(parser, event, true, false)\n\t\t}\n\t\tparser.state = yaml_PARSE_INDENTLESS_SEQUENCE_ENTRY_STATE\n\t\treturn yaml_parser_process_empty_scalar(parser, event, mark)\n\t}\n\tparser.state = parser.states[len(parser.states)-1]\n\tparser.states = parser.states[:len(parser.states)-1]\n\n\t*event = yaml_event_t{\n\t\ttyp:        yaml_SEQUENCE_END_EVENT,\n\t\tstart_mark: token.start_mark,\n\t\tend_mark:   token.start_mark, // [Go] Shouldn't this be token.end_mark?\n\t}\n\treturn true\n}\n\n// Split stem comment from head comment.\n//\n// When a sequence or map is found under a sequence entry, the former head comment\n// is assigned to the underlying sequence or map as a whole, not the individual\n// sequence or map entry as would be expected otherwise. To handle this case the\n// previous head comment is moved aside as the stem comment.\nfunc yaml_parser_split_stem_comment(parser *yaml_parser_t, stem_len int) {\n\tif stem_len == 0 {\n\t\treturn\n\t}\n\n\ttoken := peek_token(parser)\n\tif token == nil || token.typ != yaml_BLOCK_SEQUENCE_START_TOKEN && token.typ != yaml_BLOCK_MAPPING_START_TOKEN {\n\t\treturn\n\t}\n\n\tparser.stem_comment = parser.head_comment[:stem_len]\n\tif len(parser.head_comment) == stem_len {\n\t\tparser.head_comment = nil\n\t} else {\n\t\t// Copy suffix to prevent very strange bugs if someone ever appends\n\t\t// further bytes to the prefix in the stem_comment slice above.\n\t\tparser.head_comment = append([]byte(nil), parser.head_comment[stem_len+1:]...)\n\t}\n}\n\n// Parse the productions:\n// block_mapping        ::= BLOCK-MAPPING_START\n//                          *******************\n//                          ((KEY block_node_or_indentless_sequence?)?\n//                            *** *\n//                          (VALUE block_node_or_indentless_sequence?)?)*\n//\n//                          BLOCK-END\n//                          *********\n//\nfunc yaml_parser_parse_block_mapping_key(parser *yaml_parser_t, event *yaml_event_t, first bool) bool {\n\tif first {\n\t\ttoken := peek_token(parser)\n\t\tif token == nil {\n\t\t\treturn false\n\t\t}\n\t\tparser.marks = append(parser.marks, token.start_mark)\n\t\tskip_token(parser)\n\t}\n\n\ttoken := peek_token(parser)\n\tif token == nil {\n\t\treturn false\n\t}\n\n\t// [Go] A tail comment was left from the prior mapping value processed. Emit an event\n\t//      as it needs to be processed with that value and not the following key.\n\tif len(parser.tail_comment) > 0 {\n\t\t*event = yaml_event_t{\n\t\t\ttyp:          yaml_TAIL_COMMENT_EVENT,\n\t\t\tstart_mark:   token.start_mark,\n\t\t\tend_mark:     token.end_mark,\n\t\t\tfoot_comment: parser.tail_comment,\n\t\t}\n\t\tparser.tail_comment = nil\n\t\treturn true\n\t}\n\n\tif token.typ == yaml_KEY_TOKEN {\n\t\tmark := token.end_mark\n\t\tskip_token(parser)\n\t\ttoken = peek_token(parser)\n\t\tif token == nil {\n\t\t\treturn false\n\t\t}\n\t\tif token.typ != yaml_KEY_TOKEN &&\n\t\t\ttoken.typ != yaml_VALUE_TOKEN &&\n\t\t\ttoken.typ != yaml_BLOCK_END_TOKEN {\n\t\t\tparser.states = append(parser.states, yaml_PARSE_BLOCK_MAPPING_VALUE_STATE)\n\t\t\treturn yaml_parser_parse_node(parser, event, true, true)\n\t\t} else {\n\t\t\tparser.state = yaml_PARSE_BLOCK_MAPPING_VALUE_STATE\n\t\t\treturn yaml_parser_process_empty_scalar(parser, event, mark)\n\t\t}\n\t} else if token.typ == yaml_BLOCK_END_TOKEN {\n\t\tparser.state = parser.states[len(parser.states)-1]\n\t\tparser.states = parser.states[:len(parser.states)-1]\n\t\tparser.marks = parser.marks[:len(parser.marks)-1]\n\t\t*event = yaml_event_t{\n\t\t\ttyp:        yaml_MAPPING_END_EVENT,\n\t\t\tstart_mark: token.start_mark,\n\t\t\tend_mark:   token.end_mark,\n\t\t}\n\t\tyaml_parser_set_event_comments(parser, event)\n\t\tskip_token(parser)\n\t\treturn true\n\t}\n\n\tcontext_mark := parser.marks[len(parser.marks)-1]\n\tparser.marks = parser.marks[:len(parser.marks)-1]\n\treturn yaml_parser_set_parser_error_context(parser,\n\t\t\"while parsing a block mapping\", context_mark,\n\t\t\"did not find expected key\", token.start_mark)\n}\n\n// Parse the productions:\n// block_mapping        ::= BLOCK-MAPPING_START\n//\n//                          ((KEY block_node_or_indentless_sequence?)?\n//\n//                          (VALUE block_node_or_indentless_sequence?)?)*\n//                           ***** *\n//                          BLOCK-END\n//\n//\nfunc yaml_parser_parse_block_mapping_value(parser *yaml_parser_t, event *yaml_event_t) bool {\n\ttoken := peek_token(parser)\n\tif token == nil {\n\t\treturn false\n\t}\n\tif token.typ == yaml_VALUE_TOKEN {\n\t\tmark := token.end_mark\n\t\tskip_token(parser)\n\t\ttoken = peek_token(parser)\n\t\tif token == nil {\n\t\t\treturn false\n\t\t}\n\t\tif token.typ != yaml_KEY_TOKEN &&\n\t\t\ttoken.typ != yaml_VALUE_TOKEN &&\n\t\t\ttoken.typ != yaml_BLOCK_END_TOKEN {\n\t\t\tparser.states = append(parser.states, yaml_PARSE_BLOCK_MAPPING_KEY_STATE)\n\t\t\treturn yaml_parser_parse_node(parser, event, true, true)\n\t\t}\n\t\tparser.state = yaml_PARSE_BLOCK_MAPPING_KEY_STATE\n\t\treturn yaml_parser_process_empty_scalar(parser, event, mark)\n\t}\n\tparser.state = yaml_PARSE_BLOCK_MAPPING_KEY_STATE\n\treturn yaml_parser_process_empty_scalar(parser, event, token.start_mark)\n}\n\n// Parse the productions:\n// flow_sequence        ::= FLOW-SEQUENCE-START\n//                          *******************\n//                          (flow_sequence_entry FLOW-ENTRY)*\n//                           *                   **********\n//                          flow_sequence_entry?\n//                          *\n//                          FLOW-SEQUENCE-END\n//                          *****************\n// flow_sequence_entry  ::= flow_node | KEY flow_node? (VALUE flow_node?)?\n//                          *\n//\nfunc yaml_parser_parse_flow_sequence_entry(parser *yaml_parser_t, event *yaml_event_t, first bool) bool {\n\tif first {\n\t\ttoken := peek_token(parser)\n\t\tif token == nil {\n\t\t\treturn false\n\t\t}\n\t\tparser.marks = append(parser.marks, token.start_mark)\n\t\tskip_token(parser)\n\t}\n\ttoken := peek_token(parser)\n\tif token == nil {\n\t\treturn false\n\t}\n\tif token.typ != yaml_FLOW_SEQUENCE_END_TOKEN {\n\t\tif !first {\n\t\t\tif token.typ == yaml_FLOW_ENTRY_TOKEN {\n\t\t\t\tskip_token(parser)\n\t\t\t\ttoken = peek_token(parser)\n\t\t\t\tif token == nil {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tcontext_mark := parser.marks[len(parser.marks)-1]\n\t\t\t\tparser.marks = parser.marks[:len(parser.marks)-1]\n\t\t\t\treturn yaml_parser_set_parser_error_context(parser,\n\t\t\t\t\t\"while parsing a flow sequence\", context_mark,\n\t\t\t\t\t\"did not find expected ',' or ']'\", token.start_mark)\n\t\t\t}\n\t\t}\n\n\t\tif token.typ == yaml_KEY_TOKEN {\n\t\t\tparser.state = yaml_PARSE_FLOW_SEQUENCE_ENTRY_MAPPING_KEY_STATE\n\t\t\t*event = yaml_event_t{\n\t\t\t\ttyp:        yaml_MAPPING_START_EVENT,\n\t\t\t\tstart_mark: token.start_mark,\n\t\t\t\tend_mark:   token.end_mark,\n\t\t\t\timplicit:   true,\n\t\t\t\tstyle:      yaml_style_t(yaml_FLOW_MAPPING_STYLE),\n\t\t\t}\n\t\t\tskip_token(parser)\n\t\t\treturn true\n\t\t} else if token.typ != yaml_FLOW_SEQUENCE_END_TOKEN {\n\t\t\tparser.states = append(parser.states, yaml_PARSE_FLOW_SEQUENCE_ENTRY_STATE)\n\t\t\treturn yaml_parser_parse_node(parser, event, false, false)\n\t\t}\n\t}\n\n\tparser.state = parser.states[len(parser.states)-1]\n\tparser.states = parser.states[:len(parser.states)-1]\n\tparser.marks = parser.marks[:len(parser.marks)-1]\n\n\t*event = yaml_event_t{\n\t\ttyp:        yaml_SEQUENCE_END_EVENT,\n\t\tstart_mark: token.start_mark,\n\t\tend_mark:   token.end_mark,\n\t}\n\tyaml_parser_set_event_comments(parser, event)\n\n\tskip_token(parser)\n\treturn true\n}\n\n//\n// Parse the productions:\n// flow_sequence_entry  ::= flow_node | KEY flow_node? (VALUE flow_node?)?\n//                                      *** *\n//\nfunc yaml_parser_parse_flow_sequence_entry_mapping_key(parser *yaml_parser_t, event *yaml_event_t) bool {\n\ttoken := peek_token(parser)\n\tif token == nil {\n\t\treturn false\n\t}\n\tif token.typ != yaml_VALUE_TOKEN &&\n\t\ttoken.typ != yaml_FLOW_ENTRY_TOKEN &&\n\t\ttoken.typ != yaml_FLOW_SEQUENCE_END_TOKEN {\n\t\tparser.states = append(parser.states, yaml_PARSE_FLOW_SEQUENCE_ENTRY_MAPPING_VALUE_STATE)\n\t\treturn yaml_parser_parse_node(parser, event, false, false)\n\t}\n\tmark := token.end_mark\n\tskip_token(parser)\n\tparser.state = yaml_PARSE_FLOW_SEQUENCE_ENTRY_MAPPING_VALUE_STATE\n\treturn yaml_parser_process_empty_scalar(parser, event, mark)\n}\n\n// Parse the productions:\n// flow_sequence_entry  ::= flow_node | KEY flow_node? (VALUE flow_node?)?\n//                                                      ***** *\n//\nfunc yaml_parser_parse_flow_sequence_entry_mapping_value(parser *yaml_parser_t, event *yaml_event_t) bool {\n\ttoken := peek_token(parser)\n\tif token == nil {\n\t\treturn false\n\t}\n\tif token.typ == yaml_VALUE_TOKEN {\n\t\tskip_token(parser)\n\t\ttoken := peek_token(parser)\n\t\tif token == nil {\n\t\t\treturn false\n\t\t}\n\t\tif token.typ != yaml_FLOW_ENTRY_TOKEN && token.typ != yaml_FLOW_SEQUENCE_END_TOKEN {\n\t\t\tparser.states = append(parser.states, yaml_PARSE_FLOW_SEQUENCE_ENTRY_MAPPING_END_STATE)\n\t\t\treturn yaml_parser_parse_node(parser, event, false, false)\n\t\t}\n\t}\n\tparser.state = yaml_PARSE_FLOW_SEQUENCE_ENTRY_MAPPING_END_STATE\n\treturn yaml_parser_process_empty_scalar(parser, event, token.start_mark)\n}\n\n// Parse the productions:\n// flow_sequence_entry  ::= flow_node | KEY flow_node? (VALUE flow_node?)?\n//                                                                      *\n//\nfunc yaml_parser_parse_flow_sequence_entry_mapping_end(parser *yaml_parser_t, event *yaml_event_t) bool {\n\ttoken := peek_token(parser)\n\tif token == nil {\n\t\treturn false\n\t}\n\tparser.state = yaml_PARSE_FLOW_SEQUENCE_ENTRY_STATE\n\t*event = yaml_event_t{\n\t\ttyp:        yaml_MAPPING_END_EVENT,\n\t\tstart_mark: token.start_mark,\n\t\tend_mark:   token.start_mark, // [Go] Shouldn't this be end_mark?\n\t}\n\treturn true\n}\n\n// Parse the productions:\n// flow_mapping         ::= FLOW-MAPPING-START\n//                          ******************\n//                          (flow_mapping_entry FLOW-ENTRY)*\n//                           *                  **********\n//                          flow_mapping_entry?\n//                          ******************\n//                          FLOW-MAPPING-END\n//                          ****************\n// flow_mapping_entry   ::= flow_node | KEY flow_node? (VALUE flow_node?)?\n//                          *           *** *\n//\nfunc yaml_parser_parse_flow_mapping_key(parser *yaml_parser_t, event *yaml_event_t, first bool) bool {\n\tif first {\n\t\ttoken := peek_token(parser)\n\t\tparser.marks = append(parser.marks, token.start_mark)\n\t\tskip_token(parser)\n\t}\n\n\ttoken := peek_token(parser)\n\tif token == nil {\n\t\treturn false\n\t}\n\n\tif token.typ != yaml_FLOW_MAPPING_END_TOKEN {\n\t\tif !first {\n\t\t\tif token.typ == yaml_FLOW_ENTRY_TOKEN {\n\t\t\t\tskip_token(parser)\n\t\t\t\ttoken = peek_token(parser)\n\t\t\t\tif token == nil {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tcontext_mark := parser.marks[len(parser.marks)-1]\n\t\t\t\tparser.marks = parser.marks[:len(parser.marks)-1]\n\t\t\t\treturn yaml_parser_set_parser_error_context(parser,\n\t\t\t\t\t\"while parsing a flow mapping\", context_mark,\n\t\t\t\t\t\"did not find expected ',' or '}'\", token.start_mark)\n\t\t\t}\n\t\t}\n\n\t\tif token.typ == yaml_KEY_TOKEN {\n\t\t\tskip_token(parser)\n\t\t\ttoken = peek_token(parser)\n\t\t\tif token == nil {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tif token.typ != yaml_VALUE_TOKEN &&\n\t\t\t\ttoken.typ != yaml_FLOW_ENTRY_TOKEN &&\n\t\t\t\ttoken.typ != yaml_FLOW_MAPPING_END_TOKEN {\n\t\t\t\tparser.states = append(parser.states, yaml_PARSE_FLOW_MAPPING_VALUE_STATE)\n\t\t\t\treturn yaml_parser_parse_node(parser, event, false, false)\n\t\t\t} else {\n\t\t\t\tparser.state = yaml_PARSE_FLOW_MAPPING_VALUE_STATE\n\t\t\t\treturn yaml_parser_process_empty_scalar(parser, event, token.start_mark)\n\t\t\t}\n\t\t} else if token.typ != yaml_FLOW_MAPPING_END_TOKEN {\n\t\t\tparser.states = append(parser.states, yaml_PARSE_FLOW_MAPPING_EMPTY_VALUE_STATE)\n\t\t\treturn yaml_parser_parse_node(parser, event, false, false)\n\t\t}\n\t}\n\n\tparser.state = parser.states[len(parser.states)-1]\n\tparser.states = parser.states[:len(parser.states)-1]\n\tparser.marks = parser.marks[:len(parser.marks)-1]\n\t*event = yaml_event_t{\n\t\ttyp:        yaml_MAPPING_END_EVENT,\n\t\tstart_mark: token.start_mark,\n\t\tend_mark:   token.end_mark,\n\t}\n\tyaml_parser_set_event_comments(parser, event)\n\tskip_token(parser)\n\treturn true\n}\n\n// Parse the productions:\n// flow_mapping_entry   ::= flow_node | KEY flow_node? (VALUE flow_node?)?\n//                                   *                  ***** *\n//\nfunc yaml_parser_parse_flow_mapping_value(parser *yaml_parser_t, event *yaml_event_t, empty bool) bool {\n\ttoken := peek_token(parser)\n\tif token == nil {\n\t\treturn false\n\t}\n\tif empty {\n\t\tparser.state = yaml_PARSE_FLOW_MAPPING_KEY_STATE\n\t\treturn yaml_parser_process_empty_scalar(parser, event, token.start_mark)\n\t}\n\tif token.typ == yaml_VALUE_TOKEN {\n\t\tskip_token(parser)\n\t\ttoken = peek_token(parser)\n\t\tif token == nil {\n\t\t\treturn false\n\t\t}\n\t\tif token.typ != yaml_FLOW_ENTRY_TOKEN && token.typ != yaml_FLOW_MAPPING_END_TOKEN {\n\t\t\tparser.states = append(parser.states, yaml_PARSE_FLOW_MAPPING_KEY_STATE)\n\t\t\treturn yaml_parser_parse_node(parser, event, false, false)\n\t\t}\n\t}\n\tparser.state = yaml_PARSE_FLOW_MAPPING_KEY_STATE\n\treturn yaml_parser_process_empty_scalar(parser, event, token.start_mark)\n}\n\n// Generate an empty scalar event.\nfunc yaml_parser_process_empty_scalar(parser *yaml_parser_t, event *yaml_event_t, mark yaml_mark_t) bool {\n\t*event = yaml_event_t{\n\t\ttyp:        yaml_SCALAR_EVENT,\n\t\tstart_mark: mark,\n\t\tend_mark:   mark,\n\t\tvalue:      nil, // Empty\n\t\timplicit:   true,\n\t\tstyle:      yaml_style_t(yaml_PLAIN_SCALAR_STYLE),\n\t}\n\treturn true\n}\n\nvar default_tag_directives = []yaml_tag_directive_t{\n\t{[]byte(\"!\"), []byte(\"!\")},\n\t{[]byte(\"!!\"), []byte(\"tag:yaml.org,2002:\")},\n}\n\n// Parse directives.\nfunc yaml_parser_process_directives(parser *yaml_parser_t,\n\tversion_directive_ref **yaml_version_directive_t,\n\ttag_directives_ref *[]yaml_tag_directive_t) bool {\n\n\tvar version_directive *yaml_version_directive_t\n\tvar tag_directives []yaml_tag_directive_t\n\n\ttoken := peek_token(parser)\n\tif token == nil {\n\t\treturn false\n\t}\n\n\tfor token.typ == yaml_VERSION_DIRECTIVE_TOKEN || token.typ == yaml_TAG_DIRECTIVE_TOKEN {\n\t\tif token.typ == yaml_VERSION_DIRECTIVE_TOKEN {\n\t\t\tif version_directive != nil {\n\t\t\t\tyaml_parser_set_parser_error(parser,\n\t\t\t\t\t\"found duplicate %YAML directive\", token.start_mark)\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tif token.major != 1 || token.minor != 1 {\n\t\t\t\tyaml_parser_set_parser_error(parser,\n\t\t\t\t\t\"found incompatible YAML document\", token.start_mark)\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tversion_directive = &yaml_version_directive_t{\n\t\t\t\tmajor: token.major,\n\t\t\t\tminor: token.minor,\n\t\t\t}\n\t\t} else if token.typ == yaml_TAG_DIRECTIVE_TOKEN {\n\t\t\tvalue := yaml_tag_directive_t{\n\t\t\t\thandle: token.value,\n\t\t\t\tprefix: token.prefix,\n\t\t\t}\n\t\t\tif !yaml_parser_append_tag_directive(parser, value, false, token.start_mark) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\ttag_directives = append(tag_directives, value)\n\t\t}\n\n\t\tskip_token(parser)\n\t\ttoken = peek_token(parser)\n\t\tif token == nil {\n\t\t\treturn false\n\t\t}\n\t}\n\n\tfor i := range default_tag_directives {\n\t\tif !yaml_parser_append_tag_directive(parser, default_tag_directives[i], true, token.start_mark) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\tif version_directive_ref != nil {\n\t\t*version_directive_ref = version_directive\n\t}\n\tif tag_directives_ref != nil {\n\t\t*tag_directives_ref = tag_directives\n\t}\n\treturn true\n}\n\n// Append a tag directive to the directives stack.\nfunc yaml_parser_append_tag_directive(parser *yaml_parser_t, value yaml_tag_directive_t, allow_duplicates bool, mark yaml_mark_t) bool {\n\tfor i := range parser.tag_directives {\n\t\tif bytes.Equal(value.handle, parser.tag_directives[i].handle) {\n\t\t\tif allow_duplicates {\n\t\t\t\treturn true\n\t\t\t}\n\t\t\treturn yaml_parser_set_parser_error(parser, \"found duplicate %TAG directive\", mark)\n\t\t}\n\t}\n\n\t// [Go] I suspect the copy is unnecessary. This was likely done\n\t// because there was no way to track ownership of the data.\n\tvalue_copy := yaml_tag_directive_t{\n\t\thandle: make([]byte, len(value.handle)),\n\t\tprefix: make([]byte, len(value.prefix)),\n\t}\n\tcopy(value_copy.handle, value.handle)\n\tcopy(value_copy.prefix, value.prefix)\n\tparser.tag_directives = append(parser.tag_directives, value_copy)\n\treturn true\n}\n"
        },
        {
          "name": "readerc.go",
          "type": "blob",
          "size": 13.7587890625,
          "content": "// \n// Copyright (c) 2011-2019 Canonical Ltd\n// Copyright (c) 2006-2010 Kirill Simonov\n// \n// Permission is hereby granted, free of charge, to any person obtaining a copy of\n// this software and associated documentation files (the \"Software\"), to deal in\n// the Software without restriction, including without limitation the rights to\n// use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\n// of the Software, and to permit persons to whom the Software is furnished to do\n// so, subject to the following conditions:\n// \n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n// \n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\npackage yaml\n\nimport (\n\t\"io\"\n)\n\n// Set the reader error and return 0.\nfunc yaml_parser_set_reader_error(parser *yaml_parser_t, problem string, offset int, value int) bool {\n\tparser.error = yaml_READER_ERROR\n\tparser.problem = problem\n\tparser.problem_offset = offset\n\tparser.problem_value = value\n\treturn false\n}\n\n// Byte order marks.\nconst (\n\tbom_UTF8    = \"\\xef\\xbb\\xbf\"\n\tbom_UTF16LE = \"\\xff\\xfe\"\n\tbom_UTF16BE = \"\\xfe\\xff\"\n)\n\n// Determine the input stream encoding by checking the BOM symbol. If no BOM is\n// found, the UTF-8 encoding is assumed. Return 1 on success, 0 on failure.\nfunc yaml_parser_determine_encoding(parser *yaml_parser_t) bool {\n\t// Ensure that we had enough bytes in the raw buffer.\n\tfor !parser.eof && len(parser.raw_buffer)-parser.raw_buffer_pos < 3 {\n\t\tif !yaml_parser_update_raw_buffer(parser) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Determine the encoding.\n\tbuf := parser.raw_buffer\n\tpos := parser.raw_buffer_pos\n\tavail := len(buf) - pos\n\tif avail >= 2 && buf[pos] == bom_UTF16LE[0] && buf[pos+1] == bom_UTF16LE[1] {\n\t\tparser.encoding = yaml_UTF16LE_ENCODING\n\t\tparser.raw_buffer_pos += 2\n\t\tparser.offset += 2\n\t} else if avail >= 2 && buf[pos] == bom_UTF16BE[0] && buf[pos+1] == bom_UTF16BE[1] {\n\t\tparser.encoding = yaml_UTF16BE_ENCODING\n\t\tparser.raw_buffer_pos += 2\n\t\tparser.offset += 2\n\t} else if avail >= 3 && buf[pos] == bom_UTF8[0] && buf[pos+1] == bom_UTF8[1] && buf[pos+2] == bom_UTF8[2] {\n\t\tparser.encoding = yaml_UTF8_ENCODING\n\t\tparser.raw_buffer_pos += 3\n\t\tparser.offset += 3\n\t} else {\n\t\tparser.encoding = yaml_UTF8_ENCODING\n\t}\n\treturn true\n}\n\n// Update the raw buffer.\nfunc yaml_parser_update_raw_buffer(parser *yaml_parser_t) bool {\n\tsize_read := 0\n\n\t// Return if the raw buffer is full.\n\tif parser.raw_buffer_pos == 0 && len(parser.raw_buffer) == cap(parser.raw_buffer) {\n\t\treturn true\n\t}\n\n\t// Return on EOF.\n\tif parser.eof {\n\t\treturn true\n\t}\n\n\t// Move the remaining bytes in the raw buffer to the beginning.\n\tif parser.raw_buffer_pos > 0 && parser.raw_buffer_pos < len(parser.raw_buffer) {\n\t\tcopy(parser.raw_buffer, parser.raw_buffer[parser.raw_buffer_pos:])\n\t}\n\tparser.raw_buffer = parser.raw_buffer[:len(parser.raw_buffer)-parser.raw_buffer_pos]\n\tparser.raw_buffer_pos = 0\n\n\t// Call the read handler to fill the buffer.\n\tsize_read, err := parser.read_handler(parser, parser.raw_buffer[len(parser.raw_buffer):cap(parser.raw_buffer)])\n\tparser.raw_buffer = parser.raw_buffer[:len(parser.raw_buffer)+size_read]\n\tif err == io.EOF {\n\t\tparser.eof = true\n\t} else if err != nil {\n\t\treturn yaml_parser_set_reader_error(parser, \"input error: \"+err.Error(), parser.offset, -1)\n\t}\n\treturn true\n}\n\n// Ensure that the buffer contains at least `length` characters.\n// Return true on success, false on failure.\n//\n// The length is supposed to be significantly less that the buffer size.\nfunc yaml_parser_update_buffer(parser *yaml_parser_t, length int) bool {\n\tif parser.read_handler == nil {\n\t\tpanic(\"read handler must be set\")\n\t}\n\n\t// [Go] This function was changed to guarantee the requested length size at EOF.\n\t// The fact we need to do this is pretty awful, but the description above implies\n\t// for that to be the case, and there are tests\n\n\t// If the EOF flag is set and the raw buffer is empty, do nothing.\n\tif parser.eof && parser.raw_buffer_pos == len(parser.raw_buffer) {\n\t\t// [Go] ACTUALLY! Read the documentation of this function above.\n\t\t// This is just broken. To return true, we need to have the\n\t\t// given length in the buffer. Not doing that means every single\n\t\t// check that calls this function to make sure the buffer has a\n\t\t// given length is Go) panicking; or C) accessing invalid memory.\n\t\t//return true\n\t}\n\n\t// Return if the buffer contains enough characters.\n\tif parser.unread >= length {\n\t\treturn true\n\t}\n\n\t// Determine the input encoding if it is not known yet.\n\tif parser.encoding == yaml_ANY_ENCODING {\n\t\tif !yaml_parser_determine_encoding(parser) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Move the unread characters to the beginning of the buffer.\n\tbuffer_len := len(parser.buffer)\n\tif parser.buffer_pos > 0 && parser.buffer_pos < buffer_len {\n\t\tcopy(parser.buffer, parser.buffer[parser.buffer_pos:])\n\t\tbuffer_len -= parser.buffer_pos\n\t\tparser.buffer_pos = 0\n\t} else if parser.buffer_pos == buffer_len {\n\t\tbuffer_len = 0\n\t\tparser.buffer_pos = 0\n\t}\n\n\t// Open the whole buffer for writing, and cut it before returning.\n\tparser.buffer = parser.buffer[:cap(parser.buffer)]\n\n\t// Fill the buffer until it has enough characters.\n\tfirst := true\n\tfor parser.unread < length {\n\n\t\t// Fill the raw buffer if necessary.\n\t\tif !first || parser.raw_buffer_pos == len(parser.raw_buffer) {\n\t\t\tif !yaml_parser_update_raw_buffer(parser) {\n\t\t\t\tparser.buffer = parser.buffer[:buffer_len]\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\tfirst = false\n\n\t\t// Decode the raw buffer.\n\tinner:\n\t\tfor parser.raw_buffer_pos != len(parser.raw_buffer) {\n\t\t\tvar value rune\n\t\t\tvar width int\n\n\t\t\traw_unread := len(parser.raw_buffer) - parser.raw_buffer_pos\n\n\t\t\t// Decode the next character.\n\t\t\tswitch parser.encoding {\n\t\t\tcase yaml_UTF8_ENCODING:\n\t\t\t\t// Decode a UTF-8 character.  Check RFC 3629\n\t\t\t\t// (http://www.ietf.org/rfc/rfc3629.txt) for more details.\n\t\t\t\t//\n\t\t\t\t// The following table (taken from the RFC) is used for\n\t\t\t\t// decoding.\n\t\t\t\t//\n\t\t\t\t//    Char. number range |        UTF-8 octet sequence\n\t\t\t\t//      (hexadecimal)    |              (binary)\n\t\t\t\t//   --------------------+------------------------------------\n\t\t\t\t//   0000 0000-0000 007F | 0xxxxxxx\n\t\t\t\t//   0000 0080-0000 07FF | 110xxxxx 10xxxxxx\n\t\t\t\t//   0000 0800-0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx\n\t\t\t\t//   0001 0000-0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx\n\t\t\t\t//\n\t\t\t\t// Additionally, the characters in the range 0xD800-0xDFFF\n\t\t\t\t// are prohibited as they are reserved for use with UTF-16\n\t\t\t\t// surrogate pairs.\n\n\t\t\t\t// Determine the length of the UTF-8 sequence.\n\t\t\t\toctet := parser.raw_buffer[parser.raw_buffer_pos]\n\t\t\t\tswitch {\n\t\t\t\tcase octet&0x80 == 0x00:\n\t\t\t\t\twidth = 1\n\t\t\t\tcase octet&0xE0 == 0xC0:\n\t\t\t\t\twidth = 2\n\t\t\t\tcase octet&0xF0 == 0xE0:\n\t\t\t\t\twidth = 3\n\t\t\t\tcase octet&0xF8 == 0xF0:\n\t\t\t\t\twidth = 4\n\t\t\t\tdefault:\n\t\t\t\t\t// The leading octet is invalid.\n\t\t\t\t\treturn yaml_parser_set_reader_error(parser,\n\t\t\t\t\t\t\"invalid leading UTF-8 octet\",\n\t\t\t\t\t\tparser.offset, int(octet))\n\t\t\t\t}\n\n\t\t\t\t// Check if the raw buffer contains an incomplete character.\n\t\t\t\tif width > raw_unread {\n\t\t\t\t\tif parser.eof {\n\t\t\t\t\t\treturn yaml_parser_set_reader_error(parser,\n\t\t\t\t\t\t\t\"incomplete UTF-8 octet sequence\",\n\t\t\t\t\t\t\tparser.offset, -1)\n\t\t\t\t\t}\n\t\t\t\t\tbreak inner\n\t\t\t\t}\n\n\t\t\t\t// Decode the leading octet.\n\t\t\t\tswitch {\n\t\t\t\tcase octet&0x80 == 0x00:\n\t\t\t\t\tvalue = rune(octet & 0x7F)\n\t\t\t\tcase octet&0xE0 == 0xC0:\n\t\t\t\t\tvalue = rune(octet & 0x1F)\n\t\t\t\tcase octet&0xF0 == 0xE0:\n\t\t\t\t\tvalue = rune(octet & 0x0F)\n\t\t\t\tcase octet&0xF8 == 0xF0:\n\t\t\t\t\tvalue = rune(octet & 0x07)\n\t\t\t\tdefault:\n\t\t\t\t\tvalue = 0\n\t\t\t\t}\n\n\t\t\t\t// Check and decode the trailing octets.\n\t\t\t\tfor k := 1; k < width; k++ {\n\t\t\t\t\toctet = parser.raw_buffer[parser.raw_buffer_pos+k]\n\n\t\t\t\t\t// Check if the octet is valid.\n\t\t\t\t\tif (octet & 0xC0) != 0x80 {\n\t\t\t\t\t\treturn yaml_parser_set_reader_error(parser,\n\t\t\t\t\t\t\t\"invalid trailing UTF-8 octet\",\n\t\t\t\t\t\t\tparser.offset+k, int(octet))\n\t\t\t\t\t}\n\n\t\t\t\t\t// Decode the octet.\n\t\t\t\t\tvalue = (value << 6) + rune(octet&0x3F)\n\t\t\t\t}\n\n\t\t\t\t// Check the length of the sequence against the value.\n\t\t\t\tswitch {\n\t\t\t\tcase width == 1:\n\t\t\t\tcase width == 2 && value >= 0x80:\n\t\t\t\tcase width == 3 && value >= 0x800:\n\t\t\t\tcase width == 4 && value >= 0x10000:\n\t\t\t\tdefault:\n\t\t\t\t\treturn yaml_parser_set_reader_error(parser,\n\t\t\t\t\t\t\"invalid length of a UTF-8 sequence\",\n\t\t\t\t\t\tparser.offset, -1)\n\t\t\t\t}\n\n\t\t\t\t// Check the range of the value.\n\t\t\t\tif value >= 0xD800 && value <= 0xDFFF || value > 0x10FFFF {\n\t\t\t\t\treturn yaml_parser_set_reader_error(parser,\n\t\t\t\t\t\t\"invalid Unicode character\",\n\t\t\t\t\t\tparser.offset, int(value))\n\t\t\t\t}\n\n\t\t\tcase yaml_UTF16LE_ENCODING, yaml_UTF16BE_ENCODING:\n\t\t\t\tvar low, high int\n\t\t\t\tif parser.encoding == yaml_UTF16LE_ENCODING {\n\t\t\t\t\tlow, high = 0, 1\n\t\t\t\t} else {\n\t\t\t\t\tlow, high = 1, 0\n\t\t\t\t}\n\n\t\t\t\t// The UTF-16 encoding is not as simple as one might\n\t\t\t\t// naively think.  Check RFC 2781\n\t\t\t\t// (http://www.ietf.org/rfc/rfc2781.txt).\n\t\t\t\t//\n\t\t\t\t// Normally, two subsequent bytes describe a Unicode\n\t\t\t\t// character.  However a special technique (called a\n\t\t\t\t// surrogate pair) is used for specifying character\n\t\t\t\t// values larger than 0xFFFF.\n\t\t\t\t//\n\t\t\t\t// A surrogate pair consists of two pseudo-characters:\n\t\t\t\t//      high surrogate area (0xD800-0xDBFF)\n\t\t\t\t//      low surrogate area (0xDC00-0xDFFF)\n\t\t\t\t//\n\t\t\t\t// The following formulas are used for decoding\n\t\t\t\t// and encoding characters using surrogate pairs:\n\t\t\t\t//\n\t\t\t\t//  U  = U' + 0x10000   (0x01 00 00 <= U <= 0x10 FF FF)\n\t\t\t\t//  U' = yyyyyyyyyyxxxxxxxxxx   (0 <= U' <= 0x0F FF FF)\n\t\t\t\t//  W1 = 110110yyyyyyyyyy\n\t\t\t\t//  W2 = 110111xxxxxxxxxx\n\t\t\t\t//\n\t\t\t\t// where U is the character value, W1 is the high surrogate\n\t\t\t\t// area, W2 is the low surrogate area.\n\n\t\t\t\t// Check for incomplete UTF-16 character.\n\t\t\t\tif raw_unread < 2 {\n\t\t\t\t\tif parser.eof {\n\t\t\t\t\t\treturn yaml_parser_set_reader_error(parser,\n\t\t\t\t\t\t\t\"incomplete UTF-16 character\",\n\t\t\t\t\t\t\tparser.offset, -1)\n\t\t\t\t\t}\n\t\t\t\t\tbreak inner\n\t\t\t\t}\n\n\t\t\t\t// Get the character.\n\t\t\t\tvalue = rune(parser.raw_buffer[parser.raw_buffer_pos+low]) +\n\t\t\t\t\t(rune(parser.raw_buffer[parser.raw_buffer_pos+high]) << 8)\n\n\t\t\t\t// Check for unexpected low surrogate area.\n\t\t\t\tif value&0xFC00 == 0xDC00 {\n\t\t\t\t\treturn yaml_parser_set_reader_error(parser,\n\t\t\t\t\t\t\"unexpected low surrogate area\",\n\t\t\t\t\t\tparser.offset, int(value))\n\t\t\t\t}\n\n\t\t\t\t// Check for a high surrogate area.\n\t\t\t\tif value&0xFC00 == 0xD800 {\n\t\t\t\t\twidth = 4\n\n\t\t\t\t\t// Check for incomplete surrogate pair.\n\t\t\t\t\tif raw_unread < 4 {\n\t\t\t\t\t\tif parser.eof {\n\t\t\t\t\t\t\treturn yaml_parser_set_reader_error(parser,\n\t\t\t\t\t\t\t\t\"incomplete UTF-16 surrogate pair\",\n\t\t\t\t\t\t\t\tparser.offset, -1)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak inner\n\t\t\t\t\t}\n\n\t\t\t\t\t// Get the next character.\n\t\t\t\t\tvalue2 := rune(parser.raw_buffer[parser.raw_buffer_pos+low+2]) +\n\t\t\t\t\t\t(rune(parser.raw_buffer[parser.raw_buffer_pos+high+2]) << 8)\n\n\t\t\t\t\t// Check for a low surrogate area.\n\t\t\t\t\tif value2&0xFC00 != 0xDC00 {\n\t\t\t\t\t\treturn yaml_parser_set_reader_error(parser,\n\t\t\t\t\t\t\t\"expected low surrogate area\",\n\t\t\t\t\t\t\tparser.offset+2, int(value2))\n\t\t\t\t\t}\n\n\t\t\t\t\t// Generate the value of the surrogate pair.\n\t\t\t\t\tvalue = 0x10000 + ((value & 0x3FF) << 10) + (value2 & 0x3FF)\n\t\t\t\t} else {\n\t\t\t\t\twidth = 2\n\t\t\t\t}\n\n\t\t\tdefault:\n\t\t\t\tpanic(\"impossible\")\n\t\t\t}\n\n\t\t\t// Check if the character is in the allowed range:\n\t\t\t//      #x9 | #xA | #xD | [#x20-#x7E]               (8 bit)\n\t\t\t//      | #x85 | [#xA0-#xD7FF] | [#xE000-#xFFFD]    (16 bit)\n\t\t\t//      | [#x10000-#x10FFFF]                        (32 bit)\n\t\t\tswitch {\n\t\t\tcase value == 0x09:\n\t\t\tcase value == 0x0A:\n\t\t\tcase value == 0x0D:\n\t\t\tcase value >= 0x20 && value <= 0x7E:\n\t\t\tcase value == 0x85:\n\t\t\tcase value >= 0xA0 && value <= 0xD7FF:\n\t\t\tcase value >= 0xE000 && value <= 0xFFFD:\n\t\t\tcase value >= 0x10000 && value <= 0x10FFFF:\n\t\t\tdefault:\n\t\t\t\treturn yaml_parser_set_reader_error(parser,\n\t\t\t\t\t\"control characters are not allowed\",\n\t\t\t\t\tparser.offset, int(value))\n\t\t\t}\n\n\t\t\t// Move the raw pointers.\n\t\t\tparser.raw_buffer_pos += width\n\t\t\tparser.offset += width\n\n\t\t\t// Finally put the character into the buffer.\n\t\t\tif value <= 0x7F {\n\t\t\t\t// 0000 0000-0000 007F . 0xxxxxxx\n\t\t\t\tparser.buffer[buffer_len+0] = byte(value)\n\t\t\t\tbuffer_len += 1\n\t\t\t} else if value <= 0x7FF {\n\t\t\t\t// 0000 0080-0000 07FF . 110xxxxx 10xxxxxx\n\t\t\t\tparser.buffer[buffer_len+0] = byte(0xC0 + (value >> 6))\n\t\t\t\tparser.buffer[buffer_len+1] = byte(0x80 + (value & 0x3F))\n\t\t\t\tbuffer_len += 2\n\t\t\t} else if value <= 0xFFFF {\n\t\t\t\t// 0000 0800-0000 FFFF . 1110xxxx 10xxxxxx 10xxxxxx\n\t\t\t\tparser.buffer[buffer_len+0] = byte(0xE0 + (value >> 12))\n\t\t\t\tparser.buffer[buffer_len+1] = byte(0x80 + ((value >> 6) & 0x3F))\n\t\t\t\tparser.buffer[buffer_len+2] = byte(0x80 + (value & 0x3F))\n\t\t\t\tbuffer_len += 3\n\t\t\t} else {\n\t\t\t\t// 0001 0000-0010 FFFF . 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx\n\t\t\t\tparser.buffer[buffer_len+0] = byte(0xF0 + (value >> 18))\n\t\t\t\tparser.buffer[buffer_len+1] = byte(0x80 + ((value >> 12) & 0x3F))\n\t\t\t\tparser.buffer[buffer_len+2] = byte(0x80 + ((value >> 6) & 0x3F))\n\t\t\t\tparser.buffer[buffer_len+3] = byte(0x80 + (value & 0x3F))\n\t\t\t\tbuffer_len += 4\n\t\t\t}\n\n\t\t\tparser.unread++\n\t\t}\n\n\t\t// On EOF, put NUL into the buffer and return.\n\t\tif parser.eof {\n\t\t\tparser.buffer[buffer_len] = 0\n\t\t\tbuffer_len++\n\t\t\tparser.unread++\n\t\t\tbreak\n\t\t}\n\t}\n\t// [Go] Read the documentation of this function above. To return true,\n\t// we need to have the given length in the buffer. Not doing that means\n\t// every single check that calls this function to make sure the buffer\n\t// has a given length is Go) panicking; or C) accessing invalid memory.\n\t// This happens here due to the EOF above breaking early.\n\tfor buffer_len < length {\n\t\tparser.buffer[buffer_len] = 0\n\t\tbuffer_len++\n\t}\n\tparser.buffer = parser.buffer[:buffer_len]\n\treturn true\n}\n"
        },
        {
          "name": "resolve.go",
          "type": "blob",
          "size": 8.314453125,
          "content": "//\n// Copyright (c) 2011-2019 Canonical Ltd\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage yaml\n\nimport (\n\t\"encoding/base64\"\n\t\"math\"\n\t\"regexp\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype resolveMapItem struct {\n\tvalue interface{}\n\ttag   string\n}\n\nvar resolveTable = make([]byte, 256)\nvar resolveMap = make(map[string]resolveMapItem)\n\nfunc init() {\n\tt := resolveTable\n\tt[int('+')] = 'S' // Sign\n\tt[int('-')] = 'S'\n\tfor _, c := range \"0123456789\" {\n\t\tt[int(c)] = 'D' // Digit\n\t}\n\tfor _, c := range \"yYnNtTfFoO~\" {\n\t\tt[int(c)] = 'M' // In map\n\t}\n\tt[int('.')] = '.' // Float (potentially in map)\n\n\tvar resolveMapList = []struct {\n\t\tv   interface{}\n\t\ttag string\n\t\tl   []string\n\t}{\n\t\t{true, boolTag, []string{\"true\", \"True\", \"TRUE\"}},\n\t\t{false, boolTag, []string{\"false\", \"False\", \"FALSE\"}},\n\t\t{nil, nullTag, []string{\"\", \"~\", \"null\", \"Null\", \"NULL\"}},\n\t\t{math.NaN(), floatTag, []string{\".nan\", \".NaN\", \".NAN\"}},\n\t\t{math.Inf(+1), floatTag, []string{\".inf\", \".Inf\", \".INF\"}},\n\t\t{math.Inf(+1), floatTag, []string{\"+.inf\", \"+.Inf\", \"+.INF\"}},\n\t\t{math.Inf(-1), floatTag, []string{\"-.inf\", \"-.Inf\", \"-.INF\"}},\n\t\t{\"<<\", mergeTag, []string{\"<<\"}},\n\t}\n\n\tm := resolveMap\n\tfor _, item := range resolveMapList {\n\t\tfor _, s := range item.l {\n\t\t\tm[s] = resolveMapItem{item.v, item.tag}\n\t\t}\n\t}\n}\n\nconst (\n\tnullTag      = \"!!null\"\n\tboolTag      = \"!!bool\"\n\tstrTag       = \"!!str\"\n\tintTag       = \"!!int\"\n\tfloatTag     = \"!!float\"\n\ttimestampTag = \"!!timestamp\"\n\tseqTag       = \"!!seq\"\n\tmapTag       = \"!!map\"\n\tbinaryTag    = \"!!binary\"\n\tmergeTag     = \"!!merge\"\n)\n\nvar longTags = make(map[string]string)\nvar shortTags = make(map[string]string)\n\nfunc init() {\n\tfor _, stag := range []string{nullTag, boolTag, strTag, intTag, floatTag, timestampTag, seqTag, mapTag, binaryTag, mergeTag} {\n\t\tltag := longTag(stag)\n\t\tlongTags[stag] = ltag\n\t\tshortTags[ltag] = stag\n\t}\n}\n\nconst longTagPrefix = \"tag:yaml.org,2002:\"\n\nfunc shortTag(tag string) string {\n\tif strings.HasPrefix(tag, longTagPrefix) {\n\t\tif stag, ok := shortTags[tag]; ok {\n\t\t\treturn stag\n\t\t}\n\t\treturn \"!!\" + tag[len(longTagPrefix):]\n\t}\n\treturn tag\n}\n\nfunc longTag(tag string) string {\n\tif strings.HasPrefix(tag, \"!!\") {\n\t\tif ltag, ok := longTags[tag]; ok {\n\t\t\treturn ltag\n\t\t}\n\t\treturn longTagPrefix + tag[2:]\n\t}\n\treturn tag\n}\n\nfunc resolvableTag(tag string) bool {\n\tswitch tag {\n\tcase \"\", strTag, boolTag, intTag, floatTag, nullTag, timestampTag:\n\t\treturn true\n\t}\n\treturn false\n}\n\nvar yamlStyleFloat = regexp.MustCompile(`^[-+]?(\\.[0-9]+|[0-9]+(\\.[0-9]*)?)([eE][-+]?[0-9]+)?$`)\n\nfunc resolve(tag string, in string) (rtag string, out interface{}) {\n\ttag = shortTag(tag)\n\tif !resolvableTag(tag) {\n\t\treturn tag, in\n\t}\n\n\tdefer func() {\n\t\tswitch tag {\n\t\tcase \"\", rtag, strTag, binaryTag:\n\t\t\treturn\n\t\tcase floatTag:\n\t\t\tif rtag == intTag {\n\t\t\t\tswitch v := out.(type) {\n\t\t\t\tcase int64:\n\t\t\t\t\trtag = floatTag\n\t\t\t\t\tout = float64(v)\n\t\t\t\t\treturn\n\t\t\t\tcase int:\n\t\t\t\t\trtag = floatTag\n\t\t\t\t\tout = float64(v)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfailf(\"cannot decode %s `%s` as a %s\", shortTag(rtag), in, shortTag(tag))\n\t}()\n\n\t// Any data is accepted as a !!str or !!binary.\n\t// Otherwise, the prefix is enough of a hint about what it might be.\n\thint := byte('N')\n\tif in != \"\" {\n\t\thint = resolveTable[in[0]]\n\t}\n\tif hint != 0 && tag != strTag && tag != binaryTag {\n\t\t// Handle things we can lookup in a map.\n\t\tif item, ok := resolveMap[in]; ok {\n\t\t\treturn item.tag, item.value\n\t\t}\n\n\t\t// Base 60 floats are a bad idea, were dropped in YAML 1.2, and\n\t\t// are purposefully unsupported here. They're still quoted on\n\t\t// the way out for compatibility with other parser, though.\n\n\t\tswitch hint {\n\t\tcase 'M':\n\t\t\t// We've already checked the map above.\n\n\t\tcase '.':\n\t\t\t// Not in the map, so maybe a normal float.\n\t\t\tfloatv, err := strconv.ParseFloat(in, 64)\n\t\t\tif err == nil {\n\t\t\t\treturn floatTag, floatv\n\t\t\t}\n\n\t\tcase 'D', 'S':\n\t\t\t// Int, float, or timestamp.\n\t\t\t// Only try values as a timestamp if the value is unquoted or there's an explicit\n\t\t\t// !!timestamp tag.\n\t\t\tif tag == \"\" || tag == timestampTag {\n\t\t\t\tt, ok := parseTimestamp(in)\n\t\t\t\tif ok {\n\t\t\t\t\treturn timestampTag, t\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tplain := strings.Replace(in, \"_\", \"\", -1)\n\t\t\tintv, err := strconv.ParseInt(plain, 0, 64)\n\t\t\tif err == nil {\n\t\t\t\tif intv == int64(int(intv)) {\n\t\t\t\t\treturn intTag, int(intv)\n\t\t\t\t} else {\n\t\t\t\t\treturn intTag, intv\n\t\t\t\t}\n\t\t\t}\n\t\t\tuintv, err := strconv.ParseUint(plain, 0, 64)\n\t\t\tif err == nil {\n\t\t\t\treturn intTag, uintv\n\t\t\t}\n\t\t\tif yamlStyleFloat.MatchString(plain) {\n\t\t\t\tfloatv, err := strconv.ParseFloat(plain, 64)\n\t\t\t\tif err == nil {\n\t\t\t\t\treturn floatTag, floatv\n\t\t\t\t}\n\t\t\t}\n\t\t\tif strings.HasPrefix(plain, \"0b\") {\n\t\t\t\tintv, err := strconv.ParseInt(plain[2:], 2, 64)\n\t\t\t\tif err == nil {\n\t\t\t\t\tif intv == int64(int(intv)) {\n\t\t\t\t\t\treturn intTag, int(intv)\n\t\t\t\t\t} else {\n\t\t\t\t\t\treturn intTag, intv\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tuintv, err := strconv.ParseUint(plain[2:], 2, 64)\n\t\t\t\tif err == nil {\n\t\t\t\t\treturn intTag, uintv\n\t\t\t\t}\n\t\t\t} else if strings.HasPrefix(plain, \"-0b\") {\n\t\t\t\tintv, err := strconv.ParseInt(\"-\"+plain[3:], 2, 64)\n\t\t\t\tif err == nil {\n\t\t\t\t\tif true || intv == int64(int(intv)) {\n\t\t\t\t\t\treturn intTag, int(intv)\n\t\t\t\t\t} else {\n\t\t\t\t\t\treturn intTag, intv\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Octals as introduced in version 1.2 of the spec.\n\t\t\t// Octals from the 1.1 spec, spelled as 0777, are still\n\t\t\t// decoded by default in v3 as well for compatibility.\n\t\t\t// May be dropped in v4 depending on how usage evolves.\n\t\t\tif strings.HasPrefix(plain, \"0o\") {\n\t\t\t\tintv, err := strconv.ParseInt(plain[2:], 8, 64)\n\t\t\t\tif err == nil {\n\t\t\t\t\tif intv == int64(int(intv)) {\n\t\t\t\t\t\treturn intTag, int(intv)\n\t\t\t\t\t} else {\n\t\t\t\t\t\treturn intTag, intv\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tuintv, err := strconv.ParseUint(plain[2:], 8, 64)\n\t\t\t\tif err == nil {\n\t\t\t\t\treturn intTag, uintv\n\t\t\t\t}\n\t\t\t} else if strings.HasPrefix(plain, \"-0o\") {\n\t\t\t\tintv, err := strconv.ParseInt(\"-\"+plain[3:], 8, 64)\n\t\t\t\tif err == nil {\n\t\t\t\t\tif true || intv == int64(int(intv)) {\n\t\t\t\t\t\treturn intTag, int(intv)\n\t\t\t\t\t} else {\n\t\t\t\t\t\treturn intTag, intv\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\tdefault:\n\t\t\tpanic(\"internal error: missing handler for resolver table: \" + string(rune(hint)) + \" (with \" + in + \")\")\n\t\t}\n\t}\n\treturn strTag, in\n}\n\n// encodeBase64 encodes s as base64 that is broken up into multiple lines\n// as appropriate for the resulting length.\nfunc encodeBase64(s string) string {\n\tconst lineLen = 70\n\tencLen := base64.StdEncoding.EncodedLen(len(s))\n\tlines := encLen/lineLen + 1\n\tbuf := make([]byte, encLen*2+lines)\n\tin := buf[0:encLen]\n\tout := buf[encLen:]\n\tbase64.StdEncoding.Encode(in, []byte(s))\n\tk := 0\n\tfor i := 0; i < len(in); i += lineLen {\n\t\tj := i + lineLen\n\t\tif j > len(in) {\n\t\t\tj = len(in)\n\t\t}\n\t\tk += copy(out[k:], in[i:j])\n\t\tif lines > 1 {\n\t\t\tout[k] = '\\n'\n\t\t\tk++\n\t\t}\n\t}\n\treturn string(out[:k])\n}\n\n// This is a subset of the formats allowed by the regular expression\n// defined at http://yaml.org/type/timestamp.html.\nvar allowedTimestampFormats = []string{\n\t\"2006-1-2T15:4:5.999999999Z07:00\", // RCF3339Nano with short date fields.\n\t\"2006-1-2t15:4:5.999999999Z07:00\", // RFC3339Nano with short date fields and lower-case \"t\".\n\t\"2006-1-2 15:4:5.999999999\",       // space separated with no time zone\n\t\"2006-1-2\",                        // date only\n\t// Notable exception: time.Parse cannot handle: \"2001-12-14 21:59:43.10 -5\"\n\t// from the set of examples.\n}\n\n// parseTimestamp parses s as a timestamp string and\n// returns the timestamp and reports whether it succeeded.\n// Timestamp formats are defined at http://yaml.org/type/timestamp.html\nfunc parseTimestamp(s string) (time.Time, bool) {\n\t// TODO write code to check all the formats supported by\n\t// http://yaml.org/type/timestamp.html instead of using time.Parse.\n\n\t// Quick check: all date formats start with YYYY-.\n\ti := 0\n\tfor ; i < len(s); i++ {\n\t\tif c := s[i]; c < '0' || c > '9' {\n\t\t\tbreak\n\t\t}\n\t}\n\tif i != 4 || i == len(s) || s[i] != '-' {\n\t\treturn time.Time{}, false\n\t}\n\tfor _, format := range allowedTimestampFormats {\n\t\tif t, err := time.Parse(format, s); err == nil {\n\t\t\treturn t, true\n\t\t}\n\t}\n\treturn time.Time{}, false\n}\n"
        },
        {
          "name": "scannerc.go",
          "type": "blob",
          "size": 85.8984375,
          "content": "//\n// Copyright (c) 2011-2019 Canonical Ltd\n// Copyright (c) 2006-2010 Kirill Simonov\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy of\n// this software and associated documentation files (the \"Software\"), to deal in\n// the Software without restriction, including without limitation the rights to\n// use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\n// of the Software, and to permit persons to whom the Software is furnished to do\n// so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\npackage yaml\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n)\n\n// Introduction\n// ************\n//\n// The following notes assume that you are familiar with the YAML specification\n// (http://yaml.org/spec/1.2/spec.html).  We mostly follow it, although in\n// some cases we are less restrictive that it requires.\n//\n// The process of transforming a YAML stream into a sequence of events is\n// divided on two steps: Scanning and Parsing.\n//\n// The Scanner transforms the input stream into a sequence of tokens, while the\n// parser transform the sequence of tokens produced by the Scanner into a\n// sequence of parsing events.\n//\n// The Scanner is rather clever and complicated. The Parser, on the contrary,\n// is a straightforward implementation of a recursive-descendant parser (or,\n// LL(1) parser, as it is usually called).\n//\n// Actually there are two issues of Scanning that might be called \"clever\", the\n// rest is quite straightforward.  The issues are \"block collection start\" and\n// \"simple keys\".  Both issues are explained below in details.\n//\n// Here the Scanning step is explained and implemented.  We start with the list\n// of all the tokens produced by the Scanner together with short descriptions.\n//\n// Now, tokens:\n//\n//      STREAM-START(encoding)          # The stream start.\n//      STREAM-END                      # The stream end.\n//      VERSION-DIRECTIVE(major,minor)  # The '%YAML' directive.\n//      TAG-DIRECTIVE(handle,prefix)    # The '%TAG' directive.\n//      DOCUMENT-START                  # '---'\n//      DOCUMENT-END                    # '...'\n//      BLOCK-SEQUENCE-START            # Indentation increase denoting a block\n//      BLOCK-MAPPING-START             # sequence or a block mapping.\n//      BLOCK-END                       # Indentation decrease.\n//      FLOW-SEQUENCE-START             # '['\n//      FLOW-SEQUENCE-END               # ']'\n//      BLOCK-SEQUENCE-START            # '{'\n//      BLOCK-SEQUENCE-END              # '}'\n//      BLOCK-ENTRY                     # '-'\n//      FLOW-ENTRY                      # ','\n//      KEY                             # '?' or nothing (simple keys).\n//      VALUE                           # ':'\n//      ALIAS(anchor)                   # '*anchor'\n//      ANCHOR(anchor)                  # '&anchor'\n//      TAG(handle,suffix)              # '!handle!suffix'\n//      SCALAR(value,style)             # A scalar.\n//\n// The following two tokens are \"virtual\" tokens denoting the beginning and the\n// end of the stream:\n//\n//      STREAM-START(encoding)\n//      STREAM-END\n//\n// We pass the information about the input stream encoding with the\n// STREAM-START token.\n//\n// The next two tokens are responsible for tags:\n//\n//      VERSION-DIRECTIVE(major,minor)\n//      TAG-DIRECTIVE(handle,prefix)\n//\n// Example:\n//\n//      %YAML   1.1\n//      %TAG    !   !foo\n//      %TAG    !yaml!  tag:yaml.org,2002:\n//      ---\n//\n// The correspoding sequence of tokens:\n//\n//      STREAM-START(utf-8)\n//      VERSION-DIRECTIVE(1,1)\n//      TAG-DIRECTIVE(\"!\",\"!foo\")\n//      TAG-DIRECTIVE(\"!yaml\",\"tag:yaml.org,2002:\")\n//      DOCUMENT-START\n//      STREAM-END\n//\n// Note that the VERSION-DIRECTIVE and TAG-DIRECTIVE tokens occupy a whole\n// line.\n//\n// The document start and end indicators are represented by:\n//\n//      DOCUMENT-START\n//      DOCUMENT-END\n//\n// Note that if a YAML stream contains an implicit document (without '---'\n// and '...' indicators), no DOCUMENT-START and DOCUMENT-END tokens will be\n// produced.\n//\n// In the following examples, we present whole documents together with the\n// produced tokens.\n//\n//      1. An implicit document:\n//\n//          'a scalar'\n//\n//      Tokens:\n//\n//          STREAM-START(utf-8)\n//          SCALAR(\"a scalar\",single-quoted)\n//          STREAM-END\n//\n//      2. An explicit document:\n//\n//          ---\n//          'a scalar'\n//          ...\n//\n//      Tokens:\n//\n//          STREAM-START(utf-8)\n//          DOCUMENT-START\n//          SCALAR(\"a scalar\",single-quoted)\n//          DOCUMENT-END\n//          STREAM-END\n//\n//      3. Several documents in a stream:\n//\n//          'a scalar'\n//          ---\n//          'another scalar'\n//          ---\n//          'yet another scalar'\n//\n//      Tokens:\n//\n//          STREAM-START(utf-8)\n//          SCALAR(\"a scalar\",single-quoted)\n//          DOCUMENT-START\n//          SCALAR(\"another scalar\",single-quoted)\n//          DOCUMENT-START\n//          SCALAR(\"yet another scalar\",single-quoted)\n//          STREAM-END\n//\n// We have already introduced the SCALAR token above.  The following tokens are\n// used to describe aliases, anchors, tag, and scalars:\n//\n//      ALIAS(anchor)\n//      ANCHOR(anchor)\n//      TAG(handle,suffix)\n//      SCALAR(value,style)\n//\n// The following series of examples illustrate the usage of these tokens:\n//\n//      1. A recursive sequence:\n//\n//          &A [ *A ]\n//\n//      Tokens:\n//\n//          STREAM-START(utf-8)\n//          ANCHOR(\"A\")\n//          FLOW-SEQUENCE-START\n//          ALIAS(\"A\")\n//          FLOW-SEQUENCE-END\n//          STREAM-END\n//\n//      2. A tagged scalar:\n//\n//          !!float \"3.14\"  # A good approximation.\n//\n//      Tokens:\n//\n//          STREAM-START(utf-8)\n//          TAG(\"!!\",\"float\")\n//          SCALAR(\"3.14\",double-quoted)\n//          STREAM-END\n//\n//      3. Various scalar styles:\n//\n//          --- # Implicit empty plain scalars do not produce tokens.\n//          --- a plain scalar\n//          --- 'a single-quoted scalar'\n//          --- \"a double-quoted scalar\"\n//          --- |-\n//            a literal scalar\n//          --- >-\n//            a folded\n//            scalar\n//\n//      Tokens:\n//\n//          STREAM-START(utf-8)\n//          DOCUMENT-START\n//          DOCUMENT-START\n//          SCALAR(\"a plain scalar\",plain)\n//          DOCUMENT-START\n//          SCALAR(\"a single-quoted scalar\",single-quoted)\n//          DOCUMENT-START\n//          SCALAR(\"a double-quoted scalar\",double-quoted)\n//          DOCUMENT-START\n//          SCALAR(\"a literal scalar\",literal)\n//          DOCUMENT-START\n//          SCALAR(\"a folded scalar\",folded)\n//          STREAM-END\n//\n// Now it's time to review collection-related tokens. We will start with\n// flow collections:\n//\n//      FLOW-SEQUENCE-START\n//      FLOW-SEQUENCE-END\n//      FLOW-MAPPING-START\n//      FLOW-MAPPING-END\n//      FLOW-ENTRY\n//      KEY\n//      VALUE\n//\n// The tokens FLOW-SEQUENCE-START, FLOW-SEQUENCE-END, FLOW-MAPPING-START, and\n// FLOW-MAPPING-END represent the indicators '[', ']', '{', and '}'\n// correspondingly.  FLOW-ENTRY represent the ',' indicator.  Finally the\n// indicators '?' and ':', which are used for denoting mapping keys and values,\n// are represented by the KEY and VALUE tokens.\n//\n// The following examples show flow collections:\n//\n//      1. A flow sequence:\n//\n//          [item 1, item 2, item 3]\n//\n//      Tokens:\n//\n//          STREAM-START(utf-8)\n//          FLOW-SEQUENCE-START\n//          SCALAR(\"item 1\",plain)\n//          FLOW-ENTRY\n//          SCALAR(\"item 2\",plain)\n//          FLOW-ENTRY\n//          SCALAR(\"item 3\",plain)\n//          FLOW-SEQUENCE-END\n//          STREAM-END\n//\n//      2. A flow mapping:\n//\n//          {\n//              a simple key: a value,  # Note that the KEY token is produced.\n//              ? a complex key: another value,\n//          }\n//\n//      Tokens:\n//\n//          STREAM-START(utf-8)\n//          FLOW-MAPPING-START\n//          KEY\n//          SCALAR(\"a simple key\",plain)\n//          VALUE\n//          SCALAR(\"a value\",plain)\n//          FLOW-ENTRY\n//          KEY\n//          SCALAR(\"a complex key\",plain)\n//          VALUE\n//          SCALAR(\"another value\",plain)\n//          FLOW-ENTRY\n//          FLOW-MAPPING-END\n//          STREAM-END\n//\n// A simple key is a key which is not denoted by the '?' indicator.  Note that\n// the Scanner still produce the KEY token whenever it encounters a simple key.\n//\n// For scanning block collections, the following tokens are used (note that we\n// repeat KEY and VALUE here):\n//\n//      BLOCK-SEQUENCE-START\n//      BLOCK-MAPPING-START\n//      BLOCK-END\n//      BLOCK-ENTRY\n//      KEY\n//      VALUE\n//\n// The tokens BLOCK-SEQUENCE-START and BLOCK-MAPPING-START denote indentation\n// increase that precedes a block collection (cf. the INDENT token in Python).\n// The token BLOCK-END denote indentation decrease that ends a block collection\n// (cf. the DEDENT token in Python).  However YAML has some syntax pecularities\n// that makes detections of these tokens more complex.\n//\n// The tokens BLOCK-ENTRY, KEY, and VALUE are used to represent the indicators\n// '-', '?', and ':' correspondingly.\n//\n// The following examples show how the tokens BLOCK-SEQUENCE-START,\n// BLOCK-MAPPING-START, and BLOCK-END are emitted by the Scanner:\n//\n//      1. Block sequences:\n//\n//          - item 1\n//          - item 2\n//          -\n//            - item 3.1\n//            - item 3.2\n//          -\n//            key 1: value 1\n//            key 2: value 2\n//\n//      Tokens:\n//\n//          STREAM-START(utf-8)\n//          BLOCK-SEQUENCE-START\n//          BLOCK-ENTRY\n//          SCALAR(\"item 1\",plain)\n//          BLOCK-ENTRY\n//          SCALAR(\"item 2\",plain)\n//          BLOCK-ENTRY\n//          BLOCK-SEQUENCE-START\n//          BLOCK-ENTRY\n//          SCALAR(\"item 3.1\",plain)\n//          BLOCK-ENTRY\n//          SCALAR(\"item 3.2\",plain)\n//          BLOCK-END\n//          BLOCK-ENTRY\n//          BLOCK-MAPPING-START\n//          KEY\n//          SCALAR(\"key 1\",plain)\n//          VALUE\n//          SCALAR(\"value 1\",plain)\n//          KEY\n//          SCALAR(\"key 2\",plain)\n//          VALUE\n//          SCALAR(\"value 2\",plain)\n//          BLOCK-END\n//          BLOCK-END\n//          STREAM-END\n//\n//      2. Block mappings:\n//\n//          a simple key: a value   # The KEY token is produced here.\n//          ? a complex key\n//          : another value\n//          a mapping:\n//            key 1: value 1\n//            key 2: value 2\n//          a sequence:\n//            - item 1\n//            - item 2\n//\n//      Tokens:\n//\n//          STREAM-START(utf-8)\n//          BLOCK-MAPPING-START\n//          KEY\n//          SCALAR(\"a simple key\",plain)\n//          VALUE\n//          SCALAR(\"a value\",plain)\n//          KEY\n//          SCALAR(\"a complex key\",plain)\n//          VALUE\n//          SCALAR(\"another value\",plain)\n//          KEY\n//          SCALAR(\"a mapping\",plain)\n//          BLOCK-MAPPING-START\n//          KEY\n//          SCALAR(\"key 1\",plain)\n//          VALUE\n//          SCALAR(\"value 1\",plain)\n//          KEY\n//          SCALAR(\"key 2\",plain)\n//          VALUE\n//          SCALAR(\"value 2\",plain)\n//          BLOCK-END\n//          KEY\n//          SCALAR(\"a sequence\",plain)\n//          VALUE\n//          BLOCK-SEQUENCE-START\n//          BLOCK-ENTRY\n//          SCALAR(\"item 1\",plain)\n//          BLOCK-ENTRY\n//          SCALAR(\"item 2\",plain)\n//          BLOCK-END\n//          BLOCK-END\n//          STREAM-END\n//\n// YAML does not always require to start a new block collection from a new\n// line.  If the current line contains only '-', '?', and ':' indicators, a new\n// block collection may start at the current line.  The following examples\n// illustrate this case:\n//\n//      1. Collections in a sequence:\n//\n//          - - item 1\n//            - item 2\n//          - key 1: value 1\n//            key 2: value 2\n//          - ? complex key\n//            : complex value\n//\n//      Tokens:\n//\n//          STREAM-START(utf-8)\n//          BLOCK-SEQUENCE-START\n//          BLOCK-ENTRY\n//          BLOCK-SEQUENCE-START\n//          BLOCK-ENTRY\n//          SCALAR(\"item 1\",plain)\n//          BLOCK-ENTRY\n//          SCALAR(\"item 2\",plain)\n//          BLOCK-END\n//          BLOCK-ENTRY\n//          BLOCK-MAPPING-START\n//          KEY\n//          SCALAR(\"key 1\",plain)\n//          VALUE\n//          SCALAR(\"value 1\",plain)\n//          KEY\n//          SCALAR(\"key 2\",plain)\n//          VALUE\n//          SCALAR(\"value 2\",plain)\n//          BLOCK-END\n//          BLOCK-ENTRY\n//          BLOCK-MAPPING-START\n//          KEY\n//          SCALAR(\"complex key\")\n//          VALUE\n//          SCALAR(\"complex value\")\n//          BLOCK-END\n//          BLOCK-END\n//          STREAM-END\n//\n//      2. Collections in a mapping:\n//\n//          ? a sequence\n//          : - item 1\n//            - item 2\n//          ? a mapping\n//          : key 1: value 1\n//            key 2: value 2\n//\n//      Tokens:\n//\n//          STREAM-START(utf-8)\n//          BLOCK-MAPPING-START\n//          KEY\n//          SCALAR(\"a sequence\",plain)\n//          VALUE\n//          BLOCK-SEQUENCE-START\n//          BLOCK-ENTRY\n//          SCALAR(\"item 1\",plain)\n//          BLOCK-ENTRY\n//          SCALAR(\"item 2\",plain)\n//          BLOCK-END\n//          KEY\n//          SCALAR(\"a mapping\",plain)\n//          VALUE\n//          BLOCK-MAPPING-START\n//          KEY\n//          SCALAR(\"key 1\",plain)\n//          VALUE\n//          SCALAR(\"value 1\",plain)\n//          KEY\n//          SCALAR(\"key 2\",plain)\n//          VALUE\n//          SCALAR(\"value 2\",plain)\n//          BLOCK-END\n//          BLOCK-END\n//          STREAM-END\n//\n// YAML also permits non-indented sequences if they are included into a block\n// mapping.  In this case, the token BLOCK-SEQUENCE-START is not produced:\n//\n//      key:\n//      - item 1    # BLOCK-SEQUENCE-START is NOT produced here.\n//      - item 2\n//\n// Tokens:\n//\n//      STREAM-START(utf-8)\n//      BLOCK-MAPPING-START\n//      KEY\n//      SCALAR(\"key\",plain)\n//      VALUE\n//      BLOCK-ENTRY\n//      SCALAR(\"item 1\",plain)\n//      BLOCK-ENTRY\n//      SCALAR(\"item 2\",plain)\n//      BLOCK-END\n//\n\n// Ensure that the buffer contains the required number of characters.\n// Return true on success, false on failure (reader error or memory error).\nfunc cache(parser *yaml_parser_t, length int) bool {\n\t// [Go] This was inlined: !cache(A, B) -> unread < B && !update(A, B)\n\treturn parser.unread >= length || yaml_parser_update_buffer(parser, length)\n}\n\n// Advance the buffer pointer.\nfunc skip(parser *yaml_parser_t) {\n\tif !is_blank(parser.buffer, parser.buffer_pos) {\n\t\tparser.newlines = 0\n\t}\n\tparser.mark.index++\n\tparser.mark.column++\n\tparser.unread--\n\tparser.buffer_pos += width(parser.buffer[parser.buffer_pos])\n}\n\nfunc skip_line(parser *yaml_parser_t) {\n\tif is_crlf(parser.buffer, parser.buffer_pos) {\n\t\tparser.mark.index += 2\n\t\tparser.mark.column = 0\n\t\tparser.mark.line++\n\t\tparser.unread -= 2\n\t\tparser.buffer_pos += 2\n\t\tparser.newlines++\n\t} else if is_break(parser.buffer, parser.buffer_pos) {\n\t\tparser.mark.index++\n\t\tparser.mark.column = 0\n\t\tparser.mark.line++\n\t\tparser.unread--\n\t\tparser.buffer_pos += width(parser.buffer[parser.buffer_pos])\n\t\tparser.newlines++\n\t}\n}\n\n// Copy a character to a string buffer and advance pointers.\nfunc read(parser *yaml_parser_t, s []byte) []byte {\n\tif !is_blank(parser.buffer, parser.buffer_pos) {\n\t\tparser.newlines = 0\n\t}\n\tw := width(parser.buffer[parser.buffer_pos])\n\tif w == 0 {\n\t\tpanic(\"invalid character sequence\")\n\t}\n\tif len(s) == 0 {\n\t\ts = make([]byte, 0, 32)\n\t}\n\tif w == 1 && len(s)+w <= cap(s) {\n\t\ts = s[:len(s)+1]\n\t\ts[len(s)-1] = parser.buffer[parser.buffer_pos]\n\t\tparser.buffer_pos++\n\t} else {\n\t\ts = append(s, parser.buffer[parser.buffer_pos:parser.buffer_pos+w]...)\n\t\tparser.buffer_pos += w\n\t}\n\tparser.mark.index++\n\tparser.mark.column++\n\tparser.unread--\n\treturn s\n}\n\n// Copy a line break character to a string buffer and advance pointers.\nfunc read_line(parser *yaml_parser_t, s []byte) []byte {\n\tbuf := parser.buffer\n\tpos := parser.buffer_pos\n\tswitch {\n\tcase buf[pos] == '\\r' && buf[pos+1] == '\\n':\n\t\t// CR LF . LF\n\t\ts = append(s, '\\n')\n\t\tparser.buffer_pos += 2\n\t\tparser.mark.index++\n\t\tparser.unread--\n\tcase buf[pos] == '\\r' || buf[pos] == '\\n':\n\t\t// CR|LF . LF\n\t\ts = append(s, '\\n')\n\t\tparser.buffer_pos += 1\n\tcase buf[pos] == '\\xC2' && buf[pos+1] == '\\x85':\n\t\t// NEL . LF\n\t\ts = append(s, '\\n')\n\t\tparser.buffer_pos += 2\n\tcase buf[pos] == '\\xE2' && buf[pos+1] == '\\x80' && (buf[pos+2] == '\\xA8' || buf[pos+2] == '\\xA9'):\n\t\t// LS|PS . LS|PS\n\t\ts = append(s, buf[parser.buffer_pos:pos+3]...)\n\t\tparser.buffer_pos += 3\n\tdefault:\n\t\treturn s\n\t}\n\tparser.mark.index++\n\tparser.mark.column = 0\n\tparser.mark.line++\n\tparser.unread--\n\tparser.newlines++\n\treturn s\n}\n\n// Get the next token.\nfunc yaml_parser_scan(parser *yaml_parser_t, token *yaml_token_t) bool {\n\t// Erase the token object.\n\t*token = yaml_token_t{} // [Go] Is this necessary?\n\n\t// No tokens after STREAM-END or error.\n\tif parser.stream_end_produced || parser.error != yaml_NO_ERROR {\n\t\treturn true\n\t}\n\n\t// Ensure that the tokens queue contains enough tokens.\n\tif !parser.token_available {\n\t\tif !yaml_parser_fetch_more_tokens(parser) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Fetch the next token from the queue.\n\t*token = parser.tokens[parser.tokens_head]\n\tparser.tokens_head++\n\tparser.tokens_parsed++\n\tparser.token_available = false\n\n\tif token.typ == yaml_STREAM_END_TOKEN {\n\t\tparser.stream_end_produced = true\n\t}\n\treturn true\n}\n\n// Set the scanner error and return false.\nfunc yaml_parser_set_scanner_error(parser *yaml_parser_t, context string, context_mark yaml_mark_t, problem string) bool {\n\tparser.error = yaml_SCANNER_ERROR\n\tparser.context = context\n\tparser.context_mark = context_mark\n\tparser.problem = problem\n\tparser.problem_mark = parser.mark\n\treturn false\n}\n\nfunc yaml_parser_set_scanner_tag_error(parser *yaml_parser_t, directive bool, context_mark yaml_mark_t, problem string) bool {\n\tcontext := \"while parsing a tag\"\n\tif directive {\n\t\tcontext = \"while parsing a %TAG directive\"\n\t}\n\treturn yaml_parser_set_scanner_error(parser, context, context_mark, problem)\n}\n\nfunc trace(args ...interface{}) func() {\n\tpargs := append([]interface{}{\"+++\"}, args...)\n\tfmt.Println(pargs...)\n\tpargs = append([]interface{}{\"---\"}, args...)\n\treturn func() { fmt.Println(pargs...) }\n}\n\n// Ensure that the tokens queue contains at least one token which can be\n// returned to the Parser.\nfunc yaml_parser_fetch_more_tokens(parser *yaml_parser_t) bool {\n\t// While we need more tokens to fetch, do it.\n\tfor {\n\t\t// [Go] The comment parsing logic requires a lookahead of two tokens\n\t\t// so that foot comments may be parsed in time of associating them\n\t\t// with the tokens that are parsed before them, and also for line\n\t\t// comments to be transformed into head comments in some edge cases.\n\t\tif parser.tokens_head < len(parser.tokens)-2 {\n\t\t\t// If a potential simple key is at the head position, we need to fetch\n\t\t\t// the next token to disambiguate it.\n\t\t\thead_tok_idx, ok := parser.simple_keys_by_tok[parser.tokens_parsed]\n\t\t\tif !ok {\n\t\t\t\tbreak\n\t\t\t} else if valid, ok := yaml_simple_key_is_valid(parser, &parser.simple_keys[head_tok_idx]); !ok {\n\t\t\t\treturn false\n\t\t\t} else if !valid {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\t// Fetch the next token.\n\t\tif !yaml_parser_fetch_next_token(parser) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\tparser.token_available = true\n\treturn true\n}\n\n// The dispatcher for token fetchers.\nfunc yaml_parser_fetch_next_token(parser *yaml_parser_t) (ok bool) {\n\t// Ensure that the buffer is initialized.\n\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\treturn false\n\t}\n\n\t// Check if we just started scanning.  Fetch STREAM-START then.\n\tif !parser.stream_start_produced {\n\t\treturn yaml_parser_fetch_stream_start(parser)\n\t}\n\n\tscan_mark := parser.mark\n\n\t// Eat whitespaces and comments until we reach the next token.\n\tif !yaml_parser_scan_to_next_token(parser) {\n\t\treturn false\n\t}\n\n\t// [Go] While unrolling indents, transform the head comments of prior\n\t// indentation levels observed after scan_start into foot comments at\n\t// the respective indexes.\n\n\t// Check the indentation level against the current column.\n\tif !yaml_parser_unroll_indent(parser, parser.mark.column, scan_mark) {\n\t\treturn false\n\t}\n\n\t// Ensure that the buffer contains at least 4 characters.  4 is the length\n\t// of the longest indicators ('--- ' and '... ').\n\tif parser.unread < 4 && !yaml_parser_update_buffer(parser, 4) {\n\t\treturn false\n\t}\n\n\t// Is it the end of the stream?\n\tif is_z(parser.buffer, parser.buffer_pos) {\n\t\treturn yaml_parser_fetch_stream_end(parser)\n\t}\n\n\t// Is it a directive?\n\tif parser.mark.column == 0 && parser.buffer[parser.buffer_pos] == '%' {\n\t\treturn yaml_parser_fetch_directive(parser)\n\t}\n\n\tbuf := parser.buffer\n\tpos := parser.buffer_pos\n\n\t// Is it the document start indicator?\n\tif parser.mark.column == 0 && buf[pos] == '-' && buf[pos+1] == '-' && buf[pos+2] == '-' && is_blankz(buf, pos+3) {\n\t\treturn yaml_parser_fetch_document_indicator(parser, yaml_DOCUMENT_START_TOKEN)\n\t}\n\n\t// Is it the document end indicator?\n\tif parser.mark.column == 0 && buf[pos] == '.' && buf[pos+1] == '.' && buf[pos+2] == '.' && is_blankz(buf, pos+3) {\n\t\treturn yaml_parser_fetch_document_indicator(parser, yaml_DOCUMENT_END_TOKEN)\n\t}\n\n\tcomment_mark := parser.mark\n\tif len(parser.tokens) > 0 && (parser.flow_level == 0 && buf[pos] == ':' || parser.flow_level > 0 && buf[pos] == ',') {\n\t\t// Associate any following comments with the prior token.\n\t\tcomment_mark = parser.tokens[len(parser.tokens)-1].start_mark\n\t}\n\tdefer func() {\n\t\tif !ok {\n\t\t\treturn\n\t\t}\n\t\tif len(parser.tokens) > 0 && parser.tokens[len(parser.tokens)-1].typ == yaml_BLOCK_ENTRY_TOKEN {\n\t\t\t// Sequence indicators alone have no line comments. It becomes\n\t\t\t// a head comment for whatever follows.\n\t\t\treturn\n\t\t}\n\t\tif !yaml_parser_scan_line_comment(parser, comment_mark) {\n\t\t\tok = false\n\t\t\treturn\n\t\t}\n\t}()\n\n\t// Is it the flow sequence start indicator?\n\tif buf[pos] == '[' {\n\t\treturn yaml_parser_fetch_flow_collection_start(parser, yaml_FLOW_SEQUENCE_START_TOKEN)\n\t}\n\n\t// Is it the flow mapping start indicator?\n\tif parser.buffer[parser.buffer_pos] == '{' {\n\t\treturn yaml_parser_fetch_flow_collection_start(parser, yaml_FLOW_MAPPING_START_TOKEN)\n\t}\n\n\t// Is it the flow sequence end indicator?\n\tif parser.buffer[parser.buffer_pos] == ']' {\n\t\treturn yaml_parser_fetch_flow_collection_end(parser,\n\t\t\tyaml_FLOW_SEQUENCE_END_TOKEN)\n\t}\n\n\t// Is it the flow mapping end indicator?\n\tif parser.buffer[parser.buffer_pos] == '}' {\n\t\treturn yaml_parser_fetch_flow_collection_end(parser,\n\t\t\tyaml_FLOW_MAPPING_END_TOKEN)\n\t}\n\n\t// Is it the flow entry indicator?\n\tif parser.buffer[parser.buffer_pos] == ',' {\n\t\treturn yaml_parser_fetch_flow_entry(parser)\n\t}\n\n\t// Is it the block entry indicator?\n\tif parser.buffer[parser.buffer_pos] == '-' && is_blankz(parser.buffer, parser.buffer_pos+1) {\n\t\treturn yaml_parser_fetch_block_entry(parser)\n\t}\n\n\t// Is it the key indicator?\n\tif parser.buffer[parser.buffer_pos] == '?' && (parser.flow_level > 0 || is_blankz(parser.buffer, parser.buffer_pos+1)) {\n\t\treturn yaml_parser_fetch_key(parser)\n\t}\n\n\t// Is it the value indicator?\n\tif parser.buffer[parser.buffer_pos] == ':' && (parser.flow_level > 0 || is_blankz(parser.buffer, parser.buffer_pos+1)) {\n\t\treturn yaml_parser_fetch_value(parser)\n\t}\n\n\t// Is it an alias?\n\tif parser.buffer[parser.buffer_pos] == '*' {\n\t\treturn yaml_parser_fetch_anchor(parser, yaml_ALIAS_TOKEN)\n\t}\n\n\t// Is it an anchor?\n\tif parser.buffer[parser.buffer_pos] == '&' {\n\t\treturn yaml_parser_fetch_anchor(parser, yaml_ANCHOR_TOKEN)\n\t}\n\n\t// Is it a tag?\n\tif parser.buffer[parser.buffer_pos] == '!' {\n\t\treturn yaml_parser_fetch_tag(parser)\n\t}\n\n\t// Is it a literal scalar?\n\tif parser.buffer[parser.buffer_pos] == '|' && parser.flow_level == 0 {\n\t\treturn yaml_parser_fetch_block_scalar(parser, true)\n\t}\n\n\t// Is it a folded scalar?\n\tif parser.buffer[parser.buffer_pos] == '>' && parser.flow_level == 0 {\n\t\treturn yaml_parser_fetch_block_scalar(parser, false)\n\t}\n\n\t// Is it a single-quoted scalar?\n\tif parser.buffer[parser.buffer_pos] == '\\'' {\n\t\treturn yaml_parser_fetch_flow_scalar(parser, true)\n\t}\n\n\t// Is it a double-quoted scalar?\n\tif parser.buffer[parser.buffer_pos] == '\"' {\n\t\treturn yaml_parser_fetch_flow_scalar(parser, false)\n\t}\n\n\t// Is it a plain scalar?\n\t//\n\t// A plain scalar may start with any non-blank characters except\n\t//\n\t//      '-', '?', ':', ',', '[', ']', '{', '}',\n\t//      '#', '&', '*', '!', '|', '>', '\\'', '\\\"',\n\t//      '%', '@', '`'.\n\t//\n\t// In the block context (and, for the '-' indicator, in the flow context\n\t// too), it may also start with the characters\n\t//\n\t//      '-', '?', ':'\n\t//\n\t// if it is followed by a non-space character.\n\t//\n\t// The last rule is more restrictive than the specification requires.\n\t// [Go] TODO Make this logic more reasonable.\n\t//switch parser.buffer[parser.buffer_pos] {\n\t//case '-', '?', ':', ',', '?', '-', ',', ':', ']', '[', '}', '{', '&', '#', '!', '*', '>', '|', '\"', '\\'', '@', '%', '-', '`':\n\t//}\n\tif !(is_blankz(parser.buffer, parser.buffer_pos) || parser.buffer[parser.buffer_pos] == '-' ||\n\t\tparser.buffer[parser.buffer_pos] == '?' || parser.buffer[parser.buffer_pos] == ':' ||\n\t\tparser.buffer[parser.buffer_pos] == ',' || parser.buffer[parser.buffer_pos] == '[' ||\n\t\tparser.buffer[parser.buffer_pos] == ']' || parser.buffer[parser.buffer_pos] == '{' ||\n\t\tparser.buffer[parser.buffer_pos] == '}' || parser.buffer[parser.buffer_pos] == '#' ||\n\t\tparser.buffer[parser.buffer_pos] == '&' || parser.buffer[parser.buffer_pos] == '*' ||\n\t\tparser.buffer[parser.buffer_pos] == '!' || parser.buffer[parser.buffer_pos] == '|' ||\n\t\tparser.buffer[parser.buffer_pos] == '>' || parser.buffer[parser.buffer_pos] == '\\'' ||\n\t\tparser.buffer[parser.buffer_pos] == '\"' || parser.buffer[parser.buffer_pos] == '%' ||\n\t\tparser.buffer[parser.buffer_pos] == '@' || parser.buffer[parser.buffer_pos] == '`') ||\n\t\t(parser.buffer[parser.buffer_pos] == '-' && !is_blank(parser.buffer, parser.buffer_pos+1)) ||\n\t\t(parser.flow_level == 0 &&\n\t\t\t(parser.buffer[parser.buffer_pos] == '?' || parser.buffer[parser.buffer_pos] == ':') &&\n\t\t\t!is_blankz(parser.buffer, parser.buffer_pos+1)) {\n\t\treturn yaml_parser_fetch_plain_scalar(parser)\n\t}\n\n\t// If we don't determine the token type so far, it is an error.\n\treturn yaml_parser_set_scanner_error(parser,\n\t\t\"while scanning for the next token\", parser.mark,\n\t\t\"found character that cannot start any token\")\n}\n\nfunc yaml_simple_key_is_valid(parser *yaml_parser_t, simple_key *yaml_simple_key_t) (valid, ok bool) {\n\tif !simple_key.possible {\n\t\treturn false, true\n\t}\n\n\t// The 1.2 specification says:\n\t//\n\t//     \"If the ? indicator is omitted, parsing needs to see past the\n\t//     implicit key to recognize it as such. To limit the amount of\n\t//     lookahead required, the : indicator must appear at most 1024\n\t//     Unicode characters beyond the start of the key. In addition, the key\n\t//     is restricted to a single line.\"\n\t//\n\tif simple_key.mark.line < parser.mark.line || simple_key.mark.index+1024 < parser.mark.index {\n\t\t// Check if the potential simple key to be removed is required.\n\t\tif simple_key.required {\n\t\t\treturn false, yaml_parser_set_scanner_error(parser,\n\t\t\t\t\"while scanning a simple key\", simple_key.mark,\n\t\t\t\t\"could not find expected ':'\")\n\t\t}\n\t\tsimple_key.possible = false\n\t\treturn false, true\n\t}\n\treturn true, true\n}\n\n// Check if a simple key may start at the current position and add it if\n// needed.\nfunc yaml_parser_save_simple_key(parser *yaml_parser_t) bool {\n\t// A simple key is required at the current position if the scanner is in\n\t// the block context and the current column coincides with the indentation\n\t// level.\n\n\trequired := parser.flow_level == 0 && parser.indent == parser.mark.column\n\n\t//\n\t// If the current position may start a simple key, save it.\n\t//\n\tif parser.simple_key_allowed {\n\t\tsimple_key := yaml_simple_key_t{\n\t\t\tpossible:     true,\n\t\t\trequired:     required,\n\t\t\ttoken_number: parser.tokens_parsed + (len(parser.tokens) - parser.tokens_head),\n\t\t\tmark:         parser.mark,\n\t\t}\n\n\t\tif !yaml_parser_remove_simple_key(parser) {\n\t\t\treturn false\n\t\t}\n\t\tparser.simple_keys[len(parser.simple_keys)-1] = simple_key\n\t\tparser.simple_keys_by_tok[simple_key.token_number] = len(parser.simple_keys) - 1\n\t}\n\treturn true\n}\n\n// Remove a potential simple key at the current flow level.\nfunc yaml_parser_remove_simple_key(parser *yaml_parser_t) bool {\n\ti := len(parser.simple_keys) - 1\n\tif parser.simple_keys[i].possible {\n\t\t// If the key is required, it is an error.\n\t\tif parser.simple_keys[i].required {\n\t\t\treturn yaml_parser_set_scanner_error(parser,\n\t\t\t\t\"while scanning a simple key\", parser.simple_keys[i].mark,\n\t\t\t\t\"could not find expected ':'\")\n\t\t}\n\t\t// Remove the key from the stack.\n\t\tparser.simple_keys[i].possible = false\n\t\tdelete(parser.simple_keys_by_tok, parser.simple_keys[i].token_number)\n\t}\n\treturn true\n}\n\n// max_flow_level limits the flow_level\nconst max_flow_level = 10000\n\n// Increase the flow level and resize the simple key list if needed.\nfunc yaml_parser_increase_flow_level(parser *yaml_parser_t) bool {\n\t// Reset the simple key on the next level.\n\tparser.simple_keys = append(parser.simple_keys, yaml_simple_key_t{\n\t\tpossible:     false,\n\t\trequired:     false,\n\t\ttoken_number: parser.tokens_parsed + (len(parser.tokens) - parser.tokens_head),\n\t\tmark:         parser.mark,\n\t})\n\n\t// Increase the flow level.\n\tparser.flow_level++\n\tif parser.flow_level > max_flow_level {\n\t\treturn yaml_parser_set_scanner_error(parser,\n\t\t\t\"while increasing flow level\", parser.simple_keys[len(parser.simple_keys)-1].mark,\n\t\t\tfmt.Sprintf(\"exceeded max depth of %d\", max_flow_level))\n\t}\n\treturn true\n}\n\n// Decrease the flow level.\nfunc yaml_parser_decrease_flow_level(parser *yaml_parser_t) bool {\n\tif parser.flow_level > 0 {\n\t\tparser.flow_level--\n\t\tlast := len(parser.simple_keys) - 1\n\t\tdelete(parser.simple_keys_by_tok, parser.simple_keys[last].token_number)\n\t\tparser.simple_keys = parser.simple_keys[:last]\n\t}\n\treturn true\n}\n\n// max_indents limits the indents stack size\nconst max_indents = 10000\n\n// Push the current indentation level to the stack and set the new level\n// the current column is greater than the indentation level.  In this case,\n// append or insert the specified token into the token queue.\nfunc yaml_parser_roll_indent(parser *yaml_parser_t, column, number int, typ yaml_token_type_t, mark yaml_mark_t) bool {\n\t// In the flow context, do nothing.\n\tif parser.flow_level > 0 {\n\t\treturn true\n\t}\n\n\tif parser.indent < column {\n\t\t// Push the current indentation level to the stack and set the new\n\t\t// indentation level.\n\t\tparser.indents = append(parser.indents, parser.indent)\n\t\tparser.indent = column\n\t\tif len(parser.indents) > max_indents {\n\t\t\treturn yaml_parser_set_scanner_error(parser,\n\t\t\t\t\"while increasing indent level\", parser.simple_keys[len(parser.simple_keys)-1].mark,\n\t\t\t\tfmt.Sprintf(\"exceeded max depth of %d\", max_indents))\n\t\t}\n\n\t\t// Create a token and insert it into the queue.\n\t\ttoken := yaml_token_t{\n\t\t\ttyp:        typ,\n\t\t\tstart_mark: mark,\n\t\t\tend_mark:   mark,\n\t\t}\n\t\tif number > -1 {\n\t\t\tnumber -= parser.tokens_parsed\n\t\t}\n\t\tyaml_insert_token(parser, number, &token)\n\t}\n\treturn true\n}\n\n// Pop indentation levels from the indents stack until the current level\n// becomes less or equal to the column.  For each indentation level, append\n// the BLOCK-END token.\nfunc yaml_parser_unroll_indent(parser *yaml_parser_t, column int, scan_mark yaml_mark_t) bool {\n\t// In the flow context, do nothing.\n\tif parser.flow_level > 0 {\n\t\treturn true\n\t}\n\n\tblock_mark := scan_mark\n\tblock_mark.index--\n\n\t// Loop through the indentation levels in the stack.\n\tfor parser.indent > column {\n\n\t\t// [Go] Reposition the end token before potential following\n\t\t//      foot comments of parent blocks. For that, search\n\t\t//      backwards for recent comments that were at the same\n\t\t//      indent as the block that is ending now.\n\t\tstop_index := block_mark.index\n\t\tfor i := len(parser.comments) - 1; i >= 0; i-- {\n\t\t\tcomment := &parser.comments[i]\n\n\t\t\tif comment.end_mark.index < stop_index {\n\t\t\t\t// Don't go back beyond the start of the comment/whitespace scan, unless column < 0.\n\t\t\t\t// If requested indent column is < 0, then the document is over and everything else\n\t\t\t\t// is a foot anyway.\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tif comment.start_mark.column == parser.indent+1 {\n\t\t\t\t// This is a good match. But maybe there's a former comment\n\t\t\t\t// at that same indent level, so keep searching.\n\t\t\t\tblock_mark = comment.start_mark\n\t\t\t}\n\n\t\t\t// While the end of the former comment matches with\n\t\t\t// the start of the following one, we know there's\n\t\t\t// nothing in between and scanning is still safe.\n\t\t\tstop_index = comment.scan_mark.index\n\t\t}\n\n\t\t// Create a token and append it to the queue.\n\t\ttoken := yaml_token_t{\n\t\t\ttyp:        yaml_BLOCK_END_TOKEN,\n\t\t\tstart_mark: block_mark,\n\t\t\tend_mark:   block_mark,\n\t\t}\n\t\tyaml_insert_token(parser, -1, &token)\n\n\t\t// Pop the indentation level.\n\t\tparser.indent = parser.indents[len(parser.indents)-1]\n\t\tparser.indents = parser.indents[:len(parser.indents)-1]\n\t}\n\treturn true\n}\n\n// Initialize the scanner and produce the STREAM-START token.\nfunc yaml_parser_fetch_stream_start(parser *yaml_parser_t) bool {\n\n\t// Set the initial indentation.\n\tparser.indent = -1\n\n\t// Initialize the simple key stack.\n\tparser.simple_keys = append(parser.simple_keys, yaml_simple_key_t{})\n\n\tparser.simple_keys_by_tok = make(map[int]int)\n\n\t// A simple key is allowed at the beginning of the stream.\n\tparser.simple_key_allowed = true\n\n\t// We have started.\n\tparser.stream_start_produced = true\n\n\t// Create the STREAM-START token and append it to the queue.\n\ttoken := yaml_token_t{\n\t\ttyp:        yaml_STREAM_START_TOKEN,\n\t\tstart_mark: parser.mark,\n\t\tend_mark:   parser.mark,\n\t\tencoding:   parser.encoding,\n\t}\n\tyaml_insert_token(parser, -1, &token)\n\treturn true\n}\n\n// Produce the STREAM-END token and shut down the scanner.\nfunc yaml_parser_fetch_stream_end(parser *yaml_parser_t) bool {\n\n\t// Force new line.\n\tif parser.mark.column != 0 {\n\t\tparser.mark.column = 0\n\t\tparser.mark.line++\n\t}\n\n\t// Reset the indentation level.\n\tif !yaml_parser_unroll_indent(parser, -1, parser.mark) {\n\t\treturn false\n\t}\n\n\t// Reset simple keys.\n\tif !yaml_parser_remove_simple_key(parser) {\n\t\treturn false\n\t}\n\n\tparser.simple_key_allowed = false\n\n\t// Create the STREAM-END token and append it to the queue.\n\ttoken := yaml_token_t{\n\t\ttyp:        yaml_STREAM_END_TOKEN,\n\t\tstart_mark: parser.mark,\n\t\tend_mark:   parser.mark,\n\t}\n\tyaml_insert_token(parser, -1, &token)\n\treturn true\n}\n\n// Produce a VERSION-DIRECTIVE or TAG-DIRECTIVE token.\nfunc yaml_parser_fetch_directive(parser *yaml_parser_t) bool {\n\t// Reset the indentation level.\n\tif !yaml_parser_unroll_indent(parser, -1, parser.mark) {\n\t\treturn false\n\t}\n\n\t// Reset simple keys.\n\tif !yaml_parser_remove_simple_key(parser) {\n\t\treturn false\n\t}\n\n\tparser.simple_key_allowed = false\n\n\t// Create the YAML-DIRECTIVE or TAG-DIRECTIVE token.\n\ttoken := yaml_token_t{}\n\tif !yaml_parser_scan_directive(parser, &token) {\n\t\treturn false\n\t}\n\t// Append the token to the queue.\n\tyaml_insert_token(parser, -1, &token)\n\treturn true\n}\n\n// Produce the DOCUMENT-START or DOCUMENT-END token.\nfunc yaml_parser_fetch_document_indicator(parser *yaml_parser_t, typ yaml_token_type_t) bool {\n\t// Reset the indentation level.\n\tif !yaml_parser_unroll_indent(parser, -1, parser.mark) {\n\t\treturn false\n\t}\n\n\t// Reset simple keys.\n\tif !yaml_parser_remove_simple_key(parser) {\n\t\treturn false\n\t}\n\n\tparser.simple_key_allowed = false\n\n\t// Consume the token.\n\tstart_mark := parser.mark\n\n\tskip(parser)\n\tskip(parser)\n\tskip(parser)\n\n\tend_mark := parser.mark\n\n\t// Create the DOCUMENT-START or DOCUMENT-END token.\n\ttoken := yaml_token_t{\n\t\ttyp:        typ,\n\t\tstart_mark: start_mark,\n\t\tend_mark:   end_mark,\n\t}\n\t// Append the token to the queue.\n\tyaml_insert_token(parser, -1, &token)\n\treturn true\n}\n\n// Produce the FLOW-SEQUENCE-START or FLOW-MAPPING-START token.\nfunc yaml_parser_fetch_flow_collection_start(parser *yaml_parser_t, typ yaml_token_type_t) bool {\n\n\t// The indicators '[' and '{' may start a simple key.\n\tif !yaml_parser_save_simple_key(parser) {\n\t\treturn false\n\t}\n\n\t// Increase the flow level.\n\tif !yaml_parser_increase_flow_level(parser) {\n\t\treturn false\n\t}\n\n\t// A simple key may follow the indicators '[' and '{'.\n\tparser.simple_key_allowed = true\n\n\t// Consume the token.\n\tstart_mark := parser.mark\n\tskip(parser)\n\tend_mark := parser.mark\n\n\t// Create the FLOW-SEQUENCE-START of FLOW-MAPPING-START token.\n\ttoken := yaml_token_t{\n\t\ttyp:        typ,\n\t\tstart_mark: start_mark,\n\t\tend_mark:   end_mark,\n\t}\n\t// Append the token to the queue.\n\tyaml_insert_token(parser, -1, &token)\n\treturn true\n}\n\n// Produce the FLOW-SEQUENCE-END or FLOW-MAPPING-END token.\nfunc yaml_parser_fetch_flow_collection_end(parser *yaml_parser_t, typ yaml_token_type_t) bool {\n\t// Reset any potential simple key on the current flow level.\n\tif !yaml_parser_remove_simple_key(parser) {\n\t\treturn false\n\t}\n\n\t// Decrease the flow level.\n\tif !yaml_parser_decrease_flow_level(parser) {\n\t\treturn false\n\t}\n\n\t// No simple keys after the indicators ']' and '}'.\n\tparser.simple_key_allowed = false\n\n\t// Consume the token.\n\n\tstart_mark := parser.mark\n\tskip(parser)\n\tend_mark := parser.mark\n\n\t// Create the FLOW-SEQUENCE-END of FLOW-MAPPING-END token.\n\ttoken := yaml_token_t{\n\t\ttyp:        typ,\n\t\tstart_mark: start_mark,\n\t\tend_mark:   end_mark,\n\t}\n\t// Append the token to the queue.\n\tyaml_insert_token(parser, -1, &token)\n\treturn true\n}\n\n// Produce the FLOW-ENTRY token.\nfunc yaml_parser_fetch_flow_entry(parser *yaml_parser_t) bool {\n\t// Reset any potential simple keys on the current flow level.\n\tif !yaml_parser_remove_simple_key(parser) {\n\t\treturn false\n\t}\n\n\t// Simple keys are allowed after ','.\n\tparser.simple_key_allowed = true\n\n\t// Consume the token.\n\tstart_mark := parser.mark\n\tskip(parser)\n\tend_mark := parser.mark\n\n\t// Create the FLOW-ENTRY token and append it to the queue.\n\ttoken := yaml_token_t{\n\t\ttyp:        yaml_FLOW_ENTRY_TOKEN,\n\t\tstart_mark: start_mark,\n\t\tend_mark:   end_mark,\n\t}\n\tyaml_insert_token(parser, -1, &token)\n\treturn true\n}\n\n// Produce the BLOCK-ENTRY token.\nfunc yaml_parser_fetch_block_entry(parser *yaml_parser_t) bool {\n\t// Check if the scanner is in the block context.\n\tif parser.flow_level == 0 {\n\t\t// Check if we are allowed to start a new entry.\n\t\tif !parser.simple_key_allowed {\n\t\t\treturn yaml_parser_set_scanner_error(parser, \"\", parser.mark,\n\t\t\t\t\"block sequence entries are not allowed in this context\")\n\t\t}\n\t\t// Add the BLOCK-SEQUENCE-START token if needed.\n\t\tif !yaml_parser_roll_indent(parser, parser.mark.column, -1, yaml_BLOCK_SEQUENCE_START_TOKEN, parser.mark) {\n\t\t\treturn false\n\t\t}\n\t} else {\n\t\t// It is an error for the '-' indicator to occur in the flow context,\n\t\t// but we let the Parser detect and report about it because the Parser\n\t\t// is able to point to the context.\n\t}\n\n\t// Reset any potential simple keys on the current flow level.\n\tif !yaml_parser_remove_simple_key(parser) {\n\t\treturn false\n\t}\n\n\t// Simple keys are allowed after '-'.\n\tparser.simple_key_allowed = true\n\n\t// Consume the token.\n\tstart_mark := parser.mark\n\tskip(parser)\n\tend_mark := parser.mark\n\n\t// Create the BLOCK-ENTRY token and append it to the queue.\n\ttoken := yaml_token_t{\n\t\ttyp:        yaml_BLOCK_ENTRY_TOKEN,\n\t\tstart_mark: start_mark,\n\t\tend_mark:   end_mark,\n\t}\n\tyaml_insert_token(parser, -1, &token)\n\treturn true\n}\n\n// Produce the KEY token.\nfunc yaml_parser_fetch_key(parser *yaml_parser_t) bool {\n\n\t// In the block context, additional checks are required.\n\tif parser.flow_level == 0 {\n\t\t// Check if we are allowed to start a new key (not nessesary simple).\n\t\tif !parser.simple_key_allowed {\n\t\t\treturn yaml_parser_set_scanner_error(parser, \"\", parser.mark,\n\t\t\t\t\"mapping keys are not allowed in this context\")\n\t\t}\n\t\t// Add the BLOCK-MAPPING-START token if needed.\n\t\tif !yaml_parser_roll_indent(parser, parser.mark.column, -1, yaml_BLOCK_MAPPING_START_TOKEN, parser.mark) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Reset any potential simple keys on the current flow level.\n\tif !yaml_parser_remove_simple_key(parser) {\n\t\treturn false\n\t}\n\n\t// Simple keys are allowed after '?' in the block context.\n\tparser.simple_key_allowed = parser.flow_level == 0\n\n\t// Consume the token.\n\tstart_mark := parser.mark\n\tskip(parser)\n\tend_mark := parser.mark\n\n\t// Create the KEY token and append it to the queue.\n\ttoken := yaml_token_t{\n\t\ttyp:        yaml_KEY_TOKEN,\n\t\tstart_mark: start_mark,\n\t\tend_mark:   end_mark,\n\t}\n\tyaml_insert_token(parser, -1, &token)\n\treturn true\n}\n\n// Produce the VALUE token.\nfunc yaml_parser_fetch_value(parser *yaml_parser_t) bool {\n\n\tsimple_key := &parser.simple_keys[len(parser.simple_keys)-1]\n\n\t// Have we found a simple key?\n\tif valid, ok := yaml_simple_key_is_valid(parser, simple_key); !ok {\n\t\treturn false\n\n\t} else if valid {\n\n\t\t// Create the KEY token and insert it into the queue.\n\t\ttoken := yaml_token_t{\n\t\t\ttyp:        yaml_KEY_TOKEN,\n\t\t\tstart_mark: simple_key.mark,\n\t\t\tend_mark:   simple_key.mark,\n\t\t}\n\t\tyaml_insert_token(parser, simple_key.token_number-parser.tokens_parsed, &token)\n\n\t\t// In the block context, we may need to add the BLOCK-MAPPING-START token.\n\t\tif !yaml_parser_roll_indent(parser, simple_key.mark.column,\n\t\t\tsimple_key.token_number,\n\t\t\tyaml_BLOCK_MAPPING_START_TOKEN, simple_key.mark) {\n\t\t\treturn false\n\t\t}\n\n\t\t// Remove the simple key.\n\t\tsimple_key.possible = false\n\t\tdelete(parser.simple_keys_by_tok, simple_key.token_number)\n\n\t\t// A simple key cannot follow another simple key.\n\t\tparser.simple_key_allowed = false\n\n\t} else {\n\t\t// The ':' indicator follows a complex key.\n\n\t\t// In the block context, extra checks are required.\n\t\tif parser.flow_level == 0 {\n\n\t\t\t// Check if we are allowed to start a complex value.\n\t\t\tif !parser.simple_key_allowed {\n\t\t\t\treturn yaml_parser_set_scanner_error(parser, \"\", parser.mark,\n\t\t\t\t\t\"mapping values are not allowed in this context\")\n\t\t\t}\n\n\t\t\t// Add the BLOCK-MAPPING-START token if needed.\n\t\t\tif !yaml_parser_roll_indent(parser, parser.mark.column, -1, yaml_BLOCK_MAPPING_START_TOKEN, parser.mark) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\n\t\t// Simple keys after ':' are allowed in the block context.\n\t\tparser.simple_key_allowed = parser.flow_level == 0\n\t}\n\n\t// Consume the token.\n\tstart_mark := parser.mark\n\tskip(parser)\n\tend_mark := parser.mark\n\n\t// Create the VALUE token and append it to the queue.\n\ttoken := yaml_token_t{\n\t\ttyp:        yaml_VALUE_TOKEN,\n\t\tstart_mark: start_mark,\n\t\tend_mark:   end_mark,\n\t}\n\tyaml_insert_token(parser, -1, &token)\n\treturn true\n}\n\n// Produce the ALIAS or ANCHOR token.\nfunc yaml_parser_fetch_anchor(parser *yaml_parser_t, typ yaml_token_type_t) bool {\n\t// An anchor or an alias could be a simple key.\n\tif !yaml_parser_save_simple_key(parser) {\n\t\treturn false\n\t}\n\n\t// A simple key cannot follow an anchor or an alias.\n\tparser.simple_key_allowed = false\n\n\t// Create the ALIAS or ANCHOR token and append it to the queue.\n\tvar token yaml_token_t\n\tif !yaml_parser_scan_anchor(parser, &token, typ) {\n\t\treturn false\n\t}\n\tyaml_insert_token(parser, -1, &token)\n\treturn true\n}\n\n// Produce the TAG token.\nfunc yaml_parser_fetch_tag(parser *yaml_parser_t) bool {\n\t// A tag could be a simple key.\n\tif !yaml_parser_save_simple_key(parser) {\n\t\treturn false\n\t}\n\n\t// A simple key cannot follow a tag.\n\tparser.simple_key_allowed = false\n\n\t// Create the TAG token and append it to the queue.\n\tvar token yaml_token_t\n\tif !yaml_parser_scan_tag(parser, &token) {\n\t\treturn false\n\t}\n\tyaml_insert_token(parser, -1, &token)\n\treturn true\n}\n\n// Produce the SCALAR(...,literal) or SCALAR(...,folded) tokens.\nfunc yaml_parser_fetch_block_scalar(parser *yaml_parser_t, literal bool) bool {\n\t// Remove any potential simple keys.\n\tif !yaml_parser_remove_simple_key(parser) {\n\t\treturn false\n\t}\n\n\t// A simple key may follow a block scalar.\n\tparser.simple_key_allowed = true\n\n\t// Create the SCALAR token and append it to the queue.\n\tvar token yaml_token_t\n\tif !yaml_parser_scan_block_scalar(parser, &token, literal) {\n\t\treturn false\n\t}\n\tyaml_insert_token(parser, -1, &token)\n\treturn true\n}\n\n// Produce the SCALAR(...,single-quoted) or SCALAR(...,double-quoted) tokens.\nfunc yaml_parser_fetch_flow_scalar(parser *yaml_parser_t, single bool) bool {\n\t// A plain scalar could be a simple key.\n\tif !yaml_parser_save_simple_key(parser) {\n\t\treturn false\n\t}\n\n\t// A simple key cannot follow a flow scalar.\n\tparser.simple_key_allowed = false\n\n\t// Create the SCALAR token and append it to the queue.\n\tvar token yaml_token_t\n\tif !yaml_parser_scan_flow_scalar(parser, &token, single) {\n\t\treturn false\n\t}\n\tyaml_insert_token(parser, -1, &token)\n\treturn true\n}\n\n// Produce the SCALAR(...,plain) token.\nfunc yaml_parser_fetch_plain_scalar(parser *yaml_parser_t) bool {\n\t// A plain scalar could be a simple key.\n\tif !yaml_parser_save_simple_key(parser) {\n\t\treturn false\n\t}\n\n\t// A simple key cannot follow a flow scalar.\n\tparser.simple_key_allowed = false\n\n\t// Create the SCALAR token and append it to the queue.\n\tvar token yaml_token_t\n\tif !yaml_parser_scan_plain_scalar(parser, &token) {\n\t\treturn false\n\t}\n\tyaml_insert_token(parser, -1, &token)\n\treturn true\n}\n\n// Eat whitespaces and comments until the next token is found.\nfunc yaml_parser_scan_to_next_token(parser *yaml_parser_t) bool {\n\n\tscan_mark := parser.mark\n\n\t// Until the next token is not found.\n\tfor {\n\t\t// Allow the BOM mark to start a line.\n\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\treturn false\n\t\t}\n\t\tif parser.mark.column == 0 && is_bom(parser.buffer, parser.buffer_pos) {\n\t\t\tskip(parser)\n\t\t}\n\n\t\t// Eat whitespaces.\n\t\t// Tabs are allowed:\n\t\t//  - in the flow context\n\t\t//  - in the block context, but not at the beginning of the line or\n\t\t//  after '-', '?', or ':' (complex value).\n\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\treturn false\n\t\t}\n\n\t\tfor parser.buffer[parser.buffer_pos] == ' ' || ((parser.flow_level > 0 || !parser.simple_key_allowed) && parser.buffer[parser.buffer_pos] == '\\t') {\n\t\t\tskip(parser)\n\t\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\n\t\t// Check if we just had a line comment under a sequence entry that\n\t\t// looks more like a header to the following content. Similar to this:\n\t\t//\n\t\t// - # The comment\n\t\t//   - Some data\n\t\t//\n\t\t// If so, transform the line comment to a head comment and reposition.\n\t\tif len(parser.comments) > 0 && len(parser.tokens) > 1 {\n\t\t\ttokenA := parser.tokens[len(parser.tokens)-2]\n\t\t\ttokenB := parser.tokens[len(parser.tokens)-1]\n\t\t\tcomment := &parser.comments[len(parser.comments)-1]\n\t\t\tif tokenA.typ == yaml_BLOCK_SEQUENCE_START_TOKEN && tokenB.typ == yaml_BLOCK_ENTRY_TOKEN && len(comment.line) > 0 && !is_break(parser.buffer, parser.buffer_pos) {\n\t\t\t\t// If it was in the prior line, reposition so it becomes a\n\t\t\t\t// header of the follow up token. Otherwise, keep it in place\n\t\t\t\t// so it becomes a header of the former.\n\t\t\t\tcomment.head = comment.line\n\t\t\t\tcomment.line = nil\n\t\t\t\tif comment.start_mark.line == parser.mark.line-1 {\n\t\t\t\t\tcomment.token_mark = parser.mark\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Eat a comment until a line break.\n\t\tif parser.buffer[parser.buffer_pos] == '#' {\n\t\t\tif !yaml_parser_scan_comments(parser, scan_mark) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\n\t\t// If it is a line break, eat it.\n\t\tif is_break(parser.buffer, parser.buffer_pos) {\n\t\t\tif parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tskip_line(parser)\n\n\t\t\t// In the block context, a new line may start a simple key.\n\t\t\tif parser.flow_level == 0 {\n\t\t\t\tparser.simple_key_allowed = true\n\t\t\t}\n\t\t} else {\n\t\t\tbreak // We have found a token.\n\t\t}\n\t}\n\n\treturn true\n}\n\n// Scan a YAML-DIRECTIVE or TAG-DIRECTIVE token.\n//\n// Scope:\n//      %YAML    1.1    # a comment \\n\n//      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n//      %TAG    !yaml!  tag:yaml.org,2002:  \\n\n//      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n//\nfunc yaml_parser_scan_directive(parser *yaml_parser_t, token *yaml_token_t) bool {\n\t// Eat '%'.\n\tstart_mark := parser.mark\n\tskip(parser)\n\n\t// Scan the directive name.\n\tvar name []byte\n\tif !yaml_parser_scan_directive_name(parser, start_mark, &name) {\n\t\treturn false\n\t}\n\n\t// Is it a YAML directive?\n\tif bytes.Equal(name, []byte(\"YAML\")) {\n\t\t// Scan the VERSION directive value.\n\t\tvar major, minor int8\n\t\tif !yaml_parser_scan_version_directive_value(parser, start_mark, &major, &minor) {\n\t\t\treturn false\n\t\t}\n\t\tend_mark := parser.mark\n\n\t\t// Create a VERSION-DIRECTIVE token.\n\t\t*token = yaml_token_t{\n\t\t\ttyp:        yaml_VERSION_DIRECTIVE_TOKEN,\n\t\t\tstart_mark: start_mark,\n\t\t\tend_mark:   end_mark,\n\t\t\tmajor:      major,\n\t\t\tminor:      minor,\n\t\t}\n\n\t\t// Is it a TAG directive?\n\t} else if bytes.Equal(name, []byte(\"TAG\")) {\n\t\t// Scan the TAG directive value.\n\t\tvar handle, prefix []byte\n\t\tif !yaml_parser_scan_tag_directive_value(parser, start_mark, &handle, &prefix) {\n\t\t\treturn false\n\t\t}\n\t\tend_mark := parser.mark\n\n\t\t// Create a TAG-DIRECTIVE token.\n\t\t*token = yaml_token_t{\n\t\t\ttyp:        yaml_TAG_DIRECTIVE_TOKEN,\n\t\t\tstart_mark: start_mark,\n\t\t\tend_mark:   end_mark,\n\t\t\tvalue:      handle,\n\t\t\tprefix:     prefix,\n\t\t}\n\n\t\t// Unknown directive.\n\t} else {\n\t\tyaml_parser_set_scanner_error(parser, \"while scanning a directive\",\n\t\t\tstart_mark, \"found unknown directive name\")\n\t\treturn false\n\t}\n\n\t// Eat the rest of the line including any comments.\n\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\treturn false\n\t}\n\n\tfor is_blank(parser.buffer, parser.buffer_pos) {\n\t\tskip(parser)\n\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\tif parser.buffer[parser.buffer_pos] == '#' {\n\t\t// [Go] Discard this inline comment for the time being.\n\t\t//if !yaml_parser_scan_line_comment(parser, start_mark) {\n\t\t//\treturn false\n\t\t//}\n\t\tfor !is_breakz(parser.buffer, parser.buffer_pos) {\n\t\t\tskip(parser)\n\t\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check if we are at the end of the line.\n\tif !is_breakz(parser.buffer, parser.buffer_pos) {\n\t\tyaml_parser_set_scanner_error(parser, \"while scanning a directive\",\n\t\t\tstart_mark, \"did not find expected comment or line break\")\n\t\treturn false\n\t}\n\n\t// Eat a line break.\n\tif is_break(parser.buffer, parser.buffer_pos) {\n\t\tif parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {\n\t\t\treturn false\n\t\t}\n\t\tskip_line(parser)\n\t}\n\n\treturn true\n}\n\n// Scan the directive name.\n//\n// Scope:\n//      %YAML   1.1     # a comment \\n\n//       ^^^^\n//      %TAG    !yaml!  tag:yaml.org,2002:  \\n\n//       ^^^\n//\nfunc yaml_parser_scan_directive_name(parser *yaml_parser_t, start_mark yaml_mark_t, name *[]byte) bool {\n\t// Consume the directive name.\n\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\treturn false\n\t}\n\n\tvar s []byte\n\tfor is_alpha(parser.buffer, parser.buffer_pos) {\n\t\ts = read(parser, s)\n\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Check if the name is empty.\n\tif len(s) == 0 {\n\t\tyaml_parser_set_scanner_error(parser, \"while scanning a directive\",\n\t\t\tstart_mark, \"could not find expected directive name\")\n\t\treturn false\n\t}\n\n\t// Check for an blank character after the name.\n\tif !is_blankz(parser.buffer, parser.buffer_pos) {\n\t\tyaml_parser_set_scanner_error(parser, \"while scanning a directive\",\n\t\t\tstart_mark, \"found unexpected non-alphabetical character\")\n\t\treturn false\n\t}\n\t*name = s\n\treturn true\n}\n\n// Scan the value of VERSION-DIRECTIVE.\n//\n// Scope:\n//      %YAML   1.1     # a comment \\n\n//           ^^^^^^\nfunc yaml_parser_scan_version_directive_value(parser *yaml_parser_t, start_mark yaml_mark_t, major, minor *int8) bool {\n\t// Eat whitespaces.\n\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\treturn false\n\t}\n\tfor is_blank(parser.buffer, parser.buffer_pos) {\n\t\tskip(parser)\n\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Consume the major version number.\n\tif !yaml_parser_scan_version_directive_number(parser, start_mark, major) {\n\t\treturn false\n\t}\n\n\t// Eat '.'.\n\tif parser.buffer[parser.buffer_pos] != '.' {\n\t\treturn yaml_parser_set_scanner_error(parser, \"while scanning a %YAML directive\",\n\t\t\tstart_mark, \"did not find expected digit or '.' character\")\n\t}\n\n\tskip(parser)\n\n\t// Consume the minor version number.\n\tif !yaml_parser_scan_version_directive_number(parser, start_mark, minor) {\n\t\treturn false\n\t}\n\treturn true\n}\n\nconst max_number_length = 2\n\n// Scan the version number of VERSION-DIRECTIVE.\n//\n// Scope:\n//      %YAML   1.1     # a comment \\n\n//              ^\n//      %YAML   1.1     # a comment \\n\n//                ^\nfunc yaml_parser_scan_version_directive_number(parser *yaml_parser_t, start_mark yaml_mark_t, number *int8) bool {\n\n\t// Repeat while the next character is digit.\n\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\treturn false\n\t}\n\tvar value, length int8\n\tfor is_digit(parser.buffer, parser.buffer_pos) {\n\t\t// Check if the number is too long.\n\t\tlength++\n\t\tif length > max_number_length {\n\t\t\treturn yaml_parser_set_scanner_error(parser, \"while scanning a %YAML directive\",\n\t\t\t\tstart_mark, \"found extremely long version number\")\n\t\t}\n\t\tvalue = value*10 + int8(as_digit(parser.buffer, parser.buffer_pos))\n\t\tskip(parser)\n\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Check if the number was present.\n\tif length == 0 {\n\t\treturn yaml_parser_set_scanner_error(parser, \"while scanning a %YAML directive\",\n\t\t\tstart_mark, \"did not find expected version number\")\n\t}\n\t*number = value\n\treturn true\n}\n\n// Scan the value of a TAG-DIRECTIVE token.\n//\n// Scope:\n//      %TAG    !yaml!  tag:yaml.org,2002:  \\n\n//          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n//\nfunc yaml_parser_scan_tag_directive_value(parser *yaml_parser_t, start_mark yaml_mark_t, handle, prefix *[]byte) bool {\n\tvar handle_value, prefix_value []byte\n\n\t// Eat whitespaces.\n\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\treturn false\n\t}\n\n\tfor is_blank(parser.buffer, parser.buffer_pos) {\n\t\tskip(parser)\n\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Scan a handle.\n\tif !yaml_parser_scan_tag_handle(parser, true, start_mark, &handle_value) {\n\t\treturn false\n\t}\n\n\t// Expect a whitespace.\n\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\treturn false\n\t}\n\tif !is_blank(parser.buffer, parser.buffer_pos) {\n\t\tyaml_parser_set_scanner_error(parser, \"while scanning a %TAG directive\",\n\t\t\tstart_mark, \"did not find expected whitespace\")\n\t\treturn false\n\t}\n\n\t// Eat whitespaces.\n\tfor is_blank(parser.buffer, parser.buffer_pos) {\n\t\tskip(parser)\n\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Scan a prefix.\n\tif !yaml_parser_scan_tag_uri(parser, true, nil, start_mark, &prefix_value) {\n\t\treturn false\n\t}\n\n\t// Expect a whitespace or line break.\n\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\treturn false\n\t}\n\tif !is_blankz(parser.buffer, parser.buffer_pos) {\n\t\tyaml_parser_set_scanner_error(parser, \"while scanning a %TAG directive\",\n\t\t\tstart_mark, \"did not find expected whitespace or line break\")\n\t\treturn false\n\t}\n\n\t*handle = handle_value\n\t*prefix = prefix_value\n\treturn true\n}\n\nfunc yaml_parser_scan_anchor(parser *yaml_parser_t, token *yaml_token_t, typ yaml_token_type_t) bool {\n\tvar s []byte\n\n\t// Eat the indicator character.\n\tstart_mark := parser.mark\n\tskip(parser)\n\n\t// Consume the value.\n\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\treturn false\n\t}\n\n\tfor is_alpha(parser.buffer, parser.buffer_pos) {\n\t\ts = read(parser, s)\n\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\tend_mark := parser.mark\n\n\t/*\n\t * Check if length of the anchor is greater than 0 and it is followed by\n\t * a whitespace character or one of the indicators:\n\t *\n\t *      '?', ':', ',', ']', '}', '%', '@', '`'.\n\t */\n\n\tif len(s) == 0 ||\n\t\t!(is_blankz(parser.buffer, parser.buffer_pos) || parser.buffer[parser.buffer_pos] == '?' ||\n\t\t\tparser.buffer[parser.buffer_pos] == ':' || parser.buffer[parser.buffer_pos] == ',' ||\n\t\t\tparser.buffer[parser.buffer_pos] == ']' || parser.buffer[parser.buffer_pos] == '}' ||\n\t\t\tparser.buffer[parser.buffer_pos] == '%' || parser.buffer[parser.buffer_pos] == '@' ||\n\t\t\tparser.buffer[parser.buffer_pos] == '`') {\n\t\tcontext := \"while scanning an alias\"\n\t\tif typ == yaml_ANCHOR_TOKEN {\n\t\t\tcontext = \"while scanning an anchor\"\n\t\t}\n\t\tyaml_parser_set_scanner_error(parser, context, start_mark,\n\t\t\t\"did not find expected alphabetic or numeric character\")\n\t\treturn false\n\t}\n\n\t// Create a token.\n\t*token = yaml_token_t{\n\t\ttyp:        typ,\n\t\tstart_mark: start_mark,\n\t\tend_mark:   end_mark,\n\t\tvalue:      s,\n\t}\n\n\treturn true\n}\n\n/*\n * Scan a TAG token.\n */\n\nfunc yaml_parser_scan_tag(parser *yaml_parser_t, token *yaml_token_t) bool {\n\tvar handle, suffix []byte\n\n\tstart_mark := parser.mark\n\n\t// Check if the tag is in the canonical form.\n\tif parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {\n\t\treturn false\n\t}\n\n\tif parser.buffer[parser.buffer_pos+1] == '<' {\n\t\t// Keep the handle as ''\n\n\t\t// Eat '!<'\n\t\tskip(parser)\n\t\tskip(parser)\n\n\t\t// Consume the tag value.\n\t\tif !yaml_parser_scan_tag_uri(parser, false, nil, start_mark, &suffix) {\n\t\t\treturn false\n\t\t}\n\n\t\t// Check for '>' and eat it.\n\t\tif parser.buffer[parser.buffer_pos] != '>' {\n\t\t\tyaml_parser_set_scanner_error(parser, \"while scanning a tag\",\n\t\t\t\tstart_mark, \"did not find the expected '>'\")\n\t\t\treturn false\n\t\t}\n\n\t\tskip(parser)\n\t} else {\n\t\t// The tag has either the '!suffix' or the '!handle!suffix' form.\n\n\t\t// First, try to scan a handle.\n\t\tif !yaml_parser_scan_tag_handle(parser, false, start_mark, &handle) {\n\t\t\treturn false\n\t\t}\n\n\t\t// Check if it is, indeed, handle.\n\t\tif handle[0] == '!' && len(handle) > 1 && handle[len(handle)-1] == '!' {\n\t\t\t// Scan the suffix now.\n\t\t\tif !yaml_parser_scan_tag_uri(parser, false, nil, start_mark, &suffix) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t} else {\n\t\t\t// It wasn't a handle after all.  Scan the rest of the tag.\n\t\t\tif !yaml_parser_scan_tag_uri(parser, false, handle, start_mark, &suffix) {\n\t\t\t\treturn false\n\t\t\t}\n\n\t\t\t// Set the handle to '!'.\n\t\t\thandle = []byte{'!'}\n\n\t\t\t// A special case: the '!' tag.  Set the handle to '' and the\n\t\t\t// suffix to '!'.\n\t\t\tif len(suffix) == 0 {\n\t\t\t\thandle, suffix = suffix, handle\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check the character which ends the tag.\n\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\treturn false\n\t}\n\tif !is_blankz(parser.buffer, parser.buffer_pos) {\n\t\tyaml_parser_set_scanner_error(parser, \"while scanning a tag\",\n\t\t\tstart_mark, \"did not find expected whitespace or line break\")\n\t\treturn false\n\t}\n\n\tend_mark := parser.mark\n\n\t// Create a token.\n\t*token = yaml_token_t{\n\t\ttyp:        yaml_TAG_TOKEN,\n\t\tstart_mark: start_mark,\n\t\tend_mark:   end_mark,\n\t\tvalue:      handle,\n\t\tsuffix:     suffix,\n\t}\n\treturn true\n}\n\n// Scan a tag handle.\nfunc yaml_parser_scan_tag_handle(parser *yaml_parser_t, directive bool, start_mark yaml_mark_t, handle *[]byte) bool {\n\t// Check the initial '!' character.\n\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\treturn false\n\t}\n\tif parser.buffer[parser.buffer_pos] != '!' {\n\t\tyaml_parser_set_scanner_tag_error(parser, directive,\n\t\t\tstart_mark, \"did not find expected '!'\")\n\t\treturn false\n\t}\n\n\tvar s []byte\n\n\t// Copy the '!' character.\n\ts = read(parser, s)\n\n\t// Copy all subsequent alphabetical and numerical characters.\n\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\treturn false\n\t}\n\tfor is_alpha(parser.buffer, parser.buffer_pos) {\n\t\ts = read(parser, s)\n\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Check if the trailing character is '!' and copy it.\n\tif parser.buffer[parser.buffer_pos] == '!' {\n\t\ts = read(parser, s)\n\t} else {\n\t\t// It's either the '!' tag or not really a tag handle.  If it's a %TAG\n\t\t// directive, it's an error.  If it's a tag token, it must be a part of URI.\n\t\tif directive && string(s) != \"!\" {\n\t\t\tyaml_parser_set_scanner_tag_error(parser, directive,\n\t\t\t\tstart_mark, \"did not find expected '!'\")\n\t\t\treturn false\n\t\t}\n\t}\n\n\t*handle = s\n\treturn true\n}\n\n// Scan a tag.\nfunc yaml_parser_scan_tag_uri(parser *yaml_parser_t, directive bool, head []byte, start_mark yaml_mark_t, uri *[]byte) bool {\n\t//size_t length = head ? strlen((char *)head) : 0\n\tvar s []byte\n\thasTag := len(head) > 0\n\n\t// Copy the head if needed.\n\t//\n\t// Note that we don't copy the leading '!' character.\n\tif len(head) > 1 {\n\t\ts = append(s, head[1:]...)\n\t}\n\n\t// Scan the tag.\n\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\treturn false\n\t}\n\n\t// The set of characters that may appear in URI is as follows:\n\t//\n\t//      '0'-'9', 'A'-'Z', 'a'-'z', '_', '-', ';', '/', '?', ':', '@', '&',\n\t//      '=', '+', '$', ',', '.', '!', '~', '*', '\\'', '(', ')', '[', ']',\n\t//      '%'.\n\t// [Go] TODO Convert this into more reasonable logic.\n\tfor is_alpha(parser.buffer, parser.buffer_pos) || parser.buffer[parser.buffer_pos] == ';' ||\n\t\tparser.buffer[parser.buffer_pos] == '/' || parser.buffer[parser.buffer_pos] == '?' ||\n\t\tparser.buffer[parser.buffer_pos] == ':' || parser.buffer[parser.buffer_pos] == '@' ||\n\t\tparser.buffer[parser.buffer_pos] == '&' || parser.buffer[parser.buffer_pos] == '=' ||\n\t\tparser.buffer[parser.buffer_pos] == '+' || parser.buffer[parser.buffer_pos] == '$' ||\n\t\tparser.buffer[parser.buffer_pos] == ',' || parser.buffer[parser.buffer_pos] == '.' ||\n\t\tparser.buffer[parser.buffer_pos] == '!' || parser.buffer[parser.buffer_pos] == '~' ||\n\t\tparser.buffer[parser.buffer_pos] == '*' || parser.buffer[parser.buffer_pos] == '\\'' ||\n\t\tparser.buffer[parser.buffer_pos] == '(' || parser.buffer[parser.buffer_pos] == ')' ||\n\t\tparser.buffer[parser.buffer_pos] == '[' || parser.buffer[parser.buffer_pos] == ']' ||\n\t\tparser.buffer[parser.buffer_pos] == '%' {\n\t\t// Check if it is a URI-escape sequence.\n\t\tif parser.buffer[parser.buffer_pos] == '%' {\n\t\t\tif !yaml_parser_scan_uri_escapes(parser, directive, start_mark, &s) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t} else {\n\t\t\ts = read(parser, s)\n\t\t}\n\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\treturn false\n\t\t}\n\t\thasTag = true\n\t}\n\n\tif !hasTag {\n\t\tyaml_parser_set_scanner_tag_error(parser, directive,\n\t\t\tstart_mark, \"did not find expected tag URI\")\n\t\treturn false\n\t}\n\t*uri = s\n\treturn true\n}\n\n// Decode an URI-escape sequence corresponding to a single UTF-8 character.\nfunc yaml_parser_scan_uri_escapes(parser *yaml_parser_t, directive bool, start_mark yaml_mark_t, s *[]byte) bool {\n\n\t// Decode the required number of characters.\n\tw := 1024\n\tfor w > 0 {\n\t\t// Check for a URI-escaped octet.\n\t\tif parser.unread < 3 && !yaml_parser_update_buffer(parser, 3) {\n\t\t\treturn false\n\t\t}\n\n\t\tif !(parser.buffer[parser.buffer_pos] == '%' &&\n\t\t\tis_hex(parser.buffer, parser.buffer_pos+1) &&\n\t\t\tis_hex(parser.buffer, parser.buffer_pos+2)) {\n\t\t\treturn yaml_parser_set_scanner_tag_error(parser, directive,\n\t\t\t\tstart_mark, \"did not find URI escaped octet\")\n\t\t}\n\n\t\t// Get the octet.\n\t\toctet := byte((as_hex(parser.buffer, parser.buffer_pos+1) << 4) + as_hex(parser.buffer, parser.buffer_pos+2))\n\n\t\t// If it is the leading octet, determine the length of the UTF-8 sequence.\n\t\tif w == 1024 {\n\t\t\tw = width(octet)\n\t\t\tif w == 0 {\n\t\t\t\treturn yaml_parser_set_scanner_tag_error(parser, directive,\n\t\t\t\t\tstart_mark, \"found an incorrect leading UTF-8 octet\")\n\t\t\t}\n\t\t} else {\n\t\t\t// Check if the trailing octet is correct.\n\t\t\tif octet&0xC0 != 0x80 {\n\t\t\t\treturn yaml_parser_set_scanner_tag_error(parser, directive,\n\t\t\t\t\tstart_mark, \"found an incorrect trailing UTF-8 octet\")\n\t\t\t}\n\t\t}\n\n\t\t// Copy the octet and move the pointers.\n\t\t*s = append(*s, octet)\n\t\tskip(parser)\n\t\tskip(parser)\n\t\tskip(parser)\n\t\tw--\n\t}\n\treturn true\n}\n\n// Scan a block scalar.\nfunc yaml_parser_scan_block_scalar(parser *yaml_parser_t, token *yaml_token_t, literal bool) bool {\n\t// Eat the indicator '|' or '>'.\n\tstart_mark := parser.mark\n\tskip(parser)\n\n\t// Scan the additional block scalar indicators.\n\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\treturn false\n\t}\n\n\t// Check for a chomping indicator.\n\tvar chomping, increment int\n\tif parser.buffer[parser.buffer_pos] == '+' || parser.buffer[parser.buffer_pos] == '-' {\n\t\t// Set the chomping method and eat the indicator.\n\t\tif parser.buffer[parser.buffer_pos] == '+' {\n\t\t\tchomping = +1\n\t\t} else {\n\t\t\tchomping = -1\n\t\t}\n\t\tskip(parser)\n\n\t\t// Check for an indentation indicator.\n\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\treturn false\n\t\t}\n\t\tif is_digit(parser.buffer, parser.buffer_pos) {\n\t\t\t// Check that the indentation is greater than 0.\n\t\t\tif parser.buffer[parser.buffer_pos] == '0' {\n\t\t\t\tyaml_parser_set_scanner_error(parser, \"while scanning a block scalar\",\n\t\t\t\t\tstart_mark, \"found an indentation indicator equal to 0\")\n\t\t\t\treturn false\n\t\t\t}\n\n\t\t\t// Get the indentation level and eat the indicator.\n\t\t\tincrement = as_digit(parser.buffer, parser.buffer_pos)\n\t\t\tskip(parser)\n\t\t}\n\n\t} else if is_digit(parser.buffer, parser.buffer_pos) {\n\t\t// Do the same as above, but in the opposite order.\n\n\t\tif parser.buffer[parser.buffer_pos] == '0' {\n\t\t\tyaml_parser_set_scanner_error(parser, \"while scanning a block scalar\",\n\t\t\t\tstart_mark, \"found an indentation indicator equal to 0\")\n\t\t\treturn false\n\t\t}\n\t\tincrement = as_digit(parser.buffer, parser.buffer_pos)\n\t\tskip(parser)\n\n\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\treturn false\n\t\t}\n\t\tif parser.buffer[parser.buffer_pos] == '+' || parser.buffer[parser.buffer_pos] == '-' {\n\t\t\tif parser.buffer[parser.buffer_pos] == '+' {\n\t\t\t\tchomping = +1\n\t\t\t} else {\n\t\t\t\tchomping = -1\n\t\t\t}\n\t\t\tskip(parser)\n\t\t}\n\t}\n\n\t// Eat whitespaces and comments to the end of the line.\n\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\treturn false\n\t}\n\tfor is_blank(parser.buffer, parser.buffer_pos) {\n\t\tskip(parser)\n\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\treturn false\n\t\t}\n\t}\n\tif parser.buffer[parser.buffer_pos] == '#' {\n\t\tif !yaml_parser_scan_line_comment(parser, start_mark) {\n\t\t\treturn false\n\t\t}\n\t\tfor !is_breakz(parser.buffer, parser.buffer_pos) {\n\t\t\tskip(parser)\n\t\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check if we are at the end of the line.\n\tif !is_breakz(parser.buffer, parser.buffer_pos) {\n\t\tyaml_parser_set_scanner_error(parser, \"while scanning a block scalar\",\n\t\t\tstart_mark, \"did not find expected comment or line break\")\n\t\treturn false\n\t}\n\n\t// Eat a line break.\n\tif is_break(parser.buffer, parser.buffer_pos) {\n\t\tif parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {\n\t\t\treturn false\n\t\t}\n\t\tskip_line(parser)\n\t}\n\n\tend_mark := parser.mark\n\n\t// Set the indentation level if it was specified.\n\tvar indent int\n\tif increment > 0 {\n\t\tif parser.indent >= 0 {\n\t\t\tindent = parser.indent + increment\n\t\t} else {\n\t\t\tindent = increment\n\t\t}\n\t}\n\n\t// Scan the leading line breaks and determine the indentation level if needed.\n\tvar s, leading_break, trailing_breaks []byte\n\tif !yaml_parser_scan_block_scalar_breaks(parser, &indent, &trailing_breaks, start_mark, &end_mark) {\n\t\treturn false\n\t}\n\n\t// Scan the block scalar content.\n\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\treturn false\n\t}\n\tvar leading_blank, trailing_blank bool\n\tfor parser.mark.column == indent && !is_z(parser.buffer, parser.buffer_pos) {\n\t\t// We are at the beginning of a non-empty line.\n\n\t\t// Is it a trailing whitespace?\n\t\ttrailing_blank = is_blank(parser.buffer, parser.buffer_pos)\n\n\t\t// Check if we need to fold the leading line break.\n\t\tif !literal && !leading_blank && !trailing_blank && len(leading_break) > 0 && leading_break[0] == '\\n' {\n\t\t\t// Do we need to join the lines by space?\n\t\t\tif len(trailing_breaks) == 0 {\n\t\t\t\ts = append(s, ' ')\n\t\t\t}\n\t\t} else {\n\t\t\ts = append(s, leading_break...)\n\t\t}\n\t\tleading_break = leading_break[:0]\n\n\t\t// Append the remaining line breaks.\n\t\ts = append(s, trailing_breaks...)\n\t\ttrailing_breaks = trailing_breaks[:0]\n\n\t\t// Is it a leading whitespace?\n\t\tleading_blank = is_blank(parser.buffer, parser.buffer_pos)\n\n\t\t// Consume the current line.\n\t\tfor !is_breakz(parser.buffer, parser.buffer_pos) {\n\t\t\ts = read(parser, s)\n\t\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\n\t\t// Consume the line break.\n\t\tif parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {\n\t\t\treturn false\n\t\t}\n\n\t\tleading_break = read_line(parser, leading_break)\n\n\t\t// Eat the following indentation spaces and line breaks.\n\t\tif !yaml_parser_scan_block_scalar_breaks(parser, &indent, &trailing_breaks, start_mark, &end_mark) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Chomp the tail.\n\tif chomping != -1 {\n\t\ts = append(s, leading_break...)\n\t}\n\tif chomping == 1 {\n\t\ts = append(s, trailing_breaks...)\n\t}\n\n\t// Create a token.\n\t*token = yaml_token_t{\n\t\ttyp:        yaml_SCALAR_TOKEN,\n\t\tstart_mark: start_mark,\n\t\tend_mark:   end_mark,\n\t\tvalue:      s,\n\t\tstyle:      yaml_LITERAL_SCALAR_STYLE,\n\t}\n\tif !literal {\n\t\ttoken.style = yaml_FOLDED_SCALAR_STYLE\n\t}\n\treturn true\n}\n\n// Scan indentation spaces and line breaks for a block scalar.  Determine the\n// indentation level if needed.\nfunc yaml_parser_scan_block_scalar_breaks(parser *yaml_parser_t, indent *int, breaks *[]byte, start_mark yaml_mark_t, end_mark *yaml_mark_t) bool {\n\t*end_mark = parser.mark\n\n\t// Eat the indentation spaces and line breaks.\n\tmax_indent := 0\n\tfor {\n\t\t// Eat the indentation spaces.\n\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\treturn false\n\t\t}\n\t\tfor (*indent == 0 || parser.mark.column < *indent) && is_space(parser.buffer, parser.buffer_pos) {\n\t\t\tskip(parser)\n\t\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\tif parser.mark.column > max_indent {\n\t\t\tmax_indent = parser.mark.column\n\t\t}\n\n\t\t// Check for a tab character messing the indentation.\n\t\tif (*indent == 0 || parser.mark.column < *indent) && is_tab(parser.buffer, parser.buffer_pos) {\n\t\t\treturn yaml_parser_set_scanner_error(parser, \"while scanning a block scalar\",\n\t\t\t\tstart_mark, \"found a tab character where an indentation space is expected\")\n\t\t}\n\n\t\t// Have we found a non-empty line?\n\t\tif !is_break(parser.buffer, parser.buffer_pos) {\n\t\t\tbreak\n\t\t}\n\n\t\t// Consume the line break.\n\t\tif parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {\n\t\t\treturn false\n\t\t}\n\t\t// [Go] Should really be returning breaks instead.\n\t\t*breaks = read_line(parser, *breaks)\n\t\t*end_mark = parser.mark\n\t}\n\n\t// Determine the indentation level if needed.\n\tif *indent == 0 {\n\t\t*indent = max_indent\n\t\tif *indent < parser.indent+1 {\n\t\t\t*indent = parser.indent + 1\n\t\t}\n\t\tif *indent < 1 {\n\t\t\t*indent = 1\n\t\t}\n\t}\n\treturn true\n}\n\n// Scan a quoted scalar.\nfunc yaml_parser_scan_flow_scalar(parser *yaml_parser_t, token *yaml_token_t, single bool) bool {\n\t// Eat the left quote.\n\tstart_mark := parser.mark\n\tskip(parser)\n\n\t// Consume the content of the quoted scalar.\n\tvar s, leading_break, trailing_breaks, whitespaces []byte\n\tfor {\n\t\t// Check that there are no document indicators at the beginning of the line.\n\t\tif parser.unread < 4 && !yaml_parser_update_buffer(parser, 4) {\n\t\t\treturn false\n\t\t}\n\n\t\tif parser.mark.column == 0 &&\n\t\t\t((parser.buffer[parser.buffer_pos+0] == '-' &&\n\t\t\t\tparser.buffer[parser.buffer_pos+1] == '-' &&\n\t\t\t\tparser.buffer[parser.buffer_pos+2] == '-') ||\n\t\t\t\t(parser.buffer[parser.buffer_pos+0] == '.' &&\n\t\t\t\t\tparser.buffer[parser.buffer_pos+1] == '.' &&\n\t\t\t\t\tparser.buffer[parser.buffer_pos+2] == '.')) &&\n\t\t\tis_blankz(parser.buffer, parser.buffer_pos+3) {\n\t\t\tyaml_parser_set_scanner_error(parser, \"while scanning a quoted scalar\",\n\t\t\t\tstart_mark, \"found unexpected document indicator\")\n\t\t\treturn false\n\t\t}\n\n\t\t// Check for EOF.\n\t\tif is_z(parser.buffer, parser.buffer_pos) {\n\t\t\tyaml_parser_set_scanner_error(parser, \"while scanning a quoted scalar\",\n\t\t\t\tstart_mark, \"found unexpected end of stream\")\n\t\t\treturn false\n\t\t}\n\n\t\t// Consume non-blank characters.\n\t\tleading_blanks := false\n\t\tfor !is_blankz(parser.buffer, parser.buffer_pos) {\n\t\t\tif single && parser.buffer[parser.buffer_pos] == '\\'' && parser.buffer[parser.buffer_pos+1] == '\\'' {\n\t\t\t\t// Is is an escaped single quote.\n\t\t\t\ts = append(s, '\\'')\n\t\t\t\tskip(parser)\n\t\t\t\tskip(parser)\n\n\t\t\t} else if single && parser.buffer[parser.buffer_pos] == '\\'' {\n\t\t\t\t// It is a right single quote.\n\t\t\t\tbreak\n\t\t\t} else if !single && parser.buffer[parser.buffer_pos] == '\"' {\n\t\t\t\t// It is a right double quote.\n\t\t\t\tbreak\n\n\t\t\t} else if !single && parser.buffer[parser.buffer_pos] == '\\\\' && is_break(parser.buffer, parser.buffer_pos+1) {\n\t\t\t\t// It is an escaped line break.\n\t\t\t\tif parser.unread < 3 && !yaml_parser_update_buffer(parser, 3) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\tskip(parser)\n\t\t\t\tskip_line(parser)\n\t\t\t\tleading_blanks = true\n\t\t\t\tbreak\n\n\t\t\t} else if !single && parser.buffer[parser.buffer_pos] == '\\\\' {\n\t\t\t\t// It is an escape sequence.\n\t\t\t\tcode_length := 0\n\n\t\t\t\t// Check the escape character.\n\t\t\t\tswitch parser.buffer[parser.buffer_pos+1] {\n\t\t\t\tcase '0':\n\t\t\t\t\ts = append(s, 0)\n\t\t\t\tcase 'a':\n\t\t\t\t\ts = append(s, '\\x07')\n\t\t\t\tcase 'b':\n\t\t\t\t\ts = append(s, '\\x08')\n\t\t\t\tcase 't', '\\t':\n\t\t\t\t\ts = append(s, '\\x09')\n\t\t\t\tcase 'n':\n\t\t\t\t\ts = append(s, '\\x0A')\n\t\t\t\tcase 'v':\n\t\t\t\t\ts = append(s, '\\x0B')\n\t\t\t\tcase 'f':\n\t\t\t\t\ts = append(s, '\\x0C')\n\t\t\t\tcase 'r':\n\t\t\t\t\ts = append(s, '\\x0D')\n\t\t\t\tcase 'e':\n\t\t\t\t\ts = append(s, '\\x1B')\n\t\t\t\tcase ' ':\n\t\t\t\t\ts = append(s, '\\x20')\n\t\t\t\tcase '\"':\n\t\t\t\t\ts = append(s, '\"')\n\t\t\t\tcase '\\'':\n\t\t\t\t\ts = append(s, '\\'')\n\t\t\t\tcase '\\\\':\n\t\t\t\t\ts = append(s, '\\\\')\n\t\t\t\tcase 'N': // NEL (#x85)\n\t\t\t\t\ts = append(s, '\\xC2')\n\t\t\t\t\ts = append(s, '\\x85')\n\t\t\t\tcase '_': // #xA0\n\t\t\t\t\ts = append(s, '\\xC2')\n\t\t\t\t\ts = append(s, '\\xA0')\n\t\t\t\tcase 'L': // LS (#x2028)\n\t\t\t\t\ts = append(s, '\\xE2')\n\t\t\t\t\ts = append(s, '\\x80')\n\t\t\t\t\ts = append(s, '\\xA8')\n\t\t\t\tcase 'P': // PS (#x2029)\n\t\t\t\t\ts = append(s, '\\xE2')\n\t\t\t\t\ts = append(s, '\\x80')\n\t\t\t\t\ts = append(s, '\\xA9')\n\t\t\t\tcase 'x':\n\t\t\t\t\tcode_length = 2\n\t\t\t\tcase 'u':\n\t\t\t\t\tcode_length = 4\n\t\t\t\tcase 'U':\n\t\t\t\t\tcode_length = 8\n\t\t\t\tdefault:\n\t\t\t\t\tyaml_parser_set_scanner_error(parser, \"while parsing a quoted scalar\",\n\t\t\t\t\t\tstart_mark, \"found unknown escape character\")\n\t\t\t\t\treturn false\n\t\t\t\t}\n\n\t\t\t\tskip(parser)\n\t\t\t\tskip(parser)\n\n\t\t\t\t// Consume an arbitrary escape code.\n\t\t\t\tif code_length > 0 {\n\t\t\t\t\tvar value int\n\n\t\t\t\t\t// Scan the character value.\n\t\t\t\t\tif parser.unread < code_length && !yaml_parser_update_buffer(parser, code_length) {\n\t\t\t\t\t\treturn false\n\t\t\t\t\t}\n\t\t\t\t\tfor k := 0; k < code_length; k++ {\n\t\t\t\t\t\tif !is_hex(parser.buffer, parser.buffer_pos+k) {\n\t\t\t\t\t\t\tyaml_parser_set_scanner_error(parser, \"while parsing a quoted scalar\",\n\t\t\t\t\t\t\t\tstart_mark, \"did not find expected hexdecimal number\")\n\t\t\t\t\t\t\treturn false\n\t\t\t\t\t\t}\n\t\t\t\t\t\tvalue = (value << 4) + as_hex(parser.buffer, parser.buffer_pos+k)\n\t\t\t\t\t}\n\n\t\t\t\t\t// Check the value and write the character.\n\t\t\t\t\tif (value >= 0xD800 && value <= 0xDFFF) || value > 0x10FFFF {\n\t\t\t\t\t\tyaml_parser_set_scanner_error(parser, \"while parsing a quoted scalar\",\n\t\t\t\t\t\t\tstart_mark, \"found invalid Unicode character escape code\")\n\t\t\t\t\t\treturn false\n\t\t\t\t\t}\n\t\t\t\t\tif value <= 0x7F {\n\t\t\t\t\t\ts = append(s, byte(value))\n\t\t\t\t\t} else if value <= 0x7FF {\n\t\t\t\t\t\ts = append(s, byte(0xC0+(value>>6)))\n\t\t\t\t\t\ts = append(s, byte(0x80+(value&0x3F)))\n\t\t\t\t\t} else if value <= 0xFFFF {\n\t\t\t\t\t\ts = append(s, byte(0xE0+(value>>12)))\n\t\t\t\t\t\ts = append(s, byte(0x80+((value>>6)&0x3F)))\n\t\t\t\t\t\ts = append(s, byte(0x80+(value&0x3F)))\n\t\t\t\t\t} else {\n\t\t\t\t\t\ts = append(s, byte(0xF0+(value>>18)))\n\t\t\t\t\t\ts = append(s, byte(0x80+((value>>12)&0x3F)))\n\t\t\t\t\t\ts = append(s, byte(0x80+((value>>6)&0x3F)))\n\t\t\t\t\t\ts = append(s, byte(0x80+(value&0x3F)))\n\t\t\t\t\t}\n\n\t\t\t\t\t// Advance the pointer.\n\t\t\t\t\tfor k := 0; k < code_length; k++ {\n\t\t\t\t\t\tskip(parser)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// It is a non-escaped non-blank character.\n\t\t\t\ts = read(parser, s)\n\t\t\t}\n\t\t\tif parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\n\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\treturn false\n\t\t}\n\n\t\t// Check if we are at the end of the scalar.\n\t\tif single {\n\t\t\tif parser.buffer[parser.buffer_pos] == '\\'' {\n\t\t\t\tbreak\n\t\t\t}\n\t\t} else {\n\t\t\tif parser.buffer[parser.buffer_pos] == '\"' {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\t// Consume blank characters.\n\t\tfor is_blank(parser.buffer, parser.buffer_pos) || is_break(parser.buffer, parser.buffer_pos) {\n\t\t\tif is_blank(parser.buffer, parser.buffer_pos) {\n\t\t\t\t// Consume a space or a tab character.\n\t\t\t\tif !leading_blanks {\n\t\t\t\t\twhitespaces = read(parser, whitespaces)\n\t\t\t\t} else {\n\t\t\t\t\tskip(parser)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\n\t\t\t\t// Check if it is a first line break.\n\t\t\t\tif !leading_blanks {\n\t\t\t\t\twhitespaces = whitespaces[:0]\n\t\t\t\t\tleading_break = read_line(parser, leading_break)\n\t\t\t\t\tleading_blanks = true\n\t\t\t\t} else {\n\t\t\t\t\ttrailing_breaks = read_line(parser, trailing_breaks)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\n\t\t// Join the whitespaces or fold line breaks.\n\t\tif leading_blanks {\n\t\t\t// Do we need to fold line breaks?\n\t\t\tif len(leading_break) > 0 && leading_break[0] == '\\n' {\n\t\t\t\tif len(trailing_breaks) == 0 {\n\t\t\t\t\ts = append(s, ' ')\n\t\t\t\t} else {\n\t\t\t\t\ts = append(s, trailing_breaks...)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\ts = append(s, leading_break...)\n\t\t\t\ts = append(s, trailing_breaks...)\n\t\t\t}\n\t\t\ttrailing_breaks = trailing_breaks[:0]\n\t\t\tleading_break = leading_break[:0]\n\t\t} else {\n\t\t\ts = append(s, whitespaces...)\n\t\t\twhitespaces = whitespaces[:0]\n\t\t}\n\t}\n\n\t// Eat the right quote.\n\tskip(parser)\n\tend_mark := parser.mark\n\n\t// Create a token.\n\t*token = yaml_token_t{\n\t\ttyp:        yaml_SCALAR_TOKEN,\n\t\tstart_mark: start_mark,\n\t\tend_mark:   end_mark,\n\t\tvalue:      s,\n\t\tstyle:      yaml_SINGLE_QUOTED_SCALAR_STYLE,\n\t}\n\tif !single {\n\t\ttoken.style = yaml_DOUBLE_QUOTED_SCALAR_STYLE\n\t}\n\treturn true\n}\n\n// Scan a plain scalar.\nfunc yaml_parser_scan_plain_scalar(parser *yaml_parser_t, token *yaml_token_t) bool {\n\n\tvar s, leading_break, trailing_breaks, whitespaces []byte\n\tvar leading_blanks bool\n\tvar indent = parser.indent + 1\n\n\tstart_mark := parser.mark\n\tend_mark := parser.mark\n\n\t// Consume the content of the plain scalar.\n\tfor {\n\t\t// Check for a document indicator.\n\t\tif parser.unread < 4 && !yaml_parser_update_buffer(parser, 4) {\n\t\t\treturn false\n\t\t}\n\t\tif parser.mark.column == 0 &&\n\t\t\t((parser.buffer[parser.buffer_pos+0] == '-' &&\n\t\t\t\tparser.buffer[parser.buffer_pos+1] == '-' &&\n\t\t\t\tparser.buffer[parser.buffer_pos+2] == '-') ||\n\t\t\t\t(parser.buffer[parser.buffer_pos+0] == '.' &&\n\t\t\t\t\tparser.buffer[parser.buffer_pos+1] == '.' &&\n\t\t\t\t\tparser.buffer[parser.buffer_pos+2] == '.')) &&\n\t\t\tis_blankz(parser.buffer, parser.buffer_pos+3) {\n\t\t\tbreak\n\t\t}\n\n\t\t// Check for a comment.\n\t\tif parser.buffer[parser.buffer_pos] == '#' {\n\t\t\tbreak\n\t\t}\n\n\t\t// Consume non-blank characters.\n\t\tfor !is_blankz(parser.buffer, parser.buffer_pos) {\n\n\t\t\t// Check for indicators that may end a plain scalar.\n\t\t\tif (parser.buffer[parser.buffer_pos] == ':' && is_blankz(parser.buffer, parser.buffer_pos+1)) ||\n\t\t\t\t(parser.flow_level > 0 &&\n\t\t\t\t\t(parser.buffer[parser.buffer_pos] == ',' ||\n\t\t\t\t\t\tparser.buffer[parser.buffer_pos] == '?' || parser.buffer[parser.buffer_pos] == '[' ||\n\t\t\t\t\t\tparser.buffer[parser.buffer_pos] == ']' || parser.buffer[parser.buffer_pos] == '{' ||\n\t\t\t\t\t\tparser.buffer[parser.buffer_pos] == '}')) {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// Check if we need to join whitespaces and breaks.\n\t\t\tif leading_blanks || len(whitespaces) > 0 {\n\t\t\t\tif leading_blanks {\n\t\t\t\t\t// Do we need to fold line breaks?\n\t\t\t\t\tif leading_break[0] == '\\n' {\n\t\t\t\t\t\tif len(trailing_breaks) == 0 {\n\t\t\t\t\t\t\ts = append(s, ' ')\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\ts = append(s, trailing_breaks...)\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\ts = append(s, leading_break...)\n\t\t\t\t\t\ts = append(s, trailing_breaks...)\n\t\t\t\t\t}\n\t\t\t\t\ttrailing_breaks = trailing_breaks[:0]\n\t\t\t\t\tleading_break = leading_break[:0]\n\t\t\t\t\tleading_blanks = false\n\t\t\t\t} else {\n\t\t\t\t\ts = append(s, whitespaces...)\n\t\t\t\t\twhitespaces = whitespaces[:0]\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Copy the character.\n\t\t\ts = read(parser, s)\n\n\t\t\tend_mark = parser.mark\n\t\t\tif parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\n\t\t// Is it the end?\n\t\tif !(is_blank(parser.buffer, parser.buffer_pos) || is_break(parser.buffer, parser.buffer_pos)) {\n\t\t\tbreak\n\t\t}\n\n\t\t// Consume blank characters.\n\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\treturn false\n\t\t}\n\n\t\tfor is_blank(parser.buffer, parser.buffer_pos) || is_break(parser.buffer, parser.buffer_pos) {\n\t\t\tif is_blank(parser.buffer, parser.buffer_pos) {\n\n\t\t\t\t// Check for tab characters that abuse indentation.\n\t\t\t\tif leading_blanks && parser.mark.column < indent && is_tab(parser.buffer, parser.buffer_pos) {\n\t\t\t\t\tyaml_parser_set_scanner_error(parser, \"while scanning a plain scalar\",\n\t\t\t\t\t\tstart_mark, \"found a tab character that violates indentation\")\n\t\t\t\t\treturn false\n\t\t\t\t}\n\n\t\t\t\t// Consume a space or a tab character.\n\t\t\t\tif !leading_blanks {\n\t\t\t\t\twhitespaces = read(parser, whitespaces)\n\t\t\t\t} else {\n\t\t\t\t\tskip(parser)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\n\t\t\t\t// Check if it is a first line break.\n\t\t\t\tif !leading_blanks {\n\t\t\t\t\twhitespaces = whitespaces[:0]\n\t\t\t\t\tleading_break = read_line(parser, leading_break)\n\t\t\t\t\tleading_blanks = true\n\t\t\t\t} else {\n\t\t\t\t\ttrailing_breaks = read_line(parser, trailing_breaks)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\n\t\t// Check indentation level.\n\t\tif parser.flow_level == 0 && parser.mark.column < indent {\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// Create a token.\n\t*token = yaml_token_t{\n\t\ttyp:        yaml_SCALAR_TOKEN,\n\t\tstart_mark: start_mark,\n\t\tend_mark:   end_mark,\n\t\tvalue:      s,\n\t\tstyle:      yaml_PLAIN_SCALAR_STYLE,\n\t}\n\n\t// Note that we change the 'simple_key_allowed' flag.\n\tif leading_blanks {\n\t\tparser.simple_key_allowed = true\n\t}\n\treturn true\n}\n\nfunc yaml_parser_scan_line_comment(parser *yaml_parser_t, token_mark yaml_mark_t) bool {\n\tif parser.newlines > 0 {\n\t\treturn true\n\t}\n\n\tvar start_mark yaml_mark_t\n\tvar text []byte\n\n\tfor peek := 0; peek < 512; peek++ {\n\t\tif parser.unread < peek+1 && !yaml_parser_update_buffer(parser, peek+1) {\n\t\t\tbreak\n\t\t}\n\t\tif is_blank(parser.buffer, parser.buffer_pos+peek) {\n\t\t\tcontinue\n\t\t}\n\t\tif parser.buffer[parser.buffer_pos+peek] == '#' {\n\t\t\tseen := parser.mark.index+peek\n\t\t\tfor {\n\t\t\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\tif is_breakz(parser.buffer, parser.buffer_pos) {\n\t\t\t\t\tif parser.mark.index >= seen {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t\tif parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {\n\t\t\t\t\t\treturn false\n\t\t\t\t\t}\n\t\t\t\t\tskip_line(parser)\n\t\t\t\t} else if parser.mark.index >= seen {\n\t\t\t\t\tif len(text) == 0 {\n\t\t\t\t\t\tstart_mark = parser.mark\n\t\t\t\t\t}\n\t\t\t\t\ttext = read(parser, text)\n\t\t\t\t} else {\n\t\t\t\t\tskip(parser)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tbreak\n\t}\n\tif len(text) > 0 {\n\t\tparser.comments = append(parser.comments, yaml_comment_t{\n\t\t\ttoken_mark: token_mark,\n\t\t\tstart_mark: start_mark,\n\t\t\tline: text,\n\t\t})\n\t}\n\treturn true\n}\n\nfunc yaml_parser_scan_comments(parser *yaml_parser_t, scan_mark yaml_mark_t) bool {\n\ttoken := parser.tokens[len(parser.tokens)-1]\n\n\tif token.typ == yaml_FLOW_ENTRY_TOKEN && len(parser.tokens) > 1 {\n\t\ttoken = parser.tokens[len(parser.tokens)-2]\n\t}\n\n\tvar token_mark = token.start_mark\n\tvar start_mark yaml_mark_t\n\tvar next_indent = parser.indent\n\tif next_indent < 0 {\n\t\tnext_indent = 0\n\t}\n\n\tvar recent_empty = false\n\tvar first_empty = parser.newlines <= 1\n\n\tvar line = parser.mark.line\n\tvar column = parser.mark.column\n\n\tvar text []byte\n\n\t// The foot line is the place where a comment must start to\n\t// still be considered as a foot of the prior content.\n\t// If there's some content in the currently parsed line, then\n\t// the foot is the line below it.\n\tvar foot_line = -1\n\tif scan_mark.line > 0 {\n\t\tfoot_line = parser.mark.line-parser.newlines+1\n\t\tif parser.newlines == 0 && parser.mark.column > 1 {\n\t\t\tfoot_line++\n\t\t}\n\t}\n\n\tvar peek = 0\n\tfor ; peek < 512; peek++ {\n\t\tif parser.unread < peek+1 && !yaml_parser_update_buffer(parser, peek+1) {\n\t\t\tbreak\n\t\t}\n\t\tcolumn++\n\t\tif is_blank(parser.buffer, parser.buffer_pos+peek) {\n\t\t\tcontinue\n\t\t}\n\t\tc := parser.buffer[parser.buffer_pos+peek]\n\t\tvar close_flow = parser.flow_level > 0 && (c == ']' || c == '}')\n\t\tif close_flow || is_breakz(parser.buffer, parser.buffer_pos+peek) {\n\t\t\t// Got line break or terminator.\n\t\t\tif close_flow || !recent_empty {\n\t\t\t\tif close_flow || first_empty && (start_mark.line == foot_line && token.typ != yaml_VALUE_TOKEN || start_mark.column-1 < next_indent) {\n\t\t\t\t\t// This is the first empty line and there were no empty lines before,\n\t\t\t\t\t// so this initial part of the comment is a foot of the prior token\n\t\t\t\t\t// instead of being a head for the following one. Split it up.\n\t\t\t\t\t// Alternatively, this might also be the last comment inside a flow\n\t\t\t\t\t// scope, so it must be a footer.\n\t\t\t\t\tif len(text) > 0 {\n\t\t\t\t\t\tif start_mark.column-1 < next_indent {\n\t\t\t\t\t\t\t// If dedented it's unrelated to the prior token.\n\t\t\t\t\t\t\ttoken_mark = start_mark\n\t\t\t\t\t\t}\n\t\t\t\t\t\tparser.comments = append(parser.comments, yaml_comment_t{\n\t\t\t\t\t\t\tscan_mark:  scan_mark,\n\t\t\t\t\t\t\ttoken_mark: token_mark,\n\t\t\t\t\t\t\tstart_mark: start_mark,\n\t\t\t\t\t\t\tend_mark:   yaml_mark_t{parser.mark.index + peek, line, column},\n\t\t\t\t\t\t\tfoot:       text,\n\t\t\t\t\t\t})\n\t\t\t\t\t\tscan_mark = yaml_mark_t{parser.mark.index + peek, line, column}\n\t\t\t\t\t\ttoken_mark = scan_mark\n\t\t\t\t\t\ttext = nil\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tif len(text) > 0 && parser.buffer[parser.buffer_pos+peek] != 0 {\n\t\t\t\t\t\ttext = append(text, '\\n')\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !is_break(parser.buffer, parser.buffer_pos+peek) {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tfirst_empty = false\n\t\t\trecent_empty = true\n\t\t\tcolumn = 0\n\t\t\tline++\n\t\t\tcontinue\n\t\t}\n\n\t\tif len(text) > 0 && (close_flow || column-1 < next_indent && column != start_mark.column) {\n\t\t\t// The comment at the different indentation is a foot of the\n\t\t\t// preceding data rather than a head of the upcoming one.\n\t\t\tparser.comments = append(parser.comments, yaml_comment_t{\n\t\t\t\tscan_mark:  scan_mark,\n\t\t\t\ttoken_mark: token_mark,\n\t\t\t\tstart_mark: start_mark,\n\t\t\t\tend_mark:   yaml_mark_t{parser.mark.index + peek, line, column},\n\t\t\t\tfoot:       text,\n\t\t\t})\n\t\t\tscan_mark = yaml_mark_t{parser.mark.index + peek, line, column}\n\t\t\ttoken_mark = scan_mark\n\t\t\ttext = nil\n\t\t}\n\n\t\tif parser.buffer[parser.buffer_pos+peek] != '#' {\n\t\t\tbreak\n\t\t}\n\n\t\tif len(text) == 0 {\n\t\t\tstart_mark = yaml_mark_t{parser.mark.index + peek, line, column}\n\t\t} else {\n\t\t\ttext = append(text, '\\n')\n\t\t}\n\n\t\trecent_empty = false\n\n\t\t// Consume until after the consumed comment line.\n\t\tseen := parser.mark.index+peek\n\t\tfor {\n\t\t\tif parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tif is_breakz(parser.buffer, parser.buffer_pos) {\n\t\t\t\tif parser.mark.index >= seen {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\tif parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\tskip_line(parser)\n\t\t\t} else if parser.mark.index >= seen {\n\t\t\t\ttext = read(parser, text)\n\t\t\t} else {\n\t\t\t\tskip(parser)\n\t\t\t}\n\t\t}\n\n\t\tpeek = 0\n\t\tcolumn = 0\n\t\tline = parser.mark.line\n\t\tnext_indent = parser.indent\n\t\tif next_indent < 0 {\n\t\t\tnext_indent = 0\n\t\t}\n\t}\n\n\tif len(text) > 0 {\n\t\tparser.comments = append(parser.comments, yaml_comment_t{\n\t\t\tscan_mark:  scan_mark,\n\t\t\ttoken_mark: start_mark,\n\t\t\tstart_mark: start_mark,\n\t\t\tend_mark:   yaml_mark_t{parser.mark.index + peek - 1, line, column},\n\t\t\thead:       text,\n\t\t})\n\t}\n\treturn true\n}\n"
        },
        {
          "name": "sorter.go",
          "type": "blob",
          "size": 3.2666015625,
          "content": "//\n// Copyright (c) 2011-2019 Canonical Ltd\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage yaml\n\nimport (\n\t\"reflect\"\n\t\"unicode\"\n)\n\ntype keyList []reflect.Value\n\nfunc (l keyList) Len() int      { return len(l) }\nfunc (l keyList) Swap(i, j int) { l[i], l[j] = l[j], l[i] }\nfunc (l keyList) Less(i, j int) bool {\n\ta := l[i]\n\tb := l[j]\n\tak := a.Kind()\n\tbk := b.Kind()\n\tfor (ak == reflect.Interface || ak == reflect.Ptr) && !a.IsNil() {\n\t\ta = a.Elem()\n\t\tak = a.Kind()\n\t}\n\tfor (bk == reflect.Interface || bk == reflect.Ptr) && !b.IsNil() {\n\t\tb = b.Elem()\n\t\tbk = b.Kind()\n\t}\n\taf, aok := keyFloat(a)\n\tbf, bok := keyFloat(b)\n\tif aok && bok {\n\t\tif af != bf {\n\t\t\treturn af < bf\n\t\t}\n\t\tif ak != bk {\n\t\t\treturn ak < bk\n\t\t}\n\t\treturn numLess(a, b)\n\t}\n\tif ak != reflect.String || bk != reflect.String {\n\t\treturn ak < bk\n\t}\n\tar, br := []rune(a.String()), []rune(b.String())\n\tdigits := false\n\tfor i := 0; i < len(ar) && i < len(br); i++ {\n\t\tif ar[i] == br[i] {\n\t\t\tdigits = unicode.IsDigit(ar[i])\n\t\t\tcontinue\n\t\t}\n\t\tal := unicode.IsLetter(ar[i])\n\t\tbl := unicode.IsLetter(br[i])\n\t\tif al && bl {\n\t\t\treturn ar[i] < br[i]\n\t\t}\n\t\tif al || bl {\n\t\t\tif digits {\n\t\t\t\treturn al\n\t\t\t} else {\n\t\t\t\treturn bl\n\t\t\t}\n\t\t}\n\t\tvar ai, bi int\n\t\tvar an, bn int64\n\t\tif ar[i] == '0' || br[i] == '0' {\n\t\t\tfor j := i - 1; j >= 0 && unicode.IsDigit(ar[j]); j-- {\n\t\t\t\tif ar[j] != '0' {\n\t\t\t\t\tan = 1\n\t\t\t\t\tbn = 1\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor ai = i; ai < len(ar) && unicode.IsDigit(ar[ai]); ai++ {\n\t\t\tan = an*10 + int64(ar[ai]-'0')\n\t\t}\n\t\tfor bi = i; bi < len(br) && unicode.IsDigit(br[bi]); bi++ {\n\t\t\tbn = bn*10 + int64(br[bi]-'0')\n\t\t}\n\t\tif an != bn {\n\t\t\treturn an < bn\n\t\t}\n\t\tif ai != bi {\n\t\t\treturn ai < bi\n\t\t}\n\t\treturn ar[i] < br[i]\n\t}\n\treturn len(ar) < len(br)\n}\n\n// keyFloat returns a float value for v if it is a number/bool\n// and whether it is a number/bool or not.\nfunc keyFloat(v reflect.Value) (f float64, ok bool) {\n\tswitch v.Kind() {\n\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\n\t\treturn float64(v.Int()), true\n\tcase reflect.Float32, reflect.Float64:\n\t\treturn v.Float(), true\n\tcase reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64, reflect.Uintptr:\n\t\treturn float64(v.Uint()), true\n\tcase reflect.Bool:\n\t\tif v.Bool() {\n\t\t\treturn 1, true\n\t\t}\n\t\treturn 0, true\n\t}\n\treturn 0, false\n}\n\n// numLess returns whether a < b.\n// a and b must necessarily have the same kind.\nfunc numLess(a, b reflect.Value) bool {\n\tswitch a.Kind() {\n\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\n\t\treturn a.Int() < b.Int()\n\tcase reflect.Float32, reflect.Float64:\n\t\treturn a.Float() < b.Float()\n\tcase reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64, reflect.Uintptr:\n\t\treturn a.Uint() < b.Uint()\n\tcase reflect.Bool:\n\t\treturn !a.Bool() && b.Bool()\n\t}\n\tpanic(\"not a number\")\n}\n"
        },
        {
          "name": "suite_test.go",
          "type": "blob",
          "size": 0.728515625,
          "content": "//\n// Copyright (c) 2011-2019 Canonical Ltd\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage yaml_test\n\nimport (\n\t. \"gopkg.in/check.v1\"\n\t\"testing\"\n)\n\nfunc Test(t *testing.T) { TestingT(t) }\n\ntype S struct{}\n\nvar _ = Suite(&S{})\n"
        },
        {
          "name": "writerc.go",
          "type": "blob",
          "size": 1.791015625,
          "content": "// \n// Copyright (c) 2011-2019 Canonical Ltd\n// Copyright (c) 2006-2010 Kirill Simonov\n// \n// Permission is hereby granted, free of charge, to any person obtaining a copy of\n// this software and associated documentation files (the \"Software\"), to deal in\n// the Software without restriction, including without limitation the rights to\n// use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\n// of the Software, and to permit persons to whom the Software is furnished to do\n// so, subject to the following conditions:\n// \n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n// \n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\npackage yaml\n\n// Set the writer error and return false.\nfunc yaml_emitter_set_writer_error(emitter *yaml_emitter_t, problem string) bool {\n\temitter.error = yaml_WRITER_ERROR\n\temitter.problem = problem\n\treturn false\n}\n\n// Flush the output buffer.\nfunc yaml_emitter_flush(emitter *yaml_emitter_t) bool {\n\tif emitter.write_handler == nil {\n\t\tpanic(\"write handler not set\")\n\t}\n\n\t// Check if the buffer is empty.\n\tif emitter.buffer_pos == 0 {\n\t\treturn true\n\t}\n\n\tif err := emitter.write_handler(emitter, emitter.buffer[:emitter.buffer_pos]); err != nil {\n\t\treturn yaml_emitter_set_writer_error(emitter, \"write error: \"+err.Error())\n\t}\n\temitter.buffer_pos = 0\n\treturn true\n}\n"
        },
        {
          "name": "yaml.go",
          "type": "blob",
          "size": 19.61328125,
          "content": "//\n// Copyright (c) 2011-2019 Canonical Ltd\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n// Package yaml implements YAML support for the Go language.\n//\n// Source code and other details for the project are available at GitHub:\n//\n//   https://github.com/go-yaml/yaml\n//\npackage yaml\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"reflect\"\n\t\"strings\"\n\t\"sync\"\n\t\"unicode/utf8\"\n)\n\n// The Unmarshaler interface may be implemented by types to customize their\n// behavior when being unmarshaled from a YAML document.\ntype Unmarshaler interface {\n\tUnmarshalYAML(value *Node) error\n}\n\ntype obsoleteUnmarshaler interface {\n\tUnmarshalYAML(unmarshal func(interface{}) error) error\n}\n\n// The Marshaler interface may be implemented by types to customize their\n// behavior when being marshaled into a YAML document. The returned value\n// is marshaled in place of the original value implementing Marshaler.\n//\n// If an error is returned by MarshalYAML, the marshaling procedure stops\n// and returns with the provided error.\ntype Marshaler interface {\n\tMarshalYAML() (interface{}, error)\n}\n\n// Unmarshal decodes the first document found within the in byte slice\n// and assigns decoded values into the out value.\n//\n// Maps and pointers (to a struct, string, int, etc) are accepted as out\n// values. If an internal pointer within a struct is not initialized,\n// the yaml package will initialize it if necessary for unmarshalling\n// the provided data. The out parameter must not be nil.\n//\n// The type of the decoded values should be compatible with the respective\n// values in out. If one or more values cannot be decoded due to a type\n// mismatches, decoding continues partially until the end of the YAML\n// content, and a *yaml.TypeError is returned with details for all\n// missed values.\n//\n// Struct fields are only unmarshalled if they are exported (have an\n// upper case first letter), and are unmarshalled using the field name\n// lowercased as the default key. Custom keys may be defined via the\n// \"yaml\" name in the field tag: the content preceding the first comma\n// is used as the key, and the following comma-separated options are\n// used to tweak the marshalling process (see Marshal).\n// Conflicting names result in a runtime error.\n//\n// For example:\n//\n//     type T struct {\n//         F int `yaml:\"a,omitempty\"`\n//         B int\n//     }\n//     var t T\n//     yaml.Unmarshal([]byte(\"a: 1\\nb: 2\"), &t)\n//\n// See the documentation of Marshal for the format of tags and a list of\n// supported tag options.\n//\nfunc Unmarshal(in []byte, out interface{}) (err error) {\n\treturn unmarshal(in, out, false)\n}\n\n// A Decoder reads and decodes YAML values from an input stream.\ntype Decoder struct {\n\tparser      *parser\n\tknownFields bool\n}\n\n// NewDecoder returns a new decoder that reads from r.\n//\n// The decoder introduces its own buffering and may read\n// data from r beyond the YAML values requested.\nfunc NewDecoder(r io.Reader) *Decoder {\n\treturn &Decoder{\n\t\tparser: newParserFromReader(r),\n\t}\n}\n\n// KnownFields ensures that the keys in decoded mappings to\n// exist as fields in the struct being decoded into.\nfunc (dec *Decoder) KnownFields(enable bool) {\n\tdec.knownFields = enable\n}\n\n// Decode reads the next YAML-encoded value from its input\n// and stores it in the value pointed to by v.\n//\n// See the documentation for Unmarshal for details about the\n// conversion of YAML into a Go value.\nfunc (dec *Decoder) Decode(v interface{}) (err error) {\n\td := newDecoder()\n\td.knownFields = dec.knownFields\n\tdefer handleErr(&err)\n\tnode := dec.parser.parse()\n\tif node == nil {\n\t\treturn io.EOF\n\t}\n\tout := reflect.ValueOf(v)\n\tif out.Kind() == reflect.Ptr && !out.IsNil() {\n\t\tout = out.Elem()\n\t}\n\td.unmarshal(node, out)\n\tif len(d.terrors) > 0 {\n\t\treturn &TypeError{d.terrors}\n\t}\n\treturn nil\n}\n\n// Decode decodes the node and stores its data into the value pointed to by v.\n//\n// See the documentation for Unmarshal for details about the\n// conversion of YAML into a Go value.\nfunc (n *Node) Decode(v interface{}) (err error) {\n\td := newDecoder()\n\tdefer handleErr(&err)\n\tout := reflect.ValueOf(v)\n\tif out.Kind() == reflect.Ptr && !out.IsNil() {\n\t\tout = out.Elem()\n\t}\n\td.unmarshal(n, out)\n\tif len(d.terrors) > 0 {\n\t\treturn &TypeError{d.terrors}\n\t}\n\treturn nil\n}\n\nfunc unmarshal(in []byte, out interface{}, strict bool) (err error) {\n\tdefer handleErr(&err)\n\td := newDecoder()\n\tp := newParser(in)\n\tdefer p.destroy()\n\tnode := p.parse()\n\tif node != nil {\n\t\tv := reflect.ValueOf(out)\n\t\tif v.Kind() == reflect.Ptr && !v.IsNil() {\n\t\t\tv = v.Elem()\n\t\t}\n\t\td.unmarshal(node, v)\n\t}\n\tif len(d.terrors) > 0 {\n\t\treturn &TypeError{d.terrors}\n\t}\n\treturn nil\n}\n\n// Marshal serializes the value provided into a YAML document. The structure\n// of the generated document will reflect the structure of the value itself.\n// Maps and pointers (to struct, string, int, etc) are accepted as the in value.\n//\n// Struct fields are only marshalled if they are exported (have an upper case\n// first letter), and are marshalled using the field name lowercased as the\n// default key. Custom keys may be defined via the \"yaml\" name in the field\n// tag: the content preceding the first comma is used as the key, and the\n// following comma-separated options are used to tweak the marshalling process.\n// Conflicting names result in a runtime error.\n//\n// The field tag format accepted is:\n//\n//     `(...) yaml:\"[<key>][,<flag1>[,<flag2>]]\" (...)`\n//\n// The following flags are currently supported:\n//\n//     omitempty    Only include the field if it's not set to the zero\n//                  value for the type or to empty slices or maps.\n//                  Zero valued structs will be omitted if all their public\n//                  fields are zero, unless they implement an IsZero\n//                  method (see the IsZeroer interface type), in which\n//                  case the field will be excluded if IsZero returns true.\n//\n//     flow         Marshal using a flow style (useful for structs,\n//                  sequences and maps).\n//\n//     inline       Inline the field, which must be a struct or a map,\n//                  causing all of its fields or keys to be processed as if\n//                  they were part of the outer struct. For maps, keys must\n//                  not conflict with the yaml keys of other struct fields.\n//\n// In addition, if the key is \"-\", the field is ignored.\n//\n// For example:\n//\n//     type T struct {\n//         F int `yaml:\"a,omitempty\"`\n//         B int\n//     }\n//     yaml.Marshal(&T{B: 2}) // Returns \"b: 2\\n\"\n//     yaml.Marshal(&T{F: 1}} // Returns \"a: 1\\nb: 0\\n\"\n//\nfunc Marshal(in interface{}) (out []byte, err error) {\n\tdefer handleErr(&err)\n\te := newEncoder()\n\tdefer e.destroy()\n\te.marshalDoc(\"\", reflect.ValueOf(in))\n\te.finish()\n\tout = e.out\n\treturn\n}\n\n// An Encoder writes YAML values to an output stream.\ntype Encoder struct {\n\tencoder *encoder\n}\n\n// NewEncoder returns a new encoder that writes to w.\n// The Encoder should be closed after use to flush all data\n// to w.\nfunc NewEncoder(w io.Writer) *Encoder {\n\treturn &Encoder{\n\t\tencoder: newEncoderWithWriter(w),\n\t}\n}\n\n// Encode writes the YAML encoding of v to the stream.\n// If multiple items are encoded to the stream, the\n// second and subsequent document will be preceded\n// with a \"---\" document separator, but the first will not.\n//\n// See the documentation for Marshal for details about the conversion of Go\n// values to YAML.\nfunc (e *Encoder) Encode(v interface{}) (err error) {\n\tdefer handleErr(&err)\n\te.encoder.marshalDoc(\"\", reflect.ValueOf(v))\n\treturn nil\n}\n\n// Encode encodes value v and stores its representation in n.\n//\n// See the documentation for Marshal for details about the\n// conversion of Go values into YAML.\nfunc (n *Node) Encode(v interface{}) (err error) {\n\tdefer handleErr(&err)\n\te := newEncoder()\n\tdefer e.destroy()\n\te.marshalDoc(\"\", reflect.ValueOf(v))\n\te.finish()\n\tp := newParser(e.out)\n\tp.textless = true\n\tdefer p.destroy()\n\tdoc := p.parse()\n\t*n = *doc.Content[0]\n\treturn nil\n}\n\n// SetIndent changes the used indentation used when encoding.\nfunc (e *Encoder) SetIndent(spaces int) {\n\tif spaces < 0 {\n\t\tpanic(\"yaml: cannot indent to a negative number of spaces\")\n\t}\n\te.encoder.indent = spaces\n}\n\n// Close closes the encoder by writing any remaining data.\n// It does not write a stream terminating string \"...\".\nfunc (e *Encoder) Close() (err error) {\n\tdefer handleErr(&err)\n\te.encoder.finish()\n\treturn nil\n}\n\nfunc handleErr(err *error) {\n\tif v := recover(); v != nil {\n\t\tif e, ok := v.(yamlError); ok {\n\t\t\t*err = e.err\n\t\t} else {\n\t\t\tpanic(v)\n\t\t}\n\t}\n}\n\ntype yamlError struct {\n\terr error\n}\n\nfunc fail(err error) {\n\tpanic(yamlError{err})\n}\n\nfunc failf(format string, args ...interface{}) {\n\tpanic(yamlError{fmt.Errorf(\"yaml: \"+format, args...)})\n}\n\n// A TypeError is returned by Unmarshal when one or more fields in\n// the YAML document cannot be properly decoded into the requested\n// types. When this error is returned, the value is still\n// unmarshaled partially.\ntype TypeError struct {\n\tErrors []string\n}\n\nfunc (e *TypeError) Error() string {\n\treturn fmt.Sprintf(\"yaml: unmarshal errors:\\n  %s\", strings.Join(e.Errors, \"\\n  \"))\n}\n\ntype Kind uint32\n\nconst (\n\tDocumentNode Kind = 1 << iota\n\tSequenceNode\n\tMappingNode\n\tScalarNode\n\tAliasNode\n)\n\ntype Style uint32\n\nconst (\n\tTaggedStyle Style = 1 << iota\n\tDoubleQuotedStyle\n\tSingleQuotedStyle\n\tLiteralStyle\n\tFoldedStyle\n\tFlowStyle\n)\n\n// Node represents an element in the YAML document hierarchy. While documents\n// are typically encoded and decoded into higher level types, such as structs\n// and maps, Node is an intermediate representation that allows detailed\n// control over the content being decoded or encoded.\n//\n// It's worth noting that although Node offers access into details such as\n// line numbers, colums, and comments, the content when re-encoded will not\n// have its original textual representation preserved. An effort is made to\n// render the data plesantly, and to preserve comments near the data they\n// describe, though.\n//\n// Values that make use of the Node type interact with the yaml package in the\n// same way any other type would do, by encoding and decoding yaml data\n// directly or indirectly into them.\n//\n// For example:\n//\n//     var person struct {\n//             Name    string\n//             Address yaml.Node\n//     }\n//     err := yaml.Unmarshal(data, &person)\n// \n// Or by itself:\n//\n//     var person Node\n//     err := yaml.Unmarshal(data, &person)\n//\ntype Node struct {\n\t// Kind defines whether the node is a document, a mapping, a sequence,\n\t// a scalar value, or an alias to another node. The specific data type of\n\t// scalar nodes may be obtained via the ShortTag and LongTag methods.\n\tKind  Kind\n\n\t// Style allows customizing the apperance of the node in the tree.\n\tStyle Style\n\n\t// Tag holds the YAML tag defining the data type for the value.\n\t// When decoding, this field will always be set to the resolved tag,\n\t// even when it wasn't explicitly provided in the YAML content.\n\t// When encoding, if this field is unset the value type will be\n\t// implied from the node properties, and if it is set, it will only\n\t// be serialized into the representation if TaggedStyle is used or\n\t// the implicit tag diverges from the provided one.\n\tTag string\n\n\t// Value holds the unescaped and unquoted represenation of the value.\n\tValue string\n\n\t// Anchor holds the anchor name for this node, which allows aliases to point to it.\n\tAnchor string\n\n\t// Alias holds the node that this alias points to. Only valid when Kind is AliasNode.\n\tAlias *Node\n\n\t// Content holds contained nodes for documents, mappings, and sequences.\n\tContent []*Node\n\n\t// HeadComment holds any comments in the lines preceding the node and\n\t// not separated by an empty line.\n\tHeadComment string\n\n\t// LineComment holds any comments at the end of the line where the node is in.\n\tLineComment string\n\n\t// FootComment holds any comments following the node and before empty lines.\n\tFootComment string\n\n\t// Line and Column hold the node position in the decoded YAML text.\n\t// These fields are not respected when encoding the node.\n\tLine   int\n\tColumn int\n}\n\n// IsZero returns whether the node has all of its fields unset.\nfunc (n *Node) IsZero() bool {\n\treturn n.Kind == 0 && n.Style == 0 && n.Tag == \"\" && n.Value == \"\" && n.Anchor == \"\" && n.Alias == nil && n.Content == nil &&\n\t\tn.HeadComment == \"\" && n.LineComment == \"\" && n.FootComment == \"\" && n.Line == 0 && n.Column == 0\n}\n\n\n// LongTag returns the long form of the tag that indicates the data type for\n// the node. If the Tag field isn't explicitly defined, one will be computed\n// based on the node properties.\nfunc (n *Node) LongTag() string {\n\treturn longTag(n.ShortTag())\n}\n\n// ShortTag returns the short form of the YAML tag that indicates data type for\n// the node. If the Tag field isn't explicitly defined, one will be computed\n// based on the node properties.\nfunc (n *Node) ShortTag() string {\n\tif n.indicatedString() {\n\t\treturn strTag\n\t}\n\tif n.Tag == \"\" || n.Tag == \"!\" {\n\t\tswitch n.Kind {\n\t\tcase MappingNode:\n\t\t\treturn mapTag\n\t\tcase SequenceNode:\n\t\t\treturn seqTag\n\t\tcase AliasNode:\n\t\t\tif n.Alias != nil {\n\t\t\t\treturn n.Alias.ShortTag()\n\t\t\t}\n\t\tcase ScalarNode:\n\t\t\ttag, _ := resolve(\"\", n.Value)\n\t\t\treturn tag\n\t\tcase 0:\n\t\t\t// Special case to make the zero value convenient.\n\t\t\tif n.IsZero() {\n\t\t\t\treturn nullTag\n\t\t\t}\n\t\t}\n\t\treturn \"\"\n\t}\n\treturn shortTag(n.Tag)\n}\n\nfunc (n *Node) indicatedString() bool {\n\treturn n.Kind == ScalarNode &&\n\t\t(shortTag(n.Tag) == strTag ||\n\t\t\t(n.Tag == \"\" || n.Tag == \"!\") && n.Style&(SingleQuotedStyle|DoubleQuotedStyle|LiteralStyle|FoldedStyle) != 0)\n}\n\n// SetString is a convenience function that sets the node to a string value\n// and defines its style in a pleasant way depending on its content.\nfunc (n *Node) SetString(s string) {\n\tn.Kind = ScalarNode\n\tif utf8.ValidString(s) {\n\t\tn.Value = s\n\t\tn.Tag = strTag\n\t} else {\n\t\tn.Value = encodeBase64(s)\n\t\tn.Tag = binaryTag\n\t}\n\tif strings.Contains(n.Value, \"\\n\") {\n\t\tn.Style = LiteralStyle\n\t}\n}\n\n// --------------------------------------------------------------------------\n// Maintain a mapping of keys to structure field indexes\n\n// The code in this section was copied from mgo/bson.\n\n// structInfo holds details for the serialization of fields of\n// a given struct.\ntype structInfo struct {\n\tFieldsMap  map[string]fieldInfo\n\tFieldsList []fieldInfo\n\n\t// InlineMap is the number of the field in the struct that\n\t// contains an ,inline map, or -1 if there's none.\n\tInlineMap int\n\n\t// InlineUnmarshalers holds indexes to inlined fields that\n\t// contain unmarshaler values.\n\tInlineUnmarshalers [][]int\n}\n\ntype fieldInfo struct {\n\tKey       string\n\tNum       int\n\tOmitEmpty bool\n\tFlow      bool\n\t// Id holds the unique field identifier, so we can cheaply\n\t// check for field duplicates without maintaining an extra map.\n\tId int\n\n\t// Inline holds the field index if the field is part of an inlined struct.\n\tInline []int\n}\n\nvar structMap = make(map[reflect.Type]*structInfo)\nvar fieldMapMutex sync.RWMutex\nvar unmarshalerType reflect.Type\n\nfunc init() {\n\tvar v Unmarshaler\n\tunmarshalerType = reflect.ValueOf(&v).Elem().Type()\n}\n\nfunc getStructInfo(st reflect.Type) (*structInfo, error) {\n\tfieldMapMutex.RLock()\n\tsinfo, found := structMap[st]\n\tfieldMapMutex.RUnlock()\n\tif found {\n\t\treturn sinfo, nil\n\t}\n\n\tn := st.NumField()\n\tfieldsMap := make(map[string]fieldInfo)\n\tfieldsList := make([]fieldInfo, 0, n)\n\tinlineMap := -1\n\tinlineUnmarshalers := [][]int(nil)\n\tfor i := 0; i != n; i++ {\n\t\tfield := st.Field(i)\n\t\tif field.PkgPath != \"\" && !field.Anonymous {\n\t\t\tcontinue // Private field\n\t\t}\n\n\t\tinfo := fieldInfo{Num: i}\n\n\t\ttag := field.Tag.Get(\"yaml\")\n\t\tif tag == \"\" && strings.Index(string(field.Tag), \":\") < 0 {\n\t\t\ttag = string(field.Tag)\n\t\t}\n\t\tif tag == \"-\" {\n\t\t\tcontinue\n\t\t}\n\n\t\tinline := false\n\t\tfields := strings.Split(tag, \",\")\n\t\tif len(fields) > 1 {\n\t\t\tfor _, flag := range fields[1:] {\n\t\t\t\tswitch flag {\n\t\t\t\tcase \"omitempty\":\n\t\t\t\t\tinfo.OmitEmpty = true\n\t\t\t\tcase \"flow\":\n\t\t\t\t\tinfo.Flow = true\n\t\t\t\tcase \"inline\":\n\t\t\t\t\tinline = true\n\t\t\t\tdefault:\n\t\t\t\t\treturn nil, errors.New(fmt.Sprintf(\"unsupported flag %q in tag %q of type %s\", flag, tag, st))\n\t\t\t\t}\n\t\t\t}\n\t\t\ttag = fields[0]\n\t\t}\n\n\t\tif inline {\n\t\t\tswitch field.Type.Kind() {\n\t\t\tcase reflect.Map:\n\t\t\t\tif inlineMap >= 0 {\n\t\t\t\t\treturn nil, errors.New(\"multiple ,inline maps in struct \" + st.String())\n\t\t\t\t}\n\t\t\t\tif field.Type.Key() != reflect.TypeOf(\"\") {\n\t\t\t\t\treturn nil, errors.New(\"option ,inline needs a map with string keys in struct \" + st.String())\n\t\t\t\t}\n\t\t\t\tinlineMap = info.Num\n\t\t\tcase reflect.Struct, reflect.Ptr:\n\t\t\t\tftype := field.Type\n\t\t\t\tfor ftype.Kind() == reflect.Ptr {\n\t\t\t\t\tftype = ftype.Elem()\n\t\t\t\t}\n\t\t\t\tif ftype.Kind() != reflect.Struct {\n\t\t\t\t\treturn nil, errors.New(\"option ,inline may only be used on a struct or map field\")\n\t\t\t\t}\n\t\t\t\tif reflect.PtrTo(ftype).Implements(unmarshalerType) {\n\t\t\t\t\tinlineUnmarshalers = append(inlineUnmarshalers, []int{i})\n\t\t\t\t} else {\n\t\t\t\t\tsinfo, err := getStructInfo(ftype)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, err\n\t\t\t\t\t}\n\t\t\t\t\tfor _, index := range sinfo.InlineUnmarshalers {\n\t\t\t\t\t\tinlineUnmarshalers = append(inlineUnmarshalers, append([]int{i}, index...))\n\t\t\t\t\t}\n\t\t\t\t\tfor _, finfo := range sinfo.FieldsList {\n\t\t\t\t\t\tif _, found := fieldsMap[finfo.Key]; found {\n\t\t\t\t\t\t\tmsg := \"duplicated key '\" + finfo.Key + \"' in struct \" + st.String()\n\t\t\t\t\t\t\treturn nil, errors.New(msg)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif finfo.Inline == nil {\n\t\t\t\t\t\t\tfinfo.Inline = []int{i, finfo.Num}\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tfinfo.Inline = append([]int{i}, finfo.Inline...)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfinfo.Id = len(fieldsList)\n\t\t\t\t\t\tfieldsMap[finfo.Key] = finfo\n\t\t\t\t\t\tfieldsList = append(fieldsList, finfo)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\treturn nil, errors.New(\"option ,inline may only be used on a struct or map field\")\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\tif tag != \"\" {\n\t\t\tinfo.Key = tag\n\t\t} else {\n\t\t\tinfo.Key = strings.ToLower(field.Name)\n\t\t}\n\n\t\tif _, found = fieldsMap[info.Key]; found {\n\t\t\tmsg := \"duplicated key '\" + info.Key + \"' in struct \" + st.String()\n\t\t\treturn nil, errors.New(msg)\n\t\t}\n\n\t\tinfo.Id = len(fieldsList)\n\t\tfieldsList = append(fieldsList, info)\n\t\tfieldsMap[info.Key] = info\n\t}\n\n\tsinfo = &structInfo{\n\t\tFieldsMap:          fieldsMap,\n\t\tFieldsList:         fieldsList,\n\t\tInlineMap:          inlineMap,\n\t\tInlineUnmarshalers: inlineUnmarshalers,\n\t}\n\n\tfieldMapMutex.Lock()\n\tstructMap[st] = sinfo\n\tfieldMapMutex.Unlock()\n\treturn sinfo, nil\n}\n\n// IsZeroer is used to check whether an object is zero to\n// determine whether it should be omitted when marshaling\n// with the omitempty flag. One notable implementation\n// is time.Time.\ntype IsZeroer interface {\n\tIsZero() bool\n}\n\nfunc isZero(v reflect.Value) bool {\n\tkind := v.Kind()\n\tif z, ok := v.Interface().(IsZeroer); ok {\n\t\tif (kind == reflect.Ptr || kind == reflect.Interface) && v.IsNil() {\n\t\t\treturn true\n\t\t}\n\t\treturn z.IsZero()\n\t}\n\tswitch kind {\n\tcase reflect.String:\n\t\treturn len(v.String()) == 0\n\tcase reflect.Interface, reflect.Ptr:\n\t\treturn v.IsNil()\n\tcase reflect.Slice:\n\t\treturn v.Len() == 0\n\tcase reflect.Map:\n\t\treturn v.Len() == 0\n\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\n\t\treturn v.Int() == 0\n\tcase reflect.Float32, reflect.Float64:\n\t\treturn v.Float() == 0\n\tcase reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64, reflect.Uintptr:\n\t\treturn v.Uint() == 0\n\tcase reflect.Bool:\n\t\treturn !v.Bool()\n\tcase reflect.Struct:\n\t\tvt := v.Type()\n\t\tfor i := v.NumField() - 1; i >= 0; i-- {\n\t\t\tif vt.Field(i).PkgPath != \"\" {\n\t\t\t\tcontinue // Private field\n\t\t\t}\n\t\t\tif !isZero(v.Field(i)) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\treturn true\n\t}\n\treturn false\n}\n"
        },
        {
          "name": "yamlh.go",
          "type": "blob",
          "size": 28.365234375,
          "content": "//\n// Copyright (c) 2011-2019 Canonical Ltd\n// Copyright (c) 2006-2010 Kirill Simonov\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy of\n// this software and associated documentation files (the \"Software\"), to deal in\n// the Software without restriction, including without limitation the rights to\n// use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\n// of the Software, and to permit persons to whom the Software is furnished to do\n// so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\npackage yaml\n\nimport (\n\t\"fmt\"\n\t\"io\"\n)\n\n// The version directive data.\ntype yaml_version_directive_t struct {\n\tmajor int8 // The major version number.\n\tminor int8 // The minor version number.\n}\n\n// The tag directive data.\ntype yaml_tag_directive_t struct {\n\thandle []byte // The tag handle.\n\tprefix []byte // The tag prefix.\n}\n\ntype yaml_encoding_t int\n\n// The stream encoding.\nconst (\n\t// Let the parser choose the encoding.\n\tyaml_ANY_ENCODING yaml_encoding_t = iota\n\n\tyaml_UTF8_ENCODING    // The default UTF-8 encoding.\n\tyaml_UTF16LE_ENCODING // The UTF-16-LE encoding with BOM.\n\tyaml_UTF16BE_ENCODING // The UTF-16-BE encoding with BOM.\n)\n\ntype yaml_break_t int\n\n// Line break types.\nconst (\n\t// Let the parser choose the break type.\n\tyaml_ANY_BREAK yaml_break_t = iota\n\n\tyaml_CR_BREAK   // Use CR for line breaks (Mac style).\n\tyaml_LN_BREAK   // Use LN for line breaks (Unix style).\n\tyaml_CRLN_BREAK // Use CR LN for line breaks (DOS style).\n)\n\ntype yaml_error_type_t int\n\n// Many bad things could happen with the parser and emitter.\nconst (\n\t// No error is produced.\n\tyaml_NO_ERROR yaml_error_type_t = iota\n\n\tyaml_MEMORY_ERROR   // Cannot allocate or reallocate a block of memory.\n\tyaml_READER_ERROR   // Cannot read or decode the input stream.\n\tyaml_SCANNER_ERROR  // Cannot scan the input stream.\n\tyaml_PARSER_ERROR   // Cannot parse the input stream.\n\tyaml_COMPOSER_ERROR // Cannot compose a YAML document.\n\tyaml_WRITER_ERROR   // Cannot write to the output stream.\n\tyaml_EMITTER_ERROR  // Cannot emit a YAML stream.\n)\n\n// The pointer position.\ntype yaml_mark_t struct {\n\tindex  int // The position index.\n\tline   int // The position line.\n\tcolumn int // The position column.\n}\n\n// Node Styles\n\ntype yaml_style_t int8\n\ntype yaml_scalar_style_t yaml_style_t\n\n// Scalar styles.\nconst (\n\t// Let the emitter choose the style.\n\tyaml_ANY_SCALAR_STYLE yaml_scalar_style_t = 0\n\n\tyaml_PLAIN_SCALAR_STYLE         yaml_scalar_style_t = 1 << iota // The plain scalar style.\n\tyaml_SINGLE_QUOTED_SCALAR_STYLE                                 // The single-quoted scalar style.\n\tyaml_DOUBLE_QUOTED_SCALAR_STYLE                                 // The double-quoted scalar style.\n\tyaml_LITERAL_SCALAR_STYLE                                       // The literal scalar style.\n\tyaml_FOLDED_SCALAR_STYLE                                        // The folded scalar style.\n)\n\ntype yaml_sequence_style_t yaml_style_t\n\n// Sequence styles.\nconst (\n\t// Let the emitter choose the style.\n\tyaml_ANY_SEQUENCE_STYLE yaml_sequence_style_t = iota\n\n\tyaml_BLOCK_SEQUENCE_STYLE // The block sequence style.\n\tyaml_FLOW_SEQUENCE_STYLE  // The flow sequence style.\n)\n\ntype yaml_mapping_style_t yaml_style_t\n\n// Mapping styles.\nconst (\n\t// Let the emitter choose the style.\n\tyaml_ANY_MAPPING_STYLE yaml_mapping_style_t = iota\n\n\tyaml_BLOCK_MAPPING_STYLE // The block mapping style.\n\tyaml_FLOW_MAPPING_STYLE  // The flow mapping style.\n)\n\n// Tokens\n\ntype yaml_token_type_t int\n\n// Token types.\nconst (\n\t// An empty token.\n\tyaml_NO_TOKEN yaml_token_type_t = iota\n\n\tyaml_STREAM_START_TOKEN // A STREAM-START token.\n\tyaml_STREAM_END_TOKEN   // A STREAM-END token.\n\n\tyaml_VERSION_DIRECTIVE_TOKEN // A VERSION-DIRECTIVE token.\n\tyaml_TAG_DIRECTIVE_TOKEN     // A TAG-DIRECTIVE token.\n\tyaml_DOCUMENT_START_TOKEN    // A DOCUMENT-START token.\n\tyaml_DOCUMENT_END_TOKEN      // A DOCUMENT-END token.\n\n\tyaml_BLOCK_SEQUENCE_START_TOKEN // A BLOCK-SEQUENCE-START token.\n\tyaml_BLOCK_MAPPING_START_TOKEN  // A BLOCK-SEQUENCE-END token.\n\tyaml_BLOCK_END_TOKEN            // A BLOCK-END token.\n\n\tyaml_FLOW_SEQUENCE_START_TOKEN // A FLOW-SEQUENCE-START token.\n\tyaml_FLOW_SEQUENCE_END_TOKEN   // A FLOW-SEQUENCE-END token.\n\tyaml_FLOW_MAPPING_START_TOKEN  // A FLOW-MAPPING-START token.\n\tyaml_FLOW_MAPPING_END_TOKEN    // A FLOW-MAPPING-END token.\n\n\tyaml_BLOCK_ENTRY_TOKEN // A BLOCK-ENTRY token.\n\tyaml_FLOW_ENTRY_TOKEN  // A FLOW-ENTRY token.\n\tyaml_KEY_TOKEN         // A KEY token.\n\tyaml_VALUE_TOKEN       // A VALUE token.\n\n\tyaml_ALIAS_TOKEN  // An ALIAS token.\n\tyaml_ANCHOR_TOKEN // An ANCHOR token.\n\tyaml_TAG_TOKEN    // A TAG token.\n\tyaml_SCALAR_TOKEN // A SCALAR token.\n)\n\nfunc (tt yaml_token_type_t) String() string {\n\tswitch tt {\n\tcase yaml_NO_TOKEN:\n\t\treturn \"yaml_NO_TOKEN\"\n\tcase yaml_STREAM_START_TOKEN:\n\t\treturn \"yaml_STREAM_START_TOKEN\"\n\tcase yaml_STREAM_END_TOKEN:\n\t\treturn \"yaml_STREAM_END_TOKEN\"\n\tcase yaml_VERSION_DIRECTIVE_TOKEN:\n\t\treturn \"yaml_VERSION_DIRECTIVE_TOKEN\"\n\tcase yaml_TAG_DIRECTIVE_TOKEN:\n\t\treturn \"yaml_TAG_DIRECTIVE_TOKEN\"\n\tcase yaml_DOCUMENT_START_TOKEN:\n\t\treturn \"yaml_DOCUMENT_START_TOKEN\"\n\tcase yaml_DOCUMENT_END_TOKEN:\n\t\treturn \"yaml_DOCUMENT_END_TOKEN\"\n\tcase yaml_BLOCK_SEQUENCE_START_TOKEN:\n\t\treturn \"yaml_BLOCK_SEQUENCE_START_TOKEN\"\n\tcase yaml_BLOCK_MAPPING_START_TOKEN:\n\t\treturn \"yaml_BLOCK_MAPPING_START_TOKEN\"\n\tcase yaml_BLOCK_END_TOKEN:\n\t\treturn \"yaml_BLOCK_END_TOKEN\"\n\tcase yaml_FLOW_SEQUENCE_START_TOKEN:\n\t\treturn \"yaml_FLOW_SEQUENCE_START_TOKEN\"\n\tcase yaml_FLOW_SEQUENCE_END_TOKEN:\n\t\treturn \"yaml_FLOW_SEQUENCE_END_TOKEN\"\n\tcase yaml_FLOW_MAPPING_START_TOKEN:\n\t\treturn \"yaml_FLOW_MAPPING_START_TOKEN\"\n\tcase yaml_FLOW_MAPPING_END_TOKEN:\n\t\treturn \"yaml_FLOW_MAPPING_END_TOKEN\"\n\tcase yaml_BLOCK_ENTRY_TOKEN:\n\t\treturn \"yaml_BLOCK_ENTRY_TOKEN\"\n\tcase yaml_FLOW_ENTRY_TOKEN:\n\t\treturn \"yaml_FLOW_ENTRY_TOKEN\"\n\tcase yaml_KEY_TOKEN:\n\t\treturn \"yaml_KEY_TOKEN\"\n\tcase yaml_VALUE_TOKEN:\n\t\treturn \"yaml_VALUE_TOKEN\"\n\tcase yaml_ALIAS_TOKEN:\n\t\treturn \"yaml_ALIAS_TOKEN\"\n\tcase yaml_ANCHOR_TOKEN:\n\t\treturn \"yaml_ANCHOR_TOKEN\"\n\tcase yaml_TAG_TOKEN:\n\t\treturn \"yaml_TAG_TOKEN\"\n\tcase yaml_SCALAR_TOKEN:\n\t\treturn \"yaml_SCALAR_TOKEN\"\n\t}\n\treturn \"<unknown token>\"\n}\n\n// The token structure.\ntype yaml_token_t struct {\n\t// The token type.\n\ttyp yaml_token_type_t\n\n\t// The start/end of the token.\n\tstart_mark, end_mark yaml_mark_t\n\n\t// The stream encoding (for yaml_STREAM_START_TOKEN).\n\tencoding yaml_encoding_t\n\n\t// The alias/anchor/scalar value or tag/tag directive handle\n\t// (for yaml_ALIAS_TOKEN, yaml_ANCHOR_TOKEN, yaml_SCALAR_TOKEN, yaml_TAG_TOKEN, yaml_TAG_DIRECTIVE_TOKEN).\n\tvalue []byte\n\n\t// The tag suffix (for yaml_TAG_TOKEN).\n\tsuffix []byte\n\n\t// The tag directive prefix (for yaml_TAG_DIRECTIVE_TOKEN).\n\tprefix []byte\n\n\t// The scalar style (for yaml_SCALAR_TOKEN).\n\tstyle yaml_scalar_style_t\n\n\t// The version directive major/minor (for yaml_VERSION_DIRECTIVE_TOKEN).\n\tmajor, minor int8\n}\n\n// Events\n\ntype yaml_event_type_t int8\n\n// Event types.\nconst (\n\t// An empty event.\n\tyaml_NO_EVENT yaml_event_type_t = iota\n\n\tyaml_STREAM_START_EVENT   // A STREAM-START event.\n\tyaml_STREAM_END_EVENT     // A STREAM-END event.\n\tyaml_DOCUMENT_START_EVENT // A DOCUMENT-START event.\n\tyaml_DOCUMENT_END_EVENT   // A DOCUMENT-END event.\n\tyaml_ALIAS_EVENT          // An ALIAS event.\n\tyaml_SCALAR_EVENT         // A SCALAR event.\n\tyaml_SEQUENCE_START_EVENT // A SEQUENCE-START event.\n\tyaml_SEQUENCE_END_EVENT   // A SEQUENCE-END event.\n\tyaml_MAPPING_START_EVENT  // A MAPPING-START event.\n\tyaml_MAPPING_END_EVENT    // A MAPPING-END event.\n\tyaml_TAIL_COMMENT_EVENT\n)\n\nvar eventStrings = []string{\n\tyaml_NO_EVENT:             \"none\",\n\tyaml_STREAM_START_EVENT:   \"stream start\",\n\tyaml_STREAM_END_EVENT:     \"stream end\",\n\tyaml_DOCUMENT_START_EVENT: \"document start\",\n\tyaml_DOCUMENT_END_EVENT:   \"document end\",\n\tyaml_ALIAS_EVENT:          \"alias\",\n\tyaml_SCALAR_EVENT:         \"scalar\",\n\tyaml_SEQUENCE_START_EVENT: \"sequence start\",\n\tyaml_SEQUENCE_END_EVENT:   \"sequence end\",\n\tyaml_MAPPING_START_EVENT:  \"mapping start\",\n\tyaml_MAPPING_END_EVENT:    \"mapping end\",\n\tyaml_TAIL_COMMENT_EVENT:   \"tail comment\",\n}\n\nfunc (e yaml_event_type_t) String() string {\n\tif e < 0 || int(e) >= len(eventStrings) {\n\t\treturn fmt.Sprintf(\"unknown event %d\", e)\n\t}\n\treturn eventStrings[e]\n}\n\n// The event structure.\ntype yaml_event_t struct {\n\n\t// The event type.\n\ttyp yaml_event_type_t\n\n\t// The start and end of the event.\n\tstart_mark, end_mark yaml_mark_t\n\n\t// The document encoding (for yaml_STREAM_START_EVENT).\n\tencoding yaml_encoding_t\n\n\t// The version directive (for yaml_DOCUMENT_START_EVENT).\n\tversion_directive *yaml_version_directive_t\n\n\t// The list of tag directives (for yaml_DOCUMENT_START_EVENT).\n\ttag_directives []yaml_tag_directive_t\n\n\t// The comments\n\thead_comment []byte\n\tline_comment []byte\n\tfoot_comment []byte\n\ttail_comment []byte\n\n\t// The anchor (for yaml_SCALAR_EVENT, yaml_SEQUENCE_START_EVENT, yaml_MAPPING_START_EVENT, yaml_ALIAS_EVENT).\n\tanchor []byte\n\n\t// The tag (for yaml_SCALAR_EVENT, yaml_SEQUENCE_START_EVENT, yaml_MAPPING_START_EVENT).\n\ttag []byte\n\n\t// The scalar value (for yaml_SCALAR_EVENT).\n\tvalue []byte\n\n\t// Is the document start/end indicator implicit, or the tag optional?\n\t// (for yaml_DOCUMENT_START_EVENT, yaml_DOCUMENT_END_EVENT, yaml_SEQUENCE_START_EVENT, yaml_MAPPING_START_EVENT, yaml_SCALAR_EVENT).\n\timplicit bool\n\n\t// Is the tag optional for any non-plain style? (for yaml_SCALAR_EVENT).\n\tquoted_implicit bool\n\n\t// The style (for yaml_SCALAR_EVENT, yaml_SEQUENCE_START_EVENT, yaml_MAPPING_START_EVENT).\n\tstyle yaml_style_t\n}\n\nfunc (e *yaml_event_t) scalar_style() yaml_scalar_style_t     { return yaml_scalar_style_t(e.style) }\nfunc (e *yaml_event_t) sequence_style() yaml_sequence_style_t { return yaml_sequence_style_t(e.style) }\nfunc (e *yaml_event_t) mapping_style() yaml_mapping_style_t   { return yaml_mapping_style_t(e.style) }\n\n// Nodes\n\nconst (\n\tyaml_NULL_TAG      = \"tag:yaml.org,2002:null\"      // The tag !!null with the only possible value: null.\n\tyaml_BOOL_TAG      = \"tag:yaml.org,2002:bool\"      // The tag !!bool with the values: true and false.\n\tyaml_STR_TAG       = \"tag:yaml.org,2002:str\"       // The tag !!str for string values.\n\tyaml_INT_TAG       = \"tag:yaml.org,2002:int\"       // The tag !!int for integer values.\n\tyaml_FLOAT_TAG     = \"tag:yaml.org,2002:float\"     // The tag !!float for float values.\n\tyaml_TIMESTAMP_TAG = \"tag:yaml.org,2002:timestamp\" // The tag !!timestamp for date and time values.\n\n\tyaml_SEQ_TAG = \"tag:yaml.org,2002:seq\" // The tag !!seq is used to denote sequences.\n\tyaml_MAP_TAG = \"tag:yaml.org,2002:map\" // The tag !!map is used to denote mapping.\n\n\t// Not in original libyaml.\n\tyaml_BINARY_TAG = \"tag:yaml.org,2002:binary\"\n\tyaml_MERGE_TAG  = \"tag:yaml.org,2002:merge\"\n\n\tyaml_DEFAULT_SCALAR_TAG   = yaml_STR_TAG // The default scalar tag is !!str.\n\tyaml_DEFAULT_SEQUENCE_TAG = yaml_SEQ_TAG // The default sequence tag is !!seq.\n\tyaml_DEFAULT_MAPPING_TAG  = yaml_MAP_TAG // The default mapping tag is !!map.\n)\n\ntype yaml_node_type_t int\n\n// Node types.\nconst (\n\t// An empty node.\n\tyaml_NO_NODE yaml_node_type_t = iota\n\n\tyaml_SCALAR_NODE   // A scalar node.\n\tyaml_SEQUENCE_NODE // A sequence node.\n\tyaml_MAPPING_NODE  // A mapping node.\n)\n\n// An element of a sequence node.\ntype yaml_node_item_t int\n\n// An element of a mapping node.\ntype yaml_node_pair_t struct {\n\tkey   int // The key of the element.\n\tvalue int // The value of the element.\n}\n\n// The node structure.\ntype yaml_node_t struct {\n\ttyp yaml_node_type_t // The node type.\n\ttag []byte           // The node tag.\n\n\t// The node data.\n\n\t// The scalar parameters (for yaml_SCALAR_NODE).\n\tscalar struct {\n\t\tvalue  []byte              // The scalar value.\n\t\tlength int                 // The length of the scalar value.\n\t\tstyle  yaml_scalar_style_t // The scalar style.\n\t}\n\n\t// The sequence parameters (for YAML_SEQUENCE_NODE).\n\tsequence struct {\n\t\titems_data []yaml_node_item_t    // The stack of sequence items.\n\t\tstyle      yaml_sequence_style_t // The sequence style.\n\t}\n\n\t// The mapping parameters (for yaml_MAPPING_NODE).\n\tmapping struct {\n\t\tpairs_data  []yaml_node_pair_t   // The stack of mapping pairs (key, value).\n\t\tpairs_start *yaml_node_pair_t    // The beginning of the stack.\n\t\tpairs_end   *yaml_node_pair_t    // The end of the stack.\n\t\tpairs_top   *yaml_node_pair_t    // The top of the stack.\n\t\tstyle       yaml_mapping_style_t // The mapping style.\n\t}\n\n\tstart_mark yaml_mark_t // The beginning of the node.\n\tend_mark   yaml_mark_t // The end of the node.\n\n}\n\n// The document structure.\ntype yaml_document_t struct {\n\n\t// The document nodes.\n\tnodes []yaml_node_t\n\n\t// The version directive.\n\tversion_directive *yaml_version_directive_t\n\n\t// The list of tag directives.\n\ttag_directives_data  []yaml_tag_directive_t\n\ttag_directives_start int // The beginning of the tag directives list.\n\ttag_directives_end   int // The end of the tag directives list.\n\n\tstart_implicit int // Is the document start indicator implicit?\n\tend_implicit   int // Is the document end indicator implicit?\n\n\t// The start/end of the document.\n\tstart_mark, end_mark yaml_mark_t\n}\n\n// The prototype of a read handler.\n//\n// The read handler is called when the parser needs to read more bytes from the\n// source. The handler should write not more than size bytes to the buffer.\n// The number of written bytes should be set to the size_read variable.\n//\n// [in,out]   data        A pointer to an application data specified by\n//                        yaml_parser_set_input().\n// [out]      buffer      The buffer to write the data from the source.\n// [in]       size        The size of the buffer.\n// [out]      size_read   The actual number of bytes read from the source.\n//\n// On success, the handler should return 1.  If the handler failed,\n// the returned value should be 0. On EOF, the handler should set the\n// size_read to 0 and return 1.\ntype yaml_read_handler_t func(parser *yaml_parser_t, buffer []byte) (n int, err error)\n\n// This structure holds information about a potential simple key.\ntype yaml_simple_key_t struct {\n\tpossible     bool        // Is a simple key possible?\n\trequired     bool        // Is a simple key required?\n\ttoken_number int         // The number of the token.\n\tmark         yaml_mark_t // The position mark.\n}\n\n// The states of the parser.\ntype yaml_parser_state_t int\n\nconst (\n\tyaml_PARSE_STREAM_START_STATE yaml_parser_state_t = iota\n\n\tyaml_PARSE_IMPLICIT_DOCUMENT_START_STATE           // Expect the beginning of an implicit document.\n\tyaml_PARSE_DOCUMENT_START_STATE                    // Expect DOCUMENT-START.\n\tyaml_PARSE_DOCUMENT_CONTENT_STATE                  // Expect the content of a document.\n\tyaml_PARSE_DOCUMENT_END_STATE                      // Expect DOCUMENT-END.\n\tyaml_PARSE_BLOCK_NODE_STATE                        // Expect a block node.\n\tyaml_PARSE_BLOCK_NODE_OR_INDENTLESS_SEQUENCE_STATE // Expect a block node or indentless sequence.\n\tyaml_PARSE_FLOW_NODE_STATE                         // Expect a flow node.\n\tyaml_PARSE_BLOCK_SEQUENCE_FIRST_ENTRY_STATE        // Expect the first entry of a block sequence.\n\tyaml_PARSE_BLOCK_SEQUENCE_ENTRY_STATE              // Expect an entry of a block sequence.\n\tyaml_PARSE_INDENTLESS_SEQUENCE_ENTRY_STATE         // Expect an entry of an indentless sequence.\n\tyaml_PARSE_BLOCK_MAPPING_FIRST_KEY_STATE           // Expect the first key of a block mapping.\n\tyaml_PARSE_BLOCK_MAPPING_KEY_STATE                 // Expect a block mapping key.\n\tyaml_PARSE_BLOCK_MAPPING_VALUE_STATE               // Expect a block mapping value.\n\tyaml_PARSE_FLOW_SEQUENCE_FIRST_ENTRY_STATE         // Expect the first entry of a flow sequence.\n\tyaml_PARSE_FLOW_SEQUENCE_ENTRY_STATE               // Expect an entry of a flow sequence.\n\tyaml_PARSE_FLOW_SEQUENCE_ENTRY_MAPPING_KEY_STATE   // Expect a key of an ordered mapping.\n\tyaml_PARSE_FLOW_SEQUENCE_ENTRY_MAPPING_VALUE_STATE // Expect a value of an ordered mapping.\n\tyaml_PARSE_FLOW_SEQUENCE_ENTRY_MAPPING_END_STATE   // Expect the and of an ordered mapping entry.\n\tyaml_PARSE_FLOW_MAPPING_FIRST_KEY_STATE            // Expect the first key of a flow mapping.\n\tyaml_PARSE_FLOW_MAPPING_KEY_STATE                  // Expect a key of a flow mapping.\n\tyaml_PARSE_FLOW_MAPPING_VALUE_STATE                // Expect a value of a flow mapping.\n\tyaml_PARSE_FLOW_MAPPING_EMPTY_VALUE_STATE          // Expect an empty value of a flow mapping.\n\tyaml_PARSE_END_STATE                               // Expect nothing.\n)\n\nfunc (ps yaml_parser_state_t) String() string {\n\tswitch ps {\n\tcase yaml_PARSE_STREAM_START_STATE:\n\t\treturn \"yaml_PARSE_STREAM_START_STATE\"\n\tcase yaml_PARSE_IMPLICIT_DOCUMENT_START_STATE:\n\t\treturn \"yaml_PARSE_IMPLICIT_DOCUMENT_START_STATE\"\n\tcase yaml_PARSE_DOCUMENT_START_STATE:\n\t\treturn \"yaml_PARSE_DOCUMENT_START_STATE\"\n\tcase yaml_PARSE_DOCUMENT_CONTENT_STATE:\n\t\treturn \"yaml_PARSE_DOCUMENT_CONTENT_STATE\"\n\tcase yaml_PARSE_DOCUMENT_END_STATE:\n\t\treturn \"yaml_PARSE_DOCUMENT_END_STATE\"\n\tcase yaml_PARSE_BLOCK_NODE_STATE:\n\t\treturn \"yaml_PARSE_BLOCK_NODE_STATE\"\n\tcase yaml_PARSE_BLOCK_NODE_OR_INDENTLESS_SEQUENCE_STATE:\n\t\treturn \"yaml_PARSE_BLOCK_NODE_OR_INDENTLESS_SEQUENCE_STATE\"\n\tcase yaml_PARSE_FLOW_NODE_STATE:\n\t\treturn \"yaml_PARSE_FLOW_NODE_STATE\"\n\tcase yaml_PARSE_BLOCK_SEQUENCE_FIRST_ENTRY_STATE:\n\t\treturn \"yaml_PARSE_BLOCK_SEQUENCE_FIRST_ENTRY_STATE\"\n\tcase yaml_PARSE_BLOCK_SEQUENCE_ENTRY_STATE:\n\t\treturn \"yaml_PARSE_BLOCK_SEQUENCE_ENTRY_STATE\"\n\tcase yaml_PARSE_INDENTLESS_SEQUENCE_ENTRY_STATE:\n\t\treturn \"yaml_PARSE_INDENTLESS_SEQUENCE_ENTRY_STATE\"\n\tcase yaml_PARSE_BLOCK_MAPPING_FIRST_KEY_STATE:\n\t\treturn \"yaml_PARSE_BLOCK_MAPPING_FIRST_KEY_STATE\"\n\tcase yaml_PARSE_BLOCK_MAPPING_KEY_STATE:\n\t\treturn \"yaml_PARSE_BLOCK_MAPPING_KEY_STATE\"\n\tcase yaml_PARSE_BLOCK_MAPPING_VALUE_STATE:\n\t\treturn \"yaml_PARSE_BLOCK_MAPPING_VALUE_STATE\"\n\tcase yaml_PARSE_FLOW_SEQUENCE_FIRST_ENTRY_STATE:\n\t\treturn \"yaml_PARSE_FLOW_SEQUENCE_FIRST_ENTRY_STATE\"\n\tcase yaml_PARSE_FLOW_SEQUENCE_ENTRY_STATE:\n\t\treturn \"yaml_PARSE_FLOW_SEQUENCE_ENTRY_STATE\"\n\tcase yaml_PARSE_FLOW_SEQUENCE_ENTRY_MAPPING_KEY_STATE:\n\t\treturn \"yaml_PARSE_FLOW_SEQUENCE_ENTRY_MAPPING_KEY_STATE\"\n\tcase yaml_PARSE_FLOW_SEQUENCE_ENTRY_MAPPING_VALUE_STATE:\n\t\treturn \"yaml_PARSE_FLOW_SEQUENCE_ENTRY_MAPPING_VALUE_STATE\"\n\tcase yaml_PARSE_FLOW_SEQUENCE_ENTRY_MAPPING_END_STATE:\n\t\treturn \"yaml_PARSE_FLOW_SEQUENCE_ENTRY_MAPPING_END_STATE\"\n\tcase yaml_PARSE_FLOW_MAPPING_FIRST_KEY_STATE:\n\t\treturn \"yaml_PARSE_FLOW_MAPPING_FIRST_KEY_STATE\"\n\tcase yaml_PARSE_FLOW_MAPPING_KEY_STATE:\n\t\treturn \"yaml_PARSE_FLOW_MAPPING_KEY_STATE\"\n\tcase yaml_PARSE_FLOW_MAPPING_VALUE_STATE:\n\t\treturn \"yaml_PARSE_FLOW_MAPPING_VALUE_STATE\"\n\tcase yaml_PARSE_FLOW_MAPPING_EMPTY_VALUE_STATE:\n\t\treturn \"yaml_PARSE_FLOW_MAPPING_EMPTY_VALUE_STATE\"\n\tcase yaml_PARSE_END_STATE:\n\t\treturn \"yaml_PARSE_END_STATE\"\n\t}\n\treturn \"<unknown parser state>\"\n}\n\n// This structure holds aliases data.\ntype yaml_alias_data_t struct {\n\tanchor []byte      // The anchor.\n\tindex  int         // The node id.\n\tmark   yaml_mark_t // The anchor mark.\n}\n\n// The parser structure.\n//\n// All members are internal. Manage the structure using the\n// yaml_parser_ family of functions.\ntype yaml_parser_t struct {\n\n\t// Error handling\n\n\terror yaml_error_type_t // Error type.\n\n\tproblem string // Error description.\n\n\t// The byte about which the problem occurred.\n\tproblem_offset int\n\tproblem_value  int\n\tproblem_mark   yaml_mark_t\n\n\t// The error context.\n\tcontext      string\n\tcontext_mark yaml_mark_t\n\n\t// Reader stuff\n\n\tread_handler yaml_read_handler_t // Read handler.\n\n\tinput_reader io.Reader // File input data.\n\tinput        []byte    // String input data.\n\tinput_pos    int\n\n\teof bool // EOF flag\n\n\tbuffer     []byte // The working buffer.\n\tbuffer_pos int    // The current position of the buffer.\n\n\tunread int // The number of unread characters in the buffer.\n\n\tnewlines int // The number of line breaks since last non-break/non-blank character\n\n\traw_buffer     []byte // The raw buffer.\n\traw_buffer_pos int    // The current position of the buffer.\n\n\tencoding yaml_encoding_t // The input encoding.\n\n\toffset int         // The offset of the current position (in bytes).\n\tmark   yaml_mark_t // The mark of the current position.\n\n\t// Comments\n\n\thead_comment []byte // The current head comments\n\tline_comment []byte // The current line comments\n\tfoot_comment []byte // The current foot comments\n\ttail_comment []byte // Foot comment that happens at the end of a block.\n\tstem_comment []byte // Comment in item preceding a nested structure (list inside list item, etc)\n\n\tcomments      []yaml_comment_t // The folded comments for all parsed tokens\n\tcomments_head int\n\n\t// Scanner stuff\n\n\tstream_start_produced bool // Have we started to scan the input stream?\n\tstream_end_produced   bool // Have we reached the end of the input stream?\n\n\tflow_level int // The number of unclosed '[' and '{' indicators.\n\n\ttokens          []yaml_token_t // The tokens queue.\n\ttokens_head     int            // The head of the tokens queue.\n\ttokens_parsed   int            // The number of tokens fetched from the queue.\n\ttoken_available bool           // Does the tokens queue contain a token ready for dequeueing.\n\n\tindent  int   // The current indentation level.\n\tindents []int // The indentation levels stack.\n\n\tsimple_key_allowed bool                // May a simple key occur at the current position?\n\tsimple_keys        []yaml_simple_key_t // The stack of simple keys.\n\tsimple_keys_by_tok map[int]int         // possible simple_key indexes indexed by token_number\n\n\t// Parser stuff\n\n\tstate          yaml_parser_state_t    // The current parser state.\n\tstates         []yaml_parser_state_t  // The parser states stack.\n\tmarks          []yaml_mark_t          // The stack of marks.\n\ttag_directives []yaml_tag_directive_t // The list of TAG directives.\n\n\t// Dumper stuff\n\n\taliases []yaml_alias_data_t // The alias data.\n\n\tdocument *yaml_document_t // The currently parsed document.\n}\n\ntype yaml_comment_t struct {\n\n\tscan_mark  yaml_mark_t // Position where scanning for comments started\n\ttoken_mark yaml_mark_t // Position after which tokens will be associated with this comment\n\tstart_mark yaml_mark_t // Position of '#' comment mark\n\tend_mark   yaml_mark_t // Position where comment terminated\n\n\thead []byte\n\tline []byte\n\tfoot []byte\n}\n\n// Emitter Definitions\n\n// The prototype of a write handler.\n//\n// The write handler is called when the emitter needs to flush the accumulated\n// characters to the output.  The handler should write @a size bytes of the\n// @a buffer to the output.\n//\n// @param[in,out]   data        A pointer to an application data specified by\n//                              yaml_emitter_set_output().\n// @param[in]       buffer      The buffer with bytes to be written.\n// @param[in]       size        The size of the buffer.\n//\n// @returns On success, the handler should return @c 1.  If the handler failed,\n// the returned value should be @c 0.\n//\ntype yaml_write_handler_t func(emitter *yaml_emitter_t, buffer []byte) error\n\ntype yaml_emitter_state_t int\n\n// The emitter states.\nconst (\n\t// Expect STREAM-START.\n\tyaml_EMIT_STREAM_START_STATE yaml_emitter_state_t = iota\n\n\tyaml_EMIT_FIRST_DOCUMENT_START_STATE       // Expect the first DOCUMENT-START or STREAM-END.\n\tyaml_EMIT_DOCUMENT_START_STATE             // Expect DOCUMENT-START or STREAM-END.\n\tyaml_EMIT_DOCUMENT_CONTENT_STATE           // Expect the content of a document.\n\tyaml_EMIT_DOCUMENT_END_STATE               // Expect DOCUMENT-END.\n\tyaml_EMIT_FLOW_SEQUENCE_FIRST_ITEM_STATE   // Expect the first item of a flow sequence.\n\tyaml_EMIT_FLOW_SEQUENCE_TRAIL_ITEM_STATE   // Expect the next item of a flow sequence, with the comma already written out\n\tyaml_EMIT_FLOW_SEQUENCE_ITEM_STATE         // Expect an item of a flow sequence.\n\tyaml_EMIT_FLOW_MAPPING_FIRST_KEY_STATE     // Expect the first key of a flow mapping.\n\tyaml_EMIT_FLOW_MAPPING_TRAIL_KEY_STATE     // Expect the next key of a flow mapping, with the comma already written out\n\tyaml_EMIT_FLOW_MAPPING_KEY_STATE           // Expect a key of a flow mapping.\n\tyaml_EMIT_FLOW_MAPPING_SIMPLE_VALUE_STATE  // Expect a value for a simple key of a flow mapping.\n\tyaml_EMIT_FLOW_MAPPING_VALUE_STATE         // Expect a value of a flow mapping.\n\tyaml_EMIT_BLOCK_SEQUENCE_FIRST_ITEM_STATE  // Expect the first item of a block sequence.\n\tyaml_EMIT_BLOCK_SEQUENCE_ITEM_STATE        // Expect an item of a block sequence.\n\tyaml_EMIT_BLOCK_MAPPING_FIRST_KEY_STATE    // Expect the first key of a block mapping.\n\tyaml_EMIT_BLOCK_MAPPING_KEY_STATE          // Expect the key of a block mapping.\n\tyaml_EMIT_BLOCK_MAPPING_SIMPLE_VALUE_STATE // Expect a value for a simple key of a block mapping.\n\tyaml_EMIT_BLOCK_MAPPING_VALUE_STATE        // Expect a value of a block mapping.\n\tyaml_EMIT_END_STATE                        // Expect nothing.\n)\n\n// The emitter structure.\n//\n// All members are internal.  Manage the structure using the @c yaml_emitter_\n// family of functions.\ntype yaml_emitter_t struct {\n\n\t// Error handling\n\n\terror   yaml_error_type_t // Error type.\n\tproblem string            // Error description.\n\n\t// Writer stuff\n\n\twrite_handler yaml_write_handler_t // Write handler.\n\n\toutput_buffer *[]byte   // String output data.\n\toutput_writer io.Writer // File output data.\n\n\tbuffer     []byte // The working buffer.\n\tbuffer_pos int    // The current position of the buffer.\n\n\traw_buffer     []byte // The raw buffer.\n\traw_buffer_pos int    // The current position of the buffer.\n\n\tencoding yaml_encoding_t // The stream encoding.\n\n\t// Emitter stuff\n\n\tcanonical   bool         // If the output is in the canonical style?\n\tbest_indent int          // The number of indentation spaces.\n\tbest_width  int          // The preferred width of the output lines.\n\tunicode     bool         // Allow unescaped non-ASCII characters?\n\tline_break  yaml_break_t // The preferred line break.\n\n\tstate  yaml_emitter_state_t   // The current emitter state.\n\tstates []yaml_emitter_state_t // The stack of states.\n\n\tevents      []yaml_event_t // The event queue.\n\tevents_head int            // The head of the event queue.\n\n\tindents []int // The stack of indentation levels.\n\n\ttag_directives []yaml_tag_directive_t // The list of tag directives.\n\n\tindent int // The current indentation level.\n\n\tflow_level int // The current flow level.\n\n\troot_context       bool // Is it the document root context?\n\tsequence_context   bool // Is it a sequence context?\n\tmapping_context    bool // Is it a mapping context?\n\tsimple_key_context bool // Is it a simple mapping key context?\n\n\tline       int  // The current line.\n\tcolumn     int  // The current column.\n\twhitespace bool // If the last character was a whitespace?\n\tindention  bool // If the last character was an indentation character (' ', '-', '?', ':')?\n\topen_ended bool // If an explicit document end is required?\n\n\tspace_above bool // Is there's an empty line above?\n\tfoot_indent int  // The indent used to write the foot comment above, or -1 if none.\n\n\t// Anchor analysis.\n\tanchor_data struct {\n\t\tanchor []byte // The anchor value.\n\t\talias  bool   // Is it an alias?\n\t}\n\n\t// Tag analysis.\n\ttag_data struct {\n\t\thandle []byte // The tag handle.\n\t\tsuffix []byte // The tag suffix.\n\t}\n\n\t// Scalar analysis.\n\tscalar_data struct {\n\t\tvalue                 []byte              // The scalar value.\n\t\tmultiline             bool                // Does the scalar contain line breaks?\n\t\tflow_plain_allowed    bool                // Can the scalar be expessed in the flow plain style?\n\t\tblock_plain_allowed   bool                // Can the scalar be expressed in the block plain style?\n\t\tsingle_quoted_allowed bool                // Can the scalar be expressed in the single quoted style?\n\t\tblock_allowed         bool                // Can the scalar be expressed in the literal or folded styles?\n\t\tstyle                 yaml_scalar_style_t // The output style.\n\t}\n\n\t// Comments\n\thead_comment []byte\n\tline_comment []byte\n\tfoot_comment []byte\n\ttail_comment []byte\n\n\tkey_line_comment []byte\n\n\t// Dumper stuff\n\n\topened bool // If the stream was already opened?\n\tclosed bool // If the stream was already closed?\n\n\t// The information associated with the document nodes.\n\tanchors *struct {\n\t\treferences int  // The number of references.\n\t\tanchor     int  // The anchor id.\n\t\tserialized bool // If the node has been emitted?\n\t}\n\n\tlast_anchor_id int // The last assigned anchor id.\n\n\tdocument *yaml_document_t // The currently emitted document.\n}\n"
        },
        {
          "name": "yamlprivateh.go",
          "type": "blob",
          "size": 5.9853515625,
          "content": "// \n// Copyright (c) 2011-2019 Canonical Ltd\n// Copyright (c) 2006-2010 Kirill Simonov\n// \n// Permission is hereby granted, free of charge, to any person obtaining a copy of\n// this software and associated documentation files (the \"Software\"), to deal in\n// the Software without restriction, including without limitation the rights to\n// use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\n// of the Software, and to permit persons to whom the Software is furnished to do\n// so, subject to the following conditions:\n// \n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n// \n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\npackage yaml\n\nconst (\n\t// The size of the input raw buffer.\n\tinput_raw_buffer_size = 512\n\n\t// The size of the input buffer.\n\t// It should be possible to decode the whole raw buffer.\n\tinput_buffer_size = input_raw_buffer_size * 3\n\n\t// The size of the output buffer.\n\toutput_buffer_size = 128\n\n\t// The size of the output raw buffer.\n\t// It should be possible to encode the whole output buffer.\n\toutput_raw_buffer_size = (output_buffer_size*2 + 2)\n\n\t// The size of other stacks and queues.\n\tinitial_stack_size  = 16\n\tinitial_queue_size  = 16\n\tinitial_string_size = 16\n)\n\n// Check if the character at the specified position is an alphabetical\n// character, a digit, '_', or '-'.\nfunc is_alpha(b []byte, i int) bool {\n\treturn b[i] >= '0' && b[i] <= '9' || b[i] >= 'A' && b[i] <= 'Z' || b[i] >= 'a' && b[i] <= 'z' || b[i] == '_' || b[i] == '-'\n}\n\n// Check if the character at the specified position is a digit.\nfunc is_digit(b []byte, i int) bool {\n\treturn b[i] >= '0' && b[i] <= '9'\n}\n\n// Get the value of a digit.\nfunc as_digit(b []byte, i int) int {\n\treturn int(b[i]) - '0'\n}\n\n// Check if the character at the specified position is a hex-digit.\nfunc is_hex(b []byte, i int) bool {\n\treturn b[i] >= '0' && b[i] <= '9' || b[i] >= 'A' && b[i] <= 'F' || b[i] >= 'a' && b[i] <= 'f'\n}\n\n// Get the value of a hex-digit.\nfunc as_hex(b []byte, i int) int {\n\tbi := b[i]\n\tif bi >= 'A' && bi <= 'F' {\n\t\treturn int(bi) - 'A' + 10\n\t}\n\tif bi >= 'a' && bi <= 'f' {\n\t\treturn int(bi) - 'a' + 10\n\t}\n\treturn int(bi) - '0'\n}\n\n// Check if the character is ASCII.\nfunc is_ascii(b []byte, i int) bool {\n\treturn b[i] <= 0x7F\n}\n\n// Check if the character at the start of the buffer can be printed unescaped.\nfunc is_printable(b []byte, i int) bool {\n\treturn ((b[i] == 0x0A) || // . == #x0A\n\t\t(b[i] >= 0x20 && b[i] <= 0x7E) || // #x20 <= . <= #x7E\n\t\t(b[i] == 0xC2 && b[i+1] >= 0xA0) || // #0xA0 <= . <= #xD7FF\n\t\t(b[i] > 0xC2 && b[i] < 0xED) ||\n\t\t(b[i] == 0xED && b[i+1] < 0xA0) ||\n\t\t(b[i] == 0xEE) ||\n\t\t(b[i] == 0xEF && // #xE000 <= . <= #xFFFD\n\t\t\t!(b[i+1] == 0xBB && b[i+2] == 0xBF) && // && . != #xFEFF\n\t\t\t!(b[i+1] == 0xBF && (b[i+2] == 0xBE || b[i+2] == 0xBF))))\n}\n\n// Check if the character at the specified position is NUL.\nfunc is_z(b []byte, i int) bool {\n\treturn b[i] == 0x00\n}\n\n// Check if the beginning of the buffer is a BOM.\nfunc is_bom(b []byte, i int) bool {\n\treturn b[0] == 0xEF && b[1] == 0xBB && b[2] == 0xBF\n}\n\n// Check if the character at the specified position is space.\nfunc is_space(b []byte, i int) bool {\n\treturn b[i] == ' '\n}\n\n// Check if the character at the specified position is tab.\nfunc is_tab(b []byte, i int) bool {\n\treturn b[i] == '\\t'\n}\n\n// Check if the character at the specified position is blank (space or tab).\nfunc is_blank(b []byte, i int) bool {\n\t//return is_space(b, i) || is_tab(b, i)\n\treturn b[i] == ' ' || b[i] == '\\t'\n}\n\n// Check if the character at the specified position is a line break.\nfunc is_break(b []byte, i int) bool {\n\treturn (b[i] == '\\r' || // CR (#xD)\n\t\tb[i] == '\\n' || // LF (#xA)\n\t\tb[i] == 0xC2 && b[i+1] == 0x85 || // NEL (#x85)\n\t\tb[i] == 0xE2 && b[i+1] == 0x80 && b[i+2] == 0xA8 || // LS (#x2028)\n\t\tb[i] == 0xE2 && b[i+1] == 0x80 && b[i+2] == 0xA9) // PS (#x2029)\n}\n\nfunc is_crlf(b []byte, i int) bool {\n\treturn b[i] == '\\r' && b[i+1] == '\\n'\n}\n\n// Check if the character is a line break or NUL.\nfunc is_breakz(b []byte, i int) bool {\n\t//return is_break(b, i) || is_z(b, i)\n\treturn (\n\t\t// is_break:\n\t\tb[i] == '\\r' || // CR (#xD)\n\t\tb[i] == '\\n' || // LF (#xA)\n\t\tb[i] == 0xC2 && b[i+1] == 0x85 || // NEL (#x85)\n\t\tb[i] == 0xE2 && b[i+1] == 0x80 && b[i+2] == 0xA8 || // LS (#x2028)\n\t\tb[i] == 0xE2 && b[i+1] == 0x80 && b[i+2] == 0xA9 || // PS (#x2029)\n\t\t// is_z:\n\t\tb[i] == 0)\n}\n\n// Check if the character is a line break, space, or NUL.\nfunc is_spacez(b []byte, i int) bool {\n\t//return is_space(b, i) || is_breakz(b, i)\n\treturn (\n\t\t// is_space:\n\t\tb[i] == ' ' ||\n\t\t// is_breakz:\n\t\tb[i] == '\\r' || // CR (#xD)\n\t\tb[i] == '\\n' || // LF (#xA)\n\t\tb[i] == 0xC2 && b[i+1] == 0x85 || // NEL (#x85)\n\t\tb[i] == 0xE2 && b[i+1] == 0x80 && b[i+2] == 0xA8 || // LS (#x2028)\n\t\tb[i] == 0xE2 && b[i+1] == 0x80 && b[i+2] == 0xA9 || // PS (#x2029)\n\t\tb[i] == 0)\n}\n\n// Check if the character is a line break, space, tab, or NUL.\nfunc is_blankz(b []byte, i int) bool {\n\t//return is_blank(b, i) || is_breakz(b, i)\n\treturn (\n\t\t// is_blank:\n\t\tb[i] == ' ' || b[i] == '\\t' ||\n\t\t// is_breakz:\n\t\tb[i] == '\\r' || // CR (#xD)\n\t\tb[i] == '\\n' || // LF (#xA)\n\t\tb[i] == 0xC2 && b[i+1] == 0x85 || // NEL (#x85)\n\t\tb[i] == 0xE2 && b[i+1] == 0x80 && b[i+2] == 0xA8 || // LS (#x2028)\n\t\tb[i] == 0xE2 && b[i+1] == 0x80 && b[i+2] == 0xA9 || // PS (#x2029)\n\t\tb[i] == 0)\n}\n\n// Determine the width of the character.\nfunc width(b byte) int {\n\t// Don't replace these by a switch without first\n\t// confirming that it is being inlined.\n\tif b&0x80 == 0x00 {\n\t\treturn 1\n\t}\n\tif b&0xE0 == 0xC0 {\n\t\treturn 2\n\t}\n\tif b&0xF0 == 0xE0 {\n\t\treturn 3\n\t}\n\tif b&0xF8 == 0xF0 {\n\t\treturn 4\n\t}\n\treturn 0\n\n}\n"
        }
      ]
    }
  ]
}