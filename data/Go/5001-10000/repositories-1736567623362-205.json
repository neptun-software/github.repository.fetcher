{
  "metadata": {
    "timestamp": 1736567623362,
    "page": 205,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "hybridgroup/gocv",
      "stars": 6811,
      "defaultBranch": "release",
      "files": [
        {
          "name": ".astylerc",
          "type": "blob",
          "size": 0.3427734375,
          "content": "--lineend=linux\n\n--style=google\n\n--indent=spaces=4\n--indent-col1-comments\n--convert-tabs\n\n--attach-return-type\n--attach-namespaces\n--attach-classes\n--attach-inlines\n\n--add-brackets\n--add-braces\n\n--align-pointer=type\n--align-reference=type\n\n--max-code-length=100\n--break-after-logical\n\n--pad-comma\n--pad-oper\n--unpad-paren\n\n--break-blocks\n--pad-header\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.1220703125,
          "content": "profile.cov\ncount.out\n*.swp\n*.snap\n/parts\n/prime\n/stage\n.vscode/\n/build\n.idea/\ncontrib/data.yaml\ncontrib/testOilPainting.png\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 44.728515625,
          "content": "0.39.0\n---\n- **bugfix**\n  - Fixed MinGW link typo in README.md.\n  - Fixed function name typo (#1236).\n- **core**\n  - Added `FaceDetectorYN` example.\n  - Query I/O API backends registry (#1237).\n  - Face detector YN face recognizer SF (#1232).\n- **cuda**\n  - Added `createLookUpTable` and `split` functions.\n  - Added missing CUDA `imgproc` standalone functions.\n  - Added `XXXWithStream` standalone functions.\n- **docker**\n  - Added Dockerfile for container that can perform static builds of your own GoCV project (HighGUI not supported by static builds).\n  - Added Dockerfile example showing how to build using static linking.\n  - Added static build examples.\n  - Updated version for `gocv-static-builder` image.\n- **build**\n  - Updated workflow for Docker builds to latest versions.\n  - Used most recent NVIDIA CUDA base image.\n  - Used static FFmpeg build for static OpenCV build.\n  - Downgraded static build to Go 1.22 to avoid [Go issue #68976](https://github.com/golang/go/issues/68976).\n  - Modified Dockerfile used for static builds to build own versions for static linking.\n  - Corrected build options for OpenCV on arm64 for static builds.\n  - Separated build tags and linker flags for arm64 and amd64 targets.\n  - Modified LDFLAGS for correct static compilation.\n  - Removed extra file to clear space for static build/standard dev build images.\n  - Added options for Linux arm64 and separate Darwin builds.\n- **cgo**\n  - Changed tags for static OpenCV to `opencvstatic`.\n  - Added options for Linux arm64 and separate Darwin builds.\n  - Removed unneeded lib from link for Linux/arm64.\n  - Modified LDFLAGS for correct static compilation.\n- **docs**\n  - Added missing `videoio` functions to ROADMAP.\n  - Updated ROADMAP with missing `objdetect` functions for DNN faces, and moved `aruco` under `objdetect` module.\n  - Simplified the YOLO example.\n\n0.38.0\n---\n* **bugfix**\n    * aruco: correct test from latest OpenCV update\n    * exclude freetype.cpp file from being included in windows build\n    * feat(demosaicing): release mat when conversion to bayer encounters invalid pattern\n    * imgproc HomographyMethod const values typo fixed\n* **build**\n    * add macOS build for GH actions CI\n    * adjust make and docker build files to build freetype support\n    * correct ONNX DNN tests on Linux/macOS\n    * move download for GOTURN models into testdata subdirectory\n    * remove Caffe tests\n    * run DNN tests on Windows\n    * make: add task to run all cuda tests\n    * make: build non-free modules when building opencv with cuda support\n    * skip tests on macOS that are not passing due to OpenCV different results on macOS. See https://forum.opencv.org/t/match-template-different-results-on-mac-m1/10026 and other similar issues.\n    * update all generated docker images to Go 1.23.1\n* **examples**\n    * add asciicam video to ascii in your terminal\n    * add object detection example using YOLOv8\n* **core**\n    * add Closed() function to Mat\n    * add OpenCV types for half-float values\n    * add TransposeND() function\n    * persistance implement Filestorage roadmap (#1208)\n    * RotatedRect type constructors\n* **dnn**\n    * add BlobFromImageWithParams() and BlobFromImagesWithParams() functions\n    * add BlobRectToImageRect() and BlobRectsToImageRects() functions\n    * allow ReadNet() function to only pass model file, and remove tests for Caffe\n* **features2d**\n    * SIFT with params (#1186)\n* **highgui**\n    * added window pollkey function (#1198)\n    * added window WaitKeyEx support (#1195)\n    * Window set mouse callback (#1220)\n* **imgcodecs**\n    * added immultiread support\n* **imgproc**\n    * feat(imgproc): demosaicing wrapper\n    * add HomographyMethodRHO HomographyMethod added\n* **objdetect**\n    * change QRCodeDetector signature to avoid pointer to slice\n* **video**\n    * added TrackerGOTURN (see roadmap)\n* **videoio**\n    * Capture from device and file with HW acceleration\n* **cuda**\n    * add Closed() function to Mat/GpuMat\n    * add DeviceSupports function\n    * add implementations for AddWeighted and CopyMakeBorder functions\n    * add Merge and Transpose functions\n    * add support for convertFp16 function\n    * add tests for demosaicing\n    * feat(imgproc): demosaicing wrapper\n    * correct go fmt error\n* **contrib/face**\n    * added face recognizer interface (#1211)\n    * BasicFaceRecognizer + EigenFaceRecognizer + FisherFaceRecognizer (#1213)\n    * extra setters and getters for LBPHFaceRecognizer (#1194)\n* **contrib/freetype**\n    * imported freetype code by lz1998 from PR 873\n\n0.37.0\n---\n* **all**\n    * Add support for OpenCV 4.10.0\n\n0.36.1\n---\n* **bugfix**\n    * Correct error in CUDA function signature\n* **test**\n    * correct CUDA tests\n* **docker**\n    * add test image for CUDA 12\n\n0.36.0\n---\n* **all**\n    * Add support for OpenCV 4.9.0\n    * update Go to version 1.22\n    * update minimum go version to 1.21\n* **bugfix**\n    * aruco: correct test from latest OpenCV update\n* **build**\n    * add GH action for Windows\n    * remove appveyor\n    * adjusted Makefile to build for debian bookworm\n* **core**\n    * Add additional signature for MinMaxLoc.\n    * add color conversion alias\n    * add Mahalanobis(), Inv(), Row(), amd Col() functions\n    * add MulTransposed() function\n    * add PCABackProject() and PCAProject() functions\n    * add PSNR() function\n    * add SVBackSubst() and SVDecomp() functions\n* **calib3d**\n    * add FisheyeCalibrate, FisheyeDistortPoints, and CheckChessboard functions\n    * Add func comments and update readme\n    * add Rodrigues function\n    * add SolvePnP function\n    * Add more smoke tests\n    * Initial commit of more stereo bindings\n* **feature2d**\n    * Add interface for `Feature2D` algorithms\n    * Asserting some algorithms conform to `Feature2D`\n    * Prepend \"Feature2D\" prefix to component interfaces of Feature2D\n* **imgproc**\n    * add CreateHanningWindow()\n    * add EMD()\n    * Add float version of BoxPoints and MinAreaRect\n    * Add new binding for cv::Erode.\n* **videoio**\n    * add Retrieve function\n* **contrib/xfeatures2d**\n    * Add BriefDescriptorExtractor to xfeatures2d (#1114)\n    * add NewSURFWithParams func\n    * Add separate \"Compute\" bindings for detection algorithms (#1117)\n* **cuda/core**\n    * ADD Cuda MultiplyWithStream (#1142)\n\n0.35.0\n---\n* **all**\n    * Add support for OpenCV 4.8.1\n    * correct Go formatting\n* **features2d**\n    * Add Match method for BFMatcher\n* **build**\n    * remove extra files from GH actions runner so GPU images builds have enough temp file space to run correctly\n* **make**\n    * for build_raspi added conditional cmake build for 64 and 32bit platforms\n    * remove ENABLE_VFPV3=ON and add WITH_TBB=ON from 64bit build.\n    * added sudo_pre_install_clean to raspberry pi and jetson installs\n    * change sudo_pre_install_clean to support cleanup on 64bit architechtures (arm and x86)\n\n0.34.0\n---\n* **all**\n    * Add support for OpenCV 4.8.0\n    * Add support for Go 1.21\n* **build**\n    * update all builds to use OpenCV 4.8.0\n* **core**\n    * Adds support for PCACompute\n* **docker**\n    * add dockerfile for OpenCV static build\n* **make**\n    * Leave one processor free instead of using all of them when building\n\n\n0.33.0\n---\n* **bugfix**\n    * Remove opencv2/aruco.hpp include\n* **all**\n    * build performance tests with all OpenCV builds\n* **build**\n    * build and push Ubuntu 22.04 base image with OpenCV 4.7.0\n    * docker images with opencv\n    * docker production images with opencv 4.7.0\n    * Docker push to GHCR\n* **core**\n    * Add ReduceArgMax and ReduceArgMin\n* **dnn**\n    * improved NMSBoxes code\n* **docker**\n    * add dockerfile for Ubuntu 22.04 OpenCV base image\n    * updates to migrate to GHCR\n* **examples**\n    * Deallocate Mats in feature-matching example.\n    * Fix G108 (CWE-200) and G114 (CWE-676)\n    * Fix G304 (CWE-22) and G307 (CWE-703)\n    * Fix G304 (CWE-22) and G307 (CWE-703)\n    * Missed #nosec tag\n* **make**\n    * Ubuntu Jammy (22) opencv build support.\n\n\n0.32.0\n---\n* **all**\n    * update to OpenCV 4.7.0\n* **core**\n    * Add the number of thread setter and getter\n* **calib3d**\n    * add EstimateAffinePartial2DWithParams()\n* **imgcodecs**\n    * Add IMDecodeIntoMat to reduce heap allocations (#1035)\n* **imgproc**\n    * add matchShapes function support\n* **objdetect**\n    * move aruco from contrib and also refactor/update to match current OpenCV API\n* **photo**\n    * add inpaint function\n* **video**\n    * cv::KalmanFilter bindings.\n* **cuda**\n    * add support for cuda::TemplateMatching\n* **docker**\n    * update all dockerfiles for OpenCV 4.7.0/GoCV 0.32.0\n    * multiplatform for both amd64 and arm64\n    * install libjpeg-turbo into docker image\n    * add Ubunutu 18.04 and 20.04 prebuilt OpenCV images\n    * add dockerfile for older version of CUDA for those who cannot upgrade\n* **ci**\n    * remove circleci\n    * correct actions that trigger build\n* **make**\n    * change download path for OpenCV release tag\n* **windows**\n    * Update win_build_opencv.cmd\n* **docs**\n    * correct docs on building docker\n    * update ROADMAP\n    * typo in comment\n    * update comments style with gofmt\n* **openvino**\n    * Add openvino Dockerfile\n    * Fix OpenvinoVersion dangling pointer\n    * Update env.sh and README.md for 2022.1\n\n0.31.0\n---\n* **all**\n    * update to OpenCV 4.6.0\n* **build**\n    * Switch to Github Actions for Linux CI build\n    * Use go -tags static when verifying static build\n* **core**\n    * Add Mat.ElemSize (#964)\n    * avoid index out of range panic in NewPointsVectorFromPoints\n* **video**\n    * add findTransformECC function\n* **contrib/ximgproc**\n    * add PeiLinNormalization() function\n    * add anisotropicDiffusion() function\n    * implement edgePreservingFilter()\n    * implement niBlackThreshold and thinning filters\n\n0.30.0\n---\n* **all**\n    * update to OpenCV 4.5.5\n* **build**\n    * add install_nonfree make task to build all opencv_contrib modules\n    * correct download location for onnx test file\n    * Update Makefile for missing version changes\n* **core**\n    * correct how memory is being allocated for Eye(), Zeros(), and Ones() to address issue #930\n* **calib3d** \n    * Adding support for estimateAffine2DWithParams (#924)\n* **imgproc**\n    * Add DrawContoursWithParams function\n* **photo**\n    * Add bindings for fastNlMeansDenoising and fastNlMeansDenoisingColored\n    * add detailEnhance function\n    * add EdgePreservingFilter function\n    * add PencilSketch function\n    * add stylization function\n* **docs**\n    * add godoc comments for FastNlMeansDenoising functions\n    * update README with info on latest mingw-w64 t use for Windows builds\n    * dnn pose detect examples correct the order of the argument variable name\n* **examples**\n    * Fixed memory leaks in the motion detection example\n* **openvino**\n    * Update env.sh and README.md\n* **windows**\n    * use mingw-w64 8.1.0 for protobuf compile\n* **contrib**\n    * add cv::wechat_qrcode::WeChatQRCode (#949)\n    * Update cgo_static.go\n\n0.29.0\n---\n* **all**\n    * update to OpenCV 4.5.4\n* **build**\n    * add static build ability on windows\n    * use tbb for all builds for CPU accelerated operations\n* **cuda**\n    * implement a bunch of per-element operations\n    * add get/set/reset device functions\n    * add NewGpuMatWithSize() to preallocate device memory\n    * Reshape() returns a new GpuMat with the changed data\n    * correct use of Stream by adding WaitForCompletion() and passing pre-allocated GpuMats\n* **docs**\n    * update ROADMAP from recent contributions\n* **videoio**\n    * Fix open video capture with api test (#895)\n* **calib3d**\n    * added EstimateAffine2D\n    * findChessboardCornersSB\n* **aruco**\n    * added many functions as part of initial implementation\n\n0.28.0\n---\n* **all**\n    * update to OpenCV 4.5.3\n    * make task and build tag for static build of OpenCV/GoCV on Linux\n    * add Makefile tasks for OpenCV install on Nvidia Jetson\n    * add gotest for more colorful test output running tests from containers\n* **build**\n    * correcting output format for code coverage report\n    * enforce rule that all Go code is correctly formatted\n    * remove codecov\n* **core**\n    * add NewPointVectorFromMat() and NewPoint2fVectorFromMat() functions\n    * Fix possible MatProfile race by ordering remove before free.\n* **cuda**\n    * add core functions for GpuMat like Cols(), Rows(), and Type()\n    * initial implementation for the Flip function\n* **docs**\n    * update ROADMAP from recent contributions\n* **examples**\n    * correct list of examples and fix comment\n* **features2d**\n    * Add NewORBWithParams\n* **tracking**\n    * change MOSSE to KCF\n* **highgui**\n    * Add function CreateTrackbarWithValue to Window type.\n* **imgcodec**\n    * optimize IMEncode avoiding multiple data copies.\n* **imgproc**\n    * Add CircleWithParams function\n    * Add DilateWithParams() function (#827)\n    * Add EllipseWithParams function\n    * Add FillPolyWithParams function\n    * Add PointPolygonTest function\n    * Add RectangleWithParams function\n* **photo**\n    * add MergeMertens, AlignMTB and Denoising function (#848)\n* **xphoto**\n    * Add Xphoto contrib (#844)\n\n0.27.0\n---\n* **all**\n    * update to OpenCV 4.5.2\n* **core**\n    * add Append() to PointsVector/PointVector\n    * add cv::RNG\n    * add implementation for Point2fVector\n    * add rand functions\n    * add test coverage for PointsVector\n    * create new PointsVector/PointVector wrappers to avoid repetitive memory copying for seeming innocent operations involving slices of image.Point\n    * test coverage for Point2f\n    * use PointVector for everything that we can to speed up pipeline when passing around Point vectors\n    * use enum instead of int for Invert Method\n* **cuda**\n    * adding HoughLinesDetector and HoughSegmentDetector\n    * adding tests for the CannyEdgeDetector\n    * some refactoring of the API\n    * adding dockerfiles for OpenCV 4.5.2 with CUDA 11.2\n    * add GaussianFilter\n    * correct signature and test for Threshold\n    * implement SobelFilter\n    * move arithm module functions into correct location\n    * rename files to get rid of so many cudas\n    * add abs function implementation\n* **dnn**\n    * increase test coverage\n* **docker**\n    * make all Dockerfiles names/tags more consistent\n* **docs**\n    * add CUDA functions that need implementation to ROADMAP\n    * remove invalid sections and add some missing functions from ROADMAP\n* **imgproc**\n    * Add FindContoursWithParams function\n    * Add ToImageYUV and ToImageYUVWithParams\n* **make**\n    * add make task to show changelog for next release\n* **wechat_qrcode**\n    * disable module in Windows due to linker error\n\n0.26.0\n---\n* **all**\n    * update to OpenCV 4.5.1\n* **core**\n    * add Matrix initializers: eye, ones, zeros (#758)\n    * add multidimensional mat creation\n    * add ndim mat constructor\n    * added accumulators\n    * added norm call with two mats (#600)\n    * keep a reference to a []byte that backs a Mat. (#755)\n    * remove guard for DataPtrUint8 since any Mat can be treated an Uint8\n    * add Mat IsContinuous() function, and ensure that any Mat data pointers used to create Go slices only apply to continuous Mats\n    * fix buffer size for Go strings for 32-bit operating systems\n* **build**\n    * bring back codecov.io\n* **calib3d**\n    * correctly close mat after test\n* **dnn**\n    * add ReadNetFromONNX and ReadNetFromONNXBytes (#760)\n    * increase test coverage\n* **docker**\n    * dockerfiles for opencv gpu builds\n* **docs**\n    * corrected links to CUDA and OpenVINO\n    * list all unimplemented functions in photo module\n    * replace GoDocs with pkg docs\n    * update ROADMAP from recent contributions\n* **imgproc**\n    * add test coverage for GetTextSizeWithBaseline()\n    * close all Mats even those based on memory slices\n    * close Mat to avoid memory leak in ToImage()\n    * refactoring of ToImage and ImageToMatXX functions\n* **openvino**\n    * fix dldt repo in makefile for openvino\n* **os**\n    * adding gcc-c++ package to rpm deps\n* **photo**\n    * add SeamlessClone function\n* **profile**\n    * add created mats in Split and ForwardLayers to profile (#780)\n\n0.25.0\n---\n* **all**\n    * update to opencv release 4.5.0\n* **build** \n    * add file dependencies needed for DNN tests\n    * add verbose output for tests on CircleCI\n    * also run unit tests on non-free algorithms. YMMV.\n    * fix build with cuda\n    * remove Travis and switch to CircleCI using Docker based builds\n    * update CI builds to Go 1.15\n* **core**\n    * add mixChannels() method to Mat (#746)\n    * Add toGoStrings helper\n    * support ConvertToWithParams method\n* **dnn**\n    * Add NMSBoxes function (#736)\n    * Added ability to load Torch file. Tested features for extracting 128d vectors\n    * fix using wrong type for unconnectedlayertype\n    * use default ddepth for conversions to blob from image as recommended by @berak\n* **docker** \n    * use separate dockerfile for opencv to avoid massive rebuild\n* **docs**\n    * add recent contributions to ROADMAP and also add cuda functions still in need of implementation\n    * display CircleCI badge in README\n    * minor improvements to CUDA docs in READMEs\n* **features2d**\n    * add FlannBasedMatcher\n    * add drawmatches (#720)\n    * fix memory leak in SIFT\n* **highgui**\n    * refactored ROI methods\n* **imgproc**\n    * Add option to return baseline with GetTextSizeWithBaseline\n* **objdetect** \n    * Add QRCode DetectAndDecodeMulti\n* **videoio**\n    * Add video capture properties and set preferred api backend (#739)\n    * fix needed as discussed in golang/go issue #32479\n\n0.24.0\n---\n* **all**\n    * update Makefile and READMEChange constants and corresponding function signatures to have the correct types (#689)\n    * replace master branch terminology with release\n    * update to OpenCV 4.4.0\n* **calib3d**\n    * add FindHomography()\n    * add function EstimateAffinePartial2D()\n    * add GetAffineTransform() and GetAffineTransform2f()\n    * add UndistortPoints(), FisheyeUndistortPoints() and EstimateNewCameraMatrixForUndistortRectify()\n* **core**\n    * add MultiplyWithParams\n* **docs**\n    * add recent contributions to ROADMAP\n    * create CODE_OF_CONDUCT.md\n    * update copyright year\n* **features2d**\n    * close returned Mat from SIFT algorithm\n    * fix issue 707 with DrawKeyPoints\n    * SIFT patent now expired so is part of main OpenCV modules\n* **imgproc**\n    * change struct to remove GNU old-style field designator extension warning\n\n0.23.0\n---\n* **build**\n    * update Makefile and README\n    * update to use go1.14\n* **calib3d**\n    * add draw chessboard\n* **core**\n    * fix memory leak in Mat.Size() and Mat.Split() (#580)\n* **cuda**\n    * add build support\n    * add cuda backend/target\n    * add support for:\n        * cv::cuda::CannyEdgeDetector\n        * cv::cuda::CascadeClassifier Class\n        * cv::cuda::HOG Class\n    * remove breaking case statement\n* **dnn**\n    * avoid parallel test runs\n    * remove attempt at providing grayscale image blog conversion that uses mean adjustment\n* **docker**\n    * docker file last command change (#505)\n* **docs**\n    * add recent contributions to ROADMAP\n* **imgproc**\n    * add ErodeWithParams function\n    * add getGaussianKernel function\n    * add Go Point2f type and update GetPerspectiveTransform() (#589)\n    * add PhaseCorrelate binding (#626)\n    * added Polylines feature\n    * do not free contours data until after we have drawn the needed contours\n    * Threshold() should return a value (#620)\n* **make**\n    * added raspberry pi zero support to the makefile\n* **opencv**\n    * update to OpenCV 4.3.0\n* **openvino**\n    * add build support\n* **windows**\n    * add cmake flag for allocator stats counter type to avoid opencv issue #16398\n\n0.22.0\n---\n* **bgsegm**\n    * Add BackgroundSubtractorCNT\n* **calib3d**\n    * Added undistort function (#520)\n* **core**\n    * add functions (singular value decomposition, multiply between matrices, transpose matrix) (#559)\n    * Add new funcs (#578)\n    * add setIdentity() method to Mat\n    * add String method (#552)\n    * MatType: add missing constants\n* **dnn**\n    * Adding GetLayerNames()\n    * respect the bit depth of the input image to set the expected output when converting an image to a blob\n* **doc**\n    * change opencv version 3.x to 4.x\n* **docker**\n    * use Go1.13.5 for image\n* **imgcodecs**\n    * Fix webp image decode error (#523)\nimgcodecs: optimize copy of data used for IMDecode method\n* **imgproc**\n    * Add GetRectSubPix\n    * Added ClipLine\n    * Added InvertAffineTransform\n    * Added LinearPolar function (#524)\n    * correct ksize param used for MedianBlur unit test\n    * Feature/put text with line type (#527)\n    * FitEllipse\n    * In FillPoly and DrawContours functions, remove func() wrap to avoid memory freed before calling opencv functions. (#543)\n* **objdetect**\n    * Add support QR codes\n* **opencv**\n    * update to OpenCV 4.2.0 release\n* **openvino**\n    * Add openvino async\n* **test**\n    * Tolerate imprecise result in SolvePoly\n    * Tolerate imprecision in TestHoughLines\n\n0.21.0\n---\n* **build**\n    * added go clean --cache to clean target, see issue 458\n* **core**\n    * Add KMeans function\n    * added MeanWithMask function for Mats (#487)\n    * Fix possible resource leak\n* **cuda**\n    * added cudaoptflow\n    * added NewGpuMatFromMat which creates a GpuMat from a Mat\n    * Support for CUDA Image Warping (#494)\n* **dnn**\n    * add BlobFromImages (#467)\n    * add ImagesFromBlob (#468)\n* **docs**\n    * update ROADMAP with all recent contributions. Thank you!\n* **examples**\n    * face detection from image url by using IMDecode (#499)\n    * better format\n* **imgproc**\n    * Add calcBackProject\n    * Add CompareHist\n    * Add DistanceTransform and Watershed\n    * Add GrabCut\n    * Add Integral\n    * Add MorphologyExWithParams\n* **opencv**\n    * update to version 4.1.2\n* **openvino**\n    * updates needed for 2019 R3\n* **videoio**\n    * Added ToCodec to convert FOURCC string to numeric representation (#485)\n\n0.20.0\n---\n* **build**\n    * Use Go 1.12.x for build\n    * Update to OpenCV 4.1.0\n* **cuda**\n    * Initial cuda implementation\n* **docs**\n    * Fix the command to install xquartz via brew/cask\n* **features2d**\n    * Add support for SimpleBlobDetectorParams (#434)\n    * Added FastFeatureDetectorWithParams\n* **imgproc**\n    * Added function call to cv::morphologyDefaultBorderValue\n* **test**\n    * Increase test coverage for FP16BlobFromImage()\n* **video**\n    * Added calcOpticalFlowPyrLKWithParams\n    * Addition of MOG2/KNN constructor with options\n\n0.19.0\n---\n* **build**\n    * Adds Dockerfile. Updates Makefile and README.\n    * make maintainer tag same as dockerhub organization name\n    * make sure to run tests for non-free contrib algorithms\n    * update Appveyor build to use Go 1.12\n* **calib3d**\n    * add func InitUndistortRectifyMap (#405)\n* **cmd**\n    * correct formatting of code in example\n* **core**\n    * Added Bitwise Operations With Masks\n    * update to OpenCV4.0.1\n* **dnn**\n    * add new backend and target types for NVIDIA and FPGA\n    * Added blobFromImages in ROADMAP.md (#403)\n    * Implement dnn methods for loading in-memory models.\n* **docker**\n    * update Dockerfile to use OpenCV 4.0.1\n* **docs**\n    * update ROADMAP from recent contributions\n* **examples**\n    * Fixing filename in caffe-classifier example\n* **imgproc**\n    * Add 'MinEnclosingCircle' function\n    * added BoxPoints function and BorderIsolated const\n    * Added Connected Components\n    * Added the HoughLinesPointSet function.\n    * Implement CLAHE to imgproc\n* **openvino**\n    * remove lib no longer included during non-FPGA installations\n* **test**\n    * Add len(kp) == 232 to TestMSER, seems this is necessary for MacOS for some reason.\n\n0.18.0\n---\n* **build**\n    * add OPENCV_GENERATE_PKGCONFIG flag to generate pkg-config file\n    * Add required curl package to the RPM and DEBS\n    * correct name for zip directory used for code download\n    * Removing linking against face contrib module\n    * update CI to use 4.0.0 release\n    * update Makefile and Windows build command file to OpenCV 4.0.0\n    * use opencv4 file for pkg-config\n* **core**\n    * add ScaleAdd() method to Mat\n* **docs**\n    * replace OpenCV 3.4.3 references with OpenCV 4\n    * update macOS installation info to refer to new OpenCV 4.0 brew\n    * Updated function documentation with information about errors.\n* **examples**\n    * Improve accuracy in hand gesture sample\n* **features2d**\n    * update drawKeypoints() to use new stricter enum\n* **openvino**\n    * changes to accommodate release 2018R4\n* **profile**\n    * add build tag matprofile to allow for conditional inclusion of custom profile\n    * Add Mat profile wrapper in other areas of the library.\n    * Add MatProfile.\n    * Add MatProfileTest.\n    * move MatProfile tests into separate test file so they only run when custom profiler active\n* **test**\n    * Close images in tests.\n    * More Closes in tests.\n    * test that we are using 4.0.x version now\n* **videoio**\n    * Return the right type and error when opening VideoCapture fails\n\n0.17.0\n---\n* **build** \n    * Update Makefile\n    * update version of OpenCV used to 3.4.3\n    * use link to OpenCV 3.4.3 for Windows builds\n* **core** \n    * add mulSpectrums wrapper\n    * add PolarToCart() method to Mat\n    * add Reduce() method to Mat\n    * add Repeat() method to Mat\n    * add Solve() method to Mat\n    * add SolveCubic() method to Mat\n    * add SolvePoly() method to Mat\n    * add Sort() method to Mat\n    * add SortIdx() method to Mat\n    * add Trace() method to Mat\n    * Added new MatType\n    * Added Phase function\n* **dnn** \n    * update test to match OpenCV 3.4.3 behavior\n* **docs**\n    * Add example of how to run individual test\n    * adding instructions for installing pkgconfig for macOS\n    * fixed GOPATH bug.\n    * update ROADMAP from recent contributions\n* **examples**\n    * add condition to handle no circle found in circle detection example\n* **imgcodecs**\n    * Added IMEncodeWithParams function\n* **imgproc**\n    * Added Filter2D function\n    * Added fitLine function\n    * Added logPolar function\n    * Added Remap function\n    * Added SepFilter2D function\n    * Added Sobel function\n    * Added SpatialGradient function\n* **xfeatures2d**\n    * do not run SIFT test unless OpenCV was built using OPENCV_ENABLE_NONFREE\n    * do not run SURF test unless OpenCV was built using OPENCV_ENABLE_NONFREE\n\n0.16.0\n---\n* **build**\n    * add make task for Raspbian install with ARM hardware optimizations\n    * use all available cores to compile OpenCV on Windows as discussed in issue #275\n    * download performance improvements for OpenCV installs on Windows\n    * correct various errors and issues with OpenCV installs on Fedora and CentOS\n* **core**\n    * correct spelling error in constant to fix issue #269\n    * implemented & added test for Mat.SetTo\n    * improve Multiply() GoDoc and test showing Scalar() multiplication\n    * mutator functions for Mat add, subtract, multiply, and divide for uint8 and float32 values.\n* **dnn**\n    * add FP16BlobFromImage() function to convert an image Mat to a half-float aka FP16 slice of bytes\n* **docs**\n    * fix a varible error in example code in README\n\n0.15.0\n---\n* **build**\n    * add max to make -j\n    * improve path for Windows to use currently configured GOPATH\n* **core**\n    * Add Mat.DataPtr methods for direct access to OpenCV data\n    * Avoid extra copy in Mat.ToBytes + code review feedback\n* **dnn**\n    * add test coverage for ParseNetBackend and ParseNetTarget\n    * complete test coverage\n* **docs**\n    * minor cleanup of language for install\n    * use chdir instead of cd in Windows instructions\n* **examples**\n    * add 'hello, video' example to repo\n    * add HoughLinesP example\n    * correct message on device close to match actual event\n    * small change in display message for when file is input source\n    * use DrawContours in motion detect example\n* **imgproc**\n    * Add MinAreaRect() function\n* **test**\n    * filling test coverage gaps\n* **videoio**\n    * add test coverage for OpenVideoCapture\n\n0.14.0\n---\n* **build**\n    * Add -lopencv_calib3d341 to the linker\n    * auto-confirm on package installs from make deps command\n    * display PowerShell download status for OpenCV files\n    * obtain caffe test config file from new location in Travis build\n    * remove VS only dependencies from OpenCV build, copy caffe test config file from new location\n    * return back to GoCV directory after OpenCV install\n    * update for release of OpenCV v3.4.2\n    * use PowerShell for scripted OpenCV install for Windows\n    * win32 version number has not changed yet\n* **calib3d**\n    * Add Calibrate for Fisheye model(WIP)\n* **core**\n    * add GetTickCount function\n    * add GetTickFrequency function\n    * add Size() and FromPtr() methods to Mat\n    * add Total method to Mat\n    * Added RotateFlag type\n    * correct CopyTo to use pointer to Mat as destination\n    * functions converting Image to Mat\n    * rename implementation to avoid conflicts with Windows\n    * stricter use of reflect.SliceHeader\n* **dnn**\n    * add backend/device options to caffe and tensorflow DNN examples\n    * add Close to Layer\n    * add first version of dnn-pose-detection example\n    * add further comments to object detection/tracking DNN example\n    * add GetPerfProfile function to Net\n    * add initial Layer implementation alongside enhancements to Net\n    * add InputNameToIndex to Layer\n    * add new functions allowing DNN backends such as OpenVINO\n    * additional refactoring and comments in dnn-pose-detection example\n    * cleanup DNN face detection example\n    * correct const for device targets to be called Target\n    * correct test that expected init slice with blank entries\n    * do not init slice with blank entries, since added via append\n    * further cleanup of DNN face detection example\n    * make dnn-pose-detection example use Go channels for async operation\n    * refactoring and additional comments for object detection/tracking DNN example\n    * refine comment in header for style transfer example\n    * working style transfer example\n    * added ForwardLayers() to accomodate models with multiple output layers\n* **docs**\n    * add scripted Windows install info to README\n    * Added a sample gocv workflow contributing guideline\n    * mention docker image in README.\n    * mention work in progress on Android\n    * simplify and add missing step in Linux installation in README\n    * update contributing instructions to match latest version\n    * update ROADMAP from recent calib3d module contribution\n    * update ROADMAP from recent imgproc histogram contribution\n* **examples**\n    * cleanup header for caffe dnn classifier\n    * show how to use either Caffe or Tensorflow for DNN object detection\n    * further improve dnn samples\n    * rearrange and add comments to dnn style transfer example\n    * remove old copy of pose detector\n    * remove unused example\n* **features2d**\n    * free memory allocation bug for C.KeyPoints as pointed out by @tzununbekov\n    * Adding opencv::drawKeypoints() support\n* **imgproc**\n    * add equalizeHist function\n    * Added opencv::calcHist implementation\n* **openvino**\n    * add needed environment config to execute examples\n    * further details in README explaining how to use\n    * remove opencv contrib references as they are not included in OpenVINO\n* **videoio**\n    * Add OpenVideoCapture\n    * Use gocv.VideoCaptureFile if string is specified for device.\n\n0.13.0\n---\n* **build**\n    * Add cgo directives to contrib\n    * contrib subpackage also needs cpp 11 or greater for a warning free build on Linux\n    * Deprecate env scripts and update README\n    * Don't set --std=c++1z on non-macOS\n    * Remove CGO vars from CI and correct Windows cgo directives\n    * Support pkg-config via cgo directives\n    * we actually do need cpp 11 or greater for a warning free build on Linux\n* **docs**\n    * add a Github issue template to project\n    * provide specific examples of using custom environment\n* **imgproc**\n    * add HoughLinesPWithParams() function\n* **openvino**\n    * add build tag specific to openvino\n    * add roadmap info\n    * add smoke test for ie\n\n0.12.0\n---\n* **build**\n    * convert to CRLF\n    * Enable verbosity for travisCI\n    * Further improvements to Makefile\n* **core**\n    * Add Rotate, VConcat\n    * Adding InScalarRange and NewMatFromScalarWithSize functions\n    * Changed NewMatFromScalarWithSize to NewMatWithSizeFromScalar\n    * implement CheckRange(), Determinant(), EigenNonSymmetric(), Min(), and MinMaxIdx() functions\n    * implement PerspectiveTransform() and Sqrt() functions\n    * implement Transform() and Transpose() functions\n    * Make toByteArray safe for empty byte slices\n    * Renamed InScalarRange to InRangeWithScalar\n* **docs**\n    * nicer error if we can't read haarcascade_frontalface_default\n    * correct some ROADMAP links\n    * Fix example command.\n    * Fix executable name in help text.\n    * update ROADMAP from recent contributions\n* **imgproc** \n    * add BoxFilter and SqBoxFilter functions\n    * Fix the hack to convert C arrays to Go slices.\n* **videoio** \n    * Add isColor to VideoWriterFile\n    * Check numerical parameters for gocv.VideoWriterFile\n    * CodecString()\n* **features2d** \n    * add BFMatcher\n* **img_hash** \n    * Add contrib/img_hash module\n    * add GoDocs for new img_hash module\n    * Add img-similarity as an example for img_hash\n* **openvino** \n    * adds support for Intel OpenVINO toolkit PVL\n    * starting experimental work on OpenVINO IE\n    * update README files for Intel OpenVINO toolkit support\n    * WIP on IE can load an IR network\n\n0.11.0\n---\n* **build**\n    * Add astyle config\n    * Astyle cpp/h files\n    * remove duplication in Makefile for astyle\n* **core**\n    * Add GetVecfAt() function to Mat\n    * Add GetVeciAt() function to Mat\n    * Add Mat.ToImage()\n    * add MeanStdDev() method to Mat\n    * add more functions\n    * Compare Mat Type directly\n    * further cleanup for GoDocs and enforce type for convariance operations\n    * Make borderType in CopyMakeBorder be type BorderType\n    * Mat Type() should return MatType\n    * remove unused convenience functions\n    * use Mat* to indicate when a Mat is mutable aka an output parameter\n* **dnn**\n    * add a ssd sample and a GetBlobChannel helper\n    * added another helper func and a pose detection demo\n* **docs**\n    * add some additional detail about adding OpenCV functions to GoCV\n    * updates to contribution guidelines\n    * fill out complete list of needed imgproc functions for sections that have work started\n    * indicate that missing imgproc functions need implementation\n    * mention the WithParams patterns to be used for functions with default params\n    * update README for the Mat* based API changes\n    * update ROADMAP for recent changes especially awesome recent core contributions from @berak\n* **examples**\n    * Fix tf-classifier example\n    * move new DNN advanced examples into separate folders\n    * Update doc for the face contrib package\n    * Update links in caffe-classifier demo\n    * WIP on hand gestures tracking example\n* **highgui**\n    * fix constant in NewWindow\n* **imgproc**\n    * Add Ellipse() and FillPoly() functions\n    * Add HoughCirclesWithParams() func\n    * correct output Mat to for ConvexHull()\n    * rename param being used for Mat image to be modified\n* **tracking**\n    * add support for TrackerMIL, TrackerBoosting, TrackerMedianFlow, TrackerTLD, TrackerKCF, TrackerMOSSE, TrackerCSRT trackers\n    * removed mutitracker, added Csrt, rebased\n    * update GoDocs and minor renaming based on gometalint output\n\n0.10.0\n---\n* **build** \n    * install unzip before build\n    * overwrite when unzipping file to install Tensorflow test model\n    * use -DCPU_DISPATCH= flag for build to avoid problem with disabled AVX on Windows\n    * update unzipped file when installing Tensorflow test model\n* **core** \n    * add Compare() and CountNonZero() functions\n    * add getter/setter using optional params for multi-dimensional Mat using row/col/channel\n    * Add mat subtract function\n    * add new toRectangle function to DRY up conversion from CRects to []image.Rectangle\n    * add split subtract sum wrappers\n    * Add toCPoints() helper function\n    * Added Mat.CopyToWithMask() per #47\n    * added Pow() method\n    * BatchDistance BorderInterpolate CalcCovarMatrix CartToPolar\n    * CompleteSymm ConvertScaleAbs CopyMakeBorder Dct\n    * divide, multiply\n    * Eigen Exp ExtractChannels\n    * operations on a 3d Mat are not same as a 2d multichannel Mat\n    * resolve merge conflict with duplicate Subtract() function\n    * run gofmt on core tests\n    * Updated type for Mat.GetUCharAt() and Mat.SetUCharAt() to reflect uint8 instead of int8\n* **docs** \n    * update ROADMAP of completed functions in core from recent contributions\n* **env** \n    * check loading resources\n    * Add distribution detection to deps rule\n    * Add needed environment variables for Linux\n* **highgui** \n    * add some missing test coverage on WaitKey()\n* **imgproc** \n    * Add adaptive threshold function\n    * Add pyrDown and pyrUp functions\n    * Expose DrawContours()\n    * Expose WarpPerspective and GetPerspectiveTransform\n    * implement ConvexHull() and ConvexityDefects() functions\n* **opencv** \n    * update to OpenCV version 3.4.1\n\n0.9.0\n---\n* **bugfix** \n    * correct several errors in size parameter ordering\n* **build**\n    * add missing opencv_face lib reference to env.sh\n    * Support for non-brew installs of opencv on Darwin\n* **core**\n    * add Channels() method to Mat\n    * add ConvertTo() and NewMatFromBytes() functions\n    * add Type() method to Mat\n    * implement ConvertFp16() function\n* **dnn** \n    * use correct size for blob used for Caffe/Tensorflow tests\n* **docs** \n    * Update copyright date and Apache 2.0 license to include full text\n* **examples** \n    * cleanup mjpeg streamer code\n    * cleanup motion detector comments\n    * correct use of defer in loop\n    * use correct size for blob used for Caffe/Tensorflow examples\n* **imgproc**\n    * Add cv::approxPolyDP() bindings.\n    * Add cv::arcLength() bindings.\n    * Add cv::matchTemplate() bindings.\n    * correct comment and link for Blur function\n    * correct docs for BilateralFilter()\n\n0.8.0\n---\n* **core**\n    * add ColorMapFunctions and their test\n    * add Mat ToBytes\n    * add Reshape and MinMaxLoc functions\n    * also delete points\n    * fix mistake in the norm function by taking NormType instead of int as parameter\n    * SetDoubleAt func and his test\n    * SetFloatAt func and his test\n    * SetIntAt func and his test\n    * SetSCharAt func and his test\n    * SetShortAt func and his test\n    * SetUCharAt fun and his test\n    * use correct delete operator for array of new, eliminates a bunch of memory leaks\n* **dnn**\n    * add support for loading Tensorflow models\n    * adjust test for Caffe now that we are auto-cropping blob\n    * first pass at adding Caffe support\n    * go back to older function signature to avoid version conflicts with Intel CV SDK\n    * properly close DNN Net class\n    * use approx. value from test result to account forr windows precision differences\n* **features2d**\n    * implement GFTTDetector, KAZE, and MSER algorithms\n    * modify MSER test for Windows results\n* **highgui**\n    * un-deprecate WaitKey function needed for CLI apps\n* **imgcodec**\n    * add fileExt type\n* **imgproc**\n    * add the norm wrapper and use it in test for WarpAffine and WarpAffineWithParams\n    * GetRotationMatrix2D, WarpAffine and WarpAffineWithParams\n    * use NormL2 in wrap affine\n* **pvl**\n    * add support for FaceRecognizer\n    * complete wrappers for all missing FaceDetector functions\n    * update instructions to match R3 of Intel CV SDK\n* **docs**\n    * add more detail about exactly which functions are not yet implememented in the modules that are marked as 'Work Started'\n    * add refernece to Tensorflow example, and also suggest brew upgrade for MacOS\n    * improve ROADMAP to help would-be contributors know where to get started\n    * in the readme, explain compiling to a static library\n    * remove many godoc warnings by improving function descriptions\n    * update all OpenCV 3.3.1 references to v3.4.0\n    * update CGO_LDFLAGS references to match latest requirements\n    * update contribution guidelines to try to make it more inviting\n* **examples**\n    * add Caffe classifier example\n    * add Tensorflow classifier example\n    * fixed closing window in examples in infinite loop\n    * fixed format of the examples with gofmt\n* **test**\n    * add helper function for test : floatEquals\n    * add some attiribution from test function\n    * display OpenCV version in case that test fails\n    * add round function to allow for floating point accuracy differences due to GPU usage.\n* **build**\n    * improve search for already installed OpenCV on MacOS\n    * update Appveyor build to Opencv 3.4.0\n    * update to Opencv 3.4.0\n\n0.7.0\n---\n* **core**\n    * correct Merge implementation\n* **docs**\n    * change wording and formatting for roadmap\n    * update roadmap for a more complete list of OpenCV functionality\n    * sequence docs in README in same way as the web site, aka by OS\n    * show in README that some work was done on contrib face module\n* **face**\n    * LBPH facerecognizer bindings\n* **highgui**\n    * complete implementation for remaining API functions\n* **imgcodecs**\n    * add IMDecode function\n* **imgproc**\n    * elaborate on HoughLines & HoughLinesP tests to fetch a few individual results\n* **objdetect**\n    * add GroupRectangles function\n* **xfeatures2d**\n    * add SIFT and SURF algorithms from OpenCV contrib\n    * improve description for OpenCV contrib\n    * run tests from OpenCV contrib\n\n0.6.0\n---\n* **core**\n    * Add cv::LUT binding\n* **examples** \n    * do not try to go fullscreen, since does not work on OSX\n* **features2d** \n    * add AKAZE algorithm\n    * add BRISK algorithm\n    * add FastFeatureDetector algorithm\n    * implement AgastFeatureDetector algorithm\n    * implement ORB algorithm\n    * implement SimpleBlobDetector algorithm\n* **osx**\n    * Fix to get the OpenCV path with \"brew info\".\n* **highgui** \n    * use new Window with thread lock, and deprecate WaitKey() in favor of Window.WaitKey()\n    * use Window.WaitKey() in tests\n* **imgproc** \n    * add tests for HoughCircles\n* **pvl**\n    * use correct Ptr referencing\n* **video** \n    * use smart Ptr for Algorithms thanks to @alalek\n    * use unsafe.Pointer for Algorithm    \n    * move tests to single file now that they all pass\n\n0.5.0\n---\n* **core**\n    * add TermCriteria for iterative algorithms\n* **imgproc**\n    * add CornerSubPix() and GoodFeaturesToTrack() for corner detection\n* **objdetect**\n    * add DetectMultiScaleWithParams() for HOGDescriptor\n    * add DetectMultiScaleWithParams() to allow override of defaults for CascadeClassifier\n* **video**\n    * add CalcOpticalFlowFarneback() for Farneback optical flow calculations\n    * add CalcOpticalFlowPyrLK() for Lucas-Kanade optical flow calculations\n* **videoio**\n    * use temp directory for Windows test compat.\n* **build**\n    * enable Appveyor build w/cache\n* **osx**\n    * update env path to always match installed OpenCV from Homebrew\n\n0.4.0\n---\n* **core**\n    * Added cv::mean binding with single argument\n    * fix the write-strings warning\n    * return temp pointer fix\n* **examples**\n    * add counter example\n    * add motion-detect command\n    * correct counter\n    * remove redundant cast and other small cleanup\n    * set motion detect example to fullscreen\n    * use MOG2 for continous motion detection, instead of simplistic first frame only\n* **highgui**\n    * ability to better control the fullscreen window\n* **imgproc**\n    * add BorderType param type for GaussianBlur\n    * add BoundingRect() function\n    * add ContourArea() function\n    * add FindContours() function along with associated data types\n    * add Laplacian and Scharr functions\n    * add Moments() function\n    * add Threshold function\n* **pvl**\n    * add needed lib for linker missing in README\n* **test**\n    * slightly more permissive version test\n* **videoio**\n    * Add image compression flags for gocv.IMWrite\n    * Fixed possible looping out of compression parameters length\n    * Make dedicated function to run cv::imwrite with compression parameters\n\n0.3.1\n---\n* **overall**\n    * Update to use OpenCV 3.3.1\n\n0.3.0\n---\n* **docs** \n    * Correct Windows build location from same @jpfarias fix to gocv-site\n* **core**\n    * Add Resize\n    * Add Mat merge and Discrete Fourier Transform\n    * Add CopyTo() and Normalize()\n    * Implement various important Mat logical operations\n* **video**\n    * BackgroundSubtractorMOG2 algorithm now working\n    * Add BackgroundSubtractorKNN algorithm from video module\n* **videoio**\n    * Add VideoCapture::get\n* **imgproc**\n    * Add BilateralFilter and MedianBlur\n    * Additional drawing functions implemented\n    * Add HoughCircles filter\n    * Implement various morphological operations\n* **highgui**\n    * Add Trackbar support\n* **objdetect**\n    * Add HOGDescriptor\n* **build** \n    * Remove race from test on Travis, since it causes CGo segfault in MOG2\n\n0.2.0\n---\n* Switchover to custom domain for package import\n* Yes, we have Windows\n\n0.1.0\n---\nInitial release!\n\n- [X] Video capture\n- [X] GUI Window to display video\n- [X] Image load/save\n- [X] CascadeClassifier for object detection/face tracking/etc.\n- [X] Installation instructions for Ubuntu\n- [X] Installation instructions for OS X\n- [X] Code example to use VideoWriter\n- [X] Intel CV SDK PVL FaceTracker support\n- [X] imgproc Image processing\n- [X] Travis CI build\n- [X] At least minimal test coverage for each OpenCV class\n- [X] Implement more of imgproc Image processing"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.2734375,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to making participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces\nwhen an individual is representing the project or its community. Examples of\nrepresenting a project or community include using an official project e-mail\naddress, posting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event. Representation of a project may be\nfurther defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at info@hybridgroup.com. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see\nhttps://www.contributor-covenant.org/faq\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 5.78125,
          "content": "# How to contribute\n\nThank you for your interest in improving GoCV.\n\nWe would like your help to make this project better, so we appreciate any contributions. See if one of the following descriptions matches your situation:\n\n### Newcomer to GoCV, to OpenCV, or to computer vision in general\n\nWe'd love to get your feedback on getting started with GoCV. Run into any difficulty, confusion, or anything else? You are not alone. We want to know about your experience, so we can help the next people. Please open a Github issue with your questions, or get in touch directly with us.\n\n### Something in GoCV is not working as you expect\n\nPlease open a Github issue with your problem, and we will be happy to assist.\n\n### Something you want/need from OpenCV does not appear to be in GoCV\n\nWe probably have not implemented it yet. Please take a look at our [ROADMAP.md](ROADMAP.md). Your pull request adding the functionality to GoCV would be greatly appreciated.\n\n### You found some Python code on the Internet that performs some computer vision task, and you want to do it using GoCV\n\nPlease open a Github issue with your needs, and we can see what we can do.\n\n## How to use our Github repository\n\nThe `release` branch of this repo will always have the latest released version of GoCV. All of the active development work for the next release will take place in the `dev` branch. GoCV will use semantic versioning and will create a tag/release for each release.\n\nHere is how to contribute back some code or documentation:\n\n- Fork repo\n- Create a feature branch off of the `dev` branch\n- Make some useful change\n- Submit a pull request against the `dev` branch.\n- Be kind\n\n## How to add a function from OpenCV to GoCV\n\nHere are a few basic guidelines on how to add a function from OpenCV to GoCV:\n\n- Please open a Github issue. We want to help, and also make sure that there is no duplications of efforts. Sometimes what you need is already being worked on by someone else.\n- Use the proper Go style naming `MissingFunction()` for the Go wrapper.\n- Make any output parameters `Mat*` to indicate to developers that the underlying OpenCV data will be changed by the function.\n- Use Go types when possible as parameters for example `image.Point` and then convert to the appropriate OpenCV struct. Also define a new type based on `int` and `const` values instead of just passing \"magic numbers\" as params. For example, the `VideoCaptureProperties` type used in `videoio.go`.\n- Always add the function to the GoCV file named the same as the OpenCV module to which the function belongs.\n- If the new function is in a module that is not yet implemented by GoCV, a new set of files for that module will need to be added.\n- Always add a \"smoke\" test for the new function being added. We are not testing OpenCV itself, but just the GoCV wrapper, so all that is needed generally is just exercising the new function.\n- If OpenCV has any default params for a function, we have been implementing 2 versions of the function since Go does not support overloading. For example, with a OpenCV function:\n\n```c\nopencv::xYZ(int p1, int p2, int p3=2, int p4=3);\n```\n\nWe would define 2 functions in GoCV:\n\n```go\n// uses default param values\nXYZ(p1, p2)\n\n// sets each param\nXYZWithParams(p2, p2, p3, p4)\n```\n\n## How to run tests\n\nTo run the tests:\n\n```\ngo test .\ngo test ./contrib/.\n```\n\nIf you want to run an individual test, you can provide a RegExp to the `-run` argument:\n```\ngo test -run TestMat\n```\n\nIf you are using Intel OpenVINO, you can run those tests using:\n\n```\ngo test ./openvino/...\n```\n\n## Contributing workflow\n\nThis section provides a short description of one of many possible workflows you can follow to contribute to `GoCV`. This workflow is based on multiple [git remotes](https://git-scm.com/docs/git-remote) and it's by no means the only workflow you can use to contribute to `GoCV`. However, it's an option that might help you get started quickly without too much hassle as this workflow lets you work off the `gocv` repo directory path!\n\nAssuming you have already forked the `gocv` repo, you need to add a new `git remote` which will point to your GitHub fork. Notice below that you **must** `cd` to `gocv` repo directory before you add the new `git remote`:\n\n```shell\ncd $GOPATH/src/gocv.io/x/gocv\ngit remote add gocv-fork https://github.com/YOUR_GH_HANDLE/gocv.git\n```\n\nNote, that in the command above we called our new `git remote`, **gocv-fork** for convenience so we can easily recognize it. You are free to choose any remote name of your liking.\n\nYou should now see your new `git remote` when running the command below:\n\n```shell\ngit remote -v\n\ngocv-fork\thttps://github.com/YOUR_GH_HANDLE/gocv.git (fetch)\ngocv-fork\thttps://github.com/YOUR_GH_HANDLE/gocv.git (push)\norigin\t        https://github.com/hybridgroup/gocv (fetch)\norigin\t        https://github.com/hybridgroup/gocv (push)\n```\n\nBefore you create a new branch from `dev` you should fetch the latests commits from the `dev` branch:\n\n```shell\ngit fetch origin dev\n```\n\nYou want the `dev` branch in your `gocv` fork to be in sync with the `dev` branch of `gocv`, so push the earlier fetched commits to your GitHub fork as shown below. Note, the `-f` force switch might not be needed:\n\n```shell\ngit push gocv-fork dev -f\n```\n\nCreate a new feature branch from `dev`:\n\n```shell\ngit checkout -b new-feature\n```\n\nAfter you've made your changes you can run the tests using the `make` command listed below. Note, you're still working off the `gocv` project root directory, hence running the command below does not require complicated `$GOPATH` rewrites or whatnot:\n\n```shell\nmake test\n```\n\nOnce the tests have passed, commit your new code to the `new-feature` branch and push it to your fork running the command below:\n\n```shell\ngit push gocv-fork new-feature\n```\n\nYou can now open a new PR from `new-feature` branch in your forked repo against the `dev` branch of `gocv`.\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.255859375,
          "content": "# to build this docker image:\n#   docker build .\nFROM ghcr.io/hybridgroup/opencv:4.10.0\n\nENV GOPATH /go\n\nCOPY . /go/src/gocv.io/x/gocv/\n\nWORKDIR /go/src/gocv.io/x/gocv\nRUN go build -tags example -o /build/gocv_version ./cmd/version/\n\nCMD [\"/build/gocv_version\"]\n"
        },
        {
          "name": "Dockerfile-static",
          "type": "blob",
          "size": 0.5869140625,
          "content": "# to build this docker image:\n#   docker buildx build -f Dockerfile-static -t gocv-static --platform=linux/amd64,linux/arm64 .\n#\nFROM --platform=$BUILDPLATFORM ghcr.io/hybridgroup/opencv:4.10.0-static AS gocv-build\n\nENV GOPATH /go\n\nCOPY . /go/src/gocv.io/x/gocv/\n\nWORKDIR /go/src/gocv.io/x/gocv\n\nRUN --mount=target=. \\\n    --mount=type=cache,target=/root/.cache/go-build \\\n    --mount=type=cache,target=/go/pkg/mod \\\n    go build -tags static -o /build/gocv_version ./cmd/version/\n\nFROM debian:bullseye AS final\n\nCOPY --from=gocv-build /build/gocv_version /run/gocv_version\n\nCMD [\"/run/gocv_version\"]\n"
        },
        {
          "name": "Dockerfile-static-builder",
          "type": "blob",
          "size": 0.787109375,
          "content": "# to build this docker image:\n#   docker build -f Dockerfile-static-builder -t gocv-static-builder .\n# or for multi-arch builds:\n#   docker buildx build -f Dockerfile-static-builder -t ghcr.io/hybridgroup/gocv-static-builder --platform=linux/amd64,linux/arm64 --push .\n#\n# to use this docker image:\n#   cd /path/to/my/project\n#   docker run --rm -e \"BINARYNAME=mjpeg-streamer\" -e \"SRCPATH=./cmd/mjpeg-streamer\" -v $(pwd):/src -v $(pwd)/build:/build -a stdout -a stderr --platform linux/amd64 gocv-static-builder\n#\n# NOTE that you cannot use highgui from the static build!\n#\nFROM --platform=$BUILDPLATFORM ghcr.io/hybridgroup/opencv:4.10.0-static AS gocv-static-builder\n\nWORKDIR /src\n\nENV BINARYNAME=gocv_static_binary\nENV SRCPATH=.\n\nCMD go build -tags static -o /build/$BINARYNAME -buildvcs=false $SRCPATH\n"
        },
        {
          "name": "Dockerfile-test",
          "type": "blob",
          "size": 0.423828125,
          "content": "# To build:\n#   docker build -f Dockerfile-test -t gocv-test .\n#\n# To run tests:\n#   xhost +\n#   docker run -it --rm -e DISPLAY=$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix gocv-test-4.x\n#   xhost -\n#\nFROM ghcr.io/hybridgroup/opencv:4.10.0 AS gocv-test-4.10\n\nENV GOPATH /go\n\nCOPY . /go/src/gocv.io/x/gocv/\n\nWORKDIR /go/src/gocv.io/x/gocv\n\nRUN go install github.com/rakyll/gotest@latest\n\nENTRYPOINT [\"gotest\", \"-v\", \".\", \"./contrib/...\"]\n"
        },
        {
          "name": "Dockerfile-test.gpu-cuda-10",
          "type": "blob",
          "size": 0.427734375,
          "content": "# To build:\n#   docker build -f Dockerfile-test.gpu-cuda-10 -t gocv-test-gpu-cuda-10 .\n#\n# To run tests:\n#   docker run -it --rm --gpus all gocv-test-gpu-cuda-10\n#\nFROM ghcr.io/hybridgroup/opencv:4.10.0-gpu-cuda-10 AS gocv-gpu-test-cuda-10\n\nENV GOPATH /go\nENV PATH=\"${PATH}:/go/bin\"\n\nCOPY . /go/src/gocv.io/x/gocv/\n\nWORKDIR /go/src/gocv.io/x/gocv\n\nRUN go install github.com/rakyll/gotest@latest\n\nENTRYPOINT [\"gotest\", \"-v\", \"./cuda/...\"]\n"
        },
        {
          "name": "Dockerfile-test.gpu-cuda-11",
          "type": "blob",
          "size": 0.427734375,
          "content": "# To build:\n#   docker build -f Dockerfile-test.gpu-cuda-11 -t gocv-test-gpu-cuda-11 .\n#\n# To run tests:\n#   docker run -it --rm --gpus all gocv-test-gpu-cuda-11\n#\nFROM ghcr.io/hybridgroup/opencv:4.10.0-gpu-cuda-11 AS gocv-gpu-test-cuda-11\n\nENV GOPATH /go\nENV PATH=\"${PATH}:/go/bin\"\n\nCOPY . /go/src/gocv.io/x/gocv/\n\nWORKDIR /go/src/gocv.io/x/gocv\n\nRUN go install github.com/rakyll/gotest@latest\n\nENTRYPOINT [\"gotest\", \"-v\", \"./cuda/...\"]\n"
        },
        {
          "name": "Dockerfile-test.gpu-cuda-11.2.2",
          "type": "blob",
          "size": 0.443359375,
          "content": "# To build:\n#   docker build -f Dockerfile-test.gpu-cuda-11.2.2 -t gocv-test-gpu-cuda-11.2.2 .\n#\n# To run tests:\n#   docker run -it --rm --gpus all gocv-test-gpu-cuda-11.2.2\n#\nFROM ghcr.io/hybridgroup/opencv:4.10.0-gpu-cuda-11.2.2 AS gocv-gpu-test-cuda-11\n\nENV GOPATH /go\nENV PATH=\"${PATH}:/go/bin\"\n\nCOPY . /go/src/gocv.io/x/gocv/\n\nWORKDIR /go/src/gocv.io/x/gocv\n\nRUN go install github.com/rakyll/gotest@latest\n\nENTRYPOINT [\"gotest\", \"-v\", \"./cuda/...\"]\n"
        },
        {
          "name": "Dockerfile-test.gpu-cuda-12",
          "type": "blob",
          "size": 0.427734375,
          "content": "# To build:\n#   docker build -f Dockerfile-test.gpu-cuda-12 -t gocv-test-gpu-cuda-12 .\n#\n# To run tests:\n#   docker run -it --rm --gpus all gocv-test-gpu-cuda-12\n#\nFROM ghcr.io/hybridgroup/opencv:4.10.0-gpu-cuda-12 AS gocv-gpu-test-cuda-12\n\nENV GOPATH /go\nENV PATH=\"${PATH}:/go/bin\"\n\nCOPY . /go/src/gocv.io/x/gocv/\n\nWORKDIR /go/src/gocv.io/x/gocv\n\nRUN go install github.com/rakyll/gotest@latest\n\nENTRYPOINT [\"gotest\", \"-v\", \"./cuda/...\"]\n"
        },
        {
          "name": "Dockerfile.gpu",
          "type": "blob",
          "size": 0.30078125,
          "content": "# to build this docker image:\n#   docker build -f Dockerfile.gpu .\nFROM ghcr.io/hybridgroup/opencv:4.10.0-gpu-cuda-11 AS gocv-gpu\n\nENV GOPATH /go\n\nCOPY . /go/src/gocv.io/x/gocv/\n\nWORKDIR /go/src/gocv.io/x/gocv\nRUN go build -tags cuda -o /build/gocv_cuda_version ./cmd/cuda/\n\nCMD [\"/build/gocv_cuda_version\"]\n"
        },
        {
          "name": "Dockerfile.opencv",
          "type": "blob",
          "size": 5.0380859375,
          "content": "# OpenCV 4 prebuilt multiarchitecture image\n#\n# To build release:\n#   docker buildx build -f Dockerfile.opencv -t ghcr.io/hybridgroup/opencv:4.10.0 -t ghcr.io/hybridgroup/opencv:latest --platform=linux/arm64,linux/amd64 --push .\n#\n# To build prerelease:\n#   docker buildx build --build-arg OPENCV_VERSION=\"4.x\" --build-arg OPENCV_FILE=\"https://github.com/opencv/opencv/archive/refs/heads/4.x.zip\" --build-arg OPENCV_CONTRIB_FILE=\"https://github.com/opencv/opencv_contrib/archive/refs/heads/4.x.zip\" -f Dockerfile.opencv -t ghcr.io/hybridgroup/opencv:4.10.0-dev --platform=linux/arm64,linux/amd64 --push .\n\n\n###################\n# amd64 build stage\n###################\n\nFROM --platform=linux/amd64 golang:1.23-bullseye AS opencv-base-amd64\nLABEL maintainer=\"hybridgroup\"\n\nRUN apt-get update && apt-get install -y \\\n      git build-essential cmake pkg-config unzip libgtk2.0-dev \\\n      curl ca-certificates libcurl4-openssl-dev libssl-dev \\\n      libavcodec-dev libavformat-dev libswscale-dev libtbb2 libtbb-dev \\\n      libharfbuzz-dev libfreetype6-dev \\\n      libjpeg62-turbo-dev libpng-dev libtiff-dev libdc1394-22-dev nasm && \\\n      rm -rf /var/lib/apt/lists/*\n\nFROM --platform=linux/amd64 opencv-base-amd64 AS opencv-build-amd64\n\nARG OPENCV_VERSION=\"4.10.0\"\nENV OPENCV_VERSION $OPENCV_VERSION\n\nARG OPENCV_FILE=\"https://github.com/opencv/opencv/archive/${OPENCV_VERSION}.zip\"\nENV OPENCV_FILE $OPENCV_FILE\n\nARG OPENCV_CONTRIB_FILE=\"https://github.com/opencv/opencv_contrib/archive/${OPENCV_VERSION}.zip\"\nENV OPENCV_CONTRIB_FILE $OPENCV_CONTRIB_FILE\n\nRUN curl -Lo opencv.zip ${OPENCV_FILE} && \\\n      unzip -q opencv.zip && \\\n      curl -Lo opencv_contrib.zip ${OPENCV_CONTRIB_FILE} && \\\n      unzip -q opencv_contrib.zip && \\\n      rm opencv.zip opencv_contrib.zip\n\nRUN cd opencv-${OPENCV_VERSION} && \\\n      mkdir build && cd build && \\\n      cmake -D CMAKE_BUILD_TYPE=RELEASE \\\n      -D WITH_IPP=OFF \\\n      -D WITH_OPENGL=OFF \\\n      -D WITH_QT=OFF \\\n      -D WITH_FREETYPE=ON \\\n      -D CMAKE_INSTALL_PREFIX=/usr/local \\\n      -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib-${OPENCV_VERSION}/modules \\\n      -D OPENCV_ENABLE_NONFREE=ON \\\n      -D WITH_JASPER=OFF \\\n      -D WITH_TBB=ON \\\n      -D BUILD_JPEG=ON \\\n      -D WITH_SIMD=ON \\\n      -D ENABLE_LIBJPEG_TURBO_SIMD=ON \\\n      -D BUILD_DOCS=OFF \\\n      -D BUILD_EXAMPLES=OFF \\\n      -D BUILD_TESTS=OFF \\\n      -D BUILD_PERF_TESTS=ON \\\n      -D BUILD_opencv_java=NO \\\n      -D BUILD_opencv_python=NO \\\n      -D BUILD_opencv_python2=NO \\\n      -D BUILD_opencv_python3=NO \\\n      -D OPENCV_GENERATE_PKGCONFIG=ON .. && \\\n      make -j $(nproc --all) && \\\n      make preinstall && make install && ldconfig && \\\n      cd / && rm -rf opencv*\n\n\n###################\n# arm64 build stage\n###################\n\nFROM --platform=linux/arm64 golang:1.23-bullseye AS opencv-base-arm64\nLABEL maintainer=\"hybridgroup\"\n\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n      git build-essential cmake pkg-config unzip libgtk2.0-dev \\\n      curl ca-certificates libcurl4-openssl-dev libssl-dev \\\n      libavcodec-dev libavformat-dev libswscale-dev libtbb2 libtbb-dev \\\n      libharfbuzz-dev libfreetype6-dev \\\n      libjpeg62-turbo-dev libpng-dev libtiff-dev libdc1394-22-dev && \\\n      apt-get autoremove -y && apt-get autoclean -y\n\nFROM --platform=linux/arm64 opencv-base-arm64 AS opencv-build-arm64\n\nARG OPENCV_VERSION=\"4.10.0\"\nENV OPENCV_VERSION $OPENCV_VERSION\n\nARG OPENCV_FILE=\"https://github.com/opencv/opencv/archive/${OPENCV_VERSION}.zip\"\nENV OPENCV_FILE $OPENCV_FILE\n\nARG OPENCV_CONTRIB_FILE=\"https://github.com/opencv/opencv_contrib/archive/${OPENCV_VERSION}.zip\"\nENV OPENCV_CONTRIB_FILE $OPENCV_CONTRIB_FILE\n\nRUN curl -Lo opencv.zip ${OPENCV_FILE} && \\\n      unzip -q opencv.zip && \\\n      curl -Lo opencv_contrib.zip ${OPENCV_CONTRIB_FILE} && \\\n      unzip -q opencv_contrib.zip && \\\n      rm opencv.zip opencv_contrib.zip\n\nRUN cd opencv-${OPENCV_VERSION} && \\\n      mkdir build && cd build && \\\n      cmake -D CMAKE_BUILD_TYPE=RELEASE \\\n      -D CMAKE_INSTALL_PREFIX=/usr/local \\\n      -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib-${OPENCV_VERSION}/modules \\\n      -D ENABLE_NEON=ON \\\n      -D WITH_FFMPEG=ON \\\n      -D WITH_TBB=ON \\\n      -D BUILD_TBB=ON \\\n      -D BUILD_TESTS=OFF \\\n      -D WITH_EIGEN=OFF \\\n      -D WITH_GSTREAMER=OFF \\\n      -D WITH_V4L=ON \\\n      -D WITH_LIBV4L=ON \\\n      -D WITH_VTK=OFF \\\n      -D WITH_QT=OFF \\\n      -D WITH_FREETYPE=ON \\\n      -D BUILD_JPEG=ON \\\n      -D OPENCV_ENABLE_NONFREE=ON \\\n      -D BUILD_DOCS=OFF \\\n      -D BUILD_EXAMPLES=OFF \\\n      -D BUILD_TESTS=OFF \\\n      -D BUILD_PERF_TESTS=ON \\\n      -D BUILD_opencv_java=NO \\\n      -D BUILD_opencv_python=NO \\\n      -D BUILD_opencv_python2=NO \\\n      -D BUILD_opencv_python3=NO \\\n      -D OPENCV_GENERATE_PKGCONFIG=ON \\\n      -D CMAKE_TOOLCHAIN_FILE=../platforms/linux/aarch64-gnu.toolchain.cmake .. && \\\n      make -j $(nproc --all) && \\\n      make preinstall && make install && ldconfig && \\\n      cd / && rm -rf opencv*\n\nARG TARGETARCH\n\n###################\n# multiarch build stage\n###################\n\nFROM opencv-build-${TARGETARCH} as opencv-final\n\nCMD [\"opencv_version\", \"-b\"]\n"
        },
        {
          "name": "Dockerfile.opencv-gpu-cuda-10",
          "type": "blob",
          "size": 2.5,
          "content": "# to build this docker image:\n#   docker build -f Dockerfile.opencv-gpu-cuda-10 -t ghcr.io/hybridgroup/opencv:4.10.0-gpu-cuda-10 .\nFROM nvidia/cuda:10.2-cudnn8-devel AS opencv-gpu-base\nLABEL maintainer=\"hybridgroup\"\n\n# needed for cuda repo key rotation. see:\n# https://forums.developer.nvidia.com/t/notice-cuda-linux-repository-key-rotation/212771\n#\nRUN apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/3bf863cc.pub\n\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    git build-essential cmake pkg-config unzip libgtk2.0-dev \\\n    wget curl ca-certificates libcurl4-openssl-dev libssl-dev \\\n    libavcodec-dev libavformat-dev libswscale-dev libtbb2 libtbb-dev \\\n    libjpeg-dev libpng-dev libtiff-dev libdc1394-22-dev && \\\n    rm -rf /var/lib/apt/lists/*\n\nARG OPENCV_VERSION=\"4.10.0\"\nENV OPENCV_VERSION $OPENCV_VERSION\n\nRUN curl -Lo opencv.zip https://github.com/opencv/opencv/archive/${OPENCV_VERSION}.zip && \\\n    unzip -q opencv.zip && \\\n    curl -Lo opencv_contrib.zip https://github.com/opencv/opencv_contrib/archive/${OPENCV_VERSION}.zip && \\\n    unzip -q opencv_contrib.zip && \\\n    rm opencv.zip opencv_contrib.zip && \\\n    cd opencv-${OPENCV_VERSION} && \\\n    mkdir build && cd build && \\\n    cmake -D CMAKE_BUILD_TYPE=RELEASE \\\n    -D WITH_IPP=OFF \\\n    -D WITH_OPENGL=OFF \\\n    -D WITH_QT=OFF \\\n    -D CMAKE_INSTALL_PREFIX=/usr/local \\\n    -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib-${OPENCV_VERSION}/modules \\\n    -D OPENCV_ENABLE_NONFREE=ON \\\n    -D WITH_JASPER=OFF \\\n    -D BUILD_DOCS=OFF \\\n    -D BUILD_EXAMPLES=OFF \\\n    -D BUILD_TESTS=OFF \\\n    -D BUILD_PERF_TESTS=ON \\\n    -D BUILD_opencv_java=NO \\\n    -D BUILD_opencv_python=NO \\\n    -D BUILD_opencv_python2=NO \\\n    -D BUILD_opencv_python3=NO \\\n    -D WITH_TBB=ON \\\n    -D WITH_CUDA=ON \\\n    -D ENABLE_FAST_MATH=1 \\\n    -D CUDA_FAST_MATH=1 \\\n    -D WITH_CUBLAS=1 \\\n    -D CUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda/ \\\n    -D BUILD_opencv_cudacodec=OFF \\\n    -D WITH_CUDNN=ON \\\n    -D OPENCV_DNN_CUDA=ON \\\n    -D CUDA_GENERATION=Auto \\\n    -D OPENCV_GENERATE_PKGCONFIG=ON .. && \\\n    make -j $(nproc --all) && \\\n    make preinstall && make install && ldconfig && \\\n    cd / && rm -rf opencv*\n\n# install golang here\nFROM opencv-gpu-base AS opencv-gpu-golang\n\nENV GO_RELEASE=1.23.1\nRUN wget https://dl.google.com/go/go${GO_RELEASE}.linux-amd64.tar.gz && \\\n    tar xfv go${GO_RELEASE}.linux-amd64.tar.gz -C /usr/local && \\\n    rm go${GO_RELEASE}.linux-amd64.tar.gz\nENV PATH=\"${PATH}:/usr/local/go/bin\"\n\nCMD [\"go version\"]\n"
        },
        {
          "name": "Dockerfile.opencv-gpu-cuda-11",
          "type": "blob",
          "size": 2.974609375,
          "content": "# to build this docker image:\n#   docker build -f Dockerfile.opencv-gpu-cuda-11 -t ghcr.io/hybridgroup/opencv:4.10.0-gpu-cuda-11 .\n#   docker build --build-arg OPENCV_VERSION=\"4.x\" --build-arg OPENCV_FILE=\"https://github.com/opencv/opencv/archive/refs/heads/4.x.zip\" --build-arg OPENCV_CONTRIB_FILE=\"https://github.com/opencv/opencv_contrib/archive/refs/heads/4.x.zip\" -f Dockerfile.opencv-gpu-cuda-11.2.2 -t ghcr.io/hybridgroup/opencv:4.10.0-dev-gpu-cuda-11 .\nFROM nvidia/cuda:11.8.0-cudnn8-devel-ubuntu20.04 AS opencv-gpu-cuda-11-base\nLABEL maintainer=\"hybridgroup\"\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    git build-essential cmake pkg-config unzip libgtk2.0-dev \\\n    wget curl ca-certificates libcurl4-openssl-dev libssl-dev \\\n    libavcodec-dev libavformat-dev libswscale-dev libtbb2 libtbb-dev \\\n    libharfbuzz-dev libfreetype6-dev \\\n    libjpeg-turbo8-dev libpng-dev libtiff-dev libdc1394-22-dev nasm && \\\n    rm -rf /var/lib/apt/lists/*\n\nARG OPENCV_VERSION=\"4.10.0\"\nENV OPENCV_VERSION $OPENCV_VERSION\n\nARG OPENCV_FILE=\"https://github.com/opencv/opencv/archive/${OPENCV_VERSION}.zip\"\nENV OPENCV_FILE $OPENCV_FILE\n\nARG OPENCV_CONTRIB_FILE=\"https://github.com/opencv/opencv_contrib/archive/${OPENCV_VERSION}.zip\"\nENV OPENCV_CONTRIB_FILE $OPENCV_CONTRIB_FILE\n\nRUN curl -Lo opencv.zip ${OPENCV_FILE} && \\\n    unzip -q opencv.zip && \\\n    curl -Lo opencv_contrib.zip ${OPENCV_CONTRIB_FILE} && \\\n    unzip -q opencv_contrib.zip && \\\n    rm opencv.zip opencv_contrib.zip && \\\n    cd opencv-${OPENCV_VERSION} && \\\n    mkdir build && cd build && \\\n    cmake -D CMAKE_BUILD_TYPE=RELEASE \\\n    -D WITH_IPP=OFF \\\n    -D WITH_OPENGL=OFF \\\n    -D WITH_QT=OFF \\\n    -D WITH_FREETYPE=ON \\\n    -D CMAKE_INSTALL_PREFIX=/usr/local \\\n    -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib-${OPENCV_VERSION}/modules \\\n    -D OPENCV_ENABLE_NONFREE=ON \\\n    -D WITH_JASPER=OFF \\\n    -D BUILD_DOCS=OFF \\\n    -D BUILD_EXAMPLES=OFF \\\n    -D BUILD_TESTS=OFF \\\n    -D BUILD_PERF_TESTS=ON \\\n    -D BUILD_opencv_java=NO \\\n    -D BUILD_opencv_python=NO \\\n    -D BUILD_opencv_python2=NO \\\n    -D BUILD_opencv_python3=NO \\\n    -D WITH_TBB=ON \\\n    -D BUILD_JPEG=ON \\\n    -D WITH_SIMD=ON \\\n    -D WITH_LIBJPEG_TURBO_SIMD=ON \\\n    -D WITH_CUDA=ON \\\n    -D ENABLE_FAST_MATH=1 \\\n    -D CUDA_FAST_MATH=1 \\\n    -D WITH_CUBLAS=1 \\\n    -D CUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda/ \\\n    -D BUILD_opencv_cudacodec=OFF \\\n    -D WITH_CUDNN=ON \\\n    -D OPENCV_DNN_CUDA=ON \\\n    -D CUDA_ARCH_BIN=6.0,6.1,7.0,7.5,8.0,8.6 \\\n    -D OPENCV_GENERATE_PKGCONFIG=ON .. && \\\n    make -j $(nproc --all) && \\\n    make preinstall && make install && ldconfig && \\\n    cd / && rm -rf opencv*\n\n# install golang here\nFROM opencv-gpu-cuda-11-base AS opencv-gpu-cuda-11-golang\n\nENV GO_RELEASE=1.23.1\nRUN wget https://dl.google.com/go/go${GO_RELEASE}.linux-amd64.tar.gz && \\\n    tar xfv go${GO_RELEASE}.linux-amd64.tar.gz -C /usr/local && \\\n    rm go${GO_RELEASE}.linux-amd64.tar.gz\nENV PATH=\"${PATH}:/usr/local/go/bin\"\n\nCMD [\"go version\"]\n"
        },
        {
          "name": "Dockerfile.opencv-gpu-cuda-11.2.2",
          "type": "blob",
          "size": 2.982421875,
          "content": "# to build this docker image:\n#   docker build -f Dockerfile.opencv-gpu-cuda-11 -t ghcr.io/hybridgroup/opencv:4.10.0-gpu-cuda-11.2.2 .\n#   docker build --build-arg OPENCV_VERSION=\"4.x\" --build-arg OPENCV_FILE=\"https://github.com/opencv/opencv/archive/refs/heads/4.x.zip\" --build-arg OPENCV_CONTRIB_FILE=\"https://github.com/opencv/opencv_contrib/archive/refs/heads/4.x.zip\" -f Dockerfile.opencv-gpu-cuda-11.2.2 -t ghcr.io/hybridgroup/opencv:4.10.0-dev-gpu-cuda-11.2.2 .\nFROM nvidia/cuda:11.2.2-cudnn8-devel-ubuntu20.04 AS opencv-gpu-cuda-11-base\nLABEL maintainer=\"hybridgroup\"\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    git build-essential cmake pkg-config unzip libgtk2.0-dev \\\n    wget curl ca-certificates libcurl4-openssl-dev libssl-dev \\\n    libavcodec-dev libavformat-dev libswscale-dev libtbb2 libtbb-dev \\\n    libharfbuzz-dev libfreetype6-dev \\\n    libjpeg-turbo8-dev libpng-dev libtiff-dev libdc1394-22-dev nasm && \\\n    rm -rf /var/lib/apt/lists/*\n\nARG OPENCV_VERSION=\"4.10.0\"\nENV OPENCV_VERSION $OPENCV_VERSION\n\nARG OPENCV_FILE=\"https://github.com/opencv/opencv/archive/${OPENCV_VERSION}.zip\"\nENV OPENCV_FILE $OPENCV_FILE\n\nARG OPENCV_CONTRIB_FILE=\"https://github.com/opencv/opencv_contrib/archive/${OPENCV_VERSION}.zip\"\nENV OPENCV_CONTRIB_FILE $OPENCV_CONTRIB_FILE\n\nRUN curl -Lo opencv.zip ${OPENCV_FILE} && \\\n    unzip -q opencv.zip && \\\n    curl -Lo opencv_contrib.zip ${OPENCV_CONTRIB_FILE} && \\\n    unzip -q opencv_contrib.zip && \\\n    rm opencv.zip opencv_contrib.zip && \\\n    cd opencv-${OPENCV_VERSION} && \\\n    mkdir build && cd build && \\\n    cmake -D CMAKE_BUILD_TYPE=RELEASE \\\n    -D WITH_IPP=OFF \\\n    -D WITH_OPENGL=OFF \\\n    -D WITH_QT=OFF \\\n    -D WITH_FREETYPE=ON \\\n    -D CMAKE_INSTALL_PREFIX=/usr/local \\\n    -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib-${OPENCV_VERSION}/modules \\\n    -D OPENCV_ENABLE_NONFREE=ON \\\n    -D WITH_JASPER=OFF \\\n    -D BUILD_DOCS=OFF \\\n    -D BUILD_EXAMPLES=OFF \\\n    -D BUILD_TESTS=OFF \\\n    -D BUILD_PERF_TESTS=ON \\\n    -D BUILD_opencv_java=NO \\\n    -D BUILD_opencv_python=NO \\\n    -D BUILD_opencv_python2=NO \\\n    -D BUILD_opencv_python3=NO \\\n    -D WITH_TBB=ON \\\n    -D BUILD_JPEG=ON \\\n    -D WITH_SIMD=ON \\\n    -D WITH_LIBJPEG_TURBO_SIMD=ON \\\n    -D WITH_CUDA=ON \\\n    -D ENABLE_FAST_MATH=1 \\\n    -D CUDA_FAST_MATH=1 \\\n    -D WITH_CUBLAS=1 \\\n    -D CUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda/ \\\n    -D BUILD_opencv_cudacodec=OFF \\\n    -D WITH_CUDNN=ON \\\n    -D OPENCV_DNN_CUDA=ON \\\n    -D CUDA_ARCH_BIN=6.0,6.1,7.0,7.5,8.0,8.6 \\\n    -D OPENCV_GENERATE_PKGCONFIG=ON .. && \\\n    make -j $(nproc --all) && \\\n    make preinstall && make install && ldconfig && \\\n    cd / && rm -rf opencv*\n\n# install golang here\nFROM opencv-gpu-cuda-11-base AS opencv-gpu-cuda-11-golang\n\nENV GO_RELEASE=1.23.1\nRUN wget https://dl.google.com/go/go${GO_RELEASE}.linux-amd64.tar.gz && \\\n    tar xfv go${GO_RELEASE}.linux-amd64.tar.gz -C /usr/local && \\\n    rm go${GO_RELEASE}.linux-amd64.tar.gz\nENV PATH=\"${PATH}:/usr/local/go/bin\"\n\nCMD [\"go version\"]\n"
        },
        {
          "name": "Dockerfile.opencv-gpu-cuda-12",
          "type": "blob",
          "size": 2.974609375,
          "content": "# to build this docker image:\n#   docker build -f Dockerfile.opencv-gpu-cuda-12 -t ghcr.io/hybridgroup/opencv:4.10.0-gpu-cuda-12 .\n#   docker build --build-arg OPENCV_VERSION=\"4.x\" --build-arg OPENCV_FILE=\"https://github.com/opencv/opencv/archive/refs/heads/4.x.zip\" --build-arg OPENCV_CONTRIB_FILE=\"https://github.com/opencv/opencv_contrib/archive/refs/heads/4.x.zip\" -f Dockerfile.opencv-gpu-cuda-12 -t ghcr.io/hybridgroup/opencv:4.10.0-dev-gpu-cuda-12 .\nFROM nvidia/cuda:12.6.1-cudnn-devel-ubuntu22.04 AS opencv-gpu-cuda-12-base\nLABEL maintainer=\"hybridgroup\"\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    git build-essential cmake pkg-config unzip libgtk2.0-dev \\\n    wget curl ca-certificates libcurl4-openssl-dev libssl-dev \\\n    libavcodec-dev libavformat-dev libswscale-dev libtbb2 libtbb-dev \\\n    libharfbuzz-dev libfreetype6-dev \\\n    libjpeg-turbo8-dev libpng-dev libtiff-dev libdc1394-dev nasm && \\\n    rm -rf /var/lib/apt/lists/*\n\nARG OPENCV_VERSION=\"4.10.0\"\nENV OPENCV_VERSION $OPENCV_VERSION\n\nARG OPENCV_FILE=\"https://github.com/opencv/opencv/archive/${OPENCV_VERSION}.zip\"\nENV OPENCV_FILE $OPENCV_FILE\n\nARG OPENCV_CONTRIB_FILE=\"https://github.com/opencv/opencv_contrib/archive/${OPENCV_VERSION}.zip\"\nENV OPENCV_CONTRIB_FILE $OPENCV_CONTRIB_FILE\n\nRUN curl -Lo opencv.zip ${OPENCV_FILE} && \\\n    unzip -q opencv.zip && \\\n    curl -Lo opencv_contrib.zip ${OPENCV_CONTRIB_FILE} && \\\n    unzip -q opencv_contrib.zip && \\\n    rm opencv.zip opencv_contrib.zip && \\\n    cd opencv-${OPENCV_VERSION} && \\\n    mkdir build && cd build && \\\n    cmake -D CMAKE_BUILD_TYPE=RELEASE \\\n    -D WITH_IPP=OFF \\\n    -D WITH_OPENGL=OFF \\\n    -D WITH_QT=OFF \\\n    -D WITH_FREETYPE=ON \\\n    -D CMAKE_INSTALL_PREFIX=/usr/local \\\n    -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib-${OPENCV_VERSION}/modules \\\n    -D OPENCV_ENABLE_NONFREE=ON \\\n    -D WITH_JASPER=OFF \\\n    -D BUILD_DOCS=OFF \\\n    -D BUILD_EXAMPLES=OFF \\\n    -D BUILD_TESTS=OFF \\\n    -D BUILD_PERF_TESTS=ON \\\n    -D BUILD_opencv_java=NO \\\n    -D BUILD_opencv_python=NO \\\n    -D BUILD_opencv_python2=NO \\\n    -D BUILD_opencv_python3=NO \\\n    -D WITH_TBB=ON \\\n    -D BUILD_JPEG=ON \\\n    -D WITH_SIMD=ON \\\n    -D WITH_LIBJPEG_TURBO_SIMD=ON \\\n    -D WITH_CUDA=ON \\\n    -D ENABLE_FAST_MATH=1 \\\n    -D CUDA_FAST_MATH=1 \\\n    -D WITH_CUBLAS=1 \\\n    -D CUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda/ \\\n    -D BUILD_opencv_cudacodec=OFF \\\n    -D WITH_CUDNN=ON \\\n    -D OPENCV_DNN_CUDA=ON \\\n    -D CUDA_ARCH_BIN=6.0,6.1,7.0,7.5,8.0,8.6,8.9,9.0 \\\n    -D OPENCV_GENERATE_PKGCONFIG=ON .. && \\\n    make -j $(nproc --all) && \\\n    make preinstall && make install && ldconfig && \\\n    cd / && rm -rf opencv*\n\n# install golang here\nFROM opencv-gpu-cuda-12-base AS opencv-gpu-cuda-12-golang\n\nENV GO_RELEASE=1.23.1\nRUN wget https://dl.google.com/go/go${GO_RELEASE}.linux-amd64.tar.gz && \\\n    tar xfv go${GO_RELEASE}.linux-amd64.tar.gz -C /usr/local && \\\n    rm go${GO_RELEASE}.linux-amd64.tar.gz\nENV PATH=\"${PATH}:/usr/local/go/bin\"\n\nCMD [\"go version\"]\n"
        },
        {
          "name": "Dockerfile.opencv-openvino",
          "type": "blob",
          "size": 2.11328125,
          "content": "# to build this docker image:\n#   docker build -f Dockerfile.opencv-openvino -t ghcr.io/hybridgroup/opencv:4.10.0-openvino\nFROM openvino/ubuntu20_dev:2022.1.0 AS opencv-openvino-base\nLABEL maintainer=\"hybridgroup\"\nENV DEBIAN_FRONTEND=noninteractive\nUSER root\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    git build-essential cmake pkg-config unzip libgtk2.0-dev \\\n    wget curl ca-certificates libcurl4-openssl-dev libssl-dev \\\n    libavcodec-dev libavformat-dev libswscale-dev libtbb2 libtbb-dev \\\n    libjpeg-dev libpng-dev libtiff-dev libdc1394-22-dev && \\\n    rm -rf /var/lib/apt/lists/*\n\nARG OPENCV_VERSION=\"4.10.0\"\nENV OPENCV_VERSION $OPENCV_VERSION\n\nRUN curl -Lo opencv.zip https://github.com/opencv/opencv/archive/${OPENCV_VERSION}.zip && \\\n    unzip -q opencv.zip && \\\n    curl -Lo opencv_contrib.zip https://github.com/opencv/opencv_contrib/archive/${OPENCV_VERSION}.zip && \\\n    unzip -q opencv_contrib.zip && \\\n    rm opencv.zip opencv_contrib.zip && \\\n    cd opencv-${OPENCV_VERSION} && \\\n    mkdir build && cd build && \\\n    cmake -D CMAKE_BUILD_TYPE=RELEASE \\\n    -D WITH_IPP=OFF \\\n    -D WITH_OPENGL=OFF \\\n    -D WITH_QT=OFF \\\n    -D CMAKE_INSTALL_PREFIX=/usr/local \\\n    -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib-${OPENCV_VERSION}/modules \\\n    -D OPENCV_ENABLE_NONFREE=ON \\\n    -D WITH_JASPER=OFF \\\n    -D BUILD_DOCS=OFF \\\n    -D BUILD_EXAMPLES=OFF \\\n    -D BUILD_TESTS=OFF \\\n    -D BUILD_PERF_TESTS=ON \\\n    -D BUILD_opencv_java=NO \\\n    -D BUILD_opencv_python=NO \\\n    -D BUILD_opencv_python2=NO \\\n    -D BUILD_opencv_python3=NO \\\n    -D WITH_TBB=ON \\\n    -D WITH_OPENVINO=1 \\\n    -D ENABLE_FAST_MATH=1 \\\n    -D OPENCV_GENERATE_PKGCONFIG=ON .. && \\\n    make -j $(nproc --all) && \\\n    make preinstall && make install && ldconfig && \\\n    cd / && rm -rf opencv*\n\n# install golang here\nFROM opencv-openvino-base AS opencv-openvino-golang\n\nENV GO_RELEASE=1.23.1\nRUN wget https://dl.google.com/go/go${GO_RELEASE}.linux-amd64.tar.gz && \\\n    tar xfv go${GO_RELEASE}.linux-amd64.tar.gz -C /usr/local && \\\n    rm go${GO_RELEASE}.linux-amd64.tar.gz\nENV PATH=\"${PATH}:/usr/local/go/bin\"\nUSER openvino\nCMD [\"go version\"]\n"
        },
        {
          "name": "Dockerfile.opencv-static",
          "type": "blob",
          "size": 6.6748046875,
          "content": "# OpenCV 4 prebuilt multiarchitecture image\n#\n# To build release:\n#   docker buildx build -f Dockerfile.opencv-static -t ghcr.io/hybridgroup/opencv:4.10.0-static --platform=linux/arm64,linux/amd64 --push .\n#\n# To build prerelease:\n#   docker buildx build --build-arg OPENCV_VERSION=\"4.x\" --build-arg OPENCV_FILE=\"https://github.com/opencv/opencv/archive/refs/heads/4.x.zip\" --build-arg OPENCV_CONTRIB_FILE=\"https://github.com/opencv/opencv_contrib/archive/refs/heads/4.x.zip\" -f Dockerfile.opencv-static -t ghcr.io/hybridgroup/opencv:4.10.0-static-dev --platform=linux/arm64,linux/amd64 --push .\n\n\n###################\n# amd64 build stage\n###################\n\nFROM --platform=linux/amd64 golang:1.22-bullseye AS opencv-base-amd64\nLABEL maintainer=\"hybridgroup\"\nRUN apt-get update && apt-get -y install \\\n      autoconf automake libass-dev libgnutls28-dev \\\n      libmp3lame-dev libtool libvorbis-dev \\\n      meson ninja-build pkg-config \\\n      texinfo wget yasm \\\n      zlib1g-dev libx264-dev libvpx-dev \\\n      libopus-dev libdav1d-dev \\\n      git build-essential cmake pkg-config unzip \\\n      curl ca-certificates libcurl4-openssl-dev libssl-dev \\\n      libharfbuzz-dev libfreetype6-dev \\\n      nasm && \\\n      rm -rf /var/lib/apt/lists/*\n\nRUN wget -O ffmpeg-5.0.tar.bz2 \"https://www.ffmpeg.org/releases/ffmpeg-5.0.3.tar.bz2\" && \\\n      tar -xf ffmpeg-5.0.tar.bz2\n\nRUN cd ffmpeg-5.0.3 && \\\n      ./configure --pkg-config-flags=\"--static\" \\\n      --enable-static --disable-shared --enable-gpl --enable-libx264 --enable-libvpx --enable-zlib \\\n      --disable-sdl2 --disable-vaapi --disable-vdpau --disable-v4l2-m2m --disable-doc && \\\n      make -j $(nproc --all) && make install && ldconfig\n\nFROM --platform=linux/amd64 opencv-base-amd64 AS opencv-build-amd64\n\nARG OPENCV_VERSION=\"4.10.0\"\nENV OPENCV_VERSION $OPENCV_VERSION\n\nARG OPENCV_FILE=\"https://github.com/opencv/opencv/archive/${OPENCV_VERSION}.zip\"\nENV OPENCV_FILE $OPENCV_FILE\n\nARG OPENCV_CONTRIB_FILE=\"https://github.com/opencv/opencv_contrib/archive/${OPENCV_VERSION}.zip\"\nENV OPENCV_CONTRIB_FILE $OPENCV_CONTRIB_FILE\n\nRUN curl -Lo opencv.zip ${OPENCV_FILE} && \\\n      unzip -q opencv.zip && \\\n      curl -Lo opencv_contrib.zip ${OPENCV_CONTRIB_FILE} && \\\n      unzip -q opencv_contrib.zip && \\\n      rm opencv.zip opencv_contrib.zip\n\nRUN cd opencv-${OPENCV_VERSION} && \\\n      mkdir build && cd build && \\\n      cmake -D CMAKE_BUILD_TYPE=RELEASE \\\n      -D WITH_IPP=ON \\\n      -D BUILD_WITH_DYNAMIC_IPP=OFF \\\n      -D BUILD_IPP_IW=ON \\\n      -D WITH_OPENGL=ON \\\n      -D BUILD_OPENGL=ON \\\n      -D WITH_QT=OFF \\\n      -D WITH_FREETYPE=ON \\\n      -D CMAKE_INSTALL_PREFIX=/usr/local \\\n      -D BUILD_SHARED_LIBS=OFF \\\n      -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib-${OPENCV_VERSION}/modules \\\n      -D OPENCV_ENABLE_NONFREE=ON \\\n      -D WITH_JASPER=OFF \\\n      -D WITH_TBB=ON \\\n      -D BUILD_TBB=ON \\\n      -D BUILD_JPEG=ON \\\n      -D WITH_SIMD=ON \\\n      -D ENABLE_LIBJPEG_TURBO_SIMD=OFF \\\n      -D WITH_QUIRC=ON \\\n      -D WITH_GTK=OFF \\\n      -D WITH_FFMPEG=ON \\\n      -D WITH_1394=ON \\\n      -D BUILD_1394=ON \\\n      -D WITH_WEBP=ON \\\n      -D BUILD_WEBP=ON \\\n      -D WITH_OPENJPEG=ON \\\n      -D BUILD_OPENJPEG=ON \\\n      -D WITH_TIFF=ON \\\n      -D BUILD_TIFF=ON \\\n      -D BUILD_DOCS=OFF \\\n      -D BUILD_EXAMPLES=OFF \\\n      -D BUILD_TESTS=OFF \\\n      -D BUILD_PERF_TESTS=ON \\\n      -D BUILD_opencv_java=NO \\\n      -D BUILD_opencv_python=NO \\\n      -D BUILD_opencv_python2=NO \\\n      -D BUILD_opencv_python3=NO \\\n      -D OPENCV_GENERATE_PKGCONFIG=ON .. && \\\n      make -j $(nproc --all) && \\\n      make preinstall && make install && ldconfig && \\\n      cd / && rm -rf opencv*\n\n###################\n# arm64 build stage\n###################\n\nFROM --platform=linux/arm64 golang:1.22-bullseye AS opencv-base-arm64\nLABEL maintainer=\"hybridgroup\"\nRUN apt-get update && apt-get -y install \\\n      autoconf automake libass-dev libgnutls28-dev \\\n      libmp3lame-dev libtool libvorbis-dev \\\n      meson ninja-build pkg-config \\\n      texinfo wget yasm \\\n      zlib1g-dev libx264-dev libvpx-dev \\\n      libopus-dev libdav1d-dev \\\n      git build-essential cmake pkg-config unzip \\\n      curl ca-certificates libcurl4-openssl-dev libssl-dev \\\n      libharfbuzz-dev libfreetype6-dev \\\n      nasm && \\\n      rm -rf /var/lib/apt/lists/*\n\nRUN wget -O ffmpeg-5.0.tar.bz2 \"https://www.ffmpeg.org/releases/ffmpeg-5.0.3.tar.bz2\" && \\\n      tar -xf ffmpeg-5.0.tar.bz2\n\nRUN cd ffmpeg-5.0.3 && \\\n      ./configure --pkg-config-flags=\"--static\" \\\n      --enable-static --disable-shared --enable-gpl --enable-libx264 --enable-libvpx --enable-zlib \\\n      --disable-sdl2 --disable-vaapi --disable-vdpau --disable-v4l2-m2m --disable-doc && \\\n      make -j $(nproc --all) && make install && ldconfig\n\nFROM --platform=linux/arm64 opencv-base-arm64 AS opencv-build-arm64\n\nARG OPENCV_VERSION=\"4.10.0\"\nENV OPENCV_VERSION $OPENCV_VERSION\n\nARG OPENCV_FILE=\"https://github.com/opencv/opencv/archive/${OPENCV_VERSION}.zip\"\nENV OPENCV_FILE $OPENCV_FILE\n\nARG OPENCV_CONTRIB_FILE=\"https://github.com/opencv/opencv_contrib/archive/${OPENCV_VERSION}.zip\"\nENV OPENCV_CONTRIB_FILE $OPENCV_CONTRIB_FILE\n\nRUN curl -Lo opencv.zip ${OPENCV_FILE} && \\\n      unzip -q opencv.zip && \\\n      curl -Lo opencv_contrib.zip ${OPENCV_CONTRIB_FILE} && \\\n      unzip -q opencv_contrib.zip && \\\n      rm opencv.zip opencv_contrib.zip\n\nRUN cd opencv-${OPENCV_VERSION} && \\\n      mkdir build && cd build && \\\n      cmake -D CMAKE_BUILD_TYPE=RELEASE \\\n      -D WITH_IPP=OFF \\\n      -D WITH_OPENGL=ON \\\n      -D BUILD_OPENGL=ON \\\n      -D WITH_QT=OFF \\\n      -D WITH_FREETYPE=ON \\\n      -D CMAKE_INSTALL_PREFIX=/usr/local \\\n      -D BUILD_SHARED_LIBS=OFF \\\n      -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib-${OPENCV_VERSION}/modules \\\n      -D OPENCV_ENABLE_NONFREE=ON \\\n      -D WITH_JASPER=OFF \\\n      -D ENABLE_NEON=ON \\\n      -D WITH_TBB=ON \\\n      -D BUILD_TBB=ON \\\n      -D BUILD_JPEG=ON \\\n      -D WITH_SIMD=ON \\\n      -D ENABLE_LIBJPEG_TURBO_SIMD=OFF \\\n      -D WITH_QUIRC=ON \\\n      -D WITH_GTK=OFF \\\n      -D WITH_FFMPEG=ON \\\n      -D WITH_1394=ON \\\n      -D BUILD_1394=ON \\\n      -D WITH_WEBP=ON \\\n      -D BUILD_WEBP=ON \\\n      -D WITH_OPENJPEG=ON \\\n      -D BUILD_OPENJPEG=ON \\\n      -D WITH_TIFF=ON \\\n      -D BUILD_TIFF=ON \\\n      -D BUILD_DOCS=OFF \\\n      -D BUILD_EXAMPLES=OFF \\\n      -D BUILD_TESTS=OFF \\\n      -D BUILD_PERF_TESTS=ON \\\n      -D BUILD_opencv_java=NO \\\n      -D BUILD_opencv_python=NO \\\n      -D BUILD_opencv_python2=NO \\\n      -D BUILD_opencv_python3=NO \\\n      -D OPENCV_GENERATE_PKGCONFIG=ON .. && \\\n      make -j $(nproc --all) && \\\n      make preinstall && make install && ldconfig && \\\n      cd / && rm -rf opencv*\n\nARG TARGETARCH\n\n###################\n# multiarch build stage\n###################\n\nFROM opencv-build-${TARGETARCH} AS opencv-final\n\nCMD [\"opencv_version\", \"-b\"]\n"
        },
        {
          "name": "Dockerfile.opencv-ubuntu-18.04",
          "type": "blob",
          "size": 2.392578125,
          "content": "# to build this docker image:\n#   docker build -f Dockerfile.opencv-ubuntu-18.04 -t ghcr.io/hybridgroup/opencv:4.10.0-ubuntu-18.04 .\n#   docker build --build-arg OPENCV_VERSION=\"4.x\" --build-arg OPENCV_FILE=\"https://github.com/opencv/opencv/archive/refs/heads/4.x.zip\" --build-arg OPENCV_CONTRIB_FILE=\"https://github.com/opencv/opencv_contrib/archive/refs/heads/4.x.zip\" -f Dockerfile.opencv-ubuntu-18.04 -t ghcr.io/hybridgroup/opencv:4.10.0-dev-ubuntu-18.04 .\nFROM ubuntu:18.04 AS opencv-base\nLABEL maintainer=\"hybridgroup\"\n\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n      git build-essential cmake pkg-config wget unzip libgtk2.0-dev \\\n      curl ca-certificates libcurl4-openssl-dev libssl-dev \\\n      libavcodec-dev libavformat-dev libswscale-dev libtbb2 libtbb-dev \\\n      libharfbuzz-dev libfreetype6-dev \\\n      libjpeg-turbo8-dev libpng-dev libtiff-dev libdc1394-22-dev nasm && \\\n      rm -rf /var/lib/apt/lists/*\n\nARG OPENCV_VERSION=\"4.10.0\"\nENV OPENCV_VERSION $OPENCV_VERSION\n\nARG OPENCV_FILE=\"https://github.com/opencv/opencv/archive/${OPENCV_VERSION}.zip\"\nENV OPENCV_FILE $OPENCV_FILE\n\nARG OPENCV_CONTRIB_FILE=\"https://github.com/opencv/opencv_contrib/archive/${OPENCV_VERSION}.zip\"\nENV OPENCV_CONTRIB_FILE $OPENCV_CONTRIB_FILE\n\nRUN curl -Lo opencv.zip ${OPENCV_FILE} && \\\n      unzip -q opencv.zip && \\\n      curl -Lo opencv_contrib.zip ${OPENCV_CONTRIB_FILE} && \\\n      unzip -q opencv_contrib.zip && \\\n      rm opencv.zip opencv_contrib.zip && \\\n      cd opencv-${OPENCV_VERSION} && \\\n      mkdir build && cd build && \\\n      cmake -D CMAKE_BUILD_TYPE=RELEASE \\\n      -D WITH_IPP=OFF \\\n      -D WITH_OPENGL=OFF \\\n      -D WITH_QT=OFF \\\n      -D WITH_FREETYPE=ON \\\n      -D CMAKE_INSTALL_PREFIX=/usr/local \\\n      -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib-${OPENCV_VERSION}/modules \\\n      -D OPENCV_ENABLE_NONFREE=ON \\\n      -D WITH_JASPER=OFF \\\n      -D WITH_TBB=ON \\\n      -D BUILD_JPEG=ON \\\n      -D WITH_SIMD=ON \\\n      -D ENABLE_LIBJPEG_TURBO_SIMD=ON \\\n      -D BUILD_DOCS=OFF \\\n      -D BUILD_EXAMPLES=OFF \\\n      -D BUILD_TESTS=OFF \\\n      -D BUILD_PERF_TESTS=ON \\\n      -D BUILD_opencv_java=NO \\\n      -D BUILD_opencv_python=NO \\\n      -D BUILD_opencv_python2=NO \\\n      -D BUILD_opencv_python3=NO \\\n      -D OPENCV_GENERATE_PKGCONFIG=ON .. && \\\n      make -j $(nproc --all) && \\\n      make preinstall && make install && ldconfig && \\\n      cd / && rm -rf opencv*\n\nCMD [\"opencv_version\", \"-b\"]\n"
        },
        {
          "name": "Dockerfile.opencv-ubuntu-20.04",
          "type": "blob",
          "size": 2.498046875,
          "content": "# to build this docker image:\n#   docker build -f Dockerfile.opencv-ubuntu-20.04 -t ghcr.io/hybridgroup/opencv:4.10.0-ubuntu-20.04 .\n#   docker build --build-arg OPENCV_VERSION=\"4.x\" --build-arg OPENCV_FILE=\"https://github.com/opencv/opencv/archive/refs/heads/4.x.zip\" --build-arg OPENCV_CONTRIB_FILE=\"https://github.com/opencv/opencv_contrib/archive/refs/heads/4.x.zip\" -f Dockerfile.opencv-ubuntu-20.04 -t ghcr.io/hybridgroup/opencv:4.10.0-dev-ubuntu-20.04 .\nFROM ubuntu:20.04 AS opencv-base\nLABEL maintainer=\"hybridgroup\"\n\nENV TZ=Europe/Madrid\nRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone\n\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n      tzdata git build-essential cmake pkg-config wget unzip libgtk2.0-dev \\\n      curl ca-certificates libcurl4-openssl-dev libssl-dev \\\n      libavcodec-dev libavformat-dev libswscale-dev libtbb2 libtbb-dev \\\n      libharfbuzz-dev libfreetype6-dev \\\n      libjpeg-turbo8-dev libpng-dev libtiff-dev libdc1394-22-dev nasm && \\\n      rm -rf /var/lib/apt/lists/*\n\nARG OPENCV_VERSION=\"4.10.0\"\nENV OPENCV_VERSION $OPENCV_VERSION\n\nARG OPENCV_FILE=\"https://github.com/opencv/opencv/archive/${OPENCV_VERSION}.zip\"\nENV OPENCV_FILE $OPENCV_FILE\n\nARG OPENCV_CONTRIB_FILE=\"https://github.com/opencv/opencv_contrib/archive/${OPENCV_VERSION}.zip\"\nENV OPENCV_CONTRIB_FILE $OPENCV_CONTRIB_FILE\n\nRUN curl -Lo opencv.zip ${OPENCV_FILE} && \\\n      unzip -q opencv.zip && \\\n      curl -Lo opencv_contrib.zip ${OPENCV_CONTRIB_FILE} && \\\n      unzip -q opencv_contrib.zip && \\\n      rm opencv.zip opencv_contrib.zip && \\\n      cd opencv-${OPENCV_VERSION} && \\\n      mkdir build && cd build && \\\n      cmake -D CMAKE_BUILD_TYPE=RELEASE \\\n      -D WITH_IPP=OFF \\\n      -D WITH_OPENGL=OFF \\\n      -D WITH_QT=OFF \\\n      -D WITH_FREETYPE=ON \\\n      -D CMAKE_INSTALL_PREFIX=/usr/local \\\n      -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib-${OPENCV_VERSION}/modules \\\n      -D OPENCV_ENABLE_NONFREE=ON \\\n      -D WITH_JASPER=OFF \\\n      -D WITH_TBB=ON \\\n      -D BUILD_JPEG=ON \\\n      -D WITH_SIMD=ON \\\n      -D ENABLE_LIBJPEG_TURBO_SIMD=ON \\\n      -D BUILD_DOCS=OFF \\\n      -D BUILD_EXAMPLES=OFF \\\n      -D BUILD_TESTS=OFF \\\n      -D BUILD_PERF_TESTS=ON \\\n      -D BUILD_opencv_java=NO \\\n      -D BUILD_opencv_python=NO \\\n      -D BUILD_opencv_python2=NO \\\n      -D BUILD_opencv_python3=NO \\\n      -D OPENCV_GENERATE_PKGCONFIG=ON .. && \\\n      make -j $(nproc --all) && \\\n      make preinstall && make install && ldconfig && \\\n      cd / && rm -rf opencv*\n\nCMD [\"opencv_version\", \"-b\"]\n"
        },
        {
          "name": "Dockerfile.opencv-ubuntu-22.04",
          "type": "blob",
          "size": 2.4951171875,
          "content": "# to build this docker image:\n#   docker build -f Dockerfile.opencv-ubuntu-22.04 -t ghcr.io/hybridgroup/opencv:4.10.0-ubuntu-22.04 .\n#   docker build --build-arg OPENCV_VERSION=\"4.x\" --build-arg OPENCV_FILE=\"https://github.com/opencv/opencv/archive/refs/heads/4.x.zip\" --build-arg OPENCV_CONTRIB_FILE=\"https://github.com/opencv/opencv_contrib/archive/refs/heads/4.x.zip\" -f Dockerfile.opencv-ubuntu-20.04 -t ghcr.io/hybridgroup/opencv:4.10.0-dev-ubuntu-20.04 .\nFROM ubuntu:22.04 AS opencv-base\nLABEL maintainer=\"hybridgroup\"\n\nENV TZ=Europe/Madrid\nRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone\n\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n      tzdata git build-essential cmake pkg-config wget unzip libgtk2.0-dev \\\n      curl ca-certificates libcurl4-openssl-dev libssl-dev \\\n      libavcodec-dev libavformat-dev libswscale-dev libtbb2 libtbb-dev \\\n      libharfbuzz-dev libfreetype6-dev \\\n      libjpeg-turbo8-dev libpng-dev libtiff-dev libdc1394-dev nasm && \\\n      rm -rf /var/lib/apt/lists/*\n\nARG OPENCV_VERSION=\"4.10.0\"\nENV OPENCV_VERSION $OPENCV_VERSION\n\nARG OPENCV_FILE=\"https://github.com/opencv/opencv/archive/${OPENCV_VERSION}.zip\"\nENV OPENCV_FILE $OPENCV_FILE\n\nARG OPENCV_CONTRIB_FILE=\"https://github.com/opencv/opencv_contrib/archive/${OPENCV_VERSION}.zip\"\nENV OPENCV_CONTRIB_FILE $OPENCV_CONTRIB_FILE\n\nRUN curl -Lo opencv.zip ${OPENCV_FILE} && \\\n      unzip -q opencv.zip && \\\n      curl -Lo opencv_contrib.zip ${OPENCV_CONTRIB_FILE} && \\\n      unzip -q opencv_contrib.zip && \\\n      rm opencv.zip opencv_contrib.zip && \\\n      cd opencv-${OPENCV_VERSION} && \\\n      mkdir build && cd build && \\\n      cmake -D CMAKE_BUILD_TYPE=RELEASE \\\n      -D WITH_IPP=OFF \\\n      -D WITH_OPENGL=OFF \\\n      -D WITH_QT=OFF \\\n      -D WITH_FREETYPE=ON \\\n      -D CMAKE_INSTALL_PREFIX=/usr/local \\\n      -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib-${OPENCV_VERSION}/modules \\\n      -D OPENCV_ENABLE_NONFREE=ON \\\n      -D WITH_JASPER=OFF \\\n      -D WITH_TBB=ON \\\n      -D BUILD_JPEG=ON \\\n      -D WITH_SIMD=ON \\\n      -D ENABLE_LIBJPEG_TURBO_SIMD=ON \\\n      -D BUILD_DOCS=OFF \\\n      -D BUILD_EXAMPLES=OFF \\\n      -D BUILD_TESTS=OFF \\\n      -D BUILD_PERF_TESTS=ON \\\n      -D BUILD_opencv_java=NO \\\n      -D BUILD_opencv_python=NO \\\n      -D BUILD_opencv_python2=NO \\\n      -D BUILD_opencv_python3=NO \\\n      -D OPENCV_GENERATE_PKGCONFIG=ON .. && \\\n      make -j $(nproc --all) && \\\n      make preinstall && make install && ldconfig && \\\n      cd / && rm -rf opencv*\n\nCMD [\"opencv_version\", \"-b\"]\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 0.564453125,
          "content": "Copyright (c) 2017-2024 The Hybrid Group and friends\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 15.5830078125,
          "content": ".ONESHELL:\n.PHONY: test deps download build clean astyle cmds docker\n\n# GoCV version to use.\nGOCV_VERSION?=\"v0.39.0\"\n\n# OpenCV version to use.\nOPENCV_VERSION?=4.10.0\n\n# Go version to use when building Docker image\nGOVERSION?=1.22.4\n\n# Temporary directory to put files into.\nTMP_DIR?=/tmp/\n\n# Build shared or static library\nBUILD_SHARED_LIBS?=ON\n\n# Package list for each well-known Linux distribution\nRPMS=cmake curl wget git gtk2-devel libpng-devel libjpeg-devel libtiff-devel tbb tbb-devel libdc1394-devel unzip gcc-c++\nDEBS=unzip wget build-essential cmake curl git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libdc1394-22-dev libharfbuzz-dev libfreetype6-dev\nDEBS_BOOKWORM=unzip wget build-essential cmake curl git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev libtbbmalloc2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libharfbuzz-dev libfreetype6-dev\nDEBS_UBUNTU_JAMMY=unzip wget build-essential cmake curl git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libdc1394-dev libharfbuzz-dev libfreetype6-dev\nJETSON=build-essential cmake git unzip pkg-config libjpeg-dev libpng-dev libtiff-dev libavcodec-dev libavformat-dev libswscale-dev libgtk2.0-dev libcanberra-gtk* libxvidcore-dev libx264-dev libgtk-3-dev libtbb2 libtbb-dev libdc1394-22-dev libv4l-dev v4l-utils libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libavresample-dev libvorbis-dev libxine2-dev libfaac-dev libmp3lame-dev libtheora-dev libopencore-amrnb-dev libopencore-amrwb-dev libopenblas-dev libatlas-base-dev libblas-dev liblapack-dev libeigen3-dev gfortran libhdf5-dev protobuf-compiler libprotobuf-dev libgoogle-glog-dev libgflags-dev\n\nexplain:\n\t@echo \"For quick install with typical defaults of both OpenCV and GoCV, run 'make install'\"\n\n# Detect Linux distribution\ndistro_deps=\nifneq ($(shell which dnf 2>/dev/null),)\n\tdistro_deps=deps_fedora\nelse\nifneq ($(shell which apt-get 2>/dev/null),)\nifneq ($(shell cat /etc/os-release 2>/dev/null | grep \"Jammy Jellyfish\"),)\n\tdistro_deps=deps_ubuntu_jammy\nelse\nifneq ($(shell cat /etc/debian_version 2>/dev/null | grep \"12.\"),)\n\tdistro_deps=deps_debian_bookworm\nelse\n\tdistro_deps=deps_debian\nendif\nendif\nelse\nifneq ($(shell which yum 2>/dev/null),)\n\tdistro_deps=deps_rh_centos\nendif\nendif\nendif\n\n# Install all necessary dependencies.\ndeps: $(distro_deps)\n\ndeps_rh_centos:\n\tsudo yum -y install pkgconfig $(RPMS)\n\ndeps_fedora:\n\tsudo dnf -y install pkgconf-pkg-config $(RPMS)\n\ndeps_debian_bookworm:\n\tsudo apt-get -y update\n\tsudo apt-get -y install $(DEBS_BOOKWORM)\n\ndeps_debian:\n\tsudo apt-get -y update\n\tsudo apt-get -y install $(DEBS)\n\ndeps_ubuntu_jammy:\n\tsudo apt-get -y update\n\tsudo apt-get -y install $(DEBS_UBUNTU_JAMMY)\n\ndeps_jetson:\n\tsudo sh -c \"echo '/usr/local/cuda/lib64' >> /etc/ld.so.conf.d/nvidia-tegra.conf\"\n\tsudo ldconfig\n\tsudo apt-get -y update\n\tsudo apt-get -y install $(JETSON)\n\n# Download OpenCV source tarballs.\ndownload:\n\trm -rf $(TMP_DIR)opencv\n\tmkdir $(TMP_DIR)opencv\n\tcd $(TMP_DIR)opencv\n\tcurl -Lo opencv.zip https://github.com/opencv/opencv/archive/refs/tags/$(OPENCV_VERSION).zip\n\tunzip -q opencv.zip\n\tcurl -Lo opencv_contrib.zip https://github.com/opencv/opencv_contrib/archive/refs/tags/$(OPENCV_VERSION).zip\n\tunzip -q opencv_contrib.zip\n\trm opencv.zip opencv_contrib.zip\n\tcd -\n\n# Download openvino source tarballs.\ndownload_openvino:\n\tsudo rm -rf /usr/local/dldt/\n\tsudo rm -rf /usr/local/openvino/\n\tsudo git clone https://github.com/openvinotoolkit/openvino -b 2019_R3.1 /usr/local/openvino/\n\n# Build openvino.\nbuild_openvino_package:\n\tcd /usr/local/openvino/inference-engine\n\tsudo git submodule init\n\tsudo git submodule update --recursive\n\tsudo ./install_dependencies.sh\n\tsudo mv -f thirdparty/clDNN/common/intel_ocl_icd/6.3/linux/Release thirdparty/clDNN/common/intel_ocl_icd/6.3/linux/RELEASE\n\tsudo mkdir build\n\tcd build\n\tsudo rm -rf *\n\tsudo cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D BUILD_SHARED_LIBS=${BUILD_SHARED_LIBS} -D ENABLE_VPU=ON -D ENABLE_MKL_DNN=ON -D ENABLE_CLDNN=ON ..\n\tsudo $(MAKE) -j $(shell nproc --all --ignore 1)\n\tsudo touch VERSION\n\tsudo mkdir -p src/ngraph\n\tsudo cp thirdparty/ngraph/src/ngraph/version.hpp src/ngraph\n\tcd -\n\n# Build OpenCV.\nbuild:\n\tcd $(TMP_DIR)opencv/opencv-$(OPENCV_VERSION)\n\tmkdir build\n\tcd build\n\trm -rf *\n\tcmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D BUILD_SHARED_LIBS=${BUILD_SHARED_LIBS} -D OPENCV_EXTRA_MODULES_PATH=$(TMP_DIR)opencv/opencv_contrib-$(OPENCV_VERSION)/modules -D BUILD_DOCS=OFF -D BUILD_EXAMPLES=OFF -D BUILD_TESTS=OFF -D BUILD_PERF_TESTS=ON -D BUILD_opencv_java=NO -D BUILD_opencv_python=NO -D BUILD_opencv_python2=NO -D BUILD_opencv_python3=NO -D WITH_JASPER=OFF -D WITH_TBB=ON -DOPENCV_GENERATE_PKGCONFIG=ON ..\n\t$(MAKE) -j $(shell nproc --all --ignore 1)\n\t$(MAKE) preinstall\n\tcd -\n\n# Build OpenCV on Raspbian with ARM hardware optimizations.\nbuild_raspi:\n\tcd $(TMP_DIR)opencv/opencv-$(OPENCV_VERSION)\n\tmkdir build\n\tcd build\n\trm -rf *\nifneq ($(shell uname -m | grep \"aarch64\"),)\n\tcmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D BUILD_SHARED_LIBS=${BUILD_SHARED_LIBS} -D OPENCV_EXTRA_MODULES_PATH=$(TMP_DIR)opencv/opencv_contrib-$(OPENCV_VERSION)/modules -D BUILD_DOCS=OFF -D BUILD_EXAMPLES=OFF -D BUILD_TESTS=OFF -D BUILD_PERF_TESTS=ON -D BUILD_opencv_java=OFF -D BUILD_opencv_python=NO -D BUILD_opencv_python2=NO -D BUILD_opencv_python3=NO -D ENABLE_NEON=ON -D WITH_JASPER=OFF -D WITH_TBB=ON -D OPENCV_GENERATE_PKGCONFIG=ON -D WITH_FREETYPE=ON ..\nelse\n\tcmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D BUILD_SHARED_LIBS=${BUILD_SHARED_LIBS} -D OPENCV_EXTRA_MODULES_PATH=$(TMP_DIR)opencv/opencv_contrib-$(OPENCV_VERSION)/modules -D BUILD_DOCS=OFF -D BUILD_EXAMPLES=OFF -D BUILD_TESTS=OFF -D BUILD_PERF_TESTS=ON -D BUILD_opencv_java=OFF -D BUILD_opencv_python=NO -D BUILD_opencv_python2=NO -D BUILD_opencv_python3=NO -D ENABLE_NEON=ON -D ENABLE_VFPV3=ON -D WITH_JASPER=OFF -D OPENCV_GENERATE_PKGCONFIG=ON -D WITH_FREETYPE=ON ..\nendif\n\t$(MAKE) -j $(shell nproc --all --ignore 1)\n\t$(MAKE) preinstall\n\tcd -\n\n# Build OpenCV on Raspberry pi zero which has ARMv6.\nbuild_raspi_zero:\n\tcd $(TMP_DIR)opencv/opencv-$(OPENCV_VERSION)\n\tmkdir build\n\tcd build\n\trm -rf *\n\tcmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D BUILD_SHARED_LIBS=${BUILD_SHARED_LIBS} -D OPENCV_EXTRA_MODULES_PATH=$(TMP_DIR)opencv/opencv_contrib-$(OPENCV_VERSION)/modules -D BUILD_DOCS=OFF -D BUILD_EXAMPLES=OFF -D BUILD_TESTS=OFF -D BUILD_PERF_TESTS=ON -D BUILD_opencv_java=OFF -D BUILD_opencv_python=NO -D BUILD_opencv_python2=NO -D BUILD_opencv_python3=NO -D ENABLE_VFPV2=ON -D WITH_JASPER=OFF -D OPENCV_GENERATE_PKGCONFIG=ON ..\n\t$(MAKE) -j $(shell nproc --all --ignore 1)\n\t$(MAKE) preinstall\n\tcd -\n\n# Build OpenCV for NVidia Jetson with CUDA.\nbuild_jetson:\n\tcd $(TMP_DIR)opencv/opencv-$(OPENCV_VERSION)\n\tmkdir build\n\tcd build\n\trm -rf *\n\tcmake -D CMAKE_BUILD_TYPE=RELEASE \\\n\t\t-D CMAKE_INSTALL_PREFIX=/usr/local \\\n\t\t-D EIGEN_INCLUDE_PATH=/usr/include/eigen3 \\\n\t\t-D BUILD_SHARED_LIBS=${BUILD_SHARED_LIBS} \\\n\t\t-D OPENCV_EXTRA_MODULES_PATH=$(TMP_DIR)opencv/opencv_contrib-$(OPENCV_VERSION)/modules \\\n\t\t-D BUILD_DOCS=OFF -D BUILD_EXAMPLES=OFF -D BUILD_TESTS=OFF -D BUILD_PERF_TESTS=ON -D BUILD_opencv_java=OFF -D BUILD_opencv_python=NO -D BUILD_opencv_python2=NO -D BUILD_opencv_python3=NO \\\n\t\t-D WITH_OPENCL=OFF \\\n\t\t-D WITH_CUDA=ON \\\n\t\t-D CUDA_ARCH_BIN=5.3 \\\n\t\t-D CUDA_ARCH_PTX=\"\" \\\n\t\t-D WITH_CUDNN=ON \\\n\t\t-D WITH_CUBLAS=ON \\\n\t\t-D ENABLE_FAST_MATH=ON \\\n\t\t-D CUDA_FAST_MATH=ON \\\n\t\t-D OPENCV_DNN_CUDA=ON \\\n\t\t-D ENABLE_NEON=ON \\\n\t\t-D WITH_QT=OFF \\\n\t\t-D WITH_OPENMP=ON \\\n\t\t-D WITH_OPENGL=ON \\\n\t\t-D BUILD_TIFF=ON \\\n\t\t-D WITH_FFMPEG=ON \\\n\t\t-D WITH_GSTREAMER=ON \\\n\t\t-D WITH_TBB=ON \\\n\t\t-D BUILD_TBB=ON \\\n\t\t-D BUILD_TESTS=OFF \\\n\t\t-D WITH_EIGEN=ON \\\n\t\t-D WITH_V4L=ON \\\n\t\t-D WITH_LIBV4L=ON \\\n\t\t-D OPENCV_GENERATE_PKGCONFIG=ON ..\n\t$(MAKE) -j $(shell nproc --all --ignore 1)\n\t$(MAKE) preinstall\n\tcd -\n\n# Build OpenCV with non-free contrib modules.\nbuild_nonfree:\n\tcd $(TMP_DIR)opencv/opencv-$(OPENCV_VERSION)\n\tmkdir build\n\tcd build\n\trm -rf *\n\tcmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D BUILD_SHARED_LIBS=${BUILD_SHARED_LIBS} -D OPENCV_EXTRA_MODULES_PATH=$(TMP_DIR)opencv/opencv_contrib-$(OPENCV_VERSION)/modules -D BUILD_DOCS=OFF -D BUILD_EXAMPLES=OFF -D BUILD_TESTS=OFF -D BUILD_PERF_TESTS=ON -D BUILD_opencv_java=NO -D BUILD_opencv_python=NO -D BUILD_opencv_python2=NO -D BUILD_opencv_python3=NO -D WITH_JASPER=OFF -D WITH_TBB=ON -DOPENCV_GENERATE_PKGCONFIG=ON -DOPENCV_ENABLE_NONFREE=ON ..\n\t$(MAKE) -j $(shell nproc --all --ignore 1)\n\t$(MAKE) preinstall\n\tcd -\n\n# Build OpenCV with openvino.\nbuild_openvino:\n\tcd $(TMP_DIR)opencv/opencv-$(OPENCV_VERSION)\n\tmkdir build\n\tcd build\n\trm -rf *\n\tcmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D BUILD_SHARED_LIBS=${BUILD_SHARED_LIBS} -D ENABLE_CXX11=ON -D OPENCV_EXTRA_MODULES_PATH=$(TMP_DIR)opencv/opencv_contrib-$(OPENCV_VERSION)/modules -D WITH_INF_ENGINE=ON -D InferenceEngine_DIR=/usr/local/dldt/inference-engine/build -D BUILD_DOCS=OFF -D BUILD_EXAMPLES=OFF -D BUILD_TESTS=OFF -D BUILD_PERF_TESTS=ON -D BUILD_opencv_java=NO -D BUILD_opencv_python=NO -D BUILD_opencv_python2=NO -D BUILD_opencv_python3=NO -D WITH_JASPER=OFF -D WITH_TBB=ON -DOPENCV_GENERATE_PKGCONFIG=ON -DOPENCV_ENABLE_NONFREE=ON ..\n\t$(MAKE) -j $(shell nproc --all --ignore 1)\n\t$(MAKE) preinstall\n\tcd -\n\n# Build OpenCV with cuda.\nbuild_cuda:\n\tcd $(TMP_DIR)opencv/opencv-$(OPENCV_VERSION)\n\tmkdir build\n\tcd build\n\trm -rf *\n\tcmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D BUILD_SHARED_LIBS=${BUILD_SHARED_LIBS} -D OPENCV_EXTRA_MODULES_PATH=$(TMP_DIR)opencv/opencv_contrib-$(OPENCV_VERSION)/modules -D BUILD_DOCS=OFF -D BUILD_EXAMPLES=OFF -D BUILD_TESTS=OFF -D BUILD_PERF_TESTS=ON -D BUILD_opencv_java=NO -D BUILD_opencv_python=NO -D BUILD_opencv_python2=NO -D BUILD_opencv_python3=NO -D WITH_JASPER=OFF -D WITH_TBB=ON -DOPENCV_GENERATE_PKGCONFIG=ON -DWITH_CUDA=ON -DENABLE_FAST_MATH=1 -DCUDA_FAST_MATH=1 -DWITH_CUBLAS=ON -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda/ -DBUILD_opencv_cudacodec=OFF -D WITH_CUDNN=ON -D OPENCV_DNN_CUDA=ON -D CUDA_GENERATION=Auto -DOPENCV_ENABLE_NONFREE=ON -D WITH_GSTREAMER=OFF ..\n\t$(MAKE) -j $(shell nproc --all --ignore 1)\n\t$(MAKE) preinstall\n\tcd -\n\n# Build OpenCV statically linked\nbuild_static:\n\tcd $(TMP_DIR)opencv/opencv-$(OPENCV_VERSION)\n\tmkdir build\n\tcd build\n\trm -rf *\n\tcmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D BUILD_SHARED_LIBS=OFF -D OPENCV_EXTRA_MODULES_PATH=$(TMP_DIR)opencv/opencv_contrib-$(OPENCV_VERSION)/modules -D BUILD_DOCS=OFF -D BUILD_EXAMPLES=OFF -D BUILD_TESTS=OFF -D BUILD_PERF_TESTS=ON -D BUILD_opencv_java=NO -D BUILD_opencv_python=NO -D BUILD_opencv_python2=NO -D BUILD_opencv_python3=NO -DWITH_JASPER=OFF -DWITH_QT=OFF -DWITH_GTK=OFF -DWITH_FFMPEG=OFF -DWITH_TIFF=OFF -DWITH_WEBP=OFF -DWITH_PNG=OFF -DWITH_1394=OFF -DWITH_OPENJPEG=OFF -DOPENCV_GENERATE_PKGCONFIG=ON ..\n\t$(MAKE) -j $(shell nproc --all --ignore 1)\n\t$(MAKE) preinstall\n\tcd -\n\n# Build OpenCV with cuda.\nbuild_all:\n\tcd $(TMP_DIR)opencv/opencv-$(OPENCV_VERSION)\n\tmkdir build\n\tcd build\n\trm -rf *\n\tcmake -j $(shell nproc --all --ignore 1) -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D BUILD_SHARED_LIBS=${BUILD_SHARED_LIBS} -D ENABLE_CXX11=ON -D OPENCV_EXTRA_MODULES_PATH=$(TMP_DIR)opencv/opencv_contrib-$(OPENCV_VERSION)/modules -D WITH_INF_ENGINE=ON -D InferenceEngine_DIR=/usr/local/dldt/inference-engine/build -D BUILD_DOCS=OFF -D BUILD_EXAMPLES=OFF -D BUILD_TESTS=OFF -D BUILD_PERF_TESTS=ON -D BUILD_opencv_java=NO -D BUILD_opencv_python=NO -D BUILD_opencv_python2=NO -D BUILD_opencv_python3=NO -D WITH_JASPER=OFF -D WITH_TBB=ON -DOPENCV_GENERATE_PKGCONFIG=ON -DWITH_CUDA=ON -DENABLE_FAST_MATH=1 -DCUDA_FAST_MATH=1 -DWITH_CUBLAS=1 -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda/ -DBUILD_opencv_cudacodec=OFF -D WITH_CUDNN=ON -D OPENCV_DNN_CUDA=ON -D CUDA_GENERATION=Auto ..\n\t$(MAKE) -j $(shell nproc --all --ignore 1)\n\t$(MAKE) preinstall\n\tcd -\n\n# Cleanup temporary build files.\nclean:\n\tgo clean --cache\n\trm -rf $(TMP_DIR)opencv\n\n# Cleanup old library files.\nsudo_pre_install_clean:\nifneq (,$(wildcard /usr/local/lib/libopencv*))\n\tsudo rm -rf /usr/local/lib/cmake/opencv4/\n\tsudo rm -rf /usr/local/lib/libopencv*\n\tsudo rm -rf /usr/local/lib/pkgconfig/opencv*\n\tsudo rm -rf /usr/local/include/opencv*\nelse\nifneq (,$(wildcard /usr/local/lib64/libopencv*))\n\tsudo rm -rf /usr/local/lib64/cmake/opencv4/\n\tsudo rm -rf /usr/local/lib64/libopencv*\n\tsudo rm -rf /usr/local/lib64/pkgconfig/opencv*\n\tsudo rm -rf /usr/local/include/opencv*\nelse\nifneq (,$(wildcard /usr/local/lib/aarch64-linux-gnu/libopencv*))\n\tsudo rm -rf /usr/local/lib/aarch64-linux-gnu/cmake/opencv4/\n\tsudo rm -rf /usr/local/lib/aarch64-linux-gnu/libopencv*\n\tsudo rm -rf /usr/local/lib/aarch64-linux-gnu/pkgconfig/opencv*\n\tsudo rm -rf /usr/local/include/opencv*\nendif\nendif\nendif\n\n# Do everything.\ninstall: deps download sudo_pre_install_clean build sudo_install clean verify\n\n# Do everything on Raspbian.\ninstall_raspi: deps download sudo_pre_install_clean build_raspi sudo_install clean verify\n\n# Do everything on the raspberry pi zero.\ninstall_raspi_zero: deps download sudo_pre_install_clean build_raspi_zero sudo_install clean verify\n\n# Do everything on Jetson.\ninstall_jetson: deps download sudo_pre_install_clean build_jetson sudo_install clean verify\n\n# Do everything with cuda.\ninstall_cuda: deps download sudo_pre_install_clean build_cuda sudo_install clean verify verify_cuda\n\n# Do everything with openvino.\ninstall_openvino: deps download download_openvino sudo_pre_install_clean build_openvino_package sudo_install_openvino build_openvino sudo_install clean verify_openvino\n\n# Do everything statically.\ninstall_static: deps download sudo_pre_install_clean build_static sudo_install clean verify_static\n\n# Do everything with non-free modules from cpencv_contrib.\ninstall_nonfree: deps download sudo_pre_install_clean build_nonfree sudo_install clean verify\n\n# Do everything with openvino and cuda.\ninstall_all: deps download download_openvino sudo_pre_install_clean build_openvino_package sudo_install_openvino build_all sudo_install clean verify_openvino verify_cuda\n\n# Install system wide.\nsudo_install:\n\tcd $(TMP_DIR)opencv/opencv-$(OPENCV_VERSION)/build\n\tsudo $(MAKE) install\n\tsudo ldconfig\n\tcd -\n\n# Install system wide.\nsudo_install_openvino:\n\tcd /usr/local/openvino/inference-engine/build\n\tsudo $(MAKE) install\n\tsudo ldconfig\n\tcd -\n\n# Build a minimal Go app to confirm gocv works.\nverify:\n\tgo run ./cmd/version/main.go\n\n# Build a minimal Go app to confirm gocv works with statically built OpenCV.\nverify_static:\n\tgo run -tags static ./cmd/version/main.go\n\n# Build a minimal Go app to confirm gocv cuda works.\nverify_cuda:\n\tgo run ./cmd/cuda/main.go\n\n# Build a minimal Go app to confirm gocv openvino works.\nverify_openvino:\n\tgo run -tags openvino ./cmd/version/main.go\n\n# Runs tests.\n# This assumes env.sh was already sourced.\n# pvt is not tested here since it requires additional depenedences.\ntest:\n\tgo test -tags matprofile . ./contrib\n\ntest_cuda:\n\tgo test -tags matprofile ./cuda\n\ndocker:\n\tdocker build --build-arg OPENCV_VERSION=$(OPENCV_VERSION) --build-arg GOVERSION=$(GOVERSION) .\n\nastyle:\n\tastyle --project=.astylerc --recursive *.cpp,*.h\n\n\nreleaselog:\n\tgit log --pretty=format:\"%s\" $(GOCV_VERSION)..HEAD\n\nCMDS=basic-drawing caffe-classifier captest capwindow counter dnn-detection dnn-pose-detection dnn-style-transfer faceblur facedetect facedetect-from-url feature-matching find-chessboard find-circles find-lines hand-gestures hello img-similarity mjpeg-streamer motion-detect saveimage savevideo showimage ssd-facedetect tf-classifier tracking version xphoto\ncmds:\n\tfor cmd in $(CMDS) ; do \\\n\t\tgo build -o build/$$cmd cmd/$$cmd/main.go ;\n\tdone ; \\\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 23.1201171875,
          "content": "# GoCV\n\n[![GoCV](https://raw.githubusercontent.com/hybridgroup/gocv/release/images/gocvlogo.jpg)](http://gocv.io/)\n\n[![Go Reference](https://pkg.go.dev/badge/gocv.io/x/gocv.svg)](https://pkg.go.dev/gocv.io/x/gocv)\n[![Linux](https://github.com/hybridgroup/gocv/actions/workflows/linux.yml/badge.svg?branch=dev)](https://github.com/hybridgroup/gocv/actions/workflows/linux.yml)\n[![macOS](https://github.com/hybridgroup/gocv/actions/workflows/macos.yml/badge.svg?branch=dev)](https://github.com/hybridgroup/gocv/actions/workflows/macos.yml)\n[![Windows](https://github.com/hybridgroup/gocv/actions/workflows/windows.yml/badge.svg?branch=dev)](https://github.com/hybridgroup/gocv/actions/workflows/windows.yml)\n[![Go Report Card](https://goreportcard.com/badge/github.com/hybridgroup/gocv)](https://goreportcard.com/report/github.com/hybridgroup/gocv)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/hybridgroup/gocv/blob/release/LICENSE.txt)\n\nThe GoCV package provides Go language bindings for the [OpenCV 4](http://opencv.org/) computer vision library.\n\nThe GoCV package supports the latest releases of Go and OpenCV (v4.10.0) on Linux, macOS, and Windows. We intend to make the Go language a \"first-class\" client compatible with the latest developments in the OpenCV ecosystem.\n\nGoCV supports [CUDA](https://en.wikipedia.org/wiki/CUDA) for hardware acceleration using Nvidia GPUs. Check out the [CUDA README](./cuda/README.md) for more info on how to use GoCV with OpenCV/CUDA.\n\nGoCV also supports [Intel OpenVINO](https://software.intel.com/en-us/openvino-toolkit). Check out the [OpenVINO README](./openvino/README.md) for more info on how to use GoCV with the Intel OpenVINO toolkit.\n\n## How to use\n\n### Hello, video\n\nThis example opens a video capture device using device \"0\", reads frames, and shows the video in a GUI window:\n\n```go\npackage main\n\nimport (\n\t\"gocv.io/x/gocv\"\n)\n\nfunc main() {\n\twebcam, _ := gocv.OpenVideoCapture(0)\n\twindow := gocv.NewWindow(\"Hello\")\n\timg := gocv.NewMat()\n\n\tfor {\n\t\twebcam.Read(&img)\n\t\twindow.IMShow(img)\n\t\twindow.WaitKey(1)\n\t}\n}\n```\n\n### Face detect\n\n![GoCV](https://raw.githubusercontent.com/hybridgroup/gocv/release/images/face-detect.jpg)\n\nThis is a more complete example that opens a video capture device using device \"0\". It also uses the CascadeClassifier class to load an external data file containing the classifier data. The program grabs each frame from the video, then uses the classifier to detect faces. If any faces are found, it draws a green rectangle around each one, then displays the video in an output window:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"image/color\"\n\n\t\"gocv.io/x/gocv\"\n)\n\nfunc main() {\n    // set to use a video capture device 0\n    deviceID := 0\n\n\t// open webcam\n\twebcam, err := gocv.OpenVideoCapture(deviceID)\n\tif err != nil {\n\t\tfmt.Println(err)\n\t\treturn\n\t}\n\tdefer webcam.Close()\n\n\t// open display window\n\twindow := gocv.NewWindow(\"Face Detect\")\n\tdefer window.Close()\n\n\t// prepare image matrix\n\timg := gocv.NewMat()\n\tdefer img.Close()\n\n\t// color for the rect when faces detected\n\tblue := color.RGBA{0, 0, 255, 0}\n\n\t// load classifier to recognize faces\n\tclassifier := gocv.NewCascadeClassifier()\n\tdefer classifier.Close()\n\n\tif !classifier.Load(\"data/haarcascade_frontalface_default.xml\") {\n\t\tfmt.Println(\"Error reading cascade file: data/haarcascade_frontalface_default.xml\")\n\t\treturn\n\t}\n\n\tfmt.Printf(\"start reading camera device: %v\\n\", deviceID)\n\tfor {\n\t\tif ok := webcam.Read(&img); !ok {\n\t\t\tfmt.Printf(\"cannot read device %v\\n\", deviceID)\n\t\t\treturn\n\t\t}\n\t\tif img.Empty() {\n\t\t\tcontinue\n\t\t}\n\n\t\t// detect faces\n\t\trects := classifier.DetectMultiScale(img)\n\t\tfmt.Printf(\"found %d faces\\n\", len(rects))\n\n\t\t// draw a rectangle around each face on the original image\n\t\tfor _, r := range rects {\n\t\t\tgocv.Rectangle(&img, r, blue, 3)\n\t\t}\n\n\t\t// show the image in the window, and wait 1 millisecond\n\t\twindow.IMShow(img)\n\t\twindow.WaitKey(1)\n\t}\n}\n```\n\n### More examples\n\nThere are examples in the [cmd directory](./cmd) of this repo in the form of various useful command line utilities, such as [capturing an image file](./cmd/saveimage), [streaming mjpeg video](./cmd/mjpeg-streamer), [counting objects that cross a line](./cmd/counter), and [using OpenCV with Tensorflow for object classification](./cmd/tf-classifier).\n\n## How to install\n\nTo install GoCV, you must first have the matching version of OpenCV installed on your system. The current release of GoCV requires OpenCV 4.10.0.\n\nHere are instructions for Ubuntu, Raspian, macOS, and Windows.\n\n## Ubuntu/Linux\n\n### Installation\n\nYou can use `make` to install OpenCV 4.10.0 with the handy `Makefile` included with this repo. If you already have installed OpenCV, you do not need to do so again. The installation performed by the `Makefile` is minimal, so it may remove OpenCV options such as Python or Java wrappers if you have already installed OpenCV some other way.\n\n#### Quick Install\n\nFirst, change directories to where you want to install GoCV, and then use git to clone the repository to your local machine like this:\n\n    cd $HOME/folder/with/your/src/\n    git clone https://github.com/hybridgroup/gocv.git\n\nMake sure to change `$HOME/folder/with/your/src/` to where you actually want to save the code.\n\nOnce you have cloned the repo, the following commands should do everything to download and install OpenCV 4.10.0 on Linux:\n\n    cd gocv\n    make install\n\nIf you need static opencv libraries\n\n    make install BUILD_SHARED_LIBS=OFF\n\nIf it works correctly, at the end of the entire process, the following message should be displayed:\n\n    gocv version: 0.39.0\n    opencv lib version: 4.10.0\n\nThat's it, now you are ready to use GoCV.\n\n#### Using CUDA with GoCV\n\nSee the [cuda directory](./cuda) for information.\n\n#### Using OpenVINO with GoCV\n\nSee the [openvino directory](./openvino) for information.\n\n#### Make Install for OpenVINO and Cuda\n\nThe following commands should do everything to download and install OpenCV 4.10.0 with CUDA and OpenVINO on Linux. Make sure to change `$HOME/folder/with/your/src/` to the directory you used to clone GoCV:\n\n    cd $HOME/folder/with/gocv/\n    make install_all\n\nIf you need static opencv libraries\n\n    make install_all BUILD_SHARED_LIBS=OFF\n\nIf it works correctly, at the end of the entire process, the following message should be displayed:\n\n    gocv version: 0.39.0\n    opencv lib version: 4.10.0-openvino\n    cuda information:\n      Device 0:  \"GeForce MX150\"  2003Mb, sm_61, Driver/Runtime ver.10.0/10.0\n\n#### Complete Install\n\nIf you have already done the \"Quick Install\" as described above, you do not need to run any further commands. For the curious, or for custom installations, here are the details for each of the steps that are performed when you run `make install`.\n\nFirst, change directories to where you want to install GoCV, and then use git to clone the repository to your local machine like this:\n\n    cd $HOME/folder/with/your/src/\n    git clone https://github.com/hybridgroup/gocv.git\n\nMake sure to change `$HOME/folder/with/your/src/` to where you actually want to save the code.\n\n##### Install required packages\n\nFirst, you need to change the current directory to the location where you cloned the GoCV repo, so you can access the `Makefile`:\n\n    cd $HOME/folder/with/your/src/gocv\n\nNext, you need to update the system, and install any required packages:\n\n    make deps\n\n#### Download source\n\nNow, download the OpenCV 4.10.0 and OpenCV Contrib source code:\n\n    make download\n\n#### Build\n\nBuild everything. This will take quite a while:\n\n    make build\n\nIf you need static opencv libraries\n\n    make build BUILD_SHARED_LIBS=OFF\n\n#### Install\n\nOnce the code is built, you are ready to install:\n\n    make sudo_install\n\n### Verifying the installation\n\nTo verify your installation you can run one of the included examples.\n\nFirst, change the current directory to the location of the GoCV repo:\n\n    cd $HOME/src/gocv.io/x/gocv\n\nNow you should be able to build or run any of the examples:\n\n    go run ./cmd/version/main.go\n\nThe version program should output the following:\n\n    gocv version: 0.39.0\n    opencv lib version: 4.10.0\n\n#### Cleanup extra files\n\nAfter the installation is complete, you can remove the extra files and folders:\n\n    make clean\n\n### Custom Environment\n\nBy default, pkg-config is used to determine the correct flags for compiling and linking OpenCV. This behavior can be disabled by supplying `-tags customenv` when building/running your application. When building with this tag you will need to supply the CGO environment variables yourself.\n\nFor example:\n\n    export CGO_CPPFLAGS=\"-I/usr/local/include\"\n    export CGO_LDFLAGS=\"-L/usr/local/lib -lopencv_core -lopencv_face -lopencv_videoio -lopencv_imgproc -lopencv_highgui -lopencv_imgcodecs -lopencv_objdetect -lopencv_features2d -lopencv_video -lopencv_dnn -lopencv_xfeatures2d\"\n\nPlease note that you will need to run these 2 lines of code one time in your current session in order to build or run the code, in order to setup the needed ENV variables. Once you have done so, you can execute code that uses GoCV with your custom environment like this:\n\n    go run -tags customenv ./cmd/version/main.go\n\n### Docker\n\nThe project now provides `Dockerfile` which lets you build [GoCV](https://gocv.io/) Docker image which you can then use to build and run `GoCV` applications in Docker containers. The `Makefile` contains `docker` target which lets you build Docker image with a single command:\n\n```\nmake docker\n```\n\nBy default Docker image built by running the command above ships [Go](https://golang.org/) version `1.22.2`, but if you would like to build an image which uses different version of `Go` you can override the default value when running the target command:\n\n```\nmake docker GOVERSION='1.22.0'\n```\n\n#### Running GUI programs in Docker on macOS\n\nSometimes your `GoCV` programs create graphical interfaces like windows eg. when you use `gocv.Window` type when you display an image or video stream. Running the programs which create graphical interfaces in Docker container on macOS is unfortunately a bit elaborate, but not impossible. First you need to satisfy the following prerequisites:\n\n- install [xquartz](https://www.xquartz.org/). You can also install xquartz using [homebrew](https://brew.sh/) by running `brew cask install xquartz`\n- install [socat](https://linux.die.net/man/1/socat) `brew install socat`\n\nNote, you will have to log out and log back in to your machine once you have installed `xquartz`. This is so the X window system is reloaded.\n\nOnce you have installed all the prerequisites you need to allow connections from network clients to `xquartz`. Here is how you do that. First run the following command to open `xquart` so you can configure it:\n\n```shell\nopen -a xquartz\n```\n\nClick on _Security_ tab in preferences and check the \"Allow connections\" box:\n\n![app image](./images/xquartz.png)\n\nNext, you need to create a TCP proxy using `socat` which will stream [X Window](https://en.wikipedia.org/wiki/X_Window_System) data into `xquart`. Before you start the proxy you need to make sure that there is no process listening in port `6000`. The following command should **not** return any results:\n\n```shell\nlsof -i TCP:6000\n```\n\nNow you can start a local proxy which will proxy the X Window traffic into xquartz which acts a your local X server:\n\n```shell\nsocat TCP-LISTEN:6000,reuseaddr,fork UNIX-CLIENT:\\\"$DISPLAY\\\"\n```\n\nYou are now finally ready to run your `GoCV` GUI programs in Docker containers. In order to make everything work you must set `DISPLAY` environment variables as shown in a sample command below:\n\n```shell\ndocker run -it --rm -e DISPLAY=docker.for.mac.host.internal:0 your-gocv-app\n```\n\n**Note, since Docker for MacOS does not provide any video device support, you won't be able run GoCV apps which require camera.**\n\n### Alpine 3.7 Docker image\n\nThere is a Docker image with Alpine 3.7 that has been created by project contributor [@denismakogon](https://github.com/denismakogon). You can find it located at [https://github.com/denismakogon/gocv-alpine](https://github.com/denismakogon/gocv-alpine).\n\n## Raspbian\n\n### Installation\n\nWe have a special installation for the Raspberry Pi that includes some hardware optimizations. You use `make` to install OpenCV 4.10.0 with the handy `Makefile` included with this repo. If you already have installed OpenCV, you do not need to do so again. The installation performed by the `Makefile` is minimal, so it may remove OpenCV options such as Python or Java wrappers if you have already installed OpenCV some other way.\n\n#### Quick Install\n\nFirst, change directories to where you want to install GoCV, and then use git to clone the repository to your local machine like this:\n\n    cd $HOME/folder/with/your/src/\n    git clone https://github.com/hybridgroup/gocv.git\n\nMake sure to change `$HOME/folder/with/your/src/` to where you actually want to save the code.\n\nThe following make command should do everything to download and install OpenCV 4.10.0 on Raspbian:\n\n    cd $HOME/folder/with/your/src/gocv\n    make install_raspi\n\nIf it works correctly, at the end of the entire process, the following message should be displayed:\n\n    gocv version: 0.39.0\n    opencv lib version: 4.10.0\n\nThat's it, now you are ready to use GoCV.\n\n## macOS\n\n### Installation\n\nYou can install OpenCV 4.10.0 using Homebrew.\n\nIf you already have an earlier version of OpenCV (3.4.x) installed, you should probably remove it before installing the new version:\n\n    brew uninstall opencv\n\nYou can then install OpenCV 4.10.0:\n\n    brew install opencv\n\n### pkgconfig Installation\n\npkg-config is used to determine the correct flags for compiling and linking OpenCV.\nYou can install it by using Homebrew:\n\n    brew install pkgconfig\n\n### Verifying the installation\n\nTo verify your installation you can run one of the included examples.\n\nFirst, change the current directory to the location of the GoCV repo:\n\n    cd $HOME/folder/with/your/src/gocv\n\nNow you should be able to build or run any of the examples:\n\n    go run ./cmd/version/main.go\n\nThe version program should output the following:\n\n    gocv version: 0.39.0\n    opencv lib version: 4.10.0\n\n### Custom Environment\n\nBy default, pkg-config is used to determine the correct flags for compiling and linking OpenCV. This behavior can be disabled by supplying `-tags customenv` when building/running your application. When building with this tag you will need to supply the CGO environment variables yourself.\n\nFor example:\n\n    export CGO_CXXFLAGS=\"--std=c++11\"\n    export CGO_CPPFLAGS=\"-I/usr/local/Cellar/opencv/4.10.0/include\"\n    export CGO_LDFLAGS=\"-L/usr/local/Cellar/opencv/4.10.0/lib -lopencv_stitching -lopencv_superres -lopencv_videostab -lopencv_aruco -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_dnn_objdetect -lopencv_dpm -lopencv_face -lopencv_photo -lopencv_fuzzy -lopencv_hfs -lopencv_img_hash -lopencv_line_descriptor -lopencv_optflow -lopencv_reg -lopencv_rgbd -lopencv_saliency -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_surface_matching -lopencv_tracking -lopencv_datasets -lopencv_dnn -lopencv_plot -lopencv_xfeatures2d -lopencv_shape -lopencv_video -lopencv_ml -lopencv_ximgproc -lopencv_calib3d -lopencv_features2d -lopencv_highgui -lopencv_videoio -lopencv_flann -lopencv_xobjdetect -lopencv_imgcodecs -lopencv_objdetect -lopencv_xphoto -lopencv_imgproc -lopencv_core\"\n\nPlease note that you will need to run these 3 lines of code one time in your current session in order to build or run the code, in order to setup the needed ENV variables. Once you have done so, you can execute code that uses GoCV with your custom environment like this:\n\n    go run -tags customenv ./cmd/version/main.go\n\n## Windows\n\n### Installation\n\nThe following assumes that you are running a 64-bit version of Windows 10.\n\nIn order to build and install OpenCV 4.10.0 on Windows, you must first download and install MinGW-W64 and CMake, as follows.\n\n#### MinGW-W64\n\nDownload and run the MinGW-W64 compiler installer from [https://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/8.1.0/](https://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/8.1.0/).\n\nThe latest version of the MinGW-W64 toolchain is `8.1.0`, but any version from `8.X` on should work.\n\nChoose the options for \"posix\" threads, and for \"seh\" exceptions handling, then install to the default location `c:\\Program Files\\mingw-w64\\x86_64-8.1.0-posix-seh-rt_v6-rev0`.\n\nAdd the `C:\\Program Files\\mingw-w64\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\mingw64\\bin` path to your System Path.\n\n#### CMake\n\nDownload and install CMake [https://cmake.org/download/](https://cmake.org/download/) to the default location. CMake installer will add CMake to your system path.\n\n#### OpenCV 4.10.0 and OpenCV Contrib Modules\n\nThe following commands should do everything to download and install OpenCV 4.10.0 on Windows:\n\n    chdir %GOPATH%\\src\\gocv.io\\x\\gocv\n    win_build_opencv.cmd\n\nIt might take up to one hour.\n\nLast, add `C:\\opencv\\build\\install\\x64\\mingw\\bin` to your System Path.\n\n### Verifying the installation\n\nChange the current directory to the location of the GoCV repo:\n\n    chdir %GOPATH%\\src\\gocv.io\\x\\gocv\n\nNow you should be able to build or run any of the command examples:\n\n    go run cmd\\version\\main.go\n\nThe version program should output the following:\n\n    gocv version: 0.39.0\n    opencv lib version: 4.10.0\n\nThat's it, now you are ready to use GoCV.\n\n### Custom Environment\n\nBy default, OpenCV is expected to be in `C:\\opencv\\build\\install\\include`. This behavior can be disabled by supplying `-tags customenv` when building/running your application. When building with this tag you will need to supply the CGO environment variables yourself.\n\nDue to the way OpenCV produces DLLs, including the version in the name, using this method is required if you're using a different version of OpenCV.\n\nFor example:\n\n    set CGO_CXXFLAGS=\"--std=c++11\"\n    set CGO_CPPFLAGS=-IC:\\opencv\\build\\install\\include\n    set CGO_LDFLAGS=-LC:\\opencv\\build\\install\\x64\\mingw\\lib -lopencv_core4100 -lopencv_face4100 -lopencv_videoio4100 -lopencv_imgproc4100 -lopencv_highgui4100 -lopencv_imgcodecs4100 -lopencv_objdetect4100 -lopencv_features2d4100 -lopencv_video4100 -lopencv_dnn4100 -lopencv_xfeatures2d4100 -lopencv_plot4100 -lopencv_tracking4100 -lopencv_img_hash4100\n\nPlease note that you will need to run these 3 lines of code one time in your current session in order to build or run the code, in order to setup the needed ENV variables. Once you have done so, you can execute code that uses GoCV with your custom environment like this:\n\n    go run -tags customenv cmd\\version\\main.go\n\n## Android\n\nThere is some work in progress for running GoCV on Android using Gomobile. For information on how to install OpenCV/GoCV for Android, please see:\nhttps://gist.github.com/ogero/c19458cf64bd3e91faae85c3ac8874100\n\nSee original discussion here:\nhttps://github.com/hybridgroup/gocv/issues/235\n\n## Profiling\n\nSince memory allocations for images in GoCV are done through C based code, the go garbage collector will not clean all resources associated with a `Mat`. As a result, any `Mat` created _must_ be closed to avoid memory leaks.\n\nTo ease the detection and repair of the resource leaks, GoCV provides a `Mat` profiler that records when each `Mat` is created and closed. Each time a `Mat` is allocated, the stack trace is added to the profile. When it is closed, the stack trace is removed. See the [runtime/pprof documentation](https://golang.org/pkg/runtime/pprof/#Profile).\n\nIn order to include the MatProfile custom profiler, you MUST build or run your application or tests using the `-tags matprofile` build tag. For example:\n\n    go run -tags matprofile cmd/version/main.go\n\nYou can get the profile's count at any time using:\n\n```go\ngocv.MatProfile.Count()\n```\n\nYou can display the current entries (the stack traces) with:\n\n```go\nvar b bytes.Buffer\ngocv.MatProfile.WriteTo(&b, 1)\nfmt.Print(b.String())\n```\n\nThis can be very helpful to track down a leak. For example, suppose you have\nthe following nonsense program:\n\n```go\npackage main\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\n\t\"gocv.io/x/gocv\"\n)\n\nfunc leak() {\n\tgocv.NewMat()\n}\n\nfunc main() {\n\tfmt.Printf(\"initial MatProfile count: %v\\n\", gocv.MatProfile.Count())\n\tleak()\n\n\tfmt.Printf(\"final MatProfile count: %v\\n\", gocv.MatProfile.Count())\n\tvar b bytes.Buffer\n\tgocv.MatProfile.WriteTo(&b, 1)\n\tfmt.Print(b.String())\n}\n```\n\nRunning this program produces the following output:\n\n```\ninitial MatProfile count: 0\nfinal MatProfile count: 1\ngocv.io/x/gocv.Mat profile: total 1\n1 @ 0x40b936c 0x40b93b7 0x40b94e2 0x40b95af 0x402cd87 0x40558e1\n#\t0x40b936b\tgocv.io/x/gocv.newMat+0x4b\t/go/src/gocv.io/x/gocv/core.go:153\n#\t0x40b93b6\tgocv.io/x/gocv.NewMat+0x26\t/go/src/gocv.io/x/gocv/core.go:159\n#\t0x40b94e1\tmain.leak+0x21\t\t\t/go/src/github.com/dougnd/gocvprofexample/main.go:11\n#\t0x40b95ae\tmain.main+0xae\t\t\t/go/src/github.com/dougnd/gocvprofexample/main.go:16\n#\t0x402cd86\truntime.main+0x206\t\t/usr/local/Cellar/go/1.11.1/libexec/src/runtime/proc.go:201\n```\n\nWe can see that this program would leak memory. As it exited, it had one `Mat` that was never closed. The stack trace points to exactly which line the allocation happened on (line 11, the `gocv.NewMat()`).\n\nFurthermore, if the program is a long running process or if GoCV is being used on a web server, it may be helpful to install the HTTP interface )). For example:\n\n```go\npackage main\n\nimport (\n\t\"net/http\"\n\t_ \"net/http/pprof\"\n\t\"time\"\n\n\t\"gocv.io/x/gocv\"\n)\n\nfunc leak() {\n\tgocv.NewMat()\n}\n\nfunc main() {\n\tgo func() {\n\t\tticker := time.NewTicker(time.Second)\n\t\tfor {\n\t\t\t<-ticker.C\n\t\t\tleak()\n\t\t}\n\t}()\n\n\thttp.ListenAndServe(\"localhost:6060\", nil)\n}\n\n```\n\nThis will leak a `Mat` once per second. You can see the current profile count and stack traces by going to the installed HTTP debug interface: [http://localhost:6060/debug/pprof/gocv.io/x/gocv.Mat](http://localhost:6060/debug/pprof/gocv.io/x/gocv.Mat?debug=1).\n\n## How to contribute\n\nPlease take a look at our [CONTRIBUTING.md](./CONTRIBUTING.md) document to understand our contribution guidelines.\n\nThen check out our [ROADMAP.md](./ROADMAP.md) document to know what to work on next.\n\n## Why this project exists\n\nThe [https://github.com/go-opencv/go-opencv](https://github.com/go-opencv/go-opencv) package for Go and OpenCV does not support any version above OpenCV 2.x, and work on adding support for OpenCV 3 had stalled for over a year, mostly due to the complexity of [SWIG](http://swig.org/). That is why we started this project.\n\nThe GoCV package uses a C-style wrapper around the OpenCV 4 C++ classes to avoid having to deal with applying SWIG to a huge existing codebase. The mappings are intended to match as closely as possible to the original OpenCV project structure, to make it easier to find things, and to be able to figure out where to add support to GoCV for additional OpenCV image filters, algorithms, and other features.\n\nFor example, the [OpenCV `videoio` module](https://github.com/opencv/opencv/tree/master/modules/videoio) wrappers can be found in the GoCV package in the `videoio.*` files.\n\nThis package was inspired by the original https://github.com/go-opencv/go-opencv project, the blog post https://medium.com/@peterleyssens/using-opencv-3-from-golang-5510c312a3c and the repo at https://github.com/sensorbee/opencv thank you all!\n\n## License\n\nLicensed under the Apache 2.0 license. Copyright (c) 2017-2024 The Hybrid Group.\n\nLogo generated by GopherizeMe - https://gopherize.me\n"
        },
        {
          "name": "ROADMAP.md",
          "type": "blob",
          "size": 30.208984375,
          "content": "# Roadmap\n\nThis is a list of all of the functionality areas within OpenCV, and OpenCV Contrib.\n\nAny section listed with an \"X\" means that all of the relevant OpenCV functionality has been wrapped for use within GoCV.\n\nAny section listed with **WORK STARTED** indicates that some work has been done, but not all functionality in that module has been completed. If there are any functions listed under a section marked **WORK STARTED**, it indicates that that function still requires a wrapper implemented.\n\nAnd any section that is simply listed, indicates that so far, no work has been done on that module.\n\nYour pull requests will be greatly appreciated!\n\n## Modules list\n\n- [ ] **core. Core functionality - WORK STARTED**\n    - [X] **Basic structures**\n    - [X] **Operations on arrays**\n    - [X] **XML/YAML Persistence**\n\n    - [ ] **Clustering - WORK STARTED**. The following functions still need implementation:\n        - [ ] [partition](https://docs.opencv.org/master/d5/d38/group__core__cluster.html#ga2037c989e69b499c1aa271419f3a9b34)\n\n    - [ ] Optimization Algorithms\n        - [ ] [ConjGradSolver](https://docs.opencv.org/master/d0/d21/classcv_1_1ConjGradSolver.html)\n        - [ ] [DownhillSolver](https://docs.opencv.org/master/d4/d43/classcv_1_1DownhillSolver.html)\n        - [ ] [solveLP](https://docs.opencv.org/master/da/d01/group__core__optim.html#ga9a06d237a9d38ace891efa1ca1b5d00a)\n\n- [ ] **imgproc. Image processing - WORK STARTED**\n    - [ ] **Image Filtering - WORK STARTED** The following functions still need implementation:\n        - [ ] [buildPyramid](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gacfdda2bc1ac55e96de7e9f0bce7238c0)\n        - [ ] [getDerivKernels](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga6d6c23f7bd3f5836c31cfae994fc4aea)\n        - [ ] [getGaborKernel](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gae84c92d248183bd92fa713ce51cc3599)\n        - [ ] [morphologyExWithParams](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga67493776e3ad1a3df63883829375201f)\n        - [ ] [pyrMeanShiftFiltering](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga9fabdce9543bd602445f5db3827e4cc0)\n\n    - [ ] **Geometric Image Transformations - WORK STARTED** The following functions still need implementation:\n        - [ ] [convertMaps](https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga9156732fa8f01be9ebd1a194f2728b7f)\n        - [ ] [getDefaultNewCameraMatrix](https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga744529385e88ef7bc841cbe04b35bfbf)\n        - [ ] [initUndistortRectifyMap](https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga7dfb72c9cf9780a347fbe3d1c47e5d5a)\n        - [ ] [initWideAngleProjMap](https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#gaceb049ec48898d1dadd5b50c604429c8)\n        - [ ] [undistort](https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga69f2545a8b62a6b0fc2ee060dc30559d)\n\n    - [ ] **Miscellaneous Image Transformations - WORK STARTED** The following functions still need implementation:\n        - [ ] [blendLinear](https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#ga5e76540a679333d7c6cd0617c452c23d)\n        - [ ] [cvtColorTwoPlane](https://docs.opencv.org/4.x/d8/d01/group__imgproc__color__conversions.html#ga8d4cb64f7c6f03cc2b1f2356734b909d)\n        - [ ] [demosaicing](https://docs.opencv.org/4.x/d8/d01/group__imgproc__color__conversions.html#ga57261f12fccf872a2b2d66daf29d5bd0)\n        - [ ] [floodFill](https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#ga366aae45a6c1289b341d140839f18717)\n\n    - [ ] **Drawing Functions - WORK STARTED** The following functions still need implementation:\n        - [ ] [drawMarker](https://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#ga482fa7b0f578fcdd8a174904592a6250)\n        - [ ] [ellipse2Poly](https://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#ga727a72a3f6a625a2ae035f957c61051f)\n        - [ ] [fillConvexPoly](https://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#ga906aae1606ea4ed2f27bec1537f6c5c2)\n        - [ ] [getFontScaleFromHeight](https://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#ga442ff925c1a957794a1309e0ed3ba2c3)\n\n    - [ ] ColorMaps in OpenCV\n        - [ ] [applyColorMap](https://docs.opencv.org/4.10.0/d3/d50/group__imgproc__colormap.html#gacb22288ddccc55f9bd9e6d492b409cae)\n\n    - [ ] Planar Subdivision\n        - [ ] [Subdiv2D](https://docs.opencv.org/4.10.0/df/dbf/classcv_1_1Subdiv2D.html)\n\n    - [X] **Histograms**\n    - [ ] **Structural Analysis and Shape Descriptors - WORK STARTED** The following functions still need implementation:\n        - [ ] [fitEllipse](https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#gaf259efaad93098103d6c27b9e4900ffa)\n        - [ ] [fitEllipseAMS](https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#ga69e90cda55c4e192a8caa0b99c3e4550)\n        - [ ] [fitEllipseDirect](https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#ga6421884fd411923a74891998bbe9e813)\n        - [ ] [HuMoments](https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#gab001db45c1f1af6cbdbe64df04c4e944)\n        - [ ] [intersectConvexConvex](https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#ga8e840f3f3695613d32c052bec89e782c)\n        - [ ] [isContourConvex](https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#ga8abf8010377b58cbc16db6734d92941b)\n        - [ ] [minEnclosingTriangle](https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#ga1513e72f6bbdfc370563664f71e0542f)\n        - [ ] [rotatedRectangleIntersection](https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#ga8740e7645628c59d238b0b22c2abe2d4)\n\n    - [X] **Motion Analysis and Object Tracking**\n    - [ ] **Feature Detection - WORK STARTED** The following functions still need implementation:\n        - [ ] [cornerEigenValsAndVecs](https://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#ga4055896d9ef77dd3cacf2c5f60e13f1c)\n        - [ ] [cornerHarris](https://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#gac1fc3598018010880e370e2f709b4345)\n        - [ ] [cornerMinEigenVal](https://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#ga3dbce297c1feb859ee36707e1003e0a8)\n        - [ ] [createLineSegmentDetector](https://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#ga6b2ad2353c337c42551b521a73eeae7d)\n        - [ ] [preCornerDetect](https://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#gaa819f39b5c994871774081803ae22586)\n\n    - [X] **Object Detection**\n\n- [X] **imgcodecs. Image file reading and writing.**\n- [ ] **videoio. Video I/O - WORK STARTED**\n    - [ ] VideoWriterWithGStreamer\n\n- [X] **highgui. High-level GUI**\n- [ ] **video. Video Analysis - WORK STARTED**\n    - [X] **Motion Analysis**\n    - [ ] **Object Tracking - WORK STARTED** The following functions still need implementation:\n        - [ ] [buildOpticalFlowPyramid](https://docs.opencv.org/master/dc/d6b/group__video__track.html#ga86640c1c470f87b2660c096d2b22b2ce)\n        - [ ] [estimateRigidTransform](https://docs.opencv.org/master/dc/d6b/group__video__track.html#ga762cbe5efd52cf078950196f3c616d48)\n        - [ ] [findTransformECC](https://docs.opencv.org/master/dc/d6b/group__video__track.html#ga7ded46f9a55c0364c92ccd2019d43e3a)\n        - [ ] [meanShift](https://docs.opencv.org/master/dc/d6b/group__video__track.html#ga7ded46f9a55c0364c92ccd2019d43e3a)\n        - [ ] [CamShift](https://docs.opencv.org/master/dc/d6b/group__video__track.html#gaef2bd39c8356f423124f1fe7c44d54a1)\n        - [ ] [DualTVL1OpticalFlow](https://docs.opencv.org/master/dc/d47/classcv_1_1DualTVL1OpticalFlow.html)\n        - [ ] [FarnebackOpticalFlow](https://docs.opencv.org/master/de/d9e/classcv_1_1FarnebackOpticalFlow.html)\n        - [ ] [SparsePyrLKOpticalFlow](https://docs.opencv.org/master/d7/d08/classcv_1_1SparsePyrLKOpticalFlow.html)\n\n- [ ] **calib3d. Camera Calibration and 3D Reconstruction - WORK STARTED**. The following functions still need implementation:\n    - [ ] **Camera Calibration - WORK STARTED** The following functions still need implementation:\n        - [ ] [calibrateCameraRO](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#gacb6b35670216b24b67c70fcd21519ead)\n        - [ ] [calibrateHandEye](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#gaebfc1c9f7434196a374c382abf43439b)\n        - [ ] [calibrateRobotWorldHandEye](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#ga41b1a8dd70eae371eba707d101729c36)\n        - [ ] [calibrationMatrixValues](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [composeRT](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [computeCorrespondEpilines](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [convertPointsHomogeneous](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [convertPointsToHomogeneous](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [correctMatches](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [decomposeEssentialMat](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [decomposeHomographyMat](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [decomposeProjectionMatrix](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [drawChessboardCorners](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [drawFrameAxes](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [estimateAffine3D](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [filterHomographyDecompByVisibleRefpoints](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [filterSpeckles](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [find4QuadCornerSubpix](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [findCirclesGrid](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [findEssentialMat](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [findFundamentalMat](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [getDefaultNewCameraMatrix](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [getOptimalNewCameraMatrix](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [getValidDisparityROI](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [initCameraMatrix2D](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [initUndistortRectifyMap](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [initWideAngleProjMap](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [matMulDeriv](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [projectPoints](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [recoverPose](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [rectify3Collinear](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [reprojectImageTo3D](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [RQDecomp3x3](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [sampsonDistance](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [solveP3P](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [solvePnPGeneric](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [solvePnPRansac](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [solvePnPRefineLM](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [solvePnPRefineVVS](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [stereoCalibrate](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [stereoRectify](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [stereoRectifyUncalibrated](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n        - [ ] [validateDisparity](https://docs.opencv.org/master/d9/d0c/group__calib3d.html)\n\n    - [ ] **Fisheye - WORK STARTED** The following functions still need implementation:\n        - [ ] [projectPoints](https://docs.opencv.org/master/db/d58/group__calib3d__fisheye.html#gab1ad1dc30c42ee1a50ce570019baf2c4)\n        - [ ] [stereoCalibrate](https://docs.opencv.org/master/db/d58/group__calib3d__fisheye.html#gadbb3a6ca6429528ef302c784df47949b)\n        - [ ] [stereoRectify](https://docs.opencv.org/master/db/d58/group__calib3d__fisheye.html#gac1af58774006689056b0f2ef1db55ecc)\n\n- [ ] **features2d. 2D Features Framework - WORK STARTED**\n    - [X] **Feature Detection and Description**\n    - [X] **Descriptor Matchers**\n    - [X] **Drawing Function of Keypoints and Matches**\n    - [ ] Object Categorization\n        - [ ] [BOWImgDescriptorExtractor](https://docs.opencv.org/master/d2/d6b/classcv_1_1BOWImgDescriptorExtractor.html)\n        - [ ] [BOWKMeansTrainer](https://docs.opencv.org/master/d4/d72/classcv_1_1BOWKMeansTrainer.html)\n\n- [ ] **objdetect. Object Detection**\n    - [ ] **aruco. ArUco Marker Detection - WORK STARTED**\n        - [ ] [refineDetectedMarkers](https://docs.opencv.org/4.x/d2/d1a/classcv_1_1aruco_1_1ArucoDetector.html#ad806c9310cfc826a178b0aefdf09bab6)\n        - [ ] [refineDetectedMarkers](https://docs.opencv.org/4.x/d2/d1a/classcv_1_1aruco_1_1ArucoDetector.html#ad806c9310cfc826a178b0aefdf09bab6)\n        - [ ] [drawDetectedCornersCharuco](https://docs.opencv.org/4.x/de/d67/group__objdetect__aruco.html#ga7225eee644190f791e1583c499b7ab10)\n        - [ ] [drawDetectedDiamonds](https://docs.opencv.org/4.x/de/d67/group__objdetect__aruco.html#ga0dbf27203267fb8e9f282554cf0d3433)\n        - [ ] [extendDictionary](https://docs.opencv.org/4.x/de/d67/group__objdetect__aruco.html#ga928c031e9a782b18405af56c851d9549)\n        - [ ] [CharucoDetector](https://docs.opencv.org/4.x/d9/df5/classcv_1_1aruco_1_1CharucoDetector.html#ad7647d1c3d0e2db97bedc31f743e796b)\n        - [ ] [detectBoard](https://docs.opencv.org/4.x/d9/df5/classcv_1_1aruco_1_1CharucoDetector.html#aacbea601612a3a0feaa45ebb7fb255fd)\n        - [ ] [detectDiamonds](https://docs.opencv.org/4.x/d9/df5/classcv_1_1aruco_1_1CharucoDetector.html#a50342803f68deb1e6b0b79f61d4b1a73)\n\n    - [X] Face Detection\n        \n- [X] **dnn. Deep Neural Network module**\n- [ ] ml. Machine Learning\n    - [ ] [ANN_MLP](https://docs.opencv.org/4.x/d0/dce/classcv_1_1ml_1_1ANN__MLP.html)\n    - [ ] [Boost](https://docs.opencv.org/4.x/d6/d7a/classcv_1_1ml_1_1Boost.html)\n    - [ ] [DTrees](https://docs.opencv.org/4.x/d8/d89/classcv_1_1ml_1_1DTrees.html)\n    - [ ] [EM](https://docs.opencv.org/4.x/d1/dfb/classcv_1_1ml_1_1EM.html)\n    - [ ] [KNearest](https://docs.opencv.org/4.x/dd/de1/classcv_1_1ml_1_1KNearest.html)\n    - [ ] [LogisticRegression](https://docs.opencv.org/4.x/d6/df9/classcv_1_1ml_1_1LogisticRegression.html)\n    - [ ] [NormalBayesClassifier](https://docs.opencv.org/4.x/d4/d8e/classcv_1_1ml_1_1NormalBayesClassifier.html)\n    - [ ] [ParamGrid](https://docs.opencv.org/4.x/d6/dca/classcv_1_1ml_1_1ParamGrid.html)\n    - [ ] [RTrees](https://docs.opencv.org/4.x/d0/d65/classcv_1_1ml_1_1RTrees.html)\n    - [ ] [SimulatedAnnealingSolverSystem](https://docs.opencv.org/4.x/dc/db4/structcv_1_1ml_1_1SimulatedAnnealingSolverSystem.html)\n    - [ ] [SVM](https://docs.opencv.org/4.x/d1/d2d/classcv_1_1ml_1_1SVM.html)\n    - [ ] [SVMSVG](https://docs.opencv.org/4.x/de/d54/classcv_1_1ml_1_1SVMSGD.html)\n    - [ ] [TrainData](https://docs.opencv.org/4.x/dc/d32/classcv_1_1ml_1_1TrainData.html)\n\n- [ ] flann. Clustering and Search in Multi-Dimensional Spaces\n    - [ ] [hierarchicalClustering](https://docs.opencv.org/4.x/dc/de5/group__flann.html#gaf89c8914eb439855c9a24c3de01bfd82)\n\n- [ ] **photo. Computational Photography - WORK STARTED** The following functions still need implementation:\n    - [ ] [inpaint](https://docs.opencv.org/master/d7/d8b/group__photo__inpaint.html#gaedd30dfa0214fec4c88138b51d678085)\n    - [ ] [denoise_TVL1](https://docs.opencv.org/master/d1/d79/group__photo__denoise.html#ga7602ed5ae17b7de40152b922227c4e4f)\n    - [ ] [createCalibrateDebevec](https://docs.opencv.org/master/d6/df5/group__photo__hdr.html#ga7fed9707ad5f2cc0e633888867109f90)\n    - [ ] [createCalibrateRobertson](https://docs.opencv.org/master/d6/df5/group__photo__hdr.html#gae77813a21cd351a596619e5ff013be5d)\n    - [ ] [createMergeDebevec](https://docs.opencv.org/master/d6/df5/group__photo__hdr.html#gaa8eab36bc764abb2a225db7c945f87f9)\n    - [ ] [createMergeRobertson](https://docs.opencv.org/master/d6/df5/group__photo__hdr.html#ga460d4a1df1a7e8cdcf7445bb87a8fb78)\n    - [ ] [createTonemap](https://docs.opencv.org/master/d6/df5/group__photo__hdr.html#gabcbd653140b93a1fa87ccce94548cd0d)\n    - [ ] [createTonemapDrago](https://docs.opencv.org/master/d6/df5/group__photo__hdr.html#ga72bf92bb6b8653ee4be650ac01cf50b6)\n    - [ ] [createTonemapMantiuk](https://docs.opencv.org/master/d6/df5/group__photo__hdr.html#ga3b3f3bf083b7515802f039a6a70f2d21)\n    - [ ] [createTonemapReinhard](https://docs.opencv.org/master/d6/df5/group__photo__hdr.html#gadabe7f6bf1fa96ad0fd644df9182c2fb)\n    - [ ] [decolor](https://docs.opencv.org/master/d4/d32/group__photo__decolor.html#ga4864d4c007bda5dacdc5e9d4ed7e222c)\n\n- [ ] stitching. Images stitching\n    - [ ] [Stitcher](https://docs.opencv.org/4.x/d2/d8d/classcv_1_1Stitcher.html)\n\n## CUDA\n\n- [X] **core**\n\n- [ ] **cudaarithm. Operations on Matrices - WORK STARTED** The following functions still need implementation:\n    - [X] **core**\n    - [ ] **per-element operations - WORK STARTED** The following functions still need implementation:\n        - [ ] [cv::cuda::cartToPolar](https://docs.opencv.org/master/d8/d34/group__cudaarithm__elem.html#ga82210c7d1c1d42e616e554bf75a53480)\n        - [ ] [cv::cuda::compare](https://docs.opencv.org/master/d8/d34/group__cudaarithm__elem.html#ga4d41cd679f4a83862a3de71a6057db54)\n        - [ ] [cv::cuda::inRange](https://docs.opencv.org/master/d8/d34/group__cudaarithm__elem.html#gaf611ab6b1d85e951feb6f485b1ed9672)\n        - [ ] [cv::cuda::lshift](https://docs.opencv.org/master/d8/d34/group__cudaarithm__elem.html#gafd072accecb14c9adccdad45e3bf2300)\n        - [ ] [cv::cuda::magnitude](https://docs.opencv.org/master/d8/d34/group__cudaarithm__elem.html#ga3d17f4fcd79d7c01fadd217969009463)\n        - [ ] [cv::cuda::magnitudeSqr](https://docs.opencv.org/master/d8/d34/group__cudaarithm__elem.html#ga7613e382d257e150033d0ce4d6098f6a)\n        - [ ] [cv::cuda::phase](https://docs.opencv.org/master/d8/d34/group__cudaarithm__elem.html#ga5b75ec01be06dcd6e27ada09a0d4656a)\n        - [ ] [cv::cuda::polarToCart](https://docs.opencv.org/master/d8/d34/group__cudaarithm__elem.html#ga01516a286a329c303c2db746513dd9df)\n        - [ ] [cv::cuda::pow](https://docs.opencv.org/master/d8/d34/group__cudaarithm__elem.html#ga82d04ef4bcc4dfa9bfbe76488007c6c4)\n        - [ ] [cv::cuda::rshift](https://docs.opencv.org/master/d8/d34/group__cudaarithm__elem.html#ga87af0b66358cc302676f35c1fd56c2ed)\n\n    - [ ] **matrix reductions - WORK STARTED** The following functions still need implementation:\n        - [ ] [cv::cuda::absSum](https://docs.opencv.org/master/d5/de6/group__cudaarithm__reduce.html#ga690fa79ba4426c53f7d2bebf3d37a32a)\n        - [ ] [cv::cuda::calcAbsSum](https://docs.opencv.org/master/d5/de6/group__cudaarithm__reduce.html#ga15c403b76ab2c4d7ed0f5edc09891b7e)\n        - [ ] [cv::cuda::calcNorm](https://docs.opencv.org/master/d5/de6/group__cudaarithm__reduce.html#ga39d2826990d29b7e4b69dbe02bdae2e1)\n        - [ ] [cv::cuda::calcNormDiff](https://docs.opencv.org/master/d5/de6/group__cudaarithm__reduce.html#ga9be3d9a7b6c5760955f37d1039d01265)\n        - [ ] [cv::cuda::calcSqrSum](https://docs.opencv.org/master/d5/de6/group__cudaarithm__reduce.html#gac998c83597f6c206c78cee16aa87946f)\n        - [ ] [cv::cuda::calcSum](https://docs.opencv.org/master/d5/de6/group__cudaarithm__reduce.html#ga98a09144047f09f5cb1d6b6ea8e0856f)\n        - [ ] [cv::cuda::countNonZero](https://docs.opencv.org/master/d5/de6/group__cudaarithm__reduce.html#ga98a09144047f09f5cb1d6b6ea8e0856f)\n        - [ ] [cv::cuda::findMinMax](https://docs.opencv.org/master/d5/de6/group__cudaarithm__reduce.html#gae7f5f2aa9f65314470a76fccdff887f2)\n        - [ ] [cv::cuda::findMinMaxLoc](https://docs.opencv.org/master/d5/de6/group__cudaarithm__reduce.html#ga93916bc473a62d215d1130fab84d090a)\n        - [ ] [cv::cuda::integral](https://docs.opencv.org/master/d5/de6/group__cudaarithm__reduce.html#ga07e5104eba4bf45212ac9dbc5bf72ba6)\n        - [ ] [cv::cuda::meanStdDev](https://docs.opencv.org/master/d5/de6/group__cudaarithm__reduce.html#ga990a4db4c6d7e8f0f3a6685ba48fbddc)\n        - [ ] [cv::cuda::minMax](https://docs.opencv.org/master/d5/de6/group__cudaarithm__reduce.html#ga8d7de68c10717cf25e787e3c20d2dfee)\n        - [ ] [cv::cuda::minMaxLoc](https://docs.opencv.org/master/d5/de6/group__cudaarithm__reduce.html#ga5cacbc2a2323c4eaa81e7390c5d9f530)\n        - [ ] [cv::cuda::norm](https://docs.opencv.org/master/d5/de6/group__cudaarithm__reduce.html#ga6c01988a58d92126a7c60a4ab76d8324)\n        - [ ] [cv::cuda::normalize](https://docs.opencv.org/master/d5/de6/group__cudaarithm__reduce.html#ga4da4738b9956a5baaa2f5f8c2fba438a)\n        - [ ] [cv::cuda::rectStdDev](https://docs.opencv.org/master/d5/de6/group__cudaarithm__reduce.html#gac311484a4e57cab2ce2cfdc195fda7ee)\n        - [ ] [cv::cuda::reduce](https://docs.opencv.org/master/d5/de6/group__cudaarithm__reduce.html#ga21d57f661db7be093caf2c4378be2007)\n        - [ ] [cv::cuda::sqrIntegral](https://docs.opencv.org/master/d5/de6/group__cudaarithm__reduce.html#ga40c75196202706399a60bf6ba7a052ac)\n        - [ ] [cv::cuda::sqlSum](https://docs.opencv.org/master/d5/de6/group__cudaarithm__reduce.html#ga056c804ebf5d2eb9f6f35e3dcb01524c)\n        - [ ] [cv::cuda::sum](https://docs.opencv.org/master/d5/de6/group__cudaarithm__reduce.html#ga1f582844670199281e8012733b50c582)\n\n    - [ ] **Operations on matrices - WORK STARTED** The following functions still need implementation:\n        - [ ] [cv::cuda::createConvolution](https://docs.opencv.org/4.5.0/d9/d88/group__cudaarithm__arithm.html#ga2695e05ef624bf3ce03cfbda383a821d)\n        - [ ] [cv::cuda::createDFT](https://docs.opencv.org/4.5.0/d9/d88/group__cudaarithm__arithm.html#ga0f72d063b73c8bb995678525eb076f10)\n        - [ ] [cv::cuda::dft](https://docs.opencv.org/4.5.0/d9/d88/group__cudaarithm__arithm.html#gadea99cb15a715c983bcc2870d65a2e78)\n        - [ ] [cv::cuda::gemm](https://docs.opencv.org/4.5.0/d9/d88/group__cudaarithm__arithm.html#ga42efe211d7a43bbc922da044c4f17130)\n        - [ ] [cv::cuda::mulAndScaleSpectrums](https://docs.opencv.org/4.5.0/d9/d88/group__cudaarithm__arithm.html#ga5704c25b8be4f19da812e6d98c8ee464)\n        - [ ] [cv::cuda::mulSpectrums](https://docs.opencv.org/4.5.0/d9/d88/group__cudaarithm__arithm.html#gab3e8900d67c4f59bdc137a0495206cd8)\n\n- [X] **cudabgsegm. Background Segmentation**\n\n- [ ] **cudacodec** Video Encoding/Decoding. The following functions still need implementation:\n    - [ ] [cv::cuda::VideoReader](https://docs.opencv.org/master/db/ded/classcv_1_1cudacodec_1_1VideoReader.html)\n    - [ ] [cv::cuda::VideoWriter](https://docs.opencv.org/master/df/dde/classcv_1_1cudacodec_1_1VideoWriter.html)\n\n- [ ] **cudafeatures2d** Feature Detection and Description. The following functions still need implementation:\n    - [ ] [cv::cuda::FastFeatureDetector](https://docs.opencv.org/master/d4/d6a/classcv_1_1cuda_1_1FastFeatureDetector.html)\n    - [ ] [cv::cuda::ORB](https://docs.opencv.org/master/da/d44/classcv_1_1cuda_1_1ORB.html)\n\n- [ ] **cudafilters. Image Filtering - WORK STARTED** The following functions still need implementation:\n    - [ ] [cv::cuda::createBoxFilter](https://docs.opencv.org/master/dc/d66/group__cudafilters.html#ga3113b66e289bad7caef412e6e13ec2be)\n    - [ ] [cv::cuda::createBoxMaxFilter](https://docs.opencv.org/master/dc/d66/group__cudafilters.html#gaaf4740c51128d23a37f6f1b22cee49e8)\n    - [ ] [cv::cuda::createBoxMinFilter](https://docs.opencv.org/master/dc/d66/group__cudafilters.html#ga77fd36949bc8d92aabc120b4b1cfaafa)\n    - [ ] [cv::cuda::createColumnSumFilter](https://docs.opencv.org/master/dc/d66/group__cudafilters.html#gac13bf7c41a34bfde2a7f33ad8caacfdf)\n    - [ ] [cv::cuda::createDerivFilter](https://docs.opencv.org/master/dc/d66/group__cudafilters.html#ga14d76dc6982ce739c67198f52bc16ee1)\n    - [ ] [cv::cuda::createLaplacianFilter](https://docs.opencv.org/master/dc/d66/group__cudafilters.html#ga53126e88bb7e6185dcd5628e28e42cd2)\n    - [ ] [cv::cuda::createLinearFilter](https://docs.opencv.org/master/dc/d66/group__cudafilters.html#ga57cb1804ad9d1280bf86433858daabf9)\n    - [ ] [cv::cuda::createMorphologyFilter](https://docs.opencv.org/master/dc/d66/group__cudafilters.html#gae58694e07be6bdbae126f36c75c08ee6)\n    - [ ] [cv::cuda::createRowSumFilter](https://docs.opencv.org/master/dc/d66/group__cudafilters.html#gaf735de273ccb5072f3c27816fb97a53a)\n    - [ ] [cv::cuda::createScharrFilter](https://docs.opencv.org/master/dc/d66/group__cudafilters.html#ga4ac8df158e5771ddb0bd5c9091188ce6)\n    - [ ] [cv::cuda::createSeparableLinearFilter](https://docs.opencv.org/master/dc/d66/group__cudafilters.html#gaf7b79a9a92992044f328dad07a52c4bf)\n\n- [ ] **cudaimgproc. Image Processing - WORK STARTED** The following functions still need implementation:\n    - [ ] [cv::cuda::CLAHE](https://docs.opencv.org/master/db/d79/classcv_1_1cuda_1_1CLAHE.html)\n    - [ ] [cv::cuda::HoughCirclesDetector](https://docs.opencv.org/master/da/d80/classcv_1_1cuda_1_1HoughCirclesDetector.html)\n    - [ ] [cv::cuda::createGoodFeaturesToTrackDetector](https://docs.opencv.org/master/dc/d6d/group__cudaimgproc__feature.html#ga478b474a598ece101f7e706fee2c8e91)\n    - [ ] [cv::cuda::createHarrisCorner](https://docs.opencv.org/master/dc/d6d/group__cudaimgproc__feature.html#ga3e5878a803e9bba51added0c10101979)\n    - [ ] [cv::cuda::createMinEigenValCorner](https://docs.opencv.org/master/dc/d6d/group__cudaimgproc__feature.html#ga7457fd4b53b025f990b1c1dd1b749915)\n\n- [X] **cudaobjdetect. Object Detection**\n\n- [ ] **cudaoptflow. Optical Flow - WORK STARTED** The following functions still need implementation:\n    - [ ] [BroxOpticalFlow](https://docs.opencv.org/master/d7/d18/classcv_1_1cuda_1_1BroxOpticalFlow.html)\n    - [ ] [DenseOpticalFlow](https://docs.opencv.org/master/d6/d4a/classcv_1_1cuda_1_1DenseOpticalFlow.html)\n    - [ ] [DensePyrLKOpticalFlow](https://docs.opencv.org/master/d0/da4/classcv_1_1cuda_1_1DensePyrLKOpticalFlow.html)\n    - [ ] [FarnebackOpticalFlow](https://docs.opencv.org/master/d9/d30/classcv_1_1cuda_1_1FarnebackOpticalFlow.html)\n    - [ ] [NvidiaHWOpticalFlow](https://docs.opencv.org/master/d5/d26/classcv_1_1cuda_1_1NvidiaHWOpticalFlow.html)\n    - [ ] [NvidiaOpticalFlow_1_0](https://docs.opencv.org/master/dc/d9d/classcv_1_1cuda_1_1NvidiaOpticalFlow__1__0.html)\n    - [ ] [SparseOpticalFlow](https://docs.opencv.org/master/d5/dcf/classcv_1_1cuda_1_1SparseOpticalFlow.html)\n    - [ ] **[SparsePyrLKOpticalFlow](https://docs.opencv.org/master/d7/d05/classcv_1_1cuda_1_1SparsePyrLKOpticalFlow.html) - WORK STARTED**\n\n- [ ] **cudastereo** Stereo Correspondence\n    - [ ] [cv::cuda::createDisparityBilateralFilter](https://docs.opencv.org/master/dd/d47/group__cudastereo.html#gaafb5f9902f7a9e74cb2cd4e680569590)\n    - [ ] [cv::cuda::createStereoBeliefPropagation](https://docs.opencv.org/master/dd/d47/group__cudastereo.html#ga8d22dd80bdfb4e3d7d2ac09e8a07c22b)\n    - [ ] [cv::cuda::createStereoBM](https://docs.opencv.org/master/dd/d47/group__cudastereo.html#ga77edc901350dd0a7f46ec5aca4138039)\n    - [ ] [cv::cuda::createStereoConstantSpaceBP](https://docs.opencv.org/master/dd/d47/group__cudastereo.html#gaec3b49c7cf9f7701a6f549a227be4df2)\n    - [ ] [cv::cuda::createStereoSGM](https://docs.opencv.org/master/dd/d47/group__cudastereo.html#gafb7e5284de5f488d664c3155acb12c93)\n    - [ ] [cv::cuda::drawColorDisp](https://docs.opencv.org/master/dd/d47/group__cudastereo.html#ga469b23a77938dd7c06861e59cecc08c5)\n    - [ ] [cv::cuda::reprojectImageTo3D](https://docs.opencv.org/master/dd/d47/group__cudastereo.html#gaff851e3932da0f3e74d1be1d8855f094)\n\n- [X] **cudawarping. Image Warping**\n\n## Contrib modules list\n\n- [ ] alphamat. Alpha Matting\n- [ ] barcode. Barcode detecting and decoding methods\n- [ ] **bgsegm. Improved Background-Foreground Segmentation Methods - WORK STARTED**\n- [ ] bioinspired. Biologically inspired vision models and derivated tools\n- [ ] ccalib. Custom Calibration Pattern for 3D reconstruction\n- [ ] cnn_3dobj. 3D object recognition and pose estimation API\n- [ ] cvv. GUI for Interactive Visual Debugging of Computer Vision Programs\n- [ ] datasets. Framework for working with different datasets\n- [ ] dnn_modern. Deep Learning Modern Module\n- [ ] dnn_objdetect. DNN used for object detection\n- [ ] dnn_superres. DNN used for super resolution\n- [ ] dpm. Deformable Part-based Models\n- [ ] **face. Face Recognition - WORK STARTED**\n- [X] freetype. Drawing UTF-8 strings with freetype/harfbuzz\n- [ ] fuzzy. Image processing based on fuzzy mathematics\n- [ ] hdf. Hierarchical Data Format I/O routines\n- [ ] hfs. Hierarchical Feature Selection for Efficient Image Segmentation\n- [X] **img_hash. The module brings implementations of different image hashing algorithms.**\n- [ ] intensity_transform. The module brings implementations of intensity transformation algorithms to adjust image contrast.\n- [ ] line_descriptor. Binary descriptors for lines extracted from an image\n- [ ] mcc. Macbeth Chart module\n- [ ] optflow. Optical Flow Algorithms\n- [ ] ovis. OGRE 3D Visualiser\n- [ ] phase_unwrapping. Phase Unwrapping API\n- [ ] plot. Plot function for Mat data\n- [ ] quality. Image Quality Analysis (IQA) API\n- [ ] rapid. silhouette based 3D object tracking\n- [ ] reg. Image Registration\n- [ ] rgbd. RGB-Depth Processing\n- [ ] saliency. Saliency API\n- [ ] sfm. Structure From Motion\n- [ ] shape. Shape Distance and Matching\n- [ ] signal. Signal Processing\n- [ ] stereo. Stereo Correspondance Algorithms\n- [ ] structured_light. Structured Light API\n- [ ] superres. Super Resolution\n- [ ] surface_matching. Surface Matching\n- [ ] text. Scene Text Detection and Recognition\n- [ ] **tracking. Tracking API - WORK STARTED**\n- [ ] videostab. Video Stabilization\n- [ ] viz. 3D Visualizer\n- [X] **wechat_qrcode. WeChat QR code detector for detecting and parsing QR code**\n- [ ] **xfeatures2d. Extra 2D Features Framework - WORK STARTED**\n- [ ] **ximgproc. Extended Image Processing - WORK STARTED**\n- [ ] xobjdetect. Extended object detection\n- [X] **xphoto. Additional photo processing algorithms**\n"
        },
        {
          "name": "aruco.cpp",
          "type": "blob",
          "size": 10.396484375,
          "content": "#include \"aruco.h\"\n\nArucoDetector ArucoDetector_New() {\n    return new cv::aruco::ArucoDetector();\n}\n\nArucoDetector ArucoDetector_NewWithParams(ArucoDictionary dictionary, ArucoDetectorParameters params) {\n    return new cv::aruco::ArucoDetector(*dictionary, *params);\n}\n\nvoid ArucoDetector_Close(ArucoDetector ad) {\n    delete ad;\n}\n\nvoid ArucoDetector_DetectMarkers(ArucoDetector ad, Mat inputArr, Points2fVector markerCorners, IntVector *markerIds, Points2fVector rejectedCandidates) {\n    std::vector<int> _markerIds;\n    ad->detectMarkers(*inputArr, *markerCorners, _markerIds, *rejectedCandidates);\n\n    int *ids = new int[_markerIds.size()];\n\n    for (size_t i = 0; i < _markerIds.size(); ++i)\n    {\n        ids[i] = _markerIds[i];\n    }\n\n    markerIds->length = _markerIds.size();\n    markerIds->val = ids;\n}\n\nArucoDetectorParameters ArucoDetectorParameters_Create()\n{\n    return new cv::aruco::DetectorParameters();\n}\n\nvoid ArucoDetectorParameters_SetAdaptiveThreshWinSizeMin(ArucoDetectorParameters ap, int adaptiveThreshWinSizeMin) {\n    ap->adaptiveThreshWinSizeMin = adaptiveThreshWinSizeMin;\n}\n\nint ArucoDetectorParameters_GetAdaptiveThreshWinSizeMin(ArucoDetectorParameters ap) {\n    return ap->adaptiveThreshWinSizeMin;\n}\n\nvoid ArucoDetectorParameters_SetAdaptiveThreshWinSizeMax(ArucoDetectorParameters ap, int adaptiveThreshWinSizeMax) {\n    ap->adaptiveThreshWinSizeMax = adaptiveThreshWinSizeMax;\n}\n\nint ArucoDetectorParameters_GetAdaptiveThreshWinSizeMax(ArucoDetectorParameters ap) {\n    return ap->adaptiveThreshWinSizeMax;\n}\n\nvoid ArucoDetectorParameters_SetAdaptiveThreshWinSizeStep(ArucoDetectorParameters ap, int adaptiveThreshWinSizeStep) {\n    ap->adaptiveThreshWinSizeStep = adaptiveThreshWinSizeStep;\n}\n\nint ArucoDetectorParameters_GetAdaptiveThreshWinSizeStep(ArucoDetectorParameters ap) {\n    return ap->adaptiveThreshWinSizeStep;\n}\n\nvoid ArucoDetectorParameters_SetAdaptiveThreshConstant(ArucoDetectorParameters ap, double adaptiveThreshConstant) {\n    ap->adaptiveThreshConstant = adaptiveThreshConstant;\n}\n\ndouble ArucoDetectorParameters_GetAdaptiveThreshConstant(ArucoDetectorParameters ap) {\n    return ap->adaptiveThreshConstant;\n}\n\nvoid ArucoDetectorParameters_SetMinMarkerPerimeterRate(ArucoDetectorParameters ap, double minMarkerPerimeterRate) {\n    ap->minMarkerPerimeterRate = minMarkerPerimeterRate;\n}\n\ndouble ArucoDetectorParameters_GetMinMarkerPerimeterRate(ArucoDetectorParameters ap){\n    return ap->minMarkerPerimeterRate;\n}\n\nvoid ArucoDetectorParameters_SetMaxMarkerPerimeterRate(ArucoDetectorParameters ap, double maxMarkerPerimeterRate) {\n    ap->maxMarkerPerimeterRate = maxMarkerPerimeterRate;\n}\n\ndouble ArucoDetectorParameters_GetMaxMarkerPerimeterRate(ArucoDetectorParameters ap){\n    return ap->maxMarkerPerimeterRate;\n}\n\nvoid ArucoDetectorParameters_SetPolygonalApproxAccuracyRate(ArucoDetectorParameters ap, double polygonalApproxAccuracyRate) {\n    ap->polygonalApproxAccuracyRate = polygonalApproxAccuracyRate;\n}\n\ndouble ArucoDetectorParameters_GetPolygonalApproxAccuracyRate(ArucoDetectorParameters ap){\n    return ap->polygonalApproxAccuracyRate;\n}\n\nvoid ArucoDetectorParameters_SetMinCornerDistanceRate(ArucoDetectorParameters ap, double minCornerDistanceRate) {\n    ap->minCornerDistanceRate = minCornerDistanceRate;\n}\n\ndouble ArucoDetectorParameters_GetMinCornerDistanceRate(ArucoDetectorParameters ap) {\n    return ap->minCornerDistanceRate;\n}\n\nvoid ArucoDetectorParameters_SetMinDistanceToBorder(ArucoDetectorParameters ap, int minDistanceToBorder) {\n    ap->minDistanceToBorder = minDistanceToBorder;\n}\n\nint ArucoDetectorParameters_GetMinDistanceToBorder(ArucoDetectorParameters ap) {\n    return ap->minDistanceToBorder;\n}\n\nvoid ArucoDetectorParameters_SetMinMarkerDistanceRate(ArucoDetectorParameters ap, double minMarkerDistanceRate) {\n    ap->minMarkerDistanceRate = minMarkerDistanceRate;\n}\n\ndouble ArucoDetectorParameters_GetMinMarkerDistanceRate(ArucoDetectorParameters ap) {\n    return ap->minMarkerDistanceRate;\n}\n\nvoid ArucoDetectorParameters_SetCornerRefinementMethod(ArucoDetectorParameters ap, int cornerRefinementMethod) {\n    ap->cornerRefinementMethod = cv::aruco::CornerRefineMethod(cornerRefinementMethod);\n}\n\nint ArucoDetectorParameters_GetCornerRefinementMethod(ArucoDetectorParameters ap) {\n    return ap->cornerRefinementMethod;\n}\n\nvoid ArucoDetectorParameters_SetCornerRefinementWinSize(ArucoDetectorParameters ap, int cornerRefinementWinSize) {\n    ap->cornerRefinementWinSize = cornerRefinementWinSize;   \n}\n\nint ArucoDetectorParameters_GetCornerRefinementWinSize(ArucoDetectorParameters ap) {\n    return ap->cornerRefinementWinSize;\n}\n\nvoid ArucoDetectorParameters_SetCornerRefinementMaxIterations(ArucoDetectorParameters ap, int cornerRefinementMaxIterations) {\n    ap->cornerRefinementMaxIterations = cornerRefinementMaxIterations;\n}\n\nint ArucoDetectorParameters_GetCornerRefinementMaxIterations(ArucoDetectorParameters ap) {\n    return ap->cornerRefinementMaxIterations;\n}\n\nvoid ArucoDetectorParameters_SetCornerRefinementMinAccuracy(ArucoDetectorParameters ap, double cornerRefinementMinAccuracy) {\n    ap->cornerRefinementMinAccuracy = cornerRefinementMinAccuracy;\n}\n\ndouble ArucoDetectorParameters_GetCornerRefinementMinAccuracy(ArucoDetectorParameters ap) {\n    return ap->cornerRefinementMinAccuracy;\n}\n\nvoid ArucoDetectorParameters_SetMarkerBorderBits(ArucoDetectorParameters ap, int markerBorderBits) {\n    ap->markerBorderBits = markerBorderBits;\n}\n\nint ArucoDetectorParameters_GetMarkerBorderBits(ArucoDetectorParameters ap) {\n    return ap->markerBorderBits;\n}\n\nvoid ArucoDetectorParameters_SetPerspectiveRemovePixelPerCell(ArucoDetectorParameters ap, int perspectiveRemovePixelPerCell) {\n    ap->perspectiveRemovePixelPerCell = perspectiveRemovePixelPerCell;\n}\n\nint ArucoDetectorParameters_GetPerspectiveRemovePixelPerCell(ArucoDetectorParameters ap) {\n    return ap->perspectiveRemovePixelPerCell;\n}\n\nvoid ArucoDetectorParameters_SetPerspectiveRemoveIgnoredMarginPerCell(ArucoDetectorParameters ap, double perspectiveRemoveIgnoredMarginPerCell) {\n    ap->perspectiveRemoveIgnoredMarginPerCell = perspectiveRemoveIgnoredMarginPerCell;\n}\n\ndouble ArucoDetectorParameters_GetPerspectiveRemoveIgnoredMarginPerCell(ArucoDetectorParameters ap) {\n    return ap->perspectiveRemoveIgnoredMarginPerCell;\n}\n\nvoid ArucoDetectorParameters_SetMaxErroneousBitsInBorderRate(ArucoDetectorParameters ap, double maxErroneousBitsInBorderRate) {\n    ap->maxErroneousBitsInBorderRate = maxErroneousBitsInBorderRate;\n}\n\ndouble ArucoDetectorParameters_GetMaxErroneousBitsInBorderRate(ArucoDetectorParameters ap) {\n    return ap->maxErroneousBitsInBorderRate;\n}\n\nvoid ArucoDetectorParameters_SetMinOtsuStdDev(ArucoDetectorParameters ap, double minOtsuStdDev) {\n    ap->minOtsuStdDev = minOtsuStdDev;\n}\n\ndouble ArucoDetectorParameters_GetMinOtsuStdDev(ArucoDetectorParameters ap) {\n    return ap->minOtsuStdDev;\n}\n\nvoid ArucoDetectorParameters_SetErrorCorrectionRate(ArucoDetectorParameters ap, double errorCorrectionRate) {\n    ap->errorCorrectionRate = errorCorrectionRate;\n}\n\ndouble ArucoDetectorParameters_GetErrorCorrectionRate(ArucoDetectorParameters ap) {\n    return ap->errorCorrectionRate;\n}\n\nvoid ArucoDetectorParameters_SetAprilTagQuadDecimate(ArucoDetectorParameters ap, float aprilTagQuadDecimate) {\n    ap->aprilTagQuadDecimate = aprilTagQuadDecimate;\n}\n\nfloat ArucoDetectorParameters_GetAprilTagQuadDecimate(ArucoDetectorParameters ap) {\n    return ap->aprilTagQuadDecimate;\n}\n\nvoid ArucoDetectorParameters_SetAprilTagQuadSigma(ArucoDetectorParameters ap, float aprilTagQuadSigma) {\n    ap->aprilTagQuadSigma = aprilTagQuadSigma;\n}\n\nfloat ArucoDetectorParameters_GetAprilTagQuadSigma(ArucoDetectorParameters ap) {\n    return ap->aprilTagQuadSigma;\n}\n\nvoid ArucoDetectorParameters_SetAprilTagMinClusterPixels(ArucoDetectorParameters ap, int aprilTagMinClusterPixels) {\n    ap->aprilTagMinClusterPixels = aprilTagMinClusterPixels;\n}\n\nint ArucoDetectorParameters_GetAprilTagMinClusterPixels(ArucoDetectorParameters ap) {\n    return ap->aprilTagMinClusterPixels;\n}\n\nvoid ArucoDetectorParameters_SetAprilTagMaxNmaxima(ArucoDetectorParameters ap, int aprilTagMaxNmaxima) {\n    ap->aprilTagMaxNmaxima = aprilTagMaxNmaxima;\n}\n\nint ArucoDetectorParameters_GetAprilTagMaxNmaxima(ArucoDetectorParameters ap) {\n    return ap->aprilTagMaxNmaxima;\n}\n\nvoid ArucoDetectorParameters_SetAprilTagCriticalRad(ArucoDetectorParameters ap, float aprilTagCriticalRad) {\n    ap->aprilTagCriticalRad = aprilTagCriticalRad;\n}\n\nfloat ArucoDetectorParameters_GetAprilTagCriticalRad(ArucoDetectorParameters ap) {\n    return ap->aprilTagCriticalRad;\n}\n\nvoid ArucoDetectorParameters_SetAprilTagMaxLineFitMse(ArucoDetectorParameters ap, float aprilTagMaxLineFitMse) {\n    ap->aprilTagMaxLineFitMse = aprilTagMaxLineFitMse;\n}\n\nfloat ArucoDetectorParameters_GetAprilTagMaxLineFitMse(ArucoDetectorParameters ap) {\n    return ap->aprilTagMaxLineFitMse;\n}\n\nvoid ArucoDetectorParameters_SetAprilTagMinWhiteBlackDiff(ArucoDetectorParameters ap, int aprilTagMinWhiteBlackDiff) {\n    ap->aprilTagMinWhiteBlackDiff = aprilTagMinWhiteBlackDiff;\n}\n\nint ArucoDetectorParameters_GetAprilTagMinWhiteBlackDiff(ArucoDetectorParameters ap) {\n    return ap->aprilTagMinWhiteBlackDiff;\n}\n\nvoid ArucoDetectorParameters_SetAprilTagDeglitch(ArucoDetectorParameters ap, int aprilTagDeglitch) {\n    ap->aprilTagDeglitch = aprilTagDeglitch;\n}\n\nint ArucoDetectorParameters_GetAprilTagDeglitch(ArucoDetectorParameters ap) {\n    return ap->aprilTagDeglitch;\n}\n\nvoid ArucoDetectorParameters_SetDetectInvertedMarker(ArucoDetectorParameters ap, bool detectInvertedMarker) {\n    ap->detectInvertedMarker = detectInvertedMarker;\n}\n\nbool ArucoDetectorParameters_GetDetectInvertedMarker(ArucoDetectorParameters ap) {\n    return ap->detectInvertedMarker;\n}\n\nvoid ArucoDrawDetectedMarkers(Mat image, Points2fVector markerCorners, IntVector markerIds, Scalar borderColor)\n{\n    std::vector<int> _markerIds;\n    for (int i = 0, *v = markerIds.val; i < markerIds.length; ++v, ++i)\n    {\n        _markerIds.push_back(*v);\n    }\n    cv::Scalar _borderColor = cv::Scalar(borderColor.val1, borderColor.val2, borderColor.val3);\n    cv::aruco::drawDetectedMarkers(*image, *markerCorners, _markerIds, _borderColor);\n}\n\nvoid ArucoGenerateImageMarker(int dictionaryId, int id, int sidePixels, Mat img, int borderBits)\n{\n    cv::aruco::Dictionary dict = cv::aruco::getPredefinedDictionary(dictionaryId);\n    cv::aruco::generateImageMarker(dict, id, sidePixels, *img, borderBits);\n}\n\nArucoDictionary getPredefinedDictionary(int dictionaryId)\n{\n    return new cv::aruco::Dictionary(cv::aruco::getPredefinedDictionary(dictionaryId));\n}"
        },
        {
          "name": "aruco.go",
          "type": "blob",
          "size": 12.4248046875,
          "content": "package gocv\n\n/*\n#include <stdlib.h>\n#include \"aruco.h\"\n#include \"core.h\"\n*/\nimport \"C\"\n\nimport (\n\t\"reflect\"\n\t\"unsafe\"\n)\n\ntype ArucoDetector struct {\n\tp C.ArucoDetector\n}\n\n// NewArucoDetector returns a new ArucoDetector.\nfunc NewArucoDetector() ArucoDetector {\n\treturn ArucoDetector{p: C.ArucoDetector_New()}\n}\n\n// NewArucoDetectorWithParams returns a new ArucoDetector.\nfunc NewArucoDetectorWithParams(dictionary ArucoDictionary, params ArucoDetectorParameters) ArucoDetector {\n\treturn ArucoDetector{p: C.ArucoDetector_NewWithParams(dictionary.p, params.p)}\n}\n\n// Close deletes the ArucoDetector's pointer.\nfunc (a *ArucoDetector) Close() error {\n\tC.ArucoDetector_Close(a.p)\n\ta.p = nil\n\treturn nil\n}\n\n// DetectMarkers does basic marker detection.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d9/d6a/group__aruco.html#gab9159aa69250d8d3642593e508cb6baa\nfunc (a *ArucoDetector) DetectMarkers(input Mat) (\n\tmarkerCorners [][]Point2f, markerIds []int, rejectedCandidates [][]Point2f,\n) {\n\n\tpvsCorners := NewPoints2fVector()\n\tdefer pvsCorners.Close()\n\tpvsRejected := NewPoints2fVector()\n\tdefer pvsRejected.Close()\n\tcmarkerIds := C.IntVector{}\n\tdefer C.free(unsafe.Pointer(cmarkerIds.val))\n\n\tC.ArucoDetector_DetectMarkers(a.p, C.Mat(input.Ptr()), C.Points2fVector(pvsCorners.P()),\n\t\t&cmarkerIds, C.Points2fVector(pvsRejected.P()))\n\n\th := &reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(cmarkerIds.val)),\n\t\tLen:  int(cmarkerIds.length),\n\t\tCap:  int(cmarkerIds.length),\n\t}\n\tpcids := *(*[]C.int)(unsafe.Pointer(h))\n\tmarkerIds = []int{}\n\tfor i := 0; i < int(cmarkerIds.length); i++ {\n\t\tmarkerIds = append(markerIds, int(pcids[i]))\n\t}\n\n\treturn pvsCorners.ToPoints(), markerIds, pvsRejected.ToPoints()\n}\n\nfunc ArucoDrawDetectedMarkers(img Mat, markerCorners [][]Point2f, markerIds []int, borderColor Scalar) {\n\tcMarkerIds := make([]C.int, len(markerIds))\n\tfor i, s := range markerIds {\n\t\tcMarkerIds[i] = C.int(s)\n\t}\n\tmarkerIdsIntVec := C.IntVector{\n\t\tval:    (*C.int)(&cMarkerIds[0]),\n\t\tlength: C.int(len(cMarkerIds)),\n\t}\n\t_markerCorners := NewPoints2fVectorFromPoints(markerCorners)\n\n\tcBorderColor := C.struct_Scalar{\n\t\tval1: C.double(borderColor.Val1),\n\t\tval2: C.double(borderColor.Val2),\n\t\tval3: C.double(borderColor.Val3),\n\t\tval4: C.double(borderColor.Val4),\n\t}\n\n\tC.ArucoDrawDetectedMarkers(\n\t\tC.Mat(img.Ptr()),\n\t\tC.Points2fVector(_markerCorners.P()),\n\t\tmarkerIdsIntVec,\n\t\tcBorderColor,\n\t)\n}\n\nfunc ArucoGenerateImageMarker(dictionaryId ArucoDictionaryCode, id int, sidePixels int, img Mat, borderBits int) {\n\tC.ArucoGenerateImageMarker(C.int(dictionaryId), C.int(id), C.int(sidePixels), C.Mat(img.Ptr()), C.int(borderBits))\n}\n\ntype ArucoDetectorParameters struct {\n\tp C.ArucoDetectorParameters\n}\n\n// NewArucoDetectorParameters returns the default parameters for the SimpleBobDetector\nfunc NewArucoDetectorParameters() ArucoDetectorParameters {\n\treturn ArucoDetectorParameters{p: C.ArucoDetectorParameters_Create()}\n}\n\nfunc (ap *ArucoDetectorParameters) SetAdaptiveThreshWinSizeMin(adaptiveThreshWinSizeMin int) {\n\tC.ArucoDetectorParameters_SetAdaptiveThreshWinSizeMin(ap.p, C.int(adaptiveThreshWinSizeMin))\n}\n\nfunc (ap *ArucoDetectorParameters) GetAdaptiveThreshWinSizeMin() int {\n\treturn int(C.ArucoDetectorParameters_GetAdaptiveThreshWinSizeMin(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetAdaptiveThreshWinSizeMax(adaptiveThreshWinSizeMax int) {\n\tC.ArucoDetectorParameters_SetAdaptiveThreshWinSizeMax(ap.p, C.int(adaptiveThreshWinSizeMax))\n}\n\nfunc (ap *ArucoDetectorParameters) GetAdaptiveThreshWinSizeMax() int {\n\treturn int(C.ArucoDetectorParameters_GetAdaptiveThreshWinSizeMax(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetAdaptiveThreshWinSizeStep(adaptiveThreshWinSizeStep int) {\n\tC.ArucoDetectorParameters_SetAdaptiveThreshWinSizeStep(ap.p, C.int(adaptiveThreshWinSizeStep))\n}\n\nfunc (ap *ArucoDetectorParameters) GetAdaptiveThreshWinSizeStep() int {\n\treturn int(C.ArucoDetectorParameters_GetAdaptiveThreshWinSizeStep(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetAdaptiveThreshConstant(adaptiveThreshConstant float64) {\n\tC.ArucoDetectorParameters_SetAdaptiveThreshConstant(ap.p, C.double(adaptiveThreshConstant))\n}\n\nfunc (ap *ArucoDetectorParameters) GetAdaptiveThreshConstant() float64 {\n\treturn float64(C.ArucoDetectorParameters_GetAdaptiveThreshConstant(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetMinMarkerPerimeterRate(minMarkerPerimeterRate float64) {\n\tC.ArucoDetectorParameters_SetMinMarkerPerimeterRate(ap.p, C.double(minMarkerPerimeterRate))\n}\n\nfunc (ap *ArucoDetectorParameters) GetMinMarkerPerimeterRate() float64 {\n\treturn float64(C.ArucoDetectorParameters_GetMinMarkerPerimeterRate(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetMaxMarkerPerimeterRate(maxMarkerPerimeterRate float64) {\n\tC.ArucoDetectorParameters_SetMaxMarkerPerimeterRate(ap.p, C.double(maxMarkerPerimeterRate))\n}\n\nfunc (ap *ArucoDetectorParameters) GetMaxMarkerPerimeterRate() float64 {\n\treturn float64(C.ArucoDetectorParameters_GetMaxMarkerPerimeterRate(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetPolygonalApproxAccuracyRate(polygonalApproxAccuracyRate float64) {\n\tC.ArucoDetectorParameters_SetPolygonalApproxAccuracyRate(ap.p, C.double(polygonalApproxAccuracyRate))\n}\n\nfunc (ap *ArucoDetectorParameters) GetPolygonalApproxAccuracyRate() float64 {\n\treturn float64(C.ArucoDetectorParameters_GetPolygonalApproxAccuracyRate(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetMinCornerDistanceRate(minCornerDistanceRate float64) {\n\tC.ArucoDetectorParameters_SetMinCornerDistanceRate(ap.p, C.double(minCornerDistanceRate))\n}\n\nfunc (ap *ArucoDetectorParameters) GetMinCornerDistanceRate() float64 {\n\treturn float64(C.ArucoDetectorParameters_GetMinCornerDistanceRate(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetMinDistanceToBorder(minDistanceToBorder int) {\n\tC.ArucoDetectorParameters_SetMinDistanceToBorder(ap.p, C.int(minDistanceToBorder))\n}\n\nfunc (ap *ArucoDetectorParameters) GetMinDistanceToBorder() int {\n\treturn int(C.ArucoDetectorParameters_GetMinDistanceToBorder(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetMinMarkerDistanceRate(minMarkerDistanceRate float64) {\n\tC.ArucoDetectorParameters_SetMinMarkerDistanceRate(ap.p, C.double(minMarkerDistanceRate))\n}\n\nfunc (ap *ArucoDetectorParameters) GetMinMarkerDistanceRate() float64 {\n\treturn float64(C.ArucoDetectorParameters_GetMinMarkerDistanceRate(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetCornerRefinementMethod(cornerRefinementMethod int) {\n\tC.ArucoDetectorParameters_SetCornerRefinementMethod(ap.p, C.int(cornerRefinementMethod))\n}\n\nfunc (ap *ArucoDetectorParameters) GetCornerRefinementMethod() int {\n\treturn int(C.ArucoDetectorParameters_GetCornerRefinementMethod(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetCornerRefinementWinSize(cornerRefinementWinSize int) {\n\tC.ArucoDetectorParameters_SetCornerRefinementWinSize(ap.p, C.int(cornerRefinementWinSize))\n}\n\nfunc (ap *ArucoDetectorParameters) GetCornerRefinementWinSize() int {\n\treturn int(C.ArucoDetectorParameters_GetCornerRefinementWinSize(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetCornerRefinementMaxIterations(cornerRefinementMaxIterations int) {\n\tC.ArucoDetectorParameters_SetCornerRefinementMaxIterations(ap.p, C.int(cornerRefinementMaxIterations))\n}\n\nfunc (ap *ArucoDetectorParameters) GetCornerRefinementMaxIterations() int {\n\treturn int(C.ArucoDetectorParameters_GetCornerRefinementMaxIterations(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetCornerRefinementMinAccuracy(cornerRefinementMinAccuracy float64) {\n\tC.ArucoDetectorParameters_SetCornerRefinementMinAccuracy(ap.p, C.double(cornerRefinementMinAccuracy))\n}\n\nfunc (ap *ArucoDetectorParameters) GetCornerRefinementMinAccuracy() float64 {\n\treturn float64(C.ArucoDetectorParameters_GetCornerRefinementMinAccuracy(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetMarkerBorderBits(markerBorderBits int) {\n\tC.ArucoDetectorParameters_SetMarkerBorderBits(ap.p, C.int(markerBorderBits))\n}\n\nfunc (ap *ArucoDetectorParameters) GetMarkerBorderBits() int {\n\treturn int(C.ArucoDetectorParameters_GetMarkerBorderBits(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetPerspectiveRemovePixelPerCell(perspectiveRemovePixelPerCell int) {\n\tC.ArucoDetectorParameters_SetPerspectiveRemovePixelPerCell(ap.p, C.int(perspectiveRemovePixelPerCell))\n}\n\nfunc (ap *ArucoDetectorParameters) GetPerspectiveRemovePixelPerCell() int {\n\treturn int(C.ArucoDetectorParameters_GetPerspectiveRemovePixelPerCell(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetPerspectiveRemoveIgnoredMarginPerCell(perspectiveRemoveIgnoredMarginPerCell float64) {\n\tC.ArucoDetectorParameters_SetPerspectiveRemoveIgnoredMarginPerCell(ap.p, C.double(perspectiveRemoveIgnoredMarginPerCell))\n}\n\nfunc (ap *ArucoDetectorParameters) GetPerspectiveRemoveIgnoredMarginPerCell() float64 {\n\treturn float64(C.ArucoDetectorParameters_GetPerspectiveRemoveIgnoredMarginPerCell(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetMaxErroneousBitsInBorderRate(maxErroneousBitsInBorderRate float64) {\n\tC.ArucoDetectorParameters_SetMaxErroneousBitsInBorderRate(ap.p, C.double(maxErroneousBitsInBorderRate))\n}\n\nfunc (ap *ArucoDetectorParameters) GetMaxErroneousBitsInBorderRate() float64 {\n\treturn float64(C.ArucoDetectorParameters_GetMaxErroneousBitsInBorderRate(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetMinOtsuStdDev(minOtsuStdDev float64) {\n\tC.ArucoDetectorParameters_SetMinOtsuStdDev(ap.p, C.double(minOtsuStdDev))\n}\n\nfunc (ap *ArucoDetectorParameters) GetMinOtsuStdDev() float64 {\n\treturn float64(C.ArucoDetectorParameters_GetMinOtsuStdDev(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetErrorCorrectionRate(errorCorrectionRate float64) {\n\tC.ArucoDetectorParameters_SetErrorCorrectionRate(ap.p, C.double(errorCorrectionRate))\n}\n\nfunc (ap *ArucoDetectorParameters) GetErrorCorrectionRate() float64 {\n\treturn float64(C.ArucoDetectorParameters_GetErrorCorrectionRate(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetAprilTagQuadDecimate(aprilTagQuadDecimate float32) {\n\tC.ArucoDetectorParameters_SetAprilTagQuadDecimate(ap.p, C.float(aprilTagQuadDecimate))\n}\n\nfunc (ap *ArucoDetectorParameters) GetAprilTagQuadDecimate() float32 {\n\treturn float32(C.ArucoDetectorParameters_GetAprilTagQuadDecimate(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetAprilTagQuadSigma(aprilTagQuadSigma float32) {\n\tC.ArucoDetectorParameters_SetAprilTagQuadSigma(ap.p, C.float(aprilTagQuadSigma))\n}\n\nfunc (ap *ArucoDetectorParameters) GetAprilTagQuadSigma() float32 {\n\treturn float32(C.ArucoDetectorParameters_GetAprilTagQuadSigma(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetAprilTagMinClusterPixels(aprilTagMinClusterPixels int) {\n\tC.ArucoDetectorParameters_SetAprilTagMinClusterPixels(ap.p, C.int(aprilTagMinClusterPixels))\n}\n\nfunc (ap *ArucoDetectorParameters) GetAprilTagMinClusterPixels() int {\n\treturn int(C.ArucoDetectorParameters_GetAprilTagMinClusterPixels(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetAprilTagMaxNmaxima(aprilTagMaxNmaxima int) {\n\tC.ArucoDetectorParameters_SetAprilTagMaxNmaxima(ap.p, C.int(aprilTagMaxNmaxima))\n}\n\nfunc (ap *ArucoDetectorParameters) GetAprilTagMaxNmaxima() int {\n\treturn int(C.ArucoDetectorParameters_GetAprilTagMaxNmaxima(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetAprilTagCriticalRad(aprilTagCriticalRad float32) {\n\tC.ArucoDetectorParameters_SetAprilTagCriticalRad(ap.p, C.float(aprilTagCriticalRad))\n}\n\nfunc (ap *ArucoDetectorParameters) GetAprilTagCriticalRad() float32 {\n\treturn float32(C.ArucoDetectorParameters_GetAprilTagCriticalRad(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetAprilTagMaxLineFitMse(aprilTagMaxLineFitMse float32) {\n\tC.ArucoDetectorParameters_SetAprilTagMaxLineFitMse(ap.p, C.float(aprilTagMaxLineFitMse))\n}\n\nfunc (ap *ArucoDetectorParameters) GetAprilTagMaxLineFitMse() float32 {\n\treturn float32(C.ArucoDetectorParameters_GetAprilTagMaxLineFitMse(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetAprilTagMinWhiteBlackDiff(aprilTagMinWhiteBlackDiff int) {\n\tC.ArucoDetectorParameters_SetAprilTagMinWhiteBlackDiff(ap.p, C.int(aprilTagMinWhiteBlackDiff))\n}\n\nfunc (ap *ArucoDetectorParameters) GetAprilTagMinWhiteBlackDiff() int {\n\treturn int(C.ArucoDetectorParameters_GetAprilTagMinWhiteBlackDiff(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetAprilTagDeglitch(aprilTagDeglitch int) {\n\tC.ArucoDetectorParameters_SetAprilTagDeglitch(ap.p, C.int(aprilTagDeglitch))\n}\n\nfunc (ap *ArucoDetectorParameters) GetAprilTagDeglitch() int {\n\treturn int(C.ArucoDetectorParameters_GetAprilTagDeglitch(ap.p))\n}\n\nfunc (ap *ArucoDetectorParameters) SetDetectInvertedMarker(detectInvertedMarker bool) {\n\tC.ArucoDetectorParameters_SetDetectInvertedMarker(ap.p, C.bool(detectInvertedMarker))\n}\n\nfunc (ap *ArucoDetectorParameters) GetDetectInvertedMarker() bool {\n\treturn bool(C.ArucoDetectorParameters_GetDetectInvertedMarker(ap.p))\n}\n"
        },
        {
          "name": "aruco.h",
          "type": "blob",
          "size": 6.7724609375,
          "content": "#ifndef _OPENCV3_ARUCO_H_\n#define _OPENCV3_ARUCO_H_\n\n#ifdef __cplusplus\n#include <opencv2/opencv.hpp>\nextern \"C\" {\n#endif\n\n#include \"core.h\"\n\n#ifdef __cplusplus\ntypedef cv::aruco::Dictionary* ArucoDictionary;\ntypedef cv::aruco::DetectorParameters* ArucoDetectorParameters; \ntypedef cv::aruco::ArucoDetector* ArucoDetector;\n#else\ntypedef void *ArucoDictionary;\ntypedef void *ArucoDetectorParameters;\ntypedef void *ArucoDetector;\n#endif\n\nArucoDetectorParameters ArucoDetectorParameters_Create();\nvoid ArucoDetectorParameters_SetAdaptiveThreshWinSizeMin(ArucoDetectorParameters ap, int adaptiveThreshWinSizeMin);\nint ArucoDetectorParameters_GetAdaptiveThreshWinSizeMin(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetAdaptiveThreshWinSizeMax(ArucoDetectorParameters ap, int adaptiveThreshWinSizeMax);\nint ArucoDetectorParameters_GetAdaptiveThreshWinSizeMax(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetAdaptiveThreshWinSizeStep(ArucoDetectorParameters ap, int adaptiveThreshWinSizeStep);\nint ArucoDetectorParameters_GetAdaptiveThreshWinSizeStep(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetAdaptiveThreshConstant(ArucoDetectorParameters ap, double adaptiveThreshConstant);\ndouble ArucoDetectorParameters_GetAdaptiveThreshConstant(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetMinMarkerPerimeterRate(ArucoDetectorParameters ap, double minMarkerPerimeterRate);\ndouble ArucoDetectorParameters_GetMinMarkerPerimeterRate(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetMaxMarkerPerimeterRate(ArucoDetectorParameters ap, double maxMarkerPerimeterRate);\ndouble ArucoDetectorParameters_GetMaxMarkerPerimeterRate(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetPolygonalApproxAccuracyRate(ArucoDetectorParameters ap, double polygonalApproxAccuracyRate);\ndouble ArucoDetectorParameters_GetPolygonalApproxAccuracyRate(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetMinCornerDistanceRate(ArucoDetectorParameters ap, double minCornerDistanceRate);\ndouble ArucoDetectorParameters_GetMinCornerDistanceRate(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetMinDistanceToBorder(ArucoDetectorParameters ap, int minDistanceToBorder);\nint ArucoDetectorParameters_GetMinDistanceToBorder(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetMinMarkerDistanceRate(ArucoDetectorParameters ap, double minMarkerDistanceRate);\ndouble ArucoDetectorParameters_GetMinMarkerDistanceRate(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetCornerRefinementMethod(ArucoDetectorParameters ap, int cornerRefinementMethod);\nint ArucoDetectorParameters_GetCornerRefinementMethod(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetCornerRefinementWinSize(ArucoDetectorParameters ap, int cornerRefinementWinSize);\nint ArucoDetectorParameters_GetCornerRefinementWinSize(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetCornerRefinementMaxIterations(ArucoDetectorParameters ap, int cornerRefinementMaxIterations);\nint ArucoDetectorParameters_GetCornerRefinementMaxIterations(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetCornerRefinementMinAccuracy(ArucoDetectorParameters ap, double cornerRefinementMinAccuracy);\ndouble ArucoDetectorParameters_GetCornerRefinementMinAccuracy(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetMarkerBorderBits(ArucoDetectorParameters ap, int markerBorderBits);\nint ArucoDetectorParameters_GetMarkerBorderBits(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetPerspectiveRemovePixelPerCell(ArucoDetectorParameters ap, int perspectiveRemovePixelPerCell);\nint ArucoDetectorParameters_GetPerspectiveRemovePixelPerCell(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetPerspectiveRemoveIgnoredMarginPerCell(ArucoDetectorParameters ap, double perspectiveRemoveIgnoredMarginPerCell);\ndouble ArucoDetectorParameters_GetPerspectiveRemoveIgnoredMarginPerCell(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetMaxErroneousBitsInBorderRate(ArucoDetectorParameters ap, double maxErroneousBitsInBorderRate);\ndouble ArucoDetectorParameters_GetMaxErroneousBitsInBorderRate(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetMinOtsuStdDev(ArucoDetectorParameters ap, double minOtsuStdDev);\ndouble ArucoDetectorParameters_GetMinOtsuStdDev(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetErrorCorrectionRate(ArucoDetectorParameters ap, double errorCorrectionRate);\ndouble ArucoDetectorParameters_GetErrorCorrectionRate(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetAprilTagQuadDecimate(ArucoDetectorParameters ap, float aprilTagQuadDecimate);\nfloat ArucoDetectorParameters_GetAprilTagQuadDecimate(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetAprilTagQuadSigma(ArucoDetectorParameters ap, float aprilTagQuadSigma);\nfloat ArucoDetectorParameters_GetAprilTagQuadSigma(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetAprilTagMinClusterPixels(ArucoDetectorParameters ap, int aprilTagMinClusterPixels);\nint ArucoDetectorParameters_GetAprilTagMinClusterPixels(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetAprilTagMaxNmaxima(ArucoDetectorParameters ap, int aprilTagMaxNmaxima);\nint ArucoDetectorParameters_GetAprilTagMaxNmaxima(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetAprilTagCriticalRad(ArucoDetectorParameters ap, float aprilTagCriticalRad);\nfloat ArucoDetectorParameters_GetAprilTagCriticalRad(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetAprilTagMaxLineFitMse(ArucoDetectorParameters ap, float aprilTagMaxLineFitMse);\nfloat ArucoDetectorParameters_GetAprilTagMaxLineFitMse(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetAprilTagMinWhiteBlackDiff(ArucoDetectorParameters ap, int aprilTagMinWhiteBlackDiff);\nint ArucoDetectorParameters_GetAprilTagMinWhiteBlackDiff(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetAprilTagDeglitch(ArucoDetectorParameters ap, int aprilTagDeglitch);\nint ArucoDetectorParameters_GetAprilTagDeglitch(ArucoDetectorParameters ap);\nvoid ArucoDetectorParameters_SetDetectInvertedMarker(ArucoDetectorParameters ap, bool detectInvertedMarker);\nbool ArucoDetectorParameters_GetDetectInvertedMarker(ArucoDetectorParameters ap);\n\n\nArucoDictionary getPredefinedDictionary(int dictionaryId);\n\nArucoDetector ArucoDetector_New();\nArucoDetector ArucoDetector_NewWithParams(ArucoDictionary dictionary, ArucoDetectorParameters params);\nvoid ArucoDetector_Close(ArucoDetector ad);\nvoid ArucoDetector_DetectMarkers(ArucoDetector ad, Mat inputArr, Points2fVector markerCorners, IntVector *markerIds, Points2fVector rejectedCandidates);\n\nvoid ArucoDrawDetectedMarkers(Mat image, Points2fVector markerCorners, IntVector markerIds, Scalar borderColor);\nvoid ArucoGenerateImageMarker(int dictionaryId, int id, int sidePixels, Mat img, int borderBits);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif //_OPENCV3_ARUCO_H_\n"
        },
        {
          "name": "aruco_dictionaries.go",
          "type": "blob",
          "size": 1.73046875,
          "content": "package gocv\n\n/*\n#include <stdlib.h>\n#include \"aruco.h\"\n#include \"core.h\"\n*/\nimport \"C\"\n\ntype ArucoDictionaryCode int\n\nconst (\n\tArucoDict4x4_50         ArucoDictionaryCode = iota\n\tArucoDict4x4_100        ArucoDictionaryCode = iota\n\tArucoDict4x4_250        ArucoDictionaryCode = iota\n\tArucoDict4x4_1000       ArucoDictionaryCode = iota\n\tArucoDict5x5_50         ArucoDictionaryCode = iota\n\tArucoDict5x5_100        ArucoDictionaryCode = iota\n\tArucoDict5x5_250        ArucoDictionaryCode = iota\n\tArucoDict5x5_1000       ArucoDictionaryCode = iota\n\tArucoDict6x6_50         ArucoDictionaryCode = iota\n\tArucoDict6x6_100        ArucoDictionaryCode = iota\n\tArucoDict6x6_250        ArucoDictionaryCode = iota\n\tArucoDict6x6_1000       ArucoDictionaryCode = iota\n\tArucoDict7x7_50         ArucoDictionaryCode = iota\n\tArucoDict7x7_100        ArucoDictionaryCode = iota\n\tArucoDict7x7_250        ArucoDictionaryCode = iota\n\tArucoDict7x7_1000       ArucoDictionaryCode = iota\n\tArucoDictArucoOriginal  ArucoDictionaryCode = iota\n\tArucoDictAprilTag_16h5  ArucoDictionaryCode = iota ///< 4x4 bits, minimum hamming distance between any two codes = 5, 30 codes\n\tArucoDictAprilTag_25h9  ArucoDictionaryCode = iota ///< 5x5 bits, minimum hamming distance between any two codes = 9, 35 codes\n\tArucoDictAprilTag_36h10 ArucoDictionaryCode = iota ///< 6x6 bits, minimum hamming distance between any two codes = 10, 2320 codes\n\tArucoDictAprilTag_36h11 ArucoDictionaryCode = iota ///< 6x6 bits, minimum hamming distance between any two codes = 11, 587 codes\n)\n\ntype ArucoDictionary struct {\n\tp C.ArucoDictionary\n}\n\nfunc GetPredefinedDictionary(dictionaryId ArucoDictionaryCode) ArucoDictionary {\n\tvar p C.ArucoDictionary = C.getPredefinedDictionary(C.int(dictionaryId))\n\treturn ArucoDictionary{p: p}\n}\n"
        },
        {
          "name": "aruco_test.go",
          "type": "blob",
          "size": 10.5537109375,
          "content": "package gocv\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"reflect\"\n\t\"testing\"\n)\n\nconst (\n\tarucoImage6X6_250         = \"./images/aruco_6X6_250_6.png\"\n\tarucoImage6X6_250_contour = \"./images/aruco_6X6_250_6_contour.png\"\n\tarucoImage6X6_250_1       = \"./images/aruco_6X6_250_1.png\"\n)\n\nfunc TestArucoDetectorParams(t *testing.T) {\n\n\tadaptiveThreshWinSizeMin := 4\n\tadaptiveThreshWinSizeMax := 22\n\tadaptiveThreshWinSizeStep := 1\n\tadaptiveThreshConstant := 1.0\n\tminMarkerPerimeterRate := 0.2\n\tmaxMarkerPerimeterRate := 0.5\n\tpolygonalApproxAccuracyRate := 1.0\n\tminCornerDistanceRate := 0.1\n\tminDistanceToBorder := 0\n\tminMarkerDistanceRate := 1.0\n\tcornerRefinementMethod := 1\n\tcornerRefinementWinSize := 1\n\tcornerRefinementMaxIterations := 1\n\tcornerRefinementMinAccuracy := 0.5\n\tmarkerBorderBits := 1\n\tperspectiveRemovePixelPerCell := 1\n\tperspectiveRemoveIgnoredMarginPerCell := 1.0\n\tmaxErroneousBitsInBorderRate := 0.5\n\tminOtsuStdDev := .5\n\terrorCorrectionRate := 0.2\n\taprilTagQuadDecimate := float32(0.5)\n\taprilTagQuadSigma := float32(1)\n\taprilTagMinClusterPixels := 1\n\taprilTagMaxNmaxima := 1\n\taprilTagCriticalRad := float32(0.2)\n\taprilTagMaxLineFitMse := float32(0.2)\n\taprilTagMinWhiteBlackDiff := 1\n\taprilTagDeglitch := 1\n\tdetectInvertedMarker := false\n\n\tparams := NewArucoDetectorParameters()\n\tparams.SetAdaptiveThreshWinSizeMin(adaptiveThreshWinSizeMin)\n\tparams.SetAdaptiveThreshWinSizeMax(adaptiveThreshWinSizeMax)\n\tparams.SetAdaptiveThreshWinSizeStep(adaptiveThreshWinSizeStep)\n\tparams.SetAdaptiveThreshConstant(adaptiveThreshConstant)\n\tparams.SetMinMarkerPerimeterRate(minMarkerPerimeterRate)\n\tparams.SetMaxMarkerPerimeterRate(maxMarkerPerimeterRate)\n\tparams.SetPolygonalApproxAccuracyRate(polygonalApproxAccuracyRate)\n\tparams.SetMinCornerDistanceRate(minCornerDistanceRate)\n\tparams.SetMinDistanceToBorder(minDistanceToBorder)\n\tparams.SetMinMarkerDistanceRate(minMarkerDistanceRate)\n\tparams.SetCornerRefinementMethod(cornerRefinementMethod)\n\tparams.SetCornerRefinementWinSize(cornerRefinementWinSize)\n\tparams.SetCornerRefinementMaxIterations(cornerRefinementMaxIterations)\n\tparams.SetCornerRefinementMinAccuracy(cornerRefinementMinAccuracy)\n\tparams.SetMarkerBorderBits(markerBorderBits)\n\tparams.SetPerspectiveRemovePixelPerCell(perspectiveRemovePixelPerCell)\n\tparams.SetPerspectiveRemoveIgnoredMarginPerCell(perspectiveRemoveIgnoredMarginPerCell)\n\tparams.SetMaxErroneousBitsInBorderRate(maxErroneousBitsInBorderRate)\n\tparams.SetMinOtsuStdDev(minOtsuStdDev)\n\tparams.SetErrorCorrectionRate(errorCorrectionRate)\n\tparams.SetAprilTagQuadDecimate(aprilTagQuadDecimate)\n\tparams.SetAprilTagQuadSigma(aprilTagQuadSigma)\n\tparams.SetAprilTagMinClusterPixels(aprilTagMinClusterPixels)\n\tparams.SetAprilTagMaxNmaxima(aprilTagMaxNmaxima)\n\tparams.SetAprilTagCriticalRad(aprilTagCriticalRad)\n\tparams.SetAprilTagMaxLineFitMse(aprilTagMaxLineFitMse)\n\tparams.SetAprilTagMinWhiteBlackDiff(aprilTagMinWhiteBlackDiff)\n\tparams.SetAprilTagDeglitch(aprilTagDeglitch)\n\tparams.SetDetectInvertedMarker(detectInvertedMarker)\n\tif params.GetAdaptiveThreshWinSizeMin() != adaptiveThreshWinSizeMin {\n\t\tt.Error(fmt.Sprintf(\"AdaptiveThreshWinSizeMin expected %v got %v\", adaptiveThreshWinSizeMin, params.GetAdaptiveThreshWinSizeMin()))\n\t}\n\tif params.GetAdaptiveThreshWinSizeMax() != adaptiveThreshWinSizeMax {\n\t\tt.Error(fmt.Sprintf(\"AdaptiveThreshWinSizeMax expected %v got %v\", adaptiveThreshWinSizeMax, params.GetAdaptiveThreshWinSizeMax()))\n\t}\n\tif params.GetAdaptiveThreshWinSizeStep() != adaptiveThreshWinSizeStep {\n\t\tt.Error(fmt.Sprintf(\"AdaptiveThreshWinSizeStep expected %v got %v\", adaptiveThreshWinSizeStep, params.GetAdaptiveThreshWinSizeStep()))\n\t}\n\tif params.GetAdaptiveThreshConstant() != adaptiveThreshConstant {\n\t\tt.Error(fmt.Sprintf(\"AdaptiveThreshConstant expected %v got %v\", adaptiveThreshConstant, params.GetAdaptiveThreshConstant()))\n\t}\n\tif params.GetMinMarkerPerimeterRate() != minMarkerPerimeterRate {\n\t\tt.Error(fmt.Sprintf(\"MinMarkerPerimeterRate expected %v got %v\", minMarkerPerimeterRate, params.GetMinMarkerPerimeterRate()))\n\t}\n\tif params.GetMaxMarkerPerimeterRate() != maxMarkerPerimeterRate {\n\t\tt.Error(fmt.Sprintf(\"MaxMarkerPerimeterRate expected %v got %v\", maxMarkerPerimeterRate, params.GetMaxMarkerPerimeterRate()))\n\t}\n\tif params.GetPolygonalApproxAccuracyRate() != polygonalApproxAccuracyRate {\n\t\tt.Error(fmt.Sprintf(\"PolygonalApproxAccuracyRate expected %v got %v\", polygonalApproxAccuracyRate, params.GetPolygonalApproxAccuracyRate()))\n\t}\n\tif params.GetMinCornerDistanceRate() != minCornerDistanceRate {\n\t\tt.Error(fmt.Sprintf(\"MinCornerDistanceRate expected %v got %v\", minCornerDistanceRate, params.GetMinCornerDistanceRate()))\n\t}\n\tif params.GetMinDistanceToBorder() != minDistanceToBorder {\n\t\tt.Error(fmt.Sprintf(\"MinDistanceToBorder expected %v got %v\", minDistanceToBorder, params.GetMinDistanceToBorder()))\n\t}\n\tif params.GetMinMarkerDistanceRate() != minMarkerDistanceRate {\n\t\tt.Error(fmt.Sprintf(\"MinMarkerDistanceRate expected %v got %v\", minMarkerDistanceRate, params.GetMinMarkerDistanceRate()))\n\t}\n\tif params.GetCornerRefinementMethod() != cornerRefinementMethod {\n\t\tt.Error(fmt.Sprintf(\"CornerRefinementMethod expected %v got %v\", cornerRefinementMethod, params.GetCornerRefinementMethod()))\n\t}\n\tif params.GetCornerRefinementWinSize() != cornerRefinementWinSize {\n\t\tt.Error(fmt.Sprintf(\"CornerRefinementWinSize expected %v got %v\", cornerRefinementWinSize, params.GetCornerRefinementWinSize()))\n\t}\n\tif params.GetCornerRefinementMaxIterations() != cornerRefinementMaxIterations {\n\t\tt.Error(fmt.Sprintf(\"CornerRefinementMaxIterations expected %v got %v\", cornerRefinementMaxIterations, params.GetCornerRefinementMaxIterations()))\n\t}\n\tif params.GetCornerRefinementMinAccuracy() != cornerRefinementMinAccuracy {\n\t\tt.Error(fmt.Sprintf(\"CornerRefinementMinAccuracy expected %v got %v\", cornerRefinementMinAccuracy, params.GetCornerRefinementMinAccuracy()))\n\t}\n\tif params.GetMarkerBorderBits() != markerBorderBits {\n\t\tt.Error(fmt.Sprintf(\"MarkerBorderBits expected %v got %v\", markerBorderBits, params.GetMarkerBorderBits()))\n\t}\n\tif params.GetPerspectiveRemovePixelPerCell() != perspectiveRemovePixelPerCell {\n\t\tt.Error(fmt.Sprintf(\"PerspectiveRemovePixelPerCell expected %v got %v\", perspectiveRemovePixelPerCell, params.GetPerspectiveRemovePixelPerCell()))\n\t}\n\tif params.GetPerspectiveRemoveIgnoredMarginPerCell() != perspectiveRemoveIgnoredMarginPerCell {\n\t\tt.Error(fmt.Sprintf(\"PerspectiveRemoveIgnoredMarginPerCell expected %v got %v\", perspectiveRemoveIgnoredMarginPerCell, params.GetPerspectiveRemoveIgnoredMarginPerCell()))\n\t}\n\tif params.GetMaxErroneousBitsInBorderRate() != maxErroneousBitsInBorderRate {\n\t\tt.Error(fmt.Sprintf(\"MaxErroneousBitsInBorderRate expected %v got %v\", maxErroneousBitsInBorderRate, params.GetMaxErroneousBitsInBorderRate()))\n\t}\n\tif params.GetMinOtsuStdDev() != minOtsuStdDev {\n\t\tt.Error(fmt.Sprintf(\"MinOtsuStdDev expected %v got %v\", minOtsuStdDev, params.GetMinOtsuStdDev()))\n\t}\n\tif params.GetErrorCorrectionRate() != errorCorrectionRate {\n\t\tt.Error(fmt.Sprintf(\"ErrorCorrectionRate expected %v got %v\", errorCorrectionRate, params.GetErrorCorrectionRate()))\n\t}\n\tif params.GetAprilTagQuadDecimate() != aprilTagQuadDecimate {\n\t\tt.Error(fmt.Sprintf(\"AprilTagQuadDecimate expected %v got %v\", aprilTagQuadDecimate, params.GetAprilTagQuadDecimate()))\n\t}\n\tif params.GetAprilTagQuadSigma() != aprilTagQuadSigma {\n\t\tt.Error(fmt.Sprintf(\"AprilTagQuadSigma expected %v got %v\", aprilTagQuadSigma, params.GetAprilTagQuadSigma()))\n\t}\n\tif params.GetAprilTagMinClusterPixels() != aprilTagMinClusterPixels {\n\t\tt.Error(fmt.Sprintf(\"AprilTagMinClusterPixels expected %v got %v\", aprilTagMinClusterPixels, params.GetAprilTagMinClusterPixels()))\n\t}\n\tif params.GetAprilTagMaxNmaxima() != aprilTagMaxNmaxima {\n\t\tt.Error(fmt.Sprintf(\"AprilTagMaxNmaxima expected %v got %v\", aprilTagMaxNmaxima, params.GetAprilTagMaxNmaxima()))\n\t}\n\tif params.GetAprilTagCriticalRad() != aprilTagCriticalRad {\n\t\tt.Error(fmt.Sprintf(\"AprilTagCriticalRad expected %v got %v\", aprilTagCriticalRad, params.GetAprilTagCriticalRad()))\n\t}\n\tif params.GetAprilTagMaxLineFitMse() != aprilTagMaxLineFitMse {\n\t\tt.Error(fmt.Sprintf(\"AprilTagMaxLineFitMse expected %v got %v\", aprilTagMaxLineFitMse, params.GetAprilTagMaxLineFitMse()))\n\t}\n\tif params.GetAprilTagMinWhiteBlackDiff() != aprilTagMinWhiteBlackDiff {\n\t\tt.Error(fmt.Sprintf(\"AprilTagMinWhiteBlackDiff expected %v got %v\", aprilTagMinWhiteBlackDiff, params.GetAprilTagMinWhiteBlackDiff()))\n\t}\n\tif params.GetAprilTagDeglitch() != aprilTagDeglitch {\n\t\tt.Error(fmt.Sprintf(\"AprilTagDeglitch expected %v got %v\", aprilTagDeglitch, params.GetAprilTagDeglitch()))\n\t}\n\tif params.GetDetectInvertedMarker() != detectInvertedMarker {\n\t\tt.Error(fmt.Sprintf(\"DetectInvertedMarker expected %v got %v\", detectInvertedMarker, params.GetDetectInvertedMarker()))\n\t}\n\n}\n\nfunc TestDetectMarkers(t *testing.T) {\n\tpath := arucoImage6X6_250\n\timg := IMRead(path, IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(errors.New(\"Invalid input\"))\n\t}\n\tdefer img.Close()\n\n\tdict := GetPredefinedDictionary(ArucoDict6x6_250)\n\tparams := NewArucoDetectorParameters()\n\tdetector := NewArucoDetectorWithParams(dict, params)\n\tdefer detector.Close()\n\n\t_, markerIds, _ := detector.DetectMarkers(img)\n\texpected := []int{40, 98, 62, 23, 124, 203}\n\tif !reflect.DeepEqual(markerIds, expected) {\n\t\tt.Error(fmt.Sprintf(\"Marker id expected %v got %v\", expected, markerIds))\n\t}\n}\n\nfunc TestDrawDetectedMarkers(t *testing.T) {\n\tborderColor := NewScalar(200, 0, 0, 0)\n\n\timg := IMRead(arucoImage6X6_250, IMReadColor)\n\tdefer img.Close()\n\tif img.Empty() {\n\t\tt.Error(errors.New(\"Invalid input\"))\n\t}\n\tdefer img.Close()\n\timgExpected := IMRead(arucoImage6X6_250_contour, IMReadColor)\n\tif imgExpected.Empty() {\n\t\tt.Error(errors.New(\"Invalid input\"))\n\t}\n\tdefer imgExpected.Close()\n\n\tdict := GetPredefinedDictionary(ArucoDict6x6_250)\n\tparams := NewArucoDetectorParameters()\n\tdetector := NewArucoDetectorWithParams(dict, params)\n\tdefer detector.Close()\n\n\tmarkerCorners, markerIds, _ := detector.DetectMarkers(img)\n\n\tArucoDrawDetectedMarkers(img, markerCorners, markerIds, borderColor)\n\tdiff := NewMat()\n\tdefer diff.Close()\n\tAbsDiff(img, imgExpected, &diff)\n\n\tgray := NewMat()\n\tdefer gray.Close()\n\tCvtColor(diff, &gray, ColorBGRToGray)\n\tif CountNonZero(gray) > 0 {\n\t\tt.Errorf(\"expected output to match %s\", arucoImage6X6_250_contour)\n\t}\n}\n\nfunc TestArucoGenerateImageMarker(t *testing.T) {\n\timgExpected := IMRead(arucoImage6X6_250_1, IMReadGrayScale)\n\tif imgExpected.Empty() {\n\t\tt.Error(fmt.Errorf(\"Invalid marker image '%s'\", arucoImage6X6_250_1))\n\t}\n\tdefer imgExpected.Close()\n\n\timg := NewMat()\n\tdefer img.Close()\n\tArucoGenerateImageMarker(ArucoDict6x6_250, 1, 200, img, 1)\n\n\tdiff := NewMat()\n\tdefer diff.Close()\n\tAbsDiff(img, imgExpected, &diff)\n\n\tif CountNonZero(diff) > 0 {\n\t\tt.Errorf(\"expected output to match %s\", arucoImage6X6_250_1)\n\t}\n}\n"
        },
        {
          "name": "asyncarray.cpp",
          "type": "blob",
          "size": 0.58984375,
          "content": "// +build openvino\n\n#include <string.h>\n#include \"asyncarray.h\"\n\n\n// AsyncArray_New creates a new empty AsyncArray\nAsyncArray AsyncArray_New() {\n    return new cv::AsyncArray();\n}\n\n// AsyncArray_Close deletes an existing AsyncArray\nvoid AsyncArray_Close(AsyncArray a) {\n    delete a;\n}\n\nconst char* AsyncArray_GetAsync(AsyncArray async_out,Mat out) {\n    try {\n       async_out->get(*out);\n    } catch(cv::Exception ex) {\n        return ex.err.c_str();\n    }\n    return \"\";\n}\n\nAsyncArray Net_forwardAsync(Net net, const char* outputName) {\n    return new cv::AsyncArray(net->forwardAsync(outputName));\n}\n"
        },
        {
          "name": "asyncarray.go",
          "type": "blob",
          "size": 0.9033203125,
          "content": "//go:build openvino\n// +build openvino\n\npackage gocv\n\nimport (\n\t\"errors\"\n)\n\n/*\n#include <stdlib.h>\n#include \"dnn.h\"\n#include \"asyncarray.h\"\n#include \"core.h\"\n*/\nimport \"C\"\n\ntype AsyncArray struct {\n\tp C.AsyncArray\n}\n\n// NewAsyncArray returns a new empty AsyncArray.\nfunc NewAsyncArray() AsyncArray {\n\treturn newAsyncArray(C.AsyncArray_New())\n}\n\n// Ptr returns the AsyncArray's underlying object pointer.\nfunc (a *AsyncArray) Ptr() C.AsyncArray {\n\treturn a.p\n}\n\n// Get async returns the Mat\nfunc (m *AsyncArray) Get(mat *Mat) error {\n\tresult := C.AsyncArray_GetAsync(m.p, mat.p)\n\terr := C.GoString(result)\n\n\tif len(err) > 0 {\n\t\treturn errors.New(err)\n\t}\n\treturn nil\n}\n\n// newAsyncArray returns a new AsyncArray from a C AsyncArray\nfunc newAsyncArray(p C.AsyncArray) AsyncArray {\n\treturn AsyncArray{p: p}\n}\n\n// Close the AsyncArray object.\nfunc (a *AsyncArray) Close() error {\n\tC.AsyncArray_Close(a.p)\n\ta.p = nil\n\treturn nil\n}\n"
        },
        {
          "name": "asyncarray.h",
          "type": "blob",
          "size": 0.412109375,
          "content": "#ifdef __cplusplus\n#include <opencv2/opencv.hpp>\nextern \"C\" {\n#endif\n\n#include \"core.h\"\n#include \"dnn.h\"\n\n#ifdef __cplusplus\ntypedef cv::AsyncArray* AsyncArray;\n#else\ntypedef void* AsyncArray;\n#endif\n\nAsyncArray AsyncArray_New();\nconst char* AsyncArray_GetAsync(AsyncArray async_out,Mat out);\nvoid AsyncArray_Close(AsyncArray a);\nAsyncArray Net_forwardAsync(Net net, const char* outputName);\n\n\n#ifdef __cplusplus\n}\n#endif\n"
        },
        {
          "name": "asyncarray_test.go",
          "type": "blob",
          "size": 0.24609375,
          "content": "//go:build openvino\n// +build openvino\n\npackage gocv\n\nimport (\n\t\"testing\"\n)\n\nfunc TestAsyncArray(t *testing.T) {\n\tasyncarray := NewAsyncArray()\n\tdefer asyncarray.Close()\n\n\tif asyncarray.Ptr() == nil {\n\t\tt.Error(\"New AsyncArray should not be nil\")\n\t}\n}\n"
        },
        {
          "name": "calib3d.cpp",
          "type": "blob",
          "size": 5.3935546875,
          "content": "#include \"calib3d.h\"\n\ndouble Fisheye_Calibrate(Points3fVector objectPoints, Points2fVector imagePoints, Size size, Mat k, Mat d, Mat rvecs, Mat tvecs, int flags) {\n    cv::Size sz(size.width, size.height);\n    return cv::fisheye::calibrate(*objectPoints, *imagePoints, sz, *k, *d, *rvecs, *tvecs, flags);\n}\n\nvoid Fisheye_DistortPoints(Mat undistorted, Mat distorted, Mat k, Mat d) {\n    cv::fisheye::distortPoints(*undistorted, *distorted, *k, *d);\n}\n\nvoid Fisheye_UndistortImage(Mat distorted, Mat undistorted, Mat k, Mat d) {\n    cv::fisheye::undistortImage(*distorted, *undistorted, *k, *d);\n}\n\nvoid Fisheye_UndistortImageWithParams(Mat distorted, Mat undistorted, Mat k, Mat d, Mat knew, Size size) {\n    cv::Size sz(size.width, size.height);\n    cv::fisheye::undistortImage(*distorted, *undistorted, *k, *d, *knew, sz);\n}\n\nvoid Fisheye_UndistortPoints(Mat distorted, Mat undistorted, Mat k, Mat d, Mat r, Mat p) {\n    cv::fisheye::undistortPoints(*distorted, *undistorted, *k, *d, *r, *p);\n}\n\nvoid Fisheye_EstimateNewCameraMatrixForUndistortRectify(Mat k, Mat d, Size imgSize, Mat r, Mat p, double balance, Size newSize, double fovScale) {\n    cv::Size newSz(newSize.width, newSize.height);\n    cv::Size imgSz(imgSize.width, imgSize.height);\n    cv::fisheye::estimateNewCameraMatrixForUndistortRectify(*k, *d, imgSz, *r, *p, balance, newSz, fovScale);\n}\n\nvoid InitUndistortRectifyMap(Mat cameraMatrix,Mat distCoeffs,Mat r,Mat newCameraMatrix,Size size,int m1type,Mat map1,Mat map2) {\n    cv::Size sz(size.width, size.height);\n    cv::initUndistortRectifyMap(*cameraMatrix,*distCoeffs,*r,*newCameraMatrix,sz,m1type,*map1,*map2);\n}\n\nMat GetOptimalNewCameraMatrixWithParams(Mat cameraMatrix,Mat distCoeffs,Size size,double alpha,Size newImgSize,Rect* validPixROI,bool centerPrincipalPoint) {\n    cv::Size sz(size.width, size.height);\n    cv::Size newSize(newImgSize.width, newImgSize.height);\n    cv::Rect rect(validPixROI->x,validPixROI->y,validPixROI->width,validPixROI->height);\n    cv::Mat* mat = new cv::Mat(cv::getOptimalNewCameraMatrix(*cameraMatrix,*distCoeffs,sz,alpha,newSize,&rect,centerPrincipalPoint));\n    validPixROI->x = rect.x;\n    validPixROI->y = rect.y;\n    validPixROI->width = rect.width;\n    validPixROI->height = rect.height;\n    return mat;\n}\n\ndouble CalibrateCamera(Points3fVector objectPoints, Points2fVector imagePoints, Size imageSize, Mat cameraMatrix, Mat distCoeffs, Mat rvecs, Mat tvecs, int flag) {\n    return cv::calibrateCamera(*objectPoints, *imagePoints, cv::Size(imageSize.width, imageSize.height), *cameraMatrix, *distCoeffs, *rvecs, *tvecs, flag);\n}\n\nvoid Undistort(Mat src, Mat dst, Mat cameraMatrix, Mat distCoeffs, Mat newCameraMatrix) {\n    cv::undistort(*src, *dst, *cameraMatrix, *distCoeffs, *newCameraMatrix);\n}\n\nvoid UndistortPoints(Mat distorted, Mat undistorted, Mat k, Mat d, Mat r, Mat p) {\n    cv::undistortPoints(*distorted, *undistorted, *k, *d, *r, *p);\n}\n\nbool CheckChessboard(Mat image, Size size) {\n    cv::Size sz(size.width, size.height);\n    return cv::checkChessboard(*image, sz);\n}\n\nbool FindChessboardCorners(Mat image, Size patternSize, Mat corners, int flags) {\n    cv::Size sz(patternSize.width, patternSize.height);\n    return cv::findChessboardCorners(*image, sz, *corners, flags);\n}\n\nbool FindChessboardCornersSB(Mat image, Size patternSize, Mat corners, int flags) {\n    cv::Size sz(patternSize.width, patternSize.height);\n    return cv::findChessboardCornersSB(*image, sz, *corners, flags);\n}\n\nbool FindChessboardCornersSBWithMeta(Mat image, Size patternSize, Mat corners, int flags, Mat meta) {\n    cv::Size sz(patternSize.width, patternSize.height);\n    return cv::findChessboardCornersSB(*image, sz, *corners, flags, *meta);\n}\n\nvoid DrawChessboardCorners(Mat image, Size patternSize, Mat corners, bool patternWasFound) {\n    cv::Size sz(patternSize.width, patternSize.height);\n    cv::drawChessboardCorners(*image, sz, *corners, patternWasFound);\n}\n\nMat EstimateAffinePartial2D(Point2fVector from, Point2fVector to) {\n    return new cv::Mat(cv::estimateAffinePartial2D(*from, *to));\n}\n\nMat EstimateAffinePartial2DWithParams(Point2fVector from, Point2fVector to, Mat inliers, int method, double ransacReprojThreshold, size_t maxIters, double confidence, size_t refineIters) {\n    return new cv::Mat(cv::estimateAffinePartial2D(*from, *to, *inliers, method, ransacReprojThreshold, maxIters, confidence, refineIters));\n}\n\nMat EstimateAffine2D(Point2fVector from, Point2fVector to) {\n    return new cv::Mat(cv::estimateAffine2D(*from, *to));\n}\n\nMat EstimateAffine2DWithParams(Point2fVector from, Point2fVector to, Mat inliers, int method, double ransacReprojThreshold, size_t maxIters, double confidence, size_t refineIters) {\n    return new cv::Mat(cv::estimateAffine2D(*from, *to, *inliers, method, ransacReprojThreshold, maxIters, confidence, refineIters));\n}\n\nvoid TriangulatePoints(Mat projMatr1, Mat projMatr2, Point2fVector projPoints1, Point2fVector projPoints2, Mat points4D) {\n  return cv::triangulatePoints(*projMatr1, *projMatr2, *projPoints1, *projPoints2, *points4D);\n}\n\nvoid ConvertPointsFromHomogeneous(Mat src, Mat dst) {\n  return cv::convertPointsFromHomogeneous(*src, *dst);\n}\n\nvoid Rodrigues(Mat src, Mat dst) {\n\tcv::Rodrigues(*src, *dst);\n}\n\nbool SolvePnP(Point3fVector objectPoints, Point2fVector imagePoints, Mat cameraMatrix, Mat distCoeffs, Mat rvec, Mat tvec, bool useExtrinsicGuess, int flags) {\n    return cv::solvePnP(*objectPoints, *imagePoints, *cameraMatrix, *distCoeffs, *rvec, *tvec, useExtrinsicGuess, flags);\n}\n"
        },
        {
          "name": "calib3d.go",
          "type": "blob",
          "size": 14.7021484375,
          "content": "package gocv\n\n/*\n#include <stdlib.h>\n#include \"calib3d.h\"\n*/\nimport \"C\"\nimport (\n\t\"image\"\n)\n\n// Calib is a wrapper around OpenCV's \"Camera Calibration and 3D Reconstruction\" of\n// Fisheye Camera model\n//\n// For more details, please see:\n// https://docs.opencv.org/trunk/db/d58/group__calib3d__fisheye.html\n\n// CalibFlag value for calibration\ntype CalibFlag int32\n\nconst (\n\t// CalibUseIntrinsicGuess indicates that cameraMatrix contains valid initial values\n\t// of fx, fy, cx, cy that are optimized further. Otherwise, (cx, cy) is initially\n\t// set to the image center ( imageSize is used), and focal distances are computed\n\t// in a least-squares fashion.\n\tCalibUseIntrinsicGuess CalibFlag = 1 << iota\n\n\t// CalibRecomputeExtrinsic indicates that extrinsic will be recomputed after each\n\t// iteration of intrinsic optimization.\n\tCalibRecomputeExtrinsic\n\n\t// CalibCheckCond indicates that the functions will check validity of condition number\n\tCalibCheckCond\n\n\t// CalibFixSkew indicates that skew coefficient (alpha) is set to zero and stay zero\n\tCalibFixSkew\n\n\t// CalibFixK1 indicates that selected distortion coefficients are set to zeros and stay zero\n\tCalibFixK1\n\n\t// CalibFixK2 indicates that selected distortion coefficients are set to zeros and stay zero\n\tCalibFixK2\n\n\t// CalibFixK3 indicates that selected distortion coefficients are set to zeros and stay zero\n\tCalibFixK3\n\n\t// CalibFixK4 indicates that selected distortion coefficients are set to zeros and stay zero\n\tCalibFixK4\n\n\t// CalibFixIntrinsic indicates that fix K1, K2? and D1, D2? so that only R, T matrices are estimated\n\tCalibFixIntrinsic\n\n\t// CalibFixPrincipalPoint indicates that the principal point is not changed during the global optimization.\n\t// It stays at the center or at a different location specified when CalibUseIntrinsicGuess is set too.\n\tCalibFixPrincipalPoint\n)\n\n// FisheyeCalibrate performs camera calibration.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/db/d58/group__calib3d__fisheye.html#gad626a78de2b1dae7489e152a5a5a89e1\nfunc FisheyeCalibrate(objectPoints Points3fVector, imagePoints Points2fVector, size image.Point, k, d, rvecs, tvecs *Mat, flags CalibFlag) float64 {\n\tsz := C.struct_Size{\n\t\twidth:  C.int(size.X),\n\t\theight: C.int(size.Y),\n\t}\n\n\treturn float64(C.Fisheye_Calibrate(objectPoints.p, imagePoints.p, sz, k.p, d.p, rvecs.p, tvecs.p, C.int(flags)))\n}\n\n// FisheyeDistortPoints distorts 2D points using fisheye model.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/db/d58/group__calib3d__fisheye.html#gab738cdf90ceee97b2b52b0d0e7511541\nfunc FisheyeDistortPoints(undistorted Mat, distorted *Mat, k, d Mat) {\n\tC.Fisheye_DistortPoints(undistorted.Ptr(), distorted.Ptr(), k.Ptr(), d.Ptr())\n}\n\n// FisheyeUndistortImage transforms an image to compensate for fisheye lens distortion\nfunc FisheyeUndistortImage(distorted Mat, undistorted *Mat, k, d Mat) {\n\tC.Fisheye_UndistortImage(distorted.Ptr(), undistorted.Ptr(), k.Ptr(), d.Ptr())\n}\n\n// FisheyeUndistortImageWithParams transforms an image to compensate for fisheye lens distortion with Knew matrix\nfunc FisheyeUndistortImageWithParams(distorted Mat, undistorted *Mat, k, d, knew Mat, size image.Point) {\n\tsz := C.struct_Size{\n\t\twidth:  C.int(size.X),\n\t\theight: C.int(size.Y),\n\t}\n\tC.Fisheye_UndistortImageWithParams(distorted.Ptr(), undistorted.Ptr(), k.Ptr(), d.Ptr(), knew.Ptr(), sz)\n}\n\n// FisheyeUndistortPoints transforms points to compensate for fisheye lens distortion\n//\n// For further details, please see:\n// https://docs.opencv.org/master/db/d58/group__calib3d__fisheye.html#gab738cdf90ceee97b2b52b0d0e7511541\nfunc FisheyeUndistortPoints(distorted Mat, undistorted *Mat, k, d, r, p Mat) {\n\tC.Fisheye_UndistortPoints(distorted.Ptr(), undistorted.Ptr(), k.Ptr(), d.Ptr(), r.Ptr(), p.Ptr())\n}\n\n// EstimateNewCameraMatrixForUndistortRectify estimates new camera matrix for undistortion or rectification.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/db/d58/group__calib3d__fisheye.html#ga384940fdf04c03e362e94b6eb9b673c9\nfunc EstimateNewCameraMatrixForUndistortRectify(k, d Mat, imgSize image.Point, r Mat, p *Mat, balance float64, newSize image.Point, fovScale float64) {\n\timgSz := C.struct_Size{\n\t\twidth:  C.int(imgSize.X),\n\t\theight: C.int(imgSize.Y),\n\t}\n\tnewSz := C.struct_Size{\n\t\twidth:  C.int(newSize.X),\n\t\theight: C.int(newSize.Y),\n\t}\n\tC.Fisheye_EstimateNewCameraMatrixForUndistortRectify(k.Ptr(), d.Ptr(), imgSz, r.Ptr(), p.Ptr(), C.double(balance), newSz, C.double(fovScale))\n}\n\n// InitUndistortRectifyMap computes the joint undistortion and rectification transformation and represents the result in the form of maps for remap\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d9/d0c/group__calib3d.html#ga7dfb72c9cf9780a347fbe3d1c47e5d5a\nfunc InitUndistortRectifyMap(cameraMatrix Mat, distCoeffs Mat, r Mat, newCameraMatrix Mat, size image.Point, m1type int, map1 Mat, map2 Mat) {\n\tsz := C.struct_Size{\n\t\twidth:  C.int(size.X),\n\t\theight: C.int(size.Y),\n\t}\n\tC.InitUndistortRectifyMap(cameraMatrix.Ptr(), distCoeffs.Ptr(), r.Ptr(), newCameraMatrix.Ptr(), sz, C.int(m1type), map1.Ptr(), map2.Ptr())\n}\n\n// GetOptimalNewCameraMatrixWithParams computes and returns the optimal new camera matrix based on the free scaling parameter.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d9/d0c/group__calib3d.html#ga7a6c4e032c97f03ba747966e6ad862b1\nfunc GetOptimalNewCameraMatrixWithParams(cameraMatrix Mat, distCoeffs Mat, imageSize image.Point, alpha float64, newImgSize image.Point, centerPrincipalPoint bool) (Mat, image.Rectangle) {\n\tsz := C.struct_Size{\n\t\twidth:  C.int(imageSize.X),\n\t\theight: C.int(imageSize.Y),\n\t}\n\tnewSize := C.struct_Size{\n\t\twidth:  C.int(newImgSize.X),\n\t\theight: C.int(newImgSize.Y),\n\t}\n\trt := C.struct_Rect{}\n\treturn newMat(C.GetOptimalNewCameraMatrixWithParams(cameraMatrix.Ptr(), distCoeffs.Ptr(), sz, C.double(alpha), newSize, &rt, C.bool(centerPrincipalPoint))), toRect(rt)\n}\n\n// CalibrateCamera finds the camera intrinsic and extrinsic parameters from several views of a calibration pattern.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d9/d0c/group__calib3d.html#ga3207604e4b1a1758aa66acb6ed5aa65d\nfunc CalibrateCamera(objectPoints Points3fVector, imagePoints Points2fVector, imageSize image.Point,\n\tcameraMatrix *Mat, distCoeffs *Mat, rvecs *Mat, tvecs *Mat, calibFlag CalibFlag) float64 {\n\tsz := C.struct_Size{\n\t\twidth:  C.int(imageSize.X),\n\t\theight: C.int(imageSize.Y),\n\t}\n\n\tres := C.CalibrateCamera(objectPoints.p, imagePoints.p, sz, cameraMatrix.p, distCoeffs.p, rvecs.p, tvecs.p, C.int(calibFlag))\n\treturn float64(res)\n}\n\n// Undistort transforms an image to compensate for lens distortion.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#ga69f2545a8b62a6b0fc2ee060dc30559d\nfunc Undistort(src Mat, dst *Mat, cameraMatrix Mat, distCoeffs Mat, newCameraMatrix Mat) {\n\tC.Undistort(src.Ptr(), dst.Ptr(), cameraMatrix.Ptr(), distCoeffs.Ptr(), newCameraMatrix.Ptr())\n}\n\n// UndistortPoints transforms points to compensate for lens distortion\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d9/d0c/group__calib3d.html#ga55c716492470bfe86b0ee9bf3a1f0f7e\nfunc UndistortPoints(src Mat, dst *Mat, cameraMatrix, distCoeffs, rectificationTransform, newCameraMatrix Mat) {\n\tC.UndistortPoints(src.Ptr(), dst.Ptr(), cameraMatrix.Ptr(), distCoeffs.Ptr(), rectificationTransform.Ptr(), newCameraMatrix.Ptr())\n}\n\n// CheckChessboard renders the detected chessboard corners.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d9/d0c/group__calib3d.html#ga6a10b0bb120c4907e5eabbcd22319022\nfunc CheckChessboard(image Mat, size image.Point) bool {\n\tsz := C.struct_Size{\n\t\twidth:  C.int(size.X),\n\t\theight: C.int(size.Y),\n\t}\n\treturn bool(C.CheckChessboard(image.Ptr(), sz))\n}\n\n// CalibCBFlag value for chessboard calibration\n// For more details, please see:\n// https://docs.opencv.org/master/d9/d0c/group__calib3d.html#ga93efa9b0aa890de240ca32b11253dd4a\ntype CalibCBFlag int\n\nconst (\n\t// Various operation flags that can be zero or a combination of the following values:\n\t//  Use adaptive thresholding to convert the image to black and white, rather than a fixed threshold level (computed from the average image brightness).\n\tCalibCBAdaptiveThresh CalibCBFlag = 1 << iota\n\t//  Normalize the image gamma with equalizeHist before applying fixed or adaptive thresholding.\n\tCalibCBNormalizeImage\n\t//  Use additional criteria (like contour area, perimeter, square-like shape) to filter out false quads extracted at the contour retrieval stage.\n\tCalibCBFilterQuads\n\t//  Run a fast check on the image that looks for chessboard corners, and shortcut the call if none is found. This can drastically speed up the call in the degenerate condition when no chessboard is observed.\n\tCalibCBFastCheck\n\t//  Run an exhaustive search to improve detection rate.\n\tCalibCBExhaustive\n\t//  Up sample input image to improve sub-pixel accuracy due to aliasing effects.\n\tCalibCBAccuracy\n\t//  The detected pattern is allowed to be larger than patternSize (see description).\n\tCalibCBLarger\n\t//  The detected pattern must have a marker (see description). This should be used if an accurate camera calibration is required.\n\tCalibCBMarker\n)\n\n// FindChessboardCorners finds the positions of internal corners of the chessboard.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d9/d0c/group__calib3d.html#ga93efa9b0aa890de240ca32b11253dd4a\nfunc FindChessboardCorners(image Mat, patternSize image.Point, corners *Mat, flags CalibCBFlag) bool {\n\tsz := C.struct_Size{\n\t\twidth:  C.int(patternSize.X),\n\t\theight: C.int(patternSize.Y),\n\t}\n\treturn bool(C.FindChessboardCorners(image.Ptr(), sz, corners.Ptr(), C.int(flags)))\n}\n\n// FindChessboardCorners finds the positions of internal corners of the chessboard using a sector based approach.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d9/d0c/group__calib3d.html#gadc5bcb05cb21cf1e50963df26986d7c9\nfunc FindChessboardCornersSB(image Mat, patternSize image.Point, corners *Mat, flags CalibCBFlag) bool {\n\tsz := C.struct_Size{\n\t\twidth:  C.int(patternSize.X),\n\t\theight: C.int(patternSize.Y),\n\t}\n\treturn bool(C.FindChessboardCornersSB(image.Ptr(), sz, corners.Ptr(), C.int(flags)))\n}\n\n// FindChessboardCornersSBWithMeta finds the positions of internal corners of the chessboard using a sector based approach.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d9/d0c/group__calib3d.html#ga93efa9b0aa890de240ca32b11253dd4a\nfunc FindChessboardCornersSBWithMeta(image Mat, patternSize image.Point, corners *Mat, flags CalibCBFlag, meta *Mat) bool {\n\tsz := C.struct_Size{\n\t\twidth:  C.int(patternSize.X),\n\t\theight: C.int(patternSize.Y),\n\t}\n\treturn bool(C.FindChessboardCornersSBWithMeta(image.Ptr(), sz, corners.Ptr(), C.int(flags), meta.Ptr()))\n}\n\n// DrawChessboardCorners renders the detected chessboard corners.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d9/d0c/group__calib3d.html#ga6a10b0bb120c4907e5eabbcd22319022\nfunc DrawChessboardCorners(image *Mat, patternSize image.Point, corners Mat, patternWasFound bool) {\n\tsz := C.struct_Size{\n\t\twidth:  C.int(patternSize.X),\n\t\theight: C.int(patternSize.Y),\n\t}\n\tC.DrawChessboardCorners(image.Ptr(), sz, corners.Ptr(), C.bool(patternWasFound))\n}\n\n// EstimateAffinePartial2D computes an optimal limited affine transformation\n// with 4 degrees of freedom between two 2D point sets.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d9/d0c/group__calib3d.html#gad767faff73e9cbd8b9d92b955b50062d\nfunc EstimateAffinePartial2D(from, to Point2fVector) Mat {\n\treturn newMat(C.EstimateAffinePartial2D(from.p, to.p))\n}\n\n// EstimateAffinePartial2DWithParams computes an optimal limited affine transformation\n// with 4 degrees of freedom between two 2D point sets\n// with additional optional parameters.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d9/d0c/group__calib3d.html#gad767faff73e9cbd8b9d92b955b50062d\nfunc EstimateAffinePartial2DWithParams(from Point2fVector, to Point2fVector, inliers Mat, method int, ransacReprojThreshold float64, maxIters uint, confidence float64, refineIters uint) Mat {\n\treturn newMat(C.EstimateAffinePartial2DWithParams(from.p, to.p, inliers.p, C.int(method), C.double(ransacReprojThreshold), C.size_t(maxIters), C.double(confidence), C.size_t(refineIters)))\n}\n\n// EstimateAffine2D Computes an optimal affine transformation between two 2D point sets.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.0.0/d9/d0c/group__calib3d.html#ga27865b1d26bac9ce91efaee83e94d4dd\nfunc EstimateAffine2D(from, to Point2fVector) Mat {\n\treturn newMat(C.EstimateAffine2D(from.p, to.p))\n}\n\n// EstimateAffine2DWithParams Computes an optimal affine transformation between two 2D point sets\n// with additional optional parameters.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.0.0/d9/d0c/group__calib3d.html#ga27865b1d26bac9ce91efaee83e94d4dd\nfunc EstimateAffine2DWithParams(from Point2fVector, to Point2fVector, inliers Mat, method int, ransacReprojThreshold float64, maxIters uint, confidence float64, refineIters uint) Mat {\n\treturn newMat(C.EstimateAffine2DWithParams(from.p, to.p, inliers.p, C.int(method), C.double(ransacReprojThreshold), C.size_t(maxIters), C.double(confidence), C.size_t(refineIters)))\n}\n\n// TriangulatePoints reconstructs 3-dimensional points (in homogeneous coordinates)\n// by using their observations with a stereo camera.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#gad3fc9a0c82b08df034234979960b778c\nfunc TriangulatePoints(projMatr1, projMatr2 Mat, projPoints1, projPoints2 Point2fVector, points4D *Mat) {\n\tC.TriangulatePoints(projMatr1.Ptr(), projMatr2.Ptr(), projPoints1.p, projPoints2.p, points4D.Ptr())\n}\n\n// ConvertPointsFromHomogeneous converts points from homogeneous to Euclidean space.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#gac42edda3a3a0f717979589fcd6ac0035\nfunc ConvertPointsFromHomogeneous(src Mat, dst *Mat) {\n\tC.ConvertPointsFromHomogeneous(src.Ptr(), dst.Ptr())\n}\n\n// Rodrigues converts a rotation matrix to a rotation vector or vice versa.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.0.0/d9/d0c/group__calib3d.html#ga61585db663d9da06b68e70cfbf6a1eac\nfunc Rodrigues(src Mat, dst *Mat) {\n\tC.Rodrigues(src.p, dst.p)\n}\n\n// SolvePnP finds an object pose from 3D-2D point correspondences.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.0.0/d9/d0c/group__calib3d.html#ga549c2075fac14829ff4a58bc931c033d\nfunc SolvePnP(objectPoints Point3fVector, imagePoints Point2fVector, cameraMatrix, distCoeffs Mat, rvec, tvec *Mat, useExtrinsicGuess bool, flags int) bool {\n\treturn bool(C.SolvePnP(objectPoints.p, imagePoints.p, cameraMatrix.p, distCoeffs.p, rvec.p, tvec.p, C.bool(useExtrinsicGuess), C.int(flags)))\n}\n"
        },
        {
          "name": "calib3d.h",
          "type": "blob",
          "size": 2.6884765625,
          "content": "#ifndef _OPENCV3_CALIB_H_\n#define _OPENCV3_CALIB_H_\n\n#ifdef __cplusplus\n#include <opencv2/opencv.hpp>\n#include <opencv2/calib3d.hpp>\n\n\nextern \"C\" {\n#endif\n\n#include \"core.h\"\n\n//Calib\ndouble Fisheye_Calibrate(Points3fVector objectPoints, Points2fVector imagePoints, Size size, Mat k, Mat d, Mat rvecs, Mat tvecs, int flags);\nvoid Fisheye_DistortPoints(Mat undistorted, Mat distorted, Mat k, Mat d);\nvoid Fisheye_UndistortImage(Mat distorted, Mat undistorted, Mat k, Mat d);\nvoid Fisheye_UndistortImageWithParams(Mat distorted, Mat undistorted, Mat k, Mat d, Mat knew, Size size);\nvoid Fisheye_UndistortPoints(Mat distorted, Mat undistorted, Mat k, Mat d, Mat R, Mat P);\nvoid Fisheye_EstimateNewCameraMatrixForUndistortRectify(Mat k, Mat d, Size imgSize, Mat r, Mat p, double balance, Size newSize, double fovScale);\n\nvoid InitUndistortRectifyMap(Mat cameraMatrix,Mat distCoeffs,Mat r,Mat newCameraMatrix,Size size,int m1type,Mat map1,Mat map2);\nMat GetOptimalNewCameraMatrixWithParams(Mat cameraMatrix,Mat distCoeffs,Size size,double alpha,Size newImgSize,Rect* validPixROI,bool centerPrincipalPoint);\ndouble CalibrateCamera(Points3fVector objectPoints, Points2fVector imagePoints, Size imageSize, Mat cameraMatrix, Mat distCoeffs, Mat rvecs, Mat tvecs, int flag);\nvoid Undistort(Mat src, Mat dst, Mat cameraMatrix, Mat distCoeffs, Mat newCameraMatrix);\nvoid UndistortPoints(Mat distorted, Mat undistorted, Mat k, Mat d, Mat r, Mat p);\nbool CheckChessboard(Mat image, Size sz);\nbool FindChessboardCorners(Mat image, Size patternSize, Mat corners, int flags);\nbool FindChessboardCornersSB(Mat image, Size patternSize, Mat corners, int flags);\nbool FindChessboardCornersSBWithMeta(Mat image, Size patternSize, Mat corners, int flags, Mat meta);\nvoid DrawChessboardCorners(Mat image, Size patternSize, Mat corners, bool patternWasFound);\nMat EstimateAffinePartial2D(Point2fVector from, Point2fVector to);\nMat EstimateAffinePartial2DWithParams(Point2fVector from, Point2fVector to, Mat inliers, int method, double ransacReprojThreshold, size_t maxIters, double confidence, size_t refineIters);\nMat EstimateAffine2D(Point2fVector from, Point2fVector to);\nMat EstimateAffine2DWithParams(Point2fVector from, Point2fVector to, Mat inliers, int method, double ransacReprojThreshold, size_t maxIters, double confidence, size_t refineIters);\nvoid TriangulatePoints(Mat projMatr1, Mat projMatr2, Point2fVector projPoints1, Point2fVector projPoints2, Mat points4D);\nvoid ConvertPointsFromHomogeneous(Mat src, Mat dst);\nvoid Rodrigues(Mat src, Mat dst);\nbool SolvePnP(Point3fVector objectPoints, Point2fVector imagePoints, Mat cameraMatrix, Mat distCoeffs, Mat rvec, Mat tvec, bool useExtrinsicGuess, int flags);\n#ifdef __cplusplus\n}\n#endif\n\n#endif //_OPENCV3_CALIB_H\n"
        },
        {
          "name": "calib3d_string.go",
          "type": "blob",
          "size": 1.0908203125,
          "content": "package gocv\n\nfunc (c CalibFlag) String() string {\n\tswitch c {\n\tcase CalibUseIntrinsicGuess:\n\t\treturn \"calib-use-intrinsec-guess\"\n\tcase CalibRecomputeExtrinsic:\n\t\treturn \"calib-recompute-extrinsic\"\n\tcase CalibCheckCond:\n\t\treturn \"calib-check-cond\"\n\tcase CalibFixSkew:\n\t\treturn \"calib-fix-skew\"\n\tcase CalibFixK1:\n\t\treturn \"calib-fix-k1\"\n\tcase CalibFixK2:\n\t\treturn \"calib-fix-k2\"\n\tcase CalibFixK3:\n\t\treturn \"calib-fix-k3\"\n\tcase CalibFixK4:\n\t\treturn \"calib-fix-k4\"\n\tcase CalibFixIntrinsic:\n\t\treturn \"calib-fix-intrinsic\"\n\tcase CalibFixPrincipalPoint:\n\t\treturn \"calib-fix-principal-point\"\n\t}\n\treturn \"\"\n}\n\nfunc (c CalibCBFlag) String() string {\n\tswitch c {\n\tcase CalibCBAdaptiveThresh:\n\t\treturn \"calib-cb-adaptive-thresh\"\n\tcase CalibCBNormalizeImage:\n\t\treturn \"calib-cb-normalize-image\"\n\tcase CalibCBFilterQuads:\n\t\treturn \"calib-cb-filter-quads\"\n\tcase CalibCBFastCheck:\n\t\treturn \"calib-cb-fast-check\"\n\tcase CalibCBExhaustive:\n\t\treturn \"calib-cb-exhaustive\"\n\tcase CalibCBAccuracy:\n\t\treturn \"calib-cb-accuracy\"\n\tcase CalibCBLarger:\n\t\treturn \"calib-cb-larger\"\n\tcase CalibCBMarker:\n\t\treturn \"calib-cb-marker\"\n\t}\n\treturn \"\"\n}\n"
        },
        {
          "name": "calib3d_test.go",
          "type": "blob",
          "size": 21.205078125,
          "content": "package gocv\n\nimport (\n\t\"fmt\"\n\t\"image\"\n\t\"image/color\"\n\t\"math\"\n\t\"testing\"\n)\n\nfunc TestFisheyeCalibrate(t *testing.T) {\n\timg := IMRead(\"images/chessboard_4x6_distort.png\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of chessboard image\")\n\t\treturn\n\t}\n\tdefer img.Close()\n\n\tcorners := NewMat()\n\tdefer corners.Close()\n\n\tsize := image.Pt(4, 6)\n\tfound := FindChessboardCorners(img, size, &corners, 0)\n\tif !found {\n\t\tt.Error(\"chessboard pattern not found\")\n\t\treturn\n\t}\n\tif corners.Empty() {\n\t\tt.Error(\"chessboard pattern not found\")\n\t\treturn\n\t}\n\n\timagePoints := NewPoint2fVectorFromMat(corners)\n\tdefer imagePoints.Close()\n\n\tobjectPoints := NewPoint3fVector()\n\tdefer objectPoints.Close()\n\n\tfor j := 0; j < size.Y; j++ {\n\t\tfor i := 0; i < size.X; i++ {\n\t\t\tobjectPoints.Append(Point3f{\n\t\t\t\tX: float32(100 * i),\n\t\t\t\tY: float32(100 * j),\n\t\t\t\tZ: 0,\n\t\t\t})\n\t\t}\n\t}\n\n\tk := NewMat()\n\tdefer k.Close()\n\td := NewMat()\n\tdefer d.Close()\n\trvecs := NewMat()\n\tdefer rvecs.Close()\n\ttvecs := NewMat()\n\tdefer tvecs.Close()\n\n\tobjectPointsVector := NewPoints3fVector()\n\tobjectPointsVector.Append(objectPoints)\n\tdefer objectPointsVector.Close()\n\n\timagePointsVector := NewPoints2fVector()\n\timagePointsVector.Append(imagePoints)\n\tdefer imagePointsVector.Close()\n\n\tFisheyeCalibrate(\n\t\tobjectPointsVector, imagePointsVector, image.Pt(img.Cols(), img.Rows()),\n\t\t&k, &d, &rvecs, &tvecs, 0,\n\t)\n\n\tif rvecs.Empty() {\n\t\tt.Error(\"rvecs result is empty\")\n\t\treturn\n\t}\n\n\tif tvecs.Empty() {\n\t\tt.Error(\"tvecs result is empty\")\n\t\treturn\n\t}\n}\n\nfunc TestFisheyeDistortPoints(t *testing.T) {\n\tk := NewMatWithSize(3, 3, MatTypeCV64F)\n\tdefer k.Close()\n\n\tk.SetDoubleAt(0, 0, 1094.7249578198823)\n\tk.SetDoubleAt(0, 1, 0)\n\tk.SetDoubleAt(0, 2, 959.4907612030962)\n\n\tk.SetDoubleAt(1, 0, 0)\n\tk.SetDoubleAt(1, 1, 1094.9945708128778)\n\tk.SetDoubleAt(1, 2, 536.4566143451868)\n\n\tk.SetDoubleAt(2, 0, 0)\n\tk.SetDoubleAt(2, 1, 0)\n\tk.SetDoubleAt(2, 2, 1)\n\n\td := NewMatWithSize(1, 4, MatTypeCV64F)\n\tdefer d.Close()\n\n\td.SetDoubleAt(0, 0, -0.05207412392075069)\n\td.SetDoubleAt(0, 1, -0.089168300192224)\n\td.SetDoubleAt(0, 2, 0.10465607695792184)\n\td.SetDoubleAt(0, 3, -0.045693446831115585)\n\n\t// transform 3 points in one go (X and Y values of points go in each channel)\n\tsrc := NewMatWithSize(3, 1, MatTypeCV64FC2)\n\tdefer src.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\t// This camera matrix is 1920x1080. Points where x < 960 and y < 540 should move toward the top left (x and y get smaller)\n\t// The centre point should be mostly unchanged\n\t// Points where x > 960 and y > 540 should move toward the bottom right (x and y get bigger)\n\n\t// The index being used for col here is actually the channel (i.e. the point's x/y dimensions)\n\t// (since there's only 1 column so the formula: (colNumber * numChannels + channelNumber) reduces to\n\t// (0 * 2) + channelNumber\n\t// so col = 0 is the x coordinate and col = 1 is the y coordinate\n\n\tsrc.SetDoubleAt(0, 0, 480)\n\tsrc.SetDoubleAt(0, 1, 270)\n\n\tsrc.SetDoubleAt(1, 0, 960)\n\tsrc.SetDoubleAt(1, 1, 540)\n\n\tsrc.SetDoubleAt(2, 0, 1440)\n\tsrc.SetDoubleAt(2, 1, 810)\n\n\tFisheyeDistortPoints(src, &dst, k, d)\n\n\tif dst.Empty() {\n\t\tt.Error(\"final image is empty\")\n\t\treturn\n\t}\n}\n\nfunc TestFisheyeUndistorImage(t *testing.T) {\n\timg := IMRead(\"images/fisheye_sample.jpg\", IMReadUnchanged)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat test\")\n\t\treturn\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tk := NewMatWithSize(3, 3, MatTypeCV64F)\n\tdefer k.Close()\n\n\tk.SetDoubleAt(0, 0, 689.21)\n\tk.SetDoubleAt(0, 1, 0)\n\tk.SetDoubleAt(0, 2, 1295.56)\n\n\tk.SetDoubleAt(1, 0, 0)\n\tk.SetDoubleAt(1, 1, 690.48)\n\tk.SetDoubleAt(1, 2, 942.17)\n\n\tk.SetDoubleAt(2, 0, 0)\n\tk.SetDoubleAt(2, 1, 0)\n\tk.SetDoubleAt(2, 2, 1)\n\n\td := NewMatWithSize(1, 4, MatTypeCV64F)\n\tdefer d.Close()\n\n\td.SetDoubleAt(0, 0, 0)\n\td.SetDoubleAt(0, 1, 0)\n\td.SetDoubleAt(0, 2, 0)\n\td.SetDoubleAt(0, 3, 0)\n\n\tFisheyeUndistortImage(img, &dest, k, d)\n\n\tif dest.Empty() {\n\t\tt.Error(\"final image is empty\")\n\t\treturn\n\t}\n}\n\nfunc TestFisheyeUndistorImageWithParams(t *testing.T) {\n\timg := IMRead(\"images/fisheye_sample.jpg\", IMReadUnchanged)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat test\")\n\t\treturn\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tk := NewMatWithSize(3, 3, MatTypeCV64F)\n\tdefer k.Close()\n\n\tk.SetDoubleAt(0, 0, 689.21)\n\tk.SetDoubleAt(0, 1, 0)\n\tk.SetDoubleAt(0, 2, 1295.56)\n\n\tk.SetDoubleAt(1, 0, 0)\n\tk.SetDoubleAt(1, 1, 690.48)\n\tk.SetDoubleAt(1, 2, 942.17)\n\n\tk.SetDoubleAt(2, 0, 0)\n\tk.SetDoubleAt(2, 1, 0)\n\tk.SetDoubleAt(2, 2, 1)\n\n\td := NewMatWithSize(1, 4, MatTypeCV64F)\n\tdefer d.Close()\n\n\td.SetDoubleAt(0, 0, 0)\n\td.SetDoubleAt(0, 1, 0)\n\td.SetDoubleAt(0, 2, 0)\n\td.SetDoubleAt(0, 3, 0)\n\n\tknew := NewMat()\n\tdefer knew.Close()\n\n\tk.CopyTo(&knew)\n\n\tknew.SetDoubleAt(0, 0, 0.4*k.GetDoubleAt(0, 0))\n\tknew.SetDoubleAt(1, 1, 0.4*k.GetDoubleAt(1, 1))\n\n\tsize := image.Point{dest.Rows(), dest.Cols()}\n\tFisheyeUndistortImageWithParams(img, &dest, k, d, knew, size)\n\n\tif dest.Empty() {\n\t\tt.Error(\"final image is empty\")\n\t\treturn\n\t}\n}\n\nfunc TestInitUndistortRectifyMap(t *testing.T) {\n\timg := IMRead(\"images/distortion.jpg\", IMReadUnchanged)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat test\")\n\t\treturn\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tk := NewMatWithSize(3, 3, MatTypeCV64F)\n\tdefer k.Close()\n\n\tk.SetDoubleAt(0, 0, 842.0261028)\n\tk.SetDoubleAt(0, 1, 0)\n\tk.SetDoubleAt(0, 2, 667.7569792)\n\n\tk.SetDoubleAt(1, 0, 0)\n\tk.SetDoubleAt(1, 1, 707.3668897)\n\tk.SetDoubleAt(1, 2, 385.56476464)\n\n\tk.SetDoubleAt(2, 0, 0)\n\tk.SetDoubleAt(2, 1, 0)\n\tk.SetDoubleAt(2, 2, 1)\n\n\td := NewMatWithSize(1, 5, MatTypeCV64F)\n\tdefer d.Close()\n\n\td.SetDoubleAt(0, 0, -3.65584802e-01)\n\td.SetDoubleAt(0, 1, 1.41555815e-01)\n\td.SetDoubleAt(0, 2, -2.62985819e-03)\n\td.SetDoubleAt(0, 3, 2.05841873e-04)\n\td.SetDoubleAt(0, 4, -2.35021914e-02)\n\n\tnewC, roi := GetOptimalNewCameraMatrixWithParams(k, d, image.Point{X: img.Cols(), Y: img.Rows()}, (float64)(1), image.Point{X: img.Cols(), Y: img.Rows()}, false)\n\tif newC.Empty() {\n\t\tt.Error(\"final image is empty\")\n\t\treturn\n\t}\n\tfmt.Printf(\"roi:%+v\\n\", roi)\n\tdefer newC.Close()\n\tr := NewMat()\n\tdefer r.Close()\n\tmapx := NewMat()\n\tdefer mapx.Close()\n\tmapy := NewMat()\n\tdefer mapy.Close()\n\n\tInitUndistortRectifyMap(k, d, r, newC, image.Point{X: img.Cols(), Y: img.Rows()}, 5, mapx, mapy)\n\n\tRemap(img, &dest, &mapx, &mapy, InterpolationDefault, BorderConstant, color.RGBA{0, 0, 0, 0})\n\tflg := IMWrite(\"images/distortion-correct.jpg\", dest)\n\tif !flg {\n\t\tt.Error(\"IMWrite failed\")\n\t}\n}\n\nfunc TestUndistort(t *testing.T) {\n\timg := IMRead(\"images/distortion.jpg\", IMReadUnchanged)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat test\")\n\t\treturn\n\t}\n\tdefer img.Close()\n\n\tdest := img.Clone()\n\tdefer dest.Close()\n\n\tk := NewMatWithSize(3, 3, MatTypeCV64F)\n\tdefer k.Close()\n\n\tk.SetDoubleAt(0, 0, 689.21)\n\tk.SetDoubleAt(0, 1, 0)\n\tk.SetDoubleAt(0, 2, 1295.56)\n\n\tk.SetDoubleAt(1, 0, 0)\n\tk.SetDoubleAt(1, 1, 690.48)\n\tk.SetDoubleAt(1, 2, 942.17)\n\n\tk.SetDoubleAt(2, 0, 0)\n\tk.SetDoubleAt(2, 1, 0)\n\tk.SetDoubleAt(2, 2, 1)\n\n\td := NewMatWithSize(1, 4, MatTypeCV64F)\n\tdefer d.Close()\n\n\td.SetDoubleAt(0, 0, 0)\n\td.SetDoubleAt(0, 1, 0)\n\td.SetDoubleAt(0, 2, 0)\n\td.SetDoubleAt(0, 3, 0)\n\n\tknew := NewMat()\n\tdefer knew.Close()\n\n\tk.CopyTo(&knew)\n\n\tknew.SetDoubleAt(0, 0, 0.5*k.GetDoubleAt(0, 0))\n\tknew.SetDoubleAt(1, 1, 0.5*k.GetDoubleAt(1, 1))\n\n\tUndistort(img, &dest, k, d, knew)\n\n\tif dest.Empty() {\n\t\tt.Error(\"final image is empty\")\n\t\treturn\n\t}\n}\n\nfunc TestUndistortPoint(t *testing.T) {\n\tk := NewMatWithSize(3, 3, MatTypeCV64F)\n\tdefer k.Close()\n\n\tk.SetDoubleAt(0, 0, 1094.7249578198823)\n\tk.SetDoubleAt(0, 1, 0)\n\tk.SetDoubleAt(0, 2, 959.4907612030962)\n\n\tk.SetDoubleAt(1, 0, 0)\n\tk.SetDoubleAt(1, 1, 1094.9945708128778)\n\tk.SetDoubleAt(1, 2, 536.4566143451868)\n\n\tk.SetDoubleAt(2, 0, 0)\n\tk.SetDoubleAt(2, 1, 0)\n\tk.SetDoubleAt(2, 2, 1)\n\n\td := NewMatWithSize(1, 4, MatTypeCV64F)\n\tdefer d.Close()\n\n\td.SetDoubleAt(0, 0, -0.05207412392075069)\n\td.SetDoubleAt(0, 1, -0.089168300192224)\n\td.SetDoubleAt(0, 2, 0.10465607695792184)\n\td.SetDoubleAt(0, 3, -0.045693446831115585)\n\n\tr := NewMat()\n\tdefer r.Close()\n\n\t// transform 3 points in one go\n\tsrc := NewMatWithSize(3, 1, MatTypeCV64FC2)\n\tdefer src.Close()\n\tdst := NewMatWithSize(3, 1, MatTypeCV64FC2)\n\tdefer dst.Close()\n\n\t// This camera matrix is 1920x1080. Points where x < 960 and y < 540 should move toward the top left (x and y get smaller)\n\t// The centre point should be mostly unchanged\n\t// Points where x > 960 and y > 540 should move toward the bottom right (x and y get bigger)\n\n\t// The index being used for col here is actually the channel (i.e. the point's x/y dimensions)\n\t// (since there's only 1 column so the formula: (colNumber * numChannels + channelNumber) reduces to\n\t// (0 * 2) + channelNumber\n\t// so col = 0 is the x coordinate and col = 1 is the y coordinate\n\n\tsrc.SetDoubleAt(0, 0, 480)\n\tsrc.SetDoubleAt(0, 1, 270)\n\n\tsrc.SetDoubleAt(1, 0, 960)\n\tsrc.SetDoubleAt(1, 1, 540)\n\n\tsrc.SetDoubleAt(2, 0, 1920)\n\tsrc.SetDoubleAt(2, 1, 1080)\n\n\tUndistortPoints(src, &dst, k, d, r, k)\n\n\tif dst.GetDoubleAt(0, 0) >= 480 || dst.GetDoubleAt(0, 1) >= 270 {\n\t\tt.Error(\"undistortion expected top left point to move further up and left\")\n\t\treturn\n\t}\n\n\tif math.Round(dst.GetDoubleAt(1, 0)) != 960 || math.Round(dst.GetDoubleAt(1, 1)) != 540 {\n\t\tt.Error(\"undistortion expected centre point to be nearly unchanged\")\n\t\treturn\n\t}\n\n\tif dst.GetDoubleAt(2, 0) != 1920 || dst.GetDoubleAt(2, 1) != 1080 {\n\t\tt.Error(\"undistortion expected bottom right corner to be unchanged\")\n\t\treturn\n\t}\n\n}\n\nfunc TestFisheyeUndistortPoint(t *testing.T) {\n\tk := NewMatWithSize(3, 3, MatTypeCV64F)\n\tdefer k.Close()\n\n\tk.SetDoubleAt(0, 0, 1094.7249578198823)\n\tk.SetDoubleAt(0, 1, 0)\n\tk.SetDoubleAt(0, 2, 959.4907612030962)\n\n\tk.SetDoubleAt(1, 0, 0)\n\tk.SetDoubleAt(1, 1, 1094.9945708128778)\n\tk.SetDoubleAt(1, 2, 536.4566143451868)\n\n\tk.SetDoubleAt(2, 0, 0)\n\tk.SetDoubleAt(2, 1, 0)\n\tk.SetDoubleAt(2, 2, 1)\n\n\td := NewMatWithSize(1, 4, MatTypeCV64F)\n\tdefer d.Close()\n\n\td.SetDoubleAt(0, 0, -0.05207412392075069)\n\td.SetDoubleAt(0, 1, -0.089168300192224)\n\td.SetDoubleAt(0, 2, 0.10465607695792184)\n\td.SetDoubleAt(0, 3, -0.045693446831115585)\n\n\tr := NewMat()\n\tdefer r.Close()\n\n\t// transform 3 points in one go (X and Y values of points go in each channel)\n\tsrc := NewMatWithSize(3, 1, MatTypeCV64FC2)\n\tdefer src.Close()\n\tdst := NewMatWithSize(3, 1, MatTypeCV64FC2)\n\tdefer dst.Close()\n\n\t// This camera matrix is 1920x1080. Points where x < 960 and y < 540 should move toward the top left (x and y get smaller)\n\t// The centre point should be mostly unchanged\n\t// Points where x > 960 and y > 540 should move toward the bottom right (x and y get bigger)\n\n\t// The index being used for col here is actually the channel (i.e. the point's x/y dimensions)\n\t// (since there's only 1 column so the formula: (colNumber * numChannels + channelNumber) reduces to\n\t// (0 * 2) + channelNumber\n\t// so col = 0 is the x coordinate and col = 1 is the y coordinate\n\n\tsrc.SetDoubleAt(0, 0, 480)\n\tsrc.SetDoubleAt(0, 1, 270)\n\n\tsrc.SetDoubleAt(1, 0, 960)\n\tsrc.SetDoubleAt(1, 1, 540)\n\n\tsrc.SetDoubleAt(2, 0, 1440)\n\tsrc.SetDoubleAt(2, 1, 810)\n\n\tkNew := NewMat()\n\tdefer kNew.Close()\n\n\tk.CopyTo(&kNew)\n\n\tkNew.SetDoubleAt(0, 0, 0.4*k.GetDoubleAt(0, 0))\n\tkNew.SetDoubleAt(1, 1, 0.4*k.GetDoubleAt(1, 1))\n\n\timgSize := image.Point{X: 1920, Y: 1080}\n\n\tEstimateNewCameraMatrixForUndistortRectify(k, d, imgSize, r, &kNew, 1, imgSize, 1)\n\n\tFisheyeUndistortPoints(src, &dst, k, d, r, kNew)\n\n\tif dst.GetDoubleAt(0, 0) == 0 {\n\t\tt.Error(\"expected destination Mat to be populated\")\n\t}\n}\n\nfunc TestCheckChessboard(t *testing.T) {\n\timg := IMRead(\"images/chessboard_4x6.png\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of chessboard image\")\n\t\treturn\n\t}\n\tdefer img.Close()\n\n\tif !CheckChessboard(img, image.Point{X: 4, Y: 6}) {\n\t\tt.Error(\"chessboard pattern not found\")\n\t\treturn\n\t}\n}\n\nfunc TestFindAndDrawChessboard(t *testing.T) {\n\timg := IMRead(\"images/chessboard_4x6.png\", IMReadUnchanged)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of chessboard image\")\n\t\treturn\n\t}\n\tdefer img.Close()\n\n\tcorners := NewMat()\n\tdefer corners.Close()\n\n\tfound := FindChessboardCorners(img, image.Point{X: 4, Y: 6}, &corners, 0)\n\tif found == false {\n\t\tt.Error(\"chessboard pattern not found\")\n\t\treturn\n\t}\n\tif corners.Empty() {\n\t\tt.Error(\"chessboard pattern not found\")\n\t\treturn\n\t}\n\n\timg2 := NewMatWithSize(150, 150, MatTypeCV8U)\n\tdefer img2.Close()\n\n\tDrawChessboardCorners(&img2, image.Pt(4, 6), corners, true)\n\tif img2.Empty() {\n\t\tt.Error(\"Error in DrawChessboardCorners test\")\n\t}\n}\n\nfunc TestFindAndDrawChessboardSB(t *testing.T) {\n\timg := IMRead(\"images/chessboard_4x6.png\", IMReadUnchanged)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of chessboard image\")\n\t\treturn\n\t}\n\tdefer img.Close()\n\n\tcorners := NewMat()\n\tdefer corners.Close()\n\n\tfound := FindChessboardCornersSB(img, image.Point{X: 4, Y: 6}, &corners, 0)\n\tif found == false {\n\t\tt.Error(\"chessboard pattern not found\")\n\t\treturn\n\t}\n\tif corners.Empty() {\n\t\tt.Error(\"chessboard pattern not found\")\n\t\treturn\n\t}\n\n\timg2 := NewMatWithSize(150, 150, MatTypeCV8U)\n\tdefer img2.Close()\n\n\tDrawChessboardCorners(&img2, image.Pt(4, 6), corners, true)\n\tif img2.Empty() {\n\t\tt.Error(\"Error in DrawChessboardCorners test\")\n\t}\n}\n\nfunc TestFindChessboardCornersSBWithMeta(t *testing.T) {\n\timg := IMRead(\"images/chessboard_4x6.png\", IMReadUnchanged)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of chessboard image\")\n\t\treturn\n\t}\n\tdefer img.Close()\n\n\tcorners := NewMat()\n\tdefer corners.Close()\n\n\tmeta := NewMat()\n\tdefer meta.Close()\n\n\tfound := FindChessboardCornersSBWithMeta(img, image.Point{X: 4, Y: 6}, &corners, 0, &meta)\n\tif found == false {\n\t\tt.Error(\"chessboard pattern not found\")\n\t\treturn\n\t}\n\tif corners.Empty() {\n\t\tt.Error(\"chessboard pattern not found\")\n\t\treturn\n\t}\n\n\timg2 := NewMatWithSize(150, 150, MatTypeCV8U)\n\tdefer img2.Close()\n\n\tDrawChessboardCorners(&img2, image.Pt(4, 6), corners, true)\n\tif img2.Empty() {\n\t\tt.Error(\"Error in DrawChessboardCorners test\")\n\t}\n}\n\nfunc TestCalibrateCamera(t *testing.T) {\n\timg := IMRead(\"images/chessboard_4x6_distort.png\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of chessboard image\")\n\t\treturn\n\t}\n\tdefer img.Close()\n\n\tcorners := NewMat()\n\tdefer corners.Close()\n\n\tsize := image.Pt(4, 6)\n\tfound := FindChessboardCorners(img, size, &corners, 0)\n\tif !found {\n\t\tt.Error(\"chessboard pattern not found\")\n\t\treturn\n\t}\n\tif corners.Empty() {\n\t\tt.Error(\"chessboard pattern not found\")\n\t\treturn\n\t}\n\n\timagePoints := NewPoint2fVectorFromMat(corners)\n\tdefer imagePoints.Close()\n\n\tobjectPoints := NewPoint3fVector()\n\tdefer objectPoints.Close()\n\n\tfor j := 0; j < size.Y; j++ {\n\t\tfor i := 0; i < size.X; i++ {\n\t\t\tobjectPoints.Append(Point3f{\n\t\t\t\tX: float32(100 * i),\n\t\t\t\tY: float32(100 * j),\n\t\t\t\tZ: 0,\n\t\t\t})\n\t\t}\n\t}\n\n\tcameraMatrix := NewMat()\n\tdefer cameraMatrix.Close()\n\tdistCoeffs := NewMat()\n\tdefer distCoeffs.Close()\n\trvecs := NewMat()\n\tdefer rvecs.Close()\n\ttvecs := NewMat()\n\tdefer tvecs.Close()\n\n\tobjectPointsVector := NewPoints3fVector()\n\tobjectPointsVector.Append(objectPoints)\n\tdefer objectPointsVector.Close()\n\n\timagePointsVector := NewPoints2fVector()\n\timagePointsVector.Append(imagePoints)\n\tdefer imagePointsVector.Close()\n\n\tCalibrateCamera(\n\t\tobjectPointsVector, imagePointsVector, image.Pt(img.Cols(), img.Rows()),\n\t\t&cameraMatrix, &distCoeffs, &rvecs, &tvecs, 0,\n\t)\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\tUndistort(img, &dest, cameraMatrix, distCoeffs, cameraMatrix)\n\n\ttarget := IMRead(\"images/chessboard_4x6_distort_correct.png\", IMReadGrayScale)\n\tdefer target.Close()\n\n\txor := NewMat()\n\tdefer xor.Close()\n\n\t// The method for compare is ugly : different pix number < 0.5%\n\tBitwiseXor(dest, target, &xor)\n\tdifferentPixelsNumber := xor.Sum().Val1\n\tmaxDifferentPixelsNumber := float64(img.Cols()*img.Rows()) * 0.005\n\tif differentPixelsNumber > maxDifferentPixelsNumber {\n\t\tt.Error(\"the undisorted image not equal the target one:\", differentPixelsNumber, \"bigger than\", maxDifferentPixelsNumber)\n\t}\n}\n\nfunc TestEstimateAffinePartial2D(t *testing.T) {\n\tsrc := []Point2f{\n\t\t{0, 0},\n\t\t{10, 5},\n\t\t{10, 10},\n\t\t{5, 10},\n\t}\n\n\tdst := []Point2f{\n\t\t{0, 0},\n\t\t{10, 0},\n\t\t{10, 10},\n\t\t{0, 10},\n\t}\n\n\tpvsrc := NewPoint2fVectorFromPoints(src)\n\tdefer pvsrc.Close()\n\n\tpvdst := NewPoint2fVectorFromPoints(dst)\n\tdefer pvdst.Close()\n\n\tm := EstimateAffinePartial2D(pvsrc, pvdst)\n\tdefer m.Close()\n\n\tif m.Cols() != 3 {\n\t\tt.Errorf(\"TestEstimateAffinePartial2D(): unexpected cols = %v, want = %v\", m.Cols(), 3)\n\t}\n\tif m.Rows() != 2 {\n\t\tt.Errorf(\"TestEstimateAffinePartial2D(): unexpected rows = %v, want = %v\", m.Rows(), 2)\n\t}\n}\n\nfunc TestEstimateAffinePartial2DWithParams(t *testing.T) {\n\tsrc := []Point2f{\n\t\t{0, 0},\n\t\t{10, 5},\n\t\t{10, 10},\n\t\t{5, 10},\n\t}\n\n\tdst := []Point2f{\n\t\t{0, 0},\n\t\t{10, 0},\n\t\t{10, 10},\n\t\t{0, 10},\n\t}\n\n\tpvsrc := NewPoint2fVectorFromPoints(src)\n\tdefer pvsrc.Close()\n\n\tpvdst := NewPoint2fVectorFromPoints(dst)\n\tdefer pvdst.Close()\n\n\tinliers := NewMat()\n\tdefer inliers.Close()\n\tmethod := 8\n\transacProjThreshold := 3.0\n\tmaxiters := uint(2000)\n\tconfidence := 0.99\n\trefineIters := uint(10)\n\n\tm := EstimateAffinePartial2DWithParams(pvsrc, pvdst, inliers, method, ransacProjThreshold, maxiters, confidence, refineIters)\n\tdefer m.Close()\n\n\tif m.Cols() != 3 {\n\t\tt.Errorf(\"TestEstimateAffinePartial2D(): unexpected cols = %v, want = %v\", m.Cols(), 3)\n\t}\n\tif m.Rows() != 2 {\n\t\tt.Errorf(\"TestEstimateAffinePartial2D(): unexpected rows = %v, want = %v\", m.Rows(), 2)\n\t}\n}\n\nfunc TestEstimateAffine2D(t *testing.T) {\n\tsrc := []Point2f{\n\t\t{0, 0},\n\t\t{10, 5},\n\t\t{10, 10},\n\t\t{5, 10},\n\t}\n\n\tdst := []Point2f{\n\t\t{0, 0},\n\t\t{10, 0},\n\t\t{10, 10},\n\t\t{0, 10},\n\t}\n\n\tpvsrc := NewPoint2fVectorFromPoints(src)\n\tdefer pvsrc.Close()\n\n\tpvdst := NewPoint2fVectorFromPoints(dst)\n\tdefer pvdst.Close()\n\n\tm := EstimateAffine2D(pvsrc, pvdst)\n\tdefer m.Close()\n\n\tif m.Cols() != 3 {\n\t\tt.Errorf(\"TestEstimateAffine2D(): unexpected cols = %v, want = %v\", m.Cols(), 3)\n\t}\n\tif m.Rows() != 2 {\n\t\tt.Errorf(\"TestEstimateAffine2D(): unexpected rows = %v, want = %v\", m.Rows(), 2)\n\t}\n}\n\nfunc TestEstimateAffine2DWithParams(t *testing.T) {\n\tsrc := []Point2f{\n\t\t{0, 0},\n\t\t{10, 5},\n\t\t{10, 10},\n\t\t{5, 10},\n\t}\n\n\tdst := []Point2f{\n\t\t{0, 0},\n\t\t{10, 0},\n\t\t{10, 10},\n\t\t{0, 10},\n\t}\n\n\tpvsrc := NewPoint2fVectorFromPoints(src)\n\tdefer pvsrc.Close()\n\n\tpvdst := NewPoint2fVectorFromPoints(dst)\n\tdefer pvdst.Close()\n\n\tinliers := NewMat()\n\tdefer inliers.Close()\n\tmethod := 8\n\transacProjThreshold := 3.0\n\tmaxiters := uint(2000)\n\tconfidence := 0.99\n\trefineIters := uint(10)\n\n\tm := EstimateAffine2DWithParams(pvsrc, pvdst, inliers, method, ransacProjThreshold, maxiters, confidence, refineIters)\n\tdefer m.Close()\n\n\tif m.Cols() != 3 {\n\t\tt.Errorf(\"TestEstimateAffine2DWithParams(): unexpected cols = %v, want = %v\", m.Cols(), 3)\n\t}\n\tif m.Rows() != 2 {\n\t\tt.Errorf(\"TestEstimateAffine2DWithParams(): unexpected rows = %v, want = %v\", m.Rows(), 2)\n\t}\n}\n\nfunc TestTriangulatePoints(t *testing.T) {\n\tprojMat1, projMat2 := NewMatWithSize(3, 4, MatTypeCV64F), NewMatWithSize(3, 4, MatTypeCV64F)\n\tdefer projMat1.Close()\n\tdefer projMat2.Close()\n\tprojPoints1, projPoints2 := NewPoint2fVectorFromPoints([]Point2f{{Y: 1.0, X: 2.0}}), NewPoint2fVectorFromPoints([]Point2f{{Y: 3.0, X: 4.0}})\n\tdefer projPoints1.Close()\n\tdefer projPoints2.Close()\n\thomogeneous := NewMat()\n\tdefer homogeneous.Close()\n\tTriangulatePoints(projMat1, projMat2, projPoints1, projPoints2, &homogeneous)\n\tif homogeneous.Empty() {\n\t\tt.Errorf(\"TriangulatePoints(): output homogeneous mat is empty\")\n\t}\n}\n\nfunc TestConvertPointsFromHomogeneous(t *testing.T) {\n\thomogeneous := NewMatWithSize(1, 4, MatTypeCV32F)\n\tdefer homogeneous.Close()\n\thomogeneous.SetFloatAt(0, 0, 1)\n\thomogeneous.SetFloatAt(0, 1, 2)\n\thomogeneous.SetFloatAt(0, 2, 4)\n\thomogeneous.SetFloatAt(0, 3, 2)\n\teuclidean := NewMat()\n\tdefer euclidean.Close()\n\tConvertPointsFromHomogeneous(homogeneous, &euclidean)\n\tif euclidean.Empty() {\n\t\tt.Fatalf(\"ConvertPointsFromHomogeneous(): output euclidean mat is empty\")\n\t}\n\tptsVector := NewPoint3fVectorFromMat(euclidean)\n\tdefer ptsVector.Close()\n\tpts := ptsVector.ToPoints()\n\tif len(pts) != 1 {\n\t\tt.Fatalf(\"ConvertPointsFromHomogeneous(): euclidean mat converted to points is empty\")\n\t}\n\tif pts[0].X != 0.5 {\n\t\tt.Errorf(\"ConvertPointsFromHomogeneous(): euclidean X - got %v, want %v\", pts[0].X, 0.5)\n\t}\n\tif pts[0].Y != 1 {\n\t\tt.Errorf(\"ConvertPointsFromHomogeneous(): euclidean Y - got %v, want %v\", pts[0].Y, 1)\n\t}\n\tif pts[0].Z != 2 {\n\t\tt.Errorf(\"ConvertPointsFromHomogeneous(): euclidean Z - got %v, want %v\", pts[0].Z, 2)\n\t}\n}\n\nfunc TestRodrigues(t *testing.T) {\n\tk := NewMatWithSize(3, 3, MatTypeCV64F)\n\tdefer k.Close()\n\n\tk.SetDoubleAt(0, 0, 689.21)\n\tk.SetDoubleAt(0, 1, 0)\n\tk.SetDoubleAt(0, 2, 1295.56)\n\n\tk.SetDoubleAt(1, 0, 0)\n\tk.SetDoubleAt(1, 1, 690.48)\n\tk.SetDoubleAt(1, 2, 942.17)\n\n\tk.SetDoubleAt(2, 0, 0)\n\tk.SetDoubleAt(2, 1, 0)\n\tk.SetDoubleAt(2, 2, 1)\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tRodrigues(k, &dest)\n\n\tif dest.Empty() {\n\t\tt.Error(\"final result is empty\")\n\t\treturn\n\t}\n}\n\nfunc TestSolvePnP(t *testing.T) {\n\tpts := []Point3f{\n\t\t{10.0, 10.0, 0.1},\n\t\t{10.0, 20.0, 1.0},\n\t\t{20.5, 21.5, 2.0},\n\t\t{10.0, 20.0, 1.0},\n\t}\n\n\tobjectPointsVector := NewPoint3fVectorFromPoints(pts)\n\tdefer objectPointsVector.Close()\n\n\tpts2 := []Point2f{\n\t\t{10.0, 10.0},\n\t\t{10.0, 20.0},\n\t\t{20.5, 21.5},\n\t\t{25.5, 30.5},\n\t}\n\n\timagePointsVector := NewPoint2fVectorFromPoints(pts2)\n\tdefer imagePointsVector.Close()\n\n\tcameraMatrix := Eye(3, 3, MatTypeCV64F)\n\tdefer cameraMatrix.Close()\n\tdistCoeffs := NewMat()\n\tdefer distCoeffs.Close()\n\trvecs := NewMat()\n\tdefer rvecs.Close()\n\ttvecs := NewMat()\n\tdefer tvecs.Close()\n\n\tSolvePnP(objectPointsVector, imagePointsVector, cameraMatrix, distCoeffs,\n\t\t&rvecs, &tvecs, false, 0)\n\n\tif rvecs.Empty() {\n\t\tt.Error(\"rvecs result is empty\")\n\t\treturn\n\t}\n\n\tif tvecs.Empty() {\n\t\tt.Error(\"tvecs result is empty\")\n\t\treturn\n\t}\n}\n"
        },
        {
          "name": "cgo.go",
          "type": "blob",
          "size": 0.7333984375,
          "content": "//go:build !customenv && !opencvstatic\n\npackage gocv\n\n// Changes here should be mirrored in contrib/cgo.go and cuda/cgo.go.\n\n/*\n#cgo !windows pkg-config: opencv4\n#cgo CXXFLAGS:   --std=c++11\n#cgo windows  CPPFLAGS:   -IC:/opencv/build/install/include\n#cgo windows  LDFLAGS:    -LC:/opencv/build/install/x64/mingw/lib -lopencv_core4100 -lopencv_face4100 -lopencv_videoio4100 -lopencv_imgproc4100 -lopencv_highgui4100 -lopencv_imgcodecs4100 -lopencv_objdetect4100 -lopencv_features2d4100 -lopencv_video4100 -lopencv_dnn4100 -lopencv_xfeatures2d4100 -lopencv_plot4100 -lopencv_tracking4100 -lopencv_img_hash4100 -lopencv_calib3d4100 -lopencv_bgsegm4100 -lopencv_photo4100 -lopencv_aruco4100 -lopencv_wechat_qrcode4100 -lopencv_ximgproc4100\n*/\nimport \"C\"\n"
        },
        {
          "name": "cgo_static.go",
          "type": "blob",
          "size": 6.06640625,
          "content": "//go:build !customenv && opencvstatic && linux\n\npackage gocv\n\n// Changes here should be mirrored in contrib/cgo_static.go and cuda/cgo_static.go.\n\n/*\n#cgo CXXFLAGS: --std=c++11\n#cgo CPPFLAGS: -I/usr/local/include -I/usr/local/include/opencv4\n#cgo amd64 LDFLAGS: -O2 -g -static -L/usr/local/lib -L/usr/local/lib/opencv4/3rdparty -lopencv_gapi -lopencv_stitching -lopencv_aruco -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_dnn_objdetect -lopencv_dnn_superres -lopencv_dpm -lopencv_face -lopencv_freetype -lopencv_fuzzy -lopencv_hfs -lopencv_img_hash -lopencv_intensity_transform -lopencv_line_descriptor -lopencv_mcc -lopencv_quality -lopencv_rapid -lopencv_reg -lopencv_rgbd -lopencv_saliency -lopencv_signal -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_superres -lopencv_optflow -lopencv_surface_matching -lopencv_tracking -lopencv_highgui -lopencv_datasets -lopencv_text -lopencv_plot -lopencv_videostab -lopencv_videoio -lopencv_wechat_qrcode -lopencv_xfeatures2d -lopencv_shape -lopencv_ml -lopencv_ximgproc -lopencv_video -lopencv_xobjdetect -lopencv_objdetect -lopencv_calib3d -lopencv_imgcodecs -lopencv_features2d -lopencv_dnn -lopencv_flann -lopencv_xphoto -lopencv_photo -lopencv_imgproc -lopencv_core -llibprotobuf -lade -ltbb -littnotify -llibjpeg-turbo -llibwebp -llibtiff -llibopenjp2 -lIlmImf -lquirc -lippiw -lippicv -lpng -lz -lgcc -lstdc++ -lfreetype -lharfbuzz -ldl -lm -lpthread -lrt -lavdevice -lm -latomic -lavfilter -pthread -lm -latomic -lswscale -lm -latomic -lpostproc -lm -latomic -lavformat -lm -latomic -lz -lavcodec -lvpx -lm -lvpx -lm -lvpx -lm -lvpx -lm -pthread -lm -latomic -lz -lx264 -lswresample -lm -latomic -lavutil -pthread -lm -latomic\n#cgo arm64 LDFLAGS: -O2 -g -static -L/usr/local/lib -L/usr/local/lib/opencv4/3rdparty -lopencv_gapi -lopencv_stitching -lopencv_aruco -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_dnn_objdetect -lopencv_dnn_superres -lopencv_dpm -lopencv_face -lopencv_freetype -lopencv_fuzzy -lopencv_hfs -lopencv_img_hash -lopencv_intensity_transform -lopencv_line_descriptor -lopencv_mcc -lopencv_quality -lopencv_rapid -lopencv_reg -lopencv_rgbd -lopencv_saliency -lopencv_signal -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_superres -lopencv_optflow -lopencv_surface_matching -lopencv_tracking -lopencv_highgui -lopencv_datasets -lopencv_text -lopencv_plot -lopencv_videostab -lopencv_videoio -lopencv_wechat_qrcode -lopencv_xfeatures2d -lopencv_shape -lopencv_ml -lopencv_ximgproc -lopencv_video -lopencv_xobjdetect -lopencv_objdetect -lopencv_calib3d -lopencv_imgcodecs -lopencv_features2d -lopencv_dnn -lopencv_flann -lopencv_xphoto -lopencv_photo -lopencv_imgproc -lopencv_core -llibprotobuf -lade -ltbb -littnotify -llibjpeg-turbo -llibwebp -llibtiff -llibopenjp2 -lIlmImf -lquirc -ltegra_hal -lpng -lz -lgcc -lstdc++ -lfreetype -lharfbuzz -ldl -lm -lpthread -lrt -lavdevice -lm -latomic -lavfilter -pthread -lm -latomic -lswscale -lm -latomic -lpostproc -lm -latomic -lavformat -lm -latomic -lz -lavcodec -lvpx -lm -lvpx -lm -lvpx -lm -lvpx -lm -pthread -lm -latomic -lz -lx264 -lswresample -lm -latomic -lavutil -pthread -lm -latomic\n*/\nimport \"C\"\n\n// # cgo amd64 LDFLAGS: -O2 -g -static -L/usr/local/lib -L/usr/local/lib/opencv4/3rdparty -lopencv_gapi -lopencv_stitching -lopencv_aruco -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_dnn_objdetect -lopencv_dnn_superres -lopencv_dpm -lopencv_face -lopencv_freetype -lopencv_fuzzy -lopencv_hfs -lopencv_img_hash -lopencv_intensity_transform -lopencv_line_descriptor -lopencv_mcc -lopencv_quality -lopencv_rapid -lopencv_reg -lopencv_rgbd -lopencv_saliency -lopencv_signal -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_superres -lopencv_optflow -lopencv_surface_matching -lopencv_tracking -lopencv_highgui -lopencv_datasets -lopencv_text -lopencv_plot -lopencv_videostab -lopencv_videoio -lopencv_wechat_qrcode -lopencv_xfeatures2d -lopencv_shape -lopencv_ml -lopencv_ximgproc -lopencv_video -lopencv_xobjdetect -lopencv_objdetect -lopencv_calib3d -lopencv_imgcodecs -lopencv_features2d -lopencv_dnn -lopencv_flann -lopencv_xphoto -lopencv_photo -lopencv_imgproc -lopencv_core -llibprotobuf -lade -ltbb -littnotify -llibjpeg-turbo -llibwebp -llibtiff -llibopenjp2 -lIlmImf -lquirc -lippiw -lippicv -lpng -lz -lgcc -lstdc++ -lfreetype -lharfbuzz -ldl -lm -lpthread -lrt -lavdevice -lm -latomic -lavfilter -pthread -lm -latomic -lswscale -lm -latomic -lpostproc -lm -latomic -lavformat -lm -latomic -lz -lavcodec -lvpx -lm -lvpx -lm -lvpx -lm -lvpx -lm -pthread -lm -latomic -lz -lx264 -lx265 -lswresample -lm -latomic -lavutil -pthread -lm -latomic -lnuma\n// # cgo arm64 LDFLAGS: -O2 -g -static -L/usr/local/lib -L/usr/local/lib/opencv4/3rdparty -lopencv_gapi -lopencv_stitching -lopencv_aruco -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_dnn_objdetect -lopencv_dnn_superres -lopencv_dpm -lopencv_face -lopencv_freetype -lopencv_fuzzy -lopencv_hfs -lopencv_img_hash -lopencv_intensity_transform -lopencv_line_descriptor -lopencv_mcc -lopencv_quality -lopencv_rapid -lopencv_reg -lopencv_rgbd -lopencv_saliency -lopencv_signal -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_superres -lopencv_optflow -lopencv_surface_matching -lopencv_tracking -lopencv_highgui -lopencv_datasets -lopencv_text -lopencv_plot -lopencv_videostab -lopencv_videoio -lopencv_wechat_qrcode -lopencv_xfeatures2d -lopencv_shape -lopencv_ml -lopencv_ximgproc -lopencv_video -lopencv_xobjdetect -lopencv_objdetect -lopencv_calib3d -lopencv_imgcodecs -lopencv_features2d -lopencv_dnn -lopencv_flann -lopencv_xphoto -lopencv_photo -lopencv_imgproc -lopencv_core -llibprotobuf -lade -ltbb -littnotify -llibjpeg-turbo -llibwebp -llibtiff -llibopenjp2 -lIlmImf -lquirc -ltegra_hal -lpng -lz -lfreetype  -lgcc -lstdc++ -lharfbuzz -ldl -lm -lpthread -lrt -lavdevice -lm -latomic -lavfilter -pthread -lm -latomic -lswscale -lm -latomic -lpostproc -lm -latomic -lavformat -lm -latomic -lz -lavcodec -lvpx -lm -lvpx -lm -lvpx -lm -lvpx -lm -pthread -lm -latomic -lz -lx264 -lx265 -lswresample -lm -latomic -lavutil -pthread -lm -latomic -lnuma\n"
        },
        {
          "name": "cgo_static_darwin.go",
          "type": "blob",
          "size": 0.234375,
          "content": "//go:build !customenv && opencvstatic && darwin\n\npackage gocv\n\n// Changes here should be mirrored in contrib/cgo_static_darwin.go and cuda/cgo_static_darwin.go.\n\n/*\n#cgo CXXFLAGS: --std=c++11\n#cgo pkg-config: --static opencv4\n*/\nimport \"C\"\n"
        },
        {
          "name": "cgo_static_windows.go",
          "type": "blob",
          "size": 1.56640625,
          "content": "//go:build !customenv && opencvstatic && windows\n\npackage gocv\n\n// Changes here should be mirrored in contrib/cgo_static_windows.go and cuda/cgo_static_windows.go.\n\n/*\n#cgo CXXFLAGS:   --std=c++11\n#cgo CPPFLAGS:   -IC:/opencv/build/install/include\n#cgo LDFLAGS:    -LC:/opencv/build/install/x64/mingw/staticlib -lopencv_stereo4100 -lopencv_tracking4100 -lopencv_superres4100 -lopencv_stitching4100 -lopencv_optflow4100 -lopencv_gapi4100 -lopencv_face4100 -lopencv_dpm4100 -lopencv_dnn_objdetect4100 -lopencv_ccalib4100 -lopencv_bioinspired4100 -lopencv_bgsegm4100 -lopencv_aruco4100 -lopencv_xobjdetect4100 -lopencv_ximgproc4100 -lopencv_xfeatures2d4100 -lopencv_videostab4100 -lopencv_video4100 -lopencv_structured_light4100 -lopencv_shape4100 -lopencv_rgbd4100 -lopencv_rapid4100 -lopencv_objdetect4100 -lopencv_mcc4100 -lopencv_highgui4100 -lopencv_datasets4100 -lopencv_calib3d4100 -lopencv_videoio4100 -lopencv_text4100 -lopencv_line_descriptor4100 -lopencv_imgcodecs4100 -lopencv_img_hash4100 -lopencv_hfs4100 -lopencv_fuzzy4100 -lopencv_features2d4100 -lopencv_dnn_superres4100 -lopencv_dnn4100 -lopencv_xphoto4100 -lopencv_wechat_qrcode4100 -lopencv_surface_matching4100 -lopencv_reg4100 -lopencv_quality4100 -lopencv_plot4100 -lopencv_photo4100 -lopencv_phase_unwrapping4100 -lopencv_ml4100 -lopencv_intensity_transform4100 -lopencv_imgproc4100 -lopencv_flann4100 -lopencv_core4100 -lade -lquirc -llibprotobuf -lIlmImf -llibpng -llibopenjp2 -llibwebp -llibtiff -llibjpeg-turbo -lzlib -lkernel32 -lgdi32 -lwinspool -lshell32 -lole32 -loleaut32 -luuid -lcomdlg32 -ladvapi32 -luser32\n*/\nimport \"C\"\n"
        },
        {
          "name": "cmd",
          "type": "tree",
          "content": null
        },
        {
          "name": "codecov.yml",
          "type": "blob",
          "size": 0.044921875,
          "content": "ignore:\n  - \"*_string.go\"\n  - \"*/*_string.go\"\n"
        },
        {
          "name": "contrib",
          "type": "tree",
          "content": null
        },
        {
          "name": "core.cpp",
          "type": "blob",
          "size": 32.296875,
          "content": "#include \"core.h\"\n#include <string.h>\n\n// Mat_New creates a new empty Mat\nMat Mat_New() {\n    return new cv::Mat();\n}\n\n// Mat_NewWithSize creates a new Mat with a specific size dimension and number of channels.\nMat Mat_NewWithSize(int rows, int cols, int type) {\n    return new cv::Mat(rows, cols, type, 0.0);\n}\n\n// Mat_NewWithSizes creates a new Mat with specific dimension sizes and number of channels.\nMat Mat_NewWithSizes(struct IntVector sizes, int type) {\n\tstd::vector<int> sizess;\n    for (int i = 0; i < sizes.length; ++i) {\n        sizess.push_back(sizes.val[i]);\n    }\n    return new cv::Mat(sizess, type);\n}\n\n// Mat_NewFromScalar creates a new Mat from a Scalar. Intended to be used\n// for Mat comparison operation such as InRange.\nMat Mat_NewFromScalar(Scalar ar, int type) {\n    cv::Scalar c = cv::Scalar(ar.val1, ar.val2, ar.val3, ar.val4);\n    return new cv::Mat(1, 1, type, c);\n}\n\n// Mat_NewWithSizeFromScalar creates a new Mat from a Scalar with a specific size dimension and number of channels\nMat Mat_NewWithSizeFromScalar(Scalar ar, int rows, int cols, int type) {\n    cv::Scalar c = cv::Scalar(ar.val1, ar.val2, ar.val3, ar.val4);\n    return new cv::Mat(rows, cols, type, c);\n}\n\nMat Mat_NewFromBytes(int rows, int cols, int type, struct ByteArray buf) {\n    return new cv::Mat(rows, cols, type, buf.data);\n}\n\n// Mat_NewWithSizesFromScalar creates multidimensional Mat from a scalar\nMat Mat_NewWithSizesFromScalar(IntVector sizes, int type, Scalar ar) {\n    std::vector<int> _sizes;\n    for (int i = 0, *v = sizes.val; i < sizes.length; ++v, ++i) {\n        _sizes.push_back(*v);\n    }\n\n    cv::Scalar c = cv::Scalar(ar.val1, ar.val2, ar.val3, ar.val4);\n    return new cv::Mat(_sizes, type, c);\n}\n\n// Mat_NewWithSizesFromBytes creates multidimensional Mat from a bytes\nMat Mat_NewWithSizesFromBytes(IntVector sizes, int type, struct ByteArray buf) {\n    std::vector<int> _sizes;\n    for (int i = 0, *v = sizes.val; i < sizes.length; ++v, ++i) {\n        _sizes.push_back(*v);\n    }\n\n    return new cv::Mat(_sizes, type, buf.data);\n}\n\nMat Eye(int rows, int cols, int type) {\n    cv::Mat* mat = new cv::Mat(rows, cols, type);\n    *mat = cv::Mat::eye(rows, cols, type);\n    return mat;\n}\n\nMat Zeros(int rows, int cols, int type) {\n    cv::Mat* mat = new cv::Mat(rows, cols, type);\n    *mat = cv::Mat::zeros(rows, cols, type);\n    return mat;\n}\n\nMat Ones(int rows, int cols, int type) {\n    cv::Mat* mat = new cv::Mat(rows, cols, type);\n    *mat = cv::Mat::ones(rows, cols, type);\n    return mat;\n}\n\nMat Mat_FromPtr(Mat m, int rows, int cols, int type, int prow, int pcol) {\n    return new cv::Mat(rows, cols, type, m->ptr(prow, pcol));\n}\n\n// Mat_Close deletes an existing Mat\nvoid Mat_Close(Mat m) {\n    delete m;\n}\n\n// Mat_Empty tests if a Mat is empty\nint Mat_Empty(Mat m) {\n    return m->empty();\n}\n\n// Mat_IsContinuous tests if a Mat is continuous\nbool Mat_IsContinuous(Mat m) {\n    return m->isContinuous();\n}\n\nvoid Mat_Inv(Mat m) {\n    m->inv();\n}\n\nMat Mat_Col(Mat m, int c) {\n    return new cv::Mat(m->col(c));\n}\n\nMat Mat_Row(Mat m, int r) {\n    return new cv::Mat(m->row(r));\n}\n\n// Mat_Clone returns a clone of this Mat\nMat Mat_Clone(Mat m) {\n    return new cv::Mat(m->clone());\n}\n\n// Mat_CopyTo copies this Mat to another Mat.\nvoid Mat_CopyTo(Mat m, Mat dst) {\n    m->copyTo(*dst);\n}\n\n// Mat_CopyToWithMask copies this Mat to another Mat while applying the mask\nvoid Mat_CopyToWithMask(Mat m, Mat dst, Mat mask) {\n    m->copyTo(*dst, *mask);\n}\n\nvoid Mat_ConvertTo(Mat m, Mat dst, int type) {\n    m->convertTo(*dst, type);\n}\n\nvoid Mat_ConvertToWithParams(Mat m, Mat dst, int type, float alpha, float beta) {\n    m->convertTo(*dst, type, alpha, beta);\n}\n\n// Mat_ToBytes returns the bytes representation of the underlying data.\nstruct ByteArray Mat_ToBytes(Mat m) {\n    return toByteArray(reinterpret_cast<const char*>(m->data), m->total() * m->elemSize());\n}\n\nstruct ByteArray Mat_DataPtr(Mat m) {\n    return ByteArray {reinterpret_cast<char*>(m->data), static_cast<int>(m->total() * m->elemSize())};\n}\n\n// Mat_Region returns a Mat of a region of another Mat\nMat Mat_Region(Mat m, Rect r) {\n    return new cv::Mat(*m, cv::Rect(r.x, r.y, r.width, r.height));\n}\n\nMat Mat_Reshape(Mat m, int cn, int rows) {\n    return new cv::Mat(m->reshape(cn, rows));\n}\n\nvoid Mat_PatchNaNs(Mat m) {\n    cv::patchNaNs(*m);\n}\n\nMat Mat_ConvertFp16(Mat m) {\n    Mat dst = new cv::Mat();\n    cv::convertFp16(*m, *dst);\n    return dst;\n}\n\nMat Mat_Sqrt(Mat m) {\n    Mat dst = new cv::Mat();\n    cv::sqrt(*m, *dst);\n    return dst;\n}\n\n// Mat_Mean calculates the mean value M of array elements, independently for each channel, and return it as Scalar vector\nScalar Mat_Mean(Mat m) {\n    cv::Scalar c = cv::mean(*m);\n    Scalar scal = Scalar();\n    scal.val1 = c.val[0];\n    scal.val2 = c.val[1];\n    scal.val3 = c.val[2];\n    scal.val4 = c.val[3];\n    return scal;\n}\n\n// Mat_MeanWithMask calculates the mean value M of array elements,\n// independently for each channel, and returns it as Scalar vector\n// while applying the mask.\n\nScalar Mat_MeanWithMask(Mat m, Mat mask){\n    cv::Scalar c = cv::mean(*m, *mask);\n    Scalar scal = Scalar();\n    scal.val1 = c.val[0];\n    scal.val2 = c.val[1];\n    scal.val3 = c.val[2];\n    scal.val4 = c.val[3];\n    return scal;\n}\n\nvoid LUT(Mat src, Mat lut, Mat dst) {\n    cv::LUT(*src, *lut, *dst);\n}\n\n// Mat_Rows returns how many rows in this Mat.\nint Mat_Rows(Mat m) {\n    return m->rows;\n}\n\n// Mat_Cols returns how many columns in this Mat.\nint Mat_Cols(Mat m) {\n    return m->cols;\n}\n\n// Mat_Channels returns how many channels in this Mat.\nint Mat_Channels(Mat m) {\n    return m->channels();\n}\n\n// Mat_Type returns the type from this Mat.\nint Mat_Type(Mat m) {\n    return m->type();\n}\n\n// Mat_Step returns the number of bytes each matrix row occupies.\nint Mat_Step(Mat m) {\n    return m->step;\n}\n\nint Mat_Total(Mat m) {\n    return m->total();\n}\n\nint Mat_ElemSize(Mat m){\n    return m->elemSize();\n}\n\nvoid Mat_Size(Mat m, IntVector* res) {\n    cv::MatSize ms(m->size);\n    int* ids = new int[ms.dims()];\n\n    for (size_t i = 0; i < ms.dims(); ++i) {\n        ids[i] = ms[i];\n    }\n\n    res->length = ms.dims();\n    res->val = ids;\n    return;\n}\n\n// Mat_GetUChar returns a specific row/col value from this Mat expecting\n// each element to contain a schar aka CV_8U.\nuint8_t Mat_GetUChar(Mat m, int row, int col) {\n    return m->at<uchar>(row, col);\n}\n\nuint8_t Mat_GetUChar3(Mat m, int x, int y, int z) {\n    return m->at<uchar>(x, y, z);\n}\n\n// Mat_GetSChar returns a specific row/col value from this Mat expecting\n// each element to contain a schar aka CV_8S.\nint8_t Mat_GetSChar(Mat m, int row, int col) {\n    return m->at<schar>(row, col);\n}\n\nint8_t Mat_GetSChar3(Mat m, int x, int y, int z) {\n    return m->at<schar>(x, y, z);\n}\n\n// Mat_GetShort returns a specific row/col value from this Mat expecting\n// each element to contain a short aka CV_16S.\nint16_t Mat_GetShort(Mat m, int row, int col) {\n    return m->at<short>(row, col);\n}\n\nint16_t Mat_GetShort3(Mat m, int x, int y, int z) {\n    return m->at<short>(x, y, z);\n}\n\n// Mat_GetInt returns a specific row/col value from this Mat expecting\n// each element to contain an int aka CV_32S.\nint32_t Mat_GetInt(Mat m, int row, int col) {\n    return m->at<int>(row, col);\n}\n\nint32_t Mat_GetInt3(Mat m, int x, int y, int z) {\n    return m->at<int>(x, y, z);\n}\n\n// Mat_GetFloat returns a specific row/col value from this Mat expecting\n// each element to contain a float aka CV_32F.\nfloat Mat_GetFloat(Mat m, int row, int col) {\n    return m->at<float>(row, col);\n}\n\nfloat Mat_GetFloat3(Mat m, int x, int y, int z) {\n    return m->at<float>(x, y, z);\n}\n\n// Mat_GetDouble returns a specific row/col value from this Mat expecting\n// each element to contain a double aka CV_64F.\ndouble Mat_GetDouble(Mat m, int row, int col) {\n    return m->at<double>(row, col);\n}\n\ndouble Mat_GetDouble3(Mat m, int x, int y, int z) {\n    return m->at<double>(x, y, z);\n}\n\nvoid Mat_SetTo(Mat m, Scalar value) {\n    cv::Scalar c_value(value.val1, value.val2, value.val3, value.val4);\n    m->setTo(c_value);\n}\n\n// Mat_SetUChar set a specific row/col value from this Mat expecting\n// each element to contain a schar aka CV_8U.\nvoid Mat_SetUChar(Mat m, int row, int col, uint8_t val) {\n    m->at<uchar>(row, col) = val;\n}\n\nvoid Mat_SetUChar3(Mat m, int x, int y, int z, uint8_t val) {\n    m->at<uchar>(x, y, z) = val;\n}\n\n// Mat_SetSChar set a specific row/col value from this Mat expecting\n// each element to contain a schar aka CV_8S.\nvoid Mat_SetSChar(Mat m, int row, int col, int8_t val) {\n    m->at<schar>(row, col) = val;\n}\n\nvoid Mat_SetSChar3(Mat m, int x, int y, int z, int8_t val) {\n    m->at<schar>(x, y, z) = val;\n}\n\n// Mat_SetShort set a specific row/col value from this Mat expecting\n// each element to contain a short aka CV_16S.\nvoid Mat_SetShort(Mat m, int row, int col, int16_t val) {\n    m->at<short>(row, col) = val;\n}\n\nvoid Mat_SetShort3(Mat m, int x, int y, int z, int16_t val) {\n    m->at<short>(x, y, z) = val;\n}\n\n// Mat_SetInt set a specific row/col value from this Mat expecting\n// each element to contain an int aka CV_32S.\nvoid Mat_SetInt(Mat m, int row, int col, int32_t val) {\n    m->at<int>(row, col) = val;\n}\n\nvoid Mat_SetInt3(Mat m, int x, int y, int z, int32_t val) {\n    m->at<int>(x, y, z) = val;\n}\n\n// Mat_SetFloat set a specific row/col value from this Mat expecting\n// each element to contain a float aka CV_32F.\nvoid Mat_SetFloat(Mat m, int row, int col, float val) {\n    m->at<float>(row, col) = val;\n}\n\nvoid Mat_SetFloat3(Mat m, int x, int y, int z, float val) {\n    m->at<float>(x, y, z) = val;\n}\n\n// Mat_SetDouble set a specific row/col value from this Mat expecting\n// each element to contain a double aka CV_64F.\nvoid Mat_SetDouble(Mat m, int row, int col, double val) {\n    m->at<double>(row, col) = val;\n}\n\nvoid Mat_SetDouble3(Mat m, int x, int y, int z, double val) {\n    m->at<double>(x, y, z) = val;\n}\n\nvoid Mat_AddUChar(Mat m, uint8_t val) {\n    *m += val;\n}\n\nvoid Mat_SubtractUChar(Mat m, uint8_t val) {\n    *m -= val;\n}\n\nvoid Mat_MultiplyUChar(Mat m, uint8_t val) {\n    *m *= val;\n}\n\nvoid Mat_DivideUChar(Mat m, uint8_t val) {\n    *m /= val;\n}\n\nvoid Mat_AddFloat(Mat m, float val) {\n    *m += val;\n}\n\nvoid Mat_SubtractFloat(Mat m, float val) {\n    *m -= val;\n}\n\nvoid Mat_MultiplyFloat(Mat m, float val) {\n    *m *= val;\n}\n\nvoid Mat_DivideFloat(Mat m, float val) {\n    *m /= val;\n}\n\nMat Mat_MultiplyMatrix(Mat x, Mat y) {\n    return new cv::Mat((*x) * (*y));\n}\n\nMat Mat_T(Mat x) {\n    return new cv::Mat(x->t());\n}\n\nvoid Mat_AbsDiff(Mat src1, Mat src2, Mat dst) {\n    cv::absdiff(*src1, *src2, *dst);\n}\n\nvoid Mat_Add(Mat src1, Mat src2, Mat dst) {\n    cv::add(*src1, *src2, *dst);\n}\n\nvoid Mat_AddWeighted(Mat src1, double alpha, Mat src2, double beta, double gamma, Mat dst) {\n    cv::addWeighted(*src1, alpha, *src2, beta, gamma, *dst);\n}\n\nvoid Mat_BitwiseAnd(Mat src1, Mat src2, Mat dst) {\n    cv::bitwise_and(*src1, *src2, *dst);\n}\n\nvoid Mat_BitwiseAndWithMask(Mat src1, Mat src2, Mat dst, Mat mask){\n    cv::bitwise_and(*src1, *src2, *dst, *mask);\n}\n\nvoid Mat_BitwiseNot(Mat src1, Mat dst) {\n    cv::bitwise_not(*src1, *dst);\n}\n\nvoid Mat_BitwiseNotWithMask(Mat src1, Mat dst, Mat mask) {\n    cv::bitwise_not(*src1, *dst, *mask);\n}\n\nvoid Mat_BitwiseOr(Mat src1, Mat src2, Mat dst) {\n    cv::bitwise_or(*src1, *src2, *dst);\n}\n\nvoid Mat_BitwiseOrWithMask(Mat src1, Mat src2, Mat dst, Mat mask) {\n    cv::bitwise_or(*src1, *src2, *dst, *mask);\n}\n\nvoid Mat_BitwiseXor(Mat src1, Mat src2, Mat dst) {\n    cv::bitwise_xor(*src1, *src2, *dst);\n}\n\nvoid Mat_BitwiseXorWithMask(Mat src1, Mat src2, Mat dst, Mat mask) {\n    cv::bitwise_xor(*src1, *src2, *dst, *mask);\n}\n\nvoid Mat_BatchDistance(Mat src1, Mat src2, Mat dist, int dtype, Mat nidx, int normType, int K,\n                       Mat mask, int update, bool crosscheck) {\n    cv::batchDistance(*src1, *src2, *dist, dtype, *nidx, normType, K, *mask, update, crosscheck);\n}\n\nint Mat_BorderInterpolate(int p, int len, int borderType) {\n    return cv::borderInterpolate(p, len, borderType);\n}\n\nvoid  Mat_CalcCovarMatrix(Mat samples, Mat covar, Mat mean, int flags, int ctype) {\n    cv::calcCovarMatrix(*samples, *covar, *mean, flags, ctype);\n}\n\nvoid  Mat_CartToPolar(Mat x, Mat y, Mat magnitude, Mat angle, bool angleInDegrees) {\n    cv::cartToPolar(*x, *y, *magnitude, *angle, angleInDegrees);\n}\n\nbool Mat_CheckRange(Mat m) {\n    return cv::checkRange(*m);\n}\n\nvoid Mat_Compare(Mat src1, Mat src2, Mat dst, int ct) {\n    cv::compare(*src1, *src2, *dst, ct);\n}\n\nint Mat_CountNonZero(Mat src) {\n    return cv::countNonZero(*src);\n}\n\n\nvoid Mat_CompleteSymm(Mat m, bool lowerToUpper) {\n    cv::completeSymm(*m, lowerToUpper);\n}\n\nvoid Mat_ConvertScaleAbs(Mat src, Mat dst, double alpha, double beta) {\n    cv::convertScaleAbs(*src, *dst, alpha, beta);\n}\n\nvoid Mat_CopyMakeBorder(Mat src, Mat dst, int top, int bottom, int left, int right, int borderType,\n                        Scalar value) {\n    cv::Scalar c_value(value.val1, value.val2, value.val3, value.val4);\n    cv::copyMakeBorder(*src, *dst, top, bottom, left, right, borderType, c_value);\n}\n\nvoid Mat_DCT(Mat src, Mat dst, int flags) {\n    cv::dct(*src, *dst, flags);\n}\n\ndouble Mat_Determinant(Mat m) {\n    return cv::determinant(*m);\n}\n\nvoid Mat_DFT(Mat m, Mat dst, int flags) {\n    cv::dft(*m, *dst, flags);\n}\n\nvoid Mat_Divide(Mat src1, Mat src2, Mat dst) {\n    cv::divide(*src1, *src2, *dst);\n}\n\nbool Mat_Eigen(Mat src, Mat eigenvalues, Mat eigenvectors) {\n    return cv::eigen(*src, *eigenvalues, *eigenvectors);\n}\n\nvoid Mat_EigenNonSymmetric(Mat src, Mat eigenvalues, Mat eigenvectors) {\n    cv::eigenNonSymmetric(*src, *eigenvalues, *eigenvectors);\n}\n\nvoid Mat_PCABackProject(Mat data, Mat mean, Mat eigenvectors, Mat result) {\n    cv::PCABackProject(*data, *mean, *eigenvectors, *result);\n}\n\nvoid Mat_PCACompute(Mat src, Mat mean, Mat eigenvectors, Mat eigenvalues, int maxComponents) {\n    cv::PCACompute(*src, *mean, *eigenvectors, *eigenvalues, maxComponents);\n}\n\nvoid Mat_PCAProject(Mat data, Mat mean, Mat eigenvectors, Mat result) {\n    cv::PCAProject(*data, *mean, *eigenvectors, *result);\n}\n\ndouble PSNR(Mat src1, Mat src2) {\n    return cv::PSNR(*src1, *src2);\n}\n\nvoid SVBackSubst(Mat w, Mat u, Mat vt, Mat rhs, Mat dst) {\n    cv::SVBackSubst(*w, *u, *vt, *rhs, *dst);\n}\n\nvoid SVDecomp(Mat src, Mat w, Mat u, Mat vt) {\n    cv::SVDecomp(*src, *w, *u, *vt);\n}\n\nvoid Mat_Exp(Mat src, Mat dst) {\n    cv::exp(*src, *dst);\n}\n\nvoid Mat_ExtractChannel(Mat src, Mat dst, int coi) {\n    cv::extractChannel(*src, *dst, coi);\n}\n\nvoid Mat_FindNonZero(Mat src, Mat idx) {\n    cv::findNonZero(*src, *idx);\n}\n\nvoid Mat_Flip(Mat src, Mat dst, int flipCode) {\n    cv::flip(*src, *dst, flipCode);\n}\n\nvoid Mat_Gemm(Mat src1, Mat src2, double alpha, Mat src3, double beta, Mat dst, int flags) {\n    cv::gemm(*src1, *src2, alpha, *src3, beta, *dst, flags);\n}\n\nint Mat_GetOptimalDFTSize(int vecsize) {\n    return cv::getOptimalDFTSize(vecsize);\n}\n\nvoid Mat_Hconcat(Mat src1, Mat src2, Mat dst) {\n    cv::hconcat(*src1, *src2, *dst);\n}\n\nvoid Mat_Vconcat(Mat src1, Mat src2, Mat dst) {\n    cv::vconcat(*src1, *src2, *dst);\n}\n\nvoid Rotate(Mat src, Mat dst, int rotateCode) {\n    cv::rotate(*src, *dst, rotateCode);\n}\n\nvoid Mat_Idct(Mat src, Mat dst, int flags) {\n    cv::idct(*src, *dst, flags);\n}\n\nvoid Mat_Idft(Mat src, Mat dst, int flags, int nonzeroRows) {\n    cv::idft(*src, *dst, flags, nonzeroRows);\n}\n\nvoid Mat_InRange(Mat src, Mat lowerb, Mat upperb, Mat dst) {\n    cv::inRange(*src, *lowerb, *upperb, *dst);\n}\n\nvoid Mat_InRangeWithScalar(Mat src, Scalar lowerb, Scalar upperb, Mat dst) {\n    cv::Scalar lb = cv::Scalar(lowerb.val1, lowerb.val2, lowerb.val3, lowerb.val4);\n    cv::Scalar ub = cv::Scalar(upperb.val1, upperb.val2, upperb.val3, upperb.val4);\n    cv::inRange(*src, lb, ub, *dst);\n}\n\nvoid Mat_InsertChannel(Mat src, Mat dst, int coi) {\n    cv::insertChannel(*src, *dst, coi);\n}\n\ndouble Mat_Invert(Mat src, Mat dst, int flags) {\n    double ret = cv::invert(*src, *dst, flags);\n    return ret;\n}\n\ndouble KMeans(Mat data, int k, Mat bestLabels, TermCriteria criteria, int attempts, int flags, Mat centers) {\n    double ret = cv::kmeans(*data, k, *bestLabels, *criteria, attempts, flags, *centers);\n    return ret;\n}\n\ndouble KMeansPoints(PointVector points, int k, Mat bestLabels, TermCriteria criteria, int attempts, int flags, Mat centers) {\n    std::vector<cv::Point2f> pts;\n    copyPointVectorToPoint2fVector(points, &pts);\n    double ret = cv::kmeans(pts, k, *bestLabels, *criteria, attempts, flags, *centers);\n    return ret;\n}\n\nvoid Mat_Log(Mat src, Mat dst) {\n    cv::log(*src, *dst);\n}\n\nvoid Mat_Magnitude(Mat x, Mat y, Mat magnitude) {\n    cv::magnitude(*x, *y, *magnitude);\n}\n\ndouble Mat_Mahalanobis(Mat v1, Mat v2, Mat icovar) {\n    return cv::Mahalanobis(*v1, *v2, *icovar);\n}\n\nvoid MulTransposed(Mat src, Mat dest, bool ata) {\n    cv::mulTransposed(*src, *dest, ata);\n}\n\nvoid Mat_Max(Mat src1, Mat src2, Mat dst) {\n    cv::max(*src1, *src2, *dst);\n}\n\nvoid Mat_MeanStdDev(Mat src, Mat dstMean, Mat dstStdDev) {\n    cv::meanStdDev(*src, *dstMean, *dstStdDev);\n}\n\nvoid Mat_Merge(struct Mats mats, Mat dst) {\n    std::vector<cv::Mat> images;\n\n    for (int i = 0; i < mats.length; ++i) {\n        images.push_back(*mats.mats[i]);\n    }\n\n    cv::merge(images, *dst);\n}\n\nvoid Mat_Min(Mat src1, Mat src2, Mat dst) {\n    cv::min(*src1, *src2, *dst);\n}\n\nvoid Mat_MinMaxIdx(Mat m, double* minVal, double* maxVal, int* minIdx, int* maxIdx) {\n    cv::minMaxIdx(*m, minVal, maxVal, minIdx, maxIdx);\n}\n\nvoid Mat_MinMaxLoc(Mat m, double* minVal, double* maxVal, Point* minLoc, Point* maxLoc) {\n    cv::Point cMinLoc;\n    cv::Point cMaxLoc;\n    cv::minMaxLoc(*m, minVal, maxVal, &cMinLoc, &cMaxLoc);\n\n    minLoc->x = cMinLoc.x;\n    minLoc->y = cMinLoc.y;\n    maxLoc->x = cMaxLoc.x;\n    maxLoc->y = cMaxLoc.y;\n}\n\nvoid Mat_MinMaxLocWithMask(Mat m, double* minVal, double* maxVal, Point* minLoc, Point* maxLoc, Mat mask) {\n    cv::Point cMinLoc;\n    cv::Point cMaxLoc;\n    cv::minMaxLoc(*m, minVal, maxVal, &cMinLoc, &cMaxLoc, *mask);\n\n    minLoc->x = cMinLoc.x;\n    minLoc->y = cMinLoc.y;\n    maxLoc->x = cMaxLoc.x;\n    maxLoc->y = cMaxLoc.y;\n}\n\nvoid Mat_MixChannels(struct Mats src, struct Mats dst, struct IntVector fromTo) {\n    std::vector<cv::Mat> srcMats;\n\n    for (int i = 0; i < src.length; ++i) {\n        srcMats.push_back(*src.mats[i]);\n    }\n\n    std::vector<cv::Mat> dstMats;\n\n    for (int i = 0; i < dst.length; ++i) {\n        dstMats.push_back(*dst.mats[i]);\n    }\n\n    std::vector<int> fromTos;\n\n    for (int i = 0; i < fromTo.length; ++i) {\n        fromTos.push_back(fromTo.val[i]);\n    }\n\n    cv::mixChannels(srcMats, dstMats, fromTos);\n}\n\nvoid Mat_MulSpectrums(Mat a, Mat b, Mat c, int flags) {\n    cv::mulSpectrums(*a, *b, *c, flags);\n}\n\nvoid Mat_Multiply(Mat src1, Mat src2, Mat dst) {\n    cv::multiply(*src1, *src2, *dst);\n}\n\nvoid Mat_MultiplyWithParams(Mat src1, Mat src2, Mat dst, double scale, int dtype) {\n    cv::multiply(*src1, *src2, *dst, scale, dtype);\n}\n\nvoid Mat_Normalize(Mat src, Mat dst, double alpha, double beta, int typ) {\n    cv::normalize(*src, *dst, alpha, beta, typ);\n}\n\ndouble Norm(Mat src1, int normType) {\n    return cv::norm(*src1, normType);\n}\n\ndouble NormWithMats(Mat src1, Mat src2, int normType) {\n    return cv::norm(*src1, *src2, normType);\n}\n\nvoid Mat_PerspectiveTransform(Mat src, Mat dst, Mat tm) {\n    cv::perspectiveTransform(*src, *dst, *tm);\n}\n\nbool Mat_Solve(Mat src1, Mat src2, Mat dst, int flags) {\n    return cv::solve(*src1, *src2, *dst, flags);\n}\n\nint Mat_SolveCubic(Mat coeffs, Mat roots) {\n    return cv::solveCubic(*coeffs, *roots);\n}\n\ndouble Mat_SolvePoly(Mat coeffs, Mat roots, int maxIters) {\n    return cv::solvePoly(*coeffs, *roots, maxIters);\n}\n\nvoid Mat_Reduce(Mat src, Mat dst, int dim, int rType, int dType) {\n    cv::reduce(*src, *dst, dim, rType, dType);\n}\n\nvoid Mat_ReduceArgMax(Mat src, Mat dst, int axis, bool lastIndex) {\n    cv::reduceArgMax(*src, *dst, axis, lastIndex);\n}\n\nvoid Mat_ReduceArgMin(Mat src, Mat dst, int axis, bool lastIndex) {\n    cv::reduceArgMin(*src, *dst, axis, lastIndex);\n}\n\n\nvoid Mat_Repeat(Mat src, int nY, int nX, Mat dst) {\n    cv::repeat(*src, nY, nX, *dst);\n}\n\nvoid Mat_ScaleAdd(Mat src1, double alpha, Mat src2, Mat dst) {\n    cv::scaleAdd(*src1, alpha, *src2, *dst);\n}\n\nvoid Mat_SetIdentity(Mat src, double scalar) {\n    cv::setIdentity(*src, scalar);\n}\n\nvoid Mat_Sort(Mat src, Mat dst, int flags) {\n    cv::sort(*src, *dst, flags);\n}\n\nvoid Mat_SortIdx(Mat src, Mat dst, int flags) {\n    cv::sortIdx(*src, *dst, flags);\n}\n\nvoid Mat_Split(Mat src, struct Mats* mats) {\n    std::vector<cv::Mat> channels;\n    cv::split(*src, channels);\n    mats->mats = new Mat[channels.size()];\n\n    for (size_t i = 0; i < channels.size(); ++i) {\n        mats->mats[i] = new cv::Mat(channels[i]);\n    }\n\n    mats->length = (int)channels.size();\n}\n\nvoid Mat_Subtract(Mat src1, Mat src2, Mat dst) {\n    cv::subtract(*src1, *src2, *dst);\n}\n\nScalar Mat_Trace(Mat src) {\n    cv::Scalar c = cv::trace(*src);\n    Scalar scal = Scalar();\n    scal.val1 = c.val[0];\n    scal.val2 = c.val[1];\n    scal.val3 = c.val[2];\n    scal.val4 = c.val[3];\n    return scal;\n}\n\nvoid Mat_Transform(Mat src, Mat dst, Mat tm) {\n    cv::transform(*src, *dst, *tm);\n}\n\nvoid Mat_Transpose(Mat src, Mat dst) {\n    cv::transpose(*src, *dst);\n}\n\nvoid Mat_TransposeND(Mat src, struct IntVector order, Mat dst) {\n    std::vector<int> _order;\n    for (int i = 0, *v = order.val; i < order.length; ++v, ++i) {\n        _order.push_back(*v);\n    }\n\n    cv::transposeND(*src, _order, *dst);\n}\n\nvoid Mat_PolarToCart(Mat magnitude, Mat degree, Mat x, Mat y, bool angleInDegrees) {\n    cv::polarToCart(*magnitude, *degree, *x, *y, angleInDegrees);\n}\n\nvoid Mat_Pow(Mat src, double power, Mat dst) {\n    cv::pow(*src, power, *dst);\n}\n\nvoid Mat_Phase(Mat x, Mat y, Mat angle, bool angleInDegrees) {\n\tcv::phase(*x, *y, *angle, angleInDegrees);\n}\n\n\nScalar Mat_Sum(Mat src) {\n    cv::Scalar c = cv::sum(*src);\n    Scalar scal = Scalar();\n    scal.val1 = c.val[0];\n    scal.val2 = c.val[1];\n    scal.val3 = c.val[2];\n    scal.val4 = c.val[3];\n    return scal;\n}\n\n// TermCriteria_New creates a new TermCriteria\nTermCriteria TermCriteria_New(int typ, int maxCount, double epsilon) {\n    return new cv::TermCriteria(typ, maxCount, epsilon);\n}\n\nvoid Contours_Close(struct Contours cs) {\n    for (int i = 0; i < cs.length; i++) {\n        Points_Close(cs.contours[i]);\n    }\n\n    delete[] cs.contours;\n}\n\nvoid CStrings_Close(struct CStrings cstrs) {\n    for ( int i = 0; i < cstrs.length; i++ ) {\n        delete [] cstrs.strs[i];\n    }\n    delete [] cstrs.strs;\n}\n\nvoid KeyPoints_Close(struct KeyPoints ks) {\n    delete[] ks.keypoints;\n}\n\nvoid Points_Close(Points ps) {\n    for (size_t i = 0; i < ps.length; i++) {\n        Point_Close(ps.points[i]);\n    }\n\n    delete[] ps.points;\n}\n\nvoid Point_Close(Point p) {}\n\nvoid Points2f_Close(Points2f ps) {\n    for (size_t i = 0; i < ps.length; i++) {\n        Point2f_Close(ps.points[i]);\n    }\n\n    delete[] ps.points;\n}\n\nvoid Point2f_Close(Point2f p) {}\n\nvoid Rects_Close(struct Rects rs) {\n    delete[] rs.rects;\n}\n\nvoid DMatches_Close(struct DMatches ds) {\n    delete[] ds.dmatches;\n}\n\nvoid MultiDMatches_Close(struct MultiDMatches mds) {\n    for (size_t i = 0; i < mds.length; i++) {\n        DMatches_Close(mds.dmatches[i]);\n    }\n\n    delete[] mds.dmatches;\n}\n\nstruct DMatches MultiDMatches_get(struct MultiDMatches mds, int index) {\n    return mds.dmatches[index];\n}\n\n// since it is next to impossible to iterate over mats.mats on the cgo side\nMat Mats_get(struct Mats mats, int i) {\n    return mats.mats[i];\n}\n\nvoid Mats_Close(struct Mats mats) {\n    delete[] mats.mats;\n}\n\nvoid ByteArray_Release(struct ByteArray buf) {\n    delete[] buf.data;\n}\n\nstruct ByteArray toByteArray(const char* buf, int len) {\n    ByteArray ret = {new char[len], len};\n    memcpy(ret.data, buf, len);\n    return ret;\n}\n\nint64 GetCVTickCount() {\n    return cv::getTickCount();\n}\n\ndouble GetTickFrequency() {\n    return cv::getTickFrequency();\n}\n\nMat Mat_rowRange(Mat m,int startrow,int endrow) {\n    return new cv::Mat(m->rowRange(startrow,endrow));\n}\n\nMat Mat_colRange(Mat m,int startrow,int endrow) {\n    return new cv::Mat(m->colRange(startrow,endrow));\n}\n\nPointVector PointVector_New() {\n    return new std::vector< cv::Point >;\n}\n\nPointVector PointVector_NewFromPoints(Contour points) {\n    std::vector<cv::Point>* cntr = new std::vector<cv::Point>;\n\n    for (size_t i = 0; i < points.length; i++) {\n        cntr->push_back(cv::Point(points.points[i].x, points.points[i].y));\n    }\n\n    return cntr;\n}\n\nPointVector PointVector_NewFromMat(Mat mat) {\n    std::vector<cv::Point>* pts = new std::vector<cv::Point>;\n    *pts = (std::vector<cv::Point>) *mat;\n    return pts;\n}\n\nPoint PointVector_At(PointVector pv, int idx) {\n    cv::Point p = pv->at(idx);\n    return Point{.x = p.x, .y = p.y};\n}\n\nvoid PointVector_Append(PointVector pv, Point p) {\n    pv->push_back(cv::Point(p.x, p.y));\n}\n\nint PointVector_Size(PointVector p) {\n    return p->size();\n}\n\nvoid PointVector_Close(PointVector p) {\n    p->clear();\n    delete p;\n}\n\nPointsVector PointsVector_New() {\n    return new std::vector< std::vector< cv::Point > >;\n}\n\nPointsVector PointsVector_NewFromPoints(Contours points) {\n    std::vector< std::vector< cv::Point > >* pv = new std::vector< std::vector< cv::Point > >;\n\n    for (size_t i = 0; i < points.length; i++) {\n        Contour contour = points.contours[i];\n\n        std::vector<cv::Point> cntr;\n\n        for (size_t i = 0; i < contour.length; i++) {\n            cntr.push_back(cv::Point(contour.points[i].x, contour.points[i].y));\n        }\n\n        pv->push_back(cntr);\n    }\n\n    return pv;\n}\n\nint PointsVector_Size(PointsVector ps) {\n    return ps->size();\n}\n\nPointVector PointsVector_At(PointsVector ps, int idx) {\n    std::vector< cv::Point >* p = &(ps->at(idx));\n    return p;\n}\n\nvoid PointsVector_Append(PointsVector psv, PointVector pv) {\n    psv->push_back(*pv);\n}\n\nvoid PointsVector_Close(PointsVector ps) {\n    ps->clear();\n    delete ps;\n}\n\nPoint2fVector Point2fVector_New() {\n    return new std::vector< cv::Point2f >;\n}\n\nPoint2fVector Point2fVector_NewFromPoints(Contour2f points) {\n    std::vector<cv::Point2f>* cntr = new std::vector<cv::Point2f>;\n\n    for (size_t i = 0; i < points.length; i++) {\n        cntr->push_back(cv::Point2f(points.points[i].x, points.points[i].y));\n    }\n\n    return cntr;\n}\n\nPoint2fVector Point2fVector_NewFromMat(Mat mat) {\n    std::vector<cv::Point2f>* pts = new std::vector<cv::Point2f>;\n    *pts = (std::vector<cv::Point2f>) *mat;\n    return pts;\n}\n\nPoint2f Point2fVector_At(Point2fVector pfv, int idx) {\n    cv::Point2f p = pfv->at(idx);\n    return Point2f{.x = p.x, .y = p.y};\n}\n\nint Point2fVector_Size(Point2fVector pfv) {\n    return pfv->size();\n}\n\nvoid Point2fVector_Close(Point2fVector pv) {\n    pv->clear();\n    delete pv;\n}\n\n\nvoid IntVector_Close(struct IntVector ivec) {\n    delete[] ivec.val;\n}\n\nRNG TheRNG() {\n    return &cv::theRNG();\n}\n\nvoid SetRNGSeed(int seed) {\n    cv::setRNGSeed(seed);\n}\n\nvoid RNG_Fill(RNG rng, Mat mat, int distType, double a, double b, bool saturateRange) {\n    rng->fill(*mat, distType, a, b, saturateRange);\n}\n\ndouble RNG_Gaussian(RNG rng, double sigma) {\n    return rng->gaussian(sigma);\n}\n\nunsigned int RNG_Next(RNG rng) {\n    return rng->next();\n}\n\nvoid RandN(Mat mat, Scalar mean, Scalar stddev) {\n    cv::Scalar m = cv::Scalar(mean.val1, mean.val2, mean.val3, mean.val4);\n    cv::Scalar s = cv::Scalar(stddev.val1, stddev.val2, stddev.val3, stddev.val4);\n    cv::randn(*mat, m, s);\n}\n\nvoid RandShuffle(Mat mat) {\n    cv::randShuffle(*mat);\n}\n\nvoid RandShuffleWithParams(Mat mat, double iterFactor, RNG rng) {\n    cv::randShuffle(*mat, iterFactor, rng);\n}\n\nvoid RandU(Mat mat, Scalar low, Scalar high) {\n    cv::Scalar l = cv::Scalar(low.val1, low.val2, low.val3, low.val4);\n    cv::Scalar h = cv::Scalar(high.val1, high.val2, high.val3, high.val4);\n    cv::randn(*mat, l, h);\n}\n\nvoid copyPointVectorToPoint2fVector(PointVector src, Point2fVector dest) {\n    for (size_t i = 0; i < src->size(); i++) {\n        dest->push_back(cv::Point2f(src->at(i).x, src->at(i).y));\n    }\n}\n\nvoid StdByteVectorInitialize(void* data) {\n    new (data) std::vector<uchar>();\n}\n\nvoid StdByteVectorFree(void *data) {\n    reinterpret_cast<std::vector<uchar> *>(data)->~vector<uchar>();\n}\n\nsize_t StdByteVectorLen(void *data) {\n    return reinterpret_cast<std::vector<uchar> *>(data)->size();\n}\n\nuint8_t* StdByteVectorData(void *data) {\n    return reinterpret_cast<std::vector<uchar> *>(data)->data();\n}\n\nPoints2fVector Points2fVector_New(){\n    return new std::vector< std::vector< cv::Point2f > >;\n}\n\nPoints2fVector Points2fVector_NewFromPoints(Contours2f points) {\n    Points2fVector pv = Points2fVector_New();\n    for(size_t i = 0;i<points.length;i++){\n        Contour2f contour2f = points.contours[i];\n        Point2fVector cntr = Point2fVector_NewFromPoints(contour2f);\n        Points2fVector_Append(pv, cntr);\n    }\n\n    return pv;\n}\n\nint Points2fVector_Size(Points2fVector ps) {\n    return ps->size();\n}\n\nPoint2fVector Points2fVector_At(Points2fVector ps, int idx) {\n    return &(ps->at(idx));\n}\n\nvoid Points2fVector_Append(Points2fVector psv, Point2fVector pv) {\n    psv->push_back(*pv);\n}\n\nvoid Points2fVector_Close(Points2fVector ps) {\n    ps->clear();\n    delete ps;\n}\n\nPoint3fVector Point3fVector_New() {\n    return new std::vector< cv::Point3f >;\n}\n\n\nPoint3fVector Point3fVector_NewFromPoints(Contour3f points) {\n    std::vector<cv::Point3f> *cntr = new std::vector<cv::Point3f>;\n    for(size_t i = 0;i< points.length;i++) {\n        cntr->push_back(cv::Point3f(\n            points.points[i].x,\n            points.points[i].y,\n            points.points[i].z\n        ));\n    }\n\n    return cntr;\n}\n\nPoint3fVector Point3fVector_NewFromMat(Mat mat) {\n    std::vector<cv::Point3f> *pts = new std::vector<cv::Point3f>;\n    *pts = (std::vector<cv::Point3f>) *mat;\n    return pts;\n}\n\nPoint3f Point3fVector_At(Point3fVector pfv, int idx) {\n    cv::Point3f p = pfv->at(idx);\n    return Point3f{\n        .x = p.x,\n        .y = p.y,\n        .z = p.z\n    };\n}\n\nvoid Point3fVector_Append(Point3fVector pfv, Point3f point) {\n    pfv->push_back(cv::Point3f(point.x, point.y, point.z));\n}\n\nint Point3fVector_Size(Point3fVector pfv) {\n    return pfv->size();\n}\n\nvoid Point3fVector_Close(Point3fVector pv) {\n    pv->clear();\n    delete pv;\n}\n\nPoints3fVector Points3fVector_New(){\n    return new std::vector< std::vector< cv::Point3f > >;\n}\n\nPoints3fVector Points3fVector_NewFromPoints(Contours3f points) {\n    Points3fVector pv = Points3fVector_New();\n    for(size_t i = 0;i<points.length;i++){\n        Contour3f contour3f = points.contours[i];\n        Point3fVector cntr = Point3fVector_NewFromPoints(contour3f);\n        Points3fVector_Append(pv, cntr);\n    }\n\n    return pv;\n}\n\nint Points3fVector_Size(Points3fVector ps) {\n    return ps->size();\n}\n\nPoint3fVector Points3fVector_At(Points3fVector ps, int idx) {\n    return &(ps->at(idx));\n}\n\nvoid Points3fVector_Append(Points3fVector psv, Point3fVector pv) {\n    psv->push_back(*pv);\n}\n\nvoid Points3fVector_Close(Points3fVector ps) {\n    ps->clear();\n    delete ps;\n}\n\nvoid SetNumThreads(int n) {\n    cv::setNumThreads(n);\n}\n\nint GetNumThreads() {\n    return cv::getNumThreads();\n}\n\nstruct RotatedRect RotatedRect_Create(struct Point2f center, int width, int height, float angle){\n\n    cv::Point2f cvpoint2f = cv::Point2f(center.x, center.y);\n    cv::Size2f cvsize2f = cv::Size2f(width, height);\n\n    cv::RotatedRect cvrect = cv::RotatedRect(cvpoint2f, cvsize2f, angle);\n\n    Point* rpts = new Point[4];\n    cv::Point2f* pts4 = new cv::Point2f[4];\n    cvrect.points(pts4);\n\n    for (size_t j = 0; j < 4; j++) {\n        Point pt = {int(lroundf(pts4[j].x)), int(lroundf(pts4[j].y))};\n        rpts[j] = pt;\n    }\n\n    delete[] pts4;\n\n    cv::Rect bRect = cvrect.boundingRect();\n    Rect r = {bRect.x, bRect.y, bRect.width, bRect.height};\n    Point centrpt = {int(lroundf(cvrect.center.x)), int(lroundf(cvrect.center.y))};\n    Size szsz = {int(lroundf(cvrect.size.width)), int(lroundf(cvrect.size.height))};\n\n    RotatedRect retrect = {(Contour){rpts, 4}, r, centrpt, szsz, cvrect.angle};\n    return retrect;\n}\n\nstruct RotatedRect2f RotatedRect2f_Create(struct Point2f center, float width, float height, float angle){\n\n    cv::Point2f cvpoint2f = cv::Point2f(center.x, center.y);\n    cv::Size2f cvsize2f = cv::Size2f(width, height);\n\n    cv::RotatedRect cvrect = cv::RotatedRect(cvpoint2f, cvsize2f, angle);\n\n    Point2f* rpts = new Point2f[4];\n    cv::Point2f* pts4 = new cv::Point2f[4];\n    cvrect.points(pts4);\n\n    for (size_t j = 0; j < 4; j++) {\n        Point2f pt = {pts4[j].x, pts4[j].y};\n        rpts[j] = pt;\n    }\n\n    delete[] pts4;\n\n    cv::Rect bRect = cvrect.boundingRect();\n    Rect r = {bRect.x, bRect.y, bRect.width, bRect.height};\n    Point2f centrpt = {cvrect.center.x, cvrect.center.y};\n    Size2f szsz = {cvrect.size.width, cvrect.size.height};\n\n    RotatedRect2f retrect = {(Contour2f){rpts, 4}, r, centrpt, szsz, cvrect.angle};\n    return retrect;\n}\n"
        },
        {
          "name": "core.go",
          "type": "blob",
          "size": 93.681640625,
          "content": "package gocv\n\n/*\n#include <stdlib.h>\n#include \"core.h\"\n*/\nimport \"C\"\nimport (\n\t\"errors\"\n\t\"image\"\n\t\"image/color\"\n\t\"reflect\"\n\t\"unsafe\"\n)\n\nconst (\n\t// MatChannels1 is a single channel Mat.\n\tMatChannels1 = 0\n\n\t// MatChannels2 is 2 channel Mat.\n\tMatChannels2 = 8\n\n\t// MatChannels3 is 3 channel Mat.\n\tMatChannels3 = 16\n\n\t// MatChannels4 is 4 channel Mat.\n\tMatChannels4 = 24\n)\n\n// MatType is the type for the various different kinds of Mat you can create.\ntype MatType int\n\nconst (\n\t// MatTypeCV8U is a Mat of 8-bit unsigned int\n\tMatTypeCV8U MatType = 0\n\n\t// MatTypeCV8S is a Mat of 8-bit signed int\n\tMatTypeCV8S MatType = 1\n\n\t// MatTypeCV16U is a Mat of 16-bit unsigned int\n\tMatTypeCV16U MatType = 2\n\n\t// MatTypeCV16S is a Mat of 16-bit signed int\n\tMatTypeCV16S MatType = 3\n\n\t// MatTypeCV16SC2 is a Mat of 16-bit signed int with 2 channels\n\tMatTypeCV16SC2 = MatTypeCV16S + MatChannels2\n\n\t// MatTypeCV32S is a Mat of 32-bit signed int\n\tMatTypeCV32S MatType = 4\n\n\t// MatTypeCV32F is a Mat of 32-bit float\n\tMatTypeCV32F MatType = 5\n\n\t// MatTypeCV64F is a Mat of 64-bit float\n\tMatTypeCV64F MatType = 6\n\n\t// MatTypeCV16F is a Mat of 16-bit (half) float\n\tMatTypeCV16F MatType = 7\n\n\t// MatTypeCV8UC1 is a Mat of 8-bit unsigned int with a single channel\n\tMatTypeCV8UC1 = MatTypeCV8U + MatChannels1\n\n\t// MatTypeCV8UC2 is a Mat of 8-bit unsigned int with 2 channels\n\tMatTypeCV8UC2 = MatTypeCV8U + MatChannels2\n\n\t// MatTypeCV8UC3 is a Mat of 8-bit unsigned int with 3 channels\n\tMatTypeCV8UC3 = MatTypeCV8U + MatChannels3\n\n\t// MatTypeCV8UC4 is a Mat of 8-bit unsigned int with 4 channels\n\tMatTypeCV8UC4 = MatTypeCV8U + MatChannels4\n\n\t// MatTypeCV8SC1 is a Mat of 8-bit signed int with a single channel\n\tMatTypeCV8SC1 = MatTypeCV8S + MatChannels1\n\n\t// MatTypeCV8SC2 is a Mat of 8-bit signed int with 2 channels\n\tMatTypeCV8SC2 = MatTypeCV8S + MatChannels2\n\n\t// MatTypeCV8SC3 is a Mat of 8-bit signed int with 3 channels\n\tMatTypeCV8SC3 = MatTypeCV8S + MatChannels3\n\n\t// MatTypeCV8SC4 is a Mat of 8-bit signed int with 4 channels\n\tMatTypeCV8SC4 = MatTypeCV8S + MatChannels4\n\n\t// MatTypeCV16UC1 is a Mat of 16-bit unsigned int with a single channel\n\tMatTypeCV16UC1 = MatTypeCV16U + MatChannels1\n\n\t// MatTypeCV16UC2 is a Mat of 16-bit unsigned int with 2 channels\n\tMatTypeCV16UC2 = MatTypeCV16U + MatChannels2\n\n\t// MatTypeCV16UC3 is a Mat of 16-bit unsigned int with 3 channels\n\tMatTypeCV16UC3 = MatTypeCV16U + MatChannels3\n\n\t// MatTypeCV16UC4 is a Mat of 16-bit unsigned int with 4 channels\n\tMatTypeCV16UC4 = MatTypeCV16U + MatChannels4\n\n\t// MatTypeCV16SC1 is a Mat of 16-bit signed int with a single channel\n\tMatTypeCV16SC1 = MatTypeCV16S + MatChannels1\n\n\t// MatTypeCV16SC3 is a Mat of 16-bit signed int with 3 channels\n\tMatTypeCV16SC3 = MatTypeCV16S + MatChannels3\n\n\t// MatTypeCV16SC4 is a Mat of 16-bit signed int with 4 channels\n\tMatTypeCV16SC4 = MatTypeCV16S + MatChannels4\n\n\t// MatTypeCV32SC1 is a Mat of 32-bit signed int with a single channel\n\tMatTypeCV32SC1 = MatTypeCV32S + MatChannels1\n\n\t// MatTypeCV32SC2 is a Mat of 32-bit signed int with 2 channels\n\tMatTypeCV32SC2 = MatTypeCV32S + MatChannels2\n\n\t// MatTypeCV32SC3 is a Mat of 32-bit signed int with 3 channels\n\tMatTypeCV32SC3 = MatTypeCV32S + MatChannels3\n\n\t// MatTypeCV32SC4 is a Mat of 32-bit signed int with 4 channels\n\tMatTypeCV32SC4 = MatTypeCV32S + MatChannels4\n\n\t// MatTypeCV32FC1 is a Mat of 32-bit float int with a single channel\n\tMatTypeCV32FC1 = MatTypeCV32F + MatChannels1\n\n\t// MatTypeCV32FC2 is a Mat of 32-bit float int with 2 channels\n\tMatTypeCV32FC2 = MatTypeCV32F + MatChannels2\n\n\t// MatTypeCV32FC3 is a Mat of 32-bit float int with 3 channels\n\tMatTypeCV32FC3 = MatTypeCV32F + MatChannels3\n\n\t// MatTypeCV32FC4 is a Mat of 32-bit float int with 4 channels\n\tMatTypeCV32FC4 = MatTypeCV32F + MatChannels4\n\n\t// MatTypeCV64FC1 is a Mat of 64-bit float int with a single channel\n\tMatTypeCV64FC1 = MatTypeCV64F + MatChannels1\n\n\t// MatTypeCV64FC2 is a Mat of 64-bit float int with 2 channels\n\tMatTypeCV64FC2 = MatTypeCV64F + MatChannels2\n\n\t// MatTypeCV64FC3 is a Mat of 64-bit float int with 3 channels\n\tMatTypeCV64FC3 = MatTypeCV64F + MatChannels3\n\n\t// MatTypeCV64FC4 is a Mat of 64-bit float int with 4 channels\n\tMatTypeCV64FC4 = MatTypeCV64F + MatChannels4\n\n\t// MatTypeCV16FC1 is a Mat of 16-bit float with a single channel\n\tMatTypeCV16FC1 = MatTypeCV16F + MatChannels1\n\n\t// MatTypeCV16FC2 is a Mat of 16-bit float with 2 channels\n\tMatTypeCV16FC2 = MatTypeCV16F + MatChannels2\n\n\t// MatTypeCV16FC3 is a Mat of 16-bit float with 3 channels\n\tMatTypeCV16FC3 = MatTypeCV16F + MatChannels3\n\n\t// MatTypeCV16FC4 is a Mat of 16-bit float with 4 channels\n\tMatTypeCV16FC4 = MatTypeCV16F + MatChannels4\n)\n\n// CompareType is used for Compare operations to indicate which kind of\n// comparison to use.\ntype CompareType int\n\nconst (\n\t// CompareEQ src1 is equal to src2.\n\tCompareEQ CompareType = 0\n\n\t// CompareGT src1 is greater than src2.\n\tCompareGT CompareType = 1\n\n\t// CompareGE src1 is greater than or equal to src2.\n\tCompareGE CompareType = 2\n\n\t// CompareLT src1 is less than src2.\n\tCompareLT CompareType = 3\n\n\t// CompareLE src1 is less than or equal to src2.\n\tCompareLE CompareType = 4\n\n\t// CompareNE src1 is unequal to src2.\n\tCompareNE CompareType = 5\n)\n\ntype Point2f struct {\n\tX float32\n\tY float32\n}\n\nfunc NewPoint2f(x, y float32) Point2f {\n\treturn Point2f{x, y}\n}\n\nvar ErrEmptyByteSlice = errors.New(\"empty byte array\")\n\n// Mat represents an n-dimensional dense numerical single-channel\n// or multi-channel array. It can be used to store real or complex-valued\n// vectors and matrices, grayscale or color images, voxel volumes,\n// vector fields, point clouds, tensors, and histograms.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d3/d63/classcv_1_1Mat.html\ntype Mat struct {\n\tp C.Mat\n\n\t// Non-nil if Mat was created with a []byte (using NewMatFromBytes()). Nil otherwise.\n\td []byte\n}\n\n// NewMat returns a new empty Mat.\nfunc NewMat() Mat {\n\treturn newMat(C.Mat_New())\n}\n\n// NewMatFromCMat returns a new Mat from an unsafe.Pointer(C.Mat).\nfunc NewMatFromCMat(c_mat unsafe.Pointer) Mat {\n\treturn newMat(C.Mat(c_mat))\n}\n\n// NewMatWithSize returns a new Mat with a specific size and type.\nfunc NewMatWithSize(rows int, cols int, mt MatType) Mat {\n\treturn newMat(C.Mat_NewWithSize(C.int(rows), C.int(cols), C.int(mt)))\n}\n\n// NewMatWithSizes returns a new multidimensional Mat with a specific size and type.\nfunc NewMatWithSizes(sizes []int, mt MatType) Mat {\n\tsizesArray := make([]C.int, len(sizes))\n\tfor i, s := range sizes {\n\t\tsizesArray[i] = C.int(s)\n\t}\n\n\tsizesIntVector := C.IntVector{\n\t\tval:    (*C.int)(&sizesArray[0]),\n\t\tlength: C.int(len(sizes)),\n\t}\n\treturn newMat(C.Mat_NewWithSizes(sizesIntVector, C.int(mt)))\n}\n\n// NewMatWithSizesWithScalar returns a new multidimensional Mat with a specific size, type and scalar value.\nfunc NewMatWithSizesWithScalar(sizes []int, mt MatType, s Scalar) Mat {\n\tcsizes := []C.int{}\n\tfor _, v := range sizes {\n\t\tcsizes = append(csizes, C.int(v))\n\t}\n\tsizesVector := C.struct_IntVector{}\n\tsizesVector.val = (*C.int)(&csizes[0])\n\tsizesVector.length = (C.int)(len(csizes))\n\n\tsVal := C.struct_Scalar{\n\t\tval1: C.double(s.Val1),\n\t\tval2: C.double(s.Val2),\n\t\tval3: C.double(s.Val3),\n\t\tval4: C.double(s.Val4),\n\t}\n\n\treturn newMat(C.Mat_NewWithSizesFromScalar(sizesVector, C.int(mt), sVal))\n}\n\n// NewMatWithSizesWithScalar returns a new multidimensional Mat with a specific size, type and preexisting data.\nfunc NewMatWithSizesFromBytes(sizes []int, mt MatType, data []byte) (Mat, error) {\n\tcBytes, err := toByteArray(data)\n\tif err != nil {\n\t\treturn Mat{}, err\n\t}\n\n\tcsizes := []C.int{}\n\tfor _, v := range sizes {\n\t\tcsizes = append(csizes, C.int(v))\n\t}\n\tsizesVector := C.struct_IntVector{}\n\tsizesVector.val = (*C.int)(&csizes[0])\n\tsizesVector.length = (C.int)(len(csizes))\n\n\treturn newMat(C.Mat_NewWithSizesFromBytes(sizesVector, C.int(mt), *cBytes)), nil\n}\n\n// NewMatFromScalar returns a new Mat for a specific Scalar value\nfunc NewMatFromScalar(s Scalar, mt MatType) Mat {\n\tsVal := C.struct_Scalar{\n\t\tval1: C.double(s.Val1),\n\t\tval2: C.double(s.Val2),\n\t\tval3: C.double(s.Val3),\n\t\tval4: C.double(s.Val4),\n\t}\n\n\treturn newMat(C.Mat_NewFromScalar(sVal, C.int(mt)))\n}\n\n// NewMatWithSizeFromScalar returns a new Mat for a specific Scala value with a specific size and type\n// This simplifies creation of specific color filters or creating Mats of specific colors and sizes\nfunc NewMatWithSizeFromScalar(s Scalar, rows int, cols int, mt MatType) Mat {\n\tsVal := C.struct_Scalar{\n\t\tval1: C.double(s.Val1),\n\t\tval2: C.double(s.Val2),\n\t\tval3: C.double(s.Val3),\n\t\tval4: C.double(s.Val4),\n\t}\n\n\treturn newMat(C.Mat_NewWithSizeFromScalar(sVal, C.int(rows), C.int(cols), C.int(mt)))\n}\n\n// NewMatFromBytes returns a new Mat with a specific size and type, initialized from a []byte.\nfunc NewMatFromBytes(rows int, cols int, mt MatType, data []byte) (Mat, error) {\n\tcBytes, err := toByteArray(data)\n\tif err != nil {\n\t\treturn Mat{}, err\n\t}\n\tmat := newMat(C.Mat_NewFromBytes(C.int(rows), C.int(cols), C.int(mt), *cBytes))\n\n\t// Store a reference to the backing data slice. This is needed because we pass the backing\n\t// array directly to C code and without keeping a Go reference to it, it might end up\n\t// garbage collected which would result in crashes.\n\t//\n\t// TODO(bga): This could live in newMat() but I wanted to reduce the change surface.\n\t// TODO(bga): Code that needs access to the array from Go could use this directly.\n\tmat.d = data\n\n\treturn mat, nil\n}\n\n// Returns an identity matrix of the specified size and type.\n//\n// The method returns a Matlab-style identity matrix initializer, similarly to Mat::zeros. Similarly to Mat::ones.\n// For further details, please see:\n// https://docs.opencv.org/master/d3/d63/classcv_1_1Mat.html#a2cf9b9acde7a9852542bbc20ef851ed2\nfunc Eye(rows int, cols int, mt MatType) Mat {\n\treturn newMat(C.Eye(C.int(rows), C.int(cols), C.int(mt)))\n}\n\n// Returns a zero array of the specified size and type.\n//\n// The method returns a Matlab-style zero array initializer.\n// For further details, please see:\n// https://docs.opencv.org/master/d3/d63/classcv_1_1Mat.html#a0b57b6a326c8876d944d188a46e0f556\nfunc Zeros(rows int, cols int, mt MatType) Mat {\n\treturn newMat(C.Zeros(C.int(rows), C.int(cols), C.int(mt)))\n}\n\n// Returns an array of all 1's of the specified size and type.\n//\n// The method returns a Matlab-style 1's array initializer\n// For further details, please see:\n// https://docs.opencv.org/master/d3/d63/classcv_1_1Mat.html#a69ae0402d116fc9c71908d8508dc2f09\nfunc Ones(rows int, cols int, mt MatType) Mat {\n\treturn newMat(C.Ones(C.int(rows), C.int(cols), C.int(mt)))\n}\n\n// FromPtr returns a new Mat with a specific size and type, initialized from a Mat Ptr.\nfunc (m *Mat) FromPtr(rows int, cols int, mt MatType, prow int, pcol int) (Mat, error) {\n\treturn newMat(C.Mat_FromPtr(m.p, C.int(rows), C.int(cols), C.int(mt), C.int(prow), C.int(pcol))), nil\n}\n\n// Ptr returns the Mat's underlying object pointer.\nfunc (m *Mat) Ptr() C.Mat {\n\treturn m.p\n}\n\n// Empty determines if the Mat is empty or not.\nfunc (m *Mat) Empty() bool {\n\tisEmpty := C.Mat_Empty(m.p)\n\treturn isEmpty != 0\n}\n\n// Closed determines if the Mat is closed or not.\nfunc (m *Mat) Closed() bool {\n\treturn m.p == nil\n}\n\n// IsContinuous determines if the Mat is continuous.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/d63/classcv_1_1Mat.html#aa90cea495029c7d1ee0a41361ccecdf3\nfunc (m *Mat) IsContinuous() bool {\n\treturn bool(C.Mat_IsContinuous(m.p))\n}\n\n// Inv inverses a matrix.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d3/d63/classcv_1_1Mat.html#a039eb3c6740a850696a12519a4b8bfc6\nfunc (m *Mat) Inv() {\n\tC.Mat_Inv(m.p)\n}\n\n// Col creates a matrix header for the specified matrix column.\n// The underlying data of the new matrix is shared with the original matrix.\nfunc (m *Mat) Col(col int) Mat {\n\treturn newMat(C.Mat_Col(m.p, C.int(col)))\n}\n\n// Row creates a matrix header for the specified matrix row.\n// The underlying data of the new matrix is shared with the original matrix.\nfunc (m *Mat) Row(row int) Mat {\n\treturn newMat(C.Mat_Row(m.p, C.int(row)))\n}\n\n// Clone returns a cloned full copy of the Mat.\nfunc (m *Mat) Clone() Mat {\n\treturn newMat(C.Mat_Clone(m.p))\n}\n\n// CopyTo copies Mat into destination Mat.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/d63/classcv_1_1Mat.html#a33fd5d125b4c302b0c9aa86980791a77\nfunc (m *Mat) CopyTo(dst *Mat) {\n\tC.Mat_CopyTo(m.p, dst.p)\n\treturn\n}\n\n// CopyToWithMask copies Mat into destination Mat after applying the mask Mat.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/d63/classcv_1_1Mat.html#a626fe5f96d02525e2604d2ad46dd574f\nfunc (m *Mat) CopyToWithMask(dst *Mat, mask Mat) {\n\tC.Mat_CopyToWithMask(m.p, dst.p, mask.p)\n\treturn\n}\n\n// ConvertTo converts Mat into destination Mat.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/d63/classcv_1_1Mat.html#adf88c60c5b4980e05bb556080916978b\nfunc (m *Mat) ConvertTo(dst *Mat, mt MatType) {\n\tC.Mat_ConvertTo(m.p, dst.p, C.int(mt))\n\treturn\n}\n\nfunc (m *Mat) ConvertToWithParams(dst *Mat, mt MatType, alpha, beta float32) {\n\tC.Mat_ConvertToWithParams(m.p, dst.p, C.int(mt), C.float(alpha), C.float(beta))\n\treturn\n}\n\n// Total returns the total number of array elements.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/d63/classcv_1_1Mat.html#aa4d317d43fb0cba9c2503f3c61b866c8\nfunc (m *Mat) Total() int {\n\treturn int(C.Mat_Total(m.p))\n}\n\n// Size returns an array with one element for each dimension containing the size of that dimension for the Mat.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/d63/classcv_1_1Mat.html#aa4d317d43fb0cba9c2503f3c61b866c8\nfunc (m *Mat) Size() (dims []int) {\n\tcdims := C.IntVector{}\n\tC.Mat_Size(m.p, &cdims)\n\tdefer C.IntVector_Close(cdims)\n\n\th := &reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(cdims.val)),\n\t\tLen:  int(cdims.length),\n\t\tCap:  int(cdims.length),\n\t}\n\tpdims := *(*[]C.int)(unsafe.Pointer(h))\n\n\tfor i := 0; i < int(cdims.length); i++ {\n\t\tdims = append(dims, int(pdims[i]))\n\t}\n\treturn\n}\n\n// ToBytes copies the underlying Mat data to a byte array.\n//\n// For further details, please see:\n// https://docs.opencv.org/3.3.1/d3/d63/classcv_1_1Mat.html#a4d33bed1c850265370d2af0ff02e1564\nfunc (m *Mat) ToBytes() []byte {\n\tb := C.Mat_DataPtr(m.p)\n\treturn toGoBytes(b)\n}\n\n// DataPtrUint8 returns a slice that references the OpenCV allocated data.\n//\n// The data is no longer valid once the Mat has been closed. Any data that\n// needs to be accessed after the Mat is closed must be copied into Go memory.\nfunc (m *Mat) DataPtrUint8() ([]uint8, error) {\n\tif !m.IsContinuous() {\n\t\treturn nil, errors.New(\"DataPtrUint8 requires continuous Mat\")\n\t}\n\n\tp := C.Mat_DataPtr(m.p)\n\th := &reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(p.data)),\n\t\tLen:  int(p.length),\n\t\tCap:  int(p.length),\n\t}\n\treturn *(*[]uint8)(unsafe.Pointer(h)), nil\n}\n\n// DataPtrInt8 returns a slice that references the OpenCV allocated data.\n//\n// The data is no longer valid once the Mat has been closed. Any data that\n// needs to be accessed after the Mat is closed must be copied into Go memory.\nfunc (m *Mat) DataPtrInt8() ([]int8, error) {\n\tif m.Type()&MatTypeCV8S != MatTypeCV8S {\n\t\treturn nil, errors.New(\"DataPtrInt8 only supports MatTypeCV8S\")\n\t}\n\n\tif !m.IsContinuous() {\n\t\treturn nil, errors.New(\"DataPtrInt8 requires continuous Mat\")\n\t}\n\n\tp := C.Mat_DataPtr(m.p)\n\th := &reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(p.data)),\n\t\tLen:  int(p.length),\n\t\tCap:  int(p.length),\n\t}\n\treturn *(*[]int8)(unsafe.Pointer(h)), nil\n}\n\n// DataPtrUint16 returns a slice that references the OpenCV allocated data.\n//\n// The data is no longer valid once the Mat has been closed. Any data that\n// needs to be accessed after the Mat is closed must be copied into Go memory.\nfunc (m *Mat) DataPtrUint16() ([]uint16, error) {\n\tif m.Type()&MatTypeCV16U != MatTypeCV16U {\n\t\treturn nil, errors.New(\"DataPtrUint16 only supports MatTypeCV16U\")\n\t}\n\n\tif !m.IsContinuous() {\n\t\treturn nil, errors.New(\"DataPtrUint16 requires continuous Mat\")\n\t}\n\n\tp := C.Mat_DataPtr(m.p)\n\th := &reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(p.data)),\n\t\tLen:  int(p.length) / 2,\n\t\tCap:  int(p.length) / 2,\n\t}\n\treturn *(*[]uint16)(unsafe.Pointer(h)), nil\n}\n\n// DataPtrInt16 returns a slice that references the OpenCV allocated data.\n//\n// The data is no longer valid once the Mat has been closed. Any data that\n// needs to be accessed after the Mat is closed must be copied into Go memory.\nfunc (m *Mat) DataPtrInt16() ([]int16, error) {\n\tif m.Type()&MatTypeCV16S != MatTypeCV16S {\n\t\treturn nil, errors.New(\"DataPtrInt16 only supports MatTypeCV16S\")\n\t}\n\n\tif !m.IsContinuous() {\n\t\treturn nil, errors.New(\"DataPtrInt16 requires continuous Mat\")\n\t}\n\n\tp := C.Mat_DataPtr(m.p)\n\th := &reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(p.data)),\n\t\tLen:  int(p.length) / 2,\n\t\tCap:  int(p.length) / 2,\n\t}\n\treturn *(*[]int16)(unsafe.Pointer(h)), nil\n}\n\n// DataPtrFloat32 returns a slice that references the OpenCV allocated data.\n//\n// The data is no longer valid once the Mat has been closed. Any data that\n// needs to be accessed after the Mat is closed must be copied into Go memory.\nfunc (m *Mat) DataPtrFloat32() ([]float32, error) {\n\tif m.Type()&MatTypeCV32F != MatTypeCV32F {\n\t\treturn nil, errors.New(\"DataPtrFloat32 only supports MatTypeCV32F\")\n\t}\n\n\tif !m.IsContinuous() {\n\t\treturn nil, errors.New(\"DataPtrFloat32 requires continuous Mat\")\n\t}\n\n\tp := C.Mat_DataPtr(m.p)\n\th := &reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(p.data)),\n\t\tLen:  int(p.length) / 4,\n\t\tCap:  int(p.length) / 4,\n\t}\n\treturn *(*[]float32)(unsafe.Pointer(h)), nil\n}\n\n// DataPtrFloat64 returns a slice that references the OpenCV allocated data.\n//\n// The data is no longer valid once the Mat has been closed. Any data that\n// needs to be accessed after the Mat is closed must be copied into Go memory.\nfunc (m *Mat) DataPtrFloat64() ([]float64, error) {\n\tif m.Type()&MatTypeCV64F != MatTypeCV64F {\n\t\treturn nil, errors.New(\"DataPtrFloat64 only supports MatTypeCV64F\")\n\t}\n\n\tif !m.IsContinuous() {\n\t\treturn nil, errors.New(\"DataPtrFloat64 requires continuous Mat\")\n\t}\n\n\tp := C.Mat_DataPtr(m.p)\n\th := &reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(p.data)),\n\t\tLen:  int(p.length) / 8,\n\t\tCap:  int(p.length) / 8,\n\t}\n\treturn *(*[]float64)(unsafe.Pointer(h)), nil\n}\n\n// Region returns a new Mat that points to a region of this Mat. Changes made to the\n// region Mat will affect the original Mat, since they are pointers to the underlying\n// OpenCV Mat object.\nfunc (m *Mat) Region(rio image.Rectangle) Mat {\n\tcRect := C.struct_Rect{\n\t\tx:      C.int(rio.Min.X),\n\t\ty:      C.int(rio.Min.Y),\n\t\twidth:  C.int(rio.Size().X),\n\t\theight: C.int(rio.Size().Y),\n\t}\n\n\treturn newMat(C.Mat_Region(m.p, cRect))\n}\n\n// Reshape changes the shape and/or the number of channels of a 2D matrix without copying the data.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/d63/classcv_1_1Mat.html#a4eb96e3251417fa88b78e2abd6cfd7d8\nfunc (m *Mat) Reshape(cn int, rows int) Mat {\n\treturn newMat(C.Mat_Reshape(m.p, C.int(cn), C.int(rows)))\n}\n\n// ConvertFp16 converts a Mat to half-precision floating point.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga9c25d9ef44a2a48ecc3774b30cb80082\nfunc (m *Mat) ConvertFp16() Mat {\n\treturn newMat(C.Mat_ConvertFp16(m.p))\n}\n\n// Mean calculates the mean value M of array elements, independently for each channel, and return it as Scalar\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga191389f8a0e58180bb13a727782cd461\nfunc (m *Mat) Mean() Scalar {\n\ts := C.Mat_Mean(m.p)\n\treturn NewScalar(float64(s.val1), float64(s.val2), float64(s.val3), float64(s.val4))\n}\n\n// MeanWithMask calculates the mean value M of array elements,independently for each channel,\n// and returns it as Scalar vector while applying the mask.\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga191389f8a0e58180bb13a727782cd461\nfunc (m *Mat) MeanWithMask(mask Mat) Scalar {\n\ts := C.Mat_MeanWithMask(m.p, mask.p)\n\treturn NewScalar(float64(s.val1), float64(s.val2), float64(s.val3), float64(s.val4))\n}\n\n// Sqrt calculates a square root of array elements.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga186222c3919657890f88df5a1f64a7d7\nfunc (m *Mat) Sqrt() Mat {\n\treturn newMat(C.Mat_Sqrt(m.p))\n}\n\n// Sum calculates the per-channel pixel sum of an image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga716e10a2dd9e228e4d3c95818f106722\nfunc (m *Mat) Sum() Scalar {\n\ts := C.Mat_Sum(m.p)\n\treturn NewScalar(float64(s.val1), float64(s.val2), float64(s.val3), float64(s.val4))\n}\n\n// PatchNaNs converts NaN's to zeros.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga62286befb7cde3568ff8c7d14d5079da\nfunc (m *Mat) PatchNaNs() {\n\tC.Mat_PatchNaNs(m.p)\n}\n\n// LUT performs a look-up table transform of an array.\n//\n// The function LUT fills the output array with values from the look-up table.\n// Indices of the entries are taken from the input array.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gab55b8d062b7f5587720ede032d34156f\nfunc LUT(src, wbLUT Mat, dst *Mat) {\n\tC.LUT(src.p, wbLUT.p, dst.p)\n}\n\n// Rows returns the number of rows for this Mat.\nfunc (m *Mat) Rows() int {\n\treturn int(C.Mat_Rows(m.p))\n}\n\n// Cols returns the number of columns for this Mat.\nfunc (m *Mat) Cols() int {\n\treturn int(C.Mat_Cols(m.p))\n}\n\n// Channels returns the number of channels for this Mat.\nfunc (m *Mat) Channels() int {\n\treturn int(C.Mat_Channels(m.p))\n}\n\n// Type returns the type for this Mat.\nfunc (m *Mat) Type() MatType {\n\treturn MatType(C.Mat_Type(m.p))\n}\n\n// Step returns the number of bytes each matrix row occupies.\nfunc (m *Mat) Step() int {\n\treturn int(C.Mat_Step(m.p))\n}\n\n// ElemSize returns the matrix element size in bytes.\nfunc (m *Mat) ElemSize() int {\n\treturn int(C.Mat_ElemSize(m.p))\n}\n\n// GetUCharAt returns a value from a specific row/col\n// in this Mat expecting it to be of type uchar aka CV_8U.\nfunc (m *Mat) GetUCharAt(row int, col int) uint8 {\n\treturn uint8(C.Mat_GetUChar(m.p, C.int(row), C.int(col)))\n}\n\n// GetUCharAt3 returns a value from a specific x, y, z coordinate location\n// in this Mat expecting it to be of type uchar aka CV_8U.\nfunc (m *Mat) GetUCharAt3(x, y, z int) uint8 {\n\treturn uint8(C.Mat_GetUChar3(m.p, C.int(x), C.int(y), C.int(z)))\n}\n\n// GetSCharAt returns a value from a specific row/col\n// in this Mat expecting it to be of type schar aka CV_8S.\nfunc (m *Mat) GetSCharAt(row int, col int) int8 {\n\treturn int8(C.Mat_GetSChar(m.p, C.int(row), C.int(col)))\n}\n\n// GetSCharAt3 returns a value from a specific x, y, z coordinate location\n// in this Mat expecting it to be of type schar aka CV_8S.\nfunc (m *Mat) GetSCharAt3(x, y, z int) int8 {\n\treturn int8(C.Mat_GetSChar3(m.p, C.int(x), C.int(y), C.int(z)))\n}\n\n// GetShortAt returns a value from a specific row/col\n// in this Mat expecting it to be of type short aka CV_16S.\nfunc (m *Mat) GetShortAt(row int, col int) int16 {\n\treturn int16(C.Mat_GetShort(m.p, C.int(row), C.int(col)))\n}\n\n// GetShortAt3 returns a value from a specific x, y, z coordinate location\n// in this Mat expecting it to be of type short aka CV_16S.\nfunc (m *Mat) GetShortAt3(x, y, z int) int16 {\n\treturn int16(C.Mat_GetShort3(m.p, C.int(x), C.int(y), C.int(z)))\n}\n\n// GetIntAt returns a value from a specific row/col\n// in this Mat expecting it to be of type int aka CV_32S.\nfunc (m *Mat) GetIntAt(row int, col int) int32 {\n\treturn int32(C.Mat_GetInt(m.p, C.int(row), C.int(col)))\n}\n\n// GetIntAt3 returns a value from a specific x, y, z coordinate location\n// in this Mat expecting it to be of type int aka CV_32S.\nfunc (m *Mat) GetIntAt3(x, y, z int) int32 {\n\treturn int32(C.Mat_GetInt3(m.p, C.int(x), C.int(y), C.int(z)))\n}\n\n// GetFloatAt returns a value from a specific row/col\n// in this Mat expecting it to be of type float aka CV_32F.\nfunc (m *Mat) GetFloatAt(row int, col int) float32 {\n\treturn float32(C.Mat_GetFloat(m.p, C.int(row), C.int(col)))\n}\n\n// GetFloatAt3 returns a value from a specific x, y, z coordinate location\n// in this Mat expecting it to be of type float aka CV_32F.\nfunc (m *Mat) GetFloatAt3(x, y, z int) float32 {\n\treturn float32(C.Mat_GetFloat3(m.p, C.int(x), C.int(y), C.int(z)))\n}\n\n// GetDoubleAt returns a value from a specific row/col\n// in this Mat expecting it to be of type double aka CV_64F.\nfunc (m *Mat) GetDoubleAt(row int, col int) float64 {\n\treturn float64(C.Mat_GetDouble(m.p, C.int(row), C.int(col)))\n}\n\n// GetDoubleAt3 returns a value from a specific x, y, z coordinate location\n// in this Mat expecting it to be of type double aka CV_64F.\nfunc (m *Mat) GetDoubleAt3(x, y, z int) float64 {\n\treturn float64(C.Mat_GetDouble3(m.p, C.int(x), C.int(y), C.int(z)))\n}\n\n// SetTo sets all or some of the array elements to the specified scalar value.\nfunc (m *Mat) SetTo(s Scalar) {\n\tsVal := C.struct_Scalar{\n\t\tval1: C.double(s.Val1),\n\t\tval2: C.double(s.Val2),\n\t\tval3: C.double(s.Val3),\n\t\tval4: C.double(s.Val4),\n\t}\n\n\tC.Mat_SetTo(m.p, sVal)\n}\n\n// SetUCharAt sets a value at a specific row/col\n// in this Mat expecting it to be of type uchar aka CV_8U.\nfunc (m *Mat) SetUCharAt(row int, col int, val uint8) {\n\tC.Mat_SetUChar(m.p, C.int(row), C.int(col), C.uint8_t(val))\n}\n\n// SetUCharAt3 sets a value at a specific x, y, z coordinate location\n// in this Mat expecting it to be of type uchar aka CV_8U.\nfunc (m *Mat) SetUCharAt3(x, y, z int, val uint8) {\n\tC.Mat_SetUChar3(m.p, C.int(x), C.int(y), C.int(z), C.uint8_t(val))\n}\n\n// SetSCharAt sets a value at a specific row/col\n// in this Mat expecting it to be of type schar aka CV_8S.\nfunc (m *Mat) SetSCharAt(row int, col int, val int8) {\n\tC.Mat_SetSChar(m.p, C.int(row), C.int(col), C.int8_t(val))\n}\n\n// SetSCharAt3 sets a value at a specific x, y, z coordinate location\n// in this Mat expecting it to be of type schar aka CV_8S.\nfunc (m *Mat) SetSCharAt3(x, y, z int, val int8) {\n\tC.Mat_SetSChar3(m.p, C.int(x), C.int(y), C.int(z), C.int8_t(val))\n}\n\n// SetShortAt sets a value at a specific row/col\n// in this Mat expecting it to be of type short aka CV_16S.\nfunc (m *Mat) SetShortAt(row int, col int, val int16) {\n\tC.Mat_SetShort(m.p, C.int(row), C.int(col), C.int16_t(val))\n}\n\n// SetShortAt3 sets a value at a specific x, y, z coordinate location\n// in this Mat expecting it to be of type short aka CV_16S.\nfunc (m *Mat) SetShortAt3(x, y, z int, val int16) {\n\tC.Mat_SetShort3(m.p, C.int(x), C.int(y), C.int(z), C.int16_t(val))\n}\n\n// SetIntAt sets a value at a specific row/col\n// in this Mat expecting it to be of type int aka CV_32S.\nfunc (m *Mat) SetIntAt(row int, col int, val int32) {\n\tC.Mat_SetInt(m.p, C.int(row), C.int(col), C.int32_t(val))\n}\n\n// SetIntAt3 sets a value at a specific x, y, z coordinate location\n// in this Mat expecting it to be of type int aka CV_32S.\nfunc (m *Mat) SetIntAt3(x, y, z int, val int32) {\n\tC.Mat_SetInt3(m.p, C.int(x), C.int(y), C.int(z), C.int32_t(val))\n}\n\n// SetFloatAt sets a value at a specific row/col\n// in this Mat expecting it to be of type float aka CV_32F.\nfunc (m *Mat) SetFloatAt(row int, col int, val float32) {\n\tC.Mat_SetFloat(m.p, C.int(row), C.int(col), C.float(val))\n}\n\n// SetFloatAt3 sets a value at a specific x, y, z coordinate location\n// in this Mat expecting it to be of type float aka CV_32F.\nfunc (m *Mat) SetFloatAt3(x, y, z int, val float32) {\n\tC.Mat_SetFloat3(m.p, C.int(x), C.int(y), C.int(z), C.float(val))\n}\n\n// SetDoubleAt sets a value at a specific row/col\n// in this Mat expecting it to be of type double aka CV_64F.\nfunc (m *Mat) SetDoubleAt(row int, col int, val float64) {\n\tC.Mat_SetDouble(m.p, C.int(row), C.int(col), C.double(val))\n}\n\n// SetDoubleAt3 sets a value at a specific x, y, z coordinate location\n// in this Mat expecting it to be of type double aka CV_64F.\nfunc (m *Mat) SetDoubleAt3(x, y, z int, val float64) {\n\tC.Mat_SetDouble3(m.p, C.int(x), C.int(y), C.int(z), C.double(val))\n}\n\n// AddUChar adds a uchar value to each element in the Mat. Performs a\n// mat += val operation.\nfunc (m *Mat) AddUChar(val uint8) {\n\tC.Mat_AddUChar(m.p, C.uint8_t(val))\n}\n\n// SubtractUChar subtracts a uchar value from each element in the Mat. Performs a\n// mat -= val operation.\nfunc (m *Mat) SubtractUChar(val uint8) {\n\tC.Mat_SubtractUChar(m.p, C.uint8_t(val))\n}\n\n// MultiplyUChar multiplies each element in the Mat by a uint value. Performs a\n// mat *= val operation.\nfunc (m *Mat) MultiplyUChar(val uint8) {\n\tC.Mat_MultiplyUChar(m.p, C.uint8_t(val))\n}\n\n// DivideUChar divides each element in the Mat by a uint value. Performs a\n// mat /= val operation.\nfunc (m *Mat) DivideUChar(val uint8) {\n\tC.Mat_DivideUChar(m.p, C.uint8_t(val))\n}\n\n// AddFloat adds a float value to each element in the Mat. Performs a\n// mat += val operation.\nfunc (m *Mat) AddFloat(val float32) {\n\tC.Mat_AddFloat(m.p, C.float(val))\n}\n\n// SubtractFloat subtracts a float value from each element in the Mat. Performs a\n// mat -= val operation.\nfunc (m *Mat) SubtractFloat(val float32) {\n\tC.Mat_SubtractFloat(m.p, C.float(val))\n}\n\n// MultiplyFloat multiplies each element in the Mat by a float value. Performs a\n// mat *= val operation.\nfunc (m *Mat) MultiplyFloat(val float32) {\n\tC.Mat_MultiplyFloat(m.p, C.float(val))\n}\n\n// DivideFloat divides each element in the Mat by a float value. Performs a\n// mat /= val operation.\nfunc (m *Mat) DivideFloat(val float32) {\n\tC.Mat_DivideFloat(m.p, C.float(val))\n}\n\n// MultiplyMatrix multiplies matrix (m*x)\nfunc (m *Mat) MultiplyMatrix(x Mat) Mat {\n\treturn newMat(C.Mat_MultiplyMatrix(m.p, x.p))\n}\n\n// T  transpose matrix\n// https://docs.opencv.org/4.1.2/d3/d63/classcv_1_1Mat.html#aaa428c60ccb6d8ea5de18f63dfac8e11\nfunc (m *Mat) T() Mat {\n\treturn newMat(C.Mat_T(m.p))\n}\n\n// AbsDiff calculates the per-element absolute difference between two arrays\n// or between an array and a scalar.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga6fef31bc8c4071cbc114a758a2b79c14\nfunc AbsDiff(src1, src2 Mat, dst *Mat) {\n\tC.Mat_AbsDiff(src1.p, src2.p, dst.p)\n}\n\n// Add calculates the per-element sum of two arrays or an array and a scalar.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga10ac1bfb180e2cfda1701d06c24fdbd6\nfunc Add(src1, src2 Mat, dst *Mat) {\n\tC.Mat_Add(src1.p, src2.p, dst.p)\n}\n\n// AddWeighted calculates the weighted sum of two arrays.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gafafb2513349db3bcff51f54ee5592a19\nfunc AddWeighted(src1 Mat, alpha float64, src2 Mat, beta float64, gamma float64, dst *Mat) {\n\tC.Mat_AddWeighted(src1.p, C.double(alpha),\n\t\tsrc2.p, C.double(beta), C.double(gamma), dst.p)\n}\n\n// BitwiseAnd computes bitwise conjunction of the two arrays (dst = src1 & src2).\n// Calculates the per-element bit-wise conjunction of two arrays\n// or an array and a scalar.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga60b4d04b251ba5eb1392c34425497e14\nfunc BitwiseAnd(src1 Mat, src2 Mat, dst *Mat) {\n\tC.Mat_BitwiseAnd(src1.p, src2.p, dst.p)\n}\n\n// BitwiseAndWithMask computes bitwise conjunction of the two arrays (dst = src1 & src2).\n// Calculates the per-element bit-wise conjunction of two arrays\n// or an array and a scalar. It has an additional parameter for a mask.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga60b4d04b251ba5eb1392c34425497e14\nfunc BitwiseAndWithMask(src1 Mat, src2 Mat, dst *Mat, mask Mat) {\n\tC.Mat_BitwiseAndWithMask(src1.p, src2.p, dst.p, mask.p)\n}\n\n// BitwiseNot inverts every bit of an array.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga0002cf8b418479f4cb49a75442baee2f\nfunc BitwiseNot(src1 Mat, dst *Mat) {\n\tC.Mat_BitwiseNot(src1.p, dst.p)\n}\n\n// BitwiseNotWithMask inverts every bit of an array. It has an additional parameter for a mask.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga0002cf8b418479f4cb49a75442baee2f\nfunc BitwiseNotWithMask(src1 Mat, dst *Mat, mask Mat) {\n\tC.Mat_BitwiseNotWithMask(src1.p, dst.p, mask.p)\n}\n\n// BitwiseOr calculates the per-element bit-wise disjunction of two arrays\n// or an array and a scalar.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gab85523db362a4e26ff0c703793a719b4\nfunc BitwiseOr(src1 Mat, src2 Mat, dst *Mat) {\n\tC.Mat_BitwiseOr(src1.p, src2.p, dst.p)\n}\n\n// BitwiseOrWithMask calculates the per-element bit-wise disjunction of two arrays\n// or an array and a scalar. It has an additional parameter for a mask.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gab85523db362a4e26ff0c703793a719b4\nfunc BitwiseOrWithMask(src1 Mat, src2 Mat, dst *Mat, mask Mat) {\n\tC.Mat_BitwiseOrWithMask(src1.p, src2.p, dst.p, mask.p)\n}\n\n// BitwiseXor calculates the per-element bit-wise \"exclusive or\" operation\n// on two arrays or an array and a scalar.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga84b2d8188ce506593dcc3f8cd00e8e2c\nfunc BitwiseXor(src1 Mat, src2 Mat, dst *Mat) {\n\tC.Mat_BitwiseXor(src1.p, src2.p, dst.p)\n}\n\n// BitwiseXorWithMask calculates the per-element bit-wise \"exclusive or\" operation\n// on two arrays or an array and a scalar. It has an additional parameter for a mask.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga84b2d8188ce506593dcc3f8cd00e8e2c\nfunc BitwiseXorWithMask(src1 Mat, src2 Mat, dst *Mat, mask Mat) {\n\tC.Mat_BitwiseXorWithMask(src1.p, src2.p, dst.p, mask.p)\n}\n\n// BatchDistance is a naive nearest neighbor finder.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga4ba778a1c57f83233b1d851c83f5a622\nfunc BatchDistance(src1 Mat, src2 Mat, dist Mat, dtype MatType, nidx Mat, normType NormType, K int, mask Mat, update int, crosscheck bool) {\n\tC.Mat_BatchDistance(src1.p, src2.p, dist.p, C.int(dtype), nidx.p, C.int(normType), C.int(K), mask.p, C.int(update), C.bool(crosscheck))\n}\n\n// BorderInterpolate computes the source location of an extrapolated pixel.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga247f571aa6244827d3d798f13892da58\nfunc BorderInterpolate(p int, len int, borderType CovarFlags) int {\n\tret := C.Mat_BorderInterpolate(C.int(p), C.int(len), C.int(borderType))\n\treturn int(ret)\n}\n\n// CovarFlags are the covariation flags used by functions such as BorderInterpolate.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d0/de1/group__core.html#ga719ebd4a73f30f4fab258ab7616d0f0f\ntype CovarFlags int\n\nconst (\n\t// CovarScrambled indicates to scramble the results.\n\tCovarScrambled CovarFlags = 0\n\n\t// CovarNormal indicates to use normal covariation.\n\tCovarNormal CovarFlags = 1\n\n\t// CovarUseAvg indicates to use average covariation.\n\tCovarUseAvg CovarFlags = 2\n\n\t// CovarScale indicates to use scaled covariation.\n\tCovarScale CovarFlags = 4\n\n\t// CovarRows indicates to use covariation on rows.\n\tCovarRows CovarFlags = 8\n\n\t// CovarCols indicates to use covariation on columns.\n\tCovarCols CovarFlags = 16\n)\n\n// CalcCovarMatrix calculates the covariance matrix of a set of vectors.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga017122d912af19d7d0d2cccc2d63819f\nfunc CalcCovarMatrix(samples Mat, covar *Mat, mean *Mat, flags CovarFlags, ctype MatType) {\n\tC.Mat_CalcCovarMatrix(samples.p, covar.p, mean.p, C.int(flags), C.int(ctype))\n}\n\n// CartToPolar calculates the magnitude and angle of 2D vectors.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gac5f92f48ec32cacf5275969c33ee837d\nfunc CartToPolar(x Mat, y Mat, magnitude *Mat, angle *Mat, angleInDegrees bool) {\n\tC.Mat_CartToPolar(x.p, y.p, magnitude.p, angle.p, C.bool(angleInDegrees))\n}\n\n// CheckRange checks every element of an input array for invalid values.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga2bd19d89cae59361416736f87e3c7a64\nfunc CheckRange(src Mat) bool {\n\treturn bool(C.Mat_CheckRange(src.p))\n}\n\n// Compare performs the per-element comparison of two arrays\n// or an array and scalar value.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga303cfb72acf8cbb36d884650c09a3a97\nfunc Compare(src1 Mat, src2 Mat, dst *Mat, ct CompareType) {\n\tC.Mat_Compare(src1.p, src2.p, dst.p, C.int(ct))\n}\n\n// CountNonZero counts non-zero array elements.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gaa4b89393263bb4d604e0fe5986723914\nfunc CountNonZero(src Mat) int {\n\treturn int(C.Mat_CountNonZero(src.p))\n}\n\n// CompleteSymm copies the lower or the upper half of a square matrix to its another half.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gaa9d88dcd0e54b6d1af38d41f2a3e3d25\nfunc CompleteSymm(m Mat, lowerToUpper bool) {\n\tC.Mat_CompleteSymm(m.p, C.bool(lowerToUpper))\n}\n\n// ConvertScaleAbs scales, calculates absolute values, and converts the result to 8-bit.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga3460e9c9f37b563ab9dd550c4d8c4e7d\nfunc ConvertScaleAbs(src Mat, dst *Mat, alpha float64, beta float64) {\n\tC.Mat_ConvertScaleAbs(src.p, dst.p, C.double(alpha), C.double(beta))\n}\n\n// CopyMakeBorder forms a border around an image (applies padding).\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga2ac1049c2c3dd25c2b41bffe17658a36\nfunc CopyMakeBorder(src Mat, dst *Mat, top int, bottom int, left int, right int, bt BorderType, value color.RGBA) {\n\n\tcValue := C.struct_Scalar{\n\t\tval1: C.double(value.B),\n\t\tval2: C.double(value.G),\n\t\tval3: C.double(value.R),\n\t\tval4: C.double(value.A),\n\t}\n\n\tC.Mat_CopyMakeBorder(src.p, dst.p, C.int(top), C.int(bottom), C.int(left), C.int(right), C.int(bt), cValue)\n}\n\n// DftFlags represents a DFT or DCT flag.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gaf4dde112b483b38175621befedda1f1c\ntype DftFlags int\n\nconst (\n\t// DftForward performs forward 1D or 2D dft or dct.\n\tDftForward DftFlags = 0\n\n\t// DftInverse performs an inverse 1D or 2D transform.\n\tDftInverse DftFlags = 1\n\n\t// DftScale scales the result: divide it by the number of array elements. Normally, it is combined with DFT_INVERSE.\n\tDftScale DftFlags = 2\n\n\t// DftRows performs a forward or inverse transform of every individual row of the input matrix.\n\tDftRows DftFlags = 4\n\n\t// DftComplexOutput performs a forward transformation of 1D or 2D real array; the result, though being a complex array, has complex-conjugate symmetry\n\tDftComplexOutput DftFlags = 16\n\n\t// DftRealOutput performs an inverse transformation of a 1D or 2D complex array; the result is normally a complex array of the same size,\n\t// however, if the input array has conjugate-complex symmetry (for example, it is a result of forward transformation with DFT_COMPLEX_OUTPUT flag),\n\t// the output is a real array.\n\tDftRealOutput DftFlags = 32\n\n\t// DftComplexInput specifies that input is complex input. If this flag is set, the input must have 2 channels.\n\tDftComplexInput DftFlags = 64\n\n\t// DctInverse performs an inverse 1D or 2D dct transform.\n\tDctInverse = DftInverse\n\n\t// DctRows performs a forward or inverse dct transform of every individual row of the input matrix.\n\tDctRows = DftRows\n)\n\n// DCT performs a forward or inverse discrete Cosine transform of 1D or 2D array.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga85aad4d668c01fbd64825f589e3696d4\nfunc DCT(src Mat, dst *Mat, flags DftFlags) {\n\tC.Mat_DCT(src.p, dst.p, C.int(flags))\n}\n\n// Determinant returns the determinant of a square floating-point matrix.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gaf802bd9ca3e07b8b6170645ef0611d0c\nfunc Determinant(src Mat) float64 {\n\treturn float64(C.Mat_Determinant(src.p))\n}\n\n// DFT performs a forward or inverse Discrete Fourier Transform (DFT)\n// of a 1D or 2D floating-point array.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gadd6cf9baf2b8b704a11b5f04aaf4f39d\nfunc DFT(src Mat, dst *Mat, flags DftFlags) {\n\tC.Mat_DFT(src.p, dst.p, C.int(flags))\n}\n\n// Divide performs the per-element division\n// on two arrays or an array and a scalar.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga6db555d30115642fedae0cda05604874\nfunc Divide(src1 Mat, src2 Mat, dst *Mat) {\n\tC.Mat_Divide(src1.p, src2.p, dst.p)\n}\n\n// Eigen calculates eigenvalues and eigenvectors of a symmetric matrix.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga9fa0d58657f60eaa6c71f6fbb40456e3\nfunc Eigen(src Mat, eigenvalues *Mat, eigenvectors *Mat) bool {\n\tret := C.Mat_Eigen(src.p, eigenvalues.p, eigenvectors.p)\n\treturn bool(ret)\n}\n\n// EigenNonSymmetric calculates eigenvalues and eigenvectors of a non-symmetric matrix (real eigenvalues only).\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gaf51987e03cac8d171fbd2b327cf966f6\nfunc EigenNonSymmetric(src Mat, eigenvalues *Mat, eigenvectors *Mat) {\n\tC.Mat_EigenNonSymmetric(src.p, eigenvalues.p, eigenvectors.p)\n}\n\n// PCABackProject reconstructs vectors from their PC projections.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d2/de8/group__core__array.html#gab26049f30ee8e94f7d69d82c124faafc\nfunc PCABackProject(data Mat, mean Mat, eigenvectors Mat, result *Mat) {\n\tC.Mat_PCABackProject(data.p, mean.p, eigenvectors.p, result.p)\n}\n\n// PCACompute performs PCA.\n//\n// The computed eigenvalues are sorted from the largest to the smallest and the corresponding\n// eigenvectors are stored as eigenvectors rows.\n//\n// Note: Calling with maxComponents == 0 (opencv default) will cause all components to be retained.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d2/de8/group__core__array.html#ga27a565b31d820b05dcbcd47112176b6e\nfunc PCACompute(src Mat, mean *Mat, eigenvectors *Mat, eigenvalues *Mat, maxComponents int) {\n\tC.Mat_PCACompute(src.p, mean.p, eigenvectors.p, eigenvalues.p, C.int(maxComponents))\n}\n\n// PCAProject projects vector(s) to the principal component subspace.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d2/de8/group__core__array.html#ga6b9fbc7b3a99ebfd441bbec0a6bc4f88\nfunc PCAProject(data Mat, mean Mat, eigenvectors Mat, result *Mat) {\n\tC.Mat_PCAProject(data.p, mean.p, eigenvectors.p, result.p)\n}\n\n// PSNR computes the Peak Signal-to-Noise Ratio (PSNR) image quality metric.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d2/de8/group__core__array.html#ga3119e3ea73010a6f810bb05aa36ac8d6\nfunc PSNR(src1 Mat, src2 Mat) float64 {\n\treturn float64(C.PSNR(src1.p, src2.p))\n}\n\n// SVBackSubst performs a singular value back substitution.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d2/de8/group__core__array.html#gab4e620e6fc6c8a27bb2be3d50a840c0b\nfunc SVBackSubst(w Mat, u Mat, vt Mat, rhs Mat, dst *Mat) {\n\tC.SVBackSubst(w.p, u.p, vt.p, rhs.p, dst.p)\n}\n\n// SVDecomp decomposes matrix and stores the results to user-provided matrices.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d2/de8/group__core__array.html#gab477b5b7b39b370bb03e75b19d2d5109\nfunc SVDecomp(src Mat, w *Mat, u *Mat, vt *Mat) {\n\tC.SVDecomp(src.p, w.p, u.p, vt.p)\n}\n\n// Exp calculates the exponent of every array element.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga3e10108e2162c338f1b848af619f39e5\nfunc Exp(src Mat, dst *Mat) {\n\tC.Mat_Exp(src.p, dst.p)\n}\n\n// ExtractChannel extracts a single channel from src (coi is 0-based index).\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gacc6158574aa1f0281878c955bcf35642\nfunc ExtractChannel(src Mat, dst *Mat, coi int) {\n\tC.Mat_ExtractChannel(src.p, dst.p, C.int(coi))\n}\n\n// FindNonZero returns the list of locations of non-zero pixels.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gaed7df59a3539b4cc0fe5c9c8d7586190\nfunc FindNonZero(src Mat, idx *Mat) {\n\tC.Mat_FindNonZero(src.p, idx.p)\n}\n\n// Flip flips a 2D array around horizontal(0), vertical(1), or both axes(-1).\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gaca7be533e3dac7feb70fc60635adf441\nfunc Flip(src Mat, dst *Mat, flipCode int) {\n\tC.Mat_Flip(src.p, dst.p, C.int(flipCode))\n}\n\n// Gemm performs generalized matrix multiplication.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gacb6e64071dffe36434e1e7ee79e7cb35\nfunc Gemm(src1, src2 Mat, alpha float64, src3 Mat, beta float64, dst *Mat, flags int) {\n\tC.Mat_Gemm(src1.p, src2.p, C.double(alpha), src3.p, C.double(beta), dst.p, C.int(flags))\n}\n\n// GetOptimalDFTSize returns the optimal Discrete Fourier Transform (DFT) size\n// for a given vector size.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga6577a2e59968936ae02eb2edde5de299\nfunc GetOptimalDFTSize(vecsize int) int {\n\treturn int(C.Mat_GetOptimalDFTSize(C.int(vecsize)))\n}\n\n// Hconcat applies horizontal concatenation to given matrices.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gaab5ceee39e0580f879df645a872c6bf7\nfunc Hconcat(src1, src2 Mat, dst *Mat) {\n\tC.Mat_Hconcat(src1.p, src2.p, dst.p)\n}\n\n// Vconcat applies vertical concatenation to given matrices.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gaab5ceee39e0580f879df645a872c6bf7\nfunc Vconcat(src1, src2 Mat, dst *Mat) {\n\tC.Mat_Vconcat(src1.p, src2.p, dst.p)\n}\n\n// RotateFlag for image rotation\n//\n// For further details please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga6f45d55c0b1cc9d97f5353a7c8a7aac2\ntype RotateFlag int\n\nconst (\n\t// Rotate90Clockwise allows to rotate image 90 degrees clockwise\n\tRotate90Clockwise RotateFlag = 0\n\t// Rotate180Clockwise allows to rotate image 180 degrees clockwise\n\tRotate180Clockwise RotateFlag = 1\n\t// Rotate90CounterClockwise allows to rotate 270 degrees clockwise\n\tRotate90CounterClockwise RotateFlag = 2\n)\n\n// Rotate rotates a 2D array in multiples of 90 degrees\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga4ad01c0978b0ce64baa246811deeac24\nfunc Rotate(src Mat, dst *Mat, code RotateFlag) {\n\tC.Rotate(src.p, dst.p, C.int(code))\n}\n\n// IDCT calculates the inverse Discrete Cosine Transform of a 1D or 2D array.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga77b168d84e564c50228b69730a227ef2\nfunc IDCT(src Mat, dst *Mat, flags int) {\n\tC.Mat_Idct(src.p, dst.p, C.int(flags))\n}\n\n// IDFT calculates the inverse Discrete Fourier Transform of a 1D or 2D array.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gaa708aa2d2e57a508f968eb0f69aa5ff1\nfunc IDFT(src Mat, dst *Mat, flags, nonzeroRows int) {\n\tC.Mat_Idft(src.p, dst.p, C.int(flags), C.int(nonzeroRows))\n}\n\n// InRange checks if array elements lie between the elements of two Mat arrays.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga48af0ab51e36436c5d04340e036ce981\nfunc InRange(src, lb, ub Mat, dst *Mat) {\n\tC.Mat_InRange(src.p, lb.p, ub.p, dst.p)\n}\n\n// InRangeWithScalar checks if array elements lie between the elements of two Scalars\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga48af0ab51e36436c5d04340e036ce981\nfunc InRangeWithScalar(src Mat, lb, ub Scalar, dst *Mat) {\n\tlbVal := C.struct_Scalar{\n\t\tval1: C.double(lb.Val1),\n\t\tval2: C.double(lb.Val2),\n\t\tval3: C.double(lb.Val3),\n\t\tval4: C.double(lb.Val4),\n\t}\n\n\tubVal := C.struct_Scalar{\n\t\tval1: C.double(ub.Val1),\n\t\tval2: C.double(ub.Val2),\n\t\tval3: C.double(ub.Val3),\n\t\tval4: C.double(ub.Val4),\n\t}\n\n\tC.Mat_InRangeWithScalar(src.p, lbVal, ubVal, dst.p)\n}\n\n// InsertChannel inserts a single channel to dst (coi is 0-based index)\n// (it replaces channel i with another in dst).\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga1d4bd886d35b00ec0b764cb4ce6eb515\nfunc InsertChannel(src Mat, dst *Mat, coi int) {\n\tC.Mat_InsertChannel(src.p, dst.p, C.int(coi))\n}\n\n// Invert finds the inverse or pseudo-inverse of a matrix.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gad278044679d4ecf20f7622cc151aaaa2\nfunc Invert(src Mat, dst *Mat, flags SolveDecompositionFlags) float64 {\n\tret := C.Mat_Invert(src.p, dst.p, C.int(flags))\n\treturn float64(ret)\n}\n\n// KMeansFlags for kmeans center selection\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d0/de1/group__core.html#ga276000efe55ee2756e0c471c7b270949\ntype KMeansFlags int\n\nconst (\n\t// KMeansRandomCenters selects random initial centers in each attempt.\n\tKMeansRandomCenters KMeansFlags = 0\n\t// KMeansPPCenters uses kmeans++ center initialization by Arthur and Vassilvitskii [Arthur2007].\n\tKMeansPPCenters KMeansFlags = 1\n\t// KMeansUseInitialLabels uses the user-supplied lables during the first (and possibly the only) attempt\n\t// instead of computing them from the initial centers. For the second and further attempts, use the random or semi-random     // centers. Use one of KMEANS_*_CENTERS flag to specify the exact method.\n\tKMeansUseInitialLabels KMeansFlags = 2\n)\n\n// KMeans finds centers of clusters and groups input samples around the clusters.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d5/d38/group__core__cluster.html#ga9a34dc06c6ec9460e90860f15bcd2f88\nfunc KMeans(data Mat, k int, bestLabels *Mat, criteria TermCriteria, attempts int, flags KMeansFlags, centers *Mat) float64 {\n\tret := C.KMeans(data.p, C.int(k), bestLabels.p, criteria.p, C.int(attempts), C.int(flags), centers.p)\n\treturn float64(ret)\n}\n\n// KMeansPoints finds centers of clusters and groups input samples around the clusters.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d5/d38/group__core__cluster.html#ga9a34dc06c6ec9460e90860f15bcd2f88\nfunc KMeansPoints(points PointVector, k int, bestLabels *Mat, criteria TermCriteria, attempts int, flags KMeansFlags, centers *Mat) float64 {\n\tret := C.KMeansPoints(points.p, C.int(k), bestLabels.p, criteria.p, C.int(attempts), C.int(flags), centers.p)\n\treturn float64(ret)\n}\n\n// Log calculates the natural logarithm of every array element.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga937ecdce4679a77168730830a955bea7\nfunc Log(src Mat, dst *Mat) {\n\tC.Mat_Log(src.p, dst.p)\n}\n\n// Magnitude calculates the magnitude of 2D vectors.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga6d3b097586bca4409873d64a90fe64c3\nfunc Magnitude(x, y Mat, magnitude *Mat) {\n\tC.Mat_Magnitude(x.p, y.p, magnitude.p)\n}\n\n// Mahalanobis calculates the Mahalanobis distance between two vectors.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d2/de8/group__core__array.html#ga4493aee129179459cbfc6064f051aa7d\nfunc Mahalanobis(v1, v2, icovar Mat) float64 {\n\treturn float64(C.Mat_Mahalanobis(v1.p, v2.p, icovar.p))\n}\n\n// MulTransposed calculates the product of a matrix and its transposition.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d2/de8/group__core__array.html#gadc4e49f8f7a155044e3be1b9e3b270ab\nfunc MulTransposed(src Mat, dest *Mat, ata bool) {\n\tC.MulTransposed(src.p, dest.p, C.bool(ata))\n}\n\n// Max calculates per-element maximum of two arrays or an array and a scalar.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gacc40fa15eac0fb83f8ca70b7cc0b588d\nfunc Max(src1, src2 Mat, dst *Mat) {\n\tC.Mat_Max(src1.p, src2.p, dst.p)\n}\n\n// MeanStdDev calculates a mean and standard deviation of array elements.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga846c858f4004d59493d7c6a4354b301d\nfunc MeanStdDev(src Mat, dst *Mat, dstStdDev *Mat) {\n\tC.Mat_MeanStdDev(src.p, dst.p, dstStdDev.p)\n}\n\n// Merge creates one multi-channel array out of several single-channel ones.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga7d7b4d6c6ee504b30a20b1680029c7b4\nfunc Merge(mv []Mat, dst *Mat) {\n\tcMatArray := make([]C.Mat, len(mv))\n\tfor i, r := range mv {\n\t\tcMatArray[i] = r.p\n\t}\n\tcMats := C.struct_Mats{\n\t\tmats:   (*C.Mat)(&cMatArray[0]),\n\t\tlength: C.int(len(mv)),\n\t}\n\n\tC.Mat_Merge(cMats, dst.p)\n}\n\n// Min calculates per-element minimum of two arrays or an array and a scalar.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga9af368f182ee76d0463d0d8d5330b764\nfunc Min(src1, src2 Mat, dst *Mat) {\n\tC.Mat_Min(src1.p, src2.p, dst.p)\n}\n\n// MinMaxIdx finds the global minimum and maximum in an array.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga7622c466c628a75d9ed008b42250a73f\nfunc MinMaxIdx(input Mat) (minVal, maxVal float32, minIdx, maxIdx int) {\n\tvar cMinVal C.double\n\tvar cMaxVal C.double\n\tvar cMinIdx C.int\n\tvar cMaxIdx C.int\n\n\tC.Mat_MinMaxIdx(input.p, &cMinVal, &cMaxVal, &cMinIdx, &cMaxIdx)\n\n\treturn float32(cMinVal), float32(cMaxVal), int(minIdx), int(maxIdx)\n}\n\n// MinMaxLoc finds the global minimum and maximum in an array.\n//\n// For further details, please see:\n// https://docs.opencv.org/trunk/d2/de8/group__core__array.html#gab473bf2eb6d14ff97e89b355dac20707\nfunc MinMaxLoc(input Mat) (minVal, maxVal float32, minLoc, maxLoc image.Point) {\n\tvar cMinVal C.double\n\tvar cMaxVal C.double\n\tvar cMinLoc C.struct_Point\n\tvar cMaxLoc C.struct_Point\n\n\tC.Mat_MinMaxLoc(input.p, &cMinVal, &cMaxVal, &cMinLoc, &cMaxLoc)\n\n\tminLoc = image.Pt(int(cMinLoc.x), int(cMinLoc.y))\n\tmaxLoc = image.Pt(int(cMaxLoc.x), int(cMaxLoc.y))\n\n\treturn float32(cMinVal), float32(cMaxVal), minLoc, maxLoc\n}\n\n// MinMaxLocWithMask finds the global minimum and maximum in an array with a mask used to select a sub-array.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d2/de8/group__core__array.html#gab473bf2eb6d14ff97e89b355dac20707\nfunc MinMaxLocWithMask(input, mask Mat) (minVal, maxVal float32, minLoc, maxLoc image.Point) {\n\tvar cMinVal C.double\n\tvar cMaxVal C.double\n\tvar cMinLoc C.struct_Point\n\tvar cMaxLoc C.struct_Point\n\n\tC.Mat_MinMaxLocWithMask(input.p, &cMinVal, &cMaxVal, &cMinLoc, &cMaxLoc, mask.p)\n\n\tminLoc = image.Pt(int(cMinLoc.x), int(cMinLoc.y))\n\tmaxLoc = image.Pt(int(cMaxLoc.x), int(cMaxLoc.y))\n\n\treturn float32(cMinVal), float32(cMaxVal), minLoc, maxLoc\n}\n\n// Copies specified channels from input arrays to the specified channels of output arrays.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga51d768c270a1cdd3497255017c4504be\nfunc MixChannels(src []Mat, dst []Mat, fromTo []int) {\n\tcSrcArray := make([]C.Mat, len(src))\n\tfor i, r := range src {\n\t\tcSrcArray[i] = r.p\n\t}\n\tcSrcMats := C.struct_Mats{\n\t\tmats:   (*C.Mat)(&cSrcArray[0]),\n\t\tlength: C.int(len(src)),\n\t}\n\n\tcDstArray := make([]C.Mat, len(dst))\n\tfor i, r := range dst {\n\t\tcDstArray[i] = r.p\n\t}\n\tcDstMats := C.struct_Mats{\n\t\tmats:   (*C.Mat)(&cDstArray[0]),\n\t\tlength: C.int(len(dst)),\n\t}\n\n\tcFromToArray := make([]C.int, len(fromTo))\n\tfor i, ft := range fromTo {\n\t\tcFromToArray[i] = C.int(ft)\n\t}\n\n\tcFromToIntVector := C.IntVector{\n\t\tval:    (*C.int)(&cFromToArray[0]),\n\t\tlength: C.int(len(fromTo)),\n\t}\n\n\tC.Mat_MixChannels(cSrcMats, cDstMats, cFromToIntVector)\n\n\tfor i := C.int(0); i < cDstMats.length; i++ {\n\t\tdst[i].p = C.Mats_get(cDstMats, i)\n\t}\n}\n\n// Mulspectrums performs the per-element multiplication of two Fourier spectrums.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga3ab38646463c59bf0ce962a9d51db64f\nfunc MulSpectrums(a Mat, b Mat, dst *Mat, flags DftFlags) {\n\tC.Mat_MulSpectrums(a.p, b.p, dst.p, C.int(flags))\n}\n\n// Multiply calculates the per-element scaled product of two arrays.\n// Both input arrays must be of the same size and the same type.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f\nfunc Multiply(src1 Mat, src2 Mat, dst *Mat) {\n\tC.Mat_Multiply(src1.p, src2.p, dst.p)\n}\n\n// MultiplyWithParams calculates the per-element scaled product of two arrays.\n// Both input arrays must be of the same size and the same type.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f\nfunc MultiplyWithParams(src1 Mat, src2 Mat, dst *Mat, scale float64, dtype MatType) {\n\tC.Mat_MultiplyWithParams(src1.p, src2.p, dst.p, C.double(scale), C.int(dtype))\n}\n\n// NormType for normalization operations.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gad12cefbcb5291cf958a85b4b67b6149f\ntype NormType int\n\nconst (\n\t// NormInf indicates use infinite normalization.\n\tNormInf NormType = 1\n\n\t// NormL1 indicates use L1 normalization.\n\tNormL1 NormType = 2\n\n\t// NormL2 indicates use L2 normalization.\n\tNormL2 NormType = 4\n\n\t// NormL2Sqr indicates use L2 squared normalization.\n\tNormL2Sqr NormType = 5\n\n\t// NormHamming indicates use Hamming normalization.\n\tNormHamming NormType = 6\n\n\t// NormHamming2 indicates use Hamming 2-bit normalization.\n\tNormHamming2 NormType = 7\n\n\t// NormTypeMask indicates use type mask for normalization.\n\tNormTypeMask NormType = 7\n\n\t// NormRelative indicates use relative normalization.\n\tNormRelative NormType = 8\n\n\t// NormMinMax indicates use min/max normalization.\n\tNormMinMax NormType = 32\n)\n\n// Normalize normalizes the norm or value range of an array.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga87eef7ee3970f86906d69a92cbf064bd\nfunc Normalize(src Mat, dst *Mat, alpha float64, beta float64, typ NormType) {\n\tC.Mat_Normalize(src.p, dst.p, C.double(alpha), C.double(beta), C.int(typ))\n}\n\n// Norm calculates the absolute norm of an array.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga7c331fb8dd951707e184ef4e3f21dd33\nfunc Norm(src1 Mat, normType NormType) float64 {\n\treturn float64(C.Norm(src1.p, C.int(normType)))\n}\n\n// Norm calculates the absolute difference/relative norm of two arrays.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga7c331fb8dd951707e184ef4e3f21dd33\nfunc NormWithMats(src1 Mat, src2 Mat, normType NormType) float64 {\n\treturn float64(C.NormWithMats(src1.p, src2.p, C.int(normType)))\n}\n\n// PerspectiveTransform performs the perspective matrix transformation of vectors.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gad327659ac03e5fd6894b90025e6900a7\nfunc PerspectiveTransform(src Mat, dst *Mat, tm Mat) {\n\tC.Mat_PerspectiveTransform(src.p, dst.p, tm.p)\n}\n\n// TermCriteriaType for TermCriteria.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d9/d5d/classcv_1_1TermCriteria.html#a56fecdc291ccaba8aad27d67ccf72c57\ntype TermCriteriaType int\n\nconst (\n\t// Count is the maximum number of iterations or elements to compute.\n\tCount TermCriteriaType = 1\n\n\t// MaxIter is the maximum number of iterations or elements to compute.\n\tMaxIter TermCriteriaType = 1\n\n\t// EPS is the desired accuracy or change in parameters at which the\n\t// iterative algorithm stops.\n\tEPS TermCriteriaType = 2\n)\n\ntype SolveDecompositionFlags int\n\nconst (\n\t// Gaussian elimination with the optimal pivot element chosen.\n\tSolveDecompositionLu SolveDecompositionFlags = 0\n\n\t// Singular value decomposition (SVD) method. The system can be over-defined and/or the matrix src1 can be singular.\n\tSolveDecompositionSvd SolveDecompositionFlags = 1\n\n\t// Eigenvalue decomposition. The matrix src1 must be symmetrical.\n\tSolveDecompositionEing SolveDecompositionFlags = 2\n\n\t// Cholesky LL^T factorization. The matrix src1 must be symmetrical and positively defined.\n\tSolveDecompositionCholesky SolveDecompositionFlags = 3\n\n\t// QR factorization. The system can be over-defined and/or the matrix src1 can be singular.\n\tSolveDecompositionQr SolveDecompositionFlags = 4\n\n\t// While all the previous flags are mutually exclusive, this flag can be used together with any of the previous.\n\t// It means that the normal equations 𝚜𝚛𝚌𝟷^T⋅𝚜𝚛𝚌𝟷⋅𝚍𝚜𝚝=𝚜𝚛𝚌𝟷^T𝚜𝚛𝚌𝟸 are solved instead of the original system\n\t// 𝚜𝚛𝚌𝟷⋅𝚍𝚜𝚝=𝚜𝚛𝚌𝟸.\n\tSolveDecompositionNormal SolveDecompositionFlags = 5\n)\n\n// Solve solves one or more linear systems or least-squares problems.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga12b43690dbd31fed96f213eefead2373\nfunc Solve(src1 Mat, src2 Mat, dst *Mat, flags SolveDecompositionFlags) bool {\n\treturn bool(C.Mat_Solve(src1.p, src2.p, dst.p, C.int(flags)))\n}\n\n// SolveCubic finds the real roots of a cubic equation.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga1c3b0b925b085b6e96931ee309e6a1da\nfunc SolveCubic(coeffs Mat, roots *Mat) int {\n\treturn int(C.Mat_SolveCubic(coeffs.p, roots.p))\n}\n\n// SolvePoly finds the real or complex roots of a polynomial equation.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gac2f5e953016fabcdf793d762f4ec5dce\nfunc SolvePoly(coeffs Mat, roots *Mat, maxIters int) float64 {\n\treturn float64(C.Mat_SolvePoly(coeffs.p, roots.p, C.int(maxIters)))\n}\n\ntype ReduceTypes int\n\nconst (\n\t// The output is the sum of all rows/columns of the matrix.\n\tReduceSum ReduceTypes = 0\n\n\t// The output is the mean vector of all rows/columns of the matrix.\n\tReduceAvg ReduceTypes = 1\n\n\t// The output is the maximum (column/row-wise) of all rows/columns of the matrix.\n\tReduceMax ReduceTypes = 2\n\n\t// The output is the minimum (column/row-wise) of all rows/columns of the matrix.\n\tReduceMin ReduceTypes = 3\n)\n\n// Reduce reduces a matrix to a vector.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga4b78072a303f29d9031d56e5638da78e\nfunc Reduce(src Mat, dst *Mat, dim int, rType ReduceTypes, dType MatType) {\n\tC.Mat_Reduce(src.p, dst.p, C.int(dim), C.int(rType), C.int(dType))\n}\n\n// Finds indices of max elements along provided axis.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gaa87ea34d99bcc5bf9695048355163da0\nfunc ReduceArgMax(src Mat, dst *Mat, axis int, lastIndex bool) {\n\tC.Mat_ReduceArgMax(src.p, dst.p, C.int(axis), C.bool(lastIndex))\n}\n\n// Finds indices of min elements along provided axis.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gaeecd548276bfb91b938989e66b722088\nfunc ReduceArgMin(src Mat, dst *Mat, axis int, lastIndex bool) {\n\tC.Mat_ReduceArgMin(src.p, dst.p, C.int(axis), C.bool(lastIndex))\n}\n\n// Repeat fills the output array with repeated copies of the input array.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga496c3860f3ac44c40b48811333cfda2d\nfunc Repeat(src Mat, nY int, nX int, dst *Mat) {\n\tC.Mat_Repeat(src.p, C.int(nY), C.int(nX), dst.p)\n}\n\n// Calculates the sum of a scaled array and another array.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga9e0845db4135f55dcf20227402f00d98\nfunc ScaleAdd(src1 Mat, alpha float64, src2 Mat, dst *Mat) {\n\tC.Mat_ScaleAdd(src1.p, C.double(alpha), src2.p, dst.p)\n}\n\n// SetIdentity initializes a scaled identity matrix.\n// For further details, please see:\n//\n//\thttps://docs.opencv.org/master/d2/de8/group__core__array.html#ga388d7575224a4a277ceb98ccaa327c99\nfunc SetIdentity(src Mat, scalar float64) {\n\tC.Mat_SetIdentity(src.p, C.double(scalar))\n}\n\ntype SortFlags int\n\nconst (\n\t// Each matrix row is sorted independently\n\tSortEveryRow SortFlags = 0\n\n\t// Each matrix column is sorted independently; this flag and the previous one are mutually exclusive.\n\tSortEveryColumn SortFlags = 1\n\n\t// Each matrix row is sorted in the ascending order.\n\tSortAscending SortFlags = 0\n\n\t// Each matrix row is sorted in the descending order; this flag and the previous one are also mutually exclusive.\n\tSortDescending SortFlags = 16\n)\n\n// Sort sorts each row or each column of a matrix.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga45dd56da289494ce874be2324856898f\nfunc Sort(src Mat, dst *Mat, flags SortFlags) {\n\tC.Mat_Sort(src.p, dst.p, C.int(flags))\n}\n\n// SortIdx sorts each row or each column of a matrix.\n// Instead of reordering the elements themselves, it stores the indices of sorted elements in the output array\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gadf35157cbf97f3cb85a545380e383506\nfunc SortIdx(src Mat, dst *Mat, flags SortFlags) {\n\tC.Mat_SortIdx(src.p, dst.p, C.int(flags))\n}\n\n// Split creates an array of single channel images from a multi-channel image\n// Created images should be closed manualy to avoid memory leaks.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga0547c7fed86152d7e9d0096029c8518a\nfunc Split(src Mat) (mv []Mat) {\n\tcMats := C.struct_Mats{}\n\tC.Mat_Split(src.p, &(cMats))\n\tdefer C.Mats_Close(cMats)\n\tmv = make([]Mat, cMats.length)\n\tfor i := C.int(0); i < cMats.length; i++ {\n\t\tmv[i].p = C.Mats_get(cMats, i)\n\t\taddMatToProfile(mv[i].p)\n\t}\n\treturn\n}\n\n// Subtract calculates the per-element subtraction of two arrays or an array and a scalar.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gaa0f00d98b4b5edeaeb7b8333b2de353b\nfunc Subtract(src1 Mat, src2 Mat, dst *Mat) {\n\tC.Mat_Subtract(src1.p, src2.p, dst.p)\n}\n\n// Trace returns the trace of a matrix.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga3419ac19c7dcd2be4bd552a23e147dd8\nfunc Trace(src Mat) Scalar {\n\ts := C.Mat_Trace(src.p)\n\treturn NewScalar(float64(s.val1), float64(s.val2), float64(s.val3), float64(s.val4))\n}\n\n// Transform performs the matrix transformation of every array element.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga393164aa54bb9169ce0a8cc44e08ff22\nfunc Transform(src Mat, dst *Mat, tm Mat) {\n\tC.Mat_Transform(src.p, dst.p, tm.p)\n}\n\n// Transpose transposes a matrix.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga46630ed6c0ea6254a35f447289bd7404\nfunc Transpose(src Mat, dst *Mat) {\n\tC.Mat_Transpose(src.p, dst.p)\n}\n\n// TransposeND transpose for n-dimensional matrices.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gab1b1274b4a563be34cdfa55b8919a4ec\nfunc TransposeND(src Mat, order []int, dst *Mat) {\n\tcOrderArray := make([]C.int, len(order))\n\tfor i, o := range order {\n\t\tcOrderArray[i] = C.int(o)\n\t}\n\n\tcOrderVector := C.IntVector{\n\t\tval:    (*C.int)(&cOrderArray[0]),\n\t\tlength: C.int(len(order)),\n\t}\n\n\tC.Mat_TransposeND(src.p, cOrderVector, dst.p)\n}\n\n// Pow raises every array element to a power.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gaf0d056b5bd1dc92500d6f6cf6bac41ef\nfunc Pow(src Mat, power float64, dst *Mat) {\n\tC.Mat_Pow(src.p, C.double(power), dst.p)\n}\n\n// PolatToCart calculates x and y coordinates of 2D vectors from their magnitude and angle.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga581ff9d44201de2dd1b40a50db93d665\nfunc PolarToCart(magnitude Mat, degree Mat, x *Mat, y *Mat, angleInDegrees bool) {\n\tC.Mat_PolarToCart(magnitude.p, degree.p, x.p, y.p, C.bool(angleInDegrees))\n}\n\n// Phase calculates the rotation angle of 2D vectors.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga9db9ca9b4d81c3bde5677b8f64dc0137\nfunc Phase(x, y Mat, angle *Mat, angleInDegrees bool) {\n\tC.Mat_Phase(x.p, y.p, angle.p, C.bool(angleInDegrees))\n}\n\n// TermCriteria is the criteria for iterative algorithms.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d9/d5d/classcv_1_1TermCriteria.html\ntype TermCriteria struct {\n\tp C.TermCriteria\n}\n\n// NewTermCriteria returns a new TermCriteria.\nfunc NewTermCriteria(typ TermCriteriaType, maxCount int, epsilon float64) TermCriteria {\n\treturn TermCriteria{p: C.TermCriteria_New(C.int(typ), C.int(maxCount), C.double(epsilon))}\n}\n\n// Ptr returns the underlying C.TermCriteria\nfunc (tc *TermCriteria) Ptr() C.TermCriteria {\n\treturn tc.p\n}\n\n// Scalar is a 4-element vector widely used in OpenCV to pass pixel values.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d1/da0/classcv_1_1Scalar__.html\ntype Scalar struct {\n\tVal1 float64\n\tVal2 float64\n\tVal3 float64\n\tVal4 float64\n}\n\n// NewScalar returns a new Scalar. These are usually colors typically being in BGR order.\nfunc NewScalar(v1 float64, v2 float64, v3 float64, v4 float64) Scalar {\n\ts := Scalar{Val1: v1, Val2: v2, Val3: v3, Val4: v4}\n\treturn s\n}\n\n// KeyPoint is data structure for salient point detectors.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/d29/classcv_1_1KeyPoint.html\ntype KeyPoint struct {\n\tX, Y                  float64\n\tSize, Angle, Response float64\n\tOctave, ClassID       int\n}\n\n// DMatch is data structure for matching keypoint descriptors.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/de0/classcv_1_1DMatch.html#a546ddb9a87898f06e510e015a6de596e\ntype DMatch struct {\n\tQueryIdx int\n\tTrainIdx int\n\tImgIdx   int\n\tDistance float64\n}\n\n// Vecb is a generic vector of bytes.\ntype Vecb []uint8\n\n// GetVecbAt returns a vector of bytes. Its size corresponds to the number\n// of channels of the Mat.\nfunc (m *Mat) GetVecbAt(row int, col int) Vecb {\n\tch := m.Channels()\n\tv := make(Vecb, ch)\n\n\tfor c := 0; c < ch; c++ {\n\t\tv[c] = m.GetUCharAt(row, col*ch+c)\n\t}\n\n\treturn v\n}\n\n// Vecf is a generic vector of floats.\ntype Vecf []float32\n\n// GetVecfAt returns a vector of floats. Its size corresponds to the number of\n// channels of the Mat.\nfunc (m *Mat) GetVecfAt(row int, col int) Vecf {\n\tch := m.Channels()\n\tv := make(Vecf, ch)\n\n\tfor c := 0; c < ch; c++ {\n\t\tv[c] = m.GetFloatAt(row, col*ch+c)\n\t}\n\n\treturn v\n}\n\n// Vecd is a generic vector of float64/doubles.\ntype Vecd []float64\n\n// GetVecdAt returns a vector of float64s. Its size corresponds to the number\n// of channels of the Mat.\nfunc (m *Mat) GetVecdAt(row int, col int) Vecd {\n\tch := m.Channels()\n\tv := make(Vecd, ch)\n\n\tfor c := 0; c < ch; c++ {\n\t\tv[c] = m.GetDoubleAt(row, col*ch+c)\n\t}\n\n\treturn v\n}\n\n// Veci is a generic vector of integers.\ntype Veci []int32\n\n// GetVeciAt returns a vector of integers. Its size corresponds to the number\n// of channels of the Mat.\nfunc (m *Mat) GetVeciAt(row int, col int) Veci {\n\tch := m.Channels()\n\tv := make(Veci, ch)\n\n\tfor c := 0; c < ch; c++ {\n\t\tv[c] = m.GetIntAt(row, col*ch+c)\n\t}\n\n\treturn v\n}\n\n// PointVector is a wrapper around a std::vector< cv::Point >*\n// This is needed anytime that you need to pass or receive a collection of points.\ntype PointVector struct {\n\tp C.PointVector\n}\n\n// NewPointVector returns a new empty PointVector.\nfunc NewPointVector() PointVector {\n\treturn PointVector{p: C.PointVector_New()}\n}\n\n// NewPointVectorFromPoints returns a new PointVector that has been\n// initialized to a slice of image.Point.\nfunc NewPointVectorFromPoints(pts []image.Point) PointVector {\n\tp := (*C.struct_Point)(C.malloc(C.size_t(C.sizeof_struct_Point * len(pts))))\n\tdefer C.free(unsafe.Pointer(p))\n\n\th := &reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(p)),\n\t\tLen:  len(pts),\n\t\tCap:  len(pts),\n\t}\n\tpa := *(*[]C.Point)(unsafe.Pointer(h))\n\n\tfor j, point := range pts {\n\t\tpa[j] = C.struct_Point{\n\t\t\tx: C.int(point.X),\n\t\t\ty: C.int(point.Y),\n\t\t}\n\t}\n\n\tcpoints := C.struct_Points{\n\t\tpoints: (*C.Point)(p),\n\t\tlength: C.int(len(pts)),\n\t}\n\n\treturn PointVector{p: C.PointVector_NewFromPoints(cpoints)}\n}\n\n// NewPointVectorFromMat returns a new PointVector that has been\n// wrapped around a Mat of type CV_32SC2 with a single columm.\nfunc NewPointVectorFromMat(mat Mat) PointVector {\n\treturn PointVector{p: C.PointVector_NewFromMat(mat.p)}\n}\n\n// IsNil checks the CGo pointer in the PointVector.\nfunc (pv PointVector) IsNil() bool {\n\treturn pv.p == nil\n}\n\n// Size returns how many Point are in the PointVector.\nfunc (pv PointVector) Size() int {\n\treturn int(C.PointVector_Size(pv.p))\n}\n\n// At returns the image.Point\nfunc (pv PointVector) At(idx int) image.Point {\n\tif idx > pv.Size() {\n\t\treturn image.Point{}\n\t}\n\n\tcp := C.PointVector_At(pv.p, C.int(idx))\n\treturn image.Pt(int(cp.x), int(cp.y))\n}\n\n// Append appends an image.Point at end of the PointVector.\nfunc (pv PointVector) Append(point image.Point) {\n\tp := C.struct_Point{\n\t\tx: C.int(point.X),\n\t\ty: C.int(point.Y),\n\t}\n\n\tC.PointVector_Append(pv.p, p)\n\n\treturn\n}\n\n// ToPoints returns a slice of image.Point for the data in this PointVector.\nfunc (pv PointVector) ToPoints() []image.Point {\n\tpoints := make([]image.Point, pv.Size())\n\n\tfor j := 0; j < pv.Size(); j++ {\n\t\tpoints[j] = pv.At(j)\n\t}\n\treturn points\n}\n\n// Close closes and frees memory for this PointVector.\nfunc (pv PointVector) Close() {\n\tC.PointVector_Close(pv.p)\n}\n\n// PointsVector is a wrapper around a std::vector< std::vector< cv::Point > >*\ntype PointsVector struct {\n\tp C.PointsVector\n}\n\n// NewPointsVector returns a new empty PointsVector.\nfunc NewPointsVector() PointsVector {\n\treturn PointsVector{p: C.PointsVector_New()}\n}\n\n// NewPointsVectorFromPoints returns a new PointsVector that has been\n// initialized to a slice of slices of image.Point.\nfunc NewPointsVectorFromPoints(pts [][]image.Point) PointsVector {\n\tif len(pts) <= 0 {\n\t\treturn NewPointsVector()\n\t}\n\tpoints := make([]C.struct_Points, len(pts))\n\n\tfor i, pt := range pts {\n\t\tp := (*C.struct_Point)(C.malloc(C.size_t(C.sizeof_struct_Point * len(pt))))\n\t\tdefer C.free(unsafe.Pointer(p))\n\n\t\th := &reflect.SliceHeader{\n\t\t\tData: uintptr(unsafe.Pointer(p)),\n\t\t\tLen:  len(pt),\n\t\t\tCap:  len(pt),\n\t\t}\n\t\tpa := *(*[]C.Point)(unsafe.Pointer(h))\n\n\t\tfor j, point := range pt {\n\t\t\tpa[j] = C.struct_Point{\n\t\t\t\tx: C.int(point.X),\n\t\t\t\ty: C.int(point.Y),\n\t\t\t}\n\t\t}\n\n\t\tpoints[i] = C.struct_Points{\n\t\t\tpoints: (*C.Point)(p),\n\t\t\tlength: C.int(len(pt)),\n\t\t}\n\t}\n\n\tcPoints := C.struct_Contours{\n\t\tcontours: (*C.struct_Points)(&points[0]),\n\t\tlength:   C.int(len(pts)),\n\t}\n\n\treturn PointsVector{p: C.PointsVector_NewFromPoints(cPoints)}\n}\n\nfunc (pvs PointsVector) P() C.PointsVector {\n\treturn pvs.p\n}\n\n// ToPoints returns a slice of slices of image.Point for the data in this PointsVector.\nfunc (pvs PointsVector) ToPoints() [][]image.Point {\n\tppoints := make([][]image.Point, pvs.Size())\n\tfor i := 0; i < pvs.Size(); i++ {\n\t\tpts := pvs.At(i)\n\t\tpoints := make([]image.Point, pts.Size())\n\n\t\tfor j := 0; j < pts.Size(); j++ {\n\t\t\tpoints[j] = pts.At(j)\n\t\t}\n\t\tppoints[i] = points\n\t}\n\n\treturn ppoints\n}\n\n// IsNil checks the CGo pointer in the PointsVector.\nfunc (pvs PointsVector) IsNil() bool {\n\treturn pvs.p == nil\n}\n\n// Size returns how many vectors of Points are in the PointsVector.\nfunc (pvs PointsVector) Size() int {\n\treturn int(C.PointsVector_Size(pvs.p))\n}\n\n// At returns the PointVector at that index of the PointsVector.\nfunc (pvs PointsVector) At(idx int) PointVector {\n\tif idx > pvs.Size() {\n\t\treturn PointVector{}\n\t}\n\n\treturn PointVector{p: C.PointsVector_At(pvs.p, C.int(idx))}\n}\n\n// Append appends a PointVector at end of the PointsVector.\nfunc (pvs PointsVector) Append(pv PointVector) {\n\tif !pv.IsNil() {\n\t\tC.PointsVector_Append(pvs.p, pv.p)\n\t}\n\n\treturn\n}\n\n// Close closes and frees memory for this PointsVector.\nfunc (pvs PointsVector) Close() {\n\tC.PointsVector_Close(pvs.p)\n}\n\n// Point2fVector is a wrapper around a std::vector< cv::Point2f >*\n// This is needed anytime that you need to pass or receive a collection of points.\ntype Point2fVector struct {\n\tp C.Point2fVector\n}\n\n// NewPoint2fVector returns a new empty Point2fVector.\nfunc NewPoint2fVector() Point2fVector {\n\treturn Point2fVector{p: C.Point2fVector_New()}\n}\n\n// NewPoint2fVectorFromPoints returns a new Point2fVector that has been\n// initialized to a slice of image.Point.\nfunc NewPoint2fVectorFromPoints(pts []Point2f) Point2fVector {\n\tp := (*C.struct_Point2f)(C.malloc(C.size_t(C.sizeof_struct_Point2f * len(pts))))\n\tdefer C.free(unsafe.Pointer(p))\n\n\th := &reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(p)),\n\t\tLen:  len(pts),\n\t\tCap:  len(pts),\n\t}\n\tpa := *(*[]C.Point2f)(unsafe.Pointer(h))\n\n\tfor j, point := range pts {\n\t\tpa[j] = C.struct_Point2f{\n\t\t\tx: C.float(point.X),\n\t\t\ty: C.float(point.Y),\n\t\t}\n\t}\n\n\tcpoints := C.struct_Points2f{\n\t\tpoints: (*C.Point2f)(p),\n\t\tlength: C.int(len(pts)),\n\t}\n\n\treturn Point2fVector{p: C.Point2fVector_NewFromPoints(cpoints)}\n}\n\n// NewPoint2fVectorFromMat returns a new Point2fVector that has been\n// wrapped around a Mat of type CV_32FC2 with a single columm.\nfunc NewPoint2fVectorFromMat(mat Mat) Point2fVector {\n\treturn Point2fVector{p: C.Point2fVector_NewFromMat(mat.p)}\n}\n\n// IsNil checks the CGo pointer in the Point2fVector.\nfunc (pfv Point2fVector) IsNil() bool {\n\treturn pfv.p == nil\n}\n\n// Size returns how many Point are in the PointVector.\nfunc (pfv Point2fVector) Size() int {\n\treturn int(C.Point2fVector_Size(pfv.p))\n}\n\n// At returns the image.Point\nfunc (pfv Point2fVector) At(idx int) Point2f {\n\tif idx > pfv.Size() {\n\t\treturn Point2f{}\n\t}\n\n\tcp := C.Point2fVector_At(pfv.p, C.int(idx))\n\treturn Point2f{float32(cp.x), float32(cp.y)}\n}\n\n// ToPoints returns a slice of image.Point for the data in this PointVector.\nfunc (pfv Point2fVector) ToPoints() []Point2f {\n\tpoints := make([]Point2f, pfv.Size())\n\n\tfor j := 0; j < pfv.Size(); j++ {\n\t\tpoints[j] = pfv.At(j)\n\t}\n\treturn points\n}\n\n// Close closes and frees memory for this Point2fVector.\nfunc (pfv Point2fVector) Close() {\n\tC.Point2fVector_Close(pfv.p)\n}\n\n// GetTickCount returns the number of ticks.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/db/de0/group__core__utils.html#gae73f58000611a1af25dd36d496bf4487\nfunc GetTickCount() float64 {\n\treturn float64(C.GetCVTickCount())\n}\n\n// GetTickFrequency returns the number of ticks per second.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/db/de0/group__core__utils.html#ga705441a9ef01f47acdc55d87fbe5090c\nfunc GetTickFrequency() float64 {\n\treturn float64(C.GetTickFrequency())\n}\n\nfunc toByteArray(b []byte) (*C.struct_ByteArray, error) {\n\tif len(b) == 0 {\n\t\treturn nil, ErrEmptyByteSlice\n\t}\n\treturn &C.struct_ByteArray{\n\t\tdata:   (*C.char)(unsafe.Pointer(&b[0])),\n\t\tlength: C.int(len(b)),\n\t}, nil\n}\n\nfunc toGoBytes(b C.struct_ByteArray) []byte {\n\treturn C.GoBytes(unsafe.Pointer(b.data), b.length)\n}\n\n// Converts CStrings to a slice of Go strings even when the C strings are not contiguous in memory\nfunc toGoStrings(strs C.CStrings) []string {\n\tlength := int(strs.length)\n\ttmpslice := (*[1 << 20]*C.char)(unsafe.Pointer(strs.strs))[:length:length]\n\tgostrings := make([]string, length)\n\tfor i, s := range tmpslice {\n\t\tgostrings[i] = C.GoString(s)\n\t}\n\treturn gostrings\n}\n\nfunc toRectangles(ret C.Rects) []image.Rectangle {\n\tcArray := ret.rects\n\tlength := int(ret.length)\n\thdr := reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(cArray)),\n\t\tLen:  length,\n\t\tCap:  length,\n\t}\n\ts := *(*[]C.Rect)(unsafe.Pointer(&hdr))\n\n\trects := make([]image.Rectangle, length)\n\tfor i, r := range s {\n\t\trects[i] = image.Rect(int(r.x), int(r.y), int(r.x+r.width), int(r.y+r.height))\n\t}\n\treturn rects\n}\n\nfunc toRect(rect C.Rect) image.Rectangle {\n\treturn image.Rect(int(rect.x), int(rect.y), int(rect.x+rect.width), int(rect.y+rect.height))\n}\n\nfunc toCPoints(points []image.Point) C.struct_Points {\n\tcPointSlice := make([]C.struct_Point, len(points))\n\tfor i, point := range points {\n\t\tcPointSlice[i] = C.struct_Point{\n\t\t\tx: C.int(point.X),\n\t\t\ty: C.int(point.Y),\n\t\t}\n\t}\n\n\treturn C.struct_Points{\n\t\tpoints: (*C.Point)(&cPointSlice[0]),\n\t\tlength: C.int(len(points)),\n\t}\n}\n\nfunc toCPoints2f(points []Point2f) C.struct_Points2f {\n\tcPointSlice := make([]C.struct_Point2f, len(points))\n\tfor i, point := range points {\n\t\tcPointSlice[i] = C.struct_Point2f{\n\t\t\tx: C.float(point.X),\n\t\t\ty: C.float(point.Y),\n\t\t}\n\t}\n\n\treturn C.struct_Points2f{\n\t\tpoints: (*C.Point2f)(&cPointSlice[0]),\n\t\tlength: C.int(len(points)),\n\t}\n}\n\nfunc toCStrings(strs []string) C.struct_CStrings {\n\tcStringsSlice := make([]*C.char, len(strs))\n\tfor i, s := range strs {\n\t\tcStringsSlice[i] = C.CString(s)\n\t}\n\n\treturn C.struct_CStrings{\n\t\tstrs:   (**C.char)(&cStringsSlice[0]),\n\t\tlength: C.int(len(strs)),\n\t}\n}\n\n// RowRange creates a matrix header for the specified row span.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/d63/classcv_1_1Mat.html#aa6542193430356ad631a9beabc624107\nfunc (m *Mat) RowRange(start, end int) Mat {\n\treturn newMat(C.Mat_rowRange(m.p, C.int(start), C.int(end)))\n}\n\n// ColRange creates a matrix header for the specified column span.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/d63/classcv_1_1Mat.html#aadc8f9210fe4dec50513746c246fa8d9\nfunc (m *Mat) ColRange(start, end int) Mat {\n\treturn newMat(C.Mat_colRange(m.p, C.int(start), C.int(end)))\n}\n\n// RNG Random Number Generator.\n// It encapsulates the state (currently, a 64-bit integer) and\n// has methods to return scalar random values and to fill arrays\n// with random values\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d1/dd6/classcv_1_1RNG.html\ntype RNG struct {\n\tp C.RNG\n}\n\ntype RNGDistType int\n\nconst (\n\t// Uniform distribution\n\tRNGDistUniform RNGDistType = 0\n\t// Normal distribution\n\tRNGDistNormal RNGDistType = 1\n)\n\n// TheRNG Returns the default random number generator.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga75843061d150ad6564b5447e38e57722\nfunc TheRNG() RNG {\n\treturn RNG{\n\t\tp: C.TheRNG(),\n\t}\n}\n\n// TheRNG Sets state of default random number generator.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga757e657c037410d9e19e819569e7de0f\nfunc SetRNGSeed(seed int) {\n\tC.SetRNGSeed(C.int(seed))\n}\n\n// Fill Fills arrays with random numbers.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d1/dd6/classcv_1_1RNG.html#ad26f2b09d9868cf108e84c9814aa682d\nfunc (r *RNG) Fill(mat *Mat, distType RNGDistType, a, b float64, saturateRange bool) {\n\tC.RNG_Fill(r.p, mat.p, C.int(distType), C.double(a), C.double(b), C.bool(saturateRange))\n}\n\n// Gaussian Returns the next random number sampled from\n// the Gaussian distribution.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d1/dd6/classcv_1_1RNG.html#a8df8ce4dc7d15916cee743e5a884639d\nfunc (r *RNG) Gaussian(sigma float64) float64 {\n\treturn float64(C.RNG_Gaussian(r.p, C.double(sigma)))\n}\n\n// Next The method updates the state using the MWC algorithm\n// and returns the next 32-bit random number.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d1/dd6/classcv_1_1RNG.html#a8df8ce4dc7d15916cee743e5a884639d\nfunc (r *RNG) Next() uint {\n\treturn uint(C.RNG_Next(r.p))\n}\n\n// RandN Fills the array with normally distributed random numbers.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#gaeff1f61e972d133a04ce3a5f81cf6808\nfunc RandN(mat *Mat, mean, stddev Scalar) {\n\tmeanVal := C.struct_Scalar{\n\t\tval1: C.double(mean.Val1),\n\t\tval2: C.double(mean.Val2),\n\t\tval3: C.double(mean.Val3),\n\t\tval4: C.double(mean.Val4),\n\t}\n\tstddevVal := C.struct_Scalar{\n\t\tval1: C.double(stddev.Val1),\n\t\tval2: C.double(stddev.Val2),\n\t\tval3: C.double(stddev.Val3),\n\t\tval4: C.double(stddev.Val4),\n\t}\n\n\tC.RandN(mat.p, meanVal, stddevVal)\n}\n\n// RandShuffle Shuffles the array elements randomly.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga6a789c8a5cb56c6dd62506179808f763\nfunc RandShuffle(mat *Mat) {\n\tC.RandShuffle(mat.p)\n}\n\n// RandShuffleWithParams Shuffles the array elements randomly.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga6a789c8a5cb56c6dd62506179808f763\nfunc RandShuffleWithParams(mat *Mat, iterFactor float64, rng RNG) {\n\tC.RandShuffleWithParams(mat.p, C.double(iterFactor), rng.p)\n}\n\n// RandU Generates a single uniformly-distributed random\n// number or an array of random numbers.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d2/de8/group__core__array.html#ga1ba1026dca0807b27057ba6a49d258c0\nfunc RandU(mat *Mat, low, high Scalar) {\n\tlowVal := C.struct_Scalar{\n\t\tval1: C.double(low.Val1),\n\t\tval2: C.double(low.Val2),\n\t\tval3: C.double(low.Val3),\n\t\tval4: C.double(low.Val4),\n\t}\n\thighVal := C.struct_Scalar{\n\t\tval1: C.double(high.Val1),\n\t\tval2: C.double(high.Val2),\n\t\tval3: C.double(high.Val3),\n\t\tval4: C.double(high.Val4),\n\t}\n\n\tC.RandU(mat.p, lowVal, highVal)\n}\n\ntype NativeByteBuffer struct {\n\t// std::vector is build of 3 pointers And this will not change ever.\n\tstdVectorOpaq [3]uintptr\n}\n\nfunc newNativeByteBuffer() *NativeByteBuffer {\n\tbuffer := &NativeByteBuffer{}\n\tC.StdByteVectorInitialize(buffer.nativePointer())\n\treturn buffer\n}\n\nfunc (buffer *NativeByteBuffer) nativePointer() unsafe.Pointer {\n\treturn unsafe.Pointer(&buffer.stdVectorOpaq[0])\n}\n\nfunc (buffer *NativeByteBuffer) dataPointer() unsafe.Pointer {\n\treturn unsafe.Pointer(C.StdByteVectorData(buffer.nativePointer()))\n}\n\n// GetBytes returns slice of bytes backed by native buffer\nfunc (buffer *NativeByteBuffer) GetBytes() []byte {\n\tvar result []byte\n\tsliceHeader := (*reflect.SliceHeader)(unsafe.Pointer(&result))\n\tvectorLen := int(C.StdByteVectorLen(buffer.nativePointer()))\n\tsliceHeader.Cap = vectorLen\n\tsliceHeader.Len = vectorLen\n\tsliceHeader.Data = uintptr(buffer.dataPointer())\n\treturn result\n}\n\n// Len - returns length in bytes of underlying buffer\nfunc (buffer *NativeByteBuffer) Len() int {\n\treturn int(C.StdByteVectorLen(buffer.nativePointer()))\n}\n\n// Close the buffer releasing all its resources\nfunc (buffer *NativeByteBuffer) Close() {\n\tC.StdByteVectorFree(buffer.nativePointer())\n}\n\n// Points2fVector is a wrapper around a std::vector< std::vector< cv::Point2f > >*\ntype Points2fVector struct {\n\tp C.Points2fVector\n}\n\n// NewPoints2fVector returns a new empty Points2fVector.\nfunc NewPoints2fVector() Points2fVector {\n\treturn Points2fVector{p: C.Points2fVector_New()}\n}\n\n// NewPoints2fVectorFromPoints returns a new Points2fVector that has been\n// initialized to a slice of slices of Point2f.\nfunc NewPoints2fVectorFromPoints(pts [][]Point2f) Points2fVector {\n\tpvf := NewPoints2fVector()\n\tfor j := 0; j < len(pts); j++ {\n\t\tpv := NewPoint2fVectorFromPoints(pts[j])\n\t\tpvf.Append(pv)\n\t\tpv.Close()\n\t}\n\treturn pvf\n}\n\nfunc (pvs Points2fVector) P() C.Points2fVector {\n\treturn pvs.p\n}\n\n// ToPoints returns a slice of slices of Point2f for the data in this Points2fVector.\nfunc (pvs Points2fVector) ToPoints() [][]Point2f {\n\tppoints := make([][]Point2f, pvs.Size())\n\tfor j := 0; j < pvs.Size(); j++ {\n\t\tpts := pvs.At(j)\n\t\tpoints := pts.ToPoints()\n\t\tppoints[j] = points\n\t}\n\treturn ppoints\n}\n\n// IsNil checks the CGo pointer in the Points2fVector.\nfunc (pvs Points2fVector) IsNil() bool {\n\treturn pvs.p == nil\n}\n\n// Size returns how many vectors of Points are in the Points2fVector.\nfunc (pvs Points2fVector) Size() int {\n\treturn int(C.Points2fVector_Size(pvs.p))\n}\n\n// At returns the Point2fVector at that index of the Points2fVector.\nfunc (pvs Points2fVector) At(idx int) Point2fVector {\n\tif idx > pvs.Size() {\n\t\treturn Point2fVector{}\n\t}\n\treturn Point2fVector{p: C.Points2fVector_At(pvs.p, C.int(idx))}\n}\n\n// Append appends a Point2fVector at end of the Points2fVector.\nfunc (pvs Points2fVector) Append(pv Point2fVector) {\n\tif !pv.IsNil() {\n\t\tC.Points2fVector_Append(pvs.p, pv.p)\n\t}\n}\n\n// Close closes and frees memory for this Points2fVector.\nfunc (pvs Points2fVector) Close() {\n\tC.Points2fVector_Close(pvs.p)\n}\n\ntype Point3f struct {\n\tX float32\n\tY float32\n\tZ float32\n}\n\nfunc NewPoint3f(x, y, z float32) Point3f {\n\treturn Point3f{x, y, z}\n}\n\n// Point3fVector is a wrapper around a std::vector< cv::Point3f >*\ntype Point3fVector struct {\n\tp C.Point3fVector\n}\n\n// NewPoint3fVector returns a new empty Point3fVector.\nfunc NewPoint3fVector() Point3fVector {\n\treturn Point3fVector{p: C.Point3fVector_New()}\n}\n\n// NewPoint3fVectorFromPoints returns a new Point3fVector that has been\n// initialized to a slice of image.Point.\nfunc NewPoint3fVectorFromPoints(pts []Point3f) Point3fVector {\n\tp := (*C.struct_Point3f)(C.malloc(C.size_t(C.sizeof_struct_Point3f * len(pts))))\n\tdefer C.free(unsafe.Pointer(p))\n\n\th := &reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(p)),\n\t\tLen:  len(pts),\n\t\tCap:  len(pts),\n\t}\n\tpa := *(*[]C.Point3f)(unsafe.Pointer(h))\n\n\tfor j, point := range pts {\n\t\tpa[j] = C.struct_Point3f{\n\t\t\tx: C.float(point.X),\n\t\t\ty: C.float(point.Y),\n\t\t\tz: C.float(point.Z),\n\t\t}\n\t}\n\n\tcPoints := C.struct_Points3f{\n\t\tpoints: (*C.Point3f)(p),\n\t\tlength: C.int(len(pts)),\n\t}\n\n\treturn Point3fVector{p: C.Point3fVector_NewFromPoints(cPoints)}\n}\n\n// NewPoint3fVectorFromMat returns a new Point3fVector that has been\n// wrapped around a Mat of type CV_32FC3 with a single columm.\nfunc NewPoint3fVectorFromMat(mat Mat) Point3fVector {\n\treturn Point3fVector{p: C.Point3fVector_NewFromMat(mat.p)}\n}\n\n// IsNil checks the CGo pointer in the Point3fVector.\nfunc (pfv Point3fVector) IsNil() bool {\n\treturn pfv.p == nil\n}\n\n// Size returns how many Point are in the Point3fVector.\nfunc (pfv Point3fVector) Size() int {\n\treturn int(C.Point3fVector_Size(pfv.p))\n}\n\n// At returns the Point3f\nfunc (pfv Point3fVector) At(idx int) Point3f {\n\tif idx > pfv.Size() {\n\t\treturn Point3f{}\n\t}\n\tcp := C.Point3fVector_At(pfv.p, C.int(idx))\n\treturn Point3f{X: float32(cp.x), Y: float32(cp.y), Z: float32(cp.z)}\n}\n\nfunc (pfv Point3fVector) Append(point Point3f) {\n\tC.Point3fVector_Append(pfv.p, C.Point3f{\n\t\tx: C.float(point.X),\n\t\ty: C.float(point.Y),\n\t\tz: C.float(point.Z),\n\t})\n}\n\n// ToPoints returns a slice of Point3f for the data in this Point3fVector.\nfunc (pfv Point3fVector) ToPoints() []Point3f {\n\tpoints := make([]Point3f, pfv.Size())\n\tfor j := 0; j < pfv.Size(); j++ {\n\t\tpoints[j] = pfv.At(j)\n\t}\n\treturn points\n}\n\n// Close closes and frees memory for this Point3fVector.\nfunc (pfv Point3fVector) Close() {\n\tC.Point3fVector_Close(pfv.p)\n}\n\n// Points3fVector is a wrapper around a std::vector< std::vector< cv::Point3f > >*\ntype Points3fVector struct {\n\tp C.Points3fVector\n}\n\n// NewPoints3fVector returns a new empty Points3fVector.\nfunc NewPoints3fVector() Points3fVector {\n\treturn Points3fVector{p: C.Points3fVector_New()}\n}\n\n// NewPoints3fVectorFromPoints returns a new Points3fVector that has been\n// initialized to a slice of slices of Point3f.\nfunc NewPoints3fVectorFromPoints(pts [][]Point3f) Points3fVector {\n\tpvf := NewPoints3fVector()\n\tfor j := 0; j < len(pts); j++ {\n\t\tpv := NewPoint3fVectorFromPoints(pts[j])\n\t\tpvf.Append(pv)\n\t\tpv.Close()\n\t}\n\treturn pvf\n}\n\n// ToPoints returns a slice of slices of Point3f for the data in this Points3fVector.\nfunc (pvs Points3fVector) ToPoints() [][]Point3f {\n\tppoints := make([][]Point3f, pvs.Size())\n\tfor j := 0; j < pvs.Size(); j++ {\n\t\tpts := pvs.At(j)\n\t\tpoints := pts.ToPoints()\n\t\tppoints[j] = points\n\t}\n\treturn ppoints\n}\n\n// IsNil checks the CGo pointer in the Points3fVector.\nfunc (pvs Points3fVector) IsNil() bool {\n\treturn pvs.p == nil\n}\n\n// Size returns how many vectors of Points are in the Points3fVector.\nfunc (pvs Points3fVector) Size() int {\n\treturn int(C.Points3fVector_Size(pvs.p))\n}\n\n// At returns the Point3fVector at that index of the Points3fVector.\nfunc (pvs Points3fVector) At(idx int) Point3fVector {\n\tif idx > pvs.Size() {\n\t\treturn Point3fVector{}\n\t}\n\treturn Point3fVector{p: C.Points3fVector_At(pvs.p, C.int(idx))}\n}\n\n// Append appends a Point3fVector at end of the Points3fVector.\nfunc (pvs Points3fVector) Append(pv Point3fVector) {\n\tif !pv.IsNil() {\n\t\tC.Points3fVector_Append(pvs.p, pv.p)\n\t}\n}\n\n// Close closes and frees memory for this Points3fVector.\nfunc (pvs Points3fVector) Close() {\n\tC.Points3fVector_Close(pvs.p)\n}\n\n// Set the number of threads for OpenCV.\nfunc SetNumThreads(n int) {\n\tC.SetNumThreads(C.int(n))\n}\n\n// Get the number of threads for OpenCV.\nfunc GetNumThreads() int {\n\treturn int(C.GetNumThreads())\n}\n\n// NewRotatedRect creates [RotatedRect] (i.e. not up-right) rectangle on a plane.\n//\n// For further information, see:\n// https://docs.opencv.org/4.x/db/dd6/classcv_1_1RotatedRect.html#aba20dfc8444fff72bd820b616f0297ee\nfunc NewRotatedRect(center image.Point, width int, height int, angle float64) RotatedRect {\n\n\tp2f := C.struct_Point2f{\n\t\tx: C.float(float32(center.X)),\n\t\ty: C.float(float32(center.Y)),\n\t}\n\n\tc_rotRect := C.RotatedRect_Create(p2f, C.int(width), C.int(height), C.float(angle))\n\tdefer C.Points_Close(c_rotRect.pts)\n\n\treturn RotatedRect{\n\t\tPoints:       toPoints(c_rotRect.pts),\n\t\tBoundingRect: image.Rect(int(c_rotRect.boundingRect.x), int(c_rotRect.boundingRect.y), int(c_rotRect.boundingRect.x)+int(c_rotRect.boundingRect.width), int(c_rotRect.boundingRect.y)+int(c_rotRect.boundingRect.height)),\n\t\tCenter:       image.Pt(int(c_rotRect.center.x), int(c_rotRect.center.y)),\n\t\tWidth:        int(c_rotRect.size.width),\n\t\tHeight:       int(c_rotRect.size.height),\n\t\tAngle:        float64(c_rotRect.angle),\n\t}\n\n}\n\n// NewRotatedRect2f creates [RotatedRect2f] (i.e. not up-right) rectangle on a plane.\n//\n// For further information, see:\n// https://docs.opencv.org/4.x/db/dd6/classcv_1_1RotatedRect.html#aba20dfc8444fff72bd820b616f0297ee\nfunc NewRotatedRect2f(center Point2f, width float32, height float32, angle float64) RotatedRect2f {\n\tp2f := C.struct_Point2f{\n\t\tx: C.float(center.X),\n\t\ty: C.float(center.Y),\n\t}\n\tc_rotRect2f := C.RotatedRect2f_Create(p2f, C.float(width), C.float(height), C.float(angle))\n\tdefer C.Points2f_Close(c_rotRect2f.pts)\n\n\treturn RotatedRect2f{\n\t\tPoints:       toPoints2f(c_rotRect2f.pts),\n\t\tBoundingRect: image.Rect(int(c_rotRect2f.boundingRect.x), int(c_rotRect2f.boundingRect.y), int(c_rotRect2f.boundingRect.x)+int(c_rotRect2f.boundingRect.width), int(c_rotRect2f.boundingRect.y)+int(c_rotRect2f.boundingRect.height)),\n\t\tCenter:       NewPoint2f(float32(c_rotRect2f.center.x), float32(c_rotRect2f.center.y)),\n\t\tWidth:        float32(c_rotRect2f.size.width),\n\t\tHeight:       float32(c_rotRect2f.size.height),\n\t\tAngle:        float64(c_rotRect2f.angle),\n\t}\n}\n"
        },
        {
          "name": "core.h",
          "type": "blob",
          "size": 17.814453125,
          "content": "#ifndef _OPENCV3_CORE_H_\n#define _OPENCV3_CORE_H_\n\n#include <stdint.h>\n#include <stdbool.h>\n\n// Wrapper for std::vector<string>\ntypedef struct CStrings {\n    const char** strs;\n    int length;\n} CStrings;\n\ntypedef struct ByteArray {\n    char* data;\n    int length;\n} ByteArray;\n\n// Wrapper for std::vector<int>\ntypedef struct IntVector {\n    int* val;\n    int length;\n} IntVector;\n\n// Wrapper for std::vector<float>\ntypedef struct FloatVector {\n    float* val;\n    int length;\n} FloatVector;\n\n#ifdef __cplusplus\n#include <opencv2/opencv.hpp>\nextern \"C\" {\n#endif\n\ntypedef struct RawData {\n    int width;\n    int height;\n    struct ByteArray data;\n} RawData;\n\n// Wrapper for an individual cv::Point2f\ntypedef struct Point2f {\n    float x;\n    float y;\n} Point2f;\n\ntypedef struct Point3f {\n    float x;\n    float y;\n    float z;\n} Point3f;\n\n// Wrapper for an individual cv::cvPoint\ntypedef struct Point {\n    int x;\n    int y;\n} Point;\n\n// Wrapper for the vector of Point structs aka std::vector<Point>\ntypedef struct Points {\n    Point* points;\n    int length;\n} Points;\n\n// Wrapper for the vector of Point2f structs aka std::vector<Point2f>\ntypedef struct Points2f {\n    Point2f* points;\n    int length;\n} Points2f;\n\ntypedef struct Points3f {\n    Point3f *points;\n    int length;\n} Points3f;\n\n// Contour is alias for Points\ntypedef Points Contour;\n\n\n// Contour2f is alias for Points2f\ntypedef Points2f Contour2f;\n\ntypedef struct Contours2f {\n    Contour2f *contours;\n    int length;\n} Contours2f;\n\n// Contour3f is alias for Points3f\ntypedef Points3f Contour3f;\n\n// Wrapper for the vector of Points3f vectors aka std::vector< std::vector<Point3f> >\ntypedef struct Contours3f {\n    Contour3f *contours;\n    int length;\n} Contours3f;\n\n\n// Wrapper for the vector of Points vectors aka std::vector< std::vector<Point> >\ntypedef struct Contours {\n    Contour* contours;\n    int length;\n} Contours;\n\n// Wrapper for an individual cv::cvRect\ntypedef struct Rect {\n    int x;\n    int y;\n    int width;\n    int height;\n} Rect;\n\n// Wrapper for an individual cv::cvRect2f\ntypedef struct Rect2f {\n    float x;\n    float y;\n    float width;\n    float height;\n} Rect2f;\n\n// Wrapper for the vector of Rect struct aka std::vector<Rect>\ntypedef struct Rects {\n    Rect* rects;\n    int length;\n} Rects;\n\n// Wrapper for an individual cv::cvSize\ntypedef struct Size {\n    int width;\n    int height;\n} Size;\n\n// Wrapper for an individual cv::cvSize\ntypedef struct Size2f {\n    float width;\n    float height;\n} Size2f;\n\n// Wrapper for an individual cv::RotatedRect\ntypedef struct RotatedRect {\n    Points pts;\n    Rect boundingRect;\n    Point center;\n    Size size;\n    double angle;\n} RotatedRect;\n\n// Wrapper for an individual cv::RotatedRect2f\ntypedef struct RotatedRect2f {\n    Points2f pts;\n    Rect boundingRect;\n    Point2f center;\n    Size2f size;\n    double angle;\n} RotatedRect2f;\n\n// Wrapper for an individual cv::cvScalar\ntypedef struct Scalar {\n    double val1;\n    double val2;\n    double val3;\n    double val4;\n} Scalar;\n\n// Wrapper for a individual cv::KeyPoint\ntypedef struct KeyPoint {\n    double x;\n    double y;\n    double size;\n    double angle;\n    double response;\n    int octave;\n    int classID;\n} KeyPoint;\n\n// Wrapper for the vector of KeyPoint struct aka std::vector<KeyPoint>\ntypedef struct KeyPoints {\n    KeyPoint* keypoints;\n    int length;\n} KeyPoints;\n\n// Wrapper for SimpleBlobDetectorParams aka SimpleBlobDetector::Params\ntypedef struct SimpleBlobDetectorParams {\n    unsigned char   blobColor;\n    bool    filterByArea;\n    bool    filterByCircularity;\n    bool    filterByColor;\n    bool    filterByConvexity;\n    bool    filterByInertia;\n    float   maxArea;\n    float   maxCircularity;\n    float   maxConvexity;\n    float   maxInertiaRatio;\n    float   maxThreshold;\n    float   minArea;\n    float   minCircularity;\n    float   minConvexity;\n    float   minDistBetweenBlobs;\n    float   minInertiaRatio;\n    size_t  minRepeatability;\n    float   minThreshold;\n    float   thresholdStep;\n} SimpleBlobDetectorParams;\n\n// Wrapper for an individual cv::DMatch\ntypedef struct DMatch {\n    int queryIdx;\n    int trainIdx;\n    int imgIdx;\n    float distance;\n} DMatch;\n\n// Wrapper for the vector of DMatch struct aka std::vector<DMatch>\ntypedef struct DMatches {\n    DMatch* dmatches;\n    int length;\n} DMatches;\n\n// Wrapper for the vector vector of DMatch struct aka std::vector<std::vector<DMatch>>\ntypedef struct MultiDMatches {\n    DMatches* dmatches;\n    int length;\n} MultiDMatches;\n\n// Wrapper for an individual cv::Moment\ntypedef struct Moment {\n    double m00;\n    double m10;\n    double m01;\n    double m20;\n    double m11;\n    double m02;\n    double m30;\n    double m21;\n    double m12;\n    double m03;\n\n    double mu20;\n    double mu11;\n    double mu02;\n    double mu30;\n    double mu21;\n    double mu12;\n    double mu03;\n\n    double nu20;\n    double nu11;\n    double nu02;\n    double nu30;\n    double nu21;\n    double nu12;\n    double nu03;\n} Moment;\n\n#ifdef __cplusplus\ntypedef cv::Mat* Mat;\ntypedef cv::TermCriteria* TermCriteria;\ntypedef cv::RNG* RNG;\ntypedef std::vector< cv::Point >* PointVector;\ntypedef std::vector< std::vector< cv::Point > >* PointsVector;\ntypedef std::vector< cv::Point2f >* Point2fVector;\ntypedef std::vector< std::vector< cv::Point2f> >* Points2fVector;\ntypedef std::vector< cv::Point3f >* Point3fVector;\ntypedef std::vector< std::vector< cv::Point3f > >* Points3fVector;\ntypedef cv::RotatedRect* RotatedRectT;\n#else\ntypedef void* Mat;\ntypedef void* TermCriteria;\ntypedef void* RNG;\ntypedef void* PointVector;\ntypedef void* PointsVector;\ntypedef void* Point2fVector;\ntypedef void* Points2fVector;\ntypedef void* Point3fVector;\ntypedef void* Points3fVector;\ntypedef void* RotatedRectT;\n#endif\n\n// Wrapper for the vector of Mat aka std::vector<Mat>\ntypedef struct Mats {\n    Mat* mats;\n    int length;\n} Mats;\n\nMat Mats_get(struct Mats mats, int i);\nstruct DMatches MultiDMatches_get(struct MultiDMatches mds, int index);\n\nstruct ByteArray toByteArray(const char* buf, int len);\nvoid ByteArray_Release(struct ByteArray buf);\n\nvoid Contours_Close(struct Contours cs);\nvoid KeyPoints_Close(struct KeyPoints ks);\nvoid Rects_Close(struct Rects rs);\nvoid Mats_Close(struct Mats mats);\nvoid Point_Close(struct Point p);\nvoid Points_Close(struct Points ps);\nvoid Point2f_Close(struct Point2f p);\nvoid Points2f_Close(struct Points2f ps);\nvoid DMatches_Close(struct DMatches ds);\nvoid MultiDMatches_Close(struct MultiDMatches mds);\n\nMat Mat_New();\nMat Mat_NewWithSize(int rows, int cols, int type);\nMat Mat_NewWithSizes(struct IntVector sizes, int type);\nMat Mat_NewWithSizesFromScalar(IntVector sizes, int type, Scalar ar);\nMat Mat_NewWithSizesFromBytes(IntVector sizes, int type, struct ByteArray buf);\nMat Mat_NewFromScalar(const Scalar ar, int type);\nMat Mat_NewWithSizeFromScalar(const Scalar ar, int rows, int cols, int type);\nMat Mat_NewFromBytes(int rows, int cols, int type, struct ByteArray buf);\nMat Mat_FromPtr(Mat m, int rows, int cols, int type, int prows, int pcols);\nvoid Mat_Close(Mat m);\nint Mat_Empty(Mat m);\nbool Mat_IsContinuous(Mat m);\nvoid Mat_Inv(Mat m);\nMat Mat_Col(Mat m, int c);\nMat Mat_Row(Mat m, int r);\nMat Mat_Clone(Mat m);\nvoid Mat_CopyTo(Mat m, Mat dst);\nint Mat_Total(Mat m);\nvoid Mat_Size(Mat m, IntVector* res);\nvoid Mat_CopyToWithMask(Mat m, Mat dst, Mat mask);\nvoid Mat_ConvertTo(Mat m, Mat dst, int type);\nvoid Mat_ConvertToWithParams(Mat m, Mat dst, int type, float alpha, float beta);\nstruct ByteArray Mat_ToBytes(Mat m);\nstruct ByteArray Mat_DataPtr(Mat m);\nMat Mat_Region(Mat m, Rect r);\nMat Mat_Reshape(Mat m, int cn, int rows);\nvoid Mat_PatchNaNs(Mat m);\nMat Mat_ConvertFp16(Mat m);\nScalar Mat_Mean(Mat m);\nScalar Mat_MeanWithMask(Mat m, Mat mask);\nMat Mat_Sqrt(Mat m);\nint Mat_Rows(Mat m);\nint Mat_Cols(Mat m);\nint Mat_Channels(Mat m);\nint Mat_Type(Mat m);\nint Mat_Step(Mat m);\nint Mat_ElemSize(Mat m);\nMat Eye(int rows, int cols, int type);\nMat Zeros(int rows, int cols, int type);\nMat Ones(int rows, int cols, int type);\n\nuint8_t Mat_GetUChar(Mat m, int row, int col);\nuint8_t Mat_GetUChar3(Mat m, int x, int y, int z);\nint8_t Mat_GetSChar(Mat m, int row, int col);\nint8_t Mat_GetSChar3(Mat m, int x, int y, int z);\nint16_t Mat_GetShort(Mat m, int row, int col);\nint16_t Mat_GetShort3(Mat m, int x, int y, int z);\nint32_t Mat_GetInt(Mat m, int row, int col);\nint32_t Mat_GetInt3(Mat m, int x, int y, int z);\nfloat Mat_GetFloat(Mat m, int row, int col);\nfloat Mat_GetFloat3(Mat m, int x, int y, int z);\ndouble Mat_GetDouble(Mat m, int row, int col);\ndouble Mat_GetDouble3(Mat m, int x, int y, int z);\n\nvoid Mat_SetTo(Mat m, Scalar value);\nvoid Mat_SetUChar(Mat m, int row, int col, uint8_t val);\nvoid Mat_SetUChar3(Mat m, int x, int y, int z, uint8_t val);\nvoid Mat_SetSChar(Mat m, int row, int col, int8_t val);\nvoid Mat_SetSChar3(Mat m, int x, int y, int z, int8_t val);\nvoid Mat_SetShort(Mat m, int row, int col, int16_t val);\nvoid Mat_SetShort3(Mat m, int x, int y, int z, int16_t val);\nvoid Mat_SetInt(Mat m, int row, int col, int32_t val);\nvoid Mat_SetInt3(Mat m, int x, int y, int z, int32_t val);\nvoid Mat_SetFloat(Mat m, int row, int col, float val);\nvoid Mat_SetFloat3(Mat m, int x, int y, int z, float val);\nvoid Mat_SetDouble(Mat m, int row, int col, double val);\nvoid Mat_SetDouble3(Mat m, int x, int y, int z, double val);\n\nvoid Mat_AddUChar(Mat m, uint8_t val);\nvoid Mat_SubtractUChar(Mat m, uint8_t val);\nvoid Mat_MultiplyUChar(Mat m, uint8_t val);\nvoid Mat_DivideUChar(Mat m, uint8_t val);\nvoid Mat_AddFloat(Mat m, float val);\nvoid Mat_SubtractFloat(Mat m, float val);\nvoid Mat_MultiplyFloat(Mat m, float val);\nvoid Mat_DivideFloat(Mat m, float val);\nMat Mat_MultiplyMatrix(Mat x, Mat y);\n\nMat Mat_T(Mat x);\n\nvoid LUT(Mat src, Mat lut, Mat dst);\n\nvoid Mat_AbsDiff(Mat src1, Mat src2, Mat dst);\nvoid Mat_Add(Mat src1, Mat src2, Mat dst);\nvoid Mat_AddWeighted(Mat src1, double alpha, Mat src2, double beta, double gamma, Mat dst);\nvoid Mat_BitwiseAnd(Mat src1, Mat src2, Mat dst);\nvoid Mat_BitwiseAndWithMask(Mat src1, Mat src2, Mat dst, Mat mask);\nvoid Mat_BitwiseNot(Mat src1, Mat dst);\nvoid Mat_BitwiseNotWithMask(Mat src1, Mat dst, Mat mask);\nvoid Mat_BitwiseOr(Mat src1, Mat src2, Mat dst);\nvoid Mat_BitwiseOrWithMask(Mat src1, Mat src2, Mat dst, Mat mask);\nvoid Mat_BitwiseXor(Mat src1, Mat src2, Mat dst);\nvoid Mat_BitwiseXorWithMask(Mat src1, Mat src2, Mat dst, Mat mask);\nvoid Mat_Compare(Mat src1, Mat src2, Mat dst, int ct);\nvoid Mat_BatchDistance(Mat src1, Mat src2, Mat dist, int dtype, Mat nidx, int normType, int K,\n                       Mat mask, int update, bool crosscheck);\nint Mat_BorderInterpolate(int p, int len, int borderType);\nvoid Mat_CalcCovarMatrix(Mat samples, Mat covar, Mat mean, int flags, int ctype);\nvoid Mat_CartToPolar(Mat x, Mat y, Mat magnitude, Mat angle, bool angleInDegrees);\nbool Mat_CheckRange(Mat m);\nvoid Mat_CompleteSymm(Mat m, bool lowerToUpper);\nvoid Mat_ConvertScaleAbs(Mat src, Mat dst, double alpha, double beta);\nvoid Mat_CopyMakeBorder(Mat src, Mat dst, int top, int bottom, int left, int right, int borderType,\n                        Scalar value);\nint Mat_CountNonZero(Mat src);\nvoid Mat_DCT(Mat src, Mat dst, int flags);\ndouble Mat_Determinant(Mat m);\nvoid Mat_DFT(Mat m, Mat dst, int flags);\nvoid Mat_Divide(Mat src1, Mat src2, Mat dst);\nbool Mat_Eigen(Mat src, Mat eigenvalues, Mat eigenvectors);\nvoid Mat_EigenNonSymmetric(Mat src, Mat eigenvalues, Mat eigenvectors);\nvoid Mat_PCABackProject(Mat data, Mat mean, Mat eigenvectors, Mat result);\nvoid Mat_PCACompute(Mat src, Mat mean, Mat eigenvectors, Mat eigenvalues, int maxComponents);\nvoid Mat_PCAProject(Mat data, Mat mean, Mat eigenvectors, Mat result);\ndouble PSNR(Mat src1, Mat src2);\nvoid SVBackSubst(Mat w, Mat u, Mat vt, Mat rhs, Mat dst);\nvoid SVDecomp(Mat src, Mat w, Mat u, Mat vt);\nvoid Mat_Exp(Mat src, Mat dst);\nvoid Mat_ExtractChannel(Mat src, Mat dst, int coi);\nvoid Mat_FindNonZero(Mat src, Mat idx);\nvoid Mat_Flip(Mat src, Mat dst, int flipCode);\nvoid Mat_Gemm(Mat src1, Mat src2, double alpha, Mat src3, double beta, Mat dst, int flags);\nint Mat_GetOptimalDFTSize(int vecsize);\nvoid Mat_Hconcat(Mat src1, Mat src2, Mat dst);\nvoid Mat_Vconcat(Mat src1, Mat src2, Mat dst);\nvoid Rotate(Mat src, Mat dst, int rotationCode);\nvoid Mat_Idct(Mat src, Mat dst, int flags);\nvoid Mat_Idft(Mat src, Mat dst, int flags, int nonzeroRows);\nvoid Mat_InRange(Mat src, Mat lowerb, Mat upperb, Mat dst);\nvoid Mat_InRangeWithScalar(Mat src, const Scalar lowerb, const Scalar upperb, Mat dst);\nvoid Mat_InsertChannel(Mat src, Mat dst, int coi);\ndouble Mat_Invert(Mat src, Mat dst, int flags);\ndouble KMeans(Mat data, int k, Mat bestLabels, TermCriteria criteria, int attempts, int flags, Mat centers);\ndouble KMeansPoints(PointVector pts, int k, Mat bestLabels, TermCriteria criteria, int attempts, int flags, Mat centers);\nvoid Mat_Log(Mat src, Mat dst);\nvoid Mat_Magnitude(Mat x, Mat y, Mat magnitude);\ndouble Mat_Mahalanobis(Mat v1, Mat v2, Mat icovar);\nvoid MulTransposed(Mat src, Mat dest, bool ata);\nvoid Mat_Max(Mat src1, Mat src2, Mat dst);\nvoid Mat_MeanStdDev(Mat src, Mat dstMean, Mat dstStdDev);\nvoid Mat_Merge(struct Mats mats, Mat dst);\nvoid Mat_Min(Mat src1, Mat src2, Mat dst);\nvoid Mat_MinMaxIdx(Mat m, double* minVal, double* maxVal, int* minIdx, int* maxIdx);\nvoid Mat_MinMaxLoc(Mat m, double* minVal, double* maxVal, Point* minLoc, Point* maxLoc);\nvoid Mat_MinMaxLocWithMask(Mat m, double* minVal, double* maxVal, Point* minLoc, Point* maxLoc, Mat mask);\nvoid Mat_MixChannels(struct Mats src, struct Mats dst, struct IntVector fromTo);\nvoid Mat_MulSpectrums(Mat a, Mat b, Mat c, int flags);\nvoid Mat_Multiply(Mat src1, Mat src2, Mat dst);\nvoid Mat_MultiplyWithParams(Mat src1, Mat src2, Mat dst, double scale, int dtype);\nvoid Mat_Subtract(Mat src1, Mat src2, Mat dst);\nvoid Mat_Normalize(Mat src, Mat dst, double alpha, double beta, int typ);\ndouble Norm(Mat src1, int normType);\ndouble NormWithMats(Mat src1, Mat src2, int normType);\nvoid Mat_PerspectiveTransform(Mat src, Mat dst, Mat tm);\nbool Mat_Solve(Mat src1, Mat src2, Mat dst, int flags);\nint Mat_SolveCubic(Mat coeffs, Mat roots);\ndouble Mat_SolvePoly(Mat coeffs, Mat roots, int maxIters);\nvoid Mat_Reduce(Mat src, Mat dst, int dim, int rType, int dType);\nvoid Mat_ReduceArgMax(Mat src, Mat dst, int axis, bool lastIndex);\nvoid Mat_ReduceArgMin(Mat src, Mat dst, int axis, bool lastIndex);\nvoid Mat_Repeat(Mat src, int nY, int nX, Mat dst);\nvoid Mat_ScaleAdd(Mat src1, double alpha, Mat src2, Mat dst);\nvoid Mat_SetIdentity(Mat src, double scalar);\nvoid Mat_Sort(Mat src, Mat dst, int flags);\nvoid Mat_SortIdx(Mat src, Mat dst, int flags);\nvoid Mat_Split(Mat src, struct Mats* mats);\nvoid Mat_Subtract(Mat src1, Mat src2, Mat dst);\nScalar Mat_Trace(Mat src);\nvoid Mat_Transform(Mat src, Mat dst, Mat tm);\nvoid Mat_Transpose(Mat src, Mat dst);\nvoid Mat_TransposeND(Mat src, struct IntVector order, Mat dst);\nvoid Mat_PolarToCart(Mat magnitude, Mat degree, Mat x, Mat y, bool angleInDegrees);\nvoid Mat_Pow(Mat src, double power, Mat dst);\nvoid Mat_Phase(Mat x, Mat y, Mat angle, bool angleInDegrees);\nScalar Mat_Sum(Mat src1);\n\nTermCriteria TermCriteria_New(int typ, int maxCount, double epsilon);\n\nint64_t GetCVTickCount();\ndouble GetTickFrequency();\n\nMat Mat_rowRange(Mat m,int startrow,int endrow);\nMat Mat_colRange(Mat m,int startrow,int endrow);\n\nPointVector PointVector_New();\nPointVector PointVector_NewFromPoints(Contour points);\nPointVector PointVector_NewFromMat(Mat mat);\nPoint PointVector_At(PointVector pv, int idx);\nvoid PointVector_Append(PointVector pv, Point p);\nint PointVector_Size(PointVector pv);\nvoid PointVector_Close(PointVector pv);\n\nPointsVector PointsVector_New();\nPointsVector PointsVector_NewFromPoints(Contours points);\nPointVector PointsVector_At(PointsVector psv, int idx);\nvoid PointsVector_Append(PointsVector psv, PointVector pv);\nint PointsVector_Size(PointsVector psv);\nvoid PointsVector_Close(PointsVector psv);\n\nPoint2fVector Point2fVector_New();\nvoid Point2fVector_Close(Point2fVector pfv);\nPoint2fVector Point2fVector_NewFromPoints(Contour2f pts);\nPoint2fVector Point2fVector_NewFromMat(Mat mat);\nPoint2f Point2fVector_At(Point2fVector pfv, int idx);\nint Point2fVector_Size(Point2fVector pfv);\n\nvoid IntVector_Close(struct IntVector ivec);\n\nvoid CStrings_Close(struct CStrings cstrs);\n\nRNG TheRNG();\n\nvoid SetRNGSeed(int seed);\n\nvoid RNG_Fill(RNG rng, Mat mat, int distType, double a, double b, bool saturateRange);\n\ndouble RNG_Gaussian(RNG rng, double sigma);\n\nunsigned int RNG_Next(RNG rng);\n\nvoid RandN(Mat mat, Scalar mean, Scalar stddev);\n\nvoid RandShuffle(Mat mat);\n\nvoid RandShuffleWithParams(Mat mat, double iterFactor, RNG rng);\n\nvoid RandU(Mat mat, Scalar low, Scalar high);\n\nvoid copyPointVectorToPoint2fVector(PointVector src, Point2fVector dest);\n\nvoid StdByteVectorInitialize(void* data);\nvoid StdByteVectorFree(void *data);\nsize_t StdByteVectorLen(void *data);\nuint8_t* StdByteVectorData(void *data);\n\nPoints2fVector Points2fVector_New();\nPoints2fVector Points2fVector_NewFromPoints(Contours2f points);\nint Points2fVector_Size(Points2fVector ps);\nPoint2fVector Points2fVector_At(Points2fVector ps, int idx);\nvoid Points2fVector_Append(Points2fVector psv, Point2fVector pv);\nvoid Points2fVector_Close(Points2fVector ps);\n\nPoint3fVector Point3fVector_New();\nPoint3fVector Point3fVector_NewFromPoints(Contour3f points);\nPoint3fVector Point3fVector_NewFromMat(Mat mat);\nvoid Point3fVector_Append(Point3fVector pfv, Point3f point);\nPoint3f Point3fVector_At(Point3fVector pfv, int idx);\nint Point3fVector_Size(Point3fVector pfv);\nvoid Point3fVector_Close(Point3fVector pv);\nPoints3fVector Points3fVector_New();\nPoints3fVector Points3fVector_NewFromPoints(Contours3f points);\nint Points3fVector_Size(Points3fVector ps);\nPoint3fVector Points3fVector_At(Points3fVector ps, int idx);\nvoid Points3fVector_Append(Points3fVector psv, Point3fVector pv);\nvoid Points3fVector_Close(Points3fVector ps);\n\nvoid SetNumThreads(int n);\nint GetNumThreads();\n\n\nstruct RotatedRect RotatedRect_Create(struct Point2f center, int width, int height, float angle);\nstruct RotatedRect2f RotatedRect2f_Create(struct Point2f center, float width, float height, float angle);\n\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif //_OPENCV3_CORE_H_\n"
        },
        {
          "name": "core_string.go",
          "type": "blob",
          "size": 3.8095703125,
          "content": "package gocv\n\nfunc (c MatType) String() string {\n\tswitch c {\n\tcase MatTypeCV8U:\n\t\treturn \"CV8U\"\n\tcase MatTypeCV8UC2:\n\t\treturn \"CV8UC2\"\n\tcase MatTypeCV8UC3:\n\t\treturn \"CV8UC3\"\n\tcase MatTypeCV8UC4:\n\t\treturn \"CV8UC4\"\n\tcase MatTypeCV16U:\n\t\treturn \"CV16U\"\n\tcase MatTypeCV16UC2:\n\t\treturn \"CV16UC2\"\n\tcase MatTypeCV16UC3:\n\t\treturn \"CV16UC3\"\n\tcase MatTypeCV16UC4:\n\t\treturn \"CV16UC4\"\n\tcase MatTypeCV16S:\n\t\treturn \"CV16S\"\n\tcase MatTypeCV16SC2:\n\t\treturn \"CV16SC2\"\n\tcase MatTypeCV16SC3:\n\t\treturn \"CV16SC3\"\n\tcase MatTypeCV16SC4:\n\t\treturn \"CV16SC4\"\n\tcase MatTypeCV32S:\n\t\treturn \"CV32S\"\n\tcase MatTypeCV32SC2:\n\t\treturn \"CV32SC2\"\n\tcase MatTypeCV32SC3:\n\t\treturn \"CV32SC3\"\n\tcase MatTypeCV32SC4:\n\t\treturn \"CV32SC4\"\n\tcase MatTypeCV32F:\n\t\treturn \"CV32F\"\n\tcase MatTypeCV32FC2:\n\t\treturn \"CV32FC2\"\n\tcase MatTypeCV32FC3:\n\t\treturn \"CV32FC3\"\n\tcase MatTypeCV32FC4:\n\t\treturn \"CV32FC4\"\n\tcase MatTypeCV64F:\n\t\treturn \"CV64F\"\n\tcase MatTypeCV64FC2:\n\t\treturn \"CV64FC2\"\n\tcase MatTypeCV64FC3:\n\t\treturn \"CV64FC3\"\n\tcase MatTypeCV64FC4:\n\t\treturn \"CV64FC4\"\n\t}\n\treturn \"\"\n}\n\nfunc (c CompareType) String() string {\n\tswitch c {\n\tcase CompareEQ:\n\t\treturn \"eq\"\n\tcase CompareGT:\n\t\treturn \"gt\"\n\tcase CompareGE:\n\t\treturn \"ge\"\n\tcase CompareLT:\n\t\treturn \"lt\"\n\tcase CompareLE:\n\t\treturn \"le\"\n\tcase CompareNE:\n\t\treturn \"ne\"\n\t}\n\treturn \"\"\n}\n\nfunc (c CovarFlags) String() string {\n\tswitch c {\n\tcase CovarScrambled:\n\t\treturn \"covar-scrambled\"\n\tcase CovarNormal:\n\t\treturn \"covar-normal\"\n\tcase CovarUseAvg:\n\t\treturn \"covar-use-avg\"\n\tcase CovarScale:\n\t\treturn \"covar-scale\"\n\tcase CovarRows:\n\t\treturn \"covar-rows\"\n\tcase CovarCols:\n\t\treturn \"covar-cols\"\n\t}\n\treturn \"\"\n}\n\nfunc (c DftFlags) String() string {\n\tswitch c {\n\tcase DftForward:\n\t\treturn \"dft-forward\"\n\tcase DftInverse:\n\t\treturn \"dft-inverse\"\n\tcase DftScale:\n\t\treturn \"dft-scale\"\n\tcase DftRows:\n\t\treturn \"dft-rows\"\n\tcase DftComplexOutput:\n\t\treturn \"dft-complex-output\"\n\tcase DftRealOutput:\n\t\treturn \"dft-real-output\"\n\tcase DftComplexInput:\n\t\treturn \"dft-complex-input\"\n\t}\n\treturn \"\"\n}\n\nfunc (c RotateFlag) String() string {\n\tswitch c {\n\tcase Rotate90Clockwise:\n\t\treturn \"rotate-90-clockwise\"\n\tcase Rotate180Clockwise:\n\t\treturn \"rotate-180-clockwise\"\n\tcase Rotate90CounterClockwise:\n\t\treturn \"rotate-90-counter-clockwise\"\n\t}\n\treturn \"\"\n}\n\nfunc (c KMeansFlags) String() string {\n\tswitch c {\n\tcase KMeansRandomCenters:\n\t\treturn \"kmeans-random-centers\"\n\tcase KMeansPPCenters:\n\t\treturn \"kmeans-pp-centers\"\n\tcase KMeansUseInitialLabels:\n\t\treturn \"kmeans-use-initial-labels\"\n\t}\n\treturn \"\"\n}\n\nfunc (c NormType) String() string {\n\tswitch c {\n\tcase NormInf:\n\t\treturn \"norm-inf\"\n\tcase NormL1:\n\t\treturn \"norm-l1\"\n\tcase NormL2:\n\t\treturn \"norm-l2\"\n\tcase NormL2Sqr:\n\t\treturn \"norm-l2-sqr\"\n\tcase NormHamming:\n\t\treturn \"norm-hamming\"\n\tcase NormHamming2:\n\t\treturn \"norm-hamming2\"\n\tcase NormRelative:\n\t\treturn \"norm-relative\"\n\tcase NormMinMax:\n\t\treturn \"norm-minmax\"\n\t}\n\treturn \"\"\n}\n\nfunc (c TermCriteriaType) String() string {\n\tswitch c {\n\tcase Count:\n\t\treturn \"count\"\n\tcase EPS:\n\t\treturn \"eps\"\n\t}\n\treturn \"\"\n}\n\nfunc (c SolveDecompositionFlags) String() string {\n\tswitch c {\n\tcase SolveDecompositionLu:\n\t\treturn \"solve-decomposition-lu\"\n\tcase SolveDecompositionSvd:\n\t\treturn \"solve-decomposition-svd\"\n\tcase SolveDecompositionEing:\n\t\treturn \"solve-decomposition-eing\"\n\tcase SolveDecompositionCholesky:\n\t\treturn \"solve-decomposition-cholesky\"\n\tcase SolveDecompositionQr:\n\t\treturn \"solve-decomposition-qr\"\n\tcase SolveDecompositionNormal:\n\t\treturn \"solve-decomposition-normal\"\n\t}\n\treturn \"\"\n}\n\nfunc (c ReduceTypes) String() string {\n\tswitch c {\n\tcase ReduceSum:\n\t\treturn \"reduce-sum\"\n\tcase ReduceAvg:\n\t\treturn \"reduce-avg\"\n\tcase ReduceMax:\n\t\treturn \"reduce-max\"\n\tcase ReduceMin:\n\t\treturn \"reduce-min\"\n\t}\n\treturn \"\"\n}\n\nfunc (c SortFlags) String() string {\n\tswitch c {\n\tcase SortEveryRow:\n\t\treturn \"sort-every-row\"\n\tcase SortEveryColumn:\n\t\treturn \"sort-every-column\"\n\tcase SortDescending:\n\t\treturn \"sort-descending\"\n\t}\n\treturn \"\"\n}\n"
        },
        {
          "name": "core_test.go",
          "type": "blob",
          "size": 78.9091796875,
          "content": "package gocv\n\nimport (\n\t\"bytes\"\n\t\"image\"\n\t\"image/color\"\n\t_ \"image/jpeg\"\n\t_ \"image/png\"\n\t\"runtime\"\n\t\"strings\"\n\t\"testing\"\n)\n\nfunc TestMat(t *testing.T) {\n\tmat := NewMat()\n\tdefer mat.Close()\n\tif !mat.Empty() {\n\t\tt.Error(\"New Mat should be empty\")\n\t}\n}\n\nfunc TestMatClosed(t *testing.T) {\n\tmat := NewMat()\n\tmat.Close()\n\tif !mat.Closed() {\n\t\tt.Error(\"Closed Mat should be closed\")\n\t}\n}\n\nfunc TestMatWithSizes(t *testing.T) {\n\tt.Run(\"create mat with multidimensional array\", func(t *testing.T) {\n\t\tsizes := []int{100, 100, 100}\n\t\tmat := NewMatWithSizes(sizes, MatTypeCV8U)\n\t\tdefer mat.Close()\n\t\tif mat.Empty() {\n\t\t\tt.Error(\"NewMatWithSizes should not be empty\")\n\t\t}\n\n\t\tfor i, val := range mat.Size() {\n\t\t\tif val != sizes[i] {\n\t\t\t\tt.Errorf(\"NewMatWithSizes incorrect size: %v\\n\", mat.Size())\n\t\t\t}\n\t\t}\n\n\t\tif mat.Rows() != -1 {\n\t\t\tt.Errorf(\"NewMatWithSizes incorrect row count: %v\\n\", mat.Rows())\n\t\t}\n\n\t\tif mat.Cols() != -1 {\n\t\t\tt.Errorf(\"NewMatWithSizes incorrect col count: %v\\n\", mat.Cols())\n\t\t}\n\n\t\tif mat.Channels() != 1 {\n\t\t\tt.Errorf(\"NewMatWithSizes incorrect channels count: %v\\n\", mat.Channels())\n\t\t}\n\n\t\tif mat.Type() != MatTypeCV8U {\n\t\t\tt.Errorf(\"NewMatWithSizes incorrect type: %v\\n\", mat.Type())\n\t\t}\n\n\t\tif mat.Total() != 100*100*100 {\n\t\t\tt.Errorf(\"NewMatWithSizes incorrect total: %v\\n\", mat.Total())\n\t\t}\n\t})\n\n\tt.Run(\"create 2x3x3 multidimensional array with 3 channels and scalar\", func(t *testing.T) {\n\t\tsizes := []int{2, 3, 3}\n\t\ts := NewScalar(255.0, 105.0, 180.0, 0.0)\n\t\tmat := NewMatWithSizesWithScalar(sizes, MatTypeCV32FC3, s)\n\t\tdefer mat.Close()\n\t\tif mat.Empty() {\n\t\t\tt.Error(\"NewMatWithSizesWithScalar should not be empty\")\n\t\t}\n\n\t\tfor i, val := range mat.Size() {\n\t\t\tif val != sizes[i] {\n\t\t\t\tt.Errorf(\"NewMatWithSizesWithScalar incorrect size: %v\\n\", mat.Size())\n\t\t\t}\n\t\t}\n\n\t\tif mat.Rows() != -1 {\n\t\t\tt.Errorf(\"NewMatWithSizesWithScalar incorrect row count: %v\\n\", mat.Rows())\n\t\t}\n\n\t\tif mat.Cols() != -1 {\n\t\t\tt.Errorf(\"NewMatWithSizesWithScalar incorrect col count: %v\\n\", mat.Cols())\n\t\t}\n\n\t\tif mat.Channels() != 3 {\n\t\t\tt.Errorf(\"NewMatWithSizesWithScalar incorrect channels count: %v\\n\", mat.Channels())\n\t\t}\n\n\t\tif mat.Type() != MatTypeCV32FC3 {\n\t\t\tt.Errorf(\"NewMatWithSizesWithScalar incorrect type: %v\\n\", mat.Type())\n\t\t}\n\n\t\tif mat.Total() != 2*3*3 {\n\t\t\tt.Errorf(\"NewMatWithSizesWithScalar incorrect total: %v\\n\", mat.Total())\n\t\t}\n\n\t\tmatChans := Split(mat)\n\t\tscalar := []float32{255.0, 105.0, 180.0}\n\t\tfor c := 0; c < mat.Channels(); c++ {\n\t\t\tfor x := 0; x < sizes[0]; x++ {\n\t\t\t\tfor y := 0; y < sizes[1]; y++ {\n\t\t\t\t\tfor z := 0; z < sizes[2]; z++ {\n\t\t\t\t\t\tif s := matChans[c].GetFloatAt3(x, y, z); s != scalar[c] {\n\t\t\t\t\t\t\tt.Errorf(\"NewMatWithSizesWithScalar incorrect scalar: %v\\n\", s)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor _, ch := range matChans {\n\t\t\tch.Close()\n\t\t}\n\t})\n\n\tt.Run(\"create 1x2x3 multidimensional array with 3 channel and data\", func(t *testing.T) {\n\t\tsizes := []int{1, 2, 3}\n\n\t\t// generate byte array\n\t\ts := NewScalar(255.0, 123.0, 55.0, 0.0)\n\t\tmat1 := NewMatWithSizesWithScalar(sizes, MatTypeCV32FC2, s)\n\t\tdefer mat1.Close()\n\t\tb := mat1.ToBytes()\n\n\t\tmat, err := NewMatWithSizesFromBytes(sizes, MatTypeCV32FC2, b)\n\t\tdefer mat.Close()\n\t\tif err != nil {\n\t\t\tt.Errorf(\"NewMatWithSizesFromBytes %v\\n\", err)\n\t\t}\n\t\tif mat.Empty() {\n\t\t\tt.Error(\"NewMatWithSizesFromBytes should not be empty\")\n\t\t}\n\n\t\tmat2, err := NewMatWithSizesFromBytes(sizes, MatTypeCV32FC2, nil)\n\t\tdefer mat2.Close()\n\t\tif err == nil {\n\t\t\tt.Error(\"NewMatWithSizesFromBytes should return error with empty bytes\")\n\t\t}\n\n\t\tb1 := mat.ToBytes()\n\t\tif !bytes.Equal(b, b1) {\n\t\t\tt.Error(\"NewMatWithSizesFromBytes byte arrays not equal\")\n\t\t}\n\n\t\tfor i, val := range mat.Size() {\n\t\t\tif val != sizes[i] {\n\t\t\t\tt.Errorf(\"NewMatWithSizesFromBytes incorrect size: %v\\n\", mat.Size())\n\t\t\t}\n\t\t}\n\n\t\tif mat.Rows() != -1 {\n\t\t\tt.Errorf(\"NewMatWithSizesFromBytes incorrect row count: %v\\n\", mat.Rows())\n\t\t}\n\n\t\tif mat.Cols() != -1 {\n\t\t\tt.Errorf(\"NewMatWithSizesFromBytes incorrect col count: %v\\n\", mat.Cols())\n\t\t}\n\n\t\tif mat.Channels() != 2 {\n\t\t\tt.Errorf(\"NewMatWithSizesFromBytes incorrect channels count: %v\\n\", mat.Channels())\n\t\t}\n\n\t\tif mat.Type() != MatTypeCV32FC2 {\n\t\t\tt.Errorf(\"NewMatWithSizesFromBytes incorrect type: %v\\n\", mat.Type())\n\t\t}\n\n\t\tif mat.Total() != 1*2*3 {\n\t\t\tt.Errorf(\"NewMatWithSizesFromBytes incorrect total: %v\\n\", mat.Total())\n\t\t}\n\n\t\tmatChans := Split(mat)\n\t\tscalar := []float32{255.0, 123.0, 55.0}\n\t\tfor c := 0; c < mat.Channels(); c++ {\n\t\t\tfor x := 0; x < sizes[0]; x++ {\n\t\t\t\tfor y := 0; y < sizes[1]; y++ {\n\t\t\t\t\tfor z := 0; z < sizes[2]; z++ {\n\t\t\t\t\t\tif s := matChans[c].GetFloatAt3(x, y, z); s != scalar[c] {\n\t\t\t\t\t\t\tt.Errorf(\"NewMatWithSizesFromBytes incorrect value: %v\\n\", s)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor _, ch := range matChans {\n\t\t\tch.Close()\n\t\t}\n\t})\n}\n\nfunc TestMatFromBytesWithEmptyByteSlice(t *testing.T) {\n\t_, err := NewMatFromBytes(600, 800, MatTypeCV8U, []byte{})\n\tif err == nil {\n\t\tt.Error(\"TestMatFromBytesWithEmptyByteSlise: \" +\n\t\t\t\"must fail because of an empty byte slice\")\n\t}\n\tif !strings.Contains(err.Error(), ErrEmptyByteSlice.Error()) {\n\t\tt.Errorf(\"TestMatFromBytesWithEmptyByteSlice: \"+\n\t\t\t\"error must contain the following description: \"+\n\t\t\t\"%v, but have: %v\", ErrEmptyByteSlice, err)\n\t}\n}\n\nfunc TestMatFromBytesSliceGarbageCollected(t *testing.T) {\n\tdata := []byte{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n\tm, err := NewMatFromBytes(2, 5, MatTypeCV8U, data)\n\tif err != nil {\n\t\tt.Error(\"TestMatFromBytesSliceGarbageCollected: \" +\n\t\t\t\"failed to create Mat\")\n\t}\n\tdefer m.Close()\n\n\t// Force garbage collection. As data is not used after this, its backing array should\n\t// be collected.\n\truntime.GC()\n\n\tv := m.GetUCharAt(0, 0)\n\tif v != 0 {\n\t\tt.Errorf(\"TestMatFromBytesSliceGarbageCollected: \"+\n\t\t\t\"unexpected value. Want %d, got %d.\", 0, v)\n\t}\n}\n\nfunc TestMatWithSize(t *testing.T) {\n\tmat := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat.Close()\n\tif mat.Empty() {\n\t\tt.Error(\"NewMatWithSize should not be empty\")\n\t}\n\n\tif mat.Rows() != 101 {\n\t\tt.Errorf(\"NewMatWithSize incorrect row count: %v\\n\", mat.Rows())\n\t}\n\n\tif mat.Cols() != 102 {\n\t\tt.Errorf(\"NewMatWithSize incorrect col count: %v\\n\", mat.Cols())\n\t}\n\n\tif mat.Channels() != 1 {\n\t\tt.Errorf(\"NewMatWithSize incorrect channels count: %v\\n\", mat.Channels())\n\t}\n\n\tif mat.Type() != 0 {\n\t\tt.Errorf(\"NewMatWithSize incorrect type: %v\\n\", mat.Type())\n\t}\n\n\tif mat.Step() != 102 {\n\t\tt.Errorf(\"NewMatWithSize incorrect step count: %v\\n\", mat.Step())\n\t}\n}\n\nfunc TestMatWithSizeFromScalar(t *testing.T) {\n\ts := NewScalar(255.0, 105.0, 180.0, 0.0)\n\tmat := NewMatWithSizeFromScalar(s, 2, 3, MatTypeCV8UC3)\n\tdefer mat.Close()\n\tif mat.Empty() {\n\t\tt.Error(\"NewMatWithSizeFromScalar should not be empty\")\n\t}\n\n\tif mat.Rows() != 2 {\n\t\tt.Errorf(\"NewMatWithSizeFromScalar incorrect row count: %v\\n\", mat.Rows())\n\t}\n\n\tif mat.Cols() != 3 {\n\t\tt.Errorf(\"NewMatWithSizeFromScalar incorrect col count: %v\\n\", mat.Cols())\n\t}\n\n\tif mat.Channels() != 3 {\n\t\tt.Errorf(\"NewMatWithSizeFromScalar incorrect channels count: %v\\n\", mat.Channels())\n\t}\n\n\tif mat.Type() != 16 {\n\t\tt.Errorf(\"NewMatWithSizeFromScalar incorrect type: %v\\n\", mat.Type())\n\t}\n\n\tif mat.Total() != 6 {\n\t\tt.Errorf(\"incorrect total: %v\\n\", mat.Total())\n\t}\n\n\tif mat.Step() != 9 {\n\t\tt.Errorf(\"NewMatWithSizeFromScalar incorrect step count: %v\\n\", mat.Step())\n\t}\n\n\tsz := mat.Size()\n\tif sz[0] != 2 && sz[1] != 3 {\n\t\tt.Errorf(\"NewMatWithSize incorrect size: %v\\n\", sz)\n\t}\n\n\tmatChans := Split(mat)\n\tscalarByte := []byte{255, 105, 180}\n\tfor c := 0; c < mat.Channels(); c++ {\n\t\tfor i := 0; i < mat.Rows(); i++ {\n\t\t\tfor j := 0; j < mat.Cols(); j++ {\n\t\t\t\tif s := matChans[c].GetUCharAt(i, j); s != scalarByte[c] {\n\t\t\t\t\tt.Errorf(\"NewMatWithSizeFromScalar incorrect scalar: %v\\n\", s)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor _, i := range matChans {\n\t\ti.Close()\n\t}\n}\n\nfunc TestMatFromPtr(t *testing.T) {\n\tmat := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat.Close()\n\tpmat, _ := mat.FromPtr(11, 12, MatTypeCV8U, 10, 10)\n\tdefer pmat.Close()\n\n\tif pmat.Rows() != 11 {\n\t\tt.Errorf(\"Mat copy incorrect row count: %v\\n\", pmat.Rows())\n\t}\n\n\tif pmat.Cols() != 12 {\n\t\tt.Errorf(\"Mat copy incorrect col count: %v\\n\", pmat.Cols())\n\t}\n}\n\nfunc TestMatClone(t *testing.T) {\n\tmat := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat.Close()\n\tclone := mat.Clone()\n\tdefer clone.Close()\n\tif clone.Rows() != 101 {\n\t\tt.Errorf(\"Mat clone incorrect row count: %v\\n\", clone.Rows())\n\t}\n\n\tif clone.Cols() != 102 {\n\t\tt.Errorf(\"Mat clone incorrect col count: %v\\n\", clone.Cols())\n\t}\n}\n\nfunc TestMatCopyTo(t *testing.T) {\n\tmat := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat.Close()\n\tcopy := NewMat()\n\tdefer copy.Close()\n\n\tmat.CopyTo(&copy)\n\tif copy.Rows() != 101 {\n\t\tt.Errorf(\"Mat copy incorrect row count: %v\\n\", copy.Rows())\n\t}\n\n\tif copy.Cols() != 102 {\n\t\tt.Errorf(\"Mat copy incorrect col count: %v\\n\", copy.Cols())\n\t}\n}\n\nfunc TestMatCopyToWithMask(t *testing.T) {\n\tmat := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat.Close()\n\tmask := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mask.Close()\n\tdiff := NewMat()\n\tdefer diff.Close()\n\n\tmat.SetUCharAt(0, 0, 255)\n\tmat.SetUCharAt(0, 1, 255)\n\n\tmask.SetUCharAt(0, 0, 255)\n\n\tcopy := NewMat()\n\tdefer copy.Close()\n\n\tmat.CopyToWithMask(&copy, mask)\n\tif copy.Rows() != 101 {\n\t\tt.Errorf(\"Mat copy incorrect row count: %v\\n\", copy.Rows())\n\t}\n\n\tif copy.Cols() != 102 {\n\t\tt.Errorf(\"Mat copy incorrect col count: %v\\n\", copy.Cols())\n\t}\n\n\tif copy.GetUCharAt(0, 0) != 255 || copy.GetUCharAt(0, 1) != 0 {\n\t\tt.Errorf(\"Mask failed to apply to source image\")\n\t}\n\n\tCompare(mat, copy, &diff, CompareEQ)\n\tif CountNonZero(diff) == 0 {\n\t\tt.Errorf(\"Mat CopyToWithMask incorrect diff: %v\\n\", CountNonZero(diff))\n\t}\n}\n\nfunc TestMatToBytes(t *testing.T) {\n\tmat1 := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat1.Close()\n\tb := mat1.ToBytes()\n\tif len(b) != 101*102 {\n\t\tt.Errorf(\"Mat bytes incorrect length: %v\\n\", len(b))\n\t}\n\n\tcopy, err := NewMatFromBytes(101, 102, MatTypeCV8U, b)\n\tif err != nil {\n\t\tt.Error(err.Error())\n\t}\n\tdefer copy.Close()\n\tif copy.Rows() != 101 {\n\t\tt.Errorf(\"Mat from bytes incorrect row count: %v\\n\", copy.Rows())\n\t}\n\tif copy.Cols() != 102 {\n\t\tt.Errorf(\"Mat region incorrect col count: %v\\n\", copy.Cols())\n\t}\n\n\tmat2 := NewMatWithSize(101, 102, MatTypeCV16S)\n\tdefer mat2.Close()\n\tb = mat2.ToBytes()\n\tif len(b) != 101*102*2 {\n\t\tt.Errorf(\"Mat bytes incorrect length: %v\\n\", len(b))\n\t}\n\n\tmat3 := NewMatFromScalar(NewScalar(255.0, 105.0, 180.0, 0.0), MatTypeCV8UC3)\n\tdefer mat3.Close()\n\tb = mat3.ToBytes()\n\tif len(b) != 3 {\n\t\tt.Errorf(\"Mat bytes incorrect length: %v\\n\", len(b))\n\t}\n\tif bytes.Compare(b, []byte{255, 105, 180}) != 0 {\n\t\tt.Errorf(\"Mat bytes unexpected values: %v\\n\", b)\n\t}\n}\n\nfunc TestMatEye(t *testing.T) {\n\tdata := []byte{1, 0, 0, 1}\n\te := Eye(2, 2, MatTypeCV8U)\n\n\tif bytes.Compare(e.ToBytes(), data) != 0 {\n\t\tt.Errorf(\"Mat bytes are not equal\")\n\t}\n\te.Close()\n\n\tdata2 := []byte{1, 0, 0, 0, 1, 0}\n\te2 := Eye(2, 3, MatTypeCV8U)\n\tif bytes.Compare(e2.ToBytes(), data2) != 0 {\n\t\tt.Errorf(\"Mat bytes are not equal\")\n\t}\n\n\tval := e2.GetUCharAt(0, 2)\n\tif val != 0 {\n\t\tt.Errorf(\"Mat bytes unexpected value at [0,2]: %v\\n\", val)\n\t}\n\te2.Close()\n}\n\nfunc TestMatZeros(t *testing.T) {\n\texpected := NewMatWithSize(2, 3, MatTypeCV8U)\n\tz := Zeros(2, 3, MatTypeCV8U)\n\n\tif bytes.Compare(z.ToBytes(), expected.ToBytes()) != 0 {\n\t\tt.Errorf(\"Mat bytes are not equal\")\n\t}\n\n\texpected.Close()\n\tz.Close()\n\n\texpected2 := NewMatWithSize(2, 3, MatTypeCV64F)\n\tz2 := Zeros(2, 3, MatTypeCV64F)\n\n\tif bytes.Compare(z2.ToBytes(), expected2.ToBytes()) != 0 {\n\t\tt.Errorf(\"Mat bytes are not equal\")\n\t}\n\texpected2.Close()\n\tz2.Close()\n}\n\nfunc TestMatOnes(t *testing.T) {\n\texpected := NewMatWithSizeFromScalar(Scalar{Val1: 1}, 2, 3, MatTypeCV8U)\n\to := Ones(2, 3, MatTypeCV8U)\n\tif bytes.Compare(o.ToBytes(), expected.ToBytes()) != 0 {\n\t\tt.Errorf(\"Mat bytes are not equal\")\n\t}\n\tdefer expected.Close()\n\tdefer o.Close()\n\n\texpected2 := NewMatWithSizeFromScalar(Scalar{Val1: 1}, 2, 1, MatTypeCV64F)\n\to2 := Ones(2, 1, MatTypeCV64F)\n\n\tif bytes.Compare(o2.ToBytes(), expected2.ToBytes()) != 0 {\n\t\tt.Errorf(\"Mat bytes are not equal\")\n\t}\n\texpected2.Close()\n\to2.Close()\n}\n\nfunc TestMatDataPtr(t *testing.T) {\n\tconst (\n\t\trows = 101\n\t\tcols = 102\n\t)\n\tt.Run(\"Uint8\", func(t *testing.T) {\n\t\ttestPoints := []struct {\n\t\t\trow int\n\t\t\tcol int\n\t\t\tval uint8\n\t\t}{\n\t\t\t{row: 0, col: 0, val: 10},\n\t\t\t{row: 30, col: 31, val: 20},\n\t\t\t{row: rows - 1, col: cols - 1, val: 30},\n\t\t}\n\n\t\tmat1 := NewMatWithSize(rows, cols, MatTypeCV8U)\n\t\tdefer mat1.Close()\n\n\t\tb, err := mat1.DataPtrUint8()\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\t\tif len(b) != 101*102 {\n\t\t\tt.Errorf(\"Mat bytes incorrect length: %v\\n\", len(b))\n\t\t}\n\n\t\tfor _, p := range testPoints {\n\t\t\tmat1.SetUCharAt(p.row, p.col, p.val)\n\n\t\t\tif got := b[p.row*cols+p.col]; got != p.val {\n\t\t\t\tt.Errorf(\"Expected %d,%d = %d, but it was %d\", p.row, p.col, p.val, got)\n\t\t\t}\n\t\t}\n\n\t\tmat2 := NewMatWithSize(3, 9, MatTypeCV32F)\n\t\tdefer mat2.Close()\n\t\tb, err = mat2.DataPtrUint8()\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\t\tif len(b) != 3*9*4 {\n\t\t\tt.Errorf(\"Mat bytes incorrect length: %v\\n\", len(b))\n\t\t}\n\n\t\tmat3 := mat1.Region(image.Rect(25, 25, 75, 75))\n\t\tdefer mat3.Close()\n\t\t_, err = mat3.DataPtrUint8()\n\t\tif err == nil {\n\t\t\tt.Errorf(\"Expected error.\")\n\t\t}\n\t})\n\tt.Run(\"Int8\", func(t *testing.T) {\n\t\ttestPoints := []struct {\n\t\t\trow int\n\t\t\tcol int\n\t\t\tval int8\n\t\t}{\n\t\t\t{row: 0, col: 0, val: 10},\n\t\t\t{row: 30, col: 31, val: 20},\n\t\t\t{row: rows - 1, col: cols - 1, val: 30},\n\t\t}\n\n\t\tmat1 := NewMatWithSize(101, 102, MatTypeCV8S)\n\t\tdefer mat1.Close()\n\n\t\tb, err := mat1.DataPtrInt8()\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\n\t\tif len(b) != rows*cols {\n\t\t\tt.Errorf(\"Mat bytes incorrect length: %v\\n\", len(b))\n\t\t}\n\n\t\tfor _, p := range testPoints {\n\t\t\tmat1.SetSCharAt(p.row, p.col, p.val)\n\n\t\t\tif got := b[p.row*cols+p.col]; got != p.val {\n\t\t\t\tt.Errorf(\"Expected %d,%d = %d, but it was %d\", p.row, p.col, p.val, got)\n\t\t\t}\n\t\t}\n\n\t\tmat2 := NewMatWithSize(3, 9, MatTypeCV32F)\n\t\tdefer mat2.Close()\n\t\tb, err = mat2.DataPtrInt8()\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\t\tif len(b) != 3*9*4 {\n\t\t\tt.Errorf(\"Mat bytes incorrect length: %v\\n\", len(b))\n\t\t}\n\n\t\tmat3 := mat1.Region(image.Rect(25, 25, 75, 75))\n\t\tdefer mat3.Close()\n\t\t_, err = mat3.DataPtrInt8()\n\t\tif err == nil {\n\t\t\tt.Errorf(\"Expected error.\")\n\t\t}\n\t})\n\tt.Run(\"Uint16\", func(t *testing.T) {\n\t\ttestPoints := []struct {\n\t\t\trow int\n\t\t\tcol int\n\t\t\tval uint16\n\t\t}{\n\t\t\t{row: 0, col: 0, val: 10},\n\t\t\t{row: 30, col: 31, val: 20},\n\t\t\t{row: rows - 1, col: cols - 1, val: 30},\n\t\t}\n\n\t\tmat1 := NewMatWithSize(rows, cols, MatTypeCV16U)\n\t\tdefer mat1.Close()\n\n\t\tb, err := mat1.DataPtrUint16()\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\t\tif len(b) != rows*cols {\n\t\t\tt.Errorf(\"Mat bytes incorrect length: %v\\n\", len(b))\n\t\t}\n\n\t\tfor _, p := range testPoints {\n\t\t\tmat1.SetShortAt(p.row, p.col, int16(p.val))\n\n\t\t\tif got := b[p.row*cols+p.col]; got != p.val {\n\t\t\t\tt.Errorf(\"Expected %d,%d = %d, but it was %d\", p.row, p.col, p.val, got)\n\t\t\t}\n\t\t}\n\n\t\tmat2 := NewMatWithSize(3, 9, MatTypeCV32F)\n\t\tdefer mat2.Close()\n\t\t_, err = mat2.DataPtrUint16()\n\t\tif err == nil {\n\t\t\tt.Errorf(\"Expected error.\")\n\t\t}\n\n\t\tmat3 := mat1.Region(image.Rect(25, 25, 75, 75))\n\t\tdefer mat3.Close()\n\t\t_, err = mat3.DataPtrUint16()\n\t\tif err == nil {\n\t\t\tt.Errorf(\"Expected error.\")\n\t\t}\n\t})\n\tt.Run(\"Int16\", func(t *testing.T) {\n\t\ttestPoints := []struct {\n\t\t\trow int\n\t\t\tcol int\n\t\t\tval int16\n\t\t}{\n\t\t\t{row: 0, col: 0, val: 10},\n\t\t\t{row: 30, col: 31, val: 20},\n\t\t\t{row: rows - 1, col: cols - 1, val: 30},\n\t\t}\n\n\t\tmat1 := NewMatWithSize(rows, cols, MatTypeCV16S)\n\t\tdefer mat1.Close()\n\n\t\tb, err := mat1.DataPtrInt16()\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\t\tif len(b) != rows*cols {\n\t\t\tt.Errorf(\"Mat bytes incorrect length: %v\\n\", len(b))\n\t\t}\n\n\t\tfor _, p := range testPoints {\n\t\t\tmat1.SetShortAt(p.row, p.col, p.val)\n\n\t\t\tif got := b[p.row*cols+p.col]; got != p.val {\n\t\t\t\tt.Errorf(\"Expected %d,%d = %d, but it was %d\", p.row, p.col, p.val, got)\n\t\t\t}\n\t\t}\n\n\t\tmat2 := NewMatWithSize(3, 9, MatTypeCV32F)\n\t\tdefer mat2.Close()\n\t\t_, err = mat2.DataPtrInt16()\n\t\tif err == nil {\n\t\t\tt.Errorf(\"Expected error.\")\n\t\t}\n\n\t\tmat3 := mat1.Region(image.Rect(25, 25, 75, 75))\n\t\tdefer mat3.Close()\n\t\t_, err = mat3.DataPtrInt16()\n\t\tif err == nil {\n\t\t\tt.Errorf(\"Expected error.\")\n\t\t}\n\t})\n\tt.Run(\"Float32\", func(t *testing.T) {\n\t\ttestPoints := []struct {\n\t\t\trow int\n\t\t\tcol int\n\t\t\tval float32\n\t\t}{\n\t\t\t{row: 0, col: 0, val: 10.5},\n\t\t\t{row: 30, col: 31, val: 20.5},\n\t\t\t{row: rows - 1, col: cols - 1, val: 30.5},\n\t\t}\n\n\t\tmat1 := NewMatWithSize(rows, cols, MatTypeCV32F)\n\t\tdefer mat1.Close()\n\n\t\tb, err := mat1.DataPtrFloat32()\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\t\tif len(b) != rows*cols {\n\t\t\tt.Errorf(\"Mat bytes incorrect length: %v\\n\", len(b))\n\t\t}\n\n\t\tfor _, p := range testPoints {\n\t\t\tmat1.SetFloatAt(p.row, p.col, p.val)\n\n\t\t\tif got := b[p.row*cols+p.col]; got != p.val {\n\t\t\t\tt.Errorf(\"Expected %d,%d = %f, but it was %f\", p.row, p.col, p.val, got)\n\t\t\t}\n\t\t}\n\n\t\tmat2 := NewMatWithSize(3, 9, MatTypeCV16S)\n\t\tdefer mat2.Close()\n\t\t_, err = mat2.DataPtrFloat32()\n\t\tif err == nil {\n\t\t\tt.Errorf(\"Expected error.\")\n\t\t}\n\n\t\tmat3 := mat1.Region(image.Rect(25, 25, 75, 75))\n\t\tdefer mat3.Close()\n\t\t_, err = mat3.DataPtrFloat32()\n\t\tif err == nil {\n\t\t\tt.Errorf(\"Expected error.\")\n\t\t}\n\t})\n\tt.Run(\"Float64\", func(t *testing.T) {\n\t\ttestPoints := []struct {\n\t\t\trow int\n\t\t\tcol int\n\t\t\tval float64\n\t\t}{\n\t\t\t{row: 0, col: 0, val: 10.5},\n\t\t\t{row: 30, col: 31, val: 20.5},\n\t\t\t{row: rows - 1, col: cols - 1, val: 30.5},\n\t\t}\n\n\t\tmat1 := NewMatWithSize(rows, cols, MatTypeCV64F)\n\t\tdefer mat1.Close()\n\n\t\tb, err := mat1.DataPtrFloat64()\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\t\tif len(b) != rows*cols {\n\t\t\tt.Errorf(\"Mat bytes incorrect length: %v\\n\", len(b))\n\t\t}\n\n\t\tfor _, p := range testPoints {\n\t\t\tmat1.SetDoubleAt(p.row, p.col, p.val)\n\n\t\t\tif got := b[p.row*cols+p.col]; got != p.val {\n\t\t\t\tt.Errorf(\"Expected %d,%d = %f, but it was %f\", p.row, p.col, p.val, got)\n\t\t\t}\n\t\t}\n\n\t\tmat2 := NewMatWithSize(3, 9, MatTypeCV16S)\n\t\tdefer mat2.Close()\n\t\t_, err = mat2.DataPtrFloat64()\n\t\tif err == nil {\n\t\t\tt.Errorf(\"Expected error.\")\n\t\t}\n\n\t\tmat3 := mat1.Region(image.Rect(25, 25, 75, 75))\n\t\tdefer mat3.Close()\n\t\t_, err = mat3.DataPtrFloat64()\n\t\tif err == nil {\n\t\t\tt.Errorf(\"Expected error.\")\n\t\t}\n\t})\n}\n\nfunc TestMatRegion(t *testing.T) {\n\tmat := NewMatWithSize(100, 100, MatTypeCV8U)\n\tdefer mat.Close()\n\tregion := mat.Region(image.Rect(20, 25, 80, 75))\n\tdefer region.Close()\n\tif region.Rows() != 50 {\n\t\tt.Errorf(\"Mat region incorrect row count: %v\\n\", region.Rows())\n\t}\n\n\tif region.Cols() != 60 {\n\t\tt.Errorf(\"Mat region incorrect col count: %v\\n\", region.Cols())\n\t}\n}\n\nfunc TestMatReshape(t *testing.T) {\n\tmat := NewMatWithSize(100, 100, MatTypeCV8UC4)\n\tdefer mat.Close()\n\n\tr := mat.Reshape(1, 1)\n\tdefer r.Close()\n\tif r.Rows() != 1 {\n\t\tt.Errorf(\"Mat reshape incorrect row count: %v\\n\", r.Rows())\n\t}\n\n\tif r.Cols() != 40000 {\n\t\tt.Errorf(\"Mat reshape incorrect col count: %v\\n\", r.Cols())\n\t}\n}\n\nfunc TestMatPatchNaNs(t *testing.T) {\n\tmat := NewMatWithSize(100, 100, MatTypeCV32F)\n\tdefer mat.Close()\n\n\tmat.PatchNaNs()\n\tif mat.Empty() {\n\t\tt.Error(\"TestMatPatchNaNs error.\")\n\t}\n}\n\nfunc TestMatConvert(t *testing.T) {\n\tsrc := NewMatWithSize(100, 100, MatTypeCV32F)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\tsrc.ConvertTo(&dst, MatTypeCV16S)\n\tif dst.Empty() {\n\t\tt.Error(\"TestConvert dst should not be empty.\")\n\t}\n}\n\nfunc TestMatConvertWithParams(t *testing.T) {\n\tsrc := NewMatWithSize(100, 100, MatTypeCV8U)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\tsrc.ConvertToWithParams(&dst, MatTypeCV32F, 1.0/255.0, 0.0)\n\tif dst.Empty() {\n\t\tt.Error(\"TestConvertWithParams dst should not be empty.\")\n\t}\n}\n\nfunc TestMatConvertFp16(t *testing.T) {\n\tsrc := NewMatWithSize(100, 100, MatTypeCV32F)\n\tdefer src.Close()\n\tdst := src.ConvertFp16()\n\tdefer dst.Close()\n\tif dst.Empty() {\n\t\tt.Error(\"TestConvertFp16 dst should not be empty.\")\n\t}\n}\n\nfunc TestMatSqrt(t *testing.T) {\n\tsrc := NewMatWithSize(100, 100, MatTypeCV32F)\n\tdefer src.Close()\n\n\tdst := src.Sqrt()\n\tdefer dst.Close()\n\tif dst.Empty() {\n\t\tt.Error(\"TestSqrt dst should not be empty.\")\n\t}\n}\n\nfunc TestMatMean(t *testing.T) {\n\tmat := NewMatWithSize(100, 100, MatTypeCV8U)\n\tdefer mat.Close()\n\tmean := mat.Mean()\n\tif mean.Val1 != 0 {\n\t\tt.Errorf(\"Mat Mean incorrect Val1\")\n\t}\n}\n\nfunc TestMatMeanWithMask(t *testing.T) {\n\tmat := NewMatWithSize(100, 100, MatTypeCV8U)\n\tdefer mat.Close()\n\tmask := NewMatWithSize(100, 100, MatTypeCV8U)\n\tdefer mask.Close()\n\tmean := mat.MeanWithMask(mask)\n\tif mean.Val1 != 0 {\n\t\tt.Errorf(\"Mat Mean incorrect Val1\")\n\t}\n}\n\nfunc TestLUT(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadColor)\n\tif src.Empty() {\n\t\tt.Error(\"Invalid read of Source Mat in LUT test\")\n\t}\n\tdefer src.Close()\n\n\tlut := IMRead(\"images/lut.png\", IMReadColor)\n\tif lut.Empty() {\n\t\tt.Error(\"Invalid read of LUT Mat in LUT test\")\n\t}\n\tdefer lut.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tLUT(src, lut, &dst)\n\tif dst.Cols() != 400 || dst.Rows() != 343 {\n\t\tt.Errorf(\"Expected dst size of 200x172 got %dx%d\", dst.Cols(), dst.Rows())\n\t}\n}\n\nfunc TestMatAccessors(t *testing.T) {\n\tmat := NewMatWithSize(101, 102, MatTypeCV8U)\n\tif mat.GetUCharAt(50, 50) != 0 {\n\t\tt.Errorf(\"GetUCharAt incorrect value: %v\\n\", mat.GetUCharAt(50, 50))\n\t}\n\tif mat.GetUCharAt3(50, 50, 0) != 0 {\n\t\tt.Errorf(\"GetUCharAt3 incorrect value: %v\\n\", mat.GetUCharAt3(50, 50, 0))\n\t}\n\tmat.Close()\n\n\tmat = NewMatWithSize(101, 102, MatTypeCV8S)\n\tif mat.GetSCharAt(50, 50) != 0 {\n\t\tt.Errorf(\"GetSCharAt incorrect value: %v\\n\", mat.GetSCharAt(50, 50))\n\t}\n\tif mat.GetSCharAt3(50, 50, 0) != 0 {\n\t\tt.Errorf(\"GetSCharAt3 incorrect value: %v\\n\", mat.GetSCharAt3(50, 50, 0))\n\t}\n\tmat.Close()\n\n\tmat = NewMatWithSize(101, 102, MatTypeCV16S)\n\tif mat.GetShortAt(50, 50) != 0 {\n\t\tt.Errorf(\"GetShortAt incorrect value: %v\\n\", mat.GetShortAt(50, 50))\n\t}\n\tif mat.GetShortAt3(50, 50, 0) != 0 {\n\t\tt.Errorf(\"GetShortAt3 incorrect value: %v\\n\", mat.GetShortAt3(50, 50, 0))\n\t}\n\tmat.Close()\n\n\tmat = NewMatWithSize(101, 102, MatTypeCV32S)\n\tif mat.GetIntAt(50, 50) != 0 {\n\t\tt.Errorf(\"GetIntAt incorrect value: %v\\n\", mat.GetIntAt(50, 50))\n\t}\n\tif mat.GetIntAt3(50, 50, 0) != 0 {\n\t\tt.Errorf(\"GetIntAt3 incorrect value: %v\\n\", mat.GetIntAt3(50, 50, 0))\n\t}\n\tmat.Close()\n\n\tmat = NewMatWithSize(101, 102, MatTypeCV32F)\n\tif mat.GetFloatAt(50, 50) != 0.0 {\n\t\tt.Errorf(\"GetFloatAt incorrect value: %v\\n\", mat.GetFloatAt(50, 50))\n\t}\n\tif mat.GetFloatAt3(50, 50, 0) != 0.0 {\n\t\tt.Errorf(\"GetFloatAt3 incorrect value: %v\\n\", mat.GetFloatAt3(50, 50, 0))\n\t}\n\tmat.Close()\n\n\tmat = NewMatWithSize(101, 102, MatTypeCV64F)\n\tif mat.GetDoubleAt(50, 50) != 0.0 {\n\t\tt.Errorf(\"GetDoubleAt incorrect value: %v\\n\", mat.GetDoubleAt(50, 50))\n\t}\n\tif mat.GetDoubleAt3(50, 50, 0) != 0.0 {\n\t\tt.Errorf(\"GetDoubleAt3 incorrect value: %v\\n\", mat.GetDoubleAt3(50, 50, 0))\n\t}\n\tmat.Close()\n}\n\nfunc TestMatMutators(t *testing.T) {\n\tt.Run(\"SetTo\", func(t *testing.T) {\n\t\tmat := NewMatWithSizeFromScalar(NewScalar(0, 0, 0, 0), 1, 1, MatTypeCV8U)\n\t\tmat.SetTo(NewScalar(255, 255, 255, 255))\n\t\tfor z := 0; z < mat.Channels(); z++ {\n\t\t\tif mat.GetUCharAt3(0, 0, z) != 255 {\n\t\t\t\tt.Errorf(\"SetTo incorrect value: z=%v: %v\\n\", z, mat.GetUCharAt3(0, 0, z))\n\t\t\t}\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"SetUCharAt\", func(t *testing.T) {\n\t\tmat := NewMatWithSize(101, 102, MatTypeCV8U)\n\t\tmat.SetUCharAt(50, 50, 25)\n\t\tif mat.GetUCharAt(50, 50) != 25 {\n\t\t\tt.Errorf(\"SetUCharAt incorrect value: %v\\n\", mat.GetUCharAt(50, 50))\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"SetUCharAt3\", func(t *testing.T) {\n\t\tmat := NewMatWithSize(101, 102, MatTypeCV8U)\n\t\tmat.SetUCharAt3(50, 50, 0, 25)\n\t\tif mat.GetUCharAt3(50, 50, 0) != 25 {\n\t\t\tt.Errorf(\"SetUCharAt3 incorrect value: %v\\n\", mat.GetUCharAt3(50, 50, 0))\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"SetSCharAt\", func(t *testing.T) {\n\t\tmat := NewMatWithSize(101, 102, MatTypeCV8S)\n\t\tmat.SetSCharAt(50, 50, 25)\n\t\tif mat.GetSCharAt(50, 50) != 25 {\n\t\t\tt.Errorf(\"SetSCharAt incorrect value: %v\\n\", mat.GetSCharAt(50, 50))\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"SetSCharAt3\", func(t *testing.T) {\n\t\tmat := NewMatWithSize(101, 102, MatTypeCV8S)\n\t\tmat.SetSCharAt3(50, 50, 0, 25)\n\t\tif mat.GetSCharAt3(50, 50, 0) != 25 {\n\t\t\tt.Errorf(\"SetSCharAt3 incorrect value: %v\\n\", mat.GetSCharAt3(50, 50, 0))\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"SetShortAt\", func(t *testing.T) {\n\t\tmat := NewMatWithSize(101, 102, MatTypeCV16S)\n\t\tmat.SetShortAt(50, 50, 25)\n\t\tif mat.GetShortAt(50, 50) != 25 {\n\t\t\tt.Errorf(\"SetShortAt incorrect value: %v\\n\", mat.GetShortAt(50, 50))\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"SetShortAt3\", func(t *testing.T) {\n\t\tmat := NewMatWithSize(101, 102, MatTypeCV16S)\n\t\tmat.SetShortAt3(50, 50, 0, 25)\n\t\tif mat.GetShortAt3(50, 50, 0) != 25 {\n\t\t\tt.Errorf(\"SetShortAt3 incorrect value: %v\\n\", mat.GetShortAt3(50, 50, 0))\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"SetIntAt\", func(t *testing.T) {\n\t\tmat := NewMatWithSize(101, 102, MatTypeCV32S)\n\t\tmat.SetIntAt(50, 50, 25)\n\t\tif mat.GetIntAt(50, 50) != 25 {\n\t\t\tt.Errorf(\"SetIntAt incorrect value: %v\\n\", mat.GetIntAt(50, 50))\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"SetIntAt3\", func(t *testing.T) {\n\t\tmat := NewMatWithSize(101, 102, MatTypeCV32S)\n\t\tmat.SetIntAt3(50, 50, 0, 25)\n\t\tif mat.GetIntAt3(50, 50, 0) != 25 {\n\t\t\tt.Errorf(\"SetIntAt3 incorrect value: %v\\n\", mat.GetIntAt3(50, 50, 0))\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"SetFloatAt\", func(t *testing.T) {\n\t\tmat := NewMatWithSize(101, 102, MatTypeCV32F)\n\t\tmat.SetFloatAt(50, 50, 25.0)\n\t\tif mat.GetFloatAt(50, 50) != 25 {\n\t\t\tt.Errorf(\"SetFloatAt incorrect value: %v\\n\", mat.GetFloatAt(50, 50))\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"SetFloatAt3\", func(t *testing.T) {\n\t\tmat := NewMatWithSize(101, 102, MatTypeCV32F)\n\t\tmat.SetFloatAt3(50, 50, 0, 25.0)\n\t\tif mat.GetFloatAt3(50, 50, 0) != 25 {\n\t\t\tt.Errorf(\"SetFloatAt incorrect value: %v\\n\", mat.GetFloatAt3(50, 50, 0))\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"SetDoubleAt\", func(t *testing.T) {\n\t\tmat := NewMatWithSize(101, 102, MatTypeCV64F)\n\t\tmat.SetDoubleAt(50, 50, 25.0)\n\t\tif mat.GetDoubleAt(50, 50) != 25.0 {\n\t\t\tt.Errorf(\"SetDoubleAt incorrect value: %v\\n\", mat.GetDoubleAt(50, 50))\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"SetDoubleAt3\", func(t *testing.T) {\n\t\tmat := NewMatWithSize(101, 102, MatTypeCV64F)\n\t\tmat.SetDoubleAt3(50, 50, 0, 25.0)\n\t\tif mat.GetDoubleAt3(50, 50, 0) != 25.0 {\n\t\t\tt.Errorf(\"SetDoubleAt3 incorrect value: %v\\n\", mat.GetDoubleAt3(50, 50, 0))\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"AddUChar\", func(t *testing.T) {\n\t\tmat := NewMatWithSize(101, 102, MatTypeCV8U)\n\t\tmat.AddUChar(42)\n\t\tif mat.GetUCharAt(50, 50) != 42 {\n\t\t\tt.Errorf(\"AddUChar incorrect value: %v\\n\", mat.GetUCharAt(50, 50))\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"SubtractUChar\", func(t *testing.T) {\n\t\tmat := NewMatWithSizeFromScalar(NewScalar(42.0, 0, 0, 0), 101, 102, MatTypeCV8U)\n\t\tmat.SubtractUChar(40)\n\t\tif mat.GetUCharAt(50, 50) != 2 {\n\t\t\tt.Errorf(\"SubtractUChar incorrect value: %v\\n\", mat.GetUCharAt(50, 50))\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"MultiplyUChar\", func(t *testing.T) {\n\t\tmat := NewMatWithSizeFromScalar(NewScalar(5.0, 0, 0, 0), 101, 102, MatTypeCV8U)\n\t\tmat.MultiplyUChar(5)\n\t\tif mat.GetUCharAt(50, 50) != 25 {\n\t\t\tt.Errorf(\"MultiplyUChar incorrect value: %v\\n\", mat.GetUCharAt(50, 50))\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"DivideUChar\", func(t *testing.T) {\n\t\tmat := NewMatWithSizeFromScalar(NewScalar(25.0, 0, 0, 0), 101, 102, MatTypeCV8U)\n\t\tmat.DivideUChar(5)\n\t\tif mat.GetUCharAt(50, 50) != 5 {\n\t\t\tt.Errorf(\"DivideUChar incorrect value: %v\\n\", mat.GetUCharAt(50, 50))\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"AddFloat\", func(t *testing.T) {\n\t\tmat := NewMatWithSizeFromScalar(NewScalar(30.0, 0, 0, 0), 101, 102, MatTypeCV32F)\n\t\tmat.AddFloat(1.0)\n\t\tif mat.GetFloatAt(50, 50) != 31.0 {\n\t\t\tt.Errorf(\"AddFloat incorrect value: %v\\n\", mat.GetFloatAt(50, 50))\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"SubtractFloat\", func(t *testing.T) {\n\t\tmat := NewMatWithSizeFromScalar(NewScalar(30.0, 0, 0, 0), 101, 102, MatTypeCV32F)\n\t\tmat.SubtractFloat(1.0)\n\t\tif mat.GetFloatAt(50, 50) != 29.0 {\n\t\t\tt.Errorf(\"SubtractFloat incorrect value: %v\\n\", mat.GetFloatAt(50, 50))\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"MultiplyFloat\", func(t *testing.T) {\n\t\tmat := NewMatWithSizeFromScalar(NewScalar(30.0, 0, 0, 0), 101, 102, MatTypeCV32F)\n\t\tmat.MultiplyFloat(2.0)\n\t\tif mat.GetFloatAt(50, 50) != 60.0 {\n\t\t\tt.Errorf(\"MultiplyFloat incorrect value: %v\\n\", mat.GetFloatAt(50, 50))\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"DivideFloat\", func(t *testing.T) {\n\t\tmat := NewMatWithSizeFromScalar(NewScalar(30.0, 0, 0, 0), 101, 102, MatTypeCV32F)\n\t\tmat.DivideFloat(2.0)\n\t\tif mat.GetFloatAt(50, 50) != 15.0 {\n\t\t\tt.Errorf(\"DivideFloat incorrect value: %v\\n\", mat.GetFloatAt(50, 50))\n\t\t}\n\t\tmat.Close()\n\t})\n\tt.Run(\"MultiplyMatrix\", func(t *testing.T) {\n\t\tmat := NewMatWithSizeFromScalar(NewScalar(30.0, 0, 0, 0), 2, 1, MatTypeCV32F)\n\t\tmat2 := NewMatWithSizeFromScalar(NewScalar(30.0, 0, 0, 0), 1, 2, MatTypeCV32F)\n\t\tmat3 := mat.MultiplyMatrix(mat2)\n\t\tfor i := 0; i < mat3.Cols(); i++ {\n\t\t\tfor j := 0; j < mat3.Rows(); j++ {\n\t\t\t\tif mat3.GetFloatAt(i, j) != 900.0 {\n\t\t\t\t\tt.Errorf(\"MultiplyMatrix incorrect value: %v\\n\", mat3.GetFloatAt(i, j))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tmat.Close()\n\t\tmat2.Close()\n\t\tmat3.Close()\n\t})\n}\n\nfunc TestMatAbsDiff(t *testing.T) {\n\tmat1 := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat1.Close()\n\tmat2 := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat2.Close()\n\tmat3 := NewMat()\n\tdefer mat3.Close()\n\tAbsDiff(mat1, mat2, &mat3)\n\tif mat3.Empty() {\n\t\tt.Error(\"TestMatAbsDiff dest mat3 should not be empty.\")\n\t}\n}\n\nfunc TestMatAdd(t *testing.T) {\n\tmat1 := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat1.Close()\n\tmat2 := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat2.Close()\n\tmat3 := NewMat()\n\tdefer mat3.Close()\n\tAdd(mat1, mat2, &mat3)\n\tif mat3.Empty() {\n\t\tt.Error(\"TestMatAdd dest mat3 should not be empty.\")\n\t}\n}\n\nfunc TestMatAddWeighted(t *testing.T) {\n\tmat1 := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat1.Close()\n\tmat2 := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat2.Close()\n\tmat3 := NewMat()\n\tdefer mat3.Close()\n\tAddWeighted(mat1, 2.0, mat2, 3.0, 4.0, &mat3)\n\tif mat3.Empty() {\n\t\tt.Error(\"TestMatAddWeighted dest mat3 should not be empty.\")\n\t}\n}\n\nfunc TestMatBitwiseOperations(t *testing.T) {\n\tmat1 := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat1.Close()\n\tmat2 := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat2.Close()\n\tmat3 := NewMat()\n\tdefer mat3.Close()\n\tBitwiseAnd(mat1, mat2, &mat3)\n\tif mat3.Empty() {\n\t\tt.Error(\"TestMatBitwiseAnd dest mat3 should not be empty.\")\n\t}\n\n\tBitwiseOr(mat1, mat2, &mat3)\n\tif mat3.Empty() {\n\t\tt.Error(\"TestMatBitwiseOr dest mat3 should not be empty.\")\n\t}\n\n\tBitwiseXor(mat1, mat2, &mat3)\n\tif mat3.Empty() {\n\t\tt.Error(\"TestMatBitwiseXor dest mat3 should not be empty.\")\n\t}\n\n\tBitwiseNot(mat1, &mat3)\n\tif mat3.Empty() {\n\t\tt.Error(\"TestMatBitwiseNot dest mat3 should not be empty.\")\n\t}\n\n}\n\nfunc TestMatBitwiseOperationsWithMasks(t *testing.T) {\n\tmat1 := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat1.Close()\n\tmat2 := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat2.Close()\n\tmat3 := NewMat()\n\tdefer mat3.Close()\n\tmat4 := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat4.Close()\n\tBitwiseAndWithMask(mat1, mat2, &mat3, mat4)\n\tif mat3.Empty() {\n\t\tt.Error(\"TestMatBitwiseAndWithMask dest mat3 should not be empty.\")\n\t}\n\n\tBitwiseOrWithMask(mat1, mat2, &mat3, mat4)\n\tif mat3.Empty() {\n\t\tt.Error(\"TestMatBitwiseOrWithMask dest mat3 should not be empty.\")\n\t}\n\n\tBitwiseXorWithMask(mat1, mat2, &mat3, mat4)\n\tif mat3.Empty() {\n\t\tt.Error(\"TestMatBitwiseXorWithMask dest mat3 should not be empty.\")\n\t}\n\tBitwiseNotWithMask(mat1, &mat3, mat4)\n\tif mat3.Empty() {\n\t\tt.Error(\"TestMatBitwiseNotWithMask dest mat3 should not be empty.\")\n\t}\n}\n\nfunc TestMatInRange(t *testing.T) {\n\tmat1 := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat1.Close()\n\tlb := NewMatFromScalar(NewScalar(20.0, 100.0, 100.0, 0.0), MatTypeCV8U)\n\tdefer lb.Close()\n\tub := NewMatFromScalar(NewScalar(20.0, 100.0, 100.0, 0.0), MatTypeCV8U)\n\tdefer ub.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\tInRange(mat1, lb, ub, &dst)\n\tif dst.Empty() {\n\t\tt.Error(\"TestMatAddWeighted dest mat3 should not be empty.\")\n\t}\n}\n\nfunc TestMatInRangeWithScalar(t *testing.T) {\n\tmat1 := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat1.Close()\n\tlb := NewScalar(20.0, 100.0, 100.0, 0.0)\n\tub := NewScalar(20.0, 100.0, 100.0, 0.0)\n\tdst := NewMat()\n\tdefer dst.Close()\n\tInRangeWithScalar(mat1, lb, ub, &dst)\n\tif dst.Empty() {\n\t\tt.Error(\"TestMatAddWeighted dest mat3 should not be empty.\")\n\t}\n}\n\nfunc TestMatDCT(t *testing.T) {\n\tsrc := NewMatWithSize(64, 64, MatTypeCV32F)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tDCT(src, &dst, DftForward)\n\tif dst.Empty() {\n\t\tt.Error(\"TestMatDCT dst should not be empty.\")\n\t}\n}\n\nfunc TestMatDFT(t *testing.T) {\n\tsrc := NewMatWithSize(101, 102, MatTypeCV32F)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tm := GetOptimalDFTSize(101)\n\tn := GetOptimalDFTSize(102)\n\tif m != 108 {\n\t\tt.Errorf(\"TestMatOptimalDFT dst error: %d\", m)\n\t}\n\n\tif n != 108 {\n\t\tt.Errorf(\"TestMatOptimalDFT dst error: %d\", n)\n\t}\n\n\tDFT(src, &dst, DftForward)\n\tif dst.Empty() {\n\t\tt.Error(\"TestMatDFT dst should not be empty.\")\n\t}\n}\n\nfunc TestMatDivide(t *testing.T) {\n\tmat1 := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat1.Close()\n\tmat2 := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat2.Close()\n\tmat3 := NewMat()\n\tdefer mat3.Close()\n\tDivide(mat1, mat2, &mat3)\n\tif mat3.Empty() {\n\t\tt.Error(\"TestMatDivide dest mat3 should not be empty.\")\n\t}\n}\n\nfunc TestMeanStdDev(t *testing.T) {\n\tsrc := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\tdstStdDev := NewMat()\n\tdefer dstStdDev.Close()\n\tMeanStdDev(src, &dst, &dstStdDev)\n\tif dst.Empty() {\n\t\tt.Error(\"TestMeanStdDev dst should not be empty.\")\n\t}\n\tif dstStdDev.Empty() {\n\t\tt.Error(\"TestMeanStdDev dstStdDev should not be empty.\")\n\t}\n}\n\nfunc TestMatMerge(t *testing.T) {\n\tsrc := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer src.Close()\n\tsrc2 := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer src2.Close()\n\tsrc3 := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer src3.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\tMerge([]Mat{src, src2, src3}, &dst)\n\tif dst.Empty() {\n\t\tt.Error(\"TestMatMerge dst should not be empty.\")\n\t}\n}\n\nfunc TestMatMulSpectrums(t *testing.T) {\n\ta := NewMatWithSize(101, 102, MatTypeCV32F)\n\tdefer a.Close()\n\tb := NewMatWithSize(101, 102, MatTypeCV32F)\n\tdefer b.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\tMulSpectrums(a, b, &dst, 0)\n\tif dst.Empty() {\n\t\tt.Error(\"TestMatMulSpectrums dst should not be empty.\")\n\t}\n\tdst2 := NewMat()\n\tdefer dst2.Close()\n\t//test with dftrows flag (the only flag accepted in addition to 0)\n\tMulSpectrums(a, b, &dst2, DftRows)\n\tif dst2.Empty() {\n\t\tt.Error(\"TestMatMulSpectrums dst should not be empty.\")\n\t}\n}\n\nfunc TestMatMultiply(t *testing.T) {\n\tmat1 := NewMatWithSize(101, 102, MatTypeCV64F)\n\tdefer mat1.Close()\n\tmat2 := NewMatWithSize(101, 102, MatTypeCV64F)\n\tdefer mat2.Close()\n\tmat3 := NewMat()\n\tdefer mat3.Close()\n\tMultiply(mat1, mat2, &mat3)\n\tif mat3.Empty() {\n\t\tt.Error(\"TestMatMultiply dest mat3 should not be empty.\")\n\t}\n\n\t// since this is a single channel Mat, only the first value in the scalar is used\n\tmat4 := NewMatWithSizeFromScalar(NewScalar(2.0, 0.0, 0.0, 0.0), 101, 102, MatTypeCV64F)\n\tdefer mat4.Close()\n\tmat5 := NewMatWithSizeFromScalar(NewScalar(3.0, 0.0, 0.0, 0.0), 101, 102, MatTypeCV64F)\n\tdefer mat5.Close()\n\tMultiply(mat4, mat5, &mat3)\n\tif mat3.Empty() {\n\t\tt.Error(\"TestMatMultiply dest mat3 should not be empty.\")\n\t}\n\tif mat3.GetDoubleAt(0, 0) != 6.0 {\n\t\tt.Error(\"TestMatMultiply invalue value in dest mat3.\")\n\t}\n}\n\nfunc TestMatMultiplyWithParams(t *testing.T) {\n\tmat1 := NewMatWithSize(101, 102, MatTypeCV64F)\n\tdefer mat1.Close()\n\tmat2 := NewMatWithSize(101, 102, MatTypeCV64F)\n\tdefer mat2.Close()\n\tmat3 := NewMat()\n\tdefer mat3.Close()\n\tMultiplyWithParams(mat1, mat2, &mat3, 0.5, -1)\n\tif mat3.Empty() {\n\t\tt.Error(\"TestMatMultiplyWithParams dest mat3 should not be empty.\")\n\t}\n\n\t// since this is a single channel Mat, only the first value in the scalar is used\n\tmat4 := NewMatWithSizeFromScalar(NewScalar(2.0, 0.0, 0.0, 0.0), 101, 102, MatTypeCV64F)\n\tdefer mat4.Close()\n\tmat5 := NewMatWithSizeFromScalar(NewScalar(3.0, 0.0, 0.0, 0.0), 101, 102, MatTypeCV64F)\n\tdefer mat5.Close()\n\tMultiplyWithParams(mat4, mat5, &mat3, 2.0, -1)\n\tif mat3.Empty() {\n\t\tt.Error(\"TestMatMultiplyWithParams dest mat3 should not be empty.\")\n\t}\n\tif mat3.GetDoubleAt(0, 0) != 12.0 {\n\t\tt.Error(\"TestMatMultiplyWithParams invalue value in dest mat3.\")\n\t}\n}\n\nfunc TestMatNormalize(t *testing.T) {\n\tsrc := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\tNormalize(src, &dst, 0.0, 255.0, NormMinMax)\n\tif dst.Empty() {\n\t\tt.Error(\"TestMatNormalize dst should not be empty.\")\n\t}\n}\n\nfunc TestMatPerspectiveTransform(t *testing.T) {\n\tsrc := NewMatWithSize(100, 1, MatTypeCV32F+MatChannels2)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\ttm := NewMatWithSize(3, 3, MatTypeCV32F)\n\tdefer tm.Close()\n\tPerspectiveTransform(src, &dst, tm)\n\tif dst.Empty() {\n\t\tt.Error(\"PerspectiveTransform error\")\n\t}\n}\n\nfunc TestMatSolve(t *testing.T) {\n\ta := NewMatWithSize(3, 3, MatTypeCV32F)\n\tdefer a.Close()\n\tb := NewMatWithSize(3, 1, MatTypeCV32F)\n\tdefer b.Close()\n\tsolve := NewMat()\n\tdefer solve.Close()\n\n\ttestPoints := []struct {\n\t\tx2 float32\n\t\tx  float32\n\t\tc  float32\n\t\ty  float32\n\t}{\n\t\t{x2: 1, x: 1, c: 1, y: 0},\n\t\t{x2: 0, x: 0, c: 1, y: 2},\n\t\t{x2: 9, x: 3, c: 1, y: 2},\n\t}\n\n\tfor row, p := range testPoints {\n\t\ta.SetFloatAt(row, 0, p.x2)\n\t\ta.SetFloatAt(row, 1, p.x)\n\t\ta.SetFloatAt(row, 2, p.c)\n\n\t\tb.SetFloatAt(row, 0, p.y)\n\t}\n\n\tsolved := Solve(a, b, &solve, SolveDecompositionLu)\n\n\tif !solved {\n\t\tt.Errorf(\"TestMatSolve could not solve linear equations\")\n\t}\n\n\tif solve.GetFloatAt(0, 0) != 1 || solve.GetFloatAt(1, 0) != -3 || solve.GetFloatAt(2, 0) != 2 {\n\t\tt.Errorf(\"TestMatSolve incorrect results: got %v expected %v, got %v expected %v, got %v expected %v\",\n\t\t\tsolve.GetFloatAt(0, 0), 1,\n\t\t\tsolve.GetFloatAt(1, 0), -3,\n\t\t\tsolve.GetFloatAt(2, 0), 2)\n\t}\n}\n\nfunc TestSolveCubic(t *testing.T) {\n\tcoeffs := NewMatWithSize(1, 4, MatTypeCV32F)\n\tdefer coeffs.Close()\n\troots := NewMat()\n\tdefer roots.Close()\n\n\tcoeffs.SetFloatAt(0, 0, 2.0)\n\tcoeffs.SetFloatAt(0, 1, 3.0)\n\tcoeffs.SetFloatAt(0, 2, -11.0)\n\tcoeffs.SetFloatAt(0, 3, -6.0)\n\n\trootsCount := SolveCubic(coeffs, &roots)\n\n\texpectedRootsCount := 3\n\tif rootsCount != expectedRootsCount {\n\t\tt.Errorf(\"TestSolveCubic incorrect numbers of roots %d, expected %d\", rootsCount, expectedRootsCount)\n\t}\n\n\tif roots.GetFloatAt(0, 0) != -3.0 || roots.GetFloatAt(0, 1) != 2.0 || roots.GetFloatAt(0, 0) != -3.0 {\n\t\tt.Errorf(\"TestSolveCubic incorrect roots: got %f expected %f, got %f expected %f, got %f expected %f\",\n\t\t\troots.GetFloatAt(0, 0), -3.0,\n\t\t\troots.GetFloatAt(0, 1), -0.5,\n\t\t\troots.GetFloatAt(0, 0), -3.0)\n\t}\n}\n\nfunc TestSolvePoly(t *testing.T) {\n\tcoeffs := NewMatWithSize(1, 3, MatTypeCV32F)\n\tdefer coeffs.Close()\n\troots := NewMat()\n\tdefer roots.Close()\n\n\t// x² - 14x + 49 = 0\n\tcoeffs.SetFloatAt(0, 0, 49.0)\n\tcoeffs.SetFloatAt(0, 1, -14.0)\n\tcoeffs.SetFloatAt(0, 2, 1)\n\n\tdiffError := SolvePoly(coeffs, &roots, 300)\n\n\tdiffTolerance := 1.0e-61\n\tif diffError > diffTolerance {\n\t\tt.Errorf(\"TestSolvePoly was not exact, got an error of %e and should have been less than %f\", diffError, diffTolerance)\n\t}\n\n\tif roots.GetFloatAt(0, 0) != 7.0 {\n\t\tt.Errorf(\"TestSolvePoly incorrect roots: got %f expected %f\",\n\t\t\troots.GetFloatAt(0, 0), 7.0)\n\t}\n}\n\nfunc TestMatReduceToSingleRow(t *testing.T) {\n\trows := 2\n\tcols := 3\n\tsrc := NewMatWithSize(rows, cols, MatTypeCV8U)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tfor row := 0; row < rows; row++ {\n\t\tfor col := 0; col < cols; col++ {\n\t\t\tsrc.SetUCharAt(row, col, uint8(col+1))\n\t\t}\n\t}\n\n\tReduce(src, &dst, 0, ReduceSum, MatTypeCV32F)\n\n\tsz := dst.Size()\n\tif sz[0] != 1 && sz[1] != 3 {\n\t\tt.Errorf(\"TestMatReduceToSingleRow incorrect size: %v\\n\", sz)\n\t}\n\n\tif dst.GetFloatAt(0, 0) != 2 || dst.GetFloatAt(0, 1) != 4 || dst.GetFloatAt(0, 2) != 6 {\n\t\tt.Errorf(\"TestMatReduceToSingleRow incorrect reduce result: %v at (0, 0) expected 2, %v at (0, 1) expected 4, %v at (0, 2) expected 6\",\n\t\t\tdst.GetFloatAt(0, 0), dst.GetFloatAt(0, 1), dst.GetFloatAt(0, 2))\n\t}\n}\n\nfunc TestMatReduceToSingleColumn(t *testing.T) {\n\trows := 2\n\tcols := 3\n\tsrc := NewMatWithSize(rows, cols, MatTypeCV8U)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tfor row := 0; row < rows; row++ {\n\t\tfor col := 0; col < cols; col++ {\n\t\t\tsrc.SetUCharAt(row, col, uint8(col+1))\n\t\t}\n\t}\n\n\tReduce(src, &dst, 1, ReduceSum, MatTypeCV32F)\n\n\tsz := dst.Size()\n\tif sz[0] != 3 && sz[1] != 1 {\n\t\tt.Errorf(\"TestMatReduceToSingleColumn incorrect size: %v\\n\", sz)\n\t}\n\n\tif dst.GetFloatAt(0, 0) != 6 || dst.GetFloatAt(1, 0) != 6 {\n\t\tt.Errorf(\"TestMatReduceToSingleColumn incorrect reduce result: %v at (0, 0) expected 6, %v at (1, 0) expected 6\",\n\t\t\tdst.GetFloatAt(0, 0), dst.GetFloatAt(1, 0))\n\t}\n}\n\nfunc TestMatReduceArgMax(t *testing.T) {\n\trows := 2\n\tcols := 3\n\tsrc := NewMatWithSize(rows, cols, MatTypeCV8U)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tfor row := 0; row < rows; row++ {\n\t\tfor col := 0; col < cols; col++ {\n\t\t\tsrc.SetUCharAt(row, col, uint8(col+1))\n\t\t}\n\t}\n\n\tReduceArgMax(src, &dst, 1, false)\n\n\tsz := dst.Size()\n\tif sz[0] != 2 && sz[1] != 1 {\n\t\tt.Errorf(\"TestMatReduceArgMax incorrect size: %v\\n\", sz)\n\t}\n\n\tif dst.GetUCharAt(0, 0) != 2 || dst.GetUCharAt(1, 0) != 2 {\n\t\tt.Errorf(\"TestMatReduceArgMax incorrect reduce result: %v at (0, 0) expected 1, %v at (1, 0) expected 1\",\n\t\t\tdst.GetUCharAt(0, 0), dst.GetUCharAt(1, 0))\n\t}\n}\n\nfunc TestMatReduceArgMin(t *testing.T) {\n\trows := 2\n\tcols := 3\n\tsrc := NewMatWithSize(rows, cols, MatTypeCV8U)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tfor row := 0; row < rows; row++ {\n\t\tfor col := 0; col < cols; col++ {\n\t\t\tsrc.SetUCharAt(row, col, uint8(col+1))\n\t\t}\n\t}\n\n\tReduceArgMin(src, &dst, 1, false)\n\n\tsz := dst.Size()\n\tif sz[0] != 2 && sz[1] != 1 {\n\t\tt.Errorf(\"TestMatReduceArgMax incorrect size: %v\\n\", sz)\n\t}\n\n\tif dst.GetUCharAt(0, 0) != 0 || dst.GetUCharAt(1, 0) != 0 {\n\t\tt.Errorf(\"TestMatReduceArgMax incorrect reduce result: %v at (0, 0) expected 0, %v at (1, 0) expected 0\",\n\t\t\tdst.GetUCharAt(0, 0), dst.GetUCharAt(1, 0))\n\t}\n}\n\nfunc TestRepeat(t *testing.T) {\n\trows := 1\n\tcols := 3\n\tsrc := NewMatWithSize(rows, cols, MatTypeCV8U)\n\tdefer src.Close()\n\n\tfor row := 0; row < rows; row++ {\n\t\tfor col := 0; col < cols; col++ {\n\t\t\tsrc.SetUCharAt(row, col, uint8(col))\n\t\t}\n\t}\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\tRepeat(src, 3, 1, &dst)\n\n\tsize := dst.Size()\n\texpectedRows := 3\n\texpectedCols := 3\n\n\tif size[0] != expectedRows || size[1] != expectedCols {\n\t\tt.Errorf(\"TestRepeat incorrect size, got y=%d x=%d, expected y=%d x=%d.\", size[0], size[1], expectedRows, expectedCols)\n\t}\n\n\tfor row := 0; row < expectedRows; row++ {\n\t\tfor col := 0; col < expectedCols; col++ {\n\n\t\t\tresult := dst.GetUCharAt(row, col)\n\n\t\t\tif result != uint8(col) {\n\t\t\t\tt.Errorf(\"TestRepeat dst at row=%d col=%d should be %d and got %d.\", row, col, col, result)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc TestScaleAdd(t *testing.T) {\n\trows := 2\n\tcols := 3\n\tsrc1 := NewMatWithSize(rows, cols, MatTypeCV64F)\n\tdefer src1.Close()\n\n\tfor row := 0; row < rows; row++ {\n\t\tfor col := 0; col < cols; col++ {\n\t\t\tsrc1.SetDoubleAt(row, col, float64(col))\n\t\t}\n\t}\n\n\tsrc2 := NewMatWithSize(rows, cols, MatTypeCV64F)\n\tdefer src2.Close()\n\n\tfor row := 0; row < rows; row++ {\n\t\tfor col := 0; col < cols; col++ {\n\t\t\tsrc2.SetDoubleAt(row, col, 1.0)\n\t\t}\n\t}\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\talpha := 1.5\n\tScaleAdd(src1, alpha, src2, &dst)\n\n\tif dst.Empty() {\n\t\tt.Error(\"TestScaleAdd dst should not be empty.\")\n\t}\n\n\tfor row := 0; row < rows; row++ {\n\t\tfor col := 0; col < cols; col++ {\n\t\t\texpected := float64(col)*alpha + 1.0\n\t\t\tresult := dst.GetDoubleAt(row, col)\n\t\t\tif result != expected {\n\t\t\t\tt.Errorf(\"TestScaleAdd dst at row=%d col=%d should be %f and got %f.\", row, col, expected, result)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc TestSetIdentity(t *testing.T) {\n\trows := 4\n\tcols := 3\n\tsrc := NewMatWithSize(rows, cols, MatTypeCV64F)\n\tdefer src.Close()\n\tscalar := 2.5\n\tSetIdentity(src, scalar)\n\n\tif src.Empty() {\n\t\tt.Error(\"TestSetIdentity src should not be empty.\")\n\t}\n\n\tfor row := 0; row < rows; row++ {\n\t\tfor col := 0; col < cols; col++ {\n\t\t\tresult := src.GetDoubleAt(row, col)\n\t\t\texpected := 0.0\n\t\t\tif row == col {\n\t\t\t\texpected = scalar\n\t\t\t}\n\t\t\tif result != expected {\n\t\t\t\tt.Errorf(\"TestSetIdentity src at row=%d col=%d should be %f and got %f.\", row, col, expected, result)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc TestMatSortEveryRowDescending(t *testing.T) {\n\trows := 2\n\tcols := 3\n\tsrc := NewMatWithSize(rows, cols, MatTypeCV8U)\n\tdefer src.Close()\n\n\tfor row := 0; row < rows; row++ {\n\t\tfor col := 0; col < cols; col++ {\n\t\t\tsrc.SetUCharAt(row, col, uint8(col))\n\t\t}\n\t}\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tflags := SortEveryRow + SortDescending\n\tSort(src, &dst, flags)\n\n\tif dst.Empty() {\n\t\tt.Error(\"TestMatSortEveryRowDescending dst should not be empty.\")\n\t}\n\n\tfor row := 0; row < rows; row++ {\n\t\tfor col := 0; col < cols; col++ {\n\t\t\texpected := cols - col - 1\n\t\t\tresult := dst.GetUCharAt(row, col)\n\t\t\tif result != uint8(expected) {\n\t\t\t\tt.Errorf(\"TestMatSortEveryRowDescending dst at row=%d col=%d should be %d and got %d.\", row, col, expected, result)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc TestMatSortIdxEveryRowDescending(t *testing.T) {\n\trows := 2\n\tcols := 3\n\tsrc := NewMatWithSize(rows, cols, MatTypeCV8U)\n\tdefer src.Close()\n\n\tfor row := 0; row < rows; row++ {\n\t\tfor col := 0; col < cols; col++ {\n\t\t\tsrc.SetUCharAt(row, col, uint8(col))\n\t\t}\n\t}\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\tflags := SortEveryRow + SortDescending\n\tSortIdx(src, &dst, flags)\n\n\tif dst.Empty() {\n\t\tt.Error(\"TestMatSortIdxEveryRowDescending dst should not be empty.\")\n\t}\n}\n\nfunc TestMatSplit(t *testing.T) {\n\tsrc := IMRead(\"images/face.jpg\", 1)\n\tdefer src.Close()\n\tchans := Split(src)\n\tif len(chans) != src.Channels() {\n\t\tt.Error(\"Split Channel count differs\")\n\t}\n\tdst := NewMat()\n\tdefer dst.Close()\n\tMerge(chans, &dst)\n\tfor _, ch := range chans {\n\t\tch.Close()\n\t}\n\tdiff := NewMat()\n\tdefer diff.Close()\n\tAbsDiff(src, dst, &diff)\n\tsum := diff.Sum()\n\tif sum.Val1 != 0 || sum.Val2 != 0 || sum.Val3 != 0 {\n\t\tt.Error(\"Split/Merged images differ\")\n\t}\n}\n\nfunc TestMatSubtract(t *testing.T) {\n\tsrc1 := IMRead(\"images/lut.png\", 1)\n\tdefer src1.Close()\n\tsrc2 := IMRead(\"images/lut.png\", 1)\n\tdefer src2.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\tSubtract(src1, src2, &dst)\n\tsum := dst.Sum()\n\tif sum.Val1 != 0 || sum.Val2 != 0 || sum.Val3 != 0 {\n\t\tt.Error(\"Sum of Subtracting equal images is not 0\")\n\t}\n}\n\nfunc TestMatTrace(t *testing.T) {\n\trows := 3\n\tcols := 3\n\tsrc := NewMatWithSize(rows, cols, MatTypeCV8U)\n\tdefer src.Close()\n\n\t// Create and identity eye matrix\n\tfor row := 0; row <= rows; row++ {\n\t\tfor col := 0; col <= cols; col++ {\n\t\t\tif row == col {\n\t\t\t\tsrc.SetUCharAt(row, col, uint8(1))\n\t\t\t}\n\t\t}\n\t}\n\n\ttrace := Trace(src)\n\texpected := NewScalar(3, 0, 0, 0)\n\n\tif trace.Val1 != expected.Val1 || trace.Val2 != expected.Val2 || trace.Val3 != expected.Val3 || trace.Val4 != expected.Val4 {\n\t\tt.Errorf(\"Trace values should be %v and was %v\", expected, trace)\n\t}\n}\n\nfunc TestMatTransform(t *testing.T) {\n\tsrc := IMRead(\"images/lut.png\", 1)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\ttm := NewMatWithSize(4, 4, MatTypeCV8UC4)\n\tdefer tm.Close()\n\tTransform(src, &dst, tm)\n\tif dst.Empty() {\n\t\tt.Error(\"Transform error\")\n\t}\n}\n\nfunc TestMatTranspose(t *testing.T) {\n\tsrc := IMRead(\"images/lut.png\", 1)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\tTranspose(src, &dst)\n\tif dst.Empty() {\n\t\tt.Error(\"Transpose error\")\n\t}\n}\n\nfunc TestMatTransposeND(t *testing.T) {\n\trows := 1\n\tcols := 3\n\tsrc := NewMatWithSize(rows, cols, MatTypeCV8U)\n\tdefer src.Close()\n\n\tfor row := 0; row < rows; row++ {\n\t\tfor col := 0; col < cols; col++ {\n\t\t\tsrc.SetUCharAt(row, col, uint8(col))\n\t\t}\n\t}\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\tTransposeND(src, []int{1, 0}, &dst)\n\tif dst.Empty() {\n\t\tt.Error(\"TransposeND error\")\n\t}\n}\n\nfunc TestPolarToCart(t *testing.T) {\n\tmagnitude := NewMatWithSize(101, 102, MatTypeCV32F)\n\tangle := NewMatWithSize(101, 102, MatTypeCV32F)\n\tx := NewMat()\n\ty := NewMat()\n\n\tPolarToCart(magnitude, angle, &x, &y, false)\n\n\tif x.Empty() || y.Empty() {\n\t\tt.Error(\"TestPolarToCart neither x nor y should be empty.\")\n\t}\n\n\tx.Close()\n\ty.Close()\n\tmagnitude.Close()\n\tangle.Close()\n}\n\nfunc TestMatPow(t *testing.T) {\n\tsrc := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\tpower := 2.0\n\tPow(src, power, &dst)\n\n\tif dst.Empty() {\n\t\tt.Error(\"TestMatPow dest should not be empty.\")\n\t}\n}\n\nfunc TestMatSum(t *testing.T) {\n\tsrc := NewMatFromScalar(NewScalar(1, 2, 3, 4), MatTypeCV8UC4)\n\tdefer src.Close()\n\tsum := src.Sum()\n\tif sum.Val1 != 1 || sum.Val2 != 2 || sum.Val3 != 3 || sum.Val4 != 4 {\n\t\tt.Error(\"Sum values do not match constructor\")\n\t}\n}\n\nfunc TestTermCriteria(t *testing.T) {\n\ttc := NewTermCriteria(Count, 50, 2.0)\n\tif tc.p == nil {\n\t\tt.Error(\"TermCriteria has invalid value\")\n\t}\n}\n\nfunc TestScalar(t *testing.T) {\n\ts := NewScalar(127.0, 255.0, 64.0, 0.0)\n\tif s.Val1 != 127.0 || s.Val2 != 255.0 || s.Val3 != 64.0 || s.Val4 != 0.0 {\n\t\tt.Error(\"Scalar has invalid value\")\n\t}\n}\n\nfunc TestToCPoints(t *testing.T) {\n\tpoints := []image.Point{\n\t\timage.Pt(0, 0),\n\t\timage.Pt(1, 1),\n\t}\n\n\tcPoints := toCPoints(points)\n\n\tif int(cPoints.length) != len(points) {\n\t\tt.Error(\"Invalid C Points length\")\n\t}\n}\n\nfunc TestToCStrings(t *testing.T) {\n\tstrs := []string{\n\t\t\"hello\",\n\t\t\"fellow\",\n\t\t\"CStrings\",\n\t}\n\n\tcStrs := toCStrings(strs)\n\n\tif int(cStrs.length) != len(strs) {\n\t\tt.Error(\"Invalid CStrings length\")\n\t}\n}\n\nfunc TestMatBatchDistance(t *testing.T) {\n\tsrc1 := NewMatWithSize(100, 100, MatTypeCV8U)\n\tsrc2 := NewMatWithSize(100, 100, MatTypeCV8U)\n\tmask := NewMatWithSize(100, 100, MatTypeCV8U)\n\tdist := NewMat()\n\tnidx := NewMat()\n\tBatchDistance(src1, src2, dist, -1, nidx, NormL2, 15, mask, 0, false)\n\tif dist.Empty() {\n\t\tt.Error(\"TestBatchDistance dst should not be empty.\")\n\t}\n\tsrc1.Close()\n\tsrc2.Close()\n\tmask.Close()\n\tdist.Close()\n\tnidx.Close()\n}\n\nfunc TestMatBorderInterpolate(t *testing.T) {\n\tn := BorderInterpolate(1, 5, 1)\n\tif n == 0 {\n\t\tt.Error(\"TestBorderInterpolate dst should not be 0.\")\n\t}\n}\n\nfunc TestMatCalcCovarMatrix(t *testing.T) {\n\tsamples := NewMatWithSize(10, 10, MatTypeCV32F)\n\tcovar := NewMat()\n\tmean := NewMat()\n\tCalcCovarMatrix(samples, &covar, &mean, CovarRows, MatTypeCV64F)\n\tif covar.Empty() {\n\t\tt.Error(\"TestCalcCovarMatrix dst should not be empty.\")\n\t}\n\tsamples.Close()\n\tcovar.Close()\n\tmean.Close()\n}\n\nfunc TestMatCartToPolar(t *testing.T) {\n\tx := NewMatWithSize(100, 100, MatTypeCV32F)\n\ty := NewMatWithSize(100, 100, MatTypeCV32F)\n\tmagnitude := NewMat()\n\tangle := NewMat()\n\tCartToPolar(x, y, &magnitude, &angle, false)\n\tif magnitude.Empty() || angle.Empty() {\n\t\tt.Error(\"TestCartToPolar neither magnitude nor angle should be empty.\")\n\t}\n\tx.Close()\n\ty.Close()\n\tmagnitude.Close()\n\tangle.Close()\n}\n\nfunc TestMatCheckRange(t *testing.T) {\n\tmat1 := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat1.Close()\n\tret := CheckRange(mat1)\n\tif !ret {\n\t\tt.Error(\"TestCheckRange error.\")\n\t}\n}\n\nfunc TestMatCompleteSymm(t *testing.T) {\n\tsrc := NewMatWithSize(100, 100, MatTypeCV32F)\n\tCompleteSymm(src, false)\n\tif src.Empty() {\n\t\tt.Error(\"TestCompleteSymm src should not be empty.\")\n\t}\n\tsrc.Close()\n}\n\nfunc TestMatConvertScaleAbs(t *testing.T) {\n\tsrc := NewMatWithSize(100, 100, MatTypeCV32F)\n\tdst := NewMat()\n\tConvertScaleAbs(src, &dst, 1, 0)\n\tif dst.Empty() {\n\t\tt.Error(\"TestConvertScaleAbs dst should not be empty.\")\n\t}\n\tsrc.Close()\n\tdst.Close()\n}\n\nfunc TestMatCopyMakeBorder(t *testing.T) {\n\tsrc := NewMatWithSize(100, 100, MatTypeCV32F)\n\tdst := NewMat()\n\tCopyMakeBorder(src, &dst, 10, 10, 10, 10, BorderReflect, color.RGBA{0, 0, 0, 0})\n\tif dst.Empty() {\n\t\tt.Error(\"TestCopyMakeBorder dst should not be empty.\")\n\t}\n\tsrc.Close()\n\tdst.Close()\n}\n\nfunc TestMatDeterminant(t *testing.T) {\n\tmat1 := NewMatWithSize(101, 101, MatTypeCV32F)\n\tdefer mat1.Close()\n\tret := Determinant(mat1)\n\tif ret != 0 {\n\t\tt.Error(\"TestMatDeterminant error.\")\n\t}\n}\n\nfunc TestMatEigen(t *testing.T) {\n\tsrc := NewMatWithSize(10, 10, MatTypeCV32F)\n\teigenvalues := NewMat()\n\teigenvectors := NewMat()\n\tEigen(src, &eigenvalues, &eigenvectors)\n\tif eigenvectors.Empty() || eigenvalues.Empty() {\n\t\tt.Error(\"TestEigen should not have empty eigenvectors or eigenvalues.\")\n\t}\n\tsrc.Close()\n\teigenvectors.Close()\n\teigenvalues.Close()\n}\n\nfunc TestMatEigenNonSymmetric(t *testing.T) {\n\tsrc := NewMatWithSizeFromScalar(NewScalar(0.1, 0.1, 0.1, 0.1), 10, 10, MatTypeCV32F)\n\teigenvalues := NewMat()\n\teigenvectors := NewMat()\n\tEigenNonSymmetric(src, &eigenvalues, &eigenvectors)\n\tif eigenvectors.Empty() || eigenvalues.Empty() {\n\t\tt.Error(\"TestEigenNonSymmetric should not have empty eigenvectors or eigenvalues.\")\n\t}\n\tsrc.Close()\n\teigenvectors.Close()\n\teigenvalues.Close()\n}\n\nfunc TestPCABackProject(t *testing.T) {\n\tdata := NewMatWithSize(3, 1, MatTypeCV32F)\n\tdefer data.Close()\n\tdata.SetFloatAt(0, 0, float32(-5))\n\tdata.SetFloatAt(1, 0, float32(0))\n\tdata.SetFloatAt(2, 0, float32(-10))\n\n\tmean := NewMatWithSize(1, 4, MatTypeCV32F)\n\tdefer mean.Close()\n\tmean.SetFloatAt(0, 0, float32(2))\n\tmean.SetFloatAt(0, 1, float32(4))\n\tmean.SetFloatAt(0, 2, float32(4))\n\tmean.SetFloatAt(0, 3, float32(8))\n\n\tvectors := NewMatWithSizeFromScalar(NewScalar(0, 0, 0, 0), 1, 4, MatTypeCV32F)\n\tdefer vectors.Close()\n\tvectors.SetFloatAt(0, 0, float32(0.2))\n\tvectors.SetFloatAt(0, 1, float32(0.4))\n\tvectors.SetFloatAt(0, 2, float32(0.4))\n\tvectors.SetFloatAt(0, 3, float32(0.8))\n\n\tresult := NewMat()\n\tdefer result.Close()\n\n\tPCABackProject(data, mean, vectors, &result)\n\tif result.Empty() {\n\t\tt.Error(\"PCABackProject should not have empty result.\")\n\t}\n}\n\nfunc TestPCACompute(t *testing.T) {\n\tsrc := NewMatWithSize(10, 10, MatTypeCV32F)\n\t// Set some source data so the PCA is done on a non-zero matrix.\n\tsrc.SetFloatAt(0, 0, 17)\n\tsrc.SetFloatAt(2, 1, 5)\n\tsrc.SetFloatAt(9, 9, 25)\n\tmean := NewMat()\n\teigenvectors := NewMat()\n\teigenvalues := NewMat()\n\tmaxComponents := 2\n\tPCACompute(src, &mean, &eigenvectors, &eigenvalues, maxComponents)\n\tif mean.Empty() || eigenvectors.Empty() || eigenvalues.Empty() {\n\t\tt.Error(\"TestPCACompute should not have empty eigenvectors or eigenvalues.\")\n\t}\n\tif eigenvectors.Rows() > maxComponents {\n\t\tt.Errorf(\"TestPCACompute unexpected numComponents, got=%d, want<=%d\", eigenvectors.Rows(), maxComponents)\n\t}\n\tsrc.Close()\n\tmean.Close()\n\teigenvectors.Close()\n\teigenvalues.Close()\n}\n\nfunc TestPCAProject(t *testing.T) {\n\tdata := NewMatWithSize(3, 4, MatTypeCV32F)\n\tdefer data.Close()\n\tdata.SetFloatAt(0, 0, float32(1))\n\tdata.SetFloatAt(0, 1, float32(2))\n\tdata.SetFloatAt(0, 2, float32(2))\n\tdata.SetFloatAt(0, 3, float32(4))\n\tdata.SetFloatAt(1, 0, float32(2))\n\tdata.SetFloatAt(1, 1, float32(4))\n\tdata.SetFloatAt(1, 2, float32(4))\n\tdata.SetFloatAt(1, 3, float32(8))\n\tdata.SetFloatAt(2, 0, float32(0))\n\tdata.SetFloatAt(2, 1, float32(0))\n\tdata.SetFloatAt(2, 2, float32(0))\n\tdata.SetFloatAt(2, 3, float32(0))\n\n\tmean := NewMatWithSize(1, 4, MatTypeCV32F)\n\tdefer mean.Close()\n\tmean.SetFloatAt(0, 0, float32(2))\n\tmean.SetFloatAt(0, 1, float32(4))\n\tmean.SetFloatAt(0, 2, float32(4))\n\tmean.SetFloatAt(0, 3, float32(8))\n\n\tvectors := NewMatWithSizeFromScalar(NewScalar(0, 0, 0, 0), 1, 4, MatTypeCV32F)\n\tdefer vectors.Close()\n\tvectors.SetFloatAt(0, 0, float32(0.2))\n\tvectors.SetFloatAt(0, 1, float32(0.4))\n\tvectors.SetFloatAt(0, 2, float32(0.4))\n\tvectors.SetFloatAt(0, 3, float32(0.8))\n\n\tresult := NewMat()\n\tdefer result.Close()\n\n\tPCAProject(data, mean, vectors, &result)\n\tif result.Empty() {\n\t\tt.Error(\"PCABackProject should not have empty result.\")\n\t}\n}\n\nfunc TestPSNR(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadColor)\n\tif src.Empty() {\n\t\tt.Error(\"Invalid read of Source Mat in PSNR test\")\n\t}\n\tdefer src.Close()\n\n\tresult := PSNR(src, src)\n\tif result == 0 {\n\t\tt.Error(\"Unexpected PSNR of 0\")\n\t}\n}\n\nfunc TestSVBackSubst(t *testing.T) {\n\tw := NewMatWithSizeFromScalar(NewScalar(2, 0, 0, 0), 2, 2, MatTypeCV32F)\n\tdefer w.Close()\n\n\tu := NewMatWithSizeFromScalar(NewScalar(4, 0, 0, 0), 2, 2, MatTypeCV32F)\n\tdefer u.Close()\n\n\tvt := NewMatWithSizeFromScalar(NewScalar(2, 0, 0, 0), 2, 2, MatTypeCV32F)\n\tdefer vt.Close()\n\n\trhs := NewMatWithSizeFromScalar(NewScalar(1, 0, 0, 0), 2, 2, MatTypeCV32F)\n\tdefer rhs.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tSVBackSubst(w, u, vt, rhs, &dst)\n\tif dst.Empty() {\n\t\tt.Error(\"SVBackSubst should not have empty result.\")\n\t}\n}\n\nfunc TestSVDecomp(t *testing.T) {\n\tsrc := NewMatWithSize(1, 4, MatTypeCV32F)\n\tdefer src.Close()\n\tsrc.SetFloatAt(0, 0, float32(1))\n\tsrc.SetFloatAt(0, 1, float32(4))\n\tsrc.SetFloatAt(0, 2, float32(8))\n\tsrc.SetFloatAt(0, 3, float32(6))\n\n\tw := NewMat()\n\tdefer w.Close()\n\n\tu := NewMat()\n\tdefer u.Close()\n\n\tvt := NewMat()\n\tdefer vt.Close()\n\n\tSVDecomp(src, &w, &u, &vt)\n\tif w.Empty() || u.Empty() || vt.Empty() {\n\t\tt.Error(\"SVDecomp should not have empty results.\")\n\t}\n}\n\nfunc TestMatExp(t *testing.T) {\n\tsrc := NewMatWithSize(10, 10, MatTypeCV32F)\n\tdst := NewMat()\n\tExp(src, &dst)\n\tif dst.Empty() {\n\t\tt.Error(\"TestExp dst should not be empty.\")\n\t}\n\tsrc.Close()\n\tdst.Close()\n}\n\nfunc TestMatExtractChannel(t *testing.T) {\n\tsrc := NewMatWithSize(10, 10, MatTypeCV32F+MatChannels3)\n\tdst := NewMat()\n\tExtractChannel(src, &dst, 1)\n\tif dst.Empty() {\n\t\tt.Error(\"TestExtractChannel dst should not be empty.\")\n\t}\n\tsrc.Close()\n\tdst.Close()\n}\n\nfunc TestMatFindNonZero(t *testing.T) {\n\tsrc := NewMatWithSize(10, 10, MatTypeCV8U)\n\tdefer src.Close()\n\tsrc.SetFloatAt(3, 3, 17)\n\tsrc.SetFloatAt(4, 4, 17)\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tFindNonZero(src, &dst)\n\n\tif dst.Empty() {\n\t\tt.Error(\"TestMatFindNonZero dst should not be empty.\")\n\t}\n\tif dst.Rows() != 2*2 {\n\t\tt.Error(\"TestMatFindNonZero didn't find all nonzero locations.\")\n\t}\n}\n\nfunc TestMatFlip(t *testing.T) {\n\tsrc := NewMatWithSize(10, 10, MatTypeCV32F)\n\tdefer src.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tFlip(src, &dst, 0)\n\n\tif dst.Empty() {\n\t\tt.Error(\"TestMatFlip dst should not be empty.\")\n\t}\n\tif dst.Rows() != src.Rows() {\n\t\tt.Error(\"TestMatFlip src and dst size should be same.\")\n\t}\n}\n\nfunc TestMatPhase(t *testing.T) {\n\tx := NewMatFromScalar(NewScalar(1.2, 2.3, 3.4, 4.5), MatTypeCV32F)\n\tdefer x.Close()\n\n\ty := NewMatFromScalar(NewScalar(5.6, 6.7, 7.8, 8.9), MatTypeCV32F)\n\tdefer y.Close()\n\n\tangle := NewMatWithSize(4, 5, MatTypeCV32F)\n\tdefer angle.Close()\n\n\tPhase(x, y, &angle, false)\n\n\tif angle.Empty() {\n\t\tt.Error(\"TestMatPhase angle should not be empty.\")\n\t}\n\n\tif angle.Rows() != x.Rows() {\n\t\tt.Error(\"TestMatPhase x and angle size should be same.\")\n\t}\n}\n\nfunc TestMatGemm(t *testing.T) {\n\tsrc1 := NewMatWithSize(3, 4, MatTypeCV32F)\n\tdefer src1.Close()\n\n\tsrc2 := NewMatWithSize(4, 3, MatTypeCV32F)\n\tdefer src2.Close()\n\n\tsrc3 := NewMat()\n\tdefer src3.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tGemm(src1, src2, 1, src3, 0, &dst, 0)\n\n\tif dst.Empty() {\n\t\tt.Error(\"Gemm dst should not be empty.\")\n\t}\n\tif dst.Rows() != src1.Rows() {\n\t\tt.Error(\"Gemm src and dst size should be same.\")\n\t}\n}\n\nfunc TestMatHconcat(t *testing.T) {\n\tsrc := NewMatWithSize(10, 10, MatTypeCV32F)\n\tdefer src.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tHconcat(src, src, &dst)\n\n\tif dst.Empty() {\n\t\tt.Error(\"TestMatHconcat dst should not be empty.\")\n\t}\n\tif dst.Cols() != 2*src.Cols() {\n\t\tt.Error(\"TestMatHconcat dst.Cols should be 2 x src.Cols.\")\n\t}\n}\n\nfunc TestMatVconcat(t *testing.T) {\n\tsrc := NewMatWithSize(10, 10, MatTypeCV32F)\n\tdefer src.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tVconcat(src, src, &dst)\n\n\tif dst.Empty() {\n\t\tt.Error(\"TestMatVconcat dst should not be empty.\")\n\t}\n\tif dst.Rows() != 2*src.Rows() {\n\t\tt.Error(\"TestMatVconcat dst.Cols should be 2 x src.Rows().\")\n\t}\n}\n\nfunc TestRotate(t *testing.T) {\n\tsrc := NewMatWithSize(1, 2, MatTypeCV64F)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tRotate(src, &dst, Rotate90Clockwise)\n\tif dst.Rows() != 2 {\n\t\tt.Errorf(\"expected rows: %d got %d\", src.Cols(), dst.Rows())\n\t}\n\n\tdst2src := NewMat()\n\tdefer dst2src.Close()\n\n\tRotate(dst, &dst2src, Rotate90CounterClockwise)\n\tif dst2src.Rows() != 1 {\n\t\tt.Errorf(\"expected rows: %d got %d\", src.Rows(), dst2src.Rows())\n\t}\n}\n\nfunc TestMatIdct(t *testing.T) {\n\tsrc := NewMatWithSize(4, 4, MatTypeCV32F)\n\tdefer src.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tIDCT(src, &dst, 0)\n\tif dst.Empty() {\n\t\tt.Error(\"Idct dst should not be empty.\")\n\t}\n\tif dst.Rows() != src.Rows() {\n\t\tt.Error(\"Idct src and dst size should be same.\")\n\t}\n}\n\nfunc TestMatIdft(t *testing.T) {\n\tsrc := NewMatWithSize(4, 4, MatTypeCV32F)\n\tdefer src.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tIDFT(src, &dst, 0, 0)\n\tif dst.Empty() {\n\t\tt.Error(\"Idct dst should not be empty.\")\n\t}\n\tif dst.Rows() != src.Rows() {\n\t\tt.Error(\"Idct src and dst size should be same.\")\n\t}\n}\n\nfunc TestMatInsertChannel(t *testing.T) {\n\tsrc := NewMatWithSize(4, 4, MatTypeCV8U)\n\tdefer src.Close()\n\n\tdst := NewMatWithSize(4, 4, MatTypeCV8UC3)\n\tdefer dst.Close()\n\n\tInsertChannel(src, &dst, 1)\n\tif dst.Channels() != 3 {\n\t\tt.Error(\"TestMatInsertChannel dst should change the channel count\")\n\t}\n}\n\nfunc TestMatInvert(t *testing.T) {\n\tsrc := NewMatWithSize(4, 4, MatTypeCV32F) // only implemented for symm. Mats\n\tdefer src.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tInvert(src, &dst, SolveDecompositionLu)\n\tif dst.Empty() {\n\t\tt.Error(\"Invert dst should not be empty.\")\n\t}\n}\n\nfunc TestKMeans(t *testing.T) {\n\tsrc := NewMatWithSize(4, 4, MatTypeCV32F) // only implemented for symm. Mats\n\tdefer src.Close()\n\n\tbestLabels := NewMat()\n\tdefer bestLabels.Close()\n\n\tcenters := NewMat()\n\tdefer centers.Close()\n\n\tcriteria := NewTermCriteria(Count, 10, 1.0)\n\tKMeans(src, 2, &bestLabels, criteria, 2, KMeansRandomCenters, &centers)\n\tif bestLabels.Empty() {\n\t\tt.Error(\"bla\")\n\t}\n}\n\nfunc TestKMeansPoints(t *testing.T) {\n\tpoints := []image.Point{\n\t\timage.Pt(0, 0),\n\t\timage.Pt(1, 1),\n\t}\n\n\tpv := NewPointVectorFromPoints(points)\n\tdefer pv.Close()\n\n\tbestLabels := NewMat()\n\tdefer bestLabels.Close()\n\tcenters := NewMat()\n\tdefer centers.Close()\n\n\tcriteria := NewTermCriteria(Count, 10, 1.0)\n\tKMeansPoints(pv, 2, &bestLabels, criteria, 2, KMeansRandomCenters, &centers)\n\tif bestLabels.Empty() || bestLabels.Size()[0] != len(points) {\n\t\tt.Error(\"Labels is not proper\")\n\t}\n}\n\nfunc TestMatLog(t *testing.T) {\n\tsrc := NewMatWithSize(4, 3, MatTypeCV32F)\n\tdefer src.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tLog(src, &dst)\n\tif dst.Empty() {\n\t\tt.Error(\"Log dst should not be empty.\")\n\t}\n}\n\nfunc TestMatMagnitude(t *testing.T) {\n\tsrc1 := NewMatWithSize(4, 4, MatTypeCV32F)\n\tdefer src1.Close()\n\tsrc2 := NewMatWithSize(4, 4, MatTypeCV32F)\n\tdefer src2.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tMagnitude(src1, src2, &dst)\n\tif dst.Empty() {\n\t\tt.Error(\"Magnitude dst should not be empty.\")\n\t}\n}\n\nfunc TestMatMahalanobis(t *testing.T) {\n\tsrc := NewMatWithSize(10, 10, MatTypeCV32F)\n\tdefer src.Close()\n\n\tRandU(&src, Scalar{Val1: -128}, Scalar{Val1: 128})\n\n\ticovar := NewMatWithSize(10, 10, MatTypeCV32F)\n\tdefer icovar.Close()\n\tmean := NewMatWithSize(1, 10, MatTypeCV32F)\n\tdefer mean.Close()\n\n\tCalcCovarMatrix(src, &icovar, &mean, CovarRows|CovarNormal, MatTypeCV32F)\n\ticovar.Inv()\n\n\tline1 := src.Row(0)\n\tdefer line1.Close()\n\tline2 := src.Row(1)\n\tdefer line2.Close()\n\n\tresult := Mahalanobis(line1, line2, icovar)\n\tif result == 0 {\n\t\tt.Error(\"Mahalanobis result should not be empty.\")\n\t}\n}\n\nfunc TestMulTransposed(t *testing.T) {\n\tsrc := Eye(10, 10, MatTypeCV32FC1)\n\tdefer src.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tMulTransposed(src, &dst, true)\n\tif dst.Empty() {\n\t\tt.Error(\"MulTransposed dst should not be empty.\")\n\t}\n}\n\nfunc TestMatMax(t *testing.T) {\n\tsrc1 := NewMatWithSize(4, 4, MatTypeCV32F)\n\tdefer src1.Close()\n\tsrc2 := NewMatWithSize(4, 4, MatTypeCV32F)\n\tdefer src2.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tMax(src1, src2, &dst)\n\tif dst.Empty() {\n\t\tt.Error(\"Max dst should not be empty.\")\n\t}\n}\n\nfunc TestMatMin(t *testing.T) {\n\tsrc1 := NewMatWithSize(4, 4, MatTypeCV32F)\n\tdefer src1.Close()\n\tsrc2 := NewMatWithSize(4, 4, MatTypeCV32F)\n\tdefer src2.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tMin(src1, src2, &dst)\n\tif dst.Empty() {\n\t\tt.Error(\"Min dst should not be empty.\")\n\t}\n}\n\nfunc TestMatMinMaxIdx(t *testing.T) {\n\tsrc := NewMatWithSize(10, 10, MatTypeCV32F)\n\tdefer src.Close()\n\tsrc.SetFloatAt(3, 3, 17)\n\tsrc.SetFloatAt(4, 4, 16)\n\n\tminVal, maxVal, _, _ := MinMaxIdx(src)\n\n\tif minVal != 0 {\n\t\tt.Error(\"TestMatMinMaxIdx minVal should be 0.\")\n\t}\n\tif maxVal != 17 {\n\t\tt.Errorf(\"TestMatMinMaxIdx maxVal should be 17, was %f\", maxVal)\n\t}\n}\n\nfunc TestMixChannels(t *testing.T) {\n\tbgra := NewMatWithSizeFromScalar(NewScalar(255, 0, 0, 255), 10, 10, MatTypeCV8UC4)\n\tdefer bgra.Close()\n\tbgr := NewMatWithSize(bgra.Rows(), bgra.Cols(), MatTypeCV8UC3)\n\tdefer bgr.Close()\n\talpha := NewMatWithSize(bgra.Rows(), bgra.Cols(), MatTypeCV8UC1)\n\tdefer alpha.Close()\n\n\tdst := []Mat{bgr, alpha}\n\n\t// bgra[0] -> bgr[2], bgra[1] -> bgr[1],\n\t// bgra[2] -> bgr[0], bgra[3] -> alpha[0]\n\tfromTo := []int{0, 2, 1, 1, 2, 0, 3, 3}\n\n\tMixChannels([]Mat{bgra}, dst, fromTo)\n\n\tbgrChans := Split(bgr)\n\tscalarByte := []byte{0, 0, 255}\n\tfor c := 0; c < bgr.Channels(); c++ {\n\t\tfor i := 0; i < bgr.Rows(); i++ {\n\t\t\tfor j := 0; j < bgr.Cols(); j++ {\n\t\t\t\tif s := bgrChans[c].GetUCharAt(i, j); s != scalarByte[c] {\n\t\t\t\t\tt.Errorf(\"TestMixChannels incorrect bgr scalar: %v\\n\", s)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, ch := range bgrChans {\n\t\tch.Close()\n\t}\n\n\talphaChans := Split(alpha)\n\tscalarByte = []byte{255}\n\tfor c := 0; c < alpha.Channels(); c++ {\n\t\tfor i := 0; i < alpha.Rows(); i++ {\n\t\t\tfor j := 0; j < alpha.Cols(); j++ {\n\t\t\t\tif s := alphaChans[c].GetUCharAt(i, j); s != scalarByte[c] {\n\t\t\t\t\tt.Errorf(\"TestMixChannels incorrect alpha scalar: %v\\n\", s)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor _, ch := range alphaChans {\n\t\tch.Close()\n\t}\n}\n\nfunc TestGetVecfAt(t *testing.T) {\n\tvar cases = []struct {\n\t\tm            Mat\n\t\texpectedSize int\n\t}{\n\t\t{NewMatWithSize(1, 1, MatTypeCV32FC1), 1},\n\t\t{NewMatWithSize(1, 1, MatTypeCV32FC2), 2},\n\t\t{NewMatWithSize(1, 1, MatTypeCV32FC3), 3},\n\t\t{NewMatWithSize(1, 1, MatTypeCV32FC4), 4},\n\t}\n\n\tfor _, c := range cases {\n\t\tvec := c.m.GetVecfAt(0, 0)\n\t\tif len := len(vec); len != c.expectedSize {\n\t\t\tt.Errorf(\"TestGetVecfAt: expected %d, got: %d.\", c.expectedSize, len)\n\t\t}\n\t\tc.m.Close()\n\t}\n}\n\nfunc TestGetVecdAt(t *testing.T) {\n\tvar cases = []struct {\n\t\tm            Mat\n\t\texpectedSize int\n\t}{\n\t\t{NewMatWithSize(1, 1, MatTypeCV64FC1), 1},\n\t\t{NewMatWithSize(1, 1, MatTypeCV64FC2), 2},\n\t\t{NewMatWithSize(1, 1, MatTypeCV64FC3), 3},\n\t\t{NewMatWithSize(1, 1, MatTypeCV64FC4), 4},\n\t}\n\n\tfor _, c := range cases {\n\t\tvec := c.m.GetVecdAt(0, 0)\n\t\tif len := len(vec); len != c.expectedSize {\n\t\t\tt.Errorf(\"TestGetVecdAt: expected %d, got: %d.\", c.expectedSize, len)\n\t\t}\n\t\tc.m.Close()\n\t}\n}\n\nfunc TestGetVecbAt(t *testing.T) {\n\tvar cases = []struct {\n\t\tm            Mat\n\t\texpectedSize int\n\t}{\n\t\t{NewMatWithSize(1, 1, MatTypeCV8UC1), 1},\n\t\t{NewMatWithSize(1, 1, MatTypeCV8UC2), 2},\n\t\t{NewMatWithSize(1, 1, MatTypeCV8UC3), 3},\n\t\t{NewMatWithSize(1, 1, MatTypeCV8UC4), 4},\n\t}\n\n\tfor _, c := range cases {\n\t\tvec := c.m.GetVecbAt(0, 0)\n\t\tif len := len(vec); len != c.expectedSize {\n\t\t\tt.Errorf(\"TestGetVecbAt: expected %d, got: %d.\", c.expectedSize, len)\n\t\t}\n\t\tc.m.Close()\n\t}\n}\n\nfunc TestGetVeciAt(t *testing.T) {\n\tvar cases = []struct {\n\t\tm            Mat\n\t\texpectedSize int\n\t}{\n\t\t{NewMatWithSize(1, 1, MatTypeCV8UC1), 1},\n\t\t{NewMatWithSize(1, 1, MatTypeCV8UC2), 2},\n\t\t{NewMatWithSize(1, 1, MatTypeCV8UC3), 3},\n\t\t{NewMatWithSize(1, 1, MatTypeCV8UC4), 4},\n\t}\n\n\tfor _, c := range cases {\n\t\tvec := c.m.GetVeciAt(0, 0)\n\t\tif len := len(vec); len != c.expectedSize {\n\t\t\tt.Errorf(\"TestGetVeciAt: expected %d, got: %d.\", c.expectedSize, len)\n\t\t}\n\t\tc.m.Close()\n\t}\n}\n\nfunc TestGetTickFrequencyCount(t *testing.T) {\n\tfreq := GetTickFrequency()\n\tif freq == 0 {\n\t\tt.Error(\"GetTickFrequency expected non zero.\")\n\t}\n\n\tcount := GetTickCount()\n\tif count == 0 {\n\t\tt.Error(\"GetTickCount expected non zero.\")\n\t}\n}\n\nfunc TestMatT(t *testing.T) {\n\tvar q = []float32{1, 3, 2, 4}\n\tsrc := NewMatWithSize(2, 2, MatTypeCV32F)\n\tdefer src.Close()\n\tsrc.SetFloatAt(0, 0, 1)\n\tsrc.SetFloatAt(0, 1, 2)\n\tsrc.SetFloatAt(1, 0, 3)\n\tsrc.SetFloatAt(1, 1, 4)\n\n\tdst := src.T()\n\tdefer dst.Close()\n\n\tret, err := dst.DataPtrFloat32()\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\tfor i := 0; i < len(ret); i++ {\n\t\tif ret[i] != q[i] {\n\t\t\tt.Errorf(\"MatT incorrect value: %v\\n\", ret[i])\n\t\t}\n\t}\n}\n\nfunc compareImages(img0, img1 image.Image) bool {\n\tbounds0 := img0.Bounds()\n\tbounds1 := img1.Bounds()\n\tdx0 := bounds0.Dx()\n\tdy0 := bounds0.Dy()\n\tif dx0 != bounds1.Dx() || dy0 != bounds1.Dy() {\n\t\treturn false\n\t}\n\txMin0 := bounds0.Min.X\n\txMin1 := bounds1.Min.X\n\tyMin0 := bounds0.Min.Y\n\tyMin1 := bounds1.Min.Y\n\tfor i := 0; i < dx0; i++ {\n\t\tfor j := 0; j < dy0; j++ {\n\t\t\tpoint0 := img0.At(xMin0+i, yMin0+j)\n\t\t\tpoint1 := img1.At(xMin1+i, yMin1+j)\n\t\t\tr0, g0, b0, a0 := point0.RGBA()\n\t\t\tr1, g1, b1, a1 := point1.RGBA()\n\t\t\tr0 >>= 8\n\t\t\tg0 >>= 8\n\t\t\tb0 >>= 8\n\t\t\ta0 >>= 8\n\t\t\tr1 >>= 8\n\t\t\tg1 >>= 8\n\t\t\tb1 >>= 8\n\t\t\ta1 >>= 8\n\t\t\tif r0 != r1 || g0 != g1 || b0 != b1 || a0 != a1 {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t}\n\n\treturn true\n}\n\nfunc TestColRowRange(t *testing.T) {\n\tmat := NewMatWithSize(101, 102, MatTypeCV8U)\n\tdefer mat.Close()\n\tif mat.Empty() {\n\t\tt.Error(\"TestColRowRange should not be empty\")\n\t}\n\n\tif mat.Rows() != 101 {\n\t\tt.Errorf(\"TestColRowRange incorrect row count: %v\\n\", mat.Rows())\n\t}\n\n\tif mat.Cols() != 102 {\n\t\tt.Errorf(\"TestColRowRange incorrect col count: %v\\n\", mat.Cols())\n\t}\n\n\tsubmatRow := mat.RowRange(0, 50)\n\tdefer submatRow.Close()\n\tif submatRow.Rows() != 50 {\n\t\tt.Errorf(\"TestColRowRange incorrect submatRow count: %v\\n\", submatRow.Rows())\n\t}\n\n\tsubmatCols := mat.ColRange(0, 50)\n\tdefer submatCols.Close()\n\tif submatCols.Cols() != 50 {\n\t\tt.Errorf(\"TestColRowRange incorrect submatCols count: %v\\n\", submatCols.Cols())\n\t}\n}\n\nfunc TestNormWithMats(t *testing.T) {\n\tmat1 := NewMatWithSize(100, 100, MatTypeCV8UC1)\n\tdefer mat1.Close()\n\n\tmat2 := NewMatWithSize(100, 100, MatTypeCV8UC1)\n\tdefer mat2.Close()\n\n\td := NormWithMats(mat1, mat2, NormInf)\n\tif d != 0 {\n\t\tt.Fatal(\"expected 0\")\n\t}\n}\n\nfunc Test_toGoStrings(t *testing.T) {\n\tgoStrings := []string{\"foo\", \"bar\"}\n\tcStrings := toCStrings(goStrings)\n\tresult := toGoStrings(cStrings)\n\tif len(goStrings) != len(result) {\n\t\tt.Errorf(\"TesttoGoStrings failed: length of converted string is not equal to original \\n\")\n\t}\n\tfor i, s := range goStrings {\n\t\tif s != result[i] {\n\t\t\tt.Errorf(\"TesttoGoStrings failed: strings are not equal. expected=%s, actusal=%s\", s, result[i])\n\t\t}\n\t}\n}\n\nfunc TestTheRNG(t *testing.T) {\n\trng := TheRNG()\n\tif rng.p == nil {\n\t\tt.Errorf(\"got no rng\")\n\t}\n}\n\nfunc TestSetRNGSeed(t *testing.T) {\n\tSetRNGSeed(123)\n}\n\nfunc TestRNG_Fill(t *testing.T) {\n\trng := TheRNG()\n\tmat := NewMatWithSize(20, 20, MatTypeCV8UC3)\n\tdefer mat.Close()\n\trng.Fill(&mat, RNGDistNormal, 10, 20, false)\n}\n\nfunc TestRNG_Gaussian(t *testing.T) {\n\trng := TheRNG()\n\t_ = rng.Gaussian(0.5)\n}\n\nfunc TestRNG_Next(t *testing.T) {\n\trng := TheRNG()\n\t_ = rng.Next()\n}\n\nfunc TestRandN(t *testing.T) {\n\tmat := NewMatWithSize(5, 5, MatTypeCV8UC3)\n\tdefer mat.Close()\n\tRandN(&mat, NewScalar(10, 10, 10, 10), NewScalar(20, 20, 20, 20))\n}\n\nfunc TestRandShuffle(t *testing.T) {\n\tmat := NewMatWithSize(5, 5, MatTypeCV8UC3)\n\tdefer mat.Close()\n\tRandShuffle(&mat)\n}\n\nfunc TestRandShuffleWithParams(t *testing.T) {\n\tmat := NewMatWithSize(5, 5, MatTypeCV8UC3)\n\tdefer mat.Close()\n\tRandShuffleWithParams(&mat, 1, TheRNG())\n}\n\nfunc TestRandU(t *testing.T) {\n\tmat := NewMatWithSize(5, 5, MatTypeCV8UC3)\n\tdefer mat.Close()\n\tRandU(&mat, NewScalar(10, 10, 10, 10), NewScalar(20, 20, 20, 20))\n}\n\nfunc TestNewPointsVector(t *testing.T) {\n\tepv := NewPointsVector()\n\tdefer epv.Close()\n\n\tif epv.Size() != 0 {\n\t\tt.Fatal(\"expected empty pointsvector size not 0\")\n\t}\n\n\tpts := [][]image.Point{\n\t\t{\n\t\t\timage.Pt(10, 10),\n\t\t\timage.Pt(10, 20),\n\t\t\timage.Pt(20, 20),\n\t\t\timage.Pt(20, 10),\n\t\t},\n\t}\n\n\tpsv := NewPointsVectorFromPoints(pts)\n\tdefer psv.Close()\n\n\tif psv.IsNil() {\n\t\tt.Fatal(\"pointsvector pointer was nil\")\n\t}\n\n\tif psv.Size() != 1 {\n\t\tt.Fatal(\"expected pointsvector size 1\")\n\t}\n\n\tipv := psv.At(10)\n\tif !ipv.IsNil() {\n\t\tt.Fatal(\"expected pointvector nil\")\n\t}\n\n\tpv := psv.At(0)\n\tif pv.Size() != 4 {\n\t\tt.Fatal(\"expected pointvector size 4\")\n\t}\n\n\tp := pv.At(0)\n\tif p != image.Pt(10, 10) {\n\t\tt.Fatal(\"invalid At() point\")\n\t}\n\n\tp = pv.At(10)\n\tif p != image.Pt(0, 0) {\n\t\tt.Fatal(\"invalid At() point beyond range\")\n\t}\n\n\tout := psv.ToPoints()\n\tif out[0][0] != image.Pt(10, 10) {\n\t\tt.Fatal(\"invalid ToPoints() point\")\n\t}\n\n\tps := []image.Point{\n\t\timage.Pt(10, 10),\n\t\timage.Pt(10, 20),\n\t\timage.Pt(20, 20),\n\t\timage.Pt(20, 10),\n\t}\n\n\tapv := NewPointVectorFromPoints(ps)\n\tdefer apv.Close()\n\n\tpsv.Append(apv)\n\tif psv.Size() != 2 {\n\t\tt.Fatal(\"unable to append to PointsVector\")\n\t}\n}\n\nfunc TestNewPointVector(t *testing.T) {\n\tepv := NewPointVector()\n\tdefer epv.Close()\n\n\tif epv.Size() != 0 {\n\t\tt.Fatal(\"expected empty pointvector size not 0\")\n\t}\n\n\tpts := []image.Point{\n\t\timage.Pt(10, 10),\n\t\timage.Pt(10, 20),\n\t\timage.Pt(20, 20),\n\t\timage.Pt(20, 10),\n\t}\n\n\tpv := NewPointVectorFromPoints(pts)\n\tdefer pv.Close()\n\n\tif pv.IsNil() {\n\t\tt.Fatal(\"pointvector pointer was nil\")\n\t}\n\n\tif pv.Size() != 4 {\n\t\tt.Fatal(\"expected pointvector size 4\")\n\t}\n\n\tp := pv.At(0)\n\tif p != image.Pt(10, 10) {\n\t\tt.Fatal(\"invalid point\")\n\t}\n\n\tnp := image.Pt(50, 50)\n\n\tpv.Append(np)\n\tif pv.Size() != 5 {\n\t\tt.Fatal(\"unable to append to PointVector\")\n\t}\n\n\tmat := NewMatWithSize(4, 1, MatTypeCV32SC2)\n\tdefer mat.Close()\n\n\tpvm := NewPointVectorFromMat(mat)\n\tdefer pvm.Close()\n\n\tif pvm.Size() != 4 {\n\t\tt.Fatalf(\"expected size of NewPointVectorFromMat to be 4, was %d\", pvm.Size())\n\t}\n}\n\nfunc TestNewPoint2fVector(t *testing.T) {\n\tepv := NewPoint2fVector()\n\tdefer epv.Close()\n\n\tif epv.Size() != 0 {\n\t\tt.Fatal(\"expected empty pointvector size not 0\")\n\t}\n\n\tpts := []Point2f{\n\t\t{10.0, 10.0},\n\t\t{10.0, 20.0},\n\t\t{20.5, 21.5},\n\t\t{25.5, 30.5},\n\t}\n\n\tpv := NewPoint2fVectorFromPoints(pts)\n\tdefer pv.Close()\n\n\tif pv.IsNil() {\n\t\tt.Fatal(\"point2fvector pointer was nil\")\n\t}\n\n\tif pv.Size() != 4 {\n\t\tt.Fatal(\"expected point2fvector size 4\")\n\t}\n\n\tp := pv.At(0)\n\twant := Point2f{10.0, 10.0}\n\tif p != want {\n\t\tt.Fatal(\"invalid point\")\n\t}\n\n\tp = pv.At(10)\n\tnopoint := Point2f{0, 0}\n\tif p != nopoint {\n\t\tt.Fatal(\"invalid At() point beyond range\")\n\t}\n\n\tout := pv.ToPoints()\n\tif len(out) != 4 && out[0] != want {\n\t\tt.Fatal(\"invalid ToPoints()\")\n\t}\n\n\tmat := NewMatWithSize(4, 1, MatTypeCV32FC2)\n\tdefer mat.Close()\n\n\tpvm := NewPoint2fVectorFromMat(mat)\n\tdefer pvm.Close()\n\n\tif pvm.Size() != 4 {\n\t\tt.Fatalf(\"expected size of NewPoint2fVectorFromMat to be 4, was %d\", pvm.Size())\n\t}\n}\n\nfunc TestNewPoints2fVector(t *testing.T) {\n\tepv := NewPoints2fVector()\n\tdefer epv.Close()\n\n\tif epv.Size() != 0 {\n\t\tt.Fatal(\"expected empty points2fvector size not 0\")\n\t}\n\n\tpts := [][]Point2f{\n\t\t{\n\t\t\tNewPoint2f(10.0, 10.0),\n\t\t\tNewPoint2f(10.0, 20.0),\n\t\t\tNewPoint2f(20.0, 20.0),\n\t\t\tNewPoint2f(20.0, 10.0),\n\t\t},\n\t}\n\n\tpsv := NewPoints2fVectorFromPoints(pts)\n\tdefer psv.Close()\n\n\tif psv.IsNil() {\n\t\tt.Fatal(\"points2fvector pointer was nil\")\n\t}\n\n\tif psv.Size() != 1 {\n\t\tt.Fatal(\"expected points2fvector size 1\")\n\t}\n\n\tipv := psv.At(10)\n\tif !ipv.IsNil() {\n\t\tt.Fatal(\"expected pointvector nil\")\n\t}\n\n\tpv := psv.At(0)\n\tif pv.Size() != 4 {\n\t\tt.Fatal(\"expected pointvector size 4\")\n\t}\n\n\tp := pv.At(0)\n\tif p != NewPoint2f(10.0, 10.0) {\n\t\tt.Fatal(\"invalid At() point\")\n\t}\n\n\tp = pv.At(10)\n\tif p != NewPoint2f(0, 0) {\n\t\tt.Fatal(\"invalid At() point beyond range\")\n\t}\n\n\tout := psv.ToPoints()\n\tif out[0][0] != NewPoint2f(10.0, 10.0) {\n\t\tt.Fatal(\"invalid ToPoints() point\")\n\t}\n\n\tps := []Point2f{\n\t\tNewPoint2f(10, 10),\n\t\tNewPoint2f(10, 20),\n\t\tNewPoint2f(20, 20),\n\t\tNewPoint2f(20, 10),\n\t}\n\n\tapv := NewPoint2fVectorFromPoints(ps)\n\tdefer apv.Close()\n\n\tpsv.Append(apv)\n\tif psv.Size() != 2 {\n\t\tt.Fatal(\"unable to append to Points2fVector\")\n\t}\n}\n\nfunc TestNewPoint3fVector(t *testing.T) {\n\tepv := NewPoint3fVector()\n\tdefer epv.Close()\n\n\tif epv.Size() != 0 {\n\t\tt.Fatal(\"expected empty pointvector size not 0\")\n\t}\n\n\tpts := []Point3f{\n\t\t{10.0, 10.0, 0.1},\n\t\t{10.0, 20.0, 1.0},\n\t\t{20.5, 21.5, 2.0},\n\t}\n\n\tpv := NewPoint3fVectorFromPoints(pts)\n\tdefer pv.Close()\n\n\tpv.Append(NewPoint3f(25.5, 30.5, 3.0))\n\n\tif pv.IsNil() {\n\t\tt.Fatal(\"point3fvector pointer was nil\")\n\t}\n\n\tif pv.Size() != 4 {\n\t\tt.Fatal(\"expected point3fvector size 4\")\n\t}\n\n\tp := pv.At(0)\n\twant := Point3f{10.0, 10.0, 0.1}\n\tif p != want {\n\t\tt.Fatal(\"invalid point\")\n\t}\n\n\twant2 := NewPoint3f(25.5, 30.5, 3.0)\n\tif pv.At(3) != want2 {\n\t\tt.Fatal(\"fail to append point to Point3fVector\")\n\t}\n\n\tp = pv.At(10)\n\tnopoint := Point3f{0, 0, 0}\n\tif p != nopoint {\n\t\tt.Fatal(\"invalid At() point beyond range\")\n\t}\n\n\tout := pv.ToPoints()\n\tif len(out) != 4 && out[0] != want {\n\t\tt.Fatal(\"invalid ToPoints()\")\n\t}\n\n\tmat := NewMatWithSize(4, 1, MatTypeCV32FC3)\n\tdefer mat.Close()\n\n\tpvm := NewPoint3fVectorFromMat(mat)\n\tdefer pvm.Close()\n\n\tif pvm.Size() != 4 {\n\t\tt.Fatalf(\"expected size of NewPoint3fVectorFromMat to be 4, was %d\", pvm.Size())\n\t}\n}\n\nfunc TestNewPoints3fVector(t *testing.T) {\n\tepv := NewPoints3fVector()\n\tdefer epv.Close()\n\n\tif epv.Size() != 0 {\n\t\tt.Fatal(\"expected empty points3fvector size not 0\")\n\t}\n\n\tpts := [][]Point3f{\n\t\t{\n\t\t\tNewPoint3f(10.0, 10.0, 0.1),\n\t\t\tNewPoint3f(10.0, 20.0, 0.2),\n\t\t\tNewPoint3f(20.0, 20.0, 0.3),\n\t\t\tNewPoint3f(20.0, 10.0, 0.4),\n\t\t},\n\t}\n\n\tpsv := NewPoints3fVectorFromPoints(pts)\n\tdefer psv.Close()\n\n\tif psv.IsNil() {\n\t\tt.Fatal(\"points3fvector pointer was nil\")\n\t}\n\n\tif psv.Size() != 1 {\n\t\tt.Fatal(\"expected points3fvector size 1\")\n\t}\n\n\tipv := psv.At(10)\n\tif !ipv.IsNil() {\n\t\tt.Fatal(\"expected pointvector nil\")\n\t}\n\n\tpv := psv.At(0)\n\tif pv.Size() != 4 {\n\t\tt.Fatal(\"expected pointvector size 4\")\n\t}\n\n\tp := pv.At(0)\n\tif p != NewPoint3f(10.0, 10.0, 0.1) {\n\t\tt.Fatal(\"invalid At() point\")\n\t}\n\n\tp = pv.At(10)\n\tif p != NewPoint3f(0, 0, 0) {\n\t\tt.Fatal(\"invalid At() point beyond range\")\n\t}\n\n\tout := psv.ToPoints()\n\tif out[0][0] != NewPoint3f(10.0, 10.0, 0.1) {\n\t\tt.Fatal(\"invalid ToPoints() point\")\n\t}\n\n\tps := []Point3f{\n\t\tNewPoint3f(10, 10, 0.1),\n\t\tNewPoint3f(10, 20, 0.2),\n\t\tNewPoint3f(20, 20, 0.3),\n\t\tNewPoint3f(20, 10, 0.4),\n\t}\n\n\tapv := NewPoint3fVectorFromPoints(ps)\n\tdefer apv.Close()\n\n\tpsv.Append(apv)\n\tif psv.Size() != 2 {\n\t\tt.Fatal(\"unable to append to Points3fVector\")\n\t}\n}\n\nfunc TestElemSize(t *testing.T) {\n\tm1 := NewMat()\n\tdefer m1.Close()\n\tif m1.ElemSize() != 0 {\n\t\tt.Error(\"incorrect element size\")\n\t}\n\n\tm2 := NewMatWithSize(2, 2, MatTypeCV16S)\n\tdefer m2.Close()\n\tif m2.ElemSize() != 2 {\n\t\tt.Error(\"incorrect element size of MatTypeCV16S\")\n\t}\n\n\tm3 := NewMatWithSize(2, 2, MatTypeCV16SC3)\n\tdefer m3.Close()\n\tif m3.ElemSize() != 6 {\n\t\tt.Error(\"incorrect element size of MatTypeCV16SC3\")\n\t}\n\n\tm4 := NewMatWithSize(2, 2, MatTypeCV32SC4)\n\tdefer m4.Close()\n\tif m4.ElemSize() != 16 {\n\t\tt.Error(\"incorrect element size of MatTypeCV32SC4\")\n\t\treturn\n\t}\n}\n\nfunc TestSetThreadNumber(t *testing.T) {\n\toriginal := GetNumThreads()\n\n\tSetNumThreads(-1)\n\tif num := GetNumThreads(); num != original {\n\t\tt.Errorf(\"incorrect number of threads, got %d, want %d\", num, original)\n\t}\n\n\tSetNumThreads(0)\n\tif num := GetNumThreads(); num < 1 {\n\t\tt.Errorf(\"incorrect number of threads, got %d, want at least 1\", num)\n\t}\n\n\tSetNumThreads(1)\n\tif num := GetNumThreads(); num != 1 {\n\t\tt.Errorf(\"incorrect number of threads, got %d, want %d\", num, 1)\n\t}\n\n\tSetNumThreads(original)\n}\n\nfunc TestMinMaxLoc(t *testing.T) {\n\tinput := NewMatWithSize(2, 2, MatTypeCV32F)\n\tdefer input.Close()\n\tinput.SetFloatAt(0, 0, 1)\n\tinput.SetFloatAt(0, 1, 2)\n\tinput.SetFloatAt(1, 0, 3)\n\tinput.SetFloatAt(1, 1, 4)\n\tminVal, maxVal, minLoc, maxLoc := MinMaxLoc(input)\n\n\twantMinVal, wantMaxValue := float32(1.0), float32(4.0)\n\tif minVal != wantMinVal {\n\t\tt.Errorf(\"minVal got: %v, want %v\", minVal, wantMinVal)\n\t}\n\tif maxVal != wantMaxValue {\n\t\tt.Errorf(\"maxVal got: %v, want %v\", maxVal, wantMaxValue)\n\t}\n\twantMinLoc, wantMaxLoc := image.Point{Y: 0, X: 0}, image.Point{Y: 1, X: 1}\n\tif minLoc != wantMinLoc {\n\t\tt.Errorf(\"minLoc got: %v, want %v\", minLoc, wantMinLoc)\n\t}\n\tif maxLoc != wantMaxLoc {\n\t\tt.Errorf(\"maxLoc got: %v, want %v\", maxLoc, wantMaxLoc)\n\t}\n}\n\nfunc TestMinMaxLocWithMask(t *testing.T) {\n\tinput := NewMatWithSize(2, 2, MatTypeCV32F)\n\tdefer input.Close()\n\tinput.SetFloatAt(0, 0, 1)\n\tinput.SetFloatAt(0, 1, 2)\n\tinput.SetFloatAt(1, 0, 3)\n\tinput.SetFloatAt(1, 1, 4)\n\tmask := NewMatWithSize(2, 2, MatTypeCV8U)\n\tdefer mask.Close()\n\tmask.SetUCharAt(1, 0, 1)\n\tmask.SetUCharAt(1, 1, 1)\n\tminVal, maxVal, minLoc, maxLoc := MinMaxLocWithMask(input, mask)\n\n\twantMinVal, wantMaxValue := float32(3.0), float32(4.0)\n\tif minVal != wantMinVal {\n\t\tt.Errorf(\"minVal got: %v, want %v\", minVal, wantMinVal)\n\t}\n\tif maxVal != wantMaxValue {\n\t\tt.Errorf(\"maxVal got: %v, want %v\", maxVal, wantMaxValue)\n\t}\n\twantMinLoc, wantMaxLoc := image.Point{Y: 1, X: 0}, image.Point{Y: 1, X: 1}\n\tif minLoc != wantMinLoc {\n\t\tt.Errorf(\"minLoc got: %v, want %v\", minLoc, wantMinLoc)\n\t}\n\tif maxLoc != wantMaxLoc {\n\t\tt.Errorf(\"maxLoc got: %v, want %v\", maxLoc, wantMaxLoc)\n\t}\n}\n\nfunc TestNewRotatedRect(t *testing.T) {\n\n\trr := NewRotatedRect(image.Pt(1, 1), 10, 10, 75.0)\n\tif rr.Angle != 75.0 {\n\t\tt.Errorf(\"NewRotatedRect not working as intended\")\n\t}\n\n}\n\nfunc TestNewRotatedRect2f(t *testing.T) {\n\n\tpts := Point2f{\n\t\tX: 1.5,\n\t\tY: 1.5,\n\t}\n\n\trr := NewRotatedRect2f(pts, 10.5, 10.5, 75.0)\n\tif rr.Angle != 75.0 {\n\t\tt.Errorf(\"NewRotatedRect not working as intended\")\n\t}\n\n}\n"
        },
        {
          "name": "cuda",
          "type": "tree",
          "content": null
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "dnn.cpp",
          "type": "blob",
          "size": 11.1875,
          "content": "#include \"dnn.h\"\n\nNet Net_ReadNet(const char* model, const char* config) {\n    Net n = new cv::dnn::Net(cv::dnn::readNet(model, config));\n    return n;\n}\n\nNet Net_ReadNetBytes(const char* framework, struct ByteArray model, struct ByteArray config) {\n    std::vector<uchar> modelv(model.data, model.data + model.length);\n    std::vector<uchar> configv(config.data, config.data + config.length);\n    Net n = new cv::dnn::Net(cv::dnn::readNet(framework, modelv, configv));\n    return n;\n}\n\nNet Net_ReadNetFromCaffe(const char* prototxt, const char* caffeModel) {\n    Net n = new cv::dnn::Net(cv::dnn::readNetFromCaffe(prototxt, caffeModel));\n    return n;\n}\n\nNet Net_ReadNetFromCaffeBytes(struct ByteArray prototxt, struct ByteArray caffeModel) {\n    Net n = new cv::dnn::Net(cv::dnn::readNetFromCaffe(prototxt.data, prototxt.length,\n                            caffeModel.data, caffeModel.length));\n    return n;\n}\n\nNet Net_ReadNetFromTensorflow(const char* model) {\n    Net n = new cv::dnn::Net(cv::dnn::readNetFromTensorflow(model));\n    return n;\n}\n\nNet Net_ReadNetFromTensorflowBytes(struct ByteArray model) {\n    Net n = new cv::dnn::Net(cv::dnn::readNetFromTensorflow(model.data, model.length));\n    return n;\n}\n\nNet Net_ReadNetFromTorch(const char* model) {\n    Net n = new cv::dnn::Net(cv::dnn::readNetFromTorch(model));\n    return n;\n}\n\nNet Net_ReadNetFromONNX(const char* model) {\n    Net n = new cv::dnn::Net(cv::dnn::readNetFromONNX(model));\n    return n;\n}\n\nNet Net_ReadNetFromONNXBytes(struct ByteArray model) {\n    Net n = new cv::dnn::Net(cv::dnn::readNetFromONNX(model.data, model.length));\n    return n;\n}\n\nvoid Net_Close(Net net) {\n    delete net;\n}\n\nbool Net_Empty(Net net) {\n    return net->empty();\n}\n\nvoid Net_SetInput(Net net, Mat blob, const char* name) {\n    net->setInput(*blob, name);\n}\n\nMat Net_Forward(Net net, const char* outputName) {\n    return new cv::Mat(net->forward(outputName));\n}\n\nvoid Net_ForwardLayers(Net net, struct Mats* outputBlobs, struct CStrings outBlobNames) {\n    std::vector< cv::Mat > blobs;\n\n    std::vector< cv::String > names;\n    for (int i = 0; i < outBlobNames.length; ++i) {\n        names.push_back(cv::String(outBlobNames.strs[i]));\n    }\n    net->forward(blobs, names);\n\n    // copy blobs into outputBlobs\n    outputBlobs->mats = new Mat[blobs.size()];\n\n    for (size_t i = 0; i < blobs.size(); ++i) {\n        outputBlobs->mats[i] = new cv::Mat(blobs[i]);\n    }\n\n    outputBlobs->length = (int)blobs.size();\n}\n\nvoid Net_SetPreferableBackend(Net net, int backend) {\n    net->setPreferableBackend(backend);\n}\n\nvoid Net_SetPreferableTarget(Net net, int target) {\n    net->setPreferableTarget(target);\n}\n\nint64_t Net_GetPerfProfile(Net net) {\n    std::vector<double> layersTimes;\n    return net->getPerfProfile(layersTimes);\n}\n\nvoid Net_GetUnconnectedOutLayers(Net net, IntVector* res) {\n    std::vector< int > cids(net->getUnconnectedOutLayers());\n    int* ids = new int[cids.size()];\n    \n    for (size_t i = 0; i < cids.size(); ++i) {\n        ids[i] = cids[i];\n    }\n\n    res->length = cids.size();\n    res->val = ids;\n    return;\n}\n\nvoid Net_GetLayerNames(Net net, CStrings* names) {\n    std::vector< cv::String > cstrs(net->getLayerNames());\n    const char **strs = new const char*[cstrs.size()];\n\n    for (size_t i = 0; i < cstrs.size(); ++i) {\n        strs[i] = cstrs[i].c_str();\n    }\n\n    names->length = cstrs.size();\n    names->strs = strs;\n    return;\n}\n\nstruct Rect Net_BlobRectToImageRect(struct Rect rect, Size originalSize, double scalefactor, Size size, Scalar mean, bool swapRB,\n                    int ddepth, int dataLayout, int paddingMode, Scalar borderValue) {\n\n    cv::Scalar sf(scalefactor);\n    cv::Size sz(size.width, size.height);\n    cv::Scalar cm(mean.val1, mean.val2, mean.val3, mean.val4);\n    cv::dnn::DataLayout dl = static_cast<cv::dnn::DataLayout>(dataLayout);\n    cv::dnn::ImagePaddingMode pm = static_cast<cv::dnn::ImagePaddingMode>(paddingMode);\n    cv::Scalar bv(borderValue.val1, borderValue.val2, borderValue.val3, borderValue.val4);\n    cv::dnn::Image2BlobParams params = cv::dnn::Image2BlobParams(sf, sz, cm, swapRB, ddepth, dl, pm, bv);\n\n    cv::Rect bRect = params.blobRectToImageRect(cv::Rect(rect.x, rect.y, rect.width, rect.height), cv::Size(originalSize.width, originalSize.height));\n    Rect r = {bRect.x, bRect.y, bRect.width, bRect.height};\n    return r;\n}\n\nstruct Rects Net_BlobRectsToImageRects(struct Rects rects, Size originalSize, double scalefactor, Size size, Scalar mean, bool swapRB,\n                    int ddepth, int dataLayout, int paddingMode, Scalar borderValue) {\n\n    std::vector<cv::Rect> _cRects;\n    for (int i = 0; i < rects.length; ++i) {\n        _cRects.push_back(cv::Rect(\n            rects.rects[i].x,\n            rects.rects[i].y,\n            rects.rects[i].width,\n            rects.rects[i].height\n        ));\n    }\n\n    cv::Scalar sf(scalefactor);\n    cv::Size sz(size.width, size.height);\n    cv::Scalar cm(mean.val1, mean.val2, mean.val3, mean.val4);\n    cv::dnn::DataLayout dl = static_cast<cv::dnn::DataLayout>(dataLayout);\n    cv::dnn::ImagePaddingMode pm = static_cast<cv::dnn::ImagePaddingMode>(paddingMode);\n    cv::Scalar bv(borderValue.val1, borderValue.val2, borderValue.val3, borderValue.val4);\n    cv::dnn::Image2BlobParams params = cv::dnn::Image2BlobParams(sf, sz, cm, swapRB, ddepth, dl, pm, bv);\n\n    std::vector<cv::Rect> detected;\n    params.blobRectsToImageRects(_cRects, detected, cv::Size(originalSize.width, originalSize.height));\n    Rect* drects = new Rect[detected.size()];\n\n    for (size_t i = 0; i < detected.size(); ++i) {\n        Rect r = {detected[i].x, detected[i].y, detected[i].width, detected[i].height};\n        drects[i] = r;\n    }\n\n    Rects ret = {drects, (int)detected.size()};\n    return ret;\n}\n\nMat Net_BlobFromImage(Mat image, double scalefactor, Size size, Scalar mean, bool swapRB,\n                      bool crop) {\n    cv::Size sz(size.width, size.height);\n    cv::Scalar cm(mean.val1, mean.val2, mean.val3, mean.val4);\n    // use the default target ddepth here.\n    return new cv::Mat(cv::dnn::blobFromImage(*image, scalefactor, sz, cm, swapRB, crop));\n}\n\nMat Net_BlobFromImageWithParams(Mat image, double scalefactor, Size size, Scalar mean, bool swapRB,\n                      int ddepth, int dataLayout, int paddingMode, Scalar borderValue) {\n\n    cv::Scalar sf(scalefactor);\n    cv::Size sz(size.width, size.height);\n    cv::Scalar cm(mean.val1, mean.val2, mean.val3, mean.val4);\n    cv::dnn::DataLayout dl = static_cast<cv::dnn::DataLayout>(dataLayout);\n    cv::dnn::ImagePaddingMode pm = static_cast<cv::dnn::ImagePaddingMode>(paddingMode);\n    cv::Scalar bv(borderValue.val1, borderValue.val2, borderValue.val3, borderValue.val4);\n    cv::dnn::Image2BlobParams params = cv::dnn::Image2BlobParams(sf, sz, cm, swapRB, ddepth, dl, pm, bv);\n\n    return new cv::Mat(cv::dnn::blobFromImageWithParams(*image, params));\n}\n\nvoid Net_BlobFromImages(struct Mats images, Mat blob, double scalefactor, Size size,\n                       Scalar mean, bool swapRB, bool crop, int ddepth) {\n    std::vector<cv::Mat> imgs;\n    \n    for (int i = 0; i < images.length; ++i) {\n        imgs.push_back(*images.mats[i]);\n    }\n\n    cv::Size sz(size.width, size.height);\n    cv::Scalar cm = cv::Scalar(mean.val1, mean.val2, mean.val3, mean.val4);\n\n    // ignore the passed in ddepth, just use default.\n    cv::dnn::blobFromImages(imgs, *blob, scalefactor, sz, cm, swapRB, crop);\n}\n\nvoid Net_BlobFromImagesWithParams(struct Mats images, Mat blob, double scalefactor, Size size,\n                       Scalar mean, bool swapRB, int ddepth, int dataLayout, int paddingMode, Scalar borderValue) {\n    std::vector<cv::Mat> imgs;\n    \n    for (int i = 0; i < images.length; ++i) {\n        imgs.push_back(*images.mats[i]);\n    }\n\n    cv::Scalar sf(scalefactor);\n    cv::Size sz(size.width, size.height);\n    cv::Scalar cm(mean.val1, mean.val2, mean.val3, mean.val4);\n   cv::dnn::DataLayout dl = static_cast<cv::dnn::DataLayout>(dataLayout);\n    cv::dnn::ImagePaddingMode pm = static_cast<cv::dnn::ImagePaddingMode>(paddingMode);\n    cv::Scalar bv(borderValue.val1, borderValue.val2, borderValue.val3, borderValue.val4);\n    cv::dnn::Image2BlobParams params = cv::dnn::Image2BlobParams(sf, sz, cm, swapRB, ddepth, dl, pm, bv);\n\n    cv::dnn::blobFromImagesWithParams(imgs, *blob, params);\n}\n\nvoid Net_ImagesFromBlob(Mat blob_, struct Mats* images_) {\n    std::vector<cv::Mat> imgs;\n    cv::dnn::imagesFromBlob(*blob_, imgs);\n    images_->mats = new Mat[imgs.size()];\n\n    for (size_t i = 0; i < imgs.size(); ++i) {\n        images_->mats[i] = new cv::Mat(imgs[i]);\n    }\n    images_->length = (int) imgs.size();\n}\n\nMat Net_GetBlobChannel(Mat blob, int imgidx, int chnidx) {\n    size_t w = blob->size[3];\n    size_t h = blob->size[2];\n    return new cv::Mat(h, w, CV_32F, blob->ptr<float>(imgidx, chnidx));\n}\n\nScalar Net_GetBlobSize(Mat blob) {\n    Scalar scal = Scalar();\n    scal.val1 = blob->size[0];\n    scal.val2 = blob->size[1];\n    scal.val3 = blob->size[2];\n    scal.val4 = blob->size[3];\n    return scal;\n}\n\nLayer Net_GetLayer(Net net, int layerid) {\n    return new cv::Ptr<cv::dnn::Layer>(net->getLayer(layerid));\n}\n\nvoid Layer_Close(Layer layer) {\n    delete layer;\n}\n\nint Layer_InputNameToIndex(Layer layer, const char* name) {\n    return (*layer)->inputNameToIndex(name);\n}\n\nint Layer_OutputNameToIndex(Layer layer, const char* name) {\n    return (*layer)->outputNameToIndex(name);\n}\n\nconst char* Layer_GetName(Layer layer) {\n    return (*layer)->name.c_str();\n}\n\nconst char* Layer_GetType(Layer layer) {\n    return (*layer)->type.c_str();\n}\n\nvoid NMSBoxes(struct Rects bboxes, FloatVector scores, float score_threshold, float nms_threshold, IntVector* indices) {\n    std::vector<cv::Rect> _bboxes;\n\n    for (int i = 0; i < bboxes.length; ++i) {\n        _bboxes.push_back(cv::Rect(\n            bboxes.rects[i].x,\n            bboxes.rects[i].y,\n            bboxes.rects[i].width,\n            bboxes.rects[i].height\n        ));\n    }\n\n    std::vector<float> _scores;\n\n    float* f;\n    int i;\n    for (i = 0, f = scores.val; i < scores.length; ++f, ++i) {\n        _scores.push_back(*f);\n    }\n\n    std::vector<int> _indices(indices->length);\n\n    cv::dnn::NMSBoxes(_bboxes, _scores, score_threshold, nms_threshold, _indices, 1.f, 0);\n\n    int* ptr = new int[_indices.size()];\n\n    for (size_t i=0; i<_indices.size(); ++i) {\n        ptr[i] = _indices[i];\n    }\n\n    indices->length = _indices.size();\n    indices->val = ptr;\n    return;\n}\n\nvoid NMSBoxesWithParams(struct Rects bboxes, FloatVector scores, const float score_threshold, const float nms_threshold, IntVector* indices, const float eta, const int top_k) {\n    std::vector<cv::Rect> _bboxes;\n\n    for (int i = 0; i < bboxes.length; ++i) {\n        _bboxes.push_back(cv::Rect(\n            bboxes.rects[i].x,\n            bboxes.rects[i].y,\n            bboxes.rects[i].width,\n            bboxes.rects[i].height\n        ));\n    }\n\n    std::vector<float> _scores;\n\n    float* f;\n    int i;\n    for (i = 0, f = scores.val; i < scores.length; ++f, ++i) {\n        _scores.push_back(*f);\n    }\n\n    std::vector<int> _indices(indices->length);\n\n    cv::dnn::NMSBoxes(_bboxes, _scores, score_threshold, nms_threshold, _indices, eta, top_k);\n\n    int* ptr = new int[_indices.size()];\n\n    for (size_t i=0; i<_indices.size(); ++i) {\n        ptr[i] = _indices[i];\n    }\n\n    indices->length = _indices.size();\n    indices->val = ptr;\n    return;\n}"
        },
        {
          "name": "dnn.go",
          "type": "blob",
          "size": 23.548828125,
          "content": "package gocv\n\n/*\n#include <stdlib.h>\n#include \"dnn.h\"\n*/\nimport \"C\"\nimport (\n\t\"image\"\n\t\"reflect\"\n\t\"unsafe\"\n)\n\n// Net allows you to create and manipulate comprehensive artificial neural networks.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/db/d30/classcv_1_1dnn_1_1Net.html\ntype Net struct {\n\t// C.Net\n\tp unsafe.Pointer\n}\n\n// NetBackendType is the type for the various different kinds of DNN backends.\ntype NetBackendType int\n\nconst (\n\t// NetBackendDefault is the default backend.\n\tNetBackendDefault NetBackendType = 0\n\n\t// NetBackendHalide is the Halide backend.\n\tNetBackendHalide NetBackendType = 1\n\n\t// NetBackendOpenVINO is the OpenVINO backend.\n\tNetBackendOpenVINO NetBackendType = 2\n\n\t// NetBackendOpenCV is the OpenCV backend.\n\tNetBackendOpenCV NetBackendType = 3\n\n\t// NetBackendVKCOM is the Vulkan backend.\n\tNetBackendVKCOM NetBackendType = 4\n\n\t// NetBackendCUDA is the Cuda backend.\n\tNetBackendCUDA NetBackendType = 5\n)\n\n// ParseNetBackend returns a valid NetBackendType given a string. Valid values are:\n// - halide\n// - openvino\n// - opencv\n// - vulkan\n// - cuda\n// - default\nfunc ParseNetBackend(backend string) NetBackendType {\n\tswitch backend {\n\tcase \"halide\":\n\t\treturn NetBackendHalide\n\tcase \"openvino\":\n\t\treturn NetBackendOpenVINO\n\tcase \"opencv\":\n\t\treturn NetBackendOpenCV\n\tcase \"vulkan\":\n\t\treturn NetBackendVKCOM\n\tcase \"cuda\":\n\t\treturn NetBackendCUDA\n\tdefault:\n\t\treturn NetBackendDefault\n\t}\n}\n\n// NetTargetType is the type for the various different kinds of DNN device targets.\ntype NetTargetType int\n\nconst (\n\t// NetTargetCPU is the default CPU device target.\n\tNetTargetCPU NetTargetType = 0\n\n\t// NetTargetFP32 is the 32-bit OpenCL target.\n\tNetTargetFP32 NetTargetType = 1\n\n\t// NetTargetFP16 is the 16-bit OpenCL target.\n\tNetTargetFP16 NetTargetType = 2\n\n\t// NetTargetVPU is the Movidius VPU target.\n\tNetTargetVPU NetTargetType = 3\n\n\t// NetTargetVulkan is the NVIDIA Vulkan target.\n\tNetTargetVulkan NetTargetType = 4\n\n\t// NetTargetFPGA is the FPGA target.\n\tNetTargetFPGA NetTargetType = 5\n\n\t// NetTargetCUDA is the CUDA target.\n\tNetTargetCUDA NetTargetType = 6\n\n\t// NetTargetCUDAFP16 is the CUDA target.\n\tNetTargetCUDAFP16 NetTargetType = 7\n)\n\n// ParseNetTarget returns a valid NetTargetType given a string. Valid values are:\n// - cpu\n// - fp32\n// - fp16\n// - vpu\n// - vulkan\n// - fpga\n// - cuda\n// - cudafp16\nfunc ParseNetTarget(target string) NetTargetType {\n\tswitch target {\n\tcase \"cpu\":\n\t\treturn NetTargetCPU\n\tcase \"fp32\":\n\t\treturn NetTargetFP32\n\tcase \"fp16\":\n\t\treturn NetTargetFP16\n\tcase \"vpu\":\n\t\treturn NetTargetVPU\n\tcase \"vulkan\":\n\t\treturn NetTargetVulkan\n\tcase \"fpga\":\n\t\treturn NetTargetFPGA\n\tcase \"cuda\":\n\t\treturn NetTargetCUDA\n\tcase \"cudafp16\":\n\t\treturn NetTargetCUDAFP16\n\tdefault:\n\t\treturn NetTargetCPU\n\t}\n}\n\ntype DataLayoutType int\n\nconst (\n\tDataLayoutUnknown DataLayoutType = iota\n\tDataLayoutND\n\tDataLayoutNCHW\n\tDataLayoutNCDHW\n\tDataLayoutNHWC\n\tDataLayoutNDHWC\n\tDataLayoutPLANAR\n)\n\ntype PaddingModeType int\n\nconst (\n\tPaddingModeNull PaddingModeType = iota\n\tPaddingModeCropCenter\n\tPaddingModeLetterbox\n)\n\ntype ImageToBlobParams struct {\n\tScaleFactor float64\n\tSize        image.Point\n\tMean        Scalar\n\tSwapRB      bool\n\tDdepth      MatType\n\tDataLayout  DataLayoutType\n\tPaddingMode PaddingModeType\n\tBorderValue Scalar\n}\n\nfunc NewImageToBlobParams(scale float64, size image.Point, mean Scalar,\n\tswapRB bool, ddepth MatType, dataLayout DataLayoutType, paddingMode PaddingModeType, border Scalar) ImageToBlobParams {\n\treturn ImageToBlobParams{\n\t\tScaleFactor: scale,\n\t\tSize:        size,\n\t\tMean:        mean,\n\t\tSwapRB:      swapRB,\n\t\tDdepth:      ddepth,\n\t\tDataLayout:  dataLayout,\n\t\tPaddingMode: paddingMode,\n\t\tBorderValue: border,\n\t}\n}\n\n// BlobRectToImageRect gets rectangle coordinates in original image system from rectangle in blob coordinates.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.10.0/d9/d3c/structcv_1_1dnn_1_1Image2BlobParams.html#a40b2b5a731da82f042279650ffb3c3ee\nfunc (p *ImageToBlobParams) BlobRectToImageRect(rect image.Rectangle, size image.Point) image.Rectangle {\n\tcRect := C.struct_Rect{\n\t\tx:      C.int(rect.Min.X),\n\t\ty:      C.int(rect.Min.Y),\n\t\twidth:  C.int(rect.Size().X),\n\t\theight: C.int(rect.Size().Y),\n\t}\n\n\tcSize := C.struct_Size{width: C.int(size.X), height: C.int(size.Y)}\n\n\tsz := C.struct_Size{\n\t\twidth:  C.int(p.Size.X),\n\t\theight: C.int(p.Size.Y),\n\t}\n\n\tsMean := C.struct_Scalar{\n\t\tval1: C.double(p.Mean.Val1),\n\t\tval2: C.double(p.Mean.Val2),\n\t\tval3: C.double(p.Mean.Val3),\n\t\tval4: C.double(p.Mean.Val4),\n\t}\n\n\tbv := C.struct_Scalar{\n\t\tval1: C.double(p.BorderValue.Val1),\n\t\tval2: C.double(p.BorderValue.Val2),\n\t\tval3: C.double(p.BorderValue.Val3),\n\t\tval4: C.double(p.BorderValue.Val4),\n\t}\n\n\treturn toRect(C.Net_BlobRectToImageRect(cRect, cSize, C.double(p.ScaleFactor), sz, sMean, C.bool(p.SwapRB), C.int(p.Ddepth), C.int(p.DataLayout), C.int(p.PaddingMode), bv))\n}\n\n// BlobRectsToImageRects converts rectangle coordinates in original image system from rectangles in blob coordinates.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.10.0/d9/d3c/structcv_1_1dnn_1_1Image2BlobParams.html#a822728804c0d35fc3b743644ee192f60\nfunc (p *ImageToBlobParams) BlobRectsToImageRects(rects []image.Rectangle, size image.Point) []image.Rectangle {\n\tcRectArr := []C.struct_Rect{}\n\tfor _, v := range rects {\n\t\trect := C.struct_Rect{\n\t\t\tx:      C.int(v.Min.X),\n\t\t\ty:      C.int(v.Min.Y),\n\t\t\twidth:  C.int(v.Size().X),\n\t\t\theight: C.int(v.Size().Y),\n\t\t}\n\t\tcRectArr = append(cRectArr, rect)\n\t}\n\n\tcRects := C.Rects{\n\t\trects:  (*C.Rect)(&cRectArr[0]),\n\t\tlength: C.int(len(rects)),\n\t}\n\n\tcSize := C.struct_Size{width: C.int(size.X), height: C.int(size.Y)}\n\n\tsz := C.struct_Size{\n\t\twidth:  C.int(p.Size.X),\n\t\theight: C.int(p.Size.Y),\n\t}\n\n\tsMean := C.struct_Scalar{\n\t\tval1: C.double(p.Mean.Val1),\n\t\tval2: C.double(p.Mean.Val2),\n\t\tval3: C.double(p.Mean.Val3),\n\t\tval4: C.double(p.Mean.Val4),\n\t}\n\n\tbv := C.struct_Scalar{\n\t\tval1: C.double(p.BorderValue.Val1),\n\t\tval2: C.double(p.BorderValue.Val2),\n\t\tval3: C.double(p.BorderValue.Val3),\n\t\tval4: C.double(p.BorderValue.Val4),\n\t}\n\n\treturn toRectangles(C.Net_BlobRectsToImageRects(cRects, cSize, C.double(p.ScaleFactor), sz, sMean, C.bool(p.SwapRB), C.int(p.Ddepth), C.int(p.DataLayout), C.int(p.PaddingMode), bv))\n}\n\n// Close Net\nfunc (net *Net) Close() error {\n\tC.Net_Close((C.Net)(net.p))\n\tnet.p = nil\n\treturn nil\n}\n\n// Empty returns true if there are no layers in the network.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/db/d30/classcv_1_1dnn_1_1Net.html#a6a5778787d5b8770deab5eda6968e66c\nfunc (net *Net) Empty() bool {\n\treturn bool(C.Net_Empty((C.Net)(net.p)))\n}\n\n// SetInput sets the new value for the layer output blob.\n//\n// For further details, please see:\n// https://docs.opencv.org/trunk/db/d30/classcv_1_1dnn_1_1Net.html#a672a08ae76444d75d05d7bfea3e4a328\nfunc (net *Net) SetInput(blob Mat, name string) {\n\tcName := C.CString(name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\tC.Net_SetInput((C.Net)(net.p), blob.p, cName)\n}\n\n// Forward runs forward pass to compute output of layer with name outputName.\n//\n// For further details, please see:\n// https://docs.opencv.org/trunk/db/d30/classcv_1_1dnn_1_1Net.html#a98ed94cb6ef7063d3697259566da310b\nfunc (net *Net) Forward(outputName string) Mat {\n\tcName := C.CString(outputName)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\treturn newMat(C.Net_Forward((C.Net)(net.p), cName))\n}\n\n// ForwardLayers forward pass to compute outputs of layers listed in outBlobNames.\n//\n// For further details, please see:\n// https://docs.opencv.org/3.4.1/db/d30/classcv_1_1dnn_1_1Net.html#adb34d7650e555264c7da3b47d967311b\nfunc (net *Net) ForwardLayers(outBlobNames []string) (blobs []Mat) {\n\tcMats := C.struct_Mats{}\n\tC.Net_ForwardLayers((C.Net)(net.p), &(cMats), toCStrings(outBlobNames))\n\tblobs = make([]Mat, cMats.length)\n\tfor i := C.int(0); i < cMats.length; i++ {\n\t\tblobs[i].p = C.Mats_get(cMats, i)\n\t\taddMatToProfile(blobs[i].p)\n\t}\n\treturn\n}\n\n// SetPreferableBackend ask network to use specific computation backend.\n//\n// For further details, please see:\n// https://docs.opencv.org/3.4/db/d30/classcv_1_1dnn_1_1Net.html#a7f767df11386d39374db49cd8df8f59e\nfunc (net *Net) SetPreferableBackend(backend NetBackendType) error {\n\tC.Net_SetPreferableBackend((C.Net)(net.p), C.int(backend))\n\treturn nil\n}\n\n// SetPreferableTarget ask network to make computations on specific target device.\n//\n// For further details, please see:\n// https://docs.opencv.org/3.4/db/d30/classcv_1_1dnn_1_1Net.html#a9dddbefbc7f3defbe3eeb5dc3d3483f4\nfunc (net *Net) SetPreferableTarget(target NetTargetType) error {\n\tC.Net_SetPreferableTarget((C.Net)(net.p), C.int(target))\n\treturn nil\n}\n\n// ReadNet reads a deep learning network represented in one of the supported formats.\n//\n// For further details, please see:\n// https://docs.opencv.org/3.4/d6/d0f/group__dnn.html#ga3b34fe7a29494a6a4295c169a7d32422\nfunc ReadNet(model string, config string) Net {\n\tcModel := C.CString(model)\n\tdefer C.free(unsafe.Pointer(cModel))\n\n\tcConfig := C.CString(config)\n\tdefer C.free(unsafe.Pointer(cConfig))\n\treturn Net{p: unsafe.Pointer(C.Net_ReadNet(cModel, cConfig))}\n}\n\n// ReadNetBytes reads a deep learning network represented in one of the supported formats.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/d0f/group__dnn.html#ga138439da76f26266fdefec9723f6c5cd\nfunc ReadNetBytes(framework string, model []byte, config []byte) (Net, error) {\n\tcFramework := C.CString(framework)\n\tdefer C.free(unsafe.Pointer(cFramework))\n\tbModel, err := toByteArray(model)\n\tif err != nil {\n\t\treturn Net{}, err\n\t}\n\n\tvar bConfig C.ByteArray\n\tif len(config) > 0 {\n\t\tpbConfig, err := toByteArray(config)\n\t\tif err != nil {\n\t\t\treturn Net{}, err\n\t\t}\n\t\tbConfig = *pbConfig\n\t}\n\n\treturn Net{p: unsafe.Pointer(C.Net_ReadNetBytes(cFramework, *bModel, bConfig))}, nil\n}\n\n// ReadNetFromCaffe reads a network model stored in Caffe framework's format.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/d0f/group__dnn.html#ga29d0ea5e52b1d1a6c2681e3f7d68473a\nfunc ReadNetFromCaffe(prototxt string, caffeModel string) Net {\n\tcprototxt := C.CString(prototxt)\n\tdefer C.free(unsafe.Pointer(cprototxt))\n\n\tcmodel := C.CString(caffeModel)\n\tdefer C.free(unsafe.Pointer(cmodel))\n\treturn Net{p: unsafe.Pointer(C.Net_ReadNetFromCaffe(cprototxt, cmodel))}\n}\n\n// ReadNetFromCaffeBytes reads a network model stored in Caffe model in memory.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/d0f/group__dnn.html#ga946b342af1355185a7107640f868b64a\nfunc ReadNetFromCaffeBytes(prototxt []byte, caffeModel []byte) (Net, error) {\n\tbPrototxt, err := toByteArray(prototxt)\n\tif err != nil {\n\t\treturn Net{}, err\n\t}\n\tbCaffeModel, err := toByteArray(caffeModel)\n\tif err != nil {\n\t\treturn Net{}, err\n\t}\n\treturn Net{p: unsafe.Pointer(C.Net_ReadNetFromCaffeBytes(*bPrototxt, *bCaffeModel))}, nil\n}\n\n// ReadNetFromTensorflow reads a network model stored in Tensorflow framework's format.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/d0f/group__dnn.html#gad820b280978d06773234ba6841e77e8d\nfunc ReadNetFromTensorflow(model string) Net {\n\tcmodel := C.CString(model)\n\tdefer C.free(unsafe.Pointer(cmodel))\n\treturn Net{p: unsafe.Pointer(C.Net_ReadNetFromTensorflow(cmodel))}\n}\n\n// ReadNetFromTensorflowBytes reads a network model stored in Tensorflow framework's format.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/d0f/group__dnn.html#gacdba30a7c20db2788efbf5bb16a7884d\nfunc ReadNetFromTensorflowBytes(model []byte) (Net, error) {\n\tbModel, err := toByteArray(model)\n\tif err != nil {\n\t\treturn Net{}, err\n\t}\n\treturn Net{p: unsafe.Pointer(C.Net_ReadNetFromTensorflowBytes(*bModel))}, nil\n}\n\n// ReadNetFromTorch reads a network model stored in Torch framework's format (t7).\n//\n//\tcheck net.Empty() for read failure\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/d0f/group__dnn.html#gaaaed8c8530e9e92fe6647700c13d961e\nfunc ReadNetFromTorch(model string) Net {\n\tcmodel := C.CString(model)\n\tdefer C.free(unsafe.Pointer(cmodel))\n\treturn Net{p: unsafe.Pointer(C.Net_ReadNetFromTorch(cmodel))}\n}\n\n// ReadNetFromONNX reads a network model stored in ONNX framework's format.\n//\n//\tcheck net.Empty() for read failure\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/d0f/group__dnn.html#ga7faea56041d10c71dbbd6746ca854197\nfunc ReadNetFromONNX(model string) Net {\n\tcmodel := C.CString(model)\n\tdefer C.free(unsafe.Pointer(cmodel))\n\treturn Net{p: unsafe.Pointer(C.Net_ReadNetFromONNX(cmodel))}\n}\n\n// ReadNetFromONNXBytes reads a network model stored in ONNX framework's format.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/d0f/group__dnn.html#ga9198ecaac7c32ddf0aa7a1bcbd359567\nfunc ReadNetFromONNXBytes(model []byte) (Net, error) {\n\tbModel, err := toByteArray(model)\n\tif err != nil {\n\t\treturn Net{}, err\n\t}\n\treturn Net{p: unsafe.Pointer(C.Net_ReadNetFromONNXBytes(*bModel))}, nil\n}\n\n// BlobFromImage creates 4-dimensional blob from image. Optionally resizes and crops\n// image from center, subtract mean values, scales values by scalefactor,\n// swap Blue and Red channels.\n//\n// For further details, please see:\n// https://docs.opencv.org/trunk/d6/d0f/group__dnn.html#ga152367f253c81b53fe6862b299f5c5cd\nfunc BlobFromImage(img Mat, scaleFactor float64, size image.Point, mean Scalar,\n\tswapRB bool, crop bool) Mat {\n\n\tsz := C.struct_Size{\n\t\twidth:  C.int(size.X),\n\t\theight: C.int(size.Y),\n\t}\n\n\tsMean := C.struct_Scalar{\n\t\tval1: C.double(mean.Val1),\n\t\tval2: C.double(mean.Val2),\n\t\tval3: C.double(mean.Val3),\n\t\tval4: C.double(mean.Val4),\n\t}\n\n\treturn newMat(C.Net_BlobFromImage(img.p, C.double(scaleFactor), sz, sMean, C.bool(swapRB), C.bool(crop)))\n}\n\n// BlobFromImageWithParams creates 4-dimensional blob from image. Optionally resizes and crops\n// image from center, subtract mean values, scales values by scalefactor,\n// swap Blue and Red channels.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.10.0/d6/d0f/group__dnn.html#gadc12e5f4a801fd3c1d802f4c8c5d311c\nfunc BlobFromImageWithParams(img Mat, params ImageToBlobParams) Mat {\n\tsz := C.struct_Size{\n\t\twidth:  C.int(params.Size.X),\n\t\theight: C.int(params.Size.Y),\n\t}\n\n\tsMean := C.struct_Scalar{\n\t\tval1: C.double(params.Mean.Val1),\n\t\tval2: C.double(params.Mean.Val2),\n\t\tval3: C.double(params.Mean.Val3),\n\t\tval4: C.double(params.Mean.Val4),\n\t}\n\n\tbv := C.struct_Scalar{\n\t\tval1: C.double(params.BorderValue.Val1),\n\t\tval2: C.double(params.BorderValue.Val2),\n\t\tval3: C.double(params.BorderValue.Val3),\n\t\tval4: C.double(params.BorderValue.Val4),\n\t}\n\n\treturn newMat(C.Net_BlobFromImageWithParams(img.p, C.double(params.ScaleFactor), sz, sMean, C.bool(params.SwapRB), C.int(params.Ddepth), C.int(params.DataLayout), C.int(params.PaddingMode), bv))\n}\n\n// BlobFromImages Creates 4-dimensional blob from series of images.\n// Optionally resizes and crops images from center, subtract mean values,\n// scales values by scalefactor, swap Blue and Red channels.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/d0f/group__dnn.html#ga2b89ed84432e4395f5a1412c2926293c\nfunc BlobFromImages(imgs []Mat, blob *Mat, scaleFactor float64, size image.Point, mean Scalar,\n\tswapRB bool, crop bool, ddepth MatType) {\n\n\tcMatArray := make([]C.Mat, len(imgs))\n\tfor i, r := range imgs {\n\t\tcMatArray[i] = r.p\n\t}\n\n\tcMats := C.struct_Mats{\n\t\tmats:   (*C.Mat)(&cMatArray[0]),\n\t\tlength: C.int(len(imgs)),\n\t}\n\n\tsz := C.struct_Size{\n\t\twidth:  C.int(size.X),\n\t\theight: C.int(size.Y),\n\t}\n\n\tsMean := C.struct_Scalar{\n\t\tval1: C.double(mean.Val1),\n\t\tval2: C.double(mean.Val2),\n\t\tval3: C.double(mean.Val3),\n\t\tval4: C.double(mean.Val4),\n\t}\n\n\tC.Net_BlobFromImages(cMats, blob.p, C.double(scaleFactor), sz, sMean, C.bool(swapRB), C.bool(crop), C.int(ddepth))\n}\n\n// BlobFromImagesWithParams Creates 4-dimensional blob from series of images.\n// Optionally resizes and crops images from center, subtract mean values,\n// scales values by scalefactor, swap Blue and Red channels.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/d0f/group__dnn.html#ga2b89ed84432e4395f5a1412c2926293c\nfunc BlobFromImagesWithParams(imgs []Mat, blob *Mat, params ImageToBlobParams) {\n\tcMatArray := make([]C.Mat, len(imgs))\n\tfor i, r := range imgs {\n\t\tcMatArray[i] = r.p\n\t}\n\n\tcMats := C.struct_Mats{\n\t\tmats:   (*C.Mat)(&cMatArray[0]),\n\t\tlength: C.int(len(imgs)),\n\t}\n\n\tsz := C.struct_Size{\n\t\twidth:  C.int(params.Size.X),\n\t\theight: C.int(params.Size.Y),\n\t}\n\n\tsMean := C.struct_Scalar{\n\t\tval1: C.double(params.Mean.Val1),\n\t\tval2: C.double(params.Mean.Val2),\n\t\tval3: C.double(params.Mean.Val3),\n\t\tval4: C.double(params.Mean.Val4),\n\t}\n\n\tbv := C.struct_Scalar{\n\t\tval1: C.double(params.BorderValue.Val1),\n\t\tval2: C.double(params.BorderValue.Val2),\n\t\tval3: C.double(params.BorderValue.Val3),\n\t\tval4: C.double(params.BorderValue.Val4),\n\t}\n\n\tC.Net_BlobFromImagesWithParams(cMats, blob.p, C.double(params.ScaleFactor), sz, sMean, C.bool(params.SwapRB), C.int(params.Ddepth), C.int(params.DataLayout), C.int(params.PaddingMode), bv)\n}\n\n// ImagesFromBlob Parse a 4D blob and output the images it contains as\n// 2D arrays through a simpler data structure (std::vector<cv::Mat>).\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/d0f/group__dnn.html#ga4051b5fa2ed5f54b76c059a8625df9f5\nfunc ImagesFromBlob(blob Mat, imgs []Mat) {\n\tcMats := C.struct_Mats{}\n\tC.Net_ImagesFromBlob(blob.p, &(cMats))\n\t// mv = make([]Mat, cMats.length)\n\tfor i := C.int(0); i < cMats.length; i++ {\n\t\timgs[i].p = C.Mats_get(cMats, i)\n\t}\n}\n\n// GetBlobChannel extracts a single (2d)channel from a 4 dimensional blob structure\n// (this might e.g. contain the results of a SSD or YOLO detection,\n//\n//\ta bones structure from pose detection, or a color plane from Colorization)\nfunc GetBlobChannel(blob Mat, imgidx int, chnidx int) Mat {\n\treturn newMat(C.Net_GetBlobChannel(blob.p, C.int(imgidx), C.int(chnidx)))\n}\n\n// GetBlobSize retrieves the 4 dimensional size information in (N,C,H,W) order\nfunc GetBlobSize(blob Mat) Scalar {\n\ts := C.Net_GetBlobSize(blob.p)\n\treturn NewScalar(float64(s.val1), float64(s.val2), float64(s.val3), float64(s.val4))\n}\n\n// Layer is a wrapper around the cv::dnn::Layer algorithm.\ntype Layer struct {\n\t// C.Layer\n\tp unsafe.Pointer\n}\n\n// GetLayer returns pointer to layer with specified id from the network.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/db/d30/classcv_1_1dnn_1_1Net.html#a70aec7f768f38c32b1ee25f3a56526df\nfunc (net *Net) GetLayer(layer int) Layer {\n\treturn Layer{p: unsafe.Pointer(C.Net_GetLayer((C.Net)(net.p), C.int(layer)))}\n}\n\n// GetPerfProfile returns overall time for inference and timings (in ticks) for layers\n//\n// For further details, please see:\n// https://docs.opencv.org/master/db/d30/classcv_1_1dnn_1_1Net.html#a06ce946f675f75d1c020c5ddbc78aedc\nfunc (net *Net) GetPerfProfile() float64 {\n\treturn float64(C.Net_GetPerfProfile((C.Net)(net.p)))\n}\n\n// GetUnconnectedOutLayers returns indexes of layers with unconnected outputs.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/db/d30/classcv_1_1dnn_1_1Net.html#ae62a73984f62c49fd3e8e689405b056a\nfunc (net *Net) GetUnconnectedOutLayers() (ids []int) {\n\tcids := C.IntVector{}\n\tC.Net_GetUnconnectedOutLayers((C.Net)(net.p), &cids)\n\tdefer C.free(unsafe.Pointer(cids.val))\n\n\th := &reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(cids.val)),\n\t\tLen:  int(cids.length),\n\t\tCap:  int(cids.length),\n\t}\n\tpcids := *(*[]C.int)(unsafe.Pointer(h))\n\n\tfor i := 0; i < int(cids.length); i++ {\n\t\tids = append(ids, int(pcids[i]))\n\t}\n\treturn\n}\n\n// GetLayerNames returns all layer names.\n//\n// For furtherdetails, please see:\n// https://docs.opencv.org/master/db/d30/classcv_1_1dnn_1_1Net.html#ae8be9806024a0d1d41aba687cce99e6b\nfunc (net *Net) GetLayerNames() (names []string) {\n\tcstrs := C.CStrings{}\n\tdefer C.CStrings_Close(cstrs)\n\tC.Net_GetLayerNames((C.Net)(net.p), &cstrs)\n\treturn toGoStrings(cstrs)\n}\n\n// Close Layer\nfunc (l *Layer) Close() error {\n\tC.Layer_Close((C.Layer)(l.p))\n\tl.p = nil\n\treturn nil\n}\n\n// GetName returns name for this layer.\nfunc (l *Layer) GetName() string {\n\treturn C.GoString(C.Layer_GetName((C.Layer)(l.p)))\n}\n\n// GetType returns type for this layer.\nfunc (l *Layer) GetType() string {\n\treturn C.GoString(C.Layer_GetType((C.Layer)(l.p)))\n}\n\n// InputNameToIndex returns index of input blob in input array.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/d6c/classcv_1_1dnn_1_1Layer.html#a60ffc8238f3fa26cd3f49daa7ac0884b\nfunc (l *Layer) InputNameToIndex(name string) int {\n\tcName := C.CString(name)\n\tdefer C.free(unsafe.Pointer(cName))\n\treturn int(C.Layer_InputNameToIndex((C.Layer)(l.p), cName))\n}\n\n// OutputNameToIndex returns index of output blob in output array.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/d6c/classcv_1_1dnn_1_1Layer.html#a60ffc8238f3fa26cd3f49daa7ac0884b\nfunc (l *Layer) OutputNameToIndex(name string) int {\n\tcName := C.CString(name)\n\tdefer C.free(unsafe.Pointer(cName))\n\treturn int(C.Layer_OutputNameToIndex((C.Layer)(l.p), cName))\n}\n\n// NMSBoxes performs non maximum suppression given boxes and corresponding scores.\n//\n// For futher details, please see:\n// https://docs.opencv.org/4.4.0/d6/d0f/group__dnn.html#ga9d118d70a1659af729d01b10233213ee\nfunc NMSBoxes(bboxes []image.Rectangle, scores []float32, scoreThreshold float32, nmsThreshold float32) (indices []int) {\n\tbboxesRectArr := []C.struct_Rect{}\n\tfor _, v := range bboxes {\n\t\tbbox := C.struct_Rect{\n\t\t\tx:      C.int(v.Min.X),\n\t\t\ty:      C.int(v.Min.Y),\n\t\t\twidth:  C.int(v.Size().X),\n\t\t\theight: C.int(v.Size().Y),\n\t\t}\n\t\tbboxesRectArr = append(bboxesRectArr, bbox)\n\t}\n\n\tbboxesRects := C.Rects{\n\t\trects:  (*C.Rect)(&bboxesRectArr[0]),\n\t\tlength: C.int(len(bboxes)),\n\t}\n\n\tscoresFloats := []C.float{}\n\tfor _, v := range scores {\n\t\tscoresFloats = append(scoresFloats, C.float(v))\n\t}\n\tscoresVector := C.struct_FloatVector{}\n\tscoresVector.val = (*C.float)(&scoresFloats[0])\n\tscoresVector.length = (C.int)(len(scoresFloats))\n\n\tindicesVector := C.IntVector{}\n\n\tC.NMSBoxes(bboxesRects, scoresVector, C.float(scoreThreshold), C.float(nmsThreshold), &indicesVector)\n\tdefer C.free(unsafe.Pointer(indicesVector.val))\n\n\th := &reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(indicesVector.val)),\n\t\tLen:  int(indicesVector.length),\n\t\tCap:  int(indicesVector.length),\n\t}\n\n\tptr := *(*[]C.int)(unsafe.Pointer(h))\n\n\tindices = make([]int, indicesVector.length)\n\tfor i := 0; i < int(indicesVector.length); i++ {\n\t\tindices[i] = int(ptr[i])\n\t}\n\treturn\n}\n\n// NMSBoxesWithParams performs non maximum suppression given boxes and corresponding scores.\n//\n// For futher details, please see:\n// https://docs.opencv.org/4.4.0/d6/d0f/group__dnn.html#ga9d118d70a1659af729d01b10233213ee\nfunc NMSBoxesWithParams(bboxes []image.Rectangle, scores []float32, scoreThreshold float32, nmsThreshold float32, eta float32, topK int) (indices []int) {\n\tbboxesRectArr := []C.struct_Rect{}\n\tfor _, v := range bboxes {\n\t\tbbox := C.struct_Rect{\n\t\t\tx:      C.int(v.Min.X),\n\t\t\ty:      C.int(v.Min.Y),\n\t\t\twidth:  C.int(v.Size().X),\n\t\t\theight: C.int(v.Size().Y),\n\t\t}\n\t\tbboxesRectArr = append(bboxesRectArr, bbox)\n\t}\n\n\tbboxesRects := C.Rects{\n\t\trects:  (*C.Rect)(&bboxesRectArr[0]),\n\t\tlength: C.int(len(bboxes)),\n\t}\n\n\tscoresFloats := []C.float{}\n\tfor _, v := range scores {\n\t\tscoresFloats = append(scoresFloats, C.float(v))\n\t}\n\tscoresVector := C.struct_FloatVector{}\n\tscoresVector.val = (*C.float)(&scoresFloats[0])\n\tscoresVector.length = (C.int)(len(scoresFloats))\n\n\tindicesVector := C.IntVector{}\n\n\tC.NMSBoxesWithParams(bboxesRects, scoresVector, C.float(scoreThreshold), C.float(nmsThreshold), &indicesVector, C.float(eta), C.int(topK))\n\tdefer C.free(unsafe.Pointer(indicesVector.val))\n\n\th := &reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(indicesVector.val)),\n\t\tLen:  int(indicesVector.length),\n\t\tCap:  int(indicesVector.length),\n\t}\n\n\tptr := *(*[]C.int)(unsafe.Pointer(h))\n\n\tindices = make([]int, indicesVector.length)\n\tfor i := 0; i < int(indicesVector.length); i++ {\n\t\tindices[i] = int(ptr[i])\n\t}\n\treturn\n}\n"
        },
        {
          "name": "dnn.h",
          "type": "blob",
          "size": 3.205078125,
          "content": "#ifndef _OPENCV3_DNN_H_\n#define _OPENCV3_DNN_H_\n\n#include <stdbool.h>\n\n#ifdef __cplusplus\n#include <opencv2/opencv.hpp>\n#include <opencv2/dnn.hpp>\nextern \"C\" {\n#endif\n\n#include \"core.h\"\n\n#ifdef __cplusplus\ntypedef cv::dnn::Net* Net;\ntypedef cv::Ptr<cv::dnn::Layer>* Layer;\n#else\ntypedef void* Net;\ntypedef void* Layer;\n#endif\n\nNet Net_ReadNet(const char* model, const char* config);\nNet Net_ReadNetBytes(const char* framework, struct ByteArray model, struct ByteArray config);\nNet Net_ReadNetFromCaffe(const char* prototxt, const char* caffeModel);\nNet Net_ReadNetFromCaffeBytes(struct ByteArray prototxt, struct ByteArray caffeModel);\nNet Net_ReadNetFromTensorflow(const char* model);\nNet Net_ReadNetFromTensorflowBytes(struct ByteArray model);\nNet Net_ReadNetFromTorch(const char* model);\nNet Net_ReadNetFromONNX(const char* model);\nNet Net_ReadNetFromONNXBytes(struct ByteArray model);\nstruct Rect Net_BlobRectToImageRect(struct Rect rect, Size originalSize, double scalefactor, Size size, Scalar mean, bool swapRB,\n                    int ddepth, int dataLayout, int paddingMode, Scalar borderValue);\nstruct Rects Net_BlobRectsToImageRects(struct Rects rects, Size originalSize, double scalefactor, Size size, Scalar mean, bool swapRB,\n                    int ddepth, int dataLayout, int paddingMode, Scalar borderValue);\nMat Net_BlobFromImage(Mat image, double scalefactor, Size size, Scalar mean, bool swapRB,\n                      bool crop);\nMat Net_BlobFromImageWithParams(Mat image, double scalefactor, Size size, Scalar mean, bool swapRB,\n                      int ddepth, int dataLayout, int paddingMode, Scalar borderValue);\nvoid Net_BlobFromImages(struct Mats images, Mat blob,  double scalefactor, Size size, \n                        Scalar mean, bool swapRB, bool crop, int ddepth);\nvoid Net_BlobFromImagesWithParams(struct Mats images, Mat blob, double scalefactor, Size size, \n                        Scalar mean, bool swapRB, int ddepth, int dataLayout, int paddingMode, Scalar borderValue);\nvoid Net_ImagesFromBlob(Mat blob_, struct Mats* images_);\nvoid Net_Close(Net net);\nbool Net_Empty(Net net);\nvoid Net_SetInput(Net net, Mat blob, const char* name);\nMat Net_Forward(Net net, const char* outputName);\nvoid Net_ForwardLayers(Net net, struct Mats* outputBlobs, struct CStrings outBlobNames);\nvoid Net_SetPreferableBackend(Net net, int backend);\nvoid Net_SetPreferableTarget(Net net, int target);\nint64_t Net_GetPerfProfile(Net net);\nvoid Net_GetUnconnectedOutLayers(Net net, IntVector* res);\nvoid Net_GetLayerNames(Net net, CStrings* names);\n\nMat Net_GetBlobChannel(Mat blob, int imgidx, int chnidx);\nScalar Net_GetBlobSize(Mat blob);\n\nLayer Net_GetLayer(Net net, int layerid);\nvoid Layer_Close(Layer layer);\nint Layer_InputNameToIndex(Layer layer, const char* name);\nint Layer_OutputNameToIndex(Layer layer, const char* name);\nconst char* Layer_GetName(Layer layer);\nconst char* Layer_GetType(Layer layer);\n\nvoid NMSBoxes(struct Rects bboxes, FloatVector scores, float score_threshold, float nms_threshold, IntVector* indices);\nvoid NMSBoxesWithParams(struct Rects bboxes, FloatVector scores, const float score_threshold, const float nms_threshold, IntVector* indices, const float eta, const int top_k);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif //_OPENCV3_DNN_H_\n"
        },
        {
          "name": "dnn_async_openvino.go",
          "type": "blob",
          "size": 0.5625,
          "content": "//go:build openvino\n// +build openvino\n\npackage gocv\n\nimport (\n\t\"unsafe\"\n)\n\n/*\n#include <stdlib.h>\n#include \"dnn.h\"\n#include \"asyncarray.h\"\n*/\nimport \"C\"\n\n// ForwardAsync runs forward pass to compute output of layer with name outputName.\n//\n// For further details, please see:\n// https://docs.opencv.org/trunk/db/d30/classcv_1_1dnn_1_1Net.html#a814890154ea9e10b132fec00b6f6ba30\nfunc (net *Net) ForwardAsync(outputName string) AsyncArray {\n\tcName := C.CString(outputName)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\treturn newAsyncArray(C.Net_forwardAsync((C.Net)(net.p), cName))\n}\n"
        },
        {
          "name": "dnn_ext.go",
          "type": "blob",
          "size": 1.42578125,
          "content": "package gocv\n\nimport (\n\t\"image\"\n)\n\n// FP16BlobFromImage is an extended helper function to convert an Image to a half-float blob, as used by\n// the Movidius Neural Compute Stick.\nfunc FP16BlobFromImage(img Mat, scaleFactor float32, size image.Point, mean float32,\n\tswapRB bool, crop bool) []byte {\n\n\t// resizes image so it maintains aspect ratio\n\twidth := float32(img.Cols())\n\theight := float32(img.Rows())\n\n\tsquare := NewMatWithSize(size.Y, size.X, img.Type())\n\tdefer square.Close()\n\n\tmaxDim := height\n\tvar scale float32 = 1.0\n\tif width > height {\n\t\tmaxDim = width\n\t\tscale = float32(size.X) / float32(maxDim)\n\t}\n\tif width < height {\n\t\tscale = float32(size.Y) / float32(maxDim)\n\t}\n\n\tvar roi image.Rectangle\n\tif width >= height {\n\t\troi.Min.X = 0\n\t\troi.Min.Y = int(float32(size.Y)-height*scale) / 2\n\t\troi.Max.X = size.X\n\t\troi.Max.Y = int(height * scale)\n\t} else {\n\t\troi.Min.X = int(float32(size.X)-width*scale) / 2\n\t\troi.Min.Y = 0\n\t\troi.Max.X = int(width * scale)\n\t\troi.Max.Y = size.Y\n\t}\n\n\tResize(img, &square, roi.Max, 0, 0, InterpolationDefault)\n\n\tif swapRB {\n\t\tCvtColor(square, &square, ColorBGRToRGB)\n\t}\n\n\tfp32Image := NewMat()\n\tdefer fp32Image.Close()\n\n\tsquare.ConvertTo(&fp32Image, MatTypeCV32F)\n\n\tif mean != 0 {\n\t\t// subtract mean\n\t\tfp32Image.SubtractFloat(mean)\n\t}\n\n\tif scaleFactor != 1.0 {\n\t\t// multiply by scale factor\n\t\tfp32Image.MultiplyFloat(scaleFactor)\n\t}\n\n\tfp16Blob := fp32Image.ConvertFp16()\n\tdefer fp16Blob.Close()\n\n\treturn fp16Blob.ToBytes()\n}\n"
        },
        {
          "name": "dnn_string.go",
          "type": "blob",
          "size": 0.6875,
          "content": "package gocv\n\nfunc (c NetBackendType) String() string {\n\tswitch c {\n\tcase NetBackendDefault:\n\t\treturn \"\"\n\tcase NetBackendHalide:\n\t\treturn \"halide\"\n\tcase NetBackendOpenVINO:\n\t\treturn \"openvino\"\n\tcase NetBackendOpenCV:\n\t\treturn \"opencv\"\n\tcase NetBackendVKCOM:\n\t\treturn \"vulkan\"\n\tcase NetBackendCUDA:\n\t\treturn \"cuda\"\n\t}\n\treturn \"\"\n}\n\nfunc (c NetTargetType) String() string {\n\tswitch c {\n\tcase NetTargetCPU:\n\t\treturn \"cpu\"\n\tcase NetTargetFP32:\n\t\treturn \"fp32\"\n\tcase NetTargetFP16:\n\t\treturn \"fp16\"\n\tcase NetTargetVPU:\n\t\treturn \"vpu\"\n\tcase NetTargetVulkan:\n\t\treturn \"vulkan\"\n\tcase NetTargetFPGA:\n\t\treturn \"fpga\"\n\tcase NetTargetCUDA:\n\t\treturn \"cuda\"\n\tcase NetTargetCUDAFP16:\n\t\treturn \"cudafp16\"\n\t}\n\treturn \"\"\n}\n"
        },
        {
          "name": "dnn_test.go",
          "type": "blob",
          "size": 13.0732421875,
          "content": "package gocv\n\nimport (\n\t\"image\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"testing\"\n)\n\nfunc TestReadNetDiskFromTensorflow(t *testing.T) {\n\tpath := os.Getenv(\"GOCV_TENSORFLOW_TEST_FILES\")\n\tif path == \"\" {\n\t\tt.Skip(\"Unable to locate Tensorflow model files for tests\")\n\t}\n\n\tnet := ReadNet(path+\"/tensorflow_inception_graph.pb\", \"\")\n\tif net.Empty() {\n\t\tt.Errorf(\"Unable to load Tensorflow model using ReadNet\")\n\t}\n\tdefer net.Close()\n\n\tcheckTensorflowNet(t, net)\n}\n\nfunc TestReadNetMemoryFromTensorflow(t *testing.T) {\n\tpath := os.Getenv(\"GOCV_TENSORFLOW_TEST_FILES\")\n\tif path == \"\" {\n\t\tt.Skip(\"Unable to locate Tensorflow model files for tests\")\n\t}\n\n\tbModel, err := os.ReadFile(path + \"/tensorflow_inception_graph.pb\")\n\tif err != nil {\n\t\tt.Errorf(\"Failed to load model from file: %v\", err)\n\t}\n\n\t_, err = ReadNetBytes(\"tensorflow\", nil, nil)\n\tif err == nil {\n\t\tt.Errorf(\"Should have error for reading nil model bytes\")\n\t}\n\n\tnet, err := ReadNetBytes(\"tensorflow\", bModel, nil)\n\tif err != nil {\n\t\tt.Errorf(\"Failed to read net bytes: %v\", err)\n\t}\n\tif net.Empty() {\n\t\tt.Errorf(\"Unable to load Tensorflow model using ReadNetBytes\")\n\t}\n\tdefer net.Close()\n\n\tcheckTensorflowNet(t, net)\n}\n\nfunc TestReadNetDiskFromONNX(t *testing.T) {\n\tpath := os.Getenv(\"GOCV_ONNX_TEST_FILES\")\n\tif path == \"\" {\n\t\tt.Skip(\"Unable to locate ONNX model files for tests\")\n\t}\n\n\tnet := ReadNet(filepath.Join(path, \"googlenet-9.onnx\"), \"\")\n\tif net.Empty() {\n\t\tt.Errorf(\"Unable to load ONNX model using ReadNet\")\n\t}\n\tdefer net.Close()\n\n\tcheckONNXNet(t, net)\n}\n\nfunc TestReadNetMemoryFromONNX(t *testing.T) {\n\tpath := os.Getenv(\"GOCV_ONNX_TEST_FILES\")\n\tif path == \"\" {\n\t\tt.Skip(\"Unable to locate ONNX model files for tests\")\n\t}\n\n\tbModel, err := os.ReadFile(filepath.Join(path, \"googlenet-9.onnx\"))\n\tif err != nil {\n\t\tt.Errorf(\"Failed to load model from file: %v\", err)\n\t}\n\n\t_, err = ReadNetBytes(\"onnx\", nil, nil)\n\tif err == nil {\n\t\tt.Errorf(\"Should have error for reading nil model bytes\")\n\t}\n\n\tnet, err := ReadNetBytes(\"onnx\", bModel, nil)\n\tif err != nil {\n\t\tt.Errorf(\"Failed to read net bytes: %v\", err)\n\t}\n\tif net.Empty() {\n\t\tt.Errorf(\"Unable to load Caffe model using ReadNetBytes\")\n\t}\n\tdefer net.Close()\n\tcheckONNXNet(t, net)\n}\n\nfunc checkTensorflowNet(t *testing.T, net Net) {\n\timg := IMRead(\"images/space_shuttle.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in Tensorflow test\")\n\t}\n\tdefer img.Close()\n\n\tblob := BlobFromImage(img, 1.0, image.Pt(224, 224), NewScalar(0, 0, 0, 0), true, false)\n\tif blob.Empty() {\n\t\tt.Error(\"Invalid blob in Tensorflow test\")\n\t}\n\tdefer blob.Close()\n\n\tnet.SetInput(blob, \"input\")\n\tprob := net.Forward(\"softmax2\")\n\tdefer prob.Close()\n\tif prob.Empty() {\n\t\tt.Error(\"Invalid softmax2 in Tensorflow test\")\n\t}\n\n\tprobMat := prob.Reshape(1, 1)\n\tdefer probMat.Close()\n\t_, maxVal, minLoc, maxLoc := MinMaxLoc(probMat)\n\n\tif round(float64(maxVal), 0.00005) != 1.0 {\n\t\tt.Errorf(\"Tensorflow maxVal incorrect: %v\\n\", round(float64(maxVal), 0.00005))\n\t}\n\n\tif minLoc.X != 481 || minLoc.Y != 0 {\n\t\tt.Errorf(\"Tensorflow minLoc incorrect: %v\\n\", minLoc)\n\t}\n\n\tif maxLoc.X != 234 || maxLoc.Y != 0 {\n\t\tt.Errorf(\"Tensorflow maxLoc incorrect: %v\\n\", maxLoc)\n\t}\n}\n\nfunc TestTensorflowDisk(t *testing.T) {\n\tpath := os.Getenv(\"GOCV_TENSORFLOW_TEST_FILES\")\n\tif path == \"\" {\n\t\tt.Skip(\"Unable to locate Tensorflow model file for tests\")\n\t}\n\n\tnet := ReadNetFromTensorflow(path + \"/tensorflow_inception_graph.pb\")\n\tif net.Empty() {\n\t\tt.Errorf(\"Unable to load Tensorflow model\")\n\t}\n\tdefer net.Close()\n\n\tcheckTensorflowNet(t, net)\n}\n\nfunc TestTensorflowMemory(t *testing.T) {\n\tpath := os.Getenv(\"GOCV_TENSORFLOW_TEST_FILES\")\n\tif path == \"\" {\n\t\tt.Skip(\"Unable to locate Tensorflow model file for tests\")\n\t}\n\n\tb, err := os.ReadFile(path + \"/tensorflow_inception_graph.pb\")\n\tif err != nil {\n\t\tt.Errorf(\"Failed to load tensorflow model from file: %v\", err)\n\t}\n\tnet, err := ReadNetFromTensorflowBytes(b)\n\tif err != nil {\n\t\tt.Errorf(\"Failed to load Tensorflow model from bytes: %v\", err)\n\t}\n\tif net.Empty() {\n\t\tt.Errorf(\"Unable to load Tensorflow model\")\n\t}\n\tdefer net.Close()\n\n\tcheckTensorflowNet(t, net)\n}\n\nfunc TestOnnxMemory(t *testing.T) {\n\tpath := os.Getenv(\"GOCV_ONNX_TEST_FILES\")\n\tif path == \"\" {\n\t\tt.Skip(\"Unable to locate ONNX model file for tests\")\n\t}\n\n\tb, err := os.ReadFile(filepath.Join(path, \"googlenet-9.onnx\"))\n\tif err != nil {\n\t\tt.Errorf(\"Failed to load ONNX from file: %v\", err)\n\t}\n\n\tnet, err := ReadNetFromONNXBytes(b)\n\tif err != nil {\n\t\tt.Errorf(\"Failed to load Tensorflow model from bytes: %v\", err)\n\t}\n\tif net.Empty() {\n\t\tt.Errorf(\"Unable to load Tensorflow model\")\n\t}\n\tdefer net.Close()\n\n\tcheckONNXNet(t, net)\n}\n\nfunc TestOnnxDisk(t *testing.T) {\n\tpath := os.Getenv(\"GOCV_ONNX_TEST_FILES\")\n\tif path == \"\" {\n\t\tt.Skip(\"Unable to locate ONNX model file for tests\")\n\t}\n\n\tnet := ReadNetFromONNX(filepath.Join(path, \"googlenet-9.onnx\"))\n\tif net.Empty() {\n\t\tt.Errorf(\"Unable to load ONNX model\")\n\t}\n\tdefer net.Close()\n\n\tcheckONNXNet(t, net)\n}\n\nfunc checkONNXNet(t *testing.T, net Net) {\n\timg := IMRead(\"images/space_shuttle.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in ONNX test\")\n\t}\n\tdefer img.Close()\n\n\tblob := BlobFromImage(img, 1.0, image.Pt(224, 224), NewScalar(0, 0, 0, 0), true, false)\n\tif blob.Empty() {\n\t\tt.Error(\"Invalid blob in ONNX test\")\n\t}\n\tdefer blob.Close()\n\n\tnet.SetInput(blob, \"data_0\")\n\tprob := net.Forward(\"prob_1\")\n\tdefer prob.Close()\n\tif prob.Empty() {\n\t\tt.Error(\"Invalid output in ONNX test\")\n\t}\n\n\tprobMat := prob.Reshape(1, 1)\n\tdefer probMat.Close()\n\t_, maxVal, minLoc, maxLoc := MinMaxLoc(probMat)\n\n\tif round(float64(maxVal), 0.0005) != 0.9965 {\n\t\tt.Errorf(\"ONNX maxVal incorrect: %v\\n\", round(float64(maxVal), 0.0005))\n\t}\n\n\tif minLoc.X != 955 || minLoc.Y != 0 {\n\t\tt.Errorf(\"ONNX minLoc incorrect: %v\\n\", minLoc)\n\t}\n\n\tif maxLoc.X != 812 || maxLoc.Y != 0 {\n\t\tt.Errorf(\"ONNX maxLoc incorrect: %v\\n\", maxLoc)\n\t}\n}\n\nfunc TestBlobFromImages(t *testing.T) {\n\timgs := make([]Mat, 0)\n\n\timg := IMRead(\"images/space_shuttle.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in BlobFromImages test\")\n\t}\n\tdefer img.Close()\n\n\timgs = append(imgs, img)\n\timgs = append(imgs, img)\n\n\tblob := NewMat()\n\tBlobFromImages(imgs, &blob, 1.0, image.Pt(25, 25), NewScalar(0, 0, 0, 0), false, false, MatTypeCV32F)\n\tdefer blob.Close()\n\n\tsz := GetBlobSize(blob)\n\tif sz.Val1 != 2 || sz.Val2 != 3 || sz.Val3 != 25 || sz.Val4 != 25 {\n\t\tt.Errorf(\"GetBlobSize in BlobFromImages retrieved wrong values\")\n\t}\n}\n\nfunc TestBlobFromImageGreyscale(t *testing.T) {\n\timg := IMRead(\"images/space_shuttle.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in TestBlobFromImageGreyscale test\")\n\t}\n\tdefer img.Close()\n\n\tblob := BlobFromImage(img, 1.0, image.Pt(100, 100), NewScalar(0, 0, 0, 0), false, false)\n\tdefer blob.Close()\n\n\tif blob.Empty() {\n\t\tt.Errorf(\"BlobFromImageGreyscale failed to create blob\")\n\t}\n}\n\nfunc TestBlobFromImageWithParams(t *testing.T) {\n\timg := IMRead(\"images/space_shuttle.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in BlobFromImages test\")\n\t}\n\tdefer img.Close()\n\n\tparams := NewImageToBlobParams(1.0, image.Pt(25, 25), NewScalar(0, 0, 0, 0), false, MatTypeCV32F, DataLayoutNCHW, PaddingModeCropCenter, NewScalar(0, 0, 0, 0))\n\tblob := BlobFromImageWithParams(img, params)\n\tdefer blob.Close()\n\n\tsz := GetBlobSize(blob)\n\tif sz.Val1 != 1 || sz.Val2 != 3 || sz.Val3 != 25 || sz.Val4 != 25 {\n\t\tt.Errorf(\"GetBlobSize in BlobFromImagesWithParams retrieved wrong values: %v\\n\", sz)\n\t}\n}\n\nfunc TestBlobFromImagesWithParams(t *testing.T) {\n\timgs := make([]Mat, 0)\n\n\timg := IMRead(\"images/space_shuttle.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in BlobFromImagesWithParams test\")\n\t}\n\tdefer img.Close()\n\n\timgs = append(imgs, img)\n\timgs = append(imgs, img)\n\n\tparams := NewImageToBlobParams(1.0, image.Pt(25, 25), NewScalar(0, 0, 0, 0), false, MatTypeCV32F, DataLayoutNCHW, PaddingModeCropCenter, NewScalar(0, 0, 0, 0))\n\tblob := NewMat()\n\tBlobFromImagesWithParams(imgs, &blob, params)\n\tdefer blob.Close()\n\n\tsz := GetBlobSize(blob)\n\tif sz.Val1 != 2 || sz.Val2 != 3 || sz.Val3 != 25 || sz.Val4 != 25 {\n\t\tt.Errorf(\"GetBlobSize in BlobFromImagesWithParams retrieved wrong values: %v\\n\", sz)\n\t}\n}\n\nfunc TestImagesFromBlob(t *testing.T) {\n\timgs := make([]Mat, 0)\n\n\timg := IMRead(\"images/space_shuttle.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in BlobFromImages test\")\n\t}\n\tdefer img.Close()\n\n\timgs = append(imgs, img)\n\timgs = append(imgs, img)\n\n\tblob := NewMat()\n\tdefer blob.Close()\n\tBlobFromImages(imgs, &blob, 1.0, image.Pt(img.Size()[0], img.Size()[1]), NewScalar(0, 0, 0, 0), false, false, MatTypeCV32F)\n\n\timgsFromBlob := make([]Mat, len(imgs))\n\tImagesFromBlob(blob, imgsFromBlob)\n\n\tfor i := 0; i < len(imgs); i++ {\n\t\tfunc() {\n\t\t\timgFromBlob := NewMat()\n\t\t\tdefer imgFromBlob.Close()\n\t\t\timgsFromBlob[i].ConvertTo(&imgFromBlob, imgs[i].Type())\n\t\t\tdiff := NewMat()\n\t\t\tdefer diff.Close()\n\t\t\tCompare(imgs[i], imgFromBlob, &diff, CompareNE)\n\t\t\tnz := CountNonZero(diff)\n\t\t\tif nz != 0 {\n\t\t\t\tt.Error(\"imgFromBlob is different from img!\")\n\t\t\t}\n\t\t}()\n\t}\n}\n\nfunc TestGetBlobChannel(t *testing.T) {\n\timg := NewMatWithSize(100, 100, 5+16)\n\tdefer img.Close()\n\n\tblob := BlobFromImage(img, 1.0, image.Pt(0, 0), NewScalar(0, 0, 0, 0), true, false)\n\tdefer blob.Close()\n\n\tch2 := GetBlobChannel(blob, 0, 1)\n\tdefer ch2.Close()\n\n\tif ch2.Empty() {\n\t\tt.Errorf(\"GetBlobChannel failed to retrieve 2nd chan of a 3channel blob\")\n\t}\n\tif ch2.Rows() != img.Rows() || ch2.Cols() != img.Cols() {\n\t\tt.Errorf(\"GetBlobChannel: retrieved image size does not match original\")\n\t}\n}\n\nfunc TestGetBlobSize(t *testing.T) {\n\timg := NewMatWithSize(100, 100, 5+16)\n\tdefer img.Close()\n\n\tblob := BlobFromImage(img, 1.0, image.Pt(0, 0), NewScalar(0, 0, 0, 0), true, false)\n\tdefer blob.Close()\n\n\tsz := GetBlobSize(blob)\n\tif sz.Val1 != 1 || sz.Val2 != 3 || sz.Val3 != 100 || sz.Val4 != 100 {\n\t\tt.Errorf(\"GetBlobSize retrieved wrong values\")\n\t}\n}\n\nfunc TestParseNetBackend(t *testing.T) {\n\tval := ParseNetBackend(\"halide\")\n\tif val != NetBackendHalide {\n\t\tt.Errorf(\"ParseNetBackend invalid\")\n\t}\n\tval = ParseNetBackend(\"openvino\")\n\tif val != NetBackendOpenVINO {\n\t\tt.Errorf(\"ParseNetBackend invalid\")\n\t}\n\tval = ParseNetBackend(\"opencv\")\n\tif val != NetBackendOpenCV {\n\t\tt.Errorf(\"ParseNetBackend invalid\")\n\t}\n\tval = ParseNetBackend(\"vulkan\")\n\tif val != NetBackendVKCOM {\n\t\tt.Errorf(\"ParseNetBackend invalid\")\n\t}\n\tval = ParseNetBackend(\"cuda\")\n\tif val != NetBackendCUDA {\n\t\tt.Errorf(\"ParseNetBackend invalid\")\n\t}\n\tval = ParseNetBackend(\"crazytrain\")\n\tif val != NetBackendDefault {\n\t\tt.Errorf(\"ParseNetBackend invalid\")\n\t}\n}\n\nfunc TestParseNetTarget(t *testing.T) {\n\tval := ParseNetTarget(\"cpu\")\n\tif val != NetTargetCPU {\n\t\tt.Errorf(\"ParseNetTarget invalid\")\n\t}\n\tval = ParseNetTarget(\"fp32\")\n\tif val != NetTargetFP32 {\n\t\tt.Errorf(\"ParseNetTarget invalid\")\n\t}\n\tval = ParseNetTarget(\"fp16\")\n\tif val != NetTargetFP16 {\n\t\tt.Errorf(\"ParseNetTarget invalid\")\n\t}\n\tval = ParseNetTarget(\"vpu\")\n\tif val != NetTargetVPU {\n\t\tt.Errorf(\"ParseNetTarget invalid\")\n\t}\n\tval = ParseNetTarget(\"cuda\")\n\tif val != NetTargetCUDA {\n\t\tt.Errorf(\"ParseNetTarget invalid\")\n\t}\n\tval = ParseNetTarget(\"vulkan\")\n\tif val != NetTargetVulkan {\n\t\tt.Errorf(\"ParseNetTarget invalid\")\n\t}\n\tval = ParseNetTarget(\"fpga\")\n\tif val != NetTargetFPGA {\n\t\tt.Errorf(\"ParseNetTarget invalid\")\n\t}\n\tval = ParseNetTarget(\"cudafp16\")\n\tif val != NetTargetCUDAFP16 {\n\t\tt.Errorf(\"ParseNetTarget invalid\")\n\t}\n\tval = ParseNetTarget(\"idk\")\n\tif val != NetTargetCPU {\n\t\tt.Errorf(\"ParseNetTarget invalid\")\n\t}\n}\n\nfunc TestFP16BlobFromImage(t *testing.T) {\n\timg := NewMatWithSize(100, 100, 5+16)\n\tdefer img.Close()\n\n\tdata := FP16BlobFromImage(img, 1.0, image.Pt(100, 100), 0, false, false)\n\n\tif len(data) != 60000 {\n\t\tt.Errorf(\"FP16BlobFromImage incorrect length: %v\\n\", len(data))\n\t}\n\n\timg2 := NewMatWithSize(100, 50, 5+16)\n\tdefer img2.Close()\n\n\tdata = FP16BlobFromImage(img2, 2.0, image.Pt(50, 100), -0.1, true, false)\n\n\tif len(data) != 30000 {\n\t\tt.Errorf(\"FP16BlobFromImage incorrect length: %v\\n\", len(data))\n\t}\n}\n\nfunc TestNMSBoxes(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in NMSBoxes test\")\n\t}\n\tdefer img.Close()\n\n\timg.ConvertTo(&img, MatTypeCV32F)\n\n\tbboxes := []image.Rectangle{\n\t\timage.Rect(53, 47, 589, 451),\n\t\timage.Rect(118, 54, 618, 450),\n\t\timage.Rect(53, 66, 605, 480),\n\t\timage.Rect(111, 65, 630, 480),\n\t\timage.Rect(156, 51, 640, 480),\n\t}\n\tscores := []float32{0.82094115, 0.7998236, 0.9809663, 0.99717456, 0.89628726}\n\tscoreThreshold := float32(0.5)\n\tnmsThreshold := float32(0.4)\n\n\tindices := NMSBoxes(bboxes, scores, scoreThreshold, nmsThreshold)\n\n\tif indices[0] != 3 {\n\t\tt.Errorf(\"Invalid NMSBoxes test indices: %v\", indices)\n\t}\n}\n\nfunc TestNMSBoxesWithParams(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in NMSBoxesWithParams test\")\n\t}\n\tdefer img.Close()\n\n\timg.ConvertTo(&img, MatTypeCV32F)\n\n\tbboxes := []image.Rectangle{\n\t\timage.Rect(53, 47, 589, 451),\n\t\timage.Rect(118, 54, 618, 450),\n\t\timage.Rect(53, 66, 605, 480),\n\t\timage.Rect(111, 65, 630, 480),\n\t\timage.Rect(156, 51, 640, 480),\n\t}\n\tscores := []float32{0.82094115, 0.7998236, 0.9809663, 0.99717456, 0.89628726}\n\tscoreThreshold := float32(0.5)\n\tnmsThreshold := float32(0.4)\n\n\tindices := NMSBoxesWithParams(bboxes, scores, scoreThreshold, nmsThreshold, float32(1.0), 0)\n\n\tif indices[0] != 3 {\n\t\tt.Errorf(\"Invalid NMSBoxesWithParams test indices: %v\", indices)\n\t}\n}\n"
        },
        {
          "name": "env.cmd",
          "type": "blob",
          "size": 0.16015625,
          "content": "ECHO This script is no longer necessary and has been deprecated.\r\nECHO See the Custom Environment section of the README if you need to customize your environment.\r\n"
        },
        {
          "name": "env.sh",
          "type": "blob",
          "size": 0.162109375,
          "content": "echo \"This script is no longer necessary and has been deprecated.\"\necho \"See the Custom Environment section of the README if you need to customize your environment.\"\n"
        },
        {
          "name": "features2d.cpp",
          "type": "blob",
          "size": 23.873046875,
          "content": "#include \"features2d.h\"\n\nAKAZE AKAZE_Create() {\n    // TODO: params\n    return new cv::Ptr<cv::AKAZE>(cv::AKAZE::create());\n}\n\nvoid AKAZE_Close(AKAZE a) {\n    delete a;\n}\n\nstruct KeyPoints AKAZE_Detect(AKAZE a, Mat src) {\n    std::vector<cv::KeyPoint> detected;\n    (*a)->detect(*src, detected);\n\n    KeyPoint* kps = new KeyPoint[detected.size()];\n\n    for (size_t i = 0; i < detected.size(); ++i) {\n        KeyPoint k = {detected[i].pt.x, detected[i].pt.y, detected[i].size, detected[i].angle,\n                      detected[i].response, detected[i].octave, detected[i].class_id\n                     };\n        kps[i] = k;\n    }\n\n    KeyPoints ret = {kps, (int)detected.size()};\n    return ret;\n}\n\nstruct KeyPoints AKAZE_Compute(AKAZE a, Mat src, struct KeyPoints kp, Mat desc) {\n    std::vector<cv::KeyPoint> computed;\n    for (size_t i = 0; i < kp.length; i++) {\n        cv::KeyPoint k = cv::KeyPoint(kp.keypoints[i].x, kp.keypoints[i].y,\n            kp.keypoints[i].size, kp.keypoints[i].angle, kp.keypoints[i].response,\n            kp.keypoints[i].octave, kp.keypoints[i].classID);\n        computed.push_back(k);\n    }\n\n    (*a)->compute(*src, computed, *desc);\n\n    KeyPoint* kps = new KeyPoint[computed.size()];\n\n    for (size_t i = 0; i < computed.size(); ++i) {\n        KeyPoint k = {computed[i].pt.x, computed[i].pt.y, computed[i].size, computed[i].angle,\n                      computed[i].response, computed[i].octave, computed[i].class_id\n                     };\n        kps[i] = k;\n    }\n\n    KeyPoints ret = {kps, (int)computed.size()};\n    return ret;\n}\n\nstruct KeyPoints AKAZE_DetectAndCompute(AKAZE a, Mat src, Mat mask, Mat desc) {\n    std::vector<cv::KeyPoint> detected;\n    (*a)->detectAndCompute(*src, *mask, detected, *desc);\n\n    KeyPoint* kps = new KeyPoint[detected.size()];\n\n    for (size_t i = 0; i < detected.size(); ++i) {\n        KeyPoint k = {detected[i].pt.x, detected[i].pt.y, detected[i].size, detected[i].angle,\n                      detected[i].response, detected[i].octave, detected[i].class_id\n                     };\n        kps[i] = k;\n    }\n\n    KeyPoints ret = {kps, (int)detected.size()};\n    return ret;\n}\n\nAgastFeatureDetector AgastFeatureDetector_Create() {\n    // TODO: params\n    return new cv::Ptr<cv::AgastFeatureDetector>(cv::AgastFeatureDetector::create());\n}\n\nvoid AgastFeatureDetector_Close(AgastFeatureDetector a) {\n    delete a;\n}\n\nstruct KeyPoints AgastFeatureDetector_Detect(AgastFeatureDetector a, Mat src) {\n    std::vector<cv::KeyPoint> detected;\n    (*a)->detect(*src, detected);\n\n    KeyPoint* kps = new KeyPoint[detected.size()];\n\n    for (size_t i = 0; i < detected.size(); ++i) {\n        KeyPoint k = {detected[i].pt.x, detected[i].pt.y, detected[i].size, detected[i].angle,\n                      detected[i].response, detected[i].octave, detected[i].class_id\n                     };\n        kps[i] = k;\n    }\n\n    KeyPoints ret = {kps, (int)detected.size()};\n    return ret;\n}\n\nBRISK BRISK_Create() {\n    // TODO: params\n    return new cv::Ptr<cv::BRISK>(cv::BRISK::create());\n}\n\nvoid BRISK_Close(BRISK b) {\n    delete b;\n}\n\nstruct KeyPoints BRISK_Detect(BRISK b, Mat src) {\n    std::vector<cv::KeyPoint> detected;\n    (*b)->detect(*src, detected);\n\n    KeyPoint* kps = new KeyPoint[detected.size()];\n\n    for (size_t i = 0; i < detected.size(); ++i) {\n        KeyPoint k = {detected[i].pt.x, detected[i].pt.y, detected[i].size, detected[i].angle,\n                      detected[i].response, detected[i].octave, detected[i].class_id\n                     };\n        kps[i] = k;\n    }\n\n    KeyPoints ret = {kps, (int)detected.size()};\n    return ret;\n}\n\nstruct KeyPoints BRISK_Compute(BRISK b, Mat src, struct KeyPoints kp, Mat desc) {\n    std::vector<cv::KeyPoint> computed;\n    for (size_t i = 0; i < kp.length; i++) {\n        cv::KeyPoint k = cv::KeyPoint(kp.keypoints[i].x, kp.keypoints[i].y,\n            kp.keypoints[i].size, kp.keypoints[i].angle, kp.keypoints[i].response,\n            kp.keypoints[i].octave, kp.keypoints[i].classID);\n        computed.push_back(k);\n    }\n\n    (*b)->compute(*src, computed, *desc);\n\n    KeyPoint* kps = new KeyPoint[computed.size()];\n\n    for (size_t i = 0; i < computed.size(); ++i) {\n        KeyPoint k = {computed[i].pt.x, computed[i].pt.y, computed[i].size, computed[i].angle,\n                      computed[i].response, computed[i].octave, computed[i].class_id\n                     };\n        kps[i] = k;\n    }\n\n    KeyPoints ret = {kps, (int)computed.size()};\n    return ret;\n}\n\nstruct KeyPoints BRISK_DetectAndCompute(BRISK b, Mat src, Mat mask, Mat desc) {\n    std::vector<cv::KeyPoint> detected;\n    (*b)->detectAndCompute(*src, *mask, detected, *desc);\n\n    KeyPoint* kps = new KeyPoint[detected.size()];\n\n    for (size_t i = 0; i < detected.size(); ++i) {\n        KeyPoint k = {detected[i].pt.x, detected[i].pt.y, detected[i].size, detected[i].angle,\n                      detected[i].response, detected[i].octave, detected[i].class_id\n                     };\n        kps[i] = k;\n    }\n\n    KeyPoints ret = {kps, (int)detected.size()};\n    return ret;\n}\n\nGFTTDetector GFTTDetector_Create() {\n    // TODO: params\n    return new cv::Ptr<cv::GFTTDetector>(cv::GFTTDetector::create());\n}\n\nvoid GFTTDetector_Close(GFTTDetector a) {\n    delete a;\n}\n\nstruct KeyPoints GFTTDetector_Detect(GFTTDetector a, Mat src) {\n    std::vector<cv::KeyPoint> detected;\n    (*a)->detect(*src, detected);\n\n    KeyPoint* kps = new KeyPoint[detected.size()];\n\n    for (size_t i = 0; i < detected.size(); ++i) {\n        KeyPoint k = {detected[i].pt.x, detected[i].pt.y, detected[i].size, detected[i].angle,\n                      detected[i].response, detected[i].octave, detected[i].class_id\n                     };\n        kps[i] = k;\n    }\n\n    KeyPoints ret = {kps, (int)detected.size()};\n    return ret;\n}\n\nKAZE KAZE_Create() {\n    // TODO: params\n    return new cv::Ptr<cv::KAZE>(cv::KAZE::create());\n}\n\nvoid KAZE_Close(KAZE a) {\n    delete a;\n}\n\nstruct KeyPoints KAZE_Detect(KAZE a, Mat src) {\n    std::vector<cv::KeyPoint> detected;\n    (*a)->detect(*src, detected);\n\n    KeyPoint* kps = new KeyPoint[detected.size()];\n\n    for (size_t i = 0; i < detected.size(); ++i) {\n        KeyPoint k = {detected[i].pt.x, detected[i].pt.y, detected[i].size, detected[i].angle,\n                      detected[i].response, detected[i].octave, detected[i].class_id\n                     };\n        kps[i] = k;\n    }\n\n    KeyPoints ret = {kps, (int)detected.size()};\n    return ret;\n}\n\nstruct KeyPoints KAZE_Compute(KAZE a, Mat src, struct KeyPoints kp, Mat desc) {\n    std::vector<cv::KeyPoint> computed;\n    for (size_t i = 0; i < kp.length; i++) {\n        cv::KeyPoint k = cv::KeyPoint(kp.keypoints[i].x, kp.keypoints[i].y,\n            kp.keypoints[i].size, kp.keypoints[i].angle, kp.keypoints[i].response,\n            kp.keypoints[i].octave, kp.keypoints[i].classID);\n        computed.push_back(k);\n    }\n\n    (*a)->compute(*src, computed, *desc);\n\n    KeyPoint* kps = new KeyPoint[computed.size()];\n\n    for (size_t i = 0; i < computed.size(); ++i) {\n        KeyPoint k = {computed[i].pt.x, computed[i].pt.y, computed[i].size, computed[i].angle,\n                      computed[i].response, computed[i].octave, computed[i].class_id\n                     };\n        kps[i] = k;\n    }\n\n    KeyPoints ret = {kps, (int)computed.size()};\n    return ret;\n}\n\nstruct KeyPoints KAZE_DetectAndCompute(KAZE a, Mat src, Mat mask, Mat desc) {\n    std::vector<cv::KeyPoint> detected;\n    (*a)->detectAndCompute(*src, *mask, detected, *desc);\n\n    KeyPoint* kps = new KeyPoint[detected.size()];\n\n    for (size_t i = 0; i < detected.size(); ++i) {\n        KeyPoint k = {detected[i].pt.x, detected[i].pt.y, detected[i].size, detected[i].angle,\n                      detected[i].response, detected[i].octave, detected[i].class_id\n                     };\n        kps[i] = k;\n    }\n\n    KeyPoints ret = {kps, (int)detected.size()};\n    return ret;\n}\n\nMSER MSER_Create() {\n    // TODO: params\n    return new cv::Ptr<cv::MSER>(cv::MSER::create());\n}\n\nvoid MSER_Close(MSER a) {\n    delete a;\n}\n\nstruct KeyPoints MSER_Detect(MSER a, Mat src) {\n    std::vector<cv::KeyPoint> detected;\n    (*a)->detect(*src, detected);\n\n    KeyPoint* kps = new KeyPoint[detected.size()];\n\n    for (size_t i = 0; i < detected.size(); ++i) {\n        KeyPoint k = {detected[i].pt.x, detected[i].pt.y, detected[i].size, detected[i].angle,\n                      detected[i].response, detected[i].octave, detected[i].class_id\n                     };\n        kps[i] = k;\n    }\n\n    KeyPoints ret = {kps, (int)detected.size()};\n    return ret;\n}\n\nFastFeatureDetector FastFeatureDetector_Create() {\n    return new cv::Ptr<cv::FastFeatureDetector>(cv::FastFeatureDetector::create());\n}\n\nvoid FastFeatureDetector_Close(FastFeatureDetector f) {\n    delete f;\n}\n\nFastFeatureDetector FastFeatureDetector_CreateWithParams(int threshold, bool nonmaxSuppression, int type) {\n    return new cv::Ptr<cv::FastFeatureDetector>(cv::FastFeatureDetector::create(threshold,nonmaxSuppression,static_cast<cv::FastFeatureDetector::DetectorType>(type)));\n}\n\nstruct KeyPoints FastFeatureDetector_Detect(FastFeatureDetector f, Mat src) {\n    std::vector<cv::KeyPoint> detected;\n    (*f)->detect(*src, detected);\n\n    KeyPoint* kps = new KeyPoint[detected.size()];\n\n    for (size_t i = 0; i < detected.size(); ++i) {\n        KeyPoint k = {detected[i].pt.x, detected[i].pt.y, detected[i].size, detected[i].angle,\n                      detected[i].response, detected[i].octave, detected[i].class_id\n                     };\n        kps[i] = k;\n    }\n\n    KeyPoints ret = {kps, (int)detected.size()};\n    return ret;\n}\n\nORB ORB_Create() {\n    return new cv::Ptr<cv::ORB>(cv::ORB::create());\n}\n\nORB ORB_CreateWithParams(int nfeatures, float scaleFactor, int nlevels, int edgeThreshold, int firstLevel, int WTA_K, int scoreType, int patchSize, int fastThreshold) {\n    return new cv::Ptr<cv::ORB>(cv::ORB::create(nfeatures, scaleFactor, nlevels, edgeThreshold, firstLevel, WTA_K, static_cast<cv::ORB::ScoreType>(scoreType), patchSize, fastThreshold));\n}\n\nvoid ORB_Close(ORB o) {\n    delete o;\n}\n\nstruct KeyPoints ORB_Detect(ORB o, Mat src) {\n    std::vector<cv::KeyPoint> detected;\n    (*o)->detect(*src, detected);\n\n    KeyPoint* kps = new KeyPoint[detected.size()];\n\n    for (size_t i = 0; i < detected.size(); ++i) {\n        KeyPoint k = {detected[i].pt.x, detected[i].pt.y, detected[i].size, detected[i].angle,\n                      detected[i].response, detected[i].octave, detected[i].class_id\n                     };\n        kps[i] = k;\n    }\n\n    KeyPoints ret = {kps, (int)detected.size()};\n    return ret;\n}\n\nstruct KeyPoints ORB_Compute(ORB o, Mat src, struct KeyPoints kp, Mat desc) {\n    std::vector<cv::KeyPoint> computed;\n    for (size_t i = 0; i < kp.length; i++) {\n        cv::KeyPoint k = cv::KeyPoint(kp.keypoints[i].x, kp.keypoints[i].y,\n            kp.keypoints[i].size, kp.keypoints[i].angle, kp.keypoints[i].response,\n            kp.keypoints[i].octave, kp.keypoints[i].classID);\n        computed.push_back(k);\n    }\n\n    (*o)->compute(*src, computed, *desc);\n\n    KeyPoint* kps = new KeyPoint[computed.size()];\n\n    for (size_t i = 0; i < computed.size(); ++i) {\n        KeyPoint k = {computed[i].pt.x, computed[i].pt.y, computed[i].size, computed[i].angle,\n                      computed[i].response, computed[i].octave, computed[i].class_id\n                     };\n        kps[i] = k;\n    }\n\n    KeyPoints ret = {kps, (int)computed.size()};\n    return ret;\n}\n\nstruct KeyPoints ORB_DetectAndCompute(ORB o, Mat src, Mat mask, Mat desc) {\n    std::vector<cv::KeyPoint> detected;\n    (*o)->detectAndCompute(*src, *mask, detected, *desc);\n\n    KeyPoint* kps = new KeyPoint[detected.size()];\n\n    for (size_t i = 0; i < detected.size(); ++i) {\n        KeyPoint k = {detected[i].pt.x, detected[i].pt.y, detected[i].size, detected[i].angle,\n                      detected[i].response, detected[i].octave, detected[i].class_id\n                     };\n        kps[i] = k;\n    }\n\n    KeyPoints ret = {kps, (int)detected.size()};\n    return ret;\n}\n\ncv::SimpleBlobDetector::Params ConvertCParamsToCPPParams(SimpleBlobDetectorParams params) {\n    cv::SimpleBlobDetector::Params converted;\n\n    converted.blobColor = params.blobColor;\n    converted.filterByArea = params.filterByArea;\n    converted.filterByCircularity = params.filterByCircularity;\n    converted.filterByColor = params.filterByColor;\n    converted.filterByConvexity = params.filterByConvexity;\n    converted.filterByInertia = params.filterByInertia;\n    converted.maxArea = params.maxArea;\n    converted.maxCircularity = params.maxCircularity;\n    converted.maxConvexity = params.maxConvexity;\n    converted.maxInertiaRatio = params.maxInertiaRatio;\n    converted.maxThreshold = params.maxThreshold;\n    converted.minArea = params.minArea;\n    converted.minCircularity = params.minCircularity;\n    converted.minConvexity = params.minConvexity;\n    converted.minDistBetweenBlobs = params.minDistBetweenBlobs;\n    converted.minInertiaRatio = params.minInertiaRatio;\n    converted.minRepeatability = params.minRepeatability;\n    converted.minThreshold = params.minThreshold;\n    converted.thresholdStep = params.thresholdStep;\n\n    return converted;\n}\n\nSimpleBlobDetectorParams ConvertCPPParamsToCParams(cv::SimpleBlobDetector::Params params) {\n    SimpleBlobDetectorParams converted;\n\n    converted.blobColor = params.blobColor;\n    converted.filterByArea = params.filterByArea;\n    converted.filterByCircularity = params.filterByCircularity;\n    converted.filterByColor = params.filterByColor;\n    converted.filterByConvexity = params.filterByConvexity;\n    converted.filterByInertia = params.filterByInertia;\n    converted.maxArea = params.maxArea;\n    converted.maxCircularity = params.maxCircularity;\n    converted.maxConvexity = params.maxConvexity;\n    converted.maxInertiaRatio = params.maxInertiaRatio;\n    converted.maxThreshold = params.maxThreshold;\n    converted.minArea = params.minArea;\n    converted.minCircularity = params.minCircularity;\n    converted.minConvexity = params.minConvexity;\n    converted.minDistBetweenBlobs = params.minDistBetweenBlobs;\n    converted.minInertiaRatio = params.minInertiaRatio;\n    converted.minRepeatability = params.minRepeatability;\n    converted.minThreshold = params.minThreshold;\n    converted.thresholdStep = params.thresholdStep;\n\n    return converted;\n}\n\nSimpleBlobDetector SimpleBlobDetector_Create_WithParams(SimpleBlobDetectorParams params){\n    cv::SimpleBlobDetector::Params actualParams;\n    return new cv::Ptr<cv::SimpleBlobDetector>(cv::SimpleBlobDetector::create(ConvertCParamsToCPPParams(params)));\n}\n\nSimpleBlobDetector SimpleBlobDetector_Create() {\n    return new cv::Ptr<cv::SimpleBlobDetector>(cv::SimpleBlobDetector::create());\n}\n\nSimpleBlobDetectorParams SimpleBlobDetectorParams_Create() {\n    return ConvertCPPParamsToCParams(cv::SimpleBlobDetector::Params());\n}\n\nvoid SimpleBlobDetector_Close(SimpleBlobDetector b) {\n    delete b;\n}\n\nstruct KeyPoints SimpleBlobDetector_Detect(SimpleBlobDetector b, Mat src) {\n    std::vector<cv::KeyPoint> detected;\n    (*b)->detect(*src, detected);\n\n    KeyPoint* kps = new KeyPoint[detected.size()];\n\n    for (size_t i = 0; i < detected.size(); ++i) {\n        KeyPoint k = {detected[i].pt.x, detected[i].pt.y, detected[i].size, detected[i].angle,\n                      detected[i].response, detected[i].octave, detected[i].class_id\n                     };\n        kps[i] = k;\n    }\n\n    KeyPoints ret = {kps, (int)detected.size()};\n    return ret;\n}\n\nBFMatcher BFMatcher_Create() {\n    return new cv::Ptr<cv::BFMatcher>(cv::BFMatcher::create());\n}\n\nBFMatcher BFMatcher_CreateWithParams(int normType, bool crossCheck) {\n    return new cv::Ptr<cv::BFMatcher>(cv::BFMatcher::create(normType, crossCheck));\n}\n\nvoid BFMatcher_Close(BFMatcher b) {\n    delete b;\n}\n\nstruct DMatches BFMatcher_Match(BFMatcher b, Mat query, Mat train) {\n    std::vector<cv::DMatch> matches;\n    (*b)->match(*query, *train, matches);\n\n    DMatch *dmatches = new DMatch[matches.size()];\n    for (size_t i = 0; i < matches.size(); ++i) {\n        DMatch dmatch = {matches[i].queryIdx, matches[i].trainIdx, matches[i].imgIdx, matches[i].distance};\n        dmatches[i] = dmatch;\n    }\n    DMatches ret = {dmatches, (int) matches.size()};\n    return ret;\n}\n\nstruct MultiDMatches BFMatcher_KnnMatch(BFMatcher b, Mat query, Mat train, int k) {\n    std::vector< std::vector<cv::DMatch> > matches;\n    (*b)->knnMatch(*query, *train, matches, k);\n\n    DMatches *dms = new DMatches[matches.size()];\n    for (size_t i = 0; i < matches.size(); ++i) {\n        DMatch *dmatches = new DMatch[matches[i].size()];\n        for (size_t j = 0; j < matches[i].size(); ++j) {\n            DMatch dmatch = {matches[i][j].queryIdx, matches[i][j].trainIdx, matches[i][j].imgIdx,\n                             matches[i][j].distance};\n            dmatches[j] = dmatch;\n        }\n        dms[i] = {dmatches, (int) matches[i].size()};\n    }\n    MultiDMatches ret = {dms, (int) matches.size()};\n    return ret;\n}\n\nstruct MultiDMatches BFMatcher_KnnMatchWithParams(BFMatcher b, Mat query, Mat train, int k, Mat mask, bool compactResult) {\n    std::vector< std::vector<cv::DMatch> > matches;\n    (*b)->knnMatch(*query, *train, matches, k, *mask, compactResult);\n\n    DMatches *dms = new DMatches[matches.size()];\n    for (size_t i = 0; i < matches.size(); ++i) {\n        DMatch *dmatches = new DMatch[matches[i].size()];\n        for (size_t j = 0; j < matches[i].size(); ++j) {\n            DMatch dmatch = {matches[i][j].queryIdx, matches[i][j].trainIdx, matches[i][j].imgIdx,\n                             matches[i][j].distance};\n            dmatches[j] = dmatch;\n        }\n        dms[i] = {dmatches, (int) matches[i].size()};\n    }\n    MultiDMatches ret = {dms, (int) matches.size()};\n    return ret;\n}\n\nFlannBasedMatcher FlannBasedMatcher_Create() {\n    return new cv::Ptr<cv::FlannBasedMatcher>(cv::FlannBasedMatcher::create());\n}\n\nvoid FlannBasedMatcher_Close(FlannBasedMatcher f) {\n    delete f;\n}\n\nstruct MultiDMatches FlannBasedMatcher_KnnMatch(FlannBasedMatcher f, Mat query, Mat train, int k) {\n    std::vector< std::vector<cv::DMatch> > matches;\n    (*f)->knnMatch(*query, *train, matches, k);\n\n    DMatches *dms = new DMatches[matches.size()];\n    for (size_t i = 0; i < matches.size(); ++i) {\n        DMatch *dmatches = new DMatch[matches[i].size()];\n        for (size_t j = 0; j < matches[i].size(); ++j) {\n            DMatch dmatch = {matches[i][j].queryIdx, matches[i][j].trainIdx, matches[i][j].imgIdx,\n                             matches[i][j].distance};\n            dmatches[j] = dmatch;\n        }\n        dms[i] = {dmatches, (int) matches[i].size()};\n    }\n    MultiDMatches ret = {dms, (int) matches.size()};\n    return ret;\n}\n\nstruct MultiDMatches FlannBasedMatcher_KnnMatchWithParams(FlannBasedMatcher f, Mat query, Mat train, int k, Mat mask, bool compactResult) {\n    std::vector< std::vector<cv::DMatch> > matches;\n    (*f)->knnMatch(*query, *train, matches, k, *mask, compactResult);\n\n    DMatches *dms = new DMatches[matches.size()];\n    for (size_t i = 0; i < matches.size(); ++i) {\n        DMatch *dmatches = new DMatch[matches[i].size()];\n        for (size_t j = 0; j < matches[i].size(); ++j) {\n            DMatch dmatch = {matches[i][j].queryIdx, matches[i][j].trainIdx, matches[i][j].imgIdx,\n                             matches[i][j].distance};\n            dmatches[j] = dmatch;\n        }\n        dms[i] = {dmatches, (int) matches[i].size()};\n    }\n    MultiDMatches ret = {dms, (int) matches.size()};\n    return ret;\n}\n\nvoid DrawKeyPoints(Mat src, struct KeyPoints kp, Mat dst, Scalar s, int flags) {\n        std::vector<cv::KeyPoint> keypts;\n        cv::KeyPoint keypt;\n\n        for (int i = 0; i < kp.length; ++i) {\n                keypt = cv::KeyPoint(kp.keypoints[i].x, kp.keypoints[i].y,\n                                kp.keypoints[i].size, kp.keypoints[i].angle, kp.keypoints[i].response,\n                                kp.keypoints[i].octave, kp.keypoints[i].classID);\n                keypts.push_back(keypt);\n        }\n\n        cv::Scalar color = cv::Scalar(s.val1, s.val2, s.val3, s.val4);\n\n        cv::drawKeypoints(*src, keypts, *dst, color, static_cast<cv::DrawMatchesFlags>(flags));\n}\n\nSIFT SIFT_Create() {\n    // TODO: params\n    return new cv::Ptr<cv::SIFT>(cv::SIFT::create());\n}\n\nSIFT SIFT_CreateWithParams(int nfeatures, int nOctaveLayers, double contrastThreshold, double edgeThreshold, double sigma) {\n    return new cv::Ptr<cv::SIFT>(cv::SIFT::create(nfeatures, nOctaveLayers, contrastThreshold, edgeThreshold, sigma));\n}\n\n\nvoid SIFT_Close(SIFT d) {\n    delete d;\n}\n\nstruct KeyPoints SIFT_Detect(SIFT d, Mat src) {\n    std::vector<cv::KeyPoint> detected;\n    (*d)->detect(*src, detected);\n\n    KeyPoint* kps = new KeyPoint[detected.size()];\n\n    for (size_t i = 0; i < detected.size(); ++i) {\n        KeyPoint k = {detected[i].pt.x, detected[i].pt.y, detected[i].size, detected[i].angle,\n                      detected[i].response, detected[i].octave, detected[i].class_id\n                     };\n        kps[i] = k;\n    }\n\n    KeyPoints ret = {kps, (int)detected.size()};\n    return ret;\n}\n\nstruct KeyPoints SIFT_Compute(SIFT d, Mat src, struct KeyPoints kp, Mat desc) {\n    std::vector<cv::KeyPoint> computed;\n    for (size_t i = 0; i < kp.length; i++) {\n        cv::KeyPoint k = cv::KeyPoint(kp.keypoints[i].x, kp.keypoints[i].y,\n            kp.keypoints[i].size, kp.keypoints[i].angle, kp.keypoints[i].response,\n            kp.keypoints[i].octave, kp.keypoints[i].classID);\n        computed.push_back(k);\n    }\n\n    (*d)->compute(*src, computed, *desc);\n\n    KeyPoint* kps = new KeyPoint[computed.size()];\n\n    for (size_t i = 0; i < computed.size(); ++i) {\n        KeyPoint k = {computed[i].pt.x, computed[i].pt.y, computed[i].size, computed[i].angle,\n                      computed[i].response, computed[i].octave, computed[i].class_id\n                     };\n        kps[i] = k;\n    }\n\n    KeyPoints ret = {kps, (int)computed.size()};\n    return ret;\n}\n\nstruct KeyPoints SIFT_DetectAndCompute(SIFT d, Mat src, Mat mask, Mat desc) {\n    std::vector<cv::KeyPoint> detected;\n    (*d)->detectAndCompute(*src, *mask, detected, *desc);\n\n    KeyPoint* kps = new KeyPoint[detected.size()];\n\n    for (size_t i = 0; i < detected.size(); ++i) {\n        KeyPoint k = {detected[i].pt.x, detected[i].pt.y, detected[i].size, detected[i].angle,\n                      detected[i].response, detected[i].octave, detected[i].class_id\n                     };\n        kps[i] = k;\n    }\n\n    KeyPoints ret = {kps, (int)detected.size()};\n    return ret;\n}\n\nvoid DrawMatches(Mat img1, struct KeyPoints kp1, Mat img2, struct KeyPoints kp2, struct DMatches matches1to2, Mat outImg, const Scalar matchesColor, const Scalar pointColor, struct ByteArray matchesMask, int flags) {\n    std::vector<cv::KeyPoint> kp1vec, kp2vec;\n    cv::KeyPoint keypt;\n\n    for (int i = 0; i < kp1.length; ++i) {\n        keypt = cv::KeyPoint(kp1.keypoints[i].x, kp1.keypoints[i].y,\n                            kp1.keypoints[i].size, kp1.keypoints[i].angle, kp1.keypoints[i].response,\n                            kp1.keypoints[i].octave, kp1.keypoints[i].classID);\n        kp1vec.push_back(keypt);\n    }\n\n    for (int i = 0; i < kp2.length; ++i) {\n        keypt = cv::KeyPoint(kp2.keypoints[i].x, kp2.keypoints[i].y,\n                            kp2.keypoints[i].size, kp2.keypoints[i].angle, kp2.keypoints[i].response,\n                            kp2.keypoints[i].octave, kp2.keypoints[i].classID);\n        kp2vec.push_back(keypt);\n    }\n\n    cv::Scalar cvmatchescolor = cv::Scalar(matchesColor.val1, matchesColor.val2, matchesColor.val3, matchesColor.val4);\n    cv::Scalar cvpointcolor = cv::Scalar(pointColor.val1, pointColor.val2, pointColor.val3, pointColor.val4);\n    \n    std::vector<cv::DMatch> dmatchvec;\n    cv::DMatch dm;\n\n    for (int i = 0; i < matches1to2.length; i++) {\n        dm = cv::DMatch(matches1to2.dmatches[i].queryIdx, matches1to2.dmatches[i].trainIdx,\n                        matches1to2.dmatches[i].imgIdx, matches1to2.dmatches[i].distance);\n        dmatchvec.push_back(dm);\n    }\n\n    std::vector<char> maskvec;\n\n    for (int i = 0; i < matchesMask.length; i++) {\n        maskvec.push_back(matchesMask.data[i]);\n    }\n\n    cv::drawMatches(*img1, kp1vec, *img2, kp2vec, dmatchvec, *outImg, cvmatchescolor, cvpointcolor, maskvec, static_cast<cv::DrawMatchesFlags>(flags));\n}\n"
        },
        {
          "name": "features2d.go",
          "type": "blob",
          "size": 33.8740234375,
          "content": "package gocv\n\n/*\n#include <stdlib.h>\n#include \"features2d.h\"\n*/\nimport \"C\"\nimport (\n\t\"image/color\"\n\t\"io\"\n\t\"reflect\"\n\t\"unsafe\"\n)\n\ntype Feature2DDetector interface {\n\tDetect(src Mat) []KeyPoint\n}\n\ntype Feature2DComputer interface {\n\tCompute(src Mat, mask Mat, kps []KeyPoint) ([]KeyPoint, Mat)\n}\n\ntype Feature2DDetectComputer interface {\n\tDetectAndCompute(src Mat, mask Mat) ([]KeyPoint, Mat)\n}\n\ntype Feature2D interface {\n\tio.Closer\n\tFeature2DDetector\n\tFeature2DComputer\n\tFeature2DDetectComputer\n}\n\n// AKAZE is a wrapper around the cv::AKAZE algorithm.\ntype AKAZE struct {\n\t// C.AKAZE\n\tp unsafe.Pointer\n}\n\nvar _ Feature2D = (*AKAZE)(nil)\n\n// NewAKAZE returns a new AKAZE algorithm\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d8/d30/classcv_1_1AKAZE.html\nfunc NewAKAZE() AKAZE {\n\treturn AKAZE{p: unsafe.Pointer(C.AKAZE_Create())}\n}\n\n// Close AKAZE.\nfunc (a *AKAZE) Close() error {\n\tC.AKAZE_Close((C.AKAZE)(a.p))\n\ta.p = nil\n\treturn nil\n}\n\n// Detect keypoints in an image using AKAZE.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d0/d13/classcv_1_1Feature2D.html#aa4e9a7082ec61ebc108806704fbd7887\nfunc (a *AKAZE) Detect(src Mat) []KeyPoint {\n\tret := C.AKAZE_Detect((C.AKAZE)(a.p), src.p)\n\tdefer C.KeyPoints_Close(ret)\n\n\treturn getKeyPoints(ret)\n}\n\n// Compute keypoints in an image using AKAZE.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d0/d13/classcv_1_1Feature2D.html#ab3cce8d56f4fc5e1d530b5931e1e8dc0\nfunc (a *AKAZE) Compute(src Mat, mask Mat, kps []KeyPoint) ([]KeyPoint, Mat) {\n\tdesc := NewMat()\n\tkp2arr := make([]C.struct_KeyPoint, len(kps))\n\tfor i, kp := range kps {\n\t\tkp2arr[i].x = C.double(kp.X)\n\t\tkp2arr[i].y = C.double(kp.Y)\n\t\tkp2arr[i].size = C.double(kp.Size)\n\t\tkp2arr[i].angle = C.double(kp.Angle)\n\t\tkp2arr[i].response = C.double(kp.Response)\n\t\tkp2arr[i].octave = C.int(kp.Octave)\n\t\tkp2arr[i].classID = C.int(kp.ClassID)\n\t}\n\tcKeyPoints := C.struct_KeyPoints{\n\t\tkeypoints: (*C.struct_KeyPoint)(&kp2arr[0]),\n\t\tlength:    (C.int)(len(kps)),\n\t}\n\n\tret := C.AKAZE_Compute((C.AKAZE)(a.p), src.p, cKeyPoints, desc.p)\n\tdefer C.KeyPoints_Close(ret)\n\n\treturn getKeyPoints(ret), desc\n}\n\n// DetectAndCompute keypoints and compute in an image using AKAZE.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d0/d13/classcv_1_1Feature2D.html#a8be0d1c20b08eb867184b8d74c15a677\nfunc (a *AKAZE) DetectAndCompute(src Mat, mask Mat) ([]KeyPoint, Mat) {\n\tdesc := NewMat()\n\tret := C.AKAZE_DetectAndCompute((C.AKAZE)(a.p), src.p, mask.p, desc.p)\n\tdefer C.KeyPoints_Close(ret)\n\n\treturn getKeyPoints(ret), desc\n}\n\n// AgastFeatureDetector is a wrapper around the cv::AgastFeatureDetector.\ntype AgastFeatureDetector struct {\n\t// C.AgastFeatureDetector\n\tp unsafe.Pointer\n}\n\n// NewAgastFeatureDetector returns a new AgastFeatureDetector algorithm\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/d19/classcv_1_1AgastFeatureDetector.html\nfunc NewAgastFeatureDetector() AgastFeatureDetector {\n\treturn AgastFeatureDetector{p: unsafe.Pointer(C.AgastFeatureDetector_Create())}\n}\n\n// Close AgastFeatureDetector.\nfunc (a *AgastFeatureDetector) Close() error {\n\tC.AgastFeatureDetector_Close((C.AgastFeatureDetector)(a.p))\n\ta.p = nil\n\treturn nil\n}\n\n// Detect keypoints in an image using AgastFeatureDetector.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d0/d13/classcv_1_1Feature2D.html#aa4e9a7082ec61ebc108806704fbd7887\nfunc (a *AgastFeatureDetector) Detect(src Mat) []KeyPoint {\n\tret := C.AgastFeatureDetector_Detect((C.AgastFeatureDetector)(a.p), src.p)\n\tdefer C.KeyPoints_Close(ret)\n\n\treturn getKeyPoints(ret)\n}\n\n// BRISK is a wrapper around the cv::BRISK algorithm.\ntype BRISK struct {\n\t// C.BRISK\n\tp unsafe.Pointer\n}\n\nvar _ Feature2D = (*BRISK)(nil)\n\n// NewBRISK returns a new BRISK algorithm\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d8/d30/classcv_1_1AKAZE.html\nfunc NewBRISK() BRISK {\n\treturn BRISK{p: unsafe.Pointer(C.BRISK_Create())}\n}\n\n// Close BRISK.\nfunc (b *BRISK) Close() error {\n\tC.BRISK_Close((C.BRISK)(b.p))\n\tb.p = nil\n\treturn nil\n}\n\n// Detect keypoints in an image using BRISK.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d0/d13/classcv_1_1Feature2D.html#aa4e9a7082ec61ebc108806704fbd7887\nfunc (b *BRISK) Detect(src Mat) []KeyPoint {\n\tret := C.BRISK_Detect((C.BRISK)(b.p), src.p)\n\tdefer C.KeyPoints_Close(ret)\n\n\treturn getKeyPoints(ret)\n}\n\n// Compute keypoints in an image using BRISK.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d0/d13/classcv_1_1Feature2D.html#ab3cce8d56f4fc5e1d530b5931e1e8dc0\nfunc (b *BRISK) Compute(src Mat, mask Mat, kps []KeyPoint) ([]KeyPoint, Mat) {\n\tdesc := NewMat()\n\tkp2arr := make([]C.struct_KeyPoint, len(kps))\n\tfor i, kp := range kps {\n\t\tkp2arr[i].x = C.double(kp.X)\n\t\tkp2arr[i].y = C.double(kp.Y)\n\t\tkp2arr[i].size = C.double(kp.Size)\n\t\tkp2arr[i].angle = C.double(kp.Angle)\n\t\tkp2arr[i].response = C.double(kp.Response)\n\t\tkp2arr[i].octave = C.int(kp.Octave)\n\t\tkp2arr[i].classID = C.int(kp.ClassID)\n\t}\n\tcKeyPoints := C.struct_KeyPoints{\n\t\tkeypoints: (*C.struct_KeyPoint)(&kp2arr[0]),\n\t\tlength:    (C.int)(len(kps)),\n\t}\n\n\tret := C.BRISK_Compute((C.BRISK)(b.p), src.p, cKeyPoints, desc.p)\n\tdefer C.KeyPoints_Close(ret)\n\n\treturn getKeyPoints(ret), desc\n}\n\n// DetectAndCompute keypoints and compute in an image using BRISK.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d0/d13/classcv_1_1Feature2D.html#a8be0d1c20b08eb867184b8d74c15a677\nfunc (b *BRISK) DetectAndCompute(src Mat, mask Mat) ([]KeyPoint, Mat) {\n\tdesc := NewMat()\n\tret := C.BRISK_DetectAndCompute((C.BRISK)(b.p), src.p, mask.p, desc.p)\n\tdefer C.KeyPoints_Close(ret)\n\n\treturn getKeyPoints(ret), desc\n}\n\n// FastFeatureDetectorType defines the detector type\n//\n// For further details, please see:\n// https://docs.opencv.org/master/df/d74/classcv_1_1FastFeatureDetector.html#a4654f6fb0aa4b8e9123b223bfa0e2a08\ntype FastFeatureDetectorType int\n\nconst (\n\t//FastFeatureDetectorType58 is an alias of FastFeatureDetector::TYPE_5_8\n\tFastFeatureDetectorType58 FastFeatureDetectorType = 0\n\t//FastFeatureDetectorType712 is an alias of FastFeatureDetector::TYPE_7_12\n\tFastFeatureDetectorType712 FastFeatureDetectorType = 1\n\t//FastFeatureDetectorType916 is an alias of FastFeatureDetector::TYPE_9_16\n\tFastFeatureDetectorType916 FastFeatureDetectorType = 2\n)\n\n// FastFeatureDetector is a wrapper around the cv::FastFeatureDetector.\ntype FastFeatureDetector struct {\n\t// C.FastFeatureDetector\n\tp unsafe.Pointer\n}\n\n// NewFastFeatureDetector returns a new FastFeatureDetector algorithm\n//\n// For further details, please see:\n// https://docs.opencv.org/master/df/d74/classcv_1_1FastFeatureDetector.html\nfunc NewFastFeatureDetector() FastFeatureDetector {\n\treturn FastFeatureDetector{p: unsafe.Pointer(C.FastFeatureDetector_Create())}\n}\n\n// NewFastFeatureDetectorWithParams returns a new FastFeatureDetector algorithm with parameters\n//\n// For further details, please see:\n// https://docs.opencv.org/master/df/d74/classcv_1_1FastFeatureDetector.html#ab986f2ff8f8778aab1707e2642bc7f8e\nfunc NewFastFeatureDetectorWithParams(threshold int, nonmaxSuppression bool, typ FastFeatureDetectorType) FastFeatureDetector {\n\treturn FastFeatureDetector{p: unsafe.Pointer(C.FastFeatureDetector_CreateWithParams(C.int(threshold), C.bool(nonmaxSuppression), C.int(typ)))}\n}\n\n// Close FastFeatureDetector.\nfunc (f *FastFeatureDetector) Close() error {\n\tC.FastFeatureDetector_Close((C.FastFeatureDetector)(f.p))\n\tf.p = nil\n\treturn nil\n}\n\n// Detect keypoints in an image using FastFeatureDetector.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d0/d13/classcv_1_1Feature2D.html#aa4e9a7082ec61ebc108806704fbd7887\nfunc (f *FastFeatureDetector) Detect(src Mat) []KeyPoint {\n\tret := C.FastFeatureDetector_Detect((C.FastFeatureDetector)(f.p), src.p)\n\tdefer C.KeyPoints_Close(ret)\n\n\treturn getKeyPoints(ret)\n}\n\n// GFTTDetector is a wrapper around the cv::GFTTDetector algorithm.\ntype GFTTDetector struct {\n\t// C.GFTTDetector\n\tp unsafe.Pointer\n}\n\n// NewGFTTDetector returns a new GFTTDetector algorithm\n//\n// For further details, please see:\n// https://docs.opencv.org/master/df/d21/classcv_1_1GFTTDetector.html\nfunc NewGFTTDetector() GFTTDetector {\n\treturn GFTTDetector{p: unsafe.Pointer(C.GFTTDetector_Create())}\n}\n\n// Close GFTTDetector.\nfunc (a *GFTTDetector) Close() error {\n\tC.GFTTDetector_Close((C.GFTTDetector)(a.p))\n\ta.p = nil\n\treturn nil\n}\n\n// Detect keypoints in an image using GFTTDetector.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d0/d13/classcv_1_1Feature2D.html#aa4e9a7082ec61ebc108806704fbd7887\nfunc (a *GFTTDetector) Detect(src Mat) []KeyPoint {\n\tret := C.GFTTDetector_Detect((C.GFTTDetector)(a.p), src.p)\n\tdefer C.KeyPoints_Close(ret)\n\n\treturn getKeyPoints(ret)\n}\n\n// KAZE is a wrapper around the cv::KAZE algorithm.\ntype KAZE struct {\n\t// C.KAZE\n\tp unsafe.Pointer\n}\n\nvar _ Feature2D = (*KAZE)(nil)\n\n// NewKAZE returns a new KAZE algorithm\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/d61/classcv_1_1KAZE.html\nfunc NewKAZE() KAZE {\n\treturn KAZE{p: unsafe.Pointer(C.KAZE_Create())}\n}\n\n// Close KAZE.\nfunc (a *KAZE) Close() error {\n\tC.KAZE_Close((C.KAZE)(a.p))\n\ta.p = nil\n\treturn nil\n}\n\n// Detect keypoints in an image using KAZE.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d0/d13/classcv_1_1Feature2D.html#aa4e9a7082ec61ebc108806704fbd7887\nfunc (a *KAZE) Detect(src Mat) []KeyPoint {\n\tret := C.KAZE_Detect((C.KAZE)(a.p), src.p)\n\tdefer C.KeyPoints_Close(ret)\n\n\treturn getKeyPoints(ret)\n}\n\n// Compute keypoints in an image using KAZE.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d0/d13/classcv_1_1Feature2D.html#ab3cce8d56f4fc5e1d530b5931e1e8dc0\nfunc (a *KAZE) Compute(src Mat, mask Mat, kps []KeyPoint) ([]KeyPoint, Mat) {\n\tdesc := NewMat()\n\tkp2arr := make([]C.struct_KeyPoint, len(kps))\n\tfor i, kp := range kps {\n\t\tkp2arr[i].x = C.double(kp.X)\n\t\tkp2arr[i].y = C.double(kp.Y)\n\t\tkp2arr[i].size = C.double(kp.Size)\n\t\tkp2arr[i].angle = C.double(kp.Angle)\n\t\tkp2arr[i].response = C.double(kp.Response)\n\t\tkp2arr[i].octave = C.int(kp.Octave)\n\t\tkp2arr[i].classID = C.int(kp.ClassID)\n\t}\n\tcKeyPoints := C.struct_KeyPoints{\n\t\tkeypoints: (*C.struct_KeyPoint)(&kp2arr[0]),\n\t\tlength:    (C.int)(len(kps)),\n\t}\n\n\tret := C.KAZE_Compute((C.KAZE)(a.p), src.p, cKeyPoints, desc.p)\n\tdefer C.KeyPoints_Close(ret)\n\n\treturn getKeyPoints(ret), desc\n}\n\n// DetectAndCompute keypoints and compute in an image using KAZE.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d0/d13/classcv_1_1Feature2D.html#a8be0d1c20b08eb867184b8d74c15a677\nfunc (a *KAZE) DetectAndCompute(src Mat, mask Mat) ([]KeyPoint, Mat) {\n\tdesc := NewMat()\n\tret := C.KAZE_DetectAndCompute((C.KAZE)(a.p), src.p, mask.p, desc.p)\n\tdefer C.KeyPoints_Close(ret)\n\n\treturn getKeyPoints(ret), desc\n}\n\n// MSER is a wrapper around the cv::MSER algorithm.\ntype MSER struct {\n\t// C.MSER\n\tp unsafe.Pointer\n}\n\n// NewMSER returns a new MSER algorithm\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/d28/classcv_1_1MSER.html\nfunc NewMSER() MSER {\n\treturn MSER{p: unsafe.Pointer(C.MSER_Create())}\n}\n\n// Close MSER.\nfunc (a *MSER) Close() error {\n\tC.MSER_Close((C.MSER)(a.p))\n\ta.p = nil\n\treturn nil\n}\n\n// Detect keypoints in an image using MSER.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d0/d13/classcv_1_1Feature2D.html#aa4e9a7082ec61ebc108806704fbd7887\nfunc (a *MSER) Detect(src Mat) []KeyPoint {\n\tret := C.MSER_Detect((C.MSER)(a.p), src.p)\n\tdefer C.KeyPoints_Close(ret)\n\n\treturn getKeyPoints(ret)\n}\n\n// ORB is a wrapper around the cv::ORB.\ntype ORB struct {\n\t// C.ORB\n\tp unsafe.Pointer\n}\n\nvar _ Feature2D = (*ORB)(nil)\n\n// NewORB returns a new ORB algorithm\n//\n// For further details, please see:\n// https://docs.opencv.org/master/db/d95/classcv_1_1ORB.html\nfunc NewORB() ORB {\n\treturn ORB{p: unsafe.Pointer(C.ORB_Create())}\n}\n\n// NewORBWithParams returns a new ORB algorithm with parameters\n//\n// For further details, please see:\n// https://docs.opencv.org/master/db/d95/classcv_1_1ORB.html#aeff0cbe668659b7ca14bb85ff1c4073b\nfunc NewORBWithParams(nFeatures int, scaleFactor float32, nLevels int, edgeThreshold int, firstLevel int, WTAK int, scoreType ORBScoreType, patchSize int, fastThreshold int) ORB {\n\treturn ORB{p: unsafe.Pointer(C.ORB_CreateWithParams(\n\t\tC.int(nFeatures),\n\t\tC.float(scaleFactor),\n\t\tC.int(nLevels),\n\t\tC.int(edgeThreshold),\n\t\tC.int(firstLevel),\n\t\tC.int(WTAK),\n\t\tC.int(scoreType),\n\t\tC.int(patchSize),\n\t\tC.int(fastThreshold),\n\t))}\n}\n\ntype ORBScoreType int\n\nconst (\n\tORBScoreTypeHarris ORBScoreType = 0\n\tORBScoreTypeFAST   ORBScoreType = 1\n)\n\n// Close ORB.\nfunc (o *ORB) Close() error {\n\tC.ORB_Close((C.ORB)(o.p))\n\to.p = nil\n\treturn nil\n}\n\n// Detect keypoints in an image using ORB.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d0/d13/classcv_1_1Feature2D.html#aa4e9a7082ec61ebc108806704fbd7887\nfunc (o *ORB) Detect(src Mat) []KeyPoint {\n\tret := C.ORB_Detect((C.ORB)(o.p), src.p)\n\tdefer C.KeyPoints_Close(ret)\n\n\treturn getKeyPoints(ret)\n}\n\n// Compute keypoints in an image using ORB.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d0/d13/classcv_1_1Feature2D.html#ab3cce8d56f4fc5e1d530b5931e1e8dc0\nfunc (o *ORB) Compute(src Mat, mask Mat, kps []KeyPoint) ([]KeyPoint, Mat) {\n\tdesc := NewMat()\n\tkp2arr := make([]C.struct_KeyPoint, len(kps))\n\tfor i, kp := range kps {\n\t\tkp2arr[i].x = C.double(kp.X)\n\t\tkp2arr[i].y = C.double(kp.Y)\n\t\tkp2arr[i].size = C.double(kp.Size)\n\t\tkp2arr[i].angle = C.double(kp.Angle)\n\t\tkp2arr[i].response = C.double(kp.Response)\n\t\tkp2arr[i].octave = C.int(kp.Octave)\n\t\tkp2arr[i].classID = C.int(kp.ClassID)\n\t}\n\tcKeyPoints := C.struct_KeyPoints{\n\t\tkeypoints: (*C.struct_KeyPoint)(&kp2arr[0]),\n\t\tlength:    (C.int)(len(kps)),\n\t}\n\n\tret := C.ORB_Compute((C.ORB)(o.p), src.p, cKeyPoints, desc.p)\n\tdefer C.KeyPoints_Close(ret)\n\n\treturn getKeyPoints(ret), desc\n}\n\n// DetectAndCompute detects keypoints and computes from an image using ORB.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d0/d13/classcv_1_1Feature2D.html#a8be0d1c20b08eb867184b8d74c15a677\nfunc (o *ORB) DetectAndCompute(src Mat, mask Mat) ([]KeyPoint, Mat) {\n\tdesc := NewMat()\n\tret := C.ORB_DetectAndCompute((C.ORB)(o.p), src.p, mask.p, desc.p)\n\tdefer C.KeyPoints_Close(ret)\n\n\treturn getKeyPoints(ret), desc\n}\n\n// SimpleBlobDetector is a wrapper around the cv::SimpleBlobDetector.\ntype SimpleBlobDetector struct {\n\t// C.SimpleBlobDetector\n\tp unsafe.Pointer\n}\n\n// SimpleBlobDetector_Params is a wrapper around the cv::SimpleBlobdetector::Params\ntype SimpleBlobDetectorParams struct {\n\tp C.SimpleBlobDetectorParams\n}\n\n// NewSimpleBlobDetector returns a new SimpleBlobDetector algorithm\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d0/d7a/classcv_1_1SimpleBlobDetector.html\nfunc NewSimpleBlobDetector() SimpleBlobDetector {\n\treturn SimpleBlobDetector{p: unsafe.Pointer(C.SimpleBlobDetector_Create())}\n}\n\n// NewSimpleBlobDetectorWithParams returns a new SimpleBlobDetector with custom parameters\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d0/d7a/classcv_1_1SimpleBlobDetector.html\nfunc NewSimpleBlobDetectorWithParams(params SimpleBlobDetectorParams) SimpleBlobDetector {\n\treturn SimpleBlobDetector{p: unsafe.Pointer(C.SimpleBlobDetector_Create_WithParams(params.p))}\n}\n\n// Close SimpleBlobDetector.\nfunc (b *SimpleBlobDetector) Close() error {\n\tC.SimpleBlobDetector_Close((C.SimpleBlobDetector)(b.p))\n\tb.p = nil\n\treturn nil\n}\n\n// NewSimpleBlobDetectorParams returns the default parameters for the SimpleBobDetector\nfunc NewSimpleBlobDetectorParams() SimpleBlobDetectorParams {\n\treturn SimpleBlobDetectorParams{p: C.SimpleBlobDetectorParams_Create()}\n}\n\n// SetBlobColor sets the blobColor field\nfunc (p *SimpleBlobDetectorParams) SetBlobColor(blobColor int) {\n\tp.p.blobColor = C.uchar(blobColor)\n}\n\n// GetBlobColor gets the blobColor field\nfunc (p *SimpleBlobDetectorParams) GetBlobColor() int {\n\treturn int(p.p.blobColor)\n}\n\n// SetFilterByArea sets the filterByArea field\nfunc (p *SimpleBlobDetectorParams) SetFilterByArea(filterByArea bool) {\n\tp.p.filterByArea = C.bool(filterByArea)\n}\n\n// GetFilterByArea gets the filterByArea field\nfunc (p *SimpleBlobDetectorParams) GetFilterByArea() bool {\n\treturn bool(p.p.filterByArea)\n}\n\n// SetFilterByCircularity sets the filterByCircularity field\nfunc (p *SimpleBlobDetectorParams) SetFilterByCircularity(filterByCircularity bool) {\n\tp.p.filterByCircularity = C.bool(filterByCircularity)\n}\n\n// GetFilterByCircularity gets the filterByCircularity field\nfunc (p *SimpleBlobDetectorParams) GetFilterByCircularity() bool {\n\treturn bool(p.p.filterByCircularity)\n}\n\n// SetFilterByColor sets the filterByColor field\nfunc (p *SimpleBlobDetectorParams) SetFilterByColor(filterByColor bool) {\n\tp.p.filterByColor = C.bool(filterByColor)\n}\n\n// GetFilterByColor gets the filterByColor field\nfunc (p *SimpleBlobDetectorParams) GetFilterByColor() bool {\n\treturn bool(p.p.filterByColor)\n}\n\n// SetFilterByConvexity sets the filterByConvexity field\nfunc (p *SimpleBlobDetectorParams) SetFilterByConvexity(filterByConvexity bool) {\n\tp.p.filterByConvexity = C.bool(filterByConvexity)\n}\n\n// GetFilterByConvexity gets the filterByConvexity field\nfunc (p *SimpleBlobDetectorParams) GetFilterByConvexity() bool {\n\treturn bool(p.p.filterByConvexity)\n}\n\n// SetFilterByInertia sets the filterByInertia field\nfunc (p *SimpleBlobDetectorParams) SetFilterByInertia(filterByInertia bool) {\n\tp.p.filterByInertia = C.bool(filterByInertia)\n}\n\n// GetFilterByInertia gets the filterByInertia field\nfunc (p *SimpleBlobDetectorParams) GetFilterByInertia() bool {\n\treturn bool(p.p.filterByInertia)\n}\n\n// SetMaxArea sets the maxArea parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) SetMaxArea(maxArea float64) {\n\tp.p.maxArea = C.float(maxArea)\n}\n\n// GetMaxArea sets the maxArea parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) GetMaxArea() float64 {\n\treturn float64(p.p.maxArea)\n}\n\n// SetMaxCircularity sets the maxCircularity parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) SetMaxCircularity(maxCircularity float64) {\n\tp.p.maxCircularity = C.float(maxCircularity)\n}\n\n// GetMaxCircularity sets the maxCircularity parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) GetMaxCircularity() float64 {\n\treturn float64(p.p.maxCircularity)\n}\n\n// SetMaxConvexity sets the maxConvexity parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) SetMaxConvexity(maxConvexity float64) {\n\tp.p.maxConvexity = C.float(maxConvexity)\n}\n\n// GetMaxConvexity sets the maxConvexity parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) GetMaxConvexity() float64 {\n\treturn float64(p.p.maxConvexity)\n}\n\n// SetMaxInertiaRatio sets the maxInertiaRatio parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) SetMaxInertiaRatio(maxInertiaRatio float64) {\n\tp.p.maxInertiaRatio = C.float(maxInertiaRatio)\n}\n\n// GetMaxInertiaRatio sets the maxCConvexity parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) GetMaxInertiaRatio() float64 {\n\treturn float64(p.p.maxInertiaRatio)\n}\n\n// SetMaxThreshold sets the maxThreshold parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) SetMaxThreshold(maxThreshold float64) {\n\tp.p.maxThreshold = C.float(maxThreshold)\n}\n\n// GetMaxThreshold sets the maxCConvexity parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) GetMaxThreshold() float64 {\n\treturn float64(p.p.maxThreshold)\n}\n\n// SetMinArea sets the minArea parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) SetMinArea(minArea float64) {\n\tp.p.minArea = C.float(minArea)\n}\n\n// GetMinArea sets theinArea parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) GetMinArea() float64 {\n\treturn float64(p.p.minArea)\n}\n\n// SetMinCircularity sets the minCircularity parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) SetMinCircularity(minCircularity float64) {\n\tp.p.minCircularity = C.float(minCircularity)\n}\n\n// GetMinCircularity sets the minCircularity parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) GetMinCircularity() float64 {\n\treturn float64(p.p.minCircularity)\n}\n\n// SetMinConvexity sets the minConvexity parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) SetMinConvexity(minConvexity float64) {\n\tp.p.minConvexity = C.float(minConvexity)\n}\n\n// GetMinConvexity sets the minConvexity parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) GetMinConvexity() float64 {\n\treturn float64(p.p.minConvexity)\n}\n\n// SetMinDistBetweenBlobs sets the minDistBetweenBlobs parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) SetMinDistBetweenBlobs(minDistBetweenBlobs float64) {\n\tp.p.minDistBetweenBlobs = C.float(minDistBetweenBlobs)\n}\n\n// GetMinDistBetweenBlobs sets the minDistBetweenBlobs parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) GetMinDistBetweenBlobs() float64 {\n\treturn float64(p.p.minDistBetweenBlobs)\n}\n\n// SetMinInertiaRatio sets the minInertiaRatio parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) SetMinInertiaRatio(minInertiaRatio float64) {\n\tp.p.minInertiaRatio = C.float(minInertiaRatio)\n}\n\n// GetMinInertiaRatio sets the minInertiaRatio parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) GetMinInertiaRatio() float64 {\n\treturn float64(p.p.minInertiaRatio)\n}\n\n// SetMinRepeatability sets the minRepeatability parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) SetMinRepeatability(minRepeatability int) {\n\tp.p.minRepeatability = C.size_t(minRepeatability)\n}\n\n// GetMinInertiaRatio sets the minRepeatability parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) GetMinRepeatability() int {\n\treturn int(p.p.minRepeatability)\n}\n\n// SetMinThreshold sets the minThreshold parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) SetMinThreshold(minThreshold float64) {\n\tp.p.minThreshold = C.float(minThreshold)\n}\n\n// GetMinThreshold sets the minInertiaRatio parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) GetMinThreshold() float64 {\n\treturn float64(p.p.minThreshold)\n}\n\n// SetMinThreshold sets the minThreshold parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) SetThresholdStep(thresholdStep float64) {\n\tp.p.thresholdStep = C.float(thresholdStep)\n}\n\n// GetMinThreshold sets the minInertiaRatio parameter for SimpleBlobDetector_Params\nfunc (p *SimpleBlobDetectorParams) GetThresholdStep() float64 {\n\treturn float64(p.p.thresholdStep)\n}\n\n// Detect keypoints in an image using SimpleBlobDetector.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d0/d13/classcv_1_1Feature2D.html#aa4e9a7082ec61ebc108806704fbd7887\nfunc (b *SimpleBlobDetector) Detect(src Mat) []KeyPoint {\n\tret := C.SimpleBlobDetector_Detect((C.SimpleBlobDetector)(b.p), src.p)\n\tdefer C.KeyPoints_Close(ret)\n\n\treturn getKeyPoints(ret)\n}\n\n// getKeyPoints returns a slice of KeyPoint given a pointer to a C.KeyPoints\nfunc getKeyPoints(ret C.KeyPoints) []KeyPoint {\n\tcArray := ret.keypoints\n\tlength := int(ret.length)\n\thdr := reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(cArray)),\n\t\tLen:  length,\n\t\tCap:  length,\n\t}\n\ts := *(*[]C.KeyPoint)(unsafe.Pointer(&hdr))\n\n\tkeys := make([]KeyPoint, length)\n\tfor i, r := range s {\n\t\tkeys[i] = KeyPoint{float64(r.x), float64(r.y), float64(r.size), float64(r.angle), float64(r.response),\n\t\t\tint(r.octave), int(r.classID)}\n\t}\n\treturn keys\n}\n\n// BFMatcher is a wrapper around the the cv::BFMatcher algorithm\ntype BFMatcher struct {\n\t// C.BFMatcher\n\tp unsafe.Pointer\n}\n\n// NewBFMatcher returns a new BFMatcher\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/da1/classcv_1_1BFMatcher.html#abe0bb11749b30d97f60d6ade665617bd\nfunc NewBFMatcher() BFMatcher {\n\treturn BFMatcher{p: unsafe.Pointer(C.BFMatcher_Create())}\n}\n\n// NewBFMatcherWithParams creates a new BFMatchers but allows setting parameters\n// to values other than just the defaults.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/da1/classcv_1_1BFMatcher.html#abe0bb11749b30d97f60d6ade665617bd\nfunc NewBFMatcherWithParams(normType NormType, crossCheck bool) BFMatcher {\n\treturn BFMatcher{p: unsafe.Pointer(C.BFMatcher_CreateWithParams(C.int(normType), C.bool(crossCheck)))}\n}\n\n// Close BFMatcher\nfunc (b *BFMatcher) Close() error {\n\tC.BFMatcher_Close((C.BFMatcher)(b.p))\n\tb.p = nil\n\treturn nil\n}\n\n// Match Finds the best match for each descriptor from a query set.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/db/d39/classcv_1_1DescriptorMatcher.html#a0f046f47b68ec7074391e1e85c750cba\nfunc (b *BFMatcher) Match(query, train Mat) []DMatch {\n\tret := C.BFMatcher_Match((C.BFMatcher)(b.p), query.p, train.p)\n\tdefer C.DMatches_Close(ret)\n\n\treturn getDMatches(ret)\n}\n\n// KnnMatch Finds the k best matches for each descriptor from a query set.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/db/d39/classcv_1_1DescriptorMatcher.html#aa880f9353cdf185ccf3013e08210483a\nfunc (b *BFMatcher) KnnMatch(query, train Mat, k int) [][]DMatch {\n\tret := C.BFMatcher_KnnMatch((C.BFMatcher)(b.p), query.p, train.p, C.int(k))\n\tdefer C.MultiDMatches_Close(ret)\n\n\treturn getMultiDMatches(ret)\n}\n\n// FlannBasedMatcher is a wrapper around the the cv::FlannBasedMatcher algorithm\ntype FlannBasedMatcher struct {\n\t// C.FlannBasedMatcher\n\tp unsafe.Pointer\n}\n\n// NewFlannBasedMatcher returns a new FlannBasedMatcher\n//\n// For further details, please see:\n// https://docs.opencv.org/master/dc/de2/classcv_1_1FlannBasedMatcher.html#ab9114a6471e364ad221f89068ca21382\nfunc NewFlannBasedMatcher() FlannBasedMatcher {\n\treturn FlannBasedMatcher{p: unsafe.Pointer(C.FlannBasedMatcher_Create())}\n}\n\n// Close FlannBasedMatcher\nfunc (f *FlannBasedMatcher) Close() error {\n\tC.FlannBasedMatcher_Close((C.FlannBasedMatcher)(f.p))\n\tf.p = nil\n\treturn nil\n}\n\n// KnnMatch Finds the k best matches for each descriptor from a query set.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/db/d39/classcv_1_1DescriptorMatcher.html#aa880f9353cdf185ccf3013e08210483a\nfunc (f *FlannBasedMatcher) KnnMatch(query, train Mat, k int) [][]DMatch {\n\tret := C.FlannBasedMatcher_KnnMatch((C.FlannBasedMatcher)(f.p), query.p, train.p, C.int(k))\n\tdefer C.MultiDMatches_Close(ret)\n\n\treturn getMultiDMatches(ret)\n}\n\nfunc getMultiDMatches(ret C.MultiDMatches) [][]DMatch {\n\tcArray := ret.dmatches\n\tlength := int(ret.length)\n\thdr := reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(cArray)),\n\t\tLen:  length,\n\t\tCap:  length,\n\t}\n\ts := *(*[]C.DMatches)(unsafe.Pointer(&hdr))\n\n\tkeys := make([][]DMatch, length)\n\tfor i := range s {\n\t\tkeys[i] = getDMatches(C.MultiDMatches_get(ret, C.int(i)))\n\t}\n\treturn keys\n}\n\nfunc getDMatches(ret C.DMatches) []DMatch {\n\tcArray := ret.dmatches\n\tlength := int(ret.length)\n\thdr := reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(cArray)),\n\t\tLen:  length,\n\t\tCap:  length,\n\t}\n\ts := *(*[]C.DMatch)(unsafe.Pointer(&hdr))\n\n\tkeys := make([]DMatch, length)\n\tfor i, r := range s {\n\t\tkeys[i] = DMatch{int(r.queryIdx), int(r.trainIdx), int(r.imgIdx),\n\t\t\tfloat64(r.distance)}\n\t}\n\treturn keys\n}\n\n// DrawMatchesFlag are the flags setting drawing feature\n//\n// For further details please see:\n// https://docs.opencv.org/master/de/d30/structcv_1_1DrawMatchesFlags.html\ntype DrawMatchesFlag int\n\nconst (\n\t// DrawDefault creates new image and for each keypoint only the center point will be drawn\n\tDrawDefault DrawMatchesFlag = 0\n\t// DrawOverOutImg draws matches on existing content of image\n\tDrawOverOutImg DrawMatchesFlag = 1\n\t// NotDrawSinglePoints will not draw single points\n\tNotDrawSinglePoints DrawMatchesFlag = 2\n\t// DrawRichKeyPoints draws the circle around each keypoint with keypoint size and orientation\n\tDrawRichKeyPoints DrawMatchesFlag = 3\n)\n\n// DrawKeyPoints draws keypoints\n//\n// For further details please see:\n// https://docs.opencv.org/master/d4/d5d/group__features2d__draw.html#gab958f8900dd10f14316521c149a60433\nfunc DrawKeyPoints(src Mat, keyPoints []KeyPoint, dst *Mat, color color.RGBA, flag DrawMatchesFlag) {\n\tcKeyPointArray := make([]C.struct_KeyPoint, len(keyPoints))\n\n\tfor i, kp := range keyPoints {\n\t\tcKeyPointArray[i].x = C.double(kp.X)\n\t\tcKeyPointArray[i].y = C.double(kp.Y)\n\t\tcKeyPointArray[i].size = C.double(kp.Size)\n\t\tcKeyPointArray[i].angle = C.double(kp.Angle)\n\t\tcKeyPointArray[i].response = C.double(kp.Response)\n\t\tcKeyPointArray[i].octave = C.int(kp.Octave)\n\t\tcKeyPointArray[i].classID = C.int(kp.ClassID)\n\t}\n\n\tcKeyPoints := C.struct_KeyPoints{\n\t\tkeypoints: (*C.struct_KeyPoint)(&cKeyPointArray[0]),\n\t\tlength:    (C.int)(len(keyPoints)),\n\t}\n\n\tscalar := C.struct_Scalar{\n\t\tval1: C.double(color.B),\n\t\tval2: C.double(color.G),\n\t\tval3: C.double(color.R),\n\t\tval4: C.double(color.A),\n\t}\n\n\tC.DrawKeyPoints(src.p, cKeyPoints, dst.p, scalar, C.int(flag))\n}\n\n// SIFT is a wrapper around the cv::SIFT algorithm.\n// Due to the patent having expired, this is now in the main OpenCV code modules.\ntype SIFT struct {\n\t// C.SIFT\n\tp unsafe.Pointer\n}\n\nvar _ Feature2D = (*SIFT)(nil)\n\n// NewSIFT returns a new SIFT algorithm.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d5/d3c/classcv_1_1xfeatures2d_1_1SIFT.html\nfunc NewSIFT() SIFT {\n\treturn SIFT{p: unsafe.Pointer(C.SIFT_Create())}\n}\n\nfunc NewSIFTWithParams(nfeatures *int, nOctaveLayers *int, contrastThreshold *float64, edgeThreshold *float64, sigma *float64) SIFT {\n\tnumFeatures := 0\n\tif nfeatures != nil {\n\t\tnumFeatures = *nfeatures\n\t}\n\n\tnumOctaveLayers := 3\n\n\tif nOctaveLayers != nil {\n\t\tnumOctaveLayers = *nOctaveLayers\n\t}\n\n\tvar numContrastThreshold float64 = 0.04\n\n\tif contrastThreshold != nil {\n\t\tnumContrastThreshold = *contrastThreshold\n\t}\n\n\tvar numEdgeThreshold float64 = 10\n\n\tif edgeThreshold != nil {\n\t\tnumEdgeThreshold = *edgeThreshold\n\t}\n\n\tvar numSigma float64 = 1.6\n\n\tif sigma != nil {\n\t\tnumSigma = *sigma\n\t}\n\n\treturn SIFT{p: unsafe.Pointer(C.SIFT_CreateWithParams(C.int(numFeatures), C.int(numOctaveLayers), C.double(numContrastThreshold), C.double(numEdgeThreshold), C.double(numSigma)))}\n}\n\n// Close SIFT.\nfunc (d *SIFT) Close() error {\n\tC.SIFT_Close((C.SIFT)(d.p))\n\td.p = nil\n\treturn nil\n}\n\n// Detect keypoints in an image using SIFT.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d0/d13/classcv_1_1Feature2D.html#aa4e9a7082ec61ebc108806704fbd7887\nfunc (d *SIFT) Detect(src Mat) []KeyPoint {\n\tret := C.SIFT_Detect((C.SIFT)(d.p), C.Mat(src.Ptr()))\n\tdefer C.KeyPoints_Close(ret)\n\n\treturn getKeyPoints(ret)\n}\n\n// Compute keypoints in an image using SIFT.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d0/d13/classcv_1_1Feature2D.html#ab3cce8d56f4fc5e1d530b5931e1e8dc0\nfunc (d *SIFT) Compute(src Mat, mask Mat, kps []KeyPoint) ([]KeyPoint, Mat) {\n\tdesc := NewMat()\n\tkp2arr := make([]C.struct_KeyPoint, len(kps))\n\tfor i, kp := range kps {\n\t\tkp2arr[i].x = C.double(kp.X)\n\t\tkp2arr[i].y = C.double(kp.Y)\n\t\tkp2arr[i].size = C.double(kp.Size)\n\t\tkp2arr[i].angle = C.double(kp.Angle)\n\t\tkp2arr[i].response = C.double(kp.Response)\n\t\tkp2arr[i].octave = C.int(kp.Octave)\n\t\tkp2arr[i].classID = C.int(kp.ClassID)\n\t}\n\tcKeyPoints := C.struct_KeyPoints{\n\t\tkeypoints: (*C.struct_KeyPoint)(&kp2arr[0]),\n\t\tlength:    (C.int)(len(kps)),\n\t}\n\n\tret := C.SIFT_Compute((C.SIFT)(d.p), src.p, cKeyPoints, desc.p)\n\tdefer C.KeyPoints_Close(ret)\n\n\treturn getKeyPoints(ret), desc\n}\n\n// DetectAndCompute detects and computes keypoints in an image using SIFT.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d0/d13/classcv_1_1Feature2D.html#a8be0d1c20b08eb867184b8d74c15a677\nfunc (d *SIFT) DetectAndCompute(src Mat, mask Mat) ([]KeyPoint, Mat) {\n\tdesc := NewMat()\n\tret := C.SIFT_DetectAndCompute((C.SIFT)(d.p), C.Mat(src.Ptr()), C.Mat(mask.Ptr()),\n\t\tC.Mat(desc.Ptr()))\n\tdefer C.KeyPoints_Close(ret)\n\n\treturn getKeyPoints(ret), desc\n}\n\n// DrawMatches draws matches on combined train and querry images.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d5d/group__features2d__draw.html#gad8f463ccaf0dc6f61083abd8717c261a\nfunc DrawMatches(img1 Mat, kp1 []KeyPoint, img2 Mat, kp2 []KeyPoint, matches1to2 []DMatch, outImg *Mat, matchColor color.RGBA, singlePointColor color.RGBA, matchesMask []byte, flags DrawMatchesFlag) {\n\tkp1arr := make([]C.struct_KeyPoint, len(kp1))\n\tkp2arr := make([]C.struct_KeyPoint, len(kp2))\n\n\tfor i, kp := range kp1 {\n\t\tkp1arr[i].x = C.double(kp.X)\n\t\tkp1arr[i].y = C.double(kp.Y)\n\t\tkp1arr[i].size = C.double(kp.Size)\n\t\tkp1arr[i].angle = C.double(kp.Angle)\n\t\tkp1arr[i].response = C.double(kp.Response)\n\t\tkp1arr[i].octave = C.int(kp.Octave)\n\t\tkp1arr[i].classID = C.int(kp.ClassID)\n\t}\n\n\tfor i, kp := range kp2 {\n\t\tkp2arr[i].x = C.double(kp.X)\n\t\tkp2arr[i].y = C.double(kp.Y)\n\t\tkp2arr[i].size = C.double(kp.Size)\n\t\tkp2arr[i].angle = C.double(kp.Angle)\n\t\tkp2arr[i].response = C.double(kp.Response)\n\t\tkp2arr[i].octave = C.int(kp.Octave)\n\t\tkp2arr[i].classID = C.int(kp.ClassID)\n\t}\n\n\tcKeyPoints1 := C.struct_KeyPoints{\n\t\tkeypoints: (*C.struct_KeyPoint)(&kp1arr[0]),\n\t\tlength:    (C.int)(len(kp1)),\n\t}\n\n\tcKeyPoints2 := C.struct_KeyPoints{\n\t\tkeypoints: (*C.struct_KeyPoint)(&kp2arr[0]),\n\t\tlength:    (C.int)(len(kp2)),\n\t}\n\n\tdMatchArr := make([]C.struct_DMatch, len(matches1to2))\n\n\tfor i, dm := range matches1to2 {\n\t\tdMatchArr[i].queryIdx = C.int(dm.QueryIdx)\n\t\tdMatchArr[i].trainIdx = C.int(dm.TrainIdx)\n\t\tdMatchArr[i].imgIdx = C.int(dm.ImgIdx)\n\t\tdMatchArr[i].distance = C.float(dm.Distance)\n\t}\n\n\tcDMatches := C.struct_DMatches{\n\t\tdmatches: (*C.struct_DMatch)(&dMatchArr[0]),\n\t\tlength:   (C.int)(len(matches1to2)),\n\t}\n\n\tscalarMatchColor := C.struct_Scalar{\n\t\tval1: C.double(matchColor.R),\n\t\tval2: C.double(matchColor.G),\n\t\tval3: C.double(matchColor.B),\n\t\tval4: C.double(matchColor.A),\n\t}\n\n\tscalarPointColor := C.struct_Scalar{\n\t\tval1: C.double(singlePointColor.B),\n\t\tval2: C.double(singlePointColor.G),\n\t\tval3: C.double(singlePointColor.R),\n\t\tval4: C.double(singlePointColor.A),\n\t}\n\n\tmask := make([]C.char, len(matchesMask))\n\n\tcByteArray := C.struct_ByteArray{\n\t\tlength: (C.int)(len(matchesMask)),\n\t}\n\n\tif len(matchesMask) > 0 {\n\t\tcByteArray = C.struct_ByteArray{\n\t\t\tdata:   (*C.char)(&mask[0]),\n\t\t\tlength: (C.int)(len(matchesMask)),\n\t\t}\n\t}\n\n\tC.DrawMatches(img1.p, cKeyPoints1, img2.p, cKeyPoints2, cDMatches, outImg.p, scalarMatchColor, scalarPointColor, cByteArray, C.int(flags))\n}\n"
        },
        {
          "name": "features2d.h",
          "type": "blob",
          "size": 4.3671875,
          "content": "#ifndef _OPENCV3_FEATURES2D_H_\n#define _OPENCV3_FEATURES2D_H_\n\n#ifdef __cplusplus\n#include <opencv2/opencv.hpp>\nextern \"C\" {\n#endif\n\n#include \"core.h\"\n\n#ifdef __cplusplus\ntypedef cv::Ptr<cv::AKAZE>* AKAZE;\ntypedef cv::Ptr<cv::AgastFeatureDetector>* AgastFeatureDetector;\ntypedef cv::Ptr<cv::BRISK>* BRISK;\ntypedef cv::Ptr<cv::FastFeatureDetector>* FastFeatureDetector;\ntypedef cv::Ptr<cv::GFTTDetector>* GFTTDetector;\ntypedef cv::Ptr<cv::KAZE>* KAZE;\ntypedef cv::Ptr<cv::MSER>* MSER;\ntypedef cv::Ptr<cv::ORB>* ORB;\ntypedef cv::Ptr<cv::SimpleBlobDetector>* SimpleBlobDetector;\ntypedef cv::Ptr<cv::BFMatcher>* BFMatcher;\ntypedef cv::Ptr<cv::FlannBasedMatcher>* FlannBasedMatcher;\ntypedef cv::Ptr<cv::SIFT>* SIFT;\n#else\ntypedef void* AKAZE;\ntypedef void* AgastFeatureDetector;\ntypedef void* BRISK;\ntypedef void* FastFeatureDetector;\ntypedef void* GFTTDetector;\ntypedef void* KAZE;\ntypedef void* MSER;\ntypedef void* ORB;\ntypedef void* SimpleBlobDetector;\ntypedef void* BFMatcher;\ntypedef void* FlannBasedMatcher;\ntypedef void* SIFT;\n#endif\n\nAKAZE AKAZE_Create();\nvoid AKAZE_Close(AKAZE a);\nstruct KeyPoints AKAZE_Detect(AKAZE a, Mat src);\nstruct KeyPoints AKAZE_Compute(AKAZE a, Mat src, struct KeyPoints kp, Mat desc);\nstruct KeyPoints AKAZE_DetectAndCompute(AKAZE a, Mat src, Mat mask, Mat desc);\n\nAgastFeatureDetector AgastFeatureDetector_Create();\nvoid AgastFeatureDetector_Close(AgastFeatureDetector a);\nstruct KeyPoints AgastFeatureDetector_Detect(AgastFeatureDetector a, Mat src);\n\nBRISK BRISK_Create();\nvoid BRISK_Close(BRISK b);\nstruct KeyPoints BRISK_Detect(BRISK b, Mat src);\nstruct KeyPoints BRISK_Compute(BRISK b, Mat src, struct KeyPoints kp, Mat desc);\nstruct KeyPoints BRISK_DetectAndCompute(BRISK b, Mat src, Mat mask, Mat desc);\n\nFastFeatureDetector FastFeatureDetector_Create();\nFastFeatureDetector FastFeatureDetector_CreateWithParams(int threshold, bool nonmaxSuppression, int type);\nvoid FastFeatureDetector_Close(FastFeatureDetector f);\nstruct KeyPoints FastFeatureDetector_Detect(FastFeatureDetector f, Mat src);\n\nGFTTDetector GFTTDetector_Create();\nvoid GFTTDetector_Close(GFTTDetector a);\nstruct KeyPoints GFTTDetector_Detect(GFTTDetector a, Mat src);\n\nKAZE KAZE_Create();\nvoid KAZE_Close(KAZE a);\nstruct KeyPoints KAZE_Detect(KAZE a, Mat src);\nstruct KeyPoints KAZE_Compute(KAZE a, Mat src, struct KeyPoints kp, Mat desc);\nstruct KeyPoints KAZE_DetectAndCompute(KAZE a, Mat src, Mat mask, Mat desc);\n\nMSER MSER_Create();\nvoid MSER_Close(MSER a);\nstruct KeyPoints MSER_Detect(MSER a, Mat src);\n\nORB ORB_Create();\nORB ORB_CreateWithParams(int nfeatures, float scaleFactor, int nlevels, int edgeThreshold, int firstLevel, int WTA_K, int scoreType, int patchSize, int fastThreshold);\nvoid ORB_Close(ORB o);\nstruct KeyPoints ORB_Detect(ORB o, Mat src);\nstruct KeyPoints ORB_Compute(ORB o, Mat src, struct KeyPoints kp, Mat desc);\nstruct KeyPoints ORB_DetectAndCompute(ORB o, Mat src, Mat mask, Mat desc);\n\nSimpleBlobDetector SimpleBlobDetector_Create();\nSimpleBlobDetector SimpleBlobDetector_Create_WithParams(SimpleBlobDetectorParams params);\nvoid SimpleBlobDetector_Close(SimpleBlobDetector b);\nstruct KeyPoints SimpleBlobDetector_Detect(SimpleBlobDetector b, Mat src);\nSimpleBlobDetectorParams SimpleBlobDetectorParams_Create();\n\nBFMatcher BFMatcher_Create();\nBFMatcher BFMatcher_CreateWithParams(int normType, bool crossCheck);\nvoid BFMatcher_Close(BFMatcher b);\nstruct DMatches BFMatcher_Match(BFMatcher b, Mat query, Mat train);\nstruct MultiDMatches BFMatcher_KnnMatch(BFMatcher b, Mat query, Mat train, int k);\n\nFlannBasedMatcher FlannBasedMatcher_Create();\nvoid FlannBasedMatcher_Close(FlannBasedMatcher f);\nstruct MultiDMatches FlannBasedMatcher_KnnMatch(FlannBasedMatcher f, Mat query, Mat train, int k);\n\nvoid DrawKeyPoints(Mat src, struct KeyPoints kp, Mat dst, const Scalar s, int flags);\n\nSIFT SIFT_Create();\nSIFT SIFT_CreateWithParams(int nfeatures, int nOctaveLayers, double contrastThreshold, double edgeThreshold, double sigma);\nvoid SIFT_Close(SIFT f);\nstruct KeyPoints SIFT_Detect(SIFT f, Mat src);\nstruct KeyPoints SIFT_Compute(SIFT f, Mat src, struct KeyPoints kp, Mat desc);\nstruct KeyPoints SIFT_DetectAndCompute(SIFT f, Mat src, Mat mask, Mat desc);\n\nvoid DrawMatches(Mat img1, struct KeyPoints kp1, Mat img2, struct KeyPoints kp2, struct DMatches matches1to2, Mat outImg, const Scalar matchesColor, const Scalar pointColor, struct ByteArray matchesMask, int flags);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif //_OPENCV3_FEATURES2D_H_\n"
        },
        {
          "name": "features2d_string.go",
          "type": "blob",
          "size": 0.6455078125,
          "content": "package gocv\n\n/*\n#include <stdlib.h>\n#include \"features2d.h\"\n*/\nimport \"C\"\n\nfunc (c FastFeatureDetectorType) String() string {\n\tswitch c {\n\tcase FastFeatureDetectorType58:\n\t\treturn \"fast-feature-detector-type-58\"\n\tcase FastFeatureDetectorType712:\n\t\treturn \"fast-feature-detector-type-712\"\n\tcase FastFeatureDetectorType916:\n\t\treturn \"fast-feature-detector-type-916\"\n\t}\n\treturn \"\"\n}\n\nfunc (c DrawMatchesFlag) String() string {\n\tswitch c {\n\tcase DrawDefault:\n\t\treturn \"draw-default\"\n\tcase DrawOverOutImg:\n\t\treturn \"draw-over-out-imt\"\n\tcase NotDrawSinglePoints:\n\t\treturn \"draw-single-points\"\n\tcase DrawRichKeyPoints:\n\t\treturn \"draw-rich-key-points\"\n\t}\n\treturn \"\"\n}\n"
        },
        {
          "name": "features2d_test.go",
          "type": "blob",
          "size": 16.7666015625,
          "content": "package gocv\n\nimport (\n\t\"image/color\"\n\t\"runtime\"\n\t\"testing\"\n)\n\nfunc TestAKAZE(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in AKAZE test\")\n\t}\n\tdefer img.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tak := NewAKAZE()\n\tdefer ak.Close()\n\n\tkp := ak.Detect(img)\n\tif len(kp) < 512 {\n\t\tt.Errorf(\"Invalid KeyPoint array in AKAZE test: %d\", len(kp))\n\t}\n\n\tmask := NewMat()\n\tdefer mask.Close()\n\n\tkpc, desc := ak.Compute(img, mask, kp)\n\tdefer desc.Close()\n\tif len(kpc) < 512 {\n\t\tt.Errorf(\"Invalid KeyPoint array in AKAZE Compute: %d\", len(kpc))\n\t}\n\tif desc.Empty() {\n\t\tt.Error(\"Invalid Mat desc in AKAZE Compute\")\n\t}\n\n\tkpdc, desc2 := ak.DetectAndCompute(img, mask)\n\tdefer desc2.Close()\n\tif len(kpdc) < 512 {\n\t\tt.Errorf(\"Invalid KeyPoint array in AKAZE DetectAndCompute: %d\", len(kpdc))\n\t}\n\tif desc2.Empty() {\n\t\tt.Error(\"Invalid Mat desc in AKAZE DetectAndCompute\")\n\t}\n}\n\nfunc TestAgastFeatureDetector(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in AgastFeatureDetector test\")\n\t}\n\tdefer img.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tad := NewAgastFeatureDetector()\n\tdefer ad.Close()\n\n\tkp := ad.Detect(img)\n\tif len(kp) < 2800 {\n\t\tt.Errorf(\"Invalid KeyPoint array in AgastFeatureDetector test: %d\", len(kp))\n\t}\n}\n\nfunc TestBRISK(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in BRISK test\")\n\t}\n\tdefer img.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tbr := NewBRISK()\n\tdefer br.Close()\n\n\tkp := br.Detect(img)\n\tif len(kp) < 513 {\n\t\tt.Errorf(\"Invalid KeyPoint array in BRISK Detect: %d\", len(kp))\n\t}\n\n\tmask := NewMat()\n\tdefer mask.Close()\n\n\tkpc, desc := br.Compute(img, mask, kp)\n\tdefer desc.Close()\n\tif len(kpc) < 512 {\n\t\tt.Errorf(\"Invalid KeyPoint array in BRISK Compute: %d\", len(kpc))\n\t}\n\tif desc.Empty() {\n\t\tt.Error(\"Invalid Mat desc in BRISK Compute\")\n\t}\n\n\tkpdc, desc2 := br.DetectAndCompute(img, mask)\n\tdefer desc2.Close()\n\tif len(kpdc) < 512 {\n\t\tt.Errorf(\"Invalid KeyPoint array in BRISK DetectAndCompute: %d\", len(kpdc))\n\t}\n\tif desc2.Empty() {\n\t\tt.Error(\"Invalid Mat desc in BRISK DetectAndCompute\")\n\t}\n}\n\nfunc TestFastFeatureDetector(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in FastFeatureDetector test\")\n\t}\n\tdefer img.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tfd := NewFastFeatureDetector()\n\tdefer fd.Close()\n\n\tkp := fd.Detect(img)\n\tif len(kp) < 2690 {\n\t\tt.Errorf(\"Invalid KeyPoint array in FastFeatureDetector test: %d\", len(kp))\n\t}\n}\n\nfunc TestFastFeatureDetectorWithParams(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in FastFeatureDetector test\")\n\t}\n\tdefer img.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tfd := NewFastFeatureDetectorWithParams(10, true, FastFeatureDetectorType916)\n\tdefer fd.Close()\n\n\tkp := fd.Detect(img)\n\tif len(kp) < 2690 {\n\t\tt.Errorf(\"Invalid KeyPoint array in FastFeatureDetector test: %d\", len(kp))\n\t}\n}\n\nfunc TestGFTTDetector(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in GFTTDetector test\")\n\t}\n\tdefer img.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tgft := NewGFTTDetector()\n\tdefer gft.Close()\n\n\tkp := gft.Detect(img)\n\tif len(kp) < 512 {\n\t\tt.Errorf(\"Invalid KeyPoint array in GFTTDetector test: %d\", len(kp))\n\t}\n}\n\nfunc TestKAZE(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in KAZE test\")\n\t}\n\tdefer img.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tk := NewKAZE()\n\tdefer k.Close()\n\n\tkp := k.Detect(img)\n\tif len(kp) < 512 {\n\t\tt.Errorf(\"Invalid KeyPoint array in KAZE test: %d\", len(kp))\n\t}\n\n\tmask := NewMat()\n\tdefer mask.Close()\n\n\tkpc, desc := k.Compute(img, mask, kp)\n\tdefer desc.Close()\n\tif len(kpc) < 512 {\n\t\tt.Errorf(\"Invalid KeyPoint array in KAZE Compute: %d\", len(kpc))\n\t}\n\tif desc.Empty() {\n\t\tt.Error(\"Invalid Mat desc in KAZE Compute\")\n\t}\n\n\tkpdc, desc2 := k.DetectAndCompute(img, mask)\n\tdefer desc2.Close()\n\tif len(kpdc) < 512 {\n\t\tt.Errorf(\"Invalid KeyPoint array in KAZE DetectAndCompute: %d\", len(kpdc))\n\t}\n\tif desc2.Empty() {\n\t\tt.Error(\"Invalid Mat desc in KAZE DetectAndCompute\")\n\t}\n}\n\nfunc TestMSER(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in MSER test\")\n\t}\n\tdefer img.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tmser := NewMSER()\n\tdefer mser.Close()\n\n\tkp := mser.Detect(img)\n\tif len(kp) != 232 && len(kp) != 234 && len(kp) != 261 {\n\t\tt.Errorf(\"Invalid KeyPoint array in MSER test: %d\", len(kp))\n\t}\n}\n\nfunc TestORB(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in AgastFeatureDetector test\")\n\t}\n\tdefer img.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tod := NewORB()\n\tdefer od.Close()\n\n\tkp := od.Detect(img)\n\tif len(kp) != 500 {\n\t\tt.Errorf(\"Invalid KeyPoint array in ORB test: %d\", len(kp))\n\t}\n\n\tmask := NewMat()\n\tdefer mask.Close()\n\n\tkpc, desc := od.Compute(img, mask, kp)\n\tdefer desc.Close()\n\tif len(kpc) < 500 {\n\t\tt.Errorf(\"Invalid KeyPoint array in ORB Compute: %d\", len(kpc))\n\t}\n\tif desc.Empty() {\n\t\tt.Error(\"Invalid Mat desc in ORB Compute\")\n\t}\n\n\tkpdc, desc2 := od.DetectAndCompute(img, mask)\n\tdefer desc2.Close()\n\tif len(kpdc) < 500 {\n\t\tt.Errorf(\"Invalid KeyPoint array in ORB DetectAndCompute: %d\", len(kpdc))\n\t}\n\tif desc2.Empty() {\n\t\tt.Error(\"Invalid Mat desc in ORB DetectAndCompute\")\n\t}\n}\n\nfunc TestSimpleBlobDetector(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in SimpleBlobDetector test\")\n\t}\n\tdefer img.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tbd := NewSimpleBlobDetector()\n\tdefer bd.Close()\n\n\tkp := bd.Detect(img)\n\tif len(kp) != 2 {\n\t\tt.Errorf(\"Invalid KeyPoint array in SimpleBlobDetector test: %d\", len(kp))\n\t}\n}\n\nfunc TestSimpleBlobDetectorWithParams(t *testing.T) {\n\timg := IMRead(\"images/circles.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in SimpleBlobDetector test\")\n\t}\n\tdefer img.Close()\n\n\tparams := NewSimpleBlobDetectorParams()\n\tparams.SetMaxArea(27500.0)\n\n\tbdp := NewSimpleBlobDetectorWithParams(params)\n\tdefer bdp.Close()\n\n\tkp := bdp.Detect(img)\n\tif len(kp) != 4 {\n\t\tt.Errorf(\"Invalid KeyPoint array in SimpleBlobDetector test: %d\", len(kp))\n\t}\n}\n\nfunc TestSimpleBlobDetectorParams(t *testing.T) {\n\tfloat64EqualityThreshold := 1e-5\n\tknownBlobColor := 235\n\tknownFilterByArea := false\n\tknownFilterByCircularity := true\n\tknownFilterByColor := false\n\tknownFilterByConvexity := false\n\tknownFilterByInertia := false\n\tknownMaxArea := 20000.0\n\tknownMaxCircularity := 0.99\n\tknownMaxConvexity := 0.98\n\tknownMaxInertiaRatio := 0.97\n\tknownMaxThreshold := 233.0\n\tknownMinArea := 230.0\n\tknownMinCircularity := 0.9\n\tknownMinConvexity := 0.89\n\tknownMinDistBetweenBlobs := 15.5\n\tknownMinInertiaRatio := 0.88\n\tknownMinRepeatability := 5\n\tknownMinThreshold := 200.0\n\tknownThresholdStep := 2.0\n\n\tparams := NewSimpleBlobDetectorParams()\n\tparams.SetBlobColor(knownBlobColor)\n\tparams.SetFilterByArea(knownFilterByArea)\n\tparams.SetFilterByCircularity(knownFilterByCircularity)\n\tparams.SetFilterByColor(knownFilterByColor)\n\tparams.SetFilterByConvexity(knownFilterByConvexity)\n\tparams.SetFilterByInertia(knownFilterByInertia)\n\tparams.SetMaxArea(knownMaxArea)\n\tparams.SetMaxCircularity(knownMaxCircularity)\n\tparams.SetMaxConvexity(knownMaxConvexity)\n\tparams.SetMaxInertiaRatio(knownMaxInertiaRatio)\n\tparams.SetMaxThreshold(knownMaxThreshold)\n\tparams.SetMinArea(knownMinArea)\n\tparams.SetMinCircularity(knownMinCircularity)\n\tparams.SetMinConvexity(knownMinConvexity)\n\tparams.SetMinDistBetweenBlobs(knownMinDistBetweenBlobs)\n\tparams.SetMinInertiaRatio(knownMinInertiaRatio)\n\tparams.SetMinRepeatability(knownMinRepeatability)\n\tparams.SetMinThreshold(knownMinThreshold)\n\tparams.SetThresholdStep(knownThresholdStep)\n\n\tif params.GetBlobColor() != knownBlobColor {\n\t\tt.Error(\"BlobColor incorrect in SimpleBlobDetectorParams test\")\n\t}\n\n\tif params.GetFilterByArea() != knownFilterByArea {\n\t\tt.Error(\"FilterByArea incorrect in SimpleBlobDetectorParams test\")\n\t}\n\n\tif params.GetFilterByCircularity() != knownFilterByCircularity {\n\t\tt.Error(\"FilterByCircularity incorrect in SimpleBlobDetectorParams test\")\n\t}\n\n\tif params.GetFilterByColor() != knownFilterByColor {\n\t\tt.Error(\"FilterByColor incorrect in SimpleBlobDetectorParams test\")\n\t}\n\n\tif params.GetFilterByConvexity() != knownFilterByConvexity {\n\t\tt.Error(\"FilterByConvexity incorrect in SimpleBlobDetectorParams test\")\n\t}\n\n\tif params.GetFilterByInertia() != knownFilterByInertia {\n\t\tt.Error(\"FilterByInertia incorrect in SimpleBlobDetectorParams test\")\n\t}\n\n\tif params.GetMaxArea() != knownMaxArea {\n\t\tt.Error(\"MaxArea incorrect in SimpleBlobDetectorParams test\")\n\t}\n\n\tdiffMaxCircularity := params.GetMaxCircularity() - knownMaxCircularity\n\tif diffMaxCircularity > float64EqualityThreshold {\n\t\tt.Errorf(\"DiffMaxCircularity greater than float64EqualityThreshold in SimpleBlobDetectorParams test. Diff: %f\", diffMaxCircularity)\n\t}\n\n\tdiffMaxConvexity := params.GetMaxConvexity() - knownMaxConvexity\n\tif diffMaxConvexity > float64EqualityThreshold {\n\t\tt.Errorf(\"DiffMaxConvexity greater than float64EqualityThreshold in SimpleBlobDetectorParams test. Diff: %f\", diffMaxConvexity)\n\t}\n\n\tdiffMaxInertiaRatio := params.GetMaxInertiaRatio() - knownMaxInertiaRatio\n\tif diffMaxInertiaRatio > float64EqualityThreshold {\n\t\tt.Errorf(\"DiffMaxInertiaRatio greater than float64EqualityThreshold in SimpleBlobDetectorParams test. Diff: %f\", diffMaxInertiaRatio)\n\t}\n\n\tif params.GetMaxThreshold() != knownMaxThreshold {\n\t\tt.Error(\"MaxThreshold incorrect in SimpleBlobDetectorParams test\")\n\t}\n\n\tif params.GetMinArea() != knownMinArea {\n\t\tt.Error(\"MinArea incorrect in SimpleBlobDetectorParams test\")\n\t}\n\n\tdiffMinCircularity := params.GetMinCircularity() - knownMinCircularity\n\tif diffMinCircularity > float64EqualityThreshold {\n\t\tt.Errorf(\"DiffMinCircularity greater than float64EqualityThreshold in SimpleBlobDetectorParams test. Diff %f\", diffMinCircularity)\n\t}\n\n\tdiffMinConvexity := params.GetMinConvexity() - knownMinConvexity\n\tif diffMinConvexity > float64EqualityThreshold {\n\t\tt.Errorf(\"DiffMinConvexity greater than float64EqualityThreshold in SimpleBlobDetectorParams test. Diff: %f\", diffMinConvexity)\n\t}\n\n\tif params.GetMinDistBetweenBlobs() != knownMinDistBetweenBlobs {\n\t\tt.Error(\"MinDistBetweenBlobs incorrect in SimpleBlobDetectorParams test\")\n\t}\n\n\tdiffMinInertiaRatio := params.GetMinInertiaRatio() - knownMinInertiaRatio\n\tif diffMinInertiaRatio > float64EqualityThreshold {\n\t\tt.Errorf(\"DiffMinInertiaRatio greater than float64EqualityThreshold in SimpleBlobDetectorParams test. Diff: %f\", diffMinInertiaRatio)\n\t}\n\n\tif params.GetMinRepeatability() != knownMinRepeatability {\n\t\tt.Error(\"MinRepeatability incorrect in SimpleBlobDetectorParams test\")\n\t}\n\n\tif params.GetMinThreshold() != knownMinThreshold {\n\t\tt.Error(\"MinThreshold incorrect in SimpleBlobDetectorParams test\")\n\t}\n\n\tif params.GetThresholdStep() != knownThresholdStep {\n\t\tt.Error(\"ThresholdStep incorrect in SimpleBlobDetectorParams test\")\n\t}\n}\n\nfunc TestBFMatcher(t *testing.T) {\n\tdescriptorFile := \"images/sift_descriptor.png\"\n\tdesc1 := IMRead(descriptorFile, IMReadGrayScale)\n\tif desc1.Empty() {\n\t\tt.Error(\"descriptor one is empty in BFMatcher test\")\n\t}\n\tdefer desc1.Close()\n\n\tdesc2 := IMRead(descriptorFile, IMReadGrayScale)\n\tif desc2.Empty() {\n\t\tt.Error(\"descriptor two is empty in BFMatcher test\")\n\t}\n\tdefer desc2.Close()\n\n\tbf := NewBFMatcher()\n\tdefer bf.Close()\n\n\tk := 2\n\tdMatches := bf.KnnMatch(desc1, desc2, k)\n\tif len(dMatches) < 1 {\n\t\tt.Errorf(\"DMatches was excepted to have at least one element\")\n\t}\n\tfor i := range dMatches {\n\t\tif len(dMatches[i]) != k {\n\t\t\tt.Errorf(\"Length does not match k cluster amount in BFMatcher\")\n\t\t}\n\t}\n\n\tmatches := bf.Match(desc1, desc2)\n\tif len(matches) != 890 {\n\t\tt.Errorf(\"Matches was excepted to have 890 elements, but it has %d\", len(matches))\n\t}\n\n\tbfParams := NewBFMatcherWithParams(NormHamming, false)\n\tdefer bfParams.Close()\n\n\tdMatches = bfParams.KnnMatch(desc1, desc2, k)\n\tif len(dMatches) < 1 {\n\t\tt.Errorf(\"DMatches was excepted to have at least one element\")\n\t}\n\tfor i := range dMatches {\n\t\tif len(dMatches[i]) != k {\n\t\t\tt.Errorf(\"Length does not match k cluster amount in BFMatcher\")\n\t\t}\n\t}\n}\n\nfunc TestFlannBasedMatcher(t *testing.T) {\n\tdescriptorFile := \"images/sift_descriptor.png\"\n\tdesc1 := IMRead(descriptorFile, IMReadGrayScale)\n\tif desc1.Empty() {\n\t\tt.Error(\"descriptor one is empty in FlannBasedMatcher test\")\n\t}\n\tdefer desc1.Close()\n\tdesc1.ConvertTo(&desc1, MatTypeCV32F)\n\n\tdesc2 := IMRead(descriptorFile, IMReadGrayScale)\n\tif desc2.Empty() {\n\t\tt.Error(\"descriptor two is empty in FlannBasedMatcher test\")\n\t}\n\tdefer desc2.Close()\n\tdesc2.ConvertTo(&desc2, MatTypeCV32F)\n\n\tf := NewFlannBasedMatcher()\n\tdefer f.Close()\n\n\tk := 2\n\tdMatches := f.KnnMatch(desc1, desc2, k)\n\tif len(dMatches) < 1 {\n\t\tt.Errorf(\"DMatches was excepted to have at least one element\")\n\t}\n\tfor i := range dMatches {\n\t\tif len(dMatches[i]) != k {\n\t\t\tt.Errorf(\"Length does not match k cluster amount in FlannBasedMatcher\")\n\t\t}\n\t}\n}\n\nfunc TestDrawKeyPoints(t *testing.T) {\n\tkeypointsFile := \"images/simple.jpg\"\n\timg := IMRead(keypointsFile, IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"keypoints file is empty in DrawKeyPoints test\")\n\t}\n\tdefer img.Close()\n\n\tffd := NewFastFeatureDetector()\n\tkp := ffd.Detect(img)\n\n\tsimpleKP := NewMat()\n\tdefer simpleKP.Close()\n\tDrawKeyPoints(img, kp, &simpleKP, color.RGBA{255, 0, 0, 0}, DrawDefault)\n\n\tif simpleKP.Rows() != img.Rows() || simpleKP.Cols() != img.Cols() {\n\t\tt.Error(\"Invalid DrawKeyPoints test\")\n\t}\n}\n\nfunc TestDrawMatches(t *testing.T) {\n\tif runtime.GOOS == \"darwin\" {\n\t\tt.Skip(\"skipping test on macos\")\n\t}\n\n\tqueryFile := \"images/box.png\"\n\ttrainFile := \"images/box_in_scene.png\"\n\n\tquery := IMRead(queryFile, IMReadGrayScale)\n\ttrain := IMRead(trainFile, IMReadGrayScale)\n\n\tif query.Empty() || train.Empty() {\n\t\tt.Error(\"at least one of files is empty in DrawMatches test\")\n\t}\n\n\tdefer query.Close()\n\tdefer train.Close()\n\n\tsift := NewSIFT()\n\tdefer sift.Close()\n\n\tm1 := NewMat()\n\tm2 := NewMat()\n\tdefer m1.Close()\n\tdefer m2.Close()\n\n\tkp1, des1 := sift.DetectAndCompute(query, m1)\n\tkp2, des2 := sift.DetectAndCompute(train, m2)\n\tdefer des1.Close()\n\tdefer des2.Close()\n\n\tbf := NewBFMatcher()\n\tdefer bf.Close()\n\tmatches := bf.KnnMatch(des1, des2, 2)\n\n\tif len(matches) == 0 {\n\t\tt.Error(\"no matches found in DrawMatches test\")\n\t}\n\n\tvar good []DMatch\n\tfor _, m := range matches {\n\t\tif len(m) > 1 {\n\t\t\tif m[0].Distance < 0.75*m[1].Distance {\n\t\t\t\tgood = append(good, m[0])\n\t\t\t}\n\t\t}\n\t}\n\n\tc := color.RGBA{\n\t\tR: 255,\n\t\tG: 0,\n\t\tB: 0,\n\t\tA: 0,\n\t}\n\n\tmask := make([]byte, 0)\n\n\tout := NewMat()\n\tdefer out.Close()\n\n\tDrawMatches(query, kp1, train, kp2, good, &out, c, c, mask, DrawDefault)\n\n\tif out.Cols() != (query.Cols()+train.Cols()) || out.Rows() < train.Rows() || out.Rows() < query.Rows() {\n\t\tt.Error(\"Invalid DrawMatches test\")\n\t}\n\n\tmask = make([]byte, len(good))\n\n\tsmoke := NewMat()\n\tdefer smoke.Close()\n\n\tDrawMatches(query, kp1, train, kp2, good, &smoke, c, c, mask, DrawDefault)\n}\n\nfunc TestSIFT(t *testing.T) {\n\tif runtime.GOOS == \"darwin\" {\n\t\tt.Skip(\"skipping test on macos\")\n\t}\n\n\timg := IMRead(\"./images/face.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in SIFT test\")\n\t}\n\tdefer img.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tsi := NewSIFT()\n\tdefer si.Close()\n\n\tkp := si.Detect(img)\n\tif len(kp) == 512 {\n\t\tt.Errorf(\"Invalid KeyPoint array in SIFT test: %d\", len(kp))\n\t}\n\n\tmask := NewMat()\n\tdefer mask.Close()\n\n\tkpc, desc := si.Compute(img, mask, kp)\n\tdefer desc.Close()\n\tif len(kpc) < 512 {\n\t\tt.Errorf(\"Invalid KeyPoint array in SIFT Compute: %d\", len(kpc))\n\t}\n\tif desc.Empty() {\n\t\tt.Error(\"Invalid Mat desc in SIFT Compute\")\n\t}\n\n\tkpdc, desc2 := si.DetectAndCompute(img, mask)\n\tdefer desc2.Close()\n\tif len(kpdc) < 512 {\n\t\tt.Errorf(\"Invalid KeyPoint array in SIFT DetectAndCompute: %d\", len(kpdc))\n\t}\n\tif desc2.Empty() {\n\t\tt.Error(\"Invalid Mat desc in SIFT DetectAndCompute\")\n\t}\n}\n\nfunc TestSIFTWithParams(t *testing.T) {\n\tif runtime.GOOS == \"darwin\" {\n\t\tt.Skip(\"skipping test on macos\")\n\t}\n\n\timg := IMRead(\"./images/face.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in SIFT test\")\n\t}\n\tdefer img.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tnFeatures := 256\n\tnOctaveLayers := 3\n\tcontrastThreshold := 0.039\n\tvar edgeThreshold float64 = 11\n\tsigma := 1.55\n\tsi := NewSIFTWithParams(&nFeatures, &nOctaveLayers, &contrastThreshold, &edgeThreshold, &sigma)\n\tdefer si.Close()\n\n\tkp := si.Detect(img)\n\tif len(kp) != 256 {\n\t\tt.Errorf(\"Invalid KeyPoint array in SIFT test: %d\", len(kp))\n\t}\n\n\tmask := NewMat()\n\tdefer mask.Close()\n\n\tkpc, desc := si.Compute(img, mask, kp)\n\tdefer desc.Close()\n\tif len(kpc) != 256 {\n\t\tt.Errorf(\"Invalid KeyPoint array in SIFT Compute: %d\", len(kpc))\n\t}\n\tif desc.Empty() {\n\t\tt.Error(\"Invalid Mat desc in SIFT Compute\")\n\t}\n\n\tkpdc, desc2 := si.DetectAndCompute(img, mask)\n\tdefer desc2.Close()\n\tif len(kpdc) != 256 {\n\t\tt.Errorf(\"Invalid KeyPoint array in SIFT DetectAndCompute: %d\", len(kpdc))\n\t}\n\tif desc2.Empty() {\n\t\tt.Error(\"Invalid Mat desc in SIFT DetectAndCompute\")\n\t}\n}\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.375,
          "content": "module gocv.io/x/gocv\n\ngo 1.21\n\nrequire (\n\tgithub.com/hybridgroup/mjpeg v0.0.0-20140228234708-4680f319790e\n\tgithub.com/pascaldekloe/goe v0.1.0\n\tgithub.com/subeshb1/wasm-go-image-to-ascii v0.0.0-20200725121413-d828986df340\n)\n\nrequire (\n\tgithub.com/aybabtme/rgbterm v0.0.0-20170906152045-cc83f3b3ce59 // indirect\n\tgithub.com/nfnt/resize v0.0.0-20180221191011-83c6a9932646 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 2.453125,
          "content": "github.com/aybabtme/rgbterm v0.0.0-20170906152045-cc83f3b3ce59 h1:WWB576BN5zNSZc/M9d/10pqEx5VHNhaQ/yOVAkmj5Yo=\ngithub.com/aybabtme/rgbterm v0.0.0-20170906152045-cc83f3b3ce59/go.mod h1:q/89r3U2H7sSsE2t6Kca0lfwTK8JdoNGS/yzM/4iH5I=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/hybridgroup/mjpeg v0.0.0-20140228234708-4680f319790e h1:xCcwD5FOXul+j1dn8xD16nbrhJkkum/Cn+jTd/u1LhY=\ngithub.com/hybridgroup/mjpeg v0.0.0-20140228234708-4680f319790e/go.mod h1:eagM805MRKrioHYuU7iKLUyFPVKqVV6um5DAvCkUtXs=\ngithub.com/mattn/go-isatty v0.0.4/go.mod h1:M+lRXTBqGeGNdLjl/ufCoiOlB5xdOkqRJdNxMWT7Zi4=\ngithub.com/nfnt/resize v0.0.0-20180221191011-83c6a9932646 h1:zYyBkD/k9seD2A7fsi6Oo2LfFZAehjjQMERAvZLEDnQ=\ngithub.com/nfnt/resize v0.0.0-20180221191011-83c6a9932646/go.mod h1:jpp1/29i3P1S/RLdc7JQKbRpFeM1dOBd8T9ki5s+AY8=\ngithub.com/pascaldekloe/goe v0.1.0 h1:cBOtyMzM9HTpWjXfbbunk26uA6nG3a8n06Wieeh0MwY=\ngithub.com/pascaldekloe/goe v0.1.0/go.mod h1:lzWF7FIEvWOWxwDKqyGYQf6ZUaNfKdP144TG7ZOy1lc=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/shurcooL/go v0.0.0-20200502201357-93f07166e636/go.mod h1:TDJrrUr11Vxrven61rcy3hJMUqaf/CLWYhHNPmT14Lk=\ngithub.com/shurcooL/go-goon v0.0.0-20170922171312-37c2f522c041/go.mod h1:N5mDOmsrJOB+vfqUK+7DmDyjhSLIIBnXo9lvZJj3MWQ=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.3.0 h1:NGXK3lHquSN08v5vWalVI/L8XU9hdzE/G6xsrze47As=\ngithub.com/stretchr/objx v0.3.0/go.mod h1:qt09Ya8vawLte6SNmTgCsAVtYtaKzEcn8ATUoHMkEqE=\ngithub.com/stretchr/testify v1.3.0 h1:TivCn/peBQ7UY8ooIcPgZFpTNSz0Q2U6UrFlUfqbe0Q=\ngithub.com/stretchr/testify v1.3.0/go.mod h1:M5WIy9Dh21IEIfnGCwXGc5bZfKNJtfHm1UVUgZn+9EI=\ngithub.com/subeshb1/wasm-go-image-to-ascii v0.0.0-20200725121413-d828986df340 h1:EN1NUPDAdhpWv9zNNdbovzqfJaRmnrwWaq0huRzQp9I=\ngithub.com/subeshb1/wasm-go-image-to-ascii v0.0.0-20200725121413-d828986df340/go.mod h1:A2X7CsJFb8jEdYaWeCbs2HydXC69J4Iaw4DM+bly5iw=\ngithub.com/wayneashleyberry/terminal-dimensions v1.0.0/go.mod h1:PW2XrtV6KmKOPhuf7wbtcmw1/IFnC39mryRET2XbxeE=\ngolang.org/x/sys v0.0.0-20181019160139-8e24a49d80f8/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\n"
        },
        {
          "name": "gocv.go",
          "type": "blob",
          "size": 0.4443359375,
          "content": "// Package gocv is a wrapper around the OpenCV 4.x computer vision library.\n// It provides a Go language interface to the latest version of OpenCV.\n//\n// OpenCV (Open Source Computer Vision Library: http://opencv.org) is an\n// open-source BSD-licensed library that includes several hundreds of\n// computer vision algorithms.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d1/dfb/intro.html\npackage gocv // import \"gocv.io/x/gocv\"\n"
        },
        {
          "name": "helpers_test.go",
          "type": "blob",
          "size": 0.318359375,
          "content": "package gocv\n\nimport \"math\"\n\nvar eps = 0.00000001\n\nfunc floatEquals(a, b float64) bool {\n\tif math.Abs(a-b) < eps {\n\t\treturn true\n\t}\n\treturn false\n}\n\n// round helper from https://stackoverflow.com/questions/39544571/golang-round-to-nearest-0-05\nfunc round(x, unit float64) float64 {\n\treturn float64(int64(x/unit+0.5)) * unit\n}\n"
        },
        {
          "name": "highgui.cpp",
          "type": "blob",
          "size": 2.4912109375,
          "content": "#include \"highgui_gocv.h\"\n\nvoid Window_SetMouseCallback(char* winname, mouse_callback on_mouse) {\n    cv::setMouseCallback(winname, on_mouse, (void*)winname);\n}\n\n// Window\nvoid Window_New(const char* winname, int flags) {\n    cv::namedWindow(winname, flags);\n}\n\nvoid Window_Close(const char* winname) {\n    cv::destroyWindow(winname);\n}\n\nvoid Window_IMShow(const char* winname, Mat mat) {\n    cv::imshow(winname, *mat);\n}\n\ndouble Window_GetProperty(const char* winname, int flag) {\n    return cv::getWindowProperty(winname, flag);\n}\n\nvoid Window_SetProperty(const char* winname, int flag, double value) {\n    cv::setWindowProperty(winname, flag, value);\n}\n\nvoid Window_SetTitle(const char* winname, const char* title) {\n    cv::setWindowTitle(winname, title);\n}\n\nint Window_WaitKey(int delay = 0) {\n    return cv::waitKey(delay);\n}\n\nint Window_WaitKeyEx(int delay = 0) {\n    return cv::waitKeyEx(delay);\n}\n\nint Window_PollKey(void) {\n    return cv::pollKey();\n}\n\nvoid Window_Move(const char* winname, int x, int y) {\n    cv::moveWindow(winname, x, y);\n}\n\nvoid Window_Resize(const char* winname, int width, int height) {\n    cv::resizeWindow(winname, width, height);\n}\n\nstruct Rect Window_SelectROI(const char* winname, Mat img) {\n    cv::Rect bRect = cv::selectROI(winname, *img);\n    Rect r = {bRect.x, bRect.y, bRect.width, bRect.height};\n    return r;\n}\n\nstruct Rects Window_SelectROIs(const char* winname, Mat img) {\n    std::vector<cv::Rect> rois;\n    cv::selectROIs(winname, *img, rois);\n    Rect* rects = new Rect[rois.size()];\n\n    for (size_t i = 0; i < rois.size(); ++i) {\n        Rect r = {rois[i].x, rois[i].y, rois[i].width, rois[i].height};\n        rects[i] = r;\n    }\n\n    Rects ret = {rects, (int)rois.size()};\n    return ret;\n}\n\n// Trackbar\nvoid Trackbar_Create(const char* winname, const char* trackname, int max) {\n    cv::createTrackbar(trackname, winname, NULL, max);\n}\n\nvoid Trackbar_CreateWithValue(const char* winname, const char* trackname, int* value, int max) {\n    cv::createTrackbar(trackname, winname, value, max);\n}\n\nint Trackbar_GetPos(const char* winname, const char* trackname) {\n    return cv::getTrackbarPos(trackname, winname);\n}\n\nvoid Trackbar_SetPos(const char* winname, const char* trackname, int pos) {\n    cv::setTrackbarPos(trackname, winname, pos);\n}\n\nvoid Trackbar_SetMin(const char* winname, const char* trackname, int pos) {\n    cv::setTrackbarMin(trackname, winname, pos);\n}\n\nvoid Trackbar_SetMax(const char* winname, const char* trackname, int pos) {\n    cv::setTrackbarMax(trackname, winname, pos);\n}\n"
        },
        {
          "name": "highgui.go",
          "type": "blob",
          "size": 12.728515625,
          "content": "package gocv\n\n/*\n#include <stdlib.h>\n#include \"highgui_gocv.h\"\n\nvoid go_onmouse_dispatcher(int event, int x, int y, int flags, void *userdata);\n*/\nimport \"C\"\nimport (\n\t\"image\"\n\t\"runtime\"\n\t\"unsafe\"\n)\n\ntype MouseHandlerFunc func(event int, x int, y int, flags int, userdata interface{})\n\ntype mouseHandlerInfo struct {\n\tc_name_ptr *C.char\n\tfn         MouseHandlerFunc\n\tuserdata   interface{}\n}\n\nvar (\n\tonMouseHandlers = map[string]mouseHandlerInfo{}\n)\n\n// Window is a wrapper around OpenCV's \"HighGUI\" named windows.\n// While OpenCV was designed for use in full-scale applications and can be used\n// within functionally rich UI frameworks (such as Qt*, WinForms*, or Cocoa*)\n// or without any UI at all, sometimes there it is required to try functionality\n// quickly and visualize the results. This is what the HighGUI module has been designed for.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d7/dfc/group__highgui.html\ntype Window struct {\n\tname string\n\topen bool\n}\n\n// NewWindow creates a new named OpenCV window\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d7/dfc/group__highgui.html#ga5afdf8410934fd099df85c75b2e0888b\nfunc NewWindow(name string) *Window {\n\truntime.LockOSThread()\n\n\tcName := C.CString(name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\tC.Window_New(cName, 0)\n\n\treturn &Window{name: name, open: true}\n}\n\n// Close closes and deletes a named OpenCV Window.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d7/dfc/group__highgui.html#ga851ccdd6961022d1d5b4c4f255dbab34\nfunc (w *Window) Close() error {\n\tcName := C.CString(w.name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\tmcbInfo, exists := onMouseHandlers[w.name]\n\tif exists {\n\t\tmcbInfo.fn = nil\n\t\tmcbInfo.userdata = nil\n\t\tC.free(unsafe.Pointer(mcbInfo.c_name_ptr))\n\t\tdelete(onMouseHandlers, w.name)\n\t}\n\n\tC.Window_Close(cName)\n\tw.open = false\n\n\truntime.UnlockOSThread()\n\treturn nil\n}\n\n// IsOpen checks to see if the Window seems to be open.\nfunc (w *Window) IsOpen() bool {\n\treturn w.open\n}\n\n// WindowFlag value for SetWindowProperty / GetWindowProperty.\ntype WindowFlag float32\n\nconst (\n\t// WindowNormal indicates a normal window.\n\tWindowNormal WindowFlag = 0x00000000\n\n\t// WindowAutosize indicates a window sized based on the contents.\n\tWindowAutosize WindowFlag = 0x00000001\n\n\t// WindowFullscreen indicates a full-screen window.\n\tWindowFullscreen WindowFlag = 1\n\n\t// WindowFreeRatio indicates allow the user to resize without maintaining aspect ratio.\n\tWindowFreeRatio WindowFlag = 0x00000100\n\n\t// WindowKeepRatio indicates always maintain an aspect ratio that matches the contents.\n\tWindowKeepRatio WindowFlag = 0x00000000\n)\n\n// WindowPropertyFlag flags for SetWindowProperty / GetWindowProperty.\ntype WindowPropertyFlag int\n\nconst (\n\t// WindowPropertyFullscreen fullscreen property\n\t// (can be WINDOW_NORMAL or WINDOW_FULLSCREEN).\n\tWindowPropertyFullscreen WindowPropertyFlag = 0\n\n\t// WindowPropertyAutosize is autosize property\n\t// (can be WINDOW_NORMAL or WINDOW_AUTOSIZE).\n\tWindowPropertyAutosize WindowPropertyFlag = 1\n\n\t// WindowPropertyAspectRatio window's aspect ration\n\t// (can be set to WINDOW_FREERATIO or WINDOW_KEEPRATIO).\n\tWindowPropertyAspectRatio WindowPropertyFlag = 2\n\n\t// WindowPropertyOpenGL opengl support.\n\tWindowPropertyOpenGL WindowPropertyFlag = 3\n\n\t// WindowPropertyVisible or not.\n\tWindowPropertyVisible WindowPropertyFlag = 4\n)\n\n// GetWindowProperty returns properties of a window.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/dfc/group__highgui.html#gaaf9504b8f9cf19024d9d44a14e461656\nfunc (w *Window) GetWindowProperty(flag WindowPropertyFlag) float64 {\n\tcName := C.CString(w.name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\treturn float64(C.Window_GetProperty(cName, C.int(flag)))\n}\n\n// SetWindowProperty changes parameters of a window dynamically.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/dfc/group__highgui.html#ga66e4a6db4d4e06148bcdfe0d70a5df27\nfunc (w *Window) SetWindowProperty(flag WindowPropertyFlag, value WindowFlag) {\n\tcName := C.CString(w.name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\tC.Window_SetProperty(cName, C.int(flag), C.double(value))\n}\n\n// SetWindowTitle updates window title.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/dfc/group__highgui.html#ga56f8849295fd10d0c319724ddb773d96\nfunc (w *Window) SetWindowTitle(title string) {\n\tcName := C.CString(w.name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\tcTitle := C.CString(title)\n\tdefer C.free(unsafe.Pointer(cTitle))\n\n\tC.Window_SetTitle(cName, cTitle)\n}\n\n// IMShow displays an image Mat in the specified window.\n// This function should be followed by the WaitKey function which displays\n// the image for specified milliseconds. Otherwise, it won't display the image.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d7/dfc/group__highgui.html#ga453d42fe4cb60e5723281a89973ee563\nfunc (w *Window) IMShow(img Mat) {\n\tcName := C.CString(w.name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\tC.Window_IMShow(cName, img.p)\n}\n\n// WaitKey waits for a pressed key.\n// This function is the only method in OpenCV's HighGUI that can fetch\n// and handle events, so it needs to be called periodically\n// for normal event processing\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d7/dfc/group__highgui.html#ga5628525ad33f52eab17feebcfba38bd7\nfunc (w *Window) WaitKey(delay int) int {\n\treturn int(C.Window_WaitKey(C.int(delay)))\n}\n\n// WaitKeyEx Similar to waitKey, but returns full key code.\n// Note\n// Key code is implementation specific and depends on used backend: QT/GTK/Win32/etc\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d7/dfc/group__highgui.html#gafa15c0501e0ddd90918f17aa071d3dd0\nfunc (w *Window) WaitKeyEx(delay int) int {\n\treturn int(C.Window_WaitKey(C.int(delay)))\n}\n\n// PollKey polls for a pressed key.\n// The function pollKey polls for a key event without waiting.\n// It returns the code of the pressed key or -1 if no key was pressed since\n// the last invocation. To wait until a key was pressed, use waitKey.\n//\n// The functions waitKey and pollKey are the only methods in HighGUI that can\n// fetch and handle GUI events, so one of them needs to be called periodically\n// for normal event processing unless HighGUI is used within an environment that\n// takes care of event processing.\n// The function only works if there is at least one HighGUI window created and\n// the window is active. If there are several HighGUI windows, any of them can\n// be active.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d7/dfc/group__highgui.html#ga6d20fbd3100ec3badc1eaa653aff99d7\nfunc (w *Window) PollKey() int {\n\treturn int(C.Window_PollKey())\n}\n\n// MoveWindow moves window to the specified position.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/dfc/group__highgui.html#ga8d86b207f7211250dbe6e28f76307ffb\nfunc (w *Window) MoveWindow(x, y int) {\n\tcName := C.CString(w.name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\tC.Window_Move(cName, C.int(x), C.int(y))\n}\n\n// ResizeWindow resizes window to the specified size.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/dfc/group__highgui.html#ga9e80e080f7ef33f897e415358aee7f7e\nfunc (w *Window) ResizeWindow(width, height int) {\n\tcName := C.CString(w.name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\tC.Window_Resize(cName, C.int(width), C.int(height))\n}\n\n// SelectROI selects a Region Of Interest (ROI) on the given image.\n// It creates a window and allows user to select a ROI using mouse.\n//\n// Controls:\n// use space or enter to finish selection,\n// use key c to cancel selection (function will return a zero Rect).\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/dfc/group__highgui.html#ga8daf4730d3adf7035b6de9be4c469af5\nfunc (w *Window) SelectROI(img Mat) image.Rectangle {\n\tcName := C.CString(w.name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\tr := C.Window_SelectROI(cName, img.p)\n\trect := image.Rect(int(r.x), int(r.y), int(r.x+r.width), int(r.y+r.height))\n\treturn rect\n}\n\n// SelectROIs selects multiple Regions Of Interest (ROI) on the given image.\n// It creates a window and allows user to select ROIs using mouse.\n//\n// Controls:\n// use space or enter to finish current selection and start a new one\n// use esc to terminate multiple ROI selection process\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/dfc/group__highgui.html#ga0f11fad74a6432b8055fb21621a0f893\nfunc (w *Window) SelectROIs(img Mat) []image.Rectangle {\n\tcName := C.CString(w.name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\tret := C.Window_SelectROIs(cName, img.p)\n\tdefer C.Rects_Close(ret)\n\n\treturn toRectangles(ret)\n}\n\n// Deprecated: use Window.SelectROI instead\nfunc SelectROI(name string, img Mat) image.Rectangle {\n\tcName := C.CString(name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\tr := C.Window_SelectROI(cName, img.p)\n\trect := image.Rect(int(r.x), int(r.y), int(r.x+r.width), int(r.y+r.height))\n\treturn rect\n}\n\n// Deprecated: use Window.SelectROIs instead\nfunc SelectROIs(name string, img Mat) []image.Rectangle {\n\tcName := C.CString(name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\tret := C.Window_SelectROIs(cName, img.p)\n\tdefer C.Rects_Close(ret)\n\n\treturn toRectangles(ret)\n}\n\n// WaitKey that is not attached to a specific Window.\n// Only use when no Window exists in your application, e.g. command line app.\nfunc WaitKey(delay int) int {\n\treturn int(C.Window_WaitKey(C.int(delay)))\n}\n\n// Trackbar is a wrapper around OpenCV's \"HighGUI\" window Trackbars.\ntype Trackbar struct {\n\tname   string\n\tparent *Window\n}\n\n// CreateTrackbar creates a trackbar and attaches it to the specified window.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/dfc/group__highgui.html#gaf78d2155d30b728fc413803745b67a9b\nfunc (w *Window) CreateTrackbar(name string, max int) *Trackbar {\n\tcName := C.CString(w.name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\ttName := C.CString(name)\n\tdefer C.free(unsafe.Pointer(tName))\n\n\tC.Trackbar_Create(cName, tName, C.int(max))\n\treturn &Trackbar{name: name, parent: w}\n}\n\n// CreateTrackbarWithValue works like CreateTrackbar but also assigns a\n// variable value to be a position synchronized with the trackbar.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/dfc/group__highgui.html#gaf78d2155d30b728fc413803745b67a9b\nfunc (w *Window) CreateTrackbarWithValue(name string, value *int, max int) *Trackbar {\n\tcName := C.CString(w.name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\ttName := C.CString(name)\n\tdefer C.free(unsafe.Pointer(tName))\n\n\tC.Trackbar_CreateWithValue(cName, tName, (*C.int)(unsafe.Pointer(value)), C.int(max))\n\treturn &Trackbar{name: name, parent: w}\n}\n\n// GetPos returns the trackbar position.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/dfc/group__highgui.html#ga122632e9e91b9ec06943472c55d9cda8\nfunc (t *Trackbar) GetPos() int {\n\tcName := C.CString(t.parent.name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\ttName := C.CString(t.name)\n\tdefer C.free(unsafe.Pointer(tName))\n\n\treturn int(C.Trackbar_GetPos(cName, tName))\n}\n\n// SetPos sets the trackbar position.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/dfc/group__highgui.html#ga67d73c4c9430f13481fd58410d01bd8d\nfunc (t *Trackbar) SetPos(pos int) {\n\tcName := C.CString(t.parent.name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\ttName := C.CString(t.name)\n\tdefer C.free(unsafe.Pointer(tName))\n\n\tC.Trackbar_SetPos(cName, tName, C.int(pos))\n}\n\n// SetMin sets the trackbar minimum position.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/dfc/group__highgui.html#gabe26ffe8d2b60cc678895595a581b7aa\nfunc (t *Trackbar) SetMin(pos int) {\n\tcName := C.CString(t.parent.name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\ttName := C.CString(t.name)\n\tdefer C.free(unsafe.Pointer(tName))\n\n\tC.Trackbar_SetMin(cName, tName, C.int(pos))\n}\n\n// SetMax sets the trackbar maximum position.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/dfc/group__highgui.html#ga7e5437ccba37f1154b65210902fc4480\nfunc (t *Trackbar) SetMax(pos int) {\n\tcName := C.CString(t.parent.name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\ttName := C.CString(t.name)\n\tdefer C.free(unsafe.Pointer(tName))\n\n\tC.Trackbar_SetMax(cName, tName, C.int(pos))\n}\n\n//export go_onmouse_dispatcher\nfunc go_onmouse_dispatcher(event C.int, x C.int, y C.int, flags C.int, userdata unsafe.Pointer) {\n\n\tc_winname := (*C.char)(unsafe.Pointer(userdata))\n\twinName := C.GoString(c_winname)\n\tinfo, exists := onMouseHandlers[winName]\n\tif !exists {\n\t\treturn\n\t}\n\tinfo.fn(int(event), int(x), int(y), int(flags), info.userdata)\n}\n\nfunc (w *Window) SetMouseHandler(onMOuse MouseHandlerFunc, userdata interface{}) {\n\tc_winname := C.CString(w.name)\n\n\tonMouseHandlers[w.name] = mouseHandlerInfo{\n\t\tc_name_ptr: c_winname,\n\t\tfn:         onMOuse,\n\t\tuserdata:   userdata,\n\t}\n\n\tC.Window_SetMouseCallback(c_winname, C.mouse_callback(C.go_onmouse_dispatcher))\n}\n"
        },
        {
          "name": "highgui_gocv.h",
          "type": "blob",
          "size": 1.5673828125,
          "content": "#ifndef _OPENCV3_HIGHGUI_H_\n#define _OPENCV3_HIGHGUI_H_\n\n#ifdef __cplusplus\n#include <opencv2/opencv.hpp>\nextern \"C\" {\n#endif\n\n#include \"core.h\"\n\ntypedef void(*mouse_callback) (int event, int x, int y, int flags, void *userdata);\n\n/* typedef struct mouse_callback_userdata {\n    char* winname;\n    void* userdata;\n} mouse_callback_userdata; */\n\nvoid Window_SetMouseCallback(char* winname, mouse_callback on_mouse);\n\n// Window\nvoid Window_New(const char* winname, int flags);\nvoid Window_Close(const char* winname);\nvoid Window_IMShow(const char* winname, Mat mat);\ndouble Window_GetProperty(const char* winname, int flag);\nvoid Window_SetProperty(const char* winname, int flag, double value);\nvoid Window_SetTitle(const char* winname, const char* title);\nint Window_WaitKey(int);\nint Window_WaitKeyEx(int);\nint Window_PollKey(void);\nvoid Window_Move(const char* winname, int x, int y);\nvoid Window_Resize(const char* winname, int width, int height);\nstruct Rect Window_SelectROI(const char* winname, Mat img);\nstruct Rects Window_SelectROIs(const char* winname, Mat img);\n\n// Trackbar\nvoid Trackbar_Create(const char* winname, const char* trackname, int max);\nvoid Trackbar_CreateWithValue(const char* winname, const char* trackname, int* value, int max);\nint Trackbar_GetPos(const char* winname, const char* trackname);\nvoid Trackbar_SetPos(const char* winname, const char* trackname, int pos);\nvoid Trackbar_SetMin(const char* winname, const char* trackname, int pos);\nvoid Trackbar_SetMax(const char* winname, const char* trackname, int pos);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif //_OPENCV3_HIGHGUI_H_\n"
        },
        {
          "name": "highgui_onmouse_test.go",
          "type": "blob",
          "size": 0.5244140625,
          "content": "// Do not run these tests on mac OS X. They fail with errors suggesting the GUI\n// should only be touched from the main thread.\n//go:build !darwin\n// +build !darwin\n\npackage gocv\n\nimport (\n\t\"testing\"\n)\n\ntype mouseHandlerUserData struct {\n\tname string\n}\n\nfunc mouseHandler(event int, x int, y int, flags int, userdata interface{}) {}\n\nfunc TestMouseHandler(t *testing.T) {\n\twindowName := \"mouse\"\n\n\tw := NewWindow(windowName)\n\tdefer w.Close()\n\n\tudata := mouseHandlerUserData{\n\t\tname: \"gocv\",\n\t}\n\n\tw.SetMouseHandler(mouseHandler, &udata)\n}\n"
        },
        {
          "name": "highgui_string.go",
          "type": "blob",
          "size": 0.6875,
          "content": "package gocv\n\n/*\n#include <stdlib.h>\n#include \"highgui_gocv.h\"\n*/\nimport \"C\"\n\nfunc (c WindowFlag) String() string {\n\tswitch c {\n\tcase WindowNormal:\n\t\treturn \"window-normal\"\n\tcase WindowFullscreen:\n\t\treturn \"window-fullscreen\"\n\tcase WindowFreeRatio:\n\t\treturn \"window-free-ratio\"\n\t}\n\treturn \"\"\n}\n\nfunc (c WindowPropertyFlag) String() string {\n\tswitch c {\n\tcase WindowPropertyFullscreen:\n\t\treturn \"window-property-fullscreen\"\n\tcase WindowPropertyAutosize:\n\t\treturn \"window-property-autosize\"\n\tcase WindowPropertyAspectRatio:\n\t\treturn \"window-property-aspect-ratio\"\n\tcase WindowPropertyOpenGL:\n\t\treturn \"window-property-opengl\"\n\tcase WindowPropertyVisible:\n\t\treturn \"window-property-visible\"\n\t}\n\treturn \"\"\n}\n"
        },
        {
          "name": "highgui_test.go",
          "type": "blob",
          "size": 2.625,
          "content": "// Do not run these tests on mac OS X. They fail with errors suggesting the GUI\n// should only be touched from the main thread.\n//go:build !darwin\n// +build !darwin\n\npackage gocv\n\nimport (\n\t\"testing\"\n)\n\nfunc TestWindow(t *testing.T) {\n\twindow := NewWindow(\"test\")\n\tif window == nil {\n\t\tt.Error(\"Unable to create Window\")\n\t}\n\tif window.name != \"test\" {\n\t\tt.Error(\"Invalid Window name\")\n\t}\n\tval := window.WaitKey(1)\n\tif val != -1 {\n\t\tt.Error(\"Invalid WaitKey\")\n\t}\n\tif !window.IsOpen() {\n\t\tt.Error(\"Window should have been open\")\n\t}\n\n\twindow.SetWindowProperty(WindowPropertyFullscreen, WindowFullscreen)\n\n\tprop := WindowFlag(window.GetWindowProperty(WindowPropertyFullscreen))\n\tif prop != WindowFullscreen {\n\t\tt.Error(\"Window property should have been fullscreen\")\n\t}\n\n\twindow.SetWindowTitle(\"My new title\")\n\n\twindow.MoveWindow(100, 100)\n\n\twindow.ResizeWindow(100, 100)\n\n\twindow.Close()\n\tif window.IsOpen() {\n\t\tt.Error(\"Window should have been closed\")\n\t}\n}\n\nfunc TestIMShow(t *testing.T) {\n\twindow := NewWindow(\"imshow\")\n\tif window == nil {\n\t\tt.Error(\"Unable to create IMShow Window\")\n\t}\n\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in IMShow\")\n\t}\n\tdefer img.Close()\n\n\t// TODO: some way to determine if the call succeeded\n\twindow.IMShow(img)\n\n\tval := WaitKey(1)\n\tif val != -1 {\n\t\tt.Error(\"Invalid for IMShow\")\n\t}\n\n\twindow.Close()\n\tif window.IsOpen() {\n\t\tt.Error(\"IMShow window should have been closed\")\n\t}\n}\n\nfunc TestSelectROI(t *testing.T) {\n\tt.Skip(\"TODO: figure out how to implement a test that can exercise the GUI\")\n}\n\nfunc TestSelectROIs(t *testing.T) {\n\tt.Skip(\"TODO: figure out how to implement a test that can exercise the GUI\")\n}\n\nfunc TestTrackbar(t *testing.T) {\n\twindow := NewWindow(\"trackbar\")\n\tdefer window.Close()\n\n\ttracker := window.CreateTrackbar(\"trackme\", 100)\n\tif tracker.GetPos() != 0 {\n\t\tt.Error(\"Trackbar pos should have been 0\")\n\t}\n\n\ttracker.SetMin(10)\n\ttracker.SetMax(150)\n\ttracker.SetPos(50)\n\n\tif tracker.GetPos() != 50 {\n\t\tt.Error(\"Trackbar pos should have been 50\")\n\t}\n}\n\nfunc TestTrackbarWithValue(t *testing.T) {\n\twindow := NewWindow(\"trackbar\")\n\tdefer window.Close()\n\n\tvalue := 20\n\ttracker := window.CreateTrackbarWithValue(\"trackme\", &value, 100)\n\tif tracker.GetPos() != 20 {\n\t\tt.Error(\"Trackbar pos should have been 20\")\n\t}\n\n\ttracker.SetPos(50)\n\n\tif value != 50 {\n\t\tt.Error(\"Trackbar pos should have been 50\")\n\t}\n}\n\nfunc TestPollKey(t *testing.T) {\n\n\tw := NewWindow(\"polly\")\n\tdefer w.Close()\n\n\tif v := w.PollKey(); v != -1 {\n\t\tt.Errorf(\"got %d want -1\", v)\n\t}\n}\n\nfunc TestWaitKeyEx(t *testing.T) {\n\n\tw := NewWindow(\"wait\")\n\tdefer w.Close()\n\n\tif w.WaitKeyEx(1) != -1 {\n\t\tt.Error(\"WaitKeyEx failed!\")\n\t}\n}\n"
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        },
        {
          "name": "imgcodecs.cpp",
          "type": "blob",
          "size": 2.27734375,
          "content": "#include <stdlib.h>\n#include \"imgcodecs.h\"\n\n// Image\nMat Image_IMRead(const char* filename, int flags) {\n    cv::Mat img = cv::imread(filename, flags);\n    return new cv::Mat(img);\n}\n\nMats Image_IMReadMulti(const char* filename, int flags) {\n    std::vector<cv::Mat> dst;\n    Mats m = Mats();\n\n    bool b = cv::imreadmulti(filename, dst, flags);\n    if (b) {\n        m.mats = new Mat[dst.size()];\n        for (size_t i = 0; i < dst.size(); ++i) {\n            m.mats[i] = new cv::Mat(dst[i]);\n        }\n        m.length = (int)dst.size();        \n    }\n\n    return m;\n}\n\nMats Image_IMReadMulti_WithParams(const char* filename, int start, int count, int flags) {\n    std::vector<cv::Mat> dst;\n    auto m = Mats();\n    \n    auto b = cv::imreadmulti(filename, dst, start, count, flags);\n    if (b) {\n        m.mats = new Mat[dst.size()];\n        for (size_t i = 0; i < dst.size(); ++i) {\n            m.mats[i] = new cv::Mat(dst[i]);\n        }\n        m.length = (int)dst.size();        \n    }\n\n    return m;\n}\n\n\nbool Image_IMWrite(const char* filename, Mat img) {\n    return cv::imwrite(filename, *img);\n}\n\nbool Image_IMWrite_WithParams(const char* filename, Mat img, IntVector params) {\n    std::vector<int> compression_params;\n\n    for (int i = 0, *v = params.val; i < params.length; ++v, ++i) {\n        compression_params.push_back(*v);\n    }\n\n    return cv::imwrite(filename, *img, compression_params);\n}\n\nvoid Image_IMEncode(const char* fileExt, Mat img, void* vector) {\n    auto vectorPtr = reinterpret_cast<std::vector<uchar> *>(vector);\n    cv::imencode(fileExt, *img, *vectorPtr);\n}\n\nvoid Image_IMEncode_WithParams(const char* fileExt, Mat img, IntVector params, void* vector) {\n    auto vectorPtr = reinterpret_cast<std::vector<uchar> *>(vector);\n    std::vector<int> compression_params;\n\n    for (int i = 0, *v = params.val; i < params.length; ++v, ++i) {\n        compression_params.push_back(*v);\n    }\n\n    cv::imencode(fileExt, *img, *vectorPtr, compression_params);\n}\n\nMat Image_IMDecode(ByteArray buf, int flags) {\n    std::vector<uchar> data(buf.data, buf.data + buf.length);\n    cv::Mat img = cv::imdecode(data, flags);\n    return new cv::Mat(img);\n}\n\nvoid Image_IMDecodeIntoMat(ByteArray buf, int flags, Mat dest) {\n    std::vector<uchar> data(buf.data, buf.data + buf.length);\n    cv::imdecode(data, flags, dest);\n}\n"
        },
        {
          "name": "imgcodecs.go",
          "type": "blob",
          "size": 10.728515625,
          "content": "package gocv\n\n/*\n#include <stdlib.h>\n#include \"imgcodecs.h\"\n*/\nimport \"C\"\nimport (\n\t\"unsafe\"\n)\n\n// IMReadFlag is one of the valid flags to use for the IMRead function.\ntype IMReadFlag int\n\nconst (\n\t// IMReadUnchanged return the loaded image as is (with alpha channel,\n\t// otherwise it gets cropped).\n\tIMReadUnchanged IMReadFlag = -1\n\n\t// IMReadGrayScale always convert image to the single channel\n\t// grayscale image.\n\tIMReadGrayScale IMReadFlag = 0\n\n\t// IMReadColor always converts image to the 3 channel BGR color image.\n\tIMReadColor IMReadFlag = 1\n\n\t// IMReadAnyDepth returns 16-bit/32-bit image when the input has the corresponding\n\t// depth, otherwise convert it to 8-bit.\n\tIMReadAnyDepth IMReadFlag = 2\n\n\t// IMReadAnyColor the image is read in any possible color format.\n\tIMReadAnyColor IMReadFlag = 4\n\n\t// IMReadLoadGDAL uses the gdal driver for loading the image.\n\tIMReadLoadGDAL IMReadFlag = 8\n\n\t// IMReadReducedGrayscale2 always converts image to the single channel grayscale image\n\t// and the image size reduced 1/2.\n\tIMReadReducedGrayscale2 IMReadFlag = 16\n\n\t// IMReadReducedColor2 always converts image to the 3 channel BGR color image and the\n\t// image size reduced 1/2.\n\tIMReadReducedColor2 IMReadFlag = 17\n\n\t// IMReadReducedGrayscale4 always converts image to the single channel grayscale image and\n\t// the image size reduced 1/4.\n\tIMReadReducedGrayscale4 IMReadFlag = 32\n\n\t// IMReadReducedColor4 always converts image to the 3 channel BGR color image and\n\t// the image size reduced 1/4.\n\tIMReadReducedColor4 IMReadFlag = 33\n\n\t// IMReadReducedGrayscale8 always convert image to the single channel grayscale image and\n\t// the image size reduced 1/8.\n\tIMReadReducedGrayscale8 IMReadFlag = 64\n\n\t// IMReadReducedColor8 always convert image to the 3 channel BGR color image and the\n\t// image size reduced 1/8.\n\tIMReadReducedColor8 IMReadFlag = 65\n\n\t// IMReadIgnoreOrientation do not rotate the image according to EXIF's orientation flag.\n\tIMReadIgnoreOrientation IMReadFlag = 128\n)\n\n// TODO: Define IMWriteFlag type?\n\nconst (\n\t//IMWriteJpegQuality is the quality from 0 to 100 for JPEG (the higher is the better). Default value is 95.\n\tIMWriteJpegQuality = 1\n\n\t// IMWriteJpegProgressive enables JPEG progressive feature, 0 or 1, default is False.\n\tIMWriteJpegProgressive = 2\n\n\t// IMWriteJpegOptimize enables JPEG optimization, 0 or 1, default is False.\n\tIMWriteJpegOptimize = 3\n\n\t// IMWriteJpegRstInterval is the JPEG restart interval, 0 - 65535, default is 0 - no restart.\n\tIMWriteJpegRstInterval = 4\n\n\t// IMWriteJpegLumaQuality separates luma quality level, 0 - 100, default is 0 - don't use.\n\tIMWriteJpegLumaQuality = 5\n\n\t// IMWriteJpegChromaQuality separates chroma quality level, 0 - 100, default is 0 - don't use.\n\tIMWriteJpegChromaQuality = 6\n\n\t// IMWritePngCompression is the compression level from 0 to 9 for PNG. A\n\t// higher value means a smaller size and longer compression time.\n\t// If specified, strategy is changed to IMWRITE_PNG_STRATEGY_DEFAULT (Z_DEFAULT_STRATEGY).\n\t// Default value is 1 (best speed setting).\n\tIMWritePngCompression = 16\n\n\t// IMWritePngStrategy is one of cv::IMWritePNGFlags, default is IMWRITE_PNG_STRATEGY_RLE.\n\tIMWritePngStrategy = 17\n\n\t// IMWritePngBilevel is the binary level PNG, 0 or 1, default is 0.\n\tIMWritePngBilevel = 18\n\n\t// IMWritePxmBinary for PPM, PGM, or PBM can be a binary format flag, 0 or 1. Default value is 1.\n\tIMWritePxmBinary = 32\n\n\t// IMWriteWebpQuality is the quality from 1 to 100 for WEBP (the higher is\n\t// the better). By default (without any parameter) and for quality above\n\t// 100 the lossless compression is used.\n\tIMWriteWebpQuality = 64\n\n\t// IMWritePamTupletype sets the TUPLETYPE field to the corresponding string\n\t// value that is defined for the format.\n\tIMWritePamTupletype = 128\n\n\t// IMWritePngStrategyDefault is the value to use for normal data.\n\tIMWritePngStrategyDefault = 0\n\n\t// IMWritePngStrategyFiltered is the value to use for data produced by a\n\t// filter (or predictor). Filtered data consists mostly of small values\n\t// with a somewhat random distribution. In this case, the compression\n\t// algorithm is tuned to compress them better.\n\tIMWritePngStrategyFiltered = 1\n\n\t// IMWritePngStrategyHuffmanOnly forces Huffman encoding only (no string match).\n\tIMWritePngStrategyHuffmanOnly = 2\n\n\t// IMWritePngStrategyRle is the value to use to limit match distances to\n\t// one (run-length encoding).\n\tIMWritePngStrategyRle = 3\n\n\t// IMWritePngStrategyFixed is the value to prevent the use of dynamic\n\t// Huffman codes, allowing for a simpler decoder for special applications.\n\tIMWritePngStrategyFixed = 4\n)\n\n// IMRead reads an image from a file into a Mat.\n// The flags param is one of the IMReadFlag flags.\n// If the image cannot be read (because of missing file, improper permissions,\n// unsupported or invalid format), the function returns an empty Mat.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d4/da8/group__imgcodecs.html#ga288b8b3da0892bd651fce07b3bbd3a56\nfunc IMRead(name string, flags IMReadFlag) Mat {\n\tcName := C.CString(name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\treturn newMat(C.Image_IMRead(cName, C.int(flags)))\n}\n\n// IMReadMulti reads multi-page image from a file into a []Mat.\n// The flags param is one of the IMReadFlag flags.\n// If the image cannot be read (because of missing file, improper permissions,\n// unsupported or invalid format), the function returns an empty []Mat.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d4/da8/group__imgcodecs.html#gaaeb5e219c706fd6aa1ec6cf17b172080\nfunc IMReadMulti(name string, flags IMReadFlag) []Mat {\n\tvar mats []Mat\n\tmultiRead := C.struct_Mats{}\n\n\tcName := C.CString(name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\tmultiRead = C.Image_IMReadMulti(cName, C.int(flags))\n\tdefer C.Mats_Close(multiRead)\n\n\tif multiRead.length > C.int(0) {\n\t\tmats = make([]Mat, multiRead.length)\n\t\tfor i := 0; i < int(multiRead.length); i++ {\n\t\t\tmats[i].p = C.Mats_get(multiRead, C.int(i))\n\t\t}\n\t}\n\treturn mats\n}\n\n// IMReadMulti reads multi-page image from a file into a []Mat.\n// The flags param is one of the IMReadFlag flags.\n// If the image cannot be read (because of missing file, improper permissions,\n// unsupported or invalid format), the function returns an empty []Mat.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d4/da8/group__imgcodecs.html#ga55e88dc40b65807cfbe2c62d27f7fdf9\nfunc IMReadMulti_WithParams(name string, start int, count int, flags IMReadFlag) []Mat {\n\tvar mats []Mat\n\tmultiRead := C.struct_Mats{}\n\n\tcName := C.CString(name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\tmultiRead = C.Image_IMReadMulti_WithParams(cName, C.int(start), C.int(count), C.int(flags))\n\tdefer C.Mats_Close(multiRead)\n\n\tif multiRead.length > C.int(0) {\n\t\tmats = make([]Mat, multiRead.length)\n\t\tfor i := 0; i < int(multiRead.length); i++ {\n\t\t\tmats[i].p = C.Mats_get(multiRead, C.int(i))\n\t\t}\n\t}\n\treturn mats\n}\n\n// IMWrite writes a Mat to an image file.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d4/da8/group__imgcodecs.html#gabbc7ef1aa2edfaa87772f1202d67e0ce\nfunc IMWrite(name string, img Mat) bool {\n\tcName := C.CString(name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\treturn bool(C.Image_IMWrite(cName, img.p))\n}\n\n// IMWriteWithParams writes a Mat to an image file. With that func you can\n// pass compression parameters.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d4/da8/group__imgcodecs.html#gabbc7ef1aa2edfaa87772f1202d67e0ce\nfunc IMWriteWithParams(name string, img Mat, params []int) bool {\n\tcName := C.CString(name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\tcparams := []C.int{}\n\n\tfor _, v := range params {\n\t\tcparams = append(cparams, C.int(v))\n\t}\n\n\tparamsVector := C.struct_IntVector{}\n\tparamsVector.val = (*C.int)(&cparams[0])\n\tparamsVector.length = (C.int)(len(cparams))\n\n\treturn bool(C.Image_IMWrite_WithParams(cName, img.p, paramsVector))\n}\n\n// FileExt represents a file extension.\ntype FileExt string\n\nconst (\n\t// PNGFileExt is the file extension for PNG.\n\tPNGFileExt FileExt = \".png\"\n\t// JPEGFileExt is the file extension for JPEG.\n\tJPEGFileExt FileExt = \".jpg\"\n\t// GIFFileExt is the file extension for GIF.\n\tGIFFileExt FileExt = \".gif\"\n)\n\n// IMEncode encodes an image Mat into a memory buffer.\n// This function compresses the image and stores it in the returned memory buffer,\n// using the image format passed in in the form of a file extension string.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d4/da8/group__imgcodecs.html#ga461f9ac09887e47797a54567df3b8b63\nfunc IMEncode(fileExt FileExt, img Mat) (buf *NativeByteBuffer, err error) {\n\tcfileExt := C.CString(string(fileExt))\n\tdefer C.free(unsafe.Pointer(cfileExt))\n\n\tbuffer := newNativeByteBuffer()\n\tC.Image_IMEncode(cfileExt, img.Ptr(), buffer.nativePointer())\n\treturn buffer, nil\n}\n\n// IMEncodeWithParams encodes an image Mat into a memory buffer.\n// This function compresses the image and stores it in the returned memory buffer,\n// using the image format passed in in the form of a file extension string.\n//\n// Usage example:\n//\n//\tbuffer, err := gocv.IMEncodeWithParams(gocv.JPEGFileExt, img, []int{gocv.IMWriteJpegQuality, quality})\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d4/da8/group__imgcodecs.html#ga461f9ac09887e47797a54567df3b8b63\nfunc IMEncodeWithParams(fileExt FileExt, img Mat, params []int) (buf *NativeByteBuffer, err error) {\n\tcfileExt := C.CString(string(fileExt))\n\tdefer C.free(unsafe.Pointer(cfileExt))\n\n\tcparams := []C.int{}\n\n\tfor _, v := range params {\n\t\tcparams = append(cparams, C.int(v))\n\t}\n\n\tparamsVector := C.struct_IntVector{}\n\tparamsVector.val = (*C.int)(&cparams[0])\n\tparamsVector.length = (C.int)(len(cparams))\n\n\tb := newNativeByteBuffer()\n\tC.Image_IMEncode_WithParams(cfileExt, img.Ptr(), paramsVector, b.nativePointer())\n\treturn b, nil\n}\n\n// IMDecode reads an image from a buffer in memory.\n// The function IMDecode reads an image from the specified buffer in memory.\n// If the buffer is too short or contains invalid data, the function\n// returns an empty matrix.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/da8/group__imgcodecs.html#ga26a67788faa58ade337f8d28ba0eb19e\nfunc IMDecode(buf []byte, flags IMReadFlag) (Mat, error) {\n\tdata, err := toByteArray(buf)\n\tif err != nil {\n\t\treturn Mat{}, err\n\t}\n\treturn newMat(C.Image_IMDecode(*data, C.int(flags))), nil\n}\n\n// IMDecodeIntoMat reads an image from a buffer in memory into a matrix.\n// The function IMDecodeIntoMat reads an image from the specified buffer in memory.\n// If the buffer is too short or contains invalid data, the function\n// returns an error\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d4/da8/group__imgcodecs.html#ga5a0acefe5cbe0a81e904e452ec7ca733\nfunc IMDecodeIntoMat(buf []byte, flags IMReadFlag, dest *Mat) error {\n\tdata, err := toByteArray(buf)\n\tif err != nil {\n\t\treturn err\n\t}\n\tC.Image_IMDecodeIntoMat(*data, C.int(flags), dest.p)\n\treturn nil\n}\n"
        },
        {
          "name": "imgcodecs.h",
          "type": "blob",
          "size": 0.8115234375,
          "content": "#ifndef _OPENCV3_IMGCODECS_H_\n#define _OPENCV3_IMGCODECS_H_\n\n#include <stdbool.h>\n\n#ifdef __cplusplus\n#include <opencv2/opencv.hpp>\nextern \"C\" {\n#endif\n\n#include \"core.h\"\n\nMat Image_IMRead(const char* filename, int flags);\nMats Image_IMReadMulti(const char* filename, int flags);\nMats Image_IMReadMulti_WithParams(const char* filename, int start, int count, int flags);\nbool Image_IMWrite(const char* filename, Mat img);\nbool Image_IMWrite_WithParams(const char* filename, Mat img, IntVector params);\nvoid Image_IMEncode(const char* fileExt, Mat img, void* vector);\n\nvoid Image_IMEncode_WithParams(const char* fileExt, Mat img, IntVector params, void* vector);\nMat Image_IMDecode(ByteArray buf, int flags);\nvoid Image_IMDecodeIntoMat(ByteArray buf, int flag, Mat dest);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif //_OPENCV3_IMGCODECS_H_\n"
        },
        {
          "name": "imgcodecs_test.go",
          "type": "blob",
          "size": 4.54296875,
          "content": "package gocv\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"net/http\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"testing\"\n)\n\nfunc TestIMRead(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tdefer img.Close()\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in IMRead\")\n\t}\n}\n\nfunc TestIMWrite(t *testing.T) {\n\tdir, _ := ioutil.TempDir(\"\", \"gocvtests\")\n\ttmpfn := filepath.Join(dir, \"test.jpg\")\n\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tdefer img.Close()\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in IMWrite test\")\n\t}\n\n\tresult := IMWrite(tmpfn, img)\n\tif !result {\n\t\tt.Error(\"Invalid write of Mat in IMWrite test\")\n\t}\n}\n\nfunc TestIMWriteWithParams(t *testing.T) {\n\tdir, _ := ioutil.TempDir(\"\", \"gocvtests\")\n\ttmpfn := filepath.Join(dir, \"test.jpg\")\n\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tdefer img.Close()\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in IMWrite test\")\n\t}\n\n\tresult := IMWriteWithParams(tmpfn, img, []int{IMWriteJpegQuality, 60})\n\tif !result {\n\t\tt.Error(\"Invalid write of Mat in IMWrite test\")\n\t}\n}\n\nfunc TestIMEncode(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tdefer img.Close()\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in IMEncode test\")\n\t}\n\n\tbuf, err := IMEncode(PNGFileExt, img)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tdefer buf.Close()\n\tbytes := buf.GetBytes()\n\tif len(bytes) < 43000 {\n\t\tt.Errorf(\"Wrong buffer size in IMEncode test. Should have been %v\\n\", len(bytes))\n\t}\n}\n\nfunc ExampleIMEncodeWithParams() {\n\timg := IMRead(path.Join(os.Getenv(\"GOPATH\"), \"src/gocv.io/x/gocv/images/face-detect.jpg\"), IMReadColor)\n\tif img.Empty() {\n\t\tlog.Fatal(\"Invalid Mat\")\n\t}\n\n\timgHandler := func(w http.ResponseWriter, req *http.Request) {\n\t\tquality := 75\n\t\tif q, err := strconv.Atoi(req.URL.Query().Get(\"q\")); err == nil {\n\t\t\tquality = q\n\t\t}\n\t\tbuffer, err := IMEncodeWithParams(JPEGFileExt, img, []int{IMWriteJpegQuality, quality})\n\t\tif err != nil {\n\t\t\tw.WriteHeader(http.StatusInternalServerError)\n\t\t\tio.WriteString(w, err.Error())\n\t\t\treturn\n\t\t}\n\t\tdefer buffer.Close()\n\t\tw.Header().Set(\"Content-Type\", \"image/jpeg\")\n\t\tw.WriteHeader(http.StatusOK)\n\t\tw.Write(buffer.GetBytes())\n\t}\n\n\thttp.HandleFunc(\"/img\", imgHandler)\n\tfmt.Println(\"Open in browser http://127.0.0.1:8080/img?q=10 where q is a JPEG quality parameter\")\n\tlog.Fatal(http.ListenAndServe(\"127.0.0.1:8080\", nil))\n}\n\nfunc TestIMEncodeWithParams(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tdefer img.Close()\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in IMEncode test\")\n\t}\n\n\tbuf, err := IMEncodeWithParams(JPEGFileExt, img, []int{IMWriteJpegQuality, 75})\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tdefer buf.Close()\n\tif buf.Len() < 18000 {\n\t\tt.Errorf(\"Wrong buffer size in IMEncode test. Should have been %v\\n\", buf.Len())\n\t}\n\n\tbuf2, err := IMEncodeWithParams(JPEGFileExt, img, []int{IMWriteJpegQuality, 100})\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tdefer buf2.Close()\n\tif buf2.Len() < 18000 {\n\t\tt.Errorf(\"Wrong buffer size in IMEncode test. Should have been %v\\n\", buf2.Len())\n\t}\n\n\tif buf.Len() >= buf2.Len() {\n\t\tt.Errorf(\"Jpeg quality parameter does not work correctly\\n\")\n\t}\n}\n\nfunc TestIMDecode(t *testing.T) {\n\tcontent, err := ioutil.ReadFile(\"images/face-detect.jpg\")\n\tif err != nil {\n\t\tt.Error(\"Invalid ReadFile in IMDecode\")\n\t}\n\n\tdec, err := IMDecode(content, IMReadColor)\n\tif err != nil {\n\t\tt.Error(err.Error())\n\t}\n\tif dec.Empty() {\n\t\tt.Error(\"Invalid Mat in IMDecode\")\n\t}\n\tdec.Close()\n\n\tdec, err = IMDecode([]byte{}, IMReadColor)\n\tif err == nil {\n\t\tt.Error(\"Should not decode empty array\")\n\t}\n}\n\nfunc TestIMDecodeIntoMat(t *testing.T) {\n\tmat := NewMat()\n\tdefer mat.Close()\n\tcontent, err := ioutil.ReadFile(\"images/face-detect.jpg\")\n\tif err != nil {\n\t\tt.Error(\"Invalid ReadFile in IMDecode\")\n\t}\n\n\terr = IMDecodeIntoMat(content, IMReadColor, &mat)\n\tif err != nil {\n\t\tt.Error(err.Error())\n\t}\n\tif mat.Empty() {\n\t\tt.Error(\"Invalid Mat in IMDecode\")\n\t}\n\n}\n\nfunc TestIMDecodeWebp(t *testing.T) {\n\tcontent, err := ioutil.ReadFile(\"images/sample.webp\")\n\tif err != nil {\n\t\tt.Error(\"Invalid ReadFile in IMDecodeWebp\")\n\t}\n\n\tdec, err := IMDecode(content, IMReadColor)\n\tif err != nil {\n\t\tt.Error(err.Error())\n\t}\n\tif dec.Empty() {\n\t\tt.Error(\"Invalid Mat in IMDecodeWebp\")\n\t}\n\tdec.Close()\n\n}\n\nfunc TestIMReadMulti(t *testing.T) {\n\n\tmats := IMReadMulti(\"images/multipage.tif\", IMReadAnyColor)\n\n\tfor i, page := range mats {\n\t\tif page.Empty() {\n\t\t\tt.Errorf(\"page %d empty\", i)\n\t\t}\n\t}\n\n}\n\nfunc TestIMReadMulti_WithParams(t *testing.T) {\n\n\tmats := IMReadMulti_WithParams(\"images/multipage.tif\", 2, 3, IMReadAnyColor)\n\n\tfor i, page := range mats {\n\t\tif page.Empty() {\n\t\t\tt.Errorf(\"page %d empty\", i)\n\t\t}\n\t}\n\n}\n"
        },
        {
          "name": "imgproc.cpp",
          "type": "blob",
          "size": 24.4814453125,
          "content": "#include \"imgproc.h\"\n\ndouble ArcLength(PointVector curve, bool is_closed) {\n    return cv::arcLength(*curve, is_closed);\n}\n\nPointVector ApproxPolyDP(PointVector curve, double epsilon, bool closed) {\n    PointVector approxCurvePts = new std::vector<cv::Point>;\n    cv::approxPolyDP(*curve, *approxCurvePts, epsilon, closed);\n\n    return approxCurvePts;\n}\n\nvoid CvtColor(Mat src, Mat dst, int code) {\n    cv::cvtColor(*src, *dst, code);\n}\n\nvoid Demosaicing(Mat src, Mat dst, int code) {\n    cv::demosaicing(*src, *dst, code);\n}\n\nvoid EqualizeHist(Mat src, Mat dst) {\n    cv::equalizeHist(*src, *dst);\n}\n\nvoid CalcHist(struct Mats mats, IntVector chans, Mat mask, Mat hist, IntVector sz, FloatVector rng, bool acc) {\n        std::vector<cv::Mat> images;\n\n        for (int i = 0; i < mats.length; ++i) {\n            images.push_back(*mats.mats[i]);\n        }\n\n        std::vector<int> channels;\n\n        for (int i = 0, *v = chans.val; i < chans.length; ++v, ++i) {\n            channels.push_back(*v);\n        }\n\n        std::vector<int> histSize;\n\n        for (int i = 0, *v = sz.val; i < sz.length; ++v, ++i) {\n            histSize.push_back(*v);\n        }\n\n        std::vector<float> ranges;\n\n        float* f;\n        int i;\n        for (i = 0, f = rng.val; i < rng.length; ++f, ++i) {\n            ranges.push_back(*f);\n        }\n\n        cv::calcHist(images, channels, *mask, *hist, histSize, ranges, acc);\n}\n\nvoid CalcBackProject(struct Mats mats, IntVector chans, Mat hist, Mat backProject, FloatVector rng, bool uniform){\n        std::vector<cv::Mat> images;\n\n        for (int i = 0; i < mats.length; ++i) {\n            images.push_back(*mats.mats[i]);\n        }\n\n        std::vector<int> channels;\n        for (int i = 0, *v = chans.val; i < chans.length; ++v, ++i) {\n            channels.push_back(*v);\n        }\n\n        std::vector<float> ranges;\n\n        float* f;\n        int i;\n        for (i = 0, f = rng.val; i < rng.length; ++f, ++i) {\n            ranges.push_back(*f);\n        }\n\n        cv::calcBackProject(images, channels, *hist, *backProject, ranges, uniform);\n}\n\ndouble CompareHist(Mat hist1, Mat hist2, int method) {\n    return cv::compareHist(*hist1, *hist2, method);\n}\n\nfloat EMD(Mat sig1, Mat sig2, int distType) {\n    return cv::EMD(*sig1, *sig2, distType);\n}\n\nstruct RotatedRect FitEllipse(PointVector pts)\n{\n    cv::RotatedRect bRect = cv::fitEllipse(*pts);\n\n    Rect r = {bRect.boundingRect().x, bRect.boundingRect().y, bRect.boundingRect().width, bRect.boundingRect().height};\n    Point centrpt = {int(lroundf(bRect.center.x)), int(lroundf(bRect.center.y))};\n    Size szsz = {int(lroundf(bRect.size.width)), int(lroundf(bRect.size.height))};\n\n    cv::Point2f* pts4 = new cv::Point2f[4];\n    bRect.points(pts4);\n    Point* rpts = new Point[4];\n    for (size_t j = 0; j < 4; j++) {\n        Point pt = {int(lroundf(pts4[j].x)), int(lroundf(pts4[j].y))};\n        rpts[j] = pt;\n    }\n\n    delete[] pts4;\n\n    RotatedRect rotRect = {Points{rpts, 4}, r, centrpt, szsz, bRect.angle};\n    return rotRect;\n}\n\nvoid ConvexHull(PointVector points, Mat hull, bool clockwise, bool returnPoints) {\n    cv::convexHull(*points, *hull, clockwise, returnPoints);\n}\n\nvoid ConvexityDefects(PointVector points, Mat hull, Mat result) {\n    cv::convexityDefects(*points, *hull, *result);\n}\n\nvoid BilateralFilter(Mat src, Mat dst, int d, double sc, double ss) {\n    cv::bilateralFilter(*src, *dst, d, sc, ss);\n}\n\nvoid Blur(Mat src, Mat dst, Size ps) {\n    cv::Size sz(ps.width, ps.height);\n    cv::blur(*src, *dst, sz);\n}\n\nvoid BoxFilter(Mat src, Mat dst, int ddepth, Size ps) {\n    cv::Size sz(ps.width, ps.height);\n    cv::boxFilter(*src, *dst, ddepth, sz);\n}\n\nvoid SqBoxFilter(Mat src, Mat dst, int ddepth, Size ps) {\n    cv::Size sz(ps.width, ps.height);\n    cv::sqrBoxFilter(*src, *dst, ddepth, sz);\n}\n\nvoid Dilate(Mat src, Mat dst, Mat kernel) {\n    cv::dilate(*src, *dst, *kernel);\n}\n\nvoid DilateWithParams(Mat src, Mat dst, Mat kernel, Point anchor, int iterations, int borderType, Scalar borderValue) {\n    cv::Point pt1(anchor.x, anchor.y);\n    cv::Scalar c = cv::Scalar(borderValue.val1, borderValue.val2, borderValue.val3, borderValue.val4);\n\n    cv::dilate(*src, *dst, *kernel, pt1, iterations, borderType, c);\n}\n\nvoid DistanceTransform(Mat src, Mat dst, Mat labels, int distanceType, int maskSize, int labelType) {\n    cv::distanceTransform(*src, *dst, *labels, distanceType, maskSize, labelType);\n}\n\nvoid Erode(Mat src, Mat dst, Mat kernel) {\n    cv::erode(*src, *dst, *kernel);\n}\n\nvoid ErodeWithParams(Mat src, Mat dst, Mat kernel, Point anchor, int iterations, int borderType) {\n    cv::Point pt1(anchor.x, anchor.y);\n\n    cv::erode(*src, *dst, *kernel, pt1, iterations, borderType, cv::morphologyDefaultBorderValue());\n}\n\nvoid ErodeWithParamsAndBorderValue(Mat src, Mat dst, Mat kernel, Point anchor, int iterations, int borderType, Scalar borderValue) {\n    cv::Point pt1(anchor.x, anchor.y);\n    cv::Scalar c = cv::Scalar(borderValue.val1, borderValue.val2, borderValue.val3, borderValue.val4);\n\n    cv::erode(*src, *dst, *kernel, pt1, iterations, borderType, c);\n}\n\n\nvoid MatchTemplate(Mat image, Mat templ, Mat result, int method, Mat mask) {\n    cv::matchTemplate(*image, *templ, *result, method, *mask);\n}\n\nstruct Moment Moments(Mat src, bool binaryImage) {\n    cv::Moments m = cv::moments(*src, binaryImage);\n    Moment mom = {m.m00, m.m10, m.m01, m.m20, m.m11, m.m02, m.m30, m.m21, m.m12, m.m03,\n                  m.mu20, m.mu11, m.mu02, m.mu30, m.mu21, m.mu12, m.mu03,\n                  m.nu20, m.nu11, m.nu02, m.nu30, m.nu21, m.nu12, m.nu03\n                 };\n    return mom;\n}\n\nvoid PyrDown(Mat src, Mat dst, Size size, int borderType) {\n    cv::Size cvSize(size.width, size.height);\n    cv::pyrDown(*src, *dst, cvSize, borderType);\n}\n\nvoid PyrUp(Mat src, Mat dst, Size size, int borderType) {\n    cv::Size cvSize(size.width, size.height);\n    cv::pyrUp(*src, *dst, cvSize, borderType);\n}\n\nstruct Rect BoundingRect(PointVector pts) {\n    cv::Rect bRect = cv::boundingRect(*pts);\n    Rect r = {bRect.x, bRect.y, bRect.width, bRect.height};\n    return r;\n}\n\nvoid BoxPoints(RotatedRect rect, Mat boxPts){\n    cv::Point2f centerPt(rect.center.x , rect.center.y);\n    cv::Size2f rSize(rect.size.width, rect.size.height);\n    cv::RotatedRect rotatedRectangle(centerPt, rSize, rect.angle);\n    cv::boxPoints(rotatedRectangle, *boxPts);\n}\n\nvoid BoxPoints2f(RotatedRect2f rect, Mat boxPts){\n    cv::Point2f centerPt(rect.center.x , rect.center.y);\n    cv::Size2f rSize(rect.size.width, rect.size.height);\n    cv::RotatedRect rotatedRectangle(centerPt, rSize, rect.angle);\n    cv::boxPoints(rotatedRectangle, *boxPts);\n}\n\ndouble ContourArea(PointVector pts) {\n    return cv::contourArea(*pts);\n}\n\nstruct RotatedRect MinAreaRect(PointVector pts){\n    cv::RotatedRect cvrect = cv::minAreaRect(*pts);\n\n    Point* rpts = new Point[4];\n    cv::Point2f* pts4 = new cv::Point2f[4];\n    cvrect.points(pts4);\n\n    for (size_t j = 0; j < 4; j++) {\n        Point pt = {int(lroundf(pts4[j].x)), int(lroundf(pts4[j].y))};\n        rpts[j] = pt;\n    }\n\n    delete[] pts4;\n\n    cv::Rect bRect = cvrect.boundingRect();\n    Rect r = {bRect.x, bRect.y, bRect.width, bRect.height};\n    Point centrpt = {int(lroundf(cvrect.center.x)), int(lroundf(cvrect.center.y))};\n    Size szsz = {int(lroundf(cvrect.size.width)), int(lroundf(cvrect.size.height))};\n\n    RotatedRect retrect = {(Contour){rpts, 4}, r, centrpt, szsz, cvrect.angle};\n    return retrect;\n}\n\nstruct RotatedRect2f MinAreaRect2f(PointVector pts){\n    cv::RotatedRect cvrect = cv::minAreaRect(*pts);\n\n    Point2f* rpts = new Point2f[4];\n    cv::Point2f* pts4 = new cv::Point2f[4];\n    cvrect.points(pts4);\n\n    for (size_t j = 0; j < 4; j++) {\n        Point2f pt = {pts4[j].x, pts4[j].y};\n        rpts[j] = pt;\n    }\n\n    delete[] pts4;\n\n    cv::Rect bRect = cvrect.boundingRect();\n    Rect r = {bRect.x, bRect.y, bRect.width, bRect.height};\n    Point2f centrpt = {cvrect.center.x, cvrect.center.y};\n    Size2f szsz = {cvrect.size.width, cvrect.size.height};\n\n    RotatedRect2f retrect = {(Contour2f){rpts, 4}, r, centrpt, szsz, cvrect.angle};\n    return retrect;\n}\n\nvoid MinEnclosingCircle(PointVector pts, Point2f* center, float* radius){\n    cv::Point2f center2f;\n    cv::minEnclosingCircle(*pts, center2f, *radius);\n    center->x = center2f.x;\n    center->y = center2f.y;\n}\n\nPointsVector FindContours(Mat src, Mat hierarchy, int mode, int method) {\n    PointsVector contours = new std::vector<std::vector<cv::Point> >;\n    cv::findContours(*src, *contours, *hierarchy, mode, method);\n\n    return contours;\n}\n\ndouble PointPolygonTest(PointVector pts, Point pt, bool measureDist) {\n\tcv::Point2f pt1(pt.x, pt.y);\n\n  return cv::pointPolygonTest(*pts, pt1, measureDist);\n}\n\nint ConnectedComponents(Mat src, Mat labels, int connectivity, int ltype, int ccltype){\n    return cv::connectedComponents(*src, *labels, connectivity, ltype, ccltype);\n}\n\n\nint ConnectedComponentsWithStats(Mat src, Mat labels, Mat stats, Mat centroids,\n    int connectivity, int ltype, int ccltype){\n    return cv::connectedComponentsWithStats(*src, *labels, *stats, *centroids, connectivity, ltype, ccltype);\n}\n\nMat GetStructuringElement(int shape, Size ksize) {\n    cv::Size sz(ksize.width, ksize.height);\n    return new cv::Mat(cv::getStructuringElement(shape, sz));\n}\n\nScalar MorphologyDefaultBorderValue(){\n    cv::Scalar cs = cv::morphologyDefaultBorderValue();\n    return (Scalar){cs[0],cs[1],cs[2],cs[3]};\n}\n\nvoid MorphologyEx(Mat src, Mat dst, int op, Mat kernel) {\n    cv::morphologyEx(*src, *dst, op, *kernel);\n}\n\nvoid MorphologyExWithParams(Mat src, Mat dst, int op, Mat kernel, Point pt, int iterations, int borderType) {\n    cv::Point pt1(pt.x, pt.y);\n    cv::morphologyEx(*src, *dst, op, *kernel, pt1, iterations, borderType);\n}\n\nvoid GaussianBlur(Mat src, Mat dst, Size ps, double sX, double sY, int bt) {\n    cv::Size sz(ps.width, ps.height);\n    cv::GaussianBlur(*src, *dst, sz, sX, sY, bt);\n}\n\nMat GetGaussianKernel(int ksize, double sigma, int ktype){\n    return new cv::Mat(cv::getGaussianKernel(ksize, sigma, ktype));\n}\n\nvoid Laplacian(Mat src, Mat dst, int dDepth, int kSize, double scale, double delta,\n               int borderType) {\n    cv::Laplacian(*src, *dst, dDepth, kSize, scale, delta, borderType);\n}\n\nvoid Scharr(Mat src, Mat dst, int dDepth, int dx, int dy, double scale, double delta,\n            int borderType) {\n    cv::Scharr(*src, *dst, dDepth, dx, dy, scale, delta, borderType);\n}\n\nvoid MedianBlur(Mat src, Mat dst, int ksize) {\n    cv::medianBlur(*src, *dst, ksize);\n}\n\nvoid Canny(Mat src, Mat edges, double t1, double t2) {\n    cv::Canny(*src, *edges, t1, t2);\n}\n\nvoid CornerSubPix(Mat img, Mat corners, Size winSize, Size zeroZone, TermCriteria criteria) {\n    cv::Size wsz(winSize.width, winSize.height);\n    cv::Size zsz(zeroZone.width, zeroZone.height);\n    cv::cornerSubPix(*img, *corners, wsz, zsz, *criteria);\n}\n\nvoid GoodFeaturesToTrack(Mat img, Mat corners, int maxCorners, double quality, double minDist) {\n    cv::goodFeaturesToTrack(*img, *corners, maxCorners, quality, minDist);\n}\n\nvoid GrabCut(Mat img, Mat mask, Rect r, Mat bgdModel, Mat fgdModel, int iterCount, int mode) {\n    cv::Rect cvRect = cv::Rect(r.x, r.y, r.width, r.height);\n    cv::grabCut(*img, *mask, cvRect, *bgdModel, *fgdModel, iterCount, mode);\n}\n\nvoid HoughCircles(Mat src, Mat circles, int method, double dp, double minDist) {\n    cv::HoughCircles(*src, *circles, method, dp, minDist);\n}\n\nvoid HoughCirclesWithParams(Mat src, Mat circles, int method, double dp, double minDist,\n                            double param1, double param2, int minRadius, int maxRadius) {\n    cv::HoughCircles(*src, *circles, method, dp, minDist, param1, param2, minRadius, maxRadius);\n}\n\nvoid HoughLines(Mat src, Mat lines, double rho, double theta, int threshold) {\n    cv::HoughLines(*src, *lines, rho, theta, threshold);\n}\n\nvoid HoughLinesP(Mat src, Mat lines, double rho, double theta, int threshold) {\n    cv::HoughLinesP(*src, *lines, rho, theta, threshold);\n}\n\nvoid HoughLinesPWithParams(Mat src, Mat lines, double rho, double theta, int threshold, double minLineLength, double maxLineGap) {\n    cv::HoughLinesP(*src, *lines, rho, theta, threshold, minLineLength, maxLineGap);\n}\n\nvoid HoughLinesPointSet(Mat points, Mat lines, int linesMax, int threshold,\n                        double minRho, double  maxRho, double rhoStep,\n                        double minTheta, double maxTheta, double thetaStep) {\n    cv::HoughLinesPointSet(*points, *lines, linesMax, threshold,\n                           minRho, maxRho, rhoStep, minTheta, maxTheta, thetaStep );\n}\n\nvoid Integral(Mat src, Mat sum, Mat sqsum, Mat tilted) {\n    cv::integral(*src, *sum, *sqsum, *tilted);\n}\n\ndouble Threshold(Mat src, Mat dst, double thresh, double maxvalue, int typ) {\n    return cv::threshold(*src, *dst, thresh, maxvalue, typ);\n}\n\nvoid AdaptiveThreshold(Mat src, Mat dst, double maxValue, int adaptiveMethod, int thresholdType,\n                       int blockSize, double c) {\n    cv::adaptiveThreshold(*src, *dst, maxValue, adaptiveMethod, thresholdType, blockSize, c);\n}\n\nvoid ArrowedLine(Mat img, Point pt1, Point pt2, Scalar color, int thickness) {\n    cv::Point p1(pt1.x, pt1.y);\n    cv::Point p2(pt2.x, pt2.y);\n    cv::Scalar c = cv::Scalar(color.val1, color.val2, color.val3, color.val4);\n\n    cv::arrowedLine(*img, p1, p2, c, thickness);\n}\n\nbool ClipLine(Size imgSize, Point pt1, Point pt2) {\n\tcv::Size sz(imgSize.width, imgSize.height);\n\tcv::Point p1(pt1.x, pt1.y);\n\tcv::Point p2(pt2.x, pt2.y);\n\n\treturn\tcv::clipLine(sz, p1, p2);\n}\n\nvoid Circle(Mat img, Point center, int radius, Scalar color, int thickness) {\n    cv::Point p1(center.x, center.y);\n    cv::Scalar c = cv::Scalar(color.val1, color.val2, color.val3, color.val4);\n\n    cv::circle(*img, p1, radius, c, thickness);\n}\n\nvoid CircleWithParams(Mat img, Point center, int radius, Scalar color, int thickness, int lineType, int shift) {\n    cv::Point p1(center.x, center.y);\n    cv::Scalar c = cv::Scalar(color.val1, color.val2, color.val3, color.val4);\n\n    cv::circle(*img, p1, radius, c, thickness, lineType, shift);\n}\n\nvoid Ellipse(Mat img, Point center, Point axes, double angle, double\n             startAngle, double endAngle, Scalar color, int thickness) {\n    cv::Point p1(center.x, center.y);\n    cv::Point p2(axes.x, axes.y);\n    cv::Scalar c = cv::Scalar(color.val1, color.val2, color.val3, color.val4);\n\n    cv::ellipse(*img, p1, p2, angle, startAngle, endAngle, c, thickness);\n}\n\nvoid EllipseWithParams(Mat img, Point center, Point axes, double angle, double\n             startAngle, double endAngle, Scalar color, int thickness, int lineType, int shift) {\n    cv::Point p1(center.x, center.y);\n    cv::Point p2(axes.x, axes.y);\n    cv::Scalar c = cv::Scalar(color.val1, color.val2, color.val3, color.val4);\n\n    cv::ellipse(*img, p1, p2, angle, startAngle, endAngle, c, thickness, lineType, shift);\n}\n\nvoid Line(Mat img, Point pt1, Point pt2, Scalar color, int thickness) {\n    cv::Point p1(pt1.x, pt1.y);\n    cv::Point p2(pt2.x, pt2.y);\n    cv::Scalar c = cv::Scalar(color.val1, color.val2, color.val3, color.val4);\n\n    cv::line(*img, p1, p2, c, thickness);\n}\n\nvoid Rectangle(Mat img, Rect r, Scalar color, int thickness) {\n    cv::Scalar c = cv::Scalar(color.val1, color.val2, color.val3, color.val4);\n    cv::rectangle(\n        *img,\n        cv::Point(r.x, r.y),\n        cv::Point(r.x + r.width, r.y + r.height),\n        c,\n        thickness,\n        cv::LINE_AA\n    );\n}\n\nvoid RectangleWithParams(Mat img, Rect r, Scalar color, int thickness, int lineType, int shift) {\n    cv::Scalar c = cv::Scalar(color.val1, color.val2, color.val3, color.val4);\n    cv::rectangle(\n        *img,\n        cv::Point(r.x, r.y),\n        cv::Point(r.x + r.width, r.y + r.height),\n        c,\n        thickness,\n        lineType,\n        shift\n    );\n}\n\nvoid FillPoly(Mat img, PointsVector pts, Scalar color) {\n    cv::Scalar c = cv::Scalar(color.val1, color.val2, color.val3, color.val4);\n\n    cv::fillPoly(*img, *pts, c);\n}\n\nvoid FillPolyWithParams(Mat img, PointsVector pts, Scalar color, int lineType, int shift, Point offset) {\n    cv::Scalar c = cv::Scalar(color.val1, color.val2, color.val3, color.val4);\n\n    cv::fillPoly(*img, *pts, c, lineType, shift, cv::Point(offset.x, offset.y));\n}\n\nvoid Polylines(Mat img, PointsVector pts, bool isClosed, Scalar color,int thickness) {\n    cv::Scalar c = cv::Scalar(color.val1, color.val2, color.val3, color.val4);\n\n    cv::polylines(*img, *pts, isClosed, c, thickness);\n}\n\nstruct Size GetTextSize(const char* text, int fontFace, double fontScale, int thickness) {\n    return GetTextSizeWithBaseline(text, fontFace, fontScale, thickness, NULL);\n}\n\nstruct Size GetTextSizeWithBaseline(const char* text, int fontFace, double fontScale, int thickness, int* baesline) {\n    cv::Size sz = cv::getTextSize(text, fontFace, fontScale, thickness, baesline);\n    Size size = {sz.width, sz.height};\n    return size;\n}\n\nvoid PutText(Mat img, const char* text, Point org, int fontFace, double fontScale,\n             Scalar color, int thickness) {\n    cv::Point pt(org.x, org.y);\n    cv::Scalar c = cv::Scalar(color.val1, color.val2, color.val3, color.val4);\n    cv::putText(*img, text, pt, fontFace, fontScale, c, thickness);\n}\n\nvoid PutTextWithParams(Mat img, const char* text, Point org, int fontFace, double fontScale,\n                       Scalar color, int thickness, int lineType, bool bottomLeftOrigin) {\n    cv::Point pt(org.x, org.y);\n    cv::Scalar c = cv::Scalar(color.val1, color.val2, color.val3, color.val4);\n    cv::putText(*img, text, pt, fontFace, fontScale, c, thickness, lineType, bottomLeftOrigin);\n}\n\nvoid Resize(Mat src, Mat dst, Size dsize, double fx, double fy, int interp) {\n    cv::Size sz(dsize.width, dsize.height);\n    cv::resize(*src, *dst, sz, fx, fy, interp);\n}\n\nvoid GetRectSubPix(Mat src, Size patchSize, Point center, Mat dst) {\n    cv::Size sz(patchSize.width, patchSize.height);\n    cv::Point pt(center.x, center.y);\n    cv::getRectSubPix(*src, sz, pt, *dst);\n}\n\nMat GetRotationMatrix2D(Point center, double angle, double scale) {\n    cv::Point pt(center.x, center.y);\n    return new  cv::Mat(cv::getRotationMatrix2D(pt, angle, scale));\n}\n\nvoid WarpAffine(Mat src, Mat dst, Mat m, Size dsize) {\n    cv::Size sz(dsize.width, dsize.height);\n    cv::warpAffine(*src, *dst, *m, sz);\n}\n\nvoid WarpAffineWithParams(Mat src, Mat dst, Mat rot_mat, Size dsize, int flags, int borderMode,\n                          Scalar borderValue) {\n    cv::Size sz(dsize.width, dsize.height);\n    cv::Scalar c = cv::Scalar(borderValue.val1, borderValue.val2, borderValue.val3, borderValue.val4);\n    cv::warpAffine(*src, *dst, *rot_mat, sz, flags, borderMode, c);\n}\n\nvoid WarpPerspective(Mat src, Mat dst, Mat m, Size dsize) {\n    cv::Size sz(dsize.width, dsize.height);\n    cv::warpPerspective(*src, *dst, *m, sz);\n}\n\nvoid WarpPerspectiveWithParams(Mat src, Mat dst, Mat rot_mat, Size dsize, int flags, int borderMode,\n                               Scalar borderValue) {\n    cv::Size sz(dsize.width, dsize.height);\n    cv::Scalar c = cv::Scalar(borderValue.val1, borderValue.val2, borderValue.val3, borderValue.val4);\n    cv::warpPerspective(*src, *dst, *rot_mat, sz, flags, borderMode, c);\n}\n\nvoid Watershed(Mat image, Mat markers) {\n    cv::watershed(*image, *markers);\n}\n\nvoid ApplyColorMap(Mat src, Mat dst, int colormap) {\n    cv::applyColorMap(*src, *dst, colormap);\n}\n\nvoid ApplyCustomColorMap(Mat src, Mat dst, Mat colormap) {\n    cv::applyColorMap(*src, *dst, *colormap);\n}\n\nMat GetPerspectiveTransform(PointVector src, PointVector dst) {\n    std::vector<cv::Point2f> src_pts;\n    copyPointVectorToPoint2fVector(src, &src_pts);\n\n    std::vector<cv::Point2f> dst_pts;\n    copyPointVectorToPoint2fVector(dst, &dst_pts);\n\n    return new cv::Mat(cv::getPerspectiveTransform(src_pts, dst_pts));\n}\n\nMat GetPerspectiveTransform2f(Point2fVector src, Point2fVector dst) {\n    return new cv::Mat(cv::getPerspectiveTransform(*src, *dst));\n}\n\nMat GetAffineTransform(PointVector src, PointVector dst) {\n    std::vector<cv::Point2f> src_pts;\n    copyPointVectorToPoint2fVector(src, &src_pts);\n\n    std::vector<cv::Point2f> dst_pts;\n    copyPointVectorToPoint2fVector(dst, &dst_pts);\n\n    return new cv::Mat(cv::getAffineTransform(src_pts, dst_pts));\n}\n\nMat GetAffineTransform2f(Point2fVector src, Point2fVector dst) {\n    return new cv::Mat(cv::getAffineTransform(*src, *dst));\n}\n\nMat FindHomography(Mat src, Mat dst, int method, double ransacReprojThreshold, Mat mask, const int maxIters, const double confidence) {\n    return new cv::Mat(cv::findHomography(*src, *dst, method, ransacReprojThreshold, *mask, maxIters, confidence));\n}\n\nvoid DrawContours(Mat src, PointsVector contours, int contourIdx, Scalar color, int thickness) {\n    cv::Scalar c = cv::Scalar(color.val1, color.val2, color.val3, color.val4);\n    cv::drawContours(*src, *contours, contourIdx, c, thickness);\n}\n\nvoid DrawContoursWithParams(Mat src, PointsVector contours, int contourIdx, Scalar color, int thickness, int lineType, Mat hierarchy, int maxLevel, Point offset) {\n    cv::Scalar c = cv::Scalar(color.val1, color.val2, color.val3, color.val4);\n    cv::Point offsetPt(offset.x, offset.y);\n\n    std::vector<cv::Vec4i> vecHierarchy;\n    if (hierarchy->empty() == 0) {\n        for (int j = 0; j < hierarchy->cols; ++j) {\n            vecHierarchy.push_back(hierarchy->at<cv::Vec4i>(0, j));\n        }\n    }\n    cv::drawContours(*src, *contours, contourIdx, c, thickness, lineType, vecHierarchy, maxLevel, offsetPt);\n}\n\nvoid Sobel(Mat src, Mat dst, int ddepth, int dx, int dy, int ksize, double scale, double delta, int borderType) {\n\tcv::Sobel(*src, *dst, ddepth, dx, dy, ksize, scale, delta, borderType);\n}\n\nvoid SpatialGradient(Mat src, Mat dx, Mat dy, int ksize, int borderType) {\n\tcv::spatialGradient(*src, *dx, *dy, ksize, borderType);\n}\n\n\nvoid Remap(Mat src, Mat dst, Mat map1, Mat map2, int interpolation, int borderMode, Scalar borderValue) {\n        cv::Scalar c = cv::Scalar(borderValue.val1, borderValue.val2, borderValue.val3, borderValue.val4);\n        cv::remap(*src, *dst, *map1, *map2, interpolation, borderMode, c);\n}\n\nvoid Filter2D(Mat src, Mat dst, int ddepth, Mat kernel, Point anchor, double delta, int borderType) {\n        cv::Point anchorPt(anchor.x, anchor.y);\n        cv::filter2D(*src, *dst, ddepth, *kernel, anchorPt, delta, borderType);\n}\n\nvoid SepFilter2D(Mat src, Mat dst, int ddepth, Mat kernelX, Mat kernelY, Point anchor, double delta, int borderType) {\n\tcv::Point anchorPt(anchor.x, anchor.y);\n\tcv::sepFilter2D(*src, *dst, ddepth, *kernelX, *kernelY, anchorPt, delta, borderType);\n}\n\nvoid LogPolar(Mat src, Mat dst, Point center, double m, int flags) {\n\tcv::Point2f centerPt(center.x, center.y);\n\tcv::logPolar(*src, *dst, centerPt, m, flags);\n}\n\nvoid FitLine(PointVector pts, Mat line, int distType, double param, double reps, double aeps) {\n\tcv::fitLine(*pts, *line, distType, param, reps, aeps);\n}\n\nvoid LinearPolar(Mat src, Mat dst, Point center, double maxRadius, int flags) {\n\tcv::Point2f centerPt(center.x, center.y);\n\tcv::linearPolar(*src, *dst, centerPt, maxRadius, flags);\n}\n\ndouble MatchShapes(PointVector contour1, PointVector contour2, int method, double parameter) {\n    return cv::matchShapes(*contour1, *contour2, method, parameter);\n}\n\nCLAHE CLAHE_Create() {\n    return new cv::Ptr<cv::CLAHE>(cv::createCLAHE());\n}\n\nCLAHE CLAHE_CreateWithParams(double clipLimit, Size tileGridSize) {\n    cv::Size sz(tileGridSize.width, tileGridSize.height);\n    return new cv::Ptr<cv::CLAHE>(cv::createCLAHE(clipLimit, sz));\n}\n\nvoid CLAHE_Close(CLAHE c) {\n    delete c;\n}\n\nvoid CLAHE_Apply(CLAHE c, Mat src, Mat dst) {\n    (*c)->apply(*src, *dst);\n}\n\nvoid InvertAffineTransform(Mat src, Mat dst) {\n\tcv::invertAffineTransform(*src, *dst);\n}\n\nPoint2f PhaseCorrelate(Mat src1, Mat src2, Mat window, double* response) {\n    cv::Point2d result = cv::phaseCorrelate(*src1, *src2, *window, response);\n\n    Point2f result2f = {\n        .x = float(result.x),\n        .y = float(result.y),\n    };\n    return result2f;\n}\n\nvoid CreateHanningWindow(Mat dst, Size size, int typ) {\n    cv::Size sz(size.width, size.height);\n    cv::createHanningWindow(*dst, sz, typ);\n}\n\nvoid Mat_Accumulate(Mat src, Mat dst) {\n    cv::accumulate(*src, *dst);\n}\nvoid Mat_AccumulateWithMask(Mat src, Mat dst, Mat mask) {\n    cv::accumulate(*src, *dst, *mask);\n}\n\nvoid Mat_AccumulateSquare(Mat src, Mat dst) {\n    cv::accumulateSquare(*src, *dst);\n}\n\nvoid Mat_AccumulateSquareWithMask(Mat src, Mat dst, Mat mask) {\n    cv::accumulateSquare(*src, *dst, *mask);\n}\n\nvoid Mat_AccumulateProduct(Mat src1, Mat src2, Mat dst) {\n    cv::accumulateProduct(*src1, *src2, *dst);\n}\n\nvoid Mat_AccumulateProductWithMask(Mat src1, Mat src2, Mat dst, Mat mask) {\n    cv::accumulateProduct(*src1, *src2, *dst, *mask);\n}\n\nvoid Mat_AccumulatedWeighted(Mat src, Mat dst, double alpha) {\n    cv::accumulateWeighted(*src, *dst, alpha);\n}\n\nvoid Mat_AccumulatedWeightedWithMask(Mat src, Mat dst, double alpha, Mat mask) {\n    cv::accumulateWeighted(*src, *dst, alpha, *mask);\n}\n"
        },
        {
          "name": "imgproc.go",
          "type": "blob",
          "size": 78.7978515625,
          "content": "package gocv\n\n/*\n#include <stdlib.h>\n#include \"imgproc.h\"\n*/\nimport \"C\"\nimport (\n\t\"errors\"\n\t\"image\"\n\t\"image/color\"\n\t\"reflect\"\n\t\"unsafe\"\n)\n\n// ArcLength calculates a contour perimeter or a curve length.\n//\n// For further details, please see:\n//\n// https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#ga8d26483c636be6b35c3ec6335798a47c\nfunc ArcLength(curve PointVector, isClosed bool) float64 {\n\treturn float64(C.ArcLength(curve.p, C.bool(isClosed)))\n}\n\n// ApproxPolyDP approximates a polygonal curve(s) with the specified precision.\n//\n// For further details, please see:\n//\n// https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#ga0012a5fdaea70b8a9970165d98722b4c\nfunc ApproxPolyDP(curve PointVector, epsilon float64, closed bool) PointVector {\n\treturn PointVector{p: C.ApproxPolyDP(curve.p, C.double(epsilon), C.bool(closed))}\n}\n\n// ConvexHull finds the convex hull of a point set.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#ga014b28e56cb8854c0de4a211cb2be656\nfunc ConvexHull(points PointVector, hull *Mat, clockwise bool, returnPoints bool) {\n\tC.ConvexHull(points.p, hull.p, C.bool(clockwise), C.bool(returnPoints))\n}\n\n// ConvexityDefects finds the convexity defects of a contour.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#gada4437098113fd8683c932e0567f47ba\nfunc ConvexityDefects(contour PointVector, hull Mat, result *Mat) {\n\tC.ConvexityDefects(contour.p, hull.p, result.p)\n}\n\n// CvtColor converts an image from one color space to another.\n// It converts the src Mat image to the dst Mat using the\n// code param containing the desired ColorConversionCode color space.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d7/d1b/group__imgproc__misc.html#ga4e0972be5de079fed4e3a10e24ef5ef0\nfunc CvtColor(src Mat, dst *Mat, code ColorConversionCode) {\n\tC.CvtColor(src.p, dst.p, C.int(code))\n}\n\n// Demosaicing converts an image from Bayer pattern to RGB or grayscale.\n// It converts the src Mat image to the dst Mat using the\n// code param containing the desired ColorConversionCode color space.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/d1b/group__imgproc__color__conversions.html#ga57261f12fccf872a2b2d66daf29d5bd0\nfunc Demosaicing(src Mat, dst *Mat, code ColorConversionCode) {\n\tC.Demosaicing(src.p, dst.p, C.int(code))\n}\n\n// EqualizeHist normalizes the brightness and increases the contrast of the image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/dc7/group__imgproc__hist.html#ga7e54091f0c937d49bf84152a16f76d6e\nfunc EqualizeHist(src Mat, dst *Mat) {\n\tC.EqualizeHist(src.p, dst.p)\n}\n\n// CalcHist Calculates a histogram of a set of images\n//\n// For futher details, please see:\n// https://docs.opencv.org/master/d6/dc7/group__imgproc__hist.html#ga6ca1876785483836f72a77ced8ea759a\nfunc CalcHist(src []Mat, channels []int, mask Mat, hist *Mat, size []int, ranges []float64, acc bool) {\n\tcMatArray := make([]C.Mat, len(src))\n\tfor i, r := range src {\n\t\tcMatArray[i] = r.p\n\t}\n\n\tcMats := C.struct_Mats{\n\t\tmats:   (*C.Mat)(&cMatArray[0]),\n\t\tlength: C.int(len(src)),\n\t}\n\n\tchansInts := []C.int{}\n\tfor _, v := range channels {\n\t\tchansInts = append(chansInts, C.int(v))\n\t}\n\tchansVector := C.struct_IntVector{}\n\tchansVector.val = (*C.int)(&chansInts[0])\n\tchansVector.length = (C.int)(len(chansInts))\n\n\tsizeInts := []C.int{}\n\tfor _, v := range size {\n\t\tsizeInts = append(sizeInts, C.int(v))\n\t}\n\tsizeVector := C.struct_IntVector{}\n\tsizeVector.val = (*C.int)(&sizeInts[0])\n\tsizeVector.length = (C.int)(len(sizeInts))\n\n\trangeFloats := []C.float{}\n\tfor _, v := range ranges {\n\t\trangeFloats = append(rangeFloats, C.float(v))\n\t}\n\trangeVector := C.struct_FloatVector{}\n\trangeVector.val = (*C.float)(&rangeFloats[0])\n\trangeVector.length = (C.int)(len(rangeFloats))\n\n\tC.CalcHist(cMats, chansVector, mask.p, hist.p, sizeVector, rangeVector, C.bool(acc))\n}\n\n// CalcBackProject calculates the back projection of a histogram.\n//\n// For futher details, please see:\n// https://docs.opencv.org/3.4/d6/dc7/group__imgproc__hist.html#ga3a0af640716b456c3d14af8aee12e3ca\nfunc CalcBackProject(src []Mat, channels []int, hist Mat, backProject *Mat, ranges []float64, uniform bool) {\n\tcMatArray := make([]C.Mat, len(src))\n\tfor i, r := range src {\n\t\tcMatArray[i] = r.p\n\t}\n\n\tcMats := C.struct_Mats{\n\t\tmats:   (*C.Mat)(&cMatArray[0]),\n\t\tlength: C.int(len(src)),\n\t}\n\n\tchansInts := []C.int{}\n\tfor _, v := range channels {\n\t\tchansInts = append(chansInts, C.int(v))\n\t}\n\tchansVector := C.struct_IntVector{}\n\tchansVector.val = (*C.int)(&chansInts[0])\n\tchansVector.length = (C.int)(len(chansInts))\n\n\trangeFloats := []C.float{}\n\tfor _, v := range ranges {\n\t\trangeFloats = append(rangeFloats, C.float(v))\n\t}\n\trangeVector := C.struct_FloatVector{}\n\trangeVector.val = (*C.float)(&rangeFloats[0])\n\trangeVector.length = (C.int)(len(rangeFloats))\n\n\tC.CalcBackProject(cMats, chansVector, hist.p, backProject.p, rangeVector, C.bool(uniform))\n}\n\n// HistCompMethod is the method for Histogram comparison\n// For more information, see https://docs.opencv.org/master/d6/dc7/group__imgproc__hist.html#ga994f53817d621e2e4228fc646342d386\ntype HistCompMethod int\n\nconst (\n\t// HistCmpCorrel calculates the Correlation\n\tHistCmpCorrel HistCompMethod = 0\n\n\t// HistCmpChiSqr calculates the Chi-Square\n\tHistCmpChiSqr HistCompMethod = 1\n\n\t// HistCmpIntersect calculates the Intersection\n\tHistCmpIntersect HistCompMethod = 2\n\n\t// HistCmpBhattacharya applies the HistCmpBhattacharya by calculating the Bhattacharya distance.\n\tHistCmpBhattacharya HistCompMethod = 3\n\n\t// HistCmpHellinger applies the HistCmpBhattacharya comparison. It is a synonym to HistCmpBhattacharya.\n\tHistCmpHellinger = HistCmpBhattacharya\n\n\t// HistCmpChiSqrAlt applies the Alternative Chi-Square (regularly used for texture comparsion).\n\tHistCmpChiSqrAlt HistCompMethod = 4\n\n\t// HistCmpKlDiv applies the Kullback-Liebler divergence comparison.\n\tHistCmpKlDiv HistCompMethod = 5\n)\n\n// CompareHist Compares two histograms.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/dc7/group__imgproc__hist.html#gaf4190090efa5c47cb367cf97a9a519bd\nfunc CompareHist(hist1 Mat, hist2 Mat, method HistCompMethod) float32 {\n\treturn float32(C.CompareHist(hist1.p, hist2.p, C.int(method)))\n}\n\n// EMD Computes the \"minimal work\" distance between two weighted point configurations.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d6/dc7/group__imgproc__hist.html#ga902b8e60cc7075c8947345489221e0e0\nfunc EMD(signature1, signature2 Mat, typ DistanceTypes) float32 {\n\treturn float32(C.EMD(signature1.p, signature2.p, C.int(typ)))\n}\n\n// ClipLine clips the line against the image rectangle.\n// For further details, please see:\n// https://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#gaf483cb46ad6b049bc35ec67052ef1c2c\nfunc ClipLine(imgSize image.Point, pt1 image.Point, pt2 image.Point) bool {\n\tpSize := C.struct_Size{\n\t\twidth:  C.int(imgSize.X),\n\t\theight: C.int(imgSize.Y),\n\t}\n\n\trPt1 := C.struct_Point{\n\t\tx: C.int(pt1.X),\n\t\ty: C.int(pt1.Y),\n\t}\n\n\trPt2 := C.struct_Point{\n\t\tx: C.int(pt2.X),\n\t\ty: C.int(pt2.Y),\n\t}\n\n\treturn bool(C.ClipLine(pSize, rPt1, rPt2))\n}\n\n// BilateralFilter applies a bilateral filter to an image.\n//\n// Bilateral filtering is described here:\n// http://www.dai.ed.ac.uk/CVonline/LOCAL_COPIES/MANDUCHI1/Bilateral_Filtering.html\n//\n// BilateralFilter can reduce unwanted noise very well while keeping edges\n// fairly sharp. However, it is very slow compared to most filters.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga9d7064d478c95d60003cf839430737ed\nfunc BilateralFilter(src Mat, dst *Mat, diameter int, sigmaColor float64, sigmaSpace float64) {\n\tC.BilateralFilter(src.p, dst.p, C.int(diameter), C.double(sigmaColor), C.double(sigmaSpace))\n}\n\n// Blur blurs an image Mat using a normalized box filter.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga8c45db9afe636703801b0b2e440fce37\nfunc Blur(src Mat, dst *Mat, ksize image.Point) {\n\tpSize := C.struct_Size{\n\t\twidth:  C.int(ksize.X),\n\t\theight: C.int(ksize.Y),\n\t}\n\n\tC.Blur(src.p, dst.p, pSize)\n}\n\n// BoxFilter blurs an image using the box filter.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gad533230ebf2d42509547d514f7d3fbc3\nfunc BoxFilter(src Mat, dst *Mat, depth int, ksize image.Point) {\n\tpSize := C.struct_Size{\n\t\theight: C.int(ksize.X),\n\t\twidth:  C.int(ksize.Y),\n\t}\n\tC.BoxFilter(src.p, dst.p, C.int(depth), pSize)\n}\n\n// SqBoxFilter calculates the normalized sum of squares of the pixel values overlapping the filter.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga045028184a9ef65d7d2579e5c4bff6c0\nfunc SqBoxFilter(src Mat, dst *Mat, depth int, ksize image.Point) {\n\tpSize := C.struct_Size{\n\t\theight: C.int(ksize.X),\n\t\twidth:  C.int(ksize.Y),\n\t}\n\tC.SqBoxFilter(src.p, dst.p, C.int(depth), pSize)\n}\n\n// Dilate dilates an image by using a specific structuring element.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga4ff0f3318642c4f469d0e11f242f3b6c\nfunc Dilate(src Mat, dst *Mat, kernel Mat) {\n\tC.Dilate(src.p, dst.p, kernel.p)\n}\n\n// DilateWithParams dilates an image by using a specific structuring element.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga4ff0f3318642c4f469d0e11f242f3b6c\nfunc DilateWithParams(src Mat, dst *Mat, kernel Mat, anchor image.Point, iterations, borderType BorderType, borderValue color.RGBA) {\n\tcAnchor := C.struct_Point{\n\t\tx: C.int(anchor.X),\n\t\ty: C.int(anchor.Y),\n\t}\n\n\tbv := C.struct_Scalar{\n\t\tval1: C.double(borderValue.B),\n\t\tval2: C.double(borderValue.G),\n\t\tval3: C.double(borderValue.R),\n\t\tval4: C.double(borderValue.A),\n\t}\n\n\tC.DilateWithParams(src.p, dst.p, kernel.p, cAnchor, C.int(iterations), C.int(borderType), bv)\n}\n\n// DistanceTransformLabelTypes are the types of the DistanceTransform algorithm flag\ntype DistanceTransformLabelTypes int\n\nconst (\n\t// DistanceLabelCComp assigns the same label to each connected component of zeros in the source image\n\t// (as well as all the non-zero pixels closest to the connected component).\n\tDistanceLabelCComp DistanceTransformLabelTypes = 0\n\n\t// DistanceLabelPixel assigns its own label to each zero pixel (and all the non-zero pixels closest to it).\n\tDistanceLabelPixel\n)\n\n// DistanceTransformMasks are the marsk sizes for distance transform\ntype DistanceTransformMasks int\n\nconst (\n\t// DistanceMask3 is a mask of size 3\n\tDistanceMask3 DistanceTransformMasks = 0\n\n\t// DistanceMask5 is a mask of size 3\n\tDistanceMask5\n\n\t// DistanceMaskPrecise is not currently supported\n\tDistanceMaskPrecise\n)\n\n// DistanceTransform Calculates the distance to the closest zero pixel for each pixel of the source image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/d1b/group__imgproc__misc.html#ga8a0b7fdfcb7a13dde018988ba3a43042\nfunc DistanceTransform(src Mat, dst *Mat, labels *Mat, distType DistanceTypes, maskSize DistanceTransformMasks, labelType DistanceTransformLabelTypes) {\n\tC.DistanceTransform(src.p, dst.p, labels.p, C.int(distType), C.int(maskSize), C.int(labelType))\n}\n\n// Erode erodes an image by using a specific structuring element.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gaeb1e0c1033e3f6b891a25d0511362aeb\nfunc Erode(src Mat, dst *Mat, kernel Mat) {\n\tC.Erode(src.p, dst.p, kernel.p)\n}\n\n// ErodeWithParams erodes an image by using a specific structuring element.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gaeb1e0c1033e3f6b891a25d0511362aeb\nfunc ErodeWithParams(src Mat, dst *Mat, kernel Mat, anchor image.Point, iterations, borderType int) {\n\tcAnchor := C.struct_Point{\n\t\tx: C.int(anchor.X),\n\t\ty: C.int(anchor.Y),\n\t}\n\n\tC.ErodeWithParams(src.p, dst.p, kernel.p, cAnchor, C.int(iterations), C.int(borderType))\n}\n\n// ErodeWithParamsAndBorderValue erodes an image by using a specific structuring\n// element. Same as ErodeWithParams but requires an additional borderValue\n// parameter.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gaeb1e0c1033e3f6b891a25d0511362aeb\nfunc ErodeWithParamsAndBorderValue(src Mat, dst *Mat, kernel Mat, anchor image.Point, iterations, borderType int, borderValue Scalar) {\n\tcAnchor := C.struct_Point{\n\t\tx: C.int(anchor.X),\n\t\ty: C.int(anchor.Y),\n\t}\n\n\tbv := C.struct_Scalar{\n\t\tval1: C.double(borderValue.Val1),\n\t\tval2: C.double(borderValue.Val2),\n\t\tval3: C.double(borderValue.Val3),\n\t\tval4: C.double(borderValue.Val4),\n\t}\n\n\tC.ErodeWithParamsAndBorderValue(src.p, dst.p, kernel.p, cAnchor, C.int(iterations), C.int(borderType), bv)\n}\n\n// RetrievalMode is the mode of the contour retrieval algorithm.\ntype RetrievalMode int\n\nconst (\n\t// RetrievalExternal retrieves only the extreme outer contours.\n\t// It sets `hierarchy[i][2]=hierarchy[i][3]=-1` for all the contours.\n\tRetrievalExternal RetrievalMode = 0\n\n\t// RetrievalList retrieves all of the contours without establishing\n\t// any hierarchical relationships.\n\tRetrievalList RetrievalMode = 1\n\n\t// RetrievalCComp retrieves all of the contours and organizes them into\n\t// a two-level hierarchy. At the top level, there are external boundaries\n\t// of the components. At the second level, there are boundaries of the holes.\n\t// If there is another contour inside a hole of a connected component, it\n\t// is still put at the top level.\n\tRetrievalCComp RetrievalMode = 2\n\n\t// RetrievalTree retrieves all of the contours and reconstructs a full\n\t// hierarchy of nested contours.\n\tRetrievalTree RetrievalMode = 3\n\n\t// RetrievalFloodfill lacks a description in the original header.\n\tRetrievalFloodfill RetrievalMode = 4\n)\n\n// ContourApproximationMode is the mode of the contour approximation algorithm.\ntype ContourApproximationMode int\n\nconst (\n\t// ChainApproxNone stores absolutely all the contour points. That is,\n\t// any 2 subsequent points (x1,y1) and (x2,y2) of the contour will be\n\t// either horizontal, vertical or diagonal neighbors, that is,\n\t// max(abs(x1-x2),abs(y2-y1))==1.\n\tChainApproxNone ContourApproximationMode = 1\n\n\t// ChainApproxSimple compresses horizontal, vertical, and diagonal segments\n\t// and leaves only their end points.\n\t// For example, an up-right rectangular contour is encoded with 4 points.\n\tChainApproxSimple ContourApproximationMode = 2\n\n\t// ChainApproxTC89L1 applies one of the flavors of the Teh-Chin chain\n\t// approximation algorithms.\n\tChainApproxTC89L1 ContourApproximationMode = 3\n\n\t// ChainApproxTC89KCOS applies one of the flavors of the Teh-Chin chain\n\t// approximation algorithms.\n\tChainApproxTC89KCOS ContourApproximationMode = 4\n)\n\n// BoundingRect calculates the up-right bounding rectangle of a point set.\n//\n// For further details, please see:\n// https://docs.opencv.org/3.3.0/d3/dc0/group__imgproc__shape.html#gacb413ddce8e48ff3ca61ed7cf626a366\nfunc BoundingRect(contour PointVector) image.Rectangle {\n\tr := C.BoundingRect(contour.p)\n\trect := image.Rect(int(r.x), int(r.y), int(r.x+r.width), int(r.y+r.height))\n\treturn rect\n}\n\n// BoxPoints finds the four vertices of a rotated rect. Useful to draw the rotated rectangle.\n//\n// For further Details, please see:\n// https://docs.opencv.org/3.3.0/d3/dc0/group__imgproc__shape.html#gaf78d467e024b4d7936cf9397185d2f5c\nfunc BoxPoints(rect RotatedRect, pts *Mat) {\n\trPoints := toCPoints(rect.Points)\n\n\trRect := C.struct_Rect{\n\t\tx:      C.int(rect.BoundingRect.Min.X),\n\t\ty:      C.int(rect.BoundingRect.Min.Y),\n\t\twidth:  C.int(rect.BoundingRect.Max.X - rect.BoundingRect.Min.X),\n\t\theight: C.int(rect.BoundingRect.Max.Y - rect.BoundingRect.Min.Y),\n\t}\n\n\trCenter := C.struct_Point{\n\t\tx: C.int(rect.Center.X),\n\t\ty: C.int(rect.Center.Y),\n\t}\n\n\trSize := C.struct_Size{\n\t\twidth:  C.int(rect.Width),\n\t\theight: C.int(rect.Height),\n\t}\n\n\tr := C.struct_RotatedRect{\n\t\tpts:          rPoints,\n\t\tboundingRect: rRect,\n\t\tcenter:       rCenter,\n\t\tsize:         rSize,\n\t\tangle:        C.double(rect.Angle),\n\t}\n\n\tC.BoxPoints(r, pts.p)\n}\n\n// BoxPoints finds the four vertices of a rotated rect. Useful to draw the rotated rectangle.\n//\n// For further Details, please see:\n// https://docs.opencv.org/3.3.0/d3/dc0/group__imgproc__shape.html#gaf78d467e024b4d7936cf9397185d2f5c\nfunc BoxPoints2f(rect RotatedRect2f, pts *Mat) {\n\trPoints := toCPoints2f(rect.Points)\n\n\trRect := C.struct_Rect{\n\t\tx:      C.int(rect.BoundingRect.Min.X),\n\t\ty:      C.int(rect.BoundingRect.Min.Y),\n\t\twidth:  C.int(rect.BoundingRect.Max.X - rect.BoundingRect.Min.X),\n\t\theight: C.int(rect.BoundingRect.Max.Y - rect.BoundingRect.Min.Y),\n\t}\n\n\trCenter := C.struct_Point2f{\n\t\tx: C.float(rect.Center.X),\n\t\ty: C.float(rect.Center.Y),\n\t}\n\n\trSize := C.struct_Size2f{\n\t\twidth:  C.float(rect.Width),\n\t\theight: C.float(rect.Height),\n\t}\n\n\tr := C.struct_RotatedRect2f{\n\t\tpts:          rPoints,\n\t\tboundingRect: rRect,\n\t\tcenter:       rCenter,\n\t\tsize:         rSize,\n\t\tangle:        C.double(rect.Angle),\n\t}\n\n\tC.BoxPoints2f(r, pts.p)\n}\n\n// ContourArea calculates a contour area.\n//\n// For further details, please see:\n// https://docs.opencv.org/3.3.0/d3/dc0/group__imgproc__shape.html#ga2c759ed9f497d4a618048a2f56dc97f1\nfunc ContourArea(contour PointVector) float64 {\n\tresult := C.ContourArea(contour.p)\n\treturn float64(result)\n}\n\ntype RotatedRect struct {\n\tPoints       []image.Point\n\tBoundingRect image.Rectangle\n\tCenter       image.Point\n\tWidth        int\n\tHeight       int\n\tAngle        float64\n}\n\ntype RotatedRect2f struct {\n\tPoints       []Point2f\n\tBoundingRect image.Rectangle\n\tCenter       Point2f\n\tWidth        float32\n\tHeight       float32\n\tAngle        float64\n}\n\n// toPoints converts C.Contour to []image.Points\nfunc toPoints(points C.Contour) []image.Point {\n\tpArray := points.points\n\tpLength := int(points.length)\n\n\tpHdr := reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(pArray)),\n\t\tLen:  pLength,\n\t\tCap:  pLength,\n\t}\n\tsPoints := *(*[]C.Point)(unsafe.Pointer(&pHdr))\n\n\tpoints4 := make([]image.Point, pLength)\n\tfor j, pt := range sPoints {\n\t\tpoints4[j] = image.Pt(int(pt.x), int(pt.y))\n\t}\n\treturn points4\n}\n\n// toPoints2f converts C.Contour2f to []Point2f\nfunc toPoints2f(points C.Contour2f) []Point2f {\n\tpArray := points.points\n\tpLength := int(points.length)\n\n\tpHdr := reflect.SliceHeader{\n\t\tData: uintptr(unsafe.Pointer(pArray)),\n\t\tLen:  pLength,\n\t\tCap:  pLength,\n\t}\n\tsPoints := *(*[]C.Point)(unsafe.Pointer(&pHdr))\n\n\tpoints4 := make([]Point2f, pLength)\n\tfor j, pt := range sPoints {\n\t\tpoints4[j] = NewPoint2f(float32(pt.x), float32(pt.y))\n\t}\n\treturn points4\n}\n\n// MinAreaRect finds a rotated rectangle of the minimum area enclosing the input 2D point set.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#ga3d476a3417130ae5154aea421ca7ead9\nfunc MinAreaRect(points PointVector) RotatedRect {\n\tresult := C.MinAreaRect(points.p)\n\tdefer C.Points_Close(result.pts)\n\n\treturn RotatedRect{\n\t\tPoints:       toPoints(result.pts),\n\t\tBoundingRect: image.Rect(int(result.boundingRect.x), int(result.boundingRect.y), int(result.boundingRect.x)+int(result.boundingRect.width), int(result.boundingRect.y)+int(result.boundingRect.height)),\n\t\tCenter:       image.Pt(int(result.center.x), int(result.center.y)),\n\t\tWidth:        int(result.size.width),\n\t\tHeight:       int(result.size.height),\n\t\tAngle:        float64(result.angle),\n\t}\n}\n\n// MinAreaRect finds a rotated rectangle of the minimum area enclosing the input 2D point set.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#ga3d476a3417130ae5154aea421ca7ead9\nfunc MinAreaRect2f(points PointVector) RotatedRect2f {\n\tresult := C.MinAreaRect2f(points.p)\n\tdefer C.Points2f_Close(result.pts)\n\n\treturn RotatedRect2f{\n\t\tPoints:       toPoints2f(result.pts),\n\t\tBoundingRect: image.Rect(int(result.boundingRect.x), int(result.boundingRect.y), int(result.boundingRect.x)+int(result.boundingRect.width), int(result.boundingRect.y)+int(result.boundingRect.height)),\n\t\tCenter:       NewPoint2f(float32(result.center.x), float32(result.center.y)),\n\t\tWidth:        float32(result.size.width),\n\t\tHeight:       float32(result.size.height),\n\t\tAngle:        float64(result.angle),\n\t}\n}\n\n// FitEllipse Fits an ellipse around a set of 2D points.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#gaf259efaad93098103d6c27b9e4900ffa\nfunc FitEllipse(pts PointVector) RotatedRect {\n\tcRect := C.FitEllipse(pts.p)\n\tdefer C.Points_Close(cRect.pts)\n\n\treturn RotatedRect{\n\t\tPoints:       toPoints(cRect.pts),\n\t\tBoundingRect: image.Rect(int(cRect.boundingRect.x), int(cRect.boundingRect.y), int(cRect.boundingRect.x)+int(cRect.boundingRect.width), int(cRect.boundingRect.y)+int(cRect.boundingRect.height)),\n\t\tCenter:       image.Pt(int(cRect.center.x), int(cRect.center.y)),\n\t\tWidth:        int(cRect.size.width),\n\t\tHeight:       int(cRect.size.height),\n\t\tAngle:        float64(cRect.angle),\n\t}\n\n}\n\n// MinEnclosingCircle finds a circle of the minimum area enclosing the input 2D point set.\n//\n// For further details, please see:\n// https://docs.opencv.org/3.4/d3/dc0/group__imgproc__shape.html#ga8ce13c24081bbc7151e9326f412190f1\nfunc MinEnclosingCircle(pts PointVector) (x, y, radius float32) {\n\tcCenterPoint := C.struct_Point2f{}\n\tvar cRadius C.float\n\tC.MinEnclosingCircle(pts.p, &cCenterPoint, &cRadius)\n\tx, y = float32(cCenterPoint.x), float32(cCenterPoint.y)\n\tradius = float32(cRadius)\n\treturn x, y, radius\n}\n\n// FindContours finds contours in a binary image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#ga95f5b48d01abc7c2e0732db24689837b\nfunc FindContours(src Mat, mode RetrievalMode, method ContourApproximationMode) PointsVector {\n\thierarchy := NewMat()\n\tdefer hierarchy.Close()\n\treturn FindContoursWithParams(src, &hierarchy, mode, method)\n}\n\n// FindContoursWithParams finds contours in a binary image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#ga17ed9f5d79ae97bd4c7cf18403e1689a\nfunc FindContoursWithParams(src Mat, hierarchy *Mat, mode RetrievalMode, method ContourApproximationMode) PointsVector {\n\treturn PointsVector{p: C.FindContours(src.p, hierarchy.p, C.int(mode), C.int(method))}\n}\n\n// PointPolygonTest performs a point-in-contour test.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#ga1a539e8db2135af2566103705d7a5722\nfunc PointPolygonTest(pts PointVector, pt image.Point, measureDist bool) float64 {\n\tcp := C.struct_Point{\n\t\tx: C.int(pt.X),\n\t\ty: C.int(pt.Y),\n\t}\n\treturn float64(C.PointPolygonTest(pts.p, cp, C.bool(measureDist)))\n}\n\n// ConnectedComponentsAlgorithmType specifies the type for ConnectedComponents\ntype ConnectedComponentsAlgorithmType int\n\nconst (\n\t// SAUF algorithm for 8-way connectivity, SAUF algorithm for 4-way connectivity.\n\tCCL_WU ConnectedComponentsAlgorithmType = 0\n\n\t// BBDT algorithm for 8-way connectivity, SAUF algorithm for 4-way connectivity.\n\tCCL_DEFAULT ConnectedComponentsAlgorithmType = 1\n\n\t// BBDT algorithm for 8-way connectivity, SAUF algorithm for 4-way connectivity\n\tCCL_GRANA ConnectedComponentsAlgorithmType = 2\n)\n\n// ConnectedComponents computes the connected components labeled image of boolean image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#gaedef8c7340499ca391d459122e51bef5\nfunc ConnectedComponents(src Mat, labels *Mat) int {\n\treturn int(C.ConnectedComponents(src.p, labels.p, C.int(8), C.int(MatTypeCV32S), C.int(CCL_DEFAULT)))\n}\n\n// ConnectedComponents computes the connected components labeled image of boolean image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#gaedef8c7340499ca391d459122e51bef5\nfunc ConnectedComponentsWithParams(src Mat, labels *Mat, conn int, ltype MatType,\n\tccltype ConnectedComponentsAlgorithmType) int {\n\treturn int(C.ConnectedComponents(src.p, labels.p, C.int(conn), C.int(ltype), C.int(ccltype)))\n}\n\n// ConnectedComponentsTypes are the connected components algorithm output formats\ntype ConnectedComponentsTypes int\n\nconst (\n\t//The leftmost (x) coordinate which is the inclusive start of the bounding box in the horizontal direction.\n\tCC_STAT_LEFT ConnectedComponentsTypes = 0\n\n\t//The topmost (y) coordinate which is the inclusive start of the bounding box in the vertical direction.\n\tCC_STAT_TOP ConnectedComponentsTypes = 1\n\n\t// The horizontal size of the bounding box.\n\tCC_STAT_WIDTH ConnectedComponentsTypes = 2\n\n\t// The vertical size of the bounding box.\n\tCC_STAT_HEIGHT ConnectedComponentsTypes = 3\n\n\t// The total area (in pixels) of the connected component.\n\tCC_STAT_AREA ConnectedComponentsTypes = 4\n\n\tCC_STAT_MAX ConnectedComponentsTypes = 5\n)\n\n// ConnectedComponentsWithStats computes the connected components labeled image of boolean\n// image and also produces a statistics output for each label.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#ga107a78bf7cd25dec05fb4dfc5c9e765f\nfunc ConnectedComponentsWithStats(src Mat, labels *Mat, stats *Mat, centroids *Mat) int {\n\treturn int(C.ConnectedComponentsWithStats(src.p, labels.p, stats.p, centroids.p,\n\t\tC.int(8), C.int(MatTypeCV32S), C.int(CCL_DEFAULT)))\n}\n\n// ConnectedComponentsWithStats computes the connected components labeled image of boolean\n// image and also produces a statistics output for each label.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#ga107a78bf7cd25dec05fb4dfc5c9e765f\nfunc ConnectedComponentsWithStatsWithParams(src Mat, labels *Mat, stats *Mat, centroids *Mat,\n\tconn int, ltype MatType, ccltype ConnectedComponentsAlgorithmType) int {\n\treturn int(C.ConnectedComponentsWithStats(src.p, labels.p, stats.p, centroids.p, C.int(conn),\n\t\tC.int(ltype), C.int(ccltype)))\n}\n\n// TemplateMatchMode is the type of the template matching operation.\ntype TemplateMatchMode int\n\nconst (\n\t// TmSqdiff maps to TM_SQDIFF\n\tTmSqdiff TemplateMatchMode = 0\n\t// TmSqdiffNormed maps to TM_SQDIFF_NORMED\n\tTmSqdiffNormed TemplateMatchMode = 1\n\t// TmCcorr maps to TM_CCORR\n\tTmCcorr TemplateMatchMode = 2\n\t// TmCcorrNormed maps to TM_CCORR_NORMED\n\tTmCcorrNormed TemplateMatchMode = 3\n\t// TmCcoeff maps to TM_CCOEFF\n\tTmCcoeff TemplateMatchMode = 4\n\t// TmCcoeffNormed maps to TM_CCOEFF_NORMED\n\tTmCcoeffNormed TemplateMatchMode = 5\n)\n\n// MatchTemplate compares a template against overlapped image regions.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/df/dfb/group__imgproc__object.html#ga586ebfb0a7fb604b35a23d85391329be\nfunc MatchTemplate(image Mat, templ Mat, result *Mat, method TemplateMatchMode, mask Mat) {\n\tC.MatchTemplate(image.p, templ.p, result.p, C.int(method), mask.p)\n}\n\n// Moments calculates all of the moments up to the third order of a polygon\n// or rasterized shape.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#ga556a180f43cab22649c23ada36a8a139\nfunc Moments(src Mat, binaryImage bool) map[string]float64 {\n\tr := C.Moments(src.p, C.bool(binaryImage))\n\n\tresult := make(map[string]float64)\n\tresult[\"m00\"] = float64(r.m00)\n\tresult[\"m10\"] = float64(r.m10)\n\tresult[\"m01\"] = float64(r.m01)\n\tresult[\"m20\"] = float64(r.m20)\n\tresult[\"m11\"] = float64(r.m11)\n\tresult[\"m02\"] = float64(r.m02)\n\tresult[\"m30\"] = float64(r.m30)\n\tresult[\"m21\"] = float64(r.m21)\n\tresult[\"m12\"] = float64(r.m12)\n\tresult[\"m03\"] = float64(r.m03)\n\tresult[\"mu20\"] = float64(r.mu20)\n\tresult[\"mu11\"] = float64(r.mu11)\n\tresult[\"mu02\"] = float64(r.mu02)\n\tresult[\"mu30\"] = float64(r.mu30)\n\tresult[\"mu21\"] = float64(r.mu21)\n\tresult[\"mu12\"] = float64(r.mu12)\n\tresult[\"mu03\"] = float64(r.mu03)\n\tresult[\"nu20\"] = float64(r.nu20)\n\tresult[\"nu11\"] = float64(r.nu11)\n\tresult[\"nu02\"] = float64(r.nu02)\n\tresult[\"nu30\"] = float64(r.nu30)\n\tresult[\"nu21\"] = float64(r.nu21)\n\tresult[\"nu12\"] = float64(r.nu12)\n\tresult[\"nu03\"] = float64(r.nu03)\n\n\treturn result\n}\n\n// PyrDown blurs an image and downsamples it.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gaf9bba239dfca11654cb7f50f889fc2ff\nfunc PyrDown(src Mat, dst *Mat, ksize image.Point, borderType BorderType) {\n\tpSize := C.struct_Size{\n\t\theight: C.int(ksize.X),\n\t\twidth:  C.int(ksize.Y),\n\t}\n\tC.PyrDown(src.p, dst.p, pSize, C.int(borderType))\n}\n\n// PyrUp upsamples an image and then blurs it.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gada75b59bdaaca411ed6fee10085eb784\nfunc PyrUp(src Mat, dst *Mat, ksize image.Point, borderType BorderType) {\n\tpSize := C.struct_Size{\n\t\theight: C.int(ksize.X),\n\t\twidth:  C.int(ksize.Y),\n\t}\n\tC.PyrUp(src.p, dst.p, pSize, C.int(borderType))\n}\n\n// MorphologyDefaultBorder returns \"magic\" border value for erosion and dilation.\n// It is automatically transformed to Scalar::all(-DBL_MAX) for dilation.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga94756fad83d9d24d29c9bf478558c40a\nfunc MorphologyDefaultBorderValue() Scalar {\n\tvar scalar C.Scalar = C.MorphologyDefaultBorderValue()\n\treturn NewScalar(float64(scalar.val1), float64(scalar.val2), float64(scalar.val3), float64(scalar.val4))\n}\n\n// MorphologyEx performs advanced morphological transformations.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga67493776e3ad1a3df63883829375201f\nfunc MorphologyEx(src Mat, dst *Mat, op MorphType, kernel Mat) {\n\tC.MorphologyEx(src.p, dst.p, C.int(op), kernel.p)\n}\n\n// MorphologyExWithParams performs advanced morphological transformations.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga67493776e3ad1a3df63883829375201f\nfunc MorphologyExWithParams(src Mat, dst *Mat, op MorphType, kernel Mat, iterations int, borderType BorderType) {\n\tpt := C.struct_Point{\n\t\tx: C.int(-1),\n\t\ty: C.int(-1),\n\t}\n\tC.MorphologyExWithParams(src.p, dst.p, C.int(op), kernel.p, pt, C.int(iterations), C.int(borderType))\n}\n\n// MorphShape is the shape of the structuring element used for Morphing operations.\ntype MorphShape int\n\nconst (\n\t// MorphRect is the rectangular morph shape.\n\tMorphRect MorphShape = 0\n\n\t// MorphCross is the cross morph shape.\n\tMorphCross MorphShape = 1\n\n\t// MorphEllipse is the ellipse morph shape.\n\tMorphEllipse MorphShape = 2\n)\n\n// GetStructuringElement returns a structuring element of the specified size\n// and shape for morphological operations.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gac342a1bb6eabf6f55c803b09268e36dc\nfunc GetStructuringElement(shape MorphShape, ksize image.Point) Mat {\n\tsz := C.struct_Size{\n\t\twidth:  C.int(ksize.X),\n\t\theight: C.int(ksize.Y),\n\t}\n\n\treturn newMat(C.GetStructuringElement(C.int(shape), sz))\n}\n\n// MorphType type of morphological operation.\ntype MorphType int\n\nconst (\n\t// MorphErode operation\n\tMorphErode MorphType = 0\n\n\t// MorphDilate operation\n\tMorphDilate MorphType = 1\n\n\t// MorphOpen operation\n\tMorphOpen MorphType = 2\n\n\t// MorphClose operation\n\tMorphClose MorphType = 3\n\n\t// MorphGradient operation\n\tMorphGradient MorphType = 4\n\n\t// MorphTophat operation\n\tMorphTophat MorphType = 5\n\n\t// MorphBlackhat operation\n\tMorphBlackhat MorphType = 6\n\n\t// MorphHitmiss operation\n\tMorphHitmiss MorphType = 7\n)\n\n// BorderType type of border.\ntype BorderType int\n\nconst (\n\t// BorderConstant border type\n\tBorderConstant BorderType = 0\n\n\t// BorderReplicate border type\n\tBorderReplicate BorderType = 1\n\n\t// BorderReflect border type\n\tBorderReflect BorderType = 2\n\n\t// BorderWrap border type\n\tBorderWrap BorderType = 3\n\n\t// BorderReflect101 border type\n\tBorderReflect101 BorderType = 4\n\n\t// BorderTransparent border type\n\tBorderTransparent BorderType = 5\n\n\t// BorderDefault border type\n\tBorderDefault = BorderReflect101\n\n\t// BorderIsolated border type\n\tBorderIsolated BorderType = 16\n)\n\n// GaussianBlur blurs an image Mat using a Gaussian filter.\n// The function convolves the src Mat image into the dst Mat using\n// the specified Gaussian kernel params.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gaabe8c836e97159a9193fb0b11ac52cf1\nfunc GaussianBlur(src Mat, dst *Mat, ksize image.Point, sigmaX float64,\n\tsigmaY float64, borderType BorderType) {\n\tpSize := C.struct_Size{\n\t\twidth:  C.int(ksize.X),\n\t\theight: C.int(ksize.Y),\n\t}\n\n\tC.GaussianBlur(src.p, dst.p, pSize, C.double(sigmaX), C.double(sigmaY), C.int(borderType))\n}\n\n// GetGaussianKernel returns Gaussian filter coefficients.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gac05a120c1ae92a6060dd0db190a61afa\nfunc GetGaussianKernel(ksize int, sigma float64) Mat {\n\treturn newMat(C.GetGaussianKernel(C.int(ksize), C.double(sigma), C.int(MatTypeCV64F)))\n}\n\n// GetGaussianKernelWithParams returns Gaussian filter coefficients.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gac05a120c1ae92a6060dd0db190a61afa\nfunc GetGaussianKernelWithParams(ksize int, sigma float64, ktype MatType) Mat {\n\treturn newMat(C.GetGaussianKernel(C.int(ksize), C.double(sigma), C.int(ktype)))\n}\n\n// Sobel calculates the first, second, third, or mixed image derivatives using an extended Sobel operator\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gacea54f142e81b6758cb6f375ce782c8d\nfunc Sobel(src Mat, dst *Mat, ddepth MatType, dx, dy, ksize int, scale, delta float64, borderType BorderType) {\n\tC.Sobel(src.p, dst.p, C.int(ddepth), C.int(dx), C.int(dy), C.int(ksize), C.double(scale), C.double(delta), C.int(borderType))\n}\n\n// SpatialGradient calculates the first order image derivative in both x and y using a Sobel operator.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga405d03b20c782b65a4daf54d233239a2\nfunc SpatialGradient(src Mat, dx, dy *Mat, ksize MatType, borderType BorderType) {\n\tC.SpatialGradient(src.p, dx.p, dy.p, C.int(ksize), C.int(borderType))\n}\n\n// Laplacian calculates the Laplacian of an image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gad78703e4c8fe703d479c1860d76429e6\nfunc Laplacian(src Mat, dst *Mat, dDepth MatType, size int, scale float64,\n\tdelta float64, borderType BorderType) {\n\tC.Laplacian(src.p, dst.p, C.int(dDepth), C.int(size), C.double(scale), C.double(delta), C.int(borderType))\n}\n\n// Scharr calculates the first x- or y- image derivative using Scharr operator.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gaa13106761eedf14798f37aa2d60404c9\nfunc Scharr(src Mat, dst *Mat, dDepth MatType, dx int, dy int, scale float64,\n\tdelta float64, borderType BorderType) {\n\tC.Scharr(src.p, dst.p, C.int(dDepth), C.int(dx), C.int(dy), C.double(scale), C.double(delta), C.int(borderType))\n}\n\n// MedianBlur blurs an image using the median filter.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga564869aa33e58769b4469101aac458f9\nfunc MedianBlur(src Mat, dst *Mat, ksize int) {\n\tC.MedianBlur(src.p, dst.p, C.int(ksize))\n}\n\n// Canny finds edges in an image using the Canny algorithm.\n// The function finds edges in the input image image and marks\n// them in the output map edges using the Canny algorithm.\n// The smallest value between threshold1 and threshold2 is used\n// for edge linking. The largest value is used to\n// find initial segments of strong edges.\n// See http://en.wikipedia.org/wiki/Canny_edge_detector\n//\n// For further details, please see:\n// http://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#ga04723e007ed888ddf11d9ba04e2232de\nfunc Canny(src Mat, edges *Mat, t1 float32, t2 float32) {\n\tC.Canny(src.p, edges.p, C.double(t1), C.double(t2))\n}\n\n// CornerSubPix Refines the corner locations. The function iterates to find\n// the sub-pixel accurate location of corners or radial saddle points.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#ga354e0d7c86d0d9da75de9b9701a9a87e\nfunc CornerSubPix(img Mat, corners *Mat, winSize image.Point, zeroZone image.Point, criteria TermCriteria) {\n\twinSz := C.struct_Size{\n\t\twidth:  C.int(winSize.X),\n\t\theight: C.int(winSize.Y),\n\t}\n\n\tzeroSz := C.struct_Size{\n\t\twidth:  C.int(zeroZone.X),\n\t\theight: C.int(zeroZone.Y),\n\t}\n\n\tC.CornerSubPix(img.p, corners.p, winSz, zeroSz, criteria.p)\n\treturn\n}\n\n// GoodFeaturesToTrack determines strong corners on an image. The function\n// finds the most prominent corners in the image or in the specified image region.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#ga1d6bb77486c8f92d79c8793ad995d541\nfunc GoodFeaturesToTrack(img Mat, corners *Mat, maxCorners int, quality float64, minDist float64) {\n\tC.GoodFeaturesToTrack(img.p, corners.p, C.int(maxCorners), C.double(quality), C.double(minDist))\n}\n\n// GrabCutMode is the flag for GrabCut algorithm.\ntype GrabCutMode int\n\nconst (\n\t// GCInitWithRect makes the function initialize the state and the mask using the provided rectangle.\n\t// After that it runs the itercount iterations of the algorithm.\n\tGCInitWithRect GrabCutMode = 0\n\t// GCInitWithMask makes the function initialize the state using the provided mask.\n\t// GCInitWithMask and GCInitWithRect can be combined.\n\t// Then all the pixels outside of the ROI are automatically initialized with GC_BGD.\n\tGCInitWithMask GrabCutMode = 1\n\t// GCEval means that the algorithm should just resume.\n\tGCEval GrabCutMode = 2\n\t// GCEvalFreezeModel means that the algorithm should just run a single iteration of the GrabCut algorithm\n\t// with the fixed model\n\tGCEvalFreezeModel GrabCutMode = 3\n)\n\n// Grabcut runs the GrabCut algorithm.\n// The function implements the GrabCut image segmentation algorithm.\n// For further details, please see:\n// https://docs.opencv.org/master/d7/d1b/group__imgproc__misc.html#ga909c1dda50efcbeaa3ce126be862b37f\nfunc GrabCut(img Mat, mask *Mat, r image.Rectangle, bgdModel *Mat, fgdModel *Mat, iterCount int, mode GrabCutMode) {\n\tcRect := C.struct_Rect{\n\t\tx:      C.int(r.Min.X),\n\t\ty:      C.int(r.Min.Y),\n\t\twidth:  C.int(r.Size().X),\n\t\theight: C.int(r.Size().Y),\n\t}\n\n\tC.GrabCut(img.p, mask.p, cRect, bgdModel.p, fgdModel.p, C.int(iterCount), C.int(mode))\n}\n\n// HoughMode is the type for Hough transform variants.\ntype HoughMode int\n\nconst (\n\t// HoughStandard is the classical or standard Hough transform.\n\tHoughStandard HoughMode = 0\n\t// HoughProbabilistic is the probabilistic Hough transform (more efficient\n\t// in case if the picture contains a few long linear segments).\n\tHoughProbabilistic HoughMode = 1\n\t// HoughMultiScale is the multi-scale variant of the classical Hough\n\t// transform.\n\tHoughMultiScale HoughMode = 2\n\t// HoughGradient is basically 21HT, described in: HK Yuen, John Princen,\n\t// John Illingworth, and Josef Kittler. Comparative study of hough\n\t// transform methods for circle finding. Image and Vision Computing,\n\t// 8(1):71–77, 1990.\n\tHoughGradient HoughMode = 3\n)\n\n// HoughCircles finds circles in a grayscale image using the Hough transform.\n// The only \"method\" currently supported is HoughGradient. If you want to pass\n// more parameters, please see `HoughCirclesWithParams`.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#ga47849c3be0d0406ad3ca45db65a25d2d\nfunc HoughCircles(src Mat, circles *Mat, method HoughMode, dp, minDist float64) {\n\tC.HoughCircles(src.p, circles.p, C.int(method), C.double(dp), C.double(minDist))\n}\n\n// HoughCirclesWithParams finds circles in a grayscale image using the Hough\n// transform. The only \"method\" currently supported is HoughGradient.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#ga47849c3be0d0406ad3ca45db65a25d2d\nfunc HoughCirclesWithParams(src Mat, circles *Mat, method HoughMode, dp, minDist, param1, param2 float64, minRadius, maxRadius int) {\n\tC.HoughCirclesWithParams(src.p, circles.p, C.int(method), C.double(dp), C.double(minDist), C.double(param1), C.double(param2), C.int(minRadius), C.int(maxRadius))\n}\n\n// HoughLines implements the standard or standard multi-scale Hough transform\n// algorithm for line detection. For a good explanation of Hough transform, see:\n// http://homepages.inf.ed.ac.uk/rbf/HIPR2/hough.htm\n//\n// For further details, please see:\n// http://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#ga46b4e588934f6c8dfd509cc6e0e4545a\nfunc HoughLines(src Mat, lines *Mat, rho float32, theta float32, threshold int) {\n\tC.HoughLines(src.p, lines.p, C.double(rho), C.double(theta), C.int(threshold))\n}\n\n// HoughLinesP implements the probabilistic Hough transform\n// algorithm for line detection. For a good explanation of Hough transform, see:\n// http://homepages.inf.ed.ac.uk/rbf/HIPR2/hough.htm\n//\n// For further details, please see:\n// http://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#ga8618180a5948286384e3b7ca02f6feeb\nfunc HoughLinesP(src Mat, lines *Mat, rho float32, theta float32, threshold int) {\n\tC.HoughLinesP(src.p, lines.p, C.double(rho), C.double(theta), C.int(threshold))\n}\nfunc HoughLinesPWithParams(src Mat, lines *Mat, rho float32, theta float32, threshold int, minLineLength float32, maxLineGap float32) {\n\tC.HoughLinesPWithParams(src.p, lines.p, C.double(rho), C.double(theta), C.int(threshold), C.double(minLineLength), C.double(maxLineGap))\n}\n\n// HoughLinesPointSet implements the Hough transform algorithm for line\n// detection on a set of points. For a good explanation of Hough transform, see:\n// http://homepages.inf.ed.ac.uk/rbf/HIPR2/hough.htm\n//\n// For further details, please see:\n// https://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#ga2858ef61b4e47d1919facac2152a160e\nfunc HoughLinesPointSet(points Mat, lines *Mat, linesMax int, threshold int,\n\tminRho float32, maxRho float32, rhoStep float32,\n\tminTheta float32, maxTheta float32, thetaStep float32) {\n\tC.HoughLinesPointSet(points.p, lines.p, C.int(linesMax), C.int(threshold),\n\t\tC.double(minRho), C.double(maxRho), C.double(rhoStep),\n\t\tC.double(minTheta), C.double(maxTheta), C.double(thetaStep))\n}\n\n// Integral calculates one or more integral images for the source image.\n// For further details, please see:\n// https://docs.opencv.org/master/d7/d1b/group__imgproc__misc.html#ga97b87bec26908237e8ba0f6e96d23e28\nfunc Integral(src Mat, sum *Mat, sqsum *Mat, tilted *Mat) {\n\tC.Integral(src.p, sum.p, sqsum.p, tilted.p)\n}\n\n// ThresholdType type of threshold operation.\ntype ThresholdType int\n\nconst (\n\t// ThresholdBinary threshold type\n\tThresholdBinary ThresholdType = 0\n\n\t// ThresholdBinaryInv threshold type\n\tThresholdBinaryInv ThresholdType = 1\n\n\t// ThresholdTrunc threshold type\n\tThresholdTrunc ThresholdType = 2\n\n\t// ThresholdToZero threshold type\n\tThresholdToZero ThresholdType = 3\n\n\t// ThresholdToZeroInv threshold type\n\tThresholdToZeroInv ThresholdType = 4\n\n\t// ThresholdMask threshold type\n\tThresholdMask ThresholdType = 7\n\n\t// ThresholdOtsu threshold type\n\tThresholdOtsu ThresholdType = 8\n\n\t// ThresholdTriangle threshold type\n\tThresholdTriangle ThresholdType = 16\n)\n\n// Threshold applies a fixed-level threshold to each array element.\n//\n// For further details, please see:\n// https://docs.opencv.org/3.3.0/d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57\nfunc Threshold(src Mat, dst *Mat, thresh float32, maxvalue float32, typ ThresholdType) (threshold float32) {\n\treturn float32(C.Threshold(src.p, dst.p, C.double(thresh), C.double(maxvalue), C.int(typ)))\n}\n\n// AdaptiveThresholdType type of adaptive threshold operation.\ntype AdaptiveThresholdType int\n\nconst (\n\t// AdaptiveThresholdMean threshold type\n\tAdaptiveThresholdMean AdaptiveThresholdType = 0\n\n\t// AdaptiveThresholdGaussian threshold type\n\tAdaptiveThresholdGaussian AdaptiveThresholdType = 1\n)\n\n// AdaptiveThreshold applies a fixed-level threshold to each array element.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/d1b/group__imgproc__misc.html#ga72b913f352e4a1b1b397736707afcde3\nfunc AdaptiveThreshold(src Mat, dst *Mat, maxValue float32, adaptiveTyp AdaptiveThresholdType, typ ThresholdType, blockSize int, c float32) {\n\tC.AdaptiveThreshold(src.p, dst.p, C.double(maxValue), C.int(adaptiveTyp), C.int(typ), C.int(blockSize), C.double(c))\n}\n\n// ArrowedLine draws a arrow segment pointing from the first point\n// to the second one.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#ga0a165a3ca093fd488ac709fdf10c05b2\nfunc ArrowedLine(img *Mat, pt1 image.Point, pt2 image.Point, c color.RGBA, thickness int) {\n\tsp1 := C.struct_Point{\n\t\tx: C.int(pt1.X),\n\t\ty: C.int(pt1.Y),\n\t}\n\n\tsp2 := C.struct_Point{\n\t\tx: C.int(pt2.X),\n\t\ty: C.int(pt2.Y),\n\t}\n\n\tsColor := C.struct_Scalar{\n\t\tval1: C.double(c.B),\n\t\tval2: C.double(c.G),\n\t\tval3: C.double(c.R),\n\t\tval4: C.double(c.A),\n\t}\n\n\tC.ArrowedLine(img.p, sp1, sp2, sColor, C.int(thickness))\n}\n\n// Circle draws a circle.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#gaf10604b069374903dbd0f0488cb43670\nfunc Circle(img *Mat, center image.Point, radius int, c color.RGBA, thickness int) {\n\tpc := C.struct_Point{\n\t\tx: C.int(center.X),\n\t\ty: C.int(center.Y),\n\t}\n\n\tsColor := C.struct_Scalar{\n\t\tval1: C.double(c.B),\n\t\tval2: C.double(c.G),\n\t\tval3: C.double(c.R),\n\t\tval4: C.double(c.A),\n\t}\n\n\tC.Circle(img.p, pc, C.int(radius), sColor, C.int(thickness))\n}\n\n// CircleWithParams draws a circle.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#gaf10604b069374903dbd0f0488cb43670\nfunc CircleWithParams(img *Mat, center image.Point, radius int, c color.RGBA, thickness int, lineType LineType, shift int) {\n\tpc := C.struct_Point{\n\t\tx: C.int(center.X),\n\t\ty: C.int(center.Y),\n\t}\n\n\tsColor := C.struct_Scalar{\n\t\tval1: C.double(c.B),\n\t\tval2: C.double(c.G),\n\t\tval3: C.double(c.R),\n\t\tval4: C.double(c.A),\n\t}\n\n\tC.CircleWithParams(img.p, pc, C.int(radius), sColor, C.int(thickness), C.int(lineType), C.int(shift))\n}\n\n// Ellipse draws a simple or thick elliptic arc or fills an ellipse sector.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#ga28b2267d35786f5f890ca167236cbc69\nfunc Ellipse(img *Mat, center, axes image.Point, angle, startAngle, endAngle float64, c color.RGBA, thickness int) {\n\tpc := C.struct_Point{\n\t\tx: C.int(center.X),\n\t\ty: C.int(center.Y),\n\t}\n\tpa := C.struct_Point{\n\t\tx: C.int(axes.X),\n\t\ty: C.int(axes.Y),\n\t}\n\n\tsColor := C.struct_Scalar{\n\t\tval1: C.double(c.B),\n\t\tval2: C.double(c.G),\n\t\tval3: C.double(c.R),\n\t\tval4: C.double(c.A),\n\t}\n\n\tC.Ellipse(img.p, pc, pa, C.double(angle), C.double(startAngle), C.double(endAngle), sColor, C.int(thickness))\n}\n\n// Ellipse draws a simple or thick elliptic arc or fills an ellipse sector.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#ga28b2267d35786f5f890ca167236cbc69\nfunc EllipseWithParams(img *Mat, center, axes image.Point, angle, startAngle, endAngle float64, c color.RGBA, thickness int, lineType LineType, shift int) {\n\tpc := C.struct_Point{\n\t\tx: C.int(center.X),\n\t\ty: C.int(center.Y),\n\t}\n\tpa := C.struct_Point{\n\t\tx: C.int(axes.X),\n\t\ty: C.int(axes.Y),\n\t}\n\n\tsColor := C.struct_Scalar{\n\t\tval1: C.double(c.B),\n\t\tval2: C.double(c.G),\n\t\tval3: C.double(c.R),\n\t\tval4: C.double(c.A),\n\t}\n\n\tC.EllipseWithParams(img.p, pc, pa, C.double(angle), C.double(startAngle), C.double(endAngle), sColor, C.int(thickness), C.int(lineType), C.int(shift))\n}\n\n// Line draws a line segment connecting two points.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#ga7078a9fae8c7e7d13d24dac2520ae4a2\nfunc Line(img *Mat, pt1 image.Point, pt2 image.Point, c color.RGBA, thickness int) {\n\tsp1 := C.struct_Point{\n\t\tx: C.int(pt1.X),\n\t\ty: C.int(pt1.Y),\n\t}\n\n\tsp2 := C.struct_Point{\n\t\tx: C.int(pt2.X),\n\t\ty: C.int(pt2.Y),\n\t}\n\n\tsColor := C.struct_Scalar{\n\t\tval1: C.double(c.B),\n\t\tval2: C.double(c.G),\n\t\tval3: C.double(c.R),\n\t\tval4: C.double(c.A),\n\t}\n\n\tC.Line(img.p, sp1, sp2, sColor, C.int(thickness))\n}\n\n// Rectangle draws a simple, thick, or filled up-right rectangle.\n// It renders a rectangle with the desired characteristics to the target Mat image.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#ga346ac30b5c74e9b5137576c9ee9e0e8c\nfunc Rectangle(img *Mat, r image.Rectangle, c color.RGBA, thickness int) {\n\tcRect := C.struct_Rect{\n\t\tx:      C.int(r.Min.X),\n\t\ty:      C.int(r.Min.Y),\n\t\twidth:  C.int(r.Size().X),\n\t\theight: C.int(r.Size().Y),\n\t}\n\n\tsColor := C.struct_Scalar{\n\t\tval1: C.double(c.B),\n\t\tval2: C.double(c.G),\n\t\tval3: C.double(c.R),\n\t\tval4: C.double(c.A),\n\t}\n\n\tC.Rectangle(img.p, cRect, sColor, C.int(thickness))\n}\n\n// RectangleWithParams draws a simple, thick, or filled up-right rectangle.\n// It renders a rectangle with the desired characteristics to the target Mat image.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#ga346ac30b5c74e9b5137576c9ee9e0e8c\nfunc RectangleWithParams(img *Mat, r image.Rectangle, c color.RGBA, thickness int, lineType LineType, shift int) {\n\tcRect := C.struct_Rect{\n\t\tx:      C.int(r.Min.X),\n\t\ty:      C.int(r.Min.Y),\n\t\twidth:  C.int(r.Size().X),\n\t\theight: C.int(r.Size().Y),\n\t}\n\n\tsColor := C.struct_Scalar{\n\t\tval1: C.double(c.B),\n\t\tval2: C.double(c.G),\n\t\tval3: C.double(c.R),\n\t\tval4: C.double(c.A),\n\t}\n\n\tC.RectangleWithParams(img.p, cRect, sColor, C.int(thickness), C.int(lineType), C.int(shift))\n}\n\n// FillPoly fills the area bounded by one or more polygons.\n//\n// For more information, see:\n// https://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#gaf30888828337aa4c6b56782b5dfbd4b7\nfunc FillPoly(img *Mat, pts PointsVector, c color.RGBA) {\n\tsColor := C.struct_Scalar{\n\t\tval1: C.double(c.B),\n\t\tval2: C.double(c.G),\n\t\tval3: C.double(c.R),\n\t\tval4: C.double(c.A),\n\t}\n\n\tC.FillPoly(img.p, pts.p, sColor)\n}\n\n// FillPolyWithParams fills the area bounded by one or more polygons.\n//\n// For more information, see:\n// https://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#gaf30888828337aa4c6b56782b5dfbd4b7\nfunc FillPolyWithParams(img *Mat, pts PointsVector, c color.RGBA, lineType LineType, shift int, offset image.Point) {\n\toffsetP := C.struct_Point{\n\t\tx: C.int(offset.X),\n\t\ty: C.int(offset.Y),\n\t}\n\n\tsColor := C.struct_Scalar{\n\t\tval1: C.double(c.B),\n\t\tval2: C.double(c.G),\n\t\tval3: C.double(c.R),\n\t\tval4: C.double(c.A),\n\t}\n\n\tC.FillPolyWithParams(img.p, pts.p, sColor, C.int(lineType), C.int(shift), offsetP)\n}\n\n// Polylines draws several polygonal curves.\n//\n// For more information, see:\n// https://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#ga1ea127ffbbb7e0bfc4fd6fd2eb64263c\nfunc Polylines(img *Mat, pts PointsVector, isClosed bool, c color.RGBA, thickness int) {\n\tsColor := C.struct_Scalar{\n\t\tval1: C.double(c.B),\n\t\tval2: C.double(c.G),\n\t\tval3: C.double(c.R),\n\t\tval4: C.double(c.A),\n\t}\n\n\tC.Polylines(img.p, pts.p, C.bool(isClosed), sColor, C.int(thickness))\n}\n\n// HersheyFont are the font libraries included in OpenCV.\n// Only a subset of the available Hershey fonts are supported by OpenCV.\n//\n// For more information, see:\n// http://sources.isc.org/utils/misc/hershey-font.txt\ntype HersheyFont int\n\nconst (\n\t// FontHersheySimplex is normal size sans-serif font.\n\tFontHersheySimplex HersheyFont = 0\n\t// FontHersheyPlain issmall size sans-serif font.\n\tFontHersheyPlain HersheyFont = 1\n\t// FontHersheyDuplex normal size sans-serif font\n\t// (more complex than FontHersheySIMPLEX).\n\tFontHersheyDuplex HersheyFont = 2\n\t// FontHersheyComplex i a normal size serif font.\n\tFontHersheyComplex HersheyFont = 3\n\t// FontHersheyTriplex is a normal size serif font\n\t// (more complex than FontHersheyCOMPLEX).\n\tFontHersheyTriplex HersheyFont = 4\n\t// FontHersheyComplexSmall is a smaller version of FontHersheyCOMPLEX.\n\tFontHersheyComplexSmall HersheyFont = 5\n\t// FontHersheyScriptSimplex is a hand-writing style font.\n\tFontHersheyScriptSimplex HersheyFont = 6\n\t// FontHersheyScriptComplex is a more complex variant of FontHersheyScriptSimplex.\n\tFontHersheyScriptComplex HersheyFont = 7\n\t// FontItalic is the flag for italic font.\n\tFontItalic HersheyFont = 16\n)\n\n// LineType are the line libraries included in OpenCV.\n//\n// For more information, see:\n// https://vovkos.github.io/doxyrest-showcase/opencv/sphinx_rtd_theme/enum_cv_LineTypes.html\ntype LineType int\n\nconst (\n\t// Filled line\n\tFilled LineType = -1\n\t// Line4 4-connected line\n\tLine4 LineType = 4\n\t// Line8 8-connected line\n\tLine8 LineType = 8\n\t// LineAA antialiased line\n\tLineAA LineType = 16\n)\n\n// GetTextSize calculates the width and height of a text string.\n// It returns an image.Point with the size required to draw text using\n// a specific font face, scale, and thickness.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#ga3d2abfcb995fd2db908c8288199dba82\nfunc GetTextSize(text string, fontFace HersheyFont, fontScale float64, thickness int) image.Point {\n\tcText := C.CString(text)\n\tdefer C.free(unsafe.Pointer(cText))\n\n\tsz := C.GetTextSize(cText, C.int(fontFace), C.double(fontScale), C.int(thickness))\n\treturn image.Pt(int(sz.width), int(sz.height))\n}\n\n// GetTextSizeWithBaseline calculates the width and height of a text string including the basline of the text.\n// It returns an image.Point with the size required to draw text using\n// a specific font face, scale, and thickness as well as its baseline.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#ga3d2abfcb995fd2db908c8288199dba82\nfunc GetTextSizeWithBaseline(text string, fontFace HersheyFont, fontScale float64, thickness int) (image.Point, int) {\n\tcText := C.CString(text)\n\tdefer C.free(unsafe.Pointer(cText))\n\tcBaseline := C.int(0)\n\n\tsz := C.GetTextSizeWithBaseline(cText, C.int(fontFace), C.double(fontScale), C.int(thickness), &cBaseline)\n\treturn image.Pt(int(sz.width), int(sz.height)), int(cBaseline)\n}\n\n// PutText draws a text string.\n// It renders the specified text string into the img Mat at the location\n// passed in the \"org\" param, using the desired font face, font scale,\n// color, and line thinkness.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#ga5126f47f883d730f633d74f07456c576\nfunc PutText(img *Mat, text string, org image.Point, fontFace HersheyFont, fontScale float64, c color.RGBA, thickness int) {\n\tcText := C.CString(text)\n\tdefer C.free(unsafe.Pointer(cText))\n\n\tpOrg := C.struct_Point{\n\t\tx: C.int(org.X),\n\t\ty: C.int(org.Y),\n\t}\n\n\tsColor := C.struct_Scalar{\n\t\tval1: C.double(c.B),\n\t\tval2: C.double(c.G),\n\t\tval3: C.double(c.R),\n\t\tval4: C.double(c.A),\n\t}\n\n\tC.PutText(img.p, cText, pOrg, C.int(fontFace), C.double(fontScale), sColor, C.int(thickness))\n\treturn\n}\n\n// PutTextWithParams draws a text string.\n// It renders the specified text string into the img Mat at the location\n// passed in the \"org\" param, using the desired font face, font scale,\n// color, and line thinkness.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#ga5126f47f883d730f633d74f07456c576\nfunc PutTextWithParams(img *Mat, text string, org image.Point, fontFace HersheyFont, fontScale float64, c color.RGBA, thickness int, lineType LineType, bottomLeftOrigin bool) {\n\tcText := C.CString(text)\n\tdefer C.free(unsafe.Pointer(cText))\n\n\tpOrg := C.struct_Point{\n\t\tx: C.int(org.X),\n\t\ty: C.int(org.Y),\n\t}\n\n\tsColor := C.struct_Scalar{\n\t\tval1: C.double(c.B),\n\t\tval2: C.double(c.G),\n\t\tval3: C.double(c.R),\n\t\tval4: C.double(c.A),\n\t}\n\n\tC.PutTextWithParams(img.p, cText, pOrg, C.int(fontFace), C.double(fontScale), sColor, C.int(thickness), C.int(lineType), C.bool(bottomLeftOrigin))\n\treturn\n}\n\n// InterpolationFlags are bit flags that control the interpolation algorithm\n// that is used.\ntype InterpolationFlags int\n\nconst (\n\t// InterpolationNearestNeighbor is nearest neighbor. (fast but low quality)\n\tInterpolationNearestNeighbor InterpolationFlags = 0\n\n\t// InterpolationLinear is bilinear interpolation.\n\tInterpolationLinear InterpolationFlags = 1\n\n\t// InterpolationCubic is bicube interpolation.\n\tInterpolationCubic InterpolationFlags = 2\n\n\t// InterpolationArea uses pixel area relation. It is preferred for image\n\t// decimation as it gives moire-free results.\n\tInterpolationArea InterpolationFlags = 3\n\n\t// InterpolationLanczos4 is Lanczos interpolation over 8x8 neighborhood.\n\tInterpolationLanczos4 InterpolationFlags = 4\n\n\t// InterpolationDefault is an alias for InterpolationLinear.\n\tInterpolationDefault = InterpolationLinear\n\n\t// InterpolationMax indicates use maximum interpolation.\n\tInterpolationMax InterpolationFlags = 7\n\n\t// WarpFillOutliers fills all of the destination image pixels. If some of them correspond to outliers in the source image, they are set to zero.\n\tWarpFillOutliers = 8\n\n\t// WarpInverseMap, inverse transformation.\n\tWarpInverseMap = 16\n)\n\n// Resize resizes an image.\n// It resizes the image src down to or up to the specified size, storing the\n// result in dst. Note that src and dst may be the same image. If you wish to\n// scale by factor, an empty sz may be passed and non-zero fx and fy. Likewise,\n// if you wish to scale to an explicit size, a non-empty sz may be passed with\n// zero for both fx and fy.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga47a974309e9102f5f08231edc7e7529d\nfunc Resize(src Mat, dst *Mat, sz image.Point, fx, fy float64, interp InterpolationFlags) {\n\tpSize := C.struct_Size{\n\t\twidth:  C.int(sz.X),\n\t\theight: C.int(sz.Y),\n\t}\n\n\tC.Resize(src.p, dst.p, pSize, C.double(fx), C.double(fy), C.int(interp))\n\treturn\n}\n\n// GetRectSubPix retrieves a pixel rectangle from an image with sub-pixel accuracy.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga77576d06075c1a4b6ba1a608850cd614\nfunc GetRectSubPix(src Mat, patchSize image.Point, center image.Point, dst *Mat) {\n\tsz := C.struct_Size{\n\t\twidth:  C.int(patchSize.X),\n\t\theight: C.int(patchSize.Y),\n\t}\n\tpt := C.struct_Point{\n\t\tx: C.int(center.X),\n\t\ty: C.int(center.Y),\n\t}\n\tC.GetRectSubPix(src.p, sz, pt, dst.p)\n}\n\n// GetRotationMatrix2D calculates an affine matrix of 2D rotation.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#gafbbc470ce83812914a70abfb604f4326\nfunc GetRotationMatrix2D(center image.Point, angle, scale float64) Mat {\n\tpc := C.struct_Point{\n\t\tx: C.int(center.X),\n\t\ty: C.int(center.Y),\n\t}\n\treturn newMat(C.GetRotationMatrix2D(pc, C.double(angle), C.double(scale)))\n}\n\n// WarpAffine applies an affine transformation to an image. For more parameters please check WarpAffineWithParams\n//\n// For further details, please see:\n// https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga0203d9ee5fcd28d40dbc4a1ea4451983\nfunc WarpAffine(src Mat, dst *Mat, m Mat, sz image.Point) {\n\tpSize := C.struct_Size{\n\t\twidth:  C.int(sz.X),\n\t\theight: C.int(sz.Y),\n\t}\n\n\tC.WarpAffine(src.p, dst.p, m.p, pSize)\n}\n\n// WarpAffineWithParams applies an affine transformation to an image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga0203d9ee5fcd28d40dbc4a1ea4451983\nfunc WarpAffineWithParams(src Mat, dst *Mat, m Mat, sz image.Point, flags InterpolationFlags, borderType BorderType, borderValue color.RGBA) {\n\tpSize := C.struct_Size{\n\t\twidth:  C.int(sz.X),\n\t\theight: C.int(sz.Y),\n\t}\n\tbv := C.struct_Scalar{\n\t\tval1: C.double(borderValue.B),\n\t\tval2: C.double(borderValue.G),\n\t\tval3: C.double(borderValue.R),\n\t\tval4: C.double(borderValue.A),\n\t}\n\tC.WarpAffineWithParams(src.p, dst.p, m.p, pSize, C.int(flags), C.int(borderType), bv)\n}\n\n// WarpPerspective applies a perspective transformation to an image.\n// For more parameters please check WarpPerspectiveWithParams.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#gaf73673a7e8e18ec6963e3774e6a94b87\nfunc WarpPerspective(src Mat, dst *Mat, m Mat, sz image.Point) {\n\tpSize := C.struct_Size{\n\t\twidth:  C.int(sz.X),\n\t\theight: C.int(sz.Y),\n\t}\n\n\tC.WarpPerspective(src.p, dst.p, m.p, pSize)\n}\n\n// WarpPerspectiveWithParams applies a perspective transformation to an image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#gaf73673a7e8e18ec6963e3774e6a94b87\nfunc WarpPerspectiveWithParams(src Mat, dst *Mat, m Mat, sz image.Point, flags InterpolationFlags, borderType BorderType, borderValue color.RGBA) {\n\tpSize := C.struct_Size{\n\t\twidth:  C.int(sz.X),\n\t\theight: C.int(sz.Y),\n\t}\n\tbv := C.struct_Scalar{\n\t\tval1: C.double(borderValue.B),\n\t\tval2: C.double(borderValue.G),\n\t\tval3: C.double(borderValue.R),\n\t\tval4: C.double(borderValue.A),\n\t}\n\tC.WarpPerspectiveWithParams(src.p, dst.p, m.p, pSize, C.int(flags), C.int(borderType), bv)\n}\n\n// Watershed performs a marker-based image segmentation using the watershed algorithm.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/d1b/group__imgproc__misc.html#ga3267243e4d3f95165d55a618c65ac6e1\nfunc Watershed(image Mat, markers *Mat) {\n\tC.Watershed(image.p, markers.p)\n}\n\n// ColormapTypes are the 12 GNU Octave/MATLAB equivalent colormaps.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/d50/group__imgproc__colormap.html\ntype ColormapTypes int\n\n// List of the available color maps\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/d50/group__imgproc__colormap.html#ga9a805d8262bcbe273f16be9ea2055a65\nconst (\n\tColormapAutumn  ColormapTypes = 0\n\tColormapBone    ColormapTypes = 1\n\tColormapJet     ColormapTypes = 2\n\tColormapWinter  ColormapTypes = 3\n\tColormapRainbow ColormapTypes = 4\n\tColormapOcean   ColormapTypes = 5\n\tColormapSummer  ColormapTypes = 6\n\tColormapSpring  ColormapTypes = 7\n\tColormapCool    ColormapTypes = 8\n\tColormapHsv     ColormapTypes = 9\n\tColormapPink    ColormapTypes = 10\n\tColormapHot     ColormapTypes = 11\n\tColormapParula  ColormapTypes = 12\n)\n\n// ApplyColorMap applies a GNU Octave/MATLAB equivalent colormap on a given image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/d50/group__imgproc__colormap.html#gadf478a5e5ff49d8aa24e726ea6f65d15\nfunc ApplyColorMap(src Mat, dst *Mat, colormapType ColormapTypes) {\n\tC.ApplyColorMap(src.p, dst.p, C.int(colormapType))\n}\n\n// ApplyCustomColorMap applies a custom defined colormap on a given image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/d50/group__imgproc__colormap.html#gacb22288ddccc55f9bd9e6d492b409cae\nfunc ApplyCustomColorMap(src Mat, dst *Mat, customColormap Mat) {\n\tC.ApplyCustomColorMap(src.p, dst.p, customColormap.p)\n}\n\n// GetPerspectiveTransform returns 3x3 perspective transformation for the\n// corresponding 4 point pairs as image.Point.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga8c1ae0e3589a9d77fffc962c49b22043\nfunc GetPerspectiveTransform(src, dst PointVector) Mat {\n\treturn newMat(C.GetPerspectiveTransform(src.p, dst.p))\n}\n\n// GetPerspectiveTransform2f returns 3x3 perspective transformation for the\n// corresponding 4 point pairs as gocv.Point2f.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga8c1ae0e3589a9d77fffc962c49b22043\nfunc GetPerspectiveTransform2f(src, dst Point2fVector) Mat {\n\treturn newMat(C.GetPerspectiveTransform2f(src.p, dst.p))\n}\n\n// GetAffineTransform returns a 2x3 affine transformation matrix for the\n// corresponding 3 point pairs as image.Point.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga8f6d378f9f8eebb5cb55cd3ae295a999\nfunc GetAffineTransform(src, dst PointVector) Mat {\n\treturn newMat(C.GetAffineTransform(src.p, dst.p))\n}\n\n// GetAffineTransform2f returns a 2x3 affine transformation matrix for the\n// corresponding 3 point pairs as gocv.Point2f.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga8f6d378f9f8eebb5cb55cd3ae295a999\nfunc GetAffineTransform2f(src, dst Point2fVector) Mat {\n\treturn newMat(C.GetAffineTransform2f(src.p, dst.p))\n}\n\ntype HomographyMethod int\n\nconst (\n\tHomographyMethodAllPoints HomographyMethod = 0\n\tHomographyMethodLMEDS     HomographyMethod = 4\n\tHomographyMethodRANSAC    HomographyMethod = 8\n\tHomographyMethodRHO       HomographyMethod = 16\n)\n\n// FindHomography finds an optimal homography matrix using 4 or more point pairs (as opposed to GetPerspectiveTransform, which uses exactly 4)\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d9/d0c/group__calib3d.html#ga4abc2ece9fab9398f2e560d53c8c9780\nfunc FindHomography(srcPoints Mat, dstPoints *Mat, method HomographyMethod, ransacReprojThreshold float64, mask *Mat, maxIters int, confidence float64) Mat {\n\treturn newMat(C.FindHomography(srcPoints.Ptr(), dstPoints.Ptr(), C.int(method), C.double(ransacReprojThreshold), mask.Ptr(), C.int(maxIters), C.double(confidence)))\n}\n\n// DrawContours draws contours outlines or filled contours.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#ga746c0625f1781f1ffc9056259103edbc\nfunc DrawContours(img *Mat, contours PointsVector, contourIdx int, c color.RGBA, thickness int) {\n\tsColor := C.struct_Scalar{\n\t\tval1: C.double(c.B),\n\t\tval2: C.double(c.G),\n\t\tval3: C.double(c.R),\n\t\tval4: C.double(c.A),\n\t}\n\n\tC.DrawContours(img.p, contours.p, C.int(contourIdx), sColor, C.int(thickness))\n}\n\n// DrawContoursWithParams draws contours outlines or filled contours.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html#ga746c0625f1781f1ffc9056259103edbc\nfunc DrawContoursWithParams(img *Mat, contours PointsVector, contourIdx int, c color.RGBA, thickness int, lineType LineType, hierarchy Mat, maxLevel int, offset image.Point) {\n\tsColor := C.struct_Scalar{\n\t\tval1: C.double(c.B),\n\t\tval2: C.double(c.G),\n\t\tval3: C.double(c.R),\n\t\tval4: C.double(c.A),\n\t}\n\toffsetP := C.struct_Point{\n\t\tx: C.int(offset.X),\n\t\ty: C.int(offset.Y),\n\t}\n\n\tC.DrawContoursWithParams(img.p, contours.p, C.int(contourIdx), sColor, C.int(thickness), C.int(lineType), hierarchy.p, C.int(maxLevel), offsetP)\n}\n\n// Remap applies a generic geometrical transformation to an image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#gab75ef31ce5cdfb5c44b6da5f3b908ea4\nfunc Remap(src Mat, dst, map1, map2 *Mat, interpolation InterpolationFlags, borderMode BorderType, borderValue color.RGBA) {\n\tbv := C.struct_Scalar{\n\t\tval1: C.double(borderValue.B),\n\t\tval2: C.double(borderValue.G),\n\t\tval3: C.double(borderValue.R),\n\t\tval4: C.double(borderValue.A),\n\t}\n\tC.Remap(src.p, dst.p, map1.p, map2.p, C.int(interpolation), C.int(borderMode), bv)\n}\n\n// Filter2D applies an arbitrary linear filter to an image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga27c049795ce870216ddfb366086b5a04\nfunc Filter2D(src Mat, dst *Mat, ddepth MatType, kernel Mat, anchor image.Point, delta float64, borderType BorderType) {\n\tanchorP := C.struct_Point{\n\t\tx: C.int(anchor.X),\n\t\ty: C.int(anchor.Y),\n\t}\n\tC.Filter2D(src.p, dst.p, C.int(ddepth), kernel.p, anchorP, C.double(delta), C.int(borderType))\n}\n\n// SepFilter2D applies a separable linear filter to the image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga910e29ff7d7b105057d1625a4bf6318d\nfunc SepFilter2D(src Mat, dst *Mat, ddepth MatType, kernelX, kernelY Mat, anchor image.Point, delta float64, borderType BorderType) {\n\tanchorP := C.struct_Point{\n\t\tx: C.int(anchor.X),\n\t\ty: C.int(anchor.Y),\n\t}\n\tC.SepFilter2D(src.p, dst.p, C.int(ddepth), kernelX.p, kernelY.p, anchorP, C.double(delta), C.int(borderType))\n}\n\n// LogPolar remaps an image to semilog-polar coordinates space.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#gaec3a0b126a85b5ca2c667b16e0ae022d\nfunc LogPolar(src Mat, dst *Mat, center image.Point, m float64, flags InterpolationFlags) {\n\tcenterP := C.struct_Point{\n\t\tx: C.int(center.X),\n\t\ty: C.int(center.Y),\n\t}\n\tC.LogPolar(src.p, dst.p, centerP, C.double(m), C.int(flags))\n}\n\n// LinearPolar remaps an image to polar coordinates space.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#gaa38a6884ac8b6e0b9bed47939b5362f3\nfunc LinearPolar(src Mat, dst *Mat, center image.Point, maxRadius float64, flags InterpolationFlags) {\n\tcenterP := C.struct_Point{\n\t\tx: C.int(center.X),\n\t\ty: C.int(center.Y),\n\t}\n\tC.LinearPolar(src.p, dst.p, centerP, C.double(maxRadius), C.int(flags))\n}\n\n// DistanceTypes types for Distance Transform and M-estimatorss\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/d1b/group__imgproc__misc.html#gaa2bfbebbc5c320526897996aafa1d8eb\ntype DistanceTypes int\n\nconst (\n\tDistUser   DistanceTypes = 0\n\tDistL1     DistanceTypes = 1\n\tDistL2     DistanceTypes = 2\n\tDistC      DistanceTypes = 3\n\tDistL12    DistanceTypes = 4\n\tDistFair   DistanceTypes = 5\n\tDistWelsch DistanceTypes = 6\n\tDistHuber  DistanceTypes = 7\n)\n\n// FitLine fits a line to a 2D or 3D point set.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#gaf849da1fdafa67ee84b1e9a23b93f91f\nfunc FitLine(pts PointVector, line *Mat, distType DistanceTypes, param, reps, aeps float64) {\n\tC.FitLine(pts.p, line.p, C.int(distType), C.double(param), C.double(reps), C.double(aeps))\n}\n\n// Shape matching methods.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d3/dc0/group__imgproc__shape.html#gaadc90cb16e2362c9bd6e7363e6e4c317\ntype ShapeMatchModes int\n\nconst (\n\tContoursMatchI1 ShapeMatchModes = 1\n\tContoursMatchI2 ShapeMatchModes = 2\n\tContoursMatchI3 ShapeMatchModes = 3\n)\n\n// Compares two shapes.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d3/dc0/group__imgproc__shape.html#gaadc90cb16e2362c9bd6e7363e6e4c317\nfunc MatchShapes(contour1 PointVector, contour2 PointVector, method ShapeMatchModes, parameter float64) float64 {\n\treturn float64(C.MatchShapes(contour1.p, contour2.p, C.int(method), C.double(parameter)))\n}\n\n// CLAHE is a wrapper around the cv::CLAHE algorithm.\ntype CLAHE struct {\n\t// C.CLAHE\n\tp unsafe.Pointer\n}\n\n// NewCLAHE returns a new CLAHE algorithm\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/db6/classcv_1_1CLAHE.html\nfunc NewCLAHE() CLAHE {\n\treturn CLAHE{p: unsafe.Pointer(C.CLAHE_Create())}\n}\n\n// NewCLAHEWithParams returns a new CLAHE algorithm\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/db6/classcv_1_1CLAHE.html\nfunc NewCLAHEWithParams(clipLimit float64, tileGridSize image.Point) CLAHE {\n\tpSize := C.struct_Size{\n\t\twidth:  C.int(tileGridSize.X),\n\t\theight: C.int(tileGridSize.Y),\n\t}\n\treturn CLAHE{p: unsafe.Pointer(C.CLAHE_CreateWithParams(C.double(clipLimit), pSize))}\n}\n\n// Close CLAHE.\nfunc (c *CLAHE) Close() error {\n\tC.CLAHE_Close((C.CLAHE)(c.p))\n\tc.p = nil\n\treturn nil\n}\n\n// Apply CLAHE.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/db6/classcv_1_1CLAHE.html#a4e92e0e427de21be8d1fae8dcd862c5e\nfunc (c *CLAHE) Apply(src Mat, dst *Mat) {\n\tC.CLAHE_Apply((C.CLAHE)(c.p), src.p, dst.p)\n}\n\nfunc InvertAffineTransform(src Mat, dst *Mat) {\n\tC.InvertAffineTransform(src.p, dst.p)\n}\n\n// Apply phaseCorrelate.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/df3/group__imgproc__motion.html#ga552420a2ace9ef3fb053cd630fdb4952\nfunc PhaseCorrelate(src1, src2, window Mat) (phaseShift Point2f, response float64) {\n\tvar responseDouble C.double\n\tresult := C.PhaseCorrelate(src1.p, src2.p, window.p, &responseDouble)\n\n\treturn Point2f{\n\t\tX: float32(result.x),\n\t\tY: float32(result.y),\n\t}, float64(responseDouble)\n}\n\n// CreateHanningWindow computes a Hanning window coefficients in two dimensions.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d7/df3/group__imgproc__motion.html#ga80e5c3de52f6bab3a7c1e60e89308e1b\nfunc CreateHanningWindow(img *Mat, size image.Point, typ MatType) {\n\tsz := C.struct_Size{\n\t\twidth:  C.int(size.X),\n\t\theight: C.int(size.Y),\n\t}\n\n\tC.CreateHanningWindow(img.p, sz, C.int(typ))\n}\n\n// ToImage converts a Mat to a image.Image.\nfunc (m *Mat) ToImage() (image.Image, error) {\n\tswitch m.Type() {\n\tcase MatTypeCV8UC1:\n\t\timg := image.NewGray(image.Rect(0, 0, m.Cols(), m.Rows()))\n\t\tdata, err := m.DataPtrUint8()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tcopy(img.Pix, data[0:])\n\t\treturn img, nil\n\n\tcase MatTypeCV8UC3:\n\t\tdst := NewMat()\n\t\tdefer dst.Close()\n\n\t\tC.CvtColor(m.p, dst.p, C.int(ColorBGRToRGBA))\n\n\t\timg := image.NewRGBA(image.Rect(0, 0, m.Cols(), m.Rows()))\n\t\tdata, err := dst.DataPtrUint8()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tcopy(img.Pix, data[0:])\n\t\treturn img, nil\n\n\tcase MatTypeCV8UC4:\n\t\tdst := NewMat()\n\t\tdefer dst.Close()\n\n\t\tC.CvtColor(m.p, dst.p, C.int(ColorBGRAToRGBA))\n\n\t\timg := image.NewNRGBA(image.Rect(0, 0, m.Cols(), m.Rows()))\n\t\tdata, err := dst.DataPtrUint8()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tcopy(img.Pix, data[0:])\n\t\treturn img, nil\n\n\tdefault:\n\t\treturn nil, errors.New(\"ToImage supports only MatType CV8UC1, CV8UC3 and CV8UC4\")\n\t}\n}\n\n// ToImageYUV converts a Mat to a image.YCbCr using image.YCbCrSubsampleRatio420 as default subsampling param.\nfunc (m *Mat) ToImageYUV() (*image.YCbCr, error) {\n\timg, err := m.ToImage()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tbounds := img.Bounds()\n\tconverted := image.NewYCbCr(bounds, image.YCbCrSubsampleRatio420)\n\n\tfor row := 0; row < bounds.Max.Y; row++ {\n\t\tfor col := 0; col < bounds.Max.X; col++ {\n\t\t\tr, g, b, _ := img.At(col, row).RGBA()\n\t\t\ty, cb, cr := color.RGBToYCbCr(uint8(r), uint8(g), uint8(b))\n\n\t\t\tconverted.Y[converted.YOffset(col, row)] = y\n\t\t\tconverted.Cb[converted.COffset(col, row)] = cb\n\t\t\tconverted.Cr[converted.COffset(col, row)] = cr\n\t\t}\n\t}\n\treturn converted, nil\n}\n\n// ToImageYUV converts a Mat to a image.YCbCr using provided YUV subsample ratio param.\nfunc (m *Mat) ToImageYUVWithParams(ratio image.YCbCrSubsampleRatio) (*image.YCbCr, error) {\n\timg, err := m.ToImage()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tbounds := img.Bounds()\n\tconverted := image.NewYCbCr(bounds, ratio)\n\n\tfor row := 0; row < bounds.Max.Y; row++ {\n\t\tfor col := 0; col < bounds.Max.X; col++ {\n\t\t\tr, g, b, _ := img.At(col, row).RGBA()\n\t\t\ty, cb, cr := color.RGBToYCbCr(uint8(r), uint8(g), uint8(b))\n\n\t\t\tconverted.Y[converted.YOffset(col, row)] = y\n\t\t\tconverted.Cb[converted.COffset(col, row)] = cb\n\t\t\tconverted.Cr[converted.COffset(col, row)] = cr\n\t\t}\n\t}\n\treturn converted, nil\n}\n\n// ImageToMatRGBA converts image.Image to gocv.Mat,\n// which represents RGBA image having 8bit for each component.\n// Type of Mat is gocv.MatTypeCV8UC4.\nfunc ImageToMatRGBA(img image.Image) (Mat, error) {\n\tbounds := img.Bounds()\n\tx := bounds.Dx()\n\ty := bounds.Dy()\n\n\tvar data []uint8\n\tswitch img.ColorModel() {\n\tcase color.RGBAModel:\n\t\tm, res := img.(*image.RGBA)\n\t\tif !res {\n\t\t\treturn NewMat(), errors.New(\"Image color format error\")\n\t\t}\n\t\tdata = m.Pix\n\n\tcase color.NRGBAModel:\n\t\tm, res := img.(*image.NRGBA)\n\t\tif !res {\n\t\t\treturn NewMat(), errors.New(\"Image color format error\")\n\t\t}\n\t\tdata = m.Pix\n\n\tdefault:\n\t\tdata := make([]byte, 0, x*y*3)\n\t\tfor j := bounds.Min.Y; j < bounds.Max.Y; j++ {\n\t\t\tfor i := bounds.Min.X; i < bounds.Max.X; i++ {\n\t\t\t\tr, g, b, _ := img.At(i, j).RGBA()\n\t\t\t\tdata = append(data, byte(b>>8), byte(g>>8), byte(r>>8))\n\t\t\t}\n\t\t}\n\t\treturn NewMatFromBytes(y, x, MatTypeCV8UC3, data)\n\t}\n\n\t// speed up the conversion process of RGBA format\n\tcvt, err := NewMatFromBytes(y, x, MatTypeCV8UC4, data)\n\tif err != nil {\n\t\treturn NewMat(), err\n\t}\n\n\tdefer cvt.Close()\n\n\tdst := NewMat()\n\tC.CvtColor(cvt.p, dst.p, C.int(ColorBGRAToRGBA))\n\treturn dst, nil\n}\n\n// ImageToMatRGB converts image.Image to gocv.Mat,\n// which represents RGB image having 8bit for each component.\n// Type of Mat is gocv.MatTypeCV8UC3.\nfunc ImageToMatRGB(img image.Image) (Mat, error) {\n\tbounds := img.Bounds()\n\tx := bounds.Dx()\n\ty := bounds.Dy()\n\n\tvar data []uint8\n\tswitch img.ColorModel() {\n\tcase color.RGBAModel:\n\t\tm, res := img.(*image.RGBA)\n\t\tif true != res {\n\t\t\treturn NewMat(), errors.New(\"Image color format error\")\n\t\t}\n\t\tdata = m.Pix\n\t\t// speed up the conversion process of RGBA format\n\t\tsrc, err := NewMatFromBytes(y, x, MatTypeCV8UC4, data)\n\t\tif err != nil {\n\t\t\treturn NewMat(), err\n\t\t}\n\t\tdefer src.Close()\n\n\t\tdst := NewMat()\n\t\tCvtColor(src, &dst, ColorRGBAToBGR)\n\t\treturn dst, nil\n\n\tdefault:\n\t\tdata := make([]byte, 0, x*y*3)\n\t\tfor j := bounds.Min.Y; j < bounds.Max.Y; j++ {\n\t\t\tfor i := bounds.Min.X; i < bounds.Max.X; i++ {\n\t\t\t\tr, g, b, _ := img.At(i, j).RGBA()\n\t\t\t\tdata = append(data, byte(b>>8), byte(g>>8), byte(r>>8))\n\t\t\t}\n\t\t}\n\t\treturn NewMatFromBytes(y, x, MatTypeCV8UC3, data)\n\t}\n}\n\n// ImageGrayToMatGray converts image.Gray to gocv.Mat,\n// which represents grayscale image 8bit.\n// Type of Mat is gocv.MatTypeCV8UC1.\nfunc ImageGrayToMatGray(img *image.Gray) (Mat, error) {\n\tbounds := img.Bounds()\n\tx := bounds.Dx()\n\ty := bounds.Dy()\n\tm, err := NewMatFromBytes(y, x, MatTypeCV8UC1, img.Pix)\n\tif err != nil {\n\t\treturn NewMat(), err\n\t}\n\treturn m, nil\n}\n\n// Adds the square of a source image to the accumulator image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/df3/group__imgproc__motion.html#ga1a567a79901513811ff3b9976923b199\n//\n\nfunc Accumulate(src Mat, dst *Mat) {\n\tC.Mat_Accumulate(src.p, dst.p)\n}\n\n// Adds an image to the accumulator image with mask.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/df3/group__imgproc__motion.html#ga1a567a79901513811ff3b9976923b199\nfunc AccumulateWithMask(src Mat, dst *Mat, mask Mat) {\n\tC.Mat_AccumulateWithMask(src.p, dst.p, mask.p)\n}\n\n// Adds the square of a source image to the accumulator image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/df3/group__imgproc__motion.html#gacb75e7ffb573227088cef9ceaf80be8c\nfunc AccumulateSquare(src Mat, dst *Mat) {\n\tC.Mat_AccumulateSquare(src.p, dst.p)\n}\n\n// Adds the square of a source image to the accumulator image with mask.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/df3/group__imgproc__motion.html#gacb75e7ffb573227088cef9ceaf80be8c\nfunc AccumulateSquareWithMask(src Mat, dst *Mat, mask Mat) {\n\tC.Mat_AccumulateSquareWithMask(src.p, dst.p, mask.p)\n}\n\n// Adds the per-element product of two input images to the accumulator image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/df3/group__imgproc__motion.html#ga82518a940ecfda49460f66117ac82520\nfunc AccumulateProduct(src1 Mat, src2 Mat, dst *Mat) {\n\tC.Mat_AccumulateProduct(src1.p, src2.p, dst.p)\n}\n\n// Adds the per-element product of two input images to the accumulator image with mask.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/df3/group__imgproc__motion.html#ga82518a940ecfda49460f66117ac82520\nfunc AccumulateProductWithMask(src1 Mat, src2 Mat, dst *Mat, mask Mat) {\n\tC.Mat_AccumulateProductWithMask(src1.p, src2.p, dst.p, mask.p)\n}\n\n// Updates a running average.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/df3/group__imgproc__motion.html#ga4f9552b541187f61f6818e8d2d826bc7\nfunc AccumulatedWeighted(src Mat, dst *Mat, alpha float64) {\n\tC.Mat_AccumulatedWeighted(src.p, dst.p, C.double(alpha))\n}\n\n// Updates a running average with mask.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/df3/group__imgproc__motion.html#ga4f9552b541187f61f6818e8d2d826bc7\nfunc AccumulatedWeightedWithMask(src Mat, dst *Mat, alpha float64, mask Mat) {\n\tC.Mat_AccumulatedWeightedWithMask(src.p, dst.p, C.double(alpha), mask.p)\n}\n"
        },
        {
          "name": "imgproc.h",
          "type": "blob",
          "size": 9.3359375,
          "content": "#ifndef _OPENCV3_IMGPROC_H_\n#define _OPENCV3_IMGPROC_H_\n\n#include <stdbool.h>\n\n#ifdef __cplusplus\n#include <opencv2/opencv.hpp>\nextern \"C\" {\n#endif\n\n#ifdef __cplusplus\ntypedef cv::Ptr<cv::CLAHE>* CLAHE;\n#else\ntypedef void* CLAHE;\n#endif\n\n#include \"core.h\"\n\ndouble ArcLength(PointVector curve, bool is_closed);\nPointVector ApproxPolyDP(PointVector curve, double epsilon, bool closed);\nvoid CvtColor(Mat src, Mat dst, int code);\nvoid Demosaicing(Mat src, Mat dst, int code);\nvoid EqualizeHist(Mat src, Mat dst);\nvoid CalcHist(struct Mats mats, IntVector chans, Mat mask, Mat hist, IntVector sz, FloatVector rng, bool acc);\nvoid CalcBackProject(struct Mats mats, IntVector chans, Mat hist, Mat backProject, FloatVector rng, bool uniform);\ndouble CompareHist(Mat hist1, Mat hist2, int method);\nfloat EMD(Mat sig1, Mat sig2, int distType);\nvoid ConvexHull(PointVector points, Mat hull, bool clockwise, bool returnPoints);\nvoid ConvexityDefects(PointVector points, Mat hull, Mat result);\nvoid BilateralFilter(Mat src, Mat dst, int d, double sc, double ss);\nvoid Blur(Mat src, Mat dst, Size ps);\nvoid BoxFilter(Mat src, Mat dst, int ddepth, Size ps);\nvoid SqBoxFilter(Mat src, Mat dst, int ddepth, Size ps);\nvoid Dilate(Mat src, Mat dst, Mat kernel);\nvoid DilateWithParams(Mat src, Mat dst, Mat kernel, Point anchor, int iterations, int borderType, Scalar borderValue);\nvoid DistanceTransform(Mat src, Mat dst, Mat labels, int distanceType, int maskSize, int labelType);\nvoid Erode(Mat src, Mat dst, Mat kernel);\nvoid ErodeWithParams(Mat src, Mat dst, Mat kernel, Point anchor, int iterations, int borderType);\nvoid ErodeWithParamsAndBorderValue(Mat src, Mat dst, Mat kernel, Point anchor, int iterations, int borderType, Scalar borderValue);\nvoid MatchTemplate(Mat image, Mat templ, Mat result, int method, Mat mask);\nstruct Moment Moments(Mat src, bool binaryImage);\nvoid PyrDown(Mat src, Mat dst, Size dstsize, int borderType);\nvoid PyrUp(Mat src, Mat dst, Size dstsize, int borderType);\nstruct Rect BoundingRect(PointVector pts);\nvoid BoxPoints(RotatedRect rect, Mat boxPts);\nvoid BoxPoints2f(RotatedRect2f rect, Mat boxPts);\ndouble ContourArea(PointVector pts);\nstruct RotatedRect MinAreaRect(PointVector pts);\nstruct RotatedRect2f MinAreaRect2f(PointVector pts);\nstruct RotatedRect FitEllipse(PointVector pts);\nvoid MinEnclosingCircle(PointVector pts, Point2f* center, float* radius);\nPointsVector FindContours(Mat src, Mat hierarchy, int mode, int method);\ndouble PointPolygonTest(PointVector pts, Point pt, bool measureDist);\nint ConnectedComponents(Mat src, Mat dst, int connectivity, int ltype, int ccltype);\nint ConnectedComponentsWithStats(Mat src, Mat labels, Mat stats, Mat centroids, int connectivity, int ltype, int ccltype);\n\nvoid GaussianBlur(Mat src, Mat dst, Size ps, double sX, double sY, int bt);\nMat GetGaussianKernel(int ksize, double sigma, int ktype);\nvoid Laplacian(Mat src, Mat dst, int dDepth, int kSize, double scale, double delta, int borderType);\nvoid Scharr(Mat src, Mat dst, int dDepth, int dx, int dy, double scale, double delta,\n            int borderType);\nMat GetStructuringElement(int shape, Size ksize);\nScalar MorphologyDefaultBorderValue();\nvoid MorphologyEx(Mat src, Mat dst, int op, Mat kernel);\nvoid MorphologyExWithParams(Mat src, Mat dst, int op, Mat kernel, Point pt, int iterations, int borderType);\nvoid MedianBlur(Mat src, Mat dst, int ksize);\n\nvoid Canny(Mat src, Mat edges, double t1, double t2);\nvoid CornerSubPix(Mat img, Mat corners, Size winSize, Size zeroZone, TermCriteria criteria);\nvoid GoodFeaturesToTrack(Mat img, Mat corners, int maxCorners, double quality, double minDist);\nvoid GrabCut(Mat img, Mat mask, Rect rect, Mat bgdModel, Mat fgdModel, int iterCount, int mode);\nvoid HoughCircles(Mat src, Mat circles, int method, double dp, double minDist);\nvoid HoughCirclesWithParams(Mat src, Mat circles, int method, double dp, double minDist,\n                            double param1, double param2, int minRadius, int maxRadius);\nvoid HoughLines(Mat src, Mat lines, double rho, double theta, int threshold);\nvoid HoughLinesP(Mat src, Mat lines, double rho, double theta, int threshold);\nvoid HoughLinesPWithParams(Mat src, Mat lines, double rho, double theta, int threshold, double minLineLength, double maxLineGap);\nvoid HoughLinesPointSet(Mat points, Mat lines, int lines_max, int threshold,\n                        double min_rho, double  max_rho, double rho_step,\n                        double min_theta, double max_theta, double theta_step);\nvoid Integral(Mat src, Mat sum, Mat sqsum, Mat tilted);\ndouble Threshold(Mat src, Mat dst, double thresh, double maxvalue, int typ);\nvoid AdaptiveThreshold(Mat src, Mat dst, double maxValue, int adaptiveTyp, int typ, int blockSize,\n                       double c);\n\nvoid ArrowedLine(Mat img, Point pt1, Point pt2, Scalar color, int thickness);\nvoid Circle(Mat img, Point center, int radius, Scalar color, int thickness);\nvoid CircleWithParams(Mat img, Point center, int radius, Scalar color, int thickness, int lineType, int shift);\nvoid Ellipse(Mat img, Point center, Point axes, double angle, double\n             startAngle, double endAngle, Scalar color, int thickness);\nvoid EllipseWithParams(Mat img, Point center, Point axes, double angle, double\n             startAngle, double endAngle, Scalar color, int thickness, int lineType, int shift);\nvoid Line(Mat img, Point pt1, Point pt2, Scalar color, int thickness);\nvoid Rectangle(Mat img, Rect rect, Scalar color, int thickness);\nvoid RectangleWithParams(Mat img, Rect rect, Scalar color, int thickness, int lineType, int shift);\nvoid FillPoly(Mat img, PointsVector points, Scalar color);\nvoid FillPolyWithParams(Mat img, PointsVector points, Scalar color, int lineType, int shift, Point offset);\nvoid Polylines(Mat img, PointsVector points, bool isClosed, Scalar color, int thickness);\nstruct Size GetTextSize(const char* text, int fontFace, double fontScale, int thickness);\nstruct Size GetTextSizeWithBaseline(const char* text, int fontFace, double fontScale, int thickness, int* baseline);\nvoid PutText(Mat img, const char* text, Point org, int fontFace, double fontScale,\n             Scalar color, int thickness);\nvoid PutTextWithParams(Mat img, const char* text, Point org, int fontFace, double fontScale,\n                         Scalar color, int thickness, int lineType, bool bottomLeftOrigin);\nvoid Resize(Mat src, Mat dst, Size sz, double fx, double fy, int interp);\nvoid GetRectSubPix(Mat src, Size patchSize, Point center, Mat dst);\nMat GetRotationMatrix2D(Point center, double angle, double scale);\nvoid WarpAffine(Mat src, Mat dst, Mat rot_mat, Size dsize);\nvoid WarpAffineWithParams(Mat src, Mat dst, Mat rot_mat, Size dsize, int flags, int borderMode,\n                          Scalar borderValue);\nvoid WarpPerspective(Mat src, Mat dst, Mat m, Size dsize);\nvoid WarpPerspectiveWithParams(Mat src, Mat dst, Mat rot_mat, Size dsize, int flags, int borderMode,\n                               Scalar borderValue);\nvoid Watershed(Mat image, Mat markers);\nvoid ApplyColorMap(Mat src, Mat dst, int colormap);\nvoid ApplyCustomColorMap(Mat src, Mat dst, Mat colormap);\nMat GetPerspectiveTransform(PointVector src, PointVector dst);\nMat GetPerspectiveTransform2f(Point2fVector src, Point2fVector dst);\nMat GetAffineTransform(PointVector src, PointVector dst);\nMat GetAffineTransform2f(Point2fVector src, Point2fVector dst);\nMat FindHomography(Mat src, Mat dst, int method, double ransacReprojThreshold, Mat mask, const int maxIters, const double confidence) ;\nvoid DrawContours(Mat src, PointsVector contours, int contourIdx, Scalar color, int thickness);\nvoid DrawContoursWithParams(Mat src, PointsVector contours, int contourIdx, Scalar color, int thickness, int lineType, Mat hierarchy, int maxLevel, Point offset);\nvoid Sobel(Mat src, Mat dst, int ddepth, int dx, int dy, int ksize, double scale, double delta, int borderType);\nvoid SpatialGradient(Mat src, Mat dx, Mat dy, int ksize, int borderType);\nvoid Remap(Mat src, Mat dst, Mat map1, Mat map2, int interpolation, int borderMode, Scalar borderValue);\nvoid Filter2D(Mat src, Mat dst, int ddepth, Mat kernel, Point anchor, double delta, int borderType);\nvoid SepFilter2D(Mat src, Mat dst, int ddepth, Mat kernelX, Mat kernelY, Point anchor, double delta, int borderType);\nvoid LogPolar(Mat src, Mat dst, Point center, double m, int flags);\nvoid FitLine(PointVector pts, Mat line, int distType, double param, double reps, double aeps);\nvoid LinearPolar(Mat src, Mat dst, Point center, double maxRadius, int flags);\ndouble MatchShapes(PointVector contour1, PointVector contour2, int method, double parameter);\nbool ClipLine(Size imgSize, Point pt1, Point pt2);\nCLAHE CLAHE_Create();\nCLAHE CLAHE_CreateWithParams(double clipLimit, Size tileGridSize);\nvoid CLAHE_Close(CLAHE c);\nvoid CLAHE_Apply(CLAHE c, Mat src, Mat dst);\nvoid InvertAffineTransform(Mat src, Mat dst);\nPoint2f PhaseCorrelate(Mat src1, Mat src2, Mat window, double* response);\nvoid CreateHanningWindow(Mat dst, Size size, int typ);\nvoid Mat_Accumulate(Mat src, Mat dst);\nvoid Mat_AccumulateWithMask(Mat src, Mat dst, Mat mask);\nvoid Mat_AccumulateSquare(Mat src, Mat dst);\nvoid Mat_AccumulateSquareWithMask(Mat src, Mat dst, Mat mask);\nvoid Mat_AccumulateProduct(Mat src1, Mat src2, Mat dst);\nvoid Mat_AccumulateProductWithMask(Mat src1, Mat src2, Mat dst, Mat mask);\nvoid Mat_AccumulatedWeighted(Mat src, Mat dst, double alpha);\nvoid Mat_AccumulatedWeightedWithMask(Mat src, Mat dst, double alpha, Mat mask);\n#ifdef __cplusplus\n}\n#endif\n\n#endif //_OPENCV3_IMGPROC_H_\n"
        },
        {
          "name": "imgproc_colorcodes.go",
          "type": "blob",
          "size": 13.560546875,
          "content": "package gocv\n\n// ColorConversionCode is a color conversion code used on Mat.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d7/d1b/group__imgproc__misc.html#ga4e0972be5de079fed4e3a10e24ef5ef0\ntype ColorConversionCode int\n\nconst (\n\t// ColorBGRToBGRA adds alpha channel to BGR image.\n\tColorBGRToBGRA ColorConversionCode = 0\n\t// ColorRGBToRGBA adds alpha channel to RGB image.\n\tColorRGBToRGBA ColorConversionCode = ColorBGRToBGRA\n\n\t// ColorBGRAToBGR removes alpha channel from BGR image.\n\tColorBGRAToBGR ColorConversionCode = 1\n\t// ColorRGBAToRGB removes alpha channel from RGB image.\n\tColorRGBAToRGB ColorConversionCode = ColorBGRAToBGR\n\n\t// ColorBGRToRGBA converts from BGR to RGB with alpha channel.\n\tColorBGRToRGBA ColorConversionCode = 2\n\t// ColorRGBToBGRA converts from RGB to BGR with alpha channel.\n\tColorRGBToBGRA ColorConversionCode = ColorBGRToRGBA\n\n\t// ColorRGBAToBGR converts from RGB with alpha to BGR color space.\n\tColorRGBAToBGR ColorConversionCode = 3\n\t// ColorBGRAToRGB converts from BRG with alpha to RGB color space.\n\tColorBGRAToRGB ColorConversionCode = ColorRGBAToBGR\n\n\t// ColorBGRToRGB converts from BGR to RGB without alpha channel.\n\tColorBGRToRGB ColorConversionCode = 4\n\t// ColorRGBToBGR converts from RGB to BGR without alpha channel.\n\tColorRGBToBGR ColorConversionCode = ColorBGRToRGB\n\n\t// ColorBGRAToRGBA converts from BGR with alpha channel\n\t// to RGB with alpha channel.\n\tColorBGRAToRGBA ColorConversionCode = 5\n\t// ColorRGBAToBGRA converts from RGB with alpha channel\n\t// to BGR with alpha channel.\n\tColorRGBAToBGRA ColorConversionCode = ColorBGRAToRGBA\n\n\t// ColorBGRToGray converts from BGR to grayscale.\n\tColorBGRToGray ColorConversionCode = 6\n\n\t// ColorRGBToGray converts from RGB to grayscale.\n\tColorRGBToGray ColorConversionCode = 7\n\n\t// ColorGrayToBGR converts from grayscale to BGR.\n\tColorGrayToBGR ColorConversionCode = 8\n\t// ColorGrayToRGB converts from grayscale to RGB.\n\tColorGrayToRGB ColorConversionCode = ColorGrayToBGR\n\n\t// ColorGrayToBGRA converts from grayscale to BGR with alpha channel.\n\tColorGrayToBGRA ColorConversionCode = 9\n\t// ColorGrayToRGBA converts from grayscale to RGB with alpha channel.\n\tColorGrayToRGBA ColorConversionCode = ColorGrayToBGRA\n\n\t// ColorBGRAToGray converts from BGR with alpha channel to grayscale.\n\tColorBGRAToGray ColorConversionCode = 10\n\n\t// ColorRGBAToGray converts from RGB with alpha channel to grayscale.\n\tColorRGBAToGray ColorConversionCode = 11\n\n\t// ColorBGRToBGR565 converts from BGR to BGR565 (16-bit images).\n\tColorBGRToBGR565 ColorConversionCode = 12\n\n\t// ColorRGBToBGR565 converts from RGB to BGR565 (16-bit images).\n\tColorRGBToBGR565 ColorConversionCode = 13\n\n\t// ColorBGR565ToBGR converts from BGR565 (16-bit images) to BGR.\n\tColorBGR565ToBGR ColorConversionCode = 14\n\n\t// ColorBGR565ToRGB converts from BGR565 (16-bit images) to RGB.\n\tColorBGR565ToRGB ColorConversionCode = 15\n\n\t// ColorBGRAToBGR565 converts from BGRA (with alpha channel)\n\t// to BGR565 (16-bit images).\n\tColorBGRAToBGR565 ColorConversionCode = 16\n\n\t// ColorRGBAToBGR565 converts from RGBA (with alpha channel)\n\t// to BGR565 (16-bit images).\n\tColorRGBAToBGR565 ColorConversionCode = 17\n\n\t// ColorBGR565ToBGRA converts from BGR565 (16-bit images)\n\t// to BGRA (with alpha channel).\n\tColorBGR565ToBGRA ColorConversionCode = 18\n\n\t// ColorBGR565ToRGBA converts from BGR565 (16-bit images)\n\t// to RGBA (with alpha channel).\n\tColorBGR565ToRGBA ColorConversionCode = 19\n\n\t// ColorGrayToBGR565 converts from grayscale\n\t// to BGR565 (16-bit images).\n\tColorGrayToBGR565 ColorConversionCode = 20\n\n\t// ColorBGR565ToGray converts from BGR565 (16-bit images)\n\t// to grayscale.\n\tColorBGR565ToGray ColorConversionCode = 21\n\n\t// ColorBGRToBGR555 converts from BGR to BGR555 (16-bit images).\n\tColorBGRToBGR555 ColorConversionCode = 22\n\n\t// ColorRGBToBGR555 converts from RGB to BGR555 (16-bit images).\n\tColorRGBToBGR555 ColorConversionCode = 23\n\n\t// ColorBGR555ToBGR converts from BGR555 (16-bit images) to BGR.\n\tColorBGR555ToBGR ColorConversionCode = 24\n\n\t// ColorBGR555ToRGB converts from BGR555 (16-bit images) to RGB.\n\tColorBGR555ToRGB ColorConversionCode = 25\n\n\t// ColorBGRAToBGR555 converts from BGRA (with alpha channel)\n\t// to BGR555 (16-bit images).\n\tColorBGRAToBGR555 ColorConversionCode = 26\n\n\t// ColorRGBAToBGR555 converts from RGBA (with alpha channel)\n\t// to BGR555 (16-bit images).\n\tColorRGBAToBGR555 ColorConversionCode = 27\n\n\t// ColorBGR555ToBGRA converts from BGR555 (16-bit images)\n\t// to BGRA (with alpha channel).\n\tColorBGR555ToBGRA ColorConversionCode = 28\n\n\t// ColorBGR555ToRGBA converts from BGR555 (16-bit images)\n\t// to RGBA (with alpha channel).\n\tColorBGR555ToRGBA ColorConversionCode = 29\n\n\t// ColorGrayToBGR555 converts from grayscale to BGR555 (16-bit images).\n\tColorGrayToBGR555 ColorConversionCode = 30\n\n\t// ColorBGR555ToGRAY converts from BGR555 (16-bit images) to grayscale.\n\tColorBGR555ToGRAY ColorConversionCode = 31\n\n\t// ColorBGRToXYZ converts from BGR to CIE XYZ.\n\tColorBGRToXYZ ColorConversionCode = 32\n\n\t// ColorRGBToXYZ converts from RGB to CIE XYZ.\n\tColorRGBToXYZ ColorConversionCode = 33\n\n\t// ColorXYZToBGR converts from CIE XYZ to BGR.\n\tColorXYZToBGR ColorConversionCode = 34\n\n\t// ColorXYZToRGB converts from CIE XYZ to RGB.\n\tColorXYZToRGB ColorConversionCode = 35\n\n\t// ColorBGRToYCrCb converts from BGR to luma-chroma (aka YCC).\n\tColorBGRToYCrCb ColorConversionCode = 36\n\n\t// ColorRGBToYCrCb converts from RGB to luma-chroma (aka YCC).\n\tColorRGBToYCrCb ColorConversionCode = 37\n\n\t// ColorYCrCbToBGR converts from luma-chroma (aka YCC) to BGR.\n\tColorYCrCbToBGR ColorConversionCode = 38\n\n\t// ColorYCrCbToRGB converts from luma-chroma (aka YCC) to RGB.\n\tColorYCrCbToRGB ColorConversionCode = 39\n\n\t// ColorBGRToHSV converts from BGR to HSV (hue saturation value).\n\tColorBGRToHSV ColorConversionCode = 40\n\n\t// ColorRGBToHSV converts from RGB to HSV (hue saturation value).\n\tColorRGBToHSV ColorConversionCode = 41\n\n\t// ColorBGRToLab converts from BGR to CIE Lab.\n\tColorBGRToLab ColorConversionCode = 44\n\n\t// ColorRGBToLab converts from RGB to CIE Lab.\n\tColorRGBToLab ColorConversionCode = 45\n\n\t// ColorBGRToLuv converts from BGR to CIE Luv.\n\tColorBGRToLuv ColorConversionCode = 50\n\n\t// ColorRGBToLuv converts from RGB to CIE Luv.\n\tColorRGBToLuv ColorConversionCode = 51\n\n\t// ColorBGRToHLS converts from BGR to HLS (hue lightness saturation).\n\tColorBGRToHLS ColorConversionCode = 52\n\n\t// ColorRGBToHLS converts from RGB to HLS (hue lightness saturation).\n\tColorRGBToHLS ColorConversionCode = 53\n\n\t// ColorHSVToBGR converts from HSV (hue saturation value) to BGR.\n\tColorHSVToBGR ColorConversionCode = 54\n\n\t// ColorHSVToRGB converts from HSV (hue saturation value) to RGB.\n\tColorHSVToRGB ColorConversionCode = 55\n\n\t// ColorLabToBGR converts from CIE Lab to BGR.\n\tColorLabToBGR ColorConversionCode = 56\n\n\t// ColorLabToRGB converts from CIE Lab to RGB.\n\tColorLabToRGB ColorConversionCode = 57\n\n\t// ColorLuvToBGR converts from CIE Luv to BGR.\n\tColorLuvToBGR ColorConversionCode = 58\n\n\t// ColorLuvToRGB converts from CIE Luv to RGB.\n\tColorLuvToRGB ColorConversionCode = 59\n\n\t// ColorHLSToBGR converts from HLS (hue lightness saturation) to BGR.\n\tColorHLSToBGR ColorConversionCode = 60\n\n\t// ColorHLSToRGB converts from HLS (hue lightness saturation) to RGB.\n\tColorHLSToRGB ColorConversionCode = 61\n\n\t// ColorBGRToHSVFull converts from BGR to HSV (hue saturation value) full.\n\tColorBGRToHSVFull ColorConversionCode = 66\n\n\t// ColorRGBToHSVFull converts from RGB to HSV (hue saturation value) full.\n\tColorRGBToHSVFull ColorConversionCode = 67\n\n\t// ColorBGRToHLSFull converts from BGR to HLS (hue lightness saturation) full.\n\tColorBGRToHLSFull ColorConversionCode = 68\n\n\t// ColorRGBToHLSFull converts from RGB to HLS (hue lightness saturation) full.\n\tColorRGBToHLSFull ColorConversionCode = 69\n\n\t// ColorHSVToBGRFull converts from HSV (hue saturation value) to BGR full.\n\tColorHSVToBGRFull ColorConversionCode = 70\n\n\t// ColorHSVToRGBFull converts from HSV (hue saturation value) to RGB full.\n\tColorHSVToRGBFull ColorConversionCode = 71\n\n\t// ColorHLSToBGRFull converts from HLS (hue lightness saturation) to BGR full.\n\tColorHLSToBGRFull ColorConversionCode = 72\n\n\t// ColorHLSToRGBFull converts from HLS (hue lightness saturation) to RGB full.\n\tColorHLSToRGBFull ColorConversionCode = 73\n\n\t// ColorLBGRToLab converts from LBGR to CIE Lab.\n\tColorLBGRToLab ColorConversionCode = 74\n\n\t// ColorLRGBToLab converts from LRGB to CIE Lab.\n\tColorLRGBToLab ColorConversionCode = 75\n\n\t// ColorLBGRToLuv converts from LBGR to CIE Luv.\n\tColorLBGRToLuv ColorConversionCode = 76\n\n\t// ColorLRGBToLuv converts from LRGB to CIE Luv.\n\tColorLRGBToLuv ColorConversionCode = 77\n\n\t// ColorLabToLBGR converts from CIE Lab to LBGR.\n\tColorLabToLBGR ColorConversionCode = 78\n\n\t// ColorLabToLRGB converts from CIE Lab to LRGB.\n\tColorLabToLRGB ColorConversionCode = 79\n\n\t// ColorLuvToLBGR converts from CIE Luv to LBGR.\n\tColorLuvToLBGR ColorConversionCode = 80\n\n\t// ColorLuvToLRGB converts from CIE Luv to LRGB.\n\tColorLuvToLRGB ColorConversionCode = 81\n\n\t// ColorBGRToYUV converts from BGR to YUV.\n\tColorBGRToYUV ColorConversionCode = 82\n\n\t// ColorRGBToYUV converts from RGB to YUV.\n\tColorRGBToYUV ColorConversionCode = 83\n\n\t// ColorYUVToBGR converts from YUV to BGR.\n\tColorYUVToBGR ColorConversionCode = 84\n\n\t// ColorYUVToRGB converts from YUV to RGB.\n\tColorYUVToRGB ColorConversionCode = 85\n\n\t// ColorYUVToRGBNV12 converts from YUV 4:2:0 to RGB NV12.\n\tColorYUVToRGBNV12 ColorConversionCode = 90\n\n\t// ColorYUVToBGRNV12 converts from YUV 4:2:0 to BGR NV12.\n\tColorYUVToBGRNV12 ColorConversionCode = 91\n\n\t// ColorYUVToRGBNV21 converts from YUV 4:2:0 to RGB NV21.\n\tColorYUVToRGBNV21 ColorConversionCode = 92\n\n\t// ColorYUVToBGRNV21 converts from YUV 4:2:0 to BGR NV21.\n\tColorYUVToBGRNV21 ColorConversionCode = 93\n\n\t// ColorYUVToRGBANV12 converts from YUV 4:2:0 to RGBA NV12.\n\tColorYUVToRGBANV12 ColorConversionCode = 94\n\n\t// ColorYUVToBGRANV12 converts from YUV 4:2:0 to BGRA NV12.\n\tColorYUVToBGRANV12 ColorConversionCode = 95\n\n\t// ColorYUVToRGBANV21 converts from YUV 4:2:0 to RGBA NV21.\n\tColorYUVToRGBANV21 ColorConversionCode = 96\n\n\t// ColorYUVToBGRANV21 converts from YUV 4:2:0 to BGRA NV21.\n\tColorYUVToBGRANV21 ColorConversionCode = 97\n\n\tColorYUVToRGBYV12 ColorConversionCode = 98\n\tColorYUVToBGRYV12 ColorConversionCode = 99\n\tColorYUVToRGBIYUV ColorConversionCode = 100\n\tColorYUVToBGRIYUV ColorConversionCode = 101\n\n\tColorYUVToRGBAYV12 ColorConversionCode = 102\n\tColorYUVToBGRAYV12 ColorConversionCode = 103\n\tColorYUVToRGBAIYUV ColorConversionCode = 104\n\tColorYUVToBGRAIYUV ColorConversionCode = 105\n\n\tColorYUVToGRAY420 ColorConversionCode = 106\n\n\t// YUV 4:2:2 family to RGB\n\tColorYUVToRGBUYVY ColorConversionCode = 107\n\tColorYUVToBGRUYVY ColorConversionCode = 108\n\n\tColorYUVToRGBAUYVY ColorConversionCode = 111\n\tColorYUVToBGRAUYVY ColorConversionCode = 112\n\n\tColorYUVToRGBYUY2 ColorConversionCode = 115\n\tColorYUVToBGRYUY2 ColorConversionCode = 116\n\tColorYUVToRGBYVYU ColorConversionCode = 117\n\tColorYUVToBGRYVYU ColorConversionCode = 118\n\n\tColorYUVToRGBAYUY2 ColorConversionCode = 119\n\tColorYUVToBGRAYUY2 ColorConversionCode = 120\n\tColorYUVToRGBAYVYU ColorConversionCode = 121\n\tColorYUVToBGRAYVYU ColorConversionCode = 122\n\n\tColorYUVToGRAYUYVY ColorConversionCode = 123\n\tColorYUVToGRAYYUY2 ColorConversionCode = 124\n\n\t// alpha premultiplication\n\tColorRGBATomRGBA ColorConversionCode = 125\n\tColormRGBAToRGBA ColorConversionCode = 126\n\n\t// RGB to YUV 4:2:0 family\n\tColorRGBToYUVI420 ColorConversionCode = 127\n\tColorBGRToYUVI420 ColorConversionCode = 128\n\n\tColorRGBAToYUVI420 ColorConversionCode = 129\n\tColorBGRAToYUVI420 ColorConversionCode = 130\n\tColorRGBToYUVYV12  ColorConversionCode = 131\n\tColorBGRToYUVYV12  ColorConversionCode = 132\n\tColorRGBAToYUVYV12 ColorConversionCode = 133\n\tColorBGRAToYUVYV12 ColorConversionCode = 134\n\n\t// Demosaicing\n\tColorBayerBGToBGR ColorConversionCode = 46\n\tColorBayerGBToBGR ColorConversionCode = 47\n\tColorBayerRGToBGR ColorConversionCode = 48\n\tColorBayerGRToBGR ColorConversionCode = 49\n\n\tColorBayerBGToRGB ColorConversionCode = ColorBayerRGToBGR\n\tColorBayerGBToRGB ColorConversionCode = ColorBayerGRToBGR\n\tColorBayerRGToRGB ColorConversionCode = ColorBayerBGToBGR\n\tColorBayerGRToRGB ColorConversionCode = ColorBayerGBToBGR\n\n\tColorBayerBGToGRAY ColorConversionCode = 86\n\tColorBayerGBToGRAY ColorConversionCode = 87\n\tColorBayerRGToGRAY ColorConversionCode = 88\n\tColorBayerGRToGRAY ColorConversionCode = 89\n\n\t// Demosaicing using Variable Number of Gradients\n\tColorBayerBGToBGRVNG ColorConversionCode = 62\n\tColorBayerGBToBGRVNG ColorConversionCode = 63\n\tColorBayerRGToBGRVNG ColorConversionCode = 64\n\tColorBayerGRToBGRVNG ColorConversionCode = 65\n\n\tColorBayerBGToRGBVNG ColorConversionCode = ColorBayerRGToBGRVNG\n\tColorBayerGBToRGBVNG ColorConversionCode = ColorBayerGRToBGRVNG\n\tColorBayerRGToRGBVNG ColorConversionCode = ColorBayerBGToBGRVNG\n\tColorBayerGRToRGBVNG ColorConversionCode = ColorBayerGBToBGRVNG\n\n\t// Edge-Aware Demosaicing\n\tColorBayerBGToBGREA ColorConversionCode = 135\n\tColorBayerGBToBGREA ColorConversionCode = 136\n\tColorBayerRGToBGREA ColorConversionCode = 137\n\tColorBayerGRToBGREA ColorConversionCode = 138\n\n\tColorBayerBGToRGBEA ColorConversionCode = ColorBayerRGToBGREA\n\tColorBayerGBToRGBEA ColorConversionCode = ColorBayerGRToBGREA\n\tColorBayerRGToRGBEA ColorConversionCode = ColorBayerBGToBGREA\n\tColorBayerGRToRGBEA ColorConversionCode = ColorBayerGBToBGREA\n\n\t// Demosaicing with alpha channel\n\tColorBayerBGToBGRA ColorConversionCode = 139\n\tColorBayerGBToBGRA ColorConversionCode = 140\n\tColorBayerRGToBGRA ColorConversionCode = 141\n\tColorBayerGRToBGRA ColorConversionCode = 142\n\n\tColorBayerBGToRGBA ColorConversionCode = ColorBayerRGToBGRA\n\tColorBayerGBToRGBA ColorConversionCode = ColorBayerGRToBGRA\n\tColorBayerRGToRGBA ColorConversionCode = ColorBayerBGToBGRA\n\tColorBayerGRToRGBA ColorConversionCode = ColorBayerGBToBGRA\n\n\tColorCOLORCVTMAX ColorConversionCode = 143\n)\n"
        },
        {
          "name": "imgproc_colorcodes_string.go",
          "type": "blob",
          "size": 7.541015625,
          "content": "package gocv\n\nfunc (c ColorConversionCode) String() string {\n\tswitch c {\n\tcase ColorBGRToBGRA:\n\t\treturn \"color-bgr-to-bgra\"\n\tcase ColorBGRAToBGR:\n\t\treturn \"color-bgra-to-bgr\"\n\tcase ColorBGRToRGBA:\n\t\treturn \"color-bgr-to-rgba\"\n\tcase ColorRGBAToBGR:\n\t\treturn \"color-rgba-to-bgr\"\n\tcase ColorBGRToRGB:\n\t\treturn \"color-bgr-to-rgb\"\n\tcase ColorBGRAToRGBA:\n\t\treturn \"color-bgra-to-rgba\"\n\tcase ColorBGRToGray:\n\t\treturn \"color-bgr-to-gray\"\n\tcase ColorRGBToGray:\n\t\treturn \"color-rgb-to-gray\"\n\tcase ColorGrayToBGR:\n\t\treturn \"color-gray-to-bgr\"\n\tcase ColorGrayToBGRA:\n\t\treturn \"color-gray-to-bgra\"\n\tcase ColorBGRAToGray:\n\t\treturn \"color-bgra-to-gray\"\n\tcase ColorRGBAToGray:\n\t\treturn \"color-rgba-to-gray\"\n\tcase ColorBGRToBGR565:\n\t\treturn \"color-bgr-to-bgr565\"\n\tcase ColorRGBToBGR565:\n\t\treturn \"color-rgb-to-bgr565\"\n\tcase ColorBGR565ToBGR:\n\t\treturn \"color-bgr565-to-bgr\"\n\tcase ColorBGR565ToRGB:\n\t\treturn \"color-bgr565-to-rgb\"\n\tcase ColorBGRAToBGR565:\n\t\treturn \"color-bgra-to-bgr565\"\n\tcase ColorRGBAToBGR565:\n\t\treturn \"color-rgba-to-bgr565\"\n\tcase ColorBGR565ToBGRA:\n\t\treturn \"color-bgr565-to-bgra\"\n\tcase ColorBGR565ToRGBA:\n\t\treturn \"color-bgr565-to-rgba\"\n\tcase ColorGrayToBGR565:\n\t\treturn \"color-gray-to-bgr565\"\n\tcase ColorBGR565ToGray:\n\t\treturn \"color-bgr565-to-gray\"\n\tcase ColorBGRToBGR555:\n\t\treturn \"color-bgr-to-bgr555\"\n\tcase ColorRGBToBGR555:\n\t\treturn \"color-rgb-to-bgr555\"\n\tcase ColorBGR555ToBGR:\n\t\treturn \"color-bgr555-to-bgr\"\n\tcase ColorBGRAToBGR555:\n\t\treturn \"color-bgra-to-bgr555\"\n\tcase ColorRGBAToBGR555:\n\t\treturn \"color-rgba-to-bgr555\"\n\tcase ColorBGR555ToBGRA:\n\t\treturn \"color-bgr555-to-bgra\"\n\tcase ColorBGR555ToRGBA:\n\t\treturn \"color-bgr555-to-rgba\"\n\tcase ColorGrayToBGR555:\n\t\treturn \"color-gray-to-bgr555\"\n\tcase ColorBGR555ToGRAY:\n\t\treturn \"color-bgr555-to-gray\"\n\tcase ColorBGRToXYZ:\n\t\treturn \"color-bgr-to-xyz\"\n\tcase ColorRGBToXYZ:\n\t\treturn \"color-rgb-to-xyz\"\n\tcase ColorXYZToBGR:\n\t\treturn \"color-xyz-to-bgr\"\n\tcase ColorXYZToRGB:\n\t\treturn \"color-xyz-to-rgb\"\n\tcase ColorBGRToYCrCb:\n\t\treturn \"color-bgr-to-ycrcb\"\n\tcase ColorRGBToYCrCb:\n\t\treturn \"color-rgb-to-ycrcb\"\n\tcase ColorYCrCbToBGR:\n\t\treturn \"color-ycrcb-to-bgr\"\n\tcase ColorYCrCbToRGB:\n\t\treturn \"color-ycrcb-to-rgb\"\n\tcase ColorBGRToHSV:\n\t\treturn \"color-bgr-to-hsv\"\n\tcase ColorRGBToHSV:\n\t\treturn \"color-rgb-to-hsv\"\n\tcase ColorBGRToLab:\n\t\treturn \"color-bgr-to-lab\"\n\tcase ColorRGBToLab:\n\t\treturn \"color-rgb-to-lab\"\n\tcase ColorBGRToLuv:\n\t\treturn \"color-bgr-to-luv\"\n\tcase ColorRGBToLuv:\n\t\treturn \"color-rgb-to-luv\"\n\tcase ColorBGRToHLS:\n\t\treturn \"color-bgr-to-hls\"\n\tcase ColorRGBToHLS:\n\t\treturn \"color-rgb-to-hls\"\n\tcase ColorHSVToBGR:\n\t\treturn \"color-hsv-to-bgr\"\n\tcase ColorHSVToRGB:\n\t\treturn \"color-hsv-to-rgb\"\n\tcase ColorLabToBGR:\n\t\treturn \"color-lab-to-bgr\"\n\tcase ColorLabToRGB:\n\t\treturn \"color-lab-to-rgb\"\n\tcase ColorLuvToBGR:\n\t\treturn \"color-luv-to-bgr\"\n\tcase ColorLuvToRGB:\n\t\treturn \"color-luv-to-rgb\"\n\tcase ColorHLSToBGR:\n\t\treturn \"color-hls-to-bgr\"\n\tcase ColorHLSToRGB:\n\t\treturn \"color-hls-to-rgb\"\n\tcase ColorBGRToHSVFull:\n\t\treturn \"color-bgr-to-hsv-full\"\n\tcase ColorRGBToHSVFull:\n\t\treturn \"color-rgb-to-hsv-full\"\n\tcase ColorBGRToHLSFull:\n\t\treturn \"color-bgr-to-hls-full\"\n\tcase ColorRGBToHLSFull:\n\t\treturn \"color-rgb-to-hls-full\"\n\tcase ColorHSVToBGRFull:\n\t\treturn \"color-hsv-to-bgr-full\"\n\tcase ColorHSVToRGBFull:\n\t\treturn \"color-hsv-to-rgb-full\"\n\tcase ColorHLSToBGRFull:\n\t\treturn \"color-hls-to-bgr-full\"\n\tcase ColorHLSToRGBFull:\n\t\treturn \"color-hls-to-rgb-full\"\n\tcase ColorLBGRToLab:\n\t\treturn \"color-lbgr-to-lab\"\n\tcase ColorLRGBToLab:\n\t\treturn \"color-lrgb-to-lab\"\n\tcase ColorLBGRToLuv:\n\t\treturn \"color-lbgr-to-luv\"\n\tcase ColorLRGBToLuv:\n\t\treturn \"color-lrgb-to-luv\"\n\tcase ColorLabToLBGR:\n\t\treturn \"color-lab-to-lbgr\"\n\tcase ColorLabToLRGB:\n\t\treturn \"color-lab-to-lrgb\"\n\tcase ColorLuvToLBGR:\n\t\treturn \"color-luv-to-lbgr\"\n\tcase ColorLuvToLRGB:\n\t\treturn \"color-luv-to-lrgb\"\n\tcase ColorBGRToYUV:\n\t\treturn \"color-bgr-to-yuv\"\n\tcase ColorRGBToYUV:\n\t\treturn \"color-rgb-to-yuv\"\n\tcase ColorYUVToBGR:\n\t\treturn \"color-yuv-to-bgr\"\n\tcase ColorYUVToRGB:\n\t\treturn \"color-yuv-to-rgb\"\n\n\tcase ColorYUVToRGBNV12:\n\t\treturn \"color-yuv-to-rgbnv12\"\n\tcase ColorYUVToBGRNV12:\n\t\treturn \"color-yuv-to-bgrnv12\"\n\tcase ColorYUVToRGBNV21:\n\t\treturn \"color-yuv-to-rgbnv21\"\n\tcase ColorYUVToBGRNV21:\n\t\treturn \"color-yuv-to-bgrnv21\"\n\n\tcase ColorYUVToRGBANV12:\n\t\treturn \"color-yuv-to-rgbanv12\"\n\tcase ColorYUVToBGRANV12:\n\t\treturn \"color-yuv-to-bgranv12\"\n\tcase ColorYUVToRGBANV21:\n\t\treturn \"color-yuv-to-rgbanv21\"\n\tcase ColorYUVToBGRANV21:\n\t\treturn \"color-yuv-to-bgranv21\"\n\n\tcase ColorYUVToRGBYV12:\n\t\treturn \"color-yuv-to-rgbyv12\"\n\tcase ColorYUVToBGRYV12:\n\t\treturn \"color-yuv-to-bgryv12\"\n\n\tcase ColorYUVToRGBIYUV:\n\t\treturn \"color-yuv-to-rgbiyuv\"\n\tcase ColorYUVToBGRIYUV:\n\t\treturn \"color-yuv-to-bgriyuv\"\n\n\tcase ColorYUVToRGBAYV12:\n\t\treturn \"color-yuv-to-rgbayv12\"\n\tcase ColorYUVToBGRAYV12:\n\t\treturn \"color-yuv-to-bgrayv12\"\n\tcase ColorYUVToRGBAIYUV:\n\t\treturn \"color-yuv-to-rgbaiyuv\"\n\tcase ColorYUVToBGRAIYUV:\n\t\treturn \"color-yuv-to-bgraiyuv\"\n\n\tcase ColorYUVToGRAY420:\n\t\treturn \"color-yuv-to-gray420\"\n\n\tcase ColorYUVToRGBUYVY:\n\t\treturn \"color-yuv-to-rgbuyvy\"\n\tcase ColorYUVToBGRUYVY:\n\t\treturn \"color-yuv-to-bgruyvy\"\n\n\tcase ColorYUVToRGBAUYVY:\n\t\treturn \"color-yuv-to-rgbauyvy\"\n\tcase ColorYUVToBGRAUYVY:\n\t\treturn \"color-yuv-to-bgrauyvy\"\n\n\tcase ColorYUVToRGBYUY2:\n\t\treturn \"color-yuv-to-rgbyuy2\"\n\tcase ColorYUVToBGRYUY2:\n\t\treturn \"color-yuv-to-bgryuy2\"\n\n\tcase ColorYUVToRGBYVYU:\n\t\treturn \"color-yuv-to-rgbyvyu\"\n\tcase ColorYUVToBGRYVYU:\n\t\treturn \"color-yuv-to-bgryvyu\"\n\n\tcase ColorYUVToRGBAYUY2:\n\t\treturn \"color-yuv-to-rgbayuy2\"\n\tcase ColorYUVToBGRAYUY2:\n\t\treturn \"color-yuv-to-bgrayuy2\"\n\n\tcase ColorYUVToRGBAYVYU:\n\t\treturn \"color-yuv-to-rgbayvyu\"\n\tcase ColorYUVToBGRAYVYU:\n\t\treturn \"color-yuv-to-bgrayvyu\"\n\n\tcase ColorYUVToGRAYUYVY:\n\t\treturn \"color-yuv-to-grayuyvy\"\n\tcase ColorYUVToGRAYYUY2:\n\t\treturn \"color-yuv-to-grayyuy2\"\n\n\tcase ColorRGBATomRGBA:\n\t\treturn \"color-rgba-to-mrgba\"\n\tcase ColormRGBAToRGBA:\n\t\treturn \"color-mrgba-to-rgba\"\n\n\tcase ColorRGBToYUVI420:\n\t\treturn \"color-rgb-to-yuvi420\"\n\tcase ColorBGRToYUVI420:\n\t\treturn \"color-bgr-to-yuvi420\"\n\n\tcase ColorRGBAToYUVI420:\n\t\treturn \"color-rgba-to-yuvi420\"\n\n\tcase ColorBGRAToYUVI420:\n\t\treturn \"color-bgra-to-yuvi420\"\n\tcase ColorRGBToYUVYV12:\n\t\treturn \"color-rgb-to-yuvyv12\"\n\tcase ColorBGRToYUVYV12:\n\t\treturn \"color-bgr-to-yuvyv12\"\n\tcase ColorRGBAToYUVYV12:\n\t\treturn \"color-rgba-to-yuvyv12\"\n\tcase ColorBGRAToYUVYV12:\n\t\treturn \"color-bgra-to-yuvyv12\"\n\n\tcase ColorBayerBGToBGR:\n\t\treturn \"color-bayer-bgt-to-bgr\"\n\tcase ColorBayerGBToBGR:\n\t\treturn \"color-bayer-gbt-to-bgr\"\n\tcase ColorBayerRGToBGR:\n\t\treturn \"color-bayer-rgt-to-bgr\"\n\tcase ColorBayerGRToBGR:\n\t\treturn \"color-bayer-grt-to-bgr\"\n\n\tcase ColorBayerBGToGRAY:\n\t\treturn \"color-bayer-bgt-to-gray\"\n\tcase ColorBayerGBToGRAY:\n\t\treturn \"color-bayer-gbt-to-gray\"\n\tcase ColorBayerRGToGRAY:\n\t\treturn \"color-bayer-rgt-to-gray\"\n\tcase ColorBayerGRToGRAY:\n\t\treturn \"color-bayer-grt-to-gray\"\n\n\tcase ColorBayerBGToBGRVNG:\n\t\treturn \"color-bayer-bgt-to-bgrvng\"\n\tcase ColorBayerGBToBGRVNG:\n\t\treturn \"color-bayer-gbt-to-bgrvng\"\n\tcase ColorBayerRGToBGRVNG:\n\t\treturn \"color-bayer-rgt-to-bgrvng\"\n\tcase ColorBayerGRToBGRVNG:\n\t\treturn \"color-bayer-grt-to-bgrvng\"\n\n\tcase ColorBayerBGToBGREA:\n\t\treturn \"color-bayer-bgt-to-bgrea\"\n\tcase ColorBayerGBToBGREA:\n\t\treturn \"color-bayer-gbt-to-bgrea\"\n\tcase ColorBayerRGToBGREA:\n\t\treturn \"color-bayer-rgt-to-bgrea\"\n\tcase ColorBayerGRToBGREA:\n\t\treturn \"color-bayer-grt-to-bgrea\"\n\n\tcase ColorBayerBGToBGRA:\n\t\treturn \"color-bayer-bgt-to-bgra\"\n\tcase ColorBayerGBToBGRA:\n\t\treturn \"color-bayer-gbt-to-bgra\"\n\tcase ColorBayerRGToBGRA:\n\t\treturn \"color-bayer-rgt-to-bgra\"\n\tcase ColorBayerGRToBGRA:\n\t\treturn \"color-bayer-grt-to-bgra\"\n\tcase ColorCOLORCVTMAX:\n\t\treturn \"color-color-cvt-max\"\n\t}\n\treturn \"\"\n}\n"
        },
        {
          "name": "imgproc_string.go",
          "type": "blob",
          "size": 6.458984375,
          "content": "package gocv\n\nfunc (c HistCompMethod) String() string {\n\tswitch c {\n\tcase HistCmpCorrel:\n\t\treturn \"hist-cmp-correl\"\n\tcase HistCmpChiSqr:\n\t\treturn \"hist-cmp-chi-sqr\"\n\tcase HistCmpIntersect:\n\t\treturn \"hist-cmp-intersect\"\n\tcase HistCmpBhattacharya:\n\t\treturn \"hist-cmp-bhattacharya\"\n\tcase HistCmpChiSqrAlt:\n\t\treturn \"hist-cmp-chi-sqr-alt\"\n\tcase HistCmpKlDiv:\n\t\treturn \"hist-cmp-kl-div\"\n\t}\n\treturn \"\"\n}\n\nfunc (c DistanceTransformLabelTypes) String() string {\n\tswitch c {\n\tcase DistanceLabelCComp:\n\t\treturn \"distance-label-ccomp\"\n\t}\n\treturn \"\"\n}\n\nfunc (c DistanceTransformMasks) String() string {\n\tswitch c {\n\tcase DistanceMask3:\n\t\treturn \"distance-mask3\"\n\t}\n\treturn \"\"\n}\n\nfunc (c RetrievalMode) String() string {\n\tswitch c {\n\tcase RetrievalExternal:\n\t\treturn \"retrieval-external\"\n\tcase RetrievalList:\n\t\treturn \"retrieval-list\"\n\tcase RetrievalCComp:\n\t\treturn \"retrieval-ccomp\"\n\tcase RetrievalTree:\n\t\treturn \"retrieval-tree\"\n\tcase RetrievalFloodfill:\n\t\treturn \"retrieval-floodfill\"\n\t}\n\treturn \"\"\n}\n\nfunc (c ContourApproximationMode) String() string {\n\tswitch c {\n\tcase ChainApproxNone:\n\t\treturn \"chain-approx-none\"\n\tcase ChainApproxSimple:\n\t\treturn \"chain-approx-simple\"\n\tcase ChainApproxTC89L1:\n\t\treturn \"chain-approx-tc89l1\"\n\tcase ChainApproxTC89KCOS:\n\t\treturn \"chain-approx-tc89kcos\"\n\t}\n\treturn \"\"\n}\n\nfunc (c ConnectedComponentsAlgorithmType) String() string {\n\tswitch c {\n\tcase CCL_WU:\n\t\treturn \"ccl-wu\"\n\tcase CCL_DEFAULT:\n\t\treturn \"ccl-default\"\n\tcase CCL_GRANA:\n\t\treturn \"ccl-grana\"\n\t}\n\treturn \"\"\n}\n\nfunc (c ConnectedComponentsTypes) String() string {\n\tswitch c {\n\tcase CC_STAT_LEFT:\n\t\treturn \"cc-stat-left\"\n\tcase CC_STAT_TOP:\n\t\treturn \"cc-stat-top\"\n\tcase CC_STAT_WIDTH:\n\t\treturn \"cc-stat-width\"\n\tcase CC_STAT_AREA:\n\t\treturn \"cc-stat-area\"\n\tcase CC_STAT_MAX:\n\t\treturn \"cc-stat-max\"\n\tcase CC_STAT_HEIGHT:\n\t\treturn \"cc-stat-height\"\n\t}\n\treturn \"\"\n}\n\nfunc (c TemplateMatchMode) String() string {\n\tswitch c {\n\tcase TmSqdiff:\n\t\treturn \"tm-sq-diff\"\n\tcase TmSqdiffNormed:\n\t\treturn \"tm-sq-diff-normed\"\n\tcase TmCcorr:\n\t\treturn \"tm-ccorr\"\n\tcase TmCcorrNormed:\n\t\treturn \"tm-ccorr-normed\"\n\tcase TmCcoeff:\n\t\treturn \"tm-ccoeff\"\n\tcase TmCcoeffNormed:\n\t\treturn \"tm-ccoeff-normed\"\n\t}\n\treturn \"\"\n}\n\nfunc (c MorphShape) String() string {\n\tswitch c {\n\tcase MorphRect:\n\t\treturn \"morph-rect\"\n\tcase MorphCross:\n\t\treturn \"morph-cross\"\n\tcase MorphEllipse:\n\t\treturn \"morph-ellispe\"\n\t}\n\treturn \"\"\n}\n\nfunc (c MorphType) String() string {\n\tswitch c {\n\tcase MorphErode:\n\t\treturn \"morph-erode\"\n\tcase MorphDilate:\n\t\treturn \"morph-dilate\"\n\tcase MorphOpen:\n\t\treturn \"morph-open\"\n\tcase MorphClose:\n\t\treturn \"morph-close\"\n\tcase MorphGradient:\n\t\treturn \"morph-gradient\"\n\tcase MorphTophat:\n\t\treturn \"morph-tophat\"\n\tcase MorphBlackhat:\n\t\treturn \"morph-blackhat\"\n\tcase MorphHitmiss:\n\t\treturn \"morph-hitmiss\"\n\t}\n\treturn \"\"\n}\n\nfunc (c BorderType) String() string {\n\tswitch c {\n\tcase BorderConstant:\n\t\treturn \"border-constant\"\n\tcase BorderReplicate:\n\t\treturn \"border-replicate\"\n\tcase BorderReflect:\n\t\treturn \"border-reflect\"\n\tcase BorderWrap:\n\t\treturn \"border-wrap\"\n\tcase BorderTransparent:\n\t\treturn \"border-transparent\"\n\tcase BorderDefault:\n\t\treturn \"border-default\"\n\tcase BorderIsolated:\n\t\treturn \"border-isolated\"\n\t}\n\treturn \"\"\n}\n\nfunc (c GrabCutMode) String() string {\n\tswitch c {\n\tcase GCInitWithRect:\n\t\treturn \"gc-init-with-rect\"\n\tcase GCInitWithMask:\n\t\treturn \"gc-init-with-mask\"\n\tcase GCEval:\n\t\treturn \"gc-eval\"\n\tcase GCEvalFreezeModel:\n\t\treturn \"gc-eval-freeze-model\"\n\t}\n\treturn \"\"\n}\n\nfunc (c HoughMode) String() string {\n\tswitch c {\n\tcase HoughStandard:\n\t\treturn \"hough-standard\"\n\tcase HoughProbabilistic:\n\t\treturn \"hough-probabilistic\"\n\tcase HoughMultiScale:\n\t\treturn \"hough-multi-scale\"\n\tcase HoughGradient:\n\t\treturn \"hough-gradient\"\n\t}\n\treturn \"\"\n}\n\nfunc (c ThresholdType) String() string {\n\tswitch c {\n\tcase ThresholdBinary:\n\t\treturn \"threshold-binary\"\n\tcase ThresholdBinaryInv:\n\t\treturn \"threshold-binary-inv\"\n\tcase ThresholdTrunc:\n\t\treturn \"threshold-trunc\"\n\tcase ThresholdToZero:\n\t\treturn \"threshold-to-zero\"\n\tcase ThresholdToZeroInv:\n\t\treturn \"threshold-to-zero-inv\"\n\tcase ThresholdMask:\n\t\treturn \"threshold-mask\"\n\tcase ThresholdOtsu:\n\t\treturn \"threshold-otsu\"\n\tcase ThresholdTriangle:\n\t\treturn \"threshold-triangle\"\n\t}\n\treturn \"\"\n}\n\nfunc (c AdaptiveThresholdType) String() string {\n\tswitch c {\n\tcase AdaptiveThresholdMean:\n\t\treturn \"adaptative-threshold-mean\"\n\tcase AdaptiveThresholdGaussian:\n\t\treturn \"adaptative-threshold-gaussian\"\n\t}\n\treturn \"\"\n}\n\nfunc (c HersheyFont) String() string {\n\tswitch c {\n\tcase FontHersheySimplex:\n\t\treturn \"font-hershey-simplex\"\n\tcase FontHersheyPlain:\n\t\treturn \"font-hershey-plain\"\n\tcase FontHersheyDuplex:\n\t\treturn \"font-hershey-duplex\"\n\tcase FontHersheyComplex:\n\t\treturn \"font-hershey-complex\"\n\tcase FontHersheyTriplex:\n\t\treturn \"font-hershey-triplex\"\n\tcase FontHersheyComplexSmall:\n\t\treturn \"font-hershey-complex-small\"\n\tcase FontHersheyScriptSimplex:\n\t\treturn \"font-hershey-script-simplex\"\n\tcase FontHersheyScriptComplex:\n\t\treturn \"font-hershey-scipt-complex\"\n\tcase FontItalic:\n\t\treturn \"font-italic\"\n\t}\n\treturn \"\"\n}\n\nfunc (c LineType) String() string {\n\tswitch c {\n\tcase Filled:\n\t\treturn \"filled\"\n\tcase Line4:\n\t\treturn \"line4\"\n\tcase Line8:\n\t\treturn \"line8\"\n\tcase LineAA:\n\t\treturn \"line-aa\"\n\t}\n\treturn \"\"\n}\n\nfunc (c InterpolationFlags) String() string {\n\tswitch c {\n\tcase InterpolationNearestNeighbor:\n\t\treturn \"interpolation-nearest-neighbor\"\n\tcase InterpolationLinear:\n\t\treturn \"interpolation-linear\"\n\tcase InterpolationCubic:\n\t\treturn \"interpolation-cubic\"\n\tcase InterpolationArea:\n\t\treturn \"interpolation-area\"\n\tcase InterpolationLanczos4:\n\t\treturn \"interpolation-lanczos4\"\n\tcase InterpolationMax:\n\t\treturn \"interpolation-max\"\n\t}\n\treturn \"\"\n}\n\nfunc (c ColormapTypes) String() string {\n\tswitch c {\n\tcase ColormapAutumn:\n\t\treturn \"colormap-autumn\"\n\tcase ColormapBone:\n\t\treturn \"colormap-bone\"\n\tcase ColormapJet:\n\t\treturn \"colormap-jet\"\n\tcase ColormapWinter:\n\t\treturn \"colormap-winter\"\n\tcase ColormapRainbow:\n\t\treturn \"colormap-rainbow\"\n\tcase ColormapOcean:\n\t\treturn \"colormap-ocean\"\n\tcase ColormapSummer:\n\t\treturn \"colormap-summer\"\n\tcase ColormapSpring:\n\t\treturn \"colormap-spring\"\n\tcase ColormapCool:\n\t\treturn \"colormap-cool\"\n\tcase ColormapHsv:\n\t\treturn \"colormap-hsv\"\n\tcase ColormapPink:\n\t\treturn \"colormap-pink\"\n\tcase ColormapParula:\n\t\treturn \"colormap-parula\"\n\t}\n\treturn \"\"\n}\n\nfunc (c DistanceTypes) String() string {\n\tswitch c {\n\tcase DistUser:\n\t\treturn \"dist-user\"\n\tcase DistL1:\n\t\treturn \"dist-l1\"\n\tcase DistL2:\n\t\treturn \"dist-l2\"\n\tcase DistL12:\n\t\treturn \"dist-l12\"\n\tcase DistFair:\n\t\treturn \"dist-fair\"\n\tcase DistWelsch:\n\t\treturn \"dist-welsch\"\n\tcase DistHuber:\n\t\treturn \"dist-huber\"\n\t}\n\treturn \"\"\n}\n"
        },
        {
          "name": "imgproc_test.go",
          "type": "blob",
          "size": 78.5185546875,
          "content": "package gocv\n\nimport (\n\t\"fmt\"\n\t\"image\"\n\t\"image/color\"\n\t\"image/draw\"\n\t\"log\"\n\t\"math\"\n\t\"os\"\n\t\"reflect\"\n\t\"runtime\"\n\t\"testing\"\n)\n\nfunc TestApproxPolyDP(t *testing.T) {\n\timg := NewMatWithSize(100, 200, MatTypeCV8UC1)\n\tdefer img.Close()\n\n\twhite := color.RGBA{255, 255, 255, 255}\n\t// Draw triangle\n\tLine(&img, image.Pt(25, 25), image.Pt(25, 75), white, 1)\n\tLine(&img, image.Pt(25, 75), image.Pt(75, 50), white, 1)\n\tLine(&img, image.Pt(75, 50), image.Pt(25, 25), white, 1)\n\t// Draw rectangle\n\tRectangle(&img, image.Rect(125, 25, 175, 75), white, 1)\n\n\tcontours := FindContours(img, RetrievalExternal, ChainApproxSimple)\n\tdefer contours.Close()\n\n\ttrianglePerimeter := ArcLength(contours.At(0), true)\n\ttriangleContour := ApproxPolyDP(contours.At(0), 0.04*trianglePerimeter, true)\n\tdefer triangleContour.Close()\n\n\texpectedTriangleContour := []image.Point{image.Pt(25, 25), image.Pt(25, 75), image.Pt(75, 50)}\n\tactualTriangleContour := triangleContour.ToPoints()\n\tif !reflect.DeepEqual(actualTriangleContour, expectedTriangleContour) {\n\t\tt.Errorf(\"Failed to approximate triangle.\\nActual:%v\\nExpect:%v\", actualTriangleContour, expectedTriangleContour)\n\t}\n\n\trectPerimeter := ArcLength(contours.At(1), true)\n\trectContour := ApproxPolyDP(contours.At(1), 0.04*rectPerimeter, true)\n\tdefer rectContour.Close()\n\n\tactualRectContour := rectContour.ToPoints()\n\texpectedRectContour := []image.Point{image.Pt(125, 24), image.Pt(124, 75), image.Pt(175, 76), image.Pt(176, 25)}\n\tif !reflect.DeepEqual(actualRectContour, expectedRectContour) {\n\t\tt.Errorf(\"Failed to approximate rectangle.\\nActual:%v\\nExpect:%v\", actualRectContour, expectedRectContour)\n\t}\n}\n\nfunc TestConvexity(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in FindContours test\")\n\t}\n\tdefer img.Close()\n\n\tres := FindContours(img, RetrievalExternal, ChainApproxSimple)\n\tdefer res.Close()\n\n\tif res.Size() < 1 {\n\t\tt.Error(\"Invalid FindContours test\")\n\t}\n\n\tarea := ContourArea(res.At(0))\n\tif area != 127280.0 {\n\t\tt.Errorf(\"Invalid ContourArea test: %f\", area)\n\t}\n\n\thull := NewMat()\n\tdefer hull.Close()\n\n\tConvexHull(res.At(0), &hull, true, false)\n\tif hull.Empty() {\n\t\tt.Error(\"Invalid ConvexHull test\")\n\t}\n\n\tdefects := NewMat()\n\tdefer defects.Close()\n\n\tConvexityDefects(res.At(0), hull, &defects)\n\tif defects.Empty() {\n\t\tt.Error(\"Invalid ConvexityDefects test\")\n\t}\n}\n\nfunc TestMinEnclosingCircle(t *testing.T) {\n\tpts := []image.Point{\n\t\timage.Pt(0, 2),\n\t\timage.Pt(2, 0),\n\t\timage.Pt(0, -2),\n\t\timage.Pt(-2, 0),\n\t\timage.Pt(1, -1),\n\t}\n\tpv := NewPointVectorFromPoints(pts)\n\tdefer pv.Close()\n\n\tx, y, radius := MinEnclosingCircle(pv)\n\tconst epsilon = 0.001\n\tif math.Abs(float64(radius-2.0)) > epsilon ||\n\t\tmath.Abs(float64(x-0.0)) > epsilon ||\n\t\tmath.Abs(float64(y-0.0)) > epsilon {\n\t\tt.Error(\"Invalid circle returned in MinEnclosingCircle test\")\n\t}\n}\n\nfunc TestCvtColor(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in CvtColor test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tCvtColor(img, &dest, ColorBGRAToGray)\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid convert in CvtColor test\")\n\t}\n}\n\nfunc NewBayerFromMat(src Mat, pattern string) (Mat, error) {\n\tdest := NewMatWithSize(src.Rows(), src.Cols(), MatTypeCV8UC1)\n\n\tswitch pattern {\n\tcase \"bg\":\n\t\tfor y := 0; y < src.Rows(); y++ {\n\t\t\tfor x := 0; x < src.Cols(); x++ {\n\t\t\t\tif (x+y)%2 != 0 {\n\t\t\t\t\tdest.SetUCharAt(y, x, src.GetVecbAt(y, x)[1])\n\t\t\t\t} else if (x % 2) != 0 {\n\t\t\t\t\tdest.SetUCharAt(y, x, src.GetVecbAt(y, x)[0])\n\t\t\t\t} else {\n\t\t\t\t\tdest.SetUCharAt(y, x, src.GetVecbAt(y, x)[2])\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\tcase \"gb\":\n\t\tfor y := 0; y < src.Rows(); y++ {\n\t\t\tfor x := 0; x < src.Cols(); x++ {\n\t\t\t\tif (x+y)%2 == 0 {\n\t\t\t\t\tdest.SetUCharAt(y, x, src.GetVecbAt(y, x)[1])\n\t\t\t\t} else if (x % 2) == 0 {\n\t\t\t\t\tdest.SetUCharAt(y, x, src.GetVecbAt(y, x)[0])\n\t\t\t\t} else {\n\t\t\t\t\tdest.SetUCharAt(y, x, src.GetVecbAt(y, x)[2])\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\tcase \"rg\":\n\t\tfor y := 0; y < src.Rows(); y++ {\n\t\t\tfor x := 0; x < src.Cols(); x++ {\n\t\t\t\tif (x+y)%2 != 0 {\n\t\t\t\t\tdest.SetUCharAt(y, x, src.GetVecbAt(y, x)[1])\n\t\t\t\t} else if (x % 2) == 0 {\n\t\t\t\t\tdest.SetUCharAt(y, x, src.GetVecbAt(y, x)[0])\n\t\t\t\t} else {\n\t\t\t\t\tdest.SetUCharAt(y, x, src.GetVecbAt(y, x)[2])\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\tcase \"gr\":\n\t\tfor y := 0; y < src.Rows(); y++ {\n\t\t\tfor x := 0; x < src.Cols(); x++ {\n\t\t\t\tif (x+y)%2 == 0 {\n\t\t\t\t\tdest.SetUCharAt(y, x, src.GetVecbAt(y, x)[1])\n\t\t\t\t} else if (x % 2) != 0 {\n\t\t\t\t\tdest.SetUCharAt(y, x, src.GetVecbAt(y, x)[0])\n\t\t\t\t} else {\n\t\t\t\t\tdest.SetUCharAt(y, x, src.GetVecbAt(y, x)[2])\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\tdefault:\n\t\tdest.Close()\n\t\treturn Mat{}, fmt.Errorf(\"invalid pattern: %s\", pattern)\n\t}\n\n\treturn dest, nil\n}\n\nfunc TestDemosaicing(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in Demosaicing test\")\n\t}\n\tdefer img.Close()\n\n\tpatterns := map[string]ColorConversionCode{\n\t\t\"bg\": ColorBayerBGToBGR,\n\t\t\"gb\": ColorBayerGBToBGR,\n\t\t\"rg\": ColorBayerRGToBGR,\n\t\t\"gr\": ColorBayerGRToBGR,\n\t}\n\n\tfor pattern, code := range patterns {\n\t\tbayerImg, err := NewBayerFromMat(img, pattern)\n\t\tif bayerImg.Empty() {\n\t\t\tt.Error(\"Invalid conversion from Mat to Bayer in Demosaicing test\")\n\t\t}\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\n\t\tdest := NewMat()\n\n\t\tDemosaicing(bayerImg, &dest, code)\n\t\tif dest.Empty() || bayerImg.Rows() != dest.Rows() || bayerImg.Cols() != dest.Cols() {\n\t\t\tt.Error(\"Invalid convert in Demosaicing test\")\n\t\t}\n\n\t\tbayerImg.Close()\n\t\tdest.Close()\n\t}\n}\n\nfunc TestBilateralFilter(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in BilateralFilter test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tBilateralFilter(img, &dest, 1, 2.0, 3.0)\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid BilateralFilter test\")\n\t}\n}\n\nfunc TestBlur(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in GaussianBlur test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tBlur(img, &dest, image.Pt(3, 3))\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid Blur test\")\n\t}\n}\n\nfunc TestSobel(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in Sobel test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tSobel(img, &dest, MatTypeCV16S, 0, 1, 3, 1, 0, BorderDefault)\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid Sober test\")\n\t}\n}\n\nfunc TestSpatialGradient(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in SpatialGradient test\")\n\t}\n\tdefer img.Close()\n\n\tdx := NewMat()\n\tdefer dx.Close()\n\n\tdy := NewMat()\n\tdefer dy.Close()\n\n\tSpatialGradient(img, &dx, &dy, MatTypeCV16S, BorderDefault)\n\tif dx.Empty() || dy.Empty() || img.Rows() != dx.Rows() || img.Rows() != dy.Rows() || img.Cols() != dx.Cols() || img.Cols() != dy.Cols() {\n\t\tt.Error(\"Invalid SpatialGradient test\")\n\t}\n}\n\nfunc TestBoxFilter(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in BoxFilter test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tBoxFilter(img, &dest, -1, image.Pt(3, 3))\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid BoxFilter test\")\n\t}\n}\n\nfunc TestSqBoxFilter(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in SqBoxFilter test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tSqBoxFilter(img, &dest, -1, image.Pt(3, 3))\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid SqBoxFilter test\")\n\t}\n}\n\nfunc TestDilate(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in Dilate test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tkernel := GetStructuringElement(MorphRect, image.Pt(1, 1))\n\tdefer kernel.Close()\n\n\tDilate(img, &dest, kernel)\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid Dilate test\")\n\t}\n}\n\nfunc TestDilateWithParams(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in DilateWithParams test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tkernel := GetStructuringElement(MorphRect, image.Pt(1, 1))\n\tdefer kernel.Close()\n\n\tDilateWithParams(img, &dest, kernel, image.Pt(-1, -1), 3, 0, color.RGBA{0, 0, 0, 0})\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid DilateWithParams test\")\n\t}\n}\n\nfunc TestDistanceTransform(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in DistanceTransform test\")\n\t}\n\tdefer img.Close()\n\n\tgray := NewMat()\n\tdefer gray.Close()\n\tCvtColor(img, &gray, ColorBGRToGray)\n\n\tthreshImg := NewMat()\n\tdefer threshImg.Close()\n\tThreshold(gray, &threshImg, 25, 255, ThresholdBinary)\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tlabels := NewMat()\n\tdefer labels.Close()\n\n\tDistanceTransform(threshImg, &dest, &labels, DistL2, DistanceMask3, DistanceLabelCComp)\n\tif dest.Empty() || dest.Rows() != img.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid DistanceTransform test\")\n\t}\n}\n\nfunc TestMatchTemplate(t *testing.T) {\n\timgScene := IMRead(\"images/face.jpg\", IMReadGrayScale)\n\tif imgScene.Empty() {\n\t\tt.Error(\"Invalid read of face.jpg in MatchTemplate test\")\n\t}\n\tdefer imgScene.Close()\n\n\timgTemplate := IMRead(\"images/toy.jpg\", IMReadGrayScale)\n\tif imgTemplate.Empty() {\n\t\tt.Error(\"Invalid read of toy.jpg in MatchTemplate test\")\n\t}\n\tdefer imgTemplate.Close()\n\n\tresult := NewMat()\n\tdefer result.Close()\n\tm := NewMat()\n\tMatchTemplate(imgScene, imgTemplate, &result, TmCcoeffNormed, m)\n\tm.Close()\n\t_, maxConfidence, _, _ := MinMaxLoc(result)\n\tif maxConfidence < 0.95 {\n\t\tt.Errorf(\"Max confidence of %f is too low. MatchTemplate could not find template in scene.\", maxConfidence)\n\t}\n}\n\nfunc TestMoments(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in Moments test\")\n\t}\n\tdefer img.Close()\n\n\tresult := Moments(img, true)\n\tif len(result) < 1 {\n\t\tt.Errorf(\"Invalid Moments test: %v\", result)\n\t}\n}\n\nfunc TestPyrDown(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in PyrDown test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tPyrDown(img, &dest, image.Point{X: dest.Cols(), Y: dest.Rows()}, BorderDefault)\n\tif dest.Empty() && math.Abs(float64(img.Cols()-2*dest.Cols())) < 2.0 && math.Abs(float64(img.Rows()-2*dest.Rows())) < 2.0 {\n\t\tt.Error(\"Invalid PyrDown test\")\n\t}\n}\n\nfunc TestPyrUp(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in PyrUp test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tPyrUp(img, &dest, image.Point{X: dest.Cols(), Y: dest.Rows()}, BorderDefault)\n\tif dest.Empty() && math.Abs(float64(2*img.Cols()-dest.Cols())) < 2.0 && math.Abs(float64(2*img.Rows()-dest.Rows())) < 2.0 {\n\t\tt.Error(\"Invalid PyrUp test\")\n\t}\n}\n\nfunc TestBoxPoints(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in BoxPoints test\")\n\t}\n\tdefer img.Close()\n\n\tthreshImg := NewMat()\n\tdefer threshImg.Close()\n\n\tThreshold(img, &threshImg, 25, 255, ThresholdBinary)\n\n\tcontours := FindContours(threshImg, RetrievalExternal, ChainApproxSimple)\n\tdefer contours.Close()\n\n\tcontour := contours.At(0)\n\n\thull := NewMat()\n\tdefer hull.Close()\n\tConvexHull(contour, &hull, false, false)\n\thullPoints := []image.Point{}\n\tfor i := 0; i < hull.Cols(); i++ {\n\t\tfor j := 0; j < hull.Rows(); j++ {\n\t\t\tp := hull.GetIntAt(j, i)\n\t\t\thullPoints = append(hullPoints, contour.At(int(p)))\n\t\t}\n\t}\n\n\tpvhp := NewPointVectorFromPoints(hullPoints)\n\tdefer pvhp.Close()\n\n\trect := MinAreaRect(pvhp)\n\tpts := NewMat()\n\tdefer pts.Close()\n\tBoxPoints(rect, &pts)\n\n\tif pts.Empty() || pts.Rows() != 4 || pts.Cols() != 2 {\n\t\tt.Error(\"Invalid BoxPoints test\")\n\t}\n}\n\nfunc TestMinAreaRect(t *testing.T) {\n\tsrc := []image.Point{\n\t\timage.Pt(0, 2),\n\t\timage.Pt(2, 0),\n\t\timage.Pt(4, 2),\n\t\timage.Pt(2, 4),\n\t}\n\n\tpv := NewPointVectorFromPoints(src)\n\tdefer pv.Close()\n\n\tm := MinAreaRect(pv)\n\n\tif m.Center.X != 2 {\n\t\tt.Errorf(\"TestMinAreaRect(): unexpected center.X = %v, want = %v\", m.Center.X, 2)\n\t}\n\tif m.Center.Y != 2 {\n\t\tt.Errorf(\"TestMinAreaRect(): unexpected center.Y = %v, want = %v\", m.Center.Y, 2)\n\t}\n\tif m.Angle != 45.0 {\n\t\tt.Errorf(\"TestMinAreaRect(): unexpected angle = %v, want = %v\", m.Angle, 45.0)\n\t}\n}\n\nfunc TestBoxPoints2f(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in BoxPoints2f test\")\n\t}\n\tdefer img.Close()\n\n\tthreshImg := NewMat()\n\tdefer threshImg.Close()\n\n\tThreshold(img, &threshImg, 25, 255, ThresholdBinary)\n\n\tcontours := FindContours(threshImg, RetrievalExternal, ChainApproxSimple)\n\tdefer contours.Close()\n\n\tcontour := contours.At(0)\n\n\thull := NewMat()\n\tdefer hull.Close()\n\tConvexHull(contour, &hull, false, false)\n\thullPoints := []image.Point{}\n\tfor i := 0; i < hull.Cols(); i++ {\n\t\tfor j := 0; j < hull.Rows(); j++ {\n\t\t\tp := hull.GetIntAt(j, i)\n\t\t\thullPoints = append(hullPoints, contour.At(int(p)))\n\t\t}\n\t}\n\n\tpvhp := NewPointVectorFromPoints(hullPoints)\n\tdefer pvhp.Close()\n\n\trect := MinAreaRect2f(pvhp)\n\tpts := NewMat()\n\tdefer pts.Close()\n\tBoxPoints2f(rect, &pts)\n\n\tif pts.Empty() || pts.Rows() != 4 || pts.Cols() != 2 {\n\t\tt.Error(\"Invalid BoxPoints2f test\")\n\t}\n}\n\nfunc TestMinAreaRect2f(t *testing.T) {\n\tsrc := []image.Point{\n\t\timage.Pt(0, 2),\n\t\timage.Pt(2, 0),\n\t\timage.Pt(8, 4),\n\t\timage.Pt(4, 8),\n\t}\n\n\tpv := NewPointVectorFromPoints(src)\n\tdefer pv.Close()\n\n\tm := MinAreaRect2f(pv)\n\n\tif m.Center.X != 3.5 {\n\t\tt.Errorf(\"TestMinAreaRect2f(): unexpected center.X = %v, want = %v\", m.Center.X, 3.5)\n\t}\n\tif m.Center.Y != 3.5 {\n\t\tt.Errorf(\"TestMinAreaRect2f(): unexpected center.Y = %v, want = %v\", m.Center.Y, 3.5)\n\t}\n\tif m.Width != 7.071067810058594 {\n\t\tt.Errorf(\"TestMinAreaRect2f(): unexpected width = %v, want = %v\", m.Width, 7.071067810058594)\n\t}\n\tif m.Height != 5.656853675842285 {\n\t\tt.Errorf(\"TestMinAreaRect2f(): unexpected height = %v, want = %v\", m.Height, 5.656853675842285)\n\t}\n\tif m.Angle != 45.0 {\n\t\tt.Errorf(\"TestMinAreaRect2f(): unexpected angle = %v, want = %v\", m.Angle, 45.0)\n\t}\n}\n\nfunc TestFitEllipse(t *testing.T) {\n\tsrc := []image.Point{\n\t\timage.Pt(1, 1),\n\t\timage.Pt(0, 1),\n\t\timage.Pt(0, 2),\n\t\timage.Pt(1, 3),\n\t\timage.Pt(2, 3),\n\t\timage.Pt(4, 2),\n\t\timage.Pt(4, 1),\n\t\timage.Pt(0, 3),\n\t\timage.Pt(0, 2),\n\t}\n\n\tpv := NewPointVectorFromPoints(src)\n\tdefer pv.Close()\n\n\trect := FitEllipse(pv)\n\tif rect.Center.X != 2 {\n\t\tt.Errorf(\"TestFitEllipse(): unexpected center.X = %v, want = %v\", rect.Center.X, 2)\n\t}\n\tif rect.Center.Y != 2 {\n\t\tt.Errorf(\"TestFitEllipse(): unexpected center.Y = %v, want = %v\", rect.Center.Y, 2)\n\t}\n\tif rect.Angle != 78.60807800292969 {\n\t\tt.Errorf(\"TestFitEllipse(): unexpected angle = %v, want = %v\", rect.Angle, 78.60807800292969)\n\t}\n}\n\nfunc TestFindContours(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in FindContours test\")\n\t}\n\tdefer img.Close()\n\n\tres := FindContours(img, RetrievalExternal, ChainApproxSimple)\n\tdefer res.Close()\n\n\tif res.Size() < 1 {\n\t\tt.Error(\"Invalid FindContours test\")\n\t}\n\n\tarea := ContourArea(res.At(0))\n\tif area != 127280.0 {\n\t\tt.Errorf(\"Invalid ContourArea test: %f\", area)\n\t}\n\n\tr := BoundingRect(res.At(0))\n\tif !r.Eq(image.Rect(0, 0, 400, 320)) {\n\t\tt.Errorf(\"Invalid BoundingRect test: %v\", r)\n\t}\n\n\tlength := ArcLength(res.At(0), true)\n\tif int(length) != 1436 {\n\t\tt.Errorf(\"Invalid ArcLength test: %f\", length)\n\t}\n\n\tlength = ArcLength(res.At(0), false)\n\tif int(length) != 1037 {\n\t\tt.Errorf(\"Invalid ArcLength test: %f\", length)\n\t}\n}\n\nfunc TestFindContoursWithParams(t *testing.T) {\n\timg := IMRead(\"images/contours.png\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Fatal(\"Invalid read of Mat in FindContours test\")\n\t}\n\tdefer img.Close()\n\thierarchy := NewMat()\n\tdefer hierarchy.Close()\n\n\tres := FindContoursWithParams(img, &hierarchy, RetrievalTree, ChainApproxNone)\n\tdefer res.Close()\n\n\tif want := 4; want != res.Size() {\n\t\tt.Fatalf(\"Expected %d contours but got %d\", want, res.Size())\n\t}\n\tif res.Size() != hierarchy.Cols() {\n\t\tt.Fatalf(\"Expected %d hierarchy of contours, got %d\", res.Size(), hierarchy.Cols())\n\t}\n\t// Assert hierarchy values, the pattern is [Next, Previous, First_Child, Parent]\n\t// More info at https://docs.opencv.org/master/d9/d8b/tutorial_py_contours_hierarchy.html\n\tfor i, want := range []Veci{\n\t\t{1, -1, -1, -1},\n\t\t{-1, 0, 2, -1},\n\t\t{-1, -1, 3, 1},\n\t\t{-1, -1, -1, 2},\n\t} {\n\t\tgot := hierarchy.GetVeciAt(0, i)\n\t\tif !reflect.DeepEqual(want, got) {\n\t\t\tt.Errorf(\"wrong hierarchy at position %d, want %v got %v\", i, want, got)\n\t\t}\n\t}\n}\n\nfunc TestPointPolygonTest(t *testing.T) {\n\ttests := []struct {\n\t\tname      string      // name of the testcase\n\t\tthickness int         // thickness of the polygon\n\t\tpoint     image.Point // point to be checked\n\t\tresult    float64     // expected result; either distance or -1, 0, 1 based on measure parameter\n\t\tmeasure   bool        // enable distance measurement, if true\n\t}{\n\t\t{\n\t\t\tname:      \"Inside the polygon - measure=false\",\n\t\t\tthickness: 1,\n\t\t\tpoint:     image.Point{20, 30},\n\t\t\tresult:    1.0,\n\t\t\tmeasure:   false,\n\t\t}, {\n\t\t\tname:      \"Outside the polygon - measure=false\",\n\t\t\tthickness: 1,\n\t\t\tpoint:     image.Point{5, 15},\n\t\t\tresult:    -1.0,\n\t\t\tmeasure:   false,\n\t\t}, {\n\t\t\tname:      \"On the polygon - measure=false\",\n\t\t\tthickness: 1,\n\t\t\tpoint:     image.Point{10, 10},\n\t\t\tresult:    0.0,\n\t\t\tmeasure:   false,\n\t\t}, {\n\t\t\tname:      \"Inside the polygon - measure=true\",\n\t\t\tthickness: 1,\n\t\t\tpoint:     image.Point{20, 30},\n\t\t\tresult:    10.0,\n\t\t\tmeasure:   true,\n\t\t}, {\n\t\t\tname:      \"Outside the polygon - measure=true\",\n\t\t\tthickness: 1,\n\t\t\tpoint:     image.Point{5, 15},\n\t\t\tresult:    -5.0,\n\t\t\tmeasure:   true,\n\t\t}, {\n\t\t\tname:      \"On the polygon - measure=true\",\n\t\t\tthickness: 1,\n\t\t\tpoint:     image.Point{10, 10},\n\t\t\tresult:    0.0,\n\t\t\tmeasure:   true,\n\t\t},\n\t}\n\n\tpts := []image.Point{\n\t\timage.Pt(10, 10),\n\t\timage.Pt(10, 80),\n\t\timage.Pt(80, 80),\n\t\timage.Pt(80, 10),\n\t}\n\n\tctr := NewPointVectorFromPoints(pts)\n\tdefer ctr.Close()\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tif r := PointPolygonTest(ctr, tc.point, tc.measure); r != tc.result {\n\t\t\t\tt.Errorf(\"Wrong result, got = %v, want >= %v\", r, tc.result)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestConnectedComponents(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in FindContours test\")\n\t}\n\tdefer img.Close()\n\n\tlabels := NewMat()\n\tdefer labels.Close()\n\tres := ConnectedComponents(img, &labels)\n\tif res < 1 || labels.Empty() {\n\t\tt.Error(\"Invalid ConnectedComponents test\")\n\t}\n}\n\nfunc TestConnectedComponentsWithParams(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in FindContours test\")\n\t}\n\tdefer img.Close()\n\n\tlabels := NewMat()\n\tdefer labels.Close()\n\tres := ConnectedComponentsWithParams(img, &labels, 8, MatTypeCV32S, CCL_DEFAULT)\n\tif res < 1 || labels.Empty() {\n\t\tt.Error(\"Invalid ConnectedComponentsWithParams test\")\n\t}\n}\n\nfunc TestConnectedComponentsWithStats(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in FindContours test\")\n\t}\n\tdefer img.Close()\n\n\tlabels := NewMat()\n\tdefer labels.Close()\n\n\tstats := NewMat()\n\tdefer stats.Close()\n\n\tcentroids := NewMat()\n\tdefer centroids.Close()\n\n\tres := ConnectedComponentsWithStats(img, &labels, &stats, &centroids)\n\tif res < 1 || labels.Empty() || stats.Empty() || centroids.Empty() {\n\t\tt.Error(\"Invalid ConnectedComponentsWithStats test\")\n\t}\n}\n\nfunc TestConnectedComponentsWithStatsWithParams(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in FindContours test\")\n\t}\n\tdefer img.Close()\n\n\tlabels := NewMat()\n\tdefer labels.Close()\n\n\tstats := NewMat()\n\tdefer stats.Close()\n\n\tcentroids := NewMat()\n\tdefer centroids.Close()\n\n\tres := ConnectedComponentsWithStatsWithParams(img, &labels, &stats, &centroids,\n\t\t8, MatTypeCV32S, CCL_DEFAULT)\n\tif res < 1 || labels.Empty() || stats.Empty() || centroids.Empty() {\n\t\tt.Error(\"Invalid ConnectedComponentsWithStatsWithParams test\")\n\t}\n}\n\nfunc TestErode(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in Erode test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tkernel := GetStructuringElement(MorphRect, image.Pt(1, 1))\n\tdefer kernel.Close()\n\n\tErode(img, &dest, kernel)\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid Erode test\")\n\t}\n}\n\nfunc TestErodeWithParams(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in ErodeWithParams test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tkernel := GetStructuringElement(MorphRect, image.Pt(1, 1))\n\tdefer kernel.Close()\n\n\tErodeWithParams(img, &dest, kernel, image.Pt(-1, -1), 3, 0)\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid ErodeWithParams test\")\n\t}\n}\n\nfunc TestErodeWithParamsAndBorderValue(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in ErodeWithParamsAndBorderValue test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tkernel := GetStructuringElement(MorphRect, image.Pt(1, 1))\n\tdefer kernel.Close()\n\n\tErodeWithParamsAndBorderValue(img, &dest, kernel, image.Pt(-1, -1), 3, 0, NewScalar(0, 0, 0, 0))\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid ErodeWithParamsAndBorderValue test\")\n\t}\n}\n\nfunc TestMorphologyDefaultBorderValue(t *testing.T) {\n\tzeroScalar := Scalar{}\n\tmorphologyDefaultBorderValue := MorphologyDefaultBorderValue()\n\n\tif reflect.DeepEqual(zeroScalar, morphologyDefaultBorderValue) {\n\t\tt.Error(\"Got zero valued scalar\")\n\t}\n\n}\n\nfunc TestMorphologyEx(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in MorphologyEx test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tkernel := GetStructuringElement(MorphRect, image.Pt(1, 1))\n\tdefer kernel.Close()\n\n\tMorphologyEx(img, &dest, MorphOpen, kernel)\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid MorphologyEx test\")\n\t}\n}\n\nfunc TestMorphologyExWithParams(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in MorphologyEx test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tkernel := GetStructuringElement(MorphRect, image.Pt(1, 1))\n\tdefer kernel.Close()\n\n\tMorphologyExWithParams(img, &dest, MorphOpen, kernel, 2, BorderConstant)\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid MorphologyExWithParams test\")\n\t}\n}\n\nfunc TestGaussianBlur(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in GaussianBlur test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tGaussianBlur(img, &dest, image.Pt(23, 23), 30, 50, 4)\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid Blur test\")\n\t}\n}\n\nfunc TestGetGaussianKernel(t *testing.T) {\n\tkernel := GetGaussianKernel(1, 0.5)\n\tdefer kernel.Close()\n\tif kernel.Empty() {\n\t\tt.Error(\"Invalid GetGaussianKernel test\")\n\t}\n\n}\n\nfunc TestGetGaussianKernelWithParams(t *testing.T) {\n\tkernel := GetGaussianKernelWithParams(1, 0.5, MatTypeCV64F)\n\tdefer kernel.Close()\n\tif kernel.Empty() {\n\t\tt.Error(\"Invalid GetGaussianKernel test\")\n\t}\n\n}\n\nfunc TestLaplacian(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in Laplacian test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tLaplacian(img, &dest, MatTypeCV16S, 1, 1, 0, BorderDefault)\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid Laplacian test\")\n\t}\n}\n\nfunc TestScharr(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in Scharr test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tScharr(img, &dest, MatTypeCV16S, 1, 0, 0, 0, BorderDefault)\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid Scharr test\")\n\t}\n}\n\nfunc TestMedianBlur(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in MedianBlur test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tMedianBlur(img, &dest, 3)\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid MedianBlur test\")\n\t}\n}\n\nfunc TestCanny(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in Canny test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tCanny(img, &dest, 50, 150)\n\tif dest.Empty() {\n\t\tt.Error(\"Empty Canny test\")\n\t}\n\tif img.Rows() != dest.Rows() {\n\t\tt.Error(\"Invalid Canny test rows\")\n\t}\n\tif img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid Canny test cols\")\n\t}\n}\n\nfunc TestGoodFeaturesToTrackAndCornerSubPix(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in GoodFeaturesToTrack test\")\n\t}\n\tdefer img.Close()\n\n\tcorners := NewMat()\n\tdefer corners.Close()\n\n\tGoodFeaturesToTrack(img, &corners, 500, 0.01, 10)\n\tif corners.Empty() {\n\t\tt.Error(\"Empty GoodFeaturesToTrack test\")\n\t}\n\tif corners.Rows() != 205 {\n\t\tt.Errorf(\"Invalid GoodFeaturesToTrack test rows: %v\", corners.Rows())\n\t}\n\tif corners.Cols() != 1 {\n\t\tt.Errorf(\"Invalid GoodFeaturesToTrack test cols: %v\", corners.Cols())\n\t}\n\n\ttc := NewTermCriteria(Count|EPS, 20, 0.03)\n\n\tCornerSubPix(img, &corners, image.Pt(10, 10), image.Pt(-1, -1), tc)\n\tif corners.Empty() {\n\t\tt.Error(\"Empty CornerSubPix test\")\n\t}\n\tif corners.Rows() != 205 {\n\t\tt.Errorf(\"Invalid CornerSubPix test rows: %v\", corners.Rows())\n\t}\n\tif corners.Cols() != 1 {\n\t\tt.Errorf(\"Invalid CornerSubPix test cols: %v\", corners.Cols())\n\t}\n}\n\nfunc TestGrabCut(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in GrabCut test\")\n\t}\n\tdefer img.Close()\n\n\tsrc := NewMat()\n\tdefer src.Close()\n\tCvtColor(img, &img, ColorRGBAToBGR)\n\timg.ConvertTo(&src, MatTypeCV8UC3)\n\n\tmask := NewMatWithSize(img.Rows(), img.Cols(), MatTypeCV8U)\n\tdefer mask.Close()\n\n\tbgdModel := NewMat()\n\tdefer bgdModel.Close()\n\tfgdModel := NewMat()\n\tdefer fgdModel.Close()\n\n\tr := image.Rect(0, 0, 50, 50)\n\n\tGrabCut(src, &mask, r, &bgdModel, &fgdModel, 1, GCEval)\n\tif bgdModel.Empty() {\n\t\tt.Error(\"Empty bgdmodel\")\n\t} else if fgdModel.Empty() {\n\t\tt.Error(\"Empty fgdmodel\")\n\t}\n}\n\nfunc TestHoughCircles(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in HoughCircles test\")\n\t}\n\tdefer img.Close()\n\n\tcircles := NewMat()\n\tdefer circles.Close()\n\n\tHoughCircles(img, &circles, 3, 5.0, 5.0)\n\tif circles.Empty() {\n\t\tt.Error(\"Empty HoughCircles test\")\n\t}\n\tif circles.Rows() != 1 {\n\t\tt.Errorf(\"Invalid HoughCircles test rows: %v\", circles.Rows())\n\t}\n\tif circles.Cols() < 317 || circles.Cols() > 334 {\n\t\tt.Errorf(\"Invalid HoughCircles test cols: %v\", circles.Cols())\n\t}\n}\n\nfunc TestHoughCirclesWithParams(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in HoughCircles test\")\n\t}\n\tdefer img.Close()\n\n\tcircles := NewMat()\n\tdefer circles.Close()\n\n\tHoughCirclesWithParams(img, &circles, 3, 5.0, 5.0, 100, 100, 0, 0)\n\tif circles.Empty() {\n\t\tt.Error(\"Empty HoughCirclesWithParams test\")\n\t}\n\tif circles.Rows() != 1 {\n\t\tt.Errorf(\"Invalid HoughCirclesWithParams test rows: %v\", circles.Rows())\n\t}\n\tif circles.Cols() < 317 || circles.Cols() > 334 {\n\t\tt.Errorf(\"Invalid HoughCirclesWithParams test cols: %v\", circles.Cols())\n\t}\n}\n\nfunc TestHoughLines(t *testing.T) {\n\tif runtime.GOOS == \"darwin\" {\n\t\tt.Skip(\"skipping test on macos\")\n\t}\n\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in HoughLines test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tHoughLines(img, &dest, 1, math.Pi/180, 50)\n\tif dest.Empty() {\n\t\tt.Error(\"Empty HoughLines test\")\n\t}\n\n\tif dest.Rows() != 6465 {\n\t\tt.Errorf(\"Invalid HoughLines test rows: %v\", dest.Rows())\n\t}\n\tif dest.Cols() != 1 {\n\t\tt.Errorf(\"Invalid HoughLines test cols: %v\", dest.Cols())\n\t}\n\n\tif dest.GetFloatAt(0, 0) != 226 && dest.GetFloatAt(0, 1) != 0.7853982 {\n\t\tt.Errorf(\"Invalid HoughLines first test element: %v, %v\", dest.GetFloatAt(0, 0), dest.GetFloatAt(0, 1))\n\t}\n\n\tif dest.GetFloatAt(1, 0) != 228 && dest.GetFloatAt(1, 1) != 0.7853982 {\n\t\tt.Errorf(\"Invalid HoughLines second test element: %v, %v\", dest.GetFloatAt(1, 0), dest.GetFloatAt(1, 1))\n\t}\n\n\tif dest.GetFloatAt(6463, 0) != 23 && dest.GetFloatAt(6463, 1) != 0.75049156 {\n\t\tt.Errorf(\"Invalid HoughLines penultimate test element: %v, %v\", dest.GetFloatAt(6463, 0), dest.GetFloatAt(6463, 1))\n\t}\n\n\tif dest.GetFloatAt(6464, 0) != 23 && dest.GetFloatAt(6464, 1) != 0.82030475 {\n\t\tt.Errorf(\"Invalid HoughLines last test element: %v, %v\", dest.GetFloatAt(6464, 0), dest.GetFloatAt(6464, 1))\n\t}\n}\n\nfunc TestHoughLinesP(t *testing.T) {\n\tif runtime.GOOS == \"darwin\" {\n\t\tt.Skip(\"skipping test on macos\")\n\t}\n\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in HoughLinesP test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tHoughLinesP(img, &dest, 1, math.Pi/180, 50)\n\tif dest.Empty() {\n\t\tt.Error(\"Empty HoughLinesP test\")\n\t}\n\tif dest.Rows() != 4356 {\n\t\tt.Errorf(\"Invalid HoughLinesP test rows: %v\", dest.Rows())\n\t}\n\tif dest.Cols() != 1 {\n\t\tt.Errorf(\"Invalid HoughLinesP test cols: %v\", dest.Cols())\n\t}\n\n\tif dest.GetIntAt(0, 0) != 46 && dest.GetIntAt(0, 1) != 0 && dest.GetIntAt(0, 2) != 365 && dest.GetIntAt(0, 3) != 319 {\n\t\tt.Errorf(\"Invalid HoughLinesP first test element: %v, %v, %v, %v\", dest.GetIntAt(0, 0), dest.GetIntAt(0, 1), dest.GetIntAt(0, 2), dest.GetIntAt(0, 3))\n\t}\n\n\tif dest.GetIntAt(1, 0) != 62 && dest.GetIntAt(1, 1) != 319 && dest.GetIntAt(1, 2) != 197 && dest.GetIntAt(1, 3) != 197 {\n\t\tt.Errorf(\"Invalid HoughLinesP second test element: %v, %v, %v, %v\", dest.GetIntAt(1, 0), dest.GetIntAt(1, 1), dest.GetIntAt(1, 2), dest.GetIntAt(1, 3))\n\t}\n\n\tif dest.GetIntAt(433, 0) != 357 && dest.GetIntAt(433, 1) != 316 && dest.GetIntAt(433, 2) != 357 && dest.GetIntAt(433, 3) != 316 {\n\t\tt.Errorf(\"Invalid HoughLinesP penultimate test element: %v, %v, %v, %v\", dest.GetIntAt(433, 0), dest.GetIntAt(433, 1), dest.GetIntAt(433, 2), dest.GetIntAt(433, 3))\n\t}\n\n\tif dest.GetIntAt(434, 0) != 39 && dest.GetIntAt(434, 1) != 280 && dest.GetIntAt(434, 2) != 89 && dest.GetIntAt(434, 3) != 227 {\n\t\tt.Errorf(\"Invalid HoughLinesP last test element: %v, %v, %v, %v\", dest.GetIntAt(434, 0), dest.GetIntAt(434, 1), dest.GetIntAt(434, 2), dest.GetIntAt(434, 3))\n\t}\n}\n\nfunc TestHoughLinesPWithParams(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in HoughLinesPWithParams test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tHoughLinesPWithParams(img, &dest, 1, math.Pi/180, 50, 1, 1)\n\tif dest.Empty() {\n\t\tt.Error(\"Empty HoughLinesPWithParams test\")\n\t}\n\tif dest.Rows() != 514 {\n\t\tt.Errorf(\"Invalid HoughLinesPWithParams test rows: %v\", dest.Rows())\n\t}\n\tif dest.Cols() != 1 {\n\t\tt.Errorf(\"Invalid HoughLinesPWithParams test cols: %v\", dest.Cols())\n\t}\n\n\tif dest.GetIntAt(0, 0) != 46 && dest.GetIntAt(0, 1) != 0 && dest.GetIntAt(0, 2) != 365 && dest.GetIntAt(0, 3) != 319 {\n\t\tt.Errorf(\"Invalid HoughLinesPWithParams first test element: %v, %v, %v, %v\", dest.GetIntAt(0, 0), dest.GetIntAt(0, 1), dest.GetIntAt(0, 2), dest.GetIntAt(0, 3))\n\t}\n\n\tif dest.GetIntAt(1, 0) != 62 && dest.GetIntAt(1, 1) != 319 && dest.GetIntAt(1, 2) != 197 && dest.GetIntAt(1, 3) != 197 {\n\t\tt.Errorf(\"Invalid HoughLinesPWithParams second test element: %v, %v, %v, %v\", dest.GetIntAt(1, 0), dest.GetIntAt(1, 1), dest.GetIntAt(1, 2), dest.GetIntAt(1, 3))\n\t}\n\n\tif dest.GetIntAt(433, 0) != 0 && dest.GetIntAt(433, 1) != 126 && dest.GetIntAt(433, 2) != 71 && dest.GetIntAt(433, 3) != 57 {\n\t\tt.Errorf(\"Invalid HoughLinesPWithParams penultimate test element: %v, %v, %v, %v\", dest.GetIntAt(433, 0), dest.GetIntAt(433, 1), dest.GetIntAt(433, 2), dest.GetIntAt(433, 3))\n\t}\n\n\tif dest.GetIntAt(434, 0) != 309 && dest.GetIntAt(434, 1) != 280 && dest.GetIntAt(434, 2) != 89 && dest.GetIntAt(434, 3) != 227 {\n\t\tt.Errorf(\"Invalid HoughLinesPWithParams last test element: %v, %v, %v, %v\", dest.GetIntAt(434, 0), dest.GetIntAt(434, 1), dest.GetIntAt(434, 2), dest.GetIntAt(434, 3))\n\t}\n}\n\nfunc TestHoughLinesPointSet(t *testing.T) {\n\n\tpoints := [][2]int{\n\t\t{0, 369}, {10, 364}, {20, 358}, {30, 352},\n\t\t{40, 346}, {50, 341}, {60, 335}, {70, 329},\n\t\t{80, 323}, {90, 318}, {100, 312}, {110, 306},\n\t\t{120, 300}, {130, 295}, {140, 289}, {150, 284},\n\t\t{160, 277}, {170, 271}, {180, 266}, {190, 260},\n\t}\n\n\timg := NewMatWithSize(len(points), 1, MatTypeCV32F+MatChannels2)\n\tdefer img.Close()\n\tfor i, p := range points {\n\t\timg.SetFloatAt(i, 0, float32(p[0]))\n\t\timg.SetFloatAt(i, 1, float32(p[1]))\n\t}\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\trhoMin, rhoMax, rhoStep := float32(0), float32(360), float32(1)\n\tthetaMin, thetaMax, thetaStep := float32(0), float32(math.Pi/2), float32(math.Pi/180)\n\n\tHoughLinesPointSet(img, &dest, 20, 1,\n\t\trhoMin, rhoMax, rhoStep,\n\t\tthetaMin, thetaMax, thetaStep)\n\n\tif dest.Empty() {\n\t\tt.Error(\"Empty HoughLinesPointSet test\")\n\t}\n\tif dest.Rows() != 20 {\n\t\tt.Errorf(\"Invalid HoughLinesPointSet test rows: %v\", dest.Rows())\n\t}\n\tif dest.Cols() != 1 {\n\t\tt.Errorf(\"Invalid HoughLinesPointSet test cols: %v\", dest.Cols())\n\t}\n\n\tif dest.GetDoubleAt(0, 0) != 19 && dest.GetDoubleAt(0, 1) != 320 && dest.GetDoubleAt(0, 2) != 1.0471975803375244 {\n\t\tt.Errorf(\"Invalid HoughLinesPointSet first test element: %v, %v, %v\", dest.GetDoubleAt(0, 0), dest.GetDoubleAt(0, 1), dest.GetDoubleAt(0, 2))\n\t}\n\n\tif dest.GetDoubleAt(1, 0) != 7 && dest.GetDoubleAt(1, 1) != 321 && dest.GetDoubleAt(1, 2) != 1.0646508932113647 {\n\t\tt.Errorf(\"Invalid HoughLinesPointSet second test element: %v, %v, %v\", dest.GetDoubleAt(1, 0), dest.GetDoubleAt(1, 1), dest.GetDoubleAt(1, 2))\n\t}\n\n\tif dest.GetDoubleAt(18, 0) != 2 && dest.GetDoubleAt(18, 1) != 317 && dest.GetDoubleAt(18, 2) != 0 {\n\t\tt.Errorf(\"Invalid HoughLinesPointSet penultimate test element: %v, %v, %v\", dest.GetDoubleAt(18, 0), dest.GetDoubleAt(18, 1), dest.GetDoubleAt(18, 2))\n\t}\n\n\tif dest.GetDoubleAt(19, 0) != 2 && dest.GetDoubleAt(19, 1) != 330 && dest.GetDoubleAt(19, 2) != 0 {\n\t\tt.Errorf(\"Invalid HoughLinesPointSet last test element: %v, %v, %v\", dest.GetDoubleAt(19, 0), dest.GetDoubleAt(19, 1), dest.GetDoubleAt(19, 1))\n\t}\n}\n\nfunc TestIntegral(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in Integral test\")\n\t}\n\tdefer img.Close()\n\n\tsum := NewMat()\n\tdefer sum.Close()\n\tsqSum := NewMat()\n\tdefer sqSum.Close()\n\ttilted := NewMat()\n\tdefer tilted.Close()\n\n\tIntegral(img, &sum, &sqSum, &tilted)\n\tif sum.Empty() || sqSum.Empty() || tilted.Empty() {\n\t\tt.Error(\"Invalid Integral test\")\n\t}\n}\n\nfunc TestThreshold(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in Threshold test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tThreshold(img, &dest, 25, 255, ThresholdBinary)\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid Threshold test\")\n\t}\n}\nfunc TestAdaptiveThreshold(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in AdaptiveThreshold test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tAdaptiveThreshold(img, &dest, 255, AdaptiveThresholdMean, ThresholdBinary, 11, 2)\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid Threshold test\")\n\t}\n}\n\nfunc TestCircle(t *testing.T) {\n\ttests := []struct {\n\t\tname      string      // name of the testcase\n\t\tthickness int         // thickness of the circle\n\t\tpoint     image.Point // point to be checked\n\t\tresult    uint8       // expected value at the point to be checked\n\t}{\n\t\t{\n\t\t\tname:      \"Without filling\",\n\t\t\tthickness: 3,\n\t\t\tpoint:     image.Point{80, 89},\n\t\t\tresult:    255,\n\t\t}, {\n\t\t\tname:      \"With filling\",\n\t\t\tthickness: -1,\n\t\t\tpoint:     image.Point{60, 60},\n\t\t\tresult:    255,\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(\"tc.name\", func(t *testing.T) {\n\t\t\timg := NewMatWithSize(100, 100, MatTypeCV8UC1)\n\t\t\tdefer img.Close()\n\n\t\t\twhite := color.RGBA{255, 255, 255, 0}\n\t\t\tCircle(&img, image.Pt(70, 70), 20, white, tc.thickness)\n\n\t\t\tif v := img.GetUCharAt(tc.point.X, tc.point.Y); v != tc.result {\n\t\t\t\tt.Errorf(\"Wrong pixel value, got = %v, want = %v\", v, tc.result)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCircleWithParams(t *testing.T) {\n\ttests := []struct {\n\t\tname      string                // name of the testcase\n\t\tthickness int                   // thickness of the circle\n\t\tshift     int                   // how much to shift and reduce(in size)\n\t\tchecks    map[image.Point]uint8 // map of points to be checked and corresponding expected value\n\t}{\n\t\t{\n\t\t\tname:      \"Without filling and shift\",\n\t\t\tthickness: 3,\n\t\t\tshift:     0,\n\t\t\tchecks: map[image.Point]uint8{\n\t\t\t\t{80, 89}: 255,\n\t\t\t},\n\t\t}, {\n\t\t\tname:      \"With filling, without shift\",\n\t\t\tthickness: -1,\n\t\t\tshift:     0,\n\t\t\tchecks: map[image.Point]uint8{\n\t\t\t\t{60, 60}: 255,\n\t\t\t},\n\t\t}, {\n\t\t\tname:      \"Without filling, with shift\",\n\t\t\tthickness: 3,\n\t\t\tshift:     1,\n\t\t\tchecks: map[image.Point]uint8{\n\t\t\t\t{47, 38}: 255,\n\t\t\t\t{48, 38}: 0,\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\timg := NewMatWithSize(100, 100, MatTypeCV8UC1)\n\t\t\tdefer img.Close()\n\n\t\t\twhite := color.RGBA{255, 255, 255, 0}\n\t\t\tCircleWithParams(&img, image.Pt(70, 70), 20, white, tc.thickness, Line4, tc.shift)\n\n\t\t\tfor c, result := range tc.checks {\n\t\t\t\tif v := img.GetUCharAt(c.X, c.Y); v != result {\n\t\t\t\t\tt.Errorf(\"Wrong pixel value, got = %v, want = %v\", v, result)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestRectangle(t *testing.T) {\n\ttests := []struct {\n\t\tname      string      // name of the testcase\n\t\tthickness int         // thickness of the rectangle\n\t\tpoint     image.Point // point to be checked\n\t}{\n\t\t{\n\t\t\tname:      \"Without filling\",\n\t\t\tthickness: 1,\n\t\t\tpoint:     image.Point{10, 60},\n\t\t}, {\n\t\t\tname:      \"With filling\",\n\t\t\tthickness: -1,\n\t\t\tpoint:     image.Point{30, 30},\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\timg := NewMatWithSize(100, 100, MatTypeCV8UC1)\n\t\t\tdefer img.Close()\n\n\t\t\twhite := color.RGBA{255, 255, 255, 0}\n\t\t\tRectangle(&img, image.Rect(10, 10, 80, 80), white, tc.thickness)\n\n\t\t\tif v := img.GetUCharAt(tc.point.X, tc.point.Y); v < 50 {\n\t\t\t\tt.Errorf(\"Wrong pixel value, got = %v, want >= %v\", v, 50)\n\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestRectangleWithParams(t *testing.T) {\n\ttests := []struct {\n\t\tname      string      // name of the testcase\n\t\tthickness int         // thickness of the rectangle\n\t\tshift     int         // how much to shift and reduce (in size)\n\t\tpoint     image.Point // point to be checked\n\t}{\n\t\t{\n\t\t\tname:      \"Without filling and shift\",\n\t\t\tthickness: 1,\n\t\t\tpoint:     image.Point{10, 60},\n\t\t}, {\n\t\t\tname:      \"With filling, without shift\",\n\t\t\tthickness: -1,\n\t\t\tpoint:     image.Point{30, 30},\n\t\t}, {\n\t\t\tname:      \"Without filling, with shift\",\n\t\t\tthickness: 1,\n\t\t\tshift:     1,\n\t\t\tpoint:     image.Point{5, 5},\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\timg := NewMatWithSize(100, 100, MatTypeCV8UC1)\n\t\t\tdefer img.Close()\n\n\t\t\twhite := color.RGBA{255, 255, 255, 0}\n\t\t\tRectangleWithParams(&img, image.Rect(10, 10, 80, 80), white, tc.thickness, Line4, tc.shift)\n\n\t\t\tif v := img.GetUCharAt(tc.point.X, tc.point.Y); v != 255 {\n\t\t\t\tt.Errorf(\"Wrong pixel value, got = %v, want = %v\", v, 255)\n\t\t\t}\n\n\t\t})\n\t}\n}\n\nfunc TestEqualizeHist(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in EqualizeHist test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tEqualizeHist(img, &dest)\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Invalid EqualizeHist test\")\n\t}\n}\n\nfunc TestCalcHist(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in CalcHist test\")\n\t}\n\tdefer img.Close()\n\n\thist := NewMat()\n\tdefer hist.Close()\n\n\tmask := NewMat()\n\tdefer mask.Close()\n\n\tCalcHist([]Mat{img}, []int{0}, mask, &hist, []int{256}, []float64{0.0, 256.0}, false)\n\tif hist.Empty() || hist.Rows() != 256 || hist.Cols() != 1 {\n\t\tt.Error(\"Invalid CalcHist test\")\n\t}\n}\n\nfunc TestCalcBackProject(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in CalcHist test\")\n\t}\n\tdefer img.Close()\n\n\thist := NewMat()\n\tdefer hist.Close()\n\n\tbackProject := NewMat()\n\tdefer backProject.Close()\n\n\tmask := NewMat()\n\tdefer mask.Close()\n\n\tCalcHist([]Mat{img}, []int{0}, mask, &hist, []int{256}, []float64{0.0, 256.0}, false)\n\tCalcBackProject([]Mat{img}, []int{0}, hist, &backProject, []float64{0.0, 256.0}, false)\n\tif backProject.Empty() {\n\t\tt.Error(\"Invalid CalcBackProject test\")\n\t}\n}\n\nfunc TestCompareHist(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in CompareHist test\")\n\t}\n\tdefer img.Close()\n\n\thist1 := NewMat()\n\tdefer hist1.Close()\n\n\thist2 := NewMat()\n\tdefer hist2.Close()\n\n\tmask := NewMat()\n\tdefer mask.Close()\n\n\tCalcHist([]Mat{img}, []int{0}, mask, &hist1, []int{256}, []float64{0.0, 256.0}, false)\n\tCalcHist([]Mat{img}, []int{0}, mask, &hist2, []int{256}, []float64{0.0, 256.0}, false)\n\tdist := CompareHist(hist1, hist2, HistCmpCorrel)\n\tif dist != 1 {\n\t\tt.Error(\"Invalid CompareHist test\")\n\t}\n\n}\n\nfunc TestEMD(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadUnchanged)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in CompareHist test\")\n\t}\n\tdefer img.Close()\n\n\thist1 := NewMat()\n\tdefer hist1.Close()\n\n\thist2 := NewMat()\n\tdefer hist2.Close()\n\n\tmask := NewMat()\n\tdefer mask.Close()\n\n\tCalcHist([]Mat{img}, []int{0, 1}, mask, &hist1, []int{30, 32}, []float64{0.0, 180.0, 0.0, 255.0}, false)\n\tCalcHist([]Mat{img}, []int{0, 1}, mask, &hist2, []int{30, 32}, []float64{0.0, 180.0, 0.0, 255.0}, false)\n\n\tsig1 := NewMatWithSize(30*32, 3, MatTypeCV32FC1)\n\tdefer sig1.Close()\n\n\tsig2 := NewMatWithSize(30*32, 3, MatTypeCV32FC1)\n\tdefer sig2.Close()\n\n\tfor h := 0; h < 30; h++ {\n\t\tfor s := 0; s < 32; s++ {\n\t\t\tval := hist1.GetFloatAt(h, s)\n\t\t\tsig1.SetFloatAt(h*32+s, 0, val)\n\t\t\tsig1.SetFloatAt(h*32+s, 1, float32(h))\n\t\t\tsig1.SetFloatAt(h*32+s, 2, float32(s))\n\n\t\t\tval = hist2.GetFloatAt(h, s)\n\t\t\tsig2.SetFloatAt(h*32+s, 0, val)\n\t\t\tsig2.SetFloatAt(h*32+s, 1, float32(h))\n\t\t\tsig2.SetFloatAt(h*32+s, 2, float32(s))\n\t\t}\n\t}\n\n\tsim := EMD(sig1, sig2, DistL2)\n\tif (1-sim)*100 < 99.9 {\n\t\tt.Error(\"Invalid EMD test\", (1-sim)*100)\n\t}\n\n}\n\nfunc TestDrawing(t *testing.T) {\n\timg := NewMatWithSize(150, 150, MatTypeCV8U)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in Rectangle\")\n\t}\n\tdefer img.Close()\n\n\tArrowedLine(&img, image.Pt(50, 50), image.Pt(75, 75), color.RGBA{0, 0, 255, 0}, 3)\n\tCircle(&img, image.Pt(60, 60), 20, color.RGBA{0, 0, 255, 0}, 3)\n\tRectangle(&img, image.Rect(50, 50, 75, 75), color.RGBA{0, 0, 255, 0}, 3)\n\tLine(&img, image.Pt(50, 50), image.Pt(75, 75), color.RGBA{0, 0, 255, 0}, 3)\n\n\tif img.Empty() {\n\t\tt.Error(\"Error in Rectangle test\")\n\t}\n}\n\nfunc TestGetTextSize(t *testing.T) {\n\tsize := GetTextSize(\"test\", FontHersheySimplex, 1.2, 1)\n\tif size.X != 72 {\n\t\tt.Error(\"Invalid text size width\")\n\t}\n\n\tif size.Y != 26 {\n\t\tt.Error(\"Invalid text size height\")\n\t}\n\n\tsize1, base := GetTextSizeWithBaseline(\"test\", FontHersheySimplex, 1.2, 1)\n\tif size1.X != 72 {\n\t\tt.Error(\"Invalid text size width\")\n\t}\n\n\tif size1.Y != 26 {\n\t\tt.Error(\"Invalid text size height\")\n\t}\n\n\texpected := 11\n\tif base != expected {\n\t\tt.Errorf(\"invalid base. expected %d, actual %d\", expected, base)\n\t}\n}\n\nfunc TestPutText(t *testing.T) {\n\timg := NewMatWithSize(150, 150, MatTypeCV8U)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in IMRead\")\n\t}\n\tdefer img.Close()\n\n\tpt := image.Pt(10, 10)\n\tPutText(&img, \"Testing\", pt, FontHersheyPlain, 1.2, color.RGBA{255, 255, 255, 0}, 2)\n\n\tif img.Empty() {\n\t\tt.Error(\"Error in PutText test\")\n\t}\n}\nfunc TestPutTextWithParams(t *testing.T) {\n\timg := NewMatWithSize(150, 150, MatTypeCV8U)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in IMRead\")\n\t}\n\tdefer img.Close()\n\n\tpt := image.Pt(10, 10)\n\tPutTextWithParams(&img, \"Testing\", pt, FontHersheyPlain, 1.2, color.RGBA{255, 255, 255, 0}, 2, LineAA, false)\n\n\tif img.Empty() {\n\t\tt.Error(\"Error in PutText test\")\n\t}\n}\n\nfunc TestResize(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadColor)\n\tif src.Empty() {\n\t\tt.Error(\"Invalid read of Mat in Resize test\")\n\t}\n\tdefer src.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tResize(src, &dst, image.Point{}, 0.5, 0.5, InterpolationDefault)\n\tif dst.Cols() != 200 || dst.Rows() != 172 {\n\t\tt.Errorf(\"Expected dst size of 200x172 got %dx%d\", dst.Cols(), dst.Rows())\n\t}\n\n\tResize(src, &dst, image.Pt(440, 377), 0, 0, InterpolationCubic)\n\tif dst.Cols() != 440 || dst.Rows() != 377 {\n\t\tt.Errorf(\"Expected dst size of 440x377 got %dx%d\", dst.Cols(), dst.Rows())\n\t}\n}\n\nfunc TestGetRectSubPix(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadColor)\n\tif src.Empty() {\n\t\tt.Error(\"Invalid read of Mat in Resize test\")\n\t}\n\tdefer src.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tGetRectSubPix(src, image.Point{20, 30}, image.Point{200, 172}, &dst)\n\tif dst.Cols() != 20 || dst.Rows() != 30 {\n\t\tt.Errorf(\"Expected dst size of 20x30 got %dx%d\", dst.Cols(), dst.Rows())\n\t}\n}\n\nfunc TestGetRotationMatrix2D(t *testing.T) {\n\ttype args struct {\n\t\tcenter image.Point\n\t\tangle  float64\n\t\tscale  float64\n\t}\n\ttests := []struct {\n\t\tname string\n\t\targs args\n\t\twant [][]float64\n\t}{\n\t\t{\n\t\t\tname: \"90\",\n\t\t\targs: args{image.Point{0, 0}, 90.0, 1.0},\n\t\t\twant: [][]float64{\n\t\t\t\t{6.123233995736766e-17, 1, 0},\n\t\t\t\t{-1, 6.123233995736766e-17, 0},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"45\",\n\t\t\targs: args{image.Point{0, 0}, 45.0, 1.0},\n\t\t\twant: [][]float64{\n\t\t\t\t{0.7071067811865476, 0.7071067811865475, 0},\n\t\t\t\t{-0.7071067811865475, 0.7071067811865476, 0},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"0\",\n\t\t\targs: args{image.Point{0, 0}, 0.0, 1.0},\n\t\t\twant: [][]float64{\n\t\t\t\t{1, 0, 0},\n\t\t\t\t{-0, 1, 0},\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tgot := GetRotationMatrix2D(tt.args.center, tt.args.angle, tt.args.scale)\n\t\t\tfor row := 0; row < got.Rows(); row++ {\n\t\t\t\tfor col := 0; col < got.Cols(); col++ {\n\t\t\t\t\tif !floatEquals(got.GetDoubleAt(row, col), tt.want[row][col]) {\n\t\t\t\t\t\tt.Errorf(\"GetRotationMatrix2D() = %v, want %v at row:%v col:%v\", got.GetDoubleAt(row, col), tt.want[row][col], row, col)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tgot.Close()\n\t\t})\n\t}\n}\n\nfunc TestWarpAffine(t *testing.T) {\n\tsrc := NewMatWithSize(256, 256, MatTypeCV8UC1)\n\tdefer src.Close()\n\trot := GetRotationMatrix2D(image.Point{0, 0}, 1.0, 1.0)\n\tdefer rot.Close()\n\tdst := src.Clone()\n\tdefer dst.Close()\n\n\tWarpAffine(src, &dst, rot, image.Point{256, 256})\n\tresult := Norm(dst, NormL2)\n\tif result != 0.0 {\n\t\tt.Errorf(\"WarpAffine() = %v, want %v\", result, 0.0)\n\t}\n}\n\nfunc TestWarpAffineGocvLogo(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadUnchanged)\n\tdefer src.Close()\n\trot := GetRotationMatrix2D(image.Point{0, 0}, 1.0, 1.0)\n\tdefer rot.Close()\n\tdst := src.Clone()\n\tdefer dst.Close()\n\tWarpAffine(src, &dst, rot, image.Point{343, 400})\n\tresult := Norm(dst, NormL2)\n\n\tif !floatEquals(round(result, 0.05), round(111111.05, 0.05)) {\n\t\tt.Errorf(\"WarpAffine() = %v, want %v\", round(result, 0.05), round(111111.05, 0.05))\n\t}\n}\n\nfunc TestWarpAffineWithParams(t *testing.T) {\n\tsrc := NewMatWithSize(256, 256, MatTypeCV8UC1)\n\tdefer src.Close()\n\trot := GetRotationMatrix2D(image.Point{0, 0}, 1.0, 1.0)\n\tdefer rot.Close()\n\tdst := src.Clone()\n\tdefer dst.Close()\n\n\tWarpAffineWithParams(src, &dst, rot, image.Point{256, 256}, InterpolationLinear, BorderConstant, color.RGBA{0, 0, 0, 0})\n\tresult := Norm(dst, NormL2)\n\tif !floatEquals(result, 0.0) {\n\t\tt.Errorf(\"WarpAffineWithParams() = %v, want %v\", result, 0.0)\n\t}\n}\n\nfunc TestWarpAffineWithParamsGocvLogo(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadUnchanged)\n\tdefer src.Close()\n\trot := GetRotationMatrix2D(image.Point{0, 0}, 1.0, 1.0)\n\tdefer rot.Close()\n\tdst := src.Clone()\n\tdefer dst.Close()\n\tWarpAffineWithParams(src, &dst, rot, image.Point{343, 400}, InterpolationLinear, BorderConstant, color.RGBA{0, 0, 0, 0})\n\tresult := Norm(dst, NormL2)\n\tif !floatEquals(round(result, 0.05), round(111111.05, 0.05)) {\n\t\tt.Errorf(\"WarpAffine() = %v, want %v\", round(result, 0.05), round(111111.05, 0.05))\n\t}\n}\n\nfunc TestClipLine(t *testing.T) {\n\n\tif ok := ClipLine(image.Point{20, 20}, image.Point{5, 5}, image.Point{5, 5}); !ok {\n\t\tt.Error(\"ClipLine(): is false\")\n\t}\n}\n\nfunc TestWatershed(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadUnchanged)\n\tif src.Empty() {\n\t\tt.Error(\"Invalid read of Mat in Watershed test\")\n\t}\n\tdefer src.Close()\n\n\tgray := NewMat()\n\tdefer gray.Close()\n\tCvtColor(src, &gray, ColorBGRToGray)\n\n\timgThresh := NewMat()\n\tdefer imgThresh.Close()\n\tThreshold(gray, &imgThresh, 5, 50, ThresholdOtsu+ThresholdBinary)\n\n\tmarkers := NewMat()\n\tdefer markers.Close()\n\t_ = ConnectedComponents(imgThresh, &markers)\n\n\tWatershed(src, &markers)\n\tif markers.Empty() || src.Cols() != markers.Cols() || src.Rows() != markers.Rows() {\n\t\tt.Error(\"Invalid Watershed test\")\n\t}\n}\n\nfunc TestApplyColorMap(t *testing.T) {\n\ttype args struct {\n\t\tcolormapType ColormapTypes\n\t\twant         float64\n\t}\n\ttests := []struct {\n\t\tname string\n\t\targs args\n\t}{\n\t\t{name: \"COLORMAP_AUTUMN\", args: args{colormapType: ColormapAutumn, want: 118090.29593069873}},\n\t\t{name: \"COLORMAP_BONE\", args: args{colormapType: ColormapBone, want: 122067.44213343704}},\n\t\t{name: \"COLORMAP_JET\", args: args{colormapType: ColormapJet, want: 98220.64722857409}},\n\t\t{name: \"COLORMAP_WINTER\", args: args{colormapType: ColormapWinter, want: 94279.52859449394}},\n\t\t{name: \"COLORMAP_RAINBOW\", args: args{colormapType: ColormapRainbow, want: 92591.40608069411}},\n\t\t{name: \"COLORMAP_OCEAN\", args: args{colormapType: ColormapOcean, want: 106444.16919681415}},\n\t\t{name: \"COLORMAP_SUMMER\", args: args{colormapType: ColormapSummer, want: 114434.44957703952}},\n\t\t{name: \"COLORMAP_SPRING\", args: args{colormapType: ColormapSpring, want: 123557.60209715953}},\n\t\t{name: \"COLORMAP_COOL\", args: args{colormapType: ColormapCool, want: 123557.60209715953}},\n\t\t{name: \"COLORMAP_HSV\", args: args{colormapType: ColormapHsv, want: 107679.25179903508}},\n\t\t{name: \"COLORMAP_PINK\", args: args{colormapType: ColormapPink, want: 136043.97287274434}},\n\t\t{name: \"COLORMAP_HOT\", args: args{colormapType: ColormapHot, want: 124941.02475968412}},\n\t\t{name: \"COLORMAP_PARULA\", args: args{colormapType: ColormapParula, want: 111483.33555738274}},\n\t}\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadGrayScale)\n\tdefer src.Close()\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tdst := src.Clone()\n\t\t\tdefer dst.Close()\n\t\t\tApplyColorMap(src, &dst, tt.args.colormapType)\n\t\t\tresult := Norm(dst, NormL2)\n\t\t\tif !floatEquals(result, tt.args.want) {\n\t\t\t\tt.Errorf(\"TestApplyColorMap() = %v, want %v\", result, tt.args.want)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestApplyCustomColorMap(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadGrayScale)\n\tdefer src.Close()\n\tcustomColorMap := NewMatWithSize(256, 1, MatTypeCV8UC1)\n\tdefer customColorMap.Close()\n\n\tdst := src.Clone()\n\tdefer dst.Close()\n\tApplyCustomColorMap(src, &dst, customColorMap)\n\tresult := Norm(dst, NormL2)\n\tif !floatEquals(result, 0.0) {\n\t\tt.Errorf(\"TestApplyCustomColorMap() = %v, want %v\", result, 0.0)\n\t}\n}\n\nfunc TestGetPerspectiveTransform(t *testing.T) {\n\tsrc := []image.Point{\n\t\timage.Pt(0, 0),\n\t\timage.Pt(10, 5),\n\t\timage.Pt(10, 10),\n\t\timage.Pt(5, 10),\n\t}\n\tpvsrc := NewPointVectorFromPoints(src)\n\tdefer pvsrc.Close()\n\n\tdst := []image.Point{\n\t\timage.Pt(0, 0),\n\t\timage.Pt(10, 0),\n\t\timage.Pt(10, 10),\n\t\timage.Pt(0, 10),\n\t}\n\tpvdst := NewPointVectorFromPoints(dst)\n\tdefer pvdst.Close()\n\n\tm := GetPerspectiveTransform(pvsrc, pvdst)\n\tdefer m.Close()\n\n\tif m.Cols() != 3 {\n\t\tt.Errorf(\"TestGetPerspectiveTransform(): unexpected cols = %v, want = %v\", m.Cols(), 3)\n\t}\n\tif m.Rows() != 3 {\n\t\tt.Errorf(\"TestGetPerspectiveTransform(): unexpected rows = %v, want = %v\", m.Rows(), 3)\n\t}\n}\n\nfunc TestGetPerspectiveTransform2f(t *testing.T) {\n\tsrc := []Point2f{\n\t\t{0, 0},\n\t\t{10.5, 5.5},\n\t\t{10.5, 10.5},\n\t\t{5.5, 10.5},\n\t}\n\tdst := []Point2f{\n\t\t{0, 0},\n\t\t{590.20, 24.12},\n\t\t{100.12, 150.21},\n\t\t{0, 10},\n\t}\n\n\tpvsrc := NewPoint2fVectorFromPoints(src)\n\tdefer pvsrc.Close()\n\n\tpvdst := NewPoint2fVectorFromPoints(dst)\n\tdefer pvdst.Close()\n\n\tm := GetPerspectiveTransform2f(pvsrc, pvdst)\n\tdefer m.Close()\n\n\tif m.Cols() != 3 {\n\t\tt.Errorf(\"TestGetPerspectiveTransform2f(): unexpected cols = %v, want = %v\", m.Cols(), 3)\n\t}\n\tif m.Rows() != 3 {\n\t\tt.Errorf(\"TestGetPerspectiveTransform2f(): unexpected rows = %v, want = %v\", m.Rows(), 3)\n\t}\n}\n\nfunc TestGetAffineTransform(t *testing.T) {\n\tsrc := []image.Point{\n\t\timage.Pt(0, 0),\n\t\timage.Pt(10, 5),\n\t\timage.Pt(10, 10),\n\t}\n\tpvsrc := NewPointVectorFromPoints(src)\n\tdefer pvsrc.Close()\n\n\tdst := []image.Point{\n\t\timage.Pt(0, 0),\n\t\timage.Pt(10, 0),\n\t\timage.Pt(10, 10),\n\t}\n\tpvdst := NewPointVectorFromPoints(dst)\n\tdefer pvdst.Close()\n\n\tm := GetAffineTransform(pvsrc, pvdst)\n\tdefer m.Close()\n\n\tif m.Cols() != 3 {\n\t\tt.Errorf(\"TestGetAffineTransform(): unexpected cols = %v, want = %v\", m.Cols(), 3)\n\t}\n\tif m.Rows() != 2 {\n\t\tt.Errorf(\"TestGetAffineTransform(): unexpected rows = %v, want = %v\", m.Rows(), 2)\n\t}\n}\n\nfunc TestGetAffineTransform2f(t *testing.T) {\n\tsrc := []Point2f{\n\t\t{0, 0},\n\t\t{10.5, 5.5},\n\t\t{10.5, 10.5},\n\t}\n\tdst := []Point2f{\n\t\t{0, 0},\n\t\t{590.20, 24.12},\n\t\t{100.12, 150.21},\n\t}\n\n\tpvsrc := NewPoint2fVectorFromPoints(src)\n\tdefer pvsrc.Close()\n\n\tpvdst := NewPoint2fVectorFromPoints(dst)\n\tdefer pvdst.Close()\n\n\tm := GetAffineTransform2f(pvsrc, pvdst)\n\tdefer m.Close()\n\n\tif m.Cols() != 3 {\n\t\tt.Errorf(\"TestGetAffineTransform2f(): unexpected cols = %v, want = %v\", m.Cols(), 3)\n\t}\n\tif m.Rows() != 2 {\n\t\tt.Errorf(\"TestGetAffineTransform2f(): unexpected rows = %v, want = %v\", m.Rows(), 2)\n\t}\n}\n\nfunc TestFindHomography(t *testing.T) {\n\tsrc := NewMatWithSize(4, 1, MatTypeCV64FC2)\n\tdefer src.Close()\n\tdst := NewMatWithSize(4, 1, MatTypeCV64FC2)\n\tdefer dst.Close()\n\n\tsrcPoints := []Point2f{\n\t\t{193, 932},\n\t\t{191, 378},\n\t\t{1497, 183},\n\t\t{1889, 681},\n\t}\n\tdstPoints := []Point2f{\n\t\t{51.51206544281359, -0.10425475260813055},\n\t\t{51.51211051314331, -0.10437947532732306},\n\t\t{51.512222354139325, -0.10437679311830816},\n\t\t{51.51214828037607, -0.1042212249954444},\n\t}\n\n\tfor i, point := range srcPoints {\n\t\tsrc.SetDoubleAt(i, 0, float64(point.X))\n\t\tsrc.SetDoubleAt(i, 1, float64(point.Y))\n\t}\n\n\tfor i, point := range dstPoints {\n\t\tdst.SetDoubleAt(i, 0, float64(point.X))\n\t\tdst.SetDoubleAt(i, 1, float64(point.Y))\n\t}\n\n\tmask := NewMat()\n\tdefer mask.Close()\n\n\tm := FindHomography(src, &dst, HomographyMethodAllPoints, 3, &mask, 2000, 0.995)\n\tdefer m.Close()\n\n\tpvsrc := NewPoint2fVectorFromPoints(srcPoints)\n\tdefer pvsrc.Close()\n\n\tpvdst := NewPoint2fVectorFromPoints(dstPoints)\n\tdefer pvdst.Close()\n\n\tm2 := GetPerspectiveTransform2f(pvsrc, pvdst)\n\tdefer m2.Close()\n\n\tfor row := 0; row < 3; row++ {\n\t\tfor col := 0; col < 3; col++ {\n\t\t\tif math.Abs(m.GetDoubleAt(row, col)-m2.GetDoubleAt(row, col)) > 0.002 {\n\t\t\t\tt.Errorf(\"expected little difference between GetPerspectiveTransform2f and FindHomography results, got %f for row %d col %d\", math.Abs(m.GetDoubleAt(row, col)-m2.GetDoubleAt(row, col)), row, col)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc TestWarpPerspective(t *testing.T) {\n\timg := IMRead(\"images/gocvlogo.jpg\", IMReadUnchanged)\n\tdefer img.Close()\n\n\tw := img.Cols()\n\th := img.Rows()\n\n\ts := []image.Point{\n\t\timage.Pt(0, 0),\n\t\timage.Pt(10, 5),\n\t\timage.Pt(10, 10),\n\t\timage.Pt(5, 10),\n\t}\n\tpvs := NewPointVectorFromPoints(s)\n\tdefer pvs.Close()\n\n\td := []image.Point{\n\t\timage.Pt(0, 0),\n\t\timage.Pt(10, 0),\n\t\timage.Pt(10, 10),\n\t\timage.Pt(0, 10),\n\t}\n\tpvd := NewPointVectorFromPoints(d)\n\tdefer pvd.Close()\n\n\tm := GetPerspectiveTransform(pvs, pvd)\n\tdefer m.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tWarpPerspective(img, &dst, m, image.Pt(w, h))\n\n\tif dst.Cols() != w {\n\t\tt.Errorf(\"TestWarpPerspective(): unexpected cols = %v, want = %v\", dst.Cols(), w)\n\t}\n\n\tif dst.Rows() != h {\n\t\tt.Errorf(\"TestWarpPerspective(): unexpected rows = %v, want = %v\", dst.Rows(), h)\n\t}\n}\n\nfunc TestWarpPerspectiveWithParams(t *testing.T) {\n\timg := IMRead(\"images/gocvlogo.jpg\", IMReadUnchanged)\n\tdefer img.Close()\n\n\tw := img.Cols()\n\th := img.Rows()\n\n\ts := []image.Point{\n\t\timage.Pt(0, 0),\n\t\timage.Pt(10, 5),\n\t\timage.Pt(10, 10),\n\t\timage.Pt(5, 10),\n\t}\n\tpvs := NewPointVectorFromPoints(s)\n\tdefer pvs.Close()\n\n\td := []image.Point{\n\t\timage.Pt(0, 0),\n\t\timage.Pt(10, 0),\n\t\timage.Pt(10, 10),\n\t\timage.Pt(0, 10),\n\t}\n\tpvd := NewPointVectorFromPoints(d)\n\tdefer pvd.Close()\n\n\tm := GetPerspectiveTransform(pvs, pvd)\n\tdefer m.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tWarpPerspectiveWithParams(img, &dst, m, image.Pt(w, h), InterpolationLinear, BorderConstant, color.RGBA{})\n\n\tif dst.Cols() != w {\n\t\tt.Errorf(\"TestWarpPerspectiveWithParams(): unexpected cols = %v, want = %v\", dst.Cols(), w)\n\t}\n\n\tif dst.Rows() != h {\n\t\tt.Errorf(\"TestWarpPerspectiveWithParams(): unexpected rows = %v, want = %v\", dst.Rows(), h)\n\t}\n}\n\nfunc TestDrawContours(t *testing.T) {\n\timg := NewMatWithSize(100, 200, MatTypeCV8UC1)\n\tdefer img.Close()\n\n\t// Draw rectangle\n\twhite := color.RGBA{255, 255, 255, 255}\n\tRectangle(&img, image.Rect(125, 25, 175, 75), white, 1)\n\n\tcontours := FindContours(img, RetrievalExternal, ChainApproxSimple)\n\tdefer contours.Close()\n\n\tif v := img.GetUCharAt(23, 123); v != 0 {\n\t\tt.Errorf(\"TestDrawContours(): wrong pixel value = %v, want = %v\", v, 0)\n\t}\n\tif v := img.GetUCharAt(25, 125); v != 206 {\n\t\tt.Errorf(\"TestDrawContours(): wrong pixel value = %v, want = %v\", v, 206)\n\t}\n\n\tDrawContours(&img, contours, -1, white, 2)\n\n\t// contour should be drawn with thickness = 2\n\tif v := img.GetUCharAt(24, 124); v != 255 {\n\t\tt.Errorf(\"TestDrawContours(): contour has not been drawn (value = %v, want = %v)\", v, 255)\n\t}\n\tif v := img.GetUCharAt(25, 125); v != 255 {\n\t\tt.Errorf(\"TestDrawContours(): contour has not been drawn (value = %v, want = %v)\", v, 255)\n\t}\n}\n\nfunc TestDrawContoursWithParams(t *testing.T) {\n\timg := NewMatWithSize(200, 200, MatTypeCV8UC1)\n\tdefer img.Close()\n\n\t// Draw circle\n\twhite := color.RGBA{255, 255, 255, 255}\n\tblack := color.RGBA{0, 0, 0, 255}\n\tCircle(&img, image.Pt(100, 100), 80, white, -1)\n\tCircle(&img, image.Pt(100, 100), 55, black, -1)\n\tCircle(&img, image.Pt(100, 100), 30, white, -1)\n\n\thierarchy := NewMat()\n\tdefer hierarchy.Close()\n\tcontours := FindContoursWithParams(img, &hierarchy, RetrievalTree, ChainApproxSimple)\n\tdefer contours.Close()\n\n\t// Draw contours by different line-type and assert value\n\tcases := []struct {\n\t\tname        string\n\t\tlineType    LineType\n\t\texpectUChar uint8\n\t}{\n\t\t{\n\t\t\tname:        \"draw by Line4\", // 4 connected line\n\t\t\tlineType:    Line4,\n\t\t\texpectUChar: 255,\n\t\t},\n\t\t{\n\t\t\tname:        \"draw by line8\", // 8 connected line\n\t\t\tlineType:    Line8,\n\t\t\texpectUChar: 0,\n\t\t},\n\t\t{\n\t\t\tname:        \"draw by line-AA\", // anti-aliased line\n\t\t\tlineType:    LineAA,\n\t\t\texpectUChar: 68,\n\t\t},\n\t}\n\tfor _, c := range cases {\n\t\tt.Run(c.name, func(t *testing.T) {\n\t\t\tbg := NewMatWithSize(img.Rows(), img.Cols(), MatTypeCV8UC1)\n\t\t\tdefer bg.Close()\n\n\t\t\tDrawContoursWithParams(&bg, contours, -1, white, 1, c.lineType, hierarchy, 0, image.Pt(0, 0))\n\t\t\tif v := bg.GetUCharAt(22, 88); v != c.expectUChar {\n\t\t\t\tt.Errorf(\"TestDrawContoursWithParams(): contour value expect %v but got %v\", c.expectUChar, v)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestEllipse(t *testing.T) {\n\ttests := []struct {\n\t\tname      string      // name of the testcase\n\t\tthickness int         // thickness of the ellipse\n\t\tpoint     image.Point // point to be checked\n\t}{\n\t\t{\n\t\t\tname:      \"Without filling\",\n\t\t\tthickness: 2,\n\t\t\tpoint:     image.Point{24, 50},\n\t\t}, {\n\t\t\tname:      \"With filling\",\n\t\t\tthickness: -1,\n\t\t\tpoint:     image.Point{55, 47},\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\timg := NewMatWithSize(100, 100, MatTypeCV8UC1)\n\t\t\tdefer img.Close()\n\n\t\t\twhite := color.RGBA{255, 255, 255, 0}\n\t\t\tEllipse(&img, image.Pt(50., 50.), image.Pt(25., 25.), 0., 0, 360, white, tc.thickness)\n\n\t\t\tif v := img.GetUCharAt(tc.point.X, tc.point.Y); v != 255 {\n\t\t\t\tt.Errorf(\"Wrong pixel value, got = %v, want = %v\", v, 255)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestEllipseWithParams(t *testing.T) {\n\tcheck255 := func(v uint8) bool {\n\t\treturn v != 255\n\t}\n\n\ttests := []struct {\n\t\tname      string                           // name of the testcase\n\t\tthickness int                              // thickness of the ellipse\n\t\tlinetype  LineType                         // type of line used for drawing\n\t\tshift     int                              // how much to shift and reduce(in size)\n\t\tchecks    map[image.Point]func(uint8) bool // points to be checked and corresponding expected value\n\t\tcheckFn   func(uint8) bool                 // function to check if the result is as expected\n\n\t}{\n\t\t{\n\t\t\tname:      \"Without filling and shift, line = Line8\",\n\t\t\tthickness: 2,\n\t\t\tlinetype:  Line8,\n\t\t\tchecks: map[image.Point]func(uint8) bool{\n\t\t\t\t{24, 50}: check255,\n\t\t\t},\n\t\t}, {\n\t\t\tname:      \"With filling, without shift, line = Line8\",\n\t\t\tthickness: -1,\n\t\t\tlinetype:  Line8,\n\t\t\tchecks: map[image.Point]func(uint8) bool{\n\t\t\t\t{55, 47}: check255,\n\t\t\t},\n\t\t}, {\n\t\t\tname:      \"Without filling, with shift 2, line = Line8\",\n\t\t\tthickness: 2,\n\t\t\tlinetype:  Line8,\n\t\t\tshift:     2,\n\t\t\tchecks: map[image.Point]func(uint8) bool{\n\t\t\t\t{6, 12}:  check255,\n\t\t\t\t{19, 13}: check255,\n\t\t\t},\n\t\t}, {\n\t\t\tname:      \"Without filling and shift, line = LineAA\",\n\t\t\tthickness: 2,\n\t\t\tlinetype:  LineAA,\n\t\t\tchecks: map[image.Point]func(uint8) bool{\n\t\t\t\t{77, 54}: func(v uint8) bool { return v < 10 || v > 220 },\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\timg := NewMatWithSize(100, 100, MatTypeCV8UC1)\n\t\t\tdefer img.Close()\n\n\t\t\twhite := color.RGBA{255, 255, 255, 0}\n\t\t\tEllipseWithParams(&img, image.Pt(50., 50.), image.Pt(25., 25.), 0., 0, 360, white,\n\t\t\t\ttc.thickness, tc.linetype, tc.shift)\n\n\t\t\tfor c, fn := range tc.checks {\n\t\t\t\tif v := img.GetUCharAt(c.X, c.Y); fn(v) {\n\t\t\t\t\tt.Errorf(\"Wrong pixel value, got = %v\", v)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestFillPoly(t *testing.T) {\n\timg := NewMatWithSize(100, 100, MatTypeCV8UC1)\n\tdefer img.Close()\n\n\twhite := color.RGBA{255, 255, 255, 0}\n\tpts := [][]image.Point{\n\t\t{\n\t\t\timage.Pt(10, 10),\n\t\t\timage.Pt(10, 20),\n\t\t\timage.Pt(20, 20),\n\t\t\timage.Pt(20, 10),\n\t\t},\n\t}\n\n\tpv := NewPointsVectorFromPoints(pts)\n\tdefer pv.Close()\n\n\tFillPoly(&img, pv, white)\n\n\tif v := img.GetUCharAt(10, 10); v != 255 {\n\t\tt.Errorf(\"TestFillPoly(): wrong pixel value = %v, want = %v\", v, 255)\n\t}\n}\n\nfunc TestFillPolyWithParams(t *testing.T) {\n\ttests := []struct {\n\t\tname   string      // name of testcase\n\t\toffset image.Point // offset to the FillPolyWithParams function\n\t\tpoint  image.Point // point to be checked\n\t\tresult uint8       // expected value at the point to be checked\n\t}{\n\t\t{\n\t\t\tname:   \"No offset\",\n\t\t\tpoint:  image.Point{10, 10},\n\t\t\tresult: 255,\n\t\t}, {\n\t\t\tname:   \"Offset of 2\",\n\t\t\toffset: image.Point{2, 2},\n\t\t\tpoint:  image.Point{12, 12},\n\t\t\tresult: 255,\n\t\t},\n\t}\n\twhite := color.RGBA{255, 255, 255, 0}\n\tpts := [][]image.Point{\n\t\t{\n\t\t\timage.Pt(10, 10),\n\t\t\timage.Pt(10, 20),\n\t\t\timage.Pt(20, 20),\n\t\t\timage.Pt(20, 10),\n\t\t},\n\t}\n\tpv := NewPointsVectorFromPoints(pts)\n\tdefer pv.Close()\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\timg := NewMatWithSize(100, 100, MatTypeCV8UC1)\n\t\t\tdefer img.Close()\n\n\t\t\tFillPolyWithParams(&img, pv, white, Line4, 0, tc.offset)\n\n\t\t\tif v := img.GetUCharAt(tc.point.X, tc.point.Y); v != tc.result {\n\t\t\t\tt.Errorf(\"Wrong pixel value; got = %v, want = %v\", v, tc.result)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestPolylines(t *testing.T) {\n\timg := NewMatWithSize(100, 100, MatTypeCV8UC1)\n\tdefer img.Close()\n\n\twhite := color.RGBA{255, 255, 255, 0}\n\tpts := [][]image.Point{\n\t\t{\n\t\t\timage.Pt(10, 10),\n\t\t\timage.Pt(10, 20),\n\t\t\timage.Pt(20, 20),\n\t\t\timage.Pt(20, 10),\n\t\t},\n\t}\n\tpv := NewPointsVectorFromPoints(pts)\n\tdefer pv.Close()\n\n\tPolylines(&img, pv, true, white, 1)\n\n\tif v := img.GetUCharAt(10, 10); v != 255 {\n\t\tt.Errorf(\"TestPolylines(): wrong pixel value = %v, want = %v\", v, 255)\n\t}\n}\n\nfunc TestRemap(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadUnchanged)\n\tdefer src.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tmap1 := NewMatWithSize(256, 256, MatTypeCV16SC2)\n\tdefer map1.Close()\n\tmap1.SetFloatAt(50, 50, 25.4)\n\tmap2 := NewMat()\n\tdefer map2.Close()\n\n\tRemap(src, &dst, &map1, &map2, InterpolationDefault, BorderConstant, color.RGBA{0, 0, 0, 0})\n\n\tif ok := dst.Empty(); ok {\n\t\tt.Errorf(\"Remap(): dst is empty\")\n\t}\n}\n\nfunc TestFilter2D(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadUnchanged)\n\tdefer src.Close()\n\n\tdst := src.Clone()\n\tdefer dst.Close()\n\n\tkernel := GetStructuringElement(MorphRect, image.Pt(1, 1))\n\tdefer kernel.Close()\n\n\tFilter2D(src, &dst, -1, kernel, image.Pt(-1, -1), 0, BorderDefault)\n\n\tif ok := dst.Empty(); ok {\n\t\tt.Errorf(\"Filter2D(): dst is empty\")\n\t}\n}\n\nfunc TestSepFilter2D(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadUnchanged)\n\tdefer src.Close()\n\n\tdst := src.Clone()\n\tdefer dst.Close()\n\n\tkernelX := GetStructuringElement(MorphRect, image.Pt(1, 1))\n\tdefer kernelX.Close()\n\tkernelY := GetStructuringElement(MorphRect, image.Pt(1, 1))\n\tdefer kernelY.Close()\n\n\tSepFilter2D(src, &dst, -1, kernelX, kernelY, image.Pt(-1, -1), 0, BorderDefault)\n\n\tif ok := dst.Empty(); ok {\n\t\tt.Errorf(\"Filter2D(): dst is empty\")\n\t}\n}\n\nfunc TestLogPolar(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadUnchanged)\n\tdefer src.Close()\n\n\tdst := src.Clone()\n\tdefer dst.Close()\n\n\tLogPolar(src, &dst, image.Pt(22, 22), 1, InterpolationDefault)\n\n\tif ok := dst.Empty(); ok {\n\t\tt.Errorf(\"LogPolar(): dst is empty\")\n\t}\n}\n\nfunc TestLinearPolar(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadUnchanged)\n\tdefer src.Close()\n\n\tdst := src.Clone()\n\tdefer dst.Close()\n\n\tLinearPolar(src, &dst, image.Pt(22, 22), 1, InterpolationDefault)\n\n\tif ok := dst.Empty(); ok {\n\t\tt.Errorf(\"LinearPolar(): dst is empty\")\n\t}\n}\n\nfunc TestFitLine(t *testing.T) {\n\tpoints := []image.Point{image.Pt(125, 24), image.Pt(124, 75), image.Pt(175, 76), image.Pt(176, 25)}\n\tpv := NewPointVectorFromPoints(points)\n\tdefer pv.Close()\n\n\tline := NewMat()\n\tdefer line.Close()\n\n\tFitLine(pv, &line, DistL2, 0, 0.01, 0.01)\n\n\tif ok := line.Empty(); ok {\n\t\tt.Errorf(\"FitLine(): line is empty\")\n\t}\n}\n\nfunc TestMatchShapes(t *testing.T) {\n\tpoints1 := []image.Point{image.Pt(0, 0), image.Pt(1, 0), image.Pt(2, 2), image.Pt(3, 3), image.Pt(3, 4)}\n\tpoints2 := []image.Point{image.Pt(0, 0), image.Pt(1, 0), image.Pt(2, 3), image.Pt(3, 3), image.Pt(3, 5)}\n\tlowerSimilarity := 2.0\n\tupperSimilarity := 3.0\n\n\tcontour1 := NewPointVectorFromPoints(points1)\n\tdefer contour1.Close()\n\n\tcontour2 := NewPointVectorFromPoints(points2)\n\tdefer contour2.Close()\n\n\tsimilarity := MatchShapes(contour1, contour2, ContoursMatchI2, 0)\n\n\tif similarity < lowerSimilarity {\n\t\tt.Errorf(\"MatchShapes(): incorrect calculation, should be more than %f, got %f\", lowerSimilarity, similarity)\n\t}\n\n\tif similarity > upperSimilarity {\n\t\tt.Errorf(\"MatchShapes(): incorrect calculation, should be lower than %f, got %f\", upperSimilarity, similarity)\n\t}\n}\n\nfunc TestInvertAffineTransform(t *testing.T) {\n\tsrc := NewMatWithSize(2, 3, MatTypeCV32F)\n\tdefer src.Close()\n\n\tdst := NewMatWithSize(2, 3, MatTypeCV32F)\n\tdefer dst.Close()\n\n\tInvertAffineTransform(src, &dst)\n\n\tif ok := dst.Empty(); ok {\n\t\tt.Errorf(\"InvertAffineTransform(): dst is empty\")\n\t}\n}\n\nfunc TestCLAHE(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in NewCLAHE test\")\n\t}\n\tdefer img.Close()\n\n\tsrc := NewMat()\n\tdefer src.Close()\n\timg.ConvertTo(&src, MatTypeCV8UC1)\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tc := NewCLAHE()\n\tdefer c.Close()\n\tc.Apply(src, &dst)\n\tif dst.Empty() || img.Rows() != dst.Rows() || img.Cols() != dst.Cols() {\n\t\tt.Error(\"Invalid NewCLAHE test\")\n\t}\n}\n\nfunc TestCLAHEWithParams(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in CLAHEWithParams test\")\n\t}\n\tdefer img.Close()\n\n\tsrc := NewMat()\n\tdefer src.Close()\n\timg.ConvertTo(&src, MatTypeCV8UC1)\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tc := NewCLAHEWithParams(2.0, image.Pt(10, 10))\n\tdefer c.Close()\n\tc.Apply(src, &dst)\n\tif dst.Empty() || img.Rows() != dst.Rows() || img.Cols() != dst.Cols() {\n\t\tt.Error(\"Invalid NewCLAHEWithParams test\")\n\t}\n}\n\nfunc TestPhaseCorrelate(t *testing.T) {\n\ttemplate := IMRead(\"images/simple.jpg\", IMReadGrayScale)\n\tmatched := IMRead(\"images/simple-translated.jpg\", IMReadGrayScale)\n\tnotMatchedOrig := IMRead(\"images/space_shuttle.jpg\", IMReadGrayScale)\n\tnotMatched := NewMat()\n\n\tdefer template.Close()\n\tdefer matched.Close()\n\tdefer notMatchedOrig.Close()\n\tdefer notMatched.Close()\n\n\tResize(notMatchedOrig, &notMatched, image.Point{X: matched.Size()[0], Y: matched.Size()[1]}, 0, 0, InterpolationLinear)\n\n\ttemplate32FC1 := NewMat()\n\tmatched32FC1 := NewMat()\n\tnotMatched32FC1 := NewMat()\n\n\tdefer template32FC1.Close()\n\tdefer matched32FC1.Close()\n\tdefer notMatched32FC1.Close()\n\n\ttemplate.ConvertTo(&template32FC1, MatTypeCV32FC1)\n\tmatched.ConvertTo(&matched32FC1, MatTypeCV32FC1)\n\tnotMatched.ConvertTo(&notMatched32FC1, MatTypeCV32FC1)\n\n\twindow := NewMat()\n\tdefer window.Close()\n\n\tshiftTranslated, responseTranslated := PhaseCorrelate(template32FC1, matched32FC1, window)\n\t_, responseDifferent := PhaseCorrelate(template32FC1, notMatched32FC1, window)\n\n\tif !(shiftTranslated.X < 15) || !(shiftTranslated.Y < 15) {\n\t\tt.Errorf(\"expected shift to be > 15 pixels, got %v\", shiftTranslated)\n\t}\n\n\tif responseTranslated < 0.85 {\n\t\tt.Errorf(\"expected response for translated image to be > 0.85, got %f\", responseTranslated)\n\t}\n\n\tif responseDifferent > 0.05 {\n\t\tt.Errorf(\"expected response for different image to be < 0.05, but got %f\", responseDifferent)\n\t}\n}\n\nfunc TestCreateHanningWindow(t *testing.T) {\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tCreateHanningWindow(&dst, image.Pt(100, 100), MatTypeCV32F)\n\n\tif dst.Empty() {\n\t\tt.Error(\"Invalid CreateHanningWindow test\")\n\t}\n}\n\nfunc TestMatToImage(t *testing.T) {\n\tmat1 := NewMatWithSize(101, 102, MatTypeCV8UC3)\n\tdefer mat1.Close()\n\n\timg, err := mat1.ToImage()\n\tif err != nil {\n\t\tt.Errorf(\"TestToImage %v.\", err)\n\t}\n\n\tif img.Bounds().Dx() != 102 {\n\t\tt.Errorf(\"TestToImage incorrect width got %d.\", img.Bounds().Dx())\n\t}\n\n\tif img.Bounds().Dy() != 101 {\n\t\tt.Errorf(\"TestToImage incorrect height got %d.\", img.Bounds().Dy())\n\t}\n\n\tmatreg := mat1.Region(image.Rect(25, 25, 75, 75))\n\tdefer matreg.Close()\n\timg, err = matreg.ToImage()\n\tif err != nil {\n\t\tt.Errorf(\"Expected error.\")\n\t}\n\n\tmat2 := NewMatWithSize(101, 102, MatTypeCV8UC1)\n\tdefer mat2.Close()\n\n\timg, err = mat2.ToImage()\n\tif err != nil {\n\t\tt.Errorf(\"TestToImage %v.\", err)\n\t}\n\n\tmat3 := NewMatWithSize(101, 102, MatTypeCV8UC4)\n\tdefer mat3.Close()\n\n\timg, err = mat3.ToImage()\n\tif err != nil {\n\t\tt.Errorf(\"TestToImage %v.\", err)\n\t}\n\n\tmatreg3 := mat3.Region(image.Rect(25, 25, 75, 75))\n\tdefer matreg3.Close()\n\timg, err = matreg3.ToImage()\n\tif err != nil {\n\t\tt.Errorf(\"Expected error.\")\n\t}\n\n\tmatWithUnsupportedType := NewMatWithSize(101, 102, MatTypeCV8S)\n\tdefer matWithUnsupportedType.Close()\n\n\t_, err = matWithUnsupportedType.ToImage()\n\tif err == nil {\n\t\tt.Error(\"TestToImage expected error got nil.\")\n\t}\n}\n\nfunc TestMatToImageYUV(t *testing.T) {\n\tmat1 := NewMatWithSize(101, 102, MatTypeCV8UC3)\n\tdefer mat1.Close()\n\n\timg, err := mat1.ToImageYUV()\n\tif err != nil {\n\t\tt.Errorf(\"TestToImage %v.\", err)\n\t}\n\n\tif img.Bounds().Dx() != 102 {\n\t\tt.Errorf(\"TestToImage incorrect width got %d.\", img.Bounds().Dx())\n\t}\n\n\tif img.Bounds().Dy() != 101 {\n\t\tt.Errorf(\"TestToImage incorrect height got %d.\", img.Bounds().Dy())\n\t}\n\n\tmatreg := mat1.Region(image.Rect(25, 25, 75, 75))\n\tdefer matreg.Close()\n\timg, err = matreg.ToImageYUV()\n\tif err != nil {\n\t\tt.Errorf(\"Expected error.\")\n\t}\n\n\tmat2 := NewMatWithSize(101, 102, MatTypeCV8UC1)\n\tdefer mat2.Close()\n\n\timg, err = mat2.ToImageYUV()\n\tif err != nil {\n\t\tt.Errorf(\"TestToImageYUV %v.\", err)\n\t}\n\n\tmat3 := NewMatWithSize(101, 102, MatTypeCV8UC4)\n\tdefer mat3.Close()\n\n\timg, err = mat3.ToImageYUV()\n\tif err != nil {\n\t\tt.Errorf(\"TestToImageYUV %v.\", err)\n\t}\n\n\tmatreg3 := mat3.Region(image.Rect(25, 25, 75, 75))\n\tdefer matreg3.Close()\n\timg, err = matreg3.ToImageYUV()\n\tif err != nil {\n\t\tt.Errorf(\"Expected error.\")\n\t}\n\n\tmatWithUnsupportedType := NewMatWithSize(101, 102, MatTypeCV8S)\n\tdefer matWithUnsupportedType.Close()\n\n\t_, err = matWithUnsupportedType.ToImageYUV()\n\tif err == nil {\n\t\tt.Error(\"TestToImageYUV expected error got nil.\")\n\t}\n}\n\nfunc TestMatToImageYUVWithParams(t *testing.T) {\n\tmat1 := NewMatWithSize(101, 102, MatTypeCV8UC3)\n\tdefer mat1.Close()\n\n\timg, err := mat1.ToImageYUVWithParams(image.YCbCrSubsampleRatio420)\n\tif err != nil {\n\t\tt.Errorf(\"TestToImage %v.\", err)\n\t}\n\n\tif img.Bounds().Dx() != 102 {\n\t\tt.Errorf(\"TestToImage incorrect width got %d.\", img.Bounds().Dx())\n\t}\n\n\tif img.Bounds().Dy() != 101 {\n\t\tt.Errorf(\"TestToImage incorrect height got %d.\", img.Bounds().Dy())\n\t}\n\n\tmatreg := mat1.Region(image.Rect(25, 25, 75, 75))\n\tdefer matreg.Close()\n\timg, err = matreg.ToImageYUVWithParams(image.YCbCrSubsampleRatio420)\n\tif err != nil {\n\t\tt.Errorf(\"Expected error.\")\n\t}\n\n\tmat2 := NewMatWithSize(101, 102, MatTypeCV8UC1)\n\tdefer mat2.Close()\n\n\timg, err = mat2.ToImageYUVWithParams(image.YCbCrSubsampleRatio420)\n\tif err != nil {\n\t\tt.Errorf(\"TestToImageYUVWithParams image.YCbCrSubsampleRatio420%v.\", err)\n\t}\n\n\tmat3 := NewMatWithSize(101, 102, MatTypeCV8UC4)\n\tdefer mat3.Close()\n\n\timg, err = mat3.ToImageYUVWithParams(image.YCbCrSubsampleRatio420)\n\tif err != nil {\n\t\tt.Errorf(\"TestToImageYUVWithParams image.YCbCrSubsampleRatio420%v.\", err)\n\t}\n\n\tmatreg3 := mat3.Region(image.Rect(25, 25, 75, 75))\n\tdefer matreg3.Close()\n\timg, err = matreg3.ToImageYUVWithParams(image.YCbCrSubsampleRatio420)\n\tif err != nil {\n\t\tt.Errorf(\"Expected error.\")\n\t}\n\n\tmatWithUnsupportedType := NewMatWithSize(101, 102, MatTypeCV8S)\n\tdefer matWithUnsupportedType.Close()\n\n\t_, err = matWithUnsupportedType.ToImageYUVWithParams(image.YCbCrSubsampleRatio420)\n\tif err == nil {\n\t\tt.Error(\"TestToImageYUVWithParams image.YCbCrSubsampleRatio420expected error got nil.\")\n\t}\n}\n\n// Tests that image is the same after converting to Mat and back to Image\nfunc TestImageToMatRGBA(t *testing.T) {\n\tfile, err := os.Open(\"images/gocvlogo.png\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer file.Close()\n\timg0, _, err := image.Decode(file)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tmat, err := ImageToMatRGBA(img0)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer mat.Close()\n\timg1, err := mat.ToImage()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tif !compareImages(img0, img1) {\n\t\tt.Errorf(\"Image after converting to Mat and back to Image isn't the same\")\n\t}\n\n\timg3 := image.NewRGBA(image.Rect(0, 0, 200, 200))\n\tmat3, err := ImageToMatRGBA(img3)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tdefer mat3.Close()\n}\n\n// Tests that image is the same after converting to Mat and back to Image\nfunc TestImageToMatRGB(t *testing.T) {\n\tfile, err := os.Open(\"images/gocvlogo.jpg\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer file.Close()\n\timg0, _, err := image.Decode(file)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tmat, err := ImageToMatRGB(img0)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer mat.Close()\n\timg1, err := mat.ToImage()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tif !compareImages(img0, img1) {\n\t\tt.Errorf(\"Image after converting to Mat and back to Image isn't the same\")\n\t}\n\n\timg3 := image.NewRGBA(image.Rect(0, 0, 200, 200))\n\tmat3, err := ImageToMatRGB(img3)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tdefer mat3.Close()\n}\n\nfunc TestImageGrayToMatGray(t *testing.T) {\n\tfile, err := os.Open(\"images/gocvlogo.jpg\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer file.Close()\n\timgSrc, _, err := image.Decode(file)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\timg0 := image.NewGray(imgSrc.Bounds())\n\tdraw.Draw(img0, imgSrc.Bounds(), imgSrc, image.ZP, draw.Src)\n\n\tmat, err := ImageGrayToMatGray(img0)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer mat.Close()\n\timg1, err := mat.ToImage()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tif !compareImages(img0, img1) {\n\t\tt.Errorf(\"Image after converting to Mat and back to Image isn't the same\")\n\t}\n}\n\nfunc TestAccumulate(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadUnchanged)\n\tdefer src.Close()\n\n\tdst := NewMatWithSizes(src.Size(), MatTypeCV64FC3)\n\tdefer dst.Close()\n\n\tAccumulate(src, &dst)\n\n\tif ok := dst.Empty(); ok {\n\t\tt.Errorf(\"Accumulate: dst is empty\")\n\t}\n}\n\nfunc TestAccumulateWithMask(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadUnchanged)\n\tdefer src.Close()\n\n\tdst := NewMatWithSizes(src.Size(), MatTypeCV64FC3)\n\tdefer dst.Close()\n\n\tmask := NewMat()\n\tdefer mask.Close()\n\tAccumulateWithMask(src, &dst, mask)\n\n\tif ok := dst.Empty(); ok {\n\t\tt.Errorf(\"Accumulate: dst is empty\")\n\t}\n}\n\nfunc TestAccumulateSquare(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadUnchanged)\n\tdefer src.Close()\n\n\tdst := NewMatWithSizes(src.Size(), MatTypeCV64FC3)\n\tdefer dst.Close()\n\n\tAccumulateSquare(src, &dst)\n\n\tif ok := dst.Empty(); ok {\n\t\tt.Errorf(\"Accumulate: dst is empty\")\n\t}\n}\n\nfunc TestAccumulateSquareWithMask(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadUnchanged)\n\tdefer src.Close()\n\n\tdst := NewMatWithSizes(src.Size(), MatTypeCV64FC3)\n\tdefer dst.Close()\n\n\tmask := NewMat()\n\tdefer mask.Close()\n\tAccumulateSquareWithMask(src, &dst, mask)\n\n\tif ok := dst.Empty(); ok {\n\t\tt.Errorf(\"Accumulate: dst is empty\")\n\t}\n}\n\nfunc TestAccumulateProduct(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadUnchanged)\n\tdefer src.Close()\n\n\tsrc2 := src.Clone()\n\tdefer src2.Close()\n\n\tdst := NewMatWithSizes(src.Size(), MatTypeCV64FC3)\n\tdefer dst.Close()\n\n\tAccumulateProduct(src, src2, &dst)\n\n\tif ok := dst.Empty(); ok {\n\t\tt.Errorf(\"Accumulate: dst is empty\")\n\t}\n}\n\nfunc TestAccumulateProductWithMask(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadUnchanged)\n\tdefer src.Close()\n\n\tsrc2 := src.Clone()\n\tdefer src2.Close()\n\n\tdst := NewMatWithSizes(src.Size(), MatTypeCV64FC3)\n\tdefer dst.Close()\n\n\tmask := NewMat()\n\tdefer mask.Close()\n\tAccumulateProductWithMask(src, src2, &dst, mask)\n\n\tif ok := dst.Empty(); ok {\n\t\tt.Errorf(\"Accumulate: dst is empty\")\n\t}\n}\n\nfunc TestAccumulatedWeighted(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadUnchanged)\n\tdefer src.Close()\n\n\tdst := NewMatWithSizes(src.Size(), MatTypeCV64FC3)\n\tdefer dst.Close()\n\n\tAccumulatedWeighted(src, &dst, 0.1)\n\n\tif ok := dst.Empty(); ok {\n\t\tt.Errorf(\"AccumulatedWeighted: dst is empty\")\n\t}\n}\n\nfunc TestAccumulatedWeightedWithMask(t *testing.T) {\n\tsrc := IMRead(\"images/gocvlogo.jpg\", IMReadUnchanged)\n\tdefer src.Close()\n\n\tdst := NewMatWithSizes(src.Size(), MatTypeCV64FC3)\n\tdefer dst.Close()\n\n\tmask := NewMat()\n\tdefer mask.Close()\n\tAccumulatedWeightedWithMask(src, &dst, 0.1, mask)\n\n\tif ok := dst.Empty(); ok {\n\t\tt.Errorf(\"AccumulatedWeighted: dst is empty\")\n\t}\n}\n"
        },
        {
          "name": "mat_noprofile.go",
          "type": "blob",
          "size": 0.4091796875,
          "content": "//go:build !matprofile\n// +build !matprofile\n\npackage gocv\n\n/*\n#include <stdlib.h>\n#include \"core.h\"\n*/\nimport \"C\"\n\n// addMatToProfile does nothing if matprofile tag is not set.\nfunc addMatToProfile(p C.Mat) {\n\treturn\n}\n\n// newMat returns a new Mat from a C Mat\nfunc newMat(p C.Mat) Mat {\n\treturn Mat{p: p}\n}\n\n// Close the Mat object.\nfunc (m *Mat) Close() error {\n\tC.Mat_Close(m.p)\n\tm.p = nil\n\tm.d = nil\n\treturn nil\n}\n"
        },
        {
          "name": "mat_profile.go",
          "type": "blob",
          "size": 2.3544921875,
          "content": "//go:build matprofile\n// +build matprofile\n\npackage gocv\n\n/*\n#include <stdlib.h>\n#include \"core.h\"\n*/\nimport (\n\t\"C\"\n)\n\nimport (\n\t\"runtime/pprof\"\n)\n\n// MatProfile a pprof.Profile that contains stack traces that led to (currently)\n// unclosed Mat's creations.  Every time a Mat is created, the stack trace is\n// added to this profile and every time the Mat is closed the trace is removed.\n// In a program that is not leaking, this profile's count should not\n// continuously increase and ideally when a program is terminated the count\n// should be zero.  You can get the count at any time with:\n//\n//\tgocv.MatProfile.Count()\n//\n// and you can display the current entries with:\n//\n//\tvar b bytes.Buffer\n//\tgocv.MatProfile.WriteTo(&b, 1)\n//\tfmt.Print(b.String())\n//\n// This will display stack traces of where the unclosed Mats were instantiated.\n// For example, the results could look something like this:\n//\n//\t1 @ 0x4146a0c 0x4146a57 0x4119666 0x40bb18f 0x405a841\n//\t#\t0x4146a0b\tgocv.io/x/gocv.newMat+0x4b\t/go/src/gocv.io/x/gocv/core.go:120\n//\t#\t0x4146a56\tgocv.io/x/gocv.NewMat+0x26\t/go/src/gocv.io/x/gocv/core.go:126\n//\t#\t0x4119665\tgocv.io/x/gocv.TestMat+0x25\t/go/src/gocv.io/x/gocv/core_test.go:29\n//\t#\t0x40bb18e\ttesting.tRunner+0xbe\t\t/usr/local/Cellar/go/1.11/libexec/src/testing/testing.go:827\n//\n// Furthermore, if the program is a long running process or if gocv is being used on a\n// web server, it may be helpful to install the HTTP interface using:\n//\n//\timport _ \"net/http/pprof\"\n//\n// In order to include the MatProfile custom profiler, you MUST build or run your application\n// or tests using the following build tag:\n// -tags matprofile\n//\n// For more information, see the runtime/pprof package documentation.\nvar MatProfile *pprof.Profile\n\nfunc init() {\n\tprofName := \"gocv.io/x/gocv.Mat\"\n\tMatProfile = pprof.Lookup(profName)\n\tif MatProfile == nil {\n\t\tMatProfile = pprof.NewProfile(profName)\n\t}\n}\n\n// addMatToProfile records Mat to the MatProfile.\nfunc addMatToProfile(p C.Mat) {\n\tMatProfile.Add(p, 1)\n\treturn\n}\n\n// newMat returns a new Mat from a C Mat and records it to the MatProfile.\nfunc newMat(p C.Mat) Mat {\n\tm := Mat{p: p}\n\tMatProfile.Add(p, 1)\n\treturn m\n}\n\n// Close the Mat object.\nfunc (m *Mat) Close() error {\n\t// NOTE: The pointer must be removed from the profile before it is deleted to\n\t// avoid a data race.\n\tMatProfile.Remove(m.p)\n\tC.Mat_Close(m.p)\n\tm.p = nil\n\tm.d = nil\n\treturn nil\n}\n"
        },
        {
          "name": "matprofile_test.go",
          "type": "blob",
          "size": 2.0078125,
          "content": "//go:build matprofile\n// +build matprofile\n\npackage gocv\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n)\n\nfunc TestMain(m *testing.M) {\n\tret := m.Run()\n\tif MatProfile.Count() != 0 {\n\t\tvar b bytes.Buffer\n\t\tMatProfile.WriteTo(&b, 1)\n\t\tfmt.Printf(\"Not all Mat's in tests were closed: %v\", b.String())\n\t\tos.Exit(1)\n\t}\n\tos.Exit(ret)\n}\n\nfunc TestMatProfile(t *testing.T) {\n\tif MatProfile.Count() != 0 {\n\t\tvar b bytes.Buffer\n\t\tMatProfile.WriteTo(&b, 1)\n\t\tt.Errorf(\"Mat profile should start with 0 entries. A test failure here likely means that some other test is not closing all Mats. Here are the current profile entries:\\n%v\", b.String())\n\t}\n\tmat := NewMat()\n\tif MatProfile.Count() != 1 {\n\t\tt.Errorf(\"Mat profile should == 1 after NewMat but instead was %v\", MatProfile.Count())\n\t}\n\tmat2 := NewMat()\n\tif MatProfile.Count() != 2 {\n\t\tt.Errorf(\"Mat profile should == 2 after NewMat but instead was %v\", MatProfile.Count())\n\t}\n\tmat.Close()\n\tmat2.Close()\n\tif MatProfile.Count() != 0 {\n\t\tt.Errorf(\"Mat profile should == 0 after Close but instead was %v\", MatProfile.Count())\n\t}\n}\n\nfunc TestAddMatToProfile(t *testing.T) {\n\tif MatProfile.Count() != 0 {\n\t\tvar b bytes.Buffer\n\t\tMatProfile.WriteTo(&b, 1)\n\t\tt.Errorf(\"Mat profile should start with 0 entries. A test failure here likely means that some other test is not closing all Mats. Here are the current profile entries:\\n%v\", b.String())\n\t}\n\tmat := NewMatWithSize(5, 5, MatTypeCV8UC3)\n\tif MatProfile.Count() != 1 {\n\t\tt.Errorf(\"Mat profile should == 1 after creating 3 channel mat but instead was %v\", MatProfile.Count())\n\t}\n\n\tchannels := Split(mat)\n\tif MatProfile.Count() != 4 {\n\t\tt.Errorf(\"Mat profile should == 4 after split channel but instead was %v\", MatProfile.Count())\n\t}\n\n\tfor _, channel := range channels {\n\t\tchannel.Close()\n\t}\n\tif MatProfile.Count() != 1 {\n\t\tt.Errorf(\"Mat profile should == 1 after closing channels but instead was %v\", MatProfile.Count())\n\t}\n\n\tmat.Close()\n\tif MatProfile.Count() != 0 {\n\t\tt.Errorf(\"Mat profile should == 0 after closing all mats but instead was %v\", MatProfile.Count())\n\t}\n}\n"
        },
        {
          "name": "objdetect.cpp",
          "type": "blob",
          "size": 9.9228515625,
          "content": "#include \"objdetect.h\"\n\n// CascadeClassifier\n\nCascadeClassifier CascadeClassifier_New() {\n    return new cv::CascadeClassifier();\n}\n\nvoid CascadeClassifier_Close(CascadeClassifier cs) {\n    delete cs;\n}\n\nint CascadeClassifier_Load(CascadeClassifier cs, const char* name) {\n    return cs->load(name);\n}\n\nstruct Rects CascadeClassifier_DetectMultiScale(CascadeClassifier cs, Mat img) {\n    std::vector<cv::Rect> detected;\n    cs->detectMultiScale(*img, detected); // uses all default parameters\n    Rect* rects = new Rect[detected.size()];\n\n    for (size_t i = 0; i < detected.size(); ++i) {\n        Rect r = {detected[i].x, detected[i].y, detected[i].width, detected[i].height};\n        rects[i] = r;\n    }\n\n    Rects ret = {rects, (int)detected.size()};\n    return ret;\n}\n\nstruct Rects CascadeClassifier_DetectMultiScaleWithParams(CascadeClassifier cs, Mat img,\n        double scale, int minNeighbors, int flags, Size minSize, Size maxSize) {\n\n    cv::Size minSz(minSize.width, minSize.height);\n    cv::Size maxSz(maxSize.width, maxSize.height);\n\n    std::vector<cv::Rect> detected;\n    cs->detectMultiScale(*img, detected, scale, minNeighbors, flags, minSz, maxSz);\n    Rect* rects = new Rect[detected.size()];\n\n    for (size_t i = 0; i < detected.size(); ++i) {\n        Rect r = {detected[i].x, detected[i].y, detected[i].width, detected[i].height};\n        rects[i] = r;\n    }\n\n    Rects ret = {rects, (int)detected.size()};\n    return ret;\n}\n\n// HOGDescriptor\n\nHOGDescriptor HOGDescriptor_New() {\n    return new cv::HOGDescriptor();\n}\n\nvoid HOGDescriptor_Close(HOGDescriptor hog) {\n    delete hog;\n}\n\nint HOGDescriptor_Load(HOGDescriptor hog, const char* name) {\n    return hog->load(name);\n}\n\nstruct Rects HOGDescriptor_DetectMultiScale(HOGDescriptor hog, Mat img) {\n    std::vector<cv::Rect> detected;\n    hog->detectMultiScale(*img, detected);\n    Rect* rects = new Rect[detected.size()];\n\n    for (size_t i = 0; i < detected.size(); ++i) {\n        Rect r = {detected[i].x, detected[i].y, detected[i].width, detected[i].height};\n        rects[i] = r;\n    }\n\n    Rects ret = {rects, (int)detected.size()};\n    return ret;\n}\n\nstruct Rects HOGDescriptor_DetectMultiScaleWithParams(HOGDescriptor hog, Mat img,\n        double hitThresh, Size winStride, Size padding, double scale, double finalThresh,\n        bool useMeanshiftGrouping) {\n\n    cv::Size wSz(winStride.width, winStride.height);\n    cv::Size pSz(padding.width, padding.height);\n\n    std::vector<cv::Rect> detected;\n    hog->detectMultiScale(*img, detected, hitThresh, wSz, pSz, scale, finalThresh,\n                          useMeanshiftGrouping);\n    Rect* rects = new Rect[detected.size()];\n\n    for (size_t i = 0; i < detected.size(); ++i) {\n        Rect r = {detected[i].x, detected[i].y, detected[i].width, detected[i].height};\n        rects[i] = r;\n    }\n\n    Rects ret = {rects, (int)detected.size()};\n    return ret;\n}\n\nMat HOG_GetDefaultPeopleDetector() {\n    return new cv::Mat(cv::HOGDescriptor::getDefaultPeopleDetector());\n}\n\nvoid HOGDescriptor_SetSVMDetector(HOGDescriptor hog, Mat det) {\n    hog->setSVMDetector(*det);\n}\n\nstruct Rects GroupRectangles(struct Rects rects, int groupThreshold, double eps) {\n    std::vector<cv::Rect> vRect;\n\n    for (int i = 0; i < rects.length; ++i) {\n        cv::Rect r = cv::Rect(rects.rects[i].x, rects.rects[i].y, rects.rects[i].width,\n                              rects.rects[i].height);\n        vRect.push_back(r);\n    }\n\n    cv::groupRectangles(vRect, groupThreshold, eps);\n\n    Rect* results = new Rect[vRect.size()];\n\n    for (size_t i = 0; i < vRect.size(); ++i) {\n        Rect r = {vRect[i].x, vRect[i].y, vRect[i].width, vRect[i].height};\n        results[i] = r;\n    }\n\n    Rects ret = {results, (int)vRect.size()};\n    return ret;\n}\n\n// QRCodeDetector\n\nQRCodeDetector QRCodeDetector_New() {\n    return new cv::QRCodeDetector();\n}\n\nvoid QRCodeDetector_Close(QRCodeDetector qr) {\n    delete qr;\n}\n\nconst char* QRCodeDetector_DetectAndDecode(QRCodeDetector qr, Mat input,Mat points,Mat straight_qrcode) {\n  cv::String *str = new cv::String(qr->detectAndDecode(*input,*points,*straight_qrcode)); \n  return str->c_str();\n}\n\nbool QRCodeDetector_Detect(QRCodeDetector qr, Mat input,Mat points) {\n  return qr->detect(*input,*points); \n}\n\nconst char* QRCodeDetector_Decode(QRCodeDetector qr, Mat input,Mat inputPoints,Mat straight_qrcode) {\n  cv::String *str = new cv::String(qr->detectAndDecode(*input,*inputPoints,*straight_qrcode)); \n  return str->c_str();\n}\n\nbool QRCodeDetector_DetectMulti(QRCodeDetector qr, Mat input, Mat points) {\n  return qr->detectMulti(*input,*points);\n}\n\nbool QRCodeDetector_DetectAndDecodeMulti(QRCodeDetector qr, Mat input, CStrings* decoded, Mat points, struct Mats* qrCodes) {\n  std::vector<cv::String> decodedCodes;\n  std::vector<cv::Mat> straightQrCodes;\n  bool res = qr->detectAndDecodeMulti(*input, decodedCodes, *points, straightQrCodes);\n  if (!res) {\n    return res;\n  }\n\n  qrCodes->mats = new Mat[straightQrCodes.size()];\n  qrCodes->length = straightQrCodes.size();\n  for (size_t i = 0; i < straightQrCodes.size(); i++) {\n     qrCodes->mats[i] = new cv::Mat(straightQrCodes[i]);\n  }\n\n  const char **strs = new const char*[decodedCodes.size()];\n  for (size_t i = 0; i < decodedCodes.size(); ++i) {\n      strs[i] = decodedCodes[i].c_str();\n  }\n  decoded->length = decodedCodes.size();\n  decoded->strs = strs;\n  return res;\n}\n\nFaceDetectorYN FaceDetectorYN_Create(const char* model, const char* config, Size size) {\n    cv::String smodel = cv::String(model);\n    cv::String sconfig = cv::String(config);\n    cv::Size   ssize = cv::Size(size.width, size.height);\n\n    return new cv::Ptr<cv::FaceDetectorYN>(cv::FaceDetectorYN::create(smodel, sconfig, ssize));\n}\n\nFaceDetectorYN FaceDetectorYN_Create_WithParams(const char* model, const char* config, Size size, float score_threshold, float nms_threshold, int top_k, int backend_id, int target_id) {\n    cv::String smodel = cv::String(model);\n    cv::String sconfig = cv::String(config);\n    cv::Size   ssize = cv::Size(size.width, size.height);\n\n    return new cv::Ptr<cv::FaceDetectorYN>(cv::FaceDetectorYN::create(smodel, sconfig, ssize, score_threshold, nms_threshold, top_k, backend_id, target_id));\n}\n\nFaceDetectorYN FaceDetectorYN_Create_FromBytes(const char* framework, void* bufferModel, int model_size, void* bufferConfig, int config_size, Size size) {\n    cv::String sframework = cv::String(framework);\n    cv::Size   ssize = cv::Size(size.width, size.height);\n    \n    std::vector<uchar> bufferModelV;\n    std::vector<uchar> bufferConfigV;\n\n    uchar* bmv = (uchar*)bufferModel;\n    uchar* bcv = (uchar*)bufferConfig;\n\n\n    for(int i = 0; i < model_size; i ++) {\n        bufferModelV.push_back(bmv[i]);\n    }\n   for(int i = 0; i < config_size; i ++) {\n        bufferConfigV.push_back(bcv[i]);\n    }\n\n    return new cv::Ptr<cv::FaceDetectorYN>(cv::FaceDetectorYN::create(sframework, bufferModelV, bufferConfigV, ssize));\n}\n\nFaceDetectorYN FaceDetectorYN_Create_FromBytes_WithParams(const char* framework, void* bufferModel, int model_size, void* bufferConfig, int config_size, Size size, float score_threshold, float nms_threshold, int top_k, int backend_id, int target_id) {\n    cv::String sframework = cv::String(framework);\n    cv::Size   ssize = cv::Size(size.width, size.height);\n    \n    std::vector<uchar> bufferModelV;\n    std::vector<uchar> bufferConfigV;\n\n    uchar* bmv = (uchar*)bufferModel;\n    uchar* bcv = (uchar*)bufferConfig;\n\n\n    for(int i = 0; i < model_size; i ++) {\n        bufferModelV.push_back(bmv[i]);\n    }\n    for(int i = 0; i < config_size; i ++) {\n        bufferConfigV.push_back(bcv[i]);\n    }\n\n    return new cv::Ptr<cv::FaceDetectorYN>(cv::FaceDetectorYN::create(sframework, bufferModelV, bufferConfigV, ssize, score_threshold, nms_threshold, top_k, backend_id, target_id));\n}\n\nvoid FaceDetectorYN_Close(FaceDetectorYN fd) {\n    delete fd;\n}\n\nint FaceDetectorYN_Detect(FaceDetectorYN fd, Mat image, Mat faces) {\n    return (*fd)->detect(*image, *faces);\n}\n\nSize FaceDetectorYN_GetInputSize(FaceDetectorYN fd) {\n    Size sz;\n\n    cv::Size cvsz = (*fd)->getInputSize();\n\n    sz.width = cvsz.width;\n    sz.height = cvsz.height;\n\n    return sz;\n}\n\nfloat FaceDetectorYN_GetNMSThreshold(FaceDetectorYN fd) {\n    return (*fd)->getNMSThreshold();\n}\n\nfloat FaceDetectorYN_GetScoreThreshold(FaceDetectorYN fd) {\n    return (*fd)->getScoreThreshold();\n}\n\nint FaceDetectorYN_GetTopK(FaceDetectorYN fd) {\n    return (*fd)->getTopK();\n}\n\nvoid FaceDetectorYN_SetInputSize(FaceDetectorYN fd, Size input_size){\n    cv::Size isz(input_size.width, input_size.height);\n    (*fd)->setInputSize(isz);\n}\n\nvoid FaceDetectorYN_SetNMSThreshold(FaceDetectorYN fd, float nms_threshold){\n    (*fd)->setNMSThreshold(nms_threshold);\n}\n\nvoid FaceDetectorYN_SetScoreThreshold(FaceDetectorYN fd, float score_threshold){\n    (*fd)->setScoreThreshold(score_threshold);\n}\n\nvoid FaceDetectorYN_SetTopK(FaceDetectorYN fd, int top_k){\n    (*fd)->setTopK(top_k);\n}\n\nFaceRecognizerSF FaceRecognizerSF_Create(const char* model, const char* config) {\n    return FaceRecognizerSF_Create_WithParams(model, config, 0, 0);\n}\n\nFaceRecognizerSF FaceRecognizerSF_Create_WithParams(const char* model, const char* config, int backend_id, int target_id) {\n    cv::Ptr<cv::FaceRecognizerSF>* p = new cv::Ptr<cv::FaceRecognizerSF>(cv::FaceRecognizerSF::create(model, config, backend_id, target_id));\n    return p;\n}\n\nvoid FaceRecognizerSF_Close(FaceRecognizerSF fr) {\n    delete fr;\n}\n\nvoid FaceRecognizerSF_AlignCrop(FaceRecognizerSF fr, Mat src_img, Mat face_box, Mat aligned_img) {\n    (*fr)->alignCrop(*src_img, *face_box, *aligned_img);\n}\n\nvoid FaceRecognizerSF_Feature(FaceRecognizerSF fr, Mat aligned_img, Mat face_feature) {\n    (*fr)->feature(*aligned_img, *face_feature);\n}\n\nfloat FaceRecognizerSF_Match(FaceRecognizerSF fr, Mat face_feature1, Mat face_feature2) {\n    return FaceRecognizerSF_Match_WithParams(fr, face_feature1, face_feature2, 0);\n}\n\nfloat FaceRecognizerSF_Match_WithParams(FaceRecognizerSF fr, Mat face_feature1, Mat face_feature2, int dis_type) {\n    double rv = (*fr)->match(*face_feature1, *face_feature2, dis_type);\n    return (float)rv;\n}"
        },
        {
          "name": "objdetect.go",
          "type": "blob",
          "size": 19.2607421875,
          "content": "package gocv\n\n/*\n#include <stdlib.h>\n#include \"objdetect.h\"\n*/\nimport \"C\"\nimport (\n\t\"image\"\n\t\"unsafe\"\n)\n\n// CascadeClassifier is a cascade classifier class for object detection.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d1/de5/classcv_1_1CascadeClassifier.html\ntype CascadeClassifier struct {\n\tp C.CascadeClassifier\n}\n\n// NewCascadeClassifier returns a new CascadeClassifier.\nfunc NewCascadeClassifier() CascadeClassifier {\n\treturn CascadeClassifier{p: C.CascadeClassifier_New()}\n}\n\n// Close deletes the CascadeClassifier's pointer.\nfunc (c *CascadeClassifier) Close() error {\n\tC.CascadeClassifier_Close(c.p)\n\tc.p = nil\n\treturn nil\n}\n\n// Load cascade classifier from a file.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d1/de5/classcv_1_1CascadeClassifier.html#a1a5884c8cc749422f9eb77c2471958bc\nfunc (c *CascadeClassifier) Load(name string) bool {\n\tcName := C.CString(name)\n\tdefer C.free(unsafe.Pointer(cName))\n\treturn C.CascadeClassifier_Load(c.p, cName) != 0\n}\n\n// DetectMultiScale detects objects of different sizes in the input Mat image.\n// The detected objects are returned as a slice of image.Rectangle structs.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d1/de5/classcv_1_1CascadeClassifier.html#aaf8181cb63968136476ec4204ffca498\nfunc (c *CascadeClassifier) DetectMultiScale(img Mat) []image.Rectangle {\n\tret := C.CascadeClassifier_DetectMultiScale(c.p, img.p)\n\tdefer C.Rects_Close(ret)\n\n\treturn toRectangles(ret)\n}\n\n// DetectMultiScaleWithParams calls DetectMultiScale but allows setting parameters\n// to values other than just the defaults.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d1/de5/classcv_1_1CascadeClassifier.html#aaf8181cb63968136476ec4204ffca498\nfunc (c *CascadeClassifier) DetectMultiScaleWithParams(img Mat, scale float64,\n\tminNeighbors, flags int, minSize, maxSize image.Point) []image.Rectangle {\n\n\tminSz := C.struct_Size{\n\t\twidth:  C.int(minSize.X),\n\t\theight: C.int(minSize.Y),\n\t}\n\n\tmaxSz := C.struct_Size{\n\t\twidth:  C.int(maxSize.X),\n\t\theight: C.int(maxSize.Y),\n\t}\n\n\tret := C.CascadeClassifier_DetectMultiScaleWithParams(c.p, img.p, C.double(scale),\n\t\tC.int(minNeighbors), C.int(flags), minSz, maxSz)\n\tdefer C.Rects_Close(ret)\n\n\treturn toRectangles(ret)\n}\n\n// HOGDescriptor is a Histogram Of Gradiants (HOG) for object detection.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d5/d33/structcv_1_1HOGDescriptor.html#a723b95b709cfd3f95cf9e616de988fc8\ntype HOGDescriptor struct {\n\tp C.HOGDescriptor\n}\n\n// NewHOGDescriptor returns a new HOGDescriptor.\nfunc NewHOGDescriptor() HOGDescriptor {\n\treturn HOGDescriptor{p: C.HOGDescriptor_New()}\n}\n\n// Close deletes the HOGDescriptor's pointer.\nfunc (h *HOGDescriptor) Close() error {\n\tC.HOGDescriptor_Close(h.p)\n\th.p = nil\n\treturn nil\n}\n\n// DetectMultiScale detects objects in the input Mat image.\n// The detected objects are returned as a slice of image.Rectangle structs.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d5/d33/structcv_1_1HOGDescriptor.html#a660e5cd036fd5ddf0f5767b352acd948\nfunc (h *HOGDescriptor) DetectMultiScale(img Mat) []image.Rectangle {\n\tret := C.HOGDescriptor_DetectMultiScale(h.p, img.p)\n\tdefer C.Rects_Close(ret)\n\n\treturn toRectangles(ret)\n}\n\n// DetectMultiScaleWithParams calls DetectMultiScale but allows setting parameters\n// to values other than just the defaults.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d5/d33/structcv_1_1HOGDescriptor.html#a660e5cd036fd5ddf0f5767b352acd948\nfunc (h *HOGDescriptor) DetectMultiScaleWithParams(img Mat, hitThresh float64,\n\twinStride, padding image.Point, scale, finalThreshold float64, useMeanshiftGrouping bool) []image.Rectangle {\n\twSz := C.struct_Size{\n\t\twidth:  C.int(winStride.X),\n\t\theight: C.int(winStride.Y),\n\t}\n\n\tpSz := C.struct_Size{\n\t\twidth:  C.int(padding.X),\n\t\theight: C.int(padding.Y),\n\t}\n\n\tret := C.HOGDescriptor_DetectMultiScaleWithParams(h.p, img.p, C.double(hitThresh),\n\t\twSz, pSz, C.double(scale), C.double(finalThreshold), C.bool(useMeanshiftGrouping))\n\tdefer C.Rects_Close(ret)\n\n\treturn toRectangles(ret)\n}\n\n// HOGDefaultPeopleDetector returns a new Mat with the HOG DefaultPeopleDetector.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d5/d33/structcv_1_1HOGDescriptor.html#a660e5cd036fd5ddf0f5767b352acd948\nfunc HOGDefaultPeopleDetector() Mat {\n\treturn newMat(C.HOG_GetDefaultPeopleDetector())\n}\n\n// SetSVMDetector sets the data for the HOGDescriptor.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d5/d33/structcv_1_1HOGDescriptor.html#a09e354ad701f56f9c550dc0385dc36f1\nfunc (h *HOGDescriptor) SetSVMDetector(det Mat) error {\n\tC.HOGDescriptor_SetSVMDetector(h.p, det.p)\n\treturn nil\n}\n\n// GroupRectangles groups the object candidate rectangles.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d5/d54/group__objdetect.html#ga3dba897ade8aa8227edda66508e16ab9\nfunc GroupRectangles(rects []image.Rectangle, groupThreshold int, eps float64) []image.Rectangle {\n\tcRectArray := make([]C.struct_Rect, len(rects))\n\tfor i, r := range rects {\n\t\tcRect := C.struct_Rect{\n\t\t\tx:      C.int(r.Min.X),\n\t\t\ty:      C.int(r.Min.Y),\n\t\t\twidth:  C.int(r.Size().X),\n\t\t\theight: C.int(r.Size().Y),\n\t\t}\n\t\tcRectArray[i] = cRect\n\t}\n\tcRects := C.struct_Rects{\n\t\trects:  (*C.Rect)(&cRectArray[0]),\n\t\tlength: C.int(len(rects)),\n\t}\n\n\tret := C.GroupRectangles(cRects, C.int(groupThreshold), C.double(eps))\n\n\treturn toRectangles(ret)\n}\n\n// QRCodeDetector groups the object candidate rectangles.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/de/dc3/classcv_1_1QRCodeDetector.html\ntype QRCodeDetector struct {\n\tp C.QRCodeDetector\n}\n\n// newQRCodeDetector returns a new QRCodeDetector from a C QRCodeDetector\nfunc newQRCodeDetector(p C.QRCodeDetector) QRCodeDetector {\n\treturn QRCodeDetector{p: p}\n}\n\nfunc NewQRCodeDetector() QRCodeDetector {\n\treturn newQRCodeDetector(C.QRCodeDetector_New())\n}\n\nfunc (a *QRCodeDetector) Close() error {\n\tC.QRCodeDetector_Close(a.p)\n\ta.p = nil\n\treturn nil\n}\n\n// DetectAndDecode Both detects and decodes QR code.\n//\n// Returns true as long as some QR code was detected even in case where the decoding failed\n// For further details, please see:\n// https://docs.opencv.org/master/de/dc3/classcv_1_1QRCodeDetector.html#a7290bd6a5d59b14a37979c3a14fbf394\nfunc (a *QRCodeDetector) DetectAndDecode(input Mat, points *Mat, straight_qrcode *Mat) string {\n\tgoResult := C.GoString(C.QRCodeDetector_DetectAndDecode(a.p, input.p, points.p, straight_qrcode.p))\n\treturn string(goResult)\n}\n\n// Detect detects QR code in image and returns the quadrangle containing the code.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/de/dc3/classcv_1_1QRCodeDetector.html#a64373f7d877d27473f64fe04bb57d22b\nfunc (a *QRCodeDetector) Detect(input Mat, points *Mat) bool {\n\tresult := C.QRCodeDetector_Detect(a.p, input.p, points.p)\n\treturn bool(result)\n}\n\n// Decode decodes QR code in image once it's found by the detect() method. Returns UTF8-encoded output string or empty string if the code cannot be decoded.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/de/dc3/classcv_1_1QRCodeDetector.html#a4172c2eb4825c844fb1b0ae67202d329\nfunc (a *QRCodeDetector) Decode(input Mat, points Mat, straight_qrcode *Mat) string {\n\tgoResult := C.GoString(C.QRCodeDetector_DetectAndDecode(a.p, input.p, points.p, straight_qrcode.p))\n\treturn string(goResult)\n}\n\n// Detects QR codes in image and finds of the quadrangles containing the codes.\n//\n// Each quadrangle would be returned as a row in the `points` Mat and each point is a Vecf.\n// Returns true if QR code was detected\n// For usage please see TestQRCodeDetector\n// For further details, please see:\n// https://docs.opencv.org/master/de/dc3/classcv_1_1QRCodeDetector.html#aaf2b6b2115b8e8fbc9acf3a8f68872b6\nfunc (a *QRCodeDetector) DetectMulti(input Mat, points *Mat) bool {\n\tresult := C.QRCodeDetector_DetectMulti(a.p, input.p, points.p)\n\treturn bool(result)\n}\n\n// Detects QR codes in image, finds the quadrangles containing the codes, and decodes the QRCodes to strings.\n//\n// Each quadrangle would be returned as a row in the `points` Mat and each point is a Vecf.\n// Returns true as long as some QR code was detected even in case where the decoding failed\n// For usage please see TestQRCodeDetector\n// For further details, please see:\n// https://docs.opencv.org/master/de/dc3/classcv_1_1QRCodeDetector.html#a188b63ffa17922b2c65d8a0ab7b70775\nfunc (a *QRCodeDetector) DetectAndDecodeMulti(input Mat, decoded []string, points *Mat, qrCodes []Mat) bool {\n\tcDecoded := C.CStrings{}\n\tdefer C.CStrings_Close(cDecoded)\n\tcQrCodes := C.struct_Mats{}\n\tdefer C.Mats_Close(cQrCodes)\n\tsuccess := C.QRCodeDetector_DetectAndDecodeMulti(a.p, input.p, &cDecoded, points.p, &cQrCodes)\n\tif !success {\n\t\treturn bool(success)\n\t}\n\n\ttmpCodes := make([]Mat, cQrCodes.length)\n\tfor i := C.int(0); i < cQrCodes.length; i++ {\n\t\ttmpCodes[i].p = C.Mats_get(cQrCodes, i)\n\t}\n\n\tfor _, qr := range tmpCodes {\n\t\tqrCodes = append(qrCodes, qr)\n\t}\n\n\tfor _, s := range toGoStrings(cDecoded) {\n\t\tdecoded = append(decoded, s)\n\t}\n\treturn bool(success)\n}\n\ntype FaceDetectorYN struct {\n\tp C.FaceDetectorYN\n}\n\n// NewFaceDetectorYN Creates an instance of face detector with given parameters.\n//\n// modelPath: the path to the requested model\n//\n// configPath: the path to the config file for compability, which is not requested for ONNX models\n//\n// size: the size of the input image\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/df/d20/classcv_1_1FaceDetectorYN.html#a5f7fb43c60c95ca5ebab78483de02516\nfunc NewFaceDetectorYN(modelPath string, configPath string, size image.Point) FaceDetectorYN {\n\n\tc_model_path := C.CString(modelPath)\n\tdefer C.free(unsafe.Pointer(c_model_path))\n\n\tc_config_path := C.CString(configPath)\n\tdefer C.free(unsafe.Pointer(c_config_path))\n\n\tc_size := C.Size{\n\t\twidth:  C.int(size.X),\n\t\theight: C.int(size.Y),\n\t}\n\n\treturn FaceDetectorYN{p: C.FaceDetectorYN_Create(c_model_path, c_config_path, c_size)}\n}\n\n// NewFaceDetectorYNWithParams Creates an instance of face detector with given parameters.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/df/d20/classcv_1_1FaceDetectorYN.html#a5f7fb43c60c95ca5ebab78483de02516\nfunc NewFaceDetectorYNWithParams(modelPath string, configPath string, size image.Point, scoreThreshold float32, nmsThreshold float32, topK int, backendId int, targetId int) FaceDetectorYN {\n\n\tc_model_path := C.CString(modelPath)\n\tdefer C.free(unsafe.Pointer(c_model_path))\n\n\tc_config_path := C.CString(configPath)\n\tdefer C.free(unsafe.Pointer(c_config_path))\n\n\tc_size := C.Size{\n\t\twidth:  C.int(size.X),\n\t\theight: C.int(size.Y),\n\t}\n\n\treturn FaceDetectorYN{p: C.FaceDetectorYN_Create_WithParams(c_model_path, c_config_path, c_size, C.float(scoreThreshold), C.float(nmsThreshold), C.int(topK), C.int(backendId), C.int(targetId))}\n}\n\n// NewFaceDetectorYNFromBytes Creates an instance of face detector with given parameters.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/df/d20/classcv_1_1FaceDetectorYN.html#aa0796a4bfe2d4709bef81abbae9a927a\nfunc NewFaceDetectorYNFromBytes(framework string, bufferModel []byte, bufferConfig []byte, size image.Point) FaceDetectorYN {\n\n\tc_framework := C.CString(framework)\n\tdefer C.free(unsafe.Pointer(c_framework))\n\n\tc_size := C.Size{\n\t\twidth:  C.int(size.X),\n\t\theight: C.int(size.Y),\n\t}\n\n\treturn FaceDetectorYN{p: C.FaceDetectorYN_Create_FromBytes(c_framework,\n\t\tunsafe.Pointer(unsafe.SliceData(bufferModel)), C.int(len(bufferModel)),\n\t\tunsafe.Pointer(unsafe.SliceData(bufferConfig)), C.int(len(bufferConfig)), c_size)}\n}\n\n// NewFaceDetectorYNFromBuffers Creates an instance of face detector with given parameters.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/df/d20/classcv_1_1FaceDetectorYN.html#aa0796a4bfe2d4709bef81abbae9a927a\nfunc NewFaceDetectorYNFromBytesWithParams(framework string, bufferModel []byte, bufferConfig []byte, size image.Point, scoreThreshold float32, nmsThreshold float32, topK int, backendId int, targetId int) FaceDetectorYN {\n\n\tc_framework := C.CString(framework)\n\tdefer C.free(unsafe.Pointer(c_framework))\n\n\tc_size := C.Size{\n\t\twidth:  C.int(size.X),\n\t\theight: C.int(size.Y),\n\t}\n\n\treturn FaceDetectorYN{p: C.FaceDetectorYN_Create_FromBytes_WithParams(c_framework,\n\t\tunsafe.Pointer(unsafe.SliceData(bufferModel)), C.int(len(bufferModel)),\n\t\tunsafe.Pointer(unsafe.SliceData(bufferConfig)), C.int(len(bufferConfig)), c_size,\n\t\tC.float(scoreThreshold), C.float(nmsThreshold), C.int(topK), C.int(backendId), C.int(targetId))}\n}\n\nfunc (fd *FaceDetectorYN) Close() {\n\tC.FaceDetectorYN_Close(fd.p)\n}\n\n// Detect Detects faces in the input image.\n//\n// image: an image to detect\n//\n// faces: detection results stored in a 2D cv::Mat of shape [num_faces, 15]\n//\n// 0-1: x, y of bbox top left corner\n//\n// 2-3: width, height of bbox\n//\n// 4-5: x, y of right eye (blue point in the example image)\n//\n// 6-7: x, y of left eye (red point in the example image)\n//\n// 8-9: x, y of nose tip (green point in the example image)\n//\n// 10-11: x, y of right corner of mouth (pink point in the example image)\n//\n// 12-13: x, y of left corner of mouth (yellow point in the example image)\n//\n// 14: face score\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/df/d20/classcv_1_1FaceDetectorYN.html#ac05bd075ca3e6edc0e328927aae6f45b\nfunc (fd *FaceDetectorYN) Detect(image Mat, faces *Mat) int {\n\tc_rv := C.FaceDetectorYN_Detect(fd.p, image.p, faces.p)\n\treturn int(c_rv)\n}\n\nfunc (fd *FaceDetectorYN) GetInputSize() image.Point {\n\tsz := C.FaceDetectorYN_GetInputSize(fd.p)\n\n\treturn image.Pt(int(sz.width), int(sz.height))\n}\n\nfunc (fd *FaceDetectorYN) GetNMSThreshold() float32 {\n\tt := C.FaceDetectorYN_GetNMSThreshold(fd.p)\n\treturn float32(t)\n}\n\nfunc (fd *FaceDetectorYN) GetScoreThreshold() float32 {\n\tt := C.FaceDetectorYN_GetScoreThreshold(fd.p)\n\treturn float32(t)\n}\n\nfunc (fd *FaceDetectorYN) GetTopK() int {\n\ti := C.FaceDetectorYN_GetTopK(fd.p)\n\treturn int(i)\n}\n\n// SetInputSize Set the size for the network input, which overwrites the input size of creating model.\n// Call this method when the size of input image does not match the input size when creating model.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/df/d20/classcv_1_1FaceDetectorYN.html#a072418e5ce7beeb69c41edda75c41d2e\nfunc (fd *FaceDetectorYN) SetInputSize(sz image.Point) {\n\tc_sz := C.Size{\n\t\twidth:  C.int(sz.X),\n\t\theight: C.int(sz.Y),\n\t}\n\tC.FaceDetectorYN_SetInputSize(fd.p, c_sz)\n}\n\n// SetNMSThreshold Set the Non-maximum-suppression threshold to suppress\n// bounding boxes that have IoU greater than the given value.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/df/d20/classcv_1_1FaceDetectorYN.html#ab6011efee7e12dca3857d82de5269ac5\nfunc (fd *FaceDetectorYN) SetNMSThreshold(nmsThreshold float32) {\n\tC.FaceDetectorYN_SetNMSThreshold(fd.p, C.float(nmsThreshold))\n}\n\n// SetScoreThreshold Set the score threshold to filter out bounding boxes of score less than the given value.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/df/d20/classcv_1_1FaceDetectorYN.html#a37f3c23b82158fac7fdad967d315f85a\nfunc (fd *FaceDetectorYN) SetScoreThreshold(scoreThreshold float32) {\n\tC.FaceDetectorYN_SetScoreThreshold(fd.p, C.float(scoreThreshold))\n}\n\n// SetTopK Set the number of bounding boxes preserved before NMS.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/df/d20/classcv_1_1FaceDetectorYN.html#aa88d20e1e2df75ea36b851534089856a\nfunc (fd *FaceDetectorYN) SetTopK(topK int) {\n\tC.FaceDetectorYN_SetTopK(fd.p, C.int(topK))\n}\n\ntype FaceRecognizerSFDisType int\n\nconst (\n\tFaceRecognizerSFDisTypeCosine FaceRecognizerSFDisType = 0\n\tFaceRecognizerSFDisTypeNormL2 FaceRecognizerSFDisType = 1\n)\n\ntype FaceRecognizerSF struct {\n\tp C.FaceRecognizerSF\n}\n\n// NewFaceRecognizerSF Creates an instance with given parameters.\n//\n// model: the path of the onnx model used for face recognition\n//\n// config: the path to the config file for compability, which is not requested for ONNX models\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/da/d09/classcv_1_1FaceRecognizerSF.html#a04df90b0cd7d26d350acd92621a35743\nfunc NewFaceRecognizerSF(modelPath string, configPath string) FaceRecognizerSF {\n\tc_model := C.CString(modelPath)\n\tdefer C.free(unsafe.Pointer(c_model))\n\n\tc_config := C.CString(configPath)\n\tdefer C.free(unsafe.Pointer(c_config))\n\n\treturn FaceRecognizerSF{p: C.FaceRecognizerSF_Create(c_model, c_config)}\n}\n\n// NewFaceRecognizerSFWithParams Creates an instance with given parameters.\n//\n// model: the path of the onnx model used for face recognition\n//\n// config: the path to the config file for compability, which is not requested for ONNX models\n//\n// backend_id: the id of backend\n//\n// target_id: the id of target device\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/da/d09/classcv_1_1FaceRecognizerSF.html#a04df90b0cd7d26d350acd92621a35743\nfunc NewFaceRecognizerSFWithParams(modelPath string, configPath string, backendId int, targetId int) FaceRecognizerSF {\n\tc_model := C.CString(modelPath)\n\tdefer C.free(unsafe.Pointer(c_model))\n\n\tc_config := C.CString(configPath)\n\tdefer C.free(unsafe.Pointer(c_config))\n\n\treturn FaceRecognizerSF{p: C.FaceRecognizerSF_Create_WithParams(c_model, c_config, C.int(backendId), C.int(targetId))}\n}\n\n// Close Releases FaceRecognizerSF resources.\nfunc (fr *FaceRecognizerSF) Close() {\n\tC.FaceRecognizerSF_Close(fr.p)\n}\n\n// AlignCrop Aligns detected face with the source input image and crops it.\n//\n// srcImg: input image\n//\n// faceBox: the detected face result from the input image\n//\n// alignedImg: output aligned image\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/da/d09/classcv_1_1FaceRecognizerSF.html#a84492908abecbc9362b4ddc8d46b8345\nfunc (fr *FaceRecognizerSF) AlignCrop(srcImg Mat, faceBox Mat, alignedImg *Mat) {\n\tC.FaceRecognizerSF_AlignCrop(fr.p, srcImg.p, faceBox.p, alignedImg.p)\n}\n\n// Feature Extracts face feature from aligned image.\n//\n// alignedImg: input aligned image\n//\n// faceFeature: output face feature\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/da/d09/classcv_1_1FaceRecognizerSF.html#ab1b4a3c12213e89091a490c573dc5aba\nfunc (fr *FaceRecognizerSF) Feature(alignedImg Mat, faceFeature *Mat) {\n\tC.FaceRecognizerSF_Feature(fr.p, alignedImg.p, faceFeature.p)\n}\n\n// Match Calculates the distance between two face features.\n//\n// faceFeature1: the first input feature\n//\n// faceFeature2: the second input feature of the same size and the same type as face_feature1\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/da/d09/classcv_1_1FaceRecognizerSF.html#a2f0362ca1e64320a1f3ba7e1386d0219\nfunc (fr *FaceRecognizerSF) Match(faceFeature1 Mat, faceFeature2 Mat) float32 {\n\trv := C.FaceRecognizerSF_Match(fr.p, faceFeature1.p, faceFeature2.p)\n\treturn float32(rv)\n}\n\n// MatchWithParams Calculates the distance between two face features.\n//\n// faceFeature1: the first input feature\n//\n// faceFeature2: the second input feature of the same size and the same type as face_feature1\n//\n// disType: defines how to calculate the distance between two face features\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/da/d09/classcv_1_1FaceRecognizerSF.html#a2f0362ca1e64320a1f3ba7e1386d0219\nfunc (fr *FaceRecognizerSF) MatchWithParams(faceFeature1 Mat, faceFeature2 Mat, disType FaceRecognizerSFDisType) float32 {\n\trv := C.FaceRecognizerSF_Match_WithParams(fr.p, faceFeature1.p, faceFeature2.p, C.int(disType))\n\treturn float32(rv)\n}\n"
        },
        {
          "name": "objdetect.h",
          "type": "blob",
          "size": 4.1416015625,
          "content": "#ifndef _OPENCV3_OBJDETECT_H_\n#define _OPENCV3_OBJDETECT_H_\n\n#include <stdbool.h>\n\n#ifdef __cplusplus\n#include <opencv2/opencv.hpp>\nextern \"C\" {\n#endif\n\n#include \"core.h\"\n\n#ifdef __cplusplus\ntypedef cv::CascadeClassifier* CascadeClassifier;\ntypedef cv::HOGDescriptor* HOGDescriptor;\ntypedef cv::QRCodeDetector* QRCodeDetector;\ntypedef cv::Ptr<cv::FaceDetectorYN>* FaceDetectorYN;\ntypedef cv::Ptr<cv::FaceRecognizerSF>* FaceRecognizerSF;\n#else\ntypedef void* CascadeClassifier;\ntypedef void* HOGDescriptor;\ntypedef void* QRCodeDetector;\ntypedef void* FaceDetectorYN;\ntypedef void* FaceRecognizerSF;\n#endif\n\n// CascadeClassifier\nCascadeClassifier CascadeClassifier_New();\nvoid CascadeClassifier_Close(CascadeClassifier cs);\nint CascadeClassifier_Load(CascadeClassifier cs, const char* name);\nstruct Rects CascadeClassifier_DetectMultiScale(CascadeClassifier cs, Mat img);\nstruct Rects CascadeClassifier_DetectMultiScaleWithParams(CascadeClassifier cs, Mat img,\n        double scale, int minNeighbors, int flags, Size minSize, Size maxSize);\n\nHOGDescriptor HOGDescriptor_New();\nvoid HOGDescriptor_Close(HOGDescriptor hog);\nint HOGDescriptor_Load(HOGDescriptor hog, const char* name);\nstruct Rects HOGDescriptor_DetectMultiScale(HOGDescriptor hog, Mat img);\nstruct Rects HOGDescriptor_DetectMultiScaleWithParams(HOGDescriptor hog, Mat img,\n        double hitThresh, Size winStride, Size padding, double scale, double finalThreshold,\n        bool useMeanshiftGrouping);\nMat HOG_GetDefaultPeopleDetector();\nvoid HOGDescriptor_SetSVMDetector(HOGDescriptor hog, Mat det);\n\nstruct Rects GroupRectangles(struct Rects rects, int groupThreshold, double eps);\n\nQRCodeDetector QRCodeDetector_New();\nconst char* QRCodeDetector_DetectAndDecode(QRCodeDetector qr, Mat input,Mat points,Mat straight_qrcode);\nbool QRCodeDetector_Detect(QRCodeDetector qr, Mat input,Mat points);\nconst char* QRCodeDetector_Decode(QRCodeDetector qr, Mat input,Mat inputPoints,Mat straight_qrcode);\nvoid QRCodeDetector_Close(QRCodeDetector qr);\nbool QRCodeDetector_DetectMulti(QRCodeDetector qr, Mat input, Mat points);\nbool QRCodeDetector_DetectAndDecodeMulti(QRCodeDetector qr, Mat input, CStrings* decoded ,Mat points, struct Mats* mats);\n\n// FaceDetectorYN\nFaceDetectorYN FaceDetectorYN_Create(const char* model, const char* config, Size size);\nFaceDetectorYN FaceDetectorYN_Create_WithParams(const char* model, const char* config, Size size, float score_threshold, float mms_threshold, int top_k, int backend_id, int target_id);\nFaceDetectorYN FaceDetectorYN_Create_FromBytes(const char* framework, void* bufferModel, int model_size, void* bufferConfig, int config_size, Size size);\nFaceDetectorYN FaceDetectorYN_Create_FromBytes_WithParams(const char* framework, void* bufferModel, int model_size, void* bufferConfig, int config_size, Size size, float score_threshold, float mms_threshold, int top_k, int backend_id, int target_id);\nvoid FaceDetectorYN_Close(FaceDetectorYN fd); \nint FaceDetectorYN_Detect(FaceDetectorYN fd, Mat image, Mat faces);\nSize FaceDetectorYN_GetInputSize(FaceDetectorYN fd);\nfloat FaceDetectorYN_GetNMSThreshold(FaceDetectorYN fd);\nfloat FaceDetectorYN_GetScoreThreshold(FaceDetectorYN fd);\nint FaceDetectorYN_GetTopK(FaceDetectorYN fd);\nvoid FaceDetectorYN_SetInputSize(FaceDetectorYN fd, Size input_size);\nvoid FaceDetectorYN_SetNMSThreshold(FaceDetectorYN fd, float nms_threshold);\nvoid FaceDetectorYN_SetScoreThreshold(FaceDetectorYN fd, float score_threshold);\nvoid FaceDetectorYN_SetTopK(FaceDetectorYN fd, int top_k);\n\n// FaceRecognizerSF\nFaceRecognizerSF FaceRecognizerSF_Create(const char* model, const char* config);\nFaceRecognizerSF FaceRecognizerSF_Create_WithParams(const char* model, const char* config, int backend_id, int target_id);\nvoid FaceRecognizerSF_Close(FaceRecognizerSF fr);\nvoid FaceRecognizerSF_AlignCrop(FaceRecognizerSF fr, Mat src_img, Mat face_box, Mat aligned_img);\nvoid FaceRecognizerSF_Feature(FaceRecognizerSF fr, Mat aligned_img, Mat face_feature);\nfloat FaceRecognizerSF_Match(FaceRecognizerSF fr, Mat face_feature1, Mat face_feature2);\nfloat FaceRecognizerSF_Match_WithParams(FaceRecognizerSF fr, Mat face_feature1, Mat face_feature2, int dis_type);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif //_OPENCV3_OBJDETECT_H_\n"
        },
        {
          "name": "objdetect_test.go",
          "type": "blob",
          "size": 11.0849609375,
          "content": "package gocv\n\nimport (\n\t\"image\"\n\t\"image/color\"\n\t\"os\"\n\t\"testing\"\n)\n\nfunc TestCascadeClassifier(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in CascadeClassifier test\")\n\t}\n\tdefer img.Close()\n\n\t// load classifier to recognize faces\n\tclassifier := NewCascadeClassifier()\n\tdefer classifier.Close()\n\n\tclassifier.Load(\"data/haarcascade_frontalface_default.xml\")\n\n\trects := classifier.DetectMultiScale(img)\n\tif len(rects) != 1 {\n\t\tt.Error(\"Error in TestCascadeClassifier test\")\n\t}\n}\n\nfunc TestCascadeClassifierWithParams(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in CascadeClassifierWithParams test\")\n\t}\n\tdefer img.Close()\n\n\t// load classifier to recognize faces\n\tclassifier := NewCascadeClassifier()\n\tdefer classifier.Close()\n\n\tclassifier.Load(\"data/haarcascade_frontalface_default.xml\")\n\n\trects := classifier.DetectMultiScaleWithParams(img, 1.1, 3, 0, image.Pt(0, 0), image.Pt(0, 0))\n\tif len(rects) != 1 {\n\t\tt.Errorf(\"Error in CascadeClassifierWithParams test: %v\", len(rects))\n\t}\n}\n\nfunc TestHOGDescriptor(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in HOGDescriptor test\")\n\t}\n\tdefer img.Close()\n\n\t// load HOGDescriptor to recognize people\n\thog := NewHOGDescriptor()\n\tdefer hog.Close()\n\n\td := HOGDefaultPeopleDetector()\n\tdefer d.Close()\n\thog.SetSVMDetector(d)\n\n\trects := hog.DetectMultiScale(img)\n\tif len(rects) != 1 {\n\t\tt.Errorf(\"Error in TestHOGDescriptor test: %d\", len(rects))\n\t}\n}\n\nfunc TestHOGDescriptorWithParams(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in HOGDescriptorWithParams test\")\n\t}\n\tdefer img.Close()\n\n\t// load HOGDescriptor to recognize people\n\thog := NewHOGDescriptor()\n\tdefer hog.Close()\n\n\td := HOGDefaultPeopleDetector()\n\tdefer d.Close()\n\thog.SetSVMDetector(d)\n\n\trects := hog.DetectMultiScaleWithParams(img, 0, image.Pt(0, 0), image.Pt(0, 0),\n\t\t1.05, 2.0, false)\n\tif len(rects) != 1 {\n\t\tt.Errorf(\"Error in TestHOGDescriptorWithParams test: %d\", len(rects))\n\t}\n}\n\nfunc TestGroupRectangles(t *testing.T) {\n\trects := []image.Rectangle{\n\t\timage.Rect(10, 10, 30, 30),\n\t\timage.Rect(10, 10, 30, 30),\n\t\timage.Rect(10, 10, 30, 30),\n\t\timage.Rect(10, 10, 30, 30),\n\t\timage.Rect(10, 10, 30, 30),\n\t\timage.Rect(10, 10, 30, 30),\n\t\timage.Rect(10, 10, 30, 30),\n\t\timage.Rect(10, 10, 30, 30),\n\t\timage.Rect(10, 10, 30, 30),\n\t\timage.Rect(10, 10, 30, 30),\n\t\timage.Rect(10, 10, 35, 35),\n\t\timage.Rect(10, 10, 35, 35),\n\t\timage.Rect(10, 10, 35, 35),\n\t\timage.Rect(10, 10, 35, 35),\n\t\timage.Rect(10, 10, 35, 35),\n\t\timage.Rect(10, 10, 35, 35),\n\t\timage.Rect(10, 10, 35, 35),\n\t\timage.Rect(10, 10, 35, 35),\n\t\timage.Rect(10, 10, 35, 35),\n\t\timage.Rect(10, 10, 35, 35),\n\t}\n\n\tresults := GroupRectangles(rects, 1, 0.2)\n\tif len(results) != 2 {\n\t\tt.Errorf(\"Error in TestGroupRectangles test: %d\", len(results))\n\t}\n}\n\nfunc TestQRCodeDetector(t *testing.T) {\n\timg := IMRead(\"images/qrcode.png\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in QRCodeDetector test\")\n\t}\n\tdefer img.Close()\n\n\t// load QRCodeDetector to QR codes\n\n\tdetector := NewQRCodeDetector()\n\tdefer detector.Close()\n\n\tbbox := NewMat()\n\tqr := NewMat()\n\tdefer bbox.Close()\n\tdefer qr.Close()\n\n\tres := detector.Detect(img, &bbox)\n\tif !res {\n\t\tt.Errorf(\"Error in TestQRCodeDetector test: res == false\")\n\t}\n\tres2 := detector.Decode(img, bbox, &qr)\n\n\tres3 := detector.DetectAndDecode(img, &bbox, &qr)\n\n\tif res2 != res3 {\n\t\tt.Errorf(\"Error in TestQRCodeDetector res2: %s != res3: %s\", res2, res3)\n\t}\n\n\t// multi\n\timg2 := IMRead(\"images/multi_qrcodes.png\", IMReadColor)\n\tdefer img2.Close()\n\tif img2.Empty() {\n\t\tt.Error(\"Invalid Mat in QRCodeDetector test\")\n\t}\n\n\tmultiBox := NewMat()\n\tdefer multiBox.Close()\n\tres4 := detector.DetectMulti(img2, &multiBox)\n\tif !res4 {\n\t\tt.Errorf(\"Error in TestQRCodeDetector Multi test: res == false\")\n\t}\n\n\tif multiBox.Rows() != 2 {\n\t\tt.Errorf(\"Error in TestQRCodeDetector Multi test: number of Rows = %d\", multiBox.Rows())\n\t}\n\n\tmultiBox2 := NewMat()\n\tdefer multiBox2.Close()\n\tdecoded := []string{}\n\tqrCodes := make([]Mat, 0)\n\tdefer func() {\n\t\tfor _, q := range qrCodes {\n\t\t\tq.Close()\n\t\t}\n\t}()\n\tsuccess := detector.DetectAndDecodeMulti(img2, decoded, &multiBox2, qrCodes)\n\tif !success {\n\t\tt.Errorf(\"Error in TestQRCodeDetector Multi test: returned false\")\n\t}\n\n\ttmpPoints := NewMat()\n\tdefer tmpPoints.Close()\n\ttmpQr := NewMat()\n\tdefer tmpQr.Close()\n\tvar tmpDecoded string\n\tfor i, s := range decoded {\n\t\ttmpInput := padQr(&(qrCodes[i]))\n\t\tdefer tmpInput.Close()\n\t\ttmpDecoded = detector.Decode(tmpInput, tmpPoints, &tmpQr)\n\t\tif tmpDecoded != s {\n\t\t\tt.Errorf(\"Error in TestQRCodeDetector Multi test: decoded straight QR code=%s, decoded[%d] = %s\", tmpDecoded, i, s)\n\t\t}\n\t}\n\n\temptyMat := NewMatWithSize(100, 200, MatTypeCV8UC3)\n\tsuccess = detector.DetectAndDecodeMulti(emptyMat, decoded, &multiBox2, qrCodes)\n\tif success {\n\t\tt.Errorf(\"Error in TestQRCodeDetector Multi test: empty Mat returned success=true\")\n\t}\n\temptyMat.Close()\n}\n\nfunc padQr(qr *Mat) Mat {\n\tl := 101\n\td := 10\n\tL := l + 2*d\n\n\tout := NewMatWithSizeFromScalar(NewScalar(255, 255, 255, 255), L, L, MatTypeCV8UC3)\n\tqrCodes0 := NewMat()\n\tdefer qrCodes0.Close()\n\tqr.ConvertTo(&qrCodes0, MatTypeCV8UC3)\n\n\tResize(qrCodes0, &qrCodes0, image.Point{L, L}, 0, 0, InterpolationArea)\n\tCopyMakeBorder(qrCodes0, &out, d, d, d, d, BorderConstant, color.RGBA{255, 255, 255, 255})\n\treturn out\n}\n\nfunc TestFaceDetectorYN(t *testing.T) {\n\n\timg := IMRead(\"images/face.jpg\", IMReadAnyColor)\n\tdefer img.Close()\n\n\ts := image.Pt(img.Size()[1], img.Size()[0])\n\n\tfaces := NewMat()\n\tdefer faces.Close()\n\n\tfd := NewFaceDetectorYN(\"testdata/face_detection_yunet_2023mar.onnx\", \"\", s)\n\tdefer fd.Close()\n\n\tsz := fd.GetInputSize()\n\tif sz.X != 640 && sz.Y != 480 {\n\t\tt.Error(\"error on FaceDetectorYN.GetInputSize()\")\n\t}\n\tfd.SetInputSize(sz)\n\n\tt1 := fd.GetNMSThreshold()\n\tfd.SetNMSThreshold(t1)\n\n\tt2 := fd.GetScoreThreshold()\n\tfd.SetScoreThreshold(t2)\n\n\ttopK := fd.GetTopK()\n\tfd.SetTopK(topK)\n\n\tfd.Detect(img, &faces)\n\n\tfacesCount := faces.Rows()\n\n\tif facesCount < 1 {\n\t\tt.Error(\"no face detected\")\n\t}\n}\n\nfunc TestFaceDetectorYNWithParams(t *testing.T) {\n\n\timg := IMRead(\"images/face.jpg\", IMReadAnyColor)\n\tdefer img.Close()\n\n\ts := image.Pt(img.Size()[1], img.Size()[0])\n\n\tfaces := NewMat()\n\tdefer faces.Close()\n\n\tfd := NewFaceDetectorYNWithParams(\"testdata/face_detection_yunet_2023mar.onnx\", \"\", s, 0.9, 0.3, 5000, 0, 0)\n\tdefer fd.Close()\n\n\tsz := fd.GetInputSize()\n\tif sz.X != 640 && sz.Y != 480 {\n\t\tt.Error(\"error on FaceDetectorYN.GetInputSize()\")\n\t}\n\tfd.SetInputSize(sz)\n\n\tt1 := fd.GetNMSThreshold()\n\tfd.SetNMSThreshold(t1)\n\n\tt2 := fd.GetScoreThreshold()\n\tfd.SetScoreThreshold(t2)\n\n\ttopK := fd.GetTopK()\n\tfd.SetTopK(topK)\n\n\tfd.Detect(img, &faces)\n\n\tfacesCount := faces.Rows()\n\n\tif facesCount < 1 {\n\t\tt.Error(\"no face detected\")\n\t}\n\n}\n\nfunc TestFaceDetectorYNFromBytes(t *testing.T) {\n\n\tmodelBuffer, err := os.ReadFile(\"testdata/face_detection_yunet_2023mar.onnx\")\n\tif err != nil {\n\t\tt.Errorf(\"%s reading testdata/face_detection_yunet_2023mar.onnx\", err.Error())\n\t}\n\n\timg := IMRead(\"images/face.jpg\", IMReadAnyColor)\n\tdefer img.Close()\n\n\ts := image.Pt(img.Size()[1], img.Size()[0])\n\n\tfaces := NewMat()\n\tdefer faces.Close()\n\n\tfd := NewFaceDetectorYNFromBytes(\"onnx\", modelBuffer, []byte(\"\"), s)\n\tdefer fd.Close()\n\n\tsz := fd.GetInputSize()\n\tif sz.X != 640 && sz.Y != 480 {\n\t\tt.Error(\"error on FaceDetectorYN.GetInputSize()\")\n\t}\n\tfd.SetInputSize(sz)\n\n\tt1 := fd.GetNMSThreshold()\n\tfd.SetNMSThreshold(t1)\n\n\tt2 := fd.GetScoreThreshold()\n\tfd.SetScoreThreshold(t2)\n\n\ttopK := fd.GetTopK()\n\tfd.SetTopK(topK)\n\n\tfd.Detect(img, &faces)\n\n\tfacesCount := faces.Rows()\n\n\tif facesCount < 1 {\n\t\tt.Error(\"no face detected\")\n\t}\n}\n\nfunc TestFaceDetectorYNFromBytesWithParams(t *testing.T) {\n\n\tmodelBuffer, err := os.ReadFile(\"testdata/face_detection_yunet_2023mar.onnx\")\n\tif err != nil {\n\t\tt.Errorf(\"%s reading testdata/face_detection_yunet_2023mar.onnx\", err.Error())\n\t}\n\n\timg := IMRead(\"images/face.jpg\", IMReadAnyColor)\n\tdefer img.Close()\n\n\ts := image.Pt(img.Size()[1], img.Size()[0])\n\n\tfaces := NewMat()\n\tdefer faces.Close()\n\n\tfd := NewFaceDetectorYNFromBytesWithParams(\"onnx\", modelBuffer, []byte(\"\"), s, 0.9, 0.3, 5000, 0, 0)\n\tdefer fd.Close()\n\n\tsz := fd.GetInputSize()\n\tif sz.X != 640 && sz.Y != 480 {\n\t\tt.Error(\"error on FaceDetectorYN.GetInputSize()\")\n\t}\n\tfd.SetInputSize(sz)\n\n\tt1 := fd.GetNMSThreshold()\n\tfd.SetNMSThreshold(t1)\n\n\tt2 := fd.GetScoreThreshold()\n\tfd.SetScoreThreshold(t2)\n\n\ttopK := fd.GetTopK()\n\tfd.SetTopK(topK)\n\n\tfd.Detect(img, &faces)\n\n\tfacesCount := faces.Rows()\n\n\tif facesCount < 1 {\n\t\tt.Error(\"no face detected\")\n\t}\n}\n\nfunc TestFaceRecognizerSF(t *testing.T) {\n\n\trons := IMRead(\"images/face.jpg\", IMReadUnchanged)\n\tdefer rons.Close()\n\n\tronsImgSz := rons.Size()\n\n\ts := image.Pt(ronsImgSz[1], ronsImgSz[0])\n\n\tfd := NewFaceDetectorYN(\"testdata/face_detection_yunet_2023mar.onnx\", \"\", s)\n\tdefer fd.Close()\n\n\tronsFaces := NewMat()\n\tdefer ronsFaces.Close()\n\n\tdetectRv := fd.Detect(rons, &ronsFaces)\n\tt.Log(\"detect rv is\", detectRv)\n\n\tfacesCount := ronsFaces.Rows()\n\tif facesCount < 1 {\n\t\tt.Error(\"no face detected\")\n\t}\n\n\tronsFaceX0 := ronsFaces.GetFloatAt(0, 0)\n\tronsFaceY0 := ronsFaces.GetFloatAt(0, 1)\n\tronsFaceX1 := ronsFaces.GetFloatAt(0, 0) + ronsFaces.GetFloatAt(0, 2)\n\tronsFaceY1 := ronsFaces.GetFloatAt(0, 1) + ronsFaces.GetFloatAt(0, 3)\n\n\tronsFace := rons.Region(image.Rect(int(ronsFaceX0), int(ronsFaceY0), int(ronsFaceX1), int(ronsFaceY1)))\n\tdefer ronsFace.Close()\n\n\tfr := NewFaceRecognizerSF(\"testdata/face_recognition_sface_2021dec.onnx\", \"\")\n\tdefer fr.Close()\n\n\tronsAligned := NewMat()\n\tdefer ronsAligned.Close()\n\n\tfr.AlignCrop(rons, ronsFace, &ronsAligned)\n\n\tif ronsAligned.Empty() {\n\t\tt.Error(\"aligned is empty\")\n\t}\n\n\tronsFaceFeature := NewMat()\n\tdefer ronsFaceFeature.Close()\n\n\tfr.Feature(ronsAligned, &ronsFaceFeature)\n\n\tmatch := fr.Match(ronsFaceFeature, ronsFaceFeature)\n\tt.Log(\"face feature match: \", match)\n\n}\n\nfunc TestFaceRecognizerSFWithParams(t *testing.T) {\n\n\trons := IMRead(\"images/face.jpg\", IMReadUnchanged)\n\tdefer rons.Close()\n\n\tronsImgSz := rons.Size()\n\n\ts := image.Pt(ronsImgSz[1], ronsImgSz[0])\n\n\tfd := NewFaceDetectorYN(\"testdata/face_detection_yunet_2023mar.onnx\", \"\", s)\n\tdefer fd.Close()\n\n\tronsFaces := NewMat()\n\tdefer ronsFaces.Close()\n\n\tdetectRv := fd.Detect(rons, &ronsFaces)\n\tt.Log(\"detect rv is\", detectRv)\n\n\tfacesCount := ronsFaces.Rows()\n\tif facesCount < 1 {\n\t\tt.Error(\"no face detected\")\n\t}\n\n\tronsFaceX0 := ronsFaces.GetFloatAt(0, 0)\n\tronsFaceY0 := ronsFaces.GetFloatAt(0, 1)\n\tronsFaceX1 := ronsFaces.GetFloatAt(0, 0) + ronsFaces.GetFloatAt(0, 2)\n\tronsFaceY1 := ronsFaces.GetFloatAt(0, 1) + ronsFaces.GetFloatAt(0, 3)\n\n\tronsFace := rons.Region(image.Rect(int(ronsFaceX0), int(ronsFaceY0), int(ronsFaceX1), int(ronsFaceY1)))\n\tdefer ronsFace.Close()\n\n\tfr := NewFaceRecognizerSFWithParams(\"testdata/face_recognition_sface_2021dec.onnx\", \"\", 0, 0)\n\tdefer fr.Close()\n\n\tronsAligned := NewMat()\n\tdefer ronsAligned.Close()\n\n\tfr.AlignCrop(rons, ronsFace, &ronsAligned)\n\n\tif ronsAligned.Empty() {\n\t\tt.Error(\"aligned is empty\")\n\t}\n\n\tronsFaceFeature := NewMat()\n\tdefer ronsFaceFeature.Close()\n\n\tfr.Feature(ronsAligned, &ronsFaceFeature)\n\n\tmatch := fr.MatchWithParams(ronsFaceFeature, ronsFaceFeature, FaceRecognizerSFDisTypeCosine)\n\tt.Log(\"face feature match: \", match)\n\n}\n"
        },
        {
          "name": "openvino",
          "type": "tree",
          "content": null
        },
        {
          "name": "persistence.h",
          "type": "blob",
          "size": 2.8212890625,
          "content": "#ifndef _OPENCV3_OBJDETECT_H_\n#define _OPENCV3_OBJDETECT_H_\n\n#include <stdbool.h>\n\n#ifdef __cplusplus\n#include <opencv2/opencv.hpp>\nextern \"C\" {\n#endif\n\n#include \"core.h\"\n\n#ifdef __cplusplus\ntypedef cv::FileStorage* FileStorage;\ntypedef cv::FileNode* FileNode;\n#else\ntypedef void* FileStorage;\ntypedef void* FileNode;\n#endif\n\n// FileStorage\nFileStorage FileStorage_Create(void);\nFileStorage FileStorage_CreateWithParams(const char* filename, int flags, const char* encoding);\nvoid FileStorage_Close(FileStorage fs);\n\nconst char *FileStorage_ElName(FileStorage fs);\nint FileStorage_State(FileStorage fs);\n\nvoid FileStorage_EndWriteStruct(FileStorage fs);\nint FileStorage_GetFormat(FileStorage fs);\nbool FileStorage_IsOpened(FileStorage fs);\nbool FileStorage_Open(FileStorage fs, const char* filename, int flags, const char* encoding);\nvoid FileStorage_Release(FileStorage fs);\nconst char* FileStorage_ReleaseAndGetString(FileStorage fs);\nvoid FileStorage_StartWriteStruct(FileStorage fs, const char* name, int flags, const char* typeName);\nvoid FileStorage_WriteMat(FileStorage fs, const char* name, Mat val);\nvoid FileStorage_WriteString(FileStorage fs, const char* name, const char* val);\nvoid FileStorage_WriteStringArray(FileStorage fs, const char* name, const char** val, size_t len);\nvoid FileStorage_WriteDouble(FileStorage fs, const char* name, double val);\nvoid FileStorage_WriteInt(FileStorage fs, const char* name, int val);\nvoid FileStorage_WriteComment(FileStorage fs, const char* comment, bool append);\nvoid FileStorage_WriteRaw(FileStorage fs, const char* fmt, const void* vec, size_t len);\n\nFileNode FileStorage_GetFirstTopLevelNode(FileStorage fs);\nFileNode FileStorage_GetNode(FileStorage fs, const char* nodename);\nFileNode FileStorage_Root(FileStorage fs, int streamidx);\n\nbool FileNode_Empty(FileNode fn);\nbool FileNode_IsInt(FileNode fn);\nbool FileNode_IsMap(FileNode fn);\nbool FileNode_IsNamed(FileNode fn);\nbool FileNode_IsNone(FileNode fn);\nbool FileNode_IsReal(FileNode fn);\nbool FileNode_IsSeq(FileNode fn);\nbool FileNode_IsString(FileNode fn);\nchar** FileNode_Keys(FileNode fn);\nsize_t FileNode_KeysCount(FileNode fn);\nvoid FileNode_KeysFree(char** keys, size_t len);\nMat FileNode_Mat(FileNode fn);\nconst char* FileNode_Name(FileNode fn);\nfloat FileNode_Float(FileNode fn);\nconst char* FileNode_String(FileNode fn);\nFileNode FileNode_Get(FileNode fn, int i); //FileNode operator[] (int i) const\nFileNode FileNode_GetByName(FileNode fn, const char* nodename); //FileNode operator[] (const char *nodename) const\nsize_t FileNode_RawSize(FileNode fn);\nvoid FileNode_ReadRaw(FileNode fn, const char* fmt, void *vec, size_t len);\nvoid FileNode_SetValue(FileNode fn, int type, const void *value, int len);\nsize_t FileNode_Size(FileNode fn);\nint FileNode_Type(FileNode fn);\n\nvoid FileNode_Close(FileNode fn);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif //_OPENCV3_OBJDETECT_H_\n"
        },
        {
          "name": "persistence_filenode.cpp",
          "type": "blob",
          "size": 2.138671875,
          "content": "#include <string.h>\n#include \"persistence.h\"\n\nbool FileNode_Empty(FileNode fn) {\n    return fn->empty();\n}\n\nbool FileNode_IsInt(FileNode fn){\n    return fn->isInt();\n}\n\nbool FileNode_IsMap(FileNode fn){\n    return fn->isMap();\n}\n\nbool FileNode_IsNamed(FileNode fn) {\n    return fn->isNamed();\n}\n\nbool FileNode_IsNone(FileNode fn){\n    return fn->isNone();\n}\n\nbool FileNode_IsReal(FileNode fn){\n    return fn->isReal();\n}\n\nbool FileNode_IsSeq(FileNode fn) {\n    return fn->isSeq();\n}\n\nbool FileNode_IsString(FileNode fn) {\n    return fn->isString();\n}\n\nchar** FileNode_Keys(FileNode fn) {\n\n    std::vector<cv::String> keys = fn->keys();\n\n    char** c_keys = new char*[keys.size()];\n\n    for (int i = 0; i < keys.size(); i++) {\n        char *c_key = new char[keys[i].length()+1];\n        strcpy(c_key, keys[i].c_str());\n        c_keys[i] = c_key;\n    }\n\n    return c_keys;\n}\n\nsize_t FileNode_KeysCount(FileNode fn) {\n    return fn->keys().size();\n}\n\n\nvoid FileNode_KeysFree(char** keys, size_t len) {\n    for(int i = 0; i < len; i++) {\n        delete keys[i];\n    }\n    delete keys;\n}\n\nMat FileNode_Mat(FileNode fn) {\n    return new cv::Mat(fn->mat());\n}\n\nconst char* FileNode_Name(FileNode fn) {\n    char* str = new char[fn->name().length()+1];\n    strcpy(str, fn->name().c_str()); \n    return str;\n}\n\nfloat FileNode_Float(FileNode fn) {\n    return (float)fn->real();\n}\n\nconst char* FileNode_String(FileNode fn) {\n    char* str = new char[fn->string().length()+1];\n    strcpy(str, fn->string().c_str());\n    return str;\n}\n\nFileNode FileNode_Get(FileNode fn, int i) {\n    return new cv::FileNode((*fn)[i]);\n}\n\nFileNode FileNode_GetByName(FileNode fn, const char* nodename) {\n    return new cv::FileNode((*fn)[nodename]);\n}\n\nsize_t FileNode_RawSize(FileNode fn) {\n    return fn->rawSize();\n}\n\nvoid FileNode_ReadRaw(FileNode fn, const char* fmt, void *vec, size_t len) {\n    fn->readRaw(fmt, vec, len);\n}\n \nvoid FileNode_SetValue(FileNode fn, int type, const void *value, int len) {\n    fn->setValue(type, value, len);\n}\n\nsize_t FileNode_Size(FileNode fn) {\n    return fn->size();\n}\n\nint FileNode_Type(FileNode fn) {\n    return fn->type();\n}\n\nvoid FileNode_Close(FileNode fn){\n    delete fn;\n}\n"
        },
        {
          "name": "persistence_filenode.go",
          "type": "blob",
          "size": 1.8203125,
          "content": "package gocv\n\n/*\n#include <stdlib.h>\n#include \"persistence.h\"\n*/\nimport \"C\"\nimport \"unsafe\"\n\ntype FileNodeType int\n\nconst (\n\tFileNodeTypeNone     FileNodeType = 0\n\tFileNodeTypeInt      FileNodeType = 1\n\tFileNodeTypeReal     FileNodeType = 2\n\tFileNodeTypeFloat    FileNodeType = FileNodeTypeReal\n\tFileNodeTypeStr      FileNodeType = 3\n\tFileNodeTypeString   FileNodeType = FileNodeTypeStr\n\tFileNodeTypeSeq      FileNodeType = 4\n\tFileNodeTypeMap      FileNodeType = 5\n\tFileNodeTypeTypeMask FileNodeType = 7\n\tFileNodeTypeFlow     FileNodeType = 8\n\tFileNodeTypeUniform  FileNodeType = 8\n\tFileNodeTypeEmpty    FileNodeType = 16\n\tFileNodeTypeNamed    FileNodeType = 32\n)\n\n// FileNode is a wrapper for the OpenCV FileNode class\n//\n// Ref: https://docs.opencv.org/4.x/de/dd9/classcv_1_1FileNode.html\ntype FileNode struct {\n\tp C.FileNode\n}\n\nfunc (fn *FileNode) Empty() bool {\n\treturn bool(C.FileNode_Empty(fn.p))\n}\n\nfunc (fn *FileNode) IsInt() bool {\n\treturn bool(C.FileNode_IsInt(fn.p))\n}\n\nfunc (fn *FileNode) IsMap() bool {\n\treturn bool(C.FileNode_IsMap(fn.p))\n}\n\nfunc (fn *FileNode) IsNamed() bool {\n\treturn bool(C.FileNode_IsNamed(fn.p))\n}\n\nfunc (fn *FileNode) IsNone() bool {\n\treturn bool(C.FileNode_IsNone(fn.p))\n}\n\nfunc (fn *FileNode) IsReal() bool {\n\treturn bool(C.FileNode_IsReal(fn.p))\n}\n\nfunc (fn *FileNode) IsSeq() bool {\n\treturn bool(C.FileNode_IsSeq(fn.p))\n}\n\nfunc (fn *FileNode) IsString() bool {\n\treturn bool(C.FileNode_IsString(fn.p))\n}\n\nfunc (fn *FileNode) Keys() []string {\n\n\tc_keys_count := C.FileNode_KeysCount(fn.p)\n\tc_keys := C.FileNode_Keys(fn.p)\n\tdefer C.FileNode_KeysFree(c_keys, c_keys_count)\n\n\tkeys := make([]string, int(c_keys_count))\n\tc_keys_slice := unsafe.Slice(c_keys, c_keys_count)\n\n\tfor i := 0; i < int(c_keys_count); i++ {\n\t\tkeys[i] = C.GoString(c_keys_slice[i])\n\t}\n\treturn keys\n}\n\nfunc (fn *FileNode) Close() {\n\tC.FileNode_Close(fn.p)\n}\n"
        },
        {
          "name": "persistence_filestorage.cpp",
          "type": "blob",
          "size": 2.7275390625,
          "content": "#include <string.h>\n#include \"persistence.h\"\n\n\nFileStorage FileStorage_Create(void) {\n    return new cv::FileStorage();\n}\n\nFileStorage FileStorage_CreateWithParams(const char* filename, int flags, const char* encoding) {\n    return new cv::FileStorage(filename, flags, encoding);\n}\n\nconst char *FileStorage_ElName(FileStorage fs) {\n    char* str = new char[fs->elname.length()+1];\n    strcpy(str, fs->elname.c_str()); \n    return str;\n}\nint FileStorage_State(FileStorage fs) {\n    return fs->state;\n}\n\nvoid FileStorage_Close(FileStorage fs) {\n    fs->release();\n    delete fs;\n}\n\nvoid FileStorage_EndWriteStruct(FileStorage fs) {\n    fs->endWriteStruct();\n}\n\nint FileStorage_GetFormat(FileStorage fs){\n    return fs->getFormat();\n}\n\nbool FileStorage_IsOpened(FileStorage fs) {\n    return fs->isOpened();\n}\n\nbool FileStorage_Open(FileStorage fs, const char* filename, int flags, const char* encoding) {\n    return fs->open(filename, flags, encoding);\n}\n\nvoid FileStorage_Release(FileStorage fs) {\n    fs->release();\n    delete fs;\n}\n\nconst char* FileStorage_ReleaseAndGetString(FileStorage fs) {\n    cv::String s = fs->releaseAndGetString();\n\n    char* str = new char[s.length()+1];\n    strcpy(str, s.c_str()); \n    return str;\n}\n\nvoid FileStorage_StartWriteStruct(FileStorage fs, const char* name, int flags, const char* typeName){\n    fs->startWriteStruct(name, flags, typeName);\n}\n\nvoid FileStorage_WriteMat(FileStorage fs, const char* name, Mat val){\n    fs->write(name, *val);\n}\n\nvoid FileStorage_WriteString(FileStorage fs, const char* name, const char* val) {\n    fs->write(name, val);\n}\n\nvoid FileStorage_WriteStringArray(FileStorage fs, const char* name, const char** val, size_t len) {\n    std::vector<cv::String> vals;\n\n    for(int i = 0; i < len; i++) {\n        vals.push_back(val[i]);\n    }\n\n    fs->write(name, vals);\n}\n\nvoid FileStorage_WriteDouble(FileStorage fs, const char* name, double val){\n    fs->write(name, val);\n}\n\nvoid FileStorage_WriteInt(FileStorage fs, const char* name, int val){\n    fs->write(name, val);\n}\n\nvoid FileStorage_WriteComment(FileStorage fs, const char* comment, bool append){\n    fs->writeComment(comment, append);\n}\nvoid FileStorage_WriteRaw(FileStorage fs, const char* fmt, const void* vec, size_t len){\n    fs->writeRaw(fmt, vec, len);\n}\n\nFileNode FileStorage_GetFirstTopLevelNode(FileStorage fs) {\n    cv::FileNode node = fs->getFirstTopLevelNode();\n\n    FileNode fn = new cv::FileNode(node);\n    return fn;\n}\n\nFileNode FileStorage_GetNode(FileStorage fs, const char* nodename) {\n\n    cv::FileNode node = (*fs)[nodename];\n\n    FileNode fn = new cv::FileNode(node);\n    return fn;\n}\n\nFileNode FileStorage_Root(FileStorage fs, int streamidx) {\n    cv::FileNode node = fs->root(streamidx);\n\n    FileNode fn = new cv::FileNode(node);\n    return fn;\n}"
        },
        {
          "name": "persistence_filestorage.go",
          "type": "blob",
          "size": 5.1328125,
          "content": "package gocv\n\n/*\n#include <stdlib.h>\n#include <stdbool.h>\n#include \"persistence.h\"\n*/\nimport \"C\"\nimport \"unsafe\"\n\ntype FileStorageMode int\n\nconst (\n\tFileStorageModeRead        FileStorageMode = 0\n\tFileStorageModeWrite       FileStorageMode = 1\n\tFileStorageModeAppend      FileStorageMode = 2\n\tFileStorageModeMemory      FileStorageMode = 4\n\tFileStorageModeFormatMask  FileStorageMode = (7 << 3)\n\tFileStorageModeFormatAuto  FileStorageMode = 0\n\tFileStorageModeFormatXml   FileStorageMode = (1 << 3)\n\tFileStorageModeFormatYaml  FileStorageMode = (2 << 3)\n\tFileStorageModeFormatJson  FileStorageMode = (3 << 3)\n\tFileStorageModeBase64      FileStorageMode = 64\n\tFileStorageModeWriteBase64 FileStorageMode = FileStorageModeBase64 | FileStorageModeWrite\n)\n\ntype FileStorageState int\n\nconst (\n\tFileStorageStateUndefined     FileStorageState = 0\n\tFileStorageStateValueExpected FileStorageState = 1\n\tFileStorageStateNameExpected  FileStorageState = 2\n\tFileStorageStateInsideMap     FileStorageState = 4\n)\n\n// FileStorage is a wrapper for the OpenCV FileStorage class\n//\n// Ref: https://docs.opencv.org/4.x/da/d56/classcv_1_1FileStorage.html\ntype FileStorage struct {\n\tp C.FileStorage\n}\n\nfunc NewFileStorage() *FileStorage {\n\treturn &FileStorage{p: C.FileStorage_Create()}\n}\n\nfunc NewFileStorageWithParams(filename string, flags FileStorageMode, encoding string) *FileStorage {\n\tc_filename := C.CString(filename)\n\tc_encoding := C.CString(encoding)\n\tdefer C.free(unsafe.Pointer(c_filename))\n\tdefer C.free(unsafe.Pointer(c_encoding))\n\n\treturn &FileStorage{p: C.FileStorage_CreateWithParams(c_filename, C.int(flags), c_encoding)}\n}\n\nfunc (fs *FileStorage) Close() {\n\tfs.Release()\n}\n\nfunc (fs *FileStorage) Release() {\n\tC.FileStorage_Release(fs.p)\n}\n\nfunc (fs *FileStorage) ElName() string {\n\tc_str := C.FileStorage_ElName(fs.p)\n\tdefer C.free(unsafe.Pointer(c_str))\n\n\tstr := C.GoString(c_str)\n\treturn str\n}\n\nfunc (fs *FileStorage) State() FileStorageState {\n\tstate := C.FileStorage_State(fs.p)\n\treturn FileStorageState(int(state))\n}\n\nfunc (fs *FileStorage) EndWriteStruct() {\n\tC.FileStorage_EndWriteStruct(fs.p)\n\n}\n\nfunc (fs *FileStorage) GetFormat() FileStorageMode {\n\tfmt := C.FileStorage_GetFormat(fs.p)\n\treturn FileStorageMode(int(fmt))\n}\n\nfunc (fs *FileStorage) IsOpened() bool {\n\tb := C.FileStorage_IsOpened(fs.p)\n\treturn bool(b)\n}\n\nfunc (fs *FileStorage) Open(filename string, flags FileStorageMode, encoding string) bool {\n\tc_filename := C.CString(filename)\n\tc_encoding := C.CString(encoding)\n\tdefer C.free(unsafe.Pointer(c_filename))\n\tdefer C.free(unsafe.Pointer(c_encoding))\n\n\tb := C.FileStorage_Open(fs.p, c_filename, C.int(flags), c_encoding)\n\treturn bool(b)\n}\n\nfunc (fs *FileStorage) ReleaseAndGetString() string {\n\tc_str := C.FileStorage_ReleaseAndGetString(fs.p)\n\tdefer C.free(unsafe.Pointer(c_str))\n\n\tstr := C.GoString(c_str)\n\treturn str\n}\n\nfunc (fs *FileStorage) StartWriteStruct(name string, flags FileNodeType, typeName string) {\n\tc_name := C.CString(name)\n\tc_typeName := C.CString(typeName)\n\tdefer C.free(unsafe.Pointer(c_name))\n\tdefer C.free(unsafe.Pointer(c_typeName))\n\n\tC.FileStorage_StartWriteStruct(fs.p, c_name, C.int(flags), c_typeName)\n}\n\nfunc (fs *FileStorage) WriteMat(name string, mat Mat) {\n\tc_name := C.CString(name)\n\tdefer C.free(unsafe.Pointer(c_name))\n\n\tC.FileStorage_WriteMat(fs.p, c_name, mat.p)\n}\n\nfunc (fs *FileStorage) WriteString(name string, val string) {\n\tc_name := C.CString(name)\n\tc_val := C.CString(val)\n\tdefer C.free(unsafe.Pointer(c_name))\n\tdefer C.free(unsafe.Pointer(c_val))\n\n\tC.FileStorage_WriteString(fs.p, c_name, c_val)\n}\n\nfunc (fs *FileStorage) WriteStringArray(name string, val []string) {\n\tc_name := C.CString(name)\n\tdefer C.free(unsafe.Pointer(c_name))\n\n\tc_val := make([]*C.char, 0, len(val))\n\n\tfor _, v := range val {\n\t\tc_val = append(c_val, C.CString(v))\n\t}\n\tdefer func() {\n\t\tfor _, p := range c_val {\n\t\t\tC.free(unsafe.Pointer(p))\n\t\t}\n\t}()\n\tC.FileStorage_WriteStringArray(fs.p, c_name, &c_val[0], C.size_t(len(val)))\n}\n\nfunc (fs *FileStorage) WriteDouble(name string, val float32) {\n\tc_name := C.CString(name)\n\tdefer C.free(unsafe.Pointer(c_name))\n\n\tC.FileStorage_WriteDouble(fs.p, c_name, C.double(val))\n}\n\nfunc (fs *FileStorage) WriteInt(name string, val int) {\n\tc_name := C.CString(name)\n\tdefer C.free(unsafe.Pointer(c_name))\n\n\tC.FileStorage_WriteInt(fs.p, c_name, C.int(val))\n}\n\nfunc (fs *FileStorage) WriteComment(comment string, append bool) {\n\tc_comment := C.CString(comment)\n\tdefer C.free(unsafe.Pointer(c_comment))\n\n\tC.FileStorage_WriteComment(fs.p, c_comment, C.bool(append))\n}\n\nfunc (fs *FileStorage) WriteRaw(fmt string, vec []byte) {\n\tc_fmt := C.CString(fmt)\n\tdefer C.free(unsafe.Pointer(c_fmt))\n\n\tc_vec := C.CBytes(vec)\n\tdefer C.free(c_vec)\n\n\tC.FileStorage_WriteRaw(fs.p, c_fmt, c_vec, C.size_t(len(vec)))\n\n}\n\nfunc (fs *FileStorage) GetFirstTopLevelNode() *FileNode {\n\tnode_p := C.FileStorage_GetFirstTopLevelNode(fs.p)\n\treturn &FileNode{p: node_p}\n}\n\nfunc (fs *FileStorage) GetNode(name string) *FileNode {\n\tc_name := C.CString(name)\n\tdefer C.free(unsafe.Pointer(c_name))\n\n\tnode_p := C.FileStorage_GetNode(fs.p, c_name)\n\n\treturn &FileNode{p: node_p}\n\n}\n\nfunc (fs *FileStorage) Root(streamIdx int) *FileNode {\n\tnode_p := C.FileStorage_Root(fs.p, C.int(streamIdx))\n\treturn &FileNode{p: node_p}\n}\n"
        },
        {
          "name": "persistence_test.go",
          "type": "blob",
          "size": 1.1240234375,
          "content": "package gocv\n\nimport (\n\t\"os\"\n\t\"path/filepath\"\n\t\"testing\"\n)\n\nfunc TestFileStorage(t *testing.T) {\n\n\tfileStorageTestFilename := filepath.Join(os.TempDir(), \"filestorage.json\")\n\tfs := NewFileStorageWithParams(fileStorageTestFilename, FileStorageModeWrite|FileStorageModeFormatJson, \"utf-8\")\n\n\tfs.StartWriteStruct(\"gocv\", FileNodeTypeMap, \"person\")\n\tfs.ElName()\n\tfs.State()\n\tfs.GetFormat()\n\tfs.IsOpened()\n\n\tm := NewMat()\n\tdefer m.Close()\n\tfs.WriteMat(\"mat\", m)\n\n\tfs.WriteString(\"string\", \"string value\")\n\tfs.WriteStringArray(\"stringArray\", []string{\"string\", \"array\"})\n\tfs.WriteDouble(\"double\", 3.1415927)\n\tfs.WriteInt(\"int\", 42)\n\tfs.WriteComment(\"no comments\", true)\n\n\tfs.EndWriteStruct()\n\n\tfs.StartWriteStruct(\"gocv2\", FileNodeTypeSeq, \"int\")\n\tfs.WriteRaw(\"u\", []byte{0, 0})\n\tfs.EndWriteStruct()\n\n\tfs.GetNode(\"gocv\")\n\tfs.Root(0)\n\n\tfs.ReleaseAndGetString()\n\n\tfs = NewFileStorage()\n\tfs.Open(fileStorageTestFilename, FileStorageModeRead|FileStorageModeFormatJson, \"utf-8\")\n\n\tfn := fs.GetFirstTopLevelNode()\n\tdefer fn.Close()\n\n\tfn.Empty()\n\tfn.IsInt()\n\tfn.IsMap()\n\tfn.IsNamed()\n\tfn.IsNone()\n\tfn.IsReal()\n\tfn.IsSeq()\n\tfn.IsString()\n\tfn.Keys()\n\tfs.Release()\n}\n"
        },
        {
          "name": "photo.cpp",
          "type": "blob",
          "size": 4.2177734375,
          "content": "#include \"photo.h\"\n\nvoid ColorChange(Mat src, Mat mask, Mat dst, float red_mul, float green_mul, float blue_mul) {\n    cv::colorChange(*src, *mask, *dst, red_mul, green_mul, blue_mul);\n}\n\nvoid IlluminationChange(Mat src, Mat mask, Mat dst, float alpha, float beta) {\n    cv::illuminationChange(*src, *mask, *dst, alpha, beta);\n}\n\nvoid SeamlessClone(Mat src, Mat dst, Mat mask, Point p, Mat blend, int flags) {\n    cv::Point pt(p.x, p.y);\n    cv::seamlessClone(*src, *dst, *mask, pt, *blend, flags);\n}\n\nvoid TextureFlattening(Mat src, Mat mask, Mat dst, float low_threshold, float high_threshold, int kernel_size) {\n    cv::textureFlattening(*src, *mask, *dst, low_threshold, high_threshold, kernel_size);\n}\n\n\nvoid FastNlMeansDenoisingColoredMulti(\tstruct Mats src, Mat dst, int imgToDenoiseIndex, int \ttemporalWindowSize){\n  std::vector<cv::Mat> images;\n  for (int i = 0; i < src.length; ++i) {\n    images.push_back(*src.mats[i]);\n  }\n  cv::fastNlMeansDenoisingColoredMulti( images, *dst, imgToDenoiseIndex, \ttemporalWindowSize );\n}\n\nvoid FastNlMeansDenoisingColoredMultiWithParams( struct Mats src, Mat dst, int imgToDenoiseIndex, int \ttemporalWindowSize, float \th, float \thColor, int \ttemplateWindowSize, int \tsearchWindowSize ){\n  std::vector<cv::Mat> images;\n  for (int i = 0; i < src.length; ++i) {\n    images.push_back(*src.mats[i]);\n  }\n  cv::fastNlMeansDenoisingColoredMulti( images, *dst, imgToDenoiseIndex, \ttemporalWindowSize, h, hColor, templateWindowSize, searchWindowSize );\n}\n\nMergeMertens MergeMertens_Create() {\n  return new cv::Ptr<cv::MergeMertens>(cv::createMergeMertens());\n}\n\nMergeMertens MergeMertens_CreateWithParams(float contrast_weight,\n                                           float saturation_weight,\n                                           float exposure_weight) {\n  return new cv::Ptr<cv::MergeMertens>(cv::createMergeMertens(\n      contrast_weight, saturation_weight, exposure_weight));\n}\n\nvoid MergeMertens_Close(MergeMertens b) {\n  delete b;\n}\n\nvoid MergeMertens_Process(MergeMertens b, struct Mats src, Mat dst) {\n  std::vector<cv::Mat> images;\n  for (int i = 0; i < src.length; ++i) {\n    images.push_back(*src.mats[i]);\n  }\n  (*b)->process(images, *dst);\n}\n\nAlignMTB AlignMTB_Create() {\n  return new cv::Ptr<cv::AlignMTB>(cv::createAlignMTB(6,4,false));\n}\n\nAlignMTB AlignMTB_CreateWithParams(int max_bits, int exclude_range, bool cut) {\n  return new cv::Ptr<cv::AlignMTB>(\n      cv::createAlignMTB(max_bits, exclude_range, cut));\n}\n\nvoid AlignMTB_Close(AlignMTB b) { delete b; }\n\nvoid AlignMTB_Process(AlignMTB b, struct Mats src, struct Mats *dst) {\n\n  std::vector<cv::Mat> srcMats;\n  for (int i = 0; i < src.length; ++i) {\n    srcMats.push_back(*src.mats[i]);\n  }\n\n  std::vector<cv::Mat> dstMats;\n  (*b)->process(srcMats, dstMats);\n\n  dst->mats = new Mat[dstMats.size()];\n  for (size_t i = 0; i < dstMats.size() ; ++i) {\n\tdst->mats[i] = new cv::Mat( dstMats[i] );\n  }\n  dst->length = (int)dstMats.size();\n}\n\nvoid FastNlMeansDenoising(Mat src, Mat dst) {\n    cv::fastNlMeansDenoising(*src, *dst);\n}\n\nvoid FastNlMeansDenoisingWithParams(Mat src, Mat dst, float h, int templateWindowSize, int searchWindowSize) {\n    cv::fastNlMeansDenoising(*src, *dst, h, templateWindowSize, searchWindowSize);\n}\n\nvoid FastNlMeansDenoisingColored(Mat src, Mat dst) {\n    cv::fastNlMeansDenoisingColored(*src, *dst);\n}\n\nvoid FastNlMeansDenoisingColoredWithParams(Mat src, Mat dst, float h, float hColor, int templateWindowSize, int searchWindowSize) {\n    cv::fastNlMeansDenoisingColored(*src, *dst, h, hColor, templateWindowSize, searchWindowSize);\n}\n\nvoid EdgePreservingFilter(Mat src, Mat dst, int filter, float sigma_s, float sigma_r) {\n    cv::edgePreservingFilter(*src, *dst, filter, sigma_s, sigma_r);\n}\n\nvoid DetailEnhance(Mat src, Mat dst, float sigma_s, float sigma_r) {\n    cv::detailEnhance(*src, *dst, sigma_s, sigma_r);\n}\n\nvoid PencilSketch(Mat src, Mat dst1, Mat dst2, float sigma_s, float sigma_r, float shade_factor) {\n    cv::pencilSketch(*src, *dst1, *dst2, sigma_s, sigma_r, shade_factor);\n}\n\nvoid Stylization(Mat src, Mat dst, float sigma_s, float sigma_r) {\n    cv::stylization(*src, *dst, sigma_s, sigma_r);\n}\n\nvoid PhotoInpaint(Mat src, Mat mask, Mat dst, float inpaint_radius, int algorithm_type) {\n    cv::inpaint(*src, *mask, *dst, inpaint_radius, algorithm_type);\n}\n"
        },
        {
          "name": "photo.go",
          "type": "blob",
          "size": 13.0966796875,
          "content": "package gocv\n\n/*\n#include <stdlib.h>\n#include \"photo.h\"\n*/\nimport \"C\"\n\nimport (\n\t\"image\"\n\t\"unsafe\"\n)\n\n// SeamlessCloneFlags seamlessClone algorithm flags\ntype SeamlessCloneFlags int\n\n// MergeMertens is a wrapper around the cv::MergeMertens.\ntype MergeMertens struct {\n\tp unsafe.Pointer // This unsafe pointer will in fact be a C.MergeMertens\n}\n\n// AlignMTB is a wrapper around the cv::AlignMTB.\ntype AlignMTB struct {\n\tp unsafe.Pointer // This unsafe pointer will in fact be a C.AlignMTB\n}\n\nconst (\n\t// NormalClone The power of the method is fully expressed when inserting objects with complex outlines into a new background.\n\tNormalClone SeamlessCloneFlags = iota\n\n\t// MixedClone The classic method, color-based selection and alpha masking might be time consuming and often leaves an undesirable halo. Seamless cloning, even averaged with the original image, is not effective. Mixed seamless cloning based on a loose selection proves effective.\n\tMixedClone\n\n\t// MonochromeTransfer Monochrome transfer allows the user to easily replace certain features of one object by alternative features.\n\tMonochromeTransfer\n)\n\n// ColorChange mix two differently colored versions of an image seamlessly.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/df/da0/group__photo__clone.html#ga6684f35dc669ff6196a7c340dc73b98e\nfunc ColorChange(src, mask Mat, dst *Mat, red_mul, green_mul, blue_mul float32) {\n\tC.ColorChange(src.p, mask.p, dst.p, C.float(red_mul), C.float(green_mul), C.float(blue_mul))\n}\n\n// SeamlessClone blend two image by Poisson Blending.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/df/da0/group__photo__clone.html#ga2bf426e4c93a6b1f21705513dfeca49d\nfunc SeamlessClone(src, dst, mask Mat, p image.Point, blend *Mat, flags SeamlessCloneFlags) {\n\tcp := C.struct_Point{\n\t\tx: C.int(p.X),\n\t\ty: C.int(p.Y),\n\t}\n\n\tC.SeamlessClone(src.p, dst.p, mask.p, cp, blend.p, C.int(flags))\n}\n\n// IlluminationChange modifies locally the apparent illumination of an image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/df/da0/group__photo__clone.html#gac5025767cf2febd8029d474278e886c7\nfunc IlluminationChange(src, mask Mat, dst *Mat, alpha, beta float32) {\n\tC.IlluminationChange(src.p, mask.p, dst.p, C.float(alpha), C.float(beta))\n}\n\n// TextureFlattening washes out the texture of the selected region, giving its contents a flat aspect.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/df/da0/group__photo__clone.html#gad55df6aa53797365fa7cc23959a54004\nfunc TextureFlattening(src, mask Mat, dst *Mat, lowThreshold, highThreshold float32, kernelSize int) {\n\tC.TextureFlattening(src.p, mask.p, dst.p, C.float(lowThreshold), C.float(highThreshold), C.int(kernelSize))\n}\n\n// FastNlMeansDenoisingColoredMulti denoises the selected images.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d1/d79/group__photo__denoise.html#gaa501e71f52fb2dc17ff8ca5e7d2d3619\nfunc FastNlMeansDenoisingColoredMulti(src []Mat, dst *Mat, imgToDenoiseIndex int, temporalWindowSize int) {\n\tcMatArray := make([]C.Mat, len(src))\n\tfor i, r := range src {\n\t\tcMatArray[i] = (C.Mat)(r.p)\n\t}\n\tmatsVector := C.struct_Mats{\n\t\tmats:   (*C.Mat)(&cMatArray[0]),\n\t\tlength: C.int(len(src)),\n\t}\n\tC.FastNlMeansDenoisingColoredMulti(matsVector, dst.p, C.int(imgToDenoiseIndex), C.int(temporalWindowSize))\n}\n\n// FastNlMeansDenoisingColoredMulti denoises the selected images.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d1/d79/group__photo__denoise.html#gaa501e71f52fb2dc17ff8ca5e7d2d3619\nfunc FastNlMeansDenoisingColoredMultiWithParams(src []Mat, dst *Mat, imgToDenoiseIndex int, temporalWindowSize int, h float32, hColor float32, templateWindowSize int, searchWindowSize int) {\n\tcMatArray := make([]C.Mat, len(src))\n\tfor i, r := range src {\n\t\tcMatArray[i] = (C.Mat)(r.p)\n\t}\n\tmatsVector := C.struct_Mats{\n\t\tmats:   (*C.Mat)(&cMatArray[0]),\n\t\tlength: C.int(len(src)),\n\t}\n\tC.FastNlMeansDenoisingColoredMultiWithParams(matsVector, dst.p, C.int(imgToDenoiseIndex), C.int(temporalWindowSize), C.float(h), C.float(hColor), C.int(templateWindowSize), C.int(searchWindowSize))\n}\n\n// NewMergeMertens returns returns a new MergeMertens white LDR merge algorithm.\n// of type MergeMertens with default parameters.\n// MergeMertens algorithm merge the ldr image should result in a HDR image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/df5/group__photo__hdr.html\n// https://docs.opencv.org/master/d7/dd6/classcv_1_1MergeMertens.html\n// https://docs.opencv.org/master/d6/df5/group__photo__hdr.html#ga79d59aa3cb3a7c664e59a4b5acc1ccb6\nfunc NewMergeMertens() MergeMertens {\n\treturn MergeMertens{p: unsafe.Pointer(C.MergeMertens_Create())}\n}\n\n// NewMergeMertensWithParams returns a new MergeMertens white LDR merge algorithm\n// of type MergeMertens with customized parameters.\n// MergeMertens algorithm merge the ldr image should result in a HDR image.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d6/df5/group__photo__hdr.html\n// https://docs.opencv.org/master/d7/dd6/classcv_1_1MergeMertens.html\n// https://docs.opencv.org/master/d6/df5/group__photo__hdr.html#ga79d59aa3cb3a7c664e59a4b5acc1ccb6\nfunc NewMergeMertensWithParams(contrast_weight float32, saturation_weight float32, exposure_weight float32) MergeMertens {\n\treturn MergeMertens{p: unsafe.Pointer(C.MergeMertens_CreateWithParams(C.float(contrast_weight), C.float(saturation_weight), C.float(exposure_weight)))}\n}\n\n// Close MergeMertens.\nfunc (b *MergeMertens) Close() error {\n\tC.MergeMertens_Close((C.MergeMertens)(b.p)) // Here the unsafe pointer is cast into the right type\n\tb.p = nil\n\treturn nil\n}\n\n// BalanceWhite computes merge LDR images using the current MergeMertens.\n// Return a image MAT : 8bits 3 channel image ( RGB 8 bits )\n// For further details, please see:\n// https://docs.opencv.org/master/d7/dd6/classcv_1_1MergeMertens.html#a2d2254b2aab722c16954de13a663644d\nfunc (b *MergeMertens) Process(src []Mat, dst *Mat) {\n\tcMatArray := make([]C.Mat, len(src))\n\tfor i, r := range src {\n\t\tcMatArray[i] = (C.Mat)(r.p)\n\t}\n\t// Conversion function from a Golang slice into an array of matrices that are understood by OpenCV\n\tmatsVector := C.struct_Mats{\n\t\tmats:   (*C.Mat)(&cMatArray[0]),\n\t\tlength: C.int(len(src)),\n\t}\n\tC.MergeMertens_Process((C.MergeMertens)(b.p), matsVector, dst.p)\n\t// Convert a series of double [0.0,1.0] to [0,255] with Golang\n\tdst.ConvertToWithParams(dst, MatTypeCV8UC3, 255.0, 0.0)\n}\n\n// NewAlignMTB returns an AlignMTB for converts images to median threshold bitmaps.\n// of type AlignMTB converts images to median threshold bitmaps (1 for pixels\n// brighter than median luminance and 0 otherwise) and than aligns the resulting\n// bitmaps using bit operations.\n\n// For further details, please see:\n// https://docs.opencv.org/master/d6/df5/group__photo__hdr.html\n// https://docs.opencv.org/master/d7/db6/classcv_1_1AlignMTB.html\n// https://docs.opencv.org/master/d6/df5/group__photo__hdr.html#ga2f1fafc885a5d79dbfb3542e08db0244\nfunc NewAlignMTB() AlignMTB {\n\treturn AlignMTB{p: unsafe.Pointer(C.AlignMTB_Create())}\n}\n\n// NewAlignMTBWithParams returns an AlignMTB for converts images to median threshold bitmaps.\n// of type AlignMTB converts images to median threshold bitmaps (1 for pixels\n// brighter than median luminance and 0 otherwise) and than aligns the resulting\n// bitmaps using bit operations.\n\n// For further details, please see:\n// https://docs.opencv.org/master/d6/df5/group__photo__hdr.html\n// https://docs.opencv.org/master/d7/db6/classcv_1_1AlignMTB.html\n// https://docs.opencv.org/master/d6/df5/group__photo__hdr.html#ga2f1fafc885a5d79dbfb3542e08db0244\nfunc NewAlignMTBWithParams(max_bits int, exclude_range int, cut bool) AlignMTB {\n\treturn AlignMTB{p: unsafe.Pointer(C.AlignMTB_CreateWithParams(C.int(max_bits), C.int(exclude_range), C.bool(cut)))}\n}\n\n// Close AlignMTB.\nfunc (b *AlignMTB) Close() error {\n\tC.AlignMTB_Close((C.AlignMTB)(b.p))\n\tb.p = nil\n\treturn nil\n}\n\n// Process computes an alignment using the current AlignMTB.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/db6/classcv_1_1AlignMTB.html#a37b3417d844f362d781f34155cbcb201\nfunc (b *AlignMTB) Process(src []Mat, dst *[]Mat) {\n\n\tcSrcArray := make([]C.Mat, len(src))\n\tfor i, r := range src {\n\t\tcSrcArray[i] = r.p\n\t}\n\tcSrcMats := C.struct_Mats{\n\t\tmats:   (*C.Mat)(&cSrcArray[0]),\n\t\tlength: C.int(len(src)),\n\t}\n\n\tcDstMats := C.struct_Mats{}\n\n\tC.AlignMTB_Process((C.AlignMTB)(b.p), cSrcMats, &cDstMats)\n\n\t// Pass the matrices by reference from an OpenCV/C++ to a GoCV::Mat object\n\tfor i := C.int(0); i < cDstMats.length; i++ {\n\t\tvar tempdst Mat\n\t\ttempdst.p = C.Mats_get(cDstMats, i)\n\t\t*dst = append(*dst, tempdst)\n\t}\n\treturn\n}\n\n// FastNlMeansDenoising performs image denoising using Non-local Means Denoising algorithm\n// http://www.ipol.im/pub/algo/bcm_non_local_means_denoising/\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d1/d79/group__photo__denoise.html#ga4c6b0031f56ea3f98f768881279ffe93\nfunc FastNlMeansDenoising(src Mat, dst *Mat) {\n\tC.FastNlMeansDenoising(src.p, dst.p)\n}\n\n// FastNlMeansDenoisingWithParams performs image denoising using Non-local Means Denoising algorithm\n// http://www.ipol.im/pub/algo/bcm_non_local_means_denoising/\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d1/d79/group__photo__denoise.html#ga4c6b0031f56ea3f98f768881279ffe93\nfunc FastNlMeansDenoisingWithParams(src Mat, dst *Mat, h float32, templateWindowSize int, searchWindowSize int) {\n\tC.FastNlMeansDenoisingWithParams(src.p, dst.p, C.float(h), C.int(templateWindowSize), C.int(searchWindowSize))\n}\n\n// FastNlMeansDenoisingColored is a modification of fastNlMeansDenoising function for colored images.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d1/d79/group__photo__denoise.html#ga21abc1c8b0e15f78cd3eff672cb6c476\nfunc FastNlMeansDenoisingColored(src Mat, dst *Mat) {\n\tC.FastNlMeansDenoisingColored(src.p, dst.p)\n}\n\n// FastNlMeansDenoisingColoredWithParams is a modification of fastNlMeansDenoising function for colored images.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d1/d79/group__photo__denoise.html#ga21abc1c8b0e15f78cd3eff672cb6c476\nfunc FastNlMeansDenoisingColoredWithParams(src Mat, dst *Mat, h float32, hColor float32, templateWindowSize int, searchWindowSize int) {\n\tC.FastNlMeansDenoisingColoredWithParams(src.p, dst.p, C.float(h), C.float(hColor), C.int(templateWindowSize), C.int(searchWindowSize))\n}\n\n// DetailEnhance filter enhances the details of a particular image\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/df/dac/group__photo__render.html#gae5930dd822c713b36f8529b21ddebd0c\nfunc DetailEnhance(src Mat, dst *Mat, sigma_s, sigma_r float32) {\n\tC.DetailEnhance(src.p, dst.p, C.float(sigma_s), C.float(sigma_r))\n}\n\ntype EdgeFilter int\n\nconst (\n\t// RecursFilter Recursive Filtering.\n\tRecursFilter EdgeFilter = 1\n\n\t// NormconvFilter Normalized Convolution Filtering.\n\tNormconvFilter = 2\n)\n\n// EdgePreservingFilter filtering is the fundamental operation in image and video processing.\n// Edge-preserving smoothing filters are used in many different applications.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/df/dac/group__photo__render.html#gafaee2977597029bc8e35da6e67bd31f7\nfunc EdgePreservingFilter(src Mat, dst *Mat, filter EdgeFilter, sigma_s, sigma_r float32) {\n\tC.EdgePreservingFilter(src.p, dst.p, C.int(filter), C.float(sigma_s), C.float(sigma_r))\n}\n\n// PencilSketch pencil-like non-photorealistic line drawing.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/df/dac/group__photo__render.html#gae5930dd822c713b36f8529b21ddebd0c\nfunc PencilSketch(src Mat, dst1, dst2 *Mat, sigma_s, sigma_r, shade_factor float32) {\n\tC.PencilSketch(src.p, dst1.p, dst2.p, C.float(sigma_s), C.float(sigma_r), C.float(shade_factor))\n}\n\n// Stylization aims to produce digital imagery with a wide variety of effects\n// not focused on photorealism. Edge-aware filters are ideal for stylization,\n// as they can abstract regions of low contrast while preserving, or enhancing,\n// high-contrast features.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/df/dac/group__photo__render.html#gacb0f7324017df153d7b5d095aed53206\nfunc Stylization(src Mat, dst *Mat, sigma_s, sigma_r float32) {\n\tC.Stylization(src.p, dst.p, C.float(sigma_s), C.float(sigma_r))\n}\n\n// InpaintMethods is the methods for inpainting process.\ntype InpaintMethods int\n\nconst (\n\t// NS inpaints using Navier-Stokes based method, created by Bertalmio, Marcelo,\n\t// Andrea L. Bertozzi, and Guillermo Sapiro in 2001\n\tNS InpaintMethods = 0\n\n\t// Telea inpaints using Fast Marching Method proposed by Alexandru Telea in 2004.\n\tTelea InpaintMethods = 1\n)\n\n// Inpaint reconstructs the selected image area from the pixel near the area boundary.\n// The function may be used to remove dust and scratches from a scanned photo, or to\n// remove undesirable objects from still images or video.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d7/d8b/group__photo__inpaint.html#gaedd30dfa0214fec4c88138b51d678085\nfunc Inpaint(src Mat, mask Mat, dst *Mat, inpaintRadius float32, algorithmType InpaintMethods) {\n\tC.PhotoInpaint(C.Mat(src.Ptr()), C.Mat(mask.Ptr()), C.Mat(dst.Ptr()), C.float(inpaintRadius), C.int(algorithmType))\n}\n"
        },
        {
          "name": "photo.h",
          "type": "blob",
          "size": 2.3876953125,
          "content": "#ifndef _OPENCV3_PHOTO_H_\n#define _OPENCV3_PHOTO_H_\n\n#ifdef __cplusplus\n#include <opencv2/opencv.hpp>\n#include <opencv2/photo.hpp>\nextern \"C\" {\n#endif\n\n#include \"core.h\"\n\n#ifdef __cplusplus\n// see : https://docs.opencv.org/3.4/d7/dd6/classcv_1_1MergeMertens.html\ntypedef cv::Ptr<cv::MergeMertens> *MergeMertens;\n// see : https://docs.opencv.org/master/d7/db6/classcv_1_1AlignMTB.html\ntypedef cv::Ptr<cv::AlignMTB> *AlignMTB;\n#else\ntypedef void *MergeMertens;\ntypedef void *AlignMTB;\n#endif\n\nvoid ColorChange(Mat src, Mat mask, Mat dst, float red_mul, float green_mul, float blue_mul);\n\nvoid SeamlessClone(Mat src, Mat dst, Mat mask, Point p, Mat blend, int flags);\n\nvoid IlluminationChange(Mat src, Mat mask, Mat dst, float alpha, float beta);\n\nvoid TextureFlattening(Mat src, Mat mask, Mat dst, float low_threshold, float high_threshold, int kernel_size);\n\nvoid FastNlMeansDenoisingColoredMulti(struct Mats src, Mat dst, int imgToDenoiseIndex, int \ttemporalWindowSize);\nvoid FastNlMeansDenoisingColoredMultiWithParams(struct Mats src, Mat dst, int imgToDenoiseIndex, int \ttemporalWindowSize, float \th, float \thColor, int \ttemplateWindowSize, int \tsearchWindowSize );\nvoid FastNlMeansDenoising(Mat src, Mat dst);\nvoid FastNlMeansDenoisingWithParams(Mat src, Mat dst, float h, int templateWindowSize, int searchWindowSize);\nvoid FastNlMeansDenoisingColored(Mat src, Mat dst);\nvoid FastNlMeansDenoisingColoredWithParams(Mat src, Mat dst, float h, float hColor, int templateWindowSize, int searchWindowSize);\n\nMergeMertens MergeMertens_Create();\nMergeMertens MergeMertens_CreateWithParams(float contrast_weight, float saturation_weight, float exposure_weight);\nvoid MergeMertens_Process(MergeMertens b, struct Mats src, Mat dst);\nvoid MergeMertens_Close(MergeMertens b);\n\nAlignMTB AlignMTB_Create();\nAlignMTB AlignMTB_CreateWithParams(int max_bits, int exclude_range, bool cut);\nvoid AlignMTB_Process(AlignMTB b, struct Mats src, struct Mats *dst);\nvoid AlignMTB_Close(AlignMTB b);\n\nvoid DetailEnhance(Mat src, Mat dst, float sigma_s, float sigma_r);\nvoid EdgePreservingFilter(Mat src, Mat dst, int filter, float sigma_s, float sigma_r);\nvoid PencilSketch(Mat src, Mat dst1, Mat dst2, float sigma_s, float sigma_r, float shade_factor);\nvoid Stylization(Mat src, Mat dst, float sigma_s, float sigma_r);\n\nvoid PhotoInpaint(Mat src, Mat mask, Mat dst, float inpaint_radius, int algorithm_type);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif //_OPENCV3_PHOTO_H\n"
        },
        {
          "name": "photo_string.go",
          "type": "blob",
          "size": 0.2236328125,
          "content": "package gocv\n\nfunc (c SeamlessCloneFlags) String() string {\n\tswitch c {\n\tcase NormalClone:\n\t\treturn \"normal-clone\"\n\tcase MixedClone:\n\t\treturn \"mixed-clone\"\n\tcase MonochromeTransfer:\n\t\treturn \"monochrome-transfer\"\n\t}\n\treturn \"\"\n}\n"
        },
        {
          "name": "photo_test.go",
          "type": "blob",
          "size": 6.6201171875,
          "content": "package gocv\n\nimport (\n\t\"image\"\n\t\"testing\"\n)\n\nfunc TestColorChange(t *testing.T) {\n\tsrc := NewMatWithSize(20, 20, MatTypeCV8UC3)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\tmask := src.Clone()\n\tdefer mask.Close()\n\n\tColorChange(src, mask, &dst, 1.5, .5, .5)\n\tif dst.Empty() || dst.Rows() != src.Rows() || dst.Cols() != src.Cols() {\n\t\tt.Error(\"Invlalid ColorChange test\")\n\t}\n}\n\nfunc TestSeamlessClone(t *testing.T) {\n\tsrc := NewMatWithSize(20, 20, MatTypeCV8UC3)\n\tdefer src.Close()\n\tdst := NewMatWithSize(30, 30, MatTypeCV8UC3)\n\tdefer dst.Close()\n\tblend := NewMatWithSize(dst.Rows(), dst.Cols(), dst.Type())\n\tdefer blend.Close()\n\tmask := src.Clone()\n\tdefer mask.Close()\n\n\tcenter := image.Point{dst.Cols() / 2, dst.Rows() / 2}\n\tSeamlessClone(src, dst, mask, center, &blend, NormalClone)\n\tif blend.Empty() || dst.Rows() != blend.Rows() || dst.Cols() != blend.Cols() {\n\t\tt.Error(\"Invlalid SeamlessClone test\")\n\t}\n}\n\nfunc TestIlluminationChange(t *testing.T) {\n\tsrc := NewMatWithSize(20, 20, MatTypeCV8UC3)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\tmask := src.Clone()\n\tdefer mask.Close()\n\n\tIlluminationChange(src, mask, &dst, 0.2, 0.4)\n\tif dst.Empty() || dst.Rows() != src.Rows() || dst.Cols() != src.Cols() {\n\t\tt.Error(\"Invlalid IlluminationChange test\")\n\t}\n}\n\nfunc TestTextureFlattening(t *testing.T) {\n\tsrc := NewMatWithSize(20, 20, MatTypeCV8UC3)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\tmask := src.Clone()\n\tdefer mask.Close()\n\n\tTextureFlattening(src, mask, &dst, 30, 45, 3)\n\tif dst.Empty() || dst.Rows() != src.Rows() || dst.Cols() != src.Cols() {\n\t\tt.Error(\"Invlalid TextureFlattening test\")\n\t}\n}\n\nfunc TestFastNlMeansDenoisingColoredMultiWithParams(t *testing.T) {\n\tvar src [3]Mat\n\tfor i := 0; i < 3; i++ {\n\t\tsrc[i] = NewMatWithSize(20, 20, MatTypeCV8UC3)\n\t\tdefer src[i].Close()\n\t}\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tFastNlMeansDenoisingColoredMultiWithParams([]Mat{src[0], src[1], src[2]}, &dst, 1, 1, 3, 3, 7, 21)\n\n\tif dst.Empty() || dst.Rows() != src[0].Rows() || dst.Cols() != src[0].Cols() {\n\t\tt.Error(\"Invalid FastNlMeansDenoisingColoredMultiWithParams test\")\n\t}\n}\n\nfunc TestMergeMertens(t *testing.T) {\n\tvar src [3]Mat\n\tfor i := 0; i < 3; i++ {\n\t\tsrc[i] = NewMatWithSize(20, 20, MatTypeCV8UC3)\n\t\tdefer src[i].Close()\n\t}\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tmertens := NewMergeMertens()\n\tdefer mertens.Close()\n\n\tmertens.Process([]Mat{src[0], src[1], src[2]}, &dst)\n\n\tif dst.Empty() || dst.Rows() != src[0].Rows() || dst.Cols() != src[0].Cols() {\n\t\tt.Error(\"Invalid TestMergeMertens test\")\n\t}\n}\n\nfunc TestNewAlignMTB(t *testing.T) {\n\tvar src [3]Mat\n\tfor i := 0; i < 3; i++ {\n\t\tsrc[i] = NewMatWithSize(20, 20, MatTypeCV8UC3)\n\t\tdefer src[i].Close()\n\t}\n\n\talignwtb := NewAlignMTB()\n\tdefer alignwtb.Close()\n\n\tvar dst []Mat\n\talignwtb.Process([]Mat{src[0], src[1], src[2]}, &dst)\n\n\tsizedst := len(dst)\n\tt.Logf(\" Size Dst slice : %d \", sizedst)\n\tif sizedst > 0 {\n\t\tif dst[0].Empty() || dst[0].Rows() != src[0].Rows() || dst[0].Cols() != src[0].Cols() {\n\t\t\tt.Error(\"Invalid TestNewAlignMTB test\")\n\t\t}\n\t}\n\tif sizedst <= 0 {\n\t\tt.Error(\"Invalid TestNewAlignMTB test : empty result\")\n\t}\n}\n\nfunc TestFastNlMeansDenoising(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in TestFastNlMeansDenoising test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tFastNlMeansDenoising(img, &dest)\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Error in TestFastNlMeansDenoising test\")\n\t}\n}\n\nfunc TestFastNlMeansDenoisingWithParams(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in TestFastNlMeansDenoising test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tFastNlMeansDenoisingWithParams(img, &dest, 3, 7, 21)\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Error in TestFastNlMeansDenoising test\")\n\t}\n}\n\nfunc TestFastNlMeansDenoisingColored(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in FastNlMeansDenoisingColored test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tFastNlMeansDenoisingColored(img, &dest)\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Error in FastNlMeansDenoisingColored test\")\n\t}\n}\n\nfunc TestFastNlMeansDenoisingColoredWithParams(t *testing.T) {\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in FastNlMeansDenoisingColored test\")\n\t}\n\tdefer img.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tFastNlMeansDenoisingColoredWithParams(img, &dest, 3, 3, 7, 21)\n\tif dest.Empty() || img.Rows() != dest.Rows() || img.Cols() != dest.Cols() {\n\t\tt.Error(\"Error in FastNlMeansDenoisingColored test\")\n\t}\n}\n\nfunc TestDetailEnhance(t *testing.T) {\n\tsrc := NewMatWithSize(20, 20, MatTypeCV8UC3)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tDetailEnhance(src, &dst, 100.0, .5)\n\tif dst.Empty() || dst.Rows() != src.Rows() || dst.Cols() != src.Cols() {\n\t\tt.Error(\"Invlalid DetailEnhance test\")\n\t}\n}\n\nfunc TestEdgePreservingFilter(t *testing.T) {\n\tsrc := NewMatWithSize(20, 20, MatTypeCV8UC3)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tEdgePreservingFilter(src, &dst, RecursFilter, 100.0, .5)\n\tif dst.Empty() || dst.Rows() != src.Rows() || dst.Cols() != src.Cols() {\n\t\tt.Error(\"Invalid EdgePreservingFilter test\")\n\t}\n}\n\nfunc TestStylization(t *testing.T) {\n\tsrc := NewMatWithSize(20, 20, MatTypeCV8UC3)\n\tdefer src.Close()\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tStylization(src, &dst, 100.0, .5)\n\tif dst.Empty() || dst.Rows() != src.Rows() || dst.Cols() != src.Cols() {\n\t\tt.Error(\"Invlalid Stylization test\")\n\t}\n}\n\nfunc TestPencilSketch(t *testing.T) {\n\tsrc := NewMatWithSize(20, 20, MatTypeCV8UC3)\n\tdefer src.Close()\n\tdst1 := NewMat()\n\tdefer dst1.Close()\n\tdst2 := NewMat()\n\tdefer dst2.Close()\n\n\tPencilSketch(src, &dst1, &dst2, 100.0, .5, 0.05)\n\tif dst1.Empty() || dst1.Rows() != src.Rows() || dst1.Cols() != src.Cols() {\n\t\tt.Error(\"Invlalid PencilSketch test\")\n\t}\n\tif dst2.Empty() || dst2.Rows() != src.Rows() || dst2.Cols() != src.Cols() {\n\t\tt.Error(\"Invlalid PencilSketch test\")\n\t}\n}\n\nfunc TestInpaint(t *testing.T) {\n\tsrc := IMRead(\"images/inpaint-src.jpg\", IMReadColor)\n\tdefer src.Close()\n\tmask := IMRead(\"images/inpaint-mask.jpg\", IMReadGrayScale)\n\tdefer mask.Close()\n\tdst := NewMatWithSize(src.Rows(), src.Cols(), MatTypeCV8U)\n\tdefer dst.Close()\n\n\tInpaint(src, mask, &dst, 10, Telea)\n\tif dst.Channels() == 1 {\n\t\tt.Error(\"Invalid inpaint test\")\n\t}\n\n\tif sum := dst.Sum(); sum.Val1 == 0 || sum.Val2 == 0 || sum.Val3 == 0 {\n\t\tt.Error(\"Invalid inpaint test\")\n\t}\n}\n"
        },
        {
          "name": "svd.cpp",
          "type": "blob",
          "size": 0.1103515625,
          "content": "#include \"svd.h\"\n\nvoid SVD_Compute(Mat src, Mat w, Mat u, Mat vt) {\n    cv::SVD::compute(*src, *w, *u, *vt, 0);\n}"
        },
        {
          "name": "svd.go",
          "type": "blob",
          "size": 0.3369140625,
          "content": "package gocv\n\n/*\n#include <stdlib.h>\n#include \"svd.h\"\n*/\nimport \"C\"\n\n// SVDCompute decomposes matrix and stores the results to user-provided matrices\n//\n// https://docs.opencv.org/4.1.2/df/df7/classcv_1_1SVD.html#a76f0b2044df458160292045a3d3714c6\nfunc SVDCompute(src Mat, w, u, vt *Mat) {\n\tC.SVD_Compute(src.Ptr(), w.Ptr(), u.Ptr(), vt.Ptr())\n}\n"
        },
        {
          "name": "svd.h",
          "type": "blob",
          "size": 0.2353515625,
          "content": "#ifndef _OPENCV3_SVD_H_\n#define _OPENCV3_SVD_H_\n\n#ifdef __cplusplus\n#include <opencv2/opencv.hpp>\n\nextern \"C\" {\n#endif\n\n#include \"core.h\"\n\nvoid SVD_Compute(Mat src, Mat w, Mat u, Mat vt);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif //_OPENCV3_SVD_H"
        },
        {
          "name": "svd_test.go",
          "type": "blob",
          "size": 1.2568359375,
          "content": "package gocv\n\nimport (\n\t\"runtime\"\n\t\"testing\"\n)\n\nfunc TestSVDCompute(t *testing.T) {\n\tif runtime.GOOS == \"darwin\" {\n\t\tt.Skip(\"skipping test on macos\")\n\t}\n\n\tvar resultW = []float32{6.167493, 3.8214223}\n\tvar resultU = []float32{-0.1346676, -0.99089086, 0.9908908, -0.1346676}\n\tvar resultVt = []float32{0.01964448, 0.999807, -0.999807, 0.01964448}\n\n\tcheckFunc := func(a []float32, b []float32) bool {\n\t\tif len(a) != len(b) {\n\t\t\treturn false\n\t\t}\n\n\t\tfor i := range a {\n\t\t\tif a[i] != b[i] {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\treturn true\n\t}\n\n\tsrc := NewMatWithSize(2, 2, MatTypeCV32F)\n\tsrc.SetFloatAt(0, 0, 3.76956568)\n\tsrc.SetFloatAt(0, 1, -0.90478725)\n\tsrc.SetFloatAt(1, 0, 0.634576)\n\tsrc.SetFloatAt(1, 1, 6.10002347)\n\tdefer src.Close()\n\n\tw := NewMat()\n\tdefer w.Close()\n\n\tu := NewMat()\n\tdefer u.Close()\n\n\tvt := NewMat()\n\tdefer vt.Close()\n\n\tSVDCompute(src, &w, &u, &vt)\n\n\tdataW, err := w.DataPtrFloat32()\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\tif !checkFunc(resultW, dataW) {\n\t\tt.Error(\"w value is incorrect\")\n\t}\n\n\tdataU, err := u.DataPtrFloat32()\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\tif !checkFunc(resultU, dataU) {\n\t\tt.Error(\"u value is incorrect\")\n\t}\n\n\tdataVt, err := vt.DataPtrFloat32()\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\tif !checkFunc(resultVt, dataVt) {\n\t\tt.Error(\"vt value is incorrect\")\n\t}\n}\n"
        },
        {
          "name": "version.cpp",
          "type": "blob",
          "size": 0.0751953125,
          "content": "#include \"version.h\"\n\nconst char* openCVVersion() {\n    return CV_VERSION;\n}\n"
        },
        {
          "name": "version.go",
          "type": "blob",
          "size": 0.375,
          "content": "package gocv\n\n/*\n#include <stdlib.h>\n#include \"version.h\"\n*/\nimport \"C\"\n\n// GoCVVersion of this package, for display purposes.\nconst GoCVVersion = \"0.39.0\"\n\n// Version returns the current golang package version\nfunc Version() string {\n\treturn GoCVVersion\n}\n\n// OpenCVVersion returns the current OpenCV lib version\nfunc OpenCVVersion() string {\n\treturn C.GoString(C.openCVVersion())\n}\n"
        },
        {
          "name": "version.h",
          "type": "blob",
          "size": 0.228515625,
          "content": "#ifndef _OPENCV3_VERSION_H_\n#define _OPENCV3_VERSION_H_\n\n#ifdef __cplusplus\n#include <opencv2/opencv.hpp>\nextern \"C\" {\n#endif\n\n#include \"core.h\"\n\nconst char* openCVVersion();\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif //_OPENCV3_VERSION_H_\n"
        },
        {
          "name": "version_test.go",
          "type": "blob",
          "size": 0.267578125,
          "content": "package gocv\n\nimport (\n\t\"strings\"\n\t\"testing\"\n)\n\nfunc TestVersions(t *testing.T) {\n\tocvv := OpenCVVersion()\n\n\tif !strings.Contains(ocvv, \"4.10\") {\n\t\tt.Error(\"Wrong version of OpenCV:\", ocvv)\n\t}\n\n\tv := Version()\n\n\tif v != GoCVVersion {\n\t\tt.Error(\"Wrong version of GoCV\")\n\t}\n}\n"
        },
        {
          "name": "video.cpp",
          "type": "blob",
          "size": 6.8583984375,
          "content": "#include \"video.h\"\n\nBackgroundSubtractorMOG2 BackgroundSubtractorMOG2_Create() {\n    return new cv::Ptr<cv::BackgroundSubtractorMOG2>(cv::createBackgroundSubtractorMOG2());\n}\n\nBackgroundSubtractorMOG2 BackgroundSubtractorMOG2_CreateWithParams(int history, double varThreshold, bool detectShadows) {\n    return new cv::Ptr<cv::BackgroundSubtractorMOG2>(cv::createBackgroundSubtractorMOG2(history,varThreshold,detectShadows));\n}\n\nBackgroundSubtractorKNN BackgroundSubtractorKNN_Create() {\n    return new cv::Ptr<cv::BackgroundSubtractorKNN>(cv::createBackgroundSubtractorKNN());\n}\n\nBackgroundSubtractorKNN BackgroundSubtractorKNN_CreateWithParams(int history, double dist2Threshold, bool detectShadows) {\n    return new cv::Ptr<cv::BackgroundSubtractorKNN>(cv::createBackgroundSubtractorKNN(history,dist2Threshold,detectShadows));\n}\n\nvoid BackgroundSubtractorMOG2_Close(BackgroundSubtractorMOG2 b) {\n    delete b;\n}\n\nvoid BackgroundSubtractorMOG2_Apply(BackgroundSubtractorMOG2 b, Mat src, Mat dst) {\n    (*b)->apply(*src, *dst);\n}\n\nvoid BackgroundSubtractorKNN_Close(BackgroundSubtractorKNN k) {\n    delete k;\n}\n\nvoid BackgroundSubtractorKNN_Apply(BackgroundSubtractorKNN k, Mat src, Mat dst) {\n    (*k)->apply(*src, *dst);\n}\n\nvoid CalcOpticalFlowFarneback(Mat prevImg, Mat nextImg, Mat flow, double scale, int levels,\n                              int winsize, int iterations, int polyN, double polySigma, int flags) {\n    cv::calcOpticalFlowFarneback(*prevImg, *nextImg, *flow, scale, levels, winsize, iterations, polyN,\n                                 polySigma, flags);\n}\n\nvoid CalcOpticalFlowPyrLK(Mat prevImg, Mat nextImg, Mat prevPts, Mat nextPts, Mat status, Mat err) {\n    cv::calcOpticalFlowPyrLK(*prevImg, *nextImg, *prevPts, *nextPts, *status, *err);\n}\n\nvoid CalcOpticalFlowPyrLKWithParams(Mat prevImg, Mat nextImg, Mat prevPts, Mat nextPts, Mat status, Mat err, Size winSize, int maxLevel, TermCriteria criteria, int flags, double minEigThreshold){\n    cv::Size sz(winSize.width, winSize.height);\n    cv::calcOpticalFlowPyrLK(*prevImg, *nextImg, *prevPts, *nextPts, *status, *err, sz, maxLevel, *criteria, flags, minEigThreshold);\n}\n\ndouble FindTransformECC(Mat templateImage, Mat inputImage, Mat warpMatrix, int motionType, TermCriteria criteria, Mat inputMask, int gaussFiltSize){\n    return cv::findTransformECC(*templateImage, *inputImage, *warpMatrix, motionType, *criteria, *inputMask, gaussFiltSize);\n}\n\nbool Tracker_Init(Tracker self, Mat image, Rect boundingBox) {\n    cv::Rect bb(boundingBox.x, boundingBox.y, boundingBox.width, boundingBox.height);\n\n    (*self)->init(*image, bb);\n    return true;\n}\n\nbool Tracker_Update(Tracker self, Mat image, Rect* boundingBox) {\n    cv::Rect bb;\n    bool ret = (*self)->update(*image, bb);\n    boundingBox->x = int(bb.x);\n    boundingBox->y = int(bb.y);\n    boundingBox->width = int(bb.width);\n    boundingBox->height = int(bb.height);\n    return ret;\n}\n\nTrackerMIL TrackerMIL_Create() {\n    return new cv::Ptr<cv::TrackerMIL>(cv::TrackerMIL::create());\n}\n\nvoid TrackerMIL_Close(TrackerMIL self) {\n    delete self;\n}\n\nTrackerGOTURN TrackerGOTURN_Create(void){\n  return new cv::Ptr<cv::TrackerGOTURN>(cv::TrackerGOTURN::create());\n}\n\nTrackerGOTURN TrackerGOTURN_CreateWithParams(const char* modelBin, const char* modelTxt){\n\n  cv::TrackerGOTURN::Params params;\n  params.modelBin = modelBin;\n  params.modelTxt = modelTxt;\n\n  return new cv::Ptr<cv::TrackerGOTURN>(cv::TrackerGOTURN::create(params));\n}\n\n\nvoid TrackerGOTURN_Close(TrackerGOTURN tr) {\n    delete tr;\n}\n\nKalmanFilter KalmanFilter_New(int dynamParams, int measureParams) {\n    return new cv::KalmanFilter(dynamParams, measureParams, 0, CV_32F);\n}\n\nKalmanFilter KalmanFilter_NewWithParams(int dynamParams, int measureParams, int controlParams, int type) {\n    return new cv::KalmanFilter(dynamParams, measureParams, controlParams, type);\n}\n\nvoid KalmanFilter_Init(KalmanFilter kf, int dynamParams, int measureParams) {\n  kf->init(dynamParams, measureParams, 0, CV_32F);\n}\n\nvoid KalmanFilter_InitWithParams(KalmanFilter kf, int dynamParams, int measureParams, int controlParams, int type) {\n  kf->init(dynamParams, measureParams, controlParams, type);\n}\n\nvoid KalmanFilter_Close(KalmanFilter kf) {\n    delete kf;\n}\n\nMat KalmanFilter_Predict(KalmanFilter kf) {\n return new cv::Mat(kf->predict());\n}\n\nMat KalmanFilter_PredictWithParams(KalmanFilter kf, Mat control) {\n return new cv::Mat(kf->predict(*control));\n}\n\nMat KalmanFilter_Correct(KalmanFilter kf, Mat measurement) {\n  return new cv::Mat(kf->correct(*measurement));\n}\n\nMat KalmanFilter_GetStatePre(KalmanFilter kf) {\n  return new cv::Mat(kf->statePre);\n}\n\nMat KalmanFilter_GetStatePost(KalmanFilter kf) {\n  return new cv::Mat(kf->statePost);\n}\n\nMat KalmanFilter_GetTransitionMatrix(KalmanFilter kf) {\n  return new cv::Mat(kf->transitionMatrix);\n}\n\nMat KalmanFilter_GetControlMatrix(KalmanFilter kf) {\n  return new cv::Mat(kf->controlMatrix);\n}\n\nMat KalmanFilter_GetMeasurementMatrix(KalmanFilter kf) {\n  return new cv::Mat(kf->measurementMatrix);\n}\n\nMat KalmanFilter_GetProcessNoiseCov(KalmanFilter kf) {\n  return new cv::Mat(kf->processNoiseCov);\n}\n\nMat KalmanFilter_GetMeasurementNoiseCov(KalmanFilter kf) {\n  return new cv::Mat(kf->measurementNoiseCov);\n}\n\nMat KalmanFilter_GetErrorCovPre(KalmanFilter kf) {\n  return new cv::Mat(kf->errorCovPre);\n}\n\nMat KalmanFilter_GetGain(KalmanFilter kf) {\n  return new cv::Mat(kf->gain);\n}\n\nMat KalmanFilter_GetErrorCovPost(KalmanFilter kf) {\n  return new cv::Mat(kf->errorCovPost);\n}\n\nMat KalmanFilter_GetTemp1(KalmanFilter kf) {\n  return new cv::Mat(kf->temp1);\n}\n\nMat KalmanFilter_GetTemp2(KalmanFilter kf) {\n  return new cv::Mat(kf->temp2);\n}\n\nMat KalmanFilter_GetTemp3(KalmanFilter kf) {\n  return new cv::Mat(kf->temp3);\n}\n\nMat KalmanFilter_GetTemp4(KalmanFilter kf) {\n  return new cv::Mat(kf->temp4);\n}\n\nMat KalmanFilter_GetTemp5(KalmanFilter kf) {\n  return new cv::Mat(kf->temp5);\n}\n\nvoid KalmanFilter_SetStatePre(KalmanFilter kf, Mat statePre) {\n  kf->statePre = *statePre;\n}\n\nvoid KalmanFilter_SetStatePost(KalmanFilter kf, Mat statePost) {\n  kf->statePost = *statePost;\n}\n\nvoid KalmanFilter_SetTransitionMatrix(KalmanFilter kf, Mat transitionMatrix) {\n  kf->transitionMatrix = *transitionMatrix;\n}\n\nvoid KalmanFilter_SetControlMatrix(KalmanFilter kf, Mat controlMatrix) {\n  kf->controlMatrix = *controlMatrix;\n}\n\nvoid KalmanFilter_SetMeasurementMatrix(KalmanFilter kf, Mat measurementMatrix) {\n  kf->measurementMatrix = *measurementMatrix;\n}\n\nvoid KalmanFilter_SetProcessNoiseCov(KalmanFilter kf, Mat processNoiseCov) {\n  kf->processNoiseCov = *processNoiseCov;\n}\n\nvoid KalmanFilter_SetMeasurementNoiseCov(KalmanFilter kf, Mat measurementNoiseCov) {\n  kf->measurementNoiseCov = *measurementNoiseCov;\n}\n\nvoid KalmanFilter_SetErrorCovPre(KalmanFilter kf, Mat errorCovPre) {\n  kf->errorCovPre = *errorCovPre;\n}\n\nvoid KalmanFilter_SetGain(KalmanFilter kf, Mat gain) {\n  kf->gain = *gain;\n}\n\nvoid KalmanFilter_SetErrorCovPost(KalmanFilter kf, Mat errorCovPost) {\n  kf->errorCovPost = *errorCovPost;\n}\n"
        },
        {
          "name": "video.go",
          "type": "blob",
          "size": 20.6396484375,
          "content": "package gocv\n\n/*\n#include <stdlib.h>\n#include \"video.h\"\n*/\nimport \"C\"\nimport (\n\t\"image\"\n\t\"unsafe\"\n)\n\n/*\n*\n\n\tcv::OPTFLOW_USE_INITIAL_FLOW = 4,\n\tcv::OPTFLOW_LK_GET_MIN_EIGENVALS = 8,\n\tcv::OPTFLOW_FARNEBACK_GAUSSIAN = 256\n\tFor further details, please see: https://docs.opencv.org/master/dc/d6b/group__video__track.html#gga2c6cc144c9eee043575d5b311ac8af08a9d4430ac75199af0cf6fcdefba30eafe\n*/\nconst (\n\tOptflowUseInitialFlow    = 4\n\tOptflowLkGetMinEigenvals = 8\n\tOptflowFarnebackGaussian = 256\n)\n\n/*\n*\n\n\tcv::MOTION_TRANSLATION = 0,\n\tcv::MOTION_EUCLIDEAN = 1,\n\tcv::MOTION_AFFINE = 2,\n\tcv::MOTION_HOMOGRAPHY = 3\n\tFor further details, please see: https://docs.opencv.org/4.x/dc/d6b/group__video__track.html#ggaaedb1f94e6b143cef163622c531afd88a01106d6d20122b782ff25eaeffe9a5be\n*/\nconst (\n\tMotionTranslation = 0\n\tMotionEuclidean   = 1\n\tMotionAffine      = 2\n\tMotionHomography  = 3\n)\n\n// BackgroundSubtractorMOG2 is a wrapper around the cv::BackgroundSubtractorMOG2.\ntype BackgroundSubtractorMOG2 struct {\n\t// C.BackgroundSubtractorMOG2\n\tp unsafe.Pointer\n}\n\n// NewBackgroundSubtractorMOG2 returns a new BackgroundSubtractor algorithm\n// of type MOG2. MOG2 is a Gaussian Mixture-based Background/Foreground\n// Segmentation Algorithm.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/de/de1/group__video__motion.html#ga2beb2dee7a073809ccec60f145b6b29c\n// https://docs.opencv.org/master/d7/d7b/classcv_1_1BackgroundSubtractorMOG2.html\nfunc NewBackgroundSubtractorMOG2() BackgroundSubtractorMOG2 {\n\treturn BackgroundSubtractorMOG2{p: unsafe.Pointer(C.BackgroundSubtractorMOG2_Create())}\n}\n\n// NewBackgroundSubtractorMOG2WithParams returns a new BackgroundSubtractor algorithm\n// of type MOG2 with customized parameters. MOG2 is a Gaussian Mixture-based Background/Foreground\n// Segmentation Algorithm.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/de/de1/group__video__motion.html#ga2beb2dee7a073809ccec60f145b6b29c\n// https://docs.opencv.org/master/d7/d7b/classcv_1_1BackgroundSubtractorMOG2.html\nfunc NewBackgroundSubtractorMOG2WithParams(history int, varThreshold float64, detectShadows bool) BackgroundSubtractorMOG2 {\n\treturn BackgroundSubtractorMOG2{p: unsafe.Pointer(C.BackgroundSubtractorMOG2_CreateWithParams(C.int(history), C.double(varThreshold), C.bool(detectShadows)))}\n}\n\n// Close BackgroundSubtractorMOG2.\nfunc (b *BackgroundSubtractorMOG2) Close() error {\n\tC.BackgroundSubtractorMOG2_Close((C.BackgroundSubtractorMOG2)(b.p))\n\tb.p = nil\n\treturn nil\n}\n\n// Apply computes a foreground mask using the current BackgroundSubtractorMOG2.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/df6/classcv_1_1BackgroundSubtractor.html#aa735e76f7069b3fa9c3f32395f9ccd21\nfunc (b *BackgroundSubtractorMOG2) Apply(src Mat, dst *Mat) {\n\tC.BackgroundSubtractorMOG2_Apply((C.BackgroundSubtractorMOG2)(b.p), src.p, dst.p)\n\treturn\n}\n\n// BackgroundSubtractorKNN is a wrapper around the cv::BackgroundSubtractorKNN.\ntype BackgroundSubtractorKNN struct {\n\t// C.BackgroundSubtractorKNN\n\tp unsafe.Pointer\n}\n\n// NewBackgroundSubtractorKNN returns a new BackgroundSubtractor algorithm\n// of type KNN. K-Nearest Neighbors (KNN) uses a Background/Foreground\n// Segmentation Algorithm\n//\n// For further details, please see:\n// https://docs.opencv.org/master/de/de1/group__video__motion.html#gac9be925771f805b6fdb614ec2292006d\n// https://docs.opencv.org/master/db/d88/classcv_1_1BackgroundSubtractorKNN.html\nfunc NewBackgroundSubtractorKNN() BackgroundSubtractorKNN {\n\treturn BackgroundSubtractorKNN{p: unsafe.Pointer(C.BackgroundSubtractorKNN_Create())}\n}\n\n// NewBackgroundSubtractorKNNWithParams returns a new BackgroundSubtractor algorithm\n// of type KNN with customized parameters. K-Nearest Neighbors (KNN) uses a Background/Foreground\n// Segmentation Algorithm\n//\n// For further details, please see:\n// https://docs.opencv.org/master/de/de1/group__video__motion.html#gac9be925771f805b6fdb614ec2292006d\n// https://docs.opencv.org/master/db/d88/classcv_1_1BackgroundSubtractorKNN.html\nfunc NewBackgroundSubtractorKNNWithParams(history int, dist2Threshold float64, detectShadows bool) BackgroundSubtractorKNN {\n\treturn BackgroundSubtractorKNN{p: unsafe.Pointer(C.BackgroundSubtractorKNN_CreateWithParams(C.int(history), C.double(dist2Threshold), C.bool(detectShadows)))}\n}\n\n// Close BackgroundSubtractorKNN.\nfunc (k *BackgroundSubtractorKNN) Close() error {\n\tC.BackgroundSubtractorKNN_Close((C.BackgroundSubtractorKNN)(k.p))\n\tk.p = nil\n\treturn nil\n}\n\n// Apply computes a foreground mask using the current BackgroundSubtractorKNN.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d7/df6/classcv_1_1BackgroundSubtractor.html#aa735e76f7069b3fa9c3f32395f9ccd21\nfunc (k *BackgroundSubtractorKNN) Apply(src Mat, dst *Mat) {\n\tC.BackgroundSubtractorKNN_Apply((C.BackgroundSubtractorKNN)(k.p), src.p, dst.p)\n\treturn\n}\n\n// CalcOpticalFlowFarneback computes a dense optical flow using\n// Gunnar Farneback's algorithm.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/dc/d6b/group__video__track.html#ga5d10ebbd59fe09c5f650289ec0ece5af\nfunc CalcOpticalFlowFarneback(prevImg Mat, nextImg Mat, flow *Mat, pyrScale float64, levels int, winsize int,\n\titerations int, polyN int, polySigma float64, flags int) {\n\tC.CalcOpticalFlowFarneback(prevImg.p, nextImg.p, flow.p, C.double(pyrScale), C.int(levels), C.int(winsize),\n\t\tC.int(iterations), C.int(polyN), C.double(polySigma), C.int(flags))\n\treturn\n}\n\n// CalcOpticalFlowPyrLK calculates an optical flow for a sparse feature set using\n// the iterative Lucas-Kanade method with pyramids.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323\nfunc CalcOpticalFlowPyrLK(prevImg Mat, nextImg Mat, prevPts Mat, nextPts Mat, status *Mat, err *Mat) {\n\tC.CalcOpticalFlowPyrLK(prevImg.p, nextImg.p, prevPts.p, nextPts.p, status.p, err.p)\n\treturn\n}\n\n// CalcOpticalFlowPyrLKWithParams calculates an optical flow for a sparse feature set using\n// the iterative Lucas-Kanade method with pyramids.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323\nfunc CalcOpticalFlowPyrLKWithParams(prevImg Mat, nextImg Mat, prevPts Mat, nextPts Mat, status *Mat, err *Mat,\n\twinSize image.Point, maxLevel int, criteria TermCriteria, flags int, minEigThreshold float64) {\n\twinSz := C.struct_Size{\n\t\twidth:  C.int(winSize.X),\n\t\theight: C.int(winSize.Y),\n\t}\n\tC.CalcOpticalFlowPyrLKWithParams(prevImg.p, nextImg.p, prevPts.p, nextPts.p, status.p, err.p, winSz, C.int(maxLevel), criteria.p, C.int(flags), C.double(minEigThreshold))\n\treturn\n}\n\n// FindTransformECC finds the geometric transform (warp) between two images in terms of the ECC criterion.\n//\n// For futther details, please see:\n// https://docs.opencv.org/4.x/dc/d6b/group__video__track.html#ga1aa357007eaec11e9ed03500ecbcbe47\nfunc FindTransformECC(templateImage Mat, inputImage Mat, warpMatrix *Mat, motionType int, criteria TermCriteria, inputMask Mat, gaussFiltSize int) float64 {\n\treturn float64(C.FindTransformECC(templateImage.p, inputImage.p, warpMatrix.p, C.int(motionType), criteria.p, inputMask.p, C.int(gaussFiltSize)))\n}\n\n// Tracker is the base interface for object tracking.\n//\n// see: https://docs.opencv.org/master/d0/d0a/classcv_1_1Tracker.html\ntype Tracker interface {\n\t// Close closes, as Trackers need to be Closed manually.\n\t//\n\tClose() error\n\n\t// Init initializes the tracker with a known bounding box that surrounded the target.\n\t// Note: this can only be called once. If you lose the object, you have to Close() the instance,\n\t// create a new one, and call Init() on it again.\n\t//\n\t// see: https://docs.opencv.org/master/d0/d0a/classcv_1_1Tracker.html#a4d285747589b1bdd16d2e4f00c3255dc\n\t//\n\tInit(image Mat, boundingBox image.Rectangle) bool\n\n\t// Update updates the tracker, returns a new bounding box and a boolean determining whether the tracker lost the target.\n\t//\n\t// see: https://docs.opencv.org/master/d0/d0a/classcv_1_1Tracker.html#a549159bd0553e6a8de356f3866df1f18\n\t//\n\tUpdate(image Mat) (image.Rectangle, bool)\n}\n\nfunc trackerInit(trk C.Tracker, img Mat, boundingBox image.Rectangle) bool {\n\tcBox := C.struct_Rect{\n\t\tx:      C.int(boundingBox.Min.X),\n\t\ty:      C.int(boundingBox.Min.Y),\n\t\twidth:  C.int(boundingBox.Size().X),\n\t\theight: C.int(boundingBox.Size().Y),\n\t}\n\n\tret := C.Tracker_Init(trk, C.Mat(img.Ptr()), cBox)\n\treturn bool(ret)\n}\n\nfunc trackerUpdate(trk C.Tracker, img Mat) (image.Rectangle, bool) {\n\tcBox := C.struct_Rect{}\n\n\tret := C.Tracker_Update(trk, C.Mat(img.Ptr()), &cBox)\n\n\trect := image.Rect(int(cBox.x), int(cBox.y), int(cBox.x+cBox.width), int(cBox.y+cBox.height))\n\treturn rect, bool(ret)\n}\n\n// TrackerMIL is a Tracker that uses the MIL algorithm. MIL trains a classifier in an online manner\n// to separate the object from the background.\n// Multiple Instance Learning avoids the drift problem for a robust tracking.\n//\n// For further details, please see:\n// https://docs.opencv.org/master/d0/d26/classcv_1_1TrackerMIL.html\ntype TrackerMIL struct {\n\tp C.TrackerMIL\n}\n\n// NewTrackerMIL returns a new TrackerMIL.\nfunc NewTrackerMIL() Tracker {\n\treturn TrackerMIL{p: C.TrackerMIL_Create()}\n}\n\n// Close closes the TrackerMIL.\nfunc (trk TrackerMIL) Close() error {\n\tC.TrackerMIL_Close(trk.p)\n\ttrk.p = nil\n\treturn nil\n}\n\n// Init initializes the TrackerMIL.\nfunc (trk TrackerMIL) Init(img Mat, boundingBox image.Rectangle) bool {\n\treturn trackerInit(C.Tracker(trk.p), img, boundingBox)\n}\n\n// Update updates the TrackerMIL.\nfunc (trk TrackerMIL) Update(img Mat) (image.Rectangle, bool) {\n\treturn trackerUpdate(C.Tracker(trk.p), img)\n}\n\ntype TrackerGOTURN struct {\n\tp C.TrackerGOTURN\n}\n\n// NewTrackerGOTURN the GOTURN (Generic Object Tracking Using Regression Networks) tracker\n// GOTURN ([122]) is kind of trackers based on Convolutional Neural Networks (CNN).\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d7/d4c/classcv_1_1TrackerGOTURN.html#details\nfunc NewTrackerGOTURN() TrackerGOTURN {\n\treturn TrackerGOTURN{p: C.TrackerGOTURN_Create()}\n}\n\n// NewTrackerGOTURNWithParams the GOTURN (Generic Object Tracking Using Regression Networks) tracker\n// GOTURN ([122]) is kind of trackers based on Convolutional Neural Networks (CNN).\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/d7/d4c/classcv_1_1TrackerGOTURN.html#details\nfunc NewTrackerGOTURNWithParams(modelBin string, modelTxt string) TrackerGOTURN {\n\tc_modelBin := C.CString(modelBin)\n\tc_modelTxt := C.CString(modelTxt)\n\tdefer C.free(unsafe.Pointer(c_modelBin))\n\tdefer C.free(unsafe.Pointer(c_modelTxt))\n\n\treturn TrackerGOTURN{p: C.TrackerGOTURN_CreateWithParams(c_modelBin, c_modelTxt)}\n}\n\n// Init initializes the tracker with a known bounding box that surrounded the target.\n// Note: this can only be called once. If you lose the object, you have to Close() the instance,\n// create a new one, and call Init() on it again.\n//\n// see: https://docs.opencv.org/master/d0/d0a/classcv_1_1Tracker.html#a4d285747589b1bdd16d2e4f00c3255dc\nfunc (t TrackerGOTURN) Init(mat Mat, boundingBox image.Rectangle) bool {\n\treturn trackerInit(C.Tracker(t.p), mat, boundingBox)\n}\n\n// Update updates the tracker, returns a new bounding box and a boolean determining whether the tracker lost the target.\n//\n// see: https://docs.opencv.org/master/d0/d0a/classcv_1_1Tracker.html#a549159bd0553e6a8de356f3866df1f18\nfunc (t TrackerGOTURN) Update(mat Mat) (image.Rectangle, bool) {\n\treturn trackerUpdate(C.Tracker(t.p), mat)\n\n}\n\nfunc (t TrackerGOTURN) Close() error {\n\tC.TrackerGOTURN_Close(t.p)\n\tt.p = nil\n\treturn nil\n\n}\n\n// KalmanFilter implements a standard Kalman filter http://en.wikipedia.org/wiki/Kalman_filter.\n// However, you can modify transitionMatrix, controlMatrix, and measurementMatrix\n// to get an extended Kalman filter functionality.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html\ntype KalmanFilter struct {\n\tp C.KalmanFilter\n}\n\n// NewKalmanFilter returns a new KalmanFilter.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#ac0799f0611baee9e7e558f016e4a7b40\nfunc NewKalmanFilter(dynamParams int, measureParams int) KalmanFilter {\n\treturn KalmanFilter{p: C.KalmanFilter_New(C.int(dynamParams), C.int(measureParams))}\n}\n\n// NewKalmanFilterWithParams returns a new KalmanFilter.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#abac82ecfa530611a163255bc7d91c088\nfunc NewKalmanFilterWithParams(dynamParams int, measureParams int, controlParams int, matType MatType) KalmanFilter {\n\treturn KalmanFilter{p: C.KalmanFilter_NewWithParams(C.int(dynamParams), C.int(measureParams), C.int(controlParams), C.int(matType))}\n}\n\n// Init re-initializes the Kalman filter. The previous content is destroyed.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#a4f136c39c016d3530c7c5801dd1ddb3b\nfunc (kf *KalmanFilter) Init(dynamParams int, measureParams int) {\n\tC.KalmanFilter_Init(kf.p, C.int(dynamParams), C.int(measureParams))\n}\n\n// Predict computes a predicted state.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#aa710d2255566bec8d6ce608d103d4fa7\nfunc (kf *KalmanFilter) Predict() Mat {\n\treturn newMat(C.KalmanFilter_Predict(kf.p))\n}\n\n// PredictWithParams computes a predicted state.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#aa710d2255566bec8d6ce608d103d4fa7\nfunc (kf *KalmanFilter) PredictWithParams(control Mat) Mat {\n\treturn newMat(C.KalmanFilter_PredictWithParams(kf.p, control.p))\n}\n\n// Correct the predicted state from the measurement.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#a60eb7feb569222ad0657ef1875884b5e\nfunc (kf *KalmanFilter) Correct(measurement Mat) Mat {\n\treturn newMat(C.KalmanFilter_Correct(kf.p, measurement.p))\n}\n\n// Close closes the kalman filter.\nfunc (kf *KalmanFilter) Close() {\n\tC.KalmanFilter_Close(kf.p)\n\tkf.p = nil\n}\n\n// GetStatePre returns the Kalman filter's statePre Mat.\n//\n// predicted state (x'(k)): x(k)=A*x(k-1)+B*u(k)\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#a60eb7feb569222ad0657ef1875884b5e\nfunc (kf *KalmanFilter) GetStatePre() Mat {\n\treturn newMat(C.KalmanFilter_GetStatePre(kf.p))\n}\n\n// GetStatePost returns the Kalman filter's statePost Mat.\n//\n// corrected state (x(k)): x(k)=x'(k)+K(k)*(z(k)-H*x'(k))\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#add8fb5ac9c04b4600b679698dcb0447d\nfunc (kf *KalmanFilter) GetStatePost() Mat {\n\treturn newMat(C.KalmanFilter_GetStatePost(kf.p))\n}\n\n// GetTransitionMatrix returns the Kalman filter's transitionMatrix Mat.\n//\n// state transition matrix (A)\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#a0657173e411acbf40d2d3c6b46e03b19\nfunc (kf *KalmanFilter) GetTransitionMatrix() Mat {\n\treturn newMat(C.KalmanFilter_GetTransitionMatrix(kf.p))\n}\n\n// GetControlMatrix returns the Kalman filter's controlMatrix Mat.\n//\n// control matrix (B) (not used if there is no control)\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#a6486e7287114810636fb33953280ed52\nfunc (kf *KalmanFilter) GetControlMatrix() Mat {\n\treturn newMat(C.KalmanFilter_GetControlMatrix(kf.p))\n}\n\n// GetMeasurementMatrix returns the Kalman filter's measurementMatrix Mat.\n//\n// measurement matrix (H)\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#a0f60b78726d8eccf74a1f2479c2d1f97\nfunc (kf *KalmanFilter) GetMeasurementMatrix() Mat {\n\treturn newMat(C.KalmanFilter_GetMeasurementMatrix(kf.p))\n}\n\n// GetProcessNoiseCov returns the Kalman filter's processNoiseCov Mat.\n//\n// process noise covariance matrix (Q)\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#af19be9c0630d0f658bdbaea409a35cda\nfunc (kf *KalmanFilter) GetProcessNoiseCov() Mat {\n\treturn newMat(C.KalmanFilter_GetProcessNoiseCov(kf.p))\n}\n\n// GetMeasurementNoiseCov returns the Kalman filter's measurementNoiseCov Mat.\n//\n// measurement noise covariance matrix (R)\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#a828d051035ba807966ad65edf288a08e\nfunc (kf *KalmanFilter) GetMeasurementNoiseCov() Mat {\n\treturn newMat(C.KalmanFilter_GetMeasurementNoiseCov(kf.p))\n}\n\n// GetErrorCovPre returns the Kalman filter's errorCovPre Mat.\n//\n// priori error estimate covariance matrix (P'(k)): P'(k)=A*P(k-1)*At + Q)*/\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#ae1bd3a86f10753d723e7174d570d9ac1\nfunc (kf *KalmanFilter) GetErrorCovPre() Mat {\n\treturn newMat(C.KalmanFilter_GetErrorCovPre(kf.p))\n}\n\n// GetGain returns the Kalman filter's gain Mat.\n//\n// Kalman gain matrix (K(k)): K(k)=P'(k)*Ht*inv(H*P'(k)*Ht+R)\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#a077d73eb075b00779dc009a9057c27c3\nfunc (kf *KalmanFilter) GetGain() Mat {\n\treturn newMat(C.KalmanFilter_GetGain(kf.p))\n}\n\n// GetErrorCovPost returns the Kalman filter's errorCovPost Mat.\n//\n// posteriori error estimate covariance matrix (P(k)): P(k)=(I-K(k)*H)*P'(k)\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#a446d8e9a0105b0aa35cd66119c529803\nfunc (kf *KalmanFilter) GetErrorCovPost() Mat {\n\treturn newMat(C.KalmanFilter_GetErrorCovPost(kf.p))\n}\n\n// GetTemp1 returns the Kalman filter's temp1 Mat.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#aa3d064a9194c2815dbe19c056b6dc763\nfunc (kf *KalmanFilter) GetTemp1() Mat {\n\treturn newMat(C.KalmanFilter_GetTemp1(kf.p))\n}\n\n// GetTemp2 returns the Kalman filter's temp2 Mat.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#a14866bd506668eb0ed57b3974b3a1ee7\nfunc (kf *KalmanFilter) GetTemp2() Mat {\n\treturn newMat(C.KalmanFilter_GetTemp2(kf.p))\n}\n\n// GetTemp3 returns the Kalman filter's temp3 Mat.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#afdbe36066a7d7f560aa02abe6be114d8\nfunc (kf *KalmanFilter) GetTemp3() Mat {\n\treturn newMat(C.KalmanFilter_GetTemp3(kf.p))\n}\n\n// GetTemp4 returns the Kalman filter's temp4 Mat.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#a84342f2d9dec1e6389025ad229401809\nfunc (kf *KalmanFilter) GetTemp4() Mat {\n\treturn newMat(C.KalmanFilter_GetTemp4(kf.p))\n}\n\n// GetTemp5 returns the Kalman filter's temp5 Mat.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.6.0/dd/d6a/classcv_1_1KalmanFilter.html#a846c2a6222c6e5d8b1385dfbccc83ae0\nfunc (kf *KalmanFilter) GetTemp5() Mat {\n\treturn newMat(C.KalmanFilter_GetTemp5(kf.p))\n}\n\n// SetStatePre sets the Kalman filter's statePre Mat.\nfunc (kf *KalmanFilter) SetStatePre(statePre Mat) {\n\tC.KalmanFilter_SetStatePre(kf.p, statePre.p)\n}\n\n// SetStatePost sets the Kalman filter's statePost Mat.\nfunc (kf *KalmanFilter) SetStatePost(statePost Mat) {\n\tC.KalmanFilter_SetStatePost(kf.p, statePost.p)\n}\n\n// SetTransitionMatrix sets the Kalman filter's transitionMatrix Mat.\nfunc (kf *KalmanFilter) SetTransitionMatrix(transitionMatrix Mat) {\n\tC.KalmanFilter_SetTransitionMatrix(kf.p, transitionMatrix.p)\n}\n\n// SetControlMatrix sets the Kalman filter's controlMatrix Mat.\nfunc (kf *KalmanFilter) SetControlMatrix(controlMatrix Mat) {\n\tC.KalmanFilter_SetControlMatrix(kf.p, controlMatrix.p)\n}\n\n// SetMeasurementMatrix sets the Kalman filter's measurementMatrix Mat.\nfunc (kf *KalmanFilter) SetMeasurementMatrix(measurementMatrix Mat) {\n\tC.KalmanFilter_SetMeasurementMatrix(kf.p, measurementMatrix.p)\n}\n\n// SetProcessNoiseCov sets the Kalman filter's processNoiseCov Mat.\nfunc (kf *KalmanFilter) SetProcessNoiseCov(processNoiseCov Mat) {\n\tC.KalmanFilter_SetProcessNoiseCov(kf.p, processNoiseCov.p)\n}\n\n// SetMeasurementNoiseCov sets the Kalman filter's measurementNoiseCov Mat.\nfunc (kf *KalmanFilter) SetMeasurementNoiseCov(measurementNoiseCov Mat) {\n\tC.KalmanFilter_SetMeasurementNoiseCov(kf.p, measurementNoiseCov.p)\n}\n\n// SetErrorCovPre sets the Kalman filter's errorCovPre Mat.\nfunc (kf *KalmanFilter) SetErrorCovPre(errorCovPre Mat) {\n\tC.KalmanFilter_SetErrorCovPre(kf.p, errorCovPre.p)\n}\n\n// SetGain sets the Kalman filter's gain Mat.\nfunc (kf *KalmanFilter) SetGain(gain Mat) {\n\tC.KalmanFilter_SetGain(kf.p, gain.p)\n}\n\n// SetErrorCovPost sets the Kalman filter's errorCovPost Mat.\nfunc (kf *KalmanFilter) SetErrorCovPost(errorCovPost Mat) {\n\tC.KalmanFilter_SetErrorCovPost(kf.p, errorCovPost.p)\n}\n"
        },
        {
          "name": "video.h",
          "type": "blob",
          "size": 4.359375,
          "content": "#ifndef _OPENCV3_VIDEO_H_\n#define _OPENCV3_VIDEO_H_\n\n#ifdef __cplusplus\n#include <opencv2/opencv.hpp>\n#include <opencv2/video.hpp>\nextern \"C\" {\n#endif\n\n#include \"core.h\"\n\n#ifdef __cplusplus\ntypedef cv::Ptr<cv::BackgroundSubtractorMOG2>* BackgroundSubtractorMOG2;\ntypedef cv::Ptr<cv::BackgroundSubtractorKNN>* BackgroundSubtractorKNN;\ntypedef cv::Ptr<cv::Tracker>* Tracker;\ntypedef cv::Ptr<cv::TrackerMIL>* TrackerMIL;\ntypedef cv::Ptr<cv::TrackerGOTURN>* TrackerGOTURN;\ntypedef cv::KalmanFilter* KalmanFilter;\n#else\ntypedef void* BackgroundSubtractorMOG2;\ntypedef void* BackgroundSubtractorKNN;\ntypedef void* Tracker;\ntypedef void* TrackerMIL;\ntypedef void* TrackerGOTURN;\ntypedef void* KalmanFilter;\n#endif\n\nBackgroundSubtractorMOG2 BackgroundSubtractorMOG2_Create();\nBackgroundSubtractorMOG2 BackgroundSubtractorMOG2_CreateWithParams(int history, double varThreshold, bool detectShadows);\nvoid BackgroundSubtractorMOG2_Close(BackgroundSubtractorMOG2 b);\nvoid BackgroundSubtractorMOG2_Apply(BackgroundSubtractorMOG2 b, Mat src, Mat dst);\n\nBackgroundSubtractorKNN BackgroundSubtractorKNN_Create();\nBackgroundSubtractorKNN BackgroundSubtractorKNN_CreateWithParams(int history, double dist2Threshold, bool detectShadows);\n\nvoid BackgroundSubtractorKNN_Close(BackgroundSubtractorKNN b);\nvoid BackgroundSubtractorKNN_Apply(BackgroundSubtractorKNN b, Mat src, Mat dst);\n\nvoid CalcOpticalFlowPyrLK(Mat prevImg, Mat nextImg, Mat prevPts, Mat nextPts, Mat status, Mat err);\nvoid CalcOpticalFlowPyrLKWithParams(Mat prevImg, Mat nextImg, Mat prevPts, Mat nextPts, Mat status, Mat err, Size winSize, int maxLevel, TermCriteria criteria, int flags, double minEigThreshold);\nvoid CalcOpticalFlowFarneback(Mat prevImg, Mat nextImg, Mat flow, double pyrScale, int levels,\n                              int winsize, int iterations, int polyN, double polySigma, int flags);\n\ndouble FindTransformECC(Mat templateImage, Mat inputImage, Mat warpMatrix, int motionType, TermCriteria criteria, Mat inputMask, int gaussFiltSize);\n\nbool Tracker_Init(Tracker self, Mat image, Rect boundingBox);\nbool Tracker_Update(Tracker self, Mat image, Rect* boundingBox);\n\nTrackerMIL TrackerMIL_Create();\nvoid TrackerMIL_Close(TrackerMIL self);\n\nTrackerGOTURN TrackerGOTURN_Create(void);\nTrackerGOTURN TrackerGOTURN_CreateWithParams(const char* modelBin, const char* modelTxt);\nvoid TrackerGOTURN_Close(TrackerGOTURN tr);\n\nKalmanFilter KalmanFilter_New(int dynamParams, int measureParams);\nKalmanFilter KalmanFilter_NewWithParams(int dynamParams, int measureParams, int controlParams, int type);\nvoid KalmanFilter_Close(KalmanFilter kf);\n\nvoid KalmanFilter_Init(KalmanFilter kf, int dynamParams, int measureParams);\nvoid KalmanFilter_InitWithParams(KalmanFilter kf, int dynamParams, int measureParams, int controlParams, int type);\nMat KalmanFilter_Predict(KalmanFilter kf);\nMat KalmanFilter_PredictWithParams(KalmanFilter kf, Mat control);\nMat KalmanFilter_Correct(KalmanFilter kf, Mat measurement);\n\nMat KalmanFilter_GetStatePre(KalmanFilter kf);\nMat KalmanFilter_GetStatePost(KalmanFilter kf);\nMat KalmanFilter_GetTransitionMatrix(KalmanFilter kf);\nMat KalmanFilter_GetControlMatrix(KalmanFilter kf);\nMat KalmanFilter_GetMeasurementMatrix(KalmanFilter kf);\nMat KalmanFilter_GetProcessNoiseCov(KalmanFilter kf);\nMat KalmanFilter_GetMeasurementNoiseCov(KalmanFilter kf);\nMat KalmanFilter_GetErrorCovPre(KalmanFilter kf);\nMat KalmanFilter_GetGain(KalmanFilter kf);\nMat KalmanFilter_GetErrorCovPost(KalmanFilter kf);\nMat KalmanFilter_GetTemp1(KalmanFilter kf);\nMat KalmanFilter_GetTemp2(KalmanFilter kf);\nMat KalmanFilter_GetTemp3(KalmanFilter kf);\nMat KalmanFilter_GetTemp4(KalmanFilter kf);\nMat KalmanFilter_GetTemp5(KalmanFilter kf);\n\nvoid KalmanFilter_SetStatePre(KalmanFilter kf, Mat statePre);\nvoid KalmanFilter_SetStatePost(KalmanFilter kf, Mat statePost);\nvoid KalmanFilter_SetTransitionMatrix(KalmanFilter kf, Mat transitionMatrix);\nvoid KalmanFilter_SetControlMatrix(KalmanFilter kf, Mat controlMatrix);\nvoid KalmanFilter_SetMeasurementMatrix(KalmanFilter kf, Mat measurementMatrix);\nvoid KalmanFilter_SetProcessNoiseCov(KalmanFilter kf, Mat processNoiseCov);\nvoid KalmanFilter_SetMeasurementNoiseCov(KalmanFilter kf, Mat measurementNoiseCov);\nvoid KalmanFilter_SetErrorCovPre(KalmanFilter kf, Mat errorCovPre);\nvoid KalmanFilter_SetGain(KalmanFilter kf, Mat gain);\nvoid KalmanFilter_SetErrorCovPost(KalmanFilter kf, Mat errorCovPost);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif //_OPENCV3_VIDEO_H_\n"
        },
        {
          "name": "video_test.go",
          "type": "blob",
          "size": 9.3603515625,
          "content": "package gocv\n\nimport (\n\t\"image\"\n\t\"image/color\"\n\t\"math\"\n\t\"os\"\n\t\"testing\"\n)\n\nfunc TestMOG2(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in MOG2 test\")\n\t}\n\tdefer img.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tmog2 := NewBackgroundSubtractorMOG2()\n\tdefer mog2.Close()\n\n\tmog2.Apply(img, &dst)\n\n\tif dst.Empty() {\n\t\tt.Error(\"Error in TestMOG2 test\")\n\t}\n}\n\nfunc TestMOG2WithParams(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in MOG2 test\")\n\t}\n\tdefer img.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tmog2 := NewBackgroundSubtractorMOG2WithParams(250, 8, false)\n\tdefer mog2.Close()\n\n\tmog2.Apply(img, &dst)\n\n\tif dst.Empty() {\n\t\tt.Error(\"Error in TestMOG2WithParams test\")\n\t}\n}\n\nfunc TestKNN(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in KNN test\")\n\t}\n\tdefer img.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tknn := NewBackgroundSubtractorKNN()\n\tdefer knn.Close()\n\n\tknn.Apply(img, &dst)\n\n\tif dst.Empty() {\n\t\tt.Error(\"Error in TestKNN test\")\n\t}\n}\n\nfunc TestKNNWithParams(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in KNN test\")\n\t}\n\tdefer img.Close()\n\n\tdst := NewMat()\n\tdefer dst.Close()\n\n\tknn := NewBackgroundSubtractorKNNWithParams(250, 200, false)\n\tdefer knn.Close()\n\n\tknn.Apply(img, &dst)\n\n\tif dst.Empty() {\n\t\tt.Error(\"Error in TestKNNWithParams test\")\n\t}\n}\n\nfunc TestCalcOpticalFlowFarneback(t *testing.T) {\n\timg1 := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img1.Empty() {\n\t\tt.Error(\"Invalid Mat in CalcOpticalFlowFarneback test\")\n\t}\n\tdefer img1.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tCvtColor(img1, &dest, ColorBGRAToGray)\n\n\timg2 := dest.Clone()\n\tdefer img2.Close()\n\n\tflow := NewMat()\n\tdefer flow.Close()\n\n\tCalcOpticalFlowFarneback(dest, img2, &flow, 0.4, 1, 12, 2, 8, 1.2, 0)\n\n\tif flow.Empty() {\n\t\tt.Error(\"Error in CalcOpticalFlowFarneback test\")\n\t}\n\tif flow.Rows() != 480 {\n\t\tt.Errorf(\"Invalid CalcOpticalFlowFarneback test rows: %v\", flow.Rows())\n\t}\n\tif flow.Cols() != 640 {\n\t\tt.Errorf(\"Invalid CalcOpticalFlowFarneback test cols: %v\", flow.Cols())\n\t}\n}\n\nfunc TestCalcOpticalFlowPyrLK(t *testing.T) {\n\timg1 := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img1.Empty() {\n\t\tt.Error(\"Invalid Mat in CalcOpticalFlowPyrLK test\")\n\t}\n\tdefer img1.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tCvtColor(img1, &dest, ColorBGRAToGray)\n\n\timg2 := dest.Clone()\n\tdefer img2.Close()\n\n\tprevPts := NewMat()\n\tdefer prevPts.Close()\n\n\tnextPts := NewMat()\n\tdefer nextPts.Close()\n\n\tstatus := NewMat()\n\tdefer status.Close()\n\n\terr := NewMat()\n\tdefer err.Close()\n\n\tcorners := NewMat()\n\tdefer corners.Close()\n\n\tGoodFeaturesToTrack(dest, &corners, 500, 0.01, 10)\n\ttc := NewTermCriteria(Count|EPS, 20, 0.03)\n\tCornerSubPix(dest, &corners, image.Pt(10, 10), image.Pt(-1, -1), tc)\n\n\tCalcOpticalFlowPyrLK(dest, img2, corners, nextPts, &status, &err)\n\n\tif status.Empty() {\n\t\tt.Error(\"Error in CalcOpticalFlowPyrLK test\")\n\t}\n\tif status.Rows() != 323 {\n\t\tt.Errorf(\"Invalid CalcOpticalFlowPyrLK test rows: %v\", status.Rows())\n\t}\n\tif status.Cols() != 1 {\n\t\tt.Errorf(\"Invalid CalcOpticalFlowPyrLK test cols: %v\", status.Cols())\n\t}\n}\n\nfunc TestCalcOpticalFlowPyrLKWithParams(t *testing.T) {\n\timg1 := IMRead(\"images/face.jpg\", IMReadColor)\n\tif img1.Empty() {\n\t\tt.Error(\"Invalid Mat in CalcOpticalFlowPyrLK test\")\n\t}\n\tdefer img1.Close()\n\n\tdest := NewMat()\n\tdefer dest.Close()\n\n\tCvtColor(img1, &dest, ColorBGRAToGray)\n\n\timg2 := dest.Clone()\n\tdefer img2.Close()\n\n\tprevPts := NewMat()\n\tdefer prevPts.Close()\n\n\tnextPts := NewMat()\n\tdefer nextPts.Close()\n\n\tstatus := NewMat()\n\tdefer status.Close()\n\n\terr := NewMat()\n\tdefer err.Close()\n\n\tcorners := NewMat()\n\tdefer corners.Close()\n\n\tGoodFeaturesToTrack(dest, &corners, 500, 0.01, 10)\n\ttc := NewTermCriteria(Count|EPS, 30, 0.03)\n\tCornerSubPix(dest, &corners, image.Pt(10, 10), image.Pt(-1, -1), tc)\n\n\tCalcOpticalFlowPyrLKWithParams(dest, img2, corners, nextPts, &status, &err, image.Pt(21, 21), 3, tc, 0, 0.0001)\n\n\tif status.Empty() {\n\t\tt.Error(\"Error in CalcOpticalFlowPyrLK test\")\n\t}\n\tif status.Rows() != 323 {\n\t\tt.Errorf(\"Invalid CalcOpticalFlowPyrLK test rows: %v\", status.Rows())\n\t}\n\tif status.Cols() != 1 {\n\t\tt.Errorf(\"Invalid CalcOpticalFlowPyrLK test cols: %v\", status.Cols())\n\t}\n}\n\nfunc computeRMS(mat1 Mat, mat2 Mat) float64 {\n\tvar rms float64\n\tfor y := 0; y < mat1.Rows(); y++ {\n\t\tfor x := 0; x < mat1.Cols(); x++ {\n\t\t\tdiff := float64(mat1.GetFloatAt(y, x) - mat2.GetFloatAt(y, x))\n\t\t\trms += diff * diff\n\t\t}\n\t}\n\n\trms /= float64(mat1.Rows() * mat1.Cols())\n\treturn math.Sqrt(rms)\n}\n\nfunc TestFindTransformECC(t *testing.T) {\n\timg := IMRead(\"images/face.jpg\", IMReadGrayScale)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid Mat in FindTransformECC test\")\n\t}\n\tdefer img.Close()\n\ttestImg := NewMat()\n\tdefer testImg.Close()\n\tResize(img, &testImg, image.Point{216, 216}, 0, 0, InterpolationLinear)\n\n\ttranslationGround := Eye(2, 3, MatTypeCV32F)\n\tdefer translationGround.Close()\n\ttranslationGround.SetFloatAt(0, 2, 11.4159)\n\ttranslationGround.SetFloatAt(1, 2, 17.1828)\n\n\twarpedImage := NewMat()\n\tdefer warpedImage.Close()\n\tWarpAffineWithParams(testImg, &warpedImage, translationGround, image.Point{200, 200}, InterpolationLinear+WarpInverseMap, BorderConstant, color.RGBA{})\n\n\tmapTranslation := Eye(2, 3, MatTypeCV32F)\n\tdefer mapTranslation.Close()\n\teecIterations := 50\n\t// Negative value means that ECC_Iterations will be executed.\n\tvar eecEpsilon float64 = -1\n\tcriteria := NewTermCriteria(Count+EPS, eecIterations, eecEpsilon)\n\tinputMask := NewMat()\n\tdefer inputMask.Close()\n\tgaussFiltSize := 5\n\tFindTransformECC(warpedImage, testImg, &mapTranslation, MotionTranslation, criteria, inputMask, gaussFiltSize)\n\n\tmaxRMSECC := 0.1\n\trms := computeRMS(mapTranslation, translationGround)\n\tif rms > maxRMSECC {\n\t\tt.Errorf(\"FindTransformECC RMS = %f\", rms)\n\t}\n}\n\nfunc BaseTestTracker(t *testing.T, tracker Tracker, name string) {\n\tif tracker == nil {\n\t\tt.Error(\"TestTracker \" + name + \" should not be nil\")\n\t}\n\n\timg := IMRead(\"./images/face.jpg\", 1)\n\tif img.Empty() {\n\t\tt.Error(\"TestTracker \" + name + \" input img failed to load\")\n\t}\n\tdefer img.Close()\n\n\trect := image.Rect(250, 150, 250+200, 150+250)\n\tinit := tracker.Init(img, rect)\n\tif !init {\n\t\tt.Error(\"TestTracker \" + name + \" failed in Init\")\n\t}\n\n\t_, ok := tracker.Update(img)\n\tif !ok {\n\t\tt.Error(\"TestTracker \" + name + \" lost object in Update\")\n\t}\n}\n\nfunc TestSingleTrackers(t *testing.T) {\n\tgoturnPath := os.Getenv(\"GOCV_TRACKER_GOTURN_TEST_FILES\")\n\n\ttab := []struct {\n\t\tname    string\n\t\ttracker Tracker\n\t}{\n\t\t{\"MIL\", NewTrackerMIL()},\n\t\t{\"GOTURN\", NewTrackerGOTURNWithParams(goturnPath+\"/goturn.caffemodel\", goturnPath+\"/goturn.prototxt\")},\n\t}\n\n\tfor _, test := range tab {\n\t\tfunc() {\n\t\t\tdefer test.tracker.Close()\n\t\t\tBaseTestTracker(t, test.tracker, test.name)\n\t\t}()\n\t}\n}\n\nfunc TestKalmanFilter(t *testing.T) {\n\t// Basic test with default constructor.\n\tkf := NewKalmanFilter(2, 1)\n\tkf.Init(2, 1)\n\tmeasurement := Zeros(1, 1, MatTypeCV32F)\n\tprediction := kf.Predict()\n\tstatePost := kf.Correct(measurement)\n\tstatePost.Close()\n\tprediction.Close()\n\tmeasurement.Close()\n\tkf.Close()\n\n\t// Basic test with param constructor.\n\tkf = NewKalmanFilterWithParams(2, 1, 1, MatTypeCV32F)\n\tcontrol := Ones(1, 1, MatTypeCV32F)\n\tmeasurement = Ones(1, 1, MatTypeCV32F)\n\tprediction = kf.PredictWithParams(control)\n\tstatePost = kf.Correct(measurement)\n\tstatePost.Close()\n\tprediction.Close()\n\tmeasurement.Close()\n\tcontrol.Close()\n\tkf.Close()\n}\n\nfunc TestKalmanFilter_Getters(t *testing.T) {\n\tkf := NewKalmanFilterWithParams(2, 1, 1, MatTypeCV32F)\n\tgetterTests := []struct {\n\t\tdesc string\n\t\tf    func() Mat\n\t}{\n\t\t{desc: \"GetStatePre()\", f: kf.GetStatePre},\n\t\t{desc: \"GetStatePost()\", f: kf.GetStatePost},\n\t\t{desc: \"GetTransitionMatrix()\", f: kf.GetTransitionMatrix},\n\t\t{desc: \"GetControlMatrix()\", f: kf.GetControlMatrix},\n\t\t{desc: \"GetMeasurementMatrix()\", f: kf.GetMeasurementMatrix},\n\t\t{desc: \"GetProcessNoiseCov()\", f: kf.GetProcessNoiseCov},\n\t\t{desc: \"GetMeasurementNoiseCov()\", f: kf.GetMeasurementNoiseCov},\n\t\t{desc: \"GetErrorCovPre()\", f: kf.GetErrorCovPre},\n\t\t{desc: \"GetGain()\", f: kf.GetGain},\n\t\t{desc: \"GetErrorCovPost()\", f: kf.GetErrorCovPost},\n\t\t{desc: \"GetTemp1()\", f: kf.GetTemp1},\n\t\t{desc: \"GetTemp2()\", f: kf.GetTemp2},\n\t\t{desc: \"GetTemp3()\", f: kf.GetTemp3},\n\t\t{desc: \"GetTemp4()\", f: kf.GetTemp4},\n\t\t{desc: \"GetTemp5()\", f: kf.GetTemp5},\n\t}\n\tfor _, test := range getterTests {\n\t\tt.Run(test.desc, func(t *testing.T) {\n\t\t\tif got := test.f(); got.Empty() {\n\t\t\t\tt.Errorf(\"%v: returned empty, want non-Empty\", test.desc)\n\t\t\t} else {\n\t\t\t\tgot.Close()\n\t\t\t}\n\n\t\t})\n\t}\n\tkf.Close()\n}\n\nfunc TestKalmanFilter_Setters(t *testing.T) {\n\tkf := NewKalmanFilter(2, 1)\n\ttests := []struct {\n\t\tdesc string\n\t\tf    func(Mat)\n\t}{\n\t\t{desc: \"SetStatePre()\", f: kf.SetStatePre},\n\t\t{desc: \"SetStatePost()\", f: kf.SetStatePost},\n\t\t{desc: \"SetTransitionMatrix()\", f: kf.SetTransitionMatrix},\n\t\t{desc: \"SetControlMatrix()\", f: kf.SetControlMatrix},\n\t\t{desc: \"SetMeasurementMatrix()\", f: kf.SetMeasurementMatrix},\n\t\t{desc: \"SetProcessNoiseCov()\", f: kf.SetProcessNoiseCov},\n\t\t{desc: \"SetMeasurementNoiseCov()\", f: kf.SetMeasurementNoiseCov},\n\t\t{desc: \"SetErrorCovPre()\", f: kf.SetErrorCovPre},\n\t\t{desc: \"SetGain()\", f: kf.SetGain},\n\t\t{desc: \"SetErrorCovPost()\", f: kf.SetErrorCovPost},\n\t}\n\tfor _, test := range tests {\n\t\tt.Run(test.desc, func(t *testing.T) {\n\t\t\ttestMat := Ones(2, 1, MatTypeCV32F)\n\t\t\t// Just run this to make sure the execution doesn't fail.\n\t\t\ttest.f(testMat)\n\t\t\ttestMat.Close()\n\t\t})\n\t}\n\tkf.Close()\n}\n"
        },
        {
          "name": "videoio.cpp",
          "type": "blob",
          "size": 4.83984375,
          "content": "#include <stdexcept>\n#include \"videoio.h\"\n\n// VideoWriter\nVideoCapture VideoCapture_New() {\n    return new cv::VideoCapture();\n}\n\nvoid VideoCapture_Close(VideoCapture v) {\n    delete v;\n}\n\nbool VideoCapture_Open(VideoCapture v, const char* uri) {\n    return v->open(uri);\n}\n\nbool VideoCapture_OpenWithAPI(VideoCapture v, const char* uri, int apiPreference) {\n    return v->open(uri, apiPreference);\n}\n\nbool VideoCapture_OpenWithAPIParams(VideoCapture v, const char* uri, int apiPreference, int *paramsv, int paramsc) {\n    std::vector< int > params;\n\n    for( int i = 0; i< paramsc; i++) {\n        params.push_back(paramsv[i]);\n    }\n\n    return v->open(uri, apiPreference, params);\n}\n\nbool VideoCapture_OpenDevice(VideoCapture v, int device) {\n    return v->open(device);\n}\n\nbool VideoCapture_OpenDeviceWithAPI(VideoCapture v, int device, int apiPreference) {\n    return v->open(device, apiPreference);\n}\n\nbool VideoCapture_OpenDeviceWithAPIParams(VideoCapture v, int device, int apiPreference, int *paramsv, int paramsc) {\n    std::vector< int > params;\n\n    for( int i = 0; i< paramsc; i++) {\n        params.push_back(paramsv[i]);\n    }\n\n    return v->open(device, apiPreference, params);\n}\n\n\nvoid VideoCapture_Set(VideoCapture v, int prop, double param) {\n    v->set(prop, param);\n}\n\ndouble VideoCapture_Get(VideoCapture v, int prop) {\n    return v->get(prop);\n}\n\nint VideoCapture_IsOpened(VideoCapture v) {\n    return v->isOpened();\n}\n\nint VideoCapture_Read(VideoCapture v, Mat buf) {\n    return v->read(*buf);\n}\n\nvoid VideoCapture_Grab(VideoCapture v, int skip) {\n    for (int i = 0; i < skip; i++) {\n        v->grab();\n    }\n}\n\nint VideoCapture_Retrieve(VideoCapture v, Mat buf) {\n    return v->retrieve(*buf);\n}\n\n// VideoWriter\nVideoWriter VideoWriter_New() {\n    return new cv::VideoWriter();\n}\n\nvoid VideoWriter_Close(VideoWriter vw) {\n    delete vw;\n}\n\nvoid VideoWriter_Open(VideoWriter vw, const char* name, const char* codec, double fps, int width,\n                      int height, bool isColor) {\n    int codecCode = cv::VideoWriter::fourcc(codec[0], codec[1], codec[2], codec[3]);\n    vw->open(name, codecCode, fps, cv::Size(width, height), isColor);\n}\n\nint VideoWriter_IsOpened(VideoWriter vw) {\n    return vw->isOpened();\n}\n\nvoid VideoWriter_Write(VideoWriter vw, Mat img) {\n    *vw << *img;\n}\n\nchar* Videoio_Registry_GetBackendName(int api) {\n    cv::String name;\n\n    name = cv::videoio_registry::getBackendName((cv::VideoCaptureAPIs)(api));\n\n    return strdup(name.c_str());\n}\n\nIntVector Videio_Registry_GetBackends() {\n    IntVector c_backs;\n\n    std::vector<cv::VideoCaptureAPIs> backs = cv::videoio_registry::getBackends();\n\n    c_backs.val = new int[backs.size()];\n    c_backs.length = backs.size();\n\n    for(int i = 0; i < c_backs.length; i++) {\n        c_backs.val[i] = backs[i];\n    }\n\n    return c_backs;\n}\n\nchar* Videoio_Registry_GetCameraBackendPluginVersion(int api, int* version_ABI, int* version_API) {\n\n    std::string desc = cv::videoio_registry::getCameraBackendPluginVersion((cv::VideoCaptureAPIs)(api), *version_ABI, *version_API);\n\n    return strdup(desc.c_str());\n}\n\nIntVector Videoio_Registry_GetCameraBackends() {\n    IntVector c_backs;\n\n    std::vector<cv::VideoCaptureAPIs> backs = cv::videoio_registry::getCameraBackends();\n\n    c_backs.val = new int[backs.size()];\n    c_backs.length = backs.size();\n\n    for(int i = 0; i < c_backs.length; i++) {\n        c_backs.val[i] = backs[i];\n    }\n\n    return c_backs;\n}\n\nchar* Videoio_Registry_GetStreamBackendPluginVersion(int api, int* version_ABI, int* version_API){\n \n    std::string desc = cv::videoio_registry::getStreamBackendPluginVersion((cv::VideoCaptureAPIs)(api), *version_ABI, *version_API);\n\n    return strdup(desc.c_str());\n}\n\nIntVector Videoio_Registry_GetStreamBackends() {\n    IntVector c_backs;\n\n    std::vector<cv::VideoCaptureAPIs> backs = cv::videoio_registry::getStreamBackends();\n\n    c_backs.val = new int[backs.size()];\n    c_backs.length = backs.size();\n\n    for(int i = 0; i < c_backs.length; i++) {\n        c_backs.val[i] = backs[i];\n    }\n\n    return c_backs;\n}\n\nchar* Videoio_Registry_GetWriterBackendPluginVersion(int api, int* version_ABI, int* version_API){\n \n    std::string desc = cv::videoio_registry::getWriterBackendPluginVersion((cv::VideoCaptureAPIs)(api), *version_ABI, *version_API);\n\n    return strdup(desc.c_str());\n}\n\nIntVector Videoio_Registry_GetWriterBackends() {\n    IntVector c_backs;\n\n    std::vector<cv::VideoCaptureAPIs> backs = cv::videoio_registry::getWriterBackends();\n\n    c_backs.val = new int[backs.size()];\n    c_backs.length = backs.size();\n\n    for(int i = 0; i < c_backs.length; i++) {\n        c_backs.val[i] = backs[i];\n    }\n\n    return c_backs;\n}\n\nbool Videoio_Registry_HasBackend(int api) {\n    return cv::videoio_registry::hasBackend((cv::VideoCaptureAPIs)(api));\n}\n\nbool Videoio_Registry_IsBackendBuiltIn(int api) {\n    return cv::videoio_registry::isBackendBuiltIn((cv::VideoCaptureAPIs)(api));\n}\n"
        },
        {
          "name": "videoio.go",
          "type": "blob",
          "size": 23.5556640625,
          "content": "package gocv\n\n/*\n#include <stdlib.h>\n#include \"videoio.h\"\n*/\nimport \"C\"\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"strconv\"\n\t\"sync\"\n\t\"unsafe\"\n)\n\n// Select preferred API for a capture object.\n// Note: Backends are available only if they have been built with your OpenCV binaries\ntype VideoCaptureAPI int\n\nconst (\n\t// Auto detect == 0\n\tVideoCaptureAny VideoCaptureAPI = 0\n\n\t// Video For Windows (obsolete, removed)\n\tVideoCaptureVFW VideoCaptureAPI = 200\n\n\t// V4L/V4L2 capturing support\n\tVideoCaptureV4L VideoCaptureAPI = 200\n\n\t// Same as VideoCaptureV4L\n\tVideoCaptureV4L2 VideoCaptureAPI = 200\n\n\t// IEEE 1394 drivers\n\tVideoCaptureFirewire VideoCaptureAPI = 300\n\n\t// Same value as VideoCaptureFirewire\n\tVideoCaptureFireware VideoCaptureAPI = 300\n\n\t// Same value as VideoCaptureFirewire\n\tVideoCaptureIEEE1394 VideoCaptureAPI = 300\n\n\t// Same value as VideoCaptureFirewire\n\tVideoCaptureDC1394 VideoCaptureAPI = 300\n\n\t// Same value as VideoCaptureFirewire\n\tVideoCaptureCMU1394 VideoCaptureAPI = 300\n\n\t// QuickTime (obsolete, removed)\n\tVideoCaptureQT VideoCaptureAPI = 500\n\n\t// Unicap drivers (obsolete, removed)\n\tVideoCaptureUnicap VideoCaptureAPI = 600\n\n\t// DirectShow (via videoInput)\n\tVideoCaptureDshow VideoCaptureAPI = 700\n\n\t// PvAPI, Prosilica GigE SDK\n\tVideoCapturePvAPI VideoCaptureAPI = 800\n\n\t// OpenNI (for Kinect)\n\tVideoCaptureOpenNI VideoCaptureAPI = 900\n\n\t// OpenNI (for Asus Xtion)\n\tVideoCaptureOpenNIAsus VideoCaptureAPI = 910\n\n\t// Android - not used\n\tVideoCaptureAndroid VideoCaptureAPI = 1000\n\n\t// XIMEA Camera API\n\tVideoCaptureXiAPI VideoCaptureAPI = 1100\n\n\t// AVFoundation framework for iOS (OS X Lion will have the same API)\n\tVideoCaptureAVFoundation VideoCaptureAPI = 1200\n\n\t// Smartek Giganetix GigEVisionSDK\n\tVideoCaptureGiganetix VideoCaptureAPI = 1300\n\n\t// Microsoft Media Foundation (via videoInput)\n\tVideoCaptureMSMF VideoCaptureAPI = 1400\n\n\t// Microsoft Windows Runtime using Media Foundation\n\tVideoCaptureWinRT VideoCaptureAPI = 1410\n\n\t// RealSense (former Intel Perceptual Computing SDK)\n\tVideoCaptureIntelPerc VideoCaptureAPI = 1500\n\n\t// Synonym for VideoCaptureIntelPerc\n\tVideoCaptureRealsense VideoCaptureAPI = 1500\n\n\t// OpenNI2 (for Kinect)\n\tVideoCaptureOpenNI2 VideoCaptureAPI = 1600\n\n\t// OpenNI2 (for Asus Xtion and Occipital Structure sensors)\n\tVideoCaptureOpenNI2Asus VideoCaptureAPI = 1610\n\n\t// gPhoto2 connection\n\tVideoCaptureGPhoto2 VideoCaptureAPI = 1700\n\n\t// GStreamer\n\tVideoCaptureGstreamer VideoCaptureAPI = 1800\n\n\t// Open and record video file or stream using the FFMPEG library\n\tVideoCaptureFFmpeg VideoCaptureAPI = 1900\n\n\t// OpenCV Image Sequence (e.g. img_%02d.jpg)\n\tVideoCaptureImages VideoCaptureAPI = 2000\n\n\t// Aravis SDK\n\tVideoCaptureAravis VideoCaptureAPI = 2100\n\n\t// Built-in OpenCV MotionJPEG codec\n\tVideoCaptureOpencvMjpeg VideoCaptureAPI = 2200\n\n\t// Intel MediaSDK\n\tVideoCaptureIntelMFX VideoCaptureAPI = 2300\n\n\t// XINE engine (Linux)\n\tVideoCaptureXINE VideoCaptureAPI = 2400\n)\n\n// VideoCaptureProperties are the properties used for VideoCapture operations.\ntype VideoCaptureProperties int\n\nconst (\n\t// VideoCapturePosMsec contains current position of the\n\t// video file in milliseconds.\n\tVideoCapturePosMsec VideoCaptureProperties = 0\n\n\t// VideoCapturePosFrames 0-based index of the frame to be\n\t// decoded/captured next.\n\tVideoCapturePosFrames VideoCaptureProperties = 1\n\n\t// VideoCapturePosAVIRatio relative position of the video file:\n\t// 0=start of the film, 1=end of the film.\n\tVideoCapturePosAVIRatio VideoCaptureProperties = 2\n\n\t// VideoCaptureFrameWidth is width of the frames in the video stream.\n\tVideoCaptureFrameWidth VideoCaptureProperties = 3\n\n\t// VideoCaptureFrameHeight controls height of frames in the video stream.\n\tVideoCaptureFrameHeight VideoCaptureProperties = 4\n\n\t// VideoCaptureFPS controls capture frame rate.\n\tVideoCaptureFPS VideoCaptureProperties = 5\n\n\t// VideoCaptureFOURCC contains the 4-character code of codec.\n\t// see VideoWriter::fourcc for details.\n\tVideoCaptureFOURCC VideoCaptureProperties = 6\n\n\t// VideoCaptureFrameCount contains number of frames in the video file.\n\tVideoCaptureFrameCount VideoCaptureProperties = 7\n\n\t// VideoCaptureFormat format of the Mat objects returned by\n\t// VideoCapture::retrieve().\n\tVideoCaptureFormat VideoCaptureProperties = 8\n\n\t// VideoCaptureMode contains backend-specific value indicating\n\t// the current capture mode.\n\tVideoCaptureMode VideoCaptureProperties = 9\n\n\t// VideoCaptureBrightness is brightness of the image\n\t// (only for those cameras that support).\n\tVideoCaptureBrightness VideoCaptureProperties = 10\n\n\t// VideoCaptureContrast is contrast of the image\n\t// (only for cameras that support it).\n\tVideoCaptureContrast VideoCaptureProperties = 11\n\n\t// VideoCaptureSaturation saturation of the image\n\t// (only for cameras that support).\n\tVideoCaptureSaturation VideoCaptureProperties = 12\n\n\t// VideoCaptureHue hue of the image (only for cameras that support).\n\tVideoCaptureHue VideoCaptureProperties = 13\n\n\t// VideoCaptureGain is the gain of the capture image.\n\t// (only for those cameras that support).\n\tVideoCaptureGain VideoCaptureProperties = 14\n\n\t// VideoCaptureExposure is the exposure of the capture image.\n\t// (only for those cameras that support).\n\tVideoCaptureExposure VideoCaptureProperties = 15\n\n\t// VideoCaptureConvertRGB is a boolean flags indicating whether\n\t// images should be converted to RGB.\n\tVideoCaptureConvertRGB VideoCaptureProperties = 16\n\n\t// VideoCaptureWhiteBalanceBlueU is currently unsupported.\n\tVideoCaptureWhiteBalanceBlueU VideoCaptureProperties = 17\n\n\t// VideoCaptureRectification is the rectification flag for stereo cameras.\n\t// Note: only supported by DC1394 v 2.x backend currently.\n\tVideoCaptureRectification VideoCaptureProperties = 18\n\n\t// VideoCaptureMonochrome indicates whether images should be\n\t// converted to monochrome.\n\tVideoCaptureMonochrome VideoCaptureProperties = 19\n\n\t// VideoCaptureSharpness controls image capture sharpness.\n\tVideoCaptureSharpness VideoCaptureProperties = 20\n\n\t// VideoCaptureAutoExposure controls the DC1394 exposure control\n\t// done by camera, user can adjust reference level using this feature.\n\tVideoCaptureAutoExposure VideoCaptureProperties = 21\n\n\t// VideoCaptureGamma controls video capture gamma.\n\tVideoCaptureGamma VideoCaptureProperties = 22\n\n\t// VideoCaptureTemperature controls video capture temperature.\n\tVideoCaptureTemperature VideoCaptureProperties = 23\n\n\t// VideoCaptureTrigger controls video capture trigger.\n\tVideoCaptureTrigger VideoCaptureProperties = 24\n\n\t// VideoCaptureTriggerDelay controls video capture trigger delay.\n\tVideoCaptureTriggerDelay VideoCaptureProperties = 25\n\n\t// VideoCaptureWhiteBalanceRedV controls video capture setting for\n\t// white balance.\n\tVideoCaptureWhiteBalanceRedV VideoCaptureProperties = 26\n\n\t// VideoCaptureZoom controls video capture zoom.\n\tVideoCaptureZoom VideoCaptureProperties = 27\n\n\t// VideoCaptureFocus controls video capture focus.\n\tVideoCaptureFocus VideoCaptureProperties = 28\n\n\t// VideoCaptureGUID controls video capture GUID.\n\tVideoCaptureGUID VideoCaptureProperties = 29\n\n\t// VideoCaptureISOSpeed controls video capture ISO speed.\n\tVideoCaptureISOSpeed VideoCaptureProperties = 30\n\n\t// VideoCaptureBacklight controls video capture backlight.\n\tVideoCaptureBacklight VideoCaptureProperties = 32\n\n\t// VideoCapturePan controls video capture pan.\n\tVideoCapturePan VideoCaptureProperties = 33\n\n\t// VideoCaptureTilt controls video capture tilt.\n\tVideoCaptureTilt VideoCaptureProperties = 34\n\n\t// VideoCaptureRoll controls video capture roll.\n\tVideoCaptureRoll VideoCaptureProperties = 35\n\n\t// VideoCaptureIris controls video capture iris.\n\tVideoCaptureIris VideoCaptureProperties = 36\n\n\t// VideoCaptureSettings is the pop up video/camera filter dialog. Note:\n\t// only supported by DSHOW backend currently. The property value is ignored.\n\tVideoCaptureSettings VideoCaptureProperties = 37\n\n\t// VideoCaptureBufferSize controls video capture buffer size.\n\tVideoCaptureBufferSize VideoCaptureProperties = 38\n\n\t// VideoCaptureAutoFocus controls video capture auto focus..\n\tVideoCaptureAutoFocus VideoCaptureProperties = 39\n\n\t// VideoCaptureSarNumerator controls the sample aspect ratio: num/den (num)\n\tVideoCaptureSarNumerator VideoCaptureProperties = 40\n\n\t// VideoCaptureSarDenominator controls the sample aspect ratio: num/den (den)\n\tVideoCaptureSarDenominator VideoCaptureProperties = 41\n\n\t// VideoCaptureBackend is the current api backend (VideoCaptureAPI). Read-only property.\n\tVideoCaptureBackend VideoCaptureProperties = 42\n\n\t// VideoCaptureChannel controls the video input or channel number (only for those cameras that support).\n\tVideoCaptureChannel VideoCaptureProperties = 43\n\n\t// VideoCaptureAutoWB controls the auto white-balance.\n\tVideoCaptureAutoWB VideoCaptureProperties = 44\n\n\t// VideoCaptureWBTemperature controls the white-balance color temperature\n\tVideoCaptureWBTemperature VideoCaptureProperties = 45\n\n\t// VideoCaptureCodecPixelFormat shows the the codec's pixel format (4-character code). Read-only property.\n\t// Subset of AV_PIX_FMT_* or -1 if unknown.\n\tVideoCaptureCodecPixelFormat VideoCaptureProperties = 46\n\n\t// VideoCaptureBitrate displays the video bitrate in kbits/s. Read-only property.\n\tVideoCaptureBitrate VideoCaptureProperties = 47\n\n\t// VideoCaptureHWAcceleration Hardware acceleration type.\n\tVideoCaptureHWAcceleration VideoCaptureProperties = 50\n\n\t// VideoCaptureHWDevice Hardware device index (select GPU if multiple available).\n\tVideoCaptureHWDevice VideoCaptureProperties = 51\n)\n\n// VideoCapture is a wrapper around the OpenCV VideoCapture class.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d8/dfe/classcv_1_1VideoCapture.html\ntype VideoCapture struct {\n\tp C.VideoCapture\n}\n\n// VideoCaptureFile opens a VideoCapture from a file and prepares\n// to start capturing. It returns error if it fails to open the file stored in uri path.\nfunc VideoCaptureFile(uri string) (vc *VideoCapture, err error) {\n\tvc = &VideoCapture{p: C.VideoCapture_New()}\n\n\tcURI := C.CString(uri)\n\tdefer C.free(unsafe.Pointer(cURI))\n\n\tif !C.VideoCapture_Open(vc.p, cURI) {\n\t\terr = fmt.Errorf(\"Error opening file: %s\", uri)\n\t}\n\n\treturn\n}\n\n// VideoCaptureFile opens a VideoCapture from a file and prepares\n// to start capturing. It returns error if it fails to open the file stored in uri path.\nfunc VideoCaptureFileWithAPI(uri string, apiPreference VideoCaptureAPI) (vc *VideoCapture, err error) {\n\tvc = &VideoCapture{p: C.VideoCapture_New()}\n\n\tcURI := C.CString(uri)\n\tdefer C.free(unsafe.Pointer(cURI))\n\n\tif !C.VideoCapture_OpenWithAPI(vc.p, cURI, C.int(apiPreference)) {\n\t\terr = fmt.Errorf(\"Error opening file: %s with api backend: %d\", uri, apiPreference)\n\t}\n\n\treturn\n}\n\n// VideoCaptureFileWithAPIParams opens a VideoCapture from a file and prepares\n// to start capturing. It returns error if it fails to open the file stored in uri path.\nfunc VideoCaptureFileWithAPIParams(uri string, apiPreference VideoCaptureAPI, params []VideoCaptureProperties) (vc *VideoCapture, err error) {\n\tvc = &VideoCapture{p: C.VideoCapture_New()}\n\n\tcURI := C.CString(uri)\n\tdefer C.free(unsafe.Pointer(cURI))\n\n\tif !C.VideoCapture_OpenWithAPIParams(vc.p, cURI, C.int(apiPreference), (*C.int)(unsafe.Pointer(&params[0])), C.int(len(params))) {\n\t\terr = fmt.Errorf(\"Error opening file: %s with api backend: %d\", uri, apiPreference)\n\t}\n\n\treturn\n}\n\n// VideoCaptureDevice opens a VideoCapture from a device and prepares\n// to start capturing. It returns error if it fails to open the video device.\nfunc VideoCaptureDevice(device int) (vc *VideoCapture, err error) {\n\tvc = &VideoCapture{p: C.VideoCapture_New()}\n\n\tif !C.VideoCapture_OpenDevice(vc.p, C.int(device)) {\n\t\terr = fmt.Errorf(\"Error opening device: %d\", device)\n\t}\n\n\treturn\n}\n\n// VideoCaptureDeviceWithAPI opens a VideoCapture from a device with the api preference.\n// It returns error if it fails to open the video device.\nfunc VideoCaptureDeviceWithAPI(device int, apiPreference VideoCaptureAPI) (vc *VideoCapture, err error) {\n\tvc = &VideoCapture{p: C.VideoCapture_New()}\n\n\tif !C.VideoCapture_OpenDeviceWithAPI(vc.p, C.int(device), C.int(apiPreference)) {\n\t\terr = fmt.Errorf(\"Error opening device: %d with api backend: %d\", device, apiPreference)\n\t}\n\n\treturn\n}\n\n// VideoCaptureDeviceWithAPIParams opens a VideoCapture from a device with the api preference.\n// It returns error if it fails to open the video device.\nfunc VideoCaptureDeviceWithAPIParams(device int, apiPreference VideoCaptureAPI, params []VideoCaptureProperties) (vc *VideoCapture, err error) {\n\tvc = &VideoCapture{p: C.VideoCapture_New()}\n\n\tif !C.VideoCapture_OpenDeviceWithAPIParams(vc.p, C.int(device), C.int(apiPreference), (*C.int)(unsafe.Pointer(&params[0])), C.int(len(params))) {\n\t\terr = fmt.Errorf(\"Error opening device: %d with api backend: %d\", device, apiPreference)\n\t}\n\n\treturn\n}\n\n// Close VideoCapture object.\nfunc (v *VideoCapture) Close() error {\n\tC.VideoCapture_Close(v.p)\n\tv.p = nil\n\treturn nil\n}\n\n// Set parameter with property (=key).\nfunc (v *VideoCapture) Set(prop VideoCaptureProperties, param float64) {\n\tC.VideoCapture_Set(v.p, C.int(prop), C.double(param))\n}\n\n// Get parameter with property (=key).\nfunc (v VideoCapture) Get(prop VideoCaptureProperties) float64 {\n\treturn float64(C.VideoCapture_Get(v.p, C.int(prop)))\n}\n\n// IsOpened returns if the VideoCapture has been opened to read from\n// a file or capture device.\nfunc (v *VideoCapture) IsOpened() bool {\n\tisOpened := C.VideoCapture_IsOpened(v.p)\n\treturn isOpened != 0\n}\n\n// Read reads the next frame from the VideoCapture to the Mat passed in\n// as the param. It returns false if the VideoCapture cannot read frame.\nfunc (v *VideoCapture) Read(m *Mat) bool {\n\treturn C.VideoCapture_Read(v.p, m.p) != 0\n}\n\n// Grab skips a specific number of frames.\nfunc (v *VideoCapture) Grab(skip int) {\n\tC.VideoCapture_Grab(v.p, C.int(skip))\n}\n\n// Retrieve decodes and returns the grabbed video frame. Should be used after Grab\n//\n// For further details, please see:\n// http://docs.opencv.org/master/d8/dfe/classcv_1_1VideoCapture.html#a9ac7f4b1cdfe624663478568486e6712\nfunc (v *VideoCapture) Retrieve(m *Mat) bool {\n\treturn C.VideoCapture_Retrieve(v.p, m.p) != 0\n}\n\n// CodecString returns a string representation of FourCC bytes, i.e. the name of a codec\nfunc (v *VideoCapture) CodecString() string {\n\tres := \"\"\n\thexes := []int64{0xff, 0xff00, 0xff0000, 0xff000000}\n\tfor i, h := range hexes {\n\t\tres += string(rune(int64(v.Get(VideoCaptureFOURCC)) & h >> (uint(i * 8))))\n\t}\n\treturn res\n}\n\n// ToCodec returns an float64 representation of FourCC bytes\nfunc (v *VideoCapture) ToCodec(codec string) float64 {\n\tif len(codec) != 4 {\n\t\treturn -1.0\n\t}\n\tc1 := []rune(string(codec[0]))[0]\n\tc2 := []rune(string(codec[1]))[0]\n\tc3 := []rune(string(codec[2]))[0]\n\tc4 := []rune(string(codec[3]))[0]\n\treturn float64((c1 & 255) + ((c2 & 255) << 8) + ((c3 & 255) << 16) + ((c4 & 255) << 24))\n}\n\n// VideoWriter is a wrapper around the OpenCV VideoWriter`class.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/dd/d9e/classcv_1_1VideoWriter.html\ntype VideoWriter struct {\n\tmu *sync.RWMutex\n\tp  C.VideoWriter\n}\n\n// VideoWriterFile opens a VideoWriter with a specific output file.\n// The \"codec\" param should be the four-letter code for the desired output\n// codec, for example \"MJPG\".\n//\n// For further details, please see:\n// http://docs.opencv.org/master/dd/d9e/classcv_1_1VideoWriter.html#a0901c353cd5ea05bba455317dab81130\nfunc VideoWriterFile(name string, codec string, fps float64, width int, height int, isColor bool) (vw *VideoWriter, err error) {\n\n\tif fps == 0 || width == 0 || height == 0 {\n\t\treturn nil, fmt.Errorf(\"one of the numerical parameters \"+\n\t\t\t\"is equal to zero: FPS: %f, width: %d, height: %d\", fps, width, height)\n\t}\n\n\tvw = &VideoWriter{\n\t\tp:  C.VideoWriter_New(),\n\t\tmu: &sync.RWMutex{},\n\t}\n\n\tcName := C.CString(name)\n\tdefer C.free(unsafe.Pointer(cName))\n\n\tcCodec := C.CString(codec)\n\tdefer C.free(unsafe.Pointer(cCodec))\n\n\tC.VideoWriter_Open(vw.p, cName, cCodec, C.double(fps), C.int(width), C.int(height), C.bool(isColor))\n\treturn\n}\n\n// Close VideoWriter object.\nfunc (vw *VideoWriter) Close() error {\n\tC.VideoWriter_Close(vw.p)\n\tvw.p = nil\n\treturn nil\n}\n\n// IsOpened checks if the VideoWriter is open and ready to be written to.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/dd/d9e/classcv_1_1VideoWriter.html#a9a40803e5f671968ac9efa877c984d75\nfunc (vw *VideoWriter) IsOpened() bool {\n\tisOpend := C.VideoWriter_IsOpened(vw.p)\n\treturn isOpend != 0\n}\n\n// Write the next video frame from the Mat image to the open VideoWriter.\n//\n// For further details, please see:\n// http://docs.opencv.org/master/dd/d9e/classcv_1_1VideoWriter.html#a3115b679d612a6a0b5864a0c88ed4b39\nfunc (vw *VideoWriter) Write(img Mat) error {\n\tvw.mu.Lock()\n\tdefer vw.mu.Unlock()\n\tC.VideoWriter_Write(vw.p, img.p)\n\treturn nil\n}\n\n// OpenVideoCapture return VideoCapture specified by device ID if v is a\n// number. Return VideoCapture created from video file, URL, or GStreamer\n// pipeline if v is a string.\nfunc OpenVideoCapture(v interface{}) (*VideoCapture, error) {\n\tswitch vv := v.(type) {\n\tcase int:\n\t\treturn VideoCaptureDevice(vv)\n\tcase string:\n\t\tid, err := strconv.Atoi(vv)\n\t\tif err == nil {\n\t\t\treturn VideoCaptureDevice(id)\n\t\t}\n\t\treturn VideoCaptureFile(vv)\n\tdefault:\n\t\treturn nil, errors.New(\"argument must be int or string\")\n\t}\n}\n\n// OpenVideoCaptureWithAPI return VideoCapture specified by device ID if v is a\n// number. Return VideoCapture created from video file, URL, or GStreamer\n// pipeline if v is a string.\nfunc OpenVideoCaptureWithAPI(v interface{}, apiPreference VideoCaptureAPI) (*VideoCapture, error) {\n\tswitch vv := v.(type) {\n\tcase int:\n\t\treturn VideoCaptureDeviceWithAPI(vv, apiPreference)\n\tcase string:\n\t\tid, err := strconv.Atoi(vv)\n\t\tif err == nil {\n\t\t\treturn VideoCaptureDeviceWithAPI(id, apiPreference)\n\t\t}\n\t\treturn VideoCaptureFileWithAPI(vv, apiPreference)\n\tdefault:\n\t\treturn nil, errors.New(\"argument must be int or string\")\n\t}\n}\n\n// OpenVideoCaptureWithAPIParams return VideoCapture specified by device ID if v is a\n// number. Return VideoCapture created from video file, URL, or GStreamer\n// pipeline if v is a string.\nfunc OpenVideoCaptureWithAPIParams(v interface{}, apiPreference VideoCaptureAPI, params []VideoCaptureProperties) (*VideoCapture, error) {\n\tswitch vv := v.(type) {\n\tcase int:\n\t\treturn VideoCaptureDeviceWithAPIParams(vv, apiPreference, params)\n\tcase string:\n\t\tid, err := strconv.Atoi(vv)\n\t\tif err == nil {\n\t\t\treturn VideoCaptureDeviceWithAPIParams(id, apiPreference, params)\n\t\t}\n\t\t//TODO: params with files\n\t\treturn VideoCaptureFileWithAPIParams(vv, apiPreference, params)\n\tdefault:\n\t\treturn nil, errors.New(\"argument must be int or string\")\n\t}\n}\n\ntype VideoRegistryType struct{}\n\n// VideoRegistry\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/de/db1/group__videoio__registry.html\nvar VideoRegistry VideoRegistryType\n\n// GetBackendName Returns backend API name or \"UnknownVideoAPI(xxx)\".\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/de/db1/group__videoio__registry.html#ga6723e68832186e20bd44cd3c2b0d8c60\nfunc (VideoRegistryType) GetBackendName(api VideoCaptureAPI) string {\n\n\tc_name := C.Videoio_Registry_GetBackendName(C.int(api))\n\tdefer C.free(unsafe.Pointer(c_name))\n\n\tname := C.GoString(c_name)\n\treturn name\n}\n\n// GetBackends Returns list of all available backends.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/de/db1/group__videoio__registry.html#ga973abd27c3ea165472f789fa511d9f7b\nfunc (VideoRegistryType) GetBackends() []VideoCaptureAPI {\n\tintVec := C.Videio_Registry_GetBackends()\n\tdefer C.IntVector_Close(intVec)\n\n\tc_ints := unsafe.Slice(intVec.val, int(intVec.length))\n\n\tints := make([]VideoCaptureAPI, len(c_ints))\n\n\tfor i, val := range c_ints {\n\t\tints[i] = VideoCaptureAPI(int(val))\n\t}\n\treturn ints\n}\n\n// GetCameraBackendPluginVersion Returns description and ABI/API version of videoio plugin's camera interface.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/de/db1/group__videoio__registry.html#gab36e3e19ab2396410b74046de141323c\nfunc (VideoRegistryType) GetCameraBackendPluginVersion(api VideoCaptureAPI) (string, int, int) {\n\tvar (\n\t\tversion_abi C.int\n\t\tversion_api C.int\n\t)\n\n\tc_desc := C.Videoio_Registry_GetCameraBackendPluginVersion(C.int(api), &version_abi, &version_api)\n\tdefer C.free(unsafe.Pointer(c_desc))\n\tdesc := C.GoString(c_desc)\n\n\treturn desc, int(version_abi), int(version_api)\n}\n\n// GetCameraBackends Returns list of available backends which works via gocv.VideoCapture(int index)\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/de/db1/group__videoio__registry.html#ga043347faf6f5590b867a8b621906f7a9\nfunc (VideoRegistryType) GetCameraBackends() []VideoCaptureAPI {\n\tintVec := C.Videoio_Registry_GetCameraBackends()\n\tdefer C.IntVector_Close(intVec)\n\n\tc_ints := unsafe.Slice(intVec.val, int(intVec.length))\n\n\tints := make([]VideoCaptureAPI, len(c_ints))\n\n\tfor i, val := range c_ints {\n\t\tints[i] = VideoCaptureAPI(int(val))\n\t}\n\treturn ints\n}\n\n// GetStreamBackendPluginVersion Returns description and ABI/API version of videoio plugin's stream capture interface\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/de/db1/group__videoio__registry.html#gadf3c0c355f0917ccf754ac1af79d605a\nfunc (VideoRegistryType) GetStreamBackendPluginVersion(api VideoCaptureAPI) (string, int, int) {\n\tvar (\n\t\tversion_abi C.int\n\t\tversion_api C.int\n\t)\n\n\tc_desc := C.Videoio_Registry_GetStreamBackendPluginVersion(C.int(api), &version_abi, &version_api)\n\tdefer C.free(unsafe.Pointer(c_desc))\n\tdesc := C.GoString(c_desc)\n\n\treturn desc, int(version_abi), int(version_api)\n}\n\n// GetStreamBackends Returns list of available backends which works via gocv.VideoCapture(filename string)\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/de/db1/group__videoio__registry.html#ga29296d4c06ed9a9ff8bddae9fe581de1\nfunc (VideoRegistryType) GetStreamBackends() []VideoCaptureAPI {\n\tintVec := C.Videoio_Registry_GetStreamBackends()\n\tdefer C.IntVector_Close(intVec)\n\n\tc_ints := unsafe.Slice(intVec.val, int(intVec.length))\n\n\tints := make([]VideoCaptureAPI, len(c_ints))\n\n\tfor i, val := range c_ints {\n\t\tints[i] = VideoCaptureAPI(int(val))\n\t}\n\treturn ints\n}\n\n// GetWriterBackendPluginVersion Returns description and ABI/API version of videoio plugin's writer interface.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/de/db1/group__videoio__registry.html#gac41a544552a08bf3dc8142d687fbe4e5\nfunc (VideoRegistryType) GetWriterBackendPluginVersion(api VideoCaptureAPI) (string, int, int) {\n\tvar (\n\t\tversion_abi C.int\n\t\tversion_api C.int\n\t)\n\n\tc_desc := C.Videoio_Registry_GetWriterBackendPluginVersion(C.int(api), &version_abi, &version_api)\n\tdefer C.free(unsafe.Pointer(c_desc))\n\tdesc := C.GoString(c_desc)\n\n\treturn desc, int(version_abi), int(version_api)\n}\n\n// GetWriterBackends Returns list of available backends which works via gocv.VideoWriter()\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/de/db1/group__videoio__registry.html#gaed03e49e6a45ca5b20afe1b9f78955e0\nfunc (VideoRegistryType) GetWriterBackends() []VideoCaptureAPI {\n\tintVec := C.Videoio_Registry_GetWriterBackends()\n\tdefer C.IntVector_Close(intVec)\n\n\tc_ints := unsafe.Slice(intVec.val, int(intVec.length))\n\n\tints := make([]VideoCaptureAPI, len(c_ints))\n\n\tfor i, val := range c_ints {\n\t\tints[i] = VideoCaptureAPI(int(val))\n\t}\n\treturn ints\n}\n\n// HasBackend Returns true if backend is available.\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/de/db1/group__videoio__registry.html#ga9068310d50ef430c2f5f6b185a99a24b\nfunc (VideoRegistryType) HasBackend(api VideoCaptureAPI) bool {\n\tb := C.Videoio_Registry_HasBackend(C.int(api))\n\treturn bool(b)\n}\n\n// IsBackendBuiltIn Returns true if backend is built in (false if backend is used as plugin)\n//\n// For further details, please see:\n// https://docs.opencv.org/4.x/de/db1/group__videoio__registry.html#gadf24ec0854bb893a75591306ad9f3878\nfunc (VideoRegistryType) IsBackendBuiltIn(api VideoCaptureAPI) bool {\n\tb := C.Videoio_Registry_IsBackendBuiltIn(C.int(api))\n\treturn bool(b)\n}\n"
        },
        {
          "name": "videoio.h",
          "type": "blob",
          "size": 2.2587890625,
          "content": "#ifndef _OPENCV3_VIDEOIO_H_\n#define _OPENCV3_VIDEOIO_H_\n\n#ifdef __cplusplus\n#include <opencv2/opencv.hpp>\n#include <opencv2/videoio/registry.hpp>\nextern \"C\" {\n#endif\n\n#include \"core.h\"\n\n#ifdef __cplusplus\ntypedef cv::VideoCapture* VideoCapture;\ntypedef cv::VideoWriter* VideoWriter;\n#else\ntypedef void* VideoCapture;\ntypedef void* VideoWriter;\n#endif\n\n// VideoCapture\nVideoCapture VideoCapture_New();\nvoid VideoCapture_Close(VideoCapture v);\nbool VideoCapture_Open(VideoCapture v, const char* uri);\nbool VideoCapture_OpenWithAPI(VideoCapture v, const char* uri, int apiPreference);\nbool VideoCapture_OpenWithAPIParams(VideoCapture v, const char* uri, int apiPreference, int *paramsv, int paramsc);\nbool VideoCapture_OpenDevice(VideoCapture v, int device);\nbool VideoCapture_OpenDeviceWithAPI(VideoCapture v, int device, int apiPreference);\nbool VideoCapture_OpenDeviceWithAPIParams(VideoCapture v, int device, int apiPreference, int *paramsv, int paramsc);\nvoid VideoCapture_Set(VideoCapture v, int prop, double param);\ndouble VideoCapture_Get(VideoCapture v, int prop);\nint VideoCapture_IsOpened(VideoCapture v);\nint VideoCapture_Read(VideoCapture v, Mat buf);\nvoid VideoCapture_Grab(VideoCapture v, int skip);\nint VideoCapture_Retrieve(VideoCapture v, Mat buf);\n\n// VideoWriter\nVideoWriter VideoWriter_New();\nvoid VideoWriter_Close(VideoWriter vw);\nvoid VideoWriter_Open(VideoWriter vw, const char* name, const char* codec, double fps, int width,\n                      int height, bool isColor);\nint VideoWriter_IsOpened(VideoWriter vw);\nvoid VideoWriter_Write(VideoWriter vw, Mat img);\n\n//Videoio Query I/O API backends registry\nchar* Videoio_Registry_GetBackendName(int api);\nIntVector Videio_Registry_GetBackends();\nchar* Videoio_Registry_GetCameraBackendPluginVersion(int api, int* version_ABI, int* version_API);\nIntVector Videoio_Registry_GetCameraBackends();\nchar* Videoio_Registry_GetStreamBackendPluginVersion(int api, int* version_ABI, int* version_API);\nIntVector Videoio_Registry_GetStreamBackends();\nchar* Videoio_Registry_GetWriterBackendPluginVersion(int api, int* version_ABI, int* version_API);\nIntVector Videoio_Registry_GetWriterBackends();\nbool Videoio_Registry_HasBackend(int api);\nbool Videoio_Registry_IsBackendBuiltIn(int api);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif //_OPENCV3_VIDEOIO_H_\n"
        },
        {
          "name": "videoio_string.go",
          "type": "blob",
          "size": 4.5810546875,
          "content": "package gocv\n\nfunc (c VideoCaptureAPI) String() string {\n\tswitch c {\n\tcase VideoCaptureAny:\n\t\treturn \"video-capture-any\"\n\tcase VideoCaptureV4L2:\n\t\treturn \"video-capture-v4l2\"\n\tcase VideoCaptureFirewire:\n\t\treturn \"video-capture-firewire\"\n\tcase VideoCaptureQT:\n\t\treturn \"video-capture-qt\"\n\tcase VideoCaptureUnicap:\n\t\treturn \"video-capture-unicap\"\n\tcase VideoCaptureDshow:\n\t\treturn \"video-capture-dshow\"\n\tcase VideoCapturePvAPI:\n\t\treturn \"video-capture-pvapi\"\n\tcase VideoCaptureOpenNI:\n\t\treturn \"video-capture-openni\"\n\tcase VideoCaptureOpenNIAsus:\n\t\treturn \"video-capture-openni-asus\"\n\tcase VideoCaptureAndroid:\n\t\treturn \"video-capture-android\"\n\tcase VideoCaptureXiAPI:\n\t\treturn \"video-capture-xiapi\"\n\tcase VideoCaptureAVFoundation:\n\t\treturn \"video-capture-av-foundation\"\n\tcase VideoCaptureGiganetix:\n\t\treturn \"video-capture-giganetix\"\n\tcase VideoCaptureMSMF:\n\t\treturn \"video-capture-msmf\"\n\tcase VideoCaptureWinRT:\n\t\treturn \"video-capture-winrt\"\n\tcase VideoCaptureIntelPerc:\n\t\treturn \"video-capture-intel-perc\"\n\tcase VideoCaptureOpenNI2:\n\t\treturn \"video-capture-openni2\"\n\tcase VideoCaptureOpenNI2Asus:\n\t\treturn \"video-capture-openni2-asus\"\n\tcase VideoCaptureGPhoto2:\n\t\treturn \"video-capture-gphoto2\"\n\tcase VideoCaptureGstreamer:\n\t\treturn \"video-capture-gstreamer\"\n\tcase VideoCaptureFFmpeg:\n\t\treturn \"video-capture-ffmpeg\"\n\tcase VideoCaptureImages:\n\t\treturn \"video-capture-images\"\n\tcase VideoCaptureAravis:\n\t\treturn \"video-capture-aravis\"\n\tcase VideoCaptureOpencvMjpeg:\n\t\treturn \"video-capture-opencv-mjpeg\"\n\tcase VideoCaptureIntelMFX:\n\t\treturn \"video-capture-intel-mfx\"\n\tcase VideoCaptureXINE:\n\t\treturn \"video-capture-xine\"\n\t}\n\treturn \"\"\n}\n\nfunc (c VideoCaptureProperties) String() string {\n\tswitch c {\n\tcase VideoCapturePosMsec:\n\t\treturn \"video-capture-pos-msec\"\n\tcase VideoCapturePosFrames:\n\t\treturn \"video-capture-pos-frames\"\n\tcase VideoCapturePosAVIRatio:\n\t\treturn \"video-capture-pos-avi-ratio\"\n\tcase VideoCaptureFrameWidth:\n\t\treturn \"video-capture-frame-width\"\n\tcase VideoCaptureFrameHeight:\n\t\treturn \"video-capture-frame-height\"\n\tcase VideoCaptureFPS:\n\t\treturn \"video-capture-fps\"\n\tcase VideoCaptureFOURCC:\n\t\treturn \"video-capture-fourcc\"\n\tcase VideoCaptureFrameCount:\n\t\treturn \"video-capture-frame-count\"\n\tcase VideoCaptureFormat:\n\t\treturn \"video-capture-format\"\n\tcase VideoCaptureMode:\n\t\treturn \"video-capture-mode\"\n\tcase VideoCaptureBrightness:\n\t\treturn \"video-capture-brightness\"\n\tcase VideoCaptureContrast:\n\t\treturn \"video-capture-contrast\"\n\tcase VideoCaptureSaturation:\n\t\treturn \"video-capture-saturation\"\n\tcase VideoCaptureHue:\n\t\treturn \"video-capture-hue\"\n\tcase VideoCaptureGain:\n\t\treturn \"video-capture-gain\"\n\tcase VideoCaptureExposure:\n\t\treturn \"video-capture-exposure\"\n\tcase VideoCaptureConvertRGB:\n\t\treturn \"video-capture-convert-rgb\"\n\tcase VideoCaptureWhiteBalanceBlueU:\n\t\treturn \"video-capture-white-balanced-blue-u\"\n\tcase VideoCaptureWhiteBalanceRedV:\n\t\treturn \"video-capture-white-balanced-red-v\"\n\tcase VideoCaptureRectification:\n\t\treturn \"video-capture-rectification\"\n\tcase VideoCaptureMonochrome:\n\t\treturn \"video-capture-monochrome\"\n\tcase VideoCaptureSharpness:\n\t\treturn \"video-capture-sharpness\"\n\tcase VideoCaptureAutoExposure:\n\t\treturn \"video-capture-auto-exposure\"\n\tcase VideoCaptureGamma:\n\t\treturn \"video-capture-gamma\"\n\tcase VideoCaptureTemperature:\n\t\treturn \"video-capture-temperature\"\n\tcase VideoCaptureTrigger:\n\t\treturn \"video-capture-trigger\"\n\tcase VideoCaptureTriggerDelay:\n\t\treturn \"video-capture-trigger-delay\"\n\tcase VideoCaptureZoom:\n\t\treturn \"video-capture-zoom\"\n\tcase VideoCaptureFocus:\n\t\treturn \"video-capture-focus\"\n\tcase VideoCaptureGUID:\n\t\treturn \"video-capture-guid\"\n\tcase VideoCaptureISOSpeed:\n\t\treturn \"video-capture-iso-speed\"\n\tcase VideoCaptureBacklight:\n\t\treturn \"video-capture-backlight\"\n\tcase VideoCapturePan:\n\t\treturn \"video-capture-pan\"\n\tcase VideoCaptureTilt:\n\t\treturn \"video-capture-tilt\"\n\tcase VideoCaptureRoll:\n\t\treturn \"video-capture-roll\"\n\tcase VideoCaptureIris:\n\t\treturn \"video-capture-iris\"\n\tcase VideoCaptureSettings:\n\t\treturn \"video-capture-settings\"\n\tcase VideoCaptureBufferSize:\n\t\treturn \"video-capture-buffer-size\"\n\tcase VideoCaptureAutoFocus:\n\t\treturn \"video-capture-auto-focus\"\n\tcase VideoCaptureSarNumerator:\n\t\treturn \"video-capture-sar-numerator\"\n\tcase VideoCaptureSarDenominator:\n\t\treturn \"video-capture-sar-denominator\"\n\tcase VideoCaptureBackend:\n\t\treturn \"video-capture-backend\"\n\tcase VideoCaptureChannel:\n\t\treturn \"video-capture-channel\"\n\tcase VideoCaptureAutoWB:\n\t\treturn \"video-capture-auto-wb\"\n\tcase VideoCaptureWBTemperature:\n\t\treturn \"video-capture-wb-temperature\"\n\tcase VideoCaptureCodecPixelFormat:\n\t\treturn \"video-capture-pixel-format\"\n\tcase VideoCaptureBitrate:\n\t\treturn \"video-capture-bitrate\"\n\t}\n\treturn \"\"\n}\n"
        },
        {
          "name": "videoio_test.go",
          "type": "blob",
          "size": 7.7470703125,
          "content": "package gocv\n\nimport (\n\t\"io/ioutil\"\n\t\"math\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"strings\"\n\t\"testing\"\n)\n\nfunc TestVideoCaptureEmptyNumericalParameters(t *testing.T) {\n\t_, err := VideoWriterFile(\n\t\t\"images/small.mp4\", \"MJPEG\", 0, 0, 0, true)\n\tif err == nil {\n\t\tt.Error(\"Must fail due to an empty numerical parameters.\")\n\t}\n\tif !strings.Contains(err.Error(), \"one of the numerical parameters is equal to zero\") {\n\t\tt.Errorf(\"Must fail due to an empty numerical \"+\n\t\t\t\"parameters, but have different error: %v\", err)\n\t}\n}\n\nfunc TestVideoCaptureCodecString(t *testing.T) {\n\tvc, err := OpenVideoCapture(\"images/small.mp4\")\n\tif err != nil {\n\t\tt.Errorf(\"TestVideoCaptureCodecString: error loading a file: %v\", err)\n\t}\n\tif vc.CodecString() == \"\" {\n\t\tt.Fatal(\"TestVideoCaptureCodecString: empty codec string\")\n\t}\n}\n\nfunc TestVideoCaptureCodecConversion(t *testing.T) {\n\tvc, err := OpenVideoCapture(\"images/small.mp4\")\n\tif err != nil {\n\t\tt.Errorf(\"TestVideoCaptureCodecConversion: error loading a file: %v\", err)\n\t}\n\tif vc.CodecString() == \"\" {\n\t\tt.Fatal(\"TestVideoCaptureCodecConversion: empty codec string\")\n\t}\n\tif int64(vc.ToCodec(vc.CodecString())) != int64(vc.Get(VideoCaptureFOURCC)) {\n\t\tt.Fatal(\"TestVideoCaptureCodecConversion: codec conversion failed\")\n\t}\n}\n\nfunc TestVideoCaptureCodecConversionBadInput(t *testing.T) {\n\tvc, err := OpenVideoCapture(\"images/small.mp4\")\n\tif err != nil {\n\t\tt.Errorf(\"TestVideoCaptureCodecString: error loading a file: %v\", err)\n\t}\n\tcodec := vc.ToCodec(\"BAD CODEC\")\n\tif int64(codec) != -1 {\n\t\tt.Fatal(\"TestVideoCaptureCodecConversionBadInput: input validation failed\")\n\t}\n}\n\nfunc TestVideoCaptureInvalid(t *testing.T) {\n\t_, err := OpenVideoCapture(1.1)\n\tif err == nil {\n\t\tt.Errorf(\"Should return error with invalid param\")\n\t}\n}\n\nfunc TestVideoCaptureWithAPI(t *testing.T) {\n\tt.Run(\"video capture file with api\", func(t *testing.T) {\n\t\tvc, err := OpenVideoCaptureWithAPI(\"images/small.mp4\", VideoCaptureAny)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"error loading a file: %v\", err)\n\t\t}\n\t\tbackend := vc.Get(VideoCaptureBackend)\n\t\tif backend == float64(VideoCaptureAny) {\n\t\t\tt.Errorf(\"video capture backend api did not select a backend\")\n\t\t}\n\t})\n\n\tt.Run(\"video capture unknown device with api\", func(t *testing.T) {\n\t\t_, err := OpenVideoCaptureWithAPI(math.MaxInt32, VideoCaptureAny)\n\t\tif err == nil {\n\t\t\tt.Errorf(\"should return error opening device\")\n\t\t}\n\t})\n\n\tt.Run(\"video capture invalid with api\", func(t *testing.T) {\n\t\t_, err := OpenVideoCaptureWithAPI(1.1, VideoCaptureAny)\n\t\tif err == nil {\n\t\t\tt.Errorf(\"should return error with invalid param\")\n\t\t}\n\t})\n\n\tt.Run(\"video capture valid int string with api no available device\", func(t *testing.T) {\n\t\tvc5, err := OpenVideoCaptureWithAPI(\"99\", VideoCaptureAny)\n\t\tdefer vc5.Close()\n\t\tif err == nil {\n\t\t\tt.Errorf(\"should return error opening device\")\n\t\t}\n\t})\n}\n\nfunc TestVideoCaptureWithAPIParams(t *testing.T) {\n\tvc, _ := OpenVideoCaptureWithAPIParams(0, VideoCaptureAny, []VideoCaptureProperties{VideoCaptureHWAcceleration, 1, VideoCaptureHWDevice, 0})\n\tdefer vc.Close()\n\n}\n\nfunc TestVideoCaptureFileWithAPIParams(t *testing.T) {\n\tvc, _ := OpenVideoCaptureWithAPIParams(\"images/small.mp4\", VideoCaptureAny, []VideoCaptureProperties{VideoCaptureHWAcceleration, 1, VideoCaptureHWDevice, 0})\n\tdefer vc.Close()\n\n}\n\nfunc TestVideoCaptureFile(t *testing.T) {\n\tvc, err := VideoCaptureFile(\"images/small.mp4\")\n\tdefer vc.Close()\n\n\tif err != nil {\n\t\tt.Errorf(\"%s\", err)\n\t}\n\n\tif !vc.IsOpened() {\n\t\tt.Error(\"Unable to open VideoCaptureFile\")\n\t}\n\n\tif fw := vc.Get(VideoCaptureFrameWidth); int(fw) != 560 {\n\t\tt.Errorf(\"Expected frame width property of 560.0 got %f\", fw)\n\t}\n\tif fh := vc.Get(VideoCaptureFrameHeight); int(fh) != 320 {\n\t\tt.Errorf(\"Expected frame height property of 320.0 got %f\", fh)\n\t}\n\n\tvc.Set(VideoCaptureBrightness, 100.0)\n\n\tvc.Grab(10)\n\n\timg := NewMat()\n\tdefer img.Close()\n\n\tvc.Read(&img)\n\tif img.Empty() {\n\t\tt.Error(\"Unable to read VideoCaptureFile\")\n\t}\n\n\t// video capture file with non-existent video\n\tvc2, err := VideoCaptureFile(\"nonexistent.mp4\")\n\tdefer vc2.Close()\n\n\tif err == nil {\n\t\tt.Errorf(\"Expected error when opening invalid file\")\n\t}\n\n\tt.Run(\" video capture file with api\", func(t *testing.T) {\n\t\tvc3, err := VideoCaptureFileWithAPI(\"images/small.mp4\", VideoCaptureAny)\n\t\tdefer vc3.Close()\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\t})\n\n\tt.Run(\"video capture non-existent video with api\", func(t *testing.T) {\n\t\tvc4, err := VideoCaptureFileWithAPI(\"nonexistent.mp4\", VideoCaptureAny)\n\t\tdefer vc4.Close()\n\t\tif err == nil {\n\t\t\tt.Errorf(\"Expected error when opening invalid file\")\n\t\t}\n\t})\n\n\tt.Run(\"video capture invalid int\", func(t *testing.T) {\n\t\tvc5, err := OpenVideoCapture(math.MaxInt32)\n\t\tdefer vc5.Close()\n\t\tif err == nil {\n\t\t\tt.Errorf(\"should return error opening device\")\n\t\t}\n\t})\n\n\tt.Run(\"video capture invalid string\", func(t *testing.T) {\n\t\tvc5, err := OpenVideoCapture(\"test-device\")\n\t\tdefer vc5.Close()\n\t\tif err == nil {\n\t\t\tt.Errorf(\"should return error opening device\")\n\t\t}\n\t})\n\n\tt.Run(\"video capture valid string\", func(t *testing.T) {\n\t\tvc5, err := OpenVideoCapture(strconv.Itoa(math.MaxInt32))\n\t\tdefer vc5.Close()\n\t\tif err == nil {\n\t\t\tt.Errorf(\"should return error opening device\")\n\t\t}\n\t})\n}\n\nfunc TestVideoWriterFile(t *testing.T) {\n\tdir, _ := ioutil.TempDir(\"\", \"gocvtests\")\n\ttmpfn := filepath.Join(dir, \"test.avi\")\n\n\timg := IMRead(\"images/face-detect.jpg\", IMReadColor)\n\tif img.Empty() {\n\t\tt.Error(\"Invalid read of Mat in VideoWriterFile test\")\n\t}\n\tdefer img.Close()\n\n\tvw, _ := VideoWriterFile(tmpfn, \"MJPG\", 25, img.Cols(), img.Rows(), true)\n\tdefer vw.Close()\n\n\tif !vw.IsOpened() {\n\t\tt.Error(\"Unable to open VideoWriterFile\")\n\t}\n\n\terr := vw.Write(img)\n\tif err != nil {\n\t\tt.Error(\"Invalid Write() in VideoWriter\")\n\t}\n}\n\nfunc TestVideoCaptureFile_GrabRetrieve(t *testing.T) {\n\tvc, err := VideoCaptureFile(\"images/small.mp4\")\n\tdefer vc.Close()\n\n\tif err != nil {\n\t\tt.Errorf(\"%s\", err)\n\t}\n\n\tif !vc.IsOpened() {\n\t\tt.Error(\"Unable to open VideoCaptureFile\")\n\t}\n\n\tif fw := vc.Get(VideoCaptureFrameWidth); int(fw) != 560 {\n\t\tt.Errorf(\"Expected frame width property of 560.0 got %f\", fw)\n\t}\n\tif fh := vc.Get(VideoCaptureFrameHeight); int(fh) != 320 {\n\t\tt.Errorf(\"Expected frame height property of 320.0 got %f\", fh)\n\t}\n\n\tvc.Set(VideoCaptureBrightness, 100.0)\n\n\tvc.Grab(10)\n\n\timg := NewMat()\n\tdefer img.Close()\n\n\tif ok := vc.Retrieve(&img); !ok {\n\t\tt.Error(\"Unable to read VideoCaptureFile\")\n\t}\n\tif img.Empty() {\n\t\tt.Error(\"Unable to read VideoCaptureFile\")\n\t}\n}\n\nfunc TestVideoRegistry(t *testing.T) {\n\n\tname := VideoRegistry.GetBackendName(VideoCaptureFFmpeg)\n\tt.Log(\"VideoRegistry.GetBackendName()\", name)\n\n\tbacks := VideoRegistry.GetBackends()\n\tfor _, b := range backs {\n\t\tt.Log(\"VideoRegistry.GetBackends()\", b.String())\n\t}\n\n\tcameraBacks := VideoRegistry.GetCameraBackends()\n\tfor _, b := range cameraBacks {\n\t\tt.Log(\"VideoRegistry.GetCameraBackends()\", b.String())\n\t\tif !VideoRegistry.IsBackendBuiltIn(b) && VideoRegistry.HasBackend(b) {\n\n\t\t\tdescription, abiVersion, apiVersion := VideoRegistry.GetCameraBackendPluginVersion(b)\n\t\t\tt.Log(\"VideoRegistry.GetCameraBackendPluginVersion()\", description, abiVersion, apiVersion)\n\t\t}\n\t}\n\n\tstreamBacks := VideoRegistry.GetStreamBackends()\n\tfor _, b := range streamBacks {\n\t\tt.Log(\"VideoRegistry.GetStreamBackends()\", b.String())\n\t\tif !VideoRegistry.IsBackendBuiltIn(b) && VideoRegistry.HasBackend(b) {\n\n\t\t\tdescription, abiVersion, apiVersion := VideoRegistry.GetStreamBackendPluginVersion(b)\n\t\t\tt.Log(\"VideoRegistry.GetStreamBackendPluginVersion()\", description, abiVersion, apiVersion)\n\t\t}\n\t}\n\n\twriterBacks := VideoRegistry.GetWriterBackends()\n\n\tfor _, b := range writerBacks {\n\t\tt.Log(\"VideoRegistry.GetWriterBackends()\", b.String())\n\t\tif !VideoRegistry.IsBackendBuiltIn(b) && VideoRegistry.HasBackend(b) {\n\n\t\t\tdescription, abiVersion, apiVersion := VideoRegistry.GetWriterBackendPluginVersion(b)\n\t\t\tt.Log(\"VideoRegistry.GetWriterBackendPluginVersion()\", description, abiVersion, apiVersion)\n\t\t}\n\t}\n\n}\n"
        },
        {
          "name": "win_build_opencv.cmd",
          "type": "blob",
          "size": 2.423828125,
          "content": "@echo off\n\nif not exist \"C:\\opencv\" mkdir \"C:\\opencv\"\nif not exist \"C:\\opencv\\build\" mkdir \"C:\\opencv\\build\"\n\necho Downloading OpenCV sources\necho.\necho For monitoring the download progress please check the C:\\opencv directory.\necho.\n\nREM This is why there is no progress bar:\nREM https://github.com/PowerShell/PowerShell/issues/2138\n\necho Downloading: opencv-4.10.0.zip [91MB]\npowershell -command \"[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12; $ProgressPreference = 'SilentlyContinue'; Invoke-WebRequest -Uri https://github.com/opencv/opencv/archive/4.10.0.zip -OutFile c:\\opencv\\opencv-4.10.0.zip\"\necho Extracting...\npowershell -command \"$ProgressPreference = 'SilentlyContinue'; Expand-Archive -Path c:\\opencv\\opencv-4.10.0.zip -DestinationPath c:\\opencv\"\ndel c:\\opencv\\opencv-4.10.0.zip /q\necho.\n\necho Downloading: opencv_contrib-4.10.0.zip [58MB]\npowershell -command \"[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12; $ProgressPreference = 'SilentlyContinue'; Invoke-WebRequest -Uri https://github.com/opencv/opencv_contrib/archive/4.10.0.zip -OutFile c:\\opencv\\opencv_contrib-4.10.0.zip\"\necho Extracting...\npowershell -command \"$ProgressPreference = 'SilentlyContinue'; Expand-Archive -Path c:\\opencv\\opencv_contrib-4.10.0.zip -DestinationPath c:\\opencv\"\ndel c:\\opencv\\opencv_contrib-4.10.0.zip /q\necho.\n\necho Done with downloading and extracting sources.\necho.\n\n@echo on\n\ncd /D C:\\opencv\\build\nset PATH=%PATH%;C:\\Program Files (x86)\\CMake\\bin;C:\\mingw-w64\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\mingw64\\bin\nif [%1]==[static] (\n  echo Build static opencv\n  set enable_shared=OFF\n) else (\n  set enable_shared=ON\n)\ncmake C:\\opencv\\opencv-4.10.0 -G \"MinGW Makefiles\" -BC:\\opencv\\build -DENABLE_CXX11=ON -DOPENCV_EXTRA_MODULES_PATH=C:\\opencv\\opencv_contrib-4.10.0\\modules -DBUILD_SHARED_LIBS=%enable_shared% -DWITH_IPP=OFF -DWITH_MSMF=OFF -DBUILD_EXAMPLES=OFF -DBUILD_TESTS=OFF -DBUILD_PERF_TESTS=ON -DBUILD_opencv_java=OFF -DBUILD_opencv_python=OFF -DBUILD_opencv_python2=OFF -DBUILD_opencv_python3=OFF -DBUILD_DOCS=OFF -DENABLE_PRECOMPILED_HEADERS=OFF -DBUILD_opencv_saliency=OFF -DBUILD_opencv_wechat_qrcode=ON -DCPU_DISPATCH= -DOPENCV_GENERATE_PKGCONFIG=ON -DWITH_OPENCL_D3D11_NV=OFF -DOPENCV_ALLOCATOR_STATS_COUNTER_TYPE=int64_t -Wno-dev\nmingw32-make -j%NUMBER_OF_PROCESSORS%\nmingw32-make install\nrmdir c:\\opencv\\opencv-4.10.0 /s /q\nrmdir c:\\opencv\\opencv_contrib-4.10.0 /s /q\nchdir /D %GOPATH%\\src\\gocv.io\\x\\gocv\n"
        }
      ]
    }
  ]
}