{
  "metadata": {
    "timestamp": 1736567720832,
    "page": 307,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "dgraph-io/ristretto",
      "stars": 5785,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0185546875,
          "content": "# IDE\n.idea\n.vscode"
        },
        {
          "name": ".golangci.yml",
          "type": "blob",
          "size": 0.494140625,
          "content": "run:\n  skip-dirs:\n  skip-files:\n\nlinters-settings:\n  lll:\n    line-length: 120\n  staticcheck:\n    checks:\n      - all\n      - '-SA1019' # it is okay to use math/rand at times.\n  gosec:\n    excludes:\n      - G404  # it is okay to use math/rand at times.\n      - G115  # presents false positives for conversion\n\nlinters:\n  disable-all: true\n  enable:\n    - errcheck\n    - gofmt\n    - goimports\n    - gosec\n    - gosimple\n    - govet\n    - ineffassign\n    - lll\n    - staticcheck\n    - unconvert\n    - unused\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 10.7880859375,
          "content": "# Changelog\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](http://keepachangelog.com/en/1.0.0/)\nand this project will adhere to [Semantic Versioning](http://semver.org/spec/v2.0.0.html) starting v1.0.0.\n\n\n## [v2.0.1] - 2024-12-11\n\n### Fixed\n\n- Wait for goroutines to finish (#423)\n- Bump golang.org/x/sys from 0.27.0 to 0.28.0 in the minor group (#421)\n- Bump github.com/stretchr/testify from 1.9.0 to 1.10.0 in the minor group (#420)\n- Bump golang.org/x/sys from 0.26.0 to 0.27.0 in the minor group (#419)\n\n**Full Changelog**: https://github.com/dgraph-io/ristretto/compare/v2.0.0...v2.0.1\n\n\n## [v2.0.0] - 2024-11-11\n\n### Breaking\n\n- [Support generic API](https://github.com/dgraph-io/ristretto/pull/321)\n- [Restrict generic key type to only those supported](https://github.com/dgraph-io/ristretto/pull/371)\n\n### Added\n\n- [Fix build with GOOS=js GOARCH=wasm](https://github.com/dgraph-io/ristretto/pull/375)\n\n### Fixed\n\n- [Disable mmap size check on arm arch as well as arm64](https://github.com/dgraph-io/ristretto/pull/366)\n- [Upgrade xxhash dependency to v2.2.0](https://github.com/dgraph-io/ristretto/pull/367)\n- [fix: race in close](https://github.com/dgraph-io/ristretto/pull/384)\n- [Fix some memory leaks in TTL implementation](https://github.com/dgraph-io/ristretto/pull/358)\n- [stop using rand.Seed()](https://github.com/dgraph-io/ristretto/pull/385)\n- [chore(deps): bump the actions group with 4 updates](https://github.com/dgraph-io/ristretto/pull/392)\n- [chore(deps): bump the minor group with 3 updates](https://github.com/dgraph-io/ristretto/pull/391)\n- [chore(deps): bump golang.org/x/sys from 0.25.0 to 0.26.0 in the minor group](https://github.com/dgraph-io/ristretto/pull/402)\n- [Remove the policy interface](https://github.com/dgraph-io/ristretto/pull/393)\n- [Perform validation to ensure that the three parameters, NumCounters, â€¦](https://github.com/dgraph-io/ristretto/pull/410)\n- [set min version to go 1.21 in go.mod](https://github.com/dgraph-io/ristretto/pull/411)\n\n**Full Changelog**: https://github.com/dgraph-io/ristretto/compare/v0.2.0...v2.0.0\n\n\n## [v1.0.0]\n\n**This release is deprecated**\n\n## [v1.0.1]\n\n**This release is deprecated**\n\n## [v0.2.0] - 2024-10-06\n\n### Added\n\n- [fix: support compilation to wasip1 by @achille-roussel](https://github.com/dgraph-io/ristretto/pull/344)\n- [add config for cleanup ticker duration by @singhvikash11](https://github.com/dgraph-io/ristretto/pull/342)\n\n### Fixed\n- [docs(readme): Use new Wait method by @angadn](https://github.com/dgraph-io/ristretto/pull/327)\n- [docs: format example on readme by @rfyiamcool](https://github.com/dgraph-io/ristretto/pull/339)\n- [Fix flakes in TestDropUpdates by @evanj](https://github.com/dgraph-io/ristretto/pull/334)\n- [docs(Cache): document Wait, clarify Get by @evanj](https://github.com/dgraph-io/ristretto/pull/333)\n- [chore: fix typo error by @proost](https://github.com/dgraph-io/ristretto/pull/341)\n- [remove glog dependency by @jhawk28](https://github.com/dgraph-io/ristretto/pull/350)\n- [fix(OnEvict): Set missing Expiration field on evicted items by @0x1ee7](https://github.com/dgraph-io/ristretto/pull/345)\n- [uint32 -> uint64 in slice methods by @mocurin](https://github.com/dgraph-io/ristretto/pull/323)\n- [fix: cleanupTicker not being stopped by @IlyaFloppy](https://github.com/dgraph-io/ristretto/pull/343)\n\n**Full Changelog**: https://github.com/dgraph-io/ristretto/compare/v0.1.1...v0.2.0\n\n\n## [0.1.1] - 2022-10-12\n\n[0.1.1]: https://github.com/dgraph-io/ristretto/compare/v0.1.0..v0.1.1\nThis release fixes certain arm64 build issues in the z package.  It also\nincorporates CI steps in our repository.\n\n### Changed\n- [chore(docs): Include SpiceDB in the list of projects using Ristretto (#285)](https://github.com/dgraph-io/ristretto/pull/311)\n\n### Added\n- [Run CI Jobs via Github Actions #304](https://github.com/dgraph-io/ristretto/pull/304)\n\n### Fixed\n- [fix(build): update x/sys dependency](https://github.com/dgraph-io/ristretto/pull/308)\n- [fix(z): Address inconsistent mremap return arguments with arm64](https://github.com/dgraph-io/ristretto/pull/309)\n- [fix(z): runtime error: index out of range for !amd64 env #287](https://github.com/dgraph-io/ristretto/pull/307)\n\n\n## [0.1.0] - 2021-06-03\n\n[0.1.0]: https://github.com/dgraph-io/ristretto/compare/v0.0.3..v0.1.0\nThis release contains bug fixes and improvements to Ristretto. It also contains\nmajor updates to the z package. The z package contains types such as Tree (B+\ntree), Buffer, Mmap file, etc. All these types are used in Badger and Dgraph to\nimprove performance and reduce memory requirements.\n\n### Changed\n- Make item public. Add a new onReject call for rejected items. (#180)\n\n### Added\n- Use z.Buffer backing for B+ tree (#268)\n- expose GetTTL function (#270)\n- docs(README): Ristretto is production-ready. (#267)\n- Add IterateKV (#265)\n- feat(super-flags): Add GetPath method in superflags (#258)\n- add GetDuration to SuperFlag (#248)\n- add Has, GetFloat64, and GetInt64 to SuperFlag (#247)\n- move SuperFlag to Ristretto (#246)\n- add SuperFlagHelp tool to generate flag help text (#251)\n- allow empty defaults in SuperFlag (#254)\n- add mmaped b+ tree (#207)\n- Add API to allow the MaxCost of an existing cache to be updated. (#200)\n- Add OnExit handler which can be used for manual memory management (#183)\n- Add life expectancy histogram (#182)\n- Add mechanism to wait for items to be processed. (#184)\n\n### Fixed\n- change expiration type from int64 to time.Time (#277)\n- fix(buffer): make buffer capacity atleast defaultCapacity (#273)\n- Fixes for z.PersistentTree (#272)\n- Initialize persistent tree correctly (#271)\n- use xxhash v2 (#266)\n- update comments to correctly reflect counter space usage (#189)\n- enable riscv64 builds (#264)\n- Switch from log to glog (#263)\n- Use Fibonacci for latency numbers\n- cache: fix race when clearning a cache (#261)\n- Check for keys without values in superflags (#259)\n- chore(perf): using tags instead of runtime callers to improve the performance of leak detection (#255)\n- fix(Flags): panic on user errors (#256)\n- fix SuperFlagHelp newline (#252)\n- fix(arm): Fix crashing under ARMv6 due to memory mis-alignment (#239)\n- Fix incorrect unit test coverage depiction (#245)\n- chore(histogram): adding percentile in histogram (#241)\n- fix(windows): use filepath instead of path (#244)\n- fix(MmapFile): Close the fd before deleting the file (#242)\n- Fixes CGO_ENABLED=0 compilation error (#240)\n- fix(build): fix build on non-amd64 architectures (#238)\n- fix(b+tree): Do not double the size of btree (#237)\n- fix(jemalloc): Fix the stats of jemalloc (#236)\n- Don't print stuff, only return strings.\n- Bring memclrNoHeapPointers to z (#235)\n- increase number of buffers from 32 to 64 in allocator (#234)\n- Set minSize to 1MB.\n- Opt(btree): Use Go memory instead of mmap files\n- Opt(btree): Lightweight stats calculation\n- Put padding internally to z.Buffer\n- Chore(z): Add SetTmpDir API to set the temp directory (#233)\n- Add a BufferFrom\n- Bring z.Allocator and z.AllocatorPool back\n- Fix(z.Allocator): Make Allocator use Go memory\n- Updated ZeroOut to use a simple for loop.  (#231)\n- Add concurrency back\n- Add a test to check concurrency of Allocator.\n- Fix(buffer): Expose padding by z.Buffer's APIs and fix test (#222)\n- AllocateSlice should Truncate if the file is not big enough (#226)\n- Zero out allocations for structs now that we're reusing Allocators.\n- Fix the ristretto substring\n- Deal with nil z.AllocatorPool\n- Create an AllocatorPool class.\n- chore(btree): clean NewTree API (#225)\n- fix(MmapFile): Don't error out if fileSize > sz (#224)\n- feat(btree): allow option to reset btree and mmaping it to specified file. (#223)\n- Use mremap on Linux instead of munmap+mmap (#221)\n- Reuse pages in B+ tree (#220)\n- fix(allocator): make nil allocator return go byte slice (#217)\n- fix(buffer): Make padding internal to z.buffer (#216)\n- chore(buffer): add a parent directory field in z.Buffer (#215)\n- Make Allocator concurrent\n- Fix infinite loop in allocator (#214)\n- Add trim func\n- Use allocator pool. Turn off freelist.\n- Add freelists to Allocator to reuse.\n- make DeleteBelow delete values that are less than lo (#211)\n- Avoid an unnecessary Load procedure in IncrementOffset.\n- Add Stats method in Btree.\n- chore(script): fix local test script (#210)\n- fix(btree): Increase buffer size if needed. (#209)\n- chore(btree): add occupancy ratio, search benchmark and compact bug fix (#208)\n- Add licenses, remove prints, and fix a bug in compact\n- Add IncrementOffset API for z.buffers (#206)\n- Show count when printing histogram (#201)\n- Zbuffer: Add LenNoPadding and make padding 8 bytes (#204)\n- Allocate Go memory in case allocator is nil.\n- Add leak detection via leak build flag and fix a leak during cache.Close.\n- Add some APIs for allocator and buffer\n- Sync before truncation or close.\n- Handle nil MmapFile for Sync.\n- Public methods must not panic after Close() (#202)\n- Check for RD_ONLY correctly.\n- Modify MmapFile APIs\n- Add a bunch of APIs around MmapFile\n- Move APIs for mmapfile creation over to z package.\n- Add ZeroOut func\n- Add SliceOffsets\n- z: Add TotalSize method on bloom filter (#197)\n- Add Msync func\n- Buffer: Use 256 GB mmap size instead of MaxInt64 (#198)\n- Add a simple test to check next2Pow\n- Improve memory performance (#195)\n- Have a way to automatically mmap a growing buffer (#196)\n- Introduce Mmapped buffers and Merge Sort (#194)\n- Add a way to access an allocator via reference.\n- Use jemalloc.a to ensure compilation with the Go binary\n- Fix up a build issue with ReadMemStats\n- Add ReadMemStats function (#193)\n- Allocator helps allocate memory to be used by unsafe structs (#192)\n- Improve histogram output\n- Move Closer from y to z (#191)\n- Add histogram.Mean() method (#188)\n- Introduce Calloc: Manual Memory Management via jemalloc (#186)\n\n\n## [0.0.3] - 2020-07-06\n\n[0.0.3]: https://github.com/dgraph-io/ristretto/compare/v0.0.2..v0.0.3\n\n### Changed\n\n### Added\n\n### Fixed\n\n- z: use MemHashString and xxhash.Sum64String ([#153][])\n- Check conflict key before updating expiration map. ([#154][])\n- Fix race condition in Cache.Clear ([#133][])\n- Improve handling of updated items ([#168][])\n- Fix droppedSets count while updating the item ([#171][])\n\n\n## [0.0.2] - 2020-02-24\n\n[0.0.2]: https://github.com/dgraph-io/ristretto/compare/v0.0.1..v0.0.2\n\n### Added\n\n- Sets with TTL. ([#122][])\n\n### Fixed\n\n- Fix the way metrics are handled for deletions. ([#111][])\n- Support nil `*Cache` values in `Clear` and `Close`. ([#119][])\n- Delete item immediately. ([#113][])\n- Remove key from policy after TTL eviction. ([#130][])\n\n[#111]: https://github.com/dgraph-io/ristretto/issues/111\n[#113]: https://github.com/dgraph-io/ristretto/issues/113\n[#119]: https://github.com/dgraph-io/ristretto/issues/119\n[#122]: https://github.com/dgraph-io/ristretto/issues/122\n[#130]: https://github.com/dgraph-io/ristretto/issues/130\n\n\n## 0.0.1\n\nFirst release. Basic cache functionality based on a LFU policy.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 9.9345703125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 6.4150390625,
          "content": "# Ristretto\n[![Go Doc](https://img.shields.io/badge/godoc-reference-blue.svg)](https://pkg.go.dev/github.com/dgraph-io/ristretto/v2)\n[![ci-ristretto-tests](https://github.com/dgraph-io/ristretto/actions/workflows/ci-ristretto-tests.yml/badge.svg)](https://github.com/dgraph-io/ristretto/actions/workflows/ci-ristretto-tests.yml)\n[![ci-ristretto-lint](https://github.com/dgraph-io/ristretto/actions/workflows/ci-ristretto-lint.yml/badge.svg)](https://github.com/dgraph-io/ristretto/actions/workflows/ci-ristretto-lint.yml)\n[![Coverage Status](https://coveralls.io/repos/github/dgraph-io/ristretto/badge.svg?branch=main)](https://coveralls.io/github/dgraph-io/ristretto?branch=main)\n[![Go Report Card](https://img.shields.io/badge/go%20report-A%2B-brightgreen)](https://goreportcard.com/report/github.com/dgraph-io/ristretto)\n\nRistretto is a fast, concurrent cache library built with a focus on performance and correctness.\n\nThe motivation to build Ristretto comes from the need for a contention-free cache in [Dgraph][].\n\n[Dgraph]: https://github.com/dgraph-io/dgraph\n\n\n## Features\n\n* **High Hit Ratios** - with our unique admission/eviction policy pairing, Ristretto's performance is best in class.\n\t* **Eviction: SampledLFU** - on par with exact LRU and better performance on Search and Database traces.\n\t* **Admission: TinyLFU** - extra performance with little memory overhead (12 bits per counter).\n* **Fast Throughput** - we use a variety of techniques for managing contention and the result is excellent throughput.\n* **Cost-Based Eviction** - any large new item deemed valuable can evict multiple smaller items (cost could be anything).\n* **Fully Concurrent** - you can use as many goroutines as you want with little throughput degradation.\n* **Metrics** - optional performance metrics for throughput, hit ratios, and other stats.\n* **Simple API** - just figure out your ideal `Config` values and you're off and running.\n\n\n## Status\n\nRistretto is production-ready. See [Projects using Ristretto](#projects-using-ristretto).\n\n## Getting Started\n\n### Installing\nTo start using Ristretto, install Go 1.21 or above. Ristretto needs go modules. From your project, run the following command\n\n```sh\n$ go get github.com/dgraph-io/ristretto/v2\n```\nThis will retrieve the library.\n\n#### Choosing a version\n\nFollowing these rules:\n\n- v1.x.x is the first version used in most programs with Ristretto dependencies.\n- v2.x.x is the new version with support for generics, for which it has a slightly different interface. \nThis version is designed to solve compatibility problems of programs using the old version of Ristretto. If you start writing a new program, it is recommended to use this version.\n\n## Usage\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/dgraph-io/ristretto/v2\"\n)\n\nfunc main() {\n\tcache, err := ristretto.NewCache(&ristretto.Config[string, string]{\n\t\tNumCounters: 1e7,     // number of keys to track frequency of (10M).\n\t\tMaxCost:     1 << 30, // maximum cost of cache (1GB).\n\t\tBufferItems: 64,      // number of keys per Get buffer.\n\t})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer cache.Close()\n\n\t// set a value with a cost of 1\n\tcache.Set(\"key\", \"value\", 1)\n\n\t// wait for value to pass through buffers\n\tcache.Wait()\n\n\t// get value from cache\n\tvalue, found := cache.Get(\"key\")\n\tif !found {\n\t\tpanic(\"missing value\")\n\t}\n\tfmt.Println(value)\n\n\t// del value from cache\n\tcache.Del(\"key\")\n}\n```\n\n\n## Benchmarks\n\nThe benchmarks can be found in https://github.com/dgraph-io/benchmarks/tree/master/cachebench/ristretto.\n\n### Hit Ratios for Search\n\nThis trace is described as \"disk read accesses initiated by a large commercial\nsearch engine in response to various web search requests.\"\n\n<p align=\"center\">\n\t<img src=\"https://raw.githubusercontent.com/dgraph-io/ristretto/master/benchmarks/Hit%20Ratios%20-%20Search%20(ARC-S3).svg\">\n</p>\n\n### Hit Ratio for Database\n\nThis trace is described as \"a database server running at a commercial site\nrunning an ERP application on top of a commercial database.\"\n\n<p align=\"center\">\n\t<img src=\"https://raw.githubusercontent.com/dgraph-io/ristretto/master/benchmarks/Hit%20Ratios%20-%20Database%20(ARC-DS1).svg\">\n</p>\n\n### Hit Ratio for Looping\n\nThis trace demonstrates a looping access pattern.\n\n<p align=\"center\">\n\t<img src=\"https://raw.githubusercontent.com/dgraph-io/ristretto/master/benchmarks/Hit%20Ratios%20-%20Glimpse%20(LIRS-GLI).svg\">\n</p>\n\n### Hit Ratio for CODASYL\n\nThis trace is described as \"references to a CODASYL database for a one hour period.\"\n\n<p align=\"center\">\n\t<img src=\"https://raw.githubusercontent.com/dgraph-io/ristretto/master/benchmarks/Hit%20Ratios%20-%20CODASYL%20(ARC-OLTP).svg\">\n</p>\n\n### Throughput for Mixed Workload\n\n<p align=\"center\">\n\t<img src=\"https://raw.githubusercontent.com/dgraph-io/ristretto/master/benchmarks/Throughput%20-%20Mixed.svg\">\n</p>\n\n### Throughput ffor Read Workload\n\n<p align=\"center\">\n\t<img src=\"https://raw.githubusercontent.com/dgraph-io/ristretto/master/benchmarks/Throughput%20-%20Read%20(Zipfian).svg\">\n</p>\n\n### Through for Write Workload\n\n<p align=\"center\">\n\t<img src=\"https://raw.githubusercontent.com/dgraph-io/ristretto/master/benchmarks/Throughput%20-%20Write%20(Zipfian).svg\">\n</p>\n\n\n## Projects Using Ristretto\n\nBelow is a list of known projects that use Ristretto:\n\n- [Badger](https://github.com/dgraph-io/badger) - Embeddable key-value DB in Go\n- [Dgraph](https://github.com/dgraph-io/dgraph) - Horizontally scalable and distributed GraphQL database with a graph backend\n\n\n## FAQ\n\n### How are you achieving this performance? What shortcuts are you taking?\n\nWe go into detail in the [Ristretto blog post](https://blog.dgraph.io/post/introducing-ristretto-high-perf-go-cache/),\nbut in short: our throughput performance can be attributed to a mix of batching and eventual consistency. Our hit ratio\nperformance is mostly due to an excellent [admission policy](https://arxiv.org/abs/1512.00727) and SampledLFU eviction policy.\n\nAs for \"shortcuts,\" the only thing Ristretto does that could be construed as one is dropping some Set calls. That means\na Set call for a new item (updates are guaranteed) isn't guaranteed to make it into the cache. The new item could be\ndropped at two points: when passing through the Set buffer or when passing through the admission policy. However, this\ndoesn't affect hit ratios much at all as we expect the most popular items to be Set multiple times and eventually make\nit in the cache.\n\n### Is Ristretto distributed?\n\nNo, it's just like any other Go library that you can import into your project and use in a single process.\n"
        },
        {
          "name": "benchmarks",
          "type": "tree",
          "content": null
        },
        {
          "name": "cache.go",
          "type": "blob",
          "size": 23.248046875,
          "content": "/*\n * Copyright 2019 Dgraph Labs, Inc. and Contributors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n// Ristretto is a fast, fixed size, in-memory cache with a dual focus on\n// throughput and hit ratio performance. You can easily add Ristretto to an\n// existing system and keep the most valuable data where you need it.\npackage ristretto\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\t\"unsafe\"\n\n\t\"github.com/dgraph-io/ristretto/v2/z\"\n)\n\nvar (\n\t// TODO: find the optimal value for this or make it configurable\n\tsetBufSize = 32 * 1024\n)\n\nconst itemSize = int64(unsafe.Sizeof(storeItem[any]{}))\n\nfunc zeroValue[T any]() T {\n\tvar zero T\n\treturn zero\n}\n\n// Key is the generic type to represent the keys type in key-value pair of the cache.\ntype Key = z.Key\n\n// Cache is a thread-safe implementation of a hashmap with a TinyLFU admission\n// policy and a Sampled LFU eviction policy. You can use the same Cache instance\n// from as many goroutines as you want.\ntype Cache[K Key, V any] struct {\n\t// storedItems is the central concurrent hashmap where key-value items are stored.\n\tstoredItems store[V]\n\t// cachePolicy determines what gets let in to the cache and what gets kicked out.\n\tcachePolicy *defaultPolicy[V]\n\t// getBuf is a custom ring buffer implementation that gets pushed to when\n\t// keys are read.\n\tgetBuf *ringBuffer\n\t// setBuf is a buffer allowing us to batch/drop Sets during times of high\n\t// contention.\n\tsetBuf chan *Item[V]\n\t// onEvict is called for item evictions.\n\tonEvict func(*Item[V])\n\t// onReject is called when an item is rejected via admission policy.\n\tonReject func(*Item[V])\n\t// onExit is called whenever a value goes out of scope from the cache.\n\tonExit (func(V))\n\t// KeyToHash function is used to customize the key hashing algorithm.\n\t// Each key will be hashed using the provided function. If keyToHash value\n\t// is not set, the default keyToHash function is used.\n\tkeyToHash func(K) (uint64, uint64)\n\t// stop is used to stop the processItems goroutine.\n\tstop chan struct{}\n\tdone chan struct{}\n\t// indicates whether cache is closed.\n\tisClosed atomic.Bool\n\t// cost calculates cost from a value.\n\tcost func(value V) int64\n\t// ignoreInternalCost dictates whether to ignore the cost of internally storing\n\t// the item in the cost calculation.\n\tignoreInternalCost bool\n\t// cleanupTicker is used to periodically check for entries whose TTL has passed.\n\tcleanupTicker *time.Ticker\n\t// Metrics contains a running log of important statistics like hits, misses,\n\t// and dropped items.\n\tMetrics *Metrics\n}\n\n// Config is passed to NewCache for creating new Cache instances.\ntype Config[K Key, V any] struct {\n\t// NumCounters determines the number of counters (keys) to keep that hold\n\t// access frequency information. It's generally a good idea to have more\n\t// counters than the max cache capacity, as this will improve eviction\n\t// accuracy and subsequent hit ratios.\n\t//\n\t// For example, if you expect your cache to hold 1,000,000 items when full,\n\t// NumCounters should be 10,000,000 (10x). Each counter takes up roughly\n\t// 3 bytes (4 bits for each counter * 4 copies plus about a byte per\n\t// counter for the bloom filter). Note that the number of counters is\n\t// internally rounded up to the nearest power of 2, so the space usage\n\t// may be a little larger than 3 bytes * NumCounters.\n\t//\n\t// We've seen good performance in setting this to 10x the number of items\n\t// you expect to keep in the cache when full.\n\tNumCounters int64\n\n\t// MaxCost is how eviction decisions are made. For example, if MaxCost is\n\t// 100 and a new item with a cost of 1 increases total cache cost to 101,\n\t// 1 item will be evicted.\n\t//\n\t// MaxCost can be considered as the cache capacity, in whatever units you\n\t// choose to use.\n\t//\n\t// For example, if you want the cache to have a max capacity of 100MB, you\n\t// would set MaxCost to 100,000,000 and pass an item's number of bytes as\n\t// the `cost` parameter for calls to Set. If new items are accepted, the\n\t// eviction process will take care of making room for the new item and not\n\t// overflowing the MaxCost value.\n\t//\n\t// MaxCost could be anything as long as it matches how you're using the cost\n\t// values when calling Set.\n\tMaxCost int64\n\n\t// BufferItems determines the size of Get buffers.\n\t//\n\t// Unless you have a rare use case, using `64` as the BufferItems value\n\t// results in good performance.\n\t//\n\t// If for some reason you see Get performance decreasing with lots of\n\t// contention (you shouldn't), try increasing this value in increments of 64.\n\t// This is a fine-tuning mechanism and you probably won't have to touch this.\n\tBufferItems int64\n\n\t// Metrics is true when you want variety of stats about the cache.\n\t// There is some overhead to keeping statistics, so you should only set this\n\t// flag to true when testing or throughput performance isn't a major factor.\n\tMetrics bool\n\n\t// OnEvict is called for every eviction with the evicted item.\n\tOnEvict func(item *Item[V])\n\n\t// OnReject is called for every rejection done via the policy.\n\tOnReject func(item *Item[V])\n\n\t// OnExit is called whenever a value is removed from cache. This can be\n\t// used to do manual memory deallocation. Would also be called on eviction\n\t// as well as on rejection of the value.\n\tOnExit func(val V)\n\n\t// ShouldUpdate is called when a value already exists in cache and is being updated.\n\t// If ShouldUpdate returns true, the cache continues with the update (Set). If the\n\t// function returns false, no changes are made in the cache. If the value doesn't\n\t// already exist, the cache continue with setting that value for the given key.\n\t//\n\t// In this function, you can check whether the new value is valid. For example, if\n\t// your value has timestamp assosicated with it, you could check whether the new\n\t// value has the latest timestamp, preventing you from setting an older value.\n\tShouldUpdate func(cur, prev V) bool\n\n\t// KeyToHash function is used to customize the key hashing algorithm.\n\t// Each key will be hashed using the provided function. If keyToHash value\n\t// is not set, the default keyToHash function is used.\n\t//\n\t// Ristretto has a variety of defaults depending on the underlying interface type\n\t// https://github.com/dgraph-io/ristretto/blob/master/z/z.go#L19-L41).\n\t//\n\t// Note that if you want 128bit hashes you should use the both the values\n\t// in the return of the function. If you want to use 64bit hashes, you can\n\t// just return the first uint64 and return 0 for the second uint64.\n\tKeyToHash func(key K) (uint64, uint64)\n\n\t// Cost evaluates a value and outputs a corresponding cost. This function is ran\n\t// after Set is called for a new item or an item is updated with a cost param of 0.\n\t//\n\t// Cost is an optional function you can pass to the Config in order to evaluate\n\t// item cost at runtime, and only whentthe Set call isn't going to be dropped. This\n\t// is useful if calculating item cost is particularly expensive and you don't want to\n\t// waste time on items that will be dropped anyways.\n\t//\n\t// To signal to Ristretto that you'd like to use this Cost function:\n\t//   1. Set the Cost field to a non-nil function.\n\t//   2. When calling Set for new items or item updates, use a `cost` of 0.\n\tCost func(value V) int64\n\n\t// IgnoreInternalCost set to true indicates to the cache that the cost of\n\t// internally storing the value should be ignored. This is useful when the\n\t// cost passed to set is not using bytes as units. Keep in mind that setting\n\t// this to true will increase the memory usage.\n\tIgnoreInternalCost bool\n\n\t// TtlTickerDurationInSec sets the value of time ticker for cleanup keys on TTL expiry.\n\tTtlTickerDurationInSec int64\n}\n\ntype itemFlag byte\n\nconst (\n\titemNew itemFlag = iota\n\titemDelete\n\titemUpdate\n)\n\n// Item is a full representation of what's stored in the cache for each key-value pair.\ntype Item[V any] struct {\n\tflag       itemFlag\n\tKey        uint64\n\tConflict   uint64\n\tValue      V\n\tCost       int64\n\tExpiration time.Time\n\twg         *sync.WaitGroup\n}\n\n// NewCache returns a new Cache instance and any configuration errors, if any.\nfunc NewCache[K Key, V any](config *Config[K, V]) (*Cache[K, V], error) {\n\tswitch {\n\tcase config.NumCounters == 0:\n\t\treturn nil, errors.New(\"NumCounters can't be zero\")\n\tcase config.NumCounters < 0:\n\t\treturn nil, errors.New(\"NumCounters can't be negative number\")\n\tcase config.MaxCost == 0:\n\t\treturn nil, errors.New(\"MaxCost can't be zero\")\n\tcase config.MaxCost < 0:\n\t\treturn nil, errors.New(\"MaxCost can't be be negative number\")\n\tcase config.BufferItems == 0:\n\t\treturn nil, errors.New(\"BufferItems can't be zero\")\n\tcase config.BufferItems < 0:\n\t\treturn nil, errors.New(\"BufferItems can't be be negative number\")\n\tcase config.TtlTickerDurationInSec == 0:\n\t\tconfig.TtlTickerDurationInSec = bucketDurationSecs\n\t}\n\tpolicy := newPolicy[V](config.NumCounters, config.MaxCost)\n\tcache := &Cache[K, V]{\n\t\tstoredItems:        newStore[V](),\n\t\tcachePolicy:        policy,\n\t\tgetBuf:             newRingBuffer(policy, config.BufferItems),\n\t\tsetBuf:             make(chan *Item[V], setBufSize),\n\t\tkeyToHash:          config.KeyToHash,\n\t\tstop:               make(chan struct{}),\n\t\tdone:               make(chan struct{}),\n\t\tcost:               config.Cost,\n\t\tignoreInternalCost: config.IgnoreInternalCost,\n\t\tcleanupTicker:      time.NewTicker(time.Duration(config.TtlTickerDurationInSec) * time.Second / 2),\n\t}\n\tcache.storedItems.SetShouldUpdateFn(config.ShouldUpdate)\n\tcache.onExit = func(val V) {\n\t\tif config.OnExit != nil {\n\t\t\tconfig.OnExit(val)\n\t\t}\n\t}\n\tcache.onEvict = func(item *Item[V]) {\n\t\tif config.OnEvict != nil {\n\t\t\tconfig.OnEvict(item)\n\t\t}\n\t\tcache.onExit(item.Value)\n\t}\n\tcache.onReject = func(item *Item[V]) {\n\t\tif config.OnReject != nil {\n\t\t\tconfig.OnReject(item)\n\t\t}\n\t\tcache.onExit(item.Value)\n\t}\n\tif cache.keyToHash == nil {\n\t\tcache.keyToHash = z.KeyToHash[K]\n\t}\n\n\tif config.Metrics {\n\t\tcache.collectMetrics()\n\t}\n\t// NOTE: benchmarks seem to show that performance decreases the more\n\t//       goroutines we have running cache.processItems(), so 1 should\n\t//       usually be sufficient\n\tgo cache.processItems()\n\treturn cache, nil\n}\n\n// Wait blocks until all buffered writes have been applied. This ensures a call to Set()\n// will be visible to future calls to Get().\nfunc (c *Cache[K, V]) Wait() {\n\tif c == nil || c.isClosed.Load() {\n\t\treturn\n\t}\n\twg := &sync.WaitGroup{}\n\twg.Add(1)\n\tc.setBuf <- &Item[V]{wg: wg}\n\twg.Wait()\n}\n\n// Get returns the value (if any) and a boolean representing whether the\n// value was found or not. The value can be nil and the boolean can be true at\n// the same time. Get will not return expired items.\nfunc (c *Cache[K, V]) Get(key K) (V, bool) {\n\tif c == nil || c.isClosed.Load() {\n\t\treturn zeroValue[V](), false\n\t}\n\tkeyHash, conflictHash := c.keyToHash(key)\n\n\tc.getBuf.Push(keyHash)\n\tvalue, ok := c.storedItems.Get(keyHash, conflictHash)\n\tif ok {\n\t\tc.Metrics.add(hit, keyHash, 1)\n\t} else {\n\t\tc.Metrics.add(miss, keyHash, 1)\n\t}\n\treturn value, ok\n}\n\n// Set attempts to add the key-value item to the cache. If it returns false,\n// then the Set was dropped and the key-value item isn't added to the cache. If\n// it returns true, there's still a chance it could be dropped by the policy if\n// its determined that the key-value item isn't worth keeping, but otherwise the\n// item will be added and other items will be evicted in order to make room.\n//\n// To dynamically evaluate the items cost using the Config.Coster function, set\n// the cost parameter to 0 and Coster will be ran when needed in order to find\n// the items true cost.\n//\n// Set writes the value of type V as is. If type V is a pointer type, It is ok\n// to update the memory pointed to by the pointer. Updating the pointer itself\n// will not be reflected in the cache. Be careful when using slice types as the\n// value type V. Calling `append` may update the underlined array pointer which\n// will not be reflected in the cache.\nfunc (c *Cache[K, V]) Set(key K, value V, cost int64) bool {\n\treturn c.SetWithTTL(key, value, cost, 0*time.Second)\n}\n\n// SetWithTTL works like Set but adds a key-value pair to the cache that will expire\n// after the specified TTL (time to live) has passed. A zero value means the value never\n// expires, which is identical to calling Set. A negative value is a no-op and the value\n// is discarded.\n//\n// See Set for more information.\nfunc (c *Cache[K, V]) SetWithTTL(key K, value V, cost int64, ttl time.Duration) bool {\n\tif c == nil || c.isClosed.Load() {\n\t\treturn false\n\t}\n\n\tvar expiration time.Time\n\tswitch {\n\tcase ttl == 0:\n\t\t// No expiration.\n\t\tbreak\n\tcase ttl < 0:\n\t\t// Treat this a no-op.\n\t\treturn false\n\tdefault:\n\t\texpiration = time.Now().Add(ttl)\n\t}\n\n\tkeyHash, conflictHash := c.keyToHash(key)\n\ti := &Item[V]{\n\t\tflag:       itemNew,\n\t\tKey:        keyHash,\n\t\tConflict:   conflictHash,\n\t\tValue:      value,\n\t\tCost:       cost,\n\t\tExpiration: expiration,\n\t}\n\t// cost is eventually updated. The expiration must also be immediately updated\n\t// to prevent items from being prematurely removed from the map.\n\tif prev, ok := c.storedItems.Update(i); ok {\n\t\tc.onExit(prev)\n\t\ti.flag = itemUpdate\n\t}\n\t// Attempt to send item to cachePolicy.\n\tselect {\n\tcase c.setBuf <- i:\n\t\treturn true\n\tdefault:\n\t\tif i.flag == itemUpdate {\n\t\t\t// Return true if this was an update operation since we've already\n\t\t\t// updated the storedItems. For all the other operations (set/delete), we\n\t\t\t// return false which means the item was not inserted.\n\t\t\treturn true\n\t\t}\n\t\tc.Metrics.add(dropSets, keyHash, 1)\n\t\treturn false\n\t}\n}\n\n// Del deletes the key-value item from the cache if it exists.\nfunc (c *Cache[K, V]) Del(key K) {\n\tif c == nil || c.isClosed.Load() {\n\t\treturn\n\t}\n\tkeyHash, conflictHash := c.keyToHash(key)\n\t// Delete immediately.\n\t_, prev := c.storedItems.Del(keyHash, conflictHash)\n\tc.onExit(prev)\n\t// If we've set an item, it would be applied slightly later.\n\t// So we must push the same item to `setBuf` with the deletion flag.\n\t// This ensures that if a set is followed by a delete, it will be\n\t// applied in the correct order.\n\tc.setBuf <- &Item[V]{\n\t\tflag:     itemDelete,\n\t\tKey:      keyHash,\n\t\tConflict: conflictHash,\n\t}\n}\n\n// GetTTL returns the TTL for the specified key and a bool that is true if the\n// item was found and is not expired.\nfunc (c *Cache[K, V]) GetTTL(key K) (time.Duration, bool) {\n\tif c == nil {\n\t\treturn 0, false\n\t}\n\n\tkeyHash, conflictHash := c.keyToHash(key)\n\tif _, ok := c.storedItems.Get(keyHash, conflictHash); !ok {\n\t\t// not found\n\t\treturn 0, false\n\t}\n\n\texpiration := c.storedItems.Expiration(keyHash)\n\tif expiration.IsZero() {\n\t\t// found but no expiration\n\t\treturn 0, true\n\t}\n\n\tif time.Now().After(expiration) {\n\t\t// found but expired\n\t\treturn 0, false\n\t}\n\n\treturn time.Until(expiration), true\n}\n\n// Close stops all goroutines and closes all channels.\nfunc (c *Cache[K, V]) Close() {\n\tif c == nil || c.isClosed.Load() {\n\t\treturn\n\t}\n\tc.Clear()\n\n\t// Block until processItems goroutine is returned.\n\tc.stop <- struct{}{}\n\t<-c.done\n\tclose(c.stop)\n\tclose(c.done)\n\tclose(c.setBuf)\n\tc.cachePolicy.Close()\n\tc.cleanupTicker.Stop()\n\tc.isClosed.Store(true)\n}\n\n// Clear empties the hashmap and zeroes all cachePolicy counters. Note that this is\n// not an atomic operation (but that shouldn't be a problem as it's assumed that\n// Set/Get calls won't be occurring until after this).\nfunc (c *Cache[K, V]) Clear() {\n\tif c == nil || c.isClosed.Load() {\n\t\treturn\n\t}\n\t// Block until processItems goroutine is returned.\n\tc.stop <- struct{}{}\n\t<-c.done\n\n\t// Clear out the setBuf channel.\nloop:\n\tfor {\n\t\tselect {\n\t\tcase i := <-c.setBuf:\n\t\t\tif i.wg != nil {\n\t\t\t\ti.wg.Done()\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif i.flag != itemUpdate {\n\t\t\t\t// In itemUpdate, the value is already set in the storedItems.  So, no need to call\n\t\t\t\t// onEvict here.\n\t\t\t\tc.onEvict(i)\n\t\t\t}\n\t\tdefault:\n\t\t\tbreak loop\n\t\t}\n\t}\n\n\t// Clear value hashmap and cachePolicy data.\n\tc.cachePolicy.Clear()\n\tc.storedItems.Clear(c.onEvict)\n\t// Only reset metrics if they're enabled.\n\tif c.Metrics != nil {\n\t\tc.Metrics.Clear()\n\t}\n\t// Restart processItems goroutine.\n\tgo c.processItems()\n}\n\n// MaxCost returns the max cost of the cache.\nfunc (c *Cache[K, V]) MaxCost() int64 {\n\tif c == nil {\n\t\treturn 0\n\t}\n\treturn c.cachePolicy.MaxCost()\n}\n\n// UpdateMaxCost updates the maxCost of an existing cache.\nfunc (c *Cache[K, V]) UpdateMaxCost(maxCost int64) {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.cachePolicy.UpdateMaxCost(maxCost)\n}\n\n// processItems is ran by goroutines processing the Set buffer.\nfunc (c *Cache[K, V]) processItems() {\n\tstartTs := make(map[uint64]time.Time)\n\tnumToKeep := 100000 // TODO: Make this configurable via options.\n\n\ttrackAdmission := func(key uint64) {\n\t\tif c.Metrics == nil {\n\t\t\treturn\n\t\t}\n\t\tstartTs[key] = time.Now()\n\t\tif len(startTs) > numToKeep {\n\t\t\tfor k := range startTs {\n\t\t\t\tif len(startTs) <= numToKeep {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\tdelete(startTs, k)\n\t\t\t}\n\t\t}\n\t}\n\tonEvict := func(i *Item[V]) {\n\t\tif ts, has := startTs[i.Key]; has {\n\t\t\tc.Metrics.trackEviction(int64(time.Since(ts) / time.Second))\n\t\t\tdelete(startTs, i.Key)\n\t\t}\n\t\tif c.onEvict != nil {\n\t\t\tc.onEvict(i)\n\t\t}\n\t}\n\n\tfor {\n\t\tselect {\n\t\tcase i := <-c.setBuf:\n\t\t\tif i.wg != nil {\n\t\t\t\ti.wg.Done()\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\t// Calculate item cost value if new or update.\n\t\t\tif i.Cost == 0 && c.cost != nil && i.flag != itemDelete {\n\t\t\t\ti.Cost = c.cost(i.Value)\n\t\t\t}\n\t\t\tif !c.ignoreInternalCost {\n\t\t\t\t// Add the cost of internally storing the object.\n\t\t\t\ti.Cost += itemSize\n\t\t\t}\n\n\t\t\tswitch i.flag {\n\t\t\tcase itemNew:\n\t\t\t\tvictims, added := c.cachePolicy.Add(i.Key, i.Cost)\n\t\t\t\tif added {\n\t\t\t\t\tc.storedItems.Set(i)\n\t\t\t\t\tc.Metrics.add(keyAdd, i.Key, 1)\n\t\t\t\t\ttrackAdmission(i.Key)\n\t\t\t\t} else {\n\t\t\t\t\tc.onReject(i)\n\t\t\t\t}\n\t\t\t\tfor _, victim := range victims {\n\t\t\t\t\tvictim.Conflict, victim.Value = c.storedItems.Del(victim.Key, 0)\n\t\t\t\t\tonEvict(victim)\n\t\t\t\t}\n\n\t\t\tcase itemUpdate:\n\t\t\t\tc.cachePolicy.Update(i.Key, i.Cost)\n\n\t\t\tcase itemDelete:\n\t\t\t\tc.cachePolicy.Del(i.Key) // Deals with metrics updates.\n\t\t\t\t_, val := c.storedItems.Del(i.Key, i.Conflict)\n\t\t\t\tc.onExit(val)\n\t\t\t}\n\t\tcase <-c.cleanupTicker.C:\n\t\t\tc.storedItems.Cleanup(c.cachePolicy, onEvict)\n\t\tcase <-c.stop:\n\t\t\tc.done <- struct{}{}\n\t\t\treturn\n\t\t}\n\t}\n}\n\n// collectMetrics just creates a new *Metrics instance and adds the pointers\n// to the cache and policy instances.\nfunc (c *Cache[K, V]) collectMetrics() {\n\tc.Metrics = newMetrics()\n\tc.cachePolicy.CollectMetrics(c.Metrics)\n}\n\ntype metricType int\n\nconst (\n\t// The following 2 keep track of hits and misses.\n\thit = iota\n\tmiss\n\t// The following 3 keep track of number of keys added, updated and evicted.\n\tkeyAdd\n\tkeyUpdate\n\tkeyEvict\n\t// The following 2 keep track of cost of keys added and evicted.\n\tcostAdd\n\tcostEvict\n\t// The following keep track of how many sets were dropped or rejected later.\n\tdropSets\n\trejectSets\n\t// The following 2 keep track of how many gets were kept and dropped on the\n\t// floor.\n\tdropGets\n\tkeepGets\n\t// This should be the final enum. Other enums should be set before this.\n\tdoNotUse\n)\n\nfunc stringFor(t metricType) string {\n\tswitch t {\n\tcase hit:\n\t\treturn \"hit\"\n\tcase miss:\n\t\treturn \"miss\"\n\tcase keyAdd:\n\t\treturn \"keys-added\"\n\tcase keyUpdate:\n\t\treturn \"keys-updated\"\n\tcase keyEvict:\n\t\treturn \"keys-evicted\"\n\tcase costAdd:\n\t\treturn \"cost-added\"\n\tcase costEvict:\n\t\treturn \"cost-evicted\"\n\tcase dropSets:\n\t\treturn \"sets-dropped\"\n\tcase rejectSets:\n\t\treturn \"sets-rejected\" // by policy.\n\tcase dropGets:\n\t\treturn \"gets-dropped\"\n\tcase keepGets:\n\t\treturn \"gets-kept\"\n\tdefault:\n\t\treturn \"unidentified\"\n\t}\n}\n\n// Metrics is a snapshot of performance statistics for the lifetime of a cache instance.\ntype Metrics struct {\n\tall [doNotUse][]*uint64\n\n\tmu   sync.RWMutex\n\tlife *z.HistogramData // Tracks the life expectancy of a key.\n}\n\nfunc newMetrics() *Metrics {\n\ts := &Metrics{\n\t\tlife: z.NewHistogramData(z.HistogramBounds(1, 16)),\n\t}\n\tfor i := 0; i < doNotUse; i++ {\n\t\ts.all[i] = make([]*uint64, 256)\n\t\tslice := s.all[i]\n\t\tfor j := range slice {\n\t\t\tslice[j] = new(uint64)\n\t\t}\n\t}\n\treturn s\n}\n\nfunc (p *Metrics) add(t metricType, hash, delta uint64) {\n\tif p == nil {\n\t\treturn\n\t}\n\tvalp := p.all[t]\n\t// Avoid false sharing by padding at least 64 bytes of space between two\n\t// atomic counters which would be incremented.\n\tidx := (hash % 25) * 10\n\tatomic.AddUint64(valp[idx], delta)\n}\n\nfunc (p *Metrics) get(t metricType) uint64 {\n\tif p == nil {\n\t\treturn 0\n\t}\n\tvalp := p.all[t]\n\tvar total uint64\n\tfor i := range valp {\n\t\ttotal += atomic.LoadUint64(valp[i])\n\t}\n\treturn total\n}\n\n// Hits is the number of Get calls where a value was found for the corresponding key.\nfunc (p *Metrics) Hits() uint64 {\n\treturn p.get(hit)\n}\n\n// Misses is the number of Get calls where a value was not found for the corresponding key.\nfunc (p *Metrics) Misses() uint64 {\n\treturn p.get(miss)\n}\n\n// KeysAdded is the total number of Set calls where a new key-value item was added.\nfunc (p *Metrics) KeysAdded() uint64 {\n\treturn p.get(keyAdd)\n}\n\n// KeysUpdated is the total number of Set calls where the value was updated.\nfunc (p *Metrics) KeysUpdated() uint64 {\n\treturn p.get(keyUpdate)\n}\n\n// KeysEvicted is the total number of keys evicted.\nfunc (p *Metrics) KeysEvicted() uint64 {\n\treturn p.get(keyEvict)\n}\n\n// CostAdded is the sum of costs that have been added (successful Set calls).\nfunc (p *Metrics) CostAdded() uint64 {\n\treturn p.get(costAdd)\n}\n\n// CostEvicted is the sum of all costs that have been evicted.\nfunc (p *Metrics) CostEvicted() uint64 {\n\treturn p.get(costEvict)\n}\n\n// SetsDropped is the number of Set calls that don't make it into internal\n// buffers (due to contention or some other reason).\nfunc (p *Metrics) SetsDropped() uint64 {\n\treturn p.get(dropSets)\n}\n\n// SetsRejected is the number of Set calls rejected by the policy (TinyLFU).\nfunc (p *Metrics) SetsRejected() uint64 {\n\treturn p.get(rejectSets)\n}\n\n// GetsDropped is the number of Get counter increments that are dropped\n// internally.\nfunc (p *Metrics) GetsDropped() uint64 {\n\treturn p.get(dropGets)\n}\n\n// GetsKept is the number of Get counter increments that are kept.\nfunc (p *Metrics) GetsKept() uint64 {\n\treturn p.get(keepGets)\n}\n\n// Ratio is the number of Hits over all accesses (Hits + Misses). This is the\n// percentage of successful Get calls.\nfunc (p *Metrics) Ratio() float64 {\n\tif p == nil {\n\t\treturn 0.0\n\t}\n\thits, misses := p.get(hit), p.get(miss)\n\tif hits == 0 && misses == 0 {\n\t\treturn 0.0\n\t}\n\treturn float64(hits) / float64(hits+misses)\n}\n\nfunc (p *Metrics) trackEviction(numSeconds int64) {\n\tif p == nil {\n\t\treturn\n\t}\n\tp.mu.Lock()\n\tdefer p.mu.Unlock()\n\tp.life.Update(numSeconds)\n}\n\nfunc (p *Metrics) LifeExpectancySeconds() *z.HistogramData {\n\tif p == nil {\n\t\treturn nil\n\t}\n\tp.mu.RLock()\n\tdefer p.mu.RUnlock()\n\treturn p.life.Copy()\n}\n\n// Clear resets all the metrics.\nfunc (p *Metrics) Clear() {\n\tif p == nil {\n\t\treturn\n\t}\n\tfor i := 0; i < doNotUse; i++ {\n\t\tfor j := range p.all[i] {\n\t\t\tatomic.StoreUint64(p.all[i][j], 0)\n\t\t}\n\t}\n\tp.mu.Lock()\n\tp.life = z.NewHistogramData(z.HistogramBounds(1, 16))\n\tp.mu.Unlock()\n}\n\n// String returns a string representation of the metrics.\nfunc (p *Metrics) String() string {\n\tif p == nil {\n\t\treturn \"\"\n\t}\n\tvar buf bytes.Buffer\n\tfor i := 0; i < doNotUse; i++ {\n\t\tt := metricType(i)\n\t\tfmt.Fprintf(&buf, \"%s: %d \", stringFor(t), p.get(t))\n\t}\n\tfmt.Fprintf(&buf, \"gets-total: %d \", p.get(hit)+p.get(miss))\n\tfmt.Fprintf(&buf, \"hit-ratio: %.2f\", p.Ratio())\n\treturn buf.String()\n}\n"
        },
        {
          "name": "cache_test.go",
          "type": "blob",
          "size": 20.947265625,
          "content": "package ristretto\n\nimport (\n\t\"fmt\"\n\t\"math/rand\"\n\t\"runtime\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/dgraph-io/ristretto/v2/z\"\n\t\"github.com/stretchr/testify/require\"\n)\n\nvar wait = time.Millisecond * 10\n\nfunc TestCacheKeyToHash(t *testing.T) {\n\tkeyToHashCount := 0\n\tc, err := NewCache(&Config[int, int]{\n\t\tNumCounters:        10,\n\t\tMaxCost:            1000,\n\t\tBufferItems:        64,\n\t\tIgnoreInternalCost: true,\n\t\tKeyToHash: func(key int) (uint64, uint64) {\n\t\t\tkeyToHashCount++\n\t\t\treturn z.KeyToHash(key)\n\t\t},\n\t})\n\trequire.NoError(t, err)\n\tif c.Set(1, 1, 1) {\n\t\ttime.Sleep(wait)\n\t\tval, ok := c.Get(1)\n\t\trequire.True(t, ok)\n\t\trequire.NotNil(t, val)\n\t\tc.Del(1)\n\t}\n\trequire.Equal(t, 3, keyToHashCount)\n}\n\nfunc TestCacheMaxCost(t *testing.T) {\n\tcharset := \"abcdefghijklmnopqrstuvwxyz0123456789\"\n\tkey := func() []byte {\n\t\tk := make([]byte, 2)\n\t\tfor i := range k {\n\t\t\tk[i] = charset[rand.Intn(len(charset))]\n\t\t}\n\t\treturn k\n\t}\n\tc, err := NewCache(&Config[[]byte, string]{\n\t\tNumCounters: 12960, // 36^2 * 10\n\t\tMaxCost:     1e6,   // 1mb\n\t\tBufferItems: 64,\n\t\tMetrics:     true,\n\t})\n\trequire.NoError(t, err)\n\tstop := make(chan struct{}, 8)\n\tfor i := 0; i < 8; i++ {\n\t\tgo func() {\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-stop:\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t\ttime.Sleep(time.Millisecond)\n\n\t\t\t\t\tk := key()\n\t\t\t\t\tif _, ok := c.Get(k); !ok {\n\t\t\t\t\t\tval := \"\"\n\t\t\t\t\t\tif rand.Intn(100) < 10 {\n\t\t\t\t\t\t\tval = \"test\"\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tval = strings.Repeat(\"a\", 1000)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tc.Set(key(), val, int64(2+len(val)))\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\tfor i := 0; i < 20; i++ {\n\t\ttime.Sleep(time.Second)\n\t\tcacheCost := c.Metrics.CostAdded() - c.Metrics.CostEvicted()\n\t\tt.Logf(\"total cache cost: %d\\n\", cacheCost)\n\t\trequire.True(t, float64(cacheCost) <= float64(1e6*1.05))\n\t}\n\tfor i := 0; i < 8; i++ {\n\t\tstop <- struct{}{}\n\t}\n}\n\nfunc TestUpdateMaxCost(t *testing.T) {\n\tc, err := NewCache(&Config[int, int]{\n\t\tNumCounters: 10,\n\t\tMaxCost:     10,\n\t\tBufferItems: 64,\n\t})\n\trequire.NoError(t, err)\n\trequire.Equal(t, int64(10), c.MaxCost())\n\trequire.True(t, c.Set(1, 1, 1))\n\ttime.Sleep(wait)\n\t_, ok := c.Get(1)\n\t// Set is rejected because the cost of the entry is too high\n\t// when accounting for the internal cost of storing the entry.\n\trequire.False(t, ok)\n\n\t// Update the max cost of the cache and retry.\n\tc.UpdateMaxCost(1000)\n\trequire.Equal(t, int64(1000), c.MaxCost())\n\trequire.True(t, c.Set(1, 1, 1))\n\ttime.Sleep(wait)\n\tval, ok := c.Get(1)\n\trequire.True(t, ok)\n\trequire.NotNil(t, val)\n\tc.Del(1)\n}\n\nfunc TestNewCache(t *testing.T) {\n\t_, err := NewCache(&Config[int, int]{\n\t\tNumCounters: 0,\n\t})\n\trequire.Error(t, err)\n\n\t_, err = NewCache(&Config[int, int]{\n\t\tNumCounters: 100,\n\t\tMaxCost:     0,\n\t})\n\trequire.Error(t, err)\n\n\t_, err = NewCache(&Config[int, int]{\n\t\tNumCounters: 100,\n\t\tMaxCost:     10,\n\t\tBufferItems: 0,\n\t})\n\trequire.Error(t, err)\n\n\tc, err := NewCache(&Config[int, int]{\n\t\tNumCounters: 100,\n\t\tMaxCost:     10,\n\t\tBufferItems: 64,\n\t\tMetrics:     true,\n\t})\n\trequire.NoError(t, err)\n\trequire.NotNil(t, c)\n}\n\nfunc TestNilCache(t *testing.T) {\n\tvar c *Cache[int, int]\n\tval, ok := c.Get(1)\n\trequire.False(t, ok)\n\trequire.Zero(t, val)\n\n\trequire.False(t, c.Set(1, 1, 1))\n\tc.Del(1)\n\tc.Clear()\n\tc.Close()\n}\n\nfunc TestMultipleClose(t *testing.T) {\n\tvar c *Cache[int, int]\n\tc.Close()\n\n\tvar err error\n\tc, err = NewCache(&Config[int, int]{\n\t\tNumCounters: 100,\n\t\tMaxCost:     10,\n\t\tBufferItems: 64,\n\t\tMetrics:     true,\n\t})\n\trequire.NoError(t, err)\n\tc.Close()\n\tc.Close()\n}\n\nfunc TestSetAfterClose(t *testing.T) {\n\tc, err := newTestCache()\n\trequire.NoError(t, err)\n\trequire.NotNil(t, c)\n\n\tc.Close()\n\trequire.False(t, c.Set(1, 1, 1))\n}\n\nfunc TestClearAfterClose(t *testing.T) {\n\tc, err := newTestCache()\n\trequire.NoError(t, err)\n\trequire.NotNil(t, c)\n\n\tc.Close()\n\tc.Clear()\n}\n\nfunc TestGetAfterClose(t *testing.T) {\n\tc, err := newTestCache()\n\trequire.NoError(t, err)\n\trequire.NotNil(t, c)\n\n\trequire.True(t, c.Set(1, 1, 1))\n\tc.Close()\n\n\t_, ok := c.Get(1)\n\trequire.False(t, ok)\n}\n\nfunc TestDelAfterClose(t *testing.T) {\n\tc, err := newTestCache()\n\trequire.NoError(t, err)\n\trequire.NotNil(t, c)\n\n\trequire.True(t, c.Set(1, 1, 1))\n\tc.Close()\n\n\tc.Del(1)\n}\n\nfunc TestCacheProcessItems(t *testing.T) {\n\tm := &sync.Mutex{}\n\tevicted := make(map[uint64]struct{})\n\tc, err := NewCache(&Config[int, int]{\n\t\tNumCounters:        100,\n\t\tMaxCost:            10,\n\t\tBufferItems:        64,\n\t\tIgnoreInternalCost: true,\n\t\tCost: func(value int) int64 {\n\t\t\treturn int64(value)\n\t\t},\n\t\tOnEvict: func(item *Item[int]) {\n\t\t\tm.Lock()\n\t\t\tdefer m.Unlock()\n\t\t\tevicted[item.Key] = struct{}{}\n\t\t},\n\t})\n\trequire.NoError(t, err)\n\n\tvar key uint64\n\tvar conflict uint64\n\n\tkey, conflict = z.KeyToHash(1)\n\tc.setBuf <- &Item[int]{\n\t\tflag:     itemNew,\n\t\tKey:      key,\n\t\tConflict: conflict,\n\t\tValue:    1,\n\t\tCost:     0,\n\t}\n\ttime.Sleep(wait)\n\trequire.True(t, c.cachePolicy.Has(1))\n\trequire.Equal(t, int64(1), c.cachePolicy.Cost(1))\n\n\tkey, conflict = z.KeyToHash(1)\n\tc.setBuf <- &Item[int]{\n\t\tflag:     itemUpdate,\n\t\tKey:      key,\n\t\tConflict: conflict,\n\t\tValue:    2,\n\t\tCost:     0,\n\t}\n\ttime.Sleep(wait)\n\trequire.Equal(t, int64(2), c.cachePolicy.Cost(1))\n\n\tkey, conflict = z.KeyToHash(1)\n\tc.setBuf <- &Item[int]{\n\t\tflag:     itemDelete,\n\t\tKey:      key,\n\t\tConflict: conflict,\n\t}\n\ttime.Sleep(wait)\n\tkey, conflict = z.KeyToHash(1)\n\tval, ok := c.storedItems.Get(key, conflict)\n\trequire.False(t, ok)\n\trequire.Zero(t, val)\n\trequire.False(t, c.cachePolicy.Has(1))\n\n\tkey, conflict = z.KeyToHash(2)\n\tc.setBuf <- &Item[int]{\n\t\tflag:     itemNew,\n\t\tKey:      key,\n\t\tConflict: conflict,\n\t\tValue:    2,\n\t\tCost:     3,\n\t}\n\tkey, conflict = z.KeyToHash(3)\n\tc.setBuf <- &Item[int]{\n\t\tflag:     itemNew,\n\t\tKey:      key,\n\t\tConflict: conflict,\n\t\tValue:    3,\n\t\tCost:     3,\n\t}\n\tkey, conflict = z.KeyToHash(4)\n\tc.setBuf <- &Item[int]{\n\t\tflag:     itemNew,\n\t\tKey:      key,\n\t\tConflict: conflict,\n\t\tValue:    3,\n\t\tCost:     3,\n\t}\n\tkey, conflict = z.KeyToHash(5)\n\tc.setBuf <- &Item[int]{\n\t\tflag:     itemNew,\n\t\tKey:      key,\n\t\tConflict: conflict,\n\t\tValue:    3,\n\t\tCost:     5,\n\t}\n\ttime.Sleep(wait)\n\tm.Lock()\n\trequire.NotEqual(t, 0, len(evicted))\n\tm.Unlock()\n\n\tdefer func() {\n\t\trequire.NotNil(t, recover())\n\t}()\n\tc.Close()\n\tc.setBuf <- &Item[int]{flag: itemNew}\n}\n\nfunc TestCacheGet(t *testing.T) {\n\tc, err := NewCache(&Config[int, int]{\n\t\tNumCounters:        100,\n\t\tMaxCost:            10,\n\t\tBufferItems:        64,\n\t\tIgnoreInternalCost: true,\n\t\tMetrics:            true,\n\t})\n\trequire.NoError(t, err)\n\n\tkey, conflict := z.KeyToHash(1)\n\ti := Item[int]{\n\t\tKey:      key,\n\t\tConflict: conflict,\n\t\tValue:    1,\n\t}\n\tc.storedItems.Set(&i)\n\tval, ok := c.Get(1)\n\trequire.True(t, ok)\n\trequire.NotNil(t, val)\n\n\tval, ok = c.Get(2)\n\trequire.False(t, ok)\n\trequire.Zero(t, val)\n\n\t// 0.5 and not 1.0 because we tried Getting each item twice\n\trequire.Equal(t, 0.5, c.Metrics.Ratio())\n\n\tc = nil\n\tval, ok = c.Get(0)\n\trequire.False(t, ok)\n\trequire.Zero(t, val)\n}\n\n// retrySet calls SetWithTTL until the item is accepted by the cache.\nfunc retrySet(t *testing.T, c *Cache[int, int], key, value int, cost int64, ttl time.Duration) {\n\tfor {\n\t\tif set := c.SetWithTTL(key, value, cost, ttl); !set {\n\t\t\ttime.Sleep(wait)\n\t\t\tcontinue\n\t\t}\n\n\t\ttime.Sleep(wait)\n\t\tval, ok := c.Get(key)\n\t\trequire.True(t, ok)\n\t\trequire.NotNil(t, val)\n\t\trequire.Equal(t, value, val)\n\t\treturn\n\t}\n}\n\nfunc TestCacheSet(t *testing.T) {\n\tc, err := NewCache(&Config[int, int]{\n\t\tNumCounters:        100,\n\t\tMaxCost:            10,\n\t\tIgnoreInternalCost: true,\n\t\tBufferItems:        64,\n\t\tMetrics:            true,\n\t})\n\trequire.NoError(t, err)\n\n\tretrySet(t, c, 1, 1, 1, 0)\n\n\tc.Set(1, 2, 2)\n\tval, ok := c.storedItems.Get(z.KeyToHash(1))\n\trequire.True(t, ok)\n\trequire.Equal(t, 2, val)\n\n\tc.stop <- struct{}{}\n\t<-c.done\n\tfor i := 0; i < setBufSize; i++ {\n\t\tkey, conflict := z.KeyToHash(1)\n\t\tc.setBuf <- &Item[int]{\n\t\t\tflag:     itemUpdate,\n\t\t\tKey:      key,\n\t\t\tConflict: conflict,\n\t\t\tValue:    1,\n\t\t\tCost:     1,\n\t\t}\n\t}\n\trequire.False(t, c.Set(2, 2, 1))\n\trequire.Equal(t, uint64(1), c.Metrics.SetsDropped())\n\tclose(c.setBuf)\n\tclose(c.stop)\n\tclose(c.done)\n\n\tc = nil\n\trequire.False(t, c.Set(1, 1, 1))\n}\n\nfunc TestCacheInternalCost(t *testing.T) {\n\tc, err := NewCache(&Config[int, int]{\n\t\tNumCounters: 100,\n\t\tMaxCost:     10,\n\t\tBufferItems: 64,\n\t\tMetrics:     true,\n\t})\n\trequire.NoError(t, err)\n\n\t// Get should return false because the cache's cost is too small to storedItems the item\n\t// when accounting for the internal cost.\n\tc.SetWithTTL(1, 1, 1, 0)\n\ttime.Sleep(wait)\n\t_, ok := c.Get(1)\n\trequire.False(t, ok)\n}\n\nfunc TestRecacheWithTTL(t *testing.T) {\n\tc, err := NewCache(&Config[int, int]{\n\t\tNumCounters:        100,\n\t\tMaxCost:            10,\n\t\tIgnoreInternalCost: true,\n\t\tBufferItems:        64,\n\t\tMetrics:            true,\n\t})\n\n\trequire.NoError(t, err)\n\n\t// Set initial value for key = 1\n\tinsert := c.SetWithTTL(1, 1, 1, 5*time.Second)\n\trequire.True(t, insert)\n\ttime.Sleep(2 * time.Second)\n\n\t// Get value from cache for key = 1\n\tval, ok := c.Get(1)\n\trequire.True(t, ok)\n\trequire.NotNil(t, val)\n\trequire.Equal(t, 1, val)\n\n\t// Wait for expiration\n\ttime.Sleep(5 * time.Second)\n\n\t// The cached value for key = 1 should be gone\n\tval, ok = c.Get(1)\n\trequire.False(t, ok)\n\trequire.Zero(t, val)\n\n\t// Set new value for key = 1\n\tinsert = c.SetWithTTL(1, 2, 1, 5*time.Second)\n\trequire.True(t, insert)\n\ttime.Sleep(2 * time.Second)\n\n\t// Get value from cache for key = 1\n\tval, ok = c.Get(1)\n\trequire.True(t, ok)\n\trequire.NotNil(t, val)\n\trequire.Equal(t, 2, val)\n}\n\nfunc TestCacheSetWithTTL(t *testing.T) {\n\tm := &sync.Mutex{}\n\tevicted := make(map[uint64]struct{})\n\tc, err := NewCache(&Config[int, int]{\n\t\tNumCounters:        100,\n\t\tMaxCost:            10,\n\t\tIgnoreInternalCost: true,\n\t\tBufferItems:        64,\n\t\tMetrics:            true,\n\t\tOnEvict: func(item *Item[int]) {\n\t\t\tm.Lock()\n\t\t\tdefer m.Unlock()\n\t\t\tevicted[item.Key] = struct{}{}\n\t\t},\n\t})\n\trequire.NoError(t, err)\n\n\tretrySet(t, c, 1, 1, 1, time.Second)\n\n\t// Sleep to make sure the item has expired after execution resumes.\n\ttime.Sleep(2 * time.Second)\n\tval, ok := c.Get(1)\n\trequire.False(t, ok)\n\trequire.Zero(t, val)\n\n\t// Sleep to ensure that the bucket where the item was stored has been cleared\n\t// from the expiraton map.\n\ttime.Sleep(5 * time.Second)\n\tm.Lock()\n\trequire.Equal(t, 1, len(evicted))\n\t_, ok = evicted[1]\n\trequire.True(t, ok)\n\tm.Unlock()\n\n\t// Verify that expiration times are overwritten.\n\tretrySet(t, c, 2, 1, 1, time.Second)\n\tretrySet(t, c, 2, 2, 1, 100*time.Second)\n\ttime.Sleep(3 * time.Second)\n\tval, ok = c.Get(2)\n\trequire.True(t, ok)\n\trequire.Equal(t, 2, val)\n\n\t// Verify that entries with no expiration are overwritten.\n\tretrySet(t, c, 3, 1, 1, 0)\n\tretrySet(t, c, 3, 2, 1, time.Second)\n\ttime.Sleep(3 * time.Second)\n\tval, ok = c.Get(3)\n\trequire.False(t, ok)\n\trequire.Zero(t, val)\n}\n\nfunc TestCacheDel(t *testing.T) {\n\tc, err := NewCache(&Config[int, int]{\n\t\tNumCounters: 100,\n\t\tMaxCost:     10,\n\t\tBufferItems: 64,\n\t})\n\trequire.NoError(t, err)\n\n\tc.Set(1, 1, 1)\n\tc.Del(1)\n\t// The deletes and sets are pushed through the setbuf. It might be possible\n\t// that the delete is not processed before the following get is called. So\n\t// wait for a millisecond for things to be processed.\n\ttime.Sleep(time.Millisecond)\n\tval, ok := c.Get(1)\n\trequire.False(t, ok)\n\trequire.Zero(t, val)\n\n\tc = nil\n\tdefer func() {\n\t\trequire.Nil(t, recover())\n\t}()\n\tc.Del(1)\n}\n\nfunc TestCacheDelWithTTL(t *testing.T) {\n\tc, err := NewCache(&Config[int, int]{\n\t\tNumCounters:        100,\n\t\tMaxCost:            10,\n\t\tIgnoreInternalCost: true,\n\t\tBufferItems:        64,\n\t})\n\trequire.NoError(t, err)\n\tretrySet(t, c, 3, 1, 1, 10*time.Second)\n\ttime.Sleep(1 * time.Second)\n\t// Delete the item\n\tc.Del(3)\n\t// Ensure the key is deleted.\n\tval, ok := c.Get(3)\n\trequire.False(t, ok)\n\trequire.Zero(t, val)\n}\n\nfunc TestCacheGetTTL(t *testing.T) {\n\tc, err := NewCache(&Config[int, int]{\n\t\tNumCounters:        100,\n\t\tMaxCost:            10,\n\t\tIgnoreInternalCost: true,\n\t\tBufferItems:        64,\n\t\tMetrics:            true,\n\t})\n\trequire.NoError(t, err)\n\n\t// try expiration with valid ttl item\n\t{\n\t\texpiration := time.Second * 5\n\t\tretrySet(t, c, 1, 1, 1, expiration)\n\n\t\tval, ok := c.Get(1)\n\t\trequire.True(t, ok)\n\t\trequire.Equal(t, 1, val)\n\n\t\tttl, ok := c.GetTTL(1)\n\t\trequire.True(t, ok)\n\t\trequire.WithinDuration(t,\n\t\t\ttime.Now().Add(expiration), time.Now().Add(ttl), 1*time.Second)\n\n\t\tc.Del(1)\n\n\t\tttl, ok = c.GetTTL(1)\n\t\trequire.False(t, ok)\n\t\trequire.Equal(t, ttl, time.Duration(0))\n\t}\n\t// try expiration with no ttl\n\t{\n\t\tretrySet(t, c, 2, 2, 1, time.Duration(0))\n\n\t\tval, ok := c.Get(2)\n\t\trequire.True(t, ok)\n\t\trequire.Equal(t, 2, val)\n\n\t\tttl, ok := c.GetTTL(2)\n\t\trequire.True(t, ok)\n\t\trequire.Equal(t, ttl, time.Duration(0))\n\t}\n\t// try expiration with missing item\n\t{\n\t\tttl, ok := c.GetTTL(3)\n\t\trequire.False(t, ok)\n\t\trequire.Equal(t, ttl, time.Duration(0))\n\t}\n\t// try expiration with expired item\n\t{\n\t\texpiration := time.Second\n\t\tretrySet(t, c, 3, 3, 1, expiration)\n\n\t\tval, ok := c.Get(3)\n\t\trequire.True(t, ok)\n\t\trequire.Equal(t, 3, val)\n\n\t\ttime.Sleep(time.Second)\n\n\t\tttl, ok := c.GetTTL(3)\n\t\trequire.False(t, ok)\n\t\trequire.Equal(t, ttl, time.Duration(0))\n\t}\n}\n\nfunc TestCacheClear(t *testing.T) {\n\tc, err := NewCache(&Config[int, int]{\n\t\tNumCounters:        100,\n\t\tMaxCost:            10,\n\t\tIgnoreInternalCost: true,\n\t\tBufferItems:        64,\n\t\tMetrics:            true,\n\t})\n\trequire.NoError(t, err)\n\n\tfor i := 0; i < 10; i++ {\n\t\tc.Set(i, i, 1)\n\t}\n\ttime.Sleep(wait)\n\trequire.Equal(t, uint64(10), c.Metrics.KeysAdded())\n\n\tc.Clear()\n\trequire.Equal(t, uint64(0), c.Metrics.KeysAdded())\n\n\tfor i := 0; i < 10; i++ {\n\t\tval, ok := c.Get(i)\n\t\trequire.False(t, ok)\n\t\trequire.Zero(t, val)\n\t}\n}\n\nfunc TestCacheMetrics(t *testing.T) {\n\tc, err := NewCache(&Config[int, int]{\n\t\tNumCounters:        100,\n\t\tMaxCost:            10,\n\t\tIgnoreInternalCost: true,\n\t\tBufferItems:        64,\n\t\tMetrics:            true,\n\t})\n\trequire.NoError(t, err)\n\n\tfor i := 0; i < 10; i++ {\n\t\tc.Set(i, i, 1)\n\t}\n\ttime.Sleep(wait)\n\tm := c.Metrics\n\trequire.Equal(t, uint64(10), m.KeysAdded())\n}\n\nfunc TestMetrics(t *testing.T) {\n\tnewMetrics()\n}\n\nfunc TestNilMetrics(t *testing.T) {\n\tvar m *Metrics\n\tfor _, f := range []func() uint64{\n\t\tm.Hits,\n\t\tm.Misses,\n\t\tm.KeysAdded,\n\t\tm.KeysEvicted,\n\t\tm.CostEvicted,\n\t\tm.SetsDropped,\n\t\tm.SetsRejected,\n\t\tm.GetsDropped,\n\t\tm.GetsKept,\n\t} {\n\t\trequire.Equal(t, uint64(0), f())\n\t}\n}\n\nfunc TestMetricsAddGet(t *testing.T) {\n\tm := newMetrics()\n\tm.add(hit, 1, 1)\n\tm.add(hit, 2, 2)\n\tm.add(hit, 3, 3)\n\trequire.Equal(t, uint64(6), m.Hits())\n\n\tm = nil\n\tm.add(hit, 1, 1)\n\trequire.Equal(t, uint64(0), m.Hits())\n}\n\nfunc TestMetricsRatio(t *testing.T) {\n\tm := newMetrics()\n\trequire.Equal(t, float64(0), m.Ratio())\n\n\tm.add(hit, 1, 1)\n\tm.add(hit, 2, 2)\n\tm.add(miss, 1, 1)\n\tm.add(miss, 2, 2)\n\trequire.Equal(t, 0.5, m.Ratio())\n\n\tm = nil\n\trequire.Equal(t, float64(0), m.Ratio())\n}\n\nfunc TestMetricsString(t *testing.T) {\n\tm := newMetrics()\n\tm.add(hit, 1, 1)\n\tm.add(miss, 1, 1)\n\tm.add(keyAdd, 1, 1)\n\tm.add(keyUpdate, 1, 1)\n\tm.add(keyEvict, 1, 1)\n\tm.add(costAdd, 1, 1)\n\tm.add(costEvict, 1, 1)\n\tm.add(dropSets, 1, 1)\n\tm.add(rejectSets, 1, 1)\n\tm.add(dropGets, 1, 1)\n\tm.add(keepGets, 1, 1)\n\trequire.Equal(t, uint64(1), m.Hits())\n\trequire.Equal(t, uint64(1), m.Misses())\n\trequire.Equal(t, 0.5, m.Ratio())\n\trequire.Equal(t, uint64(1), m.KeysAdded())\n\trequire.Equal(t, uint64(1), m.KeysUpdated())\n\trequire.Equal(t, uint64(1), m.KeysEvicted())\n\trequire.Equal(t, uint64(1), m.CostAdded())\n\trequire.Equal(t, uint64(1), m.CostEvicted())\n\trequire.Equal(t, uint64(1), m.SetsDropped())\n\trequire.Equal(t, uint64(1), m.SetsRejected())\n\trequire.Equal(t, uint64(1), m.GetsDropped())\n\trequire.Equal(t, uint64(1), m.GetsKept())\n\n\trequire.NotEqual(t, 0, len(m.String()))\n\n\tm = nil\n\trequire.Equal(t, 0, len(m.String()))\n\n\trequire.Equal(t, \"unidentified\", stringFor(doNotUse))\n}\n\nfunc TestCacheMetricsClear(t *testing.T) {\n\tc, err := NewCache(&Config[int, int]{\n\t\tNumCounters: 100,\n\t\tMaxCost:     10,\n\t\tBufferItems: 64,\n\t\tMetrics:     true,\n\t})\n\trequire.NoError(t, err)\n\n\tc.Set(1, 1, 1)\n\tstop := make(chan struct{})\n\tgo func() {\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-stop:\n\t\t\t\treturn\n\t\t\tdefault:\n\t\t\t\tc.Get(1)\n\t\t\t}\n\t\t}\n\t}()\n\ttime.Sleep(wait)\n\tc.Clear()\n\tstop <- struct{}{}\n\tc.Metrics = nil\n\tc.Metrics.Clear()\n}\n\nfunc init() {\n\t// Set bucketSizeSecs to 1 to avoid waiting too much during the tests.\n\tbucketDurationSecs = 1\n}\n\nfunc TestBlockOnClear(t *testing.T) {\n\tc, err := NewCache(&Config[int, int]{\n\t\tNumCounters: 100,\n\t\tMaxCost:     10,\n\t\tBufferItems: 64,\n\t\tMetrics:     false,\n\t})\n\trequire.NoError(t, err)\n\tdefer c.Close()\n\n\tdone := make(chan struct{})\n\n\tgo func() {\n\t\tfor i := 0; i < 10; i++ {\n\t\t\tc.Wait()\n\t\t}\n\t\tclose(done)\n\t}()\n\n\tfor i := 0; i < 10; i++ {\n\t\tc.Clear()\n\t}\n\n\tselect {\n\tcase <-done:\n\t\t// We're OK\n\tcase <-time.After(1 * time.Second):\n\t\tt.Fatalf(\"timed out while waiting on cache\")\n\t}\n}\n\n// Regression test for bug https://github.com/dgraph-io/ristretto/issues/167\nfunc TestDropUpdates(t *testing.T) {\n\toriginalSetBugSize := setBufSize\n\tdefer func() { setBufSize = originalSetBugSize }()\n\n\ttest := func() {\n\t\t// dropppedMap stores the items dropped from the cache.\n\t\tdroppedMap := make(map[int]struct{})\n\t\tlastEvictedSet := int64(-1)\n\n\t\tvar err error\n\t\thandler := func(_ interface{}, value interface{}) {\n\t\t\tv := value.(string)\n\t\t\tlastEvictedSet, err = strconv.ParseInt(v, 10, 32)\n\t\t\trequire.NoError(t, err)\n\n\t\t\t_, ok := droppedMap[int(lastEvictedSet)]\n\t\t\tif ok {\n\t\t\t\tpanic(fmt.Sprintf(\"val = %+v was dropped but it got evicted. Dropped items: %+v\\n\",\n\t\t\t\t\tlastEvictedSet, droppedMap))\n\t\t\t}\n\t\t}\n\n\t\t// This is important. The race condition shows up only when the setBuf\n\t\t// is full and that's why we reduce the buf size here. The test will\n\t\t// try to fill up the setbuf to it's capacity and then perform an\n\t\t// update on a key.\n\t\tsetBufSize = 10\n\n\t\tc, err := NewCache(&Config[int, string]{\n\t\t\tNumCounters: 100,\n\t\t\tMaxCost:     10,\n\t\t\tBufferItems: 64,\n\t\t\tMetrics:     true,\n\t\t\tOnEvict: func(item *Item[string]) {\n\t\t\t\thandler(nil, item.Value)\n\t\t\t},\n\t\t})\n\t\trequire.NoError(t, err)\n\n\t\tfor i := 0; i < 5*setBufSize; i++ {\n\t\t\tv := fmt.Sprintf(\"%0100d\", i)\n\t\t\t// We're updating the same key.\n\t\t\tif !c.Set(0, v, 1) {\n\t\t\t\t// The race condition doesn't show up without this sleep.\n\t\t\t\ttime.Sleep(time.Microsecond)\n\t\t\t\tdroppedMap[i] = struct{}{}\n\t\t\t}\n\t\t}\n\t\t// Wait for all items to be processed: prevents next c.Set from getting dropped\n\t\tc.Wait()\n\t\t// This will cause eviction from the cache.\n\t\trequire.True(t, c.Set(1, \"\", 10))\n\n\t\t// Close() calls Clear(), which can cause the (key, value) pair of (1, nil) to be passed to\n\t\t// the OnEvict() callback if it was still in the setBuf. This fixes a panic in OnEvict:\n\t\t// \"interface {} is nil, not string\"\n\t\tc.Wait()\n\t\tc.Close()\n\n\t\trequire.NotEqual(t, -1, lastEvictedSet)\n\t}\n\n\t// Run the test 100 times since it's not reliable.\n\tfor i := 0; i < 100; i++ {\n\t\ttest()\n\t}\n}\n\nfunc TestRistrettoCalloc(t *testing.T) {\n\tmaxCacheSize := 1 << 20\n\tconfig := &Config[int, []byte]{\n\t\t// Use 5% of cache memory for storing counters.\n\t\tNumCounters: int64(float64(maxCacheSize) * 0.05 * 2),\n\t\tMaxCost:     int64(float64(maxCacheSize) * 0.95),\n\t\tBufferItems: 64,\n\t\tMetrics:     true,\n\t\tOnExit: func(val []byte) {\n\t\t\tz.Free(val)\n\t\t},\n\t}\n\tr, err := NewCache(config)\n\trequire.NoError(t, err)\n\tdefer r.Close()\n\n\tvar wg sync.WaitGroup\n\tfor i := 0; i < runtime.NumCPU(); i++ {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\trd := rand.New(rand.NewSource(time.Now().UnixNano()))\n\t\t\tfor i := 0; i < 10000; i++ {\n\t\t\t\tk := rd.Intn(10000)\n\t\t\t\tv := z.Calloc(256, \"test\")\n\t\t\t\trd.Read(v)\n\t\t\t\tif !r.Set(k, v, 256) {\n\t\t\t\t\tz.Free(v)\n\t\t\t\t}\n\t\t\t\tif rd.Intn(10) == 0 {\n\t\t\t\t\tr.Del(k)\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\twg.Wait()\n\tr.Clear()\n\trequire.Zero(t, z.NumAllocBytes())\n}\n\nfunc TestRistrettoCallocTTL(t *testing.T) {\n\tmaxCacheSize := 1 << 20\n\tconfig := &Config[int, []byte]{\n\t\t// Use 5% of cache memory for storing counters.\n\t\tNumCounters: int64(float64(maxCacheSize) * 0.05 * 2),\n\t\tMaxCost:     int64(float64(maxCacheSize) * 0.95),\n\t\tBufferItems: 64,\n\t\tMetrics:     true,\n\t\tOnExit: func(val []byte) {\n\t\t\tz.Free(val)\n\t\t},\n\t}\n\tr, err := NewCache(config)\n\trequire.NoError(t, err)\n\tdefer r.Close()\n\n\tvar wg sync.WaitGroup\n\tfor i := 0; i < runtime.NumCPU(); i++ {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\trd := rand.New(rand.NewSource(time.Now().UnixNano()))\n\t\t\tfor i := 0; i < 10000; i++ {\n\t\t\t\tk := rd.Intn(10000)\n\t\t\t\tv := z.Calloc(256, \"test\")\n\t\t\t\trd.Read(v)\n\t\t\t\tif !r.SetWithTTL(k, v, 256, time.Second) {\n\t\t\t\t\tz.Free(v)\n\t\t\t\t}\n\t\t\t\tif rd.Intn(10) == 0 {\n\t\t\t\t\tr.Del(k)\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\twg.Wait()\n\ttime.Sleep(5 * time.Second)\n\trequire.Zero(t, z.NumAllocBytes())\n}\n\nfunc newTestCache() (*Cache[int, int], error) {\n\treturn NewCache(&Config[int, int]{\n\t\tNumCounters: 100,\n\t\tMaxCost:     10,\n\t\tBufferItems: 64,\n\t\tMetrics:     true,\n\t})\n}\n\nfunc TestCacheWithTTL(t *testing.T) {\n\t// There may be a race condition, so run the test multiple times.\n\tconst try = 10\n\n\tfor i := 0; i < try; i++ {\n\t\tt.Run(strconv.Itoa(i), func(t *testing.T) {\n\t\t\tc, err := NewCache(&Config[int, int]{\n\t\t\t\tNumCounters: 100,\n\t\t\t\tMaxCost:     1000,\n\t\t\t\tBufferItems: 64,\n\t\t\t\tMetrics:     true,\n\t\t\t})\n\n\t\t\trequire.NoError(t, err)\n\n\t\t\t// Set initial value for key = 1\n\t\t\tinsert := c.SetWithTTL(1, 1, 1, 800*time.Millisecond)\n\t\t\trequire.True(t, insert)\n\n\t\t\ttime.Sleep(100 * time.Millisecond)\n\n\t\t\t// Get value from cache for key = 1\n\t\t\tval, ok := c.Get(1)\n\t\t\trequire.True(t, ok)\n\t\t\trequire.NotNil(t, val)\n\t\t\trequire.Equal(t, 1, val)\n\n\t\t\ttime.Sleep(1200 * time.Millisecond)\n\n\t\t\tval, ok = c.Get(1)\n\t\t\trequire.False(t, ok)\n\t\t\trequire.Zero(t, val)\n\t\t})\n\t}\n}\n"
        },
        {
          "name": "contrib",
          "type": "tree",
          "content": null
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.4501953125,
          "content": "module github.com/dgraph-io/ristretto/v2\n\ngo 1.21\n\ntoolchain go1.23.2\n\nrequire (\n\tgithub.com/cespare/xxhash/v2 v2.3.0\n\tgithub.com/dgryski/go-farm v0.0.0-20200201041132-a6ae2369ad13\n\tgithub.com/dustin/go-humanize v1.0.1\n\tgithub.com/pkg/errors v0.9.1\n\tgithub.com/stretchr/testify v1.10.0\n\tgolang.org/x/sys v0.29.0\n)\n\nrequire (\n\tgithub.com/davecgh/go-spew v1.1.1 // indirect\n\tgithub.com/pmezard/go-difflib v1.0.0 // indirect\n\tgopkg.in/yaml.v3 v3.0.1 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 1.734375,
          "content": "github.com/cespare/xxhash/v2 v2.3.0 h1:UL815xU9SqsFlibzuggzjXhog7bL6oX9BbNZnL2UFvs=\ngithub.com/cespare/xxhash/v2 v2.3.0/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/dgryski/go-farm v0.0.0-20200201041132-a6ae2369ad13 h1:fAjc9m62+UWV/WAFKLNi6ZS0675eEUC9y3AlwSbQu1Y=\ngithub.com/dgryski/go-farm v0.0.0-20200201041132-a6ae2369ad13/go.mod h1:SqUrOPUnsFjfmXRMNPybcSiG0BgUW2AuFH8PAnS2iTw=\ngithub.com/dustin/go-humanize v1.0.1 h1:GzkhY7T5VNhEkwH0PVJgjz+fX1rhBrR7pRT3mDkpeCY=\ngithub.com/dustin/go-humanize v1.0.1/go.mod h1:Mu1zIs6XwVuF/gI1OepvI0qD18qycQx+mFykh5fBlto=\ngithub.com/pkg/errors v0.9.1 h1:FEBLx1zS214owpjy7qsBeixbURkuhQAwrK5UwLGTwt4=\ngithub.com/pkg/errors v0.9.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/stretchr/testify v1.10.0 h1:Xv5erBjTwe/5IxqUQTdXv5kgmIvbHo3QQyRwhJsOfJA=\ngithub.com/stretchr/testify v1.10.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=\ngolang.org/x/sys v0.29.0 h1:TPYlXGxvx1MGTn2GiZDhnjPA9wZzZeGKHHmKhHYvgaU=\ngolang.org/x/sys v0.29.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405 h1:yhCVgyC4o1eVCa2tZl7eS0r+SDo693bJlVdllGtEeKM=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\n"
        },
        {
          "name": "policy.go",
          "type": "blob",
          "size": 9.1484375,
          "content": "/*\n * Copyright 2020 Dgraph Labs, Inc. and Contributors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage ristretto\n\nimport (\n\t\"math\"\n\t\"sync\"\n\t\"sync/atomic\"\n\n\t\"github.com/dgraph-io/ristretto/v2/z\"\n)\n\nconst (\n\t// lfuSample is the number of items to sample when looking at eviction\n\t// candidates. 5 seems to be the most optimal number [citation needed].\n\tlfuSample = 5\n)\n\nfunc newPolicy[V any](numCounters, maxCost int64) *defaultPolicy[V] {\n\treturn newDefaultPolicy[V](numCounters, maxCost)\n}\n\ntype defaultPolicy[V any] struct {\n\tsync.Mutex\n\tadmit    *tinyLFU\n\tevict    *sampledLFU\n\titemsCh  chan []uint64\n\tstop     chan struct{}\n\tdone     chan struct{}\n\tisClosed bool\n\tmetrics  *Metrics\n}\n\nfunc newDefaultPolicy[V any](numCounters, maxCost int64) *defaultPolicy[V] {\n\tp := &defaultPolicy[V]{\n\t\tadmit:   newTinyLFU(numCounters),\n\t\tevict:   newSampledLFU(maxCost),\n\t\titemsCh: make(chan []uint64, 3),\n\t\tstop:    make(chan struct{}),\n\t\tdone:    make(chan struct{}),\n\t}\n\tgo p.processItems()\n\treturn p\n}\n\nfunc (p *defaultPolicy[V]) CollectMetrics(metrics *Metrics) {\n\tp.metrics = metrics\n\tp.evict.metrics = metrics\n}\n\ntype policyPair struct {\n\tkey  uint64\n\tcost int64\n}\n\nfunc (p *defaultPolicy[V]) processItems() {\n\tfor {\n\t\tselect {\n\t\tcase items := <-p.itemsCh:\n\t\t\tp.Lock()\n\t\t\tp.admit.Push(items)\n\t\t\tp.Unlock()\n\t\tcase <-p.stop:\n\t\t\tp.done <- struct{}{}\n\t\t\treturn\n\t\t}\n\t}\n}\n\nfunc (p *defaultPolicy[V]) Push(keys []uint64) bool {\n\tif p.isClosed {\n\t\treturn false\n\t}\n\n\tif len(keys) == 0 {\n\t\treturn true\n\t}\n\n\tselect {\n\tcase p.itemsCh <- keys:\n\t\tp.metrics.add(keepGets, keys[0], uint64(len(keys)))\n\t\treturn true\n\tdefault:\n\t\tp.metrics.add(dropGets, keys[0], uint64(len(keys)))\n\t\treturn false\n\t}\n}\n\n// Add decides whether the item with the given key and cost should be accepted by\n// the policy. It returns the list of victims that have been evicted and a boolean\n// indicating whether the incoming item should be accepted.\nfunc (p *defaultPolicy[V]) Add(key uint64, cost int64) ([]*Item[V], bool) {\n\tp.Lock()\n\tdefer p.Unlock()\n\n\t// Cannot add an item bigger than entire cache.\n\tif cost > p.evict.getMaxCost() {\n\t\treturn nil, false\n\t}\n\n\t// No need to go any further if the item is already in the cache.\n\tif has := p.evict.updateIfHas(key, cost); has {\n\t\t// An update does not count as an addition, so return false.\n\t\treturn nil, false\n\t}\n\n\t// If the execution reaches this point, the key doesn't exist in the cache.\n\t// Calculate the remaining room in the cache (usually bytes).\n\troom := p.evict.roomLeft(cost)\n\tif room >= 0 {\n\t\t// There's enough room in the cache to store the new item without\n\t\t// overflowing. Do that now and stop here.\n\t\tp.evict.add(key, cost)\n\t\tp.metrics.add(costAdd, key, uint64(cost))\n\t\treturn nil, true\n\t}\n\n\t// incHits is the hit count for the incoming item.\n\tincHits := p.admit.Estimate(key)\n\t// sample is the eviction candidate pool to be filled via random sampling.\n\t// TODO: perhaps we should use a min heap here. Right now our time\n\t// complexity is N for finding the min. Min heap should bring it down to\n\t// O(lg N).\n\tsample := make([]*policyPair, 0, lfuSample)\n\t// As items are evicted they will be appended to victims.\n\tvictims := make([]*Item[V], 0)\n\n\t// Delete victims until there's enough space or a minKey is found that has\n\t// more hits than incoming item.\n\tfor ; room < 0; room = p.evict.roomLeft(cost) {\n\t\t// Fill up empty slots in sample.\n\t\tsample = p.evict.fillSample(sample)\n\n\t\t// Find minimally used item in sample.\n\t\tminKey, minHits, minId, minCost := uint64(0), int64(math.MaxInt64), 0, int64(0)\n\t\tfor i, pair := range sample {\n\t\t\t// Look up hit count for sample key.\n\t\t\tif hits := p.admit.Estimate(pair.key); hits < minHits {\n\t\t\t\tminKey, minHits, minId, minCost = pair.key, hits, i, pair.cost\n\t\t\t}\n\t\t}\n\n\t\t// If the incoming item isn't worth keeping in the policy, reject.\n\t\tif incHits < minHits {\n\t\t\tp.metrics.add(rejectSets, key, 1)\n\t\t\treturn victims, false\n\t\t}\n\n\t\t// Delete the victim from metadata.\n\t\tp.evict.del(minKey)\n\n\t\t// Delete the victim from sample.\n\t\tsample[minId] = sample[len(sample)-1]\n\t\tsample = sample[:len(sample)-1]\n\t\t// Store victim in evicted victims slice.\n\t\tvictims = append(victims, &Item[V]{\n\t\t\tKey:      minKey,\n\t\t\tConflict: 0,\n\t\t\tCost:     minCost,\n\t\t})\n\t}\n\n\tp.evict.add(key, cost)\n\tp.metrics.add(costAdd, key, uint64(cost))\n\treturn victims, true\n}\n\nfunc (p *defaultPolicy[V]) Has(key uint64) bool {\n\tp.Lock()\n\t_, exists := p.evict.keyCosts[key]\n\tp.Unlock()\n\treturn exists\n}\n\nfunc (p *defaultPolicy[V]) Del(key uint64) {\n\tp.Lock()\n\tp.evict.del(key)\n\tp.Unlock()\n}\n\nfunc (p *defaultPolicy[V]) Cap() int64 {\n\tp.Lock()\n\tcapacity := p.evict.getMaxCost() - p.evict.used\n\tp.Unlock()\n\treturn capacity\n}\n\nfunc (p *defaultPolicy[V]) Update(key uint64, cost int64) {\n\tp.Lock()\n\tp.evict.updateIfHas(key, cost)\n\tp.Unlock()\n}\n\nfunc (p *defaultPolicy[V]) Cost(key uint64) int64 {\n\tp.Lock()\n\tif cost, found := p.evict.keyCosts[key]; found {\n\t\tp.Unlock()\n\t\treturn cost\n\t}\n\tp.Unlock()\n\treturn -1\n}\n\nfunc (p *defaultPolicy[V]) Clear() {\n\tp.Lock()\n\tp.admit.clear()\n\tp.evict.clear()\n\tp.Unlock()\n}\n\nfunc (p *defaultPolicy[V]) Close() {\n\tif p.isClosed {\n\t\treturn\n\t}\n\n\t// Block until the p.processItems goroutine returns.\n\tp.stop <- struct{}{}\n\t<-p.done\n\tclose(p.stop)\n\tclose(p.done)\n\tclose(p.itemsCh)\n\tp.isClosed = true\n}\n\nfunc (p *defaultPolicy[V]) MaxCost() int64 {\n\tif p == nil || p.evict == nil {\n\t\treturn 0\n\t}\n\treturn p.evict.getMaxCost()\n}\n\nfunc (p *defaultPolicy[V]) UpdateMaxCost(maxCost int64) {\n\tif p == nil || p.evict == nil {\n\t\treturn\n\t}\n\tp.evict.updateMaxCost(maxCost)\n}\n\n// sampledLFU is an eviction helper storing key-cost pairs.\ntype sampledLFU struct {\n\t// NOTE: align maxCost to 64-bit boundary for use with atomic.\n\t// As per https://golang.org/pkg/sync/atomic/: \"On ARM, x86-32,\n\t// and 32-bit MIPS, it is the callerâ€™s responsibility to arrange\n\t// for 64-bit alignment of 64-bit words accessed atomically.\n\t// The first word in a variable or in an allocated struct, array,\n\t// or slice can be relied upon to be 64-bit aligned.\"\n\tmaxCost  int64\n\tused     int64\n\tmetrics  *Metrics\n\tkeyCosts map[uint64]int64\n}\n\nfunc newSampledLFU(maxCost int64) *sampledLFU {\n\treturn &sampledLFU{\n\t\tkeyCosts: make(map[uint64]int64),\n\t\tmaxCost:  maxCost,\n\t}\n}\n\nfunc (p *sampledLFU) getMaxCost() int64 {\n\treturn atomic.LoadInt64(&p.maxCost)\n}\n\nfunc (p *sampledLFU) updateMaxCost(maxCost int64) {\n\tatomic.StoreInt64(&p.maxCost, maxCost)\n}\n\nfunc (p *sampledLFU) roomLeft(cost int64) int64 {\n\treturn p.getMaxCost() - (p.used + cost)\n}\n\nfunc (p *sampledLFU) fillSample(in []*policyPair) []*policyPair {\n\tif len(in) >= lfuSample {\n\t\treturn in\n\t}\n\tfor key, cost := range p.keyCosts {\n\t\tin = append(in, &policyPair{key, cost})\n\t\tif len(in) >= lfuSample {\n\t\t\treturn in\n\t\t}\n\t}\n\treturn in\n}\n\nfunc (p *sampledLFU) del(key uint64) {\n\tcost, ok := p.keyCosts[key]\n\tif !ok {\n\t\treturn\n\t}\n\tp.used -= cost\n\tdelete(p.keyCosts, key)\n\tp.metrics.add(costEvict, key, uint64(cost))\n\tp.metrics.add(keyEvict, key, 1)\n}\n\nfunc (p *sampledLFU) add(key uint64, cost int64) {\n\tp.keyCosts[key] = cost\n\tp.used += cost\n}\n\nfunc (p *sampledLFU) updateIfHas(key uint64, cost int64) bool {\n\tif prev, found := p.keyCosts[key]; found {\n\t\t// Update the cost of an existing key, but don't worry about evicting.\n\t\t// Evictions will be handled the next time a new item is added.\n\t\tp.metrics.add(keyUpdate, key, 1)\n\t\tif prev > cost {\n\t\t\tdiff := prev - cost\n\t\t\tp.metrics.add(costAdd, key, ^(uint64(diff) - 1))\n\t\t} else if cost > prev {\n\t\t\tdiff := cost - prev\n\t\t\tp.metrics.add(costAdd, key, uint64(diff))\n\t\t}\n\t\tp.used += cost - prev\n\t\tp.keyCosts[key] = cost\n\t\treturn true\n\t}\n\treturn false\n}\n\nfunc (p *sampledLFU) clear() {\n\tp.used = 0\n\tp.keyCosts = make(map[uint64]int64)\n}\n\n// tinyLFU is an admission helper that keeps track of access frequency using\n// tiny (4-bit) counters in the form of a count-min sketch.\n// tinyLFU is NOT thread safe.\ntype tinyLFU struct {\n\tfreq    *cmSketch\n\tdoor    *z.Bloom\n\tincrs   int64\n\tresetAt int64\n}\n\nfunc newTinyLFU(numCounters int64) *tinyLFU {\n\treturn &tinyLFU{\n\t\tfreq:    newCmSketch(numCounters),\n\t\tdoor:    z.NewBloomFilter(float64(numCounters), 0.01),\n\t\tresetAt: numCounters,\n\t}\n}\n\nfunc (p *tinyLFU) Push(keys []uint64) {\n\tfor _, key := range keys {\n\t\tp.Increment(key)\n\t}\n}\n\nfunc (p *tinyLFU) Estimate(key uint64) int64 {\n\thits := p.freq.Estimate(key)\n\tif p.door.Has(key) {\n\t\thits++\n\t}\n\treturn hits\n}\n\nfunc (p *tinyLFU) Increment(key uint64) {\n\t// Flip doorkeeper bit if not already done.\n\tif added := p.door.AddIfNotHas(key); !added {\n\t\t// Increment count-min counter if doorkeeper bit is already set.\n\t\tp.freq.Increment(key)\n\t}\n\tp.incrs++\n\tif p.incrs >= p.resetAt {\n\t\tp.reset()\n\t}\n}\n\nfunc (p *tinyLFU) reset() {\n\t// Zero out incrs.\n\tp.incrs = 0\n\t// clears doorkeeper bits\n\tp.door.Clear()\n\t// halves count-min counters\n\tp.freq.Reset()\n}\n\nfunc (p *tinyLFU) clear() {\n\tp.incrs = 0\n\tp.door.Clear()\n\tp.freq.Clear()\n}\n"
        },
        {
          "name": "policy_test.go",
          "type": "blob",
          "size": 5.298828125,
          "content": "package ristretto\n\nimport (\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc TestPolicy(t *testing.T) {\n\tdefer func() {\n\t\trequire.Nil(t, recover())\n\t}()\n\tnewPolicy[int](100, 10)\n}\n\nfunc TestPolicyMetrics(t *testing.T) {\n\tp := newDefaultPolicy[int](100, 10)\n\tp.CollectMetrics(newMetrics())\n\trequire.NotNil(t, p.metrics)\n\trequire.NotNil(t, p.evict.metrics)\n}\n\nfunc TestPolicyProcessItems(t *testing.T) {\n\tp := newDefaultPolicy[int](100, 10)\n\tp.itemsCh <- []uint64{1, 2, 2}\n\ttime.Sleep(wait)\n\tp.Lock()\n\trequire.Equal(t, int64(2), p.admit.Estimate(2))\n\trequire.Equal(t, int64(1), p.admit.Estimate(1))\n\tp.Unlock()\n\n\tp.stop <- struct{}{}\n\t<-p.done\n\tp.itemsCh <- []uint64{3, 3, 3}\n\ttime.Sleep(wait)\n\tp.Lock()\n\trequire.Equal(t, int64(0), p.admit.Estimate(3))\n\tp.Unlock()\n}\n\nfunc TestPolicyPush(t *testing.T) {\n\tp := newDefaultPolicy[int](100, 10)\n\trequire.True(t, p.Push([]uint64{}))\n\n\tkeepCount := 0\n\tfor i := 0; i < 10; i++ {\n\t\tif p.Push([]uint64{1, 2, 3, 4, 5}) {\n\t\t\tkeepCount++\n\t\t}\n\t}\n\trequire.NotEqual(t, 0, keepCount)\n}\n\nfunc TestPolicyAdd(t *testing.T) {\n\tp := newDefaultPolicy[int](1000, 100)\n\tif victims, added := p.Add(1, 101); victims != nil || added {\n\t\tt.Fatal(\"can't add an item bigger than entire cache\")\n\t}\n\tp.Lock()\n\tp.evict.add(1, 1)\n\tp.admit.Increment(1)\n\tp.admit.Increment(2)\n\tp.admit.Increment(3)\n\tp.Unlock()\n\n\tvictims, added := p.Add(1, 1)\n\trequire.Nil(t, victims)\n\trequire.False(t, added)\n\n\tvictims, added = p.Add(2, 20)\n\trequire.Nil(t, victims)\n\trequire.True(t, added)\n\n\tvictims, added = p.Add(3, 90)\n\trequire.NotNil(t, victims)\n\trequire.True(t, added)\n\n\tvictims, added = p.Add(4, 20)\n\trequire.NotNil(t, victims)\n\trequire.False(t, added)\n}\n\nfunc TestPolicyHas(t *testing.T) {\n\tp := newDefaultPolicy[int](100, 10)\n\tp.Add(1, 1)\n\trequire.True(t, p.Has(1))\n\trequire.False(t, p.Has(2))\n}\n\nfunc TestPolicyDel(t *testing.T) {\n\tp := newDefaultPolicy[int](100, 10)\n\tp.Add(1, 1)\n\tp.Del(1)\n\tp.Del(2)\n\trequire.False(t, p.Has(1))\n\trequire.False(t, p.Has(2))\n}\n\nfunc TestPolicyCap(t *testing.T) {\n\tp := newDefaultPolicy[int](100, 10)\n\tp.Add(1, 1)\n\trequire.Equal(t, int64(9), p.Cap())\n}\n\nfunc TestPolicyUpdate(t *testing.T) {\n\tp := newDefaultPolicy[int](100, 10)\n\tp.Add(1, 1)\n\tp.Update(1, 2)\n\tp.Lock()\n\trequire.Equal(t, int64(2), p.evict.keyCosts[1])\n\tp.Unlock()\n}\n\nfunc TestPolicyCost(t *testing.T) {\n\tp := newDefaultPolicy[int](100, 10)\n\tp.Add(1, 2)\n\trequire.Equal(t, int64(2), p.Cost(1))\n\trequire.Equal(t, int64(-1), p.Cost(2))\n}\n\nfunc TestPolicyClear(t *testing.T) {\n\tp := newDefaultPolicy[int](100, 10)\n\tp.Add(1, 1)\n\tp.Add(2, 2)\n\tp.Add(3, 3)\n\tp.Clear()\n\trequire.Equal(t, int64(10), p.Cap())\n\trequire.False(t, p.Has(1))\n\trequire.False(t, p.Has(2))\n\trequire.False(t, p.Has(3))\n}\n\nfunc TestPolicyClose(t *testing.T) {\n\tdefer func() {\n\t\trequire.NotNil(t, recover())\n\t}()\n\n\tp := newDefaultPolicy[int](100, 10)\n\tp.Add(1, 1)\n\tp.Close()\n\tp.itemsCh <- []uint64{1}\n}\n\nfunc TestPushAfterClose(t *testing.T) {\n\tp := newDefaultPolicy[int](100, 10)\n\tp.Close()\n\trequire.False(t, p.Push([]uint64{1, 2}))\n}\n\nfunc TestAddAfterClose(t *testing.T) {\n\tp := newDefaultPolicy[int](100, 10)\n\tp.Close()\n\tp.Add(1, 1)\n}\n\nfunc TestSampledLFUAdd(t *testing.T) {\n\te := newSampledLFU(4)\n\te.add(1, 1)\n\te.add(2, 2)\n\te.add(3, 1)\n\trequire.Equal(t, int64(4), e.used)\n\trequire.Equal(t, int64(2), e.keyCosts[2])\n}\n\nfunc TestSampledLFUDel(t *testing.T) {\n\te := newSampledLFU(4)\n\te.add(1, 1)\n\te.add(2, 2)\n\te.del(2)\n\trequire.Equal(t, int64(1), e.used)\n\t_, ok := e.keyCosts[2]\n\trequire.False(t, ok)\n\te.del(4)\n}\n\nfunc TestSampledLFUUpdate(t *testing.T) {\n\te := newSampledLFU(4)\n\te.add(1, 1)\n\trequire.True(t, e.updateIfHas(1, 2))\n\trequire.Equal(t, int64(2), e.used)\n\trequire.False(t, e.updateIfHas(2, 2))\n}\n\nfunc TestSampledLFUClear(t *testing.T) {\n\te := newSampledLFU(4)\n\te.add(1, 1)\n\te.add(2, 2)\n\te.add(3, 1)\n\te.clear()\n\trequire.Equal(t, 0, len(e.keyCosts))\n\trequire.Equal(t, int64(0), e.used)\n}\n\nfunc TestSampledLFURoom(t *testing.T) {\n\te := newSampledLFU(16)\n\te.add(1, 1)\n\te.add(2, 2)\n\te.add(3, 3)\n\trequire.Equal(t, int64(6), e.roomLeft(4))\n}\n\nfunc TestSampledLFUSample(t *testing.T) {\n\te := newSampledLFU(16)\n\te.add(4, 4)\n\te.add(5, 5)\n\tsample := e.fillSample([]*policyPair{\n\t\t{1, 1},\n\t\t{2, 2},\n\t\t{3, 3},\n\t})\n\tk := sample[len(sample)-1].key\n\trequire.Equal(t, 5, len(sample))\n\trequire.NotEqual(t, 1, k)\n\trequire.NotEqual(t, 2, k)\n\trequire.NotEqual(t, 3, k)\n\trequire.Equal(t, len(sample), len(e.fillSample(sample)))\n\te.del(5)\n\tsample = e.fillSample(sample[:len(sample)-2])\n\trequire.Equal(t, 4, len(sample))\n}\n\nfunc TestTinyLFUIncrement(t *testing.T) {\n\ta := newTinyLFU(4)\n\ta.Increment(1)\n\ta.Increment(1)\n\ta.Increment(1)\n\trequire.True(t, a.door.Has(1))\n\trequire.Equal(t, int64(2), a.freq.Estimate(1))\n\n\ta.Increment(1)\n\trequire.False(t, a.door.Has(1))\n\trequire.Equal(t, int64(1), a.freq.Estimate(1))\n}\n\nfunc TestTinyLFUEstimate(t *testing.T) {\n\ta := newTinyLFU(8)\n\ta.Increment(1)\n\ta.Increment(1)\n\ta.Increment(1)\n\trequire.Equal(t, int64(3), a.Estimate(1))\n\trequire.Equal(t, int64(0), a.Estimate(2))\n}\n\nfunc TestTinyLFUPush(t *testing.T) {\n\ta := newTinyLFU(16)\n\ta.Push([]uint64{1, 2, 2, 3, 3, 3})\n\trequire.Equal(t, int64(1), a.Estimate(1))\n\trequire.Equal(t, int64(2), a.Estimate(2))\n\trequire.Equal(t, int64(3), a.Estimate(3))\n\trequire.Equal(t, int64(6), a.incrs)\n}\n\nfunc TestTinyLFUClear(t *testing.T) {\n\ta := newTinyLFU(16)\n\ta.Push([]uint64{1, 3, 3, 3})\n\ta.clear()\n\trequire.Equal(t, int64(0), a.incrs)\n\trequire.Equal(t, int64(0), a.Estimate(3))\n}\n"
        },
        {
          "name": "ring.go",
          "type": "blob",
          "size": 2.76953125,
          "content": "/*\n * Copyright 2019 Dgraph Labs, Inc. and Contributors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage ristretto\n\nimport (\n\t\"sync\"\n)\n\n// ringConsumer is the user-defined object responsible for receiving and\n// processing items in batches when buffers are drained.\ntype ringConsumer interface {\n\tPush([]uint64) bool\n}\n\n// ringStripe is a singular ring buffer that is not concurrent safe.\ntype ringStripe struct {\n\tcons ringConsumer\n\tdata []uint64\n\tcapa int\n}\n\nfunc newRingStripe(cons ringConsumer, capa int64) *ringStripe {\n\treturn &ringStripe{\n\t\tcons: cons,\n\t\tdata: make([]uint64, 0, capa),\n\t\tcapa: int(capa),\n\t}\n}\n\n// Push appends an item in the ring buffer and drains (copies items and\n// sends to Consumer) if full.\nfunc (s *ringStripe) Push(item uint64) {\n\ts.data = append(s.data, item)\n\t// Decide if the ring buffer should be drained.\n\tif len(s.data) >= s.capa {\n\t\t// Send elements to consumer and create a new ring stripe.\n\t\tif s.cons.Push(s.data) {\n\t\t\ts.data = make([]uint64, 0, s.capa)\n\t\t} else {\n\t\t\ts.data = s.data[:0]\n\t\t}\n\t}\n}\n\n// ringBuffer stores multiple buffers (stripes) and distributes Pushed items\n// between them to lower contention.\n//\n// This implements the \"batching\" process described in the BP-Wrapper paper\n// (section III part A).\ntype ringBuffer struct {\n\tpool *sync.Pool\n}\n\n// newRingBuffer returns a striped ring buffer. The Consumer in ringConfig will\n// be called when individual stripes are full and need to drain their elements.\nfunc newRingBuffer(cons ringConsumer, capa int64) *ringBuffer {\n\t// LOSSY buffers use a very simple sync.Pool for concurrently reusing\n\t// stripes. We do lose some stripes due to GC (unheld items in sync.Pool\n\t// are cleared), but the performance gains generally outweigh the small\n\t// percentage of elements lost. The performance primarily comes from\n\t// low-level runtime functions used in the standard library that aren't\n\t// available to us (such as runtime_procPin()).\n\treturn &ringBuffer{\n\t\tpool: &sync.Pool{\n\t\t\tNew: func() interface{} { return newRingStripe(cons, capa) },\n\t\t},\n\t}\n}\n\n// Push adds an element to one of the internal stripes and possibly drains if\n// the stripe becomes full.\nfunc (b *ringBuffer) Push(item uint64) {\n\t// Reuse or create a new stripe.\n\tstripe := b.pool.Get().(*ringStripe)\n\tstripe.Push(item)\n\tb.pool.Put(stripe)\n}\n"
        },
        {
          "name": "ring_test.go",
          "type": "blob",
          "size": 1.2255859375,
          "content": "package ristretto\n\nimport (\n\t\"sync\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/require\"\n)\n\ntype testConsumer struct {\n\tpush func([]uint64)\n\tsave bool\n}\n\nfunc (c *testConsumer) Push(items []uint64) bool {\n\tif c.save {\n\t\tc.push(items)\n\t\treturn true\n\t}\n\treturn false\n}\n\nfunc TestRingDrain(t *testing.T) {\n\tdrains := 0\n\tr := newRingBuffer(&testConsumer{\n\t\tpush: func(items []uint64) {\n\t\t\tdrains++\n\t\t},\n\t\tsave: true,\n\t}, 1)\n\tfor i := 0; i < 100; i++ {\n\t\tr.Push(uint64(i))\n\t}\n\trequire.Equal(t, 100, drains, \"buffers shouldn't be dropped with BufferItems == 1\")\n}\n\nfunc TestRingReset(t *testing.T) {\n\tdrains := 0\n\tr := newRingBuffer(&testConsumer{\n\t\tpush: func(items []uint64) {\n\t\t\tdrains++\n\t\t},\n\t\tsave: false,\n\t}, 4)\n\tfor i := 0; i < 100; i++ {\n\t\tr.Push(uint64(i))\n\t}\n\trequire.Equal(t, 0, drains, \"testConsumer shouldn't be draining\")\n}\n\nfunc TestRingConsumer(t *testing.T) {\n\tmu := &sync.Mutex{}\n\tdrainItems := make(map[uint64]struct{})\n\tr := newRingBuffer(&testConsumer{\n\t\tpush: func(items []uint64) {\n\t\t\tmu.Lock()\n\t\t\tdefer mu.Unlock()\n\t\t\tfor i := range items {\n\t\t\t\tdrainItems[items[i]] = struct{}{}\n\t\t\t}\n\t\t},\n\t\tsave: true,\n\t}, 4)\n\tfor i := 0; i < 100; i++ {\n\t\tr.Push(uint64(i))\n\t}\n\tl := len(drainItems)\n\trequire.NotEqual(t, 0, l)\n\trequire.True(t, l <= 100)\n}\n"
        },
        {
          "name": "sim",
          "type": "tree",
          "content": null
        },
        {
          "name": "sketch.go",
          "type": "blob",
          "size": 3.275390625,
          "content": "/*\n * Copyright 2019 Dgraph Labs, Inc. and Contributors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage ristretto\n\nimport (\n\t\"fmt\"\n\t\"math/rand\"\n\t\"time\"\n)\n\n// cmSketch is a Count-Min sketch implementation with 4-bit counters, heavily\n// based on Damian Gryski's CM4 [1].\n//\n// [1]: https://github.com/dgryski/go-tinylfu/blob/master/cm4.go\ntype cmSketch struct {\n\trows [cmDepth]cmRow\n\tseed [cmDepth]uint64\n\tmask uint64\n}\n\nconst (\n\t// cmDepth is the number of counter copies to store (think of it as rows).\n\tcmDepth = 4\n)\n\nfunc newCmSketch(numCounters int64) *cmSketch {\n\tif numCounters == 0 {\n\t\tpanic(\"cmSketch: bad numCounters\")\n\t}\n\t// Get the next power of 2 for better cache performance.\n\tnumCounters = next2Power(numCounters)\n\tsketch := &cmSketch{mask: uint64(numCounters - 1)}\n\t// Initialize rows of counters and seeds.\n\t// Cryptographic precision not needed\n\tsource := rand.New(rand.NewSource(time.Now().UnixNano())) //nolint:gosec\n\tfor i := 0; i < cmDepth; i++ {\n\t\tsketch.seed[i] = source.Uint64()\n\t\tsketch.rows[i] = newCmRow(numCounters)\n\t}\n\treturn sketch\n}\n\n// Increment increments the count(ers) for the specified key.\nfunc (s *cmSketch) Increment(hashed uint64) {\n\tfor i := range s.rows {\n\t\ts.rows[i].increment((hashed ^ s.seed[i]) & s.mask)\n\t}\n}\n\n// Estimate returns the value of the specified key.\nfunc (s *cmSketch) Estimate(hashed uint64) int64 {\n\tmin := byte(255)\n\tfor i := range s.rows {\n\t\tval := s.rows[i].get((hashed ^ s.seed[i]) & s.mask)\n\t\tif val < min {\n\t\t\tmin = val\n\t\t}\n\t}\n\treturn int64(min)\n}\n\n// Reset halves all counter values.\nfunc (s *cmSketch) Reset() {\n\tfor _, r := range s.rows {\n\t\tr.reset()\n\t}\n}\n\n// Clear zeroes all counters.\nfunc (s *cmSketch) Clear() {\n\tfor _, r := range s.rows {\n\t\tr.clear()\n\t}\n}\n\n// cmRow is a row of bytes, with each byte holding two counters.\ntype cmRow []byte\n\nfunc newCmRow(numCounters int64) cmRow {\n\treturn make(cmRow, numCounters/2)\n}\n\nfunc (r cmRow) get(n uint64) byte {\n\treturn (r[n/2] >> ((n & 1) * 4)) & 0x0f\n}\n\nfunc (r cmRow) increment(n uint64) {\n\t// Index of the counter.\n\ti := n / 2\n\t// Shift distance (even 0, odd 4).\n\ts := (n & 1) * 4\n\t// Counter value.\n\tv := (r[i] >> s) & 0x0f\n\t// Only increment if not max value (overflow wrap is bad for LFU).\n\tif v < 15 {\n\t\tr[i] += 1 << s\n\t}\n}\n\nfunc (r cmRow) reset() {\n\t// Halve each counter.\n\tfor i := range r {\n\t\tr[i] = (r[i] >> 1) & 0x77\n\t}\n}\n\nfunc (r cmRow) clear() {\n\t// Zero each counter.\n\tfor i := range r {\n\t\tr[i] = 0\n\t}\n}\n\nfunc (r cmRow) string() string {\n\ts := \"\"\n\tfor i := uint64(0); i < uint64(len(r)*2); i++ {\n\t\ts += fmt.Sprintf(\"%02d \", (r[(i/2)]>>((i&1)*4))&0x0f)\n\t}\n\ts = s[:len(s)-1]\n\treturn s\n}\n\n// next2Power rounds x up to the next power of 2, if it's not already one.\nfunc next2Power(x int64) int64 {\n\tx--\n\tx |= x >> 1\n\tx |= x >> 2\n\tx |= x >> 4\n\tx |= x >> 8\n\tx |= x >> 16\n\tx |= x >> 32\n\tx++\n\treturn x\n}\n"
        },
        {
          "name": "sketch_test.go",
          "type": "blob",
          "size": 1.5517578125,
          "content": "package ristretto\n\nimport (\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc TestSketch(t *testing.T) {\n\tdefer func() {\n\t\trequire.NotNil(t, recover())\n\t}()\n\n\ts := newCmSketch(5)\n\trequire.Equal(t, uint64(7), s.mask)\n\tnewCmSketch(0)\n}\n\nfunc TestSketchIncrement(t *testing.T) {\n\ts := newCmSketch(16)\n\ts.Increment(1)\n\ts.Increment(5)\n\ts.Increment(9)\n\tfor i := 0; i < cmDepth; i++ {\n\t\tif s.rows[i].string() != s.rows[0].string() {\n\t\t\tbreak\n\t\t}\n\t\trequire.False(t, i == cmDepth-1, \"identical rows, bad seeding\")\n\t}\n}\n\nfunc TestSketchEstimate(t *testing.T) {\n\ts := newCmSketch(16)\n\ts.Increment(1)\n\ts.Increment(1)\n\trequire.Equal(t, int64(2), s.Estimate(1))\n\trequire.Equal(t, int64(0), s.Estimate(0))\n}\n\nfunc TestSketchReset(t *testing.T) {\n\ts := newCmSketch(16)\n\ts.Increment(1)\n\ts.Increment(1)\n\ts.Increment(1)\n\ts.Increment(1)\n\ts.Reset()\n\trequire.Equal(t, int64(2), s.Estimate(1))\n}\n\nfunc TestSketchClear(t *testing.T) {\n\ts := newCmSketch(16)\n\tfor i := 0; i < 16; i++ {\n\t\ts.Increment(uint64(i))\n\t}\n\ts.Clear()\n\tfor i := 0; i < 16; i++ {\n\t\trequire.Equal(t, int64(0), s.Estimate(uint64(i)))\n\t}\n}\n\nfunc TestNext2Power(t *testing.T) {\n\tsz := 12 << 30\n\tszf := float64(sz) * 0.01\n\tval := int64(szf)\n\tt.Logf(\"szf = %.2f val = %d\\n\", szf, val)\n\tpow := next2Power(val)\n\tt.Logf(\"pow = %d. mult 4 = %d\\n\", pow, pow*4)\n}\n\nfunc BenchmarkSketchIncrement(b *testing.B) {\n\ts := newCmSketch(16)\n\tb.SetBytes(1)\n\tfor n := 0; n < b.N; n++ {\n\t\ts.Increment(1)\n\t}\n}\n\nfunc BenchmarkSketchEstimate(b *testing.B) {\n\ts := newCmSketch(16)\n\ts.Increment(1)\n\tb.SetBytes(1)\n\tfor n := 0; n < b.N; n++ {\n\t\ts.Estimate(1)\n\t}\n}\n"
        },
        {
          "name": "store.go",
          "type": "blob",
          "size": 6.4794921875,
          "content": "/*\n * Copyright 2019 Dgraph Labs, Inc. and Contributors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage ristretto\n\nimport (\n\t\"sync\"\n\t\"time\"\n)\n\ntype updateFn[V any] func(cur, prev V) bool\n\n// TODO: Do we need this to be a separate struct from Item?\ntype storeItem[V any] struct {\n\tkey        uint64\n\tconflict   uint64\n\tvalue      V\n\texpiration time.Time\n}\n\n// store is the interface fulfilled by all hash map implementations in this\n// file. Some hash map implementations are better suited for certain data\n// distributions than others, so this allows us to abstract that out for use\n// in Ristretto.\n//\n// Every store is safe for concurrent usage.\ntype store[V any] interface {\n\t// Get returns the value associated with the key parameter.\n\tGet(uint64, uint64) (V, bool)\n\t// Expiration returns the expiration time for this key.\n\tExpiration(uint64) time.Time\n\t// Set adds the key-value pair to the Map or updates the value if it's\n\t// already present. The key-value pair is passed as a pointer to an\n\t// item object.\n\tSet(*Item[V])\n\t// Del deletes the key-value pair from the Map.\n\tDel(uint64, uint64) (uint64, V)\n\t// Update attempts to update the key with a new value and returns true if\n\t// successful.\n\tUpdate(*Item[V]) (V, bool)\n\t// Cleanup removes items that have an expired TTL.\n\tCleanup(policy *defaultPolicy[V], onEvict func(item *Item[V]))\n\t// Clear clears all contents of the store.\n\tClear(onEvict func(item *Item[V]))\n\tSetShouldUpdateFn(f updateFn[V])\n}\n\n// newStore returns the default store implementation.\nfunc newStore[V any]() store[V] {\n\treturn newShardedMap[V]()\n}\n\nconst numShards uint64 = 256\n\ntype shardedMap[V any] struct {\n\tshards    []*lockedMap[V]\n\texpiryMap *expirationMap[V]\n}\n\nfunc newShardedMap[V any]() *shardedMap[V] {\n\tsm := &shardedMap[V]{\n\t\tshards:    make([]*lockedMap[V], int(numShards)),\n\t\texpiryMap: newExpirationMap[V](),\n\t}\n\tfor i := range sm.shards {\n\t\tsm.shards[i] = newLockedMap[V](sm.expiryMap)\n\t}\n\treturn sm\n}\n\nfunc (m *shardedMap[V]) SetShouldUpdateFn(f updateFn[V]) {\n\tfor i := range m.shards {\n\t\tm.shards[i].setShouldUpdateFn(f)\n\t}\n}\n\nfunc (sm *shardedMap[V]) Get(key, conflict uint64) (V, bool) {\n\treturn sm.shards[key%numShards].get(key, conflict)\n}\n\nfunc (sm *shardedMap[V]) Expiration(key uint64) time.Time {\n\treturn sm.shards[key%numShards].Expiration(key)\n}\n\nfunc (sm *shardedMap[V]) Set(i *Item[V]) {\n\tif i == nil {\n\t\t// If item is nil make this Set a no-op.\n\t\treturn\n\t}\n\n\tsm.shards[i.Key%numShards].Set(i)\n}\n\nfunc (sm *shardedMap[V]) Del(key, conflict uint64) (uint64, V) {\n\treturn sm.shards[key%numShards].Del(key, conflict)\n}\n\nfunc (sm *shardedMap[V]) Update(newItem *Item[V]) (V, bool) {\n\treturn sm.shards[newItem.Key%numShards].Update(newItem)\n}\n\nfunc (sm *shardedMap[V]) Cleanup(policy *defaultPolicy[V], onEvict func(item *Item[V])) {\n\tsm.expiryMap.cleanup(sm, policy, onEvict)\n}\n\nfunc (sm *shardedMap[V]) Clear(onEvict func(item *Item[V])) {\n\tfor i := uint64(0); i < numShards; i++ {\n\t\tsm.shards[i].Clear(onEvict)\n\t}\n\tsm.expiryMap.clear()\n}\n\ntype lockedMap[V any] struct {\n\tsync.RWMutex\n\tdata         map[uint64]storeItem[V]\n\tem           *expirationMap[V]\n\tshouldUpdate updateFn[V]\n}\n\nfunc newLockedMap[V any](em *expirationMap[V]) *lockedMap[V] {\n\treturn &lockedMap[V]{\n\t\tdata: make(map[uint64]storeItem[V]),\n\t\tem:   em,\n\t\tshouldUpdate: func(cur, prev V) bool {\n\t\t\treturn true\n\t\t},\n\t}\n}\n\nfunc (m *lockedMap[V]) setShouldUpdateFn(f updateFn[V]) {\n\tm.shouldUpdate = f\n}\n\nfunc (m *lockedMap[V]) get(key, conflict uint64) (V, bool) {\n\tm.RLock()\n\titem, ok := m.data[key]\n\tm.RUnlock()\n\tif !ok {\n\t\treturn zeroValue[V](), false\n\t}\n\tif conflict != 0 && (conflict != item.conflict) {\n\t\treturn zeroValue[V](), false\n\t}\n\n\t// Handle expired items.\n\tif !item.expiration.IsZero() && time.Now().After(item.expiration) {\n\t\treturn zeroValue[V](), false\n\t}\n\treturn item.value, true\n}\n\nfunc (m *lockedMap[V]) Expiration(key uint64) time.Time {\n\tm.RLock()\n\tdefer m.RUnlock()\n\treturn m.data[key].expiration\n}\n\nfunc (m *lockedMap[V]) Set(i *Item[V]) {\n\tif i == nil {\n\t\t// If the item is nil make this Set a no-op.\n\t\treturn\n\t}\n\n\tm.Lock()\n\tdefer m.Unlock()\n\titem, ok := m.data[i.Key]\n\n\tif ok {\n\t\t// The item existed already. We need to check the conflict key and reject the\n\t\t// update if they do not match. Only after that the expiration map is updated.\n\t\tif i.Conflict != 0 && (i.Conflict != item.conflict) {\n\t\t\treturn\n\t\t}\n\t\tif m.shouldUpdate != nil && !m.shouldUpdate(i.Value, item.value) {\n\t\t\treturn\n\t\t}\n\t\tm.em.update(i.Key, i.Conflict, item.expiration, i.Expiration)\n\t} else {\n\t\t// The value is not in the map already. There's no need to return anything.\n\t\t// Simply add the expiration map.\n\t\tm.em.add(i.Key, i.Conflict, i.Expiration)\n\t}\n\n\tm.data[i.Key] = storeItem[V]{\n\t\tkey:        i.Key,\n\t\tconflict:   i.Conflict,\n\t\tvalue:      i.Value,\n\t\texpiration: i.Expiration,\n\t}\n}\n\nfunc (m *lockedMap[V]) Del(key, conflict uint64) (uint64, V) {\n\tm.Lock()\n\tdefer m.Unlock()\n\titem, ok := m.data[key]\n\tif !ok {\n\t\treturn 0, zeroValue[V]()\n\t}\n\tif conflict != 0 && (conflict != item.conflict) {\n\t\treturn 0, zeroValue[V]()\n\t}\n\n\tif !item.expiration.IsZero() {\n\t\tm.em.del(key, item.expiration)\n\t}\n\n\tdelete(m.data, key)\n\treturn item.conflict, item.value\n}\n\nfunc (m *lockedMap[V]) Update(newItem *Item[V]) (V, bool) {\n\tm.Lock()\n\tdefer m.Unlock()\n\titem, ok := m.data[newItem.Key]\n\tif !ok {\n\t\treturn zeroValue[V](), false\n\t}\n\tif newItem.Conflict != 0 && (newItem.Conflict != item.conflict) {\n\t\treturn zeroValue[V](), false\n\t}\n\tif m.shouldUpdate != nil && !m.shouldUpdate(newItem.Value, item.value) {\n\t\treturn item.value, false\n\t}\n\n\tm.em.update(newItem.Key, newItem.Conflict, item.expiration, newItem.Expiration)\n\tm.data[newItem.Key] = storeItem[V]{\n\t\tkey:        newItem.Key,\n\t\tconflict:   newItem.Conflict,\n\t\tvalue:      newItem.Value,\n\t\texpiration: newItem.Expiration,\n\t}\n\n\treturn item.value, true\n}\n\nfunc (m *lockedMap[V]) Clear(onEvict func(item *Item[V])) {\n\tm.Lock()\n\tdefer m.Unlock()\n\ti := &Item[V]{}\n\tif onEvict != nil {\n\t\tfor _, si := range m.data {\n\t\t\ti.Key = si.key\n\t\t\ti.Conflict = si.conflict\n\t\t\ti.Value = si.value\n\t\t\tonEvict(i)\n\t\t}\n\t}\n\tm.data = make(map[uint64]storeItem[V])\n}\n"
        },
        {
          "name": "store_test.go",
          "type": "blob",
          "size": 4.6328125,
          "content": "package ristretto\n\nimport (\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/dgraph-io/ristretto/v2/z\"\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc TestStoreSetGet(t *testing.T) {\n\ts := newStore[int]()\n\tkey, conflict := z.KeyToHash(1)\n\ti := Item[int]{\n\t\tKey:      key,\n\t\tConflict: conflict,\n\t\tValue:    2,\n\t}\n\ts.Set(&i)\n\tval, ok := s.Get(key, conflict)\n\trequire.True(t, ok)\n\trequire.Equal(t, 2, val)\n\n\ti.Value = 3\n\ts.Set(&i)\n\tval, ok = s.Get(key, conflict)\n\trequire.True(t, ok)\n\trequire.Equal(t, 3, val)\n\n\tkey, conflict = z.KeyToHash(2)\n\ti = Item[int]{\n\t\tKey:      key,\n\t\tConflict: conflict,\n\t\tValue:    2,\n\t}\n\ts.Set(&i)\n\tval, ok = s.Get(key, conflict)\n\trequire.True(t, ok)\n\trequire.Equal(t, 2, val)\n}\n\nfunc TestStoreDel(t *testing.T) {\n\ts := newStore[int]()\n\tkey, conflict := z.KeyToHash(1)\n\ti := Item[int]{\n\t\tKey:      key,\n\t\tConflict: conflict,\n\t\tValue:    1,\n\t}\n\ts.Set(&i)\n\ts.Del(key, conflict)\n\tval, ok := s.Get(key, conflict)\n\trequire.False(t, ok)\n\trequire.Empty(t, val)\n\n\ts.Del(2, 0)\n}\n\nfunc TestStoreClear(t *testing.T) {\n\ts := newStore[uint64]()\n\tfor i := uint64(0); i < 1000; i++ {\n\t\tkey, conflict := z.KeyToHash(i)\n\t\tit := Item[uint64]{\n\t\t\tKey:      key,\n\t\t\tConflict: conflict,\n\t\t\tValue:    i,\n\t\t}\n\t\ts.Set(&it)\n\t}\n\ts.Clear(nil)\n\tfor i := uint64(0); i < 1000; i++ {\n\t\tkey, conflict := z.KeyToHash(i)\n\t\tval, ok := s.Get(key, conflict)\n\t\trequire.False(t, ok)\n\t\trequire.Empty(t, val)\n\t}\n}\n\nfunc TestShouldUpdate(t *testing.T) {\n\t// Create a should update function where the value only increases.\n\ts := newStore[int]()\n\ts.SetShouldUpdateFn(func(cur, prev int) bool {\n\t\treturn cur > prev\n\t})\n\n\tkey, conflict := z.KeyToHash(1)\n\ti := Item[int]{\n\t\tKey:      key,\n\t\tConflict: conflict,\n\t\tValue:    2,\n\t}\n\ts.Set(&i)\n\ti.Value = 1\n\t_, ok := s.Update(&i)\n\trequire.False(t, ok)\n\n\ti.Value = 3\n\t_, ok = s.Update(&i)\n\trequire.True(t, ok)\n}\n\nfunc TestStoreUpdate(t *testing.T) {\n\ts := newStore[int]()\n\tkey, conflict := z.KeyToHash(1)\n\ti := Item[int]{\n\t\tKey:      key,\n\t\tConflict: conflict,\n\t\tValue:    1,\n\t}\n\ts.Set(&i)\n\ti.Value = 2\n\t_, ok := s.Update(&i)\n\trequire.True(t, ok)\n\n\tval, ok := s.Get(key, conflict)\n\trequire.True(t, ok)\n\trequire.NotNil(t, val)\n\n\tval, ok = s.Get(key, conflict)\n\trequire.True(t, ok)\n\trequire.Equal(t, 2, val)\n\n\ti.Value = 3\n\t_, ok = s.Update(&i)\n\trequire.True(t, ok)\n\n\tval, ok = s.Get(key, conflict)\n\trequire.True(t, ok)\n\trequire.Equal(t, 3, val)\n\n\tkey, conflict = z.KeyToHash(2)\n\ti = Item[int]{\n\t\tKey:      key,\n\t\tConflict: conflict,\n\t\tValue:    2,\n\t}\n\t_, ok = s.Update(&i)\n\trequire.False(t, ok)\n\tval, ok = s.Get(key, conflict)\n\trequire.False(t, ok)\n\trequire.Empty(t, val)\n}\n\nfunc TestStoreCollision(t *testing.T) {\n\ts := newShardedMap[int]()\n\ts.shards[1].Lock()\n\ts.shards[1].data[1] = storeItem[int]{\n\t\tkey:      1,\n\t\tconflict: 0,\n\t\tvalue:    1,\n\t}\n\ts.shards[1].Unlock()\n\tval, ok := s.Get(1, 1)\n\trequire.False(t, ok)\n\trequire.Empty(t, val)\n\n\ti := Item[int]{\n\t\tKey:      1,\n\t\tConflict: 1,\n\t\tValue:    2,\n\t}\n\ts.Set(&i)\n\tval, ok = s.Get(1, 0)\n\trequire.True(t, ok)\n\trequire.NotEqual(t, 2, val)\n\n\t_, ok = s.Update(&i)\n\trequire.False(t, ok)\n\tval, ok = s.Get(1, 0)\n\trequire.True(t, ok)\n\trequire.NotEqual(t, 2, val)\n\n\ts.Del(1, 1)\n\tval, ok = s.Get(1, 0)\n\trequire.True(t, ok)\n\trequire.NotEmpty(t, val)\n}\n\nfunc TestStoreExpiration(t *testing.T) {\n\ts := newStore[int]()\n\tkey, conflict := z.KeyToHash(1)\n\texpiration := time.Now().Add(time.Second)\n\ti := Item[int]{\n\t\tKey:        key,\n\t\tConflict:   conflict,\n\t\tValue:      1,\n\t\tExpiration: expiration,\n\t}\n\ts.Set(&i)\n\tval, ok := s.Get(key, conflict)\n\trequire.True(t, ok)\n\trequire.Equal(t, 1, val)\n\n\tttl := s.Expiration(key)\n\trequire.Equal(t, expiration, ttl)\n\n\ts.Del(key, conflict)\n\n\t_, ok = s.Get(key, conflict)\n\trequire.False(t, ok)\n\trequire.True(t, s.Expiration(key).IsZero())\n\n\t// missing item\n\tkey, _ = z.KeyToHash(4340958203495)\n\tttl = s.Expiration(key)\n\trequire.True(t, ttl.IsZero())\n}\n\nfunc BenchmarkStoreGet(b *testing.B) {\n\ts := newStore[int]()\n\tkey, conflict := z.KeyToHash(1)\n\ti := Item[int]{\n\t\tKey:      key,\n\t\tConflict: conflict,\n\t\tValue:    1,\n\t}\n\ts.Set(&i)\n\tb.SetBytes(1)\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tfor pb.Next() {\n\t\t\ts.Get(key, conflict)\n\t\t}\n\t})\n}\n\nfunc BenchmarkStoreSet(b *testing.B) {\n\ts := newStore[int]()\n\tkey, conflict := z.KeyToHash(1)\n\tb.SetBytes(1)\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tfor pb.Next() {\n\t\t\ti := Item[int]{\n\t\t\t\tKey:      key,\n\t\t\t\tConflict: conflict,\n\t\t\t\tValue:    1,\n\t\t\t}\n\t\t\ts.Set(&i)\n\t\t}\n\t})\n}\n\nfunc BenchmarkStoreUpdate(b *testing.B) {\n\ts := newStore[int]()\n\tkey, conflict := z.KeyToHash(1)\n\ti := Item[int]{\n\t\tKey:      key,\n\t\tConflict: conflict,\n\t\tValue:    1,\n\t}\n\ts.Set(&i)\n\tb.SetBytes(1)\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tfor pb.Next() {\n\t\t\ts.Update(&Item[int]{\n\t\t\t\tKey:      key,\n\t\t\t\tConflict: conflict,\n\t\t\t\tValue:    2,\n\t\t\t})\n\t\t}\n\t})\n}\n"
        },
        {
          "name": "stress_test.go",
          "type": "blob",
          "size": 3.46875,
          "content": "package ristretto\n\nimport (\n\t\"container/heap\"\n\t\"fmt\"\n\t\"math/rand\"\n\t\"runtime\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/dgraph-io/ristretto/v2/sim\"\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc TestStressSetGet(t *testing.T) {\n\tc, err := NewCache(&Config[int, int]{\n\t\tNumCounters:        1000,\n\t\tMaxCost:            100,\n\t\tIgnoreInternalCost: true,\n\t\tBufferItems:        64,\n\t\tMetrics:            true,\n\t})\n\trequire.NoError(t, err)\n\n\tfor i := 0; i < 100; i++ {\n\t\tc.Set(i, i, 1)\n\t}\n\ttime.Sleep(wait)\n\twg := &sync.WaitGroup{}\n\tfor i := 0; i < runtime.GOMAXPROCS(0); i++ {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tr := rand.New(rand.NewSource(time.Now().UnixNano()))\n\t\t\tfor a := 0; a < 1000; a++ {\n\t\t\t\tk := r.Int() % 10\n\t\t\t\tif val, ok := c.Get(k); !ok {\n\t\t\t\t\terr = fmt.Errorf(\"expected %d but got nil\", k)\n\t\t\t\t\tbreak\n\t\t\t\t} else if val != 0 && val != k {\n\t\t\t\t\terr = fmt.Errorf(\"expected %d but got %d\", k, val)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\twg.Done()\n\t\t}()\n\t}\n\twg.Wait()\n\trequire.NoError(t, err)\n\trequire.Equal(t, 1.0, c.Metrics.Ratio())\n}\n\nfunc TestStressHitRatio(t *testing.T) {\n\tkey := sim.NewZipfian(1.0001, 1, 1000)\n\tc, err := NewCache(&Config[uint64, uint64]{\n\t\tNumCounters: 1000,\n\t\tMaxCost:     100,\n\t\tBufferItems: 64,\n\t\tMetrics:     true,\n\t})\n\trequire.NoError(t, err)\n\n\to := NewClairvoyant(100)\n\tfor i := 0; i < 10000; i++ {\n\t\tk, err := key()\n\t\trequire.NoError(t, err)\n\n\t\tif _, ok := o.Get(k); !ok {\n\t\t\to.Set(k, k, 1)\n\t\t}\n\t\tif _, ok := c.Get(k); !ok {\n\t\t\tc.Set(k, k, 1)\n\t\t}\n\t}\n\tt.Logf(\"actual: %.2f, optimal: %.2f\", c.Metrics.Ratio(), o.Metrics().Ratio())\n}\n\n// Clairvoyant is a mock cache providing us with optimal hit ratios to compare\n// with Ristretto's. It looks ahead and evicts the absolute least valuable item,\n// which we try to approximate in a real cache.\ntype Clairvoyant struct {\n\tcapacity uint64\n\thits     map[uint64]uint64\n\taccess   []uint64\n}\n\nfunc NewClairvoyant(capacity uint64) *Clairvoyant {\n\treturn &Clairvoyant{\n\t\tcapacity: capacity,\n\t\thits:     make(map[uint64]uint64),\n\t\taccess:   make([]uint64, 0),\n\t}\n}\n\n// Get just records the cache access so that we can later take this event into\n// consideration when calculating the absolute least valuable item to evict.\nfunc (c *Clairvoyant) Get(key interface{}) (interface{}, bool) {\n\tc.hits[key.(uint64)]++\n\tc.access = append(c.access, key.(uint64))\n\treturn nil, false\n}\n\n// Set isn't important because it is only called after a Get (in the case of our\n// hit ratio benchmarks, at least).\nfunc (c *Clairvoyant) Set(key, value interface{}, cost int64) bool {\n\treturn false\n}\n\nfunc (c *Clairvoyant) Metrics() *Metrics {\n\tstat := newMetrics()\n\tlook := make(map[uint64]struct{}, c.capacity)\n\tdata := &clairvoyantHeap{}\n\theap.Init(data)\n\tfor _, key := range c.access {\n\t\tif _, has := look[key]; has {\n\t\t\tstat.add(hit, 0, 1)\n\t\t\tcontinue\n\t\t}\n\t\tif uint64(data.Len()) >= c.capacity {\n\t\t\tvictim := heap.Pop(data)\n\t\t\tdelete(look, victim.(*clairvoyantItem).key)\n\t\t}\n\t\tstat.add(miss, 0, 1)\n\t\tlook[key] = struct{}{}\n\t\theap.Push(data, &clairvoyantItem{key, c.hits[key]})\n\t}\n\treturn stat\n}\n\ntype clairvoyantItem struct {\n\tkey  uint64\n\thits uint64\n}\n\ntype clairvoyantHeap []*clairvoyantItem\n\nfunc (h clairvoyantHeap) Len() int           { return len(h) }\nfunc (h clairvoyantHeap) Less(i, j int) bool { return h[i].hits < h[j].hits }\nfunc (h clairvoyantHeap) Swap(i, j int)      { h[i], h[j] = h[j], h[i] }\n\nfunc (h *clairvoyantHeap) Push(x interface{}) {\n\t*h = append(*h, x.(*clairvoyantItem))\n}\n\nfunc (h *clairvoyantHeap) Pop() interface{} {\n\told := *h\n\tn := len(old)\n\tx := old[n-1]\n\t*h = old[0 : n-1]\n\treturn x\n}\n"
        },
        {
          "name": "ttl.go",
          "type": "blob",
          "size": 4.3828125,
          "content": "/*\n * Copyright 2020 Dgraph Labs, Inc. and Contributors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage ristretto\n\nimport (\n\t\"sync\"\n\t\"time\"\n)\n\nvar (\n\t// TODO: find the optimal value or make it configurable.\n\tbucketDurationSecs = int64(5)\n)\n\nfunc storageBucket(t time.Time) int64 {\n\treturn (t.Unix() / bucketDurationSecs) + 1\n}\n\nfunc cleanupBucket(t time.Time) int64 {\n\t// The bucket to cleanup is always behind the storage bucket by one so that\n\t// no elements in that bucket (which might not have expired yet) are deleted.\n\treturn storageBucket(t) - 1\n}\n\n// bucket type is a map of key to conflict.\ntype bucket map[uint64]uint64\n\n// expirationMap is a map of bucket number to the corresponding bucket.\ntype expirationMap[V any] struct {\n\tsync.RWMutex\n\tbuckets              map[int64]bucket\n\tlastCleanedBucketNum int64\n}\n\nfunc newExpirationMap[V any]() *expirationMap[V] {\n\treturn &expirationMap[V]{\n\t\tbuckets:              make(map[int64]bucket),\n\t\tlastCleanedBucketNum: cleanupBucket(time.Now()),\n\t}\n}\n\nfunc (m *expirationMap[_]) add(key, conflict uint64, expiration time.Time) {\n\tif m == nil {\n\t\treturn\n\t}\n\n\t// Items that don't expire don't need to be in the expiration map.\n\tif expiration.IsZero() {\n\t\treturn\n\t}\n\n\tbucketNum := storageBucket(expiration)\n\tm.Lock()\n\tdefer m.Unlock()\n\n\tb, ok := m.buckets[bucketNum]\n\tif !ok {\n\t\tb = make(bucket)\n\t\tm.buckets[bucketNum] = b\n\t}\n\tb[key] = conflict\n}\n\nfunc (m *expirationMap[_]) update(key, conflict uint64, oldExpTime, newExpTime time.Time) {\n\tif m == nil {\n\t\treturn\n\t}\n\n\tm.Lock()\n\tdefer m.Unlock()\n\n\toldBucketNum := storageBucket(oldExpTime)\n\toldBucket, ok := m.buckets[oldBucketNum]\n\tif ok {\n\t\tdelete(oldBucket, key)\n\t}\n\n\t// Items that don't expire don't need to be in the expiration map.\n\tif newExpTime.IsZero() {\n\t\treturn\n\t}\n\n\tnewBucketNum := storageBucket(newExpTime)\n\tnewBucket, ok := m.buckets[newBucketNum]\n\tif !ok {\n\t\tnewBucket = make(bucket)\n\t\tm.buckets[newBucketNum] = newBucket\n\t}\n\tnewBucket[key] = conflict\n}\n\nfunc (m *expirationMap[_]) del(key uint64, expiration time.Time) {\n\tif m == nil {\n\t\treturn\n\t}\n\n\tbucketNum := storageBucket(expiration)\n\tm.Lock()\n\tdefer m.Unlock()\n\t_, ok := m.buckets[bucketNum]\n\tif !ok {\n\t\treturn\n\t}\n\tdelete(m.buckets[bucketNum], key)\n}\n\n// cleanup removes all the items in the bucket that was just completed. It deletes\n// those items from the store, and calls the onEvict function on those items.\n// This function is meant to be called periodically.\nfunc (m *expirationMap[V]) cleanup(store store[V], policy *defaultPolicy[V], onEvict func(item *Item[V])) int {\n\tif m == nil {\n\t\treturn 0\n\t}\n\n\tm.Lock()\n\tnow := time.Now()\n\tcurrentBucketNum := cleanupBucket(now)\n\t// Clean up all buckets up to and including currentBucketNum, starting from\n\t// (but not including) the last one that was cleaned up\n\tvar buckets []bucket\n\tfor bucketNum := m.lastCleanedBucketNum + 1; bucketNum <= currentBucketNum; bucketNum++ {\n\t\t// With an empty bucket, we don't need to add it to the Clean list\n\t\tif b := m.buckets[bucketNum]; b != nil {\n\t\t\tbuckets = append(buckets, b)\n\t\t}\n\t\tdelete(m.buckets, bucketNum)\n\t}\n\tm.lastCleanedBucketNum = currentBucketNum\n\tm.Unlock()\n\n\tfor _, keys := range buckets {\n\t\tfor key, conflict := range keys {\n\t\t\texpr := store.Expiration(key)\n\t\t\t// Sanity check. Verify that the store agrees that this key is expired.\n\t\t\tif expr.After(now) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tcost := policy.Cost(key)\n\t\t\tpolicy.Del(key)\n\t\t\t_, value := store.Del(key, conflict)\n\n\t\t\tif onEvict != nil {\n\t\t\t\tonEvict(&Item[V]{Key: key,\n\t\t\t\t\tConflict:   conflict,\n\t\t\t\t\tValue:      value,\n\t\t\t\t\tCost:       cost,\n\t\t\t\t\tExpiration: expr,\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\t}\n\n\tcleanedBucketsCount := len(buckets)\n\n\treturn cleanedBucketsCount\n}\n\n// clear clears the expirationMap, the caller is responsible for properly\n// evicting the referenced items\nfunc (m *expirationMap[V]) clear() {\n\tif m == nil {\n\t\treturn\n\t}\n\n\tm.Lock()\n\tm.buckets = make(map[int64]bucket)\n\tm.lastCleanedBucketNum = cleanupBucket(time.Now())\n\tm.Unlock()\n}\n"
        },
        {
          "name": "ttl_test.go",
          "type": "blob",
          "size": 2.673828125,
          "content": "package ristretto\n\nimport (\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/stretchr/testify/require\"\n)\n\n// TestExpirationMapCleanup tests the cleanup functionality of the expiration map.\n// It verifies that expired items are correctly evicted from the store and that\n// non-expired items remain in the store.\nfunc TestExpirationMapCleanup(t *testing.T) {\n\t// Create a new expiration map\n\tem := newExpirationMap[int]()\n\t// Create a new store\n\ts := newShardedMap[int]()\n\t// Create a new policy\n\tp := newDefaultPolicy[int](100, 10)\n\n\t// Add items to the store and expiration map\n\tnow := time.Now()\n\ti1 := &Item[int]{Key: 1, Conflict: 1, Value: 100, Expiration: now.Add(1 * time.Second)}\n\ts.Set(i1)\n\tem.add(i1.Key, i1.Conflict, i1.Expiration)\n\n\ti2 := &Item[int]{Key: 2, Conflict: 2, Value: 200, Expiration: now.Add(3 * time.Second)}\n\ts.Set(i2)\n\tem.add(i2.Key, i2.Conflict, i2.Expiration)\n\n\t// Create a map to store evicted items\n\tevictedItems := make(map[uint64]int)\n\tevictedItemsOnEvictFunc := func(item *Item[int]) {\n\t\tevictedItems[item.Key] = item.Value\n\t}\n\n\t// Wait for the first item to expire\n\ttime.Sleep(2 * time.Second)\n\n\t// Cleanup the expiration map\n\tcleanedBucketsCount := em.cleanup(s, p, evictedItemsOnEvictFunc)\n\trequire.Equal(t, 1, cleanedBucketsCount, \"cleanedBucketsCount should be 1 after first cleanup\")\n\n\t// Check that the first item was evicted\n\trequire.Equal(t, 1, len(evictedItems), \"evictedItems should have 1 item\")\n\trequire.Equal(t, 100, evictedItems[1], \"evictedItems should have the first item\")\n\t_, ok := s.Get(i1.Key, i1.Conflict)\n\trequire.False(t, ok, \"i1 should have been evicted\")\n\n\t// Check that the second item is still in the store\n\t_, ok = s.Get(i2.Key, i2.Conflict)\n\trequire.True(t, ok, \"i2 should still be in the store\")\n\n\t// Wait for the second item to expire\n\ttime.Sleep(2 * time.Second)\n\n\t// Cleanup the expiration map\n\tcleanedBucketsCount = em.cleanup(s, p, evictedItemsOnEvictFunc)\n\trequire.Equal(t, 1, cleanedBucketsCount, \"cleanedBucketsCount should be 1 after second cleanup\")\n\n\t// Check that the second item was evicted\n\trequire.Equal(t, 2, len(evictedItems), \"evictedItems should have 2 items\")\n\trequire.Equal(t, 200, evictedItems[2], \"evictedItems should have the second item\")\n\t_, ok = s.Get(i2.Key, i2.Conflict)\n\trequire.False(t, ok, \"i2 should have been evicted\")\n\n\tt.Run(\"Miscalculation of buckets does not cause memory leaks\", func(t *testing.T) {\n\t\t// Break lastCleanedBucketNum, this can happen if the system time is changed.\n\t\tem.lastCleanedBucketNum = storageBucket(now.AddDate(-1, 0, 0))\n\n\t\tcleanedBucketsCount = em.cleanup(s, p, evictedItemsOnEvictFunc)\n\t\trequire.Equal(t,\n\t\t\t0, cleanedBucketsCount,\n\t\t\t\"cleanedBucketsCount should be 0 after cleanup with lastCleanedBucketNum change\",\n\t\t)\n\t})\n}\n"
        },
        {
          "name": "z",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}