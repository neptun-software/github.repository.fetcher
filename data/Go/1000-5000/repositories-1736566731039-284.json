{
  "metadata": {
    "timestamp": 1736566731039,
    "page": 284,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "testcontainers/testcontainers-go",
      "stars": 3766,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".devcontainer",
          "type": "tree",
          "content": null
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.216796875,
          "content": "# Generated by golang tooling\ndebug.test\nvendor\n\n# Generated docs\nsite/\n.direnv/\nsrc/mkdocs-codeinclude-plugin\nsrc/pip-delete-this-directory.txt\n.idea/\n.DS_Store\n\nTEST-*.xml\n\ntcvenv\n\n**/go.work\n\n# VS Code settings\n.vscode\n"
        },
        {
          "name": ".golangci.yml",
          "type": "blob",
          "size": 0.84765625,
          "content": "linters:\n  enable:\n    - errcheck\n    - errorlint\n    - gci\n    - gocritic\n    - gofumpt\n    - misspell\n    - nolintlint\n    - nakedret\n    - perfsprint\n    - testifylint\n    - thelper\n    - usestdlibvars\n\nlinters-settings:\n  nakedret:\n    max-func-lines: 0\n  errorlint:\n    # Check whether fmt.Errorf uses the %w verb for formatting errors.\n    # See the https://github.com/polyfloyd/go-errorlint for caveats.\n    errorf: true\n    # Permit more than 1 %w verb, valid per Go 1.20 (Requires errorf:true)\n    errorf-multi: true\n    # Check for plain type assertions and type switches.\n    asserts: true\n    # Check for plain error comparisons.\n    comparison: true\n  gci:\n    sections:\n      - standard\n      - default\n      - prefix(github.com/testcontainers)\n  testifylint:\n    disable:\n      - float-compare\n      - go-require\n    enable-all: true\nrun:\n  timeout: 5m\n"
        },
        {
          "name": ".mockery.yaml",
          "type": "blob",
          "size": 0.2998046875,
          "content": "quiet: True\ndisable-version-string: True\nwith-expecter: True\nmockname: \"mock{{.InterfaceName}}\"\nfilename: \"{{ .InterfaceName | lower }}_mock_test.go\"\noutpkg: \"{{.PackageName}}_test\"\ndir: \"{{.InterfaceDir}}\"\npackages:\n  github.com/testcontainers/testcontainers-go/wait:\n    interfaces:\n      StrategyTarget:\n"
        },
        {
          "name": ".vscode",
          "type": "tree",
          "content": null
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.5712890625,
          "content": "# Contributing\n\nPlease see the [main contributing guidelines](./docs/contributing.md).\n\nThere are additional docs describing [contributing documentation changes](./docs/contributing_docs.md).\n\n### GitHub Sponsorship\n\nTestcontainers is [in the GitHub Sponsors program](https://github.com/sponsors/testcontainers)!\n\nThis repository is supported by our sponsors, meaning that issues are eligible to have a 'bounty' attached to them by sponsors.\n\nPlease see [the bounty policy page](https://golang.testcontainers.org/bounty) if you are interested, either as a sponsor or as a contributor.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.064453125,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2017-2019 Gianluca Arbezzano\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.8916015625,
          "content": "include ./commons-test.mk\n\n.PHONY: lint-all\nlint-all:\n\t$(MAKE) lint\n\t$(MAKE) -C modulegen lint\n\t$(MAKE) -C examples lint-examples\n\t$(MAKE) -C modules lint-modules\n\n.PHONY: test-all\ntest-all: tools test-tools test-unit\n\n.PHONY: test-examples\ntest-examples:\n\t@echo \"Running example tests...\"\n\t$(MAKE) -C examples test\n\n.PHONY: tidy-all\ntidy-all:\n\t$(MAKE) tidy\n\t$(MAKE) -C examples tidy-examples\n\t$(MAKE) -C modules tidy-modules\n\n## --------------------------------------\n\nTCENV=tcvenv\nPYTHONBIN=./$(TCENV)/bin\n\ntcvenv: tcvenv/touchfile\n\ntcvenv/touchfile:\n\t@echo \"Creating docs $(TCENV)...\"\n\ttest -d $(TCENV) || python3 -m venv $(TCENV)\n\t@echo \"Installing requirements...\"\n\t. $(PYTHONBIN)/activate; pip install -Ur requirements.txt\n\ttouch $(TCENV)/touchfile\n\nclean-docs:\n\t@echo \"Destroying docs $(TCENV)...\"\n\trm -rf $(TCENV)\n\n.PHONY: serve-docs\nserve-docs: tcvenv\n\t. $(PYTHONBIN)/activate; $(PYTHONBIN)/mkdocs serve\n"
        },
        {
          "name": "Pipfile",
          "type": "blob",
          "size": 0.3037109375,
          "content": "[[source]]\nname = \"pypi\"\nurl = \"https://pypi.org/simple\"\nverify_ssl = true\n\n[dev-packages]\n\n[packages]\nmkdocs = \"==1.5.3\"\nmkdocs-codeinclude-plugin = \"==0.2.1\"\nmkdocs-include-markdown-plugin = \"==6.2.2\"\nmkdocs-material = \"==9.5.18\"\nmkdocs-markdownextradata-plugin = \"==0.2.6\"\n\n[requires]\npython_version = \"3.8\"\n"
        },
        {
          "name": "Pipfile.lock",
          "type": "blob",
          "size": 39.87890625,
          "content": "{\n    \"_meta\": {\n        \"hash\": {\n            \"sha256\": \"0411eac13d1b06b42671b8a654fb269eb0c329d9a3d41f669ccf7b653ef8ad32\"\n        },\n        \"pipfile-spec\": 6,\n        \"requires\": {\n            \"python_version\": \"3.8\"\n        },\n        \"sources\": [\n            {\n                \"name\": \"pypi\",\n                \"url\": \"https://pypi.org/simple\",\n                \"verify_ssl\": true\n            }\n        ]\n    },\n    \"default\": {\n        \"babel\": {\n            \"hashes\": [\n                \"sha256:6919867db036398ba21eb5c7a0f6b28ab8cbc3ae7a73a44ebe34ae74a4e7d363\",\n                \"sha256:efb1a25b7118e67ce3a259bed20545c29cb68be8ad2c784c83689981b7a57287\"\n            ],\n            \"markers\": \"python_version >= '3.7'\",\n            \"version\": \"==2.14.0\"\n        },\n        \"bracex\": {\n            \"hashes\": [\n                \"sha256:0725da5045e8d37ea9592ab3614d8b561e22c3c5fde3964699be672e072ab611\",\n                \"sha256:d2fcf4b606a82ac325471affe1706dd9bbaa3536c91ef86a31f6b766f3dad1d0\"\n            ],\n            \"markers\": \"python_version >= '3.8'\",\n            \"version\": \"==2.5\"\n        },\n        \"certifi\": {\n            \"hashes\": [\n                \"sha256:5a1e7645bc0ec61a09e26c36f6106dd4cf40c6db3a1fb6352b0244e7fb057c7b\",\n                \"sha256:c198e21b1289c2ab85ee4e67bb4b4ef3ead0892059901a8d5b622f24a1101e90\"\n            ],\n            \"index\": \"pypi\",\n            \"markers\": \"python_version >= '3.6'\",\n            \"version\": \"==2024.7.4\"\n        },\n        \"charset-normalizer\": {\n            \"hashes\": [\n                \"sha256:06435b539f889b1f6f4ac1758871aae42dc3a8c0e24ac9e60c2384973ad73027\",\n                \"sha256:06a81e93cd441c56a9b65d8e1d043daeb97a3d0856d177d5c90ba85acb3db087\",\n                \"sha256:0a55554a2fa0d408816b3b5cedf0045f4b8e1a6065aec45849de2d6f3f8e9786\",\n                \"sha256:0b2b64d2bb6d3fb9112bafa732def486049e63de9618b5843bcdd081d8144cd8\",\n                \"sha256:10955842570876604d404661fbccbc9c7e684caf432c09c715ec38fbae45ae09\",\n                \"sha256:122c7fa62b130ed55f8f285bfd56d5f4b4a5b503609d181f9ad85e55c89f4185\",\n                \"sha256:1ceae2f17a9c33cb48e3263960dc5fc8005351ee19db217e9b1bb15d28c02574\",\n                \"sha256:1d3193f4a680c64b4b6a9115943538edb896edc190f0b222e73761716519268e\",\n                \"sha256:1f79682fbe303db92bc2b1136016a38a42e835d932bab5b3b1bfcfbf0640e519\",\n                \"sha256:2127566c664442652f024c837091890cb1942c30937add288223dc895793f898\",\n                \"sha256:22afcb9f253dac0696b5a4be4a1c0f8762f8239e21b99680099abd9b2b1b2269\",\n                \"sha256:25baf083bf6f6b341f4121c2f3c548875ee6f5339300e08be3f2b2ba1721cdd3\",\n                \"sha256:2e81c7b9c8979ce92ed306c249d46894776a909505d8f5a4ba55b14206e3222f\",\n                \"sha256:3287761bc4ee9e33561a7e058c72ac0938c4f57fe49a09eae428fd88aafe7bb6\",\n                \"sha256:34d1c8da1e78d2e001f363791c98a272bb734000fcef47a491c1e3b0505657a8\",\n                \"sha256:37e55c8e51c236f95b033f6fb391d7d7970ba5fe7ff453dad675e88cf303377a\",\n                \"sha256:3d47fa203a7bd9c5b6cee4736ee84ca03b8ef23193c0d1ca99b5089f72645c73\",\n                \"sha256:3e4d1f6587322d2788836a99c69062fbb091331ec940e02d12d179c1d53e25fc\",\n                \"sha256:42cb296636fcc8b0644486d15c12376cb9fa75443e00fb25de0b8602e64c1714\",\n                \"sha256:45485e01ff4d3630ec0d9617310448a8702f70e9c01906b0d0118bdf9d124cf2\",\n                \"sha256:4a78b2b446bd7c934f5dcedc588903fb2f5eec172f3d29e52a9096a43722adfc\",\n                \"sha256:4ab2fe47fae9e0f9dee8c04187ce5d09f48eabe611be8259444906793ab7cbce\",\n                \"sha256:4d0d1650369165a14e14e1e47b372cfcb31d6ab44e6e33cb2d4e57265290044d\",\n                \"sha256:549a3a73da901d5bc3ce8d24e0600d1fa85524c10287f6004fbab87672bf3e1e\",\n                \"sha256:55086ee1064215781fff39a1af09518bc9255b50d6333f2e4c74ca09fac6a8f6\",\n                \"sha256:572c3763a264ba47b3cf708a44ce965d98555f618ca42c926a9c1616d8f34269\",\n                \"sha256:573f6eac48f4769d667c4442081b1794f52919e7edada77495aaed9236d13a96\",\n                \"sha256:5b4c145409bef602a690e7cfad0a15a55c13320ff7a3ad7ca59c13bb8ba4d45d\",\n                \"sha256:6463effa3186ea09411d50efc7d85360b38d5f09b870c48e4600f63af490e56a\",\n                \"sha256:65f6f63034100ead094b8744b3b97965785388f308a64cf8d7c34f2f2e5be0c4\",\n                \"sha256:663946639d296df6a2bb2aa51b60a2454ca1cb29835324c640dafb5ff2131a77\",\n                \"sha256:6897af51655e3691ff853668779c7bad41579facacf5fd7253b0133308cf000d\",\n                \"sha256:68d1f8a9e9e37c1223b656399be5d6b448dea850bed7d0f87a8311f1ff3dabb0\",\n                \"sha256:6ac7ffc7ad6d040517be39eb591cac5ff87416c2537df6ba3cba3bae290c0fed\",\n                \"sha256:6b3251890fff30ee142c44144871185dbe13b11bab478a88887a639655be1068\",\n                \"sha256:6c4caeef8fa63d06bd437cd4bdcf3ffefe6738fb1b25951440d80dc7df8c03ac\",\n                \"sha256:6ef1d82a3af9d3eecdba2321dc1b3c238245d890843e040e41e470ffa64c3e25\",\n                \"sha256:753f10e867343b4511128c6ed8c82f7bec3bd026875576dfd88483c5c73b2fd8\",\n                \"sha256:7cd13a2e3ddeed6913a65e66e94b51d80a041145a026c27e6bb76c31a853c6ab\",\n                \"sha256:7ed9e526742851e8d5cc9e6cf41427dfc6068d4f5a3bb03659444b4cabf6bc26\",\n                \"sha256:7f04c839ed0b6b98b1a7501a002144b76c18fb1c1850c8b98d458ac269e26ed2\",\n                \"sha256:802fe99cca7457642125a8a88a084cef28ff0cf9407060f7b93dca5aa25480db\",\n                \"sha256:80402cd6ee291dcb72644d6eac93785fe2c8b9cb30893c1af5b8fdd753b9d40f\",\n                \"sha256:8465322196c8b4d7ab6d1e049e4c5cb460d0394da4a27d23cc242fbf0034b6b5\",\n                \"sha256:86216b5cee4b06df986d214f664305142d9c76df9b6512be2738aa72a2048f99\",\n                \"sha256:87d1351268731db79e0f8e745d92493ee2841c974128ef629dc518b937d9194c\",\n                \"sha256:8bdb58ff7ba23002a4c5808d608e4e6c687175724f54a5dade5fa8c67b604e4d\",\n                \"sha256:8c622a5fe39a48f78944a87d4fb8a53ee07344641b0562c540d840748571b811\",\n                \"sha256:8d756e44e94489e49571086ef83b2bb8ce311e730092d2c34ca8f7d925cb20aa\",\n                \"sha256:8f4a014bc36d3c57402e2977dada34f9c12300af536839dc38c0beab8878f38a\",\n                \"sha256:9063e24fdb1e498ab71cb7419e24622516c4a04476b17a2dab57e8baa30d6e03\",\n                \"sha256:90d558489962fd4918143277a773316e56c72da56ec7aa3dc3dbbe20fdfed15b\",\n                \"sha256:923c0c831b7cfcb071580d3f46c4baf50f174be571576556269530f4bbd79d04\",\n                \"sha256:95f2a5796329323b8f0512e09dbb7a1860c46a39da62ecb2324f116fa8fdc85c\",\n                \"sha256:96b02a3dc4381e5494fad39be677abcb5e6634bf7b4fa83a6dd3112607547001\",\n                \"sha256:9f96df6923e21816da7e0ad3fd47dd8f94b2a5ce594e00677c0013018b813458\",\n                \"sha256:a10af20b82360ab00827f916a6058451b723b4e65030c5a18577c8b2de5b3389\",\n                \"sha256:a50aebfa173e157099939b17f18600f72f84eed3049e743b68ad15bd69b6bf99\",\n                \"sha256:a981a536974bbc7a512cf44ed14938cf01030a99e9b3a06dd59578882f06f985\",\n                \"sha256:a9a8e9031d613fd2009c182b69c7b2c1ef8239a0efb1df3f7c8da66d5dd3d537\",\n                \"sha256:ae5f4161f18c61806f411a13b0310bea87f987c7d2ecdbdaad0e94eb2e404238\",\n                \"sha256:aed38f6e4fb3f5d6bf81bfa990a07806be9d83cf7bacef998ab1a9bd660a581f\",\n                \"sha256:b01b88d45a6fcb69667cd6d2f7a9aeb4bf53760d7fc536bf679ec94fe9f3ff3d\",\n                \"sha256:b261ccdec7821281dade748d088bb6e9b69e6d15b30652b74cbbac25e280b796\",\n                \"sha256:b2b0a0c0517616b6869869f8c581d4eb2dd83a4d79e0ebcb7d373ef9956aeb0a\",\n                \"sha256:b4a23f61ce87adf89be746c8a8974fe1c823c891d8f86eb218bb957c924bb143\",\n                \"sha256:bd8f7df7d12c2db9fab40bdd87a7c09b1530128315d047a086fa3ae3435cb3a8\",\n                \"sha256:beb58fe5cdb101e3a055192ac291b7a21e3b7ef4f67fa1d74e331a7f2124341c\",\n                \"sha256:c002b4ffc0be611f0d9da932eb0f704fe2602a9a949d1f738e4c34c75b0863d5\",\n                \"sha256:c083af607d2515612056a31f0a8d9e0fcb5876b7bfc0abad3ecd275bc4ebc2d5\",\n                \"sha256:c180f51afb394e165eafe4ac2936a14bee3eb10debc9d9e4db8958fe36afe711\",\n                \"sha256:c235ebd9baae02f1b77bcea61bce332cb4331dc3617d254df3323aa01ab47bd4\",\n                \"sha256:cd70574b12bb8a4d2aaa0094515df2463cb429d8536cfb6c7ce983246983e5a6\",\n                \"sha256:d0eccceffcb53201b5bfebb52600a5fb483a20b61da9dbc885f8b103cbe7598c\",\n                \"sha256:d965bba47ddeec8cd560687584e88cf699fd28f192ceb452d1d7ee807c5597b7\",\n                \"sha256:db364eca23f876da6f9e16c9da0df51aa4f104a972735574842618b8c6d999d4\",\n                \"sha256:ddbb2551d7e0102e7252db79ba445cdab71b26640817ab1e3e3648dad515003b\",\n                \"sha256:deb6be0ac38ece9ba87dea880e438f25ca3eddfac8b002a2ec3d9183a454e8ae\",\n                \"sha256:e06ed3eb3218bc64786f7db41917d4e686cc4856944f53d5bdf83a6884432e12\",\n                \"sha256:e27ad930a842b4c5eb8ac0016b0a54f5aebbe679340c26101df33424142c143c\",\n                \"sha256:e537484df0d8f426ce2afb2d0f8e1c3d0b114b83f8850e5f2fbea0e797bd82ae\",\n                \"sha256:eb00ed941194665c332bf8e078baf037d6c35d7c4f3102ea2d4f16ca94a26dc8\",\n                \"sha256:eb6904c354526e758fda7167b33005998fb68c46fbc10e013ca97f21ca5c8887\",\n                \"sha256:eb8821e09e916165e160797a6c17edda0679379a4be5c716c260e836e122f54b\",\n                \"sha256:efcb3f6676480691518c177e3b465bcddf57cea040302f9f4e6e191af91174d4\",\n                \"sha256:f27273b60488abe721a075bcca6d7f3964f9f6f067c8c4c605743023d7d3944f\",\n                \"sha256:f30c3cb33b24454a82faecaf01b19c18562b1e89558fb6c56de4d9118a032fd5\",\n                \"sha256:fb69256e180cb6c8a894fee62b3afebae785babc1ee98b81cdf68bbca1987f33\",\n                \"sha256:fd1abc0d89e30cc4e02e4064dc67fcc51bd941eb395c502aac3ec19fab46b519\",\n                \"sha256:ff8fa367d09b717b2a17a052544193ad76cd49979c805768879cb63d9ca50561\"\n            ],\n            \"markers\": \"python_full_version >= '3.7.0'\",\n            \"version\": \"==3.3.2\"\n        },\n        \"click\": {\n            \"hashes\": [\n                \"sha256:ae74fb96c20a0277a1d615f1e4d73c8414f5a98db8b799a7931d1582f3390c28\",\n                \"sha256:ca9853ad459e787e2192211578cc907e7594e294c7ccc834310722b41b9ca6de\"\n            ],\n            \"markers\": \"python_version >= '3.7'\",\n            \"version\": \"==8.1.7\"\n        },\n        \"colorama\": {\n            \"hashes\": [\n                \"sha256:08695f5cb7ed6e0531a20572697297273c47b8cae5a63ffc6d6ed5c201be6e44\",\n                \"sha256:4f1d9991f5acc0ca119f9d443620b77f9d6b33703e51011c16baf57afb285fc6\"\n            ],\n            \"markers\": \"python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6'\",\n            \"version\": \"==0.4.6\"\n        },\n        \"ghp-import\": {\n            \"hashes\": [\n                \"sha256:8337dd7b50877f163d4c0289bc1f1c7f127550241988d568c1db512c4324a619\",\n                \"sha256:9c535c4c61193c2df8871222567d7fd7e5014d835f97dc7b7439069e2413d343\"\n            ],\n            \"version\": \"==2.1.0\"\n        },\n        \"idna\": {\n            \"hashes\": [\n                \"sha256:028ff3aadf0609c1fd278d8ea3089299412a7a8b9bd005dd08b9f8285bcb5cfc\",\n                \"sha256:82fee1fc78add43492d3a1898bfa6d8a904cc97d8427f683ed8e798d07761aa0\"\n            ],\n            \"markers\": \"python_version >= '3.5'\",\n            \"version\": \"==3.7\"\n        },\n        \"importlib-metadata\": {\n            \"hashes\": [\n                \"sha256:66f342cc6ac9818fc6ff340576acd24d65ba0b3efabb2b4ac08b598965a4a2f1\",\n                \"sha256:9a547d3bc3608b025f93d403fdd1aae741c24fbb8314df4b155675742ce303c5\"\n            ],\n            \"markers\": \"python_version < '3.10'\",\n            \"version\": \"==8.4.0\"\n        },\n        \"jinja2\": {\n            \"hashes\": [\n                \"sha256:8fefff8dc3034e27bb80d67c671eb8a9bc424c0ef4c0826edbff304cceff43bb\",\n                \"sha256:aba0f4dc9ed8013c424088f68a5c226f7d6097ed89b246d7749c2ec4175c6adb\"\n            ],\n            \"index\": \"pypi\",\n            \"markers\": \"python_version >= '3.7'\",\n            \"version\": \"==3.1.5\"\n        },\n        \"markdown\": {\n            \"hashes\": [\n                \"sha256:2ae2471477cfd02dbbf038d5d9bc226d40def84b4fe2986e49b59b6b472bbed2\",\n                \"sha256:7eb6df5690b81a1d7942992c97fad2938e956e79df20cbc6186e9c3a77b1c803\"\n            ],\n            \"markers\": \"python_version >= '3.8'\",\n            \"version\": \"==3.7\"\n        },\n        \"markupsafe\": {\n            \"hashes\": [\n                \"sha256:00e046b6dd71aa03a41079792f8473dc494d564611a8f89bbbd7cb93295ebdcf\",\n                \"sha256:075202fa5b72c86ad32dc7d0b56024ebdbcf2048c0ba09f1cde31bfdd57bcfff\",\n                \"sha256:0e397ac966fdf721b2c528cf028494e86172b4feba51d65f81ffd65c63798f3f\",\n                \"sha256:17b950fccb810b3293638215058e432159d2b71005c74371d784862b7e4683f3\",\n                \"sha256:1f3fbcb7ef1f16e48246f704ab79d79da8a46891e2da03f8783a5b6fa41a9532\",\n                \"sha256:2174c595a0d73a3080ca3257b40096db99799265e1c27cc5a610743acd86d62f\",\n                \"sha256:2b7c57a4dfc4f16f7142221afe5ba4e093e09e728ca65c51f5620c9aaeb9a617\",\n                \"sha256:2d2d793e36e230fd32babe143b04cec8a8b3eb8a3122d2aceb4a371e6b09b8df\",\n                \"sha256:30b600cf0a7ac9234b2638fbc0fb6158ba5bdcdf46aeb631ead21248b9affbc4\",\n                \"sha256:397081c1a0bfb5124355710fe79478cdbeb39626492b15d399526ae53422b906\",\n                \"sha256:3a57fdd7ce31c7ff06cdfbf31dafa96cc533c21e443d57f5b1ecc6cdc668ec7f\",\n                \"sha256:3c6b973f22eb18a789b1460b4b91bf04ae3f0c4234a0a6aa6b0a92f6f7b951d4\",\n                \"sha256:3e53af139f8579a6d5f7b76549125f0d94d7e630761a2111bc431fd820e163b8\",\n                \"sha256:4096e9de5c6fdf43fb4f04c26fb114f61ef0bf2e5604b6ee3019d51b69e8c371\",\n                \"sha256:4275d846e41ecefa46e2015117a9f491e57a71ddd59bbead77e904dc02b1bed2\",\n                \"sha256:4c31f53cdae6ecfa91a77820e8b151dba54ab528ba65dfd235c80b086d68a465\",\n                \"sha256:4f11aa001c540f62c6166c7726f71f7573b52c68c31f014c25cc7901deea0b52\",\n                \"sha256:5049256f536511ee3f7e1b3f87d1d1209d327e818e6ae1365e8653d7e3abb6a6\",\n                \"sha256:58c98fee265677f63a4385256a6d7683ab1832f3ddd1e66fe948d5880c21a169\",\n                \"sha256:598e3276b64aff0e7b3451b72e94fa3c238d452e7ddcd893c3ab324717456bad\",\n                \"sha256:5b7b716f97b52c5a14bffdf688f971b2d5ef4029127f1ad7a513973cfd818df2\",\n                \"sha256:5dedb4db619ba5a2787a94d877bc8ffc0566f92a01c0ef214865e54ecc9ee5e0\",\n                \"sha256:619bc166c4f2de5caa5a633b8b7326fbe98e0ccbfacabd87268a2b15ff73a029\",\n                \"sha256:629ddd2ca402ae6dbedfceeba9c46d5f7b2a61d9749597d4307f943ef198fc1f\",\n                \"sha256:656f7526c69fac7f600bd1f400991cc282b417d17539a1b228617081106feb4a\",\n                \"sha256:6ec585f69cec0aa07d945b20805be741395e28ac1627333b1c5b0105962ffced\",\n                \"sha256:72b6be590cc35924b02c78ef34b467da4ba07e4e0f0454a2c5907f473fc50ce5\",\n                \"sha256:7502934a33b54030eaf1194c21c692a534196063db72176b0c4028e140f8f32c\",\n                \"sha256:7a68b554d356a91cce1236aa7682dc01df0edba8d043fd1ce607c49dd3c1edcf\",\n                \"sha256:7b2e5a267c855eea6b4283940daa6e88a285f5f2a67f2220203786dfa59b37e9\",\n                \"sha256:823b65d8706e32ad2df51ed89496147a42a2a6e01c13cfb6ffb8b1e92bc910bb\",\n                \"sha256:8590b4ae07a35970728874632fed7bd57b26b0102df2d2b233b6d9d82f6c62ad\",\n                \"sha256:8dd717634f5a044f860435c1d8c16a270ddf0ef8588d4887037c5028b859b0c3\",\n                \"sha256:8dec4936e9c3100156f8a2dc89c4b88d5c435175ff03413b443469c7c8c5f4d1\",\n                \"sha256:97cafb1f3cbcd3fd2b6fbfb99ae11cdb14deea0736fc2b0952ee177f2b813a46\",\n                \"sha256:a17a92de5231666cfbe003f0e4b9b3a7ae3afb1ec2845aadc2bacc93ff85febc\",\n                \"sha256:a549b9c31bec33820e885335b451286e2969a2d9e24879f83fe904a5ce59d70a\",\n                \"sha256:ac07bad82163452a6884fe8fa0963fb98c2346ba78d779ec06bd7a6262132aee\",\n                \"sha256:ae2ad8ae6ebee9d2d94b17fb62763125f3f374c25618198f40cbb8b525411900\",\n                \"sha256:b91c037585eba9095565a3556f611e3cbfaa42ca1e865f7b8015fe5c7336d5a5\",\n                \"sha256:bc1667f8b83f48511b94671e0e441401371dfd0f0a795c7daa4a3cd1dde55bea\",\n                \"sha256:bec0a414d016ac1a18862a519e54b2fd0fc8bbfd6890376898a6c0891dd82e9f\",\n                \"sha256:bf50cd79a75d181c9181df03572cdce0fbb75cc353bc350712073108cba98de5\",\n                \"sha256:bff1b4290a66b490a2f4719358c0cdcd9bafb6b8f061e45c7a2460866bf50c2e\",\n                \"sha256:c061bb86a71b42465156a3ee7bd58c8c2ceacdbeb95d05a99893e08b8467359a\",\n                \"sha256:c8b29db45f8fe46ad280a7294f5c3ec36dbac9491f2d1c17345be8e69cc5928f\",\n                \"sha256:ce409136744f6521e39fd8e2a24c53fa18ad67aa5bc7c2cf83645cce5b5c4e50\",\n                \"sha256:d050b3361367a06d752db6ead6e7edeb0009be66bc3bae0ee9d97fb326badc2a\",\n                \"sha256:d283d37a890ba4c1ae73ffadf8046435c76e7bc2247bbb63c00bd1a709c6544b\",\n                \"sha256:d9fad5155d72433c921b782e58892377c44bd6252b5af2f67f16b194987338a4\",\n                \"sha256:daa4ee5a243f0f20d528d939d06670a298dd39b1ad5f8a72a4275124a7819eff\",\n                \"sha256:db0b55e0f3cc0be60c1f19efdde9a637c32740486004f20d1cff53c3c0ece4d2\",\n                \"sha256:e61659ba32cf2cf1481e575d0462554625196a1f2fc06a1c777d3f48e8865d46\",\n                \"sha256:ea3d8a3d18833cf4304cd2fc9cbb1efe188ca9b5efef2bdac7adc20594a0e46b\",\n                \"sha256:ec6a563cff360b50eed26f13adc43e61bc0c04d94b8be985e6fb24b81f6dcfdf\",\n                \"sha256:f5dfb42c4604dddc8e4305050aa6deb084540643ed5804d7455b5df8fe16f5e5\",\n                \"sha256:fa173ec60341d6bb97a89f5ea19c85c5643c1e7dedebc22f5181eb73573142c5\",\n                \"sha256:fa9db3f79de01457b03d4f01b34cf91bc0048eb2c3846ff26f66687c2f6d16ab\",\n                \"sha256:fce659a462a1be54d2ffcacea5e3ba2d74daa74f30f5f143fe0c58636e355fdd\",\n                \"sha256:ffee1f21e5ef0d712f9033568f8344d5da8cc2869dbd08d87c84656e6a2d2f68\"\n            ],\n            \"markers\": \"python_version >= '3.7'\",\n            \"version\": \"==2.1.5\"\n        },\n        \"mergedeep\": {\n            \"hashes\": [\n                \"sha256:0096d52e9dad9939c3d975a774666af186eda617e6ca84df4c94dec30004f2a8\",\n                \"sha256:70775750742b25c0d8f36c55aed03d24c3384d17c951b3175d898bd778ef0307\"\n            ],\n            \"markers\": \"python_version >= '3.6'\",\n            \"version\": \"==1.3.4\"\n        },\n        \"mkdocs\": {\n            \"hashes\": [\n                \"sha256:3b3a78e736b31158d64dbb2f8ba29bd46a379d0c6e324c2246c3bc3d2189cfc1\",\n                \"sha256:eb7c99214dcb945313ba30426c2451b735992c73c2e10838f76d09e39ff4d0e2\"\n            ],\n            \"index\": \"pypi\",\n            \"markers\": \"python_version >= '3.7'\",\n            \"version\": \"==1.5.3\"\n        },\n        \"mkdocs-codeinclude-plugin\": {\n            \"hashes\": [\n                \"sha256:172a917c9b257fa62850b669336151f85d3cd40312b2b52520cbcceab557ea6c\",\n                \"sha256:305387f67a885f0e36ec1cf977324fe1fe50d31301147194b63631d0864601b1\"\n            ],\n            \"index\": \"pypi\",\n            \"markers\": \"python_version >= '3.7'\",\n            \"version\": \"==0.2.1\"\n        },\n        \"mkdocs-include-markdown-plugin\": {\n            \"hashes\": [\n                \"sha256:d293950f6499d2944291ca7b9bc4a60e652bbfd3e3a42b564f6cceee268694e7\",\n                \"sha256:f2bd5026650492a581d2fd44be6c22f90391910d76582b96a34c264f2d17875d\"\n            ],\n            \"index\": \"pypi\",\n            \"markers\": \"python_version >= '3.8'\",\n            \"version\": \"==6.2.2\"\n        },\n        \"mkdocs-markdownextradata-plugin\": {\n            \"hashes\": [\n                \"sha256:34dd40870781784c75809596b2d8d879da783815b075336d541de1f150c94242\",\n                \"sha256:4aed9b43b8bec65b02598387426ca4809099ea5f5aa78bf114f3296fd46686b5\"\n            ],\n            \"index\": \"pypi\",\n            \"markers\": \"python_version >= '3.6'\",\n            \"version\": \"==0.2.6\"\n        },\n        \"mkdocs-material\": {\n            \"hashes\": [\n                \"sha256:1e0e27fc9fe239f9064318acf548771a4629d5fd5dfd45444fd80a953fe21eb4\",\n                \"sha256:a43f470947053fa2405c33995f282d24992c752a50114f23f30da9d8d0c57e62\"\n            ],\n            \"index\": \"pypi\",\n            \"markers\": \"python_version >= '3.8'\",\n            \"version\": \"==9.5.18\"\n        },\n        \"mkdocs-material-extensions\": {\n            \"hashes\": [\n                \"sha256:10c9511cea88f568257f960358a467d12b970e1f7b2c0e5fb2bb48cab1928443\",\n                \"sha256:adff8b62700b25cb77b53358dad940f3ef973dd6db797907c49e3c2ef3ab4e31\"\n            ],\n            \"markers\": \"python_version >= '3.8'\",\n            \"version\": \"==1.3.1\"\n        },\n        \"packaging\": {\n            \"hashes\": [\n                \"sha256:026ed72c8ed3fcce5bf8950572258698927fd1dbda10a5e981cdf0ac37f4f002\",\n                \"sha256:5b8f2217dbdbd2f7f384c41c628544e6d52f2d0f53c6d0c3ea61aa5d1d7ff124\"\n            ],\n            \"markers\": \"python_version >= '3.8'\",\n            \"version\": \"==24.1\"\n        },\n        \"paginate\": {\n            \"hashes\": [\n                \"sha256:5e6007b6a9398177a7e1648d04fdd9f8c9766a1a945bceac82f1929e8c78af2d\"\n            ],\n            \"version\": \"==0.5.6\"\n        },\n        \"pathspec\": {\n            \"hashes\": [\n                \"sha256:a0d503e138a4c123b27490a4f7beda6a01c6f288df0e4a8b79c7eb0dc7b4cc08\",\n                \"sha256:a482d51503a1ab33b1c67a6c3813a26953dbdc71c31dacaef9a838c4e29f5712\"\n            ],\n            \"markers\": \"python_version >= '3.8'\",\n            \"version\": \"==0.12.1\"\n        },\n        \"platformdirs\": {\n            \"hashes\": [\n                \"sha256:2d7a1657e36a80ea911db832a8a6ece5ee53d8de21edd5cc5879af6530b1bfee\",\n                \"sha256:38b7b51f512eed9e84a22788b4bce1de17c0adb134d6becb09836e37d8654cd3\"\n            ],\n            \"markers\": \"python_version >= '3.8'\",\n            \"version\": \"==4.2.2\"\n        },\n        \"pygments\": {\n            \"hashes\": [\n                \"sha256:b27c2826c47d0f3219f29554824c30c5e8945175d888647acd804ddd04af846c\",\n                \"sha256:da46cec9fd2de5be3a8a784f434e4c4ab670b4ff54d605c4c2717e9d49c4c367\"\n            ],\n            \"markers\": \"python_version >= '3.7'\",\n            \"version\": \"==2.17.2\"\n        },\n        \"pymdown-extensions\": {\n            \"hashes\": [\n                \"sha256:3ab1db5c9e21728dabf75192d71471f8e50f216627e9a1fa9535ecb0231b9940\",\n                \"sha256:f938326115884f48c6059c67377c46cf631c733ef3629b6eed1349989d1b30cb\"\n            ],\n            \"markers\": \"python_version >= '3.8'\",\n            \"version\": \"==10.8.1\"\n        },\n        \"python-dateutil\": {\n            \"hashes\": [\n                \"sha256:37dd54208da7e1cd875388217d5e00ebd4179249f90fb72437e91a35459a0ad3\",\n                \"sha256:a8b2bc7bffae282281c8140a97d3aa9c14da0b136dfe83f850eea9a5f7470427\"\n            ],\n            \"markers\": \"python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'\",\n            \"version\": \"==2.9.0.post0\"\n        },\n        \"pytz\": {\n            \"hashes\": [\n                \"sha256:2a29735ea9c18baf14b448846bde5a48030ed267578472d8955cd0e7443a9812\",\n                \"sha256:328171f4e3623139da4983451950b28e95ac706e13f3f2630a879749e7a8b319\"\n            ],\n            \"markers\": \"python_version < '3.9'\",\n            \"version\": \"==2024.1\"\n        },\n        \"pyyaml\": {\n            \"hashes\": [\n                \"sha256:01179a4a8559ab5de078078f37e5c1a30d76bb88519906844fd7bdea1b7729ff\",\n                \"sha256:0833f8694549e586547b576dcfaba4a6b55b9e96098b36cdc7ebefe667dfed48\",\n                \"sha256:0a9a2848a5b7feac301353437eb7d5957887edbf81d56e903999a75a3d743086\",\n                \"sha256:0b69e4ce7a131fe56b7e4d770c67429700908fc0752af059838b1cfb41960e4e\",\n                \"sha256:0ffe8360bab4910ef1b9e87fb812d8bc0a308b0d0eef8c8f44e0254ab3b07133\",\n                \"sha256:11d8f3dd2b9c1207dcaf2ee0bbbfd5991f571186ec9cc78427ba5bd32afae4b5\",\n                \"sha256:17e311b6c678207928d649faa7cb0d7b4c26a0ba73d41e99c4fff6b6c3276484\",\n                \"sha256:1e2120ef853f59c7419231f3bf4e7021f1b936f6ebd222406c3b60212205d2ee\",\n                \"sha256:1f71ea527786de97d1a0cc0eacd1defc0985dcf6b3f17bb77dcfc8c34bec4dc5\",\n                \"sha256:23502f431948090f597378482b4812b0caae32c22213aecf3b55325e049a6c68\",\n                \"sha256:24471b829b3bf607e04e88d79542a9d48bb037c2267d7927a874e6c205ca7e9a\",\n                \"sha256:29717114e51c84ddfba879543fb232a6ed60086602313ca38cce623c1d62cfbf\",\n                \"sha256:2e99c6826ffa974fe6e27cdb5ed0021786b03fc98e5ee3c5bfe1fd5015f42b99\",\n                \"sha256:39693e1f8320ae4f43943590b49779ffb98acb81f788220ea932a6b6c51004d8\",\n                \"sha256:3ad2a3decf9aaba3d29c8f537ac4b243e36bef957511b4766cb0057d32b0be85\",\n                \"sha256:3b1fdb9dc17f5a7677423d508ab4f243a726dea51fa5e70992e59a7411c89d19\",\n                \"sha256:41e4e3953a79407c794916fa277a82531dd93aad34e29c2a514c2c0c5fe971cc\",\n                \"sha256:43fa96a3ca0d6b1812e01ced1044a003533c47f6ee8aca31724f78e93ccc089a\",\n                \"sha256:50187695423ffe49e2deacb8cd10510bc361faac997de9efef88badc3bb9e2d1\",\n                \"sha256:5ac9328ec4831237bec75defaf839f7d4564be1e6b25ac710bd1a96321cc8317\",\n                \"sha256:5d225db5a45f21e78dd9358e58a98702a0302f2659a3c6cd320564b75b86f47c\",\n                \"sha256:6395c297d42274772abc367baaa79683958044e5d3835486c16da75d2a694631\",\n                \"sha256:688ba32a1cffef67fd2e9398a2efebaea461578b0923624778664cc1c914db5d\",\n                \"sha256:68ccc6023a3400877818152ad9a1033e3db8625d899c72eacb5a668902e4d652\",\n                \"sha256:70b189594dbe54f75ab3a1acec5f1e3faa7e8cf2f1e08d9b561cb41b845f69d5\",\n                \"sha256:797b4f722ffa07cc8d62053e4cff1486fa6dc094105d13fea7b1de7d8bf71c9e\",\n                \"sha256:7c36280e6fb8385e520936c3cb3b8042851904eba0e58d277dca80a5cfed590b\",\n                \"sha256:7e7401d0de89a9a855c839bc697c079a4af81cf878373abd7dc625847d25cbd8\",\n                \"sha256:80bab7bfc629882493af4aa31a4cfa43a4c57c83813253626916b8c7ada83476\",\n                \"sha256:82d09873e40955485746739bcb8b4586983670466c23382c19cffecbf1fd8706\",\n                \"sha256:8388ee1976c416731879ac16da0aff3f63b286ffdd57cdeb95f3f2e085687563\",\n                \"sha256:8824b5a04a04a047e72eea5cec3bc266db09e35de6bdfe34c9436ac5ee27d237\",\n                \"sha256:8b9c7197f7cb2738065c481a0461e50ad02f18c78cd75775628afb4d7137fb3b\",\n                \"sha256:9056c1ecd25795207ad294bcf39f2db3d845767be0ea6e6a34d856f006006083\",\n                \"sha256:936d68689298c36b53b29f23c6dbb74de12b4ac12ca6cfe0e047bedceea56180\",\n                \"sha256:9b22676e8097e9e22e36d6b7bda33190d0d400f345f23d4065d48f4ca7ae0425\",\n                \"sha256:a4d3091415f010369ae4ed1fc6b79def9416358877534caf6a0fdd2146c87a3e\",\n                \"sha256:a8786accb172bd8afb8be14490a16625cbc387036876ab6ba70912730faf8e1f\",\n                \"sha256:a9f8c2e67970f13b16084e04f134610fd1d374bf477b17ec1599185cf611d725\",\n                \"sha256:bc2fa7c6b47d6bc618dd7fb02ef6fdedb1090ec036abab80d4681424b84c1183\",\n                \"sha256:c70c95198c015b85feafc136515252a261a84561b7b1d51e3384e0655ddf25ab\",\n                \"sha256:cc1c1159b3d456576af7a3e4d1ba7e6924cb39de8f67111c735f6fc832082774\",\n                \"sha256:ce826d6ef20b1bc864f0a68340c8b3287705cae2f8b4b1d932177dcc76721725\",\n                \"sha256:d584d9ec91ad65861cc08d42e834324ef890a082e591037abe114850ff7bbc3e\",\n                \"sha256:d7fded462629cfa4b685c5416b949ebad6cec74af5e2d42905d41e257e0869f5\",\n                \"sha256:d84a1718ee396f54f3a086ea0a66d8e552b2ab2017ef8b420e92edbc841c352d\",\n                \"sha256:d8e03406cac8513435335dbab54c0d385e4a49e4945d2909a581c83647ca0290\",\n                \"sha256:e10ce637b18caea04431ce14fabcf5c64a1c61ec9c56b071a4b7ca131ca52d44\",\n                \"sha256:ec031d5d2feb36d1d1a24380e4db6d43695f3748343d99434e6f5f9156aaa2ed\",\n                \"sha256:ef6107725bd54b262d6dedcc2af448a266975032bc85ef0172c5f059da6325b4\",\n                \"sha256:efdca5630322a10774e8e98e1af481aad470dd62c3170801852d752aa7a783ba\",\n                \"sha256:f753120cb8181e736c57ef7636e83f31b9c0d1722c516f7e86cf15b7aa57ff12\",\n                \"sha256:ff3824dc5261f50c9b0dfb3be22b4567a6f938ccce4587b38952d85fd9e9afe4\"\n            ],\n            \"markers\": \"python_version >= '3.8'\",\n            \"version\": \"==6.0.2\"\n        },\n        \"pyyaml-env-tag\": {\n            \"hashes\": [\n                \"sha256:70092675bda14fdec33b31ba77e7543de9ddc88f2e5b99160396572d11525bdb\",\n                \"sha256:af31106dec8a4d68c60207c1886031cbf839b68aa7abccdb19868200532c2069\"\n            ],\n            \"markers\": \"python_version >= '3.6'\",\n            \"version\": \"==0.1\"\n        },\n        \"regex\": {\n            \"hashes\": [\n                \"sha256:05d9b6578a22db7dedb4df81451f360395828b04f4513980b6bd7a1412c679cc\",\n                \"sha256:08a1749f04fee2811c7617fdd46d2e46d09106fa8f475c884b65c01326eb15c5\",\n                \"sha256:0940038bec2fe9e26b203d636c44d31dd8766abc1fe66262da6484bd82461ccf\",\n                \"sha256:0a2a512d623f1f2d01d881513af9fc6a7c46e5cfffb7dc50c38ce959f9246c94\",\n                \"sha256:0a54a047b607fd2d2d52a05e6ad294602f1e0dec2291152b745870afc47c1397\",\n                \"sha256:0dd3f69098511e71880fb00f5815db9ed0ef62c05775395968299cb400aeab82\",\n                \"sha256:1031a5e7b048ee371ab3653aad3030ecfad6ee9ecdc85f0242c57751a05b0ac4\",\n                \"sha256:108e2dcf0b53a7c4ab8986842a8edcb8ab2e59919a74ff51c296772e8e74d0ae\",\n                \"sha256:144a1fc54765f5c5c36d6d4b073299832aa1ec6a746a6452c3ee7b46b3d3b11d\",\n                \"sha256:19d6c11bf35a6ad077eb23852827f91c804eeb71ecb85db4ee1386825b9dc4db\",\n                \"sha256:1f687a28640f763f23f8a9801fe9e1b37338bb1ca5d564ddd41619458f1f22d1\",\n                \"sha256:224803b74aab56aa7be313f92a8d9911dcade37e5f167db62a738d0c85fdac4b\",\n                \"sha256:23a412b7b1a7063f81a742463f38821097b6a37ce1e5b89dd8e871d14dbfd86b\",\n                \"sha256:25f87ae6b96374db20f180eab083aafe419b194e96e4f282c40191e71980c666\",\n                \"sha256:2630ca4e152c221072fd4a56d4622b5ada876f668ecd24d5ab62544ae6793ed6\",\n                \"sha256:28e1f28d07220c0f3da0e8fcd5a115bbb53f8b55cecf9bec0c946eb9a059a94c\",\n                \"sha256:2b51739ddfd013c6f657b55a508de8b9ea78b56d22b236052c3a85a675102dc6\",\n                \"sha256:2cc1b87bba1dd1a898e664a31012725e48af826bf3971e786c53e32e02adae6c\",\n                \"sha256:2fef0b38c34ae675fcbb1b5db760d40c3fc3612cfa186e9e50df5782cac02bcd\",\n                \"sha256:36f392dc7763fe7924575475736bddf9ab9f7a66b920932d0ea50c2ded2f5636\",\n                \"sha256:374f690e1dd0dbdcddea4a5c9bdd97632cf656c69113f7cd6a361f2a67221cb6\",\n                \"sha256:3986217ec830c2109875be740531feb8ddafe0dfa49767cdcd072ed7e8927962\",\n                \"sha256:39fb166d2196413bead229cd64a2ffd6ec78ebab83fff7d2701103cf9f4dfd26\",\n                \"sha256:4290035b169578ffbbfa50d904d26bec16a94526071ebec3dadbebf67a26b25e\",\n                \"sha256:43548ad74ea50456e1c68d3c67fff3de64c6edb85bcd511d1136f9b5376fc9d1\",\n                \"sha256:44a22ae1cfd82e4ffa2066eb3390777dc79468f866f0625261a93e44cdf6482b\",\n                \"sha256:457c2cd5a646dd4ed536c92b535d73548fb8e216ebee602aa9f48e068fc393f3\",\n                \"sha256:459226445c7d7454981c4c0ce0ad1a72e1e751c3e417f305722bbcee6697e06a\",\n                \"sha256:47af45b6153522733aa6e92543938e97a70ce0900649ba626cf5aad290b737b6\",\n                \"sha256:499334ad139557de97cbc4347ee921c0e2b5e9c0f009859e74f3f77918339257\",\n                \"sha256:57ba112e5530530fd175ed550373eb263db4ca98b5f00694d73b18b9a02e7185\",\n                \"sha256:5ce479ecc068bc2a74cb98dd8dba99e070d1b2f4a8371a7dfe631f85db70fe6e\",\n                \"sha256:5dbc1bcc7413eebe5f18196e22804a3be1bfdfc7e2afd415e12c068624d48247\",\n                \"sha256:6277d426e2f31bdbacb377d17a7475e32b2d7d1f02faaecc48d8e370c6a3ff31\",\n                \"sha256:66372c2a01782c5fe8e04bff4a2a0121a9897e19223d9eab30c54c50b2ebeb7f\",\n                \"sha256:670fa596984b08a4a769491cbdf22350431970d0112e03d7e4eeaecaafcd0fec\",\n                \"sha256:6f435946b7bf7a1b438b4e6b149b947c837cb23c704e780c19ba3e6855dbbdd3\",\n                \"sha256:7413167c507a768eafb5424413c5b2f515c606be5bb4ef8c5dee43925aa5718b\",\n                \"sha256:7c3d389e8d76a49923683123730c33e9553063d9041658f23897f0b396b2386f\",\n                \"sha256:7d77b6f63f806578c604dca209280e4c54f0fa9a8128bb8d2cc5fb6f99da4150\",\n                \"sha256:7e76b9cfbf5ced1aca15a0e5b6f229344d9b3123439ffce552b11faab0114a02\",\n                \"sha256:7f3502f03b4da52bbe8ba962621daa846f38489cae5c4a7b5d738f15f6443d17\",\n                \"sha256:7fe9739a686dc44733d52d6e4f7b9c77b285e49edf8570754b322bca6b85b4cc\",\n                \"sha256:83ab366777ea45d58f72593adf35d36ca911ea8bd838483c1823b883a121b0e4\",\n                \"sha256:84077821c85f222362b72fdc44f7a3a13587a013a45cf14534df1cbbdc9a6796\",\n                \"sha256:8bb381f777351bd534462f63e1c6afb10a7caa9fa2a421ae22c26e796fe31b1f\",\n                \"sha256:92da587eee39a52c91aebea8b850e4e4f095fe5928d415cb7ed656b3460ae79a\",\n                \"sha256:9301cc6db4d83d2c0719f7fcda37229691745168bf6ae849bea2e85fc769175d\",\n                \"sha256:965fd0cf4694d76f6564896b422724ec7b959ef927a7cb187fc6b3f4e4f59833\",\n                \"sha256:99d6a550425cc51c656331af0e2b1651e90eaaa23fb4acde577cf15068e2e20f\",\n                \"sha256:99ef6289b62042500d581170d06e17f5353b111a15aa6b25b05b91c6886df8fc\",\n                \"sha256:a1409c4eccb6981c7baabc8888d3550df518add6e06fe74fa1d9312c1838652d\",\n                \"sha256:a74fcf77d979364f9b69fcf8200849ca29a374973dc193a7317698aa37d8b01c\",\n                \"sha256:aaa179975a64790c1f2701ac562b5eeb733946eeb036b5bcca05c8d928a62f10\",\n                \"sha256:ac69b394764bb857429b031d29d9604842bc4cbfd964d764b1af1868eeebc4f0\",\n                \"sha256:b45d4503de8f4f3dc02f1d28a9b039e5504a02cc18906cfe744c11def942e9eb\",\n                \"sha256:b7d893c8cf0e2429b823ef1a1d360a25950ed11f0e2a9df2b5198821832e1947\",\n                \"sha256:b8eb28995771c087a73338f695a08c9abfdf723d185e57b97f6175c5051ff1ae\",\n                \"sha256:b91d529b47798c016d4b4c1d06cc826ac40d196da54f0de3c519f5a297c5076a\",\n                \"sha256:bc365ce25f6c7c5ed70e4bc674f9137f52b7dd6a125037f9132a7be52b8a252f\",\n                \"sha256:bf29304a8011feb58913c382902fde3395957a47645bf848eea695839aa101b7\",\n                \"sha256:c06bf3f38f0707592898428636cbb75d0a846651b053a1cf748763e3063a6925\",\n                \"sha256:c77d10ec3c1cf328b2f501ca32583625987ea0f23a0c2a49b37a39ee5c4c4630\",\n                \"sha256:cd196d056b40af073d95a2879678585f0b74ad35190fac04ca67954c582c6b61\",\n                \"sha256:d7a353ebfa7154c871a35caca7bfd8f9e18666829a1dc187115b80e35a29393e\",\n                \"sha256:d84308f097d7a513359757c69707ad339da799e53b7393819ec2ea36bc4beb58\",\n                \"sha256:dd7ef715ccb8040954d44cfeff17e6b8e9f79c8019daae2fd30a8806ef5435c0\",\n                \"sha256:e672cf9caaf669053121f1766d659a8813bd547edef6e009205378faf45c67b8\",\n                \"sha256:ecc6148228c9ae25ce403eade13a0961de1cb016bdb35c6eafd8e7b87ad028b1\",\n                \"sha256:f1c5742c31ba7d72f2dedf7968998730664b45e38827637e0f04a2ac7de2f5f1\",\n                \"sha256:f1d6e4b7b2ae3a6a9df53efbf199e4bfcff0959dbdb5fd9ced34d4407348e39a\",\n                \"sha256:f2fc053228a6bd3a17a9b0a3f15c3ab3cf95727b00557e92e1cfe094b88cc662\",\n                \"sha256:f57515750d07e14743db55d59759893fdb21d2668f39e549a7d6cad5d70f9fea\",\n                \"sha256:f85151ec5a232335f1be022b09fbbe459042ea1951d8a48fef251223fc67eee1\",\n                \"sha256:fb0315a2b26fde4005a7c401707c5352df274460f2f85b209cf6024271373013\",\n                \"sha256:fc0916c4295c64d6890a46e02d4482bb5ccf33bf1a824c0eaa9e83b148291f90\",\n                \"sha256:fd24fd140b69f0b0bcc9165c397e9b2e89ecbeda83303abf2a072609f60239e2\",\n                \"sha256:fdae0120cddc839eb8e3c15faa8ad541cc6d906d3eb24d82fb041cfe2807bc1e\",\n                \"sha256:fe00f4fe11c8a521b173e6324d862ee7ee3412bf7107570c9b564fe1119b56fb\"\n            ],\n            \"markers\": \"python_version >= '3.8'\",\n            \"version\": \"==2024.4.28\"\n        },\n        \"requests\": {\n            \"hashes\": [\n                \"sha256:f2c3881dddb70d056c5bd7600a4fae312b2a300e39be6a118d30b90bd27262b5\",\n                \"sha256:fa5490319474c82ef1d2c9bc459d3652e3ae4ef4c4ebdd18a21145a47ca4b6b8\"\n            ],\n            \"index\": \"pypi\",\n            \"markers\": \"python_version >= '3.8'\",\n            \"version\": \"==2.32.0\"\n        },\n        \"six\": {\n            \"hashes\": [\n                \"sha256:1e61c37477a1626458e36f7b1d82aa5c9b094fa4802892072e49de9c60c4c926\",\n                \"sha256:8abb2f1d86890a2dfb989f9a77cfcfd3e47c2a354b01111771326f8aa26e0254\"\n            ],\n            \"markers\": \"python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'\",\n            \"version\": \"==1.16.0\"\n        },\n        \"urllib3\": {\n            \"hashes\": [\n                \"sha256:a448b2f64d686155468037e1ace9f2d2199776e17f0a46610480d311f73e3472\",\n                \"sha256:dd505485549a7a552833da5e6063639d0d177c04f23bc3864e41e5dc5f612168\"\n            ],\n            \"index\": \"pypi\",\n            \"markers\": \"python_version >= '3.8'\",\n            \"version\": \"==2.2.2\"\n        },\n        \"watchdog\": {\n            \"hashes\": [\n                \"sha256:0b4359067d30d5b864e09c8597b112fe0a0a59321a0f331498b013fb097406b4\",\n                \"sha256:0d8a7e523ef03757a5aa29f591437d64d0d894635f8a50f370fe37f913ce4e19\",\n                \"sha256:0e83619a2d5d436a7e58a1aea957a3c1ccbf9782c43c0b4fed80580e5e4acd1a\",\n                \"sha256:10b6683df70d340ac3279eff0b2766813f00f35a1d37515d2c99959ada8f05fa\",\n                \"sha256:132937547a716027bd5714383dfc40dc66c26769f1ce8a72a859d6a48f371f3a\",\n                \"sha256:1cdcfd8142f604630deef34722d695fb455d04ab7cfe9963055df1fc69e6727a\",\n                \"sha256:2d468028a77b42cc685ed694a7a550a8d1771bb05193ba7b24006b8241a571a1\",\n                \"sha256:32be97f3b75693a93c683787a87a0dc8db98bb84701539954eef991fb35f5fbc\",\n                \"sha256:770eef5372f146997638d737c9a3c597a3b41037cfbc5c41538fc27c09c3a3f9\",\n                \"sha256:7c7d4bf585ad501c5f6c980e7be9c4f15604c7cc150e942d82083b31a7548930\",\n                \"sha256:88456d65f207b39f1981bf772e473799fcdc10801062c36fd5ad9f9d1d463a73\",\n                \"sha256:914285126ad0b6eb2258bbbcb7b288d9dfd655ae88fa28945be05a7b475a800b\",\n                \"sha256:936acba76d636f70db8f3c66e76aa6cb5136a936fc2a5088b9ce1c7a3508fc83\",\n                \"sha256:980b71510f59c884d684b3663d46e7a14b457c9611c481e5cef08f4dd022eed7\",\n                \"sha256:984306dc4720da5498b16fc037b36ac443816125a3705dfde4fd90652d8028ef\",\n                \"sha256:a2cffa171445b0efa0726c561eca9a27d00a1f2b83846dbd5a4f639c4f8ca8e1\",\n                \"sha256:aa160781cafff2719b663c8a506156e9289d111d80f3387cf3af49cedee1f040\",\n                \"sha256:b2c45f6e1e57ebb4687690c05bc3a2c1fb6ab260550c4290b8abb1335e0fd08b\",\n                \"sha256:b4dfbb6c49221be4535623ea4474a4d6ee0a9cef4a80b20c28db4d858b64e270\",\n                \"sha256:baececaa8edff42cd16558a639a9b0ddf425f93d892e8392a56bf904f5eff22c\",\n                \"sha256:bcfd02377be80ef3b6bc4ce481ef3959640458d6feaae0bd43dd90a43da90a7d\",\n                \"sha256:c0b14488bd336c5b1845cee83d3e631a1f8b4e9c5091ec539406e4a324f882d8\",\n                \"sha256:c100d09ac72a8a08ddbf0629ddfa0b8ee41740f9051429baa8e31bb903ad7508\",\n                \"sha256:c344453ef3bf875a535b0488e3ad28e341adbd5a9ffb0f7d62cefacc8824ef2b\",\n                \"sha256:c50f148b31b03fbadd6d0b5980e38b558046b127dc483e5e4505fcef250f9503\",\n                \"sha256:c82253cfc9be68e3e49282831afad2c1f6593af80c0daf1287f6a92657986757\",\n                \"sha256:cd67c7df93eb58f360c43802acc945fa8da70c675b6fa37a241e17ca698ca49b\",\n                \"sha256:d7ab624ff2f663f98cd03c8b7eedc09375a911794dfea6bf2a359fcc266bff29\",\n                \"sha256:e252f8ca942a870f38cf785aef420285431311652d871409a64e2a0a52a2174c\",\n                \"sha256:ede7f010f2239b97cc79e6cb3c249e72962404ae3865860855d5cbe708b0fd22\",\n                \"sha256:eeea812f38536a0aa859972d50c76e37f4456474b02bd93674d1947cf1e39578\",\n                \"sha256:f15edcae3830ff20e55d1f4e743e92970c847bcddc8b7509bcd172aa04de506e\",\n                \"sha256:f5315a8c8dd6dd9425b974515081fc0aadca1d1d61e078d2246509fd756141ee\",\n                \"sha256:f6ee8dedd255087bc7fe82adf046f0b75479b989185fb0bdf9a98b612170eac7\",\n                \"sha256:f7c739888c20f99824f7aa9d31ac8a97353e22d0c0e54703a547a218f6637eb3\"\n            ],\n            \"markers\": \"python_version >= '3.8'\",\n            \"version\": \"==4.0.2\"\n        },\n        \"wcmatch\": {\n            \"hashes\": [\n                \"sha256:567d66b11ad74384954c8af86f607857c3bdf93682349ad32066231abd556c92\",\n                \"sha256:af25922e2b6dbd1550fa37a4c8de7dd558d6c1bb330c641de9b907b9776cb3c4\"\n            ],\n            \"markers\": \"python_version >= '3.8'\",\n            \"version\": \"==9.0\"\n        },\n        \"zipp\": {\n            \"hashes\": [\n                \"sha256:9960cd8967c8f85a56f920d5d507274e74f9ff813a0ab8889a5b5be2daf44064\",\n                \"sha256:c22b14cc4763c5a5b04134207736c107db42e9d3ef2d9779d465f5f1bcba572b\"\n            ],\n            \"markers\": \"python_version >= '3.8'\",\n            \"version\": \"==3.20.1\"\n        }\n    },\n    \"develop\": {}\n}\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 1.888671875,
          "content": "# Testcontainers\n\n[![Main pipeline](https://github.com/testcontainers/testcontainers-go/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/testcontainers/testcontainers-go/actions/workflows/ci.yml)\n[![GoDoc Reference](https://pkg.go.dev/badge/github.com/testcontainers/testcontainers-go.svg)](https://pkg.go.dev/github.com/testcontainers/testcontainers-go)\n[![Go Report Card](https://goreportcard.com/badge/github.com/testcontainers/testcontainers-go)](https://goreportcard.com/report/github.com/testcontainers/testcontainers-go)\n[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=testcontainers_testcontainers-go&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=testcontainers_testcontainers-go)\n[![License](https://img.shields.io/badge/license-MIT-blue)](https://github.com/testcontainers/testcontainers-go/blob/main/LICENSE)\n\n[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://github.com/codespaces/new?hide_repo_select=true&ref=main&repo=141451032&machine=standardLinux32gb&devcontainer_path=.devcontainer%2Fdevcontainer.json&location=EastUs)\n\n[![Join our Slack](https://img.shields.io/badge/Slack-4A154B?logo=slack)](https://testcontainers.slack.com/)\n\n_Testcontainers for Go_ is a Go package that makes it simple to create and clean up container-based dependencies for\nautomated integration/smoke tests. The clean, easy-to-use API enables developers to programmatically define containers\nthat should be run as part of a test and clean up those resources when the test is done.\n\nYou can find more information about _Testcontainers for Go_ at [golang.testcontainers.org](https://golang.testcontainers.org), which is rendered from the [./docs](./docs) directory.\n\n## Using _Testcontainers for Go_\n\nPlease visit [the quickstart guide](https://golang.testcontainers.org/quickstart) to understand how to add the dependency to your Go project.\n"
        },
        {
          "name": "RELEASING.md",
          "type": "blob",
          "size": 14.904296875,
          "content": "# Releasing Testcontainers for Go\n\nIn order to create a release, we have added a shell script that performs all the tasks for you, allowing a dry-run mode for checking it before creating the release. We are going to explain how to use it in this document.\n\n## Prerequisites\n\nFirst, it's really important that you first check that the [version.go](./internal/version.go) file is up-to-date, containing the right version you want to create. That file will be used by the automation to perform the release.\nOnce the version file is correct in the repository:\n\nSecond, check that the git remote for the `origin` is pointing to `github.com/testcontainers/testcontainers-go`. You can check it by running:\n\n```shell\ngit remote -v\n```\n\n## Prepare the release\n\nOnce the remote is properly set, please follow these steps:\n\n- Run the [pre-release.sh](./scripts/pre-release.sh) shell script to run it in dry-run mode.\n- You can use the `DRY_RUN` variable to enable or disable the dry-run mode. By default, it's enabled.\n- To prepare for a release, updating the _Testcontainers for Go_ dependency for all the modules and examples, without performing any Git operation:\n\n        DRY_RUN=\"false\" ./scripts/pre-release.sh\n\n- The script will update the [mkdocs.yml](./mkdocks.yml) file, updating the `latest_version` field to the current version.\n- The script will update the `go.mod` files for each Go modules and example modules under the examples and modules directories, updating the version of the testcontainers-go dependency to the recently created tag.\n- The script will modify the docs for the each Go module **that was not released yet**, updating the version of _Testcontainers for Go_ where it was added to the recently created tag.\n\nAn example execution, with dry-run mode enabled:\n\n```shell\nsed \"s/latest_version: .*/latest_version: v0.20.1/g\" /Users/mdelapenya/sourcecode/src/github.com/testcontainers/testcontainers-go/mkdocs.yml > /Users/mdelapenya/sourcecode/src/github.com/testcontainers/testcontainers-go/mkdocs.yml.tmp\nmv /Users/mdelapenya/sourcecode/src/github.com/testcontainers/testcontainers-go/mkdocs.yml.tmp /Users/mdelapenya/sourcecode/src/github.com/testcontainers/testcontainers-go/mkdocs.yml\nsed \"s/testcontainers-go v.*/testcontainers-go v0.20.1/g\" bigtable/go.mod > bigtable/go.mod.tmp\nmv bigtable/go.mod.tmp bigtable/go.mod\nsed \"s/testcontainers-go v.*/testcontainers-go v0.20.1/g\" cockroachdb/go.mod > cockroachdb/go.mod.tmp\nmv cockroachdb/go.mod.tmp cockroachdb/go.mod\nsed \"s/testcontainers-go v.*/testcontainers-go v0.20.1/g\" consul/go.mod > consul/go.mod.tmp\nmv consul/go.mod.tmp consul/go.mod\nsed \"s/testcontainers-go v.*/testcontainers-go v0.20.1/g\" datastore/go.mod > datastore/go.mod.tmp\nmv datastore/go.mod.tmp datastore/go.mod\nsed \"s/testcontainers-go v.*/testcontainers-go v0.20.1/g\" firestore/go.mod > firestore/go.mod.tmp\nmv firestore/go.mod.tmp firestore/go.mod\nsed \"s/testcontainers-go v.*/testcontainers-go v0.20.1/g\" mongodb/go.mod > mongodb/go.mod.tmp\nmv mongodb/go.mod.tmp mongodb/go.mod\nsed \"s/testcontainers-go v.*/testcontainers-go v0.20.1/g\" nginx/go.mod > nginx/go.mod.tmp\nmv nginx/go.mod.tmp nginx/go.mod\nsed \"s/testcontainers-go v.*/testcontainers-go v0.20.1/g\" pubsub/go.mod > pubsub/go.mod.tmp\nmv pubsub/go.mod.tmp pubsub/go.mod\nsed \"s/testcontainers-go v.*/testcontainers-go v0.20.1/g\" spanner/go.mod > spanner/go.mod.tmp\nmv spanner/go.mod.tmp spanner/go.mod\nsed \"s/testcontainers-go v.*/testcontainers-go v0.20.1/g\" toxiproxy/go.mod > toxiproxy/go.mod.tmp\nmv toxiproxy/go.mod.tmp toxiproxy/go.mod\ngo mod tidy\ngo mod tidy\ngo mod tidy\ngo mod tidy\ngo mod tidy\ngo mod tidy\ngo mod tidy\ngo mod tidy\ngo mod tidy\ngo mod tidy\ngo mod tidy\nsed \"s/testcontainers-go v.*/testcontainers-go v0.20.1/g\" compose/go.mod > compose/go.mod.tmp\nmv compose/go.mod.tmp compose/go.mod\nsed \"s/testcontainers-go v.*/testcontainers-go v0.20.1/g\" couchbase/go.mod > couchbase/go.mod.tmp\nmv couchbase/go.mod.tmp couchbase/go.mod\nsed \"s/testcontainers-go v.*/testcontainers-go v0.20.1/g\" localstack/go.mod > localstack/go.mod.tmp\nmv localstack/go.mod.tmp localstack/go.mod\nsed \"s/testcontainers-go v.*/testcontainers-go v0.20.1/g\" mysql/go.mod > mysql/go.mod.tmp\nmv mysql/go.mod.tmp mysql/go.mod\nsed \"s/testcontainers-go v.*/testcontainers-go v0.20.1/g\" neo4j/go.mod > neo4j/go.mod.tmp\nmv neo4j/go.mod.tmp neo4j/go.mod\nsed \"s/testcontainers-go v.*/testcontainers-go v0.20.1/g\" postgres/go.mod > postgres/go.mod.tmp\nmv postgres/go.mod.tmp postgres/go.mod\nsed \"s/testcontainers-go v.*/testcontainers-go v0.20.1/g\" pulsar/go.mod > pulsar/go.mod.tmp\nmv pulsar/go.mod.tmp pulsar/go.mod\nsed \"s/testcontainers-go v.*/testcontainers-go v0.20.1/g\" redis/go.mod > redis/go.mod.tmp\nmv redis/go.mod.tmp redis/go.mod\nsed \"s/testcontainers-go v.*/testcontainers-go v0.20.1/g\" redpanda/go.mod > redpanda/go.mod.tmp\nmv redpanda/go.mod.tmp redpanda/go.mod\nsed \"s/testcontainers-go v.*/testcontainers-go v0.20.1/g\" vault/go.mod > vault/go.mod.tmp\nmv vault/go.mod.tmp vault/go.mod\ngo mod tidy\ngo mod tidy\ngo mod tidy\ngo mod tidy\ngo mod tidy\ngo mod tidy\ngo mod tidy\ngo mod tidy\ngo mod tidy\ngo mod tidy\nsed \"s/Not available until the next release of testcontainers-go <a href=\\\"https:\\/\\/github.com\\/testcontainers\\/testcontainers-go\\\"><span class=\\\"tc-version\\\">:material-tag: main<\\/span><\\/a>/Since testcontainers-go <a href=\\\"https:\\/\\/github.com\\/testcontainers\\/testcontainers-go\\/releases\\/tag\\/v0.20.1\\\"><span class=\\\"tc-version\\\">:material-tag: v0.20.1<\\/span><\\/a>/g\" couchbase.md > couchbase.md.tmp\nmv couchbase.md.tmp couchbase.md\nsed \"s/Not available until the next release of testcontainers-go <a href=\\\"https:\\/\\/github.com\\/testcontainers\\/testcontainers-go\\\"><span class=\\\"tc-version\\\">:material-tag: main<\\/span><\\/a>/Since testcontainers-go <a href=\\\"https:\\/\\/github.com\\/testcontainers\\/testcontainers-go\\/releases\\/tag\\/v0.20.1\\\"><span class=\\\"tc-version\\\">:material-tag: v0.20.1<\\/span><\\/a>/g\" localstack.md > localstack.md.tmp\nmv localstack.md.tmp localstack.md\nsed \"s/Not available until the next release of testcontainers-go <a href=\\\"https:\\/\\/github.com\\/testcontainers\\/testcontainers-go\\\"><span class=\\\"tc-version\\\">:material-tag: main<\\/span><\\/a>/Since testcontainers-go <a href=\\\"https:\\/\\/github.com\\/testcontainers\\/testcontainers-go\\/releases\\/tag\\/v0.20.1\\\"><span class=\\\"tc-version\\\">:material-tag: v0.20.1<\\/span><\\/a>/g\" mysql.md > mysql.md.tmp\nmv mysql.md.tmp mysql.md\nsed \"s/Not available until the next release of testcontainers-go <a href=\\\"https:\\/\\/github.com\\/testcontainers\\/testcontainers-go\\\"><span class=\\\"tc-version\\\">:material-tag: main<\\/span><\\/a>/Since testcontainers-go <a href=\\\"https:\\/\\/github.com\\/testcontainers\\/testcontainers-go\\/releases\\/tag\\/v0.20.1\\\"><span class=\\\"tc-version\\\">:material-tag: v0.20.1<\\/span><\\/a>/g\" neo4j.md > neo4j.md.tmp\nmv neo4j.md.tmp neo4j.md\nsed \"s/Not available until the next release of testcontainers-go <a href=\\\"https:\\/\\/github.com\\/testcontainers\\/testcontainers-go\\\"><span class=\\\"tc-version\\\">:material-tag: main<\\/span><\\/a>/Since testcontainers-go <a href=\\\"https:\\/\\/github.com\\/testcontainers\\/testcontainers-go\\/releases\\/tag\\/v0.20.1\\\"><span class=\\\"tc-version\\\">:material-tag: v0.20.1<\\/span><\\/a>/g\" postgres.md > postgres.md.tmp\nmv postgres.md.tmp postgres.md\nsed \"s/Not available until the next release of testcontainers-go <a href=\\\"https:\\/\\/github.com\\/testcontainers\\/testcontainers-go\\\"><span class=\\\"tc-version\\\">:material-tag: main<\\/span><\\/a>/Since testcontainers-go <a href=\\\"https:\\/\\/github.com\\/testcontainers\\/testcontainers-go\\/releases\\/tag\\/v0.20.1\\\"><span class=\\\"tc-version\\\">:material-tag: v0.20.1<\\/span><\\/a>/g\" pulsar.md > pulsar.md.tmp\nmv pulsar.md.tmp pulsar.md\nsed \"s/Not available until the next release of testcontainers-go <a href=\\\"https:\\/\\/github.com\\/testcontainers\\/testcontainers-go\\\"><span class=\\\"tc-version\\\">:material-tag: main<\\/span><\\/a>/Since testcontainers-go <a href=\\\"https:\\/\\/github.com\\/testcontainers\\/testcontainers-go\\/releases\\/tag\\/v0.20.1\\\"><span class=\\\"tc-version\\\">:material-tag: v0.20.1<\\/span><\\/a>/g\" redis.md > redis.md.tmp\nmv redis.md.tmp redis.md\nsed \"s/Not available until the next release of testcontainers-go <a href=\\\"https:\\/\\/github.com\\/testcontainers\\/testcontainers-go\\\"><span class=\\\"tc-version\\\">:material-tag: main<\\/span><\\/a>/Since testcontainers-go <a href=\\\"https:\\/\\/github.com\\/testcontainers\\/testcontainers-go\\/releases\\/tag\\/v0.20.1\\\"><span class=\\\"tc-version\\\">:material-tag: v0.20.1<\\/span><\\/a>/g\" redpanda.md > redpanda.md.tmp\nmv redpanda.md.tmp redpanda.md\nsed \"s/Not available until the next release of testcontainers-go <a href=\\\"https:\\/\\/github.com\\/testcontainers\\/testcontainers-go\\\"><span class=\\\"tc-version\\\">:material-tag: main<\\/span><\\/a>/Since testcontainers-go <a href=\\\"https:\\/\\/github.com\\/testcontainers\\/testcontainers-go\\/releases\\/tag\\/v0.20.1\\\"><span class=\\\"tc-version\\\">:material-tag: v0.20.1<\\/span><\\/a>/g\" vault.md > vault.md.tmp\nmv vault.md.tmp vault.md\n```\n\n## Performing a release\n\nOnce you are satisfied with the modified files in the git state:\n\n- Run the [release.sh](./scripts/release.sh) shell script to create the release in dry-run mode.\n- You can use the `DRY_RUN` variable to enable or disable the dry-run mode. By default, it's enabled.\n\n        DRY_RUN=\"false\" ./scripts/release.sh\n\n- You can define the bump type, using the `BUMP_TYPE` environment variable. The default value is `minor`, but you can also use `major` or `patch` (the script will fail if the value is not one of these three):\n\n        BUMP_TYPE=\"major\" ./scripts/release.sh\n\n- The script will commit the current state of the git repository, if the `DRY_RUN` variable is set to `false`. The modified files are the ones modified by the `pre-release.sh` script.\n- The script will create a git tag with the current value of the [version.go](./internal/version.go) file, starting with `v`: e.g. `v0.18.0`, for the following Go modules:\n    - the root module, representing the Testcontainers for Go library.\n    - all the Go modules living in both the `examples` and `modules` directory. The git tag value for these Go modules will be created using this name convention:\n\n             \"${directory}/${module_name}/${version}\", e.g. \"examples/mysql/v0.18.0\", \"modules/compose/v0.18.0\"\n\n- The script will update the [version.go](./internal/version.go) file, setting the next development version to the value defined in the `BUMP_TYPE` environment variable. For example, if the current version is `v0.18.0`, the script will update the [version.go](./internal/version.go) file with the next development version `v0.19.0`.\n- The script will create a commit in the **main** branch if the `DRY_RUN` variable is set to `false`.\n- The script will push the main branch including the tags to the upstream repository, https://github.com/testcontainers/testcontainers-go, if the `DRY_RUN` variable is set to `false`.\n- Finally, the script will trigger the Golang proxy to update the modules in https://proxy.golang.org/, if the `DRY_RUN` variable is set to `false`.\n\nAn example execution, with dry-run mode enabled:\n\n```\n$ ./scripts/release.sh\nCurrent version: v0.20.1\ngit add /Users/mdelapenya/sourcecode/src/github.com/testcontainers/testcontainers-go/internal/version.go\ngit add /Users/mdelapenya/sourcecode/src/github.com/testcontainers/testcontainers-go/mkdocs.yml\ngit add examples/**/go.*\ngit add modules/**/go.*\ngit commit -m chore: use new version (v0.20.1) in modules and examples\ngit tag v0.20.1\ngit tag examples/bigtable/v0.20.1\ngit tag examples/datastore/v0.20.1\ngit tag examples/firestore/v0.20.1\ngit tag examples/mongodb/v0.20.1\ngit tag examples/nginx/v0.20.1\ngit tag examples/pubsub/v0.20.1\ngit tag examples/spanner/v0.20.1\ngit tag examples/toxiproxy/v0.20.1\ngit tag modules/cockroachdb/v0.20.1\ngit tag modules/compose/v0.20.1\ngit tag modules/couchbase/v0.20.1\ngit tag modules/localstack/v0.20.1\ngit tag modules/mysql/v0.20.1\ngit tag modules/neo4j/v0.20.1\ngit tag modules/postgres/v0.20.1\ngit tag modules/pulsar/v0.20.1\ngit tag modules/redis/v0.20.1\ngit tag modules/redpanda/v0.20.1\ngit tag modules/vault/v0.20.1\nWARNING: The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested\nProducing a minor bump of the version, from 0.20.1 to 0.21.0\nsed \"s/const Version = \".*\"/const Version = \"0.21.0\"/g\" /Users/mdelapenya/sourcecode/src/github.com/testcontainers/testcontainers-go/internal/version.go > /Users/mdelapenya/sourcecode/src/github.com/testcontainers/testcontainers-go/internal/version.go.tmp\nmv /Users/mdelapenya/sourcecode/src/github.com/testcontainers/testcontainers-go/internal/version.go.tmp /Users/mdelapenya/sourcecode/src/github.com/testcontainers/testcontainers-go/internal/version.go\ngit add /Users/mdelapenya/sourcecode/src/github.com/testcontainers/testcontainers-go/internal/version.go\ngit commit -m chore: prepare for next minor development cycle (0.21.0)\ngit push origin main --tags\ncurl https://proxy.golang.org/github.com/testcontainers/testcontainers-go/@v/v0.20.1.info\ncurl https://proxy.golang.org/github.com/testcontainers/testcontainers-go/examples/bigtable/@v/v0.20.1.info\ncurl https://proxy.golang.org/github.com/testcontainers/testcontainers-go/examples/datastore/@v/v0.20.1.info\ncurl https://proxy.golang.org/github.com/testcontainers/testcontainers-go/examples/firestore/@v/v0.20.1.info\ncurl https://proxy.golang.org/github.com/testcontainers/testcontainers-go/examples/mongodb/@v/v0.20.1.info\ncurl https://proxy.golang.org/github.com/testcontainers/testcontainers-go/examples/nginx/@v/v0.20.1.info\ncurl https://proxy.golang.org/github.com/testcontainers/testcontainers-go/examples/pubsub/@v/v0.20.1.info\ncurl https://proxy.golang.org/github.com/testcontainers/testcontainers-go/examples/spanner/@v/v0.20.1.info\ncurl https://proxy.golang.org/github.com/testcontainers/testcontainers-go/examples/toxiproxy/@v/v0.20.1.info\ncurl https://proxy.golang.org/github.com/testcontainers/testcontainers-go/modules/cockroachdb/@v/v0.20.1.info\ncurl https://proxy.golang.org/github.com/testcontainers/testcontainers-go/modules/compose/@v/v0.20.1.info\ncurl https://proxy.golang.org/github.com/testcontainers/testcontainers-go/modules/couchbase/@v/v0.20.1.info\ncurl https://proxy.golang.org/github.com/testcontainers/testcontainers-go/modules/localstack/@v/v0.20.1.info\ncurl https://proxy.golang.org/github.com/testcontainers/testcontainers-go/modules/mysql/@v/v0.20.1.info\ncurl https://proxy.golang.org/github.com/testcontainers/testcontainers-go/modules/neo4j/@v/v0.20.1.info\ncurl https://proxy.golang.org/github.com/testcontainers/testcontainers-go/modules/postgres/@v/v0.20.1.info\ncurl https://proxy.golang.org/github.com/testcontainers/testcontainers-go/modules/pulsar/@v/v0.20.1.info\ncurl https://proxy.golang.org/github.com/testcontainers/testcontainers-go/modules/redis/@v/v0.20.1.info\ncurl https://proxy.golang.org/github.com/testcontainers/testcontainers-go/modules/redpanda/@v/v0.20.1.info\ncurl https://proxy.golang.org/github.com/testcontainers/testcontainers-go/modules/vault/@v/v0.20.1.info\n```\n\nRight after that, you have to:\n- Verify that the commits are in the upstream repository, otherwise, update it with the current state of the main branch.\n"
        },
        {
          "name": "cleanup.go",
          "type": "blob",
          "size": 3.255859375,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"reflect\"\n\t\"time\"\n)\n\n// TerminateOptions is a type that holds the options for terminating a container.\ntype TerminateOptions struct {\n\tctx         context.Context\n\tstopTimeout *time.Duration\n\tvolumes     []string\n}\n\n// TerminateOption is a type that represents an option for terminating a container.\ntype TerminateOption func(*TerminateOptions)\n\n// NewTerminateOptions returns a fully initialised TerminateOptions.\n// Defaults: StopTimeout: 10 seconds.\nfunc NewTerminateOptions(ctx context.Context, opts ...TerminateOption) *TerminateOptions {\n\ttimeout := time.Second * 10\n\toptions := &TerminateOptions{\n\t\tstopTimeout: &timeout,\n\t\tctx:         ctx,\n\t}\n\tfor _, opt := range opts {\n\t\topt(options)\n\t}\n\treturn options\n}\n\n// Context returns the context to use during a Terminate.\nfunc (o *TerminateOptions) Context() context.Context {\n\treturn o.ctx\n}\n\n// StopTimeout returns the stop timeout to use during a Terminate.\nfunc (o *TerminateOptions) StopTimeout() *time.Duration {\n\treturn o.stopTimeout\n}\n\n// Cleanup performs any clean up needed\nfunc (o *TerminateOptions) Cleanup() error {\n\t// TODO: simplify this when when perform the client refactor.\n\tif len(o.volumes) == 0 {\n\t\treturn nil\n\t}\n\tclient, err := NewDockerClientWithOpts(o.ctx)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"docker client: %w\", err)\n\t}\n\tdefer client.Close()\n\t// Best effort to remove all volumes.\n\tvar errs []error\n\tfor _, volume := range o.volumes {\n\t\tif errRemove := client.VolumeRemove(o.ctx, volume, true); errRemove != nil {\n\t\t\terrs = append(errs, fmt.Errorf(\"volume remove %q: %w\", volume, errRemove))\n\t\t}\n\t}\n\treturn errors.Join(errs...)\n}\n\n// StopContext returns a TerminateOption that sets the context.\n// Default: context.Background().\nfunc StopContext(ctx context.Context) TerminateOption {\n\treturn func(c *TerminateOptions) {\n\t\tc.ctx = ctx\n\t}\n}\n\n// StopTimeout returns a TerminateOption that sets the timeout.\n// Default: See [Container.Stop].\nfunc StopTimeout(timeout time.Duration) TerminateOption {\n\treturn func(c *TerminateOptions) {\n\t\tc.stopTimeout = &timeout\n\t}\n}\n\n// RemoveVolumes returns a TerminateOption that sets additional volumes to remove.\n// This is useful when the container creates named volumes that should be removed\n// which are not removed by default.\n// Default: nil.\nfunc RemoveVolumes(volumes ...string) TerminateOption {\n\treturn func(c *TerminateOptions) {\n\t\tc.volumes = volumes\n\t}\n}\n\n// TerminateContainer calls [Container.Terminate] on the container if it is not nil.\n//\n// This should be called as a defer directly after [GenericContainer](...)\n// or a modules Run(...) to ensure the container is terminated when the\n// function ends.\nfunc TerminateContainer(container Container, options ...TerminateOption) error {\n\tif isNil(container) {\n\t\treturn nil\n\t}\n\n\terr := container.Terminate(context.Background(), options...)\n\tif !isCleanupSafe(err) {\n\t\treturn fmt.Errorf(\"terminate: %w\", err)\n\t}\n\n\treturn nil\n}\n\n// isNil returns true if val is nil or an nil instance false otherwise.\nfunc isNil(val any) bool {\n\tif val == nil {\n\t\treturn true\n\t}\n\n\tvalueOf := reflect.ValueOf(val)\n\tswitch valueOf.Kind() {\n\tcase reflect.Chan, reflect.Func, reflect.Map, reflect.Ptr, reflect.UnsafePointer, reflect.Interface, reflect.Slice:\n\t\treturn valueOf.IsNil()\n\tdefault:\n\t\treturn false\n\t}\n}\n"
        },
        {
          "name": "commons-test.mk",
          "type": "blob",
          "size": 1.375,
          "content": "ROOT_DIR:=$(shell dirname $(realpath $(lastword $(MAKEFILE_LIST))))\nGOBIN= $(GOPATH)/bin\n\ndefine go_install\n    go install $(1)\nendef\n\n$(GOBIN)/golangci-lint:\n\t$(call go_install,github.com/golangci/golangci-lint/cmd/golangci-lint@v1.61.0)\n\n$(GOBIN)/gotestsum:\n\t$(call go_install,gotest.tools/gotestsum@latest)\n\n$(GOBIN)/mockery:\n\t$(call go_install,github.com/vektra/mockery/v2@v2.45)\n\n.PHONY: install\ninstall: $(GOBIN)/golangci-lint $(GOBIN)/gotestsum $(GOBIN)/mockery\n\n.PHONY: clean\nclean:\n\trm $(GOBIN)/golangci-lint\n\trm $(GOBIN)/gotestsum\n\trm $(GOBIN)/mockery\n\n.PHONY: dependencies-scan\ndependencies-scan:\n\t@echo \">> Scanning dependencies in $(CURDIR)...\"\n\tgo list -json -m all | docker run --rm -i sonatypecommunity/nancy:latest sleuth --skip-update-check\n\n.PHONY: lint\nlint: $(GOBIN)/golangci-lint\n\tgolangci-lint run --out-format=colored-line-number --path-prefix=. --verbose -c $(ROOT_DIR)/.golangci.yml --fix\n\n.PHONY: generate\ngenerate: $(GOBIN)/mockery\n\tgo generate ./...\n\n.PHONY: test-%\ntest-%: $(GOBIN)/gotestsum\n\t@echo \"Running $* tests...\"\n\tgotestsum \\\n\t\t--format short-verbose \\\n\t\t--rerun-fails=5 \\\n\t\t--packages=\"./...\" \\\n\t\t--junitfile TEST-unit.xml \\\n\t\t-- \\\n\t\t-v \\\n\t\t-coverprofile=coverage.out \\\n\t\t-timeout=30m \\\n\t\t-race\n\n.PHONY: tools\ntools:\n\tgo mod download\n\n.PHONY: test-tools\ntest-tools: $(GOBIN)/gotestsum\n\n.PHONY: tidy\ntidy:\n\tgo mod tidy\n\n.PHONY: pre-commit\npre-commit: generate tidy lint\n"
        },
        {
          "name": "config.go",
          "type": "blob",
          "size": 1.2470703125,
          "content": "package testcontainers\n\nimport (\n\t\"github.com/testcontainers/testcontainers-go/internal/config\"\n)\n\n// TestcontainersConfig represents the configuration for Testcontainers\ntype TestcontainersConfig struct {\n\tHost           string `properties:\"docker.host,default=\"`                    // Deprecated: use Config.Host instead\n\tTLSVerify      int    `properties:\"docker.tls.verify,default=0\"`             // Deprecated: use Config.TLSVerify instead\n\tCertPath       string `properties:\"docker.cert.path,default=\"`               // Deprecated: use Config.CertPath instead\n\tRyukDisabled   bool   `properties:\"ryuk.disabled,default=false\"`             // Deprecated: use Config.RyukDisabled instead\n\tRyukPrivileged bool   `properties:\"ryuk.container.privileged,default=false\"` // Deprecated: use Config.RyukPrivileged instead\n\tConfig         config.Config\n}\n\n// ReadConfig reads from testcontainers properties file, storing the result in a singleton instance\n// of the TestcontainersConfig struct\nfunc ReadConfig() TestcontainersConfig {\n\tcfg := config.Read()\n\treturn TestcontainersConfig{\n\t\tHost:           cfg.Host,\n\t\tTLSVerify:      cfg.TLSVerify,\n\t\tCertPath:       cfg.CertPath,\n\t\tRyukDisabled:   cfg.RyukDisabled,\n\t\tRyukPrivileged: cfg.RyukPrivileged,\n\t\tConfig:         cfg,\n\t}\n}\n"
        },
        {
          "name": "container.go",
          "type": "blob",
          "size": 22.7783203125,
          "content": "package testcontainers\n\nimport (\n\t\"archive/tar\"\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/cpuguy83/dockercfg\"\n\t\"github.com/docker/docker/api/types\"\n\t\"github.com/docker/docker/api/types/container\"\n\t\"github.com/docker/docker/api/types/network\"\n\t\"github.com/docker/docker/api/types/registry\"\n\t\"github.com/docker/docker/pkg/archive\"\n\t\"github.com/docker/go-connections/nat\"\n\t\"github.com/google/uuid\"\n\t\"github.com/moby/patternmatcher/ignorefile\"\n\n\ttcexec \"github.com/testcontainers/testcontainers-go/exec\"\n\t\"github.com/testcontainers/testcontainers-go/internal/core\"\n\t\"github.com/testcontainers/testcontainers-go/wait\"\n)\n\n// DeprecatedContainer shows methods that were supported before, but are now deprecated\n// Deprecated: Use Container\ntype DeprecatedContainer interface {\n\tGetHostEndpoint(ctx context.Context, port string) (string, string, error)\n\tGetIPAddress(ctx context.Context) (string, error)\n\tLivenessCheckPorts(ctx context.Context) (nat.PortSet, error)\n\tTerminate(ctx context.Context) error\n}\n\n// Container allows getting info about and controlling a single container instance\ntype Container interface {\n\tGetContainerID() string                                                        // get the container id from the provider\n\tEndpoint(context.Context, string) (string, error)                              // get proto://ip:port string for the lowest exposed port\n\tPortEndpoint(ctx context.Context, port nat.Port, proto string) (string, error) // get proto://ip:port string for the given exposed port\n\tHost(context.Context) (string, error)                                          // get host where the container port is exposed\n\tInspect(context.Context) (*types.ContainerJSON, error)                         // get container info\n\tMappedPort(context.Context, nat.Port) (nat.Port, error)                        // get externally mapped port for a container port\n\tPorts(context.Context) (nat.PortMap, error)                                    // Deprecated: Use c.Inspect(ctx).NetworkSettings.Ports instead\n\tSessionID() string                                                             // get session id\n\tIsRunning() bool                                                               // IsRunning returns true if the container is running, false otherwise.\n\tStart(context.Context) error                                                   // start the container\n\tStop(context.Context, *time.Duration) error                                    // stop the container\n\n\t// Terminate stops and removes the container and its image if it was built and not flagged as kept.\n\tTerminate(ctx context.Context, opts ...TerminateOption) error\n\n\tLogs(context.Context) (io.ReadCloser, error)                    // Get logs of the container\n\tFollowOutput(LogConsumer)                                       // Deprecated: it will be removed in the next major release\n\tStartLogProducer(context.Context, ...LogProductionOption) error // Deprecated: Use the ContainerRequest instead\n\tStopLogProducer() error                                         // Deprecated: it will be removed in the next major release\n\tName(context.Context) (string, error)                           // Deprecated: Use c.Inspect(ctx).Name instead\n\tState(context.Context) (*types.ContainerState, error)           // returns container's running state\n\tNetworks(context.Context) ([]string, error)                     // get container networks\n\tNetworkAliases(context.Context) (map[string][]string, error)    // get container network aliases for a network\n\tExec(ctx context.Context, cmd []string, options ...tcexec.ProcessOption) (int, io.Reader, error)\n\tContainerIP(context.Context) (string, error)    // get container ip\n\tContainerIPs(context.Context) ([]string, error) // get all container IPs\n\tCopyToContainer(ctx context.Context, fileContent []byte, containerFilePath string, fileMode int64) error\n\tCopyDirToContainer(ctx context.Context, hostDirPath string, containerParentPath string, fileMode int64) error\n\tCopyFileToContainer(ctx context.Context, hostFilePath string, containerFilePath string, fileMode int64) error\n\tCopyFileFromContainer(ctx context.Context, filePath string) (io.ReadCloser, error)\n\tGetLogProductionErrorChannel() <-chan error\n}\n\n// ImageBuildInfo defines what is needed to build an image\ntype ImageBuildInfo interface {\n\tBuildOptions() (types.ImageBuildOptions, error) // converts the ImageBuildInfo to a types.ImageBuildOptions\n\tGetContext() (io.Reader, error)                 // the path to the build context\n\tGetDockerfile() string                          // the relative path to the Dockerfile, including the file itself\n\tGetRepo() string                                // get repo label for image\n\tGetTag() string                                 // get tag label for image\n\tBuildLogWriter() io.Writer                      // for output of build log, use io.Discard to disable the output\n\tShouldBuildImage() bool                         // return true if the image needs to be built\n\tGetBuildArgs() map[string]*string               // return the environment args used to build the from Dockerfile\n\tGetAuthConfigs() map[string]registry.AuthConfig // Deprecated. Testcontainers will detect registry credentials automatically. Return the auth configs to be able to pull from an authenticated docker registry\n}\n\n// FromDockerfile represents the parameters needed to build an image from a Dockerfile\n// rather than using a pre-built one\ntype FromDockerfile struct {\n\tContext        string                         // the path to the context of the docker build\n\tContextArchive io.ReadSeeker                  // the tar archive file to send to docker that contains the build context\n\tDockerfile     string                         // the path from the context to the Dockerfile for the image, defaults to \"Dockerfile\"\n\tRepo           string                         // the repo label for image, defaults to UUID\n\tTag            string                         // the tag label for image, defaults to UUID\n\tBuildArgs      map[string]*string             // enable user to pass build args to docker daemon\n\tPrintBuildLog  bool                           // Deprecated: Use BuildLogWriter instead\n\tBuildLogWriter io.Writer                      // for output of build log, defaults to io.Discard\n\tAuthConfigs    map[string]registry.AuthConfig // Deprecated. Testcontainers will detect registry credentials automatically. Enable auth configs to be able to pull from an authenticated docker registry\n\t// KeepImage describes whether DockerContainer.Terminate should not delete the\n\t// container image. Useful for images that are built from a Dockerfile and take a\n\t// long time to build. Keeping the image also Docker to reuse it.\n\tKeepImage bool\n\t// BuildOptionsModifier Modifier for the build options before image build. Use it for\n\t// advanced configurations while building the image. Please consider that the modifier\n\t// is called after the default build options are set.\n\tBuildOptionsModifier func(*types.ImageBuildOptions)\n}\n\ntype ContainerFile struct {\n\tHostFilePath      string    // If Reader is present, HostFilePath is ignored\n\tReader            io.Reader // If Reader is present, HostFilePath is ignored\n\tContainerFilePath string\n\tFileMode          int64\n}\n\n// validate validates the ContainerFile\nfunc (c *ContainerFile) validate() error {\n\tif c.HostFilePath == \"\" && c.Reader == nil {\n\t\treturn errors.New(\"either HostFilePath or Reader must be specified\")\n\t}\n\n\tif c.ContainerFilePath == \"\" {\n\t\treturn errors.New(\"ContainerFilePath must be specified\")\n\t}\n\n\treturn nil\n}\n\n// ContainerRequest represents the parameters used to get a running container\ntype ContainerRequest struct {\n\tFromDockerfile\n\tHostAccessPorts         []int\n\tImage                   string\n\tImageSubstitutors       []ImageSubstitutor\n\tEntrypoint              []string\n\tEnv                     map[string]string\n\tExposedPorts            []string // allow specifying protocol info\n\tCmd                     []string\n\tLabels                  map[string]string\n\tMounts                  ContainerMounts\n\tTmpfs                   map[string]string\n\tRegistryCred            string // Deprecated: Testcontainers will detect registry credentials automatically\n\tWaitingFor              wait.Strategy\n\tName                    string // for specifying container name\n\tHostname                string\n\tWorkingDir              string                                     // specify the working directory of the container\n\tExtraHosts              []string                                   // Deprecated: Use HostConfigModifier instead\n\tPrivileged              bool                                       // For starting privileged container\n\tNetworks                []string                                   // for specifying network names\n\tNetworkAliases          map[string][]string                        // for specifying network aliases\n\tNetworkMode             container.NetworkMode                      // Deprecated: Use HostConfigModifier instead\n\tResources               container.Resources                        // Deprecated: Use HostConfigModifier instead\n\tFiles                   []ContainerFile                            // files which will be copied when container starts\n\tUser                    string                                     // for specifying uid:gid\n\tSkipReaper              bool                                       // Deprecated: The reaper is globally controlled by the .testcontainers.properties file or the TESTCONTAINERS_RYUK_DISABLED environment variable\n\tReaperImage             string                                     // Deprecated: use WithImageName ContainerOption instead. Alternative reaper image\n\tReaperOptions           []ContainerOption                          // Deprecated: the reaper is configured at the properties level, for an entire test session\n\tAutoRemove              bool                                       // Deprecated: Use HostConfigModifier instead. If set to true, the container will be removed from the host when stopped\n\tAlwaysPullImage         bool                                       // Always pull image\n\tImagePlatform           string                                     // ImagePlatform describes the platform which the image runs on.\n\tBinds                   []string                                   // Deprecated: Use HostConfigModifier instead\n\tShmSize                 int64                                      // Amount of memory shared with the host (in bytes)\n\tCapAdd                  []string                                   // Deprecated: Use HostConfigModifier instead. Add Linux capabilities\n\tCapDrop                 []string                                   // Deprecated: Use HostConfigModifier instead. Drop Linux capabilities\n\tConfigModifier          func(*container.Config)                    // Modifier for the config before container creation\n\tHostConfigModifier      func(*container.HostConfig)                // Modifier for the host config before container creation\n\tEnpointSettingsModifier func(map[string]*network.EndpointSettings) // Modifier for the network settings before container creation\n\tLifecycleHooks          []ContainerLifecycleHooks                  // define hooks to be executed during container lifecycle\n\tLogConsumerCfg          *LogConsumerConfig                         // define the configuration for the log producer and its log consumers to follow the logs\n}\n\n// sessionID returns the session ID for the container request.\nfunc (c *ContainerRequest) sessionID() string {\n\tif sessionID := c.Labels[core.LabelSessionID]; sessionID != \"\" {\n\t\treturn sessionID\n\t}\n\n\treturn core.SessionID()\n}\n\n// containerOptions functional options for a container\ntype containerOptions struct {\n\tImageName           string\n\tRegistryCredentials string // Deprecated: Testcontainers will detect registry credentials automatically\n}\n\n// Deprecated: it will be removed in the next major release\n// functional option for setting the reaper image\ntype ContainerOption func(*containerOptions)\n\n// Deprecated: it will be removed in the next major release\n// WithImageName sets the reaper image name\nfunc WithImageName(imageName string) ContainerOption {\n\treturn func(o *containerOptions) {\n\t\to.ImageName = imageName\n\t}\n}\n\n// Deprecated: Testcontainers will detect registry credentials automatically, and it will be removed in the next major release\n// WithRegistryCredentials sets the reaper registry credentials\nfunc WithRegistryCredentials(registryCredentials string) ContainerOption {\n\treturn func(o *containerOptions) {\n\t\to.RegistryCredentials = registryCredentials\n\t}\n}\n\n// Validate ensures that the ContainerRequest does not have invalid parameters configured to it\n// ex. make sure you are not specifying both an image as well as a context\nfunc (c *ContainerRequest) Validate() error {\n\tvalidationMethods := []func() error{\n\t\tc.validateContextAndImage,\n\t\tc.validateContextOrImageIsSpecified,\n\t\tc.validateMounts,\n\t}\n\n\tvar err error\n\tfor _, validationMethod := range validationMethods {\n\t\terr = validationMethod()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// GetContext retrieve the build context for the request\n// Must be closed when no longer needed.\nfunc (c *ContainerRequest) GetContext() (io.Reader, error) {\n\tvar includes []string = []string{\".\"}\n\n\tif c.ContextArchive != nil {\n\t\treturn c.ContextArchive, nil\n\t}\n\n\t// always pass context as absolute path\n\tabs, err := filepath.Abs(c.Context)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error getting absolute path: %w\", err)\n\t}\n\tc.Context = abs\n\n\tdockerIgnoreExists, excluded, err := parseDockerIgnore(abs)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif dockerIgnoreExists {\n\t\t// only add .dockerignore if it exists\n\t\tincludes = append(includes, \".dockerignore\")\n\t}\n\n\tincludes = append(includes, c.GetDockerfile())\n\n\tbuildContext, err := archive.TarWithOptions(\n\t\tc.Context,\n\t\t&archive.TarOptions{ExcludePatterns: excluded, IncludeFiles: includes},\n\t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn buildContext, nil\n}\n\n// parseDockerIgnore returns if the file exists, the excluded files and an error if any\nfunc parseDockerIgnore(targetDir string) (bool, []string, error) {\n\t// based on https://github.com/docker/cli/blob/master/cli/command/image/build/dockerignore.go#L14\n\tfileLocation := filepath.Join(targetDir, \".dockerignore\")\n\tvar excluded []string\n\texists := false\n\tif f, openErr := os.Open(fileLocation); openErr == nil {\n\t\tdefer f.Close()\n\n\t\texists = true\n\n\t\tvar err error\n\t\texcluded, err = ignorefile.ReadAll(f)\n\t\tif err != nil {\n\t\t\treturn true, excluded, fmt.Errorf(\"error reading .dockerignore: %w\", err)\n\t\t}\n\t}\n\treturn exists, excluded, nil\n}\n\n// GetBuildArgs returns the env args to be used when creating from Dockerfile\nfunc (c *ContainerRequest) GetBuildArgs() map[string]*string {\n\treturn c.FromDockerfile.BuildArgs\n}\n\n// GetDockerfile returns the Dockerfile from the ContainerRequest, defaults to \"Dockerfile\".\n// Sets FromDockerfile.Dockerfile to the default if blank.\nfunc (c *ContainerRequest) GetDockerfile() string {\n\tif c.FromDockerfile.Dockerfile == \"\" {\n\t\tc.FromDockerfile.Dockerfile = \"Dockerfile\"\n\t}\n\n\treturn c.FromDockerfile.Dockerfile\n}\n\n// GetRepo returns the Repo label for image from the ContainerRequest, defaults to UUID.\n// Sets FromDockerfile.Repo to the default value if blank.\nfunc (c *ContainerRequest) GetRepo() string {\n\tif c.FromDockerfile.Repo == \"\" {\n\t\tc.FromDockerfile.Repo = uuid.NewString()\n\t}\n\n\treturn strings.ToLower(c.FromDockerfile.Repo)\n}\n\n// GetTag returns the Tag label for image from the ContainerRequest, defaults to UUID.\n// Sets FromDockerfile.Tag to the default value if blank.\nfunc (c *ContainerRequest) GetTag() string {\n\tif c.FromDockerfile.Tag == \"\" {\n\t\tc.FromDockerfile.Tag = uuid.NewString()\n\t}\n\n\treturn strings.ToLower(c.FromDockerfile.Tag)\n}\n\n// Deprecated: Testcontainers will detect registry credentials automatically, and it will be removed in the next major release.\n// GetAuthConfigs returns the auth configs to be able to pull from an authenticated docker registry.\n// Panics if an error occurs.\nfunc (c *ContainerRequest) GetAuthConfigs() map[string]registry.AuthConfig {\n\tauth, err := getAuthConfigsFromDockerfile(c)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"failed to get auth configs from Dockerfile: %v\", err))\n\t}\n\treturn auth\n}\n\n// dockerFileImages returns the images from the request Dockerfile.\nfunc (c *ContainerRequest) dockerFileImages() ([]string, error) {\n\tif c.ContextArchive == nil {\n\t\t// Source is a directory, we can read the Dockerfile directly.\n\t\timages, err := core.ExtractImagesFromDockerfile(filepath.Join(c.Context, c.GetDockerfile()), c.GetBuildArgs())\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"extract images from Dockerfile: %w\", err)\n\t\t}\n\n\t\treturn images, nil\n\t}\n\n\t// Source is an archive, we need to read it to get the Dockerfile.\n\tdockerFile := c.GetDockerfile()\n\ttr := tar.NewReader(c.FromDockerfile.ContextArchive)\n\n\tfor {\n\t\thdr, err := tr.Next()\n\t\tif err != nil {\n\t\t\tif errors.Is(err, io.EOF) {\n\t\t\t\treturn nil, fmt.Errorf(\"Dockerfile %q not found in context archive\", dockerFile)\n\t\t\t}\n\n\t\t\treturn nil, fmt.Errorf(\"reading tar archive: %w\", err)\n\t\t}\n\n\t\tif hdr.Name != dockerFile {\n\t\t\tcontinue\n\t\t}\n\n\t\timages, err := core.ExtractImagesFromReader(tr, c.GetBuildArgs())\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"extract images from Dockerfile: %w\", err)\n\t\t}\n\n\t\t// Reset the archive to the beginning.\n\t\tif _, err := c.ContextArchive.Seek(0, io.SeekStart); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"seek context archive to start: %w\", err)\n\t\t}\n\n\t\treturn images, nil\n\t}\n}\n\n// getAuthConfigsFromDockerfile returns the auth configs to be able to pull from an authenticated docker registry\nfunc getAuthConfigsFromDockerfile(c *ContainerRequest) (map[string]registry.AuthConfig, error) {\n\timages, err := c.dockerFileImages()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"docker file images: %w\", err)\n\t}\n\n\t// Get the auth configs once for all images as it can be a time-consuming operation.\n\tconfigs, err := getDockerAuthConfigs()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tauthConfigs := map[string]registry.AuthConfig{}\n\tfor _, image := range images {\n\t\tregistry, authConfig, err := dockerImageAuth(context.Background(), image, configs)\n\t\tif err != nil {\n\t\t\tif !errors.Is(err, dockercfg.ErrCredentialsNotFound) {\n\t\t\t\treturn nil, fmt.Errorf(\"docker image auth %q: %w\", image, err)\n\t\t\t}\n\n\t\t\t// Credentials not found no config to add.\n\t\t\tcontinue\n\t\t}\n\n\t\tauthConfigs[registry] = authConfig\n\t}\n\n\treturn authConfigs, nil\n}\n\nfunc (c *ContainerRequest) ShouldBuildImage() bool {\n\treturn c.FromDockerfile.Context != \"\" || c.FromDockerfile.ContextArchive != nil\n}\n\nfunc (c *ContainerRequest) ShouldKeepBuiltImage() bool {\n\treturn c.FromDockerfile.KeepImage\n}\n\n// BuildLogWriter returns the io.Writer for output of log when building a Docker image from\n// a Dockerfile. It returns the BuildLogWriter from the ContainerRequest, defaults to io.Discard.\n// For backward compatibility, if BuildLogWriter is default and PrintBuildLog is true,\n// the function returns os.Stderr.\nfunc (c *ContainerRequest) BuildLogWriter() io.Writer {\n\tif c.FromDockerfile.BuildLogWriter != nil {\n\t\treturn c.FromDockerfile.BuildLogWriter\n\t}\n\tif c.FromDockerfile.PrintBuildLog {\n\t\tc.FromDockerfile.BuildLogWriter = os.Stderr\n\t} else {\n\t\tc.FromDockerfile.BuildLogWriter = io.Discard\n\t}\n\treturn c.FromDockerfile.BuildLogWriter\n}\n\n// BuildOptions returns the image build options when building a Docker image from a Dockerfile.\n// It will apply some defaults and finally call the BuildOptionsModifier from the FromDockerfile struct,\n// if set.\nfunc (c *ContainerRequest) BuildOptions() (types.ImageBuildOptions, error) {\n\tbuildOptions := types.ImageBuildOptions{\n\t\tRemove:      true,\n\t\tForceRemove: true,\n\t}\n\n\tif c.FromDockerfile.BuildOptionsModifier != nil {\n\t\tc.FromDockerfile.BuildOptionsModifier(&buildOptions)\n\t}\n\n\t// apply mandatory values after the modifier\n\tbuildOptions.BuildArgs = c.GetBuildArgs()\n\tbuildOptions.Dockerfile = c.GetDockerfile()\n\n\t// Make sure the auth configs from the Dockerfile are set right after the user-defined build options.\n\tauthsFromDockerfile, err := getAuthConfigsFromDockerfile(c)\n\tif err != nil {\n\t\treturn types.ImageBuildOptions{}, fmt.Errorf(\"auth configs from Dockerfile: %w\", err)\n\t}\n\n\tif buildOptions.AuthConfigs == nil {\n\t\tbuildOptions.AuthConfigs = map[string]registry.AuthConfig{}\n\t}\n\n\tfor registry, authConfig := range authsFromDockerfile {\n\t\tbuildOptions.AuthConfigs[registry] = authConfig\n\t}\n\n\t// make sure the first tag is the one defined in the ContainerRequest\n\ttag := fmt.Sprintf(\"%s:%s\", c.GetRepo(), c.GetTag())\n\n\t// apply substitutors to the built image\n\tfor _, is := range c.ImageSubstitutors {\n\t\tmodifiedTag, err := is.Substitute(tag)\n\t\tif err != nil {\n\t\t\treturn types.ImageBuildOptions{}, fmt.Errorf(\"failed to substitute image %s with %s: %w\", tag, is.Description(), err)\n\t\t}\n\n\t\tif modifiedTag != tag {\n\t\t\tLogger.Printf(\"✍🏼 Replacing image with %s. From: %s to %s\\n\", is.Description(), tag, modifiedTag)\n\t\t\ttag = modifiedTag\n\t\t}\n\t}\n\n\tif len(buildOptions.Tags) > 0 {\n\t\t// prepend the tag\n\t\tbuildOptions.Tags = append([]string{tag}, buildOptions.Tags...)\n\t} else {\n\t\tbuildOptions.Tags = []string{tag}\n\t}\n\n\tif !c.ShouldKeepBuiltImage() {\n\t\tdst := GenericLabels()\n\t\tif err = core.MergeCustomLabels(dst, c.Labels); err != nil {\n\t\t\treturn types.ImageBuildOptions{}, err\n\t\t}\n\t\tif err = core.MergeCustomLabels(dst, buildOptions.Labels); err != nil {\n\t\t\treturn types.ImageBuildOptions{}, err\n\t\t}\n\t\tbuildOptions.Labels = dst\n\t}\n\n\t// Do this as late as possible to ensure we don't leak the context on error/panic.\n\tbuildContext, err := c.GetContext()\n\tif err != nil {\n\t\treturn types.ImageBuildOptions{}, err\n\t}\n\n\tbuildOptions.Context = buildContext\n\n\treturn buildOptions, nil\n}\n\nfunc (c *ContainerRequest) validateContextAndImage() error {\n\tif c.FromDockerfile.Context != \"\" && c.Image != \"\" {\n\t\treturn errors.New(\"you cannot specify both an Image and Context in a ContainerRequest\")\n\t}\n\n\treturn nil\n}\n\nfunc (c *ContainerRequest) validateContextOrImageIsSpecified() error {\n\tif c.FromDockerfile.Context == \"\" && c.FromDockerfile.ContextArchive == nil && c.Image == \"\" {\n\t\treturn errors.New(\"you must specify either a build context or an image\")\n\t}\n\n\treturn nil\n}\n\n// validateMounts ensures that the mounts do not have duplicate targets.\n// It will check the Mounts and HostConfigModifier.Binds fields.\nfunc (c *ContainerRequest) validateMounts() error {\n\ttargets := make(map[string]bool, len(c.Mounts))\n\n\tfor idx := range c.Mounts {\n\t\tm := c.Mounts[idx]\n\t\ttargetPath := m.Target.Target()\n\t\tif targets[targetPath] {\n\t\t\treturn fmt.Errorf(\"%w: %s\", ErrDuplicateMountTarget, targetPath)\n\t\t} else {\n\t\t\ttargets[targetPath] = true\n\t\t}\n\t}\n\n\tif c.HostConfigModifier == nil {\n\t\treturn nil\n\t}\n\n\thostConfig := container.HostConfig{}\n\n\tc.HostConfigModifier(&hostConfig)\n\n\tif len(hostConfig.Binds) > 0 {\n\t\tfor _, bind := range hostConfig.Binds {\n\t\t\tparts := strings.Split(bind, \":\")\n\t\t\tif len(parts) != 2 && len(parts) != 3 {\n\t\t\t\treturn fmt.Errorf(\"%w: %s\", ErrInvalidBindMount, bind)\n\t\t\t}\n\t\t\ttargetPath := parts[1]\n\t\t\tif targets[targetPath] {\n\t\t\t\treturn fmt.Errorf(\"%w: %s\", ErrDuplicateMountTarget, targetPath)\n\t\t\t} else {\n\t\t\t\ttargets[targetPath] = true\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n"
        },
        {
          "name": "container_file_test.go",
          "type": "blob",
          "size": 1.62890625,
          "content": "// This test is testing very internal logic that should not be exported away from this package. We'll\n// leave it in the main testcontainers package. Do not use for user facing examples.\npackage testcontainers\n\nimport (\n\t\"os\"\n\t\"path/filepath\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc TestContainerFileValidation(t *testing.T) {\n\ttype ContainerFileValidationTestCase struct {\n\t\tName          string\n\t\tExpectedError string\n\t\tFile          ContainerFile\n\t}\n\n\tf, err := os.Open(filepath.Join(\".\", \"testdata\", \"hello.sh\"))\n\trequire.NoError(t, err)\n\n\ttestTable := []ContainerFileValidationTestCase{\n\t\t{\n\t\t\tName: \"valid container file: has hostfilepath\",\n\t\t\tFile: ContainerFile{\n\t\t\t\tHostFilePath:      \"/path/to/host\",\n\t\t\t\tContainerFilePath: \"/path/to/container\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"valid container file: has reader\",\n\t\t\tFile: ContainerFile{\n\t\t\t\tReader:            f,\n\t\t\t\tContainerFilePath: \"/path/to/container\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName:          \"invalid container file\",\n\t\t\tExpectedError: \"either HostFilePath or Reader must be specified\",\n\t\t\tFile: ContainerFile{\n\t\t\t\tHostFilePath:      \"\",\n\t\t\t\tReader:            nil,\n\t\t\t\tContainerFilePath: \"/path/to/container\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName:          \"invalid container file\",\n\t\t\tExpectedError: \"ContainerFilePath must be specified\",\n\t\t\tFile: ContainerFile{\n\t\t\t\tHostFilePath:      \"/path/to/host\",\n\t\t\t\tContainerFilePath: \"\",\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, testCase := range testTable {\n\t\tt.Run(testCase.Name, func(t *testing.T) {\n\t\t\terr := testCase.File.validate()\n\t\t\tif testCase.ExpectedError != \"\" {\n\t\t\t\trequire.EqualError(t, err, testCase.ExpectedError)\n\t\t\t} else {\n\t\t\t\trequire.NoError(t, err)\n\t\t\t}\n\t\t})\n\t}\n}\n"
        },
        {
          "name": "container_ignore_test.go",
          "type": "blob",
          "size": 1.2236328125,
          "content": "// This test is testing very internal logic that should not be exported away from this package. We'll\n// leave it in the main testcontainers package. Do not use for user facing examples.\npackage testcontainers\n\nimport (\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc TestParseDockerIgnore(t *testing.T) {\n\ttestCases := []struct {\n\t\tfilePath         string\n\t\texists           bool\n\t\texpectedErr      error\n\t\texpectedExcluded []string\n\t}{\n\t\t{\n\t\t\tfilePath:         \"./testdata/dockerignore\",\n\t\t\texpectedErr:      nil,\n\t\t\texists:           true,\n\t\t\texpectedExcluded: []string{\"vendor\", \"foo\", \"bar\"},\n\t\t},\n\t\t{\n\t\t\tfilePath:         \"./testdata\",\n\t\t\texpectedErr:      nil,\n\t\t\texists:           true,\n\t\t\texpectedExcluded: []string{\"Dockerfile\", \"echo.Dockerfile\"},\n\t\t},\n\t\t{\n\t\t\tfilePath:         \"./testdata/data\",\n\t\t\texpectedErr:      nil,\n\t\t\texpectedExcluded: nil, // it's nil because the parseDockerIgnore function uses the zero value of a slice\n\t\t},\n\t}\n\n\tfor _, testCase := range testCases {\n\t\texists, excluded, err := parseDockerIgnore(testCase.filePath)\n\t\tassert.Equal(t, testCase.exists, exists)\n\t\trequire.ErrorIs(t, testCase.expectedErr, err)\n\t\tassert.Equal(t, testCase.expectedExcluded, excluded)\n\t}\n}\n"
        },
        {
          "name": "container_test.go",
          "type": "blob",
          "size": 14.9423828125,
          "content": "package testcontainers_test\n\nimport (\n\t\"archive/tar\"\n\t\"bytes\"\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/docker/docker/api/types\"\n\t\"github.com/docker/docker/api/types/container\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/testcontainers/testcontainers-go\"\n\t\"github.com/testcontainers/testcontainers-go/wait\"\n)\n\nfunc Test_ContainerValidation(t *testing.T) {\n\ttype ContainerValidationTestCase struct {\n\t\tName             string\n\t\tExpectedError    string\n\t\tContainerRequest testcontainers.ContainerRequest\n\t}\n\n\ttestTable := []ContainerValidationTestCase{\n\t\t{\n\t\t\tName:          \"cannot set both context and image\",\n\t\t\tExpectedError: \"you cannot specify both an Image and Context in a ContainerRequest\",\n\t\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\t\tFromDockerfile: testcontainers.FromDockerfile{\n\t\t\t\t\tContext: \".\",\n\t\t\t\t},\n\t\t\t\tImage: \"redis:latest\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"can set image without context\",\n\t\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\t\tImage: \"redis:latest\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"can set context without image\",\n\t\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\t\tFromDockerfile: testcontainers.FromDockerfile{\n\t\t\t\t\tContext: \".\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"Can mount same source to multiple targets\",\n\t\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\t\tImage: \"redis:latest\",\n\t\t\t\tHostConfigModifier: func(hc *container.HostConfig) {\n\t\t\t\t\thc.Binds = []string{\"/data:/srv\", \"/data:/data\"}\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName:          \"Cannot mount multiple sources to same target\",\n\t\t\tExpectedError: \"duplicate mount target detected: /data\",\n\t\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\t\tImage: \"redis:latest\",\n\t\t\t\tHostConfigModifier: func(hc *container.HostConfig) {\n\t\t\t\t\thc.Binds = []string{\"/data:/data\", \"/data:/data\"}\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName:          \"Invalid bind mount\",\n\t\t\tExpectedError: \"invalid bind mount: /data:/data:a:b\",\n\t\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\t\tImage: \"redis:latest\",\n\t\t\t\tHostConfigModifier: func(hc *container.HostConfig) {\n\t\t\t\t\thc.Binds = []string{\"/data:/data:a:b\"}\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"bind-options/provided\",\n\t\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\t\tImage: \"redis:latest\",\n\t\t\t\tHostConfigModifier: func(hc *container.HostConfig) {\n\t\t\t\t\thc.Binds = []string{\n\t\t\t\t\t\t\"/a:/a:nocopy\",\n\t\t\t\t\t\t\"/b:/b:ro\",\n\t\t\t\t\t\t\"/c:/c:rw\",\n\t\t\t\t\t\t\"/d:/d:z\",\n\t\t\t\t\t\t\"/e:/e:Z\",\n\t\t\t\t\t\t\"/f:/f:shared\",\n\t\t\t\t\t\t\"/g:/g:rshared\",\n\t\t\t\t\t\t\"/h:/h:slave\",\n\t\t\t\t\t\t\"/i:/i:rslave\",\n\t\t\t\t\t\t\"/j:/j:private\",\n\t\t\t\t\t\t\"/k:/k:rprivate\",\n\t\t\t\t\t\t\"/l:/l:ro,z,shared\",\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, testCase := range testTable {\n\t\tt.Run(testCase.Name, func(t *testing.T) {\n\t\t\terr := testCase.ContainerRequest.Validate()\n\t\t\tif testCase.ExpectedError != \"\" {\n\t\t\t\trequire.EqualError(t, err, testCase.ExpectedError)\n\t\t\t} else {\n\t\t\t\trequire.NoError(t, err)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc Test_GetDockerfile(t *testing.T) {\n\ttype TestCase struct {\n\t\tname                   string\n\t\tExpectedDockerfileName string\n\t\tContainerRequest       testcontainers.ContainerRequest\n\t}\n\n\ttestTable := []TestCase{\n\t\t{\n\t\t\tname:                   \"defaults to \\\"Dockerfile\\\" 1\",\n\t\t\tExpectedDockerfileName: \"Dockerfile\",\n\t\t\tContainerRequest:       testcontainers.ContainerRequest{},\n\t\t},\n\t\t{\n\t\t\tname:                   \"defaults to \\\"Dockerfile\\\" 2\",\n\t\t\tExpectedDockerfileName: \"Dockerfile\",\n\t\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\t\tFromDockerfile: testcontainers.FromDockerfile{},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:                   \"will override name\",\n\t\t\tExpectedDockerfileName: \"CustomDockerfile\",\n\t\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\t\tFromDockerfile: testcontainers.FromDockerfile{\n\t\t\t\t\tDockerfile: \"CustomDockerfile\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, testCase := range testTable {\n\t\tt.Run(testCase.name, func(t *testing.T) {\n\t\t\tn := testCase.ContainerRequest.GetDockerfile()\n\t\t\trequire.Equalf(t, n, testCase.ExpectedDockerfileName, \"expected Dockerfile name: %s, received: %s\", testCase.ExpectedDockerfileName, n)\n\t\t})\n\t}\n}\n\nfunc Test_BuildImageWithContexts(t *testing.T) {\n\ttype TestCase struct {\n\t\tName               string\n\t\tContextPath        string\n\t\tContextArchive     func() (io.ReadSeeker, error)\n\t\tExpectedEchoOutput string\n\t\tDockerfile         string\n\t\tExpectedError      string\n\t}\n\n\ttestCases := []TestCase{\n\t\t{\n\t\t\tName: \"test build from context archive\",\n\t\t\t// fromDockerfileWithContextArchive {\n\t\t\tContextArchive: func() (io.ReadSeeker, error) {\n\t\t\t\tvar buf bytes.Buffer\n\t\t\t\ttarWriter := tar.NewWriter(&buf)\n\t\t\t\tfiles := []struct {\n\t\t\t\t\tName     string\n\t\t\t\t\tContents string\n\t\t\t\t}{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"Dockerfile\",\n\t\t\t\t\t\tContents: `FROM alpine\n\t\t\t\t\t\t\t\tCMD [\"echo\", \"this is from the archive\"]`,\n\t\t\t\t\t},\n\t\t\t\t}\n\n\t\t\t\tfor _, f := range files {\n\t\t\t\t\theader := tar.Header{\n\t\t\t\t\t\tName:     f.Name,\n\t\t\t\t\t\tMode:     0o777,\n\t\t\t\t\t\tSize:     int64(len(f.Contents)),\n\t\t\t\t\t\tTypeflag: tar.TypeReg,\n\t\t\t\t\t\tFormat:   tar.FormatGNU,\n\t\t\t\t\t}\n\n\t\t\t\t\tif err := tarWriter.WriteHeader(&header); err != nil {\n\t\t\t\t\t\treturn nil, err\n\t\t\t\t\t}\n\n\t\t\t\t\tif _, err := tarWriter.Write([]byte(f.Contents)); err != nil {\n\t\t\t\t\t\treturn nil, err\n\t\t\t\t\t}\n\n\t\t\t\t\tif err := tarWriter.Close(); err != nil {\n\t\t\t\t\t\treturn nil, err\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\treader := bytes.NewReader(buf.Bytes())\n\n\t\t\t\treturn reader, nil\n\t\t\t},\n\t\t\t// }\n\t\t\tExpectedEchoOutput: \"this is from the archive\",\n\t\t},\n\t\t{\n\t\t\tName: \"test build from context archive and be able to use files in it\",\n\t\t\tContextArchive: func() (io.ReadSeeker, error) {\n\t\t\t\tvar buf bytes.Buffer\n\t\t\t\ttarWriter := tar.NewWriter(&buf)\n\t\t\t\tfiles := []struct {\n\t\t\t\t\tName     string\n\t\t\t\t\tContents string\n\t\t\t\t}{\n\t\t\t\t\t{\n\t\t\t\t\t\tName:     \"say_hi.sh\",\n\t\t\t\t\t\tContents: `echo hi this is from the say_hi.sh file!`,\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"Dockerfile\",\n\t\t\t\t\t\tContents: `FROM alpine\n\t\t\t\t\t\t\t\tWORKDIR /app\n\t\t\t\t\t\t\t\tCOPY . .\n\t\t\t\t\t\t\t\tCMD [\"sh\", \"./say_hi.sh\"]`,\n\t\t\t\t\t},\n\t\t\t\t}\n\n\t\t\t\tfor _, f := range files {\n\t\t\t\t\theader := tar.Header{\n\t\t\t\t\t\tName:     f.Name,\n\t\t\t\t\t\tMode:     0o0777,\n\t\t\t\t\t\tSize:     int64(len(f.Contents)),\n\t\t\t\t\t\tTypeflag: tar.TypeReg,\n\t\t\t\t\t\tFormat:   tar.FormatGNU,\n\t\t\t\t\t}\n\n\t\t\t\t\tif err := tarWriter.WriteHeader(&header); err != nil {\n\t\t\t\t\t\treturn nil, err\n\t\t\t\t\t}\n\n\t\t\t\t\tif _, err := tarWriter.Write([]byte(f.Contents)); err != nil {\n\t\t\t\t\t\treturn nil, err\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif err := tarWriter.Close(); err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\n\t\t\t\treader := bytes.NewReader(buf.Bytes())\n\n\t\t\t\treturn reader, nil\n\t\t\t},\n\t\t\tExpectedEchoOutput: \"hi this is from the say_hi.sh file!\",\n\t\t},\n\t\t{\n\t\t\tName:               \"test building from a context on the filesystem\",\n\t\t\tContextPath:        \"./testdata\",\n\t\t\tDockerfile:         \"echo.Dockerfile\",\n\t\t\tExpectedEchoOutput: \"this is from the echo test Dockerfile\",\n\t\t\tContextArchive: func() (io.ReadSeeker, error) {\n\t\t\t\treturn nil, nil\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName:        \"it should error if neither a context nor a context archive are specified\",\n\t\t\tContextPath: \"\",\n\t\t\tContextArchive: func() (io.ReadSeeker, error) {\n\t\t\t\treturn nil, nil\n\t\t\t},\n\t\t\tExpectedError: \"create container: you must specify either a build context or an image\",\n\t\t},\n\t}\n\n\tfor _, testCase := range testCases {\n\t\ttestCase := testCase\n\t\tt.Run(testCase.Name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\t\t\tctx := context.Background()\n\t\t\ta, err := testCase.ContextArchive()\n\t\t\trequire.NoError(t, err)\n\n\t\t\treq := testcontainers.ContainerRequest{\n\t\t\t\tFromDockerfile: testcontainers.FromDockerfile{\n\t\t\t\t\tContextArchive: a,\n\t\t\t\t\tContext:        testCase.ContextPath,\n\t\t\t\t\tDockerfile:     testCase.Dockerfile,\n\t\t\t\t},\n\t\t\t\tWaitingFor: wait.ForLog(testCase.ExpectedEchoOutput).WithStartupTimeout(1 * time.Minute),\n\t\t\t}\n\n\t\t\tc, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{\n\t\t\t\tContainerRequest: req,\n\t\t\t\tStarted:          true,\n\t\t\t})\n\t\t\ttestcontainers.CleanupContainer(t, c)\n\n\t\t\tif testCase.ExpectedError != \"\" {\n\t\t\t\trequire.EqualError(t, err, testCase.ExpectedError)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\trequire.NoError(t, err)\n\t\t})\n\t}\n}\n\nfunc TestCustomLabelsImage(t *testing.T) {\n\tconst (\n\t\tmyLabelName  = \"org.my.label\"\n\t\tmyLabelValue = \"my-label-value\"\n\t)\n\n\tctx := context.Background()\n\treq := testcontainers.GenericContainerRequest{\n\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\tImage:  \"alpine:latest\",\n\t\t\tLabels: map[string]string{myLabelName: myLabelValue},\n\t\t},\n\t}\n\n\tctr, err := testcontainers.GenericContainer(ctx, req)\n\n\trequire.NoError(t, err)\n\tt.Cleanup(func() { require.NoError(t, ctr.Terminate(ctx)) })\n\n\tctrJSON, err := ctr.Inspect(ctx)\n\trequire.NoError(t, err)\n\tassert.Equal(t, myLabelValue, ctrJSON.Config.Labels[myLabelName])\n}\n\nfunc TestCustomLabelsBuildOptionsModifier(t *testing.T) {\n\tconst (\n\t\tmyLabelName        = \"org.my.label\"\n\t\tmyLabelValue       = \"my-label-value\"\n\t\tmyBuildOptionLabel = \"org.my.bo.label\"\n\t\tmyBuildOptionValue = \"my-bo-label-value\"\n\t)\n\n\tctx := context.Background()\n\treq := testcontainers.GenericContainerRequest{\n\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\tFromDockerfile: testcontainers.FromDockerfile{\n\t\t\t\tContext:    \"./testdata\",\n\t\t\t\tDockerfile: \"Dockerfile\",\n\t\t\t\tBuildOptionsModifier: func(opts *types.ImageBuildOptions) {\n\t\t\t\t\topts.Labels = map[string]string{\n\t\t\t\t\t\tmyBuildOptionLabel: myBuildOptionValue,\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t},\n\t\t\tLabels: map[string]string{myLabelName: myLabelValue},\n\t\t},\n\t}\n\n\tctr, err := testcontainers.GenericContainer(ctx, req)\n\ttestcontainers.CleanupContainer(t, ctr)\n\trequire.NoError(t, err)\n\n\tctrJSON, err := ctr.Inspect(ctx)\n\trequire.NoError(t, err)\n\trequire.Equal(t, myLabelValue, ctrJSON.Config.Labels[myLabelName])\n\trequire.Equal(t, myBuildOptionValue, ctrJSON.Config.Labels[myBuildOptionLabel])\n}\n\nfunc Test_GetLogsFromFailedContainer(t *testing.T) {\n\tctx := context.Background()\n\t// directDockerHubReference {\n\treq := testcontainers.ContainerRequest{\n\t\tImage:      \"alpine\",\n\t\tCmd:        []string{\"echo\", \"-n\", \"I was not expecting this\"},\n\t\tWaitingFor: wait.ForLog(\"I was expecting this\").WithStartupTimeout(5 * time.Second),\n\t}\n\t// }\n\n\tc, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\ttestcontainers.CleanupContainer(t, c)\n\trequire.ErrorContains(t, err, \"container exited with code 0\")\n\n\tlogs, logErr := c.Logs(ctx)\n\trequire.NoError(t, logErr)\n\n\tb, err := io.ReadAll(logs)\n\trequire.NoError(t, err)\n\n\tlog := string(b)\n\trequire.Contains(t, log, \"I was not expecting this\")\n}\n\n// dockerImageSubstitutor {\ntype dockerImageSubstitutor struct{}\n\nfunc (s dockerImageSubstitutor) Description() string {\n\treturn \"DockerImageSubstitutor (prepends registry.hub.docker.com)\"\n}\n\nfunc (s dockerImageSubstitutor) Substitute(image string) (string, error) {\n\treturn \"registry.hub.docker.com/library/\" + image, nil\n}\n\n// }\n\n// noopImageSubstitutor {\ntype NoopImageSubstitutor struct{}\n\n// Description returns a description of what is expected from this Substitutor,\n// which is used in logs.\nfunc (s NoopImageSubstitutor) Description() string {\n\treturn \"NoopImageSubstitutor (noop)\"\n}\n\n// Substitute returns the original image, without any change\nfunc (s NoopImageSubstitutor) Substitute(image string) (string, error) {\n\treturn image, nil\n}\n\n// }\n\ntype errorSubstitutor struct{}\n\nvar errSubstitution = errors.New(\"substitution error\")\n\n// Description returns a description of what is expected from this Substitutor,\n// which is used in logs.\nfunc (s errorSubstitutor) Description() string {\n\treturn \"errorSubstitutor\"\n}\n\n// Substitute returns the original image, but returns an error\nfunc (s errorSubstitutor) Substitute(image string) (string, error) {\n\treturn image, errSubstitution\n}\n\nfunc TestImageSubstitutors(t *testing.T) {\n\ttests := []struct {\n\t\tname          string\n\t\timage         string // must be a valid image, as the test will try to create a container from it\n\t\tsubstitutors  []testcontainers.ImageSubstitutor\n\t\texpectedImage string\n\t\texpectedError error\n\t}{\n\t\t{\n\t\t\tname:          \"No substitutors\",\n\t\t\timage:         \"alpine\",\n\t\t\texpectedImage: \"alpine\",\n\t\t},\n\t\t{\n\t\t\tname:          \"Noop substitutor\",\n\t\t\timage:         \"alpine\",\n\t\t\tsubstitutors:  []testcontainers.ImageSubstitutor{NoopImageSubstitutor{}},\n\t\t\texpectedImage: \"alpine\",\n\t\t},\n\t\t{\n\t\t\tname:          \"Prepend namespace\",\n\t\t\timage:         \"alpine\",\n\t\t\tsubstitutors:  []testcontainers.ImageSubstitutor{dockerImageSubstitutor{}},\n\t\t\texpectedImage: \"registry.hub.docker.com/library/alpine\",\n\t\t},\n\t\t{\n\t\t\tname:          \"Substitution with error\",\n\t\t\timage:         \"alpine\",\n\t\t\tsubstitutors:  []testcontainers.ImageSubstitutor{errorSubstitutor{}},\n\t\t\texpectedImage: \"alpine\",\n\t\t\texpectedError: errSubstitution,\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tctx := context.Background()\n\t\t\treq := testcontainers.ContainerRequest{\n\t\t\t\tImage:             test.image,\n\t\t\t\tImageSubstitutors: test.substitutors,\n\t\t\t}\n\n\t\t\tctr, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{\n\t\t\t\tContainerRequest: req,\n\t\t\t\tStarted:          true,\n\t\t\t})\n\t\t\ttestcontainers.CleanupContainer(t, ctr)\n\t\t\tif test.expectedError != nil {\n\t\t\t\trequire.ErrorIs(t, err, test.expectedError)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\trequire.NoError(t, err)\n\n\t\t\t// enforce the concrete type, as GenericContainer returns an interface,\n\t\t\t// which will be changed in future implementations of the library\n\t\t\tdockerContainer := ctr.(*testcontainers.DockerContainer)\n\t\t\tassert.Equal(t, test.expectedImage, dockerContainer.Image)\n\t\t})\n\t}\n}\n\nfunc TestShouldStartContainersInParallel(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 1*time.Minute)\n\tt.Cleanup(cancel)\n\n\tfor i := 0; i < 3; i++ {\n\t\ti := i\n\t\tt.Run(fmt.Sprintf(\"iteration_%d\", i), func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\treq := testcontainers.ContainerRequest{\n\t\t\t\tImage:        nginxAlpineImage,\n\t\t\t\tExposedPorts: []string{nginxDefaultPort},\n\t\t\t\tWaitingFor:   wait.ForHTTP(\"/\").WithStartupTimeout(10 * time.Second),\n\t\t\t}\n\t\t\tctr, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{\n\t\t\t\tContainerRequest: req,\n\t\t\t\tStarted:          true,\n\t\t\t})\n\t\t\ttestcontainers.CleanupContainer(t, ctr)\n\t\t\trequire.NoError(t, err)\n\n\t\t\t// mappedPort {\n\t\t\tport, err := ctr.MappedPort(ctx, nginxDefaultPort)\n\t\t\t// }\n\t\t\trequire.NoError(t, err)\n\n\t\t\tt.Logf(\"Parallel container [iteration_%d] listening on %d\\n\", i, port.Int())\n\t\t})\n\t}\n}\n\nfunc ExampleGenericContainer_withSubstitutors() {\n\tctx := context.Background()\n\n\t// applyImageSubstitutors {\n\tctr, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{\n\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\tImage:             \"alpine:latest\",\n\t\t\tImageSubstitutors: []testcontainers.ImageSubstitutor{dockerImageSubstitutor{}},\n\t\t},\n\t\tStarted: true,\n\t})\n\tdefer func() {\n\t\tif err := testcontainers.TerminateContainer(ctr); err != nil {\n\t\t\tlog.Printf(\"failed to terminate container: %s\", err)\n\t\t}\n\t}()\n\n\t// }\n\tif err != nil {\n\t\tlog.Printf(\"could not start container: %v\", err)\n\t\treturn\n\t}\n\n\t// enforce the concrete type, as GenericContainer returns an interface,\n\t// which will be changed in future implementations of the library\n\tdockerContainer := ctr.(*testcontainers.DockerContainer)\n\n\tfmt.Println(dockerContainer.Image)\n\n\t// Output: registry.hub.docker.com/library/alpine:latest\n}\n"
        },
        {
          "name": "docker.go",
          "type": "blob",
          "size": 49.841796875,
          "content": "package testcontainers\n\nimport (\n\t\"archive/tar\"\n\t\"bufio\"\n\t\"context\"\n\t\"encoding/base64\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/fs\"\n\t\"net\"\n\t\"net/url\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/cenkalti/backoff/v4\"\n\t\"github.com/containerd/platforms\"\n\t\"github.com/docker/docker/api/types\"\n\t\"github.com/docker/docker/api/types/container\"\n\t\"github.com/docker/docker/api/types/filters\"\n\t\"github.com/docker/docker/api/types/image\"\n\t\"github.com/docker/docker/api/types/network\"\n\t\"github.com/docker/docker/client\"\n\t\"github.com/docker/docker/errdefs\"\n\t\"github.com/docker/docker/pkg/jsonmessage\"\n\t\"github.com/docker/docker/pkg/stdcopy\"\n\t\"github.com/docker/go-connections/nat\"\n\t\"github.com/moby/term\"\n\tspecs \"github.com/opencontainers/image-spec/specs-go/v1\"\n\n\ttcexec \"github.com/testcontainers/testcontainers-go/exec\"\n\t\"github.com/testcontainers/testcontainers-go/internal/config\"\n\t\"github.com/testcontainers/testcontainers-go/internal/core\"\n\t\"github.com/testcontainers/testcontainers-go/wait\"\n)\n\n// Implement interfaces\nvar _ Container = (*DockerContainer)(nil)\n\nconst (\n\tBridge        = \"bridge\" // Bridge network name (as well as driver)\n\tPodman        = \"podman\"\n\tReaperDefault = \"reaper_default\" // Default network name when bridge is not available\n\tpackagePath   = \"github.com/testcontainers/testcontainers-go\"\n)\n\nvar (\n\t// createContainerFailDueToNameConflictRegex is a regular expression that matches the container is already in use error.\n\tcreateContainerFailDueToNameConflictRegex = regexp.MustCompile(\"Conflict. The container name .* is already in use by container .*\")\n\n\t// minLogProductionTimeout is the minimum log production timeout.\n\tminLogProductionTimeout = time.Duration(5 * time.Second)\n\n\t// maxLogProductionTimeout is the maximum log production timeout.\n\tmaxLogProductionTimeout = time.Duration(60 * time.Second)\n\n\t// errLogProductionStop is the cause for stopping log production.\n\terrLogProductionStop = errors.New(\"log production stopped\")\n)\n\n// DockerContainer represents a container started using Docker\ntype DockerContainer struct {\n\t// Container ID from Docker\n\tID           string\n\tWaitingFor   wait.Strategy\n\tImage        string\n\texposedPorts []string // a reference to the container's requested exposed ports. It allows checking they are ready before any wait strategy\n\n\tisRunning     bool\n\timageWasBuilt bool\n\t// keepBuiltImage makes Terminate not remove the image if imageWasBuilt.\n\tkeepBuiltImage    bool\n\tprovider          *DockerProvider\n\tsessionID         string\n\tterminationSignal chan bool\n\tconsumers         []LogConsumer\n\n\t// TODO: Remove locking and wait group once the deprecated StartLogProducer and\n\t// StopLogProducer have been removed and hence logging can only be started and\n\t// stopped once.\n\n\t// logProductionCancel is used to signal the log production to stop.\n\tlogProductionCancel context.CancelCauseFunc\n\tlogProductionCtx    context.Context\n\n\tlogProductionTimeout *time.Duration\n\tlogger               Logging\n\tlifecycleHooks       []ContainerLifecycleHooks\n\n\thealthStatus string // container health status, will default to healthStatusNone if no healthcheck is present\n}\n\n// SetLogger sets the logger for the container\nfunc (c *DockerContainer) SetLogger(logger Logging) {\n\tc.logger = logger\n}\n\n// SetProvider sets the provider for the container\nfunc (c *DockerContainer) SetProvider(provider *DockerProvider) {\n\tc.provider = provider\n}\n\n// SetTerminationSignal sets the termination signal for the container\nfunc (c *DockerContainer) SetTerminationSignal(signal chan bool) {\n\tc.terminationSignal = signal\n}\n\nfunc (c *DockerContainer) GetContainerID() string {\n\treturn c.ID\n}\n\nfunc (c *DockerContainer) IsRunning() bool {\n\treturn c.isRunning\n}\n\n// Endpoint gets proto://host:port string for the lowest numbered exposed port\n// Will returns just host:port if proto is \"\"\nfunc (c *DockerContainer) Endpoint(ctx context.Context, proto string) (string, error) {\n\tinspect, err := c.Inspect(ctx)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\t// Get lowest numbered bound port.\n\tvar lowestPort nat.Port\n\tfor port := range inspect.NetworkSettings.Ports {\n\t\tif lowestPort == \"\" || port.Int() < lowestPort.Int() {\n\t\t\tlowestPort = port\n\t\t}\n\t}\n\n\treturn c.PortEndpoint(ctx, lowestPort, proto)\n}\n\n// PortEndpoint gets proto://host:port string for the given exposed port\n// Will returns just host:port if proto is \"\"\nfunc (c *DockerContainer) PortEndpoint(ctx context.Context, port nat.Port, proto string) (string, error) {\n\thost, err := c.Host(ctx)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\touterPort, err := c.MappedPort(ctx, port)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tprotoFull := \"\"\n\tif proto != \"\" {\n\t\tprotoFull = proto + \"://\"\n\t}\n\n\treturn fmt.Sprintf(\"%s%s:%s\", protoFull, host, outerPort.Port()), nil\n}\n\n// Host gets host (ip or name) of the docker daemon where the container port is exposed\n// Warning: this is based on your Docker host setting. Will fail if using an SSH tunnel\n// You can use the \"TESTCONTAINERS_HOST_OVERRIDE\" env variable to set this yourself\nfunc (c *DockerContainer) Host(ctx context.Context) (string, error) {\n\thost, err := c.provider.DaemonHost(ctx)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn host, nil\n}\n\n// Inspect gets the raw container info\nfunc (c *DockerContainer) Inspect(ctx context.Context) (*types.ContainerJSON, error) {\n\tjsonRaw, err := c.inspectRawContainer(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn jsonRaw, nil\n}\n\n// MappedPort gets externally mapped port for a container port\nfunc (c *DockerContainer) MappedPort(ctx context.Context, port nat.Port) (nat.Port, error) {\n\tinspect, err := c.Inspect(ctx)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"inspect: %w\", err)\n\t}\n\tif inspect.ContainerJSONBase.HostConfig.NetworkMode == \"host\" {\n\t\treturn port, nil\n\t}\n\n\tports := inspect.NetworkSettings.Ports\n\n\tfor k, p := range ports {\n\t\tif k.Port() != port.Port() {\n\t\t\tcontinue\n\t\t}\n\t\tif port.Proto() != \"\" && k.Proto() != port.Proto() {\n\t\t\tcontinue\n\t\t}\n\t\tif len(p) == 0 {\n\t\t\tcontinue\n\t\t}\n\t\treturn nat.NewPort(k.Proto(), p[0].HostPort)\n\t}\n\n\treturn \"\", errdefs.NotFound(fmt.Errorf(\"port %q not found\", port))\n}\n\n// Deprecated: use c.Inspect(ctx).NetworkSettings.Ports instead.\n// Ports gets the exposed ports for the container.\nfunc (c *DockerContainer) Ports(ctx context.Context) (nat.PortMap, error) {\n\tinspect, err := c.Inspect(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn inspect.NetworkSettings.Ports, nil\n}\n\n// SessionID gets the current session id\nfunc (c *DockerContainer) SessionID() string {\n\treturn c.sessionID\n}\n\n// Start will start an already created container\nfunc (c *DockerContainer) Start(ctx context.Context) error {\n\terr := c.startingHook(ctx)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"starting hook: %w\", err)\n\t}\n\n\tif err := c.provider.client.ContainerStart(ctx, c.ID, container.StartOptions{}); err != nil {\n\t\treturn fmt.Errorf(\"container start: %w\", err)\n\t}\n\tdefer c.provider.Close()\n\n\terr = c.startedHook(ctx)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"started hook: %w\", err)\n\t}\n\n\tc.isRunning = true\n\n\terr = c.readiedHook(ctx)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"readied hook: %w\", err)\n\t}\n\n\treturn nil\n}\n\n// Stop stops the container.\n//\n// In case the container fails to stop gracefully within a time frame specified\n// by the timeout argument, it is forcefully terminated (killed).\n//\n// If the timeout is nil, the container's StopTimeout value is used, if set,\n// otherwise the engine default. A negative timeout value can be specified,\n// meaning no timeout, i.e. no forceful termination is performed.\n//\n// All hooks are called in the following order:\n//   - [ContainerLifecycleHooks.PreStops]\n//   - [ContainerLifecycleHooks.PostStops]\n//\n// If the container is already stopped, the method is a no-op.\nfunc (c *DockerContainer) Stop(ctx context.Context, timeout *time.Duration) error {\n\t// Note we can't check isRunning here because we allow external creation\n\t// without exposing the ability to fully initialize the container state.\n\t// See: https://github.com/testcontainers/testcontainers-go/issues/2667\n\t// TODO: Add a check for isRunning when the above issue is resolved.\n\terr := c.stoppingHook(ctx)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"stopping hook: %w\", err)\n\t}\n\n\tvar options container.StopOptions\n\n\tif timeout != nil {\n\t\ttimeoutSeconds := int(timeout.Seconds())\n\t\toptions.Timeout = &timeoutSeconds\n\t}\n\n\tif err := c.provider.client.ContainerStop(ctx, c.ID, options); err != nil {\n\t\treturn fmt.Errorf(\"container stop: %w\", err)\n\t}\n\n\tdefer c.provider.Close()\n\n\tc.isRunning = false\n\n\terr = c.stoppedHook(ctx)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"stopped hook: %w\", err)\n\t}\n\n\treturn nil\n}\n\n// Terminate calls stops and then removes the container including its volumes.\n// If its image was built it and all child images are also removed unless\n// the [FromDockerfile.KeepImage] on the [ContainerRequest] was set to true.\n//\n// The following hooks are called in order:\n//   - [ContainerLifecycleHooks.PreTerminates]\n//   - [ContainerLifecycleHooks.PostTerminates]\n//\n// Default: timeout is 10 seconds.\nfunc (c *DockerContainer) Terminate(ctx context.Context, opts ...TerminateOption) error {\n\toptions := NewTerminateOptions(ctx, opts...)\n\terr := c.Stop(options.Context(), options.StopTimeout())\n\tif err != nil && !isCleanupSafe(err) {\n\t\treturn fmt.Errorf(\"stop: %w\", err)\n\t}\n\n\tselect {\n\t// Close reaper connection if it was attached.\n\tcase c.terminationSignal <- true:\n\tdefault:\n\t}\n\n\tdefer c.provider.client.Close()\n\n\t// TODO: Handle errors from ContainerRemove more correctly, e.g. should we\n\t// run the terminated hook?\n\terrs := []error{\n\t\tc.terminatingHook(ctx),\n\t\tc.provider.client.ContainerRemove(ctx, c.GetContainerID(), container.RemoveOptions{\n\t\t\tRemoveVolumes: true,\n\t\t\tForce:         true,\n\t\t}),\n\t\tc.terminatedHook(ctx),\n\t}\n\n\tif c.imageWasBuilt && !c.keepBuiltImage {\n\t\t_, err := c.provider.client.ImageRemove(ctx, c.Image, image.RemoveOptions{\n\t\t\tForce:         true,\n\t\t\tPruneChildren: true,\n\t\t})\n\t\terrs = append(errs, err)\n\t}\n\n\tc.sessionID = \"\"\n\tc.isRunning = false\n\n\tif err = options.Cleanup(); err != nil {\n\t\terrs = append(errs, err)\n\t}\n\n\treturn errors.Join(errs...)\n}\n\n// update container raw info\nfunc (c *DockerContainer) inspectRawContainer(ctx context.Context) (*types.ContainerJSON, error) {\n\tdefer c.provider.Close()\n\tinspect, err := c.provider.client.ContainerInspect(ctx, c.ID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &inspect, nil\n}\n\n// Logs will fetch both STDOUT and STDERR from the current container. Returns a\n// ReadCloser and leaves it up to the caller to extract what it wants.\nfunc (c *DockerContainer) Logs(ctx context.Context) (io.ReadCloser, error) {\n\tconst streamHeaderSize = 8\n\n\toptions := container.LogsOptions{\n\t\tShowStdout: true,\n\t\tShowStderr: true,\n\t}\n\n\trc, err := c.provider.client.ContainerLogs(ctx, c.ID, options)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer c.provider.Close()\n\n\tpr, pw := io.Pipe()\n\tr := bufio.NewReader(rc)\n\n\tgo func() {\n\t\tlineStarted := true\n\t\tfor err == nil {\n\t\t\tline, isPrefix, err := r.ReadLine()\n\n\t\t\tif lineStarted && len(line) >= streamHeaderSize {\n\t\t\t\tline = line[streamHeaderSize:] // trim stream header\n\t\t\t\tlineStarted = false\n\t\t\t}\n\t\t\tif !isPrefix {\n\t\t\t\tlineStarted = true\n\t\t\t}\n\n\t\t\t_, errW := pw.Write(line)\n\t\t\tif errW != nil {\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tif !isPrefix {\n\t\t\t\t_, errW := pw.Write([]byte(\"\\n\"))\n\t\t\t\tif errW != nil {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif err != nil {\n\t\t\t\t_ = pw.CloseWithError(err)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn pr, nil\n}\n\n// Deprecated: use the ContainerRequest.LogConsumerConfig field instead.\nfunc (c *DockerContainer) FollowOutput(consumer LogConsumer) {\n\tc.followOutput(consumer)\n}\n\n// followOutput adds a LogConsumer to be sent logs from the container's\n// STDOUT and STDERR\nfunc (c *DockerContainer) followOutput(consumer LogConsumer) {\n\tc.consumers = append(c.consumers, consumer)\n}\n\n// Deprecated: use c.Inspect(ctx).Name instead.\n// Name gets the name of the container.\nfunc (c *DockerContainer) Name(ctx context.Context) (string, error) {\n\tinspect, err := c.Inspect(ctx)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn inspect.Name, nil\n}\n\n// State returns container's running state.\nfunc (c *DockerContainer) State(ctx context.Context) (*types.ContainerState, error) {\n\tinspect, err := c.inspectRawContainer(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn inspect.State, nil\n}\n\n// Networks gets the names of the networks the container is attached to.\nfunc (c *DockerContainer) Networks(ctx context.Context) ([]string, error) {\n\tinspect, err := c.Inspect(ctx)\n\tif err != nil {\n\t\treturn []string{}, err\n\t}\n\n\tnetworks := inspect.NetworkSettings.Networks\n\n\tn := []string{}\n\n\tfor k := range networks {\n\t\tn = append(n, k)\n\t}\n\n\treturn n, nil\n}\n\n// ContainerIP gets the IP address of the primary network within the container.\nfunc (c *DockerContainer) ContainerIP(ctx context.Context) (string, error) {\n\tinspect, err := c.Inspect(ctx)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tip := inspect.NetworkSettings.IPAddress\n\tif ip == \"\" {\n\t\t// use IP from \"Networks\" if only single network defined\n\t\tnetworks := inspect.NetworkSettings.Networks\n\t\tif len(networks) == 1 {\n\t\t\tfor _, v := range networks {\n\t\t\t\tip = v.IPAddress\n\t\t\t}\n\t\t}\n\t}\n\n\treturn ip, nil\n}\n\n// ContainerIPs gets the IP addresses of all the networks within the container.\nfunc (c *DockerContainer) ContainerIPs(ctx context.Context) ([]string, error) {\n\tips := make([]string, 0)\n\n\tinspect, err := c.Inspect(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tnetworks := inspect.NetworkSettings.Networks\n\tfor _, nw := range networks {\n\t\tips = append(ips, nw.IPAddress)\n\t}\n\n\treturn ips, nil\n}\n\n// NetworkAliases gets the aliases of the container for the networks it is attached to.\nfunc (c *DockerContainer) NetworkAliases(ctx context.Context) (map[string][]string, error) {\n\tinspect, err := c.Inspect(ctx)\n\tif err != nil {\n\t\treturn map[string][]string{}, err\n\t}\n\n\tnetworks := inspect.NetworkSettings.Networks\n\n\ta := map[string][]string{}\n\n\tfor k := range networks {\n\t\ta[k] = networks[k].Aliases\n\t}\n\n\treturn a, nil\n}\n\n// Exec executes a command in the current container.\n// It returns the exit status of the executed command, an [io.Reader] containing the combined\n// stdout and stderr, and any encountered error. Note that reading directly from the [io.Reader]\n// may result in unexpected bytes due to custom stream multiplexing headers.\n// Use [tcexec.Multiplexed] option to read the combined output without the multiplexing headers.\n// Alternatively, to separate the stdout and stderr from [io.Reader] and interpret these headers properly,\n// [github.com/docker/docker/pkg/stdcopy.StdCopy] from the Docker API should be used.\nfunc (c *DockerContainer) Exec(ctx context.Context, cmd []string, options ...tcexec.ProcessOption) (int, io.Reader, error) {\n\tcli := c.provider.client\n\n\tprocessOptions := tcexec.NewProcessOptions(cmd)\n\n\t// processing all the options in a first loop because for the multiplexed option\n\t// we first need to have a containerExecCreateResponse\n\tfor _, o := range options {\n\t\to.Apply(processOptions)\n\t}\n\n\tresponse, err := cli.ContainerExecCreate(ctx, c.ID, processOptions.ExecConfig)\n\tif err != nil {\n\t\treturn 0, nil, fmt.Errorf(\"container exec create: %w\", err)\n\t}\n\n\thijack, err := cli.ContainerExecAttach(ctx, response.ID, container.ExecAttachOptions{})\n\tif err != nil {\n\t\treturn 0, nil, fmt.Errorf(\"container exec attach: %w\", err)\n\t}\n\n\tprocessOptions.Reader = hijack.Reader\n\n\t// second loop to process the multiplexed option, as now we have a reader\n\t// from the created exec response.\n\tfor _, o := range options {\n\t\to.Apply(processOptions)\n\t}\n\n\tvar exitCode int\n\tfor {\n\t\texecResp, err := cli.ContainerExecInspect(ctx, response.ID)\n\t\tif err != nil {\n\t\t\treturn 0, nil, fmt.Errorf(\"container exec inspect: %w\", err)\n\t\t}\n\n\t\tif !execResp.Running {\n\t\t\texitCode = execResp.ExitCode\n\t\t\tbreak\n\t\t}\n\n\t\ttime.Sleep(100 * time.Millisecond)\n\t}\n\n\treturn exitCode, processOptions.Reader, nil\n}\n\ntype FileFromContainer struct {\n\tunderlying *io.ReadCloser\n\ttarreader  *tar.Reader\n}\n\nfunc (fc *FileFromContainer) Read(b []byte) (int, error) {\n\treturn (*fc.tarreader).Read(b)\n}\n\nfunc (fc *FileFromContainer) Close() error {\n\treturn (*fc.underlying).Close()\n}\n\nfunc (c *DockerContainer) CopyFileFromContainer(ctx context.Context, filePath string) (io.ReadCloser, error) {\n\tr, _, err := c.provider.client.CopyFromContainer(ctx, c.ID, filePath)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer c.provider.Close()\n\n\ttarReader := tar.NewReader(r)\n\n\t// if we got here we have exactly one file in the TAR-stream\n\t// so we advance the index by one so the next call to Read will start reading it\n\t_, err = tarReader.Next()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tret := &FileFromContainer{\n\t\tunderlying: &r,\n\t\ttarreader:  tarReader,\n\t}\n\n\treturn ret, nil\n}\n\n// CopyDirToContainer copies the contents of a directory to a parent path in the container. This parent path must exist in the container first\n// as we cannot create it\nfunc (c *DockerContainer) CopyDirToContainer(ctx context.Context, hostDirPath string, containerParentPath string, fileMode int64) error {\n\tdir, err := isDir(hostDirPath)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif !dir {\n\t\t// it's not a dir: let the consumer to handle an error\n\t\treturn fmt.Errorf(\"path %s is not a directory\", hostDirPath)\n\t}\n\n\tbuff, err := tarDir(hostDirPath, fileMode)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// create the directory under its parent\n\tparent := filepath.Dir(containerParentPath)\n\n\terr = c.provider.client.CopyToContainer(ctx, c.ID, parent, buff, container.CopyToContainerOptions{})\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer c.provider.Close()\n\n\treturn nil\n}\n\nfunc (c *DockerContainer) CopyFileToContainer(ctx context.Context, hostFilePath string, containerFilePath string, fileMode int64) error {\n\tdir, err := isDir(hostFilePath)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif dir {\n\t\treturn c.CopyDirToContainer(ctx, hostFilePath, containerFilePath, fileMode)\n\t}\n\n\tf, err := os.Open(hostFilePath)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer f.Close()\n\n\tinfo, err := f.Stat()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// In Go 1.22 os.File is always an io.WriterTo. However, testcontainers\n\t// currently allows Go 1.21, so we need to trick the compiler a little.\n\tvar file fs.File = f\n\treturn c.copyToContainer(ctx, func(tw io.Writer) error {\n\t\t// Attempt optimized writeTo, implemented in linux\n\t\tif wt, ok := file.(io.WriterTo); ok {\n\t\t\t_, err := wt.WriteTo(tw)\n\t\t\treturn err\n\t\t}\n\t\t_, err := io.Copy(tw, f)\n\t\treturn err\n\t}, info.Size(), containerFilePath, fileMode)\n}\n\n// CopyToContainer copies fileContent data to a file in container\nfunc (c *DockerContainer) CopyToContainer(ctx context.Context, fileContent []byte, containerFilePath string, fileMode int64) error {\n\treturn c.copyToContainer(ctx, func(tw io.Writer) error {\n\t\t_, err := tw.Write(fileContent)\n\t\treturn err\n\t}, int64(len(fileContent)), containerFilePath, fileMode)\n}\n\nfunc (c *DockerContainer) copyToContainer(ctx context.Context, fileContent func(tw io.Writer) error, fileContentSize int64, containerFilePath string, fileMode int64) error {\n\tbuffer, err := tarFile(containerFilePath, fileContent, fileContentSize, fileMode)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\terr = c.provider.client.CopyToContainer(ctx, c.ID, \"/\", buffer, container.CopyToContainerOptions{})\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer c.provider.Close()\n\n\treturn nil\n}\n\n// logConsumerWriter is a writer that writes to a LogConsumer.\ntype logConsumerWriter struct {\n\tlog       Log\n\tconsumers []LogConsumer\n}\n\n// newLogConsumerWriter creates a new logConsumerWriter for logType that sends messages to all consumers.\nfunc newLogConsumerWriter(logType string, consumers []LogConsumer) *logConsumerWriter {\n\treturn &logConsumerWriter{\n\t\tlog:       Log{LogType: logType},\n\t\tconsumers: consumers,\n\t}\n}\n\n// Write writes the p content to all consumers.\nfunc (lw logConsumerWriter) Write(p []byte) (int, error) {\n\tlw.log.Content = p\n\tfor _, consumer := range lw.consumers {\n\t\tconsumer.Accept(lw.log)\n\t}\n\treturn len(p), nil\n}\n\ntype LogProductionOption func(*DockerContainer)\n\n// WithLogProductionTimeout is a functional option that sets the timeout for the log production.\n// If the timeout is lower than 5s or greater than 60s it will be set to 5s or 60s respectively.\nfunc WithLogProductionTimeout(timeout time.Duration) LogProductionOption {\n\treturn func(c *DockerContainer) {\n\t\tc.logProductionTimeout = &timeout\n\t}\n}\n\n// Deprecated: use the ContainerRequest.LogConsumerConfig field instead.\nfunc (c *DockerContainer) StartLogProducer(ctx context.Context, opts ...LogProductionOption) error {\n\treturn c.startLogProduction(ctx, opts...)\n}\n\n// startLogProduction will start a concurrent process that will continuously read logs\n// from the container and will send them to each added LogConsumer.\n//\n// Default log production timeout is 5s. It is used to set the context timeout\n// which means that each log-reading loop will last at up to the specified timeout.\n//\n// Use functional option WithLogProductionTimeout() to override default timeout. If it's\n// lower than 5s and greater than 60s it will be set to 5s or 60s respectively.\nfunc (c *DockerContainer) startLogProduction(ctx context.Context, opts ...LogProductionOption) error {\n\tfor _, opt := range opts {\n\t\topt(c)\n\t}\n\n\t// Validate the log production timeout.\n\tswitch {\n\tcase c.logProductionTimeout == nil:\n\t\tc.logProductionTimeout = &minLogProductionTimeout\n\tcase *c.logProductionTimeout < minLogProductionTimeout:\n\t\tc.logProductionTimeout = &minLogProductionTimeout\n\tcase *c.logProductionTimeout > maxLogProductionTimeout:\n\t\tc.logProductionTimeout = &maxLogProductionTimeout\n\t}\n\n\t// Setup the log writers.\n\tstdout := newLogConsumerWriter(StdoutLog, c.consumers)\n\tstderr := newLogConsumerWriter(StderrLog, c.consumers)\n\n\t// Setup the log production context which will be used to stop the log production.\n\tc.logProductionCtx, c.logProductionCancel = context.WithCancelCause(ctx)\n\n\t// We capture context cancel function to avoid data race with multiple\n\t// calls to startLogProduction.\n\tgo func(cancel context.CancelCauseFunc) {\n\t\t// Ensure the context is cancelled when log productions completes\n\t\t// so that GetLogProductionErrorChannel functions correctly.\n\t\tdefer cancel(nil)\n\n\t\tc.logProducer(stdout, stderr)\n\t}(c.logProductionCancel)\n\n\treturn nil\n}\n\n// logProducer read logs from the container and writes them to stdout, stderr until either:\n//   - logProductionCtx is done\n//   - A fatal error occurs\n//   - No more logs are available\nfunc (c *DockerContainer) logProducer(stdout, stderr io.Writer) {\n\t// Clean up idle client connections.\n\tdefer c.provider.Close()\n\n\t// Setup the log options, start from the beginning.\n\toptions := &container.LogsOptions{\n\t\tShowStdout: true,\n\t\tShowStderr: true,\n\t\tFollow:     true,\n\t}\n\n\t// Use a separate method so that timeout cancel function is\n\t// called correctly.\n\tfor c.copyLogsTimeout(stdout, stderr, options) {\n\t}\n}\n\n// copyLogsTimeout copies logs from the container to stdout and stderr with a timeout.\n// It returns true if the log production should be retried, false otherwise.\nfunc (c *DockerContainer) copyLogsTimeout(stdout, stderr io.Writer, options *container.LogsOptions) bool {\n\ttimeoutCtx, cancel := context.WithTimeout(c.logProductionCtx, *c.logProductionTimeout)\n\tdefer cancel()\n\n\terr := c.copyLogs(timeoutCtx, stdout, stderr, *options)\n\tswitch {\n\tcase err == nil:\n\t\t// No more logs available.\n\t\treturn false\n\tcase c.logProductionCtx.Err() != nil:\n\t\t// Log production was stopped or caller context is done.\n\t\treturn false\n\tcase timeoutCtx.Err() != nil, errors.Is(err, net.ErrClosed):\n\t\t// Timeout or client connection closed, retry.\n\tdefault:\n\t\t// Unexpected error, retry.\n\t\tLogger.Printf(\"Unexpected error reading logs: %v\", err)\n\t}\n\n\t// Retry from the last log received.\n\tnow := time.Now()\n\toptions.Since = fmt.Sprintf(\"%d.%09d\", now.Unix(), int64(now.Nanosecond()))\n\n\treturn true\n}\n\n// copyLogs copies logs from the container to stdout and stderr.\nfunc (c *DockerContainer) copyLogs(ctx context.Context, stdout, stderr io.Writer, options container.LogsOptions) error {\n\trc, err := c.provider.client.ContainerLogs(ctx, c.GetContainerID(), options)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"container logs: %w\", err)\n\t}\n\tdefer rc.Close()\n\n\tif _, err = stdcopy.StdCopy(stdout, stderr, rc); err != nil {\n\t\treturn fmt.Errorf(\"stdcopy: %w\", err)\n\t}\n\n\treturn nil\n}\n\n// Deprecated: it will be removed in the next major release.\nfunc (c *DockerContainer) StopLogProducer() error {\n\treturn c.stopLogProduction()\n}\n\n// stopLogProduction will stop the concurrent process that is reading logs\n// and sending them to each added LogConsumer\nfunc (c *DockerContainer) stopLogProduction() error {\n\tif c.logProductionCancel == nil {\n\t\treturn nil\n\t}\n\n\t// Signal the log production to stop.\n\tc.logProductionCancel(errLogProductionStop)\n\n\tif err := context.Cause(c.logProductionCtx); err != nil {\n\t\tswitch {\n\t\tcase errors.Is(err, errLogProductionStop):\n\t\t\t// Log production was stopped.\n\t\t\treturn nil\n\t\tcase errors.Is(err, context.DeadlineExceeded),\n\t\t\terrors.Is(err, context.Canceled):\n\t\t\t// Parent context is done.\n\t\t\treturn nil\n\t\tdefault:\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// GetLogProductionErrorChannel exposes the only way for the consumer\n// to be able to listen to errors and react to them.\nfunc (c *DockerContainer) GetLogProductionErrorChannel() <-chan error {\n\tif c.logProductionCtx == nil {\n\t\treturn nil\n\t}\n\n\terrCh := make(chan error, 1)\n\tgo func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\terrCh <- context.Cause(ctx)\n\t\tclose(errCh)\n\t}(c.logProductionCtx)\n\n\treturn errCh\n}\n\n// connectReaper connects the reaper to the container if it is needed.\nfunc (c *DockerContainer) connectReaper(ctx context.Context) error {\n\tif c.provider.config.RyukDisabled || isReaperImage(c.Image) {\n\t\t// Reaper is disabled or we are the reaper container.\n\t\treturn nil\n\t}\n\n\treaper, err := spawner.reaper(context.WithValue(ctx, core.DockerHostContextKey, c.provider.host), core.SessionID(), c.provider)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"reaper: %w\", err)\n\t}\n\n\tif c.terminationSignal, err = reaper.Connect(); err != nil {\n\t\treturn fmt.Errorf(\"reaper connect: %w\", err)\n\t}\n\n\treturn nil\n}\n\n// cleanupTermSignal triggers the termination signal if it was created and an error occurred.\nfunc (c *DockerContainer) cleanupTermSignal(err error) {\n\tif c.terminationSignal != nil && err != nil {\n\t\tc.terminationSignal <- true\n\t}\n}\n\n// DockerNetwork represents a network started using Docker\ntype DockerNetwork struct {\n\tID                string // Network ID from Docker\n\tDriver            string\n\tName              string\n\tprovider          *DockerProvider\n\tterminationSignal chan bool\n}\n\n// Remove is used to remove the network. It is usually triggered by as defer function.\nfunc (n *DockerNetwork) Remove(ctx context.Context) error {\n\tselect {\n\t// close reaper if it was created\n\tcase n.terminationSignal <- true:\n\tdefault:\n\t}\n\n\tdefer n.provider.Close()\n\n\treturn n.provider.client.NetworkRemove(ctx, n.ID)\n}\n\nfunc (n *DockerNetwork) SetTerminationSignal(signal chan bool) {\n\tn.terminationSignal = signal\n}\n\n// DockerProvider implements the ContainerProvider interface\ntype DockerProvider struct {\n\t*DockerProviderOptions\n\tclient    client.APIClient\n\thost      string\n\thostCache string\n\tconfig    config.Config\n\tmtx       sync.Mutex\n}\n\n// Client gets the docker client used by the provider\nfunc (p *DockerProvider) Client() client.APIClient {\n\treturn p.client\n}\n\n// Close closes the docker client used by the provider\nfunc (p *DockerProvider) Close() error {\n\tif p.client == nil {\n\t\treturn nil\n\t}\n\n\treturn p.client.Close()\n}\n\n// SetClient sets the docker client to be used by the provider\nfunc (p *DockerProvider) SetClient(c client.APIClient) {\n\tp.client = c\n}\n\nvar _ ContainerProvider = (*DockerProvider)(nil)\n\n// BuildImage will build and image from context and Dockerfile, then return the tag\nfunc (p *DockerProvider) BuildImage(ctx context.Context, img ImageBuildInfo) (string, error) {\n\tvar buildOptions types.ImageBuildOptions\n\tresp, err := backoff.RetryNotifyWithData(\n\t\tfunc() (types.ImageBuildResponse, error) {\n\t\t\tvar err error\n\t\t\tbuildOptions, err = img.BuildOptions()\n\t\t\tif err != nil {\n\t\t\t\treturn types.ImageBuildResponse{}, backoff.Permanent(fmt.Errorf(\"build options: %w\", err))\n\t\t\t}\n\t\t\tdefer tryClose(buildOptions.Context) // release resources in any case\n\n\t\t\tresp, err := p.client.ImageBuild(ctx, buildOptions.Context, buildOptions)\n\t\t\tif err != nil {\n\t\t\t\tif isPermanentClientError(err) {\n\t\t\t\t\treturn types.ImageBuildResponse{}, backoff.Permanent(fmt.Errorf(\"build image: %w\", err))\n\t\t\t\t}\n\t\t\t\treturn types.ImageBuildResponse{}, err\n\t\t\t}\n\t\t\tdefer p.Close()\n\n\t\t\treturn resp, nil\n\t\t},\n\t\tbackoff.WithContext(backoff.NewExponentialBackOff(), ctx),\n\t\tfunc(err error, duration time.Duration) {\n\t\t\tp.Logger.Printf(\"Failed to build image: %s, will retry\", err)\n\t\t},\n\t)\n\tif err != nil {\n\t\treturn \"\", err // Error is already wrapped.\n\t}\n\tdefer resp.Body.Close()\n\n\toutput := img.BuildLogWriter()\n\n\t// Always process the output, even if it is not printed\n\t// to ensure that errors during the build process are\n\t// correctly handled.\n\ttermFd, isTerm := term.GetFdInfo(output)\n\tif err = jsonmessage.DisplayJSONMessagesStream(resp.Body, output, termFd, isTerm, nil); err != nil {\n\t\treturn \"\", fmt.Errorf(\"build image: %w\", err)\n\t}\n\n\t// the first tag is the one we want\n\treturn buildOptions.Tags[0], nil\n}\n\n// CreateContainer fulfils a request for a container without starting it\nfunc (p *DockerProvider) CreateContainer(ctx context.Context, req ContainerRequest) (con Container, err error) {\n\t// defer the close of the Docker client connection the soonest\n\tdefer p.Close()\n\n\tvar defaultNetwork string\n\tdefaultNetwork, err = p.ensureDefaultNetwork(ctx)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"ensure default network: %w\", err)\n\t}\n\n\t// If default network is not bridge make sure it is attached to the request\n\t// as container won't be attached to it automatically\n\t// in case of Podman the bridge network is called 'podman' as 'bridge' would conflict\n\tif defaultNetwork != p.defaultBridgeNetworkName {\n\t\tisAttached := false\n\t\tfor _, net := range req.Networks {\n\t\t\tif net == defaultNetwork {\n\t\t\t\tisAttached = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !isAttached {\n\t\t\treq.Networks = append(req.Networks, defaultNetwork)\n\t\t}\n\t}\n\n\timageName := req.Image\n\n\tenv := []string{}\n\tfor envKey, envVar := range req.Env {\n\t\tenv = append(env, envKey+\"=\"+envVar)\n\t}\n\n\tif req.Labels == nil {\n\t\treq.Labels = make(map[string]string)\n\t}\n\n\tif err = req.Validate(); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// always append the hub substitutor after the user-defined ones\n\treq.ImageSubstitutors = append(req.ImageSubstitutors, newPrependHubRegistry(p.config.HubImageNamePrefix))\n\n\tvar platform *specs.Platform\n\n\tdefaultHooks := []ContainerLifecycleHooks{\n\t\tDefaultLoggingHook(p.Logger),\n\t}\n\n\torigLifecycleHooks := req.LifecycleHooks\n\treq.LifecycleHooks = []ContainerLifecycleHooks{\n\t\tcombineContainerHooks(defaultHooks, req.LifecycleHooks),\n\t}\n\n\tif req.ShouldBuildImage() {\n\t\tif err = req.buildingHook(ctx); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\timageName, err = p.BuildImage(ctx, &req)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\treq.Image = imageName\n\t\tif err = req.builtHook(ctx); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t} else {\n\t\tfor _, is := range req.ImageSubstitutors {\n\t\t\tmodifiedTag, err := is.Substitute(imageName)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"failed to substitute image %s with %s: %w\", imageName, is.Description(), err)\n\t\t\t}\n\n\t\t\tif modifiedTag != imageName {\n\t\t\t\tp.Logger.Printf(\"✍🏼 Replacing image with %s. From: %s to %s\\n\", is.Description(), imageName, modifiedTag)\n\t\t\t\timageName = modifiedTag\n\t\t\t}\n\t\t}\n\n\t\tif req.ImagePlatform != \"\" {\n\t\t\tp, err := platforms.Parse(req.ImagePlatform)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"invalid platform %s: %w\", req.ImagePlatform, err)\n\t\t\t}\n\t\t\tplatform = &p\n\t\t}\n\n\t\tvar shouldPullImage bool\n\n\t\tif req.AlwaysPullImage {\n\t\t\tshouldPullImage = true // If requested always attempt to pull image\n\t\t} else {\n\t\t\timg, _, err := p.client.ImageInspectWithRaw(ctx, imageName)\n\t\t\tif err != nil {\n\t\t\t\tif client.IsErrNotFound(err) {\n\t\t\t\t\tshouldPullImage = true\n\t\t\t\t} else {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t}\n\t\t\tif platform != nil && (img.Architecture != platform.Architecture || img.Os != platform.OS) {\n\t\t\t\tshouldPullImage = true\n\t\t\t}\n\t\t}\n\n\t\tif shouldPullImage {\n\t\t\tpullOpt := image.PullOptions{\n\t\t\t\tPlatform: req.ImagePlatform, // may be empty\n\t\t\t}\n\t\t\tif err := p.attemptToPullImage(ctx, imageName, pullOpt); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t}\n\n\tif !isReaperImage(imageName) {\n\t\t// Add the labels that identify this as a testcontainers container and\n\t\t// allow the reaper to terminate it if requested.\n\t\tAddGenericLabels(req.Labels)\n\t}\n\n\tdockerInput := &container.Config{\n\t\tEntrypoint: req.Entrypoint,\n\t\tImage:      imageName,\n\t\tEnv:        env,\n\t\tLabels:     req.Labels,\n\t\tCmd:        req.Cmd,\n\t\tHostname:   req.Hostname,\n\t\tUser:       req.User,\n\t\tWorkingDir: req.WorkingDir,\n\t}\n\n\thostConfig := &container.HostConfig{\n\t\tPrivileged: req.Privileged,\n\t\tShmSize:    req.ShmSize,\n\t\tTmpfs:      req.Tmpfs,\n\t}\n\n\tnetworkingConfig := &network.NetworkingConfig{}\n\n\t// default hooks include logger hook and pre-create hook\n\tdefaultHooks = append(defaultHooks,\n\t\tdefaultPreCreateHook(p, dockerInput, hostConfig, networkingConfig),\n\t\tdefaultCopyFileToContainerHook(req.Files),\n\t\tdefaultLogConsumersHook(req.LogConsumerCfg),\n\t\tdefaultReadinessHook(),\n\t)\n\n\t// in the case the container needs to access a local port\n\t// we need to forward the local port to the container\n\tif len(req.HostAccessPorts) > 0 {\n\t\t// a container lifecycle hook will be added, which will expose the host ports to the container\n\t\t// using a SSHD server running in a container. The SSHD server will be started and will\n\t\t// forward the host ports to the container ports.\n\t\tsshdForwardPortsHook, err := exposeHostPorts(ctx, &req, req.HostAccessPorts...)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"expose host ports: %w\", err)\n\t\t}\n\n\t\tdefer func() {\n\t\t\tif err != nil && con == nil {\n\t\t\t\t// Container setup failed so ensure we clean up the sshd container too.\n\t\t\t\tctr := &DockerContainer{\n\t\t\t\t\tprovider:       p,\n\t\t\t\t\tlogger:         p.Logger,\n\t\t\t\t\tlifecycleHooks: []ContainerLifecycleHooks{sshdForwardPortsHook},\n\t\t\t\t}\n\t\t\t\terr = errors.Join(ctr.terminatingHook(ctx))\n\t\t\t}\n\t\t}()\n\n\t\tdefaultHooks = append(defaultHooks, sshdForwardPortsHook)\n\t}\n\n\t// Combine with the original LifecycleHooks to avoid duplicate logging hooks.\n\treq.LifecycleHooks = []ContainerLifecycleHooks{\n\t\tcombineContainerHooks(defaultHooks, origLifecycleHooks),\n\t}\n\n\terr = req.creatingHook(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tresp, err := p.client.ContainerCreate(ctx, dockerInput, hostConfig, networkingConfig, platform, req.Name)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"container create: %w\", err)\n\t}\n\n\t// #248: If there is more than one network specified in the request attach newly created container to them one by one\n\tif len(req.Networks) > 1 {\n\t\tfor _, n := range req.Networks[1:] {\n\t\t\tnw, err := p.GetNetwork(ctx, NetworkRequest{\n\t\t\t\tName: n,\n\t\t\t})\n\t\t\tif err == nil {\n\t\t\t\tendpointSetting := network.EndpointSettings{\n\t\t\t\t\tAliases: req.NetworkAliases[n],\n\t\t\t\t}\n\t\t\t\terr = p.client.NetworkConnect(ctx, nw.ID, resp.ID, &endpointSetting)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, fmt.Errorf(\"network connect: %w\", err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// This should match the fields set in ContainerFromDockerResponse.\n\tctr := &DockerContainer{\n\t\tID:             resp.ID,\n\t\tWaitingFor:     req.WaitingFor,\n\t\tImage:          imageName,\n\t\timageWasBuilt:  req.ShouldBuildImage(),\n\t\tkeepBuiltImage: req.ShouldKeepBuiltImage(),\n\t\tsessionID:      req.sessionID(),\n\t\texposedPorts:   req.ExposedPorts,\n\t\tprovider:       p,\n\t\tlogger:         p.Logger,\n\t\tlifecycleHooks: req.LifecycleHooks,\n\t}\n\n\tif err = ctr.connectReaper(ctx); err != nil {\n\t\treturn ctr, err // No wrap as it would stutter.\n\t}\n\n\t// Wrapped so the returned error is passed to the cleanup function.\n\tdefer func(ctr *DockerContainer) {\n\t\tctr.cleanupTermSignal(err)\n\t}(ctr)\n\n\tif err = ctr.createdHook(ctx); err != nil {\n\t\t// Return the container to allow caller to clean up.\n\t\treturn ctr, fmt.Errorf(\"created hook: %w\", err)\n\t}\n\n\treturn ctr, nil\n}\n\nfunc (p *DockerProvider) findContainerByName(ctx context.Context, name string) (*types.Container, error) {\n\tif name == \"\" {\n\t\treturn nil, nil\n\t}\n\n\t// Note that, 'name' filter will use regex to find the containers\n\tfilter := filters.NewArgs(filters.Arg(\"name\", fmt.Sprintf(\"^%s$\", name)))\n\tcontainers, err := p.client.ContainerList(ctx, container.ListOptions{Filters: filter})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"container list: %w\", err)\n\t}\n\tdefer p.Close()\n\n\tif len(containers) > 0 {\n\t\treturn &containers[0], nil\n\t}\n\treturn nil, nil\n}\n\nfunc (p *DockerProvider) waitContainerCreation(ctx context.Context, name string) (*types.Container, error) {\n\treturn backoff.RetryNotifyWithData(\n\t\tfunc() (*types.Container, error) {\n\t\t\tc, err := p.findContainerByName(ctx, name)\n\t\t\tif err != nil {\n\t\t\t\tif !errdefs.IsNotFound(err) && isPermanentClientError(err) {\n\t\t\t\t\treturn nil, backoff.Permanent(err)\n\t\t\t\t}\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tif c == nil {\n\t\t\t\treturn nil, errdefs.NotFound(fmt.Errorf(\"container %s not found\", name))\n\t\t\t}\n\t\t\treturn c, nil\n\t\t},\n\t\tbackoff.WithContext(backoff.NewExponentialBackOff(), ctx),\n\t\tfunc(err error, duration time.Duration) {\n\t\t\tif errdefs.IsNotFound(err) {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tp.Logger.Printf(\"Waiting for container. Got an error: %v; Retrying in %d seconds\", err, duration/time.Second)\n\t\t},\n\t)\n}\n\nfunc (p *DockerProvider) ReuseOrCreateContainer(ctx context.Context, req ContainerRequest) (con Container, err error) {\n\tc, err := p.findContainerByName(ctx, req.Name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif c == nil {\n\t\tcreatedContainer, err := p.CreateContainer(ctx, req)\n\t\tif err == nil {\n\t\t\treturn createdContainer, nil\n\t\t}\n\t\tif !createContainerFailDueToNameConflictRegex.MatchString(err.Error()) {\n\t\t\treturn nil, err\n\t\t}\n\t\tc, err = p.waitContainerCreation(ctx, req.Name)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tsessionID := req.sessionID()\n\n\tvar termSignal chan bool\n\tif !p.config.RyukDisabled {\n\t\tr, err := spawner.reaper(context.WithValue(ctx, core.DockerHostContextKey, p.host), sessionID, p)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"reaper: %w\", err)\n\t\t}\n\n\t\ttermSignal, err := r.Connect()\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"reaper connect: %w\", err)\n\t\t}\n\n\t\t// Cleanup on error.\n\t\tdefer func() {\n\t\t\tif err != nil {\n\t\t\t\ttermSignal <- true\n\t\t\t}\n\t\t}()\n\t}\n\n\t// default hooks include logger hook and pre-create hook\n\tdefaultHooks := []ContainerLifecycleHooks{\n\t\tDefaultLoggingHook(p.Logger),\n\t\tdefaultReadinessHook(),\n\t\tdefaultLogConsumersHook(req.LogConsumerCfg),\n\t}\n\n\tdc := &DockerContainer{\n\t\tID:                c.ID,\n\t\tWaitingFor:        req.WaitingFor,\n\t\tImage:             c.Image,\n\t\tsessionID:         sessionID,\n\t\texposedPorts:      req.ExposedPorts,\n\t\tprovider:          p,\n\t\tterminationSignal: termSignal,\n\t\tlogger:            p.Logger,\n\t\tlifecycleHooks:    []ContainerLifecycleHooks{combineContainerHooks(defaultHooks, req.LifecycleHooks)},\n\t}\n\n\terr = dc.startedHook(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdc.isRunning = true\n\n\terr = dc.readiedHook(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn dc, nil\n}\n\n// attemptToPullImage tries to pull the image while respecting the ctx cancellations.\n// Besides, if the image cannot be pulled due to ErrorNotFound then no need to retry but terminate immediately.\nfunc (p *DockerProvider) attemptToPullImage(ctx context.Context, tag string, pullOpt image.PullOptions) error {\n\tregistry, imageAuth, err := DockerImageAuth(ctx, tag)\n\tif err != nil {\n\t\tp.Logger.Printf(\"Failed to get image auth for %s. Setting empty credentials for the image: %s. Error is: %s\", registry, tag, err)\n\t} else {\n\t\t// see https://github.com/docker/docs/blob/e8e1204f914767128814dca0ea008644709c117f/engine/api/sdk/examples.md?plain=1#L649-L657\n\t\tencodedJSON, err := json.Marshal(imageAuth)\n\t\tif err != nil {\n\t\t\tp.Logger.Printf(\"Failed to marshal image auth. Setting empty credentials for the image: %s. Error is: %s\", tag, err)\n\t\t} else {\n\t\t\tpullOpt.RegistryAuth = base64.URLEncoding.EncodeToString(encodedJSON)\n\t\t}\n\t}\n\n\tvar pull io.ReadCloser\n\terr = backoff.RetryNotify(\n\t\tfunc() error {\n\t\t\tpull, err = p.client.ImagePull(ctx, tag, pullOpt)\n\t\t\tif err != nil {\n\t\t\t\tif isPermanentClientError(err) {\n\t\t\t\t\treturn backoff.Permanent(err)\n\t\t\t\t}\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tdefer p.Close()\n\n\t\t\treturn nil\n\t\t},\n\t\tbackoff.WithContext(backoff.NewExponentialBackOff(), ctx),\n\t\tfunc(err error, duration time.Duration) {\n\t\t\tp.Logger.Printf(\"Failed to pull image: %s, will retry\", err)\n\t\t},\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer pull.Close()\n\n\t// download of docker image finishes at EOF of the pull request\n\t_, err = io.ReadAll(pull)\n\treturn err\n}\n\n// Health measure the healthiness of the provider. Right now we leverage the\n// docker-client Info endpoint to see if the daemon is reachable.\nfunc (p *DockerProvider) Health(ctx context.Context) error {\n\t_, err := p.client.Info(ctx)\n\tdefer p.Close()\n\n\treturn err\n}\n\n// RunContainer takes a RequestContainer as input and it runs a container via the docker sdk\nfunc (p *DockerProvider) RunContainer(ctx context.Context, req ContainerRequest) (Container, error) {\n\tc, err := p.CreateContainer(ctx, req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := c.Start(ctx); err != nil {\n\t\treturn c, fmt.Errorf(\"%w: could not start container\", err)\n\t}\n\n\treturn c, nil\n}\n\n// Config provides the TestcontainersConfig read from $HOME/.testcontainers.properties or\n// the environment variables\nfunc (p *DockerProvider) Config() TestcontainersConfig {\n\treturn TestcontainersConfig{\n\t\tHost:           p.config.Host,\n\t\tTLSVerify:      p.config.TLSVerify,\n\t\tCertPath:       p.config.CertPath,\n\t\tRyukDisabled:   p.config.RyukDisabled,\n\t\tRyukPrivileged: p.config.RyukPrivileged,\n\t\tConfig:         p.config,\n\t}\n}\n\n// DaemonHost gets the host or ip of the Docker daemon where ports are exposed on\n// Warning: this is based on your Docker host setting. Will fail if using an SSH tunnel\n// You can use the \"TESTCONTAINERS_HOST_OVERRIDE\" env variable to set this yourself\nfunc (p *DockerProvider) DaemonHost(ctx context.Context) (string, error) {\n\tp.mtx.Lock()\n\tdefer p.mtx.Unlock()\n\n\treturn p.daemonHostLocked(ctx)\n}\n\nfunc (p *DockerProvider) daemonHostLocked(ctx context.Context) (string, error) {\n\tif p.hostCache != \"\" {\n\t\treturn p.hostCache, nil\n\t}\n\n\thost, exists := os.LookupEnv(\"TESTCONTAINERS_HOST_OVERRIDE\")\n\tif exists {\n\t\tp.hostCache = host\n\t\treturn p.hostCache, nil\n\t}\n\n\t// infer from Docker host\n\tdaemonURL, err := url.Parse(p.client.DaemonHost())\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tdefer p.Close()\n\n\tswitch daemonURL.Scheme {\n\tcase \"http\", \"https\", \"tcp\":\n\t\tp.hostCache = daemonURL.Hostname()\n\tcase \"unix\", \"npipe\":\n\t\tif core.InAContainer() {\n\t\t\tdefaultNetwork, err := p.ensureDefaultNetworkLocked(ctx)\n\t\t\tif err != nil {\n\t\t\t\treturn \"\", fmt.Errorf(\"ensure default network: %w\", err)\n\t\t\t}\n\t\t\tip, err := p.getGatewayIP(ctx, defaultNetwork)\n\t\t\tif err != nil {\n\t\t\t\tip, err = core.DefaultGatewayIP()\n\t\t\t\tif err != nil {\n\t\t\t\t\tip = \"localhost\"\n\t\t\t\t}\n\t\t\t}\n\t\t\tp.hostCache = ip\n\t\t} else {\n\t\t\tp.hostCache = \"localhost\"\n\t\t}\n\tdefault:\n\t\treturn \"\", errors.New(\"could not determine host through env or docker host\")\n\t}\n\n\treturn p.hostCache, nil\n}\n\n// Deprecated: use network.New instead\n// CreateNetwork returns the object representing a new network identified by its name\nfunc (p *DockerProvider) CreateNetwork(ctx context.Context, req NetworkRequest) (net Network, err error) {\n\t// defer the close of the Docker client connection the soonest\n\tdefer p.Close()\n\n\tif _, err = p.ensureDefaultNetwork(ctx); err != nil {\n\t\treturn nil, fmt.Errorf(\"ensure default network: %w\", err)\n\t}\n\n\tif req.Labels == nil {\n\t\treq.Labels = make(map[string]string)\n\t}\n\n\tnc := network.CreateOptions{\n\t\tDriver:     req.Driver,\n\t\tInternal:   req.Internal,\n\t\tEnableIPv6: req.EnableIPv6,\n\t\tAttachable: req.Attachable,\n\t\tLabels:     req.Labels,\n\t\tIPAM:       req.IPAM,\n\t}\n\n\tsessionID := req.sessionID()\n\n\tvar termSignal chan bool\n\tif !p.config.RyukDisabled {\n\t\tr, err := spawner.reaper(context.WithValue(ctx, core.DockerHostContextKey, p.host), sessionID, p)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"reaper: %w\", err)\n\t\t}\n\n\t\ttermSignal, err := r.Connect()\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"reaper connect: %w\", err)\n\t\t}\n\n\t\t// Cleanup on error.\n\t\tdefer func() {\n\t\t\tif err != nil {\n\t\t\t\ttermSignal <- true\n\t\t\t}\n\t\t}()\n\t}\n\n\t// add the labels that the reaper will use to terminate the network to the request\n\tcore.AddDefaultLabels(sessionID, req.Labels)\n\n\tresponse, err := p.client.NetworkCreate(ctx, req.Name, nc)\n\tif err != nil {\n\t\treturn &DockerNetwork{}, fmt.Errorf(\"create network: %w\", err)\n\t}\n\n\tn := &DockerNetwork{\n\t\tID:                response.ID,\n\t\tDriver:            req.Driver,\n\t\tName:              req.Name,\n\t\tterminationSignal: termSignal,\n\t\tprovider:          p,\n\t}\n\n\treturn n, nil\n}\n\n// GetNetwork returns the object representing the network identified by its name\nfunc (p *DockerProvider) GetNetwork(ctx context.Context, req NetworkRequest) (network.Inspect, error) {\n\tnetworkResource, err := p.client.NetworkInspect(ctx, req.Name, network.InspectOptions{\n\t\tVerbose: true,\n\t})\n\tif err != nil {\n\t\treturn network.Inspect{}, err\n\t}\n\n\treturn networkResource, err\n}\n\nfunc (p *DockerProvider) GetGatewayIP(ctx context.Context) (string, error) {\n\t// Use a default network as defined in the DockerProvider\n\tdefaultNetwork, err := p.ensureDefaultNetwork(ctx)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"ensure default network: %w\", err)\n\t}\n\treturn p.getGatewayIP(ctx, defaultNetwork)\n}\n\nfunc (p *DockerProvider) getGatewayIP(ctx context.Context, defaultNetwork string) (string, error) {\n\tnw, err := p.GetNetwork(ctx, NetworkRequest{Name: defaultNetwork})\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tvar ip string\n\tfor _, cfg := range nw.IPAM.Config {\n\t\tif cfg.Gateway != \"\" {\n\t\t\tip = cfg.Gateway\n\t\t\tbreak\n\t\t}\n\t}\n\tif ip == \"\" {\n\t\treturn \"\", errors.New(\"Failed to get gateway IP from network settings\")\n\t}\n\n\treturn ip, nil\n}\n\n// ensureDefaultNetwork ensures that defaultNetwork is set and creates\n// it if it does not exist, returning its value.\n// It is safe to call this method concurrently.\nfunc (p *DockerProvider) ensureDefaultNetwork(ctx context.Context) (string, error) {\n\tp.mtx.Lock()\n\tdefer p.mtx.Unlock()\n\treturn p.ensureDefaultNetworkLocked(ctx)\n}\n\nfunc (p *DockerProvider) ensureDefaultNetworkLocked(ctx context.Context) (string, error) {\n\tif p.defaultNetwork != \"\" {\n\t\t// Already set.\n\t\treturn p.defaultNetwork, nil\n\t}\n\n\tnetworkResources, err := p.client.NetworkList(ctx, network.ListOptions{})\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"network list: %w\", err)\n\t}\n\n\t// TODO: remove once we have docker context support via #2810\n\t// Prefer the default bridge network if it exists.\n\t// This makes the results stable as network list order is not guaranteed.\n\tfor _, net := range networkResources {\n\t\tswitch net.Name {\n\t\tcase p.defaultBridgeNetworkName:\n\t\t\tp.defaultNetwork = p.defaultBridgeNetworkName\n\t\t\treturn p.defaultNetwork, nil\n\t\tcase ReaperDefault:\n\t\t\tp.defaultNetwork = ReaperDefault\n\t\t}\n\t}\n\n\tif p.defaultNetwork != \"\" {\n\t\treturn p.defaultNetwork, nil\n\t}\n\n\t// Create a bridge network for the container communications.\n\t_, err = p.client.NetworkCreate(ctx, ReaperDefault, network.CreateOptions{\n\t\tDriver:     Bridge,\n\t\tAttachable: true,\n\t\tLabels:     GenericLabels(),\n\t})\n\t// If the network already exists, we can ignore the error as that can\n\t// happen if we are running multiple tests in parallel and we only\n\t// need to ensure that the network exists.\n\tif err != nil && !errdefs.IsConflict(err) {\n\t\treturn \"\", fmt.Errorf(\"network create: %w\", err)\n\t}\n\n\tp.defaultNetwork = ReaperDefault\n\n\treturn p.defaultNetwork, nil\n}\n\n// ContainerFromType builds a Docker container struct from the response of the Docker API\nfunc (p *DockerProvider) ContainerFromType(ctx context.Context, response types.Container) (ctr *DockerContainer, err error) {\n\texposedPorts := make([]string, len(response.Ports))\n\tfor i, port := range response.Ports {\n\t\texposedPorts[i] = fmt.Sprintf(\"%d/%s\", port.PublicPort, port.Type)\n\t}\n\n\t// This should match the fields set in CreateContainer.\n\tctr = &DockerContainer{\n\t\tID:            response.ID,\n\t\tImage:         response.Image,\n\t\timageWasBuilt: false,\n\t\tsessionID:     response.Labels[core.LabelSessionID],\n\t\tisRunning:     response.State == \"running\",\n\t\texposedPorts:  exposedPorts,\n\t\tprovider:      p,\n\t\tlogger:        p.Logger,\n\t\tlifecycleHooks: []ContainerLifecycleHooks{\n\t\t\tDefaultLoggingHook(p.Logger),\n\t\t},\n\t}\n\n\tif err = ctr.connectReaper(ctx); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Wrapped so the returned error is passed to the cleanup function.\n\tdefer func(ctr *DockerContainer) {\n\t\tctr.cleanupTermSignal(err)\n\t}(ctr)\n\n\t// populate the raw representation of the container\n\tjsonRaw, err := ctr.inspectRawContainer(ctx)\n\tif err != nil {\n\t\t// Return the container to allow caller to clean up.\n\t\treturn ctr, fmt.Errorf(\"inspect raw container: %w\", err)\n\t}\n\n\t// the health status of the container, if any\n\tif health := jsonRaw.State.Health; health != nil {\n\t\tctr.healthStatus = health.Status\n\t}\n\n\treturn ctr, nil\n}\n\n// ListImages list images from the provider. If an image has multiple Tags, each tag is reported\n// individually with the same ID and same labels\nfunc (p *DockerProvider) ListImages(ctx context.Context) ([]ImageInfo, error) {\n\timages := []ImageInfo{}\n\n\timageList, err := p.client.ImageList(ctx, image.ListOptions{})\n\tif err != nil {\n\t\treturn images, fmt.Errorf(\"listing images %w\", err)\n\t}\n\n\tfor _, img := range imageList {\n\t\tfor _, tag := range img.RepoTags {\n\t\t\timages = append(images, ImageInfo{ID: img.ID, Name: tag})\n\t\t}\n\t}\n\n\treturn images, nil\n}\n\n// SaveImages exports a list of images as an uncompressed tar\nfunc (p *DockerProvider) SaveImages(ctx context.Context, output string, images ...string) error {\n\toutputFile, err := os.Create(output)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"opening output file %w\", err)\n\t}\n\tdefer func() {\n\t\t_ = outputFile.Close()\n\t}()\n\n\timageReader, err := p.client.ImageSave(ctx, images)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"saving images %w\", err)\n\t}\n\tdefer func() {\n\t\t_ = imageReader.Close()\n\t}()\n\n\t// Attempt optimized readFrom, implemented in linux\n\t_, err = outputFile.ReadFrom(imageReader)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"writing images to output %w\", err)\n\t}\n\n\treturn nil\n}\n\n// PullImage pulls image from registry\nfunc (p *DockerProvider) PullImage(ctx context.Context, img string) error {\n\treturn p.attemptToPullImage(ctx, img, image.PullOptions{})\n}\n\nvar permanentClientErrors = []func(error) bool{\n\terrdefs.IsNotFound,\n\terrdefs.IsInvalidParameter,\n\terrdefs.IsUnauthorized,\n\terrdefs.IsForbidden,\n\terrdefs.IsNotImplemented,\n\terrdefs.IsSystem,\n}\n\nfunc isPermanentClientError(err error) bool {\n\tfor _, isErrFn := range permanentClientErrors {\n\t\tif isErrFn(err) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc tryClose(r io.Reader) {\n\trc, ok := r.(io.Closer)\n\tif ok {\n\t\t_ = rc.Close()\n\t}\n}\n"
        },
        {
          "name": "docker_auth.go",
          "type": "blob",
          "size": 7.4560546875,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\t\"crypto/md5\"\n\t\"encoding/base64\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"net/url\"\n\t\"os\"\n\t\"sync\"\n\n\t\"github.com/cpuguy83/dockercfg\"\n\t\"github.com/docker/docker/api/types/registry\"\n\n\t\"github.com/testcontainers/testcontainers-go/internal/core\"\n)\n\n// defaultRegistryFn is variable overwritten in tests to check for behaviour with different default values.\nvar defaultRegistryFn = defaultRegistry\n\n// getRegistryCredentials is a variable overwritten in tests to mock the dockercfg.GetRegistryCredentials function.\nvar getRegistryCredentials = dockercfg.GetRegistryCredentials\n\n// DockerImageAuth returns the auth config for the given Docker image, extracting first its Docker registry.\n// Finally, it will use the credential helpers to extract the information from the docker config file\n// for that registry, if it exists.\nfunc DockerImageAuth(ctx context.Context, image string) (string, registry.AuthConfig, error) {\n\tconfigs, err := getDockerAuthConfigs()\n\tif err != nil {\n\t\treg := core.ExtractRegistry(image, defaultRegistryFn(ctx))\n\t\treturn reg, registry.AuthConfig{}, err\n\t}\n\n\treturn dockerImageAuth(ctx, image, configs)\n}\n\n// dockerImageAuth returns the auth config for the given Docker image.\nfunc dockerImageAuth(ctx context.Context, image string, configs map[string]registry.AuthConfig) (string, registry.AuthConfig, error) {\n\tdefaultRegistry := defaultRegistryFn(ctx)\n\treg := core.ExtractRegistry(image, defaultRegistry)\n\n\tif cfg, ok := getRegistryAuth(reg, configs); ok {\n\t\treturn reg, cfg, nil\n\t}\n\n\treturn reg, registry.AuthConfig{}, dockercfg.ErrCredentialsNotFound\n}\n\nfunc getRegistryAuth(reg string, cfgs map[string]registry.AuthConfig) (registry.AuthConfig, bool) {\n\tif cfg, ok := cfgs[reg]; ok {\n\t\treturn cfg, true\n\t}\n\n\t// fallback match using authentication key host\n\tfor k, cfg := range cfgs {\n\t\tkeyURL, err := url.Parse(k)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\n\t\thost := keyURL.Host\n\t\tif keyURL.Scheme == \"\" {\n\t\t\t// url.Parse: The url may be relative (a path, without a host) [...]\n\t\t\thost = keyURL.Path\n\t\t}\n\n\t\tif host == reg {\n\t\t\treturn cfg, true\n\t\t}\n\t}\n\n\treturn registry.AuthConfig{}, false\n}\n\n// defaultRegistry returns the default registry to use when pulling images\n// It will use the docker daemon to get the default registry, returning \"https://index.docker.io/v1/\" if\n// it fails to get the information from the daemon\nfunc defaultRegistry(ctx context.Context) string {\n\tclient, err := NewDockerClientWithOpts(ctx)\n\tif err != nil {\n\t\treturn core.IndexDockerIO\n\t}\n\tdefer client.Close()\n\n\tinfo, err := client.Info(ctx)\n\tif err != nil {\n\t\treturn core.IndexDockerIO\n\t}\n\n\treturn info.IndexServerAddress\n}\n\n// authConfigResult is a result looking up auth details for key.\ntype authConfigResult struct {\n\tkey string\n\tcfg registry.AuthConfig\n\terr error\n}\n\n// credentialsCache is a cache for registry credentials.\ntype credentialsCache struct {\n\tentries map[string]credentials\n\tmtx     sync.RWMutex\n}\n\n// credentials represents the username and password for a registry.\ntype credentials struct {\n\tusername string\n\tpassword string\n}\n\nvar creds = &credentialsCache{entries: map[string]credentials{}}\n\n// AuthConfig updates the details in authConfig for the given hostname\n// as determined by the details in configKey.\nfunc (c *credentialsCache) AuthConfig(hostname, configKey string, authConfig *registry.AuthConfig) error {\n\tu, p, err := creds.get(hostname, configKey)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif u != \"\" {\n\t\tauthConfig.Username = u\n\t\tauthConfig.Password = p\n\t} else {\n\t\tauthConfig.IdentityToken = p\n\t}\n\n\treturn nil\n}\n\n// get returns the username and password for the given hostname\n// as determined by the details in configPath.\n// If the username is empty, the password is an identity token.\nfunc (c *credentialsCache) get(hostname, configKey string) (string, string, error) {\n\tkey := configKey + \":\" + hostname\n\tc.mtx.RLock()\n\tentry, ok := c.entries[key]\n\tc.mtx.RUnlock()\n\n\tif ok {\n\t\treturn entry.username, entry.password, nil\n\t}\n\n\t// No entry found, request and cache.\n\tuser, password, err := getRegistryCredentials(hostname)\n\tif err != nil {\n\t\treturn \"\", \"\", fmt.Errorf(\"getting credentials for %s: %w\", hostname, err)\n\t}\n\n\tc.mtx.Lock()\n\tc.entries[key] = credentials{username: user, password: password}\n\tc.mtx.Unlock()\n\n\treturn user, password, nil\n}\n\n// configKey returns a key to use for caching credentials based on\n// the contents of the currently active config.\nfunc configKey(cfg *dockercfg.Config) (string, error) {\n\th := md5.New()\n\tif err := json.NewEncoder(h).Encode(cfg); err != nil {\n\t\treturn \"\", fmt.Errorf(\"encode config: %w\", err)\n\t}\n\n\treturn hex.EncodeToString(h.Sum(nil)), nil\n}\n\n// getDockerAuthConfigs returns a map with the auth configs from the docker config file\n// using the registry as the key\nfunc getDockerAuthConfigs() (map[string]registry.AuthConfig, error) {\n\tcfg, err := getDockerConfig()\n\tif err != nil {\n\t\tif errors.Is(err, os.ErrNotExist) {\n\t\t\treturn map[string]registry.AuthConfig{}, nil\n\t\t}\n\n\t\treturn nil, err\n\t}\n\n\tkey, err := configKey(cfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsize := len(cfg.AuthConfigs) + len(cfg.CredentialHelpers)\n\tcfgs := make(map[string]registry.AuthConfig, size)\n\tresults := make(chan authConfigResult, size)\n\tvar wg sync.WaitGroup\n\twg.Add(size)\n\tfor k, v := range cfg.AuthConfigs {\n\t\tgo func(k string, v dockercfg.AuthConfig) {\n\t\t\tdefer wg.Done()\n\n\t\t\tac := registry.AuthConfig{\n\t\t\t\tAuth:          v.Auth,\n\t\t\t\tEmail:         v.Email,\n\t\t\t\tIdentityToken: v.IdentityToken,\n\t\t\t\tPassword:      v.Password,\n\t\t\t\tRegistryToken: v.RegistryToken,\n\t\t\t\tServerAddress: v.ServerAddress,\n\t\t\t\tUsername:      v.Username,\n\t\t\t}\n\n\t\t\tswitch {\n\t\t\tcase ac.Username == \"\" && ac.Password == \"\":\n\t\t\t\t// Look up credentials from the credential store.\n\t\t\t\tif err := creds.AuthConfig(k, key, &ac); err != nil {\n\t\t\t\t\tresults <- authConfigResult{err: err}\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\tcase ac.Auth == \"\":\n\t\t\t\t// Create auth from the username and password encoding.\n\t\t\t\tac.Auth = base64.StdEncoding.EncodeToString([]byte(ac.Username + \":\" + ac.Password))\n\t\t\t}\n\n\t\t\tresults <- authConfigResult{key: k, cfg: ac}\n\t\t}(k, v)\n\t}\n\n\t// In the case where the auth field in the .docker/conf.json is empty, and the user has\n\t// credential helpers registered the auth comes from there.\n\tfor k := range cfg.CredentialHelpers {\n\t\tgo func(k string) {\n\t\t\tdefer wg.Done()\n\n\t\t\tvar ac registry.AuthConfig\n\t\t\tif err := creds.AuthConfig(k, key, &ac); err != nil {\n\t\t\t\tresults <- authConfigResult{err: err}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tresults <- authConfigResult{key: k, cfg: ac}\n\t\t}(k)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(results)\n\t}()\n\n\tvar errs []error\n\tfor result := range results {\n\t\tif result.err != nil {\n\t\t\terrs = append(errs, result.err)\n\t\t\tcontinue\n\t\t}\n\n\t\tcfgs[result.key] = result.cfg\n\t}\n\n\tif len(errs) > 0 {\n\t\treturn nil, errors.Join(errs...)\n\t}\n\n\treturn cfgs, nil\n}\n\n// getDockerConfig returns the docker config file. It will internally check, in this particular order:\n// 1. the DOCKER_AUTH_CONFIG environment variable, unmarshalling it into a dockercfg.Config\n// 2. the DOCKER_CONFIG environment variable, as the path to the config file\n// 3. else it will load the default config file, which is ~/.docker/config.json\nfunc getDockerConfig() (*dockercfg.Config, error) {\n\tif env := os.Getenv(\"DOCKER_AUTH_CONFIG\"); env != \"\" {\n\t\tvar cfg dockercfg.Config\n\t\tif err := json.Unmarshal([]byte(env), &cfg); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"unmarshal DOCKER_AUTH_CONFIG: %w\", err)\n\t\t}\n\n\t\treturn &cfg, nil\n\t}\n\n\tcfg, err := dockercfg.LoadDefaultConfig()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"load default config: %w\", err)\n\t}\n\n\treturn &cfg, nil\n}\n"
        },
        {
          "name": "docker_auth_test.go",
          "type": "blob",
          "size": 14.263671875,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\t_ \"embed\"\n\t\"encoding/base64\"\n\t\"fmt\"\n\t\"net\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"testing\"\n\n\t\"github.com/cpuguy83/dockercfg\"\n\t\"github.com/docker/docker/api/types/image\"\n\t\"github.com/docker/docker/api/types/registry\"\n\t\"github.com/docker/docker/client\"\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/testcontainers/testcontainers-go/internal/core\"\n\t\"github.com/testcontainers/testcontainers-go/wait\"\n)\n\nconst (\n\texampleAuth     = \"https://example-auth.com\"\n\tprivateRegistry = \"https://my.private.registry\"\n\texampleRegistry = \"https://example.com\"\n)\n\nfunc Test_getDockerConfig(t *testing.T) {\n\texpectedConfig := &dockercfg.Config{\n\t\tAuthConfigs: map[string]dockercfg.AuthConfig{\n\t\t\tcore.IndexDockerIO: {},\n\t\t\texampleRegistry:    {},\n\t\t\tprivateRegistry:    {},\n\t\t},\n\t\tCredentialsStore: \"desktop\",\n\t}\n\tt.Run(\"HOME/valid\", func(t *testing.T) {\n\t\ttestDockerConfigHome(t, \"testdata\")\n\n\t\tcfg, err := getDockerConfig()\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, expectedConfig, cfg)\n\t})\n\n\tt.Run(\"HOME/not-found\", func(t *testing.T) {\n\t\ttestDockerConfigHome(t, \"testdata\", \"not-found\")\n\n\t\tcfg, err := getDockerConfig()\n\t\trequire.ErrorIs(t, err, os.ErrNotExist)\n\t\trequire.Nil(t, cfg)\n\t})\n\n\tt.Run(\"HOME/invalid-config\", func(t *testing.T) {\n\t\ttestDockerConfigHome(t, \"testdata\", \"invalid-config\")\n\n\t\tcfg, err := getDockerConfig()\n\t\trequire.ErrorContains(t, err, \"json: cannot unmarshal array\")\n\t\trequire.Nil(t, cfg)\n\t})\n\n\tt.Run(\"DOCKER_AUTH_CONFIG/valid\", func(t *testing.T) {\n\t\ttestDockerConfigHome(t, \"testdata\", \"not-found\")\n\t\tt.Setenv(\"DOCKER_AUTH_CONFIG\", dockerConfig)\n\n\t\tcfg, err := getDockerConfig()\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, expectedConfig, cfg)\n\t})\n\n\tt.Run(\"DOCKER_AUTH_CONFIG/invalid-config\", func(t *testing.T) {\n\t\ttestDockerConfigHome(t, \"testdata\", \"not-found\")\n\t\tt.Setenv(\"DOCKER_AUTH_CONFIG\", `{\"auths\": []}`)\n\n\t\tcfg, err := getDockerConfig()\n\t\trequire.ErrorContains(t, err, \"json: cannot unmarshal array\")\n\t\trequire.Nil(t, cfg)\n\t})\n\n\tt.Run(\"DOCKER_CONFIG/valid\", func(t *testing.T) {\n\t\ttestDockerConfigHome(t, \"testdata\", \"not-found\")\n\t\tt.Setenv(\"DOCKER_CONFIG\", filepath.Join(\"testdata\", \".docker\"))\n\n\t\tcfg, err := getDockerConfig()\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, expectedConfig, cfg)\n\t})\n\n\tt.Run(\"DOCKER_CONFIG/invalid-config\", func(t *testing.T) {\n\t\ttestDockerConfigHome(t, \"testdata\", \"not-found\")\n\t\tt.Setenv(\"DOCKER_CONFIG\", filepath.Join(\"testdata\", \"invalid-config\", \".docker\"))\n\n\t\tcfg, err := getDockerConfig()\n\t\trequire.ErrorContains(t, err, \"json: cannot unmarshal array\")\n\t\trequire.Nil(t, cfg)\n\t})\n}\n\nfunc TestDockerImageAuth(t *testing.T) {\n\tt.Run(\"retrieve auth with DOCKER_AUTH_CONFIG env var\", func(t *testing.T) {\n\t\tusername, password := \"gopher\", \"secret\"\n\t\tcreds := setAuthConfig(t, exampleAuth, username, password)\n\n\t\tregistry, cfg, err := DockerImageAuth(context.Background(), exampleAuth+\"/my/image:latest\")\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, exampleAuth, registry)\n\t\trequire.Equal(t, username, cfg.Username)\n\t\trequire.Equal(t, password, cfg.Password)\n\t\trequire.Equal(t, creds, cfg.Auth)\n\t})\n\n\tt.Run(\"match registry authentication by host\", func(t *testing.T) {\n\t\timageReg := \"example-auth.com\"\n\t\timagePath := \"/my/image:latest\"\n\t\tbase64 := setAuthConfig(t, exampleAuth, \"gopher\", \"secret\")\n\n\t\tregistry, cfg, err := DockerImageAuth(context.Background(), imageReg+imagePath)\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, imageReg, registry)\n\t\trequire.Equal(t, \"gopher\", cfg.Username)\n\t\trequire.Equal(t, \"secret\", cfg.Password)\n\t\trequire.Equal(t, base64, cfg.Auth)\n\t})\n\n\tt.Run(\"fail to match registry authentication due to invalid host\", func(t *testing.T) {\n\t\timageReg := \"example-auth.com\"\n\t\timagePath := \"/my/image:latest\"\n\t\tinvalidRegistryURL := \"://invalid-host\"\n\n\t\tsetAuthConfig(t, invalidRegistryURL, \"gopher\", \"secret\")\n\n\t\tregistry, cfg, err := DockerImageAuth(context.Background(), imageReg+imagePath)\n\t\trequire.ErrorIs(t, err, dockercfg.ErrCredentialsNotFound)\n\t\trequire.Empty(t, cfg)\n\t\trequire.Equal(t, imageReg, registry)\n\t})\n\n\tt.Run(\"fail to match registry authentication by host with empty URL scheme creds and missing default\", func(t *testing.T) {\n\t\torigDefaultRegistryFn := defaultRegistryFn\n\t\tt.Cleanup(func() {\n\t\t\tdefaultRegistryFn = origDefaultRegistryFn\n\t\t})\n\t\tdefaultRegistryFn = func(ctx context.Context) string {\n\t\t\treturn \"\"\n\t\t}\n\n\t\timageReg := \"\"\n\t\timagePath := \"image:latest\"\n\n\t\tsetAuthConfig(t, \"example-auth.com\", \"gopher\", \"secret\")\n\n\t\tregistry, cfg, err := DockerImageAuth(context.Background(), imageReg+imagePath)\n\t\trequire.ErrorIs(t, err, dockercfg.ErrCredentialsNotFound)\n\t\trequire.Empty(t, cfg)\n\t\trequire.Equal(t, imageReg, registry)\n\t})\n}\n\nfunc TestBuildContainerFromDockerfile(t *testing.T) {\n\tctx := context.Background()\n\treq := ContainerRequest{\n\t\tFromDockerfile: FromDockerfile{\n\t\t\tContext: \"./testdata\",\n\t\t},\n\t\tAlwaysPullImage: true, // make sure the authentication takes place\n\t\tExposedPorts:    []string{\"6379/tcp\"},\n\t\tWaitingFor:      wait.ForLog(\"Ready to accept connections\"),\n\t}\n\n\tredisC, err := prepareRedisImage(ctx, req)\n\tCleanupContainer(t, redisC)\n\trequire.NoError(t, err)\n}\n\n// removeImageFromLocalCache removes the image from the local cache\nfunc removeImageFromLocalCache(t *testing.T, img string) {\n\tt.Helper()\n\tctx := context.Background()\n\n\ttestcontainersClient, err := NewDockerClientWithOpts(ctx, client.WithVersion(daemonMaxVersion))\n\tif err != nil {\n\t\tt.Log(\"could not create client to cleanup registry: \", err)\n\t}\n\tdefer testcontainersClient.Close()\n\n\t_, err = testcontainersClient.ImageRemove(ctx, img, image.RemoveOptions{\n\t\tForce:         true,\n\t\tPruneChildren: true,\n\t})\n\tif err != nil && !client.IsErrNotFound(err) {\n\t\tt.Logf(\"could not remove image %s: %v\\n\", img, err)\n\t}\n}\n\nfunc TestBuildContainerFromDockerfileWithDockerAuthConfig(t *testing.T) {\n\tregistryHost := prepareLocalRegistryWithAuth(t)\n\n\t// using the same credentials as in the Docker Registry\n\tsetAuthConfig(t, registryHost, \"testuser\", \"testpassword\")\n\n\tctx := context.Background()\n\n\treq := ContainerRequest{\n\t\tFromDockerfile: FromDockerfile{\n\t\t\tContext:    \"./testdata\",\n\t\t\tDockerfile: \"auth.Dockerfile\",\n\t\t\tBuildArgs: map[string]*string{\n\t\t\t\t\"REGISTRY_HOST\": &registryHost,\n\t\t\t},\n\t\t\tRepo: \"localhost\",\n\t\t},\n\t\tAlwaysPullImage: true, // make sure the authentication takes place\n\t\tExposedPorts:    []string{\"6379/tcp\"},\n\t\tWaitingFor:      wait.ForLog(\"Ready to accept connections\"),\n\t}\n\n\tredisC, err := prepareRedisImage(ctx, req)\n\tCleanupContainer(t, redisC)\n\trequire.NoError(t, err)\n}\n\nfunc TestBuildContainerFromDockerfileShouldFailWithWrongDockerAuthConfig(t *testing.T) {\n\tregistryHost := prepareLocalRegistryWithAuth(t)\n\n\t// using different credentials than in the Docker Registry\n\tsetAuthConfig(t, registryHost, \"foo\", \"bar\")\n\n\tctx := context.Background()\n\n\treq := ContainerRequest{\n\t\tFromDockerfile: FromDockerfile{\n\t\t\tContext:    \"./testdata\",\n\t\t\tDockerfile: \"auth.Dockerfile\",\n\t\t\tBuildArgs: map[string]*string{\n\t\t\t\t\"REGISTRY_HOST\": &registryHost,\n\t\t\t},\n\t\t},\n\t\tAlwaysPullImage: true, // make sure the authentication takes place\n\t\tExposedPorts:    []string{\"6379/tcp\"},\n\t\tWaitingFor:      wait.ForLog(\"Ready to accept connections\"),\n\t}\n\n\tredisC, err := prepareRedisImage(ctx, req)\n\tCleanupContainer(t, redisC)\n\trequire.Error(t, err)\n}\n\nfunc TestCreateContainerFromPrivateRegistry(t *testing.T) {\n\tregistryHost := prepareLocalRegistryWithAuth(t)\n\n\t// using the same credentials as in the Docker Registry\n\tsetAuthConfig(t, registryHost, \"testuser\", \"testpassword\")\n\n\tctx := context.Background()\n\treq := ContainerRequest{\n\t\tImage:           registryHost + \"/redis:5.0-alpine\",\n\t\tAlwaysPullImage: true, // make sure the authentication takes place\n\t\tExposedPorts:    []string{\"6379/tcp\"},\n\t\tWaitingFor:      wait.ForLog(\"Ready to accept connections\"),\n\t}\n\n\tredisContainer, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, redisContainer)\n\trequire.NoError(t, err)\n}\n\nfunc prepareLocalRegistryWithAuth(t *testing.T) string {\n\tt.Helper()\n\tctx := context.Background()\n\twd, err := os.Getwd()\n\trequire.NoError(t, err)\n\t// copyDirectoryToContainer {\n\treq := ContainerRequest{\n\t\tImage:        \"registry:2\",\n\t\tExposedPorts: []string{\"5000/tcp\"},\n\t\tEnv: map[string]string{\n\t\t\t\"REGISTRY_AUTH\":                             \"htpasswd\",\n\t\t\t\"REGISTRY_AUTH_HTPASSWD_REALM\":              \"Registry\",\n\t\t\t\"REGISTRY_AUTH_HTPASSWD_PATH\":               \"/auth/htpasswd\",\n\t\t\t\"REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY\": \"/data\",\n\t\t},\n\t\tFiles: []ContainerFile{\n\t\t\t{\n\t\t\t\tHostFilePath:      wd + \"/testdata/auth\",\n\t\t\t\tContainerFilePath: \"/auth\",\n\t\t\t},\n\t\t\t{\n\t\t\t\tHostFilePath:      wd + \"/testdata/data\",\n\t\t\t\tContainerFilePath: \"/data\",\n\t\t\t},\n\t\t},\n\t\tWaitingFor: wait.ForHTTP(\"/\").WithPort(\"5000/tcp\"),\n\t}\n\t// }\n\n\tgenContainerReq := GenericContainerRequest{\n\t\tProviderType:     providerType,\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t}\n\n\tregistryC, err := GenericContainer(ctx, genContainerReq)\n\tCleanupContainer(t, registryC)\n\trequire.NoError(t, err)\n\n\tmappedPort, err := registryC.MappedPort(ctx, \"5000/tcp\")\n\trequire.NoError(t, err)\n\n\tip := localAddress(t)\n\tmp := mappedPort.Port()\n\taddr := ip + \":\" + mp\n\n\tt.Cleanup(func() {\n\t\tremoveImageFromLocalCache(t, addr+\"/redis:5.0-alpine\")\n\t})\n\n\treturn addr\n}\n\nfunc prepareRedisImage(ctx context.Context, req ContainerRequest) (Container, error) {\n\tgenContainerReq := GenericContainerRequest{\n\t\tProviderType:     providerType,\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t}\n\n\treturn GenericContainer(ctx, genContainerReq)\n}\n\n// setAuthConfig sets the DOCKER_AUTH_CONFIG environment variable with\n// authentication for with the given host, username and password.\n// It returns the base64 encoded credentials.\nfunc setAuthConfig(t *testing.T, host, username, password string) string {\n\tt.Helper()\n\n\tvar creds string\n\tif username != \"\" || password != \"\" {\n\t\tcreds = base64.StdEncoding.EncodeToString([]byte(username + \":\" + password))\n\t}\n\n\tauth := fmt.Sprintf(`{\n\t\"auths\": {\n\t\t%q: {\n\t\t\t\"username\": %q,\n\t\t\t\"password\": %q,\n\t\t\t\"auth\": %q\n\t\t}\n\t},\n\t\"credsStore\": \"desktop\"\n}`,\n\t\thost,\n\t\tusername,\n\t\tpassword,\n\t\tcreds,\n\t)\n\tt.Setenv(\"DOCKER_AUTH_CONFIG\", auth)\n\n\treturn creds\n}\n\n// localAddress returns the local address of the machine\n// which can be used to connect to the local registry.\n// This avoids the issues with localhost on WSL.\nfunc localAddress(t *testing.T) string {\n\tt.Helper()\n\tif os.Getenv(\"WSL_DISTRO_NAME\") == \"\" {\n\t\treturn \"localhost\"\n\t}\n\n\tconn, err := net.Dial(\"udp\", \"golang.org:80\")\n\trequire.NoError(t, err)\n\tdefer conn.Close()\n\n\tlocalAddr := conn.LocalAddr().(*net.UDPAddr)\n\n\treturn localAddr.IP.String()\n}\n\n//go:embed testdata/.docker/config.json\nvar dockerConfig string\n\n// reset resets the credentials cache.\nfunc (c *credentialsCache) reset() {\n\tc.mtx.Lock()\n\tdefer c.mtx.Unlock()\n\tc.entries = make(map[string]credentials)\n}\n\nfunc Test_getDockerAuthConfigs(t *testing.T) {\n\tt.Run(\"HOME/valid\", func(t *testing.T) {\n\t\ttestDockerConfigHome(t, \"testdata\")\n\n\t\trequireValidAuthConfig(t)\n\t})\n\n\tt.Run(\"HOME/not-found\", func(t *testing.T) {\n\t\ttestDockerConfigHome(t, \"testdata\", \"not-exist\")\n\n\t\tauthConfigs, err := getDockerAuthConfigs()\n\t\trequire.NoError(t, err)\n\t\trequire.NotNil(t, authConfigs)\n\t\trequire.Empty(t, authConfigs)\n\t})\n\n\tt.Run(\"HOME/invalid-config\", func(t *testing.T) {\n\t\ttestDockerConfigHome(t, \"testdata\", \"invalid-config\")\n\n\t\tauthConfigs, err := getDockerAuthConfigs()\n\t\trequire.ErrorContains(t, err, \"json: cannot unmarshal array\")\n\t\trequire.Nil(t, authConfigs)\n\t})\n\n\tt.Run(\"DOCKER_AUTH_CONFIG/valid\", func(t *testing.T) {\n\t\ttestDockerConfigHome(t, \"testdata\", \"not-exist\")\n\t\tt.Setenv(\"DOCKER_AUTH_CONFIG\", dockerConfig)\n\n\t\trequireValidAuthConfig(t)\n\t})\n\n\tt.Run(\"DOCKER_AUTH_CONFIG/invalid-config\", func(t *testing.T) {\n\t\ttestDockerConfigHome(t, \"testdata\", \"not-exist\")\n\t\tt.Setenv(\"DOCKER_AUTH_CONFIG\", `{\"auths\": []}`)\n\n\t\tauthConfigs, err := getDockerAuthConfigs()\n\t\trequire.ErrorContains(t, err, \"json: cannot unmarshal array\")\n\t\trequire.Nil(t, authConfigs)\n\t})\n\n\tt.Run(\"DOCKER_AUTH_CONFIG/identity-token\", func(t *testing.T) {\n\t\ttestDockerConfigHome(t, \"testdata\", \"not-exist\")\n\n\t\t// Reset the credentials cache to ensure our mocked method is called.\n\t\tcreds.reset()\n\n\t\t// Mock getRegistryCredentials to return identity-token for index.docker.io.\n\t\told := getRegistryCredentials\n\t\tt.Cleanup(func() {\n\t\t\tgetRegistryCredentials = old\n\t\t\tcreds.reset() // Ensure our mocked results aren't cached.\n\t\t})\n\t\tgetRegistryCredentials = func(hostname string) (string, string, error) {\n\t\t\tswitch hostname {\n\t\t\tcase core.IndexDockerIO:\n\t\t\t\treturn \"\", \"identity-token\", nil\n\t\t\tdefault:\n\t\t\t\treturn \"username\", \"password\", nil\n\t\t\t}\n\t\t}\n\t\tt.Setenv(\"DOCKER_AUTH_CONFIG\", dockerConfig)\n\n\t\tauthConfigs, err := getDockerAuthConfigs()\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, map[string]registry.AuthConfig{\n\t\t\tcore.IndexDockerIO: {\n\t\t\t\tIdentityToken: \"identity-token\",\n\t\t\t},\n\t\t\tprivateRegistry: {\n\t\t\t\tUsername: \"username\",\n\t\t\t\tPassword: \"password\",\n\t\t\t},\n\t\t\texampleRegistry: {\n\t\t\t\tUsername: \"username\",\n\t\t\t\tPassword: \"password\",\n\t\t\t},\n\t\t}, authConfigs)\n\t})\n\n\tt.Run(\"DOCKER_CONFIG/valid\", func(t *testing.T) {\n\t\ttestDockerConfigHome(t, \"testdata\", \"not-found\")\n\t\tt.Setenv(\"DOCKER_CONFIG\", filepath.Join(\"testdata\", \".docker\"))\n\n\t\trequireValidAuthConfig(t)\n\t})\n\n\tt.Run(\"DOCKER_CONFIG/invalid-config\", func(t *testing.T) {\n\t\ttestDockerConfigHome(t, \"testdata\", \"not-found\")\n\t\tt.Setenv(\"DOCKER_CONFIG\", filepath.Join(\"testdata\", \"invalid-config\", \".docker\"))\n\n\t\tcfg, err := getDockerConfig()\n\t\trequire.ErrorContains(t, err, \"json: cannot unmarshal array\")\n\t\trequire.Nil(t, cfg)\n\t})\n}\n\n// requireValidAuthConfig checks that the given authConfigs map contains the expected keys.\nfunc requireValidAuthConfig(t *testing.T) {\n\tt.Helper()\n\n\tauthConfigs, err := getDockerAuthConfigs()\n\trequire.NoError(t, err)\n\n\t// We can only check the keys as the values are not deterministic as they depend\n\t// on users environment.\n\texpected := map[string]registry.AuthConfig{\n\t\tcore.IndexDockerIO: {},\n\t\texampleRegistry:    {},\n\t\tprivateRegistry:    {},\n\t}\n\tfor k := range authConfigs {\n\t\tauthConfigs[k] = registry.AuthConfig{}\n\t}\n\trequire.Equal(t, expected, authConfigs)\n}\n\n// testDockerConfigHome sets the user's home directory to the given path\n// and unsets the DOCKER_CONFIG and DOCKER_AUTH_CONFIG environment variables.\nfunc testDockerConfigHome(t *testing.T, dirs ...string) {\n\tt.Helper()\n\n\tdir := filepath.Join(dirs...)\n\tt.Setenv(\"DOCKER_AUTH_CONFIG\", \"\")\n\tt.Setenv(\"DOCKER_CONFIG\", \"\")\n\tt.Setenv(\"HOME\", dir)\n\tt.Setenv(\"USERPROFILE\", dir) // Windows\n}\n"
        },
        {
          "name": "docker_client.go",
          "type": "blob",
          "size": 3.7998046875,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"sync\"\n\n\t\"github.com/docker/docker/api/types\"\n\t\"github.com/docker/docker/api/types/events\"\n\t\"github.com/docker/docker/api/types/registry\"\n\t\"github.com/docker/docker/api/types/system\"\n\t\"github.com/docker/docker/client\"\n\n\t\"github.com/testcontainers/testcontainers-go/internal\"\n\t\"github.com/testcontainers/testcontainers-go/internal/core\"\n)\n\n// DockerClient is a wrapper around the docker client that is used by testcontainers-go.\n// It implements the SystemAPIClient interface in order to cache the docker info and reuse it.\ntype DockerClient struct {\n\t*client.Client // client is embedded into our own client\n}\n\nvar (\n\t// dockerInfo stores the docker info to be reused in the Info method\n\tdockerInfo     system.Info\n\tdockerInfoSet  bool\n\tdockerInfoLock sync.Mutex\n)\n\n// implements SystemAPIClient interface\nvar _ client.SystemAPIClient = &DockerClient{}\n\n// Events returns a channel to listen to events that happen to the docker daemon.\nfunc (c *DockerClient) Events(ctx context.Context, options events.ListOptions) (<-chan events.Message, <-chan error) {\n\treturn c.Client.Events(ctx, options)\n}\n\n// Info returns information about the docker server. The result of Info is cached\n// and reused every time Info is called.\n// It will also print out the docker server info, and the resolved Docker paths, to the default logger.\nfunc (c *DockerClient) Info(ctx context.Context) (system.Info, error) {\n\tdockerInfoLock.Lock()\n\tdefer dockerInfoLock.Unlock()\n\tif dockerInfoSet {\n\t\treturn dockerInfo, nil\n\t}\n\n\tinfo, err := c.Client.Info(ctx)\n\tif err != nil {\n\t\treturn info, fmt.Errorf(\"failed to retrieve docker info: %w\", err)\n\t}\n\tdockerInfo = info\n\tdockerInfoSet = true\n\n\tinfoMessage := `%v - Connected to docker: \n  Server Version: %v\n  API Version: %v\n  Operating System: %v\n  Total Memory: %v MB%s\n  Testcontainers for Go Version: v%s\n  Resolved Docker Host: %s\n  Resolved Docker Socket Path: %s\n  Test SessionID: %s\n  Test ProcessID: %s\n`\n\tinfoLabels := \"\"\n\tif len(dockerInfo.Labels) > 0 {\n\t\tinfoLabels = `\n  Labels:`\n\t\tfor _, lb := range dockerInfo.Labels {\n\t\t\tinfoLabels += \"\\n    \" + lb\n\t\t}\n\t}\n\n\tLogger.Printf(infoMessage, packagePath,\n\t\tdockerInfo.ServerVersion,\n\t\tc.Client.ClientVersion(),\n\t\tdockerInfo.OperatingSystem, dockerInfo.MemTotal/1024/1024,\n\t\tinfoLabels,\n\t\tinternal.Version,\n\t\tcore.MustExtractDockerHost(ctx),\n\t\tcore.MustExtractDockerSocket(ctx),\n\t\tcore.SessionID(),\n\t\tcore.ProcessID(),\n\t)\n\n\treturn dockerInfo, nil\n}\n\n// RegistryLogin logs into a Docker registry.\nfunc (c *DockerClient) RegistryLogin(ctx context.Context, auth registry.AuthConfig) (registry.AuthenticateOKBody, error) {\n\treturn c.Client.RegistryLogin(ctx, auth)\n}\n\n// DiskUsage returns the disk usage of all images.\nfunc (c *DockerClient) DiskUsage(ctx context.Context, options types.DiskUsageOptions) (types.DiskUsage, error) {\n\treturn c.Client.DiskUsage(ctx, options)\n}\n\n// Ping pings the docker server.\nfunc (c *DockerClient) Ping(ctx context.Context) (types.Ping, error) {\n\treturn c.Client.Ping(ctx)\n}\n\n// Deprecated: Use NewDockerClientWithOpts instead.\nfunc NewDockerClient() (*client.Client, error) {\n\tcli, err := NewDockerClientWithOpts(context.Background())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn cli.Client, nil\n}\n\nfunc NewDockerClientWithOpts(ctx context.Context, opt ...client.Opt) (*DockerClient, error) {\n\tdockerClient, err := core.NewClient(ctx, opt...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\ttcClient := DockerClient{\n\t\tClient: dockerClient,\n\t}\n\n\tif _, err = tcClient.Info(ctx); err != nil {\n\t\t// Fallback to environment, including the original options\n\t\tif len(opt) == 0 {\n\t\t\topt = []client.Opt{client.FromEnv, client.WithAPIVersionNegotiation()}\n\t\t}\n\n\t\tdockerClient, err := client.NewClientWithOpts(opt...)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\ttcClient.Client = dockerClient\n\t}\n\tdefer tcClient.Close()\n\n\treturn &tcClient, nil\n}\n"
        },
        {
          "name": "docker_client_test.go",
          "type": "blob",
          "size": 0.7314453125,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc TestGetDockerInfo(t *testing.T) {\n\tt.Run(\"works\", func(t *testing.T) {\n\t\tctx := context.Background()\n\t\tc, err := NewDockerClientWithOpts(ctx)\n\t\trequire.NoError(t, err)\n\n\t\tinfo, err := c.Info(ctx)\n\t\trequire.NoError(t, err)\n\t\trequire.NotNil(t, info)\n\t})\n\n\tt.Run(\"is goroutine safe\", func(t *testing.T) {\n\t\tctx := context.Background()\n\t\tc, err := NewDockerClientWithOpts(ctx)\n\t\trequire.NoError(t, err)\n\n\t\tcount := 1024\n\t\twg := sync.WaitGroup{}\n\t\twg.Add(count)\n\n\t\tfor i := 0; i < count; i++ {\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tinfo, err := c.Info(ctx)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.NotNil(t, info)\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t})\n}\n"
        },
        {
          "name": "docker_exec_test.go",
          "type": "blob",
          "size": 3.0107421875,
          "content": "package testcontainers\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"io\"\n\t\"testing\"\n\n\t\"github.com/docker/docker/pkg/stdcopy\"\n\t\"github.com/stretchr/testify/require\"\n\n\ttcexec \"github.com/testcontainers/testcontainers-go/exec\"\n)\n\nfunc TestExecWithOptions(t *testing.T) {\n\ttests := []struct {\n\t\tname string\n\t\tcmds []string\n\t\topts []tcexec.ProcessOption\n\t\twant string\n\t}{\n\t\t{\n\t\t\tname: \"with user\",\n\t\t\tcmds: []string{\"whoami\"},\n\t\t\topts: []tcexec.ProcessOption{\n\t\t\t\ttcexec.WithUser(\"nginx\"),\n\t\t\t},\n\t\t\twant: \"nginx\\n\",\n\t\t},\n\t\t{\n\t\t\tname: \"with working dir\",\n\t\t\tcmds: []string{\"pwd\"},\n\t\t\topts: []tcexec.ProcessOption{\n\t\t\t\ttcexec.WithWorkingDir(\"/var/log/nginx\"),\n\t\t\t},\n\t\t\twant: \"/var/log/nginx\\n\",\n\t\t},\n\t\t{\n\t\t\tname: \"with env\",\n\t\t\tcmds: []string{\"env\"},\n\t\t\topts: []tcexec.ProcessOption{\n\t\t\t\ttcexec.WithEnv([]string{\"TEST_ENV=test\"}),\n\t\t\t},\n\t\t\twant: \"TEST_ENV=test\\n\",\n\t\t},\n\t}\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tctx := context.Background()\n\t\t\treq := ContainerRequest{\n\t\t\t\tImage: nginxAlpineImage,\n\t\t\t}\n\n\t\t\tctr, err := GenericContainer(ctx, GenericContainerRequest{\n\t\t\t\tContainerRequest: req,\n\t\t\t\tStarted:          true,\n\t\t\t})\n\t\t\tCleanupContainer(t, ctr)\n\t\t\trequire.NoError(t, err)\n\n\t\t\t// always append the multiplexed option for having the output\n\t\t\t// in a readable format\n\t\t\ttt.opts = append(tt.opts, tcexec.Multiplexed())\n\n\t\t\tcode, reader, err := ctr.Exec(ctx, tt.cmds, tt.opts...)\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.Zero(t, code)\n\t\t\trequire.NotNil(t, reader)\n\n\t\t\tb, err := io.ReadAll(reader)\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.NotNil(t, b)\n\n\t\t\tstr := string(b)\n\t\t\trequire.Contains(t, str, tt.want)\n\t\t})\n\t}\n}\n\nfunc TestExecWithMultiplexedResponse(t *testing.T) {\n\tctx := context.Background()\n\treq := ContainerRequest{\n\t\tImage: nginxAlpineImage,\n\t}\n\n\tctr, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, ctr)\n\trequire.NoError(t, err)\n\n\tcode, reader, err := ctr.Exec(ctx, []string{\"sh\", \"-c\", \"echo stdout; echo stderr >&2\"}, tcexec.Multiplexed())\n\trequire.NoError(t, err)\n\trequire.Zero(t, code)\n\trequire.NotNil(t, reader)\n\n\tb, err := io.ReadAll(reader)\n\trequire.NoError(t, err)\n\trequire.NotNil(t, b)\n\n\tstr := string(b)\n\trequire.Contains(t, str, \"stdout\")\n\trequire.Contains(t, str, \"stderr\")\n}\n\nfunc TestExecWithNonMultiplexedResponse(t *testing.T) {\n\tctx := context.Background()\n\treq := ContainerRequest{\n\t\tImage: nginxAlpineImage,\n\t}\n\n\tctr, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, ctr)\n\trequire.NoError(t, err)\n\n\tcode, reader, err := ctr.Exec(ctx, []string{\"sh\", \"-c\", \"echo stdout; echo stderr >&2\"})\n\trequire.NoError(t, err)\n\trequire.Zero(t, code)\n\trequire.NotNil(t, reader)\n\n\tvar stdout bytes.Buffer\n\tvar stderr bytes.Buffer\n\n\twritten, err := stdcopy.StdCopy(&stdout, &stderr, reader)\n\trequire.NoError(t, err)\n\trequire.NotZero(t, written)\n\trequire.NotNil(t, stdout)\n\trequire.NotNil(t, stderr)\n\n\trequire.Equal(t, \"stdout\\n\", stdout.String())\n\trequire.Equal(t, \"stderr\\n\", stderr.String())\n}\n"
        },
        {
          "name": "docker_files_test.go",
          "type": "blob",
          "size": 5.7763671875,
          "content": "package testcontainers_test\n\nimport (\n\t\"context\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/testcontainers/testcontainers-go\"\n\t\"github.com/testcontainers/testcontainers-go/wait\"\n)\n\nconst testBashImage string = \"bash:5.2.26\"\n\nfunc TestCopyFileToContainer(t *testing.T) {\n\tctx, cnl := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer cnl()\n\n\t// copyFileOnCreate {\n\tabsPath, err := filepath.Abs(filepath.Join(\".\", \"testdata\", \"hello.sh\"))\n\trequire.NoError(t, err)\n\n\tr, err := os.Open(absPath)\n\trequire.NoError(t, err)\n\n\tctr, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{\n\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\tImage: testBashImage,\n\t\t\tFiles: []testcontainers.ContainerFile{\n\t\t\t\t{\n\t\t\t\t\tReader:            r,\n\t\t\t\t\tHostFilePath:      absPath, // will be discarded internally\n\t\t\t\t\tContainerFilePath: \"/hello.sh\",\n\t\t\t\t\tFileMode:          0o700,\n\t\t\t\t},\n\t\t\t},\n\t\t\tCmd:        []string{\"bash\", \"/hello.sh\"},\n\t\t\tWaitingFor: wait.ForLog(\"done\"),\n\t\t},\n\t\tStarted: true,\n\t})\n\t// }\n\ttestcontainers.CleanupContainer(t, ctr)\n\trequire.NoError(t, err)\n}\n\nfunc TestCopyFileToRunningContainer(t *testing.T) {\n\tctx, cnl := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer cnl()\n\n\t// Not using the assertations here to avoid leaking the library into the example\n\t// copyFileAfterCreate {\n\twaitForPath, err := filepath.Abs(filepath.Join(\".\", \"testdata\", \"waitForHello.sh\"))\n\trequire.NoError(t, err)\n\thelloPath, err := filepath.Abs(filepath.Join(\".\", \"testdata\", \"hello.sh\"))\n\trequire.NoError(t, err)\n\n\tctr, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{\n\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\tImage: testBashImage,\n\t\t\tFiles: []testcontainers.ContainerFile{\n\t\t\t\t{\n\t\t\t\t\tHostFilePath:      waitForPath,\n\t\t\t\t\tContainerFilePath: \"/waitForHello.sh\",\n\t\t\t\t\tFileMode:          0o700,\n\t\t\t\t},\n\t\t\t},\n\t\t\tCmd: []string{\"bash\", \"/waitForHello.sh\"},\n\t\t},\n\t\tStarted: true,\n\t})\n\ttestcontainers.CleanupContainer(t, ctr)\n\trequire.NoError(t, err)\n\n\terr = ctr.CopyFileToContainer(ctx, helloPath, \"/scripts/hello.sh\", 0o700)\n\t// }\n\n\trequire.NoError(t, err)\n\n\t// Give some time to the wait script to catch the hello script being created\n\terr = wait.ForLog(\"done\").WithStartupTimeout(2*time.Second).WaitUntilReady(ctx, ctr)\n\trequire.NoError(t, err)\n}\n\nfunc TestCopyDirectoryToContainer(t *testing.T) {\n\tctx, cnl := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer cnl()\n\n\t// Not using the assertations here to avoid leaking the library into the example\n\t// copyDirectoryToContainer {\n\tdataDirectory, err := filepath.Abs(filepath.Join(\".\", \"testdata\"))\n\trequire.NoError(t, err)\n\n\tctr, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{\n\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\tImage: testBashImage,\n\t\t\tFiles: []testcontainers.ContainerFile{\n\t\t\t\t{\n\t\t\t\t\tHostFilePath: dataDirectory,\n\t\t\t\t\t// ContainerFile cannot create the parent directory, so we copy the scripts\n\t\t\t\t\t// to the root of the container instead. Make sure to create the container directory\n\t\t\t\t\t// before you copy a host directory on create.\n\t\t\t\t\tContainerFilePath: \"/\",\n\t\t\t\t\tFileMode:          0o700,\n\t\t\t\t},\n\t\t\t},\n\t\t\tCmd:        []string{\"bash\", \"/testdata/hello.sh\"},\n\t\t\tWaitingFor: wait.ForLog(\"done\"),\n\t\t},\n\t\tStarted: true,\n\t})\n\t// }\n\ttestcontainers.CleanupContainer(t, ctr)\n\trequire.NoError(t, err)\n}\n\nfunc TestCopyDirectoryToRunningContainerAsFile(t *testing.T) {\n\tctx, cnl := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer cnl()\n\n\t// copyDirectoryToRunningContainerAsFile {\n\tdataDirectory, err := filepath.Abs(filepath.Join(\".\", \"testdata\"))\n\trequire.NoError(t, err)\n\twaitForPath, err := filepath.Abs(filepath.Join(dataDirectory, \"waitForHello.sh\"))\n\trequire.NoError(t, err)\n\n\tctr, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{\n\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\tImage: testBashImage,\n\t\t\tFiles: []testcontainers.ContainerFile{\n\t\t\t\t{\n\t\t\t\t\tHostFilePath:      waitForPath,\n\t\t\t\t\tContainerFilePath: \"/waitForHello.sh\",\n\t\t\t\t\tFileMode:          0o700,\n\t\t\t\t},\n\t\t\t},\n\t\t\tCmd: []string{\"bash\", \"/waitForHello.sh\"},\n\t\t},\n\t\tStarted: true,\n\t})\n\ttestcontainers.CleanupContainer(t, ctr)\n\trequire.NoError(t, err)\n\n\t// as the container is started, we can create the directory first\n\t_, _, err = ctr.Exec(ctx, []string{\"mkdir\", \"-p\", \"/scripts\"})\n\trequire.NoError(t, err)\n\n\t// because the container path is a directory, it will use the copy dir method as fallback\n\terr = ctr.CopyFileToContainer(ctx, dataDirectory, \"/scripts\", 0o700)\n\trequire.NoError(t, err)\n\t// }\n}\n\nfunc TestCopyDirectoryToRunningContainerAsDir(t *testing.T) {\n\tctx, cnl := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer cnl()\n\n\t// Not using the assertations here to avoid leaking the library into the example\n\t// copyDirectoryToRunningContainerAsDir {\n\twaitForPath, err := filepath.Abs(filepath.Join(\".\", \"testdata\", \"waitForHello.sh\"))\n\trequire.NoError(t, err)\n\tdataDirectory, err := filepath.Abs(filepath.Join(\".\", \"testdata\"))\n\trequire.NoError(t, err)\n\n\tctr, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{\n\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\tImage: testBashImage,\n\t\t\tFiles: []testcontainers.ContainerFile{\n\t\t\t\t{\n\t\t\t\t\tHostFilePath:      waitForPath,\n\t\t\t\t\tContainerFilePath: \"/waitForHello.sh\",\n\t\t\t\t\tFileMode:          0o700,\n\t\t\t\t},\n\t\t\t},\n\t\t\tCmd: []string{\"bash\", \"/waitForHello.sh\"},\n\t\t},\n\t\tStarted: true,\n\t})\n\ttestcontainers.CleanupContainer(t, ctr)\n\trequire.NoError(t, err)\n\n\t// as the container is started, we can create the directory first\n\t_, _, err = ctr.Exec(ctx, []string{\"mkdir\", \"-p\", \"/scripts\"})\n\trequire.NoError(t, err)\n\n\terr = ctr.CopyDirToContainer(ctx, dataDirectory, \"/scripts\", 0o700)\n\trequire.NoError(t, err)\n\t// }\n}\n"
        },
        {
          "name": "docker_mounts.go",
          "type": "blob",
          "size": 4.193359375,
          "content": "package testcontainers\n\nimport \"github.com/docker/docker/api/types/mount\"\n\nvar mountTypeMapping = map[MountType]mount.Type{\n\tMountTypeBind:   mount.TypeBind, // Deprecated, it will be removed in a future release\n\tMountTypeVolume: mount.TypeVolume,\n\tMountTypeTmpfs:  mount.TypeTmpfs,\n\tMountTypePipe:   mount.TypeNamedPipe,\n}\n\n// Deprecated: use Files or HostConfigModifier in the ContainerRequest, or copy files container APIs to make containers portable across Docker environments\n// BindMounter can optionally be implemented by mount sources\n// to support advanced scenarios based on mount.BindOptions\ntype BindMounter interface {\n\tGetBindOptions() *mount.BindOptions\n}\n\n// VolumeMounter can optionally be implemented by mount sources\n// to support advanced scenarios based on mount.VolumeOptions\ntype VolumeMounter interface {\n\tGetVolumeOptions() *mount.VolumeOptions\n}\n\n// TmpfsMounter can optionally be implemented by mount sources\n// to support advanced scenarios based on mount.TmpfsOptions\ntype TmpfsMounter interface {\n\tGetTmpfsOptions() *mount.TmpfsOptions\n}\n\n// Deprecated: use Files or HostConfigModifier in the ContainerRequest, or copy files container APIs to make containers portable across Docker environments\ntype DockerBindMountSource struct {\n\t*mount.BindOptions\n\n\t// HostPath is the path mounted into the container\n\t// the same host path might be mounted to multiple locations within a single container\n\tHostPath string\n}\n\n// Deprecated: use Files or HostConfigModifier in the ContainerRequest, or copy files container APIs to make containers portable across Docker environments\nfunc (s DockerBindMountSource) Source() string {\n\treturn s.HostPath\n}\n\n// Deprecated: use Files or HostConfigModifier in the ContainerRequest, or copy files container APIs to make containers portable across Docker environments\nfunc (DockerBindMountSource) Type() MountType {\n\treturn MountTypeBind\n}\n\n// Deprecated: use Files or HostConfigModifier in the ContainerRequest, or copy files container APIs to make containers portable across Docker environments\nfunc (s DockerBindMountSource) GetBindOptions() *mount.BindOptions {\n\treturn s.BindOptions\n}\n\ntype DockerVolumeMountSource struct {\n\t*mount.VolumeOptions\n\n\t// Name refers to the name of the volume to be mounted\n\t// the same volume might be mounted to multiple locations within a single container\n\tName string\n}\n\nfunc (s DockerVolumeMountSource) Source() string {\n\treturn s.Name\n}\n\nfunc (DockerVolumeMountSource) Type() MountType {\n\treturn MountTypeVolume\n}\n\nfunc (s DockerVolumeMountSource) GetVolumeOptions() *mount.VolumeOptions {\n\treturn s.VolumeOptions\n}\n\ntype DockerTmpfsMountSource struct {\n\tGenericTmpfsMountSource\n\t*mount.TmpfsOptions\n}\n\nfunc (s DockerTmpfsMountSource) GetTmpfsOptions() *mount.TmpfsOptions {\n\treturn s.TmpfsOptions\n}\n\n// PrepareMounts maps the given []ContainerMount to the corresponding\n// []mount.Mount for further processing\nfunc (m ContainerMounts) PrepareMounts() []mount.Mount {\n\treturn mapToDockerMounts(m)\n}\n\n// mapToDockerMounts maps the given []ContainerMount to the corresponding\n// []mount.Mount for further processing\nfunc mapToDockerMounts(containerMounts ContainerMounts) []mount.Mount {\n\tmounts := make([]mount.Mount, 0, len(containerMounts))\n\n\tfor idx := range containerMounts {\n\t\tm := containerMounts[idx]\n\n\t\tvar mountType mount.Type\n\t\tif mt, ok := mountTypeMapping[m.Source.Type()]; ok {\n\t\t\tmountType = mt\n\t\t} else {\n\t\t\tcontinue\n\t\t}\n\n\t\tcontainerMount := mount.Mount{\n\t\t\tType:     mountType,\n\t\t\tSource:   m.Source.Source(),\n\t\t\tReadOnly: m.ReadOnly,\n\t\t\tTarget:   m.Target.Target(),\n\t\t}\n\n\t\tswitch typedMounter := m.Source.(type) {\n\t\tcase VolumeMounter:\n\t\t\tcontainerMount.VolumeOptions = typedMounter.GetVolumeOptions()\n\t\tcase TmpfsMounter:\n\t\t\tcontainerMount.TmpfsOptions = typedMounter.GetTmpfsOptions()\n\t\tcase BindMounter:\n\t\t\tLogger.Printf(\"Mount type %s is not supported by Testcontainers for Go\", m.Source.Type())\n\t\tdefault:\n\t\t\t// The provided source type has no custom options\n\t\t}\n\n\t\tif mountType == mount.TypeVolume {\n\t\t\tif containerMount.VolumeOptions == nil {\n\t\t\t\tcontainerMount.VolumeOptions = &mount.VolumeOptions{\n\t\t\t\t\tLabels: make(map[string]string),\n\t\t\t\t}\n\t\t\t}\n\t\t\tAddGenericLabels(containerMount.VolumeOptions.Labels)\n\t\t}\n\n\t\tmounts = append(mounts, containerMount)\n\t}\n\n\treturn mounts\n}\n"
        },
        {
          "name": "docker_test.go",
          "type": "blob",
          "size": 61.095703125,
          "content": "package testcontainers\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"math/rand\"\n\t\"net/http\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/docker/docker/api/types\"\n\t\"github.com/docker/docker/api/types/container\"\n\t\"github.com/docker/docker/api/types/image\"\n\t\"github.com/docker/docker/api/types/strslice\"\n\t\"github.com/docker/docker/client\"\n\t\"github.com/docker/docker/errdefs\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/testcontainers/testcontainers-go/internal/core\"\n\t\"github.com/testcontainers/testcontainers-go/wait\"\n)\n\nconst (\n\tmysqlImage        = \"mysql:8.0.36\"\n\tnginxDelayedImage = \"menedev/delayed-nginx:1.15.2\"\n\tnginxImage        = \"nginx\"\n\tnginxAlpineImage  = \"nginx:alpine\"\n\tnginxDefaultPort  = \"80/tcp\"\n\tnginxHighPort     = \"8080/tcp\"\n\tgolangImage       = \"golang\"\n\tdaemonMaxVersion  = \"1.41\"\n)\n\nvar providerType = ProviderDocker\n\nfunc init() {\n\tif strings.Contains(os.Getenv(\"DOCKER_HOST\"), \"podman.sock\") {\n\t\tproviderType = ProviderPodman\n\t}\n}\n\nfunc TestContainerWithHostNetworkOptions(t *testing.T) {\n\tif os.Getenv(\"XDG_RUNTIME_DIR\") != \"\" {\n\t\tt.Skip(\"Skipping test that requires host network access when running in a container\")\n\t}\n\n\tctx := context.Background()\n\tSkipIfDockerDesktop(t, ctx)\n\n\tabsPath, err := filepath.Abs(filepath.Join(\"testdata\", \"nginx-highport.conf\"))\n\trequire.NoError(t, err)\n\n\tgcr := GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage: nginxAlpineImage,\n\t\t\tFiles: []ContainerFile{\n\t\t\t\t{\n\t\t\t\t\tHostFilePath:      absPath,\n\t\t\t\t\tContainerFilePath: \"/etc/nginx/conf.d/default.conf\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tExposedPorts: []string{\n\t\t\t\tnginxHighPort,\n\t\t\t},\n\t\t\tPrivileged: true,\n\t\t\tWaitingFor: wait.ForHTTP(\"/\").WithPort(nginxHighPort),\n\t\t\tHostConfigModifier: func(hc *container.HostConfig) {\n\t\t\t\thc.NetworkMode = \"host\"\n\t\t\t},\n\t\t},\n\t\tStarted: true,\n\t}\n\n\tnginxC, err := GenericContainer(ctx, gcr)\n\tCleanupContainer(t, nginxC)\n\trequire.NoError(t, err)\n\n\tendpoint, err := nginxC.PortEndpoint(ctx, nginxHighPort, \"http\")\n\trequire.NoErrorf(t, err, \"Expected server endpoint\")\n\n\t_, err = http.Get(endpoint)\n\trequire.NoErrorf(t, err, \"Expected OK response\")\n}\n\nfunc TestContainerWithHostNetworkOptions_UseExposePortsFromImageConfigs(t *testing.T) {\n\tctx := context.Background()\n\tgcr := GenericContainerRequest{\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage:      \"nginx\",\n\t\t\tPrivileged: true,\n\t\t\tWaitingFor: wait.ForExposedPort(),\n\t\t},\n\t\tStarted: true,\n\t}\n\n\tnginxC, err := GenericContainer(ctx, gcr)\n\tCleanupContainer(t, nginxC)\n\trequire.NoError(t, err)\n\n\tendpoint, err := nginxC.Endpoint(ctx, \"http\")\n\trequire.NoErrorf(t, err, \"Expected server endpoint\")\n\n\tresp, err := http.Get(endpoint)\n\trequire.NoError(t, err)\n\tdefer resp.Body.Close()\n\n\trequire.Equalf(t, http.StatusOK, resp.StatusCode, \"Expected status code %d. Got %d.\", http.StatusOK, resp.StatusCode)\n}\n\nfunc TestContainerWithNetworkModeAndNetworkTogether(t *testing.T) {\n\tif os.Getenv(\"XDG_RUNTIME_DIR\") != \"\" {\n\t\tt.Skip(\"Skipping test that requires host network access when running in a container\")\n\t}\n\n\t// skipIfDockerDesktop {\n\tctx := context.Background()\n\tSkipIfDockerDesktop(t, ctx)\n\t// }\n\n\tgcr := GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage:    nginxImage,\n\t\t\tNetworks: []string{\"new-network\"},\n\t\t\tHostConfigModifier: func(hc *container.HostConfig) {\n\t\t\t\thc.NetworkMode = \"host\"\n\t\t\t},\n\t\t},\n\t\tStarted: true,\n\t}\n\n\tnginx, err := GenericContainer(ctx, gcr)\n\tCleanupContainer(t, nginx)\n\tif err != nil {\n\t\t// Error when NetworkMode = host and Network = []string{\"bridge\"}\n\t\tt.Logf(\"Can't use Network and NetworkMode together, %s\\n\", err)\n\t}\n}\n\nfunc TestContainerWithHostNetwork(t *testing.T) {\n\tif os.Getenv(\"XDG_RUNTIME_DIR\") != \"\" {\n\t\tt.Skip(\"Skipping test that requires host network access when running in a container\")\n\t}\n\n\tctx := context.Background()\n\tSkipIfDockerDesktop(t, ctx)\n\n\tabsPath, err := filepath.Abs(filepath.Join(\"testdata\", \"nginx-highport.conf\"))\n\trequire.NoError(t, err)\n\n\tgcr := GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage:      nginxAlpineImage,\n\t\t\tWaitingFor: wait.ForHTTP(\"/\").WithPort(nginxHighPort),\n\t\t\tFiles: []ContainerFile{\n\t\t\t\t{\n\t\t\t\t\tHostFilePath:      absPath,\n\t\t\t\t\tContainerFilePath: \"/etc/nginx/conf.d/default.conf\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tHostConfigModifier: func(hc *container.HostConfig) {\n\t\t\t\thc.NetworkMode = \"host\"\n\t\t\t},\n\t\t},\n\t\tStarted: true,\n\t}\n\n\tnginxC, err := GenericContainer(ctx, gcr)\n\tCleanupContainer(t, nginxC)\n\trequire.NoError(t, err)\n\n\tportEndpoint, err := nginxC.PortEndpoint(ctx, nginxHighPort, \"http\")\n\trequire.NoErrorf(t, err, \"Expected port endpoint %s\", portEndpoint)\n\tt.Log(portEndpoint)\n\n\t_, err = http.Get(portEndpoint)\n\trequire.NoErrorf(t, err, \"Expected OK response\")\n\n\thost, err := nginxC.Host(ctx)\n\trequire.NoErrorf(t, err, \"Expected host %s\", host)\n\n\t_, err = http.Get(\"http://\" + host + \":8080\")\n\tassert.NoErrorf(t, err, \"Expected OK response\")\n}\n\nfunc TestContainerReturnItsContainerID(t *testing.T) {\n\tctx := context.Background()\n\tnginxA, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage: nginxAlpineImage,\n\t\t\tExposedPorts: []string{\n\t\t\t\tnginxDefaultPort,\n\t\t\t},\n\t\t},\n\t})\n\tCleanupContainer(t, nginxA)\n\trequire.NoError(t, err)\n\n\tassert.NotEmptyf(t, nginxA.GetContainerID(), \"expected a containerID but we got an empty string.\")\n}\n\n// testLogConsumer is a simple implementation of LogConsumer that logs to the test output.\ntype testLogConsumer struct {\n\tt *testing.T\n}\n\nfunc (l *testLogConsumer) Accept(log Log) {\n\tl.t.Log(log.LogType + \": \" + strings.TrimSpace(string(log.Content)))\n}\n\nfunc TestContainerTerminationResetsState(t *testing.T) {\n\tctx := context.Background()\n\n\tnginxA, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage: nginxAlpineImage,\n\t\t\tExposedPorts: []string{\n\t\t\t\tnginxDefaultPort,\n\t\t\t},\n\t\t\tLogConsumerCfg: &LogConsumerConfig{\n\t\t\t\tConsumers: []LogConsumer{&testLogConsumer{t: t}},\n\t\t\t},\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, nginxA)\n\trequire.NoError(t, err)\n\n\terr = nginxA.Terminate(ctx)\n\trequire.NoError(t, err)\n\trequire.Empty(t, nginxA.SessionID())\n\n\tinspect, err := nginxA.Inspect(ctx)\n\trequire.Error(t, err)\n\trequire.Nil(t, inspect)\n}\n\nfunc TestContainerStateAfterTermination(t *testing.T) {\n\tcreateContainerFn := func(ctx context.Context) (Container, error) {\n\t\treturn GenericContainer(ctx, GenericContainerRequest{\n\t\t\tProviderType: providerType,\n\t\t\tContainerRequest: ContainerRequest{\n\t\t\t\tImage: nginxAlpineImage,\n\t\t\t\tExposedPorts: []string{\n\t\t\t\t\tnginxDefaultPort,\n\t\t\t\t},\n\t\t\t\tLogConsumerCfg: &LogConsumerConfig{\n\t\t\t\t\tConsumers: []LogConsumer{&testLogConsumer{t: t}},\n\t\t\t\t},\n\t\t\t},\n\t\t\tStarted: true,\n\t\t})\n\t}\n\n\tt.Run(\"Nil State after termination\", func(t *testing.T) {\n\t\tctx := context.Background()\n\t\tnginx, err := createContainerFn(ctx)\n\t\tCleanupContainer(t, nginx)\n\t\trequire.NoError(t, err)\n\n\t\t// terminate the container before the raw state is set\n\t\terr = nginx.Terminate(ctx)\n\t\trequire.NoError(t, err)\n\n\t\tstate, err := nginx.State(ctx)\n\t\trequire.Error(t, err, \"expected error from container inspect.\")\n\n\t\trequire.Nil(t, state, \"expected nil container inspect.\")\n\t})\n\n\tt.Run(\"termination-timeout\", func(t *testing.T) {\n\t\tctx := context.Background()\n\t\tnginx, err := createContainerFn(ctx)\n\t\trequire.NoError(t, err)\n\n\t\terr = nginx.Start(ctx)\n\t\trequire.NoError(t, err, \"expected no error from container start.\")\n\n\t\terr = nginx.Terminate(ctx, StopTimeout(5*time.Microsecond))\n\t\trequire.NoError(t, err)\n\t})\n\n\tt.Run(\"Nil State after termination if raw as already set\", func(t *testing.T) {\n\t\tctx := context.Background()\n\t\tnginx, err := createContainerFn(ctx)\n\t\tCleanupContainer(t, nginx)\n\t\trequire.NoError(t, err)\n\n\t\tstate, err := nginx.State(ctx)\n\t\trequire.NoError(t, err, \"unexpected error from container inspect before container termination.\")\n\t\trequire.NotNil(t, state, \"unexpected nil container inspect before container termination.\")\n\n\t\t// terminate the container before the raw state is set\n\t\terr = nginx.Terminate(ctx)\n\t\trequire.NoError(t, err)\n\n\t\tstate, err = nginx.State(ctx)\n\t\trequire.Error(t, err, \"expected error from container inspect after container termination.\")\n\t\trequire.Nil(t, state, \"unexpected nil container inspect after container termination.\")\n\t})\n}\n\nfunc TestContainerTerminationRemovesDockerImage(t *testing.T) {\n\tt.Run(\"if not built from Dockerfile\", func(t *testing.T) {\n\t\tctx := context.Background()\n\t\tdockerClient, err := NewDockerClientWithOpts(ctx)\n\t\trequire.NoError(t, err)\n\t\tdefer dockerClient.Close()\n\n\t\tctr, err := GenericContainer(ctx, GenericContainerRequest{\n\t\t\tProviderType: providerType,\n\t\t\tContainerRequest: ContainerRequest{\n\t\t\t\tImage: nginxAlpineImage,\n\t\t\t\tExposedPorts: []string{\n\t\t\t\t\tnginxDefaultPort,\n\t\t\t\t},\n\t\t\t},\n\t\t\tStarted: true,\n\t\t})\n\t\tCleanupContainer(t, ctr)\n\t\trequire.NoError(t, err)\n\n\t\terr = ctr.Terminate(ctx)\n\t\trequire.NoError(t, err)\n\n\t\t_, _, err = dockerClient.ImageInspectWithRaw(ctx, nginxAlpineImage)\n\t\trequire.NoErrorf(t, err, \"nginx image should not have been removed\")\n\t})\n\n\tt.Run(\"if built from Dockerfile\", func(t *testing.T) {\n\t\tctx := context.Background()\n\t\tdockerClient, err := NewDockerClientWithOpts(ctx)\n\t\trequire.NoError(t, err)\n\t\tdefer dockerClient.Close()\n\n\t\treq := ContainerRequest{\n\t\t\tFromDockerfile: FromDockerfile{\n\t\t\t\tContext: filepath.Join(\".\", \"testdata\"),\n\t\t\t},\n\t\t\tExposedPorts: []string{\"6379/tcp\"},\n\t\t\tWaitingFor:   wait.ForLog(\"Ready to accept connections\"),\n\t\t}\n\t\tctr, err := GenericContainer(ctx, GenericContainerRequest{\n\t\t\tProviderType:     providerType,\n\t\t\tContainerRequest: req,\n\t\t\tStarted:          true,\n\t\t})\n\t\tCleanupContainer(t, ctr)\n\t\trequire.NoError(t, err)\n\t\tcontainerID := ctr.GetContainerID()\n\t\tresp, err := dockerClient.ContainerInspect(ctx, containerID)\n\t\trequire.NoError(t, err)\n\t\timageID := resp.Config.Image\n\n\t\terr = ctr.Terminate(ctx)\n\t\trequire.NoError(t, err)\n\n\t\t_, _, err = dockerClient.ImageInspectWithRaw(ctx, imageID)\n\t\trequire.Errorf(t, err, \"custom built image should have been removed\")\n\t})\n}\n\nfunc TestTwoContainersExposingTheSamePort(t *testing.T) {\n\tctx := context.Background()\n\tnginxA, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage: nginxAlpineImage,\n\t\t\tExposedPorts: []string{\n\t\t\t\tnginxDefaultPort,\n\t\t\t},\n\t\t\tWaitingFor: wait.ForHTTP(\"/\").WithPort(nginxDefaultPort),\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, nginxA)\n\trequire.NoError(t, err)\n\n\tnginxB, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage: nginxAlpineImage,\n\t\t\tExposedPorts: []string{\n\t\t\t\tnginxDefaultPort,\n\t\t\t},\n\t\t\tWaitingFor: wait.ForHTTP(\"/\").WithPort(nginxDefaultPort),\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, nginxB)\n\trequire.NoError(t, err)\n\n\tendpointA, err := nginxA.PortEndpoint(ctx, nginxDefaultPort, \"http\")\n\trequire.NoError(t, err)\n\n\tresp, err := http.Get(endpointA)\n\trequire.NoError(t, err)\n\tdefer resp.Body.Close()\n\n\trequire.Equalf(t, http.StatusOK, resp.StatusCode, \"Expected status code %d. Got %d.\", http.StatusOK, resp.StatusCode)\n\n\tendpointB, err := nginxB.PortEndpoint(ctx, nginxDefaultPort, \"http\")\n\trequire.NoError(t, err)\n\n\tresp, err = http.Get(endpointB)\n\trequire.NoError(t, err)\n\tdefer resp.Body.Close()\n\n\trequire.Equalf(t, http.StatusOK, resp.StatusCode, \"Expected status code %d. Got %d.\", http.StatusOK, resp.StatusCode)\n}\n\nfunc TestContainerCreation(t *testing.T) {\n\tctx := context.Background()\n\n\tnginxC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage: nginxAlpineImage,\n\t\t\tExposedPorts: []string{\n\t\t\t\tnginxDefaultPort,\n\t\t\t},\n\t\t\tWaitingFor: wait.ForHTTP(\"/\").WithPort(nginxDefaultPort),\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, nginxC)\n\trequire.NoError(t, err)\n\n\tendpoint, err := nginxC.PortEndpoint(ctx, nginxDefaultPort, \"http\")\n\trequire.NoError(t, err)\n\n\tresp, err := http.Get(endpoint)\n\trequire.NoError(t, err)\n\tdefer resp.Body.Close()\n\n\trequire.Equalf(t, http.StatusOK, resp.StatusCode, \"Expected status code %d. Got %d.\", http.StatusOK, resp.StatusCode)\n\tnetworkIP, err := nginxC.ContainerIP(ctx)\n\trequire.NoError(t, err)\n\trequire.NotEmptyf(t, networkIP, \"Expected an IP address, got %v\", networkIP)\n\tnetworkAliases, err := nginxC.NetworkAliases(ctx)\n\trequire.NoError(t, err)\n\trequire.Lenf(t, networkAliases, 1, \"Expected number of connected networks %d. Got %d.\", 0, len(networkAliases))\n\trequire.Contains(t, networkAliases, \"bridge\")\n\tassert.Emptyf(t, networkAliases[\"bridge\"], \"Expected number of aliases for 'bridge' network %d. Got %d.\", 0, len(networkAliases[\"bridge\"]))\n}\n\nfunc TestContainerCreationWithName(t *testing.T) {\n\tctx := context.Background()\n\n\tcreationName := fmt.Sprintf(\"%s_%d\", \"test_container\", time.Now().Unix())\n\texpectedName := \"/\" + creationName // inspect adds '/' in the beginning\n\n\tnginxC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage: nginxAlpineImage,\n\t\t\tExposedPorts: []string{\n\t\t\t\tnginxDefaultPort,\n\t\t\t},\n\t\t\tWaitingFor: wait.ForHTTP(\"/\").WithPort(nginxDefaultPort),\n\t\t\tName:       creationName,\n\t\t\tNetworks:   []string{\"bridge\"},\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, nginxC)\n\trequire.NoError(t, err)\n\n\tinspect, err := nginxC.Inspect(ctx)\n\trequire.NoError(t, err)\n\n\tname := inspect.Name\n\tassert.Equalf(t, expectedName, name, \"Expected container name '%s'. Got '%s'.\", expectedName, name)\n\tnetworks, err := nginxC.Networks(ctx)\n\trequire.NoError(t, err)\n\trequire.Lenf(t, networks, 1, \"Expected networks 1. Got '%d'.\", len(networks))\n\tnetwork := networks[0]\n\tswitch providerType {\n\tcase ProviderDocker:\n\t\tassert.Equalf(t, Bridge, network, \"Expected network name '%s'. Got '%s'.\", Bridge, network)\n\tcase ProviderPodman:\n\t\tassert.Equalf(t, Podman, network, \"Expected network name '%s'. Got '%s'.\", Podman, network)\n\t}\n\n\tendpoint, err := nginxC.PortEndpoint(ctx, nginxDefaultPort, \"http\")\n\trequire.NoError(t, err)\n\n\tresp, err := http.Get(endpoint)\n\trequire.NoError(t, err)\n\tdefer resp.Body.Close()\n\n\trequire.Equalf(t, http.StatusOK, resp.StatusCode, \"Expected status code %d. Got %d.\", http.StatusOK, resp.StatusCode)\n}\n\nfunc TestContainerCreationAndWaitForListeningPortLongEnough(t *testing.T) {\n\tctx := context.Background()\n\n\t// delayed-nginx will wait 2s before opening port\n\tnginxC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage: nginxDelayedImage,\n\t\t\tExposedPorts: []string{\n\t\t\t\tnginxDefaultPort,\n\t\t\t},\n\t\t\tWaitingFor: wait.ForHTTP(\"/\").WithPort(nginxDefaultPort), // default startupTimeout is 60s\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, nginxC)\n\trequire.NoError(t, err)\n\n\torigin, err := nginxC.PortEndpoint(ctx, nginxDefaultPort, \"http\")\n\trequire.NoError(t, err)\n\tresp, err := http.Get(origin)\n\trequire.NoError(t, err)\n\tdefer resp.Body.Close()\n\n\trequire.Equalf(t, http.StatusOK, resp.StatusCode, \"Expected status code %d. Got %d.\", http.StatusOK, resp.StatusCode)\n}\n\nfunc TestContainerCreationTimesOut(t *testing.T) {\n\tctx := context.Background()\n\t// delayed-nginx will wait 2s before opening port\n\tnginxC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage: nginxDelayedImage,\n\t\t\tExposedPorts: []string{\n\t\t\t\tnginxDefaultPort,\n\t\t\t},\n\t\t\tWaitingFor: wait.ForListeningPort(nginxDefaultPort).WithStartupTimeout(1 * time.Second),\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, nginxC)\n\n\tassert.Errorf(t, err, \"Expected timeout\")\n}\n\nfunc TestContainerRespondsWithHttp200ForIndex(t *testing.T) {\n\tctx := context.Background()\n\n\tnginxC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage: nginxAlpineImage,\n\t\t\tExposedPorts: []string{\n\t\t\t\tnginxDefaultPort,\n\t\t\t},\n\t\t\tWaitingFor: wait.ForHTTP(\"/\").WithStartupTimeout(10 * time.Second),\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, nginxC)\n\trequire.NoError(t, err)\n\n\torigin, err := nginxC.PortEndpoint(ctx, nginxDefaultPort, \"http\")\n\trequire.NoError(t, err)\n\tresp, err := http.Get(origin)\n\trequire.NoError(t, err)\n\tdefer resp.Body.Close()\n\n\trequire.Equalf(t, http.StatusOK, resp.StatusCode, \"Expected status code %d. Got %d.\", http.StatusOK, resp.StatusCode)\n}\n\nfunc TestContainerCreationTimesOutWithHttp(t *testing.T) {\n\tctx := context.Background()\n\t// delayed-nginx will wait 2s before opening port\n\tnginxC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage: nginxDelayedImage,\n\t\t\tExposedPorts: []string{\n\t\t\t\tnginxDefaultPort,\n\t\t\t},\n\t\t\tWaitingFor: wait.ForHTTP(\"/\").WithStartupTimeout(time.Millisecond * 500),\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, nginxC)\n\trequire.Error(t, err, \"expected timeout\")\n}\n\nfunc TestContainerCreationWaitsForLogContextTimeout(t *testing.T) {\n\tctx := context.Background()\n\treq := ContainerRequest{\n\t\tImage:        mysqlImage,\n\t\tExposedPorts: []string{\"3306/tcp\", \"33060/tcp\"},\n\t\tEnv: map[string]string{\n\t\t\t\"MYSQL_ROOT_PASSWORD\": \"password\",\n\t\t\t\"MYSQL_DATABASE\":      \"database\",\n\t\t},\n\t\tWaitingFor: wait.ForLog(\"test context timeout\").WithStartupTimeout(1 * time.Second),\n\t}\n\tc, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType:     providerType,\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, c)\n\tassert.Errorf(t, err, \"Expected timeout\")\n}\n\nfunc TestContainerCreationWaitsForLog(t *testing.T) {\n\tctx := context.Background()\n\treq := ContainerRequest{\n\t\tImage:        mysqlImage,\n\t\tExposedPorts: []string{\"3306/tcp\", \"33060/tcp\"},\n\t\tEnv: map[string]string{\n\t\t\t\"MYSQL_ROOT_PASSWORD\": \"password\",\n\t\t\t\"MYSQL_DATABASE\":      \"database\",\n\t\t},\n\t\tWaitingFor: wait.ForLog(\"port: 3306  MySQL Community Server - GPL\"),\n\t}\n\tmysqlC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType:     providerType,\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, mysqlC)\n\trequire.NoError(t, err)\n}\n\nfunc Test_BuildContainerFromDockerfileWithBuildArgs(t *testing.T) {\n\tctx := context.Background()\n\n\t// fromDockerfileWithBuildArgs {\n\tba := \"build args value\"\n\treq := ContainerRequest{\n\t\tFromDockerfile: FromDockerfile{\n\t\t\tContext:    filepath.Join(\".\", \"testdata\"),\n\t\t\tDockerfile: \"args.Dockerfile\",\n\t\t\tBuildArgs: map[string]*string{\n\t\t\t\t\"FOO\": &ba,\n\t\t\t},\n\t\t},\n\t\tExposedPorts: []string{\"8080/tcp\"},\n\t\tWaitingFor:   wait.ForLog(\"ready\"),\n\t}\n\t// }\n\n\tgenContainerReq := GenericContainerRequest{\n\t\tProviderType:     providerType,\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t}\n\n\tc, err := GenericContainer(ctx, genContainerReq)\n\tCleanupContainer(t, c)\n\trequire.NoError(t, err)\n\n\tep, err := c.Endpoint(ctx, \"http\")\n\trequire.NoError(t, err)\n\n\tresp, err := http.Get(ep + \"/env\")\n\trequire.NoError(t, err)\n\tdefer resp.Body.Close()\n\n\tbody, err := io.ReadAll(resp.Body)\n\trequire.NoError(t, err)\n\trequire.Equal(t, http.StatusAccepted, resp.StatusCode)\n\trequire.Equal(t, ba, string(body))\n}\n\nfunc Test_BuildContainerFromDockerfileWithBuildLog(t *testing.T) {\n\tr, w, err := os.Pipe()\n\trequire.NoError(t, err)\n\n\toldStderr := os.Stderr\n\tos.Stderr = w\n\tt.Cleanup(func() {\n\t\tos.Stderr = oldStderr\n\t})\n\n\tctx := context.Background()\n\n\t// fromDockerfile {\n\treq := ContainerRequest{\n\t\tFromDockerfile: FromDockerfile{\n\t\t\tContext:       filepath.Join(\".\", \"testdata\"),\n\t\t\tDockerfile:    \"buildlog.Dockerfile\",\n\t\t\tPrintBuildLog: true,\n\t\t},\n\t}\n\t// }\n\n\tgenContainerReq := GenericContainerRequest{\n\t\tProviderType:     providerType,\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t}\n\n\tc, err := GenericContainer(ctx, genContainerReq)\n\tCleanupContainer(t, c)\n\trequire.NoError(t, err)\n\n\terr = w.Close()\n\trequire.NoError(t, err)\n\n\tout, err := io.ReadAll(r)\n\trequire.NoError(t, err)\n\n\ttemp := strings.Split(string(out), \"\\n\")\n\trequire.NotEmpty(t, temp)\n\tassert.Regexpf(t, `^Step\\s*1/\\d+\\s*:\\s*FROM alpine$`, temp[0], \"Expected stdout first line to be %s. Got '%s'.\", \"Step 1/* : FROM alpine\", temp[0])\n}\n\nfunc Test_BuildContainerFromDockerfileWithBuildLogWriter(t *testing.T) {\n\tvar buffer bytes.Buffer\n\n\tctx := context.Background()\n\n\t// fromDockerfile {\n\treq := ContainerRequest{\n\t\tFromDockerfile: FromDockerfile{\n\t\t\tContext:        filepath.Join(\".\", \"testdata\"),\n\t\t\tDockerfile:     \"buildlog.Dockerfile\",\n\t\t\tBuildLogWriter: &buffer,\n\t\t},\n\t}\n\t// }\n\n\tgenContainerReq := GenericContainerRequest{\n\t\tProviderType:     providerType,\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t}\n\n\tc, err := GenericContainer(ctx, genContainerReq)\n\tCleanupContainer(t, c)\n\trequire.NoError(t, err)\n\n\tout := buffer.String()\n\ttemp := strings.Split(out, \"\\n\")\n\trequire.NotEmpty(t, temp)\n\trequire.Regexpf(t, `^Step\\s*1/\\d+\\s*:\\s*FROM alpine$`, temp[0], \"Expected stdout first line to be %s. Got '%s'.\", \"Step 1/* : FROM alpine\", temp[0])\n}\n\nfunc TestContainerCreationWaitsForLogAndPortContextTimeout(t *testing.T) {\n\tctx := context.Background()\n\treq := ContainerRequest{\n\t\tImage:        mysqlImage,\n\t\tExposedPorts: []string{\"3306/tcp\", \"33060/tcp\"},\n\t\tEnv: map[string]string{\n\t\t\t\"MYSQL_ROOT_PASSWORD\": \"password\",\n\t\t\t\"MYSQL_DATABASE\":      \"database\",\n\t\t},\n\t\tWaitingFor: wait.ForAll(\n\t\t\twait.ForLog(\"I love testcontainers-go\"),\n\t\t\twait.ForListeningPort(\"3306/tcp\"),\n\t\t),\n\t}\n\tc, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType:     providerType,\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, c)\n\trequire.Errorf(t, err, \"Expected timeout\")\n}\n\nfunc TestContainerCreationWaitingForHostPort(t *testing.T) {\n\tctx := context.Background()\n\t// exposePorts {\n\treq := ContainerRequest{\n\t\tImage:        nginxAlpineImage,\n\t\tExposedPorts: []string{nginxDefaultPort},\n\t\tWaitingFor:   wait.ForListeningPort(nginxDefaultPort),\n\t}\n\t// }\n\tnginx, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType:     providerType,\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, nginx)\n\trequire.NoError(t, err)\n}\n\nfunc TestContainerCreationWaitingForHostPortWithoutBashThrowsAnError(t *testing.T) {\n\tctx := context.Background()\n\treq := ContainerRequest{\n\t\tImage:        nginxAlpineImage,\n\t\tExposedPorts: []string{nginxDefaultPort},\n\t\tWaitingFor:   wait.ForListeningPort(nginxDefaultPort),\n\t}\n\tnginx, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType:     providerType,\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, nginx)\n\trequire.NoError(t, err)\n}\n\nfunc TestCMD(t *testing.T) {\n\t/*\n\t\techo a unique statement to ensure that we\n\t\tcan pass in a command to the ContainerRequest\n\t\tand it will be run when we run the container\n\t*/\n\n\tctx := context.Background()\n\n\treq := ContainerRequest{\n\t\tImage: \"alpine\",\n\t\tWaitingFor: wait.ForAll(\n\t\t\twait.ForLog(\"command override!\"),\n\t\t),\n\t\tCmd: []string{\"echo\", \"command override!\"},\n\t}\n\n\tc, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType:     providerType,\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, c)\n\trequire.NoError(t, err)\n}\n\nfunc TestEntrypoint(t *testing.T) {\n\t/*\n\t\techo a unique statement to ensure that we\n\t\tcan pass in an entrypoint to the ContainerRequest\n\t\tand it will be run when we run the container\n\t*/\n\n\tctx := context.Background()\n\n\treq := ContainerRequest{\n\t\tImage: \"alpine\",\n\t\tWaitingFor: wait.ForAll(\n\t\t\twait.ForLog(\"entrypoint override!\"),\n\t\t),\n\t\tEntrypoint: []string{\"echo\", \"entrypoint override!\"},\n\t}\n\n\tc, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType:     providerType,\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, c)\n\trequire.NoError(t, err)\n}\n\nfunc TestWorkingDir(t *testing.T) {\n\t/*\n\t\tprint the current working directory to ensure that\n\t\twe can specify working directory in the\n\t\tContainerRequest and it will be used for the container\n\t*/\n\n\tctx := context.Background()\n\n\treq := ContainerRequest{\n\t\tImage: \"alpine\",\n\t\tWaitingFor: wait.ForAll(\n\t\t\twait.ForLog(\"/var/tmp/test\"),\n\t\t),\n\t\tEntrypoint: []string{\"pwd\"},\n\t\tWorkingDir: \"/var/tmp/test\",\n\t}\n\n\tc, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType:     providerType,\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, c)\n\trequire.NoError(t, err)\n}\n\nfunc ExampleDockerProvider_CreateContainer() {\n\tctx := context.Background()\n\treq := ContainerRequest{\n\t\tImage:        \"nginx:alpine\",\n\t\tExposedPorts: []string{\"80/tcp\"},\n\t\tWaitingFor:   wait.ForHTTP(\"/\").WithStartupTimeout(10 * time.Second),\n\t}\n\tnginxC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tdefer func() {\n\t\tif err := TerminateContainer(nginxC); err != nil {\n\t\t\tlog.Printf(\"failed to terminate container: %s\", err)\n\t\t}\n\t}()\n\tif err != nil {\n\t\tlog.Printf(\"failed to create container: %s\", err)\n\t\treturn\n\t}\n\n\tstate, err := nginxC.State(ctx)\n\tif err != nil {\n\t\tlog.Printf(\"failed to get container state: %s\", err)\n\t\treturn\n\t}\n\n\tfmt.Println(state.Running)\n\n\t// Output:\n\t// true\n}\n\nfunc ExampleContainer_Host() {\n\tctx := context.Background()\n\treq := ContainerRequest{\n\t\tImage:        \"nginx:alpine\",\n\t\tExposedPorts: []string{\"80/tcp\"},\n\t\tWaitingFor:   wait.ForHTTP(\"/\").WithStartupTimeout(10 * time.Second),\n\t}\n\tnginxC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tdefer func() {\n\t\tif err := TerminateContainer(nginxC); err != nil {\n\t\t\tlog.Printf(\"failed to terminate container: %s\", err)\n\t\t}\n\t}()\n\tif err != nil {\n\t\tlog.Printf(\"failed to create container: %s\", err)\n\t\treturn\n\t}\n\t// containerHost {\n\tip, err := nginxC.Host(ctx)\n\tif err != nil {\n\t\tlog.Printf(\"failed to create container: %s\", err)\n\t\treturn\n\t}\n\t// }\n\tfmt.Println(ip)\n\n\tstate, err := nginxC.State(ctx)\n\tif err != nil {\n\t\tlog.Printf(\"failed to get container state: %s\", err)\n\t\treturn\n\t}\n\n\tfmt.Println(state.Running)\n\n\t// Output:\n\t// localhost\n\t// true\n}\n\nfunc ExampleContainer_Start() {\n\tctx := context.Background()\n\treq := ContainerRequest{\n\t\tImage:        \"nginx:alpine\",\n\t\tExposedPorts: []string{\"80/tcp\"},\n\t\tWaitingFor:   wait.ForHTTP(\"/\").WithStartupTimeout(10 * time.Second),\n\t}\n\tnginxC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tContainerRequest: req,\n\t})\n\tdefer func() {\n\t\tif err := TerminateContainer(nginxC); err != nil {\n\t\t\tlog.Printf(\"failed to terminate container: %s\", err)\n\t\t}\n\t}()\n\tif err != nil {\n\t\tlog.Printf(\"failed to create container: %s\", err)\n\t\treturn\n\t}\n\n\tif err = nginxC.Start(ctx); err != nil {\n\t\tlog.Printf(\"failed to start container: %s\", err)\n\t\treturn\n\t}\n\n\tstate, err := nginxC.State(ctx)\n\tif err != nil {\n\t\tlog.Printf(\"failed to get container state: %s\", err)\n\t\treturn\n\t}\n\n\tfmt.Println(state.Running)\n\n\t// Output:\n\t// true\n}\n\nfunc ExampleContainer_Stop() {\n\tctx := context.Background()\n\treq := ContainerRequest{\n\t\tImage:        \"nginx:alpine\",\n\t\tExposedPorts: []string{\"80/tcp\"},\n\t\tWaitingFor:   wait.ForHTTP(\"/\").WithStartupTimeout(10 * time.Second),\n\t}\n\tnginxC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tContainerRequest: req,\n\t})\n\tdefer func() {\n\t\tif err := TerminateContainer(nginxC); err != nil {\n\t\t\tlog.Printf(\"failed to terminate container: %s\", err)\n\t\t}\n\t}()\n\tif err != nil {\n\t\tlog.Printf(\"failed to create and start container: %s\", err)\n\t\treturn\n\t}\n\n\tfmt.Println(\"Container has been started\")\n\ttimeout := 10 * time.Second\n\tif err = nginxC.Stop(ctx, &timeout); err != nil {\n\t\tlog.Printf(\"failed to terminate container: %s\", err)\n\t\treturn\n\t}\n\n\tfmt.Println(\"Container has been stopped\")\n\n\t// Output:\n\t// Container has been started\n\t// Container has been stopped\n}\n\nfunc ExampleContainer_MappedPort() {\n\tctx := context.Background()\n\treq := ContainerRequest{\n\t\tImage:        \"nginx:alpine\",\n\t\tExposedPorts: []string{\"80/tcp\"},\n\t\tWaitingFor:   wait.ForHTTP(\"/\").WithStartupTimeout(10 * time.Second),\n\t}\n\tnginxC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tdefer func() {\n\t\tif err := TerminateContainer(nginxC); err != nil {\n\t\t\tlog.Printf(\"failed to terminate container: %s\", err)\n\t\t}\n\t}()\n\tif err != nil {\n\t\tlog.Printf(\"failed to create and start container: %s\", err)\n\t\treturn\n\t}\n\n\t// buildingAddresses {\n\tip, _ := nginxC.Host(ctx)\n\tport, _ := nginxC.MappedPort(ctx, \"80\")\n\t_, _ = http.Get(fmt.Sprintf(\"http://%s:%s\", ip, port.Port()))\n\t// }\n\n\tstate, err := nginxC.State(ctx)\n\tif err != nil {\n\t\tlog.Printf(\"failed to get container state: %s\", err)\n\t\treturn\n\t}\n\n\tfmt.Println(state.Running)\n\n\t// Output:\n\t// true\n}\n\nfunc TestContainerCreationWithVolumeAndFileWritingToIt(t *testing.T) {\n\tabsPath, err := filepath.Abs(filepath.Join(\".\", \"testdata\", \"hello.sh\"))\n\trequire.NoError(t, err)\n\tctx, cnl := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer cnl()\n\n\t// Create the volume.\n\tvolumeName := \"volumeName\"\n\n\t// Create the container that writes into the mounted volume.\n\tbashC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage: \"bash:5.2.26\",\n\t\t\tFiles: []ContainerFile{\n\t\t\t\t{\n\t\t\t\t\tHostFilePath:      absPath,\n\t\t\t\t\tContainerFilePath: \"/hello.sh\",\n\t\t\t\t\tFileMode:          700,\n\t\t\t\t},\n\t\t\t},\n\t\t\tMounts:     Mounts(VolumeMount(volumeName, \"/data\")),\n\t\t\tCmd:        []string{\"bash\", \"/hello.sh\"},\n\t\t\tWaitingFor: wait.ForLog(\"done\"),\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, bashC, RemoveVolumes(volumeName))\n\trequire.NoError(t, err)\n}\n\nfunc TestContainerCreationWithVolumeCleaning(t *testing.T) {\n\tabsPath, err := filepath.Abs(filepath.Join(\".\", \"testdata\", \"hello.sh\"))\n\trequire.NoError(t, err)\n\tctx, cnl := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer cnl()\n\n\t// Create the volume.\n\tvolumeName := \"volumeName\"\n\n\t// Create the container that writes into the mounted volume.\n\tbashC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage: \"bash:5.2.26\",\n\t\t\tFiles: []ContainerFile{\n\t\t\t\t{\n\t\t\t\t\tHostFilePath:      absPath,\n\t\t\t\t\tContainerFilePath: \"/hello.sh\",\n\t\t\t\t\tFileMode:          700,\n\t\t\t\t},\n\t\t\t},\n\t\t\tMounts:     Mounts(VolumeMount(volumeName, \"/data\")),\n\t\t\tCmd:        []string{\"bash\", \"/hello.sh\"},\n\t\t\tWaitingFor: wait.ForLog(\"done\"),\n\t\t},\n\t\tStarted: true,\n\t})\n\trequire.NoError(t, err)\n\terr = bashC.Terminate(ctx, RemoveVolumes(volumeName))\n\tCleanupContainer(t, bashC, RemoveVolumes(volumeName))\n\trequire.NoError(t, err)\n}\n\nfunc TestContainerTerminationOptions(t *testing.T) {\n\tt.Run(\"volumes\", func(t *testing.T) {\n\t\tvar options TerminateOptions\n\t\tRemoveVolumes(\"vol1\", \"vol2\")(&options)\n\t\trequire.Equal(t, TerminateOptions{\n\t\t\tvolumes: []string{\"vol1\", \"vol2\"},\n\t\t}, options)\n\t})\n\tt.Run(\"stop-timeout\", func(t *testing.T) {\n\t\tvar options TerminateOptions\n\t\ttimeout := 11 * time.Second\n\t\tStopTimeout(timeout)(&options)\n\t\trequire.Equal(t, TerminateOptions{\n\t\t\tstopTimeout: &timeout,\n\t\t}, options)\n\t})\n\n\tt.Run(\"all\", func(t *testing.T) {\n\t\tvar options TerminateOptions\n\t\ttimeout := 9 * time.Second\n\t\tStopTimeout(timeout)(&options)\n\t\tRemoveVolumes(\"vol1\", \"vol2\")(&options)\n\t\trequire.Equal(t, TerminateOptions{\n\t\t\tstopTimeout: &timeout,\n\t\t\tvolumes:     []string{\"vol1\", \"vol2\"},\n\t\t}, options)\n\t})\n}\n\nfunc TestContainerWithTmpFs(t *testing.T) {\n\tctx := context.Background()\n\treq := ContainerRequest{\n\t\tImage: \"busybox\",\n\t\tCmd:   []string{\"sleep\", \"10\"},\n\t\tTmpfs: map[string]string{\"/testtmpfs\": \"rw\"},\n\t}\n\n\tctr, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType:     providerType,\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, ctr)\n\trequire.NoError(t, err)\n\n\tpath := \"/testtmpfs/test.file\"\n\n\t// exec_reader_example {\n\tc, reader, err := ctr.Exec(ctx, []string{\"ls\", path})\n\trequire.NoError(t, err)\n\trequire.Equalf(t, 1, c, \"File %s should not have existed, expected return code 1, got %v\", path, c)\n\n\tbuf := new(strings.Builder)\n\t_, err = io.Copy(buf, reader)\n\trequire.NoError(t, err)\n\n\t// See the logs from the command execution.\n\tt.Log(buf.String())\n\t// }\n\n\t// exec_example {\n\tc, _, err = ctr.Exec(ctx, []string{\"touch\", path})\n\trequire.NoError(t, err)\n\trequire.Zerof(t, c, \"File %s should have been created successfully, expected return code 0, got %v\", path, c)\n\t// }\n\n\tc, _, err = ctr.Exec(ctx, []string{\"ls\", path})\n\trequire.NoError(t, err)\n\trequire.Zerof(t, c, \"File %s should exist, expected return code 0, got %v\", path, c)\n}\n\nfunc TestContainerNonExistentImage(t *testing.T) {\n\tt.Run(\"if the image not found don't propagate the error\", func(t *testing.T) {\n\t\tctr, err := GenericContainer(context.Background(), GenericContainerRequest{\n\t\t\tContainerRequest: ContainerRequest{\n\t\t\t\tImage: \"postgres:nonexistent-version\",\n\t\t\t},\n\t\t\tStarted: true,\n\t\t})\n\t\tCleanupContainer(t, ctr)\n\n\t\tvar nf errdefs.ErrNotFound\n\t\trequire.ErrorAsf(t, err, &nf, \"the error should have been an errdefs.ErrNotFound: %v\", err)\n\t})\n\n\tt.Run(\"the context cancellation is propagated to container creation\", func(t *testing.T) {\n\t\tctx, cancel := context.WithTimeout(context.Background(), 100*time.Millisecond)\n\t\tdefer cancel()\n\t\tc, err := GenericContainer(ctx, GenericContainerRequest{\n\t\t\tProviderType: providerType,\n\t\t\tContainerRequest: ContainerRequest{\n\t\t\t\tImage:      \"postgres:12\",\n\t\t\t\tWaitingFor: wait.ForLog(\"log\"),\n\t\t\t},\n\t\t\tStarted: true,\n\t\t})\n\t\tCleanupContainer(t, c)\n\t\trequire.ErrorIsf(t, err, ctx.Err(), \"err should be a ctx cancelled error %v\", err)\n\t})\n}\n\nfunc TestContainerCustomPlatformImage(t *testing.T) {\n\tif providerType == ProviderPodman {\n\t\tt.Skip(\"Incompatible Docker API version for Podman\")\n\t}\n\tt.Run(\"error with a non-existent platform\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tnonExistentPlatform := \"windows/arm12\"\n\t\tctx, cancel := context.WithTimeout(context.Background(), 1*time.Second)\n\t\tdefer cancel()\n\t\tc, err := GenericContainer(ctx, GenericContainerRequest{\n\t\t\tProviderType: providerType,\n\t\t\tContainerRequest: ContainerRequest{\n\t\t\t\tImage:         \"redis:latest\",\n\t\t\t\tImagePlatform: nonExistentPlatform,\n\t\t\t},\n\t\t\tStarted: false,\n\t\t})\n\t\tCleanupContainer(t, c)\n\t\trequire.Error(t, err)\n\t})\n\n\tt.Run(\"specific platform should be propagated\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tctx := context.Background()\n\n\t\tc, err := GenericContainer(ctx, GenericContainerRequest{\n\t\t\tProviderType: providerType,\n\t\t\tContainerRequest: ContainerRequest{\n\t\t\t\tImage:         \"mysql:8.0.36\",\n\t\t\t\tImagePlatform: \"linux/amd64\",\n\t\t\t},\n\t\t\tStarted: false,\n\t\t})\n\t\tCleanupContainer(t, c)\n\t\trequire.NoError(t, err)\n\n\t\tdockerCli, err := NewDockerClientWithOpts(ctx)\n\t\trequire.NoError(t, err)\n\t\tdefer dockerCli.Close()\n\n\t\tctr, err := dockerCli.ContainerInspect(ctx, c.GetContainerID())\n\t\trequire.NoError(t, err)\n\n\t\timg, _, err := dockerCli.ImageInspectWithRaw(ctx, ctr.Image)\n\t\trequire.NoError(t, err)\n\t\tassert.Equal(t, \"linux\", img.Os)\n\t\tassert.Equal(t, \"amd64\", img.Architecture)\n\t})\n}\n\nfunc TestContainerWithCustomHostname(t *testing.T) {\n\tctx := context.Background()\n\tname := fmt.Sprintf(\"some-nginx-%s-%d\", t.Name(), rand.Int())\n\thostname := fmt.Sprintf(\"my-nginx-%s-%d\", t.Name(), rand.Int())\n\treq := ContainerRequest{\n\t\tName:     name,\n\t\tImage:    nginxImage,\n\t\tHostname: hostname,\n\t}\n\tctr, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType:     providerType,\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, ctr)\n\trequire.NoError(t, err)\n\n\tactualHostname := readHostname(t, ctr.GetContainerID())\n\trequire.Equalf(t, actualHostname, hostname, \"expected hostname %s, got %s\", hostname, actualHostname)\n}\n\nfunc TestContainerInspect_RawInspectIsCleanedOnStop(t *testing.T) {\n\tctr, err := GenericContainer(context.Background(), GenericContainerRequest{\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage: nginxImage,\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, ctr)\n\trequire.NoError(t, err)\n\n\tinspect, err := ctr.Inspect(context.Background())\n\trequire.NoError(t, err)\n\n\trequire.NotEmpty(t, inspect.ID)\n\n\trequire.NoError(t, ctr.Stop(context.Background(), nil))\n}\n\nfunc readHostname(tb testing.TB, containerId string) string {\n\ttb.Helper()\n\tcontainerClient, err := NewDockerClientWithOpts(context.Background())\n\trequire.NoErrorf(tb, err, \"Failed to create Docker client\")\n\tdefer containerClient.Close()\n\n\tcontainerDetails, err := containerClient.ContainerInspect(context.Background(), containerId)\n\trequire.NoErrorf(tb, err, \"Failed to inspect container\")\n\n\treturn containerDetails.Config.Hostname\n}\n\nfunc TestDockerContainerCopyFileToContainer(t *testing.T) {\n\tctx := context.Background()\n\n\ttests := []struct {\n\t\tname           string\n\t\tcopiedFileName string\n\t}{\n\t\t{\n\t\t\tname:           \"success copy\",\n\t\t\tcopiedFileName: \"/hello_copy.sh\",\n\t\t},\n\t\t{\n\t\t\tname:           \"success copy with dir\",\n\t\t\tcopiedFileName: \"/test/hello_copy.sh\",\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tnginxC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\t\t\tProviderType: providerType,\n\t\t\t\tContainerRequest: ContainerRequest{\n\t\t\t\t\tImage:        nginxImage,\n\t\t\t\t\tExposedPorts: []string{nginxDefaultPort},\n\t\t\t\t\tWaitingFor:   wait.ForListeningPort(nginxDefaultPort),\n\t\t\t\t},\n\t\t\t\tStarted: true,\n\t\t\t})\n\t\t\tCleanupContainer(t, nginxC)\n\t\t\trequire.NoError(t, err)\n\n\t\t\t_ = nginxC.CopyFileToContainer(ctx, filepath.Join(\".\", \"testdata\", \"hello.sh\"), tc.copiedFileName, 700)\n\t\t\tc, _, err := nginxC.Exec(ctx, []string{\"bash\", tc.copiedFileName})\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.Zerof(t, c, \"File %s should exist, expected return code 0, got %v\", tc.copiedFileName, c)\n\t\t})\n\t}\n}\n\nfunc TestDockerContainerCopyDirToContainer(t *testing.T) {\n\tctx := context.Background()\n\n\tnginxC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage:        nginxImage,\n\t\t\tExposedPorts: []string{nginxDefaultPort},\n\t\t\tWaitingFor:   wait.ForListeningPort(nginxDefaultPort),\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, nginxC)\n\trequire.NoError(t, err)\n\n\tp := filepath.Join(\".\", \"testdata\", \"Dokerfile\")\n\terr = nginxC.CopyDirToContainer(ctx, p, \"/tmp/testdata/Dockerfile\", 700)\n\trequire.Error(t, err) // copying a file using the directory method will raise an error\n\n\tp = filepath.Join(\".\", \"testdata\")\n\terr = nginxC.CopyDirToContainer(ctx, p, \"/tmp/testdata\", 700)\n\trequire.NoError(t, err)\n\n\tassertExtractedFiles(t, ctx, nginxC, p, \"/tmp/testdata/\")\n}\n\nfunc TestDockerCreateContainerWithFiles(t *testing.T) {\n\tctx := context.Background()\n\thostFileName := filepath.Join(\".\", \"testdata\", \"hello.sh\")\n\tcopiedFileName := \"/hello_copy.sh\"\n\ttests := []struct {\n\t\tname   string\n\t\tfiles  []ContainerFile\n\t\terrMsg string\n\t}{\n\t\t{\n\t\t\tname: \"success copy\",\n\t\t\tfiles: []ContainerFile{\n\t\t\t\t{\n\t\t\t\t\tHostFilePath:      hostFileName,\n\t\t\t\t\tContainerFilePath: copiedFileName,\n\t\t\t\t\tFileMode:          700,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"host file not found\",\n\t\t\tfiles: []ContainerFile{\n\t\t\t\t{\n\t\t\t\t\tHostFilePath:      hostFileName + \"123\",\n\t\t\t\t\tContainerFilePath: copiedFileName,\n\t\t\t\t\tFileMode:          700,\n\t\t\t\t},\n\t\t\t},\n\t\t\terrMsg: \"can't copy \" +\n\t\t\t\thostFileName + \"123 to container: open \" + hostFileName + \"123\",\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tnginxC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\t\t\tContainerRequest: ContainerRequest{\n\t\t\t\t\tImage:        \"nginx:1.17.6\",\n\t\t\t\t\tExposedPorts: []string{\"80/tcp\"},\n\t\t\t\t\tWaitingFor:   wait.ForListeningPort(\"80/tcp\"),\n\t\t\t\t\tFiles:        tc.files,\n\t\t\t\t},\n\t\t\t\tStarted: false,\n\t\t\t})\n\t\t\tCleanupContainer(t, nginxC)\n\n\t\t\tif err != nil {\n\t\t\t\trequire.ErrorContains(t, err, tc.errMsg)\n\t\t\t} else {\n\t\t\t\tfor _, f := range tc.files {\n\t\t\t\t\trequire.NoError(t, err)\n\n\t\t\t\t\thostFileData, err := os.ReadFile(f.HostFilePath)\n\t\t\t\t\trequire.NoError(t, err)\n\n\t\t\t\t\tfd, err := nginxC.CopyFileFromContainer(ctx, f.ContainerFilePath)\n\t\t\t\t\trequire.NoError(t, err)\n\t\t\t\t\tdefer fd.Close()\n\t\t\t\t\tcontainerFileData, err := io.ReadAll(fd)\n\t\t\t\t\trequire.NoError(t, err)\n\n\t\t\t\t\trequire.Equal(t, hostFileData, containerFileData)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestDockerCreateContainerWithDirs(t *testing.T) {\n\tctx := context.Background()\n\thostDirName := \"testdata\"\n\n\tabs, err := filepath.Abs(filepath.Join(\".\", hostDirName))\n\trequire.NoError(t, err)\n\n\ttests := []struct {\n\t\tname     string\n\t\tdir      ContainerFile\n\t\thasError bool\n\t}{\n\t\t{\n\t\t\tname: \"success copy directory with full path\",\n\t\t\tdir: ContainerFile{\n\t\t\t\tHostFilePath:      abs,\n\t\t\t\tContainerFilePath: \"/tmp/\" + hostDirName, // the parent dir must exist\n\t\t\t\tFileMode:          700,\n\t\t\t},\n\t\t\thasError: false,\n\t\t},\n\t\t{\n\t\t\tname: \"success copy directory\",\n\t\t\tdir: ContainerFile{\n\t\t\t\tHostFilePath:      filepath.Join(\".\", hostDirName),\n\t\t\t\tContainerFilePath: \"/tmp/\" + hostDirName, // the parent dir must exist\n\t\t\t\tFileMode:          700,\n\t\t\t},\n\t\t\thasError: false,\n\t\t},\n\t\t{\n\t\t\tname: \"host dir not found\",\n\t\t\tdir: ContainerFile{\n\t\t\t\tHostFilePath:      filepath.Join(\".\", \"testdata123\"), // does not exist\n\t\t\t\tContainerFilePath: \"/tmp/\" + hostDirName,             // the parent dir must exist\n\t\t\t\tFileMode:          700,\n\t\t\t},\n\t\t\thasError: true,\n\t\t},\n\t\t{\n\t\t\tname: \"container dir not found\",\n\t\t\tdir: ContainerFile{\n\t\t\t\tHostFilePath:      filepath.Join(\".\", hostDirName),\n\t\t\t\tContainerFilePath: \"/parent-does-not-exist/testdata123\", // does not exist\n\t\t\t\tFileMode:          700,\n\t\t\t},\n\t\t\thasError: true,\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tnginxC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\t\t\tContainerRequest: ContainerRequest{\n\t\t\t\t\tImage:        \"nginx:1.17.6\",\n\t\t\t\t\tExposedPorts: []string{\"80/tcp\"},\n\t\t\t\t\tWaitingFor:   wait.ForListeningPort(\"80/tcp\"),\n\t\t\t\t\tFiles:        []ContainerFile{tc.dir},\n\t\t\t\t},\n\t\t\t\tStarted: false,\n\t\t\t})\n\t\t\tCleanupContainer(t, nginxC)\n\n\t\t\trequire.Equal(t, (err != nil), tc.hasError)\n\t\t\tif err == nil {\n\t\t\t\tdir := tc.dir\n\n\t\t\t\tassertExtractedFiles(t, ctx, nginxC, dir.HostFilePath, dir.ContainerFilePath)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestDockerContainerCopyToContainer(t *testing.T) {\n\tctx := context.Background()\n\n\ttests := []struct {\n\t\tname           string\n\t\tcopiedFileName string\n\t}{\n\t\t{\n\t\t\tname:           \"success copy\",\n\t\t\tcopiedFileName: \"hello_copy.sh\",\n\t\t},\n\t\t{\n\t\t\tname:           \"success copy with dir\",\n\t\t\tcopiedFileName: \"/test/hello_copy.sh\",\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tnginxC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\t\t\tProviderType: providerType,\n\t\t\t\tContainerRequest: ContainerRequest{\n\t\t\t\t\tImage:        nginxImage,\n\t\t\t\t\tExposedPorts: []string{nginxDefaultPort},\n\t\t\t\t\tWaitingFor:   wait.ForListeningPort(nginxDefaultPort),\n\t\t\t\t},\n\t\t\t\tStarted: true,\n\t\t\t})\n\t\t\tCleanupContainer(t, nginxC)\n\t\t\trequire.NoError(t, err)\n\n\t\t\tfileContent, err := os.ReadFile(filepath.Join(\".\", \"testdata\", \"hello.sh\"))\n\t\t\trequire.NoError(t, err)\n\t\t\terr = nginxC.CopyToContainer(ctx, fileContent, tc.copiedFileName, 700)\n\t\t\trequire.NoError(t, err)\n\t\t\tc, _, err := nginxC.Exec(ctx, []string{\"bash\", tc.copiedFileName})\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.Zerof(t, c, \"File %s should exist, expected return code 0, got %v\", tc.copiedFileName, c)\n\t\t})\n\t}\n}\n\nfunc TestDockerContainerCopyFileFromContainer(t *testing.T) {\n\tfileContent, err := os.ReadFile(filepath.Join(\".\", \"testdata\", \"hello.sh\"))\n\trequire.NoError(t, err)\n\tctx := context.Background()\n\n\tnginxC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage:        nginxImage,\n\t\t\tExposedPorts: []string{nginxDefaultPort},\n\t\t\tWaitingFor:   wait.ForListeningPort(nginxDefaultPort),\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, nginxC)\n\trequire.NoError(t, err)\n\n\tcopiedFileName := \"hello_copy.sh\"\n\t_ = nginxC.CopyFileToContainer(ctx, filepath.Join(\".\", \"testdata\", \"hello.sh\"), \"/\"+copiedFileName, 700)\n\tc, _, err := nginxC.Exec(ctx, []string{\"bash\", copiedFileName})\n\trequire.NoError(t, err)\n\trequire.Zerof(t, c, \"File %s should exist, expected return code 0, got %v\", copiedFileName, c)\n\n\treader, err := nginxC.CopyFileFromContainer(ctx, \"/\"+copiedFileName)\n\trequire.NoError(t, err)\n\tdefer reader.Close()\n\n\tfileContentFromContainer, err := io.ReadAll(reader)\n\trequire.NoError(t, err)\n\tassert.Equal(t, fileContent, fileContentFromContainer)\n}\n\nfunc TestDockerContainerCopyEmptyFileFromContainer(t *testing.T) {\n\tctx := context.Background()\n\n\tnginxC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage:        nginxImage,\n\t\t\tExposedPorts: []string{nginxDefaultPort},\n\t\t\tWaitingFor:   wait.ForListeningPort(nginxDefaultPort),\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, nginxC)\n\trequire.NoError(t, err)\n\n\tcopiedFileName := \"hello_copy.sh\"\n\t_ = nginxC.CopyFileToContainer(ctx, filepath.Join(\".\", \"testdata\", \"empty.sh\"), \"/\"+copiedFileName, 700)\n\tc, _, err := nginxC.Exec(ctx, []string{\"bash\", copiedFileName})\n\trequire.NoError(t, err)\n\trequire.Zerof(t, c, \"File %s should exist, expected return code 0, got %v\", copiedFileName, c)\n\n\treader, err := nginxC.CopyFileFromContainer(ctx, \"/\"+copiedFileName)\n\trequire.NoError(t, err)\n\tdefer reader.Close()\n\n\tfileContentFromContainer, err := io.ReadAll(reader)\n\trequire.NoError(t, err)\n\trequire.Empty(t, fileContentFromContainer)\n}\n\nfunc TestDockerContainerResources(t *testing.T) {\n\tif providerType == ProviderPodman {\n\t\tt.Skip(\"Rootless Podman does not support setting rlimit\")\n\t}\n\tif os.Getenv(\"XDG_RUNTIME_DIR\") != \"\" {\n\t\tt.Skip(\"Rootless Docker does not support setting rlimit\")\n\t}\n\n\tctx := context.Background()\n\n\texpected := []*container.Ulimit{\n\t\t{\n\t\t\tName: \"memlock\",\n\t\t\tHard: -1,\n\t\t\tSoft: -1,\n\t\t},\n\t\t{\n\t\t\tName: \"nofile\",\n\t\t\tHard: 65536,\n\t\t\tSoft: 65536,\n\t\t},\n\t}\n\n\tnginxC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage:        nginxAlpineImage,\n\t\t\tExposedPorts: []string{nginxDefaultPort},\n\t\t\tWaitingFor:   wait.ForListeningPort(nginxDefaultPort),\n\t\t\tHostConfigModifier: func(hc *container.HostConfig) {\n\t\t\t\thc.Resources = container.Resources{\n\t\t\t\t\tUlimits: expected,\n\t\t\t\t}\n\t\t\t},\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, nginxC)\n\trequire.NoError(t, err)\n\n\tc, err := NewDockerClientWithOpts(ctx)\n\trequire.NoError(t, err)\n\tdefer c.Close()\n\n\tcontainerID := nginxC.GetContainerID()\n\n\tresp, err := c.ContainerInspect(ctx, containerID)\n\trequire.NoError(t, err)\n\n\tassert.Equal(t, expected, resp.HostConfig.Ulimits)\n}\n\nfunc TestContainerCapAdd(t *testing.T) {\n\tif providerType == ProviderPodman {\n\t\tt.Skip(\"Rootless Podman does not support setting cap-add/cap-drop\")\n\t}\n\n\tctx := context.Background()\n\n\texpected := \"IPC_LOCK\"\n\n\tnginx, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage:        nginxAlpineImage,\n\t\t\tExposedPorts: []string{nginxDefaultPort},\n\t\t\tWaitingFor:   wait.ForListeningPort(nginxDefaultPort),\n\t\t\tHostConfigModifier: func(hc *container.HostConfig) {\n\t\t\t\thc.CapAdd = []string{expected}\n\t\t\t},\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, nginx)\n\trequire.NoError(t, err)\n\n\tdockerClient, err := NewDockerClientWithOpts(ctx)\n\trequire.NoError(t, err)\n\tdefer dockerClient.Close()\n\n\tcontainerID := nginx.GetContainerID()\n\tresp, err := dockerClient.ContainerInspect(ctx, containerID)\n\trequire.NoError(t, err)\n\n\tassert.Equal(t, strslice.StrSlice{expected}, resp.HostConfig.CapAdd)\n}\n\nfunc TestContainerRunningCheckingStatusCode(t *testing.T) {\n\tctx := context.Background()\n\treq := ContainerRequest{\n\t\tImage:         \"influxdb:1.8.10-alpine\",\n\t\tExposedPorts:  []string{\"8086/tcp\"},\n\t\tImagePlatform: \"linux/amd64\", // influxdb doesn't provide an alpine+arm build (https://github.com/influxdata/influxdata-docker/issues/335)\n\t\tWaitingFor: wait.ForAll(\n\t\t\twait.ForHTTP(\"/ping\").WithPort(\"8086/tcp\").WithStatusCodeMatcher(\n\t\t\t\tfunc(status int) bool {\n\t\t\t\t\treturn status == http.StatusNoContent\n\t\t\t\t},\n\t\t\t),\n\t\t),\n\t}\n\n\tinflux, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, influx)\n\trequire.NoError(t, err)\n}\n\nfunc TestContainerWithUserID(t *testing.T) {\n\tctx := context.Background()\n\treq := ContainerRequest{\n\t\tImage:      \"alpine:latest\",\n\t\tUser:       \"60125\",\n\t\tCmd:        []string{\"sh\", \"-c\", \"id -u\"},\n\t\tWaitingFor: wait.ForExit(),\n\t}\n\tctr, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType:     providerType,\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, ctr)\n\trequire.NoError(t, err)\n\n\tr, err := ctr.Logs(ctx)\n\trequire.NoError(t, err)\n\tdefer r.Close()\n\tb, err := io.ReadAll(r)\n\trequire.NoError(t, err)\n\tactual := regexp.MustCompile(`\\D+`).ReplaceAllString(string(b), \"\")\n\tassert.Equal(t, req.User, actual)\n}\n\nfunc TestContainerWithNoUserID(t *testing.T) {\n\tctx := context.Background()\n\treq := ContainerRequest{\n\t\tImage:      \"alpine:latest\",\n\t\tCmd:        []string{\"sh\", \"-c\", \"id -u\"},\n\t\tWaitingFor: wait.ForExit(),\n\t}\n\tctr, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType:     providerType,\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, ctr)\n\trequire.NoError(t, err)\n\n\tr, err := ctr.Logs(ctx)\n\trequire.NoError(t, err)\n\tdefer r.Close()\n\tb, err := io.ReadAll(r)\n\trequire.NoError(t, err)\n\tactual := regexp.MustCompile(`\\D+`).ReplaceAllString(string(b), \"\")\n\tassert.Equal(t, \"0\", actual)\n}\n\nfunc TestGetGatewayIP(t *testing.T) {\n\t// When using docker compose with DinD mode, and using host port or http wait strategy\n\t// It's need to invoke GetGatewayIP for get the host\n\tprovider, err := providerType.GetProvider(WithLogger(TestLogger(t)))\n\trequire.NoError(t, err)\n\tdefer provider.Close()\n\n\tdockerProvider, ok := provider.(*DockerProvider)\n\tif !ok {\n\t\tt.Skip(\"provider is not a DockerProvider\")\n\t}\n\n\tip, err := dockerProvider.GetGatewayIP(context.Background())\n\trequire.NoError(t, err)\n\trequire.NotEmpty(t, ip)\n}\n\nfunc TestNetworkModeWithContainerReference(t *testing.T) {\n\tctx := context.Background()\n\tnginxA, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage: nginxAlpineImage,\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, nginxA)\n\trequire.NoError(t, err)\n\n\tnetworkMode := fmt.Sprintf(\"container:%v\", nginxA.GetContainerID())\n\tnginxB, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage: nginxAlpineImage,\n\t\t\tHostConfigModifier: func(hc *container.HostConfig) {\n\t\t\t\thc.NetworkMode = container.NetworkMode(networkMode)\n\t\t\t},\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, nginxB)\n\trequire.NoError(t, err)\n}\n\n// creates a temporary dir in which the files will be extracted. Then it will compare the bytes of each file in the source with the bytes from the copied-from-container file\nfunc assertExtractedFiles(t *testing.T, ctx context.Context, container Container, hostFilePath string, containerFilePath string) {\n\tt.Helper()\n\t// create all copied files into a temporary dir\n\ttmpDir := t.TempDir()\n\n\t// compare the bytes of each file in the source with the bytes from the copied-from-container file\n\tsrcFiles, err := os.ReadDir(hostFilePath)\n\trequire.NoError(t, err)\n\n\tfor _, srcFile := range srcFiles {\n\t\tif srcFile.IsDir() {\n\t\t\tcontinue\n\t\t}\n\t\tsrcBytes, err := os.ReadFile(filepath.Join(hostFilePath, srcFile.Name()))\n\t\tif err != nil {\n\t\t\trequire.NoError(t, err)\n\t\t}\n\n\t\tfp := filepath.Join(containerFilePath, srcFile.Name())\n\t\t// copy file by file, as there is a limitation in the Docker client to copy an entiry directory from the container\n\t\t// paths for the container files are using Linux path separators\n\t\tfd, err := container.CopyFileFromContainer(ctx, fp)\n\t\trequire.NoError(t, err, \"Path not found in container: %s\", fp)\n\t\tdefer fd.Close()\n\n\t\ttargetPath := filepath.Join(tmpDir, srcFile.Name())\n\t\tdst, err := os.Create(targetPath)\n\t\tif err != nil {\n\t\t\trequire.NoError(t, err)\n\t\t}\n\t\tdefer dst.Close()\n\n\t\t_, err = io.Copy(dst, fd)\n\t\tif err != nil {\n\t\t\trequire.NoError(t, err)\n\t\t}\n\n\t\tuntarBytes, err := os.ReadFile(targetPath)\n\t\tif err != nil {\n\t\t\trequire.NoError(t, err)\n\t\t}\n\t\tassert.Equal(t, srcBytes, untarBytes)\n\t}\n}\n\nfunc TestDockerProviderFindContainerByName(t *testing.T) {\n\tctx := context.Background()\n\tprovider, err := NewDockerProvider(WithLogger(TestLogger(t)))\n\trequire.NoError(t, err)\n\tdefer provider.Close()\n\n\tc1, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tName:       \"test\",\n\t\t\tImage:      \"nginx:1.17.6\",\n\t\t\tWaitingFor: wait.ForExposedPort(),\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, c1)\n\trequire.NoError(t, err)\n\n\tc1Inspect, err := c1.Inspect(ctx)\n\trequire.NoError(t, err)\n\tCleanupContainer(t, c1)\n\n\tc1Name := c1Inspect.Name\n\n\tc2, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tName:       \"test2\",\n\t\t\tImage:      \"nginx:1.17.6\",\n\t\t\tWaitingFor: wait.ForExposedPort(),\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, c2)\n\trequire.NoError(t, err)\n\n\tc, err := provider.findContainerByName(ctx, \"test\")\n\trequire.NoError(t, err)\n\trequire.NotNil(t, c)\n\tassert.Contains(t, c.Names, c1Name)\n}\n\nfunc TestImageBuiltFromDockerfile_KeepBuiltImage(t *testing.T) {\n\ttests := []struct {\n\t\tkeepBuiltImage bool\n\t}{\n\t\t{keepBuiltImage: true},\n\t\t{keepBuiltImage: false},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(fmt.Sprintf(\"Keep built image: %t\", tt.keepBuiltImage), func(t *testing.T) {\n\t\t\tctx := context.Background()\n\t\t\t// Set up CLI.\n\t\t\tprovider, err := NewDockerProvider()\n\t\t\trequire.NoError(t, err, \"get docker provider should not fail\")\n\t\t\tdefer func() { _ = provider.Close() }()\n\t\t\tcli := provider.Client()\n\t\t\t// Create container.\n\t\t\tc, err := GenericContainer(ctx, GenericContainerRequest{\n\t\t\t\tProviderType: providerType,\n\t\t\t\tContainerRequest: ContainerRequest{\n\t\t\t\t\tFromDockerfile: FromDockerfile{\n\t\t\t\t\t\tContext:    \"testdata\",\n\t\t\t\t\t\tDockerfile: \"echo.Dockerfile\",\n\t\t\t\t\t\tKeepImage:  tt.keepBuiltImage,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t})\n\t\t\tCleanupContainer(t, c)\n\t\t\trequire.NoError(t, err, \"create container should not fail\")\n\t\t\t// Get the image ID.\n\t\t\tcontainerInspect, err := c.Inspect(ctx)\n\t\t\trequire.NoError(t, err, \"container inspect should not fail\")\n\n\t\t\tcontainerName := containerInspect.Name\n\t\t\tcontainerDetails, err := cli.ContainerInspect(ctx, containerName)\n\t\t\trequire.NoError(t, err, \"inspect container should not fail\")\n\t\t\tcontainerImage := containerDetails.Image\n\t\t\tt.Cleanup(func() {\n\t\t\t\t_, _ = cli.ImageRemove(ctx, containerImage, image.RemoveOptions{\n\t\t\t\t\tForce:         true,\n\t\t\t\t\tPruneChildren: true,\n\t\t\t\t})\n\t\t\t})\n\t\t\t// Now, we terminate the container and check whether the image still exists.\n\t\t\terr = c.Terminate(ctx)\n\t\t\trequire.NoError(t, err, \"terminate container should not fail\")\n\t\t\t_, _, err = cli.ImageInspectWithRaw(ctx, containerImage)\n\t\t\tif tt.keepBuiltImage {\n\t\t\t\trequire.NoError(t, err, \"image should still exist\")\n\t\t\t} else {\n\t\t\t\trequire.Error(t, err, \"image should not exist any more\")\n\t\t\t}\n\t\t})\n\t}\n}\n\n// errMockCli is a mock implementation of client.APIClient, which is handy for simulating\n// error returns in retry scenarios.\ntype errMockCli struct {\n\tclient.APIClient\n\n\terr                error\n\timageBuildCount    int\n\tcontainerListCount int\n\timagePullCount     int\n}\n\nfunc (f *errMockCli) ImageBuild(_ context.Context, _ io.Reader, _ types.ImageBuildOptions) (types.ImageBuildResponse, error) {\n\tf.imageBuildCount++\n\treturn types.ImageBuildResponse{Body: io.NopCloser(&bytes.Buffer{})}, f.err\n}\n\nfunc (f *errMockCli) ContainerList(_ context.Context, _ container.ListOptions) ([]types.Container, error) {\n\tf.containerListCount++\n\treturn []types.Container{{}}, f.err\n}\n\nfunc (f *errMockCli) ImagePull(_ context.Context, _ string, _ image.PullOptions) (io.ReadCloser, error) {\n\tf.imagePullCount++\n\treturn io.NopCloser(&bytes.Buffer{}), f.err\n}\n\nfunc (f *errMockCli) Close() error {\n\treturn nil\n}\n\nfunc TestDockerProvider_BuildImage_Retries(t *testing.T) {\n\ttests := []struct {\n\t\tname        string\n\t\terrReturned error\n\t\tshouldRetry bool\n\t}{\n\t\t{\n\t\t\tname:        \"no retry on success\",\n\t\t\terrReturned: nil,\n\t\t\tshouldRetry: false,\n\t\t},\n\t\t{\n\t\t\tname:        \"no retry when a resource is not found\",\n\t\t\terrReturned: errdefs.NotFound(errors.New(\"not available\")),\n\t\t\tshouldRetry: false,\n\t\t},\n\t\t{\n\t\t\tname:        \"no retry when parameters are invalid\",\n\t\t\terrReturned: errdefs.InvalidParameter(errors.New(\"invalid\")),\n\t\t\tshouldRetry: false,\n\t\t},\n\t\t{\n\t\t\tname:        \"no retry when resource access not authorized\",\n\t\t\terrReturned: errdefs.Unauthorized(errors.New(\"not authorized\")),\n\t\t\tshouldRetry: false,\n\t\t},\n\t\t{\n\t\t\tname:        \"no retry when resource access is forbidden\",\n\t\t\terrReturned: errdefs.Forbidden(errors.New(\"forbidden\")),\n\t\t\tshouldRetry: false,\n\t\t},\n\t\t{\n\t\t\tname:        \"no retry when not implemented by provider\",\n\t\t\terrReturned: errdefs.NotImplemented(errors.New(\"unknown method\")),\n\t\t\tshouldRetry: false,\n\t\t},\n\t\t{\n\t\t\tname:        \"no retry on system error\",\n\t\t\terrReturned: errdefs.System(errors.New(\"system error\")),\n\t\t\tshouldRetry: false,\n\t\t},\n\t\t{\n\t\t\tname:        \"retry on non-permanent error\",\n\t\t\terrReturned: errors.New(\"whoops\"),\n\t\t\tshouldRetry: true,\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tp, err := NewDockerProvider()\n\t\t\trequire.NoError(t, err)\n\t\t\tm := &errMockCli{err: tt.errReturned}\n\t\t\tp.client = m\n\n\t\t\t// give a chance to retry\n\t\t\tctx, cancel := context.WithTimeout(context.Background(), 1*time.Second)\n\t\t\tdefer cancel()\n\t\t\t_, err = p.BuildImage(ctx, &ContainerRequest{\n\t\t\t\tFromDockerfile: FromDockerfile{\n\t\t\t\t\tContext: filepath.Join(\".\", \"testdata\", \"retry\"),\n\t\t\t\t},\n\t\t\t})\n\t\t\tif tt.errReturned != nil {\n\t\t\t\trequire.Error(t, err)\n\t\t\t} else {\n\t\t\t\trequire.NoError(t, err)\n\t\t\t}\n\n\t\t\tassert.Positive(t, m.imageBuildCount)\n\t\t\tassert.Equal(t, tt.shouldRetry, m.imageBuildCount > 1)\n\t\t})\n\t}\n}\n\nfunc TestDockerProvider_waitContainerCreation_retries(t *testing.T) {\n\ttests := []struct {\n\t\tname        string\n\t\terrReturned error\n\t\tshouldRetry bool\n\t}{\n\t\t{\n\t\t\tname:        \"no retry on success\",\n\t\t\terrReturned: nil,\n\t\t\tshouldRetry: false,\n\t\t},\n\t\t{\n\t\t\tname:        \"no retry when parameters are invalid\",\n\t\t\terrReturned: errdefs.InvalidParameter(errors.New(\"invalid\")),\n\t\t\tshouldRetry: false,\n\t\t},\n\t\t{\n\t\t\tname:        \"no retry when not implemented by provider\",\n\t\t\terrReturned: errdefs.NotImplemented(errors.New(\"unknown method\")),\n\t\t\tshouldRetry: false,\n\t\t},\n\t\t{\n\t\t\tname:        \"retry when not found\",\n\t\t\terrReturned: errdefs.NotFound(errors.New(\"not there yet\")),\n\t\t\tshouldRetry: true,\n\t\t},\n\t\t{\n\t\t\tname:        \"retry on non-permanent error\",\n\t\t\terrReturned: errors.New(\"whoops\"),\n\t\t\tshouldRetry: true,\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tp, err := NewDockerProvider()\n\t\t\trequire.NoError(t, err)\n\t\t\tm := &errMockCli{err: tt.errReturned}\n\t\t\tp.client = m\n\n\t\t\t// give a chance to retry\n\t\t\tctx, cancel := context.WithTimeout(context.Background(), 1*time.Second)\n\t\t\tdefer cancel()\n\t\t\t_, _ = p.waitContainerCreation(ctx, \"someID\")\n\n\t\t\tassert.Positive(t, m.containerListCount)\n\t\t\tassert.Equal(t, tt.shouldRetry, m.containerListCount > 1)\n\t\t})\n\t}\n}\n\nfunc TestDockerProvider_attemptToPullImage_retries(t *testing.T) {\n\ttests := []struct {\n\t\tname        string\n\t\terrReturned error\n\t\tshouldRetry bool\n\t}{\n\t\t{\n\t\t\tname:        \"no retry on success\",\n\t\t\terrReturned: nil,\n\t\t\tshouldRetry: false,\n\t\t},\n\t\t{\n\t\t\tname:        \"no retry when a resource is not found\",\n\t\t\terrReturned: errdefs.NotFound(errors.New(\"not available\")),\n\t\t\tshouldRetry: false,\n\t\t},\n\t\t{\n\t\t\tname:        \"no retry when parameters are invalid\",\n\t\t\terrReturned: errdefs.InvalidParameter(errors.New(\"invalid\")),\n\t\t\tshouldRetry: false,\n\t\t},\n\t\t{\n\t\t\tname:        \"no retry when resource access not authorized\",\n\t\t\terrReturned: errdefs.Unauthorized(errors.New(\"not authorized\")),\n\t\t\tshouldRetry: false,\n\t\t},\n\t\t{\n\t\t\tname:        \"no retry when resource access is forbidden\",\n\t\t\terrReturned: errdefs.Forbidden(errors.New(\"forbidden\")),\n\t\t\tshouldRetry: false,\n\t\t},\n\t\t{\n\t\t\tname:        \"no retry when not implemented by provider\",\n\t\t\terrReturned: errdefs.NotImplemented(errors.New(\"unknown method\")),\n\t\t\tshouldRetry: false,\n\t\t},\n\t\t{\n\t\t\tname:        \"retry on non-permanent error\",\n\t\t\terrReturned: errors.New(\"whoops\"),\n\t\t\tshouldRetry: true,\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tp, err := NewDockerProvider()\n\t\t\trequire.NoError(t, err)\n\t\t\tm := &errMockCli{err: tt.errReturned}\n\t\t\tp.client = m\n\n\t\t\t// give a chance to retry\n\t\t\tctx, cancel := context.WithTimeout(context.Background(), 1*time.Second)\n\t\t\tdefer cancel()\n\t\t\t_ = p.attemptToPullImage(ctx, \"someTag\", image.PullOptions{})\n\n\t\t\tassert.Positive(t, m.imagePullCount)\n\t\t\tassert.Equal(t, tt.shouldRetry, m.imagePullCount > 1)\n\t\t})\n\t}\n}\n\nfunc TestCustomPrefixTrailingSlashIsProperlyRemovedIfPresent(t *testing.T) {\n\thubPrefixWithTrailingSlash := \"public.ecr.aws/\"\n\tdockerImage := \"amazonlinux/amazonlinux:2023\"\n\n\tctx := context.Background()\n\treq := ContainerRequest{\n\t\tImage:             dockerImage,\n\t\tImageSubstitutors: []ImageSubstitutor{newPrependHubRegistry(hubPrefixWithTrailingSlash)},\n\t}\n\n\tc, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, c)\n\trequire.NoError(t, err)\n\n\t// enforce the concrete type, as GenericContainer returns an interface,\n\t// which will be changed in future implementations of the library\n\tdockerContainer := c.(*DockerContainer)\n\trequire.Equal(t, fmt.Sprintf(\"%s%s\", hubPrefixWithTrailingSlash, dockerImage), dockerContainer.Image)\n}\n\n// TODO: remove this skip check when context rework is merged alongside [core.DockerEnvFile] removal.\nfunc Test_Provider_DaemonHost_Issue2897(t *testing.T) {\n\tctx := context.Background()\n\tprovider, err := NewDockerProvider()\n\trequire.NoError(t, err)\n\tt.Cleanup(func() {\n\t\trequire.NoError(t, provider.Close())\n\t})\n\n\torig := core.DockerEnvFile\n\tcore.DockerEnvFile = filepath.Join(t.TempDir(), \".dockerenv\")\n\tt.Cleanup(func() {\n\t\tcore.DockerEnvFile = orig\n\t})\n\n\tf, err := os.Create(core.DockerEnvFile)\n\trequire.NoError(t, err)\n\trequire.NoError(t, f.Close())\n\tt.Cleanup(func() {\n\t\trequire.NoError(t, os.Remove(f.Name()))\n\t})\n\n\terrCh := make(chan error, 1)\n\tgo func() {\n\t\t_, err := provider.DaemonHost(ctx)\n\t\terrCh <- err\n\t}()\n\n\tselect {\n\tcase <-time.After(1 * time.Second):\n\t\tt.Fatal(\"timeout waiting for DaemonHost\")\n\tcase err := <-errCh:\n\t\trequire.NoError(t, err)\n\t}\n}\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "exec",
          "type": "tree",
          "content": null
        },
        {
          "name": "file.go",
          "type": "blob",
          "size": 3.2490234375,
          "content": "package testcontainers\n\nimport (\n\t\"archive/tar\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n)\n\nfunc isDir(path string) (bool, error) {\n\tfile, err := os.Open(path)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\tdefer file.Close()\n\n\tfileInfo, err := file.Stat()\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tif fileInfo.IsDir() {\n\t\treturn true, nil\n\t}\n\n\treturn false, nil\n}\n\n// tarDir compress a directory using tar + gzip algorithms\nfunc tarDir(src string, fileMode int64) (*bytes.Buffer, error) {\n\t// always pass src as absolute path\n\tabs, err := filepath.Abs(src)\n\tif err != nil {\n\t\treturn &bytes.Buffer{}, fmt.Errorf(\"error getting absolute path: %w\", err)\n\t}\n\tsrc = abs\n\n\tbuffer := &bytes.Buffer{}\n\n\tLogger.Printf(\">> creating TAR file from directory: %s\\n\", src)\n\n\t// tar > gzip > buffer\n\tzr := gzip.NewWriter(buffer)\n\ttw := tar.NewWriter(zr)\n\n\t_, baseDir := filepath.Split(src)\n\t// keep the path relative to the parent directory\n\tindex := strings.LastIndex(src, baseDir)\n\n\t// walk through every file in the folder\n\terr = filepath.Walk(src, func(file string, fi os.FileInfo, errFn error) error {\n\t\tif errFn != nil {\n\t\t\treturn fmt.Errorf(\"error traversing the file system: %w\", errFn)\n\t\t}\n\n\t\t// if a symlink, skip file\n\t\tif fi.Mode().Type() == os.ModeSymlink {\n\t\t\tLogger.Printf(\">> skipping symlink: %s\\n\", file)\n\t\t\treturn nil\n\t\t}\n\n\t\t// generate tar header\n\t\theader, err := tar.FileInfoHeader(fi, file)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"error getting file info header: %w\", err)\n\t\t}\n\n\t\t// see https://pkg.go.dev/archive/tar#FileInfoHeader:\n\t\t// Since fs.FileInfo's Name method only returns the base name of the file it describes,\n\t\t// it may be necessary to modify Header.Name to provide the full path name of the file.\n\t\theader.Name = filepath.ToSlash(file[index:])\n\t\theader.Mode = fileMode\n\n\t\t// write header\n\t\tif err := tw.WriteHeader(header); err != nil {\n\t\t\treturn fmt.Errorf(\"error writing header: %w\", err)\n\t\t}\n\n\t\t// if not a dir, write file content\n\t\tif !fi.IsDir() {\n\t\t\tdata, err := os.Open(file)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"error opening file: %w\", err)\n\t\t\t}\n\t\t\tdefer data.Close()\n\t\t\tif _, err := io.Copy(tw, data); err != nil {\n\t\t\t\treturn fmt.Errorf(\"error compressing file: %w\", err)\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn buffer, err\n\t}\n\n\t// produce tar\n\tif err := tw.Close(); err != nil {\n\t\treturn buffer, fmt.Errorf(\"error closing tar file: %w\", err)\n\t}\n\t// produce gzip\n\tif err := zr.Close(); err != nil {\n\t\treturn buffer, fmt.Errorf(\"error closing gzip file: %w\", err)\n\t}\n\n\treturn buffer, nil\n}\n\n// tarFile compress a single file using tar + gzip algorithms\nfunc tarFile(basePath string, fileContent func(tw io.Writer) error, fileContentSize int64, fileMode int64) (*bytes.Buffer, error) {\n\tbuffer := &bytes.Buffer{}\n\n\tzr := gzip.NewWriter(buffer)\n\ttw := tar.NewWriter(zr)\n\n\thdr := &tar.Header{\n\t\tName: basePath,\n\t\tMode: fileMode,\n\t\tSize: fileContentSize,\n\t}\n\tif err := tw.WriteHeader(hdr); err != nil {\n\t\treturn buffer, err\n\t}\n\tif err := fileContent(tw); err != nil {\n\t\treturn buffer, err\n\t}\n\n\t// produce tar\n\tif err := tw.Close(); err != nil {\n\t\treturn buffer, fmt.Errorf(\"error closing tar file: %w\", err)\n\t}\n\t// produce gzip\n\tif err := zr.Close(); err != nil {\n\t\treturn buffer, fmt.Errorf(\"error closing gzip file: %w\", err)\n\t}\n\n\treturn buffer, nil\n}\n"
        },
        {
          "name": "file_test.go",
          "type": "blob",
          "size": 4.048828125,
          "content": "// This test is testing very internal logic that should not be exported away from this package. We'll\n// leave it in the main testcontainers package. Do not use for user facing examples.\npackage testcontainers\n\nimport (\n\t\"archive/tar\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc Test_IsDir(t *testing.T) {\n\ttype cases struct {\n\t\tfilepath string\n\t\texpected bool\n\t\terr      error\n\t}\n\n\ttests := []cases{\n\t\t{\n\t\t\tfilepath: \"testdata\",\n\t\t\texpected: true,\n\t\t\terr:      nil,\n\t\t},\n\t\t{\n\t\t\tfilepath: \"docker.go\",\n\t\t\texpected: false,\n\t\t\terr:      nil,\n\t\t},\n\t\t{\n\t\t\tfilepath: \"foobar.doc\",\n\t\t\texpected: false,\n\t\t\terr:      errors.New(\"does not exist\"),\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tt.Run(test.filepath, func(t *testing.T) {\n\t\t\tresult, err := isDir(test.filepath)\n\t\t\tif test.err != nil {\n\t\t\t\trequire.Error(t, err, \"expected error\")\n\t\t\t} else {\n\t\t\t\trequire.NoError(t, err, \"not expected error\")\n\t\t\t}\n\t\t\tassert.Equal(t, test.expected, result)\n\t\t})\n\t}\n}\n\nfunc Test_TarDir(t *testing.T) {\n\toriginalSrc := filepath.Join(\".\", \"testdata\")\n\ttests := []struct {\n\t\tabs bool\n\t}{\n\t\t{\n\t\t\tabs: false,\n\t\t},\n\t\t{\n\t\t\tabs: true,\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tt.Run(fmt.Sprintf(\"TarDir with abs=%t\", test.abs), func(t *testing.T) {\n\t\t\tsrc := originalSrc\n\t\t\tif test.abs {\n\t\t\t\tabsSrc, err := filepath.Abs(src)\n\t\t\t\trequire.NoError(t, err)\n\n\t\t\t\tsrc = absSrc\n\t\t\t}\n\n\t\t\tbuff, err := tarDir(src, 0o755)\n\t\t\trequire.NoError(t, err)\n\n\t\t\ttmpDir := filepath.Join(t.TempDir(), \"subfolder\")\n\t\t\terr = untar(tmpDir, bytes.NewReader(buff.Bytes()))\n\t\t\trequire.NoError(t, err)\n\n\t\t\tsrcFiles, err := os.ReadDir(src)\n\t\t\trequire.NoError(t, err)\n\n\t\t\tfor _, srcFile := range srcFiles {\n\t\t\t\tif srcFile.IsDir() {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tsrcBytes, err := os.ReadFile(filepath.Join(src, srcFile.Name()))\n\t\t\t\trequire.NoError(t, err)\n\n\t\t\t\tuntarBytes, err := os.ReadFile(filepath.Join(tmpDir, \"testdata\", srcFile.Name()))\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\tassert.Equal(t, srcBytes, untarBytes)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc Test_TarFile(t *testing.T) {\n\tb, err := os.ReadFile(filepath.Join(\".\", \"testdata\", \"Dockerfile\"))\n\trequire.NoError(t, err)\n\n\tbuff, err := tarFile(\"Docker.file\", func(tw io.Writer) error {\n\t\t_, err := tw.Write(b)\n\t\treturn err\n\t}, int64(len(b)), 0o755)\n\trequire.NoError(t, err)\n\n\ttmpDir := t.TempDir()\n\terr = untar(tmpDir, bytes.NewReader(buff.Bytes()))\n\trequire.NoError(t, err)\n\n\tuntarBytes, err := os.ReadFile(filepath.Join(tmpDir, \"Docker.file\"))\n\trequire.NoError(t, err)\n\tassert.Equal(t, b, untarBytes)\n}\n\n// untar takes a destination path and a reader; a tar reader loops over the tarfile\n// creating the file structure at 'dst' along the way, and writing any files\nfunc untar(dst string, r io.Reader) error {\n\tgzr, err := gzip.NewReader(r)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer gzr.Close()\n\n\ttr := tar.NewReader(gzr)\n\n\tfor {\n\t\theader, err := tr.Next()\n\n\t\tswitch {\n\n\t\t// if no more files are found return\n\t\tcase err == io.EOF:\n\t\t\treturn nil\n\n\t\t// return any other error\n\t\tcase err != nil:\n\t\t\treturn err\n\n\t\t// if the header is nil, just skip it (not sure how this happens)\n\t\tcase header == nil:\n\t\t\tcontinue\n\t\t}\n\n\t\t// the target location where the dir/file should be created\n\t\ttarget := filepath.Join(dst, header.Name)\n\n\t\t// the following switch could also be done using fi.Mode(), not sure if there\n\t\t// a benefit of using one vs. the other.\n\t\t// fi := header.FileInfo()\n\n\t\t// check the file type\n\t\tswitch header.Typeflag {\n\n\t\t// if its a dir and it doesn't exist create it\n\t\tcase tar.TypeDir:\n\t\t\tif _, err := os.Stat(target); err != nil {\n\t\t\t\tif err := os.MkdirAll(target, 0o755); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\n\t\t// if it's a file create it\n\t\tcase tar.TypeReg:\n\t\t\tf, err := os.OpenFile(target, os.O_CREATE|os.O_RDWR, os.FileMode(header.Mode))\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// copy over contents\n\t\t\tif _, err := io.Copy(f, tr); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// manually close here after each file operation; defering would cause each file close\n\t\t\t// to wait until all operations have completed.\n\t\t\tf.Close()\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "from_dockerfile_test.go",
          "type": "blob",
          "size": 5.34765625,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/docker/docker/api/types\"\n\t\"github.com/docker/docker/api/types/image\"\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc TestBuildImageFromDockerfile(t *testing.T) {\n\tprovider, err := NewDockerProvider()\n\trequire.NoError(t, err)\n\tdefer provider.Close()\n\n\tcli := provider.Client()\n\n\tctx := context.Background()\n\n\ttag, err := provider.BuildImage(ctx, &ContainerRequest{\n\t\t// fromDockerfileIncludingRepo {\n\t\tFromDockerfile: FromDockerfile{\n\t\t\tContext:    \"testdata\",\n\t\t\tDockerfile: \"echo.Dockerfile\",\n\t\t\tRepo:       \"test-repo\",\n\t\t\tTag:        \"test-tag\",\n\t\t},\n\t\t// }\n\t})\n\trequire.NoError(t, err)\n\trequire.Equal(t, \"test-repo:test-tag\", tag)\n\n\t_, _, err = cli.ImageInspectWithRaw(ctx, tag)\n\trequire.NoError(t, err)\n\n\tt.Cleanup(func() {\n\t\t_, err := cli.ImageRemove(ctx, tag, image.RemoveOptions{\n\t\t\tForce:         true,\n\t\t\tPruneChildren: true,\n\t\t})\n\t\trequire.NoError(t, err)\n\t})\n}\n\nfunc TestBuildImageFromDockerfile_NoRepo(t *testing.T) {\n\tprovider, err := NewDockerProvider()\n\trequire.NoError(t, err)\n\tdefer provider.Close()\n\n\tcli := provider.Client()\n\n\tctx := context.Background()\n\n\ttag, err := provider.BuildImage(ctx, &ContainerRequest{\n\t\tFromDockerfile: FromDockerfile{\n\t\t\tContext:    \"testdata\",\n\t\t\tDockerfile: \"echo.Dockerfile\",\n\t\t\tRepo:       \"test-repo\",\n\t\t},\n\t})\n\trequire.NoError(t, err)\n\trequire.True(t, strings.HasPrefix(tag, \"test-repo:\"))\n\n\t_, _, err = cli.ImageInspectWithRaw(ctx, tag)\n\trequire.NoError(t, err)\n\n\tt.Cleanup(func() {\n\t\t_, err := cli.ImageRemove(ctx, tag, image.RemoveOptions{\n\t\t\tForce:         true,\n\t\t\tPruneChildren: true,\n\t\t})\n\t\trequire.NoError(t, err)\n\t})\n}\n\nfunc TestBuildImageFromDockerfile_BuildError(t *testing.T) {\n\tctx := context.Background()\n\tdockerClient, err := NewDockerClientWithOpts(ctx)\n\trequire.NoError(t, err)\n\n\tdefer dockerClient.Close()\n\n\treq := ContainerRequest{\n\t\tFromDockerfile: FromDockerfile{\n\t\t\tDockerfile: \"error.Dockerfile\",\n\t\t\tContext:    filepath.Join(\".\", \"testdata\"),\n\t\t},\n\t}\n\tctr, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType:     providerType,\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, ctr)\n\trequire.EqualError(t, err, `create container: build image: The command '/bin/sh -c exit 1' returned a non-zero code: 1`)\n}\n\nfunc TestBuildImageFromDockerfile_NoTag(t *testing.T) {\n\tprovider, err := NewDockerProvider()\n\trequire.NoError(t, err)\n\tdefer provider.Close()\n\n\tcli := provider.Client()\n\n\tctx := context.Background()\n\n\ttag, err := provider.BuildImage(ctx, &ContainerRequest{\n\t\tFromDockerfile: FromDockerfile{\n\t\t\tContext:    \"testdata\",\n\t\t\tDockerfile: \"echo.Dockerfile\",\n\t\t\tTag:        \"test-tag\",\n\t\t},\n\t})\n\trequire.NoError(t, err)\n\trequire.True(t, strings.HasSuffix(tag, \":test-tag\"))\n\n\t_, _, err = cli.ImageInspectWithRaw(ctx, tag)\n\trequire.NoError(t, err)\n\n\tt.Cleanup(func() {\n\t\t_, err := cli.ImageRemove(ctx, tag, image.RemoveOptions{\n\t\t\tForce:         true,\n\t\t\tPruneChildren: true,\n\t\t})\n\t\trequire.NoError(t, err)\n\t})\n}\n\nfunc TestBuildImageFromDockerfile_Target(t *testing.T) {\n\t// there are thre targets: target0, target1 and target2.\n\tfor i := 0; i < 3; i++ {\n\t\tctx := context.Background()\n\t\tc, err := GenericContainer(ctx, GenericContainerRequest{\n\t\t\tContainerRequest: ContainerRequest{\n\t\t\t\tFromDockerfile: FromDockerfile{\n\t\t\t\t\tContext:    \"testdata\",\n\t\t\t\t\tDockerfile: \"target.Dockerfile\",\n\t\t\t\t\tKeepImage:  false,\n\t\t\t\t\tBuildOptionsModifier: func(buildOptions *types.ImageBuildOptions) {\n\t\t\t\t\t\tbuildOptions.Target = fmt.Sprintf(\"target%d\", i)\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tStarted: true,\n\t\t})\n\t\tCleanupContainer(t, c)\n\t\trequire.NoError(t, err)\n\n\t\tr, err := c.Logs(ctx)\n\t\trequire.NoError(t, err)\n\n\t\tlogs, err := io.ReadAll(r)\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, fmt.Sprintf(\"target%d\\n\\n\", i), string(logs))\n\t}\n}\n\nfunc ExampleGenericContainer_buildFromDockerfile() {\n\tctx := context.Background()\n\n\t// buildFromDockerfileWithModifier {\n\tc, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tContainerRequest: ContainerRequest{\n\t\t\tFromDockerfile: FromDockerfile{\n\t\t\t\tContext:    \"testdata\",\n\t\t\t\tDockerfile: \"target.Dockerfile\",\n\t\t\t\tKeepImage:  false,\n\t\t\t\tBuildOptionsModifier: func(buildOptions *types.ImageBuildOptions) {\n\t\t\t\t\tbuildOptions.Target = \"target2\"\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tStarted: true,\n\t})\n\t// }\n\tdefer func() {\n\t\tif err := TerminateContainer(c); err != nil {\n\t\t\tlog.Printf(\"failed to terminate container: %s\", err)\n\t\t}\n\t}()\n\tif err != nil {\n\t\tlog.Printf(\"failed to start container: %v\", err)\n\t\treturn\n\t}\n\n\tr, err := c.Logs(ctx)\n\tif err != nil {\n\t\tlog.Printf(\"failed to get logs: %v\", err)\n\t\treturn\n\t}\n\n\tlogs, err := io.ReadAll(r)\n\tif err != nil {\n\t\tlog.Printf(\"failed to read logs: %v\", err)\n\t\treturn\n\t}\n\n\tfmt.Println(string(logs))\n\n\t// Output: target2\n}\n\nfunc TestBuildImageFromDockerfile_TargetDoesNotExist(t *testing.T) {\n\t// the context cancellation will happen with enough time for the build to fail.\n\tctx, cancel := context.WithTimeout(context.Background(), 3*time.Second)\n\tdefer cancel()\n\n\tctr, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tContainerRequest: ContainerRequest{\n\t\t\tFromDockerfile: FromDockerfile{\n\t\t\t\tContext:    \"testdata\",\n\t\t\t\tDockerfile: \"target.Dockerfile\",\n\t\t\t\tKeepImage:  false,\n\t\t\t\tBuildOptionsModifier: func(buildOptions *types.ImageBuildOptions) {\n\t\t\t\t\tbuildOptions.Target = \"target-foo\"\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, ctr)\n\trequire.Error(t, err)\n}\n"
        },
        {
          "name": "generate.go",
          "type": "blob",
          "size": 0.044921875,
          "content": "package testcontainers\n\n//go:generate mockery\n"
        },
        {
          "name": "generic.go",
          "type": "blob",
          "size": 3.57421875,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"strings\"\n\t\"sync\"\n\n\t\"github.com/testcontainers/testcontainers-go/internal/core\"\n)\n\nvar (\n\treuseContainerMx  sync.Mutex\n\tErrReuseEmptyName = errors.New(\"with reuse option a container name mustn't be empty\")\n)\n\n// GenericContainerRequest represents parameters to a generic container\ntype GenericContainerRequest struct {\n\tContainerRequest              // embedded request for provider\n\tStarted          bool         // whether to auto-start the container\n\tProviderType     ProviderType // which provider to use, Docker if empty\n\tLogger           Logging      // provide a container specific Logging - use default global logger if empty\n\tReuse            bool         // reuse an existing container if it exists or create a new one. a container name mustn't be empty\n}\n\n// Deprecated: will be removed in the future.\n// GenericNetworkRequest represents parameters to a generic network\ntype GenericNetworkRequest struct {\n\tNetworkRequest              // embedded request for provider\n\tProviderType   ProviderType // which provider to use, Docker if empty\n}\n\n// Deprecated: use network.New instead\n// GenericNetwork creates a generic network with parameters\nfunc GenericNetwork(ctx context.Context, req GenericNetworkRequest) (Network, error) {\n\tprovider, err := req.ProviderType.GetProvider()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnetwork, err := provider.CreateNetwork(ctx, req.NetworkRequest)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"%w: failed to create network\", err)\n\t}\n\n\treturn network, nil\n}\n\n// GenericContainer creates a generic container with parameters\nfunc GenericContainer(ctx context.Context, req GenericContainerRequest) (Container, error) {\n\tif req.Reuse && req.Name == \"\" {\n\t\treturn nil, ErrReuseEmptyName\n\t}\n\n\tlogging := req.Logger\n\tif logging == nil {\n\t\tlogging = Logger\n\t}\n\tprovider, err := req.ProviderType.GetProvider(WithLogger(logging))\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"get provider: %w\", err)\n\t}\n\tdefer provider.Close()\n\n\tvar c Container\n\tif req.Reuse {\n\t\t// we must protect the reusability of the container in the case it's invoked\n\t\t// in a parallel execution, via ParallelContainers or t.Parallel()\n\t\treuseContainerMx.Lock()\n\t\tdefer reuseContainerMx.Unlock()\n\n\t\tc, err = provider.ReuseOrCreateContainer(ctx, req.ContainerRequest)\n\t} else {\n\t\tc, err = provider.CreateContainer(ctx, req.ContainerRequest)\n\t}\n\tif err != nil {\n\t\t// At this point `c` might not be nil. Give the caller an opportunity to call Destroy on the container.\n\t\t// TODO: Remove this debugging.\n\t\tif strings.Contains(err.Error(), \"toomanyrequests\") {\n\t\t\t// Debugging information for rate limiting.\n\t\t\tcfg, err := getDockerConfig()\n\t\t\tif err == nil {\n\t\t\t\tfmt.Printf(\"XXX: too many requests: %+v\", cfg)\n\t\t\t}\n\t\t}\n\t\treturn c, fmt.Errorf(\"create container: %w\", err)\n\t}\n\n\tif req.Started && !c.IsRunning() {\n\t\tif err := c.Start(ctx); err != nil {\n\t\t\treturn c, fmt.Errorf(\"start container: %w\", err)\n\t\t}\n\t}\n\treturn c, nil\n}\n\n// GenericProvider represents an abstraction for container and network providers\ntype GenericProvider interface {\n\tContainerProvider\n\tNetworkProvider\n\tImageProvider\n}\n\n// GenericLabels returns a map of labels that can be used to identify resources\n// created by this library. This includes the standard LabelSessionID if the\n// reaper is enabled, otherwise this is excluded to prevent resources being\n// incorrectly reaped.\nfunc GenericLabels() map[string]string {\n\treturn core.DefaultLabels(core.SessionID())\n}\n\n// AddGenericLabels adds the generic labels to target.\nfunc AddGenericLabels(target map[string]string) {\n\tfor k, v := range GenericLabels() {\n\t\ttarget[k] = v\n\t}\n}\n"
        },
        {
          "name": "generic_test.go",
          "type": "blob",
          "size": 5.322265625,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"os\"\n\t\"os/exec\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/docker/docker/api/types/container\"\n\t\"github.com/docker/docker/api/types/filters\"\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/testcontainers/testcontainers-go/wait\"\n)\n\nconst (\n\treusableContainerName = \"my_test_reusable_container\"\n)\n\nfunc TestGenericReusableContainer(t *testing.T) {\n\tctx := context.Background()\n\n\treusableContainerName := reusableContainerName + \"_\" + time.Now().Format(\"20060102150405\")\n\n\tn1, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage:        nginxAlpineImage,\n\t\t\tExposedPorts: []string{nginxDefaultPort},\n\t\t\tWaitingFor:   wait.ForListeningPort(nginxDefaultPort),\n\t\t\tName:         reusableContainerName,\n\t\t},\n\t\tStarted: true,\n\t})\n\trequire.NoError(t, err)\n\trequire.True(t, n1.IsRunning())\n\tCleanupContainer(t, n1)\n\n\tcopiedFileName := \"hello_copy.sh\"\n\terr = n1.CopyFileToContainer(ctx, \"./testdata/hello.sh\", \"/\"+copiedFileName, 700)\n\trequire.NoError(t, err)\n\n\ttests := []struct {\n\t\tname          string\n\t\tcontainerName string\n\t\terrorMatcher  func(err error) error\n\t\treuseOption   bool\n\t}{\n\t\t{\n\t\t\tname: \"reuse option with empty name\",\n\t\t\terrorMatcher: func(err error) error {\n\t\t\t\tif errors.Is(err, ErrReuseEmptyName) {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t\treturn err\n\t\t\t},\n\t\t\treuseOption: true,\n\t\t},\n\t\t{\n\t\t\tname:          \"container already exists (reuse=false)\",\n\t\t\tcontainerName: reusableContainerName,\n\t\t\terrorMatcher: func(err error) error {\n\t\t\t\tif err == nil {\n\t\t\t\t\treturn errors.New(\"expected error but got none\")\n\t\t\t\t}\n\t\t\t\treturn nil\n\t\t\t},\n\t\t\treuseOption: false,\n\t\t},\n\t\t{\n\t\t\tname:          \"success reusing\",\n\t\t\tcontainerName: reusableContainerName,\n\t\t\treuseOption:   true,\n\t\t\terrorMatcher: func(err error) error {\n\t\t\t\treturn err\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tn2, err := GenericContainer(ctx, GenericContainerRequest{\n\t\t\t\tProviderType: providerType,\n\t\t\t\tContainerRequest: ContainerRequest{\n\t\t\t\t\tImage:        nginxAlpineImage,\n\t\t\t\t\tExposedPorts: []string{nginxDefaultPort},\n\t\t\t\t\tWaitingFor:   wait.ForListeningPort(nginxDefaultPort),\n\t\t\t\t\tName:         tc.containerName,\n\t\t\t\t},\n\t\t\t\tStarted: true,\n\t\t\t\tReuse:   tc.reuseOption,\n\t\t\t})\n\n\t\t\trequire.NoError(t, tc.errorMatcher(err))\n\n\t\t\tif err == nil {\n\t\t\t\tc, _, err := n2.Exec(ctx, []string{\"/bin/ash\", copiedFileName})\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.Zero(t, c)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestGenericContainerShouldReturnRefOnError(t *testing.T) {\n\t// In this test, we are going to cancel the context to exit the `wait.Strategy`.\n\t// We want to make sure that the GenericContainer call will still return a reference to the\n\t// created container, so that we can Destroy it.\n\tctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)\n\tdefer cancel()\n\n\tc, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage:      nginxAlpineImage,\n\t\t\tWaitingFor: wait.ForLog(\"this string should not be present in the logs\"),\n\t\t},\n\t\tStarted: true,\n\t})\n\trequire.Error(t, err)\n\trequire.NotNil(t, c)\n\tCleanupContainer(t, c)\n}\n\nfunc TestGenericReusableContainerInSubprocess(t *testing.T) {\n\twg := sync.WaitGroup{}\n\twg.Add(10)\n\tfor i := 0; i < 10; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\n\t\t\t// create containers in subprocesses, as \"go test ./...\" does.\n\t\t\toutput := createReuseContainerInSubprocess(t)\n\n\t\t\tt.Log(output)\n\t\t\t// check is reuse container with WaitingFor work correctly.\n\t\t\trequire.Contains(t, output, \"⏳ Waiting for container id\")\n\t\t\trequire.Contains(t, output, \"🔔 Container is ready\")\n\t\t}()\n\t}\n\n\twg.Wait()\n\n\tcli, err := NewDockerClientWithOpts(context.Background())\n\trequire.NoError(t, err)\n\n\tf := filters.NewArgs(filters.KeyValuePair{Key: \"name\", Value: reusableContainerName})\n\n\tctrs, err := cli.ContainerList(context.Background(), container.ListOptions{\n\t\tAll:     true,\n\t\tFilters: f,\n\t})\n\trequire.NoError(t, err)\n\trequire.Len(t, ctrs, 1)\n\n\tprovider, err := NewDockerProvider()\n\trequire.NoError(t, err)\n\n\tprovider.SetClient(cli)\n\n\tnginxC, err := provider.ContainerFromType(context.Background(), ctrs[0])\n\tCleanupContainer(t, nginxC)\n\trequire.NoError(t, err)\n}\n\nfunc createReuseContainerInSubprocess(t *testing.T) string {\n\tt.Helper()\n\t// force verbosity in subprocesses, so that the output is printed\n\tcmd := exec.Command(os.Args[0], \"-test.run=TestHelperContainerStarterProcess\", \"-test.v=true\")\n\tcmd.Env = append(os.Environ(), \"GO_WANT_HELPER_PROCESS=1\")\n\n\toutput, err := cmd.CombinedOutput()\n\trequire.NoError(t, err, string(output))\n\n\treturn string(output)\n}\n\n// TestHelperContainerStarterProcess is a helper function\n// to start a container in a subprocess. It's not a real test.\nfunc TestHelperContainerStarterProcess(t *testing.T) {\n\tif os.Getenv(\"GO_WANT_HELPER_PROCESS\") != \"1\" {\n\t\tt.Skip(\"Skipping helper test function. It's not a real test\")\n\t}\n\n\tctx := context.Background()\n\n\tnginxC, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage:        nginxDelayedImage,\n\t\t\tExposedPorts: []string{nginxDefaultPort},\n\t\t\tWaitingFor:   wait.ForListeningPort(nginxDefaultPort), // default startupTimeout is 60s\n\t\t\tName:         reusableContainerName,\n\t\t},\n\t\tStarted: true,\n\t\tReuse:   true,\n\t})\n\trequire.NoError(t, err)\n\trequire.True(t, nginxC.IsRunning())\n}\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 2.5205078125,
          "content": "module github.com/testcontainers/testcontainers-go\n\ngo 1.22\n\nrequire (\n\tdario.cat/mergo v1.0.0\n\tgithub.com/cenkalti/backoff/v4 v4.2.1\n\tgithub.com/containerd/platforms v0.2.1\n\tgithub.com/cpuguy83/dockercfg v0.3.2\n\tgithub.com/docker/docker v27.1.1+incompatible\n\tgithub.com/docker/go-connections v0.5.0\n\tgithub.com/google/uuid v1.6.0\n\tgithub.com/magiconair/properties v1.8.7\n\tgithub.com/moby/patternmatcher v0.6.0\n\tgithub.com/moby/term v0.5.0\n\tgithub.com/opencontainers/image-spec v1.1.0\n\tgithub.com/shirou/gopsutil/v3 v3.23.12\n\tgithub.com/stretchr/testify v1.9.0\n\tgolang.org/x/crypto v0.31.0\n\tgolang.org/x/sys v0.28.0\n)\n\nrequire (\n\tgithub.com/Azure/go-ansiterm v0.0.0-20210617225240-d185dfc1b5a1 // indirect\n\tgithub.com/Microsoft/go-winio v0.6.2 // indirect\n\tgithub.com/containerd/containerd v1.7.18 // indirect\n\tgithub.com/containerd/log v0.1.0 // indirect\n\tgithub.com/davecgh/go-spew v1.1.1 // indirect\n\tgithub.com/distribution/reference v0.6.0 // indirect\n\tgithub.com/docker/go-units v0.5.0 // indirect\n\tgithub.com/felixge/httpsnoop v1.0.4 // indirect\n\tgithub.com/go-logr/logr v1.4.1 // indirect\n\tgithub.com/go-logr/stdr v1.2.2 // indirect\n\tgithub.com/go-ole/go-ole v1.2.6 // indirect\n\tgithub.com/gogo/protobuf v1.3.2 // indirect\n\tgithub.com/klauspost/compress v1.17.4 // indirect\n\tgithub.com/kr/pretty v0.3.0 // indirect\n\tgithub.com/lufia/plan9stats v0.0.0-20211012122336-39d0f177ccd0 // indirect\n\tgithub.com/moby/docker-image-spec v1.3.1 // indirect\n\tgithub.com/moby/sys/sequential v0.5.0 // indirect\n\tgithub.com/moby/sys/user v0.1.0 // indirect\n\tgithub.com/morikuni/aec v1.0.0 // indirect\n\tgithub.com/opencontainers/go-digest v1.0.0 // indirect\n\tgithub.com/pkg/errors v0.9.1 // indirect\n\tgithub.com/pmezard/go-difflib v1.0.0 // indirect\n\tgithub.com/power-devops/perfstat v0.0.0-20210106213030-5aafc221ea8c // indirect\n\tgithub.com/rogpeppe/go-internal v1.8.1 // indirect\n\tgithub.com/shoenig/go-m1cpu v0.1.6 // indirect\n\tgithub.com/sirupsen/logrus v1.9.3 // indirect\n\tgithub.com/stretchr/objx v0.5.2 // indirect\n\tgithub.com/tklauser/go-sysconf v0.3.12 // indirect\n\tgithub.com/tklauser/numcpus v0.6.1 // indirect\n\tgithub.com/yusufpapurcu/wmi v1.2.3 // indirect\n\tgo.opentelemetry.io/contrib/instrumentation/net/http/otelhttp v0.49.0 // indirect\n\tgo.opentelemetry.io/otel v1.24.0 // indirect\n\tgo.opentelemetry.io/otel/metric v1.24.0 // indirect\n\tgo.opentelemetry.io/otel/trace v1.24.0 // indirect\n\tgoogle.golang.org/grpc v1.64.1 // indirect\n\tgopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c // indirect\n\tgopkg.in/yaml.v3 v3.0.1 // indirect\n\tgotest.tools/v3 v3.5.1 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 17.9990234375,
          "content": "dario.cat/mergo v1.0.0 h1:AGCNq9Evsj31mOgNPcLyXc+4PNABt905YmuqPYYpBWk=\ndario.cat/mergo v1.0.0/go.mod h1:uNxQE+84aUszobStD9th8a29P2fMDhsBdgRYvZOxGmk=\ngithub.com/AdaLogics/go-fuzz-headers v0.0.0-20230811130428-ced1acdcaa24 h1:bvDV9vkmnHYOMsOr4WLk+Vo07yKIzd94sVoIqshQ4bU=\ngithub.com/AdaLogics/go-fuzz-headers v0.0.0-20230811130428-ced1acdcaa24/go.mod h1:8o94RPi1/7XTJvwPpRSzSUedZrtlirdB3r9Z20bi2f8=\ngithub.com/Azure/go-ansiterm v0.0.0-20210617225240-d185dfc1b5a1 h1:UQHMgLO+TxOElx5B5HZ4hJQsoJ/PvUvKRhJHDQXO8P8=\ngithub.com/Azure/go-ansiterm v0.0.0-20210617225240-d185dfc1b5a1/go.mod h1:xomTg63KZ2rFqZQzSB4Vz2SUXa1BpHTVz9L5PTmPC4E=\ngithub.com/Microsoft/go-winio v0.6.2 h1:F2VQgta7ecxGYO8k3ZZz3RS8fVIXVxONVUPlNERoyfY=\ngithub.com/Microsoft/go-winio v0.6.2/go.mod h1:yd8OoFMLzJbo9gZq8j5qaps8bJ9aShtEA8Ipt1oGCvU=\ngithub.com/cenkalti/backoff/v4 v4.2.1 h1:y4OZtCnogmCPw98Zjyt5a6+QwPLGkiQsYW5oUqylYbM=\ngithub.com/cenkalti/backoff/v4 v4.2.1/go.mod h1:Y3VNntkOUPxTVeUxJ/G5vcM//AlwfmyYozVcomhLiZE=\ngithub.com/containerd/containerd v1.7.18 h1:jqjZTQNfXGoEaZdW1WwPU0RqSn1Bm2Ay/KJPUuO8nao=\ngithub.com/containerd/containerd v1.7.18/go.mod h1:IYEk9/IO6wAPUz2bCMVUbsfXjzw5UNP5fLz4PsUygQ4=\ngithub.com/containerd/log v0.1.0 h1:TCJt7ioM2cr/tfR8GPbGf9/VRAX8D2B4PjzCpfX540I=\ngithub.com/containerd/log v0.1.0/go.mod h1:VRRf09a7mHDIRezVKTRCrOq78v577GXq3bSa3EhrzVo=\ngithub.com/containerd/platforms v0.2.1 h1:zvwtM3rz2YHPQsF2CHYM8+KtB5dvhISiXh5ZpSBQv6A=\ngithub.com/containerd/platforms v0.2.1/go.mod h1:XHCb+2/hzowdiut9rkudds9bE5yJ7npe7dG/wG+uFPw=\ngithub.com/cpuguy83/dockercfg v0.3.2 h1:DlJTyZGBDlXqUZ2Dk2Q3xHs/FtnooJJVaad2S9GKorA=\ngithub.com/cpuguy83/dockercfg v0.3.2/go.mod h1:sugsbF4//dDlL/i+S+rtpIWp+5h0BHJHfjj5/jFyUJc=\ngithub.com/creack/pty v1.1.9/go.mod h1:oKZEueFk5CKHvIhNR5MUki03XCEU+Q6VDXinZuGJ33E=\ngithub.com/creack/pty v1.1.18 h1:n56/Zwd5o6whRC5PMGretI4IdRLlmBXYNjScPaBgsbY=\ngithub.com/creack/pty v1.1.18/go.mod h1:MOBLtS5ELjhRRrroQr9kyvTxUAFNvYEK993ew/Vr4O4=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/distribution/reference v0.6.0 h1:0IXCQ5g4/QMHHkarYzh5l+u8T3t73zM5QvfrDyIgxBk=\ngithub.com/distribution/reference v0.6.0/go.mod h1:BbU0aIcezP1/5jX/8MP0YiH4SdvB5Y4f/wlDRiLyi3E=\ngithub.com/docker/docker v27.1.1+incompatible h1:hO/M4MtV36kzKldqnA37IWhebRA+LnqqcqDja6kVaKY=\ngithub.com/docker/docker v27.1.1+incompatible/go.mod h1:eEKB0N0r5NX/I1kEveEz05bcu8tLC/8azJZsviup8Sk=\ngithub.com/docker/go-connections v0.5.0 h1:USnMq7hx7gwdVZq1L49hLXaFtUdTADjXGp+uj1Br63c=\ngithub.com/docker/go-connections v0.5.0/go.mod h1:ov60Kzw0kKElRwhNs9UlUHAE/F9Fe6GLaXnqyDdmEXc=\ngithub.com/docker/go-units v0.5.0 h1:69rxXcBk27SvSaaxTtLh/8llcHD8vYHT7WSdRZ/jvr4=\ngithub.com/docker/go-units v0.5.0/go.mod h1:fgPhTUdO+D/Jk86RDLlptpiXQzgHJF7gydDDbaIK4Dk=\ngithub.com/felixge/httpsnoop v1.0.4 h1:NFTV2Zj1bL4mc9sqWACXbQFVBBg2W3GPvqp8/ESS2Wg=\ngithub.com/felixge/httpsnoop v1.0.4/go.mod h1:m8KPJKqk1gH5J9DgRY2ASl2lWCfGKXixSwevea8zH2U=\ngithub.com/go-logr/logr v1.2.2/go.mod h1:jdQByPbusPIv2/zmleS9BjJVeZ6kBagPoEUsqbVz/1A=\ngithub.com/go-logr/logr v1.4.1 h1:pKouT5E8xu9zeFC39JXRDukb6JFQPXM5p5I91188VAQ=\ngithub.com/go-logr/logr v1.4.1/go.mod h1:9T104GzyrTigFIr8wt5mBrctHMim0Nb2HLGrmQ40KvY=\ngithub.com/go-logr/stdr v1.2.2 h1:hSWxHoqTgW2S2qGc0LTAI563KZ5YKYRhT3MFKZMbjag=\ngithub.com/go-logr/stdr v1.2.2/go.mod h1:mMo/vtBO5dYbehREoey6XUKy/eSumjCCveDpRre4VKE=\ngithub.com/go-ole/go-ole v1.2.6 h1:/Fpf6oFPoeFik9ty7siob0G6Ke8QvQEuVcuChpwXzpY=\ngithub.com/go-ole/go-ole v1.2.6/go.mod h1:pprOEPIfldk/42T2oK7lQ4v4JSDwmV0As9GaiUsvbm0=\ngithub.com/gogo/protobuf v1.3.2 h1:Ov1cvc58UF3b5XjBnZv7+opcTcQFZebYjWzi34vdm4Q=\ngithub.com/gogo/protobuf v1.3.2/go.mod h1:P1XiOD3dCwIKUDQYPy72D8LYyHL2YPYrpS2s69NZV8Q=\ngithub.com/google/go-cmp v0.5.6/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.9/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/google/go-cmp v0.6.0 h1:ofyhxvXcZhMsU5ulbFiLKl/XBFqE1GSq7atu8tAmTRI=\ngithub.com/google/go-cmp v0.6.0/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/google/uuid v1.6.0 h1:NIvaJDMOsjHA8n1jAhLSgzrAzy1Hgr+hNrb57e+94F0=\ngithub.com/google/uuid v1.6.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/grpc-ecosystem/grpc-gateway/v2 v2.16.0 h1:YBftPWNWd4WwGqtY2yeZL2ef8rHAxPBD8KFhJpmcqms=\ngithub.com/grpc-ecosystem/grpc-gateway/v2 v2.16.0/go.mod h1:YN5jB8ie0yfIUg6VvR9Kz84aCaG7AsGZnLjhHbUqwPg=\ngithub.com/kisielk/errcheck v1.5.0/go.mod h1:pFxgyoBC7bSaBwPgfKdkLd5X25qrDl4LWUI2bnpBCr8=\ngithub.com/kisielk/gotool v1.0.0/go.mod h1:XhKaO+MFFWcvkIS/tQcRk01m1F5IRFswLeQ+oQHNcck=\ngithub.com/klauspost/compress v1.17.4 h1:Ej5ixsIri7BrIjBkRZLTo6ghwrEtHFk7ijlczPW4fZ4=\ngithub.com/klauspost/compress v1.17.4/go.mod h1:/dCuZOvVtNoHsyb+cuJD3itjs3NbnF6KH9zAO4BDxPM=\ngithub.com/kr/pretty v0.1.0/go.mod h1:dAy3ld7l9f0ibDNOQOHHMYYIIbhfbHSm3C4ZsoJORNo=\ngithub.com/kr/pretty v0.2.1/go.mod h1:ipq/a2n7PKx3OHsz4KJII5eveXtPO4qwEXGdVfWzfnI=\ngithub.com/kr/pretty v0.3.0 h1:WgNl7dwNpEZ6jJ9k1snq4pZsg7DOEN8hP9Xw0Tsjwk0=\ngithub.com/kr/pretty v0.3.0/go.mod h1:640gp4NfQd8pI5XOwp5fnNeVWj67G7CFk/SaSQn7NBk=\ngithub.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=\ngithub.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=\ngithub.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=\ngithub.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=\ngithub.com/lufia/plan9stats v0.0.0-20211012122336-39d0f177ccd0 h1:6E+4a0GO5zZEnZ81pIr0yLvtUWk2if982qA3F3QD6H4=\ngithub.com/lufia/plan9stats v0.0.0-20211012122336-39d0f177ccd0/go.mod h1:zJYVVT2jmtg6P3p1VtQj7WsuWi/y4VnjVBn7F8KPB3I=\ngithub.com/magiconair/properties v1.8.7 h1:IeQXZAiQcpL9mgcAe1Nu6cX9LLw6ExEHKjN0VQdvPDY=\ngithub.com/magiconair/properties v1.8.7/go.mod h1:Dhd985XPs7jluiymwWYZ0G4Z61jb3vdS329zhj2hYo0=\ngithub.com/moby/docker-image-spec v1.3.1 h1:jMKff3w6PgbfSa69GfNg+zN/XLhfXJGnEx3Nl2EsFP0=\ngithub.com/moby/docker-image-spec v1.3.1/go.mod h1:eKmb5VW8vQEh/BAr2yvVNvuiJuY6UIocYsFu/DxxRpo=\ngithub.com/moby/patternmatcher v0.6.0 h1:GmP9lR19aU5GqSSFko+5pRqHi+Ohk1O69aFiKkVGiPk=\ngithub.com/moby/patternmatcher v0.6.0/go.mod h1:hDPoyOpDY7OrrMDLaYoY3hf52gNCR/YOUYxkhApJIxc=\ngithub.com/moby/sys/sequential v0.5.0 h1:OPvI35Lzn9K04PBbCLW0g4LcFAJgHsvXsRyewg5lXtc=\ngithub.com/moby/sys/sequential v0.5.0/go.mod h1:tH2cOOs5V9MlPiXcQzRC+eEyab644PWKGRYaaV5ZZlo=\ngithub.com/moby/sys/user v0.1.0 h1:WmZ93f5Ux6het5iituh9x2zAG7NFY9Aqi49jjE1PaQg=\ngithub.com/moby/sys/user v0.1.0/go.mod h1:fKJhFOnsCN6xZ5gSfbM6zaHGgDJMrqt9/reuj4T7MmU=\ngithub.com/moby/term v0.5.0 h1:xt8Q1nalod/v7BqbG21f8mQPqH+xAaC9C3N3wfWbVP0=\ngithub.com/moby/term v0.5.0/go.mod h1:8FzsFHVUBGZdbDsJw/ot+X+d5HLUbvklYLJ9uGfcI3Y=\ngithub.com/morikuni/aec v1.0.0 h1:nP9CBfwrvYnBRgY6qfDQkygYDmYwOilePFkwzv4dU8A=\ngithub.com/morikuni/aec v1.0.0/go.mod h1:BbKIizmSmc5MMPqRYbxO4ZU0S0+P200+tUnFx7PXmsc=\ngithub.com/opencontainers/go-digest v1.0.0 h1:apOUWs51W5PlhuyGyz9FCeeBIOUDA/6nW8Oi/yOhh5U=\ngithub.com/opencontainers/go-digest v1.0.0/go.mod h1:0JzlMkj0TRzQZfJkVvzbP0HBR3IKzErnv2BNG4W4MAM=\ngithub.com/opencontainers/image-spec v1.1.0 h1:8SG7/vwALn54lVB/0yZ/MMwhFrPYtpEHQb2IpWsCzug=\ngithub.com/opencontainers/image-spec v1.1.0/go.mod h1:W4s4sFTMaBeK1BQLXbG4AdM2szdn85PY75RI83NrTrM=\ngithub.com/pkg/diff v0.0.0-20210226163009-20ebb0f2a09e/go.mod h1:pJLUxLENpZxwdsKMEsNbx1VGcRFpLqf3715MtcvvzbA=\ngithub.com/pkg/errors v0.9.1 h1:FEBLx1zS214owpjy7qsBeixbURkuhQAwrK5UwLGTwt4=\ngithub.com/pkg/errors v0.9.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/power-devops/perfstat v0.0.0-20210106213030-5aafc221ea8c h1:ncq/mPwQF4JjgDlrVEn3C11VoGHZN7m8qihwgMEtzYw=\ngithub.com/power-devops/perfstat v0.0.0-20210106213030-5aafc221ea8c/go.mod h1:OmDBASR4679mdNQnz2pUhc2G8CO2JrUAVFDRBDP/hJE=\ngithub.com/rogpeppe/go-internal v1.6.1/go.mod h1:xXDCJY+GAPziupqXw64V24skbSoqbTEfhy4qGm1nDQc=\ngithub.com/rogpeppe/go-internal v1.8.1 h1:geMPLpDpQOgVyCg5z5GoRwLHepNdb71NXb67XFkP+Eg=\ngithub.com/rogpeppe/go-internal v1.8.1/go.mod h1:JeRgkft04UBgHMgCIwADu4Pn6Mtm5d4nPKWu0nJ5d+o=\ngithub.com/shirou/gopsutil/v3 v3.23.12 h1:z90NtUkp3bMtmICZKpC4+WaknU1eXtp5vtbQ11DgpE4=\ngithub.com/shirou/gopsutil/v3 v3.23.12/go.mod h1:1FrWgea594Jp7qmjHUUPlJDTPgcsb9mGnXDxavtikzM=\ngithub.com/shoenig/go-m1cpu v0.1.6 h1:nxdKQNcEB6vzgA2E2bvzKIYRuNj7XNJ4S/aRSwKzFtM=\ngithub.com/shoenig/go-m1cpu v0.1.6/go.mod h1:1JJMcUBvfNwpq05QDQVAnx3gUHr9IYF7GNg9SUEw2VQ=\ngithub.com/shoenig/test v0.6.4 h1:kVTaSd7WLz5WZ2IaoM0RSzRsUD+m8wRR+5qvntpn4LU=\ngithub.com/shoenig/test v0.6.4/go.mod h1:byHiCGXqrVaflBLAMq/srcZIHynQPQgeyvkvXnjqq0k=\ngithub.com/sirupsen/logrus v1.9.3 h1:dueUQJ1C2q9oE3F7wvmSGAaVtTmUizReu6fjN8uqzbQ=\ngithub.com/sirupsen/logrus v1.9.3/go.mod h1:naHLuLoDiP4jHNo9R0sCBMtWGeIprob74mVsIT4qYEQ=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.4.0/go.mod h1:YvHI0jy2hoMjB+UWwv71VJQ9isScKT/TqJzVSSt89Yw=\ngithub.com/stretchr/objx v0.5.0/go.mod h1:Yh+to48EsGEfYuaHDzXPcE3xhTkx73EhmCGUpEOglKo=\ngithub.com/stretchr/objx v0.5.2 h1:xuMeJ0Sdp5ZMRXx/aWO6RZxdr3beISkG5/G/aIRr3pY=\ngithub.com/stretchr/objx v0.5.2/go.mod h1:FRsXN1f5AsAjCGJKqEizvkpNtU+EGNCLh3NxZ/8L+MA=\ngithub.com/stretchr/testify v1.7.0/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.7.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.8.0/go.mod h1:yNjHg4UonilssWZ8iaSj1OCr/vHnekPRkoO+kdMU+MU=\ngithub.com/stretchr/testify v1.8.4/go.mod h1:sz/lmYIOXD/1dqDmKjjqLyZ2RngseejIcXlSw2iwfAo=\ngithub.com/stretchr/testify v1.9.0 h1:HtqpIVDClZ4nwg75+f6Lvsy/wHu+3BoSGCbBAcpTsTg=\ngithub.com/stretchr/testify v1.9.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=\ngithub.com/tklauser/go-sysconf v0.3.12 h1:0QaGUFOdQaIVdPgfITYzaTegZvdCjmYO52cSFAEVmqU=\ngithub.com/tklauser/go-sysconf v0.3.12/go.mod h1:Ho14jnntGE1fpdOqQEEaiKRpvIavV0hSfmBq8nJbHYI=\ngithub.com/tklauser/numcpus v0.6.1 h1:ng9scYS7az0Bk4OZLvrNXNSAO2Pxr1XXRAPyjhIx+Fk=\ngithub.com/tklauser/numcpus v0.6.1/go.mod h1:1XfjsgE2zo8GVw7POkMbHENHzVg3GzmoZ9fESEdAacY=\ngithub.com/yuin/goldmark v1.1.27/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngithub.com/yuin/goldmark v1.2.1/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngithub.com/yusufpapurcu/wmi v1.2.3 h1:E1ctvB7uKFMOJw3fdOW32DwGE9I7t++CRUEMKvFoFiw=\ngithub.com/yusufpapurcu/wmi v1.2.3/go.mod h1:SBZ9tNy3G9/m5Oi98Zks0QjeHVDvuK0qfxQmPyzfmi0=\ngo.opentelemetry.io/contrib/instrumentation/net/http/otelhttp v0.49.0 h1:jq9TW8u3so/bN+JPT166wjOI6/vQPF6Xe7nMNIltagk=\ngo.opentelemetry.io/contrib/instrumentation/net/http/otelhttp v0.49.0/go.mod h1:p8pYQP+m5XfbZm9fxtSKAbM6oIllS7s2AfxrChvc7iw=\ngo.opentelemetry.io/otel v1.24.0 h1:0LAOdjNmQeSTzGBzduGe/rU4tZhMwL5rWgtp9Ku5Jfo=\ngo.opentelemetry.io/otel v1.24.0/go.mod h1:W7b9Ozg4nkF5tWI5zsXkaKKDjdVjpD4oAt9Qi/MArHo=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace v1.19.0 h1:Mne5On7VWdx7omSrSSZvM4Kw7cS7NQkOOmLcgscI51U=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace v1.19.0/go.mod h1:IPtUMKL4O3tH5y+iXVyAXqpAwMuzC1IrxVS81rummfE=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp v1.19.0 h1:IeMeyr1aBvBiPVYihXIaeIZba6b8E1bYp7lbdxK8CQg=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp v1.19.0/go.mod h1:oVdCUtjq9MK9BlS7TtucsQwUcXcymNiEDjgDD2jMtZU=\ngo.opentelemetry.io/otel/metric v1.24.0 h1:6EhoGWWK28x1fbpA4tYTOWBkPefTDQnb8WSGXlc88kI=\ngo.opentelemetry.io/otel/metric v1.24.0/go.mod h1:VYhLe1rFfxuTXLgj4CBiyz+9WYBA8pNGJgDcSFRKBco=\ngo.opentelemetry.io/otel/sdk v1.19.0 h1:6USY6zH+L8uMH8L3t1enZPR3WFEmSTADlqldyHtJi3o=\ngo.opentelemetry.io/otel/sdk v1.19.0/go.mod h1:NedEbbS4w3C6zElbLdPJKOpJQOrGUJ+GfzpjUvI0v1A=\ngo.opentelemetry.io/otel/trace v1.24.0 h1:CsKnnL4dUAr/0llH9FKuc698G04IrpWV0MQA/Y1YELI=\ngo.opentelemetry.io/otel/trace v1.24.0/go.mod h1:HPc3Xr/cOApsBI154IU0OI0HJexz+aw5uPdbs3UCjNU=\ngo.opentelemetry.io/proto/otlp v1.0.0 h1:T0TX0tmXU8a3CbNXzEKGeU5mIVOdf0oykP+u2lIVU/I=\ngo.opentelemetry.io/proto/otlp v1.0.0/go.mod h1:Sy6pihPLfYHkr3NkUbEhGHFhINUSI/v80hjKIs5JXpM=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20191011191535-87dc89f01550/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20200622213623-75b288015ac9/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/crypto v0.31.0 h1:ihbySMvVjLAeSH1IbfcRTkD/iNscyz8rGzjF/E5hV6U=\ngolang.org/x/crypto v0.31.0/go.mod h1:kDsLvtWBEx7MV9tJOj9bnXsPbxwJQ6csT/x4KIN4Ssk=\ngolang.org/x/mod v0.2.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/mod v0.3.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200226121028-0de0cce0169b/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20201021035429-f5854403a974/go.mod h1:sp8m0HH+o8qH0wwXwYZr8TS3Oi6o0r6Gce1SSxlDquU=\ngolang.org/x/net v0.26.0 h1:soB7SVo0PWrY4vPW/+ay0jKDNScG2X9wFeYlXIvJsOQ=\ngolang.org/x/net v0.26.0/go.mod h1:5YKkiSynbBIh3p6iOc/vibscux0x38BZDkn8sCUPxHE=\ngolang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190911185100-cd5d95a43a6e/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20201020160332-67f06af15bc9/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190916202348-b4ddaad3f8a3/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200930185726-fdedc70b468f/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20201204225414-ed752295db88/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210616094352-59db8d763f22/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220715151400-c0bba94af5f8/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.8.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.11.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.15.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/sys v0.28.0 h1:Fksou7UEQUWlKvIdsqzJmUmCX3cZuD2+P3XyyzwMhlA=\ngolang.org/x/sys v0.28.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/term v0.27.0 h1:WP60Sv1nlK1T6SupCHbXzSaN0b9wUmsPoRS9b61A23Q=\ngolang.org/x/term v0.27.0/go.mod h1:iMsnZpn0cago0GOrHO2+Y7u7JPn5AylBrcoWkElMTSM=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.21.0 h1:zyQAAkrwaneQ066sspRyJaG9VNi/YJ1NfzcGB3hZ/qo=\ngolang.org/x/text v0.21.0/go.mod h1:4IBbMaMmOPCJ8SecivzSH54+73PCFmPWxNTLm+vZkEQ=\ngolang.org/x/time v0.0.0-20220210224613-90d013bbcef8 h1:vVKdlvoWBphwdxWKrFZEuM0kGgGLxUOYcY4U/2Vjg44=\ngolang.org/x/time v0.0.0-20220210224613-90d013bbcef8/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20200619180055-7c47624df98f/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\ngolang.org/x/tools v0.0.0-20210106214847-113979e3529a/go.mod h1:emZCQorbCU4vsT4fOWvOPXz4eW1wZW4PmDk9uLelYpA=\ngolang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngoogle.golang.org/genproto v0.0.0-20230920204549-e6e6cdab5c13 h1:vlzZttNJGVqTsRFU9AmdnrcO1Znh8Ew9kCD//yjigk0=\ngoogle.golang.org/genproto/googleapis/api v0.0.0-20240318140521-94a12d6c2237 h1:RFiFrvy37/mpSpdySBDrUdipW/dHwsRwh3J3+A9VgT4=\ngoogle.golang.org/genproto/googleapis/api v0.0.0-20240318140521-94a12d6c2237/go.mod h1:Z5Iiy3jtmioajWHDGFk7CeugTyHtPvMHA4UTmUkyalE=\ngoogle.golang.org/genproto/googleapis/rpc v0.0.0-20240318140521-94a12d6c2237 h1:NnYq6UN9ReLM9/Y01KWNOWyI5xQ9kbIms5GGJVwS/Yc=\ngoogle.golang.org/genproto/googleapis/rpc v0.0.0-20240318140521-94a12d6c2237/go.mod h1:WtryC6hu0hhx87FDGxWCDptyssuo68sk10vYjF+T9fY=\ngoogle.golang.org/grpc v1.64.1 h1:LKtvyfbX3UGVPFcGqJ9ItpVWW6oN/2XqTxfAnwRRXiA=\ngoogle.golang.org/grpc v1.64.1/go.mod h1:hiQF4LFZelK2WKaP6W0L92zGHtiQdZxk8CrSdvyjeP0=\ngoogle.golang.org/protobuf v1.33.0 h1:uNO2rsAINq/JlFpSdYEKIZ0uKD/R9cpdv0T+yoGwGmI=\ngoogle.golang.org/protobuf v1.33.0/go.mod h1:c6P6GXX6sHbq/GpV6MGZEdwhWPcYBgnhAHhKbcUYpos=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c h1:Hei/4ADfdWqJk1ZMxUNpqntNwaWcugrBjAiHlqqRiVk=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c/go.mod h1:JHkPIbrfpd72SG/EVd6muEfDQjcINNoR0C8j2r3qZ4Q=\ngopkg.in/errgo.v2 v2.1.0/go.mod h1:hNsd1EY+bozCKY1Ytp96fpM3vjJbqLJn88ws8XvfDNI=\ngopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngotest.tools/v3 v3.5.1 h1:EENdUnS3pdur5nybKYIh2Vfgc8IUNBjxDPSjtiJcOzU=\ngotest.tools/v3 v3.5.1/go.mod h1:isy3WKz7GK6uNw/sbHzfKBLvlvXwUyV06n6brMxxopU=\n"
        },
        {
          "name": "image.go",
          "type": "blob",
          "size": 0.3720703125,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n)\n\n// ImageInfo represents a summary information of an image\ntype ImageInfo struct {\n\tID   string\n\tName string\n}\n\n// ImageProvider allows manipulating images\ntype ImageProvider interface {\n\tListImages(context.Context) ([]ImageInfo, error)\n\tSaveImages(context.Context, string, ...string) error\n\tPullImage(context.Context, string) error\n}\n"
        },
        {
          "name": "image_substitutors_test.go",
          "type": "blob",
          "size": 4.0556640625,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/testcontainers/testcontainers-go/internal/config\"\n)\n\nfunc TestCustomHubSubstitutor(t *testing.T) {\n\tt.Run(\"should substitute the image with the provided one\", func(t *testing.T) {\n\t\ts := NewCustomHubSubstitutor(\"quay.io\")\n\n\t\timg, err := s.Substitute(\"foo/foo:latest\")\n\t\trequire.NoError(t, err)\n\n\t\trequire.Equalf(t, \"quay.io/foo/foo:latest\", img, \"expected quay.io/foo/foo:latest, got %s\", img)\n\t})\n\tt.Run(\"should not substitute the image if it is already using the provided hub\", func(t *testing.T) {\n\t\ts := NewCustomHubSubstitutor(\"quay.io\")\n\n\t\timg, err := s.Substitute(\"quay.io/foo/foo:latest\")\n\t\trequire.NoError(t, err)\n\n\t\trequire.Equalf(t, \"quay.io/foo/foo:latest\", img, \"expected quay.io/foo/foo:latest, got %s\", img)\n\t})\n\tt.Run(\"should not substitute the image if hub image name prefix config exist\", func(t *testing.T) {\n\t\tt.Cleanup(config.Reset)\n\t\tconfig.Reset()\n\t\tt.Setenv(\"TESTCONTAINERS_HUB_IMAGE_NAME_PREFIX\", \"registry.mycompany.com/mirror\")\n\t\ts := NewCustomHubSubstitutor(\"quay.io\")\n\n\t\timg, err := s.Substitute(\"foo/foo:latest\")\n\t\trequire.NoError(t, err)\n\n\t\trequire.Equalf(t, \"foo/foo:latest\", img, \"expected foo/foo:latest, got %s\", img)\n\t})\n}\n\nfunc TestPrependHubRegistrySubstitutor(t *testing.T) {\n\tt.Run(\"should prepend the hub registry to images from Docker Hub\", func(t *testing.T) {\n\t\tt.Run(\"plain image\", func(t *testing.T) {\n\t\t\ts := newPrependHubRegistry(\"my-registry\")\n\n\t\t\timg, err := s.Substitute(\"foo:latest\")\n\t\t\trequire.NoError(t, err)\n\n\t\t\trequire.Equalf(t, \"my-registry/foo:latest\", img, \"expected my-registry/foo, got %s\", img)\n\t\t})\n\t\tt.Run(\"image with user\", func(t *testing.T) {\n\t\t\ts := newPrependHubRegistry(\"my-registry\")\n\n\t\t\timg, err := s.Substitute(\"user/foo:latest\")\n\t\t\trequire.NoError(t, err)\n\n\t\t\trequire.Equalf(t, \"my-registry/user/foo:latest\", img, \"expected my-registry/foo, got %s\", img)\n\t\t})\n\n\t\tt.Run(\"image with organization and user\", func(t *testing.T) {\n\t\t\ts := newPrependHubRegistry(\"my-registry\")\n\n\t\t\timg, err := s.Substitute(\"org/user/foo:latest\")\n\t\t\trequire.NoError(t, err)\n\n\t\t\trequire.Equalf(t, \"my-registry/org/user/foo:latest\", img, \"expected my-registry/org/foo:latest, got %s\", img)\n\t\t})\n\t})\n\n\tt.Run(\"should not prepend the hub registry to the image name\", func(t *testing.T) {\n\t\tt.Run(\"non-hub image\", func(t *testing.T) {\n\t\t\ts := newPrependHubRegistry(\"my-registry\")\n\n\t\t\timg, err := s.Substitute(\"quay.io/foo:latest\")\n\t\t\trequire.NoError(t, err)\n\n\t\t\trequire.Equalf(t, \"quay.io/foo:latest\", img, \"expected quay.io/foo:latest, got %s\", img)\n\t\t})\n\n\t\tt.Run(\"explicitly including registry.hub.docker.com/library\", func(t *testing.T) {\n\t\t\ts := newPrependHubRegistry(\"my-registry\")\n\n\t\t\timg, err := s.Substitute(\"registry.hub.docker.com/library/foo:latest\")\n\t\t\trequire.NoError(t, err)\n\n\t\t\trequire.Equalf(t, \"registry.hub.docker.com/library/foo:latest\", img, \"expected registry.hub.docker.com/library/foo:latest, got %s\", img)\n\t\t})\n\n\t\tt.Run(\"explicitly including registry.hub.docker.com\", func(t *testing.T) {\n\t\t\ts := newPrependHubRegistry(\"my-registry\")\n\n\t\t\timg, err := s.Substitute(\"registry.hub.docker.com/foo:latest\")\n\t\t\trequire.NoError(t, err)\n\n\t\t\trequire.Equalf(t, \"registry.hub.docker.com/foo:latest\", img, \"expected registry.hub.docker.com/foo:latest, got %s\", img)\n\t\t})\n\t})\n}\n\nfunc TestSubstituteBuiltImage(t *testing.T) {\n\treq := GenericContainerRequest{\n\t\tContainerRequest: ContainerRequest{\n\t\t\tFromDockerfile: FromDockerfile{\n\t\t\t\tContext:    \"testdata\",\n\t\t\t\tDockerfile: \"echo.Dockerfile\",\n\t\t\t\tTag:        \"my-image\",\n\t\t\t\tRepo:       \"my-repo\",\n\t\t\t},\n\t\t\tImageSubstitutors: []ImageSubstitutor{newPrependHubRegistry(\"my-registry\")},\n\t\t},\n\t\tStarted: false,\n\t}\n\n\tt.Run(\"should not use the properties prefix on built images\", func(t *testing.T) {\n\t\tconfig.Reset()\n\t\tc, err := GenericContainer(context.Background(), req)\n\t\tCleanupContainer(t, c)\n\t\trequire.NoError(t, err)\n\n\t\tjson, err := c.Inspect(context.Background())\n\t\trequire.NoError(t, err)\n\n\t\trequire.Equalf(t, \"my-registry/my-repo:my-image\", json.Config.Image, \"expected my-registry/my-repo:my-image, got %s\", json.Config.Image)\n\t})\n}\n"
        },
        {
          "name": "image_test.go",
          "type": "blob",
          "size": 1.6884765625,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/testcontainers/testcontainers-go/internal/core\"\n)\n\nfunc TestImageList(t *testing.T) {\n\tt.Setenv(\"DOCKER_HOST\", core.MustExtractDockerHost(context.Background()))\n\n\tprovider, err := ProviderDocker.GetProvider()\n\trequire.NoErrorf(t, err, \"failed to get provider\")\n\n\tdefer func() {\n\t\t_ = provider.Close()\n\t}()\n\n\treq := ContainerRequest{\n\t\tImage: \"redis:latest\",\n\t}\n\n\tctr, err := provider.CreateContainer(context.Background(), req)\n\tCleanupContainer(t, ctr)\n\trequire.NoErrorf(t, err, \"creating test container\")\n\n\timages, err := provider.ListImages(context.Background())\n\trequire.NoErrorf(t, err, \"listing images\")\n\n\trequire.NotEmptyf(t, images, \"no images retrieved\")\n\n\t// look if the list contains the container image\n\tfor _, img := range images {\n\t\tif img.Name == req.Image {\n\t\t\treturn\n\t\t}\n\t}\n\n\tt.Fatalf(\"expected image not found: %s\", req.Image)\n}\n\nfunc TestSaveImages(t *testing.T) {\n\tt.Setenv(\"DOCKER_HOST\", core.MustExtractDockerHost(context.Background()))\n\n\tprovider, err := ProviderDocker.GetProvider()\n\trequire.NoErrorf(t, err, \"failed to get provider\")\n\n\tdefer func() {\n\t\t_ = provider.Close()\n\t}()\n\n\treq := ContainerRequest{\n\t\tImage: \"redis:latest\",\n\t}\n\n\tctr, err := provider.CreateContainer(context.Background(), req)\n\tCleanupContainer(t, ctr)\n\trequire.NoErrorf(t, err, \"creating test container\")\n\n\toutput := filepath.Join(t.TempDir(), \"images.tar\")\n\terr = provider.SaveImages(context.Background(), output, req.Image)\n\trequire.NoErrorf(t, err, \"saving image %q\", req.Image)\n\n\tinfo, err := os.Stat(output)\n\trequire.NoError(t, err)\n\n\trequire.NotZerof(t, info.Size(), \"output file is empty\")\n}\n"
        },
        {
          "name": "internal",
          "type": "tree",
          "content": null
        },
        {
          "name": "lifecycle.go",
          "type": "blob",
          "size": 22.416015625,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"reflect\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/cenkalti/backoff/v4\"\n\t\"github.com/docker/docker/api/types/container\"\n\t\"github.com/docker/docker/api/types/network\"\n\t\"github.com/docker/go-connections/nat\"\n)\n\n// ContainerRequestHook is a hook that will be called before a container is created.\n// It can be used to modify container configuration before it is created,\n// using the different lifecycle hooks that are available:\n// - Creating\n// For that, it will receive a ContainerRequest, modify it and return an error if needed.\ntype ContainerRequestHook func(ctx context.Context, req ContainerRequest) error\n\n// ContainerHook is a hook that will be called after a container is created\n// It can be used to modify the state of the container after it is created,\n// using the different lifecycle hooks that are available:\n// - Created\n// - Starting\n// - Started\n// - Readied\n// - Stopping\n// - Stopped\n// - Terminating\n// - Terminated\n// For that, it will receive a Container, modify it and return an error if needed.\ntype ContainerHook func(ctx context.Context, ctr Container) error\n\n// ContainerLifecycleHooks is a struct that contains all the hooks that can be used\n// to modify the container lifecycle. All the container lifecycle hooks except the PreCreates hooks\n// will be passed to the container once it's created\ntype ContainerLifecycleHooks struct {\n\tPreBuilds      []ContainerRequestHook\n\tPostBuilds     []ContainerRequestHook\n\tPreCreates     []ContainerRequestHook\n\tPostCreates    []ContainerHook\n\tPreStarts      []ContainerHook\n\tPostStarts     []ContainerHook\n\tPostReadies    []ContainerHook\n\tPreStops       []ContainerHook\n\tPostStops      []ContainerHook\n\tPreTerminates  []ContainerHook\n\tPostTerminates []ContainerHook\n}\n\n// DefaultLoggingHook is a hook that will log the container lifecycle events\nvar DefaultLoggingHook = func(logger Logging) ContainerLifecycleHooks {\n\tshortContainerID := func(c Container) string {\n\t\treturn c.GetContainerID()[:12]\n\t}\n\n\treturn ContainerLifecycleHooks{\n\t\tPreBuilds: []ContainerRequestHook{\n\t\t\tfunc(ctx context.Context, req ContainerRequest) error {\n\t\t\t\tlogger.Printf(\"🐳 Building image %s:%s\", req.GetRepo(), req.GetTag())\n\t\t\t\treturn nil\n\t\t\t},\n\t\t},\n\t\tPostBuilds: []ContainerRequestHook{\n\t\t\tfunc(ctx context.Context, req ContainerRequest) error {\n\t\t\t\tlogger.Printf(\"✅ Built image %s\", req.Image)\n\t\t\t\treturn nil\n\t\t\t},\n\t\t},\n\t\tPreCreates: []ContainerRequestHook{\n\t\t\tfunc(ctx context.Context, req ContainerRequest) error {\n\t\t\t\tlogger.Printf(\"🐳 Creating container for image %s\", req.Image)\n\t\t\t\treturn nil\n\t\t\t},\n\t\t},\n\t\tPostCreates: []ContainerHook{\n\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\tlogger.Printf(\"✅ Container created: %s\", shortContainerID(c))\n\t\t\t\treturn nil\n\t\t\t},\n\t\t},\n\t\tPreStarts: []ContainerHook{\n\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\tlogger.Printf(\"🐳 Starting container: %s\", shortContainerID(c))\n\t\t\t\treturn nil\n\t\t\t},\n\t\t},\n\t\tPostStarts: []ContainerHook{\n\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\tlogger.Printf(\"✅ Container started: %s\", shortContainerID(c))\n\t\t\t\treturn nil\n\t\t\t},\n\t\t},\n\t\tPostReadies: []ContainerHook{\n\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\tlogger.Printf(\"🔔 Container is ready: %s\", shortContainerID(c))\n\t\t\t\treturn nil\n\t\t\t},\n\t\t},\n\t\tPreStops: []ContainerHook{\n\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\tlogger.Printf(\"🐳 Stopping container: %s\", shortContainerID(c))\n\t\t\t\treturn nil\n\t\t\t},\n\t\t},\n\t\tPostStops: []ContainerHook{\n\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\tlogger.Printf(\"✅ Container stopped: %s\", shortContainerID(c))\n\t\t\t\treturn nil\n\t\t\t},\n\t\t},\n\t\tPreTerminates: []ContainerHook{\n\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\tlogger.Printf(\"🐳 Terminating container: %s\", shortContainerID(c))\n\t\t\t\treturn nil\n\t\t\t},\n\t\t},\n\t\tPostTerminates: []ContainerHook{\n\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\tlogger.Printf(\"🚫 Container terminated: %s\", shortContainerID(c))\n\t\t\t\treturn nil\n\t\t\t},\n\t\t},\n\t}\n}\n\n// defaultPreCreateHook is a hook that will apply the default configuration to the container\nvar defaultPreCreateHook = func(p *DockerProvider, dockerInput *container.Config, hostConfig *container.HostConfig, networkingConfig *network.NetworkingConfig) ContainerLifecycleHooks {\n\treturn ContainerLifecycleHooks{\n\t\tPreCreates: []ContainerRequestHook{\n\t\t\tfunc(ctx context.Context, req ContainerRequest) error {\n\t\t\t\treturn p.preCreateContainerHook(ctx, req, dockerInput, hostConfig, networkingConfig)\n\t\t\t},\n\t\t},\n\t}\n}\n\n// defaultCopyFileToContainerHook is a hook that will copy files to the container after it's created\n// but before it's started\nvar defaultCopyFileToContainerHook = func(files []ContainerFile) ContainerLifecycleHooks {\n\treturn ContainerLifecycleHooks{\n\t\tPostCreates: []ContainerHook{\n\t\t\t// copy files to container after it's created\n\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\tfor _, f := range files {\n\t\t\t\t\tif err := f.validate(); err != nil {\n\t\t\t\t\t\treturn fmt.Errorf(\"invalid file: %w\", err)\n\t\t\t\t\t}\n\n\t\t\t\t\tvar err error\n\t\t\t\t\t// Bytes takes precedence over HostFilePath\n\t\t\t\t\tif f.Reader != nil {\n\t\t\t\t\t\tbs, ioerr := io.ReadAll(f.Reader)\n\t\t\t\t\t\tif ioerr != nil {\n\t\t\t\t\t\t\treturn fmt.Errorf(\"can't read from reader: %w\", ioerr)\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\terr = c.CopyToContainer(ctx, bs, f.ContainerFilePath, f.FileMode)\n\t\t\t\t\t} else {\n\t\t\t\t\t\terr = c.CopyFileToContainer(ctx, f.HostFilePath, f.ContainerFilePath, f.FileMode)\n\t\t\t\t\t}\n\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn fmt.Errorf(\"can't copy %s to container: %w\", f.HostFilePath, err)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\treturn nil\n\t\t\t},\n\t\t},\n\t}\n}\n\n// defaultLogConsumersHook is a hook that will start log consumers after the container is started\nvar defaultLogConsumersHook = func(cfg *LogConsumerConfig) ContainerLifecycleHooks {\n\treturn ContainerLifecycleHooks{\n\t\tPostStarts: []ContainerHook{\n\t\t\t// Produce logs sending details to the log consumers.\n\t\t\t// See combineContainerHooks for the order of execution.\n\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\tif cfg == nil || len(cfg.Consumers) == 0 {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\n\t\t\t\tdockerContainer := c.(*DockerContainer)\n\t\t\t\tdockerContainer.consumers = dockerContainer.consumers[:0]\n\t\t\t\tfor _, consumer := range cfg.Consumers {\n\t\t\t\t\tdockerContainer.followOutput(consumer)\n\t\t\t\t}\n\n\t\t\t\treturn dockerContainer.startLogProduction(ctx, cfg.Opts...)\n\t\t\t},\n\t\t},\n\t\tPostStops: []ContainerHook{\n\t\t\t// Stop the log production.\n\t\t\t// See combineContainerHooks for the order of execution.\n\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\tif cfg == nil || len(cfg.Consumers) == 0 {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\n\t\t\t\tdockerContainer := c.(*DockerContainer)\n\t\t\t\treturn dockerContainer.stopLogProduction()\n\t\t\t},\n\t\t},\n\t}\n}\n\nfunc checkPortsMapped(exposedAndMappedPorts nat.PortMap, exposedPorts []string) error {\n\tportMap, _, err := nat.ParsePortSpecs(exposedPorts)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"parse exposed ports: %w\", err)\n\t}\n\n\tfor exposedPort := range portMap {\n\t\t// having entries in exposedAndMappedPorts, where the key is the exposed port,\n\t\t// and the value is the mapped port, means that the port has been already mapped.\n\t\tif _, ok := exposedAndMappedPorts[exposedPort]; ok {\n\t\t\tcontinue\n\t\t}\n\n\t\t// check if the port is mapped with the protocol (default is TCP)\n\t\tif strings.Contains(string(exposedPort), \"/\") {\n\t\t\treturn fmt.Errorf(\"port %s is not mapped yet\", exposedPort)\n\t\t}\n\n\t\t// Port didn't have a type, default to tcp and retry.\n\t\texposedPort += \"/tcp\"\n\t\tif _, ok := exposedAndMappedPorts[exposedPort]; !ok {\n\t\t\treturn fmt.Errorf(\"port %s is not mapped yet\", exposedPort)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// defaultReadinessHook is a hook that will wait for the container to be ready\nvar defaultReadinessHook = func() ContainerLifecycleHooks {\n\treturn ContainerLifecycleHooks{\n\t\tPostStarts: []ContainerHook{\n\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\t// wait until all the exposed ports are mapped:\n\t\t\t\t// it will be ready when all the exposed ports are mapped,\n\t\t\t\t// checking every 50ms, up to 1s, and failing if all the\n\t\t\t\t// exposed ports are not mapped in 5s.\n\t\t\t\tdockerContainer := c.(*DockerContainer)\n\n\t\t\t\tb := backoff.NewExponentialBackOff()\n\n\t\t\t\tb.InitialInterval = 50 * time.Millisecond\n\t\t\t\tb.MaxElapsedTime = 5 * time.Second\n\t\t\t\tb.MaxInterval = time.Duration(float64(time.Second) * backoff.DefaultRandomizationFactor)\n\n\t\t\t\terr := backoff.RetryNotify(\n\t\t\t\t\tfunc() error {\n\t\t\t\t\t\tjsonRaw, err := dockerContainer.inspectRawContainer(ctx)\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\treturn err\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\treturn checkPortsMapped(jsonRaw.NetworkSettings.Ports, dockerContainer.exposedPorts)\n\t\t\t\t\t},\n\t\t\t\t\tb,\n\t\t\t\t\tfunc(err error, duration time.Duration) {\n\t\t\t\t\t\tdockerContainer.logger.Printf(\"All requested ports were not exposed: %v\", err)\n\t\t\t\t\t},\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn fmt.Errorf(\"all exposed ports, %s, were not mapped in 5s: %w\", dockerContainer.exposedPorts, err)\n\t\t\t\t}\n\n\t\t\t\treturn nil\n\t\t\t},\n\t\t\t// wait for the container to be ready\n\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\tdockerContainer := c.(*DockerContainer)\n\n\t\t\t\t// if a Wait Strategy has been specified, wait before returning\n\t\t\t\tif dockerContainer.WaitingFor != nil {\n\t\t\t\t\tdockerContainer.logger.Printf(\n\t\t\t\t\t\t\"⏳ Waiting for container id %s image: %s. Waiting for: %+v\",\n\t\t\t\t\t\tdockerContainer.ID[:12], dockerContainer.Image, dockerContainer.WaitingFor,\n\t\t\t\t\t)\n\t\t\t\t\tif err := dockerContainer.WaitingFor.WaitUntilReady(ctx, c); err != nil {\n\t\t\t\t\t\treturn fmt.Errorf(\"wait until ready: %w\", err)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tdockerContainer.isRunning = true\n\n\t\t\t\treturn nil\n\t\t\t},\n\t\t},\n\t}\n}\n\n// buildingHook is a hook that will be called before a container image is built.\nfunc (req ContainerRequest) buildingHook(ctx context.Context) error {\n\treturn req.applyLifecycleHooks(func(lifecycleHooks ContainerLifecycleHooks) error {\n\t\treturn lifecycleHooks.Building(ctx)(req)\n\t})\n}\n\n// builtHook is a hook that will be called after a container image is built.\nfunc (req ContainerRequest) builtHook(ctx context.Context) error {\n\treturn req.applyLifecycleHooks(func(lifecycleHooks ContainerLifecycleHooks) error {\n\t\treturn lifecycleHooks.Built(ctx)(req)\n\t})\n}\n\n// creatingHook is a hook that will be called before a container is created.\nfunc (req ContainerRequest) creatingHook(ctx context.Context) error {\n\treturn req.applyLifecycleHooks(func(lifecycleHooks ContainerLifecycleHooks) error {\n\t\treturn lifecycleHooks.Creating(ctx)(req)\n\t})\n}\n\n// applyLifecycleHooks calls hook on all LifecycleHooks.\nfunc (req ContainerRequest) applyLifecycleHooks(hook func(lifecycleHooks ContainerLifecycleHooks) error) error {\n\tvar errs []error\n\tfor _, lifecycleHooks := range req.LifecycleHooks {\n\t\tif err := hook(lifecycleHooks); err != nil {\n\t\t\terrs = append(errs, err)\n\t\t}\n\t}\n\n\treturn errors.Join(errs...)\n}\n\n// createdHook is a hook that will be called after a container is created.\nfunc (c *DockerContainer) createdHook(ctx context.Context) error {\n\treturn c.applyLifecycleHooks(ctx, false, func(lifecycleHooks ContainerLifecycleHooks) []ContainerHook {\n\t\treturn lifecycleHooks.PostCreates\n\t})\n}\n\n// startingHook is a hook that will be called before a container is started.\nfunc (c *DockerContainer) startingHook(ctx context.Context) error {\n\treturn c.applyLifecycleHooks(ctx, true, func(lifecycleHooks ContainerLifecycleHooks) []ContainerHook {\n\t\treturn lifecycleHooks.PreStarts\n\t})\n}\n\n// startedHook is a hook that will be called after a container is started.\nfunc (c *DockerContainer) startedHook(ctx context.Context) error {\n\treturn c.applyLifecycleHooks(ctx, true, func(lifecycleHooks ContainerLifecycleHooks) []ContainerHook {\n\t\treturn lifecycleHooks.PostStarts\n\t})\n}\n\n// readiedHook is a hook that will be called after a container is ready.\nfunc (c *DockerContainer) readiedHook(ctx context.Context) error {\n\treturn c.applyLifecycleHooks(ctx, true, func(lifecycleHooks ContainerLifecycleHooks) []ContainerHook {\n\t\treturn lifecycleHooks.PostReadies\n\t})\n}\n\n// printLogs is a helper function that will print the logs of a Docker container\n// We are going to use this helper function to inform the user of the logs when an error occurs\nfunc (c *DockerContainer) printLogs(ctx context.Context, cause error) {\n\treader, err := c.Logs(ctx)\n\tif err != nil {\n\t\tc.logger.Printf(\"failed accessing container logs: %v\\n\", err)\n\t\treturn\n\t}\n\n\tb, err := io.ReadAll(reader)\n\tif err != nil {\n\t\tc.logger.Printf(\"failed reading container logs: %v\\n\", err)\n\t\treturn\n\t}\n\n\tc.logger.Printf(\"container logs (%s):\\n%s\", cause, b)\n}\n\n// stoppingHook is a hook that will be called before a container is stopped.\nfunc (c *DockerContainer) stoppingHook(ctx context.Context) error {\n\treturn c.applyLifecycleHooks(ctx, false, func(lifecycleHooks ContainerLifecycleHooks) []ContainerHook {\n\t\treturn lifecycleHooks.PreStops\n\t})\n}\n\n// stoppedHook is a hook that will be called after a container is stopped.\nfunc (c *DockerContainer) stoppedHook(ctx context.Context) error {\n\treturn c.applyLifecycleHooks(ctx, false, func(lifecycleHooks ContainerLifecycleHooks) []ContainerHook {\n\t\treturn lifecycleHooks.PostStops\n\t})\n}\n\n// terminatingHook is a hook that will be called before a container is terminated.\nfunc (c *DockerContainer) terminatingHook(ctx context.Context) error {\n\treturn c.applyLifecycleHooks(ctx, false, func(lifecycleHooks ContainerLifecycleHooks) []ContainerHook {\n\t\treturn lifecycleHooks.PreTerminates\n\t})\n}\n\n// terminatedHook is a hook that will be called after a container is terminated.\nfunc (c *DockerContainer) terminatedHook(ctx context.Context) error {\n\treturn c.applyLifecycleHooks(ctx, false, func(lifecycleHooks ContainerLifecycleHooks) []ContainerHook {\n\t\treturn lifecycleHooks.PostTerminates\n\t})\n}\n\n// applyLifecycleHooks applies all lifecycle hooks reporting the container logs on error if logError is true.\nfunc (c *DockerContainer) applyLifecycleHooks(ctx context.Context, logError bool, hooks func(lifecycleHooks ContainerLifecycleHooks) []ContainerHook) error {\n\tvar errs []error\n\tfor _, lifecycleHooks := range c.lifecycleHooks {\n\t\tif err := containerHookFn(ctx, hooks(lifecycleHooks))(c); err != nil {\n\t\t\terrs = append(errs, err)\n\t\t}\n\t}\n\n\tif err := errors.Join(errs...); err != nil {\n\t\tif logError {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\t// Context has timed out so need a new context to get logs.\n\t\t\t\tctx, cancel := context.WithTimeout(context.Background(), time.Second*5)\n\t\t\t\tdefer cancel()\n\t\t\t\tc.printLogs(ctx, err)\n\t\t\tdefault:\n\t\t\t\tc.printLogs(ctx, err)\n\t\t\t}\n\t\t}\n\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\n// Building is a hook that will be called before a container image is built.\nfunc (c ContainerLifecycleHooks) Building(ctx context.Context) func(req ContainerRequest) error {\n\treturn containerRequestHook(ctx, c.PreBuilds)\n}\n\n// Building is a hook that will be called before a container image is built.\nfunc (c ContainerLifecycleHooks) Built(ctx context.Context) func(req ContainerRequest) error {\n\treturn containerRequestHook(ctx, c.PostBuilds)\n}\n\n// Creating is a hook that will be called before a container is created.\nfunc (c ContainerLifecycleHooks) Creating(ctx context.Context) func(req ContainerRequest) error {\n\treturn containerRequestHook(ctx, c.PreCreates)\n}\n\n// containerRequestHook returns a function that will iterate over all\n// the hooks and call them one by one until there is an error.\nfunc containerRequestHook(ctx context.Context, hooks []ContainerRequestHook) func(req ContainerRequest) error {\n\treturn func(req ContainerRequest) error {\n\t\tfor _, hook := range hooks {\n\t\t\tif err := hook(ctx, req); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t}\n}\n\n// containerHookFn is a helper function that will create a function to be returned by all the different\n// container lifecycle hooks. The created function will iterate over all the hooks and call them one by one.\nfunc containerHookFn(ctx context.Context, containerHook []ContainerHook) func(container Container) error {\n\treturn func(ctr Container) error {\n\t\tvar errs []error\n\t\tfor _, hook := range containerHook {\n\t\t\tif err := hook(ctx, ctr); err != nil {\n\t\t\t\terrs = append(errs, err)\n\t\t\t}\n\t\t}\n\n\t\treturn errors.Join(errs...)\n\t}\n}\n\n// Created is a hook that will be called after a container is created\nfunc (c ContainerLifecycleHooks) Created(ctx context.Context) func(container Container) error {\n\treturn containerHookFn(ctx, c.PostCreates)\n}\n\n// Starting is a hook that will be called before a container is started\nfunc (c ContainerLifecycleHooks) Starting(ctx context.Context) func(container Container) error {\n\treturn containerHookFn(ctx, c.PreStarts)\n}\n\n// Started is a hook that will be called after a container is started\nfunc (c ContainerLifecycleHooks) Started(ctx context.Context) func(container Container) error {\n\treturn containerHookFn(ctx, c.PostStarts)\n}\n\n// Readied is a hook that will be called after a container is ready\nfunc (c ContainerLifecycleHooks) Readied(ctx context.Context) func(container Container) error {\n\treturn containerHookFn(ctx, c.PostReadies)\n}\n\n// Stopping is a hook that will be called before a container is stopped\nfunc (c ContainerLifecycleHooks) Stopping(ctx context.Context) func(container Container) error {\n\treturn containerHookFn(ctx, c.PreStops)\n}\n\n// Stopped is a hook that will be called after a container is stopped\nfunc (c ContainerLifecycleHooks) Stopped(ctx context.Context) func(container Container) error {\n\treturn containerHookFn(ctx, c.PostStops)\n}\n\n// Terminating is a hook that will be called before a container is terminated\nfunc (c ContainerLifecycleHooks) Terminating(ctx context.Context) func(container Container) error {\n\treturn containerHookFn(ctx, c.PreTerminates)\n}\n\n// Terminated is a hook that will be called after a container is terminated\nfunc (c ContainerLifecycleHooks) Terminated(ctx context.Context) func(container Container) error {\n\treturn containerHookFn(ctx, c.PostTerminates)\n}\n\nfunc (p *DockerProvider) preCreateContainerHook(ctx context.Context, req ContainerRequest, dockerInput *container.Config, hostConfig *container.HostConfig, networkingConfig *network.NetworkingConfig) error {\n\t// prepare mounts\n\thostConfig.Mounts = mapToDockerMounts(req.Mounts)\n\n\tendpointSettings := map[string]*network.EndpointSettings{}\n\n\t// #248: Docker allows only one network to be specified during container creation\n\t// If there is more than one network specified in the request container should be attached to them\n\t// once it is created. We will take a first network if any specified in the request and use it to create container\n\tif len(req.Networks) > 0 {\n\t\tattachContainerTo := req.Networks[0]\n\n\t\tnw, err := p.GetNetwork(ctx, NetworkRequest{\n\t\t\tName: attachContainerTo,\n\t\t})\n\t\tif err == nil {\n\t\t\taliases := []string{}\n\t\t\tif _, ok := req.NetworkAliases[attachContainerTo]; ok {\n\t\t\t\taliases = req.NetworkAliases[attachContainerTo]\n\t\t\t}\n\t\t\tendpointSetting := network.EndpointSettings{\n\t\t\t\tAliases:   aliases,\n\t\t\t\tNetworkID: nw.ID,\n\t\t\t}\n\t\t\tendpointSettings[attachContainerTo] = &endpointSetting\n\t\t}\n\t}\n\n\tif req.ConfigModifier != nil {\n\t\treq.ConfigModifier(dockerInput)\n\t}\n\n\tif req.HostConfigModifier == nil {\n\t\treq.HostConfigModifier = defaultHostConfigModifier(req)\n\t}\n\treq.HostConfigModifier(hostConfig)\n\n\tif req.EnpointSettingsModifier != nil {\n\t\treq.EnpointSettingsModifier(endpointSettings)\n\t}\n\n\tnetworkingConfig.EndpointsConfig = endpointSettings\n\n\texposedPorts := req.ExposedPorts\n\t// this check must be done after the pre-creation Modifiers are called, so the network mode is already set\n\tif len(exposedPorts) == 0 && !hostConfig.NetworkMode.IsContainer() {\n\t\timage, _, err := p.client.ImageInspectWithRaw(ctx, dockerInput.Image)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfor p := range image.Config.ExposedPorts {\n\t\t\texposedPorts = append(exposedPorts, string(p))\n\t\t}\n\t}\n\n\texposedPortSet, exposedPortMap, err := nat.ParsePortSpecs(exposedPorts)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdockerInput.ExposedPorts = exposedPortSet\n\n\t// only exposing those ports automatically if the container request exposes zero ports and the container does not run in a container network\n\tif len(exposedPorts) == 0 && !hostConfig.NetworkMode.IsContainer() {\n\t\thostConfig.PortBindings = exposedPortMap\n\t} else {\n\t\thostConfig.PortBindings = mergePortBindings(hostConfig.PortBindings, exposedPortMap, req.ExposedPorts)\n\t}\n\n\treturn nil\n}\n\n// combineContainerHooks returns a ContainerLifecycle hook as the result\n// of combining the default hooks with the user-defined hooks.\n//\n// The order of hooks is the following:\n// - Pre-hooks run the default hooks first then the user-defined hooks\n// - Post-hooks run the user-defined hooks first then the default hooks\nfunc combineContainerHooks(defaultHooks, userDefinedHooks []ContainerLifecycleHooks) ContainerLifecycleHooks {\n\t// We use reflection here to ensure that any new hooks are handled.\n\tvar hooks ContainerLifecycleHooks\n\thooksVal := reflect.ValueOf(&hooks).Elem()\n\thooksType := reflect.TypeOf(hooks)\n\tfor _, defaultHook := range defaultHooks {\n\t\tdefaultVal := reflect.ValueOf(defaultHook)\n\t\tfor i := 0; i < hooksType.NumField(); i++ {\n\t\t\tif strings.HasPrefix(hooksType.Field(i).Name, \"Pre\") {\n\t\t\t\tfield := hooksVal.Field(i)\n\t\t\t\tfield.Set(reflect.AppendSlice(field, defaultVal.Field(i)))\n\t\t\t}\n\t\t}\n\t}\n\n\t// Append the user-defined hooks after the default pre-hooks\n\t// and because the post hooks are still empty, the user-defined\n\t// post-hooks will be the first ones to be executed.\n\tfor _, userDefinedHook := range userDefinedHooks {\n\t\tuserVal := reflect.ValueOf(userDefinedHook)\n\t\tfor i := 0; i < hooksType.NumField(); i++ {\n\t\t\tfield := hooksVal.Field(i)\n\t\t\tfield.Set(reflect.AppendSlice(field, userVal.Field(i)))\n\t\t}\n\t}\n\n\t// Finally, append the default post-hooks.\n\tfor _, defaultHook := range defaultHooks {\n\t\tdefaultVal := reflect.ValueOf(defaultHook)\n\t\tfor i := 0; i < hooksType.NumField(); i++ {\n\t\t\tif strings.HasPrefix(hooksType.Field(i).Name, \"Post\") {\n\t\t\t\tfield := hooksVal.Field(i)\n\t\t\t\tfield.Set(reflect.AppendSlice(field, defaultVal.Field(i)))\n\t\t\t}\n\t\t}\n\t}\n\n\treturn hooks\n}\n\nfunc mergePortBindings(configPortMap, exposedPortMap nat.PortMap, exposedPorts []string) nat.PortMap {\n\tif exposedPortMap == nil {\n\t\texposedPortMap = make(map[nat.Port][]nat.PortBinding)\n\t}\n\n\tmappedPorts := make(map[string]struct{}, len(exposedPorts))\n\tfor _, p := range exposedPorts {\n\t\tp = strings.Split(p, \"/\")[0]\n\t\tmappedPorts[p] = struct{}{}\n\t}\n\n\tfor k, v := range configPortMap {\n\t\tif _, ok := mappedPorts[k.Port()]; ok {\n\t\t\texposedPortMap[k] = v\n\t\t}\n\t}\n\treturn exposedPortMap\n}\n\n// defaultHostConfigModifier provides a default modifier including the deprecated fields\nfunc defaultHostConfigModifier(req ContainerRequest) func(hostConfig *container.HostConfig) {\n\treturn func(hostConfig *container.HostConfig) {\n\t\thostConfig.AutoRemove = req.AutoRemove\n\t\thostConfig.CapAdd = req.CapAdd\n\t\thostConfig.CapDrop = req.CapDrop\n\t\thostConfig.Binds = req.Binds\n\t\thostConfig.ExtraHosts = req.ExtraHosts\n\t\thostConfig.NetworkMode = req.NetworkMode\n\t\thostConfig.Resources = req.Resources\n\t}\n}\n"
        },
        {
          "name": "lifecycle_test.go",
          "type": "blob",
          "size": 33.0947265625,
          "content": "package testcontainers\n\nimport (\n\t\"bufio\"\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"reflect\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/docker/docker/api/types/container\"\n\t\"github.com/docker/docker/api/types/mount\"\n\t\"github.com/docker/docker/api/types/network\"\n\t\"github.com/docker/docker/api/types/strslice\"\n\t\"github.com/docker/go-connections/nat\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/testcontainers/testcontainers-go/wait\"\n)\n\nfunc TestPreCreateModifierHook(t *testing.T) {\n\tctx := context.Background()\n\n\tprovider, err := NewDockerProvider()\n\trequire.NoError(t, err)\n\tdefer provider.Close()\n\n\tt.Run(\"No exposed ports\", func(t *testing.T) {\n\t\t// reqWithModifiers {\n\t\treq := ContainerRequest{\n\t\t\tImage: nginxAlpineImage, // alpine image does expose port 80\n\t\t\tConfigModifier: func(config *container.Config) {\n\t\t\t\tconfig.Env = []string{\"a=b\"}\n\t\t\t},\n\t\t\tMounts: ContainerMounts{\n\t\t\t\t{\n\t\t\t\t\tSource: DockerVolumeMountSource{\n\t\t\t\t\t\tName: \"appdata\",\n\t\t\t\t\t\tVolumeOptions: &mount.VolumeOptions{\n\t\t\t\t\t\t\tLabels: GenericLabels(),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tTarget: \"/data\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tHostConfigModifier: func(hostConfig *container.HostConfig) {\n\t\t\t\thostConfig.PortBindings = nat.PortMap{\n\t\t\t\t\t\"80/tcp\": []nat.PortBinding{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tHostIP:   \"1\",\n\t\t\t\t\t\t\tHostPort: \"2\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t},\n\t\t\tEnpointSettingsModifier: func(endpointSettings map[string]*network.EndpointSettings) {\n\t\t\t\tendpointSettings[\"a\"] = &network.EndpointSettings{\n\t\t\t\t\tAliases: []string{\"b\"},\n\t\t\t\t\tLinks:   []string{\"link1\", \"link2\"},\n\t\t\t\t}\n\t\t\t},\n\t\t}\n\t\t// }\n\n\t\t// define empty inputs to be overwritten by the pre create hook\n\t\tinputConfig := &container.Config{\n\t\t\tImage: req.Image,\n\t\t}\n\t\tinputHostConfig := &container.HostConfig{}\n\t\tinputNetworkingConfig := &network.NetworkingConfig{}\n\n\t\terr = provider.preCreateContainerHook(ctx, req, inputConfig, inputHostConfig, inputNetworkingConfig)\n\t\trequire.NoError(t, err)\n\n\t\t// assertions\n\n\t\tassert.Equal(\n\t\t\tt,\n\t\t\t[]string{\"a=b\"},\n\t\t\tinputConfig.Env,\n\t\t\t\"Docker config's env should be overwritten by the modifier\",\n\t\t)\n\t\tassert.Equal(t,\n\t\t\tnat.PortSet(nat.PortSet{\"80/tcp\": struct{}{}}),\n\t\t\tinputConfig.ExposedPorts,\n\t\t\t\"Docker config's exposed ports should be overwritten by the modifier\",\n\t\t)\n\t\tassert.Equal(\n\t\t\tt,\n\t\t\t[]mount.Mount{\n\t\t\t\t{\n\t\t\t\t\tType:   mount.TypeVolume,\n\t\t\t\t\tSource: \"appdata\",\n\t\t\t\t\tTarget: \"/data\",\n\t\t\t\t\tVolumeOptions: &mount.VolumeOptions{\n\t\t\t\t\t\tLabels: GenericLabels(),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tinputHostConfig.Mounts,\n\t\t\t\"Host config's mounts should be mapped to Docker types\",\n\t\t)\n\n\t\tassert.Equal(t, nat.PortMap{\n\t\t\t\"80/tcp\": []nat.PortBinding{\n\t\t\t\t{\n\t\t\t\t\tHostIP:   \"\",\n\t\t\t\t\tHostPort: \"\",\n\t\t\t\t},\n\t\t\t},\n\t\t}, inputHostConfig.PortBindings,\n\t\t\t\"Host config's port bindings should be overwritten by the modifier\",\n\t\t)\n\n\t\tassert.Equal(\n\t\t\tt,\n\t\t\t[]string{\"b\"},\n\t\t\tinputNetworkingConfig.EndpointsConfig[\"a\"].Aliases,\n\t\t\t\"Networking config's aliases should be overwritten by the modifier\",\n\t\t)\n\t\tassert.Equal(\n\t\t\tt,\n\t\t\t[]string{\"link1\", \"link2\"},\n\t\t\tinputNetworkingConfig.EndpointsConfig[\"a\"].Links,\n\t\t\t\"Networking config's links should be overwritten by the modifier\",\n\t\t)\n\t})\n\n\tt.Run(\"No exposed ports and network mode IsContainer\", func(t *testing.T) {\n\t\treq := ContainerRequest{\n\t\t\tImage: nginxAlpineImage, // alpine image does expose port 80\n\t\t\tHostConfigModifier: func(hostConfig *container.HostConfig) {\n\t\t\t\thostConfig.PortBindings = nat.PortMap{\n\t\t\t\t\t\"80/tcp\": []nat.PortBinding{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tHostIP:   \"1\",\n\t\t\t\t\t\t\tHostPort: \"2\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t\thostConfig.NetworkMode = \"container:foo\"\n\t\t\t},\n\t\t}\n\n\t\t// define empty inputs to be overwritten by the pre create hook\n\t\tinputConfig := &container.Config{\n\t\t\tImage: req.Image,\n\t\t}\n\t\tinputHostConfig := &container.HostConfig{}\n\t\tinputNetworkingConfig := &network.NetworkingConfig{}\n\n\t\terr = provider.preCreateContainerHook(ctx, req, inputConfig, inputHostConfig, inputNetworkingConfig)\n\t\trequire.NoError(t, err)\n\n\t\t// assertions\n\n\t\tassert.Equal(\n\t\t\tt,\n\t\t\tnat.PortSet(nat.PortSet{}),\n\t\t\tinputConfig.ExposedPorts,\n\t\t\t\"Docker config's exposed ports should be empty\",\n\t\t)\n\t\tassert.Equal(t,\n\t\t\tnat.PortMap{},\n\t\t\tinputHostConfig.PortBindings,\n\t\t\t\"Host config's portBinding should be empty\",\n\t\t)\n\t})\n\n\tt.Run(\"Nil hostConfigModifier should apply default host config modifier\", func(t *testing.T) {\n\t\treq := ContainerRequest{\n\t\t\tImage:       nginxAlpineImage, // alpine image does expose port 80\n\t\t\tAutoRemove:  true,\n\t\t\tCapAdd:      []string{\"addFoo\", \"addBar\"},\n\t\t\tCapDrop:     []string{\"dropFoo\", \"dropBar\"},\n\t\t\tBinds:       []string{\"bindFoo\", \"bindBar\"},\n\t\t\tExtraHosts:  []string{\"hostFoo\", \"hostBar\"},\n\t\t\tNetworkMode: \"networkModeFoo\",\n\t\t\tResources: container.Resources{\n\t\t\t\tMemory:   2048,\n\t\t\t\tNanoCPUs: 8,\n\t\t\t},\n\t\t\tHostConfigModifier: nil,\n\t\t}\n\n\t\t// define empty inputs to be overwritten by the pre create hook\n\t\tinputConfig := &container.Config{\n\t\t\tImage: req.Image,\n\t\t}\n\t\tinputHostConfig := &container.HostConfig{}\n\t\tinputNetworkingConfig := &network.NetworkingConfig{}\n\n\t\terr = provider.preCreateContainerHook(ctx, req, inputConfig, inputHostConfig, inputNetworkingConfig)\n\t\trequire.NoError(t, err)\n\n\t\t// assertions\n\n\t\tassert.Equal(t, req.AutoRemove, inputHostConfig.AutoRemove, \"Deprecated AutoRemove should come from the container request\")\n\t\tassert.Equal(t, strslice.StrSlice(req.CapAdd), inputHostConfig.CapAdd, \"Deprecated CapAdd should come from the container request\")\n\t\tassert.Equal(t, strslice.StrSlice(req.CapDrop), inputHostConfig.CapDrop, \"Deprecated CapDrop should come from the container request\")\n\t\tassert.Equal(t, req.Binds, inputHostConfig.Binds, \"Deprecated Binds should come from the container request\")\n\t\tassert.Equal(t, req.ExtraHosts, inputHostConfig.ExtraHosts, \"Deprecated ExtraHosts should come from the container request\")\n\t\tassert.Equal(t, req.Resources, inputHostConfig.Resources, \"Deprecated Resources should come from the container request\")\n\t})\n\n\tt.Run(\"Request contains more than one network including aliases\", func(t *testing.T) {\n\t\tnetworkName := \"foo\"\n\t\tnet, err := provider.CreateNetwork(ctx, NetworkRequest{\n\t\t\tName: networkName,\n\t\t})\n\t\trequire.NoError(t, err)\n\t\tCleanupNetwork(t, net)\n\n\t\tdockerNetwork, err := provider.GetNetwork(ctx, NetworkRequest{\n\t\t\tName: networkName,\n\t\t})\n\t\trequire.NoError(t, err)\n\n\t\treq := ContainerRequest{\n\t\t\tImage:    nginxAlpineImage, // alpine image does expose port 80\n\t\t\tNetworks: []string{networkName, \"bar\"},\n\t\t\tNetworkAliases: map[string][]string{\n\t\t\t\t\"foo\": {\"foo1\"}, // network aliases are needed at the moment there is a network\n\t\t\t},\n\t\t}\n\n\t\t// define empty inputs to be overwritten by the pre create hook\n\t\tinputConfig := &container.Config{\n\t\t\tImage: req.Image,\n\t\t}\n\t\tinputHostConfig := &container.HostConfig{}\n\t\tinputNetworkingConfig := &network.NetworkingConfig{}\n\n\t\terr = provider.preCreateContainerHook(ctx, req, inputConfig, inputHostConfig, inputNetworkingConfig)\n\t\trequire.NoError(t, err)\n\n\t\t// assertions\n\n\t\tassert.Equal(\n\t\t\tt,\n\t\t\treq.NetworkAliases[networkName],\n\t\t\tinputNetworkingConfig.EndpointsConfig[networkName].Aliases,\n\t\t\t\"Networking config's aliases should come from the container request\",\n\t\t)\n\t\tassert.Equal(\n\t\t\tt,\n\t\t\tdockerNetwork.ID,\n\t\t\tinputNetworkingConfig.EndpointsConfig[networkName].NetworkID,\n\t\t\t\"Networking config's network ID should be retrieved from Docker\",\n\t\t)\n\t})\n\n\tt.Run(\"Request contains more than one network without aliases\", func(t *testing.T) {\n\t\tnetworkName := \"foo\"\n\t\tnet, err := provider.CreateNetwork(ctx, NetworkRequest{\n\t\t\tName: networkName,\n\t\t})\n\t\trequire.NoError(t, err)\n\t\tCleanupNetwork(t, net)\n\n\t\tdockerNetwork, err := provider.GetNetwork(ctx, NetworkRequest{\n\t\t\tName: networkName,\n\t\t})\n\t\trequire.NoError(t, err)\n\n\t\treq := ContainerRequest{\n\t\t\tImage:    nginxAlpineImage, // alpine image does expose port 80\n\t\t\tNetworks: []string{networkName, \"bar\"},\n\t\t}\n\n\t\t// define empty inputs to be overwritten by the pre create hook\n\t\tinputConfig := &container.Config{\n\t\t\tImage: req.Image,\n\t\t}\n\t\tinputHostConfig := &container.HostConfig{}\n\t\tinputNetworkingConfig := &network.NetworkingConfig{}\n\n\t\terr = provider.preCreateContainerHook(ctx, req, inputConfig, inputHostConfig, inputNetworkingConfig)\n\t\trequire.NoError(t, err)\n\n\t\t// assertions\n\n\t\trequire.Empty(\n\t\t\tt,\n\t\t\tinputNetworkingConfig.EndpointsConfig[networkName].Aliases,\n\t\t\t\"Networking config's aliases should be empty\",\n\t\t)\n\t\tassert.Equal(\n\t\t\tt,\n\t\t\tdockerNetwork.ID,\n\t\t\tinputNetworkingConfig.EndpointsConfig[networkName].NetworkID,\n\t\t\t\"Networking config's network ID should be retrieved from Docker\",\n\t\t)\n\t})\n\n\tt.Run(\"Request contains exposed port modifiers without protocol\", func(t *testing.T) {\n\t\treq := ContainerRequest{\n\t\t\tImage: nginxAlpineImage, // alpine image does expose port 80\n\t\t\tHostConfigModifier: func(hostConfig *container.HostConfig) {\n\t\t\t\thostConfig.PortBindings = nat.PortMap{\n\t\t\t\t\t\"80/tcp\": []nat.PortBinding{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tHostIP:   \"localhost\",\n\t\t\t\t\t\t\tHostPort: \"8080\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t},\n\t\t\tExposedPorts: []string{\"80\"},\n\t\t}\n\n\t\t// define empty inputs to be overwritten by the pre create hook\n\t\tinputConfig := &container.Config{\n\t\t\tImage: req.Image,\n\t\t}\n\t\tinputHostConfig := &container.HostConfig{}\n\t\tinputNetworkingConfig := &network.NetworkingConfig{}\n\n\t\terr = provider.preCreateContainerHook(ctx, req, inputConfig, inputHostConfig, inputNetworkingConfig)\n\t\trequire.NoError(t, err)\n\n\t\t// assertions\n\t\tassert.Equal(t, \"localhost\", inputHostConfig.PortBindings[\"80/tcp\"][0].HostIP)\n\t\tassert.Equal(t, \"8080\", inputHostConfig.PortBindings[\"80/tcp\"][0].HostPort)\n\t})\n\n\tt.Run(\"Request contains exposed port modifiers with protocol\", func(t *testing.T) {\n\t\treq := ContainerRequest{\n\t\t\tImage: nginxAlpineImage, // alpine image does expose port 80\n\t\t\tHostConfigModifier: func(hostConfig *container.HostConfig) {\n\t\t\t\thostConfig.PortBindings = nat.PortMap{\n\t\t\t\t\t\"80/tcp\": []nat.PortBinding{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tHostIP:   \"localhost\",\n\t\t\t\t\t\t\tHostPort: \"8080\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t},\n\t\t\tExposedPorts: []string{\"80/tcp\"},\n\t\t}\n\n\t\t// define empty inputs to be overwritten by the pre create hook\n\t\tinputConfig := &container.Config{\n\t\t\tImage: req.Image,\n\t\t}\n\t\tinputHostConfig := &container.HostConfig{}\n\t\tinputNetworkingConfig := &network.NetworkingConfig{}\n\n\t\terr = provider.preCreateContainerHook(ctx, req, inputConfig, inputHostConfig, inputNetworkingConfig)\n\t\trequire.NoError(t, err)\n\n\t\t// assertions\n\t\tassert.Equal(t, \"localhost\", inputHostConfig.PortBindings[\"80/tcp\"][0].HostIP)\n\t\tassert.Equal(t, \"8080\", inputHostConfig.PortBindings[\"80/tcp\"][0].HostPort)\n\t})\n}\n\nfunc TestMergePortBindings(t *testing.T) {\n\ttype arg struct {\n\t\tconfigPortMap nat.PortMap\n\t\tparsedPortMap nat.PortMap\n\t\texposedPorts  []string\n\t}\n\tcases := []struct {\n\t\tname     string\n\t\targ      arg\n\t\texpected nat.PortMap\n\t}{\n\t\t{\n\t\t\tname: \"empty ports\",\n\t\t\targ: arg{\n\t\t\t\tconfigPortMap: nil,\n\t\t\t\tparsedPortMap: nil,\n\t\t\t\texposedPorts:  nil,\n\t\t\t},\n\t\t\texpected: map[nat.Port][]nat.PortBinding{},\n\t\t},\n\t\t{\n\t\t\tname: \"config port map but not exposed\",\n\t\t\targ: arg{\n\t\t\t\tconfigPortMap: map[nat.Port][]nat.PortBinding{\n\t\t\t\t\t\"80/tcp\": {{HostIP: \"1\", HostPort: \"2\"}},\n\t\t\t\t},\n\t\t\t\tparsedPortMap: nil,\n\t\t\t\texposedPorts:  nil,\n\t\t\t},\n\t\t\texpected: map[nat.Port][]nat.PortBinding{},\n\t\t},\n\t\t{\n\t\t\tname: \"parsed port map without config\",\n\t\t\targ: arg{\n\t\t\t\tconfigPortMap: nil,\n\t\t\t\tparsedPortMap: map[nat.Port][]nat.PortBinding{\n\t\t\t\t\t\"80/tcp\": {{HostIP: \"\", HostPort: \"\"}},\n\t\t\t\t},\n\t\t\t\texposedPorts: nil,\n\t\t\t},\n\t\t\texpected: map[nat.Port][]nat.PortBinding{\n\t\t\t\t\"80/tcp\": {{HostIP: \"\", HostPort: \"\"}},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"parsed and configured but not exposed\",\n\t\t\targ: arg{\n\t\t\t\tconfigPortMap: map[nat.Port][]nat.PortBinding{\n\t\t\t\t\t\"80/tcp\": {{HostIP: \"1\", HostPort: \"2\"}},\n\t\t\t\t},\n\t\t\t\tparsedPortMap: map[nat.Port][]nat.PortBinding{\n\t\t\t\t\t\"80/tcp\": {{HostIP: \"\", HostPort: \"\"}},\n\t\t\t\t},\n\t\t\t\texposedPorts: nil,\n\t\t\t},\n\t\t\texpected: map[nat.Port][]nat.PortBinding{\n\t\t\t\t\"80/tcp\": {{HostIP: \"\", HostPort: \"\"}},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"merge both parsed and config\",\n\t\t\targ: arg{\n\t\t\t\tconfigPortMap: map[nat.Port][]nat.PortBinding{\n\t\t\t\t\t\"60/tcp\": {{HostIP: \"1\", HostPort: \"2\"}},\n\t\t\t\t\t\"70/tcp\": {{HostIP: \"1\", HostPort: \"2\"}},\n\t\t\t\t\t\"80/tcp\": {{HostIP: \"1\", HostPort: \"2\"}},\n\t\t\t\t},\n\t\t\t\tparsedPortMap: map[nat.Port][]nat.PortBinding{\n\t\t\t\t\t\"80/tcp\": {{HostIP: \"\", HostPort: \"\"}},\n\t\t\t\t\t\"90/tcp\": {{HostIP: \"\", HostPort: \"\"}},\n\t\t\t\t},\n\t\t\t\texposedPorts: []string{\"70\", \"80/tcp\"},\n\t\t\t},\n\t\t\texpected: map[nat.Port][]nat.PortBinding{\n\t\t\t\t\"70/tcp\": {{HostIP: \"1\", HostPort: \"2\"}},\n\t\t\t\t\"80/tcp\": {{HostIP: \"1\", HostPort: \"2\"}},\n\t\t\t\t\"90/tcp\": {{HostIP: \"\", HostPort: \"\"}},\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, c := range cases {\n\t\tt.Run(c.name, func(t *testing.T) {\n\t\t\tres := mergePortBindings(c.arg.configPortMap, c.arg.parsedPortMap, c.arg.exposedPorts)\n\t\t\tassert.Equal(t, c.expected, res)\n\t\t})\n\t}\n}\n\nfunc TestPortMappingCheck(t *testing.T) {\n\tmakePortMap := func(ports ...string) nat.PortMap {\n\t\tout := make(nat.PortMap)\n\t\tfor _, port := range ports {\n\t\t\t// We don't care about the actual binding in this test\n\t\t\tout[nat.Port(port)] = nil\n\t\t}\n\t\treturn out\n\t}\n\n\ttests := map[string]struct {\n\t\texposedAndMappedPorts nat.PortMap\n\t\texposedPorts          []string\n\t\texpectError           bool\n\t}{\n\t\t\"no-protocol\": {\n\t\t\texposedAndMappedPorts: makePortMap(\"1024/tcp\"),\n\t\t\texposedPorts:          []string{\"1024\"},\n\t\t},\n\t\t\"protocol\": {\n\t\t\texposedAndMappedPorts: makePortMap(\"1024/tcp\"),\n\t\t\texposedPorts:          []string{\"1024/tcp\"},\n\t\t},\n\t\t\"protocol-target-port\": {\n\t\t\texposedAndMappedPorts: makePortMap(\"1024/tcp\"),\n\t\t\texposedPorts:          []string{\"1024:1024/tcp\"},\n\t\t},\n\t\t\"target-port\": {\n\t\t\texposedAndMappedPorts: makePortMap(\"1024/tcp\"),\n\t\t\texposedPorts:          []string{\"1024:1024\"},\n\t\t},\n\t\t\"multiple-ports\": {\n\t\t\texposedAndMappedPorts: makePortMap(\"1024/tcp\", \"1025/tcp\", \"1026/tcp\"),\n\t\t\texposedPorts:          []string{\"1024\", \"25:1025/tcp\", \"1026:1026\"},\n\t\t},\n\t\t\"only-ipv4\": {\n\t\t\texposedAndMappedPorts: makePortMap(\"1024/tcp\"),\n\t\t\texposedPorts:          []string{\"0.0.0.0::1024/tcp\"},\n\t\t},\n\t\t\"no-mapped-ports\": {\n\t\t\texposedAndMappedPorts: makePortMap(),\n\t\t\texposedPorts:          []string{\"1024\"},\n\t\t\texpectError:           true,\n\t\t},\n\t\t\"wrong-mapped-port\": {\n\t\t\texposedAndMappedPorts: makePortMap(\"1023/tcp\"),\n\t\t\texposedPorts:          []string{\"1024\"},\n\t\t\texpectError:           true,\n\t\t},\n\t\t\"subset-mapped-ports\": {\n\t\t\texposedAndMappedPorts: makePortMap(\"1024/tcp\", \"1025/tcp\"),\n\t\t\texposedPorts:          []string{\"1024\", \"1025\", \"1026\"},\n\t\t\texpectError:           true,\n\t\t},\n\t}\n\tfor name, tt := range tests {\n\t\tt.Run(name, func(t *testing.T) {\n\t\t\terr := checkPortsMapped(tt.exposedAndMappedPorts, tt.exposedPorts)\n\t\t\tif tt.expectError {\n\t\t\t\trequire.Error(t, err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\trequire.NoError(t, err)\n\t\t})\n\t}\n}\n\nfunc TestLifecycleHooks(t *testing.T) {\n\ttests := []struct {\n\t\tname  string\n\t\treuse bool\n\t}{\n\t\t{\n\t\t\tname:  \"GenericContainer\",\n\t\t\treuse: false,\n\t\t},\n\t\t{\n\t\t\tname:  \"ReuseContainer\",\n\t\t\treuse: true,\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tprints := []string{}\n\t\t\tctx := context.Background()\n\t\t\t// reqWithLifecycleHooks {\n\t\t\treq := ContainerRequest{\n\t\t\t\tImage: nginxAlpineImage,\n\t\t\t\tLifecycleHooks: []ContainerLifecycleHooks{\n\t\t\t\t\t{\n\t\t\t\t\t\tPreCreates: []ContainerRequestHook{\n\t\t\t\t\t\t\tfunc(ctx context.Context, req ContainerRequest) error {\n\t\t\t\t\t\t\t\tprints = append(prints, \"pre-create hook 1\")\n\t\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tfunc(ctx context.Context, req ContainerRequest) error {\n\t\t\t\t\t\t\t\tprints = append(prints, \"pre-create hook 2\")\n\t\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tPostCreates: []ContainerHook{\n\t\t\t\t\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\t\t\t\t\tprints = append(prints, \"post-create hook 1\")\n\t\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\t\t\t\t\tprints = append(prints, \"post-create hook 2\")\n\t\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tPreStarts: []ContainerHook{\n\t\t\t\t\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\t\t\t\t\tprints = append(prints, \"pre-start hook 1\")\n\t\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\t\t\t\t\tprints = append(prints, \"pre-start hook 2\")\n\t\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tPostStarts: []ContainerHook{\n\t\t\t\t\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\t\t\t\t\tprints = append(prints, \"post-start hook 1\")\n\t\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\t\t\t\t\tprints = append(prints, \"post-start hook 2\")\n\t\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tPostReadies: []ContainerHook{\n\t\t\t\t\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\t\t\t\t\tprints = append(prints, \"post-ready hook 1\")\n\t\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\t\t\t\t\tprints = append(prints, \"post-ready hook 2\")\n\t\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tPreStops: []ContainerHook{\n\t\t\t\t\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\t\t\t\t\tprints = append(prints, \"pre-stop hook 1\")\n\t\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\t\t\t\t\tprints = append(prints, \"pre-stop hook 2\")\n\t\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tPostStops: []ContainerHook{\n\t\t\t\t\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\t\t\t\t\tprints = append(prints, \"post-stop hook 1\")\n\t\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\t\t\t\t\tprints = append(prints, \"post-stop hook 2\")\n\t\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tPreTerminates: []ContainerHook{\n\t\t\t\t\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\t\t\t\t\tprints = append(prints, \"pre-terminate hook 1\")\n\t\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\t\t\t\t\tprints = append(prints, \"pre-terminate hook 2\")\n\t\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tPostTerminates: []ContainerHook{\n\t\t\t\t\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\t\t\t\t\tprints = append(prints, \"post-terminate hook 1\")\n\t\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\t\t\t\t\tprints = append(prints, \"post-terminate hook 2\")\n\t\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}\n\t\t\t// }\n\n\t\t\tif tt.reuse {\n\t\t\t\treq.Name = \"reuse-container\"\n\t\t\t}\n\n\t\t\tc, err := GenericContainer(ctx, GenericContainerRequest{\n\t\t\t\tContainerRequest: req,\n\t\t\t\tReuse:            tt.reuse,\n\t\t\t\tStarted:          true,\n\t\t\t})\n\t\t\tCleanupContainer(t, c)\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.NotNil(t, c)\n\n\t\t\tduration := 1 * time.Second\n\t\t\terr = c.Stop(ctx, &duration)\n\t\t\trequire.NoError(t, err)\n\n\t\t\terr = c.Start(ctx)\n\t\t\trequire.NoError(t, err)\n\n\t\t\terr = c.Terminate(ctx)\n\t\t\trequire.NoError(t, err)\n\n\t\t\tlifecycleHooksIsHonouredFn(t, prints)\n\t\t})\n\t}\n}\n\n// customLoggerImplementation {\ntype inMemoryLogger struct {\n\tdata []string\n}\n\nfunc (l *inMemoryLogger) Printf(format string, args ...interface{}) {\n\tl.data = append(l.data, fmt.Sprintf(format, args...))\n}\n\n// }\n\nfunc TestLifecycleHooks_WithDefaultLogger(t *testing.T) {\n\tctx := context.Background()\n\n\t// reqWithDefaultLogginHook {\n\tdl := inMemoryLogger{}\n\n\treq := ContainerRequest{\n\t\tImage: nginxAlpineImage,\n\t\tLifecycleHooks: []ContainerLifecycleHooks{\n\t\t\tDefaultLoggingHook(&dl),\n\t\t},\n\t}\n\t// }\n\n\tc, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, c)\n\trequire.NoError(t, err)\n\trequire.NotNil(t, c)\n\n\tduration := 1 * time.Second\n\terr = c.Stop(ctx, &duration)\n\trequire.NoError(t, err)\n\n\terr = c.Start(ctx)\n\trequire.NoError(t, err)\n\n\terr = c.Terminate(ctx)\n\trequire.NoError(t, err)\n\n\t// Includes two additional entries for stop when terminate is called.\n\trequire.Len(t, dl.data, 14)\n}\n\nfunc TestCombineLifecycleHooks(t *testing.T) {\n\tprints := []string{}\n\n\tpreCreateFunc := func(prefix string, hook string, lifecycleID int, hookID int) func(ctx context.Context, req ContainerRequest) error {\n\t\treturn func(ctx context.Context, _ ContainerRequest) error {\n\t\t\tprints = append(prints, fmt.Sprintf(\"[%s] pre-%s hook %d.%d\", prefix, hook, lifecycleID, hookID))\n\t\t\treturn nil\n\t\t}\n\t}\n\thookFunc := func(prefix string, hookType string, hook string, lifecycleID int, hookID int) func(ctx context.Context, c Container) error {\n\t\treturn func(ctx context.Context, _ Container) error {\n\t\t\tprints = append(prints, fmt.Sprintf(\"[%s] %s-%s hook %d.%d\", prefix, hookType, hook, lifecycleID, hookID))\n\t\t\treturn nil\n\t\t}\n\t}\n\tpreFunc := func(prefix string, hook string, lifecycleID int, hookID int) func(ctx context.Context, c Container) error {\n\t\treturn hookFunc(prefix, \"pre\", hook, lifecycleID, hookID)\n\t}\n\tpostFunc := func(prefix string, hook string, lifecycleID int, hookID int) func(ctx context.Context, c Container) error {\n\t\treturn hookFunc(prefix, \"post\", hook, lifecycleID, hookID)\n\t}\n\n\tlifecycleHookFunc := func(prefix string, lifecycleID int) ContainerLifecycleHooks {\n\t\treturn ContainerLifecycleHooks{\n\t\t\tPreCreates:     []ContainerRequestHook{preCreateFunc(prefix, \"create\", lifecycleID, 1), preCreateFunc(prefix, \"create\", lifecycleID, 2)},\n\t\t\tPostCreates:    []ContainerHook{postFunc(prefix, \"create\", lifecycleID, 1), postFunc(prefix, \"create\", lifecycleID, 2)},\n\t\t\tPreStarts:      []ContainerHook{preFunc(prefix, \"start\", lifecycleID, 1), preFunc(prefix, \"start\", lifecycleID, 2)},\n\t\t\tPostStarts:     []ContainerHook{postFunc(prefix, \"start\", lifecycleID, 1), postFunc(prefix, \"start\", lifecycleID, 2)},\n\t\t\tPostReadies:    []ContainerHook{postFunc(prefix, \"ready\", lifecycleID, 1), postFunc(prefix, \"ready\", lifecycleID, 2)},\n\t\t\tPreStops:       []ContainerHook{preFunc(prefix, \"stop\", lifecycleID, 1), preFunc(prefix, \"stop\", lifecycleID, 2)},\n\t\t\tPostStops:      []ContainerHook{postFunc(prefix, \"stop\", lifecycleID, 1), postFunc(prefix, \"stop\", lifecycleID, 2)},\n\t\t\tPreTerminates:  []ContainerHook{preFunc(prefix, \"terminate\", lifecycleID, 1), preFunc(prefix, \"terminate\", lifecycleID, 2)},\n\t\t\tPostTerminates: []ContainerHook{postFunc(prefix, \"terminate\", lifecycleID, 1), postFunc(prefix, \"terminate\", lifecycleID, 2)},\n\t\t}\n\t}\n\n\tdefaultHooks := []ContainerLifecycleHooks{lifecycleHookFunc(\"default\", 1), lifecycleHookFunc(\"default\", 2)}\n\tuserDefinedHooks := []ContainerLifecycleHooks{lifecycleHookFunc(\"user-defined\", 1), lifecycleHookFunc(\"user-defined\", 2), lifecycleHookFunc(\"user-defined\", 3)}\n\n\thooks := combineContainerHooks(defaultHooks, userDefinedHooks)\n\n\t// call all the hooks in the right order, honouring the lifecycle\n\n\treq := ContainerRequest{}\n\terr := hooks.Creating(context.Background())(req)\n\trequire.NoError(t, err)\n\n\tc := &DockerContainer{}\n\n\terr = hooks.Created(context.Background())(c)\n\trequire.NoError(t, err)\n\terr = hooks.Starting(context.Background())(c)\n\trequire.NoError(t, err)\n\terr = hooks.Started(context.Background())(c)\n\trequire.NoError(t, err)\n\terr = hooks.Readied(context.Background())(c)\n\trequire.NoError(t, err)\n\terr = hooks.Stopping(context.Background())(c)\n\trequire.NoError(t, err)\n\terr = hooks.Stopped(context.Background())(c)\n\trequire.NoError(t, err)\n\terr = hooks.Terminating(context.Background())(c)\n\trequire.NoError(t, err)\n\terr = hooks.Terminated(context.Background())(c)\n\trequire.NoError(t, err)\n\n\t// assertions\n\n\t// There are 2 default container lifecycle hooks and 3 user-defined container lifecycle hooks.\n\t// Each lifecycle hook has 2 pre-create hooks and 2 post-create hooks.\n\t// That results in 16 hooks per lifecycle (8 defaults + 12 user-defined = 20)\n\n\t// There are 5 lifecycles (create, start, ready, stop, terminate),\n\t// but ready has only half of the hooks (it only has post), so we have 90 hooks in total.\n\trequire.Len(t, prints, 90)\n\n\t// The order of the hooks is:\n\t// - pre-X hooks: first default (2*2), then user-defined (3*2)\n\t// - post-X hooks: first user-defined (3*2), then default (2*2)\n\n\tfor i := 0; i < 5; i++ {\n\t\tvar hookType string\n\t\t// this is the particular order of execution for the hooks\n\t\tswitch i {\n\t\tcase 0:\n\t\t\thookType = \"create\"\n\t\tcase 1:\n\t\t\thookType = \"start\"\n\t\tcase 2:\n\t\t\thookType = \"ready\"\n\t\tcase 3:\n\t\t\thookType = \"stop\"\n\t\tcase 4:\n\t\t\thookType = \"terminate\"\n\t\t}\n\n\t\tinitialIndex := i * 20\n\t\tif i >= 2 {\n\t\t\tinitialIndex -= 10\n\t\t}\n\n\t\tif hookType != \"ready\" {\n\t\t\t// default pre-hooks: 4 hooks\n\t\t\tassert.Equal(t, fmt.Sprintf(\"[default] pre-%s hook 1.1\", hookType), prints[initialIndex])\n\t\t\tassert.Equal(t, fmt.Sprintf(\"[default] pre-%s hook 1.2\", hookType), prints[initialIndex+1])\n\t\t\tassert.Equal(t, fmt.Sprintf(\"[default] pre-%s hook 2.1\", hookType), prints[initialIndex+2])\n\t\t\tassert.Equal(t, fmt.Sprintf(\"[default] pre-%s hook 2.2\", hookType), prints[initialIndex+3])\n\n\t\t\t// user-defined pre-hooks: 6 hooks\n\t\t\tassert.Equal(t, fmt.Sprintf(\"[user-defined] pre-%s hook 1.1\", hookType), prints[initialIndex+4])\n\t\t\tassert.Equal(t, fmt.Sprintf(\"[user-defined] pre-%s hook 1.2\", hookType), prints[initialIndex+5])\n\t\t\tassert.Equal(t, fmt.Sprintf(\"[user-defined] pre-%s hook 2.1\", hookType), prints[initialIndex+6])\n\t\t\tassert.Equal(t, fmt.Sprintf(\"[user-defined] pre-%s hook 2.2\", hookType), prints[initialIndex+7])\n\t\t\tassert.Equal(t, fmt.Sprintf(\"[user-defined] pre-%s hook 3.1\", hookType), prints[initialIndex+8])\n\t\t\tassert.Equal(t, fmt.Sprintf(\"[user-defined] pre-%s hook 3.2\", hookType), prints[initialIndex+9])\n\t\t}\n\n\t\t// user-defined post-hooks: 6 hooks\n\t\tassert.Equal(t, fmt.Sprintf(\"[user-defined] post-%s hook 1.1\", hookType), prints[initialIndex+10])\n\t\tassert.Equal(t, fmt.Sprintf(\"[user-defined] post-%s hook 1.2\", hookType), prints[initialIndex+11])\n\t\tassert.Equal(t, fmt.Sprintf(\"[user-defined] post-%s hook 2.1\", hookType), prints[initialIndex+12])\n\t\tassert.Equal(t, fmt.Sprintf(\"[user-defined] post-%s hook 2.2\", hookType), prints[initialIndex+13])\n\t\tassert.Equal(t, fmt.Sprintf(\"[user-defined] post-%s hook 3.1\", hookType), prints[initialIndex+14])\n\t\tassert.Equal(t, fmt.Sprintf(\"[user-defined] post-%s hook 3.2\", hookType), prints[initialIndex+15])\n\n\t\t// default post-hooks: 4 hooks\n\t\tassert.Equal(t, fmt.Sprintf(\"[default] post-%s hook 1.1\", hookType), prints[initialIndex+16])\n\t\tassert.Equal(t, fmt.Sprintf(\"[default] post-%s hook 1.2\", hookType), prints[initialIndex+17])\n\t\tassert.Equal(t, fmt.Sprintf(\"[default] post-%s hook 2.1\", hookType), prints[initialIndex+18])\n\t\tassert.Equal(t, fmt.Sprintf(\"[default] post-%s hook 2.2\", hookType), prints[initialIndex+19])\n\t}\n}\n\nfunc TestLifecycleHooks_WithMultipleHooks(t *testing.T) {\n\tctx := context.Background()\n\n\tdl := inMemoryLogger{}\n\n\treq := ContainerRequest{\n\t\tImage: nginxAlpineImage,\n\t\tLifecycleHooks: []ContainerLifecycleHooks{\n\t\t\tDefaultLoggingHook(&dl),\n\t\t\tDefaultLoggingHook(&dl),\n\t\t},\n\t}\n\n\tc, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, c)\n\trequire.NoError(t, err)\n\trequire.NotNil(t, c)\n\n\tduration := 1 * time.Second\n\terr = c.Stop(ctx, &duration)\n\trequire.NoError(t, err)\n\n\terr = c.Start(ctx)\n\trequire.NoError(t, err)\n\n\terr = c.Terminate(ctx)\n\trequire.NoError(t, err)\n\n\t// Includes four additional entries for stop (twice) when terminate is called.\n\trequire.Len(t, dl.data, 28)\n}\n\ntype linesTestLogger struct {\n\tdata []string\n}\n\nfunc (l *linesTestLogger) Printf(format string, args ...interface{}) {\n\tl.data = append(l.data, fmt.Sprintf(format, args...))\n}\n\nfunc TestPrintContainerLogsOnError(t *testing.T) {\n\tctx := context.Background()\n\n\treq := ContainerRequest{\n\t\tImage:      \"alpine\",\n\t\tCmd:        []string{\"echo\", \"-n\", \"I am expecting this\"},\n\t\tWaitingFor: wait.ForLog(\"I was expecting that\").WithStartupTimeout(5 * time.Second),\n\t}\n\n\tarrayOfLinesLogger := linesTestLogger{\n\t\tdata: []string{},\n\t}\n\n\tctr, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType:     providerType,\n\t\tContainerRequest: req,\n\t\tLogger:           &arrayOfLinesLogger,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, ctr)\n\t// it should fail because the waiting for condition is not met\n\trequire.Error(t, err)\n\n\tcontainerLogs, err := ctr.Logs(ctx)\n\trequire.NoError(t, err)\n\tdefer containerLogs.Close()\n\n\t// read container logs line by line, checking that each line is present in the stdout\n\trd := bufio.NewReader(containerLogs)\n\tfor {\n\t\tline, err := rd.ReadString('\\n')\n\t\tif errors.Is(err, io.EOF) {\n\t\t\tbreak\n\t\t}\n\t\trequire.NoErrorf(t, err, \"Read Error\")\n\n\t\t// the last line of the array should contain the line of interest,\n\t\t// but we are checking all the lines to make sure that is present\n\t\tfound := false\n\t\tfor _, l := range arrayOfLinesLogger.data {\n\t\t\tif strings.Contains(l, line) {\n\t\t\t\tfound = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tassert.True(t, found, \"container log line not found in the output of the logger: %s\", line)\n\t}\n}\n\nfunc lifecycleHooksIsHonouredFn(t *testing.T, prints []string) {\n\tt.Helper()\n\n\texpects := []string{\n\t\t\"pre-create hook 1\",\n\t\t\"pre-create hook 2\",\n\t\t\"post-create hook 1\",\n\t\t\"post-create hook 2\",\n\t\t\"pre-start hook 1\",\n\t\t\"pre-start hook 2\",\n\t\t\"post-start hook 1\",\n\t\t\"post-start hook 2\",\n\t\t\"post-ready hook 1\",\n\t\t\"post-ready hook 2\",\n\t\t\"pre-stop hook 1\",\n\t\t\"pre-stop hook 2\",\n\t\t\"post-stop hook 1\",\n\t\t\"post-stop hook 2\",\n\t\t\"pre-start hook 1\",\n\t\t\"pre-start hook 2\",\n\t\t\"post-start hook 1\",\n\t\t\"post-start hook 2\",\n\t\t\"post-ready hook 1\",\n\t\t\"post-ready hook 2\",\n\t\t// Terminate currently calls stop to ensure that child containers are stopped.\n\t\t\"pre-stop hook 1\",\n\t\t\"pre-stop hook 2\",\n\t\t\"post-stop hook 1\",\n\t\t\"post-stop hook 2\",\n\t\t\"pre-terminate hook 1\",\n\t\t\"pre-terminate hook 2\",\n\t\t\"post-terminate hook 1\",\n\t\t\"post-terminate hook 2\",\n\t}\n\n\trequire.Equal(t, expects, prints)\n}\n\nfunc Test_combineContainerHooks(t *testing.T) {\n\tvar funcID string\n\tdefaultContainerRequestHook := func(ctx context.Context, req ContainerRequest) error {\n\t\tfuncID = \"defaultContainerRequestHook\"\n\t\treturn nil\n\t}\n\tuserContainerRequestHook := func(ctx context.Context, req ContainerRequest) error {\n\t\tfuncID = \"userContainerRequestHook\"\n\t\treturn nil\n\t}\n\tdefaultContainerHook := func(ctx context.Context, container Container) error {\n\t\tfuncID = \"defaultContainerHook\"\n\t\treturn nil\n\t}\n\tuserContainerHook := func(ctx context.Context, container Container) error {\n\t\tfuncID = \"userContainerHook\"\n\t\treturn nil\n\t}\n\n\tdefaultHooks := []ContainerLifecycleHooks{\n\t\t{\n\t\t\tPreBuilds:      []ContainerRequestHook{defaultContainerRequestHook},\n\t\t\tPostBuilds:     []ContainerRequestHook{defaultContainerRequestHook},\n\t\t\tPreCreates:     []ContainerRequestHook{defaultContainerRequestHook},\n\t\t\tPostCreates:    []ContainerHook{defaultContainerHook},\n\t\t\tPreStarts:      []ContainerHook{defaultContainerHook},\n\t\t\tPostStarts:     []ContainerHook{defaultContainerHook},\n\t\t\tPostReadies:    []ContainerHook{defaultContainerHook},\n\t\t\tPreStops:       []ContainerHook{defaultContainerHook},\n\t\t\tPostStops:      []ContainerHook{defaultContainerHook},\n\t\t\tPreTerminates:  []ContainerHook{defaultContainerHook},\n\t\t\tPostTerminates: []ContainerHook{defaultContainerHook},\n\t\t},\n\t}\n\tuserDefinedHooks := []ContainerLifecycleHooks{\n\t\t{\n\t\t\tPreBuilds:      []ContainerRequestHook{userContainerRequestHook},\n\t\t\tPostBuilds:     []ContainerRequestHook{userContainerRequestHook},\n\t\t\tPreCreates:     []ContainerRequestHook{userContainerRequestHook},\n\t\t\tPostCreates:    []ContainerHook{userContainerHook},\n\t\t\tPreStarts:      []ContainerHook{userContainerHook},\n\t\t\tPostStarts:     []ContainerHook{userContainerHook},\n\t\t\tPostReadies:    []ContainerHook{userContainerHook},\n\t\t\tPreStops:       []ContainerHook{userContainerHook},\n\t\t\tPostStops:      []ContainerHook{userContainerHook},\n\t\t\tPreTerminates:  []ContainerHook{userContainerHook},\n\t\t\tPostTerminates: []ContainerHook{userContainerHook},\n\t\t},\n\t}\n\texpects := ContainerLifecycleHooks{\n\t\tPreBuilds:      []ContainerRequestHook{defaultContainerRequestHook, userContainerRequestHook},\n\t\tPostBuilds:     []ContainerRequestHook{userContainerRequestHook, defaultContainerRequestHook},\n\t\tPreCreates:     []ContainerRequestHook{defaultContainerRequestHook, userContainerRequestHook},\n\t\tPostCreates:    []ContainerHook{userContainerHook, defaultContainerHook},\n\t\tPreStarts:      []ContainerHook{defaultContainerHook, userContainerHook},\n\t\tPostStarts:     []ContainerHook{userContainerHook, defaultContainerHook},\n\t\tPostReadies:    []ContainerHook{userContainerHook, defaultContainerHook},\n\t\tPreStops:       []ContainerHook{defaultContainerHook, userContainerHook},\n\t\tPostStops:      []ContainerHook{userContainerHook, defaultContainerHook},\n\t\tPreTerminates:  []ContainerHook{defaultContainerHook, userContainerHook},\n\t\tPostTerminates: []ContainerHook{userContainerHook, defaultContainerHook},\n\t}\n\n\tctx := context.Background()\n\tctxVal := reflect.ValueOf(ctx)\n\tvar req ContainerRequest\n\treqVal := reflect.ValueOf(req)\n\tcontainer := &DockerContainer{}\n\tcontainerVal := reflect.ValueOf(container)\n\n\tgot := combineContainerHooks(defaultHooks, userDefinedHooks)\n\n\t// Compare for equal. This can't be done with deep equals as functions\n\t// are not comparable so we us the unique value stored in funcID when\n\t// the function is called to determine if they are the same.\n\tgotVal := reflect.ValueOf(got)\n\tgotType := reflect.TypeOf(got)\n\texpectedVal := reflect.ValueOf(expects)\n\tfor i := 0; i < gotVal.NumField(); i++ {\n\t\tfieldName := gotType.Field(i).Name\n\t\tgotField := gotVal.Field(i)\n\t\texpectedField := expectedVal.Field(i)\n\t\trequire.Equalf(t, expectedField.Len(), 2, \"field %q not setup len expected %d got %d\", fieldName, 2, expectedField.Len()) //nolint:testifylint // False positive.\n\t\trequire.Equalf(t, expectedField.Len(), gotField.Len(), \"field %q len expected %d got %d\", fieldName, gotField.Len(), expectedField.Len())\n\t\tfor j := 0; j < gotField.Len(); j++ {\n\t\t\tgotIndex := gotField.Index(j)\n\t\t\texpectedIndex := expectedField.Index(j)\n\t\t\tvar gotID string\n\t\t\tif gotIndex.Type().Name() == \"ContainerRequestHook\" {\n\t\t\t\tgotIndex.Call([]reflect.Value{ctxVal, reqVal})\n\t\t\t\tgotID = funcID\n\t\t\t\texpectedIndex.Call([]reflect.Value{ctxVal, reqVal})\n\t\t\t} else {\n\t\t\t\tgotIndex.Call([]reflect.Value{ctxVal, containerVal})\n\t\t\t\tgotID = funcID\n\t\t\t\texpectedIndex.Call([]reflect.Value{ctxVal, containerVal})\n\t\t\t}\n\t\t\trequire.Equalf(t, funcID, gotID, \"field %q[%d] func expected %s got %s\", fieldName, j, funcID, gotID)\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "logconsumer.go",
          "type": "blob",
          "size": 0.8212890625,
          "content": "package testcontainers\n\n// StdoutLog is the log type for STDOUT\nconst StdoutLog = \"STDOUT\"\n\n// StderrLog is the log type for STDERR\nconst StderrLog = \"STDERR\"\n\n// logStruct {\n\n// Log represents a message that was created by a process,\n// LogType is either \"STDOUT\" or \"STDERR\",\n// Content is the byte contents of the message itself\ntype Log struct {\n\tLogType string\n\tContent []byte\n}\n\n// }\n\n// logConsumerInterface {\n\n// LogConsumer represents any object that can\n// handle a Log, it is up to the LogConsumer instance\n// what to do with the log\ntype LogConsumer interface {\n\tAccept(Log)\n}\n\n// }\n\n// LogConsumerConfig is a configuration object for the producer/consumer pattern\ntype LogConsumerConfig struct {\n\tOpts      []LogProductionOption // options for the production of logs\n\tConsumers []LogConsumer         // consumers for the logs\n}\n"
        },
        {
          "name": "logconsumer_test.go",
          "type": "blob",
          "size": 17.0634765625,
          "content": "package testcontainers\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"os\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/docker/docker/client\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/testcontainers/testcontainers-go/internal/config\"\n\t\"github.com/testcontainers/testcontainers-go/wait\"\n)\n\nconst lastMessage = \"DONE\"\n\ntype TestLogConsumer struct {\n\tmtx  sync.Mutex\n\tmsgs []string\n\tDone chan struct{}\n\n\t// Accepted provides a blocking way of ensuring the logs messages have been consumed.\n\t// This allows for proper synchronization during Test_StartStop in particular.\n\t// Please see func devNullAcceptorChan if you're not interested in this synchronization.\n\tAccepted chan string\n}\n\nfunc (g *TestLogConsumer) Accept(l Log) {\n\ts := string(l.Content)\n\tif s == fmt.Sprintf(\"echo %s\\n\", lastMessage) {\n\t\tclose(g.Done)\n\t\treturn\n\t}\n\tg.Accepted <- s\n\n\tg.mtx.Lock()\n\tdefer g.mtx.Unlock()\n\tg.msgs = append(g.msgs, s)\n}\n\nfunc (g *TestLogConsumer) Msgs() []string {\n\tg.mtx.Lock()\n\tdefer g.mtx.Unlock()\n\n\treturn g.msgs\n}\n\n// devNullAcceptorChan returns string channel that essentially sends all strings to dev null\nfunc devNullAcceptorChan() chan string {\n\tc := make(chan string)\n\tgo func(c <-chan string) {\n\t\tfor range c {\n\t\t\t// do nothing, just pull off channel\n\t\t}\n\t}(c)\n\treturn c\n}\n\nfunc Test_LogConsumerGetsCalled(t *testing.T) {\n\tctx := context.Background()\n\n\tg := TestLogConsumer{\n\t\tmsgs:     []string{},\n\t\tDone:     make(chan struct{}),\n\t\tAccepted: devNullAcceptorChan(),\n\t}\n\n\treq := ContainerRequest{\n\t\tFromDockerfile: FromDockerfile{\n\t\t\tContext:    \"./testdata/\",\n\t\t\tDockerfile: \"echoserver.Dockerfile\",\n\t\t},\n\t\tExposedPorts: []string{\"8080/tcp\"},\n\t\tWaitingFor:   wait.ForLog(\"ready\"),\n\t\tLogConsumerCfg: &LogConsumerConfig{\n\t\t\tConsumers: []LogConsumer{&g},\n\t\t},\n\t}\n\n\tgReq := GenericContainerRequest{\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t}\n\n\tc, err := GenericContainer(ctx, gReq)\n\tCleanupContainer(t, c)\n\trequire.NoError(t, err)\n\n\tep, err := c.Endpoint(ctx, \"http\")\n\trequire.NoError(t, err)\n\n\t_, err = http.Get(ep + \"/stdout?echo=hello\")\n\trequire.NoError(t, err)\n\n\t_, err = http.Get(ep + \"/stdout?echo=there\")\n\trequire.NoError(t, err)\n\n\t_, err = http.Get(ep + \"/stdout?echo=\" + lastMessage)\n\trequire.NoError(t, err)\n\n\tselect {\n\tcase <-g.Done:\n\tcase <-time.After(5 * time.Second):\n\t\tt.Fatal(\"never received final log message\")\n\t}\n\n\trequire.Equal(t, []string{\"ready\\n\", \"echo hello\\n\", \"echo there\\n\"}, g.Msgs())\n}\n\ntype TestLogTypeConsumer struct {\n\tLogTypes map[string]string\n\tAck      chan bool\n}\n\nfunc (t *TestLogTypeConsumer) Accept(l Log) {\n\tif string(l.Content) == fmt.Sprintf(\"echo %s\\n\", lastMessage) {\n\t\tt.Ack <- true\n\t\treturn\n\t}\n\n\tt.LogTypes[l.LogType] = string(l.Content)\n}\n\nfunc Test_ShouldRecognizeLogTypes(t *testing.T) {\n\tctx := context.Background()\n\n\tg := TestLogTypeConsumer{\n\t\tLogTypes: map[string]string{},\n\t\tAck:      make(chan bool),\n\t}\n\n\treq := ContainerRequest{\n\t\tFromDockerfile: FromDockerfile{\n\t\t\tContext:    \"./testdata/\",\n\t\t\tDockerfile: \"echoserver.Dockerfile\",\n\t\t},\n\t\tExposedPorts: []string{\"8080/tcp\"},\n\t\tWaitingFor:   wait.ForLog(\"ready\"),\n\t\tLogConsumerCfg: &LogConsumerConfig{\n\t\t\tConsumers: []LogConsumer{&g},\n\t\t},\n\t}\n\n\tgReq := GenericContainerRequest{\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t}\n\n\tc, err := GenericContainer(ctx, gReq)\n\tCleanupContainer(t, c)\n\trequire.NoError(t, err)\n\n\tep, err := c.Endpoint(ctx, \"http\")\n\trequire.NoError(t, err)\n\n\t_, err = http.Get(ep + \"/stdout?echo=this-is-stdout\")\n\trequire.NoError(t, err)\n\n\t_, err = http.Get(ep + \"/stderr?echo=this-is-stderr\")\n\trequire.NoError(t, err)\n\n\t_, err = http.Get(ep + \"/stdout?echo=\" + lastMessage)\n\trequire.NoError(t, err)\n\n\t<-g.Ack\n\n\tassert.Equal(t, map[string]string{\n\t\tStdoutLog: \"echo this-is-stdout\\n\",\n\t\tStderrLog: \"echo this-is-stderr\\n\",\n\t}, g.LogTypes)\n}\n\nfunc Test_MultipleLogConsumers(t *testing.T) {\n\tctx := context.Background()\n\n\tfirst := TestLogConsumer{\n\t\tmsgs:     []string{},\n\t\tDone:     make(chan struct{}),\n\t\tAccepted: devNullAcceptorChan(),\n\t}\n\tsecond := TestLogConsumer{\n\t\tmsgs:     []string{},\n\t\tDone:     make(chan struct{}),\n\t\tAccepted: devNullAcceptorChan(),\n\t}\n\n\treq := ContainerRequest{\n\t\tFromDockerfile: FromDockerfile{\n\t\t\tContext:    \"./testdata/\",\n\t\t\tDockerfile: \"echoserver.Dockerfile\",\n\t\t},\n\t\tExposedPorts: []string{\"8080/tcp\"},\n\t\tWaitingFor:   wait.ForLog(\"ready\"),\n\t\tLogConsumerCfg: &LogConsumerConfig{\n\t\t\tConsumers: []LogConsumer{&first, &second},\n\t\t},\n\t}\n\n\tgReq := GenericContainerRequest{\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t}\n\n\tc, err := GenericContainer(ctx, gReq)\n\tCleanupContainer(t, c)\n\trequire.NoError(t, err)\n\n\tep, err := c.Endpoint(ctx, \"http\")\n\trequire.NoError(t, err)\n\n\t_, err = http.Get(ep + \"/stdout?echo=mlem\")\n\trequire.NoError(t, err)\n\n\t_, err = http.Get(ep + \"/stdout?echo=\" + lastMessage)\n\trequire.NoError(t, err)\n\n\t<-first.Done\n\t<-second.Done\n\n\texpected := []string{\"ready\\n\", \"echo mlem\\n\"}\n\trequire.Equal(t, expected, first.Msgs())\n\trequire.Equal(t, expected, second.Msgs())\n}\n\nfunc TestContainerLogWithErrClosed(t *testing.T) {\n\tif os.Getenv(\"GITHUB_RUN_ID\") != \"\" {\n\t\tt.Skip(\"Skipping as flaky on GitHub Actions, Please see https://github.com/testcontainers/testcontainers-go/issues/1924\")\n\t}\n\n\tt.Cleanup(func() {\n\t\tconfig.Reset()\n\t})\n\n\tif providerType == ProviderPodman {\n\t\tt.Skip(\"Docker-in-Docker does not work with rootless Podman\")\n\t}\n\t// First spin up a docker-in-docker container, then spin up an inner container within that dind container\n\t// Logs are being read from the inner container via the dind container's tcp port, which can be briefly\n\t// closed to test behaviour in connection-closed situations.\n\tctx := context.Background()\n\n\tdind, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tStarted: true,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage:        \"docker:dind\",\n\t\t\tExposedPorts: []string{\"2375/tcp\"},\n\t\t\tEnv:          map[string]string{\"DOCKER_TLS_CERTDIR\": \"\"},\n\t\t\tWaitingFor:   wait.ForListeningPort(\"2375/tcp\"),\n\t\t\tPrivileged:   true,\n\t\t},\n\t})\n\tCleanupContainer(t, dind)\n\trequire.NoError(t, err)\n\n\tvar remoteDocker string\n\n\tctxEndpoint, cancel := context.WithTimeout(ctx, 5*time.Second)\n\tdefer cancel()\n\n\t// todo: remove this temporary fix (test is flaky).\n\tfor {\n\t\tremoteDocker, err = dind.Endpoint(ctxEndpoint, \"2375/tcp\")\n\t\tif err == nil {\n\t\t\tbreak\n\t\t}\n\t\tif errors.Is(err, context.DeadlineExceeded) {\n\t\t\tbreak\n\t\t}\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tt.Log(\"retrying get endpoint\")\n\t}\n\trequire.NoErrorf(t, err, \"get endpoint\")\n\n\topts := []client.Opt{client.WithHost(remoteDocker), client.WithAPIVersionNegotiation()}\n\n\tdockerClient, err := NewDockerClientWithOpts(ctx, opts...)\n\trequire.NoError(t, err)\n\tdefer dockerClient.Close()\n\n\tprovider := &DockerProvider{\n\t\tclient: dockerClient,\n\t\tconfig: config.Read(),\n\t\tDockerProviderOptions: &DockerProviderOptions{\n\t\t\tGenericProviderOptions: &GenericProviderOptions{\n\t\t\t\tLogger: TestLogger(t),\n\t\t\t},\n\t\t},\n\t}\n\n\tconsumer := TestLogConsumer{\n\t\tmsgs:     []string{},\n\t\tDone:     make(chan struct{}),\n\t\tAccepted: devNullAcceptorChan(),\n\t}\n\n\tnginx, err := provider.CreateContainer(ctx, ContainerRequest{\n\t\tImage:        \"nginx\",\n\t\tExposedPorts: []string{\"80/tcp\"},\n\t\tLogConsumerCfg: &LogConsumerConfig{\n\t\t\tConsumers: []LogConsumer{&consumer},\n\t\t},\n\t})\n\trequire.NoError(t, err)\n\terr = nginx.Start(ctx)\n\trequire.NoError(t, err)\n\tCleanupContainer(t, nginx)\n\n\tport, err := nginx.MappedPort(ctx, \"80/tcp\")\n\trequire.NoError(t, err)\n\n\t// Gather the initial container logs\n\ttime.Sleep(time.Second * 1)\n\texistingLogs := len(consumer.Msgs())\n\n\thitNginx := func() {\n\t\ti, _, err := dind.Exec(ctx, []string{\"wget\", \"--spider\", \"localhost:\" + port.Port()})\n\t\trequire.NoError(t, err, \"Can't make request to nginx container from dind container\")\n\t\trequire.Zerof(t, i, \"Can't make request to nginx container from dind container\")\n\t}\n\n\thitNginx()\n\ttime.Sleep(time.Second * 1)\n\tmsgs := consumer.Msgs()\n\trequire.Equalf(t, 1, len(msgs)-existingLogs, \"logConsumer should have 1 new log message, instead has: %v\", msgs[existingLogs:])\n\texistingLogs = len(consumer.Msgs())\n\n\tiptableArgs := []string{\n\t\t\"INPUT\", \"-p\", \"tcp\", \"--dport\", \"2375\",\n\t\t\"-j\", \"REJECT\", \"--reject-with\", \"tcp-reset\",\n\t}\n\t// Simulate a transient closed connection to the docker daemon\n\ti, _, err := dind.Exec(ctx, append([]string{\"iptables\", \"-A\"}, iptableArgs...))\n\trequire.NoErrorf(t, err, \"Failed to close connection to dind daemon: i(%d), err %v\", i, err)\n\trequire.Zerof(t, i, \"Failed to close connection to dind daemon: i(%d), err %v\", i, err)\n\ti, _, err = dind.Exec(ctx, append([]string{\"iptables\", \"-D\"}, iptableArgs...))\n\trequire.NoErrorf(t, err, \"Failed to re-open connection to dind daemon: i(%d), err %v\", i, err)\n\trequire.Zerof(t, i, \"Failed to re-open connection to dind daemon: i(%d), err %v\", i, err)\n\ttime.Sleep(time.Second * 3)\n\n\thitNginx()\n\thitNginx()\n\ttime.Sleep(time.Second * 1)\n\tmsgs = consumer.Msgs()\n\trequire.Equalf(t, 2, len(msgs)-existingLogs,\n\t\t\"LogConsumer should have 2 new log messages after detecting closed connection and\"+\n\t\t\t\" re-requesting logs. Instead has:\\n%s\", msgs[existingLogs:],\n\t)\n}\n\nfunc TestContainerLogsShouldBeWithoutStreamHeader(t *testing.T) {\n\tctx := context.Background()\n\treq := ContainerRequest{\n\t\tImage:      \"alpine:latest\",\n\t\tCmd:        []string{\"sh\", \"-c\", \"id -u\"},\n\t\tWaitingFor: wait.ForExit(),\n\t}\n\tctr, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\tCleanupContainer(t, ctr)\n\trequire.NoError(t, err)\n\n\tr, err := ctr.Logs(ctx)\n\trequire.NoError(t, err)\n\tdefer r.Close()\n\tb, err := io.ReadAll(r)\n\trequire.NoError(t, err)\n\tassert.Equal(t, \"0\", strings.TrimSpace(string(b)))\n}\n\nfunc TestContainerLogsEnableAtStart(t *testing.T) {\n\tctx := context.Background()\n\tg := TestLogConsumer{\n\t\tmsgs:     []string{},\n\t\tDone:     make(chan struct{}),\n\t\tAccepted: devNullAcceptorChan(),\n\t}\n\n\t// logConsumersAtRequest {\n\treq := ContainerRequest{\n\t\tFromDockerfile: FromDockerfile{\n\t\t\tContext:    \"./testdata/\",\n\t\t\tDockerfile: \"echoserver.Dockerfile\",\n\t\t},\n\t\tExposedPorts: []string{\"8080/tcp\"},\n\t\tWaitingFor:   wait.ForLog(\"ready\"),\n\t\tLogConsumerCfg: &LogConsumerConfig{\n\t\t\tOpts:      []LogProductionOption{WithLogProductionTimeout(10 * time.Second)},\n\t\t\tConsumers: []LogConsumer{&g},\n\t\t},\n\t}\n\t// }\n\n\tgReq := GenericContainerRequest{\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t}\n\n\tc, err := GenericContainer(ctx, gReq)\n\tCleanupContainer(t, c)\n\trequire.NoError(t, err)\n\n\tep, err := c.Endpoint(ctx, \"http\")\n\trequire.NoError(t, err)\n\n\t_, err = http.Get(ep + \"/stdout?echo=hello\")\n\trequire.NoError(t, err)\n\n\t_, err = http.Get(ep + \"/stdout?echo=there\")\n\trequire.NoError(t, err)\n\n\t_, err = http.Get(ep + \"/stdout?echo=\" + lastMessage)\n\trequire.NoError(t, err)\n\n\tselect {\n\tcase <-g.Done:\n\tcase <-time.After(10 * time.Second):\n\t\tt.Fatal(\"never received final log message\")\n\t}\n\trequire.Equal(t, []string{\"ready\\n\", \"echo hello\\n\", \"echo there\\n\"}, g.Msgs())\n}\n\nfunc Test_StartLogProductionStillStartsWithTooLowTimeout(t *testing.T) {\n\tctx := context.Background()\n\n\tg := TestLogConsumer{\n\t\tmsgs:     []string{},\n\t\tDone:     make(chan struct{}),\n\t\tAccepted: devNullAcceptorChan(),\n\t}\n\n\treq := ContainerRequest{\n\t\tFromDockerfile: FromDockerfile{\n\t\t\tContext:    \"./testdata/\",\n\t\t\tDockerfile: \"echoserver.Dockerfile\",\n\t\t},\n\t\tExposedPorts: []string{\"8080/tcp\"},\n\t\tWaitingFor:   wait.ForLog(\"ready\"),\n\t\tLogConsumerCfg: &LogConsumerConfig{\n\t\t\tOpts:      []LogProductionOption{WithLogProductionTimeout(4 * time.Second)},\n\t\t\tConsumers: []LogConsumer{&g},\n\t\t},\n\t}\n\n\tgReq := GenericContainerRequest{\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t}\n\n\tc, err := GenericContainer(ctx, gReq)\n\tCleanupContainer(t, c)\n\trequire.NoError(t, err)\n}\n\nfunc Test_StartLogProductionStillStartsWithTooHighTimeout(t *testing.T) {\n\tctx := context.Background()\n\n\tg := TestLogConsumer{\n\t\tmsgs:     []string{},\n\t\tDone:     make(chan struct{}),\n\t\tAccepted: devNullAcceptorChan(),\n\t}\n\n\treq := ContainerRequest{\n\t\tFromDockerfile: FromDockerfile{\n\t\t\tContext:    \"./testdata/\",\n\t\t\tDockerfile: \"echoserver.Dockerfile\",\n\t\t},\n\t\tExposedPorts: []string{\"8080/tcp\"},\n\t\tWaitingFor:   wait.ForLog(\"ready\"),\n\t\tLogConsumerCfg: &LogConsumerConfig{\n\t\t\tOpts:      []LogProductionOption{WithLogProductionTimeout(61 * time.Second)},\n\t\t\tConsumers: []LogConsumer{&g},\n\t\t},\n\t}\n\n\tgReq := GenericContainerRequest{\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t}\n\n\tc, err := GenericContainer(ctx, gReq)\n\tCleanupContainer(t, c)\n\trequire.NoError(t, err)\n\trequire.NotNil(t, c)\n\n\tdc := c.(*DockerContainer)\n\trequire.NoError(t, dc.stopLogProduction())\n}\n\n// bufLogger is a Logging implementation that writes to a bytes.Buffer.\ntype bufLogger struct {\n\tmtx sync.Mutex\n\tbuf bytes.Buffer\n}\n\n// Printf implements Logging.\nfunc (l *bufLogger) Printf(format string, v ...any) {\n\tl.mtx.Lock()\n\tdefer l.mtx.Unlock()\n\n\tfmt.Fprintf(&l.buf, format, v...)\n}\n\n// String returns the contents of the buffer as a string.\nfunc (l *bufLogger) String() string {\n\tl.mtx.Lock()\n\tdefer l.mtx.Unlock()\n\n\treturn l.buf.String()\n}\n\nfunc Test_MultiContainerLogConsumer_CancelledContext(t *testing.T) {\n\t// Capture global logger.\n\tlogger := &bufLogger{}\n\tLogger = logger\n\toldLogger := Logger\n\tt.Cleanup(func() {\n\t\tLogger = oldLogger\n\t})\n\n\t// Context with cancellation functionality for simulating user interruption\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel() // Ensure it gets called.\n\n\tfirst := TestLogConsumer{\n\t\tmsgs:     []string{},\n\t\tDone:     make(chan struct{}),\n\t\tAccepted: devNullAcceptorChan(),\n\t}\n\n\tcontainerReq1 := ContainerRequest{\n\t\tFromDockerfile: FromDockerfile{\n\t\t\tContext:    \"./testdata/\",\n\t\t\tDockerfile: \"echoserver.Dockerfile\",\n\t\t},\n\t\tExposedPorts: []string{\"8080/tcp\"},\n\t\tWaitingFor:   wait.ForLog(\"ready\"),\n\t\tLogConsumerCfg: &LogConsumerConfig{\n\t\t\tConsumers: []LogConsumer{&first},\n\t\t},\n\t}\n\n\tgenericReq1 := GenericContainerRequest{\n\t\tContainerRequest: containerReq1,\n\t\tStarted:          true,\n\t}\n\n\tc, err := GenericContainer(ctx, genericReq1)\n\tCleanupContainer(t, c)\n\trequire.NoError(t, err)\n\n\tep1, err := c.Endpoint(ctx, \"http\")\n\trequire.NoError(t, err)\n\n\t_, err = http.Get(ep1 + \"/stdout?echo=hello1\")\n\trequire.NoError(t, err)\n\n\t_, err = http.Get(ep1 + \"/stdout?echo=there1\")\n\trequire.NoError(t, err)\n\n\tsecond := TestLogConsumer{\n\t\tmsgs:     []string{},\n\t\tDone:     make(chan struct{}),\n\t\tAccepted: devNullAcceptorChan(),\n\t}\n\n\tcontainerReq2 := ContainerRequest{\n\t\tFromDockerfile: FromDockerfile{\n\t\t\tContext:    \"./testdata/\",\n\t\t\tDockerfile: \"echoserver.Dockerfile\",\n\t\t},\n\t\tExposedPorts: []string{\"8080/tcp\"},\n\t\tWaitingFor:   wait.ForLog(\"ready\"),\n\t\tLogConsumerCfg: &LogConsumerConfig{\n\t\t\tConsumers: []LogConsumer{&second},\n\t\t},\n\t}\n\n\tgenericReq2 := GenericContainerRequest{\n\t\tContainerRequest: containerReq2,\n\t\tStarted:          true,\n\t}\n\n\tc2, err := GenericContainer(ctx, genericReq2)\n\tCleanupContainer(t, c2)\n\trequire.NoError(t, err)\n\n\tep2, err := c2.Endpoint(ctx, \"http\")\n\trequire.NoError(t, err)\n\n\t_, err = http.Get(ep2 + \"/stdout?echo=hello2\")\n\trequire.NoError(t, err)\n\n\t_, err = http.Get(ep2 + \"/stdout?echo=there2\")\n\trequire.NoError(t, err)\n\n\t// Deliberately calling context cancel\n\tcancel()\n\n\t// We check log size due to context cancellation causing\n\t// varying message counts, leading to test failure.\n\trequire.GreaterOrEqual(t, len(first.Msgs()), 2)\n\trequire.GreaterOrEqual(t, len(second.Msgs()), 2)\n\n\trequire.NotContains(t, logger.String(), \"Unexpected error reading logs\")\n}\n\n// FooLogConsumer is a test log consumer that accepts logs from the\n// \"hello-world\" Docker image, which prints out the \"Hello from Docker!\"\n// log message.\ntype FooLogConsumer struct {\n\tLogChannel chan string\n\tt          *testing.T\n}\n\n// Accept receives a log message and sends it to the log channel if it\n// contains the \"Hello from Docker!\" message.\nfunc (c FooLogConsumer) Accept(rawLog Log) {\n\tlog := string(rawLog.Content)\n\tif strings.Contains(log, \"Hello from Docker!\") {\n\t\tselect {\n\t\tcase c.LogChannel <- log:\n\t\tdefault:\n\t\t}\n\t}\n}\n\n// AssertRead waits for a log message to be received.\nfunc (c FooLogConsumer) AssertRead() {\n\tselect {\n\tcase <-c.LogChannel:\n\tcase <-time.After(5 * time.Second):\n\t\tc.t.Fatal(\"receive timeout\")\n\t}\n}\n\n// SlurpOne reads a value from the channel if it is available.\nfunc (c FooLogConsumer) SlurpOne() {\n\tselect {\n\tcase <-c.LogChannel:\n\tdefault:\n\t}\n}\n\nfunc NewFooLogConsumer(t *testing.T) *FooLogConsumer {\n\tt.Helper()\n\n\treturn &FooLogConsumer{\n\t\tt:          t,\n\t\tLogChannel: make(chan string, 2),\n\t}\n}\n\nfunc TestRestartContainerWithLogConsumer(t *testing.T) {\n\tlogConsumer := NewFooLogConsumer(t)\n\n\tctx := context.Background()\n\tctr, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage:           \"hello-world\",\n\t\t\tAlwaysPullImage: true,\n\t\t\tLogConsumerCfg: &LogConsumerConfig{\n\t\t\t\tConsumers: []LogConsumer{logConsumer},\n\t\t\t},\n\t\t},\n\t\tStarted: false,\n\t})\n\tCleanupContainer(t, ctr)\n\trequire.NoError(t, err)\n\n\t// Start and confirm that the log consumer receives the log message.\n\terr = ctr.Start(ctx)\n\trequire.NoError(t, err)\n\n\tlogConsumer.AssertRead()\n\n\t// Stop the container and clear any pending message.\n\td := 5 * time.Second\n\terr = ctr.Stop(ctx, &d)\n\trequire.NoError(t, err)\n\n\tlogConsumer.SlurpOne()\n\n\t// Restart the container and confirm that the log consumer receives new log messages.\n\terr = ctr.Start(ctx)\n\trequire.NoError(t, err)\n\n\t// First message is from the first start.\n\tlogConsumer.AssertRead()\n\tlogConsumer.AssertRead()\n}\n"
        },
        {
          "name": "logger.go",
          "type": "blob",
          "size": 2.6142578125,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\t\"log\"\n\t\"os\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/docker/docker/client\"\n)\n\n// Logger is the default log instance\nvar Logger Logging = &noopLogger{}\n\nfunc init() {\n\t// Enable default logger in the testing with a verbose flag.\n\tif testing.Testing() {\n\t\t// Parse manually because testing.Verbose() panics unless flag.Parse() has done.\n\t\tfor _, arg := range os.Args {\n\t\t\tif strings.EqualFold(arg, \"-test.v=true\") || strings.EqualFold(arg, \"-v\") {\n\t\t\t\tLogger = log.New(os.Stderr, \"\", log.LstdFlags)\n\t\t\t}\n\t\t}\n\t}\n}\n\n// Validate our types implement the required interfaces.\nvar (\n\t_ Logging               = (*log.Logger)(nil)\n\t_ ContainerCustomizer   = LoggerOption{}\n\t_ GenericProviderOption = LoggerOption{}\n\t_ DockerProviderOption  = LoggerOption{}\n)\n\n// Logging defines the Logger interface\ntype Logging interface {\n\tPrintf(format string, v ...interface{})\n}\n\ntype noopLogger struct{}\n\n// Printf implements Logging.\nfunc (n noopLogger) Printf(format string, v ...interface{}) {\n\t// NOOP\n}\n\n// Deprecated: this function will be removed in a future release\n// LogDockerServerInfo logs the docker server info using the provided logger and Docker client\nfunc LogDockerServerInfo(ctx context.Context, client client.APIClient, logger Logging) {\n\t// NOOP\n}\n\n// TestLogger returns a Logging implementation for testing.TB\n// This way logs from testcontainers are part of the test output of a test suite or test case.\nfunc TestLogger(tb testing.TB) Logging {\n\ttb.Helper()\n\treturn testLogger{TB: tb}\n}\n\n// WithLogger returns a generic option that sets the logger to be used.\n//\n// Consider calling this before other \"With functions\" as these may generate logs.\n//\n// This can be given a TestLogger to collect the logs from testcontainers into a\n// test case.\nfunc WithLogger(logger Logging) LoggerOption {\n\treturn LoggerOption{\n\t\tlogger: logger,\n\t}\n}\n\n// LoggerOption is a generic option that sets the logger to be used.\n//\n// It can be used to set the logger for providers and containers.\ntype LoggerOption struct {\n\tlogger Logging\n}\n\n// ApplyGenericTo implements GenericProviderOption.\nfunc (o LoggerOption) ApplyGenericTo(opts *GenericProviderOptions) {\n\topts.Logger = o.logger\n}\n\n// ApplyDockerTo implements DockerProviderOption.\nfunc (o LoggerOption) ApplyDockerTo(opts *DockerProviderOptions) {\n\topts.Logger = o.logger\n}\n\n// Customize implements ContainerCustomizer.\nfunc (o LoggerOption) Customize(req *GenericContainerRequest) error {\n\treq.Logger = o.logger\n\treturn nil\n}\n\ntype testLogger struct {\n\ttesting.TB\n}\n\n// Printf implements Logging.\nfunc (t testLogger) Printf(format string, v ...interface{}) {\n\tt.Helper()\n\tt.Logf(format, v...)\n}\n"
        },
        {
          "name": "logger_test.go",
          "type": "blob",
          "size": 0.6806640625,
          "content": "package testcontainers\n\nimport (\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc TestWithLogger(t *testing.T) {\n\tlogger := TestLogger(t)\n\tlogOpt := WithLogger(logger)\n\tt.Run(\"container\", func(t *testing.T) {\n\t\tvar req GenericContainerRequest\n\t\trequire.NoError(t, logOpt.Customize(&req))\n\t\trequire.Equal(t, logger, req.Logger)\n\t})\n\n\tt.Run(\"provider\", func(t *testing.T) {\n\t\tvar opts GenericProviderOptions\n\t\tlogOpt.ApplyGenericTo(&opts)\n\t\trequire.Equal(t, logger, opts.Logger)\n\t})\n\n\tt.Run(\"docker\", func(t *testing.T) {\n\t\topts := &DockerProviderOptions{\n\t\t\tGenericProviderOptions: &GenericProviderOptions{},\n\t\t}\n\t\tlogOpt.ApplyDockerTo(opts)\n\t\trequire.Equal(t, logger, opts.Logger)\n\t})\n}\n"
        },
        {
          "name": "mkdocs.yml",
          "type": "blob",
          "size": 4.44140625,
          "content": "# This file is autogenerated by the 'modulegen' tool.\nsite_name: Testcontainers for Go\nsite_url: https://golang.testcontainers.org\nplugins:\n    - search\n    - codeinclude\n    - include-markdown\n    - markdownextradata\ntheme:\n    name: material\n    custom_dir: docs/theme\n    palette:\n        scheme: testcontainers\n    font:\n        text: Roboto\n        code: Roboto Mono\n    logo: logo.svg\n    favicon: favicon.ico\nextra_css:\n    - css/extra.css\n    - css/tc-header.css\nrepo_name: testcontainers-go\nrepo_url: https://github.com/testcontainers/testcontainers-go\nmarkdown_extensions:\n    - admonition\n    - codehilite:\n        linenums: false\n    - pymdownx.superfences\n    - pymdownx.tabbed:\n        alternate_style: true\n    - pymdownx.snippets\n    - toc:\n        permalink: true\n    - attr_list\n    - pymdownx.emoji:\n        emoji_generator: !!python/name:material.extensions.emoji.to_svg\n        emoji_index: !!python/name:material.extensions.emoji.twemoji\nnav:\n    - Home: index.md\n    - Quickstart: quickstart.md\n    - Features:\n        - features/creating_container.md\n        - features/configuration.md\n        - features/image_name_substitution.md\n        - features/files_and_mounts.md\n        - features/creating_networks.md\n        - features/networking.md\n        - features/tls.md\n        - features/test_session_semantics.md\n        - features/garbage_collector.md\n        - features/build_from_dockerfile.md\n        - features/docker_auth.md\n        - features/docker_compose.md\n        - features/follow_logs.md\n        - features/override_container_command.md\n        - Wait Strategies:\n            - Introduction: features/wait/introduction.md\n            - Exec: features/wait/exec.md\n            - Exit: features/wait/exit.md\n            - File: features/wait/file.md\n            - Health: features/wait/health.md\n            - HostPort: features/wait/host_port.md\n            - HTTP: features/wait/http.md\n            - Log: features/wait/log.md\n            - Multi: features/wait/multi.md\n            - SQL: features/wait/sql.md\n            - TLS: features/wait/tls.md\n            - Walk: features/wait/walk.md\n    - Modules:\n        - modules/index.md\n        - modules/artemis.md\n        - modules/azurite.md\n        - modules/cassandra.md\n        - modules/chroma.md\n        - modules/clickhouse.md\n        - modules/cockroachdb.md\n        - modules/consul.md\n        - modules/couchbase.md\n        - modules/databend.md\n        - modules/dolt.md\n        - modules/dynamodb.md\n        - modules/elasticsearch.md\n        - modules/etcd.md\n        - modules/gcloud.md\n        - modules/grafana-lgtm.md\n        - modules/inbucket.md\n        - modules/influxdb.md\n        - modules/k3s.md\n        - modules/k6.md\n        - modules/kafka.md\n        - modules/localstack.md\n        - modules/mariadb.md\n        - modules/meilisearch.md\n        - modules/milvus.md\n        - modules/minio.md\n        - modules/mockserver.md\n        - modules/mongodb.md\n        - modules/mssql.md\n        - modules/mysql.md\n        - modules/nats.md\n        - modules/neo4j.md\n        - modules/ollama.md\n        - modules/openfga.md\n        - modules/openldap.md\n        - modules/opensearch.md\n        - modules/postgres.md\n        - modules/pulsar.md\n        - modules/qdrant.md\n        - modules/rabbitmq.md\n        - modules/redis.md\n        - modules/redpanda.md\n        - modules/registry.md\n        - modules/surrealdb.md\n        - modules/valkey.md\n        - modules/vault.md\n        - modules/vearch.md\n        - modules/weaviate.md\n        - modules/yugabytedb.md\n    - Examples:\n        - examples/index.md\n        - examples/nginx.md\n        - examples/toxiproxy.md\n    - System Requirements:\n        - system_requirements/index.md\n        - system_requirements/docker.md\n        - Continuous Integration:\n            - system_requirements/ci/aws_codebuild.md\n            - system_requirements/ci/bitbucket_pipelines.md\n            - system_requirements/ci/circle_ci.md\n            - system_requirements/ci/concourse_ci.md\n            - system_requirements/ci/dind_patterns.md\n            - system_requirements/ci/drone.md\n            - system_requirements/ci/gitlab_ci.md\n            - system_requirements/ci/tekton.md\n            - system_requirements/ci/travis.md\n        - system_requirements/using_colima.md\n        - system_requirements/using_podman.md\n        - system_requirements/rancher.md\n    - Contributing: contributing.md\n    - Getting help: getting_help.md\nedit_uri: edit/main/docs/\nextra:\n    latest_version: v0.35.0\n"
        },
        {
          "name": "modulegen",
          "type": "tree",
          "content": null
        },
        {
          "name": "modules",
          "type": "tree",
          "content": null
        },
        {
          "name": "mounts.go",
          "type": "blob",
          "size": 4.4833984375,
          "content": "package testcontainers\n\nimport \"errors\"\n\nconst (\n\tMountTypeBind MountType = iota // Deprecated: Use MountTypeVolume instead\n\tMountTypeVolume\n\tMountTypeTmpfs\n\tMountTypePipe\n)\n\nvar (\n\tErrDuplicateMountTarget = errors.New(\"duplicate mount target detected\")\n\tErrInvalidBindMount     = errors.New(\"invalid bind mount\")\n)\n\nvar (\n\t_ ContainerMountSource = (*GenericBindMountSource)(nil) // Deprecated: use Files or HostConfigModifier in the ContainerRequest, or copy files container APIs to make containers portable across Docker environments\n\t_ ContainerMountSource = (*GenericVolumeMountSource)(nil)\n\t_ ContainerMountSource = (*GenericTmpfsMountSource)(nil)\n)\n\ntype (\n\t// ContainerMounts represents a collection of mounts for a container\n\tContainerMounts []ContainerMount\n\tMountType       uint\n)\n\n// ContainerMountSource is the base for all mount sources\ntype ContainerMountSource interface {\n\t// Source will be used as Source field in the final mount\n\t// this might either be a volume name, a host path or might be empty e.g. for Tmpfs\n\tSource() string\n\n\t// Type determines the final mount type\n\t// possible options are limited by the Docker API\n\tType() MountType\n}\n\n// Deprecated: use Files or HostConfigModifier in the ContainerRequest, or copy files container APIs to make containers portable across Docker environments\n// GenericBindMountSource implements ContainerMountSource and represents a bind mount\n// Optionally mount.BindOptions might be added for advanced scenarios\ntype GenericBindMountSource struct {\n\t// HostPath is the path mounted into the container\n\t// the same host path might be mounted to multiple locations within a single container\n\tHostPath string\n}\n\n// Deprecated: use Files or HostConfigModifier in the ContainerRequest, or copy files container APIs to make containers portable across Docker environments\nfunc (s GenericBindMountSource) Source() string {\n\treturn s.HostPath\n}\n\n// Deprecated: use Files or HostConfigModifier in the ContainerRequest, or copy files container APIs to make containers portable across Docker environments\nfunc (GenericBindMountSource) Type() MountType {\n\treturn MountTypeBind\n}\n\n// GenericVolumeMountSource implements ContainerMountSource and represents a volume mount\ntype GenericVolumeMountSource struct {\n\t// Name refers to the name of the volume to be mounted\n\t// the same volume might be mounted to multiple locations within a single container\n\tName string\n}\n\nfunc (s GenericVolumeMountSource) Source() string {\n\treturn s.Name\n}\n\nfunc (GenericVolumeMountSource) Type() MountType {\n\treturn MountTypeVolume\n}\n\n// GenericTmpfsMountSource implements ContainerMountSource and represents a TmpFS mount\n// Optionally mount.TmpfsOptions might be added for advanced scenarios\ntype GenericTmpfsMountSource struct{}\n\nfunc (s GenericTmpfsMountSource) Source() string {\n\treturn \"\"\n}\n\nfunc (GenericTmpfsMountSource) Type() MountType {\n\treturn MountTypeTmpfs\n}\n\n// ContainerMountTarget represents the target path within a container where the mount will be available\n// Note that mount targets must be unique. It's not supported to mount different sources to the same target.\ntype ContainerMountTarget string\n\nfunc (t ContainerMountTarget) Target() string {\n\treturn string(t)\n}\n\n// Deprecated: use Files or HostConfigModifier in the ContainerRequest, or copy files container APIs to make containers portable across Docker environments\n// BindMount returns a new ContainerMount with a GenericBindMountSource as source\n// This is a convenience method to cover typical use cases.\nfunc BindMount(hostPath string, mountTarget ContainerMountTarget) ContainerMount {\n\treturn ContainerMount{\n\t\tSource: GenericBindMountSource{HostPath: hostPath},\n\t\tTarget: mountTarget,\n\t}\n}\n\n// VolumeMount returns a new ContainerMount with a GenericVolumeMountSource as source\n// This is a convenience method to cover typical use cases.\nfunc VolumeMount(volumeName string, mountTarget ContainerMountTarget) ContainerMount {\n\treturn ContainerMount{\n\t\tSource: GenericVolumeMountSource{Name: volumeName},\n\t\tTarget: mountTarget,\n\t}\n}\n\n// Mounts returns a ContainerMounts to support a more fluent API\nfunc Mounts(mounts ...ContainerMount) ContainerMounts {\n\treturn mounts\n}\n\n// ContainerMount models a mount into a container\ntype ContainerMount struct {\n\t// Source is typically either a GenericVolumeMountSource, as BindMount is not supported by all Docker environments\n\tSource ContainerMountSource\n\t// Target is the path where the mount should be mounted within the container\n\tTarget ContainerMountTarget\n\t// ReadOnly determines if the mount should be read-only\n\tReadOnly bool\n}\n"
        },
        {
          "name": "mounts_test.go",
          "type": "blob",
          "size": 6.046875,
          "content": "package testcontainers_test\n\nimport (\n\t\"context\"\n\t\"testing\"\n\n\t\"github.com/docker/docker/api/types/mount\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/testcontainers/testcontainers-go\"\n)\n\nfunc TestVolumeMount(t *testing.T) {\n\tt.Parallel()\n\ttype args struct {\n\t\tvolumeName  string\n\t\tmountTarget testcontainers.ContainerMountTarget\n\t}\n\ttests := []struct {\n\t\tname string\n\t\targs args\n\t\twant testcontainers.ContainerMount\n\t}{\n\t\t{\n\t\t\tname: \"sample-data:/data\",\n\t\t\targs: args{volumeName: \"sample-data\", mountTarget: \"/data\"},\n\t\t\twant: testcontainers.ContainerMount{Source: testcontainers.GenericVolumeMountSource{Name: \"sample-data\"}, Target: \"/data\"},\n\t\t},\n\t\t{\n\t\t\tname: \"web:/var/nginx/html\",\n\t\t\targs: args{volumeName: \"web\", mountTarget: \"/var/nginx/html\"},\n\t\t\twant: testcontainers.ContainerMount{Source: testcontainers.GenericVolumeMountSource{Name: \"web\"}, Target: \"/var/nginx/html\"},\n\t\t},\n\t}\n\tfor _, tt := range tests {\n\t\ttt := tt\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\t\t\tassert.Equalf(t, tt.want, testcontainers.VolumeMount(tt.args.volumeName, tt.args.mountTarget), \"VolumeMount(%v, %v)\", tt.args.volumeName, tt.args.mountTarget)\n\t\t})\n\t}\n}\n\nfunc TestContainerMounts_PrepareMounts(t *testing.T) {\n\tvolumeOptions := &mount.VolumeOptions{\n\t\tLabels: testcontainers.GenericLabels(),\n\t}\n\n\texpectedLabels := testcontainers.GenericLabels()\n\texpectedLabels[\"hello\"] = \"world\"\n\n\tt.Parallel()\n\ttests := []struct {\n\t\tname   string\n\t\tmounts testcontainers.ContainerMounts\n\t\twant   []mount.Mount\n\t}{\n\t\t{\n\t\t\tname:   \"Empty\",\n\t\t\tmounts: nil,\n\t\t\twant:   make([]mount.Mount, 0),\n\t\t},\n\t\t{\n\t\t\tname:   \"Single volume mount\",\n\t\t\tmounts: testcontainers.ContainerMounts{{Source: testcontainers.GenericVolumeMountSource{Name: \"app-data\"}, Target: \"/data\"}},\n\t\t\twant: []mount.Mount{\n\t\t\t\t{\n\t\t\t\t\tType:          mount.TypeVolume,\n\t\t\t\t\tSource:        \"app-data\",\n\t\t\t\t\tTarget:        \"/data\",\n\t\t\t\t\tVolumeOptions: volumeOptions,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:   \"Single volume mount - read-only\",\n\t\t\tmounts: testcontainers.ContainerMounts{{Source: testcontainers.GenericVolumeMountSource{Name: \"app-data\"}, Target: \"/data\", ReadOnly: true}},\n\t\t\twant: []mount.Mount{\n\t\t\t\t{\n\t\t\t\t\tType:          mount.TypeVolume,\n\t\t\t\t\tSource:        \"app-data\",\n\t\t\t\t\tTarget:        \"/data\",\n\t\t\t\t\tReadOnly:      true,\n\t\t\t\t\tVolumeOptions: volumeOptions,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"Single volume mount - with options\",\n\t\t\tmounts: testcontainers.ContainerMounts{\n\t\t\t\t{\n\t\t\t\t\tSource: testcontainers.DockerVolumeMountSource{\n\t\t\t\t\t\tName: \"app-data\",\n\t\t\t\t\t\tVolumeOptions: &mount.VolumeOptions{\n\t\t\t\t\t\t\tNoCopy: true,\n\t\t\t\t\t\t\tLabels: map[string]string{\n\t\t\t\t\t\t\t\t\"hello\": \"world\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tTarget: \"/data\",\n\t\t\t\t},\n\t\t\t},\n\t\t\twant: []mount.Mount{\n\t\t\t\t{\n\t\t\t\t\tType:   mount.TypeVolume,\n\t\t\t\t\tSource: \"app-data\",\n\t\t\t\t\tTarget: \"/data\",\n\t\t\t\t\tVolumeOptions: &mount.VolumeOptions{\n\t\t\t\t\t\tNoCopy: true,\n\t\t\t\t\t\tLabels: expectedLabels,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\n\t\t{\n\t\t\tname:   \"Single tmpfs mount\",\n\t\t\tmounts: testcontainers.ContainerMounts{{Source: testcontainers.GenericTmpfsMountSource{}, Target: \"/data\"}},\n\t\t\twant: []mount.Mount{\n\t\t\t\t{\n\t\t\t\t\tType:   mount.TypeTmpfs,\n\t\t\t\t\tTarget: \"/data\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:   \"Single volume mount - read-only\",\n\t\t\tmounts: testcontainers.ContainerMounts{{Source: testcontainers.GenericTmpfsMountSource{}, Target: \"/data\", ReadOnly: true}},\n\t\t\twant: []mount.Mount{\n\t\t\t\t{\n\t\t\t\t\tType:     mount.TypeTmpfs,\n\t\t\t\t\tTarget:   \"/data\",\n\t\t\t\t\tReadOnly: true,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"Single tmpfs mount - with options\",\n\t\t\tmounts: testcontainers.ContainerMounts{\n\t\t\t\t{\n\t\t\t\t\tSource: testcontainers.DockerTmpfsMountSource{\n\t\t\t\t\t\tTmpfsOptions: &mount.TmpfsOptions{\n\t\t\t\t\t\t\tSizeBytes: 50 * 1024 * 1024,\n\t\t\t\t\t\t\tMode:      0o644,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tTarget: \"/data\",\n\t\t\t\t},\n\t\t\t},\n\t\t\twant: []mount.Mount{\n\t\t\t\t{\n\t\t\t\t\tType:   mount.TypeTmpfs,\n\t\t\t\t\tTarget: \"/data\",\n\t\t\t\t\tTmpfsOptions: &mount.TmpfsOptions{\n\t\t\t\t\t\tSizeBytes: 50 * 1024 * 1024,\n\t\t\t\t\t\tMode:      0o644,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\tfor _, tt := range tests {\n\t\ttt := tt\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\t\t\tassert.Equalf(t, tt.want, tt.mounts.PrepareMounts(), \"PrepareMounts()\")\n\t\t})\n\t}\n}\n\nfunc TestCreateContainerWithVolume(t *testing.T) {\n\tvolumeName := \"test-volume\"\n\t// volumeMounts {\n\treq := testcontainers.ContainerRequest{\n\t\tImage: \"alpine\",\n\t\tMounts: testcontainers.ContainerMounts{\n\t\t\t{\n\t\t\t\tSource: testcontainers.GenericVolumeMountSource{\n\t\t\t\t\tName: volumeName,\n\t\t\t\t},\n\t\t\t\tTarget: \"/data\",\n\t\t\t},\n\t\t},\n\t}\n\t// }\n\n\tctx := context.Background()\n\tc, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\ttestcontainers.CleanupContainer(t, c, testcontainers.RemoveVolumes(volumeName))\n\trequire.NoError(t, err)\n\n\t// Check if volume is created\n\tclient, err := testcontainers.NewDockerClientWithOpts(ctx)\n\trequire.NoError(t, err)\n\tdefer client.Close()\n\n\tvolume, err := client.VolumeInspect(ctx, \"test-volume\")\n\trequire.NoError(t, err)\n\tassert.Equal(t, \"test-volume\", volume.Name)\n}\n\nfunc TestMountsReceiveRyukLabels(t *testing.T) {\n\tvolumeName := \"app-data\"\n\treq := testcontainers.ContainerRequest{\n\t\tImage: \"alpine\",\n\t\tMounts: testcontainers.ContainerMounts{\n\t\t\t{\n\t\t\t\tSource: testcontainers.GenericVolumeMountSource{\n\t\t\t\t\tName: volumeName,\n\t\t\t\t},\n\t\t\t\tTarget: \"/data\",\n\t\t\t},\n\t\t},\n\t}\n\n\tctx := context.Background()\n\tclient, err := testcontainers.NewDockerClientWithOpts(ctx)\n\trequire.NoError(t, err)\n\tdefer client.Close()\n\n\t// Ensure the volume is removed before creating the container\n\t// otherwise the volume will be reused and the labels won't be set.\n\terr = client.VolumeRemove(ctx, volumeName, true)\n\trequire.NoError(t, err)\n\n\tc, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{\n\t\tContainerRequest: req,\n\t\tStarted:          true,\n\t})\n\ttestcontainers.CleanupContainer(t, c, testcontainers.RemoveVolumes(volumeName))\n\trequire.NoError(t, err)\n\n\t// Check if volume is created with the expected labels.\n\tvolume, err := client.VolumeInspect(ctx, volumeName)\n\trequire.NoError(t, err)\n\trequire.Equal(t, testcontainers.GenericLabels(), volume.Labels)\n}\n"
        },
        {
          "name": "network.go",
          "type": "blob",
          "size": 2.0791015625,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\n\t\"github.com/docker/docker/api/types/network\"\n\n\t\"github.com/testcontainers/testcontainers-go/internal/core\"\n)\n\n// NetworkProvider allows the creation of networks on an arbitrary system\ntype NetworkProvider interface {\n\tCreateNetwork(context.Context, NetworkRequest) (Network, error)      // create a network\n\tGetNetwork(context.Context, NetworkRequest) (network.Inspect, error) // get a network\n}\n\n// Deprecated: will be removed in the future\n// Network allows getting info about a single network instance\ntype Network interface {\n\tRemove(context.Context) error // removes the network\n}\n\n// Deprecated: will be removed in the future.\ntype DefaultNetwork string\n\n// Deprecated: will be removed in the future.\nfunc (n DefaultNetwork) ApplyGenericTo(opts *GenericProviderOptions) {\n\topts.defaultNetwork = string(n)\n}\n\n// Deprecated: will be removed in the future.\nfunc (n DefaultNetwork) ApplyDockerTo(opts *DockerProviderOptions) {\n\topts.defaultNetwork = string(n)\n}\n\n// Deprecated: will be removed in the future\n// NetworkRequest represents the parameters used to get a network\ntype NetworkRequest struct {\n\tDriver         string\n\tCheckDuplicate bool // Deprecated: CheckDuplicate is deprecated since API v1.44, but it defaults to true when sent by the client package to older daemons.\n\tInternal       bool\n\tEnableIPv6     *bool\n\tName           string\n\tLabels         map[string]string\n\tAttachable     bool\n\tIPAM           *network.IPAM\n\n\tSkipReaper    bool              // Deprecated: The reaper is globally controlled by the .testcontainers.properties file or the TESTCONTAINERS_RYUK_DISABLED environment variable\n\tReaperImage   string            // Deprecated: use WithImageName ContainerOption instead. Alternative reaper registry\n\tReaperOptions []ContainerOption // Deprecated: the reaper is configured at the properties level, for an entire test session\n}\n\n// sessionID returns the session ID for the network request.\nfunc (r NetworkRequest) sessionID() string {\n\tif sessionID := r.Labels[core.LabelSessionID]; sessionID != \"\" {\n\t\treturn sessionID\n\t}\n\n\treturn core.SessionID()\n}\n"
        },
        {
          "name": "network",
          "type": "tree",
          "content": null
        },
        {
          "name": "options.go",
          "type": "blob",
          "size": 10.447265625,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"net/url\"\n\t\"time\"\n\n\t\"dario.cat/mergo\"\n\t\"github.com/docker/docker/api/types/container\"\n\t\"github.com/docker/docker/api/types/network\"\n\n\ttcexec \"github.com/testcontainers/testcontainers-go/exec\"\n\t\"github.com/testcontainers/testcontainers-go/internal/core\"\n\t\"github.com/testcontainers/testcontainers-go/wait\"\n)\n\n// ContainerCustomizer is an interface that can be used to configure the Testcontainers container\n// request. The passed request will be merged with the default one.\ntype ContainerCustomizer interface {\n\tCustomize(req *GenericContainerRequest) error\n}\n\n// CustomizeRequestOption is a type that can be used to configure the Testcontainers container request.\n// The passed request will be merged with the default one.\ntype CustomizeRequestOption func(req *GenericContainerRequest) error\n\nfunc (opt CustomizeRequestOption) Customize(req *GenericContainerRequest) error {\n\treturn opt(req)\n}\n\n// CustomizeRequest returns a function that can be used to merge the passed container request with the one that is used by the container.\n// Slices and Maps will be appended.\nfunc CustomizeRequest(src GenericContainerRequest) CustomizeRequestOption {\n\treturn func(req *GenericContainerRequest) error {\n\t\tif err := mergo.Merge(req, &src, mergo.WithOverride, mergo.WithAppendSlice); err != nil {\n\t\t\treturn fmt.Errorf(\"error merging container request, keeping the original one: %w\", err)\n\t\t}\n\n\t\treturn nil\n\t}\n}\n\n// WithConfigModifier allows to override the default container config\nfunc WithConfigModifier(modifier func(config *container.Config)) CustomizeRequestOption {\n\treturn func(req *GenericContainerRequest) error {\n\t\treq.ConfigModifier = modifier\n\n\t\treturn nil\n\t}\n}\n\n// WithEndpointSettingsModifier allows to override the default endpoint settings\nfunc WithEndpointSettingsModifier(modifier func(settings map[string]*network.EndpointSettings)) CustomizeRequestOption {\n\treturn func(req *GenericContainerRequest) error {\n\t\treq.EnpointSettingsModifier = modifier\n\n\t\treturn nil\n\t}\n}\n\n// WithEnv sets the environment variables for a container.\n// If the environment variable already exists, it will be overridden.\nfunc WithEnv(envs map[string]string) CustomizeRequestOption {\n\treturn func(req *GenericContainerRequest) error {\n\t\tif req.Env == nil {\n\t\t\treq.Env = map[string]string{}\n\t\t}\n\n\t\tfor key, val := range envs {\n\t\t\treq.Env[key] = val\n\t\t}\n\n\t\treturn nil\n\t}\n}\n\n// WithHostConfigModifier allows to override the default host config\nfunc WithHostConfigModifier(modifier func(hostConfig *container.HostConfig)) CustomizeRequestOption {\n\treturn func(req *GenericContainerRequest) error {\n\t\treq.HostConfigModifier = modifier\n\n\t\treturn nil\n\t}\n}\n\n// WithHostPortAccess allows to expose the host ports to the container\nfunc WithHostPortAccess(ports ...int) CustomizeRequestOption {\n\treturn func(req *GenericContainerRequest) error {\n\t\tif req.HostAccessPorts == nil {\n\t\t\treq.HostAccessPorts = []int{}\n\t\t}\n\n\t\treq.HostAccessPorts = append(req.HostAccessPorts, ports...)\n\t\treturn nil\n\t}\n}\n\n// Deprecated: the modules API forces passing the image as part of the signature of the Run function.\n// WithImage sets the image for a container\nfunc WithImage(image string) CustomizeRequestOption {\n\treturn func(req *GenericContainerRequest) error {\n\t\treq.Image = image\n\n\t\treturn nil\n\t}\n}\n\n// imageSubstitutor {\n\n// ImageSubstitutor represents a way to substitute container image names\ntype ImageSubstitutor interface {\n\t// Description returns the name of the type and a short description of how it modifies the image.\n\t// Useful to be printed in logs\n\tDescription() string\n\tSubstitute(image string) (string, error)\n}\n\n// }\n\n// CustomHubSubstitutor represents a way to substitute the hub of an image with a custom one,\n// using provided value with respect to the HubImageNamePrefix configuration value.\ntype CustomHubSubstitutor struct {\n\thub string\n}\n\n// NewCustomHubSubstitutor creates a new CustomHubSubstitutor\nfunc NewCustomHubSubstitutor(hub string) CustomHubSubstitutor {\n\treturn CustomHubSubstitutor{\n\t\thub: hub,\n\t}\n}\n\n// Description returns the name of the type and a short description of how it modifies the image.\nfunc (c CustomHubSubstitutor) Description() string {\n\treturn fmt.Sprintf(\"CustomHubSubstitutor (replaces hub with %s)\", c.hub)\n}\n\n// Substitute replaces the hub of the image with the provided one, with certain conditions:\n//   - if the hub is empty, the image is returned as is.\n//   - if the image already contains a registry, the image is returned as is.\n//   - if the HubImageNamePrefix configuration value is set, the image is returned as is.\nfunc (c CustomHubSubstitutor) Substitute(image string) (string, error) {\n\tregistry := core.ExtractRegistry(image, \"\")\n\tcfg := ReadConfig()\n\n\texclusions := []func() bool{\n\t\tfunc() bool { return c.hub == \"\" },\n\t\tfunc() bool { return registry != \"\" },\n\t\tfunc() bool { return cfg.Config.HubImageNamePrefix != \"\" },\n\t}\n\n\tfor _, exclusion := range exclusions {\n\t\tif exclusion() {\n\t\t\treturn image, nil\n\t\t}\n\t}\n\n\tresult, err := url.JoinPath(c.hub, image)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn result, nil\n}\n\n// prependHubRegistry represents a way to prepend a custom Hub registry to the image name,\n// using the HubImageNamePrefix configuration value\ntype prependHubRegistry struct {\n\tprefix string\n}\n\n// newPrependHubRegistry creates a new prependHubRegistry\nfunc newPrependHubRegistry(hubPrefix string) prependHubRegistry {\n\treturn prependHubRegistry{\n\t\tprefix: hubPrefix,\n\t}\n}\n\n// Description returns the name of the type and a short description of how it modifies the image.\nfunc (p prependHubRegistry) Description() string {\n\treturn fmt.Sprintf(\"HubImageSubstitutor (prepends %s)\", p.prefix)\n}\n\n// Substitute prepends the Hub prefix to the image name, with certain conditions:\n//   - if the prefix is empty, the image is returned as is.\n//   - if the image is a non-hub image (e.g. where another registry is set), the image is returned as is.\n//   - if the image is a Docker Hub image where the hub registry is explicitly part of the name\n//     (i.e. anything with a registry.hub.docker.com host part), the image is returned as is.\nfunc (p prependHubRegistry) Substitute(image string) (string, error) {\n\tregistry := core.ExtractRegistry(image, \"\")\n\n\t// add the exclusions in the right order\n\texclusions := []func() bool{\n\t\tfunc() bool { return p.prefix == \"\" },                        // no prefix set at the configuration level\n\t\tfunc() bool { return registry != \"\" },                        // non-hub image\n\t\tfunc() bool { return registry == \"docker.io\" },               // explicitly including docker.io\n\t\tfunc() bool { return registry == \"registry.hub.docker.com\" }, // explicitly including registry.hub.docker.com\n\t}\n\n\tfor _, exclusion := range exclusions {\n\t\tif exclusion() {\n\t\t\treturn image, nil\n\t\t}\n\t}\n\n\tresult, err := url.JoinPath(p.prefix, image)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn result, nil\n}\n\n// WithImageSubstitutors sets the image substitutors for a container\nfunc WithImageSubstitutors(fn ...ImageSubstitutor) CustomizeRequestOption {\n\treturn func(req *GenericContainerRequest) error {\n\t\treq.ImageSubstitutors = fn\n\n\t\treturn nil\n\t}\n}\n\n// WithLogConsumers sets the log consumers for a container\nfunc WithLogConsumers(consumer ...LogConsumer) CustomizeRequestOption {\n\treturn func(req *GenericContainerRequest) error {\n\t\tif req.LogConsumerCfg == nil {\n\t\t\treq.LogConsumerCfg = &LogConsumerConfig{}\n\t\t}\n\n\t\treq.LogConsumerCfg.Consumers = consumer\n\t\treturn nil\n\t}\n}\n\n// Executable represents an executable command to be sent to a container, including options,\n// as part of the different lifecycle hooks.\ntype Executable interface {\n\tAsCommand() []string\n\t// Options can container two different types of options:\n\t// - Docker's ExecConfigs (WithUser, WithWorkingDir, WithEnv, etc.)\n\t// - testcontainers' ProcessOptions (i.e. Multiplexed response)\n\tOptions() []tcexec.ProcessOption\n}\n\n// ExecOptions is a struct that provides a default implementation for the Options method\n// of the Executable interface.\ntype ExecOptions struct {\n\topts []tcexec.ProcessOption\n}\n\nfunc (ce ExecOptions) Options() []tcexec.ProcessOption {\n\treturn ce.opts\n}\n\n// RawCommand is a type that implements Executable and represents a command to be sent to a container\ntype RawCommand struct {\n\tExecOptions\n\tcmds []string\n}\n\nfunc NewRawCommand(cmds []string) RawCommand {\n\treturn RawCommand{\n\t\tcmds: cmds,\n\t\tExecOptions: ExecOptions{\n\t\t\topts: []tcexec.ProcessOption{},\n\t\t},\n\t}\n}\n\n// AsCommand returns the command as a slice of strings\nfunc (r RawCommand) AsCommand() []string {\n\treturn r.cmds\n}\n\n// WithStartupCommand will execute the command representation of each Executable into the container.\n// It will leverage the container lifecycle hooks to call the command right after the container\n// is started.\nfunc WithStartupCommand(execs ...Executable) CustomizeRequestOption {\n\treturn func(req *GenericContainerRequest) error {\n\t\tstartupCommandsHook := ContainerLifecycleHooks{\n\t\t\tPostStarts: []ContainerHook{},\n\t\t}\n\n\t\tfor _, exec := range execs {\n\t\t\texecFn := func(ctx context.Context, c Container) error {\n\t\t\t\t_, _, err := c.Exec(ctx, exec.AsCommand(), exec.Options()...)\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tstartupCommandsHook.PostStarts = append(startupCommandsHook.PostStarts, execFn)\n\t\t}\n\n\t\treq.LifecycleHooks = append(req.LifecycleHooks, startupCommandsHook)\n\n\t\treturn nil\n\t}\n}\n\n// WithAfterReadyCommand will execute the command representation of each Executable into the container.\n// It will leverage the container lifecycle hooks to call the command right after the container\n// is ready.\nfunc WithAfterReadyCommand(execs ...Executable) CustomizeRequestOption {\n\treturn func(req *GenericContainerRequest) error {\n\t\tpostReadiesHook := []ContainerHook{}\n\n\t\tfor _, exec := range execs {\n\t\t\texecFn := func(ctx context.Context, c Container) error {\n\t\t\t\t_, _, err := c.Exec(ctx, exec.AsCommand(), exec.Options()...)\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tpostReadiesHook = append(postReadiesHook, execFn)\n\t\t}\n\n\t\treq.LifecycleHooks = append(req.LifecycleHooks, ContainerLifecycleHooks{\n\t\t\tPostReadies: postReadiesHook,\n\t\t})\n\n\t\treturn nil\n\t}\n}\n\n// WithWaitStrategy sets the wait strategy for a container, using 60 seconds as deadline\nfunc WithWaitStrategy(strategies ...wait.Strategy) CustomizeRequestOption {\n\treturn WithWaitStrategyAndDeadline(60*time.Second, strategies...)\n}\n\n// WithWaitStrategyAndDeadline sets the wait strategy for a container, including deadline\nfunc WithWaitStrategyAndDeadline(deadline time.Duration, strategies ...wait.Strategy) CustomizeRequestOption {\n\treturn func(req *GenericContainerRequest) error {\n\t\treq.WaitingFor = wait.ForAll(strategies...).WithDeadline(deadline)\n\n\t\treturn nil\n\t}\n}\n"
        },
        {
          "name": "options_test.go",
          "type": "blob",
          "size": 6.6689453125,
          "content": "package testcontainers_test\n\nimport (\n\t\"context\"\n\t\"io\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/testcontainers/testcontainers-go\"\n\t\"github.com/testcontainers/testcontainers-go/exec\"\n\t\"github.com/testcontainers/testcontainers-go/wait\"\n)\n\nfunc TestOverrideContainerRequest(t *testing.T) {\n\treq := testcontainers.GenericContainerRequest{\n\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\tEnv: map[string]string{\n\t\t\t\t\"BAR\": \"BAR\",\n\t\t\t},\n\t\t\tImage:        \"foo\",\n\t\t\tExposedPorts: []string{\"12345/tcp\"},\n\t\t\tWaitingFor: wait.ForNop(\n\t\t\t\tfunc(ctx context.Context, target wait.StrategyTarget) error {\n\t\t\t\t\treturn nil\n\t\t\t\t},\n\t\t\t),\n\t\t\tNetworks: []string{\"foo\", \"bar\", \"baaz\"},\n\t\t\tNetworkAliases: map[string][]string{\n\t\t\t\t\"foo\": {\"foo0\", \"foo1\", \"foo2\", \"foo3\"},\n\t\t\t},\n\t\t},\n\t}\n\n\ttoBeMergedRequest := testcontainers.GenericContainerRequest{\n\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\tEnv: map[string]string{\n\t\t\t\t\"FOO\": \"FOO\",\n\t\t\t},\n\t\t\tImage:        \"bar\",\n\t\t\tExposedPorts: []string{\"67890/tcp\"},\n\t\t\tNetworks:     []string{\"foo1\", \"bar1\"},\n\t\t\tNetworkAliases: map[string][]string{\n\t\t\t\t\"foo1\": {\"bar\"},\n\t\t\t},\n\t\t\tWaitingFor: wait.ForLog(\"foo\"),\n\t\t},\n\t}\n\n\t// the toBeMergedRequest should be merged into the req\n\terr := testcontainers.CustomizeRequest(toBeMergedRequest)(&req)\n\trequire.NoError(t, err)\n\n\t// toBeMergedRequest should not be changed\n\tassert.Equal(t, \"\", toBeMergedRequest.Env[\"BAR\"])\n\trequire.Len(t, toBeMergedRequest.ExposedPorts, 1)\n\tassert.Equal(t, \"67890/tcp\", toBeMergedRequest.ExposedPorts[0])\n\n\t// req should be merged with toBeMergedRequest\n\tassert.Equal(t, \"FOO\", req.Env[\"FOO\"])\n\tassert.Equal(t, \"BAR\", req.Env[\"BAR\"])\n\tassert.Equal(t, \"bar\", req.Image)\n\tassert.Equal(t, []string{\"12345/tcp\", \"67890/tcp\"}, req.ExposedPorts)\n\tassert.Equal(t, []string{\"foo\", \"bar\", \"baaz\", \"foo1\", \"bar1\"}, req.Networks)\n\tassert.Equal(t, []string{\"foo0\", \"foo1\", \"foo2\", \"foo3\"}, req.NetworkAliases[\"foo\"])\n\tassert.Equal(t, []string{\"bar\"}, req.NetworkAliases[\"foo1\"])\n\tassert.Equal(t, wait.ForLog(\"foo\"), req.WaitingFor)\n}\n\ntype msgsLogConsumer struct {\n\tmsgs []string\n}\n\n// Accept prints the log to stdout\nfunc (lc *msgsLogConsumer) Accept(l testcontainers.Log) {\n\tlc.msgs = append(lc.msgs, string(l.Content))\n}\n\nfunc TestWithLogConsumers(t *testing.T) {\n\treq := testcontainers.GenericContainerRequest{\n\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\tImage:      \"mysql:8.0.36\",\n\t\t\tWaitingFor: wait.ForLog(\"port: 3306  MySQL Community Server - GPL\"),\n\t\t},\n\t\tStarted: true,\n\t}\n\n\tlc := &msgsLogConsumer{}\n\n\terr := testcontainers.WithLogConsumers(lc)(&req)\n\trequire.NoError(t, err)\n\n\tctx := context.Background()\n\tc, err := testcontainers.GenericContainer(ctx, req)\n\ttestcontainers.CleanupContainer(t, c)\n\t// we expect an error because the MySQL environment variables are not set\n\t// but this is expected because we just want to test the log consumer\n\trequire.ErrorContains(t, err, \"container exited with code 1\")\n\trequire.NotEmpty(t, lc.msgs)\n}\n\nfunc TestWithStartupCommand(t *testing.T) {\n\treq := testcontainers.GenericContainerRequest{\n\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\tImage:      \"alpine\",\n\t\t\tEntrypoint: []string{\"tail\", \"-f\", \"/dev/null\"},\n\t\t},\n\t\tStarted: true,\n\t}\n\n\ttestExec := testcontainers.NewRawCommand([]string{\"touch\", \"/tmp/.testcontainers\"})\n\n\terr := testcontainers.WithStartupCommand(testExec)(&req)\n\trequire.NoError(t, err)\n\n\trequire.Len(t, req.LifecycleHooks, 1)\n\trequire.Len(t, req.LifecycleHooks[0].PostStarts, 1)\n\n\tc, err := testcontainers.GenericContainer(context.Background(), req)\n\ttestcontainers.CleanupContainer(t, c)\n\trequire.NoError(t, err)\n\n\t_, reader, err := c.Exec(context.Background(), []string{\"ls\", \"/tmp/.testcontainers\"}, exec.Multiplexed())\n\trequire.NoError(t, err)\n\n\tcontent, err := io.ReadAll(reader)\n\trequire.NoError(t, err)\n\tassert.Equal(t, \"/tmp/.testcontainers\\n\", string(content))\n}\n\nfunc TestWithAfterReadyCommand(t *testing.T) {\n\treq := testcontainers.GenericContainerRequest{\n\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\tImage:      \"alpine\",\n\t\t\tEntrypoint: []string{\"tail\", \"-f\", \"/dev/null\"},\n\t\t},\n\t\tStarted: true,\n\t}\n\n\ttestExec := testcontainers.NewRawCommand([]string{\"touch\", \"/tmp/.testcontainers\"})\n\n\terr := testcontainers.WithAfterReadyCommand(testExec)(&req)\n\trequire.NoError(t, err)\n\n\trequire.Len(t, req.LifecycleHooks, 1)\n\trequire.Len(t, req.LifecycleHooks[0].PostReadies, 1)\n\n\tc, err := testcontainers.GenericContainer(context.Background(), req)\n\ttestcontainers.CleanupContainer(t, c)\n\trequire.NoError(t, err)\n\n\t_, reader, err := c.Exec(context.Background(), []string{\"ls\", \"/tmp/.testcontainers\"}, exec.Multiplexed())\n\trequire.NoError(t, err)\n\n\tcontent, err := io.ReadAll(reader)\n\trequire.NoError(t, err)\n\tassert.Equal(t, \"/tmp/.testcontainers\\n\", string(content))\n}\n\nfunc TestWithEnv(t *testing.T) {\n\ttests := map[string]struct {\n\t\treq    *testcontainers.GenericContainerRequest\n\t\tenv    map[string]string\n\t\texpect map[string]string\n\t}{\n\t\t\"add\": {\n\t\t\treq: &testcontainers.GenericContainerRequest{\n\t\t\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\t\t\tEnv: map[string]string{\"KEY1\": \"VAL1\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\tenv: map[string]string{\"KEY2\": \"VAL2\"},\n\t\t\texpect: map[string]string{\n\t\t\t\t\"KEY1\": \"VAL1\",\n\t\t\t\t\"KEY2\": \"VAL2\",\n\t\t\t},\n\t\t},\n\t\t\"add-nil\": {\n\t\t\treq:    &testcontainers.GenericContainerRequest{},\n\t\t\tenv:    map[string]string{\"KEY2\": \"VAL2\"},\n\t\t\texpect: map[string]string{\"KEY2\": \"VAL2\"},\n\t\t},\n\t\t\"override\": {\n\t\t\treq: &testcontainers.GenericContainerRequest{\n\t\t\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\t\t\tEnv: map[string]string{\n\t\t\t\t\t\t\"KEY1\": \"VAL1\",\n\t\t\t\t\t\t\"KEY2\": \"VAL2\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tenv: map[string]string{\"KEY2\": \"VAL3\"},\n\t\t\texpect: map[string]string{\n\t\t\t\t\"KEY1\": \"VAL1\",\n\t\t\t\t\"KEY2\": \"VAL3\",\n\t\t\t},\n\t\t},\n\t}\n\tfor name, tc := range tests {\n\t\tt.Run(name, func(t *testing.T) {\n\t\t\topt := testcontainers.WithEnv(tc.env)\n\t\t\trequire.NoError(t, opt.Customize(tc.req))\n\t\t\trequire.Equal(t, tc.expect, tc.req.Env)\n\t\t})\n\t}\n}\n\nfunc TestWithHostPortAccess(t *testing.T) {\n\ttests := []struct {\n\t\tname      string\n\t\treq       *testcontainers.GenericContainerRequest\n\t\thostPorts []int\n\t\texpect    []int\n\t}{\n\t\t{\n\t\t\tname: \"add to existing\",\n\t\t\treq: &testcontainers.GenericContainerRequest{\n\t\t\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\t\t\tHostAccessPorts: []int{1, 2},\n\t\t\t\t},\n\t\t\t},\n\t\t\thostPorts: []int{3, 4},\n\t\t\texpect:    []int{1, 2, 3, 4},\n\t\t},\n\t\t{\n\t\t\tname:      \"add to nil\",\n\t\t\treq:       &testcontainers.GenericContainerRequest{},\n\t\t\thostPorts: []int{3, 4},\n\t\t\texpect:    []int{3, 4},\n\t\t},\n\t}\n\tfor _, tc := range tests {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\topt := testcontainers.WithHostPortAccess(tc.hostPorts...)\n\t\t\trequire.NoError(t, opt.Customize(tc.req))\n\t\t\trequire.Equal(t, tc.expect, tc.req.HostAccessPorts)\n\t\t})\n\t}\n}\n"
        },
        {
          "name": "parallel.go",
          "type": "blob",
          "size": 2.4658203125,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"sync\"\n)\n\nconst (\n\tdefaultWorkersCount = 8\n)\n\ntype ParallelContainerRequest []GenericContainerRequest\n\n// ParallelContainersOptions represents additional options for parallel running\ntype ParallelContainersOptions struct {\n\tWorkersCount int // count of parallel workers. If field empty(zero), default value will be 'defaultWorkersCount'\n}\n\n// ParallelContainersRequestError represents error from parallel request\ntype ParallelContainersRequestError struct {\n\tRequest GenericContainerRequest\n\tError   error\n}\n\ntype ParallelContainersError struct {\n\tErrors []ParallelContainersRequestError\n}\n\nfunc (gpe ParallelContainersError) Error() string {\n\treturn fmt.Sprintf(\"%v\", gpe.Errors)\n}\n\n// parallelContainersResult represents result.\ntype parallelContainersResult struct {\n\tParallelContainersRequestError\n\tContainer Container\n}\n\nfunc parallelContainersRunner(\n\tctx context.Context,\n\trequests <-chan GenericContainerRequest,\n\tresults chan<- parallelContainersResult,\n\twg *sync.WaitGroup,\n) {\n\tdefer wg.Done()\n\tfor req := range requests {\n\t\tc, err := GenericContainer(ctx, req)\n\t\tres := parallelContainersResult{Container: c}\n\t\tif err != nil {\n\t\t\tres.Request = req\n\t\t\tres.Error = err\n\t\t}\n\t\tresults <- res\n\t}\n}\n\n// ParallelContainers creates a generic containers with parameters and run it in parallel mode\nfunc ParallelContainers(ctx context.Context, reqs ParallelContainerRequest, opt ParallelContainersOptions) ([]Container, error) {\n\tif opt.WorkersCount == 0 {\n\t\topt.WorkersCount = defaultWorkersCount\n\t}\n\n\ttasksChanSize := opt.WorkersCount\n\tif tasksChanSize > len(reqs) {\n\t\ttasksChanSize = len(reqs)\n\t}\n\n\ttasksChan := make(chan GenericContainerRequest, tasksChanSize)\n\tresultsChan := make(chan parallelContainersResult, tasksChanSize)\n\tdone := make(chan struct{})\n\n\tvar wg sync.WaitGroup\n\twg.Add(tasksChanSize)\n\n\t// run workers\n\tfor i := 0; i < tasksChanSize; i++ {\n\t\tgo parallelContainersRunner(ctx, tasksChan, resultsChan, &wg)\n\t}\n\n\tvar errs []ParallelContainersRequestError\n\tcontainers := make([]Container, 0, len(reqs))\n\tgo func() {\n\t\tdefer close(done)\n\t\tfor res := range resultsChan {\n\t\t\tif res.Error != nil {\n\t\t\t\terrs = append(errs, res.ParallelContainersRequestError)\n\t\t\t} else {\n\t\t\t\tcontainers = append(containers, res.Container)\n\t\t\t}\n\t\t}\n\t}()\n\n\tfor _, req := range reqs {\n\t\ttasksChan <- req\n\t}\n\tclose(tasksChan)\n\n\twg.Wait()\n\n\tclose(resultsChan)\n\n\t<-done\n\n\tif len(errs) != 0 {\n\t\treturn containers, ParallelContainersError{Errors: errs}\n\t}\n\n\treturn containers, nil\n}\n"
        },
        {
          "name": "parallel_test.go",
          "type": "blob",
          "size": 3.08984375,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/testcontainers/testcontainers-go/wait\"\n)\n\nfunc TestParallelContainers(t *testing.T) {\n\ttests := []struct {\n\t\tname      string\n\t\treqs      ParallelContainerRequest\n\t\tresLen    int\n\t\texpErrors int\n\t}{\n\t\t{\n\t\t\tname: \"running two containers (one error)\",\n\t\t\treqs: ParallelContainerRequest{\n\t\t\t\t{\n\t\t\t\t\tContainerRequest: ContainerRequest{\n\t\t\t\t\t\tImage: \"nginx\",\n\t\t\t\t\t\tExposedPorts: []string{\n\t\t\t\t\t\t\t\"10080/tcp\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tStarted: true,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tContainerRequest: ContainerRequest{\n\t\t\t\t\t\tImage: \"bad bad bad\",\n\t\t\t\t\t\tExposedPorts: []string{\n\t\t\t\t\t\t\t\"10081/tcp\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tStarted: true,\n\t\t\t\t},\n\t\t\t},\n\t\t\tresLen:    1,\n\t\t\texpErrors: 1,\n\t\t},\n\t\t{\n\t\t\tname: \"running two containers (all errors)\",\n\t\t\treqs: ParallelContainerRequest{\n\t\t\t\t{\n\t\t\t\t\tContainerRequest: ContainerRequest{\n\t\t\t\t\t\tImage: \"bad bad bad\",\n\t\t\t\t\t\tExposedPorts: []string{\n\t\t\t\t\t\t\t\"10081/tcp\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tStarted: true,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tContainerRequest: ContainerRequest{\n\t\t\t\t\t\tImage: \"bad bad bad\",\n\t\t\t\t\t\tExposedPorts: []string{\n\t\t\t\t\t\t\t\"10081/tcp\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tStarted: true,\n\t\t\t\t},\n\t\t\t},\n\t\t\tresLen:    0,\n\t\t\texpErrors: 2,\n\t\t},\n\t\t{\n\t\t\tname: \"running two containers (success)\",\n\t\t\treqs: ParallelContainerRequest{\n\t\t\t\t{\n\t\t\t\t\tContainerRequest: ContainerRequest{\n\t\t\t\t\t\tImage: \"nginx\",\n\t\t\t\t\t\tExposedPorts: []string{\n\t\t\t\t\t\t\t\"10080/tcp\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tStarted: true,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tContainerRequest: ContainerRequest{\n\t\t\t\t\t\tImage: \"nginx\",\n\t\t\t\t\t\tExposedPorts: []string{\n\t\t\t\t\t\t\t\"10081/tcp\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tStarted: true,\n\t\t\t\t},\n\t\t\t},\n\t\t\tresLen:    2,\n\t\t\texpErrors: 0,\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tres, err := ParallelContainers(context.Background(), tc.reqs, ParallelContainersOptions{})\n\t\t\tfor _, c := range res {\n\t\t\t\tCleanupContainer(t, c)\n\t\t\t}\n\n\t\t\tif tc.expErrors != 0 {\n\t\t\t\trequire.Error(t, err)\n\t\t\t\tvar errs ParallelContainersError\n\t\t\t\trequire.ErrorAs(t, err, &errs)\n\t\t\t\trequire.Len(t, errs.Errors, tc.expErrors)\n\t\t\t}\n\n\t\t\trequire.Len(t, res, tc.resLen)\n\t\t})\n\t}\n}\n\nfunc TestParallelContainersWithReuse(t *testing.T) {\n\tconst (\n\t\tpostgresPort     = 5432\n\t\tpostgresPassword = \"test\"\n\t\tpostgresUser     = \"test\"\n\t\tpostgresDb       = \"test\"\n\t)\n\n\tnatPort := fmt.Sprintf(\"%d/tcp\", postgresPort)\n\n\treq := GenericContainerRequest{\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage:        \"postgis/postgis\",\n\t\t\tName:         \"test-postgres\",\n\t\t\tExposedPorts: []string{natPort},\n\t\t\tEnv: map[string]string{\n\t\t\t\t\"POSTGRES_PASSWORD\": postgresPassword,\n\t\t\t\t\"POSTGRES_USER\":     postgresUser,\n\t\t\t\t\"POSTGRES_DATABASE\": postgresDb,\n\t\t\t},\n\t\t\tWaitingFor: wait.ForLog(\"database system is ready to accept connections\").\n\t\t\t\tWithPollInterval(100 * time.Millisecond).\n\t\t\t\tWithOccurrence(2),\n\t\t},\n\t\tStarted: true,\n\t\tReuse:   true,\n\t}\n\n\tparallelRequest := ParallelContainerRequest{\n\t\treq,\n\t\treq,\n\t\treq,\n\t}\n\n\tctx := context.Background()\n\n\tres, err := ParallelContainers(ctx, parallelRequest, ParallelContainersOptions{})\n\tfor _, c := range res {\n\t\tCleanupContainer(t, c)\n\t}\n\trequire.NoError(t, err)\n}\n"
        },
        {
          "name": "port_forwarding.go",
          "type": "blob",
          "size": 11.83984375,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/docker/docker/api/types/container\"\n\t\"github.com/google/uuid\"\n\t\"golang.org/x/crypto/ssh\"\n\n\t\"github.com/testcontainers/testcontainers-go/internal/core/network\"\n\t\"github.com/testcontainers/testcontainers-go/wait\"\n)\n\nconst (\n\t// hubSshdImage {\n\tsshdImage string = \"testcontainers/sshd:1.2.0\"\n\t// }\n\n\t// HostInternal is the internal hostname used to reach the host from the container,\n\t// using the SSHD container as a bridge.\n\tHostInternal string = \"host.testcontainers.internal\"\n\tuser         string = \"root\"\n\tsshPort             = \"22/tcp\"\n)\n\n// sshPassword is a random password generated for the SSHD container.\nvar sshPassword = uuid.NewString()\n\n// exposeHostPorts performs all the necessary steps to expose the host ports to the container, leveraging\n// the SSHD container to create the tunnel, and the container lifecycle hooks to manage the tunnel lifecycle.\n// At least one port must be provided to expose.\n// The steps are:\n// 1. Create a new SSHD container.\n// 2. Expose the host ports to the container after the container is ready.\n// 3. Close the SSH sessions before killing the container.\nfunc exposeHostPorts(ctx context.Context, req *ContainerRequest, ports ...int) (sshdConnectHook ContainerLifecycleHooks, err error) {\n\tif len(ports) == 0 {\n\t\treturn sshdConnectHook, errors.New(\"no ports to expose\")\n\t}\n\n\t// Use the first network of the container to connect to the SSHD container.\n\tvar sshdFirstNetwork string\n\tif len(req.Networks) > 0 {\n\t\tsshdFirstNetwork = req.Networks[0]\n\t}\n\n\tif sshdFirstNetwork == \"bridge\" && len(req.Networks) > 1 {\n\t\tsshdFirstNetwork = req.Networks[1]\n\t}\n\n\topts := []ContainerCustomizer{}\n\tif len(req.Networks) > 0 {\n\t\t// get the first network of the container to connect the SSHD container to it.\n\t\tnw, err := network.GetByName(ctx, sshdFirstNetwork)\n\t\tif err != nil {\n\t\t\treturn sshdConnectHook, fmt.Errorf(\"get network %q: %w\", sshdFirstNetwork, err)\n\t\t}\n\n\t\tdockerNw := DockerNetwork{\n\t\t\tID:   nw.ID,\n\t\t\tName: nw.Name,\n\t\t}\n\n\t\t// WithNetwork reuses an already existing network, attaching the container to it.\n\t\t// Finally it sets the network alias on that network to the given alias.\n\t\t// TODO: Using an anonymous function to avoid cyclic dependencies with the network package.\n\t\twithNetwork := func(aliases []string, nw *DockerNetwork) CustomizeRequestOption {\n\t\t\treturn func(req *GenericContainerRequest) error {\n\t\t\t\tnetworkName := nw.Name\n\n\t\t\t\t// attaching to the network because it was created with success or it already existed.\n\t\t\t\treq.Networks = append(req.Networks, networkName)\n\n\t\t\t\tif req.NetworkAliases == nil {\n\t\t\t\t\treq.NetworkAliases = make(map[string][]string)\n\t\t\t\t}\n\t\t\t\treq.NetworkAliases[networkName] = aliases\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\n\t\topts = append(opts, withNetwork([]string{HostInternal}, &dockerNw))\n\t}\n\n\t// start the SSHD container with the provided options\n\tsshdContainer, err := newSshdContainer(ctx, opts...)\n\t// Ensure the SSHD container is stopped and removed in case of error.\n\tdefer func() {\n\t\tif err != nil {\n\t\t\terr = errors.Join(err, TerminateContainer(sshdContainer))\n\t\t}\n\t}()\n\tif err != nil {\n\t\treturn sshdConnectHook, fmt.Errorf(\"new sshd container: %w\", err)\n\t}\n\n\t// IP in the first network of the container.\n\tinspect, err := sshdContainer.Inspect(ctx)\n\tif err != nil {\n\t\treturn sshdConnectHook, fmt.Errorf(\"inspect sshd container: %w\", err)\n\t}\n\n\t// TODO: remove once we have docker context support via #2810\n\tsshdIP := inspect.NetworkSettings.IPAddress\n\tif sshdIP == \"\" {\n\t\tsingle := len(inspect.NetworkSettings.Networks) == 1\n\t\tfor name, network := range inspect.NetworkSettings.Networks {\n\t\t\tif name == sshdFirstNetwork || single {\n\t\t\t\tsshdIP = network.IPAddress\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\tif sshdIP == \"\" {\n\t\treturn sshdConnectHook, errors.New(\"sshd container IP not found\")\n\t}\n\n\tif req.HostConfigModifier == nil {\n\t\treq.HostConfigModifier = func(hostConfig *container.HostConfig) {}\n\t}\n\n\t// do not override the original HostConfigModifier\n\toriginalHCM := req.HostConfigModifier\n\treq.HostConfigModifier = func(hostConfig *container.HostConfig) {\n\t\t// adding the host internal alias to the container as an extra host\n\t\t// to allow the container to reach the SSHD container.\n\t\thostConfig.ExtraHosts = append(hostConfig.ExtraHosts, fmt.Sprintf(\"%s:%s\", HostInternal, sshdIP))\n\n\t\tmodes := []container.NetworkMode{container.NetworkMode(sshdFirstNetwork), \"none\", \"host\"}\n\t\t// if the container is not in one of the modes, attach it to the first network of the SSHD container\n\t\tfound := false\n\t\tfor _, mode := range modes {\n\t\t\tif hostConfig.NetworkMode == mode {\n\t\t\t\tfound = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif !found {\n\t\t\treq.Networks = append(req.Networks, sshdFirstNetwork)\n\t\t}\n\n\t\t// invoke the original HostConfigModifier with the updated hostConfig\n\t\toriginalHCM(hostConfig)\n\t}\n\n\tstopHooks := []ContainerHook{\n\t\tfunc(ctx context.Context, _ Container) error {\n\t\t\tif ctx.Err() != nil {\n\t\t\t\t// Context already canceled, need to create a new one to ensure\n\t\t\t\t// the SSH session is closed.\n\t\t\t\tvar cancel context.CancelFunc\n\t\t\t\tctx, cancel = context.WithTimeout(context.Background(), 10*time.Second)\n\t\t\t\tdefer cancel()\n\t\t\t}\n\n\t\t\treturn TerminateContainer(sshdContainer, StopContext(ctx))\n\t\t},\n\t}\n\n\t// after the container is ready, create the SSH tunnel\n\t// for each exposed port from the host.\n\tsshdConnectHook = ContainerLifecycleHooks{\n\t\tPostReadies: []ContainerHook{\n\t\t\tfunc(ctx context.Context, c Container) error {\n\t\t\t\treturn sshdContainer.exposeHostPort(ctx, req.HostAccessPorts...)\n\t\t\t},\n\t\t},\n\t\tPreStops:      stopHooks,\n\t\tPreTerminates: stopHooks,\n\t}\n\n\treturn sshdConnectHook, nil\n}\n\n// newSshdContainer creates a new SSHD container with the provided options.\nfunc newSshdContainer(ctx context.Context, opts ...ContainerCustomizer) (*sshdContainer, error) {\n\treq := GenericContainerRequest{\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage:        sshdImage,\n\t\t\tExposedPorts: []string{sshPort},\n\t\t\tEnv:          map[string]string{\"PASSWORD\": sshPassword},\n\t\t\tWaitingFor:   wait.ForListeningPort(sshPort),\n\t\t},\n\t\tStarted: true,\n\t}\n\n\tfor _, opt := range opts {\n\t\tif err := opt.Customize(&req); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tc, err := GenericContainer(ctx, req)\n\tvar sshd *sshdContainer\n\tif c != nil {\n\t\tsshd = &sshdContainer{Container: c}\n\t}\n\n\tif err != nil {\n\t\treturn sshd, fmt.Errorf(\"generic container: %w\", err)\n\t}\n\n\tif err = sshd.clientConfig(ctx); err != nil {\n\t\t// Return the container and the error to the caller to handle it.\n\t\treturn sshd, err\n\t}\n\n\treturn sshd, nil\n}\n\n// sshdContainer represents the SSHD container type used for the port forwarding container.\n// It's an internal type that extends the DockerContainer type, to add the SSH tunnelling capabilities.\ntype sshdContainer struct {\n\tContainer\n\tport           string\n\tsshConfig      *ssh.ClientConfig\n\tportForwarders []*portForwarder\n}\n\n// Terminate stops the container and closes the SSH session\nfunc (sshdC *sshdContainer) Terminate(ctx context.Context, opts ...TerminateOption) error {\n\treturn errors.Join(\n\t\tsshdC.closePorts(),\n\t\tsshdC.Container.Terminate(ctx, opts...),\n\t)\n}\n\n// Stop stops the container and closes the SSH session\nfunc (sshdC *sshdContainer) Stop(ctx context.Context, timeout *time.Duration) error {\n\treturn errors.Join(\n\t\tsshdC.closePorts(),\n\t\tsshdC.Container.Stop(ctx, timeout),\n\t)\n}\n\n// closePorts closes all port forwarders.\nfunc (sshdC *sshdContainer) closePorts() error {\n\tvar errs []error\n\tfor _, pfw := range sshdC.portForwarders {\n\t\tif err := pfw.Close(); err != nil {\n\t\t\terrs = append(errs, err)\n\t\t}\n\t}\n\tsshdC.portForwarders = nil // Ensure the port forwarders are not used after closing.\n\treturn errors.Join(errs...)\n}\n\n// clientConfig sets up the the SSHD client configuration.\nfunc (sshdC *sshdContainer) clientConfig(ctx context.Context) error {\n\tmappedPort, err := sshdC.MappedPort(ctx, sshPort)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"mapped port: %w\", err)\n\t}\n\n\tsshdC.port = mappedPort.Port()\n\tsshdC.sshConfig = &ssh.ClientConfig{\n\t\tUser:            user,\n\t\tHostKeyCallback: ssh.InsecureIgnoreHostKey(),\n\t\tAuth:            []ssh.AuthMethod{ssh.Password(sshPassword)},\n\t}\n\n\treturn nil\n}\n\n// exposeHostPort exposes the host ports to the container.\nfunc (sshdC *sshdContainer) exposeHostPort(ctx context.Context, ports ...int) (err error) {\n\tdefer func() {\n\t\tif err != nil {\n\t\t\terr = errors.Join(err, sshdC.closePorts())\n\t\t}\n\t}()\n\tfor _, port := range ports {\n\t\tpf, err := newPortForwarder(ctx, \"localhost:\"+sshdC.port, sshdC.sshConfig, port)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"new port forwarder: %w\", err)\n\t\t}\n\n\t\tsshdC.portForwarders = append(sshdC.portForwarders, pf)\n\t}\n\n\treturn nil\n}\n\n// portForwarder forwards a port from the container to the host.\ntype portForwarder struct {\n\tclient      *ssh.Client\n\tlistener    net.Listener\n\tdialTimeout time.Duration\n\tlocalAddr   string\n\tctx         context.Context\n\tcancel      context.CancelFunc\n\n\t// closeMtx protects the close operation\n\tcloseMtx sync.Mutex\n\tcloseErr error\n}\n\n// newPortForwarder creates a new running portForwarder for the given port.\n// The context is only used for the initial SSH connection.\nfunc newPortForwarder(ctx context.Context, sshDAddr string, sshConfig *ssh.ClientConfig, port int) (pf *portForwarder, err error) {\n\tvar d net.Dialer\n\tconn, err := d.DialContext(ctx, \"tcp\", sshDAddr)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"ssh dial: %w\", err)\n\t}\n\n\t// Ensure the connection is closed in case of error.\n\tdefer func() {\n\t\tif err != nil {\n\t\t\terr = errors.Join(err, conn.Close())\n\t\t}\n\t}()\n\n\tc, chans, reqs, err := ssh.NewClientConn(conn, sshDAddr, sshConfig)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"ssh new client conn: %w\", err)\n\t}\n\n\tclient := ssh.NewClient(c, chans, reqs)\n\n\tlistener, err := client.Listen(\"tcp\", fmt.Sprintf(\"localhost:%d\", port))\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"listening on remote port %d: %w\", port, err)\n\t}\n\n\tctx, cancel := context.WithCancel(context.Background())\n\n\tpf = &portForwarder{\n\t\tclient:      client,\n\t\tlistener:    listener,\n\t\tlocalAddr:   fmt.Sprintf(\"localhost:%d\", port),\n\t\tctx:         ctx,\n\t\tcancel:      cancel,\n\t\tdialTimeout: time.Second * 2,\n\t}\n\n\tgo pf.run()\n\n\treturn pf, nil\n}\n\n// Close closes the port forwarder.\nfunc (pf *portForwarder) Close() error {\n\tpf.closeMtx.Lock()\n\tdefer pf.closeMtx.Unlock()\n\n\tselect {\n\tcase <-pf.ctx.Done():\n\t\t// Already closed.\n\t\treturn pf.closeErr\n\tdefault:\n\t}\n\n\tvar errs []error\n\tif err := pf.listener.Close(); err != nil {\n\t\terrs = append(errs, fmt.Errorf(\"close listener: %w\", err))\n\t}\n\tif err := pf.client.Close(); err != nil {\n\t\terrs = append(errs, fmt.Errorf(\"close client: %w\", err))\n\t}\n\n\tpf.closeErr = errors.Join(errs...)\n\tpf.cancel()\n\n\treturn pf.closeErr\n}\n\n// run forwards the port from the remote connection to the local connection.\nfunc (pf *portForwarder) run() {\n\tfor {\n\t\tremote, err := pf.listener.Accept()\n\t\tif err != nil {\n\t\t\tif errors.Is(err, io.EOF) {\n\t\t\t\t// The listener has been closed.\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// Ignore errors as they are transient and we want requests to\n\t\t\t// continue to be accepted.\n\t\t\tcontinue\n\t\t}\n\n\t\tgo pf.tunnel(remote)\n\t}\n}\n\n// tunnel runs a tunnel between two connections; as soon as the forwarder\n// context is cancelled or one connection copies returns, irrespective of\n// the error, both connections are closed.\nfunc (pf *portForwarder) tunnel(remote net.Conn) {\n\tdefer remote.Close()\n\n\tctx, cancel := context.WithTimeout(pf.ctx, pf.dialTimeout)\n\tdefer cancel()\n\n\tvar dialer net.Dialer\n\tlocal, err := dialer.DialContext(ctx, \"tcp\", pf.localAddr)\n\tif err != nil {\n\t\t// Nothing we can do with the error.\n\t\treturn\n\t}\n\tdefer local.Close()\n\n\tctx, cancel = context.WithCancel(pf.ctx)\n\n\tgo func() {\n\t\tdefer cancel()\n\t\tio.Copy(local, remote) //nolint:errcheck // Nothing useful we can do with the error.\n\t}()\n\n\tgo func() {\n\t\tdefer cancel()\n\t\tio.Copy(remote, local) //nolint:errcheck // Nothing useful we can do with the error.\n\t}()\n\n\t// Wait for the context to be done before returning which triggers\n\t// both connections to close. This is done to to prevent the copies\n\t// blocking forever on unused connections.\n\t<-ctx.Done()\n}\n"
        },
        {
          "name": "port_forwarding_test.go",
          "type": "blob",
          "size": 4.01171875,
          "content": "package testcontainers_test\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/testcontainers/testcontainers-go\"\n\ttcexec \"github.com/testcontainers/testcontainers-go/exec\"\n\t\"github.com/testcontainers/testcontainers-go/network\"\n)\n\nconst (\n\texpectedResponse = \"Hello, World!\"\n)\n\nfunc TestExposeHostPorts(t *testing.T) {\n\thostPorts := make([]int, 3)\n\tfor i := range hostPorts {\n\t\tserver := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tfmt.Fprint(w, expectedResponse)\n\t\t}))\n\t\thostPorts[i] = server.Listener.Addr().(*net.TCPAddr).Port\n\t\tt.Cleanup(server.Close)\n\t}\n\n\tsinglePort := hostPorts[0:1]\n\n\tt.Run(\"single-port\", func(t *testing.T) {\n\t\ttestExposeHostPorts(t, singlePort, false, false)\n\t})\n\n\tt.Run(\"single-port-network\", func(t *testing.T) {\n\t\ttestExposeHostPorts(t, singlePort, true, false)\n\t})\n\n\tt.Run(\"single-port-host-access\", func(t *testing.T) {\n\t\ttestExposeHostPorts(t, singlePort, false, true)\n\t})\n\n\tt.Run(\"single-port-network-host-access\", func(t *testing.T) {\n\t\ttestExposeHostPorts(t, singlePort, true, true)\n\t})\n\n\tt.Run(\"multi-port\", func(t *testing.T) {\n\t\ttestExposeHostPorts(t, hostPorts, false, false)\n\t})\n\n\tt.Run(\"multi-port-network\", func(t *testing.T) {\n\t\ttestExposeHostPorts(t, hostPorts, true, false)\n\t})\n\n\tt.Run(\"multi-port-host-access\", func(t *testing.T) {\n\t\ttestExposeHostPorts(t, hostPorts, false, true)\n\t})\n\n\tt.Run(\"multi-port-network-host-access\", func(t *testing.T) {\n\t\ttestExposeHostPorts(t, hostPorts, true, true)\n\t})\n}\n\nfunc testExposeHostPorts(t *testing.T, hostPorts []int, hasNetwork, hasHostAccess bool) {\n\tt.Helper()\n\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second*10)\n\tdefer cancel()\n\n\tvar hostAccessPorts []int\n\tif hasHostAccess {\n\t\thostAccessPorts = hostPorts\n\t}\n\treq := testcontainers.GenericContainerRequest{\n\t\t// hostAccessPorts {\n\t\tContainerRequest: testcontainers.ContainerRequest{\n\t\t\tImage:           \"alpine:3.17\",\n\t\t\tHostAccessPorts: hostAccessPorts,\n\t\t\tCmd:             []string{\"top\"},\n\t\t},\n\t\t// }\n\t\tStarted: true,\n\t}\n\n\tif hasNetwork {\n\t\tnw, err := network.New(ctx)\n\t\trequire.NoError(t, err)\n\t\ttestcontainers.CleanupNetwork(t, nw)\n\n\t\treq.Networks = []string{nw.Name}\n\t\treq.NetworkAliases = map[string][]string{nw.Name: {\"myalpine\"}}\n\t}\n\n\tc, err := testcontainers.GenericContainer(ctx, req)\n\ttestcontainers.CleanupContainer(t, c)\n\trequire.NoError(t, err)\n\n\tif hasHostAccess {\n\t\t// Verify that the container can access the host ports.\n\t\tcontainerHasHostAccess(t, c, hostPorts...)\n\t\treturn\n\t}\n\n\t// Verify that the container cannot access the host ports.\n\tcontainerHasNoHostAccess(t, c, hostPorts...)\n}\n\n// httpRequest sends an HTTP request from the container to the host port via\n// [testcontainers.HostInternal] address.\nfunc httpRequest(t *testing.T, c testcontainers.Container, port int) (int, string) {\n\tt.Helper()\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\n\t// wgetHostInternal {\n\tcode, reader, err := c.Exec(\n\t\tctx,\n\t\t[]string{\"wget\", \"-q\", \"-O\", \"-\", \"-T\", \"2\", fmt.Sprintf(\"http://%s:%d\", testcontainers.HostInternal, port)},\n\t\ttcexec.Multiplexed(),\n\t)\n\t// }\n\trequire.NoError(t, err)\n\n\t// read the response\n\tbs, err := io.ReadAll(reader)\n\trequire.NoError(t, err)\n\n\treturn code, string(bs)\n}\n\n// containerHasHostAccess verifies that the container can access the host ports\n// via [testcontainers.HostInternal] address.\nfunc containerHasHostAccess(t *testing.T, c testcontainers.Container, ports ...int) {\n\tt.Helper()\n\tfor _, port := range ports {\n\t\tcode, response := httpRequest(t, c, port)\n\t\trequire.Zero(t, code)\n\t\trequire.Equal(t, expectedResponse, response)\n\t}\n}\n\n// containerHasNoHostAccess verifies that the container cannot access the host ports\n// via [testcontainers.HostInternal] address.\nfunc containerHasNoHostAccess(t *testing.T, c testcontainers.Container, ports ...int) {\n\tt.Helper()\n\tfor _, port := range ports {\n\t\tcode, response := httpRequest(t, c, port)\n\t\trequire.NotZero(t, code)\n\t\trequire.Contains(t, response, \"bad address\")\n\t}\n}\n"
        },
        {
          "name": "provider.go",
          "type": "blob",
          "size": 4.73828125,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"os\"\n\t\"strings\"\n\n\t\"github.com/testcontainers/testcontainers-go/internal/config\"\n\t\"github.com/testcontainers/testcontainers-go/internal/core\"\n)\n\n// possible provider types\nconst (\n\tProviderDefault ProviderType = iota // default will auto-detect provider from DOCKER_HOST environment variable\n\tProviderDocker\n\tProviderPodman\n)\n\ntype (\n\t// ProviderType is an enum for the possible providers\n\tProviderType int\n\n\t// GenericProviderOptions defines options applicable to all providers\n\tGenericProviderOptions struct {\n\t\tLogger         Logging\n\t\tdefaultNetwork string\n\t}\n\n\t// GenericProviderOption defines a common interface to modify GenericProviderOptions\n\t// These options can be passed to GetProvider in a variadic way to customize the returned GenericProvider instance\n\tGenericProviderOption interface {\n\t\tApplyGenericTo(opts *GenericProviderOptions)\n\t}\n\n\t// GenericProviderOptionFunc is a shorthand to implement the GenericProviderOption interface\n\tGenericProviderOptionFunc func(opts *GenericProviderOptions)\n\n\t// DockerProviderOptions defines options applicable to DockerProvider\n\tDockerProviderOptions struct {\n\t\tdefaultBridgeNetworkName string\n\t\t*GenericProviderOptions\n\t}\n\n\t// DockerProviderOption defines a common interface to modify DockerProviderOptions\n\t// These can be passed to NewDockerProvider in a variadic way to customize the returned DockerProvider instance\n\tDockerProviderOption interface {\n\t\tApplyDockerTo(opts *DockerProviderOptions)\n\t}\n\n\t// DockerProviderOptionFunc is a shorthand to implement the DockerProviderOption interface\n\tDockerProviderOptionFunc func(opts *DockerProviderOptions)\n)\n\nfunc (f DockerProviderOptionFunc) ApplyDockerTo(opts *DockerProviderOptions) {\n\tf(opts)\n}\n\nfunc Generic2DockerOptions(opts ...GenericProviderOption) []DockerProviderOption {\n\tconverted := make([]DockerProviderOption, 0, len(opts))\n\tfor _, o := range opts {\n\t\tswitch c := o.(type) {\n\t\tcase DockerProviderOption:\n\t\t\tconverted = append(converted, c)\n\t\tdefault:\n\t\t\tconverted = append(converted, DockerProviderOptionFunc(func(opts *DockerProviderOptions) {\n\t\t\t\to.ApplyGenericTo(opts.GenericProviderOptions)\n\t\t\t}))\n\t\t}\n\t}\n\n\treturn converted\n}\n\nfunc WithDefaultBridgeNetwork(bridgeNetworkName string) DockerProviderOption {\n\treturn DockerProviderOptionFunc(func(opts *DockerProviderOptions) {\n\t\topts.defaultBridgeNetworkName = bridgeNetworkName\n\t})\n}\n\nfunc (f GenericProviderOptionFunc) ApplyGenericTo(opts *GenericProviderOptions) {\n\tf(opts)\n}\n\n// ContainerProvider allows the creation of containers on an arbitrary system\ntype ContainerProvider interface {\n\tClose() error                                                                // close the provider\n\tCreateContainer(context.Context, ContainerRequest) (Container, error)        // create a container without starting it\n\tReuseOrCreateContainer(context.Context, ContainerRequest) (Container, error) // reuses a container if it exists or creates a container without starting\n\tRunContainer(context.Context, ContainerRequest) (Container, error)           // create a container and start it\n\tHealth(context.Context) error\n\tConfig() TestcontainersConfig\n}\n\n// GetProvider provides the provider implementation for a certain type\nfunc (t ProviderType) GetProvider(opts ...GenericProviderOption) (GenericProvider, error) {\n\topt := &GenericProviderOptions{\n\t\tLogger: Logger,\n\t}\n\n\tfor _, o := range opts {\n\t\to.ApplyGenericTo(opt)\n\t}\n\n\tpt := t\n\tif pt == ProviderDefault && strings.Contains(os.Getenv(\"DOCKER_HOST\"), \"podman.sock\") {\n\t\tpt = ProviderPodman\n\t}\n\n\tswitch pt {\n\tcase ProviderDefault, ProviderDocker:\n\t\tproviderOptions := append(Generic2DockerOptions(opts...), WithDefaultBridgeNetwork(Bridge))\n\t\tprovider, err := NewDockerProvider(providerOptions...)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"%w, failed to create Docker provider\", err)\n\t\t}\n\t\treturn provider, nil\n\tcase ProviderPodman:\n\t\tproviderOptions := append(Generic2DockerOptions(opts...), WithDefaultBridgeNetwork(Podman))\n\t\tprovider, err := NewDockerProvider(providerOptions...)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"%w, failed to create Docker provider\", err)\n\t\t}\n\t\treturn provider, nil\n\t}\n\treturn nil, errors.New(\"unknown provider\")\n}\n\n// NewDockerProvider creates a Docker provider with the EnvClient\nfunc NewDockerProvider(provOpts ...DockerProviderOption) (*DockerProvider, error) {\n\to := &DockerProviderOptions{\n\t\tGenericProviderOptions: &GenericProviderOptions{\n\t\t\tLogger: Logger,\n\t\t},\n\t}\n\n\tfor idx := range provOpts {\n\t\tprovOpts[idx].ApplyDockerTo(o)\n\t}\n\n\tctx := context.Background()\n\tc, err := NewDockerClientWithOpts(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &DockerProvider{\n\t\tDockerProviderOptions: o,\n\t\thost:                  core.MustExtractDockerHost(ctx),\n\t\tclient:                c,\n\t\tconfig:                config.Read(),\n\t}, nil\n}\n"
        },
        {
          "name": "provider_test.go",
          "type": "blob",
          "size": 1.9921875,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/testcontainers/testcontainers-go/internal/core\"\n)\n\nfunc TestProviderTypeGetProviderAutodetect(t *testing.T) {\n\tdockerHost := core.MustExtractDockerHost(context.Background())\n\tconst podmanSocket = \"unix://$XDG_RUNTIME_DIR/podman/podman.sock\"\n\n\ttests := []struct {\n\t\tname       string\n\t\ttr         ProviderType\n\t\tDockerHost string\n\t\twant       string\n\t}{\n\t\t{\n\t\t\tname:       \"default provider without podman.socket\",\n\t\t\ttr:         ProviderDefault,\n\t\t\tDockerHost: dockerHost,\n\t\t\twant:       Bridge,\n\t\t},\n\t\t{\n\t\t\tname:       \"default provider with podman.socket\",\n\t\t\ttr:         ProviderDefault,\n\t\t\tDockerHost: podmanSocket,\n\t\t\twant:       Podman,\n\t\t},\n\t\t{\n\t\t\tname:       \"docker provider without podman.socket\",\n\t\t\ttr:         ProviderDocker,\n\t\t\tDockerHost: dockerHost,\n\t\t\twant:       Bridge,\n\t\t},\n\t\t{\n\t\t\t// Explicitly setting Docker provider should not be overridden by auto-detect\n\t\t\tname:       \"docker provider with podman.socket\",\n\t\t\ttr:         ProviderDocker,\n\t\t\tDockerHost: podmanSocket,\n\t\t\twant:       Bridge,\n\t\t},\n\t\t{\n\t\t\tname:       \"Podman provider without podman.socket\",\n\t\t\ttr:         ProviderPodman,\n\t\t\tDockerHost: dockerHost,\n\t\t\twant:       Podman,\n\t\t},\n\t\t{\n\t\t\tname:       \"Podman provider with podman.socket\",\n\t\t\ttr:         ProviderPodman,\n\t\t\tDockerHost: podmanSocket,\n\t\t\twant:       Podman,\n\t\t},\n\t}\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tif tt.tr == ProviderPodman && core.IsWindows() {\n\t\t\t\tt.Skip(\"Podman provider is not implemented for Windows\")\n\t\t\t}\n\n\t\t\tt.Setenv(\"DOCKER_HOST\", tt.DockerHost)\n\n\t\t\tgot, err := tt.tr.GetProvider()\n\t\t\trequire.NoErrorf(t, err, \"ProviderType.GetProvider()\")\n\t\t\tprovider, ok := got.(*DockerProvider)\n\t\t\trequire.Truef(t, ok, \"ProviderType.GetProvider() = %T, want %T\", got, &DockerProvider{})\n\t\t\trequire.Equalf(t, tt.want, provider.defaultBridgeNetworkName, \"ProviderType.GetProvider() = %v, want %v\", provider.defaultBridgeNetworkName, tt.want)\n\t\t})\n\t}\n}\n"
        },
        {
          "name": "reaper.go",
          "type": "blob",
          "size": 17.373046875,
          "content": "package testcontainers\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"os\"\n\t\"strings\"\n\t\"sync\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/cenkalti/backoff/v4\"\n\t\"github.com/docker/docker/api/types\"\n\t\"github.com/docker/docker/api/types/container\"\n\t\"github.com/docker/docker/api/types/filters\"\n\t\"github.com/docker/docker/errdefs\"\n\t\"github.com/docker/go-connections/nat\"\n\n\t\"github.com/testcontainers/testcontainers-go/internal/config\"\n\t\"github.com/testcontainers/testcontainers-go/internal/core\"\n\t\"github.com/testcontainers/testcontainers-go/wait\"\n)\n\nconst (\n\t// Deprecated: it has been replaced by the internal core.LabelLang\n\tTestcontainerLabel = \"org.testcontainers.golang\"\n\t// Deprecated: it has been replaced by the internal core.LabelSessionID\n\tTestcontainerLabelSessionID = TestcontainerLabel + \".sessionId\"\n\t// Deprecated: it has been replaced by the internal core.LabelReaper\n\tTestcontainerLabelIsReaper = TestcontainerLabel + \".reaper\"\n)\n\nvar (\n\t// Deprecated: it has been replaced by an internal value\n\tReaperDefaultImage = config.ReaperDefaultImage\n\n\t// defaultReaperPort is the default port that the reaper listens on if not\n\t// overridden by the RYUK_PORT environment variable.\n\tdefaultReaperPort = nat.Port(\"8080/tcp\")\n\n\t// errReaperNotFound is returned when no reaper container is found.\n\terrReaperNotFound = errors.New(\"reaper not found\")\n\n\t// errReaperDisabled is returned if a reaper is requested but the\n\t// config has it disabled.\n\terrReaperDisabled = errors.New(\"reaper disabled\")\n\n\t// spawner is the singleton instance of reaperSpawner.\n\tspawner = &reaperSpawner{}\n\n\t// reaperAck is the expected response from the reaper container.\n\treaperAck = []byte(\"ACK\\n\")\n)\n\n// ReaperProvider represents a provider for the reaper to run itself with\n// The ContainerProvider interface should usually satisfy this as well, so it is pluggable\ntype ReaperProvider interface {\n\tRunContainer(ctx context.Context, req ContainerRequest) (Container, error)\n\tConfig() TestcontainersConfig\n}\n\n// NewReaper creates a Reaper with a sessionID to identify containers and a provider to use\n// Deprecated: it's not possible to create a reaper any more. Compose module uses this method\n// to create a reaper for the compose stack.\n//\n// The caller must call Connect at least once on the returned Reaper and use the returned\n// result otherwise the reaper will be kept open until the process exits.\nfunc NewReaper(ctx context.Context, sessionID string, provider ReaperProvider, reaperImageName string) (*Reaper, error) {\n\treaper, err := spawner.reaper(ctx, sessionID, provider)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"reaper: %w\", err)\n\t}\n\n\treturn reaper, nil\n}\n\n// reaperContainerNameFromSessionID returns the container name that uniquely\n// identifies the container based on the session id.\nfunc reaperContainerNameFromSessionID(sessionID string) string {\n\t// The session id is 64 characters, so we will not hit the limit of 128\n\t// characters for container names.\n\treturn \"reaper_\" + sessionID\n}\n\n// reaperSpawner is a singleton that manages the reaper container.\ntype reaperSpawner struct {\n\tinstance *Reaper\n\tmtx      sync.Mutex\n}\n\n// port returns the port that a new reaper should listens on.\nfunc (r *reaperSpawner) port() nat.Port {\n\tif port := os.Getenv(\"RYUK_PORT\"); port != \"\" {\n\t\tnatPort, err := nat.NewPort(\"tcp\", port)\n\t\tif err != nil {\n\t\t\tpanic(fmt.Sprintf(\"invalid RYUK_PORT value %q: %s\", port, err))\n\t\t}\n\t\treturn natPort\n\t}\n\n\treturn defaultReaperPort\n}\n\n// backoff returns a backoff policy for the reaper spawner.\n// It will take at most 20 seconds, doing each attempt every 100ms - 250ms.\nfunc (r *reaperSpawner) backoff() *backoff.ExponentialBackOff {\n\t// We want random intervals between 100ms and 250ms for concurrent executions\n\t// to not be synchronized: it could be the case that multiple executions of this\n\t// function happen at the same time (specifically when called from a different test\n\t// process execution), and we want to avoid that they all try to find the reaper\n\t// container at the same time.\n\tb := &backoff.ExponentialBackOff{\n\t\tInitialInterval:     time.Millisecond * 100,\n\t\tRandomizationFactor: backoff.DefaultRandomizationFactor,\n\t\tMultiplier:          backoff.DefaultMultiplier,\n\t\t// Adjust MaxInterval to compensate for randomization factor which can be added to\n\t\t// returned interval so we have a maximum of 250ms.\n\t\tMaxInterval:    time.Duration(float64(time.Millisecond*250) * backoff.DefaultRandomizationFactor),\n\t\tMaxElapsedTime: time.Second * 20,\n\t\tStop:           backoff.Stop,\n\t\tClock:          backoff.SystemClock,\n\t}\n\tb.Reset()\n\n\treturn b\n}\n\n// cleanup terminates the reaper container if set.\nfunc (r *reaperSpawner) cleanup() error {\n\tr.mtx.Lock()\n\tdefer r.mtx.Unlock()\n\n\treturn r.cleanupLocked()\n}\n\n// cleanupLocked terminates the reaper container if set.\n// It must be called with the lock held.\nfunc (r *reaperSpawner) cleanupLocked() error {\n\tif r.instance == nil {\n\t\treturn nil\n\t}\n\n\terr := TerminateContainer(r.instance.container)\n\tr.instance = nil\n\n\treturn err\n}\n\n// lookupContainer returns a DockerContainer type with the reaper container in the case\n// it's found in the running state, and including the labels for sessionID, reaper, and ryuk.\n// It will perform a retry with exponential backoff to allow for the container to be started and\n// avoid potential false negatives.\nfunc (r *reaperSpawner) lookupContainer(ctx context.Context, sessionID string) (*DockerContainer, error) {\n\tdockerClient, err := NewDockerClientWithOpts(ctx)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"new client: %w\", err)\n\t}\n\tdefer dockerClient.Close()\n\n\tprovider, err := NewDockerProvider()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"new provider: %w\", err)\n\t}\n\n\tprovider.SetClient(dockerClient)\n\n\topts := container.ListOptions{\n\t\tAll: true,\n\t\tFilters: filters.NewArgs(\n\t\t\tfilters.Arg(\"label\", fmt.Sprintf(\"%s=%s\", core.LabelSessionID, sessionID)),\n\t\t\tfilters.Arg(\"label\", fmt.Sprintf(\"%s=%t\", core.LabelReaper, true)),\n\t\t\tfilters.Arg(\"label\", fmt.Sprintf(\"%s=%t\", core.LabelRyuk, true)),\n\t\t\tfilters.Arg(\"name\", reaperContainerNameFromSessionID(sessionID)),\n\t\t),\n\t}\n\n\treturn backoff.RetryWithData(\n\t\tfunc() (*DockerContainer, error) {\n\t\t\tresp, err := dockerClient.ContainerList(ctx, opts)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"container list: %w\", err)\n\t\t\t}\n\n\t\t\tif len(resp) == 0 {\n\t\t\t\t// No reaper container not found.\n\t\t\t\treturn nil, backoff.Permanent(errReaperNotFound)\n\t\t\t}\n\n\t\t\tif len(resp) > 1 {\n\t\t\t\treturn nil, fmt.Errorf(\"found %d reaper containers for session ID %q\", len(resp), sessionID)\n\t\t\t}\n\n\t\t\tr, err := provider.ContainerFromType(ctx, resp[0])\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"from docker: %w\", err)\n\t\t\t}\n\n\t\t\tswitch {\n\t\t\tcase r.healthStatus == types.Healthy,\n\t\t\t\tr.healthStatus == types.NoHealthcheck:\n\t\t\t\treturn r, nil\n\t\t\tcase r.healthStatus != \"\":\n\t\t\t\treturn nil, fmt.Errorf(\"container not healthy: %s\", r.healthStatus)\n\t\t\t}\n\n\t\t\treturn r, nil\n\t\t},\n\t\tbackoff.WithContext(r.backoff(), ctx),\n\t)\n}\n\n// isRunning returns an error if the container is not running.\nfunc (r *reaperSpawner) isRunning(ctx context.Context, ctr Container) error {\n\tstate, err := ctr.State(ctx)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"container state: %w\", err)\n\t}\n\n\tif !state.Running {\n\t\t// Use NotFound error to indicate the container is not running\n\t\t// and should be recreated.\n\t\treturn errdefs.NotFound(fmt.Errorf(\"container state: %s\", state.Status))\n\t}\n\n\treturn nil\n}\n\n// retryError returns a permanent error if the error is not considered retryable.\nfunc (r *reaperSpawner) retryError(err error) error {\n\tvar timeout interface {\n\t\tTimeout() bool\n\t}\n\tswitch {\n\tcase isCleanupSafe(err),\n\t\tcreateContainerFailDueToNameConflictRegex.MatchString(err.Error()),\n\t\terrors.Is(err, syscall.ECONNREFUSED),\n\t\terrors.Is(err, syscall.ECONNRESET),\n\t\terrors.Is(err, syscall.ECONNABORTED),\n\t\terrors.Is(err, syscall.ETIMEDOUT),\n\t\terrors.Is(err, os.ErrDeadlineExceeded),\n\t\terrors.As(err, &timeout) && timeout.Timeout(),\n\t\terrors.Is(err, context.DeadlineExceeded),\n\t\terrors.Is(err, context.Canceled):\n\t\t// Retryable error.\n\t\treturn err\n\tdefault:\n\t\treturn backoff.Permanent(err)\n\t}\n}\n\n// reaper returns an existing Reaper instance if it exists and is running, otherwise\n// a new Reaper instance will be created with a sessionID to identify containers in\n// the same test session/program. If connect is true, the reaper will be connected\n// to the reaper container.\n// Returns an error if config.RyukDisabled is true.\n//\n// Safe for concurrent calls.\nfunc (r *reaperSpawner) reaper(ctx context.Context, sessionID string, provider ReaperProvider) (*Reaper, error) {\n\tif config.Read().RyukDisabled {\n\t\treturn nil, errReaperDisabled\n\t}\n\n\tr.mtx.Lock()\n\tdefer r.mtx.Unlock()\n\n\treturn backoff.RetryWithData(\n\t\tr.retryLocked(ctx, sessionID, provider),\n\t\tbackoff.WithContext(r.backoff(), ctx),\n\t)\n}\n\n// retryLocked returns a function that can be used to create or reuse a reaper container.\n// If connect is true, the reaper will be connected to the reaper container.\n// It must be called with the lock held.\nfunc (r *reaperSpawner) retryLocked(ctx context.Context, sessionID string, provider ReaperProvider) func() (*Reaper, error) {\n\treturn func() (reaper *Reaper, err error) {\n\t\treaper, err = r.reuseOrCreate(ctx, sessionID, provider)\n\t\t// Ensure that the reaper is terminated if an error occurred.\n\t\tdefer func() {\n\t\t\tif err != nil {\n\t\t\t\tif reaper != nil {\n\t\t\t\t\terr = errors.Join(err, TerminateContainer(reaper.container))\n\t\t\t\t}\n\t\t\t\terr = r.retryError(errors.Join(err, r.cleanupLocked()))\n\t\t\t}\n\t\t}()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tif err = r.isRunning(ctx, reaper.container); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\t// Check we can still connect.\n\t\ttermSignal, err := reaper.connect(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"connect: %w\", err)\n\t\t}\n\n\t\treaper.setOrSignal(termSignal)\n\n\t\tr.instance = reaper\n\n\t\treturn reaper, nil\n\t}\n}\n\n// reuseOrCreate returns an existing Reaper instance if it exists, otherwise a new Reaper instance.\nfunc (r *reaperSpawner) reuseOrCreate(ctx context.Context, sessionID string, provider ReaperProvider) (*Reaper, error) {\n\tif r.instance != nil {\n\t\t// We already have an associated reaper.\n\t\treturn r.instance, nil\n\t}\n\n\t// Look for an existing reaper created in the same test session but in a\n\t// different test process execution e.g. when running tests in parallel.\n\tcontainer, err := r.lookupContainer(context.Background(), sessionID)\n\tif err != nil {\n\t\tif !errors.Is(err, errReaperNotFound) {\n\t\t\treturn nil, fmt.Errorf(\"look up container: %w\", err)\n\t\t}\n\n\t\t// The reaper container was not found, continue to create a new one.\n\t\treaper, err := r.newReaper(ctx, sessionID, provider)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"new reaper: %w\", err)\n\t\t}\n\n\t\treturn reaper, nil\n\t}\n\n\t// A reaper container exists re-use it.\n\treaper, err := r.fromContainer(ctx, sessionID, provider, container)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"from container %q: %w\", container.ID[:8], err)\n\t}\n\n\treturn reaper, nil\n}\n\n// fromContainer constructs a Reaper from an already running reaper DockerContainer.\nfunc (r *reaperSpawner) fromContainer(ctx context.Context, sessionID string, provider ReaperProvider, dockerContainer *DockerContainer) (*Reaper, error) {\n\tLogger.Printf(\"⏳ Waiting for Reaper %q to be ready\", dockerContainer.ID[:8])\n\n\t// Reusing an existing container so we determine the port from the container's exposed ports.\n\tif err := wait.ForExposedPort().\n\t\tWithPollInterval(100*time.Millisecond).\n\t\tSkipInternalCheck().\n\t\tWaitUntilReady(ctx, dockerContainer); err != nil {\n\t\treturn nil, fmt.Errorf(\"wait for reaper %s: %w\", dockerContainer.ID[:8], err)\n\t}\n\n\tendpoint, err := dockerContainer.Endpoint(ctx, \"\")\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"port endpoint: %w\", err)\n\t}\n\n\tLogger.Printf(\"🔥 Reaper obtained from Docker for this test session %s\", dockerContainer.ID[:8])\n\n\treturn &Reaper{\n\t\tProvider:  provider,\n\t\tSessionID: sessionID,\n\t\tEndpoint:  endpoint,\n\t\tcontainer: dockerContainer,\n\t}, nil\n}\n\n// newReaper creates a connected Reaper with a sessionID to identify containers\n// and a provider to use.\nfunc (r *reaperSpawner) newReaper(ctx context.Context, sessionID string, provider ReaperProvider) (reaper *Reaper, err error) {\n\tdockerHostMount := core.MustExtractDockerSocket(ctx)\n\n\tport := r.port()\n\ttcConfig := provider.Config().Config\n\treq := ContainerRequest{\n\t\tImage:        config.ReaperDefaultImage,\n\t\tExposedPorts: []string{string(port)},\n\t\tLabels:       core.DefaultLabels(sessionID),\n\t\tPrivileged:   tcConfig.RyukPrivileged,\n\t\tWaitingFor:   wait.ForListeningPort(port),\n\t\tName:         reaperContainerNameFromSessionID(sessionID),\n\t\tHostConfigModifier: func(hc *container.HostConfig) {\n\t\t\thc.AutoRemove = true\n\t\t\thc.Binds = []string{dockerHostMount + \":/var/run/docker.sock\"}\n\t\t\thc.NetworkMode = Bridge\n\t\t},\n\t\tEnv: map[string]string{},\n\t}\n\tif to := tcConfig.RyukConnectionTimeout; to > time.Duration(0) {\n\t\treq.Env[\"RYUK_CONNECTION_TIMEOUT\"] = to.String()\n\t}\n\tif to := tcConfig.RyukReconnectionTimeout; to > time.Duration(0) {\n\t\treq.Env[\"RYUK_RECONNECTION_TIMEOUT\"] = to.String()\n\t}\n\tif tcConfig.RyukVerbose {\n\t\treq.Env[\"RYUK_VERBOSE\"] = \"true\"\n\t}\n\n\t// Setup reaper-specific labels for the reaper container.\n\treq.Labels[core.LabelReaper] = \"true\"\n\treq.Labels[core.LabelRyuk] = \"true\"\n\tdelete(req.Labels, core.LabelReap)\n\n\t// Attach reaper container to a requested network if it is specified\n\tif p, ok := provider.(*DockerProvider); ok {\n\t\tdefaultNetwork, err := p.ensureDefaultNetwork(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"ensure default network: %w\", err)\n\t\t}\n\n\t\treq.Networks = append(req.Networks, defaultNetwork)\n\t}\n\n\tc, err := provider.RunContainer(ctx, req)\n\tdefer func() {\n\t\tif err != nil {\n\t\t\terr = errors.Join(err, TerminateContainer(c))\n\t\t}\n\t}()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"run container: %w\", err)\n\t}\n\n\tendpoint, err := c.PortEndpoint(ctx, port, \"\")\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"port endpoint: %w\", err)\n\t}\n\n\treturn &Reaper{\n\t\tProvider:  provider,\n\t\tSessionID: sessionID,\n\t\tEndpoint:  endpoint,\n\t\tcontainer: c,\n\t}, nil\n}\n\n// Reaper is used to start a sidecar container that cleans up resources\ntype Reaper struct {\n\tProvider   ReaperProvider\n\tSessionID  string\n\tEndpoint   string\n\tcontainer  Container\n\tmtx        sync.Mutex // Protects termSignal.\n\ttermSignal chan bool\n}\n\n// Connect connects to the reaper container and sends the labels to it\n// so that it can clean up the containers with the same labels.\n//\n// It returns a channel that can be closed to terminate the connection.\n// Returns an error if config.RyukDisabled is true.\nfunc (r *Reaper) Connect() (chan bool, error) {\n\tif config.Read().RyukDisabled {\n\t\treturn nil, errReaperDisabled\n\t}\n\n\tif termSignal := r.useTermSignal(); termSignal != nil {\n\t\treturn termSignal, nil\n\t}\n\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second*5)\n\tdefer cancel()\n\n\treturn r.connect(ctx)\n}\n\n// close signals the connection to close if needed.\n// Safe for concurrent calls.\nfunc (r *Reaper) close() {\n\tr.mtx.Lock()\n\tdefer r.mtx.Unlock()\n\n\tif r.termSignal != nil {\n\t\tr.termSignal <- true\n\t\tr.termSignal = nil\n\t}\n}\n\n// setOrSignal sets the reapers termSignal field if nil\n// otherwise consumes by sending true to it.\n// Safe for concurrent calls.\nfunc (r *Reaper) setOrSignal(termSignal chan bool) {\n\tr.mtx.Lock()\n\tdefer r.mtx.Unlock()\n\n\tif r.termSignal != nil {\n\t\t// Already have an existing connection, close the new one.\n\t\ttermSignal <- true\n\t\treturn\n\t}\n\n\t// First or new unused termSignal, assign for caller to reuse.\n\tr.termSignal = termSignal\n}\n\n// useTermSignal if termSignal is not nil returns it\n// and sets it to nil, otherwise returns nil.\n//\n// Safe for concurrent calls.\nfunc (r *Reaper) useTermSignal() chan bool {\n\tr.mtx.Lock()\n\tdefer r.mtx.Unlock()\n\n\tif r.termSignal == nil {\n\t\treturn nil\n\t}\n\n\t// Use existing connection.\n\tterm := r.termSignal\n\tr.termSignal = nil\n\n\treturn term\n}\n\n// connect connects to the reaper container and sends the labels to it\n// so that it can clean up the containers with the same labels.\n//\n// It returns a channel that can be sent true to terminate the connection.\n// Returns an error if config.RyukDisabled is true.\nfunc (r *Reaper) connect(ctx context.Context) (chan bool, error) {\n\tvar d net.Dialer\n\tconn, err := d.DialContext(ctx, \"tcp\", r.Endpoint)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"dial reaper %s: %w\", r.Endpoint, err)\n\t}\n\n\tterminationSignal := make(chan bool)\n\tgo func() {\n\t\tdefer conn.Close()\n\t\tif err := r.handshake(conn); err != nil {\n\t\t\tLogger.Printf(\"Reaper handshake failed: %s\", err)\n\t\t}\n\t\t<-terminationSignal\n\t}()\n\treturn terminationSignal, nil\n}\n\n// handshake sends the labels to the reaper container and reads the ACK.\nfunc (r *Reaper) handshake(conn net.Conn) error {\n\tlabels := core.DefaultLabels(r.SessionID)\n\tlabelFilters := make([]string, 0, len(labels))\n\tfor l, v := range labels {\n\t\tlabelFilters = append(labelFilters, fmt.Sprintf(\"label=%s=%s\", l, v))\n\t}\n\n\tfilters := []byte(strings.Join(labelFilters, \"&\") + \"\\n\")\n\tbuf := make([]byte, 4)\n\tif _, err := conn.Write(filters); err != nil {\n\t\treturn fmt.Errorf(\"writing filters: %w\", err)\n\t}\n\n\tn, err := io.ReadFull(conn, buf)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"read ack: %w\", err)\n\t}\n\n\tif !bytes.Equal(reaperAck, buf[:n]) {\n\t\t// We have received the ACK so all done.\n\t\treturn fmt.Errorf(\"unexpected reaper response: %s\", buf[:n])\n\t}\n\n\treturn nil\n}\n\n// Labels returns the container labels to use so that this Reaper cleans them up\n// Deprecated: internally replaced by core.DefaultLabels(sessionID)\nfunc (r *Reaper) Labels() map[string]string {\n\treturn GenericLabels()\n}\n\n// isReaperImage returns true if the image name is the reaper image.\nfunc isReaperImage(name string) bool {\n\treturn strings.HasSuffix(name, config.ReaperDefaultImage)\n}\n"
        },
        {
          "name": "reaper_test.go",
          "type": "blob",
          "size": 17.08203125,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"os\"\n\t\"strconv\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/docker/docker/api/types/container\"\n\t\"github.com/docker/docker/api/types/network\"\n\t\"github.com/docker/docker/errdefs\"\n\t\"github.com/docker/go-connections/nat\"\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/testcontainers/testcontainers-go/internal/config\"\n\t\"github.com/testcontainers/testcontainers-go/internal/core\"\n\t\"github.com/testcontainers/testcontainers-go/wait\"\n)\n\n// testSessionID the tests need to create a reaper in a different session, so that it does not interfere with other tests\nconst testSessionID = \"this-is-a-different-session-id\"\n\ntype mockReaperProvider struct {\n\treq              ContainerRequest\n\thostConfig       *container.HostConfig\n\tendpointSettings map[string]*network.EndpointSettings\n\tconfig           TestcontainersConfig\n}\n\nfunc newMockReaperProvider(cfg config.Config) *mockReaperProvider {\n\tm := &mockReaperProvider{\n\t\tconfig: TestcontainersConfig{\n\t\t\tConfig: cfg,\n\t\t},\n\t}\n\n\treturn m\n}\n\nvar errExpected = errors.New(\"expected\")\n\nfunc (m *mockReaperProvider) RunContainer(ctx context.Context, req ContainerRequest) (Container, error) {\n\tm.req = req\n\n\tm.hostConfig = &container.HostConfig{}\n\tm.endpointSettings = map[string]*network.EndpointSettings{}\n\n\tif req.HostConfigModifier == nil {\n\t\treq.HostConfigModifier = defaultHostConfigModifier(req)\n\t}\n\treq.HostConfigModifier(m.hostConfig)\n\n\tif req.EnpointSettingsModifier != nil {\n\t\treq.EnpointSettingsModifier(m.endpointSettings)\n\t}\n\n\t// we're only interested in the request, so instead of mocking the Docker client\n\t// we'll error out here\n\treturn nil, errExpected\n}\n\nfunc (m *mockReaperProvider) Config() TestcontainersConfig {\n\treturn m.config\n}\n\n// expectedReaperRequest creates the expected reaper container request with the given customizations.\nfunc expectedReaperRequest(customize ...func(*ContainerRequest)) ContainerRequest {\n\treq := ContainerRequest{\n\t\tImage:        config.ReaperDefaultImage,\n\t\tExposedPorts: []string{\"8080/tcp\"},\n\t\tLabels:       core.DefaultLabels(testSessionID),\n\t\tHostConfigModifier: func(hostConfig *container.HostConfig) {\n\t\t\thostConfig.Binds = []string{core.MustExtractDockerSocket(context.Background()) + \":/var/run/docker.sock\"}\n\t\t},\n\t\tWaitingFor: wait.ForListeningPort(nat.Port(\"8080/tcp\")),\n\t\tEnv: map[string]string{\n\t\t\t\"RYUK_CONNECTION_TIMEOUT\":   \"1m0s\",\n\t\t\t\"RYUK_RECONNECTION_TIMEOUT\": \"10s\",\n\t\t},\n\t}\n\n\treq.Labels[core.LabelReaper] = \"true\"\n\treq.Labels[core.LabelRyuk] = \"true\"\n\tdelete(req.Labels, core.LabelReap)\n\n\tfor _, customize := range customize {\n\t\tcustomize(&req)\n\t}\n\n\treturn req\n}\n\n// reaperDisable disables / enables the reaper for the duration of the test.\nfunc reaperDisable(t *testing.T, disabled bool) {\n\tt.Helper()\n\n\tconfig.Reset()\n\tt.Setenv(\"TESTCONTAINERS_RYUK_DISABLED\", strconv.FormatBool(disabled))\n\tt.Cleanup(config.Reset)\n}\n\nfunc testContainerStart(t *testing.T) {\n\tt.Helper()\n\tctx := context.Background()\n\n\tctr, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage: nginxAlpineImage,\n\t\t\tExposedPorts: []string{\n\t\t\t\tnginxDefaultPort,\n\t\t\t},\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, ctr)\n\trequire.NoError(t, err)\n}\n\n// testReaperRunning validates that a reaper is running.\nfunc testReaperRunning(t *testing.T) {\n\tt.Helper()\n\n\tctx := context.Background()\n\tsessionID := core.SessionID()\n\treaperContainer, err := spawner.lookupContainer(ctx, sessionID)\n\trequire.NoError(t, err)\n\trequire.NotNil(t, reaperContainer)\n}\n\nfunc TestContainer(t *testing.T) {\n\treaperDisable(t, false)\n\n\tt.Run(\"start/reaper-enabled\", func(t *testing.T) {\n\t\ttestContainerStart(t)\n\t\ttestReaperRunning(t)\n\t})\n\n\tt.Run(\"stop/reaper-enabled\", func(t *testing.T) {\n\t\ttestContainerStop(t)\n\t\ttestReaperRunning(t)\n\t})\n\n\tt.Run(\"terminate/reaper-enabled\", func(t *testing.T) {\n\t\ttestContainerTerminate(t)\n\t\ttestReaperRunning(t)\n\t})\n\n\treaperDisable(t, true)\n\n\tt.Run(\"start/reaper-disabled\", func(t *testing.T) {\n\t\ttestContainerStart(t)\n\t})\n\n\tt.Run(\"stop/reaper-disabled\", func(t *testing.T) {\n\t\ttestContainerStop(t)\n\t})\n\n\tt.Run(\"terminate/reaper-disabled\", func(t *testing.T) {\n\t\ttestContainerTerminate(t)\n\t})\n}\n\n// testContainerStop tests stopping a container.\nfunc testContainerStop(t *testing.T) {\n\tt.Helper()\n\n\tctx := context.Background()\n\n\tnginxA, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage: nginxAlpineImage,\n\t\t\tExposedPorts: []string{\n\t\t\t\tnginxDefaultPort,\n\t\t\t},\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, nginxA)\n\trequire.NoError(t, err)\n\n\tstate, err := nginxA.State(ctx)\n\trequire.NoError(t, err)\n\trequire.True(t, state.Running)\n\n\tstopTimeout := 10 * time.Second\n\terr = nginxA.Stop(ctx, &stopTimeout)\n\trequire.NoError(t, err)\n\n\tstate, err = nginxA.State(ctx)\n\trequire.NoError(t, err)\n\trequire.False(t, state.Running)\n\trequire.Equal(t, \"exited\", state.Status)\n}\n\n// testContainerTerminate tests terminating a container.\nfunc testContainerTerminate(t *testing.T) {\n\tt.Helper()\n\tctx := context.Background()\n\n\tnginxA, err := GenericContainer(ctx, GenericContainerRequest{\n\t\tProviderType: providerType,\n\t\tContainerRequest: ContainerRequest{\n\t\t\tImage: nginxAlpineImage,\n\t\t\tExposedPorts: []string{\n\t\t\t\tnginxDefaultPort,\n\t\t\t},\n\t\t},\n\t\tStarted: true,\n\t})\n\tCleanupContainer(t, nginxA)\n\trequire.NoError(t, err)\n\n\tstate, err := nginxA.State(ctx)\n\trequire.NoError(t, err)\n\trequire.True(t, state.Running)\n\n\terr = nginxA.Terminate(ctx)\n\trequire.NoError(t, err)\n\n\t_, err = nginxA.State(ctx)\n\trequire.Error(t, err)\n}\n\nfunc Test_NewReaper(t *testing.T) {\n\treaperDisable(t, false)\n\n\tctx := context.Background()\n\n\tt.Run(\"non-privileged\", func(t *testing.T) {\n\t\ttestNewReaper(ctx, t,\n\t\t\tconfig.Config{\n\t\t\t\tRyukConnectionTimeout:   time.Minute,\n\t\t\t\tRyukReconnectionTimeout: 10 * time.Second,\n\t\t\t},\n\t\t\texpectedReaperRequest(),\n\t\t)\n\t})\n\n\tt.Run(\"privileged\", func(t *testing.T) {\n\t\ttestNewReaper(ctx, t,\n\t\t\tconfig.Config{\n\t\t\t\tRyukPrivileged:          true,\n\t\t\t\tRyukConnectionTimeout:   time.Minute,\n\t\t\t\tRyukReconnectionTimeout: 10 * time.Second,\n\t\t\t},\n\t\t\texpectedReaperRequest(),\n\t\t)\n\t})\n\n\tt.Run(\"custom-timeouts\", func(t *testing.T) {\n\t\ttestNewReaper(ctx, t,\n\t\t\tconfig.Config{\n\t\t\t\tRyukPrivileged:          true,\n\t\t\t\tRyukConnectionTimeout:   2 * time.Minute,\n\t\t\t\tRyukReconnectionTimeout: 20 * time.Second,\n\t\t\t},\n\t\t\texpectedReaperRequest(func(req *ContainerRequest) {\n\t\t\t\treq.Env = map[string]string{\n\t\t\t\t\t\"RYUK_CONNECTION_TIMEOUT\":   \"2m0s\",\n\t\t\t\t\t\"RYUK_RECONNECTION_TIMEOUT\": \"20s\",\n\t\t\t\t}\n\t\t\t}),\n\t\t)\n\t})\n\n\tt.Run(\"verbose\", func(t *testing.T) {\n\t\ttestNewReaper(ctx, t,\n\t\t\tconfig.Config{\n\t\t\t\tRyukPrivileged: true,\n\t\t\t\tRyukVerbose:    true,\n\t\t\t},\n\t\t\texpectedReaperRequest(func(req *ContainerRequest) {\n\t\t\t\treq.Env = map[string]string{\n\t\t\t\t\t\"RYUK_VERBOSE\": \"true\",\n\t\t\t\t}\n\t\t\t}),\n\t\t)\n\t})\n\n\tt.Run(\"docker-host\", func(t *testing.T) {\n\t\ttestNewReaper(context.WithValue(ctx, core.DockerHostContextKey, core.DockerSocketPathWithSchema), t,\n\t\t\tconfig.Config{\n\t\t\t\tRyukConnectionTimeout:   time.Minute,\n\t\t\t\tRyukReconnectionTimeout: 10 * time.Second,\n\t\t\t},\n\t\t\texpectedReaperRequest(func(req *ContainerRequest) {\n\t\t\t\treq.HostConfigModifier = func(hostConfig *container.HostConfig) {\n\t\t\t\t\thostConfig.Binds = []string{core.MustExtractDockerSocket(ctx) + \":/var/run/docker.sock\"}\n\t\t\t\t}\n\t\t\t}),\n\t\t)\n\t})\n\n\tt.Run(\"hub-prefix\", func(t *testing.T) {\n\t\ttestNewReaper(context.WithValue(ctx, core.DockerHostContextKey, core.DockerSocketPathWithSchema), t,\n\t\t\tconfig.Config{\n\t\t\t\tHubImageNamePrefix:      \"registry.mycompany.com/mirror\",\n\t\t\t\tRyukPrivileged:          true,\n\t\t\t\tRyukConnectionTimeout:   time.Minute,\n\t\t\t\tRyukReconnectionTimeout: 10 * time.Second,\n\t\t\t},\n\t\t\texpectedReaperRequest(func(req *ContainerRequest) {\n\t\t\t\treq.Image = config.ReaperDefaultImage\n\t\t\t\treq.Privileged = true\n\t\t\t}),\n\t\t)\n\t})\n\n\tt.Run(\"hub-prefix-env\", func(t *testing.T) {\n\t\tconfig.Reset()\n\t\tt.Cleanup(config.Reset)\n\n\t\tt.Setenv(\"TESTCONTAINERS_HUB_IMAGE_NAME_PREFIX\", \"registry.mycompany.com/mirror\")\n\t\ttestNewReaper(context.WithValue(ctx, core.DockerHostContextKey, core.DockerSocketPathWithSchema), t,\n\t\t\tconfig.Config{\n\t\t\t\tRyukPrivileged:          true,\n\t\t\t\tRyukConnectionTimeout:   time.Minute,\n\t\t\t\tRyukReconnectionTimeout: 10 * time.Second,\n\t\t\t},\n\t\t\texpectedReaperRequest(func(req *ContainerRequest) {\n\t\t\t\treq.Image = config.ReaperDefaultImage\n\t\t\t\treq.Privileged = true\n\t\t\t}),\n\t\t)\n\t})\n}\n\nfunc testNewReaper(ctx context.Context, t *testing.T, cfg config.Config, expected ContainerRequest) {\n\tt.Helper()\n\n\tif prefix := os.Getenv(\"TESTCONTAINERS_HUB_IMAGE_NAME_PREFIX\"); prefix != \"\" {\n\t\tcfg.HubImageNamePrefix = prefix\n\t}\n\n\tprovider := newMockReaperProvider(cfg)\n\n\t// We need a new reaperSpawner for each test case to avoid reusing\n\t// an existing reaper instance.\n\tspawner := &reaperSpawner{}\n\treaper, err := spawner.reaper(ctx, testSessionID, provider)\n\tcleanupReaper(t, reaper, spawner)\n\t// We should have errored out see mockReaperProvider.RunContainer.\n\trequire.ErrorIs(t, err, errExpected)\n\n\trequire.Equal(t, expected.Image, provider.req.Image, \"expected image doesn't match the submitted request\")\n\trequire.Equal(t, expected.ExposedPorts, provider.req.ExposedPorts, \"expected exposed ports don't match the submitted request\")\n\trequire.Equal(t, expected.Labels, provider.req.Labels, \"expected labels don't match the submitted request\")\n\trequire.Equal(t, expected.Mounts, provider.req.Mounts, \"expected mounts don't match the submitted request\")\n\trequire.Equal(t, expected.WaitingFor, provider.req.WaitingFor, \"expected waitingFor don't match the submitted request\")\n\trequire.Equal(t, expected.Env, provider.req.Env, \"expected env doesn't match the submitted request\")\n\n\t// checks for reaper's preCreationCallback fields\n\trequire.Equal(t, container.NetworkMode(Bridge), provider.hostConfig.NetworkMode, \"expected networkMode doesn't match the submitted request\")\n\trequire.True(t, provider.hostConfig.AutoRemove, \"expected networkMode doesn't match the submitted request\")\n}\n\nfunc Test_ReaperReusedIfHealthy(t *testing.T) {\n\treaperDisable(t, false)\n\n\tSkipIfProviderIsNotHealthy(t)\n\n\tctx := context.Background()\n\t// As other integration tests run with the (shared) Reaper as well, re-use the instance to not interrupt other tests\n\tif spawner.instance != nil {\n\t\tt.Cleanup(func() {\n\t\t\trequire.NoError(t, spawner.cleanup())\n\t\t})\n\t}\n\n\tprovider, err := ProviderDocker.GetProvider()\n\trequire.NoError(t, err)\n\n\treaper, err := spawner.reaper(context.WithValue(ctx, core.DockerHostContextKey, provider.(*DockerProvider).host), testSessionID, provider)\n\tcleanupReaper(t, reaper, spawner)\n\trequire.NoError(t, err, \"creating the Reaper should not error\")\n\n\treaperReused, err := spawner.reaper(context.WithValue(ctx, core.DockerHostContextKey, provider.(*DockerProvider).host), testSessionID, provider)\n\tcleanupReaper(t, reaper, spawner)\n\trequire.NoError(t, err, \"reusing the Reaper should not error\")\n\n\t// Ensure the internal state of both reaper instances is the same\n\trequire.Equal(t, reaper.SessionID, reaperReused.SessionID, \"expecting the same SessionID\")\n\trequire.Equal(t, reaper.Endpoint, reaperReused.Endpoint, \"expecting the same reaper endpoint\")\n\trequire.Equal(t, reaper.Provider, reaperReused.Provider, \"expecting the same container provider\")\n\trequire.Equal(t, reaper.container.GetContainerID(), reaperReused.container.GetContainerID(), \"expecting the same container ID\")\n\trequire.Equal(t, reaper.container.SessionID(), reaperReused.container.SessionID(), \"expecting the same session ID\")\n\n\ttermSignal, err := reaper.Connect()\n\tcleanupTermSignal(t, termSignal)\n\trequire.NoError(t, err, \"connecting to Reaper should be successful\")\n}\n\nfunc Test_RecreateReaperIfTerminated(t *testing.T) {\n\treaperDisable(t, false)\n\n\tSkipIfProviderIsNotHealthy(t)\n\n\tprovider, err := ProviderDocker.GetProvider()\n\trequire.NoError(t, err)\n\n\tctx := context.Background()\n\treaper, err := spawner.reaper(context.WithValue(ctx, core.DockerHostContextKey, provider.(*DockerProvider).host), testSessionID, provider)\n\tcleanupReaper(t, reaper, spawner)\n\trequire.NoError(t, err, \"creating the Reaper should not error\")\n\n\ttermSignal, err := reaper.Connect()\n\tif termSignal != nil {\n\t\ttermSignal <- true\n\t}\n\trequire.NoError(t, err)\n\n\t// Wait for up to ryuk's default reconnect timeout + 1s to allow for a graceful shutdown/cleanup of the container.\n\ttimeout := time.NewTimer(time.Second * 11)\n\tt.Cleanup(func() {\n\t\ttimeout.Stop()\n\t})\n\tfor {\n\t\tstate, err := reaper.container.State(ctx)\n\t\tif err != nil {\n\t\t\tif errdefs.IsNotFound(err) {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\trequire.NoError(t, err)\n\t\t}\n\n\t\tif !state.Running {\n\t\t\tbreak\n\t\t}\n\n\t\tselect {\n\t\tcase <-timeout.C:\n\t\t\tt.Fatal(\"reaper container should have been terminated\")\n\t\tdefault:\n\t\t}\n\n\t\ttime.Sleep(time.Millisecond * 100)\n\t}\n\n\trecreatedReaper, err := spawner.reaper(context.WithValue(ctx, core.DockerHostContextKey, provider.(*DockerProvider).host), testSessionID, provider)\n\tcleanupReaper(t, recreatedReaper, spawner)\n\trequire.NoError(t, err, \"creating the Reaper should not error\")\n\trequire.NotEqual(t, reaper.container.GetContainerID(), recreatedReaper.container.GetContainerID(), \"expected different container ID\")\n\n\trecreatedTermSignal, err := recreatedReaper.Connect()\n\tcleanupTermSignal(t, recreatedTermSignal)\n\trequire.NoError(t, err, \"connecting to Reaper should be successful\")\n}\n\nfunc TestReaper_reuseItFromOtherTestProgramUsingDocker(t *testing.T) {\n\treaperDisable(t, false)\n\n\t// Explicitly set the reaper instance to nil to simulate another test\n\t// program in the same session accessing the same reaper.\n\tspawner.instance = nil\n\n\tSkipIfProviderIsNotHealthy(t)\n\n\tctx := context.Background()\n\t// As other integration tests run with the (shared) Reaper as well,\n\t// re-use the instance to not interrupt other tests.\n\tif spawner.instance != nil {\n\t\tt.Cleanup(func() {\n\t\t\trequire.NoError(t, spawner.cleanup())\n\t\t})\n\t}\n\n\tprovider, err := ProviderDocker.GetProvider()\n\trequire.NoError(t, err)\n\n\treaper, err := spawner.reaper(context.WithValue(ctx, core.DockerHostContextKey, provider.(*DockerProvider).host), testSessionID, provider)\n\tcleanupReaper(t, reaper, spawner)\n\trequire.NoError(t, err, \"creating the Reaper should not error\")\n\n\t// Explicitly reset the reaper instance to nil to simulate another test\n\t// program in the same session accessing the same reaper.\n\tspawner.instance = nil\n\n\treaperReused, err := spawner.reaper(context.WithValue(ctx, core.DockerHostContextKey, provider.(*DockerProvider).host), testSessionID, provider)\n\tcleanupReaper(t, reaper, spawner)\n\trequire.NoError(t, err, \"reusing the Reaper should not error\")\n\n\t// Ensure that the internal state of both reaper instances is the same.\n\trequire.Equal(t, reaper.SessionID, reaperReused.SessionID, \"expecting the same SessionID\")\n\trequire.Equal(t, reaper.Endpoint, reaperReused.Endpoint, \"expecting the same reaper endpoint\")\n\trequire.Equal(t, reaper.Provider, reaperReused.Provider, \"expecting the same container provider\")\n\trequire.Equal(t, reaper.container.GetContainerID(), reaperReused.container.GetContainerID(), \"expecting the same container ID\")\n\trequire.Equal(t, reaper.container.SessionID(), reaperReused.container.SessionID(), \"expecting the same session ID\")\n\n\ttermSignal, err := reaper.Connect()\n\tcleanupTermSignal(t, termSignal)\n\trequire.NoError(t, err, \"connecting to Reaper should be successful\")\n}\n\n// TestReaper_ReuseRunning tests whether reusing the reaper if using\n// testcontainers from concurrently multiple packages works as expected. In this\n// case, global locks are without any effect as Go tests different packages\n// isolated. Therefore, this test does not use the same logic with locks on\n// purpose. We expect reaper creation to still succeed in case a reaper is\n// already running for the same session id by returning its container instance\n// instead.\nfunc TestReaper_ReuseRunning(t *testing.T) {\n\treaperDisable(t, false)\n\n\tconst concurrency = 64\n\n\ttimeout, cancel := context.WithTimeout(context.Background(), time.Minute)\n\tdefer cancel()\n\n\tsessionID := SessionID()\n\n\tdockerProvider, err := NewDockerProvider()\n\trequire.NoError(t, err, \"new docker provider should not fail\")\n\n\tobtainedReaperContainerIDs := make([]string, concurrency)\n\tvar wg sync.WaitGroup\n\tfor i := 0; i < concurrency; i++ {\n\t\twg.Add(1)\n\t\tgo func(i int) {\n\t\t\tdefer wg.Done()\n\t\t\tspawner := &reaperSpawner{}\n\t\t\treaper, err := spawner.reaper(timeout, sessionID, dockerProvider)\n\t\t\tcleanupReaper(t, reaper, spawner)\n\t\t\trequire.NoError(t, err)\n\n\t\t\tobtainedReaperContainerIDs[i] = reaper.container.GetContainerID()\n\t\t}(i)\n\t}\n\twg.Wait()\n\n\t// Assure that all calls returned the same container.\n\tfirstContainerID := obtainedReaperContainerIDs[0]\n\tfor i, containerID := range obtainedReaperContainerIDs {\n\t\trequire.Equal(t, firstContainerID, containerID, \"call %d should have returned same container id\", i)\n\t}\n}\n\nfunc TestSpawnerBackoff(t *testing.T) {\n\tb := spawner.backoff()\n\tfor i := 0; i < 100; i++ {\n\t\trequire.LessOrEqual(t, b.NextBackOff(), time.Millisecond*250, \"backoff should not exceed max interval\")\n\t}\n}\n\n// cleanupReaper schedules reaper for cleanup if it's not nil.\nfunc cleanupReaper(t *testing.T, reaper *Reaper, spawner *reaperSpawner) {\n\tt.Helper()\n\n\tif reaper == nil {\n\t\treturn\n\t}\n\n\tt.Cleanup(func() {\n\t\treaper.close()\n\t\trequire.NoError(t, spawner.cleanup())\n\t})\n}\n\n// cleanupTermSignal ensures that termSignal\nfunc cleanupTermSignal(t *testing.T, termSignal chan bool) {\n\tt.Helper()\n\n\tt.Cleanup(func() {\n\t\tif termSignal != nil {\n\t\t\ttermSignal <- true\n\t\t}\n\t})\n}\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.14453125,
          "content": "mkdocs==1.5.3\nmkdocs-codeinclude-plugin==0.2.1\nmkdocs-include-markdown-plugin==6.2.2\nmkdocs-material==9.5.18\nmkdocs-markdownextradata-plugin==0.2.6\n"
        },
        {
          "name": "runtime.txt",
          "type": "blob",
          "size": 0.00390625,
          "content": "3.8\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "sonar-project.properties",
          "type": "blob",
          "size": 2.109375,
          "content": "# This file is autogenerated by the 'modulegen' tool.\n# Github organization linked to sonarcloud\nsonar.organization=testcontainers\n\n# Project key from sonarcloud dashboard for Github Action, otherwise pick a project key you like\nsonar.projectKey=testcontainers_testcontainers-go\n\nsonar.projectName=testcontainers-go\n\nsonar.projectVersion=v0.35.0\n\nsonar.sources=.\n\nsonar.exclusions=**/*_test.go,**/vendor/**,**/testdata/**\n\nsonar.tests=.\nsonar.test.inclusions=**/*_test.go\nsonar.test.exclusions=**/vendor/**\n\nsonar.go.coverage.reportPaths=**/coverage.out\nsonar.go.tests.reportPaths=TEST-unit.xml,examples/nginx/TEST-unit.xml,examples/toxiproxy/TEST-unit.xml,modulegen/TEST-unit.xml,modules/artemis/TEST-unit.xml,modules/azurite/TEST-unit.xml,modules/cassandra/TEST-unit.xml,modules/chroma/TEST-unit.xml,modules/clickhouse/TEST-unit.xml,modules/cockroachdb/TEST-unit.xml,modules/compose/TEST-unit.xml,modules/consul/TEST-unit.xml,modules/couchbase/TEST-unit.xml,modules/databend/TEST-unit.xml,modules/dolt/TEST-unit.xml,modules/dynamodb/TEST-unit.xml,modules/elasticsearch/TEST-unit.xml,modules/etcd/TEST-unit.xml,modules/gcloud/TEST-unit.xml,modules/grafana-lgtm/TEST-unit.xml,modules/inbucket/TEST-unit.xml,modules/influxdb/TEST-unit.xml,modules/k3s/TEST-unit.xml,modules/k6/TEST-unit.xml,modules/kafka/TEST-unit.xml,modules/localstack/TEST-unit.xml,modules/mariadb/TEST-unit.xml,modules/meilisearch/TEST-unit.xml,modules/milvus/TEST-unit.xml,modules/minio/TEST-unit.xml,modules/mockserver/TEST-unit.xml,modules/mongodb/TEST-unit.xml,modules/mssql/TEST-unit.xml,modules/mysql/TEST-unit.xml,modules/nats/TEST-unit.xml,modules/neo4j/TEST-unit.xml,modules/ollama/TEST-unit.xml,modules/openfga/TEST-unit.xml,modules/openldap/TEST-unit.xml,modules/opensearch/TEST-unit.xml,modules/postgres/TEST-unit.xml,modules/pulsar/TEST-unit.xml,modules/qdrant/TEST-unit.xml,modules/rabbitmq/TEST-unit.xml,modules/redis/TEST-unit.xml,modules/redpanda/TEST-unit.xml,modules/registry/TEST-unit.xml,modules/surrealdb/TEST-unit.xml,modules/valkey/TEST-unit.xml,modules/vault/TEST-unit.xml,modules/vearch/TEST-unit.xml,modules/weaviate/TEST-unit.xml,modules/yugabytedb/TEST-unit.xml\n"
        },
        {
          "name": "testcontainers.go",
          "type": "blob",
          "size": 2.822265625,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\n\t\"github.com/testcontainers/testcontainers-go/internal/core\"\n)\n\n// Deprecated: use MustExtractDockerHost instead.\nfunc ExtractDockerSocket() string {\n\treturn MustExtractDockerSocket(context.Background())\n}\n\n// MustExtractDockerSocket Extracts the docker socket from the different alternatives, removing the socket schema.\n// Use this function to get the docker socket path, not the host (e.g. mounting the socket in a container).\n// This function does not consider Windows containers at the moment.\n// The possible alternatives are:\n//\n//  1. Docker host from the \"tc.host\" property in the ~/.testcontainers.properties file.\n//  2. The TESTCONTAINERS_DOCKER_SOCKET_OVERRIDE environment variable.\n//  3. Using a Docker client, check if the Info().OperativeSystem is \"Docker Desktop\" and return the default docker socket path for rootless docker.\n//  4. Else, Get the current Docker Host from the existing strategies: see MustExtractDockerHost.\n//  5. If the socket contains the unix schema, the schema is removed (e.g. unix:///var/run/docker.sock -> /var/run/docker.sock)\n//  6. Else, the default location of the docker socket is used (/var/run/docker.sock)\n//\n// It panics if a Docker client cannot be created, or the Docker host cannot be discovered.\nfunc MustExtractDockerSocket(ctx context.Context) string {\n\treturn core.MustExtractDockerSocket(ctx)\n}\n\n// SessionID returns a unique session ID for the current test session. Because each Go package\n// will be run in a separate process, we need a way to identify the current test session.\n// By test session, we mean:\n//   - a single \"go test\" invocation (including flags)\n//   - a single \"go test ./...\" invocation (including flags)\n//   - the execution of a single test or a set of tests using the IDE\n//\n// As a consequence, with the sole goal of aggregating test execution across multiple\n// packages, this variable will contain the value of the parent process ID (pid) of the current process\n// and its creation date, to use it to generate a unique session ID. We are using the parent pid because\n// the current process will be a child process of:\n//   - the process that is running the tests, e.g.: \"go test\";\n//   - the process that is running the application in development mode, e.g. \"go run main.go -tags dev\";\n//   - the process that is running the tests in the IDE, e.g.: \"go test ./...\".\n//\n// Finally, we will hash the combination of the \"testcontainers-go:\" string with the parent pid\n// and the creation date of that parent process to generate a unique session ID.\n//\n// This sessionID will be used to:\n//   - identify the test session, aggregating the test execution of multiple packages in the same test session.\n//   - tag the containers created by testcontainers-go, adding a label to the container with the session ID.\nfunc SessionID() string {\n\treturn core.SessionID()\n}\n"
        },
        {
          "name": "testcontainers_test.go",
          "type": "blob",
          "size": 2.0654296875,
          "content": "package testcontainers\n\nimport (\n\t\"os\"\n\t\"os/exec\"\n\t\"regexp\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc TestSessionID(t *testing.T) {\n\tt.Run(\"SessionID() returns a non-empty string\", func(t *testing.T) {\n\t\tsessionID := SessionID()\n\t\trequire.NotEmptyf(t, sessionID, \"SessionID() returned an empty string\")\n\t})\n\n\tt.Run(\"Multiple calls to SessionID() return the same value\", func(t *testing.T) {\n\t\tsessionID1 := SessionID()\n\t\tsessionID2 := SessionID()\n\t\trequire.Equalf(t, sessionID1, sessionID2, \"SessionID() returned different values: %s != %s\", sessionID1, sessionID2)\n\t})\n\n\tt.Run(\"Multiple calls to SessionID() in multiple goroutines return the same value\", func(t *testing.T) {\n\t\tsessionID1 := \"\"\n\t\tsessionID2 := \"\"\n\n\t\tdone := make(chan bool)\n\t\tgo func() {\n\t\t\tsessionID1 = SessionID()\n\t\t\tdone <- true\n\t\t}()\n\n\t\tgo func() {\n\t\t\tsessionID2 = SessionID()\n\t\t\tdone <- true\n\t\t}()\n\n\t\t<-done\n\t\t<-done\n\n\t\trequire.Equalf(t, sessionID1, sessionID2, \"SessionID() returned different values: %s != %s\", sessionID1, sessionID2)\n\t})\n\n\tt.Run(\"SessionID() from different child processes returns the same value\", func(t *testing.T) {\n\t\targs := []string{\"test\", \"./...\", \"-v\", \"-run\", \"TestSessionIDHelper\"}\n\t\tenv := append(os.Environ(), \"TESTCONTAINERS_SESSION_ID_HELPER=1\")\n\n\t\tre := regexp.MustCompile(\">>>(.*)<<<\")\n\n\t\tcmd1 := exec.Command(\"go\", args...)\n\t\tcmd1.Env = env\n\t\tstdoutStderr1, err := cmd1.CombinedOutput()\n\t\trequire.NoErrorf(t, err, \"cmd1.Run() failed with %s\", err)\n\t\tsessionID1 := re.FindString(string(stdoutStderr1))\n\n\t\tcmd2 := exec.Command(\"go\", args...)\n\t\tcmd2.Env = env\n\t\tstdoutStderr2, err := cmd2.CombinedOutput()\n\t\trequire.NoErrorf(t, err, \"cmd2.Run() failed with %s\", err)\n\t\tsessionID2 := re.FindString(string(stdoutStderr2))\n\n\t\trequire.Equalf(t, sessionID1, sessionID2, \"SessionID() returned different values: %s != %s\", sessionID1, sessionID2)\n\t})\n}\n\n// Not a real test, used to print out the session ID\nfunc TestSessionIDHelper(t *testing.T) {\n\tif os.Getenv(\"TESTCONTAINERS_SESSION_ID_HELPER\") == \"\" {\n\t\tt.Skip(\"Not a real test, used as a test helper\")\n\t}\n\n\tt.Logf(\">>>%s<<<\\n\", SessionID())\n}\n"
        },
        {
          "name": "testdata",
          "type": "tree",
          "content": null
        },
        {
          "name": "testhelpers_test.go",
          "type": "blob",
          "size": 0.1005859375,
          "content": "package testcontainers_test\n\nconst (\n\tnginxAlpineImage = \"nginx:alpine\"\n\tnginxDefaultPort = \"80/tcp\"\n)\n"
        },
        {
          "name": "testing.go",
          "type": "blob",
          "size": 4.59375,
          "content": "package testcontainers\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io\"\n\t\"regexp\"\n\t\"testing\"\n\n\t\"github.com/docker/docker/errdefs\"\n\t\"github.com/stretchr/testify/require\"\n)\n\n// errAlreadyInProgress is a regular expression that matches the error for a container\n// removal that is already in progress.\nvar errAlreadyInProgress = regexp.MustCompile(`removal of container .* is already in progress`)\n\n// SkipIfProviderIsNotHealthy is a utility function capable of skipping tests\n// if the provider is not healthy, or running at all.\n// This is a function designed to be used in your test, when Docker is not mandatory for CI/CD.\n// In this way tests that depend on Testcontainers won't run if the provider is provisioned correctly.\nfunc SkipIfProviderIsNotHealthy(t *testing.T) {\n\tt.Helper()\n\tctx := context.Background()\n\tprovider, err := ProviderDocker.GetProvider()\n\tif err != nil {\n\t\tt.Skipf(\"Docker is not running. TestContainers can't perform is work without it: %s\", err)\n\t}\n\terr = provider.Health(ctx)\n\tif err != nil {\n\t\tt.Skipf(\"Docker is not running. TestContainers can't perform is work without it: %s\", err)\n\t}\n}\n\n// SkipIfDockerDesktop is a utility function capable of skipping tests\n// if tests are run using Docker Desktop.\nfunc SkipIfDockerDesktop(t *testing.T, ctx context.Context) {\n\tt.Helper()\n\tcli, err := NewDockerClientWithOpts(ctx)\n\trequire.NoErrorf(t, err, \"failed to create docker client: %s\", err)\n\n\tinfo, err := cli.Info(ctx)\n\trequire.NoErrorf(t, err, \"failed to get docker info: %s\", err)\n\n\tif info.OperatingSystem == \"Docker Desktop\" {\n\t\tt.Skip(\"Skipping test that requires host network access when running in Docker Desktop\")\n\t}\n}\n\n// exampleLogConsumer {\n\n// StdoutLogConsumer is a LogConsumer that prints the log to stdout\ntype StdoutLogConsumer struct{}\n\n// Accept prints the log to stdout\nfunc (lc *StdoutLogConsumer) Accept(l Log) {\n\tfmt.Print(string(l.Content))\n}\n\n// }\n\n// CleanupContainer is a helper function that schedules the container\n// to be stopped / terminated when the test ends.\n//\n// This should be called as a defer directly after (before any error check)\n// of [GenericContainer](...) or a modules Run(...) in a test to ensure the\n// container is stopped when the function ends.\n//\n// before any error check. If container is nil, its a no-op.\nfunc CleanupContainer(tb testing.TB, ctr Container, options ...TerminateOption) {\n\ttb.Helper()\n\n\ttb.Cleanup(func() {\n\t\tnoErrorOrIgnored(tb, TerminateContainer(ctr, options...))\n\t})\n}\n\n// CleanupNetwork is a helper function that schedules the network to be\n// removed when the test ends.\n// This should be the first call after NewNetwork(...) in a test before\n// any error check. If network is nil, its a no-op.\nfunc CleanupNetwork(tb testing.TB, network Network) {\n\ttb.Helper()\n\n\ttb.Cleanup(func() {\n\t\tif !isNil(network) {\n\t\t\tnoErrorOrIgnored(tb, network.Remove(context.Background()))\n\t\t}\n\t})\n}\n\n// noErrorOrIgnored is a helper function that checks if the error is nil or an error\n// we can ignore.\nfunc noErrorOrIgnored(tb testing.TB, err error) {\n\ttb.Helper()\n\n\tif isCleanupSafe(err) {\n\t\treturn\n\t}\n\n\trequire.NoError(tb, err)\n}\n\n// causer is an interface that allows to get the cause of an error.\ntype causer interface {\n\tCause() error\n}\n\n// wrapErr is an interface that allows to unwrap an error.\ntype wrapErr interface {\n\tUnwrap() error\n}\n\n// unwrapErrs is an interface that allows to unwrap multiple errors.\ntype unwrapErrs interface {\n\tUnwrap() []error\n}\n\n// isCleanupSafe reports whether all errors in err's tree are one of the\n// following, so can safely be ignored:\n//   - nil\n//   - not found\n//   - already in progress\nfunc isCleanupSafe(err error) bool {\n\tif err == nil {\n\t\treturn true\n\t}\n\n\tswitch x := err.(type) { //nolint:errorlint // We need to check for interfaces.\n\tcase errdefs.ErrNotFound:\n\t\treturn true\n\tcase errdefs.ErrConflict:\n\t\t// Terminating a container that is already terminating.\n\t\tif errAlreadyInProgress.MatchString(err.Error()) {\n\t\t\treturn true\n\t\t}\n\t\treturn false\n\tcase causer:\n\t\treturn isCleanupSafe(x.Cause())\n\tcase wrapErr:\n\t\treturn isCleanupSafe(x.Unwrap())\n\tcase unwrapErrs:\n\t\tfor _, e := range x.Unwrap() {\n\t\t\tif !isCleanupSafe(e) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\treturn true\n\tdefault:\n\t\treturn false\n\t}\n}\n\n// RequireContainerExec is a helper function that executes a command in a container\n// It insures that there is no error during the execution\n// Finally returns the output of its execution\nfunc RequireContainerExec(ctx context.Context, t *testing.T, container Container, cmd []string) string {\n\tt.Helper()\n\n\tcode, out, err := container.Exec(ctx, cmd)\n\trequire.NoError(t, err)\n\trequire.Zero(t, code)\n\n\tcheckBytes, err := io.ReadAll(out)\n\trequire.NoError(t, err)\n\treturn string(checkBytes)\n}\n"
        },
        {
          "name": "testing_test.go",
          "type": "blob",
          "size": 1.8349609375,
          "content": "package testcontainers\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc ExampleSkipIfProviderIsNotHealthy() {\n\tSkipIfProviderIsNotHealthy(&testing.T{})\n}\n\ntype notFoundError struct{}\n\nfunc (notFoundError) NotFound() {}\n\nfunc (notFoundError) Error() string {\n\treturn \"not found\"\n}\n\nfunc Test_isNotFound(t *testing.T) {\n\ttests := map[string]struct {\n\t\terr  error\n\t\twant bool\n\t}{\n\t\t\"nil\": {\n\t\t\terr:  nil,\n\t\t\twant: true,\n\t\t},\n\t\t\"join-nils\": {\n\t\t\terr:  errors.Join(nil, nil),\n\t\t\twant: true,\n\t\t},\n\t\t\"join-nil-not-found\": {\n\t\t\terr:  errors.Join(nil, notFoundError{}),\n\t\t\twant: true,\n\t\t},\n\t\t\"not-found\": {\n\t\t\terr:  notFoundError{},\n\t\t\twant: true,\n\t\t},\n\t\t\"other\": {\n\t\t\terr:  errors.New(\"other\"),\n\t\t\twant: false,\n\t\t},\n\t\t\"join-other\": {\n\t\t\terr:  errors.Join(nil, notFoundError{}, errors.New(\"other\")),\n\t\t\twant: false,\n\t\t},\n\t\t\"warp\": {\n\t\t\terr:  fmt.Errorf(\"wrap: %w\", notFoundError{}),\n\t\t\twant: true,\n\t\t},\n\t\t\"multi-warp\": {\n\t\t\terr:  fmt.Errorf(\"wrap: %w\", fmt.Errorf(\"wrap: %w\", notFoundError{})),\n\t\t\twant: true,\n\t\t},\n\t\t\"multi-warp-other\": {\n\t\t\terr:  fmt.Errorf(\"wrap: %w\", fmt.Errorf(\"wrap: %w\", errors.New(\"other\"))),\n\t\t\twant: false,\n\t\t},\n\t\t\"multi-warp-other-not-found\": {\n\t\t\terr:  fmt.Errorf(\"wrap: %w\", fmt.Errorf(\"wrap: %w %w\", errors.New(\"other\"), notFoundError{})),\n\t\t\twant: false,\n\t\t},\n\t\t\"multi-warp-not-found-nil\": {\n\t\t\terr:  fmt.Errorf(\"wrap: %w\", fmt.Errorf(\"wrap: %w %w\", nil, notFoundError{})),\n\t\t\twant: true,\n\t\t},\n\t\t\"multi-join-not-found-other\": {\n\t\t\terr:  errors.Join(nil, fmt.Errorf(\"wrap: %w\", errors.Join(notFoundError{}, errors.New(\"other\")))),\n\t\t\twant: false,\n\t\t},\n\t\t\"multi-join-not-found-nil\": {\n\t\t\terr:  errors.Join(nil, fmt.Errorf(\"wrap: %w\", errors.Join(notFoundError{}, nil))),\n\t\t\twant: true,\n\t\t},\n\t}\n\tfor name, tc := range tests {\n\t\tt.Run(name, func(t *testing.T) {\n\t\t\trequire.Equal(t, tc.want, isCleanupSafe(tc.err))\n\t\t})\n\t}\n}\n"
        },
        {
          "name": "wait",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}