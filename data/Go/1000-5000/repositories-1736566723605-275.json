{
  "metadata": {
    "timestamp": 1736566723605,
    "page": 275,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI4MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "mjl-/mox",
      "stars": 3784,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.0712890625,
          "content": "/mox\n/testdata/\n/node_modules/\n/local/\n/rfc/\n/cover.*\n/.go/\n/tmp/\n/.git/\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.5390625,
          "content": "/mox\n/mox.exe\n/rfc/[0-9][0-9]*\n/rfc/xr/\n/local/\n/testdata/check/\n/testdata/*/data/\n/testdata/ctl/dkim/\n/testdata/empty/\n/testdata/exportmaildir/\n/testdata/exportmbox/\n/testdata/imap/data/\n/testdata/junk/*.bloom\n/testdata/junk/*.db\n/testdata/sent/\n/testdata/smtp/datajunk/\n/testdata/smtp/postmaster/\n/testdata/train/\n/testdata/upgradetest.mbox.gz\n/testdata/integration/example-integration.zone\n/testdata/integration/tmp-pebble-ca.pem\n/cover.out\n/cover.html\n/.go/\n/node_modules/\n/upgrade*-verifydata.*.pprof\n/upgrade*-openaccounts.*.pprof\n/website/html/\n"
        },
        {
          "name": ".go",
          "type": "tree",
          "content": null
        },
        {
          "name": ".jshintrc",
          "type": "blob",
          "size": 0.1728515625,
          "content": "{\n\t\"esversion\": 9,\n\t\"asi\": true,\n\t\"strict\": \"implied\",\n\t\"globals\": {\n\t\t\"self\": true,\n\t\t\"window\": true,\n\t\t\"console\": true,\n\t\t\"document\": true,\n\t\t\"Node\": true,\n\t\t\"api\": true\n\t}\n}\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.701171875,
          "content": "FROM golang:1-alpine AS build\nWORKDIR /build\nCOPY . .\nRUN GOPROXY=off CGO_ENABLED=0 go build -trimpath\n\n# Using latest may break at some point, but will hopefully be convenient most of the time.\nFROM alpine:latest\nWORKDIR /mox\nCOPY --from=build /build/mox /bin/mox\n\nRUN apk add --no-cache tzdata\n\n# SMTP for incoming message delivery.\nEXPOSE 25/tcp\n# SMTP/submission with TLS.\nEXPOSE 465/tcp\n# SMTP/submission without initial TLS.\nEXPOSE 587/tcp\n# HTTP for internal account and admin pages.\nEXPOSE 80/tcp\n# HTTPS for ACME (Let's Encrypt), MTA-STS and autoconfig.\nEXPOSE 443/tcp\n# IMAP with TLS.\nEXPOSE 993/tcp\n# IMAP without initial TLS.\nEXPOSE 143/tcp\n# Prometheus metrics.\nEXPOSE 8010/tcp\n\nCMD [\"/bin/mox\", \"serve\"]\n"
        },
        {
          "name": "Dockerfile.imaptest",
          "type": "blob",
          "size": 0.458984375,
          "content": "FROM alpine:latest\n\nRUN apk --no-cache add build-base\nWORKDIR /src\nRUN wget http://dovecot.org/nightly/dovecot-latest.tar.gz && tar -zxvf dovecot-latest.tar.gz && cd dovecot-0.0.0-* && ./configure && make install && cd ..\nRUN wget http://dovecot.org/nightly/imaptest/imaptest-latest.tar.gz && tar -zxvf imaptest-latest.tar.gz && cd dovecot-0.0-imaptest-0.0.0-* && ./configure --with-dovecot=$(ls -d ../dovecot-0.0.0-*) && make install\nENTRYPOINT /usr/local/bin/imaptest\n"
        },
        {
          "name": "Dockerfile.moximaptest",
          "type": "blob",
          "size": 0.28515625,
          "content": "FROM golang:1-alpine AS build\nWORKDIR /build\nCOPY . .\nRUN GOPROXY=off CGO_ENABLED=0 go build -trimpath\n\n# Using latest may break at some point, but will hopefully be convenient most of the time.\nFROM alpine:latest\nWORKDIR /mox\nCOPY --from=build /build/mox /bin/mox\n\nCMD [\"/bin/mox\", \"serve\"]\n"
        },
        {
          "name": "Dockerfile.release",
          "type": "blob",
          "size": 1.060546875,
          "content": "FROM --platform=linux/amd64 docker.io/golang:1-alpine AS build\n# note: cannot use $TARGETOS or $TARGETARCH because apparently the --platform in\n# the FROM above overrides the actual target os/arch from the command-line.\nARG goos\nARG goarch\nWORKDIR /\nARG moxversion\nRUN CGO_ENABLED=0 GOOS=$goos GOARCH=$goarch go install -mod mod -trimpath github.com/mjl-/mox@$moxversion\nRUN test -f /go/bin/mox && cp /go/bin/mox /bin/mox || cp /go/bin/${goos}_${goarch}/mox /bin/mox\n\n# Using latest may break at some point, but will hopefully be convenient most of the time.\nFROM --platform=$TARGETPLATFORM docker.io/alpine:latest\nWORKDIR /mox\nCOPY --from=build /bin/mox /bin/mox\n\n# SMTP for incoming message delivery.\nEXPOSE 25/tcp\n# SMTP/submission with TLS.\nEXPOSE 465/tcp\n# SMTP/submission without initial TLS.\nEXPOSE 587/tcp\n# HTTP for internal account and admin pages.\nEXPOSE 80/tcp\n# HTTPS for ACME (Let's Encrypt), MTA-STS and autoconfig.\nEXPOSE 443/tcp\n# IMAP with TLS.\nEXPOSE 993/tcp\n# IMAP without initial TLS.\nEXPOSE 143/tcp\n# Prometheus metrics.\nEXPOSE 8010/tcp\n\nCMD [\"/bin/mox\", \"serve\"]\n"
        },
        {
          "name": "LICENSE.MIT",
          "type": "blob",
          "size": 1.0498046875,
          "content": "Copyright 2021 Mechiel Lukkien <mechiel@ueber.net>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
        },
        {
          "name": "LICENSE.MPLv2.0",
          "type": "blob",
          "size": 16.3349609375,
          "content": "Mozilla Public License Version 2.0\n==================================\n\n1. Definitions\n--------------\n\n1.1. \"Contributor\"\n    means each individual or legal entity that creates, contributes to\n    the creation of, or owns Covered Software.\n\n1.2. \"Contributor Version\"\n    means the combination of the Contributions of others (if any) used\n    by a Contributor and that particular Contributor's Contribution.\n\n1.3. \"Contribution\"\n    means Covered Software of a particular Contributor.\n\n1.4. \"Covered Software\"\n    means Source Code Form to which the initial Contributor has attached\n    the notice in Exhibit A, the Executable Form of such Source Code\n    Form, and Modifications of such Source Code Form, in each case\n    including portions thereof.\n\n1.5. \"Incompatible With Secondary Licenses\"\n    means\n\n    (a) that the initial Contributor has attached the notice described\n        in Exhibit B to the Covered Software; or\n\n    (b) that the Covered Software was made available under the terms of\n        version 1.1 or earlier of the License, but not also under the\n        terms of a Secondary License.\n\n1.6. \"Executable Form\"\n    means any form of the work other than Source Code Form.\n\n1.7. \"Larger Work\"\n    means a work that combines Covered Software with other material, in \n    a separate file or files, that is not Covered Software.\n\n1.8. \"License\"\n    means this document.\n\n1.9. \"Licensable\"\n    means having the right to grant, to the maximum extent possible,\n    whether at the time of the initial grant or subsequently, any and\n    all of the rights conveyed by this License.\n\n1.10. \"Modifications\"\n    means any of the following:\n\n    (a) any file in Source Code Form that results from an addition to,\n        deletion from, or modification of the contents of Covered\n        Software; or\n\n    (b) any new file in Source Code Form that contains any Covered\n        Software.\n\n1.11. \"Patent Claims\" of a Contributor\n    means any patent claim(s), including without limitation, method,\n    process, and apparatus claims, in any patent Licensable by such\n    Contributor that would be infringed, but for the grant of the\n    License, by the making, using, selling, offering for sale, having\n    made, import, or transfer of either its Contributions or its\n    Contributor Version.\n\n1.12. \"Secondary License\"\n    means either the GNU General Public License, Version 2.0, the GNU\n    Lesser General Public License, Version 2.1, the GNU Affero General\n    Public License, Version 3.0, or any later versions of those\n    licenses.\n\n1.13. \"Source Code Form\"\n    means the form of the work preferred for making modifications.\n\n1.14. \"You\" (or \"Your\")\n    means an individual or a legal entity exercising rights under this\n    License. For legal entities, \"You\" includes any entity that\n    controls, is controlled by, or is under common control with You. For\n    purposes of this definition, \"control\" means (a) the power, direct\n    or indirect, to cause the direction or management of such entity,\n    whether by contract or otherwise, or (b) ownership of more than\n    fifty percent (50%) of the outstanding shares or beneficial\n    ownership of such entity.\n\n2. License Grants and Conditions\n--------------------------------\n\n2.1. Grants\n\nEach Contributor hereby grants You a world-wide, royalty-free,\nnon-exclusive license:\n\n(a) under intellectual property rights (other than patent or trademark)\n    Licensable by such Contributor to use, reproduce, make available,\n    modify, display, perform, distribute, and otherwise exploit its\n    Contributions, either on an unmodified basis, with Modifications, or\n    as part of a Larger Work; and\n\n(b) under Patent Claims of such Contributor to make, use, sell, offer\n    for sale, have made, import, and otherwise transfer either its\n    Contributions or its Contributor Version.\n\n2.2. Effective Date\n\nThe licenses granted in Section 2.1 with respect to any Contribution\nbecome effective for each Contribution on the date the Contributor first\ndistributes such Contribution.\n\n2.3. Limitations on Grant Scope\n\nThe licenses granted in this Section 2 are the only rights granted under\nthis License. No additional rights or licenses will be implied from the\ndistribution or licensing of Covered Software under this License.\nNotwithstanding Section 2.1(b) above, no patent license is granted by a\nContributor:\n\n(a) for any code that a Contributor has removed from Covered Software;\n    or\n\n(b) for infringements caused by: (i) Your and any other third party's\n    modifications of Covered Software, or (ii) the combination of its\n    Contributions with other software (except as part of its Contributor\n    Version); or\n\n(c) under Patent Claims infringed by Covered Software in the absence of\n    its Contributions.\n\nThis License does not grant any rights in the trademarks, service marks,\nor logos of any Contributor (except as may be necessary to comply with\nthe notice requirements in Section 3.4).\n\n2.4. Subsequent Licenses\n\nNo Contributor makes additional grants as a result of Your choice to\ndistribute the Covered Software under a subsequent version of this\nLicense (see Section 10.2) or under the terms of a Secondary License (if\npermitted under the terms of Section 3.3).\n\n2.5. Representation\n\nEach Contributor represents that the Contributor believes its\nContributions are its original creation(s) or it has sufficient rights\nto grant the rights to its Contributions conveyed by this License.\n\n2.6. Fair Use\n\nThis License is not intended to limit any rights You have under\napplicable copyright doctrines of fair use, fair dealing, or other\nequivalents.\n\n2.7. Conditions\n\nSections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted\nin Section 2.1.\n\n3. Responsibilities\n-------------------\n\n3.1. Distribution of Source Form\n\nAll distribution of Covered Software in Source Code Form, including any\nModifications that You create or to which You contribute, must be under\nthe terms of this License. You must inform recipients that the Source\nCode Form of the Covered Software is governed by the terms of this\nLicense, and how they can obtain a copy of this License. You may not\nattempt to alter or restrict the recipients' rights in the Source Code\nForm.\n\n3.2. Distribution of Executable Form\n\nIf You distribute Covered Software in Executable Form then:\n\n(a) such Covered Software must also be made available in Source Code\n    Form, as described in Section 3.1, and You must inform recipients of\n    the Executable Form how they can obtain a copy of such Source Code\n    Form by reasonable means in a timely manner, at a charge no more\n    than the cost of distribution to the recipient; and\n\n(b) You may distribute such Executable Form under the terms of this\n    License, or sublicense it under different terms, provided that the\n    license for the Executable Form does not attempt to limit or alter\n    the recipients' rights in the Source Code Form under this License.\n\n3.3. Distribution of a Larger Work\n\nYou may create and distribute a Larger Work under terms of Your choice,\nprovided that You also comply with the requirements of this License for\nthe Covered Software. If the Larger Work is a combination of Covered\nSoftware with a work governed by one or more Secondary Licenses, and the\nCovered Software is not Incompatible With Secondary Licenses, this\nLicense permits You to additionally distribute such Covered Software\nunder the terms of such Secondary License(s), so that the recipient of\nthe Larger Work may, at their option, further distribute the Covered\nSoftware under the terms of either this License or such Secondary\nLicense(s).\n\n3.4. Notices\n\nYou may not remove or alter the substance of any license notices\n(including copyright notices, patent notices, disclaimers of warranty,\nor limitations of liability) contained within the Source Code Form of\nthe Covered Software, except that You may alter any license notices to\nthe extent required to remedy known factual inaccuracies.\n\n3.5. Application of Additional Terms\n\nYou may choose to offer, and to charge a fee for, warranty, support,\nindemnity or liability obligations to one or more recipients of Covered\nSoftware. However, You may do so only on Your own behalf, and not on\nbehalf of any Contributor. You must make it absolutely clear that any\nsuch warranty, support, indemnity, or liability obligation is offered by\nYou alone, and You hereby agree to indemnify every Contributor for any\nliability incurred by such Contributor as a result of warranty, support,\nindemnity or liability terms You offer. You may include additional\ndisclaimers of warranty and limitations of liability specific to any\njurisdiction.\n\n4. Inability to Comply Due to Statute or Regulation\n---------------------------------------------------\n\nIf it is impossible for You to comply with any of the terms of this\nLicense with respect to some or all of the Covered Software due to\nstatute, judicial order, or regulation then You must: (a) comply with\nthe terms of this License to the maximum extent possible; and (b)\ndescribe the limitations and the code they affect. Such description must\nbe placed in a text file included with all distributions of the Covered\nSoftware under this License. Except to the extent prohibited by statute\nor regulation, such description must be sufficiently detailed for a\nrecipient of ordinary skill to be able to understand it.\n\n5. Termination\n--------------\n\n5.1. The rights granted under this License will terminate automatically\nif You fail to comply with any of its terms. However, if You become\ncompliant, then the rights granted under this License from a particular\nContributor are reinstated (a) provisionally, unless and until such\nContributor explicitly and finally terminates Your grants, and (b) on an\nongoing basis, if such Contributor fails to notify You of the\nnon-compliance by some reasonable means prior to 60 days after You have\ncome back into compliance. Moreover, Your grants from a particular\nContributor are reinstated on an ongoing basis if such Contributor\nnotifies You of the non-compliance by some reasonable means, this is the\nfirst time You have received notice of non-compliance with this License\nfrom such Contributor, and You become compliant prior to 30 days after\nYour receipt of the notice.\n\n5.2. If You initiate litigation against any entity by asserting a patent\ninfringement claim (excluding declaratory judgment actions,\ncounter-claims, and cross-claims) alleging that a Contributor Version\ndirectly or indirectly infringes any patent, then the rights granted to\nYou by any and all Contributors for the Covered Software under Section\n2.1 of this License shall terminate.\n\n5.3. In the event of termination under Sections 5.1 or 5.2 above, all\nend user license agreements (excluding distributors and resellers) which\nhave been validly granted by You or Your distributors under this License\nprior to termination shall survive termination.\n\n************************************************************************\n*                                                                      *\n*  6. Disclaimer of Warranty                                           *\n*  -------------------------                                           *\n*                                                                      *\n*  Covered Software is provided under this License on an \"as is\"       *\n*  basis, without warranty of any kind, either expressed, implied, or  *\n*  statutory, including, without limitation, warranties that the       *\n*  Covered Software is free of defects, merchantable, fit for a        *\n*  particular purpose or non-infringing. The entire risk as to the     *\n*  quality and performance of the Covered Software is with You.        *\n*  Should any Covered Software prove defective in any respect, You     *\n*  (not any Contributor) assume the cost of any necessary servicing,   *\n*  repair, or correction. This disclaimer of warranty constitutes an   *\n*  essential part of this License. No use of any Covered Software is   *\n*  authorized under this License except under this disclaimer.         *\n*                                                                      *\n************************************************************************\n\n************************************************************************\n*                                                                      *\n*  7. Limitation of Liability                                          *\n*  --------------------------                                          *\n*                                                                      *\n*  Under no circumstances and under no legal theory, whether tort      *\n*  (including negligence), contract, or otherwise, shall any           *\n*  Contributor, or anyone who distributes Covered Software as          *\n*  permitted above, be liable to You for any direct, indirect,         *\n*  special, incidental, or consequential damages of any character      *\n*  including, without limitation, damages for lost profits, loss of    *\n*  goodwill, work stoppage, computer failure or malfunction, or any    *\n*  and all other commercial damages or losses, even if such party      *\n*  shall have been informed of the possibility of such damages. This   *\n*  limitation of liability shall not apply to liability for death or   *\n*  personal injury resulting from such party's negligence to the       *\n*  extent applicable law prohibits such limitation. Some               *\n*  jurisdictions do not allow the exclusion or limitation of           *\n*  incidental or consequential damages, so this exclusion and          *\n*  limitation may not apply to You.                                    *\n*                                                                      *\n************************************************************************\n\n8. Litigation\n-------------\n\nAny litigation relating to this License may be brought only in the\ncourts of a jurisdiction where the defendant maintains its principal\nplace of business and such litigation shall be governed by laws of that\njurisdiction, without reference to its conflict-of-law provisions.\nNothing in this Section shall prevent a party's ability to bring\ncross-claims or counter-claims.\n\n9. Miscellaneous\n----------------\n\nThis License represents the complete agreement concerning the subject\nmatter hereof. If any provision of this License is held to be\nunenforceable, such provision shall be reformed only to the extent\nnecessary to make it enforceable. Any law or regulation which provides\nthat the language of a contract shall be construed against the drafter\nshall not be used to construe this License against a Contributor.\n\n10. Versions of the License\n---------------------------\n\n10.1. New Versions\n\nMozilla Foundation is the license steward. Except as provided in Section\n10.3, no one other than the license steward has the right to modify or\npublish new versions of this License. Each version will be given a\ndistinguishing version number.\n\n10.2. Effect of New Versions\n\nYou may distribute the Covered Software under the terms of the version\nof the License under which You originally received the Covered Software,\nor under the terms of any subsequent version published by the license\nsteward.\n\n10.3. Modified Versions\n\nIf you create software not governed by this License, and you want to\ncreate a new license for such software, you may create and use a\nmodified version of this License if you rename the license and remove\nany references to the name of the license steward (except to note that\nsuch modified license differs from this License).\n\n10.4. Distributing Source Code Form that is Incompatible With Secondary\nLicenses\n\nIf You choose to distribute Source Code Form that is Incompatible With\nSecondary Licenses under the terms of this version of the License, the\nnotice described in Exhibit B of this License must be attached.\n\nExhibit A - Source Code Form License Notice\n-------------------------------------------\n\n  This Source Code Form is subject to the terms of the Mozilla Public\n  License, v. 2.0. If a copy of the MPL was not distributed with this\n  file, You can obtain one at https://mozilla.org/MPL/2.0/.\n\nIf it is not possible or desirable to put the notice in a particular\nfile, then You may include the notice in a location (such as a LICENSE\nfile in a relevant directory) where a recipient would be likely to look\nfor such a notice.\n\nYou may add additional accurate notices of copyright ownership.\n\nExhibit B - \"Incompatible With Secondary Licenses\" Notice\n---------------------------------------------------------\n\n  This Source Code Form is \"Incompatible With Secondary Licenses\", as\n  defined by the Mozilla Public License, v. 2.0.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 7.0771484375,
          "content": "default: build\n\nbuild: build0 frontend build1\n\nbuild0:\n\t# build early to catch syntax errors\n\tCGO_ENABLED=0 go build\n\tCGO_ENABLED=0 go vet ./...\n\t./gendoc.sh\n\t# we rewrite some dmarcprt and tlsrpt enums into untyped strings: real-world\n\t# reports have invalid values, and our loose Go typed strings accept all values,\n\t# but we don't want the typescript runtime checker to fail on those unrecognized\n\t# values.\n\t(cd webadmin && CGO_ENABLED=0 go run ../vendor/github.com/mjl-/sherpadoc/cmd/sherpadoc/*.go -adjust-function-names none -rename 'config Domain ConfigDomain,dmarc Policy DMARCPolicy,mtasts MX STSMX,tlsrptdb Record TLSReportRecord,tlsrptdb SuppressAddress TLSRPTSuppressAddress,dmarcrpt DKIMResult string,dmarcrpt SPFResult string,dmarcrpt SPFDomainScope string,dmarcrpt DMARCResult string,dmarcrpt PolicyOverride string,dmarcrpt Alignment string,dmarcrpt Disposition string,tlsrpt PolicyType string,tlsrpt ResultType string' Admin) >webadmin/api.json\n\t(cd webaccount && CGO_ENABLED=0 go run ../vendor/github.com/mjl-/sherpadoc/cmd/sherpadoc/*.go -adjust-function-names none Account) >webaccount/api.json\n\t(cd webmail && CGO_ENABLED=0 go run ../vendor/github.com/mjl-/sherpadoc/cmd/sherpadoc/*.go -adjust-function-names none Webmail) >webmail/api.json\n\t./gents.sh webadmin/api.json webadmin/api.ts\n\t./gents.sh webaccount/api.json webaccount/api.ts\n\t./gents.sh webmail/api.json webmail/api.ts\n\nbuild1:\n\t# build again, api json files above are embedded and new frontend code generated\n\tCGO_ENABLED=0 go build\n\ninstall: build0 frontend\n\tCGO_ENABLED=0 go install\n\nrace: build0\n\tgo build -race\n\ntest:\n\tCGO_ENABLED=0 go test -shuffle=on -coverprofile cover.out ./...\n\tgo tool cover -html=cover.out -o cover.html\n\ntest-race:\n\tCGO_ENABLED=1 go test -race -shuffle=on -covermode atomic -coverprofile cover.out ./...\n\tgo tool cover -html=cover.out -o cover.html\n\n# note: if testdata/upgradetest.mbox.gz exists, its messages will be imported\n# during tests. helpful for performance/resource consumption tests.\ntest-upgrade: build\n\tnice ./test-upgrade.sh\n\n# needed for \"check\" target\ninstall-staticcheck:\n\tCGO_ENABLED=0 go install honnef.co/go/tools/cmd/staticcheck@latest\n\ncheck:\n\tCGO_ENABLED=0 go vet -tags integration\n\tCGO_ENABLED=0 go vet -tags website website/website.go\n\tCGO_ENABLED=0 go vet -tags link rfc/link.go\n\tCGO_ENABLED=0 go vet -tags errata rfc/errata.go\n\tCGO_ENABLED=0 go vet -tags xr rfc/xr.go\n\tGOARCH=386 CGO_ENABLED=0 go vet ./...\n\tCGO_ENABLED=0 staticcheck ./...\n\tCGO_ENABLED=0 staticcheck -tags integration\n\tCGO_ENABLED=0 staticcheck -tags website website/website.go\n\tCGO_ENABLED=0 staticcheck -tags link rfc/link.go\n\tCGO_ENABLED=0 staticcheck -tags errata rfc/errata.go\n\tCGO_ENABLED=0 staticcheck -tags xr rfc/xr.go\n\n# needed for check-shadow\ninstall-shadow:\n\tCGO_ENABLED=0 go install golang.org/x/tools/go/analysis/passes/shadow/cmd/shadow@latest\n\n# having \"err\" shadowed is common, best to not have others\ncheck-shadow:\n\tCGO_ENABLED=0 go vet -vettool=$$(which shadow) ./... 2>&1 | grep -v '\"err\"'\n\tCGO_ENABLED=0 go vet -tags integration -vettool=$$(which shadow) 2>&1 | grep -v '\"err\"'\n\tCGO_ENABLED=0 go vet -tags website -vettool=$$(which shadow) website/website.go 2>&1 | grep -v '\"err\"'\n\tCGO_ENABLED=0 go vet -tags link -vettool=$$(which shadow) rfc/link.go 2>&1 | grep -v '\"err\"'\n\tCGO_ENABLED=0 go vet -tags errata -vettool=$$(which shadow) rfc/errata.go 2>&1 | grep -v '\"err\"'\n\tCGO_ENABLED=0 go vet -tags xr -vettool=$$(which shadow) rfc/xr.go 2>&1 | grep -v '\"err\"'\n\nfuzz:\n\tgo test -fuzz FuzzParseSignature -fuzztime 5m ./dkim\n\tgo test -fuzz FuzzParseRecord -fuzztime 5m ./dkim\n\tgo test -fuzz . -fuzztime 5m ./dmarc\n\tgo test -fuzz . -fuzztime 5m ./dmarcrpt\n\tgo test -fuzz . -parallel 1 -fuzztime 5m ./imapserver\n\tgo test -fuzz . -parallel 1 -fuzztime 5m ./junk\n\tgo test -fuzz FuzzParseRecord -fuzztime 5m ./mtasts\n\tgo test -fuzz FuzzParsePolicy -fuzztime 5m ./mtasts\n\tgo test -fuzz . -parallel 1 -fuzztime 5m ./smtpserver\n\tgo test -fuzz . -fuzztime 5m ./spf\n\tgo test -fuzz FuzzParseRecord -fuzztime 5m ./tlsrpt\n\tgo test -fuzz FuzzParseMessage -fuzztime 5m ./tlsrpt\n\ngovendor:\n\tgo mod tidy\n\tgo mod vendor\n\t./genlicenses.sh\n\ntest-integration:\n\t-docker-compose -f docker-compose-integration.yml kill\n\t-docker-compose -f docker-compose-integration.yml down\n\tdocker image build --pull --no-cache -f Dockerfile -t mox_integration_moxmail .\n\tdocker image build --pull --no-cache -f testdata/integration/Dockerfile.test -t mox_integration_test testdata/integration\n\t-rm -rf testdata/integration/moxacmepebble/data\n\t-rm -rf testdata/integration/moxmail2/data\n\t-rm -f testdata/integration/tmp-pebble-ca.pem\n\tMOX_UID=$$(id -u) docker-compose -f docker-compose-integration.yml run test\n\tdocker-compose -f docker-compose-integration.yml kill\n\n\nimaptest-build:\n\t-docker-compose -f docker-compose-imaptest.yml build --no-cache --pull mox\n\nimaptest-run:\n\t-rm -r testdata/imaptest/data\n\tmkdir testdata/imaptest/data\n\tdocker-compose -f docker-compose-imaptest.yml run --entrypoint /usr/local/bin/imaptest imaptest host=mox port=1143 user=mjl@mox.example pass=testtest mbox=imaptest.mbox\n\tdocker-compose -f docker-compose-imaptest.yml down\n\n\nfmt:\n\tgo fmt ./...\n\tgofmt -w -s *.go */*.go\n\ntswatch:\n\tbash -c 'while true; do inotifywait -q -e close_write *.ts webadmin/*.ts webaccount/*.ts webmail/*.ts; make frontend; done'\n\nnode_modules/.bin/tsc:\n\t-mkdir -p node_modules/.bin\n\tnpm ci --ignore-scripts\n\ninstall-js: node_modules/.bin/tsc\n\ninstall-js0:\n\t-mkdir -p node_modules/.bin\n\tnpm install --ignore-scripts --save-dev --save-exact typescript@5.1.6\n\nwebmail/webmail.js: lib.ts webmail/api.ts webmail/lib.ts webmail/webmail.ts\n\t./tsc.sh $@ lib.ts webmail/api.ts webmail/lib.ts webmail/webmail.ts\n\nwebmail/msg.js: lib.ts webmail/api.ts webmail/lib.ts webmail/msg.ts\n\t./tsc.sh $@ lib.ts webmail/api.ts webmail/lib.ts webmail/msg.ts\n\nwebmail/text.js: lib.ts webmail/api.ts webmail/lib.ts webmail/text.ts\n\t./tsc.sh $@ lib.ts webmail/api.ts webmail/lib.ts webmail/text.ts\n\nwebadmin/admin.js: lib.ts webadmin/api.ts webadmin/admin.ts\n\t./tsc.sh $@ lib.ts webadmin/api.ts webadmin/admin.ts\n\nwebaccount/account.js: lib.ts webaccount/api.ts webaccount/account.ts\n\t./tsc.sh $@ lib.ts webaccount/api.ts webaccount/account.ts\n\nfrontend: node_modules/.bin/tsc webadmin/admin.js webaccount/account.js webmail/webmail.js webmail/msg.js webmail/text.js\n\ninstall-apidiff:\n\tCGO_ENABLED=0 go install golang.org/x/exp/cmd/apidiff@v0.0.0-20231206192017-f3f8817b8deb\n\ngenapidiff:\n\t./apidiff.sh\n\ndocker:\n\tdocker build -t mox:dev .\n\ndocker-release:\n\t./docker-release.sh\n\ngenwebsite:\n\t./genwebsite.sh\n\nbuildall:\n\tCGO_ENABLED=0 GOOS=linux GOARCH=arm go build\n\tCGO_ENABLED=0 GOOS=linux GOARCH=arm64 go build\n\tCGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build\n\tCGO_ENABLED=0 GOOS=linux GOARCH=386 go build\n\tCGO_ENABLED=0 GOOS=openbsd GOARCH=amd64 go build\n\tCGO_ENABLED=0 GOOS=freebsd GOARCH=amd64 go build\n\tCGO_ENABLED=0 GOOS=netbsd GOARCH=amd64 go build\n\tCGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build\n\tCGO_ENABLED=0 GOOS=dragonfly GOARCH=amd64 go build\n\tCGO_ENABLED=0 GOOS=illumos GOARCH=amd64 go build\n\tCGO_ENABLED=0 GOOS=solaris GOARCH=amd64 go build\n\tCGO_ENABLED=0 GOOS=aix GOARCH=ppc64 go build\n\tCGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build\n\t# no plan9 for now\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 25.0615234375,
          "content": "Mox is a modern full-featured open source secure mail server for low-maintenance self-hosted email.\n\nFor more details, see the mox website, https://www.xmox.nl.\n\nSee Quickstart below to get started.\n\n## Features\n\n- Quick and easy to start/maintain mail server, for your own domain(s).\n- SMTP (with extensions) for receiving, submitting and delivering email.\n- IMAP4 (with extensions) for giving email clients access to email.\n- Webmail for reading/sending email from the browser.\n- SPF/DKIM/DMARC for authenticating messages/delivery, also DMARC aggregate\n  reports.\n- Reputation tracking, learning (per user) host-, domain- and\n  sender address-based reputation from (Non-)Junk email classification.\n- Bayesian spam filtering that learns (per user) from (Non-)Junk email.\n- Slowing down senders with no/low reputation or questionable email content\n  (similar to greylisting). Rejected emails are stored in a mailbox called Rejects\n  for a short period, helping with misclassified legitimate synchronous\n  signup/login/transactional emails.\n- Internationalized email, with unicode in email address usernames\n  (\"localparts\"), and in domain names (IDNA).\n- Automatic TLS with ACME, for use with Let's Encrypt and other CA's.\n- DANE and MTA-STS for inbound and outbound delivery over SMTP with STARTTLS,\n  including REQUIRETLS and with incoming/outgoing TLSRPT reporting.\n- Web admin interface that helps you set up your domains, accounts and list\n  aliases (instructions to create DNS records, configure\n  SPF/DKIM/DMARC/TLSRPT/MTA-STS), for status information, and modifying the\n  configuration file.\n- Account autodiscovery (with SRV records, Microsoft-style, Thunderbird-style,\n  and Apple device management profiles) for easy account setup (though client\n  support is limited).\n- Webserver with serving static files and forwarding requests (reverse\n  proxy), so port 443 can also be used to serve websites.\n- Simple HTTP/JSON API for sending transaction email and receiving delivery\n  events and incoming messages (webapi and webhooks).\n- Prometheus metrics and structured logging for operational insight.\n- \"mox localserve\" subcommand for running mox locally for email-related\n  testing/developing, including pedantic mode.\n- Most non-server Go packages mox consists of are written to be reusable.\n\nMox is available under the MIT-license and was created by Mechiel Lukkien,\nmechiel@ueber.net. Mox includes BSD-3-claused code from the Go Authors, and the\nPublic Suffix List by Mozilla under Mozilla Public License, v2.0.\n\nMox has automated tests, including for interoperability with Postfix for SMTP.\nMox is manually tested with email clients: Mozilla Thunderbird, mutt, iOS Mail,\nmacOS Mail, Android Mail, Microsoft Outlook. Mox is also manually tested to\ninteroperate with popular cloud providers: gmail.com, outlook.com, yahoo.com,\nproton.me.\n\nThe code is heavily cross-referenced with the RFCs for readability/maintainability.\n\n# Quickstart\n\nThe easiest way to get started with serving email for your domain is to get a\n(virtual) machine dedicated to serving email, name it `[host].[domain]` (e.g.\nmail.example.com). Having a DNSSEC-verifying resolver installed, such as\nunbound, is highly recommended. Run as root:\n\n\t# Create mox user and homedir (or pick another name or homedir):\n\tuseradd -m -d /home/mox mox\n\n\tcd /home/mox\n\t... compile or download mox to this directory, see below ...\n\n\t# Generate config files for your address/domain:\n\t./mox quickstart you@example.com\n\nThe quickstart:\n\n- Creates configuration files mox.conf and domains.conf.\n- Adds the domain and an account for the email address to domains.conf\n- Generates an admin and account password.\n- Prints the DNS records you need to add, for the machine and domain.\n- Prints commands to start mox, and optionally install mox as a service.\n\nA machine that doesn't already run a webserver is highly recommended because\nmodern email requires HTTPS, and mox currently needs to run a webserver for\nautomatic TLS with ACME.  You could combine mox with an existing webserver, but\nit requires a lot more configuration. If you want to serve websites on the same\nmachine, consider using the webserver built into mox. It's pretty good! If you\nwant to run an existing webserver on port 443/80, see `mox help quickstart`.\n\nAfter starting, you can access the admin web interface on internal IPs.\n\n# Download\n\nDownload a mox binary from\nhttps://beta.gobuilds.org/github.com/mjl-/mox@latest/linux-amd64-latest/.\n\nSymlink or rename it to \"mox\".\n\nThe URL above always resolves to the latest release for linux/amd64 built with\nthe latest Go toolchain.  See the links at the bottom of that page for binaries\nfor other platforms.\n\n# Compiling\n\nYou can easily (cross) compile mox yourself. You need a recent Go toolchain\ninstalled.  Run `go version`, it must be >= 1.22. Download the latest version\nfrom https://go.dev/dl/ or see https://go.dev/doc/manage-install.\n\nTo download the source code of the latest release, and compile it to binary \"mox\":\n\n\tGOBIN=$PWD CGO_ENABLED=0 go install github.com/mjl-/mox@latest\n\nMox only compiles for and fully works on unix systems. Mox also compiles for\nWindows, but \"mox serve\" does not yet work, though \"mox localserve\" (for a\nlocal test instance) and most other subcommands do. Mox does not compile for\nPlan 9.\n\n# Docker\n\nAlthough not recommended, you can also run mox with docker image\n`r.xmox.nl/mox`, with tags like `v0.0.1` and `v0.0.1-go1.20.1-alpine3.17.2`, see\nhttps://r.xmox.nl/r/mox/.  See\nhttps://github.com/mjl-/mox/blob/main/docker-compose.yml to get started.\n\nNew docker images aren't (automatically) generated for new Go runtime/compile\nreleases.\n\nIt is important to run with docker host networking, so mox can use the public\nIPs and has correct remote IP information for incoming connections (important\nfor junk filtering and rate-limiting).\n\n# Future/development\n\nSee develop.txt for instructions/tips for developing on mox.\n\nMox will receive funding for essentially full-time continued work from August\n2023 to August 2024 through NLnet/EU's NGI0 Entrust, see\nhttps://nlnet.nl/project/Mox/.\n\n## Roadmap\n\n- Calendaring with CalDAV/iCal\n- More IMAP extensions (PREVIEW, WITHIN, IMPORTANT, COMPRESS=DEFLATE,\n  CREATE-SPECIAL-USE, SAVEDATE, UNAUTHENTICATE, REPLACE, QUOTA, NOTIFY,\n  MULTIAPPEND, OBJECTID, MULTISEARCH, THREAD, SORT)\n- SMTP DSN extension\n- \"mox setup\" command, with webapp for interactive setup\n- Introbox, to which first-time senders are delivered\n- ARC, with forwarded email from trusted source\n- Forwarding (to an external address)\n- Add special IMAP mailbox (\"Queue?\") that contains queued but\n  undelivered messages, updated with IMAP flags/keywords/tags and message headers.\n- External addresses in aliases/lists.\n- Autoresponder (out of office/vacation)\n- OAUTH2 support, for single sign on\n- IMAP extensions for \"online\"/non-syncing/webmail clients (SORT (including\n  DISPLAYFROM, DISPLAYTO), THREAD, PARTIAL, CONTEXT=SEARCH CONTEXT=SORT ESORT,\n  FILTERS)\n- Improve support for mobile clients with extensions: IMAP URLAUTH, SMTP\n  CHUNKING and BINARYMIME, IMAP CATENATE\n- Mailing list manager\n- Privilege separation, isolating parts of the application to more restricted\n  sandbox (e.g. new unauthenticated connections)\n- Using mox as backup MX\n- JMAP\n- Sieve for filtering (for now see Rulesets in the account config)\n- Milter support, for integration with external tools\n- IMAP Sieve extension, to run Sieve scripts after message changes (not only\n  new deliveries)\n\nThere are many smaller improvements to make as well, search for \"todo\" in the code.\n\n## Not supported/planned\n\nThere is currently no plan to implement the following. Though this may\nchange in the future.\n\n- Functioning as SMTP relay\n- POP3\n- Delivery to (unix) OS system users\n- Support for pluggable delivery mechanisms\n- iOS Mail push notifications (with XAPPLEPUSHSERVICE undocumented imap\n  extension and hard to get APNS certificate)\n\n\n# FAQ - Frequently Asked Questions\n\n## Why a new mail server implementation?\n\nMox aims to make \"running a mail server\" easy and nearly effortless. Excellent\nquality (open source) mail server software exists, but getting a working setup\ntypically requires you configure half a dozen services (SMTP, IMAP,\nSPF/DKIM/DMARC, spam filtering), which are often written in C (where small bugs\noften have large consequences). That seems to lead to people no longer running\ntheir own mail servers, instead switching to one of the few centralized email\nproviders. Email with SMTP is a long-time decentralized messaging protocol. To\nkeep it decentralized, people need to run their own mail server. Mox aims to\nmake that easy.\n\n## Where is the documentation?\n\nTo keep mox as a project maintainable, documentation is integrated into, and\ngenerated from the code.\n\nA list of mox commands, and their help output, are at\nhttps://www.xmox.nl/commands/.\n\nMox is configured through configuration files, and each field comes with\ndocumentation. See https://www.xmox.nl/config/ for config files containing all\nfields and their documentation.\n\nYou can get the same information by running \"mox\" without arguments to list its\nsubcommands and usage, and \"mox help [subcommand]\" for more details.\n\nThe example config files are printed by \"mox config describe-static\" and \"mox\nconfig describe-dynamic\".\n\nIf you're missing some documentation, please create an issue describing what is\nunclear or confusing, and we'll try to improve the documentation.\n\n## Is Mox affected by SMTP smuggling?\n\nMox itself is not affected: it only treats \"\\r\\n.\\r\\n\" as SMTP end-of-message.\nBut read on for caveats.\n\nSMTP smuggling exploits differences in handling by SMTP servers of: carriage\nreturns (CR, or \"\\r\"), newlines (line feeds, LF, \"\\n\") in the context of \"dot\nstuffing\".  SMTP is a text-based protocol. An SMTP transaction to send a\nmessage is finalized with a \"\\r\\n.\\r\\n\" sequence. This sequence could occur in\nthe message being transferred, so any verbatim \".\" at the start of a line in a\nmessage is \"escaped\" with another dot (\"dot stuffing\"), to not trigger the SMTP\nend-of-message. SMTP smuggling takes advantage of bugs in some mail servers\nthat interpret other sequences than \"\\r\\n.\\r\\n\" as SMTP end-of-message. For\nexample \"\\n.\\n\" or even \"\\r.\\r\", and perhaps even other magic character\ncombinations.\n\nBefore v0.0.9, mox accepted SMTP transactions with bare carriage returns\n(without newline) for compatibility with real-world email messages, considering\nthem meaningless and therefore innocuous.\n\nSince v0.0.9, SMTP transactions with bare carriage returns are rejected.\nSending messages with bare carriage returns to buggy mail servers can cause\nthose mail servers to materialize non-existent messages. Now that mox rejects\nmessages with bare carriage returns, sending a message through mox can no\nlonger be used to trigger those bugs.\n\nMox can still handle bare carriage returns in email messages, e.g. those\nimported from mbox files or Maildirs, or from messages added over IMAP. Mox\nstill fixes up messages with bare newlines by adding the missing carriage\nreturns.\n\nBefore v0.0.9, an SMTP transaction for a message containing \"\\n.\\n\" would\nresult in a non-specific error message, and \"\\r\\n.\\n\" would result in the dot\nbeing dropped. Since v0.0.9, these sequences are rejected with a message\nmentioning SMTP smuggling.\n\n## How do I import/export email?\n\nUse the import functionality on the accounts web page to import a zip/tgz with\nmaildirs/mbox files, or use the \"mox import maildir\" or \"mox import mbox\"\nsubcommands. You could also use your IMAP email client, add your mox account,\nand copy or move messages from one account to the other.\n\nSimilarly, see the export functionality on the accounts web page and the \"mox\nexport maildir\" and \"mox export mbox\" subcommands to export email.\n\nImporting large mailboxes may require a lot of memory (a limitation of the\ncurrent database). Splitting up mailboxes in smaller parts (e.g. 100k messages)\nwould help.\n\n## How can I help?\n\nMox needs users and testing in real-life setups! So just give it a try, send\nand receive emails through it with your favourite email clients, and file an\nissue if you encounter a problem or would like to see a feature/functionality\nimplemented.\n\nInstead of switching email for your domain over to mox, you could simply\nconfigure mox for a subdomain, e.g. [you]@moxtest.[yourdomain].\n\nIf you have experience with how the email protocols are used in the wild, e.g.\ncompatibility issues, limitations, anti-spam measures, specification\nviolations, that would be interesting to hear about.\n\nPull requests for bug fixes and new code are welcome too. If the changes are\nlarge, it helps to start a discussion (create an \"issue\") before doing all the\nwork. In practice, starting with a small contribution and growing from there has\nthe highest chance of success.\n\nBy contributing (e.g. code), you agree your contributions are licensed under the\nMIT license (like mox), and have the rights to do so.\n\n## Where can I discuss mox?\n\nJoin #mox on irc.oftc.net, or #mox:matrix.org (https://matrix.to/#/#mox:matrix.org),\nor #mox on the \"Gopher slack\".\n\nFor bug reports, please file an issue at https://github.com/mjl-/mox/issues/new.\n\n## How do I change my password?\n\nRegular users (doing IMAP/SMTP with authentication) can change their password\nat the account page, e.g. `http://localhost/`. Or you can set a password with \"mox\nsetaccountpassword\".\n\nThe admin can change the password of any account through the admin page, at\n`http://localhost/admin/` by default (leave username empty when logging in).\n\nThe account and admin pages are served on localhost for configs created with\nthe quickstart.  To access these from your browser, run\n`ssh -L 8080:localhost:80 you@yourmachine` locally and open\n`http://localhost:8080/[...]`.\n\nThe admin password can be changed with \"mox setadminpassword\".\n\n## How do I configure a second mox instance as a backup MX?\n\nUnfortunately, mox does not yet provide an option for that. Mox does spam\nfiltering based on reputation of received messages. It will take a good amount\nof work to share that information with a backup MX. Without that information,\nspammers could use a backup MX to get their spam accepted.\n\nUntil mox has a proper solution, you can simply run a single SMTP server. The\nauthor has run a single mail server for over a decade without issues. Machines\nand network connectivity are stable nowadays, and email delivery will be\nretried for many hours during temporary errors (e.g. when rebooting a machine\nafter updates).\n\n## How do I stay up to date?\n\nPlease set \"CheckUpdates: true\" in mox.conf. Mox will check for a new version\nthrough a DNS TXT request for `_updates.xmox.nl` once per 24h. Only if a new\nversion is published will the changelog be fetched and delivered to the\npostmaster mailbox.\n\nThe changelog, including latest update instructions, is at\nhttps://updates.xmox.nl/changelog.\n\nYou can also monitor newly added releases on this repository with the github\n\"watch\" feature, or use the github RSS feed for tags\n(https://github.com/mjl-/mox/tags.atom) or releases\n(https://github.com/mjl-/mox/releases.atom), or monitor the docker images.\n\nKeep in mind you have a responsibility to keep the internet-connected software\nyou run up to date and secure.\n\n## How do I upgrade my mox installation?\n\nWe try to make upgrades effortless and you can typically just put a new binary\nin place and restart. If manual actions are required, the release notes mention\nthem. Check the release notes of all version between your current installation\nand the release you're upgrading to.\n\nBefore upgrading, make a backup of the data directory with `mox backup\n<destdir>`. This writes consistent snapshots of the database files, and\nduplicates message files from the outgoing queue and accounts.  Using the new\nmox binary, run `mox verifydata <backupdir>` (do NOT use the \"live\" data\ndirectory!) for a dry run. If this fails, an upgrade will probably fail too.\nImportant: verifydata with the new mox binary can modify the database files (due\nto automatic schema upgrades). So make a fresh backup again before the actual\nupgrade. See the help output of the \"backup\" and \"verifydata\" commands for more\ndetails.\n\nDuring backup, message files are hardlinked if possible, and copied otherwise.\nUsing a destination directory like `data/tmp/backup` increases the odds\nhardlinking succeeds: the default mox systemd service file mounts\nthe data directory separately, so hardlinks to outside the data directory are\ncross-device and will fail.\n\nIf an upgrade fails and you have to restore (parts) of the data directory, you\nshould run `mox verifydata <datadir>` (with the original binary) on the\nrestored directory before starting mox again. If problematic files are found,\nfor example queue or account message files that are not in the database, run\n`mox verifydata -fix <datadir>` to move away those files. After a restore, you may\nalso want to run `mox bumpuidvalidity <account>` for each account for which\nmessages in a mailbox changed, to force IMAP clients to synchronize mailbox\nstate.\n\n## How secure is mox?\n\nSecurity is high on the priority list for mox. Mox is young, so don't expect no\nbugs at all. Mox does have automated tests for some security aspects, e.g. for\nlogin, and uses fuzzing. Mox is written in Go, so some classes of bugs such as\nbuffer mishandling do not typically result in privilege escalation.  Of course\nlogic bugs will still exist. If you find any security issues, please email them\nto mechiel@ueber.net.\n\n## I'm now running an email server, but how does email work?\n\nCongrats and welcome to the club! Running an email server on the internet comes\nwith some responsibilities so you should understand how it works. See\nhttps://explained-from-first-principles.com/email/ for a thorough explanation.\n\n## What are the minimum requirements to run mox?\n\nMox does not need much. Nowadays most machines are larger than mox needs. You\ncan start with a machine with 512MB RAM, any CPU will do. For storage you\nshould account for the size of the email messages (no compression currently),\nan additional 15% overhead for the meta data, and add some more headroom.\nExpand as necessary.\n\n## Won't the big email providers block my email?\n\nIt is a common misconception that it is impossible to run your own email server\nnowadays. The claim is that the handful big email providers will simply block\nyour email. However, you can run your own email server just fine, and your\nemail will be accepted, provided you are doing it right.\n\nIf your email is rejected, it is often because your IP address has a bad email\nsending reputation. Email servers often use IP blocklists to reject email\nnetworks with a bad email sending reputation. These blocklists often work at\nthe level of whole network ranges. So if you try to run an email server from a\nhosting provider with a bad reputation (which happens if they don't monitor\ntheir network or don't act on abuse/spam reports), your IP too will have a bad\nreputation and other mail servers (both large and small) may reject messages\ncoming from you. During the quickstart, mox checks if your IPs are on a few\noften-used blocklists. It's typically not a good idea to host an email server\non the cheapest or largest cloud providers: They often don't spend the\nresources necessary for a good reputation, or they simply block all outgoing\nSMTP traffic. It's better to look for a technically-focused local provider.\nThey too may initially block outgoing SMTP connections on new machines to\nprevent spam from their networks. But they will either automatically open up\noutgoing SMTP traffic after a cool down period (e.g. 24 hours), or after you've\ncontacted their support.\n\nAfter you get past the IP blocklist checks, email servers use many more signals\nto determine if your email message could be spam and should be rejected. Mox\nhelps you set up a system that doesn't trigger most of the technical signals\n(e.g. with SPF/DKIM/DMARC). But there are more signals, for example: Sending to\na mail server or address for the first time. Sending from a newly registered\ndomain (especially if you're sending automated messages, and if you send more\nmessages after previous messages were rejected), domains that existed for a few\nweeks to a month are treated more friendly. Sending messages with content that\nresembles known spam messages.\n\nShould your email be rejected, you will typically get an error message during\nthe SMTP transaction that explains why. In the case of big email providers the\nerror message often has instructions on how to prove to them you are a\nlegitimate sender.\n\n## Can mox deliver through a smarthost?\n\nYes, you can configure a \"Transport\" in mox.conf and configure \"Routes\" in\ndomains.conf to send some or all messages through the transport. A transport\ncan be an SMTP relay or authenticated submission, or making mox make outgoing\nconnections through a SOCKS proxy.\n\nFor an example, see https://www.xmox.nl/config/#hdr-example-transport. For\ndetails about Transports and Routes, see\nhttps://www.xmox.nl/config/#cfg-mox-conf-Transports and\nhttps://www.xmox.nl/config/#cfg-domains-conf-Routes.\n\nRemember to add the IP addresses of the transport to the SPF records of your\ndomains. Keep in mind some 3rd party submission servers may mishandle your\nmessages, for example by replacing your Message-Id header and thereby\ninvalidating your DKIM-signatures, or rejecting messages with more than one\nDKIM-signature.\n\n## Can I use mox to send transactional email?\n\nYes. While you can use SMTP submission to send messages you've composed\nyourself, and monitor a mailbox for DSNs, a more convenient option is to use\nthe mox HTTP/JSON-based webapi and webhooks.\n\nThe mox webapi can be used to send outgoing messages that mox composes. The web\napi can also be used to deal with messages stored in an account, like changing\nmessage flags, retrieving messages in parsed form or individual parts of\nmultipart messages, or moving messages to another mailbox or deleting messages\naltogether.\n\nMox webhooks can be used to receive updates about incoming and outgoing\ndeliveries. Mox can automatically manage per account suppression lists.\n\nSee https://www.xmox.nl/features/#hdr-webapi-and-webhooks for details.\n\n## Can I use existing TLS certificates/keys?\n\nYes. The quickstart command creates a config that uses ACME with Let's Encrypt,\nbut you can change the config file to use existing certificate and key files.\n\nYou'll see \"ACME: letsencrypt\" in the \"TLS\" section of the \"public\" Listener.\nRemove or comment out the ACME-line, and add a \"KeyCerts\" section, see\nhttps://www.xmox.nl/config/#cfg-mox-conf-Listeners-x-TLS-KeyCerts\n\nYou can have multiple certificates and keys: The line with the \"-\" (dash) is\nthe start of a list item. Duplicate that line up to and including the line with\nKeyFile for each certificate/key you have. Mox makes a TLS config that holds\nall specified certificates/keys, and uses it for all services for that Listener\n(including a webserver), choosing the correct certificate for incoming\nrequests.\n\nKeep in mind that for each email domain you host, you will need a certificate\nfor `mta-sts.<domain>`, `autoconfig.<domain>` and `mail.<domain>`, unless you\ndisable MTA-STS, autoconfig and the client-settings-domain for that domain.\n\nMox opens the key and certificate files during initial startup, as root (and\npasses file descriptors to the unprivileged process).  No special permissions\nare needed on the key and certificate files.\n\n## Can I directly access mailboxes through the file system?\n\nNo, mox only provides access to email through protocols like IMAP.\n\nWhile it can be convenient for users/email clients to access email through\nconventions like Maildir, providing such access puts quite a burden on the\nserver: The server has to continuously watch for changes made to the mail store\nby external programs, and sync its internal state. By only providing access to\nemails through mox, the storage/state management is simpler and easier to\nimplement reliably.\n\nNot providing direct file system access also allows future improvements in the\nstorage mechanism. Such as encryption of all stored messages. Programs won't be\nable to access such messages directly.\n\nMox stores metadata about delivered messages in its per-account message index\ndatabase, more than fits in a simple (filename-based) format like Maildir. The\nIP address of the remote SMTP server during delivery, SPF/DKIM/DMARC domains\nand validation status, and more...\n\nFor efficiency, mox doesn't prepend message headers generated during delivery\n(e.g. Authentication-Results) to the on-disk message file, but only stores it\nin the database. This prevents a rewrite of the entire message file. When\nreading a message, mox combines the prepended headers from the database with\nthe message file.\n\nMox user accounts have no relation to operating system user accounts. Multiple\nsystem users reading their email on a single machine is not very common\nanymore. All data (for all accounts) stored by mox is accessible only by the\nmox process.  Messages are currently stored as individual files in standard\nInternet Message Format (IMF), at `data/accounts/<account>/msg/<dir>/<msgid>`:\n`msgid` is a consecutive unique integer id assigned by the per-account message\nindex database; `dir` groups 8k consecutive message ids into a directory,\nensuring they don't become too large.  The message index database file for an\naccount is at `data/accounts/<account>/index.db`, accessed with the bstore\ndatabase library, which uses bbolt (formerly BoltDB) for storage, a\ntransactional key/value library/file format inspired by LMDB.\n"
        },
        {
          "name": "admin",
          "type": "tree",
          "content": null
        },
        {
          "name": "apidiff.sh",
          "type": "blob",
          "size": 1.0498046875,
          "content": "#!/bin/sh\nset -e\n\nprevversion=$(go list -mod=readonly -m -f '{{ .Version }}' github.com/mjl-/mox@latest)\nif ! test -d tmp/mox-$prevversion; then\n\tmkdir -p tmp/mox-$prevversion\n\tgit archive --format=tar $prevversion | tar -C tmp/mox-$prevversion -xf -\nfi\n(rm -r tmp/apidiff || exit 0)\nmkdir -p tmp/apidiff/$prevversion tmp/apidiff/next\n(rm apidiff/next.txt apidiff/next.txt.new 2>/dev/null || exit 0)\nfor p in $(cat apidiff/packages.txt); do\n\tif ! test -d tmp/mox-$prevversion/$p; then\n\t\tcontinue\n\tfi\n\t(cd tmp/mox-$prevversion && apidiff -w ../apidiff/$prevversion/$p.api ./$p)\n\tapidiff -w tmp/apidiff/next/$p.api ./$p\n\tapidiff -incompatible tmp/apidiff/$prevversion/$p.api tmp/apidiff/next/$p.api >$p.diff\n\tif test -s $p.diff; then\n\t\t(\n\t\techo '#' $p\n\t\tcat $p.diff\n\t\techo\n\t\t) >>apidiff/next.txt.new\n\tfi\n\trm $p.diff\ndone\nif test -s apidiff/next.txt.new; then\n\t(\n\techo \"Below are the incompatible changes between $prevversion and next, per package.\"\n\techo\n\tcat apidiff/next.txt.new\n\t) >apidiff/next.txt\n\trm apidiff/next.txt.new\nelse\n\tmv apidiff/next.txt.new apidiff/next.txt\nfi\n"
        },
        {
          "name": "apidiff",
          "type": "tree",
          "content": null
        },
        {
          "name": "autotls",
          "type": "tree",
          "content": null
        },
        {
          "name": "backup.go",
          "type": "blob",
          "size": 18.1318359375,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/fs\"\n\t\"log/slog\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"strings\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/mjl-/bstore\"\n\n\t\"github.com/mjl-/mox/dmarcdb\"\n\t\"github.com/mjl-/mox/mox-\"\n\t\"github.com/mjl-/mox/moxvar\"\n\t\"github.com/mjl-/mox/mtastsdb\"\n\t\"github.com/mjl-/mox/queue\"\n\t\"github.com/mjl-/mox/store\"\n\t\"github.com/mjl-/mox/tlsrptdb\"\n)\n\nfunc backupctl(ctx context.Context, ctl *ctl) {\n\t/* protocol:\n\t> \"backup\"\n\t> destdir\n\t> \"verbose\" or \"\"\n\t< stream\n\t< \"ok\" or error\n\t*/\n\n\t// Convention in this function: variables containing \"src\" or \"dst\" are file system\n\t// paths that can be passed to os.Open and such. Variables with dirs/paths without\n\t// \"src\" or \"dst\" are incomplete paths relative to the source or destination data\n\t// directories.\n\n\tdstDataDir := ctl.xread()\n\tverbose := ctl.xread() == \"verbose\"\n\n\t// Set when an error is encountered. At the end, we warn if set.\n\tvar incomplete bool\n\n\t// We'll be writing output, and logging both to mox and the ctl stream.\n\twriter := ctl.writer()\n\n\t// Format easily readable output for the user.\n\tformatLog := func(prefix, text string, err error, attrs ...slog.Attr) []byte {\n\t\tvar b bytes.Buffer\n\t\tfmt.Fprint(&b, prefix)\n\t\tfmt.Fprint(&b, text)\n\t\tif err != nil {\n\t\t\tfmt.Fprint(&b, \": \"+err.Error())\n\t\t}\n\t\tfor _, a := range attrs {\n\t\t\tfmt.Fprintf(&b, \"; %s=%v\", a.Key, a.Value)\n\t\t}\n\t\tfmt.Fprint(&b, \"\\n\")\n\t\treturn b.Bytes()\n\t}\n\n\t// Log an error to both the mox service as the user running \"mox backup\".\n\tpkglogx := func(prefix, text string, err error, attrs ...slog.Attr) {\n\t\tctl.log.Errorx(text, err, attrs...)\n\n\t\t_, werr := writer.Write(formatLog(prefix, text, err, attrs...))\n\t\tctl.xcheck(werr, \"write to ctl\")\n\t}\n\n\t// Log an error but don't mark backup as failed.\n\txwarnx := func(text string, err error, attrs ...slog.Attr) {\n\t\tpkglogx(\"warning: \", text, err, attrs...)\n\t}\n\n\t// Log an error that causes the backup to be marked as failed. We typically\n\t// continue processing though.\n\txerrx := func(text string, err error, attrs ...slog.Attr) {\n\t\tincomplete = true\n\t\tpkglogx(\"error: \", text, err, attrs...)\n\t}\n\n\t// If verbose is enabled, log to the cli command. Always log as info level.\n\txvlog := func(text string, attrs ...slog.Attr) {\n\t\tctl.log.Info(text, attrs...)\n\t\tif verbose {\n\t\t\t_, werr := writer.Write(formatLog(\"\", text, nil, attrs...))\n\t\t\tctl.xcheck(werr, \"write to ctl\")\n\t\t}\n\t}\n\n\tif _, err := os.Stat(dstDataDir); err == nil {\n\t\txwarnx(\"destination data directory already exists\", nil, slog.String(\"dir\", dstDataDir))\n\t}\n\n\tsrcDataDir := filepath.Clean(mox.DataDirPath(\".\"))\n\n\t// When creating a file in the destination, we first ensure its directory exists.\n\t// We track which directories we created, to prevent needless syscalls.\n\tcreatedDirs := map[string]struct{}{}\n\tensureDestDir := func(dstpath string) {\n\t\tdstdir := filepath.Dir(dstpath)\n\t\tif _, ok := createdDirs[dstdir]; !ok {\n\t\t\terr := os.MkdirAll(dstdir, 0770)\n\t\t\tif err != nil {\n\t\t\t\txerrx(\"creating directory\", err)\n\t\t\t}\n\t\t\tcreatedDirs[dstdir] = struct{}{}\n\t\t}\n\t}\n\n\t// Backup a single file by copying (never hardlinking, the file may change).\n\tbackupFile := func(path string) {\n\t\ttmFile := time.Now()\n\t\tsrcpath := filepath.Join(srcDataDir, path)\n\t\tdstpath := filepath.Join(dstDataDir, path)\n\n\t\tsf, err := os.Open(srcpath)\n\t\tif err != nil {\n\t\t\txerrx(\"open source file (not backed up)\", err, slog.String(\"srcpath\", srcpath), slog.String(\"dstpath\", dstpath))\n\t\t\treturn\n\t\t}\n\t\tdefer sf.Close()\n\n\t\tensureDestDir(dstpath)\n\t\tdf, err := os.OpenFile(dstpath, os.O_WRONLY|os.O_CREATE|os.O_EXCL, 0660)\n\t\tif err != nil {\n\t\t\txerrx(\"creating destination file (not backed up)\", err, slog.String(\"srcpath\", srcpath), slog.String(\"dstpath\", dstpath))\n\t\t\treturn\n\t\t}\n\t\tdefer func() {\n\t\t\tif df != nil {\n\t\t\t\tdf.Close()\n\t\t\t}\n\t\t}()\n\t\tif _, err := io.Copy(df, sf); err != nil {\n\t\t\txerrx(\"copying file (not backed up properly)\", err, slog.String(\"srcpath\", srcpath), slog.String(\"dstpath\", dstpath))\n\t\t\treturn\n\t\t}\n\t\terr = df.Close()\n\t\tdf = nil\n\t\tif err != nil {\n\t\t\txerrx(\"closing destination file (not backed up properly)\", err, slog.String(\"srcpath\", srcpath), slog.String(\"dstpath\", dstpath))\n\t\t\treturn\n\t\t}\n\t\txvlog(\"backed up file\", slog.String(\"path\", path), slog.Duration(\"duration\", time.Since(tmFile)))\n\t}\n\n\t// Back up the files in a directory (by copying).\n\tbackupDir := func(dir string) {\n\t\ttmDir := time.Now()\n\t\tsrcdir := filepath.Join(srcDataDir, dir)\n\t\tdstdir := filepath.Join(dstDataDir, dir)\n\t\terr := filepath.WalkDir(srcdir, func(srcpath string, d fs.DirEntry, err error) error {\n\t\t\tif err != nil {\n\t\t\t\txerrx(\"walking file (not backed up)\", err, slog.String(\"srcpath\", srcpath))\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif d.IsDir() {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tbackupFile(srcpath[len(srcDataDir)+1:])\n\t\t\treturn nil\n\t\t})\n\t\tif err != nil {\n\t\t\txerrx(\"copying directory (not backed up properly)\", err,\n\t\t\t\tslog.String(\"srcdir\", srcdir),\n\t\t\t\tslog.String(\"dstdir\", dstdir),\n\t\t\t\tslog.Duration(\"duration\", time.Since(tmDir)))\n\t\t\treturn\n\t\t}\n\t\txvlog(\"backed up directory\", slog.String(\"dir\", dir), slog.Duration(\"duration\", time.Since(tmDir)))\n\t}\n\n\t// Backup a database by copying it in a readonly transaction.\n\t// Always logs on error, so caller doesn't have to, but also returns the error so\n\t// callers can see result.\n\tbackupDB := func(db *bstore.DB, path string) (rerr error) {\n\t\tdefer func() {\n\t\t\tif rerr != nil {\n\t\t\t\txerrx(\"backing up database\", rerr, slog.String(\"path\", path))\n\t\t\t}\n\t\t}()\n\n\t\ttmDB := time.Now()\n\n\t\tdstpath := filepath.Join(dstDataDir, path)\n\t\tensureDestDir(dstpath)\n\t\tdf, err := os.OpenFile(dstpath, os.O_WRONLY|os.O_CREATE|os.O_EXCL, 0660)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"creating destination file: %v\", err)\n\t\t}\n\t\tdefer func() {\n\t\t\tif df != nil {\n\t\t\t\tdf.Close()\n\t\t\t}\n\t\t}()\n\t\terr = db.Read(ctx, func(tx *bstore.Tx) error {\n\t\t\t// Using regular WriteTo seems fine, and fast. It just copies pages.\n\t\t\t//\n\t\t\t// bolt.Compact is slower, it writes all key/value pairs, building up new data\n\t\t\t// structures. My compacted test database was ~60% of original size. Lz4 on the\n\t\t\t// uncompacted database got it to 14%. Lz4 on the compacted database got it to 13%.\n\t\t\t// Backups are likely archived somewhere with compression, so we don't compact.\n\t\t\t//\n\t\t\t// Tests with WriteTo and os.O_DIRECT were slower than without O_DIRECT, but\n\t\t\t// probably because everything fit in the page cache. It may be better to use\n\t\t\t// O_DIRECT when copying many large or inactive databases.\n\t\t\t_, err := tx.WriteTo(df)\n\t\t\treturn err\n\t\t})\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"copying database: %v\", err)\n\t\t}\n\t\terr = df.Close()\n\t\tdf = nil\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"closing destination database after copy: %v\", err)\n\t\t}\n\t\txvlog(\"backed up database file\", slog.String(\"path\", path), slog.Duration(\"duration\", time.Since(tmDB)))\n\t\treturn nil\n\t}\n\n\t// Try to create a hardlink. Fall back to copying the file (e.g. when on different file system).\n\twarnedHardlink := false // We warn once about failing to hardlink.\n\tlinkOrCopy := func(srcpath, dstpath string) (bool, error) {\n\t\tensureDestDir(dstpath)\n\n\t\tif err := os.Link(srcpath, dstpath); err == nil {\n\t\t\treturn true, nil\n\t\t} else if os.IsNotExist(err) {\n\t\t\t// No point in trying with regular copy, we would warn twice.\n\t\t\treturn false, err\n\t\t} else if !warnedHardlink {\n\t\t\tvar hardlinkHint string\n\t\t\tif runtime.GOOS == \"linux\" && errors.Is(err, syscall.EXDEV) {\n\t\t\t\thardlinkHint = \" (hint: if running under systemd, ReadWritePaths in mox.service may cause multiple mountpoints; consider merging paths into a single parent directory to prevent cross-device/mountpoint hardlinks)\"\n\t\t\t}\n\t\t\txwarnx(\"creating hardlink to message failed, will be doing regular file copies and not warn again\"+hardlinkHint, err, slog.String(\"srcpath\", srcpath), slog.String(\"dstpath\", dstpath))\n\t\t\twarnedHardlink = true\n\t\t}\n\n\t\t// Fall back to copying.\n\t\tsf, err := os.Open(srcpath)\n\t\tif err != nil {\n\t\t\treturn false, fmt.Errorf(\"open source path %s: %v\", srcpath, err)\n\t\t}\n\t\tdefer func() {\n\t\t\terr := sf.Close()\n\t\t\tctl.log.Check(err, \"closing copied source file\")\n\t\t}()\n\n\t\tdf, err := os.OpenFile(dstpath, os.O_WRONLY|os.O_CREATE|os.O_EXCL, 0660)\n\t\tif err != nil {\n\t\t\treturn false, fmt.Errorf(\"create destination path %s: %v\", dstpath, err)\n\t\t}\n\t\tdefer func() {\n\t\t\tif df != nil {\n\t\t\t\terr := df.Close()\n\t\t\t\tctl.log.Check(err, \"closing partial destination file\")\n\t\t\t}\n\t\t}()\n\t\tif _, err := io.Copy(df, sf); err != nil {\n\t\t\treturn false, fmt.Errorf(\"coping: %v\", err)\n\t\t}\n\t\terr = df.Close()\n\t\tdf = nil\n\t\tif err != nil {\n\t\t\treturn false, fmt.Errorf(\"closing destination file: %v\", err)\n\t\t}\n\t\treturn false, nil\n\t}\n\n\t// Start making the backup.\n\ttmStart := time.Now()\n\n\tctl.log.Print(\"making backup\", slog.String(\"destdir\", dstDataDir))\n\n\terr := os.MkdirAll(dstDataDir, 0770)\n\tif err != nil {\n\t\txerrx(\"creating destination data directory\", err)\n\t}\n\n\tif err := os.WriteFile(filepath.Join(dstDataDir, \"moxversion\"), []byte(moxvar.Version), 0660); err != nil {\n\t\txerrx(\"writing moxversion\", err)\n\t}\n\tbackupDB(store.AuthDB, \"auth.db\")\n\tbackupDB(dmarcdb.ReportsDB, \"dmarcrpt.db\")\n\tbackupDB(dmarcdb.EvalDB, \"dmarceval.db\")\n\tbackupDB(mtastsdb.DB, \"mtasts.db\")\n\tbackupDB(tlsrptdb.ReportDB, \"tlsrpt.db\")\n\tbackupDB(tlsrptdb.ResultDB, \"tlsrptresult.db\")\n\tbackupFile(\"receivedid.key\")\n\n\t// Acme directory is optional.\n\tsrcAcmeDir := filepath.Join(srcDataDir, \"acme\")\n\tif _, err := os.Stat(srcAcmeDir); err == nil {\n\t\tbackupDir(\"acme\")\n\t} else if err != nil && !os.IsNotExist(err) {\n\t\txerrx(\"copying acme/\", err)\n\t}\n\n\t// Copy the queue database and all message files.\n\tbackupQueue := func(path string) {\n\t\ttmQueue := time.Now()\n\n\t\tif err := backupDB(queue.DB, path); err != nil {\n\t\t\txerrx(\"queue not backed up\", err, slog.String(\"path\", path), slog.Duration(\"duration\", time.Since(tmQueue)))\n\t\t\treturn\n\t\t}\n\n\t\tdstdbpath := filepath.Join(dstDataDir, path)\n\t\topts := bstore.Options{MustExist: true, RegisterLogger: ctl.log.Logger}\n\t\tdb, err := bstore.Open(ctx, dstdbpath, &opts, queue.DBTypes...)\n\t\tif err != nil {\n\t\t\txerrx(\"open copied queue database\", err, slog.String(\"dstpath\", dstdbpath), slog.Duration(\"duration\", time.Since(tmQueue)))\n\t\t\treturn\n\t\t}\n\n\t\tdefer func() {\n\t\t\tif db != nil {\n\t\t\t\terr := db.Close()\n\t\t\t\tctl.log.Check(err, \"closing new queue db\")\n\t\t\t}\n\t\t}()\n\n\t\t// Link/copy known message files. Warn if files are missing or unexpected\n\t\t// (though a message file could have been removed just now due to delivery, or a\n\t\t// new message may have been queued).\n\t\ttmMsgs := time.Now()\n\t\tseen := map[string]struct{}{}\n\t\tvar nlinked, ncopied int\n\t\terr = bstore.QueryDB[queue.Msg](ctx, db).ForEach(func(m queue.Msg) error {\n\t\t\tmp := store.MessagePath(m.ID)\n\t\t\tseen[mp] = struct{}{}\n\t\t\tsrcpath := filepath.Join(srcDataDir, \"queue\", mp)\n\t\t\tdstpath := filepath.Join(dstDataDir, \"queue\", mp)\n\t\t\tif linked, err := linkOrCopy(srcpath, dstpath); err != nil {\n\t\t\t\txerrx(\"linking/copying queue message\", err, slog.String(\"srcpath\", srcpath), slog.String(\"dstpath\", dstpath))\n\t\t\t} else if linked {\n\t\t\t\tnlinked++\n\t\t\t} else {\n\t\t\t\tncopied++\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t\tif err != nil {\n\t\t\txerrx(\"processing queue messages (not backed up properly)\", err, slog.Duration(\"duration\", time.Since(tmMsgs)))\n\t\t} else {\n\t\t\txvlog(\"queue message files linked/copied\",\n\t\t\t\tslog.Int(\"linked\", nlinked),\n\t\t\t\tslog.Int(\"copied\", ncopied),\n\t\t\t\tslog.Duration(\"duration\", time.Since(tmMsgs)))\n\t\t}\n\n\t\t// Read through all files in queue directory and warn about anything we haven't handled yet.\n\t\ttmWalk := time.Now()\n\t\tsrcqdir := filepath.Join(srcDataDir, \"queue\")\n\t\terr = filepath.WalkDir(srcqdir, func(srcqpath string, d fs.DirEntry, err error) error {\n\t\t\tif err != nil {\n\t\t\t\txerrx(\"walking files in queue\", err, slog.String(\"srcpath\", srcqpath))\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif d.IsDir() {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tp := srcqpath[len(srcqdir)+1:]\n\t\t\tif _, ok := seen[p]; ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif p == \"index.db\" {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tqp := filepath.Join(\"queue\", p)\n\t\t\txwarnx(\"backing up unrecognized file in queue directory\", nil, slog.String(\"path\", qp))\n\t\t\tbackupFile(qp)\n\t\t\treturn nil\n\t\t})\n\t\tif err != nil {\n\t\t\txerrx(\"walking queue directory (not backed up properly)\", err, slog.String(\"dir\", \"queue\"), slog.Duration(\"duration\", time.Since(tmWalk)))\n\t\t} else {\n\t\t\txvlog(\"walked queue directory\", slog.Duration(\"duration\", time.Since(tmWalk)))\n\t\t}\n\n\t\txvlog(\"queue backed finished\", slog.Duration(\"duration\", time.Since(tmQueue)))\n\t}\n\tbackupQueue(filepath.FromSlash(\"queue/index.db\"))\n\n\tbackupAccount := func(acc *store.Account) {\n\t\tdefer acc.Close()\n\n\t\ttmAccount := time.Now()\n\n\t\t// Copy database file.\n\t\tdbpath := filepath.Join(\"accounts\", acc.Name, \"index.db\")\n\t\terr := backupDB(acc.DB, dbpath)\n\t\tif err != nil {\n\t\t\txerrx(\"copying account database\", err, slog.String(\"path\", dbpath), slog.Duration(\"duration\", time.Since(tmAccount)))\n\t\t}\n\n\t\t// todo: should document/check not taking a rlock on account.\n\n\t\t// Copy junkfilter files, if configured.\n\t\tif jf, _, err := acc.OpenJunkFilter(ctx, ctl.log); err != nil {\n\t\t\tif !errors.Is(err, store.ErrNoJunkFilter) {\n\t\t\t\txerrx(\"opening junk filter for account (not backed up)\", err)\n\t\t\t}\n\t\t} else {\n\t\t\tdb := jf.DB()\n\t\t\tjfpath := filepath.Join(\"accounts\", acc.Name, \"junkfilter.db\")\n\t\t\tbackupDB(db, jfpath)\n\t\t\tbloompath := filepath.Join(\"accounts\", acc.Name, \"junkfilter.bloom\")\n\t\t\tbackupFile(bloompath)\n\t\t\tdb = nil\n\t\t\terr := jf.Close()\n\t\t\tctl.log.Check(err, \"closing junkfilter\")\n\t\t}\n\n\t\tdstdbpath := filepath.Join(dstDataDir, dbpath)\n\t\topts := bstore.Options{MustExist: true, RegisterLogger: ctl.log.Logger}\n\t\tdb, err := bstore.Open(ctx, dstdbpath, &opts, store.DBTypes...)\n\t\tif err != nil {\n\t\t\txerrx(\"open copied account database\", err, slog.String(\"dstpath\", dstdbpath), slog.Duration(\"duration\", time.Since(tmAccount)))\n\t\t\treturn\n\t\t}\n\n\t\tdefer func() {\n\t\t\tif db != nil {\n\t\t\t\terr := db.Close()\n\t\t\t\tctl.log.Check(err, \"close account database\")\n\t\t\t}\n\t\t}()\n\n\t\t// Link/copy known message files. Warn if files are missing or unexpected (though a\n\t\t// message file could have been added just now due to delivery, or a message have\n\t\t// been removed).\n\t\ttmMsgs := time.Now()\n\t\tseen := map[string]struct{}{}\n\t\tvar nlinked, ncopied int\n\t\terr = bstore.QueryDB[store.Message](ctx, db).FilterEqual(\"Expunged\", false).ForEach(func(m store.Message) error {\n\t\t\tmp := store.MessagePath(m.ID)\n\t\t\tseen[mp] = struct{}{}\n\t\t\tamp := filepath.Join(\"accounts\", acc.Name, \"msg\", mp)\n\t\t\tsrcpath := filepath.Join(srcDataDir, amp)\n\t\t\tdstpath := filepath.Join(dstDataDir, amp)\n\t\t\tif linked, err := linkOrCopy(srcpath, dstpath); err != nil {\n\t\t\t\txerrx(\"linking/copying account message\", err, slog.String(\"srcpath\", srcpath), slog.String(\"dstpath\", dstpath))\n\t\t\t} else if linked {\n\t\t\t\tnlinked++\n\t\t\t} else {\n\t\t\t\tncopied++\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t\tif err != nil {\n\t\t\txerrx(\"processing account messages (not backed up properly)\", err, slog.Duration(\"duration\", time.Since(tmMsgs)))\n\t\t} else {\n\t\t\txvlog(\"account message files linked/copied\",\n\t\t\t\tslog.Int(\"linked\", nlinked),\n\t\t\t\tslog.Int(\"copied\", ncopied),\n\t\t\t\tslog.Duration(\"duration\", time.Since(tmMsgs)))\n\t\t}\n\n\t\t// Read through all files in account directory and warn about anything we haven't handled yet.\n\t\ttmWalk := time.Now()\n\t\tsrcadir := filepath.Join(srcDataDir, \"accounts\", acc.Name)\n\t\terr = filepath.WalkDir(srcadir, func(srcapath string, d fs.DirEntry, err error) error {\n\t\t\tif err != nil {\n\t\t\t\txerrx(\"walking files in account\", err, slog.String(\"srcpath\", srcapath))\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif d.IsDir() {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tp := srcapath[len(srcadir)+1:]\n\t\t\tl := strings.Split(p, string(filepath.Separator))\n\t\t\tif l[0] == \"msg\" {\n\t\t\t\tmp := filepath.Join(l[1:]...)\n\t\t\t\tif _, ok := seen[mp]; ok {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t}\n\t\t\tswitch p {\n\t\t\tcase \"index.db\", \"junkfilter.db\", \"junkfilter.bloom\":\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tap := filepath.Join(\"accounts\", acc.Name, p)\n\t\t\tif strings.HasPrefix(p, \"msg\"+string(filepath.Separator)) {\n\t\t\t\txwarnx(\"backing up unrecognized file in account message directory (should be moved away)\", nil, slog.String(\"path\", ap))\n\t\t\t} else {\n\t\t\t\txwarnx(\"backing up unrecognized file in account directory\", nil, slog.String(\"path\", ap))\n\t\t\t}\n\t\t\tbackupFile(ap)\n\t\t\treturn nil\n\t\t})\n\t\tif err != nil {\n\t\t\txerrx(\"walking account directory (not backed up properly)\", err, slog.String(\"srcdir\", srcadir), slog.Duration(\"duration\", time.Since(tmWalk)))\n\t\t} else {\n\t\t\txvlog(\"walked account directory\", slog.Duration(\"duration\", time.Since(tmWalk)))\n\t\t}\n\n\t\txvlog(\"account backup finished\", slog.String(\"dir\", filepath.Join(\"accounts\", acc.Name)), slog.Duration(\"duration\", time.Since(tmAccount)))\n\t}\n\n\t// For each configured account, open it, make a copy of the database and\n\t// hardlink/copy the messages. We track the accounts we handled, and skip the\n\t// account directories when handling \"all other files\" below.\n\taccounts := map[string]struct{}{}\n\tfor _, accName := range mox.Conf.Accounts() {\n\t\tacc, err := store.OpenAccount(ctl.log, accName)\n\t\tif err != nil {\n\t\t\txerrx(\"opening account for copying (will try to copy as regular files later)\", err, slog.String(\"account\", accName))\n\t\t\tcontinue\n\t\t}\n\t\taccounts[accName] = struct{}{}\n\t\tbackupAccount(acc)\n\t}\n\n\t// Copy all other files, that aren't part of the known files, databases, queue or accounts.\n\ttmWalk := time.Now()\n\terr = filepath.WalkDir(srcDataDir, func(srcpath string, d fs.DirEntry, err error) error {\n\t\tif err != nil {\n\t\t\txerrx(\"walking path\", err, slog.String(\"path\", srcpath))\n\t\t\treturn nil\n\t\t}\n\n\t\tif srcpath == srcDataDir {\n\t\t\treturn nil\n\t\t}\n\t\tp := srcpath[len(srcDataDir)+1:]\n\t\tif p == \"queue\" || p == \"acme\" || p == \"tmp\" {\n\t\t\treturn fs.SkipDir\n\t\t}\n\t\tl := strings.Split(p, string(filepath.Separator))\n\t\tif len(l) >= 2 && l[0] == \"accounts\" {\n\t\t\tname := l[1]\n\t\t\tif _, ok := accounts[name]; ok {\n\t\t\t\treturn fs.SkipDir\n\t\t\t}\n\t\t}\n\n\t\t// Only files are explicitly backed up.\n\t\tif d.IsDir() {\n\t\t\treturn nil\n\t\t}\n\n\t\tswitch p {\n\t\tcase \"auth.db\", \"dmarcrpt.db\", \"dmarceval.db\", \"mtasts.db\", \"tlsrpt.db\", \"tlsrptresult.db\", \"receivedid.key\", \"ctl\":\n\t\t\t// Already handled.\n\t\t\treturn nil\n\t\tcase \"lastknownversion\": // Optional file, not yet handled.\n\t\tdefault:\n\t\t\txwarnx(\"backing up unrecognized file\", nil, slog.String(\"path\", p))\n\t\t}\n\t\tbackupFile(p)\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\txerrx(\"walking other files (not backed up properly)\", err, slog.Duration(\"duration\", time.Since(tmWalk)))\n\t} else {\n\t\txvlog(\"walking other files finished\", slog.Duration(\"duration\", time.Since(tmWalk)))\n\t}\n\n\txvlog(\"backup finished\", slog.Duration(\"duration\", time.Since(tmStart)))\n\n\twriter.xclose()\n\n\tif incomplete {\n\t\tctl.xwrite(\"errors were encountered during backup\")\n\t} else {\n\t\tctl.xwriteok()\n\t}\n}\n"
        },
        {
          "name": "compatibility.txt",
          "type": "blob",
          "size": 1.421875,
          "content": "Known compatibility issues.\n\n- Autodiscovery with Microsoft Outlook (on macOS): Outlook appears to use a Microsoft service to fetch the configuration, instead of connecting directly. Their service makes an invalid TLS handshake (an SNI name with a trailing dot), which is rejected by the Go crypto/tls library. (2023-01)\n- Microsoft Outlook on macOS cannot sent messages. IMAP appears to work. During setup, an SMTP connection comes in, and AUTH PLAIN is successful. But the \"Send\" button is grayed out, so sending is not possible. There is probably something in our SMTP session that Outlook does not like. Though their logging only contains lines explaining SMTP was successful, both for SIZE and AUTH, with no mention of errors.\n- When adding an account in Microsoft Outlook on macOS with the \"sync to microsoft cloud\" checkbox checked (the default), you'll get incoming IMAP/SMTP connections from the cloud instead of from Outlook. IMAP works. SMTP for submission does not work. I'm seeing what appears to be a \"LOGIN\" SASL mechanism. A draft https://www.ietf.org/archive/id/draft-murchison-sasl-login-00.txt expired in 2004, and was created only to document that LOGIN is deprecated/obsolete. We don't announce support for LOGIN, because we don't support it. On top of that, they are sending SASL \"initial client data\", which is not allowed with the LOGIN mechanism. Perhaps our SMTP protocol responses have something weird to them that trigger this.\n"
        },
        {
          "name": "config",
          "type": "tree",
          "content": null
        },
        {
          "name": "ctl.go",
          "type": "blob",
          "size": 43.619140625,
          "content": "package main\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"log/slog\"\n\t\"maps\"\n\t\"net\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"runtime/debug\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/mjl-/bstore\"\n\n\t\"github.com/mjl-/mox/admin\"\n\t\"github.com/mjl-/mox/config\"\n\t\"github.com/mjl-/mox/dns\"\n\t\"github.com/mjl-/mox/message\"\n\t\"github.com/mjl-/mox/metrics\"\n\t\"github.com/mjl-/mox/mlog\"\n\t\"github.com/mjl-/mox/mox-\"\n\t\"github.com/mjl-/mox/queue\"\n\t\"github.com/mjl-/mox/smtp\"\n\t\"github.com/mjl-/mox/store\"\n\t\"github.com/mjl-/mox/webapi\"\n)\n\n// ctl represents a connection to the ctl unix domain socket of a running mox instance.\n// ctl provides functions to read/write commands/responses/data streams.\ntype ctl struct {\n\tcmd  string // Set for server-side of commands.\n\tconn net.Conn\n\tr    *bufio.Reader // Set for first reader.\n\tx    any           // If set, errors are handled by calling panic(x) instead of log.Fatal.\n\tlog  mlog.Log      // If set, along with x, logging is done here.\n}\n\n// xctl opens a ctl connection.\nfunc xctl() *ctl {\n\tp := mox.DataDirPath(\"ctl\")\n\tconn, err := net.Dial(\"unix\", p)\n\tif err != nil {\n\t\tlog.Fatalf(\"connecting to control socket at %q: %v\", p, err)\n\t}\n\tctl := &ctl{conn: conn}\n\tversion := ctl.xread()\n\tif version != \"ctlv0\" {\n\t\tlog.Fatalf(\"ctl protocol mismatch, got %q, expected ctlv0\", version)\n\t}\n\treturn ctl\n}\n\n// Interpret msg as an error.\n// If ctl.x is set, the string is also written to the ctl to be interpreted as error by the other party.\nfunc (c *ctl) xerror(msg string) {\n\tif c.x == nil {\n\t\tlog.Fatalln(msg)\n\t}\n\tc.log.Debugx(\"ctl error\", fmt.Errorf(\"%s\", msg), slog.String(\"cmd\", c.cmd))\n\tc.xwrite(msg)\n\tpanic(c.x)\n}\n\n// Check if err is not nil. If so, handle error through ctl.x or log.Fatal. If\n// ctl.x is set, the error string is written to ctl, to be interpreted as an error\n// by the command reading from ctl.\nfunc (c *ctl) xcheck(err error, msg string) {\n\tif err == nil {\n\t\treturn\n\t}\n\tif c.x == nil {\n\t\tlog.Fatalf(\"%s: %s\", msg, err)\n\t}\n\tc.log.Debugx(msg, err, slog.String(\"cmd\", c.cmd))\n\tfmt.Fprintf(c.conn, \"%s: %s\\n\", msg, err)\n\tpanic(c.x)\n}\n\n// Read a line and return it without trailing newline.\nfunc (c *ctl) xread() string {\n\tif c.r == nil {\n\t\tc.r = bufio.NewReader(c.conn)\n\t}\n\tline, err := c.r.ReadString('\\n')\n\tc.xcheck(err, \"read from ctl\")\n\treturn strings.TrimSuffix(line, \"\\n\")\n}\n\n// Read a line. If not \"ok\", the string is interpreted as an error.\nfunc (c *ctl) xreadok() {\n\tline := c.xread()\n\tif line != \"ok\" {\n\t\tc.xerror(line)\n\t}\n}\n\n// Write a string, typically a command or parameter.\nfunc (c *ctl) xwrite(text string) {\n\t_, err := fmt.Fprintln(c.conn, text)\n\tc.xcheck(err, \"write\")\n}\n\n// Write \"ok\" to indicate success.\nfunc (c *ctl) xwriteok() {\n\tc.xwrite(\"ok\")\n}\n\n// Copy data from a stream from ctl to dst.\nfunc (c *ctl) xstreamto(dst io.Writer) {\n\t_, err := io.Copy(dst, c.reader())\n\tc.xcheck(err, \"reading message\")\n}\n\n// Copy data from src to a stream to ctl.\nfunc (c *ctl) xstreamfrom(src io.Reader) {\n\tw := c.writer()\n\t_, err := io.Copy(w, src)\n\tc.xcheck(err, \"copying\")\n\tw.xclose()\n}\n\n// Writer returns an io.Writer for a data stream to ctl.\n// When done writing, caller must call xclose to signal the end of the stream.\n// Behaviour of \"x\" is copied from ctl.\nfunc (c *ctl) writer() *ctlwriter {\n\treturn &ctlwriter{cmd: c.cmd, conn: c.conn, x: c.x, log: c.log}\n}\n\n// Reader returns an io.Reader for a data stream from ctl.\n// Behaviour of \"x\" is copied from ctl.\nfunc (c *ctl) reader() *ctlreader {\n\tif c.r == nil {\n\t\tc.r = bufio.NewReader(c.conn)\n\t}\n\treturn &ctlreader{cmd: c.cmd, conn: c.conn, r: c.r, x: c.x, log: c.log}\n}\n\n/*\nCtlwriter and ctlreader implement the writing and reading a data stream. They\nimplement the io.Writer and io.Reader interface. In the protocol below each\nnon-data message ends with a newline that is typically stripped when\ninterpreting.\n\nZero or more data transactions:\n\n\t> \"123\" (for data size) or an error message\n\t> data, 123 bytes\n\t< \"ok\" or an error message\n\nFollowed by a end of stream indicated by zero data bytes message:\n\n\t> \"0\"\n*/\n\ntype ctlwriter struct {\n\tcmd  string   // Set for server-side of commands.\n\tconn net.Conn // Ctl socket from which messages are read.\n\tbuf  []byte   // Scratch buffer, for reading response.\n\tx    any      // If not nil, errors in Write and xcheckf are handled with panic(x), otherwise with a log.Fatal.\n\tlog  mlog.Log\n}\n\nfunc (s *ctlwriter) Write(buf []byte) (int, error) {\n\t_, err := fmt.Fprintf(s.conn, \"%d\\n\", len(buf))\n\ts.xcheck(err, \"write count\")\n\t_, err = s.conn.Write(buf)\n\ts.xcheck(err, \"write data\")\n\tif s.buf == nil {\n\t\ts.buf = make([]byte, 512)\n\t}\n\tn, err := s.conn.Read(s.buf)\n\ts.xcheck(err, \"reading response to write\")\n\tline := strings.TrimSuffix(string(s.buf[:n]), \"\\n\")\n\tif line != \"ok\" {\n\t\ts.xerror(line)\n\t}\n\treturn len(buf), nil\n}\n\nfunc (s *ctlwriter) xerror(msg string) {\n\tif s.x == nil {\n\t\tlog.Fatalln(msg)\n\t} else {\n\t\ts.log.Debugx(\"error\", fmt.Errorf(\"%s\", msg), slog.String(\"cmd\", s.cmd))\n\t\tpanic(s.x)\n\t}\n}\n\nfunc (s *ctlwriter) xcheck(err error, msg string) {\n\tif err == nil {\n\t\treturn\n\t}\n\tif s.x == nil {\n\t\tlog.Fatalf(\"%s: %s\", msg, err)\n\t} else {\n\t\ts.log.Debugx(msg, err, slog.String(\"cmd\", s.cmd))\n\t\tpanic(s.x)\n\t}\n}\n\nfunc (s *ctlwriter) xclose() {\n\t_, err := fmt.Fprintf(s.conn, \"0\\n\")\n\ts.xcheck(err, \"write eof\")\n}\n\ntype ctlreader struct {\n\tcmd      string        // Set for server-side of command.\n\tconn     net.Conn      // For writing \"ok\" after reading.\n\tr        *bufio.Reader // Buffered ctl socket.\n\terr      error         // If set, returned for each read. can also be io.EOF.\n\tnpending int           // Number of bytes that can still be read until a new count line must be read.\n\tx        any           // If set, errors are handled with panic(x) instead of log.Fatal.\n\tlog      mlog.Log      // If x is set, logging goes to log.\n}\n\nfunc (s *ctlreader) Read(buf []byte) (N int, Err error) {\n\tif s.err != nil {\n\t\treturn 0, s.err\n\t}\n\tif s.npending == 0 {\n\t\tline, err := s.r.ReadString('\\n')\n\t\ts.xcheck(err, \"reading count\")\n\t\tline = strings.TrimSuffix(line, \"\\n\")\n\t\tn, err := strconv.ParseInt(line, 10, 32)\n\t\tif err != nil {\n\t\t\ts.xerror(line)\n\t\t}\n\t\tif n == 0 {\n\t\t\ts.err = io.EOF\n\t\t\treturn 0, s.err\n\t\t}\n\t\ts.npending = int(n)\n\t}\n\trn := len(buf)\n\tif rn > s.npending {\n\t\trn = s.npending\n\t}\n\tn, err := s.r.Read(buf[:rn])\n\ts.xcheck(err, \"read from ctl\")\n\ts.npending -= n\n\tif s.npending == 0 {\n\t\t_, err = fmt.Fprintln(s.conn, \"ok\")\n\t\ts.xcheck(err, \"writing ok after reading\")\n\t}\n\treturn n, err\n}\n\nfunc (s *ctlreader) xerror(msg string) {\n\tif s.x == nil {\n\t\tlog.Fatalln(msg)\n\t} else {\n\t\ts.log.Debugx(\"error\", fmt.Errorf(\"%s\", msg), slog.String(\"cmd\", s.cmd))\n\t\tpanic(s.x)\n\t}\n}\n\nfunc (s *ctlreader) xcheck(err error, msg string) {\n\tif err == nil {\n\t\treturn\n\t}\n\tif s.x == nil {\n\t\tlog.Fatalf(\"%s: %s\", msg, err)\n\t} else {\n\t\ts.log.Debugx(msg, err, slog.String(\"cmd\", s.cmd))\n\t\tpanic(s.x)\n\t}\n}\n\n// servectl handles requests on the unix domain socket \"ctl\", e.g. for graceful shutdown, local mail delivery.\nfunc servectl(ctx context.Context, log mlog.Log, conn net.Conn, shutdown func()) {\n\tlog.Debug(\"ctl connection\")\n\n\tvar stop = struct{}{} // Sentinel value for panic and recover.\n\tctl := &ctl{conn: conn, x: stop, log: log}\n\tdefer func() {\n\t\tx := recover()\n\t\tif x == nil || x == stop {\n\t\t\treturn\n\t\t}\n\t\tlog.Error(\"servectl panic\", slog.Any(\"err\", x), slog.String(\"cmd\", ctl.cmd))\n\t\tdebug.PrintStack()\n\t\tmetrics.PanicInc(metrics.Ctl)\n\t}()\n\n\tdefer conn.Close()\n\n\tctl.xwrite(\"ctlv0\")\n\tfor {\n\t\tservectlcmd(ctx, ctl, shutdown)\n\t}\n}\n\nfunc xparseJSON(ctl *ctl, s string, v any) {\n\tdec := json.NewDecoder(strings.NewReader(s))\n\tdec.DisallowUnknownFields()\n\terr := dec.Decode(v)\n\tctl.xcheck(err, \"parsing from ctl as json\")\n}\n\nfunc servectlcmd(ctx context.Context, ctl *ctl, shutdown func()) {\n\tlog := ctl.log\n\tcmd := ctl.xread()\n\tctl.cmd = cmd\n\tlog.Info(\"ctl command\", slog.String(\"cmd\", cmd))\n\tswitch cmd {\n\tcase \"stop\":\n\t\tshutdown()\n\t\tos.Exit(0)\n\n\tcase \"deliver\":\n\t\t/* The protocol, double quoted are literals.\n\n\t\t> \"deliver\"\n\t\t> address\n\t\t< \"ok\"\n\t\t> stream\n\t\t< \"ok\"\n\t\t*/\n\n\t\tto := ctl.xread()\n\t\ta, addr, err := store.OpenEmail(log, to)\n\t\tctl.xcheck(err, \"lookup destination address\")\n\n\t\tmsgFile, err := store.CreateMessageTemp(log, \"ctl-deliver\")\n\t\tctl.xcheck(err, \"creating temporary message file\")\n\t\tdefer store.CloseRemoveTempFile(log, msgFile, \"deliver message\")\n\t\tmw := message.NewWriter(msgFile)\n\t\tctl.xwriteok()\n\n\t\tctl.xstreamto(mw)\n\t\terr = msgFile.Sync()\n\t\tctl.xcheck(err, \"syncing message to storage\")\n\n\t\tm := store.Message{\n\t\t\tReceived: time.Now(),\n\t\t\tSize:     mw.Size,\n\t\t}\n\n\t\ta.WithWLock(func() {\n\t\t\terr := a.DeliverDestination(log, addr, &m, msgFile)\n\t\t\tctl.xcheck(err, \"delivering message\")\n\t\t\tlog.Info(\"message delivered through ctl\", slog.Any(\"to\", to))\n\t\t})\n\n\t\terr = a.Close()\n\t\tctl.xcheck(err, \"closing account\")\n\t\tctl.xwriteok()\n\n\tcase \"setaccountpassword\":\n\t\t/* protocol:\n\t\t> \"setaccountpassword\"\n\t\t> account\n\t\t> password\n\t\t< \"ok\" or error\n\t\t*/\n\n\t\taccount := ctl.xread()\n\t\tpw := ctl.xread()\n\n\t\tacc, err := store.OpenAccount(log, account)\n\t\tctl.xcheck(err, \"open account\")\n\t\tdefer func() {\n\t\t\tif acc != nil {\n\t\t\t\terr := acc.Close()\n\t\t\t\tlog.Check(err, \"closing account after setting password\")\n\t\t\t}\n\t\t}()\n\n\t\terr = acc.SetPassword(log, pw)\n\t\tctl.xcheck(err, \"setting password\")\n\t\terr = acc.Close()\n\t\tctl.xcheck(err, \"closing account\")\n\t\tacc = nil\n\t\tctl.xwriteok()\n\n\tcase \"queueholdruleslist\":\n\t\t/* protocol:\n\t\t> \"queueholdruleslist\"\n\t\t< \"ok\"\n\t\t< stream\n\t\t*/\n\t\tl, err := queue.HoldRuleList(ctx)\n\t\tctl.xcheck(err, \"listing hold rules\")\n\t\tctl.xwriteok()\n\t\txw := ctl.writer()\n\t\tfmt.Fprintln(xw, \"hold rules:\")\n\t\tfor _, hr := range l {\n\t\t\tvar elems []string\n\t\t\tif hr.Account != \"\" {\n\t\t\t\telems = append(elems, fmt.Sprintf(\"account %q\", hr.Account))\n\t\t\t}\n\t\t\tvar zerodom dns.Domain\n\t\t\tif hr.SenderDomain != zerodom {\n\t\t\t\telems = append(elems, fmt.Sprintf(\"sender domain %q\", hr.SenderDomain.Name()))\n\t\t\t}\n\t\t\tif hr.RecipientDomain != zerodom {\n\t\t\t\telems = append(elems, fmt.Sprintf(\"sender domain %q\", hr.RecipientDomain.Name()))\n\t\t\t}\n\t\t\tif len(elems) == 0 {\n\t\t\t\tfmt.Fprintf(xw, \"id %d: all messages\\n\", hr.ID)\n\t\t\t} else {\n\t\t\t\tfmt.Fprintf(xw, \"id %d: %s\\n\", hr.ID, strings.Join(elems, \", \"))\n\t\t\t}\n\t\t}\n\t\tif len(l) == 0 {\n\t\t\tfmt.Fprint(xw, \"(none)\\n\")\n\t\t}\n\t\txw.xclose()\n\n\tcase \"queueholdrulesadd\":\n\t\t/* protocol:\n\t\t> \"queueholdrulesadd\"\n\t\t> account\n\t\t> senderdomainstr\n\t\t> recipientdomainstr\n\t\t< \"ok\" or error\n\t\t*/\n\t\tvar hr queue.HoldRule\n\t\thr.Account = ctl.xread()\n\t\tsenderdomstr := ctl.xread()\n\t\trcptdomstr := ctl.xread()\n\t\tvar err error\n\t\thr.SenderDomain, err = dns.ParseDomain(senderdomstr)\n\t\tctl.xcheck(err, \"parsing sender domain\")\n\t\thr.RecipientDomain, err = dns.ParseDomain(rcptdomstr)\n\t\tctl.xcheck(err, \"parsing recipient domain\")\n\t\thr, err = queue.HoldRuleAdd(ctx, log, hr)\n\t\tctl.xcheck(err, \"add hold rule\")\n\t\tctl.xwriteok()\n\n\tcase \"queueholdrulesremove\":\n\t\t/* protocol:\n\t\t> \"queueholdrulesremove\"\n\t\t> id\n\t\t< \"ok\" or error\n\t\t*/\n\t\tidstr := ctl.xread()\n\t\tid, err := strconv.ParseInt(idstr, 10, 64)\n\t\tctl.xcheck(err, \"parsing id\")\n\t\terr = queue.HoldRuleRemove(ctx, log, id)\n\t\tctl.xcheck(err, \"remove hold rule\")\n\t\tctl.xwriteok()\n\n\tcase \"queuelist\":\n\t\t/* protocol:\n\t\t> \"queuelist\"\n\t\t> filters as json\n\t\t> sort as json\n\t\t< \"ok\"\n\t\t< stream\n\t\t*/\n\t\tfilterline := ctl.xread()\n\t\tsortline := ctl.xread()\n\t\tvar f queue.Filter\n\t\txparseJSON(ctl, filterline, &f)\n\t\tvar s queue.Sort\n\t\txparseJSON(ctl, sortline, &s)\n\t\tqmsgs, err := queue.List(ctx, f, s)\n\t\tctl.xcheck(err, \"listing queue\")\n\t\tctl.xwriteok()\n\n\t\txw := ctl.writer()\n\t\tfmt.Fprintln(xw, \"messages:\")\n\t\tfor _, qm := range qmsgs {\n\t\t\tvar lastAttempt string\n\t\t\tif qm.LastAttempt != nil {\n\t\t\t\tlastAttempt = time.Since(*qm.LastAttempt).Round(time.Second).String()\n\t\t\t}\n\t\t\tfmt.Fprintf(xw, \"%5d %s from:%s to:%s next %s last %s error %q\\n\", qm.ID, qm.Queued.Format(time.RFC3339), qm.Sender().LogString(), qm.Recipient().LogString(), -time.Since(qm.NextAttempt).Round(time.Second), lastAttempt, qm.LastResult().Error)\n\t\t}\n\t\tif len(qmsgs) == 0 {\n\t\t\tfmt.Fprint(xw, \"(none)\\n\")\n\t\t}\n\t\txw.xclose()\n\n\tcase \"queueholdset\":\n\t\t/* protocol:\n\t\t> \"queueholdset\"\n\t\t> queuefilters as json\n\t\t> \"true\" or \"false\"\n\t\t< \"ok\" or error\n\t\t< count\n\t\t*/\n\n\t\tfilterline := ctl.xread()\n\t\thold := ctl.xread() == \"true\"\n\t\tvar f queue.Filter\n\t\txparseJSON(ctl, filterline, &f)\n\t\tcount, err := queue.HoldSet(ctx, f, hold)\n\t\tctl.xcheck(err, \"setting on hold status for messages\")\n\t\tctl.xwriteok()\n\t\tctl.xwrite(fmt.Sprintf(\"%d\", count))\n\n\tcase \"queueschedule\":\n\t\t/* protocol:\n\t\t> \"queueschedule\"\n\t\t> queuefilters as json\n\t\t> relative to now\n\t\t> duration\n\t\t< \"ok\" or error\n\t\t< count\n\t\t*/\n\n\t\tfilterline := ctl.xread()\n\t\trelnow := ctl.xread()\n\t\tduration := ctl.xread()\n\t\tvar f queue.Filter\n\t\txparseJSON(ctl, filterline, &f)\n\t\td, err := time.ParseDuration(duration)\n\t\tctl.xcheck(err, \"parsing duration for next delivery attempt\")\n\t\tvar count int\n\t\tif relnow == \"\" {\n\t\t\tcount, err = queue.NextAttemptAdd(ctx, f, d)\n\t\t} else {\n\t\t\tcount, err = queue.NextAttemptSet(ctx, f, time.Now().Add(d))\n\t\t}\n\t\tctl.xcheck(err, \"setting next delivery attempts in queue\")\n\t\tctl.xwriteok()\n\t\tctl.xwrite(fmt.Sprintf(\"%d\", count))\n\n\tcase \"queuetransport\":\n\t\t/* protocol:\n\t\t> \"queuetransport\"\n\t\t> queuefilters as json\n\t\t> transport\n\t\t< \"ok\" or error\n\t\t< count\n\t\t*/\n\n\t\tfilterline := ctl.xread()\n\t\ttransport := ctl.xread()\n\t\tvar f queue.Filter\n\t\txparseJSON(ctl, filterline, &f)\n\t\tcount, err := queue.TransportSet(ctx, f, transport)\n\t\tctl.xcheck(err, \"adding to next delivery attempts in queue\")\n\t\tctl.xwriteok()\n\t\tctl.xwrite(fmt.Sprintf(\"%d\", count))\n\n\tcase \"queuerequiretls\":\n\t\t/* protocol:\n\t\t> \"queuerequiretls\"\n\t\t> queuefilters as json\n\t\t> reqtls (empty string, \"true\" or \"false\")\n\t\t< \"ok\" or error\n\t\t< count\n\t\t*/\n\n\t\tfilterline := ctl.xread()\n\t\treqtls := ctl.xread()\n\t\tvar req *bool\n\t\tswitch reqtls {\n\t\tcase \"\":\n\t\tcase \"true\":\n\t\t\tv := true\n\t\t\treq = &v\n\t\tcase \"false\":\n\t\t\tv := false\n\t\t\treq = &v\n\t\tdefault:\n\t\t\tctl.xcheck(fmt.Errorf(\"unknown value %q\", reqtls), \"parsing value\")\n\t\t}\n\t\tvar f queue.Filter\n\t\txparseJSON(ctl, filterline, &f)\n\t\tcount, err := queue.RequireTLSSet(ctx, f, req)\n\t\tctl.xcheck(err, \"setting tls requirements on messages in queue\")\n\t\tctl.xwriteok()\n\t\tctl.xwrite(fmt.Sprintf(\"%d\", count))\n\n\tcase \"queuefail\":\n\t\t/* protocol:\n\t\t> \"queuefail\"\n\t\t> queuefilters as json\n\t\t< \"ok\" or error\n\t\t< count\n\t\t*/\n\n\t\tfilterline := ctl.xread()\n\t\tvar f queue.Filter\n\t\txparseJSON(ctl, filterline, &f)\n\t\tcount, err := queue.Fail(ctx, log, f)\n\t\tctl.xcheck(err, \"marking messages from queue as failed\")\n\t\tctl.xwriteok()\n\t\tctl.xwrite(fmt.Sprintf(\"%d\", count))\n\n\tcase \"queuedrop\":\n\t\t/* protocol:\n\t\t> \"queuedrop\"\n\t\t> queuefilters as json\n\t\t< \"ok\" or error\n\t\t< count\n\t\t*/\n\n\t\tfilterline := ctl.xread()\n\t\tvar f queue.Filter\n\t\txparseJSON(ctl, filterline, &f)\n\t\tcount, err := queue.Drop(ctx, log, f)\n\t\tctl.xcheck(err, \"dropping messages from queue\")\n\t\tctl.xwriteok()\n\t\tctl.xwrite(fmt.Sprintf(\"%d\", count))\n\n\tcase \"queuedump\":\n\t\t/* protocol:\n\t\t> \"queuedump\"\n\t\t> id\n\t\t< \"ok\" or error\n\t\t< stream\n\t\t*/\n\n\t\tidstr := ctl.xread()\n\t\tid, err := strconv.ParseInt(idstr, 10, 64)\n\t\tif err != nil {\n\t\t\tctl.xcheck(err, \"parsing id\")\n\t\t}\n\t\tmr, err := queue.OpenMessage(ctx, id)\n\t\tctl.xcheck(err, \"opening message\")\n\t\tdefer func() {\n\t\t\terr := mr.Close()\n\t\t\tlog.Check(err, \"closing message from queue\")\n\t\t}()\n\t\tctl.xwriteok()\n\t\tctl.xstreamfrom(mr)\n\n\tcase \"queueretiredlist\":\n\t\t/* protocol:\n\t\t> \"queueretiredlist\"\n\t\t> filters as json\n\t\t> sort as json\n\t\t< \"ok\"\n\t\t< stream\n\t\t*/\n\t\tfilterline := ctl.xread()\n\t\tsortline := ctl.xread()\n\t\tvar f queue.RetiredFilter\n\t\txparseJSON(ctl, filterline, &f)\n\t\tvar s queue.RetiredSort\n\t\txparseJSON(ctl, sortline, &s)\n\t\tqmsgs, err := queue.RetiredList(ctx, f, s)\n\t\tctl.xcheck(err, \"listing retired queue\")\n\t\tctl.xwriteok()\n\n\t\txw := ctl.writer()\n\t\tfmt.Fprintln(xw, \"retired messages:\")\n\t\tfor _, qm := range qmsgs {\n\t\t\tvar lastAttempt string\n\t\t\tif qm.LastAttempt != nil {\n\t\t\t\tlastAttempt = time.Since(*qm.LastAttempt).Round(time.Second).String()\n\t\t\t}\n\t\t\tresult := \"failure\"\n\t\t\tif qm.Success {\n\t\t\t\tresult = \"success\"\n\t\t\t}\n\t\t\tsender, err := qm.Sender()\n\t\t\txcheckf(err, \"parsing sender\")\n\t\t\tfmt.Fprintf(xw, \"%5d %s %s from:%s to:%s last %s error %q\\n\", qm.ID, qm.Queued.Format(time.RFC3339), result, sender.LogString(), qm.Recipient().LogString(), lastAttempt, qm.LastResult().Error)\n\t\t}\n\t\tif len(qmsgs) == 0 {\n\t\t\tfmt.Fprint(xw, \"(none)\\n\")\n\t\t}\n\t\txw.xclose()\n\n\tcase \"queueretiredprint\":\n\t\t/* protocol:\n\t\t> \"queueretiredprint\"\n\t\t> id\n\t\t< \"ok\"\n\t\t< stream\n\t\t*/\n\t\tidstr := ctl.xread()\n\t\tid, err := strconv.ParseInt(idstr, 10, 64)\n\t\tif err != nil {\n\t\t\tctl.xcheck(err, \"parsing id\")\n\t\t}\n\t\tl, err := queue.RetiredList(ctx, queue.RetiredFilter{IDs: []int64{id}}, queue.RetiredSort{})\n\t\tctl.xcheck(err, \"getting retired messages\")\n\t\tif len(l) == 0 {\n\t\t\tctl.xcheck(errors.New(\"not found\"), \"getting retired message\")\n\t\t}\n\t\tm := l[0]\n\t\tctl.xwriteok()\n\t\txw := ctl.writer()\n\t\tenc := json.NewEncoder(xw)\n\t\tenc.SetIndent(\"\", \"\\t\")\n\t\terr = enc.Encode(m)\n\t\tctl.xcheck(err, \"encode retired message\")\n\t\txw.xclose()\n\n\tcase \"queuehooklist\":\n\t\t/* protocol:\n\t\t> \"queuehooklist\"\n\t\t> filters as json\n\t\t> sort as json\n\t\t< \"ok\"\n\t\t< stream\n\t\t*/\n\t\tfilterline := ctl.xread()\n\t\tsortline := ctl.xread()\n\t\tvar f queue.HookFilter\n\t\txparseJSON(ctl, filterline, &f)\n\t\tvar s queue.HookSort\n\t\txparseJSON(ctl, sortline, &s)\n\t\thooks, err := queue.HookList(ctx, f, s)\n\t\tctl.xcheck(err, \"listing webhooks\")\n\t\tctl.xwriteok()\n\n\t\txw := ctl.writer()\n\t\tfmt.Fprintln(xw, \"webhooks:\")\n\t\tfor _, h := range hooks {\n\t\t\tvar lastAttempt string\n\t\t\tif len(h.Results) > 0 {\n\t\t\t\tlastAttempt = time.Since(h.LastResult().Start).Round(time.Second).String()\n\t\t\t}\n\t\t\tfmt.Fprintf(xw, \"%5d %s account:%s next %s last %s error %q url %s\\n\", h.ID, h.Submitted.Format(time.RFC3339), h.Account, time.Until(h.NextAttempt).Round(time.Second), lastAttempt, h.LastResult().Error, h.URL)\n\t\t}\n\t\tif len(hooks) == 0 {\n\t\t\tfmt.Fprint(xw, \"(none)\\n\")\n\t\t}\n\t\txw.xclose()\n\n\tcase \"queuehookschedule\":\n\t\t/* protocol:\n\t\t> \"queuehookschedule\"\n\t\t> hookfilters as json\n\t\t> relative to now\n\t\t> duration\n\t\t< \"ok\" or error\n\t\t< count\n\t\t*/\n\n\t\tfilterline := ctl.xread()\n\t\trelnow := ctl.xread()\n\t\tduration := ctl.xread()\n\t\tvar f queue.HookFilter\n\t\txparseJSON(ctl, filterline, &f)\n\t\td, err := time.ParseDuration(duration)\n\t\tctl.xcheck(err, \"parsing duration for next delivery attempt\")\n\t\tvar count int\n\t\tif relnow == \"\" {\n\t\t\tcount, err = queue.HookNextAttemptAdd(ctx, f, d)\n\t\t} else {\n\t\t\tcount, err = queue.HookNextAttemptSet(ctx, f, time.Now().Add(d))\n\t\t}\n\t\tctl.xcheck(err, \"setting next delivery attempts in queue\")\n\t\tctl.xwriteok()\n\t\tctl.xwrite(fmt.Sprintf(\"%d\", count))\n\n\tcase \"queuehookcancel\":\n\t\t/* protocol:\n\t\t> \"queuehookcancel\"\n\t\t> hookfilters as json\n\t\t< \"ok\" or error\n\t\t< count\n\t\t*/\n\n\t\tfilterline := ctl.xread()\n\t\tvar f queue.HookFilter\n\t\txparseJSON(ctl, filterline, &f)\n\t\tcount, err := queue.HookCancel(ctx, log, f)\n\t\tctl.xcheck(err, \"canceling webhooks in queue\")\n\t\tctl.xwriteok()\n\t\tctl.xwrite(fmt.Sprintf(\"%d\", count))\n\n\tcase \"queuehookprint\":\n\t\t/* protocol:\n\t\t> \"queuehookprint\"\n\t\t> id\n\t\t< \"ok\"\n\t\t< stream\n\t\t*/\n\t\tidstr := ctl.xread()\n\t\tid, err := strconv.ParseInt(idstr, 10, 64)\n\t\tif err != nil {\n\t\t\tctl.xcheck(err, \"parsing id\")\n\t\t}\n\t\tl, err := queue.HookList(ctx, queue.HookFilter{IDs: []int64{id}}, queue.HookSort{})\n\t\tctl.xcheck(err, \"getting webhooks\")\n\t\tif len(l) == 0 {\n\t\t\tctl.xcheck(errors.New(\"not found\"), \"getting webhook\")\n\t\t}\n\t\th := l[0]\n\t\tctl.xwriteok()\n\t\txw := ctl.writer()\n\t\tenc := json.NewEncoder(xw)\n\t\tenc.SetIndent(\"\", \"\\t\")\n\t\terr = enc.Encode(h)\n\t\tctl.xcheck(err, \"encode webhook\")\n\t\txw.xclose()\n\n\tcase \"queuehookretiredlist\":\n\t\t/* protocol:\n\t\t> \"queuehookretiredlist\"\n\t\t> filters as json\n\t\t> sort as json\n\t\t< \"ok\"\n\t\t< stream\n\t\t*/\n\t\tfilterline := ctl.xread()\n\t\tsortline := ctl.xread()\n\t\tvar f queue.HookRetiredFilter\n\t\txparseJSON(ctl, filterline, &f)\n\t\tvar s queue.HookRetiredSort\n\t\txparseJSON(ctl, sortline, &s)\n\t\tl, err := queue.HookRetiredList(ctx, f, s)\n\t\tctl.xcheck(err, \"listing retired webhooks\")\n\t\tctl.xwriteok()\n\n\t\txw := ctl.writer()\n\t\tfmt.Fprintln(xw, \"retired webhooks:\")\n\t\tfor _, h := range l {\n\t\t\tvar lastAttempt string\n\t\t\tif len(h.Results) > 0 {\n\t\t\t\tlastAttempt = time.Since(h.LastResult().Start).Round(time.Second).String()\n\t\t\t}\n\t\t\tresult := \"success\"\n\t\t\tif !h.Success {\n\t\t\t\tresult = \"failure\"\n\t\t\t}\n\t\t\tfmt.Fprintf(xw, \"%5d %s %s account:%s last %s error %q url %s\\n\", h.ID, h.Submitted.Format(time.RFC3339), result, h.Account, lastAttempt, h.LastResult().Error, h.URL)\n\t\t}\n\t\tif len(l) == 0 {\n\t\t\tfmt.Fprint(xw, \"(none)\\n\")\n\t\t}\n\t\txw.xclose()\n\n\tcase \"queuehookretiredprint\":\n\t\t/* protocol:\n\t\t> \"queuehookretiredprint\"\n\t\t> id\n\t\t< \"ok\"\n\t\t< stream\n\t\t*/\n\t\tidstr := ctl.xread()\n\t\tid, err := strconv.ParseInt(idstr, 10, 64)\n\t\tif err != nil {\n\t\t\tctl.xcheck(err, \"parsing id\")\n\t\t}\n\t\tl, err := queue.HookRetiredList(ctx, queue.HookRetiredFilter{IDs: []int64{id}}, queue.HookRetiredSort{})\n\t\tctl.xcheck(err, \"getting retired webhooks\")\n\t\tif len(l) == 0 {\n\t\t\tctl.xcheck(errors.New(\"not found\"), \"getting retired webhook\")\n\t\t}\n\t\th := l[0]\n\t\tctl.xwriteok()\n\t\txw := ctl.writer()\n\t\tenc := json.NewEncoder(xw)\n\t\tenc.SetIndent(\"\", \"\\t\")\n\t\terr = enc.Encode(h)\n\t\tctl.xcheck(err, \"encode retired webhook\")\n\t\txw.xclose()\n\n\tcase \"queuesuppresslist\":\n\t\t/* protocol:\n\t\t> \"queuesuppresslist\"\n\t\t> account (or empty)\n\t\t< \"ok\" or error\n\t\t< stream\n\t\t*/\n\n\t\taccount := ctl.xread()\n\t\tl, err := queue.SuppressionList(ctx, account)\n\t\tctl.xcheck(err, \"listing suppressions\")\n\t\tctl.xwriteok()\n\t\txw := ctl.writer()\n\t\tfmt.Fprintln(xw, \"suppressions (account, address, manual, time added, base adddress, reason):\")\n\t\tfor _, sup := range l {\n\t\t\tmanual := \"No\"\n\t\t\tif sup.Manual {\n\t\t\t\tmanual = \"Yes\"\n\t\t\t}\n\t\t\tfmt.Fprintf(xw, \"%q\\t%q\\t%s\\t%s\\t%q\\t%q\\n\", sup.Account, sup.OriginalAddress, manual, sup.Created.Round(time.Second), sup.BaseAddress, sup.Reason)\n\t\t}\n\t\tif len(l) == 0 {\n\t\t\tfmt.Fprintln(xw, \"(none)\")\n\t\t}\n\t\txw.xclose()\n\n\tcase \"queuesuppressadd\":\n\t\t/* protocol:\n\t\t> \"queuesuppressadd\"\n\t\t> account\n\t\t> address\n\t\t< \"ok\" or error\n\t\t*/\n\n\t\taccount := ctl.xread()\n\t\taddress := ctl.xread()\n\t\t_, ok := mox.Conf.Account(account)\n\t\tif !ok {\n\t\t\tctl.xcheck(errors.New(\"unknown account\"), \"looking up account\")\n\t\t}\n\t\taddr, err := smtp.ParseAddress(address)\n\t\tctl.xcheck(err, \"parsing address\")\n\t\tsup := webapi.Suppression{\n\t\t\tAccount: account,\n\t\t\tManual:  true,\n\t\t\tReason:  \"added through mox cli\",\n\t\t}\n\t\terr = queue.SuppressionAdd(ctx, addr.Path(), &sup)\n\t\tctl.xcheck(err, \"adding suppression\")\n\t\tctl.xwriteok()\n\n\tcase \"queuesuppressremove\":\n\t\t/* protocol:\n\t\t> \"queuesuppressremove\"\n\t\t> account\n\t\t> address\n\t\t< \"ok\" or error\n\t\t*/\n\n\t\taccount := ctl.xread()\n\t\taddress := ctl.xread()\n\t\taddr, err := smtp.ParseAddress(address)\n\t\tctl.xcheck(err, \"parsing address\")\n\t\terr = queue.SuppressionRemove(ctx, account, addr.Path())\n\t\tctl.xcheck(err, \"removing suppression\")\n\t\tctl.xwriteok()\n\n\tcase \"queuesuppresslookup\":\n\t\t/* protocol:\n\t\t> \"queuesuppresslookup\"\n\t\t> account or empty\n\t\t> address\n\t\t< \"ok\" or error\n\t\t< stream\n\t\t*/\n\n\t\taccount := ctl.xread()\n\t\taddress := ctl.xread()\n\t\tif account != \"\" {\n\t\t\t_, ok := mox.Conf.Account(account)\n\t\t\tif !ok {\n\t\t\t\tctl.xcheck(errors.New(\"unknown account\"), \"looking up account\")\n\t\t\t}\n\t\t}\n\t\taddr, err := smtp.ParseAddress(address)\n\t\tctl.xcheck(err, \"parsing address\")\n\t\tsup, err := queue.SuppressionLookup(ctx, account, addr.Path())\n\t\tctl.xcheck(err, \"looking up suppression\")\n\t\tctl.xwriteok()\n\t\txw := ctl.writer()\n\t\tif sup == nil {\n\t\t\tfmt.Fprintln(xw, \"not present\")\n\t\t} else {\n\t\t\tmanual := \"no\"\n\t\t\tif sup.Manual {\n\t\t\t\tmanual = \"yes\"\n\t\t\t}\n\t\t\tfmt.Fprintf(xw, \"present\\nadded: %s\\nmanual: %s\\nbase address: %s\\nreason: %q\\n\", sup.Created.Round(time.Second), manual, sup.BaseAddress, sup.Reason)\n\t\t}\n\t\txw.xclose()\n\n\tcase \"importmaildir\", \"importmbox\":\n\t\tmbox := cmd == \"importmbox\"\n\t\timportctl(ctx, ctl, mbox)\n\n\tcase \"domainadd\":\n\t\t/* protocol:\n\t\t> \"domainadd\"\n\t\t> domain\n\t\t> account\n\t\t> localpart\n\t\t< \"ok\" or error\n\t\t*/\n\t\tdomain := ctl.xread()\n\t\taccount := ctl.xread()\n\t\tlocalpart := ctl.xread()\n\t\td, err := dns.ParseDomain(domain)\n\t\tctl.xcheck(err, \"parsing domain\")\n\t\terr = admin.DomainAdd(ctx, d, account, smtp.Localpart(localpart))\n\t\tctl.xcheck(err, \"adding domain\")\n\t\tctl.xwriteok()\n\n\tcase \"domainrm\":\n\t\t/* protocol:\n\t\t> \"domainrm\"\n\t\t> domain\n\t\t< \"ok\" or error\n\t\t*/\n\t\tdomain := ctl.xread()\n\t\td, err := dns.ParseDomain(domain)\n\t\tctl.xcheck(err, \"parsing domain\")\n\t\terr = admin.DomainRemove(ctx, d)\n\t\tctl.xcheck(err, \"removing domain\")\n\t\tctl.xwriteok()\n\n\tcase \"accountadd\":\n\t\t/* protocol:\n\t\t> \"accountadd\"\n\t\t> account\n\t\t> address\n\t\t< \"ok\" or error\n\t\t*/\n\t\taccount := ctl.xread()\n\t\taddress := ctl.xread()\n\t\terr := admin.AccountAdd(ctx, account, address)\n\t\tctl.xcheck(err, \"adding account\")\n\t\tctl.xwriteok()\n\n\tcase \"accountrm\":\n\t\t/* protocol:\n\t\t> \"accountrm\"\n\t\t> account\n\t\t< \"ok\" or error\n\t\t*/\n\t\taccount := ctl.xread()\n\t\terr := admin.AccountRemove(ctx, account)\n\t\tctl.xcheck(err, \"removing account\")\n\t\tctl.xwriteok()\n\n\tcase \"tlspubkeylist\":\n\t\t/* protocol:\n\t\t> \"tlspubkeylist\"\n\t\t> account (or empty)\n\t\t< \"ok\" or error\n\t\t< stream\n\t\t*/\n\t\taccountOpt := ctl.xread()\n\t\ttlspubkeys, err := store.TLSPublicKeyList(ctx, accountOpt)\n\t\tctl.xcheck(err, \"list tls public keys\")\n\t\tctl.xwriteok()\n\t\txw := ctl.writer()\n\t\tfmt.Fprintf(xw, \"# fingerprint, type, name, account, login address, no imap preauth (%d)\\n\", len(tlspubkeys))\n\t\tfor _, k := range tlspubkeys {\n\t\t\tfmt.Fprintf(xw, \"%s\\t%s\\t%q\\t%s\\t%s\\t%v\\n\", k.Fingerprint, k.Type, k.Name, k.Account, k.LoginAddress, k.NoIMAPPreauth)\n\t\t}\n\t\txw.xclose()\n\n\tcase \"tlspubkeyget\":\n\t\t/* protocol:\n\t\t> \"tlspubkeyget\"\n\t\t> fingerprint\n\t\t< \"ok\" or error\n\t\t< type\n\t\t< name\n\t\t< account\n\t\t< address\n\t\t< noimappreauth (true/false)\n\t\t< stream (certder)\n\t\t*/\n\t\tfp := ctl.xread()\n\t\ttlspubkey, err := store.TLSPublicKeyGet(ctx, fp)\n\t\tctl.xcheck(err, \"looking tls public key\")\n\t\tctl.xwriteok()\n\t\tctl.xwrite(tlspubkey.Type)\n\t\tctl.xwrite(tlspubkey.Name)\n\t\tctl.xwrite(tlspubkey.Account)\n\t\tctl.xwrite(tlspubkey.LoginAddress)\n\t\tctl.xwrite(fmt.Sprintf(\"%v\", tlspubkey.NoIMAPPreauth))\n\t\tctl.xstreamfrom(bytes.NewReader(tlspubkey.CertDER))\n\n\tcase \"tlspubkeyadd\":\n\t\t/* protocol:\n\t\t> \"tlspubkeyadd\"\n\t\t> loginaddress\n\t\t> name (or empty)\n\t\t> noimappreauth (true/false)\n\t\t> stream (certder)\n\t\t< \"ok\" or error\n\t\t*/\n\t\tloginAddress := ctl.xread()\n\t\tname := ctl.xread()\n\t\tnoimappreauth := ctl.xread()\n\t\tif noimappreauth != \"true\" && noimappreauth != \"false\" {\n\t\t\tctl.xcheck(fmt.Errorf(\"bad value %q\", noimappreauth), \"parsing noimappreauth\")\n\t\t}\n\t\tvar b bytes.Buffer\n\t\tctl.xstreamto(&b)\n\t\ttlspubkey, err := store.ParseTLSPublicKeyCert(b.Bytes())\n\t\tctl.xcheck(err, \"parsing certificate\")\n\t\tif name != \"\" {\n\t\t\ttlspubkey.Name = name\n\t\t}\n\t\tacc, _, err := store.OpenEmail(ctl.log, loginAddress)\n\t\tctl.xcheck(err, \"open account for address\")\n\t\tdefer func() {\n\t\t\terr := acc.Close()\n\t\t\tctl.log.Check(err, \"close account\")\n\t\t}()\n\t\ttlspubkey.Account = acc.Name\n\t\ttlspubkey.LoginAddress = loginAddress\n\t\ttlspubkey.NoIMAPPreauth = noimappreauth == \"true\"\n\n\t\terr = store.TLSPublicKeyAdd(ctx, &tlspubkey)\n\t\tctl.xcheck(err, \"adding tls public key\")\n\t\tctl.xwriteok()\n\n\tcase \"tlspubkeyrm\":\n\t\t/* protocol:\n\t\t> \"tlspubkeyadd\"\n\t\t> fingerprint\n\t\t< \"ok\" or error\n\t\t*/\n\t\tfp := ctl.xread()\n\t\terr := store.TLSPublicKeyRemove(ctx, fp)\n\t\tctl.xcheck(err, \"removing tls public key\")\n\t\tctl.xwriteok()\n\n\tcase \"addressadd\":\n\t\t/* protocol:\n\t\t> \"addressadd\"\n\t\t> address\n\t\t> account\n\t\t< \"ok\" or error\n\t\t*/\n\t\taddress := ctl.xread()\n\t\taccount := ctl.xread()\n\t\terr := admin.AddressAdd(ctx, address, account)\n\t\tctl.xcheck(err, \"adding address\")\n\t\tctl.xwriteok()\n\n\tcase \"addressrm\":\n\t\t/* protocol:\n\t\t> \"addressrm\"\n\t\t> address\n\t\t< \"ok\" or error\n\t\t*/\n\t\taddress := ctl.xread()\n\t\terr := admin.AddressRemove(ctx, address)\n\t\tctl.xcheck(err, \"removing address\")\n\t\tctl.xwriteok()\n\n\tcase \"aliaslist\":\n\t\t/* protocol:\n\t\t> \"aliaslist\"\n\t\t> domain\n\t\t< \"ok\" or error\n\t\t< stream\n\t\t*/\n\t\tdomain := ctl.xread()\n\t\td, err := dns.ParseDomain(domain)\n\t\tctl.xcheck(err, \"parsing domain\")\n\t\tdc, ok := mox.Conf.Domain(d)\n\t\tif !ok {\n\t\t\tctl.xcheck(errors.New(\"no such domain\"), \"listing aliases\")\n\t\t}\n\t\tctl.xwriteok()\n\t\tw := ctl.writer()\n\t\tfor _, a := range dc.Aliases {\n\t\t\tlp, err := smtp.ParseLocalpart(a.LocalpartStr)\n\t\t\tctl.xcheck(err, \"parsing alias localpart\")\n\t\t\tfmt.Fprintln(w, smtp.NewAddress(lp, a.Domain).Pack(true))\n\t\t}\n\t\tw.xclose()\n\n\tcase \"aliasprint\":\n\t\t/* protocol:\n\t\t> \"aliasprint\"\n\t\t> address\n\t\t< \"ok\" or error\n\t\t< stream\n\t\t*/\n\t\taddress := ctl.xread()\n\t\t_, alias, ok := mox.Conf.AccountDestination(address)\n\t\tif !ok {\n\t\t\tctl.xcheck(errors.New(\"no such address\"), \"looking up alias\")\n\t\t} else if alias == nil {\n\t\t\tctl.xcheck(errors.New(\"address not an alias\"), \"looking up alias\")\n\t\t}\n\t\tctl.xwriteok()\n\t\tw := ctl.writer()\n\t\tfmt.Fprintf(w, \"# postpublic %v\\n\", alias.PostPublic)\n\t\tfmt.Fprintf(w, \"# listmembers %v\\n\", alias.ListMembers)\n\t\tfmt.Fprintf(w, \"# allowmsgfrom %v\\n\", alias.AllowMsgFrom)\n\t\tfmt.Fprintln(w, \"# members:\")\n\t\tfor _, a := range alias.Addresses {\n\t\t\tfmt.Fprintln(w, a)\n\t\t}\n\t\tw.xclose()\n\n\tcase \"aliasadd\":\n\t\t/* protocol:\n\t\t> \"aliasadd\"\n\t\t> address\n\t\t> json alias\n\t\t< \"ok\" or error\n\t\t*/\n\t\taddress := ctl.xread()\n\t\tline := ctl.xread()\n\t\taddr, err := smtp.ParseAddress(address)\n\t\tctl.xcheck(err, \"parsing address\")\n\t\tvar alias config.Alias\n\t\txparseJSON(ctl, line, &alias)\n\t\terr = admin.AliasAdd(ctx, addr, alias)\n\t\tctl.xcheck(err, \"adding alias\")\n\t\tctl.xwriteok()\n\n\tcase \"aliasupdate\":\n\t\t/* protocol:\n\t\t> \"aliasupdate\"\n\t\t> alias\n\t\t> \"true\" or \"false\" for postpublic\n\t\t> \"true\" or \"false\" for listmembers\n\t\t> \"true\" or \"false\" for allowmsgfrom\n\t\t< \"ok\" or error\n\t\t*/\n\t\taddress := ctl.xread()\n\t\tpostpublic := ctl.xread()\n\t\tlistmembers := ctl.xread()\n\t\tallowmsgfrom := ctl.xread()\n\t\taddr, err := smtp.ParseAddress(address)\n\t\tctl.xcheck(err, \"parsing address\")\n\t\terr = admin.DomainSave(ctx, addr.Domain.Name(), func(d *config.Domain) error {\n\t\t\ta, ok := d.Aliases[addr.Localpart.String()]\n\t\t\tif !ok {\n\t\t\t\treturn fmt.Errorf(\"alias does not exist\")\n\t\t\t}\n\n\t\t\tswitch postpublic {\n\t\t\tcase \"false\":\n\t\t\t\ta.PostPublic = false\n\t\t\tcase \"true\":\n\t\t\t\ta.PostPublic = true\n\t\t\t}\n\t\t\tswitch listmembers {\n\t\t\tcase \"false\":\n\t\t\t\ta.ListMembers = false\n\t\t\tcase \"true\":\n\t\t\t\ta.ListMembers = true\n\t\t\t}\n\t\t\tswitch allowmsgfrom {\n\t\t\tcase \"false\":\n\t\t\t\ta.AllowMsgFrom = false\n\t\t\tcase \"true\":\n\t\t\t\ta.AllowMsgFrom = true\n\t\t\t}\n\n\t\t\td.Aliases = maps.Clone(d.Aliases)\n\t\t\td.Aliases[addr.Localpart.String()] = a\n\t\t\treturn nil\n\t\t})\n\t\tctl.xcheck(err, \"saving alias\")\n\t\tctl.xwriteok()\n\n\tcase \"aliasrm\":\n\t\t/* protocol:\n\t\t> \"aliasrm\"\n\t\t> alias\n\t\t< \"ok\" or error\n\t\t*/\n\t\taddress := ctl.xread()\n\t\taddr, err := smtp.ParseAddress(address)\n\t\tctl.xcheck(err, \"parsing address\")\n\t\terr = admin.AliasRemove(ctx, addr)\n\t\tctl.xcheck(err, \"removing alias\")\n\t\tctl.xwriteok()\n\n\tcase \"aliasaddaddr\":\n\t\t/* protocol:\n\t\t> \"aliasaddaddr\"\n\t\t> alias\n\t\t> addresses as json\n\t\t< \"ok\" or error\n\t\t*/\n\t\taddress := ctl.xread()\n\t\tline := ctl.xread()\n\t\taddr, err := smtp.ParseAddress(address)\n\t\tctl.xcheck(err, \"parsing address\")\n\t\tvar addresses []string\n\t\txparseJSON(ctl, line, &addresses)\n\t\terr = admin.AliasAddressesAdd(ctx, addr, addresses)\n\t\tctl.xcheck(err, \"adding addresses to alias\")\n\t\tctl.xwriteok()\n\n\tcase \"aliasrmaddr\":\n\t\t/* protocol:\n\t\t> \"aliasrmaddr\"\n\t\t> alias\n\t\t> addresses as json\n\t\t< \"ok\" or error\n\t\t*/\n\t\taddress := ctl.xread()\n\t\tline := ctl.xread()\n\t\taddr, err := smtp.ParseAddress(address)\n\t\tctl.xcheck(err, \"parsing address\")\n\t\tvar addresses []string\n\t\txparseJSON(ctl, line, &addresses)\n\t\terr = admin.AliasAddressesRemove(ctx, addr, addresses)\n\t\tctl.xcheck(err, \"removing addresses to alias\")\n\t\tctl.xwriteok()\n\n\tcase \"loglevels\":\n\t\t/* protocol:\n\t\t> \"loglevels\"\n\t\t< \"ok\"\n\t\t< stream\n\t\t*/\n\t\tctl.xwriteok()\n\t\tl := mox.Conf.LogLevels()\n\t\tkeys := []string{}\n\t\tfor k := range l {\n\t\t\tkeys = append(keys, k)\n\t\t}\n\t\tsort.Slice(keys, func(i, j int) bool {\n\t\t\treturn keys[i] < keys[j]\n\t\t})\n\t\ts := \"\"\n\t\tfor _, k := range keys {\n\t\t\tks := k\n\t\t\tif ks == \"\" {\n\t\t\t\tks = \"(default)\"\n\t\t\t}\n\t\t\ts += ks + \": \" + mlog.LevelStrings[l[k]] + \"\\n\"\n\t\t}\n\t\tctl.xstreamfrom(strings.NewReader(s))\n\n\tcase \"setloglevels\":\n\t\t/* protocol:\n\t\t> \"setloglevels\"\n\t\t> pkg\n\t\t> level (if empty, log level for pkg will be unset)\n\t\t< \"ok\" or error\n\t\t*/\n\t\tpkg := ctl.xread()\n\t\tlevelstr := ctl.xread()\n\t\tif levelstr == \"\" {\n\t\t\tmox.Conf.LogLevelRemove(log, pkg)\n\t\t} else {\n\t\t\tlevel, ok := mlog.Levels[levelstr]\n\t\t\tif !ok {\n\t\t\t\tctl.xerror(\"bad level\")\n\t\t\t}\n\t\t\tmox.Conf.LogLevelSet(log, pkg, level)\n\t\t}\n\t\tctl.xwriteok()\n\n\tcase \"retrain\":\n\t\t/* protocol:\n\t\t> \"retrain\"\n\t\t> account or empty\n\t\t< \"ok\" or error\n\t\t*/\n\t\taccount := ctl.xread()\n\n\t\txretrain := func(name string) {\n\t\t\tacc, err := store.OpenAccount(log, name)\n\t\t\tctl.xcheck(err, \"open account\")\n\t\t\tdefer func() {\n\t\t\t\tif acc != nil {\n\t\t\t\t\terr := acc.Close()\n\t\t\t\t\tlog.Check(err, \"closing account after retraining\")\n\t\t\t\t}\n\t\t\t}()\n\n\t\t\t// todo: can we retrain an account without holding a write lock? perhaps by writing a junkfilter to a new location, and staying informed of message changes while we go through all messages in the account?\n\n\t\t\tacc.WithWLock(func() {\n\t\t\t\tconf, _ := acc.Conf()\n\t\t\t\tif conf.JunkFilter == nil {\n\t\t\t\t\tctl.xcheck(store.ErrNoJunkFilter, \"looking for junk filter\")\n\t\t\t\t}\n\n\t\t\t\t// Remove existing junk filter files.\n\t\t\t\tbasePath := mox.DataDirPath(\"accounts\")\n\t\t\t\tdbPath := filepath.Join(basePath, acc.Name, \"junkfilter.db\")\n\t\t\t\tbloomPath := filepath.Join(basePath, acc.Name, \"junkfilter.bloom\")\n\t\t\t\terr := os.Remove(dbPath)\n\t\t\t\tlog.Check(err, \"removing old junkfilter database file\", slog.String(\"path\", dbPath))\n\t\t\t\terr = os.Remove(bloomPath)\n\t\t\t\tlog.Check(err, \"removing old junkfilter bloom filter file\", slog.String(\"path\", bloomPath))\n\n\t\t\t\t// Open junk filter, this creates new files.\n\t\t\t\tjf, _, err := acc.OpenJunkFilter(ctx, log)\n\t\t\t\tctl.xcheck(err, \"open new junk filter\")\n\t\t\t\tdefer func() {\n\t\t\t\t\tif jf == nil {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\terr := jf.Close()\n\t\t\t\t\tlog.Check(err, \"closing junk filter during cleanup\")\n\t\t\t\t}()\n\n\t\t\t\t// Read through messages with junk or nonjunk flag set, and train them.\n\t\t\t\tvar total, trained int\n\t\t\t\tq := bstore.QueryDB[store.Message](ctx, acc.DB)\n\t\t\t\tq.FilterEqual(\"Expunged\", false)\n\t\t\t\terr = q.ForEach(func(m store.Message) error {\n\t\t\t\t\ttotal++\n\t\t\t\t\tok, err := acc.TrainMessage(ctx, log, jf, m)\n\t\t\t\t\tif ok {\n\t\t\t\t\t\ttrained++\n\t\t\t\t\t}\n\t\t\t\t\treturn err\n\t\t\t\t})\n\t\t\t\tctl.xcheck(err, \"training messages\")\n\t\t\t\tlog.Info(\"retrained messages\", slog.Int(\"total\", total), slog.Int(\"trained\", trained))\n\n\t\t\t\t// Close junk filter, marking success.\n\t\t\t\terr = jf.Close()\n\t\t\t\tjf = nil\n\t\t\t\tctl.xcheck(err, \"closing junk filter\")\n\t\t\t})\n\t\t}\n\n\t\tif account == \"\" {\n\t\t\tfor _, name := range mox.Conf.Accounts() {\n\t\t\t\txretrain(name)\n\t\t\t}\n\t\t} else {\n\t\t\txretrain(account)\n\t\t}\n\t\tctl.xwriteok()\n\n\tcase \"recalculatemailboxcounts\":\n\t\t/* protocol:\n\t\t> \"recalculatemailboxcounts\"\n\t\t> account\n\t\t< \"ok\" or error\n\t\t< stream\n\t\t*/\n\t\taccount := ctl.xread()\n\t\tacc, err := store.OpenAccount(log, account)\n\t\tctl.xcheck(err, \"open account\")\n\t\tdefer func() {\n\t\t\tif acc != nil {\n\t\t\t\terr := acc.Close()\n\t\t\t\tlog.Check(err, \"closing account after recalculating mailbox counts\")\n\t\t\t}\n\t\t}()\n\t\tctl.xwriteok()\n\n\t\tw := ctl.writer()\n\n\t\tacc.WithWLock(func() {\n\t\t\tvar changes []store.Change\n\t\t\terr = acc.DB.Write(ctx, func(tx *bstore.Tx) error {\n\t\t\t\tvar totalSize int64\n\t\t\t\terr := bstore.QueryTx[store.Mailbox](tx).ForEach(func(mb store.Mailbox) error {\n\t\t\t\t\tmc, err := mb.CalculateCounts(tx)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn fmt.Errorf(\"calculating counts for mailbox %q: %w\", mb.Name, err)\n\t\t\t\t\t}\n\t\t\t\t\ttotalSize += mc.Size\n\n\t\t\t\t\tif !mb.HaveCounts || mc != mb.MailboxCounts {\n\t\t\t\t\t\t_, err := fmt.Fprintf(w, \"for %s setting new counts %s (was %s)\\n\", mb.Name, mc, mb.MailboxCounts)\n\t\t\t\t\t\tctl.xcheck(err, \"write\")\n\t\t\t\t\t\tmb.HaveCounts = true\n\t\t\t\t\t\tmb.MailboxCounts = mc\n\t\t\t\t\t\tif err := tx.Update(&mb); err != nil {\n\t\t\t\t\t\t\treturn fmt.Errorf(\"storing new counts for %q: %v\", mb.Name, err)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tchanges = append(changes, mb.ChangeCounts())\n\t\t\t\t\t}\n\t\t\t\t\treturn nil\n\t\t\t\t})\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\n\t\t\t\tdu := store.DiskUsage{ID: 1}\n\t\t\t\tif err := tx.Get(&du); err != nil {\n\t\t\t\t\treturn fmt.Errorf(\"get disk usage: %v\", err)\n\t\t\t\t}\n\t\t\t\tif du.MessageSize != totalSize {\n\t\t\t\t\t_, err := fmt.Fprintf(w, \"setting new total message size %d (was %d)\\n\", totalSize, du.MessageSize)\n\t\t\t\t\tctl.xcheck(err, \"write\")\n\t\t\t\t\tdu.MessageSize = totalSize\n\t\t\t\t\tif err := tx.Update(&du); err != nil {\n\t\t\t\t\t\treturn fmt.Errorf(\"update disk usage: %v\", err)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn nil\n\t\t\t})\n\t\t\tctl.xcheck(err, \"write transaction for mailbox counts\")\n\n\t\t\tstore.BroadcastChanges(acc, changes)\n\t\t})\n\t\tw.xclose()\n\n\tcase \"fixmsgsize\":\n\t\t/* protocol:\n\t\t> \"fixmsgsize\"\n\t\t> account or empty\n\t\t< \"ok\" or error\n\t\t< stream\n\t\t*/\n\n\t\taccountOpt := ctl.xread()\n\t\tctl.xwriteok()\n\t\tw := ctl.writer()\n\n\t\tvar foundProblem bool\n\t\tconst batchSize = 10000\n\n\t\txfixmsgsize := func(accName string) {\n\t\t\tacc, err := store.OpenAccount(log, accName)\n\t\t\tctl.xcheck(err, \"open account\")\n\t\t\tdefer func() {\n\t\t\t\terr := acc.Close()\n\t\t\t\tlog.Check(err, \"closing account after fixing message sizes\")\n\t\t\t}()\n\n\t\t\ttotal := 0\n\t\t\tvar lastID int64\n\t\t\tfor {\n\t\t\t\tvar n int\n\n\t\t\t\tacc.WithRLock(func() {\n\t\t\t\t\tmailboxCounts := map[int64]store.Mailbox{} // For broadcasting.\n\n\t\t\t\t\t// Don't process all message in one transaction, we could block the account for too long.\n\t\t\t\t\terr := acc.DB.Write(ctx, func(tx *bstore.Tx) error {\n\t\t\t\t\t\tq := bstore.QueryTx[store.Message](tx)\n\t\t\t\t\t\tq.FilterEqual(\"Expunged\", false)\n\t\t\t\t\t\tq.FilterGreater(\"ID\", lastID)\n\t\t\t\t\t\tq.Limit(batchSize)\n\t\t\t\t\t\tq.SortAsc(\"ID\")\n\t\t\t\t\t\treturn q.ForEach(func(m store.Message) error {\n\t\t\t\t\t\t\tlastID = m.ID\n\t\t\t\t\t\t\tn++\n\n\t\t\t\t\t\t\tp := acc.MessagePath(m.ID)\n\t\t\t\t\t\t\tst, err := os.Stat(p)\n\t\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t\tmb := store.Mailbox{ID: m.MailboxID}\n\t\t\t\t\t\t\t\tif xerr := tx.Get(&mb); xerr != nil {\n\t\t\t\t\t\t\t\t\t_, werr := fmt.Fprintf(w, \"get mailbox id %d for message with file error: %v\\n\", mb.ID, xerr)\n\t\t\t\t\t\t\t\t\tctl.xcheck(werr, \"write\")\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t_, werr := fmt.Fprintf(w, \"checking file %s for message %d in mailbox %q (id %d): %v (continuing)\\n\", p, m.ID, mb.Name, mb.ID, err)\n\t\t\t\t\t\t\t\tctl.xcheck(werr, \"write\")\n\t\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tfilesize := st.Size()\n\t\t\t\t\t\t\tcorrectSize := int64(len(m.MsgPrefix)) + filesize\n\t\t\t\t\t\t\tif m.Size == correctSize {\n\t\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tfoundProblem = true\n\n\t\t\t\t\t\t\tmb := store.Mailbox{ID: m.MailboxID}\n\t\t\t\t\t\t\tif err := tx.Get(&mb); err != nil {\n\t\t\t\t\t\t\t\t_, werr := fmt.Fprintf(w, \"get mailbox id %d for message with file size mismatch: %v\\n\", mb.ID, err)\n\t\t\t\t\t\t\t\tctl.xcheck(werr, \"write\")\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t_, err = fmt.Fprintf(w, \"fixing message %d in mailbox %q (id %d) with incorrect size %d, should be %d (len msg prefix %d + on-disk file %s size %d)\\n\", m.ID, mb.Name, mb.ID, m.Size, correctSize, len(m.MsgPrefix), p, filesize)\n\t\t\t\t\t\t\tctl.xcheck(err, \"write\")\n\n\t\t\t\t\t\t\t// We assume that the original message size was accounted as stored in the mailbox\n\t\t\t\t\t\t\t// total size. If this isn't correct, the user can always run\n\t\t\t\t\t\t\t// recalculatemailboxcounts.\n\t\t\t\t\t\t\tmb.Size -= m.Size\n\t\t\t\t\t\t\tmb.Size += correctSize\n\t\t\t\t\t\t\tif err := tx.Update(&mb); err != nil {\n\t\t\t\t\t\t\t\treturn fmt.Errorf(\"update mailbox counts: %v\", err)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tmailboxCounts[mb.ID] = mb\n\n\t\t\t\t\t\t\tm.Size = correctSize\n\n\t\t\t\t\t\t\tmr := acc.MessageReader(m)\n\t\t\t\t\t\t\tpart, err := message.EnsurePart(log.Logger, false, mr, m.Size)\n\t\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t\t_, werr := fmt.Fprintf(w, \"parsing message %d again: %v (continuing)\\n\", m.ID, err)\n\t\t\t\t\t\t\t\tctl.xcheck(werr, \"write\")\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tm.ParsedBuf, err = json.Marshal(part)\n\t\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t\treturn fmt.Errorf(\"marshal parsed message: %v\", err)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\ttotal++\n\t\t\t\t\t\t\tif err := tx.Update(&m); err != nil {\n\t\t\t\t\t\t\t\treturn fmt.Errorf(\"update message: %v\", err)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t})\n\n\t\t\t\t\t})\n\t\t\t\t\tctl.xcheck(err, \"find and fix wrong message sizes\")\n\n\t\t\t\t\tvar changes []store.Change\n\t\t\t\t\tfor _, mb := range mailboxCounts {\n\t\t\t\t\t\tchanges = append(changes, mb.ChangeCounts())\n\t\t\t\t\t}\n\t\t\t\t\tstore.BroadcastChanges(acc, changes)\n\t\t\t\t})\n\t\t\t\tif n < batchSize {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\t_, err = fmt.Fprintf(w, \"%d message size(s) fixed for account %s\\n\", total, accName)\n\t\t\tctl.xcheck(err, \"write\")\n\t\t}\n\n\t\tif accountOpt != \"\" {\n\t\t\txfixmsgsize(accountOpt)\n\t\t} else {\n\t\t\tfor i, accName := range mox.Conf.Accounts() {\n\t\t\t\tvar line string\n\t\t\t\tif i > 0 {\n\t\t\t\t\tline = \"\\n\"\n\t\t\t\t}\n\t\t\t\t_, err := fmt.Fprintf(w, \"%sFixing message sizes in account %s...\\n\", line, accName)\n\t\t\t\tctl.xcheck(err, \"write\")\n\t\t\t\txfixmsgsize(accName)\n\t\t\t}\n\t\t}\n\t\tif foundProblem {\n\t\t\t_, err := fmt.Fprintf(w, \"\\nProblems were found and fixed. You should invalidate messages stored at imap clients with the \\\"mox bumpuidvalidity account [mailbox]\\\" command.\\n\")\n\t\t\tctl.xcheck(err, \"write\")\n\t\t}\n\n\t\tw.xclose()\n\n\tcase \"reparse\":\n\t\t/* protocol:\n\t\t> \"reparse\"\n\t\t> account or empty\n\t\t< \"ok\" or error\n\t\t< stream\n\t\t*/\n\n\t\taccountOpt := ctl.xread()\n\t\tctl.xwriteok()\n\t\tw := ctl.writer()\n\n\t\tconst batchSize = 100\n\n\t\txreparseAccount := func(accName string) {\n\t\t\tacc, err := store.OpenAccount(log, accName)\n\t\t\tctl.xcheck(err, \"open account\")\n\t\t\tdefer func() {\n\t\t\t\terr := acc.Close()\n\t\t\t\tlog.Check(err, \"closing account after reparsing messages\")\n\t\t\t}()\n\n\t\t\ttotal := 0\n\t\t\tvar lastID int64\n\t\t\tfor {\n\t\t\t\tvar n int\n\t\t\t\t// Don't process all message in one transaction, we could block the account for too long.\n\t\t\t\terr := acc.DB.Write(ctx, func(tx *bstore.Tx) error {\n\t\t\t\t\tq := bstore.QueryTx[store.Message](tx)\n\t\t\t\t\tq.FilterEqual(\"Expunged\", false)\n\t\t\t\t\tq.FilterGreater(\"ID\", lastID)\n\t\t\t\t\tq.Limit(batchSize)\n\t\t\t\t\tq.SortAsc(\"ID\")\n\t\t\t\t\treturn q.ForEach(func(m store.Message) error {\n\t\t\t\t\t\tlastID = m.ID\n\t\t\t\t\t\tmr := acc.MessageReader(m)\n\t\t\t\t\t\tp, err := message.EnsurePart(log.Logger, false, mr, m.Size)\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t_, err := fmt.Fprintf(w, \"parsing message %d: %v (continuing)\\n\", m.ID, err)\n\t\t\t\t\t\t\tctl.xcheck(err, \"write\")\n\t\t\t\t\t\t}\n\t\t\t\t\t\tm.ParsedBuf, err = json.Marshal(p)\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\treturn fmt.Errorf(\"marshal parsed message: %v\", err)\n\t\t\t\t\t\t}\n\t\t\t\t\t\ttotal++\n\t\t\t\t\t\tn++\n\t\t\t\t\t\tif err := tx.Update(&m); err != nil {\n\t\t\t\t\t\t\treturn fmt.Errorf(\"update message: %v\", err)\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn nil\n\t\t\t\t\t})\n\n\t\t\t\t})\n\t\t\t\tctl.xcheck(err, \"update messages with parsed mime structure\")\n\t\t\t\tif n < batchSize {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\t_, err = fmt.Fprintf(w, \"%d message(s) reparsed for account %s\\n\", total, accName)\n\t\t\tctl.xcheck(err, \"write\")\n\t\t}\n\n\t\tif accountOpt != \"\" {\n\t\t\txreparseAccount(accountOpt)\n\t\t} else {\n\t\t\tfor i, accName := range mox.Conf.Accounts() {\n\t\t\t\tvar line string\n\t\t\t\tif i > 0 {\n\t\t\t\t\tline = \"\\n\"\n\t\t\t\t}\n\t\t\t\t_, err := fmt.Fprintf(w, \"%sReparsing account %s...\\n\", line, accName)\n\t\t\t\tctl.xcheck(err, \"write\")\n\t\t\t\txreparseAccount(accName)\n\t\t\t}\n\t\t}\n\t\tw.xclose()\n\n\tcase \"reassignthreads\":\n\t\t/* protocol:\n\t\t> \"reassignthreads\"\n\t\t> account or empty\n\t\t< \"ok\" or error\n\t\t< stream\n\t\t*/\n\n\t\taccountOpt := ctl.xread()\n\t\tctl.xwriteok()\n\t\tw := ctl.writer()\n\n\t\txreassignThreads := func(accName string) {\n\t\t\tacc, err := store.OpenAccount(log, accName)\n\t\t\tctl.xcheck(err, \"open account\")\n\t\t\tdefer func() {\n\t\t\t\terr := acc.Close()\n\t\t\t\tlog.Check(err, \"closing account after reassigning threads\")\n\t\t\t}()\n\n\t\t\t// We don't want to step on an existing upgrade process.\n\t\t\terr = acc.ThreadingWait(log)\n\t\t\tctl.xcheck(err, \"waiting for threading upgrade to finish\")\n\t\t\t// todo: should we try to continue if the threading upgrade failed? only if there is a chance it will succeed this time...\n\n\t\t\t// todo: reassigning isn't atomic (in a single transaction), ideally it would be (bstore would need to be able to handle large updates).\n\t\t\tconst batchSize = 50000\n\t\t\ttotal, err := acc.ResetThreading(ctx, log, batchSize, true)\n\t\t\tctl.xcheck(err, \"resetting threading fields\")\n\t\t\t_, err = fmt.Fprintf(w, \"New thread base subject assigned to %d message(s), starting to reassign threads...\\n\", total)\n\t\t\tctl.xcheck(err, \"write\")\n\n\t\t\t// Assign threads again. Ideally we would do this in a single transaction, but\n\t\t\t// bstore/boltdb cannot handle so many pending changes, so we set a high batchsize.\n\t\t\terr = acc.AssignThreads(ctx, log, nil, 0, 50000, w)\n\t\t\tctl.xcheck(err, \"reassign threads\")\n\n\t\t\t_, err = fmt.Fprintf(w, \"Threads reassigned. You should invalidate messages stored at imap clients with the \\\"mox bumpuidvalidity account [mailbox]\\\" command.\\n\")\n\t\t\tctl.xcheck(err, \"write\")\n\t\t}\n\n\t\tif accountOpt != \"\" {\n\t\t\txreassignThreads(accountOpt)\n\t\t} else {\n\t\t\tfor i, accName := range mox.Conf.Accounts() {\n\t\t\t\tvar line string\n\t\t\t\tif i > 0 {\n\t\t\t\t\tline = \"\\n\"\n\t\t\t\t}\n\t\t\t\t_, err := fmt.Fprintf(w, \"%sReassigning threads for account %s...\\n\", line, accName)\n\t\t\t\tctl.xcheck(err, \"write\")\n\t\t\t\txreassignThreads(accName)\n\t\t\t}\n\t\t}\n\t\tw.xclose()\n\n\tcase \"backup\":\n\t\tbackupctl(ctx, ctl)\n\n\tdefault:\n\t\tlog.Info(\"unrecognized command\", slog.String(\"cmd\", cmd))\n\t\tctl.xwrite(\"unrecognized command\")\n\t\treturn\n\t}\n}\n"
        },
        {
          "name": "ctl_test.go",
          "type": "blob",
          "size": 12.2900390625,
          "content": "//go:build !integration\n\npackage main\n\nimport (\n\t\"context\"\n\t\"crypto/ed25519\"\n\tcryptorand \"crypto/rand\"\n\t\"crypto/x509\"\n\t\"flag\"\n\t\"fmt\"\n\t\"math/big\"\n\t\"net\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/mjl-/mox/config\"\n\t\"github.com/mjl-/mox/dmarcdb\"\n\t\"github.com/mjl-/mox/dns\"\n\t\"github.com/mjl-/mox/mlog\"\n\t\"github.com/mjl-/mox/mox-\"\n\t\"github.com/mjl-/mox/mtastsdb\"\n\t\"github.com/mjl-/mox/queue\"\n\t\"github.com/mjl-/mox/smtp\"\n\t\"github.com/mjl-/mox/store\"\n\t\"github.com/mjl-/mox/tlsrptdb\"\n)\n\nvar ctxbg = context.Background()\nvar pkglog = mlog.New(\"ctl\", nil)\n\nfunc tcheck(t *testing.T, err error, errmsg string) {\n\tif err != nil {\n\t\tt.Helper()\n\t\tt.Fatalf(\"%s: %v\", errmsg, err)\n\t}\n}\n\n// TestCtl executes commands through ctl. This tests at least the protocols (who\n// sends when/what) is tested. We often don't check the actual results, but\n// unhandled errors would cause a panic.\nfunc TestCtl(t *testing.T) {\n\tos.RemoveAll(\"testdata/ctl/data\")\n\tmox.ConfigStaticPath = filepath.FromSlash(\"testdata/ctl/mox.conf\")\n\tmox.ConfigDynamicPath = filepath.FromSlash(\"testdata/ctl/domains.conf\")\n\tif errs := mox.LoadConfig(ctxbg, pkglog, true, false); len(errs) > 0 {\n\t\tt.Fatalf(\"loading mox config: %v\", errs)\n\t}\n\tdefer store.Switchboard()()\n\n\terr := queue.Init()\n\ttcheck(t, err, \"queue init\")\n\tdefer queue.Shutdown()\n\n\terr = store.Init(ctxbg)\n\ttcheck(t, err, \"store init\")\n\tdefer store.Close()\n\n\ttestctl := func(fn func(clientctl *ctl)) {\n\t\tt.Helper()\n\n\t\tcconn, sconn := net.Pipe()\n\t\tclientctl := ctl{conn: cconn, log: pkglog}\n\t\tserverctl := ctl{conn: sconn, log: pkglog}\n\t\tdone := make(chan struct{})\n\t\tgo func() {\n\t\t\tservectlcmd(ctxbg, &serverctl, func() {})\n\t\t\tclose(done)\n\t\t}()\n\t\tfn(&clientctl)\n\t\tcconn.Close()\n\t\t<-done\n\t\tsconn.Close()\n\t}\n\n\t// \"deliver\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdDeliver(ctl, \"mjl@mox.example\")\n\t})\n\n\t// \"setaccountpassword\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdSetaccountpassword(ctl, \"mjl\", \"test4321\")\n\t})\n\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueHoldrulesList(ctl)\n\t})\n\n\t// All messages.\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueHoldrulesAdd(ctl, \"\", \"\", \"\")\n\t})\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueHoldrulesAdd(ctl, \"mjl\", \"\", \"\")\n\t})\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueHoldrulesAdd(ctl, \"\", \"☺.mox.example\", \"\")\n\t})\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueHoldrulesAdd(ctl, \"mox\", \"☺.mox.example\", \"example.com\")\n\t})\n\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueHoldrulesRemove(ctl, 1)\n\t})\n\n\t// Queue a message to list/change/dump.\n\tmsg := \"Subject: subject\\r\\n\\r\\nbody\\r\\n\"\n\tmsgFile, err := store.CreateMessageTemp(pkglog, \"queuedump-test\")\n\ttcheck(t, err, \"temp file\")\n\t_, err = msgFile.Write([]byte(msg))\n\ttcheck(t, err, \"write message\")\n\t_, err = msgFile.Seek(0, 0)\n\ttcheck(t, err, \"rewind message\")\n\tdefer os.Remove(msgFile.Name())\n\tdefer msgFile.Close()\n\taddr, err := smtp.ParseAddress(\"mjl@mox.example\")\n\ttcheck(t, err, \"parse address\")\n\tqml := []queue.Msg{queue.MakeMsg(addr.Path(), addr.Path(), false, false, int64(len(msg)), \"<random@localhost>\", nil, nil, time.Now(), \"subject\")}\n\tqueue.Add(ctxbg, pkglog, \"mjl\", msgFile, qml...)\n\tqmid := qml[0].ID\n\n\t// Has entries now.\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueHoldrulesList(ctl)\n\t})\n\n\t// \"queuelist\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueList(ctl, queue.Filter{}, queue.Sort{})\n\t})\n\n\t// \"queueholdset\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueHoldSet(ctl, queue.Filter{}, true)\n\t})\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueHoldSet(ctl, queue.Filter{}, false)\n\t})\n\n\t// \"queueschedule\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueSchedule(ctl, queue.Filter{}, true, time.Minute)\n\t})\n\n\t// \"queuetransport\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueTransport(ctl, queue.Filter{}, \"socks\")\n\t})\n\n\t// \"queuerequiretls\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueRequireTLS(ctl, queue.Filter{}, nil)\n\t})\n\n\t// \"queuedump\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueDump(ctl, fmt.Sprintf(\"%d\", qmid))\n\t})\n\n\t// \"queuefail\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueFail(ctl, queue.Filter{})\n\t})\n\n\t// \"queuedrop\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueDrop(ctl, queue.Filter{})\n\t})\n\n\t// \"queueholdruleslist\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueHoldrulesList(ctl)\n\t})\n\n\t// \"queueholdrulesadd\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueHoldrulesAdd(ctl, \"mjl\", \"\", \"\")\n\t})\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueHoldrulesAdd(ctl, \"mjl\", \"localhost\", \"\")\n\t})\n\n\t// \"queueholdrulesremove\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueHoldrulesRemove(ctl, 2)\n\t})\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueHoldrulesList(ctl)\n\t})\n\n\t// \"queuesuppresslist\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueSuppressList(ctl, \"mjl\")\n\t})\n\n\t// \"queuesuppressadd\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueSuppressAdd(ctl, \"mjl\", \"base@localhost\")\n\t})\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueSuppressAdd(ctl, \"mjl\", \"other@localhost\")\n\t})\n\n\t// \"queuesuppresslookup\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueSuppressLookup(ctl, \"mjl\", \"base@localhost\")\n\t})\n\n\t// \"queuesuppressremove\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueSuppressRemove(ctl, \"mjl\", \"base@localhost\")\n\t})\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueSuppressList(ctl, \"mjl\")\n\t})\n\n\t// \"queueretiredlist\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueRetiredList(ctl, queue.RetiredFilter{}, queue.RetiredSort{})\n\t})\n\n\t// \"queueretiredprint\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueRetiredPrint(ctl, \"1\")\n\t})\n\n\t// \"queuehooklist\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueHookList(ctl, queue.HookFilter{}, queue.HookSort{})\n\t})\n\n\t// \"queuehookschedule\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueHookSchedule(ctl, queue.HookFilter{}, true, time.Minute)\n\t})\n\n\t// \"queuehookprint\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueHookPrint(ctl, \"1\")\n\t})\n\n\t// \"queuehookcancel\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueHookCancel(ctl, queue.HookFilter{})\n\t})\n\n\t// \"queuehookretiredlist\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueHookRetiredList(ctl, queue.HookRetiredFilter{}, queue.HookRetiredSort{})\n\t})\n\n\t// \"queuehookretiredprint\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdQueueHookRetiredPrint(ctl, \"1\")\n\t})\n\n\t// \"importmbox\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdImport(ctl, true, \"mjl\", \"inbox\", \"testdata/importtest.mbox\")\n\t})\n\n\t// \"importmaildir\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdImport(ctl, false, \"mjl\", \"inbox\", \"testdata/importtest.maildir\")\n\t})\n\n\t// \"domainadd\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdConfigDomainAdd(ctl, dns.Domain{ASCII: \"mox2.example\"}, \"mjl\", \"\")\n\t})\n\n\t// \"accountadd\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdConfigAccountAdd(ctl, \"mjl2\", \"mjl2@mox2.example\")\n\t})\n\n\t// \"addressadd\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdConfigAddressAdd(ctl, \"mjl3@mox2.example\", \"mjl2\")\n\t})\n\n\t// Add a message.\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdDeliver(ctl, \"mjl3@mox2.example\")\n\t})\n\t// \"retrain\", retrain junk filter.\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdRetrain(ctl, \"mjl2\")\n\t})\n\n\t// \"addressrm\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdConfigAddressRemove(ctl, \"mjl3@mox2.example\")\n\t})\n\n\t// \"accountrm\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdConfigAccountRemove(ctl, \"mjl2\")\n\t})\n\n\t// \"domainrm\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdConfigDomainRemove(ctl, dns.Domain{ASCII: \"mox2.example\"})\n\t})\n\n\t// \"aliasadd\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdConfigAliasAdd(ctl, \"support@mox.example\", config.Alias{Addresses: []string{\"mjl@mox.example\"}})\n\t})\n\n\t// \"aliaslist\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdConfigAliasList(ctl, \"mox.example\")\n\t})\n\n\t// \"aliasprint\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdConfigAliasPrint(ctl, \"support@mox.example\")\n\t})\n\n\t// \"aliasupdate\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdConfigAliasUpdate(ctl, \"support@mox.example\", \"true\", \"true\", \"true\")\n\t})\n\n\t// \"aliasaddaddr\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdConfigAliasAddaddr(ctl, \"support@mox.example\", []string{\"mjl2@mox.example\"})\n\t})\n\n\t// \"aliasrmaddr\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdConfigAliasRmaddr(ctl, \"support@mox.example\", []string{\"mjl2@mox.example\"})\n\t})\n\n\t// \"aliasrm\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdConfigAliasRemove(ctl, \"support@mox.example\")\n\t})\n\n\t// accounttlspubkeyadd\n\tcertDER := fakeCert(t)\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdConfigTlspubkeyAdd(ctl, \"mjl@mox.example\", \"testkey\", false, certDER)\n\t})\n\n\t// \"accounttlspubkeylist\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdConfigTlspubkeyList(ctl, \"\")\n\t})\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdConfigTlspubkeyList(ctl, \"mjl\")\n\t})\n\n\ttpkl, err := store.TLSPublicKeyList(ctxbg, \"\")\n\ttcheck(t, err, \"list tls public keys\")\n\tif len(tpkl) != 1 {\n\t\tt.Fatalf(\"got %d tls public keys, expected 1\", len(tpkl))\n\t}\n\tfingerprint := tpkl[0].Fingerprint\n\n\t// \"accounttlspubkeyget\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdConfigTlspubkeyGet(ctl, fingerprint)\n\t})\n\n\t// \"accounttlspubkeyrm\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdConfigTlspubkeyRemove(ctl, fingerprint)\n\t})\n\n\ttpkl, err = store.TLSPublicKeyList(ctxbg, \"\")\n\ttcheck(t, err, \"list tls public keys\")\n\tif len(tpkl) != 0 {\n\t\tt.Fatalf(\"got %d tls public keys, expected 0\", len(tpkl))\n\t}\n\n\t// \"loglevels\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdLoglevels(ctl)\n\t})\n\n\t// \"setloglevels\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdSetLoglevels(ctl, \"\", \"debug\")\n\t})\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdSetLoglevels(ctl, \"smtpserver\", \"debug\")\n\t})\n\n\t// Export data, import it again\n\txcmdExport(true, false, []string{filepath.FromSlash(\"testdata/ctl/data/tmp/export/mbox/\"), filepath.FromSlash(\"testdata/ctl/data/accounts/mjl\")}, &cmd{log: pkglog})\n\txcmdExport(false, false, []string{filepath.FromSlash(\"testdata/ctl/data/tmp/export/maildir/\"), filepath.FromSlash(\"testdata/ctl/data/accounts/mjl\")}, &cmd{log: pkglog})\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdImport(ctl, true, \"mjl\", \"inbox\", filepath.FromSlash(\"testdata/ctl/data/tmp/export/mbox/Inbox.mbox\"))\n\t})\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdImport(ctl, false, \"mjl\", \"inbox\", filepath.FromSlash(\"testdata/ctl/data/tmp/export/maildir/Inbox\"))\n\t})\n\n\t// \"recalculatemailboxcounts\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdRecalculateMailboxCounts(ctl, \"mjl\")\n\t})\n\n\t// \"fixmsgsize\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdFixmsgsize(ctl, \"mjl\")\n\t})\n\ttestctl(func(ctl *ctl) {\n\t\tacc, err := store.OpenAccount(ctl.log, \"mjl\")\n\t\ttcheck(t, err, \"open account\")\n\t\tdefer func() {\n\t\t\tacc.Close()\n\t\t\tacc.CheckClosed()\n\t\t}()\n\n\t\tcontent := []byte(\"Subject: hi\\r\\n\\r\\nbody\\r\\n\")\n\n\t\tdeliver := func(m *store.Message) {\n\t\t\tt.Helper()\n\t\t\tm.Size = int64(len(content))\n\t\t\tmsgf, err := store.CreateMessageTemp(ctl.log, \"ctltest\")\n\t\t\ttcheck(t, err, \"create temp file\")\n\t\t\tdefer os.Remove(msgf.Name())\n\t\t\tdefer msgf.Close()\n\t\t\t_, err = msgf.Write(content)\n\t\t\ttcheck(t, err, \"write message file\")\n\t\t\terr = acc.DeliverMailbox(ctl.log, \"Inbox\", m, msgf)\n\t\t\ttcheck(t, err, \"deliver message\")\n\t\t}\n\n\t\tvar msgBadSize store.Message\n\t\tdeliver(&msgBadSize)\n\n\t\tmsgBadSize.Size = 1\n\t\terr = acc.DB.Update(ctxbg, &msgBadSize)\n\t\ttcheck(t, err, \"update message to bad size\")\n\t\tmb := store.Mailbox{ID: msgBadSize.MailboxID}\n\t\terr = acc.DB.Get(ctxbg, &mb)\n\t\ttcheck(t, err, \"get db\")\n\t\tmb.Size -= int64(len(content))\n\t\tmb.Size += 1\n\t\terr = acc.DB.Update(ctxbg, &mb)\n\t\ttcheck(t, err, \"update mailbox size\")\n\n\t\t// Fix up the size.\n\t\tctlcmdFixmsgsize(ctl, \"\")\n\n\t\terr = acc.DB.Get(ctxbg, &msgBadSize)\n\t\ttcheck(t, err, \"get message\")\n\t\tif msgBadSize.Size != int64(len(content)) {\n\t\t\tt.Fatalf(\"after fixing, message size is %d, should be %d\", msgBadSize.Size, len(content))\n\t\t}\n\t})\n\n\t// \"reparse\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdReparse(ctl, \"mjl\")\n\t})\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdReparse(ctl, \"\")\n\t})\n\n\t// \"reassignthreads\"\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdReassignthreads(ctl, \"mjl\")\n\t})\n\ttestctl(func(ctl *ctl) {\n\t\tctlcmdReassignthreads(ctl, \"\")\n\t})\n\n\t// \"backup\", backup account.\n\terr = dmarcdb.Init()\n\ttcheck(t, err, \"dmarcdb init\")\n\tdefer dmarcdb.Close()\n\terr = mtastsdb.Init(false)\n\ttcheck(t, err, \"mtastsdb init\")\n\tdefer mtastsdb.Close()\n\terr = tlsrptdb.Init()\n\ttcheck(t, err, \"tlsrptdb init\")\n\tdefer tlsrptdb.Close()\n\ttestctl(func(ctl *ctl) {\n\t\tos.RemoveAll(\"testdata/ctl/data/tmp/backup-data\")\n\t\terr := os.WriteFile(\"testdata/ctl/data/receivedid.key\", make([]byte, 16), 0600)\n\t\ttcheck(t, err, \"writing receivedid.key\")\n\t\tctlcmdBackup(ctl, filepath.FromSlash(\"testdata/ctl/data/tmp/backup-data\"), false)\n\t})\n\n\t// Verify the backup.\n\txcmd := cmd{\n\t\tflag:     flag.NewFlagSet(\"\", flag.ExitOnError),\n\t\tflagArgs: []string{filepath.FromSlash(\"testdata/ctl/data/tmp/backup-data\")},\n\t}\n\tcmdVerifydata(&xcmd)\n}\n\nfunc fakeCert(t *testing.T) []byte {\n\tt.Helper()\n\tseed := make([]byte, ed25519.SeedSize)\n\tprivKey := ed25519.NewKeyFromSeed(seed) // Fake key, don't use this for real!\n\ttemplate := &x509.Certificate{\n\t\tSerialNumber: big.NewInt(1), // Required field...\n\t}\n\tlocalCertBuf, err := x509.CreateCertificate(cryptorand.Reader, template, template, privKey.Public(), privKey)\n\ttcheck(t, err, \"making certificate\")\n\treturn localCertBuf\n}\n"
        },
        {
          "name": "dane",
          "type": "tree",
          "content": null
        },
        {
          "name": "develop.txt",
          "type": "blob",
          "size": 12.318359375,
          "content": "This file has notes useful for mox developers.\n\n# Building & testing\n\nFor a full build, you'll need a recent Go compiler/toolchain and nodejs/npm for\nthe frontend. Run \"make build\" to do a full build. Run \"make test\" to run the\ntest suite. With docker installed, you can run \"make test-integration\" to start\nup a few mox instances, a dns server, a postfix instance, and send email\nbetween them.\n\nThe mox localserve command is a convenient way to test locally. Most of the\ncode paths are reachable/testable with mox localserve, but some use cases will\nrequire a full setup.\n\nBefore committing, run at least \"make fmt\" and \"make check\" (which requires\nstaticcheck, run \"make install-staticcheck\" once). Also run \"make check-shadow\"\nand fix any shadowed variables other than \"err\" (which are filtered out, but\ncauses the command to always exit with an error code; run \"make install-shadow\"\nonce to install the shadow command). If you've updated RFC references, run\n\"make\" in rfc/, it verifies the referenced files exist.\n\nWhen making changes to the public API of a package listed in\napidiff/packages.txt, run \"make genapidiff\" to update the list of changes in\nthe upcoming release (run \"make install-apidiff\" once to install the apidiff\ncommand).\n\nNew features may be worth mentioning on the website, see website/ and\ninstructions below.\n\n\n# Code style, guidelines, notes\n\n- Keep the same style as existing code.\n- For Windows: use package \"path/filepath\" when dealing with files/directories.\n  Test code can pass forward-slashed paths directly to standard library functions,\n  but use proper filepath functions when parameters are passed and in non-test\n  code.  Mailbox names always use forward slash, so use package \"path\" for mailbox\n  name/path manipulation. Do not remove/rename files that are still open.\n- Not all code uses adns, the DNSSEC-aware resolver. Such as code that makes\n  http requests, like mtasts and autotls/autocert.\n- We don't have an internal/ directory, really just to prevent long paths in\n  the repo, and to keep all Go code matching *.go */*.go (without matching\n  vendor/). Part of the packages are reusable by other software. Those reusable\n  packages must not cause mox implementation details (such as bstore) to get out,\n  which would cause unexpected dependencies. Those packages also only expose the\n  standard slog package for logging, not our mlog package. Packages not intended\n  for reuse do use mlog as it is more convenient. Internally, we always use\n  mlog.Log to do the logging, wrapping an slog.Logger.\n\n\n# Reusable packages\n\nMost non-server Go packages are meant to be reusable. This means internal\ndetails are not exposed in the API, and we don't make unneeded changes. We can\nstill make breaking changes when it improves mox: We don't want to be stuck\nwith bad API. Third party users aren't affected too seriously due to Go's\nminimal version selection. The reusable packages are in apidiff/packages.txt.\nWe generate the incompatible changes with each release.\n\n\n# Web interfaces/frontend\n\nThe web interface frontends (for webmail/, webadmin/ and webaccount/) are\nwritten in strict TypeScript. The web API is a simple self-documenting\nHTTP/JSON RPC API mechanism called sherpa,\nhttps://www.ueber.net/who/mjl/sherpa/. The web API exposes types and functions\nas implemented in Go, using https://github.com/mjl-/sherpa. API definitions in\nJSON form are generated with https://github.com/mjl-/sherpadoc. Those API\ndefinitions are used to generate TypeScript clients with by\nhttps://github.com/mjl-/sherpats/.\n\nThe JavaScript that is generated from the TypeScript is included in the\nrepository. This makes it available for inclusion in the binary, which is\npractical for users, and desirable given Go's reproducible builds. When\ndeveloping, run \"make\" to also build the frontend code. Run \"make\ninstall-frontend\" once to install the TypeScript compiler into ./node_modules/.\n\nThere are no other external (runtime or devtime) frontend dependencies. A\nlight-weight abstraction over the DOM is provided by ./lib.ts. A bit more\nmanual UI state management must be done compared to \"frameworks\", but it is\nlittle code, and this allows JavaScript/TypeScript developer to quickly get\nstarted. UI state is often encapsulated in a JavaScript object with a\nTypeScript interface exposing a \"root\" HTMLElement that is added to the DOM,\nand functions for accessing/changing the internal state, keeping the UI\nmanagable.\n\n\n# Website\n\nThe content of the public website at https://www.xmox.nl is in website/, as\nmarkdown files. The website HTML is generated with \"make genwebsite\", which\nwrites to website/html/ (files not committed).  The FAQ is taken from\nREADME.md, the protocol support table is generated from rfc/index.txt. The\nwebsite is kept in this repository so a commit can change both the\nimplementation and the documentation on the website. Some of the info in\nREADME.md is duplicated on the website, often more elaborate and possibly with\na slightly less technical audience.  The website should also mostly be readable\nthrough the markdown in the git repo.\n\nLarge files (images/videos) are in https://github.com/mjl-/mox-website-files to\nkeep the repository reasonably sized.\n\nThe public website may serve the content from the \"website\" branch. After a\nrelease release, the main branch (with latest development code and\ncorresponding changes to the website about new features) is merged into the\nwebsite branch.  Commits to the website branch (e.g. for a news item, or any\nother change unrelated to a new release) is merged back into the main branch.\n\n\n# TLS certificates\n\nhttps://github.com/cloudflare/cfssl is useful for testing with TLS\ncertificates. Create a CA and configure it in mox.conf TLS.CA.CertFiles, and\nsign host certificates and configure them in the listeners TLS.KeyCerts.\n\nSetup a local CA with cfssl, run once:\n\n```sh\ngo install github.com/cloudflare/cfssl/cmd/cfssl@latest\ngo install github.com/cloudflare/cfssl/cmd/cfssljson@latest\n\nmkdir -p local/cfssl\ncd local/cfssl\n\ncfssl print-defaults config > ca-config.json # defaults are fine\n\n# Based on: cfssl print-defaults csr > ca-csr.json\ncat <<EOF >ca-csr.json\n{\n    \"CN\": \"mox ca\",\n    \"key\": {\n        \"algo\": \"ecdsa\",\n        \"size\": 256\n    },\n    \"names\": [\n        {\n            \"C\": \"NL\"\n        }\n    ]\n}\nEOF\n\ncfssl gencert -initca ca-csr.json | cfssljson -bare ca - # Generate ca key and cert.\n\n# Generate wildcard certificates for one or more domains, add localhost for use with pebble, see below.\ndomains=\"moxtest.example localhost\"\nfor domain in $domains; do\n\tcat <<EOF >wildcard.$domain.csr.json\n{\n  \"key\": {\n    \"algo\": \"ecdsa\",\n    \"size\": 256\n  },\n  \"names\": [\n  {\n    \"O\": \"mox\"\n  }\n  ],\n  \"hosts\": [\n    \"$domain\",\n    \"*.$domain\"\n  ]\n}\nEOF\n\tcfssl gencert -ca ca.pem -ca-key ca-key.pem -profile=www wildcard.$domain.csr.json | cfssljson -bare wildcard.$domain\ndone\n```\n\nNow configure mox.conf to add the cfssl CA root certificate:\n\n```\nTLS:\n\tCA:\n\t\tAdditionalToSystem: true\n\t\tCertFiles:\n\t\t\t# Assuming local/<env>/config/mox.conf and local/cfssl/.\n\t\t\t- ../../cfssl/ca.pem\n\n[...]\n\nListeners:\n\tpublic:\n                TLS:\n\t\t\tKeyCerts:\n\t\t\t\t# Assuming local/<env>/config/mox.conf and local/cfssl/.\n\t\t\t\tCertFile: ../../cfssl/wildcard.$domain.pem\n\t\t\t\tKeyFile: ../../cfssl/wildcard.$domain-key.pem\n```\n\n\n# ACME\n\nhttps://github.com/letsencrypt/pebble is useful for testing with ACME. Start a\npebble instance that uses the localhost TLS cert/key created by cfssl for its\nTLS serving. Pebble generates a new CA certificate for its own use each time it\nis started. Fetch it from https://localhost:15000/roots/0, write it to a file, and\nadd it to mox.conf TLS.CA.CertFiles. See below.\n\nSetup pebble, run once:\n\n```sh\ngo install github.com/letsencrypt/pebble/cmd/pebble@latest\n\nmkdir -p local/pebble\ncat <<EOF >local/pebble/config.json\n{\n  \"pebble\": {\n    \"listenAddress\": \"localhost:14000\",\n    \"managementListenAddress\": \"localhost:15000\",\n    \"certificate\": \"local/cfssl/localhost.pem\",\n    \"privateKey\": \"local/cfssl/localhost-key.pem\",\n    \"httpPort\": 80,\n    \"tlsPort\": 443,\n    \"ocspResponderURL\": \"\",\n    \"externalAccountBindingRequired\": false\n  }\n}\nEOF\n```\n\nStart pebble, this generates a new temporary pebble CA certificate:\n\n```sh\npebble -config local/pebble/config.json\n```\n\nWrite new CA bundle that includes pebble's temporary CA cert:\n\n```sh\nexport CURL_CA_BUNDLE=local/ca-bundle.pem # for curl\nexport SSL_CERT_FILE=local/ca-bundle.pem # for go apps\ncat /etc/ssl/certs/ca-certificates.crt local/cfssl/ca.pem >local/ca-bundle.pem\ncurl https://localhost:15000/roots/0 >local/pebble/ca.pem # fetch temp pebble ca, DO THIS EVERY TIME PEBBLE IS RESTARTED!\ncat /etc/ssl/certs/ca-certificates.crt local/cfssl/ca.pem local/pebble/ca.pem >local/ca-bundle.pem # create new list that includes cfssl ca and temp pebble ca.\nrm -r local/*/data/acme/keycerts/pebble # remove existing pebble-signed certs in acme cert/key cache, they are invalid due to newly generated temp pebble ca.\n```\n\nEdit mox.conf, adding pebble ACME and its ca.pem:\n\n```\nACME:\n\tpebble:\n\t\tDirectoryURL: https://localhost:14000/dir\n\t\tContactEmail: root@mox.example\nTLS:\n\tCA:\n\t\tAdditionalToSystem: true\n\t\tCertFiles:\n\t\t\t# Assuming local/<env>/config/mox.conf and local/pebble/ca.pem and local/cfssl/ca.pem.\n\t\t\t- ../../pebble/ca.pem\n\t\t\t- ../../cfssl/ca.pem\n\n[...]\n\nListeners:\n\tpublic:\n                TLS:\n                        ACME: pebble\n```\n\nFor mail clients and browsers to accept pebble-signed certificates, you must add\nthe temporary pebble CA cert to their trusted root CA store each time pebble is\nstarted (e.g. to your thunderbird/firefox testing profile). Pebble has no option\nto not regenerate its CA certificate, presumably for fear of people using it for\nnon-testing purposes. Unfortunately, this also makes it inconvenient to use for\ntesting purposes.\n\n\n# Messages for testing\n\nFor compatibility and preformance testing, it helps to have many messages,\ncreated a long time ago and recently, by different mail user agents. A helpful\nsource is the Linux kernel mailing list. Archives are available as multiple git\nrepositories (split due to size) at\nhttps://lore.kernel.org/lkml/_/text/mirror/.  The git repo's can be converted\nto compressed mbox files (about 800MB each) with:\n\n```\n# 0 is the first epoch (with over half a million messages), 12 is last\n# already-complete epoch at the time of writing (with a quarter million\n# messages). The archives are large, converting will take some time.\nfor i in 0 12; do\n        git clone --mirror http://lore.kernel.org/lkml/$i lkml-$i.git\n        (cd lkml-$i.git && time ./tombox.sh | gzip >../lkml-$i.mbox.gz)\ndone\n```\n\nWith the following \"tombox.sh\" script:\n\n```\n#!/bin/sh\npre=''\nfor rev in $(git rev-list master | reverse); do\n        printf \"$pre\"\n        echo \"From sender@host  $(date '+%a %b %e %H:%M:%S %Y' -d @$(git show -s --format=%ct $rev))\"\n        git show ${rev}:m | sed 's/^>*From />&/'\n        pre='\\n'\ndone\n```\n\n\n# Release proces\n\n- Gather feedback on recent changes.\n- Check if dependencies need updates.\n- Check code if there are deprecated features that can be removed.\n- Generate apidiff and check if breaking changes can be prevented. Update moxtools.\n- Update features & roadmap in README.md and website.\n- Write release notes, copy from previous.\n- Build and run tests with previous major Go release, run \"make docker-release\" to test building images.\n- Run tests, including with race detector, also with TZ= for UTC-behaviour, and with -count 2.\n- Run integration and upgrade tests.\n- Run fuzzing tests for a while.\n- Deploy to test environment. Test the update instructions.\n- Test mox localserve on various OSes (linux, bsd, macos, windows).\n- Send and receive email through the major webmail providers, check headers.\n- Send and receive email with imap4/smtp clients.\n- Check DNS check admin page.\n- Check with https://internet.nl.\n- Move apidiff/next.txt to apidiff/<version>.txt, and create empty next.txt.\n- Add release to the Latest release & News sections of website/index.md.\n- Create git tag (note: \"#\" is comment, not title/header), push code.\n- Build and publish new docker image.\n- Publish signed release notes for updates.xmox.nl and update DNS record.\n- Deploy update to website.\n- Create new release on the github page, so watchers get a notification.\n  Copy/paste it manually from the tag text, and add link to download/compile\n  instructions to prevent confusion about \"assets\" github links to.\n- Publish new cross-referenced code/rfc to www.xmox.nl/xr/.\n- Update moxtools with latest version.\n- Update implementations support matrix.\n"
        },
        {
          "name": "dkim",
          "type": "tree",
          "content": null
        },
        {
          "name": "dmarc",
          "type": "tree",
          "content": null
        },
        {
          "name": "dmarcdb",
          "type": "tree",
          "content": null
        },
        {
          "name": "dmarcrpt",
          "type": "tree",
          "content": null
        },
        {
          "name": "dns",
          "type": "tree",
          "content": null
        },
        {
          "name": "dnsbl",
          "type": "tree",
          "content": null
        },
        {
          "name": "doc.go",
          "type": "blob",
          "size": 57.3837890625,
          "content": "/*\nCommand mox is a modern, secure, full-featured, open source mail server for\nlow-maintenance self-hosted email.\n\nMox is started with the \"serve\" subcommand, but mox also has many other\nsubcommands.\n\nMany of those commands talk to a running mox instance, through the ctl file in\nthe data directory. Specify the configuration file (that holds the path to the\ndata directory) through the -config flag or MOXCONF environment variable.\n\nCommands that don't talk to a running mox instance are often for\ntesting/debugging email functionality. For example for parsing an email message,\nor looking up SPF/DKIM/DMARC records.\n\nBelow is the usage information as printed by the command when started without\nany parameters. Followed by the help and usage information for each command.\n\n# Usage\n\n\tmox [-config config/mox.conf] [-pedantic] ...\n\tmox serve\n\tmox quickstart [-skipdial] [-existing-webserver] [-hostname host] user@domain [user | uid]\n\tmox stop\n\tmox setaccountpassword account\n\tmox setadminpassword\n\tmox loglevels [level [pkg]]\n\tmox queue holdrules list\n\tmox queue holdrules add [ruleflags]\n\tmox queue holdrules remove ruleid\n\tmox queue list [filtersortflags]\n\tmox queue hold [filterflags]\n\tmox queue unhold [filterflags]\n\tmox queue schedule [filterflags] [-now] duration\n\tmox queue transport [filterflags] transport\n\tmox queue requiretls [filterflags] {yes | no | default}\n\tmox queue fail [filterflags]\n\tmox queue drop [filterflags]\n\tmox queue dump id\n\tmox queue retired list [filtersortflags]\n\tmox queue retired print id\n\tmox queue suppress list [-account account]\n\tmox queue suppress add account address\n\tmox queue suppress remove account address\n\tmox queue suppress lookup [-account account] address\n\tmox queue webhook list [filtersortflags]\n\tmox queue webhook schedule [filterflags] duration\n\tmox queue webhook cancel [filterflags]\n\tmox queue webhook print id\n\tmox queue webhook retired list [filtersortflags]\n\tmox queue webhook retired print id\n\tmox import maildir accountname mailboxname maildir\n\tmox import mbox accountname mailboxname mbox\n\tmox export maildir [-single] dst-dir account-path [mailbox]\n\tmox export mbox [-single] dst-dir account-path [mailbox]\n\tmox localserve\n\tmox help [command ...]\n\tmox backup dest-dir\n\tmox verifydata data-dir\n\tmox licenses\n\tmox config test\n\tmox config dnscheck domain\n\tmox config dnsrecords domain\n\tmox config describe-domains >domains.conf\n\tmox config describe-static >mox.conf\n\tmox config account add account address\n\tmox config account rm account\n\tmox config address add address account\n\tmox config address rm address\n\tmox config domain add domain account [localpart]\n\tmox config domain rm domain\n\tmox config tlspubkey list [account]\n\tmox config tlspubkey get fingerprint\n\tmox config tlspubkey add address [name] < cert.pem\n\tmox config tlspubkey rm fingerprint\n\tmox config tlspubkey gen stem\n\tmox config alias list domain\n\tmox config alias print alias\n\tmox config alias add alias@domain rcpt1@domain ...\n\tmox config alias update alias@domain [-postpublic false|true -listmembers false|true -allowmsgfrom false|true]\n\tmox config alias rm alias@domain\n\tmox config alias addaddr alias@domain rcpt1@domain ...\n\tmox config alias rmaddr alias@domain rcpt1@domain ...\n\tmox config describe-sendmail >/etc/moxsubmit.conf\n\tmox config printservice >mox.service\n\tmox config ensureacmehostprivatekeys\n\tmox config example [name]\n\tmox checkupdate\n\tmox cid cid\n\tmox clientconfig domain\n\tmox dane dial host:port\n\tmox dane dialmx domain [destination-host]\n\tmox dane makerecord usage selector matchtype [certificate.pem | publickey.pem | privatekey.pem]\n\tmox dns lookup [ptr | mx | cname | ips | a | aaaa | ns | txt | srv | tlsa] name\n\tmox dkim gened25519 >$selector._domainkey.$domain.ed25519.privatekey.pkcs8.pem\n\tmox dkim genrsa >$selector._domainkey.$domain.rsa2048.privatekey.pkcs8.pem\n\tmox dkim lookup selector domain\n\tmox dkim txt <$selector._domainkey.$domain.key.pkcs8.pem\n\tmox dkim verify message\n\tmox dkim sign message\n\tmox dmarc lookup domain\n\tmox dmarc parsereportmsg message ...\n\tmox dmarc verify remoteip mailfromaddress helodomain < message\n\tmox dmarc checkreportaddrs domain\n\tmox dnsbl check zone ip\n\tmox dnsbl checkhealth zone\n\tmox mtasts lookup domain\n\tmox retrain [accountname]\n\tmox sendmail [-Fname] [ignoredflags] [-t] [<message]\n\tmox spf check domain ip\n\tmox spf lookup domain\n\tmox spf parse txtrecord\n\tmox tlsrpt lookup domain\n\tmox tlsrpt parsereportmsg message ...\n\tmox version\n\tmox webapi [method [baseurl-with-credentials]\n\tmox example [name]\n\tmox bumpuidvalidity account [mailbox]\n\tmox reassignuids account [mailboxid]\n\tmox fixuidmeta account\n\tmox fixmsgsize [account]\n\tmox reparse [account]\n\tmox ensureparsed account\n\tmox recalculatemailboxcounts account\n\tmox message parse message.eml\n\tmox reassignthreads [account]\n\n# mox serve\n\nStart mox, serving SMTP/IMAP/HTTPS.\n\nIncoming email is accepted over SMTP. Email can be retrieved by users using\nIMAP. HTTP listeners are started for the admin/account web interfaces, and for\nautomated TLS configuration. Missing essential TLS certificates are immediately\nrequested, other TLS certificates are requested on demand.\n\nOnly implemented on unix systems, not Windows.\n\n\tusage: mox serve\n\n# mox quickstart\n\nQuickstart generates configuration files and prints instructions to quickly set up a mox instance.\n\nQuickstart writes configuration files, prints initial admin and account\npasswords, DNS records you should create. If you run it on Linux it writes a\nsystemd service file and prints commands to enable and start mox as service.\n\nAll output is written to quickstart.log for later reference.\n\nThe user or uid is optional, defaults to \"mox\", and is the user or uid/gid mox\nwill run as after initialization.\n\nQuickstart assumes mox will run on the machine you run quickstart on and uses\nits host name and public IPs. On many systems the hostname is not a fully\nqualified domain name, but only the first dns \"label\", e.g. \"mail\" in case of\n\"mail.example.org\". If so, quickstart does a reverse DNS lookup to find the\nhostname, and as fallback uses the label plus the domain of the email address\nyou specified. Use flag -hostname to explicitly specify the hostname mox will\nrun on.\n\nMox is by far easiest to operate if you let it listen on port 443 (HTTPS) and\n80 (HTTP). TLS will be fully automatic with ACME with Let's Encrypt.\n\nYou can run mox along with an existing webserver, but because of MTA-STS and\nautoconfig, you'll need to forward HTTPS traffic for two domains to mox. Run\n\"mox quickstart -existing-webserver ...\" to generate configuration files and\ninstructions for configuring mox along with an existing webserver.\n\nBut please first consider configuring mox on port 443. It can itself serve\ndomains with HTTP/HTTPS, including with automatic TLS with ACME, is easily\nconfigured through both configuration files and admin web interface, and can act\nas a reverse proxy (and static file server for that matter), so you can forward\ntraffic to your existing backend applications. Look for \"WebHandlers:\" in the\noutput of \"mox config describe-domains\" and see the output of\n\"mox config example webhandlers\".\n\n\tusage: mox quickstart [-skipdial] [-existing-webserver] [-hostname host] user@domain [user | uid]\n\t  -existing-webserver\n\t    \tuse if a webserver is already running, so mox won't listen on port 80 and 443; you'll have to provide tls certificates/keys, and configure the existing webserver as reverse proxy, forwarding requests to mox.\n\t  -hostname string\n\t    \thostname mox will run on, by default the hostname of the machine quickstart runs on; if specified, the IPs for the hostname are configured for the public listener\n\t  -skipdial\n\t    \tskip check for outgoing smtp (port 25) connectivity\n\n# mox stop\n\nShut mox down, giving connections maximum 3 seconds to stop before closing them.\n\nWhile shutting down, new IMAP and SMTP connections will get a status response\nindicating temporary unavailability. Existing connections will get a 3 second\nperiod to finish their transaction and shut down. Under normal circumstances,\nonly IMAP has long-living connections, with the IDLE command to get notified of\nnew mail deliveries.\n\n\tusage: mox stop\n\n# mox setaccountpassword\n\nSet new password an account.\n\nThe password is read from stdin. Secrets derived from the password, but not the\npassword itself, are stored in the account database. The stored secrets are for\nauthentication with: scram-sha-256, scram-sha-1, cram-md5, plain text (bcrypt\nhash).\n\nThe parameter is an account name, as configured under Accounts in domains.conf\nand as present in the data/accounts/ directory, not a configured email address\nfor an account.\n\n\tusage: mox setaccountpassword account\n\n# mox setadminpassword\n\nSet a new admin password, for the web interface.\n\nThe password is read from stdin. Its bcrypt hash is stored in a file named\n\"adminpasswd\" in the configuration directory.\n\n\tusage: mox setadminpassword\n\n# mox loglevels\n\nPrint the log levels, or set a new default log level, or a level for the given package.\n\nBy default, a single log level applies to all logging in mox. But for each\n\"pkg\", an overriding log level can be configured. Examples of packages:\nsmtpserver, smtpclient, queue, imapserver, spf, dkim, dmarc, junk, message,\netc.\n\nSpecify a pkg and an empty level to clear the configured level for a package.\n\nValid labels: error, info, debug, trace, traceauth, tracedata.\n\n\tusage: mox loglevels [level [pkg]]\n\n# mox queue holdrules list\n\nList hold rules for the delivery queue.\n\nMessages submitted to the queue that match a hold rule will be marked as on hold\nand not scheduled for delivery.\n\n\tusage: mox queue holdrules list\n\n# mox queue holdrules add\n\nAdd hold rule for the delivery queue.\n\nAdd a hold rule to mark matching newly submitted messages as on hold. Set the\nmatching rules with the flags. Don't specify any flags to match all submitted\nmessages.\n\n\tusage: mox queue holdrules add [ruleflags]\n\t  -account string\n\t    \taccount submitting the message\n\t  -recipientdom string\n\t    \trecipient domain\n\t  -senderdom string\n\t    \tsender domain\n\n# mox queue holdrules remove\n\nRemove hold rule for the delivery queue.\n\nRemove a hold rule by its id.\n\n\tusage: mox queue holdrules remove ruleid\n\n# mox queue list\n\nList matching messages in the delivery queue.\n\nPrints the message with its ID, last and next delivery attempts, last error.\n\n\tusage: mox queue list [filtersortflags]\n\t  -account string\n\t    \taccount that queued the message\n\t  -asc\n\t    \tsort ascending instead of descending (default)\n\t  -from string\n\t    \tfrom address of message, use \"@example.com\" to match all messages for a domain\n\t  -hold value\n\t    \ttrue or false, whether to match only messages that are (not) on hold\n\t  -ids value\n\t    \tcomma-separated list of message IDs\n\t  -n int\n\t    \tnumber of messages to return\n\t  -nextattempt string\n\t    \tfilter by time of next delivery attempt relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -sort value\n\t    \tfield to sort by, \"nextattempt\" (default) or \"queued\"\n\t  -submitted string\n\t    \tfilter by time of submission relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -to string\n\t    \trecipient address of message, use \"@example.com\" to match all messages for a domain\n\t  -transport value\n\t    \ttransport to use for messages, empty string sets the default behaviour\n\n# mox queue hold\n\nMark matching messages on hold.\n\nMessages that are on hold are not delivered until marked as off hold again, or\notherwise handled by the admin.\n\n\tusage: mox queue hold [filterflags]\n\t  -account string\n\t    \taccount that queued the message\n\t  -from string\n\t    \tfrom address of message, use \"@example.com\" to match all messages for a domain\n\t  -hold value\n\t    \ttrue or false, whether to match only messages that are (not) on hold\n\t  -ids value\n\t    \tcomma-separated list of message IDs\n\t  -n int\n\t    \tnumber of messages to return\n\t  -nextattempt string\n\t    \tfilter by time of next delivery attempt relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -submitted string\n\t    \tfilter by time of submission relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -to string\n\t    \trecipient address of message, use \"@example.com\" to match all messages for a domain\n\t  -transport value\n\t    \ttransport to use for messages, empty string sets the default behaviour\n\n# mox queue unhold\n\nMark matching messages off hold.\n\nOnce off hold, messages can be delivered according to their current next\ndelivery attempt. See the \"queue schedule\" command.\n\n\tusage: mox queue unhold [filterflags]\n\t  -account string\n\t    \taccount that queued the message\n\t  -from string\n\t    \tfrom address of message, use \"@example.com\" to match all messages for a domain\n\t  -hold value\n\t    \ttrue or false, whether to match only messages that are (not) on hold\n\t  -ids value\n\t    \tcomma-separated list of message IDs\n\t  -n int\n\t    \tnumber of messages to return\n\t  -nextattempt string\n\t    \tfilter by time of next delivery attempt relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -submitted string\n\t    \tfilter by time of submission relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -to string\n\t    \trecipient address of message, use \"@example.com\" to match all messages for a domain\n\t  -transport value\n\t    \ttransport to use for messages, empty string sets the default behaviour\n\n# mox queue schedule\n\nChange next delivery attempt for matching messages.\n\nThe next delivery attempt is adjusted by the duration parameter. If the -now\nflag is set, the new delivery attempt is set to the duration added to the\ncurrent time, instead of added to the current scheduled time.\n\nSchedule immediate delivery with \"mox queue schedule -now 0\".\n\n\tusage: mox queue schedule [filterflags] [-now] duration\n\t  -account string\n\t    \taccount that queued the message\n\t  -from string\n\t    \tfrom address of message, use \"@example.com\" to match all messages for a domain\n\t  -hold value\n\t    \ttrue or false, whether to match only messages that are (not) on hold\n\t  -ids value\n\t    \tcomma-separated list of message IDs\n\t  -n int\n\t    \tnumber of messages to return\n\t  -nextattempt string\n\t    \tfilter by time of next delivery attempt relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -now\n\t    \tschedule for duration relative to current time instead of relative to current next delivery attempt for messages\n\t  -submitted string\n\t    \tfilter by time of submission relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -to string\n\t    \trecipient address of message, use \"@example.com\" to match all messages for a domain\n\t  -transport value\n\t    \ttransport to use for messages, empty string sets the default behaviour\n\n# mox queue transport\n\nSet transport for matching messages.\n\nBy default, the routing rules determine how a message is delivered. The default\nand common case is direct delivery with SMTP. Messages can get a previously\nconfigured transport assigned to use for delivery, e.g. using submission to\nanother mail server or with connections over a SOCKS proxy.\n\n\tusage: mox queue transport [filterflags] transport\n\t  -account string\n\t    \taccount that queued the message\n\t  -from string\n\t    \tfrom address of message, use \"@example.com\" to match all messages for a domain\n\t  -hold value\n\t    \ttrue or false, whether to match only messages that are (not) on hold\n\t  -ids value\n\t    \tcomma-separated list of message IDs\n\t  -n int\n\t    \tnumber of messages to return\n\t  -nextattempt string\n\t    \tfilter by time of next delivery attempt relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -submitted string\n\t    \tfilter by time of submission relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -to string\n\t    \trecipient address of message, use \"@example.com\" to match all messages for a domain\n\t  -transport value\n\t    \ttransport to use for messages, empty string sets the default behaviour\n\n# mox queue requiretls\n\nSet TLS requirements for delivery of matching messages.\n\nValue \"yes\" is handled as if the RequireTLS extension was specified during\nsubmission.\n\nValue \"no\" is handled as if the message has a header \"TLS-Required: No\". This\nheader is not added by the queue. If messages without this header are relayed\nthrough other mail servers they will apply their own default TLS policy.\n\nValue \"default\" is the default behaviour, currently for unverified opportunistic\nTLS.\n\n\tusage: mox queue requiretls [filterflags] {yes | no | default}\n\t  -account string\n\t    \taccount that queued the message\n\t  -from string\n\t    \tfrom address of message, use \"@example.com\" to match all messages for a domain\n\t  -hold value\n\t    \ttrue or false, whether to match only messages that are (not) on hold\n\t  -ids value\n\t    \tcomma-separated list of message IDs\n\t  -n int\n\t    \tnumber of messages to return\n\t  -nextattempt string\n\t    \tfilter by time of next delivery attempt relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -submitted string\n\t    \tfilter by time of submission relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -to string\n\t    \trecipient address of message, use \"@example.com\" to match all messages for a domain\n\t  -transport value\n\t    \ttransport to use for messages, empty string sets the default behaviour\n\n# mox queue fail\n\nFail delivery of matching messages, delivering DSNs.\n\nFailing a message is handled similar to how delivery is given up after all\ndelivery attempts failed. The DSN (delivery status notification) message\ncontains a line saying the message was canceled by the admin.\n\n\tusage: mox queue fail [filterflags]\n\t  -account string\n\t    \taccount that queued the message\n\t  -from string\n\t    \tfrom address of message, use \"@example.com\" to match all messages for a domain\n\t  -hold value\n\t    \ttrue or false, whether to match only messages that are (not) on hold\n\t  -ids value\n\t    \tcomma-separated list of message IDs\n\t  -n int\n\t    \tnumber of messages to return\n\t  -nextattempt string\n\t    \tfilter by time of next delivery attempt relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -submitted string\n\t    \tfilter by time of submission relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -to string\n\t    \trecipient address of message, use \"@example.com\" to match all messages for a domain\n\t  -transport value\n\t    \ttransport to use for messages, empty string sets the default behaviour\n\n# mox queue drop\n\nRemove matching messages from the queue.\n\nDangerous operation, this completely removes the message. If you want to store\nthe message, use \"queue dump\" before removing.\n\n\tusage: mox queue drop [filterflags]\n\t  -account string\n\t    \taccount that queued the message\n\t  -from string\n\t    \tfrom address of message, use \"@example.com\" to match all messages for a domain\n\t  -hold value\n\t    \ttrue or false, whether to match only messages that are (not) on hold\n\t  -ids value\n\t    \tcomma-separated list of message IDs\n\t  -n int\n\t    \tnumber of messages to return\n\t  -nextattempt string\n\t    \tfilter by time of next delivery attempt relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -submitted string\n\t    \tfilter by time of submission relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -to string\n\t    \trecipient address of message, use \"@example.com\" to match all messages for a domain\n\t  -transport value\n\t    \ttransport to use for messages, empty string sets the default behaviour\n\n# mox queue dump\n\nDump a message from the queue.\n\nThe message is printed to stdout and is in standard internet mail format.\n\n\tusage: mox queue dump id\n\n# mox queue retired list\n\nList matching messages in the retired queue.\n\nPrints messages with their ID and results.\n\n\tusage: mox queue retired list [filtersortflags]\n\t  -account string\n\t    \taccount that queued the message\n\t  -asc\n\t    \tsort ascending instead of descending (default)\n\t  -from string\n\t    \tfrom address of message, use \"@example.com\" to match all messages for a domain\n\t  -ids value\n\t    \tcomma-separated list of retired message IDs\n\t  -lastactivity string\n\t    \tfilter by time of last activity relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -n int\n\t    \tnumber of messages to return\n\t  -result value\n\t    \t\"success\" or \"failure\" as result of delivery\n\t  -sort value\n\t    \tfield to sort by, \"lastactivity\" (default) or \"queued\"\n\t  -submitted string\n\t    \tfilter by time of submission relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -to string\n\t    \trecipient address of message, use \"@example.com\" to match all messages for a domain\n\t  -transport value\n\t    \ttransport to use for messages, empty string sets the default behaviour\n\n# mox queue retired print\n\nPrint a message from the retired queue.\n\nPrints a JSON representation of the information from the retired queue.\n\n\tusage: mox queue retired print id\n\n# mox queue suppress list\n\nPrint addresses in suppression list.\n\n\tusage: mox queue suppress list [-account account]\n\t  -account string\n\t    \tonly show suppression list for this account\n\n# mox queue suppress add\n\nAdd address to suppression list for account.\n\n\tusage: mox queue suppress add account address\n\n# mox queue suppress remove\n\nRemove address from suppression list for account.\n\n\tusage: mox queue suppress remove account address\n\n# mox queue suppress lookup\n\nCheck if address is present in suppression list, for any or specific account.\n\n\tusage: mox queue suppress lookup [-account account] address\n\t  -account string\n\t    \tonly check address in specified account\n\n# mox queue webhook list\n\nList matching webhooks in the queue.\n\nPrints list of webhooks, their IDs and basic information.\n\n\tusage: mox queue webhook list [filtersortflags]\n\t  -account string\n\t    \taccount that queued the message/webhook\n\t  -asc\n\t    \tsort ascending instead of descending (default)\n\t  -event value\n\t    \tevent this webhook is about: incoming, delivered, suppressed, delayed, failed, relayed, expanded, canceled, unrecognized\n\t  -ids value\n\t    \tcomma-separated list of webhook IDs\n\t  -n int\n\t    \tnumber of webhooks to return\n\t  -nextattempt string\n\t    \tfilter by time of next delivery attempt relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -sort value\n\t    \tfield to sort by, \"nextattempt\" (default) or \"queued\"\n\t  -submitted string\n\t    \tfilter by time of submission relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\n# mox queue webhook schedule\n\nChange next delivery attempt for matching webhooks.\n\nThe next delivery attempt is adjusted by the duration parameter. If the -now\nflag is set, the new delivery attempt is set to the duration added to the\ncurrent time, instead of added to the current scheduled time.\n\nSchedule immediate delivery with \"mox queue schedule -now 0\".\n\n\tusage: mox queue webhook schedule [filterflags] duration\n\t  -account string\n\t    \taccount that queued the message/webhook\n\t  -event value\n\t    \tevent this webhook is about: incoming, delivered, suppressed, delayed, failed, relayed, expanded, canceled, unrecognized\n\t  -ids value\n\t    \tcomma-separated list of webhook IDs\n\t  -n int\n\t    \tnumber of webhooks to return\n\t  -nextattempt string\n\t    \tfilter by time of next delivery attempt relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -now\n\t    \tschedule for duration relative to current time instead of relative to current next delivery attempt for webhooks\n\t  -submitted string\n\t    \tfilter by time of submission relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\n# mox queue webhook cancel\n\nFail delivery of matching webhooks.\n\n\tusage: mox queue webhook cancel [filterflags]\n\t  -account string\n\t    \taccount that queued the message/webhook\n\t  -event value\n\t    \tevent this webhook is about: incoming, delivered, suppressed, delayed, failed, relayed, expanded, canceled, unrecognized\n\t  -ids value\n\t    \tcomma-separated list of webhook IDs\n\t  -n int\n\t    \tnumber of webhooks to return\n\t  -nextattempt string\n\t    \tfilter by time of next delivery attempt relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -submitted string\n\t    \tfilter by time of submission relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\n# mox queue webhook print\n\nPrint details of a webhook from the queue.\n\nThe webhook is printed to stdout as JSON.\n\n\tusage: mox queue webhook print id\n\n# mox queue webhook retired list\n\nList matching webhooks in the retired queue.\n\nPrints list of retired webhooks, their IDs and basic information.\n\n\tusage: mox queue webhook retired list [filtersortflags]\n\t  -account string\n\t    \taccount that queued the message/webhook\n\t  -asc\n\t    \tsort ascending instead of descending (default)\n\t  -event value\n\t    \tevent this webhook is about: incoming, delivered, suppressed, delayed, failed, relayed, expanded, canceled, unrecognized\n\t  -ids value\n\t    \tcomma-separated list of retired webhook IDs\n\t  -lastactivity string\n\t    \tfilter by time of last activity relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\t  -n int\n\t    \tnumber of webhooks to return\n\t  -sort value\n\t    \tfield to sort by, \"lastactivity\" (default) or \"queued\"\n\t  -submitted string\n\t    \tfilter by time of submission relative to now, value must start with \"<\" (before now) or \">\" (after now)\n\n# mox queue webhook retired print\n\nPrint details of a webhook from the retired queue.\n\nThe retired webhook is printed to stdout as JSON.\n\n\tusage: mox queue webhook retired print id\n\n# mox import maildir\n\nImport a maildir into an account.\n\nThe mbox/maildir archive is accessed and imported by the running mox process, so\nit must have access to the archive files. The default suggested systemd service\nfile isolates mox from most of the file system, with only the \"data/\" directory\naccessible, so you may want to put the mbox/maildir archive files in a\ndirectory like \"data/import/\" to make it available to mox.\n\nBy default, messages will train the junk filter based on their flags and, if\n\"automatic junk flags\" configuration is set, based on mailbox naming.\n\nIf the destination mailbox is the Sent mailbox, the recipients of the messages\nare added to the message metadata, causing later incoming messages from these\nrecipients to be accepted, unless other reputation signals prevent that.\n\nUsers can also import mailboxes/messages through the account web page by\nuploading a zip or tgz file with mbox and/or maildirs.\n\nMessages are imported even if already present. Importing messages twice will\nresult in duplicate messages.\n\nMailbox flags, like \"seen\", \"answered\", will be imported. An optional\ndovecot-keywords file can specify additional flags, like Forwarded/Junk/NotJunk.\n\n\tusage: mox import maildir accountname mailboxname maildir\n\n# mox import mbox\n\nImport an mbox into an account.\n\nUsing mbox is not recommended, maildir is a better defined format.\n\nThe mbox/maildir archive is accessed and imported by the running mox process, so\nit must have access to the archive files. The default suggested systemd service\nfile isolates mox from most of the file system, with only the \"data/\" directory\naccessible, so you may want to put the mbox/maildir archive files in a\ndirectory like \"data/import/\" to make it available to mox.\n\nBy default, messages will train the junk filter based on their flags and, if\n\"automatic junk flags\" configuration is set, based on mailbox naming.\n\nIf the destination mailbox is the Sent mailbox, the recipients of the messages\nare added to the message metadata, causing later incoming messages from these\nrecipients to be accepted, unless other reputation signals prevent that.\n\nUsers can also import mailboxes/messages through the account web page by\nuploading a zip or tgz file with mbox and/or maildirs.\n\nMessages are imported even if already present. Importing messages twice will\nresult in duplicate messages.\n\n\tusage: mox import mbox accountname mailboxname mbox\n\n# mox export maildir\n\nExport one or all mailboxes from an account in maildir format.\n\nExport bypasses a running mox instance. It opens the account mailbox/message\ndatabase file directly. This may block if a running mox instance also has the\ndatabase open, e.g. for IMAP connections. To export from a running instance, use\nthe accounts web page or webmail.\n\n\tusage: mox export maildir [-single] dst-dir account-path [mailbox]\n\t  -single\n\t    \texport single mailbox, without any children. disabled if mailbox isn't specified.\n\n# mox export mbox\n\nExport messages from one or all mailboxes in an account in mbox format.\n\nUsing mbox is not recommended. Maildir is a better format.\n\nExport bypasses a running mox instance. It opens the account mailbox/message\ndatabase file directly. This may block if a running mox instance also has the\ndatabase open, e.g. for IMAP connections. To export from a running instance, use\nthe accounts web page or webmail.\n\nFor mbox export, \"mboxrd\" is used where message lines starting with the magic\n\"From \" string are escaped by prepending a >. All \">*From \" are escaped,\notherwise reconstructing the original could lose a \">\".\n\n\tusage: mox export mbox [-single] dst-dir account-path [mailbox]\n\t  -single\n\t    \texport single mailbox, without any children. disabled if mailbox isn't specified.\n\n# mox localserve\n\nStart a local SMTP/IMAP server that accepts all messages, useful when testing/developing software that sends email.\n\nLocalserve starts mox with a configuration suitable for local email-related\nsoftware development/testing. It listens for SMTP/Submission(s), IMAP(s) and\nHTTP(s), on the regular port numbers + 1000.\n\nData is stored in the system user's configuration directory under\n\"mox-localserve\", e.g. $HOME/.config/mox-localserve/ on linux, but can be\noverridden with the -dir flag. If the directory does not yet exist, it is\nautomatically initialized with configuration files, an account with email\naddress mox@localhost and password moxmoxmox, and a newly generated self-signed\nTLS certificate.\n\nIncoming messages are delivered as normal, falling back to accepting and\ndelivering to the mox account for unknown addresses.\nSubmitted messages are added to the queue, which delivers by ignoring the\ndestination servers, always connecting to itself instead.\n\nRecipient addresses with the following localpart suffixes are handled specially:\n\n- \"temperror\": fail with a temporary error code\n- \"permerror\": fail with a permanent error code\n- [45][0-9][0-9]: fail with the specific error code\n- \"timeout\": no response (for an hour)\n\nIf the localpart begins with \"mailfrom\" or \"rcptto\", the error is returned\nduring those commands instead of during \"data\".\n\n\tusage: mox localserve\n\t  -dir string\n\t    \tconfiguration storage directory (default \"$userconfigdir/mox-localserve\")\n\t  -initonly\n\t    \twrite configuration files and exit\n\t  -ip string\n\t    \tserve on this ip instead of default 127.0.0.1 and ::1. only used when writing configuration, at first launch.\n\n# mox help\n\nPrints help about matching commands.\n\nIf multiple commands match, they are listed along with the first line of their help text.\nIf a single command matches, its usage and full help text is printed.\n\n\tusage: mox help [command ...]\n\n# mox backup\n\nCreates a backup of the data directory.\n\nBackup creates consistent snapshots of the databases and message files and\ncopies other files in the data directory. Empty directories are not copied.\nThese files can then be stored elsewhere for long-term storage, or used to fall\nback to should an upgrade fail. Simply copying files in the data directory\nwhile mox is running can result in unusable database files.\n\nMessage files never change (they are read-only, though can be removed) and are\nhard-linked so they don't consume additional space. If hardlinking fails, for\nexample when the backup destination directory is on a different file system, a\nregular copy is made. Using a destination directory like \"data/tmp/backup\"\nincreases the odds hardlinking succeeds: the default systemd service file\nspecifically mounts the data directory, causing attempts to hardlink outside it\nto fail with an error about cross-device linking.\n\nAll files in the data directory that aren't recognized (i.e. other than known\ndatabase files, message files, an acme directory, the \"tmp\" directory, etc),\nare stored, but with a warning.\n\nRemove files in the destination directory before doing another backup. The\nbackup command will not overwrite files, but print and return errors.\n\nExit code 0 indicates the backup was successful. A clean successful backup does\nnot print any output, but may print warnings. Use the -verbose flag for\ndetails, including timing.\n\nTo restore a backup, first shut down mox, move away the old data directory and\nmove an earlier backed up directory in its place, run \"mox verifydata\",\npossibly with the \"-fix\" option, and restart mox. After the restore, you may\nalso want to run \"mox bumpuidvalidity\" for each account for which messages in a\nmailbox changed, to force IMAP clients to synchronize mailbox state.\n\nBefore upgrading, to check if the upgrade will likely succeed, first make a\nbackup, then use the new mox binary to run \"mox verifydata\" on the backup. This\ncan change the backup files (e.g. upgrade database files, move away\nunrecognized message files), so you should make a new backup before actually\nupgrading.\n\n\tusage: mox backup dest-dir\n\t  -verbose\n\t    \tprint progress\n\n# mox verifydata\n\nVerify the contents of a data directory, typically of a backup.\n\nVerifydata checks all database files to see if they are valid BoltDB/bstore\ndatabases. It checks that all messages in the database have a corresponding\non-disk message file and there are no unrecognized files. If option -fix is\nspecified, unrecognized message files are moved away. This may be needed after\na restore, because messages enqueued or delivered in the future may get those\nmessage sequence numbers assigned and writing the message file would fail.\nConsistency of message/mailbox UID, UIDNEXT and UIDVALIDITY is verified as\nwell.\n\nBecause verifydata opens the database files, schema upgrades may automatically\nbe applied. This can happen if you use a new mox release. It is useful to run\n\"mox verifydata\" with a new binary before attempting an upgrade, but only on a\ncopy of the database files, as made with \"mox backup\". Before upgrading, make a\nnew backup again since \"mox verifydata\" may have upgraded the database files,\npossibly making them potentially no longer readable by the previous version.\n\n\tusage: mox verifydata data-dir\n\t  -fix\n\t    \tfix fixable problems, such as moving away message files not referenced by their database\n\t  -skip-size-check\n\t    \tskip the check for message size\n\n# mox licenses\n\nPrint licenses of mox source code and dependencies.\n\n\tusage: mox licenses\n\n# mox config test\n\nParses and validates the configuration files.\n\nIf valid, the command exits with status 0. If not valid, all errors encountered\nare printed.\n\n\tusage: mox config test\n\n# mox config dnscheck\n\nCheck the DNS records with the configuration for the domain, and print any errors/warnings.\n\n\tusage: mox config dnscheck domain\n\n# mox config dnsrecords\n\nPrints annotated DNS records as zone file that should be created for the domain.\n\nThe zone file can be imported into existing DNS software. You should review the\nDNS records, especially if your domain previously/currently has email\nconfigured.\n\n\tusage: mox config dnsrecords domain\n\n# mox config describe-domains\n\nPrints an annotated empty configuration for use as domains.conf.\n\nThe domains configuration file contains the domains and their configuration,\nand accounts and their configuration. This includes the configured email\naddresses. The mox admin web interface, and the mox command line interface, can\nmake changes to this file. Mox automatically reloads this file when it changes.\n\nLike the static configuration, the example domains.conf printed by this command\nneeds modifications to make it valid.\n\n\tusage: mox config describe-domains >domains.conf\n\n# mox config describe-static\n\nPrints an annotated empty configuration for use as mox.conf.\n\nThe static configuration file cannot be reloaded while mox is running. Mox has\nto be restarted for changes to the static configuration file to take effect.\n\nThis configuration file needs modifications to make it valid. For example, it\nmay contain unfinished list items.\n\n\tusage: mox config describe-static >mox.conf\n\n# mox config account add\n\nAdd an account with an email address and reload the configuration.\n\nEmail can be delivered to this address/account. A password has to be configured\nexplicitly, see the setaccountpassword command.\n\n\tusage: mox config account add account address\n\n# mox config account rm\n\nRemove an account and reload the configuration.\n\nEmail addresses for this account will also be removed, and incoming email for\nthese addresses will be rejected.\n\nAll data for the account will be removed.\n\n\tusage: mox config account rm account\n\n# mox config address add\n\nAdds an address to an account and reloads the configuration.\n\nIf address starts with a @ (i.e. a missing localpart), this is a catchall\naddress for the domain.\n\n\tusage: mox config address add address account\n\n# mox config address rm\n\nRemove an address and reload the configuration.\n\nIncoming email for this address will be rejected after removing an address.\n\n\tusage: mox config address rm address\n\n# mox config domain add\n\nAdds a new domain to the configuration and reloads the configuration.\n\nThe account is used for the postmaster mailboxes the domain, including as DMARC and\nTLS reporting. Localpart is the \"username\" at the domain for this account. If\nmust be set if and only if account does not yet exist.\n\n\tusage: mox config domain add domain account [localpart]\n\n# mox config domain rm\n\nRemove a domain from the configuration and reload the configuration.\n\nThis is a dangerous operation. Incoming email delivery for this domain will be\nrejected.\n\n\tusage: mox config domain rm domain\n\n# mox config tlspubkey list\n\nList TLS public keys for TLS client certificate authentication.\n\nIf account is absent, the TLS public keys for all accounts are listed.\n\n\tusage: mox config tlspubkey list [account]\n\n# mox config tlspubkey get\n\nGet a TLS public key for a fingerprint.\n\nPrints the type, name, account and address for the key, and the certificate in\nPEM format.\n\n\tusage: mox config tlspubkey get fingerprint\n\n# mox config tlspubkey add\n\nAdd a TLS public key to the account of the given address.\n\nThe public key is read from the certificate.\n\nThe optional name is a human-readable descriptive name of the key. If absent,\nthe CommonName from the certificate is used.\n\n\tusage: mox config tlspubkey add address [name] < cert.pem\n\t  -no-imap-preauth\n\t    \tDon't automatically switch new IMAP connections authenticated with this key to \"authenticated\" state after the TLS handshake. For working around clients that ignore the untagged IMAP PREAUTH response and try to authenticate while already authenticated.\n\n# mox config tlspubkey rm\n\nRemove TLS public key for fingerprint.\n\n\tusage: mox config tlspubkey rm fingerprint\n\n# mox config tlspubkey gen\n\nGenerate an ed25519 private key and minimal certificate for use a TLS public key and write to files starting with stem.\n\nThe private key is written to $stem.$timestamp.ed25519privatekey.pkcs8.pem.\nThe certificate is written to $stem.$timestamp.certificate.pem.\nThe private key and certificate are also written to\n$stem.$timestamp.ed25519privatekey-certificate.pem.\n\nThe certificate can be added to an account with \"mox config account tlspubkey add\".\n\nThe combined file can be used with \"mox sendmail\".\n\nThe private key is also written to standard error in raw-url-base64-encoded\nform, also for use with \"mox sendmail\". The fingerprint is written to standard\nerror too, for reference.\n\n\tusage: mox config tlspubkey gen stem\n\n# mox config alias list\n\nShow aliases (lists) for domain.\n\n\tusage: mox config alias list domain\n\n# mox config alias print\n\nPrint settings and members of alias (list).\n\n\tusage: mox config alias print alias\n\n# mox config alias add\n\nAdd new alias (list) with one or more addresses and public posting enabled.\n\nAn alias is used for delivering incoming email to multiple recipients. If you\nwant to add an address to an account, don't use an alias, just add the address\nto the account.\n\n\tusage: mox config alias add alias@domain rcpt1@domain ...\n\n# mox config alias update\n\nUpdate alias (list) configuration.\n\n\tusage: mox config alias update alias@domain [-postpublic false|true -listmembers false|true -allowmsgfrom false|true]\n\t  -allowmsgfrom string\n\t    \twhether alias address can be used in message from header\n\t  -listmembers string\n\t    \twhether list members can list members\n\t  -postpublic string\n\t    \twhether anyone or only list members can post\n\n# mox config alias rm\n\nRemove alias (list).\n\n\tusage: mox config alias rm alias@domain\n\n# mox config alias addaddr\n\nAdd addresses to alias (list).\n\n\tusage: mox config alias addaddr alias@domain rcpt1@domain ...\n\n# mox config alias rmaddr\n\nRemove addresses from alias (list).\n\n\tusage: mox config alias rmaddr alias@domain rcpt1@domain ...\n\n# mox config describe-sendmail\n\nDescribe configuration for mox when invoked as sendmail.\n\n\tusage: mox config describe-sendmail >/etc/moxsubmit.conf\n\n# mox config printservice\n\nPrints a systemd unit service file for mox.\n\nThis is the same file as generated using quickstart. If the systemd service file\nhas changed with a newer version of mox, use this command to generate an up to\ndate version.\n\n\tusage: mox config printservice >mox.service\n\n# mox config ensureacmehostprivatekeys\n\nEnsure host private keys exist for TLS listeners with ACME.\n\nIn mox.conf, each listener can have TLS configured. Long-lived private key files\ncan be specified, which will be used when requesting ACME certificates.\nConfiguring these private keys makes it feasible to publish DANE TLSA records\nfor the corresponding public keys in DNS, protected with DNSSEC, allowing TLS\ncertificate verification without depending on a list of Certificate Authorities\n(CAs). Previous versions of mox did not pre-generate private keys for use with\nACME certificates, but would generate private keys on-demand. By explicitly\nconfiguring private keys, they will not change automatedly with new\ncertificates, and the DNS TLSA records stay valid.\n\nThis command looks for listeners in mox.conf with TLS with ACME configured. For\neach missing host private key (of type rsa-2048 and ecdsa-p256) a key is written\nto config/hostkeys/. If a certificate exists in the ACME \"cache\", its private\nkey is copied. Otherwise a new private key is generated. Snippets for manually\nupdating/editing mox.conf are printed.\n\nAfter running this command, and updating mox.conf, run \"mox config dnsrecords\"\nfor a domain and create the TLSA DNS records it suggests to enable DANE.\n\n\tusage: mox config ensureacmehostprivatekeys\n\n# mox config example\n\nList available config examples, or print a specific example.\n\n\tusage: mox config example [name]\n\n# mox checkupdate\n\nCheck if a newer version of mox is available.\n\nA single DNS TXT lookup to _updates.xmox.nl tells if a new version is\navailable. If so, a changelog is fetched from https://updates.xmox.nl, and the\nindividual entries verified with a builtin public key. The changelog is\nprinted.\n\n\tusage: mox checkupdate\n\n# mox cid\n\nTurn an ID from a Received header into a cid, for looking up in logs.\n\nA cid is essentially a connection counter initialized when mox starts. Each log\nline contains a cid. Received headers added by mox contain a unique ID that can\nbe decrypted to a cid by admin of a mox instance only.\n\n\tusage: mox cid cid\n\n# mox clientconfig\n\nPrint the configuration for email clients for a domain.\n\nSending email is typically not done on the SMTP port 25, but on submission\nports 465 (with TLS) and 587 (without initial TLS, but usually added to the\nconnection with STARTTLS). For IMAP, the port with TLS is 993 and without is\n143.\n\nWithout TLS/STARTTLS, passwords are sent in clear text, which should only be\nconfigured over otherwise secured connections, like a VPN.\n\n\tusage: mox clientconfig domain\n\n# mox dane dial\n\nDial the address using TLS with certificate verification using DANE.\n\nData is copied between connection and stdin/stdout until either side closes the\nconnection.\n\n\tusage: mox dane dial host:port\n\t  -usages string\n\t    \tallowed usages for dane, comma-separated list (default \"pkix-ta,pkix-ee,dane-ta,dane-ee\")\n\n# mox dane dialmx\n\nConnect to MX server for domain using STARTTLS verified with DANE.\n\nIf no destination host is specified, regular delivery logic is used to find the\nhosts to attempt delivery too. This involves following CNAMEs for the domain,\nlooking up MX records, and possibly falling back to the domain name itself as\nhost.\n\nIf a destination host is specified, that is the only candidate host considered\nfor dialing.\n\nWith a list of destinations gathered, each is dialed until a successful SMTP\nsession verified with DANE has been initialized, including EHLO and STARTTLS\ncommands.\n\nOnce connected, data is copied between connection and stdin/stdout, until\neither side closes the connection.\n\nThis command follows the same logic as delivery attempts made from the queue,\nsharing most of its code.\n\n\tusage: mox dane dialmx domain [destination-host]\n\t  -ehlohostname string\n\t    \thostname to send in smtp ehlo command (default \"localhost\")\n\n# mox dane makerecord\n\nPrint TLSA record for given certificate/key and parameters.\n\nValid values:\n- usage: pkix-ta (0), pkix-ee (1), dane-ta (2), dane-ee (3)\n- selector: cert (0), spki (1)\n- matchtype: full (0), sha2-256 (1), sha2-512 (2)\n\nCommon DANE TLSA record parameters are: dane-ee spki sha2-256, or 3 1 1,\nfollowed by a sha2-256 hash of the DER-encoded \"SPKI\" (subject public key info)\nfrom the certificate. An example DNS zone file entry:\n\n\t_25._tcp.example.com. TLSA 3 1 1 133b919c9d65d8b1488157315327334ead8d83372db57465ecabf53ee5748aee\n\nThe first usable information from the pem file is used to compose the TLSA\nrecord. In case of selector \"cert\", a certificate is required. Otherwise the\n\"subject public key info\" (spki) of the first certificate or public or private\nkey (pkcs#8, pkcs#1 or ec private key) is used.\n\n\tusage: mox dane makerecord usage selector matchtype [certificate.pem | publickey.pem | privatekey.pem]\n\n# mox dns lookup\n\nLookup DNS name of given type.\n\nLookup always prints whether the response was DNSSEC-protected.\n\nExamples:\n\nmox dns lookup ptr 1.1.1.1\nmox dns lookup mx xmox.nl\nmox dns lookup txt _dmarc.xmox.nl.\nmox dns lookup tlsa _25._tcp.xmox.nl\n\n\tusage: mox dns lookup [ptr | mx | cname | ips | a | aaaa | ns | txt | srv | tlsa] name\n\n# mox dkim gened25519\n\nGenerate a new ed25519 key for use with DKIM.\n\nEd25519 keys are much smaller than RSA keys of comparable cryptographic\nstrength. This is convenient because of maximum DNS message sizes. At the time\nof writing, not many mail servers appear to support ed25519 DKIM keys though,\nso it is recommended to sign messages with both RSA and ed25519 keys.\n\n\tusage: mox dkim gened25519 >$selector._domainkey.$domain.ed25519.privatekey.pkcs8.pem\n\n# mox dkim genrsa\n\nGenerate a new 2048 bit RSA private key for use with DKIM.\n\nThe generated file is in PEM format, and has a comment it is generated for use\nwith DKIM, by mox.\n\n\tusage: mox dkim genrsa >$selector._domainkey.$domain.rsa2048.privatekey.pkcs8.pem\n\n# mox dkim lookup\n\nLookup and print the DKIM record for the selector at the domain.\n\n\tusage: mox dkim lookup selector domain\n\n# mox dkim txt\n\nPrint a DKIM DNS TXT record with the public key derived from the private key read from stdin.\n\nThe DNS should be configured as a TXT record at $selector._domainkey.$domain.\n\n\tusage: mox dkim txt <$selector._domainkey.$domain.key.pkcs8.pem\n\n# mox dkim verify\n\nVerify the DKIM signatures in a message and print the results.\n\nThe message is parsed, and the DKIM-Signature headers are validated. Validation\nof older messages may fail because the DNS records have been removed or changed\nby now, or because the signature header may have specified an expiration time\nthat was passed.\n\n\tusage: mox dkim verify message\n\n# mox dkim sign\n\nSign a message, adding DKIM-Signature headers based on the domain in the From header.\n\nThe message is parsed, the domain looked up in the configuration files, and\nDKIM-Signature headers generated. The message is printed with the DKIM-Signature\nheaders prepended.\n\n\tusage: mox dkim sign message\n\n# mox dmarc lookup\n\nLookup dmarc policy for domain, a DNS TXT record at _dmarc.<domain>, validate and print it.\n\n\tusage: mox dmarc lookup domain\n\n# mox dmarc parsereportmsg\n\nParse a DMARC report from an email message, and print its extracted details.\n\nDMARC reports are periodically mailed, if requested in the DMARC DNS record of\na domain. Reports are sent by mail servers that received messages with our\ndomain in a From header. This may or may not be legatimate email. DMARC reports\ncontain summaries of evaluations of DMARC and DKIM/SPF, which can help\nunderstand email deliverability problems.\n\n\tusage: mox dmarc parsereportmsg message ...\n\n# mox dmarc verify\n\nParse an email message and evaluate it against the DMARC policy of the domain in the From-header.\n\nmailfromaddress and helodomain are used for SPF validation. If both are empty,\nSPF validation is skipped.\n\nmailfromaddress should be the address used as MAIL FROM in the SMTP session.\nFor DSN messages, that address may be empty. The helo domain was specified at\nthe beginning of the SMTP transaction that delivered the message. These values\ncan be found in message headers.\n\n\tusage: mox dmarc verify remoteip mailfromaddress helodomain < message\n\n# mox dmarc checkreportaddrs\n\nFor each reporting address in the domain's DMARC record, check if it has opted into receiving reports (if needed).\n\nA DMARC record can request reports about DMARC evaluations to be sent to an\nemail/http address. If the organizational domains of that of the DMARC record\nand that of the report destination address do not match, the destination\naddress must opt-in to receiving DMARC reports by creating a DMARC record at\n<dmarcdomain>._report._dmarc.<reportdestdomain>.\n\n\tusage: mox dmarc checkreportaddrs domain\n\n# mox dnsbl check\n\nTest if IP is in the DNS blocklist of the zone, e.g. bl.spamcop.net.\n\nIf the IP is in the blocklist, an explanation is printed. This is typically a\nURL with more information.\n\n\tusage: mox dnsbl check zone ip\n\n# mox dnsbl checkhealth\n\nCheck the health of the DNS blocklist represented by zone, e.g. bl.spamcop.net.\n\nThe health of a DNS blocklist can be checked by querying for 127.0.0.1 and\n127.0.0.2. The second must and the first must not be present.\n\n\tusage: mox dnsbl checkhealth zone\n\n# mox mtasts lookup\n\nLookup the MTASTS record and policy for the domain.\n\nMTA-STS is a mechanism for a domain to specify if it requires TLS connections\nfor delivering email. If a domain has a valid MTA-STS DNS TXT record at\n_mta-sts.<domain> it signals it implements MTA-STS. A policy can then be\nfetched at https://mta-sts.<domain>/.well-known/mta-sts.txt. The policy\nspecifies the mode (enforce, testing, none), which MX servers support TLS and\nshould be used, and how long the policy can be cached.\n\n\tusage: mox mtasts lookup domain\n\n# mox retrain\n\nRecreate and retrain the junk filter for the account or all accounts.\n\nUseful after having made changes to the junk filter configuration, or if the\nimplementation has changed.\n\n\tusage: mox retrain [accountname]\n\n# mox sendmail\n\nSendmail is a drop-in replacement for /usr/sbin/sendmail to deliver emails sent by unix processes like cron.\n\nIf invoked as \"sendmail\", it will act as sendmail for sending messages. Its\nintention is to let processes like cron send emails. Messages are submitted to\nan actual mail server over SMTP. The destination mail server and credentials are\nconfigured in /etc/moxsubmit.conf, see mox config describe-sendmail. The From\nmessage header is rewritten to the configured address. When the addressee\nappears to be a local user, because without @, the message is sent to the\nconfigured default address.\n\nIf submitting an email fails, it is added to a directory moxsubmit.failures in\nthe user's home directory.\n\nMost flags are ignored to fake compatibility with other sendmail\nimplementations. A single recipient or the -t flag with a To-header is required.\nWith the -t flag, Cc and Bcc headers are not handled specially, so Bcc is not\nremoved and the addresses do not receive the email.\n\n/etc/moxsubmit.conf should be group-readable and not readable by others and this\nbinary should be setgid that group:\n\n\tgroupadd moxsubmit\n\tinstall -m 2755 -o root -g moxsubmit mox /usr/sbin/sendmail\n\ttouch /etc/moxsubmit.conf\n\tchown root:moxsubmit /etc/moxsubmit.conf\n\tchmod 640 /etc/moxsubmit.conf\n\t# edit /etc/moxsubmit.conf\n\n\n\tusage: mox sendmail [-Fname] [ignoredflags] [-t] [<message]\n\n# mox spf check\n\nCheck the status of IP for the policy published in DNS for the domain.\n\nIPs may be allowed to send for a domain, or disallowed, and several shades in\nbetween. If not allowed, an explanation may be provided by the policy. If so,\nthe explanation is printed. The SPF mechanism that matched (if any) is also\nprinted.\n\n\tusage: mox spf check domain ip\n\n# mox spf lookup\n\nLookup the SPF record for the domain and print it.\n\n\tusage: mox spf lookup domain\n\n# mox spf parse\n\nParse the record as SPF record. If valid, nothing is printed.\n\n\tusage: mox spf parse txtrecord\n\n# mox tlsrpt lookup\n\nLookup the TLSRPT record for the domain.\n\nA TLSRPT record typically contains an email address where reports about TLS\nconnectivity should be sent. Mail servers attempting delivery to our domain\nshould attempt to use TLS. TLSRPT lets them report how many connection\nsuccessfully used TLS, and how what kind of errors occurred otherwise.\n\n\tusage: mox tlsrpt lookup domain\n\n# mox tlsrpt parsereportmsg\n\nParse and print the TLSRPT in the message.\n\nThe report is printed in formatted JSON.\n\n\tusage: mox tlsrpt parsereportmsg message ...\n\n# mox version\n\nPrints this mox version.\n\n\tusage: mox version\n\n# mox webapi\n\nLists available methods, prints request/response parameters for method, or calls a method with a request read from standard input.\n\n\tusage: mox webapi [method [baseurl-with-credentials]\n\n# mox example\n\nList available examples, or print a specific example.\n\n\tusage: mox example [name]\n\n# mox bumpuidvalidity\n\nChange the IMAP UID validity of the mailbox, causing IMAP clients to refetch messages.\n\nThis can be useful after manually repairing metadata about the account/mailbox.\n\nOpens account database file directly. Ensure mox does not have the account\nopen, or is not running.\n\n\tusage: mox bumpuidvalidity account [mailbox]\n\n# mox reassignuids\n\nReassign UIDs in one mailbox or all mailboxes in an account and bump UID validity, causing IMAP clients to refetch messages.\n\nOpens account database file directly. Ensure mox does not have the account\nopen, or is not running.\n\n\tusage: mox reassignuids account [mailboxid]\n\n# mox fixuidmeta\n\nFix inconsistent UIDVALIDITY and UIDNEXT in messages/mailboxes/account.\n\nThe next UID to use for a message in a mailbox should always be higher than any\nexisting message UID in the mailbox. If it is not, the mailbox UIDNEXT is\nupdated.\n\nEach mailbox has a UIDVALIDITY sequence number, which should always be lower\nthan the per-account next UIDVALIDITY to use. If it is not, the account next\nUIDVALIDITY is updated.\n\nOpens account database file directly. Ensure mox does not have the account\nopen, or is not running.\n\n\tusage: mox fixuidmeta account\n\n# mox fixmsgsize\n\nEnsure message sizes in the database matching the sum of the message prefix length and on-disk file size.\n\nMessages with an inconsistent size are also parsed again.\n\nIf an inconsistency is found, you should probably also run \"mox\nbumpuidvalidity\" on the mailboxes or entire account to force IMAP clients to\nrefetch messages.\n\n\tusage: mox fixmsgsize [account]\n\n# mox reparse\n\nParse all messages in the account or all accounts again.\n\nCan be useful after upgrading mox with improved message parsing. Messages are\nparsed in batches, so other access to the mailboxes/messages are not blocked\nwhile reparsing all messages.\n\n\tusage: mox reparse [account]\n\n# mox ensureparsed\n\nEnsure messages in the database have a pre-parsed MIME form in the database.\n\n\tusage: mox ensureparsed account\n\t  -all\n\t    \tstore new parsed message for all messages\n\n# mox recalculatemailboxcounts\n\nRecalculate message counts for all mailboxes in the account, and total message size for quota.\n\nWhen a message is added to/removed from a mailbox, or when message flags change,\nthe total, unread, unseen and deleted messages are accounted, the total size of\nthe mailbox, and the total message size for the account. In case of a bug in\nthis accounting, the numbers could become incorrect. This command will find, fix\nand print them.\n\n\tusage: mox recalculatemailboxcounts account\n\n# mox message parse\n\nParse message, print JSON representation.\n\n\tusage: mox message parse message.eml\n\t  -smtputf8\n\t    \tcheck if message needs smtputf8\n\n# mox reassignthreads\n\nReassign message threads.\n\nFor all accounts, or optionally only the specified account.\n\nThreading for all messages in an account is first reset, and new base subject\nand normalized message-id saved with the message. Then all messages are\nevaluated and matched against their parents/ancestors.\n\nMessages are matched based on the References header, with a fall-back to an\nIn-Reply-To header, and if neither is present/valid, based only on base\nsubject.\n\nA References header typically points to multiple previous messages in a\nhierarchy. From oldest ancestor to most recent parent. An In-Reply-To header\nwould have only a message-id of the parent message.\n\nA message is only linked to a parent/ancestor if their base subject is the\nsame. This ensures unrelated replies, with a new subject, are placed in their\nown thread.\n\nThe base subject is lower cased, has whitespace collapsed to a single\nspace, and some components removed: leading \"Re:\", \"Fwd:\", \"Fw:\", or bracketed\ntag (that mailing lists often add, e.g. \"[listname]\"), trailing \"(fwd)\", or\nenclosing \"[fwd: ...]\".\n\nMessages are linked to all their ancestors. If an intermediate parent/ancestor\nmessage is deleted in the future, the message can still be linked to the earlier\nancestors. If the direct parent already wasn't available while matching, this is\nstored as the message having a \"missing link\" to its stored ancestors.\n\n\tusage: mox reassignthreads [account]\n*/\npackage main\n\n// NOTE: DO NOT EDIT, this file is generated by gendoc.sh.\n"
        },
        {
          "name": "docker-compose-imaptest.yml",
          "type": "blob",
          "size": 0.857421875,
          "content": "version: '3.7'\nservices:\n  mox:\n    build:\n      context: .\n      dockerfile: Dockerfile.moximaptest\n    volumes:\n      - ./testdata/imaptest/config:/mox/config\n      - ./testdata/imaptest/data:/mox/data\n      - ./testdata/imaptest/imaptest.mbox:/mox/imaptest.mbox\n    working_dir: /mox\n    tty: true # For job control with set -m.\n    command: sh -c 'set -m; mox serve & sleep 1; echo testtest | mox setaccountpassword mjl; fg'\n    healthcheck:\n      test: netstat -nlt | grep ':1143 '\n      interval: 1s\n      timeout: 1s\n      retries: 10\n\n  imaptest:\n    build:\n      dockerfile: Dockerfile.imaptest\n      context: .\n    command: host=mox port=1143 'user=mjl@mox.example' pass=testtest mbox=/imaptest/imaptest.mbox\n    working_dir: /imaptest\n    volumes:\n      - ./testdata/imaptest:/imaptest\n    depends_on:\n      mox:\n        condition: service_healthy\n    restart: never\n"
        },
        {
          "name": "docker-compose-integration.yml",
          "type": "blob",
          "size": 6.21484375,
          "content": "version: '3.7'\nservices:\n  # We run integration_test.go from this container, it connects to the other mox instances.\n  test:\n    hostname: test.mox1.example\n    image: mox_integration_test\n    # We add our cfssl-generated CA (which is in the repo) and acme pebble CA\n    # (generated each time pebble starts) to the list of trusted CA's, so the TLS\n    # dials in integration_test.go succeed.\n    command: [\"sh\", \"-c\", \"set -ex; cat /integration/tmp-pebble-ca.pem /integration/tls/ca.pem >>/etc/ssl/certs/ca-certificates.crt; go test -tags integration\"]\n    volumes:\n      - ./.go:/.go\n      - ./testdata/integration/resolv.conf:/etc/resolv.conf\n      - ./testdata/integration:/integration\n      - ./testdata/integration/moxsubmit.conf:/etc/moxsubmit.conf\n      - .:/mox\n    environment:\n      GOCACHE: /.go/.cache/go-build\n    depends_on:\n      dns:\n        condition: service_healthy\n      # moxmail2 depends on moxacmepebble, we connect to both.\n      moxmail2:\n        condition: service_healthy\n      postfixmail:\n        condition: service_healthy\n      localserve:\n        condition: service_healthy\n    networks:\n      mailnet1:\n        ipv4_address: 172.28.1.50\n\n  # First mox instance that uses ACME with pebble.\n  moxacmepebble:\n    hostname: moxacmepebble.mox1.example\n    domainname: mox1.example\n    image: mox_integration_moxmail\n    environment:\n      MOX_UID: \"${MOX_UID}\"\n    command: [\"sh\", \"-c\", \"/integration/moxacmepebble.sh\"]\n    volumes:\n      - ./testdata/integration/resolv.conf:/etc/resolv.conf\n      - ./testdata/integration:/integration\n    healthcheck:\n      test: netstat -nlt | grep ':25 '\n      interval: 1s\n      timeout: 1s\n      retries: 10\n    depends_on:\n      dns:\n        condition: service_healthy\n      acmepebble:\n        condition: service_healthy\n    networks:\n      mailnet1:\n        ipv4_address: 172.28.1.10\n\n  # Second mox instance, with TLS cert/keys from files.\n  moxmail2:\n    hostname: moxmail2.mox2.example\n    domainname: mox2.example\n    image: mox_integration_moxmail\n    environment:\n      MOX_UID: \"${MOX_UID}\"\n    command: [\"sh\", \"-c\", \"/integration/moxmail2.sh\"]\n    volumes:\n      - ./testdata/integration/resolv.conf:/etc/resolv.conf\n      - ./testdata/integration:/integration\n    healthcheck:\n      test: netstat -nlt | grep ':25 '\n      interval: 1s\n      timeout: 1s\n      retries: 10\n    depends_on:\n      dns:\n        condition: service_healthy\n      acmepebble:\n        condition: service_healthy\n      # moxacmepebble creates tmp-pebble-ca.pem, needed by moxmail2 to trust the certificates offered by moxacmepebble.\n      moxacmepebble:\n        condition: service_healthy\n    networks:\n      mailnet1:\n        ipv4_address: 172.28.1.20\n\n  localserve:\n    hostname: localserve.mox1.example\n    domainname: mox1.example\n    image: mox_integration_moxmail\n    command: [\"sh\", \"-c\", \"set -e; chmod o+r /etc/resolv.conf; mox -checkconsistency localserve -ip 172.28.1.60\"]\n    volumes:\n      - ./.go:/.go\n      - ./testdata/integration/resolv.conf:/etc/resolv.conf\n      - .:/mox\n    environment:\n      GOCACHE: /.go/.cache/go-build\n    healthcheck:\n      test: netstat -nlt | grep ':1025 '\n      interval: 1s\n      timeout: 1s\n      retries: 10\n    depends_on:\n      dns:\n        condition: service_healthy\n    networks:\n      mailnet1:\n        ipv4_address: 172.28.1.60\n\n  postfixmail:\n    hostname: postfixmail.postfix.example\n    domainname: postfix.example\n    build:\n      dockerfile: Dockerfile.postfix\n      context: testdata/integration\n    volumes:\n      # todo: figure out how to mount files with a uid that the process in the container can read...\n      - ./testdata/integration/resolv.conf:/etc/resolv.conf\n    command: [\"sh\", \"-c\", \"set -e; chmod o+r /etc/resolv.conf; (echo 'maillog_file = /dev/stdout'; echo 'mydestination = $$myhostname, localhost.$$mydomain, localhost, $$mydomain'; echo 'smtp_tls_security_level = may') >>/etc/postfix/main.cf; echo 'root: postfix@mox1.example' >>/etc/postfix/aliases; newaliases; postfix start-fg\"]\n    healthcheck:\n      test: netstat -nlt | grep ':25 '\n      interval: 1s\n      timeout: 1s\n      retries: 10\n    depends_on:\n      dns:\n        condition: service_healthy\n    networks:\n      mailnet1:\n        ipv4_address: 172.28.1.70\n\n  dns:\n    hostname: dns.example\n    build:\n      dockerfile: Dockerfile.dns\n      # todo: figure out how to build from dockerfile with empty context without creating empty dirs in file system.\n      context: testdata/integration\n    volumes:\n      - ./testdata/integration/resolv.conf:/etc/resolv.conf\n      - ./testdata/integration:/integration\n    # We start with a base example.zone, but moxacmepebble appends its records,\n    # followed by moxmail2. They restart unbound after appending records.\n    command: [\"sh\", \"-c\", \"set -ex; ls -l /etc/resolv.conf; chmod o+r /etc/resolv.conf; install -m 640 -o unbound /integration/unbound.conf /etc/unbound/; chmod 755 /integration; chmod 644 /integration/*.zone; cp /integration/example.zone /integration/example-integration.zone; ls -ld /integration /integration/reverse.zone; unbound -d -p -v\"]\n    healthcheck:\n      test: netstat -nlu | grep '172.28.1.30:53 '\n      interval: 1s\n      timeout: 1s\n      retries: 10\n    networks:\n      mailnet1:\n        ipv4_address: 172.28.1.30\n\n  # pebble is a small acme server useful for testing. It creates a new CA\n  # certificate each time it starts, so we go through some trouble to configure the\n  # certificate in moxacmepebble and moxmail2.\n  acmepebble:\n    hostname: acmepebble.example\n    image: docker.io/letsencrypt/pebble:v2.3.1@sha256:fc5a537bf8fbc7cc63aa24ec3142283aa9b6ba54529f86eb8ff31fbde7c5b258\n    volumes:\n      - ./testdata/integration/resolv.conf:/etc/resolv.conf\n      - ./testdata/integration:/integration\n    command: [\"sh\", \"-c\", \"set -ex; mount; ls -l /etc/resolv.conf; chmod o+r /etc/resolv.conf; pebble -config /integration/pebble-config.json\"]\n    ports:\n      - 14000:14000  # ACME port\n      - 15000:15000  # Management port\n    healthcheck:\n      test: netstat -nlt | grep ':14000 '\n      interval: 1s\n      timeout: 1s\n      retries: 10\n    depends_on:\n      dns:\n        condition: service_healthy\n    networks:\n      mailnet1:\n        ipv4_address: 172.28.1.40\n\nnetworks:\n  mailnet1:\n    driver: bridge\n    ipam:\n      driver: default\n      config:\n        - subnet: \"172.28.1.0/24\"\n"
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 1.783203125,
          "content": "# Before launching mox, run the quickstart to create config files for running as\n# user the mox user (create it on the host system first, e.g. \"useradd -d $PWD mox\"):\n#\n#\tmkdir config data web\n# \tdocker-compose run mox mox quickstart you@yourdomain.example $(id -u mox)\n#\n# note: if you are running quickstart on a different machine than you will deploy\n# mox to, use the \"quickstart -hostname ...\" flag.\n#\n# After following the quickstart instructions you can start mox:\n#\n# \tdocker-compose up\n#\n#\n# If you want to run \"mox localserve\", you could start it like this:\n#\n#\tdocker run \\\n#\t\t-p 127.0.0.1:25:1025 \\\n#\t\t-p 127.0.0.1:465:1465 \\\n#\t\t-p 127.0.0.1:587:1587 \\\n#\t\t-p 127.0.0.1:993:1993 \\\n#\t\t-p 127.0.0.1:143:1143 \\\n#\t\t-p 127.0.0.1:443:1443 \\\n#\t\t-p 127.0.0.1:80:1080 \\\n#\t\tr.xmox.nl/mox:latest mox localserve -ip 0.0.0.0\n#\n# The -ip flag ensures connections to the published ports make it to mox, and it\n# prevents listening on ::1 (IPv6 is not enabled in docker by default).\n\nversion: '3.7'\nservices:\n  mox:\n    # Replace \"latest\" with the version you want to run, see https://r.xmox.nl/r/mox/.\n    # Include the @sha256:... digest to ensure you get the listed image.\n    image: r.xmox.nl/mox:latest\n    environment:\n      - MOX_DOCKER=yes # Quickstart won't try to write systemd service file.\n    # Mox needs host networking because it needs access to the IPs of the\n    # machine, and the IPs of incoming connections for spam filtering.\n    network_mode: 'host'\n    volumes:\n      - ./config:/mox/config\n      - ./data:/mox/data\n      # web is optional but recommended to bind in, useful for serving static files with\n      # the webserver.\n      - ./web:/mox/web\n    working_dir: /mox\n    restart: on-failure\n    healthcheck:\n      test: netstat -nlt | grep ':25 '\n      interval: 1s\n      timeout: 1s\n      retries: 10\n"
        },
        {
          "name": "docker-release.sh",
          "type": "blob",
          "size": 2.630859375,
          "content": "#!/bin/sh\n\n# Abort on error.\nset -e\n\n# We are using podman because docker generates errors when it's in the second\n# stage and copies a non-linux/amd64 binary from the first stage that is\n# linux/amd64.\n\n# The platforms we build for (what alpine supports).\nplatforms=linux/amd64,linux/arm64,linux/arm,linux/386,linux/ppc64le,linux/s390x\n# todo: linux/riscv64 currently absent for alpine:latest, only at alpine:edge\n\n# We are building by \"go install github.com/mjl-/mox@$moxversion\", to ensure the\n# binary gets a proper version stamped into its buildinfo. It also helps to ensure\n# there is no accidental local change in the image.\nmoxversion=$(go list -mod mod -m github.com/mjl-/mox@$(git rev-parse HEAD) | cut -f2 -d' ')\necho Building mox $moxversion for $platforms, without local/uncommitted changes\n\n# Ensure latest golang and alpine docker images.\npodman image pull --quiet docker.io/golang:1-alpine\nfor i in $(echo $platforms | sed 's/,/ /g'); do\n\tpodman image pull --quiet --platform $i docker.io/alpine:latest\ndone\n# \"Last pulled\" apparently is the one used for \"podman run\" below, not the one\n# that matches the platform. So pull for current platform again.\npodman image pull --quiet docker.io/alpine:latest\n\n# Get the goland and alpine versions from the docker images.\ngoversion=$(podman run golang:1-alpine go version | cut -f3 -d' ')\nalpineversion=alpine$(podman run alpine:latest cat /etc/alpine-release)\n# We assume the alpines for all platforms have the same version...\necho Building with $goversion and $alpineversion\n\n# We build the images individually so we can pass goos and goarch ourselves,\n# needed because the platform in \"FROM --platform <image>\" in the first stage\n# seems to override the TARGET* variables.\ntest -d empty || mkdir empty\n((rm -r tmp/gomod || exit 0); mkdir -p tmp/gomod) # fetch modules through goproxy just once\n(podman manifest rm mox:$moxversion-$goversion-$alpineversion || exit 0)\nfor platform in $(echo $platforms | sed 's/,/ /g'); do\n\tgoos=$(echo $platform | sed 's,/.*$,,')\n\tgoarch=$(echo $platform | sed 's,^.*/,,')\n\tpodman build --platform $platform -f Dockerfile.release -v $HOME/go/pkg/sumdb:/go/pkg/sumbd:ro -v $PWD/tmp/gomod:/go/pkg/mod --build-arg goos=$goos --build-arg goarch=$goarch --build-arg moxversion=$moxversion --manifest mox:$moxversion-$goversion-$alpineversion empty\ndone\n\ncat <<EOF\n\n# Suggested commands to push images:\n\npodman manifest push --all mox:$moxversion-$goversion-$alpineversion \\$host/mox:$moxversion-$goversion-$alpineversion\n\npodman manifest push --all mox:$moxversion-$goversion-$alpineversion \\$host/mox:$moxversion\npodman manifest push --all mox:$moxversion-$goversion-$alpineversion \\$host/mox:latest\nEOF\n"
        },
        {
          "name": "dsn",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples.go",
          "type": "blob",
          "size": 9.9609375,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"encoding/base64\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"log\"\n\t\"reflect\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/mjl-/sconf\"\n\n\t\"github.com/mjl-/mox/config\"\n\t\"github.com/mjl-/mox/mox-\"\n\t\"github.com/mjl-/mox/smtp\"\n\t\"github.com/mjl-/mox/webhook\"\n)\n\nfunc cmdExample(c *cmd) {\n\tc.params = \"[name]\"\n\tc.help = `List available examples, or print a specific example.`\n\n\targs := c.Parse()\n\tif len(args) > 1 {\n\t\tc.Usage()\n\t}\n\n\tvar match func() string\n\tfor _, ex := range examples {\n\t\tif len(args) == 0 {\n\t\t\tfmt.Println(ex.Name)\n\t\t} else if args[0] == ex.Name {\n\t\t\tmatch = ex.Get\n\t\t}\n\t}\n\tif len(args) == 0 {\n\t\treturn\n\t}\n\tif match == nil {\n\t\tlog.Fatalln(\"not found\")\n\t}\n\tfmt.Print(match())\n}\n\nfunc cmdConfigExample(c *cmd) {\n\tc.params = \"[name]\"\n\tc.help = `List available config examples, or print a specific example.`\n\n\targs := c.Parse()\n\tif len(args) > 1 {\n\t\tc.Usage()\n\t}\n\n\tvar match func() string\n\tfor _, ex := range configExamples {\n\t\tif len(args) == 0 {\n\t\t\tfmt.Println(ex.Name)\n\t\t} else if args[0] == ex.Name {\n\t\t\tmatch = ex.Get\n\t\t}\n\t}\n\tif len(args) == 0 {\n\t\treturn\n\t}\n\tif match == nil {\n\t\tlog.Fatalln(\"not found\")\n\t}\n\tfmt.Print(match())\n}\n\nvar configExamples = []struct {\n\tName string\n\tGet  func() string\n}{\n\t{\n\t\t\"webhandlers\",\n\t\tfunc() string {\n\t\t\tconst webhandlers = `# Snippet of domains.conf to configure WebDomainRedirects and WebHandlers.\n\n# Redirect all requests for mox.example to https://www.mox.example.\nWebDomainRedirects:\n\tmox.example: www.mox.example\n\n# Each request is matched against these handlers until one matches and serves it.\nWebHandlers:\n\t-\n\t\t# Redirect all plain http requests to https, leaving path, query strings, etc\n\t\t# intact. When the request is already to https, the destination URL would have the\n\t\t# same scheme, host and path, causing this redirect handler to not match the\n\t\t# request (and not cause a redirect loop) and the webserver to serve the request\n\t\t# with a later handler.\n\t\tLogName: redirhttps\n\t\tDomain: www.mox.example\n\t\tPathRegexp: ^/\n\t\t# Could leave DontRedirectPlainHTTP at false if it wasn't for this being an\n\t\t# example for doing this redirect.\n\t\tDontRedirectPlainHTTP: true\n\t\tWebRedirect:\n\t\t\tBaseURL: https://www.mox.example\n\t-\n\t\t# The name of the handler, used in logging and metrics.\n\t\tLogName: staticmjl\n\t\t# With ACME configured, each configured domain will automatically get a TLS\n\t\t# certificate on first request.\n\t\tDomain: www.mox.example\n\t\tPathRegexp: ^/who/mjl/\n\t\tWebStatic:\n\t\t\tStripPrefix: /who/mjl\n\t\t\t# Requested path /who/mjl/inferno/ resolves to local web/mjl/inferno.\n\t\t\t# If a directory contains an index.html, it is served when a directory is requested.\n\t\t\tRoot: web/mjl\n\t\t\t# With ListFiles true, if a directory does not contain an index.html, the contents are listed.\n\t\t\tListFiles: true\n\t\t\tResponseHeaders:\n\t\t\t\tX-Mox: hi\n\t-\n\t\tLogName: redir\n\t\tDomain: www.mox.example\n\t\tPathRegexp: ^/redir/a/b/c\n\t\t# Don't redirect from plain HTTP to HTTPS.\n\t\tDontRedirectPlainHTTP: true\n\t\tWebRedirect:\n\t\t\t# Just change the domain and add query string set fragment. No change to scheme.\n\t\t\t# Path will start with /redir/a/b/c (and whathever came after) because no\n\t\t\t# OrigPathRegexp+ReplacePath is set.\n\t\t\tBaseURL: //moxest.example?q=1#frag\n\t\t\t# Default redirection is 308 - Permanent Redirect.\n\t\t\tStatusCode: 307\n\t-\n\t\tLogName: oldnew\n\t\tDomain: www.mox.example\n\t\tPathRegexp: ^/old/\n\t\tWebRedirect:\n\t\t\t# Replace path, leaving rest of URL intact.\n\t\t\tOrigPathRegexp: ^/old/(.*)\n\t\t\tReplacePath: /new/$1\n\t-\n\t\tLogName: app\n\t\tDomain: www.mox.example\n\t\tPathRegexp: ^/app/\n\t\tWebForward:\n\t\t\t# Strip the path matched by PathRegexp before forwarding the request. So original\n\t\t\t# request /app/api become just /api.\n\t\t\tStripPath: true\n\t\t\t# URL of backend, where requests are forwarded to. The path in the URL is kept,\n\t\t\t# so for incoming request URL /app/api, the outgoing request URL has path /app-v2/api.\n\t\t\t# Requests are made with Go's net/http DefaultTransporter, including using\n\t\t\t# HTTP_PROXY and HTTPS_PROXY environment variables.\n\t\t\tURL: http://127.0.0.1:8900/app-v2/\n\t\t\t# Add headers to response.\n\t\t\tResponseHeaders:\n\t\t\t\tX-Frame-Options: deny\n\t\t\t\tX-Content-Type-Options: nosniff\n`\n\t\t\t// Parse just so we know we have the syntax right.\n\t\t\t// todo: ideally we would have a complete config file and parse it fully.\n\t\t\tvar conf struct {\n\t\t\t\tWebDomainRedirects map[string]string\n\t\t\t\tWebHandlers        []config.WebHandler\n\t\t\t}\n\t\t\terr := sconf.Parse(strings.NewReader(webhandlers), &conf)\n\t\t\txcheckf(err, \"parsing webhandlers example\")\n\t\t\treturn webhandlers\n\t\t},\n\t},\n\t{\n\t\t\"transport\",\n\t\tfunc() string {\n\t\t\tconst moxconf = `# Snippet for mox.conf, defining a transport called Example that connects on the\n# SMTP submission with TLS port 465 (\"submissions\"), authenticating with\n# SCRAM-SHA-256-PLUS (other providers may not support SCRAM-SHA-256-PLUS, but they\n# typically do support the older CRAM-MD5).:\n\n# Transport are mechanisms for delivering messages. Transports can be referenced\n# from Routes in accounts, domains and the global configuration. There is always\n# an implicit/fallback delivery transport doing direct delivery with SMTP from the\n# outgoing message queue. Transports are typically only configured when using\n# smarthosts, i.e. when delivering through another SMTP server. Zero or one\n# transport methods must be set in a transport, never multiple. When using an\n# external party to send email for a domain, keep in mind you may have to add\n# their IP address to your domain's SPF record, and possibly additional DKIM\n# records. (optional)\nTransports:\n\tExample:\n\t\t# Submission SMTP over a TLS connection to submit email to a remote queue.\n\t\t# (optional)\n\t\tSubmissions:\n\t\t\t# Host name to connect to and for verifying its TLS certificate.\n\t\t\tHost: smtp.example.com\n\n\t\t\t# If set, authentication credentials for the remote server. (optional)\n\t\t\tAuth:\n\t\t\t\tUsername: user@example.com\n\t\t\t\tPassword: test1234\n\t\t\t\tMechanisms:\n\t\t\t\t\t# Allowed authentication mechanisms. Defaults to SCRAM-SHA-256-PLUS,\n\t\t\t\t\t# SCRAM-SHA-256, SCRAM-SHA-1-PLUS, SCRAM-SHA-1, CRAM-MD5. Not included by default:\n\t\t\t\t\t# PLAIN. Specify the strongest mechanism known to be implemented by the server to\n\t\t\t\t\t# prevent mechanism downgrade attacks. (optional)\n\n\t\t\t\t\t- SCRAM-SHA-256-PLUS\n`\n\n\t\t\tconst domainsconf = `# Snippet for domains.conf, specifying a route that sends through the transport:\n\n# Routes for delivering outgoing messages through the queue. Each delivery attempt\n# evaluates account routes, domain routes and finally these global routes. The\n# transport of the first matching route is used in the delivery attempt. If no\n# routes match, which is the default with no configured routes, messages are\n# delivered directly from the queue. (optional)\nRoutes:\n\t-\n\t\tTransport: Example\n`\n\n\t\t\tvar static struct {\n\t\t\t\tTransports map[string]config.Transport\n\t\t\t}\n\t\t\tvar dynamic struct {\n\t\t\t\tRoutes []config.Route\n\t\t\t}\n\t\t\terr := sconf.Parse(strings.NewReader(moxconf), &static)\n\t\t\txcheckf(err, \"parsing moxconf example\")\n\t\t\terr = sconf.Parse(strings.NewReader(domainsconf), &dynamic)\n\t\t\txcheckf(err, \"parsing domainsconf example\")\n\t\t\treturn moxconf + \"\\n\\n\" + domainsconf\n\t\t},\n\t},\n}\n\nvar exampleTime = time.Date(2024, time.March, 27, 0, 0, 0, 0, time.UTC)\n\nvar examples = []struct {\n\tName string\n\tGet  func() string\n}{\n\t{\n\t\t\"webhook-outgoing-delivered\",\n\t\tfunc() string {\n\t\t\tv := webhook.Outgoing{\n\t\t\t\tVersion:       0,\n\t\t\t\tEvent:         webhook.EventDelivered,\n\t\t\t\tQueueMsgID:    101,\n\t\t\t\tFromID:        base64.RawURLEncoding.EncodeToString([]byte(\"0123456789abcdef\")),\n\t\t\t\tMessageID:     \"<QnxzgulZK51utga6agH_rg@mox.example>\",\n\t\t\t\tSubject:       \"subject of original message\",\n\t\t\t\tWebhookQueued: exampleTime,\n\t\t\t\tExtra:         map[string]string{},\n\t\t\t\tSMTPCode:      smtp.C250Completed,\n\t\t\t}\n\t\t\treturn \"Example webhook HTTP POST JSON body for successful outgoing delivery:\\n\\n\\t\" + formatJSON(v)\n\t\t},\n\t},\n\t{\n\t\t\"webhook-outgoing-dsn-failed\",\n\t\tfunc() string {\n\t\t\tv := webhook.Outgoing{\n\t\t\t\tVersion:          0,\n\t\t\t\tEvent:            webhook.EventFailed,\n\t\t\t\tDSN:              true,\n\t\t\t\tSuppressing:      true,\n\t\t\t\tQueueMsgID:       102,\n\t\t\t\tFromID:           base64.RawURLEncoding.EncodeToString([]byte(\"0123456789abcdef\")),\n\t\t\t\tMessageID:        \"<QnxzgulZK51utga6agH_rg@mox.example>\",\n\t\t\t\tSubject:          \"subject of original message\",\n\t\t\t\tWebhookQueued:    exampleTime,\n\t\t\t\tExtra:            map[string]string{\"userid\": \"456\"},\n\t\t\t\tError:            \"timeout connecting to host\",\n\t\t\t\tSMTPCode:         smtp.C554TransactionFailed,\n\t\t\t\tSMTPEnhancedCode: \"5.\" + smtp.SeNet4Other0,\n\t\t\t}\n\t\t\treturn `Example webhook HTTP POST JSON body for failed delivery based on incoming DSN\nmessage, with custom extra data fields (from original submission), and adding address to the suppression list:\n\n\t` + formatJSON(v)\n\t\t},\n\t},\n\t{\n\t\t\"webhook-incoming-basic\",\n\t\tfunc() string {\n\t\t\tv := webhook.Incoming{\n\t\t\t\tVersion:   0,\n\t\t\t\tFrom:      []webhook.NameAddress{{Address: \"mox@localhost\"}},\n\t\t\t\tTo:        []webhook.NameAddress{{Address: \"mjl@localhost\"}},\n\t\t\t\tSubject:   \"hi\",\n\t\t\t\tMessageID: \"<QnxzgulZK51utga6agH_rg@mox.example>\",\n\t\t\t\tDate:      &exampleTime,\n\t\t\t\tText:      \"hello world ☺\\n\",\n\t\t\t\tStructure: webhook.Structure{\n\t\t\t\t\tContentType:       \"text/plain\",\n\t\t\t\t\tContentTypeParams: map[string]string{\"charset\": \"utf-8\"},\n\t\t\t\t\tDecodedSize:       int64(len(\"hello world ☺\\r\\n\")),\n\t\t\t\t\tParts:             []webhook.Structure{},\n\t\t\t\t},\n\t\t\t\tMeta: webhook.IncomingMeta{\n\t\t\t\t\tMsgID:               201,\n\t\t\t\t\tMailFrom:            \"mox@localhost\",\n\t\t\t\t\tMailFromValidated:   false,\n\t\t\t\t\tMsgFromValidated:    true,\n\t\t\t\t\tRcptTo:              \"mjl@localhost\",\n\t\t\t\t\tDKIMVerifiedDomains: []string{\"localhost\"},\n\t\t\t\t\tRemoteIP:            \"127.0.0.1\",\n\t\t\t\t\tReceived:            exampleTime.Add(3 * time.Second),\n\t\t\t\t\tMailboxName:         \"Inbox\",\n\t\t\t\t\tAutomated:           false,\n\t\t\t\t},\n\t\t\t}\n\t\t\treturn \"Example JSON body for webhooks for incoming delivery of basic message:\\n\\n\\t\" + formatJSON(v)\n\t\t},\n\t},\n}\n\nfunc formatJSON(v any) string {\n\tnv, _ := mox.FillNil(reflect.ValueOf(v))\n\tv = nv.Interface()\n\tvar b bytes.Buffer\n\tenc := json.NewEncoder(&b)\n\tenc.SetIndent(\"\\t\", \"\\t\")\n\tenc.SetEscapeHTML(false)\n\terr := enc.Encode(v)\n\txcheckf(err, \"encoding to json\")\n\treturn b.String()\n}\n"
        },
        {
          "name": "export.go",
          "type": "blob",
          "size": 2.45703125,
          "content": "package main\n\nimport (\n\t\"context\"\n\t\"log\"\n\t\"path/filepath\"\n\t\"time\"\n\n\t\"github.com/mjl-/bstore\"\n\n\t\"github.com/mjl-/mox/store\"\n)\n\nfunc cmdExportMaildir(c *cmd) {\n\tc.params = \"[-single] dst-dir account-path [mailbox]\"\n\tc.help = `Export one or all mailboxes from an account in maildir format.\n\nExport bypasses a running mox instance. It opens the account mailbox/message\ndatabase file directly. This may block if a running mox instance also has the\ndatabase open, e.g. for IMAP connections. To export from a running instance, use\nthe accounts web page or webmail.\n`\n\tvar single bool\n\tc.flag.BoolVar(&single, \"single\", false, \"export single mailbox, without any children. disabled if mailbox isn't specified.\")\n\targs := c.Parse()\n\txcmdExport(false, single, args, c)\n}\n\nfunc cmdExportMbox(c *cmd) {\n\tc.params = \"[-single] dst-dir account-path [mailbox]\"\n\tc.help = `Export messages from one or all mailboxes in an account in mbox format.\n\nUsing mbox is not recommended. Maildir is a better format.\n\nExport bypasses a running mox instance. It opens the account mailbox/message\ndatabase file directly. This may block if a running mox instance also has the\ndatabase open, e.g. for IMAP connections. To export from a running instance, use\nthe accounts web page or webmail.\n\nFor mbox export, \"mboxrd\" is used where message lines starting with the magic\n\"From \" string are escaped by prepending a >. All \">*From \" are escaped,\notherwise reconstructing the original could lose a \">\".\n`\n\tvar single bool\n\tc.flag.BoolVar(&single, \"single\", false, \"export single mailbox, without any children. disabled if mailbox isn't specified.\")\n\targs := c.Parse()\n\txcmdExport(true, single, args, c)\n}\n\nfunc xcmdExport(mbox, single bool, args []string, c *cmd) {\n\tif len(args) != 2 && len(args) != 3 {\n\t\tc.Usage()\n\t}\n\n\tdst := args[0]\n\taccountDir := args[1]\n\tvar mailbox string\n\tif len(args) == 3 {\n\t\tmailbox = args[2]\n\t} else {\n\t\tsingle = false\n\t}\n\n\tdbpath := filepath.Join(accountDir, \"index.db\")\n\topts := bstore.Options{Timeout: 5 * time.Second, Perm: 0660, RegisterLogger: c.log.Logger}\n\tdb, err := bstore.Open(context.Background(), dbpath, &opts, store.DBTypes...)\n\txcheckf(err, \"open database %q\", dbpath)\n\tdefer func() {\n\t\tif err := db.Close(); err != nil {\n\t\t\tlog.Printf(\"closing db after export: %v\", err)\n\t\t}\n\t}()\n\n\ta := store.DirArchiver{Dir: dst}\n\terr = store.ExportMessages(context.Background(), c.log, db, accountDir, a, !mbox, mailbox, !single)\n\txcheckf(err, \"exporting messages\")\n\terr = a.Close()\n\txcheckf(err, \"closing archiver\")\n}\n"
        },
        {
          "name": "gendoc.sh",
          "type": "blob",
          "size": 3.005859375,
          "content": "#!/usr/bin/env sh\n\n# ./doc.go\n(\ncat <<EOF\n/*\nCommand mox is a modern, secure, full-featured, open source mail server for\nlow-maintenance self-hosted email.\n\nMox is started with the \"serve\" subcommand, but mox also has many other\nsubcommands.\n\nMany of those commands talk to a running mox instance, through the ctl file in\nthe data directory. Specify the configuration file (that holds the path to the\ndata directory) through the -config flag or MOXCONF environment variable.\n\nCommands that don't talk to a running mox instance are often for\ntesting/debugging email functionality. For example for parsing an email message,\nor looking up SPF/DKIM/DMARC records.\n\nBelow is the usage information as printed by the command when started without\nany parameters. Followed by the help and usage information for each command.\n\n\n# Usage\n\nEOF\n\n./mox 2>&1 | sed -e 's/^usage: */\t/' -e 's/^  */\t/'\necho\n./mox helpall 2>&1\n\ncat <<EOF\n*/\npackage main\n\n// NOTE: DO NOT EDIT, this file is generated by gendoc.sh.\nEOF\n)>doc.go\ngofmt -w doc.go\n\n# ./config/doc.go\n(\ncat <<EOF\n/*\nPackage config holds the configuration file definitions.\n\nMox uses two config files:\n\n1. mox.conf, also called the static configuration file.\n2. domains.conf, also called the dynamic configuration file.\n\nThe static configuration file is never reloaded during the lifetime of a\nrunning mox instance. After changes to mox.conf, mox must be restarted for the\nchanges to take effect.\n\nThe dynamic configuration file is reloaded automatically when it changes.\nIf the file contains an error after the change, the reload is aborted and the\nprevious version remains active.\n\nBelow are \"empty\" config files, generated from the config file definitions in\nthe source code, along with comments explaining the fields. Fields named \"x\" are\nplaceholders for user-chosen map keys.\n\n# sconf\n\nThe config files are in \"sconf\" format. Properties of sconf files:\n\n- Indentation with tabs only.\n- \"#\" as first non-whitespace character makes the line a comment. Lines with a\n  value cannot also have a comment.\n- Values don't have syntax indicating their type. For example, strings are\n  not quoted/escaped and can never span multiple lines.\n- Fields that are optional can be left out completely. But the value of an\n  optional field may itself have required fields.\n\nSee https://pkg.go.dev/github.com/mjl-/sconf for details.\n\n\n# mox.conf\n\nEOF\n./mox config describe-static | sed 's/^/\t/'\n\ncat <<EOF\n\n# domains.conf\n\nEOF\n./mox config describe-domains | sed 's/^/\t/'\n\ncat <<EOF\n\n# Examples\n\nMox includes configuration files to illustrate common setups. You can see these\nexamples with \"mox config example\", and print a specific example with \"mox\nconfig example <name>\". Below are all examples included in mox.\n\nEOF\n\nfor ex in $(./mox config example); do\n\techo '# Example '$ex\n\techo\n\t./mox config example $ex | sed 's/^/\t/'\n\techo\ndone\n\ncat <<EOF\n*/\npackage config\n\n// NOTE: DO NOT EDIT, this file is generated by ../gendoc.sh.\nEOF\n)>config/doc.go\ngofmt -w config/doc.go\n\n# ./webapi/doc.go\n./webapi/gendoc.sh >webapi/doc.go\ngofmt -w webapi/doc.go\n"
        },
        {
          "name": "genlicenses.sh",
          "type": "blob",
          "size": 0.22265625,
          "content": "#!/bin/sh\nrm -r licenses\nset -e\nfor p in $(cd vendor && find . -iname '*license*' -or -iname '*licence*' -or -iname '*notice*' -or -iname '*patent*'); do\n\t(set +e; mkdir -p $(dirname licenses/$p))\n\tcp vendor/$p licenses/$p\ndone\n"
        },
        {
          "name": "gentestdata.go",
          "type": "blob",
          "size": 12.97265625,
          "content": "package main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/mjl-/bstore\"\n\t\"github.com/mjl-/sconf\"\n\n\t\"github.com/mjl-/mox/config\"\n\t\"github.com/mjl-/mox/dmarcdb\"\n\t\"github.com/mjl-/mox/dmarcrpt\"\n\t\"github.com/mjl-/mox/dns\"\n\t\"github.com/mjl-/mox/mlog\"\n\t\"github.com/mjl-/mox/mox-\"\n\t\"github.com/mjl-/mox/moxvar\"\n\t\"github.com/mjl-/mox/mtasts\"\n\t\"github.com/mjl-/mox/mtastsdb\"\n\t\"github.com/mjl-/mox/queue\"\n\t\"github.com/mjl-/mox/smtp\"\n\t\"github.com/mjl-/mox/store\"\n\t\"github.com/mjl-/mox/tlsrpt\"\n\t\"github.com/mjl-/mox/tlsrptdb\"\n)\n\nfunc cmdGentestdata(c *cmd) {\n\tc.unlisted = true\n\tc.params = \"dest-dir\"\n\tc.help = `Generate a data directory populated, for testing upgrades.`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tdestDataDir, err := filepath.Abs(args[0])\n\txcheckf(err, \"making destination directory an absolute path\")\n\n\tif _, err := os.Stat(destDataDir); err == nil {\n\t\tlog.Fatalf(\"destination directory already exists, refusing to generate test data\")\n\t}\n\terr = os.MkdirAll(destDataDir, 0770)\n\txcheckf(err, \"creating destination data directory\")\n\terr = os.MkdirAll(filepath.Join(destDataDir, \"tmp\"), 0770)\n\txcheckf(err, \"creating tmp directory\")\n\n\ttempfile := func() *os.File {\n\t\tf, err := os.CreateTemp(filepath.Join(destDataDir, \"tmp\"), \"temp\")\n\t\txcheckf(err, \"creating temp file\")\n\t\treturn f\n\t}\n\n\tctxbg := context.Background()\n\tmox.Conf.Log[\"\"] = mlog.LevelInfo\n\tmlog.SetConfig(mox.Conf.Log)\n\n\tconst domainsConf = `\nDomains:\n\tmox.example: nil\n\t☺.example: nil\nAccounts:\n\ttest0:\n\t\tDomain: mox.example\n\t\tDestinations:\n\t\t\ttest0@mox.example: nil\n\ttest1:\n\t\tDomain: mox.example\n\t\tDestinations:\n\t\t\ttest1@mox.example: nil\n\ttest2:\n\t\tDomain: ☺.example\n\t\tDestinations:\n\t\t\t☹@☺.example: nil\n\t\tJunkFilter:\n\t\t\tThreshold: 0.95\n\t\t\tParams:\n\t\t\t\tTwograms: true\n\t\t\t\tMaxPower: 0.1\n\t\t\t\tTopWords: 10\n\t\t\t\tIgnoreWords: 0.1\n`\n\n\tmox.ConfigStaticPath = filepath.FromSlash(\"/tmp/mox-bogus/mox.conf\")\n\tmox.ConfigDynamicPath = filepath.FromSlash(\"/tmp/mox-bogus/domains.conf\")\n\tmox.Conf.DynamicLastCheck = time.Now() // Should prevent warning.\n\tmox.Conf.Static = config.Static{\n\t\tDataDir: destDataDir,\n\t}\n\terr = sconf.Parse(strings.NewReader(domainsConf), &mox.Conf.Dynamic)\n\txcheckf(err, \"parsing domains config\")\n\n\tconst dmarcReport = `<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<feedback>\n  <report_metadata>\n    <org_name>google.com</org_name>\n    <email>noreply-dmarc-support@google.com</email>\n    <extra_contact_info>https://support.google.com/a/answer/2466580</extra_contact_info>\n    <report_id>10051505501689795560</report_id>\n    <date_range>\n      <begin>1596412800</begin>\n      <end>1596499199</end>\n    </date_range>\n  </report_metadata>\n  <policy_published>\n    <domain>mox.example</domain>\n    <adkim>r</adkim>\n    <aspf>r</aspf>\n    <p>reject</p>\n    <sp>reject</sp>\n    <pct>100</pct>\n  </policy_published>\n  <record>\n    <row>\n      <source_ip>127.0.0.1</source_ip>\n      <count>1</count>\n      <policy_evaluated>\n        <disposition>none</disposition>\n        <dkim>pass</dkim>\n        <spf>pass</spf>\n      </policy_evaluated>\n    </row>\n    <identifiers>\n      <header_from>example.org</header_from>\n    </identifiers>\n    <auth_results>\n      <dkim>\n        <domain>example.org</domain>\n        <result>pass</result>\n        <selector>example</selector>\n      </dkim>\n      <spf>\n        <domain>example.org</domain>\n        <result>pass</result>\n      </spf>\n    </auth_results>\n  </record>\n</feedback>\n`\n\n\tconst tlsReport = `{\n     \"organization-name\": \"Company-X\",\n     \"date-range\": {\n       \"start-datetime\": \"2016-04-01T00:00:00Z\",\n       \"end-datetime\": \"2016-04-01T23:59:59Z\"\n     },\n     \"contact-info\": \"sts-reporting@company-x.example\",\n     \"report-id\": \"5065427c-23d3-47ca-b6e0-946ea0e8c4be\",\n     \"policies\": [{\n       \"policy\": {\n         \"policy-type\": \"sts\",\n         \"policy-string\": [\"version: STSv1\",\"mode: testing\",\n               \"mx: *.mail.company-y.example\",\"max_age: 86400\"],\n         \"policy-domain\": \"mox.example\",\n         \"mx-host\": [\"*.mail.company-y.example\"]\n       },\n       \"summary\": {\n         \"total-successful-session-count\": 5326,\n         \"total-failure-session-count\": 303\n       },\n       \"failure-details\": [{\n         \"result-type\": \"certificate-expired\",\n         \"sending-mta-ip\": \"2001:db8:abcd:0012::1\",\n         \"receiving-mx-hostname\": \"mx1.mail.company-y.example\",\n         \"failed-session-count\": 100\n       }, {\n         \"result-type\": \"starttls-not-supported\",\n         \"sending-mta-ip\": \"2001:db8:abcd:0013::1\",\n         \"receiving-mx-hostname\": \"mx2.mail.company-y.example\",\n         \"receiving-ip\": \"203.0.113.56\",\n         \"failed-session-count\": 200,\n         \"additional-information\": \"https://reports.company-x.example/report_info ? id = 5065427 c - 23 d3# StarttlsNotSupported \"\n       }, {\n         \"result-type\": \"validation-failure\",\n         \"sending-mta-ip\": \"198.51.100.62\",\n         \"receiving-ip\": \"203.0.113.58\",\n         \"receiving-mx-hostname\": \"mx-backup.mail.company-y.example\",\n         \"failed-session-count\": 3,\n         \"failure-reason-code\": \"X509_V_ERR_PROXY_PATH_LENGTH_EXCEEDED\"\n       }]\n     }]\n   }`\n\n\terr = os.WriteFile(filepath.Join(destDataDir, \"moxversion\"), []byte(moxvar.Version), 0660)\n\txcheckf(err, \"writing moxversion\")\n\n\t// Populate auth.db\n\terr = store.Init(ctxbg)\n\txcheckf(err, \"store init\")\n\terr = store.TLSPublicKeyAdd(ctxbg, &store.TLSPublicKey{Fingerprint: \"...\", Type: \"ecdsa-p256\", CertDER: []byte(\"...\"), Account: \"test0\", LoginAddress: \"test0@mox.example\"})\n\txcheckf(err, \"adding tlspubkey\")\n\n\t// Populate dmarc.db.\n\terr = dmarcdb.Init()\n\txcheckf(err, \"dmarcdb init\")\n\treport, err := dmarcrpt.ParseReport(strings.NewReader(dmarcReport))\n\txcheckf(err, \"parsing dmarc aggregate report\")\n\terr = dmarcdb.AddReport(ctxbg, report, dns.Domain{ASCII: \"mox.example\"})\n\txcheckf(err, \"adding dmarc aggregate report\")\n\n\t// Populate mtasts.db.\n\terr = mtastsdb.Init(false)\n\txcheckf(err, \"mtastsdb init\")\n\tmtastsPolicy := mtasts.Policy{\n\t\tVersion: \"STSv1\",\n\t\tMode:    mtasts.ModeTesting,\n\t\tMX: []mtasts.MX{\n\t\t\t{Domain: dns.Domain{ASCII: \"mx1.example.com\"}},\n\t\t\t{Domain: dns.Domain{ASCII: \"mx2.example.com\"}},\n\t\t\t{Domain: dns.Domain{ASCII: \"backup-example.com\"}, Wildcard: true},\n\t\t},\n\t\tMaxAgeSeconds: 1296000,\n\t}\n\terr = mtastsdb.Upsert(ctxbg, dns.Domain{ASCII: \"mox.example\"}, \"123\", &mtastsPolicy, mtastsPolicy.String())\n\txcheckf(err, \"adding mtastsdb report\")\n\n\t// Populate tlsrpt.db.\n\terr = tlsrptdb.Init()\n\txcheckf(err, \"tlsrptdb init\")\n\ttlsreportJSON, err := tlsrpt.Parse(strings.NewReader(tlsReport))\n\txcheckf(err, \"parsing tls report\")\n\ttlsr := tlsreportJSON.Convert()\n\terr = tlsrptdb.AddReport(ctxbg, c.log, dns.Domain{ASCII: \"mox.example\"}, \"tlsrpt@mox.example\", false, &tlsr)\n\txcheckf(err, \"adding tls report\")\n\n\t// Populate queue, with a message.\n\terr = queue.Init()\n\txcheckf(err, \"queue init\")\n\tmailfrom := smtp.Path{Localpart: \"other\", IPDomain: dns.IPDomain{Domain: dns.Domain{ASCII: \"other.example\"}}}\n\trcptto := smtp.Path{Localpart: \"test0\", IPDomain: dns.IPDomain{Domain: dns.Domain{ASCII: \"mox.example\"}}}\n\tprefix := []byte{}\n\tmf := tempfile()\n\txcheckf(err, \"temp file for queue message\")\n\tdefer os.Remove(mf.Name())\n\tdefer mf.Close()\n\tconst qmsg = \"From: <test0@mox.example>\\r\\nTo: <other@remote.example>\\r\\nSubject: test\\r\\n\\r\\nthe message...\\r\\n\"\n\t_, err = fmt.Fprint(mf, qmsg)\n\txcheckf(err, \"writing message\")\n\tqm := queue.MakeMsg(mailfrom, rcptto, false, false, int64(len(qmsg)), \"<test@localhost>\", prefix, nil, time.Now(), \"test\")\n\terr = queue.Add(ctxbg, c.log, \"test0\", mf, qm)\n\txcheckf(err, \"enqueue message\")\n\n\t// Create three accounts.\n\t// First account without messages.\n\taccTest0, err := store.OpenAccount(c.log, \"test0\")\n\txcheckf(err, \"open account test0\")\n\terr = accTest0.ThreadingWait(c.log)\n\txcheckf(err, \"wait for threading to finish\")\n\terr = accTest0.Close()\n\txcheckf(err, \"close account\")\n\n\t// Second account with one message.\n\taccTest1, err := store.OpenAccount(c.log, \"test1\")\n\txcheckf(err, \"open account test1\")\n\terr = accTest1.ThreadingWait(c.log)\n\txcheckf(err, \"wait for threading to finish\")\n\terr = accTest1.DB.Write(ctxbg, func(tx *bstore.Tx) error {\n\t\tinbox, err := bstore.QueryTx[store.Mailbox](tx).FilterNonzero(store.Mailbox{Name: \"Inbox\"}).Get()\n\t\txcheckf(err, \"looking up inbox\")\n\t\tconst msg = \"From: <other@remote.example>\\r\\nTo: <test1@mox.example>\\r\\nSubject: test\\r\\n\\r\\nthe message...\\r\\n\"\n\t\tm := store.Message{\n\t\t\tMailboxID:          inbox.ID,\n\t\t\tMailboxOrigID:      inbox.ID,\n\t\t\tMailboxDestinedID:  inbox.ID,\n\t\t\tRemoteIP:           \"1.2.3.4\",\n\t\t\tRemoteIPMasked1:    \"1.2.3.4\",\n\t\t\tRemoteIPMasked2:    \"1.2.3.0\",\n\t\t\tRemoteIPMasked3:    \"1.2.0.0\",\n\t\t\tEHLODomain:         \"other.example\",\n\t\t\tMailFrom:           \"other@remote.example\",\n\t\t\tMailFromLocalpart:  smtp.Localpart(\"other\"),\n\t\t\tMailFromDomain:     \"remote.example\",\n\t\t\tRcptToLocalpart:    \"test1\",\n\t\t\tRcptToDomain:       \"mox.example\",\n\t\t\tMsgFromLocalpart:   \"other\",\n\t\t\tMsgFromDomain:      \"remote.example\",\n\t\t\tMsgFromOrgDomain:   \"remote.example\",\n\t\t\tEHLOValidated:      true,\n\t\t\tMailFromValidated:  true,\n\t\t\tMsgFromValidated:   true,\n\t\t\tEHLOValidation:     store.ValidationStrict,\n\t\t\tMailFromValidation: store.ValidationPass,\n\t\t\tMsgFromValidation:  store.ValidationStrict,\n\t\t\tDKIMDomains:        []string{\"other.example\"},\n\t\t\tSize:               int64(len(msg)),\n\t\t}\n\t\tmf := tempfile()\n\t\txcheckf(err, \"creating temp file for delivery\")\n\t\t_, err = fmt.Fprint(mf, msg)\n\t\txcheckf(err, \"writing deliver message to file\")\n\t\terr = accTest1.DeliverMessage(c.log, tx, &m, mf, false, true, false, true)\n\n\t\tmfname := mf.Name()\n\t\txcheckf(err, \"add message to account test1\")\n\t\terr = mf.Close()\n\t\txcheckf(err, \"closing file\")\n\t\terr = os.Remove(mfname)\n\t\txcheckf(err, \"removing temp message file\")\n\n\t\terr = tx.Get(&inbox)\n\t\txcheckf(err, \"get inbox\")\n\t\tinbox.Add(m.MailboxCounts())\n\t\terr = tx.Update(&inbox)\n\t\txcheckf(err, \"update inbox\")\n\n\t\treturn nil\n\t})\n\txcheckf(err, \"write transaction with new message\")\n\terr = accTest1.Close()\n\txcheckf(err, \"close account\")\n\n\t// Third account with two messages and junkfilter.\n\taccTest2, err := store.OpenAccount(c.log, \"test2\")\n\txcheckf(err, \"open account test2\")\n\terr = accTest2.ThreadingWait(c.log)\n\txcheckf(err, \"wait for threading to finish\")\n\terr = accTest2.DB.Write(ctxbg, func(tx *bstore.Tx) error {\n\t\tinbox, err := bstore.QueryTx[store.Mailbox](tx).FilterNonzero(store.Mailbox{Name: \"Inbox\"}).Get()\n\t\txcheckf(err, \"looking up inbox\")\n\t\tconst msg0 = \"From: <other@remote.example>\\r\\nTo: <☹@xn--74h.example>\\r\\nSubject: test\\r\\n\\r\\nthe message...\\r\\n\"\n\t\tm0 := store.Message{\n\t\t\tMailboxID:          inbox.ID,\n\t\t\tMailboxOrigID:      inbox.ID,\n\t\t\tMailboxDestinedID:  inbox.ID,\n\t\t\tRemoteIP:           \"::1\",\n\t\t\tRemoteIPMasked1:    \"::\",\n\t\t\tRemoteIPMasked2:    \"::\",\n\t\t\tRemoteIPMasked3:    \"::\",\n\t\t\tEHLODomain:         \"other.example\",\n\t\t\tMailFrom:           \"other@remote.example\",\n\t\t\tMailFromLocalpart:  smtp.Localpart(\"other\"),\n\t\t\tMailFromDomain:     \"remote.example\",\n\t\t\tRcptToLocalpart:    \"☹\",\n\t\t\tRcptToDomain:       \"☺.example\",\n\t\t\tMsgFromLocalpart:   \"other\",\n\t\t\tMsgFromDomain:      \"remote.example\",\n\t\t\tMsgFromOrgDomain:   \"remote.example\",\n\t\t\tEHLOValidated:      true,\n\t\t\tMailFromValidated:  true,\n\t\t\tMsgFromValidated:   true,\n\t\t\tEHLOValidation:     store.ValidationStrict,\n\t\t\tMailFromValidation: store.ValidationPass,\n\t\t\tMsgFromValidation:  store.ValidationStrict,\n\t\t\tDKIMDomains:        []string{\"other.example\"},\n\t\t\tSize:               int64(len(msg0)),\n\t\t}\n\t\tmf0 := tempfile()\n\t\txcheckf(err, \"creating temp file for delivery\")\n\t\t_, err = fmt.Fprint(mf0, msg0)\n\t\txcheckf(err, \"writing deliver message to file\")\n\t\terr = accTest2.DeliverMessage(c.log, tx, &m0, mf0, false, false, false, true)\n\t\txcheckf(err, \"add message to account test2\")\n\n\t\tmf0name := mf0.Name()\n\t\terr = mf0.Close()\n\t\txcheckf(err, \"closing file\")\n\t\terr = os.Remove(mf0name)\n\t\txcheckf(err, \"removing temp message file\")\n\n\t\terr = tx.Get(&inbox)\n\t\txcheckf(err, \"get inbox\")\n\t\tinbox.Add(m0.MailboxCounts())\n\t\terr = tx.Update(&inbox)\n\t\txcheckf(err, \"update inbox\")\n\n\t\tsent, err := bstore.QueryTx[store.Mailbox](tx).FilterNonzero(store.Mailbox{Name: \"Sent\"}).Get()\n\t\txcheckf(err, \"looking up inbox\")\n\t\tconst prefix1 = \"Extra: test\\r\\n\"\n\t\tconst msg1 = \"From: <other@remote.example>\\r\\nTo: <☹@xn--74h.example>\\r\\nSubject: test\\r\\n\\r\\nthe message...\\r\\n\"\n\t\tm1 := store.Message{\n\t\t\tMailboxID:         sent.ID,\n\t\t\tMailboxOrigID:     sent.ID,\n\t\t\tMailboxDestinedID: sent.ID,\n\t\t\tFlags:             store.Flags{Seen: true, Junk: true},\n\t\t\tSize:              int64(len(prefix1) + len(msg1)),\n\t\t\tMsgPrefix:         []byte(prefix1),\n\t\t}\n\t\tmf1 := tempfile()\n\t\txcheckf(err, \"creating temp file for delivery\")\n\t\t_, err = fmt.Fprint(mf1, msg1)\n\t\txcheckf(err, \"writing deliver message to file\")\n\t\terr = accTest2.DeliverMessage(c.log, tx, &m1, mf1, false, false, false, true)\n\t\txcheckf(err, \"add message to account test2\")\n\n\t\tmf1name := mf1.Name()\n\t\terr = mf1.Close()\n\t\txcheckf(err, \"closing file\")\n\t\terr = os.Remove(mf1name)\n\t\txcheckf(err, \"removing temp message file\")\n\n\t\terr = tx.Get(&sent)\n\t\txcheckf(err, \"get sent\")\n\t\tsent.Add(m1.MailboxCounts())\n\t\terr = tx.Update(&sent)\n\t\txcheckf(err, \"update sent\")\n\n\t\treturn nil\n\t})\n\txcheckf(err, \"write transaction with new message\")\n\terr = accTest2.Close()\n\txcheckf(err, \"close account\")\n}\n"
        },
        {
          "name": "gents.sh",
          "type": "blob",
          "size": 0.3505859375,
          "content": "#!/bin/sh\nset -eu\n\n# generate new typescript client, only install it when it is different, so we\n# don't trigger frontend builds needlessly.\ngo run vendor/github.com/mjl-/sherpats/cmd/sherpats/main.go -bytes-to-string -slices-nullable -maps-nullable -nullable-optional -namespace api api <$1 >$2.tmp\nif cmp -s $2 $2.tmp; then\n\trm $2.tmp\nelse\n\tmv $2.tmp $2\nfi\n"
        },
        {
          "name": "genwebsite.sh",
          "type": "blob",
          "size": 3.818359375,
          "content": "#!/usr/bin/env bash\n\nmkdir website/html 2>/dev/null\nrm -r website/html/* 2>/dev/null\n\nset -euo pipefail\n\ncommithash=$(git rev-parse --short HEAD)\ncommitdate=$(git log -1 --date=format:\"%Y-%m-%d\" --format=\"%ad\")\nexport commithash\nexport commitdate\n\n# Link to static files and cross-references.\nln -sf ../../../mox-website-files/files website/html/files\nln -sf ../../rfc/xr website/html/xr\n\n\n# All commands below are executed relative to ./website/\ncd website\n\ngo run website.go -root -title 'Mox: modern, secure, all-in-one mail server' 'Mox' < index.md >html/index.html\n\nmkdir html/features\n(\n\tcat features/index.md\n\techo\n\tsed -n -e '/# FAQ/q' -e '/## Roadmap/,/# FAQ/p' < ../README.md\n\techo\n\techo 'Also see the [Protocols](../protocols/) page for implementation status, and (non)-plans.'\n) | go run website.go 'Features' >html/features/index.html\n\nmkdir html/screenshots\ngo run website.go 'Screenshots' < screenshots/index.md >html/screenshots/index.html\n\nmkdir html/install\ngo run website.go 'Install' < install/index.md >html/install/index.html\n\nmkdir html/faq\nsed -n '/# FAQ/,//p' < ../README.md | go run website.go 'FAQ' >html/faq/index.html\n\nmkdir html/config\n(\n\techo '# Config reference'\n\techo\n\tsed -n '/^Package config holds /,/\\*\\//p' < ../config/doc.go | grep -v -E '^(Package config holds |\\*/)' | sed 's/^# /## /'\n) | go run website.go 'Config reference' >html/config/index.html\n\nmkdir html/commands\n(\n\techo '# Command reference'\n\techo\n\tsed -n '/^Mox is started /,/\\*\\//p' < ../doc.go | grep -v '\\*/' | sed 's/^# /## /'\n) | go run website.go 'Command reference' >html/commands/index.html\n\nmkdir html/protocols\ngo run website.go -protocols 'Protocols' <../rfc/index.txt >html/protocols/index.html\n\nmkdir html/b\ncat <<'EOF' >html/b/index.html\n<!doctype html>\n<html>\n\t<head>\n\t\t<meta charset=\"utf-8\" />\n\t\t<title>mox build</title>\n\t\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\t\t<link rel=\"icon\" href=\"noNeedlessFaviconRequestsPlease:\" />\n\t\t<style>\nbody { padding: 1em; }\n* { font-size: 18px; font-family: ubuntu, lato, sans-serif; margin: 0; padding: 0; box-sizing: border-box; }\np { max-width: 50em; margin-bottom: 2ex; }\npre { font-family: 'ubuntu mono', monospace; }\npre, blockquote { padding: 1em; background-color: #eee; border-radius: .25em; display: inline-block; margin-bottom: 1em; }\nh1 { margin: 1em 0 .5em 0; }\n\t\t</style>\n\t</head>\n\t<body>\n<script>\nconst elem = (name, ...s) => {\n\tconst e = document.createElement(name)\n\te.append(...s)\n\treturn e\n}\nconst link = (url, anchor) => {\n\tconst e = document.createElement('a')\n\te.setAttribute('href', url)\n\te.setAttribute('rel', 'noopener')\n\te.append(anchor || url)\n\treturn e\n}\nlet h = location.hash.substring(1)\nconst ok = /^[a-zA-Z0-9_\\.]+$/.test(h)\nif (!ok) {\n\th = '<tag-or-branch-or-commithash>'\n}\nconst init = () => {\n\tdocument.body.append(\n\t\telem('p', 'Compile or download any version of mox, by tag (release), branch or commit hash.'),\n\t\telem('h1', 'Compile'),\n\t\telem('p', 'Run:'),\n\t\telem('pre', 'CGO_ENABLED=0 GOBIN=$PWD go install github.com/mjl-/mox@'+h),\n\t\telem('p', 'Mox is tested with the Go toolchain versions that are still have support: The most recent version, and the version before.'),\n\t\telem('h1', 'Download'),\n\t\telem('p', 'Download a binary for your platform:'),\n\t\telem('blockquote', ok ?\n\t\t\tlink('https://beta.gobuilds.org/github.com/mjl-/mox@'+h) :\n\t\t\t'https://beta.gobuilds.org/github.com/mjl-/mox@'+h\n\t\t),\n\t\telem('p', 'Because mox is written in Go, builds are reproducible, also when cross-compiling. Gobuilds.org is a service that builds Go applications on-demand with the latest Go toolchain/runtime.'),\n\t\telem('h1', 'Localserve'),\n\t\telem('p', 'Changes to mox can often be most easily tested locally with ', link('../features/#hdr-localserve', '\"mox localserve\"'), ', without having to update your running mail server.'),\n\t)\n}\nwindow.addEventListener('load', init)\n</script>\n\t</body>\n</html>\nEOF\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 1.1796875,
          "content": "module github.com/mjl-/mox\n\ngo 1.22.0\n\nrequire (\n\tgithub.com/mjl-/adns v0.0.0-20240509092456-2dc8715bf4af\n\tgithub.com/mjl-/autocert v0.0.0-20231214125928-31b7400acb05\n\tgithub.com/mjl-/bstore v0.0.6\n\tgithub.com/mjl-/sconf v0.0.7\n\tgithub.com/mjl-/sherpa v0.6.7\n\tgithub.com/mjl-/sherpadoc v0.0.16\n\tgithub.com/mjl-/sherpaprom v0.0.2\n\tgithub.com/mjl-/sherpats v0.0.6\n\tgithub.com/prometheus/client_golang v1.18.0\n\tgithub.com/russross/blackfriday/v2 v2.1.0\n\tgo.etcd.io/bbolt v1.3.11\n\tgolang.org/x/crypto v0.31.0\n\tgolang.org/x/exp v0.0.0-20240416160154-fe59bbe5cc7f\n\tgolang.org/x/net v0.33.0\n\tgolang.org/x/text v0.21.0\n\trsc.io/qr v0.2.0\n)\n\nrequire (\n\tgithub.com/beorn7/perks v1.0.1 // indirect\n\tgithub.com/cespare/xxhash/v2 v2.2.0 // indirect\n\tgithub.com/matttproud/golang_protobuf_extensions/v2 v2.0.0 // indirect\n\tgithub.com/mjl-/xfmt v0.0.2 // indirect\n\tgithub.com/prometheus/client_model v0.5.0 // indirect\n\tgithub.com/prometheus/common v0.45.0 // indirect\n\tgithub.com/prometheus/procfs v0.12.0 // indirect\n\tgolang.org/x/mod v0.22.0 // indirect\n\tgolang.org/x/sync v0.10.0 // indirect\n\tgolang.org/x/sys v0.28.0 // indirect\n\tgolang.org/x/tools v0.28.0 // indirect\n\tgoogle.golang.org/protobuf v1.31.0 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 10.630859375,
          "content": "github.com/alecthomas/template v0.0.0-20160405071501-a0175ee3bccc/go.mod h1:LOuyumcjzFXgccqObfd/Ljyb9UuFJ6TxHnclSeseNhc=\ngithub.com/alecthomas/units v0.0.0-20151022065526-2efee857e7cf/go.mod h1:ybxpYRFXyAe+OPACYpWeL0wqObRcbAqCMya13uyzqw0=\ngithub.com/beorn7/perks v0.0.0-20180321164747-3a771d992973/go.mod h1:Dwedo/Wpr24TaqPxmxbtue+5NUziq4I4S80YR8gNf3Q=\ngithub.com/beorn7/perks v1.0.0/go.mod h1:KWe93zE9D1o94FZ5RNwFwVgaQK1VOXiVxmqh+CedLV8=\ngithub.com/beorn7/perks v1.0.1 h1:VlbKKnNfV8bJzeqoa4cOKqO6bYr3WgKZxO8Z16+hsOM=\ngithub.com/beorn7/perks v1.0.1/go.mod h1:G2ZrVWU2WbWT9wwq4/hrbKbnv/1ERSJQ0ibhJ6rlkpw=\ngithub.com/cespare/xxhash/v2 v2.2.0 h1:DC2CZ1Ep5Y4k3ZQ899DldepgrayRUGE6BBZ/cd9Cj44=\ngithub.com/cespare/xxhash/v2 v2.2.0/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/go-kit/kit v0.8.0/go.mod h1:xBxKIO96dXMWWy0MnWVtmwkA9/13aqxPnvrjFYMA2as=\ngithub.com/go-logfmt/logfmt v0.3.0/go.mod h1:Qt1PoO58o5twSAckw1HlFXLmHsOX5/0LbT9GBnD5lWE=\ngithub.com/go-stack/stack v1.8.0/go.mod h1:v0f6uXyyMGvRgIKkXu+yp6POWl0qKG85gN/melR3HDY=\ngithub.com/gogo/protobuf v1.1.1/go.mod h1:r8qH/GZQm5c6nD/R0oafs1akxWv10x8SbQlK7atdtwQ=\ngithub.com/golang/protobuf v1.2.0/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.1/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.5.0/go.mod h1:FsONVRAS9T7sI+LIUmWTfcYkHO4aIWwzhcaSAoJOfIk=\ngithub.com/google/go-cmp v0.5.5/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.6.0 h1:ofyhxvXcZhMsU5ulbFiLKl/XBFqE1GSq7atu8tAmTRI=\ngithub.com/google/go-cmp v0.6.0/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/julienschmidt/httprouter v1.2.0/go.mod h1:SYymIcj16QtmaHHD7aYtjjsJG7VTCxuUUipMqKk8s4w=\ngithub.com/konsorten/go-windows-terminal-sequences v1.0.1/go.mod h1:T0+1ngSBFLxvqU3pZ+m/2kptfBszLMUkC4ZK/EgS/cQ=\ngithub.com/kr/logfmt v0.0.0-20140226030751-b84e30acd515/go.mod h1:+0opPa2QZZtGFBFZlji/RkVcI2GknAs/DXo4wKdlNEc=\ngithub.com/matttproud/golang_protobuf_extensions v1.0.1/go.mod h1:D8He9yQNgCq6Z5Ld7szi9bcBfOoFv/3dc6xSMkL2PC0=\ngithub.com/matttproud/golang_protobuf_extensions/v2 v2.0.0 h1:jWpvCLoY8Z/e3VKvlsiIGKtc+UG6U5vzxaoagmhXfyg=\ngithub.com/matttproud/golang_protobuf_extensions/v2 v2.0.0/go.mod h1:QUyp042oQthUoa9bqDv0ER0wrtXnBruoNd7aNjkbP+k=\ngithub.com/mjl-/adns v0.0.0-20240509092456-2dc8715bf4af h1:sEDWZPIi5K1qKk7JQoAZyDwXkRQseIf7y5ony8JeYEQ=\ngithub.com/mjl-/adns v0.0.0-20240509092456-2dc8715bf4af/go.mod h1:v47qUMJnipnmDTRGaHwpCwzE6oypa5K33mUvBfzZBn8=\ngithub.com/mjl-/autocert v0.0.0-20231214125928-31b7400acb05 h1:s6ay4bh4tmpPLdxjyeWG45mcwHfEluBMuGPkqxHWUJ4=\ngithub.com/mjl-/autocert v0.0.0-20231214125928-31b7400acb05/go.mod h1:taMFU86abMxKLPV4Bynhv8enbYmS67b8LG80qZv2Qus=\ngithub.com/mjl-/bstore v0.0.6 h1:ntlu9MkfCkpm2XfBY4+Ws4KK9YzXzewr3+lCueFB+9c=\ngithub.com/mjl-/bstore v0.0.6/go.mod h1:/cD25FNBaDfvL/plFRxI3Ba3E+wcB0XVOS8nJDqndg0=\ngithub.com/mjl-/sconf v0.0.7 h1:bdBcSFZCDFMm/UdBsgNCsjkYmKrSgYwp7rAOoufwHe4=\ngithub.com/mjl-/sconf v0.0.7/go.mod h1:uF8OdWtLT8La3i4ln176i1pB0ps9pXGCaABEU55ZkE0=\ngithub.com/mjl-/sherpa v0.6.7 h1:C5F8XQdV5nCuS4fvB+ye/ziUQrajEhOoj/t2w5T14BY=\ngithub.com/mjl-/sherpa v0.6.7/go.mod h1:dSpAOdgpwdqQZ72O4n3EHo/tR68eKyan8tYYraUMPNc=\ngithub.com/mjl-/sherpadoc v0.0.0-20190505200843-c0a7f43f5f1d/go.mod h1:5khTKxoKKNXcB8bkVUO6GlzC7PFtMmkHq578lPbmnok=\ngithub.com/mjl-/sherpadoc v0.0.16 h1:BdlFNXfnTaA7qO54kof4xpNFJxYBTY0cIObRk7QAP6M=\ngithub.com/mjl-/sherpadoc v0.0.16/go.mod h1:vh5zcsk3j/Tvm725EY+unTZb3EZcZcpiEQzrODSa6+I=\ngithub.com/mjl-/sherpaprom v0.0.2 h1:1dlbkScsNafM5jURI44uiWrZMSwfZtcOFEEq7vx2C1Y=\ngithub.com/mjl-/sherpaprom v0.0.2/go.mod h1:cl5nMNOvqhzMiQJ2FzccQ9ReivjHXe53JhOVkPfSvw4=\ngithub.com/mjl-/sherpats v0.0.6 h1:2lSoJbb+jkjLOdlvoMxItq0QQrrnkH+rnm3PMRfpbmA=\ngithub.com/mjl-/sherpats v0.0.6/go.mod h1:MoNZJtLmu8oCZ4Ocv5vZksENN4pp6/SJMlg9uTII4KA=\ngithub.com/mjl-/xfmt v0.0.2 h1:6dLgd6U3bmDJKtTxsaSYYyMaORoO4hKBAJo4XKkPRko=\ngithub.com/mjl-/xfmt v0.0.2/go.mod h1:DIEOLmETMQHHr4OgwPG7iC37rDiN9MaZIZxNm5hBtL8=\ngithub.com/mwitkow/go-conntrack v0.0.0-20161129095857-cc309e4a2223/go.mod h1:qRWi+5nqEBWmkhHvq77mSJWrCKwh8bxhgT7d/eI7P4U=\ngithub.com/pkg/errors v0.8.0/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/prometheus/client_golang v0.9.1/go.mod h1:7SWBe2y4D6OKWSNQJUaRYU/AaXPKyh/dDVn+NZz0KFw=\ngithub.com/prometheus/client_golang v1.18.0 h1:HzFfmkOzH5Q8L8G+kSJKUx5dtG87sewO+FoDDqP5Tbk=\ngithub.com/prometheus/client_golang v1.18.0/go.mod h1:T+GXkCk5wSJyOqMIzVgvvjFDlkOQntgjkJWKrN5txjA=\ngithub.com/prometheus/client_model v0.0.0-20180712105110-5c3871d89910/go.mod h1:MbSGuTsp3dbXC40dX6PRTWyKYBIrTGTE9sqQNg2J8bo=\ngithub.com/prometheus/client_model v0.0.0-20190129233127-fd36f4220a90/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6Tm2C1GtYGdfGttqA=\ngithub.com/prometheus/client_model v0.5.0 h1:VQw1hfvPvk3Uv6Qf29VrPF32JB6rtbgI6cYPYQjL0Qw=\ngithub.com/prometheus/client_model v0.5.0/go.mod h1:dTiFglRmd66nLR9Pv9f0mZi7B7fk5Pm3gvsjB5tr+kI=\ngithub.com/prometheus/common v0.3.0/go.mod h1:TNfzLD0ON7rHzMJeJkieUDPYmFC7Snx/y86RQel1bk4=\ngithub.com/prometheus/common v0.45.0 h1:2BGz0eBc2hdMDLnO/8n0jeB3oPrt2D08CekT0lneoxM=\ngithub.com/prometheus/common v0.45.0/go.mod h1:YJmSTw9BoKxJplESWWxlbyttQR4uaEcGyv9MZjVOJsY=\ngithub.com/prometheus/procfs v0.0.0-20181005140218-185b4288413d/go.mod h1:c3At6R/oaqEKCNdg8wHV1ftS6bRYblBhIjjI8uT2IGk=\ngithub.com/prometheus/procfs v0.0.0-20190503130316-740c07785007/go.mod h1:TjEm7ze935MbeOT/UhFTIMYKhuLP4wbCsTZCD3I8kEA=\ngithub.com/prometheus/procfs v0.12.0 h1:jluTpSng7V9hY0O2R9DzzJHYb2xULk9VTR1V1R/k6Bo=\ngithub.com/prometheus/procfs v0.12.0/go.mod h1:pcuDEFsWDnvcgNzo4EEweacyhjeA9Zk3cnaOZAZEfOo=\ngithub.com/russross/blackfriday/v2 v2.1.0 h1:JIOH55/0cWyOuilr9/qlrm0BSXldqnqwMsf35Ld67mk=\ngithub.com/russross/blackfriday/v2 v2.1.0/go.mod h1:+Rmxgy9KzJVeS9/2gXHxylqXiyQDYRxCVz55jmeOWTM=\ngithub.com/sirupsen/logrus v1.2.0/go.mod h1:LxeOpSwHxABJmUn/MG1IvRgCAasNZTLOkJPxbbu5VWo=\ngithub.com/stretchr/objx v0.1.1/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/testify v1.2.2/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=\ngithub.com/stretchr/testify v1.8.1 h1:w7B6lhMri9wdJUVmEZPGGhZzrYTPvgJArz7wNPgYKsk=\ngithub.com/stretchr/testify v1.8.1/go.mod h1:w2LPCIKwWwSfY2zedu0+kehJoqGctiVI29o6fzry7u4=\ngo.etcd.io/bbolt v1.3.11 h1:yGEzV1wPz2yVCLsD8ZAiGHhHVlczyC9d1rP43/VCRJ0=\ngo.etcd.io/bbolt v1.3.11/go.mod h1:dksAq7YMXoljX0xu6VF5DMZGbhYYoLUalEiSySYAS4I=\ngolang.org/x/crypto v0.0.0-20180904163835-0709b304e793/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20191011191535-87dc89f01550/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.31.0 h1:ihbySMvVjLAeSH1IbfcRTkD/iNscyz8rGzjF/E5hV6U=\ngolang.org/x/crypto v0.31.0/go.mod h1:kDsLvtWBEx7MV9tJOj9bnXsPbxwJQ6csT/x4KIN4Ssk=\ngolang.org/x/exp v0.0.0-20240416160154-fe59bbe5cc7f h1:99ci1mjWVBWwJiEKYY6jWa4d2nTQVIEhZIptnrVb1XY=\ngolang.org/x/exp v0.0.0-20240416160154-fe59bbe5cc7f/go.mod h1:/lliqkxwWAhPjf5oSOIJup2XcqJaw8RGS6k3TGEc7GI=\ngolang.org/x/mod v0.5.1/go.mod h1:5OXOZSfqPIIbmVBIIKWRFfZjPR0E5r58TLhUjH0a2Ro=\ngolang.org/x/mod v0.22.0 h1:D4nJWe9zXqHOmWqj4VMOJhvzj7bEZg4wEYa759z1pH4=\ngolang.org/x/mod v0.22.0/go.mod h1:6SkKJ3Xj0I0BrPOZoBy3bdMptDDU9oJrpohJ3eWZ1fY=\ngolang.org/x/net v0.0.0-20181114220301-adae6a3d119a/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.33.0 h1:74SYHlV8BIgHIFC/LrYkOGIwL19eTYXQ5wc6TBuO36I=\ngolang.org/x/net v0.33.0/go.mod h1:HXLR5J+9DxmrqMwG9qjGCxZ+zKXxBru04zlTvWlWuN4=\ngolang.org/x/sync v0.0.0-20181108010431-42b317875d0f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20181221193216-37e7f081c4d4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.10.0 h1:3NQrjDixjgGwUOCaF8w2+VYHv0Ve/vGYSbdkTa98gmQ=\ngolang.org/x/sync v0.10.0/go.mod h1:Czt+wKu1gCyEFDUtn0jG5QVvpJ6rzVqr5aXyt9drQfk=\ngolang.org/x/sys v0.0.0-20180905080454-ebe1bf3edb33/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20181116152217-5ac8a444bdc5/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.28.0 h1:Fksou7UEQUWlKvIdsqzJmUmCX3cZuD2+P3XyyzwMhlA=\ngolang.org/x/sys v0.28.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.21.0 h1:zyQAAkrwaneQ066sspRyJaG9VNi/YJ1NfzcGB3hZ/qo=\ngolang.org/x/text v0.21.0/go.mod h1:4IBbMaMmOPCJ8SecivzSH54+73PCFmPWxNTLm+vZkEQ=\ngolang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.28.0 h1:WuB6qZ4RPCQo5aP3WdKZS7i595EdWqWR8vqJTlwTVK8=\ngolang.org/x/tools v0.28.0/go.mod h1:dcIOrVd3mfQKTgrDVQHqCPMWy6lnhfhtX3hLXYVLfRw=\ngolang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngoogle.golang.org/protobuf v1.26.0-rc.1/go.mod h1:jlhhOSvTdKEhbULTjvd4ARK9grFBp09yW+WbY/TyQbw=\ngoogle.golang.org/protobuf v1.31.0 h1:g0LDEJHgrBl9N9r17Ru3sqWhkIx2NB67okBHPwC7hs8=\ngoogle.golang.org/protobuf v1.31.0/go.mod h1:HV8QOd/L58Z+nl8r43ehVNZIU/HEI6OcFqwMG9pJV4I=\ngopkg.in/alecthomas/kingpin.v2 v2.2.6/go.mod h1:FMv+mEhP44yOT+4EoQTLFTRgOQ1FBLkstjWtayDeSgw=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/yaml.v2 v2.2.1/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\nrsc.io/qr v0.2.0 h1:6vBLea5/NRMVTz8V66gipeLycZMl/+UlFmk8DvqQ6WY=\nrsc.io/qr v0.2.0/go.mod h1:IF+uZjkb9fqyeF/4tlBoynqmQxUoPfWEKh921coOuXs=\n"
        },
        {
          "name": "http",
          "type": "tree",
          "content": null
        },
        {
          "name": "imapclient",
          "type": "tree",
          "content": null
        },
        {
          "name": "imapserver",
          "type": "tree",
          "content": null
        },
        {
          "name": "import.go",
          "type": "blob",
          "size": 12.388671875,
          "content": "package main\n\nimport (\n\t\"bufio\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"log/slog\"\n\t\"net\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"runtime/debug\"\n\t\"strings\"\n\t\"time\"\n\n\t\"golang.org/x/exp/maps\"\n\n\t\"github.com/mjl-/mox/config\"\n\t\"github.com/mjl-/mox/message\"\n\t\"github.com/mjl-/mox/metrics\"\n\t\"github.com/mjl-/mox/mox-\"\n\t\"github.com/mjl-/mox/store\"\n)\n\n// todo: add option to trust imported messages, causing us to look at Authentication-Results and Received-SPF headers and add eg verified spf/dkim/dmarc domains to our store, to jumpstart reputation.\n\nconst importCommonHelp = `The mbox/maildir archive is accessed and imported by the running mox process, so\nit must have access to the archive files. The default suggested systemd service\nfile isolates mox from most of the file system, with only the \"data/\" directory\naccessible, so you may want to put the mbox/maildir archive files in a\ndirectory like \"data/import/\" to make it available to mox.\n\nBy default, messages will train the junk filter based on their flags and, if\n\"automatic junk flags\" configuration is set, based on mailbox naming.\n\nIf the destination mailbox is the Sent mailbox, the recipients of the messages\nare added to the message metadata, causing later incoming messages from these\nrecipients to be accepted, unless other reputation signals prevent that.\n\nUsers can also import mailboxes/messages through the account web page by\nuploading a zip or tgz file with mbox and/or maildirs.\n\nMessages are imported even if already present. Importing messages twice will\nresult in duplicate messages.\n`\n\nfunc cmdImportMaildir(c *cmd) {\n\tc.params = \"accountname mailboxname maildir\"\n\tc.help = `Import a maildir into an account.\n\n` + importCommonHelp + `\nMailbox flags, like \"seen\", \"answered\", will be imported. An optional\ndovecot-keywords file can specify additional flags, like Forwarded/Junk/NotJunk.\n`\n\targs := c.Parse()\n\tif len(args) != 3 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdImport(xctl(), false, args[0], args[1], args[2])\n}\n\nfunc cmdImportMbox(c *cmd) {\n\tc.params = \"accountname mailboxname mbox\"\n\tc.help = `Import an mbox into an account.\n\nUsing mbox is not recommended, maildir is a better defined format.\n\n` + importCommonHelp\n\targs := c.Parse()\n\tif len(args) != 3 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdImport(xctl(), true, args[0], args[1], args[2])\n}\n\nfunc cmdXImportMaildir(c *cmd) {\n\tc.unlisted = true\n\tc.params = \"accountdir mailboxname maildir\"\n\tc.help = `Import a maildir into an account by directly accessing the data directory.\n\n\nSee \"mox help import maildir\" for details.\n`\n\txcmdXImport(false, c)\n}\n\nfunc cmdXImportMbox(c *cmd) {\n\tc.unlisted = true\n\tc.params = \"accountdir mailboxname mbox\"\n\tc.help = `Import an mbox into an account by directly accessing the data directory.\n\nSee \"mox help import mbox\" for details.\n`\n\txcmdXImport(true, c)\n}\n\nfunc xcmdXImport(mbox bool, c *cmd) {\n\targs := c.Parse()\n\tif len(args) != 3 {\n\t\tc.Usage()\n\t}\n\n\taccountdir := args[0]\n\taccount := filepath.Base(accountdir)\n\n\t// Set up the mox config so the account can be opened.\n\tif filepath.Base(filepath.Dir(accountdir)) != \"accounts\" {\n\t\tlog.Fatalf(\"accountdir must be of the form .../accounts/<name>\")\n\t}\n\tvar err error\n\tmox.Conf.Static.DataDir, err = filepath.Abs(filepath.Dir(filepath.Dir(accountdir)))\n\txcheckf(err, \"making absolute datadir\")\n\tmox.ConfigStaticPath = \"fake.conf\"\n\tmox.Conf.DynamicLastCheck = time.Now().Add(time.Hour) // Silence errors about config file.\n\tmox.Conf.Dynamic.Accounts = map[string]config.Account{\n\t\taccount: {},\n\t}\n\tdefer store.Switchboard()()\n\n\tcconn, sconn := net.Pipe()\n\tclientctl := ctl{conn: cconn, r: bufio.NewReader(cconn), log: c.log}\n\tserverctl := ctl{conn: sconn, r: bufio.NewReader(sconn), log: c.log}\n\tgo servectlcmd(context.Background(), &serverctl, func() {})\n\n\tctlcmdImport(&clientctl, mbox, account, args[1], args[2])\n}\n\nfunc ctlcmdImport(ctl *ctl, mbox bool, account, mailbox, src string) {\n\tif mbox {\n\t\tctl.xwrite(\"importmbox\")\n\t} else {\n\t\tctl.xwrite(\"importmaildir\")\n\t}\n\tctl.xwrite(account)\n\tif strings.EqualFold(mailbox, \"Inbox\") {\n\t\tmailbox = \"Inbox\"\n\t}\n\tctl.xwrite(mailbox)\n\tctl.xwrite(src)\n\tctl.xreadok()\n\tfmt.Fprintln(os.Stderr, \"importing...\")\n\tfor {\n\t\tline := ctl.xread()\n\t\tif strings.HasPrefix(line, \"progress \") {\n\t\t\tn := line[len(\"progress \"):]\n\t\t\tfmt.Fprintf(os.Stderr, \"%s...\\n\", n)\n\t\t\tcontinue\n\t\t}\n\t\tif line != \"ok\" {\n\t\t\tlog.Fatalf(\"import, expected ok, got %q\", line)\n\t\t}\n\t\tbreak\n\t}\n\tcount := ctl.xread()\n\tfmt.Fprintf(os.Stderr, \"%s imported\\n\", count)\n}\n\nfunc importctl(ctx context.Context, ctl *ctl, mbox bool) {\n\t/* protocol:\n\t> \"importmaildir\" or \"importmbox\"\n\t> account\n\t> mailbox\n\t> src (mbox file or maildir directory)\n\t< \"ok\" or error\n\t< \"progress\" count (zero or more times, once for every 1000 messages)\n\t< \"ok\" when done, or error\n\t< count (of total imported messages, only if not error)\n\t*/\n\taccount := ctl.xread()\n\tmailbox := ctl.xread()\n\tsrc := ctl.xread()\n\n\tkind := \"maildir\"\n\tif mbox {\n\t\tkind = \"mbox\"\n\t}\n\tctl.log.Info(\"importing messages\",\n\t\tslog.String(\"kind\", kind),\n\t\tslog.String(\"account\", account),\n\t\tslog.String(\"mailbox\", mailbox),\n\t\tslog.String(\"source\", src))\n\n\tvar err error\n\tvar mboxf *os.File\n\tvar mdnewf, mdcurf *os.File\n\tvar msgreader store.MsgSource\n\n\t// Open account, creating a database file if it doesn't exist yet. It must be known\n\t// in the configuration file.\n\ta, err := store.OpenAccount(ctl.log, account)\n\tctl.xcheck(err, \"opening account\")\n\tdefer func() {\n\t\tif a != nil {\n\t\t\terr := a.Close()\n\t\t\tctl.log.Check(err, \"closing account after import\")\n\t\t}\n\t}()\n\n\terr = a.ThreadingWait(ctl.log)\n\tctl.xcheck(err, \"waiting for account thread upgrade\")\n\n\tdefer func() {\n\t\tif mboxf != nil {\n\t\t\terr := mboxf.Close()\n\t\t\tctl.log.Check(err, \"closing mbox file after import\")\n\t\t}\n\t\tif mdnewf != nil {\n\t\t\terr := mdnewf.Close()\n\t\t\tctl.log.Check(err, \"closing maildir new after import\")\n\t\t}\n\t\tif mdcurf != nil {\n\t\t\terr := mdcurf.Close()\n\t\t\tctl.log.Check(err, \"closing maildir cur after import\")\n\t\t}\n\t}()\n\n\t// Messages don't always have a junk flag set. We'll assume anything in a mailbox\n\t// starting with junk or spam is junk mail.\n\n\t// First check if we can access the mbox/maildir.\n\t// Mox needs to be able to access those files, the user running the import command\n\t// may be a different user who can access the files.\n\tif mbox {\n\t\tmboxf, err = os.Open(src)\n\t\tctl.xcheck(err, \"open mbox file\")\n\t\tmsgreader = store.NewMboxReader(ctl.log, store.CreateMessageTemp, src, mboxf)\n\t} else {\n\t\tmdnewf, err = os.Open(filepath.Join(src, \"new\"))\n\t\tctl.xcheck(err, \"open subdir new of maildir\")\n\t\tmdcurf, err = os.Open(filepath.Join(src, \"cur\"))\n\t\tctl.xcheck(err, \"open subdir cur of maildir\")\n\t\tmsgreader = store.NewMaildirReader(ctl.log, store.CreateMessageTemp, mdnewf, mdcurf)\n\t}\n\n\ttx, err := a.DB.Begin(ctx, true)\n\tctl.xcheck(err, \"begin transaction\")\n\tdefer func() {\n\t\tif tx != nil {\n\t\t\terr := tx.Rollback()\n\t\t\tctl.log.Check(err, \"rolling back transaction\")\n\t\t}\n\t}()\n\n\t// All preparations done. Good to go.\n\tctl.xwriteok()\n\n\t// We will be delivering messages. If we fail halfway, we need to remove the created msg files.\n\tvar deliveredIDs []int64\n\n\tdefer func() {\n\t\tx := recover()\n\t\tif x == nil {\n\t\t\treturn\n\t\t}\n\n\t\tif x != ctl.x {\n\t\t\tctl.log.Error(\"import error\", slog.String(\"panic\", fmt.Sprintf(\"%v\", x)))\n\t\t\tdebug.PrintStack()\n\t\t\tmetrics.PanicInc(metrics.Import)\n\t\t} else {\n\t\t\tctl.log.Error(\"import error\")\n\t\t}\n\n\t\tfor _, id := range deliveredIDs {\n\t\t\tp := a.MessagePath(id)\n\t\t\terr := os.Remove(p)\n\t\t\tctl.log.Check(err, \"closing message file after import error\", slog.String(\"path\", p))\n\t\t}\n\n\t\tctl.xerror(fmt.Sprintf(\"import error: %v\", x))\n\t}()\n\n\tvar changes []store.Change\n\n\tvar modseq store.ModSeq // Assigned on first delivered messages, used for all messages.\n\n\txdeliver := func(m *store.Message, mf *os.File) {\n\t\t// todo: possibly set dmarcdomain to the domain of the from address? at least for non-spams that have been seen. otherwise user would start without any reputations. the assumption would be that the user has accepted email and deemed it legit, coming from the indicated sender.\n\n\t\tconst sync = false\n\t\tconst notrain = true\n\t\tconst nothreads = true\n\t\tconst updateDiskUsage = false\n\t\terr := a.DeliverMessage(ctl.log, tx, m, mf, sync, notrain, nothreads, updateDiskUsage)\n\t\tctl.xcheck(err, \"delivering message\")\n\t\tdeliveredIDs = append(deliveredIDs, m.ID)\n\t\tctl.log.Debug(\"delivered message\", slog.Int64(\"id\", m.ID))\n\t\tchanges = append(changes, m.ChangeAddUID())\n\t}\n\n\t// todo: one goroutine for reading messages, one for parsing the message, one adding to database, one for junk filter training.\n\tn := 0\n\ta.WithWLock(func() {\n\t\t// Ensure mailbox exists.\n\t\tvar mb store.Mailbox\n\t\tmb, changes, err = a.MailboxEnsure(tx, mailbox, true)\n\t\tctl.xcheck(err, \"ensuring mailbox exists\")\n\n\t\t// We ensure keywords in messages make it to the mailbox as well.\n\t\tmailboxKeywords := map[string]bool{}\n\n\t\tjf, _, err := a.OpenJunkFilter(ctx, ctl.log)\n\t\tif err != nil && !errors.Is(err, store.ErrNoJunkFilter) {\n\t\t\tctl.xcheck(err, \"open junk filter\")\n\t\t}\n\t\tdefer func() {\n\t\t\tif jf != nil {\n\t\t\t\terr = jf.Close()\n\t\t\t\tctl.xcheck(err, \"close junk filter\")\n\t\t\t}\n\t\t}()\n\n\t\tconf, _ := a.Conf()\n\n\t\tmaxSize := a.QuotaMessageSize()\n\t\tvar addSize int64\n\t\tdu := store.DiskUsage{ID: 1}\n\t\terr = tx.Get(&du)\n\t\tctl.xcheck(err, \"get disk usage\")\n\n\t\tprocess := func(m *store.Message, msgf *os.File, origPath string) {\n\t\t\tdefer store.CloseRemoveTempFile(ctl.log, msgf, \"message to import\")\n\n\t\t\taddSize += m.Size\n\t\t\tif maxSize > 0 && du.MessageSize+addSize > maxSize {\n\t\t\t\tctl.xcheck(fmt.Errorf(\"account over maximum total message size %d\", maxSize), \"checking quota\")\n\t\t\t}\n\n\t\t\tfor _, kw := range m.Keywords {\n\t\t\t\tmailboxKeywords[kw] = true\n\t\t\t}\n\t\t\tmb.Add(m.MailboxCounts())\n\n\t\t\t// Parse message and store parsed information for later fast retrieval.\n\t\t\tp, err := message.EnsurePart(ctl.log.Logger, false, msgf, m.Size)\n\t\t\tif err != nil {\n\t\t\t\tctl.log.Infox(\"parsing message, continuing\", err, slog.String(\"path\", origPath))\n\t\t\t}\n\t\t\tm.ParsedBuf, err = json.Marshal(p)\n\t\t\tctl.xcheck(err, \"marshal parsed message structure\")\n\n\t\t\t// Set fields needed for future threading. By doing it now, DeliverMessage won't\n\t\t\t// have to parse the Part again.\n\t\t\tp.SetReaderAt(store.FileMsgReader(m.MsgPrefix, msgf))\n\t\t\tm.PrepareThreading(ctl.log, &p)\n\n\t\t\tif m.Received.IsZero() {\n\t\t\t\tif p.Envelope != nil && !p.Envelope.Date.IsZero() {\n\t\t\t\t\tm.Received = p.Envelope.Date\n\t\t\t\t} else {\n\t\t\t\t\tm.Received = time.Now()\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// We set the flags that Deliver would set now and train ourselves. This prevents\n\t\t\t// Deliver from training, which would open the junk filter, change it, and write it\n\t\t\t// back to disk, for each message (slow).\n\t\t\tm.JunkFlagsForMailbox(mb, conf)\n\t\t\tif jf != nil && m.NeedsTraining() {\n\t\t\t\tif words, err := jf.ParseMessage(p); err != nil {\n\t\t\t\t\tctl.log.Infox(\"parsing message for updating junk filter\", err, slog.String(\"parse\", \"\"), slog.String(\"path\", origPath))\n\t\t\t\t} else {\n\t\t\t\t\terr = jf.Train(ctx, !m.Junk, words)\n\t\t\t\t\tctl.xcheck(err, \"training junk filter\")\n\t\t\t\t\tm.TrainedJunk = &m.Junk\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif modseq == 0 {\n\t\t\t\tvar err error\n\t\t\t\tmodseq, err = a.NextModSeq(tx)\n\t\t\t\tctl.xcheck(err, \"assigning next modseq\")\n\t\t\t}\n\n\t\t\tm.MailboxID = mb.ID\n\t\t\tm.MailboxOrigID = mb.ID\n\t\t\tm.CreateSeq = modseq\n\t\t\tm.ModSeq = modseq\n\t\t\txdeliver(m, msgf)\n\n\t\t\tn++\n\t\t\tif n%1000 == 0 {\n\t\t\t\tctl.xwrite(fmt.Sprintf(\"progress %d\", n))\n\t\t\t}\n\t\t}\n\n\t\tfor {\n\t\t\tm, msgf, origPath, err := msgreader.Next()\n\t\t\tif err == io.EOF {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tctl.xcheck(err, \"reading next message\")\n\n\t\t\tprocess(m, msgf, origPath)\n\t\t}\n\n\t\t// Match threads.\n\t\tif len(deliveredIDs) > 0 {\n\t\t\terr = a.AssignThreads(ctx, ctl.log, tx, deliveredIDs[0], 0, io.Discard)\n\t\t\tctl.xcheck(err, \"assigning messages to threads\")\n\t\t}\n\n\t\t// Get mailbox again, uidnext is likely updated.\n\t\tmc := mb.MailboxCounts\n\t\terr = tx.Get(&mb)\n\t\tctl.xcheck(err, \"get mailbox\")\n\t\tmb.MailboxCounts = mc\n\n\t\t// If there are any new keywords, update the mailbox.\n\t\tvar mbKwChanged bool\n\t\tmb.Keywords, mbKwChanged = store.MergeKeywords(mb.Keywords, maps.Keys(mailboxKeywords))\n\t\tif mbKwChanged {\n\t\t\tchanges = append(changes, mb.ChangeKeywords())\n\t\t}\n\n\t\terr = tx.Update(&mb)\n\t\tctl.xcheck(err, \"updating message counts and keywords in mailbox\")\n\t\tchanges = append(changes, mb.ChangeCounts())\n\n\t\terr = a.AddMessageSize(ctl.log, tx, addSize)\n\t\txcheckf(err, \"updating total message size\")\n\n\t\terr = tx.Commit()\n\t\tctl.xcheck(err, \"commit\")\n\t\ttx = nil\n\t\tctl.log.Info(\"delivered messages through import\", slog.Int(\"count\", len(deliveredIDs)))\n\t\tdeliveredIDs = nil\n\n\t\tstore.BroadcastChanges(a, changes)\n\t})\n\n\terr = a.Close()\n\tctl.xcheck(err, \"closing account\")\n\ta = nil\n\n\tctl.xwriteok()\n\tctl.xwrite(fmt.Sprintf(\"%d\", n))\n}\n"
        },
        {
          "name": "integration_test.go",
          "type": "blob",
          "size": 5.8544921875,
          "content": "//go:build integration\n\n// todo: set up a test for dane, mta-sts, etc.\n\npackage main\n\nimport (\n\t\"crypto/tls\"\n\t\"fmt\"\n\t\"log/slog\"\n\t\"net\"\n\t\"os\"\n\t\"os/exec\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/mjl-/mox/dns\"\n\t\"github.com/mjl-/mox/imapclient\"\n\t\"github.com/mjl-/mox/mlog\"\n\t\"github.com/mjl-/mox/mox-\"\n\t\"github.com/mjl-/mox/sasl\"\n\t\"github.com/mjl-/mox/smtpclient\"\n)\n\nfunc tcheck(t *testing.T, err error, errmsg string) {\n\tif err != nil {\n\t\tt.Helper()\n\t\tt.Fatalf(\"%s: %s\", errmsg, err)\n\t}\n}\n\nfunc TestDeliver(t *testing.T) {\n\tlog := mlog.New(\"integration\", nil)\n\tmlog.Logfmt = true\n\n\thostname, err := os.Hostname()\n\ttcheck(t, err, \"hostname\")\n\tourHostname, err := dns.ParseDomain(hostname)\n\ttcheck(t, err, \"parse hostname\")\n\n\t// Single update from IMAP IDLE.\n\ttype idleResponse struct {\n\t\tuntagged imapclient.Untagged\n\t\terr      error\n\t}\n\n\t// Deliver submits a message over submissions, and checks with imap idle if the\n\t// message is received by the destination mail server.\n\tdeliver := func(checkTime bool, dialtls bool, imaphost, imapuser, imappassword string, send func()) {\n\t\tt.Helper()\n\n\t\t// Connect to IMAP, execute IDLE command, which will return on deliver message.\n\t\t// TLS certificates work because the container has the CA certificates configured.\n\t\tvar imapconn net.Conn\n\t\tvar err error\n\t\tif dialtls {\n\t\t\timapconn, err = tls.Dial(\"tcp\", imaphost, nil)\n\t\t} else {\n\t\t\timapconn, err = net.Dial(\"tcp\", imaphost)\n\t\t}\n\t\ttcheck(t, err, \"dial imap\")\n\t\tdefer imapconn.Close()\n\n\t\timapc, err := imapclient.New(imapconn, false)\n\t\ttcheck(t, err, \"new imapclient\")\n\n\t\t_, _, err = imapc.Login(imapuser, imappassword)\n\t\ttcheck(t, err, \"imap login\")\n\n\t\t_, _, err = imapc.Select(\"Inbox\")\n\t\ttcheck(t, err, \"imap select inbox\")\n\n\t\terr = imapc.Commandf(\"\", \"idle\")\n\t\ttcheck(t, err, \"write imap idle command\")\n\n\t\t_, _, _, err = imapc.ReadContinuation()\n\t\ttcheck(t, err, \"read imap continuation\")\n\n\t\tidle := make(chan idleResponse)\n\t\tgo func() {\n\t\t\tfor {\n\t\t\t\tuntagged, err := imapc.ReadUntagged()\n\t\t\t\tidle <- idleResponse{untagged, err}\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t\tdefer func() {\n\t\t\terr := imapc.Writelinef(\"done\")\n\t\t\ttcheck(t, err, \"aborting idle\")\n\t\t}()\n\n\t\tt0 := time.Now()\n\t\tsend()\n\n\t\t// Wait for notification of delivery.\n\t\tselect {\n\t\tcase resp := <-idle:\n\t\t\ttcheck(t, resp.err, \"idle notification\")\n\t\t\t_, ok := resp.untagged.(imapclient.UntaggedExists)\n\t\t\tif !ok {\n\t\t\t\tt.Fatalf(\"got idle %#v, expected untagged exists\", resp.untagged)\n\t\t\t}\n\t\t\tif d := time.Since(t0); checkTime && d < 1*time.Second {\n\t\t\t\tt.Fatalf(\"delivery took %v, but should have taken at least 1 second, the first-time sender delay\", d)\n\t\t\t}\n\t\tcase <-time.After(30 * time.Second):\n\t\t\tt.Fatalf(\"timeout after 5s waiting for IMAP IDLE notification of new message, should take about 1 second\")\n\t\t}\n\t}\n\n\tsubmit := func(dialtls bool, mailfrom, password, desthost, rcptto string) {\n\t\tvar conn net.Conn\n\t\tvar err error\n\t\tif dialtls {\n\t\t\tconn, err = tls.Dial(\"tcp\", desthost, nil)\n\t\t} else {\n\t\t\tconn, err = net.Dial(\"tcp\", desthost)\n\t\t}\n\t\ttcheck(t, err, \"dial submission\")\n\t\tdefer conn.Close()\n\n\t\tmsg := fmt.Sprintf(`From: <%s>\nTo: <%s>\nSubject: test message\n\nThis is the message.\n`, mailfrom, rcptto)\n\t\tmsg = strings.ReplaceAll(msg, \"\\n\", \"\\r\\n\")\n\t\tauth := func(mechanisms []string, cs *tls.ConnectionState) (sasl.Client, error) {\n\t\t\treturn sasl.NewClientPlain(mailfrom, password), nil\n\t\t}\n\t\tc, err := smtpclient.New(mox.Context, log.Logger, conn, smtpclient.TLSSkip, false, ourHostname, dns.Domain{ASCII: desthost}, smtpclient.Opts{Auth: auth})\n\t\ttcheck(t, err, \"smtp hello\")\n\t\terr = c.Deliver(mox.Context, mailfrom, rcptto, int64(len(msg)), strings.NewReader(msg), false, false, false)\n\t\ttcheck(t, err, \"deliver with smtp\")\n\t\terr = c.Close()\n\t\ttcheck(t, err, \"close smtpclient\")\n\t}\n\n\t// Make sure moxacmepebble has a TLS certificate.\n\tconn, err := tls.Dial(\"tcp\", \"moxacmepebble.mox1.example:465\", nil)\n\ttcheck(t, err, \"dial submission\")\n\tdefer conn.Close()\n\n\tlog.Print(\"submitting email to moxacmepebble, waiting for imap notification at moxmail2\")\n\tt0 := time.Now()\n\tdeliver(true, true, \"moxmail2.mox2.example:993\", \"moxtest2@mox2.example\", \"accountpass4321\", func() {\n\t\tsubmit(true, \"moxtest1@mox1.example\", \"accountpass1234\", \"moxacmepebble.mox1.example:465\", \"moxtest2@mox2.example\")\n\t})\n\tlog.Print(\"success\", slog.Duration(\"duration\", time.Since(t0)))\n\n\tlog.Print(\"submitting email to moxmail2, waiting for imap notification at moxacmepebble\")\n\tt0 = time.Now()\n\tdeliver(true, true, \"moxacmepebble.mox1.example:993\", \"moxtest1@mox1.example\", \"accountpass1234\", func() {\n\t\tsubmit(true, \"moxtest2@mox2.example\", \"accountpass4321\", \"moxmail2.mox2.example:465\", \"moxtest1@mox1.example\")\n\t})\n\tlog.Print(\"success\", slog.Duration(\"duration\", time.Since(t0)))\n\n\tlog.Print(\"submitting email to postfix, waiting for imap notification at moxacmepebble\")\n\tt0 = time.Now()\n\tdeliver(false, true, \"moxacmepebble.mox1.example:993\", \"moxtest1@mox1.example\", \"accountpass1234\", func() {\n\t\tsubmit(true, \"moxtest1@mox1.example\", \"accountpass1234\", \"moxacmepebble.mox1.example:465\", \"root@postfix.example\")\n\t})\n\tlog.Print(\"success\", slog.Duration(\"duration\", time.Since(t0)))\n\n\tlog.Print(\"submitting email to localserve\")\n\tt0 = time.Now()\n\tdeliver(false, false, \"localserve.mox1.example:1143\", \"mox@localhost\", \"moxmoxmox\", func() {\n\t\tsubmit(false, \"mox@localhost\", \"moxmoxmox\", \"localserve.mox1.example:1587\", \"moxtest1@mox1.example\")\n\t})\n\tlog.Print(\"success\", slog.Duration(\"duration\", time.Since(t0)))\n\n\tlog.Print(\"submitting email to localserve\")\n\tt0 = time.Now()\n\tdeliver(false, false, \"localserve.mox1.example:1143\", \"mox@localhost\", \"moxmoxmox\", func() {\n\t\tcmd := exec.Command(\"go\", \"run\", \".\", \"sendmail\", \"mox@localhost\")\n\t\tconst msg = `Subject: test\n\na message.\n`\n\t\tcmd.Stdin = strings.NewReader(msg)\n\t\tvar out strings.Builder\n\t\tcmd.Stdout = &out\n\t\terr := cmd.Run()\n\t\tlog.Print(\"sendmail\", slog.String(\"output\", out.String()))\n\t\ttcheck(t, err, \"sendmail\")\n\t})\n\tlog.Print(\"success\", slog.Any(\"duration\", time.Since(t0)))\n}\n"
        },
        {
          "name": "iprev",
          "type": "tree",
          "content": null
        },
        {
          "name": "junk.go",
          "type": "blob",
          "size": 12.607421875,
          "content": "package main\n\n/*\nnote: these testdata paths are not in the repo, you should gather some of your\nown ham/spam emails.\n\n./mox junk train testdata/train/ham testdata/train/spam\n./mox junk train -sent-dir testdata/sent testdata/train/ham testdata/train/spam\n./mox junk check 'testdata/check/ham/mail1'\n./mox junk test testdata/check/ham testdata/check/spam\n./mox junk analyze testdata/train/ham testdata/train/spam\n./mox junk analyze -top-words 10 -train-ratio 0.5 -spam-threshold 0.85 -max-power 0.01 -sent-dir testdata/sent testdata/train/ham testdata/train/spam\n./mox junk play -top-words 10 -train-ratio 0.5 -spam-threshold 0.85 -max-power 0.01 -sent-dir testdata/sent testdata/train/ham testdata/train/spam\n*/\n\nimport (\n\t\"context\"\n\t\"flag\"\n\t\"fmt\"\n\t\"log\"\n\tmathrand \"math/rand\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"sort\"\n\t\"time\"\n\n\t\"github.com/mjl-/mox/junk\"\n\t\"github.com/mjl-/mox/message\"\n\t\"github.com/mjl-/mox/mlog\"\n\t\"github.com/mjl-/mox/mox-\"\n)\n\ntype junkArgs struct {\n\tparams                        junk.Params\n\tspamThreshold                 float64\n\ttrainRatio                    float64\n\tseed                          bool\n\tsentDir                       string\n\tdatabasePath, bloomfilterPath string\n\tdebug                         bool\n}\n\nfunc (a junkArgs) SetLogLevel() {\n\tmox.Conf.Log[\"\"] = mlog.LevelInfo\n\tif a.debug {\n\t\tmox.Conf.Log[\"\"] = mlog.LevelDebug\n\t}\n\tmlog.SetConfig(mox.Conf.Log)\n}\n\nfunc junkFlags(fs *flag.FlagSet) (a junkArgs) {\n\tfs.BoolVar(&a.params.Onegrams, \"one-grams\", false, \"use 1-grams, i.e. single words, for scoring\")\n\tfs.BoolVar(&a.params.Twograms, \"two-grams\", true, \"use 2-grams, i.e. word pairs, for scoring\")\n\tfs.BoolVar(&a.params.Threegrams, \"three-grams\", false, \"use 3-grams, i.e. word triplets, for scoring\")\n\tfs.Float64Var(&a.params.MaxPower, \"max-power\", 0.05, \"maximum word power, e.g. min 0.05/max 0.95\")\n\tfs.Float64Var(&a.params.IgnoreWords, \"ignore-words\", 0.1, \"ignore words with ham/spaminess within this distance from 0.5\")\n\tfs.IntVar(&a.params.TopWords, \"top-words\", 10, \"number of top spam and number of top ham words from email to use\")\n\tfs.IntVar(&a.params.RareWords, \"rare-words\", 1, \"words are rare if encountered this number during training, and skipped for scoring\")\n\tfs.BoolVar(&a.debug, \"debug\", false, \"print debug logging when calculating spam probability\")\n\n\tfs.Float64Var(&a.spamThreshold, \"spam-threshold\", 0.95, \"probability where message is seen as spam\")\n\tfs.Float64Var(&a.trainRatio, \"train-ratio\", 0.5, \"part of data to use for training versus analyzing (for analyze only)\")\n\tfs.StringVar(&a.sentDir, \"sent-dir\", \"\", \"directory with sent mails, for training\")\n\tfs.BoolVar(&a.seed, \"seed\", false, \"seed prng before analysis\")\n\tfs.StringVar(&a.databasePath, \"dbpath\", \"filter.db\", \"database file for ham/spam words\")\n\tfs.StringVar(&a.bloomfilterPath, \"bloompath\", \"filter.bloom\", \"bloom filter for ignoring unique strings\")\n\n\treturn\n}\n\nfunc listDir(dir string) (l []string) {\n\tfiles, err := os.ReadDir(dir)\n\txcheckf(err, \"listing directory %q\", dir)\n\tfor _, f := range files {\n\t\tl = append(l, f.Name())\n\t}\n\treturn l\n}\n\nfunc must(f *junk.Filter, err error) *junk.Filter {\n\txcheckf(err, \"filter\")\n\treturn f\n}\n\nfunc cmdJunkTrain(c *cmd) {\n\tc.unlisted = true\n\tc.params = \"hamdir spamdir\"\n\tc.help = \"Train a junk filter with messages from hamdir and spamdir.\"\n\ta := junkFlags(c.flag)\n\targs := c.Parse()\n\tif len(args) != 2 {\n\t\tc.Usage()\n\t}\n\ta.SetLogLevel()\n\n\tf := must(junk.NewFilter(context.Background(), c.log, a.params, a.databasePath, a.bloomfilterPath))\n\tdefer func() {\n\t\tif err := f.Close(); err != nil {\n\t\t\tlog.Printf(\"closing junk filter: %v\", err)\n\t\t}\n\t}()\n\n\thamFiles := listDir(args[0])\n\tspamFiles := listDir(args[1])\n\tvar sentFiles []string\n\tif a.sentDir != \"\" {\n\t\tsentFiles = listDir(a.sentDir)\n\t}\n\n\terr := f.TrainDirs(args[0], a.sentDir, args[1], hamFiles, sentFiles, spamFiles)\n\txcheckf(err, \"train\")\n}\n\nfunc cmdJunkCheck(c *cmd) {\n\tc.unlisted = true\n\tc.params = \"mailfile\"\n\tc.help = \"Check an email message against a junk filter, printing the probability of spam on a scale from 0 to 1.\"\n\ta := junkFlags(c.flag)\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\ta.SetLogLevel()\n\n\tf := must(junk.OpenFilter(context.Background(), c.log, a.params, a.databasePath, a.bloomfilterPath, false))\n\tdefer func() {\n\t\tif err := f.Close(); err != nil {\n\t\t\tlog.Printf(\"closing junk filter: %v\", err)\n\t\t}\n\t}()\n\n\tprob, _, _, _, err := f.ClassifyMessagePath(context.Background(), args[0])\n\txcheckf(err, \"testing mail\")\n\n\tfmt.Printf(\"%.6f\\n\", prob)\n}\n\nfunc cmdJunkTest(c *cmd) {\n\tc.unlisted = true\n\tc.params = \"hamdir spamdir\"\n\tc.help = \"Check a directory with hams and one with spams against the junk filter, and report the success ratio.\"\n\ta := junkFlags(c.flag)\n\targs := c.Parse()\n\tif len(args) != 2 {\n\t\tc.Usage()\n\t}\n\ta.SetLogLevel()\n\n\tf := must(junk.OpenFilter(context.Background(), c.log, a.params, a.databasePath, a.bloomfilterPath, false))\n\tdefer func() {\n\t\tif err := f.Close(); err != nil {\n\t\t\tlog.Printf(\"closing junk filter: %v\", err)\n\t\t}\n\t}()\n\n\ttestDir := func(dir string, ham bool) (int, int) {\n\t\tok, bad := 0, 0\n\t\tfiles, err := os.ReadDir(dir)\n\t\txcheckf(err, \"readdir %q\", dir)\n\t\tfor _, fi := range files {\n\t\t\tpath := filepath.Join(dir, fi.Name())\n\t\t\tprob, _, _, _, err := f.ClassifyMessagePath(context.Background(), path)\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"classify message %q: %s\", path, err)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif ham && prob < a.spamThreshold || !ham && prob > a.spamThreshold {\n\t\t\t\tok++\n\t\t\t} else {\n\t\t\t\tbad++\n\t\t\t}\n\t\t\tif ham && prob > a.spamThreshold {\n\t\t\t\tfmt.Printf(\"ham %q: %.4f\\n\", path, prob)\n\t\t\t}\n\t\t\tif !ham && prob < a.spamThreshold {\n\t\t\t\tfmt.Printf(\"spam %q: %.4f\\n\", path, prob)\n\t\t\t}\n\t\t}\n\t\treturn ok, bad\n\t}\n\n\tnhamok, nhambad := testDir(args[0], true)\n\tnspamok, nspambad := testDir(args[1], false)\n\tfmt.Printf(\"total ham, ok %d, bad %d\\n\", nhamok, nhambad)\n\tfmt.Printf(\"total spam, ok %d, bad %d\\n\", nspamok, nspambad)\n\tfmt.Printf(\"specifity (true negatives, hams identified): %.6f\\n\", float64(nhamok)/(float64(nhamok+nhambad)))\n\tfmt.Printf(\"sensitivity (true positives, spams identified): %.6f\\n\", float64(nspamok)/(float64(nspamok+nspambad)))\n\tfmt.Printf(\"accuracy: %.6f\\n\", float64(nhamok+nspamok)/float64(nhamok+nhambad+nspamok+nspambad))\n}\n\nfunc cmdJunkAnalyze(c *cmd) {\n\tc.unlisted = true\n\tc.params = \"hamdir spamdir\"\n\tc.help = `Analyze a directory with ham messages and one with spam messages.\n\nA part of the messages is used for training, and remaining for testing. The\nmessages are shuffled, with optional random seed.`\n\ta := junkFlags(c.flag)\n\targs := c.Parse()\n\tif len(args) != 2 {\n\t\tc.Usage()\n\t}\n\ta.SetLogLevel()\n\n\tf := must(junk.NewFilter(context.Background(), c.log, a.params, a.databasePath, a.bloomfilterPath))\n\tdefer func() {\n\t\tif err := f.Close(); err != nil {\n\t\t\tlog.Printf(\"closing junk filter: %v\", err)\n\t\t}\n\t}()\n\n\thamDir := args[0]\n\tspamDir := args[1]\n\thamFiles := listDir(hamDir)\n\tspamFiles := listDir(spamDir)\n\n\tvar seed int64\n\tif a.seed {\n\t\tseed = time.Now().UnixMilli()\n\t}\n\t// Still at math/rand (v1 instead of v2) for potential comparison to earlier test results.\n\trand := mathrand.New(mathrand.NewSource(seed))\n\n\tshuffle := func(l []string) {\n\t\tcount := len(l)\n\t\tfor i := range l {\n\t\t\tn := rand.Intn(count)\n\t\t\tl[i], l[n] = l[n], l[i]\n\t\t}\n\t}\n\n\tshuffle(hamFiles)\n\tshuffle(spamFiles)\n\n\tntrainham := int(a.trainRatio * float64(len(hamFiles)))\n\tntrainspam := int(a.trainRatio * float64(len(spamFiles)))\n\n\ttrainHam := hamFiles[:ntrainham]\n\ttrainSpam := spamFiles[:ntrainspam]\n\ttestHam := hamFiles[ntrainham:]\n\ttestSpam := spamFiles[ntrainspam:]\n\n\tvar trainSent []string\n\tif a.sentDir != \"\" {\n\t\ttrainSent = listDir(a.sentDir)\n\t}\n\n\terr := f.TrainDirs(hamDir, a.sentDir, spamDir, trainHam, trainSent, trainSpam)\n\txcheckf(err, \"train\")\n\n\ttestDir := func(dir string, files []string, ham bool) (ok, bad, malformed int) {\n\t\tfor _, name := range files {\n\t\t\tpath := filepath.Join(dir, name)\n\t\t\tprob, _, _, _, err := f.ClassifyMessagePath(context.Background(), path)\n\t\t\tif err != nil {\n\t\t\t\t// log.Infof(\"%s: %s\", path, err)\n\t\t\t\tmalformed++\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif ham && prob < a.spamThreshold || !ham && prob > a.spamThreshold {\n\t\t\t\tok++\n\t\t\t} else {\n\t\t\t\tbad++\n\t\t\t}\n\t\t\tif ham && prob > a.spamThreshold {\n\t\t\t\tfmt.Printf(\"ham %q: %.4f\\n\", path, prob)\n\t\t\t}\n\t\t\tif !ham && prob < a.spamThreshold {\n\t\t\t\tfmt.Printf(\"spam %q: %.4f\\n\", path, prob)\n\t\t\t}\n\t\t}\n\t\treturn\n\t}\n\n\tnhamok, nhambad, nmalformedham := testDir(args[0], testHam, true)\n\tnspamok, nspambad, nmalformedspam := testDir(args[1], testSpam, false)\n\tfmt.Printf(\"training done, nham %d, nsent %d, nspam %d\\n\", ntrainham, len(trainSent), ntrainspam)\n\tfmt.Printf(\"total ham, ok %d, bad %d, malformed %d\\n\", nhamok, nhambad, nmalformedham)\n\tfmt.Printf(\"total spam, ok %d, bad %d, malformed %d\\n\", nspamok, nspambad, nmalformedspam)\n\tfmt.Printf(\"specifity (true negatives, hams identified): %.6f\\n\", float64(nhamok)/(float64(nhamok+nhambad)))\n\tfmt.Printf(\"sensitivity (true positives, spams identified): %.6f\\n\", float64(nspamok)/(float64(nspamok+nspambad)))\n\tfmt.Printf(\"accuracy: %.6f\\n\", float64(nhamok+nspamok)/float64(nhamok+nhambad+nspamok+nspambad))\n}\n\nfunc cmdJunkPlay(c *cmd) {\n\tc.unlisted = true\n\tc.params = \"hamdir spamdir\"\n\tc.help = \"Play messages from ham and spam directory according to their time of arrival and report on junk filter performance.\"\n\ta := junkFlags(c.flag)\n\targs := c.Parse()\n\tif len(args) != 2 {\n\t\tc.Usage()\n\t}\n\ta.SetLogLevel()\n\n\tf := must(junk.NewFilter(context.Background(), c.log, a.params, a.databasePath, a.bloomfilterPath))\n\tdefer func() {\n\t\tif err := f.Close(); err != nil {\n\t\t\tlog.Printf(\"closing junk filter: %v\", err)\n\t\t}\n\t}()\n\n\t// We'll go through all emails to find their dates.\n\ttype msg struct {\n\t\tdir, filename string\n\t\tham, sent     bool\n\t\tt             time.Time\n\t}\n\tvar msgs []msg\n\n\tvar nbad, nnodate, nham, nspam, nsent int\n\n\tscanDir := func(dir string, ham, sent bool) {\n\t\tfor _, name := range listDir(dir) {\n\t\t\tpath := filepath.Join(dir, name)\n\t\t\tmf, err := os.Open(path)\n\t\t\txcheckf(err, \"open %q\", path)\n\t\t\tfi, err := mf.Stat()\n\t\t\txcheckf(err, \"stat %q\", path)\n\t\t\tp, err := message.EnsurePart(c.log.Logger, false, mf, fi.Size())\n\t\t\tif err != nil {\n\t\t\t\tnbad++\n\t\t\t\tif err := mf.Close(); err != nil {\n\t\t\t\t\tlog.Printf(\"closing message file: %v\", err)\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif p.Envelope.Date.IsZero() {\n\t\t\t\tnnodate++\n\t\t\t\tif err := mf.Close(); err != nil {\n\t\t\t\t\tlog.Printf(\"closing message file: %v\", err)\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif err := mf.Close(); err != nil {\n\t\t\t\tlog.Printf(\"closing message file: %v\", err)\n\t\t\t}\n\t\t\tmsgs = append(msgs, msg{dir, name, ham, sent, p.Envelope.Date})\n\t\t\tif sent {\n\t\t\t\tnsent++\n\t\t\t} else if ham {\n\t\t\t\tnham++\n\t\t\t} else {\n\t\t\t\tnspam++\n\t\t\t}\n\t\t}\n\t}\n\n\thamDir := args[0]\n\tspamDir := args[1]\n\tscanDir(hamDir, true, false)\n\tscanDir(spamDir, false, false)\n\tif a.sentDir != \"\" {\n\t\tscanDir(a.sentDir, true, true)\n\t}\n\n\t// Sort the messages, earliest first.\n\tsort.Slice(msgs, func(i, j int) bool {\n\t\treturn msgs[i].t.Before(msgs[j].t)\n\t})\n\n\t// Play all messages as if they are coming in. We predict their spaminess, check if\n\t// we are right. And we train the system with the result.\n\tvar nhamok, nhambad, nspamok, nspambad int\n\n\tplay := func(msg msg) {\n\t\tvar words map[string]struct{}\n\t\tpath := filepath.Join(msg.dir, msg.filename)\n\t\tif !msg.sent {\n\t\t\tvar prob float64\n\t\t\tvar err error\n\t\t\tprob, words, _, _, err = f.ClassifyMessagePath(context.Background(), path)\n\t\t\tif err != nil {\n\t\t\t\tnbad++\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif msg.ham {\n\t\t\t\tif prob < a.spamThreshold {\n\t\t\t\t\tnhamok++\n\t\t\t\t} else {\n\t\t\t\t\tnhambad++\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif prob > a.spamThreshold {\n\t\t\t\t\tnspamok++\n\t\t\t\t} else {\n\t\t\t\t\tnspambad++\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tmf, err := os.Open(path)\n\t\t\txcheckf(err, \"open %q\", path)\n\t\t\tdefer func() {\n\t\t\t\tif err := mf.Close(); err != nil {\n\t\t\t\t\tlog.Printf(\"closing message file: %v\", err)\n\t\t\t\t}\n\t\t\t}()\n\t\t\tfi, err := mf.Stat()\n\t\t\txcheckf(err, \"stat %q\", path)\n\t\t\tp, err := message.EnsurePart(c.log.Logger, false, mf, fi.Size())\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"bad sent message %q: %s\", path, err)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\twords, err = f.ParseMessage(p)\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"bad sent message %q: %s\", path, err)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tif err := f.Train(context.Background(), msg.ham, words); err != nil {\n\t\t\tlog.Printf(\"train: %s\", err)\n\t\t}\n\t}\n\n\tfor _, m := range msgs {\n\t\tplay(m)\n\t}\n\n\terr := f.Save()\n\txcheckf(err, \"saving filter\")\n\n\tfmt.Printf(\"completed, nham %d, nsent %d, nspam %d, nbad %d, nwithoutdate %d\\n\", nham, nsent, nspam, nbad, nnodate)\n\tfmt.Printf(\"total ham, ok %d, bad %d\\n\", nhamok, nhambad)\n\tfmt.Printf(\"total spam, ok %d, bad %d\\n\", nspamok, nspambad)\n\tfmt.Printf(\"specifity (true negatives, hams identified): %.6f\\n\", float64(nhamok)/(float64(nhamok+nhambad)))\n\tfmt.Printf(\"sensitivity (true positives, spams identified): %.6f\\n\", float64(nspamok)/(float64(nspamok+nspambad)))\n\tfmt.Printf(\"accuracy: %.6f\\n\", float64(nhamok+nspamok)/float64(nhamok+nhambad+nspamok+nspambad))\n}\n"
        },
        {
          "name": "junk",
          "type": "tree",
          "content": null
        },
        {
          "name": "lib.ts",
          "type": "blob",
          "size": 11.3583984375,
          "content": "// Javascript is generated from typescript, do not modify generated javascript because changes will be overwritten.\n\ntype ElemArg = string | String | Element | Function | {_class: string[]} | {_attrs: {[k: string]: string}} | {_styles: {[k: string]: string | number}} | {_props: {[k: string]: any}} | {root: HTMLElement} | ElemArg[]\n\nconst [dom, style, attr, prop] = (function() {\n\n// Start of unicode block (rough approximation of script), from https://www.unicode.org/Public/UNIDATA/Blocks.txt\nconst scriptblocks = [0x0000, 0x0080, 0x0100, 0x0180, 0x0250, 0x02B0, 0x0300, 0x0370, 0x0400, 0x0500, 0x0530, 0x0590, 0x0600, 0x0700, 0x0750, 0x0780, 0x07C0, 0x0800, 0x0840, 0x0860, 0x0870, 0x08A0, 0x0900, 0x0980, 0x0A00, 0x0A80, 0x0B00, 0x0B80, 0x0C00, 0x0C80, 0x0D00, 0x0D80, 0x0E00, 0x0E80, 0x0F00, 0x1000, 0x10A0, 0x1100, 0x1200, 0x1380, 0x13A0, 0x1400, 0x1680, 0x16A0, 0x1700, 0x1720, 0x1740, 0x1760, 0x1780, 0x1800, 0x18B0, 0x1900, 0x1950, 0x1980, 0x19E0, 0x1A00, 0x1A20, 0x1AB0, 0x1B00, 0x1B80, 0x1BC0, 0x1C00, 0x1C50, 0x1C80, 0x1C90, 0x1CC0, 0x1CD0, 0x1D00, 0x1D80, 0x1DC0, 0x1E00, 0x1F00, 0x2000, 0x2070, 0x20A0, 0x20D0, 0x2100, 0x2150, 0x2190, 0x2200, 0x2300, 0x2400, 0x2440, 0x2460, 0x2500, 0x2580, 0x25A0, 0x2600, 0x2700, 0x27C0, 0x27F0, 0x2800, 0x2900, 0x2980, 0x2A00, 0x2B00, 0x2C00, 0x2C60, 0x2C80, 0x2D00, 0x2D30, 0x2D80, 0x2DE0, 0x2E00, 0x2E80, 0x2F00, 0x2FF0, 0x3000, 0x3040, 0x30A0, 0x3100, 0x3130, 0x3190, 0x31A0, 0x31C0, 0x31F0, 0x3200, 0x3300, 0x3400, 0x4DC0, 0x4E00, 0xA000, 0xA490, 0xA4D0, 0xA500, 0xA640, 0xA6A0, 0xA700, 0xA720, 0xA800, 0xA830, 0xA840, 0xA880, 0xA8E0, 0xA900, 0xA930, 0xA960, 0xA980, 0xA9E0, 0xAA00, 0xAA60, 0xAA80, 0xAAE0, 0xAB00, 0xAB30, 0xAB70, 0xABC0, 0xAC00, 0xD7B0, 0xD800, 0xDB80, 0xDC00, 0xE000, 0xF900, 0xFB00, 0xFB50, 0xFE00, 0xFE10, 0xFE20, 0xFE30, 0xFE50, 0xFE70, 0xFF00, 0xFFF0, 0x10000, 0x10080, 0x10100, 0x10140, 0x10190, 0x101D0, 0x10280, 0x102A0, 0x102E0, 0x10300, 0x10330, 0x10350, 0x10380, 0x103A0, 0x10400, 0x10450, 0x10480, 0x104B0, 0x10500, 0x10530, 0x10570, 0x10600, 0x10780, 0x10800, 0x10840, 0x10860, 0x10880, 0x108E0, 0x10900, 0x10920, 0x10980, 0x109A0, 0x10A00, 0x10A60, 0x10A80, 0x10AC0, 0x10B00, 0x10B40, 0x10B60, 0x10B80, 0x10C00, 0x10C80, 0x10D00, 0x10E60, 0x10E80, 0x10EC0, 0x10F00, 0x10F30, 0x10F70, 0x10FB0, 0x10FE0, 0x11000, 0x11080, 0x110D0, 0x11100, 0x11150, 0x11180, 0x111E0, 0x11200, 0x11280, 0x112B0, 0x11300, 0x11400, 0x11480, 0x11580, 0x11600, 0x11660, 0x11680, 0x11700, 0x11800, 0x118A0, 0x11900, 0x119A0, 0x11A00, 0x11A50, 0x11AB0, 0x11AC0, 0x11B00, 0x11C00, 0x11C70, 0x11D00, 0x11D60, 0x11EE0, 0x11F00, 0x11FB0, 0x11FC0, 0x12000, 0x12400, 0x12480, 0x12F90, 0x13000, 0x13430, 0x14400, 0x16800, 0x16A40, 0x16A70, 0x16AD0, 0x16B00, 0x16E40, 0x16F00, 0x16FE0, 0x17000, 0x18800, 0x18B00, 0x18D00, 0x1AFF0, 0x1B000, 0x1B100, 0x1B130, 0x1B170, 0x1BC00, 0x1BCA0, 0x1CF00, 0x1D000, 0x1D100, 0x1D200, 0x1D2C0, 0x1D2E0, 0x1D300, 0x1D360, 0x1D400, 0x1D800, 0x1DF00, 0x1E000, 0x1E030, 0x1E100, 0x1E290, 0x1E2C0, 0x1E4D0, 0x1E7E0, 0x1E800, 0x1E900, 0x1EC70, 0x1ED00, 0x1EE00, 0x1F000, 0x1F030, 0x1F0A0, 0x1F100, 0x1F200, 0x1F300, 0x1F600, 0x1F650, 0x1F680, 0x1F700, 0x1F780, 0x1F800, 0x1F900, 0x1FA00, 0x1FA70, 0x1FB00, 0x20000, 0x2A700, 0x2B740, 0x2B820, 0x2CEB0, 0x2F800, 0x30000, 0x31350, 0xE0000, 0xE0100, 0xF0000, 0x100000]\n\n// Find block code belongs in.\nconst findBlock = (code: number): number => {\n\tlet s = 0\n\tlet e = scriptblocks.length\n\twhile (s < e-1) {\n\t\tlet i = Math.floor((s+e)/2)\n\t\tif (code < scriptblocks[i]) {\n\t\t\te = i\n\t\t} else {\n\t\t\ts = i\n\t\t}\n\t}\n\treturn s\n}\n\n// formatText adds s to element e, in a way that makes switching unicode scripts\n// clear, with alternating DOM TextNode and span elements with a \"switchscript\"\n// class. Useful for highlighting look alikes, e.g. a (ascii 0x61) and а (cyrillic\n// 0x430).\n//\n// This is only called one string at a time, so the UI can still display strings\n// without highlighting switching scripts, by calling formatText on the parts.\nconst formatText = (e: HTMLElement, s: string): void => {\n\t// Handle some common cases quickly.\n\tif (!s) {\n\t\treturn\n\t}\n\tlet ascii = true\n\tfor (const c of s) {\n\t\tconst cp = c.codePointAt(0) // For typescript, to check for undefined.\n\t\tif (cp !== undefined && cp >= 0x0080) {\n\t\t\tascii = false\n\t\t\tbreak\n\t\t}\n\t}\n\tif (ascii) {\n\t\te.appendChild(document.createTextNode(s))\n\t\treturn\n\t}\n\n\t// todo: handle grapheme clusters? wait for Intl.Segmenter?\n\n\tlet n = 0 // Number of text/span parts added.\n\tlet str = '' // Collected so far.\n\tlet block = -1 // Previous block/script.\n\tlet mod = 1\n\tconst put = (nextblock: number) => {\n\t\tif (n === 0 && nextblock === 0) {\n\t\t\t// Start was non-ascii, second block is ascii, we'll start marked as switched.\n\t\t\tmod = 0\n\t\t}\n\t\tif (n % 2 === mod) {\n\t\t\tconst x = document.createElement('span')\n\t\t\tx.classList.add('scriptswitch')\n\t\t\tx.appendChild(document.createTextNode(str))\n\t\t\te.appendChild(x)\n\t\t} else {\n\t\t\te.appendChild(document.createTextNode(str))\n\t\t}\n\t\tn++\n\t\tstr = ''\n\t}\n\tfor (const c of s) {\n\t\t// Basic whitespace does not switch blocks. Will probably need to extend with more\n\t\t// punctuation in the future. Possibly for digits too. But perhaps not in all\n\t\t// scripts.\n\t\tif (c === ' ' || c === '\\t' || c === '\\r' || c === '\\n') {\n\t\t\tstr += c\n\t\t\tcontinue\n\t\t}\n\t\tconst code: number = c.codePointAt(0) as number\n\t\tif (block < 0 || !(code >= scriptblocks[block] && (code < scriptblocks[block+1] || block === scriptblocks.length-1))) {\n\t\t\tconst nextblock = code < 0x0080 ? 0 : findBlock(code)\n\t\t\tif (block >= 0) {\n\t\t\t\tput(nextblock)\n\t\t\t}\n\t\t\tblock = nextblock\n\t\t}\n\t\tstr += c\n\t}\n\tput(-1)\n}\n\nconst _domKids = <T extends HTMLElement>(e: T, l: ElemArg[]): T => {\n\tl.forEach((c) => {\n\t\tconst xc = c as {[k: string]: any}\n\t\tif (typeof c === 'string') {\n\t\t\tformatText(e, c)\n\t\t} else if (c instanceof String) {\n\t\t\t// String is an escape-hatch for text that should not be formatted with\n\t\t\t// unicode-block-change-highlighting, e.g. for textarea values.\n\t\t\te.appendChild(document.createTextNode(''+c))\n\t\t} else if (c instanceof Element) {\n\t\t\te.appendChild(c)\n\t\t} else if (c instanceof Function) {\n\t\t\tif (!c.name) {\n\t\t\t\tthrow new Error('function without name')\n\t\t\t}\n\t\t\te.addEventListener(c.name as string, c as EventListener)\n\t\t} else if (Array.isArray(xc)) {\n\t\t\t_domKids(e, c as ElemArg[])\n\t\t} else if (xc._class) {\n\t\t\tfor (const s of xc._class) {\n\t\t\t\te.classList.toggle(s, true)\n\t\t\t}\n\t\t} else if (xc._attrs) {\n\t\t\tfor (const k in xc._attrs) {\n\t\t\t\te.setAttribute(k, xc._attrs[k])\n\t\t\t}\n\t\t} else if (xc._styles) {\n\t\t\tfor (const k in xc._styles) {\n\t\t\t\tconst estyle: {[k: string]: any} = e.style\n\t\t\t\testyle[k as string] = xc._styles[k]\n\t\t\t}\n\t\t} else if (xc._props) {\n\t\t\tfor (const k in xc._props) {\n\t\t\t\tconst eprops: {[k: string]: any} = e\n\t\t\t\teprops[k] = xc._props[k]\n\t\t\t}\n\t\t} else if (xc.root) {\n\t\t\te.appendChild(xc.root)\n\t\t} else {\n\t\t\tconsole.log('bad kid', c)\n\t\t\tthrow new Error('bad kid')\n\t\t}\n\t})\n\treturn e\n}\nconst dom = {\n\t_kids: function(e: HTMLElement, ...kl: ElemArg[]) {\n\t\twhile(e.firstChild) {\n\t\t\te.removeChild(e.firstChild)\n\t\t}\n\t\t_domKids(e, kl)\n\t},\n\t_attrs: (x: {[k: string]: string}) => { return {_attrs: x}},\n\t_class: (...x: string[]) => { return {_class: x}},\n\t// The createElement calls are spelled out so typescript can derive function\n\t// signatures with a specific HTML*Element return type.\n\tdiv: (...l: ElemArg[]) => _domKids(document.createElement('div'), l),\n\tspan: (...l: ElemArg[]) => _domKids(document.createElement('span'), l),\n\ta: (...l: ElemArg[]) => _domKids(document.createElement('a'), l),\n\tinput: (...l: ElemArg[]) => _domKids(document.createElement('input'), l),\n\ttextarea: (...l: ElemArg[]) => _domKids(document.createElement('textarea'), l),\n\tselect: (...l: ElemArg[]) => _domKids(document.createElement('select'), l),\n\toption: (...l: ElemArg[]) => _domKids(document.createElement('option'), l),\n\tclickbutton: (...l: ElemArg[]) => _domKids(document.createElement('button'), [attr.type('button'), ...l]),\n\tsubmitbutton: (...l: ElemArg[]) => _domKids(document.createElement('button'), [attr.type('submit'), ...l]),\n\tform: (...l: ElemArg[]) => _domKids(document.createElement('form'), l),\n\tfieldset: (...l: ElemArg[]) => _domKids(document.createElement('fieldset'), l),\n\ttable: (...l: ElemArg[]) => _domKids(document.createElement('table'), l),\n\tthead: (...l: ElemArg[]) => _domKids(document.createElement('thead'), l),\n\ttbody: (...l: ElemArg[]) => _domKids(document.createElement('tbody'), l),\n\ttfoot: (...l: ElemArg[]) => _domKids(document.createElement('tfoot'), l),\n\ttr: (...l: ElemArg[]) => _domKids(document.createElement('tr'), l),\n\ttd: (...l: ElemArg[]) => _domKids(document.createElement('td'), l),\n\tth: (...l: ElemArg[]) => _domKids(document.createElement('th'), l),\n\tdatalist: (...l: ElemArg[]) => _domKids(document.createElement('datalist'), l),\n\th1: (...l: ElemArg[]) => _domKids(document.createElement('h1'), l),\n\th2: (...l: ElemArg[]) => _domKids(document.createElement('h2'), l),\n\th3: (...l: ElemArg[]) => _domKids(document.createElement('h3'), l),\n\tbr: (...l: ElemArg[]) => _domKids(document.createElement('br'), l),\n\thr: (...l: ElemArg[]) => _domKids(document.createElement('hr'), l),\n\tpre: (...l: ElemArg[]) => _domKids(document.createElement('pre'), l),\n\tlabel: (...l: ElemArg[]) => _domKids(document.createElement('label'), l),\n\tul: (...l: ElemArg[]) => _domKids(document.createElement('ul'), l),\n\tli: (...l: ElemArg[]) => _domKids(document.createElement('li'), l),\n\tiframe: (...l: ElemArg[]) => _domKids(document.createElement('iframe'), l),\n\tb: (...l: ElemArg[]) => _domKids(document.createElement('b'), l),\n\timg: (...l: ElemArg[]) => _domKids(document.createElement('img'), l),\n\tstyle: (...l: ElemArg[]) => _domKids(document.createElement('style'), l),\n\tsearch: (...l: ElemArg[]) => _domKids(document.createElement('search'), l),\n\tp: (...l: ElemArg[]) => _domKids(document.createElement('p'), l),\n}\nconst _attr = (k: string, v: string) => { const o: {[key: string]: string} = {}; o[k] = v; return {_attrs: o} }\nconst attr = {\n\ttitle: (s: string) => _attr('title', s),\n\tvalue: (s: string) => _attr('value', s),\n\ttype: (s: string) => _attr('type', s),\n\ttabindex: (s: string) => _attr('tabindex', s),\n\tsrc: (s: string) => _attr('src', s),\n\tplaceholder: (s: string) => _attr('placeholder', s),\n\thref: (s: string) => _attr('href', s),\n\tchecked: (s: string) => _attr('checked', s),\n\tselected: (s: string) => _attr('selected', s),\n\tid: (s: string) => _attr('id', s),\n\tdatalist: (s: string) => _attr('datalist', s),\n\trows: (s: string) => _attr('rows', s),\n\ttarget: (s: string) => _attr('target', s),\n\trel: (s: string) => _attr('rel', s),\n\trequired: (s: string) => _attr('required', s),\n\tmultiple: (s: string) => _attr('multiple', s),\n\tdownload: (s: string) => _attr('download', s),\n\tdisabled: (s: string) => _attr('disabled', s),\n\tdraggable: (s: string) => _attr('draggable', s),\n\trowspan: (s: string) => _attr('rowspan', s),\n\tcolspan: (s: string) => _attr('colspan', s),\n\tfor: (s: string) => _attr('for', s),\n\trole: (s: string) => _attr('role', s),\n\tarialabel: (s: string) => _attr('aria-label', s),\n\tarialive: (s: string) => _attr('aria-live', s),\n\tname: (s: string) => _attr('name', s),\n\tmin: (s: string) => _attr('min', s),\n\tmax: (s: string) => _attr('max', s),\n\taction: (s: string) => _attr('action', s),\n\tmethod: (s: string) => _attr('method', s),\n\tautocomplete: (s: string) => _attr('autocomplete', s),\n\tlist: (s: string) => _attr('list', s),\n\tform: (s: string) => _attr('form', s),\n\tsize: (s: string) => _attr('size', s),\n}\nconst style = (x: {[k: string]: string | number}) => { return {_styles: x}}\nconst prop = (x: {[k: string]: any}) => { return {_props: x}}\nreturn [dom, style, attr, prop]\n})()\n"
        },
        {
          "name": "licenses.go",
          "type": "blob",
          "size": 0.396484375,
          "content": "package main\n\nimport (\n\t\"embed\"\n\t\"os\"\n\n\t\"github.com/mjl-/mox/mox-\"\n)\n\n//go:embed LICENSE.MIT LICENSE.MPLv2.0 licenses/*\nvar licensesFsys embed.FS\n\nfunc init() {\n\tmox.LicensesFsys = licensesFsys\n}\n\nfunc cmdLicenses(c *cmd) {\n\tc.help = `Print licenses of mox source code and dependencies.`\n\targs := c.Parse()\n\tif len(args) != 0 {\n\t\tc.Usage()\n\t}\n\n\terr := mox.LicensesWrite(os.Stdout)\n\txcheckf(err, \"write\")\n}\n"
        },
        {
          "name": "licenses",
          "type": "tree",
          "content": null
        },
        {
          "name": "localserve.go",
          "type": "blob",
          "size": 16.7724609375,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/ecdsa\"\n\t\"crypto/elliptic\"\n\tcryptorand \"crypto/rand\"\n\t\"crypto/x509\"\n\t\"crypto/x509/pkix\"\n\t\"encoding/pem\"\n\t\"fmt\"\n\tgolog \"log\"\n\t\"log/slog\"\n\t\"math/big\"\n\t\"net\"\n\t\"os\"\n\t\"os/signal\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"golang.org/x/crypto/bcrypt\"\n\n\t\"github.com/mjl-/sconf\"\n\n\t\"github.com/mjl-/mox/admin\"\n\t\"github.com/mjl-/mox/config\"\n\t\"github.com/mjl-/mox/dkim\"\n\t\"github.com/mjl-/mox/dns\"\n\t\"github.com/mjl-/mox/junk\"\n\t\"github.com/mjl-/mox/mlog\"\n\t\"github.com/mjl-/mox/mox-\"\n\t\"github.com/mjl-/mox/moxvar\"\n\t\"github.com/mjl-/mox/queue\"\n\t\"github.com/mjl-/mox/smtpserver\"\n\t\"github.com/mjl-/mox/store\"\n)\n\nfunc cmdLocalserve(c *cmd) {\n\tc.help = `Start a local SMTP/IMAP server that accepts all messages, useful when testing/developing software that sends email.\n\nLocalserve starts mox with a configuration suitable for local email-related\nsoftware development/testing. It listens for SMTP/Submission(s), IMAP(s) and\nHTTP(s), on the regular port numbers + 1000.\n\nData is stored in the system user's configuration directory under\n\"mox-localserve\", e.g. $HOME/.config/mox-localserve/ on linux, but can be\noverridden with the -dir flag. If the directory does not yet exist, it is\nautomatically initialized with configuration files, an account with email\naddress mox@localhost and password moxmoxmox, and a newly generated self-signed\nTLS certificate.\n\nIncoming messages are delivered as normal, falling back to accepting and\ndelivering to the mox account for unknown addresses.\nSubmitted messages are added to the queue, which delivers by ignoring the\ndestination servers, always connecting to itself instead.\n\nRecipient addresses with the following localpart suffixes are handled specially:\n\n- \"temperror\": fail with a temporary error code\n- \"permerror\": fail with a permanent error code\n- [45][0-9][0-9]: fail with the specific error code\n- \"timeout\": no response (for an hour)\n\nIf the localpart begins with \"mailfrom\" or \"rcptto\", the error is returned\nduring those commands instead of during \"data\".\n`\n\tgolog.SetFlags(0)\n\n\tuserConfDir, _ := os.UserConfigDir()\n\tif userConfDir == \"\" {\n\t\tuserConfDir = \".\"\n\t}\n\t// If we are being run to gather help output, show a placeholder directory\n\t// instead of evaluating to the actual userconfigdir on the host os.\n\tif c._gather {\n\t\tuserConfDir = \"$userconfigdir\"\n\t}\n\n\tvar dir, ip string\n\tvar initOnly bool\n\tc.flag.StringVar(&dir, \"dir\", filepath.Join(userConfDir, \"mox-localserve\"), \"configuration storage directory\")\n\tc.flag.StringVar(&ip, \"ip\", \"\", \"serve on this ip instead of default 127.0.0.1 and ::1. only used when writing configuration, at first launch.\")\n\tc.flag.BoolVar(&initOnly, \"initonly\", false, \"write configuration files and exit\")\n\targs := c.Parse()\n\tif len(args) != 0 {\n\t\tc.Usage()\n\t}\n\n\tlog := c.log\n\tmox.FilesImmediate = true\n\n\tif initOnly {\n\t\tif _, err := os.Stat(dir); err == nil {\n\t\t\tlog.Print(\"warning: directory for configuration files already exists, continuing\")\n\t\t}\n\t\tlog.Print(\"creating mox localserve config\", slog.String(\"dir\", dir))\n\t\terr := writeLocalConfig(log, dir, ip)\n\t\tif err != nil {\n\t\t\tlog.Fatalx(\"creating mox localserve config\", err, slog.String(\"dir\", dir))\n\t\t}\n\t\treturn\n\t}\n\n\t// Load config, creating a new one if needed.\n\tvar existingConfig bool\n\tif _, err := os.Stat(dir); err != nil && os.IsNotExist(err) {\n\t\terr := writeLocalConfig(log, dir, ip)\n\t\tif err != nil {\n\t\t\tlog.Fatalx(\"creating mox localserve config\", err, slog.String(\"dir\", dir))\n\t\t}\n\t} else if err != nil {\n\t\tlog.Fatalx(\"stat config dir\", err, slog.String(\"dir\", dir))\n\t} else if err := localLoadConfig(log, dir); err != nil {\n\t\tlog.Fatalx(\"loading mox localserve config (hint: when creating a new config with -dir, the directory must not yet exist)\", err, slog.String(\"dir\", dir))\n\t} else if ip != \"\" {\n\t\tlog.Fatal(\"can only use -ip when writing a new config file\")\n\t} else {\n\t\texistingConfig = true\n\t}\n\n\t// For new configs, we keep the \"info\" loglevel set by writeLocalConfig until after\n\t// initializing database files, to prevent lots of schema upgrade logging.\n\tfallbackLevel := mox.Conf.Static.LogLevel\n\tif fallbackLevel == \"\" {\n\t\tfallbackLevel = \"debug\"\n\t}\n\tif existingConfig {\n\t\tloadLoglevel(log, fallbackLevel)\n\t}\n\n\t// Initialize receivedid.\n\trecvidbuf, err := os.ReadFile(filepath.Join(dir, \"receivedid.key\"))\n\tif err == nil && len(recvidbuf) != 16+8 {\n\t\terr = fmt.Errorf(\"bad length %d, need 16+8\", len(recvidbuf))\n\t}\n\tif err != nil {\n\t\tlog.Errorx(\"reading receivedid.key\", err)\n\t\trecvidbuf = make([]byte, 16+8)\n\t\t_, err := cryptorand.Read(recvidbuf)\n\t\tif err != nil {\n\t\t\tlog.Fatalx(\"read random recvid key\", err)\n\t\t}\n\t}\n\tif err := mox.ReceivedIDInit(recvidbuf[:16], recvidbuf[16:]); err != nil {\n\t\tlog.Fatalx(\"init receivedid\", err)\n\t}\n\n\t// Make smtp server accept all email and deliver to account \"mox\".\n\tsmtpserver.Localserve = true\n\t// Tell queue it shouldn't be queuing/delivering.\n\tqueue.Localserve = true\n\t// Tell DKIM not to fail signatures for TLD localhost.\n\tdkim.Localserve = true\n\n\tconst mtastsdbRefresher = false\n\tconst sendDMARCReports = false\n\tconst sendTLSReports = false\n\tconst skipForkExec = true\n\tif err := start(mtastsdbRefresher, sendDMARCReports, sendTLSReports, skipForkExec); err != nil {\n\t\tlog.Fatalx(\"starting mox\", err)\n\t}\n\n\tloadLoglevel(log, fallbackLevel)\n\n\tgolog.Printf(\"mox, version %s %s/%s\", moxvar.Version, runtime.GOOS, runtime.GOARCH)\n\tgolog.Print(\"\")\n\tgolog.Printf(\"the default user is mox@localhost, with password moxmoxmox\")\n\tgolog.Printf(\"the default admin password is moxadmin\")\n\tgolog.Printf(\"port numbers are those common for the services + 1000\")\n\tgolog.Printf(\"tls uses generated self-signed certificate %s\", filepath.Join(dir, \"localhost.crt\"))\n\tgolog.Printf(\"all incoming email to any address is accepted (if checks pass), unless the recipient localpart ends with:\")\n\tgolog.Print(\"\")\n\tgolog.Printf(`- \"temperror\": fail with a temporary error code.`)\n\tgolog.Printf(`- \"permerror\": fail with a permanent error code.`)\n\tgolog.Printf(`- [45][0-9][0-9]: fail with the specific error code.`)\n\tgolog.Printf(`- \"timeout\": no response (for an hour).`)\n\tgolog.Print(\"\")\n\tgolog.Print(`if the localpart begins with \"mailfrom\" or \"rcptto\", the error is returned`)\n\tgolog.Print(`during those commands instead of during \"data\".  if the localpart begins with`)\n\tgolog.Print(`\"queue\", the submission is accepted but delivery from the queue will fail.`)\n\tgolog.Print(\"\")\n\tgolog.Print(\" smtp://localhost:1025                           - receive email\")\n\tgolog.Print(\"smtps://mox%40localhost:moxmoxmox@localhost:1465 - send email\")\n\tgolog.Print(\" smtp://mox%40localhost:moxmoxmox@localhost:1587 - send email (without tls)\")\n\tgolog.Print(\"imaps://mox%40localhost:moxmoxmox@localhost:1993 - read email\")\n\tgolog.Print(\" imap://mox%40localhost:moxmoxmox@localhost:1143 - read email (without tls)\")\n\tgolog.Print(\"https://localhost:1443/account/                  - account https (email mox@localhost, password moxmoxmox)\")\n\tgolog.Print(\" http://localhost:1080/account/                  - account http (without tls)\")\n\tgolog.Print(\"https://localhost:1443/webmail/                  - webmail https (email mox@localhost, password moxmoxmox)\")\n\tgolog.Print(\" http://localhost:1080/webmail/                  - webmail http (without tls)\")\n\tgolog.Print(\"https://localhost:1443/webapi/                   - webmail https (email mox@localhost, password moxmoxmox)\")\n\tgolog.Print(\" http://localhost:1080/webapi/                   - webmail http (without tls)\")\n\tgolog.Print(\"https://localhost:1443/admin/                    - admin https (password moxadmin)\")\n\tgolog.Print(\" http://localhost:1080/admin/                    - admin http (without tls)\")\n\tgolog.Print(\"\")\n\tif existingConfig {\n\t\tgolog.Printf(\"serving from existing config dir %s/\", dir)\n\t\tgolog.Printf(\"if urls above don't work, consider resetting by removing config dir\")\n\t} else {\n\t\tgolog.Printf(\"serving from newly created config dir %s/\", dir)\n\t}\n\n\tctlpath := mox.DataDirPath(\"ctl\")\n\t_ = os.Remove(ctlpath)\n\tctl, err := net.Listen(\"unix\", ctlpath)\n\tif err != nil {\n\t\tlog.Fatalx(\"listen on ctl unix domain socket\", err)\n\t}\n\tgo func() {\n\t\tfor {\n\t\t\tconn, err := ctl.Accept()\n\t\t\tif err != nil {\n\t\t\t\tlog.Printx(\"accept for ctl\", err)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tcid := mox.Cid()\n\t\t\tctx := context.WithValue(mox.Context, mlog.CidKey, cid)\n\t\t\tgo servectl(ctx, log.WithCid(cid), conn, func() { shutdown(log) })\n\t\t}\n\t}()\n\n\t// Graceful shutdown.\n\tsigc := make(chan os.Signal, 1)\n\tsignal.Notify(sigc, os.Interrupt, syscall.SIGTERM)\n\tsig := <-sigc\n\tlog.Print(\"shutting down, waiting max 3s for existing connections\", slog.Any(\"signal\", sig))\n\tshutdown(log)\n\tif num, ok := sig.(syscall.Signal); ok {\n\t\tos.Exit(int(num))\n\t} else {\n\t\tos.Exit(1)\n\t}\n}\n\nfunc writeLocalConfig(log mlog.Log, dir, ip string) (rerr error) {\n\tdefer func() {\n\t\tx := recover()\n\t\tif x != nil {\n\t\t\tif err, ok := x.(error); ok {\n\t\t\t\trerr = err\n\t\t\t}\n\t\t}\n\t\tif rerr != nil {\n\t\t\terr := os.RemoveAll(dir)\n\t\t\tlog.Check(err, \"removing config directory\", slog.String(\"dir\", dir))\n\t\t}\n\t}()\n\n\txcheck := func(err error, msg string) {\n\t\tif err != nil {\n\t\t\tpanic(fmt.Errorf(\"%s: %s\", msg, err))\n\t\t}\n\t}\n\n\tos.MkdirAll(dir, 0770)\n\n\t// Generate key and self-signed certificate for use with TLS.\n\tprivKey, err := ecdsa.GenerateKey(elliptic.P256(), cryptorand.Reader)\n\txcheck(err, \"generating ecdsa key for self-signed certificate\")\n\tprivKeyDER, err := x509.MarshalPKCS8PrivateKey(privKey)\n\txcheck(err, \"marshal private key to pkcs8\")\n\tprivBlock := &pem.Block{\n\t\tType: \"PRIVATE KEY\",\n\t\tHeaders: map[string]string{\n\t\t\t\"Note\": \"ECDSA key generated by mox localserve for self-signed certificate.\",\n\t\t},\n\t\tBytes: privKeyDER,\n\t}\n\tvar privPEM bytes.Buffer\n\terr = pem.Encode(&privPEM, privBlock)\n\txcheck(err, \"pem-encoding private key\")\n\terr = os.WriteFile(filepath.Join(dir, \"localhost.key\"), privPEM.Bytes(), 0660)\n\txcheck(err, \"writing private key for self-signed certificate\")\n\n\t// Now the certificate.\n\ttemplate := &x509.Certificate{\n\t\tSerialNumber: big.NewInt(time.Now().Unix()), // Required field.\n\t\tDNSNames:     []string{\"localhost\"},\n\t\tNotBefore:    time.Now().Add(-time.Hour),\n\t\tNotAfter:     time.Now().Add(4 * 365 * 24 * time.Hour),\n\t\tIssuer: pkix.Name{\n\t\t\tOrganization: []string{\"mox localserve\"},\n\t\t},\n\t\tSubject: pkix.Name{\n\t\t\tOrganization: []string{\"mox localserve\"},\n\t\t\tCommonName:   \"localhost\",\n\t\t},\n\t}\n\tcertDER, err := x509.CreateCertificate(cryptorand.Reader, template, template, privKey.Public(), privKey)\n\txcheck(err, \"making self-signed certificate\")\n\n\tpubBlock := &pem.Block{\n\t\tType: \"CERTIFICATE\",\n\t\t// Comments (header) would cause failure to parse the certificate when we load the config.\n\t\tBytes: certDER,\n\t}\n\tvar crtPEM bytes.Buffer\n\terr = pem.Encode(&crtPEM, pubBlock)\n\txcheck(err, \"pem-encoding self-signed certificate\")\n\terr = os.WriteFile(filepath.Join(dir, \"localhost.crt\"), crtPEM.Bytes(), 0660)\n\txcheck(err, \"writing self-signed certificate\")\n\n\t// Write adminpasswd.\n\tadminpw := \"moxadmin\"\n\tadminpwhash, err := bcrypt.GenerateFromPassword([]byte(adminpw), bcrypt.DefaultCost)\n\txcheck(err, \"generating hash for admin password\")\n\terr = os.WriteFile(filepath.Join(dir, \"adminpasswd\"), adminpwhash, 0660)\n\txcheck(err, \"writing adminpasswd file\")\n\n\t// Write mox.conf.\n\tips := []string{\"127.0.0.1\", \"::1\"}\n\tif ip != \"\" {\n\t\tips = []string{ip}\n\t}\n\n\tlocal := config.Listener{\n\t\tIPs: ips,\n\t\tTLS: &config.TLS{\n\t\t\tKeyCerts: []config.KeyCert{\n\t\t\t\t{\n\t\t\t\t\tCertFile: \"localhost.crt\",\n\t\t\t\t\tKeyFile:  \"localhost.key\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\tlocal.SMTP.Enabled = true\n\tlocal.SMTP.Port = 1025\n\tlocal.Submission.Enabled = true\n\tlocal.Submission.Port = 1587\n\tlocal.Submission.NoRequireSTARTTLS = true\n\tlocal.Submissions.Enabled = true\n\tlocal.Submissions.Port = 1465\n\tlocal.IMAP.Enabled = true\n\tlocal.IMAP.Port = 1143\n\tlocal.IMAP.NoRequireSTARTTLS = true\n\tlocal.IMAPS.Enabled = true\n\tlocal.IMAPS.Port = 1993\n\tlocal.AccountHTTP.Enabled = true\n\tlocal.AccountHTTP.Port = 1080\n\tlocal.AccountHTTP.Path = \"/account/\"\n\tlocal.AccountHTTPS.Enabled = true\n\tlocal.AccountHTTPS.Port = 1443\n\tlocal.AccountHTTPS.Path = \"/account/\"\n\tlocal.WebmailHTTP.Enabled = true\n\tlocal.WebmailHTTP.Port = 1080\n\tlocal.WebmailHTTP.Path = \"/webmail/\"\n\tlocal.WebmailHTTPS.Enabled = true\n\tlocal.WebmailHTTPS.Port = 1443\n\tlocal.WebmailHTTPS.Path = \"/webmail/\"\n\tlocal.WebAPIHTTP.Enabled = true\n\tlocal.WebAPIHTTP.Port = 1080\n\tlocal.WebAPIHTTP.Path = \"/webapi/\"\n\tlocal.WebAPIHTTPS.Enabled = true\n\tlocal.WebAPIHTTPS.Port = 1443\n\tlocal.WebAPIHTTPS.Path = \"/webapi/\"\n\tlocal.AdminHTTP.Enabled = true\n\tlocal.AdminHTTP.Port = 1080\n\tlocal.AdminHTTPS.Enabled = true\n\tlocal.AdminHTTPS.Port = 1443\n\tlocal.MetricsHTTP.Enabled = true\n\tlocal.MetricsHTTP.Port = 1081\n\tlocal.WebserverHTTP.Enabled = true\n\tlocal.WebserverHTTP.Port = 1080\n\tlocal.WebserverHTTPS.Enabled = true\n\tlocal.WebserverHTTPS.Port = 1443\n\n\tuid := os.Getuid()\n\tif uid < 0 {\n\t\tuid = 1 // For windows.\n\t}\n\tstatic := config.Static{\n\t\tDataDir:           \".\",\n\t\tLogLevel:          \"traceauth\",\n\t\tHostname:          \"localhost\",\n\t\tUser:              fmt.Sprintf(\"%d\", uid),\n\t\tAdminPasswordFile: \"adminpasswd\",\n\t\tPedantic:          true,\n\t\tListeners: map[string]config.Listener{\n\t\t\t\"local\": local,\n\t\t},\n\t}\n\ttlsca := struct {\n\t\tAdditionalToSystem bool     `sconf:\"optional\"`\n\t\tCertFiles          []string `sconf:\"optional\"`\n\t}{true, []string{\"localhost.crt\"}}\n\tstatic.TLS.CA = &tlsca\n\tstatic.Postmaster.Account = \"mox\"\n\tstatic.Postmaster.Mailbox = \"Inbox\"\n\n\tvar moxconfBuf bytes.Buffer\n\terr = sconf.WriteDocs(&moxconfBuf, static)\n\txcheck(err, \"making mox.conf\")\n\n\terr = os.WriteFile(filepath.Join(dir, \"mox.conf\"), moxconfBuf.Bytes(), 0660)\n\txcheck(err, \"writing mox.conf\")\n\n\t// Write domains.conf.\n\tacc := config.Account{\n\t\tKeepRetiredMessagePeriod: 72 * time.Hour,\n\t\tKeepRetiredWebhookPeriod: 72 * time.Hour,\n\t\tRejectsMailbox:           \"Rejects\",\n\t\tDestinations: map[string]config.Destination{\n\t\t\t\"mox@localhost\": {},\n\t\t},\n\t\tNoFirstTimeSenderDelay: true,\n\t}\n\tacc.AutomaticJunkFlags.Enabled = true\n\tacc.AutomaticJunkFlags.JunkMailboxRegexp = \"^(junk|spam)\"\n\tacc.AutomaticJunkFlags.NeutralMailboxRegexp = \"^(inbox|neutral|postmaster|dmarc|tlsrpt|rejects)\"\n\tacc.JunkFilter = &config.JunkFilter{\n\t\tThreshold: 0.95,\n\t\tParams: junk.Params{\n\t\t\tOnegrams:    true,\n\t\t\tMaxPower:    .01,\n\t\t\tTopWords:    10,\n\t\t\tIgnoreWords: .1,\n\t\t\tRareWords:   2,\n\t\t},\n\t}\n\n\tdkimKeyBuf, err := admin.MakeDKIMEd25519Key(dns.Domain{ASCII: \"localserve\"}, dns.Domain{ASCII: \"localhost\"})\n\txcheck(err, \"making dkim key\")\n\tdkimKeyPath := \"dkim.localserve.privatekey.pkcs8.pem\"\n\terr = os.WriteFile(filepath.Join(dir, dkimKeyPath), dkimKeyBuf, 0660)\n\txcheck(err, \"writing dkim key file\")\n\n\tdynamic := config.Dynamic{\n\t\tDomains: map[string]config.Domain{\n\t\t\t\"localhost\": {\n\t\t\t\tLocalpartCatchallSeparator: \"+\",\n\t\t\t\tDKIM: config.DKIM{\n\t\t\t\t\tSign: []string{\"localserve\"},\n\t\t\t\t\tSelectors: map[string]config.Selector{\n\t\t\t\t\t\t\"localserve\": {\n\t\t\t\t\t\t\tExpiration:     \"72h\",\n\t\t\t\t\t\t\tPrivateKeyFile: dkimKeyPath,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tAccounts: map[string]config.Account{\n\t\t\t\"mox\": acc,\n\t\t},\n\t\tWebHandlers: []config.WebHandler{\n\t\t\t{\n\t\t\t\tLogName:               \"workdir\",\n\t\t\t\tDomain:                \"localhost\",\n\t\t\t\tPathRegexp:            \"^/workdir/\",\n\t\t\t\tDontRedirectPlainHTTP: true,\n\t\t\t\tWebStatic: &config.WebStatic{\n\t\t\t\t\tStripPrefix: \"/workdir/\",\n\t\t\t\t\tRoot:        \".\",\n\t\t\t\t\tListFiles:   true,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\tvar domainsconfBuf bytes.Buffer\n\terr = sconf.WriteDocs(&domainsconfBuf, dynamic)\n\txcheck(err, \"making domains.conf\")\n\n\terr = os.WriteFile(filepath.Join(dir, \"domains.conf\"), domainsconfBuf.Bytes(), 0660)\n\txcheck(err, \"writing domains.conf\")\n\n\t// Write receivedid.key.\n\trecvidbuf := make([]byte, 16+8)\n\t_, err = cryptorand.Read(recvidbuf)\n\txcheck(err, \"reading random recvid data\")\n\terr = os.WriteFile(filepath.Join(dir, \"receivedid.key\"), recvidbuf, 0660)\n\txcheck(err, \"writing receivedid.key\")\n\n\t// Load config, so we can access the account.\n\terr = localLoadConfig(log, dir)\n\txcheck(err, \"loading config\")\n\n\t// Info so we don't log lots about initializing database.\n\tloadLoglevel(log, \"info\")\n\n\t// Set password on account.\n\ta, _, err := store.OpenEmail(log, \"mox@localhost\")\n\txcheck(err, \"opening account to set password\")\n\tpassword := \"moxmoxmox\"\n\terr = a.SetPassword(log, password)\n\txcheck(err, \"setting password\")\n\terr = a.Close()\n\txcheck(err, \"closing account\")\n\n\tgolog.Printf(\"config created in %s\", dir)\n\treturn nil\n}\n\nfunc loadLoglevel(log mlog.Log, fallback string) {\n\tll := loglevel\n\tif ll == \"\" {\n\t\tll = fallback\n\t}\n\tif level, ok := mlog.Levels[ll]; ok {\n\t\tmox.Conf.Log[\"\"] = level\n\t\tmlog.SetConfig(mox.Conf.Log)\n\t} else {\n\t\tlog.Fatal(\"unknown loglevel\", slog.String(\"loglevel\", loglevel))\n\t}\n}\n\nfunc localLoadConfig(log mlog.Log, dir string) error {\n\tmox.ConfigStaticPath = filepath.Join(dir, \"mox.conf\")\n\tmox.ConfigDynamicPath = filepath.Join(dir, \"domains.conf\")\n\terrs := mox.LoadConfig(context.Background(), log, true, false)\n\tif len(errs) > 1 {\n\t\tlog.Error(\"loading config generated config file: multiple errors\")\n\t\tfor _, err := range errs {\n\t\t\tlog.Errorx(\"config error\", err)\n\t\t}\n\t\treturn fmt.Errorf(\"stopping after multiple config errors\")\n\t} else if len(errs) == 1 {\n\t\treturn fmt.Errorf(\"loading config file: %v\", errs[0])\n\t}\n\treturn nil\n}\n"
        },
        {
          "name": "main.go",
          "type": "blob",
          "size": 112.681640625,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto\"\n\t\"crypto/ecdsa\"\n\t\"crypto/ed25519\"\n\t\"crypto/elliptic\"\n\tcryptorand \"crypto/rand\"\n\t\"crypto/rsa\"\n\t\"crypto/sha256\"\n\t\"crypto/sha512\"\n\t\"crypto/x509\"\n\t\"encoding/base64\"\n\t\"encoding/json\"\n\t\"encoding/pem\"\n\t\"errors\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/fs\"\n\t\"log\"\n\t\"log/slog\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"reflect\"\n\t\"runtime\"\n\t\"slices\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"golang.org/x/crypto/bcrypt\"\n\t\"golang.org/x/text/secure/precis\"\n\n\t\"github.com/mjl-/adns\"\n\n\t\"github.com/mjl-/autocert\"\n\t\"github.com/mjl-/bstore\"\n\t\"github.com/mjl-/sconf\"\n\t\"github.com/mjl-/sherpa\"\n\n\t\"github.com/mjl-/mox/admin\"\n\t\"github.com/mjl-/mox/config\"\n\t\"github.com/mjl-/mox/dane\"\n\t\"github.com/mjl-/mox/dkim\"\n\t\"github.com/mjl-/mox/dmarc\"\n\t\"github.com/mjl-/mox/dmarcdb\"\n\t\"github.com/mjl-/mox/dmarcrpt\"\n\t\"github.com/mjl-/mox/dns\"\n\t\"github.com/mjl-/mox/dnsbl\"\n\t\"github.com/mjl-/mox/message\"\n\t\"github.com/mjl-/mox/mlog\"\n\t\"github.com/mjl-/mox/mox-\"\n\t\"github.com/mjl-/mox/moxio\"\n\t\"github.com/mjl-/mox/moxvar\"\n\t\"github.com/mjl-/mox/mtasts\"\n\t\"github.com/mjl-/mox/publicsuffix\"\n\t\"github.com/mjl-/mox/queue\"\n\t\"github.com/mjl-/mox/smtp\"\n\t\"github.com/mjl-/mox/smtpclient\"\n\t\"github.com/mjl-/mox/spf\"\n\t\"github.com/mjl-/mox/store\"\n\t\"github.com/mjl-/mox/tlsrpt\"\n\t\"github.com/mjl-/mox/tlsrptdb\"\n\t\"github.com/mjl-/mox/updates\"\n\t\"github.com/mjl-/mox/webadmin\"\n\t\"github.com/mjl-/mox/webapi\"\n)\n\nvar (\n\tchangelogDomain = \"xmox.nl\"\n\tchangelogURL    = \"https://updates.xmox.nl/changelog\"\n\tchangelogPubKey = base64Decode(\"sPNiTDQzvb4FrytNEiebJhgyQzn57RwEjNbGWMM/bDY=\")\n)\n\nfunc base64Decode(s string) []byte {\n\tbuf, err := base64.StdEncoding.DecodeString(s)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn buf\n}\n\nfunc envString(k, def string) string {\n\ts := os.Getenv(k)\n\tif s == \"\" {\n\t\treturn def\n\t}\n\treturn s\n}\n\nvar commands = []struct {\n\tcmd string\n\tfn  func(c *cmd)\n}{\n\t{\"serve\", cmdServe},\n\t{\"quickstart\", cmdQuickstart},\n\t{\"stop\", cmdStop},\n\t{\"setaccountpassword\", cmdSetaccountpassword},\n\t{\"setadminpassword\", cmdSetadminpassword},\n\t{\"loglevels\", cmdLoglevels},\n\t{\"queue holdrules list\", cmdQueueHoldrulesList},\n\t{\"queue holdrules add\", cmdQueueHoldrulesAdd},\n\t{\"queue holdrules remove\", cmdQueueHoldrulesRemove},\n\t{\"queue list\", cmdQueueList},\n\t{\"queue hold\", cmdQueueHold},\n\t{\"queue unhold\", cmdQueueUnhold},\n\t{\"queue schedule\", cmdQueueSchedule},\n\t{\"queue transport\", cmdQueueTransport},\n\t{\"queue requiretls\", cmdQueueRequireTLS},\n\t{\"queue fail\", cmdQueueFail},\n\t{\"queue drop\", cmdQueueDrop},\n\t{\"queue dump\", cmdQueueDump},\n\t{\"queue retired list\", cmdQueueRetiredList},\n\t{\"queue retired print\", cmdQueueRetiredPrint},\n\t{\"queue suppress list\", cmdQueueSuppressList},\n\t{\"queue suppress add\", cmdQueueSuppressAdd},\n\t{\"queue suppress remove\", cmdQueueSuppressRemove},\n\t{\"queue suppress lookup\", cmdQueueSuppressLookup},\n\t{\"queue webhook list\", cmdQueueHookList},\n\t{\"queue webhook schedule\", cmdQueueHookSchedule},\n\t{\"queue webhook cancel\", cmdQueueHookCancel},\n\t{\"queue webhook print\", cmdQueueHookPrint},\n\t{\"queue webhook retired list\", cmdQueueHookRetiredList},\n\t{\"queue webhook retired print\", cmdQueueHookRetiredPrint},\n\t{\"import maildir\", cmdImportMaildir},\n\t{\"import mbox\", cmdImportMbox},\n\t{\"export maildir\", cmdExportMaildir},\n\t{\"export mbox\", cmdExportMbox},\n\t{\"localserve\", cmdLocalserve},\n\t{\"help\", cmdHelp},\n\t{\"backup\", cmdBackup},\n\t{\"verifydata\", cmdVerifydata},\n\t{\"licenses\", cmdLicenses},\n\n\t{\"config test\", cmdConfigTest},\n\t{\"config dnscheck\", cmdConfigDNSCheck},\n\t{\"config dnsrecords\", cmdConfigDNSRecords},\n\t{\"config describe-domains\", cmdConfigDescribeDomains},\n\t{\"config describe-static\", cmdConfigDescribeStatic},\n\t{\"config account add\", cmdConfigAccountAdd},\n\t{\"config account rm\", cmdConfigAccountRemove},\n\t{\"config address add\", cmdConfigAddressAdd},\n\t{\"config address rm\", cmdConfigAddressRemove},\n\t{\"config domain add\", cmdConfigDomainAdd},\n\t{\"config domain rm\", cmdConfigDomainRemove},\n\t{\"config tlspubkey list\", cmdConfigTlspubkeyList},\n\t{\"config tlspubkey get\", cmdConfigTlspubkeyGet},\n\t{\"config tlspubkey add\", cmdConfigTlspubkeyAdd},\n\t{\"config tlspubkey rm\", cmdConfigTlspubkeyRemove},\n\t{\"config tlspubkey gen\", cmdConfigTlspubkeyGen},\n\t{\"config alias list\", cmdConfigAliasList},\n\t{\"config alias print\", cmdConfigAliasPrint},\n\t{\"config alias add\", cmdConfigAliasAdd},\n\t{\"config alias update\", cmdConfigAliasUpdate},\n\t{\"config alias rm\", cmdConfigAliasRemove},\n\t{\"config alias addaddr\", cmdConfigAliasAddaddr},\n\t{\"config alias rmaddr\", cmdConfigAliasRemoveaddr},\n\n\t{\"config describe-sendmail\", cmdConfigDescribeSendmail},\n\t{\"config printservice\", cmdConfigPrintservice},\n\t{\"config ensureacmehostprivatekeys\", cmdConfigEnsureACMEHostprivatekeys},\n\t{\"config example\", cmdConfigExample},\n\n\t{\"checkupdate\", cmdCheckupdate},\n\t{\"cid\", cmdCid},\n\t{\"clientconfig\", cmdClientConfig},\n\t{\"deliver\", cmdDeliver},\n\t// todo: turn cmdDANEDialmx into a regular \"dialmx\" command that follows mta-sts policy, with options to require dane, mta-sts or requiretls. the code will be similar to queue/direct.go\n\t{\"dane dial\", cmdDANEDial},\n\t{\"dane dialmx\", cmdDANEDialmx},\n\t{\"dane makerecord\", cmdDANEMakeRecord},\n\t{\"dns lookup\", cmdDNSLookup},\n\t{\"dkim gened25519\", cmdDKIMGened25519},\n\t{\"dkim genrsa\", cmdDKIMGenrsa},\n\t{\"dkim lookup\", cmdDKIMLookup},\n\t{\"dkim txt\", cmdDKIMTXT},\n\t{\"dkim verify\", cmdDKIMVerify},\n\t{\"dkim sign\", cmdDKIMSign},\n\t{\"dmarc lookup\", cmdDMARCLookup},\n\t{\"dmarc parsereportmsg\", cmdDMARCParsereportmsg},\n\t{\"dmarc verify\", cmdDMARCVerify},\n\t{\"dmarc checkreportaddrs\", cmdDMARCCheckreportaddrs},\n\t{\"dnsbl check\", cmdDNSBLCheck},\n\t{\"dnsbl checkhealth\", cmdDNSBLCheckhealth},\n\t{\"mtasts lookup\", cmdMTASTSLookup},\n\t{\"retrain\", cmdRetrain},\n\t{\"sendmail\", cmdSendmail},\n\t{\"spf check\", cmdSPFCheck},\n\t{\"spf lookup\", cmdSPFLookup},\n\t{\"spf parse\", cmdSPFParse},\n\t{\"tlsrpt lookup\", cmdTLSRPTLookup},\n\t{\"tlsrpt parsereportmsg\", cmdTLSRPTParsereportmsg},\n\t{\"version\", cmdVersion},\n\t{\"webapi\", cmdWebapi},\n\n\t{\"example\", cmdExample},\n\t{\"bumpuidvalidity\", cmdBumpUIDValidity},\n\t{\"reassignuids\", cmdReassignUIDs},\n\t{\"fixuidmeta\", cmdFixUIDMeta},\n\t{\"fixmsgsize\", cmdFixmsgsize},\n\t{\"reparse\", cmdReparse},\n\t{\"ensureparsed\", cmdEnsureParsed},\n\t{\"recalculatemailboxcounts\", cmdRecalculateMailboxCounts},\n\t{\"message parse\", cmdMessageParse},\n\t{\"reassignthreads\", cmdReassignthreads},\n\n\t// Not listed.\n\t{\"helpall\", cmdHelpall},\n\t{\"junk analyze\", cmdJunkAnalyze},\n\t{\"junk check\", cmdJunkCheck},\n\t{\"junk play\", cmdJunkPlay},\n\t{\"junk test\", cmdJunkTest},\n\t{\"junk train\", cmdJunkTrain},\n\t{\"dmarcdb addreport\", cmdDMARCDBAddReport},\n\t{\"tlsrptdb addreport\", cmdTLSRPTDBAddReport},\n\t{\"updates addsigned\", cmdUpdatesAddSigned},\n\t{\"updates genkey\", cmdUpdatesGenkey},\n\t{\"updates pubkey\", cmdUpdatesPubkey},\n\t{\"updates serve\", cmdUpdatesServe},\n\t{\"updates verify\", cmdUpdatesVerify},\n\t{\"gentestdata\", cmdGentestdata},\n\t{\"ximport maildir\", cmdXImportMaildir},\n\t{\"ximport mbox\", cmdXImportMbox},\n\t{\"openaccounts\", cmdOpenaccounts},\n\t{\"readmessages\", cmdReadmessages},\n\t{\"queuefillretired\", cmdQueueFillRetired},\n}\n\nvar cmds []cmd\n\nfunc init() {\n\tfor _, xc := range commands {\n\t\tc := cmd{words: strings.Split(xc.cmd, \" \"), fn: xc.fn}\n\t\tcmds = append(cmds, c)\n\t}\n}\n\ntype cmd struct {\n\twords []string\n\tfn    func(c *cmd)\n\n\t// Set before calling command.\n\tflag     *flag.FlagSet\n\tflagArgs []string\n\t_gather  bool // Set when using Parse to gather usage for a command.\n\n\t// Set by invoked command or Parse.\n\tunlisted bool   // If set, command is not listed until at least some words are matched from command.\n\tparams   string // Arguments to command. Multiple lines possible.\n\thelp     string // Additional explanation. First line is synopsis, the rest is only printed for an explicit help/usage for that command.\n\targs     []string\n\n\tlog mlog.Log\n}\n\nfunc (c *cmd) Parse() []string {\n\t// To gather params and usage information, we just run the command but cause this\n\t// panic after the command has registered its flags and set its params and help\n\t// information. This is then caught and that info printed.\n\tif c._gather {\n\t\tpanic(\"gather\")\n\t}\n\n\tc.flag.Usage = c.Usage\n\tc.flag.Parse(c.flagArgs)\n\tc.args = c.flag.Args()\n\treturn c.args\n}\n\nfunc (c *cmd) gather() {\n\tc.flag = flag.NewFlagSet(\"mox \"+strings.Join(c.words, \" \"), flag.ExitOnError)\n\tc._gather = true\n\tdefer func() {\n\t\tx := recover()\n\t\t// panic generated by Parse.\n\t\tif x != \"gather\" {\n\t\t\tpanic(x)\n\t\t}\n\t}()\n\tc.fn(c)\n}\n\nfunc (c *cmd) makeUsage() string {\n\tvar r strings.Builder\n\tcs := \"mox \" + strings.Join(c.words, \" \")\n\tfor i, line := range strings.Split(strings.TrimSpace(c.params), \"\\n\") {\n\t\ts := \"\"\n\t\tif i == 0 {\n\t\t\ts = \"usage:\"\n\t\t}\n\t\tif line != \"\" {\n\t\t\tline = \" \" + line\n\t\t}\n\t\tfmt.Fprintf(&r, \"%6s %s%s\\n\", s, cs, line)\n\t}\n\tc.flag.SetOutput(&r)\n\tc.flag.PrintDefaults()\n\treturn r.String()\n}\n\nfunc (c *cmd) printUsage() {\n\tfmt.Fprint(os.Stderr, c.makeUsage())\n\tif c.help != \"\" {\n\t\tfmt.Fprint(os.Stderr, \"\\n\"+c.help+\"\\n\")\n\t}\n}\n\nfunc (c *cmd) Usage() {\n\tc.printUsage()\n\tos.Exit(2)\n}\n\nfunc cmdHelp(c *cmd) {\n\tc.params = \"[command ...]\"\n\tc.help = `Prints help about matching commands.\n\nIf multiple commands match, they are listed along with the first line of their help text.\nIf a single command matches, its usage and full help text is printed.\n`\n\targs := c.Parse()\n\tif len(args) == 0 {\n\t\tc.Usage()\n\t}\n\n\tprefix := func(l, pre []string) bool {\n\t\tif len(pre) > len(l) {\n\t\t\treturn false\n\t\t}\n\t\treturn slices.Equal(pre, l[:len(pre)])\n\t}\n\n\tvar partial []cmd\n\tfor _, c := range cmds {\n\t\tif slices.Equal(c.words, args) {\n\t\t\tc.gather()\n\t\t\tfmt.Print(c.makeUsage())\n\t\t\tif c.help != \"\" {\n\t\t\t\tfmt.Print(\"\\n\" + c.help + \"\\n\")\n\t\t\t}\n\t\t\treturn\n\t\t} else if prefix(c.words, args) {\n\t\t\tpartial = append(partial, c)\n\t\t}\n\t}\n\tif len(partial) == 0 {\n\t\tfmt.Fprintf(os.Stderr, \"%s: unknown command\\n\", strings.Join(args, \" \"))\n\t\tos.Exit(2)\n\t}\n\tfor _, c := range partial {\n\t\tc.gather()\n\t\tline := \"mox \" + strings.Join(c.words, \" \")\n\t\tfmt.Printf(\"%s\\n\", line)\n\t\tif c.help != \"\" {\n\t\t\tfmt.Printf(\"\\t%s\\n\", strings.Split(c.help, \"\\n\")[0])\n\t\t}\n\t}\n}\n\nfunc cmdHelpall(c *cmd) {\n\tc.unlisted = true\n\tc.help = `Print all detailed usage and help information for all listed commands.\n\nUsed to generate documentation.\n`\n\targs := c.Parse()\n\tif len(args) != 0 {\n\t\tc.Usage()\n\t}\n\n\tn := 0\n\tfor _, c := range cmds {\n\t\tc.gather()\n\t\tif c.unlisted {\n\t\t\tcontinue\n\t\t}\n\t\tif n > 0 {\n\t\t\tfmt.Fprintf(os.Stderr, \"\\n\")\n\t\t}\n\t\tn++\n\n\t\tfmt.Fprintf(os.Stderr, \"# mox %s\\n\\n\", strings.Join(c.words, \" \"))\n\t\tif c.help != \"\" {\n\t\t\tfmt.Fprintln(os.Stderr, c.help+\"\\n\")\n\t\t}\n\t\ts := c.makeUsage()\n\t\ts = \"\\t\" + strings.ReplaceAll(s, \"\\n\", \"\\n\\t\")\n\t\tfmt.Fprintln(os.Stderr, s)\n\t}\n}\n\nfunc usage(l []cmd, unlisted bool) {\n\tvar lines []string\n\tif !unlisted {\n\t\tlines = append(lines, \"mox [-config config/mox.conf] [-pedantic] ...\")\n\t}\n\tfor _, c := range l {\n\t\tc.gather()\n\t\tif c.unlisted && !unlisted {\n\t\t\tcontinue\n\t\t}\n\t\tfor _, line := range strings.Split(c.params, \"\\n\") {\n\t\t\tx := append([]string{\"mox\"}, c.words...)\n\t\t\tif line != \"\" {\n\t\t\t\tx = append(x, line)\n\t\t\t}\n\t\t\tlines = append(lines, strings.Join(x, \" \"))\n\t\t}\n\t}\n\tfor i, line := range lines {\n\t\tpre := \"       \"\n\t\tif i == 0 {\n\t\t\tpre = \"usage: \"\n\t\t}\n\t\tfmt.Fprintln(os.Stderr, pre+line)\n\t}\n\tos.Exit(2)\n}\n\nvar loglevel string // Empty will be interpreted as info, except by localserve.\nvar pedantic bool\n\n// subcommands that are not \"serve\" should use this function to load the config, it\n// restores any loglevel specified on the command-line, instead of using the\n// loglevels from the config file and it does not load files like TLS keys/certs.\nfunc mustLoadConfig() {\n\tmox.MustLoadConfig(false, false)\n\tll := loglevel\n\tif ll == \"\" {\n\t\tll = \"info\"\n\t}\n\tif level, ok := mlog.Levels[ll]; ok {\n\t\tmox.Conf.Log[\"\"] = level\n\t\tmlog.SetConfig(mox.Conf.Log)\n\t} else {\n\t\tlog.Fatal(\"unknown loglevel\", slog.String(\"loglevel\", loglevel))\n\t}\n\tif pedantic {\n\t\tmox.SetPedantic(true)\n\t}\n}\n\nfunc main() {\n\t// CheckConsistencyOnClose is true by default, for all the test packages. A regular\n\t// mox server should never use it. But integration tests enable it again with a\n\t// flag.\n\tstore.CheckConsistencyOnClose = false\n\n\tctxbg := context.Background()\n\tmox.Shutdown = ctxbg\n\tmox.Context = ctxbg\n\n\tlog.SetFlags(0)\n\n\t// If invoked as sendmail, e.g. /usr/sbin/sendmail, we do enough so cron can get a\n\t// message sent using smtp submission to a configured server.\n\tif len(os.Args) > 0 && filepath.Base(os.Args[0]) == \"sendmail\" {\n\t\tc := &cmd{\n\t\t\tflag:     flag.NewFlagSet(\"sendmail\", flag.ExitOnError),\n\t\t\tflagArgs: os.Args[1:],\n\t\t\tlog:      mlog.New(\"sendmail\", nil),\n\t\t}\n\t\tcmdSendmail(c)\n\t\treturn\n\t}\n\n\tflag.StringVar(&mox.ConfigStaticPath, \"config\", envString(\"MOXCONF\", filepath.FromSlash(\"config/mox.conf\")), \"configuration file, other config files are looked up in the same directory, defaults to $MOXCONF with a fallback to mox.conf\")\n\tflag.StringVar(&loglevel, \"loglevel\", \"\", \"if non-empty, this log level is set early in startup\")\n\tflag.BoolVar(&pedantic, \"pedantic\", false, \"protocol violations result in errors instead of accepting/working around them\")\n\tflag.BoolVar(&store.CheckConsistencyOnClose, \"checkconsistency\", false, \"dangerous option for testing only, enables data checks that abort/panic when inconsistencies are found\")\n\n\tvar cpuprofile, memprofile, tracefile string\n\tflag.StringVar(&cpuprofile, \"cpuprof\", \"\", \"store cpu profile to file\")\n\tflag.StringVar(&memprofile, \"memprof\", \"\", \"store mem profile to file\")\n\tflag.StringVar(&tracefile, \"trace\", \"\", \"store execution trace to file\")\n\n\tflag.Usage = func() { usage(cmds, false) }\n\tflag.Parse()\n\targs := flag.Args()\n\tif len(args) == 0 {\n\t\tusage(cmds, false)\n\t}\n\n\tif tracefile != \"\" {\n\t\tdefer traceExecution(tracefile)()\n\t}\n\tdefer profile(cpuprofile, memprofile)()\n\n\tif pedantic {\n\t\tmox.SetPedantic(true)\n\t}\n\n\tmox.ConfigDynamicPath = filepath.Join(filepath.Dir(mox.ConfigStaticPath), \"domains.conf\")\n\tll := loglevel\n\tif ll == \"\" {\n\t\tll = \"info\"\n\t}\n\tif level, ok := mlog.Levels[ll]; ok {\n\t\tmox.Conf.Log[\"\"] = level\n\t\tmlog.SetConfig(mox.Conf.Log)\n\t\t// note: SetConfig may be called again when subcommands loads config.\n\t} else {\n\t\tlog.Fatalf(\"unknown loglevel %q\", loglevel)\n\t}\n\n\tvar partial []cmd\nnext:\n\tfor _, c := range cmds {\n\t\tfor i, w := range c.words {\n\t\t\tif i >= len(args) || w != args[i] {\n\t\t\t\tif i > 0 {\n\t\t\t\t\tpartial = append(partial, c)\n\t\t\t\t}\n\t\t\t\tcontinue next\n\t\t\t}\n\t\t}\n\t\tc.flag = flag.NewFlagSet(\"mox \"+strings.Join(c.words, \" \"), flag.ExitOnError)\n\t\tc.flagArgs = args[len(c.words):]\n\t\tc.log = mlog.New(strings.Join(c.words, \"\"), nil)\n\t\tc.fn(&c)\n\t\treturn\n\t}\n\tif len(partial) > 0 {\n\t\tusage(partial, true)\n\t}\n\tusage(cmds, false)\n}\n\nfunc xcheckf(err error, format string, args ...any) {\n\tif err == nil {\n\t\treturn\n\t}\n\tmsg := fmt.Sprintf(format, args...)\n\tlog.Fatalf(\"%s: %s\", msg, err)\n}\n\nfunc xparseIP(s, what string) net.IP {\n\tip := net.ParseIP(s)\n\tif ip == nil {\n\t\tlog.Fatalf(\"invalid %s: %q\", what, s)\n\t}\n\treturn ip\n}\n\nfunc xparseDomain(s, what string) dns.Domain {\n\td, err := dns.ParseDomain(s)\n\txcheckf(err, \"parsing %s %q\", what, s)\n\treturn d\n}\n\nfunc cmdClientConfig(c *cmd) {\n\tc.params = \"domain\"\n\tc.help = `Print the configuration for email clients for a domain.\n\nSending email is typically not done on the SMTP port 25, but on submission\nports 465 (with TLS) and 587 (without initial TLS, but usually added to the\nconnection with STARTTLS). For IMAP, the port with TLS is 993 and without is\n143.\n\nWithout TLS/STARTTLS, passwords are sent in clear text, which should only be\nconfigured over otherwise secured connections, like a VPN.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\td := xparseDomain(args[0], \"domain\")\n\tmustLoadConfig()\n\tprintClientConfig(d)\n}\n\nfunc printClientConfig(d dns.Domain) {\n\tcc, err := admin.ClientConfigsDomain(d)\n\txcheckf(err, \"getting client config\")\n\tfmt.Printf(\"%-20s %-30s %5s %-15s %s\\n\", \"Protocol\", \"Host\", \"Port\", \"Listener\", \"Note\")\n\tfor _, e := range cc.Entries {\n\t\tfmt.Printf(\"%-20s %-30s %5d %-15s %s\\n\", e.Protocol, e.Host, e.Port, e.Listener, e.Note)\n\t}\n\tfmt.Printf(`\nTo prevent authentication mechanism downgrade attempts that may result in\nclients sending plain text passwords to a MitM, clients should always be\nexplicitly configured with the most secure authentication mechanism supported,\nthe first of: SCRAM-SHA-256-PLUS, SCRAM-SHA-1-PLUS, SCRAM-SHA-256, SCRAM-SHA-1,\nCRAM-MD5.\n`)\n}\n\nfunc cmdConfigTest(c *cmd) {\n\tc.help = `Parses and validates the configuration files.\n\nIf valid, the command exits with status 0. If not valid, all errors encountered\nare printed.\n`\n\targs := c.Parse()\n\tif len(args) != 0 {\n\t\tc.Usage()\n\t}\n\n\tmox.FilesImmediate = true\n\n\t_, errs := mox.ParseConfig(context.Background(), c.log, mox.ConfigStaticPath, true, true, false)\n\tif len(errs) > 1 {\n\t\tlog.Printf(\"multiple errors:\")\n\t\tfor _, err := range errs {\n\t\t\tlog.Printf(\"%s\", err)\n\t\t}\n\t\tos.Exit(1)\n\t} else if len(errs) == 1 {\n\t\tlog.Fatalf(\"%s\", errs[0])\n\t\tos.Exit(1)\n\t}\n\tfmt.Println(\"config OK\")\n}\n\nfunc cmdConfigDescribeStatic(c *cmd) {\n\tc.params = \">mox.conf\"\n\tc.help = `Prints an annotated empty configuration for use as mox.conf.\n\nThe static configuration file cannot be reloaded while mox is running. Mox has\nto be restarted for changes to the static configuration file to take effect.\n\nThis configuration file needs modifications to make it valid. For example, it\nmay contain unfinished list items.\n`\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\n\tvar sc config.Static\n\terr := sconf.Describe(os.Stdout, &sc)\n\txcheckf(err, \"describing config\")\n}\n\nfunc cmdConfigDescribeDomains(c *cmd) {\n\tc.params = \">domains.conf\"\n\tc.help = `Prints an annotated empty configuration for use as domains.conf.\n\nThe domains configuration file contains the domains and their configuration,\nand accounts and their configuration. This includes the configured email\naddresses. The mox admin web interface, and the mox command line interface, can\nmake changes to this file. Mox automatically reloads this file when it changes.\n\nLike the static configuration, the example domains.conf printed by this command\nneeds modifications to make it valid.\n`\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\n\tvar dc config.Dynamic\n\terr := sconf.Describe(os.Stdout, &dc)\n\txcheckf(err, \"describing config\")\n}\n\nfunc cmdConfigPrintservice(c *cmd) {\n\tc.params = \">mox.service\"\n\tc.help = `Prints a systemd unit service file for mox.\n\nThis is the same file as generated using quickstart. If the systemd service file\nhas changed with a newer version of mox, use this command to generate an up to\ndate version.\n`\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\n\tpwd, err := os.Getwd()\n\tif err != nil {\n\t\tlog.Printf(\"current working directory: %v\", err)\n\t\tpwd = \"/home/mox\"\n\t}\n\tservice := strings.ReplaceAll(moxService, \"/home/mox\", pwd)\n\tfmt.Print(service)\n}\n\nfunc cmdConfigDomainAdd(c *cmd) {\n\tc.params = \"domain account [localpart]\"\n\tc.help = `Adds a new domain to the configuration and reloads the configuration.\n\nThe account is used for the postmaster mailboxes the domain, including as DMARC and\nTLS reporting. Localpart is the \"username\" at the domain for this account. If\nmust be set if and only if account does not yet exist.\n`\n\targs := c.Parse()\n\tif len(args) != 2 && len(args) != 3 {\n\t\tc.Usage()\n\t}\n\n\td := xparseDomain(args[0], \"domain\")\n\tmustLoadConfig()\n\tvar localpart smtp.Localpart\n\tif len(args) == 3 {\n\t\tvar err error\n\t\tlocalpart, err = smtp.ParseLocalpart(args[2])\n\t\txcheckf(err, \"parsing localpart\")\n\t}\n\tctlcmdConfigDomainAdd(xctl(), d, args[1], localpart)\n}\n\nfunc ctlcmdConfigDomainAdd(ctl *ctl, domain dns.Domain, account string, localpart smtp.Localpart) {\n\tctl.xwrite(\"domainadd\")\n\tctl.xwrite(domain.Name())\n\tctl.xwrite(account)\n\tctl.xwrite(string(localpart))\n\tctl.xreadok()\n\tfmt.Printf(\"domain added, remember to add dns records, see:\\n\\nmox config dnsrecords %s\\nmox config dnscheck %s\\n\", domain.Name(), domain.Name())\n}\n\nfunc cmdConfigDomainRemove(c *cmd) {\n\tc.params = \"domain\"\n\tc.help = `Remove a domain from the configuration and reload the configuration.\n\nThis is a dangerous operation. Incoming email delivery for this domain will be\nrejected.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\td := xparseDomain(args[0], \"domain\")\n\tmustLoadConfig()\n\tctlcmdConfigDomainRemove(xctl(), d)\n}\n\nfunc ctlcmdConfigDomainRemove(ctl *ctl, d dns.Domain) {\n\tctl.xwrite(\"domainrm\")\n\tctl.xwrite(d.Name())\n\tctl.xreadok()\n\tfmt.Printf(\"domain removed, remember to remove dns records for %s\\n\", d)\n}\n\nfunc cmdConfigAliasList(c *cmd) {\n\tc.params = \"domain\"\n\tc.help = `Show aliases (lists) for domain.`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\tctlcmdConfigAliasList(xctl(), args[0])\n}\n\nfunc ctlcmdConfigAliasList(ctl *ctl, address string) {\n\tctl.xwrite(\"aliaslist\")\n\tctl.xwrite(address)\n\tctl.xreadok()\n\tctl.xstreamto(os.Stdout)\n}\n\nfunc cmdConfigAliasPrint(c *cmd) {\n\tc.params = \"alias\"\n\tc.help = `Print settings and members of alias (list).`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\tctlcmdConfigAliasPrint(xctl(), args[0])\n}\n\nfunc ctlcmdConfigAliasPrint(ctl *ctl, address string) {\n\tctl.xwrite(\"aliasprint\")\n\tctl.xwrite(address)\n\tctl.xreadok()\n\tctl.xstreamto(os.Stdout)\n}\n\nfunc cmdConfigAliasAdd(c *cmd) {\n\tc.params = \"alias@domain rcpt1@domain ...\"\n\tc.help = `Add new alias (list) with one or more addresses and public posting enabled.\n\nAn alias is used for delivering incoming email to multiple recipients. If you\nwant to add an address to an account, don't use an alias, just add the address\nto the account.\n`\n\targs := c.Parse()\n\tif len(args) < 2 {\n\t\tc.Usage()\n\t}\n\n\talias := config.Alias{PostPublic: true, Addresses: args[1:]}\n\n\tmustLoadConfig()\n\tctlcmdConfigAliasAdd(xctl(), args[0], alias)\n}\n\nfunc ctlcmdConfigAliasAdd(ctl *ctl, address string, alias config.Alias) {\n\tctl.xwrite(\"aliasadd\")\n\tctl.xwrite(address)\n\txctlwriteJSON(ctl, alias)\n\tctl.xreadok()\n}\n\nfunc cmdConfigAliasUpdate(c *cmd) {\n\tc.params = \"alias@domain [-postpublic false|true -listmembers false|true -allowmsgfrom false|true]\"\n\tc.help = `Update alias (list) configuration.`\n\tvar postpublic, listmembers, allowmsgfrom string\n\tc.flag.StringVar(&postpublic, \"postpublic\", \"\", \"whether anyone or only list members can post\")\n\tc.flag.StringVar(&listmembers, \"listmembers\", \"\", \"whether list members can list members\")\n\tc.flag.StringVar(&allowmsgfrom, \"allowmsgfrom\", \"\", \"whether alias address can be used in message from header\")\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\talias := args[0]\n\tmustLoadConfig()\n\tctlcmdConfigAliasUpdate(xctl(), alias, postpublic, listmembers, allowmsgfrom)\n}\n\nfunc ctlcmdConfigAliasUpdate(ctl *ctl, alias, postpublic, listmembers, allowmsgfrom string) {\n\tctl.xwrite(\"aliasupdate\")\n\tctl.xwrite(alias)\n\tctl.xwrite(postpublic)\n\tctl.xwrite(listmembers)\n\tctl.xwrite(allowmsgfrom)\n\tctl.xreadok()\n}\n\nfunc cmdConfigAliasRemove(c *cmd) {\n\tc.params = \"alias@domain\"\n\tc.help = \"Remove alias (list).\"\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\tctlcmdConfigAliasRemove(xctl(), args[0])\n}\n\nfunc ctlcmdConfigAliasRemove(ctl *ctl, alias string) {\n\tctl.xwrite(\"aliasrm\")\n\tctl.xwrite(alias)\n\tctl.xreadok()\n}\n\nfunc cmdConfigAliasAddaddr(c *cmd) {\n\tc.params = \"alias@domain rcpt1@domain ...\"\n\tc.help = `Add addresses to alias (list).`\n\targs := c.Parse()\n\tif len(args) < 2 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\tctlcmdConfigAliasAddaddr(xctl(), args[0], args[1:])\n}\n\nfunc ctlcmdConfigAliasAddaddr(ctl *ctl, alias string, addresses []string) {\n\tctl.xwrite(\"aliasaddaddr\")\n\tctl.xwrite(alias)\n\txctlwriteJSON(ctl, addresses)\n\tctl.xreadok()\n}\n\nfunc cmdConfigAliasRemoveaddr(c *cmd) {\n\tc.params = \"alias@domain rcpt1@domain ...\"\n\tc.help = `Remove addresses from alias (list).`\n\targs := c.Parse()\n\tif len(args) < 2 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\tctlcmdConfigAliasRmaddr(xctl(), args[0], args[1:])\n}\n\nfunc ctlcmdConfigAliasRmaddr(ctl *ctl, alias string, addresses []string) {\n\tctl.xwrite(\"aliasrmaddr\")\n\tctl.xwrite(alias)\n\txctlwriteJSON(ctl, addresses)\n\tctl.xreadok()\n}\n\nfunc cmdConfigAccountAdd(c *cmd) {\n\tc.params = \"account address\"\n\tc.help = `Add an account with an email address and reload the configuration.\n\nEmail can be delivered to this address/account. A password has to be configured\nexplicitly, see the setaccountpassword command.\n`\n\targs := c.Parse()\n\tif len(args) != 2 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\tctlcmdConfigAccountAdd(xctl(), args[0], args[1])\n}\n\nfunc ctlcmdConfigAccountAdd(ctl *ctl, account, address string) {\n\tctl.xwrite(\"accountadd\")\n\tctl.xwrite(account)\n\tctl.xwrite(address)\n\tctl.xreadok()\n\tfmt.Printf(\"account added, set a password with \\\"mox setaccountpassword %s\\\"\\n\", account)\n}\n\nfunc cmdConfigAccountRemove(c *cmd) {\n\tc.params = \"account\"\n\tc.help = `Remove an account and reload the configuration.\n\nEmail addresses for this account will also be removed, and incoming email for\nthese addresses will be rejected.\n\nAll data for the account will be removed.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\tctlcmdConfigAccountRemove(xctl(), args[0])\n}\n\nfunc ctlcmdConfigAccountRemove(ctl *ctl, account string) {\n\tctl.xwrite(\"accountrm\")\n\tctl.xwrite(account)\n\tctl.xreadok()\n\tfmt.Println(\"account removed\")\n}\n\nfunc cmdConfigTlspubkeyList(c *cmd) {\n\tc.params = \"[account]\"\n\tc.help = `List TLS public keys for TLS client certificate authentication.\n\nIf account is absent, the TLS public keys for all accounts are listed.\n`\n\targs := c.Parse()\n\tvar accountOpt string\n\tif len(args) == 1 {\n\t\taccountOpt = args[0]\n\t} else if len(args) > 1 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\tctlcmdConfigTlspubkeyList(xctl(), accountOpt)\n}\n\nfunc ctlcmdConfigTlspubkeyList(ctl *ctl, accountOpt string) {\n\tctl.xwrite(\"tlspubkeylist\")\n\tctl.xwrite(accountOpt)\n\tctl.xreadok()\n\tctl.xstreamto(os.Stdout)\n}\n\nfunc cmdConfigTlspubkeyGet(c *cmd) {\n\tc.params = \"fingerprint\"\n\tc.help = `Get a TLS public key for a fingerprint.\n\nPrints the type, name, account and address for the key, and the certificate in\nPEM format.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\tctlcmdConfigTlspubkeyGet(xctl(), args[0])\n}\n\nfunc ctlcmdConfigTlspubkeyGet(ctl *ctl, fingerprint string) {\n\tctl.xwrite(\"tlspubkeyget\")\n\tctl.xwrite(fingerprint)\n\tctl.xreadok()\n\ttyp := ctl.xread()\n\tname := ctl.xread()\n\taccount := ctl.xread()\n\taddress := ctl.xread()\n\tnoimappreauth := ctl.xread()\n\tvar b bytes.Buffer\n\tctl.xstreamto(&b)\n\tbuf := b.Bytes()\n\tvar block *pem.Block\n\tif len(buf) != 0 {\n\t\tblock = &pem.Block{\n\t\t\tType:  \"CERTIFICATE\",\n\t\t\tBytes: buf,\n\t\t}\n\t}\n\n\tfmt.Printf(\"type: %s\\nname: %s\\naccount: %s\\naddress: %s\\nno imap preauth: %s\\n\", typ, name, account, address, noimappreauth)\n\tif block != nil {\n\t\tfmt.Printf(\"certificate:\\n\\n\")\n\t\tpem.Encode(os.Stdout, block)\n\t}\n}\n\nfunc cmdConfigTlspubkeyAdd(c *cmd) {\n\tc.params = \"address [name] < cert.pem\"\n\tc.help = `Add a TLS public key to the account of the given address.\n\nThe public key is read from the certificate.\n\nThe optional name is a human-readable descriptive name of the key. If absent,\nthe CommonName from the certificate is used.\n`\n\tvar noimappreauth bool\n\tc.flag.BoolVar(&noimappreauth, \"no-imap-preauth\", false, \"Don't automatically switch new IMAP connections authenticated with this key to \\\"authenticated\\\" state after the TLS handshake. For working around clients that ignore the untagged IMAP PREAUTH response and try to authenticate while already authenticated.\")\n\targs := c.Parse()\n\tvar address, name string\n\tif len(args) == 1 {\n\t\taddress = args[0]\n\t} else if len(args) == 2 {\n\t\taddress, name = args[0], args[1]\n\t} else {\n\t\tc.Usage()\n\t}\n\n\tbuf, err := io.ReadAll(os.Stdin)\n\txcheckf(err, \"reading from stdin\")\n\tblock, _ := pem.Decode(buf)\n\tif block == nil {\n\t\terr = errors.New(\"no pem block found\")\n\t} else if block.Type != \"CERTIFICATE\" {\n\t\terr = fmt.Errorf(\"unexpected type %q, expected CERTIFICATE\", block.Type)\n\t}\n\txcheckf(err, \"parsing pem\")\n\n\tmustLoadConfig()\n\tctlcmdConfigTlspubkeyAdd(xctl(), address, name, noimappreauth, block.Bytes)\n}\n\nfunc ctlcmdConfigTlspubkeyAdd(ctl *ctl, address, name string, noimappreauth bool, certDER []byte) {\n\tctl.xwrite(\"tlspubkeyadd\")\n\tctl.xwrite(address)\n\tctl.xwrite(name)\n\tctl.xwrite(fmt.Sprintf(\"%v\", noimappreauth))\n\tctl.xstreamfrom(bytes.NewReader(certDER))\n\tctl.xreadok()\n}\n\nfunc cmdConfigTlspubkeyRemove(c *cmd) {\n\tc.params = \"fingerprint\"\n\tc.help = `Remove TLS public key for fingerprint.`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\tctlcmdConfigTlspubkeyRemove(xctl(), args[0])\n}\n\nfunc ctlcmdConfigTlspubkeyRemove(ctl *ctl, fingerprint string) {\n\tctl.xwrite(\"tlspubkeyrm\")\n\tctl.xwrite(fingerprint)\n\tctl.xreadok()\n}\n\nfunc cmdConfigTlspubkeyGen(c *cmd) {\n\tc.params = \"stem\"\n\tc.help = `Generate an ed25519 private key and minimal certificate for use a TLS public key and write to files starting with stem.\n\nThe private key is written to $stem.$timestamp.ed25519privatekey.pkcs8.pem.\nThe certificate is written to $stem.$timestamp.certificate.pem.\nThe private key and certificate are also written to\n$stem.$timestamp.ed25519privatekey-certificate.pem.\n\nThe certificate can be added to an account with \"mox config account tlspubkey add\".\n\nThe combined file can be used with \"mox sendmail\".\n\nThe private key is also written to standard error in raw-url-base64-encoded\nform, also for use with \"mox sendmail\". The fingerprint is written to standard\nerror too, for reference.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tstem := args[0]\n\ttimestamp := time.Now().Format(\"200601021504\")\n\tprefix := stem + \".\" + timestamp\n\n\tseed := make([]byte, ed25519.SeedSize)\n\tif _, err := cryptorand.Read(seed); err != nil {\n\t\tpanic(err)\n\t}\n\tprivKey := ed25519.NewKeyFromSeed(seed)\n\tprivKeyBuf, err := x509.MarshalPKCS8PrivateKey(privKey)\n\txcheckf(err, \"marshal private key as pkcs8\")\n\tvar b bytes.Buffer\n\terr = pem.Encode(&b, &pem.Block{Type: \"PRIVATE KEY\", Bytes: privKeyBuf})\n\txcheckf(err, \"marshal pkcs8 private key to pem\")\n\tprivKeyBufPEM := b.Bytes()\n\n\tcertBuf, tlsCert := xminimalCert(privKey)\n\tb = bytes.Buffer{}\n\terr = pem.Encode(&b, &pem.Block{Type: \"CERTIFICATE\", Bytes: certBuf})\n\txcheckf(err, \"marshal certificate to pem\")\n\tcertBufPEM := b.Bytes()\n\n\txwriteFile := func(p string, data []byte, what string) {\n\t\tlog.Printf(\"writing %s\", p)\n\t\terr = os.WriteFile(p, data, 0600)\n\t\txcheckf(err, \"writing %s file: %v\", what, err)\n\t}\n\n\txwriteFile(prefix+\".ed25519privatekey.pkcs8.pem\", privKeyBufPEM, \"private key\")\n\txwriteFile(prefix+\".certificate.pem\", certBufPEM, \"certificate\")\n\tcombinedPEM := append(append([]byte{}, privKeyBufPEM...), certBufPEM...)\n\txwriteFile(prefix+\".ed25519privatekey-certificate.pem\", combinedPEM, \"combined private key and certificate\")\n\n\tshabuf := sha256.Sum256(tlsCert.Leaf.RawSubjectPublicKeyInfo)\n\n\t_, err = fmt.Fprintf(os.Stderr, \"ed25519 private key as raw-url-base64: %s\\ned25519 public key fingerprint: %s\\n\",\n\t\tbase64.RawURLEncoding.EncodeToString(seed),\n\t\tbase64.RawURLEncoding.EncodeToString(shabuf[:]),\n\t)\n\txcheckf(err, \"write private key and public key fingerprint\")\n}\n\nfunc cmdConfigAddressAdd(c *cmd) {\n\tc.params = \"address account\"\n\tc.help = `Adds an address to an account and reloads the configuration.\n\nIf address starts with a @ (i.e. a missing localpart), this is a catchall\naddress for the domain.\n`\n\targs := c.Parse()\n\tif len(args) != 2 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\tctlcmdConfigAddressAdd(xctl(), args[0], args[1])\n}\n\nfunc ctlcmdConfigAddressAdd(ctl *ctl, address, account string) {\n\tctl.xwrite(\"addressadd\")\n\tctl.xwrite(address)\n\tctl.xwrite(account)\n\tctl.xreadok()\n\tfmt.Println(\"address added\")\n}\n\nfunc cmdConfigAddressRemove(c *cmd) {\n\tc.params = \"address\"\n\tc.help = `Remove an address and reload the configuration.\n\nIncoming email for this address will be rejected after removing an address.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\tctlcmdConfigAddressRemove(xctl(), args[0])\n}\n\nfunc ctlcmdConfigAddressRemove(ctl *ctl, address string) {\n\tctl.xwrite(\"addressrm\")\n\tctl.xwrite(address)\n\tctl.xreadok()\n\tfmt.Println(\"address removed\")\n}\n\nfunc cmdConfigDNSRecords(c *cmd) {\n\tc.params = \"domain\"\n\tc.help = `Prints annotated DNS records as zone file that should be created for the domain.\n\nThe zone file can be imported into existing DNS software. You should review the\nDNS records, especially if your domain previously/currently has email\nconfigured.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\td := xparseDomain(args[0], \"domain\")\n\tmustLoadConfig()\n\tdomConf, ok := mox.Conf.Domain(d)\n\tif !ok {\n\t\tlog.Fatalf(\"unknown domain\")\n\t}\n\n\tresolver := dns.StrictResolver{Pkg: \"main\"}\n\t_, result, err := resolver.LookupTXT(context.Background(), d.ASCII+\".\")\n\tif !dns.IsNotFound(err) {\n\t\txcheckf(err, \"looking up record for dnssec-status\")\n\t}\n\n\tvar certIssuerDomainName, acmeAccountURI string\n\tpublic := mox.Conf.Static.Listeners[\"public\"]\n\tif public.TLS != nil && public.TLS.ACME != \"\" {\n\t\tacme, ok := mox.Conf.Static.ACME[public.TLS.ACME]\n\t\tif ok && acme.Manager.Manager.Client != nil {\n\t\t\tcertIssuerDomainName = acme.IssuerDomainName\n\t\t\tacc, err := acme.Manager.Manager.Client.GetReg(context.Background(), \"\")\n\t\t\tc.log.Check(err, \"get public acme account\")\n\t\t\tif err == nil {\n\t\t\t\tacmeAccountURI = acc.URI\n\t\t\t}\n\t\t}\n\t}\n\n\trecords, err := admin.DomainRecords(domConf, d, result.Authentic, certIssuerDomainName, acmeAccountURI)\n\txcheckf(err, \"records\")\n\tfmt.Print(strings.Join(records, \"\\n\") + \"\\n\")\n}\n\nfunc cmdConfigDNSCheck(c *cmd) {\n\tc.params = \"domain\"\n\tc.help = \"Check the DNS records with the configuration for the domain, and print any errors/warnings.\"\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\td := xparseDomain(args[0], \"domain\")\n\tmustLoadConfig()\n\t_, ok := mox.Conf.Domain(d)\n\tif !ok {\n\t\tlog.Fatalf(\"unknown domain\")\n\t}\n\n\t// todo future: move http.Admin.CheckDomain to mox- and make it return a regular error.\n\tdefer func() {\n\t\tx := recover()\n\t\tif x == nil {\n\t\t\treturn\n\t\t}\n\t\terr, ok := x.(*sherpa.Error)\n\t\tif !ok {\n\t\t\tpanic(x)\n\t\t}\n\t\tlog.Fatalf(\"%s\", err)\n\t}()\n\n\tprintResult := func(name string, r webadmin.Result) {\n\t\tif len(r.Errors) == 0 && len(r.Warnings) == 0 {\n\t\t\treturn\n\t\t}\n\t\tfmt.Printf(\"# %s\\n\", name)\n\t\tfor _, s := range r.Errors {\n\t\t\tfmt.Printf(\"error: %s\\n\", s)\n\t\t}\n\t\tfor _, s := range r.Warnings {\n\t\t\tfmt.Printf(\"warning: %s\\n\", s)\n\t\t}\n\t}\n\n\tresult := webadmin.Admin{}.CheckDomain(context.Background(), args[0])\n\tprintResult(\"DNSSEC\", result.DNSSEC.Result)\n\tprintResult(\"IPRev\", result.IPRev.Result)\n\tprintResult(\"MX\", result.MX.Result)\n\tprintResult(\"TLS\", result.TLS.Result)\n\tprintResult(\"DANE\", result.DANE.Result)\n\tprintResult(\"SPF\", result.SPF.Result)\n\tprintResult(\"DKIM\", result.DKIM.Result)\n\tprintResult(\"DMARC\", result.DMARC.Result)\n\tprintResult(\"Host TLSRPT\", result.HostTLSRPT.Result)\n\tprintResult(\"Domain TLSRPT\", result.DomainTLSRPT.Result)\n\tprintResult(\"MTASTS\", result.MTASTS.Result)\n\tprintResult(\"SRV conf\", result.SRVConf.Result)\n\tprintResult(\"Autoconf\", result.Autoconf.Result)\n\tprintResult(\"Autodiscover\", result.Autodiscover.Result)\n}\n\nfunc cmdConfigEnsureACMEHostprivatekeys(c *cmd) {\n\tc.params = \"\"\n\tc.help = `Ensure host private keys exist for TLS listeners with ACME.\n\nIn mox.conf, each listener can have TLS configured. Long-lived private key files\ncan be specified, which will be used when requesting ACME certificates.\nConfiguring these private keys makes it feasible to publish DANE TLSA records\nfor the corresponding public keys in DNS, protected with DNSSEC, allowing TLS\ncertificate verification without depending on a list of Certificate Authorities\n(CAs). Previous versions of mox did not pre-generate private keys for use with\nACME certificates, but would generate private keys on-demand. By explicitly\nconfiguring private keys, they will not change automatedly with new\ncertificates, and the DNS TLSA records stay valid.\n\nThis command looks for listeners in mox.conf with TLS with ACME configured. For\neach missing host private key (of type rsa-2048 and ecdsa-p256) a key is written\nto config/hostkeys/. If a certificate exists in the ACME \"cache\", its private\nkey is copied. Otherwise a new private key is generated. Snippets for manually\nupdating/editing mox.conf are printed.\n\nAfter running this command, and updating mox.conf, run \"mox config dnsrecords\"\nfor a domain and create the TLSA DNS records it suggests to enable DANE.\n`\n\targs := c.Parse()\n\tif len(args) != 0 {\n\t\tc.Usage()\n\t}\n\n\t// Load a private key from p, in various forms. We only look at the first PEM\n\t// block. Files with only a private key, or with multiple blocks but private key\n\t// first like autocert does, can be loaded.\n\tloadPrivateKey := func(f *os.File) (any, error) {\n\t\tbuf, err := io.ReadAll(f)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"reading private key file: %v\", err)\n\t\t}\n\t\tblock, _ := pem.Decode(buf)\n\t\tif block == nil {\n\t\t\treturn nil, fmt.Errorf(\"no pem block found in pem file\")\n\t\t}\n\t\tvar privKey any\n\t\tswitch block.Type {\n\t\tcase \"EC PRIVATE KEY\":\n\t\t\tprivKey, err = x509.ParseECPrivateKey(block.Bytes)\n\t\tcase \"RSA PRIVATE KEY\":\n\t\t\tprivKey, err = x509.ParsePKCS1PrivateKey(block.Bytes)\n\t\tcase \"PRIVATE KEY\":\n\t\t\tprivKey, err = x509.ParsePKCS8PrivateKey(block.Bytes)\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"unrecognized pem block type %q\", block.Type)\n\t\t}\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"parsing private key of type %q: %v\", block.Type, err)\n\t\t}\n\t\treturn privKey, nil\n\t}\n\n\t// Either load a private key from file, or if it doesn't exist generate a new\n\t// private key.\n\txtryLoadPrivateKey := func(kt autocert.KeyType, p string) any {\n\t\tf, err := os.Open(p)\n\t\tif err != nil && errors.Is(err, fs.ErrNotExist) {\n\t\t\tswitch kt {\n\t\t\tcase autocert.KeyRSA2048:\n\t\t\t\tprivKey, err := rsa.GenerateKey(cryptorand.Reader, 2048)\n\t\t\t\txcheckf(err, \"generating new 2048-bit rsa private key\")\n\t\t\t\treturn privKey\n\t\t\tcase autocert.KeyECDSAP256:\n\t\t\t\tprivKey, err := ecdsa.GenerateKey(elliptic.P256(), cryptorand.Reader)\n\t\t\t\txcheckf(err, \"generating new ecdsa p-256 private key\")\n\t\t\t\treturn privKey\n\t\t\t}\n\t\t\tlog.Fatalf(\"unexpected keytype %v\", kt)\n\t\t\treturn nil\n\t\t}\n\t\txcheckf(err, \"%s: open acme key and certificate file\", p)\n\n\t\t// Load private key from file. autocert stores a PEM file that starts with a\n\t\t// private key, followed by certificate(s). So we can just read it and should find\n\t\t// the private key we are looking for.\n\t\tprivKey, err := loadPrivateKey(f)\n\t\tif xerr := f.Close(); xerr != nil {\n\t\t\tlog.Printf(\"closing private key file: %v\", xerr)\n\t\t}\n\t\txcheckf(err, \"parsing private key from acme key and certificate file\")\n\n\t\tswitch k := privKey.(type) {\n\t\tcase *rsa.PrivateKey:\n\t\t\tif k.N.BitLen() == 2048 {\n\t\t\t\treturn privKey\n\t\t\t}\n\t\t\tlog.Printf(\"warning: rsa private key in %s has %d bits, skipping and generating new 2048-bit rsa private key\", p, k.N.BitLen())\n\t\t\tprivKey, err := rsa.GenerateKey(cryptorand.Reader, 2048)\n\t\t\txcheckf(err, \"generating new 2048-bit rsa private key\")\n\t\t\treturn privKey\n\t\tcase *ecdsa.PrivateKey:\n\t\t\tif k.Curve == elliptic.P256() {\n\t\t\t\treturn privKey\n\t\t\t}\n\t\t\tlog.Printf(\"warning: ecdsa private key in %s has curve %v, skipping and generating new p-256 ecdsa key\", p, k.Curve.Params().Name)\n\t\t\tprivKey, err := ecdsa.GenerateKey(elliptic.P256(), cryptorand.Reader)\n\t\t\txcheckf(err, \"generating new ecdsa p-256 private key\")\n\t\t\treturn privKey\n\t\tdefault:\n\t\t\tlog.Fatalf(\"%s: unexpected private key file of type %T\", p, privKey)\n\t\t\treturn nil\n\t\t}\n\t}\n\n\t// Write privKey as PKCS#8 private key to p. Only if file does not yet exist.\n\twriteHostPrivateKey := func(privKey any, p string) error {\n\t\tos.MkdirAll(filepath.Dir(p), 0700)\n\t\tf, err := os.OpenFile(p, os.O_CREATE|os.O_EXCL|os.O_WRONLY, 0600)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"create: %v\", err)\n\t\t}\n\t\tdefer func() {\n\t\t\tif f != nil {\n\t\t\t\tif err := f.Close(); err != nil {\n\t\t\t\t\tlog.Printf(\"closing new hostkey file %s after error: %v\", p, err)\n\t\t\t\t}\n\t\t\t\tif err := os.Remove(p); err != nil {\n\t\t\t\t\tlog.Printf(\"removing new hostkey file %s after error: %v\", p, err)\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t\tbuf, err := x509.MarshalPKCS8PrivateKey(privKey)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"marshal private host key: %v\", err)\n\t\t}\n\t\tblock := pem.Block{\n\t\t\tType:  \"PRIVATE KEY\",\n\t\t\tBytes: buf,\n\t\t}\n\t\tif err := pem.Encode(f, &block); err != nil {\n\t\t\treturn fmt.Errorf(\"write as pem: %v\", err)\n\t\t}\n\t\tif err := f.Close(); err != nil {\n\t\t\treturn fmt.Errorf(\"close: %v\", err)\n\t\t}\n\t\tf = nil\n\t\treturn nil\n\t}\n\n\tmustLoadConfig()\n\ttimestamp := time.Now().Format(\"20060102T150405\")\n\tdidCreate := false\n\tfor listenerName, l := range mox.Conf.Static.Listeners {\n\t\tif l.TLS == nil || l.TLS.ACME == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\thaveKeyTypes := map[autocert.KeyType]bool{}\n\t\tfor _, privKeyFile := range l.TLS.HostPrivateKeyFiles {\n\t\t\tp := mox.ConfigDirPath(privKeyFile)\n\t\t\tf, err := os.Open(p)\n\t\t\txcheckf(err, \"open host private key\")\n\t\t\tprivKey, err := loadPrivateKey(f)\n\t\t\tif err := f.Close(); err != nil {\n\t\t\t\tlog.Printf(\"closing host private key file: %v\", err)\n\t\t\t}\n\t\t\txcheckf(err, \"loading host private key\")\n\t\t\tswitch k := privKey.(type) {\n\t\t\tcase *rsa.PrivateKey:\n\t\t\t\tif k.N.BitLen() == 2048 {\n\t\t\t\t\thaveKeyTypes[autocert.KeyRSA2048] = true\n\t\t\t\t}\n\t\t\tcase *ecdsa.PrivateKey:\n\t\t\t\tif k.Curve == elliptic.P256() {\n\t\t\t\t\thaveKeyTypes[autocert.KeyECDSAP256] = true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tcreated := []string{}\n\t\tfor _, kt := range []autocert.KeyType{autocert.KeyRSA2048, autocert.KeyECDSAP256} {\n\t\t\tif haveKeyTypes[kt] {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\t// Lookup key in ACME cache.\n\t\t\thost := l.HostnameDomain\n\t\t\tif host.ASCII == \"\" {\n\t\t\t\thost = mox.Conf.Static.HostnameDomain\n\t\t\t}\n\t\t\tfilename := host.ASCII\n\t\t\tkind := \"ecdsap256\"\n\t\t\tif kt == autocert.KeyRSA2048 {\n\t\t\t\tfilename += \"+rsa\"\n\t\t\t\tkind = \"rsa2048\"\n\t\t\t}\n\t\t\tp := mox.DataDirPath(filepath.Join(\"acme\", \"keycerts\", l.TLS.ACME, filename))\n\t\t\tprivKey := xtryLoadPrivateKey(kt, p)\n\n\t\t\trelPath := filepath.Join(\"hostkeys\", fmt.Sprintf(\"%s.%s.%s.privatekey.pkcs8.pem\", host.Name(), timestamp, kind))\n\t\t\tdestPath := mox.ConfigDirPath(relPath)\n\t\t\terr := writeHostPrivateKey(privKey, destPath)\n\t\t\txcheckf(err, \"writing host private key file to %s: %v\", destPath, err)\n\t\t\tcreated = append(created, relPath)\n\t\t\tfmt.Printf(\"Wrote host private key: %s\\n\", destPath)\n\t\t}\n\t\tdidCreate = didCreate || len(created) > 0\n\t\tif len(created) > 0 {\n\t\t\ttls := config.TLS{\n\t\t\t\tHostPrivateKeyFiles: append(l.TLS.HostPrivateKeyFiles, created...),\n\t\t\t}\n\t\t\tfmt.Printf(\"\\nEnsure Listener %q in %s has the following in its TLS section, below \\\"ACME: %s\\\" (don't forget to indent with tabs):\\n\\n\", listenerName, mox.ConfigStaticPath, l.TLS.ACME)\n\t\t\terr := sconf.Write(os.Stdout, tls)\n\t\t\txcheckf(err, \"writing new TLS.HostPrivateKeyFiles section\")\n\t\t\tfmt.Println()\n\t\t}\n\t}\n\tif didCreate {\n\t\tfmt.Printf(`\nAfter updating mox.conf and restarting, run \"mox config dnsrecords\" for a\ndomain and create the TLSA DNS records it suggests to enable DANE.\n`)\n\t}\n}\n\nfunc cmdLoglevels(c *cmd) {\n\tc.params = \"[level [pkg]]\"\n\tc.help = `Print the log levels, or set a new default log level, or a level for the given package.\n\nBy default, a single log level applies to all logging in mox. But for each\n\"pkg\", an overriding log level can be configured. Examples of packages:\nsmtpserver, smtpclient, queue, imapserver, spf, dkim, dmarc, junk, message,\netc.\n\nSpecify a pkg and an empty level to clear the configured level for a package.\n\nValid labels: error, info, debug, trace, traceauth, tracedata.\n`\n\targs := c.Parse()\n\tif len(args) > 2 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\n\tif len(args) == 0 {\n\t\tctlcmdLoglevels(xctl())\n\t} else {\n\t\tvar pkg string\n\t\tif len(args) == 2 {\n\t\t\tpkg = args[1]\n\t\t}\n\t\tctlcmdSetLoglevels(xctl(), pkg, args[0])\n\t}\n}\n\nfunc ctlcmdLoglevels(ctl *ctl) {\n\tctl.xwrite(\"loglevels\")\n\tctl.xreadok()\n\tctl.xstreamto(os.Stdout)\n}\n\nfunc ctlcmdSetLoglevels(ctl *ctl, pkg, level string) {\n\tctl.xwrite(\"setloglevels\")\n\tctl.xwrite(pkg)\n\tctl.xwrite(level)\n\tctl.xreadok()\n}\n\nfunc cmdStop(c *cmd) {\n\tc.help = `Shut mox down, giving connections maximum 3 seconds to stop before closing them.\n\nWhile shutting down, new IMAP and SMTP connections will get a status response\nindicating temporary unavailability. Existing connections will get a 3 second\nperiod to finish their transaction and shut down. Under normal circumstances,\nonly IMAP has long-living connections, with the IDLE command to get notified of\nnew mail deliveries.\n`\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\n\tctl := xctl()\n\tctl.xwrite(\"stop\")\n\t// Read will hang until remote has shut down.\n\tbuf := make([]byte, 128)\n\tn, err := ctl.conn.Read(buf)\n\tif err == nil {\n\t\tlog.Fatalf(\"expected eof after graceful shutdown, got data %q\", buf[:n])\n\t} else if err != io.EOF {\n\t\tlog.Fatalf(\"expected eof after graceful shutdown, got error %v\", err)\n\t}\n\tfmt.Println(\"mox stopped\")\n}\n\nfunc cmdBackup(c *cmd) {\n\tc.params = \"dest-dir\"\n\tc.help = `Creates a backup of the data directory.\n\nBackup creates consistent snapshots of the databases and message files and\ncopies other files in the data directory. Empty directories are not copied.\nThese files can then be stored elsewhere for long-term storage, or used to fall\nback to should an upgrade fail. Simply copying files in the data directory\nwhile mox is running can result in unusable database files.\n\nMessage files never change (they are read-only, though can be removed) and are\nhard-linked so they don't consume additional space. If hardlinking fails, for\nexample when the backup destination directory is on a different file system, a\nregular copy is made. Using a destination directory like \"data/tmp/backup\"\nincreases the odds hardlinking succeeds: the default systemd service file\nspecifically mounts the data directory, causing attempts to hardlink outside it\nto fail with an error about cross-device linking.\n\nAll files in the data directory that aren't recognized (i.e. other than known\ndatabase files, message files, an acme directory, the \"tmp\" directory, etc),\nare stored, but with a warning.\n\nRemove files in the destination directory before doing another backup. The\nbackup command will not overwrite files, but print and return errors.\n\nExit code 0 indicates the backup was successful. A clean successful backup does\nnot print any output, but may print warnings. Use the -verbose flag for\ndetails, including timing.\n\nTo restore a backup, first shut down mox, move away the old data directory and\nmove an earlier backed up directory in its place, run \"mox verifydata\",\npossibly with the \"-fix\" option, and restart mox. After the restore, you may\nalso want to run \"mox bumpuidvalidity\" for each account for which messages in a\nmailbox changed, to force IMAP clients to synchronize mailbox state.\n\nBefore upgrading, to check if the upgrade will likely succeed, first make a\nbackup, then use the new mox binary to run \"mox verifydata\" on the backup. This\ncan change the backup files (e.g. upgrade database files, move away\nunrecognized message files), so you should make a new backup before actually\nupgrading.\n`\n\n\tvar verbose bool\n\tc.flag.BoolVar(&verbose, \"verbose\", false, \"print progress\")\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\n\tdstDataDir, err := filepath.Abs(args[0])\n\txcheckf(err, \"making path absolute\")\n\n\tctlcmdBackup(xctl(), dstDataDir, verbose)\n}\n\nfunc ctlcmdBackup(ctl *ctl, dstDataDir string, verbose bool) {\n\tctl.xwrite(\"backup\")\n\tctl.xwrite(dstDataDir)\n\tif verbose {\n\t\tctl.xwrite(\"verbose\")\n\t} else {\n\t\tctl.xwrite(\"\")\n\t}\n\tctl.xstreamto(os.Stdout)\n\tctl.xreadok()\n}\n\nfunc cmdSetadminpassword(c *cmd) {\n\tc.help = `Set a new admin password, for the web interface.\n\nThe password is read from stdin. Its bcrypt hash is stored in a file named\n\"adminpasswd\" in the configuration directory.\n`\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\n\tpath := mox.ConfigDirPath(mox.Conf.Static.AdminPasswordFile)\n\tif path == \"\" {\n\t\tlog.Fatal(\"no admin password file configured\")\n\t}\n\n\tpw := xreadpassword()\n\tpw, err := precis.OpaqueString.String(pw)\n\txcheckf(err, `checking password with \"precis\" requirements`)\n\thash, err := bcrypt.GenerateFromPassword([]byte(pw), bcrypt.DefaultCost)\n\txcheckf(err, \"generating hash for password\")\n\terr = os.WriteFile(path, hash, 0660)\n\txcheckf(err, \"writing hash to admin password file\")\n}\n\nfunc xreadpassword() string {\n\tfmt.Printf(`\nType new password. Password WILL echo.\n\nWARNING: Bots will try to bruteforce your password. Connections with failed\nauthentication attempts will be rate limited but attackers WILL find weak\npasswords. If your account is compromised, spammers are likely to abuse your\nsystem, spamming your address and the wider internet in your name. So please\npick a random, unguessable password, preferably at least 12 characters.\n\n`)\n\tfmt.Printf(\"password: \")\n\tbuf := make([]byte, 64)\n\tn, err := os.Stdin.Read(buf)\n\txcheckf(err, \"reading stdin\")\n\tpw := string(buf[:n])\n\tpw = strings.TrimSuffix(strings.TrimSuffix(pw, \"\\r\\n\"), \"\\n\")\n\tif len(pw) < 8 {\n\t\tlog.Fatal(\"password must be at least 8 characters\")\n\t}\n\treturn pw\n}\n\nfunc cmdSetaccountpassword(c *cmd) {\n\tc.params = \"account\"\n\tc.help = `Set new password an account.\n\nThe password is read from stdin. Secrets derived from the password, but not the\npassword itself, are stored in the account database. The stored secrets are for\nauthentication with: scram-sha-256, scram-sha-1, cram-md5, plain text (bcrypt\nhash).\n\nThe parameter is an account name, as configured under Accounts in domains.conf\nand as present in the data/accounts/ directory, not a configured email address\nfor an account.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\n\tpw := xreadpassword()\n\n\tctlcmdSetaccountpassword(xctl(), args[0], pw)\n}\n\nfunc ctlcmdSetaccountpassword(ctl *ctl, account, password string) {\n\tctl.xwrite(\"setaccountpassword\")\n\tctl.xwrite(account)\n\tctl.xwrite(password)\n\tctl.xreadok()\n}\n\nfunc cmdDeliver(c *cmd) {\n\tc.unlisted = true\n\tc.params = \"address < message\"\n\tc.help = \"Deliver message to address.\"\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdDeliver(xctl(), args[0])\n}\n\nfunc ctlcmdDeliver(ctl *ctl, address string) {\n\tctl.xwrite(\"deliver\")\n\tctl.xwrite(address)\n\tctl.xreadok()\n\tctl.xstreamfrom(os.Stdin)\n\tline := ctl.xread()\n\tif line == \"ok\" {\n\t\tfmt.Println(\"message delivered\")\n\t} else {\n\t\tlog.Fatalf(\"deliver: %s\", line)\n\t}\n}\n\nfunc cmdDKIMGenrsa(c *cmd) {\n\tc.params = \">$selector._domainkey.$domain.rsa2048.privatekey.pkcs8.pem\"\n\tc.help = `Generate a new 2048 bit RSA private key for use with DKIM.\n\nThe generated file is in PEM format, and has a comment it is generated for use\nwith DKIM, by mox.\n`\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\n\tbuf, err := admin.MakeDKIMRSAKey(dns.Domain{}, dns.Domain{})\n\txcheckf(err, \"making rsa private key\")\n\t_, err = os.Stdout.Write(buf)\n\txcheckf(err, \"writing rsa private key\")\n}\n\nfunc cmdDANEDial(c *cmd) {\n\tc.params = \"host:port\"\n\tvar usages string\n\tc.flag.StringVar(&usages, \"usages\", \"pkix-ta,pkix-ee,dane-ta,dane-ee\", \"allowed usages for dane, comma-separated list\")\n\tc.help = `Dial the address using TLS with certificate verification using DANE.\n\nData is copied between connection and stdin/stdout until either side closes the\nconnection.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tallowedUsages := []adns.TLSAUsage{}\n\tif usages != \"\" {\n\t\tfor _, s := range strings.Split(usages, \",\") {\n\t\t\tvar usage adns.TLSAUsage\n\t\t\tswitch strings.ToLower(s) {\n\t\t\tcase \"pkix-ta\", strconv.Itoa(int(adns.TLSAUsagePKIXTA)):\n\t\t\t\tusage = adns.TLSAUsagePKIXTA\n\t\t\tcase \"pkix-ee\", strconv.Itoa(int(adns.TLSAUsagePKIXEE)):\n\t\t\t\tusage = adns.TLSAUsagePKIXEE\n\t\t\tcase \"dane-ta\", strconv.Itoa(int(adns.TLSAUsageDANETA)):\n\t\t\t\tusage = adns.TLSAUsageDANETA\n\t\t\tcase \"dane-ee\", strconv.Itoa(int(adns.TLSAUsageDANEEE)):\n\t\t\t\tusage = adns.TLSAUsageDANEEE\n\t\t\tdefault:\n\t\t\t\tlog.Fatalf(\"unknown dane usage %q\", s)\n\t\t\t}\n\t\t\tallowedUsages = append(allowedUsages, usage)\n\t\t}\n\t}\n\n\tpkixRoots, err := x509.SystemCertPool()\n\txcheckf(err, \"get system pkix certificate pool\")\n\n\tresolver := dns.StrictResolver{Pkg: \"danedial\"}\n\tconn, record, err := dane.Dial(context.Background(), c.log.Logger, resolver, \"tcp\", args[0], allowedUsages, pkixRoots)\n\txcheckf(err, \"dial\")\n\tlog.Printf(\"(connected, verified with %s)\", record)\n\n\tgo func() {\n\t\t_, err := io.Copy(os.Stdout, conn)\n\t\txcheckf(err, \"copy from connection to stdout\")\n\t\tconn.Close()\n\t}()\n\t_, err = io.Copy(conn, os.Stdin)\n\txcheckf(err, \"copy from stdin to connection\")\n}\n\nfunc cmdDANEDialmx(c *cmd) {\n\tc.params = \"domain [destination-host]\"\n\tvar ehloHostname string\n\tc.flag.StringVar(&ehloHostname, \"ehlohostname\", \"localhost\", \"hostname to send in smtp ehlo command\")\n\tc.help = `Connect to MX server for domain using STARTTLS verified with DANE.\n\nIf no destination host is specified, regular delivery logic is used to find the\nhosts to attempt delivery too. This involves following CNAMEs for the domain,\nlooking up MX records, and possibly falling back to the domain name itself as\nhost.\n\nIf a destination host is specified, that is the only candidate host considered\nfor dialing.\n\nWith a list of destinations gathered, each is dialed until a successful SMTP\nsession verified with DANE has been initialized, including EHLO and STARTTLS\ncommands.\n\nOnce connected, data is copied between connection and stdin/stdout, until\neither side closes the connection.\n\nThis command follows the same logic as delivery attempts made from the queue,\nsharing most of its code.\n`\n\targs := c.Parse()\n\tif len(args) != 1 && len(args) != 2 {\n\t\tc.Usage()\n\t}\n\n\tehloDomain, err := dns.ParseDomain(ehloHostname)\n\txcheckf(err, \"parsing ehlo hostname\")\n\n\torigNextHop, err := dns.ParseDomain(args[0])\n\txcheckf(err, \"parse domain\")\n\n\tctxbg := context.Background()\n\n\tresolver := dns.StrictResolver{}\n\tvar haveMX bool\n\tvar origNextHopAuthentic, expandedNextHopAuthentic bool\n\tvar expandedNextHop dns.Domain\n\tvar hosts []dns.IPDomain\n\tif len(args) == 1 {\n\t\tvar permanent bool\n\t\thaveMX, origNextHopAuthentic, expandedNextHopAuthentic, expandedNextHop, hosts, permanent, err = smtpclient.GatherDestinations(ctxbg, c.log.Logger, resolver, dns.IPDomain{Domain: origNextHop})\n\t\tstatus := \"temporary\"\n\t\tif permanent {\n\t\t\tstatus = \"permanent\"\n\t\t}\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"gathering destinations: %v (%s)\", err, status)\n\t\t}\n\t\tif expandedNextHop != origNextHop {\n\t\t\tlog.Printf(\"followed cnames to %s\", expandedNextHop)\n\t\t}\n\t\tif haveMX {\n\t\t\tlog.Printf(\"found mx record, trying mx hosts\")\n\t\t} else {\n\t\t\tlog.Printf(\"no mx record found, will try to connect to domain directly\")\n\t\t}\n\t\tif !origNextHopAuthentic {\n\t\t\tlog.Fatalf(\"error: initial domain not dnssec-secure\")\n\t\t}\n\t\tif !expandedNextHopAuthentic {\n\t\t\tlog.Fatalf(\"error: expanded domain not dnssec-secure\")\n\t\t}\n\n\t\tl := []string{}\n\t\tfor _, h := range hosts {\n\t\t\tl = append(l, h.String())\n\t\t}\n\t\tlog.Printf(\"destinations: %s\", strings.Join(l, \", \"))\n\t} else {\n\t\td, err := dns.ParseDomain(args[1])\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"parsing destination host: %v\", err)\n\t\t}\n\t\tlog.Printf(\"skipping domain mx/cname lookups, assuming domain is dnssec-protected\")\n\n\t\torigNextHopAuthentic = true\n\t\texpandedNextHopAuthentic = true\n\t\texpandedNextHop = d\n\t\thosts = []dns.IPDomain{{Domain: d}}\n\t}\n\n\tdialedIPs := map[string][]net.IP{}\n\tfor _, host := range hosts {\n\t\t// It should not be possible for hosts to have IP addresses: They are not\n\t\t// allowed by dns.ParseDomain, and MX records cannot contain them.\n\t\tif host.IsIP() {\n\t\t\tlog.Fatalf(\"unexpected IP address for destination host\")\n\t\t}\n\n\t\tlog.Printf(\"attempting to connect to %s\", host)\n\n\t\tauthentic, expandedAuthentic, expandedHost, ips, _, err := smtpclient.GatherIPs(ctxbg, c.log.Logger, resolver, \"ip\", host, dialedIPs)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"resolving ips for %s: %v, skipping\", host, err)\n\t\t\tcontinue\n\t\t}\n\t\tif !authentic {\n\t\t\tlog.Printf(\"no dnssec for ips of %s, skipping\", host)\n\t\t\tcontinue\n\t\t}\n\t\tif !expandedAuthentic {\n\t\t\tlog.Printf(\"no dnssec for cname-followed ips of %s, skipping\", host)\n\t\t\tcontinue\n\t\t}\n\t\tif expandedHost != host.Domain {\n\t\t\tlog.Printf(\"host %s cname-expanded to %s\", host, expandedHost)\n\t\t}\n\t\tlog.Printf(\"host %s resolved to ips %s, looking up tlsa records\", host, ips)\n\n\t\tdaneRequired, daneRecords, tlsaBaseDomain, err := smtpclient.GatherTLSA(ctxbg, c.log.Logger, resolver, host.Domain, expandedAuthentic, expandedHost)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"looking up tlsa records: %s, skipping\", err)\n\t\t\tcontinue\n\t\t}\n\t\ttlsMode := smtpclient.TLSRequiredStartTLS\n\t\tif len(daneRecords) == 0 {\n\t\t\tif !daneRequired {\n\t\t\t\tlog.Printf(\"host %s has no tlsa records, skipping\", expandedHost)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tlog.Printf(\"warning: only unusable tlsa records found, continuing with required tls without certificate verification\")\n\t\t\tdaneRecords = nil\n\t\t} else {\n\t\t\tvar l []string\n\t\t\tfor _, r := range daneRecords {\n\t\t\t\tl = append(l, r.String())\n\t\t\t}\n\t\t\tlog.Printf(\"tlsa records: %s\", strings.Join(l, \"; \"))\n\t\t}\n\n\t\ttlsHostnames := smtpclient.GatherTLSANames(haveMX, expandedNextHopAuthentic, expandedAuthentic, origNextHop, expandedNextHop, host.Domain, tlsaBaseDomain)\n\t\tvar l []string\n\t\tfor _, name := range tlsHostnames {\n\t\t\tl = append(l, name.String())\n\t\t}\n\t\tlog.Printf(\"gathered valid tls certificate names for potential verification with dane-ta: %s\", strings.Join(l, \", \"))\n\n\t\tdialer := &net.Dialer{Timeout: 5 * time.Second}\n\t\tconn, _, err := smtpclient.Dial(ctxbg, c.log.Logger, dialer, dns.IPDomain{Domain: expandedHost}, ips, 25, dialedIPs, nil)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"dial %s: %v, skipping\", expandedHost, err)\n\t\t\tcontinue\n\t\t}\n\t\tlog.Printf(\"connected to %s, %s, starting smtp session with ehlo and starttls with dane verification\", expandedHost, conn.RemoteAddr())\n\n\t\tvar verifiedRecord adns.TLSA\n\t\topts := smtpclient.Opts{\n\t\t\tDANERecords:        daneRecords,\n\t\t\tDANEMoreHostnames:  tlsHostnames[1:],\n\t\t\tDANEVerifiedRecord: &verifiedRecord,\n\t\t\tRootCAs:            mox.Conf.Static.TLS.CertPool,\n\t\t}\n\t\ttlsPKIX := false\n\t\tsc, err := smtpclient.New(ctxbg, c.log.Logger, conn, tlsMode, tlsPKIX, ehloDomain, tlsHostnames[0], opts)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"setting up smtp session: %v, skipping\", err)\n\t\t\tconn.Close()\n\t\t\tcontinue\n\t\t}\n\n\t\tsmtpConn, err := sc.Conn()\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"error: taking over smtp connection: %s\", err)\n\t\t}\n\t\tlog.Printf(\"tls verified with tlsa record: %s\", verifiedRecord)\n\t\tlog.Printf(\"smtp session initialized and connected to stdin/stdout\")\n\n\t\tgo func() {\n\t\t\t_, err := io.Copy(os.Stdout, smtpConn)\n\t\t\txcheckf(err, \"copy from connection to stdout\")\n\t\t\tsmtpConn.Close()\n\t\t}()\n\t\t_, err = io.Copy(smtpConn, os.Stdin)\n\t\txcheckf(err, \"copy from stdin to connection\")\n\t}\n\n\tlog.Fatalf(\"no remaining destinations\")\n}\n\nfunc cmdDANEMakeRecord(c *cmd) {\n\tc.params = \"usage selector matchtype [certificate.pem | publickey.pem | privatekey.pem]\"\n\tc.help = `Print TLSA record for given certificate/key and parameters.\n\nValid values:\n- usage: pkix-ta (0), pkix-ee (1), dane-ta (2), dane-ee (3)\n- selector: cert (0), spki (1)\n- matchtype: full (0), sha2-256 (1), sha2-512 (2)\n\nCommon DANE TLSA record parameters are: dane-ee spki sha2-256, or 3 1 1,\nfollowed by a sha2-256 hash of the DER-encoded \"SPKI\" (subject public key info)\nfrom the certificate. An example DNS zone file entry:\n\n\t_25._tcp.example.com. TLSA 3 1 1 133b919c9d65d8b1488157315327334ead8d83372db57465ecabf53ee5748aee\n\nThe first usable information from the pem file is used to compose the TLSA\nrecord. In case of selector \"cert\", a certificate is required. Otherwise the\n\"subject public key info\" (spki) of the first certificate or public or private\nkey (pkcs#8, pkcs#1 or ec private key) is used.\n`\n\n\targs := c.Parse()\n\tif len(args) != 4 {\n\t\tc.Usage()\n\t}\n\n\tvar usage adns.TLSAUsage\n\tswitch strings.ToLower(args[0]) {\n\tcase \"pkix-ta\", strconv.Itoa(int(adns.TLSAUsagePKIXTA)):\n\t\tusage = adns.TLSAUsagePKIXTA\n\tcase \"pkix-ee\", strconv.Itoa(int(adns.TLSAUsagePKIXEE)):\n\t\tusage = adns.TLSAUsagePKIXEE\n\tcase \"dane-ta\", strconv.Itoa(int(adns.TLSAUsageDANETA)):\n\t\tusage = adns.TLSAUsageDANETA\n\tcase \"dane-ee\", strconv.Itoa(int(adns.TLSAUsageDANEEE)):\n\t\tusage = adns.TLSAUsageDANEEE\n\tdefault:\n\t\tif v, err := strconv.ParseUint(args[0], 10, 16); err != nil {\n\t\t\tlog.Fatalf(\"bad usage %q\", args[0])\n\t\t} else {\n\t\t\t// Does not influence certificate association data, so we can accept other numbers.\n\t\t\tlog.Printf(\"warning: continuing with unrecognized tlsa usage %d\", v)\n\t\t\tusage = adns.TLSAUsage(v)\n\t\t}\n\t}\n\n\tvar selector adns.TLSASelector\n\tswitch strings.ToLower(args[1]) {\n\tcase \"cert\", strconv.Itoa(int(adns.TLSASelectorCert)):\n\t\tselector = adns.TLSASelectorCert\n\tcase \"spki\", strconv.Itoa(int(adns.TLSASelectorSPKI)):\n\t\tselector = adns.TLSASelectorSPKI\n\tdefault:\n\t\tlog.Fatalf(\"bad selector %q\", args[1])\n\t}\n\n\tvar matchType adns.TLSAMatchType\n\tswitch strings.ToLower(args[2]) {\n\tcase \"full\", strconv.Itoa(int(adns.TLSAMatchTypeFull)):\n\t\tmatchType = adns.TLSAMatchTypeFull\n\tcase \"sha2-256\", strconv.Itoa(int(adns.TLSAMatchTypeSHA256)):\n\t\tmatchType = adns.TLSAMatchTypeSHA256\n\tcase \"sha2-512\", strconv.Itoa(int(adns.TLSAMatchTypeSHA512)):\n\t\tmatchType = adns.TLSAMatchTypeSHA512\n\tdefault:\n\t\tlog.Fatalf(\"bad matchtype %q\", args[2])\n\t}\n\n\tbuf, err := os.ReadFile(args[3])\n\txcheckf(err, \"reading certificate\")\n\tfor {\n\t\tvar block *pem.Block\n\t\tblock, buf = pem.Decode(buf)\n\t\tif block == nil {\n\t\t\textra := \"\"\n\t\t\tif len(buf) > 0 {\n\t\t\t\textra = \" (with leftover data from pem file)\"\n\t\t\t}\n\t\t\tif selector == adns.TLSASelectorCert {\n\t\t\t\tlog.Fatalf(\"no certificate found in pem file%s\", extra)\n\t\t\t} else {\n\t\t\t\tlog.Fatalf(\"no certificate or public or private key found in pem file%s\", extra)\n\t\t\t}\n\t\t}\n\t\tvar cert *x509.Certificate\n\t\tvar data []byte\n\t\tif block.Type == \"CERTIFICATE\" {\n\t\t\tcert, err = x509.ParseCertificate(block.Bytes)\n\t\t\txcheckf(err, \"parse certificate\")\n\t\t\tswitch selector {\n\t\t\tcase adns.TLSASelectorCert:\n\t\t\t\tdata = cert.Raw\n\t\t\tcase adns.TLSASelectorSPKI:\n\t\t\t\tdata = cert.RawSubjectPublicKeyInfo\n\t\t\t}\n\t\t} else if selector == adns.TLSASelectorCert {\n\t\t\t// We need a certificate, just a public/private key won't do.\n\t\t\tlog.Printf(\"skipping pem type %q, certificate is required\", block.Type)\n\t\t\tcontinue\n\t\t} else {\n\t\t\tvar privKey, pubKey any\n\t\t\tvar err error\n\t\t\tswitch block.Type {\n\t\t\tcase \"PUBLIC KEY\":\n\t\t\t\t_, err := x509.ParsePKIXPublicKey(block.Bytes)\n\t\t\t\txcheckf(err, \"parse pkix subject public key info (spki)\")\n\t\t\t\tdata = block.Bytes\n\t\t\tcase \"EC PRIVATE KEY\":\n\t\t\t\tprivKey, err = x509.ParseECPrivateKey(block.Bytes)\n\t\t\t\txcheckf(err, \"parse ec private key\")\n\t\t\tcase \"RSA PRIVATE KEY\":\n\t\t\t\tprivKey, err = x509.ParsePKCS1PrivateKey(block.Bytes)\n\t\t\t\txcheckf(err, \"parse pkcs#1 rsa private key\")\n\t\t\tcase \"RSA PUBLIC KEY\":\n\t\t\t\tpubKey, err = x509.ParsePKCS1PublicKey(block.Bytes)\n\t\t\t\txcheckf(err, \"parse pkcs#1 rsa public key\")\n\t\t\tcase \"PRIVATE KEY\":\n\t\t\t\t// PKCS#8 private key\n\t\t\t\tprivKey, err = x509.ParsePKCS8PrivateKey(block.Bytes)\n\t\t\t\txcheckf(err, \"parse pkcs#8 private key\")\n\t\t\tdefault:\n\t\t\t\tlog.Printf(\"skipping unrecognized pem type %q\", block.Type)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif data == nil {\n\t\t\t\tif pubKey == nil && privKey != nil {\n\t\t\t\t\tif signer, ok := privKey.(crypto.Signer); !ok {\n\t\t\t\t\t\tlog.Fatalf(\"private key of type %T is not a signer, cannot get public key\", privKey)\n\t\t\t\t\t} else {\n\t\t\t\t\t\tpubKey = signer.Public()\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif pubKey == nil {\n\t\t\t\t\t// Should not happen.\n\t\t\t\t\tlog.Fatalf(\"internal error: did not find private or public key\")\n\t\t\t\t}\n\t\t\t\tdata, err = x509.MarshalPKIXPublicKey(pubKey)\n\t\t\t\txcheckf(err, \"marshal pkix subject public key info (spki)\")\n\t\t\t}\n\t\t}\n\n\t\tswitch matchType {\n\t\tcase adns.TLSAMatchTypeFull:\n\t\tcase adns.TLSAMatchTypeSHA256:\n\t\t\tp := sha256.Sum256(data)\n\t\t\tdata = p[:]\n\t\tcase adns.TLSAMatchTypeSHA512:\n\t\t\tp := sha512.Sum512(data)\n\t\t\tdata = p[:]\n\t\t}\n\t\tfmt.Printf(\"%d %d %d %x\\n\", usage, selector, matchType, data)\n\t\tbreak\n\t}\n}\n\nfunc cmdDNSLookup(c *cmd) {\n\tc.params = \"[ptr | mx | cname | ips | a | aaaa | ns | txt | srv | tlsa] name\"\n\tc.help = `Lookup DNS name of given type.\n\nLookup always prints whether the response was DNSSEC-protected.\n\nExamples:\n\nmox dns lookup ptr 1.1.1.1\nmox dns lookup mx xmox.nl\nmox dns lookup txt _dmarc.xmox.nl.\nmox dns lookup tlsa _25._tcp.xmox.nl\n`\n\targs := c.Parse()\n\n\tif len(args) != 2 {\n\t\tc.Usage()\n\t}\n\n\tresolver := dns.StrictResolver{Pkg: \"dns\"}\n\n\t// like xparseDomain, but treat unparseable domain as an ASCII name so names with\n\t// underscores are still looked up, e,g <selector>._domainkey.<host>.\n\txdomain := func(s string) dns.Domain {\n\t\td, err := dns.ParseDomain(s)\n\t\tif err != nil {\n\t\t\treturn dns.Domain{ASCII: strings.TrimSuffix(s, \".\")}\n\t\t}\n\t\treturn d\n\t}\n\n\tcmd, name := args[0], args[1]\n\n\tswitch cmd {\n\tcase \"ptr\":\n\t\tip := xparseIP(name, \"ip\")\n\t\tptrs, result, err := resolver.LookupAddr(context.Background(), ip.String())\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"dns lookup: %v (%s)\", err, dnssecStatus(result.Authentic))\n\t\t}\n\t\tfmt.Printf(\"names (%d, %s):\\n\", len(ptrs), dnssecStatus(result.Authentic))\n\t\tfor _, ptr := range ptrs {\n\t\t\tfmt.Printf(\"- %s\\n\", ptr)\n\t\t}\n\n\tcase \"mx\":\n\t\tname := xdomain(name)\n\t\tmxl, result, err := resolver.LookupMX(context.Background(), name.ASCII+\".\")\n\t\tif err != nil {\n\t\t\tlog.Printf(\"dns lookup: %v (%s)\", err, dnssecStatus(result.Authentic))\n\t\t\t// We can still have valid records...\n\t\t}\n\t\tfmt.Printf(\"mx records (%d, %s):\\n\", len(mxl), dnssecStatus(result.Authentic))\n\t\tfor _, mx := range mxl {\n\t\t\tfmt.Printf(\"- %s, preference %d\\n\", mx.Host, mx.Pref)\n\t\t}\n\n\tcase \"cname\":\n\t\tname := xdomain(name)\n\t\ttarget, result, err := resolver.LookupCNAME(context.Background(), name.ASCII+\".\")\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"dns lookup: %v (%s)\", err, dnssecStatus(result.Authentic))\n\t\t}\n\t\tfmt.Printf(\"%s (%s)\\n\", target, dnssecStatus(result.Authentic))\n\n\tcase \"ips\", \"a\", \"aaaa\":\n\t\tnetwork := \"ip\"\n\t\tif cmd == \"a\" {\n\t\t\tnetwork = \"ip4\"\n\t\t} else if cmd == \"aaaa\" {\n\t\t\tnetwork = \"ip6\"\n\t\t}\n\t\tname := xdomain(name)\n\t\tips, result, err := resolver.LookupIP(context.Background(), network, name.ASCII+\".\")\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"dns lookup: %v (%s)\", err, dnssecStatus(result.Authentic))\n\t\t}\n\t\tfmt.Printf(\"records (%d, %s):\\n\", len(ips), dnssecStatus(result.Authentic))\n\t\tfor _, ip := range ips {\n\t\t\tfmt.Printf(\"- %s\\n\", ip)\n\t\t}\n\n\tcase \"ns\":\n\t\tname := xdomain(name)\n\t\tnsl, result, err := resolver.LookupNS(context.Background(), name.ASCII+\".\")\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"dns lookup: %v (%s)\", err, dnssecStatus(result.Authentic))\n\t\t}\n\t\tfmt.Printf(\"ns records (%d, %s):\\n\", len(nsl), dnssecStatus(result.Authentic))\n\t\tfor _, ns := range nsl {\n\t\t\tfmt.Printf(\"- %s\\n\", ns)\n\t\t}\n\n\tcase \"txt\":\n\t\thost := xdomain(name)\n\t\tl, result, err := resolver.LookupTXT(context.Background(), host.ASCII+\".\")\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"dns lookup: %v (%s)\", err, dnssecStatus(result.Authentic))\n\t\t}\n\t\tfmt.Printf(\"txt records (%d, %s):\\n\", len(l), dnssecStatus(result.Authentic))\n\t\tfor _, txt := range l {\n\t\t\tfmt.Printf(\"- %s\\n\", txt)\n\t\t}\n\n\tcase \"srv\":\n\t\thost := xdomain(name)\n\t\t_, l, result, err := resolver.LookupSRV(context.Background(), \"\", \"\", host.ASCII+\".\")\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"dns lookup: %v (%s)\", err, dnssecStatus(result.Authentic))\n\t\t}\n\t\tfmt.Printf(\"srv records (%d, %s):\\n\", len(l), dnssecStatus(result.Authentic))\n\t\tfor _, srv := range l {\n\t\t\tfmt.Printf(\"- host %s, port %d, priority %d, weight %d\\n\", srv.Target, srv.Port, srv.Priority, srv.Weight)\n\t\t}\n\n\tcase \"tlsa\":\n\t\thost := xdomain(name)\n\t\tl, result, err := resolver.LookupTLSA(context.Background(), 0, \"\", host.ASCII+\".\")\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"dns lookup: %v (%s)\", err, dnssecStatus(result.Authentic))\n\t\t}\n\t\tfmt.Printf(\"tlsa records (%d, %s):\\n\", len(l), dnssecStatus(result.Authentic))\n\t\tfor _, tlsa := range l {\n\t\t\tfmt.Printf(\"- usage %q (%d), selector %q (%d), matchtype %q (%d), certificate association data %x\\n\", tlsa.Usage, tlsa.Usage, tlsa.Selector, tlsa.Selector, tlsa.MatchType, tlsa.MatchType, tlsa.CertAssoc)\n\t\t}\n\tdefault:\n\t\tlog.Fatalf(\"unknown record type %q\", args[0])\n\t}\n}\n\nfunc cmdDKIMGened25519(c *cmd) {\n\tc.params = \">$selector._domainkey.$domain.ed25519.privatekey.pkcs8.pem\"\n\tc.help = `Generate a new ed25519 key for use with DKIM.\n\nEd25519 keys are much smaller than RSA keys of comparable cryptographic\nstrength. This is convenient because of maximum DNS message sizes. At the time\nof writing, not many mail servers appear to support ed25519 DKIM keys though,\nso it is recommended to sign messages with both RSA and ed25519 keys.\n`\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\n\tbuf, err := admin.MakeDKIMEd25519Key(dns.Domain{}, dns.Domain{})\n\txcheckf(err, \"making dkim ed25519 key\")\n\t_, err = os.Stdout.Write(buf)\n\txcheckf(err, \"writing dkim ed25519 key\")\n}\n\nfunc cmdDKIMTXT(c *cmd) {\n\tc.params = \"<$selector._domainkey.$domain.key.pkcs8.pem\"\n\tc.help = `Print a DKIM DNS TXT record with the public key derived from the private key read from stdin.\n\nThe DNS should be configured as a TXT record at $selector._domainkey.$domain.\n`\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\n\tprivKey, err := parseDKIMKey(os.Stdin)\n\txcheckf(err, \"reading dkim private key from stdin\")\n\n\tr := dkim.Record{\n\t\tVersion: \"DKIM1\",\n\t\tHashes:  []string{\"sha256\"},\n\t\tFlags:   []string{\"s\"},\n\t}\n\n\tswitch key := privKey.(type) {\n\tcase *rsa.PrivateKey:\n\t\tr.PublicKey = key.Public()\n\tcase ed25519.PrivateKey:\n\t\tr.PublicKey = key.Public()\n\t\tr.Key = \"ed25519\"\n\tdefault:\n\t\tlog.Fatalf(\"unsupported private key type %T, must be rsa or ed25519\", privKey)\n\t}\n\n\trecord, err := r.Record()\n\txcheckf(err, \"making record\")\n\tfmt.Print(\"<selector>._domainkey.<your.domain.> TXT \")\n\tfor record != \"\" {\n\t\ts := record\n\t\tif len(s) > 100 {\n\t\t\ts, record = record[:100], record[100:]\n\t\t} else {\n\t\t\trecord = \"\"\n\t\t}\n\t\tfmt.Printf(`\"%s\" `, s)\n\t}\n\tfmt.Println(\"\")\n}\n\nfunc parseDKIMKey(r io.Reader) (any, error) {\n\tbuf, err := io.ReadAll(r)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"reading pem from stdin: %v\", err)\n\t}\n\tb, _ := pem.Decode(buf)\n\tif b == nil {\n\t\treturn nil, fmt.Errorf(\"decoding pem: %v\", err)\n\t}\n\tprivKey, err := x509.ParsePKCS8PrivateKey(b.Bytes)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"parsing private key: %v\", err)\n\t}\n\treturn privKey, nil\n}\n\nfunc cmdDKIMVerify(c *cmd) {\n\tc.params = \"message\"\n\tc.help = `Verify the DKIM signatures in a message and print the results.\n\nThe message is parsed, and the DKIM-Signature headers are validated. Validation\nof older messages may fail because the DNS records have been removed or changed\nby now, or because the signature header may have specified an expiration time\nthat was passed.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tmsgf, err := os.Open(args[0])\n\txcheckf(err, \"open message\")\n\n\tresults, err := dkim.Verify(context.Background(), c.log.Logger, dns.StrictResolver{}, false, dkim.DefaultPolicy, msgf, true)\n\txcheckf(err, \"dkim verify\")\n\n\tfor _, result := range results {\n\t\tvar sigh string\n\t\tif result.Sig == nil {\n\t\t\tlog.Printf(\"warning: could not parse signature\")\n\t\t} else {\n\t\t\tsigh, err = result.Sig.Header()\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"warning: packing signature: %s\", err)\n\t\t\t}\n\t\t}\n\t\tvar txt string\n\t\tif result.Record == nil {\n\t\t\tlog.Printf(\"warning: missing DNS record\")\n\t\t} else {\n\t\t\ttxt, err = result.Record.Record()\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"warning: packing record: %s\", err)\n\t\t\t}\n\t\t}\n\t\tfmt.Printf(\"status %q, err %v\\nrecord %q\\nheader %s\\n\", result.Status, result.Err, txt, sigh)\n\t}\n}\n\nfunc cmdDKIMSign(c *cmd) {\n\tc.params = \"message\"\n\tc.help = `Sign a message, adding DKIM-Signature headers based on the domain in the From header.\n\nThe message is parsed, the domain looked up in the configuration files, and\nDKIM-Signature headers generated. The message is printed with the DKIM-Signature\nheaders prepended.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tmsgf, err := os.Open(args[0])\n\txcheckf(err, \"open message\")\n\tdefer msgf.Close()\n\n\tp, err := message.Parse(c.log.Logger, true, msgf)\n\txcheckf(err, \"parsing message\")\n\n\tif len(p.Envelope.From) != 1 {\n\t\tlog.Fatalf(\"found %d from headers, need exactly 1\", len(p.Envelope.From))\n\t}\n\tlocalpart, err := smtp.ParseLocalpart(p.Envelope.From[0].User)\n\txcheckf(err, \"parsing localpart of address in from-header\")\n\tdom, err := dns.ParseDomain(p.Envelope.From[0].Host)\n\txcheckf(err, \"parsing domain of address in from-header\")\n\n\tmustLoadConfig()\n\n\tdomConf, ok := mox.Conf.Domain(dom)\n\tif !ok {\n\t\tlog.Fatalf(\"domain %s not configured\", dom)\n\t}\n\n\tselectors := mox.DKIMSelectors(domConf.DKIM)\n\theaders, err := dkim.Sign(context.Background(), c.log.Logger, localpart, dom, selectors, false, msgf)\n\txcheckf(err, \"signing message with dkim\")\n\tif headers == \"\" {\n\t\tlog.Fatalf(\"no DKIM configured for domain %s\", dom)\n\t}\n\t_, err = fmt.Fprint(os.Stdout, headers)\n\txcheckf(err, \"write headers\")\n\t_, err = io.Copy(os.Stdout, msgf)\n\txcheckf(err, \"write message\")\n}\n\nfunc cmdDKIMLookup(c *cmd) {\n\tc.params = \"selector domain\"\n\tc.help = \"Lookup and print the DKIM record for the selector at the domain.\"\n\targs := c.Parse()\n\tif len(args) != 2 {\n\t\tc.Usage()\n\t}\n\n\tselector := xparseDomain(args[0], \"selector\")\n\tdomain := xparseDomain(args[1], \"domain\")\n\n\tstatus, record, txt, authentic, err := dkim.Lookup(context.Background(), c.log.Logger, dns.StrictResolver{}, selector, domain)\n\tif err != nil {\n\t\tfmt.Printf(\"error: %s\\n\", err)\n\t}\n\tif status != dkim.StatusNeutral {\n\t\tfmt.Printf(\"status: %s\\n\", status)\n\t}\n\tif txt != \"\" {\n\t\tfmt.Printf(\"TXT record: %s\\n\", txt)\n\t}\n\tif authentic {\n\t\tfmt.Println(\"dnssec-signed: yes\")\n\t} else {\n\t\tfmt.Println(\"dnssec-signed: no\")\n\t}\n\tif record != nil {\n\t\tfmt.Printf(\"Record:\\n\")\n\t\tpairs := []any{\n\t\t\t\"version\", record.Version,\n\t\t\t\"hashes\", record.Hashes,\n\t\t\t\"key\", record.Key,\n\t\t\t\"notes\", record.Notes,\n\t\t\t\"services\", record.Services,\n\t\t\t\"flags\", record.Flags,\n\t\t}\n\t\tfor i := 0; i < len(pairs); i += 2 {\n\t\t\tfmt.Printf(\"\\t%s: %v\\n\", pairs[i], pairs[i+1])\n\t\t}\n\t}\n}\n\nfunc cmdDMARCLookup(c *cmd) {\n\tc.params = \"domain\"\n\tc.help = \"Lookup dmarc policy for domain, a DNS TXT record at _dmarc.<domain>, validate and print it.\"\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tfromdomain := xparseDomain(args[0], \"domain\")\n\t_, domain, _, txt, authentic, err := dmarc.Lookup(context.Background(), c.log.Logger, dns.StrictResolver{}, fromdomain)\n\txcheckf(err, \"dmarc lookup domain %s\", fromdomain)\n\tfmt.Printf(\"dmarc record at domain %s: %s\\n\", domain, txt)\n\tfmt.Printf(\"(%s)\\n\", dnssecStatus(authentic))\n}\n\nfunc dnssecStatus(v bool) string {\n\tif v {\n\t\treturn \"with dnssec\"\n\t}\n\treturn \"without dnssec\"\n}\n\nfunc cmdDMARCVerify(c *cmd) {\n\tc.params = \"remoteip mailfromaddress helodomain < message\"\n\tc.help = `Parse an email message and evaluate it against the DMARC policy of the domain in the From-header.\n\nmailfromaddress and helodomain are used for SPF validation. If both are empty,\nSPF validation is skipped.\n\nmailfromaddress should be the address used as MAIL FROM in the SMTP session.\nFor DSN messages, that address may be empty. The helo domain was specified at\nthe beginning of the SMTP transaction that delivered the message. These values\ncan be found in message headers.\n`\n\targs := c.Parse()\n\tif len(args) != 3 {\n\t\tc.Usage()\n\t}\n\n\tvar heloDomain *dns.Domain\n\n\tremoteIP := xparseIP(args[0], \"remoteip\")\n\n\tvar mailfrom *smtp.Address\n\tif args[1] != \"\" {\n\t\ta, err := smtp.ParseAddress(args[1])\n\t\txcheckf(err, \"parsing mailfrom address\")\n\t\tmailfrom = &a\n\t}\n\tif args[2] != \"\" {\n\t\td := xparseDomain(args[2], \"helo domain\")\n\t\theloDomain = &d\n\t}\n\tvar received *spf.Received\n\tspfStatus := spf.StatusNone\n\tvar spfIdentity *dns.Domain\n\tif mailfrom != nil || heloDomain != nil {\n\t\tspfArgs := spf.Args{\n\t\t\tRemoteIP:      remoteIP,\n\t\t\tLocalIP:       net.ParseIP(\"127.0.0.1\"),\n\t\t\tLocalHostname: dns.Domain{ASCII: \"localhost\"},\n\t\t}\n\t\tif mailfrom != nil {\n\t\t\tspfArgs.MailFromLocalpart = mailfrom.Localpart\n\t\t\tspfArgs.MailFromDomain = mailfrom.Domain\n\t\t}\n\t\tif heloDomain != nil {\n\t\t\tspfArgs.HelloDomain = dns.IPDomain{Domain: *heloDomain}\n\t\t}\n\t\trspf, spfDomain, expl, authentic, err := spf.Verify(context.Background(), c.log.Logger, dns.StrictResolver{}, spfArgs)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"spf verify: %v (explanation: %q, authentic %v)\", err, expl, authentic)\n\t\t} else {\n\t\t\treceived = &rspf\n\t\t\tspfStatus = received.Result\n\t\t\t// todo: should probably potentially do two separate spf validations\n\t\t\tif mailfrom != nil {\n\t\t\t\tspfIdentity = &mailfrom.Domain\n\t\t\t} else {\n\t\t\t\tspfIdentity = heloDomain\n\t\t\t}\n\t\t\tfmt.Printf(\"spf result: %s: %s (%s)\\n\", spfDomain, spfStatus, dnssecStatus(authentic))\n\t\t}\n\t}\n\n\tdata, err := io.ReadAll(os.Stdin)\n\txcheckf(err, \"read message\")\n\tdmarcFrom, _, _, err := message.From(c.log.Logger, false, bytes.NewReader(data), nil)\n\txcheckf(err, \"extract dmarc from message\")\n\n\tconst ignoreTestMode = false\n\tdkimResults, err := dkim.Verify(context.Background(), c.log.Logger, dns.StrictResolver{}, true, func(*dkim.Sig) error { return nil }, bytes.NewReader(data), ignoreTestMode)\n\txcheckf(err, \"dkim verify\")\n\tfor _, r := range dkimResults {\n\t\tfmt.Printf(\"dkim result: %q (err %v)\\n\", r.Status, r.Err)\n\t}\n\n\t_, result := dmarc.Verify(context.Background(), c.log.Logger, dns.StrictResolver{}, dmarcFrom.Domain, dkimResults, spfStatus, spfIdentity, false)\n\txcheckf(result.Err, \"dmarc verify\")\n\tfmt.Printf(\"dmarc from: %s\\ndmarc status: %q\\ndmarc reject: %v\\ncmarc record: %s\\n\", dmarcFrom, result.Status, result.Reject, result.Record)\n}\n\nfunc cmdDMARCCheckreportaddrs(c *cmd) {\n\tc.params = \"domain\"\n\tc.help = `For each reporting address in the domain's DMARC record, check if it has opted into receiving reports (if needed).\n\nA DMARC record can request reports about DMARC evaluations to be sent to an\nemail/http address. If the organizational domains of that of the DMARC record\nand that of the report destination address do not match, the destination\naddress must opt-in to receiving DMARC reports by creating a DMARC record at\n<dmarcdomain>._report._dmarc.<reportdestdomain>.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tdom := xparseDomain(args[0], \"domain\")\n\t_, domain, record, txt, authentic, err := dmarc.Lookup(context.Background(), c.log.Logger, dns.StrictResolver{}, dom)\n\txcheckf(err, \"dmarc lookup domain %s\", dom)\n\tfmt.Printf(\"dmarc record at domain %s: %q\\n\", domain, txt)\n\tfmt.Printf(\"(%s)\\n\", dnssecStatus(authentic))\n\n\tcheck := func(kind, addr string) {\n\t\tvar authentic bool\n\n\t\tprintResult := func(format string, args ...any) {\n\t\t\tfmt.Printf(\"%s %s: %s (%s)\\n\", kind, addr, fmt.Sprintf(format, args...), dnssecStatus(authentic))\n\t\t}\n\n\t\tu, err := url.Parse(addr)\n\t\tif err != nil {\n\t\t\tprintResult(\"parsing uri: %v (skipping)\", addr, err)\n\t\t\treturn\n\t\t}\n\t\tvar destdom dns.Domain\n\t\tswitch u.Scheme {\n\t\tcase \"mailto\":\n\t\t\ta, err := smtp.ParseAddress(u.Opaque)\n\t\t\tif err != nil {\n\t\t\t\tprintResult(\"parsing destination email address %s: %v (skipping)\", u.Opaque, err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tdestdom = a.Domain\n\t\tdefault:\n\t\t\tprintResult(\"unrecognized scheme in reporting address %s (skipping)\", u.Scheme)\n\t\t\treturn\n\t\t}\n\n\t\tif publicsuffix.Lookup(context.Background(), c.log.Logger, dom) == publicsuffix.Lookup(context.Background(), c.log.Logger, destdom) {\n\t\t\tprintResult(\"pass (same organizational domain)\")\n\t\t\treturn\n\t\t}\n\n\t\taccepts, status, _, txts, authentic, err := dmarc.LookupExternalReportsAccepted(context.Background(), c.log.Logger, dns.StrictResolver{}, domain, destdom)\n\t\tvar txtstr string\n\t\ttxtaddr := fmt.Sprintf(\"%s._report._dmarc.%s\", domain.ASCII, destdom.ASCII)\n\t\tif len(txts) == 0 {\n\t\t\ttxtstr = fmt.Sprintf(\" (no txt records %s)\", txtaddr)\n\t\t} else {\n\t\t\ttxtstr = fmt.Sprintf(\" (txt record %s: %q)\", txtaddr, txts)\n\t\t}\n\t\tif status != dmarc.StatusNone {\n\t\t\tprintResult(\"fail: %s%s\", err, txtstr)\n\t\t} else if accepts {\n\t\t\tprintResult(\"pass%s\", txtstr)\n\t\t} else if err != nil {\n\t\t\tprintResult(\"fail: %s%s\", err, txtstr)\n\t\t} else {\n\t\t\tprintResult(\"fail%s\", txtstr)\n\t\t}\n\t}\n\n\tfor _, uri := range record.AggregateReportAddresses {\n\t\tcheck(\"aggregate reporting\", uri.Address)\n\t}\n\tfor _, uri := range record.FailureReportAddresses {\n\t\tcheck(\"failure reporting\", uri.Address)\n\t}\n}\n\nfunc cmdDMARCParsereportmsg(c *cmd) {\n\tc.params = \"message ...\"\n\tc.help = `Parse a DMARC report from an email message, and print its extracted details.\n\nDMARC reports are periodically mailed, if requested in the DMARC DNS record of\na domain. Reports are sent by mail servers that received messages with our\ndomain in a From header. This may or may not be legatimate email. DMARC reports\ncontain summaries of evaluations of DMARC and DKIM/SPF, which can help\nunderstand email deliverability problems.\n`\n\targs := c.Parse()\n\tif len(args) == 0 {\n\t\tc.Usage()\n\t}\n\n\tfor _, arg := range args {\n\t\tf, err := os.Open(arg)\n\t\txcheckf(err, \"open %q\", arg)\n\t\tfeedback, err := dmarcrpt.ParseMessageReport(c.log.Logger, f)\n\t\txcheckf(err, \"parse report in %q\", arg)\n\t\tmeta := feedback.ReportMetadata\n\t\tfmt.Printf(\"Report: period %s-%s, organisation %q, reportID %q, %s\\n\", time.Unix(meta.DateRange.Begin, 0).UTC().String(), time.Unix(meta.DateRange.End, 0).UTC().String(), meta.OrgName, meta.ReportID, meta.Email)\n\t\tif len(meta.Errors) > 0 {\n\t\t\tfmt.Printf(\"Errors:\\n\")\n\t\t\tfor _, s := range meta.Errors {\n\t\t\t\tfmt.Printf(\"\\t- %s\\n\", s)\n\t\t\t}\n\t\t}\n\t\tpol := feedback.PolicyPublished\n\t\tfmt.Printf(\"Policy: domain %q, policy %q, subdomainpolicy %q, dkim %q, spf %q, percentage %d, options %q\\n\", pol.Domain, pol.Policy, pol.SubdomainPolicy, pol.ADKIM, pol.ASPF, pol.Percentage, pol.ReportingOptions)\n\t\tfor _, record := range feedback.Records {\n\t\t\tidents := record.Identifiers\n\t\t\tfmt.Printf(\"\\theaderfrom %q, envelopes from %q, to %q\\n\", idents.HeaderFrom, idents.EnvelopeFrom, idents.EnvelopeTo)\n\t\t\teval := record.Row.PolicyEvaluated\n\t\t\tvar reasons string\n\t\t\tfor _, reason := range eval.Reasons {\n\t\t\t\treasons += \"; \" + string(reason.Type)\n\t\t\t\tif reason.Comment != \"\" {\n\t\t\t\t\treasons += fmt.Sprintf(\": %q\", reason.Comment)\n\t\t\t\t}\n\t\t\t}\n\t\t\tfmt.Printf(\"\\tresult %s: dkim %s, spf %s; sourceIP %s, count %d%s\\n\", eval.Disposition, eval.DKIM, eval.SPF, record.Row.SourceIP, record.Row.Count, reasons)\n\t\t\tfor _, dkim := range record.AuthResults.DKIM {\n\t\t\t\tvar result string\n\t\t\t\tif dkim.HumanResult != \"\" {\n\t\t\t\t\tresult = fmt.Sprintf(\": %q\", dkim.HumanResult)\n\t\t\t\t}\n\t\t\t\tfmt.Printf(\"\\t\\tdkim %s; domain %q selector %q%s\\n\", dkim.Result, dkim.Domain, dkim.Selector, result)\n\t\t\t}\n\t\t\tfor _, spf := range record.AuthResults.SPF {\n\t\t\t\tfmt.Printf(\"\\t\\tspf %s; domain %q scope %q\\n\", spf.Result, spf.Domain, spf.Scope)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc cmdDMARCDBAddReport(c *cmd) {\n\tc.unlisted = true\n\tc.params = \"fromdomain < message\"\n\tc.help = \"Add a DMARC report to the database.\"\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\n\tfromdomain := xparseDomain(args[0], \"domain\")\n\tfmt.Fprintln(os.Stderr, \"reading report message from stdin\")\n\treport, err := dmarcrpt.ParseMessageReport(c.log.Logger, os.Stdin)\n\txcheckf(err, \"parse message\")\n\terr = dmarcdb.AddReport(context.Background(), report, fromdomain)\n\txcheckf(err, \"add dmarc report\")\n}\n\nfunc cmdTLSRPTLookup(c *cmd) {\n\tc.params = \"domain\"\n\tc.help = `Lookup the TLSRPT record for the domain.\n\nA TLSRPT record typically contains an email address where reports about TLS\nconnectivity should be sent. Mail servers attempting delivery to our domain\nshould attempt to use TLS. TLSRPT lets them report how many connection\nsuccessfully used TLS, and how what kind of errors occurred otherwise.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\td := xparseDomain(args[0], \"domain\")\n\t_, txt, err := tlsrpt.Lookup(context.Background(), c.log.Logger, dns.StrictResolver{}, d)\n\txcheckf(err, \"tlsrpt lookup for %s\", d)\n\tfmt.Println(txt)\n}\n\nfunc cmdTLSRPTParsereportmsg(c *cmd) {\n\tc.params = \"message ...\"\n\tc.help = `Parse and print the TLSRPT in the message.\n\nThe report is printed in formatted JSON.\n`\n\targs := c.Parse()\n\tif len(args) == 0 {\n\t\tc.Usage()\n\t}\n\n\tfor _, arg := range args {\n\t\tf, err := os.Open(arg)\n\t\txcheckf(err, \"open %q\", arg)\n\t\treportJSON, err := tlsrpt.ParseMessage(c.log.Logger, f)\n\t\txcheckf(err, \"parse report in %q\", arg)\n\t\t// todo future: only print the highlights?\n\t\tenc := json.NewEncoder(os.Stdout)\n\t\tenc.SetIndent(\"\", \"\\t\")\n\t\tenc.SetEscapeHTML(false)\n\t\terr = enc.Encode(reportJSON)\n\t\txcheckf(err, \"write report\")\n\t}\n}\n\nfunc cmdSPFCheck(c *cmd) {\n\tc.params = \"domain ip\"\n\tc.help = `Check the status of IP for the policy published in DNS for the domain.\n\nIPs may be allowed to send for a domain, or disallowed, and several shades in\nbetween. If not allowed, an explanation may be provided by the policy. If so,\nthe explanation is printed. The SPF mechanism that matched (if any) is also\nprinted.\n`\n\targs := c.Parse()\n\tif len(args) != 2 {\n\t\tc.Usage()\n\t}\n\n\tdomain := xparseDomain(args[0], \"domain\")\n\n\tip := xparseIP(args[1], \"ip\")\n\n\tspfargs := spf.Args{\n\t\tRemoteIP:          ip,\n\t\tMailFromLocalpart: \"user\",\n\t\tMailFromDomain:    domain,\n\t\tHelloDomain:       dns.IPDomain{Domain: domain},\n\t\tLocalIP:           net.ParseIP(\"127.0.0.1\"),\n\t\tLocalHostname:     dns.Domain{ASCII: \"localhost\"},\n\t}\n\tr, _, explanation, authentic, err := spf.Verify(context.Background(), c.log.Logger, dns.StrictResolver{}, spfargs)\n\tif err != nil {\n\t\tfmt.Printf(\"error: %s\\n\", err)\n\t}\n\tif explanation != \"\" {\n\t\tfmt.Printf(\"explanation: %s\\n\", explanation)\n\t}\n\tfmt.Printf(\"status: %s (%s)\\n\", r.Result, dnssecStatus(authentic))\n\tif r.Mechanism != \"\" {\n\t\tfmt.Printf(\"mechanism: %s\\n\", r.Mechanism)\n\t}\n}\n\nfunc cmdSPFParse(c *cmd) {\n\tc.params = \"txtrecord\"\n\tc.help = \"Parse the record as SPF record. If valid, nothing is printed.\"\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\t_, _, err := spf.ParseRecord(args[0])\n\txcheckf(err, \"parsing record\")\n}\n\nfunc cmdSPFLookup(c *cmd) {\n\tc.params = \"domain\"\n\tc.help = \"Lookup the SPF record for the domain and print it.\"\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tdomain := xparseDomain(args[0], \"domain\")\n\t_, txt, _, authentic, err := spf.Lookup(context.Background(), c.log.Logger, dns.StrictResolver{}, domain)\n\txcheckf(err, \"spf lookup for %s\", domain)\n\tfmt.Println(txt)\n\tfmt.Printf(\"(%s)\\n\", dnssecStatus(authentic))\n}\n\nfunc cmdMTASTSLookup(c *cmd) {\n\tc.params = \"domain\"\n\tc.help = `Lookup the MTASTS record and policy for the domain.\n\nMTA-STS is a mechanism for a domain to specify if it requires TLS connections\nfor delivering email. If a domain has a valid MTA-STS DNS TXT record at\n_mta-sts.<domain> it signals it implements MTA-STS. A policy can then be\nfetched at https://mta-sts.<domain>/.well-known/mta-sts.txt. The policy\nspecifies the mode (enforce, testing, none), which MX servers support TLS and\nshould be used, and how long the policy can be cached.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tdomain := xparseDomain(args[0], \"domain\")\n\n\trecord, policy, _, err := mtasts.Get(context.Background(), c.log.Logger, dns.StrictResolver{}, domain)\n\tif err != nil {\n\t\tfmt.Printf(\"error: %s\\n\", err)\n\t}\n\tif record != nil {\n\t\tfmt.Printf(\"DNS TXT record _mta-sts.%s: %s\\n\", domain.ASCII, record.String())\n\t}\n\tif policy != nil {\n\t\tfmt.Println(\"\")\n\t\tfmt.Printf(\"policy at https://mta-sts.%s/.well-known/mta-sts.txt:\\n\", domain.ASCII)\n\t\tfmt.Printf(\"%s\", policy.String())\n\t}\n}\n\nfunc cmdRetrain(c *cmd) {\n\tc.params = \"[accountname]\"\n\tc.help = `Recreate and retrain the junk filter for the account or all accounts.\n\nUseful after having made changes to the junk filter configuration, or if the\nimplementation has changed.\n`\n\targs := c.Parse()\n\tif len(args) > 1 {\n\t\tc.Usage()\n\t}\n\tvar account string\n\tif len(args) == 1 {\n\t\taccount = args[0]\n\t}\n\n\tmustLoadConfig()\n\tctlcmdRetrain(xctl(), account)\n}\n\nfunc ctlcmdRetrain(ctl *ctl, account string) {\n\tctl.xwrite(\"retrain\")\n\tctl.xwrite(account)\n\tctl.xreadok()\n}\n\nfunc cmdTLSRPTDBAddReport(c *cmd) {\n\tc.unlisted = true\n\tc.params = \"< message\"\n\tc.help = \"Parse a TLS report from the message and add it to the database.\"\n\tvar hostReport bool\n\tc.flag.BoolVar(&hostReport, \"hostreport\", false, \"report for a host instead of domain\")\n\targs := c.Parse()\n\tif len(args) != 0 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\n\t// First read message, to get the From-header. Then parse it as TLSRPT.\n\tfmt.Fprintln(os.Stderr, \"reading report message from stdin\")\n\tbuf, err := io.ReadAll(os.Stdin)\n\txcheckf(err, \"reading message\")\n\tpart, err := message.Parse(c.log.Logger, true, bytes.NewReader(buf))\n\txcheckf(err, \"parsing message\")\n\tif part.Envelope == nil || len(part.Envelope.From) != 1 {\n\t\tlog.Fatalf(\"message must have one From-header\")\n\t}\n\tfrom := part.Envelope.From[0]\n\tdomain := xparseDomain(from.Host, \"domain\")\n\n\treportJSON, err := tlsrpt.ParseMessage(c.log.Logger, bytes.NewReader(buf))\n\txcheckf(err, \"parsing tls report in message\")\n\n\tmailfrom := from.User + \"@\" + from.Host // todo future: should escape and such\n\treport := reportJSON.Convert()\n\terr = tlsrptdb.AddReport(context.Background(), c.log, domain, mailfrom, hostReport, &report)\n\txcheckf(err, \"add tls report to database\")\n}\n\nfunc cmdDNSBLCheck(c *cmd) {\n\tc.params = \"zone ip\"\n\tc.help = `Test if IP is in the DNS blocklist of the zone, e.g. bl.spamcop.net.\n\nIf the IP is in the blocklist, an explanation is printed. This is typically a\nURL with more information.\n`\n\targs := c.Parse()\n\tif len(args) != 2 {\n\t\tc.Usage()\n\t}\n\n\tzone := xparseDomain(args[0], \"zone\")\n\tip := xparseIP(args[1], \"ip\")\n\n\tstatus, explanation, err := dnsbl.Lookup(context.Background(), c.log.Logger, dns.StrictResolver{}, zone, ip)\n\tfmt.Printf(\"status: %s\\n\", status)\n\tif status == dnsbl.StatusFail {\n\t\tfmt.Printf(\"explanation: %q\\n\", explanation)\n\t}\n\tif err != nil {\n\t\tfmt.Printf(\"error: %s\\n\", err)\n\t}\n}\n\nfunc cmdDNSBLCheckhealth(c *cmd) {\n\tc.params = \"zone\"\n\tc.help = `Check the health of the DNS blocklist represented by zone, e.g. bl.spamcop.net.\n\nThe health of a DNS blocklist can be checked by querying for 127.0.0.1 and\n127.0.0.2. The second must and the first must not be present.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tzone := xparseDomain(args[0], \"zone\")\n\terr := dnsbl.CheckHealth(context.Background(), c.log.Logger, dns.StrictResolver{}, zone)\n\txcheckf(err, \"unhealthy\")\n\tfmt.Println(\"healthy\")\n}\n\nfunc cmdCheckupdate(c *cmd) {\n\tc.help = `Check if a newer version of mox is available.\n\nA single DNS TXT lookup to _updates.xmox.nl tells if a new version is\navailable. If so, a changelog is fetched from https://updates.xmox.nl, and the\nindividual entries verified with a builtin public key. The changelog is\nprinted.\n`\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\n\tcurrent, lastknown, _, err := store.LastKnown()\n\tif err != nil {\n\t\tlog.Printf(\"getting last known version: %s\", err)\n\t} else {\n\t\tfmt.Printf(\"last known version: %s\\n\", lastknown)\n\t\tfmt.Printf(\"current version: %s\\n\", current)\n\t}\n\tlatest, _, err := updates.Lookup(context.Background(), c.log.Logger, dns.StrictResolver{}, dns.Domain{ASCII: changelogDomain})\n\txcheckf(err, \"lookup of latest version\")\n\tfmt.Printf(\"latest version: %s\\n\", latest)\n\n\tif latest.After(current) {\n\t\tchangelog, err := updates.FetchChangelog(context.Background(), c.log.Logger, changelogURL, current, changelogPubKey)\n\t\txcheckf(err, \"fetching changelog\")\n\t\tif len(changelog.Changes) == 0 {\n\t\t\tlog.Printf(\"no changes in changelog\")\n\t\t\treturn\n\t\t}\n\t\tfmt.Println(\"Changelog\")\n\t\tfor _, c := range changelog.Changes {\n\t\t\tfmt.Println(\"\\n\" + strings.TrimSpace(c.Text))\n\t\t}\n\t}\n}\n\nfunc cmdCid(c *cmd) {\n\tc.params = \"cid\"\n\tc.help = `Turn an ID from a Received header into a cid, for looking up in logs.\n\nA cid is essentially a connection counter initialized when mox starts. Each log\nline contains a cid. Received headers added by mox contain a unique ID that can\nbe decrypted to a cid by admin of a mox instance only.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\trecvidpath := mox.DataDirPath(\"receivedid.key\")\n\trecvidbuf, err := os.ReadFile(recvidpath)\n\txcheckf(err, \"reading %s\", recvidpath)\n\tif len(recvidbuf) != 16+8 {\n\t\tlog.Fatalf(\"bad data in %s: got %d bytes, expect 16+8=24\", recvidpath, len(recvidbuf))\n\t}\n\terr = mox.ReceivedIDInit(recvidbuf[:16], recvidbuf[16:])\n\txcheckf(err, \"init receivedid\")\n\n\tcid, err := mox.ReceivedToCid(args[0])\n\txcheckf(err, \"received id to cid\")\n\tfmt.Printf(\"%x\\n\", cid)\n}\n\nfunc cmdVersion(c *cmd) {\n\tc.help = \"Prints this mox version.\"\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\tfmt.Println(moxvar.Version)\n\tfmt.Printf(\"%s/%s\\n\", runtime.GOOS, runtime.GOARCH)\n}\n\nfunc cmdWebapi(c *cmd) {\n\tc.params = \"[method [baseurl-with-credentials]\"\n\tc.help = \"Lists available methods, prints request/response parameters for method, or calls a method with a request read from standard input.\"\n\targs := c.Parse()\n\tif len(args) > 2 {\n\t\tc.Usage()\n\t}\n\n\tt := reflect.TypeFor[webapi.Methods]()\n\tmethods := map[string]reflect.Type{}\n\tvar ml []string\n\tfor i := 0; i < t.NumMethod(); i++ {\n\t\tmt := t.Method(i)\n\t\tmethods[mt.Name] = mt.Type\n\t\tml = append(ml, mt.Name)\n\t}\n\n\tif len(args) == 0 {\n\t\tfmt.Println(strings.Join(ml, \"\\n\"))\n\t\treturn\n\t}\n\n\tmt, ok := methods[args[0]]\n\tif !ok {\n\t\tlog.Fatalf(\"unknown method %q\", args[0])\n\t}\n\tresultNotJSON := mt.Out(0).Kind() == reflect.Interface\n\n\tif len(args) == 1 {\n\t\tfmt.Println(\"# Example request\")\n\t\tfmt.Println()\n\t\tprintJSON(\"\\t\", mox.FillExample(nil, reflect.New(mt.In(1))).Interface())\n\t\tfmt.Println()\n\t\tif resultNotJSON {\n\t\t\tfmt.Println(\"Output is non-JSON data.\")\n\t\t\treturn\n\t\t}\n\t\tfmt.Println(\"# Example response\")\n\t\tfmt.Println()\n\t\tprintJSON(\"\\t\", mox.FillExample(nil, reflect.New(mt.Out(0))).Interface())\n\t\treturn\n\t}\n\n\tvar response any\n\tif !resultNotJSON {\n\t\tresponse = reflect.New(mt.Out(0))\n\t}\n\n\tfmt.Fprintln(os.Stderr, \"reading request from stdin...\")\n\trequest, err := io.ReadAll(os.Stdin)\n\txcheckf(err, \"read message\")\n\n\tdec := json.NewDecoder(bytes.NewReader(request))\n\tdec.DisallowUnknownFields()\n\terr = dec.Decode(reflect.New(mt.In(1)).Interface())\n\txcheckf(err, \"parsing request\")\n\n\tresp, err := http.PostForm(args[1]+args[0], url.Values{\"request\": []string{string(request)}})\n\txcheckf(err, \"http post\")\n\tdefer resp.Body.Close()\n\tif resp.StatusCode == http.StatusBadRequest {\n\t\tbuf, err := io.ReadAll(&moxio.LimitReader{R: resp.Body, Limit: 10 * 1024})\n\t\txcheckf(err, \"reading response for 400 bad request error\")\n\t\terr = json.Unmarshal(buf, &response)\n\t\tif err == nil {\n\t\t\tprintJSON(\"\", response)\n\t\t} else {\n\t\t\tfmt.Fprintf(os.Stderr, \"(not json)\\n\")\n\t\t\tos.Stderr.Write(buf)\n\t\t}\n\t\tos.Exit(1)\n\t} else if resp.StatusCode != http.StatusOK {\n\t\tfmt.Fprintf(os.Stderr, \"http response %s\\n\", resp.Status)\n\t\t_, err := io.Copy(os.Stderr, resp.Body)\n\t\txcheckf(err, \"copy body\")\n\t} else {\n\t\terr := json.NewDecoder(resp.Body).Decode(&resp)\n\t\txcheckf(err, \"unmarshal response\")\n\t\tprintJSON(\"\", response)\n\t}\n}\n\nfunc printJSON(indent string, v any) {\n\tfmt.Printf(\"%s\", indent)\n\tenc := json.NewEncoder(os.Stdout)\n\tenc.SetIndent(indent, \"\\t\")\n\tenc.SetEscapeHTML(false)\n\terr := enc.Encode(v)\n\txcheckf(err, \"encode json\")\n}\n\n// todo: should make it possible to run this command against a running mox. it should disconnect existing clients for accounts with a bumped uidvalidity, so they will reconnect and refetch the data.\nfunc cmdBumpUIDValidity(c *cmd) {\n\tc.params = \"account [mailbox]\"\n\tc.help = `Change the IMAP UID validity of the mailbox, causing IMAP clients to refetch messages.\n\nThis can be useful after manually repairing metadata about the account/mailbox.\n\nOpens account database file directly. Ensure mox does not have the account\nopen, or is not running.\n`\n\targs := c.Parse()\n\tif len(args) != 1 && len(args) != 2 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\ta, err := store.OpenAccount(c.log, args[0])\n\txcheckf(err, \"open account\")\n\tdefer func() {\n\t\tif err := a.Close(); err != nil {\n\t\t\tlog.Printf(\"closing account: %v\", err)\n\t\t}\n\t}()\n\n\terr = a.DB.Write(context.Background(), func(tx *bstore.Tx) error {\n\t\tuidvalidity, err := a.NextUIDValidity(tx)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"assigning next uid validity: %v\", err)\n\t\t}\n\n\t\tq := bstore.QueryTx[store.Mailbox](tx)\n\t\tif len(args) == 2 {\n\t\t\tq.FilterEqual(\"Name\", args[1])\n\t\t}\n\t\tmbl, err := q.SortAsc(\"Name\").List()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"looking up mailbox: %v\", err)\n\t\t}\n\t\tif len(args) == 2 && len(mbl) != 1 {\n\t\t\treturn fmt.Errorf(\"looking up mailbox %q, found %d mailboxes\", args[1], len(mbl))\n\t\t}\n\t\tfor _, mb := range mbl {\n\t\t\tmb.UIDValidity = uidvalidity\n\t\t\terr = tx.Update(&mb)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"updating uid validity for mailbox: %v\", err)\n\t\t\t}\n\t\t\tfmt.Printf(\"uid validity for %q updated to %d\\n\", mb.Name, uidvalidity)\n\t\t}\n\t\treturn nil\n\t})\n\txcheckf(err, \"updating database\")\n}\n\nfunc cmdReassignUIDs(c *cmd) {\n\tc.params = \"account [mailboxid]\"\n\tc.help = `Reassign UIDs in one mailbox or all mailboxes in an account and bump UID validity, causing IMAP clients to refetch messages.\n\nOpens account database file directly. Ensure mox does not have the account\nopen, or is not running.\n`\n\targs := c.Parse()\n\tif len(args) != 1 && len(args) != 2 {\n\t\tc.Usage()\n\t}\n\n\tvar mailboxID int64\n\tif len(args) == 2 {\n\t\tvar err error\n\t\tmailboxID, err = strconv.ParseInt(args[1], 10, 64)\n\t\txcheckf(err, \"parsing mailbox id\")\n\t}\n\n\tmustLoadConfig()\n\ta, err := store.OpenAccount(c.log, args[0])\n\txcheckf(err, \"open account\")\n\tdefer func() {\n\t\tif err := a.Close(); err != nil {\n\t\t\tlog.Printf(\"closing account: %v\", err)\n\t\t}\n\t}()\n\n\t// Gather the last-assigned UIDs per mailbox.\n\tuidlasts := map[int64]store.UID{}\n\n\terr = a.DB.Write(context.Background(), func(tx *bstore.Tx) error {\n\t\t// Reassign UIDs, going per mailbox. We assign starting at 1, only changing the\n\t\t// message if it isn't already at the intended UID. Doing it in this order ensures\n\t\t// we don't get into trouble with duplicate UIDs for a mailbox. We assign a new\n\t\t// modseq. Not strictly needed, for doesn't hurt.\n\t\tmodseq, err := a.NextModSeq(tx)\n\t\txcheckf(err, \"assigning next modseq\")\n\n\t\tq := bstore.QueryTx[store.Message](tx)\n\t\tif len(args) == 2 {\n\t\t\tq.FilterNonzero(store.Message{MailboxID: mailboxID})\n\t\t}\n\t\tq.SortAsc(\"MailboxID\", \"UID\")\n\t\terr = q.ForEach(func(m store.Message) error {\n\t\t\tuidlasts[m.MailboxID]++\n\t\t\tuid := uidlasts[m.MailboxID]\n\t\t\tif m.UID != uid {\n\t\t\t\tm.UID = uid\n\t\t\t\tm.ModSeq = modseq\n\t\t\t\tif err := tx.Update(&m); err != nil {\n\t\t\t\t\treturn fmt.Errorf(\"updating uid for message: %v\", err)\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"reading through messages: %v\", err)\n\t\t}\n\n\t\t// Now update the uidnext and uidvalidity for each mailbox.\n\t\terr = bstore.QueryTx[store.Mailbox](tx).ForEach(func(mb store.Mailbox) error {\n\t\t\t// Assign each mailbox a completely new uidvalidity.\n\t\t\tuidvalidity, err := a.NextUIDValidity(tx)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"assigning next uid validity: %v\", err)\n\t\t\t}\n\n\t\t\tif mb.UIDValidity >= uidvalidity {\n\t\t\t\t// This should not happen, but since we're fixing things up after a hypothetical\n\t\t\t\t// mishap, might as well account for inconsistent uidvalidity.\n\t\t\t\tnext := store.NextUIDValidity{ID: 1, Next: mb.UIDValidity + 2}\n\t\t\t\tif err := tx.Update(&next); err != nil {\n\t\t\t\t\tlog.Printf(\"updating nextuidvalidity: %v, continuing\", err)\n\t\t\t\t}\n\t\t\t\tmb.UIDValidity++\n\t\t\t} else {\n\t\t\t\tmb.UIDValidity = uidvalidity\n\t\t\t}\n\t\t\tmb.UIDNext = uidlasts[mb.ID] + 1\n\t\t\tif err := tx.Update(&mb); err != nil {\n\t\t\t\treturn fmt.Errorf(\"updating uidvalidity and uidnext for mailbox: %v\", err)\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"updating mailboxes: %v\", err)\n\t\t}\n\t\treturn nil\n\t})\n\txcheckf(err, \"updating database\")\n}\n\nfunc cmdFixUIDMeta(c *cmd) {\n\tc.params = \"account\"\n\tc.help = `Fix inconsistent UIDVALIDITY and UIDNEXT in messages/mailboxes/account.\n\nThe next UID to use for a message in a mailbox should always be higher than any\nexisting message UID in the mailbox. If it is not, the mailbox UIDNEXT is\nupdated.\n\nEach mailbox has a UIDVALIDITY sequence number, which should always be lower\nthan the per-account next UIDVALIDITY to use. If it is not, the account next\nUIDVALIDITY is updated.\n\nOpens account database file directly. Ensure mox does not have the account\nopen, or is not running.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\ta, err := store.OpenAccount(c.log, args[0])\n\txcheckf(err, \"open account\")\n\tdefer func() {\n\t\tif err := a.Close(); err != nil {\n\t\t\tlog.Printf(\"closing account: %v\", err)\n\t\t}\n\t}()\n\n\tvar maxUIDValidity uint32\n\n\terr = a.DB.Write(context.Background(), func(tx *bstore.Tx) error {\n\t\t// We look at each mailbox, retrieve its max UID and compare against the mailbox\n\t\t// UIDNEXT.\n\t\terr := bstore.QueryTx[store.Mailbox](tx).ForEach(func(mb store.Mailbox) error {\n\t\t\tif mb.UIDValidity > maxUIDValidity {\n\t\t\t\tmaxUIDValidity = mb.UIDValidity\n\t\t\t}\n\t\t\tm, err := bstore.QueryTx[store.Message](tx).FilterNonzero(store.Message{MailboxID: mb.ID}).SortDesc(\"UID\").Limit(1).Get()\n\t\t\tif err == bstore.ErrAbsent || err == nil && m.UID < mb.UIDNext {\n\t\t\t\treturn nil\n\t\t\t} else if err != nil {\n\t\t\t\treturn fmt.Errorf(\"finding message with max uid in mailbox: %w\", err)\n\t\t\t}\n\t\t\tolduidnext := mb.UIDNext\n\t\t\tmb.UIDNext = m.UID + 1\n\t\t\tlog.Printf(\"fixing uidnext to %d (max uid is %d, old uidnext was %d) for mailbox %q (id %d)\", mb.UIDNext, m.UID, olduidnext, mb.Name, mb.ID)\n\t\t\tif err := tx.Update(&mb); err != nil {\n\t\t\t\treturn fmt.Errorf(\"updating mailbox uidnext: %v\", err)\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"processing mailboxes: %v\", err)\n\t\t}\n\n\t\tuidvalidity := store.NextUIDValidity{ID: 1}\n\t\tif err := tx.Get(&uidvalidity); err != nil {\n\t\t\treturn fmt.Errorf(\"reading account next uidvalidity: %v\", err)\n\t\t}\n\t\tif maxUIDValidity >= uidvalidity.Next {\n\t\t\tlog.Printf(\"account next uidvalidity %d <= highest uidvalidity %d found in mailbox, resetting account next uidvalidity to %d\", uidvalidity.Next, maxUIDValidity, maxUIDValidity+1)\n\t\t\tuidvalidity.Next = maxUIDValidity + 1\n\t\t\tif err := tx.Update(&uidvalidity); err != nil {\n\t\t\t\treturn fmt.Errorf(\"updating account next uidvalidity: %v\", err)\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t})\n\txcheckf(err, \"updating database\")\n}\n\nfunc cmdFixmsgsize(c *cmd) {\n\tc.params = \"[account]\"\n\tc.help = `Ensure message sizes in the database matching the sum of the message prefix length and on-disk file size.\n\nMessages with an inconsistent size are also parsed again.\n\nIf an inconsistency is found, you should probably also run \"mox\nbumpuidvalidity\" on the mailboxes or entire account to force IMAP clients to\nrefetch messages.\n`\n\targs := c.Parse()\n\tif len(args) > 1 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\tvar account string\n\tif len(args) == 1 {\n\t\taccount = args[0]\n\t}\n\tctlcmdFixmsgsize(xctl(), account)\n}\n\nfunc ctlcmdFixmsgsize(ctl *ctl, account string) {\n\tctl.xwrite(\"fixmsgsize\")\n\tctl.xwrite(account)\n\tctl.xreadok()\n\tctl.xstreamto(os.Stdout)\n}\n\nfunc cmdReparse(c *cmd) {\n\tc.params = \"[account]\"\n\tc.help = `Parse all messages in the account or all accounts again.\n\nCan be useful after upgrading mox with improved message parsing. Messages are\nparsed in batches, so other access to the mailboxes/messages are not blocked\nwhile reparsing all messages.\n`\n\targs := c.Parse()\n\tif len(args) > 1 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\tvar account string\n\tif len(args) == 1 {\n\t\taccount = args[0]\n\t}\n\tctlcmdReparse(xctl(), account)\n}\n\nfunc ctlcmdReparse(ctl *ctl, account string) {\n\tctl.xwrite(\"reparse\")\n\tctl.xwrite(account)\n\tctl.xreadok()\n\tctl.xstreamto(os.Stdout)\n}\n\nfunc cmdEnsureParsed(c *cmd) {\n\tc.params = \"account\"\n\tc.help = \"Ensure messages in the database have a pre-parsed MIME form in the database.\"\n\tvar all bool\n\tc.flag.BoolVar(&all, \"all\", false, \"store new parsed message for all messages\")\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\ta, err := store.OpenAccount(c.log, args[0])\n\txcheckf(err, \"open account\")\n\tdefer func() {\n\t\tif err := a.Close(); err != nil {\n\t\t\tlog.Printf(\"closing account: %v\", err)\n\t\t}\n\t}()\n\n\tn := 0\n\terr = a.DB.Write(context.Background(), func(tx *bstore.Tx) error {\n\t\tq := bstore.QueryTx[store.Message](tx)\n\t\tq.FilterEqual(\"Expunged\", false)\n\t\tq.FilterFn(func(m store.Message) bool {\n\t\t\treturn all || m.ParsedBuf == nil\n\t\t})\n\t\tl, err := q.List()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"list messages: %v\", err)\n\t\t}\n\t\tfor _, m := range l {\n\t\t\tmr := a.MessageReader(m)\n\t\t\tp, err := message.EnsurePart(c.log.Logger, false, mr, m.Size)\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"parsing message %d: %v (continuing)\", m.ID, err)\n\t\t\t}\n\t\t\tm.ParsedBuf, err = json.Marshal(p)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"marshal parsed message: %v\", err)\n\t\t\t}\n\t\t\tif err := tx.Update(&m); err != nil {\n\t\t\t\treturn fmt.Errorf(\"update message: %v\", err)\n\t\t\t}\n\t\t\tn++\n\t\t}\n\t\treturn nil\n\t})\n\txcheckf(err, \"update messages with parsed mime structure\")\n\tfmt.Printf(\"%d messages updated\\n\", n)\n}\n\nfunc cmdRecalculateMailboxCounts(c *cmd) {\n\tc.params = \"account\"\n\tc.help = `Recalculate message counts for all mailboxes in the account, and total message size for quota.\n\nWhen a message is added to/removed from a mailbox, or when message flags change,\nthe total, unread, unseen and deleted messages are accounted, the total size of\nthe mailbox, and the total message size for the account. In case of a bug in\nthis accounting, the numbers could become incorrect. This command will find, fix\nand print them.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\tctlcmdRecalculateMailboxCounts(xctl(), args[0])\n}\n\nfunc ctlcmdRecalculateMailboxCounts(ctl *ctl, account string) {\n\tctl.xwrite(\"recalculatemailboxcounts\")\n\tctl.xwrite(account)\n\tctl.xreadok()\n\tctl.xstreamto(os.Stdout)\n}\n\nfunc cmdMessageParse(c *cmd) {\n\tc.params = \"message.eml\"\n\tc.help = \"Parse message, print JSON representation.\"\n\n\tvar smtputf8 bool\n\tc.flag.BoolVar(&smtputf8, \"smtputf8\", false, \"check if message needs smtputf8\")\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tf, err := os.Open(args[0])\n\txcheckf(err, \"open\")\n\tdefer f.Close()\n\n\tpart, err := message.Parse(c.log.Logger, false, f)\n\txcheckf(err, \"parsing message\")\n\terr = part.Walk(c.log.Logger, nil)\n\txcheckf(err, \"parsing nested parts\")\n\tenc := json.NewEncoder(os.Stdout)\n\tenc.SetIndent(\"\", \"\\t\")\n\tenc.SetEscapeHTML(false)\n\terr = enc.Encode(part)\n\txcheckf(err, \"write\")\n\n\tif smtputf8 {\n\t\tneeds, err := part.NeedsSMTPUTF8()\n\t\txcheckf(err, \"checking if message needs smtputf8\")\n\t\tfmt.Println(\"message needs smtputf8:\", needs)\n\t}\n}\n\nfunc cmdOpenaccounts(c *cmd) {\n\tc.unlisted = true\n\tc.params = \"datadir account ...\"\n\tc.help = `Open and close accounts, for triggering data upgrades, for tests.\n\nOpens database files directly, not going through a running mox instance.\n`\n\n\targs := c.Parse()\n\tif len(args) <= 1 {\n\t\tc.Usage()\n\t}\n\n\tdataDir := filepath.Clean(args[0])\n\tfor _, accName := range args[1:] {\n\t\taccDir := filepath.Join(dataDir, \"accounts\", accName)\n\t\tlog.Printf(\"opening account %s...\", accDir)\n\t\ta, err := store.OpenAccountDB(c.log, accDir, accName)\n\t\txcheckf(err, \"open account %s\", accName)\n\t\terr = a.ThreadingWait(c.log)\n\t\txcheckf(err, \"wait for threading upgrade to complete for %s\", accName)\n\t\terr = a.Close()\n\t\txcheckf(err, \"close account %s\", accName)\n\t}\n}\n\nfunc cmdReassignthreads(c *cmd) {\n\tc.params = \"[account]\"\n\tc.help = `Reassign message threads.\n\nFor all accounts, or optionally only the specified account.\n\nThreading for all messages in an account is first reset, and new base subject\nand normalized message-id saved with the message. Then all messages are\nevaluated and matched against their parents/ancestors.\n\nMessages are matched based on the References header, with a fall-back to an\nIn-Reply-To header, and if neither is present/valid, based only on base\nsubject.\n\nA References header typically points to multiple previous messages in a\nhierarchy. From oldest ancestor to most recent parent. An In-Reply-To header\nwould have only a message-id of the parent message.\n\nA message is only linked to a parent/ancestor if their base subject is the\nsame. This ensures unrelated replies, with a new subject, are placed in their\nown thread.\n\nThe base subject is lower cased, has whitespace collapsed to a single\nspace, and some components removed: leading \"Re:\", \"Fwd:\", \"Fw:\", or bracketed\ntag (that mailing lists often add, e.g. \"[listname]\"), trailing \"(fwd)\", or\nenclosing \"[fwd: ...]\".\n\nMessages are linked to all their ancestors. If an intermediate parent/ancestor\nmessage is deleted in the future, the message can still be linked to the earlier\nancestors. If the direct parent already wasn't available while matching, this is\nstored as the message having a \"missing link\" to its stored ancestors.\n`\n\targs := c.Parse()\n\tif len(args) > 1 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\tvar account string\n\tif len(args) == 1 {\n\t\taccount = args[0]\n\t}\n\tctlcmdReassignthreads(xctl(), account)\n}\n\nfunc ctlcmdReassignthreads(ctl *ctl, account string) {\n\tctl.xwrite(\"reassignthreads\")\n\tctl.xwrite(account)\n\tctl.xreadok()\n\tctl.xstreamto(os.Stdout)\n}\n\nfunc cmdReadmessages(c *cmd) {\n\tc.unlisted = true\n\tc.params = \"datadir account ...\"\n\tc.help = `Open account, parse several headers for all messages.\n\nFor performance testing.\n\nOpens database files directly, not going through a running mox instance.\n`\n\n\tgomaxprocs := runtime.GOMAXPROCS(0)\n\tvar procs, workqueuesize, limit int\n\tc.flag.IntVar(&procs, \"procs\", gomaxprocs, \"number of goroutines for reading messages\")\n\tc.flag.IntVar(&workqueuesize, \"workqueuesize\", 2*gomaxprocs, \"number of messages to keep in work queue\")\n\tc.flag.IntVar(&limit, \"limit\", 0, \"number of messages to process if greater than zero\")\n\targs := c.Parse()\n\tif len(args) <= 1 {\n\t\tc.Usage()\n\t}\n\n\ttype threadPrep struct {\n\t\treferences []string\n\t\tinReplyTo  []string\n\t}\n\n\tthreadingFields := [][]byte{\n\t\t[]byte(\"references\"),\n\t\t[]byte(\"in-reply-to\"),\n\t}\n\n\tdataDir := filepath.Clean(args[0])\n\tfor _, accName := range args[1:] {\n\t\taccDir := filepath.Join(dataDir, \"accounts\", accName)\n\t\tlog.Printf(\"opening account %s...\", accDir)\n\t\ta, err := store.OpenAccountDB(c.log, accDir, accName)\n\t\txcheckf(err, \"open account %s\", accName)\n\n\t\tprepareMessages := func(in, out chan moxio.Work[store.Message, threadPrep]) {\n\t\t\theaderbuf := make([]byte, 8*1024)\n\t\t\tscratch := make([]byte, 4*1024)\n\t\t\tfor {\n\t\t\t\tw, ok := <-in\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tm := w.In\n\t\t\t\tvar partialPart struct {\n\t\t\t\t\tHeaderOffset int64\n\t\t\t\t\tBodyOffset   int64\n\t\t\t\t}\n\t\t\t\tif err := json.Unmarshal(m.ParsedBuf, &partialPart); err != nil {\n\t\t\t\t\tw.Err = fmt.Errorf(\"unmarshal part: %v\", err)\n\t\t\t\t} else {\n\t\t\t\t\tsize := partialPart.BodyOffset - partialPart.HeaderOffset\n\t\t\t\t\tif int(size) > len(headerbuf) {\n\t\t\t\t\t\theaderbuf = make([]byte, size)\n\t\t\t\t\t}\n\t\t\t\t\tif size > 0 {\n\t\t\t\t\t\tbuf := headerbuf[:int(size)]\n\t\t\t\t\t\terr := func() error {\n\t\t\t\t\t\t\tmr := a.MessageReader(m)\n\t\t\t\t\t\t\tdefer mr.Close()\n\n\t\t\t\t\t\t\t// ReadAt returns whole buffer or error. Single read should be fast.\n\t\t\t\t\t\t\tn, err := mr.ReadAt(buf, partialPart.HeaderOffset)\n\t\t\t\t\t\t\tif err != nil || n != len(buf) {\n\t\t\t\t\t\t\t\treturn fmt.Errorf(\"read header: %v\", err)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t}()\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\tw.Err = err\n\t\t\t\t\t\t} else if h, err := message.ParseHeaderFields(buf, scratch, threadingFields); err != nil {\n\t\t\t\t\t\t\tw.Err = err\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tw.Out.references = h[\"References\"]\n\t\t\t\t\t\t\tw.Out.inReplyTo = h[\"In-Reply-To\"]\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tout <- w\n\t\t\t}\n\t\t}\n\n\t\tn := 0\n\t\tt := time.Now()\n\t\tt0 := t\n\n\t\tprocessMessage := func(m store.Message, prep threadPrep) error {\n\t\t\tif n%100000 == 0 {\n\t\t\t\tlog.Printf(\"%d messages (delta %s)\", n, time.Since(t))\n\t\t\t\tt = time.Now()\n\t\t\t}\n\t\t\tn++\n\t\t\treturn nil\n\t\t}\n\n\t\twq := moxio.NewWorkQueue[store.Message, threadPrep](procs, workqueuesize, prepareMessages, processMessage)\n\n\t\terr = a.DB.Write(context.Background(), func(tx *bstore.Tx) error {\n\t\t\tq := bstore.QueryTx[store.Message](tx)\n\t\t\tq.FilterEqual(\"Expunged\", false)\n\t\t\tq.SortAsc(\"ID\")\n\t\t\tif limit > 0 {\n\t\t\t\tq.Limit(limit)\n\t\t\t}\n\t\t\terr = q.ForEach(wq.Add)\n\t\t\tif err == nil {\n\t\t\t\terr = wq.Finish()\n\t\t\t}\n\t\t\twq.Stop()\n\n\t\t\treturn err\n\t\t})\n\t\txcheckf(err, \"processing message\")\n\n\t\terr = a.Close()\n\t\txcheckf(err, \"close account %s\", accName)\n\t\tlog.Printf(\"account %s, total time %s\", accName, time.Since(t0))\n\t}\n}\n\nfunc cmdQueueFillRetired(c *cmd) {\n\tc.unlisted = true\n\tc.help = `Fill retired messag and webhooks queue with testdata.\n\nFor testing the pagination. Operates directly on queue database.\n`\n\tvar n int\n\tc.flag.IntVar(&n, \"n\", 10000, \"retired messages and retired webhooks to insert\")\n\targs := c.Parse()\n\tif len(args) != 0 {\n\t\tc.Usage()\n\t}\n\n\tmustLoadConfig()\n\terr := queue.Init()\n\txcheckf(err, \"init queue\")\n\terr = queue.DB.Write(context.Background(), func(tx *bstore.Tx) error {\n\t\tnow := time.Now()\n\n\t\t// Cause autoincrement ID for queue.Msg to be forwarded, and use the reserved ID\n\t\t// space for inserting retired messages.\n\t\tfm := queue.Msg{}\n\t\terr = tx.Insert(&fm)\n\t\txcheckf(err, \"temporarily insert message to get autoincrement sequence\")\n\t\terr = tx.Delete(&fm)\n\t\txcheckf(err, \"removing temporary message for resetting autoincrement sequence\")\n\t\tfm.ID += int64(n)\n\t\terr = tx.Insert(&fm)\n\t\txcheckf(err, \"temporarily insert message to forward autoincrement sequence\")\n\t\terr = tx.Delete(&fm)\n\t\txcheckf(err, \"removing temporary message after forwarding autoincrement sequence\")\n\t\tfm.ID -= int64(n)\n\n\t\t// And likewise for webhooks.\n\t\tfh := queue.Hook{Account: \"x\", URL: \"x\", NextAttempt: time.Now()}\n\t\terr = tx.Insert(&fh)\n\t\txcheckf(err, \"temporarily insert webhook to get autoincrement sequence\")\n\t\terr = tx.Delete(&fh)\n\t\txcheckf(err, \"removing temporary webhook for resetting autoincrement sequence\")\n\t\tfh.ID += int64(n)\n\t\terr = tx.Insert(&fh)\n\t\txcheckf(err, \"temporarily insert webhook to forward autoincrement sequence\")\n\t\terr = tx.Delete(&fh)\n\t\txcheckf(err, \"removing temporary webhook after forwarding autoincrement sequence\")\n\t\tfh.ID -= int64(n)\n\n\t\tfor i := 0; i < n; i++ {\n\t\t\tt0 := now.Add(-time.Duration(i) * time.Second)\n\t\t\tlast := now.Add(-time.Duration(i/10) * time.Second)\n\t\t\tmr := queue.MsgRetired{\n\t\t\t\tID:                 fm.ID + int64(i),\n\t\t\t\tQueued:             t0,\n\t\t\t\tSenderAccount:      \"test\",\n\t\t\t\tSenderLocalpart:    \"mox\",\n\t\t\t\tSenderDomainStr:    \"localhost\",\n\t\t\t\tFromID:             fmt.Sprintf(\"%016d\", i),\n\t\t\t\tRecipientLocalpart: \"mox\",\n\t\t\t\tRecipientDomain:    dns.IPDomain{Domain: dns.Domain{ASCII: \"localhost\"}},\n\t\t\t\tRecipientDomainStr: \"localhost\",\n\t\t\t\tAttempts:           i % 6,\n\t\t\t\tLastAttempt:        &last,\n\t\t\t\tResults: []queue.MsgResult{\n\t\t\t\t\t{\n\t\t\t\t\t\tStart:    last,\n\t\t\t\t\t\tDuration: time.Millisecond,\n\t\t\t\t\t\tSuccess:  i%10 != 0,\n\t\t\t\t\t\tCode:     250,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tHas8bit:          i%2 == 0,\n\t\t\t\tSMTPUTF8:         i%8 == 0,\n\t\t\t\tSize:             int64(i * 100),\n\t\t\t\tMessageID:        fmt.Sprintf(\"<msg%d@localhost>\", i),\n\t\t\t\tSubject:          fmt.Sprintf(\"test message %d\", i),\n\t\t\t\tExtra:            map[string]string{\"i\": fmt.Sprintf(\"%d\", i)},\n\t\t\t\tLastActivity:     last,\n\t\t\t\tRecipientAddress: \"mox@localhost\",\n\t\t\t\tSuccess:          i%10 != 0,\n\t\t\t\tKeepUntil:        now.Add(48 * time.Hour),\n\t\t\t}\n\t\t\terr := tx.Insert(&mr)\n\t\t\txcheckf(err, \"inserting retired message\")\n\t\t}\n\n\t\tfor i := 0; i < n; i++ {\n\t\t\tt0 := now.Add(-time.Duration(i) * time.Second)\n\t\t\tlast := now.Add(-time.Duration(i/10) * time.Second)\n\t\t\tvar event string\n\t\t\tif i%10 != 0 {\n\t\t\t\tevent = \"delivered\"\n\t\t\t}\n\t\t\thr := queue.HookRetired{\n\t\t\t\tID:            fh.ID + int64(i),\n\t\t\t\tQueueMsgID:    fm.ID + int64(i),\n\t\t\t\tFromID:        fmt.Sprintf(\"%016d\", i),\n\t\t\t\tMessageID:     fmt.Sprintf(\"<msg%d@localhost>\", i),\n\t\t\t\tSubject:       fmt.Sprintf(\"test message %d\", i),\n\t\t\t\tExtra:         map[string]string{\"i\": fmt.Sprintf(\"%d\", i)},\n\t\t\t\tAccount:       \"test\",\n\t\t\t\tURL:           \"http://localhost/hook\",\n\t\t\t\tIsIncoming:    i%10 == 0,\n\t\t\t\tOutgoingEvent: event,\n\t\t\t\tPayload:       \"{}\",\n\n\t\t\t\tSubmitted: t0,\n\t\t\t\tAttempts:  i % 6,\n\t\t\t\tResults: []queue.HookResult{\n\t\t\t\t\t{\n\t\t\t\t\t\tStart:    t0,\n\t\t\t\t\t\tDuration: time.Millisecond,\n\t\t\t\t\t\tURL:      \"http://localhost/hook\",\n\t\t\t\t\t\tSuccess:  i%10 != 0,\n\t\t\t\t\t\tCode:     200,\n\t\t\t\t\t\tResponse: \"ok\",\n\t\t\t\t\t},\n\t\t\t\t},\n\n\t\t\t\tSuccess:      i%10 != 0,\n\t\t\t\tLastActivity: last,\n\t\t\t\tKeepUntil:    now.Add(48 * time.Hour),\n\t\t\t}\n\t\t\terr := tx.Insert(&hr)\n\t\t\txcheckf(err, \"inserting retired hook\")\n\t\t}\n\n\t\treturn nil\n\t})\n\txcheckf(err, \"add to queue\")\n\tlog.Printf(\"added %d retired messages and %d retired webhooks\", n, n)\n}\n"
        },
        {
          "name": "message",
          "type": "tree",
          "content": null
        },
        {
          "name": "metrics.go",
          "type": "blob",
          "size": 7.3720703125,
          "content": "package main\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"log/slog\"\n\t\"os\"\n\t\"time\"\n\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"github.com/prometheus/client_golang/prometheus/promauto\"\n\n\t\"github.com/mjl-/mox/dane\"\n\t\"github.com/mjl-/mox/dkim\"\n\t\"github.com/mjl-/mox/dmarc\"\n\t\"github.com/mjl-/mox/dns\"\n\t\"github.com/mjl-/mox/dnsbl\"\n\t\"github.com/mjl-/mox/iprev\"\n\t\"github.com/mjl-/mox/metrics\"\n\t\"github.com/mjl-/mox/mlog\"\n\t\"github.com/mjl-/mox/mtasts\"\n\t\"github.com/mjl-/mox/smtpclient\"\n\t\"github.com/mjl-/mox/spf\"\n\t\"github.com/mjl-/mox/subjectpass\"\n\t\"github.com/mjl-/mox/tlsrpt\"\n\t\"github.com/mjl-/mox/updates\"\n)\n\nvar metricHTTPClient = promauto.NewHistogramVec(\n\tprometheus.HistogramOpts{\n\t\tName:    \"mox_httpclient_request_duration_seconds\",\n\t\tHelp:    \"HTTP requests lookups.\",\n\t\tBuckets: []float64{0.01, 0.05, 0.100, 0.5, 1, 5, 10, 20, 30},\n\t},\n\t[]string{\n\t\t\"pkg\",\n\t\t\"method\",\n\t\t\"code\",\n\t\t\"result\",\n\t},\n)\n\n// httpClientObserve tracks the result of an HTTP transaction in a metric, and\n// logs the result.\nfunc httpClientObserve(ctx context.Context, elog *slog.Logger, pkg, method string, statusCode int, err error, start time.Time) {\n\tlog := mlog.New(\"metrics\", elog)\n\tvar result string\n\tswitch {\n\tcase err == nil:\n\t\tswitch statusCode / 100 {\n\t\tcase 2:\n\t\t\tresult = \"ok\"\n\t\tcase 4:\n\t\t\tresult = \"usererror\"\n\t\tcase 5:\n\t\t\tresult = \"servererror\"\n\t\tdefault:\n\t\t\tresult = \"other\"\n\t\t}\n\tcase errors.Is(err, os.ErrDeadlineExceeded) || errors.Is(err, context.DeadlineExceeded):\n\t\tresult = \"timeout\"\n\tcase errors.Is(err, context.Canceled):\n\t\tresult = \"canceled\"\n\tdefault:\n\t\tresult = \"error\"\n\t}\n\tmetricHTTPClient.WithLabelValues(pkg, method, result, fmt.Sprintf(\"%d\", statusCode)).Observe(float64(time.Since(start)) / float64(time.Second))\n\tlog.Debugx(\"httpclient result\", err,\n\t\tslog.String(\"pkg\", pkg),\n\t\tslog.String(\"method\", method),\n\t\tslog.Int(\"code\", statusCode),\n\t\tslog.Duration(\"duration\", time.Since(start)))\n}\n\nfunc init() {\n\tdane.MetricVerify = promauto.NewCounter(\n\t\tprometheus.CounterOpts{\n\t\t\tName: \"mox_dane_verify_total\",\n\t\t\tHelp: \"Total number of DANE verification attempts, including mox_dane_verify_errors_total.\",\n\t\t},\n\t)\n\tdane.MetricVerifyErrors = promauto.NewCounter(\n\t\tprometheus.CounterOpts{\n\t\t\tName: \"mox_dane_verify_errors_total\",\n\t\t\tHelp: \"Total number of DANE verification failures, causing connections to fail.\",\n\t\t},\n\t)\n\n\tdkim.MetricSign = counterVec{promauto.NewCounterVec(\n\t\tprometheus.CounterOpts{\n\t\t\tName: \"mox_dkim_sign_total\",\n\t\t\tHelp: \"DKIM messages signings, label key is the type of key, rsa or ed25519.\",\n\t\t},\n\t\t[]string{\n\t\t\t\"key\",\n\t\t},\n\t)}\n\tdkim.MetricVerify = histogramVec{\n\t\tpromauto.NewHistogramVec(\n\t\t\tprometheus.HistogramOpts{\n\t\t\t\tName:    \"mox_dkim_verify_duration_seconds\",\n\t\t\t\tHelp:    \"DKIM verify, including lookup, duration and result.\",\n\t\t\t\tBuckets: []float64{0.001, 0.005, 0.01, 0.05, 0.100, 0.5, 1, 5, 10, 20},\n\t\t\t},\n\t\t\t[]string{\n\t\t\t\t\"algorithm\",\n\t\t\t\t\"status\",\n\t\t\t},\n\t\t),\n\t}\n\n\tdmarc.MetricVerify = histogramVec{promauto.NewHistogramVec(\n\t\tprometheus.HistogramOpts{\n\t\t\tName:    \"mox_dmarc_verify_duration_seconds\",\n\t\t\tHelp:    \"DMARC verify, including lookup, duration and result.\",\n\t\t\tBuckets: []float64{0.001, 0.005, 0.01, 0.05, 0.100, 0.5, 1, 5, 10, 20},\n\t\t},\n\t\t[]string{\n\t\t\t\"status\",\n\t\t\t\"reject\", // yes/no\n\t\t\t\"use\",    // yes/no, if policy is used after random selection\n\t\t},\n\t)}\n\tdns.MetricLookup = histogramVec{\n\t\tpromauto.NewHistogramVec(\n\t\t\tprometheus.HistogramOpts{\n\t\t\t\tName:    \"mox_dns_lookup_duration_seconds\",\n\t\t\t\tHelp:    \"DNS lookups.\",\n\t\t\t\tBuckets: []float64{0.001, 0.005, 0.01, 0.05, 0.100, 0.5, 1, 5, 10, 20, 30},\n\t\t\t},\n\t\t\t[]string{\n\t\t\t\t\"pkg\",\n\t\t\t\t\"type\",   // Lower-case Resolver method name without leading Lookup.\n\t\t\t\t\"result\", // ok, nxdomain, temporary, timeout, canceled, error\n\t\t\t},\n\t\t),\n\t}\n\n\tdnsbl.MetricLookup = histogramVec{promauto.NewHistogramVec(\n\t\tprometheus.HistogramOpts{\n\t\t\tName:    \"mox_dnsbl_lookup_duration_seconds\",\n\t\t\tHelp:    \"DNSBL lookup\",\n\t\t\tBuckets: []float64{0.001, 0.005, 0.01, 0.05, 0.100, 0.5, 1, 5, 10, 20},\n\t\t},\n\t\t[]string{\n\t\t\t\"zone\",\n\t\t\t\"status\",\n\t\t},\n\t)}\n\n\tiprev.MetricIPRev = histogramVec{promauto.NewHistogramVec(\n\t\tprometheus.HistogramOpts{\n\t\t\tName:    \"mox_iprev_lookup_total\",\n\t\t\tHelp:    \"Number of iprev lookups.\",\n\t\t\tBuckets: []float64{0.001, 0.005, 0.01, 0.05, 0.100, 0.5, 1, 5, 10, 20, 30},\n\t\t},\n\t\t[]string{\"status\"},\n\t)}\n\n\tmtasts.MetricGet = histogramVec{promauto.NewHistogramVec(\n\t\tprometheus.HistogramOpts{\n\t\t\tName:    \"mox_mtasts_get_duration_seconds\",\n\t\t\tHelp:    \"MTA-STS get of policy, including lookup, duration and result.\",\n\t\t\tBuckets: []float64{0.01, 0.05, 0.100, 0.5, 1, 5, 10, 20},\n\t\t},\n\t\t[]string{\n\t\t\t\"result\", // ok, lookuperror, fetcherror\n\t\t},\n\t)}\n\tmtasts.HTTPClientObserve = httpClientObserve\n\n\tsmtpclient.MetricCommands = histogramVec{promauto.NewHistogramVec(\n\t\tprometheus.HistogramOpts{\n\t\t\tName:    \"mox_smtpclient_command_duration_seconds\",\n\t\t\tHelp:    \"SMTP client command duration and result codes in seconds.\",\n\t\t\tBuckets: []float64{0.001, 0.005, 0.01, 0.05, 0.100, 0.5, 1, 5, 10, 20, 30, 60, 120},\n\t\t},\n\t\t[]string{\n\t\t\t\"cmd\",\n\t\t\t\"code\",\n\t\t\t\"secode\",\n\t\t},\n\t)}\n\tsmtpclient.MetricTLSRequiredNoIgnored = counterVec{promauto.NewCounterVec(\n\t\tprometheus.CounterOpts{\n\t\t\tName: \"mox_smtpclient_tlsrequiredno_ignored_total\",\n\t\t\tHelp: \"Connection attempts with TLS policy findings ignored due to message with TLS-Required: No header. Does not cover case where TLS certificate cannot be PKIX-verified.\",\n\t\t},\n\t\t[]string{\n\t\t\t\"ignored\", // daneverification (no matching tlsa record)\n\t\t},\n\t)}\n\tsmtpclient.MetricPanicInc = func() {\n\t\tmetrics.PanicInc(metrics.Smtpclient)\n\t}\n\n\tspf.MetricVerify = histogramVec{promauto.NewHistogramVec(\n\t\tprometheus.HistogramOpts{\n\t\t\tName:    \"mox_spf_verify_duration_seconds\",\n\t\t\tHelp:    \"SPF verify, including lookup, duration and result.\",\n\t\t\tBuckets: []float64{0.001, 0.005, 0.01, 0.05, 0.100, 0.5, 1, 5, 10, 20},\n\t\t},\n\t\t[]string{\n\t\t\t\"status\",\n\t\t},\n\t)}\n\n\tsubjectpass.MetricGenerate = promauto.NewCounter(\n\t\tprometheus.CounterOpts{\n\t\t\tName: \"mox_subjectpass_generate_total\",\n\t\t\tHelp: \"Number of generated subjectpass challenges.\",\n\t\t},\n\t)\n\tsubjectpass.MetricVerify = counterVec{promauto.NewCounterVec(\n\t\tprometheus.CounterOpts{\n\t\t\tName: \"mox_subjectpass_verify_total\",\n\t\t\tHelp: \"Number of subjectpass verifications.\",\n\t\t},\n\t\t[]string{\n\t\t\t\"result\", // ok, fail\n\t\t},\n\t)}\n\n\ttlsrpt.MetricLookup = histogramVec{promauto.NewHistogramVec(\n\t\tprometheus.HistogramOpts{\n\t\t\tName:    \"mox_tlsrpt_lookup_duration_seconds\",\n\t\t\tHelp:    \"TLSRPT lookups with result.\",\n\t\t\tBuckets: []float64{0.001, 0.005, 0.01, 0.05, 0.100, 0.5, 1, 5, 10, 20, 30},\n\t\t},\n\t\t[]string{\"result\"},\n\t)}\n\n\tupdates.MetricLookup = histogramVec{promauto.NewHistogramVec(\n\t\tprometheus.HistogramOpts{\n\t\t\tName:    \"mox_updates_lookup_duration_seconds\",\n\t\t\tHelp:    \"Updates lookup with result.\",\n\t\t\tBuckets: []float64{0.001, 0.005, 0.01, 0.05, 0.100, 0.5, 1, 5, 10, 20, 30},\n\t\t},\n\t\t[]string{\"result\"},\n\t)}\n\tupdates.MetricFetchChangelog = histogramVec{promauto.NewHistogramVec(\n\t\tprometheus.HistogramOpts{\n\t\t\tName:    \"mox_updates_fetchchangelog_duration_seconds\",\n\t\t\tHelp:    \"Fetch changelog with result.\",\n\t\t\tBuckets: []float64{0.001, 0.005, 0.01, 0.05, 0.100, 0.5, 1, 5, 10, 20, 30},\n\t\t},\n\t\t[]string{\"result\"},\n\t)}\n}\n\ntype counterVec struct {\n\t*prometheus.CounterVec\n}\n\nfunc (m counterVec) IncLabels(labels ...string) {\n\tm.CounterVec.WithLabelValues(labels...).Inc()\n}\n\ntype histogramVec struct {\n\t*prometheus.HistogramVec\n}\n\nfunc (m histogramVec) ObserveLabels(v float64, labels ...string) {\n\tm.HistogramVec.WithLabelValues(labels...).Observe(v)\n}\n"
        },
        {
          "name": "metrics",
          "type": "tree",
          "content": null
        },
        {
          "name": "mlog",
          "type": "tree",
          "content": null
        },
        {
          "name": "mox-",
          "type": "tree",
          "content": null
        },
        {
          "name": "mox.service",
          "type": "blob",
          "size": 1.322265625,
          "content": "[Unit]\nDescription=mox mail server\nAfter=network-online.target\nWants=network-online.target\n\n[Service]\nUMask=007\nLimitNOFILE=65535\nType=simple\n# Mox starts as root, but drops privileges after binding network addresses.\nWorkingDirectory=/home/mox\nExecStart=/home/mox/mox serve\nRestartSec=5s\nRestart=always\nExecStop=/home/mox/mox stop\nSyslogFacility=mail\n\n# Isolate process, reducing attack surface.\nPrivateDevices=yes\nPrivateTmp=yes\nProtectSystem=strict\nReadWritePaths=/home/mox/config /home/mox/data\nProtectKernelTunables=yes\nProtectControlGroups=yes\nAmbientCapabilities=\nCapabilityBoundingSet=CAP_SETUID CAP_SETGID CAP_NET_BIND_SERVICE CAP_CHOWN CAP_FSETID CAP_DAC_OVERRIDE CAP_DAC_READ_SEARCH CAP_FOWNER CAP_KILL\nNoNewPrivileges=yes\nRestrictAddressFamilies=AF_INET AF_INET6 AF_UNIX AF_NETLINK\nProtectProc=invisible\nRestrictNamespaces=yes\nRestrictRealtime=yes\nRemoveIPC=yes\nProtectHostname=yes\nProtectClock=yes\nProtectKernelLogs=yes\nProtectKernelModules=yes\nMemoryDenyWriteExecute=yes\nLockPersonality=yes\nDevicePolicy=closed\nSystemCallArchitectures=native\nSystemCallFilter=@system-service\n\n# Cannot have RestrictSUIDSGID with setgid directories.\n#RestrictSUIDSGID=yes\n\n# prevents CAP_NET_BIND_SERVICE from working?\n#PrivateUsers=yes\n\n# To check security-related settings:\n# sudo systemd-analyze security mox.service\n\n[Install]\nWantedBy=multi-user.target\n"
        },
        {
          "name": "moxio",
          "type": "tree",
          "content": null
        },
        {
          "name": "moxvar",
          "type": "tree",
          "content": null
        },
        {
          "name": "mtasts",
          "type": "tree",
          "content": null
        },
        {
          "name": "mtastsdb",
          "type": "tree",
          "content": null
        },
        {
          "name": "package-lock.json",
          "type": "blob",
          "size": 0.5751953125,
          "content": "{\n  \"name\": \"mox\",\n  \"lockfileVersion\": 3,\n  \"requires\": true,\n  \"packages\": {\n    \"\": {\n      \"devDependencies\": {\n        \"typescript\": \"5.1.6\"\n      }\n    },\n    \"node_modules/typescript\": {\n      \"version\": \"5.1.6\",\n      \"resolved\": \"https://registry.npmjs.org/typescript/-/typescript-5.1.6.tgz\",\n      \"integrity\": \"sha512-zaWCozRZ6DLEWAWFrVDz1H6FVXzUSfTy5FUMWsQlU8Ym5JP9eO4xkTIROFCQvhQf61z6O/G6ugw3SgAnvvm+HA==\",\n      \"dev\": true,\n      \"bin\": {\n        \"tsc\": \"bin/tsc\",\n        \"tsserver\": \"bin/tsserver\"\n      },\n      \"engines\": {\n        \"node\": \">=14.17\"\n      }\n    }\n  }\n}\n"
        },
        {
          "name": "package.json",
          "type": "blob",
          "size": 0.0556640625,
          "content": "{\n  \"devDependencies\": {\n    \"typescript\": \"5.1.6\"\n  }\n}\n"
        },
        {
          "name": "profile.go",
          "type": "blob",
          "size": 1.0439453125,
          "content": "package main\n\nimport (\n\t\"log\"\n\t\"os\"\n\t\"runtime\"\n\t\"runtime/pprof\"\n\t\"runtime/trace\"\n)\n\nfunc memprofile(mempath string) {\n\tif mempath == \"\" {\n\t\treturn\n\t}\n\n\tf, err := os.Create(mempath)\n\txcheckf(err, \"creating memory profile\")\n\tdefer func() {\n\t\tif err := f.Close(); err != nil {\n\t\t\tlog.Printf(\"closing memory profile: %v\", err)\n\t\t}\n\t}()\n\truntime.GC() // get up-to-date statistics\n\terr = pprof.WriteHeapProfile(f)\n\txcheckf(err, \"writing memory profile\")\n}\n\nfunc profile(cpupath, mempath string) func() {\n\tif cpupath == \"\" {\n\t\treturn func() {\n\t\t\tmemprofile(mempath)\n\t\t}\n\t}\n\n\tf, err := os.Create(cpupath)\n\txcheckf(err, \"creating CPU profile\")\n\terr = pprof.StartCPUProfile(f)\n\txcheckf(err, \"start CPU profile\")\n\treturn func() {\n\t\tpprof.StopCPUProfile()\n\t\tif err := f.Close(); err != nil {\n\t\t\tlog.Printf(\"closing cpu profile: %v\", err)\n\t\t}\n\t\tmemprofile(mempath)\n\t}\n}\n\nfunc traceExecution(path string) func() {\n\tf, err := os.Create(path)\n\txcheckf(err, \"create trace file\")\n\ttrace.Start(f)\n\treturn func() {\n\t\ttrace.Stop()\n\t\terr := f.Close()\n\t\txcheckf(err, \"close trace file\")\n\t}\n}\n"
        },
        {
          "name": "prometheus.rules",
          "type": "blob",
          "size": 3.3642578125,
          "content": "# example prometheus alerting rules file for mox.\n\ngroups:\n- name: mox\n  rules:\n  - alert: mox-panic\n    expr: increase(mox_panic_total[1h]) > 0\n    annotations:\n      summary: unhandled panic\n\n  - alert: mox-ip-on-dns-blocklist\n    expr: mox_dnsbl_ips_success < 1\n    annotations:\n      summary: ip is on dns blocklist\n\n  - alert: mox-queue-failing-delivery\n    expr: increase(mox_queue_delivery_duration_seconds_count{attempt!~\"[123]\",result!=\"ok\"}[1h]) > 0\n    annotations:\n      summary: delivery from queue had a 4th or later attempt fail\n\n  - alert: mox-smtpserver-errors\n    expr: increase(mox_smtpserver_errors_total[1h]) > 0\n    annotations:\n      summary: errors in smtpserver operation\n\n  - alert: mox-webserver-errors\n    expr: increase(mox_httpserver_request_duration_seconds_count{code=~\"5..\"}[1h]) > 0\n    annotations:\n      summary: http 5xx responses from webserver\n\n  - alert: mox-queue-hold\n    expr: mox_queue_hold > 0\n    for: 2h\n    annotations:\n      summary: messages on hold in queue for at least two hours\n\n  - alert: mox-submission-errors\n    expr: increase(mox_smtpserver_submission_total{result=~\".*error\"}[1h]) > 0\n    annotations:\n      summary: smtp submission errors\n\n  - alert: mox-delivery-errors\n    expr: increase(mox_smtpserver_delivery_total{result=~\".*error\"}[1h]) > 0\n    annotations:\n      summary: smtp delivery errors\n\n  - alert: mox-webmail-errors\n    expr: increase(mox_webmail_errors_total[1h]) > 0\n    annotations:\n      summary: errors in webmail operation\n\n  - alert: mox-webmailsubmission-errors\n    expr: increase(mox_webmail_submission_total{result=~\".*error\"}[1h]) > 0\n    annotations:\n      summary: webmail submission errors\n\n  - alert: mox-sherpa-server-errors\n    expr: increase(sherpa_errors_total{api=~\"mox.*\",code=~\"server:.*\"}[1h]) > 0\n    annotations:\n      summary: sherpa web api server errors\n\n  # the alerts below can be used to keep a closer eye or when starting to use mox,\n  # but can be noisy, or you may not be able to prevent them.\n\n  - alert: mox-incoming-delivery-starttls-errors\n    expr: sum by (instance) (increase(mox_smtpserver_delivery_starttls_errors_total[1h])) / sum by (instance) (increase(mox_smtpserver_delivery_starttls_total[1h])) > 0.1\n    annotations:\n      summary: starttls handshake errors for >10% of incoming smtp delivery connections\n\n  # change period to match your expected incoming message rate.\n  - alert: mox-no-deliveries\n    expr: sum by (instance) (rate(mox_smtpserver_delivery_total{result=\"delivered\"}[6h])) == 0\n    annotations:\n      summary: no mail delivered for 6 hours\n\n  # may be noisy. anyone can send these reports. you may want to silence it.\n  - alert: mox-tlsrpt-errors\n    expr: increase(mox_tlsrptdb_session_total{type!=\"success\"}[1h]) > 0\n    annotations:\n      summary: tls reports about unsuccessful tls connections\n\n  # may be noisy. can be caused by someone trying to send email as you. and\n  # anyone can send these reports. you are not in control over when this fires,\n  # so you may want to silence it.\n  - alert: mox-dmarc-rejects\n    expr: increase(mox_dmarcdb_policy_evaluated_total{disposition!=\"none\"}[1h]) > 0\n    annotations:\n      summary: dmarc reports about rejects/quarantines due to failing dmarc check\n\n  # may be noisy\n  - alert: mox-auth-ratelimited\n    expr: increase(mox_authentication_ratelimited_total[1h]) > 0\n    annotations:\n      summary: authentication connections/requests were rate limited\n"
        },
        {
          "name": "publicsuffix",
          "type": "tree",
          "content": null
        },
        {
          "name": "queue.go",
          "type": "blob",
          "size": 23.08984375,
          "content": "package main\n\nimport (\n\t\"encoding/json\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/mjl-/mox/queue\"\n)\n\nfunc xctlwriteJSON(ctl *ctl, v any) {\n\tfbuf, err := json.Marshal(v)\n\txcheckf(err, \"marshal as json to ctl\")\n\tctl.xwrite(string(fbuf))\n}\n\nfunc cmdQueueHoldrulesList(c *cmd) {\n\tc.help = `List hold rules for the delivery queue.\n\nMessages submitted to the queue that match a hold rule will be marked as on hold\nand not scheduled for delivery.\n`\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueHoldrulesList(xctl())\n}\n\nfunc ctlcmdQueueHoldrulesList(ctl *ctl) {\n\tctl.xwrite(\"queueholdruleslist\")\n\tctl.xreadok()\n\tif _, err := io.Copy(os.Stdout, ctl.reader()); err != nil {\n\t\tlog.Fatalf(\"%s\", err)\n\t}\n}\n\nfunc cmdQueueHoldrulesAdd(c *cmd) {\n\tc.params = \"[ruleflags]\"\n\tc.help = `Add hold rule for the delivery queue.\n\nAdd a hold rule to mark matching newly submitted messages as on hold. Set the\nmatching rules with the flags. Don't specify any flags to match all submitted\nmessages.\n`\n\tvar account, senderDomain, recipientDomain string\n\tc.flag.StringVar(&account, \"account\", \"\", \"account submitting the message\")\n\tc.flag.StringVar(&senderDomain, \"senderdom\", \"\", \"sender domain\")\n\tc.flag.StringVar(&recipientDomain, \"recipientdom\", \"\", \"recipient domain\")\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueHoldrulesAdd(xctl(), account, senderDomain, recipientDomain)\n}\n\nfunc ctlcmdQueueHoldrulesAdd(ctl *ctl, account, senderDomain, recipientDomain string) {\n\tctl.xwrite(\"queueholdrulesadd\")\n\tctl.xwrite(account)\n\tctl.xwrite(senderDomain)\n\tctl.xwrite(recipientDomain)\n\tctl.xreadok()\n}\n\nfunc cmdQueueHoldrulesRemove(c *cmd) {\n\tc.params = \"ruleid\"\n\tc.help = `Remove hold rule for the delivery queue.\n\nRemove a hold rule by its id.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\tid, err := strconv.ParseInt(args[0], 10, 64)\n\txcheckf(err, \"parsing id\")\n\tmustLoadConfig()\n\tctlcmdQueueHoldrulesRemove(xctl(), id)\n}\n\nfunc ctlcmdQueueHoldrulesRemove(ctl *ctl, id int64) {\n\tctl.xwrite(\"queueholdrulesremove\")\n\tctl.xwrite(fmt.Sprintf(\"%d\", id))\n\tctl.xreadok()\n}\n\n// flagFilterSort is used by many of the queue commands to accept flags for\n// filtering the messages the operation applies to.\nfunc flagFilterSort(fs *flag.FlagSet, f *queue.Filter, s *queue.Sort) {\n\tfs.Func(\"ids\", \"comma-separated list of message IDs\", func(v string) error {\n\t\tfor _, s := range strings.Split(v, \",\") {\n\t\t\tid, err := strconv.ParseInt(s, 10, 64)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tf.IDs = append(f.IDs, id)\n\t\t}\n\t\treturn nil\n\t})\n\tfs.IntVar(&f.Max, \"n\", 0, \"number of messages to return\")\n\tfs.StringVar(&f.Account, \"account\", \"\", \"account that queued the message\")\n\tfs.StringVar(&f.From, \"from\", \"\", `from address of message, use \"@example.com\" to match all messages for a domain`)\n\tfs.StringVar(&f.To, \"to\", \"\", `recipient address of message, use \"@example.com\" to match all messages for a domain`)\n\tfs.StringVar(&f.Submitted, \"submitted\", \"\", `filter by time of submission relative to now, value must start with \"<\" (before now) or \">\" (after now)`)\n\tfs.StringVar(&f.NextAttempt, \"nextattempt\", \"\", `filter by time of next delivery attempt relative to now, value must start with \"<\" (before now) or \">\" (after now)`)\n\tfs.Func(\"transport\", \"transport to use for messages, empty string sets the default behaviour\", func(v string) error {\n\t\tf.Transport = &v\n\t\treturn nil\n\t})\n\tfs.Func(\"hold\", \"true or false, whether to match only messages that are (not) on hold\", func(v string) error {\n\t\tvar hold bool\n\t\tif v == \"true\" {\n\t\t\thold = true\n\t\t} else if v == \"false\" {\n\t\t\thold = false\n\t\t} else {\n\t\t\treturn fmt.Errorf(\"bad value %q\", v)\n\t\t}\n\t\tf.Hold = &hold\n\t\treturn nil\n\t})\n\tif s != nil {\n\t\tfs.Func(\"sort\", `field to sort by, \"nextattempt\" (default) or \"queued\"`, func(v string) error {\n\t\t\tswitch v {\n\t\t\tcase \"nextattempt\":\n\t\t\t\ts.Field = \"NextAttempt\"\n\t\t\tcase \"queued\":\n\t\t\t\ts.Field = \"Queued\"\n\t\t\tdefault:\n\t\t\t\treturn fmt.Errorf(\"unknown value %q\", v)\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t\tfs.BoolVar(&s.Asc, \"asc\", false, \"sort ascending instead of descending (default)\")\n\t}\n}\n\n// flagRetiredFilterSort has filters for retired messages.\nfunc flagRetiredFilterSort(fs *flag.FlagSet, f *queue.RetiredFilter, s *queue.RetiredSort) {\n\tfs.Func(\"ids\", \"comma-separated list of retired message IDs\", func(v string) error {\n\t\tfor _, s := range strings.Split(v, \",\") {\n\t\t\tid, err := strconv.ParseInt(s, 10, 64)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tf.IDs = append(f.IDs, id)\n\t\t}\n\t\treturn nil\n\t})\n\tfs.IntVar(&f.Max, \"n\", 0, \"number of messages to return\")\n\tfs.StringVar(&f.Account, \"account\", \"\", \"account that queued the message\")\n\tfs.StringVar(&f.From, \"from\", \"\", `from address of message, use \"@example.com\" to match all messages for a domain`)\n\tfs.StringVar(&f.To, \"to\", \"\", `recipient address of message, use \"@example.com\" to match all messages for a domain`)\n\tfs.StringVar(&f.Submitted, \"submitted\", \"\", `filter by time of submission relative to now, value must start with \"<\" (before now) or \">\" (after now)`)\n\tfs.StringVar(&f.LastActivity, \"lastactivity\", \"\", `filter by time of last activity relative to now, value must start with \"<\" (before now) or \">\" (after now)`)\n\tfs.Func(\"transport\", \"transport to use for messages, empty string sets the default behaviour\", func(v string) error {\n\t\tf.Transport = &v\n\t\treturn nil\n\t})\n\tfs.Func(\"result\", `\"success\" or \"failure\" as result of delivery`, func(v string) error {\n\t\tswitch v {\n\t\tcase \"success\":\n\t\t\tt := true\n\t\t\tf.Success = &t\n\t\tcase \"failure\":\n\t\t\tt := false\n\t\t\tf.Success = &t\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"bad argument %q, need success or failure\", v)\n\t\t}\n\t\treturn nil\n\t})\n\tif s != nil {\n\t\tfs.Func(\"sort\", `field to sort by, \"lastactivity\" (default) or \"queued\"`, func(v string) error {\n\t\t\tswitch v {\n\t\t\tcase \"lastactivity\":\n\t\t\t\ts.Field = \"LastActivity\"\n\t\t\tcase \"queued\":\n\t\t\t\ts.Field = \"Queued\"\n\t\t\tdefault:\n\t\t\t\treturn fmt.Errorf(\"unknown value %q\", v)\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t\tfs.BoolVar(&s.Asc, \"asc\", false, \"sort ascending instead of descending (default)\")\n\t}\n}\n\nfunc cmdQueueList(c *cmd) {\n\tc.params = \"[filtersortflags]\"\n\tc.help = `List matching messages in the delivery queue.\n\nPrints the message with its ID, last and next delivery attempts, last error.\n`\n\tvar f queue.Filter\n\tvar s queue.Sort\n\tflagFilterSort(c.flag, &f, &s)\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueList(xctl(), f, s)\n}\n\nfunc ctlcmdQueueList(ctl *ctl, f queue.Filter, s queue.Sort) {\n\tctl.xwrite(\"queuelist\")\n\txctlwriteJSON(ctl, f)\n\txctlwriteJSON(ctl, s)\n\tctl.xreadok()\n\tif _, err := io.Copy(os.Stdout, ctl.reader()); err != nil {\n\t\tlog.Fatalf(\"%s\", err)\n\t}\n}\n\nfunc cmdQueueHold(c *cmd) {\n\tc.params = \"[filterflags]\"\n\tc.help = `Mark matching messages on hold.\n\nMessages that are on hold are not delivered until marked as off hold again, or\notherwise handled by the admin.\n`\n\tvar f queue.Filter\n\tflagFilterSort(c.flag, &f, nil)\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueHoldSet(xctl(), f, true)\n}\n\nfunc cmdQueueUnhold(c *cmd) {\n\tc.params = \"[filterflags]\"\n\tc.help = `Mark matching messages off hold.\n\nOnce off hold, messages can be delivered according to their current next\ndelivery attempt. See the \"queue schedule\" command.\n`\n\tvar f queue.Filter\n\tflagFilterSort(c.flag, &f, nil)\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueHoldSet(xctl(), f, false)\n}\n\nfunc ctlcmdQueueHoldSet(ctl *ctl, f queue.Filter, hold bool) {\n\tctl.xwrite(\"queueholdset\")\n\txctlwriteJSON(ctl, f)\n\tif hold {\n\t\tctl.xwrite(\"true\")\n\t} else {\n\t\tctl.xwrite(\"false\")\n\t}\n\tline := ctl.xread()\n\tif line == \"ok\" {\n\t\tfmt.Printf(\"%s messages changed\\n\", ctl.xread())\n\t} else {\n\t\tlog.Fatalf(\"%s\", line)\n\t}\n}\n\nfunc cmdQueueSchedule(c *cmd) {\n\tc.params = \"[filterflags] [-now] duration\"\n\tc.help = `Change next delivery attempt for matching messages.\n\nThe next delivery attempt is adjusted by the duration parameter. If the -now\nflag is set, the new delivery attempt is set to the duration added to the\ncurrent time, instead of added to the current scheduled time.\n\nSchedule immediate delivery with \"mox queue schedule -now 0\".\n`\n\tvar fromNow bool\n\tc.flag.BoolVar(&fromNow, \"now\", false, \"schedule for duration relative to current time instead of relative to current next delivery attempt for messages\")\n\tvar f queue.Filter\n\tflagFilterSort(c.flag, &f, nil)\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\td, err := time.ParseDuration(args[0])\n\txcheckf(err, \"parsing duration %q\", args[0])\n\tmustLoadConfig()\n\tctlcmdQueueSchedule(xctl(), f, fromNow, d)\n}\n\nfunc ctlcmdQueueSchedule(ctl *ctl, f queue.Filter, fromNow bool, d time.Duration) {\n\tctl.xwrite(\"queueschedule\")\n\txctlwriteJSON(ctl, f)\n\tif fromNow {\n\t\tctl.xwrite(\"yes\")\n\t} else {\n\t\tctl.xwrite(\"\")\n\t}\n\tctl.xwrite(d.String())\n\tline := ctl.xread()\n\tif line == \"ok\" {\n\t\tfmt.Printf(\"%s message(s) rescheduled\\n\", ctl.xread())\n\t} else {\n\t\tlog.Fatalf(\"%s\", line)\n\t}\n}\n\nfunc cmdQueueTransport(c *cmd) {\n\tc.params = \"[filterflags] transport\"\n\tc.help = `Set transport for matching messages.\n\nBy default, the routing rules determine how a message is delivered. The default\nand common case is direct delivery with SMTP. Messages can get a previously\nconfigured transport assigned to use for delivery, e.g. using submission to\nanother mail server or with connections over a SOCKS proxy.\n`\n\tvar f queue.Filter\n\tflagFilterSort(c.flag, &f, nil)\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueTransport(xctl(), f, args[0])\n}\n\nfunc ctlcmdQueueTransport(ctl *ctl, f queue.Filter, transport string) {\n\tctl.xwrite(\"queuetransport\")\n\txctlwriteJSON(ctl, f)\n\tctl.xwrite(transport)\n\tline := ctl.xread()\n\tif line == \"ok\" {\n\t\tfmt.Printf(\"%s message(s) changed\\n\", ctl.xread())\n\t} else {\n\t\tlog.Fatalf(\"%s\", line)\n\t}\n}\n\nfunc cmdQueueRequireTLS(c *cmd) {\n\tc.params = \"[filterflags] {yes | no | default}\"\n\tc.help = `Set TLS requirements for delivery of matching messages.\n\nValue \"yes\" is handled as if the RequireTLS extension was specified during\nsubmission.\n\nValue \"no\" is handled as if the message has a header \"TLS-Required: No\". This\nheader is not added by the queue. If messages without this header are relayed\nthrough other mail servers they will apply their own default TLS policy.\n\nValue \"default\" is the default behaviour, currently for unverified opportunistic\nTLS.\n`\n\tvar f queue.Filter\n\tflagFilterSort(c.flag, &f, nil)\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\tvar tlsreq *bool\n\tswitch args[0] {\n\tcase \"yes\":\n\t\tv := true\n\t\ttlsreq = &v\n\tcase \"no\":\n\t\tv := false\n\t\ttlsreq = &v\n\tcase \"default\":\n\tdefault:\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueRequireTLS(xctl(), f, tlsreq)\n}\n\nfunc ctlcmdQueueRequireTLS(ctl *ctl, f queue.Filter, tlsreq *bool) {\n\tctl.xwrite(\"queuerequiretls\")\n\txctlwriteJSON(ctl, f)\n\tvar req string\n\tif tlsreq == nil {\n\t\treq = \"\"\n\t} else if *tlsreq {\n\t\treq = \"true\"\n\t} else {\n\t\treq = \"false\"\n\t}\n\tctl.xwrite(req)\n\tline := ctl.xread()\n\tif line == \"ok\" {\n\t\tfmt.Printf(\"%s message(s) changed\\n\", ctl.xread())\n\t} else {\n\t\tlog.Fatalf(\"%s\", line)\n\t}\n}\n\nfunc cmdQueueFail(c *cmd) {\n\tc.params = \"[filterflags]\"\n\tc.help = `Fail delivery of matching messages, delivering DSNs.\n\nFailing a message is handled similar to how delivery is given up after all\ndelivery attempts failed. The DSN (delivery status notification) message\ncontains a line saying the message was canceled by the admin.\n`\n\tvar f queue.Filter\n\tflagFilterSort(c.flag, &f, nil)\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueFail(xctl(), f)\n}\n\nfunc ctlcmdQueueFail(ctl *ctl, f queue.Filter) {\n\tctl.xwrite(\"queuefail\")\n\txctlwriteJSON(ctl, f)\n\tline := ctl.xread()\n\tif line == \"ok\" {\n\t\tfmt.Printf(\"%s message(s) marked as failed\\n\", ctl.xread())\n\t} else {\n\t\tlog.Fatalf(\"%s\", line)\n\t}\n}\n\nfunc cmdQueueDrop(c *cmd) {\n\tc.params = \"[filterflags]\"\n\tc.help = `Remove matching messages from the queue.\n\nDangerous operation, this completely removes the message. If you want to store\nthe message, use \"queue dump\" before removing.\n`\n\tvar f queue.Filter\n\tflagFilterSort(c.flag, &f, nil)\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueDrop(xctl(), f)\n}\n\nfunc ctlcmdQueueDrop(ctl *ctl, f queue.Filter) {\n\tctl.xwrite(\"queuedrop\")\n\txctlwriteJSON(ctl, f)\n\tline := ctl.xread()\n\tif line == \"ok\" {\n\t\tfmt.Printf(\"%s message(s) dropped\\n\", ctl.xread())\n\t} else {\n\t\tlog.Fatalf(\"%s\", line)\n\t}\n}\n\nfunc cmdQueueDump(c *cmd) {\n\tc.params = \"id\"\n\tc.help = `Dump a message from the queue.\n\nThe message is printed to stdout and is in standard internet mail format.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueDump(xctl(), args[0])\n}\n\nfunc ctlcmdQueueDump(ctl *ctl, id string) {\n\tctl.xwrite(\"queuedump\")\n\tctl.xwrite(id)\n\tctl.xreadok()\n\tif _, err := io.Copy(os.Stdout, ctl.reader()); err != nil {\n\t\tlog.Fatalf(\"%s\", err)\n\t}\n}\n\nfunc cmdQueueSuppressList(c *cmd) {\n\tc.params = \"[-account account]\"\n\tc.help = `Print addresses in suppression list.`\n\tvar account string\n\tc.flag.StringVar(&account, \"account\", \"\", \"only show suppression list for this account\")\n\targs := c.Parse()\n\tif len(args) != 0 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueSuppressList(xctl(), account)\n}\n\nfunc ctlcmdQueueSuppressList(ctl *ctl, account string) {\n\tctl.xwrite(\"queuesuppresslist\")\n\tctl.xwrite(account)\n\tctl.xreadok()\n\tif _, err := io.Copy(os.Stdout, ctl.reader()); err != nil {\n\t\tlog.Fatalf(\"%s\", err)\n\t}\n}\n\nfunc cmdQueueSuppressAdd(c *cmd) {\n\tc.params = \"account address\"\n\tc.help = `Add address to suppression list for account.`\n\targs := c.Parse()\n\tif len(args) != 2 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueSuppressAdd(xctl(), args[0], args[1])\n}\n\nfunc ctlcmdQueueSuppressAdd(ctl *ctl, account, address string) {\n\tctl.xwrite(\"queuesuppressadd\")\n\tctl.xwrite(account)\n\tctl.xwrite(address)\n\tctl.xreadok()\n}\n\nfunc cmdQueueSuppressRemove(c *cmd) {\n\tc.params = \"account address\"\n\tc.help = `Remove address from suppression list for account.`\n\targs := c.Parse()\n\tif len(args) != 2 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueSuppressRemove(xctl(), args[0], args[1])\n}\n\nfunc ctlcmdQueueSuppressRemove(ctl *ctl, account, address string) {\n\tctl.xwrite(\"queuesuppressremove\")\n\tctl.xwrite(account)\n\tctl.xwrite(address)\n\tctl.xreadok()\n}\n\nfunc cmdQueueSuppressLookup(c *cmd) {\n\tc.params = \"[-account account] address\"\n\tc.help = `Check if address is present in suppression list, for any or specific account.`\n\tvar account string\n\tc.flag.StringVar(&account, \"account\", \"\", \"only check address in specified account\")\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueSuppressLookup(xctl(), account, args[0])\n}\n\nfunc ctlcmdQueueSuppressLookup(ctl *ctl, account, address string) {\n\tctl.xwrite(\"queuesuppresslookup\")\n\tctl.xwrite(account)\n\tctl.xwrite(address)\n\tctl.xreadok()\n\tif _, err := io.Copy(os.Stdout, ctl.reader()); err != nil {\n\t\tlog.Fatalf(\"%s\", err)\n\t}\n}\n\nfunc cmdQueueRetiredList(c *cmd) {\n\tc.params = \"[filtersortflags]\"\n\tc.help = `List matching messages in the retired queue.\n\nPrints messages with their ID and results.\n`\n\tvar f queue.RetiredFilter\n\tvar s queue.RetiredSort\n\tflagRetiredFilterSort(c.flag, &f, &s)\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueRetiredList(xctl(), f, s)\n}\n\nfunc ctlcmdQueueRetiredList(ctl *ctl, f queue.RetiredFilter, s queue.RetiredSort) {\n\tctl.xwrite(\"queueretiredlist\")\n\txctlwriteJSON(ctl, f)\n\txctlwriteJSON(ctl, s)\n\tctl.xreadok()\n\tif _, err := io.Copy(os.Stdout, ctl.reader()); err != nil {\n\t\tlog.Fatalf(\"%s\", err)\n\t}\n}\n\nfunc cmdQueueRetiredPrint(c *cmd) {\n\tc.params = \"id\"\n\tc.help = `Print a message from the retired queue.\n\nPrints a JSON representation of the information from the retired queue.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueRetiredPrint(xctl(), args[0])\n}\n\nfunc ctlcmdQueueRetiredPrint(ctl *ctl, id string) {\n\tctl.xwrite(\"queueretiredprint\")\n\tctl.xwrite(id)\n\tctl.xreadok()\n\tif _, err := io.Copy(os.Stdout, ctl.reader()); err != nil {\n\t\tlog.Fatalf(\"%s\", err)\n\t}\n}\n\n// note: outgoing hook events are in queue/hooks.go, mox-/config.go, queue.go and webapi/gendoc.sh. keep in sync.\n\n// flagHookFilterSort is used by many of the queue commands to accept flags for\n// filtering the webhooks the operation applies to.\nfunc flagHookFilterSort(fs *flag.FlagSet, f *queue.HookFilter, s *queue.HookSort) {\n\tfs.Func(\"ids\", \"comma-separated list of webhook IDs\", func(v string) error {\n\t\tfor _, s := range strings.Split(v, \",\") {\n\t\t\tid, err := strconv.ParseInt(s, 10, 64)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tf.IDs = append(f.IDs, id)\n\t\t}\n\t\treturn nil\n\t})\n\tfs.IntVar(&f.Max, \"n\", 0, \"number of webhooks to return\")\n\tfs.StringVar(&f.Account, \"account\", \"\", \"account that queued the message/webhook\")\n\tfs.StringVar(&f.Submitted, \"submitted\", \"\", `filter by time of submission relative to now, value must start with \"<\" (before now) or \">\" (after now)`)\n\tfs.StringVar(&f.NextAttempt, \"nextattempt\", \"\", `filter by time of next delivery attempt relative to now, value must start with \"<\" (before now) or \">\" (after now)`)\n\tfs.Func(\"event\", `event this webhook is about: incoming, delivered, suppressed, delayed, failed, relayed, expanded, canceled, unrecognized`, func(v string) error {\n\t\tswitch v {\n\t\tcase \"incoming\", \"delivered\", \"suppressed\", \"delayed\", \"failed\", \"relayed\", \"expanded\", \"canceled\", \"unrecognized\":\n\t\t\tf.Event = v\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"invalid parameter %q\", v)\n\t\t}\n\t\treturn nil\n\t})\n\tif s != nil {\n\t\tfs.Func(\"sort\", `field to sort by, \"nextattempt\" (default) or \"queued\"`, func(v string) error {\n\t\t\tswitch v {\n\t\t\tcase \"nextattempt\":\n\t\t\t\ts.Field = \"NextAttempt\"\n\t\t\tcase \"queued\":\n\t\t\t\ts.Field = \"Queued\"\n\t\t\tdefault:\n\t\t\t\treturn fmt.Errorf(\"unknown value %q\", v)\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t\tfs.BoolVar(&s.Asc, \"asc\", false, \"sort ascending instead of descending (default)\")\n\t}\n}\n\n// flagHookRetiredFilterSort is used by many of the queue commands to accept flags\n// for filtering the webhooks the operation applies to.\nfunc flagHookRetiredFilterSort(fs *flag.FlagSet, f *queue.HookRetiredFilter, s *queue.HookRetiredSort) {\n\tfs.Func(\"ids\", \"comma-separated list of retired webhook IDs\", func(v string) error {\n\t\tfor _, s := range strings.Split(v, \",\") {\n\t\t\tid, err := strconv.ParseInt(s, 10, 64)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tf.IDs = append(f.IDs, id)\n\t\t}\n\t\treturn nil\n\t})\n\tfs.IntVar(&f.Max, \"n\", 0, \"number of webhooks to return\")\n\tfs.StringVar(&f.Account, \"account\", \"\", \"account that queued the message/webhook\")\n\tfs.StringVar(&f.Submitted, \"submitted\", \"\", `filter by time of submission relative to now, value must start with \"<\" (before now) or \">\" (after now)`)\n\tfs.StringVar(&f.LastActivity, \"lastactivity\", \"\", `filter by time of last activity relative to now, value must start with \"<\" (before now) or \">\" (after now)`)\n\tfs.Func(\"event\", `event this webhook is about: incoming, delivered, suppressed, delayed, failed, relayed, expanded, canceled, unrecognized`, func(v string) error {\n\t\tswitch v {\n\t\tcase \"incoming\", \"delivered\", \"suppressed\", \"delayed\", \"failed\", \"relayed\", \"expanded\", \"canceled\", \"unrecognized\":\n\t\t\tf.Event = v\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"invalid parameter %q\", v)\n\t\t}\n\t\treturn nil\n\t})\n\tif s != nil {\n\t\tfs.Func(\"sort\", `field to sort by, \"lastactivity\" (default) or \"queued\"`, func(v string) error {\n\t\t\tswitch v {\n\t\t\tcase \"lastactivity\":\n\t\t\t\ts.Field = \"LastActivity\"\n\t\t\tcase \"queued\":\n\t\t\t\ts.Field = \"Queued\"\n\t\t\tdefault:\n\t\t\t\treturn fmt.Errorf(\"unknown value %q\", v)\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t\tfs.BoolVar(&s.Asc, \"asc\", false, \"sort ascending instead of descending (default)\")\n\t}\n}\n\nfunc cmdQueueHookList(c *cmd) {\n\tc.params = \"[filtersortflags]\"\n\tc.help = `List matching webhooks in the queue.\n\nPrints list of webhooks, their IDs and basic information.\n`\n\tvar f queue.HookFilter\n\tvar s queue.HookSort\n\tflagHookFilterSort(c.flag, &f, &s)\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueHookList(xctl(), f, s)\n}\n\nfunc ctlcmdQueueHookList(ctl *ctl, f queue.HookFilter, s queue.HookSort) {\n\tctl.xwrite(\"queuehooklist\")\n\txctlwriteJSON(ctl, f)\n\txctlwriteJSON(ctl, s)\n\tctl.xreadok()\n\tif _, err := io.Copy(os.Stdout, ctl.reader()); err != nil {\n\t\tlog.Fatalf(\"%s\", err)\n\t}\n}\n\nfunc cmdQueueHookSchedule(c *cmd) {\n\tc.params = \"[filterflags] duration\"\n\tc.help = `Change next delivery attempt for matching webhooks.\n\nThe next delivery attempt is adjusted by the duration parameter. If the -now\nflag is set, the new delivery attempt is set to the duration added to the\ncurrent time, instead of added to the current scheduled time.\n\nSchedule immediate delivery with \"mox queue schedule -now 0\".\n`\n\tvar fromNow bool\n\tc.flag.BoolVar(&fromNow, \"now\", false, \"schedule for duration relative to current time instead of relative to current next delivery attempt for webhooks\")\n\tvar f queue.HookFilter\n\tflagHookFilterSort(c.flag, &f, nil)\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\td, err := time.ParseDuration(args[0])\n\txcheckf(err, \"parsing duration %q\", args[0])\n\tmustLoadConfig()\n\tctlcmdQueueHookSchedule(xctl(), f, fromNow, d)\n}\n\nfunc ctlcmdQueueHookSchedule(ctl *ctl, f queue.HookFilter, fromNow bool, d time.Duration) {\n\tctl.xwrite(\"queuehookschedule\")\n\txctlwriteJSON(ctl, f)\n\tif fromNow {\n\t\tctl.xwrite(\"yes\")\n\t} else {\n\t\tctl.xwrite(\"\")\n\t}\n\tctl.xwrite(d.String())\n\tline := ctl.xread()\n\tif line == \"ok\" {\n\t\tfmt.Printf(\"%s webhook(s) rescheduled\\n\", ctl.xread())\n\t} else {\n\t\tlog.Fatalf(\"%s\", line)\n\t}\n}\n\nfunc cmdQueueHookCancel(c *cmd) {\n\tc.params = \"[filterflags]\"\n\tc.help = `Fail delivery of matching webhooks.`\n\tvar f queue.HookFilter\n\tflagHookFilterSort(c.flag, &f, nil)\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueHookCancel(xctl(), f)\n}\n\nfunc ctlcmdQueueHookCancel(ctl *ctl, f queue.HookFilter) {\n\tctl.xwrite(\"queuehookcancel\")\n\txctlwriteJSON(ctl, f)\n\tline := ctl.xread()\n\tif line == \"ok\" {\n\t\tfmt.Printf(\"%s webhook(s)s marked as canceled\\n\", ctl.xread())\n\t} else {\n\t\tlog.Fatalf(\"%s\", line)\n\t}\n}\n\nfunc cmdQueueHookPrint(c *cmd) {\n\tc.params = \"id\"\n\tc.help = `Print details of a webhook from the queue.\n\nThe webhook is printed to stdout as JSON.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueHookPrint(xctl(), args[0])\n}\n\nfunc ctlcmdQueueHookPrint(ctl *ctl, id string) {\n\tctl.xwrite(\"queuehookprint\")\n\tctl.xwrite(id)\n\tctl.xreadok()\n\tif _, err := io.Copy(os.Stdout, ctl.reader()); err != nil {\n\t\tlog.Fatalf(\"%s\", err)\n\t}\n}\n\nfunc cmdQueueHookRetiredList(c *cmd) {\n\tc.params = \"[filtersortflags]\"\n\tc.help = `List matching webhooks in the retired queue.\n\nPrints list of retired webhooks, their IDs and basic information.\n`\n\tvar f queue.HookRetiredFilter\n\tvar s queue.HookRetiredSort\n\tflagHookRetiredFilterSort(c.flag, &f, &s)\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueHookRetiredList(xctl(), f, s)\n}\n\nfunc ctlcmdQueueHookRetiredList(ctl *ctl, f queue.HookRetiredFilter, s queue.HookRetiredSort) {\n\tctl.xwrite(\"queuehookretiredlist\")\n\txctlwriteJSON(ctl, f)\n\txctlwriteJSON(ctl, s)\n\tctl.xreadok()\n\tif _, err := io.Copy(os.Stdout, ctl.reader()); err != nil {\n\t\tlog.Fatalf(\"%s\", err)\n\t}\n}\n\nfunc cmdQueueHookRetiredPrint(c *cmd) {\n\tc.params = \"id\"\n\tc.help = `Print details of a webhook from the retired queue.\n\nThe retired webhook is printed to stdout as JSON.\n`\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\tmustLoadConfig()\n\tctlcmdQueueHookRetiredPrint(xctl(), args[0])\n}\n\nfunc ctlcmdQueueHookRetiredPrint(ctl *ctl, id string) {\n\tctl.xwrite(\"queuehookretiredprint\")\n\tctl.xwrite(id)\n\tctl.xreadok()\n\tif _, err := io.Copy(os.Stdout, ctl.reader()); err != nil {\n\t\tlog.Fatalf(\"%s\", err)\n\t}\n}\n"
        },
        {
          "name": "queue",
          "type": "tree",
          "content": null
        },
        {
          "name": "quickstart.go",
          "type": "blob",
          "size": 37.408203125,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto\"\n\t\"crypto/ecdsa\"\n\t\"crypto/elliptic\"\n\tcryptorand \"crypto/rand\"\n\t\"crypto/rsa\"\n\t\"crypto/x509\"\n\t\"encoding/pem\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/url\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"sort\"\n\t\"strings\"\n\t\"time\"\n\n\t_ \"embed\"\n\n\t\"golang.org/x/crypto/bcrypt\"\n\n\t\"github.com/mjl-/sconf\"\n\n\t\"github.com/mjl-/mox/admin\"\n\t\"github.com/mjl-/mox/config\"\n\t\"github.com/mjl-/mox/dns\"\n\t\"github.com/mjl-/mox/dnsbl\"\n\t\"github.com/mjl-/mox/mlog\"\n\t\"github.com/mjl-/mox/mox-\"\n\t\"github.com/mjl-/mox/smtp\"\n\t\"github.com/mjl-/mox/store\"\n)\n\n//go:embed mox.service\nvar moxService string\n\nfunc pwgen() string {\n\tchars := \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!@#$%^&*-_;:,<.>/\"\n\ts := \"\"\n\tbuf := make([]byte, 1)\n\tfor i := 0; i < 12; i++ {\n\t\tfor {\n\t\t\tcryptorand.Read(buf)\n\t\t\ti := int(buf[0])\n\t\t\tif i+len(chars) > 255 {\n\t\t\t\tcontinue // Prevent bias.\n\t\t\t}\n\t\t\ts += string(chars[i%len(chars)])\n\t\t\tbreak\n\t\t}\n\t}\n\treturn s\n}\n\nfunc cmdQuickstart(c *cmd) {\n\tc.params = \"[-skipdial] [-existing-webserver] [-hostname host] user@domain [user | uid]\"\n\tc.help = `Quickstart generates configuration files and prints instructions to quickly set up a mox instance.\n\nQuickstart writes configuration files, prints initial admin and account\npasswords, DNS records you should create. If you run it on Linux it writes a\nsystemd service file and prints commands to enable and start mox as service.\n\nAll output is written to quickstart.log for later reference.\n\nThe user or uid is optional, defaults to \"mox\", and is the user or uid/gid mox\nwill run as after initialization.\n\nQuickstart assumes mox will run on the machine you run quickstart on and uses\nits host name and public IPs. On many systems the hostname is not a fully\nqualified domain name, but only the first dns \"label\", e.g. \"mail\" in case of\n\"mail.example.org\". If so, quickstart does a reverse DNS lookup to find the\nhostname, and as fallback uses the label plus the domain of the email address\nyou specified. Use flag -hostname to explicitly specify the hostname mox will\nrun on.\n\nMox is by far easiest to operate if you let it listen on port 443 (HTTPS) and\n80 (HTTP). TLS will be fully automatic with ACME with Let's Encrypt.\n\nYou can run mox along with an existing webserver, but because of MTA-STS and\nautoconfig, you'll need to forward HTTPS traffic for two domains to mox. Run\n\"mox quickstart -existing-webserver ...\" to generate configuration files and\ninstructions for configuring mox along with an existing webserver.\n\nBut please first consider configuring mox on port 443. It can itself serve\ndomains with HTTP/HTTPS, including with automatic TLS with ACME, is easily\nconfigured through both configuration files and admin web interface, and can act\nas a reverse proxy (and static file server for that matter), so you can forward\ntraffic to your existing backend applications. Look for \"WebHandlers:\" in the\noutput of \"mox config describe-domains\" and see the output of\n\"mox config example webhandlers\".\n`\n\tvar existingWebserver bool\n\tvar hostname string\n\tvar skipDial bool\n\tc.flag.BoolVar(&existingWebserver, \"existing-webserver\", false, \"use if a webserver is already running, so mox won't listen on port 80 and 443; you'll have to provide tls certificates/keys, and configure the existing webserver as reverse proxy, forwarding requests to mox.\")\n\tc.flag.StringVar(&hostname, \"hostname\", \"\", \"hostname mox will run on, by default the hostname of the machine quickstart runs on; if specified, the IPs for the hostname are configured for the public listener\")\n\tc.flag.BoolVar(&skipDial, \"skipdial\", false, \"skip check for outgoing smtp (port 25) connectivity\")\n\targs := c.Parse()\n\tif len(args) != 1 && len(args) != 2 {\n\t\tc.Usage()\n\t}\n\n\t// Write all output to quickstart.log.\n\tlogfile, err := os.Create(\"quickstart.log\")\n\txcheckf(err, \"creating quickstart.log\")\n\n\torigStdout := os.Stdout\n\torigStderr := os.Stderr\n\tpiper, pipew, err := os.Pipe()\n\txcheckf(err, \"creating pipe for logging to logfile\")\n\tpipec := make(chan struct{})\n\tgo func() {\n\t\tio.Copy(io.MultiWriter(origStdout, logfile), piper)\n\t\tclose(pipec)\n\t}()\n\t// A single pipe, so writes to stdout and stderr don't get interleaved.\n\tos.Stdout = pipew\n\tos.Stderr = pipew\n\tlogClose := func() {\n\t\tpipew.Close()\n\t\t<-pipec\n\t\tos.Stdout = origStdout\n\t\tos.Stderr = origStderr\n\t\terr := logfile.Close()\n\t\txcheckf(err, \"closing quickstart.log\")\n\t}\n\tdefer logClose()\n\tlog.SetOutput(os.Stdout)\n\tfmt.Printf(\"(output is also written to quickstart.log)\\n\\n\")\n\tdefer fmt.Printf(\"\\n(output is also written to quickstart.log)\\n\")\n\n\t// We take care to cleanup created files when we error out.\n\t// We don't want to get a new user into trouble with half of the files\n\t// after encountering an error.\n\n\t// We use fatalf instead of log.Fatal* to cleanup files.\n\tvar cleanupPaths []string\n\tfatalf := func(format string, args ...any) {\n\t\t// We remove in reverse order because dirs would have been created first and must\n\t\t// be removed last, after their files have been removed.\n\t\tfor i := len(cleanupPaths) - 1; i >= 0; i-- {\n\t\t\tp := cleanupPaths[i]\n\t\t\tif err := os.Remove(p); err != nil {\n\t\t\t\tlog.Printf(\"cleaning up %q: %s\", p, err)\n\t\t\t}\n\t\t}\n\n\t\tlog.Printf(format, args...)\n\t\tlogClose()\n\t\tos.Exit(1)\n\t}\n\n\txwritefile := func(path string, data []byte, perm os.FileMode) {\n\t\tos.MkdirAll(filepath.Dir(path), 0770)\n\t\tf, err := os.OpenFile(path, os.O_WRONLY|os.O_CREATE|os.O_EXCL, perm)\n\t\tif err != nil {\n\t\t\tfatalf(\"creating file %q: %s\", path, err)\n\t\t}\n\t\tcleanupPaths = append(cleanupPaths, path)\n\t\t_, err = f.Write(data)\n\t\tif err == nil {\n\t\t\terr = f.Close()\n\t\t}\n\t\tif err != nil {\n\t\t\tfatalf(\"writing file %q: %s\", path, err)\n\t\t}\n\t}\n\n\taddr, err := smtp.ParseAddress(args[0])\n\tif err != nil {\n\t\tfatalf(\"parsing email address: %s\", err)\n\t}\n\taccountName := addr.Localpart.String()\n\tdomain := addr.Domain\n\n\tfor _, c := range accountName {\n\t\tif c > 0x7f {\n\t\t\tfmt.Printf(`NOTE: Username %q is not ASCII-only. It is recommended you also configure an\nASCII-only alias. Both for delivery of email from other systems, and for\nlogging in with IMAP.\n\n`, accountName)\n\t\t\tbreak\n\t\t}\n\t}\n\n\tresolver := dns.StrictResolver{}\n\t// We don't want to spend too much total time on the DNS lookups. Because DNS may\n\t// not work during quickstart, and we don't want to loop doing requests and having\n\t// to wait for a timeout each time.\n\tresolveCtx, resolveCancel := context.WithTimeout(context.Background(), 10*time.Second)\n\tdefer resolveCancel()\n\n\t// Some DNSSEC-verifying resolvers return unauthentic data for \".\", so we check \"com\".\n\tfmt.Printf(\"Checking if DNS resolvers are DNSSEC-verifying...\")\n\t_, resolverDNSSECResult, err := resolver.LookupNS(resolveCtx, \"com.\")\n\tif err != nil {\n\t\tfmt.Println(\"\")\n\t\tfatalf(\"checking dnssec support in resolver: %v\", err)\n\t} else if !resolverDNSSECResult.Authentic {\n\t\tfmt.Printf(`\n\nWARNING: It looks like the DNS resolvers configured on your system do not\nverify DNSSEC, or aren't trusted (by having loopback IPs or through \"options\ntrust-ad\" in /etc/resolv.conf).  Without DNSSEC, outbound delivery with SMTP\nused unprotected MX records, and SMTP STARTTLS connections cannot verify the TLS\ncertificate with DANE (based on a public key in DNS), and will fall back to\neither MTA-STS for verification, or use \"opportunistic TLS\" with no certificate\nverification.\n\nRecommended action: Install unbound, a DNSSEC-verifying recursive DNS resolver,\nensure it has DNSSEC root keys (see unbound-anchor), and enable support for\n\"extended dns errors\" (EDE, available since unbound v1.16.0, see below; not\nrequired, but it gives helpful error messages about DNSSEC failures instead of\ngeneric DNS SERVFAIL errors). Test with \"dig com. ns\" and look for \"ad\"\n(authentic data) in response \"flags\".\n\ncat <<EOF >/etc/unbound/unbound.conf.d/ede.conf\nserver:\n    ede: yes\n    val-log-level: 2\nEOF\n\nTroubleshooting hints:\n- Ensure /etc/resolv.conf has \"nameserver 127.0.0.1\". If the IP is 127.0.0.53,\n  DNS resolving is done by systemd-resolved. Make sure \"resolvconf\" isn't\n  overwriting /etc/resolv.conf (Debian has a package \"openresolv\" that makes this\n  easier). \"dig\" also shows to which IP the DNS request was sent.\n- Ensure unbound has DNSSEC root keys available. See unbound config option\n  \"auto-trust-anchor-file\" and the unbound-anchor command. Ensure the file exists.\n- Run \"./mox dns lookup ns com.\" to simulate the DNSSEC check done by mox. The\n  output should say \"with dnssec\".\n- The \"delv\" command can check whether a domain is DNSSEC-signed, but it does\n  its own DNSSEC verification instead of relying on the resolver, so you cannot\n  use it to check whether unbound is verifying DNSSEC correctly.\n- Increase logging in unbound, see options \"verbosity\" and \"log-queries\".\n\n`)\n\t} else {\n\t\tfmt.Println(\" OK\")\n\t}\n\n\t// We are going to find the (public) IPs to listen on and possibly the host name.\n\n\t// Start with reasonable defaults. We'll replace them specific IPs, if we can find them.\n\tprivateListenerIPs := []string{\"127.0.0.1\", \"::1\"}\n\tpublicListenerIPs := []string{\"0.0.0.0\", \"::\"}\n\tvar publicNATIPs []string // Actual public IP, but when it is NATed and machine doesn't have direct access.\n\tdefaultPublicListenerIPs := true\n\n\t// If we find IPs based on network interfaces, {public,private}ListenerIPs are set\n\t// based on these values.\n\tvar loopbackIPs, privateIPs, publicIPs []string\n\n\t// Gather IP addresses for public and private listeners.\n\t// We look at each network interface. If an interface has a private address, we\n\t// conservatively assume all addresses on that interface are private.\n\tifaces, err := net.Interfaces()\n\tif err != nil {\n\t\tfatalf(\"listing network interfaces: %s\", err)\n\t}\n\tparseAddrIP := func(s string) net.IP {\n\t\tif strings.HasPrefix(s, \"[\") && strings.HasSuffix(s, \"]\") {\n\t\t\ts = s[1 : len(s)-1]\n\t\t}\n\t\tip, _, _ := net.ParseCIDR(s)\n\t\treturn ip\n\t}\n\tfor _, iface := range ifaces {\n\t\tif iface.Flags&net.FlagUp == 0 {\n\t\t\tcontinue\n\t\t}\n\t\taddrs, err := iface.Addrs()\n\t\tif err != nil {\n\t\t\tfatalf(\"listing address for network interface: %s\", err)\n\t\t}\n\t\tif len(addrs) == 0 {\n\t\t\tcontinue\n\t\t}\n\n\t\t// todo: should we detect temporary/ephemeral ipv6 addresses and not add them?\n\t\tvar nonpublic bool\n\t\tfor _, addr := range addrs {\n\t\t\tip := parseAddrIP(addr.String())\n\t\t\tif ip.IsInterfaceLocalMulticast() || ip.IsLinkLocalMulticast() || ip.IsLinkLocalUnicast() || ip.IsMulticast() {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif ip.IsLoopback() || ip.IsPrivate() {\n\t\t\t\tnonpublic = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tfor _, addr := range addrs {\n\t\t\tip := parseAddrIP(addr.String())\n\t\t\tif ip == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif ip.IsInterfaceLocalMulticast() || ip.IsLinkLocalMulticast() || ip.IsLinkLocalUnicast() || ip.IsMulticast() {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif nonpublic {\n\t\t\t\tif ip.IsLoopback() {\n\t\t\t\t\tloopbackIPs = append(loopbackIPs, ip.String())\n\t\t\t\t} else {\n\t\t\t\t\tprivateIPs = append(privateIPs, ip.String())\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tpublicIPs = append(publicIPs, ip.String())\n\t\t\t}\n\t\t}\n\t}\n\n\tvar dnshostname dns.Domain\n\tif hostname == \"\" {\n\t\thostnameStr, err := os.Hostname()\n\t\tif err != nil {\n\t\t\tfatalf(\"hostname: %s\", err)\n\t\t}\n\t\tif strings.Contains(hostnameStr, \".\") {\n\t\t\tdnshostname, err = dns.ParseDomain(hostnameStr)\n\t\t\tif err != nil {\n\t\t\t\tfatalf(\"parsing hostname: %v\", err)\n\t\t\t}\n\t\t} else {\n\t\t\t// It seems Linux machines don't have a single FQDN configured. E.g. /etc/hostname\n\t\t\t// is just the name without domain. We'll look up the names for all IPs, and hope\n\t\t\t// to find a single FQDN name (with at least 1 dot).\n\t\t\tnames := map[string]struct{}{}\n\t\t\tif len(publicIPs) > 0 {\n\t\t\t\tfmt.Printf(\"Trying to find hostname by reverse lookup of public IPs %s...\", strings.Join(publicIPs, \", \"))\n\t\t\t}\n\t\t\tvar warned bool\n\t\t\twarnf := func(format string, args ...any) {\n\t\t\t\twarned = true\n\t\t\t\tfmt.Printf(\"\\n%s\", fmt.Sprintf(format, args...))\n\t\t\t}\n\t\t\tfor _, ip := range publicIPs {\n\t\t\t\trevctx, revcancel := context.WithTimeout(resolveCtx, 5*time.Second)\n\t\t\t\tdefer revcancel()\n\t\t\t\tl, _, err := resolver.LookupAddr(revctx, ip)\n\t\t\t\tif err != nil {\n\t\t\t\t\twarnf(\"WARNING: looking up reverse name(s) for %s: %v\", ip, err)\n\t\t\t\t}\n\t\t\t\tfor _, name := range l {\n\t\t\t\t\tif strings.Contains(name, \".\") {\n\t\t\t\t\t\tnames[name] = struct{}{}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tvar nameList []string\n\t\t\tfor k := range names {\n\t\t\t\tnameList = append(nameList, strings.TrimRight(k, \".\"))\n\t\t\t}\n\t\t\tsort.Slice(nameList, func(i, j int) bool {\n\t\t\t\treturn nameList[i] < nameList[j]\n\t\t\t})\n\t\t\tif len(nameList) == 0 {\n\t\t\t\tdnshostname, err = dns.ParseDomain(hostnameStr + \".\" + domain.Name())\n\t\t\t\tif err != nil {\n\t\t\t\t\tfmt.Println()\n\t\t\t\t\tfatalf(\"parsing hostname: %v\", err)\n\t\t\t\t}\n\t\t\t\twarnf(`WARNING: cannot determine hostname because the system name is not an FQDN and\nno public IPs resolving to an FQDN were found. Quickstart guessed the host name\nbelow. If it is not correct, please remove the generated config files and run\nquickstart again with the -hostname flag.\n\n\t\t%s\n`, dnshostname)\n\t\t\t} else {\n\t\t\t\tif len(nameList) > 1 {\n\t\t\t\t\twarnf(`WARNING: multiple hostnames found for the public IPs, using the first of: %s\nIf this is not correct, remove the generated config files and run quickstart\nagain with the -hostname flag.\n`, strings.Join(nameList, \", \"))\n\t\t\t\t}\n\t\t\t\tdnshostname, err = dns.ParseDomain(nameList[0])\n\t\t\t\tif err != nil {\n\t\t\t\t\tfmt.Println()\n\t\t\t\t\tfatalf(\"parsing hostname %s: %v\", nameList[0], err)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif warned {\n\t\t\t\tfmt.Printf(\"\\n\\n\")\n\t\t\t} else {\n\t\t\t\tfmt.Printf(\" found %s\\n\", dnshostname)\n\t\t\t}\n\t\t}\n\t} else {\n\t\t// Host name was explicitly configured on command-line. We'll try to use its public\n\t\t// IPs below.\n\t\tvar err error\n\t\tdnshostname, err = dns.ParseDomain(hostname)\n\t\tif err != nil {\n\t\t\tfatalf(\"parsing hostname: %v\", err)\n\t\t}\n\t}\n\n\tfmt.Printf(\"Looking up IPs for hostname %s...\", dnshostname)\n\tipctx, ipcancel := context.WithTimeout(resolveCtx, 5*time.Second)\n\tdefer ipcancel()\n\tips, domainDNSSECResult, err := resolver.LookupIPAddr(ipctx, dnshostname.ASCII+\".\")\n\tipcancel()\n\tvar xips []net.IPAddr\n\tvar hostIPs []string\n\tvar dnswarned bool\n\thostPrivate := len(ips) > 0\n\tfor _, ip := range ips {\n\t\tif !ip.IP.IsPrivate() {\n\t\t\thostPrivate = false\n\t\t}\n\t\t// During linux install, you may get an alias for you full hostname in /etc/hosts\n\t\t// resolving to 127.0.1.1, which would result in a false positive about the\n\t\t// hostname having a record. Filter it out. It is a bit surprising that hosts don't\n\t\t// otherwise know their FQDN.\n\t\tif ip.IP.IsLoopback() {\n\t\t\tdnswarned = true\n\t\t\tfmt.Printf(\"\\n\\nWARNING: Your hostname is resolving to a loopback IP address %s. This likely breaks email delivery to local accounts. /etc/hosts likely contains a line like %q. Either replace it with your actual IP(s), or remove the line.\\n\", ip.IP, fmt.Sprintf(\"%s %s\", ip.IP, dnshostname.ASCII))\n\t\t\tcontinue\n\t\t}\n\t\txips = append(xips, ip)\n\t\thostIPs = append(hostIPs, ip.String())\n\t}\n\tif err == nil && len(xips) == 0 {\n\t\t// todo: possibly check this by trying to resolve without using /etc/hosts?\n\t\terr = errors.New(\"hostname not in dns, probably only in /etc/hosts\")\n\t}\n\tips = xips\n\n\t// We may have found private and public IPs on the machine, and IPs for the host\n\t// name we think we should use. They may not match with each other. E.g. the public\n\t// IPs on interfaces could be different from the IPs for the host. We don't try to\n\t// detect all possible configs, but just generate what makes sense given whether we\n\t// found public/private/hostname IPs. If the user is doing sensible things, it\n\t// should be correct. But they should be checking the generated config file anyway.\n\t// And we do log which host name we are using, and whether we detected a NAT setup.\n\t// In the future, we may do an interactive setup that can guide the user better.\n\n\tif !hostPrivate && len(publicIPs) == 0 && len(privateIPs) > 0 {\n\t\t// We only have private IPs, assume we are behind a NAT and put the IPs of the host in NATIPs.\n\t\tpublicListenerIPs = privateIPs\n\t\tpublicNATIPs = hostIPs\n\t\tdefaultPublicListenerIPs = false\n\t\tif len(loopbackIPs) > 0 {\n\t\t\tprivateListenerIPs = loopbackIPs\n\t\t}\n\t} else {\n\t\tif len(hostIPs) > 0 {\n\t\t\tpublicListenerIPs = hostIPs\n\t\t\tdefaultPublicListenerIPs = false\n\n\t\t\t// Only keep private IPs that are not in host-based publicListenerIPs. For\n\t\t\t// internal-only setups, including integration tests.\n\t\t\tm := map[string]bool{}\n\t\t\tfor _, ip := range hostIPs {\n\t\t\t\tm[ip] = true\n\t\t\t}\n\t\t\tvar npriv []string\n\t\t\tfor _, ip := range privateIPs {\n\t\t\t\tif !m[ip] {\n\t\t\t\t\tnpriv = append(npriv, ip)\n\t\t\t\t}\n\t\t\t}\n\t\t\tsort.Strings(npriv)\n\t\t\tprivateIPs = npriv\n\t\t} else if len(publicIPs) > 0 {\n\t\t\tpublicListenerIPs = publicIPs\n\t\t\tdefaultPublicListenerIPs = false\n\t\t\thostIPs = publicIPs // For DNSBL check below.\n\t\t}\n\t\tif len(privateIPs) > 0 {\n\t\t\tprivateListenerIPs = append(privateIPs, loopbackIPs...)\n\t\t} else if len(loopbackIPs) > 0 {\n\t\t\tprivateListenerIPs = loopbackIPs\n\t\t}\n\t}\n\tif err != nil {\n\t\tif !dnswarned {\n\t\t\tfmt.Printf(\"\\n\")\n\t\t}\n\t\tdnswarned = true\n\t\tfmt.Printf(`\nWARNING: Quickstart assumed the hostname of this machine is %s and generates a\nconfig for that host, but could not retrieve that name from DNS:\n\n\t%s\n\nThis likely means one of two things:\n\n1. You don't have any DNS records for this machine at all. You should add them\n   before continuing.\n2. The hostname mentioned is not the correct host name of this machine. You will\n   have to replace the hostname in the suggested DNS records and generated\n   config/mox.conf file. Make sure your hostname resolves to your public IPs, and\n   your public IPs resolve back (reverse) to your hostname.\n\n\n`, dnshostname, err)\n\t} else if !domainDNSSECResult.Authentic {\n\t\tif !dnswarned {\n\t\t\tfmt.Printf(\"\\n\")\n\t\t}\n\t\tdnswarned = true\n\t\tfmt.Printf(`\nNOTE: It looks like the DNS records of your domain (zone) are not DNSSEC-signed.\nMail servers that send email to your domain, or receive email from your domain,\ncannot verify that the MX/SPF/DKIM/DMARC/MTA-STS records they receive are\nauthentic. DANE, for authenticated delivery without relying on a pool of\ncertificate authorities, requires DNSSEC, so will not be configured at this\ntime.\nRecommended action: Continue now, but consider enabling DNSSEC for your domain\nlater at your DNS operator, and adding DANE records for protecting incoming\nmessages over SMTP.\n\n`)\n\t}\n\n\tif !dnswarned {\n\t\tfmt.Printf(\" OK\\n\")\n\n\t\tvar l []string\n\t\ttype result struct {\n\t\t\tIP    string\n\t\t\tAddrs []string\n\t\t\tErr   error\n\t\t}\n\t\tresults := make(chan result)\n\t\tfor _, ip := range ips {\n\t\t\ts := ip.String()\n\t\t\tl = append(l, s)\n\t\t\tgo func() {\n\t\t\t\trevctx, revcancel := context.WithTimeout(resolveCtx, 5*time.Second)\n\t\t\t\tdefer revcancel()\n\t\t\t\taddrs, _, err := resolver.LookupAddr(revctx, s)\n\t\t\t\tresults <- result{s, addrs, err}\n\t\t\t}()\n\t\t}\n\t\tfmt.Printf(\"Looking up reverse names for IP(s) %s...\", strings.Join(l, \", \"))\n\t\tvar warned bool\n\t\twarnf := func(format string, args ...any) {\n\t\t\tfmt.Printf(\"\\nWARNING: %s\", fmt.Sprintf(format, args...))\n\t\t\twarned = true\n\t\t}\n\t\tfor i := 0; i < len(ips); i++ {\n\t\t\tr := <-results\n\t\t\tif r.Err != nil {\n\t\t\t\twarnf(\"looking up reverse name for %s: %v\", r.IP, r.Err)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif len(r.Addrs) != 1 {\n\t\t\t\twarnf(\"expected exactly 1 name for %s, got %d (%v)\", r.IP, len(r.Addrs), r.Addrs)\n\t\t\t}\n\t\t\tvar match bool\n\t\t\tfor i, a := range r.Addrs {\n\t\t\t\ta = strings.TrimRight(a, \".\")\n\t\t\t\tr.Addrs[i] = a // For potential error message below.\n\t\t\t\td, err := dns.ParseDomain(a)\n\t\t\t\tif err != nil {\n\t\t\t\t\twarnf(\"parsing reverse name %q for %s: %v\", a, r.IP, err)\n\t\t\t\t}\n\t\t\t\tif d == dnshostname {\n\t\t\t\t\tmatch = true\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !match {\n\t\t\t\twarnf(\"reverse name(s) %s for ip %s do not match hostname %s, which will cause other mail servers to reject incoming messages from this IP\", strings.Join(r.Addrs, \",\"), r.IP, dnshostname)\n\t\t\t}\n\t\t}\n\t\tif warned {\n\t\t\tfmt.Printf(\"\\n\\n\")\n\t\t} else {\n\t\t\tfmt.Printf(\" OK\\n\")\n\t\t}\n\t}\n\n\t// Check outgoing SMTP connectivity.\n\tif !skipDial {\n\t\tfmt.Printf(\"Checking if outgoing smtp connections can be made by connecting to gmail.com mx on port 25...\")\n\t\tmxctx, mxcancel := context.WithTimeout(context.Background(), 5*time.Second)\n\t\tmx, _, err := resolver.LookupMX(mxctx, \"gmail.com.\")\n\t\tmxcancel()\n\t\tif err == nil && len(mx) == 0 {\n\t\t\terr = errors.New(\"no mx records\")\n\t\t}\n\t\tvar ok bool\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"\\n\\nERROR: looking up gmail.com mx record: %s\\n\", err)\n\t\t} else {\n\t\t\tdialctx, dialcancel := context.WithTimeout(context.Background(), 10*time.Second)\n\t\t\td := net.Dialer{}\n\t\t\taddr := net.JoinHostPort(mx[0].Host, \"25\")\n\t\t\tconn, err := d.DialContext(dialctx, \"tcp\", addr)\n\t\t\tdialcancel()\n\t\t\tif err != nil {\n\t\t\t\tfmt.Printf(\"\\n\\nERROR: connecting to %s: %s\\n\", addr, err)\n\t\t\t} else {\n\t\t\t\tconn.Close()\n\t\t\t\tfmt.Printf(\" OK\\n\")\n\t\t\t\tok = true\n\t\t\t}\n\t\t}\n\t\tif !ok {\n\t\t\tfmt.Printf(`\nWARNING: Could not verify outgoing smtp connections can be made, outgoing\ndelivery may not be working. Many providers block outgoing smtp connections by\ndefault, requiring an explicit request or a cooldown period before allowing\noutgoing smtp connections. To send through a smarthost, configure a \"Transport\"\nin mox.conf and use it in \"Routes\" in domains.conf. See\n\"mox config example transport\".\n\n`)\n\t\t}\n\t}\n\n\tzones := []dns.Domain{\n\t\t{ASCII: \"sbl.spamhaus.org\"},\n\t\t{ASCII: \"bl.spamcop.net\"},\n\t}\n\tif len(hostIPs) > 0 {\n\t\tfmt.Printf(\"Checking whether host name IPs are listed in popular DNS block lists...\")\n\t\tvar listed bool\n\t\tfor _, zone := range zones {\n\t\t\tfor _, ip := range hostIPs {\n\t\t\t\tdnsblctx, dnsblcancel := context.WithTimeout(context.Background(), 5*time.Second)\n\t\t\t\tstatus, expl, err := dnsbl.Lookup(dnsblctx, c.log.Logger, resolver, zone, net.ParseIP(ip))\n\t\t\t\tdnsblcancel()\n\t\t\t\tif status == dnsbl.StatusPass {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\terrstr := \"\"\n\t\t\t\tif err != nil {\n\t\t\t\t\terrstr = fmt.Sprintf(\" (%s)\", err)\n\t\t\t\t}\n\t\t\t\tfmt.Printf(\"\\nWARNING: checking your public IP %s in DNS block list %s: %v %s%s\", ip, zone.Name(), status, expl, errstr)\n\t\t\t\tlisted = true\n\t\t\t}\n\t\t}\n\t\tif listed {\n\t\t\tlog.Printf(`\nOther mail servers are likely to reject email from IPs that are in a blocklist.\nIf all your IPs are in block lists, you will encounter problems delivering\nemail. Your IP may be in block lists only temporarily. To see if your IPs are\nlisted in more DNS block lists, visit:\n\n`)\n\t\t\tfor _, ip := range hostIPs {\n\t\t\t\tfmt.Printf(\"- https://multirbl.valli.org/lookup/%s.html\\n\", url.PathEscape(ip))\n\t\t\t}\n\t\t\tfmt.Printf(\"\\n\")\n\t\t} else {\n\t\t\tfmt.Printf(\" OK\\n\")\n\t\t}\n\t}\n\n\tif defaultPublicListenerIPs {\n\t\tlog.Printf(`\nWARNING: Could not find your public IP address(es). The \"public\" listener is\nconfigured to listen on 0.0.0.0 (IPv4) and :: (IPv6). If you don't change these\nto your actual public IP addresses, you will likely get \"address in use\" errors\nwhen starting mox because the \"internal\" listener binds to a specific IP\naddress on the same port(s). If you are behind a NAT, instead configure the\nactual public IPs in the listener's \"NATIPs\" option.\n\n`)\n\t}\n\tif len(publicNATIPs) > 0 {\n\t\tlog.Printf(`\nNOTE: Quickstart used the IPs of the host name of the mail server, but only\nfound private IPs on the machine. This indicates this machine is behind a NAT,\nso the host IPs were configured in the NATIPs field of the public listeners. If\nyou are behind a NAT that does not preserve the remote IPs of connections, you\nwill likely experience problems accepting email due to IP-based policies. For\nexample, SPF is a mechanism that checks if an IP address is allowed to send\nemail for a domain, and mox uses IP-based (non)junk classification, and IP-based\nrate-limiting both for accepting email and blocking bad actors (such as with too\nmany authentication failures).\n\n`)\n\t}\n\n\tfmt.Printf(\"\\n\")\n\n\tuser := \"mox\"\n\tif len(args) == 2 {\n\t\tuser = args[1]\n\t}\n\n\tdc := config.Dynamic{}\n\tsc := config.Static{\n\t\tDataDir:           filepath.FromSlash(\"../data\"),\n\t\tUser:              user,\n\t\tLogLevel:          \"debug\", // Help new users, they'll bring it back to info when it all works.\n\t\tHostname:          dnshostname.Name(),\n\t\tAdminPasswordFile: \"adminpasswd\",\n\t}\n\n\t// todo: let user specify an alternative fallback address?\n\t// Don't attempt to use a non-ascii localpart with Let's Encrypt, it won't work.\n\t// Messages to postmaster will get to the account too.\n\tvar contactEmail string\n\tif addr.Localpart.IsInternational() {\n\t\tcontactEmail = smtp.NewAddress(\"postmaster\", addr.Domain).Pack(false)\n\t} else {\n\t\tcontactEmail = addr.Pack(false)\n\t}\n\tif !existingWebserver {\n\t\tsc.ACME = map[string]config.ACME{\n\t\t\t\"letsencrypt\": {\n\t\t\t\tDirectoryURL:     \"https://acme-v02.api.letsencrypt.org/directory\",\n\t\t\t\tContactEmail:     contactEmail,\n\t\t\t\tIssuerDomainName: \"letsencrypt.org\",\n\t\t\t},\n\t\t}\n\t}\n\n\tdataDir := \"data\" // ../data is relative to config/\n\tos.MkdirAll(dataDir, 0770)\n\tadminpw := pwgen()\n\tadminpwhash, err := bcrypt.GenerateFromPassword([]byte(adminpw), bcrypt.DefaultCost)\n\tif err != nil {\n\t\tfatalf(\"generating hash for generated admin password: %s\", err)\n\t}\n\txwritefile(filepath.Join(\"config\", sc.AdminPasswordFile), adminpwhash, 0660)\n\tfmt.Printf(\"Admin password: %s\\n\", adminpw)\n\n\tpublic := config.Listener{\n\t\tIPs:    publicListenerIPs,\n\t\tNATIPs: publicNATIPs,\n\t}\n\tpublic.SMTP.Enabled = true\n\tpublic.Submissions.Enabled = true\n\tpublic.IMAPS.Enabled = true\n\n\tif existingWebserver {\n\t\thostbase := filepath.FromSlash(\"path/to/\" + dnshostname.Name())\n\t\tmtastsbase := filepath.FromSlash(\"path/to/mta-sts.\" + domain.Name())\n\t\tautoconfigbase := filepath.FromSlash(\"path/to/autoconfig.\" + domain.Name())\n\t\tmailbase := filepath.FromSlash(\"path/to/mail.\" + domain.Name())\n\t\tpublic.TLS = &config.TLS{\n\t\t\tKeyCerts: []config.KeyCert{\n\t\t\t\t{CertFile: hostbase + \"-chain.crt.pem\", KeyFile: hostbase + \".key.pem\"},\n\t\t\t\t{CertFile: mtastsbase + \"-chain.crt.pem\", KeyFile: mtastsbase + \".key.pem\"},\n\t\t\t\t{CertFile: autoconfigbase + \"-chain.crt.pem\", KeyFile: autoconfigbase + \".key.pem\"},\n\t\t\t},\n\t\t}\n\t\tif mailbase != hostbase {\n\t\t\tpublic.TLS.KeyCerts = append(public.TLS.KeyCerts, config.KeyCert{CertFile: mailbase + \"-chain.crt.pem\", KeyFile: mailbase + \".key.pem\"})\n\t\t}\n\n\t\tfmt.Println(\n\t\t\t`Placeholder paths to TLS certificates to be provided by the existing webserver\nhave been placed in config/mox.conf and need to be edited.\n\nNo private keys for the public listener have been generated for use with DANE.\nTo configure DANE (which requires DNSSEC), set config field HostPrivateKeyFiles\nin the \"public\" Listener to both RSA 2048-bit and ECDSA P-256 private key files\nand check the admin page for the needed DNS records.`)\n\n\t} else {\n\t\t// todo: we may want to generate a second set of keys, make the user already add it to the DNS, but keep the private key offline. would require config option to specify a public key only, so the dane records can be generated.\n\t\thostRSAPrivateKey, err := rsa.GenerateKey(cryptorand.Reader, 2048)\n\t\tif err != nil {\n\t\t\tfatalf(\"generating rsa private key for host: %s\", err)\n\t\t}\n\t\thostECDSAPrivateKey, err := ecdsa.GenerateKey(elliptic.P256(), cryptorand.Reader)\n\t\tif err != nil {\n\t\t\tfatalf(\"generating ecsa private key for host: %s\", err)\n\t\t}\n\t\tnow := time.Now()\n\t\ttimestamp := now.Format(\"20060102T150405\")\n\t\thostRSAPrivateKeyFile := filepath.Join(\"hostkeys\", fmt.Sprintf(\"%s.%s.%s.privatekey.pkcs8.pem\", dnshostname.Name(), timestamp, \"rsa2048\"))\n\t\thostECDSAPrivateKeyFile := filepath.Join(\"hostkeys\", fmt.Sprintf(\"%s.%s.%s.privatekey.pkcs8.pem\", dnshostname.Name(), timestamp, \"ecdsap256\"))\n\t\txwritehostkeyfile := func(path string, key crypto.Signer) {\n\t\t\tbuf, err := x509.MarshalPKCS8PrivateKey(key)\n\t\t\tif err != nil {\n\t\t\t\tfatalf(\"marshaling host private key to pkcs8 for %s: %s\", path, err)\n\t\t\t}\n\t\t\tvar b bytes.Buffer\n\t\t\tblock := pem.Block{\n\t\t\t\tType:  \"PRIVATE KEY\",\n\t\t\t\tBytes: buf,\n\t\t\t}\n\t\t\terr = pem.Encode(&b, &block)\n\t\t\tif err != nil {\n\t\t\t\tfatalf(\"pem-encoding host private key file for %s: %s\", path, err)\n\t\t\t}\n\t\t\txwritefile(path, b.Bytes(), 0600)\n\t\t}\n\t\txwritehostkeyfile(filepath.Join(\"config\", hostRSAPrivateKeyFile), hostRSAPrivateKey)\n\t\txwritehostkeyfile(filepath.Join(\"config\", hostECDSAPrivateKeyFile), hostECDSAPrivateKey)\n\n\t\tpublic.TLS = &config.TLS{\n\t\t\tACME: \"letsencrypt\",\n\t\t\tHostPrivateKeyFiles: []string{\n\t\t\t\thostRSAPrivateKeyFile,\n\t\t\t\thostECDSAPrivateKeyFile,\n\t\t\t},\n\t\t\tHostPrivateRSA2048Keys:   []crypto.Signer{hostRSAPrivateKey},\n\t\t\tHostPrivateECDSAP256Keys: []crypto.Signer{hostECDSAPrivateKey},\n\t\t}\n\t\tpublic.AutoconfigHTTPS.Enabled = true\n\t\tpublic.MTASTSHTTPS.Enabled = true\n\t\tpublic.WebserverHTTP.Enabled = true\n\t\tpublic.WebserverHTTPS.Enabled = true\n\t}\n\n\t// Suggest blocklists, but we'll comment them out after generating the config.\n\tfor _, zone := range zones {\n\t\tpublic.SMTP.DNSBLs = append(public.SMTP.DNSBLs, zone.Name())\n\t}\n\n\t// Monitor DNSBLs by default, without using them for incoming deliveries.\n\tfor _, zone := range zones {\n\t\tdc.MonitorDNSBLs = append(dc.MonitorDNSBLs, zone.Name())\n\t}\n\n\tinternal := config.Listener{\n\t\tIPs:      privateListenerIPs,\n\t\tHostname: \"localhost\",\n\t}\n\tinternal.AccountHTTP.Enabled = true\n\tinternal.AdminHTTP.Enabled = true\n\tinternal.WebmailHTTP.Enabled = true\n\tinternal.WebAPIHTTP.Enabled = true\n\tinternal.MetricsHTTP.Enabled = true\n\tif existingWebserver {\n\t\tinternal.AccountHTTP.Port = 1080\n\t\tinternal.AccountHTTP.Forwarded = true\n\t\tinternal.AdminHTTP.Port = 1080\n\t\tinternal.AdminHTTP.Forwarded = true\n\t\tinternal.WebmailHTTP.Port = 1080\n\t\tinternal.WebmailHTTP.Forwarded = true\n\t\tinternal.WebAPIHTTP.Port = 1080\n\t\tinternal.WebAPIHTTP.Forwarded = true\n\t\tinternal.AutoconfigHTTPS.Enabled = true\n\t\tinternal.AutoconfigHTTPS.Port = 81\n\t\tinternal.AutoconfigHTTPS.NonTLS = true\n\t\tinternal.MTASTSHTTPS.Enabled = true\n\t\tinternal.MTASTSHTTPS.Port = 81\n\t\tinternal.MTASTSHTTPS.NonTLS = true\n\t\tinternal.WebserverHTTP.Enabled = true\n\t\tinternal.WebserverHTTP.Port = 81\n\t}\n\n\tsc.Listeners = map[string]config.Listener{\n\t\t\"public\":   public,\n\t\t\"internal\": internal,\n\t}\n\tsc.Postmaster.Account = accountName\n\tsc.Postmaster.Mailbox = \"Postmaster\"\n\tsc.HostTLSRPT.Account = accountName\n\tsc.HostTLSRPT.Localpart = \"tls-reports\"\n\tsc.HostTLSRPT.Mailbox = \"TLSRPT\"\n\n\tmox.ConfigStaticPath = filepath.FromSlash(\"config/mox.conf\")\n\tmox.ConfigDynamicPath = filepath.FromSlash(\"config/domains.conf\")\n\n\tmox.Conf.DynamicLastCheck = time.Now() // Prevent error logging by Make calls below.\n\n\taccountConf := admin.MakeAccountConfig(addr)\n\tconst withMTASTS = true\n\tconfDomain, keyPaths, err := admin.MakeDomainConfig(context.Background(), domain, dnshostname, accountName, withMTASTS)\n\tif err != nil {\n\t\tfatalf(\"making domain config: %s\", err)\n\t}\n\tcleanupPaths = append(cleanupPaths, keyPaths...)\n\n\tdc.Domains = map[string]config.Domain{\n\t\tdomain.Name(): confDomain,\n\t}\n\tdc.Accounts = map[string]config.Account{\n\t\taccountName: accountConf,\n\t}\n\n\t// Build config in memory, so we can easily comment out the DNSBLs config.\n\tvar sb strings.Builder\n\tsc.CheckUpdates = true // Commented out below.\n\tif err := sconf.WriteDocs(&sb, &sc); err != nil {\n\t\tfatalf(\"generating static config: %v\", err)\n\t}\n\tconfstr := sb.String()\n\tconfstr = strings.ReplaceAll(confstr, \"\\nCheckUpdates: true\\n\", \"\\n#\\n# RECOMMENDED: please enable to stay up to date\\n#\\n#CheckUpdates: true\\n\")\n\tconfstr = strings.ReplaceAll(confstr, \"DNSBLs:\\n\", \"#DNSBLs:\\n\")\n\tfor _, bl := range public.SMTP.DNSBLs {\n\t\tconfstr = strings.ReplaceAll(confstr, \"- \"+bl+\"\\n\", \"#- \"+bl+\"\\n\")\n\t}\n\txwritefile(filepath.FromSlash(\"config/mox.conf\"), []byte(confstr), 0660)\n\n\t// Generate domains config, and add a commented out example for delivery to a mailing list.\n\tvar db bytes.Buffer\n\tif err := sconf.WriteDocs(&db, &dc); err != nil {\n\t\tfatalf(\"generating domains config: %v\", err)\n\t}\n\n\t// This approach is a bit horrible, but it generates a convenient\n\t// example that includes the comments. Though it is gone by the first\n\t// write of the file by mox.\n\todests := fmt.Sprintf(\"\\t\\tDestinations:\\n\\t\\t\\t%s: nil\\n\", addr.String())\n\tvar destsExample = struct {\n\t\tDestinations map[string]config.Destination\n\t}{\n\t\tDestinations: map[string]config.Destination{\n\t\t\taddr.String(): {\n\t\t\t\tRulesets: []config.Ruleset{\n\t\t\t\t\t{\n\t\t\t\t\t\tVerifiedDomain: \"list.example.org\",\n\t\t\t\t\t\tHeadersRegexp: map[string]string{\n\t\t\t\t\t\t\t\"^list-id$\": `<name\\.list\\.example\\.org>`,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tListAllowDomain: \"list.example.org\",\n\t\t\t\t\t\tMailbox:         \"Lists/Example\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\tvar destBuf strings.Builder\n\tif err := sconf.Describe(&destBuf, destsExample); err != nil {\n\t\tfatalf(\"describing destination example: %v\", err)\n\t}\n\tndests := odests + \"# If you receive email from mailing lists, you may want to configure them like the\\n# example below (remove the empty/false SMTPMailRegexp and IsForward).\\n# If you are receiving forwarded email, see the IsForwarded option in a Ruleset.\\n\"\n\tfor _, line := range strings.Split(destBuf.String(), \"\\n\")[1:] {\n\t\tndests += \"#\\t\\t\" + line + \"\\n\"\n\t}\n\tdconfstr := strings.ReplaceAll(db.String(), odests, ndests)\n\txwritefile(filepath.FromSlash(\"config/domains.conf\"), []byte(dconfstr), 0660)\n\n\t// Verify config.\n\tloadTLSKeyCerts := !existingWebserver\n\tmc, errs := mox.ParseConfig(context.Background(), c.log, filepath.FromSlash(\"config/mox.conf\"), true, loadTLSKeyCerts, false)\n\tif len(errs) > 0 {\n\t\tif len(errs) > 1 {\n\t\t\tlog.Printf(\"checking generated config, multiple errors:\")\n\t\t\tfor _, err := range errs {\n\t\t\t\tlog.Println(err)\n\t\t\t}\n\t\t\tfatalf(\"aborting due to multiple config errors\")\n\t\t}\n\t\tfatalf(\"checking generated config: %s\", errs[0])\n\t}\n\tmox.SetConfig(mc)\n\t// NOTE: Now that we've prepared the config, we can open the account\n\t// and set a passsword, and the public key for the DKIM private keys\n\t// are available for generating the DKIM DNS records below.\n\n\tconfDomain, ok := mc.Domain(domain)\n\tif !ok {\n\t\tfatalf(\"cannot find domain in new config\")\n\t}\n\n\tacc, _, err := store.OpenEmail(c.log, args[0])\n\tif err != nil {\n\t\tfatalf(\"open account: %s\", err)\n\t}\n\tcleanupPaths = append(cleanupPaths, dataDir, filepath.Join(dataDir, \"accounts\"), filepath.Join(dataDir, \"accounts\", accountName), filepath.Join(dataDir, \"accounts\", accountName, \"index.db\"))\n\n\tpassword := pwgen()\n\n\t// Kludge to cause no logging to be printed about setting a new password.\n\tloglevel := mox.Conf.Log[\"\"]\n\tmox.Conf.Log[\"\"] = mlog.LevelWarn\n\tmlog.SetConfig(mox.Conf.Log)\n\tif err := acc.SetPassword(c.log, password); err != nil {\n\t\tfatalf(\"setting password: %s\", err)\n\t}\n\tmox.Conf.Log[\"\"] = loglevel\n\tmlog.SetConfig(mox.Conf.Log)\n\n\tif err := acc.Close(); err != nil {\n\t\tfatalf(\"closing account: %s\", err)\n\t}\n\tfmt.Printf(\"IMAP, SMTP submission and HTTP account password for %s: %s\\n\\n\", args[0], password)\n\tfmt.Printf(`When configuring your email client, use the email address as username. If\nautoconfig/autodiscover does not work, use these settings:\n`)\n\tprintClientConfig(domain)\n\n\tif existingWebserver {\n\t\tfmt.Printf(`\nConfiguration files have been written to config/mox.conf and\nconfig/domains.conf.\n\nCreate the DNS records below, by adding them to your zone file or through the\nweb interface of your DNS operator. The admin interface can show these same\nrecords, and has a page to check they have been configured correctly.\n\nYou must configure your existing webserver to forward requests for:\n\n\thttps://mta-sts.%s/\n\thttps://autoconfig.%s/\n\nTo mox, at:\n\n\thttp://127.0.0.1:81\n\nIf it makes it easier to get a TLS certificate for %s, you can add a\nreverse proxy for that hostname too.\n\nYou must edit mox.conf and configure the paths to the TLS certificates and keys.\nThe paths are relative to config/ directory that holds mox.conf! To test if your\nconfig is valid, run:\n\n\t./mox config test\n\nThe DNS records to add:\n`, domain.ASCII, domain.ASCII, dnshostname.ASCII)\n\t} else {\n\t\tfmt.Printf(`\nConfiguration files have been written to config/mox.conf and\nconfig/domains.conf. You should review them. Then create the DNS records below,\nby adding them to your zone file or through the web interface of your DNS\noperator. You can also skip creating the DNS records and start mox immediately.\nThe admin interface can show these same records, and has a page to check they\nhave been configured correctly. The DNS records to add:\n`)\n\t}\n\n\t// We do not verify the records exist: If they don't exist, we would only be\n\t// priming dns caches with negative/absent records, causing our \"quick setup\" to\n\t// appear to fail or take longer than \"quick\".\n\n\trecords, err := admin.DomainRecords(confDomain, domain, domainDNSSECResult.Authentic, \"letsencrypt.org\", \"\")\n\tif err != nil {\n\t\tfatalf(\"making required DNS records\")\n\t}\n\tfmt.Print(\"\\n\\n\" + strings.Join(records, \"\\n\") + \"\\n\\n\\n\\n\")\n\n\tfmt.Printf(`WARNING: The configuration and DNS records above assume you do not currently\nhave email configured for your domain. If you do already have email configured,\nor if you are sending email for your domain from other machines/services, you\nshould understand the consequences of the DNS records above before\ncontinuing!\n`)\n\tif os.Getenv(\"MOX_DOCKER\") == \"\" {\n\t\tfmt.Printf(`\nYou can now start mox with \"./mox serve\", as root.\n`)\n\t} else {\n\t\tfmt.Printf(`\nYou can now start the mox container.\n`)\n\t}\n\tfmt.Printf(`\nFile ownership and permissions are automatically set correctly by mox when\nstarting up. On linux, you may want to enable mox as a systemd service.\n\n`)\n\n\t// For now, we only give service config instructions for linux when not running in docker.\n\tif runtime.GOOS == \"linux\" && os.Getenv(\"MOX_DOCKER\") == \"\" {\n\t\tpwd, err := os.Getwd()\n\t\tif err != nil {\n\t\t\tlog.Printf(\"current working directory: %v\", err)\n\t\t\tpwd = \"/home/mox\"\n\t\t}\n\t\tservice := strings.ReplaceAll(moxService, \"/home/mox\", pwd)\n\t\txwritefile(\"mox.service\", []byte(service), 0644)\n\t\tcleanupPaths = append(cleanupPaths, \"mox.service\")\n\t\tfmt.Printf(`See mox.service for a systemd service file. To enable and start:\n\n\tsudo chmod 644 mox.service\n\tsudo systemctl enable $PWD/mox.service\n\tsudo systemctl start mox.service\n\tsudo journalctl -f -u mox.service # See logs\n`)\n\t}\n\n\tfmt.Printf(`\nAfter starting mox, the web interfaces are served at:\n\nhttp://localhost/         - account (email address as username)\nhttp://localhost/webmail/ - webmail (email address as username)\nhttp://localhost/admin/   - admin (empty username)\n\nTo access these from your browser, run\n\"ssh -L 8080:localhost:80 you@yourmachine\" locally and open\nhttp://localhost:8080/[...].\n\nIf you run into problem, have questions/feedback or found a bug, please let us\nknow. Mox needs your help!\n\nEnjoy!\n`)\n\n\tif !existingWebserver {\n\t\tfmt.Printf(`\nPS: If you want to run mox along side an existing webserver that uses port 443\nand 80, see \"mox help quickstart\" with the -existing-webserver option.\n`)\n\t}\n\n\tcleanupPaths = nil\n}\n"
        },
        {
          "name": "ratelimit",
          "type": "tree",
          "content": null
        },
        {
          "name": "rfc",
          "type": "tree",
          "content": null
        },
        {
          "name": "sasl",
          "type": "tree",
          "content": null
        },
        {
          "name": "scram",
          "type": "tree",
          "content": null
        },
        {
          "name": "sendmail.go",
          "type": "blob",
          "size": 16.9833984375,
          "content": "package main\n\nimport (\n\t\"bufio\"\n\t\"context\"\n\t\"crypto\"\n\t\"crypto/ed25519\"\n\tcryptorand \"crypto/rand\"\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"encoding/base64\"\n\t\"encoding/pem\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"math/big\"\n\t\"net\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"slices\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/mjl-/sconf\"\n\n\t\"github.com/mjl-/mox/dns\"\n\t\"github.com/mjl-/mox/message\"\n\t\"github.com/mjl-/mox/mox-\"\n\t\"github.com/mjl-/mox/sasl\"\n\t\"github.com/mjl-/mox/smtp\"\n\t\"github.com/mjl-/mox/smtpclient\"\n)\n\nvar submitconf struct {\n\tLocalHostname                   string           `sconf-doc:\"Hosts don't always have an FQDN, set it explicitly, for EHLO.\"`\n\tHost                            string           `sconf-doc:\"Host to dial for delivery, e.g. mail.<domain>.\"`\n\tPort                            int              `sconf-doc:\"Port to dial for delivery, e.g. 465 for submissions, 587 for submission, or perhaps 25 for smtp.\"`\n\tTLS                             bool             `sconf-doc:\"Connect with TLS. Usually for connections to port 465.\"`\n\tSTARTTLS                        bool             `sconf-doc:\"After starting in plain text, use STARTTLS to enable TLS. For port 587 and 25.\"`\n\tTLSInsecureSkipVerify           bool             `sconf:\"optional\" sconf-doc:\"If true, do not verify the server TLS identity.\"`\n\tUsername                        string           `sconf-doc:\"For SMTP authentication.\"`\n\tPassword                        string           `sconf:\"optional\" sconf-doc:\"For password-based SMTP authentication, e.g. SCRAM-SHA-256-PLUS, CRAM-MD5, PLAIN.\"`\n\tClientAuthEd25519PrivateKey     string           `sconf:\"optional\" sconf-doc:\"If set, used for TLS client authentication with a certificate. The private key must be a raw-url-base64-encoded ed25519 key. A basic certificate is composed automatically. The server must use the public key of a certificate to identify/verify users.\"`\n\tClientAuthCertPrivateKeyPEMFile string           `sconf:\"optional\" sconf-doc:\"If set, an absolute path to a PEM file containing both a PKCS#8 unencrypted private key and a certificate. Used for TLS client authentication.\"`\n\tAuthMethod                      string           `sconf-doc:\"If set, only attempt this authentication mechanism. E.g. EXTERNAL (for TLS client authentication), SCRAM-SHA-256-PLUS, SCRAM-SHA-256, SCRAM-SHA-1-PLUS, SCRAM-SHA-1, CRAM-MD5, PLAIN. If not set, any mutually supported algorithm can be used, in order listed, from most to least secure. It is recommended to specify the strongest authentication mechanism known to be implemented by the server, to prevent mechanism downgrade attacks. Exactly one of Password, ClientAuthEd25519PrivateKey and ClientAuthCertPrivateKeyPEMFile must be set.\"`\n\tFrom                            string           `sconf-doc:\"Address for MAIL FROM in SMTP and From-header in message.\"`\n\tDefaultDestination              string           `sconf:\"optional\" sconf-doc:\"Used when specified address does not contain an @ and may be a local user (eg root).\"`\n\tRequireTLS                      RequireTLSOption `sconf:\"optional\" sconf-doc:\"If yes, submission server must implement SMTP REQUIRETLS extension, and connection to submission server must use verified TLS. If no, a TLS-Required header with value no is added to the message, allowing fallback to unverified TLS or plain text delivery despite recpient domain policies. By default, the submission server will follow the policies of the recipient domain (MTA-STS and/or DANE), and apply unverified opportunistic TLS with STARTTLS.\"`\n\n\t// For TLS client authentication with a certificate. Either from\n\t// ClientAuthEd25519PrivateKey or ClientAuthCertPrivateKeyPEMFile.\n\tclientCert *tls.Certificate\n}\n\ntype RequireTLSOption string\n\nconst (\n\tRequireTLSDefault RequireTLSOption = \"\"\n\tRequireTLSYes     RequireTLSOption = \"yes\"\n\tRequireTLSNo      RequireTLSOption = \"no\"\n)\n\nfunc cmdConfigDescribeSendmail(c *cmd) {\n\tc.params = \">/etc/moxsubmit.conf\"\n\tc.help = `Describe configuration for mox when invoked as sendmail.`\n\tif len(c.Parse()) != 0 {\n\t\tc.Usage()\n\t}\n\n\terr := sconf.Describe(os.Stdout, submitconf)\n\txcheckf(err, \"describe config\")\n}\n\nfunc cmdSendmail(c *cmd) {\n\tc.params = \"[-Fname] [ignoredflags] [-t] [<message]\"\n\tc.help = `Sendmail is a drop-in replacement for /usr/sbin/sendmail to deliver emails sent by unix processes like cron.\n\nIf invoked as \"sendmail\", it will act as sendmail for sending messages. Its\nintention is to let processes like cron send emails. Messages are submitted to\nan actual mail server over SMTP. The destination mail server and credentials are\nconfigured in /etc/moxsubmit.conf, see mox config describe-sendmail. The From\nmessage header is rewritten to the configured address. When the addressee\nappears to be a local user, because without @, the message is sent to the\nconfigured default address.\n\nIf submitting an email fails, it is added to a directory moxsubmit.failures in\nthe user's home directory.\n\nMost flags are ignored to fake compatibility with other sendmail\nimplementations. A single recipient or the -t flag with a To-header is required.\nWith the -t flag, Cc and Bcc headers are not handled specially, so Bcc is not\nremoved and the addresses do not receive the email.\n\n/etc/moxsubmit.conf should be group-readable and not readable by others and this\nbinary should be setgid that group:\n\n\tgroupadd moxsubmit\n\tinstall -m 2755 -o root -g moxsubmit mox /usr/sbin/sendmail\n\ttouch /etc/moxsubmit.conf\n\tchown root:moxsubmit /etc/moxsubmit.conf\n\tchmod 640 /etc/moxsubmit.conf\n\t# edit /etc/moxsubmit.conf\n`\n\n\t// We are faking that we parse flags, this is non-standard, we want to be lax and ignore most flags.\n\targs := c.flagArgs\n\tc.flagArgs = []string{}\n\tc.Parse() // We still have to call Parse for the usage gathering.\n\n\t// Typical cron usage of sendmail:\n\t// anacron: https://salsa.debian.org/debian/anacron/-/blob/c939c8c80fc9419c11a5e6be5cbe84f03ad332fd/runjob.c#L183\n\t// cron: https://github.com/vixie/cron/blob/fea7a6c5421f88f034be8eef66a84d8b65b5fbe0/config.h#L41\n\n\tvar from string\n\tvar tflag bool // If set, we need to take the recipient(s) from the message headers. We only do one recipient, in To.\n\to := 0\n\tfor i, s := range args {\n\t\tif s == \"--\" {\n\t\t\to = i + 1\n\t\t\tbreak\n\t\t}\n\t\tif !strings.HasPrefix(s, \"-\") {\n\t\t\to = i\n\t\t\tbreak\n\t\t}\n\t\ts = s[1:]\n\t\tif strings.HasPrefix(s, \"F\") {\n\t\t\tfrom = s[1:]\n\t\t\tlog.Printf(\"ignoring -F %q\", from) // todo\n\t\t} else if s == \"t\" {\n\t\t\ttflag = true\n\t\t}\n\t\to = i + 1\n\t\t// Ignore options otherwise.\n\t\t// todo: we may want to parse more flags. some invocations may not be about sending a message. for now, we'll assume sendmail is only invoked to send a message.\n\t}\n\targs = args[o:]\n\n\t// todo: perhaps allow configuration of config file through environment variable? have to keep in mind that mox with setgid moxsubmit would be reading the file.\n\tconst confPath = \"/etc/moxsubmit.conf\"\n\terr := sconf.ParseFile(confPath, &submitconf)\n\txcheckf(err, \"parsing config\")\n\n\tvar secrets []string\n\tfor _, s := range []string{submitconf.Password, submitconf.ClientAuthEd25519PrivateKey, submitconf.ClientAuthCertPrivateKeyPEMFile} {\n\t\tif s != \"\" {\n\t\t\tsecrets = append(secrets, s)\n\t\t}\n\t}\n\tif len(secrets) != 1 {\n\t\txcheckf(fmt.Errorf(\"got passwords/keys %s, need exactly one\", strings.Join(secrets, \", \")), \"checking passwords/keys\")\n\t}\n\tif submitconf.ClientAuthEd25519PrivateKey != \"\" {\n\t\tseed, err := base64.RawURLEncoding.DecodeString(submitconf.ClientAuthEd25519PrivateKey)\n\t\txcheckf(err, \"parsing ed25519 private key\")\n\t\tif len(seed) != ed25519.SeedSize {\n\t\t\txcheckf(fmt.Errorf(\"got %d bytes, need %d\", len(seed), ed25519.SeedSize), \"parsing ed25519 private key\")\n\t\t}\n\t\tprivKey := ed25519.NewKeyFromSeed(seed)\n\t\t_, cert := xminimalCert(privKey)\n\t\tsubmitconf.clientCert = &cert\n\t} else if submitconf.ClientAuthCertPrivateKeyPEMFile != \"\" {\n\t\tpemBuf, err := os.ReadFile(submitconf.ClientAuthCertPrivateKeyPEMFile)\n\t\txcheckf(err, \"reading pem file\")\n\t\tvar cert tls.Certificate\n\t\tfor {\n\t\t\tblock, rest := pem.Decode(pemBuf)\n\t\t\tif block == nil && len(rest) != 0 {\n\t\t\t\tlog.Printf(\"xxx, leftover data %q\", rest)\n\t\t\t\tlog.Fatalf(\"leftover data in pem file\")\n\t\t\t} else if block == nil {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tswitch block.Type {\n\t\t\tcase \"CERTIFICATE\":\n\t\t\t\tc, err := x509.ParseCertificate(block.Bytes)\n\t\t\t\txcheckf(err, \"parsing certificate\")\n\t\t\t\tif cert.Leaf == nil {\n\t\t\t\t\tcert.Leaf = c\n\t\t\t\t}\n\t\t\t\tcert.Certificate = append(cert.Certificate, block.Bytes)\n\t\t\tcase \"PRIVATE KEY\":\n\t\t\t\tif cert.PrivateKey != nil {\n\t\t\t\t\tlog.Fatalf(\"cannot handle multiple private keys\")\n\t\t\t\t}\n\t\t\t\tprivKey, err := x509.ParsePKCS8PrivateKey(block.Bytes)\n\t\t\t\txcheckf(err, \"parsing private key\")\n\t\t\t\tcert.PrivateKey = privKey\n\t\t\tdefault:\n\t\t\t\tlog.Fatalf(\"unrecognized pem type %q, only CERTIFICATE and PRIVATE KEY allowed\", block.Type)\n\t\t\t}\n\t\t\tpemBuf = rest\n\t\t}\n\t\tif len(cert.Certificate) == 0 {\n\t\t\tlog.Fatalf(\"no certificate(s) found in pem file\")\n\t\t}\n\t\tif cert.PrivateKey == nil {\n\t\t\tlog.Fatalf(\"no private key found in pem file\")\n\t\t}\n\t\ttype cryptoPublicKey interface {\n\t\t\tEqual(x crypto.PublicKey) bool\n\t\t}\n\t\tif !cert.PrivateKey.(crypto.Signer).Public().(cryptoPublicKey).Equal(cert.Leaf.PublicKey) {\n\t\t\tlog.Fatalf(\"certificate public key does not match with private key\")\n\t\t}\n\t\tsubmitconf.clientCert = &cert\n\t}\n\n\tvar recipient string\n\tif len(args) == 1 && !tflag {\n\t\trecipient = args[0]\n\t\tif !strings.Contains(recipient, \"@\") {\n\t\t\tif submitconf.DefaultDestination == \"\" {\n\t\t\t\tlog.Fatalf(\"recipient %q has no @ and no default destination configured\", recipient)\n\t\t\t}\n\t\t\trecipient = submitconf.DefaultDestination\n\t\t} else {\n\t\t\t_, err := smtp.ParseAddress(args[0])\n\t\t\txcheckf(err, \"parsing recipient address\")\n\t\t}\n\t} else if !tflag || len(args) != 0 {\n\t\tlog.Fatalln(\"need either exactly 1 recipient, or -t\")\n\t}\n\n\t// Read message and build message we are going to send. We replace \\n\n\t// with \\r\\n, and we replace the From header.\n\t// todo: should we also wrap lines that are too long? perhaps only if this is just text, no multipart?\n\tvar sb strings.Builder\n\tr := bufio.NewReader(os.Stdin)\n\theader := true // Whether we are in the header.\n\tfmt.Fprintf(&sb, \"From: <%s>\\r\\n\", submitconf.From)\n\tvar haveTo bool\n\tfor {\n\t\tline, err := r.ReadString('\\n')\n\t\tif err != nil && err != io.EOF {\n\t\t\txcheckf(err, \"reading message\")\n\t\t}\n\t\tif line != \"\" {\n\t\t\tif !strings.HasSuffix(line, \"\\n\") {\n\t\t\t\tline += \"\\n\"\n\t\t\t}\n\t\t\tif !strings.HasSuffix(line, \"\\r\\n\") {\n\t\t\t\tline = line[:len(line)-1] + \"\\r\\n\"\n\t\t\t}\n\t\t\tif header && line == \"\\r\\n\" {\n\t\t\t\t// Bare \\r\\n marks end of header.\n\t\t\t\tif !haveTo {\n\t\t\t\t\tline = fmt.Sprintf(\"To: <%s>\\r\\n\", recipient) + line\n\t\t\t\t}\n\t\t\t\tif submitconf.RequireTLS == RequireTLSNo {\n\t\t\t\t\tline = \"TLS-Required: No\\r\\n\" + line\n\t\t\t\t}\n\t\t\t\theader = false\n\t\t\t} else if header {\n\t\t\t\tt := strings.SplitN(line, \":\", 2)\n\t\t\t\tif len(t) != 2 {\n\t\t\t\t\tlog.Fatalf(\"invalid message, missing colon in header\")\n\t\t\t\t}\n\t\t\t\tk := strings.ToLower(t[0])\n\t\t\t\tif k == \"from\" {\n\t\t\t\t\t// We already added a From header.\n\t\t\t\t\tif err == io.EOF {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t\tcontinue\n\t\t\t\t} else if tflag && k == \"to\" {\n\t\t\t\t\tif recipient != \"\" {\n\t\t\t\t\t\tlog.Fatalf(\"only single To header allowed\")\n\t\t\t\t\t}\n\t\t\t\t\ts := strings.TrimSpace(t[1])\n\t\t\t\t\tif !strings.Contains(s, \"@\") {\n\t\t\t\t\t\tif submitconf.DefaultDestination == \"\" {\n\t\t\t\t\t\t\tlog.Fatalf(\"recipient %q has no @ and no default destination is configured\", s)\n\t\t\t\t\t\t}\n\t\t\t\t\t\trecipient = submitconf.DefaultDestination\n\t\t\t\t\t} else {\n\t\t\t\t\t\taddrs, err := message.ParseAddressList(s)\n\t\t\t\t\t\txcheckf(err, \"parsing To address list\")\n\t\t\t\t\t\tif len(addrs) != 1 {\n\t\t\t\t\t\t\tlog.Fatalf(\"only single address allowed in To header\")\n\t\t\t\t\t\t}\n\t\t\t\t\t\trecipient = addrs[0].User + \"@\" + addrs[0].Host\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif k == \"to\" {\n\t\t\t\t\thaveTo = true\n\t\t\t\t}\n\t\t\t}\n\t\t\tsb.WriteString(line)\n\t\t}\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t}\n\t}\n\tif header && submitconf.RequireTLS == RequireTLSNo {\n\t\tsb.WriteString(\"TLS-Required: No\\r\\n\")\n\t}\n\tmsg := sb.String()\n\n\tif recipient == \"\" {\n\t\tlog.Fatalf(\"no recipient\")\n\t}\n\n\t// Message seems acceptable. We'll try to deliver it from here. If that fails, we\n\t// store the message in the users home directory.\n\t// Must only use xsavecheckf for error checking in the code below.\n\n\txsavecheckf := func(err error, format string, args ...any) {\n\t\tif err == nil {\n\t\t\treturn\n\t\t}\n\t\tlog.Printf(\"submit failed: %s: %s\", fmt.Sprintf(format, args...), err)\n\t\thomedir, err := os.UserHomeDir()\n\t\txcheckf(err, \"finding homedir for storing message after failed delivery\")\n\t\tmaildir := filepath.Join(homedir, \"moxsubmit.failures\")\n\t\tos.Mkdir(maildir, 0700)\n\t\tf, err := os.CreateTemp(maildir, \"newmsg.\")\n\t\txcheckf(err, \"creating temp file for storing message after failed delivery\")\n\t\t// note: not removing the partial file if writing/closing below fails.\n\t\t_, err = f.Write([]byte(msg))\n\t\txcheckf(err, \"writing message to temp file after failed delivery\")\n\t\tname := f.Name()\n\t\terr = f.Close()\n\t\txcheckf(err, \"closing message in temp file after failed delivery\")\n\t\tf = nil\n\t\tlog.Printf(\"saved message in %s\", name)\n\t\tos.Exit(1)\n\t}\n\n\taddr := net.JoinHostPort(submitconf.Host, fmt.Sprintf(\"%d\", submitconf.Port))\n\td := net.Dialer{Timeout: 30 * time.Second}\n\tconn, err := d.Dial(\"tcp\", addr)\n\txsavecheckf(err, \"dial submit server\")\n\n\tauth := func(mechanisms []string, cs *tls.ConnectionState) (sasl.Client, error) {\n\t\t// Check explicitly configured mechanisms.\n\t\tswitch submitconf.AuthMethod {\n\t\tcase \"EXTERNAL\":\n\t\t\treturn sasl.NewClientExternal(submitconf.Username), nil\n\t\tcase \"SCRAM-SHA-256-PLUS\":\n\t\t\tif cs == nil {\n\t\t\t\treturn nil, fmt.Errorf(\"scram plus authentication mechanism requires tls\")\n\t\t\t}\n\t\t\treturn sasl.NewClientSCRAMSHA256PLUS(submitconf.Username, submitconf.Password, *cs), nil\n\t\tcase \"SCRAM-SHA-256\":\n\t\t\treturn sasl.NewClientSCRAMSHA256(submitconf.Username, submitconf.Password, false), nil\n\t\tcase \"SCRAM-SHA-1-PLUS\":\n\t\t\tif cs == nil {\n\t\t\t\treturn nil, fmt.Errorf(\"scram plus authentication mechanism requires tls\")\n\t\t\t}\n\t\t\treturn sasl.NewClientSCRAMSHA1PLUS(submitconf.Username, submitconf.Password, *cs), nil\n\t\tcase \"SCRAM-SHA-1\":\n\t\t\treturn sasl.NewClientSCRAMSHA1(submitconf.Username, submitconf.Password, false), nil\n\t\tcase \"CRAM-MD5\":\n\t\t\treturn sasl.NewClientCRAMMD5(submitconf.Username, submitconf.Password), nil\n\t\tcase \"PLAIN\":\n\t\t\treturn sasl.NewClientPlain(submitconf.Username, submitconf.Password), nil\n\t\t}\n\n\t\t// Try the defaults, from more to less secure.\n\t\tif cs != nil && submitconf.clientCert != nil {\n\t\t\treturn sasl.NewClientExternal(submitconf.Username), nil\n\t\t} else if cs != nil && slices.Contains(mechanisms, \"SCRAM-SHA-256-PLUS\") {\n\t\t\treturn sasl.NewClientSCRAMSHA256PLUS(submitconf.Username, submitconf.Password, *cs), nil\n\t\t} else if slices.Contains(mechanisms, \"SCRAM-SHA-256\") {\n\t\t\treturn sasl.NewClientSCRAMSHA256(submitconf.Username, submitconf.Password, true), nil\n\t\t} else if cs != nil && slices.Contains(mechanisms, \"SCRAM-SHA-1-PLUS\") {\n\t\t\treturn sasl.NewClientSCRAMSHA1PLUS(submitconf.Username, submitconf.Password, *cs), nil\n\t\t} else if slices.Contains(mechanisms, \"SCRAM-SHA-1\") {\n\t\t\treturn sasl.NewClientSCRAMSHA1(submitconf.Username, submitconf.Password, true), nil\n\t\t} else if slices.Contains(mechanisms, \"CRAM-MD5\") {\n\t\t\treturn sasl.NewClientCRAMMD5(submitconf.Username, submitconf.Password), nil\n\t\t} else if slices.Contains(mechanisms, \"PLAIN\") {\n\t\t\treturn sasl.NewClientPlain(submitconf.Username, submitconf.Password), nil\n\t\t}\n\t\t// No mutually supported mechanism.\n\t\treturn nil, nil\n\t}\n\n\tctx, cancel := context.WithTimeout(context.Background(), 3*time.Minute)\n\tdefer cancel()\n\ttlsMode := smtpclient.TLSSkip\n\ttlsPKIX := false\n\tif submitconf.TLS {\n\t\ttlsMode = smtpclient.TLSImmediate\n\t\ttlsPKIX = true\n\t} else if submitconf.STARTTLS {\n\t\ttlsMode = smtpclient.TLSRequiredStartTLS\n\t\ttlsPKIX = true\n\t} else if submitconf.RequireTLS == RequireTLSYes {\n\t\txsavecheckf(errors.New(\"cannot submit with requiretls enabled without tls to submission server\"), \"checking tls configuration\")\n\t}\n\tif submitconf.TLSInsecureSkipVerify {\n\t\ttlsPKIX = false\n\t}\n\n\tourHostname, err := dns.ParseDomain(submitconf.LocalHostname)\n\txsavecheckf(err, \"parsing our local hostname\")\n\n\tvar remoteHostname dns.Domain\n\tif net.ParseIP(submitconf.Host) == nil {\n\t\tremoteHostname, err = dns.ParseDomain(submitconf.Host)\n\t\txsavecheckf(err, \"parsing remote hostname\")\n\t}\n\n\t// todo: implement SRV and DANE, allowing for a simpler config file (just the email address & password)\n\topts := smtpclient.Opts{\n\t\tAuth:       auth,\n\t\tRootCAs:    mox.Conf.Static.TLS.CertPool,\n\t\tClientCert: submitconf.clientCert,\n\t}\n\tclient, err := smtpclient.New(ctx, c.log.Logger, conn, tlsMode, tlsPKIX, ourHostname, remoteHostname, opts)\n\txsavecheckf(err, \"open smtp session\")\n\n\terr = client.Deliver(ctx, submitconf.From, recipient, int64(len(msg)), strings.NewReader(msg), true, false, submitconf.RequireTLS == RequireTLSYes)\n\txsavecheckf(err, \"submit message\")\n\n\tif err := client.Close(); err != nil {\n\t\tlog.Printf(\"closing smtp session after message was sent: %v\", err)\n\t}\n}\n\nfunc xminimalCert(privKey ed25519.PrivateKey) ([]byte, tls.Certificate) {\n\ttemplate := &x509.Certificate{\n\t\t// Required field.\n\t\tSerialNumber: big.NewInt(time.Now().Unix()),\n\t}\n\tcertBuf, err := x509.CreateCertificate(cryptorand.Reader, template, template, privKey.Public(), privKey)\n\txcheckf(err, \"creating minimal certificate\")\n\tcert, err := x509.ParseCertificate(certBuf)\n\txcheckf(err, \"parsing certificate\")\n\tc := tls.Certificate{\n\t\tCertificate: [][]byte{certBuf},\n\t\tPrivateKey:  privKey,\n\t\tLeaf:        cert,\n\t}\n\treturn certBuf, c\n}\n"
        },
        {
          "name": "serve.go",
          "type": "blob",
          "size": 2.9990234375,
          "content": "package main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"time\"\n\n\t\"github.com/mjl-/mox/dmarcdb\"\n\t\"github.com/mjl-/mox/dns\"\n\t\"github.com/mjl-/mox/http\"\n\t\"github.com/mjl-/mox/imapserver\"\n\t\"github.com/mjl-/mox/mlog\"\n\t\"github.com/mjl-/mox/mox-\"\n\t\"github.com/mjl-/mox/mtastsdb\"\n\t\"github.com/mjl-/mox/queue\"\n\t\"github.com/mjl-/mox/smtpserver\"\n\t\"github.com/mjl-/mox/store\"\n\t\"github.com/mjl-/mox/tlsrptdb\"\n\t\"github.com/mjl-/mox/tlsrptsend\"\n)\n\nfunc shutdown(log mlog.Log) {\n\t// We indicate we are shutting down. Causes new connections and new SMTP commands\n\t// to be rejected. Should stop active connections pretty quickly.\n\tmox.ShutdownCancel()\n\n\t// Now we are going to wait for all connections to be gone, up to a timeout.\n\tdone := mox.Connections.Done()\n\tsecond := time.Tick(time.Second)\n\tselect {\n\tcase <-done:\n\t\tlog.Print(\"connections shutdown, waiting until 1 second passed\")\n\t\t<-second\n\n\tcase <-time.Tick(3 * time.Second):\n\t\t// We now cancel all pending operations, and set an immediate deadline on sockets.\n\t\t// Should get us a clean shutdown relatively quickly.\n\t\tmox.ContextCancel()\n\t\tmox.Connections.Shutdown()\n\n\t\tsecond := time.Tick(time.Second)\n\t\tselect {\n\t\tcase <-done:\n\t\t\tlog.Print(\"no more connections, shutdown is clean, waiting until 1 second passed\")\n\t\t\t<-second // Still wait for second, giving processes like imports a chance to clean up.\n\t\tcase <-second:\n\t\t\tlog.Print(\"shutting down with pending sockets\")\n\t\t}\n\t}\n\terr := os.Remove(mox.DataDirPath(\"ctl\"))\n\tlog.Check(err, \"removing ctl unix domain socket during shutdown\")\n}\n\n// start initializes all packages, starts all listeners and the switchboard\n// goroutine, then returns.\nfunc start(mtastsdbRefresher, sendDMARCReports, sendTLSReports, skipForkExec bool) error {\n\tsmtpserver.Listen()\n\timapserver.Listen()\n\thttp.Listen()\n\n\tif !skipForkExec {\n\t\t// If we were just launched as root, fork and exec as unprivileged user, handing\n\t\t// over the bound sockets to the new process. We'll get to this same code path\n\t\t// again, skipping this if block, continuing below with the actual serving.\n\t\tif os.Getuid() == 0 {\n\t\t\tmox.ForkExecUnprivileged()\n\t\t\tpanic(\"cannot happen\")\n\t\t} else {\n\t\t\tmox.CleanupPassedFiles()\n\t\t}\n\t}\n\n\tif err := mtastsdb.Init(mtastsdbRefresher); err != nil {\n\t\treturn fmt.Errorf(\"mtastsdb init: %s\", err)\n\t}\n\n\tif err := tlsrptdb.Init(); err != nil {\n\t\treturn fmt.Errorf(\"tlsrptdb init: %s\", err)\n\t}\n\n\tif err := dmarcdb.Init(); err != nil {\n\t\treturn fmt.Errorf(\"dmarcdb init: %s\", err)\n\t}\n\n\tif err := store.Init(mox.Context); err != nil {\n\t\treturn fmt.Errorf(\"store init: %s\", err)\n\t}\n\n\tdone := make(chan struct{}) // Goroutines for messages and webhooks, and cleaners.\n\tif err := queue.Start(dns.StrictResolver{Pkg: \"queue\"}, done); err != nil {\n\t\treturn fmt.Errorf(\"queue start: %s\", err)\n\t}\n\n\tif sendDMARCReports {\n\t\tdmarcdb.Start(dns.StrictResolver{Pkg: \"dmarcdb\"})\n\t}\n\n\tif sendTLSReports {\n\t\ttlsrptsend.Start(dns.StrictResolver{Pkg: \"tlsrptsend\"})\n\t}\n\n\tstore.StartAuthCache()\n\tsmtpserver.Serve()\n\timapserver.Serve()\n\thttp.Serve()\n\n\tgo func() {\n\t\tstore.Switchboard()\n\t\t<-make(chan struct{})\n\t}()\n\treturn nil\n}\n"
        },
        {
          "name": "serve_unix.go",
          "type": "blob",
          "size": 17.74609375,
          "content": "//go:build !windows\n\npackage main\n\nimport (\n\t\"context\"\n\tcryptorand \"crypto/rand\"\n\t\"fmt\"\n\t\"io/fs\"\n\t\"log/slog\"\n\t\"net\"\n\t\"os\"\n\t\"os/signal\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"runtime/debug\"\n\t\"slices\"\n\t\"strings\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"github.com/prometheus/client_golang/prometheus/promauto\"\n\n\t\"github.com/mjl-/mox/dns\"\n\t\"github.com/mjl-/mox/dnsbl\"\n\t\"github.com/mjl-/mox/message\"\n\t\"github.com/mjl-/mox/metrics\"\n\t\"github.com/mjl-/mox/mlog\"\n\t\"github.com/mjl-/mox/mox-\"\n\t\"github.com/mjl-/mox/moxvar\"\n\t\"github.com/mjl-/mox/queue\"\n\t\"github.com/mjl-/mox/store\"\n\t\"github.com/mjl-/mox/updates\"\n)\n\nvar metricDNSBL = promauto.NewGaugeVec(\n\tprometheus.GaugeOpts{\n\t\tName: \"mox_dnsbl_ips_success\",\n\t\tHelp: \"DNSBL lookups to configured DNSBLs of our IPs.\",\n\t},\n\t[]string{\n\t\t\"zone\",\n\t\t\"ip\",\n\t},\n)\n\nfunc monitorDNSBL(log mlog.Log) {\n\tdefer func() {\n\t\t// On error, don't bring down the entire server.\n\t\tx := recover()\n\t\tif x != nil {\n\t\t\tlog.Error(\"monitordnsbl panic\", slog.Any(\"panic\", x))\n\t\t\tdebug.PrintStack()\n\t\t\tmetrics.PanicInc(metrics.Serve)\n\t\t}\n\t}()\n\n\tpublicListener := mox.Conf.Static.Listeners[\"public\"]\n\n\t// We keep track of the previous metric values, so we can delete those we no longer\n\t// monitor.\n\ttype key struct {\n\t\tzone dns.Domain\n\t\tip   string\n\t}\n\tprevResults := map[key]struct{}{}\n\n\t// Last time we checked, and how many outgoing delivery connections were made at that time.\n\tvar last time.Time\n\tvar lastConns int64\n\n\tresolver := dns.StrictResolver{Pkg: \"dnsblmonitor\"}\n\tvar sleep time.Duration // No sleep on first iteration.\n\tfor {\n\t\ttime.Sleep(sleep)\n\t\t// We check more often when we send more. Every 100 messages, and between 5 mins\n\t\t// and 3 hours.\n\t\tconns := queue.ConnectionCounter()\n\t\tif sleep > 0 && conns < lastConns+100 && time.Since(last) < 3*time.Hour {\n\t\t\tcontinue\n\t\t}\n\t\tsleep = 5 * time.Minute\n\t\tlastConns = conns\n\t\tlast = time.Now()\n\n\t\t// Gather zones.\n\t\tzones := append([]dns.Domain{}, publicListener.SMTP.DNSBLZones...)\n\t\tconf := mox.Conf.DynamicConfig()\n\t\tfor _, zone := range conf.MonitorDNSBLZones {\n\t\t\tif !slices.Contains(zones, zone) {\n\t\t\t\tzones = append(zones, zone)\n\t\t\t}\n\t\t}\n\t\t// And gather IPs.\n\t\tips, err := mox.IPs(mox.Context, false)\n\t\tif err != nil {\n\t\t\tlog.Errorx(\"listing ips for dnsbl monitor\", err)\n\t\t\t// Mark checks as broken.\n\t\t\tfor k := range prevResults {\n\t\t\t\tmetricDNSBL.WithLabelValues(k.zone.Name(), k.ip).Set(-1)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\tvar publicIPs []net.IP\n\t\tvar publicIPstrs []string\n\t\tfor _, ip := range ips {\n\t\t\tif ip.IsLoopback() || ip.IsPrivate() {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tpublicIPs = append(publicIPs, ip)\n\t\t\tpublicIPstrs = append(publicIPstrs, ip.String())\n\t\t}\n\n\t\t// Remove labels that no longer exist from metric.\n\t\tfor k := range prevResults {\n\t\t\tif !slices.Contains(zones, k.zone) || !slices.Contains(publicIPstrs, k.ip) {\n\t\t\t\tmetricDNSBL.DeleteLabelValues(k.zone.Name(), k.ip)\n\t\t\t\tdelete(prevResults, k)\n\t\t\t}\n\t\t}\n\n\t\t// Do DNSBL checks and update metric.\n\t\tfor _, ip := range publicIPs {\n\t\t\tfor _, zone := range zones {\n\t\t\t\tstatus, expl, err := dnsbl.Lookup(mox.Context, log.Logger, resolver, zone, ip)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Errorx(\"dnsbl monitor lookup\", err,\n\t\t\t\t\t\tslog.Any(\"ip\", ip),\n\t\t\t\t\t\tslog.Any(\"zone\", zone),\n\t\t\t\t\t\tslog.String(\"expl\", expl),\n\t\t\t\t\t\tslog.Any(\"status\", status))\n\t\t\t\t}\n\t\t\t\tvar v float64\n\t\t\t\tif status == dnsbl.StatusPass {\n\t\t\t\t\tv = 1\n\t\t\t\t}\n\t\t\t\tmetricDNSBL.WithLabelValues(zone.Name(), ip.String()).Set(v)\n\t\t\t\tk := key{zone, ip.String()}\n\t\t\t\tprevResults[k] = struct{}{}\n\n\t\t\t\ttime.Sleep(time.Second)\n\t\t\t}\n\t\t}\n\t}\n}\n\n// also see localserve.go, code is similar or even shared.\nfunc cmdServe(c *cmd) {\n\tc.help = `Start mox, serving SMTP/IMAP/HTTPS.\n\nIncoming email is accepted over SMTP. Email can be retrieved by users using\nIMAP. HTTP listeners are started for the admin/account web interfaces, and for\nautomated TLS configuration. Missing essential TLS certificates are immediately\nrequested, other TLS certificates are requested on demand.\n\nOnly implemented on unix systems, not Windows.\n`\n\targs := c.Parse()\n\tif len(args) != 0 {\n\t\tc.Usage()\n\t}\n\n\t// Set debug logging until config is fully loaded.\n\tmlog.Logfmt = true\n\tmox.Conf.Log[\"\"] = mlog.LevelDebug\n\tmlog.SetConfig(mox.Conf.Log)\n\n\tcheckACMEHosts := os.Getuid() != 0\n\n\tlog := c.log\n\n\tif os.Getuid() == 0 {\n\t\tmox.MustLoadConfig(true, checkACMEHosts)\n\n\t\t// No need to potentially start and keep multiple processes. As root, we just need\n\t\t// to start the child process.\n\t\truntime.GOMAXPROCS(1)\n\n\t\tmoxconf, err := filepath.Abs(mox.ConfigStaticPath)\n\t\tlog.Check(err, \"finding absolute mox.conf path\")\n\t\tdomainsconf, err := filepath.Abs(mox.ConfigDynamicPath)\n\t\tlog.Check(err, \"finding absolute domains.conf path\")\n\n\t\tlog.Print(\"starting as root, initializing network listeners\",\n\t\t\tslog.String(\"version\", moxvar.Version),\n\t\t\tslog.Any(\"pid\", os.Getpid()),\n\t\t\tslog.String(\"moxconf\", moxconf),\n\t\t\tslog.String(\"domainsconf\", domainsconf))\n\t\tif os.Getenv(\"MOX_SOCKETS\") != \"\" {\n\t\t\tlog.Fatal(\"refusing to start as root with $MOX_SOCKETS set\")\n\t\t}\n\t\tif os.Getenv(\"MOX_FILES\") != \"\" {\n\t\t\tlog.Fatal(\"refusing to start as root with $MOX_FILES set\")\n\t\t}\n\n\t\tif !mox.Conf.Static.NoFixPermissions {\n\t\t\t// Fix permissions now that we have privilege to do so. Useful for update of v0.0.1\n\t\t\t// that was running directly as mox-user.\n\t\t\tworkdir, err := os.Getwd()\n\t\t\tif err != nil {\n\t\t\t\tlog.Printx(\"get working dir, continuing without potentially fixing up permissions\", err)\n\t\t\t} else {\n\t\t\t\tconfigdir := filepath.Dir(mox.ConfigStaticPath)\n\t\t\t\tdatadir := mox.DataDirPath(\".\")\n\t\t\t\terr := fixperms(log, workdir, configdir, datadir, mox.Conf.Static.UID, mox.Conf.Static.GID)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatalx(\"fixing permissions\", err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\tmox.RestorePassedFiles()\n\t\tmox.MustLoadConfig(true, checkACMEHosts)\n\t\tlog.Print(\"starting as unprivileged user\",\n\t\t\tslog.String(\"user\", mox.Conf.Static.User),\n\t\t\tslog.Any(\"uid\", mox.Conf.Static.UID),\n\t\t\tslog.Any(\"gid\", mox.Conf.Static.GID),\n\t\t\tslog.Any(\"pid\", os.Getpid()))\n\t}\n\n\tsyscall.Umask(syscall.Umask(007) | 007)\n\n\t// Initialize key and random buffer for creating opaque SMTP\n\t// transaction IDs based on \"cid\"s.\n\trecvidpath := mox.DataDirPath(\"receivedid.key\")\n\trecvidbuf, err := os.ReadFile(recvidpath)\n\tif err != nil || len(recvidbuf) != 16+8 {\n\t\trecvidbuf = make([]byte, 16+8)\n\t\tif _, err := cryptorand.Read(recvidbuf); err != nil {\n\t\t\tlog.Fatalx(\"reading random recvid data\", err)\n\t\t}\n\t\tif err := os.WriteFile(recvidpath, recvidbuf, 0660); err != nil {\n\t\t\tlog.Fatalx(\"writing recvidpath\", err, slog.String(\"path\", recvidpath))\n\t\t}\n\t\terr := os.Chown(recvidpath, int(mox.Conf.Static.UID), 0)\n\t\tlog.Check(err, \"chown receveidid.key\",\n\t\t\tslog.String(\"path\", recvidpath),\n\t\t\tslog.Any(\"uid\", mox.Conf.Static.UID),\n\t\t\tslog.Any(\"gid\", 0))\n\t\terr = os.Chmod(recvidpath, 0640)\n\t\tlog.Check(err, \"chmod receveidid.key to 0640\", slog.String(\"path\", recvidpath))\n\t}\n\tif err := mox.ReceivedIDInit(recvidbuf[:16], recvidbuf[16:]); err != nil {\n\t\tlog.Fatalx(\"init receivedid\", err)\n\t}\n\n\t// Start mox. If running as root, this will bind/listen on network sockets, and\n\t// fork and exec itself as unprivileged user, then waits for the child to stop and\n\t// exit. When running as root, this function never returns. But the new\n\t// unprivileged user will get here again, with network sockets prepared.\n\t//\n\t// We listen to the unix domain ctl socket afterwards, which we always remove\n\t// before listening. We need to do that because we may not have cleaned up our\n\t// control socket during unexpected shutdown. We don't want to remove and listen on\n\t// the unix domain socket first. If we would, we would make the existing instance\n\t// unreachable over its ctl socket, and then fail because the network addresses are\n\t// taken.\n\tconst mtastsdbRefresher = true\n\tconst skipForkExec = false\n\tif err := start(mtastsdbRefresher, !mox.Conf.Static.NoOutgoingDMARCReports, !mox.Conf.Static.NoOutgoingTLSReports, skipForkExec); err != nil {\n\t\tlog.Fatalx(\"start\", err)\n\t}\n\tlog.Print(\"ready to serve\")\n\n\tif mox.Conf.Static.CheckUpdates {\n\t\tcheckUpdates := func() time.Duration {\n\t\t\tnext := 24 * time.Hour\n\t\t\tcurrent, lastknown, mtime, err := store.LastKnown()\n\t\t\tif err != nil {\n\t\t\t\tlog.Infox(\"determining own version before checking for updates, trying again in 24h\", err)\n\t\t\t\treturn next\n\t\t\t}\n\n\t\t\t// We don't want to check for updates at every startup. So we sleep based on file\n\t\t\t// mtime. But file won't exist initially.\n\t\t\tif !mtime.IsZero() && time.Since(mtime) < 24*time.Hour {\n\t\t\t\td := 24*time.Hour - time.Since(mtime)\n\t\t\t\tlog.Debug(\"sleeping for next check for updates\", slog.Duration(\"sleep\", d))\n\t\t\t\ttime.Sleep(d)\n\t\t\t\tnext = 0\n\t\t\t}\n\t\t\tnow := time.Now()\n\t\t\tif err := os.Chtimes(mox.DataDirPath(\"lastknownversion\"), now, now); err != nil {\n\t\t\t\tif !os.IsNotExist(err) {\n\t\t\t\t\tlog.Infox(\"setting mtime on lastknownversion file, continuing\", err)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tlog.Debug(\"checking for updates\", slog.Any(\"lastknown\", lastknown))\n\t\t\tupdatesctx, updatescancel := context.WithTimeout(mox.Context, time.Minute)\n\t\t\tlatest, _, changelog, err := updates.Check(updatesctx, log.Logger, dns.StrictResolver{Log: log.Logger}, dns.Domain{ASCII: changelogDomain}, lastknown, changelogURL, changelogPubKey)\n\t\t\tupdatescancel()\n\t\t\tif err != nil {\n\t\t\t\tlog.Infox(\"checking for updates\", err, slog.Any(\"latest\", latest))\n\t\t\t\treturn next\n\t\t\t}\n\t\t\tif !latest.After(lastknown) {\n\t\t\t\tlog.Debug(\"no new version available\")\n\t\t\t\treturn next\n\t\t\t}\n\t\t\tif len(changelog.Changes) == 0 {\n\t\t\t\tlog.Info(\"new version available, but changelog is empty, ignoring\", slog.Any(\"latest\", latest))\n\t\t\t\treturn next\n\t\t\t}\n\n\t\t\tvar cl string\n\t\t\tfor _, c := range changelog.Changes {\n\t\t\t\tcl += \"----\\n\\n\" + strings.TrimSpace(c.Text) + \"\\n\\n\"\n\t\t\t}\n\t\t\tcl += \"----\"\n\n\t\t\ta, err := store.OpenAccount(log, mox.Conf.Static.Postmaster.Account)\n\t\t\tif err != nil {\n\t\t\t\tlog.Infox(\"open account for postmaster changelog delivery\", err)\n\t\t\t\treturn next\n\t\t\t}\n\t\t\tdefer func() {\n\t\t\t\terr := a.Close()\n\t\t\t\tlog.Check(err, \"closing account\")\n\t\t\t}()\n\t\t\tf, err := store.CreateMessageTemp(log, \"changelog\")\n\t\t\tif err != nil {\n\t\t\t\tlog.Infox(\"making temporary message file for changelog delivery\", err)\n\t\t\t\treturn next\n\t\t\t}\n\t\t\tdefer store.CloseRemoveTempFile(log, f, \"message for changelog delivery\")\n\n\t\t\tm := store.Message{\n\t\t\t\tReceived: time.Now(),\n\t\t\t\tFlags:    store.Flags{Flagged: true},\n\t\t\t}\n\t\t\tn, err := fmt.Fprintf(f, \"Date: %s\\r\\nSubject: mox %s available\\r\\nContent-Type: text/plain; charset=utf-8\\r\\nContent-Transfer-Encoding: 8-bit\\r\\n\\r\\nHi!\\r\\n\\r\\nVersion %s of mox is available, this install is at %s.\\r\\n\\r\\nChanges:\\r\\n\\r\\n%s\\r\\n\\r\\nRemember to make a backup with \\\"mox backup\\\" before upgrading.\\r\\nPlease report any issues at https://github.com/mjl-/mox, thanks!\\r\\n\\r\\nCheers,\\r\\nmox\\r\\n\", time.Now().Format(message.RFC5322Z), latest, latest, current, strings.ReplaceAll(cl, \"\\n\", \"\\r\\n\"))\n\t\t\tif err != nil {\n\t\t\t\tlog.Infox(\"writing temporary message file for changelog delivery\", err)\n\t\t\t\treturn next\n\t\t\t}\n\t\t\tm.Size = int64(n)\n\n\t\t\tvar derr error\n\t\t\ta.WithWLock(func() {\n\t\t\t\tderr = a.DeliverMailbox(log, mox.Conf.Static.Postmaster.Mailbox, &m, f)\n\t\t\t})\n\t\t\tif derr != nil {\n\t\t\t\tlog.Errorx(\"changelog delivery\", derr)\n\t\t\t\treturn next\n\t\t\t}\n\n\t\t\tlog.Info(\"delivered changelog\",\n\t\t\t\tslog.Any(\"current\", current),\n\t\t\t\tslog.Any(\"lastknown\", lastknown),\n\t\t\t\tslog.Any(\"latest\", latest))\n\t\t\tif err := store.StoreLastKnown(latest); err != nil {\n\t\t\t\t// This will be awkward, we'll keep notifying the postmaster once every 24h...\n\t\t\t\tlog.Infox(\"updating last known version\", err)\n\t\t\t}\n\t\t\treturn next\n\t\t}\n\n\t\tgo func() {\n\t\t\tfor {\n\t\t\t\tnext := checkUpdates()\n\t\t\t\ttime.Sleep(next)\n\t\t\t}\n\t\t}()\n\t}\n\n\tgo monitorDNSBL(log)\n\n\tctlpath := mox.DataDirPath(\"ctl\")\n\t_ = os.Remove(ctlpath)\n\tctl, err := net.Listen(\"unix\", ctlpath)\n\tif err != nil {\n\t\tlog.Fatalx(\"listen on ctl unix domain socket\", err)\n\t}\n\tgo func() {\n\t\tfor {\n\t\t\tconn, err := ctl.Accept()\n\t\t\tif err != nil {\n\t\t\t\tlog.Printx(\"accept for ctl\", err)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tcid := mox.Cid()\n\t\t\tctx := context.WithValue(mox.Context, mlog.CidKey, cid)\n\t\t\tgo servectl(ctx, log.WithCid(cid), conn, func() { shutdown(log) })\n\t\t}\n\t}()\n\n\t// Remove old temporary files that somehow haven't been cleaned up.\n\ttmpdir := mox.DataDirPath(\"tmp\")\n\tos.MkdirAll(tmpdir, 0770)\n\ttmps, err := os.ReadDir(tmpdir)\n\tif err != nil {\n\t\tlog.Errorx(\"listing files in tmpdir\", err)\n\t} else {\n\t\tnow := time.Now()\n\t\tfor _, e := range tmps {\n\t\t\tif fi, err := e.Info(); err != nil {\n\t\t\t\tlog.Errorx(\"stat tmp file\", err, slog.String(\"filename\", e.Name()))\n\t\t\t} else if now.Sub(fi.ModTime()) > 7*24*time.Hour && !fi.IsDir() {\n\t\t\t\tp := filepath.Join(tmpdir, e.Name())\n\t\t\t\tif err := os.Remove(p); err != nil {\n\t\t\t\t\tlog.Errorx(\"removing stale temporary file\", err, slog.String(\"path\", p))\n\t\t\t\t} else {\n\t\t\t\t\tlog.Info(\"removed stale temporary file\", slog.String(\"path\", p))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Graceful shutdown.\n\tsigc := make(chan os.Signal, 1)\n\tsignal.Notify(sigc, os.Interrupt, syscall.SIGTERM)\n\tsig := <-sigc\n\tlog.Print(\"shutting down, waiting max 3s for existing connections\", slog.Any(\"signal\", sig))\n\tshutdown(log)\n\tif num, ok := sig.(syscall.Signal); ok {\n\t\tos.Exit(int(num))\n\t} else {\n\t\tos.Exit(1)\n\t}\n}\n\n// Set correct permissions for mox working directory, binary, config and data and service file.\n//\n// We require being able to stat the basic non-optional paths. Then we'll try to\n// fix up permissions. If an error occurs when fixing permissions, we log and\n// continue (could not be an actual problem).\nfunc fixperms(log mlog.Log, workdir, configdir, datadir string, moxuid, moxgid uint32) (rerr error) {\n\ttype fserr struct{ Err error }\n\tdefer func() {\n\t\tx := recover()\n\t\tif x == nil {\n\t\t\treturn\n\t\t}\n\t\te, ok := x.(fserr)\n\t\tif ok {\n\t\t\trerr = e.Err\n\t\t} else {\n\t\t\tpanic(x)\n\t\t}\n\t}()\n\n\tcheckf := func(err error, format string, args ...any) {\n\t\tif err != nil {\n\t\t\tpanic(fserr{fmt.Errorf(format, args...)})\n\t\t}\n\t}\n\n\t// Changes we have to make. We collect them first, then apply.\n\ttype change struct {\n\t\tpath           string\n\t\tuid, gid       *uint32\n\t\tolduid, oldgid uint32\n\t\tmode           *fs.FileMode\n\t\toldmode        fs.FileMode\n\t}\n\tvar changes []change\n\n\tensure := func(p string, uid, gid uint32, perm fs.FileMode) bool {\n\t\tfi, err := os.Stat(p)\n\t\tcheckf(err, \"stat %s\", p)\n\n\t\tst, ok := fi.Sys().(*syscall.Stat_t)\n\t\tif !ok {\n\t\t\tcheckf(fmt.Errorf(\"got %T\", st), \"stat sys, expected syscall.Stat_t\")\n\t\t}\n\n\t\tvar ch change\n\t\tif st.Uid != uid || st.Gid != gid {\n\t\t\tch.uid = &uid\n\t\t\tch.gid = &gid\n\t\t\tch.olduid = st.Uid\n\t\t\tch.oldgid = st.Gid\n\t\t}\n\t\tif perm != fi.Mode()&(fs.ModeSetgid|0777) {\n\t\t\tch.mode = &perm\n\t\t\tch.oldmode = fi.Mode() & (fs.ModeSetgid | 0777)\n\t\t}\n\t\tvar zerochange change\n\t\tif ch == zerochange {\n\t\t\treturn false\n\t\t}\n\t\tch.path = p\n\t\tchanges = append(changes, ch)\n\t\treturn true\n\t}\n\n\txexists := func(p string) bool {\n\t\t_, err := os.Stat(p)\n\t\tif err != nil && !os.IsNotExist(err) {\n\t\t\tcheckf(err, \"stat %s\", p)\n\t\t}\n\t\treturn err == nil\n\t}\n\n\t// We ensure these permissions:\n\t//\n\t//\t$workdir root:mox 0751\n\t//\t$configdir mox:root 0750 + setgid, and recursively (but files 0640)\n\t//\t$datadir mox:root 0750 + setgid, and recursively (but files 0640)\n\t//\t$workdir/mox (binary, optional) root:mox 0750\n\t//\t$workdir/mox.service (systemd service file, optional) root:root 0644\n\n\tconst root = 0\n\tensure(workdir, root, moxgid, 0751)\n\tfixconfig := ensure(configdir, moxuid, 0, fs.ModeSetgid|0750)\n\tfixdata := ensure(datadir, moxuid, 0, fs.ModeSetgid|0750)\n\n\t// Binary and systemd service file do not exist (there) when running under docker.\n\tbinary := filepath.Join(workdir, \"mox\")\n\tif xexists(binary) {\n\t\tensure(binary, root, moxgid, 0750)\n\t}\n\tsvc := filepath.Join(workdir, \"mox.service\")\n\tif xexists(svc) {\n\t\tensure(svc, root, root, 0644)\n\t}\n\n\tif len(changes) == 0 {\n\t\treturn\n\t}\n\n\t// Apply changes.\n\tlog.Print(\"fixing up permissions, will continue on errors\")\n\tfor _, ch := range changes {\n\t\tif ch.uid != nil {\n\t\t\terr := os.Chown(ch.path, int(*ch.uid), int(*ch.gid))\n\t\t\tlog.Printx(\"chown, fixing uid/gid\", err,\n\t\t\t\tslog.String(\"path\", ch.path),\n\t\t\t\tslog.Any(\"olduid\", ch.olduid),\n\t\t\t\tslog.Any(\"oldgid\", ch.oldgid),\n\t\t\t\tslog.Any(\"newuid\", *ch.uid),\n\t\t\t\tslog.Any(\"newgid\", *ch.gid))\n\t\t}\n\t\tif ch.mode != nil {\n\t\t\terr := os.Chmod(ch.path, *ch.mode)\n\t\t\tlog.Printx(\"chmod, fixing permissions\", err,\n\t\t\t\tslog.String(\"path\", ch.path),\n\t\t\t\tslog.Any(\"oldmode\", fmt.Sprintf(\"%03o\", ch.oldmode)),\n\t\t\t\tslog.Any(\"newmode\", fmt.Sprintf(\"%03o\", *ch.mode)))\n\t\t}\n\t}\n\n\twalkchange := func(dir string) {\n\t\terr := filepath.WalkDir(dir, func(path string, d fs.DirEntry, err error) error {\n\t\t\tif err != nil {\n\t\t\t\tlog.Printx(\"walk error, continuing\", err, slog.String(\"path\", path))\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tfi, err := d.Info()\n\t\t\tif err != nil {\n\t\t\t\tlog.Printx(\"stat during walk, continuing\", err, slog.String(\"path\", path))\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tst, ok := fi.Sys().(*syscall.Stat_t)\n\t\t\tif !ok {\n\t\t\t\tlog.Printx(\"syscall stat during walk, continuing\", err, slog.String(\"path\", path))\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif st.Uid != moxuid || st.Gid != root {\n\t\t\t\terr := os.Chown(path, int(moxuid), root)\n\t\t\t\tlog.Printx(\"walk chown, fixing uid/gid\", err,\n\t\t\t\t\tslog.String(\"path\", path),\n\t\t\t\t\tslog.Any(\"olduid\", st.Uid),\n\t\t\t\t\tslog.Any(\"oldgid\", st.Gid),\n\t\t\t\t\tslog.Any(\"newuid\", moxuid),\n\t\t\t\t\tslog.Any(\"newgid\", root))\n\t\t\t}\n\t\t\tomode := fi.Mode() & (fs.ModeSetgid | 0777)\n\t\t\tvar nmode fs.FileMode\n\t\t\tif fi.IsDir() {\n\t\t\t\tnmode = fs.ModeSetgid | 0750\n\t\t\t} else {\n\t\t\t\tnmode = 0640\n\t\t\t}\n\t\t\tif omode != nmode {\n\t\t\t\terr := os.Chmod(path, nmode)\n\t\t\t\tlog.Printx(\"walk chmod, fixing permissions\", err,\n\t\t\t\t\tslog.String(\"path\", path),\n\t\t\t\t\tslog.Any(\"oldmode\", fmt.Sprintf(\"%03o\", omode)),\n\t\t\t\t\tslog.Any(\"newmode\", fmt.Sprintf(\"%03o\", nmode)))\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t\tlog.Check(err, \"walking dir to fix permissions\", slog.String(\"dir\", dir))\n\t}\n\n\t// If config or data dir needed fixing, also set uid/gid and mode and files/dirs\n\t// inside, recursively. We don't always recurse, data probably contains many files.\n\tif fixconfig {\n\t\tlog.Print(\"fixing permissions in config dir\", slog.String(\"configdir\", configdir))\n\t\twalkchange(configdir)\n\t}\n\tif fixdata {\n\t\tlog.Print(\"fixing permissions in data dir\", slog.String(\"configdir\", configdir))\n\t\twalkchange(datadir)\n\t}\n\treturn nil\n}\n"
        },
        {
          "name": "serve_windows.go",
          "type": "blob",
          "size": 0.3955078125,
          "content": "package main\n\nimport (\n\t\"log\"\n)\n\n// also see localserve.go, code is similar or even shared.\nfunc cmdServe(c *cmd) {\n\tc.help = `Start mox, serving SMTP/IMAP/HTTPS. Not implemented on windows.\n`\n\targs := c.Parse()\n\tif len(args) != 0 {\n\t\tc.Usage()\n\t}\n\tlog.Fatalln(\"mox serve not implemented on windows yet due to unfamiliarity with the windows security model, other commands including localserve do work\")\n}\n"
        },
        {
          "name": "smtp",
          "type": "tree",
          "content": null
        },
        {
          "name": "smtpclient",
          "type": "tree",
          "content": null
        },
        {
          "name": "smtpserver",
          "type": "tree",
          "content": null
        },
        {
          "name": "spf",
          "type": "tree",
          "content": null
        },
        {
          "name": "store",
          "type": "tree",
          "content": null
        },
        {
          "name": "stub",
          "type": "tree",
          "content": null
        },
        {
          "name": "subjectpass",
          "type": "tree",
          "content": null
        },
        {
          "name": "test-upgrade.sh",
          "type": "blob",
          "size": 4.005859375,
          "content": "#!/bin/sh\n\n# note: If testdata/upgradetest.mbox.gz exists it will be imported it as part of\n# testing the upgrades. If this is a large mailbox, it will highlight performance\n# or resource consumption issues during upgrades.\n\n# todo: should we also test with mox.conf and domains.conf files? should \"mox backup\" and \"mox gentestdata\" add them, and \"mox verifydata\" use them?\n\nset -e\n# set -x\n\n# We'll set a max memory limit during upgrades. We modify the softlimit when\n# importing the potentially large mbox file.\n# Currently at 1024MB, needed for upgrading with 500k messages from v0.0.5 to\n# v0.0.9 (two new indexes on store.Message).\nmemlimit=1024000\nulimit -S -d $memlimit\n\n(rm -r testdata/upgrade 2>/dev/null || exit 0)\nmkdir testdata/upgrade\ncd testdata/upgrade\n\n# Check that we can upgrade what we currently generate.\n../../mox gentestdata data\n../../mox verifydata data\n../../mox openaccounts data test0 test1 test2\nrm -r data\necho\n\n# For each historic release (i.e. all tagged versions) except the first few that\n# didn't have the gentestdata command, we generate a data directory for testing\n# and simulate upgrading to the currently checked out version.\n# The awk command reverses the tags, so we try the previous release first since\n# it is the most likely to fail.\ntagsrev=$(git tag --sort creatordate | grep -v '^v0\\.0\\.[123]$' | awk '{a[i++]=$0} END {for (j=i-1; j>=0;) print a[j--] }')\nif test \"$tagsrev\" = \"\"; then exit 0; fi\nfor tag in $tagsrev; do\n\techo \"Testing upgrade from $tag to current.\"\n\tmkdir $tag\n\t(CGO_ENABLED=0 GOBIN=$PWD/$tag go install github.com/mjl-/mox@$tag)\n\t# Generate with historic release.\n\t./$tag/mox gentestdata $tag/data\n\t# Verify with current code. v0.0.[45] had a message with wrong Size. We don't\n\t# want to abort the upgrade check because of it.\n\tif test $tag = v0.0.4 -o $tag = v0.0.5; then\n\t\t../../mox verifydata -skip-size-check $tag/data\n\telse\n\t\t../../mox verifydata $tag/data\n\tfi\n\techo\n\trm -r $tag/data\ndone\n\n# Do upgrade from v0.0.5 with big import straight to current. Will create\n# multiple new indices so may be heavier during upgrade.\necho \"Testing upgrade from v0.0.5 + big import straight to current.\"\ntag=v0.0.5\n./$tag/mox gentestdata stepdata\nulimit -S -d unlimited\necho 'Importing bulk data for upgrading.'\ngunzip < ../upgradetest.mbox.gz | time ./$tag/mox ximport mbox ./stepdata/accounts/test0 upgradetest /dev/stdin\necho\nulimit -S -d $memlimit\ntime ../../mox -cpuprof ../../upgrade0-verifydata.cpu.pprof -memprof ../../upgrade0-verifydata.mem.pprof verifydata -skip-size-check stepdata\ntime ../../mox -loglevel info -cpuprof ../../upgrade0-openaccounts.cpu.pprof -memprof ../../upgrade0-openaccounts.mem.pprof openaccounts stepdata test0 test1 test2\nrm -r stepdata\n\n\n# Also go step-wise through each released version. Having upgraded step by step\n# can have added more schema upgrades to the database files.\ntags=$(git tag --sort creatordate | grep -v '^v0\\.0\\.[123]$' | cat)\nfirst=yes\nfor tag in $tags; do\n\tif test \"$first\" = yes; then\n\t\techo \"Starting with test data for $tag.\"\n\t\t./$tag/mox gentestdata stepdata\n\t\techo\n\t\tfirst=\n\telse\n\t\t# v0.0.5 got the ximport command\n\t\tif test $tag = v0.0.5 -a -f ../upgradetest.mbox.gz; then\n\t\t\tulimit -S -d unlimited\n\t\t\techo 'Importing bulk data for upgrading.'\n\t\t\tgunzip < ../upgradetest.mbox.gz | time ./$tag/mox ximport mbox ./stepdata/accounts/test0 upgradetest /dev/stdin\n\t\t\techo\n\t\t\tulimit -S -d $memlimit\n\t\tfi\n\n\t\techo \"Upgrade data to $tag.\"\n\t\tif test $tag = v0.0.4 -o $tag = v0.0.5; then\n\t\t\ttime ./$tag/mox verifydata stepdata\n\t\telse\n\t\t\ttime ./$tag/mox verifydata -skip-size-check stepdata\n\t\t\ttime ./$tag/mox openaccounts stepdata test0 test1 test2\n\t\tfi\n\t\techo\n\tfi\ndone\necho \"Testing final upgrade to current.\"\ntime ../../mox -cpuprof ../../upgrade1-verifydata.cpu.pprof -memprof ../../upgrade1-verifydata.mem.pprof verifydata -skip-size-check stepdata\ntime ../../mox -loglevel info -cpuprof ../../upgrade1-openaccounts.cpu.pprof -memprof ../../upgrade1-openaccounts.mem.pprof openaccounts stepdata test0 test1 test2\nrm -r stepdata\nrm */mox\ncd ../..\nrmdir testdata/upgrade/* testdata/upgrade\n"
        },
        {
          "name": "testdata",
          "type": "tree",
          "content": null
        },
        {
          "name": "tlsrpt",
          "type": "tree",
          "content": null
        },
        {
          "name": "tlsrptdb",
          "type": "tree",
          "content": null
        },
        {
          "name": "tlsrptsend",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools.go",
          "type": "blob",
          "size": 0.1435546875,
          "content": "//go:build tools\n// +build tools\n\npackage main\n\nimport (\n\t_ \"github.com/mjl-/sherpadoc/cmd/sherpadoc\"\n\t_ \"github.com/mjl-/sherpats/cmd/sherpats\"\n)\n"
        },
        {
          "name": "tsc.sh",
          "type": "blob",
          "size": 0.814453125,
          "content": "#!/usr/bin/env bash\nset -euo pipefail\n\n# - todo: get tsc to not emit semicolons except for the handful cases where it is needed.\n# - todo: get tsc to directly print unix line numbers without --pretty (which seems unaware of termcap).\n# - todo: get tsc to not turn multiline statements into one huge line. makes the dom-building statements unreadable in the js output.\n\nout=$1\nshift\n./node_modules/.bin/tsc --noEmitOnError true --pretty false --newLine lf --strict --allowUnreachableCode false --allowUnusedLabels false --noFallthroughCasesInSwitch true --noImplicitReturns true --noUnusedLocals true --noImplicitThis true --noUnusedParameters true --target es2022 --module none --outFile $out.spaces \"$@\" | sed -E 's/^([^\\(]+)\\(([0-9]+),([0-9]+)\\):/\\1:\\2:\\3: /'\nCGO_ENABLED=0 go run unexpand.go -t 4 <$out.spaces >$out\nrm $out.spaces\n"
        },
        {
          "name": "unexpand.go",
          "type": "blob",
          "size": 1.25,
          "content": "//go:build tools\n// +build tools\n\n// For unexpand the 4 spaces that the typescript compiler outputs into tabs.\n// Not all unexpand commands implement the -t flag (openbsd).\npackage main\n\nimport (\n\t\"bufio\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"os\"\n)\n\nfunc xcheckf(err error, format string, args ...any) {\n\tif err != nil {\n\t\tlog.Fatalf(\"%s: %s\", fmt.Sprintf(format, args...), err)\n\t}\n}\n\nfunc main() {\n\tlog.SetFlags(0)\n\tvar width int\n\tflag.IntVar(&width, \"t\", 8, \"tab width\")\n\tflag.Parse()\n\tflag.Usage = func() {\n\t\tlog.Print(\"usage: unexpand [-t tabwidth] < input.spaces >output.tabs\")\n\t\tflag.PrintDefaults()\n\t\tos.Exit(2)\n\t}\n\tif flag.NArg() != 0 {\n\t\tflag.Usage()\n\t}\n\tif width <= 0 {\n\t\tflag.Usage()\n\t}\n\n\tr := bufio.NewReader(os.Stdin)\n\tw := bufio.NewWriter(os.Stdout)\n\n\tnspace := 0\n\tstart := true\n\n\tflush := func() {\n\t\tfor ; nspace > 0; nspace-- {\n\t\t\terr := w.WriteByte(' ')\n\t\t\txcheckf(err, \"write\")\n\t\t}\n\t}\n\twrite := func(b byte) {\n\t\terr := w.WriteByte(b)\n\t\txcheckf(err, \"write\")\n\t}\n\n\tfor {\n\t\tb, err := r.ReadByte()\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t}\n\t\txcheckf(err, \"read\")\n\n\t\tif start && b == ' ' {\n\t\t\tnspace++\n\t\t\tif nspace == width {\n\t\t\t\twrite('\\t')\n\t\t\t\tnspace = 0\n\t\t\t}\n\t\t} else {\n\t\t\tflush()\n\t\t\twrite(b)\n\t\t\tstart = b == '\\n'\n\t\t}\n\t}\n\tflush()\n\terr := w.Flush()\n\txcheckf(err, \"flush output\")\n}\n"
        },
        {
          "name": "updates.go",
          "type": "blob",
          "size": 7.36328125,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"crypto/ed25519\"\n\tcryptorand \"crypto/rand\"\n\t\"encoding/base64\"\n\t\"encoding/json\"\n\t\"fmt\"\n\thtmltemplate \"html/template\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"os\"\n\t\"strings\"\n\n\t\"github.com/mjl-/mox/moxio\"\n\t\"github.com/mjl-/mox/updates\"\n)\n\nfunc cmdUpdatesAddSigned(c *cmd) {\n\tc.unlisted = true\n\tc.params = \"privkey-file changes-file < message\"\n\tc.help = \"Add a signed change to the changes file.\"\n\targs := c.Parse()\n\tif len(args) != 2 {\n\t\tc.Usage()\n\t}\n\n\tf, err := os.Open(args[0])\n\txcheckf(err, \"open private key file\")\n\tdefer f.Close()\n\tseed, err := io.ReadAll(base64.NewDecoder(base64.StdEncoding, f))\n\txcheckf(err, \"read private key file\")\n\tif len(seed) != ed25519.SeedSize {\n\t\tlog.Fatalf(\"private key is %d bytes, must be %d\", len(seed), ed25519.SeedSize)\n\t}\n\n\tvf, err := os.Open(args[1])\n\txcheckf(err, \"open changes file\")\n\tvar changelog updates.Changelog\n\terr = json.NewDecoder(vf).Decode(&changelog)\n\txcheckf(err, \"parsing changes file\")\n\n\tprivKey := ed25519.NewKeyFromSeed(seed)\n\n\tfmt.Fprintln(os.Stderr, \"reading changelog text from stdin\")\n\tbuf, err := io.ReadAll(os.Stdin)\n\txcheckf(err, \"parse message\")\n\n\tif len(buf) == 0 {\n\t\tlog.Fatalf(\"empty message\")\n\t}\n\t// Message starts with headers similar to email, with \"version\" and \"date\".\n\t// todo future: enforce this format?\n\tsig := ed25519.Sign(privKey, buf)\n\n\tchange := updates.Change{\n\t\tPubKey: privKey.Public().(ed25519.PublicKey),\n\t\tSig:    sig,\n\t\tText:   string(buf),\n\t}\n\tchangelog.Changes = append([]updates.Change{change}, changelog.Changes...)\n\n\tvar b bytes.Buffer\n\tenc := json.NewEncoder(&b)\n\tenc.SetIndent(\"\", \"\\t\")\n\terr = enc.Encode(changelog)\n\txcheckf(err, \"encode changelog as json\")\n\terr = os.WriteFile(args[1], b.Bytes(), 0644)\n\txcheckf(err, \"writing versions file\")\n}\n\nfunc cmdUpdatesVerify(c *cmd) {\n\tc.unlisted = true\n\tc.params = \"pubkey-base64 < changelog-file\"\n\tc.help = \"Verify the changelog file against the public key.\"\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tpubKey := ed25519.PublicKey(base64Decode(args[0]))\n\n\tvar changelog updates.Changelog\n\terr := json.NewDecoder(os.Stdin).Decode(&changelog)\n\txcheckf(err, \"parsing changelog file\")\n\n\tfor i, c := range changelog.Changes {\n\t\tif !bytes.Equal(c.PubKey, pubKey) {\n\t\t\tlog.Fatalf(\"change has different public key %x, expected %x\", c.PubKey, pubKey)\n\t\t} else if !ed25519.Verify(pubKey, []byte(c.Text), c.Sig) {\n\t\t\tlog.Fatalf(\"verification failed for change with index %d\", i)\n\t\t}\n\t}\n\tfmt.Printf(\"%d change(s) verified\\n\", len(changelog.Changes))\n}\n\nfunc cmdUpdatesGenkey(c *cmd) {\n\tc.unlisted = true\n\tc.params = \">privkey\"\n\tc.help = \"Generate a key for signing a changelog file with.\"\n\targs := c.Parse()\n\tif len(args) != 0 {\n\t\tc.Usage()\n\t}\n\n\tbuf := make([]byte, ed25519.SeedSize)\n\t_, err := cryptorand.Read(buf)\n\txcheckf(err, \"generating key\")\n\tenc := base64.NewEncoder(base64.StdEncoding, os.Stdout)\n\t_, err = enc.Write(buf)\n\txcheckf(err, \"writing private key\")\n\terr = enc.Close()\n\txcheckf(err, \"writing private key\")\n}\n\nfunc cmdUpdatesPubkey(c *cmd) {\n\tc.unlisted = true\n\tc.params = \"<privkey >pubkey\"\n\tc.help = \"Print the public key for a private key.\"\n\targs := c.Parse()\n\tif len(args) != 0 {\n\t\tc.Usage()\n\t}\n\n\tseed := make([]byte, ed25519.SeedSize)\n\t_, err := io.ReadFull(base64.NewDecoder(base64.StdEncoding, os.Stdin), seed)\n\txcheckf(err, \"reading private key\")\n\tprivKey := ed25519.NewKeyFromSeed(seed)\n\tpubKey := []byte(privKey.Public().(ed25519.PublicKey))\n\tenc := base64.NewEncoder(base64.StdEncoding, os.Stdout)\n\t_, err = enc.Write(pubKey)\n\txcheckf(err, \"writing public key\")\n\terr = enc.Close()\n\txcheckf(err, \"writing public key\")\n}\n\nvar updatesTemplate = htmltemplate.Must(htmltemplate.New(\"changelog\").Parse(`<!doctype html>\n<html>\n\t<head>\n\t\t<meta charset=\"utf-8\" />\n\t\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\t\t<title>mox changelog</title>\n\t\t<style>\nbody, html { padding: 1em; font-size: 16px; }\n* { font-size: inherit; font-family: ubuntu, lato, sans-serif; margin: 0; padding: 0; box-sizing: border-box; }\nh1, h2, h3, h4 { margin-bottom: 1ex; }\nh1 { font-size: 1.2rem; }\n.literal { background-color: #fdfdfd; padding: .5em 1em; border: 1px solid #eee; border-radius: 4px; white-space: pre-wrap; font-family: monospace; font-size: 15px; tab-size: 4; }\n\t\t</style>\n\t</head>\n\t<body>\n\t\t<h1>Changes{{ if .FromVersion }} since {{ .FromVersion }}{{ end }}</h1>\n\t{{ if not .Changes }}\n\t\t<div>No changes</div>\n\t{{ end }}\n\t{{ range .Changes }}\n\t\t<pre class=\"literal\">{{ .Text }}</pre>\n\t\t<hr style=\"margin:1ex 0\" />\n\t{{ end }}\n\t</body>\n</html>\n`))\n\nfunc cmdUpdatesServe(c *cmd) {\n\tc.unlisted = true\n\tc.help = \"Serve changelog.json with updates.\"\n\tvar address, changelog string\n\tc.flag.StringVar(&address, \"address\", \"127.0.0.1:8596\", \"address to serve /changelog on\")\n\tc.flag.StringVar(&changelog, \"changelog\", \"changelog.json\", \"changelog file to serve\")\n\targs := c.Parse()\n\tif len(args) != 0 {\n\t\tc.Usage()\n\t}\n\n\tparseFile := func() (*updates.Changelog, error) {\n\t\tf, err := os.Open(changelog)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tdefer f.Close()\n\t\tvar cl updates.Changelog\n\t\tif err := json.NewDecoder(f).Decode(&cl); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn &cl, nil\n\t}\n\n\t_, err := parseFile()\n\tif err != nil {\n\t\tlog.Fatalf(\"parsing %s: %v\", changelog, err)\n\t}\n\n\tsrv := http.NewServeMux()\n\tsrv.HandleFunc(\"/changelog\", func(w http.ResponseWriter, r *http.Request) {\n\t\tcl, err := parseFile()\n\t\tif err != nil {\n\t\t\tlog.Printf(\"parsing %s: %v\", changelog, err)\n\t\t\thttp.Error(w, \"500 - internal server error\", http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\t\tfrom := r.URL.Query().Get(\"from\")\n\t\tvar fromVersion *updates.Version\n\t\tif from != \"\" {\n\t\t\tv, err := updates.ParseVersion(from)\n\t\t\tif err == nil {\n\t\t\t\tfromVersion = &v\n\t\t\t}\n\t\t}\n\t\tif fromVersion != nil {\n\t\tnextchange:\n\t\t\tfor i, c := range cl.Changes {\n\t\t\t\tfor _, line := range strings.Split(strings.Split(c.Text, \"\\n\\n\")[0], \"\\n\") {\n\t\t\t\t\tif strings.HasPrefix(line, \"version:\") {\n\t\t\t\t\t\tv, err := updates.ParseVersion(strings.TrimSpace(strings.TrimPrefix(line, \"version:\")))\n\t\t\t\t\t\tif err == nil && !v.After(*fromVersion) {\n\t\t\t\t\t\t\tcl.Changes = cl.Changes[:i]\n\t\t\t\t\t\t\tbreak nextchange\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Check if client accepts html. If so, we'll provide a human-readable version.\n\t\taccept := r.Header.Get(\"Accept\")\n\t\tvar html bool\n\taccept:\n\t\tfor _, ac := range strings.Split(accept, \",\") {\n\t\t\tvar ok bool\n\t\t\tfor i, kv := range strings.Split(strings.TrimSpace(ac), \";\") {\n\t\t\t\tif i == 0 {\n\t\t\t\t\tct := strings.TrimSpace(kv)\n\t\t\t\t\tif strings.EqualFold(ct, \"text/html\") || strings.EqualFold(ct, \"text/*\") {\n\t\t\t\t\t\tok = true\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tcontinue accept\n\t\t\t\t}\n\t\t\t\tt := strings.SplitN(strings.TrimSpace(kv), \"=\", 2)\n\t\t\t\tif !strings.EqualFold(t[0], \"q\") || len(t) != 2 {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tswitch t[1] {\n\t\t\t\tcase \"0\", \"0.\", \"0.0\", \"0.00\", \"0.000\":\n\t\t\t\t\tok = false\n\t\t\t\t\tcontinue accept\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tif ok {\n\t\t\t\thtml = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif html {\n\t\t\tw.Header().Set(\"Content-Type\", \"text/html; charset=utf-8\")\n\t\t\terr := updatesTemplate.Execute(w, map[string]any{\n\t\t\t\t\"FromVersion\": fromVersion,\n\t\t\t\t\"Changes\":     cl.Changes,\n\t\t\t})\n\t\t\tif err != nil && !moxio.IsClosed(err) {\n\t\t\t\tlog.Printf(\"writing changelog html: %v\", err)\n\t\t\t}\n\t\t} else {\n\t\t\tw.Header().Set(\"Content-Type\", \"application/json; charset=utf-8\")\n\t\t\tif err := json.NewEncoder(w).Encode(cl); err != nil && !moxio.IsClosed(err) {\n\t\t\t\tlog.Printf(\"writing changelog json: %v\", err)\n\t\t\t}\n\t\t}\n\t})\n\tlog.Printf(\"listening on %s\", address)\n\tlog.Fatalln(http.ListenAndServe(address, srv))\n}\n"
        },
        {
          "name": "updates",
          "type": "tree",
          "content": null
        },
        {
          "name": "vendor",
          "type": "tree",
          "content": null
        },
        {
          "name": "verifydata.go",
          "type": "blob",
          "size": 16.1953125,
          "content": "package main\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io/fs\"\n\t\"log\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"slices\"\n\t\"strconv\"\n\t\"strings\"\n\n\tbolt \"go.etcd.io/bbolt\"\n\n\t\"github.com/mjl-/bstore\"\n\n\t\"github.com/mjl-/mox/dmarcdb\"\n\t\"github.com/mjl-/mox/junk\"\n\t\"github.com/mjl-/mox/moxvar\"\n\t\"github.com/mjl-/mox/mtastsdb\"\n\t\"github.com/mjl-/mox/queue\"\n\t\"github.com/mjl-/mox/store\"\n\t\"github.com/mjl-/mox/tlsrptdb\"\n)\n\nfunc cmdVerifydata(c *cmd) {\n\tc.params = \"data-dir\"\n\tc.help = `Verify the contents of a data directory, typically of a backup.\n\nVerifydata checks all database files to see if they are valid BoltDB/bstore\ndatabases. It checks that all messages in the database have a corresponding\non-disk message file and there are no unrecognized files. If option -fix is\nspecified, unrecognized message files are moved away. This may be needed after\na restore, because messages enqueued or delivered in the future may get those\nmessage sequence numbers assigned and writing the message file would fail.\nConsistency of message/mailbox UID, UIDNEXT and UIDVALIDITY is verified as\nwell.\n\nBecause verifydata opens the database files, schema upgrades may automatically\nbe applied. This can happen if you use a new mox release. It is useful to run\n\"mox verifydata\" with a new binary before attempting an upgrade, but only on a\ncopy of the database files, as made with \"mox backup\". Before upgrading, make a\nnew backup again since \"mox verifydata\" may have upgraded the database files,\npossibly making them potentially no longer readable by the previous version.\n`\n\tvar fix bool\n\tc.flag.BoolVar(&fix, \"fix\", false, \"fix fixable problems, such as moving away message files not referenced by their database\")\n\n\t// To prevent aborting the upgrade test with v0.0.[45] that had a message with\n\t// incorrect Size.\n\tvar skipSizeCheck bool\n\tc.flag.BoolVar(&skipSizeCheck, \"skip-size-check\", false, \"skip the check for message size\")\n\n\targs := c.Parse()\n\tif len(args) != 1 {\n\t\tc.Usage()\n\t}\n\n\tdataDir := filepath.Clean(args[0])\n\n\tctxbg := context.Background()\n\n\t// Check whether file exists, or rather, that it doesn't not exist. Other errors\n\t// will return true as well, so the triggered check can give the details.\n\texists := func(path string) bool {\n\t\t_, err := os.Stat(path)\n\t\treturn err == nil || !os.IsNotExist(err)\n\t}\n\n\t// Check for error. If so, write a log line, including the path, and set fail so we\n\t// can warn at the end.\n\tvar fail bool\n\tcheckf := func(err error, path, format string, args ...any) {\n\t\tif err == nil {\n\t\t\treturn\n\t\t}\n\t\tfail = true\n\t\tlog.Printf(\"error: %s: %s: %v\", path, fmt.Sprintf(format, args...), err)\n\t}\n\n\t// When we fix problems, we may have to move files/dirs. We need to ensure the\n\t// directory of the destination path exists before we move. We keep track of\n\t// created dirs so we don't try to create the same directory all the time.\n\tcreatedDirs := map[string]struct{}{}\n\tensureDir := func(path string) {\n\t\tdir := filepath.Dir(path)\n\t\tif _, ok := createdDirs[dir]; ok {\n\t\t\treturn\n\t\t}\n\t\terr := os.MkdirAll(dir, 0770)\n\t\tcheckf(err, dir, \"creating directory\")\n\t\tcreatedDirs[dir] = struct{}{}\n\t}\n\n\t// Check a database file by opening it with BoltDB and bstore and lightly checking\n\t// its contents.\n\tcheckDB := func(required bool, path string, types []any) {\n\t\t_, err := os.Stat(path)\n\t\tif !required && err != nil && errors.Is(err, fs.ErrNotExist) {\n\t\t\treturn\n\t\t}\n\t\tcheckf(err, path, \"checking if database file exists\")\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\tbdb, err := bolt.Open(path, 0600, nil)\n\t\tcheckf(err, path, \"open database with bolt\")\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\t// Check BoltDB consistency.\n\t\terr = bdb.View(func(tx *bolt.Tx) error {\n\t\t\tfor err := range tx.Check() {\n\t\t\t\tcheckf(err, path, \"bolt database problem\")\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t\tcheckf(err, path, \"reading bolt database\")\n\t\tbdb.Close()\n\n\t\topts := bstore.Options{RegisterLogger: c.log.Logger}\n\t\tdb, err := bstore.Open(ctxbg, path, &opts, types...)\n\t\tcheckf(err, path, \"open database with bstore\")\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\tdefer db.Close()\n\n\t\terr = db.Read(ctxbg, func(tx *bstore.Tx) error {\n\t\t\t// Check bstore consistency, if it can export all records for all types. This is a\n\t\t\t// quick way to get bstore to parse all records.\n\t\t\ttypes, err := tx.Types()\n\t\t\tcheckf(err, path, \"getting bstore types from database\")\n\t\t\tif err != nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tfor _, t := range types {\n\t\t\t\tvar fields []string\n\t\t\t\terr := tx.Records(t, &fields, func(m map[string]any) error {\n\t\t\t\t\treturn nil\n\t\t\t\t})\n\t\t\t\tcheckf(err, path, \"parsing record for type %q\", t)\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t\tcheckf(err, path, \"checking database file\")\n\t}\n\n\tcheckFile := func(dbpath, path string, prefixSize int, size int64) {\n\t\tst, err := os.Stat(path)\n\t\tcheckf(err, path, \"checking if file exists\")\n\t\tif !skipSizeCheck && err == nil && int64(prefixSize)+st.Size() != size {\n\t\t\tfilesize := st.Size()\n\t\t\tcheckf(fmt.Errorf(\"%s: message size is %d, should be %d (length of MsgPrefix %d + file size %d), see \\\"mox fixmsgsize\\\"\", path, size, int64(prefixSize)+st.Size(), prefixSize, filesize), dbpath, \"checking message size\")\n\t\t}\n\t}\n\n\tcheckQueue := func() {\n\t\tdbpath := filepath.Join(dataDir, \"queue/index.db\")\n\t\tcheckDB(true, dbpath, queue.DBTypes)\n\n\t\t// Check that all messages present in the database also exist on disk.\n\t\tseen := map[string]struct{}{}\n\t\topts := bstore.Options{MustExist: true, RegisterLogger: c.log.Logger}\n\t\tdb, err := bstore.Open(ctxbg, dbpath, &opts, queue.DBTypes...)\n\t\tcheckf(err, dbpath, \"opening queue database to check messages\")\n\t\tif err == nil {\n\t\t\terr := bstore.QueryDB[queue.Msg](ctxbg, db).ForEach(func(m queue.Msg) error {\n\t\t\t\tmp := store.MessagePath(m.ID)\n\t\t\t\tseen[mp] = struct{}{}\n\t\t\t\tp := filepath.Join(dataDir, \"queue\", mp)\n\t\t\t\tcheckFile(dbpath, p, len(m.MsgPrefix), m.Size)\n\t\t\t\treturn nil\n\t\t\t})\n\t\t\tcheckf(err, dbpath, \"reading messages in queue database to check files\")\n\t\t}\n\n\t\t// Check that there are no files that could be treated as a message.\n\t\tqdir := filepath.Join(dataDir, \"queue\")\n\t\terr = filepath.WalkDir(qdir, func(qpath string, d fs.DirEntry, err error) error {\n\t\t\tcheckf(err, qpath, \"walk\")\n\t\t\tif err != nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif d.IsDir() {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tp := qpath[len(qdir)+1:]\n\t\t\tif p == \"index.db\" {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif _, ok := seen[p]; ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tl := strings.Split(p, string(filepath.Separator))\n\t\t\tif len(l) == 1 {\n\t\t\t\tlog.Printf(\"warning: %s: unrecognized file in queue directory, ignoring\", qpath)\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\t// If it doesn't look like a message number, there is no risk of it being the name\n\t\t\t// of a message enqueued in the future.\n\t\t\tif len(l) >= 3 {\n\t\t\t\tif _, err := strconv.ParseInt(l[1], 10, 64); err != nil {\n\t\t\t\t\tlog.Printf(\"warning: %s: unrecognized file in queue directory, ignoring\", qpath)\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !fix {\n\t\t\t\tcheckf(errors.New(\"may interfere with messages enqueued in the future\"), qpath, \"unrecognized file in queue directory (use the -fix flag to move it away)\")\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tnpath := filepath.Join(dataDir, \"moved\", \"queue\", p)\n\t\t\tensureDir(npath)\n\t\t\terr = os.Rename(qpath, npath)\n\t\t\tcheckf(err, qpath, \"moving queue message file away\")\n\t\t\tif err == nil {\n\t\t\t\tlog.Printf(\"warning: moved %s to %s\", qpath, npath)\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t\tcheckf(err, qdir, \"walking queue directory\")\n\t}\n\n\t// Check an account, with its database file and messages.\n\tcheckAccount := func(name string) {\n\t\taccdir := filepath.Join(dataDir, \"accounts\", name)\n\t\tcheckDB(true, filepath.Join(accdir, \"index.db\"), store.DBTypes)\n\n\t\tjfdbpath := filepath.Join(accdir, \"junkfilter.db\")\n\t\tjfbloompath := filepath.Join(accdir, \"junkfilter.bloom\")\n\t\tif exists(jfdbpath) || exists(jfbloompath) {\n\t\t\tcheckDB(true, jfdbpath, junk.DBTypes)\n\t\t}\n\t\t// todo: add some kind of check for the bloom filter?\n\n\t\t// Check that all messages in the database have a message file on disk.\n\t\t// And check consistency of UIDs with the mailbox UIDNext, and check UIDValidity.\n\t\tseen := map[string]struct{}{}\n\t\tdbpath := filepath.Join(accdir, \"index.db\")\n\t\topts := bstore.Options{MustExist: true, RegisterLogger: c.log.Logger}\n\t\tdb, err := bstore.Open(ctxbg, dbpath, &opts, store.DBTypes...)\n\t\tcheckf(err, dbpath, \"opening account database to check messages\")\n\t\tif err == nil {\n\t\t\tuidvalidity := store.NextUIDValidity{ID: 1}\n\t\t\tif err := db.Get(ctxbg, &uidvalidity); err != nil {\n\t\t\t\tcheckf(err, dbpath, \"missing nextuidvalidity\")\n\t\t\t}\n\n\t\t\tup := store.Upgrade{ID: 1}\n\t\t\tif err := db.Get(ctxbg, &up); err != nil {\n\t\t\t\tlog.Printf(\"warning: %s: getting upgrade record (continuing, but not checking message threading): %v\", dbpath, err)\n\t\t\t} else if up.Threads != 2 {\n\t\t\t\tlog.Printf(\"warning: %s: no message threading in database, skipping checks for threading consistency\", dbpath)\n\t\t\t}\n\n\t\t\tmailboxes := map[int64]store.Mailbox{}\n\t\t\terr := bstore.QueryDB[store.Mailbox](ctxbg, db).ForEach(func(mb store.Mailbox) error {\n\t\t\t\tmailboxes[mb.ID] = mb\n\n\t\t\t\tif mb.UIDValidity >= uidvalidity.Next {\n\t\t\t\t\tcheckf(errors.New(`inconsistent uidvalidity for mailbox/account, see \"mox fixuidmeta\"`), dbpath, \"mailbox %q (id %d) has uidvalidity %d >= account nextuidvalidity %d\", mb.Name, mb.ID, mb.UIDValidity, uidvalidity.Next)\n\t\t\t\t}\n\t\t\t\treturn nil\n\t\t\t})\n\t\t\tcheckf(err, dbpath, \"reading mailboxes to check uidnext consistency\")\n\n\t\t\tmbCounts := map[int64]store.MailboxCounts{}\n\t\t\tvar totalSize int64\n\t\t\terr = bstore.QueryDB[store.Message](ctxbg, db).ForEach(func(m store.Message) error {\n\t\t\t\tmb := mailboxes[m.MailboxID]\n\t\t\t\tif m.UID >= mb.UIDNext {\n\t\t\t\t\tcheckf(errors.New(`inconsistent uidnext for message/mailbox, see \"mox fixuidmeta\"`), dbpath, \"message id %d in mailbox %q (id %d) has uid %d >= mailbox uidnext %d\", m.ID, mb.Name, mb.ID, m.UID, mb.UIDNext)\n\t\t\t\t}\n\n\t\t\t\tif m.ModSeq < m.CreateSeq {\n\t\t\t\t\tcheckf(errors.New(`inconsistent modseq/createseq for message`), dbpath, \"message id %d in mailbox %q (id %d) has modseq %d < createseq %d\", m.ID, mb.Name, mb.ID, m.ModSeq, m.CreateSeq)\n\t\t\t\t}\n\n\t\t\t\tmc := mbCounts[mb.ID]\n\t\t\t\tmc.Add(m.MailboxCounts())\n\t\t\t\tmbCounts[mb.ID] = mc\n\n\t\t\t\tif m.Expunged {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t\ttotalSize += m.Size\n\n\t\t\t\tmp := store.MessagePath(m.ID)\n\t\t\t\tseen[mp] = struct{}{}\n\t\t\t\tp := filepath.Join(accdir, \"msg\", mp)\n\t\t\t\tcheckFile(dbpath, p, len(m.MsgPrefix), m.Size)\n\n\t\t\t\tif up.Threads != 2 {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\n\t\t\t\tif m.ThreadID <= 0 {\n\t\t\t\t\tcheckf(errors.New(`see \"mox reassignthreads\"`), dbpath, \"message id %d, thread %d in mailbox %q (id %d) has bad threadid\", m.ID, m.ThreadID, mb.Name, mb.ID)\n\t\t\t\t}\n\t\t\t\tif len(m.ThreadParentIDs) == 0 {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t\tif slices.Contains(m.ThreadParentIDs, m.ID) {\n\t\t\t\t\tcheckf(errors.New(`see \"mox reassignthreads\"`), dbpath, \"message id %d, thread %d in mailbox %q (id %d) has itself as thread parent\", m.ID, m.ThreadID, mb.Name, mb.ID)\n\t\t\t\t}\n\t\t\t\tfor i, pid := range m.ThreadParentIDs {\n\t\t\t\t\tam := store.Message{ID: pid}\n\t\t\t\t\tif err := db.Get(ctxbg, &am); err == bstore.ErrAbsent {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t} else if err != nil {\n\t\t\t\t\t\treturn fmt.Errorf(\"get ancestor message: %v\", err)\n\t\t\t\t\t} else if !slices.Equal(m.ThreadParentIDs[i+1:], am.ThreadParentIDs) {\n\t\t\t\t\t\tcheckf(errors.New(`see \"mox reassignthreads\"`), dbpath, \"message %d, thread %d has ancestor ids %v, and ancestor at index %d with id %d should have the same tail but has %v\", m.ID, m.ThreadID, m.ThreadParentIDs, i, am.ID, am.ThreadParentIDs)\n\t\t\t\t\t} else {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn nil\n\t\t\t})\n\t\t\tcheckf(err, dbpath, \"reading messages in account database to check files\")\n\n\t\t\thaveCounts := true\n\t\t\tfor _, mb := range mailboxes {\n\t\t\t\t// We only check if database doesn't have zero values, i.e. not yet set.\n\t\t\t\tif !mb.HaveCounts {\n\t\t\t\t\thaveCounts = false\n\t\t\t\t}\n\t\t\t\tif mb.HaveCounts && mb.MailboxCounts != mbCounts[mb.ID] {\n\t\t\t\t\tcheckf(errors.New(`wrong mailbox counts, see \"mox recalculatemailboxcounts\"`), dbpath, \"mailbox %q (id %d) has wrong counts %s, should be %s\", mb.Name, mb.ID, mb.MailboxCounts, mbCounts[mb.ID])\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif haveCounts {\n\t\t\t\tdu := store.DiskUsage{ID: 1}\n\t\t\t\terr := db.Get(ctxbg, &du)\n\t\t\t\tif err == nil {\n\t\t\t\t\tif du.MessageSize != totalSize {\n\t\t\t\t\t\tcheckf(errors.New(`wrong total message size, see mox recalculatemailboxcounts\"`), dbpath, \"account has wrong total message size %d, should be %d\", du.MessageSize, totalSize)\n\t\t\t\t\t}\n\t\t\t\t} else if err != nil && !errors.Is(err, bstore.ErrAbsent) {\n\t\t\t\t\tcheckf(err, dbpath, \"get disk usage\")\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Walk through all files in the msg directory. Warn about files that weren't in\n\t\t// the database as message file. Possibly move away files that could cause trouble.\n\t\tmsgdir := filepath.Join(accdir, \"msg\")\n\t\tif !exists(msgdir) {\n\t\t\t// New accounts with messages don't have a msg directory.\n\t\t\treturn\n\t\t}\n\t\terr = filepath.WalkDir(msgdir, func(msgpath string, d fs.DirEntry, err error) error {\n\t\t\tcheckf(err, msgpath, \"walk\")\n\t\t\tif err != nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif d.IsDir() {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tp := msgpath[len(msgdir)+1:]\n\t\t\tif _, ok := seen[p]; ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tl := strings.Split(p, string(filepath.Separator))\n\t\t\tif len(l) == 1 {\n\t\t\t\tlog.Printf(\"warning: %s: unrecognized file in message directory, ignoring\", msgpath)\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif !fix {\n\t\t\t\tcheckf(errors.New(\"may interfere with future account messages\"), msgpath, \"unrecognized file in account message directory (use the -fix flag to move it away)\")\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tnpath := filepath.Join(dataDir, \"moved\", \"accounts\", name, \"msg\", p)\n\t\t\tensureDir(npath)\n\t\t\terr = os.Rename(msgpath, npath)\n\t\t\tcheckf(err, msgpath, \"moving account message file away\")\n\t\t\tif err == nil {\n\t\t\t\tlog.Printf(\"warning: moved %s to %s\", msgpath, npath)\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t\tcheckf(err, msgdir, \"walking account message directory\")\n\t}\n\n\t// Check everything in the \"accounts\" directory.\n\tcheckAccounts := func() {\n\t\taccountsDir := filepath.Join(dataDir, \"accounts\")\n\t\tentries, err := os.ReadDir(accountsDir)\n\t\tcheckf(err, accountsDir, \"reading accounts directory\")\n\t\tfor _, e := range entries {\n\t\t\t// We treat all directories as accounts. When we were backing up, we only verified\n\t\t\t// accounts from the config and made regular file copies of all other files\n\t\t\t// (perhaps an old account, but at least not with an open database file). It may\n\t\t\t// turn out that that account was/is not valid, generating warnings. Better safe\n\t\t\t// than sorry. It should hopefully get the admin to move away such an old account.\n\t\t\tif e.IsDir() {\n\t\t\t\tcheckAccount(e.Name())\n\t\t\t} else {\n\t\t\t\tlog.Printf(\"warning: %s: unrecognized file in accounts directory, ignoring\", filepath.Join(\"accounts\", e.Name()))\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check all files, skipping the known files, queue and accounts directories. Warn\n\t// about unknown files. Skip a \"tmp\" directory. And a \"moved\" directory, we\n\t// probably created it ourselves.\n\tbackupmoxversion := \"(unknown)\"\n\tcheckOther := func() {\n\t\terr := filepath.WalkDir(dataDir, func(dpath string, d fs.DirEntry, err error) error {\n\t\t\tcheckf(err, dpath, \"walk\")\n\t\t\tif err != nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif dpath == dataDir {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tp := dpath\n\t\t\tif dataDir != \".\" {\n\t\t\t\tp = p[len(dataDir)+1:]\n\t\t\t}\n\t\t\tswitch p {\n\t\t\tcase \"auth.db\", \"dmarcrpt.db\", \"dmarceval.db\", \"mtasts.db\", \"tlsrpt.db\", \"tlsrptresult.db\", \"receivedid.key\", \"lastknownversion\":\n\t\t\t\treturn nil\n\t\t\tcase \"acme\", \"queue\", \"accounts\", \"tmp\", \"moved\":\n\t\t\t\treturn fs.SkipDir\n\t\t\tcase \"moxversion\":\n\t\t\t\tbuf, err := os.ReadFile(dpath)\n\t\t\t\tcheckf(err, dpath, \"reading moxversion\")\n\t\t\t\tif err == nil {\n\t\t\t\t\tbackupmoxversion = string(buf)\n\t\t\t\t}\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tlog.Printf(\"warning: %s: unrecognized other file, ignoring\", dpath)\n\t\t\treturn nil\n\t\t})\n\t\tcheckf(err, dataDir, \"walking data directory\")\n\t}\n\n\tcheckDB(false, filepath.Join(dataDir, \"auth.db\"), store.AuthDBTypes) // Since v0.0.14.\n\tcheckDB(true, filepath.Join(dataDir, \"dmarcrpt.db\"), dmarcdb.ReportsDBTypes)\n\tcheckDB(false, filepath.Join(dataDir, \"dmarceval.db\"), dmarcdb.EvalDBTypes) // After v0.0.7.\n\tcheckDB(true, filepath.Join(dataDir, \"mtasts.db\"), mtastsdb.DBTypes)\n\tcheckDB(true, filepath.Join(dataDir, \"tlsrpt.db\"), tlsrptdb.ReportDBTypes)\n\tcheckDB(false, filepath.Join(dataDir, \"tlsrptresult.db\"), tlsrptdb.ResultDBTypes) // After v0.0.7.\n\tcheckQueue()\n\tcheckAccounts()\n\tcheckOther()\n\n\tif backupmoxversion != moxvar.Version {\n\t\tlog.Printf(\"NOTE: The backup was made with mox version %q, while verifydata was run with mox version %q. Database files have probably been modified by running mox verifydata. Make a fresh backup before upgrading.\", backupmoxversion, moxvar.Version)\n\t}\n\n\tif fail {\n\t\tlog.Fatalf(\"errors were found\")\n\t} else {\n\t\tfmt.Printf(\"%s: OK\\n\", dataDir)\n\t}\n}\n"
        },
        {
          "name": "webaccount",
          "type": "tree",
          "content": null
        },
        {
          "name": "webadmin",
          "type": "tree",
          "content": null
        },
        {
          "name": "webapi",
          "type": "tree",
          "content": null
        },
        {
          "name": "webapisrv",
          "type": "tree",
          "content": null
        },
        {
          "name": "webauth",
          "type": "tree",
          "content": null
        },
        {
          "name": "webhook",
          "type": "tree",
          "content": null
        },
        {
          "name": "webmail",
          "type": "tree",
          "content": null
        },
        {
          "name": "webops",
          "type": "tree",
          "content": null
        },
        {
          "name": "website",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}