{
  "metadata": {
    "timestamp": 1736567197576,
    "page": 795,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjgwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "yanyiwu/gojieba",
      "stars": 2465,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.056640625,
          "content": "tags\n*swp\n*.out\n*.o\n*.d\n*.ut\nbuild\nexample/example\n.idea\n\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 3.5439453125,
          "content": "# CHANGELOG\n\n## v1.4.4\n\n+ [NewJieba][cursor.ai-gen] check if the dictionary files exist\n+ [github/actions] go version using 1.20 at least\n+ [go.mod] go 1.13->1.17\n+ [github/actions] strategy: fail-fast: false\n+ [github/actions] add windows os test and remove go-1.17,1.18,1.19\n+ [github/actions] stale issues\n\n## v1.4.3\n\n+ [compile] add flags: -std=c++11 to fix [issue-123](https://github.com/yanyiwu/gojieba/issues/123)\n+ [github/actions] add macos os test\n\n## v1.4.2\n\n+ use default DICT_PATHs in config.go when args.path is empty str\n+ [deps/cppjieba] v5.1.2 -> v5.3.1\n+ README update demo url: gojieba-demo\n\n## v1.4.1\n\n+ [limonp] removed deps/limonp\n\n## v1.4.0\n\n+ [cppjieba] upgrade cppjieba to v5.1.2\n+ [github/actions] go-version: ['1.17', '1.18', '1.19', '1.20', '1.21']\n\n## v1.3.0\n\n- Merged [pr-103 AddWordEx](https://github.com/yanyiwu/gojieba/pull/103)\n\n## v1.2.0\n\n- Merged [pr-96 Fix - memory allocted by cgo will not automaticlly free by gc.](https://github.com/yanyiwu/gojieba/pull/96)\n- Merged [pr-99 feature: add RemoveWord api #99](https://github.com/yanyiwu/gojieba/pull/99)\n\n## v1.1.2\n\n+ upgrade cppjieba to v5.0.3\n\n## v1.1.1\n\n+ merge [pr-60](https://github.com/yanyiwu/gojieba/pull/60)\n\n## v1.1.0\n\n+ remove [bleve] to pass travis-ci testing.\n\n## v1.0.0\n\nNotice:\n\n+ remove NewExtractor, and use its api in Jieba.\n+ upgrade cppjieba to v5.0.0\n\n## v0.17.1\n\n+ fix [issue 8](https://github.com/yanyiwu/gojieba/issues/8)\n\n## v0.17.0\n\n+ add ExtractWithWeight api and fix [issue 6](https://github.com/yanyiwu/gojieba/issues/6)\n\n## v0.16.1\n\n+ fix [issue 5](https://github.com/yanyiwu/gojieba/issues/5)\n\n## v0.16.0\n\n+ upgrade cppjieba -> v4.8.1 and support (word,freq,tag) format of user dict\n+ add AddWord api\n\n## v0.15.0\n\n+ upgrade cppjieba -> v4.8.0, and make CutForSearch api behaves the same as jieba by Python\n+ remove SetCutForSearchThreshold api\n\n## v0.14.0\n\n+ upgrade cppjieba -> v4.7.0\n+ add new api: Tokenize for location information of words\n+ add new api: SetCutForSearchThreshold\n+ use Tokenize instead of Cut and SetCutForSearchThreshold(3) in gojieba/bleve\n\n## v0.13.0\n\n+ NewJieba(...string) support variable arguments\n+ NewExtractor(...string) support variable arguments\n+ removed example/ and write Example in `*_test.go`\n+ add some kind of Benchmark, Testing\n+ fix bug in extractor.go: calling C.free manully to free momery allocated by C.CString\n\n## v0.12.0\n\n+ supported [bleve] custom analyzer by using gojieba.\n\n## v0.11.1\n\n+ Fix bug: calling C.free manully to free momery allocated by C.CString.\n\n## v0.11.0\n\n+ Expose new api: Tag\n\n## v0.10.3\n\nUpgrade to fix potential trouble:\n\n+ limonp -> v0.6.0\n+ cppjieba -> v4.5.3\n\n## v0.10.2\n\n1. Fix error in `go vet` \n2. Upgrade limonp to v0.5.4 and cppjieba to v4.5.0 to support more unicode character\n\n## v0.10.1\n\nUpgrade:\n\n+ cppjieba -> v4.4.1 to fix bug, see details in [CppJieba ChangeLog v4.4.1](https://github.com/yanyiwu/cppjieba/blob/master/ChangeLog.md#v441)\n\n## v0.10.0\n\n1. 源码布局变动，增加 deps/ 管理外部依赖代码。\n2. 增加 Extractor 关键词抽取功能。\n3. Upgrade [limonp] to version v0.5.1\n4. Upgrade [cppjieba] to version v4.3.1\n5. 分词接口变动 New -> NewJieba\n6. 增加关键词抽取类 NewExtractor\n\n## v0.9.3\n\n1. 修复多余日志输出的问题。\n\n## v0.9.2\n\n1. 升级 [cppjieba] to v4.2.1  \n\n## v0.9.1\n\n1. 升级 [cppjieba] to v4.1.2  \n2. 增加英文介绍 `README_EN.md`\n\n## v0.9.0\n\n1. 完成基本分词功能：【全模式，精确模式，搜索引擎模式】\n\n[cppjieba]:https://github.com/yanyiwu/cppjieba\n[limonp]:https://github.com/yanyiwu/limonp\n[bleve]:https://github.com/blevesearch/bleve\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0625,
          "content": "MIT License\n\nCopyright (c) The project creators and maintainers\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 5.1259765625,
          "content": "# GoJieba\n\n[![Test](https://github.com/yanyiwu/gojieba/actions/workflows/test.yml/badge.svg)](https://github.com/yanyiwu/gojieba/actions/workflows/test.yml)\n[![Author](https://img.shields.io/badge/author-@yanyiwu-blue.svg?style=flat)](http://yanyiwu.com/) \n[![Tag](https://img.shields.io/github/v/tag/yanyiwu/gojieba.svg)](https://github.com/yanyiwu/gojieba/releases)\n[![Performance](https://img.shields.io/badge/performance-excellent-brightgreen.svg?style=flat)](http://yanyiwu.com/work/2015/06/14/jieba-series-performance-test.html) \n[![License](https://img.shields.io/badge/license-MIT-yellow.svg?style=flat)](http://yanyiwu.mit-license.org)\n[![GoDoc](https://godoc.org/github.com/yanyiwu/gojieba?status.svg)](https://godoc.org/github.com/yanyiwu/gojieba)\n[![Coverage Status](https://coveralls.io/repos/yanyiwu/gojieba/badge.svg?branch=master&service=github)](https://coveralls.io/github/yanyiwu/gojieba?branch=master)\n[![Go Report Card](https://goreportcard.com/badge/yanyiwu/gojieba)](https://goreportcard.com/report/yanyiwu/gojieba)\n[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/avelino/awesome-go) \n\n[GoJieba]是\"结巴\"中文分词的Golang语言版本。\n\n## 简介\n\n+ 支持多种分词方式，包括: 最大概率模式, HMM新词发现模式, 搜索引擎模式, 全模式\n+ 核心算法底层由C++实现，性能高效。\n+ 字典路径可配置，NewJieba(...string), NewExtractor(...string) 可变形参，当参数为空时使用默认词典(推荐方式)\n\n## 用法\n\n```bash\ngo get github.com/yanyiwu/gojieba\n```\n\n分词示例\n\n```golang\npackage main\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n\n\t\"github.com/yanyiwu/gojieba\"\n)\n\nfunc main() {\n\tvar s string\n\tvar words []string\n\tuse_hmm := true\n\tx := gojieba.NewJieba()\n\tdefer x.Free()\n\n\ts = \"我来到北京清华大学\"\n\twords = x.CutAll(s)\n\tfmt.Println(s)\n\tfmt.Println(\"全模式:\", strings.Join(words, \"/\"))\n\n\twords = x.Cut(s, use_hmm)\n\tfmt.Println(s)\n\tfmt.Println(\"精确模式:\", strings.Join(words, \"/\"))\n\ts = \"比特币\"\n\twords = x.Cut(s, use_hmm)\n\tfmt.Println(s)\n\tfmt.Println(\"精确模式:\", strings.Join(words, \"/\"))\n\n\tx.AddWord(\"比特币\")\n\t// `AddWordEx` 支持指定词语的权重，作为 `AddWord` 权重太低加词失败的补充。\n\t// `tag` 参数可以为空字符串，也可以指定词性。\n\t// x.AddWordEx(\"比特币\", 100000, \"\")\n\ts = \"比特币\"\n\twords = x.Cut(s, use_hmm)\n\tfmt.Println(s)\n\tfmt.Println(\"添加词典后,精确模式:\", strings.Join(words, \"/\"))\n\n\ts = \"他来到了网易杭研大厦\"\n\twords = x.Cut(s, use_hmm)\n\tfmt.Println(s)\n\tfmt.Println(\"新词识别:\", strings.Join(words, \"/\"))\n\n\ts = \"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\"\n\twords = x.CutForSearch(s, use_hmm)\n\tfmt.Println(s)\n\tfmt.Println(\"搜索引擎模式:\", strings.Join(words, \"/\"))\n\n\ts = \"长春市长春药店\"\n\twords = x.Tag(s)\n\tfmt.Println(s)\n\tfmt.Println(\"词性标注:\", strings.Join(words, \",\"))\n\n\ts = \"区块链\"\n\twords = x.Tag(s)\n\tfmt.Println(s)\n\tfmt.Println(\"词性标注:\", strings.Join(words, \",\"))\n\n\ts = \"长江大桥\"\n\twords = x.CutForSearch(s, !use_hmm)\n\tfmt.Println(s)\n\tfmt.Println(\"搜索引擎模式:\", strings.Join(words, \"/\"))\n\n\twordinfos := x.Tokenize(s, gojieba.SearchMode, !use_hmm)\n\tfmt.Println(s)\n\tfmt.Println(\"Tokenize:(搜索引擎模式)\", wordinfos)\n\n\twordinfos = x.Tokenize(s, gojieba.DefaultMode, !use_hmm)\n\tfmt.Println(s)\n\tfmt.Println(\"Tokenize:(默认模式)\", wordinfos)\n\n\tkeywords := x.ExtractWithWeight(s, 5)\n\tfmt.Println(\"Extract:\", keywords)\n}\n```\n\n```\n我来到北京清华大学\n全模式: 我/来到/北京/清华/清华大学/华大/大学\n我来到北京清华大学\n精确模式: 我/来到/北京/清华大学\n比特币\n精确模式: 比特/币\n比特币\n添加词典后,精确模式: 比特币\n他来到了网易杭研大厦\n新词识别: 他/来到/了/网易/杭研/大厦\n小明硕士毕业于中国科学院计算所，后在日本京都大学深造\n搜索引擎模式: 小明/硕士/毕业/于/中国/科学/学院/科学院/中国科学院/计算/计算所/，/后/在/日本/京都/大学/日本京都大学/深造\n长春市长春药店\n词性标注: 长春市/ns,长春/ns,药店/n\n区块链\n词性标注: 区块链/nz\n长江大桥\n搜索引擎模式: 长江/大桥/长江大桥\n长江大桥\nTokenize: [{长江 0 6} {大桥 6 12} {长江大桥 0 12}]\n```\n\nSee Details in [gojieba-demo](http://github.com/yanyiwu/gojieba-demo)\nSee example in [jieba_test](jieba_test.go), [extractor_test](extractor_test.go)\n\n## Benchmark\n\n[Jieba中文分词系列性能评测]\n\nUnittest\n\n```bash\ngo test ./...\n```\n\nBenchmark\n\n```bash\ngo test -bench \"Jieba\" -test.benchtime 10s\ngo test -bench \"Extractor\" -test.benchtime 10s\n```\n\n## Contributors\n\n### Code Contributors\n\nThis project exists thanks to all the people who contribute.\n<a href=\"https://github.com/yanyiwu/gojieba/graphs/contributors\"><img src=\"https://opencollective.com/gojieba/contributors.svg?width=890&button=false\" /></a>\n\n[CppJieba]:http://github.com/yanyiwu/cppjieba\n[GoJieba]:http://github.com/yanyiwu/gojieba\n[Jieba]:https://github.com/fxsjy/jieba\n[Jieba中文分词系列性能评测]:http://yanyiwu.com/work/2015/06/14/jieba-series-performance-test.html\n"
        },
        {
          "name": "config.go",
          "type": "blob",
          "size": 0.9638671875,
          "content": "package gojieba\n\nimport (\n\t\"path\"\n\t\"runtime\"\n)\n\nvar (\n\tDICT_DIR        string\n\tDICT_PATH       string\n\tHMM_PATH        string\n\tUSER_DICT_PATH  string\n\tIDF_PATH        string\n\tSTOP_WORDS_PATH string\n)\n\nfunc init() {\n\tDICT_DIR = path.Join(path.Dir(getCurrentFilePath()), \"deps/cppjieba/dict\")\n\tDICT_PATH = path.Join(DICT_DIR, \"jieba.dict.utf8\")\n\tHMM_PATH = path.Join(DICT_DIR, \"hmm_model.utf8\")\n\tUSER_DICT_PATH = path.Join(DICT_DIR, \"user.dict.utf8\")\n\tIDF_PATH = path.Join(DICT_DIR, \"idf.utf8\")\n\tSTOP_WORDS_PATH = path.Join(DICT_DIR, \"stop_words.utf8\")\n}\n\nconst TOTAL_DICT_PATH_NUMBER = 5\n\nfunc getDictPaths(args ...string) [TOTAL_DICT_PATH_NUMBER]string {\n\tdicts := [TOTAL_DICT_PATH_NUMBER]string{\n\t\tDICT_PATH,\n\t\tHMM_PATH,\n\t\tUSER_DICT_PATH,\n\t\tIDF_PATH,\n\t\tSTOP_WORDS_PATH,\n\t}\n\tfor i := 0; i < len(args) && i < len(dicts); i++ {\n\t\tif args[i] != \"\" {\n\t\t\tdicts[i] = args[i]\n\t\t}\n\t}\n\treturn dicts\n}\n\nfunc getCurrentFilePath() string {\n\t_, filePath, _, _ := runtime.Caller(1)\n\treturn filePath\n}\n"
        },
        {
          "name": "config_test.go",
          "type": "blob",
          "size": 0.111328125,
          "content": "package gojieba\n\nimport \"testing\"\n\nfunc TestConfig(t *testing.T) {\n\tfile := getCurrentFilePath()\n\tprintln(file)\n}\n"
        },
        {
          "name": "deps",
          "type": "tree",
          "content": null
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.0419921875,
          "content": "module github.com/yanyiwu/gojieba\n\ngo 1.17\n"
        },
        {
          "name": "jieba.cpp",
          "type": "blob",
          "size": 3.80859375,
          "content": "extern \"C\" {\n    #include \"jieba.h\"\n}\n\n#include \"cppjieba/Jieba.hpp\"\n\nstatic char** ConvertWords(const std::vector<std::string>& words) {\n  char ** res = (char**)malloc(sizeof(char*) * (words.size() + 1));\n  for (size_t i = 0; i < words.size(); i++) {\n    res[i] = (char*)malloc(sizeof(char) * (words[i].length() + 1));\n    strcpy(res[i], words[i].c_str());\n  }\n  res[words.size()] = NULL;\n  return res;\n}\n\nstatic Word* ConvertWords(const std::vector<cppjieba::Word>& words) {\n  Word* res = (Word*)malloc(sizeof(Word) * (words.size() + 1));\n  for (size_t i = 0; i < words.size(); i++) {\n    res[i].offset = words[i].offset;\n    res[i].len = words[i].word.size();\n  }\n  res[words.size()].offset = 0;\n  res[words.size()].len = 0;\n  return res;\n}\n\nstatic struct CWordWeight* ConvertWords(const std::vector<std::pair<std::string, double> >& words) {\n  struct CWordWeight* res = (struct CWordWeight*)malloc(sizeof(struct CWordWeight) * (words.size() + 1));\n  for (size_t i = 0; i < words.size(); i++) {\n    res[i].word = (char*)malloc(sizeof(char) * (words[i].first.length() + 1));\n    strcpy(res[i].word, words[i].first.c_str());\n    res[i].weight = words[i].second;\n  }\n  res[words.size()].word = NULL;\n  return res;\n}\n\nJieba NewJieba(const char* dict_path,\n      const char* hmm_path, \n      const char* user_dict,\n      const char* idf_path,\n      const char* stop_words_path) {\n  return (Jieba)(new cppjieba::Jieba(dict_path, hmm_path, user_dict, idf_path, stop_words_path));\n}\n\nvoid FreeJieba(Jieba x) {\n  delete (cppjieba::Jieba*)x;\n}\n\nchar** Cut(Jieba x, const char* sentence, int is_hmm_used) {\n  std::vector<std::string> words;\n  ((cppjieba::Jieba*)x)->Cut(sentence, words, is_hmm_used);\n  char** res = ConvertWords(words);\n  return res;\n}\n\nchar** CutAll(Jieba x, const char* sentence) {\n  std::vector<std::string> words;\n  ((cppjieba::Jieba*)x)->CutAll(sentence, words);\n  char** res = ConvertWords(words);\n  return res;\n}\n\nchar** CutForSearch(Jieba x, const char* sentence, int is_hmm_used) {\n  std::vector<std::string> words;\n  ((cppjieba::Jieba*)x)->CutForSearch(sentence, words, is_hmm_used);\n  char** res = ConvertWords(words);\n  return res;\n}\n\nchar** Tag(Jieba x, const char* sentence) {\n  std::vector<std::pair<std::string, std::string> > result;\n  ((cppjieba::Jieba*)x)->Tag(sentence, result);\n  std::vector<std::string> words;\n  words.reserve(result.size());\n  for (size_t i = 0; i < result.size(); ++i) {\n    words.push_back(result[i].first + \"/\" + result[i].second);\n  }\n  return ConvertWords(words);\n}\n\nvoid AddWord(Jieba x, const char* word) {\n  ((cppjieba::Jieba*)x)->InsertUserWord(word);\n}\n\nvoid AddWordEx(Jieba x, const char* word, int freq, const char* tag) {\n  ((cppjieba::Jieba*)x)->InsertUserWord(word, freq, tag);\n}\n\nvoid RemoveWord(Jieba x, const char* word) {\n  ((cppjieba::Jieba*)x)->DeleteUserWord(word);\n}\n\nWord* Tokenize(Jieba x, const char* sentence, TokenizeMode mode, int is_hmm_used) {\n  std::vector<cppjieba::Word> words;\n  switch (mode) {\n    case SearchMode:\n      ((cppjieba::Jieba*)x)->CutForSearch(sentence, words, is_hmm_used);\n      return ConvertWords(words);\n    default:\n      ((cppjieba::Jieba*)x)->Cut(sentence, words, is_hmm_used);\n      return ConvertWords(words);\n  }\n}\n\nstruct CWordWeight* ExtractWithWeight(Jieba handle, const char* sentence, int top_k) {\n  std::vector<std::pair<std::string, double> > words;\n  ((cppjieba::Jieba*)handle)->extractor.Extract(sentence, words, top_k);\n  struct CWordWeight* res = ConvertWords(words);\n  return res;\n}\n\nvoid FreeWordWeights(struct CWordWeight* wws) {\n  struct CWordWeight* x = wws;\n  while (x && x->word) {\n    free(x->word);\n    x->word = NULL;\n    x++;\n  }\n  free(wws);\n}\n\nchar** Extract(Jieba handle, const char* sentence, int top_k) {\n  std::vector<std::string> words;\n  ((cppjieba::Jieba*)handle)->extractor.Extract(sentence, words, top_k);\n  char** res = ConvertWords(words);\n  return res;\n}\n"
        },
        {
          "name": "jieba.go",
          "type": "blob",
          "size": 4.0234375,
          "content": "package gojieba\n\n/*\n#cgo CXXFLAGS: -I./deps/cppjieba/include -I./deps/cppjieba/deps/limonp/include -DLOGGING_LEVEL=LL_WARNING -O3 -Wno-deprecated -Wno-unused-variable -std=c++11\n#include <stdlib.h>\n#include \"jieba.h\"\n*/\nimport \"C\"\nimport (\n\t\"runtime\"\n\t\"unsafe\"\n\t\"os\"\n\t\"fmt\"\n)\n\ntype TokenizeMode int\n\nconst (\n\tDefaultMode TokenizeMode = iota\n\tSearchMode\n)\n\ntype Word struct {\n\tStr   string\n\tStart int\n\tEnd   int\n}\n\ntype Jieba struct {\n\tjieba C.Jieba\n}\n\nfunc NewJieba(paths ...string) *Jieba {\n\tdictpaths := getDictPaths(paths...)\n\t\n\t// check if the dictionary files exist\n\tfor _, path := range dictpaths {\n\t\tif _, err := os.Stat(path); os.IsNotExist(err) {\n\t\t\tpanic(fmt.Sprintf(\"Dictionary file does not exist: %s\", path))\n\t\t}\n\t}\n\n\tdpath, hpath, upath, ipath, spath := C.CString(dictpaths[0]), C.CString(dictpaths[1]), C.CString(dictpaths[2]), C.CString(dictpaths[3]), C.CString(dictpaths[4])\n\tdefer C.free(unsafe.Pointer(dpath))\n\tdefer C.free(unsafe.Pointer(hpath))\n\tdefer C.free(unsafe.Pointer(upath))\n\tdefer C.free(unsafe.Pointer(ipath))\n\tdefer C.free(unsafe.Pointer(spath))\n\tjieba := &Jieba{\n\t\tC.NewJieba(\n\t\t\tdpath,\n\t\t\thpath,\n\t\t\tupath,\n\t\t\tipath,\n\t\t\tspath,\n\t\t),\n\t}\n\t// set finalizer to free the memory when the object is garbage collected\n\truntime.SetFinalizer(jieba, (*Jieba).Free)\n\treturn jieba\n}\n\nfunc (x *Jieba) Free() {\n\tC.FreeJieba(x.jieba)\n}\n\nfunc (x *Jieba) Cut(s string, hmm bool) []string {\n\tc_int_hmm := 0\n\tif hmm {\n\t\tc_int_hmm = 1\n\t}\n\tcstr := C.CString(s)\n\tdefer C.free(unsafe.Pointer(cstr))\n\tvar words **C.char = C.Cut(x.jieba, cstr, C.int(c_int_hmm))\n\tdefer C.FreeWords(words)\n\tres := cstrings(words)\n\treturn res\n}\n\nfunc (x *Jieba) CutAll(s string) []string {\n\tcstr := C.CString(s)\n\tdefer C.free(unsafe.Pointer(cstr))\n\tvar words **C.char = C.CutAll(x.jieba, cstr)\n\tdefer C.FreeWords(words)\n\tres := cstrings(words)\n\treturn res\n}\n\nfunc (x *Jieba) CutForSearch(s string, hmm bool) []string {\n\tc_int_hmm := 0\n\tif hmm {\n\t\tc_int_hmm = 1\n\t}\n\tcstr := C.CString(s)\n\tdefer C.free(unsafe.Pointer(cstr))\n\tvar words **C.char = C.CutForSearch(x.jieba, cstr, C.int(c_int_hmm))\n\tdefer C.FreeWords(words)\n\tres := cstrings(words)\n\treturn res\n}\n\nfunc (x *Jieba) Tag(s string) []string {\n\tcstr := C.CString(s)\n\tdefer C.free(unsafe.Pointer(cstr))\n\tvar words **C.char = C.Tag(x.jieba, cstr)\n\tdefer C.FreeWords(words)\n\tres := cstrings(words)\n\treturn res\n}\n\nfunc (x *Jieba) AddWord(s string) {\n\tcstr := C.CString(s)\n\tdefer C.free(unsafe.Pointer(cstr))\n\tC.AddWord(x.jieba, cstr)\n}\n\nfunc (x *Jieba) AddWordEx(s string, freq int, tag string) {\n\tcstr := C.CString(s)\n\tctag := C.CString(tag)\n\tdefer C.free(unsafe.Pointer(ctag))\n\tdefer C.free(unsafe.Pointer(cstr))\n\tC.AddWordEx(x.jieba, cstr, C.int(freq), ctag)\n}\n\nfunc (x *Jieba) RemoveWord(s string) {\n\tcstr := C.CString(s)\n\tdefer C.free(unsafe.Pointer(cstr))\n\tC.RemoveWord(x.jieba, cstr)\n}\n\nfunc (x *Jieba) Tokenize(s string, mode TokenizeMode, hmm bool) []Word {\n\tc_int_hmm := 0\n\tif hmm {\n\t\tc_int_hmm = 1\n\t}\n\tcstr := C.CString(s)\n\tdefer C.free(unsafe.Pointer(cstr))\n\tvar words *C.Word = C.Tokenize(x.jieba, cstr, C.TokenizeMode(mode), C.int(c_int_hmm))\n\tdefer C.free(unsafe.Pointer(words))\n\treturn convertWords(s, words)\n}\n\ntype WordWeight struct {\n\tWord   string\n\tWeight float64\n}\n\nfunc (x *Jieba) Extract(s string, topk int) []string {\n\tcstr := C.CString(s)\n\tdefer C.free(unsafe.Pointer(cstr))\n\tvar words **C.char = C.Extract(x.jieba, cstr, C.int(topk))\n\tres := cstrings(words)\n\tdefer C.FreeWords(words)\n\treturn res\n}\n\nfunc (x *Jieba) ExtractWithWeight(s string, topk int) []WordWeight {\n\tcstr := C.CString(s)\n\tdefer C.free(unsafe.Pointer(cstr))\n\twords := C.ExtractWithWeight(x.jieba, cstr, C.int(topk))\n\tp := unsafe.Pointer(words)\n\tres := cwordweights((*C.struct_CWordWeight)(p))\n\tdefer C.FreeWordWeights(words)\n\treturn res\n}\n\nfunc cwordweights(x *C.struct_CWordWeight) []WordWeight {\n\tvar s []WordWeight\n\teltSize := unsafe.Sizeof(*x)\n\tfor (*x).word != nil {\n\t\tww := WordWeight{\n\t\t\tC.GoString(((C.struct_CWordWeight)(*x)).word),\n\t\t\tfloat64((*x).weight),\n\t\t}\n\t\ts = append(s, ww)\n\t\tx = (*C.struct_CWordWeight)(unsafe.Pointer(uintptr(unsafe.Pointer(x)) + eltSize))\n\t}\n\treturn s\n}\n"
        },
        {
          "name": "jieba.h",
          "type": "blob",
          "size": 1.1611328125,
          "content": "#ifndef CJIEBA_JIEBA_H\n#define CJIEBA_JIEBA_H\n\n#include <stdlib.h>\n#include \"util.h\"\n\ntypedef void* Jieba;\n\ntypedef struct {\n  size_t offset;\n  size_t len;\n} Word;\n\ntypedef enum {\n  DefaultMode = 0,\n  SearchMode = 1,\n} TokenizeMode;\n\nJieba NewJieba(const char* dict_path,\n      const char* hmm_path, \n      const char* user_dict,\n      const char* idf_path,\n      const char* stop_words_path);\nvoid FreeJieba(Jieba);\n\nchar** Cut(Jieba handle, const char* sentence, int is_hmm_used);\nchar** CutAll(Jieba handle, const char* sentence);\nchar** CutForSearch(Jieba handle, const char* sentence, int is_hmm_used);\nchar** Tag(Jieba handle, const char* sentence);\nvoid AddWord(Jieba handle, const char* word);\nvoid AddWordEx(Jieba handle, const char* word, int freq, const char* tag);\nvoid RemoveWord(Jieba handle, const char* word);\n\nWord* Tokenize(Jieba x, const char* sentence, TokenizeMode mode, int is_hmm_used);\n\nstruct CWordWeight {\n  char* word;\n  double weight;\n};\n\nchar** Extract(Jieba handle, const char* sentence, int top_k);\nstruct CWordWeight* ExtractWithWeight(Jieba handle, const char* sentence, int top_k);\nvoid FreeWordWeights(struct CWordWeight* wws);\n\n#endif // CJIEBA_JIEBA_H\n"
        },
        {
          "name": "jieba_test.go",
          "type": "blob",
          "size": 7.7724609375,
          "content": "package gojieba\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n\t\"strings\"\n\t\"testing\"\n)\n\nfunc ExampleJieba() {\n\tvar s string\n\tvar words []string\n\tuse_hmm := true\n\t//equals with x := NewJieba(DICT_PATH, HMM_PATH, USER_DICT_PATH)\n\tx := NewJieba()\n\tdefer x.Free()\n\n\ts = \"我来到北京清华大学\"\n\twords = x.CutAll(s)\n\tfmt.Println(s)\n\tfmt.Println(\"全模式:\", strings.Join(words, \"/\"))\n\n\twords = x.Cut(s, use_hmm)\n\tfmt.Println(s)\n\tfmt.Println(\"精确模式:\", strings.Join(words, \"/\"))\n\n\ts = \"比特币\"\n\twords = x.Cut(s, use_hmm)\n\tfmt.Println(s)\n\tfmt.Println(\"精确模式:\", strings.Join(words, \"/\"))\n\n\tx.AddWord(\"比特币\")\n\ts = \"比特币\"\n\twords = x.Cut(s, use_hmm)\n\tfmt.Println(s)\n\tfmt.Println(\"添加词典后,精确模式:\", strings.Join(words, \"/\"))\n\n\tx.AddWord(\"这是一个很长的关键字\")\n\ts = \"这是一个很长的关键字\"\n\twords = x.Extract(s, 3)\n\tfmt.Println(s)\n\tfmt.Println(\"添加词典后,Extract:\", strings.Join(words, \"/\"))\n\n\tx.RemoveWord(\"这是一个很长的关键字\")\n\ts = \"这是一个很长的关键字\"\n\twords = x.Extract(s, 3)\n\tfmt.Println(s)\n\tfmt.Println(\"从词典删除后,Extract:\", strings.Join(words, \"/\"))\n\n\ts = \"他来到了网易杭研大厦\"\n\twords = x.Cut(s, use_hmm)\n\tfmt.Println(s)\n\tfmt.Println(\"新词识别:\", strings.Join(words, \"/\"))\n\n\ts = \"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\"\n\twords = x.CutForSearch(s, use_hmm)\n\tfmt.Println(s)\n\tfmt.Println(\"搜索引擎模式:\", strings.Join(words, \"/\"))\n\n\ts = \"长春市长春药店\"\n\twords = x.Tag(s)\n\tfmt.Println(s)\n\tfmt.Println(\"词性标注:\", strings.Join(words, \",\"))\n\n\ts = \"区块链\"\n\twords = x.Tag(s)\n\tfmt.Println(s)\n\tfmt.Println(\"词性标注:\", strings.Join(words, \",\"))\n\n\ts = \"长江大桥\"\n\twords = x.CutForSearch(s, !use_hmm)\n\tfmt.Println(s)\n\tfmt.Println(\"搜索引擎模式:\", strings.Join(words, \"/\"))\n\n\twordinfos := x.Tokenize(s, SearchMode, !use_hmm)\n\tfmt.Println(s)\n\tfmt.Println(\"Tokenize:\", wordinfos)\n\n\t// Output:\n\t// 我来到北京清华大学\n\t// 全模式: 我/来到/北京/清华/清华大学/华大/大学\n\t// 我来到北京清华大学\n\t// 精确模式: 我/来到/北京/清华大学\n\t// 比特币\n\t// 精确模式: 比特/币\n\t// 比特币\n\t// 添加词典后,精确模式: 比特币\n\t// 这是一个很长的关键字\n\t// 添加词典后,Extract: 这是一个很长的关键字\n\t// 这是一个很长的关键字\n\t// 从词典删除后,Extract: 关键字/很长/这是\n\t// 他来到了网易杭研大厦\n\t// 新词识别: 他/来到/了/网易/杭研/大厦\n\t// 小明硕士毕业于中国科学院计算所，后在日本京都大学深造\n\t// 搜索引擎模式: 小明/硕士/毕业/于/中国/科学/学院/科学院/中国科学院/计算/计算所/，/后/在/日本/京都/大学/日本京都大学/深造\n\t// 长春市长春药店\n\t// 词性标注: 长春市/ns,长春/ns,药店/n\n\t// 区块链\n\t// 词性标注: 区块链/nz\n\t// 长江大桥\n\t// 搜索引擎模式: 长江/大桥/长江大桥\n\t// 长江大桥\n\t// Tokenize: [{长江 0 6} {大桥 6 12} {长江大桥 0 12}]\n}\n\nfunc TestJieba(t *testing.T) {\n\t//equals with x := NewJieba(DICT_PATH, HMM_PATH, USER_DICT_PATH)\n\tx := NewJieba()\n\tdefer x.Free()\n\tvar s string\n\tvar expected string\n\tvar actual string\n\tvar use_hmm = true\n\n\ts = \"我来到北京清华大学\"\n\texpected = \"我/来到/北京/清华/清华大学/华大/大学\"\n\tactual = strings.Join(x.CutAll(s), \"/\")\n\tif expected != actual {\n\t\tt.Error(actual)\n\t}\n\n\ts = \"我来到北京清华大学\"\n\texpected = \"我/来到/北京/清华大学\"\n\tactual = strings.Join(x.Cut(s, use_hmm), \"/\")\n\tif expected != actual {\n\t\tt.Error(actual)\n\t}\n\n\ts = \"他来到了网易杭研大厦\"\n\texpected = \"他/来到/了/网易/杭研/大厦\"\n\tactual = strings.Join(x.Cut(s, use_hmm), \"/\")\n\tif expected != actual {\n\t\tt.Error(actual)\n\t}\n\n\ts = \"他来到了网易杭研大厦\"\n\texpected = \"他/来到/了/网易/杭/研/大厦\"\n\tactual = strings.Join(x.Cut(s, !use_hmm), \"/\")\n\tif expected != actual {\n\t\tt.Error(actual)\n\t}\n\n\ts = \"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\"\n\texpected = \"小明/硕士/毕业/于/中国/科学/学院/科学院/中国科学院/计算/计算所/，/后/在/日本/京都/大学/日本京都大学/深造\"\n\tactual = strings.Join(x.CutForSearch(s, use_hmm), \"/\")\n\tif expected != actual {\n\t\tt.Error(actual)\n\t}\n\n\ts = \"长春市长春药店\"\n\texpected = \"长春市/ns,长春/ns,药店/n\"\n\tactual = strings.Join(x.Tag(s), \",\")\n\tif expected != actual {\n\t\tt.Error(actual)\n\t}\n\n\ts = \"长春市长春药店\"\n\twordinfos := x.Tokenize(s, SearchMode, false)\n\texpectedwords := []Word{\n\t\tWord{Str: \"长春\", Start: 0, End: 6},\n\t\tWord{Str: \"长春市\", Start: 0, End: 9},\n\t\tWord{Str: \"长春\", Start: 9, End: 15},\n\t\tWord{Str: \"药店\", Start: 15, End: 21},\n\t}\n\tif !reflect.DeepEqual(wordinfos, expectedwords) {\n\t\tt.Error()\n\t}\n}\n\nfunc TestJiebaCutForSearch(t *testing.T) {\n\tx := NewJieba()\n\tdefer x.Free()\n\ts := \"长江大桥\"\n\twords := x.CutForSearch(s, false)\n\texpected := []string{\n\t\t\"长江\",\n\t\t\"大桥\",\n\t\t\"长江大桥\",\n\t}\n\tif !reflect.DeepEqual(words, expected) {\n\t\tt.Error(words, expected)\n\t}\n\twordinfos := x.Tokenize(s, SearchMode, false)\n\texpectedwords := []Word{\n\t\tWord{Str: \"长江\", Start: 0, End: 6},\n\t\tWord{Str: \"大桥\", Start: 6, End: 12},\n\t\tWord{Str: \"长江大桥\", Start: 0, End: 12},\n\t}\n\tif !reflect.DeepEqual(wordinfos, expectedwords) {\n\t\tt.Error(wordinfos, expectedwords)\n\t}\n}\n\nfunc TestNewJieba(t *testing.T) {\n\tx := NewJieba(\"\", \"\", \"./deps/cppjieba/dict/user.dict.utf8\", \"\", \"\")\n\tdefer x.Free()\n}\n\nfunc BenchmarkJieba(b *testing.B) {\n\t//equals with x := NewJieba(DICT_PATH, HMM_PATH, USER_DICT_PATH)\n\tx := NewJieba()\n\ts := \"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\"\n\tdefer x.Free()\n\tb.ResetTimer()\n\t// Stop Timer before x.Free()\n\tdefer b.StopTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tx.Cut(s, false)\n\t\tx.Cut(s, true)\n\t\tx.CutAll(s)\n\t\tx.CutForSearch(s, false)\n\t\tx.CutForSearch(s, true)\n\t\tx.Tag(s)\n\t\tx.Tokenize(s, DefaultMode, true)\n\t\tx.Tokenize(s, DefaultMode, false)\n\t}\n}\n\nfunc ExampleExtract() {\n\tx := NewJieba()\n\tdefer x.Free()\n\n\ts := \"我是拖拉机学院手扶拖拉机专业的。不用多久，我就会升职加薪，当上CEO，走上人生巅峰。\"\n\twords := x.Extract(s, 5)\n\tfmt.Println(s)\n\tfmt.Println(\"关键词抽取:\", strings.Join(words, \"/\"))\n\tword_weights := x.ExtractWithWeight(s, 5)\n\tfmt.Println(\"关键词抽取:\", word_weights)\n\n\tx.AddWord(\"人生巅峰\")\n\twords = x.Extract(s, 5)\n\tfmt.Println(\"AddWord后关键词抽取:\", strings.Join(words, \"/\"))\n\n\tx.RemoveWord(\"人生巅峰\")\n\twords = x.Extract(s, 5)\n\tfmt.Println(\"RemoveWord后关键词抽取:\", strings.Join(words, \"/\"))\n\t// Output:\n\t// 我是拖拉机学院手扶拖拉机专业的。不用多久，我就会升职加薪，当上CEO，走上人生巅峰。\n\t// 关键词抽取: CEO/升职/加薪/手扶拖拉机/巅峰\n\t// 关键词抽取: [{CEO 11.739204307083542} {升职 10.8561552143} {加薪 10.642581114} {手扶拖拉机 10.0088573539} {巅峰 9.49395840471}]\n\t// AddWord后关键词抽取: CEO/人生巅峰/升职/加薪/手扶拖拉机\n\t// RemoveWord后关键词抽取: CEO/升职/加薪/手扶拖拉机/巅峰\n}\n\nfunc TestExtractor(t *testing.T) {\n\tx := NewJieba()\n\tdefer x.Free()\n\ts := \"我是拖拉机学院手扶拖拉机专业的。不用多久，我就会升职加薪，当上CEO，走上人生巅峰。\"\n\texpected := \"CEO/升职/加薪/手扶拖拉机/巅峰\"\n\tactual := strings.Join(x.Extract(s, 5), \"/\")\n\tif expected != actual {\n\t\tt.Error(actual)\n\t}\n}\n\nfunc BenchmarkExtractor(b *testing.B) {\n\t// equals with:\n\t// x := NewExtractor(DICT_PATH, HMM_PATH, USER_DICT_PATH, IDF_PATH, STOP_WORDS_PATH)\n\tx := NewJieba()\n\tdefer x.Free()\n\ts := \"我是拖拉机学院手扶拖拉机专业的。不用多久，我就会升职加薪，当上CEO，走上人生巅峰。\"\n\tb.ResetTimer()\n\t// Stop Timer before x.Free()\n\tdefer b.StopTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tx.Extract(s, 10)\n\t\tx.ExtractWithWeight(s, 10)\n\t}\n}\n"
        },
        {
          "name": "util.c",
          "type": "blob",
          "size": 0.1669921875,
          "content": "#include \"util.h\"\n#include <stdlib.h>\n\nvoid FreeWords(char** words) {\n  char** x = words;\n  while (x && *x) {\n    free(*x);\n    *x = NULL;\n    x ++;\n  }\n  free(words);\n}\n\n"
        },
        {
          "name": "util.go",
          "type": "blob",
          "size": 1.12890625,
          "content": "package gojieba\n\n/*\n#include \"jieba.h\"\n*/\nimport \"C\"\nimport (\n\t\"os\"\n\t\"unsafe\"\n)\n\nfunc isDirExists(path string) bool {\n\tfi, err := os.Stat(path)\n\tif err != nil {\n\t\treturn os.IsExist(err)\n\t} else {\n\t\treturn fi.IsDir()\n\t}\n\treturn false\n}\n\nfunc cstrings(x **C.char) []string {\n\tvar s []string\n\teltSize := unsafe.Sizeof(*x)\n\tfor *x != nil {\n\t\ts = append(s, C.GoString(*x))\n\t\tx = (**C.char)(unsafe.Pointer(uintptr(unsafe.Pointer(x)) + eltSize))\n\t}\n\treturn s\n}\n\nfunc convertWords(s string, words *C.Word) []Word {\n\tresult := make([]Word, 0)\n\tx := words\n\teltSize := unsafe.Sizeof(*x)\n\tstart := 0\n\tend := 0\n\tfor (*x).len != 0 {\n\t\tstart = int((*x).offset)\n\t\tend = start + int((*x).len)\n\t\tresult = append(result, Word{s[start:end], start, end})\n\t\tx = (*C.Word)(unsafe.Pointer(uintptr(unsafe.Pointer(x)) + eltSize))\n\t}\n\treturn result\n}\n\n//func cwordweights(x unsafe.Pointer) []WordWeight {\n//\tvar s []WordWeight\n//\teltSize := 16\n//\tfor (*(*C.char))(x) != nil {\n//\t\tww := WordWeight{\n//\t\t\tC.GoString((*C.char))(x)),\n//\t\t\t(*x).weight,\n//\t\t}\n//\t\ts = append(s, ww)\n//\t\tx = (*C.struct_CWordWeight)(unsafe.Pointer(uintptr(unsafe.Pointer(x)) + eltSize))\n//\t}\n//\treturn s\n//}\n"
        },
        {
          "name": "util.h",
          "type": "blob",
          "size": 0.09765625,
          "content": "#ifndef CJIEBA_UTIL_H\n#define CJIEBA_UTIL_H\n\nvoid FreeWords(char** words);\n\n#endif // CJIEBA_UTIL_H\n"
        }
      ]
    }
  ]
}