{
  "metadata": {
    "timestamp": 1736567372880,
    "page": 979,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjk4MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "VictoriaMetrics/fastcache",
      "stars": 2163,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0576171875,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2018 VictoriaMetrics\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 6.2353515625,
          "content": "[![Build Status](https://github.com/VictoriaMetrics/fastcache/workflows/main/badge.svg)](https://github.com/VictoriaMetrics/fastcache/actions)\n[![GoDoc](https://godoc.org/github.com/VictoriaMetrics/fastcache?status.svg)](http://godoc.org/github.com/VictoriaMetrics/fastcache)\n[![Go Report](https://goreportcard.com/badge/github.com/VictoriaMetrics/fastcache)](https://goreportcard.com/report/github.com/VictoriaMetrics/fastcache)\n[![codecov](https://codecov.io/gh/VictoriaMetrics/fastcache/branch/master/graph/badge.svg)](https://codecov.io/gh/VictoriaMetrics/fastcache)\n\n# fastcache - fast thread-safe inmemory cache for big number of entries in Go\n\n### Features\n\n* Fast. Performance scales on multi-core CPUs. See benchmark results below.\n* Thread-safe. Concurrent goroutines may read and write into a single\n  cache instance.\n* The fastcache is designed for storing big number of entries without\n  [GC overhead](https://syslog.ravelin.com/further-dangers-of-large-heaps-in-go-7a267b57d487).\n* Fastcache automatically evicts old entries when reaching the maximum cache size\n  set on its creation.\n* [Simple API](http://godoc.org/github.com/VictoriaMetrics/fastcache).\n* Simple source code.\n* Cache may be [saved to file](https://godoc.org/github.com/VictoriaMetrics/fastcache#Cache.SaveToFile)\n  and [loaded from file](https://godoc.org/github.com/VictoriaMetrics/fastcache#LoadFromFile).\n* Works on [Google AppEngine](https://cloud.google.com/appengine/docs/go/).\n\n\n### Benchmarks\n\n`Fastcache` performance is compared with [BigCache](https://github.com/allegro/bigcache), standard Go map\nand [sync.Map](https://golang.org/pkg/sync/#Map).\n\n```\nGOMAXPROCS=4 go test github.com/VictoriaMetrics/fastcache -bench='Set|Get' -benchtime=10s\ngoos: linux\ngoarch: amd64\npkg: github.com/VictoriaMetrics/fastcache\nBenchmarkBigCacheSet-4      \t    2000\t  10566656 ns/op\t   6.20 MB/s\t 4660369 B/op\t       6 allocs/op\nBenchmarkBigCacheGet-4      \t    2000\t   6902694 ns/op\t   9.49 MB/s\t  684169 B/op\t  131076 allocs/op\nBenchmarkBigCacheSetGet-4   \t    1000\t  17579118 ns/op\t   7.46 MB/s\t 5046744 B/op\t  131083 allocs/op\nBenchmarkCacheSet-4         \t    5000\t   3808874 ns/op\t  17.21 MB/s\t    1142 B/op\t       2 allocs/op\nBenchmarkCacheGet-4         \t    5000\t   3293849 ns/op\t  19.90 MB/s\t    1140 B/op\t       2 allocs/op\nBenchmarkCacheSetGet-4      \t    2000\t   8456061 ns/op\t  15.50 MB/s\t    2857 B/op\t       5 allocs/op\nBenchmarkStdMapSet-4        \t    2000\t  10559382 ns/op\t   6.21 MB/s\t  268413 B/op\t   65537 allocs/op\nBenchmarkStdMapGet-4        \t    5000\t   2687404 ns/op\t  24.39 MB/s\t    2558 B/op\t      13 allocs/op\nBenchmarkStdMapSetGet-4     \t     100\t 154641257 ns/op\t   0.85 MB/s\t  387405 B/op\t   65558 allocs/op\nBenchmarkSyncMapSet-4       \t     500\t  24703219 ns/op\t   2.65 MB/s\t 3426543 B/op\t  262411 allocs/op\nBenchmarkSyncMapGet-4       \t    5000\t   2265892 ns/op\t  28.92 MB/s\t    2545 B/op\t      79 allocs/op\nBenchmarkSyncMapSetGet-4    \t    1000\t  14595535 ns/op\t   8.98 MB/s\t 3417190 B/op\t  262277 allocs/op\n```\n\n`MB/s` column here actually means `millions of operations per second`.\nAs you can see, `fastcache` is faster than the `BigCache` in all the cases.\n`fastcache` is faster than the standard Go map and `sync.Map` on workloads\nwith inserts.\n\n\n### Limitations\n\n* Keys and values must be byte slices. Other types must be marshaled before\n  storing them in the cache.\n* Big entries with sizes exceeding 64KB must be stored via [distinct API](http://godoc.org/github.com/VictoriaMetrics/fastcache#Cache.SetBig).\n* There is no cache expiration. Entries are evicted from the cache only\n  on cache size overflow. Entry deadline may be stored inside the value in order\n  to implement cache expiration.\n\n\n### Architecture details\n\nThe cache uses ideas from [BigCache](https://github.com/allegro/bigcache):\n\n* The cache consists of many buckets, each with its own lock.\n  This helps scaling the performance on multi-core CPUs, since multiple\n  CPUs may concurrently access distinct buckets.\n* Each bucket consists of a `hash(key) -> (key, value) position` map\n  and 64KB-sized byte slices (chunks) holding encoded `(key, value)` entries.\n  Each bucket contains only `O(chunksCount)` pointers. For instance, 64GB cache\n  would contain ~1M pointers, while similarly-sized `map[string][]byte`\n  would contain ~1B pointers for short keys and values. This would lead to\n  [huge GC overhead](https://syslog.ravelin.com/further-dangers-of-large-heaps-in-go-7a267b57d487).\n\n64KB-sized chunks reduce memory fragmentation and the total memory usage comparing\nto a single big chunk per bucket.\nChunks are allocated off-heap if possible. This reduces total memory usage because\nGC collects unused memory more frequently without the need in `GOGC` tweaking.\n\n\n### Users\n\n* `Fastcache` has been extracted from [VictoriaMetrics](https://github.com/VictoriaMetrics/VictoriaMetrics) sources.\n  See [this article](https://medium.com/devopslinks/victoriametrics-creating-the-best-remote-storage-for-prometheus-5d92d66787ac)\n  for more info about `VictoriaMetrics`.\n\n\n### FAQ\n\n#### What is the difference between `fastcache` and other similar caches like [BigCache](https://github.com/allegro/bigcache) or [FreeCache](https://github.com/coocood/freecache)?\n\n* `Fastcache` is faster. See benchmark results above.\n* `Fastcache` uses less memory due to lower heap fragmentation. This allows\n  saving many GBs of memory on multi-GB caches.\n* `Fastcache` API [is simpler](http://godoc.org/github.com/VictoriaMetrics/fastcache).\n  The API is designed to be used in zero-allocation mode.\n\n\n#### Why `fastcache` doesn't support cache expiration?\n\nBecause we don't need cache expiration in [VictoriaMetrics](https://github.com/VictoriaMetrics/VictoriaMetrics).\nCached entries inside `VictoriaMetrics` never expire. They are automatically evicted on cache size overflow.\n\nIt is easy to implement cache expiration on top of `fastcache` by caching values\nwith marshaled deadlines and verifying deadlines after reading these values\nfrom the cache.\n\n\n#### Why `fastcache` doesn't support advanced features such as [thundering herd protection](https://en.wikipedia.org/wiki/Thundering_herd_problem) or callbacks on entries' eviction?\n\nBecause these features would complicate the code and would make it slower.\n`Fastcache` source code is simple - just copy-paste it and implement the feature you want\non top of it.\n"
        },
        {
          "name": "bigcache.go",
          "type": "blob",
          "size": 4.1357421875,
          "content": "package fastcache\n\nimport (\n\t\"sync\"\n\t\"sync/atomic\"\n\n\txxhash \"github.com/cespare/xxhash/v2\"\n)\n\n// maxSubvalueLen is the maximum size of subvalue chunk.\n//\n// - 16 bytes are for subkey encoding\n// - 4 bytes are for len(key)+len(value) encoding inside fastcache\n// - 1 byte is implementation detail of fastcache\nconst maxSubvalueLen = chunkSize - 16 - 4 - 1\n\n// maxKeyLen is the maximum size of key.\n//\n// - 16 bytes are for (hash + valueLen)\n// - 4 bytes are for len(key)+len(subkey)\n// - 1 byte is implementation detail of fastcache\nconst maxKeyLen = chunkSize - 16 - 4 - 1\n\n// SetBig sets (k, v) to c where len(v) may exceed 64KB.\n//\n// GetBig must be used for reading stored values.\n//\n// The stored entry may be evicted at any time either due to cache\n// overflow or due to unlikely hash collision.\n// Pass higher maxBytes value to New if the added items disappear\n// frequently.\n//\n// It is safe to store entries smaller than 64KB with SetBig.\n//\n// k and v contents may be modified after returning from SetBig.\nfunc (c *Cache) SetBig(k, v []byte) {\n\tatomic.AddUint64(&c.bigStats.SetBigCalls, 1)\n\tif len(k) > maxKeyLen {\n\t\tatomic.AddUint64(&c.bigStats.TooBigKeyErrors, 1)\n\t\treturn\n\t}\n\tvalueLen := len(v)\n\tvalueHash := xxhash.Sum64(v)\n\n\t// Split v into chunks with up to 64Kb each.\n\tsubkey := getSubkeyBuf()\n\tvar i uint64\n\tfor len(v) > 0 {\n\t\tsubkey.B = marshalUint64(subkey.B[:0], valueHash)\n\t\tsubkey.B = marshalUint64(subkey.B, uint64(i))\n\t\ti++\n\t\tsubvalueLen := maxSubvalueLen\n\t\tif len(v) < subvalueLen {\n\t\t\tsubvalueLen = len(v)\n\t\t}\n\t\tsubvalue := v[:subvalueLen]\n\t\tv = v[subvalueLen:]\n\t\tc.Set(subkey.B, subvalue)\n\t}\n\n\t// Write metavalue, which consists of valueHash and valueLen.\n\tsubkey.B = marshalUint64(subkey.B[:0], valueHash)\n\tsubkey.B = marshalUint64(subkey.B, uint64(valueLen))\n\tc.Set(k, subkey.B)\n\tputSubkeyBuf(subkey)\n}\n\n// GetBig searches for the value for the given k, appends it to dst\n// and returns the result.\n//\n// GetBig returns only values stored via SetBig. It doesn't work\n// with values stored via other methods.\n//\n// k contents may be modified after returning from GetBig.\nfunc (c *Cache) GetBig(dst, k []byte) (r []byte) {\n\tatomic.AddUint64(&c.bigStats.GetBigCalls, 1)\n\tsubkey := getSubkeyBuf()\n\tdstWasNil := dst == nil\n\tdefer func() {\n\t\tputSubkeyBuf(subkey)\n\t\tif len(r) == 0 && dstWasNil {\n\t\t\t// Guarantee that if the caller provided nil and this is a cache miss that\n\t\t\t// the caller can accurately test for a cache miss with `if r == nil`.\n\t\t\tr = nil\n\t\t}\n\t}()\n\n\t// Read and parse metavalue\n\tsubkey.B = c.Get(subkey.B[:0], k)\n\tif len(subkey.B) == 0 {\n\t\t// Nothing found.\n\t\treturn dst\n\t}\n\tif len(subkey.B) != 16 {\n\t\tatomic.AddUint64(&c.bigStats.InvalidMetavalueErrors, 1)\n\t\treturn dst\n\t}\n\tvalueHash := unmarshalUint64(subkey.B)\n\tvalueLen := unmarshalUint64(subkey.B[8:])\n\n\t// Collect result from chunks.\n\tdstLen := len(dst)\n\tif n := dstLen + int(valueLen) - cap(dst); n > 0 {\n\t\tdst = append(dst[:cap(dst)], make([]byte, n)...)\n\t}\n\tdst = dst[:dstLen]\n\tvar i uint64\n\tfor uint64(len(dst)-dstLen) < valueLen {\n\t\tsubkey.B = marshalUint64(subkey.B[:0], valueHash)\n\t\tsubkey.B = marshalUint64(subkey.B, uint64(i))\n\t\ti++\n\t\tdstNew := c.Get(dst, subkey.B)\n\t\tif len(dstNew) == len(dst) {\n\t\t\t// Cannot find subvalue\n\t\t\treturn dst[:dstLen]\n\t\t}\n\t\tdst = dstNew\n\t}\n\n\t// Verify the obtained value.\n\tv := dst[dstLen:]\n\tif uint64(len(v)) != valueLen {\n\t\tatomic.AddUint64(&c.bigStats.InvalidValueLenErrors, 1)\n\t\treturn dst[:dstLen]\n\t}\n\th := xxhash.Sum64(v)\n\tif h != valueHash {\n\t\tatomic.AddUint64(&c.bigStats.InvalidValueHashErrors, 1)\n\t\treturn dst[:dstLen]\n\t}\n\treturn dst\n}\n\nfunc getSubkeyBuf() *bytesBuf {\n\tv := subkeyPool.Get()\n\tif v == nil {\n\t\treturn &bytesBuf{}\n\t}\n\treturn v.(*bytesBuf)\n}\n\nfunc putSubkeyBuf(bb *bytesBuf) {\n\tbb.B = bb.B[:0]\n\tsubkeyPool.Put(bb)\n}\n\nvar subkeyPool sync.Pool\n\ntype bytesBuf struct {\n\tB []byte\n}\n\nfunc marshalUint64(dst []byte, u uint64) []byte {\n\treturn append(dst, byte(u>>56), byte(u>>48), byte(u>>40), byte(u>>32), byte(u>>24), byte(u>>16), byte(u>>8), byte(u))\n}\n\nfunc unmarshalUint64(src []byte) uint64 {\n\t_ = src[7]\n\treturn uint64(src[0])<<56 | uint64(src[1])<<48 | uint64(src[2])<<40 | uint64(src[3])<<32 | uint64(src[4])<<24 | uint64(src[5])<<16 | uint64(src[6])<<8 | uint64(src[7])\n}\n"
        },
        {
          "name": "bigcache_test.go",
          "type": "blob",
          "size": 1.5859375,
          "content": "package fastcache\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"testing\"\n)\n\nfunc TestSetGetBig(t *testing.T) {\n\tc := New(256 * 1024 * 1024)\n\tconst valuesCount = 10\n\tfor _, valueSize := range []int{1, 100, 1<<16 - 1, 1 << 16, 1<<16 + 1, 1 << 17, 1<<17 + 1, 1<<17 - 1, 1 << 19} {\n\t\tt.Run(fmt.Sprintf(\"valueSize_%d\", valueSize), func(t *testing.T) {\n\t\t\tfor seed := 0; seed < 3; seed++ {\n\t\t\t\ttestSetGetBig(t, c, valueSize, valuesCount, seed)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc testSetGetBig(t *testing.T, c *Cache, valueSize, valuesCount, seed int) {\n\tm := make(map[string][]byte)\n\tvar buf []byte\n\tfor i := 0; i < valuesCount; i++ {\n\t\tkey := []byte(fmt.Sprintf(\"key %d\", i))\n\t\tvalue := createValue(valueSize, seed)\n\t\tc.SetBig(key, value)\n\t\tm[string(key)] = value\n\t\tbuf = c.GetBig(buf[:0], key)\n\t\tif !bytes.Equal(buf, value) {\n\t\t\tt.Fatalf(\"seed=%d; unexpected value obtained for key=%q; got len(value)=%d; want len(value)=%d\", seed, key, len(buf), len(value))\n\t\t}\n\t}\n\tvar s Stats\n\tc.UpdateStats(&s)\n\tif s.SetBigCalls < uint64(valuesCount) {\n\t\tt.Fatalf(\"expecting SetBigCalls >= %d; got %d\", valuesCount, s.SetBigCalls)\n\t}\n\tif s.GetBigCalls < uint64(valuesCount) {\n\t\tt.Fatalf(\"expecting GetBigCalls >= %d; got %d\", valuesCount, s.GetBigCalls)\n\t}\n\n\t// Verify that values stil exist\n\tfor key, value := range m {\n\t\tbuf = c.GetBig(buf[:0], []byte(key))\n\t\tif !bytes.Equal(buf, value) {\n\t\t\tt.Fatalf(\"seed=%d; unexpected value obtained for key=%q; got len(value)=%d; want len(value)=%d\", seed, key, len(buf), len(value))\n\t\t}\n\t}\n}\n\nfunc createValue(size, seed int) []byte {\n\tvar buf []byte\n\tfor i := 0; i < size; i++ {\n\t\tbuf = append(buf, byte(i+seed))\n\t}\n\treturn buf\n}\n"
        },
        {
          "name": "bigcache_timing_test.go",
          "type": "blob",
          "size": 0.59765625,
          "content": "package fastcache\n\nimport (\n\t\"testing\"\n)\n\nfunc BenchmarkSetBig(b *testing.B) {\n\tkey := []byte(\"key12345\")\n\tvalue := createValue(256*1024, 0)\n\tc := New(1024 * 1024)\n\tb.SetBytes(int64(len(value)))\n\tb.ReportAllocs()\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tfor pb.Next() {\n\t\t\tc.SetBig(key, value)\n\t\t}\n\t})\n}\n\nfunc BenchmarkGetBig(b *testing.B) {\n\tkey := []byte(\"key12345\")\n\tvalue := createValue(265*1024, 0)\n\tc := New(1024 * 1024)\n\tc.SetBig(key, value)\n\tb.SetBytes(int64(len(value)))\n\tb.ReportAllocs()\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tvar buf []byte\n\t\tfor pb.Next() {\n\t\t\tbuf = c.GetBig(buf[:0], key)\n\t\t}\n\t})\n}\n"
        },
        {
          "name": "fastcache.go",
          "type": "blob",
          "size": 11.46484375,
          "content": "// Package fastcache implements fast in-memory cache.\n//\n// The package has been extracted from https://victoriametrics.com/\npackage fastcache\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"sync/atomic\"\n\n\txxhash \"github.com/cespare/xxhash/v2\"\n)\n\nconst bucketsCount = 512\n\nconst chunkSize = 64 * 1024\n\nconst bucketSizeBits = 40\n\nconst genSizeBits = 64 - bucketSizeBits\n\nconst maxGen = 1<<genSizeBits - 1\n\nconst maxBucketSize uint64 = 1 << bucketSizeBits\n\n// Stats represents cache stats.\n//\n// Use Cache.UpdateStats for obtaining fresh stats from the cache.\ntype Stats struct {\n\t// GetCalls is the number of Get calls.\n\tGetCalls uint64\n\n\t// SetCalls is the number of Set calls.\n\tSetCalls uint64\n\n\t// Misses is the number of cache misses.\n\tMisses uint64\n\n\t// Collisions is the number of cache collisions.\n\t//\n\t// Usually the number of collisions must be close to zero.\n\t// High number of collisions suggest something wrong with cache.\n\tCollisions uint64\n\n\t// Corruptions is the number of detected corruptions of the cache.\n\t//\n\t// Corruptions may occur when corrupted cache is loaded from file.\n\tCorruptions uint64\n\n\t// EntriesCount is the current number of entries in the cache.\n\tEntriesCount uint64\n\n\t// BytesSize is the current size of the cache in bytes.\n\tBytesSize uint64\n\n\t// MaxBytesSize is the maximum allowed size of the cache in bytes (aka capacity).\n\tMaxBytesSize uint64\n\n\t// BigStats contains stats for GetBig/SetBig methods.\n\tBigStats\n}\n\n// Reset resets s, so it may be re-used again in Cache.UpdateStats.\nfunc (s *Stats) Reset() {\n\t*s = Stats{}\n}\n\n// BigStats contains stats for GetBig/SetBig methods.\ntype BigStats struct {\n\t// GetBigCalls is the number of GetBig calls.\n\tGetBigCalls uint64\n\n\t// SetBigCalls is the number of SetBig calls.\n\tSetBigCalls uint64\n\n\t// TooBigKeyErrors is the number of calls to SetBig with too big key.\n\tTooBigKeyErrors uint64\n\n\t// InvalidMetavalueErrors is the number of calls to GetBig resulting\n\t// to invalid metavalue.\n\tInvalidMetavalueErrors uint64\n\n\t// InvalidValueLenErrors is the number of calls to GetBig resulting\n\t// to a chunk with invalid length.\n\tInvalidValueLenErrors uint64\n\n\t// InvalidValueHashErrors is the number of calls to GetBig resulting\n\t// to a chunk with invalid hash value.\n\tInvalidValueHashErrors uint64\n}\n\nfunc (bs *BigStats) reset() {\n\tatomic.StoreUint64(&bs.GetBigCalls, 0)\n\tatomic.StoreUint64(&bs.SetBigCalls, 0)\n\tatomic.StoreUint64(&bs.TooBigKeyErrors, 0)\n\tatomic.StoreUint64(&bs.InvalidMetavalueErrors, 0)\n\tatomic.StoreUint64(&bs.InvalidValueLenErrors, 0)\n\tatomic.StoreUint64(&bs.InvalidValueHashErrors, 0)\n}\n\n// Cache is a fast thread-safe inmemory cache optimized for big number\n// of entries.\n//\n// It has much lower impact on GC comparing to a simple `map[string][]byte`.\n//\n// Use New or LoadFromFile* for creating new cache instance.\n// Concurrent goroutines may call any Cache methods on the same cache instance.\n//\n// Call Reset when the cache is no longer needed. This reclaims the allocated\n// memory.\ntype Cache struct {\n\tbuckets [bucketsCount]bucket\n\n\tbigStats BigStats\n}\n\n// New returns new cache with the given maxBytes capacity in bytes.\n//\n// maxBytes must be smaller than the available RAM size for the app,\n// since the cache holds data in memory.\n//\n// If maxBytes is less than 32MB, then the minimum cache capacity is 32MB.\nfunc New(maxBytes int) *Cache {\n\tif maxBytes <= 0 {\n\t\tpanic(fmt.Errorf(\"maxBytes must be greater than 0; got %d\", maxBytes))\n\t}\n\tvar c Cache\n\tmaxBucketBytes := uint64((maxBytes + bucketsCount - 1) / bucketsCount)\n\tfor i := range c.buckets[:] {\n\t\tc.buckets[i].Init(maxBucketBytes)\n\t}\n\treturn &c\n}\n\n// Set stores (k, v) in the cache.\n//\n// Get must be used for reading the stored entry.\n//\n// The stored entry may be evicted at any time either due to cache\n// overflow or due to unlikely hash collision.\n// Pass higher maxBytes value to New if the added items disappear\n// frequently.\n//\n// (k, v) entries with summary size exceeding 64KB aren't stored in the cache.\n// SetBig can be used for storing entries exceeding 64KB.\n//\n// k and v contents may be modified after returning from Set.\nfunc (c *Cache) Set(k, v []byte) {\n\th := xxhash.Sum64(k)\n\tidx := h % bucketsCount\n\tc.buckets[idx].Set(k, v, h)\n}\n\n// Get appends value by the key k to dst and returns the result.\n//\n// Get allocates new byte slice for the returned value if dst is nil.\n//\n// Get returns only values stored in c via Set.\n//\n// k contents may be modified after returning from Get.\nfunc (c *Cache) Get(dst, k []byte) []byte {\n\th := xxhash.Sum64(k)\n\tidx := h % bucketsCount\n\tdst, _ = c.buckets[idx].Get(dst, k, h, true)\n\treturn dst\n}\n\n// HasGet works identically to Get, but also returns whether the given key\n// exists in the cache. This method makes it possible to differentiate between a\n// stored nil/empty value versus and non-existing value.\nfunc (c *Cache) HasGet(dst, k []byte) ([]byte, bool) {\n\th := xxhash.Sum64(k)\n\tidx := h % bucketsCount\n\treturn c.buckets[idx].Get(dst, k, h, true)\n}\n\n// Has returns true if entry for the given key k exists in the cache.\nfunc (c *Cache) Has(k []byte) bool {\n\th := xxhash.Sum64(k)\n\tidx := h % bucketsCount\n\t_, ok := c.buckets[idx].Get(nil, k, h, false)\n\treturn ok\n}\n\n// Del deletes value for the given k from the cache.\n//\n// k contents may be modified after returning from Del.\nfunc (c *Cache) Del(k []byte) {\n\th := xxhash.Sum64(k)\n\tidx := h % bucketsCount\n\tc.buckets[idx].Del(h)\n}\n\n// Reset removes all the items from the cache.\nfunc (c *Cache) Reset() {\n\tfor i := range c.buckets[:] {\n\t\tc.buckets[i].Reset()\n\t}\n\tc.bigStats.reset()\n}\n\n// UpdateStats adds cache stats to s.\n//\n// Call s.Reset before calling UpdateStats if s is re-used.\nfunc (c *Cache) UpdateStats(s *Stats) {\n\tfor i := range c.buckets[:] {\n\t\tc.buckets[i].UpdateStats(s)\n\t}\n\ts.GetBigCalls += atomic.LoadUint64(&c.bigStats.GetBigCalls)\n\ts.SetBigCalls += atomic.LoadUint64(&c.bigStats.SetBigCalls)\n\ts.TooBigKeyErrors += atomic.LoadUint64(&c.bigStats.TooBigKeyErrors)\n\ts.InvalidMetavalueErrors += atomic.LoadUint64(&c.bigStats.InvalidMetavalueErrors)\n\ts.InvalidValueLenErrors += atomic.LoadUint64(&c.bigStats.InvalidValueLenErrors)\n\ts.InvalidValueHashErrors += atomic.LoadUint64(&c.bigStats.InvalidValueHashErrors)\n}\n\ntype bucket struct {\n\tmu sync.RWMutex\n\n\t// chunks is a ring buffer with encoded (k, v) pairs.\n\t// It consists of 64KB chunks.\n\tchunks [][]byte\n\n\t// m maps hash(k) to idx of (k, v) pair in chunks.\n\tm map[uint64]uint64\n\n\t// idx points to chunks for writing the next (k, v) pair.\n\tidx uint64\n\n\t// gen is the generation of chunks.\n\tgen uint64\n\n\tgetCalls    uint64\n\tsetCalls    uint64\n\tmisses      uint64\n\tcollisions  uint64\n\tcorruptions uint64\n}\n\nfunc (b *bucket) Init(maxBytes uint64) {\n\tif maxBytes == 0 {\n\t\tpanic(fmt.Errorf(\"maxBytes cannot be zero\"))\n\t}\n\tif maxBytes >= maxBucketSize {\n\t\tpanic(fmt.Errorf(\"too big maxBytes=%d; should be smaller than %d\", maxBytes, maxBucketSize))\n\t}\n\tmaxChunks := (maxBytes + chunkSize - 1) / chunkSize\n\tb.chunks = make([][]byte, maxChunks)\n\tb.m = make(map[uint64]uint64)\n\tb.Reset()\n}\n\nfunc (b *bucket) Reset() {\n\tb.mu.Lock()\n\tchunks := b.chunks\n\tfor i := range chunks {\n\t\tputChunk(chunks[i])\n\t\tchunks[i] = nil\n\t}\n\tb.m = make(map[uint64]uint64)\n\tb.idx = 0\n\tb.gen = 1\n\tatomic.StoreUint64(&b.getCalls, 0)\n\tatomic.StoreUint64(&b.setCalls, 0)\n\tatomic.StoreUint64(&b.misses, 0)\n\tatomic.StoreUint64(&b.collisions, 0)\n\tatomic.StoreUint64(&b.corruptions, 0)\n\tb.mu.Unlock()\n}\n\nfunc (b *bucket) cleanLocked() {\n\tbGen := b.gen & ((1 << genSizeBits) - 1)\n\tbIdx := b.idx\n\tbm := b.m\n\tnewItems := 0\n\tfor _, v := range bm {\n\t\tgen := v >> bucketSizeBits\n\t\tidx := v & ((1 << bucketSizeBits) - 1)\n\t\tif (gen+1 == bGen || gen == maxGen && bGen == 1) && idx >= bIdx || gen == bGen && idx < bIdx {\n\t\t\tnewItems++\n\t\t}\n\t}\n\tif newItems < len(bm) {\n\t\t// Re-create b.m with valid items, which weren't expired yet instead of deleting expired items from b.m.\n\t\t// This should reduce memory fragmentation and the number Go objects behind b.m.\n\t\t// See https://github.com/VictoriaMetrics/VictoriaMetrics/issues/5379\n\t\tbmNew := make(map[uint64]uint64, newItems)\n\t\tfor k, v := range bm {\n\t\t\tgen := v >> bucketSizeBits\n\t\t\tidx := v & ((1 << bucketSizeBits) - 1)\n\t\t\tif (gen+1 == bGen || gen == maxGen && bGen == 1) && idx >= bIdx || gen == bGen && idx < bIdx {\n\t\t\t\tbmNew[k] = v\n\t\t\t}\n\t\t}\n\t\tb.m = bmNew\n\t}\n}\n\nfunc (b *bucket) UpdateStats(s *Stats) {\n\ts.GetCalls += atomic.LoadUint64(&b.getCalls)\n\ts.SetCalls += atomic.LoadUint64(&b.setCalls)\n\ts.Misses += atomic.LoadUint64(&b.misses)\n\ts.Collisions += atomic.LoadUint64(&b.collisions)\n\ts.Corruptions += atomic.LoadUint64(&b.corruptions)\n\n\tb.mu.RLock()\n\ts.EntriesCount += uint64(len(b.m))\n\tbytesSize := uint64(0)\n\tfor _, chunk := range b.chunks {\n\t\tbytesSize += uint64(cap(chunk))\n\t}\n\ts.BytesSize += bytesSize\n\ts.MaxBytesSize += uint64(len(b.chunks)) * chunkSize\n\tb.mu.RUnlock()\n}\n\nfunc (b *bucket) Set(k, v []byte, h uint64) {\n\tatomic.AddUint64(&b.setCalls, 1)\n\tif len(k) >= (1<<16) || len(v) >= (1<<16) {\n\t\t// Too big key or value - its length cannot be encoded\n\t\t// with 2 bytes (see below). Skip the entry.\n\t\treturn\n\t}\n\tvar kvLenBuf [4]byte\n\tkvLenBuf[0] = byte(uint16(len(k)) >> 8)\n\tkvLenBuf[1] = byte(len(k))\n\tkvLenBuf[2] = byte(uint16(len(v)) >> 8)\n\tkvLenBuf[3] = byte(len(v))\n\tkvLen := uint64(len(kvLenBuf) + len(k) + len(v))\n\tif kvLen >= chunkSize {\n\t\t// Do not store too big keys and values, since they do not\n\t\t// fit a chunk.\n\t\treturn\n\t}\n\n\tchunks := b.chunks\n\tneedClean := false\n\tb.mu.Lock()\n\tidx := b.idx\n\tidxNew := idx + kvLen\n\tchunkIdx := idx / chunkSize\n\tchunkIdxNew := idxNew / chunkSize\n\tif chunkIdxNew > chunkIdx {\n\t\tif chunkIdxNew >= uint64(len(chunks)) {\n\t\t\tidx = 0\n\t\t\tidxNew = kvLen\n\t\t\tchunkIdx = 0\n\t\t\tb.gen++\n\t\t\tif b.gen&((1<<genSizeBits)-1) == 0 {\n\t\t\t\tb.gen++\n\t\t\t}\n\t\t\tneedClean = true\n\t\t} else {\n\t\t\tidx = chunkIdxNew * chunkSize\n\t\t\tidxNew = idx + kvLen\n\t\t\tchunkIdx = chunkIdxNew\n\t\t}\n\t\tchunks[chunkIdx] = chunks[chunkIdx][:0]\n\t}\n\tchunk := chunks[chunkIdx]\n\tif chunk == nil {\n\t\tchunk = getChunk()\n\t\tchunk = chunk[:0]\n\t}\n\tchunk = append(chunk, kvLenBuf[:]...)\n\tchunk = append(chunk, k...)\n\tchunk = append(chunk, v...)\n\tchunks[chunkIdx] = chunk\n\tb.m[h] = idx | (b.gen << bucketSizeBits)\n\tb.idx = idxNew\n\tif needClean {\n\t\tb.cleanLocked()\n\t}\n\tb.mu.Unlock()\n}\n\nfunc (b *bucket) Get(dst, k []byte, h uint64, returnDst bool) ([]byte, bool) {\n\tatomic.AddUint64(&b.getCalls, 1)\n\tfound := false\n\tchunks := b.chunks\n\tb.mu.RLock()\n\tv := b.m[h]\n\tbGen := b.gen & ((1 << genSizeBits) - 1)\n\tif v > 0 {\n\t\tgen := v >> bucketSizeBits\n\t\tidx := v & ((1 << bucketSizeBits) - 1)\n\t\tif gen == bGen && idx < b.idx || gen+1 == bGen && idx >= b.idx || gen == maxGen && bGen == 1 && idx >= b.idx {\n\t\t\tchunkIdx := idx / chunkSize\n\t\t\tif chunkIdx >= uint64(len(chunks)) {\n\t\t\t\t// Corrupted data during the load from file. Just skip it.\n\t\t\t\tatomic.AddUint64(&b.corruptions, 1)\n\t\t\t\tgoto end\n\t\t\t}\n\t\t\tchunk := chunks[chunkIdx]\n\t\t\tidx %= chunkSize\n\t\t\tif idx+4 >= chunkSize {\n\t\t\t\t// Corrupted data during the load from file. Just skip it.\n\t\t\t\tatomic.AddUint64(&b.corruptions, 1)\n\t\t\t\tgoto end\n\t\t\t}\n\t\t\tkvLenBuf := chunk[idx : idx+4]\n\t\t\tkeyLen := (uint64(kvLenBuf[0]) << 8) | uint64(kvLenBuf[1])\n\t\t\tvalLen := (uint64(kvLenBuf[2]) << 8) | uint64(kvLenBuf[3])\n\t\t\tidx += 4\n\t\t\tif idx+keyLen+valLen >= chunkSize {\n\t\t\t\t// Corrupted data during the load from file. Just skip it.\n\t\t\t\tatomic.AddUint64(&b.corruptions, 1)\n\t\t\t\tgoto end\n\t\t\t}\n\t\t\tif string(k) == string(chunk[idx:idx+keyLen]) {\n\t\t\t\tidx += keyLen\n\t\t\t\tif returnDst {\n\t\t\t\t\tdst = append(dst, chunk[idx:idx+valLen]...)\n\t\t\t\t}\n\t\t\t\tfound = true\n\t\t\t} else {\n\t\t\t\tatomic.AddUint64(&b.collisions, 1)\n\t\t\t}\n\t\t}\n\t}\nend:\n\tb.mu.RUnlock()\n\tif !found {\n\t\tatomic.AddUint64(&b.misses, 1)\n\t}\n\treturn dst, found\n}\n\nfunc (b *bucket) Del(h uint64) {\n\tb.mu.Lock()\n\tdelete(b.m, h)\n\tb.mu.Unlock()\n}\n"
        },
        {
          "name": "fastcache_gen_test.go",
          "type": "blob",
          "size": 2.78515625,
          "content": "package fastcache\n\nimport (\n\t\"bytes\"\n\t\"strconv\"\n\t\"testing\"\n)\n\nfunc TestGenerationOverflow(t *testing.T) {\n\tc := New(1) // each bucket has 64 *1024 bytes capacity\n\n\t// Initial generation is 1\n\tgenVal(t, c, 1)\n\n\t// These two keys has to the same bucket (100), so we can push the\n\t// generations up much faster.  The keys and values are sized so that\n\t// every time we push them into the cache they will completely fill the\n\t// bucket\n\tkey1 := []byte(strconv.Itoa(26))\n\tbigVal1 := make([]byte, (32*1024)-(len(key1)+4))\n\tfor i := range bigVal1 {\n\t\tbigVal1[i] = 1\n\t}\n\tkey2 := []byte(strconv.Itoa(8))\n\tbigVal2 := make([]byte, (32*1024)-(len(key2)+5))\n\tfor i := range bigVal2 {\n\t\tbigVal2[i] = 2\n\t}\n\n\t// Do some initial Set/Get demonstrate that this works\n\tfor i := 0; i < 10; i++ {\n\t\tc.Set(key1, bigVal1)\n\t\tc.Set(key2, bigVal2)\n\t\tgetVal(t, c, key1, bigVal1)\n\t\tgetVal(t, c, key2, bigVal2)\n\t\tgenVal(t, c, uint64(1+i))\n\t}\n\n\t// This is a hack to simulate calling Set 2^24-3 times\n\t// Actually doing this takes ~24 seconds, making the test slow\n\tc.buckets[100].gen = (1 << 24) - 2\n\n\t// c.buckets[100].gen == 16,777,215\n\t// Set/Get still works\n\n\tc.Set(key1, bigVal1)\n\tc.Set(key2, bigVal2)\n\n\tgetVal(t, c, key1, bigVal1)\n\tgetVal(t, c, key2, bigVal2)\n\n\tgenVal(t, c, (1<<24)-1)\n\n\t// After the next Set operations\n\t// c.buckets[100].gen == 16,777,216\n\n\t// This set creates an index where `idx | (b.gen << bucketSizeBits)` == 0\n\t// The value is in the cache but is unreadable by Get\n\tc.Set(key1, bigVal1)\n\n\t// The Set above overflowed the bucket's generation. This means that\n\t// key2 is still in the cache, but can't get read because key2 has a\n\t// _very large_ generation value and appears to be from the future\n\tgetVal(t, c, key2, bigVal2)\n\n\t// This Set creates an index where `(b.gen << bucketSizeBits)>>bucketSizeBits)==0`\n\t// The value is in the cache but is unreadable by Get\n\tc.Set(key2, bigVal2)\n\n\t// Ensure generations are working as we expect\n\t// NB: Here we skip the 2^24 generation, because the bucket carefully\n\t// avoids `generation==0`\n\tgenVal(t, c, (1<<24)+1)\n\n\tgetVal(t, c, key1, bigVal1)\n\tgetVal(t, c, key2, bigVal2)\n\n\t// Do it a few more times to show that this bucket is now unusable\n\tfor i := 0; i < 10; i++ {\n\t\tc.Set(key1, bigVal1)\n\t\tc.Set(key2, bigVal2)\n\t\tgetVal(t, c, key1, bigVal1)\n\t\tgetVal(t, c, key2, bigVal2)\n\t\tgenVal(t, c, uint64((1<<24)+2+i))\n\t}\n}\n\nfunc getVal(t *testing.T, c *Cache, key, expected []byte) {\n\tt.Helper()\n\tget := c.Get(nil, key)\n\tif !bytes.Equal(get, expected) {\n\t\tt.Errorf(\"Expected value (%v) was not returned from the cache, instead got %v\", expected[:10], get)\n\t}\n}\n\nfunc genVal(t *testing.T, c *Cache, expected uint64) {\n\tt.Helper()\n\tactual := c.buckets[100].gen\n\t// Ensure generations are working as we expect\n\tif actual != expected {\n\t\tt.Fatalf(\"Expected generation to be %d found %d instead\", expected, actual)\n\t}\n}\n"
        },
        {
          "name": "fastcache_test.go",
          "type": "blob",
          "size": 7.0888671875,
          "content": "package fastcache\n\nimport (\n\t\"fmt\"\n\t\"runtime\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestCacheSmall(t *testing.T) {\n\tc := New(1)\n\tdefer c.Reset()\n\n\tif v := c.Get(nil, []byte(\"aaa\")); len(v) != 0 {\n\t\tt.Fatalf(\"unexpected non-empty value obtained from small cache: %q\", v)\n\t}\n\tif v, exist := c.HasGet(nil, []byte(\"aaa\")); exist || len(v) != 0 {\n\t\tt.Fatalf(\"unexpected non-empty value obtained from small cache: %q\", v)\n\t}\n\n\tc.Set([]byte(\"key\"), []byte(\"value\"))\n\tif v := c.Get(nil, []byte(\"key\")); string(v) != \"value\" {\n\t\tt.Fatalf(\"unexpected value obtained; got %q; want %q\", v, \"value\")\n\t}\n\tif v := c.Get(nil, nil); len(v) != 0 {\n\t\tt.Fatalf(\"unexpected non-empty value obtained from small cache: %q\", v)\n\t}\n\tif v, exist := c.HasGet(nil, nil); exist {\n\t\tt.Fatalf(\"unexpected nil-keyed value obtained in small cache: %q\", v)\n\t}\n\tif v := c.Get(nil, []byte(\"aaa\")); len(v) != 0 {\n\t\tt.Fatalf(\"unexpected non-empty value obtained from small cache: %q\", v)\n\t}\n\n\tc.Set([]byte(\"aaa\"), []byte(\"bbb\"))\n\tif v := c.Get(nil, []byte(\"aaa\")); string(v) != \"bbb\" {\n\t\tt.Fatalf(\"unexpected value obtained; got %q; want %q\", v, \"bbb\")\n\t}\n\tif v, exist := c.HasGet(nil, []byte(\"aaa\")); !exist || string(v) != \"bbb\" {\n\t\tt.Fatalf(\"unexpected value obtained; got %q; want %q\", v, \"bbb\")\n\t}\n\n\tc.Reset()\n\tif v := c.Get(nil, []byte(\"aaa\")); len(v) != 0 {\n\t\tt.Fatalf(\"unexpected non-empty value obtained from empty cache: %q\", v)\n\t}\n\tif v, exist := c.HasGet(nil, []byte(\"aaa\")); exist || len(v) != 0 {\n\t\tt.Fatalf(\"unexpected non-empty value obtained from small cache: %q\", v)\n\t}\n\n\t// Test empty value\n\tk := []byte(\"empty\")\n\tc.Set(k, nil)\n\tif v := c.Get(nil, k); len(v) != 0 {\n\t\tt.Fatalf(\"unexpected non-empty value obtained from empty entry: %q\", v)\n\t}\n\tif v, exist := c.HasGet(nil, k); !exist {\n\t\tt.Fatalf(\"cannot find empty entry for key %q\", k)\n\t} else if len(v) != 0 {\n\t\tt.Fatalf(\"unexpected non-empty value obtained from empty entry: %q\", v)\n\t}\n\tif !c.Has(k) {\n\t\tt.Fatalf(\"cannot find empty entry for key %q\", k)\n\t}\n\tif c.Has([]byte(\"foobar\")) {\n\t\tt.Fatalf(\"non-existing entry found in the cache\")\n\t}\n}\n\nfunc TestCacheWrap(t *testing.T) {\n\tc := New(bucketsCount * chunkSize * 1.5)\n\tdefer c.Reset()\n\n\tcalls := uint64(5e6)\n\n\tfor i := uint64(0); i < calls; i++ {\n\t\tk := []byte(fmt.Sprintf(\"key %d\", i))\n\t\tv := []byte(fmt.Sprintf(\"value %d\", i))\n\t\tc.Set(k, v)\n\t\tvv := c.Get(nil, k)\n\t\tif string(vv) != string(v) {\n\t\t\tt.Fatalf(\"unexpected value for key %q; got %q; want %q\", k, vv, v)\n\t\t}\n\t}\n\tfor i := uint64(0); i < calls/10; i++ {\n\t\tx := i * 10\n\t\tk := []byte(fmt.Sprintf(\"key %d\", x))\n\t\tv := []byte(fmt.Sprintf(\"value %d\", x))\n\t\tvv := c.Get(nil, k)\n\t\tif len(vv) > 0 && string(v) != string(vv) {\n\t\t\tt.Fatalf(\"unexpected value for key %q; got %q; want %q\", k, vv, v)\n\t\t}\n\t}\n\n\tvar s Stats\n\tc.UpdateStats(&s)\n\tgetCalls := calls + calls/10\n\tif s.GetCalls != getCalls {\n\t\tt.Fatalf(\"unexpected number of getCalls; got %d; want %d\", s.GetCalls, getCalls)\n\t}\n\tif s.SetCalls != calls {\n\t\tt.Fatalf(\"unexpected number of setCalls; got %d; want %d\", s.SetCalls, calls)\n\t}\n\tif s.Misses == 0 || s.Misses >= calls/10 {\n\t\tt.Fatalf(\"unexpected number of misses; got %d; it should be between 0 and %d\", s.Misses, calls/10)\n\t}\n\tif s.Collisions != 0 {\n\t\tt.Fatalf(\"unexpected number of collisions; got %d; want 0\", s.Collisions)\n\t}\n\tif s.EntriesCount < calls/5 {\n\t\tt.Fatalf(\"unexpected number of items; got %d; cannot be smaller than %d\", s.EntriesCount, calls/5)\n\t}\n\tif s.BytesSize < 1024 {\n\t\tt.Fatalf(\"unexpected BytesSize; got %d; cannot be smaller than %d\", s.BytesSize, 1024)\n\t}\n\tif s.MaxBytesSize < 32*1024*1024 {\n\t\tt.Fatalf(\"unexpected MaxBytesSize; got %d; cannot be smaller than %d\", s.MaxBytesSize, 32*1024*1024)\n\t}\n}\n\nfunc TestCacheDel(t *testing.T) {\n\tc := New(1024)\n\tdefer c.Reset()\n\tfor i := 0; i < 100; i++ {\n\t\tk := []byte(fmt.Sprintf(\"key %d\", i))\n\t\tv := []byte(fmt.Sprintf(\"value %d\", i))\n\t\tc.Set(k, v)\n\t\tvv := c.Get(nil, k)\n\t\tif string(vv) != string(v) {\n\t\t\tt.Fatalf(\"unexpected value for key %q; got %q; want %q\", k, vv, v)\n\t\t}\n\t\tc.Del(k)\n\t\tvv = c.Get(nil, k)\n\t\tif len(vv) > 0 {\n\t\t\tt.Fatalf(\"unexpected non-empty value got for key %q: %q\", k, vv)\n\t\t}\n\t}\n}\n\nfunc TestCacheBigKeyValue(t *testing.T) {\n\tc := New(1024)\n\tdefer c.Reset()\n\n\t// Both key and value exceed 64Kb\n\tk := make([]byte, 90*1024)\n\tv := make([]byte, 100*1024)\n\tc.Set(k, v)\n\tvv := c.Get(nil, k)\n\tif len(vv) > 0 {\n\t\tt.Fatalf(\"unexpected non-empty value got for key %q: %q\", k, vv)\n\t}\n\n\t// len(key) + len(value) > 64Kb\n\tk = make([]byte, 40*1024)\n\tv = make([]byte, 40*1024)\n\tc.Set(k, v)\n\tvv = c.Get(nil, k)\n\tif len(vv) > 0 {\n\t\tt.Fatalf(\"unexpected non-empty value got for key %q: %q\", k, vv)\n\t}\n}\n\nfunc TestCacheSetGetSerial(t *testing.T) {\n\titemsCount := 10000\n\tc := New(30 * itemsCount)\n\tdefer c.Reset()\n\tif err := testCacheGetSet(c, itemsCount); err != nil {\n\t\tt.Fatalf(\"unexpected error: %s\", err)\n\t}\n}\n\nfunc TestCacheGetSetConcurrent(t *testing.T) {\n\titemsCount := 10000\n\tconst gorotines = 10\n\tc := New(30 * itemsCount * gorotines)\n\tdefer c.Reset()\n\n\tch := make(chan error, gorotines)\n\tfor i := 0; i < gorotines; i++ {\n\t\tgo func() {\n\t\t\tch <- testCacheGetSet(c, itemsCount)\n\t\t}()\n\t}\n\tfor i := 0; i < gorotines; i++ {\n\t\tselect {\n\t\tcase err := <-ch:\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"unexpected error: %s\", err)\n\t\t\t}\n\t\tcase <-time.After(5 * time.Second):\n\t\t\tt.Fatalf(\"timeout\")\n\t\t}\n\t}\n}\n\nfunc testCacheGetSet(c *Cache, itemsCount int) error {\n\tfor i := 0; i < itemsCount; i++ {\n\t\tk := []byte(fmt.Sprintf(\"key %d\", i))\n\t\tv := []byte(fmt.Sprintf(\"value %d\", i))\n\t\tc.Set(k, v)\n\t\tvv := c.Get(nil, k)\n\t\tif string(vv) != string(v) {\n\t\t\treturn fmt.Errorf(\"unexpected value for key %q after insertion; got %q; want %q\", k, vv, v)\n\t\t}\n\t}\n\tmisses := 0\n\tfor i := 0; i < itemsCount; i++ {\n\t\tk := []byte(fmt.Sprintf(\"key %d\", i))\n\t\tvExpected := fmt.Sprintf(\"value %d\", i)\n\t\tv := c.Get(nil, k)\n\t\tif string(v) != string(vExpected) {\n\t\t\tif len(v) > 0 {\n\t\t\t\treturn fmt.Errorf(\"unexpected value for key %q after all insertions; got %q; want %q\", k, v, vExpected)\n\t\t\t}\n\t\t\tmisses++\n\t\t}\n\t}\n\tif misses >= itemsCount/100 {\n\t\treturn fmt.Errorf(\"too many cache misses; got %d; want less than %d\", misses, itemsCount/100)\n\t}\n\treturn nil\n}\n\nfunc TestCacheResetUpdateStatsSetConcurrent(t *testing.T) {\n\tc := New(12334)\n\n\tstopCh := make(chan struct{})\n\n\t// run workers for cache reset\n\tvar resettersWG sync.WaitGroup\n\tfor i := 0; i < 10; i++ {\n\t\tresettersWG.Add(1)\n\t\tgo func() {\n\t\t\tdefer resettersWG.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-stopCh:\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t\tc.Reset()\n\t\t\t\t\truntime.Gosched()\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\t// run workers for update cache stats\n\tvar statsWG sync.WaitGroup\n\tfor i := 0; i < 10; i++ {\n\t\tstatsWG.Add(1)\n\t\tgo func() {\n\t\t\tdefer statsWG.Done()\n\t\t\tvar s Stats\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-stopCh:\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t\tc.UpdateStats(&s)\n\t\t\t\t\truntime.Gosched()\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\t// run workers for setting data to cache\n\tvar settersWG sync.WaitGroup\n\tfor i := 0; i < 10; i++ {\n\t\tsettersWG.Add(1)\n\t\tgo func() {\n\t\t\tdefer settersWG.Done()\n\t\t\tfor j := 0; j < 100; j++ {\n\t\t\t\tkey := []byte(fmt.Sprintf(\"key_%d\", j))\n\t\t\t\tvalue := []byte(fmt.Sprintf(\"value_%d\", j))\n\t\t\t\tc.Set(key, value)\n\t\t\t\truntime.Gosched()\n\t\t\t}\n\t\t}()\n\t}\n\n\t// wait for setters\n\tsettersWG.Wait()\n\tclose(stopCh)\n\tstatsWG.Wait()\n\tresettersWG.Wait()\n}\n"
        },
        {
          "name": "fastcache_timing_test.go",
          "type": "blob",
          "size": 7.8115234375,
          "content": "package fastcache\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n\t\"unsafe\"\n\n\t\"github.com/allegro/bigcache\"\n)\n\nfunc BenchmarkBigCacheSet(b *testing.B) {\n\tconst items = 1 << 16\n\tcfg := bigcache.DefaultConfig(time.Minute)\n\tcfg.Verbose = false\n\tc, err := bigcache.NewBigCache(cfg)\n\tif err != nil {\n\t\tb.Fatalf(\"cannot create cache: %s\", err)\n\t}\n\tdefer c.Close()\n\tb.ReportAllocs()\n\tb.SetBytes(items)\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tk := []byte(\"\\x00\\x00\\x00\\x00\")\n\t\tv := []byte(\"xyza\")\n\t\tfor pb.Next() {\n\t\t\tfor i := 0; i < items; i++ {\n\t\t\t\tk[0]++\n\t\t\t\tif k[0] == 0 {\n\t\t\t\t\tk[1]++\n\t\t\t\t}\n\t\t\t\tif err := c.Set(b2s(k), v); err != nil {\n\t\t\t\t\tpanic(fmt.Errorf(\"unexpected error: %s\", err))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc BenchmarkBigCacheGet(b *testing.B) {\n\tconst items = 1 << 16\n\tcfg := bigcache.DefaultConfig(time.Minute)\n\tcfg.Verbose = false\n\tc, err := bigcache.NewBigCache(cfg)\n\tif err != nil {\n\t\tb.Fatalf(\"cannot create cache: %s\", err)\n\t}\n\tdefer c.Close()\n\tk := []byte(\"\\x00\\x00\\x00\\x00\")\n\tv := []byte(\"xyza\")\n\tfor i := 0; i < items; i++ {\n\t\tk[0]++\n\t\tif k[0] == 0 {\n\t\t\tk[1]++\n\t\t}\n\t\tif err := c.Set(b2s(k), v); err != nil {\n\t\t\tb.Fatalf(\"unexpected error: %s\", err)\n\t\t}\n\t}\n\n\tb.ReportAllocs()\n\tb.SetBytes(items)\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tk := []byte(\"\\x00\\x00\\x00\\x00\")\n\t\tfor pb.Next() {\n\t\t\tfor i := 0; i < items; i++ {\n\t\t\t\tk[0]++\n\t\t\t\tif k[0] == 0 {\n\t\t\t\t\tk[1]++\n\t\t\t\t}\n\t\t\t\tvv, err := c.Get(b2s(k))\n\t\t\t\tif err != nil {\n\t\t\t\t\tpanic(fmt.Errorf(\"BUG: unexpected error: %s\", err))\n\t\t\t\t}\n\t\t\t\tif string(vv) != string(v) {\n\t\t\t\t\tpanic(fmt.Errorf(\"BUG: invalid value obtained; got %q; want %q\", vv, v))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc BenchmarkBigCacheSetGet(b *testing.B) {\n\tconst items = 1 << 16\n\tcfg := bigcache.DefaultConfig(time.Minute)\n\tcfg.Verbose = false\n\tc, err := bigcache.NewBigCache(cfg)\n\tif err != nil {\n\t\tb.Fatalf(\"cannot create cache: %s\", err)\n\t}\n\tdefer c.Close()\n\tb.ReportAllocs()\n\tb.SetBytes(2 * items)\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tk := []byte(\"\\x00\\x00\\x00\\x00\")\n\t\tv := []byte(\"xyza\")\n\t\tfor pb.Next() {\n\t\t\tfor i := 0; i < items; i++ {\n\t\t\t\tk[0]++\n\t\t\t\tif k[0] == 0 {\n\t\t\t\t\tk[1]++\n\t\t\t\t}\n\t\t\t\tif err := c.Set(b2s(k), v); err != nil {\n\t\t\t\t\tpanic(fmt.Errorf(\"unexpected error: %s\", err))\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor i := 0; i < items; i++ {\n\t\t\t\tk[0]++\n\t\t\t\tif k[0] == 0 {\n\t\t\t\t\tk[1]++\n\t\t\t\t}\n\t\t\t\tvv, err := c.Get(b2s(k))\n\t\t\t\tif err != nil {\n\t\t\t\t\tpanic(fmt.Errorf(\"BUG: unexpected error: %s\", err))\n\t\t\t\t}\n\t\t\t\tif string(vv) != string(v) {\n\t\t\t\t\tpanic(fmt.Errorf(\"BUG: invalid value obtained; got %q; want %q\", vv, v))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc b2s(b []byte) string {\n\treturn *(*string)(unsafe.Pointer(&b))\n}\n\nfunc BenchmarkCacheSet(b *testing.B) {\n\tconst items = 1 << 16\n\tc := New(12 * items)\n\tdefer c.Reset()\n\tb.ReportAllocs()\n\tb.SetBytes(items)\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tk := []byte(\"\\x00\\x00\\x00\\x00\")\n\t\tv := []byte(\"xyza\")\n\t\tfor pb.Next() {\n\t\t\tfor i := 0; i < items; i++ {\n\t\t\t\tk[0]++\n\t\t\t\tif k[0] == 0 {\n\t\t\t\t\tk[1]++\n\t\t\t\t}\n\t\t\t\tc.Set(k, v)\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc BenchmarkCacheGet(b *testing.B) {\n\tconst items = 1 << 16\n\tc := New(12 * items)\n\tdefer c.Reset()\n\tk := []byte(\"\\x00\\x00\\x00\\x00\")\n\tv := []byte(\"xyza\")\n\tfor i := 0; i < items; i++ {\n\t\tk[0]++\n\t\tif k[0] == 0 {\n\t\t\tk[1]++\n\t\t}\n\t\tc.Set(k, v)\n\t}\n\n\tb.ReportAllocs()\n\tb.SetBytes(items)\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tvar buf []byte\n\t\tk := []byte(\"\\x00\\x00\\x00\\x00\")\n\t\tfor pb.Next() {\n\t\t\tfor i := 0; i < items; i++ {\n\t\t\t\tk[0]++\n\t\t\t\tif k[0] == 0 {\n\t\t\t\t\tk[1]++\n\t\t\t\t}\n\t\t\t\tbuf = c.Get(buf[:0], k)\n\t\t\t\tif string(buf) != string(v) {\n\t\t\t\t\tpanic(fmt.Errorf(\"BUG: invalid value obtained; got %q; want %q\", buf, v))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc BenchmarkCacheHas(b *testing.B) {\n\tconst items = 1 << 16\n\tc := New(12 * items)\n\tdefer c.Reset()\n\tk := []byte(\"\\x00\\x00\\x00\\x00\")\n\tfor i := 0; i < items; i++ {\n\t\tk[0]++\n\t\tif k[0] == 0 {\n\t\t\tk[1]++\n\t\t}\n\t\tc.Set(k, nil)\n\t}\n\n\tb.ReportAllocs()\n\tb.SetBytes(items)\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tk := []byte(\"\\x00\\x00\\x00\\x00\")\n\t\tfor pb.Next() {\n\t\t\tfor i := 0; i < items; i++ {\n\t\t\t\tk[0]++\n\t\t\t\tif k[0] == 0 {\n\t\t\t\t\tk[1]++\n\t\t\t\t}\n\t\t\t\tif !c.Has(k) {\n\t\t\t\t\tpanic(fmt.Errorf(\"BUG: missing value for key %q\", k))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc BenchmarkCacheSetGet(b *testing.B) {\n\tconst items = 1 << 16\n\tc := New(12 * items)\n\tdefer c.Reset()\n\tb.ReportAllocs()\n\tb.SetBytes(2 * items)\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tk := []byte(\"\\x00\\x00\\x00\\x00\")\n\t\tv := []byte(\"xyza\")\n\t\tvar buf []byte\n\t\tfor pb.Next() {\n\t\t\tfor i := 0; i < items; i++ {\n\t\t\t\tk[0]++\n\t\t\t\tif k[0] == 0 {\n\t\t\t\t\tk[1]++\n\t\t\t\t}\n\t\t\t\tc.Set(k, v)\n\t\t\t}\n\t\t\tfor i := 0; i < items; i++ {\n\t\t\t\tk[0]++\n\t\t\t\tif k[0] == 0 {\n\t\t\t\t\tk[1]++\n\t\t\t\t}\n\t\t\t\tbuf = c.Get(buf[:0], k)\n\t\t\t\tif string(buf) != string(v) {\n\t\t\t\t\tpanic(fmt.Errorf(\"BUG: invalid value obtained; got %q; want %q\", buf, v))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc BenchmarkStdMapSet(b *testing.B) {\n\tconst items = 1 << 16\n\tm := make(map[string][]byte)\n\tvar mu sync.Mutex\n\tb.ReportAllocs()\n\tb.SetBytes(items)\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tk := []byte(\"\\x00\\x00\\x00\\x00\")\n\t\tv := []byte(\"xyza\")\n\t\tfor pb.Next() {\n\t\t\tfor i := 0; i < items; i++ {\n\t\t\t\tk[0]++\n\t\t\t\tif k[0] == 0 {\n\t\t\t\t\tk[1]++\n\t\t\t\t}\n\t\t\t\tmu.Lock()\n\t\t\t\tm[string(k)] = v\n\t\t\t\tmu.Unlock()\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc BenchmarkStdMapGet(b *testing.B) {\n\tconst items = 1 << 16\n\tm := make(map[string][]byte)\n\tk := []byte(\"\\x00\\x00\\x00\\x00\")\n\tv := []byte(\"xyza\")\n\tfor i := 0; i < items; i++ {\n\t\tk[0]++\n\t\tif k[0] == 0 {\n\t\t\tk[1]++\n\t\t}\n\t\tm[string(k)] = v\n\t}\n\n\tvar mu sync.RWMutex\n\tb.ReportAllocs()\n\tb.SetBytes(items)\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tk := []byte(\"\\x00\\x00\\x00\\x00\")\n\t\tfor pb.Next() {\n\t\t\tfor i := 0; i < items; i++ {\n\t\t\t\tk[0]++\n\t\t\t\tif k[0] == 0 {\n\t\t\t\t\tk[1]++\n\t\t\t\t}\n\t\t\t\tmu.RLock()\n\t\t\t\tvv := m[string(k)]\n\t\t\t\tmu.RUnlock()\n\t\t\t\tif string(vv) != string(v) {\n\t\t\t\t\tpanic(fmt.Errorf(\"BUG: unexpected value; got %q; want %q\", vv, v))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc BenchmarkStdMapSetGet(b *testing.B) {\n\tconst items = 1 << 16\n\tm := make(map[string][]byte)\n\tvar mu sync.RWMutex\n\tb.ReportAllocs()\n\tb.SetBytes(2 * items)\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tk := []byte(\"\\x00\\x00\\x00\\x00\")\n\t\tv := []byte(\"xyza\")\n\t\tfor pb.Next() {\n\t\t\tfor i := 0; i < items; i++ {\n\t\t\t\tk[0]++\n\t\t\t\tif k[0] == 0 {\n\t\t\t\t\tk[1]++\n\t\t\t\t}\n\t\t\t\tmu.Lock()\n\t\t\t\tm[string(k)] = v\n\t\t\t\tmu.Unlock()\n\t\t\t}\n\t\t\tfor i := 0; i < items; i++ {\n\t\t\t\tk[0]++\n\t\t\t\tif k[0] == 0 {\n\t\t\t\t\tk[1]++\n\t\t\t\t}\n\t\t\t\tmu.RLock()\n\t\t\t\tvv := m[string(k)]\n\t\t\t\tmu.RUnlock()\n\t\t\t\tif string(vv) != string(v) {\n\t\t\t\t\tpanic(fmt.Errorf(\"BUG: unexpected value; got %q; want %q\", vv, v))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc BenchmarkSyncMapSet(b *testing.B) {\n\tconst items = 1 << 16\n\tm := sync.Map{}\n\tb.ReportAllocs()\n\tb.SetBytes(items)\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tk := []byte(\"\\x00\\x00\\x00\\x00\")\n\t\tv := \"xyza\"\n\t\tfor pb.Next() {\n\t\t\tfor i := 0; i < items; i++ {\n\t\t\t\tk[0]++\n\t\t\t\tif k[0] == 0 {\n\t\t\t\t\tk[1]++\n\t\t\t\t}\n\t\t\t\tm.Store(string(k), v)\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc BenchmarkSyncMapGet(b *testing.B) {\n\tconst items = 1 << 16\n\tm := sync.Map{}\n\tk := []byte(\"\\x00\\x00\\x00\\x00\")\n\tv := \"xyza\"\n\tfor i := 0; i < items; i++ {\n\t\tk[0]++\n\t\tif k[0] == 0 {\n\t\t\tk[1]++\n\t\t}\n\t\tm.Store(string(k), v)\n\t}\n\n\tb.ReportAllocs()\n\tb.SetBytes(items)\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tk := []byte(\"\\x00\\x00\\x00\\x00\")\n\t\tfor pb.Next() {\n\t\t\tfor i := 0; i < items; i++ {\n\t\t\t\tk[0]++\n\t\t\t\tif k[0] == 0 {\n\t\t\t\t\tk[1]++\n\t\t\t\t}\n\t\t\t\tvv, ok := m.Load(string(k))\n\t\t\t\tif !ok || vv.(string) != string(v) {\n\t\t\t\t\tpanic(fmt.Errorf(\"BUG: unexpected value; got %q; want %q\", vv, v))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc BenchmarkSyncMapSetGet(b *testing.B) {\n\tconst items = 1 << 16\n\tm := sync.Map{}\n\tb.ReportAllocs()\n\tb.SetBytes(2 * items)\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tk := []byte(\"\\x00\\x00\\x00\\x00\")\n\t\tv := \"xyza\"\n\t\tfor pb.Next() {\n\t\t\tfor i := 0; i < items; i++ {\n\t\t\t\tk[0]++\n\t\t\t\tif k[0] == 0 {\n\t\t\t\t\tk[1]++\n\t\t\t\t}\n\t\t\t\tm.Store(string(k), v)\n\t\t\t}\n\t\t\tfor i := 0; i < items; i++ {\n\t\t\t\tk[0]++\n\t\t\t\tif k[0] == 0 {\n\t\t\t\t\tk[1]++\n\t\t\t\t}\n\t\t\t\tvv, ok := m.Load(string(k))\n\t\t\t\tif !ok || vv.(string) != string(v) {\n\t\t\t\t\tpanic(fmt.Errorf(\"BUG: unexpected value; got %q; want %q\", vv, v))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n}\n"
        },
        {
          "name": "file.go",
          "type": "blob",
          "size": 11.1796875,
          "content": "package fastcache\n\nimport (\n\t\"encoding/binary\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"runtime\"\n\n\t\"github.com/golang/snappy\"\n)\n\n// SaveToFile atomically saves cache data to the given filePath using a single\n// CPU core.\n//\n// SaveToFile may be called concurrently with other operations on the cache.\n//\n// The saved data may be loaded with LoadFromFile*.\n//\n// See also SaveToFileConcurrent for faster saving to file.\nfunc (c *Cache) SaveToFile(filePath string) error {\n\treturn c.SaveToFileConcurrent(filePath, 1)\n}\n\n// SaveToFileConcurrent saves cache data to the given filePath using concurrency\n// CPU cores.\n//\n// SaveToFileConcurrent may be called concurrently with other operations\n// on the cache.\n//\n// The saved data may be loaded with LoadFromFile*.\n//\n// See also SaveToFile.\nfunc (c *Cache) SaveToFileConcurrent(filePath string, concurrency int) error {\n\t// Create dir if it doesn't exist.\n\tdir := filepath.Dir(filePath)\n\tif _, err := os.Stat(dir); err != nil {\n\t\tif !os.IsNotExist(err) {\n\t\t\treturn fmt.Errorf(\"cannot stat %q: %s\", dir, err)\n\t\t}\n\t\tif err := os.MkdirAll(dir, 0755); err != nil {\n\t\t\treturn fmt.Errorf(\"cannot create dir %q: %s\", dir, err)\n\t\t}\n\t}\n\n\t// Save cache data into a temporary directory.\n\ttmpDir, err := ioutil.TempDir(dir, \"fastcache.tmp.\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"cannot create temporary dir inside %q: %s\", dir, err)\n\t}\n\tdefer func() {\n\t\tif tmpDir != \"\" {\n\t\t\t_ = os.RemoveAll(tmpDir)\n\t\t}\n\t}()\n\tgomaxprocs := runtime.GOMAXPROCS(-1)\n\tif concurrency <= 0 || concurrency > gomaxprocs {\n\t\tconcurrency = gomaxprocs\n\t}\n\tif err := c.save(tmpDir, concurrency); err != nil {\n\t\treturn fmt.Errorf(\"cannot save cache data to temporary dir %q: %s\", tmpDir, err)\n\t}\n\n\t// Remove old filePath contents, since os.Rename may return\n\t// error if filePath dir exists.\n\tif err := os.RemoveAll(filePath); err != nil {\n\t\treturn fmt.Errorf(\"cannot remove old contents at %q: %s\", filePath, err)\n\t}\n\tif err := os.Rename(tmpDir, filePath); err != nil {\n\t\treturn fmt.Errorf(\"cannot move temporary dir %q to %q: %s\", tmpDir, filePath, err)\n\t}\n\ttmpDir = \"\"\n\treturn nil\n}\n\n// LoadFromFile loads cache data from the given filePath.\n//\n// See SaveToFile* for saving cache data to file.\nfunc LoadFromFile(filePath string) (*Cache, error) {\n\treturn load(filePath, 0)\n}\n\n// LoadFromFileOrNew tries loading cache data from the given filePath.\n//\n// The function falls back to creating new cache with the given maxBytes\n// capacity if error occurs during loading the cache from file.\nfunc LoadFromFileOrNew(filePath string, maxBytes int) *Cache {\n\tc, err := load(filePath, maxBytes)\n\tif err == nil {\n\t\treturn c\n\t}\n\treturn New(maxBytes)\n}\n\nfunc (c *Cache) save(dir string, workersCount int) error {\n\tif err := saveMetadata(c, dir); err != nil {\n\t\treturn err\n\t}\n\n\t// Save buckets by workersCount concurrent workers.\n\tworkCh := make(chan int, workersCount)\n\tresults := make(chan error)\n\tfor i := 0; i < workersCount; i++ {\n\t\tgo func(workerNum int) {\n\t\t\tresults <- saveBuckets(c.buckets[:], workCh, dir, workerNum)\n\t\t}(i)\n\t}\n\t// Feed workers with work\n\tfor i := range c.buckets[:] {\n\t\tworkCh <- i\n\t}\n\tclose(workCh)\n\n\t// Read results.\n\tvar err error\n\tfor i := 0; i < workersCount; i++ {\n\t\tresult := <-results\n\t\tif result != nil && err == nil {\n\t\t\terr = result\n\t\t}\n\t}\n\treturn err\n}\n\nfunc load(filePath string, maxBytes int) (*Cache, error) {\n\tmaxBucketChunks, err := loadMetadata(filePath)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif maxBytes > 0 {\n\t\tmaxBucketBytes := uint64((maxBytes + bucketsCount - 1) / bucketsCount)\n\t\texpectedBucketChunks := (maxBucketBytes + chunkSize - 1) / chunkSize\n\t\tif maxBucketChunks != expectedBucketChunks {\n\t\t\treturn nil, fmt.Errorf(\"cache file %s contains maxBytes=%d; want %d\", filePath, maxBytes, expectedBucketChunks*chunkSize*bucketsCount)\n\t\t}\n\t}\n\n\t// Read bucket files from filePath dir.\n\td, err := os.Open(filePath)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot open %q: %s\", filePath, err)\n\t}\n\tdefer func() {\n\t\t_ = d.Close()\n\t}()\n\tfis, err := d.Readdir(-1)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot read files from %q: %s\", filePath, err)\n\t}\n\tresults := make(chan error)\n\tworkersCount := 0\n\tvar c Cache\n\tfor _, fi := range fis {\n\t\tfn := fi.Name()\n\t\tif fi.IsDir() || !dataFileRegexp.MatchString(fn) {\n\t\t\tcontinue\n\t\t}\n\t\tworkersCount++\n\t\tgo func(dataPath string) {\n\t\t\tresults <- loadBuckets(c.buckets[:], dataPath, maxBucketChunks)\n\t\t}(filePath + \"/\" + fn)\n\t}\n\terr = nil\n\tfor i := 0; i < workersCount; i++ {\n\t\tresult := <-results\n\t\tif result != nil && err == nil {\n\t\t\terr = result\n\t\t}\n\t}\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// Initialize buckets, which could be missing due to incomplete or corrupted files in the cache.\n\t// It is better initializing such buckets instead of returning error, since the rest of buckets\n\t// contain valid data.\n\tfor i := range c.buckets[:] {\n\t\tb := &c.buckets[i]\n\t\tif len(b.chunks) == 0 {\n\t\t\tb.chunks = make([][]byte, maxBucketChunks)\n\t\t\tb.m = make(map[uint64]uint64)\n\t\t}\n\t}\n\treturn &c, nil\n}\n\nfunc saveMetadata(c *Cache, dir string) error {\n\tmetadataPath := dir + \"/metadata.bin\"\n\tmetadataFile, err := os.Create(metadataPath)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"cannot create %q: %s\", metadataPath, err)\n\t}\n\tdefer func() {\n\t\t_ = metadataFile.Close()\n\t}()\n\tmaxBucketChunks := uint64(cap(c.buckets[0].chunks))\n\tif err := writeUint64(metadataFile, maxBucketChunks); err != nil {\n\t\treturn fmt.Errorf(\"cannot write maxBucketChunks=%d to %q: %s\", maxBucketChunks, metadataPath, err)\n\t}\n\treturn nil\n}\n\nfunc loadMetadata(dir string) (uint64, error) {\n\tmetadataPath := dir + \"/metadata.bin\"\n\tmetadataFile, err := os.Open(metadataPath)\n\tif err != nil {\n\t\treturn 0, fmt.Errorf(\"cannot open %q: %s\", metadataPath, err)\n\t}\n\tdefer func() {\n\t\t_ = metadataFile.Close()\n\t}()\n\tmaxBucketChunks, err := readUint64(metadataFile)\n\tif err != nil {\n\t\treturn 0, fmt.Errorf(\"cannot read maxBucketChunks from %q: %s\", metadataPath, err)\n\t}\n\tif maxBucketChunks == 0 {\n\t\treturn 0, fmt.Errorf(\"invalid maxBucketChunks=0 read from %q\", metadataPath)\n\t}\n\treturn maxBucketChunks, nil\n}\n\nvar dataFileRegexp = regexp.MustCompile(`^data\\.\\d+\\.bin$`)\n\nfunc saveBuckets(buckets []bucket, workCh <-chan int, dir string, workerNum int) error {\n\tdataPath := fmt.Sprintf(\"%s/data.%d.bin\", dir, workerNum)\n\tdataFile, err := os.Create(dataPath)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"cannot create %q: %s\", dataPath, err)\n\t}\n\tdefer func() {\n\t\t_ = dataFile.Close()\n\t}()\n\tzw := snappy.NewBufferedWriter(dataFile)\n\tfor bucketNum := range workCh {\n\t\tif err := writeUint64(zw, uint64(bucketNum)); err != nil {\n\t\t\treturn fmt.Errorf(\"cannot write bucketNum=%d to %q: %s\", bucketNum, dataPath, err)\n\t\t}\n\t\tif err := buckets[bucketNum].Save(zw); err != nil {\n\t\t\treturn fmt.Errorf(\"cannot save bucket[%d] to %q: %s\", bucketNum, dataPath, err)\n\t\t}\n\t}\n\tif err := zw.Close(); err != nil {\n\t\treturn fmt.Errorf(\"cannot close snappy.Writer for %q: %s\", dataPath, err)\n\t}\n\treturn nil\n}\n\nfunc loadBuckets(buckets []bucket, dataPath string, maxChunks uint64) error {\n\tdataFile, err := os.Open(dataPath)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"cannot open %q: %s\", dataPath, err)\n\t}\n\tdefer func() {\n\t\t_ = dataFile.Close()\n\t}()\n\tzr := snappy.NewReader(dataFile)\n\tfor {\n\t\tbucketNum, err := readUint64(zr)\n\t\tif err == io.EOF {\n\t\t\t// Reached the end of file.\n\t\t\treturn nil\n\t\t}\n\t\tif bucketNum >= uint64(len(buckets)) {\n\t\t\treturn fmt.Errorf(\"unexpected bucketNum read from %q: %d; must be smaller than %d\", dataPath, bucketNum, len(buckets))\n\t\t}\n\t\tif err := buckets[bucketNum].Load(zr, maxChunks); err != nil {\n\t\t\treturn fmt.Errorf(\"cannot load bucket[%d] from %q: %s\", bucketNum, dataPath, err)\n\t\t}\n\t}\n}\n\nfunc (b *bucket) Save(w io.Writer) error {\n\tb.mu.Lock()\n\tb.cleanLocked()\n\tb.mu.Unlock()\n\n\tb.mu.RLock()\n\tdefer b.mu.RUnlock()\n\n\t// Store b.idx, b.gen and b.m to w.\n\n\tbIdx := b.idx\n\tbGen := b.gen\n\tchunksLen := 0\n\tfor _, chunk := range b.chunks {\n\t\tif chunk == nil {\n\t\t\tbreak\n\t\t}\n\t\tchunksLen++\n\t}\n\tkvs := make([]byte, 0, 2*8*len(b.m))\n\tvar u64Buf [8]byte\n\tfor k, v := range b.m {\n\t\tbinary.LittleEndian.PutUint64(u64Buf[:], k)\n\t\tkvs = append(kvs, u64Buf[:]...)\n\t\tbinary.LittleEndian.PutUint64(u64Buf[:], v)\n\t\tkvs = append(kvs, u64Buf[:]...)\n\t}\n\n\tif err := writeUint64(w, bIdx); err != nil {\n\t\treturn fmt.Errorf(\"cannot write b.idx: %s\", err)\n\t}\n\tif err := writeUint64(w, bGen); err != nil {\n\t\treturn fmt.Errorf(\"cannot write b.gen: %s\", err)\n\t}\n\tif err := writeUint64(w, uint64(len(kvs))/2/8); err != nil {\n\t\treturn fmt.Errorf(\"cannot write len(b.m): %s\", err)\n\t}\n\tif _, err := w.Write(kvs); err != nil {\n\t\treturn fmt.Errorf(\"cannot write b.m: %s\", err)\n\t}\n\n\t// Store b.chunks to w.\n\tif err := writeUint64(w, uint64(chunksLen)); err != nil {\n\t\treturn fmt.Errorf(\"cannot write len(b.chunks): %s\", err)\n\t}\n\tfor chunkIdx := 0; chunkIdx < chunksLen; chunkIdx++ {\n\t\tchunk := b.chunks[chunkIdx][:chunkSize]\n\t\tif _, err := w.Write(chunk); err != nil {\n\t\t\treturn fmt.Errorf(\"cannot write b.chunks[%d]: %s\", chunkIdx, err)\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (b *bucket) Load(r io.Reader, maxChunks uint64) error {\n\tif maxChunks == 0 {\n\t\treturn fmt.Errorf(\"the number of chunks per bucket cannot be zero\")\n\t}\n\tbIdx, err := readUint64(r)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"cannot read b.idx: %s\", err)\n\t}\n\tbGen, err := readUint64(r)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"cannot read b.gen: %s\", err)\n\t}\n\tkvsLen, err := readUint64(r)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"cannot read len(b.m): %s\", err)\n\t}\n\tkvsLen *= 2 * 8\n\tkvs := make([]byte, kvsLen)\n\tif _, err := io.ReadFull(r, kvs); err != nil {\n\t\treturn fmt.Errorf(\"cannot read b.m: %s\", err)\n\t}\n\tm := make(map[uint64]uint64, kvsLen/2/8)\n\tfor len(kvs) > 0 {\n\t\tk := binary.LittleEndian.Uint64(kvs)\n\t\tkvs = kvs[8:]\n\t\tv := binary.LittleEndian.Uint64(kvs)\n\t\tkvs = kvs[8:]\n\t\tm[k] = v\n\t}\n\n\tmaxBytes := maxChunks * chunkSize\n\tif maxBytes >= maxBucketSize {\n\t\treturn fmt.Errorf(\"too big maxBytes=%d; should be smaller than %d\", maxBytes, maxBucketSize)\n\t}\n\tchunks := make([][]byte, maxChunks)\n\tchunksLen, err := readUint64(r)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"cannot read len(b.chunks): %s\", err)\n\t}\n\tif chunksLen > uint64(maxChunks) {\n\t\treturn fmt.Errorf(\"chunksLen=%d cannot exceed maxChunks=%d\", chunksLen, maxChunks)\n\t}\n\tcurrChunkIdx := bIdx / chunkSize\n\tif currChunkIdx > 0 && currChunkIdx >= chunksLen {\n\t\treturn fmt.Errorf(\"too big bIdx=%d; should be smaller than %d\", bIdx, chunksLen*chunkSize)\n\t}\n\tfor chunkIdx := uint64(0); chunkIdx < chunksLen; chunkIdx++ {\n\t\tchunk := getChunk()\n\t\tchunks[chunkIdx] = chunk\n\t\tif _, err := io.ReadFull(r, chunk); err != nil {\n\t\t\t// Free up allocated chunks before returning the error.\n\t\t\tfor _, chunk := range chunks {\n\t\t\t\tif chunk != nil {\n\t\t\t\t\tputChunk(chunk)\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn fmt.Errorf(\"cannot read b.chunks[%d]: %s\", chunkIdx, err)\n\t\t}\n\t}\n\t// Adjust len for the chunk pointed by currChunkIdx.\n\tif chunksLen > 0 {\n\t\tchunkLen := bIdx % chunkSize\n\t\tchunks[currChunkIdx] = chunks[currChunkIdx][:chunkLen]\n\t}\n\n\tb.mu.Lock()\n\tfor _, chunk := range b.chunks {\n\t\tputChunk(chunk)\n\t}\n\tb.chunks = chunks\n\tb.m = m\n\tb.idx = bIdx\n\tb.gen = bGen\n\tb.mu.Unlock()\n\n\treturn nil\n}\n\nfunc writeUint64(w io.Writer, u uint64) error {\n\tvar u64Buf [8]byte\n\tbinary.LittleEndian.PutUint64(u64Buf[:], u)\n\t_, err := w.Write(u64Buf[:])\n\treturn err\n}\n\nfunc readUint64(r io.Reader) (uint64, error) {\n\tvar u64Buf [8]byte\n\tif _, err := io.ReadFull(r, u64Buf[:]); err != nil {\n\t\treturn 0, err\n\t}\n\tu := binary.LittleEndian.Uint64(u64Buf[:])\n\treturn u, nil\n}\n"
        },
        {
          "name": "file_test.go",
          "type": "blob",
          "size": 6.2890625,
          "content": "package fastcache\n\nimport (\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"sync\"\n\t\"testing\"\n)\n\nfunc TestSaveLoadSmall(t *testing.T) {\n\ttmpDir, err := ioutil.TempDir(\"\", \"test\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tfilePath := filepath.Join(tmpDir, \"TestSaveLoadSmall.fastcache\")\n\tdefer os.RemoveAll(filePath)\n\n\tc := New(1)\n\tdefer c.Reset()\n\n\tkey := []byte(\"foobar\")\n\tvalue := []byte(\"abcdef\")\n\tc.Set(key, value)\n\tif err := c.SaveToFile(filePath); err != nil {\n\t\tt.Fatalf(\"SaveToFile error: %s\", err)\n\t}\n\n\tc1, err := LoadFromFile(filePath)\n\tif err != nil {\n\t\tt.Fatalf(\"LoadFromFile error: %s\", err)\n\t}\n\tvv := c1.Get(nil, key)\n\tif string(vv) != string(value) {\n\t\tt.Fatalf(\"unexpected value obtained from cache; got %q; want %q\", vv, value)\n\t}\n\n\t// Verify that key can be overwritten.\n\tnewValue := []byte(\"234fdfd\")\n\tc1.Set(key, newValue)\n\tvv = c1.Get(nil, key)\n\tif string(vv) != string(newValue) {\n\t\tt.Fatalf(\"unexpected new value obtained from cache; got %q; want %q\", vv, newValue)\n\t}\n}\n\nfunc TestSaveLoadFile(t *testing.T) {\n\tfor _, concurrency := range []int{0, 1, 2, 4, 10} {\n\t\tt.Run(fmt.Sprintf(\"concurrency_%d\", concurrency), func(t *testing.T) {\n\t\t\ttestSaveLoadFile(t, concurrency)\n\t\t})\n\t}\n}\n\nfunc testSaveLoadFile(t *testing.T, concurrency int) {\n\tvar s Stats\n\ttmpDir, err := ioutil.TempDir(\"\", \"test\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tfilePath := filepath.Join(tmpDir, fmt.Sprintf(\"TestSaveLoadFile.%d.fastcache\", concurrency))\n\tdefer os.RemoveAll(filePath)\n\n\tconst itemsCount = 10000\n\tconst maxBytes = bucketsCount * chunkSize * 2\n\tc := New(maxBytes)\n\tfor i := 0; i < itemsCount; i++ {\n\t\tk := []byte(fmt.Sprintf(\"key %d\", i))\n\t\tv := []byte(fmt.Sprintf(\"value %d\", i))\n\t\tc.Set(k, v)\n\t\tvv := c.Get(nil, k)\n\t\tif string(v) != string(vv) {\n\t\t\tt.Fatalf(\"unexpected cache value for k=%q; got %q; want %q; bucket[0]=%#v\", k, vv, v, &c.buckets[0])\n\t\t}\n\t}\n\tif concurrency == 1 {\n\t\tif err := c.SaveToFile(filePath); err != nil {\n\t\t\tt.Fatalf(\"SaveToFile error: %s\", err)\n\t\t}\n\t} else {\n\t\tif err := c.SaveToFileConcurrent(filePath, concurrency); err != nil {\n\t\t\tt.Fatalf(\"SaveToFileConcurrent(%d) error: %s\", concurrency, err)\n\t\t}\n\t}\n\ts.Reset()\n\tc.UpdateStats(&s)\n\tif s.EntriesCount != itemsCount {\n\t\tt.Fatalf(\"unexpected entriesCount; got %d; want %d\", s.EntriesCount, itemsCount)\n\t}\n\tc.Reset()\n\n\t// Verify LoadFromFile\n\tc, err = LoadFromFile(filePath)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %s\", err)\n\t}\n\ts.Reset()\n\tc.UpdateStats(&s)\n\tif s.EntriesCount != itemsCount {\n\t\tt.Fatalf(\"unexpected entriesCount; got %d; want %d\", s.EntriesCount, itemsCount)\n\t}\n\tfor i := 0; i < itemsCount; i++ {\n\t\tk := []byte(fmt.Sprintf(\"key %d\", i))\n\t\tv := []byte(fmt.Sprintf(\"value %d\", i))\n\t\tvv := c.Get(nil, k)\n\t\tif string(v) != string(vv) {\n\t\t\tt.Fatalf(\"unexpected cache value for k=%q; got %q; want %q; bucket[0]=%#v\", k, vv, v, &c.buckets[0])\n\t\t}\n\t}\n\tc.Reset()\n\n\t// Verify LoadFromFileOrNew\n\tc = LoadFromFileOrNew(filePath, maxBytes)\n\ts.Reset()\n\tc.UpdateStats(&s)\n\tif s.EntriesCount != itemsCount {\n\t\tt.Fatalf(\"unexpected entriesCount; got %d; want %d\", s.EntriesCount, itemsCount)\n\t}\n\tfor i := 0; i < itemsCount; i++ {\n\t\tk := []byte(fmt.Sprintf(\"key %d\", i))\n\t\tv := []byte(fmt.Sprintf(\"value %d\", i))\n\t\tvv := c.Get(nil, k)\n\t\tif string(v) != string(vv) {\n\t\t\tt.Fatalf(\"unexpected cache value for k=%q; got %q; want %q; bucket[0]=%#v\", k, vv, v, &c.buckets[0])\n\t\t}\n\t}\n\tc.Reset()\n\n\t// Overwrite existing keys\n\tfor i := 0; i < itemsCount; i++ {\n\t\tk := []byte(fmt.Sprintf(\"key %d\", i))\n\t\tv := []byte(fmt.Sprintf(\"value %d\", i))\n\t\tc.Set(k, v)\n\t\tvv := c.Get(nil, k)\n\t\tif string(v) != string(vv) {\n\t\t\tt.Fatalf(\"unexpected cache value for k=%q; got %q; want %q; bucket[0]=%#v\", k, vv, v, &c.buckets[0])\n\t\t}\n\t}\n\n\t// Add new keys\n\tfor i := 0; i < itemsCount; i++ {\n\t\tk := []byte(fmt.Sprintf(\"new key %d\", i))\n\t\tv := []byte(fmt.Sprintf(\"new value %d\", i))\n\t\tc.Set(k, v)\n\t\tvv := c.Get(nil, k)\n\t\tif string(v) != string(vv) {\n\t\t\tt.Fatalf(\"unexpected cache value for k=%q; got %q; want %q; bucket[0]=%#v\", k, vv, v, &c.buckets[0])\n\t\t}\n\t}\n\n\t// Verify all the keys exist\n\tfor i := 0; i < itemsCount; i++ {\n\t\tk := []byte(fmt.Sprintf(\"key %d\", i))\n\t\tv := []byte(fmt.Sprintf(\"value %d\", i))\n\t\tvv := c.Get(nil, k)\n\t\tif string(v) != string(vv) {\n\t\t\tt.Fatalf(\"unexpected cache value for k=%q; got %q; want %q; bucket[0]=%#v\", k, vv, v, &c.buckets[0])\n\t\t}\n\t\tk = []byte(fmt.Sprintf(\"new key %d\", i))\n\t\tv = []byte(fmt.Sprintf(\"new value %d\", i))\n\t\tvv = c.Get(nil, k)\n\t\tif string(v) != string(vv) {\n\t\t\tt.Fatalf(\"unexpected cache value for k=%q; got %q; want %q; bucket[0]=%#v\", k, vv, v, &c.buckets[0])\n\t\t}\n\t}\n\n\t// Verify incorrect maxBytes passed to LoadFromFileOrNew\n\tc = LoadFromFileOrNew(filePath, maxBytes*10)\n\ts.Reset()\n\tc.UpdateStats(&s)\n\tif s.EntriesCount != 0 {\n\t\tt.Fatalf(\"unexpected non-zero entriesCount; got %d\", s.EntriesCount)\n\t}\n\tc.Reset()\n}\n\nfunc TestSaveLoadConcurrent(t *testing.T) {\n\tc := New(1024)\n\tdefer c.Reset()\n\tc.Set([]byte(\"foo\"), []byte(\"bar\"))\n\n\tstopCh := make(chan struct{})\n\n\t// Start concurrent workers that run Get and Set on c.\n\tvar wgWorkers sync.WaitGroup\n\tfor i := 0; i < 5; i++ {\n\t\twgWorkers.Add(1)\n\t\tgo func() {\n\t\t\tdefer wgWorkers.Done()\n\t\t\tvar buf []byte\n\t\t\tj := 0\n\t\t\tfor {\n\t\t\t\tk := []byte(fmt.Sprintf(\"key %d\", j))\n\t\t\t\tv := []byte(fmt.Sprintf(\"value %d\", j))\n\t\t\t\tc.Set(k, v)\n\t\t\t\tbuf = c.Get(buf[:0], k)\n\t\t\t\tif string(buf) != string(v) {\n\t\t\t\t\tpanic(fmt.Errorf(\"unexpected value for key %q; got %q; want %q\", k, buf, v))\n\t\t\t\t}\n\t\t\t\tj++\n\t\t\t\tselect {\n\t\t\t\tcase <-stopCh:\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\t// Start concurrent SaveToFile and LoadFromFile calls.\n\ttmpDir, err := ioutil.TempDir(\"\", \"test\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer os.RemoveAll(tmpDir)\n\n\tvar wgSavers sync.WaitGroup\n\tfor i := 0; i < 4; i++ {\n\t\twgSavers.Add(1)\n\t\tfilePath := filepath.Join(tmpDir, fmt.Sprintf(\"TestSaveLoadFile.%d.fastcache\", i))\n\t\tgo func() {\n\t\t\tdefer wgSavers.Done()\n\t\t\tdefer os.RemoveAll(filePath)\n\t\t\tfor j := 0; j < 3; j++ {\n\t\t\t\tif err := c.SaveToFileConcurrent(filePath, 3); err != nil {\n\t\t\t\t\tpanic(fmt.Errorf(\"cannot save cache to %q: %s\", filePath, err))\n\t\t\t\t}\n\t\t\t\tcc, err := LoadFromFile(filePath)\n\t\t\t\tif err != nil {\n\t\t\t\t\tpanic(fmt.Errorf(\"cannot load cache from %q: %s\", filePath, err))\n\t\t\t\t}\n\t\t\t\tvar s Stats\n\t\t\t\tcc.UpdateStats(&s)\n\t\t\t\tif s.EntriesCount == 0 {\n\t\t\t\t\tpanic(fmt.Errorf(\"unexpected empty cache loaded from %q\", filePath))\n\t\t\t\t}\n\t\t\t\tcc.Reset()\n\t\t\t}\n\t\t}()\n\t}\n\n\twgSavers.Wait()\n\n\tclose(stopCh)\n\twgWorkers.Wait()\n}\n"
        },
        {
          "name": "file_timing_test.go",
          "type": "blob",
          "size": 1.9033203125,
          "content": "package fastcache\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"sync\"\n\t\"testing\"\n)\n\nfunc BenchmarkSaveToFile(b *testing.B) {\n\tfor _, concurrency := range []int{1, 2, 4, 8, 16} {\n\t\tb.Run(fmt.Sprintf(\"concurrency_%d\", concurrency), func(b *testing.B) {\n\t\t\tbenchmarkSaveToFile(b, concurrency)\n\t\t})\n\t}\n}\n\nfunc benchmarkSaveToFile(b *testing.B, concurrency int) {\n\tfilePath := fmt.Sprintf(\"BencharkSaveToFile.%d.fastcache\", concurrency)\n\tdefer os.RemoveAll(filePath)\n\tc := newBenchCache()\n\n\tb.ReportAllocs()\n\tb.ResetTimer()\n\tb.SetBytes(benchCacheSize)\n\tfor i := 0; i < b.N; i++ {\n\t\tif err := c.SaveToFileConcurrent(filePath, concurrency); err != nil {\n\t\t\tb.Fatalf(\"unexpected error when saving to file: %s\", err)\n\t\t}\n\t}\n}\n\nfunc BenchmarkLoadFromFile(b *testing.B) {\n\tfor _, concurrency := range []int{1, 2, 4, 8, 16} {\n\t\tb.Run(fmt.Sprintf(\"concurrency_%d\", concurrency), func(b *testing.B) {\n\t\t\tbenchmarkLoadFromFile(b, concurrency)\n\t\t})\n\t}\n}\n\nfunc benchmarkLoadFromFile(b *testing.B, concurrency int) {\n\tfilePath := fmt.Sprintf(\"BenchmarkLoadFromFile.%d.fastcache\", concurrency)\n\tdefer os.RemoveAll(filePath)\n\n\tc := newBenchCache()\n\tif err := c.SaveToFileConcurrent(filePath, concurrency); err != nil {\n\t\tb.Fatalf(\"cannot save cache to file: %s\", err)\n\t}\n\n\tb.ReportAllocs()\n\tb.ResetTimer()\n\tb.SetBytes(benchCacheSize)\n\tfor i := 0; i < b.N; i++ {\n\t\tc, err := LoadFromFile(filePath)\n\t\tif err != nil {\n\t\t\tb.Fatalf(\"cannot load cache from file: %s\", err)\n\t\t}\n\t\tvar s Stats\n\t\tc.UpdateStats(&s)\n\t\tif s.EntriesCount == 0 {\n\t\t\tb.Fatalf(\"unexpected zero entries\")\n\t\t}\n\t}\n}\n\nvar (\n\tbenchCache     *Cache\n\tbenchCacheOnce sync.Once\n)\n\nfunc newBenchCache() *Cache {\n\tbenchCacheOnce.Do(func() {\n\t\tc := New(benchCacheSize)\n\t\titemsCount := benchCacheSize / 20\n\t\tfor i := 0; i < itemsCount; i++ {\n\t\t\tk := []byte(fmt.Sprintf(\"key %d\", i))\n\t\t\tv := []byte(fmt.Sprintf(\"value %d\", i))\n\t\t\tc.Set(k, v)\n\t\t}\n\t\tbenchCache = c\n\t})\n\treturn benchCache\n}\n\nconst benchCacheSize = bucketsCount * chunkSize\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.3154296875,
          "content": "module github.com/VictoriaMetrics/fastcache\n\ngo 1.13\n\nrequire (\n\tgithub.com/allegro/bigcache v1.2.1-0.20190218064605-e24eb225f156\n\tgithub.com/cespare/xxhash/v2 v2.2.0\n\tgithub.com/davecgh/go-spew v1.1.1 // indirect\n\tgithub.com/golang/snappy v0.0.4\n\tgithub.com/stretchr/testify v1.3.0 // indirect\n\tgolang.org/x/sys v0.14.0\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 1.3916015625,
          "content": "github.com/allegro/bigcache v1.2.1-0.20190218064605-e24eb225f156 h1:eMwmnE/GDgah4HI848JfFxHt+iPb26b4zyfspmqY0/8=\ngithub.com/allegro/bigcache v1.2.1-0.20190218064605-e24eb225f156/go.mod h1:Cb/ax3seSYIx7SuZdm2G2xzfwmv3TPSk2ucNfQESPXM=\ngithub.com/cespare/xxhash/v2 v2.2.0 h1:DC2CZ1Ep5Y4k3ZQ899DldepgrayRUGE6BBZ/cd9Cj44=\ngithub.com/cespare/xxhash/v2 v2.2.0/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/golang/snappy v0.0.4 h1:yAGX7huGHXlcLOEtBnF4w7FQwA26wojNCwOYAEhLjQM=\ngithub.com/golang/snappy v0.0.4/go.mod h1:/XxbfmMg8lxefKM7IXC3fBNl/7bRcc72aCRzEWrmP2Q=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/testify v1.3.0 h1:TivCn/peBQ7UY8ooIcPgZFpTNSz0Q2U6UrFlUfqbe0Q=\ngithub.com/stretchr/testify v1.3.0/go.mod h1:M5WIy9Dh21IEIfnGCwXGc5bZfKNJtfHm1UVUgZn+9EI=\ngolang.org/x/sys v0.14.0 h1:Vz7Qs629MkJkGyHxUlRHizWJRG2j8fbQKjELVSNhy7Q=\ngolang.org/x/sys v0.14.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\n"
        },
        {
          "name": "malloc_heap.go",
          "type": "blob",
          "size": 0.1787109375,
          "content": "//go:build appengine || windows\n// +build appengine windows\n\npackage fastcache\n\nfunc getChunk() []byte {\n\treturn make([]byte, chunkSize)\n}\n\nfunc putChunk(chunk []byte) {\n\t// No-op.\n}\n"
        },
        {
          "name": "malloc_mmap.go",
          "type": "blob",
          "size": 1.1591796875,
          "content": "//go:build !appengine && !windows\n// +build !appengine,!windows\n\npackage fastcache\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"unsafe\"\n\n\t\"golang.org/x/sys/unix\"\n)\n\nconst chunksPerAlloc = 1024\n\nvar (\n\tfreeChunks     []*[chunkSize]byte\n\tfreeChunksLock sync.Mutex\n)\n\nfunc getChunk() []byte {\n\tfreeChunksLock.Lock()\n\tif len(freeChunks) == 0 {\n\t\t// Allocate offheap memory, so GOGC won't take into account cache size.\n\t\t// This should reduce free memory waste.\n\t\tdata, err := unix.Mmap(-1, 0, chunkSize*chunksPerAlloc, unix.PROT_READ|unix.PROT_WRITE, unix.MAP_ANON|unix.MAP_PRIVATE)\n\t\tif err != nil {\n\t\t\tpanic(fmt.Errorf(\"cannot allocate %d bytes via mmap: %s\", chunkSize*chunksPerAlloc, err))\n\t\t}\n\t\tfor len(data) > 0 {\n\t\t\tp := (*[chunkSize]byte)(unsafe.Pointer(&data[0]))\n\t\t\tfreeChunks = append(freeChunks, p)\n\t\t\tdata = data[chunkSize:]\n\t\t}\n\t}\n\tn := len(freeChunks) - 1\n\tp := freeChunks[n]\n\tfreeChunks[n] = nil\n\tfreeChunks = freeChunks[:n]\n\tfreeChunksLock.Unlock()\n\treturn p[:]\n}\n\nfunc putChunk(chunk []byte) {\n\tif chunk == nil {\n\t\treturn\n\t}\n\tchunk = chunk[:chunkSize]\n\tp := (*[chunkSize]byte)(unsafe.Pointer(&chunk[0]))\n\n\tfreeChunksLock.Lock()\n\tfreeChunks = append(freeChunks, p)\n\tfreeChunksLock.Unlock()\n}\n"
        },
        {
          "name": "vendor",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}