{
  "metadata": {
    "timestamp": 1736567160874,
    "page": 754,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjc2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "raviqqe/muffet",
      "stars": 2527,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".cspell.json",
          "type": "blob",
          "size": 0.5234375,
          "content": "{\n  \"words\": [\n    \"andybalholm\",\n    \"bradleyjkemp\",\n    \"brotli\",\n    \"brotli\",\n    \"codecov\",\n    \"cupaloy\",\n    \"errcheck\",\n    \"fasthttp\",\n    \"fasthttp\",\n    \"fasthttpproxy\",\n    \"iframe\",\n    \"isatty\",\n    \"jessevdk\",\n    \"logrusorgru\",\n    \"mattn\",\n    \"muffet\",\n    \"nolint\",\n    \"oxffaa\",\n    \"preconnect\",\n    \"ratelimit\",\n    \"raviqqe\",\n    \"redirections\",\n    \"redirections\",\n    \"robotstxt\",\n    \"sitemapindex\",\n    \"stretchr\",\n    \"stylesheet\",\n    \"temoto\",\n    \"unbrotli\",\n    \"urlset\",\n    \"valyala\",\n    \"yhat\"\n  ]\n}\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0595703125,
          "content": "*.snap\n.snapcraft\ncoverage.txt\ndist\nmuffet\nparts\nprime\nstage\n"
        },
        {
          "name": ".goreleaser.yaml",
          "type": "blob",
          "size": 0.4169921875,
          "content": "version: 2\nbuilds:\n  - env:\n      - CGO_ENABLED=0\n    goarch:\n      - 386\n      - amd64\n      - arm\n      - arm64\n    goos:\n      - darwin\n      - freebsd\n      - linux\n      - windows\n    goarm:\n      - 6\n      - 7\narchives:\n  - format: tar.gz\n    name_template: \"{{ .ProjectName }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}\"\n    format_overrides:\n      - goos: windows\n        format: zip\nchangelog:\n  sort: asc\n"
        },
        {
          "name": ".snapshots",
          "type": "tree",
          "content": null
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.1982421875,
          "content": "FROM golang AS build\nADD . /app\nWORKDIR /app\nRUN CGO_ENABLED=0 GOOS=linux go install .\n\nFROM alpine\nRUN apk --no-cache add ca-certificates\nCOPY --from=build /go/bin/muffet /muffet\nENTRYPOINT [\"/muffet\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0380859375,
          "content": "MIT License\n\nCopyright (c) Yota Toyama\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 1.4775390625,
          "content": "# Muffet\n\n[![GitHub Action](https://img.shields.io/github/actions/workflow/status/raviqqe/muffet/test.yaml?branch=main&style=flat-square)](https://github.com/raviqqe/muffet/actions)\n[![Codecov](https://img.shields.io/codecov/c/github/raviqqe/muffet.svg?style=flat-square)](https://codecov.io/gh/raviqqe/muffet)\n[![Go Report Card](https://goreportcard.com/badge/github.com/raviqqe/muffet?style=flat-square)](https://goreportcard.com/report/github.com/raviqqe/muffet)\n[![Docker](https://img.shields.io/docker/pulls/raviqqe/muffet?style=flat-square)](https://hub.docker.com/r/raviqqe/muffet)\n[![License](https://img.shields.io/github/license/raviqqe/muffet.svg?style=flat-square)](LICENSE)\n\n![demo](img/demo.gif)\n\nMuffet is a website link checker which scrapes and inspects all pages in a\nwebsite recursively.\n\n## Features\n\n- Massive speed\n- High compatibility with web browsers\n- Different tag support (`a`, `img`, `link`, `script`, etc)\n- Multiple output formats (text, JSON, and JUnit XML)\n\n## Installation\n\n```sh\ngo install github.com/raviqqe/muffet/v2@latest\n```\n\n### Homebrew\n\n```sh\nbrew install muffet\n```\n\n## Usage\n\n```sh\nmuffet https://shady.bakery.hotland\n```\n\nFor more information, see `muffet --help`.\n\n### Docker\n\n```sh\ndocker run raviqqe/muffet https://shady.bakery.hotland\n```\n\n### GitHub Action\n\n- [My Broken Link Checker](https://github.com/ruzickap/action-my-broken-link-checker)\n\nCurrently, we do not provide any official one. Feel free to create an issue if you want!\n\n## License\n\n[MIT](LICENSE)\n"
        },
        {
          "name": "arguments.go",
          "type": "blob",
          "size": 5.4462890625,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"net/http\"\n\t\"regexp\"\n\t\"strings\"\n\n\t\"github.com/jessevdk/go-flags\"\n)\n\ntype arguments struct {\n\tRawAcceptedStatusCodes string   `long:\"accepted-status-codes\" value-name:\"<codes>\" default:\"200..300\" description:\"Accepted HTTP response status codes (e.g. '200..300,403')\"`\n\tBufferSize             int      `short:\"b\" long:\"buffer-size\" value-name:\"<size>\" default:\"4096\" description:\"HTTP response buffer size in bytes\"`\n\tMaxConnections         int      `short:\"c\" long:\"max-connections\" value-name:\"<count>\" default:\"512\" description:\"Maximum number of HTTP connections\"`\n\tMaxConnectionsPerHost  int      `long:\"max-connections-per-host\" value-name:\"<count>\" default:\"512\" description:\"Maximum number of HTTP connections per host\"`\n\tMaxResponseBodySize    int      `long:\"max-response-body-size\" value-name:\"<size>\" default:\"10000000\" description:\"Maximum response body size to read\"`\n\tRawExcludedPatterns    []string `short:\"e\" long:\"exclude\" value-name:\"<pattern>...\" description:\"Exclude URLs matched with given regular expressions\"`\n\tRawIncludedPatterns    []string `short:\"i\" long:\"include\" value-name:\"<pattern>...\" description:\"Include URLs matched with given regular expressions\"`\n\tFollowRobotsTxt        bool     `long:\"follow-robots-txt\" description:\"Follow robots.txt when scraping pages\"`\n\tFollowSitemapXML       bool     `long:\"follow-sitemap-xml\" description:\"Scrape only pages listed in sitemap.xml (deprecated)\"`\n\tRawHeaders             []string `long:\"header\" value-name:\"<header>...\" description:\"Custom headers\"`\n\t// TODO Remove a short option.\n\tIgnoreFragments bool   `short:\"f\" long:\"ignore-fragments\" description:\"Ignore URL fragments\"`\n\tDnsResolver     string `long:\"dns-resolver\" value-name:\"<address>\" description:\"Custom DNS resolver\"`\n\tFormat          string `long:\"format\" description:\"Output format\" default:\"text\" choice:\"text\" choice:\"json\" choice:\"junit\"`\n\t// TODO Remove this option.\n\tJSONOutput bool `long:\"json\" description:\"Output results in JSON (deprecated)\"`\n\t// TODO Remove this option.\n\tVerboseJSON bool `long:\"experimental-verbose-json\" description:\"Include successful results in JSON (deprecated)\"`\n\t// TODO Remove this option.\n\tJUnitOutput         bool   `long:\"junit\" description:\"Output results as JUnit XML file (deprecated)\"`\n\tMaxRedirections     int    `short:\"r\" long:\"max-redirections\" value-name:\"<count>\" default:\"64\" description:\"Maximum number of redirections\"`\n\tRateLimit           int    `long:\"rate-limit\" value-name:\"<rate>\" description:\"Max requests per second\"`\n\tTimeout             int    `short:\"t\" long:\"timeout\" value-name:\"<seconds>\" default:\"10\" description:\"Timeout for HTTP requests in seconds\"`\n\tVerbose             bool   `short:\"v\" long:\"verbose\" description:\"Show successful results too\"`\n\tProxy               string `long:\"proxy\" value-name:\"<host>\" description:\"HTTP proxy host\"`\n\tSkipTLSVerification bool   `long:\"skip-tls-verification\" description:\"Skip TLS certificate verification\"`\n\tOnePageOnly         bool   `long:\"one-page-only\" description:\"Only check links found in the given URL\"`\n\tColor               color  `long:\"color\" description:\"Color output\" choice:\"auto\" choice:\"always\" choice:\"never\" default:\"auto\"`\n\tHelp                bool   `short:\"h\" long:\"help\" description:\"Show this help\"`\n\tVersion             bool   `long:\"version\" description:\"Show version\"`\n\tURL                 string\n\tAcceptedStatusCodes statusCodeSet\n\tExcludedPatterns    []*regexp.Regexp\n\tIncludePatterns     []*regexp.Regexp\n\tHeader              http.Header\n}\n\nfunc getArguments(ss []string) (*arguments, error) {\n\targs := arguments{}\n\tss, err := flags.NewParser(&args, flags.PassDoubleDash).ParseArgs(ss)\n\n\tif err != nil {\n\t\treturn nil, err\n\t} else if args.Version || args.Help {\n\t\treturn &args, nil\n\t} else if len(ss) != 1 {\n\t\treturn nil, errors.New(\"invalid number of arguments\")\n\t}\n\n\treconcileDeprecatedArguments(&args)\n\n\targs.URL = ss[0]\n\n\targs.ExcludedPatterns, err = compileRegexps(args.RawExcludedPatterns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\targs.IncludePatterns, err = compileRegexps(args.RawIncludedPatterns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\targs.Header, err = parseHeaders(args.RawHeaders)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\targs.AcceptedStatusCodes, err = parseStatusCodeSet(args.RawAcceptedStatusCodes)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif args.Format == \"junit\" && args.Verbose {\n\t\treturn nil, errors.New(\"verbose option not supported for JUnit output\")\n\t}\n\n\treturn &args, nil\n}\n\nfunc help() string {\n\tp := flags.NewParser(&arguments{}, flags.PassDoubleDash)\n\tp.Usage = \"[options] <url>\"\n\n\t// Parse() is run here to show default values in help.\n\t// This seems to be a bug in go-flags.\n\tp.Parse() // nolint:errcheck\n\n\tb := &bytes.Buffer{}\n\tp.WriteHelp(b)\n\treturn b.String()\n}\n\nfunc compileRegexps(regexps []string) ([]*regexp.Regexp, error) {\n\trs := make([]*regexp.Regexp, 0, len(regexps))\n\n\tfor _, s := range regexps {\n\t\tr, err := regexp.Compile(s)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\trs = append(rs, r)\n\t}\n\n\treturn rs, nil\n}\n\nfunc parseHeaders(headers []string) (http.Header, error) {\n\th := make(http.Header, len(headers))\n\n\tfor _, s := range headers {\n\t\ti := strings.IndexRune(s, ':')\n\n\t\tif i < 0 {\n\t\t\treturn nil, errors.New(\"invalid header format\")\n\t\t}\n\n\t\th.Add(s[:i], strings.TrimSpace(s[i+1:]))\n\t}\n\n\treturn h, nil\n}\n\nfunc reconcileDeprecatedArguments(args *arguments) {\n\tif args.JSONOutput {\n\t\targs.Format = \"json\"\n\t\targs.Verbose = args.Verbose || args.VerboseJSON\n\t} else if args.JUnitOutput {\n\t\targs.Format = \"junit\"\n\t}\n}\n"
        },
        {
          "name": "arguments_test.go",
          "type": "blob",
          "size": 2.9072265625,
          "content": "package main\n\nimport (\n\t\"net/http\"\n\t\"testing\"\n\n\t\"github.com/bradleyjkemp/cupaloy\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestGetArguments(t *testing.T) {\n\tfor _, ss := range [][]string{\n\t\t{\"https://foo.com\"},\n\t\t{\"--accepted-status-codes\", \"200..300,403\", \"https://foo.com\"},\n\t\t{\"-b\", \"42\", \"https://foo.com\"},\n\t\t{\"--buffer-size\", \"42\", \"https://foo.com\"},\n\t\t{\"-c\", \"1\", \"https://foo.com\"},\n\t\t{\"--max-connections\", \"1\", \"https://foo.com\"},\n\t\t{\"--max-connections-per-host\", \"1\", \"https://foo.com\"},\n\t\t{\"--max-response-body-size\", \"1\", \"https://foo.com\"},\n\t\t{\"-e\", \"regex1\", \"-e\", \"regex2\", \"https://foo.com\"},\n\t\t{\"--exclude\", \"regex1\", \"--exclude\", \"regex2\", \"https://foo.com\"},\n\t\t{\"--header\", \"MyHeader: foo\", \"--header\", \"YourHeader: bar\", \"https://foo.com\"},\n\t\t{\"--header\", \"User-Agent: custom-agent\", \"https://foo.com\"},\n\t\t{\"-r\", \"4\", \"https://foo.com\"},\n\t\t{\"--max-redirections\", \"4\", \"https://foo.com\"},\n\t\t{\"--follow-robots-txt\", \"https://foo.com\"},\n\t\t{\"--follow-sitemap-xml\", \"https://foo.com\"},\n\t\t{\"-t\", \"10\", \"https://foo.com\"},\n\t\t{\"--timeout\", \"10\", \"https://foo.com\"},\n\t\t{\"--rate-limit\", \"1\", \"https://foo.com\"},\n\t\t{\"--proxy\", \"localhost:8080\", \"https://foo.com\"},\n\t\t{\"--skip-tls-verification\", \"https://foo.com\"},\n\t\t{\"-v\", \"https://foo.com\"},\n\t\t{\"--verbose\", \"https://foo.com\"},\n\t\t{\"-v\", \"-f\", \"https://foo.com\"},\n\t\t{\"-v\", \"--ignore-fragments\", \"https://foo.com\"},\n\t\t{\"--one-page-only\", \"https://foo.com\"},\n\t\t{\"--json\", \"https://foo.com\"},\n\t\t{\"-h\"},\n\t\t{\"--help\"},\n\t\t{\"--version\"},\n\t} {\n\t\t_, err := getArguments(ss)\n\t\tassert.Nil(t, err)\n\t}\n}\n\nfunc TestGetArgumentsError(t *testing.T) {\n\tfor _, ss := range [][]string{\n\t\t{},\n\t\t{\"--accepted-status-codes\", \"foo\", \"https://foo.com\"},\n\t\t{\"-b\", \"foo\", \"https://foo.com\"},\n\t\t{\"--buffer-size\", \"foo\", \"https://foo.com\"},\n\t\t{\"-c\", \"foo\", \"https://foo.com\"},\n\t\t{\"--max-connections\", \"foo\", \"https://foo.com\"},\n\t\t{\"-e\", \"(\", \"https://foo.com\"},\n\t\t{\"-j\", \"MyHeader\", \"https://foo.com\"},\n\t\t{\"--header\", \"MyHeader\", \"https://foo.com\"},\n\t\t{\"-l\", \"foo\", \"https://foo.com\"},\n\t\t{\"--max-redirections\", \"foo\", \"https://foo.com\"},\n\t\t{\"-t\", \"foo\", \"https://foo.com\"},\n\t\t{\"--timeout\", \"foo\", \"https://foo.com\"},\n\t} {\n\t\t_, err := getArguments(ss)\n\t\tassert.NotNil(t, err)\n\t}\n}\n\nfunc TestHelp(t *testing.T) {\n\tcupaloy.SnapshotT(t, help())\n}\n\nfunc TestParseHeader(t *testing.T) {\n\tfor _, c := range []struct {\n\t\targuments []string\n\t\theader    http.Header\n\t}{\n\t\t{\n\t\t\tnil,\n\t\t\thttp.Header{},\n\t\t},\n\t\t{\n\t\t\t[]string{\"MyHeader: foo\"},\n\t\t\t(func() http.Header {\n\t\t\t\th := http.Header{}\n\t\t\t\th.Add(\"MyHeader\", \"foo\")\n\t\t\t\treturn h\n\t\t\t})(),\n\t\t},\n\t\t{\n\t\t\t[]string{\"MyHeader: foo\", \"YourHeader: bar\"},\n\t\t\t(func() http.Header {\n\t\t\t\th := http.Header{}\n\t\t\t\th.Add(\"MyHeader\", \"foo\")\n\t\t\t\th.Add(\"YourHeader\", \"bar\")\n\t\t\t\treturn h\n\t\t\t})(),\n\t\t},\n\t} {\n\t\ths, err := parseHeaders(c.arguments)\n\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, c.header, hs)\n\t}\n}\n\nfunc TestParseHeadersError(t *testing.T) {\n\t_, err := parseHeaders([]string{\"MyHeader\"})\n\tassert.NotNil(t, err)\n}\n"
        },
        {
          "name": "cache.go",
          "type": "blob",
          "size": 0.48828125,
          "content": "package main\n\nimport \"sync\"\n\ntype cache struct {\n\tlocks  *sync.Map\n\tvalues *sync.Map\n}\n\nfunc newCache() cache {\n\treturn cache{&sync.Map{}, &sync.Map{}}\n}\n\nfunc (c cache) LoadOrStore(key string) (any, func(any)) {\n\tif x, ok := c.values.Load(key); ok {\n\t\treturn x, nil\n\t}\n\n\tg := &sync.WaitGroup{}\n\tg.Add(1)\n\n\tif g, ok := c.locks.LoadOrStore(key, g); ok {\n\t\tg.(*sync.WaitGroup).Wait()\n\t\tx, _ := c.values.Load(key)\n\n\t\treturn x, nil\n\t}\n\n\treturn nil, func(x any) {\n\t\tc.values.Store(key, x)\n\t\tg.Done()\n\t}\n}\n"
        },
        {
          "name": "cache_test.go",
          "type": "blob",
          "size": 0.9130859375,
          "content": "package main\n\nimport (\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestNewCache(t *testing.T) {\n\tnewCache()\n}\n\nfunc TestCacheLoadOrStore(t *testing.T) {\n\tc := newCache()\n\n\tx, f := c.LoadOrStore(\"https://foo.com\")\n\n\tassert.Nil(t, x)\n\tassert.NotNil(t, f)\n\n\tf(42)\n\n\tx, f = c.LoadOrStore(\"https://foo.com\")\n\n\tassert.Equal(t, 42, x)\n\tassert.Nil(t, f)\n}\n\nfunc TestCacheLoadOrStoreConcurrency(t *testing.T) {\n\tc := newCache()\n\n\tx, f := c.LoadOrStore(\"key\")\n\tassert.Nil(t, x)\n\tassert.NotNil(t, f)\n\n\tgo func() {\n\t\tx, f := c.LoadOrStore(\"key\")\n\t\tassert.Equal(t, 42, x)\n\t\tassert.Nil(t, f)\n\t}()\n\n\ttime.Sleep(time.Millisecond)\n\n\tf(42)\n}\n\nfunc BenchmarkCacheLoadOrStore(b *testing.B) {\n\tc := newCache()\n\tg := &sync.WaitGroup{}\n\n\t_, f := c.LoadOrStore(\"https://foo.com\")\n\tf(42)\n\n\tb.ResetTimer()\n\n\tfor i := 0; i < b.N; i++ {\n\t\tg.Add(1)\n\n\t\tgo func() {\n\t\t\tc.LoadOrStore(\"https://foo.com\")\n\t\t\tg.Done()\n\t\t}()\n\t}\n\n\tg.Wait()\n}\n"
        },
        {
          "name": "checked_http_client.go",
          "type": "blob",
          "size": 0.5771484375,
          "content": "package main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"net/url\"\n)\n\ntype checkedHttpClient struct {\n\tclient              httpClient\n\tacceptedStatusCodes statusCodeSet\n}\n\nfunc newCheckedHttpClient(c httpClient, acceptedStatusCodes statusCodeSet) httpClient {\n\treturn &checkedHttpClient{c, acceptedStatusCodes}\n}\n\nfunc (c *checkedHttpClient) Get(u *url.URL, header http.Header) (httpResponse, error) {\n\tr, err := c.client.Get(u, header)\n\tif err != nil {\n\t\treturn nil, err\n\t} else if code := r.StatusCode(); !c.acceptedStatusCodes.Contains(code) {\n\t\treturn nil, fmt.Errorf(\"%v\", code)\n\t}\n\n\treturn r, nil\n}\n"
        },
        {
          "name": "checked_http_client_test.go",
          "type": "blob",
          "size": 0.8515625,
          "content": "package main\n\nimport (\n\t\"net/url\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestCheckedHttpClientFailWithValidStatusCode(t *testing.T) {\n\tu, err := url.Parse(testUrl)\n\n\tassert.Nil(t, err)\n\n\tr, err := newCheckedHttpClient(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\treturn newFakeHttpResponse(200, testUrl, nil, nil), nil\n\t\t\t},\n\t\t),\n\t\tstatusCodeSet{{200, 201}: {}},\n\t).Get(u, nil)\n\n\tassert.Nil(t, err)\n\tassert.NotNil(t, r)\n}\n\nfunc TestCheckedHttpClientFailWithInvalidStatusCode(t *testing.T) {\n\tu, err := url.Parse(testUrl)\n\n\tassert.Nil(t, err)\n\n\tr, err := newCheckedHttpClient(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\treturn newFakeHttpResponse(404, testUrl, nil, nil), nil\n\t\t\t},\n\t\t),\n\t\tstatusCodeSet{{200, 201}: {}},\n\t).Get(u, nil)\n\n\tassert.Nil(t, r)\n\tassert.Equal(t, err.Error(), \"404\")\n}\n"
        },
        {
          "name": "color.go",
          "type": "blob",
          "size": 0.208984375,
          "content": "package main\n\ntype color string\n\nconst (\n\tauto   color = \"auto\"\n\talways color = \"always\"\n\tnever  color = \"never\"\n)\n\nfunc isColorEnabled(c color, terminal bool) bool {\n\treturn c == always || terminal && c == auto\n}\n"
        },
        {
          "name": "color_test.go",
          "type": "blob",
          "size": 0.3837890625,
          "content": "package main\n\nimport (\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestIsColorEnable(t *testing.T) {\n\tassert.True(t, isColorEnabled(auto, true))\n\tassert.False(t, isColorEnabled(auto, false))\n\tassert.True(t, isColorEnabled(always, true))\n\tassert.True(t, isColorEnabled(always, false))\n\tassert.False(t, isColorEnabled(never, true))\n\tassert.False(t, isColorEnabled(never, false))\n}\n"
        },
        {
          "name": "command.go",
          "type": "blob",
          "size": 4.1123046875,
          "content": "package main\n\nimport (\n\t\"encoding/json\"\n\t\"encoding/xml\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/logrusorgru/aurora/v3\"\n\t\"github.com/temoto/robotstxt\"\n)\n\ntype command struct {\n\tstdout, stderr    io.Writer\n\tterminal          bool\n\thttpClientFactory httpClientFactory\n}\n\nfunc newCommand(stdout, stderr io.Writer, terminal bool, f httpClientFactory) *command {\n\treturn &command{stdout, stderr, terminal, f}\n}\n\nfunc (c *command) Run(args []string) bool {\n\tok, err := c.runWithError(args)\n\tif err != nil {\n\t\tc.printError(err)\n\t}\n\n\treturn ok\n}\n\nfunc (c *command) runWithError(ss []string) (bool, error) {\n\targs, err := getArguments(ss)\n\tif err != nil {\n\t\treturn false, err\n\t} else if args.Help {\n\t\tc.print(help())\n\t\treturn true, nil\n\t} else if args.Version {\n\t\tc.print(version)\n\t\treturn true, nil\n\t}\n\n\tclient := newCheckedHttpClient(\n\t\tnewRedirectHttpClient(\n\t\t\tnewThrottledHttpClient(\n\t\t\t\tc.httpClientFactory.Create(\n\t\t\t\t\thttpClientOptions{\n\t\t\t\t\t\tMaxConnectionsPerHost: args.MaxConnectionsPerHost,\n\t\t\t\t\t\tMaxResponseBodySize:   args.MaxResponseBodySize,\n\t\t\t\t\t\tBufferSize:            args.BufferSize,\n\t\t\t\t\t\tProxy:                 args.Proxy,\n\t\t\t\t\t\tSkipTLSVerification:   args.SkipTLSVerification,\n\t\t\t\t\t\tTimeout:               time.Duration(args.Timeout) * time.Second,\n\t\t\t\t\t\tHeader:                args.Header,\n\t\t\t\t\t\tDnsResolver:           args.DnsResolver,\n\t\t\t\t\t},\n\t\t\t\t),\n\t\t\t\targs.RateLimit,\n\t\t\t\targs.MaxConnections,\n\t\t\t\targs.MaxConnectionsPerHost,\n\t\t\t),\n\t\t\targs.MaxRedirections,\n\t\t),\n\t\targs.AcceptedStatusCodes,\n\t)\n\n\tfl := newLinkFilterer(args.ExcludedPatterns, args.IncludePatterns)\n\n\tf := newLinkFetcher(\n\t\tclient,\n\t\t[]pageParser{\n\t\t\tnewSitemapPageParser(fl),\n\t\t\tnewHtmlPageParser(newLinkFinder(fl)),\n\t\t},\n\t\tlinkFetcherOptions{\n\t\t\targs.IgnoreFragments,\n\t\t},\n\t)\n\n\t_, p, err := f.Fetch(args.URL)\n\tif err != nil {\n\t\treturn false, fmt.Errorf(\"failed to fetch root page: %v\", err)\n\t} else if p == nil {\n\t\treturn false, errors.New(\"root page has invalid content type\")\n\t}\n\n\trd := (*robotstxt.RobotsData)(nil)\n\n\tif args.FollowRobotsTxt {\n\t\trd, err = newRobotsTxtFetcher(client).Fetch(p.URL())\n\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t}\n\n\tsm := (map[string]struct{})(nil)\n\n\tif args.FollowSitemapXML {\n\t\tsm, err = newSitemapFetcher(client).Fetch(p.URL())\n\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t}\n\n\tchecker := newPageChecker(\n\t\tf,\n\t\tnewLinkValidator(p.URL().Hostname(), rd, sm),\n\t\targs.OnePageOnly,\n\t)\n\n\tgo checker.Check(p)\n\n\tswitch args.Format {\n\tcase \"json\":\n\t\treturn c.printResultsInJSON(checker.Results(), args.Verbose)\n\tcase \"junit\":\n\t\treturn c.printResultsInJUnitXML(checker.Results())\n\t}\n\n\tformatter := newPageResultFormatter(\n\t\targs.Verbose,\n\t\tisColorEnabled(args.Color, c.terminal),\n\t)\n\n\tok := true\n\n\tfor r := range checker.Results() {\n\t\tif !r.OK() || args.Verbose {\n\t\t\tc.print(formatter.Format(r))\n\t\t}\n\n\t\tok = ok && r.OK()\n\t}\n\n\treturn ok, nil\n}\n\nfunc (c *command) printResultsInJSON(rc <-chan *pageResult, verbose bool) (bool, error) {\n\trs := []any{}\n\tok := true\n\n\tfor r := range rc {\n\t\tif !r.OK() || verbose {\n\t\t\trs = append(rs, newJSONPageResult(r, verbose))\n\t\t}\n\n\t\tok = ok && r.OK()\n\t}\n\n\tbs, err := json.Marshal(rs)\n\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tc.print(string(bs))\n\n\treturn ok, nil\n}\n\nfunc (c *command) printResultsInJUnitXML(rc <-chan *pageResult) (bool, error) {\n\trs := []*xmlPageResult{}\n\tok := true\n\n\tfor r := range rc {\n\t\trs = append(rs, newXMLPageResult(r))\n\t\tok = ok && r.OK()\n\t}\n\n\tbs, err := xml.MarshalIndent(\n\t\tstruct {\n\t\t\t// spell-checker: disable-next-line\n\t\t\tXMLName xml.Name `xml:\"testsuites\"`\n\t\t\t// spell-checker: disable-next-line\n\t\t\tPageResults []*xmlPageResult `xml:\"testsuite\"`\n\t\t}{\n\t\t\tPageResults: rs,\n\t\t},\n\t\t\"\",\n\t\t\"  \",\n\t)\n\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tc.print(xml.Header)\n\tc.print(string(bs))\n\n\treturn ok, nil\n}\n\nfunc (c *command) print(xs ...any) {\n\tif _, err := fmt.Fprintln(c.stdout, strings.TrimSpace(fmt.Sprint(xs...))); err != nil {\n\t\tpanic(err)\n\t}\n}\n\nfunc (c *command) printError(xs ...any) {\n\ts := fmt.Sprint(xs...)\n\n\t// Do not check --color option here because this can be used on argument parsing errors.\n\tif c.terminal {\n\t\ts = aurora.Red(s).String()\n\t}\n\n\tif _, err := fmt.Fprintln(c.stderr, s); err != nil {\n\t\tpanic(err)\n\t}\n}\n"
        },
        {
          "name": "command_test.go",
          "type": "blob",
          "size": 6.3046875,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"io\"\n\t\"net/url\"\n\t\"regexp\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/bradleyjkemp/cupaloy\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc newTestCommand(h func(*url.URL) (*fakeHttpResponse, error)) *command {\n\treturn newTestCommandWithStdout(io.Discard, h)\n}\n\nfunc newTestCommandWithStdout(stdout io.Writer, h func(*url.URL) (*fakeHttpResponse, error)) *command {\n\treturn newCommand(\n\t\tstdout,\n\t\tio.Discard,\n\t\tfalse,\n\t\tnewFakeHttpClientFactory(h),\n\t)\n}\n\nfunc newTestCommandWithStderr(stderr io.Writer, h func(*url.URL) (*fakeHttpResponse, error)) *command {\n\treturn newCommand(\n\t\tio.Discard,\n\t\tstderr,\n\t\tfalse,\n\t\tnewFakeHttpClientFactory(h),\n\t)\n}\n\nfunc TestCommandRun(t *testing.T) {\n\tok := newTestCommand(\n\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\ts := \"http://foo.com\"\n\n\t\t\tif u.String() != s {\n\t\t\t\treturn nil, errors.New(\"\")\n\t\t\t}\n\n\t\t\treturn newFakeHtmlResponse(s, \"\"), nil\n\t\t},\n\t).Run([]string{\"http://foo.com\"})\n\n\tassert.True(t, ok)\n}\n\nfunc TestCommandRunWithLinks(t *testing.T) {\n\tvisited := false\n\n\tok := newTestCommand(\n\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\tswitch u.String() {\n\t\t\tcase \"http://foo.com\":\n\t\t\t\treturn newFakeHtmlResponse(\n\t\t\t\t\t\"http://foo.com\",\n\t\t\t\t\t`<html><body><a href=\"/foo\" /></body></html>`,\n\t\t\t\t), nil\n\t\t\tcase \"http://foo.com/foo\":\n\t\t\t\tvisited = true\n\t\t\t\treturn newFakeHtmlResponse(\"http://foo.com\", \"\"), nil\n\t\t\t}\n\n\t\t\treturn nil, errors.New(\"\")\n\t\t},\n\t).Run([]string{\"http://foo.com\"})\n\n\tassert.True(t, ok)\n\tassert.True(t, visited)\n}\n\nfunc TestCommandRunWithVerboseOption(t *testing.T) {\n\tb := &bytes.Buffer{}\n\n\tok := newTestCommandWithStdout(\n\t\tb,\n\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\treturn newFakeHtmlResponse(\"http://foo.com\", \"\"), nil\n\t\t},\n\t).Run([]string{\"-v\", \"http://foo.com\"})\n\n\tassert.True(t, ok)\n\tassert.Greater(t, b.Len(), 0)\n}\n\nfunc TestCommandFailToRun(t *testing.T) {\n\tok := newTestCommand(\n\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\treturn nil, errors.New(\"\")\n\t\t},\n\t).Run([]string{\"http://foo.com\"})\n\n\tassert.False(t, ok)\n}\n\nfunc TestCommandFailToRunWithInvalidLink(t *testing.T) {\n\tb := &bytes.Buffer{}\n\n\tok := newTestCommandWithStdout(\n\t\tb,\n\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\tif u.String() == \"http://foo.com\" {\n\t\t\t\treturn newFakeHtmlResponse(\n\t\t\t\t\t\"http://foo.com\",\n\t\t\t\t\t`<html><body><a href=\"/foo\" /></body></html>`,\n\t\t\t\t), nil\n\t\t\t}\n\n\t\t\treturn nil, errors.New(\"\")\n\t\t},\n\t).Run([]string{\"http://foo.com\"})\n\n\tassert.False(t, ok)\n\tassert.Regexp(t, `http://foo\\.com/foo`, b.String())\n}\n\nfunc TestCommandFailToParseArguments(t *testing.T) {\n\tb := &bytes.Buffer{}\n\n\tc := newTestCommandWithStderr(\n\t\tb,\n\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\treturn newFakeHtmlResponse(\"\", \"\"), nil\n\t\t},\n\t)\n\n\tok := c.Run(nil)\n\n\tassert.False(t, ok)\n\tassert.Greater(t, b.Len(), 0)\n}\n\nfunc TestCommandFailToFetchRootPage(t *testing.T) {\n\tb := &bytes.Buffer{}\n\n\tok := newTestCommandWithStderr(\n\t\tb,\n\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\treturn nil, errors.New(\"foo\")\n\t\t},\n\t).Run([]string{\"http://foo.com\"})\n\n\tassert.False(t, ok)\n\tcupaloy.SnapshotT(t, b.String())\n}\n\nfunc TestCommandFailToGetHTMLRootPage(t *testing.T) {\n\tb := &bytes.Buffer{}\n\n\tok := newTestCommandWithStderr(\n\t\tb,\n\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\treturn newFakeHttpResponse(\n\t\t\t\t200,\n\t\t\t\t\"\",\n\t\t\t\tnil,\n\t\t\t\tmap[string]string{\"content-type\": \"image/png\"},\n\t\t\t), nil\n\t\t},\n\t).Run([]string{\"http://foo.com\"})\n\n\tassert.False(t, ok)\n\tcupaloy.SnapshotT(t, b.String())\n}\n\nfunc TestCommandColorErrorMessage(t *testing.T) {\n\tb := &bytes.Buffer{}\n\n\tc := newCommand(\n\t\tio.Discard,\n\t\tb,\n\t\ttrue,\n\t\tnewFakeHttpClientFactory(func(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\treturn nil, errors.New(\"foo\")\n\t\t}),\n\t)\n\n\tok := c.Run([]string{\"http://foo.com\"})\n\n\tassert.False(t, ok)\n\tcupaloy.SnapshotT(t, b.String())\n}\n\nfunc TestCommandShowHelp(t *testing.T) {\n\tb := &bytes.Buffer{}\n\n\tc := newTestCommandWithStdout(\n\t\tb,\n\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\treturn newFakeHtmlResponse(\"\", \"\"), nil\n\t\t},\n\t)\n\n\tok := c.Run([]string{\"--help\"})\n\n\tassert.True(t, ok)\n\tassert.Greater(t, b.Len(), 0)\n}\n\nfunc TestCommandShowVersion(t *testing.T) {\n\tb := &bytes.Buffer{}\n\n\tc := newTestCommandWithStdout(\n\t\tb,\n\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\treturn newFakeHtmlResponse(\"\", \"\"), nil\n\t\t},\n\t)\n\n\tok := c.Run([]string{\"--version\"})\n\tassert.True(t, ok)\n\n\tr, err := regexp.Compile(`^[0-9]+\\.[0-9]+\\.[0-9]+$`)\n\tassert.Nil(t, err)\n\tassert.True(t, r.MatchString(strings.TrimSpace(b.String())))\n}\n\nfunc TestCommandFailToRunWithJSONOutput(t *testing.T) {\n\tb := &bytes.Buffer{}\n\n\tok := newTestCommandWithStdout(\n\t\tb,\n\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\tif u.String() == \"http://foo.com\" {\n\t\t\t\treturn newFakeHtmlResponse(\n\t\t\t\t\t\"http://foo.com\",\n\t\t\t\t\t`<html><body><a href=\"/foo\" /></body></html>`,\n\t\t\t\t), nil\n\t\t\t}\n\n\t\t\treturn nil, errors.New(\"foo\")\n\t\t},\n\t).Run([]string{\"--json\", \"http://foo.com\"})\n\n\tassert.False(t, ok)\n\tassert.Greater(t, b.Len(), 0)\n}\n\nfunc TestCommandDoNotIncludeSuccessfulPageInJSONOutput(t *testing.T) {\n\tb := &bytes.Buffer{}\n\n\tok := newTestCommandWithStdout(\n\t\tb,\n\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\treturn newFakeHtmlResponse(\"\", \"\"), nil\n\t\t},\n\t).Run([]string{\"--json\", \"http://foo.com\"})\n\n\tassert.True(t, ok)\n\tassert.Equal(t, strings.TrimSpace(b.String()), \"[]\")\n}\n\nfunc TestCommandIncludeSuccessfulPageInJSONOutputWhenRequested(t *testing.T) {\n\tb := &bytes.Buffer{}\n\n\tok := newTestCommandWithStdout(\n\t\tb,\n\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\treturn newFakeHtmlResponse(\"\", \"\"), nil\n\t\t},\n\t).Run([]string{\"--json\", \"--experimental-verbose-json\", \"http://foo.com\"})\n\n\tassert.True(t, ok)\n\tassert.Equal(t, strings.TrimSpace(b.String()), \"[{\\\"url\\\":\\\"\\\",\\\"links\\\":[]}]\")\n}\n\nfunc TestCommandFailToRunWithJUnitOutput(t *testing.T) {\n\tb := &bytes.Buffer{}\n\n\tok := newTestCommandWithStdout(\n\t\tb,\n\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\tif u.String() == \"http://foo.com\" {\n\t\t\t\treturn newFakeHtmlResponse(\n\t\t\t\t\t\"http://foo.com\",\n\t\t\t\t\t`<html><body><a href=\"/foo\" /></body></html>`,\n\t\t\t\t), nil\n\t\t\t}\n\n\t\t\treturn nil, errors.New(\"foo\")\n\t\t},\n\t).Run([]string{\"--junit\", \"http://foo.com\"})\n\n\tassert.False(t, ok)\n\tassert.Greater(t, b.Len(), 0)\n}\n\nfunc TestCommandFailWithVerboseAndJUnitOptions(t *testing.T) {\n\tb := &bytes.Buffer{}\n\n\tok := newTestCommandWithStderr(b, nil).Run(\n\t\t[]string{\"--junit\", \"--verbose\", \"http://foo.com\"},\n\t)\n\n\tassert.False(t, ok)\n\tcupaloy.SnapshotT(t, b.String())\n}\n"
        },
        {
          "name": "concurrent_string_set.go",
          "type": "blob",
          "size": 0.275390625,
          "content": "package main\n\nimport \"sync\"\n\ntype concurrentStringSet struct {\n\tset *sync.Map\n}\n\nfunc newConcurrentStringSet() concurrentStringSet {\n\treturn concurrentStringSet{&sync.Map{}}\n}\n\nfunc (c concurrentStringSet) Add(s string) bool {\n\t_, exist := c.set.LoadOrStore(s, nil)\n\treturn exist\n}\n"
        },
        {
          "name": "concurrent_string_set_test.go",
          "type": "blob",
          "size": 0.2880859375,
          "content": "package main\n\nimport (\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestNewConcurrentStringSet(t *testing.T) {\n\tnewConcurrentStringSet()\n}\n\nfunc TestConcurrentStringSetAdd(t *testing.T) {\n\ts := newConcurrentStringSet()\n\tassert.False(t, s.Add(\"foo\"))\n\tassert.True(t, s.Add(\"foo\"))\n}\n"
        },
        {
          "name": "configuration.go",
          "type": "blob",
          "size": 0.134765625,
          "content": "package main\n\nimport \"time\"\n\nconst (\n\tversion     = \"2.10.6\"\n\tagentName   = \"muffet\"\n\tconcurrency = 1024\n\ttcpTimeout  = 5 * time.Second\n)\n"
        },
        {
          "name": "daemon_manager.go",
          "type": "blob",
          "size": 0.45703125,
          "content": "package main\n\nimport \"sync\"\n\ntype daemonManager struct {\n\tdaemons   chan func()\n\twaitGroup *sync.WaitGroup\n}\n\nfunc newDaemonManager(capacity int) *daemonManager {\n\treturn &daemonManager{make(chan func(), capacity), &sync.WaitGroup{}}\n}\n\nfunc (m daemonManager) Add(f func()) {\n\tm.waitGroup.Add(1)\n\n\tm.daemons <- func() {\n\t\tf()\n\t\tm.waitGroup.Done()\n\t}\n}\n\nfunc (m daemonManager) Run() {\n\tgo func() {\n\t\tfor f := range m.daemons {\n\t\t\tgo f()\n\t\t}\n\t}()\n\n\tm.waitGroup.Wait()\n}\n"
        },
        {
          "name": "daemon_manager_test.go",
          "type": "blob",
          "size": 0.296875,
          "content": "package main\n\nimport (\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestNewDaemonManager(t *testing.T) {\n\tnewDaemonManager(1)\n}\n\nfunc TestDaemonsRun(t *testing.T) {\n\tx := 0\n\n\tm := newDaemonManager(42)\n\tm.Add(func() { x++ })\n\tm.Run()\n\n\tassert.Equal(t, 1, x)\n\tassert.Zero(t, len(m.daemons))\n}\n"
        },
        {
          "name": "fake_http_client_factory_test.go",
          "type": "blob",
          "size": 0.35546875,
          "content": "package main\n\nimport \"net/url\"\n\ntype fakeHttpClientFactory struct {\n\thandler func(*url.URL) (*fakeHttpResponse, error)\n}\n\nfunc newFakeHttpClientFactory(h func(*url.URL) (*fakeHttpResponse, error)) httpClientFactory {\n\treturn &fakeHttpClientFactory{h}\n}\n\nfunc (f *fakeHttpClientFactory) Create(httpClientOptions) httpClient {\n\treturn newFakeHttpClient(f.handler)\n}\n"
        },
        {
          "name": "fake_http_client_test.go",
          "type": "blob",
          "size": 0.3427734375,
          "content": "package main\n\nimport (\n\t\"net/http\"\n\t\"net/url\"\n)\n\ntype fakeHttpClient struct {\n\thandler func(*url.URL) (*fakeHttpResponse, error)\n}\n\nfunc newFakeHttpClient(h func(*url.URL) (*fakeHttpResponse, error)) *fakeHttpClient {\n\treturn &fakeHttpClient{h}\n}\n\nfunc (c *fakeHttpClient) Get(u *url.URL, _ http.Header) (httpResponse, error) {\n\treturn c.handler(u)\n}\n"
        },
        {
          "name": "fake_http_response_test.go",
          "type": "blob",
          "size": 1.1494140625,
          "content": "package main\n\nimport \"strings\"\n\ntype fakeHttpResponse struct {\n\tstatusCode int\n\tlocation   string\n\tbody       []byte\n\theaders    map[string]string\n}\n\nfunc newFakeHttpResponse(statusCode int, location string, body []byte, headers map[string]string) *fakeHttpResponse {\n\ths := make(map[string]string, len(headers))\n\n\tfor k, v := range headers {\n\t\ths[strings.ToLower(k)] = v\n\t}\n\n\treturn &fakeHttpResponse{statusCode, location, body, hs}\n}\n\nfunc newFakeHtmlResponse(location string, body string) *fakeHttpResponse {\n\treturn newFakeHttpResponse(\n\t\t200,\n\t\tlocation,\n\t\t[]byte(body),\n\t\tmap[string]string{\"content-type\": \"text/html\"},\n\t)\n}\n\nfunc newFakeXmlResponse(location string, body string) *fakeHttpResponse {\n\treturn newFakeHttpResponse(\n\t\t200,\n\t\tlocation,\n\t\t[]byte(body),\n\t\tmap[string]string{\"content-type\": \"application/xml\"},\n\t)\n}\n\nfunc (r *fakeHttpResponse) URL() string {\n\treturn r.location\n}\n\nfunc (r *fakeHttpResponse) StatusCode() int {\n\treturn r.statusCode\n}\n\nfunc (r *fakeHttpResponse) Header(name string) string {\n\tif v, ok := r.headers[strings.ToLower(name)]; ok {\n\t\treturn v\n\t}\n\n\treturn \"\"\n}\n\nfunc (r *fakeHttpResponse) Body() ([]byte, error) {\n\treturn r.body, nil\n}\n"
        },
        {
          "name": "fasthttp_http_client.go",
          "type": "blob",
          "size": 1.1376953125,
          "content": "package main\n\nimport (\n\t\"net/http\"\n\t\"net/url\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/valyala/fasthttp\"\n)\n\ntype fasthttpHttpClient struct {\n\tclient  *fasthttp.Client\n\ttimeout time.Duration\n\theader  http.Header\n}\n\nfunc newFasthttpHttpClient(c *fasthttp.Client, timeout time.Duration, header http.Header) httpClient {\n\treturn &fasthttpHttpClient{c, timeout, header}\n}\n\nfunc (c *fasthttpHttpClient) Get(u *url.URL, header http.Header) (httpResponse, error) {\n\treq, res := fasthttp.Request{}, fasthttp.Response{}\n\treq.SetRequestURI(u.String())\n\treq.SetConnectionClose()\n\n\tfor k, vs := range c.header {\n\t\tfor _, v := range vs {\n\t\t\treq.Header.Add(k, v)\n\t\t}\n\t}\n\n\tfor k, vs := range header {\n\t\tfor _, v := range vs {\n\t\t\treq.Header.Add(k, v)\n\t\t}\n\t}\n\n\t// Some HTTP servers require \"Accept\" headers set explicitly.\n\tif !includeHeader(c.header, \"Accept\") {\n\t\treq.Header.Add(\"Accept\", \"*/*\")\n\t}\n\n\terr := c.client.DoTimeout(&req, &res, c.timeout)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn newFasthttpHttpResponse(req.URI(), &res), nil\n}\n\nfunc includeHeader(h http.Header, k string) bool {\n\tfor kk := range h {\n\t\tif strings.EqualFold(kk, k) {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}\n"
        },
        {
          "name": "fasthttp_http_client_factory.go",
          "type": "blob",
          "size": 1.3291015625,
          "content": "package main\n\nimport (\n\t\"context\"\n\t\"crypto/tls\"\n\t\"net\"\n\n\t\"github.com/valyala/fasthttp\"\n\t\"github.com/valyala/fasthttp/fasthttpproxy\"\n)\n\ntype fasthttpHttpClientFactory struct {\n}\n\nfunc newFasthttpHttpClientFactory() *fasthttpHttpClientFactory {\n\treturn &fasthttpHttpClientFactory{}\n}\n\nfunc (*fasthttpHttpClientFactory) Create(o httpClientOptions) httpClient {\n\td := func(address string) (net.Conn, error) {\n\t\treturn fasthttp.DialTimeout(address, tcpTimeout)\n\t}\n\n\tif o.Proxy != \"\" {\n\t\td = fasthttpproxy.FasthttpHTTPDialerTimeout(o.Proxy, tcpTimeout)\n\t} else if o.DnsResolver != \"\" {\n\t\tnd := &net.Dialer{}\n\t\ttd := &fasthttp.TCPDialer{\n\t\t\tConcurrency: concurrency,\n\t\t\tResolver: &net.Resolver{\n\t\t\t\tPreferGo: true,\n\t\t\t\tDial: func(ctx context.Context, network, address string) (net.Conn, error) {\n\t\t\t\t\treturn nd.DialContext(ctx, \"udp\", o.DnsResolver)\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\td = func(address string) (net.Conn, error) {\n\t\t\treturn td.DialTimeout(address, tcpTimeout)\n\t\t}\n\t}\n\n\treturn newFasthttpHttpClient(\n\t\t&fasthttp.Client{\n\t\t\tMaxConnsPerHost: o.MaxConnectionsPerHost,\n\t\t\tReadBufferSize:  o.BufferSize,\n\t\t\tTLSConfig: &tls.Config{\n\t\t\t\tInsecureSkipVerify: o.SkipTLSVerification,\n\t\t\t},\n\t\t\tDial:                     d,\n\t\t\tDisablePathNormalizing:   true,\n\t\t\tNoDefaultUserAgentHeader: true,\n\t\t\tMaxResponseBodySize:      o.MaxResponseBodySize,\n\t\t},\n\t\to.Timeout,\n\t\to.Header,\n\t)\n}\n"
        },
        {
          "name": "fasthttp_http_client_factory_test.go",
          "type": "blob",
          "size": 0.447265625,
          "content": "package main\n\nimport \"testing\"\n\nfunc TestFasthttpHttpClientFactoryCreate(t *testing.T) {\n\tnewFasthttpHttpClientFactory().Create(httpClientOptions{})\n}\n\nfunc TestFasthttpHttpClientFactoryCreateWithProxy(t *testing.T) {\n\tnewFasthttpHttpClientFactory().Create(httpClientOptions{Proxy: \"foo\"})\n}\n\nfunc TestFasthttpHttpClientFactoryCreateWithCustomDnsResolver(t *testing.T) {\n\tnewFasthttpHttpClientFactory().Create(httpClientOptions{DnsResolver: \"1.1.1.1:53\"})\n}\n"
        },
        {
          "name": "fasthttp_http_response.go",
          "type": "blob",
          "size": 0.8076171875,
          "content": "package main\n\nimport (\n\t\"github.com/valyala/fasthttp\"\n)\n\ntype fasthttpHttpResponse struct {\n\turl      *fasthttp.URI\n\tresponse *fasthttp.Response\n}\n\nfunc newFasthttpHttpResponse(u *fasthttp.URI, r *fasthttp.Response) httpResponse {\n\treturn fasthttpHttpResponse{u, r}\n}\n\nfunc (r fasthttpHttpResponse) URL() string {\n\treturn r.url.String()\n}\n\nfunc (r fasthttpHttpResponse) StatusCode() int {\n\treturn r.response.StatusCode()\n}\n\nfunc (r fasthttpHttpResponse) Header(key string) string {\n\treturn string(r.response.Header.Peek(key))\n}\n\nfunc (r fasthttpHttpResponse) Body() ([]byte, error) {\n\tswitch string(r.response.Header.Peek(\"Content-Encoding\")) {\n\tcase \"gzip\":\n\t\treturn r.response.BodyGunzip()\n\tcase \"deflate\":\n\t\treturn r.response.BodyInflate()\n\tcase \"br\":\n\t\treturn r.response.BodyUnbrotli()\n\t}\n\n\treturn r.response.Body(), nil\n}\n"
        },
        {
          "name": "fasthttp_http_response_test.go",
          "type": "blob",
          "size": 1.3486328125,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"compress/zlib\"\n\t\"testing\"\n\n\t\"github.com/andybalholm/brotli\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/valyala/fasthttp\"\n)\n\nfunc TestFastHttpResponseDecodeGzipBody(t *testing.T) {\n\tb := bytes.Buffer{}\n\tw := gzip.NewWriter(&b)\n\t_, err := w.Write([]byte(\"foo\"))\n\tassert.Nil(t, err)\n\terr = w.Close()\n\tassert.Nil(t, err)\n\n\tr := fasthttp.Response{}\n\tr.Header.Add(\"Content-Encoding\", \"gzip\")\n\tr.SetBody(b.Bytes())\n\n\tbs, err := newFasthttpHttpResponse(nil, &r).Body()\n\n\tassert.Nil(t, err)\n\tassert.Equal(t, \"foo\", string(bs))\n}\n\nfunc TestFastHttpResponseDecodeDeflateBody(t *testing.T) {\n\tb := bytes.Buffer{}\n\tw := zlib.NewWriter(&b)\n\t_, err := w.Write([]byte(\"foo\"))\n\tassert.Nil(t, err)\n\terr = w.Close()\n\tassert.Nil(t, err)\n\n\tr := fasthttp.Response{}\n\tr.Header.Add(\"Content-Encoding\", \"deflate\")\n\tr.SetBody(b.Bytes())\n\n\tbs, err := newFasthttpHttpResponse(nil, &r).Body()\n\n\tassert.Nil(t, err)\n\tassert.Equal(t, \"foo\", string(bs))\n}\n\nfunc TestFastHttpResponseDecodeBrotliBody(t *testing.T) {\n\tb := bytes.Buffer{}\n\tw := brotli.NewWriter(&b)\n\t_, err := w.Write([]byte(\"foo\"))\n\tassert.Nil(t, err)\n\terr = w.Close()\n\tassert.Nil(t, err)\n\n\tr := fasthttp.Response{}\n\tr.Header.Add(\"Content-Encoding\", \"br\")\n\tr.SetBody(b.Bytes())\n\n\tbs, err := newFasthttpHttpResponse(nil, &r).Body()\n\n\tassert.Nil(t, err)\n\tassert.Equal(t, \"foo\", string(bs))\n}\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 1.1357421875,
          "content": "module github.com/raviqqe/muffet/v2\n\ngo 1.22.0\n\nrequire (\n\tgithub.com/andybalholm/brotli v1.1.1\n\tgithub.com/bradleyjkemp/cupaloy v2.3.0+incompatible\n\tgithub.com/jessevdk/go-flags v1.6.1\n\tgithub.com/logrusorgru/aurora/v3 v3.0.0\n\tgithub.com/mattn/go-colorable v0.1.14\n\tgithub.com/mattn/go-isatty v0.0.20\n\tgithub.com/oxffaa/gopher-parse-sitemap v0.0.0-20191021113419-005d2eb1def4\n\tgithub.com/stretchr/testify v1.10.0\n\tgithub.com/temoto/robotstxt v1.1.2\n\tgithub.com/valyala/fasthttp v1.58.0\n\tgithub.com/yhat/scrape v0.0.0-20161128144610-24b7890b0945\n\tgo.uber.org/ratelimit v0.3.1\n\tgolang.org/x/net v0.34.0\n)\n\nrequire (\n\tgithub.com/benbjohnson/clock v1.3.0 // indirect\n\tgithub.com/davecgh/go-spew v1.1.1 // indirect\n\tgithub.com/klauspost/compress v1.17.11 // indirect\n\tgithub.com/kr/text v0.2.0 // indirect\n\tgithub.com/niemeyer/pretty v0.0.0-20200227124842-a10e7caefd8e // indirect\n\tgithub.com/pmezard/go-difflib v1.0.0 // indirect\n\tgithub.com/valyala/bytebufferpool v1.0.0 // indirect\n\tgolang.org/x/sys v0.29.0 // indirect\n\tgolang.org/x/text v0.21.0 // indirect\n\tgopkg.in/check.v1 v1.0.0-20200227125254-8fa46927fb4f // indirect\n\tgopkg.in/yaml.v3 v3.0.1 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 5.248046875,
          "content": "github.com/andybalholm/brotli v1.1.1 h1:PR2pgnyFznKEugtsUo0xLdDop5SKXd5Qf5ysW+7XdTA=\ngithub.com/andybalholm/brotli v1.1.1/go.mod h1:05ib4cKhjx3OQYUY22hTVd34Bc8upXjOLL2rKwwZBoA=\ngithub.com/benbjohnson/clock v1.3.0 h1:ip6w0uFQkncKQ979AypyG0ER7mqUSBdKLOgAle/AT8A=\ngithub.com/benbjohnson/clock v1.3.0/go.mod h1:J11/hYXuz8f4ySSvYwY0FKfm+ezbsZBKZxNJlLklBHA=\ngithub.com/bradleyjkemp/cupaloy v2.3.0+incompatible h1:UafIjBvWQmS9i/xRg+CamMrnLTKNzo+bdmT/oH34c2Y=\ngithub.com/bradleyjkemp/cupaloy v2.3.0+incompatible/go.mod h1:Au1Xw1sgaJ5iSFktEhYsS0dbQiS1B0/XMXl+42y9Ilk=\ngithub.com/creack/pty v1.1.9/go.mod h1:oKZEueFk5CKHvIhNR5MUki03XCEU+Q6VDXinZuGJ33E=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/jessevdk/go-flags v1.6.1 h1:Cvu5U8UGrLay1rZfv/zP7iLpSHGUZ/Ou68T0iX1bBK4=\ngithub.com/jessevdk/go-flags v1.6.1/go.mod h1:Mk8T1hIAWpOiJiHa9rJASDK2UGWji0EuPGBnNLMooyc=\ngithub.com/klauspost/compress v1.17.11 h1:In6xLpyWOi1+C7tXUUWv2ot1QvBjxevKAaI6IXrJmUc=\ngithub.com/klauspost/compress v1.17.11/go.mod h1:pMDklpSncoRMuLFrf1W9Ss9KT+0rH90U12bZKk7uwG0=\ngithub.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=\ngithub.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=\ngithub.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=\ngithub.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=\ngithub.com/logrusorgru/aurora/v3 v3.0.0 h1:R6zcoZZbvVcGMvDCKo45A9U/lzYyzl5NfYIvznmDfE4=\ngithub.com/logrusorgru/aurora/v3 v3.0.0/go.mod h1:vsR12bk5grlLvLXAYrBsb5Oc/N+LxAlxggSjiwMnCUc=\ngithub.com/mattn/go-colorable v0.1.14 h1:9A9LHSqF/7dyVVX6g0U9cwm9pG3kP9gSzcuIPHPsaIE=\ngithub.com/mattn/go-colorable v0.1.14/go.mod h1:6LmQG8QLFO4G5z1gPvYEzlUgJ2wF+stgPZH1UqBm1s8=\ngithub.com/mattn/go-isatty v0.0.20 h1:xfD0iDuEKnDkl03q4limB+vH+GxLEtL/jb4xVJSWWEY=\ngithub.com/mattn/go-isatty v0.0.20/go.mod h1:W+V8PltTTMOvKvAeJH7IuucS94S2C6jfK/D7dTCTo3Y=\ngithub.com/niemeyer/pretty v0.0.0-20200227124842-a10e7caefd8e h1:fD57ERR4JtEqsWbfPhv4DMiApHyliiK5xCTNVSPiaAs=\ngithub.com/niemeyer/pretty v0.0.0-20200227124842-a10e7caefd8e/go.mod h1:zD1mROLANZcx1PVRCS0qkT7pwLkGfwJo4zjcN/Tysno=\ngithub.com/oxffaa/gopher-parse-sitemap v0.0.0-20191021113419-005d2eb1def4 h1:2vmb32OdDhjZf2ETGDlr9n8RYXx7c+jXPxMiPbwnA+8=\ngithub.com/oxffaa/gopher-parse-sitemap v0.0.0-20191021113419-005d2eb1def4/go.mod h1:2JQx4jDHmWrbABvpOayg/+OTU6ehN0IyK2EHzceXpJo=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/testify v1.3.0/go.mod h1:M5WIy9Dh21IEIfnGCwXGc5bZfKNJtfHm1UVUgZn+9EI=\ngithub.com/stretchr/testify v1.10.0 h1:Xv5erBjTwe/5IxqUQTdXv5kgmIvbHo3QQyRwhJsOfJA=\ngithub.com/stretchr/testify v1.10.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=\ngithub.com/temoto/robotstxt v1.1.2 h1:W2pOjSJ6SWvldyEuiFXNxz3xZ8aiWX5LbfDiOFd7Fxg=\ngithub.com/temoto/robotstxt v1.1.2/go.mod h1:+1AmkuG3IYkh1kv0d2qEB9Le88ehNO0zwOr3ujewlOo=\ngithub.com/valyala/bytebufferpool v1.0.0 h1:GqA5TC/0021Y/b9FG4Oi9Mr3q7XYx6KllzawFIhcdPw=\ngithub.com/valyala/bytebufferpool v1.0.0/go.mod h1:6bBcMArwyJ5K/AmCkWv1jt77kVWyCJ6HpOuEn7z0Csc=\ngithub.com/valyala/fasthttp v1.58.0 h1:GGB2dWxSbEprU9j0iMJHgdKYJVDyjrOwF9RE59PbRuE=\ngithub.com/valyala/fasthttp v1.58.0/go.mod h1:SYXvHHaFp7QZHGKSHmoMipInhrI5StHrhDTYVEjK/Kw=\ngithub.com/xyproto/randomstring v1.0.5 h1:YtlWPoRdgMu3NZtP45drfy1GKoojuR7hmRcnhZqKjWU=\ngithub.com/xyproto/randomstring v1.0.5/go.mod h1:rgmS5DeNXLivK7YprL0pY+lTuhNQW3iGxZ18UQApw/E=\ngithub.com/yhat/scrape v0.0.0-20161128144610-24b7890b0945 h1:6Ju8pZBYFTN9FaV/JvNBiIHcsgEmP4z4laciqjfjY8E=\ngithub.com/yhat/scrape v0.0.0-20161128144610-24b7890b0945/go.mod h1:4vRFPPNYllgCacoj+0FoKOjTW68rUhEfqPLiEJaK2w8=\ngo.uber.org/atomic v1.7.0 h1:ADUqmZGgLDDfbSL9ZmPxKTybcoEYHgpYfELNoN+7hsw=\ngo.uber.org/atomic v1.7.0/go.mod h1:fEN4uk6kAWBTFdckzkM89CLk9XfWZrxpCo0nPH17wJc=\ngo.uber.org/ratelimit v0.3.1 h1:K4qVE+byfv/B3tC+4nYWP7v/6SimcO7HzHekoMNBma0=\ngo.uber.org/ratelimit v0.3.1/go.mod h1:6euWsTB6U/Nb3X++xEUXA8ciPJvr19Q/0h1+oDcJhRk=\ngolang.org/x/net v0.34.0 h1:Mb7Mrk043xzHgnRM88suvJFwzVrRfHEHJEl5/71CKw0=\ngolang.org/x/net v0.34.0/go.mod h1:di0qlW3YNM5oh6GqDGQr92MyTozJPmybPK4Ev/Gm31k=\ngolang.org/x/sys v0.6.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.29.0 h1:TPYlXGxvx1MGTn2GiZDhnjPA9wZzZeGKHHmKhHYvgaU=\ngolang.org/x/sys v0.29.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/text v0.21.0 h1:zyQAAkrwaneQ066sspRyJaG9VNi/YJ1NfzcGB3hZ/qo=\ngolang.org/x/text v0.21.0/go.mod h1:4IBbMaMmOPCJ8SecivzSH54+73PCFmPWxNTLm+vZkEQ=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20200227125254-8fa46927fb4f h1:BLraFXnmrev5lT+xlilqcH8XK9/i0At2xKjWk4p6zsU=\ngopkg.in/check.v1 v1.0.0-20200227125254-8fa46927fb4f/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\n"
        },
        {
          "name": "host_throttler.go",
          "type": "blob",
          "size": 0.5146484375,
          "content": "package main\n\nimport \"go.uber.org/ratelimit\"\n\ntype hostThrottler struct {\n\tlimiter     ratelimit.Limiter\n\tconnections semaphore\n}\n\nfunc newHostThrottler(requestPerSecond, maxConnectionsPerHost int) *hostThrottler {\n\tl := ratelimit.NewUnlimited()\n\n\tif requestPerSecond > 0 {\n\t\tl = ratelimit.New(requestPerSecond)\n\t}\n\n\treturn &hostThrottler{l, newSemaphore(maxConnectionsPerHost)}\n}\n\nfunc (t *hostThrottler) Request() {\n\tt.connections.Request()\n\tt.limiter.Take()\n}\n\nfunc (t *hostThrottler) Release() {\n\tt.connections.Release()\n}\n"
        },
        {
          "name": "host_throttler_pool.go",
          "type": "blob",
          "size": 0.54296875,
          "content": "package main\n\nimport \"sync\"\n\ntype hostThrottlerPool struct {\n\trequestPerSecond, maxConnectionsPerHost int\n\thostMap                                 sync.Map\n}\n\nfunc newHostThrottlerPool(requestPerSecond, maxConnectionsPerHost int) *hostThrottlerPool {\n\treturn &hostThrottlerPool{requestPerSecond, maxConnectionsPerHost, sync.Map{}}\n}\n\nfunc (p *hostThrottlerPool) Get(name string) *hostThrottler {\n\tt := newHostThrottler(p.requestPerSecond, p.maxConnectionsPerHost)\n\tx, ok := p.hostMap.LoadOrStore(name, t)\n\n\tif ok {\n\t\tt = x.(*hostThrottler)\n\t}\n\n\treturn t\n}\n"
        },
        {
          "name": "host_throttler_pool_test.go",
          "type": "blob",
          "size": 0.82421875,
          "content": "package main\n\nimport (\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestNewHostThrottlerPool(t *testing.T) {\n\tnewHostThrottlerPool(1, 1)\n}\n\nfunc TestHostThrottlerPoolGetHost(t *testing.T) {\n\tc := make(chan struct{}, 100)\n\ts := newHostThrottlerPool(1000000, 1)\n\n\tfor i := 0; i < 2; i++ {\n\t\tgo func() {\n\t\t\ts.Get(\"foo\").Request()\n\t\t\tc <- struct{}{}\n\t\t}()\n\t}\n\n\t<-c\n\n\tassert.Equal(t, 0, len(c))\n\n\ts.Get(\"foo\").Release()\n\t<-c\n}\n\nfunc TestHostThrottlerPoolGetHosts(t *testing.T) {\n\thosts := []string{\"foo\", \"bar\"}\n\tc := make(chan struct{}, 100)\n\ts := newHostThrottlerPool(1000000, 1)\n\n\tfor _, host := range hosts {\n\t\tfor i := 0; i < 2; i++ {\n\t\t\tgo func(host string) {\n\t\t\t\ts.Get(host).Request()\n\t\t\t\tc <- struct{}{}\n\t\t\t}(host)\n\t\t}\n\t}\n\n\t<-c\n\t<-c\n\n\tassert.Equal(t, 0, len(c))\n\n\tfor _, host := range hosts {\n\t\ts.Get(host).Release()\n\t\t<-c\n\t}\n}\n"
        },
        {
          "name": "host_throttler_test.go",
          "type": "blob",
          "size": 0.3876953125,
          "content": "package main\n\nimport (\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestNewHostThrottler(t *testing.T) {\n\tnewHostThrottler(1, 1)\n}\n\nfunc TestHostThrottlerRequest(t *testing.T) {\n\tc := make(chan struct{}, 100)\n\ts := newHostThrottler(1000000, 1)\n\n\tfor i := 0; i < 2; i++ {\n\t\tgo func() {\n\t\t\ts.Request()\n\t\t\tc <- struct{}{}\n\t\t}()\n\t}\n\n\t<-c\n\n\tassert.Equal(t, 0, len(c))\n\n\ts.Release()\n\t<-c\n}\n"
        },
        {
          "name": "html_page.go",
          "type": "blob",
          "size": 0.4619140625,
          "content": "package main\n\nimport (\n\t\"net/url\"\n)\n\ntype htmlPage struct {\n\turl       *url.URL\n\tfragments map[string]struct{}\n\tlinks     map[string]error\n}\n\nfunc newHtmlPage(u *url.URL, fragments map[string]struct{}, links map[string]error) *htmlPage {\n\treturn &htmlPage{u, fragments, links}\n}\n\nfunc (p *htmlPage) URL() *url.URL {\n\treturn p.url\n}\n\nfunc (p *htmlPage) Fragments() map[string]struct{} {\n\treturn p.fragments\n}\n\nfunc (p *htmlPage) Links() map[string]error {\n\treturn p.links\n}\n"
        },
        {
          "name": "html_page_parser.go",
          "type": "blob",
          "size": 0.9951171875,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"net/url\"\n\n\t\"github.com/yhat/scrape\"\n\t\"golang.org/x/net/html\"\n\t\"golang.org/x/net/html/atom\"\n)\n\ntype htmlPageParser struct {\n\tlinkFinder linkFinder\n}\n\nfunc newHtmlPageParser(f linkFinder) *htmlPageParser {\n\treturn &htmlPageParser{f}\n}\n\nfunc (p htmlPageParser) Parse(u *url.URL, typ string, body []byte) (page, error) {\n\tif typ != \"text/html\" {\n\t\treturn nil, nil\n\t}\n\n\tn, err := html.Parse(bytes.NewReader(body))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tu.Fragment = \"\"\n\n\tfrs := map[string]struct{}{}\n\n\tscrape.FindAllNested(n, func(n *html.Node) bool {\n\t\tfor _, a := range []string{\"id\", \"name\"} {\n\t\t\tif s := scrape.Attr(n, a); s != \"\" {\n\t\t\t\tfrs[s] = struct{}{}\n\t\t\t}\n\t\t}\n\n\t\treturn false\n\t})\n\n\tbase := u\n\n\tif n, ok := scrape.Find(n, func(n *html.Node) bool {\n\t\treturn n.DataAtom == atom.Base\n\t}); ok {\n\t\tu, err := url.Parse(scrape.Attr(n, \"href\"))\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tbase = base.ResolveReference(u)\n\t}\n\n\treturn newHtmlPage(u, frs, p.linkFinder.Find(n, base)), nil\n}\n"
        },
        {
          "name": "html_page_parser_test.go",
          "type": "blob",
          "size": 3.4970703125,
          "content": "package main\n\nimport (\n\t\"net/url\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nconst HTML_MIME_TYPE = \"text/html\"\n\nfunc parseURL(t *testing.T, s string) *url.URL {\n\tu, err := url.Parse(s)\n\n\tassert.Nil(t, err)\n\n\treturn u\n}\n\nfunc TestHtmlPageParserParsePage(t *testing.T) {\n\t_, err := newHtmlPageParser(newTestLinkFinder()).Parse(parseURL(t, \"http://foo.com\"), HTML_MIME_TYPE, nil)\n\tassert.Nil(t, err)\n}\n\nfunc TestHtmlPageParserSetCorrectURL(t *testing.T) {\n\tu := parseURL(t, \"http://foo.com\")\n\n\tp, err := newHtmlPageParser(newTestLinkFinder()).Parse(u, HTML_MIME_TYPE, nil)\n\tassert.Nil(t, err)\n\tassert.Equal(t, u.String(), p.URL().String())\n}\n\nfunc TestHtmlPageParserIgnorePageURLFragment(t *testing.T) {\n\tp, err := newHtmlPageParser(newTestLinkFinder()).Parse(parseURL(t, \"http://foo.com#id\"), HTML_MIME_TYPE, nil)\n\tassert.Nil(t, err)\n\tassert.Equal(t, \"http://foo.com\", p.URL().String())\n}\n\nfunc TestHtmlPageParserKeepQuery(t *testing.T) {\n\ts := \"http://foo.com?bar=baz\"\n\n\tp, err := newHtmlPageParser(newTestLinkFinder()).Parse(parseURL(t, s), HTML_MIME_TYPE, nil)\n\tassert.Nil(t, err)\n\tassert.Equal(t, s, p.URL().String())\n}\n\nfunc TestHtmlPageParserResolveLinksWithBaseTag(t *testing.T) {\n\tp, err := newHtmlPageParser(newTestLinkFinder()).Parse(\n\t\tparseURL(t, \"http://foo.com\"),\n\t\tHTML_MIME_TYPE,\n\t\t[]byte(`\n\t\t\t<html>\n\t\t\t  <head>\n\t\t\t\t\t<base href=\"foo/\" />\n\t\t\t\t</head>\n\t\t\t\t<body>\n\t\t\t\t  <a href=\"bar\" />\n\t\t\t\t</body>\n\t\t\t</html>\n\t\t`),\n\t)\n\tassert.Nil(t, err)\n\tassert.Equal(t, map[string]error{\"http://foo.com/foo/bar\": nil}, p.Links())\n}\n\nfunc TestHtmlPageParserResolveLinksWithBlankBaseTag(t *testing.T) {\n\tp, err := newHtmlPageParser(newTestLinkFinder()).Parse(\n\t\tparseURL(t, \"http://foo.com\"),\n\t\tHTML_MIME_TYPE,\n\t\t[]byte(`\n\t\t\t<html>\n\t\t\t  <head>\n\t\t\t\t\t<base href=\"_blank\" />\n\t\t\t\t</head>\n\t\t\t\t<body>\n\t\t\t\t  <a href=\"bar\" />\n\t\t\t\t</body>\n\t\t\t</html>\n\t\t`),\n\t)\n\tassert.Nil(t, err)\n\tassert.Equal(t, map[string]error{\"http://foo.com/bar\": nil}, p.Links())\n}\n\nfunc TestHtmlPageParserFailToParseWithInvalidBaseTag(t *testing.T) {\n\t_, err := newHtmlPageParser(newTestLinkFinder()).Parse(\n\t\tparseURL(t, \"http://foo.com\"),\n\t\tHTML_MIME_TYPE,\n\t\t[]byte(`\n\t\t\t<html>\n\t\t\t  <head>\n\t\t\t\t\t<base href=\":\" />\n\t\t\t\t</head>\n\t\t\t\t<body>\n\t\t\t\t</body>\n\t\t\t</html>\n\t\t`),\n\t)\n\tassert.NotNil(t, err)\n}\n\nfunc TestHtmlPageParserParseID(t *testing.T) {\n\tp, err := newHtmlPageParser(newTestLinkFinder()).Parse(\n\t\tparseURL(t, \"http://foo.com\"),\n\t\tHTML_MIME_TYPE,\n\t\t[]byte(`<p id=\"foo\" />`),\n\t)\n\tassert.Nil(t, err)\n\tassert.Equal(t, map[string]struct{}{\"foo\": {}}, p.Fragments())\n}\n\nfunc TestHtmlPageParserParseName(t *testing.T) {\n\tp, err := newHtmlPageParser(newTestLinkFinder()).Parse(\n\t\tparseURL(t, \"http://foo.com\"),\n\t\tHTML_MIME_TYPE,\n\t\t[]byte(`<p name=\"foo\" />`),\n\t)\n\tassert.Nil(t, err)\n\tassert.Equal(t, map[string]struct{}{\"foo\": {}}, p.Fragments())\n}\n\nfunc TestHtmlPageParserParseIDAndName(t *testing.T) {\n\tp, err := newHtmlPageParser(newTestLinkFinder()).Parse(\n\t\tparseURL(t, \"http://foo.com\"),\n\t\tHTML_MIME_TYPE,\n\t\t[]byte(`<p id=\"foo\" name=\"bar\" />`),\n\t)\n\tassert.Nil(t, err)\n\tassert.Equal(t, map[string]struct{}{\"foo\": {}, \"bar\": {}}, p.Fragments())\n}\n\nfunc TestHtmlPageParserParseLinks(t *testing.T) {\n\tfor _, ss := range [][2]string{\n\t\t{\n\t\t\t`<a href=\"foo\">bar</a>`,\n\t\t\t\"http://foo.com/foo\",\n\t\t},\n\t\t{\n\t\t\t`<img src=\"foo.img\" />`,\n\t\t\t\"http://foo.com/foo.img\",\n\t\t},\n\t} {\n\t\tp, err := newHtmlPageParser(newTestLinkFinder()).Parse(\n\t\t\tparseURL(t, \"http://foo.com\"),\n\t\t\tHTML_MIME_TYPE,\n\t\t\t[]byte(ss[0]),\n\t\t)\n\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, 1, len(p.Links()))\n\t\t_, ok := p.Links()[ss[1]]\n\t\tassert.True(t, ok)\n\t}\n}\n"
        },
        {
          "name": "http_client.go",
          "type": "blob",
          "size": 0.2607421875,
          "content": "package main\n\nimport (\n\t\"net/http\"\n\t\"net/url\"\n)\n\ntype httpClient interface {\n\t// Get sends an HTTP request with a GET method.\n\t// It depends on implementation of each client what is considered as errors.\n\tGet(url *url.URL, header http.Header) (httpResponse, error)\n}\n"
        },
        {
          "name": "http_client_factory.go",
          "type": "blob",
          "size": 0.359375,
          "content": "package main\n\nimport (\n\t\"net/http\"\n\t\"time\"\n)\n\ntype httpClientOptions struct {\n\tMaxConnectionsPerHost,\n\tMaxResponseBodySize,\n\tBufferSize int\n\tProxy               string\n\tSkipTLSVerification bool\n\tTimeout             time.Duration\n\tHeader              http.Header\n\tDnsResolver         string\n}\n\ntype httpClientFactory interface {\n\tCreate(httpClientOptions) httpClient\n}\n"
        },
        {
          "name": "http_response.go",
          "type": "blob",
          "size": 0.1220703125,
          "content": "package main\n\ntype httpResponse interface {\n\tURL() string\n\tStatusCode() int\n\tHeader(string) string\n\tBody() ([]byte, error)\n}\n"
        },
        {
          "name": "img",
          "type": "tree",
          "content": null
        },
        {
          "name": "json_page_result.go",
          "type": "blob",
          "size": 0.7275390625,
          "content": "package main\n\ntype jsonPageResult struct {\n\tURL   string `json:\"url\"`\n\tLinks []any  `json:\"links\"`\n}\n\ntype jsonSuccessLinkResult struct {\n\tURL    string `json:\"url\"`\n\tStatus int    `json:\"status\"`\n}\n\ntype jsonErrorLinkResult struct {\n\tURL   string `json:\"url\"`\n\tError string `json:\"error\"`\n}\n\nfunc newJSONPageResult(r *pageResult, verbose bool) *jsonPageResult {\n\tc := len(r.ErrorLinkResults)\n\n\tif verbose {\n\t\tc += len(r.SuccessLinkResults)\n\t}\n\n\tls := make([]any, 0, c)\n\n\tif verbose {\n\t\tfor _, r := range r.SuccessLinkResults {\n\t\t\tls = append(ls, &jsonSuccessLinkResult{r.URL, r.StatusCode})\n\t\t}\n\t}\n\n\tfor _, r := range r.ErrorLinkResults {\n\t\tls = append(ls, &jsonErrorLinkResult{r.URL, r.Error.Error()})\n\t}\n\n\treturn &jsonPageResult{r.URL, ls}\n}\n"
        },
        {
          "name": "json_page_result_test.go",
          "type": "blob",
          "size": 0.986328125,
          "content": "package main\n\nimport (\n\t\"encoding/json\"\n\t\"errors\"\n\t\"testing\"\n\n\t\"github.com/bradleyjkemp/cupaloy\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestMarshalErrorJSONPageResult(t *testing.T) {\n\tbs, err := json.Marshal(newJSONPageResult(\n\t\t&pageResult{\n\t\t\t\"http://foo.com\",\n\t\t\t[]*successLinkResult{},\n\t\t\t[]*errorLinkResult{\n\t\t\t\t{\"http://foo.com/bar\", errors.New(\"baz\")},\n\t\t\t},\n\t\t}, false))\n\tassert.Nil(t, err)\n\tcupaloy.SnapshotT(t, bs)\n}\n\nfunc TestMarshalSuccessJSONPageResult(t *testing.T) {\n\tbs, err := json.Marshal(newJSONPageResult(\n\t\t&pageResult{\n\t\t\t\"http://foo.com\",\n\t\t\t[]*successLinkResult{\n\t\t\t\t{\"http://foo.com/foo\", 200},\n\t\t\t},\n\t\t\t[]*errorLinkResult{},\n\t\t}, false))\n\tassert.Nil(t, err)\n\tcupaloy.SnapshotT(t, bs)\n}\n\nfunc TestMarshalVerboseSuccessJSONPageResult(t *testing.T) {\n\tbs, err := json.Marshal(newJSONPageResult(\n\t\t&pageResult{\n\t\t\t\"http://foo.com\",\n\t\t\t[]*successLinkResult{\n\t\t\t\t{\"http://foo.com/foo\", 200},\n\t\t\t},\n\t\t\t[]*errorLinkResult{},\n\t\t}, true))\n\tassert.Nil(t, err)\n\tcupaloy.SnapshotT(t, bs)\n}\n"
        },
        {
          "name": "link_fetcher.go",
          "type": "blob",
          "size": 2.1962890625,
          "content": "package main\n\nimport (\n\t\"fmt\"\n\t\"mime\"\n\t\"net/url\"\n\t\"strings\"\n)\n\ntype linkFetcher struct {\n\tclient      httpClient\n\tpageParsers []pageParser\n\tcache       cache\n\toptions     linkFetcherOptions\n}\n\ntype fetchResult struct {\n\tStatusCode int\n\tPage       page\n}\n\nfunc newLinkFetcher(c httpClient, ps []pageParser, o linkFetcherOptions) *linkFetcher {\n\treturn &linkFetcher{c, ps, newCache(), o}\n}\n\n// Fetch fetches a link and returns a successful status code and optionally HTML page, or an error.\nfunc (f *linkFetcher) Fetch(u string) (int, page, error) {\n\tu, fr, err := separateFragment(u)\n\tif err != nil {\n\t\treturn 0, nil, err\n\t}\n\n\ts, p, err := f.sendRequestWithCache(u)\n\tif err != nil {\n\t\treturn 0, nil, err\n\t} else if p == nil || f.options.IgnoreFragments || fr == \"\" || strings.HasPrefix(fr, \":~:\") {\n\t\t// TODO Support text fragments.\n\t\treturn s, p, nil\n\t} else if _, ok := p.Fragments()[fr]; !ok {\n\t\treturn 0, nil, fmt.Errorf(\"id #%v not found\", fr)\n\t}\n\n\treturn s, p, nil\n}\n\nfunc (f *linkFetcher) sendRequestWithCache(u string) (int, page, error) {\n\tx, store := f.cache.LoadOrStore(u)\n\n\tif store == nil {\n\t\tif err, ok := x.(error); ok {\n\t\t\treturn 0, nil, err\n\t\t}\n\n\t\tr := x.(fetchResult)\n\n\t\treturn r.StatusCode, r.Page, nil\n\t}\n\n\ts, p, err := f.sendRequest(u)\n\n\tif err == nil {\n\t\tstore(fetchResult{s, p})\n\t} else {\n\t\tstore(err)\n\t}\n\n\treturn s, p, err\n}\n\nfunc (f *linkFetcher) sendRequest(s string) (int, page, error) {\n\tu, err := url.Parse(s)\n\tif err != nil {\n\t\treturn 0, nil, err\n\t}\n\n\tr, err := f.client.Get(u, nil)\n\n\tif err != nil {\n\t\treturn 0, nil, err\n\t}\n\n\tt := \"\"\n\n\tif s := strings.TrimSpace(r.Header(\"Content-Type\")); s != \"\" {\n\t\tt, _, err = mime.ParseMediaType(s)\n\n\t\tif err != nil {\n\t\t\treturn 0, nil, err\n\t\t}\n\t}\n\n\tbs, err := r.Body()\n\tif err != nil {\n\t\treturn 0, nil, err\n\t}\n\n\tfor _, pp := range f.pageParsers {\n\t\tu, err := url.Parse(r.URL())\n\t\tif err != nil {\n\t\t\treturn 0, nil, err\n\t\t}\n\n\t\tp, err := pp.Parse(u, t, bs)\n\t\tif err != nil {\n\t\t\treturn 0, nil, err\n\t\t} else if p != nil {\n\t\t\treturn r.StatusCode(), p, nil\n\t\t}\n\t}\n\n\treturn r.StatusCode(), nil, nil\n}\n\nfunc separateFragment(s string) (string, string, error) {\n\tu, err := url.Parse(s)\n\tif err != nil {\n\t\treturn \"\", \"\", err\n\t}\n\n\tf := u.Fragment\n\tu.Fragment = \"\"\n\n\treturn u.String(), f, nil\n}\n"
        },
        {
          "name": "link_fetcher_options.go",
          "type": "blob",
          "size": 0.0693359375,
          "content": "package main\n\ntype linkFetcherOptions struct {\n\tIgnoreFragments bool\n}\n"
        },
        {
          "name": "link_fetcher_test.go",
          "type": "blob",
          "size": 5.66796875,
          "content": "package main\n\nimport (\n\t\"errors\"\n\t\"net/url\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc newTestLinkFetcher(c *fakeHttpClient) *linkFetcher {\n\treturn newTestLinkFetcherWithOptions(c, linkFetcherOptions{})\n}\n\nfunc newTestLinkFetcherWithOptions(c *fakeHttpClient, o linkFetcherOptions) *linkFetcher {\n\treturn newLinkFetcher(c, []pageParser{newSitemapPageParser(newTestLinkFilterer()), newHtmlPageParser(newTestLinkFinder())}, o)\n}\n\nfunc TestNewFetcher(t *testing.T) {\n\tnewTestLinkFetcher(newFakeHttpClient(nil))\n}\n\nfunc TestLinkFetcherFetch(t *testing.T) {\n\tf := newTestLinkFetcher(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\tif u.String() != \"http://foo.com\" {\n\t\t\t\t\treturn nil, errors.New(\"\")\n\t\t\t\t}\n\n\t\t\t\treturn newFakeHtmlResponse(\"http://foo.com\", \"\"), nil\n\t\t\t}),\n\t)\n\n\ts, p, err := f.Fetch(\"http://foo.com\")\n\n\tassert.Equal(t, 200, s)\n\tassert.NotNil(t, p)\n\tassert.Nil(t, err)\n}\n\nfunc TestLinkFetcherFetchFromCache(t *testing.T) {\n\tok := true\n\ts := \"http://foo.com\"\n\n\tf := newTestLinkFetcher(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\tif !ok {\n\t\t\t\t\treturn nil, errors.New(\"\")\n\t\t\t\t}\n\n\t\t\t\tok = false\n\n\t\t\t\treturn newFakeHtmlResponse(s, \"\"), nil\n\t\t\t}),\n\t)\n\n\tsc, p, err := f.Fetch(s)\n\tassert.Equal(t, 200, sc)\n\tassert.NotNil(t, p)\n\tassert.Nil(t, err)\n\n\tsc, p, err = f.Fetch(s)\n\tassert.Equal(t, 200, sc)\n\tassert.NotNil(t, p)\n\tassert.Nil(t, err)\n}\n\nfunc TestLinkFetcherFetchCacheConcurrency(t *testing.T) {\n\tc := 0\n\n\tf := newTestLinkFetcher(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\tc++\n\n\t\t\t\treturn newFakeHtmlResponse(\"http://foo.com\", \"\"), nil\n\t\t\t}),\n\t)\n\n\tg := &sync.WaitGroup{}\n\n\tfor i := 0; i < 1000; i++ {\n\t\tg.Add(1)\n\t\tgo func() {\n\t\t\tdefer g.Done()\n\n\t\t\ttime.Sleep(time.Millisecond)\n\n\t\t\t_, _, err := f.Fetch(\"http://foo.com\")\n\t\t\tassert.Nil(t, err)\n\t\t}()\n\t}\n\n\tg.Wait()\n\n\tassert.Equal(t, 1, c)\n}\n\nfunc TestLinkFetcherFetchWithFragments(t *testing.T) {\n\ts := \"http://foo.com\"\n\tf := newTestLinkFetcher(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\tif u.String() != s {\n\t\t\t\t\treturn nil, errors.New(\"\")\n\t\t\t\t}\n\n\t\t\t\treturn newFakeHtmlResponse(s, `<p id=\"foo\" />`), nil\n\t\t\t},\n\t\t),\n\t)\n\n\tsc, p, err := f.Fetch(s + \"#foo\")\n\n\tassert.Equal(t, 200, sc)\n\tassert.NotNil(t, p)\n\tassert.Nil(t, err)\n\n\t_, _, err = f.Fetch(s + \"#bar\")\n\n\tassert.Equal(t, \"id #bar not found\", err.Error())\n}\n\nfunc TestLinkFetcherFetchIgnoringFragments(t *testing.T) {\n\ts := \"http://foo.com\"\n\tf := newTestLinkFetcherWithOptions(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\tif u.String() != s {\n\t\t\t\t\treturn nil, errors.New(\"\")\n\t\t\t\t}\n\n\t\t\t\treturn newFakeHtmlResponse(s, \"\"), nil\n\t\t\t},\n\t\t),\n\t\tlinkFetcherOptions{IgnoreFragments: true},\n\t)\n\n\t_, _, err := f.Fetch(s + \"#bar\")\n\tassert.Nil(t, err)\n}\n\nfunc TestLinkFetcherFetchSkippingTextFragment(t *testing.T) {\n\ts := \"http://foo.com\"\n\tf := newTestLinkFetcher(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\tif u.String() != s {\n\t\t\t\t\treturn nil, errors.New(\"\")\n\t\t\t\t}\n\n\t\t\t\treturn newFakeHtmlResponse(s, \"\"), nil\n\t\t\t},\n\t\t),\n\t)\n\n\t_, _, err := f.Fetch(s + \"#:~:text=foo\")\n\tassert.Nil(t, err)\n}\n\nfunc TestLinkFetcherFetchSitemap(t *testing.T) {\n\tf := newTestLinkFetcher(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\tif u.String() != \"http://foo.com/sitemap.xml\" {\n\t\t\t\t\treturn nil, errors.New(\"\")\n\t\t\t\t}\n\n\t\t\t\treturn newFakeXmlResponse(\"http://foo.com/sitemap.xml\", `\n\t\t\t\t\t<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\t\t\t\t\t<urlset\n\t\t\t\t\t\txmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\"\n\t\t\t\t\t\txmlns:news=\"http://www.google.com/schemas/sitemap-news/0.9\"\n\t\t\t\t\t\txmlns:xhtml=\"http://www.w3.org/1999/xhtml\"\n\t\t\t\t\t\txmlns:image=\"http://www.google.com/schemas/sitemap-image/1.1\"\n\t\t\t\t\t\txmlns:video=\"http://www.google.com/schemas/sitemap-video/1.1\"\n\t\t\t\t\t>\n\t\t\t\t\t\t<url>\n\t\t\t\t\t\t\t<loc>https://foo.com/</loc>\n\t\t\t\t\t\t</url>\n\t\t\t\t\t</urlset>\n\t\t\t\t`), nil\n\t\t\t}),\n\t)\n\n\ts, p, err := f.Fetch(\"http://foo.com/sitemap.xml\")\n\n\tassert.Equal(t, 200, s)\n\tassert.NotNil(t, p)\n\tassert.Nil(t, err)\n\tassert.Equal(t, map[string]error{\"https://foo.com/\": nil}, p.Links())\n}\n\nfunc TestLinkFetcherFetchSitemapIndex(t *testing.T) {\n\tf := newTestLinkFetcher(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\tif u.String() != \"http://foo.com/sitemap-index.xml\" {\n\t\t\t\t\treturn nil, errors.New(\"\")\n\t\t\t\t}\n\n\t\t\t\treturn newFakeXmlResponse(\"http://foo.com/sitemap-index.xml\", `\n\t\t\t\t\t<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\t\t\t\t\t<sitemapindex xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n\t\t\t\t\t\t<sitemap>\n\t\t\t\t\t\t\t<loc>https://foo.com/sitemap-0.xml</loc>\n\t\t\t\t\t\t</sitemap>\n\t\t\t\t\t</sitemapindex>\n\t\t\t\t`), nil\n\t\t\t}),\n\t)\n\n\ts, p, err := f.Fetch(\"http://foo.com/sitemap-index.xml\")\n\n\tassert.Equal(t, 200, s)\n\tassert.NotNil(t, p)\n\tassert.Nil(t, err)\n\tassert.Equal(t, map[string]error{\"https://foo.com/sitemap-0.xml\": nil}, p.Links())\n}\n\nfunc TestLinkFetcherFailToFetch(t *testing.T) {\n\tf := newTestLinkFetcher(\n\t\tnewFakeHttpClient(func(*url.URL) (*fakeHttpResponse, error) {\n\t\t\treturn nil, errors.New(\"\")\n\t\t}))\n\n\t_, _, err := f.Fetch(\"http://foo.com\")\n\n\tassert.NotNil(t, err)\n}\n\nfunc TestLinkFetcherFailToParseURL(t *testing.T) {\n\tf := newTestLinkFetcher(\n\t\tnewFakeHttpClient(func(*url.URL) (*fakeHttpResponse, error) {\n\t\t\treturn newFakeHtmlResponse(\"\", \"\"), nil\n\t\t}))\n\n\t_, _, err := f.Fetch(\":\")\n\n\tassert.NotNil(t, err)\n}\n\nfunc TestSeparateFragment(t *testing.T) {\n\tfor _, ss := range [][3]string{\n\t\t{\"http://foo.com#bar\", \"http://foo.com\", \"bar\"},\n\t\t{\"#bar\", \"\", \"bar\"},\n\t} {\n\t\tu, id, err := separateFragment(ss[0])\n\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, ss[1], u)\n\t\tassert.Equal(t, ss[2], id)\n\t}\n}\n\nfunc TestFailToSeparateFragment(t *testing.T) {\n\t_, _, err := separateFragment(\":\")\n\n\tassert.NotNil(t, err)\n}\n"
        },
        {
          "name": "link_filterer.go",
          "type": "blob",
          "size": 0.9228515625,
          "content": "package main\n\nimport (\n\t\"net/url\"\n\t\"regexp\"\n)\n\nvar validSchemes = map[string]struct{}{\n\t\"\":      {},\n\t\"http\":  {},\n\t\"https\": {},\n}\n\ntype linkFilterer struct {\n\texcludedPatterns []*regexp.Regexp\n\tincludedPatterns []*regexp.Regexp\n}\n\nfunc newLinkFilterer(es []*regexp.Regexp, is []*regexp.Regexp) linkFilterer {\n\treturn linkFilterer{excludedPatterns: es, includedPatterns: is}\n}\n\nfunc (f linkFilterer) IsValid(u *url.URL) bool {\n\ts := u.String()\n\n\tif _, ok := validSchemes[u.Scheme]; !ok {\n\t\treturn false\n\t}\n\n\treturn !f.isLinkExcluded(s) && f.isLinkIncluded(s)\n}\n\nfunc (f linkFilterer) isLinkExcluded(u string) bool {\n\treturn f.matches(u, f.excludedPatterns)\n}\n\nfunc (f linkFilterer) isLinkIncluded(u string) bool {\n\treturn len(f.includedPatterns) == 0 || f.matches(u, f.includedPatterns)\n}\n\nfunc (f linkFilterer) matches(u string, rs []*regexp.Regexp) bool {\n\tfor _, r := range rs {\n\t\tif r.MatchString(u) {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}\n"
        },
        {
          "name": "link_filterer_test.go",
          "type": "blob",
          "size": 1.8662109375,
          "content": "package main\n\nimport (\n\t\"fmt\"\n\t\"net/url\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc newTestLinkFilterer() linkFilterer {\n\treturn newLinkFilterer(nil, nil)\n}\n\nfunc TestLinkFiltererIsLinkExcluded(t *testing.T) {\n\tu, err := url.Parse(\"http://foo.com\")\n\tassert.Nil(t, err)\n\n\tfor _, x := range []struct {\n\t\tregexps []string\n\t\tanswer  bool\n\t}{\n\t\t{\n\t\t\t[]string{\"foo\\\\.com\"},\n\t\t\tfalse,\n\t\t},\n\t\t{\n\t\t\t[]string{\"foo\"},\n\t\t\tfalse,\n\t\t},\n\t\t{\n\t\t\t[]string{\"bar\", \"foo\"},\n\t\t\tfalse,\n\t\t},\n\t\t{\n\t\t\t[]string{\"bar\"},\n\t\t\ttrue,\n\t\t},\n\t} {\n\t\tt.Run(fmt.Sprint(x.regexps), func(t *testing.T) {\n\t\t\trs, err := compileRegexps(x.regexps)\n\t\t\tassert.Nil(t, err)\n\n\t\t\tassert.Equal(t, x.answer, newLinkFilterer(rs, nil).IsValid(u))\n\t\t})\n\t}\n}\n\nfunc TestLinkFiltererIsLinkIncluded(t *testing.T) {\n\tu, err := url.Parse(\"http://foo.com\")\n\tassert.Nil(t, err)\n\n\tfor _, x := range []struct {\n\t\tregexps []string\n\t\tanswer  bool\n\t}{\n\t\t{\n\t\t\t[]string{\"foo\\\\.com\"},\n\t\t\ttrue,\n\t\t},\n\t\t{\n\t\t\t[]string{\"foo\"},\n\t\t\ttrue,\n\t\t},\n\t\t{\n\t\t\t[]string{\"bar\", \"foo\"},\n\t\t\ttrue,\n\t\t},\n\t\t{\n\t\t\t[]string{\"bar\"},\n\t\t\tfalse,\n\t\t},\n\t} {\n\t\tt.Run(fmt.Sprint(x.regexps), func(t *testing.T) {\n\t\t\trs, err := compileRegexps(x.regexps)\n\t\t\tassert.Nil(t, err)\n\n\t\t\tassert.Equal(t, x.answer, newLinkFilterer(nil, rs).IsValid(u))\n\t\t})\n\t}\n}\n\nfunc TestLinkFiltererExcludeEntireUrl(t *testing.T) {\n\tb, err := url.Parse(\"http://foo.com\")\n\tassert.Nil(t, err)\n\n\trs, err := compileRegexps([]string{\"foo\"})\n\tassert.Nil(t, err)\n\n\tassert.False(t, newLinkFilterer(rs, nil).IsValid(b))\n}\n\nfunc TestLinkFiltererIncludeEntireUrl(t *testing.T) {\n\tb, err := url.Parse(\"http://foo.com\")\n\tassert.Nil(t, err)\n\n\trs, err := compileRegexps([]string{\"foo\"})\n\tassert.Nil(t, err)\n\n\tassert.True(t, newLinkFilterer(nil, rs).IsValid(b))\n}\n\nfunc TestLinkFiltererExcludeInvalidScheme(t *testing.T) {\n\tb, err := url.Parse(\"mailto:foo@bar.baz\")\n\tassert.Nil(t, err)\n\n\tassert.False(t, newLinkFilterer(nil, nil).IsValid(b))\n}\n"
        },
        {
          "name": "link_finder.go",
          "type": "blob",
          "size": 2.103515625,
          "content": "package main\n\nimport (\n\t\"net/url\"\n\t\"regexp\"\n\t\"strings\"\n\t\"unicode\"\n\n\t\"github.com/yhat/scrape\"\n\t\"golang.org/x/net/html\"\n\t\"golang.org/x/net/html/atom\"\n)\n\nvar atomToAttributes = map[atom.Atom][]string{\n\tatom.A:      {\"href\"},\n\tatom.Frame:  {\"src\"},\n\tatom.Iframe: {\"src\"},\n\tatom.Img:    {\"src\"},\n\tatom.Link:   {\"href\"},\n\tatom.Script: {\"src\"},\n\tatom.Source: {\"src\", \"srcset\"},\n\tatom.Track:  {\"src\"},\n\tatom.Meta:   {\"content\"},\n}\n\nvar imageDescriptorPattern = regexp.MustCompile(`(\\S)\\s+\\S+\\s*$`)\n\ntype linkFinder struct {\n\tlinkFilterer linkFilterer\n}\n\nfunc newLinkFinder(f linkFilterer) linkFinder {\n\treturn linkFinder{f}\n}\n\nfunc (f linkFinder) Find(n *html.Node, base *url.URL) map[string]error {\n\tls := map[string]error{}\n\n\tfor _, n := range scrape.FindAllNested(n, func(n *html.Node) bool {\n\t\t_, ok := atomToAttributes[n.DataAtom]\n\t\treturn ok\n\t}) {\n\n\t\t// `preconnect` and `dns-prefetch` links are not HTTP resources.\n\t\tif n.DataAtom == atom.Link {\n\n\t\t\tif rel := scrape.Attr(n, \"rel\"); rel == \"preconnect\" || rel == \"dns-prefetch\" {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tfor _, a := range atomToAttributes[n.DataAtom] {\n\t\t\tss := f.parseLinks(n, a)\n\n\t\t\tfor _, s := range ss {\n\t\t\t\ts := f.trimUrl(s)\n\n\t\t\t\tif s == \"\" {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tu, err := url.Parse(s)\n\t\t\t\tif err != nil {\n\t\t\t\t\tls[s] = err\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tu = base.ResolveReference(u)\n\n\t\t\t\tif f.linkFilterer.IsValid(u) {\n\t\t\t\t\tls[u.String()] = nil\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn ls\n}\n\nfunc (f linkFinder) parseLinks(n *html.Node, a string) []string {\n\ts := scrape.Attr(n, a)\n\tss := []string{}\n\n\tswitch a {\n\tcase \"srcset\":\n\t\tfor _, s := range strings.Split(s, \",\") {\n\t\t\tss = append(ss, f.trimUrl(imageDescriptorPattern.ReplaceAllString(s, \"$1\")))\n\t\t}\n\tcase \"content\":\n\t\tswitch scrape.Attr(n, \"property\") {\n\t\tcase \"og:image\", \"og:audio\", \"og:video\", \"og:image:url\", \"og:image:secure_url\", \"twitter:image\":\n\t\t\tss = append(ss, s)\n\t\t}\n\tdefault:\n\t\tss = append(ss, s)\n\t}\n\n\treturn ss\n}\n\nfunc (linkFinder) trimUrl(s string) string {\n\ts = strings.TrimSpace(s)\n\n\tif !strings.HasPrefix(s, \"data:\") {\n\t\treturn s\n\t}\n\n\treturn strings.Map(func(r rune) rune {\n\t\tif unicode.IsSpace(r) {\n\t\t\treturn -1\n\t\t}\n\n\t\treturn r\n\t}, s)\n}\n"
        },
        {
          "name": "link_finder_test.go",
          "type": "blob",
          "size": 5.6171875,
          "content": "package main\n\nimport (\n\t\"fmt\"\n\t\"net/url\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n\t\"golang.org/x/net/html\"\n)\n\nfunc newTestLinkFinder() linkFinder {\n\treturn newLinkFinder(newTestLinkFilterer())\n}\n\nfunc TestLinkFinderFindLinks(t *testing.T) {\n\tb, err := url.Parse(\"https://localhost\")\n\tassert.Nil(t, err)\n\n\tfor _, c := range []struct {\n\t\thtml      string\n\t\tlinkCount int\n\t}{\n\t\t{``, 0},\n\t\t{`<a href=\"\" />`, 0},\n\t\t{`<a href=\"/\" />`, 1},\n\t\t{`<a href=\"/foo\" />`, 1},\n\t\t// TODO: Test <frame> tag.\n\t\t{`<iframe src=\"/iframe\"></iframe>`, 1},\n\t\t{`<img src=\"/foo.jpg\" />`, 1},\n\t\t{`<link href=\"/link\" />`, 1},\n\t\t{`<script src=\"/foo.js\"></script>`, 1},\n\t\t{`<source src=\"/foo.png\" />`, 1},\n\t\t{`<source srcset=\"/foo.png\" />`, 1},\n\t\t{`<source src=\"/foo.png\" srcset=\"/bar.png\" />`, 2},\n\t\t{`<track src=\"/foo.vtt\" />`, 1},\n\t\t{`<a href=\"/\"><img src=\"/foo.png\" /></a>`, 2},\n\t\t{`<a href=\"/\" /><a href=\"/\" />`, 1},\n\t} {\n\t\tn, err := html.Parse(strings.NewReader(htmlWithBody(c.html)))\n\t\tassert.Nil(t, err)\n\n\t\ts, e := 0, 0\n\n\t\tfor _, err := range newTestLinkFinder().Find(n, b) {\n\t\t\tif err == nil {\n\t\t\t\ts++\n\t\t\t} else {\n\t\t\t\te++\n\t\t\t}\n\t\t}\n\n\t\tassert.Equal(t, c.linkCount, s)\n\t\tassert.Equal(t, 0, e)\n\t}\n}\n\nfunc TestLinkFinderFindLinkWithoutEncodedSpaces(t *testing.T) {\n\tb, err := url.Parse(\"http://foo.com\")\n\tassert.Nil(t, err)\n\n\tn, err := html.Parse(strings.NewReader(\n\t\thtmlWithBody(`<a href=\"http://foo.com/a%20b\" />`)),\n\t)\n\tassert.Nil(t, err)\n\n\tls := newTestLinkFinder().Find(n, b)\n\n\terr, ok := ls[\"http://foo.com/a%20b\"]\n\tassert.True(t, ok)\n\tassert.Nil(t, err)\n}\n\nfunc TestLinkFinderFindLinkWithoutSpacesNotEncoded(t *testing.T) {\n\tb, err := url.Parse(\"http://foo.com\")\n\tassert.Nil(t, err)\n\n\tn, err := html.Parse(strings.NewReader(\n\t\thtmlWithBody(`<a href=\"http://foo.com/a b\" />`)),\n\t)\n\tassert.Nil(t, err)\n\n\tls := newTestLinkFinder().Find(n, b)\n\n\terr, ok := ls[\"http://foo.com/a%20b\"]\n\tassert.True(t, ok)\n\tassert.Nil(t, err)\n}\n\nfunc TestLinkFinderFindLinkWithLeadingAndTrailingSpaces(t *testing.T) {\n\tb, err := url.Parse(\"http://foo.com\")\n\tassert.Nil(t, err)\n\n\tn, err := html.Parse(strings.NewReader(\n\t\thtmlWithBody(`<a href=\" http://foo.com \" />`)),\n\t)\n\tassert.Nil(t, err)\n\n\tls := newTestLinkFinder().Find(n, b)\n\n\terr, ok := ls[\"http://foo.com\"]\n\tassert.True(t, ok)\n\tassert.Nil(t, err)\n}\n\nfunc TestLinkFinderFailWithInvalidURL(t *testing.T) {\n\tb, err := url.Parse(\"http://foo.com\")\n\tassert.Nil(t, err)\n\n\tn, err := html.Parse(strings.NewReader(htmlWithBody(`<a href=\":\" />`)))\n\tassert.Nil(t, err)\n\n\tls := newTestLinkFinder().Find(n, b)\n\n\tassert.Equal(t, 1, len(ls))\n\tassert.NotNil(t, ls[\":\"])\n}\n\nfunc TestLinkFinderFindLinkInSrcSet(t *testing.T) {\n\tb, err := url.Parse(\"http://foo.com\")\n\tassert.Nil(t, err)\n\n\tn, err := html.Parse(strings.NewReader(\n\t\thtmlWithBody(`<source srcset=\"foo.png\" />`)),\n\t)\n\tassert.Nil(t, err)\n\n\tls := newTestLinkFinder().Find(n, b)\n\n\terr, ok := ls[\"http://foo.com/foo.png\"]\n\tassert.True(t, ok)\n\tassert.Nil(t, err)\n}\n\nfunc TestLinkFinderFindMultipleLinksInSrcSet(t *testing.T) {\n\tb, err := url.Parse(\"http://foo.com\")\n\tassert.Nil(t, err)\n\n\tn, err := html.Parse(strings.NewReader(\n\t\thtmlWithBody(`<source srcset=\"foo.png, bar.png\" />`)),\n\t)\n\tassert.Nil(t, err)\n\n\tls := newTestLinkFinder().Find(n, b)\n\n\terr, ok := ls[\"http://foo.com/foo.png\"]\n\tassert.True(t, ok)\n\tassert.Nil(t, err)\n\n\terr, ok = ls[\"http://foo.com/bar.png\"]\n\tassert.True(t, ok)\n\tassert.Nil(t, err)\n}\n\nfunc TestLinkFinderFindMultipleLinksInSrcSetWithDescriptors(t *testing.T) {\n\tb, err := url.Parse(\"http://foo.com\")\n\tassert.Nil(t, err)\n\n\tn, err := html.Parse(strings.NewReader(\n\t\thtmlWithBody(`<source srcset=\"foo.png 100w, bar.png 200w\" />`)),\n\t)\n\tassert.Nil(t, err)\n\n\tls := newTestLinkFinder().Find(n, b)\n\n\terr, ok := ls[\"http://foo.com/foo.png\"]\n\tassert.True(t, ok)\n\tassert.Nil(t, err)\n\n\terr, ok = ls[\"http://foo.com/bar.png\"]\n\tassert.True(t, ok)\n\tassert.Nil(t, err)\n}\n\nfunc TestLinkFinderFindMetaTags(t *testing.T) {\n\tb, err := url.Parse(\"http://foo.com\")\n\tassert.Nil(t, err)\n\n\tn, err := html.Parse(strings.NewReader(\n\t\thtmlWithHead(`<meta property=\"og:image\" content=\"foo.png\" />`)),\n\t)\n\tassert.Nil(t, err)\n\n\tls := newTestLinkFinder().Find(n, b)\n\n\terr, ok := ls[\"http://foo.com/foo.png\"]\n\tassert.True(t, ok)\n\tassert.Nil(t, err)\n}\n\nfunc TestLinkFinderFindDataSchemeLinkWithSpaces(t *testing.T) {\n\tb, err := url.Parse(\"http://foo.com\")\n\tassert.Nil(t, err)\n\n\tn, err := html.Parse(strings.NewReader(\n\t\thtmlWithBody(`<a href=\"data:text/plain, Hello,%20world! \" />`)),\n\t)\n\tassert.Nil(t, err)\n\n\tls := newTestLinkFinder().Find(n, b)\n\n\tassert.Len(t, ls, 0)\n}\n\nfunc TestLinkFinderIgnoreMetaTags(t *testing.T) {\n\tb, err := url.Parse(\"http://foo.com\")\n\tassert.Nil(t, err)\n\n\tn, err := html.Parse(strings.NewReader(\n\t\thtmlWithHead(`<meta property=\"og:title\" content=\"title\" />`)),\n\t)\n\tassert.Nil(t, err)\n\n\tls := newTestLinkFinder().Find(n, b)\n\n\tassert.Len(t, ls, 0)\n}\n\nfunc TestLinkFinderIgnorePreconnect(t *testing.T) {\n\tb, err := url.Parse(\"https://localhost\")\n\tassert.Nil(t, err)\n\n\tfor _, c := range []struct {\n\t\thtml      string\n\t\tlinkCount int\n\t}{\n\t\t{`<link rel=\"preconnect\" href=\"https://foo.com\">`, 0},\n\t\t{`<link rel=\"dns-prefetch\" href=\"https://foo.com\">`, 0},\n\t\t{`<link rel=\"dns-prefetch\" href=\"https://foo.com\"><link href=\"https://bar.com/baz.css\" rel=\"stylesheet\">`, 1},\n\t} {\n\t\tn, err := html.Parse(strings.NewReader(htmlWithBody(c.html)))\n\t\tassert.Nil(t, err)\n\n\t\ts, e := 0, 0\n\n\t\tfor _, err := range newTestLinkFinder().Find(n, b) {\n\t\t\tif err == nil {\n\t\t\t\ts++\n\t\t\t} else {\n\t\t\t\te++\n\t\t\t}\n\t\t}\n\n\t\tassert.Equal(t, c.linkCount, s)\n\t\tassert.Equal(t, 0, e)\n\t}\n}\n\nfunc htmlWithBody(b string) string {\n\treturn fmt.Sprintf(`<html><body>%v</body></html>`, b)\n}\n\nfunc htmlWithHead(b string) string {\n\treturn fmt.Sprintf(`<html><head>%v</head><body><p>hi</p></body></html>`, b)\n}\n"
        },
        {
          "name": "link_validator.go",
          "type": "blob",
          "size": 0.7099609375,
          "content": "package main\n\nimport (\n\t\"net/url\"\n\n\t\"github.com/temoto/robotstxt\"\n)\n\ntype linkValidator struct {\n\thostname    string\n\tsitemapURLs map[string]struct{}\n\trobotsData  *robotstxt.RobotsData\n}\n\nfunc newLinkValidator(hostname string, robotsData *robotstxt.RobotsData, sitemap map[string]struct{}) *linkValidator {\n\treturn &linkValidator{hostname, sitemap, robotsData}\n}\n\n// Validate validates a link and returns true if it is valid as one of an HTML page.\nfunc (v *linkValidator) Validate(u *url.URL) bool {\n\tif v.sitemapURLs != nil {\n\t\tif _, ok := v.sitemapURLs[u.String()]; !ok {\n\t\t\treturn false\n\t\t}\n\t}\n\n\tif v.robotsData != nil && !v.robotsData.TestAgent(u.Path, agentName) {\n\t\treturn false\n\t}\n\n\treturn u.Hostname() == v.hostname\n}\n"
        },
        {
          "name": "link_validator_test.go",
          "type": "blob",
          "size": 1.3203125,
          "content": "package main\n\nimport (\n\t\"net/url\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/temoto/robotstxt\"\n)\n\nfunc TestLinkValidatorReturnTrueForSameHostname(t *testing.T) {\n\ti := newLinkValidator(\"foo.com\", nil, nil)\n\n\tfor _, s := range []string{\n\t\t\"http://foo.com\",\n\t\t\"http://foo.com/bar\",\n\t\t\"https://foo.com\",\n\t} {\n\t\tu, err := url.Parse(s)\n\t\tassert.Nil(t, err)\n\t\tassert.True(t, i.Validate(u))\n\t}\n}\n\nfunc TestLinkValidatorReturnFalseForDifferentHostname(t *testing.T) {\n\ti := newLinkValidator(\"foo.com\", nil, nil)\n\n\tu, err := url.Parse(\"http://bar.com\")\n\tassert.Nil(t, err)\n\tassert.False(t, i.Validate(u))\n}\n\nfunc TestLinkValidatorValidateWithSitemap(t *testing.T) {\n\ti := newLinkValidator(\n\t\t\"foo.com\",\n\t\tnil,\n\t\tmap[string]struct{}{\"http://foo.com/foo\": {}},\n\t)\n\n\tu, err := url.Parse(\"http://foo.com/foo\")\n\tassert.Nil(t, err)\n\tassert.True(t, i.Validate(u))\n\n\tu, err = url.Parse(\"http://foo.com/bar\")\n\tassert.Nil(t, err)\n\tassert.False(t, i.Validate(u))\n}\n\nfunc TestLinkValidatorValidateWithRobotsTxt(t *testing.T) {\n\tr, err := robotstxt.FromString(`\n\t\tUser-Agent: *\n\t\tDisallow: /bar\n\t`)\n\tassert.Nil(t, err)\n\n\ti := newLinkValidator(\"foo.com\", r, nil)\n\n\tu, err := url.Parse(\"http://foo.com/foo\")\n\tassert.Nil(t, err)\n\tassert.True(t, i.Validate(u))\n\n\tu, err = url.Parse(\"http://foo.com/bar\")\n\tassert.Nil(t, err)\n\tassert.False(t, i.Validate(u))\n}\n"
        },
        {
          "name": "main.go",
          "type": "blob",
          "size": 0.2890625,
          "content": "package main\n\nimport (\n\t\"os\"\n\n\t\"github.com/mattn/go-colorable\"\n\t\"github.com/mattn/go-isatty\"\n)\n\nfunc main() {\n\tok := newCommand(\n\t\tcolorable.NewColorableStdout(),\n\t\tos.Stderr,\n\t\tisatty.IsTerminal(os.Stdout.Fd()),\n\t\tnewFasthttpHttpClientFactory(),\n\t).Run(os.Args[1:])\n\n\tif !ok {\n\t\tos.Exit(1)\n\t}\n}\n"
        },
        {
          "name": "page.go",
          "type": "blob",
          "size": 0.1328125,
          "content": "package main\n\nimport (\n\t\"net/url\"\n)\n\ntype page interface {\n\tURL() *url.URL\n\tFragments() map[string]struct{}\n\tLinks() map[string]error\n}\n"
        },
        {
          "name": "page_checker.go",
          "type": "blob",
          "size": 1.599609375,
          "content": "package main\n\nimport \"sync\"\n\ntype pageChecker struct {\n\tfetcher       *linkFetcher\n\tlinkValidator *linkValidator\n\tdaemonManager *daemonManager\n\tresults       chan *pageResult\n\tdonePages     concurrentStringSet\n\tonePageOnly   bool\n}\n\nfunc newPageChecker(f *linkFetcher, v *linkValidator, onePageOnly bool) *pageChecker {\n\treturn &pageChecker{\n\t\tf,\n\t\tv,\n\t\tnewDaemonManager(concurrency),\n\t\tmake(chan *pageResult, concurrency),\n\t\tnewConcurrentStringSet(),\n\t\tonePageOnly,\n\t}\n}\n\nfunc (c *pageChecker) Results() <-chan *pageResult {\n\treturn c.results\n}\n\nfunc (c *pageChecker) Check(page page) {\n\tc.addPage(page)\n\tc.daemonManager.Run()\n\n\tclose(c.results)\n}\n\nfunc (c *pageChecker) checkPage(p page) {\n\tus := p.Links()\n\n\tsc := make(chan *successLinkResult, len(us))\n\tec := make(chan *errorLinkResult, len(us))\n\tw := sync.WaitGroup{}\n\n\tfor u, err := range us {\n\t\tif err != nil {\n\t\t\tec <- &errorLinkResult{u, err}\n\t\t\tcontinue\n\t\t}\n\n\t\tw.Add(1)\n\n\t\tgo func(u string) {\n\t\t\tdefer w.Done()\n\n\t\t\tstatus, p, err := c.fetcher.Fetch(u)\n\n\t\t\tif err == nil {\n\t\t\t\tsc <- &successLinkResult{u, status}\n\t\t\t} else {\n\t\t\t\tec <- &errorLinkResult{u, err}\n\t\t\t}\n\n\t\t\tif !c.onePageOnly && p != nil && c.linkValidator.Validate(p.URL()) {\n\t\t\t\tc.addPage(p)\n\t\t\t}\n\t\t}(u)\n\t}\n\n\tw.Wait()\n\n\tclose(sc)\n\tclose(ec)\n\n\tss := make([]*successLinkResult, 0, len(sc))\n\n\tfor s := range sc {\n\t\tss = append(ss, s)\n\t}\n\n\tes := make([]*errorLinkResult, 0, len(ec))\n\n\tfor e := range ec {\n\t\tes = append(es, e)\n\t}\n\n\tc.results <- &pageResult{p.URL().String(), ss, es}\n}\n\nfunc (c *pageChecker) addPage(p page) {\n\tif !c.donePages.Add(p.URL().String()) {\n\t\tc.daemonManager.Add(func() { c.checkPage(p) })\n\t}\n}\n"
        },
        {
          "name": "page_checker_test.go",
          "type": "blob",
          "size": 2.0029296875,
          "content": "package main\n\nimport (\n\t\"errors\"\n\t\"net/url\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc newTestPageChecker(c *fakeHttpClient) *pageChecker {\n\treturn newPageChecker(\n\t\tnewLinkFetcher(\n\t\t\tc,\n\t\t\t[]pageParser{newHtmlPageParser(newTestLinkFinder())},\n\t\t\tlinkFetcherOptions{},\n\t\t),\n\t\tnewLinkValidator(\"foo.com\", nil, nil),\n\t\tfalse,\n\t)\n}\n\nfunc newTestPage(t *testing.T, fragments map[string]struct{}, links map[string]error) page {\n\tu, err := url.Parse(\"http://foo.com\")\n\tassert.Nil(t, err)\n\n\treturn newHtmlPage(u, fragments, links)\n}\n\nfunc TestPageCheckerCheckOnePage(t *testing.T) {\n\tc := newTestPageChecker(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\treturn nil, errors.New(\"\")\n\t\t\t},\n\t\t),\n\t)\n\n\tgo c.Check(newTestPage(t, nil, nil))\n\n\ti := 0\n\n\tfor r := range c.Results() {\n\t\ti++\n\t\tassert.True(t, r.OK())\n\t}\n\n\tassert.Equal(t, 1, i)\n}\n\nfunc TestPageCheckerCheckTwoPages(t *testing.T) {\n\tc := newTestPageChecker(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\ts := \"http://foo.com/foo\"\n\n\t\t\t\tif u.String() != s {\n\t\t\t\t\treturn nil, errors.New(\"\")\n\t\t\t\t}\n\n\t\t\t\treturn newFakeHtmlResponse(s, \"\"), nil\n\t\t\t},\n\t\t),\n\t)\n\n\tgo c.Check(\n\t\tnewTestPage(t, nil, map[string]error{\"http://foo.com/foo\": nil}),\n\t)\n\n\ti := 0\n\n\tfor r := range c.Results() {\n\t\ti++\n\t\tassert.True(t, r.OK())\n\t}\n\n\tassert.Equal(t, 2, i)\n}\n\nfunc TestPageCheckerFailToCheckPage(t *testing.T) {\n\tc := newTestPageChecker(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\treturn nil, errors.New(\"\")\n\t\t\t},\n\t\t),\n\t)\n\n\tgo c.Check(\n\t\tnewTestPage(t, nil, map[string]error{\"http://foo.com/foo\": nil}),\n\t)\n\n\tassert.False(t, (<-c.Results()).OK())\n}\n\nfunc TestPageCheckerDoNotCheckSamePageTwice(t *testing.T) {\n\tc := newTestPageChecker(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\treturn newFakeHtmlResponse(\"http://foo.com\", \"\"), nil\n\t\t\t},\n\t\t),\n\t)\n\n\tgo c.Check(newTestPage(t, nil, map[string]error{\"http://foo.com\": nil}))\n\n\ti := 0\n\n\tfor range c.Results() {\n\t\ti++\n\t}\n\n\tassert.Equal(t, 1, i)\n}\n"
        },
        {
          "name": "page_parser.go",
          "type": "blob",
          "size": 0.173828125,
          "content": "package main\n\nimport \"net/url\"\n\ntype pageParser interface {\n\t// Returned pages can be nil to indicate unrecognized file formats.\n\tParse(*url.URL, string, []byte) (page, error)\n}\n"
        },
        {
          "name": "page_result.go",
          "type": "blob",
          "size": 0.3427734375,
          "content": "package main\n\ntype pageResult struct {\n\tURL                string\n\tSuccessLinkResults []*successLinkResult\n\tErrorLinkResults   []*errorLinkResult\n}\n\ntype successLinkResult struct {\n\tURL        string\n\tStatusCode int\n}\n\ntype errorLinkResult struct {\n\tURL   string\n\tError error\n}\n\nfunc (r *pageResult) OK() bool {\n\treturn len(r.ErrorLinkResults) == 0\n}\n"
        },
        {
          "name": "page_result_formatter.go",
          "type": "blob",
          "size": 1.2958984375,
          "content": "package main\n\nimport (\n\t\"fmt\"\n\t\"sort\"\n\t\"strings\"\n\n\t\"github.com/logrusorgru/aurora/v3\"\n)\n\ntype pageResultFormatter struct {\n\tverbose bool\n\taurora  aurora.Aurora\n}\n\nfunc newPageResultFormatter(verbose bool, color bool) *pageResultFormatter {\n\treturn &pageResultFormatter{verbose, aurora.NewAurora(color)}\n}\n\nfunc (f *pageResultFormatter) Format(r *pageResult) string {\n\tss := []string(nil)\n\n\tif f.verbose {\n\t\tss = append(ss, f.formatSuccessLinkResults(r.SuccessLinkResults)...)\n\t}\n\n\tss = append(ss, f.formatErrorLinkResults(r.ErrorLinkResults)...)\n\n\treturn strings.Join(\n\t\tappend([]string{fmt.Sprint(f.aurora.Yellow(r.URL))}, formatMessages(ss)...),\n\t\t\"\\n\",\n\t)\n}\n\nfunc (f *pageResultFormatter) formatSuccessLinkResults(rs []*successLinkResult) []string {\n\tss := make([]string, 0, len(rs))\n\n\tfor _, r := range rs {\n\t\tss = append(ss, fmt.Sprintf(\"%v\", f.aurora.Green(r.StatusCode))+\"\\t\"+r.URL)\n\t}\n\n\tsort.Strings(ss)\n\n\treturn ss\n}\n\nfunc (f *pageResultFormatter) formatErrorLinkResults(rs []*errorLinkResult) []string {\n\tss := make([]string, 0, len(rs))\n\n\tfor _, r := range rs {\n\t\tss = append(ss, fmt.Sprintf(\"%v\", f.aurora.Red(r.Error))+\"\\t\"+r.URL)\n\t}\n\n\tsort.Strings(ss)\n\n\treturn ss\n}\n\nfunc formatMessages(ss []string) []string {\n\tts := make([]string, 0, len(ss))\n\n\tfor _, s := range ss {\n\t\tts = append(ts, \"\\t\"+s)\n\t}\n\n\treturn ts\n}\n"
        },
        {
          "name": "page_result_formatter_test.go",
          "type": "blob",
          "size": 2.025390625,
          "content": "package main\n\nimport (\n\t\"errors\"\n\t\"testing\"\n\n\t\"github.com/bradleyjkemp/cupaloy\"\n)\n\nfunc TestPageResultFormatterFormatEmptyResult(t *testing.T) {\n\tcupaloy.SnapshotT(t,\n\t\tnewPageResultFormatter(false, true).Format(\n\t\t\t&pageResult{\"http://foo.com\", nil, nil},\n\t\t),\n\t)\n}\n\nfunc TestPageResultFormatterFormatSuccessLinkResults(t *testing.T) {\n\tcupaloy.SnapshotT(t,\n\t\tnewPageResultFormatter(false, true).Format(\n\t\t\t&pageResult{\n\t\t\t\t\"http://foo.com\",\n\t\t\t\t[]*successLinkResult{\n\t\t\t\t\t{\"http://foo.com\", 200},\n\t\t\t\t},\n\t\t\t\tnil,\n\t\t\t},\n\t\t),\n\t)\n}\n\nfunc TestPageResultFormatterFormatErrorLinkResults(t *testing.T) {\n\tcupaloy.SnapshotT(t,\n\t\tnewPageResultFormatter(false, true).Format(\n\t\t\t&pageResult{\n\t\t\t\t\"http://foo.com\",\n\t\t\t\t[]*successLinkResult{\n\t\t\t\t\t{\"http://foo.com\", 200},\n\t\t\t\t},\n\t\t\t\t[]*errorLinkResult{\n\t\t\t\t\t{\"http://foo.com\", errors.New(\"500\")},\n\t\t\t\t},\n\t\t\t},\n\t\t),\n\t)\n}\n\nfunc TestPageResultFormatterFormatSuccessLinkResultsVerbosely(t *testing.T) {\n\tcupaloy.SnapshotT(t,\n\t\tnewPageResultFormatter(true, true).Format(\n\t\t\t&pageResult{\n\t\t\t\t\"http://foo.com\",\n\t\t\t\t[]*successLinkResult{\n\t\t\t\t\t{\"http://foo.com\", 200},\n\t\t\t\t},\n\t\t\t\tnil,\n\t\t\t},\n\t\t),\n\t)\n}\n\nfunc TestPageResultFormatterFormatErrorLinkResultsVerbosely(t *testing.T) {\n\tcupaloy.SnapshotT(t,\n\t\tnewPageResultFormatter(true, true).Format(\n\t\t\t&pageResult{\n\t\t\t\t\"http://foo.com\",\n\t\t\t\t[]*successLinkResult{\n\t\t\t\t\t{\"http://foo.com\", 200},\n\t\t\t\t},\n\t\t\t\t[]*errorLinkResult{\n\t\t\t\t\t{\"http://foo.com\", errors.New(\"500\")},\n\t\t\t\t},\n\t\t\t},\n\t\t),\n\t)\n}\n\nfunc TestPageResultFormatterSortSuccessLinkResults(t *testing.T) {\n\tcupaloy.SnapshotT(t,\n\t\tnewPageResultFormatter(true, true).Format(\n\t\t\t&pageResult{\n\t\t\t\t\"http://foo.com\",\n\t\t\t\t[]*successLinkResult{\n\t\t\t\t\t{\"http://foo.com\", 200},\n\t\t\t\t\t{\"http://bar.com\", 200},\n\t\t\t\t},\n\t\t\t\tnil,\n\t\t\t},\n\t\t),\n\t)\n}\n\nfunc TestPageResultFormatterSortErrorLinkResults(t *testing.T) {\n\tcupaloy.SnapshotT(t,\n\t\tnewPageResultFormatter(false, true).Format(\n\t\t\t&pageResult{\n\t\t\t\t\"http://foo.com\",\n\t\t\t\tnil,\n\t\t\t\t[]*errorLinkResult{\n\t\t\t\t\t{\"http://foo.com\", errors.New(\"500\")},\n\t\t\t\t\t{\"http://bar.com\", errors.New(\"500\")},\n\t\t\t\t},\n\t\t\t},\n\t\t),\n\t)\n}\n"
        },
        {
          "name": "page_result_test.go",
          "type": "blob",
          "size": 0.23046875,
          "content": "package main\n\nimport (\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestPageResultOK(t *testing.T) {\n\tassert.True(t, (&pageResult{\"\", nil, nil}).OK())\n\tassert.False(t, (&pageResult{\"\", nil, []*errorLinkResult{{}}}).OK())\n}\n"
        },
        {
          "name": "redirect_http_client.go",
          "type": "blob",
          "size": 1.2666015625,
          "content": "package main\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"net/http/cookiejar\"\n\t\"net/url\"\n)\n\ntype redirectHttpClient struct {\n\tclient          httpClient\n\tmaxRedirections int\n}\n\nfunc newRedirectHttpClient(c httpClient, maxRedirections int) httpClient {\n\treturn &redirectHttpClient{c, maxRedirections}\n}\n\nfunc (c *redirectHttpClient) Get(u *url.URL, header http.Header) (httpResponse, error) {\n\tif header == nil {\n\t\theader = http.Header{}\n\t}\n\n\tcj, err := cookiejar.New(nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor i := range c.maxRedirections + 1 {\n\t\tfor _, c := range cj.Cookies(u) {\n\t\t\theader.Add(\"cookie\", c.String())\n\t\t}\n\n\t\tr, err := c.client.Get(u, header)\n\t\tif err != nil && i == 0 {\n\t\t\treturn nil, err\n\t\t} else if err != nil {\n\t\t\treturn nil, fmt.Errorf(\"%w (following redirect %v)\", err, u.String())\n\t\t} else if c := r.StatusCode(); c < 300 || c >= 400 {\n\t\t\treturn r, nil\n\t\t}\n\n\t\ts := r.Header(\"Location\")\n\n\t\tif len(s) == 0 {\n\t\t\treturn nil, errors.New(\"location header not set\")\n\t\t}\n\n\t\tu, err = u.Parse(s)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tcj.SetCookies(u, parseCookies(r.Header(\"set-cookie\")))\n\t}\n\n\treturn nil, errors.New(\"too many redirections\")\n}\n\nfunc parseCookies(s string) []*http.Cookie {\n\th := http.Header{}\n\th.Add(\"cookie\", s)\n\treturn (&http.Request{Header: h}).Cookies()\n}\n"
        },
        {
          "name": "redirect_http_client_test.go",
          "type": "blob",
          "size": 5.0771484375,
          "content": "package main\n\nimport (\n\t\"errors\"\n\t\"net/url\"\n\t\"strconv\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nconst testUrl = \"http://foo.com\"\n\nfunc TestNewRedirectHttpClient(t *testing.T) {\n\tnewRedirectHttpClient(newFakeHttpClient(nil), 42)\n}\n\nfunc TestRedirectHttpClientGet(t *testing.T) {\n\tu, err := url.Parse(testUrl)\n\n\tassert.Nil(t, err)\n\n\tr, err := newRedirectHttpClient(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\tif u.String() != testUrl {\n\t\t\t\t\treturn nil, errors.New(\"\")\n\t\t\t\t}\n\n\t\t\t\treturn newFakeHtmlResponse(testUrl, \"\"), nil\n\t\t\t},\n\t\t),\n\t\t42,\n\t).Get(u, nil)\n\n\tassert.Nil(t, err)\n\tassert.Equal(t, 200, r.StatusCode())\n}\n\nfunc TestRedirectHttpClientGetWithoutRedirect(t *testing.T) {\n\tu, err := url.Parse(testUrl)\n\n\tassert.Nil(t, err)\n\n\tr, err := newRedirectHttpClient(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\tif u.String() != testUrl {\n\t\t\t\t\treturn nil, errors.New(\"\")\n\t\t\t\t}\n\n\t\t\t\treturn newFakeHtmlResponse(testUrl, \"\"), nil\n\t\t\t},\n\t\t),\n\t\t0,\n\t).Get(u, nil)\n\n\tassert.Nil(t, err)\n\tassert.Equal(t, 200, r.StatusCode())\n}\n\nfunc TestRedirectHttpClientGetWithRedirect(t *testing.T) {\n\tu, err := url.Parse(testUrl)\n\n\tassert.Nil(t, err)\n\n\tredirected := false\n\tr, err := newRedirectHttpClient(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\tif u.String() != testUrl {\n\t\t\t\t\treturn nil, errors.New(\"\")\n\t\t\t\t} else if !redirected {\n\t\t\t\t\tredirected = true\n\n\t\t\t\t\treturn newFakeHttpResponse(\n\t\t\t\t\t\t300,\n\t\t\t\t\t\ttestUrl,\n\t\t\t\t\t\tnil,\n\t\t\t\t\t\tmap[string]string{\"location\": testUrl},\n\t\t\t\t\t), nil\n\t\t\t\t}\n\n\t\t\t\treturn newFakeHtmlResponse(\"\", \"\"), nil\n\t\t\t},\n\t\t),\n\t\t42,\n\t).Get(u, nil)\n\n\tassert.Nil(t, err)\n\tassert.Equal(t, 200, r.StatusCode())\n}\n\nfunc TestRedirectHttpClientGetWithRedirects(t *testing.T) {\n\tconst maxRedirections = 42\n\n\tu, err := url.Parse(testUrl)\n\n\tassert.Nil(t, err)\n\n\ti := 0\n\tr, err := newRedirectHttpClient(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\tif u.String() != testUrl {\n\t\t\t\t\treturn nil, errors.New(\"\")\n\t\t\t\t} else if i < maxRedirections {\n\t\t\t\t\ti++\n\n\t\t\t\t\treturn newFakeHttpResponse(\n\t\t\t\t\t\t300,\n\t\t\t\t\t\ttestUrl,\n\t\t\t\t\t\tnil,\n\t\t\t\t\t\tmap[string]string{\"location\": testUrl},\n\t\t\t\t\t), nil\n\t\t\t\t}\n\n\t\t\t\treturn newFakeHtmlResponse(\"\", \"\"), nil\n\t\t\t},\n\t\t),\n\t\tmaxRedirections,\n\t).Get(u, nil)\n\n\tassert.Nil(t, err)\n\tassert.Equal(t, 200, r.StatusCode())\n\tassert.Equal(t, maxRedirections, i)\n}\n\nfunc TestRedirectHttpClientGetWithRelativeRedirect(t *testing.T) {\n\tconst maxRedirections = 42\n\n\tu, err := url.Parse(testUrl)\n\n\tassert.Nil(t, err)\n\n\tredirected := false\n\tr, err := newRedirectHttpClient(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\tswitch u.String() {\n\t\t\t\tcase \"http://foo.com/foo\":\n\t\t\t\t\treturn newFakeHtmlResponse(\"\", \"\"), nil\n\t\t\t\tcase testUrl:\n\t\t\t\t\tif !redirected {\n\t\t\t\t\t\tredirected = true\n\n\t\t\t\t\t\treturn newFakeHttpResponse(\n\t\t\t\t\t\t\t300,\n\t\t\t\t\t\t\ttestUrl,\n\t\t\t\t\t\t\tnil,\n\t\t\t\t\t\t\tmap[string]string{\"location\": \"/foo\"},\n\t\t\t\t\t\t), nil\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\treturn nil, errors.New(\"\")\n\t\t\t},\n\t\t),\n\t\tmaxRedirections,\n\t).Get(u, nil)\n\n\tassert.Nil(t, err)\n\tassert.Equal(t, 200, r.StatusCode())\n\tassert.Equal(t, redirected, true)\n}\n\nfunc TestRedirectHttpClientFailWithTooManyRedirects(t *testing.T) {\n\tfor _, n := range []int{0, 1, 42} {\n\t\tt.Run(strconv.Itoa(n), func(t *testing.T) {\n\t\t\tu, err := url.Parse(testUrl)\n\n\t\t\tassert.Nil(t, err)\n\n\t\t\ti := 0\n\t\t\tr, err := newRedirectHttpClient(\n\t\t\t\tnewFakeHttpClient(\n\t\t\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\t\t\ti++\n\n\t\t\t\t\t\treturn newFakeHttpResponse(\n\t\t\t\t\t\t\t300,\n\t\t\t\t\t\t\ttestUrl,\n\t\t\t\t\t\t\tnil,\n\t\t\t\t\t\t\tmap[string]string{\"location\": testUrl},\n\t\t\t\t\t\t), nil\n\t\t\t\t\t},\n\t\t\t\t),\n\t\t\t\tn,\n\t\t\t).Get(u, nil)\n\n\t\t\tassert.Nil(t, r)\n\t\t\tassert.Equal(t, err.Error(), \"too many redirections\")\n\t\t\tassert.Equal(t, n+1, i)\n\t\t})\n\t}\n}\n\nfunc TestRedirectHttpClientFailWithUnsetLocationHeader(t *testing.T) {\n\tu, err := url.Parse(testUrl)\n\n\tassert.Nil(t, err)\n\n\tr, err := newRedirectHttpClient(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\treturn newFakeHttpResponse(300, testUrl, nil, nil), nil\n\t\t\t},\n\t\t),\n\t\t42,\n\t).Get(u, nil)\n\n\tassert.Nil(t, r)\n\tassert.Equal(t, err.Error(), \"location header not set\")\n}\n\nfunc TestRedirectHttpClientFailWithInvalidLocationURL(t *testing.T) {\n\tu, err := url.Parse(testUrl)\n\n\tassert.Nil(t, err)\n\n\tr, err := newRedirectHttpClient(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\treturn newFakeHttpResponse(\n\t\t\t\t\t300,\n\t\t\t\t\ttestUrl,\n\t\t\t\t\tnil,\n\t\t\t\t\tmap[string]string{\"location\": \":\"},\n\t\t\t\t), nil\n\t\t\t},\n\t\t),\n\t\t42,\n\t).Get(u, nil)\n\n\tassert.Nil(t, r)\n\tassert.Contains(t, err.Error(), \"parse\")\n}\n\nfunc TestRedirectHttpClientFailAfterRedirect(t *testing.T) {\n\tu, err := url.Parse(testUrl)\n\n\tassert.Nil(t, err)\n\n\tredirected := false\n\tr, err := newRedirectHttpClient(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\tif !redirected {\n\t\t\t\t\tredirected = true\n\n\t\t\t\t\treturn newFakeHttpResponse(\n\t\t\t\t\t\t300,\n\t\t\t\t\t\ttestUrl,\n\t\t\t\t\t\tnil,\n\t\t\t\t\t\tmap[string]string{\"location\": \"/foo\"},\n\t\t\t\t\t), nil\n\t\t\t\t}\n\n\t\t\t\treturn nil, errors.New(\"foo\")\n\t\t\t},\n\t\t),\n\t\t42,\n\t).Get(u, nil)\n\n\tassert.Nil(t, r)\n\tassert.Contains(t, err.Error(), \"following redirect http://foo.com/foo\")\n}\n"
        },
        {
          "name": "robots_txt_fetcher.go",
          "type": "blob",
          "size": 0.630859375,
          "content": "package main\n\nimport (\n\t\"fmt\"\n\t\"net/url\"\n\n\t\"github.com/temoto/robotstxt\"\n)\n\ntype robotsTxtFetcher struct {\n\tclient httpClient\n}\n\nfunc newRobotsTxtFetcher(c httpClient) *robotsTxtFetcher {\n\treturn &robotsTxtFetcher{c}\n}\n\nfunc (f *robotsTxtFetcher) Fetch(uu *url.URL) (*robotstxt.RobotsData, error) {\n\tu := *uu\n\tu.Path = \"robots.txt\"\n\n\tr, err := f.client.Get(&u, nil)\n\tif err != nil {\n\t\treturn nil, f.formatError(err)\n\t}\n\n\tbs, err := r.Body()\n\tif err != nil {\n\t\treturn nil, f.formatError(err)\n\t}\n\n\treturn robotstxt.FromBytes(bs)\n}\n\nfunc (*robotsTxtFetcher) formatError(err error) error {\n\treturn fmt.Errorf(\"failed to fetch robots.txt: %v\", err)\n}\n"
        },
        {
          "name": "robots_txt_fetcher_test.go",
          "type": "blob",
          "size": 0.9873046875,
          "content": "package main\n\nimport (\n\t\"errors\"\n\t\"net/url\"\n\t\"testing\"\n\n\t\"github.com/bradleyjkemp/cupaloy\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestRobotsTxtFetcherFetchRobotsTxt(t *testing.T) {\n\ts := \"http://foo.com\"\n\tu, err := url.Parse(s)\n\tassert.Nil(t, err)\n\n\tr, err := newRobotsTxtFetcher(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\tif u.String() != s+\"/robots.txt\" {\n\t\t\t\t\treturn nil, errors.New(\"\")\n\t\t\t\t}\n\n\t\t\t\treturn newFakeHttpResponse(\n\t\t\t\t\t200,\n\t\t\t\t\ts,\n\t\t\t\t\t[]byte(`\n\t\t\t\t\t\tUser-Agent: *\n\t\t\t\t\t\tDisallow: /bar\n\t\t\t\t\t`),\n\t\t\t\t\tmap[string]string{\"content-type\": \"text/plain\"},\n\t\t\t\t), nil\n\t\t\t})).Fetch(u)\n\n\tassert.Nil(t, err)\n\tassert.False(t, r.TestAgent(\"/bar\", \"foo\"))\n}\n\nfunc TestRobotsTxtFetcherFailToFetchRobotsTxt(t *testing.T) {\n\tu, err := url.Parse(\"http://foo.com\")\n\tassert.Nil(t, err)\n\n\t_, err = newRobotsTxtFetcher(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\treturn nil, errors.New(\"foo\")\n\t\t\t})).Fetch(u)\n\n\tcupaloy.SnapshotT(t, err.Error())\n}\n"
        },
        {
          "name": "semaphore.go",
          "type": "blob",
          "size": 0.2314453125,
          "content": "package main\n\ntype semaphore struct {\n\tchannel chan bool\n}\n\nfunc newSemaphore(n int) semaphore {\n\treturn semaphore{make(chan bool, n)}\n}\n\nfunc (s semaphore) Request() {\n\ts.channel <- true\n}\n\nfunc (s semaphore) Release() {\n\t<-s.channel\n}\n"
        },
        {
          "name": "semaphore_test.go",
          "type": "blob",
          "size": 0.31640625,
          "content": "package main\n\nimport (\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestSemaphoreRequest(t *testing.T) {\n\ts := newSemaphore(1)\n\n\ts.Request()\n\n\tassert.Equal(t, 1, len(s.channel))\n}\n\nfunc TestSemaphoreRelease(t *testing.T) {\n\ts := newSemaphore(1)\n\n\ts.Request()\n\ts.Release()\n\n\tassert.Equal(t, 0, len(s.channel))\n}\n"
        },
        {
          "name": "sitemap_fetcher.go",
          "type": "blob",
          "size": 0.8740234375,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"net/url\"\n\n\tsitemap \"github.com/oxffaa/gopher-parse-sitemap\"\n)\n\ntype sitemapFetcher struct {\n\tclient httpClient\n}\n\nfunc newSitemapFetcher(c httpClient) *sitemapFetcher {\n\treturn &sitemapFetcher{c}\n}\n\nfunc (f *sitemapFetcher) Fetch(uu *url.URL) (map[string]struct{}, error) {\n\tu := *uu\n\tu.Path = \"sitemap.xml\"\n\n\tr, err := f.client.Get(&u, nil)\n\tif err != nil {\n\t\treturn nil, f.formatGetError(err)\n\t}\n\n\tus := map[string]struct{}{}\n\n\tbs, err := r.Body()\n\tif err != nil {\n\t\treturn nil, f.formatGetError(err)\n\t}\n\n\terr = sitemap.Parse(bytes.NewReader(bs), func(e sitemap.Entry) error {\n\t\tus[e.GetLocation()] = struct{}{}\n\n\t\treturn nil\n\t})\n\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to parse sitemap.xml: %v\", err)\n\t}\n\n\treturn us, nil\n}\n\nfunc (*sitemapFetcher) formatGetError(err error) error {\n\treturn fmt.Errorf(\"failed to GET sitemap.xml: %v\", err)\n}\n"
        },
        {
          "name": "sitemap_fetcher_test.go",
          "type": "blob",
          "size": 1.533203125,
          "content": "package main\n\nimport (\n\t\"errors\"\n\t\"net/url\"\n\t\"testing\"\n\n\t\"github.com/bradleyjkemp/cupaloy\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestSitemapFetcherFetchSitemap(t *testing.T) {\n\ts := \"http://foo.com\"\n\tu, err := url.Parse(s)\n\tassert.Nil(t, err)\n\n\tsm, err := newSitemapFetcher(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\tif u.String() != s+\"/sitemap.xml\" {\n\t\t\t\t\treturn nil, errors.New(\"\")\n\t\t\t\t}\n\n\t\t\t\treturn newFakeHttpResponse(\n\t\t\t\t\t200,\n\t\t\t\t\ts,\n\t\t\t\t\t[]byte(`\n\t\t\t\t\t\t<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\t\t\t\t\t\t<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n\t\t\t\t\t\t\t<url>\n\t\t\t\t\t\t\t\t<loc>http://foo.com/bar</loc>\n\t\t\t\t\t\t\t</url>\n\t\t\t\t\t\t</urlset>\n\t\t\t\t\t`),\n\t\t\t\t\tmap[string]string{\"content-type\": \"text/xml\"},\n\t\t\t\t), nil\n\t\t\t})).Fetch(u)\n\n\tassert.Nil(t, err)\n\n\t_, ok := sm[\"http://foo.com/bar\"]\n\tassert.True(t, ok)\n}\n\nfunc TestSitemapFetcherFailToFetchSitemap(t *testing.T) {\n\tu, err := url.Parse(\"http://foo.com\")\n\tassert.Nil(t, err)\n\n\t_, err = newSitemapFetcher(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\treturn nil, errors.New(\"foo\")\n\t\t\t},\n\t\t),\n\t).Fetch(u)\n\n\tcupaloy.SnapshotT(t, err.Error())\n}\n\nfunc TestSitemapFetcherFailToParseSitemap(t *testing.T) {\n\tu, err := url.Parse(\"http://foo.com\")\n\tassert.Nil(t, err)\n\n\t_, err = newSitemapFetcher(\n\t\tnewFakeHttpClient(\n\t\t\tfunc(u *url.URL) (*fakeHttpResponse, error) {\n\t\t\t\treturn newFakeHttpResponse(\n\t\t\t\t\t200, \"\", []byte(`<`),\n\t\t\t\t\tmap[string]string{\"content-type\": \"text/xml\"},\n\t\t\t\t), nil\n\t\t\t},\n\t\t),\n\t).Fetch(u)\n\n\tcupaloy.SnapshotT(t, err.Error())\n}\n"
        },
        {
          "name": "sitemap_page.go",
          "type": "blob",
          "size": 0.3955078125,
          "content": "package main\n\nimport (\n\t\"net/url\"\n)\n\ntype sitemapPage struct {\n\turl   *url.URL\n\tlinks map[string]error\n}\n\nfunc newSitemapPage(u *url.URL, links map[string]error) *sitemapPage {\n\treturn &sitemapPage{u, links}\n}\n\nfunc (p *sitemapPage) URL() *url.URL {\n\treturn p.url\n}\n\nfunc (p *sitemapPage) Fragments() map[string]struct{} {\n\treturn nil\n}\n\nfunc (p *sitemapPage) Links() map[string]error {\n\treturn p.links\n}\n"
        },
        {
          "name": "sitemap_page_parser.go",
          "type": "blob",
          "size": 1.033203125,
          "content": "package main\n\nimport (\n\t\"bytes\"\n\t\"net/url\"\n\n\tsitemap \"github.com/oxffaa/gopher-parse-sitemap\"\n)\n\ntype sitemapPageParser struct {\n\tlinkFilterer linkFilterer\n}\n\nfunc newSitemapPageParser(f linkFilterer) *sitemapPageParser {\n\treturn &sitemapPageParser{f}\n}\n\nfunc (p *sitemapPageParser) Parse(u *url.URL, typ string, bs []byte) (page, error) {\n\tif typ != \"application/xml\" && typ != \"text/xml\" {\n\t\treturn nil, nil\n\t}\n\n\tls := map[string]error{}\n\tc := func(e interface{ GetLocation() string }) error {\n\t\tu, err := url.Parse(e.GetLocation())\n\n\t\tif p.linkFilterer.IsValid(u) {\n\t\t\tls[u.String()] = err\n\t\t}\n\n\t\treturn nil\n\t}\n\n\terr := sitemap.Parse(bytes.NewReader(bs), func(e sitemap.Entry) error {\n\t\treturn c(e)\n\t})\n\n\t// TODO Detect XML files as sitemaps.\n\tif err == nil && len(ls) != 0 {\n\t\treturn newSitemapPage(u, ls), nil\n\t}\n\n\terr = sitemap.ParseIndex(bytes.NewReader(bs), func(e sitemap.IndexEntry) error {\n\t\treturn c(e)\n\t})\n\n\t// TODO Detect XML files as sitemap indices.\n\tif err == nil && len(ls) != 0 {\n\t\treturn newSitemapPage(u, ls), nil\n\t}\n\n\treturn nil, nil\n}\n"
        },
        {
          "name": "sitemap_page_parser_test.go",
          "type": "blob",
          "size": 3.6318359375,
          "content": "package main\n\nimport (\n\t\"regexp\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nconst (\n\tSITEMAP_MIME_TYPE       = \"application/xml\"\n\tSITEMAP_MIME_TYPE_ALIAS = \"text/xml\"\n)\n\nfunc TestSitemapPageParserParsePage(t *testing.T) {\n\tp, err := newSitemapPageParser(newTestLinkFilterer()).Parse(parseURL(t, \"https://foo.com/sitemap.xml\"), SITEMAP_MIME_TYPE, []byte(`\n\t\t<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\t\t<urlset\n\t\t\txmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\"\n\t\t\txmlns:news=\"http://www.google.com/schemas/sitemap-news/0.9\"\n\t\t\txmlns:xhtml=\"http://www.w3.org/1999/xhtml\"\n\t\t\txmlns:image=\"http://www.google.com/schemas/sitemap-image/1.1\"\n\t\t\txmlns:video=\"http://www.google.com/schemas/sitemap-video/1.1\"\n\t\t>\n\t\t\t<url>\n\t\t\t\t<loc>https://foo.com/</loc>\n\t\t\t</url>\n\t\t</urlset>\n\t`))\n\n\tassert.Nil(t, err)\n\tassert.Equal(t, \"https://foo.com/sitemap.xml\", p.URL().String())\n\tassert.Equal(t, map[string]error{\"https://foo.com/\": nil}, p.Links())\n\tassert.Equal(t, map[string]struct{}(nil), p.Fragments())\n}\n\nfunc TestSitemapPageParserParsePageMimeTypeAlias(t *testing.T) {\n\tp, err := newSitemapPageParser(newTestLinkFilterer()).Parse(parseURL(t, \"https://foo.com/sitemap.xml\"), SITEMAP_MIME_TYPE_ALIAS, []byte(`\n\t\t<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\t\t<urlset\n\t\t\txmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\"\n\t\t\txmlns:news=\"http://www.google.com/schemas/sitemap-news/0.9\"\n\t\t\txmlns:xhtml=\"http://www.w3.org/1999/xhtml\"\n\t\t\txmlns:image=\"http://www.google.com/schemas/sitemap-image/1.1\"\n\t\t\txmlns:video=\"http://www.google.com/schemas/sitemap-video/1.1\"\n\t\t>\n\t\t\t<url>\n\t\t\t\t<loc>https://foo.com/</loc>\n\t\t\t</url>\n\t\t</urlset>\n\t`))\n\n\tassert.Nil(t, err)\n\tassert.NotNil(t, p)\n\tassert.Equal(t, \"https://foo.com/sitemap.xml\", p.URL().String())\n\tassert.Equal(t, map[string]error{\"https://foo.com/\": nil}, p.Links())\n\tassert.Equal(t, map[string]struct{}(nil), p.Fragments())\n}\n\nfunc TestSitemapPageParserParseIndexPage(t *testing.T) {\n\tp, err := newSitemapPageParser(newTestLinkFilterer()).Parse(parseURL(t, \"https://foo.com/sitemap.xml\"), SITEMAP_MIME_TYPE, []byte(`\n\t\t<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\t\t<sitemapindex xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n\t\t\t<sitemap>\n\t\t\t\t<loc>https://foo.com/sitemap-0.xml</loc>\n\t\t\t</sitemap>\n\t\t</sitemapindex>\n\t`))\n\n\tassert.Nil(t, err)\n\tassert.Equal(t, \"https://foo.com/sitemap.xml\", p.URL().String())\n\tassert.Equal(t, map[string]error{\"https://foo.com/sitemap-0.xml\": nil}, p.Links())\n\tassert.Equal(t, map[string]struct{}(nil), p.Fragments())\n}\n\nfunc TestSitemapPageParserExcludeLink(t *testing.T) {\n\tp, err := newSitemapPageParser(\n\t\tnewLinkFilterer([]*regexp.Regexp{regexp.MustCompile(\"private\")}, nil),\n\t).Parse(parseURL(t, \"https://foo.com/sitemap.xml\"), SITEMAP_MIME_TYPE, []byte(`\n\t\t<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\t\t<sitemapindex xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n\t\t\t<sitemap>\n\t\t\t\t<loc>https://foo.com/private-sitemap.xml</loc>\n\t\t\t</sitemap>\n\t\t\t<sitemap>\n\t\t\t\t<loc>https://foo.com/public-sitemap.xml</loc>\n\t\t\t</sitemap>\n\t\t</sitemapindex>\n\t`))\n\n\tassert.Nil(t, err)\n\tassert.Equal(t, \"https://foo.com/sitemap.xml\", p.URL().String())\n\tassert.Equal(t, map[string]error{\"https://foo.com/public-sitemap.xml\": nil}, p.Links())\n\tassert.Equal(t, map[string]struct{}(nil), p.Fragments())\n}\n\nfunc TestSitemapPageParserFailToParseXML(t *testing.T) {\n\tp, err := newSitemapPageParser(newTestLinkFilterer()).Parse(parseURL(t, \"https://foo.com/sitemap.xml\"), SITEMAP_MIME_TYPE, []byte(\"\"))\n\n\tassert.Nil(t, err)\n\tassert.Nil(t, p)\n}\n\nfunc TestSitemapPageParserFailToParseHTML(t *testing.T) {\n\tp, err := newSitemapPageParser(newTestLinkFilterer()).Parse(parseURL(t, \"https://foo.com/sitemap.xml\"), \"text/html\", []byte(\"\"))\n\n\tassert.Nil(t, err)\n\tassert.Nil(t, p)\n}\n"
        },
        {
          "name": "status_code_range.go",
          "type": "blob",
          "size": 0.66796875,
          "content": "package main\n\nimport (\n\t\"fmt\"\n\t\"strconv\"\n\t\"strings\"\n)\n\ntype statusCodeRange struct {\n\tstart int\n\tend   int\n}\n\nfunc parseStatusCodeRange(s string) (*statusCodeRange, error) {\n\tif c, err := strconv.Atoi(s); err == nil {\n\t\treturn &statusCodeRange{c, c + 1}, nil\n\t}\n\n\tss := strings.Split(s, \"..\")\n\tif len(ss) != 2 {\n\t\treturn nil, fmt.Errorf(\"invalid status code range: %v\", s)\n\t}\n\n\tcs := []int{0, 0}\n\n\tfor i, s := range ss {\n\t\tc, err := strconv.Atoi(s)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"invalid status code: %v\", s)\n\t\t}\n\n\t\tcs[i] = c\n\t}\n\n\treturn &statusCodeRange{cs[0], cs[1]}, nil\n}\n\nfunc (r statusCodeRange) Contains(code int) bool {\n\treturn code >= r.start && code < r.end\n}\n"
        },
        {
          "name": "status_code_range_test.go",
          "type": "blob",
          "size": 0.7998046875,
          "content": "package main\n\nimport (\n\t\"github.com/stretchr/testify/assert\"\n\t\"testing\"\n)\n\nfunc TestParsingFixedStatusCode(t *testing.T) {\n\tr, err := parseStatusCodeRange(\"403\")\n\n\tassert.Nil(t, err)\n\tassert.Equal(t, 403, r.start)\n\tassert.Equal(t, 404, r.end)\n}\n\nfunc TestParsingStatusCodeRange(t *testing.T) {\n\tr, err := parseStatusCodeRange(\"200..300\")\n\n\tassert.Nil(t, err)\n\tassert.Equal(t, 200, r.start)\n\tassert.Equal(t, 300, r.end)\n}\n\nfunc TestParsingInvalidStatusCode(t *testing.T) {\n\t_, err := parseStatusCodeRange(\"foo\")\n\n\tassert.NotNil(t, err)\n}\n\nfunc TestInRangeOfStatusCode(t *testing.T) {\n\tr := statusCodeRange{200, 300}\n\n\tassert.False(t, r.Contains(199))\n\tassert.True(t, r.Contains(200))\n\tassert.True(t, r.Contains(201))\n\n\tassert.True(t, r.Contains(298))\n\tassert.True(t, r.Contains(299))\n\tassert.False(t, r.Contains(300))\n}\n"
        },
        {
          "name": "status_code_set.go",
          "type": "blob",
          "size": 0.458984375,
          "content": "package main\n\nimport \"strings\"\n\ntype statusCodeSet map[statusCodeRange]struct{}\n\nfunc parseStatusCodeSet(value string) (statusCodeSet, error) {\n\trs := statusCodeSet{}\n\n\tfor _, r := range strings.Split(value, \",\") {\n\t\tr, err := parseStatusCodeRange(r)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\trs[*r] = struct{}{}\n\t}\n\n\treturn rs, nil\n}\n\nfunc (s statusCodeSet) Contains(code int) bool {\n\tfor r := range s {\n\t\tif r.Contains(code) {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}\n"
        },
        {
          "name": "status_code_set_test.go",
          "type": "blob",
          "size": 0.533203125,
          "content": "package main\n\nimport (\n\t\"github.com/stretchr/testify/assert\"\n\t\"testing\"\n)\n\nfunc TestParsingValidStatusCodeSet(t *testing.T) {\n\tfor s, r := range map[string]statusCodeSet{\n\t\t\"200\":          {{200, 201}: {}},\n\t\t\"200..300\":     {{200, 300}: {}},\n\t\t\"200..207,403\": {{200, 207}: {}, {403, 404}: {}},\n\t} {\n\t\tt.Run(s, func(t *testing.T) {\n\t\t\ts, err := parseStatusCodeSet(s)\n\n\t\t\tassert.Nil(t, err)\n\t\t\tassert.Equal(t, s, r)\n\t\t})\n\t}\n}\n\nfunc TestParsingInvalidStatusCodeSet(t *testing.T) {\n\t_, err := parseStatusCodeSet(\"200,foo\")\n\n\tassert.NotNil(t, err)\n}\n"
        },
        {
          "name": "throttled_http_client.go",
          "type": "blob",
          "size": 0.6826171875,
          "content": "package main\n\nimport (\n\t\"net/http\"\n\t\"net/url\"\n)\n\ntype throttledHttpClient struct {\n\tclient            httpClient\n\tconnections       semaphore\n\thostThrottlerPool *hostThrottlerPool\n}\n\nfunc newThrottledHttpClient(c httpClient, requestPerSecond int, maxConnections, maxConnectionsPerHost int) httpClient {\n\treturn &throttledHttpClient{\n\t\tc,\n\t\tnewSemaphore(maxConnections),\n\t\tnewHostThrottlerPool(requestPerSecond, maxConnectionsPerHost),\n\t}\n}\n\nfunc (c *throttledHttpClient) Get(u *url.URL, header http.Header) (httpResponse, error) {\n\tc.connections.Request()\n\tdefer c.connections.Release()\n\n\tt := c.hostThrottlerPool.Get(u.Hostname())\n\tt.Request()\n\tdefer t.Release()\n\n\treturn c.client.Get(u, header)\n}\n"
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "xml_page_result.go",
          "type": "blob",
          "size": 1.1826171875,
          "content": "package main\n\ntype xmlPageResult struct {\n\tUrl      string `xml:\"name,attr\"`\n\tTotal    int    `xml:\"tests,attr\"`\n\tFailures int    `xml:\"failures,attr\"`\n\tSkipped  int    `xml:\"skipped,attr\"`\n\t// spell-checker: disable-next-line\n\tLinks []*xmlLinkResult `xml:\"testcase\"`\n}\n\ntype xmlLinkResult struct {\n\tUrl string `xml:\"name,attr\"`\n\t// spell-checker: disable-next-line\n\tSource  string          `xml:\"classname,attr\"`\n\tFailure *xmlLinkFailure `xml:\"failure\"`\n}\n\ntype xmlLinkFailure struct {\n\tMessage string `xml:\"message,attr\"`\n}\n\nfunc newXMLPageResult(pr *pageResult) *xmlPageResult {\n\tls := make([]*xmlLinkResult, 0, len(pr.SuccessLinkResults)+len(pr.ErrorLinkResults))\n\n\tfor _, r := range pr.SuccessLinkResults {\n\t\tls = append(\n\t\t\tls,\n\t\t\t&xmlLinkResult{\n\t\t\t\tUrl:    r.URL,\n\t\t\t\tSource: pr.URL,\n\t\t\t},\n\t\t)\n\t}\n\n\tfor _, r := range pr.ErrorLinkResults {\n\t\tls = append(\n\t\t\tls,\n\t\t\t&xmlLinkResult{\n\t\t\t\tUrl:     r.URL,\n\t\t\t\tSource:  pr.URL,\n\t\t\t\tFailure: &xmlLinkFailure{Message: r.Error.Error()},\n\t\t\t},\n\t\t)\n\t}\n\n\treturn &xmlPageResult{\n\t\tUrl: pr.URL,\n\t\t// TODO: Consider adding information skipped links, if that can be tracked.\n\t\tSkipped:  0,\n\t\tTotal:    len(ls),\n\t\tFailures: len(pr.ErrorLinkResults),\n\t\tLinks:    ls,\n\t}\n}\n"
        },
        {
          "name": "xml_page_result_test.go",
          "type": "blob",
          "size": 0.7607421875,
          "content": "package main\n\nimport (\n\t\"encoding/xml\"\n\t\"errors\"\n\t\"testing\"\n\n\t\"github.com/bradleyjkemp/cupaloy\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestMarshalErrorXMLPageResult(t *testing.T) {\n\tbs, err := marshalXML(newXMLPageResult(\n\t\t&pageResult{\n\t\t\t\"http://foo.com\",\n\t\t\t[]*successLinkResult{},\n\t\t\t[]*errorLinkResult{\n\t\t\t\t{\"http://foo.com/bar\", errors.New(\"baz\")},\n\t\t\t},\n\t\t}))\n\tassert.Nil(t, err)\n\tcupaloy.SnapshotT(t, bs)\n}\n\nfunc TestMarshalSuccessXMLPageResult(t *testing.T) {\n\tbs, err := marshalXML(newXMLPageResult(\n\t\t&pageResult{\n\t\t\t\"http://foo.com\",\n\t\t\t[]*successLinkResult{\n\t\t\t\t{\"http://foo.com/bar\", 200},\n\t\t\t},\n\t\t\t[]*errorLinkResult{},\n\t\t}))\n\tassert.Nil(t, err)\n\tcupaloy.SnapshotT(t, bs)\n}\n\nfunc marshalXML(x any) ([]byte, error) {\n\treturn xml.MarshalIndent(x, \"\", \"  \")\n}\n"
        }
      ]
    }
  ]
}