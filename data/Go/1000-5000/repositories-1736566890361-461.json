{
  "metadata": {
    "timestamp": 1736566890361,
    "page": 461,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQ3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "open-telemetry/opentelemetry-collector-contrib",
      "stars": 3198,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".chloggen",
          "type": "tree",
          "content": null
        },
        {
          "name": ".codecov.yml",
          "type": "blob",
          "size": 0.5498046875,
          "content": "codecov:\n  notify:\n    require_ci_to_pass: yes\n    # wait for unit and integration test builds.\n    after_n_builds: 2\n  strict_yaml_branch: main  # only use the latest copy on main branch\n\ncoverage:\n  precision: 2\n  round: down\n  range: \"80...100\"\n  status:\n    project:\n      default:\n        enabled: yes\n        target: 85%  # This needs to be updated to 90 or higher.\n    patch:\n      default:\n        enabled: yes\n        target: 95%\n\nignore:\n  - \"*/**/third_party/**/*\" # Ignore all 'third_party' directories and files within those directories recursively.\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.1845703125,
          "content": "# This file is documented at https://git-scm.com/docs/gitattributes.\n# Linguist-specific attributes are documented at\n# https://github.com/github/linguist.\n\ngo.sum linguist-generated=true\n\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.3623046875,
          "content": "local/\nvendor/\n\n# GoLand IDEA\n/.idea/\n*.iml\n\n# VS Code\n.vscode\n*.code-workspace\n\n# Project IDX\n.idx/\n\n# Binaries for programs and plugins\n*.exe\n*.exe~\n*.dll\n*.so\n*.dylib\nbin/\ndist/\n.tools/\n\n# Emacs\n*~\n\\#*\\#\n\n# Miscellaneous files\n*.sw[op]\n*.DS_Store\n__debug_bin*\n\n# Coverage\ncoverage/*\n*-coverage.txt\nintegration-coverage.html\n\n# Wix\n*.wixobj\n*.wixpdb\n\ngo.work*\n\n/result\n"
        },
        {
          "name": ".golangci.yml",
          "type": "blob",
          "size": 7.9853515625,
          "content": "# options for analysis running\nrun:\n  # default concurrency is a available CPU number\n  concurrency: 4\n\n  # timeout for analysis, e.g. 30s, 5m, default is 1m\n  timeout: 20m\n\n  # exit code when at least one issue was found, default is 1\n  issues-exit-code: 1\n\n  # include test files or not, default is true\n  tests: true\n\n  # which dirs to skip: issues from them won't be reported;\n  # can use regexp here: generated.*, regexp is applied on full path;\n  # default value is empty list, but default dirs are skipped independently\n  # from this option's value (see exclude-dirs-use-default).\n  exclude-dirs:\n    - third_party\n    - local\n    - cmd/otelcontribcol\n    - cmd/oteltestbedcol\n\n  # default is true. Enables skipping of directories:\n  #   vendor$, third_party$, testdata$, examples$, Godeps$, builtin$\n  exclude-dirs-use-default: false\n\n  # which files to skip: they will be analyzed, but issues from them\n  # won't be reported. Default value is empty list, but there is\n  # no need to include all autogenerated files, we confidently recognize\n  # autogenerated files. If it's not please let us know.\n  skip-files:\n\n  # by default isn't set. If set we pass it to \"go list -mod={option}\". From \"go help modules\":\n  # If invoked with -mod=readonly, the go command is disallowed from the implicit\n  # automatic updating of go.mod described above. Instead, it fails when any changes\n  # to go.mod are needed. This setting is most useful to check that go.mod does\n  # not need updates, such as in a continuous integration and testing system.\n  # If invoked with -mod=vendor, the go command assumes that the vendor\n  # directory holds the correct copies of dependencies and ignores\n  # the dependency descriptions in go.mod.\n  modules-download-mode: readonly\n\n# output configuration options\noutput:\n  # colored-line-number|line-number|json|tab|checkstyle|code-climate, default is \"colored-line-number\"\n  formats: colored-line-number\n\n  # print lines of code with issue, default is true\n  print-issued-lines: true\n\n  # print linter name in the end of issue text, default is true\n  print-linter-name: true\n\n# all available settings of specific linters\nlinters-settings:\n  gci:\n    sections:\n      - standard\n      - default\n      - prefix(github.com/open-telemetry/opentelemetry-collector-contrib)\n\n  govet:\n    # settings per analyzer\n    settings:\n      printf: # analyzer name, run `go tool vet help` to see all analyzers\n        funcs: # run `go tool vet help printf` to see available settings for `printf` analyzer\n          - (github.com/golangci/golangci-lint/pkg/logutils.Log).Infof\n          - (github.com/golangci/golangci-lint/pkg/logutils.Log).Warnf\n          - (github.com/golangci/golangci-lint/pkg/logutils.Log).Errorf\n          - (github.com/golangci/golangci-lint/pkg/logutils.Log).Fatalf\n\n    enable-all: true\n    # TODO: Enable this and fix the alignment issues.\n    disable:\n      - fieldalignment\n      - loopclosure\n\n  revive:\n    # minimal confidence for issues, default is 0.8\n    min-confidence: 0.8\n    rules:\n      # Blank import should be only in a main or test package, or have a comment justifying it.\n      - name: blank-imports\n      # context.Context() should be the first parameter of a function when provided as argument.\n      - name: context-as-argument\n      # Basic types should not be used as a key in `context.WithValue`\n      - name: context-keys-type\n      # Importing with `.` makes the programs much harder to understand\n      - name: dot-imports\n      # Empty blocks make code less readable and could be a symptom of a bug or unfinished refactoring.\n      - name: empty-block\n      # for better readability, variables of type `error` must be named with the prefix `err`.\n      - name: error-naming\n      # for better readability, the errors should be last in the list of returned values by a function.\n      - name: error-return\n      # for better readability, error messages should not be capitalized or end with punctuation or a newline.\n      - name: error-strings\n      # report when replacing `errors.New(fmt.Sprintf())` with `fmt.Errorf()` is possible\n      - name: errorf\n      # incrementing an integer variable by 1 is recommended to be done using the `++` operator\n      - name: increment-decrement\n      # highlights redundant else-blocks that can be eliminated from the code\n      - name: indent-error-flow\n      # This rule suggests a shorter way of writing ranges that do not use the second value.\n      - name: range\n      # receiver names in a method should reflect the struct name (p for Person, for example)\n      - name: receiver-naming\n      # redefining built in names (true, false, append, make) can lead to bugs very difficult to detect.\n      - name: redefines-builtin-id\n      # redundant else-blocks that can be eliminated from the code.\n      - name: superfluous-else\n      # prevent confusing name for variables when using `time` package\n      - name: time-naming\n      # warns when an exported function or method returns a value of an un-exported type.\n      - name: unexported-return\n      # spots and proposes to remove unreachable code. also helps to spot errors\n      - name: unreachable-code\n      # Functions or methods with unused parameters can be a symptom of an unfinished refactoring or a bug.\n      - name: unused-parameter\n      # Since Go 1.18, interface{} has an alias: any. This rule proposes to replace instances of interface{} with any.\n      - name: use-any\n      # report when a variable declaration can be simplified\n      - name: var-declaration\n      # warns when initialism, variable or package naming conventions are not followed.\n      - name: var-naming\n\n  goimports:\n    # put imports beginning with prefix after 3rd-party packages;\n    # it's a comma-separated list of prefixes\n    local-prefixes: github.com/open-telemetry/opentelemetry-collector-contrib\n\n  misspell:\n    # Correct spellings using locale preferences for US or UK.\n    # Default is to use a neutral variety of English.\n    # Setting locale to US will correct the British spelling of 'colour' to 'color'.\n    locale: US\n    ignore-words:\n      - cancelled\n      - metre\n      - meter\n      - metres\n      - kilometre\n      - kilometres\n\n  depguard:\n    rules:\n      denied-deps:\n        deny:\n          - pkg: go.uber.org/atomic\n            desc: \"Use 'sync/atomic' instead of go.uber.org/atomic\"\n          - pkg: github.com/pkg/errors\n            desc: \"Use 'errors' or 'fmt' instead of github.com/pkg/errors\"\n          - pkg: github.com/hashicorp/go-multierror\n            desc: \"Use go.uber.org/multierr instead of github.com/hashicorp/go-multierror\"\n        # Add a different guard rule so that we can ignore tests.\n      ignore-in-test:\n          deny:\n          - pkg: go.opentelemetry.io/proto\n            desc: \"Use go.opentelemetry.io/collector/pdata instead\"\n            # Allow in tests for testing pdata or other receivers/exporters that expect OTLP.\n          files:\n            - \"!**/*_test.go\"\n\n  exhaustive:\n    explicit-exhaustive-switch: true\n    ignore-enum-members: \"pmetric.MetricTypeEmpty\"\n\n  predeclared:\n    ignore: copy\n\n  testifylint:\n    disable:\n      - float-compare\n      - require-error\n      - suite-subtest-run\n      - encoded-compare # has false positives that cannot be fixed with testifylint-fix\n    enable-all: true\n  thelper:\n    test:\n      begin: false\n    benchmark:\n      begin: false\n    tb:\n      begin: false\n    fuzz:\n      begin: false\n\nlinters:\n  enable:\n    - copyloopvar\n    - decorder\n    - depguard\n    - errcheck\n    - errorlint\n    - exhaustive\n    - gci\n    - gocritic\n    - gofumpt\n    - goimports\n    - gosec\n    - govet\n    - misspell\n    - predeclared\n    - reassign\n    - revive\n    - staticcheck\n    - tenv\n    - testifylint\n    - thelper\n    - unconvert\n    - unparam\n    - unused\n    - usestdlibvars\n    - wastedassign\n    - whitespace\n\nissues:\n  # Excluding configuration per-path, per-linter, per-text and per-source\n  exclude-rules:\n    # Exclude some linters from running on tests files.\n    - text: \"G404:\"\n      linters:\n        - gosec\n    - text: \"G402:\"\n      linters:\n        - gosec\n    - text: \"G115:\"\n      linters:\n        - gosec\n"
        },
        {
          "name": "CHANGELOG-API.md",
          "type": "blob",
          "size": 25.1787109375,
          "content": "<!-- This file is autogenerated. See CONTRIBUTING.md for instructions to add an entry. -->\n\n# GO API Changelog\n\nThis changelog includes only developer-facing changes.\nIf you are looking for user-facing changes, check out [CHANGELOG.md](./CHANGELOG.md).\n\n<!-- next version -->\n\n## v0.117.0\n\n### 💡 Enhancements 💡\n\n- `pkg/ottl`: Change OTTL contexts to properly handle `ottl.Path` with context (#29017)\n  The OTTL contexts have a new option `EnablePathContextNames` to enable support for expressing a statement's context via path names in the statement\n\n## v0.116.0\n\n### 🚩 Deprecations 🚩\n\n- `routingprocessor`: Deprecated in favor of the routing connector. (#36616)\n\n### 💡 Enhancements 💡\n\n- `pkg/ottl`: Add the `ottl.ParserCollection` utility to help handling parsers for multiple OTTL contexts (#29017)\n  The `ottl.ParserCollection` groups contexts' `ottl.Parser`s, choosing the suitable one \n  to parse a given statement. It supports context inference using the given statements, \n  and allows prepending the context name to the statements' paths.\n  \n\n## v0.115.0\n\n### 🛑 Breaking changes 🛑\n\n- `pkg/datadog`: Refactor the API that provides metrics translator (#36474)\n  This is API change only and does not affect end users\n\n## v0.114.0\n\n### 🛑 Breaking changes 🛑\n\n- `pkg/stanza`: Changed signature of `emit.Callback` function in `pkg/stanza/fileconsumer/emit` package by introducing `emit.Token` struct that encapsulates the token's body and attributes. (#36260)\n\n### 💡 Enhancements 💡\n\n- `pkg/datadog`: Expose an API `TranslatorFromConfig` that creates a new metrics translator (#36300)\n  This is only code refactor and has no user-facing impact\n\n## v0.113.0\n\n### 🛑 Breaking changes 🛑\n\n- `testbed`: `scenarios.createConfigYaml()` and `utils.CreateConfigYaml()` functions now take processor configs as a struct slice argument instead of `map[string]string`. (#33003)\n  - This is to preserve processor order. `ProcessorNameAndConfigBody` is the newly created struct.\n  \n\n### 💡 Enhancements 💡\n\n- `receiver/prometheusremotewrite`: Implement body unmarshaling for Prometheus Remote Write requests (#35624)\n  Warning - The HTTP Server still doesn't do anything. It's just a placeholder for now.\n\n## v0.112.0\n\n### 🛑 Breaking changes 🛑\n\n- `pkg/translator/jaeger`: Remove error from method signature as it always returns nil (#35560)\n\n### 🚀 New components 🚀\n\n- `pkg/status`: Refactors the extension/healthcheckv2extension/internal/status into pkg/status (#34692)\n\n### 💡 Enhancements 💡\n\n- `pkg/translator/prometheusremotewrite`: add FromMetricsV2 (#33661)\n  The public function is partially implemented and not ready for use\n- `receiver/prometheusremotewrite`: Add HTTP Server to handler Prometheus Remote Write requests (#35535)\n  Warning - The HTTP Server still doesn't do anything. It's just a placeholder for now.\n\n## v0.111.0\n\n### 💡 Enhancements 💡\n\n- `opampsupervisor`: Pass config structure instead of file path when using NewSupervisor function (#34379)\n\n## v0.110.0\n\n### 🛑 Breaking changes 🛑\n\n- `all`: TimeoutSettings/QueueSettings fields in various Config structs are no longer embedded (#35158)\n  Structs in which .TimeoutSettings is no longer embedded:\n  * carbonexporter.Config\n  * googlecloudpubsubreceiver.Config\n  Structs in which .TimeoutSettings and .QueueSettings are no longer embedded:\n  * alertmanagerexporter.Config\n  * googlecloudexporter.Config\n  * googlemanagedprometheusexporter.Config\n  * otelarrowexporter.Config\n  \n\n### 🚩 Deprecations 🚩\n\n- `datadogexporter`: The datadog exporter config has been deprecated in favor of the new `datadog/config` package. The new package is shared between the Datadog exporter and the Datadog Connector.\n (#35067)\n  The new `datadog/config` package is a shared module for Datadog exporter configuration. The module is shared between the Datadog exporter and the Datadog Connector.\n  \n\n### 💡 Enhancements 💡\n\n- `pkg/datadog`: Create a new module for Datadog exporter configuration.\n (#35067)\n  This change introduces a new module for Datadog exporter configuration. The module is shared between the Datadog exporter and the Datadog Connector.\n  \n- `kafkaexporter`: Add option to supply destination topic through context. (#34503, #34432)\n\n## v0.109.0\n\n### 🛑 Breaking changes 🛑\n\n- `pkg/ottl`: Change the OTTL grammar to support expressing statements context via path names (#29017)\n  The `ottl.Path` interface requires a new method: `Context() string`\n- `prometheusreceiver`: Move the TargetAllocator configuration struct to an internal directory (#33146)\n\n### 💡 Enhancements 💡\n\n- `pkg/ottl`: Add support for localized time parsing into the coreinternal/timeutils (#32977)\n- `googlecloudmonitoringreceiver`: Enhancing the Google Cloud monitoring receiver to establish a client connection, scrape GCP Cloud Metrics, and transform them into an OpenTelemetry compatible format for pipeline processing. (#33762)\n  - Implements client connection to Google Cloud Monitoring API.\n  - Scrapes timeseries data based on configured metrics.\n  - Converts the data into OpenTelemetry format for use in the pipeline.\n  \n\n## v0.108.0\n\n### 🛑 Breaking changes 🛑\n\n- `pkg/stanza/operator/input/windows`: Change type name from `EvtRpcLogin` to `EvtRPCLogin`. (#34656)\n\n## v0.107.0\n\n### 🚀 New components 🚀\n\n- `googlecloudmonitoringreceiver`: Adding new component - [Google Cloud monitoring](https://cloud.google.com/monitoring/api/metrics_gcp) receiver to fetch GCP Cloud Metrics and transform to OpenTelemetry compatible format. (#33762)\n\n### 💡 Enhancements 💡\n\n- `internal/grpcutil`: Add internal/grpcutil package with gRPC-specified timeout parsing (#33688)\n- `pmetrictest`: Add support for histogram comparison options (#34521)\n- `kafkaexporter`: add an ability to partition logs based on resource attributes. (#33229)\n\n## v0.106.1\n\n## v0.106.0\n\n## v0.105.0\n\n## v0.104.0\n\n### 🛑 Breaking changes 🛑\n\n- `exporter/clickhouse`: Unexport extra configuration methods. (#33647)\n- `exporter/clickhouse`: Change internal config type for `create_schema` to use a `bool` instead of `*bool` (#33694)\n- `pkg/ottl`: Changed ScopeContext, InstrumentationResourceContext, TransformContext interfaces to make SchemaURL accessible in resources and scopes on all signals (#30229)\n\n### 💡 Enhancements 💡\n\n- `pkg/ottl`: Add ByteSliceLikeGetter interface (#31929)\n\n## v0.103.0\n\n### 🛑 Breaking changes 🛑\n\n- `stanza`: remove deprecated code (#33519)\n  This change removes:\n    - adapter.LogEmitter, use helper.LogEmitter instead\n    - adapter.NewLogEmitter, use helper.NewLogEmitter instead\n    - fileconsumer.Manager's SugaredLogger struct member\n    - pipeline.DirectedPipeline's SugaredLogger struct member\n    - testutil.Logger, use zaptest.NewLogger instead\n  \n\n### 💡 Enhancements 💡\n\n- `pkg/winperfcounters`: It is now possible to force a `watcher` to re-create the PDH query of a given counter via the `Reset()` function. (#32798)\n\n## v0.102.0\n\n### 💡 Enhancements 💡\n\n- `prometheusreceiver`: Allow to configure http client used by target allocator generated scrape targets (#18054)\n\n### 🧰 Bug fixes 🧰\n\n- `exp/metrics`: fixes staleness.Evict such that it only ever evicts actually stale metrics (#33265)\n\n## v0.101.0\n\n### 🛑 Breaking changes 🛑\n\n- `opampextension`: Move custom message interfaces to separate package (#32950)\n  Moves `CustomCapabilityRegistry`, `CustomCapabilityHandler`, and `CustomCapabilityRegisterOption` to a new module.\n  These types can now be found in the new `github.com/open-telemetry/opentelemetry-collector-contrib/extension/opampcustommessages` module.\n  \n- `pkg/stanza`: The internal logger has been changed from zap.SugaredLogger to zap.Logger. (#32177)\n  Functions accepting a SugaredLogger, and fields of type SugaredLogger, have been deprecated.\n\n### 💡 Enhancements 💡\n\n- `testbed`: Add the use of connectors to the testbed (#30165)\n\n## v0.100.0\n\n### 🛑 Breaking changes 🛑\n\n- `pkg/stanza`: Pass TelemetrySettings to the Build method of the Builder interface (#32662, #31256)\n  The reason for this breaking change is to pass in the component.TelemetrySettings\n  so as to use them later in various ways:\n    - be able to report state statistics and telemetry in general\n    - be able to switch from SugaredLogger to Logger\n  \n\n### 🚩 Deprecations 🚩\n\n- `confmap/provider/s3`: Deprecate `s3provider.New` in favor of `s3provider.NewFactory` (#32742)\n- `confmap/provider/secretsmanager`: Deprecate `secretsmanagerprovider.New` in favor of `secretsmanagerprovider.NewFactory` (#32743)\n\n### 🚀 New components 🚀\n\n- `roundrobinconnector`: Add a roundrobin connector, that can help single thread components to scale (#32853)\n\n### 💡 Enhancements 💡\n\n- `opampextension`: Added support for other components to register custom capabilities and receive custom messages from an opamp extension (#32021)\n- `kafkaexporter`: add an ability to publish kafka messages with message key based on metric resource attributes - it will allow partitioning metrics in Kafka. (#29433, #30666, #31675)\n- `sshcheckreceiver`: Add support for running this receiver on Windows (#30650)\n\n## v0.99.0\n\n### 💡 Enhancements 💡\n\n- `prometheusremotewrite`: Optimize the prometheusremotewrite.FromMetrics function, based around more performant metric identifier hashing. (#31385)\n- `pkg/pdatatest/plogtest`: Add an option to ignore log timestamp (#32540)\n- `filelogreceiver`: Add `exclude_older_than` configuration setting (#31053)\n\n## v0.98.0\n\n### 💡 Enhancements 💡\n\n- `pkg/sampling`: Usability improvements in the sampling API. (#31918)\n\n## v0.97.0\n\n### 🛑 Breaking changes 🛑\n\n- `datadogexporter`: Remove config structs `LimitedClientConfig` and `LimitedTLSClientSettings` (#31733)\n  This should have no impact to end users as long as they do not import Datadog exporter config structs in their source code.\n- `cmd/mdatagen`: Delete deprecated cmd/mdatagen from this project. Use go.opentelemetry.io/collector/cmd/mdatagen instead. (#30497)\n- `azuremonitorreceiver`: Reduce the public API for this receiver. (#24850)\n  This unexports the following types ArmClient, MetricsDefinitionsClientInterface, MetricsValuesClient.\n- `general`: Update any component using `scraperhelper.ScraperControllerSettings` to use `scraperhelper.ControllerConfig` (#31816)\n  This changes the config field name from `ScraperControllerSettings` to `ControllerConfig`\n- `prometheusreceiver`: Remove enable_protobuf_negotiation option on the prometheus receiver. Use config.global.scrape_protocols = [ PrometheusProto, OpenMetricsText1.0.0, OpenMetricsText0.0.1, PrometheusText0.0.4 ] instead. (#30883)\n  See https://prometheus.io/docs/prometheus/latest/configuration/configuration/#configuration-file for details on setting scrape_protocols.\n\n### 🚩 Deprecations 🚩\n\n- `pkg/stanza`: Deprecate fileconsumer.BuildWithSplitFunc in favor of Build with options pattern (#31596)\n\n### 💡 Enhancements 💡\n\n- `clickhouseexporter`: Allow configuring `ON CLUSTER` and `ENGINE` when creating database and tables (#24649)\n  Increases table creation flexibility with the ability to add replication for fault tolerance\n- `all`: Remove explicit checks in all receivers to check if the next consumer is nil (#31793)\n  The nil check is now done by the pipeline builder.\n\n## v0.96.0\n\n### 🛑 Breaking changes 🛑\n\n- `cmd/mdatagen`: Use enum for stability levels in the Metadata struct (#31530)\n- `httpforwarder`: Remove extension named httpforwarder, use httpforwarderextension instead. (#24171)\n\n## v0.95.0\n\n### 🛑 Breaking changes 🛑\n\n- `pkg/stanza`: Remove deprecated pkg/stanza/attrs (#30449)\n- `httpforwarderextension`: Rename the extension httpforwarder to httpforwarderextension (#24171)\n- `extension/storage`: The `filestorage` and `dbstorage` extensions are now standalone modules. (#31040)\n  If using the OpenTelemetry Collector Builder, you will need to update your import paths to use the new module(s).\n  - `github.com/open-telemetry/opentelemetry-collector-contrib/extension/storage/filestorage`\n  - `github.com/open-telemetry/opentelemetry-collector-contrib/extension/storage/dbstorage`\n  \n\n### 💡 Enhancements 💡\n\n- `pkg/golden`: Added an option to skip the metric timestamp normalization for WriteMetrics. (#30919)\n- `healthcheckextension`: Remove usage of deprecated `host.ReportFatalError` (#30582)\n\n## v0.94.0\n\n### 🚩 Deprecations 🚩\n\n- `testbed`: Deprecate testbed.GetAvailablePort in favor of testutil.GetAvailablePort (#30811)\n  Move healthcheckextension to use testutil.GetAvailablePort\n\n### 🚀 New components 🚀\n\n- `pkg_sampling`: Package of code for parsing OpenTelemetry tracestate probability sampling fields. (#29738)\n\n## v0.93.0\n\n### 🛑 Breaking changes 🛑\n\n- `testbed`: Remove unused AWS XRay mock receiver (#30381)\n- `docker`: Adopt api_version as strings to correct invalid float truncation (#24025)\n- `prometheusreceiver`: Consolidate Config members and remove the need of placeholders. (#29901)\n- `all`: Remove obsolete \"// +build\" directive (#30651)\n- `testbed`: Expand TestCase capabilities with broken out LoadGenerator interface (#30303)\n\n### 🚩 Deprecations 🚩\n\n- `pkg/stanza`: Deprecate pkg/stanza/attrs package in favor of pkg/stanza/fileconsumer/attrs (#30449)\n\n### 💡 Enhancements 💡\n\n- `testbed`: Adds and adopts new WithEnvVar child process option, moving GOMAXPROCS=2 to initializations (#30491)\n\n## v0.92.0\n\n### 🛑 Breaking changes 🛑\n\n- `carbonexporter`: Change Config member names (#29862)\n- `carbonreceiver`: Hide unnecessary public API (#29895)\n- `pkg/ottl`: Unexport `ADD`, `SUB`, `MULT`, `DIV`, `EQ`, `NE`, `LT`, `LTE`, `GT`, and `GTE` (#29925)\n- `pkg/ottl`: Change `Path` to be an Interface instead of the grammar struct. (#29897)\n  Affects creators of custom contexts.\n- `golden`: Use testing.TB for golden.WriteMetrics, golden.WriteTraces and golden.WriteLogs over *testing.T (#30277)\n\n### 💡 Enhancements 💡\n\n- `kafkaexporter`: add ability to publish kafka messages with message key of TraceID - it will allow partitioning of the kafka Topic. (#12318)\n- `kafkaexporter`: Adds the ability to configure the Kafka client's Client ID. (#30144)\n\n## v0.91.0\n\n### 🛑 Breaking changes 🛑\n\n- `pkg/ottl`: Rename `Statements` to `StatementSequence`. Remove `Eval` function from `StatementSequence`, use `ConditionSequence` instead. (#29598)\n\n### 💡 Enhancements 💡\n\n- `pkg/ottl`: Add `ConditionSequence` for evaluating lists of conditions (#29339)\n\n## v0.90.0\n\n### 🛑 Breaking changes 🛑\n\n- `clickhouseexporter`: Replace `Config.QueueSettings` field with `exporterhelper.QueueSettings` and remove `QueueSettings` struct (#27653)\n- `kafkareceiver`: Do not export the function `WithTracesUnmarshalers`, `WithMetricsUnmarshalers`, `WithLogsUnmarshalers` (#26304)\n\n### 💡 Enhancements 💡\n\n- `datadogreceiver`: The datadogreceiver supports the new datadog protocol that is sent by the datadog agent API/v0.2/traces. (#27045)\n- `pkg/ottl`: Add ability to independently parse OTTL conditions. (#29315)\n\n### 🧰 Bug fixes 🧰\n\n- `cassandraexporter`: Exist check for keyspace and dynamic timeout (#27633)\n\n## v0.89.0\n\n### 🛑 Breaking changes 🛑\n\n- `carbonreceiver`: Do not export function New and pass checkapi. (#26304)\n- `collectdreceiver`: Move to use confighttp.HTTPServerSettings (#28811)\n- `kafkaexporter`: Do not export function WithTracesMarshalers, WithMetricsMarshalers, WithLogsMarshalers and pass checkapi (#26304)\n- `remoteobserverprocessor`: Rename remoteobserverprocessor to remotetapprocessor (#27873)\n\n### 💡 Enhancements 💡\n\n- `extension/encoding`: Introduce interfaces for encoding extensions. (#28686)\n- `exporter/awss3exporter`: This feature allows role assumption for s3 exportation. It is especially useful on Kubernetes clusters that are using IAM roles for service accounts (#28674)\n\n## v0.88.0\n\n### 🚩 Deprecations 🚩\n\n- `pkg/stanza`: Deprecate 'flush.WithPeriod'. Use 'flush.WithFunc' instead. (#27843)\n\n## v0.87.0\n\n### 🛑 Breaking changes 🛑\n\n- `exporter/kafka, receiver/kafka, receiver/kafkametrics`: Move configuration parts to an internal pkg (#27093)\n- `pulsarexporter`: Do not export function WithTracesMarshalers, add test for that and pass checkapi (#26304)\n- `pulsarreceiver`: Do not export the functions `WithLogsUnmarshalers`, `WithMetricsUnmarshalers`, `WithTracesUnmarshalers`, add tests and pass checkapi. (#26304)\n\n### 💡 Enhancements 💡\n\n- `mdatagen`: allows adding warning section to resource_attribute configuration (#19174)\n- `mdatagen`: allow setting empty metric units (#27089)\n\n## v0.86.0\n\n### 🛑 Breaking changes 🛑\n\n- `azuremonitorexporter`: Unexport `Accept` to comply with checkapi (#26304)\n- `tailsamplingprocessor`: Unexport `SamplingProcessorMetricViews` to comply with checkapi (#26304)\n- `awskinesisexporter`: Do not export the functions `NewTracesExporter`, `NewMetricsExporter`, `NewLogsExporter` and pass checkapi. (#26304)\n- `dynatraceexporter`: Rename struct to keep expected `exporter.Factory` and pass checkapi. (#26304)\n- `ecsobserver`: Do not export the function `DefaultConfig` and pass checkapi. (#26304)\n- `f5cloudexporter`: Do not export the function `NewFactoryWithTokenSourceGetter` and pass checkapi. (#26304)\n- `fluentforwardreceiver`: rename `Logs` and `DetermineNextEventMode` functions and all usage to lowercase to stop exporting method and pass checkapi (#26304)\n- `groupbyattrsprocessor`: Do not export the function `MetricViews` and pass checkapi. (#26304)\n- `groupbytraceprocessor`: Do not export the function `MetricViews` and pass checkapi. (#26304)\n- `jaegerreceiver`: Do not export the function `DefaultServerConfigUDP` and pass checkapi. (#26304)\n- `lokiexporter`: Do not export the function `MetricViews` and pass checkapi. (#26304)\n- `mongodbatlasreceiver`: Rename struct to pass checkapi. (#26304)\n- `mongodbreceiver`: Do not export the function `NewClient` and pass checkapi. (#26304)\n- `mysqlreceiver`: Do not export the function `Query` (#26304)\n- `pkg/ottl`: Remove support for `ottlarg`. The struct's field order is now the function parameter order. (#25705)\n- `pkg/stanza`: Make trim func composable (#26536)\n  - Adds trim.WithFunc to allow trim funcs to wrap bufio.SplitFuncs.\n  - Removes trim.Func from split.Config.Func. Use trim.WithFunc instead.\n  - Removes trim.Func from flush.WithPeriod. Use trim.WithFunc instead.\n  \n- `pkg/stanza`: Rename syslog and tcp MultilineBuilders (#26631)\n  - Rename syslog.OctetMultiLineBuilder to syslog.OctetSplitFuncBuilder\n  - Rename tc.MultilineBuilder to tcp.SplitFuncBuilder\n  \n- `probabilisticsamplerprocessor`: Do not export the function `SamplingProcessorMetricViews` and pass checkapi. (#26304)\n- `sentryexporter`: Do not export the functions `CreateSentryExporter` and pass checkapi. (#26304)\n- `sumologicexporter`: Do not export the function `CreateDefaultHTTPClientSettings` and pass checkapi. (#26304)\n\n### 💡 Enhancements 💡\n\n- `pkg/ottl`: Add support for optional parameters (#20879)\n  The new `ottl.Optional` type can now be used in a function's `Arguments` struct\n  to indicate that a parameter is optional.\n  \n\n## v0.85.0\n\n### 🛑 Breaking changes 🛑\n\n- `alibabacloudlogserviceexporter`: Do not export the function `NewLogServiceClient` (#26304)\n- `awss3exporter`: Do not export the function `NewMarshaler` (#26304)\n- `statsdreceiver`: rename and do not export function `New` to `newReceiver` to pass checkapi (#26304)\n- `chronyreceiver`: Removes duplicate `Timeout` field. This change has no impact on end users of the component. (#26113)\n- `dockerstatsreceiver`: Removes duplicate `Timeout` field. This change has no impact on end users of the component. (#26114)\n- `elasticsearchexporter`: Do not export the function `DurationAsMicroseconds` (#26304)\n- `jaegerexporter`: Do not export the function `MetricViews` (#26304)\n- `k8sobjectsreceiver`: Do not export the function `NewTicker` (#26304)\n- `pkg/stanza`: Rename 'pkg/stanza/decoder' to 'pkg/stanza/decode' (#26340)\n- `pkg/stanza`: Move tokenize.SplitterConfig.Encoding to fileconsumer.Config.Encoding (#26511)\n- `pkg/stanza`: Remove Flusher from tokenize.SplitterConfig (#26517)\n  Removes the following in favor of flush.WithPeriod - tokenize.DefaultFlushPeriod - tokenize.FlusherConfig - tokenize.NewFlusherConfig\n- `pkg/stanza`: Remove tokenize.SplitterConfig (#26537)\n- `pkg/stanza`: Rename \"tokenize\" package to \"split\" (#26540)\n  - Remove 'Multiline' struct\n  - Remove 'NewMultilineConfig' struct\n  - Rename 'MultilineConfig' to 'split.Config'\n  \n- `pkg/stanza`: Extract whitespace trim configuration into trim.Config (#26511)\n  - PreserveLeading and PreserveTrailing removed from tokenize.SplitterConfig.\n  - PreserveLeadingWhitespaces and PreserveTrailingWhitespaces removed from tcp.BaseConfig and udp.BaseConfig.\n  \n\n### 💡 Enhancements 💡\n\n- `oauth2clientauthextension`: Enable dynamically reading ClientID and ClientSecret from files (#26117)\n  - Read the client ID and/or secret from a file by specifying the file path to the ClientIDFile (`client_id_file`) and ClientSecretFile (`client_secret_file`) fields respectively.\n  - The file is read every time the client issues a new token. This means that the corresponding value can change dynamically during the execution by modifying the file contents.\n  \n\n## v0.84.0\n\n### 🛑 Breaking changes 🛑\n\n- `memcachedreceiver`: Removes duplicate `Timeout` field. This change has no impact on end users of the component. (#26084)\n- `podmanreceiver`: Removes duplicate `Timeout` field. This change has no impact on end users of the component. (#26083)\n- `zookeeperreceiver`: Removes duplicate `Timeout` field. This change has no impact on end users of the component. (#26082)\n- `jaegerreceiver`: Deprecate remote_sampling config in the jaeger receiver (#24186)\n  The jaeger receiver will fail to start if remote_sampling config is specified in it.  The `receiver.jaeger.DisableRemoteSampling` feature gate can be set to let the receiver start and treat  remote_sampling config as no-op. In a future version this feature gate will be removed and the receiver will always  fail when remote_sampling config is specified.\n  \n- `pkg/ottl`: use IntGetter argument for Substring function (#25852)\n- `pkg/stanza`: Remove deprecated 'helper.Encoding' and 'helper.EncodingConfig.Build' (#25846)\n- `pkg/stanza`: Remove deprecated fileconsumer config structs (#24853)\n  Includes | - MatchingCriteria - OrderingCriteria - NumericSortRule - AlphabeticalSortRule - TimestampSortRule\n- `googlecloudexporter`: remove retry_on_failure from the googlecloud exporter. The exporter itself handles retries, and retrying can cause issues. (#57233)\n\n### 🚩 Deprecations 🚩\n\n- `pkg/stanza`: Deprecate 'helper.EncodingConfig' and 'helper.NewEncodingConfig' (#25846)\n- `pkg/stanza`: Deprecate encoding related elements of helper pacakge, in favor of new decoder package (#26019)\n  Includes the following deprecations | - Decoder - NewDecoder - LookupEncoding - IsNop\n- `pkg/stanza`: Deprecate tokenization related elements of helper pacakge, in favor of new tokenize package (#25914)\n  Includes the following deprecations | - Flusher - FlusherConfig - NewFlusherConfig - Multiline - MultilineConfig - NewMultilineConfig - NewLineStartSplitFunc - NewLineEndSplitFunc - NewNewlineSplitFunc - Splitter - SplitterConfig - NewSplitterConfig - SplitNone\n\n### 💡 Enhancements 💡\n\n- `googlemanagedprometheus`: Add a `add_metric_suffixes` option to the googlemanagedprometheus exporter. When set to false, metric suffixes are not added. (#26071)\n- `receiver/prometheus`: translate units from prometheus to UCUM (#23208)\n\n### 🧰 Bug fixes 🧰\n\n- `receiver/influxdb`: add allowable inputs to line protocol precision parameter (#24974)\n\n## v0.83.0\n\n### 🛑 Breaking changes 🛑\n\n- `exporter/clickhouse`: Change the type of `Config.Password` to be `configopaque.String` (#17273)\n- `all`: Remove go 1.19 support, bump minimum to go 1.20 and add testing for 1.21 (#8207)\n- `solacereceiver`: Move model package to the internal package (#24890)\n- `receiver/statsdreceiver`: Move protocol and transport packages to internal (#24892)\n- `filterprocessor`: Unexport `Strict` and `Regexp` (#24845)\n- `mdatagen`: Rename the mdatagen sum field `aggregation` to `aggregation_temporality` (#16374)\n- `metricstransformprocessor`: Unexport elements of the Go API of the processor (#24846)\n- `mezmoexporter`: Unexport the `MezmoLogLine` and `MezmoLogBody` structs (#24842)\n- `pkg/stanza`: Remove deprecated 'fileconsumer.FileAttributes' (#24688)\n- `pkg/stanza`: Remove deprecated 'fileconsumer.EmitFunc' (#24688)\n- `pkg/stanza`: Remove deprecated `fileconsumer.Finder` (#24688)\n- `pkg/stanza`: Remove deprecated `fileconsumer.BaseSortRule` and `fileconsumer.SortRuleImpl` (#24688)\n- `pkg/stanza`: Remove deprecated 'fileconsumer.Reader' (#24688)\n\n### 🚩 Deprecations 🚩\n\n- `pkg/stanza`: Deprecate helper.Encoding and helper.EncodingConfig.Build (#24980)\n- `pkg/stanza`: Deprecate fileconsumer MatchingCriteria in favor of new matcher package (#24853)\n\n### 💡 Enhancements 💡\n\n- `changelog`: Generate separate changelogs for end users and package consumers (#24014)\n- `splunkhecexporter`: Add heartbeat check while startup and new config param, heartbeat/startup (defaults to false). This is different than the healtcheck_startup, as the latter doesn't take token or index into account. (#24411)\n- `k8sclusterreceiver`: Allows disabling metrics and resource attributes (#24568)\n- `cmd/mdatagen`: Avoid reusing the same ResourceBuilder instance for multiple ResourceMetrics (#24762)\n\n### 🧰 Bug fixes 🧰\n\n- `splunkhecreceiver`: aligns success resp body w/ splunk enterprise (#19219)\n  changes resp from plaintext \"ok\" to json {\"text\"：\"success\", \"code\"：0}\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 535.09765625,
          "content": "<!-- This file is autogenerated. See CONTRIBUTING.md for instructions to add an entry. -->\n\n# Changelog\n\nStarting with version v0.83.0, this changelog includes only user-facing changes.\nIf you are looking for developer-facing changes, check out [CHANGELOG-API.md](./CHANGELOG-API.md).\n\n<!-- next version -->\n\n## v0.117.0\n\n### 🛑 Breaking changes 🛑\n\n- `cloudfoundryreceiver`: Introduce a feature gate enable copying envelope tags to the metrics as resource attributes instead of datapoint attributes. (#34824)\n- `pkg/ottl`: removed the ability to reference entire parent objects. (#36872)\n  Statements like `set(cache[\"resource\"], resource)` in non-resource contexts will no longer work. \n  \n- `routingconnector`: Change default value of `match_once` parameter to `true`. (#29882)\n  This field was deprecated in v0.116.0 and will be removed in v0.120.0.\n\n### 🚩 Deprecations 🚩\n\n- `sapmexporter`: Deprecate SAPM exporter (#36028)\n  The SAPM exporter is being marked as deprecated. Please use the `otlphttp` exporter with the configuration shown\n  below. Also update your pipeline configuration for Traces accordingly.\n  ```yaml\n    exporters:\n        otlphttp:\n            traces_endpoint: \"${SPLUNK_INGEST_URL}/v2/trace/otlp\"\n            headers:\n                \"X-SF-Token\": \"${SPLUNK_ACCESS_TOKEN}\"\n    ```\n  \n\n### 🚀 New components 🚀\n\n- `libhoneyreceiver`: Mark the libhoney receiver exporter as Alpha. (#36693)\n\n### 💡 Enhancements 💡\n\n- `k8sclusterreceiver`: Add additional attributes to node and pod entities (#35879)\n  Adds the following attributes to node and pod metadata/entities:\n    - `k8s.pod.phase`: The phase of a Pod indicates where the Pod is in its lifecycle. E.g. 'Pending', 'Running'\n    - `k8s.pod.status_reason`: A brief message indicating details about why the pod is in this state. E.g. 'Evicted'\n    - `k8s.node.condition_*`: The condition of a node. e.g. `k8s.node.condition_ready`. The value can be `true`, `false`, `unknown`.\n  \n- `awsxrayexporter`: merge in latest semantic conventions for awsxrayexporter. (#36894)\n- `receivercreator`: Add support for starting logs' collection based on provided k8s annotations' hints (#34427)\n- `opensearchexporter`: Add Sending Queue to enable persistent queue in case of upstream failure (#33919)\n- `libhoneyreceiver`: Implement log signal for libhoney receiver (#36693)\n- `ottl`: Add a new ottl trim function that trims leading and trailing characters from a string (default- whitespace). (#34100)\n- `exporter/prometheusremotewrite`: In preparation to re-introducing multiple workers, we're removing a data-race when batching timeseries. (#36601)\n- `redisstorageextension`: Move redis storage extension to alpha (#36778)\n- `logzioexporter`: Remove jaeger dbmodel dependency. (#36972)\n- `sigv4authextension`: Add support for endpoint based names for logs and traces (#36828)\n- `awsemfexporter`: Split EMF log to multiple log splits when buckets larger than 100. (#36771)\n- `sqlqueryreceiver`: Add instrumentation scope to SQL query receiver metrics and logs (#31028)\n- `statsdreceiver`: Add UDS support to statsdreceiver (#21385)\n- `tailsamplingprocessor`: Support hot sampling policy loading (#37014)\n- `cmd/telemetrygen`: Introduce support for generating histograms in telemetrygen (#36322)\n- `libhoneyreceiver`: Implement trace signal for libhoney receiver (#36693)\n\n### 🧰 Bug fixes 🧰\n\n- `receiver/azureeventhub`: Ensure that observed timestamp is set when unmarshaling logs. (#36861)\n- `internal/docker`: Fix image matching regular expression to properly match SHA256 strings. (#36239)\n  This affects the `docker_observer` extension.\n- `opampsupervisor`: Report an 'Applied' remote config status when an empty config is received. (#36682)\n- `k8sobjectsreceiver`: ensure the `k8s.namespace.name` attribute is set for objects retrieved using the `watch` mode (#36352)\n- `mongodbatlasreceiver`: Update the mongoDB Atlas receiver to use the Default HTTP Transport that supports default proxy configuration (#36412)\n- `mysqlreceiver`: Avoid recording a value for the MysqlBufferPoolPages metric when out-of-bounds. (#35495)\n  When using compressed tables, Innodb_buffer_pool_pages_misc may report an out-of-bounds value.\n  See https://bugs.mysql.com/bug.php?id=59550 for context.\n  \n- `pkg/ottl`: fix handling of nested maps within slices in the `flatten` function (#36162)\n- `mysqlreceiver`: Divide large values directly in SQL queries to avoid int overflows (#35495)\n\n## v0.116.0\n\n### 🛑 Breaking changes 🛑\n\n- `jsonlogencodingextension`: Change how logs are marshaled. Instead of marshaling just the first log, marshal all logs into a JSON array. (#34064)\n- `githubreceiver`: Update metric names to match VCS Metric Semantic Conventions and scraper key name. (#36714)\n  * Change the `github` scraper key to `scraper`\n  * Add `vcs.repository.url.full` attribute\n  * Change attribute `repository.name` to `vcs.repository.name`\n  * Change attribute `ref.name` to `vcs.ref.head.name`\n  * Change attribute `ref.type` to `vcs.ref.head.type`\n  * Change attribute `change.state` to `vcs.change.state`\n  * Add attribute `vcs.revision_delta.direction` with `ahead` and `behind` values\n  * Change metric `vcs.repository.ref.revisions_ahead` to `vcs.ref.revisions_delta` with `vcs.revision_delta.direction=ahead`\n  * Change metric `vcs.repository.ref.revisions_behind` to `vcs.ref.revisions_delta` with `vcs.revision_delta.direction=behind`\n  * Change metric `vcs.repository.ref.count` to `vcs.ref.count`\n  * Change metric `vcs.repository.ref.time` to `vcs.ref.time`\n  * Add attribute `vcs.line_change.type` with `added` and `removed` values\n  * Change metric `vcs.repository.ref.lines_added` to `vcs.ref.lines_delta` with `vcs.line_change.type=added`\n  * Change metric `vcs.repository.ref.lines_removed` to `vcs.ref.lines_delta` with `vcs.line_change.type=removed`\n  * Change metric `vcs.repository.contributor.count` to `vcs.contributor.count`\n  * Change metric `vcs.repository.change.time_open` to `vcs.change.duration` with `vcs.change.state=open`\n  * Change metric `vcs.repository.change.time_to_approval` to `vcs.change.time_to_approval`\n  * Change metric `vcs.repository.change.time_to_merge` to `vcs.change.time_to_merge`\n  * Change metric `vcs.repository.change.count` to `vcs.change.count`\n  \n- `processor/tailsampling`: Reverts #33671, allowing for composite policies to specify inverted clauses in conjunction with other policies. This is a change bringing the previous state into place, breaking users who rely on what was introduced as part of #33671. (#34085)\n\n### 🚩 Deprecations 🚩\n\n- `connector/routing`: Deprecate `match_once` parameter. (#29882)\n- `routingprocessor`: Deprecated in favor of the routing connector. (#36616)\n- `splunkhecexporter`: Add `otel_attrs_to_hec_metadata/*` config fields to replace `hec_metadata_to_otel_attrs/*` fields. (#35092)\n  `otel_attrs_to_hec_metadata/*` config fields will replace the `hec_metadata_to_otel_attrs/*` fields in a later release.\n  \n- `kineticaexporter`: The kineticaexporter is now Unmaintained as it has no active code owners from the vendor (#36808)\n\n### 🚀 New components 🚀\n\n- `dorisexporter`: Mark the Doris exporter as Alpha. (#33479)\n- `libhoneyreceiver`: Introduce the scaffolding of a new component, libhoneyreceiver (#36693)\n\n### 💡 Enhancements 💡\n\n- `purefareceiver`: Implements support for scraping Pure Storage FlashArray with Purity version 6.6.11+ (#36251)\n- `azureeventhubreceiver`: support providing one or more time formats for timestamp parsing (#36650)\n- `googlecloudmonitoringreceiver`: Add metric-specific labels to googlecloudmonitoringreceiver component (#35711)\n- `awss3receiver`: Add support RFC3339 format for starttime and endtime (#36787)\n- `awsxrayexporter`: Generate url section in xray segment when `net.peer.name` is available (#35375)\n- `clickhouseexporter`: Exporter now sorts attribute maps' keys during INSERT, yielding better compression and predictable aggregates (#33634)\n- `datadogconnector`: Flip configs `traces::compute_stats_by_span_kind`, `traces::peer_tags_aggregation` and `traces::peer_service_aggregation` to true by default (#35969)\n  This enables Datadog APM stats on peer tags by default and is a backwards-compatible change. Read more on https://docs.datadoghq.com/tracing/guide/inferred-service-opt-in/.\n- `datadogexporter`: Flip configs `traces::compute_stats_by_span_kind`, `traces::peer_tags_aggregation` and `traces::peer_service_aggregation` to true by default (#35969)\n  This enables Datadog APM stats on peer tags by default and is a backwards-compatible change. Read more on https://docs.datadoghq.com/tracing/guide/inferred-service-opt-in/.\n- `elasticsearchexporter`: Map *.geo.location.{lat,lon} as geo_point field in OTel mode (#36565)\n  In OTel mapping mode, merge *.geo.location.{lat,lon} to *.geo.location such that they are stored as geo_point in Elasticsearch.\n- `fileexporter`: Add support for profiles signal. (#35978)\n- `pkg/ottl`: GetXML Converter now supports selecting text, CDATA, and attribute (value) content. (#36821)\n- `githubreceiver`: Adds webhook skeleton to GitHub receiver to receive events from GitHub for tracing. (#27460)\n  This PR adds a skeleton for the GitHub receiver to receive events from GitHub\n  for tracing via a webhook. The trace portion of this receiver will run and\n  respond to GET requests for the health check only.\n  \n- `kafkaexporter, kafkareceiver`: Add a new mechanism \"AWS_MSK_IAM_OAUTHBEARER\" for kafka exporter and kafka receiver. This mechanism use the AWS MSK IAM SASL Signer for Go https://github.com/aws/aws-msk-iam-sasl-signer-go. (#19747)\n- `loadbalancingexporter`: Adds a an optional configuration to the k8s resolver which returns hostnames instead of IPs for headless services pointing at statefulsets (#18412)\n- `mongodbatlasreceiver`: Adds additional metrics to the MongoDB Atlas receiver (#36525)\n  Adds a number of new default disabled metrics to the MongoDB Atlas receiver. These metrics are:\n  - mongodbatlas.disk.partition.queue.depth\n  - mongodbatlas.disk.partition.throughput\n  - mongodbatlas.process.cache.ratio\n  \n- `s3exporter`: Upgrading to adopt aws sdk v2 (#36699)\n- `opampextension`: Use status subscription for fine granular component health reporting (#35856)\n- `pkg/pdatatest`: Add support for Profiles signal comparison. (#36232)\n- `receiver/prometheusremotewrite`: Parse labels from Prometheus Remote Write requests into Resource and Metric Attributes. (#35656)\n  Warning - The HTTP Server still doesn't pass metrics to the next consumer. The component is unusable for now.\n- `signaltometrics`: Add config validation and custom OTTL functions (#35930)\n  Adds config validation for the signal to metrics connector. Also introduces `AdjustedCount` OTTL function.\n- `testbed`: Add batcher performance tests (#36206)\n- `tesbed`: add options for retry/storage for filelog sender (#36781)\n\n### 🧰 Bug fixes 🧰\n\n- `azuremonitorexporter`: fix bug to remove default config of endpoint which causes failing to parse endpoint correctly. (#36704)\n- `receiver/prometheusreceiver`: Metric adjuster no longer assumes that all metrics from a scrape come from the same resource (#36477)\n- `connector/datadog, exporter/datadog, pkg/datadog`: throw error if datadog API key contains invalid characters (#36509)\n- `parseutils`: Handle escaped quotes when parsing pairs using SplitString. (#36176)\n- `exporter/prometheusremotewrite`: Fix exemplar handling when the exemplar is an integer value. (#36657)\n  Send metrics with exemplars as integer values now are correctly handled.\n- `googlecloudmonitoringreceiver`: Fix \"no validation found\" error if workload is running on Google Cloud Platform (#36607)\n- `k8sattributesprocessor`: Override extracted k8s attributes if original value has been empty (#36373)\n- `k8sattributesreceiver`: Log any errors encountered during kube client initialisation (#35879)\n  This addresses an issue where the collector, due to an error encountered during the kubernetes client initialisation,\n  was reporting an 'unavailable' status via the health check extension without any further information to be found in the logs.\n  \n- `opampextension`: Fix blocking agent shutdown due to unclosed channel (#36764)\n- `opampsupervisor`: avoid nil pointer access when reporting the last received remote config (#36850)\n- `postgresqlreceiver`: Update the postgresqlreceiver to handle new table schema for the bgwriter metrics in pg17+ (#36784)\n- `jaegerreceiver`: Remove ineffectual warning from jaegerreceiver (#35894)\n- `datadogexporter`: read response body on pushSketches to allow connection re-use (#36779)\n- `sumologicextension`: Skip likely zombie processes on Windows. (#36481)\n\n## v0.115.0\n\n### 🛑 Breaking changes 🛑\n\n- `awsfirehosereceiver`: Follow receiver contract based on type of error (#5909)\n- `elasticsearchexporter`: Respect `flush::bytes` in sync bulk indexer, `flush::bytes` measures uncompressed size, change default `batcher::max_size_items` to `0` (#36163)\n  Limit the bulk request size to roughly `flush::bytes` for sync bulk indexer. Sync bulk indexer is used when `batcher::enabled` is either true or false. In order words, sync bulk indexer is not used when batcher config is undefined. Change `flush::bytes` to always measure in uncompressed bytes. Change default `batcher::max_size_items` to `0` as bulk request size limit is now more effectively enforced by `flush::bytes`.\n- `k8sattributesprocessor`: Move k8sattr.fieldExtractConfigRegex.disallow feature gate to Beta. (#25128)\n  Disable the `k8sattr.fieldExtractConfigRegex.disallow` feature gate to get the old behavior.\n- `internal`: Remove stable gate `component.UseLocalHostAsDefaultHost` (#36589)\n- `cmd/opampsupervisor`: Update default logger output paths to stderr (#36072)\n  The default output paths for the opamp supervisor logger have been updated to stderr from [stdout, stderr].\n  \n- `opampsupervisor`: Enable strict unmarshalling of the OpAMP Supervisor config file. An error will now be returned if an invalid config key is set. (#35838)\n\n### 🚩 Deprecations 🚩\n\n- `postgresqlreceiver`: Minimal supported PostgreSQL version updated from 9.6 to 13.0 (#30923)\n  Aligning on the supported versions as can be seen [in the PostgreSQL releases section](https://www.postgresql.org/support/versioning)\n- `exporter/prometheusremotewrite`: Change `exporter.prometheusremotewriteexporter.deprecateCreatedMetric` feature gate from Alpha to Beta version. (#35003)\n  The `export_created_metric` configuration parameter is now ignored by default.\n\n### 🚀 New components 🚀\n\n- `signaltometricsconnector`: New component for generating metrics from raw signals using user defined OTTL expressions. (#35930)\n- `extension/cgroupruntime`: Initial implementation for cgroupruntime extension. (#30289)\n- `huaweicloudcesreceiver`: Introduce new receiver fetching data from huawei Cloud Eye Service. (#34953)\n- `netflowreceiver`: Introduce the netflow receiver (#32732)\n\n### 💡 Enhancements 💡\n\n- `datadogexporter`: Add a configurable `reporter_period` parameter to the Datadog exporter’s host metadata configuration to allow users to specify the frequency at which host metadata is sent to Datadog. (#36450)\n- `awsemfexporter`: Add support for 1 second metric resolution in CloudWatch Embedded Metrics Format based on metric attributes (#29506)\n- `awsemfexporter`: Improvement unit conversion during EMF log translation (#35937)\n- `sumologicexporter`: adding new products for auto discovery (#35622)\n- `postgresqlreceiver`: Added new postgresql metrics to acheive parity with Telegraf (#36528)\n- `loadbalancingexporter`: Adding sending_queue, retry_on_failure and timeout settings to loadbalancing exporter configuration (#35378, #16826)\n  When switching to top-level sending_queue configuration - users should carefully review queue size\n  In some rare cases setting top-level queue size to n*queueSize might be not enough to prevent data loss\n  \n- `pkg/stanza`: Introduce active file grouping mechanism. (#23787)\n- `receivercreator`: Add support for starting receivers/scrapers based on provided annotations' hints for metrics' collection (#34427)\n- `tailsamplingprocessor`: Adds decision cache for non-sampled trace IDs (#31583)\n- `cmd/opampsupervisor`: Support environment variable expansion in the OpAMP supervisor config. (#36269)\n- `pkg/ottl`: Move debug log to `Statement.Execute` so that components using it instead of `StatementSequence` also get debug logs. (#36456)\n- `routingconnector`: Add abiilty to route by 'datapoint' context (#36523)\n- `signalfxreceiver`: Follow receiver contract based on type of error (#5909)\n  Use 503 error code for retryable and 400 error code for not-retryable errors instead of responding with a 500 unconditionally.\n\n### 🧰 Bug fixes 🧰\n\n- `cmd/opampsupervisor`: Do not log err if the last received doesn't exist (#36013)\n- `receiver/azureeventhub`: When using a storage extension, the component will call Close on the client during component shutdown. This fixes a bug that resulted in a file potentially remaining locked after component shutdown. (#36238)\n- `azuremonitorexporter`: Fixes an issue where the Azure Monitor exporter was not sending data to App Insights due to the Telemetry Channel not being flushed. (#35037)\n- `exporter/pulsarexporter`: Change configuration option `map_connections_per_broker`, rename to `max_connections_per_broker`. (#36579)\n- `failoverconnector`: Resolves a bug that prevents proper recovery when disabling max retries (#36587)\n- `googlecloudpubsubexporter`: Fix a goroutine leak during shutdown. (#30438)\n  A goroutine leak was found in the googlecloudpubsubexporter. \n  The goroutine leak was caused by the exporter not closing the underlying created gRPC client when using an insecure custom endpoint.\n  \n- `processor/k8sattribute`: fixes parsing of k8s image names to support images with tags and digests. (#36131)\n- `clickhouseexporter`: Fix incorrect Resource Attribute `service.name` translation to ClickHouse ServiceName field for Logs Records (#36349)\n- `awsfirehosereceiver`: fix timestamp when ingesting logs from CloudWatch through firehose (#36122)\n- `pkg/ottl`: Allow indexing []int64, []float64, []bool, and []byte slices (#29441)\n  It should now be possible to index all slice types\n- `opencensusreceiver`: Do not report error message when OpenCensus receiver is shutdown cleanly. (#36622)\n- `loadbalancingexporter`: The k8sresolver in loadbalancingexporter was triggering exporter churn in the way the change event was handled. (#35658)\n- `vcenterreceiver`: The existing code did not honor TLS settings beyond 'insecure'. All TLS client config should now be honored. (#36482)\n\n## v0.114.0\n\n### 🛑 Breaking changes 🛑\n\n- `datadogexporter`: Stop prefixing `http_server_duration`, `http_server_request_size` and `http_server_response_size` with `otelcol` (#36265)\n  These metrics can be from SDKs rather than collector. Stop prefixing them to be consistent with https://opentelemetry.io/docs/collector/internal-telemetry/#lists-of-internal-metrics\n- `otelarrowreceiver`: New admission control metrics are consistent across Arrow and OTLP data paths. (#36334)\n  `otelcol_otelarrow_admission_in_flight_bytes` new, replaces `otelcol_otel_arrow_receiver_in_flight_bytes`\n  `otelcol_otelarrow_admission_waiting_bytes`: new, describes waiting requests\n  `otelcol_otel_arrow_receiver_in_flight_items`: removed\n  `otelcol_otel_arrow_receiver_in_flight_requests`: removed\n  \n\n### 🚩 Deprecations 🚩\n\n- `exporter/prometheusremotewrite`: Deprecate configuration option `export_created metric` (#35003)\n  Disable the exporter.prometheusremotewriteexporter.deprecateCreatedMetric feature gate to temporarily re-enable the created metric.\n\n### 💡 Enhancements 💡\n\n- `datadogreceiver`: Add json handling for the `api/v2/series` endpoint in the datadogreceiver (#36079)\n- `googlemanagedprometheus`: Add `CumulativeNormalization` config option to allow users to configure to specify whether to report normalized or un-normalized points. Defaults to normalized. (#36357)\n- `elasticsearchexporter`: Translate `k8s.*.name` resource attributes in ECS mode (#36233)\n  Translate `k8s.job.name`, `k8s.cronjob.name`, `k8s.statefulset.name`, `k8s.replicaset.name`, `k8s.daemonset.name`, `k8s.container.name` to `kubernetes.*.name`. Translate `k8s.cluster.name` to `orchestrator.cluster.name`.\n- `encodingextension`: Add support for profiles signal to encodingextension (#36008)\n- `k8sattributesprocessor`: Add support for profiles signal (#35983)\n- `cmd/githubgen`: Adds a flag to skip checking GitHub organization membership for CODEOWNERS (#36263)\n- `container`: Set non root group permissions for container image (#35179)\n- `k8sclusterreceiver`: Add support for limiting observed resources to a specific namespace. (#9401)\n  This change allows to make use of this receiver with `Roles`/`RoleBindings`, as opposed to giving the collector cluster-wide read access.\n- `opampextension`: Add content type to opamp extension when reporting EffectiveConfig (#36327)\n  Add EffectiveConfig.ConfigMap.ConfigMap[*].ContentType as \"text/yaml\" to the opamp extension when reporting EffectiveConfig.\n- `otelarrowreceiver`: Admission control improvements (LIFO); admission.waiter_limit is deprecated, replaced with admission.waiting_limit_mib. (#36074)\n- `otelarrowreceiver`: Add a new LIFO-based bounded queue. (#36074)\n- `connector/otlpjson`: Throw error on invalid otlp payload. (#35738, #35739)\n- `prometheusremotewriteexporter`: reduce allocation when serializing protobuf (#35185)\n- `resourcedetectionprocessor`: Introduce support for Profiles signal type. (#35980)\n- `routingconnector`: Add ability to route by metric context (#36236)\n- `routingconnector`: Add ability to route by span context (#36276)\n- `processor/spanprocessor`: Add a new configuration option to keep the original span name when extracting attributes from the span name. (#36120)\n- `splunkenterprisereceiver`: Add new metrics for Splunk Enterprise dispatch artifacts caches (#36181)\n\n### 🧰 Bug fixes 🧰\n\n- `pkg/stanza`: Ensure that time parsing happens before entry is sent to downstream operators (#36213)\n- `prometheusexporter`: Fixes a race condition between the exporter start and shutdown functions. (#36139)\n- `processor/k8sattributes`: Block when starting until the metadata have been synced, to fix that some data couldn't be associated with metadata when the agent was just started. (#32556)\n- `exporter/loadbalancing`: Shutdown exporters during collector shutdown. This fixes a memory leak. (#36024)\n- `pkg/ottl`: Respect the `depth` option when flattening slices using `flatten` (#36161)\n  The `depth` option is also now required to be at least `1`.\n- `prometheusexporter`: reject metrics whose types have changed, use pre-existing descriptions when help strings change (#28617)\n- `pkg/stanza`: Synchronous handling of entries passed from the log emitter to the receiver adapter (#35453)\n- `prometheusreceiver`: Fix prometheus receiver to support static scrape config with Target Allocator (#36062)\n\n## v0.113.0\n\n### 🛑 Breaking changes 🛑\n\n- `sapmreceiver`: Remove the deprecated access_token_passthrough from SAPM receiver. (#35972)\n  Please use `include_metadata` instead with the following config option applied to the batch processor:\n  batch:\n    metadata_keys: [X-Sf-Token]\n  \n- `pkg/ottl`: Promote `processor.transform.ConvertBetweenSumAndGaugeMetricContext` feature gate to Stable (#36216)\n  This gate can no longer be disabled. The `convert_sum_to_gauge` and `convert_gauge_to_sum` may now only be used with the `metric` context.\n\n### 🚩 Deprecations 🚩\n\n- `opensearchexporter`: The OpenSearch exporter is now marked as unmaintained and will be removed in 6 months. (#35781)\n  Any codeowners can reinstate the component by submitting a PR to revert the change or commenting on https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/35781.\n  \n\n### 🚀 New components 🚀\n\n- `dorisexporter`: metrics implementation (#33479)\n- `extensions/observer/cfgardenobserver`: Implemented the observer, the second PR in the 3 PR process for new components (#33618)\n\n### 💡 Enhancements 💡\n\n- `splunkenterprisereceiver`: Add telemetry around the Splunk Enterprise kv-store. (#35445)\n- `journaldreceiver`: adds ability to parse journald's MESSAGE field as a string if desired (#36005)\n- `journaldreceiver`: allows querying a journald namespace (#36031)\n- `hostmetricsreceiver`: Add the system.uptime metric in the hostmetrics receiver (#31627)\n  This metric is provided by the new `system` scraper.\n- `azuredataexplorerexporter`: Add new configuration option `use_default_auth` to enable default authentication for Azure Data Explorer. This option allows users to leverage workload identity for authentication. (#33667)\n- `awss3receiver`: Mark the AWS S3 receiver as Alpha. (#30750)\n- `opampsupervisor`: Makes the Supervisor's OpAmp server port configurable with 'agent::opamp_server_port'. (#36001)\n- `datadogreceiver`: Follow receiver contract based on type of error (#5909)\n- `hostmetrics`: Adjust scraper creation to make it so the scraper name is reported with hostmetrics scraper errors. (#35814)\n- `pkg/translator/prometheusremotewrite`: `FromMetricsV2` now transforms attributes into labels. (#33661)\n- `ntpreceiver`: Move NTP receiver to alpha (#36152)\n- `opampsupervisor`: Supervisor waits for configurable healthchecks to report remote config status. (#21079)\n- `otelarrowreceiver`: Enable unlimited admission control when request_limit_mib is set to 0. (#36074)\n- `pkg/ottl`: Add SliceToMap function (#35256)\n- `receiver/prometheusremotewrite`: Implement body unmarshaling for Prometheus Remote Write requests (#35624)\n  Warning - The HTTP Server still doesn't do anything. It's just a placeholder for now.\n- `receiver/prometheusremotewrite`: Implement Content-Type negotiation for Prometheus Remote Write requests (#35565)\n  Warning - The HTTP Server still doesn't do anything. It's just a placeholder for now.\n- `otlpjsonfilereceiver`: Add support for profiles signal (#35977)\n- `journaldreceiver`: Restart journalctl if it exits unexpectedly (#35635)\n- `routingconnector`: Add ability to route by request metadata. (#19738)\n- `exporter/signalfx`: Enabling retrying for dimension properties update without tags in case of 400 response error. (#36044)\n  Property and tag updates are done using the same API call. After this change, the exporter will retry once to sync\n  properties in case of 400 response error.\n  \n- `signalfxexporter`: Add more default metrics related to Kubernetes cronjobs, jobs, statefulset, and hpa (#36026)\n- `simpleprometheusreceiver`: Support to set `job_name` in config (#31502)\n- `solacereceiver`: Add support to the Solace Receiver to convert the new `Move to Dead Message Queue` and new `Delete` spans generated by Solace Event Broker to OTLP. (#36071)\n- `routingconnector`: Add ability to route log records individually using OTTL log record context. (#35939)\n- `splunkenterprisereceiver`: Add new metrics for Splunk Enterprise dispatch artifacts (#35950)\n\n### 🧰 Bug fixes 🧰\n\n- `awsfirehosereceiver`: make otlp_v1 a valid record type (#35750, #36125)\n- `datadogreceiver`: Return a json reponse instead of \"OK\" when a trace is received with a newer protocol version. (#35705)\n- `datadogreceiver`: Changes response message for `/api/v1/check_run` 202 response to be JSON and on par with Datadog API spec (#36027)\n- `receiver/windowseventlog`: Fix panic when rendering long event messages. (#36179)\n- `hostmetricsreceiver`: Do not set the default value of HOST_PROC_MOUNTINFO to respect root_path (#35990)\n- `prometheusexporter`: Fixes an issue where the prometheus exporter would not shut down the server when the collector was stopped. (#35464)\n- `k8sobserver`: Enable observation of ingress objects if the `ObserveIngresses` config option is set to true (#35324)\n- `pkg/stanza`: Fixed bug causing Operators with DropOnErrorQuiet to send log entries to the next operator. (#35010)\n  This issue was introduced by a bug fix meant to ensure Silent Operators are not logging errors (#35010). With this fix,\n  this side effect bug has been resolved.\n  \n- `otelarrowreceiver`: Simplify receiver admission control logic (#36074)\n- `otelarrowreceiver`: Avoid breaking telemetry when admission control fails in OTLP handlers. (#36074)\n- `dbstorage`: Add postgresql support (#35692)\n- `splunkhecreceiver`: Avoid a memory leak by changing how we record obsreports for logs and metrics. (#35294)\n- `receiver/filelog`: fix record counting with header (#35869)\n- `connector/routing`: Fix detection of duplicate conditions in routing table. (#35962)\n- `solacereceiver`: The Solace receiver may unexpectedly terminate on reporting traces when used with a memory limiter processor and under high load (#35958)\n- `pkg/stanza/operator`: Retain Operator should propagate the severity field (#35832)\n  The retain operator should propagate the severity field like it does with timestamps. \n  \n- `pkg/stanza`: Handle error of callback function of `ParserOperator.ProcessWithCallback` (#35769)\n  `ProcessWithCallback` of `ParserOperator` first calls the `ParseWith` method\n  which properly handles errors with `HandleEntryError`.\n  Then the callback function is called and its returned error should also\n  be handled by the `HandleEntryError` ensuring a consistent experience.\n  \n- `webhookeventreceiver`: Pass the consumer error to EndLogsOp (#35844)\n\n## v0.112.0\n\n### 🛑 Breaking changes 🛑\n\n- `elasticsearchexporter`: Enable gzip compression by default (#35865)\n  To disable compression, set config `compression` to `none`.\n- `elasticsearchexporter`: Set body.* for log body in OTel mode (#35771)\n  Log record body in OTel mapping mode will be stored in body.text, body.structured, body.flattened based on body value type and presence of event.name attribute\n- `processor/metricsgeneration`: Remove \"experimental_\" prefix from metrics generator processor name. (#35426)\n\n### 🚩 Deprecations 🚩\n\n- `sapmreceiver`: Deprecate SAPM receiver (#32125)\n- `elasticsearchexporter`: Deprecate retry::max_requests in favor of retry::max_retries (#32344)\n  retry::max_retries will be exactly retry::max_requests - 1\n\n### 🚀 New components 🚀\n\n- `confmap/aesprovider`: Initial aes encryption provider. Allows configurations to decrypt secrets using AES encryption. (#35550)\n- `systemdreceiver`: Introduce the scaffolding of a new component, systemdreceiver (#33532)\n- `ntpreceiver`: Introduce new receiver reporting the offset between the local machine and a NTP server. (#34375)\n- `tlscheckreceiver`: Add TLS Check Receiver component to monitor x.509 certificate expiry (#35423)\n\n### 💡 Enhancements 💡\n\n- `awsfirehosereceiver`: Add support for CloudWatch logs (#35077)\n- `awsfirehosereceiver`: added OTLP v1 support to Firehose receiver (#34982)\n- `awss3receiver`: Add support for monitoring the progress of ingesting data from an S3 bucket via OpAMP custom messages. (#30750)\n- `azureeventshubreceiver`: Updates the Azure Event Hub receiver to use the new Resource Logs translator. (#35357)\n- `cloudflarereceiver`: Respond 503 on non-permanent and 400 on permanent errors (#35642)\n- `elasticsearchexporter`: Add hint in error logs for TSDB version_conflict_engine_exception error (#35546)\n- `pkg/ottl`: Add ConvertAttributesToElementsXML Converter (#35328)\n- `logdedupprocessor`: Add a `condition` field to the Log DeDuplication Processor. (#35440)\n- `opampextension`: Support using auth extensions for authenticating with opamp servers (#35507)\n- `azureblobreceiver`: adds support for using azidentity default auth, enabling the use of Azure Managed Identities, e.g. Workload Identities on AKS (#35636)\n  This change allows to use authentication type \"default\", which makes the receiver use azidentity default Credentials, \n  which automatically picks up, identities assigned to e.g. a container or a VirtualMachine\n  \n- `elasticsearchexporter`: Introduce an experimental bodymap mapping mode for logs (#35444)\n- `googlecloudexporter`: Google Cloud exporter is marked as mutating. (#35366)\n- `googlemanagedprometheusexporter`: GMP exporter is marked as mutating. (#35366)\n- `k8sobserver`: Emit endpoint per Pod's container (#35491)\n- `mongodbreceiver`: Add support for MongoDB direct connection (#35427)\n- `exporter/clickhouse`: Add the ability to override default table names for all metric types. (#34225)\n  'metrics_table_name' of the clickhouse exporter config is deprecated and newly introduced parameter 'metrics_tables' should be used instead.\n  \n- `metricsgenerationprocessor`: Introduce functionality to only do metric calculations on data points whose attributes match (#35425)\n  This functionality can be enabled by the `metricsgeneration.MatchAttributes` feature gate, which is disabled by default.\n  \n- `chronyreceiver`: Move chronyreceiver to beta (#35913)\n- `opampextension`: Implement `ReportsHealth` capability in OpAMP extension (#35433)\n- `opampextension`: Report OS description semantic convention (`os.description`) as a part of non-identifying agent description. (#35555)\n- `otelarrowexporter`: Adjust defaults from https://opentelemetry.io/blog/2024/otel-arrow-production/ experiments. (#35477)\n- `pkg/ottl`: Parsing invalid statements and conditions now prints all errors instead of just the first one found. (#35728)\n- `pkg/ottl`: Add ParseSimplifiedXML Converter (#35421)\n- `receiver/prometheusremotewrite`: Add HTTP Server to handler Prometheus Remote Write requests (#35535)\n  Warning - The HTTP Server still doesn't do anything. It's just a placeholder for now.\n- `rabbitmqexporter`: Allow to configure the name of the AMQP connection in the rabbitmqexporter (#34681)\n- `routingconnector`: Allow routing based on OTTL Conditions (#35731)\n  Each route must contain either a statement or a condition.\n  \n- `sapmreceiver`: Respond 503 on non-permanent and 400 on permanent errors (#35300)\n- `opampsupervisor`: Allow collector logs to passthrough to supervisor output to facilitate running in a containerized environment. (#35473)\n- `hostmetricsreceiver`: Use HOST_PROC_MOUNTINFO as part of configuration instead of environment variable (#35504)\n- `pkg/ottl`: Add ConvertTextToElements Converter (#35364)\n\n### 🧰 Bug fixes 🧰\n\n- `metricstransform`: The previously removed functionality of aggregating against an empty label set is restored. (#34430)\n- `datadogreceiver`: Use `Check` name from Service Check structure as metric name rather than hardcoded string `service_check` (#35718)\n- `azuredataexplorerexporter`: Fix compression type for Azure Data Explorer exporter by adding the compression type in ingestion properties. (#35353)\n- `telemetrygen`: ensure validate is called (#35745)\n- `deltatocumulative`: fix meter panic on startup (#35685)\n  properly constructs the TelemetryBuilder, so it does not panic on startup, rendering the entire component unusable\n- `elasticsearchexporter`: Log and drop invalid metrics instead of returning error to avoid upstream retries (#35740)\n- `elasticsearchexporter`: Preserve attribute names and metric names on prefix conflict in OTel mapping mode (#35651)\n  e.g. if there are attributes \"a\" and \"a.b\", they should be sent to Elasticsearch as is, instead of \"a.value\" and \"a.b\", in OTel mapping mode\n- `elasticsearchexporter`: Make OTel mapping mode send to data streams only (#35839)\n  This prevents auto creating regular indices in OTel mapping mode due to a race condition in Elasticsearch where otel-data index templates are not ready.\n- `elasticsearchexporter`: Sanitize datastream routing fields (#34285)\n  Sanitize the dataset and namespace fields according to https://www.elastic.co/guide/en/ecs/current/ecs-data_stream.html.\n- `oidcauthextension`: Fix a goroutine leak during shutdown. (#30438)\n  A goroutine leak was found in oidcauthextension. The goroutine leak was caused by the oidcauthextension not closing the idle connections in the client and transport.\n  \n- `filelogreceiver`: Supports `add_metadata_from_filepath` for Windows filepaths (#35558)\n- `filelogreceiver`: Suppress errors on EBADF when unlocking files. (#35706)\n  This error is harmless and happens regularly when delete_after_read is set. This is because we acquire the lock right at the start of the ReadToEnd function and then defer the unlock, but that function also performs the delete. So, by the time it returns and the defer runs the file descriptor is no longer valid.\n- `kafkareceiver`: Fixes issue causing kafkareceiver to block during Shutdown(). (#30789)\n- `hostmetrics receiver`: Fix duplicate filesystem metrics (#34635, #34512)\n  The hostmetrics exposes duplicate metrics of identical mounts exposed in namespaces. The duplication causes errors in exporters that are sensitive to duplicate metrics. We can safely drop the duplicates as the metrics should be exactly the same.\n- `pkg/translator/prometheusremotewrite`: Fix metric comparison func in prom translation layer (#35741)\n- `pkg/ottl`: Allow indexing string slice type (#29441)\n- `mysqlreceiver`: Add replica metric support for versions of MySQL earlier than 8.0.22. (#35217)\n- `stanza/input/windows`: Close remote session while resubscribing (#35577)\n- `telemetrygen`: Enable the `--otlp-insecure-skip-verify` flag (#35735)\n- `receiver/windowseventlog`: Errors returned when passing data downstream will now be propagated correctly. (#35461)\n- `datadogreceiver`: Changes response message for `/api/v1/series` and `/api/v2/series` 202 response to be JSON and on par with Datadog API spec (#35743)\n\n## v0.111.0\n\n### 🛑 Breaking changes 🛑\n\n- `instanaexporter`: Remove deprecated instanaexporter (#35367)\n  Use the `otlp` exporter instead as explained in IBM's [documentation](https://www.ibm.com/docs/en/instana-observability/current?topic=opentelemetry-sending-data-instana-backend).\n- `elasticsearchexporter`: Drop cumulative temporality histogram and exponential histogram (#35442)\n  Cumulative temporality histogram and exponential histogram are not supported by Elasticsearch. Use cumulativetodeltaprocessor to convert cumulative temporality to delta temporality.\n- `elasticsearchexporter`: Implement receiver-based routing under *_dynamic_index config (#34246)\n- `config`: Move component.UseLocalHostAsDefaultHost feature gate to stable. (#35569)\n- `metricsgenerationprocessor`: Generate metrics even when the second metric's value is 0 (#35533)\n- `signalfxexporter`: Do not exclude the metric `container.memory.working_set` (#35475)\n- `sqlqueryreceiver`: Fail if value for log column in result set is missing, collect errors (#35068)\n- `windowseventlogreceiver`: The 'raw' flag no longer suppresses rendering info. (#34720)\n  Previously, this flag controlled two behaviors simultaneously:\n    1. Whether or not the body of the log record was an XML string or structured object.\n    2. Whether or not rendering info was resolved.\n  A separate 'suppress_rendering_info' option now controls rendering info resolution.\n  This is considered a breaking change because users setting only the 'raw' flag without also setting the\n  new 'suppress_rendering_info' flag may see a performance decrease along with more detailed events.\n  \n\n### 🚩 Deprecations 🚩\n\n- `sapmreceiver`: `access_token_passthrough` is deprecated (#35330)\n  - \"`access_token_passthrough` is deprecated.\"\n  - \"Please enable include_metadata in the receiver and add the following config to the batch processor:\"\n  ```yaml\n  batch:\n    metadata_keys: [X-Sf-Token]\n  ```\n  \n\n### 🚀 New components 🚀\n\n- `receiver/prometheusremotewrite`: Add a new receiver for Prometheus Remote Write.\n (#33782)\n\n### 💡 Enhancements 💡\n\n- `sumconnector`: adds connector and summing logic along with tests (#32669)\n- `receivercreator`: Validate endpoint's configuration before starting receivers (#33145)\n- `otelarrowreceiver`: Add admission control in the otelarrow receiver's standard otlp data path.\nAlso moves admission control config options to a separate block.\narrow.admission_limit_mib -> admission.request_limit_mib\narrow.waiter_limit -> admission.waiter_limit\n (#35021)\n- `clickhouseexporter`: Upgrading stability for traces to beta (#35186)\n  The trace exporter has proven to be stable for production deployments.\n  Trace configuration is unlikely to receive any significant changes.\n  \n- `clickhouseexporter`: Updated the default trace table (#34245)\n  Reduced data types, improved partitioning and time range queries\n- `opampsupervisor`: Add configurable logging for the supervisor. (#35466)\n- `datadogreceiver`: Move receiver's metrics stability to alpha. (#18278)\n- `datadogreceiver`: Add container id from v0.5 request header (#35345)\n- `elasticsearchexporter`: Implement elasticsearch.mapping.hints attribute handling for data points in OTel mapping mode (#35479)\n  elasticsearch.mapping.hints takes a slice of strings. `_doc_count` enables emitting `_doc_count` for the document. `aggregate_metric_double` causes histogram or exponential histogram to be emitted as aggregate_metric_double.\n- `elasticsearchexporter`: Revert TSDB array dimension workaround for metrics OTel mode (#35291)\n  Remove the workaround to stringify array dimensions as the limitation has been lifted in Elasticsearch v8.16.0.\n- `receiver/statsd`: Add support for aggregating on Host/IP.\n (#23809)\n- `opampsupervisor`: Skip executing the collector if no config is provided (#33680)\n- `googlecloudmonitoringreceiver`: Move receiver's stability to alpha. (#33762)\n- `hostmetricsreceiver`: Add ability to mute all errors (mainly due to access rights) coming from process scraper of the hostmetricsreceiver (#20435)\n- `kubeletstats`: Introduce feature gate for deprecation of container.cpu.utilization, k8s.pod.cpu.utilization and k8s.node.cpu.utilization metrics (#35139)\n- `opampsupervisor`: Make supervisor runnable as a Windows Service. (#34774)\n- `opampsupervisor`: Add config option for setting the timeout for the initial bootstrap information retrieval from the agent (#34996)\n- `pkg/ottl`: Add InsertXML Converter (#35436)\n- `pkg/ottl`: Add GetXML Converter (#35462)\n- `pkg/ottl`: Add ToKeyValueString Converter (#35334)\n- `pkg/ottl`: Add RemoveXML Converter (#35301)\n- `geoipprocessor`: No longer return an error when geo metadata is not found by a provider. (#35047)\n- `sqlserverreceiver`: Add computer name resource attribute to relevant metrics (#35040)\n- `windowseventlogreceiver`: Add 'suppress_rendering_info' option. (#34720)\n  When this flag is enabled, the receiver will not attempt to resolve rendering info. This can improve performance\n  but comes at a cost of losing some details in the event log.\n  \n- `windowseventlogreceiver`: Move artificial \"remote_server\" field to 'attributes[\"server.address\"]'. (#34720)\n\n### 🧰 Bug fixes 🧰\n\n- `webhookeventreceiver`: Fixed a bug where request bodies containing newline characters caused the results to split into multiple log entries (#35028)\n- `opampsupervisor`: Only use TLS config when connecting to OpAMP server if using `wss` or `https` protocols. (#35283)\n- `metricsgenerationprocessor`: Allow metric calculations to be done on sum metrics (#35428)\n- `sqlqueryreceiver`: Fix reprocessing of logs when tracking_column type is timestamp (#35194)\n- `windowseventlogreceiver`: While collecting from a remote windows host, the stanza operator will no longer log \"subscription handle is already open\" constantly during successful collection. (#35520)\n- `windowseventlogreceiver`: If collecting from a remote host, the receiver will stop collecting if the host restarts. This change resubscribes when the host restarts. (#35175)\n\n## v0.110.0\n\n### 🛑 Breaking changes 🛑\n\n- `pkg/stanza`: Move `filelog.container.removeOriginalTimeField` feature gate to beta (#33389)\n  - Disable the `filelog.container.removeOriginalTimeField` feature gate to get the old behavior.\n  \n- `resourcedetectionprocessor`: Move `processor.resourcedetection.hostCPUSteppingAsString` feature gate to stable. (#31136)\n- `resourcedetectionprocessor`: Remove `processor.resourcedetection.hostCPUModelAndFamilyAsString` feature gate. (#29025)\n\n### 🚩 Deprecations 🚩\n\n- `hostmetricsreceiver`: Set the receiver.hostmetrics.normalizeProcessCPUUtilization feature gate to stable. (#34763)\n\n### 🚀 New components 🚀\n\n- `azurelogs_translater`: Adds a new translater that converts Azure EventHub logs to OpenTelemetry logs used by the Azure Events Hub receiver. (#39704)\n- `dorisexporter`: logs implementation (#33479)\n- `dorisexporter`: traces implementation (#33479)\n\n### 💡 Enhancements 💡\n\n- `otelarrowexporter`: Allow separate arrow exporter per unique value of configured metadataKeys. (#34178)\n- `processor/transform`: Add custom function to the transform processor to convert exponential histograms to explicit histograms. (#33827)\n- `datadogconnector`: Map the new OTel semantic convention `deployment.environment.name` to `env` for OTLP traces in APM stats. (#35147)\n  The old convention `deployment.environment` still works\n- `datadogexporter`: Map the new OTel semantic convention `deployment.environment.name` to `env` for OTLP traces, metrics and logs. (#35147)\n  The old convention `deployment.environment` still works\n- `file_storage`: provide a new option to the user to create a directory on start (#34939)\n- `headersetterextension`: adding default_value config (#34412)\n  default_value config item applied in case context value is empty\n  \n- `kafkaexporter`: Add support for encoding extensions in the Kafka exporter. (#34384)\n  This change adds support for encoding extensions in the Kafka exporter. Loading extensions takes precedence over the internally supported encodings.\n  \n- `datadogexporter`: Adds exporter.datadogexporter.metricremappingdisabled featuregate which disables renaming OpenTelemetry metrics to match Datadog semantics. This feature gate is only for internal use. (#35025)\n- `otelarrowexporter`: Add BatcherConfig field following similar in OTLP exporter. (#34802)\n- `otelarrowreceiver`: Add gRPC timeout propagation. (#34742)\n- `kafkareceiver`: Add support for `otlp_json` encoding to Kafka receiver. The payload is deserialized into OpenTelemetry traces using JSON format. (#33627)\n  This encoding allows the Kafka receiver to handle trace data in JSON format,\n  enabling integration with systems that export traces as JSON-encoded data.\n  \n- `pkg/ottl`: Improved JSON unmarshaling performance by 10-20% by switching dependencies. (#35130)\n- `pkg/ottl`: Added support for locale in the Time converter (#32978)\n- `datadogexporter`: Upgrade logs in Datadog Exporter to beta (#35359)\n- `remotetapprocessor`: Origin header is no longer required for websocket connections (#34925)\n- `deltatorateprocessor`: Remove unnecessary data copies. (#35165)\n- `transformprocessor`: Remove unnecessary data copy when transform sum to/from gauge (#35177)\n- `sapmexporter`: Prioritize token in context when accesstokenpassthrough is enabled (#35123)\n- `tailsamplingprocessor`: Fix the behavior for numeric tag filters with `inverse_match` set to `true`. (#34296)\n\n### 🧰 Bug fixes 🧰\n\n- `splunkenterprise`: Fix a flaky search related to iops metrics. (#35081)\n- `azuremonitorexporter`: fix issue for property endpoint is ignored when using instrumentation_key (#33971)\n- `groupbytraceprocessor`: Ensure processor_groupbytrace_incomplete_releases metric has a unit. (#35221)\n- `datadogreceiver`: Fix numeric span attributes (#35087)\n- `deltatocumulative`: do not drop gauges and summaries (#35284)\n  Gauges and Summaries are no longer dropped from processor output.\n  Instead, they are passed through as-is\n  \n- `pkg/stanza`: Do not get formatted message for Windows events without an event provider. (#35135)\n  Attempting to get the formatted message for Windows events without an event provider can result in an error being logged. |\n  This change ensures that the formatted message is not retrieved for such events.\n  \n- `cmd/opampsupervisor`: Ensure the Supervisor processes all fields in a ServerToAgent message. (#34349)\n- `signalfxexporter`: Ensure token is not sent through for event data (#35154)\n- `prometheusreceiver`: Fix the retrieval of scrape configurations by also considering scrape config files (#34786)\n- `redactionprocessor`: Fix panic when using the redaction processor in a logs pipeline (#35331)\n- `exporter/splunkhec`: Fix incorrect claim that the exporter doesn't mutate data when batching is enabled. (#35306)\n  The bug lead to runtime panics when the exporter was used with the batcher enabled in a fanout scenario.\n  \n\n## v0.109.0\n\n### 🛑 Breaking changes 🛑\n\n- `clickhouseexporter`: Upgrade trace SpanKind and StatusCode string values (#34799)\n  This change updates the output of the trace SpanKind and StatusCode fields to be consistent\n  with the specification's enum values. While this change will not break any deployments, it may affect\n  queries dependent on the old enum names.\n  \n  For more details on old->new values, see this related PR:\n  https://github.com/open-telemetry/opentelemetry-collector/pull/6250\n  \n- `spanmetricsconnector`: Improve consistency between metrics generated by spanmetricsconnector. Added traces.span.metrics as default namespace (#33227, #32818)\n  Default namespace for the generated metrics is traces.span.metrics now. | The deprecated metrics are: calls, duration and events. | The feature flag connector.spanmetrics.legacyMetricNames was added to revert the behavior.\n- `servicegraphconnector`: Fix histogram metrics miss unit (#34511)\n  All metrics will remove the suffix `_seconds`. It will not introduce breaking change if users use | `prometheusexporter` or `prometheusremotewriteexporter` to exporter metrics in pipeline. | In some cases, like using `clickhouseexporter`(save data in native OTLP format), it will be a breaking change. | Users can use `transformprocessor` to add back this suffix.\n- `gitproviderreceiver`: The Git Provider Receiver has been renamed to GitHub Receiver. (#34731)\n  This rename was to better match the OpenTelemetry semantic convention changes in v1.27.0\n  and allows for Traces and Log signals to be added to this component. Traces\n  as mentioned in issue #27460 will be added in a future release to this component.\n  \n- `ottl`: Remove tracing from OTTL due to performance concerns (#34910)\n- `vcenterreceiver`: Updated units on several metrics to be more in line with documented semantics. (#34946)\n  The following are the metrics with their respective unit changes:\n    - vcenter.datacenter.cpu.limit ({MHz} -> MHz)\n    - vcenter.cluster.cpu.limit ({MHz} -> MHz)\n    - vcenter.cluster.cpu.effective ({MHz} -> MHz)\n    - vcenter.cluster.vsan.operations ({operations/sec} -> {operations/s})\n    - vcenter.cluster.vsan.congestions ({congestions/sec} -> {congestions/s})\n    - vcenter.host.network.packet.error.rate ({errors/sec} -> {errors/s})\n    - vcenter.host.network.packet.rate ({packets/sec} -> {packets/s})\n    - vcenter.host.network.packet.drop.rate ({packets/sec} -> {packets/s})\n    - vcenter.host.vsan.operations ({operations/sec} -> {operations/s})\n    - vcenter.host.vsan.congestions ({congestions/sec} -> {congestions/s})\n    - vcenter.resource_pool.cpu.usage ({MHz} -> MHz)\n    - vcenter.vm.network.throughput (By/sec -> By/s)\n    - vcenter.vm.network.packet.rate ({packets/sec} -> {packets/s})\n    - vcenter.vm.vsan.operations ({operations/sec} -> {operations/s})\n  \n\n### 🚩 Deprecations 🚩\n\n- `instanaexporter`: Marking instanaexporter module as deprecated (#34994)\n\n### 💡 Enhancements 💡\n\n- `pkg/ottl`: Added Decode() converter function (#32493)\n- `testbed`: Add test case scenarios to handle large files to existing testbed. (#34288)\n- `filestorage`: Add directory validation for compaction on-rebound (#35114)\n- `windowseventlogreceiver`: Avoid rendering the whole event to obtain the provider name (#34755)\n- `datadogreceiver`: add support for sketch metrics in Datadog receiver (#18278)\n- `datadogconnector`: Optimize Datadog connector when there are many peer tags and `connector.datadogconnector.NativeIngest` is enabled (#34945)\n  `connector.datadogconnector.NativeIngest` is currently enabled by default\n- `splunkhecexporter`: Drop empty log events (#34871)\n  Log records with no body are dropped by Splunk on reception\n  as they contain no log message, albeit they may have attributes.\n  \n  This PR removes those logs from consideration to be exported.\n  \n  This is in tune with the behavior of splunkhecreceiver, which refuses HEC events with no event (#19769)\n  \n- `elasticsearchexporter`: Add exponential histogram support (#34813)\n- `elasticsearchexporter`: Add span event support to traces OTel mapping mode (#34831)\n  Span events are now supported in OTel mapping mode. They will be routed to `logs-${data_stream.dataset}-${data_stream.namespace}` if `traces_dynamic_index::enabled` is `true`.\n- `transformprocessor`: Support aggregating metrics based on their attribute values and substituting the values with a new value. (#16224)\n- `kafkareceiver`: Adds tunable fetch sizes to Kafka Receiver (#22741, #34431)\n  Adds the ability to tune the minumum, default and maximum fetch sizes for the Kafka Receiver\n- `solarwindsapmsettingsextension`: Added logic for refresh function (#27668)\n- `githubreceiver`: Promote GitHub receiver metrics to alpha status. (#34960)\n- `googlecloudmonitoringreceiver`: Enhancing the Google Cloud monitoring receiver to establish a client connection, scrape GCP Cloud Metrics, and transform them into an OpenTelemetry compatible format for pipeline processing. (#33762)\n  - Implements client connection to Google Cloud Monitoring API.\n  - Scrapes timeseries data based on configured metrics.\n  - Converts the data into OpenTelemetry format for use in the pipeline.\n  \n- `processor/interval`: Support for gauge and summary metrics. (#34803)\n  Only the last value of a gauge or summary metric is reported in the interval processor, instead of all values.\n- `kafkareceiver`: Add support for encoding extensions in the Kafka receiver. (#33888)\n  This change adds support for encoding extensions in the Kafka receiver. Loading extensions takes precedence over the internally supported encodings.\n  \n- `datadogexporter`: Add support for setting a custom log source from resource attribute `datadog.log.source` (#35051)\n- `opampextension`: Adds the ability to configure the polling interval for the HTTP client. (#34749)\n- `otelarrowexporter`: Add gRPC timeout propagation. (#34733)\n- `pkg/ottl`: Add `Sort` function to sort array to ascending order or descending order (#34200)\n- `exporter/prometheusexpoter`: Support for Prometheus Created Timestamps. (#32521)\n- `redactionprocessor`: Add support for logs and metrics (#34479)\n- `exceptionsconnector,servicegraphconnector,spanmetricsconnector`: Extract the `getDimensionValue` function as a common function. (#34627)\n- `sqlqueryreceiver`: Support populating log attributes from sql query (#24459)\n- `opampsupervisor`: Add new config parameter `agent.health_check_port` to allow configuring the port used by the agent healthcheck extension. (#34643)\n\n### 🧰 Bug fixes 🧰\n\n- `apachereceiver`: Fix panic on invalid endpoint configuration (#34992)\n- `deltatocumulative`: drop bad samples (#34979)\n  removes bad (rejected) samples from output. previously identified and metric-tracked those as such, but didn't actually drop them.\n  \n- `elasticsearchexporter`: Fix dynamic mapping for double values storing integers (#34680)\n- `elasticsearchexporter`: Stringify attribute array values in metrics OTel mode (#35004)\n  Elasticsearch TSDB does not support array dimensions. Workaround it by stringifying attribute array values in OTel mapping mode for metrics.\n- `fileconsumer`: Fix bug where max_concurrent_files could not be set to 1. (#35080)\n- `servicegraphconnector`: Fix incorrectly reversed latency settings for the server and client (#34933)\n- `hostmetricsreceiver`: In filesystem scraper, do not prefix partitions when using the environment variable HOST_PROC_MOUNTINFO (#35043)\n- `splunkhecreceiver`: Fix memory leak when the receiver is used for both metrics and logs at the same time (#34886)\n- `geoipprocessor`: Avoid using internal empty attribute.Set pointer (#34882)\n- `pkg/stanza`: Synchronize shutdown in stanza adapter (#31074)\n  Stanza-based receivers should now flush all data before shutting down\n- `sqlserverreceiver`: Fix bug where metrics were being emitted with the wrong database name resource attribute (#35036)\n- `signalfxexporter`: Fix memory leak by re-organizing the exporter's functionality lifecycle (#32781)\n- `otlpjsonconnector`: Handle OTLPJSON unmarshal error (#34782)\n- `mysqlreceiver`: mysql client raise error when the TABLE_ROWS column is NULL, convert NULL to int64 (#34195)\n- `pkg/stanza`: An operator configured with silent errors shouldn't log errors while processing log entries. (#35008)\n- `datadogexporter`: Use correct hostname for logs when using Datadog Agent logs pipeline with a gateway deployment. (#35058)\n\n## v0.108.0\n\n### 🛑 Breaking changes 🛑\n\n- `all`: Added support for go1.23, bumped the minimum version to 1.22 (#34658)\n- `lokiexporter`: Update the scope name for telemetry produced by the lokiexporter from `otelcol/loki` to `github.com/open-telemetry/opentelemetry-collector-contrib/exporter/lokiexporter` (#34612)\n- `azuretranslator`: The scope name has been updated from `otelcol/azureresourcelogs` and `otelcol/azureresourcetraces` to `github.com/open-telemetry/opentelemetry-collector-contrib/pkg/translator/azure` (#34712)\n- `datadogreceiver`: The scope name has been updated from `otelcol/datadogreceiver` to `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/datadogreceiver/internal/translator` (#34711)\n- `splunkhecexporter`: The scope name has been updated from `otelcol/splunkhec` to `github.com/open-telemetry/opentelemetry-collector-contrib/exporter/splunkhecexporter` (#34710)\n- `googlecloudmonitorreceiver`: The scope name has been updated from `otelcol/googlecloudmonitoringreceiver` to `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/googlecloudmonitoringreceiver` (#34709)\n- `elasticsearchexporter`: Update OTel mapping mode for logs and metrics; Remove trace_flags (#34472)\n  Update logs and metrics OTel mapping mode to always emit \"scope\" and zero int, but not emit empty strings for known fields. Breaking change to remove trace_flags from logs.\n- `elasticsearchexporter`: Change default retry.retry_on_status to [429] (#32584)\n  To retain the previous behavior, set retry.retry_on_status to `[429, 500, 502, 503, 504]`.\n- `gitproviderreceiver`: Update metric names and attributes to match the newest Semantic Conventions for VCS. (#34278)\n  Attribute Changes:\n    - `branch.name` is now `ref.name`\n    - Added a `ref.type` attribute\n    - `pull_request.state` is now `change.state`\n    - `git.vendor.name` is now `vcs.vendor.name`\n  Metric Changes:\n    - `git.repository.count` is now `vcs.repository.count`\n    - `git.repository.contributor.count` is now `vcs.repository.contributor.count`\n    - `git.repository.branch.count` is now `vcs.repository.ref.count`\n    - `git.repository.branch.time` is now `vcs.repository.ref.time\n    - `git.repository.branch.commit.aheadby.count` is now `vcs.repository.ref.revisions_ahead`\n    - `git.repository.branch.commit.behindby.count` is now `vcs.repository.ref.revisions_behind\n    - `git.repository.branch.line.addition.count` is now `vcs.repository.ref.lines_added`\n    - `git.repository.branch.line.deletion.count` is now `vcs.repository.ref.lines_deleted`\n    - `git.repository.pull_request.time_open` is now `vcs.change.time_open`\n    - `git.repository.pull_request.time_to_merge` is now `vcs.change.time_to_merge`\n    - `git.repository.pull_request.time_to_approval` is now `vcs.change.time_to_approval`\n    - `git.repository.pull_request.count` is now `vcs.change.count`\n  \n- `transformprocessor`: Promote processor.transform.ConvertBetweenSumAndGaugeMetricContext feature flag from alpha to beta (#34567)\n- `exporter/datadog`: The `logs::dump_payloads` config option is invalid when the Datadog Agent logs pipeline is enabled (now enabled by default). (#34420)\n  An error will be raised if `logs::dump_payloads` is set while the Datadog Agent logs pipeline is enabled. To avoid this error, remove the `logs::dump_payloads` config option or temporarily disable the `exporter.datadogexporter.UseLogsAgentExporter` feature gate.\n- `vcenterreceiver`: Several host performance metrics now return 1 data point per time series instead of 5. (#34708)\n  The 5 data points previously sent represented consecutive 20s sampling periods. Depending on the collection interval \n  these could easily overlap. Sending just the latest of these data points is more in line with other performance metrics.\n  \n  This change also fixes an issue with the googlecloud exporter seeing these datapoints as duplicates.\n  \n  Following is the list of affected metrics which will now only report a single datapoint per set of unique attribute values.\n  - vcenter.host.cpu.reserved\n  - vcenter.host.disk.latency.avg\n  - vcenter.host.disk.latency.max\n  - vcenter.host.disk.throughput\n  - vcenter.host.network.packet.drop.rate\n  - vcenter.host.network.packet.error.rate\n  - vcenter.host.network.packet.rate\n  - vcenter.host.network.throughput\n  - vcenter.host.network.usage\n  \n\n### 🚀 New components 🚀\n\n- `exporter/doris`: Add a new component for exporting logs, traces and metrics to Doris (#33479)\n\n### 💡 Enhancements 💡\n\n- `geoipprocessor`: Add a context configuration option to specify the IP address attribute telemetry location. (#34036)\n- `awss3receiver`: Enhance the logging of the AWS S3 Receiver in normal operation to make it easier for user to debug what is happening. (#30750)\n- `datadogreceiver`: Implement '/info' endpoint (#34772)\n- `datadogreceiver`: Add sampling.priority attribute for Probabilistic Sampling Processor (#34267)\n- `datadogreceiver`: Implement '/stats' endpoint (#34790)\n- `datadogconnector`: Add a config `traces::bucket_interval` (#34554)\n  `traces::bucket_interval` specifies the time interval size of aggregation buckets that aggregate the Datadog trace metrics. It is also the time interval that Datadog trace metrics payloads are flushed to the pipeline. Default is 10s if unset.\n- `deltatocumulative`: Promote to `alpha` stability (#34747)\n  promotes the deltatocumulative processor to alpha stability, as most features are now implemented and ready for wider testing.\n- `deltatocumulative`: explicit-bounds histograms (#30705)\n  implements aggregation of explicit-bounds (traditional) histograms.\n- `elasticsearchexporter`: Add OTel mapping mode for metrics (#34248)\n- `elasticsearchexporter`: Add OTel mapping mode for traces (#34588, #34590)\n  Add OTel mapping mode support for traces, without span events.\n- `filelogreceiver`: If acquire_fs_lock is true, attempt to acquire a shared lock before reading a file. (#34801)\n  Unix only. If a lock cannot be acquired then the file will be ignored until the next poll cycle.\n- `solacereceiver`: Updated the format for generated metrics. Included a `receiver_name` attribute that identifies the Solace receiver that generated the metrics (#34541)\n- `geoipprocessor`: Move processor's stability to alpha. (#34737)\n- `prometheusreceiver`: Ensure Target Allocator's confighttp is used in the receiver's service discovery (#33370)\n- `datadogreceiver`: Include error when logging unmarshaling failures in Datadog receiver. (#34515)\n- `metricstransformprocessor`: Add scaling exponential histogram support (#29803)\n- `exporter/datadog`: Use Datadog Agent logs pipeline by default for exporting logs to Datadog. Upgrades `exporter.datadogexporter.UseLogsAgentExporter` feature flag to beta. (#34420)\n- `pkg/ottl`: Introduce `UserAgent` converter to parse UserAgent strings (#32434)\n\n### 🧰 Bug fixes 🧰\n\n- `tailsamplingprocessor`: Update the `policy` value in metrics dimension value to be unique across multiple tail sampling components with the same policy name. (#34192)\n  This change ensures that the `policy` value in the metrics exported by the tail sampling processor is unique across multiple tail sampling processors with the same policy name.\n- `datadogreceiver`: add feature discovery (#34718)\n- `datadogconnector`: Put back the `otelcol_` prefix for Datadog internal metrics on trace and APM stats exporting (#34807)\n  Recovers these metrics from an upstream breaking change. See https://github.com/open-telemetry/opentelemetry-collector/pull/9759 and https://github.com/open-telemetry/opentelemetry-collector/pull/10940.\n- `datadogexporter`: Put back the `otelcol_` prefix for Datadog internal metrics on trace and APM stats exporting (#34807)\n  Recovers these metrics from an upstream breaking change. See https://github.com/open-telemetry/opentelemetry-collector/pull/9759 and https://github.com/open-telemetry/opentelemetry-collector/pull/10940.\n- `awsfirehosereceiver`: Fix validation of requests with empty access key (#34847)\n- `connector/exceptionsconnector`: Fix dimensions configuration did not take effect for resource attributes (#34603)\n- `prometheusreceiver`: Group scraped metrics into resources created from `job` and `instance` label pairs (#34237)\n  The receiver will now create a resource for each distinct job/instance label combination.\n  In addition to the label/instance pairs detected from the scraped metrics, a resource representing the overall\n  scrape configuration will be created. This additional resource will contain the scrape metrics, such as the number of scraped metrics, the scrape duration, etc.\n  \n- `cmd/opampsupervisor`: Fix supervisor support for Windows. (#34570)\n- `tailsamplingprocessor`: Fix the behavior for numeric tag filters with `inverse_match` set to `true`. (#34296)\n- `pkg/stanza`: fix nil value conversion (#34672)\n- `k8sclusterreceiver`: Lower the log level of a message indicating a cache miss from WARN to DEBUG. (#34817)\n\n## v0.107.0\n\nThis release fixes CVE-2024-42368 on the `bearerauthtokenextension` (#34516)\n\n### 🛑 Breaking changes 🛑\n\n- `clickhouseexporter`: Add `compress` option to ClickHouse exporter, with default value of `lz4` (#34365)\n  This change adds a new `compress` option to the config field and enables it by default.\n  Prior to this change, compression was not enabled by default.\n  The only way to enable compression prior to this change was via the DSN URL.\n  With this change, `lz4` compression will be enabled by default.\n  The list of valid options is provided by the underlying `clickhouse-go` driver.\n  While this change is marked as breaking, there should be no effect to existing deployments by enabling compression.\n  Compression should improve network performance on most deployments that have a remote ClickHouse server.\n  \n- Update the scope name for telemetry produce by components. The following table summarizes the changes:\n\n| Component name | Previous scope | New scope |  PR number |\n|----------------|----------------|-----------|------------|\n| `azureeventhubreceiver` | `otelcol/azureeventhubreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/azureeventhubreceiver` |  #34611 |\n| `cloudfoundryreceiver` | `otelcol/cloudfoundry` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/cloudfoundryreceiver` |  #34612 |\n| `cloudflarereceiver` | `otelcol/cloudflare` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/cloudflarereceiver` |  #34613 |\n| `azuremonitorreceiver` | `otelcol/azuremonitorreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/azuremonitorreceiver` |  #34618 |\n| `fileconsumer` | `otelcol/fileconsumer` | `github.com/open-telemetry/opentelemetry-collector-contrib/pkg/stanza/fileconsumer` |  #34619 |\n| `loadbalancingexporter` | `otelcol/loadbalancing` | `github.com/open-telemetry/opentelemetry-collector-contrib/exporter/loadbalancingexporter` |  #34429 |\n| `sumologicexporter` | `otelcol/sumologic` | `github.com/open-telemetry/opentelemetry-collector-contrib/exporter/sumologicexporter` |  #34438 |\n| `prometheusremotewriteexporter` | `otelcol/prometheusremotewrite` | `github.com/open-telemetry/opentelemetry-collector-contrib/exporter/prometheusremotewriteexporter` |  #34440 |\n| `activedirectorydsreceiver` | `otelcol/activedirectorydsreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/activedirectorydsreceiver` |  #34492 |\n| `aerospikereceiver` | `otelcol/aerospikereceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/aerospikereceiver` |  #34518 |\n| `apachereceiver` | `otelcol/apachereceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/apachereceiver` |  #34517 |\n| `apachesparkreceiver` | `otelcol/apachesparkreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/apachesparkreceiver` |  #34519 |\n| `bigipreceiver` | `otelcol/bigipreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/bigipreceiver` |  #34520 |\n| `chronyreceiver` | `otelcol/chronyreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/chronyreceiver` |  #34524 |\n| `couchdbreceiver` | `otelcol/couchdbreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/couchdbreceiver` |  #34525 |\n| `countconnector` | `otelcol/countconnector` | `github.com/open-telemetry/opentelemetry-collector-contrib/connector/countconnector` |  #34583 |\n| `deltatocumulativeprocessor` | `otelcol/deltatocumulative` | `github.com/open-telemetry/opentelemetry-collector-contrib/processor/deltatocumulativeprocessor` |  #34550 |\n| `dockerstatsreceiver` | `otelcol/dockerstatsreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/dockerstatsreceiver` |  #34528 |\n| `elasticsearchreceiver` | `otelcol/elasticsearchreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/elasticsearchreceiver` |  #34529 |\n| `expvarreceiver` | `otelcol/expvarreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/expvarreceiver` |  #34530 |\n| `filestatsreceiver` | `otelcol/filestatsreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/filestatsreceiver` |  #34429 |\n| `filterprocessor` | `otelcol/filter` | `github.com/open-telemetry/opentelemetry-collector-contrib/processor/filterprocessor` |  #34550 |\n| `flinkmetricsreceiver` | `otelcol/flinkmetricsreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/flinkmetricsreceiver` |  #34533 |\n| `fluentforwardreceiver` | `otelcol/fluentforwardreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/fluentforwardreceiver` |  #34534 |\n| `gitproviderreceiver` | `otelcol/gitproviderreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/gitproviderreceiver` |  #34496 |\n| `googlespannerreceiver` | `otelcol/googlecloudspannermetrics` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/googlespannerreceiver` |  #34593 |\n| `grafanacloudconnector` | `otelcol/grafanacloud` | `github.com/open-telemetry/opentelemetry-collector-contrib/connector/grafanacloudconnector` |  #34552 |\n| `groupbyattrsprocessor` | `otelcol/groupbyattrs` | `github.com/open-telemetry/opentelemetry-collector-contrib/processor/groupbyattrsprocessor` |  #34550 |\n| `groupbytraceprocessor` | `otelcol/groupbytrace` | `github.com/open-telemetry/opentelemetry-collector-contrib/processor/groupbytraceprocessor` |  #34550 |\n| `haproxyreceiver` | `otelcol/haproxyreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/haproxyreceiver` |  #34498 |\n| `hostmetricsreceiver` receiver's scrapers | `otelcol/hostmetricsreceiver/*` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/hostmetricsreceiver/internal/scraper/*` |  #34526 |\n| `httpcheckreceiver` | `otelcol/httpcheckreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/httpcheckreceiver` |  #34497 |\n| `iisreceiver` | `otelcol/iisreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/iisreceiver` |  #34535 |\n| `k8sattributesprocessor` | `otelcol/k8sattributes` | `github.com/open-telemetry/opentelemetry-collector-contrib/processor/k8sattributesprocessor` |  #34550 |\n| `k8sclusterreceiver` | `otelcol/k8sclusterreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/k8sclusterreceiver` |  #34536 |\n| `kafkametricsreceiver` | `otelcol/kafkametricsreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/kafkametricsreceiver` |  #34538 |\n| `kafkareceiver` | `otelcol/kafkareceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/kafkareceiver` |  #34539 |\n| `kubeletstatsreceiver` | `otelcol/kubeletstatsreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/kubeletstatsreceiver` |  #34537 |\n| `memcachedreceiver` | `otelcol/memcachedreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/memcachedreceiver` |  #34542 |\n| `mongodbatlasreceiver` | `otelcol/mongodbatlasreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/mongodbatlasreceiver` |  #34543 |\n| `mongodbreceiver` | `otelcol/mongodbreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/mongodbreceiver` |  #34544 |\n| `mysqlreceiver` | `otelcol/mysqlreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/mysqlreceiver` |  #34545 |\n| `nginxreceiver` | `otelcol/nginxreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/nginxreceiver` |  #34493 |\n| `nsxtreceiver` | `otelcol/nsxtreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/nsxtreceiver` |  #34429 |\n| `oracledbreceiver` | `otelcol/oracledbreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/oracledbreceiver` |  #34491 |\n| `otelarrowreceiver` | `otelcol/otelarrowreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/otelarrowreceiver` |  #34546 |\n| `podmanreceiver` | `otelcol/podmanreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/podmanreceiver` |  #34429 |\n| `postgresqlreceiver` | `otelcol/postgresqlreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/postgresqlreceiver` |  #34476 |\n| `probabilisticsamplerprocessor` | `otelcol/probabilisticsampler` | `github.com/open-telemetry/opentelemetry-collector-contrib/processor/probabilisticsamplerprocessor` |  #34550 |\n| `prometheusreceiver` | `otelcol/prometheusreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/prometheusreceiver` |  #34589 |\n| `rabbitmqreceiver` | `otelcol/rabbitmqreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/rabbitmqreceiver` |  #34475 |\n| `sshcheckreceiver` | `otelcol/sshcheckreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/sshcheckreceiver` |  #34448 |\n| `vcenterreceiver` | `otelcol/vcenter` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/vcenterreceiver` |  #34449 |\n| `zookeeperreceiver` | `otelcol/zookeeper` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/zookeeperreceiver` |  #34450 |\n| `redisreceiver` | `otelcol/redisreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/redisreceiver` |  #34470 |\n| `riakreceiver` | `otelcol/riakreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/riakreceiver` |  #34469 |\n| `routingprocessor` | `otelcol/routing` | `github.com/open-telemetry/opentelemetry-collector-contrib/processor/routingprocessor` |  #34550 |\n| `saphanareceiver` | `otelcol/saphanareceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/saphanareceiver` |  #34468 |\n| `servicegraphconnector` | `otelcol/servicegraph` | `github.com/open-telemetry/opentelemetry-collector-contrib/connector/servicegraphconnector` |  #34552 |\n| `snmpreceiver` | `otelcol/snmpreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/snmpreceiver` |  #34592 |\n| `snowflakereceiver` | `otelcol/snowflakereceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/snowflakereceiver` |  #34467 |\n| `solacereceiver` | `otelcol/solacereceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/solacereceiver` |  #34466 |\n| `splunkenterprisereceiver` | `otelcol/splunkenterprisereceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/splunkenterprisereceiver` |  #34452 |\n| `statsdreceiver` | `otelcol/statsdreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/statsdreceiver` |  #34547 |\n| `tailsamplingprocessor` | `otelcol/tailsampling` | `github.com/open-telemetry/opentelemetry-collector-contrib/processor/tailsamplingprocessor` |  #34550 |\n| `sqlserverreceiver` | `otelcol/sqlserverreceiver` | `github.com/open-telemetry/opentelemetry-collector-contrib/receiver/sqlserverreceiver` |  #34451 |\n\n- `elasticsearchreceiver`: Enable more index metrics by default (#34396)\n  This enables the following metrics by default: \n  `elasticsearch.index.documents`\n  `elasticsearch.index.operations.merge.current`\n  `elasticsearch.index.segments.count`\n  To preserve previous behavior, update your Elasticsearch receiver configuration to disable these metrics.\n- `vcenterreceiver`: Enables all of the vSAN metrics by default. (#34409)\n  The following metrics will be enabled by default now:\n    - vcenter.cluster.vsan.throughput\n    - vcenter.cluster.vsan.operations\n    - vcenter.cluster.vsan.latency.avg\n    - vcenter.cluster.vsan.congestions\n    - vcenter.host.vsan.throughput\n    - vcenter.host.vsan.operations\n    - vcenter.host.vsan.latency.avg\n    - vcenter.host.vsan.congestions\n    - vcenter.host.vsan.cache.hit_rate\n    - vcenter.vm.vsan.throughput\n    - vcenter.vm.vsan.operations\n    - vcenter.vm.vsan.latency.avg\n  \n\n### 🚩 Deprecations 🚩\n\n- `exporter/datadog`: Deprecates `logs::dump_payloads` since it is invalid with the Datadog Agent logs pipeline, which will be enabled by default in the v0.108.0 release. (#34490)\n\n### 🚀 New components 🚀\n\n- `logdedupeprocessor`: Add new logdedupeprocessor processor that deduplicates log entries. (#34118)\n- `coralogixprocessor`: creating new component for coralogix features (#33090)\n- `googlecloudmonitoringreceiver`: Adding new component - [Google Cloud monitoring](https://cloud.google.com/monitoring/api/metrics_gcp) receiver to fetch GCP Cloud Metrics and transform to OpenTelemetry compatible format. (#33762)\n\n### 💡 Enhancements 💡\n\n- `awsemfexporter`: AWS EMF Exporter to update ApplicationSignals log group name and namespace, and adjust AWS service name prefix logic in spans (#33798)\n- `azureeventhubreceiver`: Added traces support in azureeventhubreceiver (#33583)\n- `exporter/prometheusremotewrite`: Reduce unnecessary memory allocation by removing buffer that was not used by Snappy encoding function. (#34273)\n- `exporter/prometheusremotewrite`: Reduce memory allocations of prometheus remote write exporter \"batchtimeseries\" when large batch sizes are used (#34269)\n- `clickhouseexporter`: Updated the default logs table to a more optimized schema (#34203)\n  Improved partitioning and time range queries.\n- `bearertokenauthextension`: use constant time comparison. This fixes CVE-2024-42368 (#34516)\n- `processor/k8sattributes`: Add support for `container.image.repo_digests` metadata (#34029)\n- `datadogconnector`: Move feature gate `connector.datadogconnector.NativeIngest` to beta (#34549)\n  When this feature gate is enabled (default), the datadog connector uses the new API to produce APM stats under the hood. | The new API has better throughput when your spans have many attributes (especially container related attributes). Funtional-wise the new API should have no user-facing change compared to the old API. | However if you observe any unexpected behaviors, you can disable this feature gate to revert to the old stats processing APIs.\n- `elasticsearchexporter`: Add opt-in support for the experimental `batcher` config (#32377)\n  By enabling (or explicitly disabling) the batcher, the Elasticsearch exporter's\n  existing batching/buffering logic will be disabled, and the batch sender will be used.\n  \n- `elasticsearchexporter`: Add summary support for metrics (#34560)\n- `hostmetricsreceiver`: add reporting interval to entity event (#34240)\n- `elasticsearchreceiver`: Add metric for active index merges (#34387)\n- `kafkaexporter`: add an ability to partition logs based on resource attributes. (#33229)\n- `logdedupprocessor`: Adds a histogram metric to record the number of aggregated log records. (#34579)\n- `logdedupprocessor`: Updates stability level to alpha. (#34575)\n- `logdedup`: Make the name of the log deduplication component consistent (#34571)\n- `logdedupprocessor`: Ensures any pending aggregated logs are processed and sent to the next consumer before shutting down. (#34615)\n- `logdedupprocessor`: Adds a scope aggregator to the logdedup processor enabling the aggregation of logs per scope. (#34606)\n- `logdedupprocessor`: Simplifies the processor shutdown behaviour by removing the unnecessary done channel. (#34478)\n- `pkg/ottl`: Add support for map literals in OTTL (#32388)\n- `pkg/ottl`: Introduce ExtractGrokPatterns converter (#32593)\n- `pkg/ottl`: Add the `MD5` function to convert the `value` into a MD5 hash/digest (#33792)\n- `pkg/ottl`: Introduce `sha512` converter to generate SHA-512 hash/digest from given payload. (#34007)\n- `kafkametricsreceiver`: Add option to configure cluster alias name and add new metrics for kafka topic configurations (#34148)\n- `receiver/splunkhec`: Add a regex to enforce metrics naming for Splunk events fields based on metrics documentation. (#34275)\n- `telemetrygen`: Support boolean values in `--telemetry-attributes` and `--otlp-attributes` flag (#18928)\n- `filelogreceiver`: Check for unsupported fractional seconds directive when converting strptime time layout to native format (#34390)\n- `windowseventlogreceiver`: Add remote collection support to Stanza operator windows pkg to support remote log collect for the Windows Event Log receiver. (#33100)\n\n### 🧰 Bug fixes 🧰\n\n- `configauth`: Fix unmarshaling of authentication in HTTP servers. (#34325)\n  This brings in a bug fix from the core collector. See https://github.com/open-telemetry/opentelemetry-collector/issues/10750.\n- `docker_observer`: Change default endpoint for `docker_observer` on Windows to `npipe:////./pipe/docker_engine` (#34358)\n- `pkg/translator/jaeger`: Change the translation to jaeger spans to match semantic conventions. (#34368)\n  `otel.library.name` is deprecated and replaced by `otel.scope.name`\n  `otel.library.version` is deprecated and replaced by `otel.scope.version`\n  \n- `pkg/stanza`: Ensure that errors from `Process` and `Write` do not break for loops (#34295)\n- `cmd/opampsupervisor`: Start even if the OpAMP server cannot be contacted, and continually retry connecting. (#33408, #33799)\n- `cmd/opampsupervisor`: Write the generated effective config and agent log files to the user-defined storage directory. (#34341)\n- `azuremonitorreceiver`: Add Azure China as a `cloud` option. (#34315)\n- `postgresqlreceiver`: Support unix socket based replication by handling null values in the client_addr field (#33107)\n- `splunkhecexporter`: Copy the bytes to be placed in the request body to avoid corruption on reuse (#34357)\n  This bug is a manifestation of https://github.com/golang/go/issues/51907.\n  Under high load, the pool of buffers used to send requests is reused enough\n  that the same buffer is used concurrently to process data and be sent as request body.\n  The fix is to copy the payload into a new byte array before sending it.\n  \n- `syslogexporter`: Fix issue where exporter may hang indefinitely while dialing. (#34393)\n- `clickhouseexporter`: Use observed timestamp if timestamp is zero (#34150)\n  Some OpenTelemetry libraries do not send timestamp for logs, but they should always send | the observed timestamp. In these cases the ClickHouse exporter just stored a zero timestamp | to the database. This changes the behavior to look into the observed timestamp if the timestamp | is zero.\n- `webhookeventreceiver`: added a timestamp to the logs generated from incoming events. (#33702)\n\n## v0.106.1\n\n### 🧰 Bug fixes 🧰\n\n- `configauth`: Fix unmarshaling of authentication in HTTP servers. (#34325)\n  This brings in a bug fix from the core collector. See https://github.com/open-telemetry/opentelemetry-collector/issues/10750.\n\n## v0.106.0\n\n### 🛑 Breaking changes 🛑\n\n- `vcenterreceiver`: Enables various vCenter metrics that were disabled by default until v0.106.0 (#33607)\n  The following metrics will be enabled by default \"vcenter.datacenter.cluster.count\", \"vcenter.datacenter.vm.count\", \"vcenter.datacenter.datastore.count\",\n  \"vcenter.datacenter.host.count\", \"vcenter.datacenter.disk.space\", \"vcenter.datacenter.cpu.limit\", \"vcenter.datacenter.memory.limit\",\n  \"vcenter.resource_pool.memory.swapped\", \"vcenter.resource_pool.memory.ballooned\", and \"vcenter.resource_pool.memory.granted\". The \n  \"resourcePoolMemoryUsageAttribute\" has also been bumped up to release v.0.107.0\n  \n- `googlemanagedprometheusexporter`: Fix typo in `exporter.googlemanagedpromethues.intToDouble` feature gate (#34232)\n\n### 🚩 Deprecations 🚩\n\n- `k8sattributesprocessor`: Deprecate `extract.annotations.regex` and `extract.labels.regex` config fields in favor of the `ExtractPatterns` function in the transform processor. The `FieldExtractConfig.Regex` parameter will be removed in version v0.111.0. (#25128)\n  Deprecating of FieldExtractConfig.Regex parameter means that it is recommended to use the `ExtractPatterns` function from the transform processor instead. To convert your current configuration please check the `ExtractPatterns` function [documentation](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/pkg/ottl/ottlfuncs#extractpatterns). You should use the `pattern` parameter of `ExtractPatterns` instead of using the `FieldExtractConfig.Regex` parameter.\n\n### 🚀 New components 🚀\n\n- `otlpjsonconnector`: New component that will allow extracting otlpjson data from incoming Logs. (#34239, #34208)\n- `redis_storage`: Adds a new storage extension using Redis to store data in transit (#31682)\n\n### 💡 Enhancements 💡\n\n- `processor/transform`: Add `scale_metric` function that scales all data points in a metric. (#16214)\n- `vcenterreceiver`: Adds vCenter vSAN host metrics. (#33556)\n  Introduces the following vSAN host metrics to the vCenter receiver:\n    - vcenter.host.vsan.throughput\n    - vcenter.host.vsan.iops\n    - vcenter.host.vsan.congestions\n    - vcenter.host.vsan.cache.hit_rate\n    - vcenter.host.vsan.latency.avg\n  \n- `transformprocessor`: Support aggregating metrics based on their attributes. (#16224)\n- `metricstransformprocessor`: Adds the 'median' aggregation type to the Metrics Transform Processor. Also uses the refactored aggregation business logic from internal/core package. (#16224)\n- `telemetrygen`: uses the go logging SDK instead of pdata (#18902)\n- `elasticsearchexporter`: Add explicit bounds histogram support to metrics (#34045)\n- `hostmetricsreceiver`: allow configuring log pipeline to send host EntityState event (#33927)\n- `elasticsearchexporter`: Introduce an experimental OTel native mapping mode for logs (#33290)\n- `extension/healthcheckv2`: Add extension/subcomponent management logic. (#26661)\n- `otlpjsonconnector`: Add connector's implementations (#34249, #34208)\n- `windowsperfcountersreceiver`: Improve handling of non-existing instances for Windows Performance Counters (#33815)\n  It is an expected that when querying Windows Performance Counters the targeted instances may not be present.\n  The receiver will no longer require the use of `recreate_query` to handle non-existing instances.\n  As soon as the instances are available, the receiver will start collecting metrics for them.\n  There won't be warning log messages when there are no matches for the configured instances.\n  \n- `kafkareceiver`: Add settings session_timeout and heartbeat_interval to Kafka Receiver for group management facilities (#28630)\n- `otelarrowreceiver, otelarrowexporter`: OTel-Arrow internal packages moved into this repository. (#33567)\n  New integration testing between otelarrowexporter and otelarrowreceiver.\n- `otlpjsonconnector`: Move connector's stability to alpha. (#34208, #34253)\n- `pkg/ottl`: Adds an `Format` function to OTTL that calls `fmt.Sprintf` (#33405)\n- `vcenterreceiver`: Adds a number of default disabled vSAN metrics for Clusters. (#33556)\n- `vcenterreceiver`: Adds a number of default disabled vSAN metrics for Virtual Machines. (#33556)\n\n### 🧰 Bug fixes 🧰\n\n- `clickhouseexporter`: Increase the default number of queue consumers to 10 (#34176)\n- `opencensusreceiver`: Do not report an error into resource status during receiver shutdown when the listener connection was closed. (#33865)\n- `datadogconnector`: Produce stats for non-root client and producer spans when `connector.datadogconnector.NativeIngest` and `compute_top_level_by_span_kind` are enabled (#34197)\n  You should have only run into this bug when ALL the conditions below are met | 1. feature gate `connector.datadogconnector.NativeIngest` is enabled | 2. config `compute_top_level_by_span_kind` is set to true | 3. config `compute_stats_by_span_kind` is unset or set to false | 4. you have child spans with client or producer span kind\n- `datadogconnector`: Respect `_dd.measured` when `connector.datadogconnector.NativeIngest` is enabled (#34197)\n  Spans with attribute `_dd.measured` set to 1 will always get Datadog APM stats\n- `deltatocumulativeprocessor`: fix bucket counts when downscaling exp histograms with odd offsets (#33831)\n- `otelarrowreceiver`: Fix potential goroutine leak when in stream-shutdown. (#34236)\n- `otelarrowreceiver`: Eliminate one spurious span error. (#34175)\n- `pkg/ottl`: Handle JSON array provided to ParseJSON function (#33535)\n- `exporter/datadog`: Fixes a bug where `otelcol_exporter_sent_log_records` was reporting double as many logs sent when using the logs agent feature gate. (#33887)\n- `statsdeceiver`: Log only non-EOF errors when reading payload received via TCP. (#33951)\n- `vcenterreceiver`: Adds destroys to the ContainerViews in the client. (#34254)\n  This may not be necessary, but it should be better practice than not.\n\n## v0.105.0\n\n### 🛑 Breaking changes 🛑\n\n- `skywalkingexporter`: Remove unmaintained component (#23796)\n- `elasticsearchexporter`: Make \"dedup\" option no-op, always de-duplicate. (#33773)\n  Elasticsearch does not permit duplicate keys in JSON objects, so there is no value in being able to configure deduplication.\n- `elasticsearchexporter`: Remove defunct \"file\" and \"fields\" configuration settings. (#33803)\n  This is a breaking change only because removing the attributes would prevent collector startup if those attributes are specified, but otherwise there is no functional change. These configuration attributes have never done anything.\n- `stanza`: errors from Operator.Process are returned instead of silently ignored. (#33783)\n  This public function is affected: https://pkg.go.dev/github.com/open-telemetry/opentelemetry-collector-contrib/pkg/stanza@v0.104.0/operator/helper#WriterOperator.Write\n- `vcenterreceiver`: Enables various vCenter metrics that were disabled by default until v0.105 (#34022)\n  The following metrics will be enabled by default \"vcenter.host.network.packet.drop.rate\",\n  \"vcenter.vm.cpu.readiness\", \"vcenter.host.cpu.capacity\", and \"vcenter.host.cpu.reserved\".\n  \n\n### 🚩 Deprecations 🚩\n\n- `lokiexporter`: Deprecate component (#33916)\n\n### 🚀 New components 🚀\n\n- `sumconnector`: creates a wireframe and initial pr to develop from (#32669)\n- `extensions/observer/cfgardenobserver`: Add a new observer that discovers containers through the Garden API (#33618)\n\n### 💡 Enhancements 💡\n\n- `pkg/ottl`: Added Hex() converter function (#31929)\n- `pkg/ottl`: Add IsRootSpan() converter function. (#32918)\n  Converter `IsRootSpan()` returns `true` if the span in the corresponding context is root, that means its `parent_span_id` equals to hexadecimal representation of zero. In all other scenarios function returns `false`.\n- `vcenterreceiver`: Adds additional vCenter resource pool metrics and a memory_usage_type attribute for vcenter.resource_pool.memory.usage metric to use. (#33607)\n  Added \"vcenter.resource_pool.memory.swapped\", \"vcenter.resource_pool.memory.ballooned\", and \"vcenter.resource_pool.memory.granted\"\n  metrics. Also added an additional attribute, \"memory_usage_type\" for \"vcenter.resource_pool.memory.usage\" metric, which is\n  currently under a feature gate.\n  \n- `kubeletstatsreceiver`: Add `k8s.pod.memory.node.utilization` and `k8s.container.memory.node.utilization` metrics (#33591)\n- `vcenterreceiver`: Adds vCenter metrics at the datacenter level. (#33607)\n  Introduces various datacenter metrics which work by aggregating stats from datastores, clusters, hosts, and VM's.\n- `processor/resource, processor/attributes`: Add an option to extract value from a client address by specifying `client.address` value in the `from_context` field. (#34051)\n- `awss3receiver`: Add support for retrieving logs and metrics to the AWS S3 Receiver. (#30750)\n- `receiver/azuremonitorreceiver`: Add support for Managed Identity and Default Credential auth (#31268, #33584)\n- `azuremonitorreceiver`: Add `maximum_number_of_records_per_resource` config parameter in order to overwrite default (#32165)\n- `clickhouseexporter`: Upgrading stability for logs to beta (#33615)\n  The logs exporter has been proven to be stable for large scale production deployments.\n  Configuration options specific to logs are unlikely to change.\n  \n- `cloudfoundryreceiver`: Add support to receive CloudFoundry Logs (#32671)\n- `datadogreceiver`: Add support for metrics in Datadog receiver (#18278)\n- `datadogexporter`: Add a feature gate `exporter.datadogexporter.TraceExportUseCustomHTTPClient` that allows a custom HTTP client to be used in trace export (#34025)\n  This is an experimental feature. By default the feature gate is disabled and trace export uses a default HTTP client.\n- `elasticsearchexporter`: Introduce experimental `telemetry.log_request_body` and `telemetry.log_response_body` config (#33854)\n- `cmd/opampsupervisor`: Adds support for forwarding custom messages to/from the agent (#33575)\n- `geoipprocessor`: Add providers configuration and maxmind provider factory (#33269)\n- `healthcheckv2extension`: Add partial gRPC service implementation to healthcheckv2. (#26661)\n- `healthcheckv2extension`: Add support for streaming Watch RPC to healthcheckv2 gRPC service. (#26661)\n- `healthcheckv2extension`: Add HTTP service to healthcheckv2 (#26661)\n- `splunkhecexporter`: Increase the performance of JSON marshaling (#34011)\n- `pkg/stanza`: Add `parse_ints` config in json parser to support parsing int or float properly (#33696)\n- `loadbalancingexporter`: Adds a new streamID routingKey, which will route based on the datapoint ID. See updated README for details (#32513)\n- `awsxrayexporter`: Allow multiple log group names/arns to be set in environmental variables (#33795)\n- `dockerobserver`: Add hint to error when using float for `api_version` field (#34043)\n- `dockerstatsreceiver`: Add hint to error when using float for `api_version` field (#34043)\n- `pkg/ottl`: Emit traces for statement sequence executions to troubleshoot OTTL statements/conditions (#33433)\n- `pkg/stanza`: Bump 'logs.jsonParserArray' and 'logs.assignKeys' feature gates to beta. (#33948)\n  This enables the feature gates by default to allow use of the\n  `json_array_parser` and `assign_keys` operations.\n  \n- `receiver/filelog`: Add filelog.container.removeOriginalTimeField feature-flag for removing original time field (#33946)\n- `statsdreceiver`: Allow configuring summary percentiles (#33701)\n- `pkg/stanza`: Switch to faster json parser lib for container operator (#33929)\n- `telemetrygen`: telemetrygen `--rate` flag changed from Int64 to Float64 (#33984)\n- `extension/opamp`: Rely on the Collector APIs to do config redaction (#34078)\n  Previously all config fields had to be redacted, now `configopaque.String` is used to determine\n  which fields should be redacted. As a result, fields that are not sensitive are no longer redacted.\n  \n- `azuremonitorreceiver`: Upgrade stability to alpha (#33689)\n- `windowsperfcountersreceiver`: `windowsperfcountersreceiver` now appends an index number to additional instance names that share a name. An example of this is when scraping ` rocess(*)` counters with multiple running instances of the same executable. (#32319)\n  **NOTES**\n  - This change can expose cardinality issues where the counters were previously collapsed under the non-indexed instance name.\n  - The change mimics Windows Performance Monitor behavior: The first instance name remains unchanged, additional instances are suffixed with `#<N>` where `N=1` and is increased for each duplicate.\n    - e.g. Given 3 powershell instances, this will return `powershell`, `powershell#1` and `powershell#2`.\n  \n\n### 🧰 Bug fixes 🧰\n\n- `servicegraphconnector`: Fix failed label does not work leads to servicegraph metrics error (#32018)\n- `apachesparkreceiver`: Updating the stability to reflect that the component is shipped as part of contrib. (#33906)\n- `azureblobreceiver`: Updating the stability to reflect that the component is shipped as part of contrib. (#33902)\n- `countconnector`: Updating the stability to reflect that the component is shipped as part of contrib. (#33903)\n- `deltatorateprocessor`: Updating the stability to reflect that the component is shipped as part of contrib. (#33904)\n- `httpcheckreceiver`: Updating the stability to reflect that the component is shipped as part of contrib. (#33897)\n- `metricsgenerationprocessor`: Updating the stability to reflect that the component is shipped as part of contrib. (#33905)\n- `podmanreceiver`: Updating the stability to reflect that the component is shipped as part of contrib. (#33899)\n- `purefareceiver`: Updating the stability to reflect that the component is shipped as part of contrib. (#33901)\n- `purefbreceiver`: Updating the stability to reflect that the component is shipped as part of contrib. (#33900)\n- `zookeeperreceiver`: Updating the stability to reflect that the component is shipped as part of contrib. (#33898)\n- `probabilisticsamplerprocessor`: Fix bug where log sampling was being reported by the counter `otelcol_processor_probabilistic_sampler_count_traces_sampled` (#33874)\n- `cmd/telemetrygen`: Fix `make docker-telemetrygen` command. (#33989)\n- `processor/groupbyattrsprocessor`: Fix dropping of metadata fields when processing metrics. (#33419)\n- `testbed`: Fixes incorrect count for sent data items in load generator. (#34057)\n- `prometheusreceiver`: Fix hash computation to include non exported fields like regex in scrape configuration for TargetAllocator (#29313)\n- `datadogexporter`: Exit when API key validation fails and `api::fail_on_invalid_key` is set to `true`. (#33935)\n- `kafkametricsreceiver`: Fix issue with incorrect consumer offset (#33309)\n- `sqlserverreceiver`: Enable default metrics to properly trigger SQL Server scrape (#34065)\n- `syslogreceiver`: Allow to define `max_octets` for octet counting RFC5424 syslog parser (#33182)\n- `windowsperfcountersreceiver`: Metric definitions with no matching performance counter are no longer included as metrics with zero datapoints in the scrape output. (#4972)\n\n## v0.104.0\n\n### 🛑 Breaking changes 🛑\n\n- `sumologicexporter`: removed compress_encoding (#33604)\n- `exporter/clickhouse`: Change behavior of how default database is read from the config (#33693)\n  Changed the default `database` to `default`.\n  The final database will prioritize `endpoint`, unless `database` is set to a value not equal to `default`.\n  If neither are specified then it defaults to the `default` database.\n  Possible breaking change if someone has the DSN configured in combination with `database` config option.\n  \n- `exporter/clickhouse`: Add `async_insert` config option to enable inserting asynchronously by default. (#33614)\n  Adds `async_insert` config option to enable inserting asynchronously by default.\n  To preserve the previous behavior, set `async_insert` to `false` in your config.\n  When enabled, the exporter will insert asynchronously, which can improve performance for high-throughput deployments.\n  The `async_insert` option can be set to `true` or `false` to enable or disable async inserts, respectively. The default value is `true`.\n  Keep in mind this setting is added since the exporter now sets it to default.\n  Async insert and its related settings can still be defined in `endpoint` and `connection_params`, which take priority over the new config option.\n  \n- `clickhouseexporter`: Add `AggregationTemporality` column to histogram and exponential histogram tables. Rename `AggTemp` column to `AggregationTemporality` in sum table. (#33424)\n  It's a breaking change. users who upgrade to the latest version need to alter the Clickhouse table:\n  ```sql\n  ALTER TABLE otel_metrics_exponential_histogram ADD COLUMN AggregationTemporality Int32 CODEC(ZSTD(1));\n  ALTER TABLE otel_metrics_histogram ADD COLUMN AggregationTemporality Int32 CODEC(ZSTD(1));\n  ALTER TABLE otel_metrics_sum RENAME COLUMN AggTemp TO AggregationTemporality;\n  ```\n  \n- `exporter/clickhouse`: Remove deprecated `ttl_days` config option, use `ttl` instead. (#33648)\n- `vcenterreceiver`: Drops support for vCenter 6.7 (#33607)\n- `all`: Promote `component.UseLocalHostAsDefaultHost` feature gate to beta. This changes default endpoints from 0.0.0.0 to localhost (#30702)\n  This change affects the following components:\n    - extension/awsproxy\n    - extension/health_check\n    - extension/health_checkv2\n    - extension/jaegerremotesampling\n    - internal/aws/proxy\n    - processor/remotetap\n    - receiver/awsfirehose\n    - receiver/awsxray\n    - receiver/influxdb\n    - receiver/jaeger\n    - receiver/loki\n    - receiver/opencensus\n    - receiver/sapm\n    - receiver/signalfx\n    - receiver/skywalking\n    - receiver/splunk_hec\n    - receiver/zipkin\n    - receiver/zookeeper\n  \n- `receiver/mongodb`: Graduate receiver.mongodb.removeDatabaseAttr feature gate to stable (#24972)\n\n### 🚩 Deprecations 🚩\n\n- `exporter/elasticsearch`: Deprecate the \"dedot\" configuration. (#33772)\n  dedot has been deprecated, and will always be enabled in ECS mode and disabled for other modes in future\n- `exporter/elasticsearch`: Deprecate the \"dedup\" configuration. (#33773)\n  dedup has been deprecated, and will always be enabled in future.\n\n### 🚀 New components 🚀\n\n- `otelarrow`: OTel-Arrow exporter and receiver are marked alpha, added to otelcontribcol (#26491)\n\n### 💡 Enhancements 💡\n\n- `exporter/elasticsearch`: Add initial support for metrics (#33513)\n- `elasticsearchexporter`: Add translation for k8s.deployment.name resource  attribute (#33622)\n- `k8sattributesprocessor`: Add support for exposing `k8s.pod.ip` as a resource attribute (#32960)\n- `geoipprocessor`: Add MaxMind geoip provider for GeoIP2-City and GeoLite2-City databases. (#32663)\n- `vcenterreceiver`: Adds vCenter CPU readiness metric for VMs. (#33607)\n- `awsemfexporter`: AWS EMF Exporter to add AppSignals metadata flag into the user-agent (#32998)\n- `receiver/mongodb`: Ensure support of 6.0 and 7.0 MongoDB versions with integration tests (#32716)\n- `sumologicexporter`: added timeout validation (#33151)\n- `clickhouseexporter`: Updated the default logs table to a more optimized schema (#33611)\n  Simplified data types, improved partitioning and time range queries.\n- `datadogconnector`: Add a feature gate `connector.datadogconnector.NativeIngest` that enables datadog connector to use the new native OTel API in APM stats computation. (#33297)\n  The feature gate `connector.datadogconnector.NativeIngest` is disabled by default.\n- `datadogexporter`: Adds Kubernetes DD tags to keep when mapping resource attributes (#33728)\n  See https://github.com/DataDog/opentelemetry-mapping-go/pull/334 for details.\n- `exporter/elasticsearch`: Add data stream routing (#33794, #33756)\n  `data_stream.dataset` and `data_stream.namespace` in attributes will be respected when config `*_dynamic_index.enabled` is true.\n  \n- `exporter/elasticsearch`: Encode metrics resource attributes in ECS mapping mode (#33823)\n- `elasticsearchexporter`: Preserve `host.name` resource attribute in ECS mode (#33670)\n- `servicegraphprocessor`: Added a new configuration option `enable_virtual_node_label` to allow users to identify which node is the virtual node in each edge of the service graph. (#31889)\n- `pkg/stanza`: Switch JSON parser used by json_parser to github.com/goccy/go-json (#33784)\n- `k8sobserver`: Add support for k8s.ingress endpoint. (#32971)\n- `statsdreceiver`: Optimize statsdreceiver to reduce object allocations (#33683)\n- `routingprocessor`: Use mdatagen to define the component's telemetry (#33526)\n- `loadbalancerexporter`: Refactors how the load balancing exporter splits metrics (#32513)\n  All splitting is *behaviorally*, the same. However, the `resource` routingID now uses the `internal/exp/metrics/identity` package to generate the load balancing key, instead of bespoke code. This means that when upgrading to this version your routes for specific metric groupings could change. However, this will be stable and all future metrics will follow the new routing\n- `receiver/mongodbreceiver`: Add `server.address` and `server.port` resource attributes to MongoDB receiver. (#32810, #32350)\n  The new resource attributes are added to the MongoDB receiver to distinguish metrics coming from different MongoDB instances.\n    - `server.address`: The address of the MongoDB host, enabled by default.\n    - `server.port`: The port of the MongoDB host, disabled by default.\n  \n- `observerextension`: Expose host and port in endpoint's environment (#33571)\n- `rabbitmqexporter`: Promote rabbitmqexporter to alpha. (#33331)\n- `pkg/ottl`: Add a `schema_url` field to access the SchemaURL in resources and scopes on all signals (#30229)\n- `solacereceiver`: Renamed some SemConv fields to support latest semantic conventions for messaging spans (version `1.25.0`) (#33499)\n- `sqlserverreceiver`: Enable more perf counter metrics when directly connecting to SQL Server (#33420)\n  This enables the following metrics by default on non Windows-based systems:\n  `sqlserver.batch.request.rate`\n  `sqlserver.batch.sql_compilation.rate`\n  `sqlserver.batch.sql_recompilation.rate`\n  `sqlserver.page.buffer_cache.hit_ratio`\n  `sqlserver.user.connection.count`\n  \n- `extension/googleclientauth`: Add Google-signed ID token support (#33185)\n  Update github.com/GoogleCloudPlatform/opentelemetry-operations-go/extension/googleclientauth to v0.48.0.\n  With this update, extension/googleclientauth now supports Google-signed ID token as auth header.\n  \n- `vcenterreceiver`: Adds vCenter CPU capacity and network drop rate metrics to hosts. (#33607)\n\n### 🧰 Bug fixes 🧰\n\n- `resourcedetectionprocessor`: Fetch CPU info only if related attributes are enabled (#33774)\n- `datasetexporter`: Upgrade dataset-go to v0.19.0 and fix found issues (#33498, #32533, #33675)\n  Upgrade `dataset-go` library from v0.18.0 to v0.19.0.\n  Enable skipped integration test and adjust the test so it is passing again.\n  Do not validate configuration, let the framework run the validation.\n  \n- `datasetexporter`: Upgrade dataset-go to v0.20.0 (#33812)\n  Upgrade `dataset-go` library from v0.19.0 to v0.20.0.\n  Make number of outgoing connections configurable.\n  \n- `datadogexporter`: Fix panics on invalid sized trace & span IDs (#33566)\n  See https://github.com/DataDog/opentelemetry-mapping-go/pull/340 for details.\n- `datadogexporter`: Ignore metric datapoints with `no recorded value` flag (#33728)\n  This flag is not supported by Datadog, so we just ignore these datapoints. See https://github.com/DataDog/opentelemetry-mapping-go/pull/330 for details.\n- `tailsamplingprocessor`: Fix precedence of inverted match in and policy (#33671)\n  Previously if the decision from a policy evaluation was `NotSampled` or `InvertNotSampled` it would return a `NotSampled` decision regardless, effectively downgrading the result.\n  \n  This was breaking the documented behaviour that inverted decisions should take precedence over all others.\n  \n- `otelarrowreceiver`: Ensure consume operations are not canceled at stream EOF. (#33570)\n- `vcenterreceiver`: Fixes errors in some of the client calls for environments containing multiple datacenters. (#33734)\n\n## v0.103.0\n\n### 🛑 Breaking changes 🛑\n\n- `cmd/opampsupervisor,extension/opamp`: Upgrade the opamp-go library to v0.15.0 (#33416)\n  With this change, UUIDv7 is recommended for the OpAMP extension's instance_uid field instead of ULID. ULIDs will continue to work, but may be displayed as UUIDs.\n  The supervisor's persistent state (${storage_dir}/persistent_state.yaml) will need to be cleared to generate a new UUIDv7 instead of a ULID.\n  This change may be incompatible with management servers using v0.14.0 of opamp-go.\n  \n- `mongodbreceiver`: Now only supports `TCP` connections (#32199)\n  This fixes a bug where hosts had to explicitly set `tcp` as the transport type. The `transport` option has been removed.\n- `cmd/configschema`: Removes the deprecated `configschema` command. This command will no longer be released or supported. (#33384)\n- `sqlserverreceiver`: sqlserver.database.io.read_latency has been renamed to sqlserver.database.latency with a `direction` attribute. (#29865)\n\n### 🚩 Deprecations 🚩\n\n- `healthcheckextension`: Remove incorrect logic behind `check_collector_pipeline` config (#33469)\n  This logic incorrectly set the pipeline to OK after waiting for enough callbacks from the\n  opencensus library to be called. As this was broken, I'm removing it to remove the dependency\n  on opencensus as well. Improvements will be available via healthcheckv2 extension.\n  \n- `googlecloudspannerreceiver`: Mark the component as unmaintained. If we don't find new maintainers, it will be deprecated and removed. (#32651)\n\n### 💡 Enhancements 💡\n\n- `filelogreceiver`: If include_file_record_number is true, it will add the file record number as the attribute `log.file.record_number` (#33530)\n- `kubeletstats`: Add k8s.pod.cpu.node.utilization metric (#33390)\n- `awss3exporter`: endpoint should contain the S3 bucket (#32774)\n- `awss3receiver`: Add support for encoding extensions to be used in the AWS S3 Receiver. (#30750)\n- `gitproviderreceiver`: Adds branch commit and line based metrics (#22028)\n  Adds the following branch based metrics.\n  * git.repository.branch.time\n  * git.repository.branch.commit.aheadby.count\n  * git.repository.branch.commit.behindby.count\n  * git.repository.branch.line.deletion.count\n  * git.repository.branch.line.addition.count\n  \n- `statsdreceiver`: update statsd receiver to use mdatagen (#33524)\n- `coralogixexporter`: Allow setting application name from `cx.application.name` and `cx.subsystem.name` resource attributes (#33217)\n- `metricstransformprocessor`: Adds the 'count' aggregation type to the Metrics Transform Processor. (#24978)\n- `elasticsearchexporter`: Add support for confighttp options, notably \"auth\". (#33367)\n  Add support for confighttp and related configuration settings, such as \"auth\".\n  This change also means that the Elasticsearch URL may be specified as \"endpoint\",\n  like the otlphttp exporter.\n  \n- `elasticsearchexporter`: Check that endpoints are valid URLs during config validation. (#33350)\n  Check that endpoints are valid URLs during config validation so that\n  an invalid endpoint causes a fatal error during startup, rather than\n  leading to a persistent runtime error.\n  \n- `opampsupervisor`: Add config validation for the supervisor config (#32843)\n- `statsdreceiver`: Added received/accepted/refused metrics (#24278)\n- `filelogreceiver`: Add support for gzip compressed log files (#2328)\n- `confmap/provider/secretsmanagerprovider`: Add support for JSON formatted secrets in secretsmanagerprovider confmap (#32143)\n  The `secretsmanagerprovider` confmap will now allow to get secret by a json key if the secret value is json.\n  To specify key separate key from secret name/arn by `#` e.g. `mySecret#mySecretKey`.\n  \n- `geoipprocessor`: Add initial processing based on source.address resource attribute (#32663)\n- `healthcheckv2extension`: Add shared aggregation logic for status events. (#26661)\n- `tailsamplingprocessor`: Simple LRU Decision Cache for \"keep\" decisions (#31583)\n- `processor/tailsampling`: Migrates internal telemetry to OpenTelemetry SDK via mdatagen (#31581)\n  The metric names and their properties, such as bucket boundaries for histograms, were kept like before, to keep backwards compatibility.\n- `kafka`: Added `disable_fast_negotiation` configuration option for Kafka Kerberos authentication, allowing the disabling of PA-FX-FAST negotiation. (#26345)\n- `pkg/ottl`: Added `keep_matching_keys` function to allow dropping all keys from a map that don't match the pattern. (#32989)\n- `OTel-Arrow`: Update to OTel-Arrow v0.24.0 (#26491)\n- `pkg/ottl`: Add debug logs to help troubleshoot OTTL statements/conditions (#33274)\n- `pkg/ottl`: Introducing `append` function for appending items into an existing array (#32141)\n- `pkg/ottl`: Introducing `Uri` converter parsing URI string into SemConv (#32433)\n- `probabilisticsamplerprocessor`: Add Proportional and Equalizing sampling modes (#31918)\n  Both the existing hash_seed mode and the two new modes use OTEP 235 semantic conventions to encode sampling probability.\n- `prometheusreceiver`: Resource attributes produced by the prometheus receiver now include stable semantic conventions for `server` and `url`. (#32814)\n  To migrate from the legacy net.host.name, net.host.port, and http.scheme resource attributes, |\n  migrate to server.address, server.port, and url.scheme, and then |\n  set the receiver.prometheus.removeLegacyResourceAttributes feature gate.\n  \n- `datadogexporter`: The Datadog Exporter now supports the `proxy_url` parameter to configure an HTTP proxy to use when sending telemetry to Datadog. (#33316)\n- `spanmetrics`: Produce delta temporality span metrics with StartTimeUnixNano and TimeUnixNano values representing an uninterrupted series (#31671, #30688)\n  This allows producing delta span metrics instead of the more memory-intensive cumulative metrics, specifically when a downstream component can convert the delta metrics to cumulative.\n- `sqlserverreceiver`: Add support for more Database IO metrics (#29865)\n  The following metrics have been added:\n  - sqlserver.database.latency\n  - sqlserver.database.io\n  - sqlserver.database.operations\n  \n- `cmd/opampsupervisor`: Receive and report effective config to the OpAMP server (#30622)\n- `processor/transform`: Add `transform.flatten.logs` featuregate to give each log record a distinct resource and scope. (#32080)\n  This option is useful when applying transformations which alter the resource or scope. e.g. `set(resource.attributes[\"to\"], attributes[\"from\"])`, which may otherwise result in unexpected behavior. Using this option typically incurs a performance penalty as the processor must compute many hashes and create copies of resource and scope information for every log record.\n  \n- `receiver/windowsperfcounters`: Counter configuration now supports recreating the underlying performance query at scrape time. (#32798)\n\n### 🧰 Bug fixes 🧰\n\n- `filelogreceiver`: Container parser should add k8s metadata as resource attributes and not as log record attributes (#33341)\n- `deltatocumulative`: properly drop samples when at limit (#33285)\n  fixes a segfault in the limiting behavior, where streams exceeding the limit still had their samples processed. due to not being tracked, this led to a nil-pointer deref\n- `postgresqlreceiver`: Fix bug where `postgresql.rows` always returning 0 for `state=\"dead\"` (#33489)\n- `prometheusreceiver`: Fall back to scrape config job/instance labels for aggregated metrics without instance/job labels (#32555)\n- `elasticsearchexporter`: Duplicate Key in JSON (#33454)\n- `logzioexporter`: Fix issue where log attributes were not correctly exported (#33231)\n- `exporter/datadog`: Prevents collector shut down when Datadog logs pipeline fails to validate API key (#33195)\n\n## v0.102.0\n\n### 🛑 Breaking changes 🛑\n\n- `k8sattributesprocessor`: Move `k8sattr.rfc3339` feature gate to stable. (#33304)\n- `extension/opamp`: Redact all values in the effective config (#33267)\n  All values will be treated as if they are a `configopaque.String` type. This will\n  be changed once the Collector APIs are updated to unmarshal the config while\n  only redacting actual `configopaque.String`-typed values.\n  \n  The exception to redaction is the `service::pipelines` section, which is useful\n  for debugging and does not contain any `configopaque.String` values.\n  \n- `extension/filestorage`: Replace path-unsafe characters in component names (#3148)\n  The feature gate `extension.filestorage.replaceUnsafeCharacters` is now removed.\n- `vcenterreceiver`: vcenterreceiver replaces deprecated packet metrics by removing them and enabling by default the newer ones. (#32929, #32835)\n  Removes the following metrics: `vcenter.host.network.packet.errors`, `vcenter.host.network.packet.count`, and\n  `vcenter.vm.network.packet.count`. \n  \n  Also enables by default the following metrics: `vcenter.host.network.packet.error.rate`,\n  `vcenter.host.network.packet.rate`, and `vcenter.vm.network.packet.rate`.\n  \n\n### 🚀 New components 🚀\n\n- `geoipprocessor`: introduce the GeoIP processor (#32663)\n\n### 💡 Enhancements 💡\n\n- `pkg/ottl`: Add the `Day` Converter to extract the int Day component from a time.Time (#33106)\n- `pkg/ottl`: Adds `Month` converter to extract the int Month component from a time.Time (#33106)\n- `cmd/telemetrygen`: Add support for adding spanID and traceID as exemplars to datapoints generated by telemetrygen (#33320)\n- `cmd/telemetrygen`: Add support for specifying trace ID and span ID in telemetrygen for logs (#33234)\n- `pkg/ottl`: Adds a `Year` converter for extracting the int year component from a time.Time (#33106)\n- `filelogreceiver`: Log when files are rotated/moved/truncated (#33237)\n- `stanza`: Add monitoring metrics for open and harvested files in fileconsumer (#31256)\n- `awss3receiver`: Uses obsreport to report metrics for the AWS S3 Receiver. (#30750)\n- `awsxrayexporter`: AWS X-Ray exporter to make local root spans a segment for internal/service spans and subsegment + segment for client/producer/consumer spans. (#33000)\n- `prometheusreceiver`: Allow to configure http client used by target allocator generated scrape targets (#18054)\n- `clickhouseexporter`: Add `create_schema` option to ClickHouse exporter (#32282)\n  The new create_schema option allows disabling default DDL to let the user manage their own schema.\n- `pkg/stanza`: Expose recombine max log size option in the container parser configuration (#33186)\n- `sumologicexporter`: add support for tracing (#32315)\n- `exceptionsconnector`: Add support for exemplars in exceptionsconnector (#24409)\n- `processor/resourcedetectionprocessor`: Add support for Azure tags in ResourceDetectionProcessor. (#32953)\n- `solarwindsapmsettingsextension`: Added the first part of concrete implementation of solarwindsapmsettingsextension (#27668)\n- `kubeletstatsreceiver`: Add k8s.container.cpu.node.utilization metric (#27885)\n- `pkg/ottl`: Adds a `Minute` converter for extracting the int minute component from a time.Time (#33106)\n\n### 🧰 Bug fixes 🧰\n\n- `podmanreceiver`: add scraper's shutdown method (#29994)\n- `awsxrayexporter`: Fix the DB subsegment(client span) name with JDBC conn string starts with \"jdbc:\" (#33225)\n- `exp/metrics`: fixes staleness.Evict such that it only ever evicts actually stale metrics (#33265)\n- `receiver/mysql`: Remove the order by clause for the column that does not exist (#33271)\n- `influxdb(exporter|receiver)`: remove Metric flags field to/from InfluxDB conversion (#29896)\n- `kafkareceiver`: Fix bug that was blocking shutdown (#30789)\n- `exporter/datadog`: Fixes a potential race condition when the traces exporter and metrics exporter are both shutting down. (#33291)\n\n## v0.101.0\n\n### 🛑 Breaking changes 🛑\n\n- `sumologicexporter`: change logs behavior (#31479)\n  * set OTLP as default format\n  * add support for OTLP format\n  * do not support metadata attributes\n  * do not support source headers\n  \n- `sumologicexporter`: change metrics behavior (#31479)\n  * remove suppport for carbon2 and graphite\n  * add support for otlp format\n  * do not support metadata attributes\n  * do not support source headers\n  * set otlp as default metrics format\n  \n- `sumologicexporter`: remove deprecated configuration options (#32315)\n  migration has been described in the following document\n  https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/v0.100.0/exporter/sumologicexporter#migration-to-new-architecture\n- `remotetapprocessor`: Make the `limit` configuration work properly. (#32385)\n  The `limit` configuration was ignored previously, but now it works according to the configuration and documentation.\n  Nothing is required of users.\n  See the remotetapprocessor's `README.md` for details.\n  \n- `groupbytraceprocessor`: Fix groupbytrace metrics contain duplicate prefix (#32698)\n- `vcenterreceiver`: Removes `vcenter.cluster.name` attribute from `vcenter.datastore` metrics (#32674)\n  If there were multiple Clusters, Datastore metrics were being repeated under Resources differentiated with a\n  `vcenter.cluster.name` resource attribute. In the same vein, if there were standalone Hosts, in addition to\n  clusters the metrics would be repeated under a Resource without the `vcenter.cluster.name` attribute. Now there\n  will only be a single set of metrics for one Datastore (as there should be, as Datastores don't belong to\n  Clusters).\n  \n- `resourcedetectionprocessor`: Move `processor.resourcedetection.hostCPUModelAndFamilyAsString` feature gate to stable. (#29025)\n- `filelog, journald, tcp, udp, syslog, windowseventlog receivers`: The internal logger has been changed from zap.SugaredLogger to zap.Logger. (#32177)\n  This should not have any meaningful impact on most users but the logging format for some logs may have changed.\n- `awsxrayexporter`: change x-ray exporter's translator to make \".\" split annotation pass as-is (#32694, #31732)\n  This change make below change to beta stage for feature gate 'exporter.xray.allowDot'，this change will let the change mention below enable by default | In the past, X-Ray doesn’t support “.”. So we have a translator in x-ray export to translates it to “_” before sending traces to X-Ray Service. | To match otel naming style, x-ray service team decide to change their service to support both \".\" type and \"\" type of naming. In this case the translator that translate \".\" to \"\" is no-longer needed. This PR change the way this translator work | X-Ray PMs agree on rolling out this change by using feature-gate\n\n### 🚀 New components 🚀\n\n- `awss3receiver`: Initial implementation of the AWS S3 receiver. (#30750)\n- `receiver/mysql`: Adds INFORMATION_SCHEMA TABLES metrics (#32693)\n  This adds table size metrics using the INFORMATION_SCHEMA TABLES table: https://dev.mysql.com/doc/refman/8.3/en/information-schema-tables-table.html. \n  Specifically, we are adding the columns: `TABLE_ROWS`, `AVG_ROW_LENGTH`, `DATA_LENGTH`, `INDEX_LENGTH`.\n  \n- `exporter/otelarrow`: Implementation copied from opentelemetry/otel-arrow repository @v0.23.0. (#26491)\n\n### 💡 Enhancements 💡\n\n- `filelogreceiver`: Add container operator parser (#31959)\n- `jsonlogencodingextension`: Move jsonlogencodingextension to alpha (#32697)\n- `exceptionsconnector`: Make span name a default dimension for ouput metrics and log records. (#32162)\n- `azureblobreceiver`: Support service principal authentication for Blob storage (#32705)\n- `deltatocumulativeprocessor`: exponential histogram accumulation (#31340)\n  accumulates exponential histogram datapoints by adding respective bucket counts. also handles downscaling, changing zero-counts, offset adaptions and optional fields\n- `sumologicexporter`: add sticky session support (#32315)\n- `elasticsearchexporter`: Replace go-elasticsearch BulkIndexer with go-docappender (#32378)\n  Replace go-elasticsearch BulkIndexer with go-docappender bulk indexer, in preparation for future reliability fixes.\n  As a result of this change, there are minor behavioral differences:\n  - flush timeout is now enforced on client side\n  - oversize payload special handling is now removed\n  - go-docappender uses bulk request filterPath which means bulk response is smaller, less JSON parsing and lower CPU usage\n  - document level retry debug logging is removed as retries are done transparently\n  \n- `elasticsearchexporter`: Converts more SemConv fields in OTel events to ECS fields in Elasticsearch documents when `mapping.mode: ecs` is specified. (#31694)\n- `extension/storage/filestorage`: New flag cleanup_on_start for the compaction section (default=false). (#32863)\n  It will remove all temporary files in the compaction directory (those which start with `tempdb`),\n  temp files will be left if a previous run of the process is killed while compacting.\n  \n- `opampsupervisor`: Allows the supervisor to persist its instance ID between restarts. (#21073)\n- `opampsupervisor`: Adds the ability to configure the agent description (#32824)\n- `vcenterreceiver`: Refactors how and when client makes calls in order to provide for faster collection times. (#31837)\n- `resourcedetectionprocessor`: Support GCP Bare Metal Solution in resource detection processor. (#32985)\n- `splunkhecreceiver`: Make the channelID header check case-insensitive and allow hecreceiver endpoints able to extract channelID from query params (#32995)\n- `processor/transform`: Allow common where clause (#27830)\n- `loadbalancingexporter`: Improve the performance when merging traces belonging to the same backend (#32032)\n- `pkg/ottl`: Added support for timezone in Time converter (#32140)\n- `jsonlogencodingextension`: Adds a new encoding option for JSON log encoding exension to grab attributes and resources from a log and output that in JSON format. (#32679)\n- `probabilisticsamplerprocessor`: Adds the `FailClosed` flag to solidify current behavior when randomness source is missing. (#31918)\n- `prometheusremotewriteexporter`: Add `exporter.prometheusremotewritexporter.RetryOn429` feature gate to retry on http status code 429 response. (#31032)\n  The feature gate is initially disabled by default.\n- `vcenterreceiver`: Changing various default configurations for vcenterreceiver and removing warnings about future release. (#32803, #32805, #32821, #32531, #32557)\n  The resource attributes that will now be enabled by default are `vcenter.datacenter.name`, `vcenter.virtual_app.name`,\n  `vcenter.virtual_app.inventory_path`, `vcenter.vm_template.name`, and `vcenter.vm_template.id`. The metric\n  `vcenter.cluster.memory.used` will be removed.  The metrics `vcenter.cluster.vm_template.count` and\n  `vcenter.vm.memory.utilization` will be enabled by default.\n  \n- `sqlserverreceiver`: Add metrics for database status (#29865)\n- `sqlserverreceiver`: Add more metrics (#29865)\n  Added metrics are:\n  - sqlserver.resource_pool.disk.throttled.read.rate\n  - sqlserver.resource_pool.disk.throttled.write.rate\n  - sqlserver.processes.blocked\n  These metrics are only available when directly connecting to the SQL server instance\n  \n- `extension/encoding/text_encoding`: Add support for marshaling and unmarshaling text with separators. (#32679)\n\n### 🧰 Bug fixes 🧰\n\n- `deltatocumulativeprocessor`: Evict only stale streams (#33014)\n  Changes eviction behavior to only evict streams that are actually stale.\n  Currently, once the stream limit is hit, on each new stream the oldest tracked one is evicted.\n  Under heavy load this can rapidly delete all streams over and over, rendering the processor useless.\n  \n- `elasticsearchexporter`: Retried docs are no longer included in failed docs in an edge case where all errors are retriable (#33092)\n  Update dep go-docappender to 2.1.2.\n  This fixes the bug when all errors are retriable in bulk request response, retried docs will be included in failed docs.\n  \n- `cmd/opampsupervisor`: The OpAMP supervisor now configures the `ppid` parameter of the opamp extension, which allows the collector to shut down if the supervisor is no longer running. (#32189)\n- `vcenterreceiver`: Adds inititially disabled packet drop rate metric for VMs. (#32929)\n- `awskinesisexporter`: fixed compressed data not generating the compression footers (#32860)\n- `splunkhecreceiver`: Fix single metric value parsing (#33084)\n- `vcenterreceiver`: vcenterreceiver client no longer returns error if no Virtual Apps are found. (#33073)\n- `vcenterreceiver`: Adds inititially disabled new packet rate metrics to replace the existing ones for VMs & Hosts. (#32835)\n- `googlecloudpubsubreceiver`: Fix memory leak during shutdown (#32361)\n- `datadogexporter`: Compress host metadata before sending with gzip. (#32992)\n- `resourcedetectionprocessor`: Change type of `host.cpu.stepping` from int to string. (#31136)\n  - Disable the `processor.resourcedetection.hostCPUSteppingAsString` feature gate to get the old behavior.\n  \n- `pkg/ottl`: Fixes a bug where function name could be used in a condition, resulting in a cryptic error message. (#33051)\n\n## v0.100.0\n\n### 🛑 Breaking changes 🛑\n\n- `receiver/hostmetrics`: enable feature gate `receiver.hostmetrics.normalizeProcessCPUUtilization` (#31368)\n  This changes the value of the metric `process.cpu.utilization` by dividing it by the number of CPU cores.\n  For example, if a process is using 2 CPU cores on a 16-core machine,\n  the value of this metric was previously `2`, but now it will be `0.125`.\n  \n- `testbed`: Remove deprecated `GetAvailablePort` function (#32800)\n\n### 🚀 New components 🚀\n\n- `healthcheckv2extension`: Introduce the skeleton for the temporary healthcheckv2 extension. (#26661)\n- `intervalprocessor`: Implements the new interval processor. See the README for more info about how to use it (#29461)\n- `OpenTelemetry Protocol with Apache Arrow Receiver`: Implementation copied from opentelemetry/otel-arrow repository @v0.20.0. (#26491)\n- `roundrobinconnector`: Add a roundrobin connector, that can help single thread components to scale (#32853)\n\n### 💡 Enhancements 💡\n\n- `telemetrygen`: Add support to set metric name (#32840)\n- `exporter/kafkaexporter`: Enable setting message topics using resource attributes. (#31178)\n- `exporter/datadog`: Introduces the Datadog Agent logs pipeline for exporting logs to Datadog under the \"exporter.datadogexporter.UseLogsAgentExporter\" feature gate. (#32327)\n- `elasticsearchexporter`: Add retry.retry_on_status config (#32584)\n  Previously, the status codes that trigger retries were hardcoded to be 429, 500, 502, 503, 504.\n  It is now configurable using `retry.retry_on_status`, and defaults to `[429, 500, 502, 503, 504]` to avoid a breaking change.\n  To avoid duplicates, it is recommended to configure `retry.retry_on_status` to `[429]`, which would be the default in a future version.\n  \n- `exporter/splunkhec`: add experimental exporter batcher config (#32545)\n- `windowsperfcountersreceiver`: Returns partial errors for failures during scraping to prevent throwing out all successfully retrieved metrics (#16712)\n- `jaegerencodingextension`: Promote jaegerencodingextension to alpha (#32699)\n- `kafkaexporter`: add an ability to publish kafka messages with message key based on metric resource attributes - it will allow partitioning metrics in Kafka. (#29433, #30666, #31675)\n- `cmd/opampsupervisor`: Switch the OpAMP Supervisor's bootstrap config to use the nopreceiver and nopexporter (#32455)\n- `otlpencodingextension`: Move otlpencodingextension to alpha (#32701)\n- `prometheusreceiver`: Prometheus receivers and exporters now preserve 'unknown', 'info', and 'stateset' types. (#16768)\n  It uses the metric.metadata field with the 'prometheus.type' key to store the original type.\n- `ptracetest`: Add support for ignore scope span instrumentation scope information (#32852)\n- `sqlserverreceiver`: Enable direct connection to SQL Server (#30297)\n  Directly connecting to SQL Server will enable the receiver to gather more metrics\n  for observing the SQL Server instance. The first metric added with this update is\n  `sqlserver.database.io.read_latency`.\n  \n- `connector/datadog`: The Datadog connector now has a config option to identify top-level spans by span kind. This new logic can be enabled by setting `traces::compute_top_level_by_span_kind` to true in the Datadog connector config. Default is false. (#32005)\n  `traces::compute_top_level_by_span_kind` needs to be enabled in both the Datadog connector and Datadog exporter configs if both components are being used.\n  With this new logic, root spans and spans with a server or consumer `span.kind` will be marked as top-level. Additionally, spans with a client or producer `span.kind` will have stats computed.\n  Enabling this config option may increase the number of spans that generate trace metrics, and may change which spans appear as top-level in Datadog.\n  \n- `exporter/datadog`: The Datadog exporter now has a config option to identify top-level spans by span kind. This new logic can be enabled by setting `traces::compute_top_level_by_span_kind` to true in the Datadog exporter config. Default is false. (#32005)\n  `traces::compute_top_level_by_span_kind` needs to be enabled in both the Datadog connector and Datadog exporter configs if both components are being used.\n  With this new logic, root spans and spans with a server or consumer `span.kind` will be marked as top-level. Additionally, spans with a client or producer `span.kind` will have stats computed.\n  Enabling this config option may increase the number of spans that generate trace metrics, and may change which spans appear as top-level in Datadog.\n  \n- `exporter/datadog`: Support stable semantic conventions for HTTP spans (#32823)\n- `cmd/opampsupervisor`: Persist collector remote config & telemetry settings (#21078)\n- `cmd/opampsupervisor`: Support AcceptsRestartCommand Capability. (#21077)\n- `telemetrygen`: Add headers to gRPC metadata for logs (#32668)\n- `sshcheckreceiver`: Add support for running this receiver on Windows (#30650)\n- `zipkinencodingextension`: Move zipkinencodingextension to alpha (#32702)\n\n### 🧰 Bug fixes 🧰\n\n- `prometheusremotewrite`: Modify prometheusremotewrite.FromMetrics to only generate target_info if there are metrics, as otherwise you can't deduce the timestamp. (#32318)\n- `prometheusremotewrite`: Change prometheusremotewrite.FromMetrics so that the target_info metric is only generated if at least one identifying OTel resource attribute (service.name and/or service.instance.id) is defined. (#32148)\n- `k8sclusterreceiver`: Fix container state metadata (#32676)\n- `sumologicexporter`: do not replace `.` with `_` for prometheus format (#31479)\n- `pkg/stanza`: Allow sorting by ascending order when using the mtime sort_type. (#32792)\n- `opampextension`: Add a new `ppid` parameter that can be used to enable orphan detection for the supervisor. (#32189)\n- `awsxrayreceiver`: Retain CloudWatch Log Group when translating X-Ray segments (#31784)\n- `pkg/stanza`: Fix issue when `exclude_older_than` is enabled without `ordering_criteria` configured (#32681)\n- `awskinesisexporter`: the compressor was crashing under high load due it not being thread safe. (#32589)\n  removed compressor abstraction and each execution has its own buffer (so it's thread safe)\n- `filelogreceiver`: When a flush timed out make sure we are at EOF (can't read more) (#31512, #32170)\n- `vcenterreceiver`: Adds the `vcenter.cluster.name` resource attribute to resource pool with a ClusterComputeResource parent (#32535)\n- `vcenterreceiver`: Updates `vcenter.cluster.memory.effective` (primarily that the value was reporting MiB when it should have been bytes) (#32782)\n- `vcenterreceiver`: Adds warning to `vcenter.cluster.memory.used` metric if configured about its future removal (#32805)\n- `vcenterreceiver`: Updates the `vcenter.cluster.vm.count` metric to also report suspended VM counts (#32803)\n- `vcenterreceiver`: Adds `vcenter.datacenter.name` attributes to all resource types to help with resource identification (#32531)\n- `vcenterreceiver`: Adds `vcenter.cluster.name` attributes warning log related to Datastore resource (#32674)\n- `vcenterreceiver`: Adds new `vcenter.virtual_app.name` and `vcenter.virtual_app.inventory_path` resource attributes to appropriate VM Resources (#32557)\n- `vcenterreceiver`: Adds functionality for `vcenter.vm.disk.throughput` while also changing to a gauge. (#32772)\n- `vcenterreceiver`: Adds initially disabled functionality for VM Templates (#32821)\n- `remotetapprocessor`: Fix memory leak on shutdown (#32571)\n- `haproxyreceiver`: Fix reading stats larger than 4096 bytes (#32652)\n- `connector/count`: Fix handling of non-string attributes in the count connector (#30314)\n- `datadogexporter`: Fix nil pointer dereference when using beta infrastructure monitoring offering (#32865)\n  The bug happened under the following conditions:\n  - Setting `datadog.host.use_as_host_metadata` to true on a payload with data about the Datadog exporter host\n  - Running using the official opentelemetry-collector-contrib Docker image\n  \n- `pkg/translator/jaeger`: translate binary attribute values to/from Jaeger as is, without encoding them as base64 strings (#32204)\n- `awscloudwatchreceiver`: Fixed a bug where autodiscovery would not use nextToken in the paginated request (#32053)\n- `awsxrayexporter`: make comma`,` as invalid char for x-ray segment name (#32610)\n\n## v0.99.0\n\n### 🛑 Breaking changes 🛑\n\n- `dynatraceexporter`: remove deprecated component (#32278)\n- `extension/filestorage`: Replace path-unsafe characters in component names (#3148)\n  The feature gate `extension.filestorage.replaceUnsafeCharacters` is now stable and cannot be disabled.\n  See the File Storage extension's README for details.\n  \n- `gitproviderreceiver`: Changed git provider metrics to better match conventions (#31985)\n  - Renamed `git.repository.pull_request.open.time` to `git.repository.pull_request.time_open`\n  - Renamed `git.repository.pull_request.merged.time` to `git.repository.pull_request.time_to_merge`\n  - Renamed `git.repository.pull_request.approved.time` to `git.repository.pull_request.time_to_approval`\n  - Combined `git.repository.pull_request.merged.count` and `git.repository.pull_request.open.count` into `git.repository.pull_request.count` with an attribute of `pull_request.state` equal to `open` or `merged`\n  \n- `all`: Bump minimum version to go 1.21.0 (#32451)\n- `exporter/loadbalancing`: Change AWS Cloud map resolver config fields from camelCase to snake_case. (#32331)\n  The snake_case is required in OTel Collector config fields. It used to be enforced by tests in cmd/oteltestbedcol,\n  but we had to disable them. Now, the tests are going to be enforced on every component independently. \n  Hence, the camelCase config fields recently added with the new AWS Cloud Map resolver has to be fixed.\n  \n- `connector/servicegraphconnector`: Change `connector.servicegraph.virtualNode` feature gate from Alpha to Beta (now enabled by default) and change `virtual_node_peer_attributes` default values. (#31734)\n\n### 🚀 New components 🚀\n\n- `googleclientauthextension`: Add implementation of Google Client Auth Extension. (#32029)\n- `ackextension`: Promote to `alpha` stability (#26376)\n\n### 💡 Enhancements 💡\n\n- `deltatocumulativeprocessor`: exposes max_stale as metric (#32441)\n- `sumologicexporter`: use Sumo Logic Extension for authentication and to obtain endpoint (#31479)\n- `failoverconnector`: This change puts the failoverconnector into alpha (#20766)\n- `vcenterreceiver`: Changes process for collecting VMs & VM perf metrics used by the `vccenterreceiver` to be more efficient (one call now for all VMs) (#31837)\n- `opampextension`: Added a new `agent_description.non_identifying_attributes` config option to allow setting user-defined non-identifying attributes (#32107)\n- `googleclientauthextension`: Mark Google Client Auth Extension alpha stability. (#32442)\n- `splunkhecreceiver`: adding support for ack in the splunkhecreceiver (#26376)\n- `hostmetricsreceiver`: The hostmetricsreceiver now caches the system boot time at receiver start and uses it for all subsequent calls. The featuregate `hostmetrics.process.bootTimeCache` can be disabled to restore previous behaviour. (#28849)\n  This change was made because it greatly reduces the CPU usage of the process and processes scrapers.\n- `filelogreceiver`: Add `send_quiet` and `drop_quiet` options for `on_error` setting of operators (#32145)\n- `otlpjsonfilereceiver`: Add a replay_file config option to support replaying static telemetry (#31533)\n- `pkg/ottl`: Add `IsList` OTTL Function (#27870)\n- `rabbitmqexporter`: Implements the RabbitMQ exporter (#28891)\n- `filelogreceiver`: Add `exclude_older_than` configuration setting (#31053)\n- `pkg/stanza/operator/transformer/recombine`: add a new \"max_unmatched_batch_size\" config parameter to configure the maximum number of consecutive entries that will be combined into a single entry before the match occurs (#31653)\n- `awsxrayreceiver`: Add support for local namespace in subsegment (#31514)\n\n### 🧰 Bug fixes 🧰\n\n- `awscloudwatchreceiver`: The receiver now supports extracting data from named loggroups without requiring filters for log streams. This was already advertised as feature, but ignored during initialization. (#32345)\n- `awskinesisexporter`: Wraps the `AssumeRoleProvider` in a `CachedCredentials` provider, in the case the AWS role is specified. This prevents a role assumption from happening every API call. (#32415)\n- `receiver/hostmetricsreceiver`: do not extract the cpu count if the metric is not enabled; this will prevent unnecessary overhead, especially on windows (#32133)\n- `azuremonitorexporter`: Fix: Use correct parentId for span events. (#27233)\n- `failoverconnector`: This change adds a fix for an identified bug regarding extra failover switches (#32094)\n- `failoverconnector`: Fix flaky test in pipeline selector component (#32396)\n- `pkg/stanza`: Fix race condition which prevented `jsonArrayParserFeatureGate` from working correctly. (#32313)\n- `cmd/opampsupervisor`: Fix collector subprocess not being stopped if bootstrapping fails (#31943)\n- `vcenterreceiver`: Remove the `vcenter.cluster.name` resource attribute from Host resources if the Host is standalone (no cluster) (#32548)\n- `azureeventhubreceiver`: Fix memory leak on shutdown (#32401)\n- `fluentforwardreceiver`: Fix memory leak (#32363)\n- `processor/resourcedetection, exporter/datadog`: Fix memory leak on AKS (#32574)\n- `mongodbatlasreceiver`: Fix memory leak by closing idle connections on shutdown (#32206)\n- `haproxyreceiver`: Fix show stat command on unix socket (#32291)\n- `opampsupervisor`: Fix restart delay when agent process exits unexpectedly. (#27891)\n- `spanmetrics`: Discard counter span metric exemplars after each flush interval to avoid unbounded memory growth (#31683)\n  This aligns exemplar discarding for counter span metrics with the existing logic for histogram span metrics\n- `stanza`: Unmarshaling now preserves the initial configuration. (#32169)\n- `resourcedetectionprocessor`: Update to ec2 scraper so that core attributes are not dropped if describeTags returns an error (likely due to permissions) (#30672)\n\n## v0.98.0\n\n### 🛑 Breaking changes 🛑\n\n- `podmanreceiver`: Adds metrics and resources metadata and sets seconds precision for cpu metrics (#28640)\n- `clickhouseexporter`: Add ServiceName as `column` into Clickhouse metrics tables (#31670)\n  It's a breaking change. users who upgrade to the latest version need to alter the Clickhouse table:\n  ```sql\n  ALTER TABLE otel_metrics_exponential_histogram ADD COLUMN ServiceName LowCardinality(String) CODEC(ZSTD(1));\n  ALTER TABLE otel_metrics_gauge ADD COLUMN ServiceName LowCardinality(String) CODEC(ZSTD(1));\n  ALTER TABLE otel_metrics_histogram ADD COLUMN ServiceName LowCardinality(String) CODEC(ZSTD(1));\n  ALTER TABLE otel_metrics_sum ADD COLUMN ServiceName LowCardinality(String) CODEC(ZSTD(1));\n  ALTER TABLE otel_metrics_summary ADD COLUMN ServiceName LowCardinality(String) CODEC(ZSTD(1));\n  ```\n  \n- `elasticsearchexporter`: Initial pass in implementing the `ecs` mapping mode (#31553)\n  Breaking change if mapping `mode` is set to `ecs`, use `none` to maintain existing format\n- `pkg/stanza`: Revert recombine operator's 'overwrite_with' default value. (#30783)\n  Restores the previous the default value of `oldest`, meaning that the recombine operator will emit the\n  first entry from each batch (with the recombined field). This fixes the bug introduced by 30783 and restores\n  the default setting so as to effectively cancel out the bug for users who were not using this setting.\n  For users who were explicitly setting `overwrite_with`, this corrects the intended behavior.\n  \n- `processor/attributes, processor/resource`: Remove stable coreinternal.attraction.hash.sha256 feature gate. (#31997)\n- `receiver/dockerstats`: Remove stable receiver.dockerstats.useScraperV2 feature gate. (#31999)\n- `awsxrayexporter`: change x-ray exporter's translator to make \".\" split annotation pass as-is (#31732)\n  In the past, X-Ray doesn’t support “.”. So we have a translator in x-ray export to translates it to “_” before sending traces to X-Ray Service. | To match otel naming style, x-ray service team decide to change their service to support both \".\" type and \"\" type of naming. In this case the translator that translate \".\" to \"\" is no-longer needed. This PR change the way this translator work | X-Ray PMs agree on rolling out this change by using feature-gate\n- `oracledbreceiver`: Fix incorrect values being set for oracledb.tablespace_size.limit and oracledb.tablespace_size.usage (#31451)\n  Please grant the `DBA_TABLESPACE_USAGE_METRICS` permission to the user connecting to the Oracle DB instance to ensure all enabled\n  metrics are properly ingested.\n\n### 🚩 Deprecations 🚩\n\n- `postgresqlreceiver`: Minimal supported PostgreSQL version will be updated from 9.6 to 12.0 in a future release. (#30923)\n  Aligning on the supported versions as can be seen [in the PostgreSQL releases section](https://www.postgresql.org/support/versioning)\n  \n\n### 🚀 New components 🚀\n\n- `avrologencodingextension`: Add new encoding extension to support mapping of AVRO messages to logs. (#21067)\n\n### 💡 Enhancements 💡\n\n- `ottl`: Add new Unix function to convert from epoch timestamp to time.Time (#27868)\n- `filelogreceiver`: When reading a file on filelogreceiver not on windows, if include_file_owner_name is true, it will add the file owner name as the attribute `log.file.owner.name` and if include_file_owner_group_name is true, it will add the file owner group name as the attribute `log.file.owner.group.name`. (#30775)\n- `awsproxyextension`: Make awsproxy extension more resilient by initiating the AWS client during Start. (#27849)\n- `deltatocumulativeprocessor`: self-instrumentation to observe key metrics of the stream accumulation (#30705)\n- `datadog/connector`: Enable connector to use any attribute from the resource as Container Tag (#32224)\n  This change allows the connector to use any attribute from the resource as a container tag. This is useful when you want to use a custom attribute from the resource as a container tag. For example, you can use the `namespace` attribute from the resource as a container tag.\n  \n- `exceptionsconnector`: change stability of exceptionsconnector from development to alpha (#31820)\n- `exceptionsconnector`: Copy span attributes to the generated log from exception. (#24410)\n- `prometheusreceiver`: Allows receiving prometheus native histograms (#26555)\n  - Native histograms are compatible with OTEL exponential histograms.\n  - The feature can be enabled via the feature gate `receiver.prometheusreceiver.EnableNativeHistograms`.\n    Run the collector with the command line option `--feature-gates=receiver.prometheusreceiver.EnableNativeHistograms`.\n  - Currently the feature also requires that targets are scraped via the ProtoBuf format.\n    To start scraping native histograms, set\n    `config.global.scrape_protocols` to `[ PrometheusProto, OpenMetricsText1.0.0, OpenMetricsText0.0.1, PrometheusText0.0.4 ]` in the\n    receiver configuration. This requirement will be lifted once Prometheus can scrape native histograms over text formats.\n  - For more up to date information see the README.md file of the receiver at\n    https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/receiver/prometheusreceiver/README.md#prometheus-native-histograms.\n  \n- `all`: Add support for ARM build (#12920)\n- `failoverconnector`: Support ignoring `max_retries` setting in failover connector (#9868)\n- `spanmetricsconnector`: Change default value of metrics_flush_interval from 15s to 60s (#31776)\n- `pkg/ottl`: Adding a string converter into pkg/ottl (#27867)\n- `cmd/opampsupervisor`: Handle OpAMP connection settings. (#21043)\n- `loadbalancingexporter`: Support the timeout period of k8s resolver list watch can be configured. (#31757)\n- `cmd/telemetrygen`: Add Support for specifying Log Severity (#26498)\n\n### 🧰 Bug fixes 🧰\n\n- `datadog/connector`: Fix data race in datadog metrics client (#31964)\n  The PR ensures mutex protects gauges map in every code path.\n- `exporter/awskinesisexporter`: Fixed issue with compression what was causing EOF exceptions when attempting to decompress the payload (#32081)\n- `filelogreceiver`: Fix missing scope name and group logs based on scope (#23387)\n- `jaegerremotesamplingextension`: Fix leaking goroutine on shutdown (#31157)\n- `jmxreceiver`: Fix memory leak during component shutdown (#32289)\n- `k8sobjectsreceiver`: Fix memory leak caused by the pull mode's interval ticker (#31919)\n- `kafkareceiver`: fix kafka receiver panic on shutdown (#31926)\n- `prometheusreceiver`: Fix a bug where a new prometheus receiver with the same name cannot be created after the previous receiver is Shutdown (#32123)\n- `resourcedetectionprocessor`: Only attempt to detect Kubernetes node resource attributes when they're enabled. (#31941)\n- `syslogreceiver`: Fix issue where static resource and attributes were ignored (#31849)\n\n## v0.97.0\n\n### 🛑 Breaking changes 🛑\n\n- `datadogconnector`: Remove feature gate `connector.datadogconnector.performance` (#31638)\n- `cmd/mdatagen`: Delete deprecated cmd/mdatagen from this project. Use go.opentelemetry.io/collector/cmd/mdatagen instead. (#30497)\n- `receiver/postgresql`: Bump postgresqlreceiver.preciselagmetrics gate to beta (#31220)\n- `receiver/vcenter`: Bump receiver.vcenter.emitPerfMetricsWithObjects feature gate to stable (#31215)\n- `prometheusreceiver`: Remove enable_protobuf_negotiation option on the prometheus receiver. Use config.global.scrape_protocols = [ PrometheusProto, OpenMetricsText1.0.0, OpenMetricsText0.0.1, PrometheusText0.0.4 ] instead. (#30883)\n  See https://prometheus.io/docs/prometheus/latest/configuration/configuration/#configuration-file for details on setting scrape_protocols.\n- `vcenterreceiver`: Fixed the resource attribute model to more accurately support multi-cluster deployments (#30879)\n  For more information on impacts please refer https://github.com/open-telemetry/opentelemetry-collector-contrib/pull/31113. The main impacts are that\n  the `vcenter.resource_pool.name`, `vcenter.resource_pool.inventory_path`, and `vcenter.cluster.name` are reported with more accuracy on VM metrics.\n  \n\n### 🚩 Deprecations 🚩\n\n- `instanaexporter`: Mark the Instana Exporter as deprecated. (#31765)\n\n### 🚀 New components 🚀\n\n- `awss3receiver`: introduce the AWS S3 receiver (#30750)\n- `sumologicextension`: promote to `alpha` stability (#29601)\n- `googleclientauthextension`: Add boilerplate for Google Client Auth Extension (#31412)\n- `grafanacloudconnector`: Adds a connector to generate metrics for Grafana Cloud. (#31647)\n- `rabbitmqexporter`: Add new exporter for sending telemetry to RabbitMQ brokers using the AMQP 0.9.1 protocol (#28891)\n\n### 💡 Enhancements 💡\n\n- `exporter/loadbalancingexporter`: Adding AWS Cloud Map for service discovery of Collectors backend. (#27241)\n- `ottl`: Add new function to decode a base64 encoded string and output the original string (#31543)\n- `ackextension`: adding the in-memory implementation of the ackextension (#26376)\n- `awss3exporter`: add `compression` option to enable file compression on S3 (#27872)\n  Add `compression` option to compress files using `compress/gzip` library before uploading to S3.\n  \n- `servicegraphprocessor`: Added a new configuration option `database_name_attribute` to allow users to specify a custom attribute name for identifying the database name in span attributes. (#30726)\n- `awss3exporter`: Add support for encoding extension to awss3exporter (#30554)\n- `processor/k8sattributes`: Add support for `k8s.node.uid` metadata (#31637)\n- `awss3exporter`: Add support for specifying the file extension for files uploaded to S3 when using an encoding extension. (#31818)\n- `datadogexporter`: Datadog exporter uses the same default HTTP settings as Datadog Agent HTTP transport (#31733)\n- `datadogexporter`: Datadog exporter respects a subset of settings in confighttp client configs (#31733)\n  Currently the following configs are respected: `read_buffer_size`, `write_buffer_size`, `timeout`, `max_idle_conns`, `max_idle_conns_per_host`, `max_conns_per_host`, `idle_conn_timeout`, `disable_keep_alives` and `tls.insecure_skip_verify`.\n- `deltatocumulativeprocessor`: introduce configurable stream limit (#31488)\n  Adds `max_streams` option that allows to set upper bound (default = unlimited)\n  to the number of tracked streams. Any additional streams exceeding the limit\n  are dropped.\n  \n- `deltatocumulativeprocessor`: expire stale series (#30705, #31016)\n  Adds `max_stale` option that allows to set an interval (default = `5min`)\n  after which a series that no longer receives new samples is removed from\n  tracking.\n  \n- `datadogconnector`: Add a new option to the Datadog connector to enable container tags on stats Payloads. (#31642)\n  This change adds a new option to the Datadog connector to enable container tags on stats Payloads. This is useful for users who want to use container tags as second primary tag for Datadog APM.\n  \n- `dockerstatsreceiver`: add metrics for online CPU count and memory fails count (#31366)\n- `fileexporter`: Adopt the encoding extension with the file exporter. (#31774)\n- `pkg/ottl`: Add `ParseXML` function for parsing XML from a target string. (#31133)\n- `fileexporter`: Added the option to write telemetry data into multiple files, where the file path is based on a resource attribute. (#24654)\n- `fileexporter`: File write mode is configurable now (truncate or append) (#31364)\n- `elasticsearchexporter`: When timestamp is not set, use observedTimestamp (#11752)\n- `k8sclusterreceiver`: add optional status_last_terminated_reason resource attribute (#31282)\n- `awsproxyextension`: Expose service_name as configurable option. Previously, it was hardcoded as xray. (#29550)\n- `datadogexporter`: Add new telemetry metric, `otelcol_datadog_otlp_translator_resources_missing_source` that counts OTLP resources missing a hostname-identifying attribute. (#31805)\n  - Enable Collector metrics https://opentelemetry.io/docs/collector/internal-telemetry/#configure-internal-metrics to check for this metric.\n  \n- `extension/opamp`: Promote the OpAMP extension to alpha stability (#31616)\n- `prometheusremotewriteexporter`: Publish telemetry about translation of metrics from Otel to Prometheus. Don't drop all data points if some fail translation. (#29729)\n- `prometheusreceiver`: Use confighttp for target allocator client (#31449)\n- `spanmetricsconnector`: Add `metrics_expiration` option to enable expiration of metrics if spans are not received within a certain time frame. (#30559)\n  The feature can be configured by specifiying the desired duration in the `metrics_expiration` option. By default, the expiration is disabled (set to 0).\n- `splunkentreceiver`: Updated the config.go and propogated these changes to other receiver components. Change was necessary to differentiate different configurable endpoints. (#30254)\n- `exporter/datadogexporter`: Do not drop traces when payload channel is full. (#31893)\n- `connector/datadogconnector`: Do not resolve container tags if payload already has tags associated with it. (#31893)\n\n### 🧰 Bug fixes 🧰\n\n- `bigipreceiver`: Fix potential nil pointer usage in GetPoolMembers (#31899)\n- `carbonreceiver`: Do not report fatal error when closed normally (#31913)\n- `datadogexporter`: Fix data race in metrics exporter shutdown (#31663)\n- `deltatocumulativeprocessor`: timer-based expiry (#31615)\n  converts expiry to 1m timer, eliminating a race condition and failing test\n  \n- `telemetrygen`: Do not use WithBlock when forming grpc connections for metrics/traces in telemetrygen to avoid infinite retry after failure (#31401)\n- `filestatsreceiver`: Fix file.path to return the proper absolute path of the file (#31738)\n- `internal/docker`: Updated docker dependency and fixed zap.String incompatibility (#31087)\n- `exporter/loadbalancing`: Fix panic when a sub-exporter is shut down while still handling requests. (#31410)\n- `cmd/telemetrygen`: Fixed key mapping for logs telemetry attributes. (#31309)\n- `exporter/awskinesisexporter`: Fix the capacity of records slices in the initialized batch (#20914)\n- `hostmetricsreceiver`: Adds the receiver.hostmetrics.normalizeProcessCPUUtilization feature gate to optionally normalize process.cpu.utilization values. (#31368)\n  When enabled, the receiver.hostmetrics.normalizeProcessCPUUtilization feature gate will cause process.cpu.utilization values to be divided by the number of logical cores on the system. This is necessary to produce a value on the interval of [0-1], as the description of process.cpu.utilization the metric says.\n  \n- `transformprocessor`: Change metric unit for metrics extracted with `extract_count_metric()` to be the default unit (`1`) (#31575)\n  The original metric `unit` does not apply to extracted `count` metrics the same way it does to `sum`, `min` or `max`. \n  Metrics extracted using `extract_count_metric()` now use the more appropriate default unit (`1`) instead.\n  \n- `dockerstatsreceiver`: Add shutdown method to fix leaking goroutines (#30438)\n- `loadbalancingexporter`: Fix memory leaks on shutdown (#31050)\n- `signalfxexporter`: Fix memory leak in shutdown (#30864, #30438)\n- `servicegraphprocessor`: Fix 'failed to find dimensions for key' error from race condition in metrics cleanup. (#31701)\n- `processor/k8sattributes`: Allows k8sattributes processor to work with k8s role/rolebindings when filter::namespace is set. (#14742)\n- `exporter/datadog`: Demote noisy gohai logs to debug level (#29741)\n  These logs would be present at the info level when using the official Docker images but were not useful to end-users.\n  \n- `opencensusreceiver`: Refactor the opencensusreceiver to pass lifecycle tests and avoid leaking gRPC connections. (#31643)\n- `sqlqueryreceiver`: Fix memory leak on shutdown for log telemetry (#31782)\n\n## v0.96.0\n\n### 🛑 Breaking changes 🛑\n\n- `f5cloudexporter`: Remove deprecated module (#31531)\n- `datadogconnector`: Move feature gate `connector.datadogconnector.performance` to stable stage. (#31414)\n  `connector.datadogconnector.performance` will be removed in the next release\n- `spanmetricsprocessor`: Remove spanmetrics processor (#29567)\n  - You can use the spanmetrics connector as a replacement\n  \n- `httpforwarder`: Remove extension named httpforwarder, use httpforwarderextension instead. (#24171)\n- `k8sclusterreceiver`: Remove deprecated k8s.kubeproxy.version resource attribute (#29748)\n\n### 🚀 New components 🚀\n\n- `ackextension`: Adding an interface for Acknowledgement extension (#26376)\n- `sumologicextension`: add implementation of Sumo Logic Extension (#29601)\n\n### 💡 Enhancements 💡\n\n- `datadogexporter`: Attach the collector version to stats payloads to improve the debugging experience. (#31454)\n- `awsxrayexporter`: support both deprecated and stable http attributes translation for backward compatibility. (#30935)\n- `azuremonitorexporter`: Added support for configuring the Azure Monitor Exporter connection string via the `APPLICATIONINSIGHTS_CONNECTION_STRING` environment variable. (#31523)\n- `datadogconnector`: datadogconnector no longer mutates the input traces in trace-to-trace pipelines. (#31414)\n- `statsdreceiver`: Add support for the latest version of DogStatsD protocol (v1.3) (#31295)\n- `fileexporter`: Scope the behavior of the fileexporter to its lifecycle, so it is safe to shut it down or restart it. (#27489)\n- `processor/resourcedetection`: Add `processor.resourcedetection.hostCPUSteppingAsString` feature gate to change the type of `host.cpu.stepping` from `int` to `string`. (#31136)\n  This feature gate will graduate to beta in the next release.\n  \n- `routingconnector`: a warning is logged if there are two or more routing items with the same routing statement (#30663)\n- `pkg/ottl`: Add new IsInt function to facilitate type checking. (#27894)\n- `cmd/mdatagen`: Make lifecycle tests generated by default (#31532)\n- `opampextension`: enables creating and using an http client (#31389)\n- `pkg/stanza`: Improve timestamp parsing documentation (#31490)\n- `postgresqlreceiver`: Add `receiver.postgresql.connectionPool` feature gate to reuse database connections (#30831)\n  The default implementation recreates and closes connections on each scrape per database configured/discovered.\n  This change offers a feature gated alternative to keep connections open. Also, it exposes connection configuration to control the behavior of the pool.\n  \n- `datadogconnector`: Add `source:datadogconnector` tag to trace agent telemetry metrics generated by the datadogconnector. (#31528)\n- `datadogexporter`: Add `source:datadogexporter` tag to trace agent telemetry metrics generated by the datadogexporter. (#31528)\n- `datadogexporter`: Automatically map `cloud.region`, `cloud.availability_zone` and `cloud.provider` to the `region`, `zone` and `cloud_provider` host tags. (#31372)\n\n### 🧰 Bug fixes 🧰\n\n- `carbonreceiver`: Accept carbon metrics with float timestamps (#31312)\n- `chronyreceiver`: move initialization of the chrony client to the start function (#27849)\n- `deltatocumulativeprocessor`: permits advancing delta start timestamps, as required by spec. (#31365)\n- `deltatocumulativeprocessor`: due to an oversight, only the first sample of each stream was processed. now all samples are. (#31350)\n- `cmd/telemetrygen`: Inherit root CAs from the host environment if not supplied on the command line. (#31191)\n- `syslogexporter`: fix setting network connection, do not load TLS configuration for UDP (#31130)\n- `journaldreceiver`: Fix bug where failed startup could bury error message due to panic during shutdown (#31476)\n- `loadbalancingexporter`: Fixes a bug where the endpoint become required, despite not being used by the load balancing exporter. (#31371)\n- `oracledbreceiver`: Use metadata.Type for the scraper id to avoid invalid scraper IDs. (#31457)\n- `filelogreceiver`: Fix bug where delete_after_read would cause panic (#31383)\n- `receiver/filelog`: Fix issue where file fingerprint could be corrupted while reading. (#22936)\n- `cmd/telemetrygen`: Fix incorrect error logged in traces batch span processor shutdown (#31362)\n\n## v0.95.0\n\n### 🛑 Breaking changes 🛑\n\n- `all`: Bump minimum version to go 1.21 (#31105)\n- `receiver/elasticsearch`: Remove receiver.elasticsearch.emitNodeVersionAttr feature gate (#31221)\n- `receiver/mongodb`: Bump receiver.mongodb.removeDatabaseAttr feature gate to beta (#31212)\n- `splunkenterprisereceiver`: adds additional metrics specific to indexers (#30704)\n- `exporter/datadogexporter`: Disable APM stats computation in Datadog Exporter by default, `exporter.datadogexporter.DisableAPMStats` is changed to beta (#31219)\n- `extension/storage`: The `filestorage` and `dbstorage` extensions are now standalone modules. (#31040)\n  If using the OpenTelemetry Collector Builder, you will need to update your import paths to use the new module(s).\n  - `github.com/open-telemetry/opentelemetry-collector-contrib/extension/storage/filestorage`\n  - `github.com/open-telemetry/opentelemetry-collector-contrib/extension/storage/dbstorage`\n  \n\n### 🚩 Deprecations 🚩\n\n- `f5cloudexporter`: deprecating component that is no longer maintained (#31186)\n\n### 🚀 New components 🚀\n\n- `confmap/secretsmanagerprovider`: Initial implementation of secrets manager provider. Allows fetch variables from AWS Secrets Manager (#19368)\n- `deltatocumulative`: adds processor to convert sums (initially) from delta to cumulative temporality (#30705)\n\n### 💡 Enhancements 💡\n\n- `hostmetricsreceiver`: Add a new optional resource attribute `process.cgroup` to the `process` scraper of the `hostmetrics` receiver. (#29282)\n- `datadogexporter`: Adds support for stable JVM metrics introduced in opentelemetry-java-instrumentation v2.0.0 (#31194)\n  See https://github.com/DataDog/opentelemetry-mapping-go/pull/265 for details.\n- `datasetexporter`: Release resources if they haven't been used for some time. (#31292)\n- `datadogconnector`: Add a trace config `peer_tags` on supplementary peer tags on APM stats. (#31158)\n- `datadogexporter`: Add a trace config `peer_tags` on supplementary peer tags on APM stats. (#31158)\n- `awss3exporter`: Add a marshaler that stores the body of log records in s3. (#30318)\n- `pkg/ottl`: Adds a new ParseCSV converter that can be used to parse CSV strings. (#30921)\n- `loadbalancingexporter`: Add benchmarks for Metrics and Traces (#30915)\n- `pkg/ottl`: Add support to specify the format for a replacement string (#27820)\n- `pkg/ottl`: Add `ParseKeyValue` function for parsing key value pairs from a target string (#30998)\n- `receivercreator`: Remove use of `ReportFatalError` (#30596)\n- `processor/tail_sampling`: Add metrics that measure the number of sampled spans and the number of spans that are dropped due to sampling decisions. (#30482)\n- `exporter/signalfx`: Send histograms in otlp format with new config `send_otlp_histograms` option (#26298)\n- `receiver/signalfx`: Accept otlp protobuf requests when content-type is \"application/x-protobuf;format=otlp\" (#26298)\n- `signalfxreceiver`: Remove deprecated use of `host.ReportFatalError` (#30598)\n- `syslogexporter`: Adding support for sending rfc6587 octet counts in syslog messages (#31013)\n- `connector/datadogconnector`: Internal telemetry metrics for the Datadog traces exporter are now reported through the Collector's self-telemetry (#31179)\n  - These internal metrics may be dropped or change name without prior notice\n  \n- `exporter/datadogexporter`: Internal telemetry metrics for the Datadog traces exporter are now reported through the Collector's self-telemetry (#31179)\n  - These internal metrics may be dropped or change name without prior notice\n  \n\n### 🧰 Bug fixes 🧰\n\n- `pkg/stanza`: Add 'allow_skip_pri_header' flag to syslog setting. (#30397)\n  Allow parsing syslog records without PRI header. Currently pri header is beng enforced although it's not mandatory by the RFC standard. Since influxdata/go-syslog is not maintained we had to switch to haimrubinstein/go-syslog.\n  \n- `datadogexporter`: Fix bug where multiple resources would cause datadogexporter to send extraneous additional stats buckets. (#31173)\n- `extension/storage`: Ensure fsync is turned on after compaction (#20266)\n- `logstransformprocessor`: Fix potential panic on shutdown due to incorrect shutdown order (#31139)\n- `logicmonitorexporter`: Fix memory leak on shutdown (#31150)\n- `opencensusreceiver`: Fix memory leak on shutdown (#31152)\n- `receiver/prometheusreceiver`: prometheusreceiver fix translation of metrics with _created suffix (#30309)\n- `pkg/stanza`: Fixed a bug in the keyvalue_parser where quoted values could be split if they contained a delimited. (#31034)\n\n## v0.94.0\n\n### 🛑 Breaking changes 🛑\n\n- `servicegraphprocessor`: removed deprecated component, use the servicegraph connector instead. (#26091)\n- `datadogconnector`: Enable feature gate `connector.datadogconnector.performance` by default. (#30829)\n  See https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/connector/datadogconnector#feature-gate-for-performance for caveats of this feature gate.\n- `datadogprocessor`: Delete datadogprocessor which has been deprecated since v0.84.0 (#31026)\n  Use datadogconnector instead.\n- `kafkareceiver`: standardizes the default topic name for metrics and logs receivers to the same topic name as the metrics and logs exporters of the kafkaexporter (#27292)\n  If you are using the Kafka receiver in a logs and/or a metrics pipeline\n  and you are not customizing the name of the topic to read from with the `topic` property,\n  the receiver will now read from `otlp_logs` or `otlp_metrics` topic instead of `otlp_spans` topic.\n  To maintain previous behavior, set the `topic` property to `otlp_spans`.\n  \n- `pkg/stanza`: Entries are no longer logged during error conditions. (#26670)\n  This change is being made to ensure sensitive information contained in logs are never logged inadvertently.\n  This change is a breaking change because it may change user expectations. However, it should require\n  no action on the part of the user unless they are relying on logs from a few specific error cases.\n  \n- `pkg/stanza`: Invert recombine operator's 'overwrite_with' default value. (#30783)\n  Previously, the default value was `oldest`, meaning that the recombine operator _should_ emit the\n  first entry from each batch (with the recombined field). However, the actual behavior was inverted.\n  This fixes the bug but also inverts the default setting so as to effectively cancel out the bug fix\n  for users who were not using this setting. For users who were explicitly setting `overwrite_with`,\n  this corrects the intended behavior.\n  \n\n### 🚩 Deprecations 🚩\n\n- `skywalkingexporter`: Mark the component as unmaintained. If we don't find new maintainers, it will be deprecated and removed. (#23796)\n\n### 🚀 New components 🚀\n\n- `sumologicextension`: add configuration and readme (#29601)\n- `failoverconnector`: Refactor of connector to seperate concerns between managing indexes and core failover component (#20766)\n- `otelarrow`: Skeleton of new OpenTelemetry Protocol with Apache Arrow Receiver (#26491)\n- `processor/interval`: Adds the initial structure for a new processor that aggregates metrics and periodically forwards the latest values to the next component in the pipeline. (#29461)\n  As per the CONTRIBUTING.md recommendations, this PR only creates the basic structure of the processor. The concrete implementation will come as a separate followup PR\n  \n\n### 💡 Enhancements 💡\n\n- `receiver/journald`: add a new config option \"all\" that turns on full output from journalctl, including lines that are too long. (#30920)\n- `pkg/stanza`: Add support in a header configuration for json array parser. (#30321)\n- `awss3exporter`: Add the ability to export trace/log/metrics in OTLP ProtoBuf format. (#30682)\n- `dockerobserver`: Upgrading Docker API version default from 1.22 to 1.24 (#30900)\n- `filterprocessor`: move metrics from OpenCensus to OpenTelemetry (#30736)\n- `groupbyattrsprocessor`: move metrics from OpenCensus to OpenTelemetry (#30763)\n- `datadogconnector`: Add trace configs that mirror datadog exporter (#30787)\n  ignore_resources: disable certain traces based on their resource name\n  span_name_remappings: map of datadog span names and preferred name to map to\n  span_name_as_resource_name: use OTLP span name as datadog operation name\n  compute_stats_by_span_kind: enables an additional stats computation check based on span kind\n  peer_tags_aggregation: enables aggregation of peer related tags\n  trace_buffer: specifies the buffer size for datadog trace payloads\n  \n- `elasticsearchexporter`: Add `mapping.mode: raw` configuration option (#26647)\n  Setting `mapping.mode: raw` in the Elasticsearch exporter's configuration\n  will result logs and traces being indexed into Elasticsearch with their\n  attribute fields directly at the root level of the document instead inside an\n  `Attributes` object. Similarly, this setting will also result in traces being\n  indexed into Elasticsearch with their event fields directly at the root level\n  of the document instead of inside an `Events` object.\n  \n- `loadbalancingexporter`: Optimize metrics and traces export (#30141)\n- `gitproviderreceiver`: Add pull request metrics (#22028)\n  - git.repository.pull_request.open.count\n  - git.repository.pull_request.open.time\n  - git.repository.pull_request.merged.count\n  - git.repository.pull_request.merged.time\n  - git.repository.pull_request.approved.time\n  \n- `all`: Add `component.UseLocalHostAsDefaultHost` feature gate that changes default endpoints from 0.0.0.0 to localhost (#30702)\n  This change affects the following components:\n    - extension/awsproxy\n    - extension/health_check\n    - extension/jaegerremotesampling\n    - internal/aws/proxy\n    - processor/remotetap\n    - receiver/awsfirehose\n    - receiver/awsxray\n    - receiver/influxdb\n    - receiver/jaeger\n    - receiver/loki\n    - receiver/opencensus\n    - receiver/sapm\n    - receiver/signalfx\n    - receiver/skywalking\n    - receiver/splunk_hec\n    - receiver/zipkin\n    - receiver/zookeeper\n  \n- `googlepubsubreceiver`: Add support for GoogleCloud logging encoding (#29299)\n- `processor/resourcedetectionprocessor`: Detect Azure cluster name from IMDS metadata (#26794)\n- `processor/transform`: Add `copy_metric` function to allow duplicating a metric (#30846)\n\n### 🧰 Bug fixes 🧰\n\n- `basicauthextension`: Accept empty usernames. (#30470)\n  Per https://datatracker.ietf.org/doc/html/rfc2617#section-2, username and password may be empty strings (\"\").\n  The validation used to enforce that usernames cannot be empty.\n  \n- `servicegraphconnector`: update prefix to match the component type (#31023)\n- `datadog/connector`: Create a separate connector in the Datadog connector for the trace-to-metrics and trace-to-trace pipelines. It should reduce the number of conversions we do and help with Datadog connector performance. (#30828)\n  Simplify datadog/connector with two separate connectors in trace-to-metrics pipeline and trace-to-trace pipeline.\n- `datadogreceiver`: Set AppVersion to allow Datadog version property to transform properly to service.version resource attribute (#30225)\n- `cmd/opampsupervisor`: Fix memory leak on shutdown (#30438)\n- `exporter/datadog`: Fixes a bug where empty histograms were not being sent to the backend in the distributions mode. (#31019)\n- `pkg/ottl`: Fix parsing of string escapes in OTTL (#23238)\n- `pkg/stanza`: Recombine operator should always recombine partial logs (#30797)\n  Previously, certain circumstances could result in partial logs being emitted without any\n  recombiniation. This could occur when using `is_first_entry`, if the first partial log from\n  a source was emitted before a matching \"start of log\" indicator was found. This could also\n  occur when the collector was shutting down.\n  \n- `pkg/stanza`: Fix bug where recombine operator's 'overwrite_with' condition was inverted. (#30783)\n- `exporter/signalfx`: Use \"unknown\" value for the environment correlation calls as fallback. (#31052)\n  This fixed the APM/IM correlation in the Splunk Observability UI for the users that send traces with no \"deployment.environment\" resource attribute value set.\n- `namedpipereceiver`: Fix SIGSEGV when named pipe creation fails (#31088)\n\n## v0.93.0\n\n### 🛑 Breaking changes 🛑\n\n- `azuremonitorexporter`: Fixed an issue where span attributes with double and int values were incorrectly added to the `measurements` field in the Application Insights schema. These attributes are now correctly placed in the `properties` field. (#29683)\n- `vcenterreceiver`: Bump \"receiver.vcenter.emitPerfMetricsWithObjects\" feature gate (#30615)\n- `docker`: Adopt api_version as strings to correct invalid float truncation (#24025)\n- `extension/filestorage`: Replace path-unsafe characters in component names (#3148)\n  The feature gate `extension.filestorage.replaceUnsafeCharacters` is now enabled by default.\n  See the File Storage extension's README for details.\n  \n- `postgresqlreceiver`: add schema attribute to postgresqlreceiver (#29559)\n  Adds a new resource attribute to the PSQL receiver to store the schema of the table or index\n  Existing table attributes are adjusted to not include the schema, which was inconsistently used\n  \n\n### 🚩 Deprecations 🚩\n\n- `mdatagen`: Deprecate mdatagen in preparation for its move to opentelemetry-collector (#30497)\n\n### 🚀 New components 🚀\n\n- `solarwindsapmsettingsextension`: added configuration and readme (#27668)\n- `alertmanagerexporter`: Add Alertmanager exporter to builder config (#23569)\n- `otelarrow`: Skeleton of new OpenTelemetry Protocol with Apache Arrow Exporter. (#26491)\n- `osqueryreceiver`: Adds osquery receiver skeleton (#30375)\n\n### 💡 Enhancements 💡\n\n- `pkg/stanza`: Add a json array parser operator and an assign keys transformer. (#30321)\n  Json array parser opreator can be used to parse a json array string input into a list of objects. |\n  Assign keys transformer can be used to assigns keys from the configuration to an input list\n  \n- `splunkhecexporter`: Batch data according to access token and index, if present. (#30404)\n- `awscloudwatchlogsexporter`: Add instrumentation scope in log records exported to CloudWatch logs (#30316, #29884)\n- `cassandraexporter`: added authorization by username and password (#27827)\n- `lokiexporter`: migrate metrics to use OpenTelemetry (#30170)\n- `cmd/telemetrygen`: This updates telemetrygen to create multiple child spans per trace and enhances the tool's functionality for load testing the remote tracing backend. (#30687)\n- `cmd/telemetrygen`: This updates telemetrygen with TLS/mTLS options to test the security of telemetry ingestion services and infrastructure for secure communication. To illustrate the usage, a new example, secure-tracing is added to examples collection. (#29681)\n- `k8sattributesprocessor`: Apply lifecycle tests to k8sprocessor, change its behavior to report fatal error (#30387)\n- `k8sclusterreceiver`: add new disabled os.description, k8s.container_runtime.version resource attributes (#30342)\n- `k8sclusterreceiver`: add os.type resource attribute (#30342)\n- `kubeletstatsreceiver`: Add new `*.cpu.usage` metrics. (#25901)\n- `oidcauthextension`: Move validation logic outside of the extension creation, to the configuration validation (#30460)\n- `datadogexporter`: Add support for setting host tags via host metadata. (#30680)\n  When the `datadog.host.use_as_metadata` resource attribute is set to `true`:\n    - Nonempty string-value resource attributes starting with `datadog.host.tag.` will be added as host tags for the host associated with the resource.\n    - deployment.environment and k8s.cluster.name as mapped to Datadog names and added as host tags for the host associated with the resource.\n  \n- `opensearchexporter`: added opensearch exporter to the contrib distribution metadata (#30183)\n- `pkg/ottl`: Add `flatten` function for flattening maps (#30455)\n- `redisreciever`: adds metric for slave_repl_offset (#6942)\n  also adds a shell script to set up docker-compose integration test\n- `exporter/datadogexporter`: Add kafka metrics mapping. This allows users of the JMX Receiver/JMX Metrics Gatherer and kafka metrics receiver to have access to the OOTB kafka Dashboard. (#30731)\n- `receiver/sqlquery`: Add debug log when running SQL query (#29672)\n- `cmd/opampsupervisor`: Use a bootstrapping flow to get the Collector's agent description. (#21071)\n\n### 🧰 Bug fixes 🧰\n\n- `receiver/filelog`: fix panic after upgrading from v0.71.0 when using storage (#30235)\n- `clickhouseexporter`: Fix clickhouse exporter insert metrics data bug (#30210)\n- `prometheusremotewriteexporter`: Check if the context was canceled by a timeout in the component level to avoid unnecessary retries. (#30308)\n- `elasticsearchreceifver`: Fix nil panic on non-linux systems (#30140)\n- `kafkareceiver`: The Kafka receiver now exports some partition-specific metrics per-partition, with a `partition` tag (#30177)\n  The following metrics now render per partition:\n    - kafka_receiver_messages\n    - kafka_receiver_current_offset\n    - kafka_receiver_offset_lag\n  \n\n## v0.92.0\n\n### 🛑 Breaking changes 🛑\n\n- `httpforwarder`: Use confighttp.HTTPDefaultClientSettings when configuring the HTTPClientSettings for the httpforwarder extension. (#6641)\n  By default, the HTTP forwarder extension will now use the defaults set in the extension:\n  * The idle connection timeout is set to 90s.\n  * The max idle connection count is set to 100.\n  \n- `pkg/ottl`: Now validates against extraneous path segments that a context does not know how to use. (#30042)\n- `pkg/ottl`: Throw an error if keys are used on a path that does not allow them. (#30162)\n- `tanzuexporter`: Remove tanzuexporter, user can still use versions 0.91. (#30184)\n- `zipkinexporter`: Use default client HTTP settings in zipkinexporter, move validation to config validation (#29931)\n\n### 🚩 Deprecations 🚩\n\n- `mdatagen`: Component is being moved to core to allow it to be used there as well. (#30173)\n- `k8sclusterreceiver`: deprecate optional k8s.kubeproxy.version resource attribute (#29748)\n- `configschema`: Deprecating configschema to prefer generating documentation as part of its metadata generation with mdatagen (#30187)\n\n### 🚀 New components 🚀\n\n- `failoverconnector`: PR provides core logic for failover connector and implements failover for trace signals (#20766)\n- `failoverconnector`: PR extends failover connector for metric and log pipelines (#20766)\n- `namedpipereceiver`: Add \"namedpipereceiver\" that allows ingesting logs over a Named Pipe (#27234)\n\n### 💡 Enhancements 💡\n\n- `encoding/jaegerencodingextension`: Add support for JSON protocol for jaeger codec (#6272)\n- `githubgen`: Adds a set of distribution reports that can be used to notify distribution maintainers of any changes to distributions. (#28628)\n- `vcenterreceiver`: Add explicit statement of support for version 8 of ESXi and vCenter (#30274)\n- `carbonexporter`: Add support for resourcetotelemetry (#29879)\n- `carbonexporter`: Add retry and queue, use standard configs (#29862)\n- `carbonexporter`: Add ability to configure max_idle_conns (#30109)\n- `mdatagen`: add Meter/Tracer methods to simplify instrumenting components (#29927)\n- `servicegraphprocessor`: update own telemetry to use otel (#29917)\n- `datadogexporter`: DataDog log timestamp (ie. '@timestamp') now includes milliseconds (#29785)\n- `exporter/elasticsearch`: set the User-Agent header in the outgoing HTTP requests. (#29898)\n- `elasticsearchexporter`: add missing trace status description in span (#27645)\n- `routingconnector`: routingconnector supports matching the statement only once (#26353)\n- `filestatsreceiver`: Add a file.count metric to filestatsreceiver that reports the number of files matched by the receiver (#24651)\n- `filterprocessor`: Add telemetry for metrics, logs, and spans that were intentionally dropped via filterprocessor. (#13169)\n- `googlecloudpubsubexporter`: Expose `Endpoint` and `Insecure` in configuration. (#29304)\n- `exporter/honeycombmarker`: set the User-Agent header in the outgoing HTTP requests (#29894)\n- `pkg/ottl`: Add Hour OTTL Converter (#29468)\n- `kafkaexporter`: add ability to publish kafka messages with message key of TraceID - it will allow partitioning of the kafka Topic. (#12318)\n- `kafkareceiver`: Add three new metrics to record unmarshal errors. (#29302)\n- `kineticaexporter`: added metrics handling (#27239)\n- `logzioexporter`: add scopename to exported logs (#20659)\n  when it exists, scope name will be added to exported logs under the scopeName field.\n- `hostmetricsreceiver`: Add `system.memory.limit` metric reporting the total memory available. (#30306)\n  This metric is opt-in. To enable it, set `scrapers::memory::metrics::system.memory.limit::enabled` to `true` in the hostmetrics config.\n  \n- `datadogexporter`: Add support for more semantic conventions related to host metadata (#30158)\n  The following semantic conventions are now detected for host metadata:\n  - `host.ip`\n  - `host.mac`\n  - `system.cpu.physical.count`\n  - `system.cpu.logical.count`\n  - `system.cpu.frequency`\n  - `system.memory.limit`\n  \n- `prometheusexporter`: Accumulate histograms with delta temporality (#4968)\n- `kafkaexporter`: Adds the ability to configure the Kafka client's Client ID. (#30144)\n- `pkg/stanza`: Remove sampling policy from logger (#23801)\n- `resourcedetectionprocessor`: Add \"aws.ecs.task.id\" attribute (#8274)\n  Resourcedetectionprocessor now exports \"aws.ecs.task.id\" attribute, in addition to \"aws.ecs.task.arn\".\n  This allows exporters like \"awsemfexporter\" to automatically pick up that attribute and make it available\n  in templating (e.g. to use in CloudWatch log stream name).\n  \n- `spanmetricsconnector`: Fix OOM issue for spanmetrics by limiting the number of exemplars that can be added to a unique dimension set (#27451)\n- `connector/spanmetrics`: Configurable resource metrics key attributes, filter the resource attributes used to create the resource metrics key. (#29711)\n  This enhancement can be used to fix broken spanmetrics counters after a span producing service restart, when resource attributes contain dynamic/ephemeral values (e.g. process id).\n- `splunkhecreceiver`: Returns json response in raw endpoint when it is successful (#20766)\n- `logicmonitorexporter`: add support for log resource mapping configurations (#29732)\n- `sqlqueryreceiver`: Swap MS SQL Server driver from legacy 'denisenkom' to official Microsoft fork (#27200)\n\n### 🧰 Bug fixes 🧰\n\n- `awsemfexporter`: AWS EMF Exporter will drop metrics that contain Inf values to avoid JSON marshal errors. (#29336)\n- `azuretranslatorpkg`: When receiving data from Azure some data does not meet the Common Specifications when sending the timestamp. Allow the attribute timeStamp to be used as an alternative to the standard time. (#28806)\n- `datadogconnector`: Add feature flag to address memory issue with Datadog Connector (#29755)\n- `filterset`: Fix concurrency issue when enabling caching. (#11829)\n- `pkg/ottl`: Fix issue with the hash value of a match subgroup in replace_pattern functions. (#29409)\n- `opampsupervisor`: Fix panic on agent shutdown (#29955)\n- `prometheusreceiver`: Fix configuration validation to allow specification of Target Allocator configuration without providing scrape configurations (#30135)\n- `carbonexporter`: Fix metric with empty numberdatapoint serialization (#30182)\n- `wavefrontreceiver`: Return error if partially quoted (#30315)\n- `hosmetricsreceiver`: change cpu.load.average metrics from 1 to {thread} (#29914)\n- `bearertokenauthextension`: Http receiver trying to get the authorization with the lower case from headers, But The headers from Http is received as Authorization capitalcase even-though we sent in lower case and Always return 401 Unauthorized (#24656)\n- `pkg/ottl`: Fix bug where the Converter `IsBool` was not usable (#30151)\n- `prometheusremotewriteexporter`: sanitize retry default settings (#30286)\n- `snowflakereceiver`: Fixed bug where storage metrics for snowflake were not being reported (#29750)\n- `apachesparkreceiver`: propagate application list errors to reveal underlying issue (#30278)\n- `haproxyreceiver`: Support empty values in haproxy stats. (#30252)\n- `time`: The `%z` strptime format now correctly parses `Z` as a valid timezone (#29929)\n  `strptime(3)` says that `%z` is \"an RFC-822/ISO 8601 standard\n  timezone specification\", but the previous code did not allow the\n  string \"Z\" to signify UTC time, as required by ISO 8601. Now, both\n  `+0000` and `Z` are recognized as UTC times in all components that\n  handle `strptime` format strings.\n  \n\n## v0.91.0\n\n### 🚀 New components 🚀\n\n- `alertmanagerexporter`: Add Alertmanager exporter implementation and tests (#23569)\n\n### 💡 Enhancements 💡\n\n- `spanmetricsconnector`: Add exemplars to sum metric (#27451)\n- `exporter/datadogexporter`: Add support for nested log attributes. (#29633)\n- `jaegerreceiver,jaegerremotesamplingextension`: mark featuregates to replace Thrift-gen with Proto-gen types for sampling strategies as stable (#27636)\n  The following featuregates are stable:\n    - extension.jaegerremotesampling.replaceThriftWithProto\n    - receiver.jaegerreceiver.replaceThriftWithProto\n  \n- `awsemfexporter/awscloudwatchlogsexporter`: Add component name to user agent header for outgoing put log even requests (#29595)\n- `elasticsearchexporter`: Logstash format compatibility. Traces or Logs data can be written into an index in logstash format. (#29624)\n- `extension/opampextension`: Implement `extension.NotifyConfig` to be notified of the Collector's effective config and report it to the OpAMP server. (#27293)\n- `receiver/influxdbreceiver`: Endpoint `/ping` added to enhance compatibility with third party products (#29594)\n- `kafkareceiver`: Add the ability to consume logs from Azure Diagnostic Settings streamed through Event Hubs using the Kafka API. (#18210)\n- `resourcedetectionprocessor`: Add detection of host.ip to system detector. (#24450)\n- `resourcedetectionprocessor`: Add detection of host.mac to system detector. (#29587)\n- `pkg/ottl`: Add `silent` ErrorMode to allow disabling logging of errors that are ignored. (#29710)\n- `postgresqlreceiver`: Add config property for excluding specific databases from scraping (#29605)\n- `redisreceiver`: Upgrade the redis library dependency to resolve security vulns in v7 (#29600)\n- `signalfxexporter`: Enable HTTP/2 health check by default (#29716)\n- `splunkhecexporter`: Enable HTTP/2 health check by default (#29717)\n- `statsdreceiver`: Add support for 'simple' tags that do not have a defined value, to accommodate DogStatsD metrics that may utilize these. (#29012)\n  This functionality is gated behind a new `enable_simple_tags` config boolean, as it is not part of the StatsD spec.\n\n### 🧰 Bug fixes 🧰\n\n- `exporter/prometheusremotewrite`: prometheusremotewrite exporter fix created metrics missing timestamp (#24915)\n- `connector/spanmetrics`: Fix memory leak when the cumulative temporality is used. (#27654)\n- `awscontainerinsightreceiver`: Filter terminated pods from node request metrics (#27262)\n- `clickhouseexporter`: Fix regression error introduced in #29095 (#29573)\n- `prometheusexporter`: Fix panic when exporter mutates data (#29574)\n- `splunkhecexporter`: Do not send null event field values in HEC events. Replace null values with an empty string. (#29551)\n- `k8sobjectsreceiver`: fix k8sobjects receiver fails when some unrelated Kubernetes API is down (#29706)\n- `resourcedetectionprocessor`: Change type of `host.cpu.model.id` and `host.cpu.model.family` from int to string. (#29025)\n  - Disable the `processor.resourcedetection.hostCPUModelAndFamilyAsString` feature gate to get the old behavior.\n  \n- `Fix problem where checkpoints could be lost when collector is shutdown abruptly`: filelogreceiver (#29609, #29491)\n- `googlecloudspannerreceiver`: Google Cloud Spanner Receiver currently generates an exception and exits if it attempts to read data from a database that doesn't exist. However it's normal for a single receiver to poll multiple databases, so this is not graceful failure. This PR makes a change to gracefully generate an error in case of an unreadable missing database and then continue reading other databases.. (#26732)\n- `pkg/stanza`: Allow `key_value_parser` to parse values that contain the delimiter string. (#29629)\n\n## v0.90.1\n\n### 🧰 Bug fixes 🧰\n\n- `exporters`: Upgrade core dependency to remove noisy \"Exporting finished\" log message in exporters. (#29612)\n\n## v0.90.0\n\n### 🛑 Breaking changes 🛑\n\n- `dockerstatsreceiver`: Add [container.cpu.limit], [container.cpu.shares] and [container.restarts] metrics from docker container api (#21087)\n  It requires API version 1.25 or greater.\n\n### 🚀 New components 🚀\n\n- `failoverconnector`: New component that will allow for pipeline failover triggered by the health of target downstream exporters (#20766)\n- `gitproviderreceiver`: add repo, branch, and contributor count metrics (#22028)\n\n### 💡 Enhancements 💡\n\n- `opensearchexporter`: Promote opensearchexporter to alpha. (#24668)\n- `awsemfexporter`: Improve NaN value checking for Summary metric types. (#28894)\n- `awsemfexporter`: Logs relating to the start and finish of processing metrics have been reduced to debug level (#29337)\n- `azuremonitorreceiver`: Support Azure gov cloud (#27573)\n- `clickhouseexporter`: Added support for more control over TTL configuration. Currently, it supports timelines only in days, now also in hours, minutes and seconds (propertyName ttl_days --> ttl). (#28675)\n- `datasetexporter`: Collect usage metrics with Otel and send grouped attributes in session info. (#27650, #27652)\n- `resourcedetectionprocessor`: Add k8s cluster name detection when running in EKS (#26794)\n- `pkg/ottl`: Add new IsDouble function to facilitate type checking. (#27895)\n- `configschema`: Generate metadata for connectors. (#26990)\n- `telemetrygen`: Exposes the span duration as a command line argument `--span-duration` (#29116)\n- `honeycombmarkerexporter`: Change honeycombmarkerexporter to alpha (#27666)\n- `mysqlreceiver`: expose tls in mysqlreceiver (#29269)\n  If `tls` is not set, the default is to disable TLS connections.\n- `processor/transform`: Convert between sum and gauge in metric context when alpha feature gate `processor.transform.ConvertBetweenSumAndGaugeMetricContext` enabled (#20773)\n- `receiver/mongodbatlasreceiver`: adds project config to mongodbatlas metrics to filter by project name and clusters. (#28865)\n- `pkg/stanza`: Add \"namedpipe\" operator. (#27234)\n- `pkg/resourcetotelemetry`: Do not clone data in pkg/resourcetotelemetry by default (#29327)\n  - The resulting consumer will be marked as `MutatesData` instead\n  \n- `pkg/stanza`: Improve performance by not calling decode when nop encoding is defined (#28899)\n- `exporter/prometheusremotewrite`: prometheusremotewrite exporter add option to send metadata (#13849)\n- `receivercreator`: Added support for discovery of endpoints based on K8s services (#29022)\n  By discovering endpoints based on K8s services, a dynamic probing of K8s service leveraging for example the httpcheckreceiver get enabled\n- `signalfxexporter`: change default timeout to 10 seconds (#29436)\n- `awss3exporter`: add support for `s3_force_path_style` and `disable_ssl` parameters (#29331)\n  In order to support alternative object-storage, these parameters are useful and help to leverage those systems not\n  compatible with domain style path, or just hosted without ssl (like just deployed in a k8s namespace).\n  \n- `hostmetricsreceiver`: Add optional Linux-only metric `system.linux.memory.available` (#7417)\n  This is an alternative to `system.memory.usage` metric with `state=free`.\n  Linux starting from 3.14 exports \"available\" memory. It takes \"free\" memory as a baseline, and then factors in kernel-specific values.\n  This is supposed to be more accurate than just \"free\" memory.\n  For reference, see the calculations [here](https://superuser.com/a/980821).\n  See also `MemAvailable` in [/proc/meminfo](https://man7.org/linux/man-pages/man5/proc.5.html).\n  \n- `azuremonitorexporter`: Updated Azure Monitor Exporter service version from v2.0 to v2.1. (#29234)\n\n### 🧰 Bug fixes 🧰\n\n- `cassandraexporter`: Exist check for keyspace and dynamic timeout (#27633)\n- `datadogreceiver`: Fix set telemetry.sdk.language=dotnet instead of .NET (#29459)\n- `filelogreceiver`: Fix issue where files were unnecessarily kept open on Windows (#29149)\n- `receiver/activedirectoryds`: Fix shutdown of `activedirectorydsreceiver` when shutdown was called right after creation, without a corresponding start call. (#29505)\n- `honeycombmarkerexporter`: Fix default api_url and dataset_slug (#29309)\n- `influxdbexporter`: When InfluxDB v1 compatibility is enabled AND username&password are set, the exporter panics. Not any more! (#27084)\n- `mongodbreceiver`: add `receiver.mongodb.removeDatabaseAttr` Alpha feature gate to remove duplicate database name attribute (#24972)\n- `pkg/stanza`: Fix panic during stop for udp async mode only. (#29120)\n\n## v0.89.0\n\n### 🛑 Breaking changes 🛑\n\n- `pkg/stanza`: Improve parsing of Windows Event XML by handling anonymous `Data` elements. (#21491)\n  This improves the contents of Windows log events for which the publisher manifest is unavailable. Previously, anonymous `Data` elements were ignored. This is a breaking change for users who were relying on the previous data format.\n- `processor/k8sattributes`: Graduate \"k8sattr.rfc3339\" feature gate to Beta. (#28817)\n  Time format of `k8s.pod.start_time` attribute value migrated from RFC3339:\n  Before: 2023-07-10 12:34:39.740638 -0700 PDT m=+0.020184946\n  After: 2023-07-10T12:39:53.112485-07:00\n  The feature gate can be temporary reverted back by adding `--feature-gate=-k8sattr.rfc3339` to the command line.\n  \n- `filelogreceiver`: Change \"Started watching file\" log behavior (#28491)\n  Previously, every unique file path which was found by the receiver would be remembered indefinitely.\n  This list was kept independently of the uniqueness / checkpointing mechanism (which does not rely on the file path).\n  The purpose of this list was to allow us to emit a lot whenever a path was seen for the first time.\n  This removes the separate list and relies instead on the same mechanism as checkpointing. Now, a similar log is emitted\n  any time a file is found which is not currently checkpointed. Because the checkpointing mechanism does not maintain history\n  indefintiely, it is now possible that a log will be emitted for the same file path. This will happen when no file exists at\n  the path for a period of time.\n  \n- `dockerstatsreceiver`: cpu.container.percent metric is removed in favor of container.cpu.utilization (#21807)\n  The metric `container.cpu.percentage` is now removed. `container.cpu.utilization` is enabled by default as a replacement.\n  For details, see the [docs](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/dockerstatsreceiver#transition-to-cpu-utilization-metric-name-aligned-with-opentelemetry-specification).\n  \n- `encoding extensions`: Rename encoding extensions for consistency with storage extensions (#24451)\n  - `jaegerencoding` -> `jaeger_encoding`\n  - `otlpencoding` -> `otlp_encoding`\n  - `textencoding` -> `text_encoding`\n  - `zipkinencoding` -> `zipkin_encoding`\n  \n- `remoteobserverprocessor`: Rename remoteobserverprocessor to remotetapprocessor (#27873)\n- `collectdreceiver`: Stop using opencensus metrics, use the obsrecv format (#25148)\n\n### 🚩 Deprecations 🚩\n\n- `datadogexporter`: Deprecate config `traces::peer_service_aggregation` in favor of `traces::peer_tags_aggregation` (#29089)\n- `postgresqlreceiver`: Deprecation of postgresql replication lag metrics `postgresql.wal.lag` in favor of more precise 'postgresql.wal.delay' (#26714)\n\n### 🚀 New components 🚀\n\n- `extension/opampextension`: Add a new extension that implements an OpAMP agent for reporting the collector's health and effective configuration. (#16462)\n- `sumologicprocessor`: add Sumo Logic Processor (#23946)\n  move processor from https://github.com/SumoLogic/sumologic-otel-collector/ repository\n- `alertmanagerexporter`: Add new exporter for sending events as alerts to Alertmanager (#23569)\n- `remotetapextension`: Add a new extension, remotetapextension to use with the remoteobserverprocessor processors. (#19634)\n- `otlpencodingextension`: Introduce OTLP encoding extension (#6272)\n- `pkg/translator/azure`: Create a translator for Azure Resource Log format (#18210)\n\n### 💡 Enhancements 💡\n\n- `awsxrayexporter`: Convert individual HTTP error events into exceptions within subsegments for AWS SDK spans and strip AWS.SDK prefix from remote aws service name (#27232)\n- `azuremonitorexporter`: Added connection string support to the Azure Monitor Exporter (#28853)\n  This enhancement simplifies the configuration process and aligns the exporter with Azure Monitor's recommended practices.\n  The Connection String method allows the inclusion of various fields such as the InstrumentationKey and IngestionEndpoint\n  within a single string, facilitating an easier and more integrated setup.\n  While the traditional InstrumentationKey method remains supported for backward compatibility, it will be phased out.\n  Users are encouraged to adopt the Connection String approach to ensure future compatibility and to leverage the broader\n  configuration options it enables.\n  \n- `opensearchexporter`: Add log exporting capability to the opensearchexporter. (#23611)\n- `pdatatest`: Allow to compare metrics resource attributes or metric attribute values by matching on a portion of the dimension value with a regular expression. (#27690)\n  Use `MatchResourceAttributeValue(\"node_id\", \"cloud-node\")` to match two metrics with a resource attribute value that starts with \"cloud-node\".\n  Use `MatchMetricAttributeValue(\"hostname\", \"container-tomcat-\", \"gauge.one\", \"sum.one\")` to match metrics with the `hostname` attribute starting with `container-tomcat-`.\n  \n- `processor/tailsampling`: adds optional upper bound duration for sampling (#26115)\n- `clickhouseexporter`: Add persistent storage support to clickhouse exporter (#27653)\n- `azuremonitorexporter`: Added documentation to describe how to use with the AAD Auth Proxy and enable AAD based authentication. (#24451)\n- `azuremonitorexporter`: Extended Azure Monitor exporter to support persistent queue. Default is for QueueSettings.Enabled to be false. (#25859)\n- `collectdreceiver`: Add support of confighttp.HTTPServerSettings (#28811)\n- `collectdreceiver`: Promote collectdreceiver as beta component (#28658)\n- `receiver/hostmetricsreceiver`: Added support for host's cpuinfo frequnecies. (#27445)\n  In Linux the current frequency is populated using the values from /proc/cpuinfo. An os specific implementation will be needed for Windows and others.\n- `datadogexporter`: Add a new traces config `trace_buffer` that specifies the number of outgoing trace payloads to buffer before dropping. (#28577)\n  If you start seeing log messages like `Payload in channel full. Dropped 1 payload.` in the datadog exporter, consider setting a higher `trace_buffer` to avoid traces being dropped.\n- `datadogexporter`: Add a new config `traces::peer_tags_aggregation` that enables aggregation of peer related tags in Datadog exporter (#29089)\n- `receiver/hostmetrics/scrapers/process`: add configuration option to mute `error reading username for process` (#14311, #17187)\n- `syslogexporter`: Promote syslogexporter to alpha and add it to otelcontribcol (#21242, #21244, #21245)\n- `azureevenhubreceiver`: Allow the Consumer Group to be set in the Configuration. (#28633)\n- `spanmetricsconnector`: Add Events metric to span metrics connector that adds list of event attributes as dimensions (#27451)\n- `exceptionsconnector`: Add trace id and span id to generated logs from exceptions when using exceptionsconnector. (#24407)\n- `processor/k8sattribute`: support adding labels and annotations from node (#22620)\n- `windowseventlogreceiver`: Add parsing for Security and Execution event fields. (#27810)\n- `filelogreceiver`: Add the ability to order files by mtime, to only read the most recently modified files (#27812)\n- `wavefrontreceiver`: Wrap metrics receiver under carbon receiver instead of using export function (#27248)\n- `exporter/datadog`: Added the \"exporter.datadogexporter.DisableAPMStats\" feature gate to disable APM stats computation. (#28615)\n- `pkg/ottl`: Add IsBool function into OTTL (#27897)\n- `k8sclusterreceiver`: add k8s.node.condition metric (#27617)\n- `kafka`: Expose resolve_canonical_bootstrap_servers_only (#26022)\n- `mongodbatlasreceiver`: Enhanced collector logs to include more information about the MongoDB Atlas API calls being made during logs retrieval. (#28851)\n- `datadogexporter`: Add support for host.cpu attributes. (#29156)\n- `datadogexporter`: Add support for custom container tags via resource attributes prefixed by `datadog.container.tag.*`. (#29156)\n- `receiver/mongodbatlasreceiver`: emit resource attributes \"`mongodb_atlas.region.name`\" and \"`mongodb_atlas.provider.name`\" on metric scrape. (#28833)\n- `pkg/golden`: Move the internal/coreinternal/golden folder to pkg/golden (#28594)\n- `processor/resourcedetection`: Add `processor.resourcedetection.hostCPUModelAndFamilyAsString` feature gate to change the type of `host.cpu.family` and `host.cpu.model.id` attributes from `int` to `string`. (#29025)\n  This feature gate will graduate to beta in the next release.\n  \n- `tailsamplingprocessor`: Optimize performance of tailsamplingprocessor (#27889)\n- `redisreceiver`: include server.address and server.port resource attributes (#22044)\n- `servicegraphprocessor, servicegraphconnector`: Add a config option to periodically flush metrics, instead of flushing on every push. (#27679)\n- `spanmetricsconnector`: Add exemplars to sum metric (#27451)\n- `exporter/syslog`: send syslog messages in batches (#21244)\n  This changes the behavior of the Syslog exporter to send each batch of Syslog messages in a single request (with messages separated by newlines), instead of sending each message in a separate request and closing the connection after each message.\n- `cmd/telemetrygen`: Use exporter per worker for better metrics throughput (#26709)\n- `cmd/telemetrygen`: Add support for --otlp-http for telemetrygen logs (#18867)\n- `exporter/awss3exporter`: This feature allows role assumption for s3 exportation. It is especially useful on Kubernetes clusters that are using IAM roles for service accounts (#28674)\n\n### 🧰 Bug fixes 🧰\n\n- `lokiexporter`: The tenant attribute is now not automatically promoted to a label. (#21045)\n  To add tenant attributes (resource/record) to labels, use the label hints explicitly.\n- `azuretranslator`: Allow numeric fields to use a String or Integer representation in JSON. (#28650)\n- `extension/zipkinencodingextension`: Fix bug when err is nil if invalid protocol value is supplied. (#28686)\n- `filelogreceiver`: Fix issue where counting number of logs emitted could cause panic (#27469, #29107)\n- `lokireceiver`: Fix issue where counting number of logs emitted could cause panic (#27469, #29107)\n- `kafkareceiver`: Fix issue where counting number of logs emitted could cause panic (#27469, #29107)\n- `k8sobjectsreceiver`: Fix issue where counting number of logs emitted could cause panic (#27469, #29107)\n- `fluentforwardreceiver`: Fix issue where counting number of logs emitted could cause panic (#27469, #29107)\n- `otlpjsonfilereceiver`: Fix issue where counting number of logs emitted could cause panic (#27469, #29107)\n- `datadogconnector`: Mark datadogconnector as `MutatesData` to prevent data race (#29111)\n- `azureeventhubreceiver`: Updated documentation around Azure Metric to OTel mapping. (#28622)\n- `receiver/hostmetrics`: Fix panic on load_scraper_windows shutdown (#28678)\n- `apachesparkreceiver`: Replacing inaccurate units for the spark.job.stage.active and spark.job.stage.result metrics for the Apache Spark receiver. (#29104)\n- `splunkhecreceiver`: Do not encode JSON response objects as string. (#27604)\n- `processor/k8sattributes`: Set attributes from namespace/node labels or annotations even if node/namespaces attribute are not set. (#28837)\n- `datadogexporter`: Only extract DD container tags from resource attributes. Previously, container tags were also extracted from span attributes. (#29156)\n- `datadogexporter`: Only add container tags in dedicated container tag section. Previously, container tags were also added as span tags. Container tags will now only be accessible via the span container tab, and not as span tags. (#29156)\n- `pkg/stanza`: Fix data-corruption/race-condition issue in udp async (reuse of buffer); use buffer pool isntead. (#27613)\n- `datadogexporter`: Fixes potential log records loss on a transient network/connectivity error (#24550)\n  The Datadog exporter threats network/connectivity errors (http client doesn't receive a response) as permanent errors, which can lead to log records loss. This change makes these errors retryable.\n- `servicegraphprocessor, servicegraphconnector`: Measure latency in seconds instead of milliseconds (#27488)\n  Measures latency in seconds instead of milliseconds, as the metric name indicates.\n  Previously, milliseconds was used.\n  This unit is still available via the feature gate `processor.servicegraph.legacyLatencyUnitMs`.\n  This is a breaking change.\n  \n- `sshcheckreceiver`: Use key_file instead of keyfile for the key in config. Aligns project practice, code, and docs. (#27035)\n- `zipkinreceiver`: Return BadRequest in case of permanent errors (#4335)\n\n## v0.88.0\n\n### 🛑 Breaking changes 🛑\n\n- `k8sclusterreceiver`: Remove opencensus.resourcetype resource attribute (#26487)\n- `splunkhecexporter`: Remove `max_connections` configuration setting. (#27610)\n  use max_idle_conns or max_idle_conns_per_host instead.\n  \n- `signalfxexporter`: Remove `max_connections` configuration setting. (#27610)\n  use max_idle_conns or max_idle_conns_per_host instead.\n  \n\n### 🚩 Deprecations 🚩\n\n- `dockerstatsreceiver`: cpu.container.percent metric will be deprecated in v0.79.0 in favor of container.cpu.utilization (#21807)\n  The metric `container.cpu.percentage` is now disabled by default and will be removed in v0.88.0.\n  As a replacement, the following metric is now enabled by default: `container.cpu.utilization`.\n  For details, see the [docs](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/dockerstatsreceiver#transition-to-cpu-utilization-metric-name-aligned-with-opentelemetry-specification).\n  \n- `parquetexporter`: Remove the parquet exporter (#27284)\n\n### 🚀 New components 🚀\n\n- `encoding/jsonlogencodingextension`: Add a new extension to support JSON encoding (only logs) (#6272)\n- `honeycombmarkerexporter`: This component will export markers to be consumed by the Honeycomb Markers API to highlight user events (#26653)\n- `zipkinencodingextension`: Introduce zipkin encoding extension. (#6272)\n\n### 💡 Enhancements 💡\n\n- `datasetexporter`: Make export of resources and scopes more flexible (#27651, #27649)\n- `pkg/stanza`: Add option to run udp logs receiver (and stanza udp input operator) concurrently to reduce data-loss during high-scale scenarios (#27613)\n- `receiver/prometheus`: Warn instead of failing when users rename using metric_relabel_configs in the prometheus receiver (#5001)\n- `awscloudwatchlogsexporter/awsemfexporter`: Reduce noisy logs emitted by CloudWatch Logs Pusher. (#27774)\n  The Collector logger will now write successful CloudWatch API writes at the Debug level instead of Info level.\n- `k8sobjectsreceiver`: Move k8sobjectsreceiver from Alpha stability to Beta stability for logs. (#27635)\n- `datadogconnector`: Allow datadogconnector to be used as a traces-to-traces connector (#27846)\n- `doubleconverter`: Adding a double converter into pkg/ottl (#22056)\n- `syslogreceiver`: validate protocol name (#27581)\n- `elasticsearchexporter`: add missing scope info in span attributes (#27282)\n- `entension/storage/filestorage`: Add support for setting bbolt fsync option (#20266)\n- `filelogreceiver`: Add a new \"top_n\" option to specify the number of files to track when using ordering criteria (#23788)\n- `azuredataexplorerexporter`: Added exporter helper config support for Azure Data Explorer exporter (#24329)\n- `k8sclusterreceiver`: add optional k8s.pod.qos_class resource attribute (#27483)\n- `pkg/stanza`: Log warning, instead of error, when Windows Event Log publisher metadata is not available and cache the successfully retrieved ones. (#27658)\n- `pkg/ottl`: Add optional Converter parameters to replacement Editors (#27235)\n  Functions to modify matched text during replacement can now be passed as optional arguments to the following Editors:\n  - `replace_pattern`\n  - `replace_all_patterns`\n  - `replace_match`\n  - `replace_all_matches`\n  \n- `awscloudwatchlogsexporter`: Improve the performance of the awscloudwatchlogsexporter (#26692)\n  Improve the performance by adding support to multiple consumers and removing locks and limiters that are no longer\n  necessary.\n  \n- `pkg/pdatatest`: support ignore timestamps in span comparisons for pdatatest (#27688)\n- `prometheusremotewriteexporter`: addition of `max_batch_size_bytes` configurable parameter, to allow users to adjust it based on the capabilities of their specific remote storage (#21911)\n- `pkg/pdatatest`: support ignore span attribute value in span comparisons for ptracetest (#27689)\n- `pkg/pdatatest`: support ignore span ID in span comparisons for ptracetest (#27685)\n- `pkg/pdatatest`: support ignore trace ID in span comparisons for ptracetest (#27687)\n- `pkg/stanza`: When async is enabled for udp receiver, separate logic into readers (only read logs from udp port and push to channel), and processors (read logs from channel and process; decode, split, add attributes, and push downstream), allowing to change concurrency level for both readers and processors separately. (#27613)\n- `signalfxexporter`: Add an option to control the dimension client timeout (#27815)\n- `signalfxexporter`: Add the build version to the user agent of the SignalFx exporter (#16841)\n- `splunkentreceiver`: Users can now use auth settings and basicauth extension to connect to their Splunk enterprise deployments (#27026)\n\n### 🧰 Bug fixes 🧰\n\n- `datasetexporter`: Do not crash on NPE when any of the attributes contains null value. (#27648)\n- `syslog`: add integration tests and fix related bugs (#21245)\n- `processor/resourcedetection`: Don't parse the field `cpuInfo.Model` if it's blank. (#27678)\n- `k8sclusterreceiver`: Change clusterquota and resourcequota metrics to use {resource} unit (#10553)\n- `cmd/telemetrygen`: Fix `go install` for telemetrygen (#27855)\n- `pkg/ottl`: Fix bug where named parameters needed a space after the equal sign (`=`). (#28511)\n- `filelogreceiver`: Fix issue where batching of files could result in ignoring start_at setting. (#27773)\n- `prometheusremotewrite`: Fix remote write exporter not respecting retrySettings.enabled flag (#27592)\n- `redactionprocessor`: Fix mask when multiple patterns exist (#27646)\n\n## v0.87.0\n\n### 🛑 Breaking changes 🛑\n\n- `receiver/kubeletstats`: Fixes a bug where the \"insecure_skip_verify\" config was not being honored when \"auth_type\" is \"serviceAccount\" in kubelet client. (#26319)\n  Before the fix, the kubelet client was not verifying kubelet's certificate. The default value of the config is false,\n  so with the fix the client will start verifying tls cert unless the config is explicitly set to true.\n  \n- `parquetexporter`: Deprecate the Parquet Exporter, it will be removed in the next release. (#27284)\n- `bug_fix`: Improve counting for the `count_traces_sampled` metric (#25882)\n- `extension/filestorage`: Replace path-unsafe characters in component names (#3148)\n\n### 🚩 Deprecations 🚩\n\n- `resourcedetectionprocessor`: Detect faas.instance in the gcp detector, and deprecate detecting faas.id in the gcp detector. (#26486)\n  faas.id has been removed from the semantic conventions.\n- `k8sclusterreceiver`: Deprecate opencensus.resourcetype resource attribute (#26487)\n  opencensus.resourcetype resource attribute is deprecated and disabled by default.\n\n### 🚀 New components 🚀\n\n- `encodingextension`: Add implementation of encodingextension (#6272)\n\n### 💡 Enhancements 💡\n\n- `processor/probabilisticsampler`: Allow non-bytes values to be used as the source for the sampling decision (#18222)\n- `receiver/azuremonitorreceiver`: Add support for authenticating using AD workload identity (#24451)\n- `kafkareceiver`: Allow users to attach kafka header metadata with the log/metric/trace record in the pipeline. Introduce a new config param, 'header_extraction' and some examples. (#24367)\n- `exporter/kafkaexporter`: Adding Zipkin encoding option for traces to kafkaexporter (#21102)\n- `kubeletstatsreceiver`: Support specifying context for `kubeConfig` `auth_type` (#26665)\n- `kubeletstatsreceiver`: Adds new `k8s.pod.cpu_limit_utilization`, `k8s.pod.cpu_request_utilization`, `k8s.container.cpu_limit_utilization`, and `k8s.container.cpu_request_utilization` metrics that represent the ratio of cpu used vs set limits and requests. (#27276)\n- `kubeletstatsreceiver`: Adds new `k8s.pod.memory_limit_utilization`, `k8s.pod.memory_request_utilization`, `k8s.container.memory_limit_utilization`, and `k8s.container.memory_request_utilization` metrics that represent the ratio of memory used vs set limits and requests. (#25894)\n- `filestatsreceiver`: Move the filestats receiver to beta stability (#27252)\n- `haproxyreceiver`: Move the haproxyreceiver to beta stability (#27254)\n- `splunkentreceiver`: adding additional metrics to the splunkentreceiver (#12667)\n- `cmd/telemetrygen`: Add support for custom telemetry attributes (#26505)\n\n### 🧰 Bug fixes 🧰\n\n- `processor/spanmetrics`: Prune histograms when dimension cache is pruned. (#27080)\n  Dimension cache was always pruned but histograms were not being pruned. This caused metric series created\n  by processor/spanmetrics to grow unbounded.\n  \n- `syslogexporter`: use proper defaults according to RFCs (#25114)\n- `syslogparser`: return correct structure from syslog parser (#27414)\n- `splunkhecreceiver`: Fix receiver behavior when used for metrics and logs at the same time; metrics are no longer dropped. (#27473)\n- `metricstransformprocessor`: Fixes a nil pointer dereference when copying an exponential histogram (#27409)\n- `telemetrygen`: better defaults for http exporter mode (#26999)\n  - the url path default is now correct for both traces and metrics\n  - when not provided, the endpoint is automatically set to target a local gRPC or HTTP endpoint depending on the communication mode selected\n  \n- `k8sclusterreceiver`: change k8s.container.ready, k8s.pod.phase, k8s.pod.status_reason, k8s.namespace.phase units to empty (#10553)\n- `k8sclusterreceiver`: Change k8s.node.condition* metric units to empty (#10553)\n- `syslogreceiver`: Fix issue where long tokens would be truncated prematurely (#27294)\n- `mongodbreceiver`: Fix mongo version not being collected (#27441)\n\n## v0.86.0\n\n### 🛑 Breaking changes 🛑\n\n- `jaegerexporter, jaegerthrifthttpexporter`: Removing deprecated jaeger and jaegerthrifthttp exporters (#26546)\n  This follows the deprecation plan to remove the component. The original removal date was July 2023, it is now past that.\n- `receiver/nginx`: Bump 'nginx.connections_current' gate to stable (#27024)\n\n### 💡 Enhancements 💡\n\n- `processor/tailsampling`: Allow sub-second decision wait time (#26354)\n- `processor/resourcedetection`: Added support for host's cpuinfo attributes. (#26532)\n  In Linux and Darwin all fields are populated. In Windows only family, vendor.id and model.name are populated.\n- `pkg/stanza`: Add 'omit_pattern' setting to `split.Config`. (#26381)\n  This can be used omit the start or end pattern from a log entry.\n- `skywaklingreceiver`: implement receiver for JVM metrics in Skywalking and adapted it to the OpenTelemetry protocol. (#20315)\n- `statsdreceiver`: Add TCP support to statsdreceiver (#23327)\n- `azuredataexplorerexporter`: Added an optional column in the exported trace data to store the status code and message as a dynamic field. (#26496)\n- `statsdreceiver`: Allow for empty tag sets (#27011)\n- `pkg/ottl`: Update contexts to set and get time.Time (#22010)\n- `pkg/ottl`: Add a Now() function to ottl that returns the current system time (#27038, #26507)\n- `filelogreceiver`: Log the globbing IO errors (#23768)\n- `exporter/loadbalancing`: Allow metrics routing (#25858)\n- `pkg/ottl`: Allow named arguments in function invocations (#20879)\n  Arguments can now be specified by a snake-cased version of their name in the function's\n  `Arguments` struct. Named arguments can be specified in any order, but must be specified\n  after arguments without a name.\n  \n- `pkg/ottl`: Add new `TruncateTime` function to help with manipulation of timestamps (#26696)\n- `pkg/stanza`: Add 'overwrite_text' option to severity parser. (#26671)\n  Allows the user to overwrite the text of the severity parser with the official string representation of the severity level.\n  \n- `prometheusreceiver`: add a new flag, enable_protobuf_negotiation, which enables protobuf negotiation when scraping prometheus clients (#27027)\n- `redisreceiver`: Added `redis.cmd.latency` metric. (#6942)\n- `processor/resourcedetectionprocessor`: add k8snode detector to provide node metadata; currently the detector provides `k8d.node.uid` (#26538)\n- `routingconnector`: Change routingconnector stability to alpha (#26495)\n- `supported platforms`: Add `linux/s390x` architecture to cross build tests in CI (#25138)\n- `telemetrygen`: Move the telemetrygen tool to use gRPC logging at warn level, in line with otlpgrpc. (#26659)\n- `splunkentreceiver`: adding component logic to splunkenterprise receiver (#12667)\n- `splunkhecreceiver`: Update splunk hec receiver to extract time query parameter if it is provided (#27006)\n- `cmd/telemetrygen`: Add CLI option for selecting different metric types (#26667)\n- `cloudflarereceiver`: Make TLS config optional for cloudflarereceiver (#26562)\n- `receiver/awscontainerinsightsreceiver`: Remove the need to set an env var in the receiver to get CPU and memory info (#24777)\n- `awsxrayexporter`: Change `exporter.awsxray.skiptimestampvalidation` feature gate from Alpha to Beta (#26553)\n- `processor/k8sattributes`: allow metadata extractions to be set to empty list (#14452)\n\n### 🧰 Bug fixes 🧰\n\n- `processor/tailsampling`: Prevent the tail-sampling processor from accepting duplicate policy names (#27016)\n- `awsemfexporter`: AWS EMF Exporter will not drop any metrics that contain NaN values to avoid JSON marshal errors. (#26267)\n- `k8sclusterreceiver`: Change k8s.deployment.available and k8s.deployment.desired metric units to {pod} (#10553)\n- `awsxrayexporter`: Restore the AWS X-Ray metadata structure when exporting. (#23610)\n- `telemetrygen`: remove need for JSON unmarshalling of trace status codes and unsupport mixed case input (#25906)\n- `haproxyreceiver`: Remove unused resource attributes. (#24920)\n- `k8sclusterreceiver`: Change k8scluster receiver metric units to follow otel semantic conventions (#10553)\n- `pkg/stanza`: Fix bug where force_flush_period not applied (#26691)\n- `filelogreceiver`: Fix issue where truncated file could be read incorrectly. (#27037)\n- `receiver/hostmetricsreceiver`: Make sure the process scraper uses the gopsutil context, respecting the `root_path` configuration. (#24777)\n  This regression was introduced by #24777\n- `k8sclusterreceiver`: change k8s.container.restarts unit from 1 to {restart} (#10553)\n\n## v0.85.0\n\n### 🛑 Breaking changes 🛑\n\n- `k8sclusterreceiver`: Remove deprecated Kubernetes API resources (#23612, #26551)\n  Drop support of HorizontalPodAutoscaler v2beta2 version and CronJob v1beta1 version. \n  Note that metrics for those resources will not be emitted anymore on Kubernetes 1.22 and older.\n  \n- `prometheusexporters`: Append prometheus type and unit suffixes by default in prometheus exporters. (#26488)\n  Suffixes can be disabled by setting add_metric_suffixes to false on the exporter.\n- `attributesprocessor, resourceprocessor`: Transition featuregate `coreinternal.attraction.hash.sha256` to stable (#4759)\n\n### 💡 Enhancements 💡\n\n- `postgresqlreceiver`: Added `postgresql.database.locks` metric. (#26317)\n- `receiver/statsdreceiver`: Add support for distribution type metrics in the statsdreceiver. (#24768)\n- `pkg/ottl`: Add converters to convert time to unix nanoseconds, unix microseconds, unix milliseconds or unix seconds (#24686)\n- `oauth2clientauthextension`: Enable dynamically reading ClientID and ClientSecret from files (#26117)\n  - Read the client ID and/or secret from a file by specifying the file path to the ClientIDFile (`client_id_file`) and ClientSecretFile (`client_secret_file`) fields respectively.\n  - The file is read every time the client issues a new token. This means that the corresponding value can change dynamically during the execution by modifying the file contents.\n  \n- `receiver/hostmetrics`: Don't collect connections data from the host if system.network.connections metric is disabled to not waste CPU cycles. (#25815)\n- `jaegerreceiver,jaegerremotesamplingextension`: Add featuregates to replace Thrift-gen with Proto-gen types for sampling strategies (#18401)\n  Available featuregates are:\n  - extension.jaegerremotesampling.replaceThriftWithProto\n  - receiver.jaegerreceiver.replaceThriftWithProto\n  \n- `influxdbexporter`: Add user-configurable LogRecord dimensions (otel attributes -> InfluxDB tags) (#26342)\n- `k8sclusterreceiver`: Add optional k8s.kubelet.version, k8s.kubeproxy.version node resource attributes (#24835)\n- `k8sclusterreceiver`: Add k8s.pod.status_reason option metric (#24034)\n- `k8sobjectsreceiver`: Adds logic to properly handle 410 response codes when watching. This improves the reliability of the receiver. (#26098)\n- `k8sobjectreceiver`: Adds option to exclude event types (MODIFIED, DELETED, etc) in watch mode. (#26042)\n- `datadogexporter`: Host metadata for remote hosts is now reported on first sight or on change (#25145)\n  Host metadata for remote hosts will only be sent for payloads with the datadog.host.use_as_metadata resource attribute.\n  \n\n### 🧰 Bug fixes 🧰\n\n- `processor/routing`: When using attributes instead of resource attributes, the routing processor would crash the collector. This does not affect the connector version of this component. (#26462)\n- `awsemfexporter`: Fix possible panic in when configuration option `awsemf.output_destination:stdout` is set (#26250)\n- `snmpreceiver`: Fix how to determine how many RAs on a metric are scalar (#26363)\n  We now create the proper number of resources for configurations where a resource uses fewer than the available number of scalar resource attribtues.\n- `processor/tailsampling`: Added saving instrumentation library information for tail-sampling (#13642)\n- `receiver/kubeletstats`: Fixes client to refresh service account token when authenticating with kubelet (#26120)\n- `datadogexporter`: Fixes crash when mapping OTLP Exponential Histograms with no buckets. These will now be dropped instead. (#26103)\n- `filelogreceiver`: Fix the behavior of the add operator to continue to support EXPR(env(\"MY_ENV_VAR\")) expressions (#26373)\n- `snmpreceiver`: SNMP values of type Counter64 were seen as unsupported, because the returned data type unint64 was unhandeled. (#23897, #26119)\n- `pkg/stanza`: Fix issue unsupported type 'syslog_parser' (#26452)\n\n## v0.84.0\n\n### 🛑 Breaking changes 🛑\n\n- `jaegerreceiver`: Deprecate remote_sampling config in the jaeger receiver (#24186)\n  The jaeger receiver will fail to start if remote_sampling config is specified in it.  The `receiver.jaeger.DisableRemoteSampling` feature gate can be set to let the receiver start and treat  remote_sampling config as no-op. In a future version this feature gate will be removed and the receiver will always  fail when remote_sampling config is specified.\n  \n- `googlecloudexporter`: remove retry_on_failure from the googlecloud exporter. The exporter itself handles retries, and retrying can cause issues. (#57233)\n- `vcenterreceiver`: Dimensions performance metrics into metric attribute `object` (#25147)\n  The following metrics have been effected to include the new metric attribute to properly dimension the data.`vcenter.vm.network.throughput`,`vcenter.vm.network.usage`,`vcenter.vm.network.packet.count`,`vcenter.vm.disk.latency.avg`,`vcenter.vm.disk.latency.max`,`vcenter.host.network.usage`,`vcenter.host.network.throughput`,`vcenter.host.network.packet.count`,`vcenter.host.network.packet.errors`,\n  `vcenter.host.disk.latency.avg`,`vcenter.host.disk.latency.max`, and `vcenter.host.disk.throughput`. More information on how to migrate can be found at https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/vcenterreceiver#feature-gates\n  \n\n### 🚩 Deprecations 🚩\n\n- `datadogprocessor`: Deprecation of Datadog processor in favor of Datadog connector (#19740)\n- `tanzuobservabilityexporter`: Deprecation of Tanzu Observability (Wavefront) Exporter in favor of native OTLP ingestion. (#24225)\n\n### 💡 Enhancements 💡\n\n- `redisreceiver`: Adding username parameter for connecting to redis (#24408)\n- `postgresqlreceiver`: Added `postgresql.temp_files` metric. (#26080)\n- `receiver/azuremonitor`: Added new attrbutes to the metrics like name, type and resource_group. (#24774)\n- `clickhouseexporter`: Change writing of metrics data to batch (#24403)\n- `signalfxexporter`: Added a mechanism to drop histogram buckets (#25845)\n- `journaldreceiver`: add support for identifiers (#20295)\n- `journaldreceiver`: add support for dmesg (#20295)\n- `cassandraexporter`: Allow custom port for Cassandra connection (#24391)\n- `pkg/ottl`: Add converters to covert duration to nanoseconds, microseconds, milliseconds, seconds, minutes or hours (#24686)\n- `snmpreceiver`: Support scalar OID resource attributes (#23373)\n  Add column and scalar OID metrics to resources that have scalar OID attributes\n- `googlemanagedprometheus`: Add a `add_metric_suffixes` option to the googlemanagedprometheus exporter. When set to false, metric suffixes are not added. (#26071)\n- `haproxyreceiver`: Add support for HTTP connections (#24440)\n- `cmd/telemetrygen`: Add cli flag --status-code for trace generation (#24286)\n- `kubeletstatsreceiver`: Add a new `uptime` metric for nodes, pods, and containers to track how many seconds have passed since the object started (#25867)\n- `opensearchexporter`: implement [OpenSearch](https://opensearch.org/) exporter. (#23611)\n- `pkg/ottl`: Add new `ExtractPatterns` converter that extract regex pattern from string. (#25834, #25856)\n- `pkg/ottl`: Add support for Log, Metric and Trace Slices to `Len` converter (#25868)\n- `lokitranslator`: Added Attributes support to the InstrumentationScope (#24027)\n- `lokitranslator`: Public method `LogToLokiEntry` from `pkg/loki/translator` now returns normalized (`.` replaced by `_`) label names (#26093)\n- `postgresqlreceiver`: Added `postgresql.deadlocks` metric. (#25688)\n- `postgresqlreceiver`: Added `postgresql.sequential_scans` metric. (#26096)\n- `prometheusreceiver`: The otel_scope_name and otel_scope_version labels are used to populate scope name and version. otel_scope_info is used to populate scope attributes. (#25870)\n- `receiver/prometheus`: translate units from prometheus to UCUM (#23208)\n- `snmpreceiver`: Add support for SNMP values of type counter64 (#23897)\n- `snmpreceiver`: Timeout for SNMP requests can now be configured. (#25885)\n- `telemetrygen`: The telemetrygen now supports setting the log's body (#26031)\n- `awsxrayexporter`: add `exporter.awsxray.skiptimestampvalidation` Alpha feature gate to remove xray timestamp restriction on first 32 bits of trace id (#26041)\n\n### 🧰 Bug fixes 🧰\n\n- `receiver_creator`: Update expr and relocate breaking `type` function to `typeOf` (#26038)\n- `azuremonitor_logexporter`: The log exporter now supports non-string data for the log record body. (#23422)\n- `vcenterreceiver`: Added a vcenter.resource_pool.inventory_path resource attribute to resource pool metrics in order to properly dimension resource pools of the same name. (#25831)\n- `loadbalancingexporter`: fix k8s service resolver retaining invalid old endpoints (#24914)\n- `prometheusremotewriteexporter`: Retry on 5xx status codes using `cenkalti/backoff` client (#20304)\n- `cmd/telemetrygen`: fix the default value of the arg status-code (#25849)\n\n## v0.83.0\n\n### 🛑 Breaking changes 🛑\n\n- `receiver/k8scluster`: Unify predefined and custom node metrics. (#24776)\n  - Update metrics description and units to be consistent\n  - Remove predefined metrics definitions from metadata.yaml because they are controlled by `node_conditions_to_report` \n    and `allocatable_types_to_report` config options.\n  \n- `prometheusexporter`: Remove invalid unit translations from the prometheus exporters (#24647)\n- `receiver/prometheusexec`: Removes the deprecated prometheus_exec receiver (#24740)\n\n### 🚀 New components 🚀\n\n- `datadogconnector`: This is a new component that computes Datadog APM Stats in the event that trace pipelines are sampled. (#19740)\n  This component replaces the Datadog processor\n  \n- `gitproviderreceiver`: Add the skeleton for the new gitproviderreceiver in development with accompanying github scraper. (#22028)\n\n### 💡 Enhancements 💡\n\n- `azuredataexplorerexporter`: Add support for managed identity. This enables users to not use Key based authentication (#21924)\n- `awsemfexporter`: Add awsemf.nodimrollupdefault feature gate to aws emf exporter (#23997)\n  Enabling the awsemf.nodimrollupdefault will cause the AWS EMF Exporter to use the NoDimensionRollup configuration\n  setting by default instead of ZeroAndSingleDimensionRollup.\n  \n- `awss3exporter`: add Sumo Logic Installed Collector marshaler (#23212)\n- `receiver/collectdreceiver`: Migrate from opencensus to pdata, change collectd, test to match pdata format. (#20760)\n- `datasetexporter`: Make duration of shutdown procedure configurable to minimise data losses. (#24415)\n- `datasetexporter`: Make sure serverHost field is correctly and always populated on the DataSet events. For more information and available configuration options, please refer to the plugin readme file. (#20660, #24415)\n- `datadogreceiver`: add datadog trace and span id (#23057)\n- `pkg/ottl`: Add support for using addition and subtraction with time and duration (#22009)\n- `transformprocessor`: Add extract_count_metric OTTL function to transform processor (#22853)\n- `transformprocessor`: Add extract_sum_metric OTTL function to transform processor (#22853)\n- `prometheusreceiver`: Don't drop histograms without buckets (#22070)\n- `pkg/ottl`: Add a new Function Getter to the OTTL package, to allow passing Converters as literal parameters. (#22961)\n  Currently OTTL provides no way to use any defined Converter within another Editor/Converter.\n  Although Converters can be passed as a parameter, they are always executed and the result is what is actually passed as the parameter.\n  This allows OTTL to pass Converters themselves as a parameter so they can be executed within the function.\n  \n- `resourcedetectionprocessor`: GCP resource detection processor can automatically add `gcp.gce.instance.hostname` and `gcp.gce.instance.name` attributes. (#24598)\n- `splunkhecexporter`: Add heartbeat check while startup and new config param, heartbeat/startup (defaults to false). This is different than the healtcheck_startup, as the latter doesn't take token or index into account. (#24411)\n- `hostmetricsreceiver`: Report  logical and physical number of CPUs as metric. (#22099)\n  Use the `system.cpu.logical.count::enabled` and `system.cpu.physical.count::enabled` flags to enable them\n  \n- `k8sclusterreceiver`: Allows disabling metrics and resource attributes (#24568)\n- `k8sclusterreceiver`: Reduce memory utilization (#24769)\n- `k8sattributes`: Added k8s.cluster.uid to k8sattributes processor to add cluster uid (#21974)\n- `resourcedetectionprocessor`: Collect heroku metadata available instead of exiting early. Log at debug level if metadata is missing to help troubleshooting. (#25059)\n- `hostmetricsreceiver`: Improved description of the system.cpu.utilization metrics. (#25115)\n- `cmd/mdatagen`: Avoid reusing the same ResourceBuilder instance for multiple ResourceMetrics (#24762)\n- `resourcedetectionprocessor`: Add detection of os.description to system detector (#24541)\n- `filelogreceiver`: Bump 'filelog.allowHeaderMetadataParsing' feature gate to beta (#18198)\n- `receiver/purefareceiver`: implement the custom label `fa_array_name` to act as a pretty label for metrics received. (#23889, #21248, #22027)\n- `receiver/prometheusreceiver`: Add config `report-extra-scrape-metrics` to report additional prometheus scraping metrics (#21040)\n  Emits additional metrics - scrape_body_size_bytes, scrape_sample_limit, scrape_timeout_seconds. scrape_body_size_bytes metric can be used for checking failed scrapes due to body-size-limit.\n- `receiver/sqlquery`: Set ObservedTimestamp on collected logs (#23776)\n- `exporter/awss3exporter`: Allow custom endpoints to be configured for exporting spans (#21833)\n- `cmd/telemetrygen`: Add ability to set custom path to endpoint. (#24551)\n- `telemetrygen`: Adds batch option to configure whether to batch traces, and size option to configure minimum size in MB of each trace for load testing. (#9597)\n- `webhookreceiver`: Add an optional config setting to set a required header that all incoming requests must provide (#24270)\n- `extension/jaegerremotesampling`: gRPC remote source usage in jaegerremotesampling extension propagates HTTP headers if set in gRPC client config (#24414)\n- `extension/jaegerremotesampling`: gRPC remote source usage in jaegerremotesampling extension supports optional caching via existing `reload_interval` config (#24840)\n\n### 🧰 Bug fixes 🧰\n\n- `receiver/sshcheck`: Add the SSH endpoint as a resource attribute (#24441)\n- `awsemfexporter`: Enforce time to live on metric data that is stored for the purpose of cumulative to delta conversions within EMF Exporter (#25058)\n  This change fixes a bug where the cache used to store metric information for cumulative to delta\n  conversions was not enforcing its time to live. This could cause excessive memory growth in certain scenarios which could\n  lead to OOM failures for Collector. To properly fix this issue package global metric caches were removed and replaced\n  with caches that are unique per emf exporter. A byproduct of this change is that no two emf exporters within an \n  Collector will share a caches leading to more accurate cumulative to delta conversions. \n  \n- `awsemfexporter`: Add retain_initial_value_of_delta_metric to translateOTelToGroupedMetric, allowing the initial set of metrics to be published (#24051)\n- `carbonreceiver`: Fix Carbon receiver obsrecv operations memory leak (#24275)\n  The carbonreceiver has a memory leak where it will repeatedly open new obsrecv operations but not close them afterwards. Those operations eventually create a burden.\n  \n  The fix is to make sure the receiver only creates an operation per interaction over TCP.\n  \n- `datadogexporter`: Populate OTLP resource attributes in Datadog logs. Changes mapping for `jvm.loaded_classes` from `process.runtime.jvm.classes.loaded` to `process.runtime.jvm.classes.current_loaded`. (#24674)\n- `datadogexporter`: Fix the population of Datadog `system.*` metrics. Ensure the average is within [min, max] in histograms. (#25071)\n  The minimum and maximum estimation is only used when the minimum and maximum are not available in the OTLP payload or this is a cumulative payload.\n- `pkg/stanza`: Create a new decoder for each TCP/UDP connection to prevent concurrent write to buffer. (#24980)\n- `exporter/kafkaexporter`: Fixes a panic when SASL configuration is not present (#24797)\n- `lokitranslator, lokiexporter`: Fixes a panic that occurred during the promotion of nested attributes containing dots to labels (#25125)\n- `awsxrayexporter`: Fix X-Ray Segment status code and exception translations. (#24381)\n- `receiver/haproxy`: Make sure emitted resource metrics have distinct resources by default (#24921)\n  This is done by enabling and renaming the following resource attributes:\n    - proxy_name -> haproxy.proxy_name\n    - service_name -> haproxy.service_name\n  \n- `receiver/k8sobjects`: Fix bug where duplicate data would be ingested for watch mode if the client connection got reset. (#24806)\n- `datadogreceiver`: Fixed NPE on failed to decode message path (#24562)\n- `zipkinreceiver`: Respects zipkin's serialised status tags to be converted to span status (#14965)\n- `datadogexporter`: Correctly set metrics exporter capabilities to state that it mutates data (#24908)\n  This could lead to random panics if using more than one metrics exporter.\n  \n- `processor/resourcedetection`: Do not drop all system attributes if `host.id` cannot be fetched. (#24669)\n- `signalfxexporter`: convert vmpage_io* translated metrics to pages (#25064)\n- `splunkhecreceiver`: aligns success resp body w/ splunk enterprise (#19219)\n  changes resp from plaintext \"ok\" to json {\"text\"：\"success\", \"code\"：0}\n\n## v0.82.0\n\n### 🛑 Breaking changes 🛑\n\n- `receiver/awsfirehose`: Change the type of `Config.AccessKey` to be `configopaque.String` (#17273)\n- `receiver/cloudfoundry`: Change the type of `Config.UAA.Password` to be `configopaque.String` (#17273)\n- `exporter/datasetexporter`: Remove temporary client side attribute aggregation and corresponding traces.max_wait and traces.aggregate config options which are now redundant. (#20660)\n  This pull request removes the following attributes from the DataSet trace events: services, \n  span_count, error_count. Those attributes were populated on the client side as part of the client\n  side aggregation code. This client side aggregation was meant as a temporary solution until a\n  proper solution is implement on the server side. Being a temporary solution meant it had many\n  edge cases and would only work under specific and limited circumstances (all spans which belong\n  to a trace are part of the same batch received by the plugin).\n  \n  Corresponding config options (traces.aggregate and traces.max_wait) which are not redundant and\n  unused have also been removed.\n  \n- `mysqlreceiver`: removing `mysql.locked_connects` metric which is replaced by `mysql.connection.errors` (#23211)\n- `pkg/ottl`: Allow access to the metrics slice in the metric context (#24446)\n  This is only a breaking change for users using OTTL in custom components. For all Contrib components this is an enhancement.\n- `pkg/stanza`: Make fileconsumer.PositionalScanner internal (#23999)\n- `pkg/stanza`: Make fileconsumer.Fingerprint internal (#23998)\n- `receiver/httpcheck`: Fail fast on endpoint missing scheme (#23020)\n  Previously, when configured with an endpoint without HTTP/HTTPS scheme like \"opentelemetry.io\",\n  the receiver would start correctly, but fail to check the endpoint, producing the `httpcheck.error`\n  metric on every collection interval. After this change, the receiver fails to start, writing\n  an error log saying that you need to provide a scheme in the endpoint.\n  \n- `receiver/jmx`: Change the types of `Config.{Password,KeystorePassword,TruststorePassword}` to be `configopaque.String` (#17273)\n- `httpcheckreceiver`: support scraping multiple targets (#18823)\n- `resourcedetectionprocessor`: Disable `host.id` by default on the `system` detector. This restores the behavior prior to v0.72.0 when using the `system` detector together with other detectors that set `host.id` (#21233)\n  To re-enable `host.id` on the `system` detector set `system::resource_attributes::host.id::enabled` to `true`:  \n  \n  ```\n  resourcedetection:\n    detectors: [system]\n    system:\n      resource_attributes:\n        host.id:\n          enabled: true\n  ```\n  \n- `receiver/nsxt`: Change the type of `Config.Password` to be `configopaque.String` (#17273)\n- `receiver/podman`: Change the type of `Config.SSHPassphrase` to be `configopaque.String` (#17273)\n- `receiver/postgresql`: Change the type of `Config.Password` to be `configopaque.String` (#17273)\n- `prometheusreciever`: Remove unused buffer_period and buffer_count configuration options (#24258)\n- `prometheusreceiver`: Add the `trim_metric_suffixes` configuration option to allow enable metric suffix trimming. (#21743, #8950)\n  When enabled, suffixes for unit and type are trimmed from metric names. \n  If you previously enabled the `pkg.translator.prometheus.NormalizeName` \n  feature gate, you will need to enable this option to have suffixes trimmed.\n  \n- `receiver/pulsar`: Change the types of `Config.Authentication.Token.Token` and `Config.Authentication.Athenz.PrivateKey` to be `configopaque.String` (#17273)\n- `receiver/rabbitmq`: Change the type of `Config.Password` to be `configopaque.String` (#17273)\n- `receiver/redis`: Change the type of `Config.Password` to be `configopaque.String` (#17273)\n- `receiver/riak`: Change the type of `Config.Password` to be `configopaque.String` (#17273)\n- `receiver/saphana`: Change the type of `Config.Password` to be `configopaque.String` (#17273)\n- `receiver/snmp`: Change the types of the `Config.{AuthPassword,PrivacyPassword}` fields to be of `configopaque.String` (#17273)\n- `receiver/snowflake`: Change the type of `Config.Password` to be `configopaque.String` (#17273)\n- `receiver/solace`: Change the type of `Config.Auth.PlainText.Password` to be `configopaque.String` (#17273)\n- `spanmetricsconnector`: Histograms will not have exemplars by default (#23872)\n  Previously spanmetricsconnector would attach every single span as an exemplar to the histogram.\n  Exemplars are now disabled by default. To enable them set `exemplars::enabled=true`\n  \n- `receiver/vcenter`: Change the type of `Config.Password` to be `configopaque.String` (#17273)\n\n### 🚩 Deprecations 🚩\n\n- `dynatraceexporter`: Add deprecation note to Dynatrace metrics exporter (#23992)\n- `pkg/stanza`: Deprecate fileconsumer.EmitFunc in favor of fileconsumer.emit.Callback (#24036)\n- `pkg/stanza`: Deprecate filconsumer.Finder and related sortation structs and functions (#24013)\n- `servicegraphprocessor`: Service Graph Processor is deprecated in favor of the Service Graph Connector (#19737)\n\n### 🚀 New components 🚀\n\n- `exceptionsconnector`: A connector that generate metrics and logs from recorded applications exceptions from spans (#17272)\n- `opensearchexporter`: exports OpenTelemetry signals to [OpenSearch](https://opensearch.org/). (#23611)\n- `routingconnector`: A connector version of the routingprocessor (#19738)\n\n### 💡 Enhancements 💡\n\n- `lokiexporter, lokitranslator`: Added setting `default_labels_enabled`. This setting allows to make default labels `exporter`, `job`, `instance`, `level` optional (#22156)\n- `windowseventlogreceiver`: Add `exclude_providers` to the config. One or more event log providers to exclude from processing. (#21491)\n- `loadbalancingexporter`: Added docs for k8s service resolver. (#24287)\n- `loadbalancingexporter`: Added kubernetes service resolver to loadbalancingexporter. (#22776)\n- `opamp supervisor`: Add Capabilities support to Supervisor config. (#21044)\n- `opamp supervisor`: OpAMP Supervisor config file now supports \"tls\" settings in the \"server\" section. (#23848)\n- `pkg/ottl`: Add new `Len` converter that computes the length of strings, slices, and maps. (#23847)\n- `pkg/stanza`: Add option to skip log tokenization for both tcp and udp receivers. use the 'one_log_per_packet' setting to skip log tokenization if multiline is not used. (#23440)\n- `redisreceiver`: Adds unit to metrics where this was missing. (#23573)\n  Affected metrics can be found below.\n  - redis.role\n  - redis.cmd.calls\n  - redis.clients.connected\n  - redis.clients.blocked\n  - redis.keys.expired\n  - redis.keys.evicted\n  - redis.connections.received\n  - redis.connections.rejected\n  - redis.memory.fragmentation_ratio\n  - redis.rdb.changes_since_last_save\n  - redis.commands.processed\n  - redis.keyspace.hits\n  - redis.keyspace.misses\n  - redis.slaves.connected\n  - redis.db.keys\n  - redis.db.expires\n  \n- `elasticsearchexporter`: Add span duration in span store. (#14538)\n- `exporter/datasetexporter`: Rename 'observed_timestamp' field on the DataSet event to 'sca:observedTimestamp' and ensure the value is nanoseconds since epoch, update serializing and handling of body / message field to ensure it's consistent with other DataSet integrations and allow user to disable exporting scope information with each event by setting 'export_scope_info_on_event' logs config option to false. (#20660, #23826)\n- `exporter/datasetexporter`: Correctly map LogRecord severity to DataSet severity, remove redundant DataSet event message field prefix (OtelExporter - Log -) and remove redundant DataSet event fields (flags, flags.is_sampled). (#20660, #23672)\n- `journaldreceiver`: fail if unsufficient permissions for journalctl command (#20906)\n- `pkg/ottl`: Adds support for using boolean expressions with durations (#22713)\n- `pkg/ottl`: Adds support for using boolean expressions with time objects (#22008)\n- `pkg/ottl`: Add new `Duration` converter to convert string to a Golang time.duration (#22015)\n- `kafkareceiver`: Added support for json-encoded logs for the kafkareceiver (#20734)\n- `resourcedetectionprocessor`: Support GCP Cloud Run Jobs in resource detection processor. (#23681)\n- `googlemanagedprometheusexporter`: GMP exporter now automatically adds target_info and otel_scope_info metrics. (#24372)\n- `googlemanagedprometheusexporter`: GMP exporter supports filtering resource attributes to metric labels. (#21654)\n- `hostmetricsreceiver`: Remove the need to set environment variables with hostmetricsreceiver (#23861)\n- `experimentalmetricmetadata`: Introduce experimental entity event data types (#23565)\n- `influxdbexporter`: limit size of write payload (#24001)\n- `k8sclusterreceiver`: Change k8s.clusterresourcequota metrics to use mdatagen (#4367)\n- `k8sclusterreceiver`: Change k8s.cronjob.active_jobs to use mdatagen (#10553)\n- `k8sclusterreceiver`: Change k8s.daemonset metrics to use mdatagen (#10553)\n- `k8sclusterreceiver`: Refactor k8s.job metrics to use mdatagen (#10553)\n- `k8sclusterreceiver`: Change k8s.replicaset metrics to use mdatagen (#10553)\n- `k8sclusterreceiver`: Update k8s.replicationcontroller metrics to use mdatagen (#10553)\n- `k8sattrprocessor`: Add k8sattr.rfc3339 feature gate to allow RFC3339 format for k8s.pod.start_time timestamp value. (#24016)\n  Timestamp value before and after.\n  `2023-07-10 12:34:39.740638 -0700 PDT m=+0.020184946`, `2023-07-10T12:39:53.112485-07:00`\n  \n- `k8sclusterreceiver`: k8sclusterreceiver - Begin emitting entity events as logs (#24400)\n- `k8sclustereceiver`: Report entity state periodically (#24413)\n- `exporter/kafka`: Added support to Kafka exporter for configuring SASL handshake version (#21074)\n- `tailsamplingprocessor`: Added invert_match rule for numeric matcher, to support exclusion decision (#24563)\n- `cmd/mdatagen`: Simplify resource building in MetricsBuilder, suggest using ResourceBuilder instead. (#24443)\n- `cmd/mdatagen`: Introduce resource builder helper. (#24360)\n- `datadogexporter`: Add support for the `metrics::sums::initial_cumulative_monotonic_value` setting (#24544)\n  The setting has the same values and semantics as the `initial_value` setting from the `cumulativetodelta` processor\n  \n- `datadogexporter`: Source resolution logic now runs all source providers in parallel to improve start times. (#24234)\n  All source providers now run in all environments so you may see more spurious logs from downstream dependencies when using the Datadog exporter. These logs should be safe to ignore.\n  \n- `datadogexporter`: Add support for reporting host metadata from remote hosts. (#24290)\n  Resource attributes for each telemetry signal will be used for host metadata if the 'datadog.host.use_as_metadata' boolean attribute is set to 'true'.\n  \n- `resourcedetectionprocessor`: The system detector now detects the `host.arch` semantic convention (#22939)\n  The GOARCH value is used on architectures that are not well-known\n- `pkg/ottl`: Improve error reporting for errors during statement parsing (#23840)\n  - Failures are now printed for all statements within a context, and the statements are printed next to the errors.\n  - Erroneous values found during parsing are now quoted in error logs.\n  \n- `prometheusremotewrite`: improve the latency and memory utilisation of the conversion from OpenTelemetry to Prometheus remote write (#24288)\n- `prometheusremotewriteexporter, prometheusexporter`: Add `add_metric_suffixes` configuration option, which can disable the addition of type and unit suffixes. (#21743, #8950)\n- `pkg/translator/prometheusremotewrite`: Downscale exponential histograms to fit prometheus native histograms if necessary. (#17565)\n- `routingprocessor`: Enables processor to extract metadata from client.Info (#20913)\n  Enables processor to perform context based routing for payloads on the http server of otlp receiver\n- `processor/transform`: Report all errors from parsing OTTL statements (#24245)\n- `azuremonitorexporter`: Map enduser.id to Azure UserID tag (#18103)\n\n### 🧰 Bug fixes 🧰\n\n- `datasetexporter`: Call the correct library function then exporter is shutting down. (#24253)\n- `awscloudwatchreceiver`: emit logs from one log stream in the same resource (#22145)\n- `resourcedetectionprocessor`: avoid returning empty host.id on the `system` detector (#24230)\n- `ecsobserver`: Don't fail with error when finding a task of EC2 launch type and missing container instance, just ignore them. This fixes behavior when task is provisioning and its containers are not assigned to instances yet. (#23279)\n- `filelogreceiver`: Fix file sort timestamp validation (#24041)\n- `lokitranslator`: Fix bug when attributes targeted in slice hint not converted to labels when log record has severity_number (#22038)\n- `prometheusreceiver`: Don't fail the whole scrape on invalid data (#24030)\n- `datadogreceiver`: Include datadog span.Resource in translated span attributes (#23150)\n- `cmd/telemetrygen`: Move the span attribute span.kind to the native Kind which is a top level trace information (#24286)\n- `pkg/stanza`: Fix issue where nil body would be converted to string (#24017)\n- `pkg/stanza`: Fix issue where syslog input ignored enable_octet_counting setting (#24073)\n- `processor/resourcedetection`: Fix docker detector not setting any attributes. (#24280)\n- `processor/resourcedetection`: Fix Heroku config option for the `service.name` and `service.version` attributes (#24355)\n  `service.name` and `service.version` attributes were mistakenly controlled by `heroku.app.name` and\n  `heroku.release.version` options under `resource_attributes` configuration introduced in 0.81.0. \n  This PR fixes the issue by using the correct config options named the same as the attributes.\n- `processor/resourcedetection`: make sure to use a aks config struct instead of nil to avoid collector panic (#24549)\n- `filelogreceiver`: Fix issue where files were deduplicated unnecessarily (#24235)\n- `processor/tailsamplingprocessor`: Fix data race when accessing spans during policies evaluation (#24283)\n- `zipkintranslator`: Stop dropping error tags from Zipkin spans. The old code removes all errors from those spans, rendering them useless if an actual error happened. In addition, no longer delete error tags if they contain useful information. (#16530)\n\n## v0.81.0\n\n### 🛑 Breaking changes 🛑\n\n- `clickhouseexporter`: Add scopeName and scopeVersion column to span table. (#21214)\n- `clickhouseexporter`: add log scope columns to span table. (#20280)\n- `receiver/aerospike`: Change the type of `Config.Password` to be `configopaque.String` (#17273)\n- `receiver/bigip`: Change the type of `Config.Password` to be `configopaque.String` (#17273)\n- `receiver/couchdb`: Change the type of `Config.Password` to be `configopaque.String` (#17273)\n- `receiver/elasticsearch`: Change the type of `Config.Password` to be `configopaque.String` (#17273)\n- `receiver/mongodb`: Change the type of `Config.Password` to be `configopaque.String` (#17273)\n- `receiver/mongodbatlas`: Change the types of `Config.PrivateKey` and `Config.Alerts.Secret` to be `configopaque.String` (#17273)\n- `receiver/mysql`: Change the type of `Config.Password` to be `configopaque.String` (#17273)\n- `dockerstatsreceiver`: Add non populated metrics `container.memory.anon` and `container.memory.file` that are only available when the host uses cgroups v2. (#21097)\n  Metric `container.memory.file` was added to fulfil the lack of `container.memory.total_cache` metric in case that the\n  cgroup version mounted in the host is v2 instead of v1.\n  \n  Now there is documentation of which metrics are available depending cgroups version being used on the host.\n  \n\n### 🚩 Deprecations 🚩\n\n- `mysqlreceiver`: set `mysql.locked_connects` as optional in order to remove it in next release (#14138, #23274)\n\n### 💡 Enhancements 💡\n\n- `mdatagen`: Adds a parent field to metadata.yaml for subcomponents. (#23636)\n- `sqlqueryreceiver`: Add support of Start and End Timestamp Column in Metric Configuration. (#18925, #14146)\n- `postgresqlreceiver`: Adds unit to metrics where this was missing. (#23571)\n  Affected metrics can be found below.\n  - postgresql.bgwriter.maxwritten\n  - postgresql.table.count\n  \n- `mdatagen`: Adds validation to mdatagen to ensure that all required fields are present, and their content is valid. (#23783)\n- `filelogreceiver`: Add support for tracking the current file in filelogreceiver (#22998)\n- `exporter/datasetexporter`: Add more details to User-Agent header for DataSet HTTP requests (#20660)\n- `dockerstatsreceiver`: Add `container.image.id` and `container.command_line` optional resource attributes (#21092)\n- `googlecloudexporter`: Adds an experimental, opt-in write ahead log for GCP metrics exporter. (#23679)\n- `pkg/ottl`: Adds new `Time` converter to convert a string to a Golang time struct based on a supplied format (#22007)\n- `hostmetricsreceiver`: Add new Windows-exclusive process.handles metric. (#21379)\n- `websocketprocessor`: Rename websocketprocessor to remoteobserverprocessor (#23856)\n- `resourcedetectionprocessor`: Adds a way to configure the list of added resource attributes by the processor (#21482)\n  Users can now configure what resource attributes are gathered by specific detectors.\n  Example configuration:\n  \n  ```\n  resourcedetection:\n    detectors: [system, ec2]\n    system:\n      resource_attributes:\n        host.name:\n          enabled: true\n        host.id:\n          enabled: false\n    ec2:\n      resource_attributes:\n        host.name:\n          enabled: false\n        host.id:\n          enabled: true\n  ```\n  \n  For example, this config makes `host.name` being set by `system` detector, and `host.id` by `ec2` detector.\n  Moreover:\n  - Existing behavior remains unaffected as all attributes are currently enabled by default.\n  - The default attributes 'enabled' values are defined in `metadata.yaml`.\n  - Future releases will introduce changes to resource_attributes `enabled` values.\n  - Users can tailor resource detection process to their needs and environment.\n  \n- `spanmetricsconnector`: Added disabling options for histogram metrics and option to exclude default labels from all metrics. In some cases users want to optionally disable part of metrics because they generate too much data or are not needed. (#16344)\n- `statsdreceiver`: All receivers are setting receiver name and version when sending data. This change introduces the same behaviour to the statsd receiver. (#23563)\n- `zookeeperreceiver`: Adds an additional health check metric based off of the response from the zookeeper ruok 4lw command. (#21481)\n- `k8sclusterreceiver`: Switch k8s.pod and k8s.container metrics to use pdata. (#23441)\n\n### 🧰 Bug fixes 🧰\n\n- `k8sclusterreceiver`: Add back all other vendor-specific node conditions, and report them even if missing, as well as all allocatable node metrics if present,  to the list of Kubernetes node metrics available, which went missing during the pdata translation (#23839)\n- `k8sclusterreceiver`: Add explicitly `k8s.node.allocatable_pods` to the list of Kubernetes node metrics available, which went missing during the pdata translation (#23839)\n- `awsecscontainermetricsreceiver`: Fix possible panics in awsecscontainermetrics receiver (#23644)\n- `elasticsearchexporter`: use mapping.dedup and mapping.dedot configuration values (#19419)\n- `receiver/kafkametricsreceiver`: Updates certain metrics in kafkametricsreceiver to function as non-monotonic sums. (#4327)\n  Update the metrics type in KafkaMetricsReceiver from \"gauge\" to \"nonmonotonic sum\". Changes metrics are, kafka.brokers, kafka.topic.partitions, kafka.partition.replicas, kafka.partition.replicas_in_sync, kafka.consumer_group.members.\n- `clickhouseexporter`: Fix clickhouse exporter create database fail (#23664)\n- `spanmetricsconnector`: set timestamp correctly for metrics with delta temporality (#7128)\n- `vcenterreceiver`: Fixed a bug in which the vCenter receiver was incorrectly emitting the \"used\" attribute twice under the vcenter.datastore.disk.usage metric instead of \"used\" and \"available\". (#23654)\n- `mongodbreceiver`: Fix missing version in mongodb creating panics during scrapes (#23859)\n- `postgresqlreceiver`: fixed an issue where postgresql receiver was emitting the same attribute value \"toast_hit\" twice under postgresql.blocks_read metric. (#23657)\n- `windowseventlogreceiver`: Fix buffer overflow when ingesting large raw Events (#23677)\n- `pkg/stanza`: adding octet counting event breaking for syslog parser (#23577)\n\n## v0.80.0\n\n### 🛑 Breaking changes 🛑\n\n- `redisreceiver`: Updates metric unit from no unit to Bytes. (#23454)\n  Affected metrics can be found below.\n  - redis.clients.max_input_buffer\n  - redis.clients.max_output_buffer\n  - redis.replication.backlog_first_byte_offset\n  - redis.replication.offset\n  \n- `elasticsearchreceiver`: Bump 'receiver.elasticsearch.emitNodeVersionAttr' to stable (#16847)\n  All node metrics are now enriched with the node version resource attribute.\n- `nginxreceiver`: Bump 'receiver.nginx.emitConnectionsCurrentAsSum' featuregate to beta (enabled by default) (#4326)\n- `servicegraphprocessor`: Change metric names to match the spec (#18743, #16578)\n  Latency metric `traces_service_graph_request_duration_seconds` are deprecated in favor of server and client metrics | `traces_service_graph_server_request_seconds` and `traces_service_graph_client_request_seconds` | respectively. Use the feature gate `processor.servicegraph.legacyLatencyMetricNames` to enable the old metric names.\n- `prometheusreceiver, prometheusexporter, prometheusremotewrite`: Disable `pkg.translator.prometheus.NormalizeName` feature gate by default (#23208)\n  The feature gate `pkg.translator.prometheus.NormalizeName` was enabled prematurely while translation\n  on the prometheus receiver was incomplete. To address this, the feature gate has been reverted back to alpha status.\n  This will remain the case until the translation on the receiver side aligns with the translation on the exporter side,\n  or until it is replaced with a configuration option or completely removed. To maintain the current behavior, you can\n  enable the feature gate using the `--feature-gates=pkg.translator.prometheus.NormalizeName` command argument. \n  However, please note that the translation in the prometheus receiver is a subject to future changes.\n  \n\n### 🚩 Deprecations 🚩\n\n- `mysqlreceiver`: deprecate `mysql.locked_connects` in favor of `mysql.connection.errors` (#14138)\n- `sumologicexporter`: deprecating options which are going to be removed (#23059)\n  The following options are going to be deprecated and removed in the future:\n  \n  - `metric_format: {carbon2, graphite}` (leaving only `prometheus`)\n  - `metadata_attributes: [<regex>]`\n  - `graphite_template: <template>`\n  - `source_category: <template>`\n  - `source_name: <template>`\n  - `source_host: <template>`\n\n### 🚀 New components 🚀\n\n- `websocketprocessor`: Implementation of websocket processor (#19633)\n\n### 💡 Enhancements 💡\n\n- `aerospikereceiver`: Adds unit to metrics where this was missing. (#23572)\n  Affected metrics can be found below.\n  - aerospike.node.query.tracked\n  \n- `awsemfexporter`: Add exponential histogram support. (#22626)\n- `awsxrayexporter`: Adding translation support for span links for the aws x-ray exporter (#20353)\n- `bearertokenauthextension`: Extension now implements configauth.ServerAuthenticator (#22737)\n- `datadogexporter`: Add `traces::compute_stats_by_span_kind` and `traces::peer_service_aggregation` configuration flags (#23240)\n  Config `traces::compute_stats_by_span_kind` enables an additional stats computation check on span kind. | Config `traces::peer_service_aggregation` enables `peer.service` aggregation in the exporter.\n- `resourcedetectionprocessor`: use opentelemetry-go library for `host.id` detection in the `system` detector (#18533)\n- `mysqlreceiver`: add `aborted`, `aborted_clients` and `locked` values to `error` property for `mysql.connection.errors` metric (#14138)\n- `datasetexporter`: Allow include Logs resource info export to DataSet based on new export_resource_info_on_event configuration. Fix timestamp handling. (#20660)\n- `k8sattributesprocessor`: Store only necessary ReplicaSet data (#23226)\n- `k8sattributesprocessor`: Store only necessary Pod data (#23226)\n- `dockerstatsreceiver`: Add container.uptime metric, indicating time elapsed since the start of the container. (#22037)\n- `influxdbexporter`: Add configurable span dimensions (#23230)\n- `receiver/k8s_cluster`: Do not store unused data in the k8s API cache to reduce RAM usage (#23433)\n- `lokiexporter`: Added `flags` field from plog.LogRecord into Loki entry (#21650)\n- `pkg/ottl`: Add new `IsString` and `IsMap` functions to facilitate type checking. (#22750)\n  Especially useful for checking log body type before parsing.\n- `pkg/ottl`: Adds `StandardFuncs` and `StandardConverters` to facilitate function map generation. (#23190)\n  This change means that new functions added to ottlfuncs get automatically added to Cotnrib components that use OTTL\n- `pkg/ottl`: Change replacement functions to accept a path expression as a replacement (#22787)\n  The following replacement functions now accept a path expression as a replacement:\n  - replace_match\n  - replace_pattern\n  - replace_all_matches\n  - replace_all_patterns\n  \n- `sapmexporter`: sapm exporter now supports `compression` config option to specify either gzip or zstd compression to use. (#23257)\n- `sapmreceiver`: sapm receiver now accepts requests in compressed with zstd. (#23257)\n- `exporter/signalfx`: Do not drop container.cpu.time metric in the default translations so it can be enabled in the include_metrics config. (#23403)\n- `sqlqueryreceiver`: Add support for logs (#20284)\n- `exporter/datadog`: Adds metric otel.datadog_exporter.runtime_metrics.running to track when the Datadog Exporter receives a payload containing runtime metrics. (#23138)\n- `k8sclusterreceiver`: Switch k8s.deployment metrics to use pdata. (#23416)\n- `k8sclusterreceiver`: Switch k8s.hpa metrics to use pdata. (#18250)\n- `k8sclusterreceiver`: Switch k8s.namespace metrics to use pdata. (#23437)\n- `k8sclusterreceiver`: Switch k8s.node metrics to use pdata. (#23438)\n- `k8sclusterreceiver`: Switch k8s.rq metrics to use pdata. (#23419)\n- `k8sclusterreceiver`: Switch k8s.ss metrics to use pdata. (#23420)\n- `testbed`: Add `WithAgentExePath`, which allows setting the path of the Collector executable. (#23258)\n- `carbonreceiver, wavefrontreceiver`: Remove use of opencensus model in carbonreceiver and wavefrontreceiver (#20759, #20761)\n- `webhookeventreceiver`: Mark the component as Alpha and add to `component.go` (#18101)\n- `webhookeventreceiver`: first pass implementing the components internals. (#18101)\n\n### 🧰 Bug fixes 🧰\n\n- `datadogreceiver`: add client context to the traces received by datadogreceiver (#22991)\n- `otel-collector`: Fix cri-o log format time layout (#23027)\n- `receiver/hostmetricsreceiver`: Fix not sending `process.cpu.utilization` when `process.cpu.time` is disabled. (#23450)\n- `receiver/kafkametricsreceiver`: Updates certain metrics in kafkametricsreceiver to function as non-monotonic sums. (#4327)\n  Update the metric type in KafkaMetricsReceiver from \"gauge\" to \"nonmonotonic sum\".\n- `processor/hostmetrics`: Fix issue where receiver fails to read parent-process information for some processes on Windows (#14679)\n- `receiver/skywalking`: Fix the issue where `ParentSpanId` is lost when crossing segments. (#21799)\n- `iisreceiver`: Removes error message on every scrape where no items are present in the queue. (#14575)\n- `k8sclusterreceiver`: Fix empty k8s.namespace.name attribute in k8s.namespace.phase metric (#23452)\n- `splunkhecexporter`: Apply multi-metric merge at the level of the whole batch rather than within events emitted for one metric. (#23365)\n\n## v0.79.0\n\n### 🛑 Breaking changes 🛑\n\n- `attributesprocessor`: Enable SHA-256 as hashing algorithm by default for attributesprocessor hashing action (#4759)\n- `windowseventlogreceiver`: Emit raw Windows events as strings instead of byte arrays (#22704)\n- `receiver/httpcheck`: Removed the default `endpoint` value of `http://localhost:80`. The `endpoint` property is now required. (#22995)\n- `pkg/ottl`: Removes `StandardTypeGetter` in favor of `StandardStringGetter`, `StandardIntGetter`, `StandardFloatGetter`, and `StandardPMapGetter`, which handle converting pcommon.Values of the proper type. (#22763)\n  This is only a breaking change for users using OTTL in custom components. For all Contrib components this is an enhancement.\n- `postgresqlreceiver`: Remove resource attribute feature gates (#22479)\n\n### 🚩 Deprecations 🚩\n\n- `dockerstatsreceiver`: cpu.container.percent metric will be deprecated in v0.79.0 in favor of container.cpu.utilization (#21807)\n  This starts the process of phasing out incorrect metric name:\n  - `container.cpu.utilization`\n  and replacing it with the names adhering to the semantic conventions:\n  - `container.cpu.percent`\n  At this stage, the new metric is added, but is disabled by default.\n  See the \"Deprecations\" section of the Docker Stats receiver's README for details.\n  \n\n### 💡 Enhancements 💡\n\n- `receiver/azuremonitorreceiver`: Retrieve metric values with all dimension keys in filter (#21715)\n- `apachesparkreceiver`: Changes required to move the Apache Spark receiver to Alpha stability (#21046)\n- `journaldreceiver`: add support for grep (#20295)\n- `mysqlreceiver`: add mysql.uptime metric (#14138)\n- `googlecloudspannerreceiver`: Adding a new config option to allow truncation of query text to 1024 characters. (#22072)\n- `vcenterreceiver`: Adds VM memory utilisation metric (#20917)\n- `receivers`: Adding `initial_delay` to receivers to control when scraping interval starts (#23030)\n  The updated receivers are:\n  - `active_directory_ds`\n  - `aerospike`\n  - `apache`\n  - `apachespark`\n  - `azuremonitor`\n  - `couchdb`\n  - `chrony`\n  - `docker_stats`\n  - `elasticsearch`\n  - `expvar`\n  - `filestats`\n  - `flinkmetrics`\n  - `googlecloudspanner`\n  - `haproxy`\n  - `httpcheck`\n  - `iis`\n  - `memcached`\n  - `mongodb`\n  - `mysql`\n  - `nginx`\n  - `oracledb`\n  - `podman_stats`\n  - `postgresql`\n  - `rabbitmq`\n  - `riak`\n  - `snowflake`\n  - `sqlquery`\n  - `sqlserver`\n  - `sshcheck`\n  - `vcenter`\n  - `windowsperfcounters`\n  - `zookeeper`\n- `oracledbreceiver`: Add a simpler alternative configuration option (#22087)\n- `exporter/datadog`: Upgrade opentelemetry-mapping-go to v0.3.0 and use pkg/otlp/logs for logs translation (#23137)\n- `pkg/ottl`: Add `body.string` accessor to ottllog (#22786)\n- `pkg/ottl`: Allow indexing map and slice log bodies (#17396, #22068)\n- `pkg/ottl`: Add hash converters/functions for OTTL (#22725)\n- `solacereceiver`: Updated solacereceiver to handle new features of Solace PubSub+ 10.4.1 (#22809)\n- `splunkhecreceiver`: Support different strategies for splitting payloads when receiving a request with the Splunk HEC receiver. (#22788)\n- `exporter/splunk_hec`: Apply compression to Splunk HEC payload unconditionally if it's enabled in the config. (#22969, #22018)\n  The compression used to be enabled only if the payload size was greater than 1.5KB which significantly\n  complicated the logic and made it hard to test. This change makes the compression unconditionally applied to \n  the payload if it's enabled in the config. The benchmarking shows improvements in the throughput and CPU usage for \n  large payloads and expected degradation for small payloads which is acceptable given that it's not a common case.\n  \n- `awsxrayexporter`: Support 2 new aws service name attributes for populating X-Ray segment name (#22835)\n\n### 🧰 Bug fixes 🧰\n\n- `jmxreceiver`: Fixed the issue where the JMX receiver's subprocess wasn't canceled upon shutdown, resulting in a rogue java process. (#23051)\n- `internal/filter/filterlog`: fix filtering non-string body by bodies property (#22736)\n  Affects `filterprocessor` and `attributesprocessor`.\n- `prometheusreceiver`: Remove sd_file validations from config.go in Prometheus Receiver to avoid failing Collector with error as this behaviour is incompatible with the Prometheus. (#21509)\n- `filelogreceiver`: Fix issue where empty files would not be skipped, resulting in extraneous errors. (#22815)\n- `servicegraphprocessor`: consume traces even metric count is equal to 0 (#23028)\n- `fileexporter`: Fixes broken lines when rotation is set. (#22747)\n- `receiver/purefareceiver`: Ensure that all endpoints beyond volumes and hosts are beeing scraped. (#14886)\n- `exporter/datadog`: `tls::insecure_skip_verify` is now honored when exporting traces. (#22772)\n- `exporter/splunk_hec`: Make sure the `max_event_size` option is used to drop events larger than `max_event_size` instead of using it for batch size. (#18066)\n- `httpcheckreceiver`: Update default collection interval to match documented value (#23019)\n- `azuredataexplorerexporter`: Update underlying SDK to perform retries on init on machines with flaky networks. (#22771)\n- `flink metrics receiver`: Fixed error when failing to read job manager metrics (#23143)\n- `apache receiver`: reverted default collection time back to 10s from 1m (#23030)\n- `postgresqlreceiver`: Fix race condition when capturing errors from multiple requests simultaneously (#23026)\n- `prometheusreceiver`: The prometheus receiver now sets a full, versioned user agent. (#21910)\n- `awscloudwatchreceiver`: Fixes a bug where the AWS CloudWatch receiver does the log stream filtering (using prefix) incorrectly. (#22123)\n  An additional request was being made with a single log stream prefix definition.\n  This request was made with the stream name set to \"\".\n  This results in logs collection from all log streams in the log group.\n  \n- `spanmetricsconnector`: Fix initialization of the default histogram buckets when the `seconds` unit is provided. (#21797)\n- `splunkhecreceiver`: Fix reusing the same splunkhecreiver between logs and metrics (#22848)\n\n## v0.78.0\n\n### 🛑 Breaking changes 🛑\n\n- `receiver/chrony`: Update emitted Scope name to \"otelcol/chronyreceiver\" (#21382)\n- `elasticsearchreceiver`: Enable 'elasticsearch.node.version' resource attribute on node metrics, by default (#16847)\n- `receiver/filestats`: Update emitted Scope name to \"otelcol/filestatsreceiver\" (#21382)\n- `receiver/mongodbatlas`: Update emitted Scope name to \"otelcol/mongodbatlasreceiver\" (#21382)\n- `receivers`: Updating receivers that run intervals to use standard interval by default (#22138)\n- `datadog receiver`: Updating datadog translations to align more closely to semantic convention (#21210, #21525)\n  - `service.name` is moved from assigned from span attributes to resource attributes\n  - Moved from using datadog's `span.Resouce` to `span.Name` to set span name\n  - Exported traces are now grouped by `service.name` by default\n  \n- `nginxreceiver`: Add featuregate to emit 'nginx.connections_current' as a non-monotonic sum (#4326)\n- `pkg/ottl`: Updates the `Int` converter to use a new `IntLikeGetter` which will error if the value cannot be converted to an int. (#22059)\n  Affected components: transformprocessor, filterprocessor, routingprocessor, tailsamplingprocessor, countconnector. It is HIGHLY recommended to use each component's error_mode configuration option to handle errors returned by `Int`.\n  \n- `dockerstatsreceiver`: Remove container.memory.total_swap and container.memory.swap metrics as they are not reported by the docker API (#21190)\n\n### 🚀 New components 🚀\n\n- `apachesparkreceiver`: adds the apachesparkreceiver metric receiver (#21046)\n- `awscloudwatchmetricsreceiver`: Added [AWS CloudWatch metrics](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/working_with_metrics.html) receiver using GetMetricData API call (#15667)\n- `syslogexporter`: Add syslogexporter for sending logs to syslog server (#17982)\n- `filereceiver`: This change enables the file receiver. (#14638)\n- `datasetexporter`: Enable Datasetexporter in `internal/components` (#20660)\n- `splunkenterprisereceiver`: Wireframe for the splunk enterprise monitoring receiver (#12667)\n- `WebSocket processor`: Add WebSocket processor skeleton (#19633)\n\n### 💡 Enhancements 💡\n\n- `jmxreceiver`: Add the JMX metrics gatherer version 1.26.0-alpha to the supported jars hash list (#22042)\n- `receivercreator`: add logs and traces support to receivercreator (#19205, #19206)\n- `pkg/ottl`: Add Log function (#18076)\n- `awsemfexporter`: Added a `tags` field to the config of the exporter to set tags for a Cloudwatch Log Group (#19406)\n- `tailsamplingprocessor`: Add OTTL Condition policy for tailsampling processor. (#20294)\n- `pkg/ottl`: Add a uuid function to ottl (#20301)\n- `oracledbreceiver`: Adds support for `consistent gets` and `db block gets` metrics. Disabled by default. (#21215)\n- `pkg/batchperresourceattr`: Mark as not mutating as it does defensive copying. (#21885)\n- `cumulativetodelta`: Makes handling of the first observed point configurable. Defaults to auto based on start time. (#20770)\n- `elasticsearchexporter`: Add dynamic indexing option to elasticsearchexporter (#5854)\n- `receiver/kafkareceiver`: Support configuration of initial offset strategy to allow consuming form latest or earliest offset (#14976)\n- `fileexporter`: provide additional documentation for the working setup of the file exporter. (#20279)\n- `internal/filter`: Add `Log`, `UUID`, and `ParseJSON` converters to filterottl standard functions (#21970)\n- `pkg/stanza`: aggregate the latter part of the split-log due to triggering the size limit (#21241)\n- `exporter/datadog`: Map Docker stats receiver metrics to Datadog container metrics. (#22149)\n  This change enables the use of the Containers (Overview) dashboard.\n- `dockerstatsreceiver`: docker container's `pids_stats` metrics are reported when available (#21041)\n- `datasetexporter`: Add support for exporting logs and traces. (#20660)\n- `datasetexporter`: Mark component as alpha and upgrade to the latest `dataset-go` v0.0.8. (#20660)\n- `k8sattributesprocessor`: Support adding attribute `k8s.deployment.uid`. (#14003)\n- `kafkareceiver`: Add `text` unmarshaler, which will decode the kafka message as text and insert it as the body of a log record. (#20734)\n- `cmd/mdatagen`: Allow setting resource_attributes without introducing the metrics builder. (#21516)\n- `receiver/mongodbatlasreceiver`: Allow collection of MongoDB Atlas Access Logs as a new feature of the MongoDBAtlas receiver. (#21182)\n- `sshcheckreceiver`: Promote sshcheckreceiver to alpha (#21488)\n- `pkg/ottl`: Add `FloatLikeGetter` and `FloatGetter` to facilitate float retrival for functions. (#21896)\n- `pkg/ottl`: Add access to get and set span kind using a string (#21773)\n- `processor/routingprocessor`: Instrument the routing processor with non-routed spans/metricpoints/logrecords counters (OTel SDK). (#21476)\n- `skywalkingreceiver`: Refactoring the code structure/directory for the following metrics receiver implementation (#20315)\n- `exporter/splunkhec`: Improve performance and reduce memory consumption. (#22018)\n- `processor/transform`: Add access to the Log function (#22014)\n\n### 🧰 Bug fixes 🧰\n\n- `statsdreceiver`: Handles StatsD server not running when shutting down to avoid NPE (#22004)\n- `exporter/elasticsearch`: Fix elasticsearch exporter not exporting span events (#18479)\n- `tests`: switch math/rand to crypto/rand (#20341)\n- `dockerstats`: Only one label/envVar was added even if multiple ones were specified by ContainerLabelsToMetricLabels or EnvVarsToMetricLabels (#21113)\n- `pkg/ottl`: Fix the factory name for the limit function (#21920)\n- `awsxrayexporter`: Fix a panic that can occur with string-valued DynamoDB attributes. (#22707)\n- `processor/filter`: Fix issue where the OTTL function `HasAttributeKeyOnDatapoint` was not usable. (#22057)\n- `pkg/ottl`: Allow using capture groups in `replace_all_patterns` when replacing map keys (#22094)\n- `confmap/provider/s3provider`: Fix typo in s3 confmap provider regex pattern (#22146)\n  Fix regex pattern for s3 confmap provider. This typo allows for using different domains\n  from what is expected.\n  \n- `confmap/provider/s3provider`: Properly handle bucket names containing dot characters (#22054)\n  Properly handle bucket names containing dot characters, according to\n  https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html\n  \n- `receiver/dockerstats`: Fix `container.memory.usage.total` and `container.memory.percent` calculation. (#21097)\n  The fix updates the way to calculate the metrics to be consistent with `MEM USAGE`` and `MEM %`\n  showed by the `stats` docker CLI command. It also support v1 and v2 of cgroups.\n  Expect to see an increase of these metrics if currently running the receiver in a cgroups v1 environment.\n  As well as see a decrease in these values if running on cgroups v2 environment. \n  \n- `exporter/splunkhec`: Fix a bug causing incorrect data in the partial error returned by the exporter (#21720)\n\n## v0.77.0\n\n### 🛑 Breaking changes 🛑\n\n- `dotnetdiagnosticsreceiver`: Removing component which has been unmaintained for over 6 months (#13218)\n- `cmd/mdatagen`: Don't expose `resource_attributes` user config section if it's empty. (#21519)\n- `pkg/ottl`: Reimplement all OTTL function factories to implement the `ottl.Factory` interface. (#14712)\n  The `ottl.Factory` interface allows making factories extendable and defines\n  canonical names for the functions across components using the OTTL.\n\n### 🚀 New components 🚀\n\n- `datasetexporter`: Add new DataSet exporter. (#20660)\n\n### 💡 Enhancements 💡\n\n- `receiver/azuremonitorreceiver`: Providing an option to include resource tags and location as metric attributes (#21173)\n- `mdatagen`: Support stability level per signal (#21153)\n- `filestatsreceiver`: Promote filestats receiver to alpha, add to the otelcontribcol tests. (#21257)\n- `mdatagen`: Add support for slice and map attributes. (#18272)\n- `receiver/mongodbatlasreceiver`: emit \"`mongodb_atlas.cluster.name`\" attribute which is thename of the cluster as defined in Atlas. This attribute is disabled by default, if you want to emit it, you'll need to explicitly enable it. (#21154)\n- `pkg/ottl`: Allow using Converters as constant boolean expressions (#20911)\n  This means you don't need to add `== true` after `IsMatch` in OTTL conditions.\n- `pkg/ottl`: Add support for complex indexing of Paths and Converters to allow accessing nested items. (#20754)\n  All components using OTTL can take advantage of this feature.\n- `signalfxexporter`: Expose dimension_client configuration for dimension/metadata updates (#21512)\n- `pkg/stanza`: Add \"unquote\" operator (#10282)\n\n### 🧰 Bug fixes 🧰\n\n- `snowflakereceiver`: Wiring snowflakereceiver component by adding it to components.go (#21381)\n- `pkg/stanza`: Fix errors in loop evaluating file attributes on windows if the file path contains a Junction (#21088)\n- `clickhouseexporter`: Fix insert metrics with duplicate scope data (#21082)\n- `transformprocessor`: Fixed a scenario where replace_all_patterns would wipe out non-string values on key name change. (#21109)\n- `influxdbexporter`: handle empty attribute values emitted by hostmetricsreceiver with logger.Debug instead of PermanentError (#21474)\n- `receiver/k8scluster`: Make sure the k8scluster receiver is watching for v2 and v2beta2 HorizontalPodAutoscalers for Kubernetes 1.26 (#20480)\n- `splunkhecexporter`: Enforce marshaling json with sorted keys by alphabetical order to produce identical hashes when merging events. (#21486)\n- `googlecloudspannerreceiver`: Changing type of USED_BYTES from INT to FLOAT (#21500)\n- `receiver/mongodbatlasreceiver`: Disk Usage & Utilization metrics are now being reported correctly. (#21180)\n- `receiver/mongodbatlasreceiver`: Reduce the likelihood that mongodbatlas log receivers will emit empty logs, causing unnecessary events to propagate through a pipeline. (#14170)\n- `datadogexporter`: Use literal 'host' resource attribute on OTLP payloads when present as the host value to avoid double tagging. (#21507)\n- `receiver/nsx`: Remove incorrectly exposed resource attributes from the user configuration interface. (#21523)\n- `signalfxexporter`: disk.utilization and disk.summary_utilization now matches the df command by only counting non-root usage. disk.utilization = (used/(used + free)) * 100 (#20656)\n\n## v0.76.1\n\n### 🛑 Breaking changes 🛑\n\n- `prometheusreceiver, prometheusexporter, prometheusremotewrite`: Enable pkg.translator.prometheus.NormalizeName by default (#20518)\n  Enabling normalization by default changes the emitted metrics for components that rely on\n  the prometheus translation package. This feature can still be disabled via the following\n  `--feature-gates=-pkg.translator.prometheus.NormalizeName`\n  \n- `cumulativetodeltaprocessor`: Removes stable `processor.cumulativetodeltaprocessor.EnableHistogramSupport` feature gate. Setting this gate will cause an error. (#20717)\n- `exporter/lokiexporter`: Remove deprecated Loki exporters parameters. (#15653, #15365)\n  The support of `labels.{attributes/resource}`, `labels.record`, `tenant`, | and `format` configuration parameters are dropped in favor of attribute hints way of configuring the exporter.\n- `solacereceiver`: Changed the type of the max_unacknowledged configuration option from uint32 to int32 (#20666)\n\n### 🚩 Deprecations 🚩\n\n- `dotnetdiagnosticsreceiver`: add deprecation notice (#20740)\n\n### 🚀 New components 🚀\n\n- `lokireceiver`: Added implementation of the Loki receiver component (#18635)\n- `receiver/azuremonitorreceiver`: New component for scraping Azure Monitor metrics (#18899)\n- `cassandra_exporter`: Cassandra exporter implementation (#17910)\n- `lokireceiver`: Mark loki receiver as Alpha (#18635)\n- `filestatsreceiver`: Initial implementation of the new filestatsreceiver component. (#19729)\n\n### 💡 Enhancements 💡\n\n- `jmxreceiver`: Add the JMX metrics gatherer version 1.24.0-alpha to the supported jars hash list (#20551)\n- `jmxreceiver`: Add the JMX metrics gatherer version 1.25.0-alpha to the supported jars hash list (#21052)\n- `jmxreceiver`: Add the JMX metrics gatherer version 1.25.1-alpha to the supported jars hash list (#21103)\n- `exporter/awsxray`: Add opt-in telemetry for X-Ray receiver/exporter (#19415)\n- `awsemfexporter`: Add support AWS Embedded Metric Format Version 0 (#20314)\n- `splunkhecexporter`: Set the default value of the idle connection timeout to 10s, rather than 30s by default (#20543)\n- `coralogixexporter`: Allow users to use only Coralogix domain to configure exporter (#20719)\n- `datadogexporter`: Ensure that container tags are set globally on the payload so that they can be picked up as primary tags in the app (APM). (#20923)\n- `datadogexporter`: Reduce log level of retriable errors to Debug level (#20755)\n- `datadogexporter`: Support OTel semconv 1.17.0 in Datadog OTLP trace ingestion. (#20923)\n- `datadogexporter`: Use minimum and maximum values from cumulative Histograms. Values are used only when we can assume they are from the last time window or otherwise to clamp estimates. (#20872)\n- `journaldreceiver`: add support for `matches` configuration (#20295)\n- `fileexporter`: Add periodic flushing (#18251)\n  Adding flushing to the file exporter eases the analysis\n  of the output the exporter generates.\n  \n- `pkg/stanza`: Add and option to pause reading a file and attempt to resend the current batch of logs if it encounters an error from downstream components. (#20511)\n  Add a `retry_on_failure` config option (disabled by default) that can be used to slow down reading logs instead of \n  dropping logs if downstream components return a non-permanent error. The configuration has the following options:\n    - `enabled`: Enable or disable the retry mechanism. Default is `false`.\n    - `initial_interval`: The initial interval to wait before retrying. Default is `1s`.\n    - `max_interval`: The maximum interval to wait before retrying. Default is `30s`.\n    - `max_elapsed_time`: The maximum amount of time to wait before giving up. Default is `5m`.\n  \n- `k8sattributesprocessor`: Allow getting k8s.container.name, container.image.name and container.image.tag by container.id. (#19468)\n  The container.id resource attribute can be set automatically in most SDKs by means of API.\n- `instanaexporter`: Preserve resource attributes in converted spans (#20454)\n- `splunkhecexporter`: Apply a new config `maxEventSize` on our events, it would break down the events based on this. This basically implements HEC's `maxEventSize` on our exporter. It is implemented on uncompressed data. (#20290)\n- `splunkhecreceiver`: Make Splunk HEC receiver Health endpoint mimic the real one (#20871)\n- `receiver/mongodbatlasreceiver`: emit \"`mongodb_atlas.user.alias`\" attribute which is the user-friendly hostname of the cluster node as displayed in the Atlas portal. This attribute is disabled by default, if you want to emit it, you'll need to explicitly enable it. (#18881)\n- `prometheusreceiver`: All receivers are setting receiver name and version when sending data. This change introduces the same behaviour to the prometheus receiver. (#20902)\n- `splunkhecexporter`: Adding an option in splunkhecexporter to enable heartbeat. A heartbeat is a metadata event about the current environment and build information. If heartbeat is enabled, splunkhecexporter will periodically send heartbeat to the destination in given time intervals from configurations. (#20225)\n- `vcenterreceiver`: Adds VM CPU usage and utilization metrics (#20895)\n- `awss3exporter`: Add implementation of AWS S3 exporter (#2835)\n\n### 🧰 Bug fixes 🧰\n\n- `servicegraphprocessor`: Only create client virtual nodes when server spans are orphans (#19764)\n- `datadogexporter`: Re-add support for span links (span links are added as metadata to the converted span), which were erroneously removed from previous release. (#20923)\n- `datadogexporter`: Fix issue in hostname detection. (#20923)\n  In the latest release, feature gate (exporter.datadog.hostname.preview) was graduated to Stable. The behaviour was set to the behaviour of the feature gate disabled, instead of enabled. The behaviour is now set to the behaviour of the feature gate enabled.\n- `azuremonitorexporter`: Ensure that metric attributes are exported to Azure Monitor (#19407)\n- `pkg/stanza`: fix eventData format for Windows events (#20547)\n- `fluentforwardreceiver`: Fixed performance issue. (#20721)\n- `receiver/k8scluster`: Use newer v2 HorizontalPodAutoscaler for Kubernetes 1.26 (#20480)\n  v2beta2 HorizontalPodAutoscaler is no longer available starting in Kubernetes 1.26\n- `pkg/stanza`: fix flaky test (#20877)\n- `pkg/stanza`: Fix issue where recombine operator would never flush. (#20451)\n  1.Make the forceFlushTimeout compare with timeSinceFirstEntry not timeSinceLastEntry 2.set the period of ticker to 1/5 forceFlushTimeout\n- `spanmetricsconnector`: fix spanmetrics connector to support adding exemplar to metric (#20771)\n- `mongodbreceiver`: Fixes scraper error `Unauthorized` by not calling index stats on an internal local MongoDB database. (#21114)\n- `receiver/mongodbatlasreceiver`: Ensure that Process metrics are emitted with only the correct subset of attributes. (#21155)\n- `splunkhecexporter`: Do not send data to a Splunk backend if no data is present in the batch. Previously compressed batches would not correctly detect data was not present in the batch. (#20290)\n- `filelogreceiver`: Fix issue where first few lines of a file could be ignored when another file had recently contained the same beginning. (#20745)\n- `filelogreceiver`: stanza panic when trace_flags is an empty string (#20924)\n- `hostmetricsreceiver/processscraper`: fixing the processmetrics tests to support testing collection in darwin (#19141)\n  Darwin only supports some of the processmetrics + using Cmdline to get the Executable Path, which caused tests to fail.\n- `awsxrayexporter`: Fixed DynamoDB table name from being set as an empty string when reading from attributes (#19204)\n\n## v0.75.0\n\n### 🛑 Breaking changes 🛑\n\n- `datadogexporter`: Graduate exporter.datadog.hostname.preview feature gate to Stable. (#20286)\n- `pkg/ottl`: Add typed getter for `pcommon.map` and update related functions to use it. (#19781)\n  Using the impacted functions, such as `keep_keys` or `replace_all_patterns`, without a `pcommon.map` will now result in an error. Only pass these function paths that result in a `pcommon.map` or set `ErrorMode` to `IgnoreError`.\n- `pkg/ottl`: Updates `ConvertCase`, `ParseJSON`, `Split`, and `Substring` to use `StringGetter` (#19137)\n  Affected components: `transformprocessor`, `filterprocessor`, `routingprocessor`.  It is HIGHLY recommended to use each component's `error_mode` configuration option to handle errors returned by these functions. \n  \n- `pkg/ottl`: Adds new StringLikeGetter for converting values to string for use. (#19782)\n  Concat now converts more types to string instead of ignoring them.  IsMatch now converts []byte to string using `hex.EncodeToString(v)`.\n\n### 🚩 Deprecations 🚩\n\n- `datadogexporter`: Deprecate `metrics::histograms::send_count_sum_metrics` in favor of `metrics::histograms::send_aggregation_metrics`. (#20285)\n  Toggling `metrics::histograms::send_count_sum_metrics` will now send .min and .max metrics when available.\n  \n\n### 🚀 New components 🚀\n\n- `awss3exporter`: Add new AWS S3 exporter. (#9979)\n- `servicegraphconnector`: Add servicegraph connector to the build. (#20452)\n\n### 💡 Enhancements 💡\n\n- `clickhouseexporter`: Insert instrumentation scope name and version to SpanAttributes column in traces table (#17408)\n- `stanza`: Enhancement pkg/stanza/flatten to support resource and attributes (#20448)\n- `azuredataexplorerexporter`: Migrate stablity to beta. All the dependent libraries have moved to beta. (#19161)\n- `awsecscontainermetricsreceiver`: Add ServiceName from task metadata endpoint (#19728)\n- `mdatagen`: Warnings can now be specified in metadata.yaml to be included in the generated status table. (#20242)\n- `coralogixexporter`: Change coralogixexporter to default to gzip compression for logs and traces (#20337)\n- `datadogexporter`: Adds support for span links (span links are added as metadata to the converted span). (#20286)\n- `mdatagen`: Do not print \"Supported pipeline types\" in the generated status for extensions (#20236)\n- `filereceiver`: Update file receiver to be able to replay metrics in time. (#14638)\n- `googlecloudspannerreceiver`: adding table size statistics as metrics (#18689)\n- `processscraper`: Introduced `mute_process_exe_error` and `mute_process_io_error` flags to allow scraping of all processes on Linux machines. (#18923)\n- `attributesprocessor, resourceprocessor`: Add feature gate to support using SHA2-256 instead of SHA-1 for hashing (#4759, #5576)\n  enable switching to use SHA-2 256 with the feature gate `coreinternal.attraction.hash.sha256`\n- `translator/loki`: Normalize label names so they follow the Prometheus label names standard (#14113)\n  Loki doesn't support label names containing dots. |\n  Users had to convert dot-separated attributes into underscore-separated attributes before promoting them to Loki labels. |\n  From now on users can drop relabeling from their configuration. All dots in label names will be replaced with underscores automatically before sending request to Loki.\n  \n- `mongodbatlasreceiver`: Add support to collect organization events. (#19449, #20308)\n- `datadogexporter`: Send .min and .max metrics for delta OTLP Histograms and Exponential Histograms when `metrics::histograms::send_aggregation_metrics` is enabled. (#20285)\n- `receiver/purefareceiver`: Add missing code snippet that validate the config file (#14886)\n- `servicegraphprocessor`: Making cache and expire loop time configurable (#19639)\n  add new config items(cache_loop, store_expiration_loop)\n  \n- `servicegraphprocessor`: Making peer attributes of virtual node building configurable (#20428)\n  add new config items(virtual_node_peer_attributes: [db.name, rpc.service]) in Config:\n- `solacereceiver`: Updated solacereceiver to handle new features of Solace PubSub+ 10.4.x (#20349)\n- `sqlserverreceiver`: Adds support to collect metrics from a SQL Server that has a named instance. (#19140, #20247)\n- `logicmonitorexporter`: adds support for traces. (#19646)\n- `elasticsearchexporter`: Support Persistent queue for Elasticsearch exporter. (#19424)\n\n### 🧰 Bug fixes 🧰\n\n- `coralogixexporter`: Correctly declare mutation capability in factory for all signal exporter. (#20292)\n- `processor/metricstransform`: Preserve metric description while aggregating labels (#14577)\n- `extension/sigv4authextension`: Don't panic if no credentials provider is set up. (#19796)\n- `clickhouseexporter`: Fix clickhouse exporter default TTL settings. (#20302)\n- `receiver/elasticsearchreceiver`: Fix bug - no nodeStatsMetrics for es version before 7.9 (#19389)\n- `prometheusreceiver`: Update Prometheus dependency and disable newly-failing OpenMetrics compatibility tests (#20270)\n  Prometheus now accepts exemplar data on all metric types, which causes OpenMetrics compatibility tests to fail.\n  This change disables the negative tests relating to exemplar parsing.\n  \n- `processor/k8sattributes`: Fix image name parsing when repository name contains a port number. (#20239)\n- `mongodbatlasreceiver`: Fix issue where default collection interval of 1 minute was too short to collect several metrics. (#18032)\n  Default collection interval is now 3 minutes.\n- `pkg/ottl`: Fix bug where StringGetter was not allowed in a slice as a function param. (#19783)\n- `splunkhecexporter`: Make sure to not return an error if we are over capacity, just return that we cannot accept the event. (#20481)\n- `signalfxexporter`: Fixes undesired default reporting of per-core system.cpu.time for idle states. (#20354)\n\n## v0.74.0\n\n### 🛑 Breaking changes 🛑\n\n- `k8sattributes`: Remove support of deprecated `pod_association` fields (#19642)\n  Fields are now nested under the pod_association::sources\n- `k8sattributes`: Remove support of deprecated options in extract.metadata field (#19438)\n- `spanmetricsconnector`: Remove deprecated `latency_histogram_buckets` configuration parameter. (#19372)\n  Use the `histogram` configuration section to provide buckets for\n  explicit buckets histogram metrics. \n  \n- `spanmetricsconnector`: Rename `latency` histogram metrics to `duration`. (#19214)\n\n### 🚩 Deprecations 🚩\n\n- `spanmetricsprocessor`: Deprecate the `spanmetrics` processor in favour of the `spanmetrics` connector. (#19736)\n  Please note that the `spanmetrics` connector contains breaking changes related to configurations\n  metrics names and attributes. Please see the `spanmetrics` connector README for more information.  \n  \n\n### 🚀 New components 🚀\n\n- `lokireceiver`: The Loki receiver implements the [Loki push api](https://grafana.com/docs/loki/latest/clients/promtail/#loki-push-api) as specified [here](https://grafana.com/docs/loki/latest/api/#push-log-entries-to-loki) (#18635)\n- `cloudflarereceiver`: Adds support for receiving logs from Cloudflare's LogPush API. (#19201)\n- `webhookeventreceiver`: New component wireframe for webhookeventreceiver (#18101)\n- `spanmetricsconnector`: Add the `spanmetricsconnector` connector to build. (#18760)\n\n### 💡 Enhancements 💡\n\n- `exporter/awsemfexporter`: Add ServiceName/service.name as a valid token replacement in log_stream_name (#16531)\n- `azureeventhubreceiver`: Add the ability to consume Metrics from Azure Diagnostic Settings and convert them into OpenTelemetry Metrics (#18690)\n- `mdatagen`: use metadata to generate status table (#19175)\n  This change updates mdatagen to support auto-generation of the stability level table in the documentation. It also\n  generates a generated_status.go file which contains the stability which is used in the factory of a component.\n  \n- `mdatagen`: Allow mdatagen to support components that do not produce metrics. (#19772)\n  This allows us to define metadata.yaml files for components that don't generate metrics, specifically in support of generating the status table.\n- `countconnector`: Add ability to count by attributes (#19432)\n- `healthcheckextension`: Add `response_body` configuration option that allows specifying a specific response body (#18824)\n- `k8sobjectsreceiver`: Enabling resource version filter on pull mode (#18828)\n- `kubeletstatsreceiver`: Add support for `kubeConfig` auth_type in kubeletstatsreceiver (#17562)\n- `translator/loki`: Loki add raw log export format (#18888)\n- `clickhouseexporter`: Improve clickhouse DSN parsing (#18079)\n  Improve clickhouse DSN parsing to support all possible configuration options and fixes TLS support.\n- `routingprocessor`: Adds new `error_mode` configuration option that allows specifying how errors returned by OTTL statements should be handled. (#19147)\n  If a condition errors when using `ignore` the payload will be routed to the default exporter.\n- `spanmetricsconnector`: Set resource attributes for generated metrics. (#18502)\n- `spanmetricsconnector`: Add optional `seconds` unit support for recording generated duration measurements. (#18698)\n  The `unit` is configurable. The allowed values are `ms` and `s`.\n  The default `unit` is `ms`.\n  \n- `splunkhecreceiver`: Appends query param (index, source, sourcetype, and host) for raw path (#19632)\n- `splunkhecreceiver`: align error message with splunk enterprise to include No Data, Invalid Data Format, Event field is required, and  Event field cannot be blank (#19219)\n- `reciver/statsdreceiver`: Metrics emitted by the statsd receiver are batched by source IP address, available in context. (#15290)\n\n### 🧰 Bug fixes 🧰\n\n- `elasticsearchexporter`: roll back elasticsearch client to v7.17.7 due to incompatibility with older elasticsearch versions (#16310)\n- `sqlqueryreceiver`: Don't panic when a query produces NULLs (#19177)\n- `sentry/sentryexporter`: Fix `environment` configuration not being tracked properly on sentry. (#18694)\n  For sentry export, the environment value should have been attached to transaction.\n- `azuremonitorexporter`: Ensure that attributes for LogRecords are exported to Azure Monitor (#16557)\n- `azuremonitorexporter`: Fix a bug that prevented integer NumberDataPoint metrics to be exported to Azure Monitor. (#18905)\n- `azuremonitorexporter`: Ensure that resource attributes, instrumentation scope and cloud tags are exported to Azure Monitor for logs (#18525)\n- `influxdbexporter`: include histogram min and max in InfluxDB/Telegraf Prometheus schemas (#16714)\n- `influxdbexporter`: Fix exported histograms to be cumulative, Prometheus-style (#19453)\n- `influxdbreceiver`: Test the InfluxDB write APIs with canonical client libraries (#5321)\n- `influxdbreceiver`: Decompose Prometheus-style, cumulative histogram bucket counts (#19453)\n- `receiver/elasticsearch`: Fix \"no such index [_cluster]\" error by adding \"/nodes\" to the ClusterStats request (#17867)\n- `mongodbatlasreceiver`: Fixes issue where filestorageextension usage with the mongodbatlasreceiver would cause a race condition/timeout (#19434)\n- `mysqlreceiver`: Adds a version check to make sure replica query is supported (#19469)\n- `oracledbreceiver`: Update metric description and explain that unlimited translates to -1 (#19752)\n- `signalfxexporter`: use a copy of system.cpu.time and system.paging.operations when splitting the metric, this will allow the user to send the original metric (#19743)\n- `transformprocessor`: Fixes bug where the value for `error_mode` was ignored. (#19629)\n\n## v0.73.0\n\n### 🛑 Breaking changes 🛑\n\n- `googlecloudexporter`: Disable retry helper by default in GCP and GMP exporter configs. (#19203)\n- `k8sattributesprocessor`: Remove `container.id` as default metadata given possible ambiguity matching a container run to a container ID (#16432)\n- `pkg/ottl`: Ability to reference matched capture groups in `replace_pattern()` and `replace_all_patterns()` (#18610)\n  This change affects all processors that use OTTL (i.e. `transformprocessor`, `routingprocessor`, and `filterprocessor`).\n  This is a breaking change in the rare scenario that the `$` character is currently used in a replacement string.\n  To output a literal `$` in a replacement string it must now be escaped with an additional `$`.\n- `resourcedetectionprocessor`: Bump OpenShift semconv version from 1.16.0 to 1.18.0. (#19168)\n  Rename google openshift platform attribute from google_cloud_openshift to gcp_openshift.\n- `spanmetricsconnector`: Drop Prometheus-specific metrics labels sanitization. (#18678)\n  The spanmeterics connector is the OTel component, therefore, we would\n  like to strip Prometheus-specific parts from it. Metric names and attributes\n  conversion to Prometheus conventions should happen in Prometheus components,\n  e.g. Prometheus Remote Write exporter.\n  \n\n### 🚀 New components 🚀\n\n- `filereceiver`: Add basic file reading capabilities to file receiver. Second PR. (#14638)\n  This component is not yet enabled.\n\n### 💡 Enhancements 💡\n\n- `jmxreceiver`: Add the JMX metrics gatherer version 1.23.0-alpha to the supported jars hash list (#18888)\n- `telemetrygen`: Add makefile targets and docker build for telemetrygen (#18835)\n- `internal/filter`: Adds new `filterottl` package that enables filtering/matching using OTTL conditions. (#18930)\n- `pulsarexporter`: Expose in configuration all Pulsar producer options (#19182)\n- `receiver/splunkhec`: Adds sharedcomponent to Splunk HEC Receiver (#18734)\n- `resourcedetectionprocessor`: Add support for detecting AWS Lambda resources. (#17584)\n- `awscloudwatchlogsexporter`: Add the ability to export raw log to cloud watch (#18758)\n  Add emf and raw log support for aws cloudwatch exporter.\n- `awsemfexporter`: The AWS EMF exporter now supports the additional configuration flag `retain_initial_value_of_delta_metric`. With this flag active the first value of a metric is not discarded but instead sent to AWS. (#16218)\n- `processor/tailsampling`: adds support for a BooleanAttribute PolicyType (#17545)\n  enables use of boolean attrbiutes in defining tail sampling policies\n- `pkg/stanza`: Add `header_delimiter` option to the `csv_parser`. (#18198)\n- `datadogexporter`: Enable gzip compression for metric payloads submitted by native Datadog client (#17373)\n- `hostmetrics`: Have the hostmetrics receiver file system scraper use more debug messages (#18236)\n  Log a debug message instead of an error if the collector does not have the permissions to access a locked drive on the host. We do not want to log an error message on every poll for this case.\n- `exporter/prometheus`: Produce exemplars for monotonic sum metrics (i.e. counters in Prometheus) when available (#18201)\n  This could be a breaking change if you already have enabled OpenMetrics format for the Prometheus exporter and have enabled exemplar ingestion in your Prometheus scraper.  To ensure names and types are generated correctly according to the OpenMetrics conventions, you should run your collector with `--feature-gates=pkg.translator.prometheus.NormalizeName`\n- `filelogreceiver`: Adds ability to parse a file header and parse it as metadata to decorate log entries. (#18198)\n  This feature must be activated with the `filelog.allowHeaderMetadataParsing` feature gate.\n- `filterprocessor`: Add `error_mode` configuration option that allows specifying how errors from OTTL conditions should be handled. (#19142)\n- `receiver/purefareceiver`: Ensure a clear visualization for hosts scraper from Pure Storage FlashArray API (#14886)\n- `k8sattributesprocessor`: e2e test support log data (#18392)\n- `k8sattributesprocessor`: k8sattributesprocessor e2e tests support metric data type. (#18391)\n- `k8sattributesprocessor`: Default `container.id` to latest instance unless `k8s.container.restart_count` is specified (#16432)\n- `mdatagen`: Turn on the ability to enable/disable resource attributes by embedding MetricsSettings and ResourceAttributesSettings into all scraping receivers as MetricsBuilderConfig (#16373)\n  Currently, the only way to add configurative functionality to mdatagen is by using a bunch of WithResourceAttributesSettings options to the constructor.\n  This PR changes the first argument to the NewMetricsBuilder constructor to be of type MetricsBuilderConfig,\n  which is a new class that wraps both MetricsSettings and ResourceAttributesSettings, and may be (hopefully) easily extended with more\n  configuration in the future.\n  \n- `pkg/ottl`: Add Eval function to Statements (#18915)\n- `Process Metrics for Mac`: Enabling process metrics to be collected for Mac in the hostmetrics receiver (#17863)\n- `servicegraphprocessor`: servicegraph support virtual/peer node (#17196)\n- `tailsamplingprocessor`: Add a max_spans configuration for the span_count policy of tailsamplingprocessor (#18215)\n- `spanmetricsconnector`: Allow optional usage of Exponential Histograms when generating latency metrics. (#18528)\n- `splunkhecexporter`: Allow merging metric events. (#11532)\n- `filelogreceiver`: Support preserving whitespace for log entries (#18242)\n- `awsemfexporter`: Support exporting quantile for summary metrics (#17265)\n- `cmd/telemetrygen`: Initial implementation of `telemetrygen logs` subcommand for exporting log data (#12927)\n- `transformprocessor`: Add error_mode configuration option that allows specifying how the processor should handle errors from statements. (#18693)\n- `resourcedetectionprocessor`: Update Heroku mappings to match specification (#18872)\n- `awsxrayexporter`: Allow additions of special attributes to the list of indexable attributes in the AWS X-Ray exporter when explicitly listed by the user (#19173)\n- `awsxrayexporter`: Reformatted and improved accuracy of data captured in user agent string in the AWS X-Ray exporter (#18264)\n\n### 🧰 Bug fixes 🧰\n\n- `bearertokenauthextension`: Allow bearertokenauthextension to pick updated token from bearertoken file for http requests (#17031)\n- `cumulativetodeltaprocessor`: exclude the first point after a restart in monotonic sums (#17190, #18053)\n- `datadogreceiver`: Fix misuse of span.Type and span.kind meta of dd spans. (#18190)\n- `mongodbatlasreceiver`: Fixes issue where on a failed start we don't try to checkpoint with an unset storage client. (#19191)\n- `fluentforwardreceiver`: Fix issue where the receiver was dropping errors returned by processors (#18860)\n- `filelogreceiver`: Fixed a bug when delete_after_read was enabled partially read files would be deleted on collector shutdown. (#18926)\n- `receiver/jaeger`: Fix translation of span status (#19171)\n- `hostmetricsreceiver`: Fix `process.cpu.utilization` calculation by using individual `CPUUtilizationCalculator` instances per-PID. (#19119)\n  Update `processscraper` to keep a map of PIDs to `CPUUtilizationCalculator`s, rather than using a single instance globally.\n- `filterprocessor`: Fixes issue where errors in the filterprocessor might not be logged (#18862)\n- `pkg/pdatautil`: Fix a potential panic that could occur while hashing nested maps. (#18910)\n- `receiver_creator`: No longer attempt to add observer target to `endpoint` if underlying receiver config doesn't support it. (#7381)\n  Also adds backticked expansion support for more config forms\n- `transformprocessor`: Fixes a bug where the transformprocessor's errors failed to be logged. (#18859)\n- `prometheusreceiver`: Validate that histograms include the inf bucket (#9384)\n\n## v0.72.0\n\n### 🛑 Breaking changes 🛑\n\n- `fluentbitextension`: remove deprecated extension (#18505)\n- `all`: Remove go 1.18 support, bump minimum to go 1.19 and add testing for 1.20 (#18436)\n- `pkg/ottl`: switch ErrorMode to be a string instead of an int (#18692)\n- `hostmetricsreceiver`: Remove deprecated process memory metrics (#14327)\n  The metrics `process.memory.physical_usage` and `process.memory.virtual_usage` have been deprecated since v0.64.0.\n  They are now being removed. You should use the following metrics instead: `process.memory.usage`, `process.memory.virtual`.\n  For details, see the [docs](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/v0.71.0/receiver/hostmetricsreceiver#transition-to-process-memory-metric-names-aligned-with-opentelemetry-specification).\n  \n- `promtailreceiver`: Promtail recevier is completely removed from the repository (#18474, #18493)\n  Promtail receiver in its current implementation has a dependency on Loki that leads to a huge amount of |\n  dependencies. It is getting difficult to maintain those dependencies. That's why the decision to |\n  remove promtail receiver was made\n  \n\n### 🚩 Deprecations 🚩\n\n- `jaegerexporter, jaegerthrifthttpexporter`: marking jaeger exporters as deprecated (#18503)\n- `promtailreceiver`: Deprecate promtail receiver (#18474, #18493)\n  Promtail receiver in its current implementation has a dependency on Loki that leads to a huge amount of |\n  dependencies. It is getting difficult to maintain those dependencies. That's why the decision to |\n  deprecate and remove promtail receiver was made\n  \n\n### 🚀 New components 🚀\n\n- `countconnector`: Add count connector to build (#18501)\n- `forwardconnector`: Add forward connector to build (#18501)\n- `servicegraphconnector`: Add preliminary implementation as a connector. (#18389)\n- `spanmetricsconnector`: Add preliminary implementation as a connector. (#18535)\n\n### 💡 Enhancements 💡\n\n- `clickhouseexporter`: Add indexes for attributes on metric tables (#18221)\n  Attributes are used for filtering. Adding indexes for them will speed up queries.\n- `sentry/sentryexporter`: Add `environment` configuration option that allows specifying env for transaction. (#18694)\n- `countconnector`: Add ability to count spans, span events, metrics, data points, and logs, based on ottl conditions. (#18687)\n- `exporter/awscloudwatch`: Flush logs on the exporter shutdown (#18518)\n- `resourcedetectionprocessor`: add host.id to system detector (#18533)\n- `k8sattributesprocessor`: run tests on 4 latest k8s version (#18767)\n- `filelogreceiver`: Added `max_batches` configuration parameter to limit the number of batches processed in a polling interval. (#18476)\n- `filterprocessor`: Add new functions `HasAttrKeyOnDatapoint` and `HasAttrOnDatapoint` to allow existing expr matching logic with OTTL. (#16798)\n- `processor/k8sattribute`: add more test cases for k8sattribute e2e (#18512)\n- `k8sobjectsreceiver`: Ensure that the observed timestamp is set. (#18700)\n- `k8sobjectsreceiver`: Improving watch mode reliability to handle recoverable issue such as API timeouts. (#18078)\n- `k8sattributeprocessor`: Allow using k8s.pod.hostname to refer to pod.spec.hostname (#18494)\n- `translator/loki`: Added default labels `job=service.namespace/service.name` and `instance=service.instance.id` to log record to send to Loki (#18500)\n- `pkg/ottl`: Change typed getters to error on nil (#18735)\n- `pkg/ottl`: Introduce the concept of type-specific Getters that help simplify type assertions in functions. (#18042)\n- `pkg/ottl`: Add `NewStatements` func to enable creation of Statements structs. (#18385)\n- `redactionprocessor`: Add IgnoreList to redaction processor (#18680)\n- `translator/prometheusremotewrite`: Add metric name to error message when invalid (#18292)\n  Exporter prometheusremotewrite doesn't support non-cumulative monotonic, histogram, and summary OTLP metrics.\n  Added metric name to error message when the unsupported metrics get dropped.\n  \n- `spanmetricsprocessor`: Support set namespace for generated metric. (#18679)\n- `awsxrayreceiver`: set `service.name` attribute (#18480)\n- `signalfxexporter`: Add `exclude_properties` config option to filter dimension update property content (#18464)\n- `snowflakereceiver`: updated README.md to include more detailed documentation. (#14754)\n- `splunkhecexporter`: Reconnect when server returns 502/429 errors. (#18281)\n- `pkg/stanza`: Reduced `Converter` memory footprint by condensing the `aggregationLoop` logic into `workerLoop`. (#18411)\n- `telemetrygen`: Implement a simple metric generation command for telemetrygen (#17986)\n\n### 🧰 Bug fixes 🧰\n\n- `coralogixexporter`: fix authentication issue when using coralogixexporter with only metrics or traces (#18096)\n- `cumulativetodeltaprocessor`: Data points with the NoValueRecorded flag set are no longer considered in calculating deltas. (#18766)\n- `awsecscontainermetricsreceiver`: Fix possible sig sev that could happen during component shutdown. (#18736)\n- `clickhouseexporter`: Fix metric inserts results in empty entries (#18226)\n- `exporter/awskinesis`: Restore Kinesis stream validation on the start (#18522)\n- `datadogexporter`: Stop reporting the first cumulative monotonic sum value if the start timestamp of the timeseries matches its timestamp. (#18484)\n- `oidcauthextension`: Fix case-sensitivity of authorization header (#18405)\n- `oracledbreceiver`: record a value of -1 for `oracledb.tablespace_size.limit` if the max tablespace size is not set (#18670)\n- `pkg/ottl`: Fix bug where an empty TelemetrySettings struct could result in a panic during condition checking (#18669)\n- `spanmetrics`: Do not drop metric data points on attributes cache misses. (#18725)\n- `statsdreceiver`: Ensure that the start timestamp and timestamp of successive data points for counters align. (#18470)\n\n## v0.71.0\n\n### 🛑 Breaking changes 🛑\n\n- `clickhouseexporter`: use endpoint instead of raw dsn in configuration. (#8028)\n- `azureeventhubreceiver`: Switch default formatter from \"raw\" to \"azure\". (#16549)\n- `elasticsearchreceiver`: Remove feature gates for index operations and cluster shards count (#14635)\n- `humioexporter`: Remove deprecated humio exporter (#17013)\n- `dockerstatsreceiver`: Removed the deprecated scraper implementation which was toggled by the featuregate `receiver.dockerstats.useScraperV2`. (#18449, #9794)\n- `tracegen`: Removes tracegen tool now that trace functionality has been moved to telemetrygen. (#9597)\n- `extension/jaegerremotesampling`: Remove misleading http endpoint from jaegerremotesampling extension. (#18058)\n\n### 🚩 Deprecations 🚩\n\n- `servicegraphprocessor`: Deprecate unprefix label set (#18268)\n- `signalfxexporter`: Deprecate config `translation_rules` in favor of metrics transform processor (#18218)\n\n### 🚀 New components 🚀\n\n- `haproxyreceiver`: Adds haproxy receiver to the components of the OpenTelemetry collector contrib distribution (#16829)\n- `receiver/purefbreceiver`: Add a new receiver that scrapes metrics using Purestorage FlashBlade API (#17528)\n- `datadog-receiver`: Allows you to ingest traces from DDAPM agents (#1852)\n- `logicmonitorexporter`: Enable Logicmonitor Exporter (#13727)\n- `filereceiver`: A receiver for reading the output of a File Exporter (#14638)\n  This component is not yet enabled.\n- `logicmonitorexporter`: Add implementation for Logicmonitor exporter (#13727)\n- `sshcheckreceiver`: Add sshcheck - a receiver to remotely check SSH servers. (#14312)\n  Check the availability of SSH and SFTP servers.\n- `pkg/stanza`: Remove deprecated `adapter.Convert` and `adapter.ConvertFrom` functions. (#17429)\n\n### 💡 Enhancements 💡\n\n- `headerssetter`: Extend the headers setter extension with header modification actions. (#16581, #7596)\n  Please update configurations to use the action that suits your requirements:\n    - `insert`: Inserts the new header if it does not exist.\n    - `update`: Updates the header value if it exists.\n    - `upsert`: Inserts a header if it does not exist and updates the header\n       if it exists.\n    - `delete`: Deletes the header.\n  The default action is `upsert`, however, in future versions, we'll require this\n  to be explicitly set.\n  \n- `azureeventhubreceiver`: Add Azure Event Hub receiver to contrib components (#18208)\n- `pkg/pdatatest`: Adds more test cases for traces (#18030)\n- `azuremonitorexporter`: Adds metrics exporting (#14915)\n- `datadogreceiver`: Adopting OTel apis for the Start and Stop limits (#18227)\n- `datadogexporter`: Datadog trace exporter will now retry sending usage metrics when it fails (#18238)\n- `datadogexporter`: Run API key validation on Datadog exporter in separate goroutine (#18238)\n- `pkg/stanza/operator/transformer/recombine`: add a new \"max_log_size\" config parameter to limit the max bytes size of the combined field (#17387)\n- `exporter/awsxray`: Adds `aws.xray.annotations` attribute to forward annotation keys from the AWS X-Ray receiver to the AWS X-Ray exporter. (#17550)\n- `googlecloudexporter`: New release of GCP exporter (#18197)\n  \"Various features and bug fixes for the GCP exporter including:\n  * Fix GetClientOptions conflicts with default credentials\n  * Support multi-project quota usage\n  * Include service attributes in logs exporter by default\n  * Use a copy of shared log labels to prevent interference between LogRecords\n  * Bump Cloud Trace libraries to support auto-retry on failures\"\n  \n- `googlemanagedprometheusexporter`: Promote GMP exporter to beta (#18197)\n- `http_forwarder`: Set factory stability level to beta. (#18100)\n- `pkg/pdatatest`: Bring reported errors to a consistent state. (#18041)\n- `signalfxexporter`: Avoid stringify every data point that does not match the filter. (#18274)\n- `influxdbexporter`: update influxdb-observability and influxdbexporter, to better utilize InfluxDB/IOx (#18080)\n- `influxdbreceiver`: routine update to dependency influxdb-observability for influxdbreceiver (#18080)\n- `k8sattributesprocessor`: Add end to end test framework for Kubernetes related components (#15651)\n- `k8sclusterreceiver`: Change internal metric store to use pdata (#18214)\n- `mongodbatlasreceiver`: Adds Events API Logs Support (#18061)\n- `signalfxexporter`: Move config validation to Validate (#18205)\n- `cmd/otelcontribcol`: Change otelcontribcol and oteltestbedcol to use the builder (#11867)\n- `pkg/pdatatest`: Ensure all pdata fields are checked. (#17865)\n- `pkg/pdatatest`: Do not ignore timestamps implicitly, provide explicit options for that. (#17865)\n- `haproxyreceiver`: Promote haproxy receiver to alpha (#18022)\n- `splunkhecexporter`: Support exporting log body to raw Splunk HEC endpoint (#18056)\n- `resourcedetectionprocessor/openshift`: Respect tls config when connecting to the api server. (#17961)\n- `signalfxexporter`: Move initialization of the config defaults in Unmarshal. (#18207)\n- `splunkhecexporter`: Expose HTTPClientSettings on splunkhecexporter (#16838)\n- `awsemfexporter`: Instead of supply metric metadata and label for aws calculator, supply with aws metric key which consists of metric metadata and label (#17207)\n- `datadogreceiver`: Adopting new Datadog Agent API levels (#18227)\n\n### 🧰 Bug fixes 🧰\n\n- `clickhouseexporter`: Fix StartTime is not inserted for Gauge and Counter (#18220)\n- `awscloudwatchreceiver`: Fixes issue where limit per discovery request could be configured to exceed API limitations. (#18293)\n  The request now always sets a limit of 50\n  \n- `cumulativetodeltaprocessor`: exclude the first point even in monotonic metrics (#17190, #18053)\n- `datadogexporter`: Fix a nil dereferencing bug on http response (#18099)\n- `prometheusreceiver`: Fix bug in prometheus receiver that panics if no configuration is given. (#16538)\n- `datadogexporter`: Fixed a bug where using multiple Datadog exporters with different API keys in separate pipelines could result in traces ending up in the wrong account. (#18233)\n- `receiver/splunkhec`: Return 400 status code when nested indextime fields are present (#17308)\n- `exporter/loki`: Do not retry on 4xx status code (excluding 429), as these are permanent errors (#18059)\n- `mezmoexporter`: No longer require a specific path.  This will allow for compatibility with both log analysis and pipeline. (#18011)\n- `servicegraphprocessor`: Fix cache cleanup in servicegraph proccesor to also purge stale series (#16262)\n- `snmpreceiver`: Set StartTimestamp to scraper start time. (#17984)\n- `snowflakereceiver`: added doc.go containing pragma for mdatagen (#17978)\n- `spanmetricsprocessor`: Fix a flaky test caused by a race condition between WaitGroup completion and observed logs being written and flushed. (#18014)\n- `splunkhecexporter`: Flatten nested attribute map before sending it to splunk as indexed fields. (#17308)\n- `exporter/datadog`: Fix bug where ddtags are not set correctly when logs are batched. (#17398)\n- `googlemanagedprometheusexporter` Fixed broken export on target_info and scope_info metrics for GMP. (#18468)\n\n## v0.70.0\n\n### 🛑 Breaking changes 🛑\n\n- `dockerstatsreceiver`: Transition the receiver.dockerstats.useScraperV2 featuregate to stable (#17509, #9794)\n- `exporter/azuredataexplorer`: Changed the type of `Config.ApplicationKey` to `configopaque.String`. (#17273)\n- `exporter/azuremonitor`: Changed the type of `Config.InstrumentationKey` to `configopaque.String`. (#17273)\n- `exporter/coralogix`: Changed the type of `Config.PrivateKey` to `configopaque.String`. (#17273)\n- `exporter/elasticsearch`: Changed the types of the `Config.{Password,APIKey}` fields to `configopaque.String`. (#17273)\n- `exporter/influxdb`: Changed the types of the `Config.Token` and `Config.V1Compatibility.Password` fields to `configopaque.String`. (#17273)\n- `exporter/instana`: Changed the type of `Config.AgentKey` to `configopaque.String`. (#17273)\n- `exporter/logicmonitor`: Changed the type of `Config.APIToken.AccessKey` to `configopaque.String`. (#17273)\n- `exporter/logzio`: Changed the type of `Config.Token` to `configopaque.String`. (#17273)\n- `exporter/mezmo`: Changed the type of `Config.IngestKey` to `configopaque.String`. (#17273)\n- `exporter/pulsar`: Changed the types of the `Config.Authentication.Token.Token` and `Config.Authentication.Athenz.PrivateKey` fields to `configopaque.String`. (#17273)\n- `exporter/sapm`: Changed the type of `Config.AccessToken` to `configopaque.String`. (#17273)\n- `exporter/tencentcloudlogservice`: Changed the type of `Config.SecretKey` to `configopaque.String`. (#17273)\n- `exporter/alibabacloudlogservice`: Changed the type of `Config.AccessKeySecret` to `configopaque.String`. (#17273)\n- `extension/basicauth`: Change `Config.Password` to use type `configopaque.String`. (#17273)\n- `extension/bearertokenauth`: Change `config.BearerToken` to use `configopaque.String` type. (#17273)\n- `extension/oauth2clientauth`: Change `Config.ClientSecret` to use the `configopaque.String` type. (#17273)\n- `pkg/ottl`: Change signatures of ottl and all context Parsers to accept a list of Options. (#13759)\n- `pkg/translator/prometheusremotewrite`: Remove deprecated in `0.45` `MetricsToPRW` function. (#17446)\n- `spanmetricsprocessor`: Emits all metrics (whose dimension keys are cached) every configured duration (#15688, #15687, #16024)\n\n### 🚩 Deprecations 🚩\n\n- `tracegen`: Deprecates tracegen, functionality has been moved to telemetrygen traces (#9597)\n\n### 💡 Enhancements 💡\n\n- `haproxyreceiver`: Add new metrics to the haproxyreceiver (#16829)\n- `jmxreceiver`: Add the JMX metrics gatherer version 1.22.0-alpha to the supported jars hash list (#17831)\n- `mongodbreceiver`: Add mongodb health/status metrics (#17021)\n- `mdatagen`: Adds ability to enable/disable resource attributes in output and sets all existing resource attributes to enabled by default. (#16373)\n  We may change NewMetricBuilder in the future from taking in ResourceMetrics to taking in a MetricsBuildingConfiguration,\n  but for now changing the settings requires a call to WithResourceAttributeSettings.\n  \n- `internal/comparetest`: add support of traces for comparetest (#17414)\n- `awsxrayexporter`: Add support to string resource attributes of type slice so that it is possible to set those resource attributes using the `OTEL_RESOURCE_ATTRIBUTES` environment variable. Strings are converted to string slices of size 1.\n (#17503)\n- `internal/comparetest`: Add support for all metric types (#17538)\n- `coralogixexporter`: improve coralogix exporter performance (#17268)\n  improves coralogix exporter to send batched telemetry data to the backend\n- `internal/comparetest`: Do not ignore order of any slices by default, use an options for that. (#17551)\n- `mysqlreceiver`: add mysql.commands metric with supprot for delete, insert, select, update (#14138)\n- `exporter/dynatrace`: Provide more logs on the results of metrics submissions (#15248)\n- `prometheusremotewriteexporter`: Add support for converting OTLP Exponential Histograms to Prometheus Native Histograms (#16207)\n- `pkg/pdatautil`: Export comparetest and pdatautil modules under github.com/open-telemetry/opentelemetry-collector-contrib/pkg (#17873)\n- `clickhouseexporter`: export metrics to clickhouse (#16478)\n- `mongodbatlasreceiver`: Adds `mongodbatlas.project.name` and `mongodbatlas.org.id` as polled alerts resource attributes (#17513)\n- `filelogreceiver`: Add `delete_after_read` setting and associated `filelog.allowFileDeletion` feature gate. (#16314)\n  If enabled, files will be consumed and then immediately deleted.\n- `datadogprocessor`: Now that the Datadog processor is part of the official contrib distribution, it has been moved to the beta stability level. (#17862)\n- `kafkareceiver`: Prevent offset commit failures and connection issues by ensuring that sessions are quickly completed after consumer group rebalances. (#17312)\n- `lokiexporter`: Added QueueSettings validation into Config Validate method (#7841)\n- `telemetrygen`: Moves tracegen functionality to the telemetrygen traces subcommand, as well as the existing Github actions (#9597)\n- `pkg/ottl`: Add new `cache` path to all contexts which can be used as temporary cache during complex transformations (#16994)\n- `pkg/pdatatest`: Metric support compare exemplar (#17580)\n- `processor/probabilisticsampler`: Implement the FNV hash library for the probabilistic sampler. (#16456)\n- `redisreceiver`: Add scraper shutdown with redis client close function to avoid redis client connection pool leaks (#17491)\n- `resourcedetectionprocessor`: add openshift support (#15694)\n- `snowflakereceiver`: added scraper and factory to snowflakereceiver (#14754)\n- `internal/comparetest`: traces support IgnoreResourceAttributeValue compare option (#17588)\n- `processor/transform`: Add substring function. (#17038)\n- `processor/groupbyattr`: Improve performance by using map hashes for resource grouping (#17527)\n- `windowseventlogreceiver`: Support sending the raw XML of the event (#17858)\n\n### 🧰 Bug fixes 🧰\n\n- `receiver/purefareceiver`: Updating documentation to include required configuration fields. (#14886)\n- `clickhousexporter`: Clickhouse string type cast function of insert flow changed because of missing span values. (#17834)\n- `prometheusremotewriteexporter`: Export `_created` metric for Summary, Histogram and Monotonic Sum metric points if `StartTimeUnixNano` is set. (#17412, #12426)\n  The export of tbe `_created` metric is configurable in the Prometheus remote write exporter. It is disabled by default.\n- `clickhouseexporter`: Fix \"no such host\" error when the DSN hostname contains the database name (#16476)\n- `oracledbreceiver`: the resource attribute `oracledb.instance.name` now captures the database name. (#17850)\n- `signalfxexporter`: Make sure the metadata updater is tied to the exporter itself, so it can tack on the exporter lifecycle. (#17976)\n- `mdatagen`: Fixing templateFS to work on windows systems (#17576)\n  This fix will allow the command to work as a static binary without needing reference to the templates on disk.\n  \n- `pkg/ottl`: Fix issue where IsMatch returned an error if the target val was nil (#17572)\n  - Affected components\n    - `filterprocessor`\n    - `routingprocessor`\n    - `transformprocessor`\n  \n- `batchperresourceattr`: Optimize batch processor attribute and don't reset the caller's instance, instead make a copy of the original resource attributes (#17835)\n- `receiver/prometheusreceiver`: Use `_created` metrics, if present, to set `StartTimeUnixNano` for Sum, Histogram and Summary metrics. (#12428)\n  If the `_created` metric was present in the Histogram, Summary or Counter\n  metric family, only then its values is used to set `StartTimeUnixNano` on the\n  relevant OTLP metric and dropped afterwards. Otherwise, it is converted to the\n  monotonic OTLP Sum metric.\n  This behaviour is disabled by default. Use the `receiver.prometheusreceiver.UseCreatedMetric`\n  to enable it.\n  \n- `exporter/prometheusremotewriteexporter`: Export exemplars for the Monotonic Sum metric. (#17573)\n- `windowseventlogreceiver`: Fix panic that can occur when event is larger than current buffer size. (#17879)\n- `windowseventlogreceiver`: Fixed a panic that could create an empty buffer due to incorrect use of unsafe pointers in syscall. (#17878)\n  Fixed a potential panic due to a syscall indicating a that the event buffer should resize to 0. The next used of that resized buffer would result in an index out of bounds panic.\n  \n  Also, added a safety check for buffer resize cases that if the syscall indicates it needs the buffer size to be 0, an error will be returned.\n  \n\n## v0.69.0\n\n### 🛑 Breaking changes 🛑\n\n- `apachereceiver`: Remove feature gates that enable sending server name and port as resource attributes. (#14791)\n- `elasticsearchreceiver`: change feature gates for cluster health and index operations to beta (#14635)\n- `resourcedetectionprocessor`: Remove deprecated gke/gce detectors, use gcp instead. (#10348)\n- `extension/asapauth`: Change `Config.PrivateKey` to use the `configopaque.String` opaque type. (#17316)\n- `processor/resourcedetectionprocessor`: Change `Config.Token` to use `configopaque.String` opaque type. (#17314)\n- `googlecloudexporter`: Graduate exporter.googlecloud.OTLPDirect feature-gate to GA, and remove legacy exporter. (#17192)\n- `exporter/datadog`: Change `Config.API.Key` to use `configopaque.String` opaque type. (#17296)\n- `transformprocessor`: Remove deprecated config options.  Use `[trace|metric|log]_statements` instead. (#16773)\n\n### 🚩 Deprecations 🚩\n\n- `mysqlreceiver`: remove mysql.commands metric (#14138)\n- `hostmetricsreceiver`: Disable deprecated process memory metrics (#14327)\n  The metrics `process.memory.physical_usage` and `process.memory.virtual_usage` are now disabled by default and will be removed in v0.72.0.\n  As a replacement, the following metrics are now enabled by default: `process.memory.usage`, `process.memory.virtual`.\n  For details, see the [docs](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/v0.68.0/receiver/hostmetricsreceiver#transition-to-process-memory-metric-names-aligned-with-opentelemetry-specification).\n\n\n### 💡 Enhancements 💡\n\n- `receiver/elasticsearch`: Add node version as a resource attribute (#16847)\n- `hostmetricsreceiver`: Add a new optional metric `process.disk.operations` to the `process` scraper of the `hostmetrics` receiver. (#14084)\n- `signalfxexporter`: Use configopaque for access_token field (#17294)\n- `datadogexporter`: Update datadogexporter metrics export to use datadog-api-client-go instead of Zorkian by default (#16776)\n  This is guarded by feature gate and can be disabled by adding CLI flag --feature-gates=-exporter.datadogexporter.metricexportnativeclient\n- `internal/comparetest`: add golden functions ReadLogs, WriteLogs, CompareLogs (#10896)\n- `haproxyreceiver`: Adds a new socket interface and CSV reader for haproxy stats (#16829)\n- `resourcedetectionprocessor`: Add support to detect Heroku resources (#16833)\n- `logstransformprocessor`: Lets the logs transform processor directly pass messags to next consumer, avoiding the timing issues it previously exhibited. (#16604, #15378, #9761)\n- `mdatagen`: Add ability to specify additional warnings in metadata.yaml (#17180)\n- `signalfxexporter`: Add all HTTP client settings to the SignalFx exporter configuration (#16807)\n- `snowflakereceiver`: added client to snowflakereceiver (#14754)\n- `snowflakereceiver`: added config to snowflakereceiver (#14754)\n- `splunkhecexporter`: Use configopaque for token field (#17295)\n- `xrayexporter`: Add Cloud Watch log group names from xray exporter config (#16939)\n- `receiver/purefareceiver`: Add a relabel config for important default label names on FlashArray endpoints (#14886)\n\n### 🧰 Bug fixes 🧰\n\n- `carbonreceiver`: Create the carbon receiver server when the `Start` method is called, and only close it if created. (#17404)\n- `pkg/stanza`: Fix issue where glob could match directories (#16995)\n- `kafkareceiver`: fix support of Kafka consumer offset autocommit config (#17374)\n- `pkg/stanza`: Fix support of include/exclude patterns with \"\\\" separators on Windows. (#14754)\n- `awsemfexporter`: Ensure that the config.logger is not nil to avoid segfaults (#9978)\n- `statsdreceiver`: Fix the statsdreceiver initialization to only create a server when `Start` is called. (#17402)\n- `receiver/splunkhec`: Map HEC key fields to resource attributes correctly. (#13997)\n- `otlpjsonfilereceiver`: Disregard empty resource logs, metrics or traces when reading from files. (#12603)\n- `receiver/purefareceiver`: Set an explicit reload interval for all scrapers. (#16992)\n- `servicegraphprocessor`: fix servicegraphprocessor concurrent map read and write (#16850)\n- `filelogreceiver`: Truncate log entry if it is longer than `max_log_size` (#16487)\n- `cmd/metadata`: Ensure template files are downloaded as part of the `go get` and embeded into the application (#17442)\n\n## v0.68.0\n\n### 🛑 Breaking changes 🛑\n\n- `splunkhecreceiver`: Delete the `path` key which is no longer in use and has been deprecated since September 2021. (#16999)\n- `pkg/ottl`: Enforce functions used as a value to start with an uppercase letter and the statement's invocation to start with a lowercase letter. (#16718)\n\n### 🚩 Deprecations 🚩\n\n- `humioexporter`: Humio now known as LogScale beginning with version 1.68 supports OTLP using HTTP and no longer requires a product specific exporter. (#17013)\n\n### 🚀 New components 🚀\n\n- `haproxyreceiver`: A receiver scraping metrics from the HAProxy stats command. (#16829)\n- `processor/datadogprocessor`: The Datadog Processor is used to compute pre-sampling APM Stats. (#15689)\n  Use it to get full visibility into APM Stats in conjunction with the Collector's tail sampling processors.\n\n### 💡 Enhancements 💡\n\n- `jmxreceiver`: Add the JMX metrics gatherer version 1.21.0-alpha to the supported jars hash list (#17064)\n- `hostmetricsreceiver`: Add a new optional metric `process.memory.utilization` to the metrics scraped by the `process` scraper of the `hostmetrics` receiver. (#14084)\n- `mysqlreceiver`: add mysql.replica.time_behind_source and mysql.replica.sql_delay metrics (#14138)\n- `elasticsearchreceiver`: Add additional node metrics around request cache and process stats (#16095)\n- `datadogexporter`: Added support for consuming Datadog APM Stats as OTLP Metrics (usually generated by the datadogprocessor). (#16853)\n- `googlecloudspannerreceiver`: Support for p50, p95 and p99 percentile latencies for queries and transactions. (#16429)\n- `exporter/loki`: Added `InstrumentationScope` to log object (#16485)\n- `exporter/loki`: Allow nested attributes to be used in labels (#16475)\n- `mongodbreceiver`: Add mongodb metrics for operation latency and replication. (#16848)\n- `oracledbreceiver`: Set OracleDB receiver as alpha, from in development. (#16843)\n- `snowflakereceiver`: added metrics to snowflakereceiver (#14754)\n  generated w/ mdatagen\n- `pkg/ottl`: Add substring Converter, returns a substring from the given start index to the specified length. (#17038)\n\n### 🧰 Bug fixes 🧰\n\n- `k8sobjects`: Fix empty `event.name` attribute when using watch mode (#16542)\n- `logzioexporter`: Implemented `GetLevel` method for `go-hclog` logger (#17009)\n- `oracledbreceiver`: Remove duplicate method to create default config. (#16997)\n- `postgresqlreceiver`: Fix issue where WAL stats query was incorrectly coalescing intervals. (#16769)\n- `splunkhecexporter`: Fix data race when gzip compression is enabled (#17083)\n  Removed gzip writer pool and create a new one when needed.\n- `splunkhecexporter`: Fix isssue where splunkhec exporter always returns over capacity error when compression is enabled and MaxContentLength is 0 (#17035)\n\n## v0.67.0\n\n### 🛑 Breaking changes 🛑\n\n- `apachereceiver`: turn on by default feature gates for server name and port resource attributes (#14791)\n- `cumulativetodeltaprocessor`: Remove histogram feature gate. (#16720)\n- `mysqlreceiver`: rename mysql.commands metric to mysql.prepared_statements (#14138)\n  According to the documentation, the `Com_stmt_xxx` is related to prepared statements\n  ref: https://dev.mysql.com/doc/refman/8.0/en/server-status-variables.html\n\n- `mysqlreceiver`: rename mysql.commands metric to mysql.prepared_statements (#14138)\n  Disable the `receiver.mysqlreceiver.renameCommands` feature gate to temporarily revert this change.\n- `dockerstatsreceiver`: Enable the `receiver.dockerstats.useScraperV2` feature gate by default. (#16381, #9794)\n  See the README for information on how to migrate.\n  The featuregate can be disabled, but it will be removed in a future release.\n\n- `coralogixexporter`: remove old jaeger based tracing client (#7931)\n- `splunkhecexporter`: Remove all use of the name attribute from logs as it is deprecated. (#16611)\n\n### 🚩 Deprecations 🚩\n\n- `servicegraphprocessor`: use prefix to distinguish dimensions from different span kind (#16002)\n  The metrics label converts from dimensions specifying in the config will have a prefix to mark where are from.\n  The `client_` prefix relates to the dimensions coming from spans with `SPAN_KIND_CLIENT`, and the `server_` prefix relates to the\n  dimensions coming from spans with `SPAN_KIND_SERVER`. The old dimensions will be removed in the next release.\n\n\n### 🚀 New components 🚀\n\n- `receiver/promtailreceiver`: Add a new receiver that scrapes logs using Promtail client (#14632)\n- `receiver/purefareceiver`: Add a new receiver that scrapes metrics using Purestorage FlashArray API (#14886)\n- `logicmonitorexporter`: New exporter for exporting traces and logs to Logicmonitor Platform (#13727)\n\n### 💡 Enhancements 💡\n\n- `splunkhecexporter`: Add HEC health check before sending the data to Splunk (#16479)\n- `jmxreceiver`: Add the JMX metrics gatherer version 1.20.1-alpha to the supported jars hash list (#16437)\n- `hostmetricsreceiver`: Add a new optional metric `process.cpu.utilization` to the `process` scraper of the `hostmetrics` receiver. (#14084)\n- `azureeventhubreceiver`: adds alternate log formatter that maps Azure log fields into OpenTelemetry attributes (#16283)\n- `mysqlreceiver`: add mysql.connection.count metric (#14138)\n- `elasticsearchreceiver`: add scraping metrics on cluster level (#14635)\n  The receiver now emits jvm and cache eviction metrics on cluster level scraped from new endpoint /_cluster/stats.\n- `influxdbexporter`: Add support for exporting to InfluxDB v1.X API (#16042)\n- `vcenterreceiver`: Added `vcenter.vm.memory.ssdswapped` and `vcenter.vm.memory.swapped` metrics. (#16727)\n- `filelogreceiver`: Promote component to Beta status (#15355)\n- `probabilisticsamplerprocessor`: Add support for probabilistic sampling of logs (#9117)\n- `cmd/mdatagen`: Add support for `resource_attributes::enum` field (#16464)\n  `resource_attributes::enum` values in metadata.yaml are now properly supported in metrics builder developer interface.\n\n- `cmd/mdatagen`: Improve generated documentation (#16556, #16563)\n- `cmd/mdatagen`: Add a metadata.yaml option to specify a warning that will be shown in case if metric is enabled. (#16536)\n- `kafkaexporter`: Allows for custom marshalers to be added in future releases (#14514)\n- `oracledbreceiver`: Add oracledbreceiver implementation (config, scraper, db client) (#16043)\n- `filterprocessor`: Adapt ottl configuration to same BoolExpr, remove duplicate code (#16446)\n- `pkg/ottl`: Updates the IsMatch function to convert bools, ints, and floats to strings before matching. (#16503)\n- `pkg/ottl`: Add new `merge` function to OTTL, which allows merging maps. (#16461)\n- `pkg/ottl`: Add ability to negate conditions with the `not` keyword (#16553)\n- `pkg/ottl`: Add new `ParseJSON` function that can convert a json string into `pcommon.Map`. (#16444)\n- `internal/filter`: Change filter interface to be compatible with ottl (#16443)\n- `receiver/awscontainerinsightreceiver`: Polish up awscontainerinsightreceiver README (#16378)\n- `pkg/translator/loki`: Remove loki dependency, copy files from logproto (#16822)\n  Files copied from github.com/grafana/loki/pkg/logproto to remove unnecessary dependencies.\n  In logproto.pb.go I had to remove few types Query[Request|Response] and SampleQuery[Request|Response]\n  and the gRPC service that uses them, because they depend on another loki package stats.\n\n- `snmpreceiver`: Set component status to alpha (#16454)\n- `solacereceiver`: Added baggage unmarshalling support (introduced in Solace PubSub+ Event Broker 10.2.1) (#16570)\n- `solacereceiver`: Added configurable retry interval for flow control scenarios (#16570)\n- `cmd/otelcontribcol`: Split cmd/otelcontribcol into a separate module, extract testbed in a separate module (#16715)\n- `transformprocessor`: Add the `merge_maps` and `ParseJSON` functions. (#16551)\n- `pkg/stanza`: Upgrade version of doublestar from v3 to v4 (#16528)\n- `configschema`: add yaml generation command (#15231)\n\n### 🧰 Bug fixes 🧰\n\n- `exporter/azuredataexplorerexporter`: Makes timestamp precision to nanos, updated azure-kusto-go to 0.9.2 (#16546)\n- `cumulativetodeltaprocessor`: Updates histogram conversion logic to correctly remove Min and Max when a histogram is converted. (#16520)\n- `datadogexporter`: Doesn't append duplicate ddtags on each log submission leading to 414 API errors. (#16380)\n- `exporter/dynatrace`: Make sure the original metrics are not mutated (#16506)\n- `elasticsearchreceiver`: fix the set of operations for which the data is fetched on index-level (#14635)\n- `filterexpr`: Fixed filterexpr Matcher.MatchMetric to be thread-safe (#13573)\n- `fileexporter`: Fix nil pointer in `fileexporter` when reusing configuration for multiple telemetry signals or pipelines. (#16733)\n- `vcenterreceiver`: vcenter.vm.memory.ballooned is taken from vm.Summary.QuickStats.BalloonedMemory that is expressed MiBy, not By. (#16728)\n- `servicegraphprocessor`: Fixes the number of bucket counts. (#16000)\n- `prometheusexporter`: Make sure the exporter doesn't mutate metrics (#16499, #16572)\n- `datadogexporter`: Suppress logs exporter payload dump to avoid filelogreceiver escape loop (#16380)\n- `headerssetter`: Do not require the secure transport for the headers setter extension. (#16508)\n- `exporterconfig`: The exporter config options should be HTTPS endpoint URL only (#14323)\n- `pkg/translator/loki`: fix loki.resource.labels not working as expected (#15386)\n- `cmd/mdatagen`: Rename metadata.yaml attribute field from `value` to `name_override` (#16561)\n- `exporter/awsemfexporter`: Consider metric data type while grouping metrics (#16512)\n- `exporter/awsemfexporter`: Export fields of MetricDescriptor to enable decoding (#16566)\n- `awskinesis`: Fixed configuration issues not being correctly used. (#16259)\n  -| - Fixed applying region to the kinesis exporter\n- `pkg/ottl`: Add support for lists to be used as Getter values (#16320)\n- `prometheusreceiver`: Fix prometheus receiver panic on shutdown (#16469)\n- `exporter/instana`: Make sure the original traces are not mutated (#16505)\n- `routingprocessor`: Fix bug in routing processor that prevented collector from starting if `from_attribute` is not provided with `OTTL` routing statements. (#16555)\n- `tailsamplingprocessor`: When dealing with traces that have already been evaluated, use the final decision instead of trying using the individual decisions by the policies. (#14760)\n- `processor/transform`: Fix issue where collector would panic under certain conditions if the transformprocessor was configured to transform span events. (#16622)\n- `zipkinreceiver`: Fix zipkinreceiver panic on shutdown (#16471)\n\n## v0.66.0\n\n### 💡 Enhancements 💡\n\n- `hostmetricsreceiver`: Add a new optional metric `process.signals_pending` to the metrics scraped by the `process` scraper of the `hostmetrics` receiver. (#14084)\n- `splunkhecreceiver`: Add a healthcheck endpoint as part of the splunkhecreceiver. Just returns 200 for now if the receiver is running. (#15367)\n- `filterprocessor`: Add ability to filter spans, span events, metrics, datapoints, and logs via OTTL conditions (#16369)\n- `googlecloudspannerreceiver`: Configurably mask the PII in lock stats metrics. (#16343)\n- `interna/coreinternal`: Split internal/coreinternal/processor into a separate internal/filter module (#16410)\n\n### 🧰 Bug fixes 🧰\n\n- Fixes missed dependency updates in v0.65.0\n\n## v0.65.0\n\n### 🛑 Breaking changes 🛑\n\n- `mongodbreceiver`: Drop support for versions of MongoDB prior to 4.0 (#16182)\n- `pkg/ottl`: Rename `ottldatapoints` to `ottldatapoint` (#16245)\n- `pkg/ottl`: Rename `ottllogs` to `ottllog` (#16242)\n- `pkg/ottl`: Renames `ottltraces` to `ottlspan` (#16241)\n- `redisreceiver`: Support more metric label values for redis.cpu.time (#14943)\n\n### 💡 Enhancements 💡\n\n- `exporter/loki`: Automatic mapping beetwen `LogRecord.SeverityNumber` to `LogRecord.Attributes[\"level\"]` (#14313)\n- `jmxreceiver`: Add the JMX metrics gatherer version 1.20.0-alpha to the supported jars hash list (#16356)\n- `mongodbreceiver`: Add additional metrics for mongodb locks (#13661)\n  Add additional metrics for locks.acquire_count, locks.acquire_wait_count, locks.deadlock_count, locks.time_acquiring_micros\n\n- `elasticsearchreceiver`: add jvm heap percentage usage metric (#14635)\n- `elasticsearchreceiver`: add missing data points for operation count and operation time (#14635)\n- `elasticsearchreceiver`: add segment memory metric on node level (#14635)\n- `elasticsearchreceiver`: Add cluster health metrics for two more shards types (#14635)\n- `elasticsearchreceiver`: add document count metrics on index level (#14635)\n- `elasticsearchreceiver`: add fielddata memory size metrics on index level (#14635)\n- `elasticsearchreceiver`: Add query cache metrics on index level (#14635)\n- `exporter/awsxrayexporter`: Favour semantic convention attributes for DynamoDB table name and messaging url when translating OTel data into X-Ray AWS data. (#16075)\n- `azuremonitorexporter`: Support span and exception events (#16260)\n- `datadogexporter`: Change log level for host metadata (#14186)\n- `azureeventhubreceiver`: Mark the Azure Event Hub receiver as alpha. (#12786)\n- `pkg/ottl`: Add ability to perform basic (+, -, *, and /) arithmetic operations on ints and floats.  Paths and Functions that return ints/floats are allowed. (#15711)\n  Affected components\n  - routingprocessor\n  - transformprocessor\n\n- `pkg/ottl`: Add support for setting Maps in Values.  This enables Contexts to set map values for attributes. (#16352)\n- `prometheusreceiver`: Trim type's and unit's suffixes from metric name as per otel specs. (#8950)\n  Can be enabled by the featuregate `pkg.translator.prometheus.NormalizeName`\n- `pkg/ottl`: Remove duplicate parse IDs code, avoid coreinternal dependency (#16393)\n  The \"[trace|span]_id_string\" func returns \"000..000\" string for invalid ids.\n- `exporter/signalfxexporter`: Allow user to add a custom CA so the ingest and api clients can verify and communicate with custom TLS servers. (#16250)\n  \"`ingest_tls`\" and \"`api_tls`\" can be used to set the absolute path to the CA file \"`ca_file`\".\n  This is needed when the exporter is pointing to a TLS enabled signalfx receiver or/and TLS enabled http_forwarder\n  and the CA is not in the system cert pool\n\n- `pkg/stanza`: Support to Customize bufio.SplitFunc (#14593)\n- `processor/transform`: Adds new configuration options that allow specifying the OTTL context to use when executing statements. See [Transform Processor README](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/transformprocessor#config) for more details. (#15381)\n  The existing configuration options will be deprecated in a future release.\n\n- `transformprocessor`: Added OTTL function ConvertCase into the Transform Processor (#16083)\n\n### 🧰 Bug fixes 🧰\n\n- `receiver/jaeger`: Fix an error message in thrift HTTP message decoder (#16372)\n- `spanmetricsprocessor`: Register `processor.spanmetrics.PermissiveLabelSanitization` featuregate, which was only defined but not registered. (#16269)\n- `splunkhecexporter`: Apply max content length to compressed HEC content (#13995)\n  The Splunk HEC exporter uses the unzipped content to check the size of the payload to send, instead of the compressed content.\n  The max content length configuration should apply to the zipped content when compression is enabled.\n\n- `receiver/hostmetrics`: Remove \"Deprecated\" label from network metrics (#16227)\n  Replacement of the metrics was rejected some time ago, but the labels were not updated.\n\n- `mongodbatlasreceiver`: Checks host and port before assigning attributes in `poll` mode (#16284)\n- `datadogexporter`: Fixes crash when logging error on logs exporter (#16077)\n- `pkg/ottl`: Fix list argument parsing when using internal arguments (#16298)\n- `pkg/stanza, filelog, journald, windowseventlog`: Fix issue where specifying a non-existent storage extension caused panic during shutdown. (#16212)\n- `pkg/stanza`: Fix severity range unmarshaling (#16339)\n- `splunkhecexporter`: Do not log a warning on mapping empty metrics. (#3549)\n- `exporter/datadog`: Fixes bug to append tags in attributes instead of replacing them, simplifies filelog receiver setup, and adds `otel_source` tag. (#15387)\n- `processor/transform`: Fix issue where the metric context was using datapoint functions. (#16251)\n- `vcenterreceiver`: collect VM may be panic nil pointer. (#16277)\n\n## v0.64.0\n\n### 🛑 Breaking changes 🛑\n\n- `pkg/stanza, filelog, journald, syslog, tcplog, udplog, windowseventlog, logstransform`: Remove ability to configure `converter`. (#15696)\n  The design of the converter is opaque and its behavior may change in the future.\n  Because of this, the `converter` settings are deemed unstable. The actual behavior of the\n  converter remains unchanged, but will always use the former default values.\n\n- `exporter/googlemanagedprometheusexporter`: Moved ClientConfig under MetricConfig, and added an option to change the default metric name prefix for advanced use cases. (#10543)\n- `pkg/ottl`: Update `ExprFunc`, `Set`, and `Get` to all return errors. (#15649)\n- `pkg/ottl`: Change Statement to use `Expr[K]` and `BoolExpr[K]` and for `Statement.Execute` to require `context.Context`. (#15709)\n- `tanzuobservabilityexporter`: Add a new metric exporter config(app_tags_excluded) to exclude application resource attrs(application, service.name, cluster, shard) from the metric tags. Rename the config resource_attributes to resource_attrs_included. Build in-house logic in the tanzuobservability exporter and remove the usage of resourcetotelemetry. (#14733)\n\n### 🚩 Deprecations 🚩\n\n- `hostmetricsreceiver`: Introduce renamed process memory metrics (#14327)\n  This starts the process of phasing out incorrect metric names:\n\n  - `process.memory.physical_usage`\n  - `process.memory.virtual_usage`\n\n  and replacing them with the names adhering to the semantic conventions:\n\n  - `process.memory.usage`\n  - `process.memory.virtual`\n\n  At this stage, the new metrics are added, but they are disabled by default.\n  See the \"Deprecations\" section of the Host Metrics receiver's README for details.\n\n\n### 💡 Enhancements 💡\n\n- `awsemfexporter`: Added a `log_retention` field to the config to specify log retention policy for a Cloudwatch Log Group (#15678)\n- `translator/jaeger`: Add refType as attribute to link when translating Jaeger span references to OTEL. (#14465)\n  The attribute is used to set the proper refType when translating back from OTEL to Jager.\n\n  In the case of a span with multiple parents, which Jaeger supports, all the refType are properly translated.\n\n- `apachereceiver`: add port resource attribute (#14791)\n- `apachereceiver`: Extract server name as resource attribute (#14791)\n  The feature is enabled through a feature gate and will be enabled by default in v0.65.\n- `mysqlreceiver`: add more mysql metrics (#14138)\n  - Add mysql.connection.errors metric (#14723)\n  - Add mysql.mysqlx_connections metric (#14727)\n  - Add mysql.joins metric (#14728)\n  - Add mysql.table_open_cache metric (#14737)\n  - Add mysql queries (all, client and slow) count metrics (#14738)\n  - Add metrics based on events_statements_summary_by_digest table (#14770)\n  - Add mysql.client.network.io metric (#14744)\n\n- `elasticsearchreceiver`: Add metrics related to GET operations (#14635)\n- `elastisearchreceiver`: Add new metrics related to segments, aggregated by all shards (#14635)\n- `elasticsearchreceiver`: add store size metric for index level (#14635)\n- `elasticsearchreceiver`: Add metrics related to merge operations with aggregated for all shards (#14635)\n- `elasticsearchreceiver`: add translog metrics on index level (#14635)\n- `hostmetricsreceiver`: Add new process metrics (#12482)\n  Add `process.context_switches` and `process.open_file_descriptors` as process metrics. They are disabled by default.\n- `metricstransformprocessor`: Add support for scaling histogram metrics (#15690)\n- `datadogexporter`: Use minimum and maximum fields from delta OTLP Histograms and OTLP ExponentialHistograms when available. (#16048)\n- `pkg/ottl`: Add `ConvertCase` OTTL function with `lower`, `upper`, `camel` and `snake` case options. (#15379, #16070, #16083)\n- `pkg/ottl`: Add `parent_span_id.string` accessor. (#16041)\n- `pkg/ottl`: Add new Span Event context to allow for efficient transformation of Span Event telemetry. (#14907)\n- `pkg/stanza, filelog, journald, syslog, tcplog, udplog, windowseventlog, logstransform`: This component does not mutate data, but can be useful as a generic node in complex pipelines. (#15706)\n- `pkg/stanza`: improve performance (#16028)\n- `signalfxexporter`: Allow 2 additional metrics to be included when exporting to SignalFx, k8s.container.cpu_request and k8s.container.memory_request. (#16009)\n- `hostmetricsreceiver`: Added `root_path` config option, allowing the user to specify where the host filesystem is. (#5879, #16026)\n- `snmpreceiver`: adds integration tests for SNMP metric receiver (#13409)\n- `snmpreceiver`: adds scraper for SNMP metric receiver (#13409)\n- `spanmetricsprocessor`: Improve spanmetricsprocessor performance, reuse buffer to calculate key (#16033)\n- `global`: Update gopsutil to 3.22.10 to return Windows partitions, regardless of errors (#14315)\n- `hostmetricsreceiver/filesystem`: Add configuration option to track virtual partitions (#15680)\n\n### 🧰 Bug fixes 🧰\n\n- `clickhouseexporter`: remove unnecessary function in trace table creation SQL (#15679)\n- `elasticsearchexporter`: Fixed nil panic error when setting custom headers in elasticsearch exporter (#16017)\n- `elasticsearchreceiver`: emit missing data points related to segments, aggregated by primary shards (#14635)\n- `zipkinreceiver`: Fix invalid timestamps when using Zipkin V1 receiver (#15720)\n- `kubeletstatsreceiver`: return an error if metadata containerID is empty and log a warning message (#16061)\n  The kubelet apiserver /pod metadata endpoint might not have the containerID set for newly created containers.\n  Mark these datapoints as failed and don't process them. The issue should be resolved on the nexy poll.\n\n\n- `jaegertranslator`: For HTTP status codes in the 4xx range span status MUST be left unset in case of SpanKind.SERVER and MUST be set to Error in case of SpanKind.CLIENT. (#8273)\n- `mezmoexporter`: Fix usage of HTTP client to honor settings (#15246)\n  This change fixes mezmoexporter's usage of the user supplied HTTP client\n  settings. Previously, the settings were ignored for every request.\n\n- `vcenterreceiver`: Print the correct error message if VM fetch fails. (#15682)\n- `vcenterreceiver`: Fix x509 with TLS.InsecureSkipVerify setting (#15701)\n\n## v0.63.0\n\n### 🛑 Breaking changes 🛑\n\n- `processor/cumulativetodelta`: Sets the `processor.cumulativetodeltaprocessor.EnableHistogramSupport` feature gate to enabled by default.  Histograms will be converted by default if they match include rules. (#15288)\n- `pkg/ottl`: Renames accessor for instrumentation scope from `instrumentation_library` to `instrumentation_scope` to match documentation (#14933)\n- `pkg/ottl`: Add lists to the OTTL grammar and change the function signature of `Concat`. (#13391)\n  The following functions have changed:\n  `keep_keys` now has a function signature of `keep_keys(target, keys[])`.\n  `Concat` now has a function signature of `Concat(keys[], delimiter)`.\n\n- `pkg/ottl`: Updates `ParseStatements` to return a `[]*Statement` instead of `[]Statement`. (#14911)\n- `postgresqlreceiver`: Change postgresql.bgwriter.duration data type from int to double (#14725, #14972)\n- `extension/headerssetter`: Remove deprecated `extension/headerssetter` module. (#13774)\n  The `headerssetter` extension was superseded by `headerssetterextension`.\n- `elasticsearchreceiver`: removing direction feature gate (#14955)\n- `hostmetricsreceiver`: remove direction feature gate (#14959)\n- `kubeletstatsreceiver`: remove direction feature gate (#14961)\n- `memcachedreceiver`: removing direction feature gate (#14964)\n- `vcenterreceiver`: removing direction feature gate (#14963)\n- `zookeeperreceiver`: removing direction feature gate (#14962)\n- `exporter/routingprocessor`: Rename OTTL `expression` configuration parameter of the routing table to `statement` to align with the OTTL naming. (#14950)\n- `dockerstatsreceiver`: `container.cpu.usage.system` is no longer a default metric. Added more description for the metric. (#9794, #14558)\n  Change is not breaking unless you are have enabled the featuregate `receiver.dockerstats.useScraperV2` and are using the specified metric.\n- `processor/transform`: Convert the `keep_keys` and `Concat` functions to use list parameters and change the function signature of `Concat`. (#13391)\n  The updated functions now have the following signatures:\n  `keep_keys` now has a function signature of `keep_keys(target, keys[])`.\n  `Concat` now has a function signature of `Concat(keys[], delimiter)`.\n\n\n### 🚩 Deprecations 🚩\n\n- `exporter/influxdb`: change status to beta (#14098)\n- `receiver/influxdb`: change status to beta (#14099)\n\n### 🚀 New components 🚀\n\n- `azureblobreciver`: Add a new component `azureblobreciver` (#8834)\n  Add a new component `azureblobreceiver` that reads logs and traces from Azure Blob Storage\n- `k8sobjectsreceiver`: Add a new k8sobjects receiver to collect(pull/watch) Kubernetes Objects (#14185)\n- `httpcheckreceiver`: New HTTP Check receiver allows users to run synthethic checks from the collector (#10607)\n\n### 💡 Enhancements 💡\n\n- `oracledbreceiver`: Add metrics captured by this receiver (#13939)\n- `hostmetricsreceiver`: Add a new metric `process.paging.faults` to the `process` scraper of the `hostmetrics` receiver. (#14084)\n- `receiver/prometheusreceiver`: Append exemplars to the metrics received by prometheus receiver (#8353)\n  Acknowledge exemplars coming from prometheus receiver and append it to otel format\n- `azureblobreceiver`: Implementation of the component (second PR) (#8834)\n- `azureeventhubreceiver`: Adds implementation of Azure event hub receiver for raw data (#12786)\n- `bearertokenauthextension`: Allow bearertokenauthextension to support custom auth schemes apart from \"Bearer\" (#14771)\n- `clickhouseexporter`: Add support export OTLP traces to ClickHouse (#8028)\n- `mysqlreceiver`: add mysql.opened_resources metric (#14138)\n- `receiver/mysql`: add metrics based on events_statements_summary_by_digest table (#14138)\n- `mysqlreceiver`: add mysql.mysqlx_worker_threads (#14138)\n- `receiver/statsdreceiver`: Add OTLP exponential histogram aggregator support for high-resolution histogram and timing metrics (#5742)\n- `pkg/translator/loki`: Add support for formatting Loki log lines in logfmt format, toggled by providing `loki.format` hint. It can have value `logfmt` or `json`. JSON is default if no format hint is present. (#15351)\n- `exporter/lokiexporter`: Add multi-tenancy support for Loki exporter via `loki.tenant` hint. (#14706)\n- `pkg/translator/loki`: Add support for grouping Loki requests by attribute that is resolved from the `loki.tenant` hint. (#14706)\n- `cmd/mdatagen`: Add ability to see if `enabled` option is overridden in user settings. (#15344)\n- `oracledbreceiver`: Adds DML locks and transaction metrics to capture usage and limits (#13939)\n- `pkg/ottl`: Add new Instrumentation Scope context to allow for efficient transformation of Instrumentation Scope telemetry. (#14892)\n- `pkg/ottl`: Add new Metric context to allow for efficient transformation of metric telemetry. (#14895)\n- `snmpreceiver`: adds SNMP config helper for SNMP Receiver metric scraper (#13409)\n- `snmpreceiver`: adds otel metric helper struct for SNMP metric receiver scraper (#13409)\n- `snmpreceiver`: changes the client of the SNMP metric receiver to only return data in its functions rather than try to process that data (#13409)\n- `snmpreceiver`: changes the config of the SNMP Metric Receiver to have \"`double`\" as an option in place of \"`float`\" (#13409)\n- `solacereceiver`: Updates Solace Receiver with a variety of improvements and fixes for compatibility with Solace PubSub+ Event Broker 10.2.0 (#15244)\n- `syslogreceiver`: Added RFC 6587 Octet Counting and Non-Transparent-Framing support. (#8390)\n- `elasticsearchexporter`: upgrade version of elasticsearch client to 8.4 (#15385)\n- `dockerstatsreceiver`: Log warning when using ScraperV1, and add documentation for migrating from V1 to V2. (#9794, #14968)\n- `windowsperfcountersreceiver`: Retry counter retrieval once, when error indicates possible rollover (#14343)\n\n### 🧰 Bug fixes 🧰\n\n- `servicegraph`: Add servicegraph processor to component list (#14899)\n  Bumps servicegraph stability to alpha\n- `azuremonitorexporter`: Application Insights Severity Level mapping was incorrectly based on SeverityText which was unique for every language/SDK. (#15275)\n  Application Insights Severity Level mapping was incorrectly based on SeverityText which was unique for every language/SDK. The mapping approach has been changed to analyze SeverityNumber, which is supposed to be common across languages/SDKs.\n- `awscloudwatchreceiver`: Fix config validation for some named configurations. (#14952)\n- `exporter/awsxrayexporter`: Fix an issue where the awsxrayexporter would not parse .Net stacktrace correctly. (#14780)\n- `postgresqlreceiver`: Fix issue where WAL lag stats could cause panic (#14972)\n- `prometheusremotewriteexporter`: Fix value of `+Inf` histogram bucket to be equal to total count (#4975)\n- `prometheusreceiver`: Fix metrics being grouped into the same metrics family incorrectly (#13117)\n- `spanmetricsprocessor`: Sets TraceID and SpanID fields in Exemplar type (as per the spec) and removes the use of FilteredAttributes to pass these values around. (#13401)\n- `splunkhecexporter`: Skip `SummaryDataPoint.Sum` and `HistogramDataPoint.Sum` NaN values (#14877)\n- `pkg/winperfcounters`: Fix testing with `-race` flag for winperfcounters package and winperfcounter based receivers (#10145, #10146, #10149, #10150)\n\n## v0.62.0\n\n### 🛑 Breaking changes 🛑\n\n- `pkg/ottl`: Enhance replace_all_patterns functions to take a new parameter that specifies whether the function applies to keys or values. (#12631)\n- `pkg/ottl`: Unexports several types intended only for the package's grammar. (#14599)\n- `pkg/ottl`: Changed Statement to be an interface with an `Execute` function. (#14869)\n- `pkg/ottl`: Rename the `Queries` signal configuration field to `Statements` and remove the `ottlconfig` package. (#14680)\n- `confmap/provider/s3provider`: Rename `s3mapprovider` to a `s3provider` making it consistent with other providers. (#14616)\n- `processor/transform`: Rename the `queries` config key to `statements`. (#14680)\n\n### 🚀 New components 🚀\n\n- `oracledbreceiver`: Add a new Oracle DB receiver component collecting metrics by periodically querying the database. (#13939)\n- `azuredataexplorer`: Adding a new exporter to OpenTelemetry that supports Metrics, Logs and Traces into Azure Data Explorer, a timeseries & analytics offering from Azure (#11830)\n- `awscloudwatchreceiver`: Adds the `awscloudwatchreceiver` in an alpha state (#14449)\n- `snmpreceiver`: adds the snmpreceiver metric receiver (#13409)\n\n### 💡 Enhancements 💡\n\n- `probabilisticsamplerprocessor`: add more mterics to probabilistic sampler for observ. (#13924)\n- `mongodbatlasreceiver`: Safeguard against large amounts of alert emissions. (#14610)\n- `bearertokenauthextension`: support reading tokens from file (#14325)\n- `cumulativetodeltaprocessor`: Reduce memory consumption in cumulativetodeltaprocessor by removing unnecessary storage of metric identities. (#13751)\n- `carbonexporter`: Change carbonexporter to use pdata, remove dependency on opencensus (#14589)\n- `coralogixexporter`: Adds support for mapping application name and subsystem using Resource attributes (#14398)\n- `mysqlreceiver`: add mysql.tmp_resources metric (#14138)\n- `mysqlreceiver`: add mysql.locked_connects metric (#14138)\n- `elasticsearchreceiver`: Add scraping index stats and generate search metrics (#14635)\n- `pkg/telemetryquerylanguage`: Add the Int factory function to the transform processor (#11810)\n- `exporters`: Use `BuildInfo.Command` for identifying the collector in some AWS exporter user agents. (#14719)\n  Some exporters were using a build-time constant definition to change the identity of the collector binary in user agent strings.  These will now use the collector service's `BuildInfo.Command` value.\n- `jaegerexporter`: Adds support for ValueTypeBytes to Jaeger's trace to jaegerproto translator. (#14574)\n- `mongodbatlasreceiver`: Adds capability to retrieve alerts from the API rather than listening (#14121)\n- `pkg/ottl`: Use generics to avoid context cast in getters and funcs. (#14482)\n- `pkg/ottl`: Simplify parser creation logic. (#14601)\n- `pkg/ottl`: Add new Resource context to allow for efficient transformation of resource telemetry. (#14887)\n- `exporter/signalfxexporter/translation`: Drop datapoints that have more than 36 dimensions and log a message when agent is set to debug (#14625)\n  Additionally, the metric and dimension validation failures are now logged in Debug instead of Warn\n- `sigv4authextension`: Have \"sts_region\" default to \"region\" if not provided (#14573)\n- `snmpreceiver`: adds the client for the snmpreceiver (#13409)\n- `snmpreceiver`: adds the full configuration that the SNMP Receiver will use (#13409)\n- `splunkhecreceiver`: Updates Splunk receiver http status codes in order to be compliant with SplunkCloud (#14469)\n- `pkg/stanza`: `readerFactory` and  `Reader` use  `helper.Encoding` directly, no longer depends on `helper.Splitter` (#14593)\n- `pkg/stanza`: `readerFactory` and  `Reader` use  `bufio.SplitFunc` directly, no longer depends on `helper.Splitter` (#14766)\n- `pkg/stanza`: add splitter factory which return a split func (#14766)\n- `exporter/awsxrayexporter`: Change the value of xraysegment.url from `dbConnectionString` to the span name. This makes the XRay segment timeline more informationally useful. (#14342)\n  This change contravenes the AWS documentation for what values should go into this segment field.\n- `pkg/translator/zipkin`: Change zipkin V1 conversion to use pdata. (#14592)\n- `filterexpr`: Prevent the matcher from panicking (#13573)\n\n### 🧰 Bug fixes 🧰\n\n- `clickhouseexporter`: Fix serviceName variable scope (#8028)\n- `exporter/datadogexporter`: Fix an issue where the Datadog system metrics system.memory.{usage,total} would be incorrect in Kubernetes. (#14618)\n- `mysqlreceiver`: Fix sql queries for scraping table and index metrics. (#14138)\n- `fileexporter`: set rotation disabled by default (#14690)\n- `fluentforwardreceiver`: added case to handle uint64 timestamp (#11435)\n- `sqlqueryreceiver`: fix oracle db integration test (#12332)\n- `prometheusreceiver`: changes to use the new scrape_configs endpoint in the target allocator to dynamically pull scrape configuration. (#14597)\n- `saphanareceiver`: Fix incorrect use of units for saphana licenses metrics (#10565)\n- `hostmetricsreceiver`: Allow to continue collecting partition information even if an error is returned (#14315)\n  Log the error and continue if partition information, however incomplete, was provided.\n- `kubeletstatsreceiver`: Fix use network io as network errors bug (#14318)\n\n## v0.61.0\n\n### 🛑 Breaking changes 🛑\n\n- `dockerstatsreceiver`: For V2 scraper implementation, change the defaults from emitting everything to a sensible set of defaults. (#9794, #14093)\n  This is only breaking if you have explicitly enabled the featuregate `receiver.dockerstats.useScraperV2`.\n- `dockerstatsreceiver`: Change 'stats' config key to 'metrics'. (#9794, #14184)\n  Note: this is only breaking for those who have explicitly enabled the featuregate `receiver.dockerstatsd.useScraperV2`.\n- `iisreceiver`: Emit metrics per-site and per-app-pool with new resource attributes. (#14448)\n- `pkg/telemetryquerylanguage`: Unexport `BoolExpressionEvaluator`, `Literal`, `NewGetter`, and `NewFunctionCall`. (#13737)\n- `mongodbatlasreceiver`: Retain actual raw log line as Body. The `raw` attribute is now removed. Use Body instead for the raw log line. (#14178)\n- `mysqlreceiver`: The metrics are now being emitted with a resource attribute marking the endpoint of the database. (#14138)\n- `pkg/ottl`: Rename `ParseQueries` to `ParseStatements` and rename `Query` to `Statement`. (#14444)\n- `jaegerreceiver`: Remove remote sampling endpoint from the Jaeger receiver (#6633)\n- `oteltransformationlanguage`: Renames ottldatapoints to ottldatapoints to better represent how the context is intended to be used. (#14384)\n- `pkg/ottl`: Renames Telemetry Query Language to OpenTelemetry Transformation Language to avoid confusion with an analysis language. (#14150)\n- `pkg/ottl`: Flattens ottlcommon and ottlotel into ottlfuncs. (#14386)\n- `pkg/ottl`: Replaced Logger with TelemetrySettings (#14389)\n\n### 🚩 Deprecations 🚩\n\n- `coralogixexporter`: deprecating jaeger based tracing configuration in favour of OpenTelemetry protocol based one. (#7931)\n  Please remove the `endpoint` field and use the new `traces.endpoint` field with your OpenTelemetry endpoint.\n- `elasticsearchreceiver, hostmetricsreceiver, kubelestatsreceiver, memcachedreceiver, vcenterreceiver, zookeeperreceiver`: Log message to announce `direction` attribute feature gate deprecation (#14129)\n  The change to remove the `direction` attribute has been reverted in the specification. As a result, the following feature gates will be removed in v0.62.0:\n  - `receiver.elasticsearchreceiver.emitMetricsWithDirectionAttribute`\n  - `receiver.elasticsearchreceiver.emitMetricsWithoutDirectionAttribute`\n  - `receiver.hostmetricsreceiver.emitMetricsWithDirectionAttribute`\n  - `receiver.hostmetricsreceiver.emitMetricsWithoutDirectionAttribute`\n  - `receiver.kubelestatsreceiver.emitMetricsWithDirectionAttribute`\n  - `receiver.kubelestatsreceiver.emitMetricsWithoutDirectionAttribute`\n  - `receiver.memcachedreceiver.emitMetricsWithDirectionAttribute`\n  - `receiver.memcachedreceiver.emitMetricsWithoutDirectionAttribute`\n  - `receiver.vcenterreceiver.emitMetricsWithDirectionAttribute`\n  - `receiver.vcenterreceiver.emitMetricsWithoutDirectionAttribute`\n  - `receiver.zookeeperreceiver.emitMetricsWithDirectionAttribute`\n  - `receiver.zookeeperreceiver.emitMetricsWithoutDirectionAttribute`\n- `extensions/headerssetter`: Deprecate the `extensions/headerssetter` module, use `extensions/headerssetterextenions` instead. (#13774)\n\n### 🚀 New components 🚀\n\n- `s3mapprovider`: A new implementation of ConfigMapProvider for Amazon S3 (s3mapprovider) allows OTEL Collector the ability to load configuration for itself by fetching and reading config files stored in Amazon S3. (#12939)\n\n### 💡 Enhancements 💡\n\n- `loki`: Split the conversion OTLP -> Loki into its own package (#13649)\n- `kafkareceiver`: Add direct unmarshaler, inserting Kafka payload bytes as the body of a log record (#13252)\n- `apachereceiver`: The receiver now supports 6 more metrics, more information in the linked issue. (#14095)\n- `datadogexporter`: Add logs support (#2651)\n- `datadogexporter`: The \"hostmetrics\" receiver metrics are now correctly mapped to Datadog system metrics. (#14005)\n- `fileexporter`: support for compressing the telemetry data before exporting. (#13626)\n- `fileexporter`: support for encoding telemetry data using proto marshaler (#13626)\n- `googlecloudspannerreceiver`: Fixed errors when transaction-stats columns are NULL (#14189)\n- `cumulativetodeltaprocessor`: Reduce memory consumption of histograms in cumulativetodeltaprocessor by allocating only a single identity per datapoint. (#13751)\n- `chronyreceiver`: Improved chronyreceiver's context and timeout handling (#14131)\n  Updated chronyreceiver to use `net.Dialer.DialContext` and respect timeouts more closely\n- `filterspan`: Add span kind filtering. (#13612)\n- `mysqlreceiver`: The receiver now scraper 16 new metrics related to io_waits. (#14138)\n- `filelog`, `journald`, `syslog`, `tcplog`, `udplog`, `windowseventlog`: Allow 'parse_to' fields to accept 'attributes' and 'resource' (#14089)\n- `sentryexporter`: Make sentry status more detailed - use HTTP and Grpc codes from tags (#13407)\n- `routingprocessor`: Add support for using OpenTelemetry Transformation Language (OTTL) expressions as routing conditions. (#13158)\n- `transformprocessor`: Add `Split` function, which separates a string by the delimiter and returns an array of substrings. (#11790)\n- `pkg/winperfcounters`: Add counter path to error if scraping fails (#14443)\n\n### 🧰 Bug fixes 🧰\n\n- `awsemfexporter`: Fix regression that causes null dimensions to be appended during dimension roll up. (#14532)\n- `k8sprocessor`: check every association for eventual update (#13119)\n- `sentryexporter`: Omit empty parent span id (#13415)\n- `pkg/ottl`: Replace invalid comparison print statement with a debug log entry (#14467)\n- `servicegraphprocessor`: Fixed metric names to match the specification. (#14187)\n- `hostmetricsreceiver`: On Windows systems, do not fail to start if a performance counter is missing or inaccessible. (#14032)\n- `loki`: Fix converting log resources to loki labels for more than one log record. (#14288)\n- `mongodbatlasreceiver`: Fix timestamp parsing for mongodb 4.2 audit logs (#14168)\n- `mongodbatlasreceiver`: Add missing fields for audit logs (#14177)\n- `mongodbatlasreceiver`: Fix potential infinite loop when scraping audit logs (#14169)\n- `otlpjsonfilereceiver`: logs receive operations should use StartLogsOp/EndLogsOp (#14535)\n- `pkg/translator/prometheus`: do not normalize metric name with colon (#14135)\n\n## v0.60.0\n\n### 🛑 Breaking changes 🛑\n\n- `pkg/stanza`: Change name of ParserConfig.Config to more specific ParserConfig.SeverityConfig (#14126)\n- `pkg/stanza/adapter`: Remove `OperatorConfigs` type, rename `LogReceiverType.DecodeInputConfig` to `LogReceiverType.InputConfig`. (#14078)\n- `postgresqlreceiver`: The receiver will now emit resource attributes via default. (#13811)\n  old behavior can be established by setting the featuregates `receiver.postgresql.emitMetricsWithResourceAttributes` to false and `receiver.postgresql.emitMetricsWithoutResourceAttributes` to true\n\n- `k8sattributesprocessor`: Change the way how `key_regex` setting is handled. After this change, provided expressions are applied to the full length of attribute values. (#9716)\n- `pkg/telemetryquerylanguage`: Add ability to specify attribute keys in the `limit` function that aren't allowed to be dropped (#9734)\n  This breaking change affects the transform processor since we don't have a way to default values in a function call.\n\n### 🚩 Deprecations 🚩\n\n- `exporter/influxdb`: Change status to unmaintained (#14098)\n- `receiver/influxdb`: Change status to unmaintained (#14099)\n\n### 🚀 New components 🚀\n\n- `instanaexporter`: Enable Instana exporter (#13395)\n- `servicegraph`: Add traces processor that builds a map representing the interrelationships between various services in a system (#9232)\n\n### 💡 Enhancements 💡\n\n- `elasticsearchreceiver`: Add additional node metric for cache count (#14027)\n- `pkg/telemetryquerylanguage`: Add `Concat`, which allows concatenating an arbitrary number of strings with a delimiter (#12476)\n- `processor/filter`: Added ability to filter by metric type using expression `MetricType` keyword. (#14107)\n- `elasticsearchreceiver`: Add additional two cluster-level metrics (#13748)\n  Add additional cluster metrics for elasticsearch.cluster.in_flight_fetch & elasticsearch.cluster.pending_tasks.\n\n- `dockerstatsreceiver`: Simplify BlockIO metrics by taking operation out of the metric name and putting it in an attribute. (#9794, #13445)\n- `elasticsearchreceiver`: Added `node.fs.disk.{free,total}` to elasticsearch receiver (#13571)\n- `elasticsearchexporter`: Support sending OpenTelemetry tracing data to Elasticsearch index or data stream. (#12069)\n- `elasticsearchreceiver`: Adds new method Version in the client request to get the elasticsearch version number (#14012)\n- `fileexporter`: Support for rotation of telemetry files (#13626)\n- `processor/filer`: Add support for ExponentialHistogram and Summary metrics (#14116)\n- `receiver/k8scluster`: Moving initialization of k8s client from receiver init to receiver start phase. (#12582)\n- `lokiexporter`: Overhaul of the Loki Exporter, in preparation for native OTLP support at Loki (#12873)\n- `awskinesisexporter`: Upgrading client to use v2 of the AWS SDK (#13898)\n- `prometheusreceiver`: Remove storing pointers to pdata points, allow removing unnecessary pdata points copy. (#13922)\n- `sigv4authextension`: Add more context to credential errors generated by the sigv4auth extension. (#14031)\n- `tailsampling`: Add support for all sampling policies in and & composite policy (#11505)\n- `pkg/telemetryquerylanguage`: Add a Logger interface and allow it to be specified as an argument type in TQL functions. (#9730)\n- `telemetryquerylanguage`: Adds inequality operators `<`, `<=`, `>=`, `>` to TQL. (#12491)\n- `telemetryquerylanguage`: Add the Int factory function. (#11810)\n- `telemetryquerylanguage`: Add split factory function to separate a string by the delimiter, and returns an array of substrings. (#11790)\n- `processor/transform`: Add `Concat`, which allows concatenating an arbitrary number of strings with a delimiter (#12476)\n\n### 🧰 Bug fixes 🧰\n\n- `hostmetricsreceiver`: Set process metrics start time to process create time (#11447)\n- `awsemfexporter`: Properly handle empty dimension set in metric_declarations (#13766)\n- `clickhouseexporter`: cast FlagsStruct into uint32 in ExecContext to fix export failure (#13843)\n- `k8sprocessor`: fix the passthrough mode (#13765)\n  Treating k8s.pod.ip resource attribute in special way, as it is added by passthrough mode\n- `elasticsearchreceiver`: Fix issue where `elasticsearch.os.*` metrics were not being collected (#13983)\n- `elasticsearchreceiver`: Fix issue where `elasticsearch.node.script.*` metrics were not being collected (#13983)\n- `elasticsearchreceiver`: Fix issue where `elasticsearch.node.translog.*` metrics were not being collected (#13983)\n- `elasticsearchreceiver`: Fix issue where `elasticsearch.cluster_state.*` metrics were not being collected (#13930)\n- `elasticsearchreceiver`: Fix issue where `elasticsearch.node.shards.data_set.size` emits 0 value for unsupported version (#14012)\n- `elasticsearchreceiver`: Fix elasticsearch.node.disk.io.read/write metrics from By to KiBy (#13815)\n- `elasticsearchreceiver`: Fix issue where `elasticsearch.indexing_pressure.memory.limit` emits 0 value for unsupported version (#14012)\n- `elasticsearchreceiver`: Fix issue where `elasticsearch.cluster.state_update.time` emits attributes pairs that don't exist (#13984)\n- `awsxrayexporter`: Fixes a bug in the logic for parsing CloudWatch Log Group ARNs (#13702)\n- `loadbalancingexporter`: Fixed the case in loadbalancingexporter where a DNS resolver is defined without an explicit Port. (#10321)\n- `k8sattributesprocessor`: k8sattributesprocessor now correctly adds attributes to new pods that start after the collector (#13619)\n- `tailsamplingprocessor`: Fixes SpanCount sampler not using the correct span count for decision. (#13865)\n- `filelogreceiver`: Fix issue for missing `key_value_parser` operator (#13631)\n- `mongodbatlasreceiver`: fix log parsing for clusters using major version 4.2 (#14008)\n- `chronyreceiver`: When trying to read from socket, the socket type was incorrect (#13862)\n- `postgresqlreceiver`: Uses the postgres databasename when retrieving database inventory information (#13641)\n- `prometheusreceiver/prometheusremotewriteexporter`: Leave the sum unset in histograms without sums, and don't produce _sum metric points for histograms without sums (#7546)\n- `processor/redaction`: Update redaction attributes in case if data sent through the processor more than once, not not ignore them. (#13854)\n- `chloggen`: changelog generation tool moved to https://github.com/open-telemetry/opentelemetry-go-build-tools (#14022)\n- `exporter/AlibabaCloudLogServiceExporter`: Fix issue that promethus occuring error when the resource metric labels contains dot (#3429)\n- `exporter/tanzuobservabilityexporter`: This change causes tanzuobservabilityexporter to depend on 0.10.4 of the\nwavefront-sdk-go library.\n (#13417)\n- `transformprocessor`: Fixes panic of transformprocessor handling Gauge types (#13905)\n- `vcenterreceiver`: Fix incorrect KBy and MBy units, updating them to KiBy and MiBy (#13935)\n\n# v0.59.0\n\n## 🛑 Breaking changes 🛑\n- `elasticsearchreceiver`: Remove direction for metrics. The feature gate: receiver.elasticsearchreceiver.emitMetricsWithoutDirectionAttribute can be set to apply the following (#13258) (#12189)\n  - `elasticsearch` metrics:\n    - `elasticsearch.node.cluster.io` will become:\n      - `elasticsearch.node.cluster.io.received`\n      - `elasticsearch.node.cluster.io.sent`\n- `kubeletstatsreceiver`: Remove direction for metrics. The feature gate: receiver.kubeletstatsreceiver.emitMetricsWithoutDirectionAttribute can be set to apply the following (#12588) (#12164)\n  - `kubeletstats` metrics:\n    - `k8s.node.network.io` will become:\n      - `k8s.node.network.io.transmit`\n      - `k8s.node.network.io.receive`\n    - `k8s.node.network.errors` will become:\n      - `k8s.node.network.errors.transmit`\n      - `k8s.node.network.errors.receive`\n- `processor/metricstransform`: Remove `processor.metricstransformprocessor.UseOTLPDataModel` feature flag. OpenCensus-based implementation is not available anymore.\n (#13405)\n- `exporter/mezmoexporter`: This change removes the hardcoded \"otel\" hostname that was embedded\nin outgoing logs data.\n (#13410)\n  It is replaced by:\n\n    1. Sending to a new collector endpoint that does not require the\n    hostname parameter.\n\n    2. Recognizing the \"host.name\" resource attribute and using that\n    value to fill in log metadata recognized upstream.\n\n    This is a breaking change, and as such will generate a startup\n    error if the exporter is configured to send to an endpoint that\n    does not support this feature.\n- `filelog, journald, otlpjsonfile, syslog, tcplog, udplog, windowseventlog receivers`: Remove `helper.Duration` struct. Configured time values no longer have a default unit of `s` (#13439)\n- `pkg/stanza`: Remove HostIdentifier, HostIdentifierConfig and associated functions (#13396)\n- `filelog, journald, syslog, tcplog, udplog, and windowseventlog receivers`: Fix a bug where original severity text was not preserved. (#13263)\n- `pkg/stanza`: Update function and struct names in keyvalue parser (#13418)\n- `cmd/mdatagen`: Remove old metadata generator (#13374)\n\n### 🚩 Deprecations 🚩\n- `jaegerreceiver`: Add remote sampling deprecation warning (#6633)\n\n### 🚀 New components 🚀\n- `pulsarreceiver`: Add Apache Pulsar receiver (#9796)\n- `instanaexporter`: Add Instana exporter implementation (#13395)\n- `instanaexporter`: Add initial structure of the Instana exporter (#13395)\n\n### 💡 Enhancements 💡\n- `loadbalancingexporter`: Added `interval` and `timeout` to the dns configuration in the loadbalancer exporter (#10199)\n- `pkg/telemetryquerylanguage`: Add `Join`, which allows joining an arbitrary number of strings with a delimiter (#12476)\n- `elasticsearchreceiver`: Add additional metrics (#13115)\n  Add additional metrics for indexing_pressure, published_states, state_queue, ingest, script.\n\n- `hostmetricsreceiver`: Add threads count metric (#12482)\n- `aerospikereceiver`: Add query_count and query_tracked metrics (#13255)\n- `docsgen`: use contrib components, add makefile target (#12639)\n- `dockerstatsreceiver`: Change relevant memory metrics from gauges to sums, so they are aligned with spec recommendations and can be aggregated. (#9794)\n- `pkg/stanza/csv_parser`: Add `ignore_quotes` option that ignores all quoting in fields if true. (#13656)\n- `pkg/telemetryquerylanguage`: Add TQL mappings for `InstrumentationScope.attributes` (#13639)\n- `k8sattributesprocessor`: Add support for discovering Kubernetes CronJob name (#141)\n- `coreinternal`: Move test utilities out of testbed into coreinternal, allow use of these lightweight helpers from other modules. (#5742)\n- `kafkametricsreceiver`: Migrate receiver to the new metrics builder (#7142)\n  This allows users to disable particular metrics in through user settings.\n- `mongodbatlasreceiver`: Add logs retrieval capability (#12347)\n- `mongodbreceiver`: Enhance partial error handling with descriptive metric/attribute messages. (#13367)\n- `filelog, journald, syslog, tcplog, udplog, windowseventlog receivers`: Add ability to set log body when when parsing. (#10274)\n- `filelog, journald, syslog, tcplog, udplog, windowseventlog receivers`: Enhance error message when csv_parser finds unexpected number of fields (#13427)\n- `filelog, journald, syslog, tcplog, udplog, windowseventlog receivers`: Enable debugging operators `stdout` and `file_output` (#13394)\n- `postgresqlreceiver`: Adds background writer metrics (#13327)\n  Adds the following metrics:\n  - postgresql.bgwriter.buffers.allocated\n  - postgresql.bgwriter.buffers.writes\n  - postgresql.bgwriter.checkpoint.count\n  - postgresql.bgwriter.duration\n  - postgresql.bgwriter.maxwritten.count\n\n- `postgresqlreceiver`: Adds more metrics regarding database tables. (#13228)\n  metrics added:\n    postgresql.database.count\n    postgresql.table.count\n    postgresql.table.size\n    postgresql.table.vacuum.count\n\n- `postgresqlreceiver`: Adds WAL and connections metrics (#13399)\n  metrics added\n  - postgresql.replication.data_delay\n  - postgresql.wal.age\n  - postgresql.wal.lag\n  - postgresql.connection.max\n\n- `prometheusreceiver`: allow to query scrape jobs from OpenTelemetryOperators TargetAllocator (#7944)\n- `prometheusremotewrite`: Support customization of target_info metric including the ability to disable it (#12300)\n- `prometheusexporter`: Adds a feature to prometheusexporter that enables it to export exemplars along with histogram metrics. (#5192)\n- `prometheusexporter`: Use HTTPServerSettings in the exporter to leverage inbuilt TLS. (#10851)\n- `receivercreator`: adds the unique EndpointID to generated receiver componentID to prevent collisions (#12670)\n- `spanmetricsprocessor`: The unit of the `latency` metric is now explicitly defined. (#13423)\n- `extension/storage/storagetest`: Add in-memory and file-backed test extensions and clients (#13086)\n- `telemetryquerylanguage`: Avoid copying attributes when filtering on keys in the `keep_keys` TQL function (#4756)\n- `prometheusreceiver`: Remove temporary maps to dedup and remove unuseful labels (#13705)\n\n\n### 🧰 Bug fixes 🧰\n- `processor/metricstransform`: Aggregate cumulative data points with different start time. (#12611)\n- `expvarreceiver`: Fixes an bug where the mSpanSys value was recorded into the mCacheSys metric. (#13171)\n- `extension/filestorage`: Allow putting the compaction temp folder on a different filesystem. (#13449)\n- `prometheusremotewriteexporter`: Handle the case with 0 metrics gracefully. (#10364)\n- `prometheusreceiver`: Fix num data point for metrics recorded in prometheusreceiver (#13705)\n- `loadbalancingexporter`: Fixed a crash if `endpointFor` is called before any endpoints have been discovered (#10110)\n- `prometheusreceiver`: Fix timestamp for histograms and summaries with no Sum (#13705)\n- `exporter/sumologic`: Mark the exporter as mutating. (#13647)\n- `jaegerremotesampling`: Mark as alpha (#13005)\n- `mongodbreceiver`: Adds metric versioning checks to prevent partial errors (#13155)\n- `mongodbreceiver`: Change lpu integration test to use a mongodb 4.4 (#12981)\n- `pkg/translator/prometheus`: do not normalize metric name with multiple underscore (#13322)\n- `prometheusreceiver`: Make the error returned when dropping summary metrics that collide with histograms clearer. (#12976)\n- `prometheusremotewriteexporter`: Don't emit the target_info metric when it would only contain job and instance (#12768)\n- `receiver_creator`: Correct observer instance reference by updating watch_observers use ComponentID instead of just Type (#12801)\n- `vcenterreceiver`: Re-establish sessions when running with particular TLS settings. (#13447)\n\n\n# v0.58.0\n\n## 🛑 Breaking changes 🛑\n- `clickhouseexporter`: update table schema (#8028)\n  1. add ServiceName field as primary key.\n  2. use Map type for attribute, add secondary index.\n\n- `postgresqlreceiver`: Moves metric attributes `table` and `database` to resource attributes. (#12960)\n  This move has been hidden behind a featuregate. Please see https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/receiver/postgresqlreceiver/README.md#feature-gate-configurations for more information transitioning.\n  This affects the following metrics.\n  - postgresql.blocks_read\n  - postgresql.commits\n  - postgresql.db_size\n  - postgresql.backends\n  - postgresql.operations\n  - postgresql.rollbacks\n\n- `all`: Update minimum go version to 1.18 (#12918)\n\n### 🚩 Deprecations 🚩\n- `dotnetdiagnosticsreceiver`: Change status to unmaintained (#12757)\n\n### 🚀 New components 🚀\n- `azureblobreceiver`: Add a new component `azureblobreciver` (#8834)\n  Add a new component `azureblobreceiver` that reads logs and traces from Azure Blob Storage\n- `azureeventhubreceiver`: New component to receive logs from Azure Event Hubs (#12786)\n- `headers_setter`: Add support for setting exporter headers from the upstream requests context (#5733, #7945, #4814)\n\n### 💡 Enhancements 💡\n- `filterprocessor`: Add ability to filter based on logs SeverityText and Body. (#9235)\n- `aerospikereceiver`: Support tls configuration. Add tls and tlsname config items. (#12770)\n- `datadogexporter`: Send host info when sending hostmetadata from datadogexporter (#12944)\n- `jaegerremotesampling`: extend jaegerremotesampling with remote sampling via gRPC (#6694)\n- `filterprocessor`: Add log filtering based on SeverityNumber (#12959)\n- `hostmetricsreceiver`: Add new resource attribute `process.parent_pid`.  The value of the attribute is the parent PID (#12290)\n- `k8sattributesprocessor`: Add support for discovering Kubernetes DaemonSet name and DaemonSet UID\" (#141)\n- `k8sattributesprocessor`: Add support for discovering Kubernetes Job name and Job UID\" (#141)\n- `k8sattributesprocessor`: Add support for discovering Kubernetes ReplicaSet name and ReplicaSet UID (#141)\n- `k8sattributesprocessor`: Add support for discovering Kubernetes StatefulSet name and StatefulSet UID\" (#141)\n- `loadbalancingexporter`: Exporting trace pipelines based on Service name to avoid duplicate label svc + operation in collector hosts. (#12652)\n- `lokiexporter`: Don't retry on 4xx responses (excluding 429) from loki (#12930)\n- `observers`: Adds multiple observer.Notify subscriber support to observer.EndpointWatcher for multiple Endpoint event consumers. (#10830, #11541, #11544)\n- `filelogreceiver`: Process batches consecutively, rather than one per poll interval (#10285)\n- `postgresqlreceiver`: Client refactor to eventually support resource attributes. (#13087)\n- `postgresqlreceiver`: Adds Index Resource Attribute and Metrics Collection. (#13167)\n  This enhancement will only be enabled with the receiver.postgresql.emitMetricsWithResourceAttributes feature gate being enabled.\n- `pkg/translator/signalfx`: report Histogram min/max when present, do not report sum when not present (#13153)\n- `sigv4authextension`: Added separate region for STS for cross region auth (#12736)\n- `solacereceiver`: Adds topic destination as a new attribute to receiver's spans (#12640)\n- `pkg/telemetryquerylanguage`: Add Getter slices to the TQL parser, allowing them to be specified as function parameters. (#12476)\n\n### 🧰 Bug fixes 🧰\n- `aerospikereceiver`: Fix crash when connecting to an Aerospike server with authentication using a config with collect_cluster_metrics == false and no username or password. (#12979)\n- `apachereceiver`: Fix some partial errors not being correctly reported (#13133)\n- `couchdbreceiver`: Fix some partial errors not being correctly reported (#13007)\n- `signalfxreceiver`: log attempts to divide by zero at the debug level (#12969)\n- `mongodbreceiver`: Fix partial scraper errors not being reported (#13108)\n- `mysqlreceiver`: Fix some partial errors not being correctly reported (#13009)\n- `tailsamplingprocessor`: Fixing null pointer exception for span count sampling strategy. (#12745)\n\n\n# v0.57.2\n\n## 🛑 Breaking changes 🛑\n- `healthcheckextension`: Remove deprecated `port` field from config. (#12668)\n- `processor/cumulativetodelta`: Removes the deprecated `metrics` config option.  Use `include`/`exclude` instead. (#12732)\n- `lokiexporter`: Deprecate the `format` option (#12897)\n- `metricstransformprocessor`: Remove deprecated `metric_name` settings option (#12737)\n- `pkg/stanza/fileconsumer`: Unexport several fields that are meant for internal usage only (#12793)\n- `pkg/stanza/fileconsumer`: Rename fileconsumer.Input to fileconsumer.Manager (#12876)\n- `prometheusremotewriteexporter`: Export `target_info` not `target` for resource attributes (#12079)\n- `pkg/translator/signalfx`: Remove no longer necessary prom compatible configuration from `FromTranslator` (#12671)\n- `signalfxexporter`: Remove no longer necessary feature gate for prom compatible metrics (#12671)\n- `zookeeperreceiver`: Remove direction for metrics. The feature gate: receiver.zookeeperreceiver.emitMetricsWithoutDirectionAttribute can be set to apply the following (#12772) (#12184)\n  - `zookeeper` metrics:\n    - `zookeeper.packet.count` will become:\n      - `zookeeper.packet.received.count`\n      - `zookeeper.packet.sent.count`\n\n### 🚀 New components 🚀\n- `chronyreceiver`: This will add in support for measuring tracking data from `chronyd` (#11789)\n\n### 💡 Enhancements 💡\n- `datadogexporter`: Add host metadata tags to metrics on serverless environments (#12486)\n- `observer`: Add observer.Endpoint.ID to Env() (#12751)\n- `aerospikereceiver`: Scrape nodes in parallel when in collect_cluster_metrics mode. (#11563)\n- `coralogixexporter`: Add logs client to coralogixexporter (#12601)\n- `awscontainerinsightreceiver`: Pod Detection changes to support Containerd runtime in K8s (#12638)\n- `dockerstatsreceiver`: Enable a featuregate for the new implementation of scrape. Change the units in the new implementation to align to semantic convention. (#9794)\n  This allows the new implementation of scrape to be used via a featuregate.\n  It also updates the tests, which now test for expected descriptions and units in the new implementation.\n\n- `healthcheckextension`: Use `confighttp.HTTPServerSettings` to allow tls and auth. (#12668)\n- `demo`: Add connection time out for client in examples/demo/client (#12431)\n- `prometheusexporter`: Export target_info metrics with the resource attributes. (#8265)\n- `resourcedetectionprocessor`: update Azure resource detector to save \"name\" from Azure metadata API in azure.vm.name attribute (#12779)\n- `pkg/telemetryquerylanguage`: Adds standard contexts to the module that should be used when interacting with OTLP traces, metrics, and logs. (#12589)\n- `pkg/telemetryquerylanguage`: Adds a set of otel functions to the telemetryquerylanguage module. (#12754)\n- `pkg/telemetryquerylanguage`: Adds a set of common functions to the telemetryquerylanguage module. (#12739)\n- `cumulativetodeltaprocessor`: Cumulative Histogram metrics will now be converted to delta temporality and are no longer skipped. (#12423)\n  This means that consumers who currently rely on Histograms being skipped would need to ensure they are excluded via config.\n- `dockerstatsreceiver`: Initial PR for onboarding dockerstats onto mdatagen scraping. (#9794)\n  Additionally appends the internal docker client to allow options (bug fix).\n- `mongodbreceiver`: Enhance mongodbreceiver by adding new metrics (#12672)\n- `chronyreceiver`: Added internal chrony client (#11789)\n  -| Added an internal client for the receiver with modifications of the upstream client to fit the collector\n- `receivercreator`: add per-receiver `resource_attribute` and validate endpoint type keys on global (#11766)\n- `pkg/translator/signalfx`: Optimize ToMetrics to emit datapoints under the same metric when same name and type. (#12902)\n- `sqlqueryreceiver`: Add static_attributes optional configuration to allow adding attributes/tags to queried metrics. (#11868)\n\n### 🧰 Bug fixes 🧰\n- `spanmetricsprocessor`: Fix panic caused by race condition when accessing span attributes. (#12644)\n- `awsxrayexporter`: Stop dropping exception in aws xray events for non error codes (#12643)\n- `signalfxexporter`: use azure.vm.name instead of host.name to build azure resource id (#12779)\n- `receiver/hostmetrics`: Do not throw scraping errors if conntrack metrics collection is disabled (#12799)\n- `kubeletstatsreceiver`: Fetch metadata from initContainers (#12887)\n- `metricstransformprocessor`: Fix logic in merging exponential histogram. (#12865)\n- `resourcedetectionprocessor`: Add back `host.name` attribute when running on GKE (#12354)\n- `filelogreceiver`: Fix issue where checkpoints could be ignored if `start_at`` was set to `end`` (#12769)\n- `pkg/stanza`: Stop readerFactory from returning an error when creating an unsafeReader (#12766)\n  This bug caused the filelog receiver to crash when the collector was restarted and the logs were being read from the end of the file\n- `prometheusreceiver`: Fix handling of timestamps to prevent reset when a new datapoint is recorded (#12746)\n- `exporter/prometheusremotewrite`: Fix a panic when a histogram does not have any buckets (#12777)\n- `signalfxexporter`: fix invalid response error message (#12654)\n- `skywalkingreceiver`: Add extra link attributes from skywalking ref. (#12651)\n- `spanmetricsprocessor`: Modifies spanmetrics processor to handle negative durations without crashing. Related to open-telemetry/opentelemetry-js-contrib#1013 (#7250)\n  Sets negative durations to count towards the smallest histogram bucket.\n- `splunkhecexporter`: use proper config flags to configure content length of gzip buffers for metrics and traces (#12906)\n\n\n# v0.57.1\n\nThis version has been skipped.\n\n# v0.57.0\n\nThis version has been skipped.\n\n# v0.56.0\n\n## 🛑 Breaking changes 🛑\n- `datadogexporter`: Change default value of `host_metadata::hostname_source` to `config_or_system` (#10424)\n   - This behavior can be reverted by disabling the `exporter.datadog.hostname.preview` feature gate.\n\n- `datadogexporter`: Make automatically detected hostname match the one reported by other Datadog products. (#10424)\n   - This behavior can be reverted by disabling the `exporter.datadog.hostname.preview` feature gate.\n\n- `dynatraceexporter`: Improve serialization of certain Instrument/Temporality pairings (#11828)\n  - Non-monotonic cumulative Sum metrics will be exported as Gauges from now on. Non-monotonic cumulative Sums (usually UpDownCounters) will show the current value instead of a change rate.\n\n- `transformprocessor`: Field `metric.type` is now accessed as an enum/int64 instead of a string. (#10349)\n- `memcachedreceiver`: Remove direction for metrics. The feature gate: receiver.memcachedreceiver.emitMetricsWithoutDirectionAttribute can be set to apply the following (#12404) (#12165)\n  - `memcached` metrics:\n    - `memcached.network` will become:\n      - `memcached.network.sent`\n      - `memcached.network.received`\n- `tracegen`: Moving component under `cmd` for consistency (#12474)\n- `datadogexporter`: Remove deprecated configuration features. (#9099, #9016, #8845, #8783, #8781, #8489, #8396)\n    - [Remove `env` in favor of `deployment.environment` semantic convention](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/9016)\n    - [Remove `version` in favor of `service.version` semantic convention](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/8783)\n    - [Remove `service` in favor of `service.name` semantic convention](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/8781)\n    - [Remove `tags`, `send_metadata` and `use_resource_metadata` in favor of `host_metadata` section](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/9099)\n    - [Remove `metrics::report_quantiles` in favor of `metrics::summaries::mode`](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/8845)\n    - [Remove `metrics::send_monotonic_counter` in favor of `metrics::sums::cumulative_monotonic_mode`](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/8489)\n    - [Remove automatic support for environment variable detection in favor of Collector's `${}` syntax](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/8396)\n    - [Remove `metrics::instrumentation_library_metadata_as_tags` in favor of `metrics::instrumentation_scope_as_tags`](https://github.com/open-telemetry/opentelemetry-collector-contrib/pull/11135)\n\n- `datadogexporter`: Remove deprecated `config` package. (#8373)\n- `observiqexporter`: Remove the observiq exporter (#12406)\n- `vcenterreceiver`: Adds the `vcenter.cluster.name` resource attribute to `vcenter.datastore` metrics (#12357)\n- `vcenterreceiver`: remove metadata declaration and references to uncollected metric `vcenter.vm.cpu.utilization` (#12358)\n- `vcenterreceiver`: Remove direction for metrics. The feature gate: receiver.vcenterreceiver.emitMetricsWithoutDirectionAttribute can be set to apply the following (#11849) (#12185)\n  - `vcenter.host.disk.throughput` will become:\n    - `vcenter.host.disk.throughput.read`\n    - `vcenter.host.disk.throughput.write`\n  - `vcenter.host.disk.latency.avg` will become:\n    - `vcenter.host.disk.latency.avg.read`\n    - `vcenter.host.disk.latency.avg.write`\n  - `vcenter.host.network.throughput` will become:\n    - `vcenter.host.network.throughputt.receive`\n    - `vcenter.host.network.throughput.transmit`\n  - `vcenter.host.network.packet.errors` will become:\n    - `vcenter.host.network.packet.errors.receive`\n    - `vcenter.host.network.packet.errors.transmit`\n  - `vcenter.host.network.packet.count` will become:\n    - `vcenter.host.network.packet.count.receive`\n    - `vcenter.host.network.packet.count.transmit`\n  - `vcenter.vm.disk.latency.avg.read` will become:\n    - `vcenter.vm.disk.latency.avg.read`\n    - `vcenter.vm.disk.latency.avg.write`\n  - `vcenter.vm.network.throughput` will become:\n    - `vcenter.vm.network.throughput.receive`\n    - `vcenter.vm.network.throughput.transmit`\n  - `vcenter.vm.network.packet.count` will become:\n    - `vcenter.vm.network.packet.count.receive`\n    - `vcenter.vm.network.packet.count.transmit`\n\n### 🚩 Deprecations 🚩\n- `hostmetricsreceiver`: Remove direction for disk metrics. The feature gate: receiver.hostmetricsreceiver.emitMetricsWithoutDirectionAttribute can be set to apply the following (#11849) (#11816)\n  - `disk` scraper metrics:\n    - `system.disk.io` will become:\n      - `system.disk.io.read`\n      - `system.disk.io.write`\n    - `system.disk.operations` will become:\n      - `system.disk.operations.read`\n      - `system.disk.operations.write`\n    - `system.disk.operation_time` will become:\n      - `system.disk.operation_time.read`\n      - `system.disk.operation_time.write`\n    - `system.disk.merged` will become:\n      - `system.disk.merged.read`\n      - `system.disk.merged.write`\n\n### 🚀 New components 🚀\n- `telemetryquerylanguage`: Expose the telemetry query language as a package. (#11751)\n- `chronyreceiver`: -| This component is a pure go implementation for capturing data from [chrony](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/system_administrators_guide/ch-configuring_ntp_using_the_chrony_suite) (#11789)\n- `otlpjsonfilereceiver`: Add a new file receiver reading JSON-encoded OTLP data, after [serialization specification](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/protocol/file-exporter.md#json-file-serialization) (#10836)\n- `pulsarexporter`: Add Apache Pulsar exporter (#9795)\n- `solacereceiver`: Add Solace receiver to receive trace data from a Solace PubSub+ Event Broker. (#10572)\n\n### 💡 Enhancements 💡\n- `tanzuobservabilityexporter`: Improve algorithm to translate OTEL delta exponential histograms into tanzu observability histograms (#12173)\n- `internal/scrapertest`: Add sortation functions for scrapertest (#10837)\n- `elasticsearchreceiver`: Add additional metrics (#12176)\n  Add additional metrics for circuit breakers, disk IO r/w, translog, and CPU load.\n\n- `supported platforms`: Add `linux-ppc64le` architecture to cross build tests in CI (#12350)\n- `dockerobserver`: incorporate observer.EndpointsWatcher in preparation of multiple event subscribers and use existing internal event loop watcher (#10830, #11541)\n- `hostmetrics`: Adding connection tracking count and max metrics for linux (#11769)\n- `hostmetricsreceiver`: New config setting scrape_process_delay is used to indicate the minimum amount of time a process must be running before process metrics can be scraped for it. The default value is 0 seconds (\"0s\"). (#8976)\n- `transformprocessor`: Add ability to interact with enums via sybmols. (#10349)\n- `telemetryquerylanguage`: Adds to the grammar the ability to interpret Enums. (#11751)\n- `transformprocessor`: Update the transform processor to use the Telemetry Query Language package (#11751)\n- `transformprocessor`: Add `delete_key` and `delete_matching_keys` which allow deleting keys from maps. (#11823)\n- `receiver/jaeger`: Handle spans with own process (#10186)\n- `k8sobserver`: incorporate observer.EndpointsWatcher in preparation for multiple event subscribers (#10830, #11544)\n- `exporter/loki`: Handle multi-tenant use-cases (#3121)\n- `metricstransformprocessor`: Do not produce empty metrics (#12210)\n- `schemaprocessor`: renaming some internal packages to help improve maintainability (#8495)\n- `groupbytrace`: Promote groupbytrace to beta (#12169)\n- `redisreceiver`: Add redis.version resource attribute. (#12139)\n- `podmanreceiver`: Fetch containers stats one by one and add container image as metric attribute (#9013)\n- `all`: Components now report their stability level. (#12104)\n- `sqlqueryreceiver`: Add Oracle DB Support (#12137)\n- `sqlserverreceiver`: Added tests to validate counter names and a scraper test. (#9374)\n- `templatequerylanguage`: TQL grammar now supports complex `where` expressions with `and`, `or` and parentheses (#10195)\n- `transformprocessor`: Add .string accessor to get hex string for trace_id and span_id (#11555)\n- `pkg/translator/jaeger`: Handle spans with own process (#10186)\n\n### 🧰 Bug fixes 🧰\n- `cmd/chloggen`: Compare changelog to common ancestor with main (#12149)\n- `logstransformprocessor`: Remove support for storage (#12424)\n- `elasticsearchreceiver`: Remove unused `disk_usage_state` attribute from documentation (#12429)\n- `filterlog`: change OR to AND logic for filtering logs - as desribed, and as is done for span filtering (#11439)\n- `lokiexporter`: Wrap quotes around log message (#11827)\n- `tooling`: Fix a bug in the makefile causing `make rpm-package` to fail (#12162)\n- `prometheusexporter`: Fix cumulative condition for the delta-to-cumulative (#4153)\n- `xrayreceiver`: Ensure that the UDP Poller ends the obsreport span it creates with every loop. (#12299)\n  This avoids a memory leak that can happen when spans are created to track received\n  segments but never ended.\n- `googlecloudexporter`: Various bug fixes in parsing OTel logs to GCP LogEntries (#12157)\n- `datadogexporter`: Fix logs related to the source provider. (#12160)\n- `pkg/stanza/fileconsumer`: Fix issue where reader could become stuck on newlines (#10125, #10127, #10128)\n- `receivercreator`: dynamically created receivers log with their `name` field (#16481)\n- `skywalkingreceiver`: Fix skywalking traceid and spanid convertion (#11562)\n- `spanmetricsprocessor`: Fixes the number of explicit bucket counts by removing the manually added \"catch-all\" bucket. (#11784)\n- `spanmetricsprocessor`: Fix concurrency bug causing premature key eviction. (#9018)\n- `spanmetricsprocessor`: Removes a comment that is no longer relevant due to a fix. (#12427)\n- `sqlqueryreceiver`: Metrics did not contain a timestamp. Timestamps are required for a variety of backends, especially prometheus. In order to work with prometheus we must set the metrics timestamp because metrics with the default timestamp (year 1970) will be dropped by prometheus backends. (#12088)\n- `statsdreceiver`: Fixing parsing issue for values on statsd receiver (#12120)\n- `vcenterreceiver`: Fixes calculation of `vcenter.vm.disk.utilization`. (#12342)\n\n\n# v0.55.0\n\n## 🛑 Breaking changes 🛑\n- `datadogexporter`: Remove `Sanitize` method from `Config` struct. (#8373)\n- `datadogexporter`: (Under `exporter.datadog.hostname.preview` feature gate) Remove `docker` hostname detector (#11834)\n- `k8sclusterreceiver`: The `receiver.k8sclusterreceiver.reportCpuMetricsAsDouble` feature gate has been removed (#10838)\n    - If users were disabling this feature gate, they may have to update\n      monitoring for a few Kubernetes cpu metrics. For more details see [feature-gate-configurations](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/v0.54.0/receiver/k8sclusterreceiver#feature-gate-configurations).\n\n- `prometheusexporter`: Automatically rename metrics with units to follow Prometheus naming convention (#8950)\n\n### 🚩 Deprecations 🚩\n- `datadogexporter`: Deprecate `config` package in favor of structs on the `datadogexporter` package. (#8373)\n- `k8sattributesprocessor`: Announcing `pod_association` rules will be deprecated. Use `pod_association.sources` rules instead. This is in order to support metadata enrichment based on multiple attributes. (#4309)\n- `hostmetricsreceiver`: Remove direction for network, paging and process metrics. The feature gates `receiver.hostmetricsreceiver.emitMetricsWithoutDirectionAttribute` and `receiver.hostmetricsreceiver.emitMetricsWithDirectionAttribute` can be used to control the transition (#11815)\n    - `system.network.dropped` will become:\n      - `system.network.dropped.receive`\n      - `system.network.dropped.transmit`\n    - `system.network.errors` will become:\n      - `system.network.errors.receive`\n      - `system.network.errors.transmit`\n    - `system.network.io` will become:\n      - `system.network.io.receive`\n      - `system.network.io.transmit`\n    - `system.network.packets` will become:\n      - `system.network.packets.receive`\n      - `system.network.packets.transmit`\n    - `system.paging.operations` will become:\n      - `system.paging.operations.page_in`\n      - `system.paging.operations.page_out`\n    - `process.disk.io` will become:\n      - `process.disk.io.read`\n      - `process.disk.io.write`\n\n- `logzioexporter`: Announcing `custom_endpoint`, `drain_interval`, `queue_capacity`, `queue_max_length` configuration options will be deprecated in upcoming releases (#10821)\n- `simpleprometheusreceiver`: Announcing `tls_enable`, `tls_config` will be deprecated and use `confighttp.HTTPClientSettings` instead. (#11553)\n\n### 🚀 New components 🚀\n- `sqlqueryreceiver`: Enable the component (#11848)\n\n### 💡 Enhancements 💡\n- `cmd/chloggen`: Update CI process to validate new changelog strategy (#11841)\n- `cmd/chloggen`: Add new tool for conflict-free CHANGELOG.md management (#11539)\n- `coralogixexporter`: Add support for metrics (#11065)\n- `coreinternal/attraction`: Supports pattern for delete and hash attractions (#11886)\n- `filterprocessor`: Add ability to filter `Spans` (#6341)\n- `flinkmetricsreceiver`: Add attribute values to metadata (#11520)\n- `k8sattributesprocessor`: do not ignore hostNetwork pods for enrichment based on non IP attribute (#12073)\n- `logzioexporter`: Add support for logs pipeline and support for exporterhelper (#10821)\n- `pkg/stanza`: Export `pkg/stanza/fileconsumer` package (#11844)\n- `prometheusreceiver`: Add `target_info` labels to resource attributes (#11034)\n- `redisreceiver`: Add more metrics, `redis.maxmemory`, `redis.role`, `redis.cmd.calls` `redis.cmd.usec` (#11090)\n- `sapmexporter`: Add config option to log responses from Splunk APM (#11425)\n- `splunkhecexporter`: Update limits for max_content_length settings (#11550)\n- `sqlqueryreceiver`: Add core functionality (#10867)\n- `tracegen`: Add additional resource attributes (#11145)\n- `transformprocessor`: Add IsMatch factory function.  This function allows regex matching in conditions. (#10903)\n- `transformprocessor`: replace_pattern` and `replace_all_patterns` use regex for pattern matching and replacing text in attributes/metrics (#11125)\n\n### 🧰 Bug fixes 🧰\n- `aerospikereceiver`: Fix issue where namespaces would not be collected (#11465)\n- `aerospikereceiver`: Fix typo in metric name. Ensure namespace transactions are collected (#12085) (#12083)\n- `coralogixexporter`: Fix metrics bearer token (#11831)\n- `datadogexporter`: (Under `exporter.datadog.hostname.preview` feature gate) Make the hostname reported on GKE match the Datadog GCP integration hostname. (#11893)\n- `datadogexporter`: The `traces.span_name_remappings` setting now correctly refers to the OpenTelemetry key to be renamed without any sort of normalization. (#9693)\n- `datadogexporter`: Unify traces exporter behavior with Datadog Agent OTLP traces ingest. (#9693)\n- `filelogreceiver`: Read log lines from lost files first in a poll cycle (#12084)\n- `filestorageextension`: Copy values returned by Get (#11776)\n- `cmd/chloggen`: Fix problem where 'new' command would fail when branch name contained '/' (#11887)\n- `kafkaexporter`: Fixed config.Topic mutation causing **Logs|Metrics|Traces** to default to 1 topic (#11420)\n- `mongodbreceiver`: do not ignore TLS Settings in mongodbreceiver (#12092)\n- `prometheusexporter`: Expose the same metric from different targets correctly (#4986)\n- `redactionprocessor`: Respect allow_all_keys configuration (#11542)\n- `saphanareceiver`: Fix component memory query, add better error handling (#11507)\n- `sapmreceiver`: Fix issue where component instance use in multiple pipelines leads to start failures (#11518)\n- `signalfxreceiver`: Fix issue where component instance use in multiple pipelines leads to start failures (#11513)\n- `splunkhecreceiver`: Fix issue where component instance use in multiple pipelines leads to start failures (#11517)\n\n\n## v0.54.0\n\n## 🛑 Breaking changes 🛑\n\n- `transformprocessor`: `metric.is_monotonic` is now accessed via a bool literal instead of a string. (#10473)\n- `vcenterreceiver`: Changed the attribute `effective` on `vcenter.cluster.host.count` as it will now be reported as a bool rather than a string (#10914)\n\n### 🚩 Deprecations 🚩\n\n- `datadogexporter`: Deprecate `instrumentation_library_metadata_as_tags` (#11135)\n- `datadogexporter`: Deprecate `Sanitize` method of `Config` struct (#8829)\n- `observiqexporter`: Deprecate the observiq exporter (#10977)\n- `honeycombexporter`: Deprecate honeycomb exporter (#10318)\n\n### 🚀 New components 🚀\n\n- `expvarreceiver`: Include `expvarreceiver` in components (#10847)\n- `googlemanagedprometheusexporter` Add the Google Managed Service for Prometheus exporter. (#10840)\n- `googlemanagedprometheusexporter` The Google Managed Service for Prometheus exporter is alpha. (#10925)\n\n### 💡 Enhancements 💡\n\n- `tailsamplingprocessor`: Add trace_state policy (#10852)\n- `mongodbatlasreceiver` Add support for receiving alerts (#10854)\n- `cmd/mdatagen`: Allow attribute values of any types (#9245)\n- `metricstransformprocessor`: Migrate the processor from OC to pdata (#10817)\n  - This behavior can be reverted by disabling the `processor.metricstransformprocessor.UseOTLPDataModel` feature gate.\n- `transformprocessor`: Add byte slice literal to the grammar.  Add new SpanID and TraceID functions that take a byte slice and return a Span/Trace ID. (#10487)\n- `transformprocessor`: Add Summary transform functions. (#11041)\n- `transformprocessor`: Add nil literal to the grammar. (#11150)\n- `elasticsearchreceiver`: Add integration test for elasticsearch receiver (#10165)\n- `tailsamplingprocessor`: New sampler added that allows to sample based on minimum number of spans\n- `datadogexporter`: Some config validation and unmarshaling steps are now done on `Validate` and `Unmarshal` instead of `Sanitize` (#8829)\n- `datadogexporter`: Add `exporter.datadog.hostname.preview` feature flag and related warnings (#10926)\n- `datadogexporter`: Add `instrumentation_scope_metadata_as_tags` instead of `instrumentation_library_metadata_as_tags` in favor of https://github.com/open-telemetry/opentelemetry-proto/releases/tag/v0.15.0 (#11135)\n- `examples`: Add an example for scraping Couchbase metrics (#10894)\n- `filestorageextension`: Add background compaction capability (#9327)\n- `googlecloudpubsubreceiver`: Added new `Endpoint` and `Insecure` connection configuration options. (#10845)\n- `dynatraceexporter`: Provide better estimated summaries for partial histograms. (#11044)\n- `mongodbreceiver`: Add integration test for mongodb receiver (#10864)\n- `mezmoexporter`: add logging for HTTP errors (#10875)\n- `googlecloudexporter`: Support writing to multiple GCP projects by setting the `gcp.project.id` resource attribute, and support service account impersonation (#11051)\n- `k8sattributeprocessor`: Add debug logs to help identify missing attributes (#11060)\n- `jmxreceiver`: Add latest releases of jmx metrics gatherer & wildfly jar to supported jars hash list (#11134)\n- `rabbitmqreceiver`: Add integration test for rabbitmq receiver (#10865)\n- `transformprocessor`: Allow using trace_state with key-value struct (#11029)\n\n### 🧰 Bug fixes 🧰\n\n- `kubletetstatsreceiver`: Bring back `k8s.container.name` attribute (#10848)\n- `transformprocessor`: Fix issue where some metric fields were not working correctly in conditions. (#10473)\n- `transformprocessor`: Fix issue where some trace fields were not working correctly in conditions. (#10471)\n- `transformprocessor`: Fix issue where some log fields were not working correctly in conditions. (#10903)\n- `pkg/stanza`: Skip building fingerprint in case of configuration change (#10485)\n- `windowseventlogreceiver`: Fixed example config in readme (#10971)\n- `pkg/stanza`: Fix access to atomic variable without using atomic package (#11023)\n- `exporter/awsemfexporter:`: Fix dead links in README.md. (#11027)\n- `googlecloudexporter`: Fix (self-obs) point_count metric calculation, concurrent map write panic, and dropped log attributes (#11051)\n- `signalfxexporter`: Event Type is a required field, if not set, set it to `unknown` to prevent signalfx ingest from dropping it (#11121)\n- `prometheusreceiver`: validate that combined metric points (e.g. histograms) have the same timestamp (#9385)\n- `splunkhecexporter`: Fix flaky test when exporting traces (#11418)\n- `mongodbatlasexporter`: Fix mongodbatlas.system.memory.usage.max not being reported (#11126)\n- `receiver/awsxrayreceiver`: Fix null span exception fields causing null pointer exception (#11431)\n- `pkg/stanza`: use ObservedTimestamp to decide if flush log for recombine operator (#11433)\n\n\n## v0.53.0\n\n### 🛑 Breaking changes 🛑\n\n- `jmxreceiver`: Remove properties & groovyscript parameters from JMX Receiver. Add ResourceAttributes & LogLevel parameter to supply some of the removed functionality with reduced attack surface (#9685)\n- `resourcedetectionprocessor`: 'gke' and 'gce' resource detectors are replaced with a single 'gcp' detector (#10347)\n- `pkg/stanza`: Removed reference to deprecated `ClusterName` (#10426)\n- `couchbasereceiver`: Fully removed unimplemented Couchbase receiver (#10482)\n- `hostmetricsreciever`: Fix Load Scraper to normalize 1m, 5m, and 15m averages independently (#8267)\n\n### 🚀 New components 🚀\n\n- `flinkmetricsreceiver`: Add implementation of Flink Metric Receiver (#10121)\n- `windowseventlogreceiver` Added implementation of Windows Event Log Receiver (#9228)\n- `vcenterreceiver`: Add metrics receiver for new vcenterreceiver component (#9224)\n- `googlecloudpubsubreceiver` Activate the Google Cloud Pubsub receiver. (#10580)\n- `googlecloudpubsubexporter` Activate the Google Cloud Pubsub exporter. (#10580)\n- `aerospikereceiver`: Add implementation of Aerospike Metric Receiver. (#9961)\n\n### 💡 Enhancements 💡\n\n- `awsemfexporter`: Add min and max support for histograms (#10577)\n- `tailsamplingprocessor`: Add support for string invert matching to `and` policy (#9553)\n- `mezemoexporter`: Add user agent string to outgoing HTTP requests (#10470)\n- `prometheusreceiver`: Improve performance of metrics builder (#10546)\n- `transformprocessor`: Add functions for conversion of scalar metric types (`gauge_to_sum` and `sum_to_gauge`) (#10255)\n- `dynatraceexporter`: Use min and max when provided in a data point for histograms (#10815)\n- `dynatraceexporter`: Truncate unmarshalable responses to avoid long log lines (#10568)\n- `scrapertest`: Add `IgnoreResourceAttributeValue` option to metric comparison (#10828)\n\n### 🧰 Bug fixes 🧰\n\n- `transformprocessor`: Fix issue where incorrect error was returned if a bad path was passed to a function (#10141)\n- `tanzuobservabilityexporter`: Improve how negative values in exponential histograms are handled. (#10135)\n- `dynatraceexporter`: Ensure min is always less than or equal to mean and max is always greater or equal to mean for histogram estimation. (#10257)\n- `resourcedetectionprocessor`: GCP resource detector now properly detects zone/region on GKE (#10347)\n- `resourcedetectionprocessor`: GCP resource detector no longer fails to detect resource when using workload identity (#10486)\n- `tailsamplingprocessor`: Fix composite sampler with inverse policy\n- `awsprometheusremotewriteexporter`: Fix signing of empty request bodies. (#10578)\n- `sigv4authextension`: Fix signing of empty request bodies. (#10578)\n- `prometheusexporter`: Converting monotonic Delta to Cumulative sums (#9919)\n- `statsdreceiver`: Update the lastIntervalTime for Counter metrics (#9919)\n- `resourcedetectionprocessor`: GCP resource detector now correctly detects region on Google App Engine standard (#10814)\n- `apachereceiver`: Update units to follow semconv (#10587)\n\n## v0.52.0\n\n### 🛑 Breaking changes 🛑\n\n- `jmxreceiver`: Hash the jars provided to JMX Receiver and only allow if they match an approved list (#9687)\n- `jmxreceiver`: Remove properties & groovyscript parameters from JMX Receiver. Add ResourceAttributes & LogLevel parameter to supply some of the removed functionality with reduced attack surface (#9685)\n\n### 🚀 New components 🚀\n\n- `aerospikereceiver`: Add implementation of Aerospike Metrics Receiver (#9961)\n- `bigipreceiver`: Add implementation of F5 Big-IP Metric Receiver (#9680)\n- `expvarreceiver`: Initial work for a receiver designed to scrape `memstats` from Golang applications. (#9747)\n- `mezmoexporter`: Add implementation of Mezmo Log exporter (#9743)\n- `nsxtreceiver`: Added implementation of NSX-T Metric Receiver (#9568)\n- `expvarreceiver`: Add implementation of new receiver. (#10183)\n- `telemetrygen`: Started implementing an upgraded version of `tracegen` generating traces and metrics (#9597)\n\n### 💡 Enhancements 💡\n\n- `transformprocessor`: Add transformation of metrics (#10100)\n- `transformprocessor`: Include transform processor in components (#10134)\n- `kubeletstatsreceiver`: Update receiver to use new Metrics Builder. All emitted metrics remain the same. (#9744)\n- `transformprocessor`: Add new `replace_match` and `replace_all_matches` functions (#10132)\n- `resourcedetectionprocessor`: Add \"cname\" and \"lookup\" hostname sources\n- `jmxreceiver`: Communicate with JMX metrics gatherer subprocess via properties file (#9685)\n- `pkg/stanza`: make multiline tests more like integration tests #10353\n\n### 🧰 Bug fixes 🧰\n\n- `datadogexporter`: add error checks for datadog exporter (#9964)\n- `datadogexporter`: Fix host aliases not being properly sent to the Datadog backend (#9748)\n- `groupbyattrsprocessor`: copied aggregationtemporality when grouping metrics. (#9088)\n- `jaeger`: Update OTLP-Jaeger translation of span events according to the OTel Spec: use `event` log field instead\n  of `message` to represent OTel Span Event Name (#10273)\n- `mongodbreceiver`: Fix issue where receiver startup could hang (#10111)\n- `transformprocessor`: Fix issue where metric.aggregation_temporality and metric.is_monotic were not actually gettable or settable (#10197)\n- `signalfxexporter`: Emit prometheus compatible histogram/summary to signalfx #10299\n  - This behavior can be reverted using the `exporter.signalfxexporter.PrometheusCompatible` featuregate.\n- `podmanreceiver`: Container Stats Error structure (#9397)\n- `pkg/stanza`: pipeline.Operators() will return a consistently ordered list of operators whenever possible (#9761)\n- `tanzuobservabilityexporter`: add  error checks for tanzuobservability exporter (#10188)\n\n## v0.51.0\n\n### 🛑 Breaking changes 🛑\n\n- `datadogexporter`: Replace HistogramMode defined as string with enum. (#9589)\n- `pkg/translator/signalfx`: Change signalfx translator to expose To/From translator structs. (#9740)\n- `transformprocessor`: Add parameter validation to `truncate_all` and `limit` functions.  The `limit` parameter can no longer be negative. (#9783)\n- `newrelicexporter` deleted. Use New Relic [native OTLP ingest](https://docs.newrelic.com/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-setup/) instead. (#9894)\n- `k8sclusterreceiver`: Removing `ClusterName` as per https://github.com/kubernetes/apimachinery/commit/430b920312ca0fa10eca95967764ff08f34083a3. (#9885)\n\n### 🚩 Deprecations 🚩\n\n- `exporter/azuremonitor`: Deprecate use of LogRecord.Name as the log envelope category name. There is no replacement. (#9258)\n- `processor/k8sattributes`: Deprecate use of k8s.cluster.name metadata parameter (obsolete) (#9968)\n\n### 🚀 New components 🚀\n\n- `schemaprocessor`: Starting the initial work to allow from translating from semantic convention to another (#8371)\n- `saphanareceiver`: Added implementation of SAP HANA Metric Receiver (#8827)\n- `logstransformprocessor`: Add implementation of Logs Transform Processor (#9335)\n\n### 💡 Enhancements 💡\n\n- `cmd/mdatagen`: Replace enum attributes values with typed constants (#9683)\n- `elasticsearchreceiver`: Update metrics scope name from `otelcol/elasticsearch`\n  to `otelcol/elasticsearchreceiver` (#9757)\n- `k8sclusterreceiver`: Validate that k8s API supports a resource before setting up a watcher for it (#9523)\n- `internal/stanza`: Add support for `remove` operator (#9524)\n- `k8sattributesprocessor`: Support regex capture groups in tag_name (#9525)\n- `mongoreceiver`: Update metrics scope name from `otelcol/mongodb` to `otelcol/mongodbreceiver` (#9759)\n- `transformprocessor`: Add new `truncation` function to allow truncating string values in maps such as `attributes` or `resource.attributes` (#9546)\n- `datadogexporter`: Add `api.fail_on_invalid_key` to fail fast if api key is invalid (#9426)\n- `transformprocessor`: Add support for functions to validate parameters (#9563)\n- `googlecloudexporter`: Add GCP cloud logging exporter (#9679)\n- `transformprocessor`: Add new `limit` function to allow limiting the number of items in a map, such as the number of attributes in `attributes` or `resource.attributes` (#9552)\n- `processor/attributes`: Support attributes set by server authenticator (#9420)\n- `datadogexporter`: Experimental support for Exponential Histograms with delta aggregation temporality (#8350)\n- `prometheusreceiver`: Support OpenMetrics Info and Stateset metrics (#9378)\n\n### 🧰 Bug fixes 🧰\n\n- `k8sclusterreceiver`: Fix the receiver to work with 1.19 and 1.20 k8s API versions (#9523)\n- `azuremonitorexporter`: Fix log exporter bug related to incorrectly mapping SpanId (#9579)\n- `mysqlreceiver`: Fix attribute values mismatch with its definition (#9688)\n- `opencensusreceiver`: Do not report fatal error if err is server closed (#9559).\n- `sqlserverreceiver`: Fix the receiver to have integer types on metrics where applicable (#9601)\n- `prometheusreceiver`: Fix the memory issue introduced in the 0.49.0 release (#9718)\n- `couchdbreceiver`: Fix issue where the receiver would not respect custom metric settings (#9598)\n- `nginxreceiver`: Include nginxreceiver in components (#9572)\n- `pkg/translator/prometheusremotewrite`: Fix data race when used with other exporters (#9736)\n- `examples/demo`: fix baggage not work in trace demo app. (#9418)\n- `prometheusreceiver`: Handle the condition where `up` metric value is NaN (#9253)\n- `tanzuobservabilityexporter`: Make metrics stanza in config be optional (#9098)\n- `filelogreceiver`: Update Kubernetes examples to fix native OTel logs collection issue where 0 length logs cause errors (#9754)\n- `logstransformprocessor`: Resolve node ordering to fix intermittent failures (#9761)\n- `awsinsightreceiver`: Migrate from `ConfigMapsResourceLock` to `ConfigMapsLeasesResourceLock` as per https://github.com/kubernetes/client-go/commit/276ea3ed979947d7cdd4b3d708862245ddcd8883 (#9885)\n- `filelog`, `journald`, `syslog`, `tcplog`, `udplog`: Add support for []string type for converting log record entries (#9887)\n\n## v0.50.0\n\n### 🛑 Breaking changes 🛑\n\n- `stackdriverexporter`: Remove the stackdriver exporter in favor of the identical googlecloud exporter (#9274)\n- `filelog, journald, syslog, tcplog, udplog`: Remove `preserve_to` field from sub-parsers (#9331)\n- `kafkametricsreceiver`: instrumentation name updated from `otelcol/kafkametrics` to `otelcol/kafkametricsreceiver` (#9406)\n- `kubeletstatsreceiver`: instrumentation name updated from `kubeletstats` to `otelcol/kubeletstatsreceiver` (#9400)\n- `datadogexporter`: Remove `GetHostTags` method from `TagsConfig` struct (#9423)\n- `googlecloudexporter`: Graduate the `exporter.googlecloud.OTLPDirect` feature-gate to Beta.  This includes changes to the configuration structure, and many changes to default behavior. (#9471)\n\n### 🚩 Deprecations 🚩\n\n- `cumulativetodeltaprocessor`: Deprecated `metrics` configuration option in favor of `include` and `exclude` (#8952)\n- `datadogexporter`: Deprecate `metrics::report_quantiles` in favor of `metrics::summaries::mode` (#8846)\n- `datadogexporter`: Deprecate `traces.sample_rate` setting. It was never used anywhere. (#9771)\n\n### 🚀 New components 🚀\n\n- `iisreceiver`: Add implementation of IIS Metric Receiver (#8832)\n- `sqlserverreceiver`: Add implementation of SQL Server Metric Receiver (#8398)\n- `activedirectorydsreceiver`: Add implementation of Active Directory Domain Services metric receiver (#9359)\n- `sqlqueryreceiver`: Add readme, factory, and config to initial implementation of SQL receiver (#9408)\n\n### 💡 Enhancements 💡\n\n- `pkg/translator/prometheusremotewrite`: Allow to disable sanitize metric labels (#8270)\n- `basicauthextension`: Implement `configauth.ClientAuthenticator` so that the extension can also be used as HTTP client basic authenticator.(#8847)\n- `azuremonitorexporter`, `lokiexporter`, `observiqexporter`: Update timestamp processing logic (#9130)\n- `cumulativetodeltaprocessor`: add new include/exclude configuration options with regex support (#8952)\n- `datadogexporter`: Update deprecation messages to reflect new deprecation plan (#9422)\n- `cmd/mdatagen`: Update generated functions to have simple parse function to handle string parsing consistently and limit code duplication across receivers (#7574)\n- `attributesprocessor`: Support filter by severity (#9132)\n- `transformprocessor`: Add transformation of logs (#9368)\n- `datadogexporter`: Add `metrics::summaries::mode` to specify export mode for summaries (#8846)\n- `prometheusreceiver`: Add resource attributes for kubernetes resource discovery labels (#9416)\n\n### 🧰 Bug fixes 🧰\n\n- `fluentforwardreceiver`: Release port on shutdown (#9111)\n- `prometheusexporter`: Prometheus fails to generate logs when prometheus exporter produced a check exception occurs. (#8949)\n- `resourcedetectionprocessor`: Wire docker detector (#9372)\n- `kafkametricsreceiver`: The kafkametricsreceiver was changed to connect to kafka during scrape, rather than startup. If kafka is unavailable the receiver will attempt to connect during subsequent scrapes until succcessful (#8817).\n- `datadogexporter`: Update Kubernetes example manifest to new executable name. (#9425).\n- `riakreceiver`: Fix issue where user configured metric settings were ignored. (#9561)\n- `sqlserverreceiver`: Update `sqlserver.transaction_log.growth.count` and `sqlserver.transaction_log.shrink.count` to be monotonic sums. (#9522)\n\n## v0.49.0\n\n### ⚠️ Warning  ⚠️\n\nThis release contains an issue in\n[Prometheus receiver](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/prometheusreceiver)\ncausing 30% memory consumption increase when there is a lot of target churn. The issue is currently being\ninvestigated and will be fixed in one of the new releases. More details:\nhttps://github.com/open-telemetry/opentelemetry-collector-contrib/issues/9278.\n\n### 🛑 Breaking changes 🛑\n\n- `filelogreceiver`, `journaldreceiver`, `syslogreceiver`, `tcplogreceiver`, `udplogreceiver`:\n  - Updated data model to align with stable logs data model, which includes various breaking changes. (#9139, #8835)\n    - A detailed [Upgrade Guide](https://github.com/open-telemetry/opentelemetry-log-collection/releases/tag/v0.28.0) is available in the log-collection v0.29.0 release notes.\n- `datadogexporter`: Remove `OnlyMetadata` method from `Config` struct (#8980)\n- `datadogexporter`: Remove `GetCensoredKey` method from `APIConfig` struct (#8980)\n- `mongodbatlasreceiver`: Updated to uses newer metric builder which changed some metric and resource attributes (#9093)\n- `dynatraceexporter`: Make `serialization` package `/internal` (#9097)\n- `attributesprocessor`: Remove log names from filters (#9131)\n- `k8sclusterreceiver`: The `receiver.k8sclusterreceiver.reportCpuMetricsAsDouble` feature gate is now enabled by default (#9367)\n  - Users may have to update monitoring for a few Kubernetes cpu metrics, for\n    more details see [feature-gate-configurations](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/v0.54.0/receiver/k8sclusterreceiver#feature-gate-configurations).\n\n### 🚩 Deprecations 🚩\n\n- `datadogexporter`: Deprecate `service` setting in favor of `service.name` semantic convention (#8784)\n- `datadogexporter`: Deprecate `version` setting in favor of `service.version` semantic convention (#8784)\n- `datadogexporter`: Deprecate `env` setting in favor of `deployment.environment` semantic convention (#9017)\n- `datadogexporter`: Deprecate `GetHostTags` method from `TagsConfig` struct (#8975)\n- `datadogexporter`: Deprecate `tags` setting in favor of `host_metadata::tags` (#9100)\n- `datadogexporter`: Deprecate `send_metadata` setting in favor of `host_metadata::enabled` (#9100)\n- `datadogexporter`: Deprecate `use_resource_metadata` setting in favor of `host_metadata::hostname_source` (#9100)\n- `prometheusexecreceiver`: Deprecate prom_exec receiver (#9058)\n- `fluentbitextension`: Deprecate Fluentbit extension (#9062)\n\n### 🚀 New components 🚀\n\n- `riakreceiver`: Riak Metric Receiver (#8548)\n\n### 💡 Enhancements 💡\n- `splunkhecexporter`: Add support for batching traces (#8995)\n- `hostmetricsreceiver`: Migrate Processes scraper to the Metrics builder (#8855)\n- `tanzuobservabilityexporter`: Use resourcetotelemetry helper (#8338)\n- Add `make crosslink` target to ensure replace statements are included in `go.mod` for all transitive dependencies within repository (#8822)\n- `filestorageextension`: Change bbolt DB settings for better performance (#9004)\n- `jaegerremotesamplingextension`: Add local and remote sampling stores (#8818)\n- `attributesprocessor`: Add support to filter on log body (#8996)\n- `prometheusremotewriteexporter`: Translate resource attributes to the target info metric (#8493)\n- `prometheusexporter`: Add `job` and `instance` labels to metrics so they can be scraped with `honor_labels: true` (#9115)\n- `podmanreceiver`: Add API timeout configuration option (#9014)\n- `cmd/mdatagen`: Add `sem_conv_version` field to metadata.yaml that is used to set metrics SchemaURL (#9010)\n- `splunkheceporter`: Add an option to disable log or profiling data (#9065)\n- `windowsperfcountersreceiver`: Move code into separate package for use in other windowsperfcounter receivers (#9108)\n- `datadogexporter`: Add `host_metadata` configuration section to configure host metadata export (#9100)\n- `cmd/mdatagen`: Update documentation generated for attributes to list enumerated values and show the \"value\" that will be visible on metrics when it is different from the attribute key in metadata.yaml (#8983)\n- `routingprocessor`: add option to drop resource attribute used for routing (#8990)\n\n### 🧰 Bug fixes 🧰\n\n- `filestorageextension`: use correct bbolt options for compaction (#9134)\n- `hostmetricsreceiver`: Use cpu times for time delta in cpu.utilization calculation (#8857)\n- `dynatraceexporter`: Remove overly verbose stacktrace from certain logs (#8989)\n- `googlecloudexporter`: fix the `exporter.googlecloud.OTLPDirect` fature-gate, which was not applied when the flag was provided (#9116)\n- `signalfxexporter`: Fix bug to enable timeouts for correlating traces and metrics (#9101)\n- `windowsperfcountersreceiver`: fix exported values being integers instead of doubles (#9138)\n- `prometheusreceiver`: Fix issues with relabelling the `job` and `instance` labels. (#8780)\n- `dynatraceexporter`: Continue processing data points after a serialization error. (#9330)\n\n## v0.48.0\n\n### 💡 Enhancements 💡\n\n- `k8seventsreceiver`: Add Api_version and resource_version (#8539)\n- `datadogexporter`: Add `metrics::sums::cumulative_monotonic_mode` to specify export mode for cumulative monotonic sums (#8490)\n- `dynatraceexporter`: add multi-instance deployment note to README.md (#8848)\n- `resourcedetectionprocessor`: Add attribute allowlist (#8547)\n- `datadogexporter`:  Metrics payload data and Sketches payload data will be logged if collector is started in debug mode (#8929)\n- `cmd/mdatagen`: Add resource attributes definition to metadata.yaml and move `pdata.Metrics` creation to the\n  generated code (#8555)\n\n### 🛑 Breaking changes 🛑\n\n- `windowsperfcountersreceiver`: Added metrics configuration (#8376)\n- `lokiexporter`: Remove deprecated LogRecord.name field (#8951)\n- `splunkhecexporter`: Remove deprecated LogRecord.name field (#8951)\n\n### 🚩 Deprecations 🚩\n\n- `datadogexporter`: Deprecate `OnlyMetadata` method from `Config` struct (#8359)\n- `datadogexporter`: Deprecate `GetCensoredKey` method from `APIConfig` struct (#8830)\n- `datadogexporter`: Deprecate `metrics::send_monotonic_counter` in favor of `metrics::sums::cumulative_monotonic_mode` (#8490)\n\n### 🚀 New components 🚀\n\n- `sigv4authextension`: Enable component (#8518)\n\n## v0.47.0\n\n### 💡 Enhancements 💡\n\n- `googlecloudexporter`: Add Validate method in config (#8559)\n- `attributesprocessor`: Add convert action (#7930)\n- `attributesprocessor`: Add metric support (#8111)\n- `prometheusremotewriteexporter`: Write-Ahead Log support enabled (#7304)\n- `hostreceiver/filesystemscraper`: Add filesystem utilization (#8027)\n- `hostreceiver/pagingscraper`: Add paging.utilization (#6221)\n- `googlecloudexporter`: [Alpha] Translate metrics directly from OTLP to gcm using the `exporter.googlecloud.OTLPDirect` feature-gate (#7177)\n- `simpleprometheusreceiver`: Add support for static labels (#7908)\n- `spanmetricsprocessor`: Dropping the condition to replace _ with key_ as __ label is reserved and _ is not (#8057)\n- `podmanreceiver`: Add container.runtime attribute to container metrics (#8262)\n- `dockerstatsreceiver`: Add container.runtime attribute to container metrics (#8261)\n- `tanzuobservabilityexporter`: instrumentation Library and Dropped Counts to Span Tags (#8120)\n- `clickhouseexporter`: Implement consume log logic. (#9705)\n- `influxdbexporter`: Add support for cumulative, non-monotonic metrics. (#8348)\n- `oauth2clientauthextension`: Add support for EndpointParams (#7307)\n- Add `NewMetricData` function to `MetricsBuilder` to consistently set instrumentation library name (#8255)\n- `googlecloudpubsubreceiver` Added implementation of Google Cloud Pubsub receiver. (#8391)\n- `googlecloudpubsubexporter` Added implementation of Google Cloud Pubsub exporter. (#8391)\n- `coralogixexporter` Allow exporter timeout to be configured (#7957)\n- `prometheusremotewriteexporter` support adding trace id and span id attached to exemplars (#8380)\n- `influxdbexporter`: accept histogram metric missing infinity bucket. (#8462)\n- `skywalkingreceiver`: Added implementation of Skywalking receiver. (#8549)\n- `prometheusreceiver`: Fix staleness bug for histograms and summaries (#8561)\n\n### 🛑 Breaking changes 🛑\n\n- `mongodbatlasreceiver`: rename mislabeled attribute `memory_state` to correct `disk_status` on partition disk metrics (#7747)\n- `mongodbatlasreceiver`: Correctly set initial lookback for querying mongodb atlas api (#8246)\n- `nginxreceiver`: instrumentation name updated from `otelcol/nginx` to `otelcol/nginxreceiver` (#8255)\n- `postgresqlreceiver`: instrumentation name updated from `otelcol/postgresql` to `otelcol/postgresqlreceiver` (#8255)\n- `redisreceiver`: instrumentation name updated from `otelcol/redis` to `otelcol/redisreceiver` (#8255)\n- `apachereceiver`: instrumentation name updated from `otelcol/apache` to `otelcol/apachereceiver` ()\n- `couchdbreceiver`: instrumentation name updated from `otelcol/couchdb` to `otelcol/couchdbreceiver` (#8366)\n- `prometheusreceiver` Change resource attributes on metrics: `instance` -> `service.instance.id`, `host.name` -> `net.host.name`,  `port` -> `net.host.port`, `scheme` -> `http.scheme`, `job` removed (#8266)\n- `prometheusremotewriteexporter` Use `service.*` resource attributes instead of `job` and `instance` resource attributes when adding job and instance labels to metrics (#8266)\n- `mysqlreceiver`: instrumentation name updated from `otel/mysql` to `otelcol/mysqlreceiver` (#8387)\n- `zookeeperreceiver`: instrumentation name updated from `otelcol/zookeeper` to `otelcol/zookeeperreceiver` (#8389)\n- `coralogixexporter`: Create dynamic subsystem name (#7957)\n  - Deprecate configuration changed. Dynamic subsystem name from traces service name property.\n- `rabbitmqreceiver`: instrumentation name updated from `otelcol/rabbitmq` to `otelcol/rabbitmqreceiver` (#8400)\n\n### 🧰 Bug fixes 🧰\n\n- `zipkinexporter`: Set \"error\" tag value when status is set to error (#8187)\n- `prometheusremotewriteexporter`: Correctly handle metric labels which collide after sanitization (#8378)\n- `prometheusremotewriteexporter`: Drop labels when exemplar attributes exceed the max number of characters (#8379)\n- `k8sclusterreceiver`: Add support to enable k8s node and container cpu metrics to be reported as double values (#8245)\n  - Use \"--feature-gates=receiver.k8sclusterreceiver.reportCpuMetricsAsDouble\" to enable reporting node and container\n    cpu metrics as a double values.\n- `tanzuobservabilityexporter`: Fix a typo in Instrumentation Library name and version tags (#8384)\n- `logreceivers`: Fix an issue where receiver would sometimes fail to build using Go 1.18 (#8521)\n- `awsxrayreceiver`: Add defaults for optional stack frame parameters (#8790)\n\n### 🚩 Deprecations 🚩\n\n- `datadogexporter`: Deprecate automatic environment variable detection (#8397)\n\n### 🚀 New components 🚀\n- `sigv4authextension`: New Component: Sigv4 Authenticator Extension (#8263)\n\n## v0.46.0\n\n### 💡 Enhancements 💡\n\n- `internal/stanza`: Export metrics from Stanza receivers (#8025)\n- `hostreceiver/pagingscraper`: Migrate the scraper to the mdatagen metrics builder (#7139)\n- Do not drop zero trace/span id spans in the jaeger conversion (#7946)\n- Upgrade to use semantic conventions 1.6.1 (#7926)\n- `dynatraceexporter`: Validate QueueSettings and perform config validation in Validate() instead (#8020)\n- `sapmexporter`: Add validation for `sending_queue` setting (#8023)\n- `signalfxexporter`: Add validation for `sending_queue` setting (#8026)\n- `internal/stanza`: Add support for arbitrary attribute types (#8081)\n- `resourcedetectionprocessor`: Add confighttp.HTTPClientSettings To Resource Detection Config Fixes (#7397)\n- `hostmetricsreceiver`: Add cpu.utilization metrics to cpu scrapper (#7130)\n- `honeycombexporter`: Add validation for `sending_queue` setting (#8113)\n- `routingprocessor`: Expand error handling on failure to build exporters (#8125)\n- `skywalkingreceiver`: Add new skywalking receiver component folder and structure (#8107)\n- `groupbyattrsprocesor`: Allow empty keys, which allows to use the processor for compaction (#7793)\n- `datadogexporter`: Add rbac to example k8s manifest file (#8186)\n- `splunkhecexporter`: Add validation for `sending_queue` setting (#8256)\n\n### 🛑 Breaking changes 🛑\n\n- Remove deprecated functions from jaeger translator (#8032)\n- `internal/stanza`: Remove `write_to` setting from input operators (#8081)\n- `mongodbatlasreceiver`: rename `mongodb.atlas.*` attributes to `mongodb_atlas.*` adhering to naming guidelines. Adding 3 new attributes (#7960)\n\n### 🧰 Bug fixes 🧰\n\n- `prometheusreceiver`: Fix segfault that can occur after receiving stale metrics (#8056)\n- `filelogreceiver`: Fix issue where logs could occasionally be duplicated (#8123)\n- `prometheusremotewriteexporter`: Fix empty non-string resource attributes (#8116)\n\n### 🚀 New components 🚀\n\n## v0.45.1\n\n### 💡 Enhancements 💡\n\n- `sumologicexporter`: Move validation to Config (#7936)\n- `elasticsearchexporter`: Fix crash with batch processor (#7953).\n- `splunkhecexporter`: Batch metrics payloads (#7760)\n- `tanzuobservabilityexporter`: Add internal SDK metric tag (#7826)\n- `hostreceiver/processscraper`: Migrate the scraper to the mdatagen metrics builder (#7287)\n\n### 🧰 Bug fixes 🧰\n\n- `awsprometheusremotewriteexporter`: fix dependencies issue (#7963)\n\n### 🚀 New components 🚀\n\n- `awsfirehose` receiver: Add AWS Kinesis Data Firehose Receiver (#7918)\n\n## v0.45.0\n\n### 💡 Enhancements 💡\n\n- `hostreceiver/filesystemscraper`: Migrate the scraper to the mdatagen metrics builder (#7772)\n- `hostreceiver/memoryscraper`: Migrate the scraper to the mdatagen metrics builder (#7312)\n- `lokiexporter`: Use record attributes as log labels (#7569)\n- `routingprocessor`: Do not err on failure to build exporters (#7423)\n- `apachereceiver`: Update to mdatagen v2 (#7573)\n- `datadogexporter`: Don't send host metadata if hostname is empty (#7426)\n- `datadogexporter`: Add insecure_skip_verify flag to configuration (#7422)\n- `coralogixexporter`: Update readme (#7785)\n- `awscloudwatchlogsexporter`: Remove name from aws cloudwatch logs exporter (#7554)\n- `tanzuobservabilityexporter`: Update OTel Collector's Exporter to match WF Proxy Handling of source (#7929)\n- `hostreceiver/memoryscraper`: Add memory.utilization (#6221)\n- `awskinesisexporter`: Add Queue Config Validation AWS Kinesis Exporter (#7835)\n- `elasticsearchexporter`: Remove usage of deprecated LogRecord.Name field (#7829).\n- `loadbalancingexporter`: Allow non-exist hostname on startup (#7935)\n- `datadogexporter`: Use exact sum, count and average on Datadog distributions (#7830)\n- `storage/filestorage`: add optional compaction to filestorage (#7768)\n- `tanzuobservabilityexporter`: Add attributes from the Resource to the resulting WF metric tags & set `source` value in WF metric (#8101)\n\n### 🛑 Breaking changes 🛑\n\n- Use go mod compat, drops support for reproducibility with go 1.16 (#7915)\n- `apachereceiver`: Update instrumentation library name from `otel/apache` to `otelcol/apache` (#7754)\n- `pkg/translator/prometheusremotewrite`: Cleanup prw translator public functions (#7776)\n- `prometheusreceiver`: The OpenCensus-based metric conversion pipeline has\n  been removed.\n  - The `receiver.prometheus.OTLPDirect` feature gate has been removed as\n    the direct pipeline is the only remaining pipeline.\n- `translator/jaeger`: Cleanup jaeger translator function names (#7775)\n  - Deprecate old funcs with Internal word.\n- `mysqlreceiver`: Update data model and names for several metrics (#7924)\n  - Change all metrics to Int values\n  - Remove `mysql.buffer_pool_pages`. Replace with:\n    - `mysql.buffer_pool.pages`\n    - `mysql.buffer_pool.data_pages`\n    - `mysql.buffer_pool.page_flushes`\n  - Remove `mysql.buffer_pool_size`. Replace with:\n    - `mysql.buffer_pool.limit`\n    - `mysql.buffer_pool.usage`\n  - Rename `mysql.buffer_pool_operations` to `mysql.buffer_pool.operations`\n\n### 🚩 Deprecations 🚩\n\n- Deprecated log_names setting from filter processor. (#7552)\n\n### 🧰 Bug fixes 🧰\n\n - `tailsamplingprocessor`: \"And\" policy only works as a sub policy under a composite policy (#7590)\n - `prometheusreceiver`: Correctly map description and units when converting\n  Prometheus metadata directly to pdata. (#7748)\n - `sumologicexporter`: fix exporter panics on malformed histogram (#7548)\n- `awsecscontainermetrics`: CPU Reserved is now 1024/vCPU for ECS Container Insights (#6734)\n\n### 🚀 New components 🚀\n\n- `clickhouse` exporter: Add ClickHouse Exporter (#6907)\n- `pkg/translator/signalfx`: Extract signalfx to metrics conversion in a separate package (#7778)\n  - Extract FromMetrics to SignalFx translator package (#7823)\n\n## v0.44.0\n\n### 💡 Enhancements 💡\n\n- `kafkaexporter`: Add compression and flush max messages options.\n- `dynatraceexporter`: Write error logs using plugin logger (#7360)\n- `dynatraceexporter`: Fix docs for TLS settings (#7568)\n- `tanzuobservabilityexporter`: Turn on metrics exporter (#7281)\n- `attributesprocessor` `resourceprocessor`: Add `from_context` value source\n- `resourcedetectionprocessor`: check cluster config to verify resource is on aws for eks resources (#7186)\n- `awscloudwatchlogsexporter`: enable awscloudwatchlogsexporter which accepts and exports log data (#7297)\n- `translator/prometheusremotewrite`: add a new module to help translate data from OTLP to Prometheus Remote Write (#7240)\n- `azuremonitorexporter`: In addition to traces, export logs to Azure Application Insights (#7403)\n- `jmxreceiver`: Added `additional_jars` configuration option to launch JMX Metric Gatherer JAR with extended `CLASSPATH` (#7378)\n- `awscontainerinsightreceiver`: add full pod name when configured to AWS Container Insights Receiver (#7415)\n- `hostreceiver/loadscraper`: Migrate the scraper to the mdatagen metrics builder (#7288)\n- `awsecscontainermetricsreceiver`: Rename attributes to follow semantic conventions (#7425)\n- `datadogexporter`: Always map conventional attributes to tags (#7185)\n- `mysqlreceiver`: Add golden files for integration test (#7303)\n- `nginxreceiver`: Standardize integration test (#7515)\n- `mysqlreceiver`: Update to use mdatagen v2 (#7507)\n- `postgresqlreceiver`: Add integration tests (#7501)\n- `apachereceiver`: Add integration test (#7517)\n- `mysqlreceiver`: Use scrapererror to report errors (#7513)\n- `postgresreceiver`: Update to mdatagen v2 (#7503)\n- `nginxreceiver`: Update to mdatagen v2 (#7549)\n- `datadogexporter`: Fix traces exporter's initialization log (#7564)\n- `tailsamplingprocessor`: Add And sampling policy (#6910)\n- `coralogixexporter`: Add Coralogix Exporter (#7383)\n- `prometheusexecreceiver`: Add default value for `scrape_timeout` option (#7587)\n\n### 🛑 Breaking changes 🛑\n\n- `resourcedetectionprocessor`: Update `os.type` attribute values according to semantic conventions (#7544)\n- `awsprometheusremotewriteexporter`: Deprecation notice; may be removed after v0.49.0\n  - Switch to using the `prometheusremotewriteexporter` + `sigv4authextension` instead\n\n### 🧰 Bug fixes 🧰\n\n- `resourcedetectionprocessor`: fix `meta` allow list excluding keys with nil values (#7424)\n- `postgresqlreceiver`: Fix issue where empty metrics could be returned after failed connection (#7502)\n- `resourcetotelemetry`: Ensure resource attributes are added to summary\n  and exponential histogram data points. (#7523)\n\n### 🚩 Deprecations 🚩\n\n- Deprecated otel_to_hec_fields.name setting from splunkhec exporter. (#7560)\n\n## v0.43.0\n\n### 💡 Enhancements 💡\n\n- `coralogixexporter`: First implementation of Coralogix Exporter (#6816)\n- `cloudfoundryreceiver`: Enable Cloud Foundry client (#7060)\n- `elasticsearchexporter`: add elasticsearchexporter to the components exporter list (#6002)\n- `elasticsearchreceiver`: Add metric metadata (#6892)\n- `elasticsearchreceiver`: Use same metrics as JMX receiver for JVM metrics (#7160)\n- `elasticsearchreceiver`: Implement scraping logic (#7174)\n- `datadogexporter`: Add http.status_code tag to trace stats (#6889)\n- `datadogexporter`: Add configuration option to use OTel span name into the Datatog resource name (#6611)\n- `mongodbreceiver`: Add initial client code to the component (#7125)\n- `tanzuobservabilityexporter`: Support delta histograms (#6897)\n- `awscloudwatchlogsexporter`: Use cwlogs package to export logs (#7152)\n- `mysqlreceiver`: Add the receiver to available components (#7078)\n- `tanzuobservabilityexporter`: Documentation for the memory_limiter configuration (#7164)\n- `dynatraceexporter`: Do not shut down exporter when metrics ingest module is temporarily unavailable (#7161)\n- `mongodbreceiver`: Add metric metadata (#7163)\n- `mongodbreceiver`: Add metric scraping (#7175)\n- `postgresqlreceiver`: add the receiver to available components (#7079)\n- `rabbitmqreceiver`: Add scraper logic (#7299)\n- `tanzuobservability exporter`: Support summary metrics (#7121)\n- `mongodbatlasreceiver`: Add retry and backoff to HTTP client (#6943)\n- Use Jaeger gRPC instead of Thrift in the docker-compose example (#7243)\n- `tanzuobservabilityexporter`: Support exponential histograms (#7127)\n- `receiver_creator`: Log added and removed endpoint env structs (#7248)\n- `prometheusreceiver`: Use the OTLP data conversion path by default. (#7282)\n  - Use `--feature-gates=-receiver.prometheus.OTLPDirect` to re-enable the\n    OpenCensus conversion path.\n- `extension/observers`: Correctly set image and tag on container endpoints (#7279)\n- `tanzuobservabilityexporter`: Document how to enable memory_limiter (#7286)\n- `hostreceiver/networkscraper`: Migrate the scraper to the mdatagen metrics builder (#7048)\n- `hostmetricsreceiver`: Add MuteProcessNameError config flag to mute specific error reading process executable (#7176)\n- `scrapertest`: Improve comparison logic (#7305)\n- `hostmetricsreceiver`: add `cpu_average` option for load scraper to report the average cpu load (#6999)\n- `scrapertest`: Add comparison option to ignore specific attributes (#6519)\n- `tracegen`: Add option to pass in custom headers to export calls via command line (#7308)\n- `tracegen`: Provide official container images (#7179)\n- `scrapertest`: Add comparison function for pdata.Metrics (#7400)\n- `prometheusremotewriteexporter` : Dropping the condition to replace _ with key_ as __ label is reserved and _ is not (#7112)\n\n### 🛑 Breaking changes 🛑\n\n- `tanzuobservabilityexporter`: Remove status.code\n- `tanzuobservabilityexporter`: Use semantic conventions for status.message (#7126)\n- `k8sattributesprocessor`: Move `kube` and `observability` packages to `internal` folder (#7159)\n- `k8sattributesprocessor`: Unexport processor `Option`s (#7311)\n- `zookeeperreceiver`: Refactored metrics to have correct units, types, and combined some metrics via attributes. (#7280)\n- `prometheusremotewriteexporter`: `PRWExporter` struct and `NewPRWExporter()`\n  function are now unexported. (#TBD)\n- `newrelicexporter` marked as deprecated (#7284)\n\n### 🚀 New components 🚀\n\n- `rabbitmqreceiver`: Establish codebase for RabbitMQ metrics receiver (#7239)\n- Add `basicauth` extension (#7167)\n- `k8seventsreceiver`: Implement core logic (#6885)\n\n### 🧰 Bug fixes 🧰\n\n- `k8sattributeprocessor`: Parse IP out of net.Addr to correctly tag k8s.pod.ip (#7077)\n- `k8sattributeprocessor`: Process IP correctly for net.Addr instances that are not typed (#7133)\n- `mdatagen`: Fix validation of `enabled` field in metadata.yaml (#7166)\n- `elasticsearch`: Fix timestamp for each metric being startup time (#7255)\n- `prometheusremotewriteexporter`: Fix index out of range panic caused by expiring metrics (#7149)\n- `resourcedetection`: Log the error when checking for ec2metadata availability (#7296)\n\n## v0.42.0\n\n### 💡 Enhancements 💡\n\n- `couchbasereceiver`: Add couchbase client (#7122)\n- `couchdbreceiver`: Add couchdb scraper (#7131)\n- `couchdbreceiver`: Add couchdb client (#6880)\n- `elasticsearchreceiver`: Implement scraper client (#7019)\n- `couchdbreceiver`: Add metadata metrics (#6878)\n- `prometheusremotewriteexporter`: Handling Staleness flag from OTLP (#6679)\n- `prometheusexporter`: Handling Staleness flag from OTLP (#6805)\n- `prometheusreceiver`: Set OTLP no-data-present flag for stale scraped metrics. (#7043)\n- `mysqlreceiver`: Add Integration test (#6916)\n- `datadogexporter`: Add compatibility with ECS Fargate semantic conventions (#6670)\n- `k8s_observer`: discover k8s.node endpoints (#6820)\n- `redisreceiver`: Add missing description fields to keyspace metrics (#6940)\n- `redisreceiver`: Set start timestamp uniformly for gauge and sum metrics (#6941)\n- `kafkaexporter`: Allow controlling Kafka acknowledgment behaviour  (#6301)\n- `lokiexporter`: Log the first part of the http body on failed pushes to loki (#6946)\n- `resourcedetectionprocessor`: add the [consul](https://www.consul.io/) detector (#6382)\n- `awsemfexporter`: refactor cw_client logic into separate `cwlogs` package (#7072)\n- `prometheusexporter`: Dropping the condition to replace _ with key_ as __ label is reserved and _ is not (#7506)\n\n### 🛑 Breaking changes 🛑\n\n- `memcachedreceiver`: Update metric names (#6594)\n- `memcachedreceiver`: Fix some metric units and value types (#6895)\n- `sapm` receiver: Use Jaeger status values instead of OpenCensus (#6682)\n- `jaeger` receiver/exporter: Parse/set Jaeger status with OTel spec values (#6682)\n- `awsecscontainermetricsreceiver`: remove tag from `container.image.name` (#6436)\n- `k8sclusterreceiver`: remove tag from `container.image.name` (#6436)\n\n### 🚀 New components 🚀\n\n- `ecs_task_observer`: Discover running containers in AWS ECS tasks (#6894)\n- `mongodbreceiver`: Establish codebase for MongoDB metrics receiver (#6972)\n- `couchbasereceiver`: Establish codebase for Couchbase metrics receiver (#7046)\n- `dbstorage`: New experimental dbstorage extension (#7061)\n- `redactionprocessor`: Remove sensitive data from traces (#6495)\n\n### 🧰 Bug fixes 🧰\n\n- `ecstaskobserver`: Fix \"Incorrect conversion between integer types\" security issue (#6939)\n- Fix typo in \"direction\" metrics attribute description (#6949)\n- `zookeeperreceiver`: Fix issue where receiver could panic during shutdown (#7020)\n- `prometheusreceiver`: Fix metadata fetching when metrics differ by trimmable suffixes (#6932)\n- Sanitize URLs being logged (#7021)\n- `prometheusreceiver`: Fix start time tracking for long scrape intervals (#7053)\n- `signalfxexporter`: Don't use syscall to avoid compilation errors on some platforms (#7062)\n- `tailsamplingprocessor`: Add support for new policies as composite sub-policies (#6975)\n\n### 💡 Enhancements 💡\n\n- `lokiexporter`: add complete log record to body (#6619)\n- `k8sclusterreceiver` add `container.image.tag` attribute (#6436)\n- `spanmetricproccessor`: use an LRU cache for the cached Dimensions key-value pairs (#2179)\n- `skywalkingexporter`: add skywalking metrics exporter (#6528)\n- `deltatorateprocessor`: add int counter support (#6982)\n- `filestorageextension`: document default values (#7022)\n- `redisreceiver`: Migrate the scraper to the mdatagen metrics builder (#6938)\n\n## v0.41.0\n\n### 🛑 Breaking changes 🛑\n\n- None\n\n### 🚀 New components 🚀\n\n- `asapauthextension` (#6627)\n- `mongodbatlasreceiver` (#6367)\n\n### 🧰 Bug fixes 🧰\n\n- `filestorageextension`: fix panic when configured directory cannot be accessed (#6103)\n- `hostmetricsreceiver`: fix set of attributes for system.cpu.time metric (#6422)\n- `k8sobserver`: only record pod endpoints for running pods (#5878)\n- `mongodbatlasreceiver`: fix attributes fields in metadata.yaml (#6440)\n- `prometheusexecreceiver`: command line processing on Windows (#6145)\n- `spanmetricsprocessor`: fix exemplars support (#6140)\n-  Remap arm64 to aarch64 on rpm/deb packages (#6635)\n\n### 💡 Enhancements 💡\n\n- `datadogexporter`: do not use attribute localhost-like hostnames (#6477)\n- `datadogexporter`: retry per network call (#6412)\n- `datadogexporter`: take hostname into account for cache (#6223)\n- `exporter/lokiexporter`: adding a feature for loki exporter to encode JSON for log entry (#5846)\n- `googlecloudspannerreceiver`: added fallback to ADC for database connections. (#6629)\n- `googlecloudspannerreceiver`: added parsing only distinct items for sample lock request label. (#6514)\n- `googlecloudspannerreceiver`: added request tag label to metadata config for top query stats. (#6475)\n- `googlecloudspannerreceiver`: added sample lock requests label to the top lock stats metrics. (#6466)\n- `googlecloudspannerreceiver`: added transaction tag label to metadata config for top transaction stats. (#6433)\n- `groupbyattrsprocessor`: added support for metrics signal (#6248)\n- `hostmetricsreceiver`: ensure SchemaURL is set (#6482)\n- `kubeletstatsreceiver`: add support for read-only kubelet endpoint (#6488)\n- `mysqlreceiver`: enable native authentication (#6628)\n- `mysqlreceiver`: remove requirement for password on MySQL (#6479)\n- `receiver/prometheusreceiver`: do not add host.name to metrics from localhost/unspecified targets (#6476)\n- `spanmetricsprocessor`: add setStatus operation (#5886)\n- `splunkhecexporter`: remove duplication of host.name attribute (#6527)\n- `tanzuobservabilityexporter`: add consumer for sum metrics. (#6385)\n- Update log-collection library to v0.23.0 (#6593)\n\n## v0.40.0\n\n### 🛑 Breaking changes 🛑\n\n- `tencentcloudlogserviceexporter`: change `Endpoint` to `Region` to simplify configuration (#6135)\n\n### 🚀 New components 🚀\n\n- Add `memcached` receiver (#5839)\n\n### 🧰 Bug fixes 🧰\n\n- Fix token passthrough for HEC (#5435)\n- `datadogexporter`: Fix missing resource attributes default mapping when resource_attributes_as_tags: false (#6359)\n- `tanzuobservabilityexporter`: Log and report missing metric values. (#5835)\n- `mongodbatlasreceiver`: Fix metrics metadata (#6395)\n\n### 💡 Enhancements 💡\n\n- `awsprometheusremotewrite` exporter: Improve error message when failing to sign request\n- `mongodbatlas`: add metrics (#5921)\n- `healthcheckextension`: Add path option (#6111)\n- Set unprivileged user to container image (#6380)\n- `k8sclusterreceiver`: Add allocatable type of metrics (#6113)\n- `observiqexporter`: Allow Dialer timeout to be configured (#5906)\n- `routingprocessor`: remove broken debug log fields (#6373)\n- `prometheusremotewriteexporter`: Add exemplars support (#5578)\n- `fluentforwardreceiver`: Convert attributes with nil value to AttributeValueTypeEmpty (#6630)\n\n## v0.39.0\n\n### 🛑 Breaking changes 🛑\n\n- `httpdreceiver` renamed to `apachereceiver` to match industry standards (#6207)\n- `tencentcloudlogserviceexporter` change `Endpoint` to `Region` to simplify configuration (#6135)\n\n### 🚀 New components 🚀\n\n- Add `postgresqlreceiver` config and factory (#6153)\n- Add TencentCloud LogService exporter `tencentcloudlogserviceexporter` (#5722)\n- Restore `jaegerthrifthttpexporter` (#5666)\n- Add `skywalkingexporter` (#5690, #6114)\n\n### 🧰 Bug fixes 🧰\n\n- `datadogexporter`: Improve cumulative metrics reset detection using `StartTimestamp` (#6120)\n- `mysqlreceiver`: Address issues in shutdown function (#6239)\n- `tailsamplingprocessor`: End go routines during shutdown (#5693)\n- `googlecloudexporter`: Update google cloud exporter to correctly close the metric exporter (#5990)\n- `statsdreceiver`: Fix the summary point calculation (#6155)\n- `datadogexporter` Correct default value for `send_count_sum_metrics` (#6130)\n\n### 💡 Enhancements 💡\n\n- `datadogexporter`: Increase default timeout to 15 seconds (#6131)\n- `googlecloudspannerreceiver`: Added metrics cardinality handling for Google Cloud Spanner receiver (#5981, #6148, #6229)\n- `mysqlreceiver`: Mysql add support for different protocols (#6138)\n- `bearertokenauthextension`: Added support of Bearer Auth for HTTP Exporters (#5962)\n- `awsxrayexporter`: Fallback to rpc.method for segment operation when aws.operation missing (#6231)\n- `healthcheckextension`: Add new health check feature for collector pipeline (#5643)\n- `datadogexporter`: Always add current hostname (#5967)\n- `k8sattributesprocessor`: Add code to fetch all annotations and labels by specifying key regex (#5780)\n- `datadogexporter`: Do not rely on collector to resolve envvar when possible to resolve them (#6122)\n- `datadogexporter`: Add container tags to attributes package (#6086)\n- `datadogexporter`: Preserve original TraceID (#6158)\n- `prometheusreceiver`: Enhance prometheus receiver logger to determine errors, test real e2e usage (#5870)\n- `awsxrayexporter`: Added support for AWS AppRunner origin (#6141)\n\n## v0.38.0\n\n### 🛑 Breaking changes 🛑\n\n- `datadogexporter` Make distributions the default histogram export option. (#5885)\n- `redisreceiver` Update Redis receiver's metric names. (#5837)\n- Remove `scraperhelper` from contrib, use the core version. (#5826)\n\n### 🚀 New components 🚀\n\n- `googlecloudspannerreceiver` Added implementation of Google Cloud Spanner receiver. (#5727)\n- `awsxrayproxy` Wire up awsxrayproxy extension. (#5747)\n- `awscontainerinsightreceiver` Enable AWS Container Insight receiver. (#5960)\n\n### 🧰 Bug fixes 🧰\n\n- `statsdreceiver`: fix start timestamp / temporality for counters. (#5714)\n- Fix security issue related to github.com/tidwall/gjson. (#5936)\n- `datadogexporter` Fix cumulative histogram handling in distributions mode (#5867)\n- `datadogexporter` Skip nil sketches (#5925)\n\n### 💡 Enhancements 💡\n\n- Extend `kafkareceiver` configuration capabilities. (#5677)\n- Convert `mongodbatlas` receiver to use scraperhelper. (#5827)\n- Convert `dockerstats` receiver to use scraperhelper. (#5825)\n- Convert `podman` receiver to use scraperhelper. (#5822)\n- Convert `redisreceiver` to use scraperhelper. (#5796)\n- Convert `kubeletstats` receiver to use scraperhelper. (#5821)\n- `googlecloudspannerreceiver` Migrated Google Cloud Spanner receiver to scraper approach. (#5868)\n- `datadogexporter` Use a `Consumer` interface for decoupling from zorkian's package. (#5315)\n- `mdatagen` - Add support for extended metric descriptions (#5688)\n- `signalfxexporter` Log datapoints option. (#5689)\n- `cumulativetodeltaprocessor`: Update cumulative to delta. (#5772)\n- Update configuration default values in log receivers docs. (#5840)\n- `fluentforwardreceiver`: support more complex fluent-bit objects. (#5676)\n- `datadogexporter` Remove spammy logging. (#5856)\n- `datadogexporter` Remove obsolete report_buckets config. (#5858)\n- Improve performance of metric expression matcher. (#5864)\n- `tanzuobservabilityexporter` Introduce metricsConsumer and gaugeMetricConsumer. (#5426)\n- `awsxrayexporter` rpc.system has priority to determine aws namespace. (#5833)\n- `tailsamplingprocessor` Add support for composite sampling policy to the tailsampler. (#4958)\n- `kafkaexporter` Add support for AWS_MSK_IAM SASL Auth (#5763)\n- Refactor the client Authenticators  for the new \"ClientAuthenticator\" interfaces (#5905)\n- `mongodbatlasreceiver` Add client wrapper for MongoDB Atlas support (#5386)\n- `redisreceiver` Update Redis config options (#5861)\n- `routingprocessor`: allow routing for all signals (#5869)\n- `extension/observer/docker` add ListAndWatch to observer (#5851)\n\n## v0.37.1\n\n### 🧰 Bug fixes 🧰\n\n- Fixes a problem with v0.37.0 which contained dependencies on v0.36.0 components. They should have been updated to v0.37.0.\n\n## v0.37.0\n\n### 🚀 New components 🚀\n\n- [`journald` receiver](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/journaldreceiver) to parse Journald events from systemd journal using the [opentelemetry-log-collection](https://github.com/open-telemetry/opentelemetry-log-collection) library\n\n### 🛑 Breaking changes 🛑\n\n- Remove squash on configtls.TLSClientSetting for splunkhecexporter (#5541)\n- Remove squash on configtls.TLSClientSetting for elastic components (#5539)\n- Remove squash on configtls.TLSClientSetting for observiqexporter (#5540)\n- Remove squash on configtls.TLSClientSetting for AWS components (#5454)\n- Move `k8sprocessor` to `k8sattributesprocessor`.\n- Rename `k8s_tagger` configuration `k8sattributes`.\n- filelog receiver: use empty value for `SeverityText` field instead of `\"Undefined\"` (#5423)\n- Rename `configparser.ConfigMap` to `config.Map`\n- Rename `pdata.AggregationTemporality*` to `pdata.MetricAggregationTemporality*`\n- Remove deprecated `batchpertrace` package/module (#5380)\n\n### 💡 Enhancements 💡\n\n- `k8sattributes` processor: add container metadata enrichment (#5467, #5572)\n- `resourcedetection` processor: Add an option to force using hostname instead of FQDN (#5064)\n- `dockerstats` receiver: Move docker client into new shared `internal/docker` (#4702)\n- `spanmetrics` processor:\n  - Add exemplars to metrics (#5263)\n  - Support resource attributes in metrics dimensions (#4624)\n- `filter` processor:\n  - Add log filtering by `regexp` type filters (#5237)\n  - Add record level log filtering (#5418)\n- `dynatrace` exporter: Handle non-gauge data types (#5056)\n- `datadog` exporter:\n  - Add support for exporting histograms as sketches (#5082)\n  - Scrub sensitive information from errors (#5575)\n  - Add option to send instrumentation library metadata tags with metrics (#5431)\n- `podman` receiver: Add `api_version`, `ssh_key`, and `ssh_passphrase` config options (#5430)\n- `signalfx` exporter:\n  - Add `max_connections` config option (#5432)\n  - Add dimension name to log when value > 256 chars (#5258)\n  - Discourage setting of endpoint path (#4851)\n- `kubeletstats` receiver: Convert to pdata instead of using OpenCensus (#5458)\n- `tailsampling` processor: Add `invert_match` config option to `string_attribute` policy (#4393)\n- `awsemf` exporter: Add a feature flag in UserAgent for AWS backend to monitor the adoptions (#5178)\n- `splunkhec` exporter: Handle explicitly NaN and Inf values (#5581)\n- `hostmetrics` receiver:\n  - Collect more process states in processes scraper (#4856)\n  - Add device label to paging scraper (#4854)\n- `awskinesis` exporter: Extend to allow for dynamic export types (#5440)\n\n### 🧰 Bug fixes 🧰\n\n- `datadog` exporter:\n  - Fix tags on summary and bucket metrics (#5416)\n  - Fix cache key generation for cumulative metrics (#5417)\n- `resourcedetection` processor: Fix failure to start collector if at least one detector returns an error (#5242)\n- `prometheus` exporter: Do not record obsreport calls (#5438)\n- `prometheus` receiver: Metric type fixes to match Prometheus functionality (#4865)\n- `sentry` exporter: Fix sentry tracing (#4320)\n- `statsd` receiver: Set quantiles for metrics (#5647)\n\n## v0.36.0\n\n### 🛑 Breaking changes 🛑\n\n- `filter` processor: The configs for `logs` filter processor have been changed to be consistent with the `metrics` filter processor. (#4895)\n- `splunk_hec` receiver:\n  - `source_key`, `sourcetype_key`, `host_key` and `index_key` have now moved under `hec_metadata_to_otel_attrs` (#4726)\n  - `path` field on splunkhecreceiver configuration is removed: We removed the `path` attribute as any request going to the Splunk HEC receiver port should be accepted, and added the `raw_path` field to explicitly map the path accepting raw HEC data. (#4951)\n- feat(dynatrace): tags is deprecated in favor of default_dimensions (#5055)\n\n### 💡 Enhancements 💡\n\n- `filter` processor: Add ability to `include` logs based on resource attributes in addition to excluding logs based on resource attributes for strict matching. (#4895)\n- `kubelet` API: Add ability to create an empty CertPool when the system run environment is windows\n- `JMX` receiver: Allow JMX receiver logging level to be configured (#4898)\n- `datadog` exporter: Export histograms as in OpenMetrics Datadog check (#5065)\n- `dockerstats` receiver: Set Schema URL (#5239)\n- Rename memorylimiter -> memorylimiterprocessor (#5262)\n- `awskinesis` exporter: Refactor AWS kinesis exporter to be synchronous  (#5248)\n\n## v0.35.0\n\n### 🛑 Breaking changes 🛑\n\n- Rename configparser.Parser to configparser.ConfigMap (#5070)\n- Rename TelemetryCreateSettings -> TelemetrySettings (#5169)\n\n### 💡 Enhancements 💡\n\n- chore: update influxdb exporter and receiver (#5058)\n- chore(dynatrace): use payload limit from api constants (#5077)\n- Add documentation for filelog's new force_flush_period parameter (#5066)\n- Reuse the gzip reader with a sync.Pool (#5145)\n- Add a trace observer when splunkhecreceiver is used for logs (#5063)\n- Remove usage of deprecated pdata.AttributeValueMapToMap (#5174)\n- Podman Stats Receiver: Receiver and Metrics implementation (#4577)\n\n### 🧰 Bug fixes 🧰\n\n- Use staleness markers generated by prometheus, rather than making our own (#5062)\n- `datadogexporter` exporter: skip NaN and infinite values (#5053)\n\n## v0.34.0\n\n### 🚀 New components 🚀\n\n- [`cumulativetodelta` processor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/cumulativetodeltaprocessor) to convert cumulative sum metrics to cumulative delta\n\n- [`file` exporter](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/fileexporter) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`jaeger` exporter](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/v0.85.0/exporter/jaegerexporter) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`kafka` exporter](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/kafkaexporter) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`opencensus` exporter](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/opencensusexporter) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`prometheus` exporter](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/prometheusexporter) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`prometheusremotewrite` exporter](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/prometheusremotewriteexporter) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`zipkin` exporter](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/zipkinexporter) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`attribute` processor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/attributesprocessor) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`filter` processor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/filterprocessor) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`probabilisticsampler` processor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/probabilisticsamplerprocessor) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`resource` processor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/resourceprocessor) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`span` processor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/spanprocessor) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`hostmetrics` receiver](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/hostmetricsreceiver) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`jaeger` receiver](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/jaegerreceiver) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`kafka` receiver](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/kafkareceiver) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`opencensus` receiver](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/opencensusreceiver) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`prometheus` receiver](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/prometheusreceiver) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`zipkin` receiver](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/zipkinreceiver) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`bearertokenauth` extension](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/extension/bearertokenauthextension) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`healthcheck` extension](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/extension/healthcheckextension) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`oidcauth` extension](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/extension/oidcauthextension) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`pprof` extension](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/extension/pprofextension) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n- [`testbed`](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/testbed) from core repository ([#3474](https://github.com/open-telemetry/opentelemetry-collector/issues/3474))\n\n### 💡 Enhancements 💡\n\n- `tailsampling` processor: Add new policy `probabilistic` (#3876)\n\n## v0.33.0\n\n# 🎉 OpenTelemetry Collector Contrib v0.33.0 (Beta) 🎉\n\nThe OpenTelemetry Collector Contrib contains everything in the [opentelemetry-collector release](https://github.com/open-telemetry/opentelemetry-collector/releases/tag/v0.32.0) (be sure to check the release notes here as well!). Check out the [Getting Started Guide](https://opentelemetry.io/docs/collector/getting-started/) for deployment and configuration information.\n\n### 🚀 New components 🚀\n\n- [`cumulativetodelta` processor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/cumulativetodeltaprocessor) to convert cumulative sum metrics to cumulative delta\n\n### 💡 Enhancements 💡\n\n- Collector contrib has now full support for metrics proto v0.9.0.\n\n## v0.32.0\n\n# 🎉 OpenTelemetry Collector Contrib v0.32.0 (Beta) 🎉\n\nThis release is marked as \"bad\" since the metrics pipelines will produce bad data.\n\n- See https://github.com/open-telemetry/opentelemetry-collector/issues/3824\n\nThe OpenTelemetry Collector Contrib contains everything in the [opentelemetry-collector release](https://github.com/open-telemetry/opentelemetry-collector/releases/tag/v0.32.0) (be sure to check the release notes here as well!). Check out the [Getting Started Guide](https://opentelemetry.io/docs/collector/getting-started/) for deployment and configuration information.\n\n### 🛑 Breaking changes 🛑\n\n- `splunk_hec` receiver/exporter: `com.splunk.source` field is mapped to `source` field in Splunk instead of `service.name` (#4596)\n- `redis` receiver: Move interval runner package to `internal/interval` (#4600)\n- `datadog` exporter: Export summary count and sum as monotonic counts (#4605)\n\n### 💡 Enhancements 💡\n\n- `logzio` exporter:\n  - New implementation of an in-memory queue to store traces, data compression with gzip, and queue configuration options (#4395)\n  - Make `Hclog2ZapLogger` struct and methods private for public go api review (#4431)\n- `newrelic` exporter (#4392):\n  - Marked unsupported metric as permanent error\n  - Force the interval to be valid even if 0\n- `awsxray` exporter: Add PHP stacktrace parsing support (#4454)\n- `file_storage` extension: Implementation of batch storage API (#4145)\n- `datadog` exporter:\n  - Skip sum metrics with no aggregation temporality (#4597)\n  - Export delta sums as counts (#4609)\n- `elasticsearch` exporter: Add dedot support (#4579)\n- `signalfx` exporter: Add process metric to translation rules (#4598)\n- `splunk_hec` exporter: Add profiling logs support (#4464)\n- `awsemf` exporter: Replace logGroup and logStream pattern with metric labels (#4466)\n\n### 🧰 Bug fixes 🧰\n\n- `awsxray` exporter: Fix the origin on ECS/EKS/EB on EC2 cases (#4391)\n- `splunk_hec` exporter: Prevent re-sending logs that were successfully sent (#4467)\n- `signalfx` exporter: Prefix temporary metric translations (#4394)\n\n## v0.31.0\n\n# 🎉 OpenTelemetry Collector Contrib v0.31.0 (Beta) 🎉\n\nThe OpenTelemetry Collector Contrib contains everything in the [opentelemetry-collector release](https://github.com/open-telemetry/opentelemetry-collector/releases/tag/v0.31.0) (be sure to check the release notes here as well!). Check out the [Getting Started Guide](https://opentelemetry.io/docs/collector/getting-started/) for deployment and configuration information.\n\n### 🛑 Breaking changes 🛑\n\n- `influxdb` receiver: Removed `metrics_schema` config option (#4277)\n\n### 💡 Enhancements 💡\n\n- Update to OTLP 0.8.0:\n  - Remove use of `IntHistogram` (#4276)\n  - Update exporters/receivers for `NumberDataPoint`\n- Remove use of deprecated `pdata` slice `Resize()` (#4203, #4208, #4209)\n- `awsemf` exporter: Added the option to have a user who is sending metrics from EKS Fargate Container Insights to reformat them to look the same as insights from ECS so that they can be ingested by CloudWatch (#4130)\n- `k8scluster` receiver: Support OpenShift cluster quota metrics (#4342)\n- `newrelic` exporter (#4278):\n  - Requests are now retry-able via configuration option (defaults to retries enabled). Permanent errors are not retried.\n  - The exporter monitoring metrics now include an untagged summary metric for ease of use.\n  - Improved error logging to include URLs that fail to post messages to New Relic.\n- `datadog` exporter: Upscale trace stats when global sampling rate is set (#4213)\n\n### 🧰 Bug fixes 🧰\n\n- `statsd` receiver: Add option to set Counter to be monotonic (#4154)\n- Fix `internal/stanza` severity mappings (#4315)\n- `awsxray` exporter: Fix the wrong AWS env resource setting (#4384)\n- `newrelic` exporter (#4278):\n  - Configuration unmarshalling did not allow timeout value to be set to 0 in the endpoint specific section.\n  - Request cancellation was not propagated via context into the http request.\n  - The queued retry logger is set to a zap.Nop logger as intended.\n\n## v0.30.0\n\n# 🎉 OpenTelemetry Collector Contrib v0.30.0 (Beta) 🎉\n\nThe OpenTelemetry Collector Contrib contains everything in the [opentelemetry-collector release](https://github.com/open-telemetry/opentelemetry-collector/releases/tag/v0.30.0) (be sure to check the release notes here as well!). Check out the [Getting Started Guide](https://opentelemetry.io/docs/collector/getting-started/) for deployment and configuration information.\n\n### 🚀 New components 🚀\n- `oauth2clientauth` extension: ported from core (#3848)\n- `metrics-generation` processor: is now enabled and available (#4047)\n\n### 🛑 Breaking changes 🛑\n\n- Removed `jaegerthrifthttp` exporter (#4089)\n\n### 💡 Enhancements 💡\n\n- `tailsampling` processor:\n  - Add new policy `status_code` (#3754)\n  - Add new tail sampling processor policy: status_code (#3754)\n- `awscontainerinsights` receiver:\n  - Integrate components and fix bugs for EKS Container Insights (#3846)\n  - Add Cgroup to collect ECS instance metrics for container insights receiver #3875\n- `spanmetrics` processor: Support sub-millisecond latency buckets (#4091)\n- `sentry` exporter: Add exception event capture in sentry (#3854)\n\n## v0.29.0\n\n# 🎉 OpenTelemetry Collector Contrib v0.29.0 (Beta) 🎉\n\nThe OpenTelemetry Collector Contrib contains everything in the [opentelemetry-collector release](https://github.com/open-telemetry/opentelemetry-collector/releases/tag/v0.29.0) (be sure to check the release notes here as well!). Check out the [Getting Started Guide](https://opentelemetry.io/docs/collector/getting-started/) for deployment and configuration information.\n\n### 🛑 Breaking changes 🛑\n\n- `redis` receiver (#3808)\n  - removed configuration `service_name`. Use resource processor or `resource_attributes` setting if using `receivercreator`\n  - removed `type` label and set instrumentation library name to `otelcol/redis` as other receivers do\n\n### 💡 Enhancements 💡\n\n- `tailsampling` processor:\n  - Add new policy `latency` (#3750)\n  - Add new policy `status_code` (#3754)\n- `splunkhec` exporter: Include `trace_id` and `span_id` if set (#3850)\n- `newrelic` exporter: Update instrumentation naming in accordance with otel spec (#3733)\n- `sentry` exporter: Added support for insecure connection with Sentry (#3446)\n- `k8s` processor:\n  - Add namespace k8s tagger (#3384)\n  - Add ignored pod names as config parameter (#3520)\n- `awsemf` exporter: Add support for `TaskDefinitionFamily` placeholder on log stream name (#3755)\n- `loki` exporter: Add resource attributes as Loki label (#3418)\n\n### 🧰 Bug fixes 🧰\n\n- `datadog` exporter:\n  - Ensure top level spans are computed (#3786)\n  - Update `env` clobbering behavior (#3851)\n- `awsxray` exporter: Fixed filtered attribute translation (#3757)\n- `splunkhec` exporter: Include trace and span id if set in log record (#3850)\n\n## v0.28.0\n\n# 🎉 OpenTelemetry Collector Contrib v0.28.0 (Beta) 🎉\n\nThe OpenTelemetry Collector Contrib contains everything in the [opentelemetry-collector release](https://github.com/open-telemetry/opentelemetry-collector/releases/tag/v0.28.0) (be sure to check the release notes here as well!). Check out the [Getting Started Guide](https://opentelemetry.io/docs/collector/getting-started/) for deployment and configuration information.\n\n### 🚀 New components 🚀\n\n- `humio` exporter to export data to Humio using JSON over the HTTP Ingest API\n- `udplog` receiver to receives logs from udp using the [opentelemetry-log-collection](https://github.com/open-telemetry/opentelemetry-log-collection) library\n- `tanzuobservability` exporter to send traces to [Tanzu Observability](https://tanzu.vmware.com/observability)\n\n### 🛑 Breaking changes 🛑\n\n- `f5cloud` exporter (#3509):\n  - Renamed the config 'auth' field to 'f5cloud_auth'. This will prevent a config field name collision when [Support for Custom Exporter Authenticators as Extensions](https://github.com/open-telemetry/opentelemetry-collector/pull/3128) is ready to be integrated.\n\n### 💡 Enhancements 💡\n\n- Enabled Dependabot for Github Actions (#3543)\n- Change obsreport helpers for receivers to use the new pattern created in Collector (#3439,#3443,#3449,#3504,#3521,#3548)\n- `datadog` exporter:\n  - Add logging for unknown or unsupported metric types (#3421)\n  - Add collector version tag to internal health metrics (#3394)\n  - Remove sublayer stats calc and mutex (#3531)\n  - Deduplicate hosts for which we send running metrics (#3539)\n  - Add support for summary datatype (#3660)\n  - Add datadog span operation name remapping config option (#3444)\n  - Update error formatting for error spans that are not exceptions (#3701)\n- `nginx` receiver: Update the nginx metrics to more closely align with the conventions (#3420)\n- `elasticsearch` exporter: Init JSON encoding support (#3101)\n- `jmx` receiver:\n  - Allow setting system properties (#3450)\n  - Update tested JMX Metric Gatherer release (#3695)\n- Refactor components for the Client Authentication Extensions (#3507)\n- Remove redundant conversion calls (#3688)\n- `storage` extension: Add a `Close` method to Client interface (#3506)\n- `splunkhec` exporter: Add `metric_type` as key which maps to the type of the metric (#3696)\n- `k8s` processor: Add semantic conventions to k8s-tagger for pod metadata (#3544)\n- `kubeletstats` receiver: Refactor kubelet client to internal folder (#3698)\n- `newrelic` exporter (#3690):\n  - Updates the log level from error to debug when New Relic rate limiting occurs\n  - Updates the sanitized api key that is reported via metrics\n- `filestorage` extension: Add ability to specify name (#3703)\n- `awsemf` exporter: Store the initial value for cumulative metrics (#3425)\n- `awskinesis` exporter: Refactor to allow for extended types of encoding (#3655)\n- `ecsobserver` extension:\n  - Add task definition, ec2, and service fetcher (#3503)\n  - Add exporter to convert task to target (#3333)\n\n### 🧰 Bug fixes 🧰\n\n- `awsemf` exporter: Remove delta adjustment from summaries by default (#3408)\n- `alibabacloudlogservice` exporter: Sanitize labels for metrics (#3454)\n- `statsd` receiver: Fix StatsD drop metrics tags when using summary as observer_type for timer/histogram (#3440)\n- `awsxray` exporter: Restore setting of Throttle for HTTP throttle response (#3685)\n- `awsxray` receiver: Fix quick start bug (#3653)\n- `metricstransform` processor: Check all data points for matching metric label values (#3435)\n\n## v0.27.0\n\n# 🎉 OpenTelemetry Collector Contrib v0.27.0 (Beta) 🎉\n\nThe OpenTelemetry Collector Contrib contains everything in the [opentelemetry-collector release](https://github.com/open-telemetry/opentelemetry-collector/releases/tag/v0.27.0) (be sure to check the release notes here as well!). Check out the [Getting Started Guide](https://opentelemetry.io/docs/collector/getting-started/) for deployment and configuration information.\n\n### 🚀 New components 🚀\n\n- `tcplog` receiver to receive logs from tcp using the [opentelemetry-log-collection](https://github.com/open-telemetry/opentelemetry-log-collection) library\n- `influxdb` receiver to accept metrics data as [InfluxDB Line Protocol](https://docs.influxdata.com/influxdb/v2.0/reference/syntax/line-protocol/)\n\n### 💡 Enhancements 💡\n\n- `splunkhec` exporter:\n  - Include the response in returned 400 errors (#3338)\n  - Map summary metrics to Splunk HEC metrics (#3344)\n  - Add HEC telemetry (#3260)\n- `newrelic` exporter: Include dropped attributes and events counts (#3187)\n- `datadog` exporter:\n  - Add Fargate task ARN to container tags (#3326)\n  - Improve mappings for span kind dd span type (#3368)\n- `signalfx` exporter: Add info log for host metadata properties update (#3343)\n- `awsprometheusremotewrite` exporter: Add SDK and system information to User-Agent header (#3317)\n- `metricstransform` processor: Add filtering capabilities matching metric label values for applying changes (#3201)\n- `groupbytrace` processor: Added workers for queue processing (#2902)\n- `resourcedetection` processor: Add docker detector (#2775)\n- `tailsampling` processor: Support regex on span attribute filtering (#3335)\n\n### 🧰 Bug fixes 🧰\n\n- `datadog` exporter:\n  - Update Datadog attributes to tags mapping (#3292)\n  - Consistent `hostname` and default metrics behavior (#3286)\n- `signalfx` exporter: Handle character limits on metric names and dimensions (#3328)\n- `newrelic` exporter: Fix timestamp value for cumulative metrics (#3406)\n\n## v0.26.0\n\n# 🎉 OpenTelemetry Collector Contrib v0.26.0 (Beta) 🎉\n\nThe OpenTelemetry Collector Contrib contains everything in the [opentelemetry-collector release](https://github.com/open-telemetry/opentelemetry-collector/releases/tag/v0.26.0) (be sure to check the release notes here as well!). Check out the [Getting Started Guide](https://opentelemetry.io/docs/collector/getting-started/) for deployment and configuration information.\n\n### 🚀 New components 🚀\n\n- `influxdb` exporter to support sending tracing, metrics, and logging data to [InfluxDB](https://www.influxdata.com/products/)\n\n### 🛑 Breaking changes 🛑\n\n- `signalfx` exporter (#3207):\n  - Additional metrics excluded by default by signalfx exporter\n    - system.disk.io_time\n    - system.disk.operation_time\n    - system.disk.weighted_io_time\n    - system.network.connections\n    - system.processes.count\n    - system.processes.created\n\n### 💡 Enhancements 💡\n\n- Add default config and systemd environment file support for DEB/RPM packages (#3123)\n- Log errors on receiver start/stop failures (#3208)\n- `newrelic` exporter: Update API key detection logic (#3212)\n- `splunkhec` exporter:\n  - Mark permanent errors to avoid futile retries (#3253)\n  - Add TLS certs verification (#3204)\n- `datadog` exporter:\n  - Add env and tag name normalization to trace payloads (#3200)\n  - add `ignore_resource`s configuration option (#3245)\n- `jmx` receiver: Update for latest snapshot and header support (#3283)\n- `awsxray` exporter: Added support for stack trace translation for .NET language (#3280)\n- `statsd` receiver: Add timing/histogram for statsD receiver as OTLP summary (#3261)\n\n### 🧰 Bug fixes 🧰\n\n- `awsprometheusremotewrite` exporter:\n  - Remove `sending_queue` (#3186)\n  - Use the correct default for aws_auth.service (#3161)\n  - Identify the Amazon Prometheus region from the endpoint (#3210)\n  - Don't panic in case session can't be constructed (#3221)\n- `datadog` exporter: Add max tag length (#3185)\n- `sapm` exporter: Fix crash when passing the signalfx access token (#3294)\n- `newrelic` exporter: Update error conditions (#3322)\n\n## v0.25.0\n\n# 🎉 OpenTelemetry Collector Contrib v0.25.0 (Beta) 🎉\n\nThe OpenTelemetry Collector Contrib contains everything in the [opentelemetry-collector release](https://github.com/open-telemetry/opentelemetry-collector/releases/tag/v0.25.0) (be sure to check the release notes here as well!). Check out the [Getting Started Guide](https://opentelemetry.io/docs/collector/getting-started/) for deployment and configuration information.\n\n### 🚀 New components 🚀\n\n- `kafkametricsreceiver` new receiver component for collecting metrics about a kafka cluster - primarily lag and offset. [configuration instructions](receiver/kafkametricsreceiver/README.md)\n- `file_storage` extension to read and write data to the local file system (#3087)\n\n### 🛑 Breaking changes 🛑\n\n- `newrelic` exporter (#3091):\n  - Removal of common attributes (use opentelemetry collector resource processor to add attributes)\n  - Drop support for cumulative metrics being sent to New Relic via a collector\n\n### 💡 Enhancements 💡\n\n- Update `opentelemetry-log-collection` to v0.17.0 for log receivers (#3017)\n- `datadog` exporter:\n  - Add `peer.service` priority instead of `service.name` (#2817)\n  - Improve support of semantic conventions for K8s, Azure and ECS (#2623)\n- Improve and batch logs translation for stanza (#2892)\n- `statsd` receiver: Add timing/histogram as OTLP gauge (#2973)\n- `honeycomb` exporter: Add Retry and Queue settings (#2714)\n- `resourcedetection` processor:\n  - Add AKS resource detector (#3035)\n  - Use conventions package constants for ECS detector (#3171)\n- `sumologic` exporter: Add graphite format (#2695)\n- Add trace attributes to the log entry for stanza (#3018)\n- `splunk_hec` exporter: Send log record name as part of the HEC log event (#3119)\n- `newrelic` exporter (#3091):\n  - Add support for logs\n  - Performance improvements\n  - Optimizations to the New Relic payload to reduce payload size\n  - Metrics generated for monitoring the exporter\n  - Insert Key vs License keys are auto-detected in some cases\n  - Collector version information is properly extracted via the application start info parameters\n\n### 🧰 Bug fixes 🧰\n\n- `splunk_hec` exporter: Fix sending log payload with missing the GZIP footer (#3032)\n- `awsxray` exporter: Remove propagation of error on shutdown (#2999)\n- `resourcedetection` processor:\n  - Correctly report DRAGONFLYBSD value (#3100)\n  - Fallback to `os.Hostname` when FQDN is not available (#3099)\n- `httpforwarder` extension: Do not report ErrServerClosed when shutting down the service (#3173)\n- `collectd` receiver: Do not report ErrServerClosed when shutting down the service (#3178)\n\n## v0.24.0\n\n# 🎉 OpenTelemetry Collector Contrib v0.24.0 (Beta) 🎉\n\nThe OpenTelemetry Collector Contrib contains everything in the [opentelemetry-collector release](https://github.com/open-telemetry/opentelemetry-collector/releases/tag/v0.24.0) (be sure to check the release notes here as well!). Check out the [Getting Started Guide](https://opentelemetry.io/docs/collector/getting-started/) for deployment and configuration information.\n\n### 🚀 New components 🚀\n\n- `fluentbit` extension and `fluentforward` receiver moved from opentelemetry-collector\n\n### 💡 Enhancements 💡\n\n- Check `NO_WINDOWS_SERVICE` environment variable to force interactive mode on Windows (#2819)\n- `resourcedetection `processor:\n  - Add task revision to ECS resource detector (#2814)\n  - Add GKE detector (#2821)\n  - Add Amazon EKS detector (#2820)\n  - Add `VMScaleSetName` field to Azure detector (#2890)\n- `awsemf` exporter:\n  - Add `parse_json_encoded_attr_values` config option to decode json-encoded strings in attribute values (#2827)\n  - Add `output_destination` config option to support AWS Lambda (#2720)\n- `googlecloud` exporter: Handle `cloud.availability_zone` semantic convention (#2893)\n- `newrelic` exporter: Add `instrumentation.provider` to default attributes (#2900)\n- Set unprivileged user to container image (#2925)\n- `splunkhec` exporter: Add `max_content_length_logs` config option to send log data in payloads less than max content length (#2524)\n- `k8scluster` and `kubeletstats` receiver: Replace package constants in favor of constants from conventions in core (#2996)\n\n### 🧰 Bug fixes 🧰\n\n- `spanmetrics` processor:\n  - Rename `calls` metric to `calls_total` and set `IsMonotonic` to true (#2837)\n  - Validate duplicate dimensions at start (#2844)\n- `awsemf` exporter: Calculate delta instead of rate for cumulative metrics (#2512)\n- `signalfx` exporter:\n  - Remove more unnecessary translation rules (#2889)\n  - Implement summary type (#2998)\n- `awsxray` exporter: Remove translation to HTTP status from OC status (#2978)\n- `awsprometheusremotewrite` exporter: Close HTTP body after RoundTrip (#2955)\n- `splunkhec` exporter: Add ResourceAttributes to Splunk Event (#2843)\n\n## v0.23.0\n\n# 🎉 OpenTelemetry Collector Contrib v0.23.0 (Beta) 🎉\n\nThe OpenTelemetry Collector Contrib contains everything in the [opentelemetry-collector release](https://github.com/open-telemetry/opentelemetry-collector/releases/tag/v0.23.0) (be sure to check the release notes here as well!). Check out the [Getting Started Guide](https://opentelemetry.io/docs/collector/getting-started/) for deployment and configuration information.\n\n### 🚀 New components 🚀\n\n- `groupbyattrs` processor to group the records by provided attributes\n- `dotnetdiagnostics` receiver to read metrics from .NET processes\n\n### 🛑 Breaking changes 🛑\n\n- `stackdriver` exporter marked as deprecated and renamed to `googlecloud`\n- Change the rule expression in receiver creator for matching endpoints types from `type.port`, `type.hostport` and `type.pod` to `type == \"port\"`, `type == \"hostport\"` and `type == \"pod\"` (#2661)\n\n### 💡 Enhancements 💡\n\n- `loadbalancing` exporter: Add support for logs (#2470)\n- `sumologic` exporter: Add carbon formatter (#2562)\n- `awsecscontainermetrics` receiver: Add new metric for stopped container (#2383)\n- `awsemf` exporter:\n  - Send EMF logs in batches (#2572)\n  - Add prometheus type field for CloudWatch compatibility (#2689)\n- `signalfx` exporter:\n  - Add resource attributes to events (#2631)\n  - Add translation rule to drop dimensions (#2660)\n  - Remove temporary host translation workaround (#2652)\n  - Remove unnecessary default translation rules (#2672)\n  - Update `exclude_metrics` option so that the default exclude rules can be overridden by setting the option to `[]` (#2737)\n- `awsprometheusremotewrite` exporter: Add support for given IAM roles (#2675)\n- `statsd` receiver: Change to use OpenTelemetry type instead of OpenCensus type (#2733)\n- `resourcedetection` processor: Add missing entries for `cloud.infrastructure_service` (#2777)\n\n### 🧰 Bug fixes 🧰\n\n- `dynatrace` exporter: Serialize each datapoint into separate line (#2618)\n- `splunkhec` exporter: Retain all otel attributes (#2712)\n- `newrelic` exporter: Fix default metric URL (#2739)\n- `googlecloud` exporter: Add host.name label if hostname is present in node (#2711)\n\n## v0.22.0\n\n# 🎉 OpenTelemetry Collector Contrib v0.22.0 (Beta) 🎉\n\nThe OpenTelemetry Collector Contrib contains everything in the [opentelemetry-collector release](https://github.com/open-telemetry/opentelemetry-collector/releases/tag/v0.22.0) (be sure to check the release notes here as well!). Check out the [Getting Started Guide](https://opentelemetry.io/docs/collector/getting-started/) for deployment and configuration information.\n\n### 🚀 New components 🚀\n\n- `filelog` receiver to tail and parse logs from files using the [opentelemetry-log-collection](https://github.com/open-telemetry/opentelemetry-log-collection) library\n\n### 💡 Enhancements 💡\n\n- `dynatrace` exporter: Send metrics to Dynatrace in chunks of 1000 (#2468)\n- `k8s` processor: Add ability to associate metadata tags using pod UID rather than just IP (#2199)\n- `signalfx` exporter:\n  - Add statusCode to logging field on dimension client (#2459)\n  - Add translation rules for `cpu.utilization_per_core` (#2540)\n  - Updates to metadata handling (#2531)\n  - Calculate extra network I/O metrics (#2553)\n  - Calculate extra disk I/O metrics (#2557)\n- `statsd` receiver: Add metric type label and `enable_metric_type` option (#2466)\n- `sumologic` exporter: Add support for carbon2 format (#2562)\n- `resourcedetection` processor: Add Azure detector (#2372)\n- `k8scluster` receiver: Use OTel conventions for metadata (#2530)\n- `newrelic` exporter: Multi-tenant support for sending trace data and performance enhancements (#2481)\n- `stackdriver` exporter: Enable `retry_on_failure` and `sending_queue` options (#2613)\n- Use standard way to convert from time.Time to proto Timestamp (#2548)\n\n### 🧰 Bug fixes 🧰\n\n- `signalfx` exporter:\n  - Fix calculation of `network.total` metric (#2551)\n  - Correctly convert dimensions on metadata updates (#2552)\n- `awsxray` exporter and receiver: Fix the type of content_length (#2539)\n- `resourcedetection` processor: Use values in accordance to semantic conventions for AWS (#2556)\n- `awsemf` exporter: Fix concurrency issue (#2571)\n\n## v0.21.0\n\n# 🎉 OpenTelemetry Collector Contrib v0.21.0 (Beta) 🎉\n\nThe OpenTelemetry Collector Contrib contains everything in the [opentelemetry-collector release](https://github.com/open-telemetry/opentelemetry-collector/releases/tag/v0.21.0) (be sure to check the release notes here as well!). Check out the [Getting Started Guide](https://opentelemetry.io/docs/collector/getting-started/) for deployment and configuration information.\n\n### 🚀 New components 🚀\n\n- `loki` exporter to export data via HTTP to Loki\n\n### 🛑 Breaking changes 🛑\n\n- `signalfx` exporter: Allow periods to be sent in dimension keys (#2456). Existing users who do not want to change this functionality can set `nonalphanumeric_dimension_chars` to `_-`\n\n### 💡 Enhancements 💡\n\n- `awsemf` exporter:\n  - Support unit customization before sending logs to AWS CloudWatch (#2318)\n  - Group exported metrics by labels (#2317)\n- `datadog` exporter: Add basic span events support (#2338)\n- `alibabacloudlogservice` exporter: Support new metrics interface (#2280)\n- `sumologic` exporter:\n  - Enable metrics pipeline (#2117)\n  - Add support for all types of log body (#2380)\n- `signalfx` exporter: Add `nonalphanumeric_dimension_chars` config option (#2442)\n\n### 🧰 Bug fixes 🧰\n\n- `resourcedetection` processor: Fix resource attribute environment variable (#2378)\n- `k8scluster` receiver: Fix nil pointer bug (#2450)\n\n## v0.20.0\n\n# 🎉 OpenTelemetry Collector Contrib v0.20.0 (Beta) 🎉\n\nThe OpenTelemetry Collector Contrib"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 23.0537109375,
          "content": "# Contributing\n\nIf you would like to contribute please read OpenTelemetry Collector [contributing\nguidelines](https://github.com/open-telemetry/opentelemetry-collector/blob/main/CONTRIBUTING.md) before you begin your\nwork.\n\n## Pull-requests\n\n### Title guidelines\n\nThe title for your pull-request should contain the component type and name in brackets, plus a short statement for your\nchange. For instance:\n\n    [processor/tailsampling] fix AND policy\n\n### Description guidelines\n\nWhen linking to an open issue, if your PR is meant to close said issue, please prefix your issue with one of the\nfollowing keywords: `Resolves`, `Fixes`, or `Closes`. More information on this functionality (and more keyword options) can be found\n[here](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword).\nThis will automatically close the issue once your PR has been merged.\n\n## Changelog\n\n### Overview\n\nThere are two Changelogs for this repository:\n\n- `CHANGELOG.md` is intended for users of the collector and lists changes that affect the behavior of the collector.\n- `CHANGELOG-API.md` is intended for developers who are importing packages from the collector codebase.\n\n### When to add a Changelog Entry\n\nPull requests that contain user-facing changes will require a changelog entry. Keep in mind the following types of users:\n1. Those who are consuming the telemetry exported from the collector\n2. Those who are deploying or otherwise managing the collector or its configuration\n3. Those who are depending on APIs exported from collector packages\n4. Those who are contributing to the repository\n\nChanges that affect the first two groups should be noted in `CHANGELOG.md`. Changes that affect the third or forth groups should be noted in `CHANGELOG-API.md`.\n\nIf a changelog entry is not required, a maintainer or approver will add the `Skip Changelog` label to the pull request.\n\n**Examples**\n\nChangelog entry required:\n- Changes to the configuration of the collector or any component\n- Changes to the telemetry emitted from and/or processed by the collector\n- Changes to the prerequisites or assumptions for running a collector\n- Changes to an API exported by a collector package\n- Meaningful changes to the performance of the collector\n\nJudgement call:\n- Major changes to documentation\n- Major changes to tests or test frameworks\n- Changes to developer tooling in the repo\n\nNo changelog entry:\n- Typical documentation updates\n- Refactorings with no meaningful change in functionality\n- Most changes to tests\n- Chores, such as enabling linters, or minor changes to the CI process\n\n### Adding a Changelog Entry\n\nThe [CHANGELOG.md](./CHANGELOG.md) and [CHANGELOG-API.md](./CHANGELOG-API.md) files in this repo is autogenerated from `.yaml` files in the `./.chloggen` directory.\n\nYour pull-request should add a new `.yaml` file to this directory. The name of your file must be unique since the last release.\n\nDuring the collector release process, all `./chloggen/*.yaml` files are transcribed into `CHANGELOG.md` and `CHANGELOG-API.md` and then deleted.\n\n**Recommended Steps**\n1. Create an entry file using `make chlog-new`. This generates a file based on your current branch (e.g. `./.chloggen/my-branch.yaml`)\n2. Fill in all fields in the new file\n3. Run `make chlog-validate` to ensure the new file is valid\n4. Commit and push the file\n\nAlternately, copy `./.chloggen/TEMPLATE.yaml`, or just create your file from scratch.\n\n## Portable Code\n\nIn order to ensure compatibility with different operating systems, code should be portable. Below are some guidelines to follow when writing portable code:\n\n* Avoid using platform-specific libraries, features etc. Please opt for portable multi-platform solutions. \n\n* Avoid hard-coding platform-specific values. Use environment variables or configuration files for storing platform-specific values.\n\n    For example, avoid using hard-coded file path\n    ```\n    filePath := \"C:\\Users\\Bob\\Documents\\sampleData.csv\"\n    ```\n\n    Instead environment variable or configuration file can be used.\n    ```\n    filePath := os.Getenv(\"DATA_FILE_PATH\")\n    ```\n    or\n    ```\n    filePath := Configuration.Get(\"data_file_path\")\n    ```\n\n* Be mindful of \n  - Standard file systems and file paths such as forward slashes (/) instead of backward slashes (\\\\) in Windows. Use the [`path/filepath` package](https://pkg.go.dev/path/filepath) when working with filepaths. \n  - Consistent line ending formats such as Unix (LF) or Windows (CRLF).\n\n* Test your implementation thoroughly on different platforms if possible and fix any issues. \n\nWith above guidelines, you can write code that is more portable and easier to maintain across different platforms. \n\n## Adding New Components\n\n**Before** any code is written, [open an\nissue](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/new?assignees=&labels=Sponsor+Needed%2Cneeds+triage&projects=&template=new_component.yaml&title=New+component%3A+)\nproviding the following information:\n\n* Who's the sponsor for your component. A sponsor is an approver or maintainer who will be the official reviewer of the code and a code owner\n  for the component. You will need to find a sponsor for the component in order for it to be accepted.\n* Some information about your component, such as the reasoning behind it, use-cases, telemetry data types supported, and\n  anything else you think is relevant for us to make a decision about accepting the component.\n* The configuration options your component will accept. This will give us a better understanding of what it does, and \n  how it may be implemented.\n\nComponents refer to connectors, exporters, extensions, processors, and receivers. The key criteria to implementing a component is to:\n\n* Implement the [component.Component](https://pkg.go.dev/go.opentelemetry.io/collector/component#Component) interface\n* Provide a configuration structure which defines the configuration of the component\n* Provide the implementation which performs the component operation\n* Have a `metadata.yaml` file and its generated code (using [mdatadgen](https://github.com/open-telemetry/opentelemetry-collector/blob/main/cmd/mdatagen/README.md)).\n\nFamiliarize yourself with the interface of the component that you want to write, and use existing implementations as a reference.\n[Building a Trace Receiver](https://opentelemetry.io/docs/collector/trace-receiver/) tutorial provides a detailed example of building a component.\n\n*NOTICE:* The Collector is in Beta stage and as such the interfaces may undergo breaking changes. Component creators\nmust be available to update or review their components when such changes happen, otherwise the component will be\nexcluded from the default builds.\n\nGenerally, maintenance of components is the responsibility of contributors who authored them. If the original author or\nsome other contributor does not maintain the component it may be excluded from the default build. The component **will**\nbe excluded if it causes build problems, has failing tests, or otherwise causes problems to the rest of the repository\nand its contributors.\n\n- Create your component under the proper folder and use Go standard package naming recommendations.\n- Use a boiler-plate Makefile that just references the one at top level, ie.: `include ../../Makefile.Common` - this\n  allows you to build your component with required build configurations for the contrib repo while avoiding building the\n  full repo during development.\n- Each component has its own go.mod file. This allows custom builds of the collector to take a limited sets of\n  dependencies - so run `go mod` commands as appropriate for your component.\n- Implement the needed interface on your component by importing the appropriate component from the core repo. Follow the\n  pattern of existing components regarding config and factory source files and tests.\n- Implement your component as appropriate. Provide end-to-end tests (or mock backend/client as appropriate). Target is\n  to get 80% or more of code coverage.\n- Add a README.md on the root of your component describing its configuration and usage, likely referencing some of the\n  yaml files used in the component tests. We also suggest that the yaml files used in tests have comments for all\n  available configuration settings so users can copy and modify them as needed.\n- Run `make crosslink` to update intra-repository dependencies. It will add a `replace` directive to `go.mod` file of every intra-repository dependant. This is necessary for your component to be included in the contrib executable.\n- Add your component to `versions.yaml`.\n- All components included in the distribution must be included in\n  [`cmd/otelcontribcol/builder-config.yaml`](./cmd/otelcontribcol/builder-config.yaml)\n  and in the respective testing harnesses. To align with the test goal of the\n  project, components must be testable within the framework defined within the\n  folder. If a component can not be properly tested within the existing\n  framework, it must increase the non testable components number with a comment\n  within the PR explaining as to why it can not be tested. **(Note: this does\n  not automatically include any components in official release binaries. See\n  [Releasing new components](#releasing-new-components).)**\n\n- Create a `metadata.yaml` file with at minimum the required fields defined in [metadata-schema.yaml](https://github.com/open-telemetry/opentelemetry-collector/blob/main/cmd/mdatagen/metadata-schema.yaml).\nHere is a minimal representation:\n```\ntype: <name of your component, such as apache, http, haproxy, postgresql>\n\nstatus:\n  class: <class of component, one of cmd, connector, exporter, extension, processor or receiver>\n  stability:\n    development: [<pick the signals supported: logs, metrics, traces. For extension, use \"extension\">]\n  codeowners:\n    active: [<github account of the sponsor, such as alice>, <your GitHub account if you are already an OpenTelemetry member>]\n```\n- Run `make generate-gh-issue-templates` to add your component to the dropdown list in the issue templates.\n- For README.md, you can start with the following:\n```\n# <Title of your component>\n<!-- status autogenerated section -->\n<!-- end autogenerated section -->\n```\n- Create a `doc.go` file with a generate pragma. For a `fooreceiver`, the file will look like:\n```\n// Copyright The OpenTelemetry Authors\n// SPDX-License-Identifier: Apache-2.0\n\n//go:generate mdatagen metadata.yaml\n\n// Package fooreceiver bars.\npackage fooreceiver // import \"github.com/open-telemetry/opentelemetry-collector-contrib/receiver/fooreceiver\"\n```\n- Type `make update-codeowners`. This will trigger the regeneration of the `.github/CODEOWNERS` file and the [metadata generator](https://github.com/open-telemetry/opentelemetry-collector/blob/main/cmd/mdatagen/README.md#using-the-metadata-generator) to generate the associated code/documentation.\n\nWhen submitting a component to the community, consider breaking it down into separate PRs as follows:\n\n* **First PR** should include the overall structure of the new component:\n  * Readme, configuration, and factory implementation usually using the helper\n    factory structs.\n  * This PR is usually trivial to review, so the size limit does not apply to\n    it.\n  * The component should use [`In Development` Stability](https://github.com/open-telemetry/opentelemetry-collector#development) in its README.\n  * Before submitting a PR, run the following commands from the root of the repository to ensure your new component is meeting the repo linting expectations:\n    * `make checkdoc`\n    * `make checkmetadata`\n    * `make checkapi`\n    * `make goporto`\n    * `make crosslink`\n    * `make gotidy`\n    * `make genotelcontribcol`\n    * `make genoteltestbedcol`\n    * `make generate`\n    * `make multimod-verify`\n    * `make generate-gh-issue-templates`\n    * `make addlicense`\n* **Second PR** should include the concrete implementation of the component. If the\n  size of this PR is larger than the recommended size consider splitting it in\n  multiple PRs.\n* **Last PR** should mark the new component as `Alpha` stability.\n  * Update its `metadata.yaml` file.\n    * Mark the stability as `alpha`\n    * Add `contrib` to the list of distributions\n  * Add it to the `cmd/otelcontribcol` binary by updating the `cmd/otelcontribcol/builder-config.yaml` file.\n  * Please also run:\n    - `make generate`\n    - `make genotelcontribcol`\n  * The component's tests must also be added as a part of its respective `component_type_tests.go` file in the `cmd/otelcontribcol` directory.\n  * The component must be enabled only after sufficient testing and only when it meets [`Alpha` stability requirements](https://github.com/open-telemetry/opentelemetry-collector#alpha).\n* Once your component has reached `Alpha` stability, you may also submit a PR to the [OpenTelemetry Collector Releases](https://github.com/open-telemetry/opentelemetry-collector-releases) repository to include your component in future releases of the OpenTelemetry Collector `contrib` distribution.\n* Once a new component has been added to the executable:\n  * Please add the component\n    to the [OpenTelemetry.io registry](https://github.com/open-telemetry/opentelemetry.io#adding-a-project-to-the-opentelemetry-registry).\n\n### Releasing New Components\nAfter a component has been merged it must be added to the\n[OpenTelemetry Collector Contrib's release manifest.yaml](https://github.com/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/manifest.yaml)\nto be included in the distributed otelcol-contrib binaries and docker images.\n\n## Adding metrics to existing receivers\nFollowing these steps for contributing additional metrics to existing receivers.\n - Read instructions [here](https://github.com/open-telemetry/opentelemetry-collector/blob/main/CONTRIBUTING.md#fork) on how to\n   fork, build and create PRs. The only difference is to change repository name from `opentelemetry-collector` to `opentelemetry-collector-contrib`\n - Edit `metadata.yaml` of your metrics receiver to add new metrics, e.g.: `redisreceiver/metadata.yaml`\n - To generate new metrics on top of this updated YAML file.\n   - Run `cd receiver/redisreceiver`\n   - Run `go generate ./...`\n- Review the changed files and merge the changes into your forked repo.\n- Create PR from Github web console following the instructions above.\n\n## General Recommendations\nBelow are some recommendations that apply to typical components. These are not rigid rules and there are exceptions but\nin general try to follow them.\n\n- Avoid introducing batching, retries or worker pools directly on receivers and exporters. Typically, these are general\n  cases that can be better handled via processors (that also can be reused by other receivers and exporters).\n- When implementing exporters try to leverage the exporter helpers from the core repo, see [exporterhelper\n  package](https://github.com/open-telemetry/opentelemetry-collector/tree/main/exporter/exporterhelper). This will\n  ensure that the exporter provides [zPages](https://opencensus.io/zpages/) and a standard set of metrics.\n- `replace` statements in `go.mod` files can be automatically inserted by running `make crosslink`. For more information\n  on the `crosslink` tool see the README [here](https://github.com/open-telemetry/opentelemetry-go-build-tools/tree/main/crosslink).\n\n## Issue Triaging\n\nSee [issue-triaging.md](./issue-triaging.md) for more information on the issue triaging process.\n\n### Adding Labels via Comments\n\nIn order to facilitate proper label usage and to empower Code Owners, you are able to add labels to issues via comments. To add a label through a comment, post a new comment on an issue starting with `/label`, followed by a space-separated list of your desired labels. Supported labels come from the table below, or correspond to a component defined in the [CODEOWNERS file](.github/CODEOWNERS).\n\nThe following general labels are supported:\n\n| Label                     | Label in Comment          |\n|---------------------------|---------------------------|\n| `arm64`                   | `arm64`                   |\n| `good first issue`        | `good-first-issue`        |\n| `help wanted`             | `help-wanted`             |\n| `discussion needed`       | `discussion-needed`       |\n| `needs triage`            | `needs-triage`            |\n| `os:mac`                  | `os:mac`                  |\n| `os:windows`              | `os:windows`              |\n| `waiting for author`      | `waiting-for-author`      |\n| `waiting-for-code-owners` | `waiting-for-code-owners` |\n| `bug`                     | `bug`                     |\n| `priority:p0`             | `priority:p0`             |\n| `priority:p1`             | `priority:p1`             |\n| `priority:p2`             | `priority:p2`             |\n| `priority:p3`             | `priority:p3`             |\n| `Stale`                   | `stale`                   |\n| `never stale`             | `never-stale`             |\n\nTo delete a label, prepend the label with `-`. Note that you must make a new comment to modify labels; you cannot edit an existing comment.\n\nExample label comment:\n\n```\n/label receiver/prometheus help-wanted -exporter/prometheus\n```\n\n## Membership, Roles, and Responsibilities\n\n### Membership levels\n\nSee the [OpenTelemetry membership guide](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md) for information on how to become a member of the OpenTelemetry organization and the different roles available. In addition to the roles listed there we also have a Collector-specific role: code owners.\n\n### Becoming a Code Owner\n\nA Code Owner is responsible for a component within Collector Contrib, as indicated by the [CODEOWNERS file](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/.github/CODEOWNERS). That responsibility includes maintaining the component, triaging and responding to issues, and reviewing pull requests.\n\nSometimes a component may be in need of a new or additional Code Owner. A few reasons this situation may arise would be:\n\n- The existing Code Owners are actively looking for more help.\n- A previous Code Owner stepped down.\n- An existing Code Owner has become unresponsive. See [unmaintained stability status](https://github.com/open-telemetry/opentelemetry-collector#unmaintained).\n- The component was never assigned a Code Owner.\n\nCode Ownership does not have to be a full-time job. If you can find a couple hours to help out on a recurring basis, please consider pursuing Code Ownership.\n\n#### Requirements\n\nIf you would like to help and become a Code Owner you must meet the following requirements:\n\n1. [Be a member of the OpenTelemetry organization.](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#member)\n2. (Code Owner Discretion) It is best to have resolved an issue related to the component, contributed directly to the component, and/or review component PRs. How much interaction with the component is required before becoming a Code Owner is up to any existing Code Owners.\n\nCode Ownership is ultimately up to the judgement of the existing Code Owners and Collector Contrib Maintainers. Meeting the above requirements is not a guarantee to be granted Code Ownership.\n\n#### How to become a Code Owner\n\nTo become a Code Owner, open a PR with the following changes:\n\n1. Add your GitHub username to the active codeowners entry in the component's `metadata.yaml` file.\n2. Run the command `make update-codeowners`.\n      * Note: A GitHub [personal access token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens) must be configured for this command to work.\n      * If this command is unsuccessful, manually update the component's row in the [CODEOWNERS](.github/CODEOWNERS) file, and then run `make generate` to regenerate the component's README header.\n\nBe sure to tag the existing Code Owners, if any, within the PR to ensure they receive a notification.\n\n### Emeritus roles\n\nContributors who are unable to meet the responsibilities of their role are encouraged to move to [emeritus](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager). In case of long temporary absences, contributors are encouraged to let maintainers know on the CNCF Slack (e.g. on the #otel-collector-dev channel or privately via DM) and to mark themselves as 'Busy' on Github.\n\nIn the event that a contributor becomes inactive without prior notice, the maintainers will attempt to contact the contributor via both Github and the CNCF Slack to confirm their status. After two weeks, if the contributor is an approver or maintainer, they may be removed from the Github review auto-assignment.\n\nIf the contributor does not respond within a period of two months, they may be moved to emeritus status at the discretion of the maintainers, following a majority vote among the maintainers (possibly excluding the contributor in question).\n\n## Makefile Guidelines\n\nWhen adding or modifying the `Makefile`'s in this repository, consider the following design guidelines.\n\nMake targets are organized according to whether they apply to the entire repository, or only to an individual module.\nThe [Makefile](./Makefile) SHOULD contain \"repo-level\" targets. (i.e. targets that apply to the entire repo.)\nLikewise, `Makefile.Common` SHOULD contain \"module-level\" targets. (i.e. targets that apply to one module at a time.)\nEach module should have a `Makefile` at its root that includes `Makefile.Common`.\n\n### Module-level targets\n\nModule-level targets SHOULD NOT act on nested modules. For example, running `make lint` at the root of the repo will\n*only* evaluate code that is part of the `go.opentelemetry.io/collector` module. This excludes nested modules such as\n`go.opentelemetry.io/collector/component`.\n\nEach module-level target SHOULD have a corresponding repo-level target. For example, `make golint` will run `make lint`\nin each module. In this way, the entire repository is covered. The root `Makefile` contains some \"for each module\" targets\nthat can wrap a module-level target into a repo-level target.\n\n### Repo-level targets\n\nWhenever reasonable, targets SHOULD be implemented as module-level targets (and wrapped with a repo-level target).\nHowever, there are many valid justifications for implementing a standalone repo-level target.\n\n1. The target naturally applies to the repo as a whole. (e.g. Building the collector.)\n2. Interaction between modules would be problematic.\n3. A necessary tool does not provide a mechanism for scoping its application. (e.g. `porto` cannot be limited to a specific module.)\n4. The \"for each module\" pattern would result in incomplete coverage of the codebase. (e.g. A target that scans all file, not just `.go` files.)\n\n### Default targets\n\nThe default module-level target (i.e. running `make` in the context of an individual module), should run a substantial set of module-level\ntargets for an individual module. Ideally, this would include *all* module-level targets, but exceptions should be made if a particular\ntarget would result in unacceptable latency in the local development loop.\n\nThe default repo-level target (i.e. running `make` at the root of the repo) should meaningfully validate the entire repo. This should include\nrunning the default common target for each module as well as additional repo-level targets.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 20.1611328125,
          "content": "include ./Makefile.Common\n\nRUN_CONFIG?=local/config.yaml\nCMD?=\nOTEL_VERSION=main\nOTEL_STABLE_VERSION=main\n\nVERSION=$(shell git describe --always --match \"v[0-9]*\" HEAD)\nTRIMMED_VERSION=$(shell grep -o 'v[^-]*' <<< \"$(VERSION)\" | cut -c 2-)\nCORE_VERSIONS=$(SRC_PARENT_DIR)/opentelemetry-collector/versions.yaml\nGOMOD=$(SRC_ROOT)/cmd/otelcontribcol/go.mod\n\nCOMP_REL_PATH=cmd/otelcontribcol/components.go\nMOD_NAME=github.com/open-telemetry/opentelemetry-collector-contrib\n\nGROUP ?= all\nFOR_GROUP_TARGET=for-$(GROUP)-target\n\nFIND_MOD_ARGS=-type f -name \"go.mod\"\nTO_MOD_DIR=dirname {} \\; | sort | grep -E '^./'\nEX_COMPONENTS=-not -path \"./receiver/*\" -not -path \"./processor/*\" -not -path \"./exporter/*\" -not -path \"./extension/*\" -not -path \"./connector/*\"\nEX_INTERNAL=-not -path \"./internal/*\"\nEX_PKG=-not -path \"./pkg/*\"\nEX_CMD=-not -path \"./cmd/*\"\n\n# NONROOT_MODS includes ./* dirs (excludes . dir)\nNONROOT_MODS := $(shell find . $(FIND_MOD_ARGS) -exec $(TO_MOD_DIR) )\n\nRECEIVER_MODS_0 := $(shell find ./receiver/[a-f]* $(FIND_MOD_ARGS) -exec $(TO_MOD_DIR) )\nRECEIVER_MODS_1 := $(shell find ./receiver/[g-o]* $(FIND_MOD_ARGS) -exec $(TO_MOD_DIR) )\nRECEIVER_MODS_2 := $(shell find ./receiver/[p]* $(FIND_MOD_ARGS) -exec $(TO_MOD_DIR) ) # Prometheus is special and gets its own section.\nRECEIVER_MODS_3 := $(shell find ./receiver/[q-z]* $(FIND_MOD_ARGS) -exec $(TO_MOD_DIR) )\nRECEIVER_MODS := $(RECEIVER_MODS_0) $(RECEIVER_MODS_1) $(RECEIVER_MODS_2) $(RECEIVER_MODS_3)\nPROCESSOR_MODS_0 := $(shell find ./processor/[a-o]* $(FIND_MOD_ARGS) -exec $(TO_MOD_DIR) )\nPROCESSOR_MODS_1 := $(shell find ./processor/[p-z]* $(FIND_MOD_ARGS) -exec $(TO_MOD_DIR) )\nPROCESSOR_MODS := $(PROCESSOR_MODS_0) $(PROCESSOR_MODS_1)\nEXPORTER_MODS_0 := $(shell find ./exporter/[a-m]* $(FIND_MOD_ARGS) -exec $(TO_MOD_DIR) )\nEXPORTER_MODS_1 := $(shell find ./exporter/[n-z]* $(FIND_MOD_ARGS) -exec $(TO_MOD_DIR) )\nEXPORTER_MODS := $(EXPORTER_MODS_0) $(EXPORTER_MODS_1)\nEXPORTER_MODS_0 := $(shell find ./exporter/[a-c]* $(FIND_MOD_ARGS) -exec $(TO_MOD_DIR) )\nEXPORTER_MODS_1 := $(shell find ./exporter/[d-i]* $(FIND_MOD_ARGS) -exec $(TO_MOD_DIR) )\nEXPORTER_MODS_2 := $(shell find ./exporter/[k-o]* $(FIND_MOD_ARGS) -exec $(TO_MOD_DIR) )\nEXPORTER_MODS_3 := $(shell find ./exporter/[p-z]* $(FIND_MOD_ARGS) -exec $(TO_MOD_DIR) )\nEXPORTER_MODS := $(EXPORTER_MODS_0) $(EXPORTER_MODS_1) $(EXPORTER_MODS_2) $(EXPORTER_MODS_3)\nEXTENSION_MODS := $(shell find ./extension/* $(FIND_MOD_ARGS) -exec $(TO_MOD_DIR) )\nCONNECTOR_MODS := $(shell find ./connector/* $(FIND_MOD_ARGS) -exec $(TO_MOD_DIR) )\nINTERNAL_MODS := $(shell find ./internal/* $(FIND_MOD_ARGS) -exec $(TO_MOD_DIR) )\nPKG_MODS := $(shell find ./pkg/* $(FIND_MOD_ARGS) -exec $(TO_MOD_DIR) )\nCMD_MODS_0 := $(shell find ./cmd/[a-m]* $(FIND_MOD_ARGS) -exec $(TO_MOD_DIR) )\nCMD_MODS_1 := $(shell find ./cmd/[n-z]* $(FIND_MOD_ARGS) -not -path \"./cmd/otel*col/*\" -exec $(TO_MOD_DIR) )\nCMD_MODS := $(CMD_MODS_0) $(CMD_MODS_1)\nOTHER_MODS := $(shell find . $(EX_COMPONENTS) $(EX_INTERNAL) $(EX_PKG) $(EX_CMD) $(FIND_MOD_ARGS) -exec $(TO_MOD_DIR) ) $(PWD)\nALL_MODS := $(RECEIVER_MODS) $(PROCESSOR_MODS) $(EXPORTER_MODS) $(EXTENSION_MODS) $(CONNECTOR_MODS) $(INTERNAL_MODS) $(PKG_MODS) $(CMD_MODS) $(OTHER_MODS)\nCGO_MODS := ./receiver/hostmetricsreceiver\n\nFIND_INTEGRATION_TEST_MODS={ find . -type f -name \"*integration_test.go\" & find . -type f -name \"*e2e_test.go\" -not -path \"./testbed/*\"; }\nINTEGRATION_MODS := $(shell $(FIND_INTEGRATION_TEST_MODS) | xargs $(TO_MOD_DIR) | uniq)\n\nifeq ($(GOOS),windows)\n\tEXTENSION := .exe\nendif\n\n.DEFAULT_GOAL := all\n\nall-modules:\n\t@echo $(NONROOT_MODS) | tr ' ' '\\n' | sort\n\nall-groups:\n\t@echo \"receiver-0: $(RECEIVER_MODS_0)\"\n\t@echo \"\\nreceiver-1: $(RECEIVER_MODS_1)\"\n\t@echo \"\\nreceiver-2: $(RECEIVER_MODS_2)\"\n\t@echo \"\\nreceiver-3: $(RECEIVER_MODS_3)\"\n\t@echo \"\\nreceiver: $(RECEIVER_MODS)\"\n\t@echo \"\\nprocessor-0: $(PROCESSOR_MODS_0)\"\n\t@echo \"\\nprocessor-1: $(PROCESSOR_MODS_1)\"\n\t@echo \"\\nprocessor: $(PROCESSOR_MODS)\"\n\t@echo \"\\nexporter-0: $(EXPORTER_MODS_0)\"\n\t@echo \"\\nexporter-1: $(EXPORTER_MODS_1)\"\n\t@echo \"\\nexporter-2: $(EXPORTER_MODS_2)\"\n\t@echo \"\\nexporter-3: $(EXPORTER_MODS_3)\"\n\t@echo \"\\nextension: $(EXTENSION_MODS)\"\n\t@echo \"\\nconnector: $(CONNECTOR_MODS)\"\n\t@echo \"\\ninternal: $(INTERNAL_MODS)\"\n\t@echo \"\\npkg: $(PKG_MODS)\"\n\t@echo \"\\ncmd-0: $(CMD_MODS_0)\"\n\t@echo \"\\ncmd-1: $(CMD_MODS_1)\"\n\t@echo \"\\nother: $(OTHER_MODS)\"\n\n.PHONY: all\nall: install-tools all-common goporto multimod-verify gotest otelcontribcol\n\n.PHONY: all-common\nall-common:\n\t@$(MAKE) $(FOR_GROUP_TARGET) TARGET=\"common\"\n\n.PHONY: e2e-test\ne2e-test: otelcontribcol oteltestbedcol\n\t$(MAKE) --no-print-directory -C testbed run-tests\n\n.PHONY: integration-test\nintegration-test:\n\t@$(MAKE) for-integration-target TARGET=\"mod-integration-test\"\n\n.PHONY: integration-tests-with-cover\nintegration-tests-with-cover:\n\t@$(MAKE) for-integration-target TARGET=\"do-integration-tests-with-cover\"\n\n# Long-running e2e tests\n.PHONY: stability-tests\nstability-tests: otelcontribcol\n\t@echo Stability tests are disabled until we have a stable performance environment.\n\t@echo To enable the tests replace this echo by $(MAKE) -C testbed run-stability-tests\n\n.PHONY: gogci\ngogci:\n\t$(MAKE) $(FOR_GROUP_TARGET) TARGET=\"gci\"\n\n.PHONY: gotidy\ngotidy:\n\t$(MAKE) $(FOR_GROUP_TARGET) TARGET=\"tidy\"\n\n.PHONY: remove-toolchain\nremove-toolchain:\n\t$(MAKE) $(FOR_GROUP_TARGET) TARGET=\"toolchain\"\n\n.PHONY: gomoddownload\ngomoddownload:\n\t$(MAKE) $(FOR_GROUP_TARGET) TARGET=\"moddownload\"\n\n.PHONY: gotest\ngotest:\n\t$(MAKE) $(FOR_GROUP_TARGET) TARGET=\"test\"\n\n.PHONY: gotest-with-cover\ngotest-with-cover:\n\t@$(MAKE) $(FOR_GROUP_TARGET) TARGET=\"test-with-cover\"\n\t$(GOCMD) tool covdata textfmt -i=./coverage/unit -o ./$(GROUP)-coverage.txt\n\n.PHONY: gobuildtest\ngobuildtest:\n\t$(MAKE) $(FOR_GROUP_TARGET) TARGET=\"buildtest\"\n\n.PHONY: gorunbuilttest\ngorunbuilttest:\n\t$(MAKE) $(FOR_GROUP_TARGET) TARGET=\"runbuilttest\"\n\n.PHONY: gointegration-test\ngointegration-test:\n\t$(MAKE) $(FOR_GROUP_TARGET) TARGET=\"mod-integration-test\"\n\n.PHONY: gofmt\ngofmt:\n\t$(MAKE) $(FOR_GROUP_TARGET) TARGET=\"fmt\"\n\n.PHONY: golint\ngolint:\n\t$(MAKE) $(FOR_GROUP_TARGET) TARGET=\"lint\"\n\n.PHONY: gogovulncheck\ngogovulncheck:\n\t$(MAKE) $(FOR_GROUP_TARGET) TARGET=\"govulncheck\"\n\n.PHONY: gotestifylint\ngotestifylint:\n\t$(MAKE) $(FOR_GROUP_TARGET) TARGET=\"testifylint\"\n\n.PHONY: gotestifylint-fix\ngotestifylint-fix:\n\t$(MAKE) $(FOR_GROUP_TARGET) TARGET=\"testifylint-fix\"\n\n.PHONY: goporto\ngoporto: $(PORTO)\n\t$(PORTO) -w --include-internal --skip-dirs \"^cmd$$\" ./\n\n.PHONY: for-all\nfor-all:\n\t@echo \"running $${CMD} in root\"\n\t@$${CMD}\n\t@set -e; for dir in $(NONROOT_MODS); do \\\n\t  (cd \"$${dir}\" && \\\n\t  \techo \"running $${CMD} in $${dir}\" && \\\n\t \t$${CMD} ); \\\n\tdone\n\nCOMMIT?=HEAD\nMODSET?=contrib-core\nREMOTE?=git@github.com:open-telemetry/opentelemetry-collector-contrib.git\n.PHONY: push-tags\npush-tags: $(MULTIMOD)\n\t$(MULTIMOD) verify\n\tset -e; for tag in `$(MULTIMOD) tag -m ${MODSET} -c ${COMMIT} --print-tags | grep -v \"Using\" `; do \\\n\t\techo \"pushing tag $${tag}\"; \\\n\t\tgit push ${REMOTE} $${tag}; \\\n\tdone;\n\n# Define a delegation target for each module\n.PHONY: $(ALL_MODS)\n$(ALL_MODS):\n\t@echo \"Running target '$(TARGET)' in module '$@' as part of group '$(GROUP)'\"\n\t$(MAKE) --no-print-directory -C $@ $(TARGET)\n\n# Trigger each module's delegation target\n.PHONY: for-all-target\nfor-all-target: $(ALL_MODS)\n\n.PHONY: for-receiver-target\nfor-receiver-target: $(RECEIVER_MODS)\n\n.PHONY: for-receiver-0-target\nfor-receiver-0-target: $(RECEIVER_MODS_0)\n\n.PHONY: for-receiver-1-target\nfor-receiver-1-target: $(RECEIVER_MODS_1)\n\n.PHONY: for-receiver-2-target\nfor-receiver-2-target: $(RECEIVER_MODS_2)\n\n.PHONY: for-receiver-3-target\nfor-receiver-3-target: $(RECEIVER_MODS_3)\n\n.PHONY: for-processor-target\nfor-processor-target: $(PROCESSOR_MODS)\n\n.PHONY: for-processor-0-target\nfor-processor-0-target: $(PROCESSOR_MODS_0)\n\n.PHONY: for-processor-1-target\nfor-processor-1-target: $(PROCESSOR_MODS_1)\n\n.PHONY: for-exporter-target\nfor-exporter-target: $(EXPORTER_MODS)\n\n.PHONY: for-exporter-0-target\nfor-exporter-0-target: $(EXPORTER_MODS_0)\n\n.PHONY: for-exporter-1-target\nfor-exporter-1-target: $(EXPORTER_MODS_1)\n\n.PHONY: for-exporter-2-target\nfor-exporter-2-target: $(EXPORTER_MODS_2)\n\n.PHONY: for-exporter-3-target\nfor-exporter-3-target: $(EXPORTER_MODS_3)\n\n.PHONY: for-extension-target\nfor-extension-target: $(EXTENSION_MODS)\n\n.PHONY: for-connector-target\nfor-connector-target: $(CONNECTOR_MODS)\n\n.PHONY: for-internal-target\nfor-internal-target: $(INTERNAL_MODS)\n\n.PHONY: for-pkg-target\nfor-pkg-target: $(PKG_MODS)\n\n.PHONY: for-cmd-target\nfor-cmd-target: $(CMD_MODS)\n\n.PHONY: for-cmd-0-target\nfor-cmd-0-target: $(CMD_MODS_0)\n\n.PHONY: for-cmd-1-target\nfor-cmd-1-target: $(CMD_MODS_1)\n\n.PHONY: for-other-target\nfor-other-target: $(OTHER_MODS)\n\n.PHONY: for-integration-target\nfor-integration-target: $(INTEGRATION_MODS)\n\n.PHONY: for-cgo-target\nfor-cgo-target: $(CGO_MODS)\n\n# Debugging target, which helps to quickly determine whether for-all-target is working or not.\n.PHONY: all-pwd\nall-pwd:\n\t$(MAKE) $(FOR_GROUP_TARGET) TARGET=\"pwd\"\n\n.PHONY: run\nrun:\n\tcd ./cmd/otelcontribcol && GO111MODULE=on $(GOCMD) run --race . --config ../../${RUN_CONFIG} ${RUN_ARGS}\n\n.PHONY: docker-component # Not intended to be used directly\ndocker-component: check-component\n\tGOOS=linux GOARCH=amd64 $(MAKE) $(COMPONENT)\n\tcp ./bin/$(COMPONENT)_linux_amd64 ./cmd/$(COMPONENT)/$(COMPONENT)\n\tdocker build -t $(COMPONENT) ./cmd/$(COMPONENT)/\n\trm ./cmd/$(COMPONENT)/$(COMPONENT)\n\n.PHONY: check-component\ncheck-component:\nifndef COMPONENT\n\t$(error COMPONENT variable was not defined)\nendif\n\n.PHONY: docker-otelcontribcol\ndocker-otelcontribcol:\n\tCOMPONENT=otelcontribcol $(MAKE) docker-component\n\n.PHONY: docker-telemetrygen\ndocker-telemetrygen:\n\tGOOS=linux GOARCH=$(GOARCH) $(MAKE) telemetrygen\n\tcp bin/telemetrygen_* cmd/telemetrygen/\n\tcd cmd/telemetrygen && docker build --platform linux/$(GOARCH) --build-arg=\"TARGETOS=$(GOOS)\" --build-arg=\"TARGETARCH=$(GOARCH)\" -t telemetrygen:latest .\n\trm cmd/telemetrygen/telemetrygen_*\n\n.PHONY: generate\ngenerate: install-tools\n\tPATH=\"$$PWD/.tools:$$PATH\" $(MAKE) for-all CMD=\"$(GOCMD) generate ./...\"\n\t$(MAKE) gofmt\n\n.PHONY: githubgen-install\ngithubgen-install:\n\tcd cmd/githubgen && $(GOCMD) install .\n\n.PHONY: gengithub\ngengithub: githubgen-install\n\tgithubgen\n\n.PHONY: gendistributions\ngendistributions: githubgen-install\n\tgithubgen distributions\n\n.PHONY: update-codeowners\nupdate-codeowners: gengithub generate\n\nFILENAME?=$(shell git branch --show-current)\n.PHONY: chlog-new\nchlog-new: $(CHLOGGEN)\n\t$(CHLOGGEN) new --config $(CHLOGGEN_CONFIG) --filename $(FILENAME)\n\n.PHONY: chlog-validate\nchlog-validate: $(CHLOGGEN)\n\t$(CHLOGGEN) validate --config $(CHLOGGEN_CONFIG)\n\n.PHONY: chlog-preview\nchlog-preview: $(CHLOGGEN)\n\t$(CHLOGGEN) update --config $(CHLOGGEN_CONFIG) --dry\n\n.PHONY: chlog-update\nchlog-update: $(CHLOGGEN)\n\t$(CHLOGGEN) update --config $(CHLOGGEN_CONFIG) --version $(VERSION)\n\n.PHONY: genotelcontribcol\ngenotelcontribcol: $(BUILDER)\n\t$(BUILDER) --skip-compilation --config cmd/otelcontribcol/builder-config.yaml --output-path cmd/otelcontribcol\n\n# Build the Collector executable.\n.PHONY: otelcontribcol\notelcontribcol: genotelcontribcol\n\tcd ./cmd/otelcontribcol && GO111MODULE=on CGO_ENABLED=0 $(GOCMD) build -trimpath -o ../../bin/otelcontribcol_$(GOOS)_$(GOARCH)$(EXTENSION) \\\n\t\t-tags $(GO_BUILD_TAGS) .\n\n# Build the Collector executable without the symbol table, debug information, and the DWARF symbol table.\n.PHONY: otelcontribcollite\notelcontribcollite: genotelcontribcol\n\tcd ./cmd/otelcontribcol && GO111MODULE=on CGO_ENABLED=0 $(GOCMD) build -trimpath -o ../../bin/otelcontribcol_$(GOOS)_$(GOARCH)$(EXTENSION) \\\n\t\t-tags $(GO_BUILD_TAGS) -ldflags $(GO_BUILD_LDFLAGS) .\n\n.PHONY: genoteltestbedcol\ngenoteltestbedcol: $(BUILDER)\n\t$(BUILDER) --skip-compilation --config cmd/oteltestbedcol/builder-config.yaml --output-path cmd/oteltestbedcol\n\n# Build the Collector executable, with only components used in testbed.\n.PHONY: oteltestbedcol\noteltestbedcol: genoteltestbedcol\n\tcd ./cmd/oteltestbedcol && GO111MODULE=on CGO_ENABLED=0 $(GOCMD) build -trimpath -o ../../bin/oteltestbedcol_$(GOOS)_$(GOARCH)$(EXTENSION) \\\n\t\t-tags $(GO_BUILD_TAGS) .\n\n.PHONY: oteltestbedcollite\noteltestbedcollite: genoteltestbedcol\n\tcd ./cmd/oteltestbedcol && GO111MODULE=on CGO_ENABLED=0 $(GOCMD) build -trimpath -o ../../bin/oteltestbedcol_$(GOOS)_$(GOARCH)$(EXTENSION) \\\n\t\t-tags $(GO_BUILD_TAGS) -ldflags $(GO_BUILD_LDFLAGS) .\n\n# Build the telemetrygen executable.\n.PHONY: telemetrygen\ntelemetrygen:\n\tcd ./cmd/telemetrygen && GO111MODULE=on CGO_ENABLED=0 $(GOCMD) build -trimpath -o ../../bin/telemetrygen_$(GOOS)_$(GOARCH)$(EXTENSION) \\\n\t\t-tags $(GO_BUILD_TAGS) .\n\n.PHONY: telemetrygenlite\ntelemetrygenlite:\n\tcd ./cmd/telemetrygen && GO111MODULE=on CGO_ENABLED=0 $(GOCMD) build -trimpath -o ../../bin/telemetrygen_$(GOOS)_$(GOARCH)$(EXTENSION) \\\n\t\t-tags $(GO_BUILD_TAGS) -ldflags $(GO_BUILD_LDFLAGS) .\n\n# helper function to update the core packages in builder-config.yaml\n# input parameters are\n# $(1) = path/to/versions.yaml (where it greps the relevant packages)\n# $(2) = path/to/go.mod (where it greps the package-versions)\n# $(3) = path/to/builder-config.yaml (where we want to update the versions)\ndefine updatehelper\n\tif [ ! -f $(1) ] || [ ! -f $(2) ] || [ ! -f $(3) ]; then \\\n\t\t\techo \"Usage: updatehelper <versions.yaml> <go.mod> <builder-config.yaml>\"; \\\n\t\t\texit 1; \\\n\tfi\n\tgrep \"go\\.opentelemetry\\.io\" $(1) | sed 's/^[[:space:]]*-[[:space:]]*//' | while IFS= read -r line; do \\\n\t\t\tif grep -qF \"$$line\" $(2); then \\\n\t\t\t\t\tpackage=$$(grep -F \"$$line\" $(2) | head -n 1 | awk '{print $$1}'); \\\n\t\t\t\t\tversion=$$(grep -F \"$$line\" $(2) | head -n 1 | awk '{print $$2}'); \\\n\t\t\t\t\tbuilder_package=$$(grep -F \"$$package\" $(3) | awk '{print $$3}'); \\\n\t\t\t\t\tbuilder_version=$$(grep -F \"$$package\" $(3) | awk '{print $$4}'); \\\n\t\t\t\t\tif [ \"$$builder_package\" == \"$$package\" ]; then \\\n\t\t\t\t\t\tsed -i.bak -e \"s|$$builder_package.*$$builder_version|$$builder_package $$version|\" $(3); \\\n\t\t\t\t\t\trm $(3).bak; \\\n\t\t\t\t\t\techo \"[$(3)]: $$package updated from $$builder_version to $$version\"; \\\n\t\t\t\t\tfi; \\\n\t\t\tfi; \\\n\tdone\nendef\n\n\n.PHONY: update-otel\nupdate-otel:$(MULTIMOD)\n\t$(MULTIMOD) sync -s=true -o ../opentelemetry-collector -m stable --commit-hash $(OTEL_STABLE_VERSION)\n\tgit add . && git commit -s -m \"[chore] multimod update stable modules\" ; \\\n\t$(MULTIMOD) sync -s=true -o ../opentelemetry-collector -m beta --commit-hash $(OTEL_VERSION)\n\tgit add . && git commit -s -m \"[chore] multimod update beta modules\" ; \\\n\t$(MAKE) gotidy\n\t$(call updatehelper,$(CORE_VERSIONS),$(GOMOD),./cmd/otelcontribcol/builder-config.yaml)\n\t$(call updatehelper,$(CORE_VERSIONS),$(GOMOD),./cmd/oteltestbedcol/builder-config.yaml)\n\t$(MAKE) genotelcontribcol\n\t$(MAKE) genoteltestbedcol\n\t$(MAKE) generate\n\t$(MAKE) crosslink\n\t$(MAKE) remove-toolchain\n\tgit add . && git commit -s -m \"[chore] mod and toolchain tidy\" ; \\\n\n.PHONY: otel-from-tree\notel-from-tree:\n\t# This command allows you to make changes to your local checkout of otel core and build\n\t# contrib against those changes without having to push to github and update a bunch of\n\t# references. The workflow is:\n\t#\n\t# 1. Hack on changes in core (assumed to be checked out in ../opentelemetry-collector from this directory)\n\t# 2. Run `make otel-from-tree` (only need to run it once to remap go modules)\n\t# 3. You can now build contrib and it will use your local otel core changes.\n\t# 4. Before committing/pushing your contrib changes, undo by running `make otel-from-lib`.\n\t$(MAKE) for-all CMD=\"$(GOCMD) mod edit -replace go.opentelemetry.io/collector=$(SRC_PARENT_DIR)/opentelemetry-collector\"\n\n.PHONY: otel-from-lib\notel-from-lib:\n\t# Sets opentelemetry core to be not be pulled from local source tree. (Undoes otel-from-tree.)\n\t$(MAKE) for-all CMD=\"$(GOCMD) mod edit -dropreplace go.opentelemetry.io/collector\"\n\n.PHONY: build-examples\nbuild-examples:\n\tdocker compose -f examples/demo/docker-compose.yaml build\n\tcd examples/secure-tracing/certs && $(MAKE) clean && $(MAKE) all && docker compose -f ../docker-compose.yaml build\n\tdocker compose -f exporter/splunkhecexporter/example/docker-compose.yml build\n\n.PHONY: deb-rpm-package\n%-package: ARCH ?= amd64\n%-package:\n\tGOOS=linux GOARCH=$(ARCH) $(MAKE) otelcontribcol\n\tdocker build -t otelcontribcol-fpm internal/buildscripts/packaging/fpm\n\tdocker run --rm -v $(CURDIR):/repo -e PACKAGE=$* -e VERSION=$(VERSION) -e ARCH=$(ARCH) otelcontribcol-fpm\n\n# Verify existence of READMEs for components specified as default components in the collector.\n.PHONY: checkdoc\ncheckdoc: $(CHECKFILE)\n\t$(CHECKFILE) --project-path $(CURDIR) --component-rel-path $(COMP_REL_PATH) --module-name $(MOD_NAME) --file-name \"README.md\"\n\n# Verify existence of metadata.yaml for components specified as default components in the collector.\n.PHONY: checkmetadata\ncheckmetadata: $(CHECKFILE)\n\t$(CHECKFILE) --project-path $(CURDIR) --component-rel-path $(COMP_REL_PATH) --module-name $(MOD_NAME) --file-name \"metadata.yaml\"\n\n.PHONY: checkapi\ncheckapi:\n\t$(GOCMD) run cmd/checkapi/main.go .\n\n.PHONY: kind-ready\nkind-ready:\n\t@if [ -n \"$(shell kind get clusters -q)\" ]; then echo \"kind is ready\"; else echo \"kind not ready\"; exit 1; fi\n\n.PHONY: kind-build\nkind-build: kind-ready docker-otelcontribcol\n\tdocker tag otelcontribcol otelcontribcol-dev:0.0.1\n\tkind load docker-image otelcontribcol-dev:0.0.1\n\n.PHONY: kind-install-daemonset\nkind-install-daemonset: kind-ready kind-uninstall-daemonset## Install a local Collector version into the cluster.\n\t@echo \"Installing daemonset collector\"\n\thelm install daemonset-collector-dev open-telemetry/opentelemetry-collector --values ./examples/kubernetes/daemonset-collector-dev.yaml\n\n.PHONY: kind-uninstall-daemonset\nkind-uninstall-daemonset: kind-ready\n\t@echo \"Uninstalling daemonset collector\"\n\thelm uninstall --ignore-not-found daemonset-collector-dev\n\n.PHONY: kind-install-deployment\nkind-install-deployment: kind-ready kind-uninstall-deployment## Install a local Collector version into the cluster.\n\t@echo \"Installing deployment collector\"\n\thelm install deployment-collector-dev open-telemetry/opentelemetry-collector --values ./examples/kubernetes/deployment-collector-dev.yaml\n\n.PHONY: kind-uninstall-deployment\nkind-uninstall-deployment: kind-ready\n\t@echo \"Uninstalling deployment collector\"\n\thelm uninstall --ignore-not-found deployment-collector-dev\n\n.PHONY: all-checklinks\nall-checklinks:\n\t$(MAKE) $(FOR_GROUP_TARGET) TARGET=\"checklinks\"\n\n# Function to execute a command. Note the empty line before endef to make sure each command\n# gets executed separately instead of concatenated with previous one.\n# Accepts command to execute as first parameter.\ndefine exec-command\n$(1)\n\nendef\n\n# List of directories where certificates are stored for unit tests.\nCERT_DIRS := receiver/sapmreceiver/testdata \\\n             receiver/signalfxreceiver/testdata \\\n             receiver/splunkhecreceiver/testdata \\\n             receiver/mongodbatlasreceiver/testdata/alerts/cert \\\n             receiver/mongodbreceiver/testdata/certs \\\n             receiver/cloudflarereceiver/testdata/cert\n\n# Generate certificates for unit tests relying on certificates.\n.PHONY: certs\ncerts:\n\t$(foreach dir, $(CERT_DIRS), $(call exec-command, @internal/buildscripts/gen-certs.sh -o $(dir)))\n\n.PHONY: multimod-verify\nmultimod-verify: $(MULTIMOD)\n\t@echo \"Validating versions.yaml\"\n\t$(MULTIMOD) verify\n\n.PHONY: multimod-prerelease\nmultimod-prerelease: $(MULTIMOD)\n\t$(MULTIMOD) prerelease -s=true -b=false -v ./versions.yaml -m contrib-base\n\t$(MAKE) gotidy\n\n.PHONY: multimod-sync\nmultimod-sync: $(MULTIMOD)\n\t$(MULTIMOD) sync -a=true -s=true -o ../opentelemetry-collector\n\t$(MAKE) gotidy\n\n.PHONY: crosslink\ncrosslink: $(CROSSLINK)\n\t@echo \"Executing crosslink\"\n\t$(CROSSLINK) --root=$(shell pwd) --prune\n\n.PHONY: clean\nclean:\n\t@echo \"Removing coverage files\"\n\tfind . -type f -name 'coverage.txt' -delete\n\tfind . -type f -name 'coverage.html' -delete\n\tfind . -type f -name 'coverage.out' -delete\n\tfind . -type f -name 'integration-coverage.txt' -delete\n\tfind . -type f -name 'integration-coverage.html' -delete\n\t@echo \"Removing built binary files\"\n\tfind . -type f -name 'builtunitetest.test' -delete\n\n.PHONY: generate-gh-issue-templates\ngenerate-gh-issue-templates:\n\tcd cmd/githubgen && $(GOCMD) install .\n\tgithubgen issue-templates\n\n.PHONY: checks\nchecks:\n\t$(MAKE) checkdoc\n\t$(MAKE) checkmetadata\n\t$(MAKE) checkapi\n\t$(MAKE) -j4 goporto\n\t$(MAKE) crosslink\n\t$(MAKE) -j4 gotidy\n\t$(MAKE) genotelcontribcol\n\t$(MAKE) genoteltestbedcol\n\t$(MAKE) gendistributions\n\t$(MAKE) -j4 generate\n\t$(MAKE) multimod-verify\n\tgit diff --exit-code || (echo 'Some files need committing' && git status && exit 1)\n"
        },
        {
          "name": "Makefile.Common",
          "type": "blob",
          "size": 11.763671875,
          "content": "# In order to ensure make instructions fail if there is command that fails a pipe (ie: `go test ... | tee -a ./test_results.txt`)\n# the value `-o pipefail` (or `set -o pipefail`) is added to each shell command that make runs\n# otherwise in the example command pipe, only the exit code of `tee` is recorded instead of `go test` which can cause\n# test to pass in CI when they should not.\nSHELL = /bin/bash\n.SHELLFLAGS = -o pipefail -c\n\nSHELL_CASE_EXP = case \"$$(uname -s)\" in CYGWIN*|MINGW*|MSYS*) echo \"true\";; esac;\nUNIX_SHELL_ON_WINDOWS := $(shell $(SHELL_CASE_EXP))\n\nifeq ($(UNIX_SHELL_ON_WINDOWS),true)\n\t# The \"sed\" transformation below is needed on Windows, since commands like `go list -f '{{ .Dir }}'`\n\t# return Windows paths and such paths are incompatible with other *nix tools, like `find`,\n\t# used by the Makefile shell.\n\t# The backslash needs to be doubled so its passed correctly to the shell.\n\tNORMALIZE_DIRS = sed -e 's/^/\\\\//' -e 's/://' -e 's/\\\\\\\\/\\\\//g' | sort\nelse\n\tNORMALIZE_DIRS = sort\nendif\n\n# SRC_ROOT is the top of the source tree.\nSRC_ROOT := $(shell git rev-parse --show-toplevel)\n# SRC_PARENT_DIR is the absolute path of source tree's parent directory\nSRC_PARENT_DIR := $(shell dirname $(SRC_ROOT))\n\n# build tags required by any component should be defined as an independent variables and later added to GO_BUILD_TAGS below\nGO_BUILD_TAGS=\"\"\n# These ldflags allow the build tool to omit the symbol table, debug information, and the DWARF symbol table to downscale binary size.\nGO_BUILD_LDFLAGS=\"-s -w\"\nGOTEST_TIMEOUT?= 600s\nGOTEST_OPT?= -race -timeout $(GOTEST_TIMEOUT) -parallel 4 --tags=$(GO_BUILD_TAGS)\nGOTEST_INTEGRATION_OPT?= -race -timeout 360s -parallel 4 -skip Sudo\nGOTEST_INTEGRATION_OPT_SUDO= $(GOTEST_INTEGRATION_OPT) -exec sudo -run Sudo\nGOTEST_OPT_WITH_COVERAGE = $(GOTEST_OPT) -coverprofile=coverage.txt -covermode=atomic\nGOTEST_OPT_WITH_INTEGRATION=$(GOTEST_INTEGRATION_OPT) -tags=integration,$(GO_BUILD_TAGS)\nGOTEST_OPT_WITH_INTEGRATION_SUDO=$(GOTEST_INTEGRATION_OPT_SUDO) -tags=integration,$(GO_BUILD_TAGS)\nGOTEST_OPT_WITH_INTEGRATION_COVERAGE=$(GOTEST_OPT_WITH_INTEGRATION) -coverprofile=integration-coverage.txt -covermode=atomic\nGOCMD?= go\nGOOS=$(shell $(GOCMD) env GOOS)\nGOARCH=$(shell $(GOCMD) env GOARCH)\nGOTESTARCH?=$(GOARCH)\n\nDOCKERCMD ?= docker\n\n# In order to help reduce toil related to managing tooling for the open telemetry collector\n# this section of the makefile looks at only requiring command definitions to be defined\n# as part of $(TOOLS_MOD_DIR)/tools.go, following the existing practice.\n# Modifying the tools' `go.mod` file will trigger a rebuild of the tools to help\n# ensure that all contributors are using the most recent version to make builds repeatable everywhere.\nTOOLS_MOD_DIR    := $(SRC_ROOT)/internal/tools\nTOOLS_MOD_REGEX  := \"\\s+_\\s+\\\".*\\\"\"\nTOOLS_PKG_NAMES  := $(shell grep -E $(TOOLS_MOD_REGEX) < $(TOOLS_MOD_DIR)/tools.go | tr -d \" _\\\"\")\nTOOLS_BIN_DIR    := $(SRC_ROOT)/.tools\nTOOLS_BIN_NAMES  := $(addprefix $(TOOLS_BIN_DIR)/, $(notdir $(TOOLS_PKG_NAMES)))\nCHLOGGEN_CONFIG  := .chloggen/config.yaml\n\n.PHONY: install-tools\ninstall-tools: $(TOOLS_BIN_NAMES)\n\n$(TOOLS_BIN_DIR):\n\tmkdir -p $@\n\n$(TOOLS_BIN_NAMES): $(TOOLS_BIN_DIR) $(TOOLS_MOD_DIR)/go.mod\n\tcd $(TOOLS_MOD_DIR) && GOOS=\"\" GOARCH=\"\" $(GOCMD) build -o $@ -trimpath $(filter %/$(notdir $@),$(TOOLS_PKG_NAMES))\n\nADDLICENSE          := $(TOOLS_BIN_DIR)/addlicense\nMDLINKCHECK         := $(TOOLS_BIN_DIR)/markdown-link-check\nMISSPELL            := $(TOOLS_BIN_DIR)/misspell -error\nMISSPELL_CORRECTION := $(TOOLS_BIN_DIR)/misspell -w\nLINT                := $(TOOLS_BIN_DIR)/golangci-lint\nMULTIMOD            := $(TOOLS_BIN_DIR)/multimod\nCHLOGGEN            := $(TOOLS_BIN_DIR)/chloggen\nGOIMPORTS           := $(TOOLS_BIN_DIR)/goimports\nPORTO               := $(TOOLS_BIN_DIR)/porto\nCHECKFILE           := $(TOOLS_BIN_DIR)/checkfile\nCROSSLINK           := $(TOOLS_BIN_DIR)/crosslink\nGOJUNIT             := $(TOOLS_BIN_DIR)/go-junit-report\nBUILDER             := $(TOOLS_BIN_DIR)/builder\nGOFUMPT             := $(TOOLS_BIN_DIR)/gofumpt\nGOVULNCHECK         := $(TOOLS_BIN_DIR)/govulncheck\nGCI                 := $(TOOLS_BIN_DIR)/gci\nGOTESTSUM           := $(TOOLS_BIN_DIR)/gotestsum\nTESTIFYLINT         := $(TOOLS_BIN_DIR)/testifylint\n\nGOTESTSUM_OPT?= --rerun-fails=1\nTESTIFYLINT_OPT?= --enable-all --disable=float-compare,require-error,suite-subtest-run,encoded-compare\n\n# BUILD_TYPE should be one of (dev, release).\nBUILD_TYPE?=release\n\nALL_PKG_DIRS := $(shell $(GOCMD) list -f '{{ .Dir }}' ./... | $(NORMALIZE_DIRS))\n\nALL_SRC := $(shell find $(ALL_PKG_DIRS) -name '*.go' \\\n                                -not -path '*/third_party/*' \\\n                                -not -path '*/local/*' \\\n                                -type f | sort)\n\nALL_SRC_AND_SHELL := find . -type f \\( -iname '*.go' -o -iname \"*.sh\" \\) ! -path '**/third_party/*' | sort\n\n# All source code and documents. Used in spell check.\nALL_SRC_AND_DOC_CMD := find $(ALL_PKG_DIRS) -name \"*.md\" -o -name \"*.go\" -o -name \"*.yaml\" -not -path '*/third_party/*' -type f | sort\nifeq ($(UNIX_SHELL_ON_WINDOWS),true)\n\t# Windows has a low limit, 8192 chars, to create a process. Workaround it by breaking it in smaller commands.\n\tMISSPELL_CMD := $(ALL_SRC_AND_DOC_CMD) | xargs -n 20 $(MISSPELL)\n\tMISSPELL_CORRECTION_CMD := $(ALL_SRC_AND_DOC_CMD) | xargs -n 20 $(MISSPELL_CORRECTION)\nelse\n\tALL_SRC_AND_DOC := $(shell $(ALL_SRC_AND_DOC_CMD))\n\tMISSPELL_CMD := $(MISSPELL) $(ALL_SRC_AND_DOC)\n\tMISSPELL_CORRECTION_CMD := $(MISSPELL_CORRECTION) $(ALL_SRC_AND_DOC)\nendif\n\n# ALL_PKGS is used with 'go cover'\nALL_PKGS := $(shell $(GOCMD) list $(sort $(dir $(ALL_SRC))))\n\nADDLICENSE_CMD := $(ADDLICENSE) -s=only -y \"\" -c \"The OpenTelemetry Authors\"\n\npwd:\n\t@pwd\n\nall-pkgs:\n\t@echo $(ALL_PKGS) | tr ' ' '\\n' | sort\n\nall-srcs:\n\t@echo $(ALL_SRC) | tr ' ' '\\n' | sort\n\nall-pkg-dirs:\n\t@echo $(ALL_PKG_DIRS) | tr ' ' '\\n' | sort\n\n.DEFAULT_GOAL := common\n\n.PHONY: common\ncommon: lint test\n\n.PHONY: test\ntest: $(GOTESTSUM)\n\t$(GOTESTSUM) $(GOTESTSUM_OPT) --packages=\"./...\" -- $(GOTEST_OPT)\n\n.PHONY: test-with-cover\ntest-with-cover: $(GOTESTSUM)\n\tmkdir -p $(PWD)/coverage/unit\n\t$(GOTESTSUM) $(GOTESTSUM_OPT) --packages=\"./...\" -- $(GOTEST_OPT) -cover -covermode=atomic -args -test.gocoverdir=\"$(PWD)/coverage/unit\"\n\n.PHONY: do-unit-tests-with-cover\ndo-unit-tests-with-cover: $(GOTESTSUM)\n\t@echo \"running $(GOCMD) unit test ./... + coverage in `pwd`\"\n\t$(GOTESTSUM) $(GOTESTSUM_OPT) --packages=\"./...\" -- $(GOTEST_OPT_WITH_COVERAGE)\n\t$(GOCMD) tool cover -html=coverage.txt -o coverage.html\n\n.PHONY: buildtest\nbuildtest:\nifneq (,$(wildcard ./*.go))\n\tGOARCH=$(GOTESTARCH) CGO_ENABLED=1 $(GOCMD) test -c -o builtunitetest.test\nendif\n\n.PHONY: runbuilttest\nrunbuilttest: $(GOTESTSUM)\nifneq (,$(wildcard ./builtunitetest.test))\n\t$(GOTESTSUM) --raw-command -- $(GOCMD) tool test2json -p \"./...\" -t ./builtunitetest.test -test.v -test.failfast -test.timeout $(GOTEST_TIMEOUT)\nendif\n\n.PHONY: mod-integration-test\nmod-integration-test: $(GOTESTSUM)\n\t@echo \"running $(GOCMD) integration test ./... in `pwd`\"\n\t$(GOTESTSUM) $(GOTESTSUM_OPT) --packages=\"./...\" -- $(GOTEST_OPT_WITH_INTEGRATION)\n\t$(GOTESTSUM) $(GOTESTSUM_OPT) --packages=\"./...\" -- $(GOTEST_OPT_WITH_INTEGRATION_SUDO)\n\t@if [ -e integration-coverage.txt ]; then \\\n\t\t$(GOCMD) tool cover -html=integration-coverage.txt -o integration-coverage.html; \\\n\tfi\n\n.PHONY: do-integration-tests-with-cover\ndo-integration-tests-with-cover: $(GOTESTSUM)\n\t@echo \"running $(GOCMD) integration test ./... + coverage in `pwd`\"\n\t$(GOTESTSUM) $(GOTESTSUM_OPT) --packages=\"./...\" -- $(GOTEST_OPT_WITH_INTEGRATION_COVERAGE)\n\t@if [ -e integration-coverage.txt ]; then \\\n\t\t$(GOCMD) tool cover -html=integration-coverage.txt -o integration-coverage.html; \\\n\tfi\n\n.PHONY: benchmark\nbenchmark: $(GOTESTSUM)\n\t$(GOTESTSUM) $(GOTESTSUM_OPT) --packages=\"$(ALL_PKGS)\" -- -bench=. -run=notests --tags=$(GO_BUILD_TAGS)\n\n.PHONY: addlicense\naddlicense: $(ADDLICENSE)\n\t@ADDLICENSEOUT=$$(for f in $$($(ALL_SRC_AND_SHELL)); do \\\n\t\t`$(ADDLICENSE_CMD) \"$$f\" 2>&1`; \\\n\tdone); \\\n\tif [ \"$$ADDLICENSEOUT\" ]; then \\\n\t\techo \"$(ADDLICENSE) FAILED => add License errors:\\n\"; \\\n\t\techo \"$$ADDLICENSEOUT\\n\"; \\\n\t\texit 1; \\\n\telse \\\n\t\techo \"Add License finished successfully\"; \\\n\tfi\n\n.PHONY: checklicense\nchecklicense: $(ADDLICENSE)\n\t@licRes=$$(for f in $$($(ALL_SRC_AND_SHELL)); do \\\n\t\tawk '/Copyright The OpenTelemetry Authors|generated|GENERATED/ && NR<=3 { found=1; next } END { if (!found) print FILENAME }' $$f; \\\n\t\tawk '/SPDX-License-Identifier: Apache-2.0|generated|GENERATED/ && NR<=4 { found=1; next } END { if (!found) print FILENAME }' $$f; \\\n\t\t$(ADDLICENSE_CMD) -check \"$$f\" 2>&1 || echo \"$$f\"; \\\n\t\tdone); \\\n\tif [ -n \"$${licRes}\" ]; then \\\n\t\techo \"license header checking failed:\"; echo \"$${licRes}\"; \\\n\t\texit 1; \\\n\telse \\\n\t\techo \"Check License finished successfully\"; \\\n\tfi\n\n.PHONY: checklinks\nchecklinks:\n\tcommand -v $(DOCKERCMD) >/dev/null 2>&1 || { echo >&2 \"$(DOCKERCMD) not installed. Install before continuing\"; exit 1; }\n\t$(DOCKERCMD) run -w /home/repo --rm \\\n\t\t--mount 'type=bind,source='$(PWD)',target=/home/repo' \\\n\t\t--mount 'type=bind,source='$(SRC_ROOT)/.github/lychee.toml',target=/lychee.toml' \\\n\t\tlycheeverse/lychee \\\n\t\t--config /lychee.toml \\\n\t\t--root-dir /home/repo \\\n\t\t-v \\\n\t\t--no-progress './**/*.md'\n\n.PHONY: fmt\nfmt: $(GOFUMPT) $(GOIMPORTS)\n\t$(GOFUMPT) -l -w .\n\t$(GOIMPORTS) -w -local github.com/open-telemetry/opentelemetry-collector-contrib ./\n\n.PHONY: lint\nlint: $(LINT) checklicense misspell\n\t$(LINT) run --allow-parallel-runners --build-tags integration --timeout=30m --path-prefix $(shell basename \"$(CURDIR)\")\n\n.PHONY: govulncheck\ngovulncheck: $(GOVULNCHECK)\n\t$(GOVULNCHECK) ./...\n\n.PHONY: tidy\ntidy:\n\trm -fr go.sum\n\t$(GOCMD) mod tidy -compat=1.22.0\n\n.PHONY: toolchain\ntoolchain:\n\t$(GOCMD) get toolchain@none\n\n.PHONY: misspell\nmisspell: $(TOOLS_BIN_DIR)/misspell\n\t@echo \"running $(MISSPELL)\"\n\t@$(MISSPELL_CMD)\n\n.PHONY: misspell-correction\nmisspell-correction: $(TOOLS_BIN_DIR)/misspell\n\t$(MISSPELL_CORRECTION_CMD)\n\n.PHONY: moddownload\nmoddownload:\n\t$(GOCMD) mod download\n\n.PHONY: testifylint\ntestifylint: $(TESTIFYLINT)\n\t@echo \"running $(TESTIFYLINT)\"\n\t$(TESTIFYLINT) $(TESTIFYLINT_OPT) ./...\n\n.PHONY: testifylint-fix\ntestifylint-fix:\n\t@$(MAKE) testifylint TESTIFYLINT_OPT=\"${TESTIFYLINT_OPT} --fix\"\n\n.PHONY: gci\ngci: $(TOOLS_BIN_DIR)/gci\n\t@echo \"running $(GCI)\"\n\t@$(GCI) write -s standard -s default -s \"prefix(github.com/open-telemetry/opentelemetry-collector-contrib)\" $(ALL_SRC_AND_DOC)\n\nCHANGED_GOLANG_SOURCES?=$(shell git diff main --name-only | grep -E '.*\\.go$$' | grep -v -E '.*_test\\.go$$')\n.PHONY: for-affected-components\nfor-affected-components:\n\t@echo \"Checking for affected components...\"\n\t@if [ -z '$(CHANGED_GOLANG_SOURCES)' ]; then \\\n\t\techo \"No go source changes detected in shippable code.\"; \\\n\telse \\\n\t\tcd $(SRC_ROOT); \\\n\t\tDEPENDENT_PKGS=$$(echo $(CHANGED_GOLANG_SOURCES) | xargs sed -n 's|^package .* // import \"\\(.*\\)\"$$|\\1|p' | uniq); \\\n\t\tif [ -z '$${DEPENDENT_PKGS}' ]; then \\\n\t\t\techo \"No other package depends on the one being changed.\"; \\\n\t\telse \\\n\t\t\tDEPENDENT_PKG_DIRS=$$(echo $${DEPENDENT_PKGS} | tr ' ' '\\n' | xargs -I {} grep --include=go.mod -rl {} | xargs -r dirname | uniq); \\\n\t\t\tset -e; for dir in $$(echo $${DEPENDENT_PKG_DIRS}); do \\\n\t\t\t(cd \"$${dir}\" && \\\n\t\t\t\techo \"running $${CMD} in $${dir}\" && \\\n\t\t\t\t$${CMD} ); \\\n\t\t\tdone \\\n\t\tfi \\\n\tfi\n\nCHANGED_GOLANG_TESTS?=$(shell git diff main --name-only | grep -E '.*_test\\.go$$')\n.PHONY: run-changed-tests\nrun-changed-tests:\n\t@echo \"Checking for affected tests...\"\n\t@if [ -z '$(CHANGED_GOLANG_TESTS)' ]; then \\\n\t\techo \"No go test changes detected.\"; \\\n\telse \\\n\t\tcd $(SRC_ROOT); \\\n\t\tAFFECTED_TEST_DIRS=$$(echo $(CHANGED_GOLANG_TESTS) | tr ' ' '\\n' | xargs dirname | uniq); \\\n\t\tif [ -z '$${AFFECTED_TEST_DIRS}' ]; then \\\n\t\t\techo \"Failed to find the affected test directories.\"; \\\n\t\telse \\\n\t\t\tset -e; for dir in $$(echo $${AFFECTED_TEST_DIRS}); do \\\n\t\t\t(cd \"$${dir}\" && \\\n\t\t\t\t$(GOTESTSUM) $(GOTESTSUM_OPT) --packages=\"./...\" -- $(GOTEST_OPT) ); \\\n\t\t\tdone \\\n\t\tfi \\\n\tfi\n"
        },
        {
          "name": "NOTICE",
          "type": "blob",
          "size": 2.2001953125,
          "content": "receiver/hostmetricsreceiver/internal/scraper/processscraper/process.go contains code originating from gopsutil under internal/common/common.go.\n\nCopyright (c) 2014, WAKAYAMA Shirou\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without modification,\nare permitted provided that the following conditions are met:\n\n * Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n * Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n * Neither the name of the gopsutil authors nor the names of its contributors\n   may be used to endorse or promote products derived from this software without\n   specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\nANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\ninternal/grpcutil contains code derived from gRPC-Go\n\nCopyright 2014 gRPC authors.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 10.673828125,
          "content": "---\n\n<p align=\"center\">\n  <strong>\n    <a href=\"https://opentelemetry.io/docs/collector/getting-started/\">Getting Started</a>\n    &nbsp;&nbsp;&bull;&nbsp;&nbsp;\n    <a href=\"https://github.com/open-telemetry/opentelemetry-collector/blob/main/CONTRIBUTING.md\">Getting Involved</a>\n    &nbsp;&nbsp;&bull;&nbsp;&nbsp;\n    <a href=\"https://cloud-native.slack.com/archives/C01N6P7KR6W\">Getting In Touch</a>\n  </strong>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/open-telemetry/opentelemetry-collector-contrib/actions/workflows/build-and-test.yml?query=branch%3Amain\">\n    <img alt=\"Build Status\" src=\"https://img.shields.io/github/actions/workflow/status/open-telemetry/opentelemetry-collector-contrib/build-and-test.yml?branch=main&style=for-the-badge\">\n  </a>\n  <a href=\"https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector-contrib\">\n    <img alt=\"Go Report Card\" src=\"https://goreportcard.com/badge/github.com/open-telemetry/opentelemetry-collector-contrib?style=for-the-badge\">\n  </a>\n  <a href=\"https://codecov.io/gh/open-telemetry/opentelemetry-collector-contrib/branch/main/\">\n    <img alt=\"Codecov Status\" src=\"https://img.shields.io/codecov/c/github/open-telemetry/opentelemetry-collector-contrib?style=for-the-badge\">\n  </a>\n  <a href=\"https://github.com/open-telemetry/opentelemetry-collector-contrib/releases\">\n    <img alt=\"GitHub release (latest by date including pre-releases)\" src=\"https://img.shields.io/github/v/release/open-telemetry/opentelemetry-collector-contrib?include_prereleases&style=for-the-badge\">\n  </a>\n  <img alt=\"Beta\" src=\"https://img.shields.io/badge/status-beta-informational?style=for-the-badge&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABgAAAAYCAYAAADgdz34AAAAAXNSR0IArs4c6QAAAIRlWElmTU0AKgAAAAgABQESAAMAAAABAAEAAAEaAAUAAAABAAAASgEbAAUAAAABAAAAUgEoAAMAAAABAAIAAIdpAAQAAAABAAAAWgAAAAAAAACQAAAAAQAAAJAAAAABAAOgAQADAAAAAQABAACgAgAEAAAAAQAAABigAwAEAAAAAQAAABgAAAAA8A2UOAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAAVlpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IlhNUCBDb3JlIDUuNC4wIj4KICAgPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4KICAgICAgPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIKICAgICAgICAgICAgeG1sbnM6dGlmZj0iaHR0cDovL25zLmFkb2JlLmNvbS90aWZmLzEuMC8iPgogICAgICAgICA8dGlmZjpPcmllbnRhdGlvbj4xPC90aWZmOk9yaWVudGF0aW9uPgogICAgICA8L3JkZjpEZXNjcmlwdGlvbj4KICAgPC9yZGY6UkRGPgo8L3g6eG1wbWV0YT4KTMInWQAABK5JREFUSA2dVm1sFEUYfmd2b/f2Pkqghn5eEQWKrRgjpkYgpoRCLC0oxV5apAiGUDEpJvwxEQ2raWPU+Kf8INU/RtEedwTCR9tYPloxGNJYTTQUwYqJ1aNpaLH3sXu3t7vjvFevpSqt7eSyM+/czvM8877PzB3APBoLgoDLsNePF56LBwqa07EKlDGg84CcWsI4CEbhNnDpAd951lXE2NkiNknCCTLv4HtzZuvPm1C/IKv4oDNXqNDHragety2XVzjECZsJARuBMyRzJrh1O0gQwLXuxofxsPSj4hG8fMLQo7bl9JJD8XZfC1E5yWFOMtd07dvX5kDwg6+2++Chq8txHGtfPoAp0gOFmhYoNFkHjn2TNUmrwRdna7W1QSkU8hvbGk4uThLrapaiLA2E6QY4u/lS9ItHfvJkxYsTMVtnAJLipYIWtVrcdX+8+b8IVnPl/R81prbuPZ1jpYw+0aEUGSkdFsgyBIaFTXCm6nyaxMtJ4n+TeDhJzGqZtQZcuYDgqDwDbqb0JF9oRpIG1Oea3bC1Y6N3x/WV8Zh83emhCs++hlaghDw+8w5UlYKq2lU7Pl8IkvS9KDqXmKmEwdMppVPKwGSEilmyAwJhRwWcq7wYC6z4wZ1rrEoMWxecdOjZWXeAQClBcYDN3NwVwD9pGwqUSyQgclcmxpNJqCuwLmDh3WtvPqXdlt+6Oz70HPGDNSNBee/EOen+rGbEFqDENBPDbtdCp0ukPANmzO0QQJYUpyS5IJJI3Hqt4maS+EB3199ozm8EDU/6fVNU2dQpdx3ZnKzeFXyaUTiasEV/gZMzJMjr3Z+WvAdQ+hs/zw9savimxUntDSaBdZ2f+Idbm1rlNY8esFffBit9HtK5/MejsrJVxikOXlb1Ukir2X+Rbdkd1KG2Ixfn2Ql4JRmELnYK9mEM8G36fAA3xEQ89fxXihC8q+sAKi9jhHxNqagY2hiaYgRCm0f0QP7H4Fp11LSXiuBY2aYFlh0DeDIVVFUJQn5rCnpiNI2gvLxHnASn9DIVHJJlm5rXvQAGEo4zvKq2w5G1NxENN7jrft1oxMdekETjxdH2Z3x+VTVYsPb+O0C/9/auN6v2hNZw5b2UOmSbG5/rkC3LBA+1PdxFxORjxpQ81GcxKc+ybVjEBvUJvaGJ7p7n5A5KSwe4AzkasA+crmzFtowoIVTiLjANm8GDsrWW35ScI3JY8Urv83tnkF8JR0yLvEt2hO/0qNyy3Jb3YKeHeHeLeOuVLRpNF+pkf85OW7/zJxWdXsbsKBUk2TC0BCPwMq5Q/CPvaJFkNS/1l1qUPe+uH3oD59erYGI/Y4sce6KaXYElAIOLt+0O3t2+/xJDF1XvOlWGC1W1B8VMszbGfOvT5qaRRAIFK3BCO164nZ0uYLH2YjNN8thXS2v2BK9gTfD7jHVxzHr4roOlEvYYz9QIz+Vl/sLDXInsctFsXjqIRnO2ZO387lxmIboLDZCJ59KLFliNIgh9ipt6tLg9SihpRPDO1ia5byw7de1aCQmF5geOQtK509rzfdwxaKOIq+73AvwCC5/5fcV4vo3+3LpMdtWHh0ywsJC/ZGoCb8/9D8F/ifgLLl8S8QWfU8cAAAAASUVORK5CYII=\">\n</p>\n\n<p align=\"center\">\n  <strong>\n    <a href=\"https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/vision.md\">Vision</a>\n    &nbsp;&nbsp;&bull;&nbsp;&nbsp;\n    <a href=\"https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/observability.md\">Observability</a>\n    &nbsp;&nbsp;&bull;&nbsp;&nbsp;\n    <a href=\"https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/security-best-practices.md\">Security</a>\n    &nbsp;&nbsp;&bull;&nbsp;&nbsp;\n  </strong>\n</p>\n\n---\n\n# OpenTelemetry Collector Contrib\n\nThis is a repository for OpenTelemetry Collector components that are not suitable for the  [core repository](https://github.com/open-telemetry/opentelemetry-collector) of the collector. \n\nThe official distributions, core and contrib, are available as part of the [opentelemetry-collector-releases](https://github.com/open-telemetry/opentelemetry-collector-releases) repository. Some of the components in this repository are part of the \"core\" distribution, such as the Jaeger and Prometheus components, but most of the components here are only available as part of the \"contrib\" distribution. Users of the OpenTelemetry Collector are also encouraged to build their own custom distributions with the [OpenTelemetry Collector Builder](https://github.com/open-telemetry/opentelemetry-collector/tree/main/cmd/builder), using the components they need from the core repository, the contrib repository, and possibly third-party or internal repositories.\n\nEach component has its own support levels, as defined in the following sections. For each signal that a component supports, there's a stability level, setting the right expectations. It is possible then that a component will be **Stable** for traces but **Alpha** for metrics and **Development** for logs.\n\n## Stability levels\n\nStability level for components in this repository follow the [definitions](https://github.com/open-telemetry/opentelemetry-collector#stability-levels) from the OpenTelemetry Collector repository.\n\n## Gated features\n\nSome features are hidden behind feature gates before they are part of the main code path for the component. Note that the feature gates themselves might be at different [lifecycle stages](https://github.com/open-telemetry/opentelemetry-collector/tree/main/featuregate#feature-lifecycle).\n\n## Support\n\nEach component is supported either by the community of OpenTelemetry Collector Contrib maintainers, as defined by the GitHub group [@open-telemetry/collector-contrib-maintainer](https://github.com/orgs/open-telemetry/teams/collector-contrib-maintainer), or by specific vendors. See the individual README files for information about the specific components.\n\nThe OpenTelemetry Collector Contrib maintainers may at any time downgrade specific components if they are deemed unmaintained or if they pose a risk to the repository and/or binary distribution.\n\nEven though the OpenTelemetry Collector Contrib maintainers are ultimately responsible for the components hosted here, actual support will likely be provided by individual contributors, typically a code owner for the specific component.\n\n## Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md).\n\nTriagers ([@open-telemetry/collector-contrib-triagers](https://github.com/orgs/open-telemetry/teams/collector-contrib-triagers))\n\n- [Benedikt Bongartz](https://github.com/frzifus), Red Hat\n- [Florian Bacher](https://github.com/bacherfl), Dynatrace\n- [Jared Tan](https://github.com/JaredTan95), DaoCloud\n- [Murphy Chen](https://github.com/Frapschen), DaoCloud\n- [Paulo Janotti](https://github.com/pjanotti), Splunk\n- [Vihas Makwana](https://github.com/VihasMakwana), Elastic\n- [Braydon Kains](https://github.com/braydonk), Google\n- Actively seeking contributors to triage issues\n\nEmeritus Triagers:\n\n- [Alolita Sharma](https://github.com/alolita)\n- [Gabriel Aszalos](https://github.com/gbbr)\n- [Goutham Veeramachaneni](https://github.com/gouthamve)\n- [Punya Biswal](https://github.com/punya)\n- [Steve Flanders](https://github.com/flands)\n\nApprovers ([@open-telemetry/collector-contrib-approvers](https://github.com/orgs/open-telemetry/teams/collector-contrib-approvers)):\n\n- [Antoine Toulme](https://github.com/atoulme), Splunk\n- [Christos Markou](https://github.com/ChrsMark), Elastic\n- [Curtis Robert](https://github.com/crobert-1), Splunk\n- [David Ashpole](https://github.com/dashpole), Google\n- [Matt Wear](https://github.com/mwear), Lightstep\n- [Yang Song](https://github.com/songy23), DataDog\n- [Ziqi Zhao](https://github.com/fatsheep9146), Alibaba\n\nEmeritus Approvers:\n\n- [Anthony Mirabella](https://github.com/Aneurysm9)\n- [Bryan Aguilar](https://github.com/bryan-aguilar)\n- [Przemek Maciolek](https://github.com/pmm-sumo)\n- [Ruslan Kovalov](https://github.com/kovrus)\n\nMaintainers ([@open-telemetry/collector-contrib-maintainer](https://github.com/orgs/open-telemetry/teams/collector-contrib-maintainer)):\n\n- [Alex Boten](https://github.com/codeboten), Honeycomb\n- [Andrzej Stencel](https://github.com/andrzej-stencel), Elastic\n- [Bogdan Drutu](https://github.com/bogdandrutu), Snowflake\n- [Daniel Jaglowski](https://github.com/djaglowski), observIQ\n- [Dmitrii Anoshin](https://github.com/dmitryax), Splunk\n- [Evan Bradley](https://github.com/evan-bradley), Dynatrace\n- [Juraci Paixão Kröhling](https://github.com/jpkrohling), Grafana Labs\n- [Pablo Baeyens](https://github.com/mx-psi), DataDog\n- [Sean Marciniak](https://github.com/MovieStoreGuy), Splunk\n- [Tyler Helmuth](https://github.com/TylerHelmuth), Honeycomb\n\nEmeritus Maintainers\n\n- [Tigran Najaryan](https://github.com/tigrannajaryan)\n\nLearn more about roles in the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md).\n\n## PRs and Reviews\n\nWhen creating a PR please follow the process [described\nhere](https://github.com/open-telemetry/opentelemetry-collector/blob/main/CONTRIBUTING.md#how-to-structure-prs-to-get-expedient-reviews).\n\nNew PRs will be automatically associated with the reviewers based on\n[CODEOWNERS](.github/CODEOWNERS). PRs will be also automatically assigned to one of the\nmaintainers or approvers for facilitation.\n\nThe facilitator is responsible for helping the PR author and reviewers to make progress\nor if progress cannot be made for closing the PR.\n\nIf the reviewers do not have approval rights the facilitator is also responsible\nfor the official approval that is required for the PR to be merged and if the facilitator\nis a maintainer they are responsible for merging the PR as well.\n\nThe facilitator is not required to perform a thorough review, but they are encouraged to\nenforce Collector best practices and consistency across the codebase and component\nbehavior. The facilitators will typically rely on codeowner's detailed review of the code\nwhen making the final approval decision. \n"
        },
        {
          "name": "cmd",
          "type": "tree",
          "content": null
        },
        {
          "name": "confmap",
          "type": "tree",
          "content": null
        },
        {
          "name": "connector",
          "type": "tree",
          "content": null
        },
        {
          "name": "distributions.yaml",
          "type": "blob",
          "size": 0.6513671875,
          "content": "# A collection of distributions that can be referenced in the metadata.yaml files.\n# The rules below apply to every distribution added to this list:\n# - The distribution is open source and maintained by the OpenTelemetry project.\n# - The link must point to a publicly accessible repository.\n - name: core\n   url: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol\n - name: contrib\n   url: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n - name: k8s\n   url: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-k8s"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "exporter",
          "type": "tree",
          "content": null
        },
        {
          "name": "extension",
          "type": "tree",
          "content": null
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 1.3330078125,
          "content": "module github.com/open-telemetry/opentelemetry-collector-contrib\n\n// NOTE:\n// This go.mod is NOT used to build any official binary.\n// To see the builder manifests used for official binaries,\n// check https://github.com/open-telemetry/opentelemetry-collector-releases\n//\n// For the OpenTelemetry Collector Contrib distribution specifically, see\n// https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n\ngo 1.22.0\n\n// Replace references to modules that are in this repository with their relateive paths\n// so that we always build with current (latest) version of the source code.\n\n// see https://github.com/google/gnostic/issues/262\nreplace github.com/googleapis/gnostic v0.5.6 => github.com/googleapis/gnostic v0.5.5\n\nretract (\n\tv0.76.2\n\tv0.76.1\n\tv0.65.0\n\tv0.37.0 // Contains dependencies on v0.36.0 components, which should have been updated to v0.37.0.\n)\n\n// see https://github.com/distribution/distribution/issues/3590\nexclude github.com/docker/distribution v2.8.0+incompatible\n\n// see https://github.com/DataDog/agent-payload/issues/218\nexclude github.com/DataDog/agent-payload/v5 v5.0.59\n\n// openshift removed all tags from their repo, use the pseudoversion from the release-3.9 branch HEAD\nreplace github.com/openshift/api v3.9.0+incompatible => github.com/openshift/api v0.0.0-20180801171038-322a19404e37\n"
        },
        {
          "name": "internal",
          "type": "tree",
          "content": null
        },
        {
          "name": "issue-triaging.md",
          "type": "blob",
          "size": 7.466796875,
          "content": "# Issue management\n\nTo help provide a consistent process for seeing issues through to completion, this section details some guidelines and\ndefinitions to keep in mind when triaging issues.\n\n### Roles\n\nDetermining the root cause of issues is a shared responsibility between those with triager permissions, code owners,\nOpenTelemetry community members, issue authors, and anyone else who would like to contribute.\n\n#### Triagers\n\nContributors with [triager](https://github.com/open-telemetry/opentelemetry-collector-contrib/#contributing) permissions can help move\nissues along by adding missing component labels, which help organize issues and trigger automations to notify code owners. They can\nalso use their familiarity with the Collector and its components to investigate issues themselves. Alternatively, they may point issue\nauthors to another resource or someone else who may know more.\n\n#### Code Owners\n\nIn many cases, the code owners for an issue are the best resource to help determine the root cause of a bug or whether an enhancement\nis fit to be added to a component. Code owners will be notified by repository automations when:\n\n- a component label is added to an issue\n- an issue is opened\n- the issue becomes stale\n\nCode owners may not have triager permissions on the repository,\nso they can help triage through investigation and by participating in discussions. They can also help organize issues by\n[adding labels via comments](#adding-labels-via-comments).\n\n#### Community Members\n\nCommunity members or interested parties are welcome to help triage issues by investigating the root cause of bugs, adding input for\nfeatures they would like to see, or participating in design discussions.\n\n### Triage process\n\nTriaging an issue requires getting the issue into a state where there is enough information available on the issue or understanding\nbetween the involved parties to allow work to begin or for the issue to be closed. Facilitating this may involve, but is not limited to:\n\n- Determining whether the issue is related to the code or documentation, or whether the issue can be resolved without any changes.\n- Ensuring that a bug can be reproduced, and if possible, the behavior can be traced back to the offending code or documentation.\n- Determining whether a feature request belongs in a component, should be accomplished through other means, or isn't appropriate for a component at this time.\n- Guiding any interested parties to another person or resource that may be more knowledgeable about an issue.\n- Suggesting an issue for discussion at a SIG meeting if a synchronous discussion would be more productive.\n\n#### Issue assignment\n\nIssues are assigned for someone to work on by a triager when someone volunteers to work on an issue. Assignment is intended to prevent duplicate work by making it visible who is\nworking on a particular task. A person who is assigned to the issue may be assigned to help triage the issue and implement it, or can be assigned after the issue has already been\ntriaged and is ready for work. If someone who is assigned to an issue is no longer able to work on it, they may request to be unassigned from the issue.\n\n### Label Definitions\n\n| Label                | When to apply                                                                                                                                                                                                  |\n| -------------------- |----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `bug`                | Something that is advertised or intended to work isn't working as expected.                                                                                                                                    |\n| `enhancement`        | Something that isn't an advertised feature that would be useful to users or maintainers.                                                                                                                       |\n| `flaky test`         | A test unexpectedly failed during CI, showing that there is a problem with the tests or test setup that is causing the tests to intermittently fail.                                                           |\n| `documentation`      | This is a collector usability issue that could likely be resolved by providing relevant documentation. Please consider adding new or improving existing documentation before closing issues with this label.   |\n| `good first issue`   | Implementing this issue would not require specialized or in-depth knowledge about the component and is ideal for a new or first-time contributor to take.                                                      |\n| `help wanted`        | The code owners for this component do not expect to have time to work on it soon, and would welcome help from contributors.                                                                                    |\n| `discussion needed`  | This issue needs more input from the maintainers or community before work can be started.                                                                                                                      |\n| `needs triage`       | This label is added automatically, and can be removed when a triager or code owner deems that an issue is either ready for work or should not need any work. See also the [triaging process](#triage-process). |\n| `waiting for author` | Can be applied when input is required from the author before the issue can move any further.                                                                                                                   |\n| `priority:p0`        | A critical security vulnerability or Collector panic using a default or common configuration unrelated to a specific component.                                                                                |\n| `priority:p1`        | An urgent issue that should be worked on quickly, before most other issues.                                                                                                                                    |\n| `priority:p2`        | A standard bug or enhancement.                                                                                                                                                                                 |\n| `priority:p3`        | A technical improvement, lower priority bug, or other minor issue. Generally something that is considered a \"nice to have.\"                                                                                    |\n| `release:blocker`    | This issue must be resolved before the next Collector version can be released.                                                                                                                                 |\n| `Sponsor Needed`     | A new component has been proposed, but implementation is not ready to begin. This can be because a sponsor has not yet been decided, or because some details on the component still need to be decided.        |\n| `Accepted Component` | A sponsor has elected to take on a component and implementation is ready to begin.                                                                                                                             |\n| `Vendor Specific Component` | This should be applied to any component proposal where the functionality for the component is particular to a vendor.                                                                                          |\n"
        },
        {
          "name": "pkg",
          "type": "tree",
          "content": null
        },
        {
          "name": "processor",
          "type": "tree",
          "content": null
        },
        {
          "name": "receiver",
          "type": "tree",
          "content": null
        },
        {
          "name": "renovate.json",
          "type": "blob",
          "size": 4.9794921875,
          "content": "{\n  \"$schema\": \"https://docs.renovatebot.com/renovate-schema.json\",\n  \"labels\": [\n    \"renovatebot\",\n    \"dependencies\"\n  ],\n  \"constraints\": {\n    \"go\": \"1.22.0\"\n  },\n  \"schedule\": [\n    \"on tuesday\"\n  ],\n  \"extends\": [\n    \"config:recommended\",\n    \"customManagers:githubActionsVersions\"\n  ],\n  \"ignorePaths\": [\n    \"**/receiver/apachesparkreceiver/testdata/integration/Dockerfile.apache-spark\",\n    \"**/receiver/elasticsearchreceiver/testdata/integration/Dockerfile.elasticsearch.7_16_3\",\n    \"**/receiver/elasticsearchreceiver/testdata/integration/Dockerfile.elasticsearch.7_9_3\",\n    \"**/receiver/mongodbreceiver/testdata/integration/Dockerfile.mongodb.4_0\",\n    \"**/receiver/mongodbreceiver/testdata/integration/Dockerfile.mongodb.4_4.lpu\",\n    \"**/receiver/mongodbreceiver/testdata/integration/Dockerfile.mongodb.4_4lpu\",\n    \"**/receiver/mongodbreceiver/testdata/integration/Dockerfile.mongodb.5_0\"\n  ],\n  \"packageRules\": [\n    {\n      \"matchManagers\": [\n        \"gomod\"\n      ],\n      \"matchUpdateTypes\": [\n        \"pin\",\n        \"pinDigest\",\n        \"digest\",\n        \"lockFileMaintenance\",\n        \"rollback\",\n        \"bump\",\n        \"replacement\"\n      ],\n      \"enabled\": false\n    },\n    {\n      \"matchManagers\": [\n        \"gomod\"\n      ],\n      \"matchUpdateTypes\": [\n        \"major\"\n      ],\n      \"prBodyNotes\": [\n        \":warning: MAJOR VERSION UPDATE :warning: - please manually update this package\"\n      ],\n      \"labels\": [\n        \"dependency-major-update\"\n      ]\n    },\n    {\n      \"matchManagers\": [\n        \"dockerfile\"\n      ],\n      \"groupName\": \"dockerfile deps\"\n    },\n    {\n      \"matchManagers\": [\n        \"docker-compose\"\n      ],\n      \"groupName\": \"docker-compose deps\"\n    },\n    {\n      \"matchManagers\": [\n        \"github-actions\"\n      ],\n      \"groupName\": \"github-actions deps\"\n    },\n    {\n      \"matchManagers\": [\n        \"gomod\"\n      ],\n      \"groupName\": \"All github.com/aws packages\",\n      \"matchSourceUrls\": [\n        \"https://github.com/aws{/,}**\"\n      ]\n    },\n    {\n      \"matchManagers\": [\n        \"gomod\"\n      ],\n      \"groupName\": \"All github.com/azure packages\",\n      \"matchSourceUrls\": [\n        \"https://github.com/azure{/,}**\"\n      ]\n    },\n    {\n      \"matchManagers\": [\n        \"gomod\"\n      ],\n      \"groupName\": \"All github.com/datadog packages\",\n      \"matchSourceUrls\": [\n        \"https://github.com/datadog{/,}**\"\n      ]\n    },\n    {\n      \"matchManagers\": [\n        \"gomod\"\n      ],\n      \"groupName\": \"All google.golang.org packages\",\n      \"matchSourceUrls\": [\n        \"https://google.golang.org{/,}**\"\n      ]\n    },\n    {\n      \"matchManagers\": [\n        \"gomod\"\n      ],\n      \"groupName\": \"All golang.org/x packages\",\n      \"matchPackageNames\": [\n        \"golang.org/x{/,}**\"\n      ]\n    },\n    {\n      \"matchManagers\": [\n        \"gomod\"\n      ],\n      \"groupName\": \"All go.opentelemetry.io/build-tools packages\",\n      \"matchPackageNames\": [\n        \"go.opentelemetry.io/build-tools{/,}**\"\n      ]\n    },\n    {\n      \"matchManagers\": [\n        \"gomod\"\n      ],\n      \"groupName\": \"All go.opentelemetry.io/otel packages\",\n      \"matchSourceUrls\": [\n        \"https://go.opentelemetry.io/otel{/,}**\"\n      ]\n    },\n    {\n      \"matchManagers\": [\n        \"gomod\"\n      ],\n      \"groupName\": \"All cloud.google.com/go packages\",\n      \"matchPackageNames\": [\n        \"cloud.google.com/go{/,}**\"\n      ]\n    },\n    {\n      \"matchManagers\": [\n        \"gomod\"\n      ],\n      \"groupName\": \"All github.com/googlecloudplatform packages\",\n      \"matchSourceUrls\": [\n        \"https://github.com/googlecloudplatform{/,}**\"\n      ]\n    },\n    {\n      \"matchManagers\": [\n        \"gomod\"\n      ],\n      \"matchSourceUrls\": [\n        \"https://github.com/open-telemetry/opentelemetry-collector\"\n      ],\n      \"groupName\": \"All OpenTelemetry Collector dev packages\",\n      \"matchUpdateTypes\": [\n        \"digest\"\n      ]\n    },\n    {\n      \"matchManagers\": [\n        \"gomod\"\n      ],\n      \"matchSourceUrls\": [\n        \"https://github.com/open-telemetry/opentelemetry-collector\"\n      ],\n      \"groupName\": \"All OpenTelemetry Collector packages\",\n      \"matchUpdateTypes\": [\n        \"major\",\n        \"minor\",\n        \"patch\"\n      ]\n    },\n    {\n      \"matchManagers\": [\n        \"gomod\"\n      ],\n      \"matchSourceUrls\": [\n        \"https://github.com/open-telemetry/opentelemetry-collector-contrib\"\n      ],\n      \"groupName\": \"All OpenTelemetry Collector Contrib packages\",\n      \"matchUpdateTypes\": [\n        \"major\",\n        \"minor\",\n        \"patch\"\n      ]\n    },\n    {\n      \"matchManagers\": [\n        \"gomod\"\n      ],\n      \"matchSourceUrls\": [\n        \"https://github.com/open-telemetry/opentelemetry-go-contrib\"\n      ],\n      \"groupName\": \"All opentelemetry-go-contrib packages\"\n    },\n    {\n      \"matchPackageNames\": [\n        \"google.golang.org/grpc\"\n      ],\n      \"allowedVersions\": \"!/v1.68.0$/\"\n    }\n  ],\n  \"ignoreDeps\": [\n    \"github.com/DataDog/datadog-agent/pkg/trace/exportable\",\n    \"github.com/DataDog/datadog-api-client-go\"\n  ],\n  \"prConcurrentLimit\": 200,\n  \"suppressNotifications\": [\n    \"prEditedNotification\"\n  ]\n}\n"
        },
        {
          "name": "reports",
          "type": "tree",
          "content": null
        },
        {
          "name": "testbed",
          "type": "tree",
          "content": null
        },
        {
          "name": "versions.yaml",
          "type": "blob",
          "size": 26.80078125,
          "content": "# Copyright The OpenTelemetry Authors\n# SPDX-License-Identifier: Apache-2.0\n\nmodule-sets:\n  contrib-base:\n    version: v0.117.0\n    modules:\n      - github.com/open-telemetry/opentelemetry-collector-contrib\n      - github.com/open-telemetry/opentelemetry-collector-contrib/cmd/githubgen\n      - github.com/open-telemetry/opentelemetry-collector-contrib/cmd/opampsupervisor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/cmd/telemetrygen\n      - github.com/open-telemetry/opentelemetry-collector-contrib/confmap/provider/aesprovider\n      - github.com/open-telemetry/opentelemetry-collector-contrib/confmap/provider/s3provider\n      - github.com/open-telemetry/opentelemetry-collector-contrib/confmap/provider/secretsmanagerprovider\n      - github.com/open-telemetry/opentelemetry-collector-contrib/connector/countconnector\n      - github.com/open-telemetry/opentelemetry-collector-contrib/connector/datadogconnector\n      - github.com/open-telemetry/opentelemetry-collector-contrib/connector/exceptionsconnector\n      - github.com/open-telemetry/opentelemetry-collector-contrib/connector/failoverconnector\n      - github.com/open-telemetry/opentelemetry-collector-contrib/connector/grafanacloudconnector\n      - github.com/open-telemetry/opentelemetry-collector-contrib/connector/otlpjsonconnector\n      - github.com/open-telemetry/opentelemetry-collector-contrib/connector/roundrobinconnector\n      - github.com/open-telemetry/opentelemetry-collector-contrib/connector/routingconnector\n      - github.com/open-telemetry/opentelemetry-collector-contrib/connector/servicegraphconnector\n      - github.com/open-telemetry/opentelemetry-collector-contrib/connector/signaltometricsconnector\n      - github.com/open-telemetry/opentelemetry-collector-contrib/connector/spanmetricsconnector\n      - github.com/open-telemetry/opentelemetry-collector-contrib/connector/sumconnector\n      - github.com/open-telemetry/opentelemetry-collector-contrib/examples/demo/client\n      - github.com/open-telemetry/opentelemetry-collector-contrib/examples/demo/server\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/alertmanagerexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/alibabacloudlogserviceexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/awscloudwatchlogsexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/awsemfexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/awskinesisexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/awss3exporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/awsxrayexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/azuredataexplorerexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/azuremonitorexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/carbonexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/cassandraexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/clickhouseexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/coralogixexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/datadogexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/datadogexporter/integrationtest\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/datasetexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/dorisexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/elasticsearchexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/elasticsearchexporter/integrationtest\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/fileexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/googlecloudexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/googlecloudpubsubexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/googlemanagedprometheusexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/honeycombmarkerexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/influxdbexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/kafkaexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/kineticaexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/loadbalancingexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/logicmonitorexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/logzioexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/lokiexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/mezmoexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/opencensusexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/opensearchexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/otelarrowexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/prometheusexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/prometheusremotewriteexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/pulsarexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/rabbitmqexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/sapmexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/sentryexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/signalfxexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/splunkhecexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/sumologicexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/syslogexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/tencentcloudlogserviceexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/exporter/zipkinexporter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/ackextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/asapauthextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/awsproxy\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/basicauthextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/bearertokenauthextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/cgroupruntimeextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/encoding\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/encoding/avrologencodingextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/encoding/jaegerencodingextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/encoding/jsonlogencodingextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/encoding/otlpencodingextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/encoding/textencodingextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/encoding/zipkinencodingextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/googleclientauthextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/headerssetterextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/healthcheckextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/healthcheckv2extension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/httpforwarderextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/jaegerremotesampling\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/oauth2clientauthextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/observer\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/observer/cfgardenobserver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/observer/dockerobserver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/observer/ecsobserver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/observer/ecstaskobserver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/observer/hostobserver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/observer/k8sobserver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/oidcauthextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/opampcustommessages\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/opampextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/pprofextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/remotetapextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/sigv4authextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/solarwindsapmsettingsextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/storage\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/storage/dbstorage\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/storage/filestorage\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/storage/redisstorageextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/extension/sumologicextension\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/aws/awsutil\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/aws/containerinsight\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/aws/cwlogs\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/aws/ecsutil\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/aws/k8s\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/aws/metrics\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/aws/proxy\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/aws/xray\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/aws/xray/testdata/sampleapp\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/aws/xray/testdata/sampleserver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/collectd\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/common\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/coreinternal\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/docker\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/exp/metrics\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/filter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/grpcutil\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/k8sconfig\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/k8stest\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/kafka\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/kubelet\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/metadataproviders\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/pdatautil\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/rabbitmq\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/otelarrow\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/sharedcomponent\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/splunk\n      - github.com/open-telemetry/opentelemetry-collector-contrib/internal/sqlquery\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/batchperresourceattr\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/batchpersignal\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/experimentalmetricmetadata\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/golden\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/kafka/topic\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/ottl\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/pdatatest\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/pdatautil\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/resourcetotelemetry\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/sampling\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/stanza\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/datadog\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/status\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/translator/azure\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/translator/azurelogs\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/translator/jaeger\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/translator/loki\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/translator/opencensus\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/translator/prometheus\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/translator/prometheusremotewrite\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/translator/signalfx\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/translator/skywalking\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/translator/zipkin\n      - github.com/open-telemetry/opentelemetry-collector-contrib/pkg/winperfcounters\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/attributesprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/cumulativetodeltaprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/coralogixprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/deltatocumulativeprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/deltatorateprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/filterprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/geoipprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/groupbyattrsprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/groupbytraceprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/intervalprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/k8sattributesprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/logdedupprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/logstransformprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/metricsgenerationprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/metricstransformprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/probabilisticsamplerprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/redactionprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/remotetapprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/resourcedetectionprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/resourceprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/routingprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/schemaprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/spanprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/sumologicprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/tailsamplingprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/processor/transformprocessor\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/activedirectorydsreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/aerospikereceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/apachereceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/apachesparkreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/awscloudwatchmetricsreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/awscloudwatchreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/awscontainerinsightreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/awsecscontainermetricsreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/awsfirehosereceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/awss3receiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/awsxrayreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/azureblobreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/azureeventhubreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/azuremonitorreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/bigipreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/carbonreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/chronyreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/cloudflarereceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/cloudfoundryreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/collectdreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/couchdbreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/datadogreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/dockerstatsreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/elasticsearchreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/expvarreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/filelogreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/filestatsreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/flinkmetricsreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/fluentforwardreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/githubreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/googlecloudmonitoringreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/googlecloudpubsubreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/googlecloudspannerreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/haproxyreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/hostmetricsreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/huaweicloudcesreceiver      \n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/httpcheckreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/iisreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/influxdbreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/jaegerreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/jmxreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/journaldreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/k8sclusterreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/k8seventsreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/k8sobjectsreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/kafkametricsreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/kafkareceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/kubeletstatsreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/libhoneyreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/lokireceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/memcachedreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/mongodbatlasreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/mongodbreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/mysqlreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/namedpipereceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/nginxreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/netflowreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/nsxtreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/ntpreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/opencensusreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/oracledbreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/osqueryreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/otelarrowreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/otlpjsonfilereceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/podmanreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/postgresqlreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/prometheusreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/prometheusremotewritereceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/pulsarreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/purefareceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/purefbreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/rabbitmqreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/receivercreator\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/redisreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/riakreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/saphanareceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/sapmreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/signalfxreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/simpleprometheusreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/simpleprometheusreceiver/examples/federation/prom-counter\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/skywalkingreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/snmpreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/snowflakereceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/solacereceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/splunkenterprisereceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/splunkhecreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/sqlqueryreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/sqlserverreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/sshcheckreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/statsdreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/syslogreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/systemdreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/tcplogreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/tlscheckreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/udplogreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/vcenterreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/wavefrontreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/webhookeventreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/windowseventlogreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/windowsperfcountersreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/zipkinreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/receiver/zookeeperreceiver\n      - github.com/open-telemetry/opentelemetry-collector-contrib/testbed\n      - github.com/open-telemetry/opentelemetry-collector-contrib/testbed/mockdatasenders/mockdatadogagentexporter\n\nexcluded-modules:\n  - github.com/open-telemetry/opentelemetry-collector-contrib/cmd/otelcontribcol\n  - github.com/open-telemetry/opentelemetry-collector-contrib/cmd/oteltestbedcol\n  - github.com/open-telemetry/opentelemetry-collector-contrib/internal/tools\n  - github.com/open-telemetry/opentelemetry-collector-contrib/cmd/telemetrygen/internal/e2etest\n"
        }
      ]
    }
  ]
}