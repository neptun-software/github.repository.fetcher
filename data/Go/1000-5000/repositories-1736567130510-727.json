{
  "metadata": {
    "timestamp": 1736567130510,
    "page": 727,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjczMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "nsqio/go-nsq",
      "stars": 2600,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": "AUTHORS",
          "type": "blob",
          "size": 0.404296875,
          "content": "# For a complete listing, see https://github.com/nsqio/go-nsq/graphs/contributors\n\n# Original Authors\n\nMatt Reiferson <mreiferson@gmail.com>\nJehiah Czebotar <jehiah@gmail.com>\n\n# Maintainers\n\nPierce Lopez <ploxiln@gmail.com>\n\n# Disclaimer\n\nMatt Reiferson's contributions to this project are being made solely in a personal capacity\nand does not convey any rights to any intellectual property of any third parties.\n"
        },
        {
          "name": "ChangeLog.md",
          "type": "blob",
          "size": 10.650390625,
          "content": "## go-nsq Change Log\n\n### 1.1.0 - 2021-10-25\n\n * #275/#281 - support separate Logger for each log level (thanks @crazyweave)\n * #282 - consumer: reduce duplicate RDY (ready) count updates (thanks @andyxning)\n * #283 - remove redundant Config initialized check (thanks @SwanSpouse)\n * #313 - add Authorization header to lookup queries\n * #321 - consumer: fix panic with some invalid lookupd http addresses (thanks @martin-sucha)\n * #317 - producer: connect() code-style improvement (thanks @martin-sucha)\n * #330 - fix random backoff jitter on 32-bit architectures\n * #333 - consumer: re-use http client with keepalives for lookupd requests (thanks @JieTrancender)\n * #336 - producer: shutdown logging prefix consistent with other logging (thanks @karalabe)\n * #294 - docs: fix producer example (thanks @nikitabuyevich)\n * #307 - docs: add exit signal handling to consumer example\n * #324 - docs: fix Consumer.SetLogger() description (thanks @gabriel-vasile)\n * #297 - add AUTHORS file\n * #329/#330 - switch to GitHub Actions for CI\n\n### 1.0.8 - 2019-12-24\n\nThanks to @judwhite, @vitaliytv, and @HaraldNordgren for contributing to testing and dependency management improvements\n\n * #248 - support go modules\n * #249 - consumer: update RDY when setting MaxInFlight to 0\n * #267 - check response message size is positive (thanks @andyxning)\n * #271 - godoc for publisher and consumer (thanks @skateinmars)\n * #270 - set log level (thanks @YongHaoWu)\n * #255 - go vet tls.Config copying (thanks @iaburton)\n\n### 1.0.7 - 2017-08-04\n\n**Upgrading from 1.0.6**: There are no backward incompatible changes.\n\n * #97/#209 - consumer: retry nsqlookupd queries\n * #179/#208 - consumer: redistribute RDY when connections are active\n * #184/#201 - producer: fix misleading Stop() EOF (thanks @mengskysama)\n * #203 - switch to golang/snappy (addressing potential snappy related deadlocks)\n * #202 - consumer: fix backoff logging\n\n### 1.0.6 - 2016-06-04\n\n**Upgrading from 1.0.5**: There are no backward incompatible changes.\n\n * #175 - consumer: reduce garbage generation in DecodeMessage (thanks @Dieterbe)\n * #162 - producer: support `DeferredPublish` (thanks @DanielHeckrath)\n\n### 1.0.5 - 2015-09-19\n\n**Upgrading from 1.0.4**: There are no backward incompatible changes.\n\n * #156 - consumer: prevent data race on RNG\n * #155 - config: support `flag.Value` interface\n * #147/#150 - consumer: fix application of `max_backoff_duration` (thanks @judwhite)\n * #138 - fix lint, vet, fmt issues\n * #137 - remove `go-simplejson` dependency\n\n### 1.0.4 - 2015-04-07\n\n**Upgrading from 1.0.3**: There are no backward incompatible changes.\n\n * #133 - fix `ErrNotConnected` race during `Producer` connection (thanks @jeddenlea)\n * #132 - fix `RDY` redistribution after backoff with no connections\n * #128 - fix backoff stall when using `RequeueWithoutBackoff`\n * #127 - fix handling of connection closing when resuming after backoff (thanks @jnewmano)\n * #126 - allow `BackoffStrategy` to be set via flag (thanks @twmb)\n * #125 - add pluggable consumer `BackoffStrategy`; add full-jitter strategy (thanks @hden)\n * #124 - add `DialTimeout` and `LocalAddr` config (thanks @yashkin)\n * #119 - add `Producer.Ping()` method (thanks @zulily)\n * #122 - refactor log level string handling\n * #120 - fix `Message` data races on `responded`\n * #114 - fix lookupd jitter having no effect (thanks @judwhite)\n\n### 1.0.3 - 2015-02-07\n\n**Upgrading from 1.0.2**: There are no backward incompatible changes.\n\n * #104 - fix reconnect address bug (thanks @ryanslade)\n * #106 - fix backoff reconnect deadlock (thanks @ryanslade)\n * #107 - fix out-of-bounds error when removing nsqlookupd addresses (thanks @andreas)\n * #108 - fix potential logger race conditions (thanks @judwhite)\n * #111 - fix resolved address error in reconnect loop (thanks @twmb)\n\n### 1.0.2 - 2015-01-21\n\n**Upgrading from 1.0.1**: There are no backward incompatible changes.\n\n * #102 - TLS min/max config defaults (thanks @twmb)\n * #99 - fix `Consumer.Stop()` race and `Producer.Stop()` deadlock (thanks @tylertreat)\n * #92 - expose `Message.NSQDAddress`\n * #95 - cleanup panic during `Consumer.Stop()` if handlers are deadlocked\n * #98 - add `tls-min-version` option (thanks @twmb)\n * #93 - expose a way to get `Consumer` runtime stats (thanks @dcarney)\n * #94 - allow `#ephemeral` topic names (thanks @jamesgroat)\n\n### 1.0.1 - 2014-11-09\n\n**Upgrading from 1.0.0**: There are no backward incompatible changes functionally, however this\nrelease no longer compiles with Go `1.0.x`.\n\n * #89 - don't spam connection teardown cleanup messages\n * #91 - add consumer `DisconnectFrom*`\n * #87 - allow `heartbeat_interval` and `output_buffer_timeout` to be disabled\n * #86 - pluggable `nsqlookupd` behaviors\n * #83 - send `RDY` before `FIN`/`REQ` (forwards compatibility with nsqio/nsq#404)\n * #82 - fix panic when conn isn't assigned\n * #75/#76 - minor config related bug fixes\n * #75/#77/#78 - add `tls-cert` and `tls-key` config options\n\n### 1.0.0 - 2014-08-11\n\n**Upgrading from 0.3.7**: The public API was significantly refactored and is not backwards\ncompatible, please read [UPGRADING](UPGRADING.md).\n\n * #58 - support `IDENTIFY` `msg_timeout`\n * #54 - per-connection TLS config and set `ServerName`\n * #49 - add common connect helpers\n * #43/#63 - more flexible `nsqlookupd` URL specification\n * #35 - `AUTH` support\n * #41/#62 - use package private RNG\n * #36 - support 64 character topic/channel names\n * #30/#38/#39/#42/#45/#46/#48/#51/#52/#65/#70 - refactor public API (see [UPGRADING](UPGRADING.md))\n\n### 0.3.7 - 2014-05-25\n\n**Upgrading from 0.3.6**: There are no backward incompatible changes. **THIS IS THE LAST STABLE\nRELEASE PROVIDING THIS API**. Future releases will be based on the api in #30 and **will not be\nbackwards compatible!**\n\nThis is a bug fix release relating to the refactoring done in `0.3.6`.\n\n * #32 - fix potential panic for race condition when # conns == 0\n * #33/#34 - more granular connection locking\n\n### 0.3.6 - 2014-04-29\n\n**Upgrading from 0.3.5**: There are no backward incompatible changes.\n\nThis release includes a significant internal refactoring, designed\nto better encapsulate responsibility, see #19.\n\nSpecifically:\n\n * make `Conn` public\n * move transport responsibilities into `Conn` from `Reader`/`Writer`\n * supply callbacks for hooking into `Conn` events\n\nAs part of the refactoring, a few additional clean exit related \nissues were resolved:\n\n * wait group now includes all exit related goroutines\n * ensure that readLoop exits before exiting cleanup\n * always check messagesInFlight at readLoop exit\n * close underlying connection last\n\n### 0.3.5 - 2014-04-05\n\n**Upgrading from 0.3.4**: There are no backward incompatible changes.\n\nThis release includes a few new features such as support for channel\nsampling and sending along a user agent string (which is now displayed\nin `nsqadmin`).\n\nAlso, a critical bug fix for potential deadlocks (thanks @kjk\nfor reporting and help testing).\n\nNew Features/Improvements:\n\n * #27 - reader logs disambiguate topic/channel\n * #22 - channel sampling\n * #23 - user agent\n\nBug Fixes:\n\n * #24 - fix racey reader IDENTIFY buffering\n * #29 - fix recursive RLock deadlocks\n\n### 0.3.4 - 2013-11-19\n\n**Upgrading from 0.3.3**: There are no backward incompatible changes.\n\nThis is a bug fix release, notably potential deadlocks in `Message.Requeue()` and `Message.Touch()`\nas well as a potential busy loop cleaning up closed connections with in-flight messages.\n\nNew Features/Improvements:\n\n * #14 - add `Reader.Configure()`\n * #18 - return an exported error when an `nsqlookupd` address is already configured\n\nBug Fixes:\n\n * #15 - dont let `handleError()` loop if already connected\n * #17 - resolve potential deadlocks on `Message` responders\n * #16 - eliminate busy loop when draining `finishedMessages`\n\n### 0.3.3 - 2013-10-21\n\n**Upgrading from 0.3.2**: This release requires NSQ binary version `0.2.23+` for compression\nsupport.\n\nThis release contains significant `Reader` refactoring of the RDY handling code paths. The\nmotivation is documented in #1 however the commits in #8 identify individual changes. Additionally,\nwe eliminated deadlocks during connection cleanup in `Writer`.\n\nAs a result, both user-facing APIs should now be considerably more robust and stable. Additionally,\n`Reader` should behave better when backing off.\n\nNew Features/Improvements:\n\n * #9 - ability to ignore publish responses in `Writer`\n * #12 - `Requeue()` method on `Message`\n * #6 - `Touch()` method on `Message`\n * #4 - snappy/deflate feature negotiation\n\nBug Fixes:\n\n * #8 - `Reader` RDY handling refactoring (race conditions, deadlocks, consolidation)\n * #13 - fix `Writer` deadlocks\n * #10 - stop accessing simplejson internals\n * #5 - fix `max-in-flight` race condition\n\n### 0.3.2 - 2013-08-26\n\n**Upgrading from 0.3.1**: This release requires NSQ binary version `0.2.22+` for TLS support.\n\nNew Features/Improvements:\n\n * #227 - TLS feature negotiation\n * #164/#202/#255 - add `Writer`\n * #186 - `MaxBackoffDuration` of `0` disables backoff\n * #175 - support for `nsqd` config option `--max-rdy-count`\n * #169 - auto-reconnect to hard-coded `nsqd`\n\nBug Fixes:\n\n * #254/#256/#257 - new connection RDY starvation\n * #250 - `nsqlookupd` polling improvements\n * #243 - limit `IsStarved()` to connections w/ in-flight messages\n * #169 - use last RDY count for `IsStarved()`; redistribute RDY state\n * #204 - fix early termination blocking\n * #177 - support `broadcast_address`\n * #161 - connection pool goroutine safety\n\n### 0.3.1 - 2013-02-07\n\n**Upgrading from 0.3.0**: This release requires NSQ binary version `0.2.17+` for `TOUCH` support.\n\n * #119 - add TOUCH command\n * #133 - improved handling of errors/magic\n * #127 - send IDENTIFY (missed in #90)\n * #16 - add backoff to Reader\n\n### 0.3.0 - 2013-01-07\n\n**Upgrading from 0.2.4**: There are no backward incompatible changes to applications\nwritten against the public `nsq.Reader` API.\n\nHowever, there *are* a few backward incompatible changes to the API for applications that \ndirectly use other public methods, or properties of a few NSQ data types:\n\n`nsq.Message` IDs are now a type `nsq.MessageID` (a `[16]byte` array).  The signatures of\n`nsq.Finish()` and `nsq.Requeue()` reflect this change.\n\n`nsq.SendCommand()` and `nsq.Frame()` were removed in favor of `nsq.SendFramedResponse()`.\n\n`nsq.Subscribe()` no longer accepts `shortId` and `longId`.  If upgrading your consumers\nbefore upgrading your `nsqd` binaries to `0.2.16-rc.1` they will not be able to send the \noptional custom identifiers.\n    \n * #90 performance optimizations\n * #81 reader performance improvements / MPUB support\n\n### 0.2.4 - 2012-10-15\n\n * #69 added IsStarved() to reader API\n\n### 0.2.3 - 2012-10-11\n\n * #64 timeouts on reader queries to lookupd\n * #54 fix crash issue with reader cleaning up from unexpectedly closed nsqd connections\n\n### 0.2.2 - 2012-10-09\n\n * Initial public release\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 0.9990234375,
          "content": "Permission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 0.8037109375,
          "content": "## go-nsq\n\n[![Build Status](https://github.com/nsqio/go-nsq/workflows/tests/badge.svg)](https://github.com/nsqio/go-nsq/actions) [![GoDoc](https://godoc.org/github.com/nsqio/go-nsq?status.svg)](https://godoc.org/github.com/nsqio/go-nsq) [![GitHub release](https://img.shields.io/github/release/nsqio/go-nsq.svg)](https://github.com/nsqio/go-nsq/releases/latest)\n\nThe official Go package for [NSQ][nsq].\n\n### Docs\n\nSee [godoc][nsq_gopkgdoc] and the [main repo apps][apps] directory for examples of clients built\nusing this package.\n\n### Tests\n\nTests are run via `./test.sh` (which requires `nsqd` and `nsqlookupd` to be installed).\n\n[nsq]: https://github.com/nsqio/nsq\n[nsq_gopkgdoc]: http://godoc.org/github.com/nsqio/go-nsq\n[apps]: https://github.com/nsqio/nsq/tree/master/apps\n[travis]: http://travis-ci.org/nsqio/go-nsq\n"
        },
        {
          "name": "UPGRADING.md",
          "type": "blob",
          "size": 6.8505859375,
          "content": "This outlines the backwards incompatible changes that were made to the public API after the\n`v0.3.7` stable release, and and how to migrate existing legacy codebases.\n\n#### Background\n\nThe original `go-nsq` codebase is some of our earliest Go code, and one of our first attempts at a\npublic Go library.\n\nWe've learned a lot over the last 2 years and we wanted `go-nsq` to reflect the experiences we've\nhad working with the library as well as the general Go conventions and best practices we picked up\nalong the way.\n\nThe diff can be seen via: https://github.com/nsqio/go-nsq/compare/v0.3.7...HEAD\n\nThe bulk of the refactoring came via: https://github.com/nsqio/go-nsq/pull/30\n\n#### Naming\n\nPreviously, the high-level types we exposed were named `nsq.Reader` and `nsq.Writer`. These\nreflected internal naming conventions we had used at bitly for some time but conflated semantics\nwith what a typical Go developer would expect (they obviously did not implement `io.Reader` and\n`io.Writer`).\n\nWe renamed these types to `nsq.Consumer` and `nsq.Producer`, which more effectively communicate\ntheir purpose and is consistent with the NSQ documentation.\n\n#### Configuration\n\nIn the previous API there were inconsistent and confusing ways to configure your clients.\n\nNow, configuration is performed *before* creating an `nsq.Consumer` or `nsq.Producer` by creating\nan `nsq.Config` struct. The only valid way to do this is via `nsq.NewConfig` (i.e. using a struct\nliteral will panic due to invalid internal state).\n\nThe `nsq.Config` struct has exported variables that can be set directly in a type-safe manner. You\ncan also call `cfg.Validate()` to check that the values are correct and within range.\n\n`nsq.Config` also exposes a convenient helper method `Set(k string, v interface{})` that can set\noptions by *coercing* the supplied `interface{}` value.\n\nThis is incredibly convenient if you're reading options from a config file or in a serialized\nformat that does not exactly match the native types.\n\nIt is both flexible and forgiving.\n\n#### Improving the nsq.Handler interface\n\n`go-nsq` attempts to make writing the common use case consumer incredibly easy.\n\nYou specify a type that implements the `nsq.Handler` interface, the interface method is called per\nmessage, and the return value of said method indicates to the library what the response to `nsqd`\nshould be (`FIN` or `REQ`), all the while managing flow control and backoff.\n\nHowever, more advanced use cases require the ability to respond to a message *later*\n(\"asynchronously\", if you will). Our original API provided a *second* message handler interface\ncalled `nsq.AsyncHandler`.\n\nUnfortunately, it was never obvious from the name alone (or even the documentation) how to properly\nuse this form. The API was needlessly complex, involving the garbage creation of wrapping structs\nto track state and respond to messages.\n\nWe originally had the same problem in `pynsq`, our Python client library, and we were able to\nresolve the tension and expose an API that was robust and supported all use cases.\n\nThe new `go-nsq` message handler interface exposes only `nsq.Handler`, and its `HandleMessage`\nmethod remains identical (specifically, `nsq.AsyncHandler` has been removed).\n\nAdditionally, the API to configure handlers has been improved to provide better first-class support\nfor common operations. We've added `AddConcurrentHandlers` (for quickly spawning multiple handler\ngoroutines).\n\nFor the most common use case, where you want `go-nsq` to respond to messages on your behalf, there\nare no changes required! In fact, we've made it even easier to implement the `nsq.Handler`\ninterface for simple functions by providing the `nsq.HandlerFunc` type (in the spirit of the Go\nstandard library's `http.HandlerFunc`):\n\n```go\nr, err := nsq.NewConsumer(\"test_topic\", \"test_channel\", nsq.NewConfig())\nif err != nil {\n    log.Fatalf(err.Error())\n}\n\nr.AddHandler(nsq.HandlerFunc(func(m *nsq.Message) error {\n    return doSomeWork(m)\n})\n\nerr := r.ConnectToNSQD(nsqdAddr)\nif err != nil {\n    log.Fatalf(err.Error())\n}\n\n<-r.StopChan\n```\n\nIn the new API, we've made the `nsq.Message` struct more robust, giving it the ability to proxy\nresponses. If you want to usurp control of the message from `go-nsq`, you simply call\n`msg.DisableAutoResponse()`.\n\nThis is effectively the same as if you had used `nsq.AsyncHandler`, only you don't need to manage\n`nsq.FinishedMessage` structs or implement a separate interface. Instead you just keep/pass\nreferences to the `nsq.Message` itself, and when you're ready to respond you call `msg.Finish()`,\n`msg.Requeue(<duration>)` or `msg.Touch(<duration>)`.  Additionally, this means you can make this\ndecision on a *per-message* basis rather than for the lifetime of the handler.\n\nHere is an example:\n\n```go\ntype myHandler struct {}\n\nfunc (h *myHandler) HandleMessage(m *nsq.Message) error {\n    m.DisableAutoResponse()\n    workerChan <- m\n    return nil\n}\n\ngo func() {\n    for m := range workerChan {\n        err := doSomeWork(m)\n        if err != nil {\n            m.Requeue(-1)\n            continue\n        }\n        m.Finish()\n    }\n}()\n\ncfg := nsq.NewConfig()\ncfg.MaxInFlight = 1000\nr, err := nsq.NewConsumer(\"test_topic\", \"test_channel\", cfg)\nif err != nil {\n    log.Fatalf(err.Error())\n}\nr.AddConcurrentHandlers(&myHandler{}, 20)\n\nerr := r.ConnectToNSQD(nsqdAddr)\nif err != nil {\n    log.Fatalf(err.Error())\n}\n\n<-r.StopChan\n```\n\n#### Requeue without backoff\n\nAs a side effect of the message handler restructuring above, it is now trivial to respond to a\nmessage without triggering a backoff state in `nsq.Consumer` (which was not possible in the\nprevious API).\n\nThe `nsq.Message` type now has a `msg.RequeueWithoutBackoff()` method for this purpose.\n\n#### Producer Error Handling\n\nPreviously, `Writer` (now `Producer`) returned a triplicate of `frameType`, `responseBody`, and\n`error` from calls to `*Publish`.\n\nThis required the caller to check both `error` and `frameType` to confirm success. `Producer`\npublish methods now return only `error`.\n\n#### Logging\n\nOne of the challenges library implementors face is how to provide feedback via logging, while\nexposing an interface that follows the standard library and still provides a means to control and\nconfigure the output.\n\nIn the new API, we've provided a method on `Consumer` and `Producer` called `SetLogger` that takes\nan interface compatible with the Go standard library `log.Logger` (which can be instantiated via\n`log.NewLogger`) and a traditional log level integer `nsq.LogLevel{Debug,Info,Warning,Error}`:\n\n    Output(maxdepth int, s string) error\n\nThis gives the user the flexibility to control the format, destination, and verbosity while still\nconforming to standard library logging conventions.\n\n#### Misc.\n\nUn-exported `NewDeadlineTransport` and `ApiRequest`, which never should have been exported in the\nfirst place.\n\n`nsq.Message` serialization switched away from `binary.{Read,Write}` for performance and\n`nsq.Message` now implements the `io.WriterTo` interface.\n"
        },
        {
          "name": "api_request.go",
          "type": "blob",
          "size": 1.5615234375,
          "content": "package nsq\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"net/http\"\n\t\"time\"\n)\n\ntype deadlinedConn struct {\n\tTimeout time.Duration\n\tnet.Conn\n}\n\nfunc (c *deadlinedConn) Read(b []byte) (n int, err error) {\n\tc.Conn.SetReadDeadline(time.Now().Add(c.Timeout))\n\treturn c.Conn.Read(b)\n}\n\nfunc (c *deadlinedConn) Write(b []byte) (n int, err error) {\n\tc.Conn.SetWriteDeadline(time.Now().Add(c.Timeout))\n\treturn c.Conn.Write(b)\n}\n\ntype wrappedResp struct {\n\tStatus     string      `json:\"status_txt\"`\n\tStatusCode int         `json:\"status_code\"`\n\tData       interface{} `json:\"data\"`\n}\n\n// stores the result in the value pointed to by ret(must be a pointer)\nfunc apiRequestNegotiateV1(httpclient *http.Client, method string, endpoint string, headers http.Header, ret interface{}) error {\n\treq, err := http.NewRequest(method, endpoint, nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor k, v := range headers {\n\t\treq.Header[k] = v\n\t}\n\n\treq.Header.Add(\"Accept\", \"application/vnd.nsq; version=1.0\")\n\n\tresp, err := httpclient.Do(req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\trespBody, err := io.ReadAll(resp.Body)\n\tresp.Body.Close()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif resp.StatusCode != 200 {\n\t\treturn fmt.Errorf(\"got response %s %q\", resp.Status, respBody)\n\t}\n\n\tif len(respBody) == 0 {\n\t\trespBody = []byte(\"{}\")\n\t}\n\n\tif resp.Header.Get(\"X-NSQ-Content-Type\") == \"nsq; version=1.0\" {\n\t\treturn json.Unmarshal(respBody, ret)\n\t}\n\n\twResp := &wrappedResp{\n\t\tData: ret,\n\t}\n\n\tif err = json.Unmarshal(respBody, wResp); err != nil {\n\t\treturn err\n\t}\n\n\t// wResp.StatusCode here is equal to resp.StatusCode, so ignore it\n\treturn nil\n}\n"
        },
        {
          "name": "command.go",
          "type": "blob",
          "size": 6.0263671875,
          "content": "package nsq\n\nimport (\n\t\"bytes\"\n\t\"encoding/binary\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"strconv\"\n\t\"time\"\n)\n\nvar byteSpace = []byte(\" \")\nvar byteNewLine = []byte(\"\\n\")\n\n// Command represents a command from a client to an NSQ daemon\ntype Command struct {\n\tName   []byte\n\tParams [][]byte\n\tBody   []byte\n}\n\n// String returns the name and parameters of the Command\nfunc (c *Command) String() string {\n\tif len(c.Params) > 0 {\n\t\treturn fmt.Sprintf(\"%s %s\", c.Name, string(bytes.Join(c.Params, byteSpace)))\n\t}\n\treturn string(c.Name)\n}\n\n// WriteTo implements the WriterTo interface and\n// serializes the Command to the supplied Writer.\n//\n// It is suggested that the target Writer is buffered\n// to avoid performing many system calls.\nfunc (c *Command) WriteTo(w io.Writer) (int64, error) {\n\tvar total int64\n\tvar buf [4]byte\n\n\tn, err := w.Write(c.Name)\n\ttotal += int64(n)\n\tif err != nil {\n\t\treturn total, err\n\t}\n\n\tfor _, param := range c.Params {\n\t\tn, err := w.Write(byteSpace)\n\t\ttotal += int64(n)\n\t\tif err != nil {\n\t\t\treturn total, err\n\t\t}\n\t\tn, err = w.Write(param)\n\t\ttotal += int64(n)\n\t\tif err != nil {\n\t\t\treturn total, err\n\t\t}\n\t}\n\n\tn, err = w.Write(byteNewLine)\n\ttotal += int64(n)\n\tif err != nil {\n\t\treturn total, err\n\t}\n\n\tif c.Body != nil {\n\t\tbufs := buf[:]\n\t\tbinary.BigEndian.PutUint32(bufs, uint32(len(c.Body)))\n\t\tn, err := w.Write(bufs)\n\t\ttotal += int64(n)\n\t\tif err != nil {\n\t\t\treturn total, err\n\t\t}\n\t\tn, err = w.Write(c.Body)\n\t\ttotal += int64(n)\n\t\tif err != nil {\n\t\t\treturn total, err\n\t\t}\n\t}\n\n\treturn total, nil\n}\n\n// Identify creates a new Command to provide information about the client.  After connecting,\n// it is generally the first message sent.\n//\n// The supplied map is marshaled into JSON to provide some flexibility\n// for this command to evolve over time.\n//\n// See http://nsq.io/clients/tcp_protocol_spec.html#identify for information\n// on the supported options\nfunc Identify(js map[string]interface{}) (*Command, error) {\n\tbody, err := json.Marshal(js)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &Command{[]byte(\"IDENTIFY\"), nil, body}, nil\n}\n\n// Auth sends credentials for authentication\n//\n// After `Identify`, this is usually the first message sent, if auth is used.\nfunc Auth(secret string) (*Command, error) {\n\treturn &Command{[]byte(\"AUTH\"), nil, []byte(secret)}, nil\n}\n\n// Register creates a new Command to add a topic/channel for the connected nsqd\nfunc Register(topic string, channel string) *Command {\n\tparams := [][]byte{[]byte(topic)}\n\tif len(channel) > 0 {\n\t\tparams = append(params, []byte(channel))\n\t}\n\treturn &Command{[]byte(\"REGISTER\"), params, nil}\n}\n\n// UnRegister creates a new Command to remove a topic/channel for the connected nsqd\nfunc UnRegister(topic string, channel string) *Command {\n\tparams := [][]byte{[]byte(topic)}\n\tif len(channel) > 0 {\n\t\tparams = append(params, []byte(channel))\n\t}\n\treturn &Command{[]byte(\"UNREGISTER\"), params, nil}\n}\n\n// Ping creates a new Command to keep-alive the state of all the\n// announced topic/channels for a given client\nfunc Ping() *Command {\n\treturn &Command{[]byte(\"PING\"), nil, nil}\n}\n\n// Publish creates a new Command to write a message to a given topic\nfunc Publish(topic string, body []byte) *Command {\n\tvar params = [][]byte{[]byte(topic)}\n\treturn &Command{[]byte(\"PUB\"), params, body}\n}\n\n// DeferredPublish creates a new Command to write a message to a given topic\n// where the message will queue at the channel level until the timeout expires\nfunc DeferredPublish(topic string, delay time.Duration, body []byte) *Command {\n\tvar params = [][]byte{[]byte(topic), []byte(strconv.Itoa(int(delay / time.Millisecond)))}\n\treturn &Command{[]byte(\"DPUB\"), params, body}\n}\n\n// MultiPublish creates a new Command to write more than one message to a given topic\n// (useful for high-throughput situations to avoid roundtrips and saturate the pipe)\nfunc MultiPublish(topic string, bodies [][]byte) (*Command, error) {\n\tvar params = [][]byte{[]byte(topic)}\n\n\tnum := uint32(len(bodies))\n\tbodySize := 4\n\tfor _, b := range bodies {\n\t\tbodySize += len(b) + 4\n\t}\n\tbody := make([]byte, 0, bodySize)\n\tbuf := bytes.NewBuffer(body)\n\n\terr := binary.Write(buf, binary.BigEndian, &num)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfor _, b := range bodies {\n\t\terr = binary.Write(buf, binary.BigEndian, int32(len(b)))\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t_, err = buf.Write(b)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn &Command{[]byte(\"MPUB\"), params, buf.Bytes()}, nil\n}\n\n// Subscribe creates a new Command to subscribe to the given topic/channel\nfunc Subscribe(topic string, channel string) *Command {\n\tvar params = [][]byte{[]byte(topic), []byte(channel)}\n\treturn &Command{[]byte(\"SUB\"), params, nil}\n}\n\n// Ready creates a new Command to specify\n// the number of messages a client is willing to receive\nfunc Ready(count int) *Command {\n\tvar params = [][]byte{[]byte(strconv.Itoa(count))}\n\treturn &Command{[]byte(\"RDY\"), params, nil}\n}\n\n// Finish creates a new Command to indiciate that\n// a given message (by id) has been processed successfully\nfunc Finish(id MessageID) *Command {\n\tvar params = [][]byte{id[:]}\n\treturn &Command{[]byte(\"FIN\"), params, nil}\n}\n\n// Requeue creates a new Command to indicate that\n// a given message (by id) should be requeued after the given delay\n// NOTE: a delay of 0 indicates immediate requeue\nfunc Requeue(id MessageID, delay time.Duration) *Command {\n\tvar params = [][]byte{id[:], []byte(strconv.Itoa(int(delay / time.Millisecond)))}\n\treturn &Command{[]byte(\"REQ\"), params, nil}\n}\n\n// Touch creates a new Command to reset the timeout for\n// a given message (by id)\nfunc Touch(id MessageID) *Command {\n\tvar params = [][]byte{id[:]}\n\treturn &Command{[]byte(\"TOUCH\"), params, nil}\n}\n\n// StartClose creates a new Command to indicate that the\n// client would like to start a close cycle.  nsqd will no longer\n// send messages to a client in this state and the client is expected\n// finish pending messages and close the connection\nfunc StartClose() *Command {\n\treturn &Command{[]byte(\"CLS\"), nil, nil}\n}\n\n// Nop creates a new Command that has no effect server side.\n// Commonly used to respond to heartbeats\nfunc Nop() *Command {\n\treturn &Command{[]byte(\"NOP\"), nil, nil}\n}\n"
        },
        {
          "name": "command_test.go",
          "type": "blob",
          "size": 0.2421875,
          "content": "package nsq\n\nimport (\n\t\"bytes\"\n\t\"testing\"\n)\n\nfunc BenchmarkCommand(b *testing.B) {\n\tb.StopTimer()\n\tdata := make([]byte, 2048)\n\tcmd := Publish(\"test\", data)\n\tvar buf bytes.Buffer\n\tb.StartTimer()\n\n\tfor i := 0; i < b.N; i++ {\n\t\tcmd.WriteTo(&buf)\n\t}\n}\n"
        },
        {
          "name": "config.go",
          "type": "blob",
          "size": 19.5732421875,
          "content": "package nsq\n\nimport (\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"errors\"\n\t\"fmt\"\n\t\"log\"\n\t\"math\"\n\t\"math/rand\"\n\t\"net\"\n\t\"os\"\n\t\"reflect\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\t\"unsafe\"\n)\n\n// Define handlers for setting config defaults, and setting config values from command line arguments or config files\ntype configHandler interface {\n\tHandlesOption(c *Config, option string) bool\n\tSet(c *Config, option string, value interface{}) error\n\tValidate(c *Config) error\n}\n\ntype defaultsHandler interface {\n\tSetDefaults(c *Config) error\n}\n\n// BackoffStrategy defines a strategy for calculating the duration of time\n// a consumer should backoff for a given attempt\ntype BackoffStrategy interface {\n\tCalculate(attempt int) time.Duration\n}\n\n// ExponentialStrategy implements an exponential backoff strategy (default)\ntype ExponentialStrategy struct {\n\tcfg *Config\n}\n\n// Calculate returns a duration of time: 2 ^ attempt\nfunc (s *ExponentialStrategy) Calculate(attempt int) time.Duration {\n\tbackoffDuration := s.cfg.BackoffMultiplier *\n\t\ttime.Duration(math.Pow(2, float64(attempt)))\n\treturn backoffDuration\n}\n\nfunc (s *ExponentialStrategy) setConfig(cfg *Config) {\n\ts.cfg = cfg\n}\n\n// FullJitterStrategy implements http://www.awsarchitectureblog.com/2015/03/backoff.html\ntype FullJitterStrategy struct {\n\tcfg *Config\n\n\trngOnce sync.Once\n\trng     *rand.Rand\n}\n\n// Calculate returns a random duration of time [0, 2 ^ attempt]\nfunc (s *FullJitterStrategy) Calculate(attempt int) time.Duration {\n\t// lazily initialize the RNG\n\ts.rngOnce.Do(func() {\n\t\tif s.rng != nil {\n\t\t\treturn\n\t\t}\n\t\ts.rng = rand.New(rand.NewSource(time.Now().UnixNano()))\n\t})\n\n\tbackoffDuration := s.cfg.BackoffMultiplier *\n\t\ttime.Duration(math.Pow(2, float64(attempt)))\n\treturn time.Duration(s.rng.Int63n(int64(backoffDuration)))\n}\n\nfunc (s *FullJitterStrategy) setConfig(cfg *Config) {\n\ts.cfg = cfg\n}\n\n// Config is a struct of NSQ options\n//\n// The only valid way to create a Config is via NewConfig, using a struct literal will panic.\n// After Config is passed into a high-level type (like Consumer, Producer, etc.) the values are no\n// longer mutable (they are copied).\n//\n// Use Set(option string, value interface{}) as an alternate way to set parameters\ntype Config struct {\n\tinitialized bool\n\n\t// used to Initialize, Validate\n\tconfigHandlers []configHandler\n\n\tDialTimeout time.Duration `opt:\"dial_timeout\" default:\"1s\"`\n\n\t// Deadlines for network reads and writes\n\tReadTimeout  time.Duration `opt:\"read_timeout\" min:\"100ms\" max:\"5m\" default:\"60s\"`\n\tWriteTimeout time.Duration `opt:\"write_timeout\" min:\"100ms\" max:\"5m\" default:\"1s\"`\n\n\t// LocalAddr is the local address to use when dialing an nsqd.\n\t// If empty, a local address is automatically chosen.\n\tLocalAddr net.Addr `opt:\"local_addr\"`\n\n\t// Duration between polling lookupd for new producers, and fractional jitter to add to\n\t// the lookupd pool loop. this helps evenly distribute requests even if multiple consumers\n\t// restart at the same time\n\t//\n\t// NOTE: when not using nsqlookupd, LookupdPollInterval represents the duration of time between\n\t// reconnection attempts\n\tLookupdPollInterval time.Duration `opt:\"lookupd_poll_interval\" min:\"10ms\" max:\"5m\" default:\"60s\"`\n\tLookupdPollJitter   float64       `opt:\"lookupd_poll_jitter\" min:\"0\" max:\"1\" default:\"0.3\"`\n\tLookupdPollTimeout  time.Duration `opt:\"lookupd_poll_timeout\" default:\"1m\"`\n\n\t// Maximum duration when REQueueing (for doubling of deferred requeue)\n\tMaxRequeueDelay     time.Duration `opt:\"max_requeue_delay\" min:\"0\" max:\"60m\" default:\"15m\"`\n\tDefaultRequeueDelay time.Duration `opt:\"default_requeue_delay\" min:\"0\" max:\"60m\" default:\"90s\"`\n\n\t// Backoff strategy, defaults to exponential backoff. Overwrite this to define alternative backoff algrithms.\n\tBackoffStrategy BackoffStrategy `opt:\"backoff_strategy\" default:\"exponential\"`\n\t// Maximum amount of time to backoff when processing fails 0 == no backoff\n\tMaxBackoffDuration time.Duration `opt:\"max_backoff_duration\" min:\"0\" max:\"60m\" default:\"2m\"`\n\t// Unit of time for calculating consumer backoff\n\tBackoffMultiplier time.Duration `opt:\"backoff_multiplier\" min:\"0\" max:\"60m\" default:\"1s\"`\n\n\t// Maximum number of times this consumer will attempt to process a message before giving up\n\tMaxAttempts uint16 `opt:\"max_attempts\" min:\"0\" max:\"65535\" default:\"5\"`\n\n\t// Duration to wait for a message from an nsqd when in a state where RDY\n\t// counts are re-distributed (e.g. max_in_flight < num_producers)\n\tLowRdyIdleTimeout time.Duration `opt:\"low_rdy_idle_timeout\" min:\"1s\" max:\"5m\" default:\"10s\"`\n\t// Duration to wait until redistributing RDY for an nsqd regardless of LowRdyIdleTimeout\n\tLowRdyTimeout time.Duration `opt:\"low_rdy_timeout\" min:\"1s\" max:\"5m\" default:\"30s\"`\n\t// Duration between redistributing max-in-flight to connections\n\tRDYRedistributeInterval time.Duration `opt:\"rdy_redistribute_interval\" min:\"1ms\" max:\"5s\" default:\"5s\"`\n\n\t// Identifiers sent to nsqd representing this client\n\t// UserAgent is in the spirit of HTTP (default: \"<client_library_name>/<version>\")\n\tClientID  string `opt:\"client_id\"` // (defaults: short hostname)\n\tHostname  string `opt:\"hostname\"`\n\tUserAgent string `opt:\"user_agent\"`\n\n\t// Duration of time between heartbeats. This must be less than ReadTimeout\n\tHeartbeatInterval time.Duration `opt:\"heartbeat_interval\" default:\"30s\"`\n\t// Integer percentage to sample the channel (requires nsqd 0.2.25+)\n\tSampleRate int32 `opt:\"sample_rate\" min:\"0\" max:\"99\"`\n\n\t// To set TLS config, use the following options:\n\t//\n\t// tls_v1 - Bool enable TLS negotiation\n\t// tls_root_ca_file - String path to file containing root CA\n\t// tls_insecure_skip_verify - Bool indicates whether this client should verify server certificates\n\t// tls_cert - String path to file containing public key for certificate\n\t// tls_key - String path to file containing private key for certificate\n\t// tls_min_version - String indicating the minimum version of tls acceptable ('ssl3.0', 'tls1.0', 'tls1.1', 'tls1.2')\n\t//\n\tTlsV1     bool        `opt:\"tls_v1\"`\n\tTlsConfig *tls.Config `opt:\"tls_config\"`\n\n\t// Compression Settings\n\tDeflate      bool `opt:\"deflate\"`\n\tDeflateLevel int  `opt:\"deflate_level\" min:\"1\" max:\"9\" default:\"6\"`\n\tSnappy       bool `opt:\"snappy\"`\n\n\t// Size of the buffer (in bytes) used by nsqd for buffering writes to this connection\n\tOutputBufferSize int64 `opt:\"output_buffer_size\" default:\"16384\"`\n\t// Timeout used by nsqd before flushing buffered writes (set to 0 to disable).\n\t//\n\t// WARNING: configuring clients with an extremely low\n\t// (< 25ms) output_buffer_timeout has a significant effect\n\t// on nsqd CPU usage (particularly with > 50 clients connected).\n\tOutputBufferTimeout time.Duration `opt:\"output_buffer_timeout\" default:\"250ms\"`\n\n\t// Maximum number of messages to allow in flight (concurrency knob)\n\tMaxInFlight int `opt:\"max_in_flight\" min:\"0\" default:\"1\"`\n\n\t// The server-side message timeout for messages delivered to this client\n\tMsgTimeout time.Duration `opt:\"msg_timeout\" min:\"0\"`\n\n\t// Maximum size of a single message in bytes (0 means no limit)\n\tMaxMsgSize int32 `opt:\"max_msg_size\" min:\"0\" default:\"0\"`\n\n\t// Secret for nsqd authentication (requires nsqd 0.2.29+)\n\tAuthSecret string `opt:\"auth_secret\"`\n\t// Use AuthSecret as 'Authorization: Bearer {AuthSecret}' on lookupd queries\n\tLookupdAuthorization bool `opt:\"skip_lookupd_authorization\" default:\"true\"`\n}\n\n// NewConfig returns a new default nsq configuration.\n//\n// This must be used to initialize Config structs. Values can be set directly, or through Config.Set()\nfunc NewConfig() *Config {\n\tc := &Config{\n\t\tconfigHandlers: []configHandler{&structTagsConfig{}, &tlsConfig{}},\n\t\tinitialized:    true,\n\t}\n\tif err := c.setDefaults(); err != nil {\n\t\tpanic(err.Error())\n\t}\n\treturn c\n}\n\n// Set takes an option as a string and a value as an interface and\n// attempts to set the appropriate configuration option.\n//\n// It attempts to coerce the value into the right format depending on the named\n// option and the underlying type of the value passed in.\n//\n// Calls to Set() that take a time.Duration as an argument can be input as:\n//\n//\t\"1000ms\" (a string parsed by time.ParseDuration())\n//\t1000 (an integer interpreted as milliseconds)\n//\t1000*time.Millisecond (a literal time.Duration value)\n//\n// Calls to Set() that take bool can be input as:\n//\n//\t\"true\" (a string parsed by strconv.ParseBool())\n//\ttrue (a boolean)\n//\t1 (an int where 1 == true and 0 == false)\n//\n// It returns an error for an invalid option or value.\nfunc (c *Config) Set(option string, value interface{}) error {\n\tc.assertInitialized()\n\toption = strings.Replace(option, \"-\", \"_\", -1)\n\tfor _, h := range c.configHandlers {\n\t\tif h.HandlesOption(c, option) {\n\t\t\treturn h.Set(c, option, value)\n\t\t}\n\t}\n\treturn fmt.Errorf(\"invalid option %s\", option)\n}\n\nfunc (c *Config) assertInitialized() {\n\tif !c.initialized {\n\t\tpanic(\"Config{} must be created with NewConfig()\")\n\t}\n}\n\n// Validate checks that all values are within specified min/max ranges\nfunc (c *Config) Validate() error {\n\tc.assertInitialized()\n\tfor _, h := range c.configHandlers {\n\t\tif err := h.Validate(c); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (c *Config) setDefaults() error {\n\tfor _, h := range c.configHandlers {\n\t\thh, ok := h.(defaultsHandler)\n\t\tif ok {\n\t\t\tif err := hh.SetDefaults(c); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}\n\ntype structTagsConfig struct{}\n\n// Handle options that are listed in StructTags\nfunc (h *structTagsConfig) HandlesOption(c *Config, option string) bool {\n\tval := reflect.ValueOf(c).Elem()\n\ttyp := val.Type()\n\tfor i := 0; i < typ.NumField(); i++ {\n\t\tfield := typ.Field(i)\n\t\topt := field.Tag.Get(\"opt\")\n\t\tif opt == option {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// Set values based on parameters in StructTags\nfunc (h *structTagsConfig) Set(c *Config, option string, value interface{}) error {\n\tval := reflect.ValueOf(c).Elem()\n\ttyp := val.Type()\n\tfor i := 0; i < typ.NumField(); i++ {\n\t\tfield := typ.Field(i)\n\t\topt := field.Tag.Get(\"opt\")\n\n\t\tif option != opt {\n\t\t\tcontinue\n\t\t}\n\n\t\tmin := field.Tag.Get(\"min\")\n\t\tmax := field.Tag.Get(\"max\")\n\n\t\tfieldVal := val.FieldByName(field.Name)\n\t\tdest := unsafeValueOf(fieldVal)\n\t\tcoercedVal, err := coerce(value, field.Type)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to coerce option %s (%v) - %s\",\n\t\t\t\toption, value, err)\n\t\t}\n\t\tif min != \"\" {\n\t\t\tcoercedMinVal, _ := coerce(min, field.Type)\n\t\t\tif valueCompare(coercedVal, coercedMinVal) == -1 {\n\t\t\t\treturn fmt.Errorf(\"invalid %s ! %v < %v\",\n\t\t\t\t\toption, coercedVal.Interface(), coercedMinVal.Interface())\n\t\t\t}\n\t\t}\n\t\tif max != \"\" {\n\t\t\tcoercedMaxVal, _ := coerce(max, field.Type)\n\t\t\tif valueCompare(coercedVal, coercedMaxVal) == 1 {\n\t\t\t\treturn fmt.Errorf(\"invalid %s ! %v > %v\",\n\t\t\t\t\toption, coercedVal.Interface(), coercedMaxVal.Interface())\n\t\t\t}\n\t\t}\n\t\tif coercedVal.Type().String() == \"nsq.BackoffStrategy\" {\n\t\t\tv := coercedVal.Interface().(BackoffStrategy)\n\t\t\tif v, ok := v.(interface {\n\t\t\t\tsetConfig(*Config)\n\t\t\t}); ok {\n\t\t\t\tv.setConfig(c)\n\t\t\t}\n\t\t}\n\t\tdest.Set(coercedVal)\n\t\treturn nil\n\t}\n\treturn fmt.Errorf(\"unknown option %s\", option)\n}\n\nfunc (h *structTagsConfig) SetDefaults(c *Config) error {\n\tval := reflect.ValueOf(c).Elem()\n\ttyp := val.Type()\n\tfor i := 0; i < typ.NumField(); i++ {\n\t\tfield := typ.Field(i)\n\t\topt := field.Tag.Get(\"opt\")\n\t\tdefaultVal := field.Tag.Get(\"default\")\n\t\tif defaultVal == \"\" || opt == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\tif err := c.Set(opt, defaultVal); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\thostname, err := os.Hostname()\n\tif err != nil {\n\t\tlog.Fatalf(\"ERROR: unable to get hostname %s\", err.Error())\n\t}\n\n\tc.ClientID = strings.Split(hostname, \".\")[0]\n\tc.Hostname = hostname\n\tc.UserAgent = fmt.Sprintf(\"go-nsq/%s\", VERSION)\n\treturn nil\n}\n\nfunc (h *structTagsConfig) Validate(c *Config) error {\n\tval := reflect.ValueOf(c).Elem()\n\ttyp := val.Type()\n\tfor i := 0; i < typ.NumField(); i++ {\n\t\tfield := typ.Field(i)\n\n\t\tmin := field.Tag.Get(\"min\")\n\t\tmax := field.Tag.Get(\"max\")\n\n\t\tif min == \"\" && max == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\tvalue := val.FieldByName(field.Name)\n\n\t\tif min != \"\" {\n\t\t\tcoercedMinVal, _ := coerce(min, field.Type)\n\t\t\tif valueCompare(value, coercedMinVal) == -1 {\n\t\t\t\treturn fmt.Errorf(\"invalid %s ! %v < %v\",\n\t\t\t\t\tfield.Name, value.Interface(), coercedMinVal.Interface())\n\t\t\t}\n\t\t}\n\t\tif max != \"\" {\n\t\t\tcoercedMaxVal, _ := coerce(max, field.Type)\n\t\t\tif valueCompare(value, coercedMaxVal) == 1 {\n\t\t\t\treturn fmt.Errorf(\"invalid %s ! %v > %v\",\n\t\t\t\t\tfield.Name, value.Interface(), coercedMaxVal.Interface())\n\t\t\t}\n\t\t}\n\t}\n\n\tif c.HeartbeatInterval > c.ReadTimeout {\n\t\treturn fmt.Errorf(\"HeartbeatInterval %v must be less than ReadTimeout %v\", c.HeartbeatInterval, c.ReadTimeout)\n\t}\n\n\treturn nil\n}\n\n// Parsing for higher order TLS settings\ntype tlsConfig struct {\n\tcertFile string\n\tkeyFile  string\n}\n\nfunc (t *tlsConfig) HandlesOption(c *Config, option string) bool {\n\tswitch option {\n\tcase \"tls_root_ca_file\", \"tls_insecure_skip_verify\", \"tls_cert\", \"tls_key\", \"tls_min_version\":\n\t\treturn true\n\t}\n\treturn false\n}\n\nfunc (t *tlsConfig) Set(c *Config, option string, value interface{}) error {\n\tif c.TlsConfig == nil {\n\t\tc.TlsConfig = &tls.Config{\n\t\t\tMinVersion: tls.VersionTLS10,\n\t\t\tMaxVersion: tls.VersionTLS12, // enable TLS_FALLBACK_SCSV prior to Go 1.5: https://go-review.googlesource.com/#/c/1776/\n\t\t}\n\t}\n\tval := reflect.ValueOf(c.TlsConfig).Elem()\n\n\tswitch option {\n\tcase \"tls_cert\", \"tls_key\":\n\t\tif option == \"tls_cert\" {\n\t\t\tt.certFile = value.(string)\n\t\t} else {\n\t\t\tt.keyFile = value.(string)\n\t\t}\n\t\tif t.certFile != \"\" && t.keyFile != \"\" && len(c.TlsConfig.Certificates) == 0 {\n\t\t\tcert, err := tls.LoadX509KeyPair(t.certFile, t.keyFile)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tc.TlsConfig.Certificates = []tls.Certificate{cert}\n\t\t}\n\t\treturn nil\n\tcase \"tls_root_ca_file\":\n\t\tfilename, ok := value.(string)\n\t\tif !ok {\n\t\t\treturn fmt.Errorf(\"ERROR: %v is not a string\", value)\n\t\t}\n\t\ttlsCertPool := x509.NewCertPool()\n\t\tcaCertFile, err := os.ReadFile(filename)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"ERROR: failed to read custom Certificate Authority file %s\", err)\n\t\t}\n\t\tif !tlsCertPool.AppendCertsFromPEM(caCertFile) {\n\t\t\treturn fmt.Errorf(\"ERROR: failed to append certificates from Certificate Authority file\")\n\t\t}\n\t\tc.TlsConfig.RootCAs = tlsCertPool\n\t\treturn nil\n\tcase \"tls_insecure_skip_verify\":\n\t\tfieldVal := val.FieldByName(\"InsecureSkipVerify\")\n\t\tdest := unsafeValueOf(fieldVal)\n\t\tcoercedVal, err := coerce(value, fieldVal.Type())\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to coerce option %s (%v) - %s\",\n\t\t\t\toption, value, err)\n\t\t}\n\t\tdest.Set(coercedVal)\n\t\treturn nil\n\tcase \"tls_min_version\":\n\t\tversion, ok := value.(string)\n\t\tif !ok {\n\t\t\treturn fmt.Errorf(\"ERROR: %v is not a string\", value)\n\t\t}\n\t\tswitch version {\n\t\tcase \"ssl3.0\":\n\t\t\tc.TlsConfig.MinVersion = tls.VersionSSL30\n\t\tcase \"tls1.0\":\n\t\t\tc.TlsConfig.MinVersion = tls.VersionTLS10\n\t\tcase \"tls1.1\":\n\t\t\tc.TlsConfig.MinVersion = tls.VersionTLS11\n\t\tcase \"tls1.2\":\n\t\t\tc.TlsConfig.MinVersion = tls.VersionTLS12\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"ERROR: %v is not a tls version\", value)\n\t\t}\n\t\treturn nil\n\t}\n\n\treturn fmt.Errorf(\"unknown option %s\", option)\n}\n\nfunc (t *tlsConfig) Validate(c *Config) error {\n\treturn nil\n}\n\n// because Config contains private structs we can't use reflect.Value\n// directly, instead we need to \"unsafely\" address the variable\nfunc unsafeValueOf(val reflect.Value) reflect.Value {\n\tuptr := unsafe.Pointer(val.UnsafeAddr())\n\treturn reflect.NewAt(val.Type(), uptr).Elem()\n}\n\nfunc valueCompare(v1 reflect.Value, v2 reflect.Value) int {\n\tswitch v1.Type().String() {\n\tcase \"int\", \"int16\", \"int32\", \"int64\":\n\t\tif v1.Int() > v2.Int() {\n\t\t\treturn 1\n\t\t} else if v1.Int() < v2.Int() {\n\t\t\treturn -1\n\t\t}\n\t\treturn 0\n\tcase \"uint\", \"uint16\", \"uint32\", \"uint64\":\n\t\tif v1.Uint() > v2.Uint() {\n\t\t\treturn 1\n\t\t} else if v1.Uint() < v2.Uint() {\n\t\t\treturn -1\n\t\t}\n\t\treturn 0\n\tcase \"float32\", \"float64\":\n\t\tif v1.Float() > v2.Float() {\n\t\t\treturn 1\n\t\t} else if v1.Float() < v2.Float() {\n\t\t\treturn -1\n\t\t}\n\t\treturn 0\n\tcase \"time.Duration\":\n\t\tif v1.Interface().(time.Duration) > v2.Interface().(time.Duration) {\n\t\t\treturn 1\n\t\t} else if v1.Interface().(time.Duration) < v2.Interface().(time.Duration) {\n\t\t\treturn -1\n\t\t}\n\t\treturn 0\n\t}\n\tpanic(\"impossible\")\n}\n\nfunc coerce(v interface{}, typ reflect.Type) (reflect.Value, error) {\n\tvar err error\n\tif typ.Kind() == reflect.Ptr {\n\t\treturn reflect.ValueOf(v), nil\n\t}\n\tswitch typ.String() {\n\tcase \"string\":\n\t\tv, err = coerceString(v)\n\tcase \"int\", \"int16\", \"int32\", \"int64\":\n\t\tv, err = coerceInt64(v)\n\tcase \"uint\", \"uint16\", \"uint32\", \"uint64\":\n\t\tv, err = coerceUint64(v)\n\tcase \"float32\", \"float64\":\n\t\tv, err = coerceFloat64(v)\n\tcase \"bool\":\n\t\tv, err = coerceBool(v)\n\tcase \"time.Duration\":\n\t\tv, err = coerceDuration(v)\n\tcase \"net.Addr\":\n\t\tv, err = coerceAddr(v)\n\tcase \"nsq.BackoffStrategy\":\n\t\tv, err = coerceBackoffStrategy(v)\n\tdefault:\n\t\tv = nil\n\t\terr = fmt.Errorf(\"invalid type %s\", typ.String())\n\t}\n\treturn valueTypeCoerce(v, typ), err\n}\n\nfunc valueTypeCoerce(v interface{}, typ reflect.Type) reflect.Value {\n\tval := reflect.ValueOf(v)\n\tif reflect.TypeOf(v) == typ {\n\t\treturn val\n\t}\n\ttval := reflect.New(typ).Elem()\n\tswitch typ.String() {\n\tcase \"int\", \"int16\", \"int32\", \"int64\":\n\t\ttval.SetInt(val.Int())\n\tcase \"uint\", \"uint16\", \"uint32\", \"uint64\":\n\t\ttval.SetUint(val.Uint())\n\tcase \"float32\", \"float64\":\n\t\ttval.SetFloat(val.Float())\n\tdefault:\n\t\ttval.Set(val)\n\t}\n\treturn tval\n}\n\nfunc coerceString(v interface{}) (string, error) {\n\tswitch v := v.(type) {\n\tcase string:\n\t\treturn v, nil\n\tcase int, int16, int32, int64, uint, uint16, uint32, uint64:\n\t\treturn fmt.Sprintf(\"%d\", v), nil\n\tcase float32, float64:\n\t\treturn fmt.Sprintf(\"%f\", v), nil\n\t}\n\treturn fmt.Sprintf(\"%s\", v), nil\n}\n\nfunc coerceDuration(v interface{}) (time.Duration, error) {\n\tswitch v := v.(type) {\n\tcase string:\n\t\treturn time.ParseDuration(v)\n\tcase int, int16, int32, int64:\n\t\t// treat like ms\n\t\treturn time.Duration(reflect.ValueOf(v).Int()) * time.Millisecond, nil\n\tcase uint, uint16, uint32, uint64:\n\t\t// treat like ms\n\t\treturn time.Duration(reflect.ValueOf(v).Uint()) * time.Millisecond, nil\n\tcase time.Duration:\n\t\treturn v, nil\n\t}\n\treturn 0, errors.New(\"invalid value type\")\n}\n\nfunc coerceAddr(v interface{}) (net.Addr, error) {\n\tswitch v := v.(type) {\n\tcase string:\n\t\treturn net.ResolveTCPAddr(\"tcp\", v)\n\tcase net.Addr:\n\t\treturn v, nil\n\t}\n\treturn nil, errors.New(\"invalid value type\")\n}\n\nfunc coerceBackoffStrategy(v interface{}) (BackoffStrategy, error) {\n\tswitch v := v.(type) {\n\tcase string:\n\t\tswitch v {\n\t\tcase \"\", \"exponential\":\n\t\t\treturn &ExponentialStrategy{}, nil\n\t\tcase \"full_jitter\":\n\t\t\treturn &FullJitterStrategy{}, nil\n\t\t}\n\tcase BackoffStrategy:\n\t\treturn v, nil\n\t}\n\treturn nil, errors.New(\"invalid value type\")\n}\n\nfunc coerceBool(v interface{}) (bool, error) {\n\tswitch v := v.(type) {\n\tcase bool:\n\t\treturn v, nil\n\tcase string:\n\t\treturn strconv.ParseBool(v)\n\tcase int, int16, int32, int64:\n\t\treturn reflect.ValueOf(v).Int() != 0, nil\n\tcase uint, uint16, uint32, uint64:\n\t\treturn reflect.ValueOf(v).Uint() != 0, nil\n\t}\n\treturn false, errors.New(\"invalid value type\")\n}\n\nfunc coerceFloat64(v interface{}) (float64, error) {\n\tswitch v := v.(type) {\n\tcase string:\n\t\treturn strconv.ParseFloat(v, 64)\n\tcase int, int16, int32, int64:\n\t\treturn float64(reflect.ValueOf(v).Int()), nil\n\tcase uint, uint16, uint32, uint64:\n\t\treturn float64(reflect.ValueOf(v).Uint()), nil\n\tcase float32:\n\t\treturn float64(v), nil\n\tcase float64:\n\t\treturn v, nil\n\t}\n\treturn 0, errors.New(\"invalid value type\")\n}\n\nfunc coerceInt64(v interface{}) (int64, error) {\n\tswitch v := v.(type) {\n\tcase string:\n\t\treturn strconv.ParseInt(v, 10, 64)\n\tcase int, int16, int32, int64:\n\t\treturn reflect.ValueOf(v).Int(), nil\n\tcase uint, uint16, uint32, uint64:\n\t\treturn int64(reflect.ValueOf(v).Uint()), nil\n\t}\n\treturn 0, errors.New(\"invalid value type\")\n}\n\nfunc coerceUint64(v interface{}) (uint64, error) {\n\tswitch v := v.(type) {\n\tcase string:\n\t\treturn strconv.ParseUint(v, 10, 64)\n\tcase int, int16, int32, int64:\n\t\treturn uint64(reflect.ValueOf(v).Int()), nil\n\tcase uint, uint16, uint32, uint64:\n\t\treturn reflect.ValueOf(v).Uint(), nil\n\t}\n\treturn 0, errors.New(\"invalid value type\")\n}\n"
        },
        {
          "name": "config_flag.go",
          "type": "blob",
          "size": 0.6796875,
          "content": "package nsq\n\nimport (\n\t\"strings\"\n)\n\n// ConfigFlag wraps a Config and implements the flag.Value interface\ntype ConfigFlag struct {\n\tConfig *Config\n}\n\n// Set takes a comma separated value and follows the rules in Config.Set\n// using the first field as the option key, and the second (if present) as the value\nfunc (c *ConfigFlag) Set(opt string) (err error) {\n\tparts := strings.SplitN(opt, \",\", 2)\n\tkey := parts[0]\n\n\tswitch len(parts) {\n\tcase 1:\n\t\t// default options specified without a value to boolean true\n\t\terr = c.Config.Set(key, true)\n\tcase 2:\n\t\terr = c.Config.Set(key, parts[1])\n\t}\n\treturn\n}\n\n// String implements the flag.Value interface\nfunc (c *ConfigFlag) String() string {\n\treturn \"\"\n}\n"
        },
        {
          "name": "config_flag_test.go",
          "type": "blob",
          "size": 0.5546875,
          "content": "package nsq_test\n\nimport (\n\t\"flag\"\n\n\t\"github.com/nsqio/go-nsq\"\n)\n\nfunc ExampleConfigFlag() {\n\tcfg := nsq.NewConfig()\n\tflagSet := flag.NewFlagSet(\"\", flag.ExitOnError)\n\n\tflagSet.Var(&nsq.ConfigFlag{cfg}, \"consumer-opt\", \"option to pass through to nsq.Consumer (may be given multiple times)\")\n\tflagSet.PrintDefaults()\n\n\terr := flagSet.Parse([]string{\n\t\t\"--consumer-opt=heartbeat_interval,1s\",\n\t\t\"--consumer-opt=max_attempts,10\",\n\t})\n\tif err != nil {\n\t\tpanic(err.Error())\n\t}\n\tprintln(\"HeartbeatInterval\", cfg.HeartbeatInterval)\n\tprintln(\"MaxAttempts\", cfg.MaxAttempts)\n}\n"
        },
        {
          "name": "config_test.go",
          "type": "blob",
          "size": 3.0546875,
          "content": "package nsq\n\nimport (\n\t\"math/rand\"\n\t\"net\"\n\t\"reflect\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestConfigSet(t *testing.T) {\n\tc := NewConfig()\n\tif err := c.Set(\"not a real config value\", struct{}{}); err == nil {\n\t\tt.Error(\"No error when setting an invalid value\")\n\t}\n\tif err := c.Set(\"tls_v1\", \"lol\"); err == nil {\n\t\tt.Error(\"No error when setting `tls_v1` to an invalid value\")\n\t}\n\tif err := c.Set(\"tls_v1\", true); err != nil {\n\t\tt.Errorf(\"Error setting `tls_v1` config. %s\", err)\n\t}\n\n\tif err := c.Set(\"tls-insecure-skip-verify\", true); err != nil {\n\t\tt.Errorf(\"Error setting `tls-insecure-skip-verify` config. %v\", err)\n\t}\n\tif c.TlsConfig.InsecureSkipVerify != true {\n\t\tt.Errorf(\"Error setting `tls-insecure-skip-verify` config: %v\", c.TlsConfig)\n\t}\n\tif err := c.Set(\"tls-min-version\", \"tls1.2\"); err != nil {\n\t\tt.Errorf(\"Error setting `tls-min-version` config: %s\", err)\n\t}\n\tif err := c.Set(\"tls-min-version\", \"tls1.3\"); err == nil {\n\t\tt.Error(\"No error when setting `tls-min-version` to an invalid value\")\n\t}\n\tif err := c.Set(\"local_addr\", &net.TCPAddr{}); err != nil {\n\t\tt.Errorf(\"Error setting `local_addr` config: %s\", err)\n\t}\n\tif err := c.Set(\"local_addr\", \"1.2.3.4:27015\"); err != nil {\n\t\tt.Errorf(\"Error setting `local_addr` config: %s\", err)\n\t}\n\tif err := c.Set(\"dial_timeout\", \"5s\"); err != nil {\n\t\tt.Errorf(\"Error setting `dial_timeout` config: %s\", err)\n\t}\n\tif c.LocalAddr.String() != \"1.2.3.4:27015\" {\n\t\tt.Error(\"Failed to assign `local_addr` config\")\n\t}\n\tif reflect.ValueOf(c.BackoffStrategy).Type().String() != \"*nsq.ExponentialStrategy\" {\n\t\tt.Error(\"Failed to set default `exponential` backoff strategy\")\n\t}\n\tif err := c.Set(\"backoff_strategy\", \"full_jitter\"); err != nil {\n\t\tt.Errorf(\"Failed to assign `backoff_strategy` config: %v\", err)\n\t}\n\tif reflect.ValueOf(c.BackoffStrategy).Type().String() != \"*nsq.FullJitterStrategy\" {\n\t\tt.Error(\"Failed to set `full_jitter` backoff strategy\")\n\t}\n}\n\nfunc TestConfigValidate(t *testing.T) {\n\tc := NewConfig()\n\tif err := c.Validate(); err != nil {\n\t\tt.Error(\"initialized config is invalid\")\n\t}\n\tc.DeflateLevel = 100\n\tif err := c.Validate(); err == nil {\n\t\tt.Error(\"no error set for invalid value\")\n\t}\n}\n\nfunc TestExponentialBackoff(t *testing.T) {\n\texpected := []time.Duration{\n\t\t1 * time.Second,\n\t\t2 * time.Second,\n\t\t8 * time.Second,\n\t\t32 * time.Second,\n\t}\n\tbackoffTest(t, expected, func(c *Config) BackoffStrategy {\n\t\treturn &ExponentialStrategy{cfg: c}\n\t})\n}\n\nfunc TestFullJitterBackoff(t *testing.T) {\n\texpected := []time.Duration{\n\t\t724039541 * time.Nanosecond,\n\t\t1603903257 * time.Nanosecond,\n\t\t5232470547 * time.Nanosecond,\n\t\t21467499218 * time.Nanosecond,\n\t}\n\tbackoffTest(t, expected, func(c *Config) BackoffStrategy {\n\t\treturn &FullJitterStrategy{cfg: c, rng: rand.New(rand.NewSource(99))}\n\t})\n}\n\nfunc backoffTest(t *testing.T, expected []time.Duration, cb func(c *Config) BackoffStrategy) {\n\tconfig := NewConfig()\n\tattempts := []int{0, 1, 3, 5}\n\ts := cb(config)\n\tfor i := range attempts {\n\t\tresult := s.Calculate(attempts[i])\n\t\tif result != expected[i] {\n\t\t\tt.Fatalf(\"wrong backoff duration %v for attempt %d (should be %v)\",\n\t\t\t\tresult, attempts[i], expected[i])\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "conn.go",
          "type": "blob",
          "size": 18.2939453125,
          "content": "package nsq\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/flate\"\n\t\"crypto/tls\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"strings\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"github.com/golang/snappy\"\n)\n\n// IdentifyResponse represents the metadata\n// returned from an IDENTIFY command to nsqd\ntype IdentifyResponse struct {\n\tMaxRdyCount  int64 `json:\"max_rdy_count\"`\n\tTLSv1        bool  `json:\"tls_v1\"`\n\tDeflate      bool  `json:\"deflate\"`\n\tSnappy       bool  `json:\"snappy\"`\n\tAuthRequired bool  `json:\"auth_required\"`\n}\n\n// AuthResponse represents the metadata\n// returned from an AUTH command to nsqd\ntype AuthResponse struct {\n\tIdentity        string `json:\"identity\"`\n\tIdentityUrl     string `json:\"identity_url\"`\n\tPermissionCount int64  `json:\"permission_count\"`\n}\n\ntype msgResponse struct {\n\tmsg     *Message\n\tcmd     *Command\n\tsuccess bool\n\tbackoff bool\n}\n\n// Conn represents a connection to nsqd\n//\n// Conn exposes a set of callbacks for the\n// various events that occur on a connection\ntype Conn struct {\n\t// 64bit atomic vars need to be first for proper alignment on 32bit platforms\n\tmessagesInFlight int64\n\tmaxRdyCount      int64\n\trdyCount         int64\n\tlastRdyTimestamp int64\n\tlastMsgTimestamp int64\n\n\tmtx sync.Mutex\n\n\tconfig *Config\n\n\tconn    *net.TCPConn\n\ttlsConn *tls.Conn\n\taddr    string\n\n\tdelegate ConnDelegate\n\n\tlogger   []logger\n\tlogLvl   LogLevel\n\tlogFmt   []string\n\tlogGuard sync.RWMutex\n\n\tr io.Reader\n\tw io.Writer\n\n\tcmdChan         chan *Command\n\tmsgResponseChan chan *msgResponse\n\texitChan        chan int\n\tdrainReady      chan int\n\n\tcloseFlag int32\n\tstopper   sync.Once\n\twg        sync.WaitGroup\n\n\treadLoopRunning int32\n}\n\n// NewConn returns a new Conn instance\nfunc NewConn(addr string, config *Config, delegate ConnDelegate) *Conn {\n\tif !config.initialized {\n\t\tpanic(\"Config must be created with NewConfig()\")\n\t}\n\treturn &Conn{\n\t\taddr: addr,\n\n\t\tconfig:   config,\n\t\tdelegate: delegate,\n\n\t\tmaxRdyCount:      2500,\n\t\tlastMsgTimestamp: time.Now().UnixNano(),\n\n\t\tcmdChan:         make(chan *Command),\n\t\tmsgResponseChan: make(chan *msgResponse),\n\t\texitChan:        make(chan int),\n\t\tdrainReady:      make(chan int),\n\n\t\tlogger: make([]logger, LogLevelMax+1),\n\t\tlogFmt: make([]string, LogLevelMax+1),\n\t}\n}\n\n// SetLogger assigns the logger to use as well as a level.\n//\n// The format parameter is expected to be a printf compatible string with\n// a single %s argument.  This is useful if you want to provide additional\n// context to the log messages that the connection will print, the default\n// is '(%s)'.\n//\n// The logger parameter is an interface that requires the following\n// method to be implemented (such as the the stdlib log.Logger):\n//\n//\tOutput(calldepth int, s string)\nfunc (c *Conn) SetLogger(l logger, lvl LogLevel, format string) {\n\tc.logGuard.Lock()\n\tdefer c.logGuard.Unlock()\n\n\tif format == \"\" {\n\t\tformat = \"(%s)\"\n\t}\n\tfor level := range c.logger {\n\t\tc.logger[level] = l\n\t\tc.logFmt[level] = format\n\t}\n\tc.logLvl = lvl\n}\n\nfunc (c *Conn) SetLoggerForLevel(l logger, lvl LogLevel, format string) {\n\tc.logGuard.Lock()\n\tdefer c.logGuard.Unlock()\n\n\tif format == \"\" {\n\t\tformat = \"(%s)\"\n\t}\n\tc.logger[lvl] = l\n\tc.logFmt[lvl] = format\n}\n\n// SetLoggerLevel sets the package logging level.\nfunc (c *Conn) SetLoggerLevel(lvl LogLevel) {\n\tc.logGuard.Lock()\n\tdefer c.logGuard.Unlock()\n\n\tc.logLvl = lvl\n}\n\nfunc (c *Conn) getLogger(lvl LogLevel) (logger, LogLevel, string) {\n\tc.logGuard.RLock()\n\tdefer c.logGuard.RUnlock()\n\n\treturn c.logger[lvl], c.logLvl, c.logFmt[lvl]\n}\n\nfunc (c *Conn) getLogLevel() LogLevel {\n\tc.logGuard.RLock()\n\tdefer c.logGuard.RUnlock()\n\n\treturn c.logLvl\n}\n\n// Connect dials and bootstraps the nsqd connection\n// (including IDENTIFY) and returns the IdentifyResponse\nfunc (c *Conn) Connect() (*IdentifyResponse, error) {\n\tdialer := &net.Dialer{\n\t\tLocalAddr: c.config.LocalAddr,\n\t\tTimeout:   c.config.DialTimeout,\n\t}\n\n\tconn, err := dialer.Dial(\"tcp\", c.addr)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tc.conn = conn.(*net.TCPConn)\n\tc.r = conn\n\tc.w = conn\n\n\t_, err = c.Write(MagicV2)\n\tif err != nil {\n\t\tc.Close()\n\t\treturn nil, fmt.Errorf(\"[%s] failed to write magic - %s\", c.addr, err)\n\t}\n\n\tresp, err := c.identify()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif resp != nil && resp.AuthRequired {\n\t\tif c.config.AuthSecret == \"\" {\n\t\t\tc.log(LogLevelError, \"Auth Required\")\n\t\t\treturn nil, errors.New(\"Auth Required\")\n\t\t}\n\t\terr := c.auth(c.config.AuthSecret)\n\t\tif err != nil {\n\t\t\tc.log(LogLevelError, \"Auth Failed %s\", err)\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tc.wg.Add(2)\n\tatomic.StoreInt32(&c.readLoopRunning, 1)\n\tgo c.readLoop()\n\tgo c.writeLoop()\n\treturn resp, nil\n}\n\n// Close idempotently initiates connection close\nfunc (c *Conn) Close() error {\n\tatomic.StoreInt32(&c.closeFlag, 1)\n\tif c.conn != nil && atomic.LoadInt64(&c.messagesInFlight) == 0 {\n\t\treturn c.conn.CloseRead()\n\t}\n\treturn nil\n}\n\n// IsClosing indicates whether or not the\n// connection is currently in the processing of\n// gracefully closing\nfunc (c *Conn) IsClosing() bool {\n\treturn atomic.LoadInt32(&c.closeFlag) == 1\n}\n\n// RDY returns the current RDY count\nfunc (c *Conn) RDY() int64 {\n\treturn atomic.LoadInt64(&c.rdyCount)\n}\n\n// LastRDY returns the previously set RDY count\nfunc (c *Conn) LastRDY() int64 {\n\treturn atomic.LoadInt64(&c.rdyCount)\n}\n\n// SetRDY stores the specified RDY count\nfunc (c *Conn) SetRDY(rdy int64) {\n\tatomic.StoreInt64(&c.rdyCount, rdy)\n\tif rdy > 0 {\n\t\tatomic.StoreInt64(&c.lastRdyTimestamp, time.Now().UnixNano())\n\t}\n}\n\n// MaxRDY returns the nsqd negotiated maximum\n// RDY count that it will accept for this connection\nfunc (c *Conn) MaxRDY() int64 {\n\treturn c.maxRdyCount\n}\n\n// LastRdyTime returns the time of the last non-zero RDY\n// update for this connection\nfunc (c *Conn) LastRdyTime() time.Time {\n\treturn time.Unix(0, atomic.LoadInt64(&c.lastRdyTimestamp))\n}\n\n// LastMessageTime returns a time.Time representing\n// the time at which the last message was received\nfunc (c *Conn) LastMessageTime() time.Time {\n\treturn time.Unix(0, atomic.LoadInt64(&c.lastMsgTimestamp))\n}\n\n// RemoteAddr returns the configured destination nsqd address\nfunc (c *Conn) RemoteAddr() net.Addr {\n\treturn c.conn.RemoteAddr()\n}\n\n// String returns the fully-qualified address\nfunc (c *Conn) String() string {\n\treturn c.addr\n}\n\n// Read performs a deadlined read on the underlying TCP connection\nfunc (c *Conn) Read(p []byte) (int, error) {\n\tc.conn.SetReadDeadline(time.Now().Add(c.config.ReadTimeout))\n\treturn c.r.Read(p)\n}\n\n// Write performs a deadlined write on the underlying TCP connection\nfunc (c *Conn) Write(p []byte) (int, error) {\n\tc.conn.SetWriteDeadline(time.Now().Add(c.config.WriteTimeout))\n\treturn c.w.Write(p)\n}\n\n// WriteCommand is a goroutine safe method to write a Command\n// to this connection, and flush.\nfunc (c *Conn) WriteCommand(cmd *Command) error {\n\tc.mtx.Lock()\n\n\t_, err := cmd.WriteTo(c)\n\tif err != nil {\n\t\tgoto exit\n\t}\n\terr = c.Flush()\n\nexit:\n\tc.mtx.Unlock()\n\tif err != nil {\n\t\tc.log(LogLevelError, \"IO error - %s\", err)\n\t\tc.delegate.OnIOError(c, err)\n\t}\n\treturn err\n}\n\ntype flusher interface {\n\tFlush() error\n}\n\n// Flush writes all buffered data to the underlying TCP connection\nfunc (c *Conn) Flush() error {\n\tif f, ok := c.w.(flusher); ok {\n\t\treturn f.Flush()\n\t}\n\treturn nil\n}\n\nfunc (c *Conn) identify() (*IdentifyResponse, error) {\n\tci := make(map[string]interface{})\n\tci[\"client_id\"] = c.config.ClientID\n\tci[\"hostname\"] = c.config.Hostname\n\tci[\"user_agent\"] = c.config.UserAgent\n\tci[\"short_id\"] = c.config.ClientID // deprecated\n\tci[\"long_id\"] = c.config.Hostname  // deprecated\n\tci[\"tls_v1\"] = c.config.TlsV1\n\tci[\"deflate\"] = c.config.Deflate\n\tci[\"deflate_level\"] = c.config.DeflateLevel\n\tci[\"snappy\"] = c.config.Snappy\n\tci[\"feature_negotiation\"] = true\n\tif c.config.HeartbeatInterval == -1 {\n\t\tci[\"heartbeat_interval\"] = -1\n\t} else {\n\t\tci[\"heartbeat_interval\"] = int64(c.config.HeartbeatInterval / time.Millisecond)\n\t}\n\tci[\"sample_rate\"] = c.config.SampleRate\n\tci[\"output_buffer_size\"] = c.config.OutputBufferSize\n\tif c.config.OutputBufferTimeout == -1 {\n\t\tci[\"output_buffer_timeout\"] = -1\n\t} else {\n\t\tci[\"output_buffer_timeout\"] = int64(c.config.OutputBufferTimeout / time.Millisecond)\n\t}\n\tci[\"msg_timeout\"] = int64(c.config.MsgTimeout / time.Millisecond)\n\tcmd, err := Identify(ci)\n\tif err != nil {\n\t\treturn nil, ErrIdentify{err.Error()}\n\t}\n\n\terr = c.WriteCommand(cmd)\n\tif err != nil {\n\t\treturn nil, ErrIdentify{err.Error()}\n\t}\n\n\tframeType, data, err := ReadUnpackedResponse(c, c.config.MaxMsgSize)\n\tif err != nil {\n\t\treturn nil, ErrIdentify{err.Error()}\n\t}\n\n\tif frameType == FrameTypeError {\n\t\treturn nil, ErrIdentify{string(data)}\n\t}\n\n\t// check to see if the server was able to respond w/ capabilities\n\t// i.e. it was a JSON response\n\tif data[0] != '{' {\n\t\treturn nil, nil\n\t}\n\n\tresp := &IdentifyResponse{}\n\terr = json.Unmarshal(data, resp)\n\tif err != nil {\n\t\treturn nil, ErrIdentify{err.Error()}\n\t}\n\n\tc.log(LogLevelDebug, \"IDENTIFY response: %+v\", resp)\n\n\tc.maxRdyCount = resp.MaxRdyCount\n\n\tif resp.TLSv1 {\n\t\tc.log(LogLevelInfo, \"upgrading to TLS\")\n\t\terr := c.upgradeTLS(c.config.TlsConfig)\n\t\tif err != nil {\n\t\t\treturn nil, ErrIdentify{err.Error()}\n\t\t}\n\t}\n\n\tif resp.Deflate {\n\t\tc.log(LogLevelInfo, \"upgrading to Deflate\")\n\t\terr := c.upgradeDeflate(c.config.DeflateLevel)\n\t\tif err != nil {\n\t\t\treturn nil, ErrIdentify{err.Error()}\n\t\t}\n\t}\n\n\tif resp.Snappy {\n\t\tc.log(LogLevelInfo, \"upgrading to Snappy\")\n\t\terr := c.upgradeSnappy()\n\t\tif err != nil {\n\t\t\treturn nil, ErrIdentify{err.Error()}\n\t\t}\n\t}\n\n\t// now that connection is bootstrapped, enable read buffering\n\t// (and write buffering if it's not already capable of Flush())\n\tc.r = bufio.NewReader(c.r)\n\tif _, ok := c.w.(flusher); !ok {\n\t\tc.w = bufio.NewWriter(c.w)\n\t}\n\n\treturn resp, nil\n}\n\nfunc (c *Conn) upgradeTLS(tlsConf *tls.Config) error {\n\thost, _, err := net.SplitHostPort(c.addr)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// create a local copy of the config to set ServerName for this connection\n\tconf := &tls.Config{}\n\tif tlsConf != nil {\n\t\tconf = tlsConf.Clone()\n\t}\n\tconf.ServerName = host\n\n\tc.tlsConn = tls.Client(c.conn, conf)\n\terr = c.tlsConn.Handshake()\n\tif err != nil {\n\t\treturn err\n\t}\n\tc.r = c.tlsConn\n\tc.w = c.tlsConn\n\tframeType, data, err := ReadUnpackedResponse(c, c.config.MaxMsgSize)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif frameType != FrameTypeResponse || !bytes.Equal(data, []byte(\"OK\")) {\n\t\treturn errors.New(\"invalid response from TLS upgrade\")\n\t}\n\treturn nil\n}\n\nfunc (c *Conn) upgradeDeflate(level int) error {\n\tconn := net.Conn(c.conn)\n\tif c.tlsConn != nil {\n\t\tconn = c.tlsConn\n\t}\n\tfw, _ := flate.NewWriter(conn, level)\n\tc.r = flate.NewReader(conn)\n\tc.w = fw\n\tframeType, data, err := ReadUnpackedResponse(c, c.config.MaxMsgSize)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif frameType != FrameTypeResponse || !bytes.Equal(data, []byte(\"OK\")) {\n\t\treturn errors.New(\"invalid response from Deflate upgrade\")\n\t}\n\treturn nil\n}\n\nfunc (c *Conn) upgradeSnappy() error {\n\tconn := net.Conn(c.conn)\n\tif c.tlsConn != nil {\n\t\tconn = c.tlsConn\n\t}\n\tc.r = snappy.NewReader(conn)\n\tc.w = snappy.NewBufferedWriter(conn)\n\tframeType, data, err := ReadUnpackedResponse(c, c.config.MaxMsgSize)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif frameType != FrameTypeResponse || !bytes.Equal(data, []byte(\"OK\")) {\n\t\treturn errors.New(\"invalid response from Snappy upgrade\")\n\t}\n\treturn nil\n}\n\nfunc (c *Conn) auth(secret string) error {\n\tcmd, err := Auth(secret)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\terr = c.WriteCommand(cmd)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tframeType, data, err := ReadUnpackedResponse(c, c.config.MaxMsgSize)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif frameType == FrameTypeError {\n\t\treturn errors.New(\"Error authenticating \" + string(data))\n\t}\n\n\tresp := &AuthResponse{}\n\terr = json.Unmarshal(data, resp)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tc.log(LogLevelInfo, \"Auth accepted. Identity: %q %s Permissions: %d\",\n\t\tresp.Identity, resp.IdentityUrl, resp.PermissionCount)\n\n\treturn nil\n}\n\nfunc (c *Conn) readLoop() {\n\tdelegate := &connMessageDelegate{c}\n\tfor {\n\t\tif atomic.LoadInt32(&c.closeFlag) == 1 {\n\t\t\tgoto exit\n\t\t}\n\n\t\tframeType, data, err := ReadUnpackedResponse(c, c.config.MaxMsgSize)\n\t\tif err != nil {\n\t\t\tif err == io.EOF && atomic.LoadInt32(&c.closeFlag) == 1 {\n\t\t\t\tgoto exit\n\t\t\t}\n\t\t\tif !strings.Contains(err.Error(), \"use of closed network connection\") {\n\t\t\t\tc.log(LogLevelError, \"IO error - %s\", err)\n\t\t\t\tc.delegate.OnIOError(c, err)\n\t\t\t}\n\t\t\tgoto exit\n\t\t}\n\n\t\tif frameType == FrameTypeResponse && bytes.Equal(data, []byte(\"_heartbeat_\")) {\n\t\t\tc.log(LogLevelDebug, \"heartbeat received\")\n\t\t\tc.delegate.OnHeartbeat(c)\n\t\t\terr := c.WriteCommand(Nop())\n\t\t\tif err != nil {\n\t\t\t\tc.log(LogLevelError, \"IO error - %s\", err)\n\t\t\t\tc.delegate.OnIOError(c, err)\n\t\t\t\tgoto exit\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\tswitch frameType {\n\t\tcase FrameTypeResponse:\n\t\t\tc.delegate.OnResponse(c, data)\n\t\tcase FrameTypeMessage:\n\t\t\tmsg, err := DecodeMessage(data)\n\t\t\tif err != nil {\n\t\t\t\tc.log(LogLevelError, \"IO error - %s\", err)\n\t\t\t\tc.delegate.OnIOError(c, err)\n\t\t\t\tgoto exit\n\t\t\t}\n\t\t\tmsg.Delegate = delegate\n\t\t\tmsg.NSQDAddress = c.String()\n\n\t\t\tatomic.AddInt64(&c.messagesInFlight, 1)\n\t\t\tatomic.StoreInt64(&c.lastMsgTimestamp, time.Now().UnixNano())\n\n\t\t\tc.delegate.OnMessage(c, msg)\n\t\tcase FrameTypeError:\n\t\t\tc.log(LogLevelError, \"protocol error - %s\", data)\n\t\t\tc.delegate.OnError(c, data)\n\t\tdefault:\n\t\t\tc.log(LogLevelError, \"IO error - %s\", err)\n\t\t\tc.delegate.OnIOError(c, fmt.Errorf(\"unknown frame type %d\", frameType))\n\t\t}\n\t}\n\nexit:\n\tatomic.StoreInt32(&c.readLoopRunning, 0)\n\t// start the connection close\n\tmessagesInFlight := atomic.LoadInt64(&c.messagesInFlight)\n\tif messagesInFlight == 0 {\n\t\t// if we exited readLoop with no messages in flight\n\t\t// we need to explicitly trigger the close because\n\t\t// writeLoop won't\n\t\tc.close()\n\t} else {\n\t\tc.log(LogLevelWarning, \"delaying close, %d outstanding messages\", messagesInFlight)\n\t}\n\tc.wg.Done()\n\tc.log(LogLevelInfo, \"readLoop exiting\")\n}\n\nfunc (c *Conn) writeLoop() {\n\tfor {\n\t\tselect {\n\t\tcase <-c.exitChan:\n\t\t\tc.log(LogLevelInfo, \"breaking out of writeLoop\")\n\t\t\t// Indicate drainReady because we will not pull any more off msgResponseChan\n\t\t\tclose(c.drainReady)\n\t\t\tgoto exit\n\t\tcase cmd := <-c.cmdChan:\n\t\t\terr := c.WriteCommand(cmd)\n\t\t\tif err != nil {\n\t\t\t\tc.log(LogLevelError, \"error sending command %s - %s\", cmd, err)\n\t\t\t\tc.close()\n\t\t\t\tcontinue\n\t\t\t}\n\t\tcase resp := <-c.msgResponseChan:\n\t\t\t// Decrement this here so it is correct even if we can't respond to nsqd\n\t\t\tmsgsInFlight := atomic.AddInt64(&c.messagesInFlight, -1)\n\n\t\t\tif resp.success {\n\t\t\t\tc.log(LogLevelDebug, \"FIN %s\", resp.msg.ID)\n\t\t\t\tc.delegate.OnMessageFinished(c, resp.msg)\n\t\t\t\tc.delegate.OnResume(c)\n\t\t\t} else {\n\t\t\t\tc.log(LogLevelDebug, \"REQ %s\", resp.msg.ID)\n\t\t\t\tc.delegate.OnMessageRequeued(c, resp.msg)\n\t\t\t\tif resp.backoff {\n\t\t\t\t\tc.delegate.OnBackoff(c)\n\t\t\t\t} else {\n\t\t\t\t\tc.delegate.OnContinue(c)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\terr := c.WriteCommand(resp.cmd)\n\t\t\tif err != nil {\n\t\t\t\tc.log(LogLevelError, \"error sending command %s - %s\", resp.cmd, err)\n\t\t\t\tc.close()\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif msgsInFlight == 0 &&\n\t\t\t\tatomic.LoadInt32(&c.closeFlag) == 1 {\n\t\t\t\tc.close()\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t}\n\nexit:\n\tc.wg.Done()\n\tc.log(LogLevelInfo, \"writeLoop exiting\")\n}\n\nfunc (c *Conn) close() {\n\t// a \"clean\" connection close is orchestrated as follows:\n\t//\n\t//     1. CLOSE cmd sent to nsqd\n\t//     2. CLOSE_WAIT response received from nsqd\n\t//     3. set c.closeFlag\n\t//     4. readLoop() exits\n\t//         a. if messages-in-flight > 0 delay close()\n\t//             i. writeLoop() continues receiving on c.msgResponseChan chan\n\t//                 x. when messages-in-flight == 0 call close()\n\t//         b. else call close() immediately\n\t//     5. c.exitChan close\n\t//         a. writeLoop() exits\n\t//             i. c.drainReady close\n\t//     6a. launch cleanup() goroutine (we're racing with intraprocess\n\t//        routed messages, see comments below)\n\t//         a. wait on c.drainReady\n\t//         b. loop and receive on c.msgResponseChan chan\n\t//            until messages-in-flight == 0\n\t//            i. ensure that readLoop has exited\n\t//     6b. launch waitForCleanup() goroutine\n\t//         b. wait on waitgroup (covers readLoop() and writeLoop()\n\t//            and cleanup goroutine)\n\t//         c. underlying TCP connection close\n\t//         d. trigger Delegate OnClose()\n\t//\n\tc.stopper.Do(func() {\n\t\tc.log(LogLevelInfo, \"beginning close\")\n\t\tclose(c.exitChan)\n\t\tc.conn.CloseRead()\n\n\t\tc.wg.Add(1)\n\t\tgo c.cleanup()\n\n\t\tgo c.waitForCleanup()\n\t})\n}\n\nfunc (c *Conn) cleanup() {\n\t<-c.drainReady\n\tticker := time.NewTicker(100 * time.Millisecond)\n\tlastWarning := time.Now()\n\t// writeLoop has exited, drain any remaining in flight messages\n\tfor {\n\t\t// we're racing with readLoop which potentially has a message\n\t\t// for handling so infinitely loop until messagesInFlight == 0\n\t\t// and readLoop has exited\n\t\tvar msgsInFlight int64\n\t\tselect {\n\t\tcase <-c.msgResponseChan:\n\t\t\tmsgsInFlight = atomic.AddInt64(&c.messagesInFlight, -1)\n\t\tcase <-ticker.C:\n\t\t\tmsgsInFlight = atomic.LoadInt64(&c.messagesInFlight)\n\t\t}\n\t\tif msgsInFlight > 0 {\n\t\t\tif time.Since(lastWarning) > time.Second {\n\t\t\t\tc.log(LogLevelWarning, \"draining... waiting for %d messages in flight\", msgsInFlight)\n\t\t\t\tlastWarning = time.Now()\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\t// until the readLoop has exited we cannot be sure that there\n\t\t// still won't be a race\n\t\tif atomic.LoadInt32(&c.readLoopRunning) == 1 {\n\t\t\tif time.Since(lastWarning) > time.Second {\n\t\t\t\tc.log(LogLevelWarning, \"draining... readLoop still running\")\n\t\t\t\tlastWarning = time.Now()\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\tgoto exit\n\t}\n\nexit:\n\tticker.Stop()\n\tc.wg.Done()\n\tc.log(LogLevelInfo, \"finished draining, cleanup exiting\")\n}\n\nfunc (c *Conn) waitForCleanup() {\n\t// this blocks until readLoop and writeLoop\n\t// (and cleanup goroutine above) have exited\n\tc.wg.Wait()\n\tc.conn.CloseWrite()\n\tc.log(LogLevelInfo, \"clean close complete\")\n\tc.delegate.OnClose(c)\n}\n\nfunc (c *Conn) onMessageFinish(m *Message) {\n\tc.msgResponseChan <- &msgResponse{msg: m, cmd: Finish(m.ID), success: true}\n}\n\nfunc (c *Conn) onMessageRequeue(m *Message, delay time.Duration, backoff bool) {\n\tif delay == -1 {\n\t\t// linear delay\n\t\tdelay = c.config.DefaultRequeueDelay * time.Duration(m.Attempts)\n\t\t// bound the requeueDelay to configured max\n\t\tif delay > c.config.MaxRequeueDelay {\n\t\t\tdelay = c.config.MaxRequeueDelay\n\t\t}\n\t}\n\tc.msgResponseChan <- &msgResponse{msg: m, cmd: Requeue(m.ID, delay), success: false, backoff: backoff}\n}\n\nfunc (c *Conn) onMessageTouch(m *Message) {\n\tselect {\n\tcase c.cmdChan <- Touch(m.ID):\n\tcase <-c.exitChan:\n\t}\n}\n\nfunc (c *Conn) log(lvl LogLevel, line string, args ...interface{}) {\n\tlogger, logLvl, logFmt := c.getLogger(lvl)\n\n\tif logger == nil {\n\t\treturn\n\t}\n\n\tif logLvl > lvl {\n\t\treturn\n\t}\n\n\tlogger.Output(2, fmt.Sprintf(\"%-4s %s %s\", lvl,\n\t\tfmt.Sprintf(logFmt, c.String()),\n\t\tfmt.Sprintf(line, args...)))\n}\n"
        },
        {
          "name": "consumer.go",
          "type": "blob",
          "size": 31.0947265625,
          "content": "package nsq\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"log\"\n\t\"math\"\n\t\"math/rand\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n)\n\n// Handler is the message processing interface for Consumer\n//\n// Implement this interface for handlers that return whether or not message\n// processing completed successfully.\n//\n// When the return value is nil Consumer will automatically handle FINishing.\n//\n// When the returned value is non-nil Consumer will automatically handle REQueing.\ntype Handler interface {\n\tHandleMessage(message *Message) error\n}\n\n// HandlerFunc is a convenience type to avoid having to declare a struct\n// to implement the Handler interface, it can be used like this:\n//\n//\tconsumer.AddHandler(nsq.HandlerFunc(func(m *Message) error {\n//\t\t// handle the message\n//\t}))\ntype HandlerFunc func(message *Message) error\n\n// HandleMessage implements the Handler interface\nfunc (h HandlerFunc) HandleMessage(m *Message) error {\n\treturn h(m)\n}\n\n// DiscoveryFilter is an interface accepted by `SetBehaviorDelegate()`\n// for filtering the nsqds returned from discovery via nsqlookupd\ntype DiscoveryFilter interface {\n\tFilter([]string) []string\n}\n\n// FailedMessageLogger is an interface that can be implemented by handlers that wish\n// to receive a callback when a message is deemed \"failed\" (i.e. the number of attempts\n// exceeded the Consumer specified MaxAttemptCount)\ntype FailedMessageLogger interface {\n\tLogFailedMessage(message *Message)\n}\n\n// ConsumerStats represents a snapshot of the state of a Consumer's connections and the messages\n// it has seen\ntype ConsumerStats struct {\n\tMessagesReceived uint64\n\tMessagesFinished uint64\n\tMessagesRequeued uint64\n\tConnections      int\n}\n\nvar instCount int64\n\ntype backoffSignal int\n\nconst (\n\tbackoffFlag backoffSignal = iota\n\tcontinueFlag\n\tresumeFlag\n)\n\n// Consumer is a high-level type to consume from NSQ.\n//\n// A Consumer instance is supplied a Handler that will be executed\n// concurrently via goroutines to handle processing the stream of messages\n// consumed from the specified topic/channel. See: Handler/HandlerFunc\n// for details on implementing the interface to create handlers.\n//\n// If configured, it will poll nsqlookupd instances and handle connection (and\n// reconnection) to any discovered nsqds.\ntype Consumer struct {\n\t// 64bit atomic vars need to be first for proper alignment on 32bit platforms\n\tmessagesReceived uint64\n\tmessagesFinished uint64\n\tmessagesRequeued uint64\n\ttotalRdyCount    int64\n\tbackoffDuration  int64\n\tbackoffCounter   int32\n\tmaxInFlight      int32\n\n\tmtx sync.RWMutex\n\n\tlogger   []logger\n\tlogLvl   LogLevel\n\tlogGuard sync.RWMutex\n\n\tbehaviorDelegate interface{}\n\n\tid      int64\n\ttopic   string\n\tchannel string\n\tconfig  Config\n\n\trngMtx sync.Mutex\n\trng    *rand.Rand\n\n\tneedRDYRedistributed int32\n\n\tbackoffMtx sync.Mutex\n\n\tincomingMessages chan *Message\n\n\trdyRetryMtx    sync.Mutex\n\trdyRetryTimers map[string]*time.Timer\n\n\tpendingConnections map[string]*Conn\n\tconnections        map[string]*Conn\n\n\tnsqdTCPAddrs []string\n\n\t// used at connection close to force a possible reconnect\n\tlookupdRecheckChan chan int\n\tlookupdHTTPAddrs   []string\n\tlookupdQueryIndex  int\n\tlookupdHttpClient  *http.Client\n\n\twg              sync.WaitGroup\n\trunningHandlers int32\n\tstopFlag        int32\n\tconnectedFlag   int32\n\tstopHandler     sync.Once\n\texitHandler     sync.Once\n\n\t// read from this channel to block until consumer is cleanly stopped\n\tStopChan chan int\n\texitChan chan int\n}\n\n// NewConsumer creates a new instance of Consumer for the specified topic/channel\n//\n// The only valid way to create a Config is via NewConfig, using a struct literal will panic.\n// After Config is passed into NewConsumer the values are no longer mutable (they are copied).\nfunc NewConsumer(topic string, channel string, config *Config) (*Consumer, error) {\n\tif err := config.Validate(); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif !IsValidTopicName(topic) {\n\t\treturn nil, errors.New(\"invalid topic name\")\n\t}\n\n\tif !IsValidChannelName(channel) {\n\t\treturn nil, errors.New(\"invalid channel name\")\n\t}\n\n\tr := &Consumer{\n\t\tid: atomic.AddInt64(&instCount, 1),\n\n\t\ttopic:   topic,\n\t\tchannel: channel,\n\t\tconfig:  *config,\n\n\t\tlogger:      make([]logger, LogLevelMax+1),\n\t\tlogLvl:      LogLevelInfo,\n\t\tmaxInFlight: int32(config.MaxInFlight),\n\n\t\tincomingMessages: make(chan *Message),\n\n\t\trdyRetryTimers:     make(map[string]*time.Timer),\n\t\tpendingConnections: make(map[string]*Conn),\n\t\tconnections:        make(map[string]*Conn),\n\n\t\tlookupdRecheckChan: make(chan int, 1),\n\n\t\trng: rand.New(rand.NewSource(time.Now().UnixNano())),\n\n\t\tStopChan: make(chan int),\n\t\texitChan: make(chan int),\n\t}\n\n\t// Set default logger for all log levels\n\tl := log.New(os.Stderr, \"\", log.Flags())\n\tfor index := range r.logger {\n\t\tr.logger[index] = l\n\t}\n\n\tr.wg.Add(1)\n\tgo r.rdyLoop()\n\treturn r, nil\n}\n\n// Stats retrieves the current connection and message statistics for a Consumer\nfunc (r *Consumer) Stats() *ConsumerStats {\n\treturn &ConsumerStats{\n\t\tMessagesReceived: atomic.LoadUint64(&r.messagesReceived),\n\t\tMessagesFinished: atomic.LoadUint64(&r.messagesFinished),\n\t\tMessagesRequeued: atomic.LoadUint64(&r.messagesRequeued),\n\t\tConnections:      len(r.conns()),\n\t}\n}\n\nfunc (r *Consumer) conns() []*Conn {\n\tr.mtx.RLock()\n\tconns := make([]*Conn, 0, len(r.connections))\n\tfor _, c := range r.connections {\n\t\tconns = append(conns, c)\n\t}\n\tr.mtx.RUnlock()\n\treturn conns\n}\n\n// SetLogger assigns the logger to use as well as a level\n//\n// The logger parameter is an interface that requires the following\n// method to be implemented (such as the the stdlib log.Logger):\n//\n//\tOutput(calldepth int, s string) error\nfunc (r *Consumer) SetLogger(l logger, lvl LogLevel) {\n\tr.logGuard.Lock()\n\tdefer r.logGuard.Unlock()\n\n\tfor level := range r.logger {\n\t\tr.logger[level] = l\n\t}\n\tr.logLvl = lvl\n}\n\n// SetLoggerForLevel assigns the same logger for specified `level`.\nfunc (r *Consumer) SetLoggerForLevel(l logger, lvl LogLevel) {\n\tr.logGuard.Lock()\n\tdefer r.logGuard.Unlock()\n\n\tr.logger[lvl] = l\n}\n\n// SetLoggerLevel sets the package logging level.\nfunc (r *Consumer) SetLoggerLevel(lvl LogLevel) {\n\tr.logGuard.Lock()\n\tdefer r.logGuard.Unlock()\n\n\tr.logLvl = lvl\n}\n\nfunc (r *Consumer) getLogger(lvl LogLevel) (logger, LogLevel) {\n\tr.logGuard.RLock()\n\tdefer r.logGuard.RUnlock()\n\n\treturn r.logger[lvl], r.logLvl\n}\n\nfunc (r *Consumer) getLogLevel() LogLevel {\n\tr.logGuard.RLock()\n\tdefer r.logGuard.RUnlock()\n\n\treturn r.logLvl\n}\n\n// SetBehaviorDelegate takes a type implementing one or more\n// of the following interfaces that modify the behavior\n// of the `Consumer`:\n//\n//\tDiscoveryFilter\nfunc (r *Consumer) SetBehaviorDelegate(cb interface{}) {\n\tmatched := false\n\n\tif _, ok := cb.(DiscoveryFilter); ok {\n\t\tmatched = true\n\t}\n\n\tif !matched {\n\t\tpanic(\"behavior delegate does not have any recognized methods\")\n\t}\n\n\tr.behaviorDelegate = cb\n}\n\n// perConnMaxInFlight calculates the per-connection max-in-flight count.\n//\n// This may change dynamically based on the number of connections to nsqd the Consumer\n// is responsible for.\nfunc (r *Consumer) perConnMaxInFlight() int64 {\n\tb := float64(r.getMaxInFlight())\n\ts := b / float64(len(r.conns()))\n\treturn int64(math.Min(math.Max(1, s), b))\n}\n\n// IsStarved indicates whether any connections for this consumer are blocked on processing\n// before being able to receive more messages (ie. RDY count of 0 and not exiting)\nfunc (r *Consumer) IsStarved() bool {\n\tfor _, conn := range r.conns() {\n\t\tthreshold := int64(float64(conn.RDY()) * 0.85)\n\t\tinFlight := atomic.LoadInt64(&conn.messagesInFlight)\n\t\tif inFlight >= threshold && inFlight > 0 && !conn.IsClosing() {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (r *Consumer) getMaxInFlight() int32 {\n\treturn atomic.LoadInt32(&r.maxInFlight)\n}\n\n// ChangeMaxInFlight sets a new maximum number of messages this comsumer instance\n// will allow in-flight, and updates all existing connections as appropriate.\n//\n// # For example, ChangeMaxInFlight(0) would pause message flow\n//\n// If already connected, it updates the reader RDY state for each connection.\nfunc (r *Consumer) ChangeMaxInFlight(maxInFlight int) {\n\tif r.getMaxInFlight() == int32(maxInFlight) {\n\t\treturn\n\t}\n\n\tatomic.StoreInt32(&r.maxInFlight, int32(maxInFlight))\n\n\tfor _, c := range r.conns() {\n\t\tr.maybeUpdateRDY(c)\n\t}\n}\n\n// set lookupd http client\nfunc (r *Consumer) SetLookupdHttpClient(httpclient *http.Client) {\n\tr.lookupdHttpClient = httpclient\n}\n\n// ConnectToNSQLookupd adds an nsqlookupd address to the list for this Consumer instance.\n//\n// If it is the first to be added, it initiates an HTTP request to discover nsqd\n// producers for the configured topic.\n//\n// A goroutine is spawned to handle continual polling.\nfunc (r *Consumer) ConnectToNSQLookupd(addr string) error {\n\tif atomic.LoadInt32(&r.stopFlag) == 1 {\n\t\treturn errors.New(\"consumer stopped\")\n\t}\n\tif atomic.LoadInt32(&r.runningHandlers) == 0 {\n\t\treturn errors.New(\"no handlers\")\n\t}\n\n\tparsedAddr, err := buildLookupAddr(addr, r.topic)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tatomic.StoreInt32(&r.connectedFlag, 1)\n\n\tr.mtx.Lock()\n\tfor _, x := range r.lookupdHTTPAddrs {\n\t\tif x == parsedAddr {\n\t\t\tr.mtx.Unlock()\n\t\t\treturn nil\n\t\t}\n\t}\n\tr.lookupdHTTPAddrs = append(r.lookupdHTTPAddrs, parsedAddr)\n\tif r.lookupdHttpClient == nil {\n\t\ttransport := &http.Transport{\n\t\t\tDialContext: (&net.Dialer{\n\t\t\t\tTimeout:   r.config.LookupdPollTimeout,\n\t\t\t\tKeepAlive: 30 * time.Second,\n\t\t\t}).DialContext,\n\t\t\tResponseHeaderTimeout: r.config.LookupdPollTimeout,\n\t\t\tMaxIdleConns:          100,\n\t\t\tIdleConnTimeout:       90 * time.Second,\n\t\t\tTLSHandshakeTimeout:   10 * time.Second,\n\t\t}\n\t\tr.lookupdHttpClient = &http.Client{\n\t\t\tTransport: transport,\n\t\t\tTimeout:   r.config.LookupdPollTimeout,\n\t\t}\n\t}\n\n\tnumLookupd := len(r.lookupdHTTPAddrs)\n\tr.mtx.Unlock()\n\n\t// if this is the first one, kick off the go loop\n\tif numLookupd == 1 {\n\t\tr.queryLookupd()\n\t\tr.wg.Add(1)\n\t\tgo r.lookupdLoop()\n\t}\n\n\treturn nil\n}\n\n// ConnectToNSQLookupds adds multiple nsqlookupd address to the list for this Consumer instance.\n//\n// If adding the first address it initiates an HTTP request to discover nsqd\n// producers for the configured topic.\n//\n// A goroutine is spawned to handle continual polling.\nfunc (r *Consumer) ConnectToNSQLookupds(addresses []string) error {\n\tfor _, addr := range addresses {\n\t\terr := r.ConnectToNSQLookupd(addr)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// poll all known lookup servers every LookupdPollInterval\nfunc (r *Consumer) lookupdLoop() {\n\t// add some jitter so that multiple consumers discovering the same topic,\n\t// when restarted at the same time, dont all connect at once.\n\tr.rngMtx.Lock()\n\tjitter := time.Duration(int64(r.rng.Float64() *\n\t\tr.config.LookupdPollJitter * float64(r.config.LookupdPollInterval)))\n\tr.rngMtx.Unlock()\n\tvar ticker *time.Ticker\n\n\tselect {\n\tcase <-time.After(jitter):\n\tcase <-r.exitChan:\n\t\tgoto exit\n\t}\n\n\tticker = time.NewTicker(r.config.LookupdPollInterval)\n\n\tfor {\n\t\tselect {\n\t\tcase <-ticker.C:\n\t\t\tr.queryLookupd()\n\t\tcase <-r.lookupdRecheckChan:\n\t\t\tr.queryLookupd()\n\t\tcase <-r.exitChan:\n\t\t\tgoto exit\n\t\t}\n\t}\n\nexit:\n\tif ticker != nil {\n\t\tticker.Stop()\n\t}\n\tr.log(LogLevelInfo, \"exiting lookupdLoop\")\n\tr.wg.Done()\n}\n\n// return the next lookupd endpoint to query\n// keeping track of which one was last used\nfunc (r *Consumer) nextLookupdEndpoint() string {\n\tr.mtx.RLock()\n\tif r.lookupdQueryIndex >= len(r.lookupdHTTPAddrs) {\n\t\tr.lookupdQueryIndex = 0\n\t}\n\taddr := r.lookupdHTTPAddrs[r.lookupdQueryIndex]\n\tnum := len(r.lookupdHTTPAddrs)\n\tr.mtx.RUnlock()\n\tr.lookupdQueryIndex = (r.lookupdQueryIndex + 1) % num\n\n\treturn addr\n}\n\ntype lookupResp struct {\n\tChannels  []string    `json:\"channels\"`\n\tProducers []*peerInfo `json:\"producers\"`\n\tTimestamp int64       `json:\"timestamp\"`\n}\n\ntype peerInfo struct {\n\tRemoteAddress    string `json:\"remote_address\"`\n\tHostname         string `json:\"hostname\"`\n\tBroadcastAddress string `json:\"broadcast_address\"`\n\tTCPPort          int    `json:\"tcp_port\"`\n\tHTTPPort         int    `json:\"http_port\"`\n\tVersion          string `json:\"version\"`\n}\n\n// make an HTTP req to one of the configured nsqlookupd instances to discover\n// which nsqd's provide the topic we are consuming.\n//\n// initiate a connection to any new producers that are identified.\nfunc (r *Consumer) queryLookupd() {\n\tretries := 0\n\nretry:\n\tendpoint := r.nextLookupdEndpoint()\n\n\tr.log(LogLevelInfo, \"querying nsqlookupd %s\", endpoint)\n\n\tvar data lookupResp\n\theaders := make(http.Header)\n\tif r.config.AuthSecret != \"\" && r.config.LookupdAuthorization {\n\t\theaders.Set(\"Authorization\", fmt.Sprintf(\"Bearer %s\", r.config.AuthSecret))\n\t}\n\terr := apiRequestNegotiateV1(r.lookupdHttpClient, \"GET\", endpoint, headers, &data)\n\tif err != nil {\n\t\tr.log(LogLevelError, \"error querying nsqlookupd (%s) - %s\", endpoint, err)\n\t\tretries++\n\t\tif retries < 3 {\n\t\t\tr.log(LogLevelInfo, \"retrying with next nsqlookupd\")\n\t\t\tgoto retry\n\t\t}\n\t\treturn\n\t}\n\n\tvar nsqdAddrs []string\n\tfor _, producer := range data.Producers {\n\t\tbroadcastAddress := producer.BroadcastAddress\n\t\tport := producer.TCPPort\n\t\tjoined := net.JoinHostPort(broadcastAddress, strconv.Itoa(port))\n\t\tnsqdAddrs = append(nsqdAddrs, joined)\n\t}\n\t// apply filter\n\tif discoveryFilter, ok := r.behaviorDelegate.(DiscoveryFilter); ok {\n\t\tnsqdAddrs = discoveryFilter.Filter(nsqdAddrs)\n\t}\n\tfor _, addr := range nsqdAddrs {\n\t\terr = r.ConnectToNSQD(addr)\n\t\tif err != nil && err != ErrAlreadyConnected {\n\t\t\tr.log(LogLevelError, \"(%s) error connecting to nsqd - %s\", addr, err)\n\t\t\tcontinue\n\t\t}\n\t}\n}\n\n// ConnectToNSQDs takes multiple nsqd addresses to connect directly to.\n//\n// It is recommended to use ConnectToNSQLookupd so that topics are discovered\n// automatically.  This method is useful when you want to connect to local instance.\nfunc (r *Consumer) ConnectToNSQDs(addresses []string) error {\n\tfor _, addr := range addresses {\n\t\terr := r.ConnectToNSQD(addr)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// ConnectToNSQD takes a nsqd address to connect directly to.\n//\n// It is recommended to use ConnectToNSQLookupd so that topics are discovered\n// automatically.  This method is useful when you want to connect to a single, local,\n// instance.\nfunc (r *Consumer) ConnectToNSQD(addr string) error {\n\tif atomic.LoadInt32(&r.stopFlag) == 1 {\n\t\treturn errors.New(\"consumer stopped\")\n\t}\n\n\tif atomic.LoadInt32(&r.runningHandlers) == 0 {\n\t\treturn errors.New(\"no handlers\")\n\t}\n\n\tatomic.StoreInt32(&r.connectedFlag, 1)\n\n\tconn := NewConn(addr, &r.config, &consumerConnDelegate{r})\n\tconn.SetLoggerLevel(r.getLogLevel())\n\tformat := fmt.Sprintf(\"%3d [%s/%s] (%%s)\", r.id, r.topic, r.channel)\n\tfor index := range r.logger {\n\t\tconn.SetLoggerForLevel(r.logger[index], LogLevel(index), format)\n\t}\n\tr.mtx.Lock()\n\t_, pendingOk := r.pendingConnections[addr]\n\t_, ok := r.connections[addr]\n\tif ok || pendingOk {\n\t\tr.mtx.Unlock()\n\t\treturn ErrAlreadyConnected\n\t}\n\tr.pendingConnections[addr] = conn\n\tif idx := indexOf(addr, r.nsqdTCPAddrs); idx == -1 {\n\t\tr.nsqdTCPAddrs = append(r.nsqdTCPAddrs, addr)\n\t}\n\tr.mtx.Unlock()\n\n\tr.log(LogLevelInfo, \"(%s) connecting to nsqd\", addr)\n\n\tcleanupConnection := func() {\n\t\tr.mtx.Lock()\n\t\tdelete(r.pendingConnections, addr)\n\t\tr.mtx.Unlock()\n\t\tconn.Close()\n\t}\n\n\tresp, err := conn.Connect()\n\tif err != nil {\n\t\tcleanupConnection()\n\t\treturn err\n\t}\n\n\tif resp != nil {\n\t\tif resp.MaxRdyCount < int64(r.getMaxInFlight()) {\n\t\t\tr.log(LogLevelWarning,\n\t\t\t\t\"(%s) max RDY count %d < consumer max in flight %d, truncation possible\",\n\t\t\t\tconn.String(), resp.MaxRdyCount, r.getMaxInFlight())\n\t\t}\n\t}\n\n\tcmd := Subscribe(r.topic, r.channel)\n\terr = conn.WriteCommand(cmd)\n\tif err != nil {\n\t\tcleanupConnection()\n\t\treturn fmt.Errorf(\"[%s] failed to subscribe to %s:%s - %s\",\n\t\t\tconn, r.topic, r.channel, err.Error())\n\t}\n\n\tr.mtx.Lock()\n\tdelete(r.pendingConnections, addr)\n\tr.connections[addr] = conn\n\tr.mtx.Unlock()\n\n\t// pre-emptive signal to existing connections to lower their RDY count\n\tfor _, c := range r.conns() {\n\t\tif c != conn {\n\t\t\tr.maybeUpdateRDY(c)\n\t\t}\n\t}\n\tr.maybeUpdateRDY(conn)\n\n\treturn nil\n}\n\nfunc indexOf(n string, h []string) int {\n\tfor i, a := range h {\n\t\tif n == a {\n\t\t\treturn i\n\t\t}\n\t}\n\treturn -1\n}\n\n// DisconnectFromNSQD closes the connection to and removes the specified\n// `nsqd` address from the list\nfunc (r *Consumer) DisconnectFromNSQD(addr string) error {\n\tr.mtx.Lock()\n\tdefer r.mtx.Unlock()\n\n\tidx := indexOf(addr, r.nsqdTCPAddrs)\n\tif idx == -1 {\n\t\treturn ErrNotConnected\n\t}\n\n\t// slice delete\n\tr.nsqdTCPAddrs = append(r.nsqdTCPAddrs[:idx], r.nsqdTCPAddrs[idx+1:]...)\n\n\tpendingConn, pendingOk := r.pendingConnections[addr]\n\tconn, ok := r.connections[addr]\n\n\tif ok {\n\t\tconn.Close()\n\t} else if pendingOk {\n\t\tpendingConn.Close()\n\t}\n\n\treturn nil\n}\n\n// DisconnectFromNSQLookupd removes the specified `nsqlookupd` address\n// from the list used for periodic discovery.\nfunc (r *Consumer) DisconnectFromNSQLookupd(addr string) error {\n\tparsedAddr, err := buildLookupAddr(addr, r.topic)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tr.mtx.Lock()\n\tdefer r.mtx.Unlock()\n\n\tidx := indexOf(parsedAddr, r.lookupdHTTPAddrs)\n\tif idx == -1 {\n\t\treturn ErrNotConnected\n\t}\n\n\tif len(r.lookupdHTTPAddrs) == 1 {\n\t\treturn fmt.Errorf(\"cannot disconnect from only remaining nsqlookupd HTTP address %s\", addr)\n\t}\n\n\tr.lookupdHTTPAddrs = append(r.lookupdHTTPAddrs[:idx], r.lookupdHTTPAddrs[idx+1:]...)\n\n\treturn nil\n}\n\nfunc (r *Consumer) onConnMessage(c *Conn, msg *Message) {\n\tatomic.AddUint64(&r.messagesReceived, 1)\n\tr.incomingMessages <- msg\n}\n\nfunc (r *Consumer) onConnMessageFinished(c *Conn, msg *Message) {\n\tatomic.AddUint64(&r.messagesFinished, 1)\n}\n\nfunc (r *Consumer) onConnMessageRequeued(c *Conn, msg *Message) {\n\tatomic.AddUint64(&r.messagesRequeued, 1)\n}\n\nfunc (r *Consumer) onConnBackoff(c *Conn) {\n\tr.startStopContinueBackoff(c, backoffFlag)\n}\n\nfunc (r *Consumer) onConnContinue(c *Conn) {\n\tr.startStopContinueBackoff(c, continueFlag)\n}\n\nfunc (r *Consumer) onConnResume(c *Conn) {\n\tr.startStopContinueBackoff(c, resumeFlag)\n}\n\nfunc (r *Consumer) onConnResponse(c *Conn, data []byte) {\n\tswitch {\n\tcase bytes.Equal(data, []byte(\"CLOSE_WAIT\")):\n\t\t// server is ready for us to close (it ack'd our StartClose)\n\t\t// we can assume we will not receive any more messages over this channel\n\t\t// (but we can still write back responses)\n\t\tr.log(LogLevelInfo, \"(%s) received CLOSE_WAIT from nsqd\", c.String())\n\t\tc.Close()\n\t}\n}\n\nfunc (r *Consumer) onConnError(c *Conn, data []byte) {}\n\nfunc (r *Consumer) onConnHeartbeat(c *Conn) {}\n\nfunc (r *Consumer) onConnIOError(c *Conn, err error) {\n\tc.Close()\n}\n\nfunc (r *Consumer) onConnClose(c *Conn) {\n\tvar hasRDYRetryTimer bool\n\n\t// remove this connections RDY count from the consumer's total\n\trdyCount := c.RDY()\n\tatomic.AddInt64(&r.totalRdyCount, -rdyCount)\n\n\tr.rdyRetryMtx.Lock()\n\tif timer, ok := r.rdyRetryTimers[c.String()]; ok {\n\t\t// stop any pending retry of an old RDY update\n\t\ttimer.Stop()\n\t\tdelete(r.rdyRetryTimers, c.String())\n\t\thasRDYRetryTimer = true\n\t}\n\tr.rdyRetryMtx.Unlock()\n\n\tr.mtx.Lock()\n\tdelete(r.connections, c.String())\n\tleft := len(r.connections)\n\tr.mtx.Unlock()\n\n\tr.log(LogLevelWarning, \"there are %d connections left alive\", left)\n\n\tif (hasRDYRetryTimer || rdyCount > 0) &&\n\t\t(int32(left) == r.getMaxInFlight() || r.inBackoff()) {\n\t\t// we're toggling out of (normal) redistribution cases and this conn\n\t\t// had a RDY count...\n\t\t//\n\t\t// trigger RDY redistribution to make sure this RDY is moved\n\t\t// to a new connection\n\t\tatomic.StoreInt32(&r.needRDYRedistributed, 1)\n\t}\n\n\t// we were the last one (and stopping)\n\tif atomic.LoadInt32(&r.stopFlag) == 1 {\n\t\tif left == 0 {\n\t\t\tr.stopHandlers()\n\t\t}\n\t\treturn\n\t}\n\n\tr.mtx.RLock()\n\tnumLookupd := len(r.lookupdHTTPAddrs)\n\treconnect := indexOf(c.String(), r.nsqdTCPAddrs) >= 0\n\tr.mtx.RUnlock()\n\tif numLookupd > 0 {\n\t\t// trigger a poll of the lookupd\n\t\tselect {\n\t\tcase r.lookupdRecheckChan <- 1:\n\t\tdefault:\n\t\t}\n\t} else if reconnect {\n\t\t// there are no lookupd and we still have this nsqd TCP address in our list...\n\t\t// try to reconnect after a bit\n\t\tgo func(addr string) {\n\t\t\tfor {\n\t\t\t\tr.log(LogLevelInfo, \"(%s) re-connecting in %s\", addr, r.config.LookupdPollInterval)\n\t\t\t\ttime.Sleep(r.config.LookupdPollInterval)\n\t\t\t\tif atomic.LoadInt32(&r.stopFlag) == 1 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\tr.mtx.RLock()\n\t\t\t\treconnect := indexOf(addr, r.nsqdTCPAddrs) >= 0\n\t\t\t\tr.mtx.RUnlock()\n\t\t\t\tif !reconnect {\n\t\t\t\t\tr.log(LogLevelWarning, \"(%s) skipped reconnect after removal...\", addr)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\terr := r.ConnectToNSQD(addr)\n\t\t\t\tif err != nil && err != ErrAlreadyConnected {\n\t\t\t\t\tr.log(LogLevelError, \"(%s) error connecting to nsqd - %s\", addr, err)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t}(c.String())\n\t}\n}\n\nfunc (r *Consumer) startStopContinueBackoff(conn *Conn, signal backoffSignal) {\n\t// prevent many async failures/successes from immediately resulting in\n\t// max backoff/normal rate (by ensuring that we dont continually incr/decr\n\t// the counter during a backoff period)\n\tr.backoffMtx.Lock()\n\tdefer r.backoffMtx.Unlock()\n\tif r.inBackoffTimeout() {\n\t\treturn\n\t}\n\n\t// update backoff state\n\tbackoffUpdated := false\n\tbackoffCounter := atomic.LoadInt32(&r.backoffCounter)\n\tswitch signal {\n\tcase resumeFlag:\n\t\tif backoffCounter > 0 {\n\t\t\tbackoffCounter--\n\t\t\tbackoffUpdated = true\n\t\t}\n\tcase backoffFlag:\n\t\tnextBackoff := r.config.BackoffStrategy.Calculate(int(backoffCounter) + 1)\n\t\tif nextBackoff <= r.config.MaxBackoffDuration {\n\t\t\tbackoffCounter++\n\t\t\tbackoffUpdated = true\n\t\t}\n\t}\n\tatomic.StoreInt32(&r.backoffCounter, backoffCounter)\n\n\tif r.backoffCounter == 0 && backoffUpdated {\n\t\t// exit backoff\n\t\tcount := r.perConnMaxInFlight()\n\t\tr.log(LogLevelWarning, \"exiting backoff, returning all to RDY %d\", count)\n\t\tfor _, c := range r.conns() {\n\t\t\tr.updateRDY(c, count)\n\t\t}\n\t} else if r.backoffCounter > 0 {\n\t\t// start or continue backoff\n\t\tbackoffDuration := r.config.BackoffStrategy.Calculate(int(backoffCounter))\n\n\t\tif backoffDuration > r.config.MaxBackoffDuration {\n\t\t\tbackoffDuration = r.config.MaxBackoffDuration\n\t\t}\n\n\t\tr.log(LogLevelWarning, \"backing off for %s (backoff level %d), setting all to RDY 0\",\n\t\t\tbackoffDuration, backoffCounter)\n\n\t\t// send RDY 0 immediately (to *all* connections)\n\t\tfor _, c := range r.conns() {\n\t\t\tr.updateRDY(c, 0)\n\t\t}\n\n\t\tr.backoff(backoffDuration)\n\t}\n}\n\nfunc (r *Consumer) backoff(d time.Duration) {\n\tatomic.StoreInt64(&r.backoffDuration, d.Nanoseconds())\n\ttime.AfterFunc(d, r.resume)\n}\n\nfunc (r *Consumer) resume() {\n\tif atomic.LoadInt32(&r.stopFlag) == 1 {\n\t\tatomic.StoreInt64(&r.backoffDuration, 0)\n\t\treturn\n\t}\n\n\t// pick a random connection to test the waters\n\tconns := r.conns()\n\tif len(conns) == 0 {\n\t\tr.log(LogLevelWarning, \"no connection available to resume\")\n\t\tr.log(LogLevelWarning, \"backing off for %s\", time.Second)\n\t\tr.backoff(time.Second)\n\t\treturn\n\t}\n\tr.rngMtx.Lock()\n\tidx := r.rng.Intn(len(conns))\n\tr.rngMtx.Unlock()\n\tchoice := conns[idx]\n\n\tr.log(LogLevelWarning,\n\t\t\"(%s) backoff timeout expired, sending RDY 1\",\n\t\tchoice.String())\n\n\t// while in backoff only ever let 1 message at a time through\n\terr := r.updateRDY(choice, 1)\n\tif err != nil {\n\t\tr.log(LogLevelWarning, \"(%s) error resuming RDY 1 - %s\", choice.String(), err)\n\t\tr.log(LogLevelWarning, \"backing off for %s\", time.Second)\n\t\tr.backoff(time.Second)\n\t\treturn\n\t}\n\n\tatomic.StoreInt64(&r.backoffDuration, 0)\n}\n\nfunc (r *Consumer) inBackoff() bool {\n\treturn atomic.LoadInt32(&r.backoffCounter) > 0\n}\n\nfunc (r *Consumer) inBackoffTimeout() bool {\n\treturn atomic.LoadInt64(&r.backoffDuration) > 0\n}\n\nfunc (r *Consumer) maybeUpdateRDY(conn *Conn) {\n\tinBackoff := r.inBackoff()\n\tinBackoffTimeout := r.inBackoffTimeout()\n\tif inBackoff || inBackoffTimeout {\n\t\tr.log(LogLevelDebug, \"(%s) skip sending RDY inBackoff:%v || inBackoffTimeout:%v\",\n\t\t\tconn, inBackoff, inBackoffTimeout)\n\t\treturn\n\t}\n\n\tcount := r.perConnMaxInFlight()\n\tr.log(LogLevelDebug, \"(%s) sending RDY %d\", conn, count)\n\tif err := r.updateRDY(conn, count); err != nil {\n\t\tr.log(LogLevelWarning, \"(%s) error sending RDY %d: %v\", conn, count, err)\n\t}\n}\n\nfunc (r *Consumer) rdyLoop() {\n\tredistributeTicker := time.NewTicker(r.config.RDYRedistributeInterval)\n\n\tfor {\n\t\tselect {\n\t\tcase <-redistributeTicker.C:\n\t\t\tr.redistributeRDY()\n\t\tcase <-r.exitChan:\n\t\t\tgoto exit\n\t\t}\n\t}\n\nexit:\n\tredistributeTicker.Stop()\n\tr.log(LogLevelInfo, \"rdyLoop exiting\")\n\tr.wg.Done()\n}\n\nfunc (r *Consumer) updateRDY(c *Conn, count int64) error {\n\tif c.IsClosing() {\n\t\treturn ErrClosing\n\t}\n\n\t// never exceed the nsqd's configured max RDY count\n\tif count > c.MaxRDY() {\n\t\tcount = c.MaxRDY()\n\t}\n\n\t// stop any pending retry of an old RDY update\n\tr.rdyRetryMtx.Lock()\n\tif timer, ok := r.rdyRetryTimers[c.String()]; ok {\n\t\ttimer.Stop()\n\t\tdelete(r.rdyRetryTimers, c.String())\n\t}\n\tr.rdyRetryMtx.Unlock()\n\n\t// never exceed our global max in flight. truncate if possible.\n\t// this could help a new connection get partial max-in-flight\n\trdyCount := c.RDY()\n\tmaxPossibleRdy := int64(r.getMaxInFlight()) - atomic.LoadInt64(&r.totalRdyCount) + rdyCount\n\tif maxPossibleRdy > 0 && maxPossibleRdy < count {\n\t\tcount = maxPossibleRdy\n\t}\n\tif maxPossibleRdy <= 0 && count > 0 {\n\t\tif rdyCount == 0 {\n\t\t\t// we wanted to exit a zero RDY count but we couldn't send it...\n\t\t\t// in order to prevent eternal starvation we reschedule this attempt\n\t\t\t// (if any other RDY update succeeds this timer will be stopped)\n\t\t\tr.rdyRetryMtx.Lock()\n\t\t\tr.rdyRetryTimers[c.String()] = time.AfterFunc(5*time.Second,\n\t\t\t\tfunc() {\n\t\t\t\t\tr.updateRDY(c, count)\n\t\t\t\t})\n\t\t\tr.rdyRetryMtx.Unlock()\n\t\t}\n\t\treturn ErrOverMaxInFlight\n\t}\n\n\treturn r.sendRDY(c, count)\n}\n\nfunc (r *Consumer) sendRDY(c *Conn, count int64) error {\n\tif count == 0 && c.LastRDY() == 0 {\n\t\t// no need to send. It's already that RDY count\n\t\treturn nil\n\t}\n\n\tatomic.AddInt64(&r.totalRdyCount, count-c.RDY())\n\n\tlastRDY := c.LastRDY()\n\tc.SetRDY(count)\n\tif count == lastRDY {\n\t\treturn nil\n\t}\n\n\terr := c.WriteCommand(Ready(int(count)))\n\tif err != nil {\n\t\tr.log(LogLevelError, \"(%s) error sending RDY %d - %s\", c.String(), count, err)\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc (r *Consumer) redistributeRDY() {\n\tif r.inBackoffTimeout() {\n\t\treturn\n\t}\n\n\t// if an external heuristic set needRDYRedistributed we want to wait\n\t// until we can actually redistribute to proceed\n\tconns := r.conns()\n\tif len(conns) == 0 {\n\t\treturn\n\t}\n\n\tmaxInFlight := r.getMaxInFlight()\n\tif len(conns) > int(maxInFlight) {\n\t\tr.log(LogLevelDebug, \"redistributing RDY state (%d conns > %d max_in_flight)\",\n\t\t\tlen(conns), maxInFlight)\n\t\tatomic.StoreInt32(&r.needRDYRedistributed, 1)\n\t}\n\n\tif r.inBackoff() && len(conns) > 1 {\n\t\tr.log(LogLevelDebug, \"redistributing RDY state (in backoff and %d conns > 1)\", len(conns))\n\t\tatomic.StoreInt32(&r.needRDYRedistributed, 1)\n\t}\n\n\tif !atomic.CompareAndSwapInt32(&r.needRDYRedistributed, 1, 0) {\n\t\treturn\n\t}\n\n\tpossibleConns := make([]*Conn, 0, len(conns))\n\tfor _, c := range conns {\n\t\tlastMsgDuration := time.Since(c.LastMessageTime())\n\t\tlastRdyDuration := time.Since(c.LastRdyTime())\n\t\trdyCount := c.RDY()\n\t\tr.log(LogLevelDebug, \"(%s) rdy: %d (last message received %s)\",\n\t\t\tc.String(), rdyCount, lastMsgDuration)\n\t\tif rdyCount > 0 {\n\t\t\tif lastMsgDuration > r.config.LowRdyIdleTimeout {\n\t\t\t\tr.log(LogLevelDebug, \"(%s) idle connection, giving up RDY\", c.String())\n\t\t\t\tr.updateRDY(c, 0)\n\t\t\t} else if lastRdyDuration > r.config.LowRdyTimeout {\n\t\t\t\tr.log(LogLevelDebug, \"(%s) RDY timeout, giving up RDY\", c.String())\n\t\t\t\tr.updateRDY(c, 0)\n\t\t\t}\n\t\t}\n\t\tpossibleConns = append(possibleConns, c)\n\t}\n\n\tavailableMaxInFlight := int64(maxInFlight) - atomic.LoadInt64(&r.totalRdyCount)\n\tif r.inBackoff() {\n\t\tavailableMaxInFlight = 1 - atomic.LoadInt64(&r.totalRdyCount)\n\t}\n\n\tfor len(possibleConns) > 0 && availableMaxInFlight > 0 {\n\t\tavailableMaxInFlight--\n\t\tr.rngMtx.Lock()\n\t\ti := r.rng.Int() % len(possibleConns)\n\t\tr.rngMtx.Unlock()\n\t\tc := possibleConns[i]\n\t\t// delete\n\t\tpossibleConns = append(possibleConns[:i], possibleConns[i+1:]...)\n\t\tr.log(LogLevelDebug, \"(%s) redistributing RDY\", c.String())\n\t\tr.updateRDY(c, 1)\n\t}\n}\n\n// Stop will initiate a graceful stop of the Consumer (permanent)\n//\n// NOTE: receive on StopChan to block until this process completes\nfunc (r *Consumer) Stop() {\n\tif !atomic.CompareAndSwapInt32(&r.stopFlag, 0, 1) {\n\t\treturn\n\t}\n\n\tr.log(LogLevelInfo, \"stopping...\")\n\n\tif len(r.conns()) == 0 {\n\t\tr.stopHandlers()\n\t} else {\n\t\tfor _, c := range r.conns() {\n\t\t\terr := c.WriteCommand(StartClose())\n\t\t\tif err != nil {\n\t\t\t\tr.log(LogLevelError, \"(%s) error sending CLS - %s\", c.String(), err)\n\t\t\t}\n\t\t}\n\n\t\ttime.AfterFunc(time.Second*30, func() {\n\t\t\t// if we've waited this long handlers are blocked on processing messages\n\t\t\t// so we can't just stopHandlers (if any adtl. messages were pending processing\n\t\t\t// we would cause a panic on channel close)\n\t\t\t//\n\t\t\t// instead, we just bypass handler closing and skip to the final exit\n\t\t\tr.exit()\n\t\t})\n\t}\n}\n\nfunc (r *Consumer) stopHandlers() {\n\tr.stopHandler.Do(func() {\n\t\tr.log(LogLevelInfo, \"stopping handlers\")\n\t\tclose(r.incomingMessages)\n\t})\n}\n\n// AddHandler sets the Handler for messages received by this Consumer. This can be called\n// multiple times to add additional handlers. Handler will have a 1:1 ratio to message handling goroutines.\n//\n// # This panics if called after connecting to NSQD or NSQ Lookupd\n//\n// (see Handler or HandlerFunc for details on implementing this interface)\nfunc (r *Consumer) AddHandler(handler Handler) {\n\tr.AddConcurrentHandlers(handler, 1)\n}\n\n// AddConcurrentHandlers sets the Handler for messages received by this Consumer.  It\n// takes a second argument which indicates the number of goroutines to spawn for\n// message handling.\n//\n// # This panics if called after connecting to NSQD or NSQ Lookupd\n//\n// (see Handler or HandlerFunc for details on implementing this interface)\nfunc (r *Consumer) AddConcurrentHandlers(handler Handler, concurrency int) {\n\tif atomic.LoadInt32(&r.connectedFlag) == 1 {\n\t\tpanic(\"already connected\")\n\t}\n\n\tatomic.AddInt32(&r.runningHandlers, int32(concurrency))\n\tfor i := 0; i < concurrency; i++ {\n\t\tgo r.handlerLoop(handler)\n\t}\n}\n\nfunc (r *Consumer) handlerLoop(handler Handler) {\n\tr.log(LogLevelDebug, \"starting Handler\")\n\n\tfor {\n\t\tmessage, ok := <-r.incomingMessages\n\t\tif !ok {\n\t\t\tgoto exit\n\t\t}\n\n\t\tif r.shouldFailMessage(message, handler) {\n\t\t\tmessage.Finish()\n\t\t\tcontinue\n\t\t}\n\n\t\terr := handler.HandleMessage(message)\n\t\tif err != nil {\n\t\t\tr.log(LogLevelError, \"Handler returned error (%s) for msg %s\", err, message.ID)\n\t\t\tif !message.IsAutoResponseDisabled() {\n\t\t\t\tmessage.Requeue(-1)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\tif !message.IsAutoResponseDisabled() {\n\t\t\tmessage.Finish()\n\t\t}\n\t}\n\nexit:\n\tr.log(LogLevelDebug, \"stopping Handler\")\n\tif atomic.AddInt32(&r.runningHandlers, -1) == 0 {\n\t\tr.exit()\n\t}\n}\n\nfunc (r *Consumer) shouldFailMessage(message *Message, handler interface{}) bool {\n\t// message passed the max number of attempts\n\tif r.config.MaxAttempts > 0 && message.Attempts > r.config.MaxAttempts {\n\t\tr.log(LogLevelWarning, \"msg %s attempted %d times, giving up\",\n\t\t\tmessage.ID, message.Attempts)\n\n\t\tlogger, ok := handler.(FailedMessageLogger)\n\t\tif ok {\n\t\t\tlogger.LogFailedMessage(message)\n\t\t}\n\n\t\treturn true\n\t}\n\treturn false\n}\n\nfunc (r *Consumer) exit() {\n\tr.exitHandler.Do(func() {\n\t\tclose(r.exitChan)\n\t\tr.wg.Wait()\n\t\tclose(r.StopChan)\n\t})\n}\n\nfunc (r *Consumer) log(lvl LogLevel, line string, args ...interface{}) {\n\tlogger, logLvl := r.getLogger(lvl)\n\n\tif logger == nil {\n\t\treturn\n\t}\n\n\tif logLvl > lvl {\n\t\treturn\n\t}\n\n\tlogger.Output(2, fmt.Sprintf(\"%-4s %3d [%s/%s] %s\",\n\t\tlvl, r.id, r.topic, r.channel,\n\t\tfmt.Sprintf(line, args...)))\n}\n\nfunc buildLookupAddr(addr, topic string) (string, error) {\n\turlString := addr\n\tif !strings.Contains(urlString, \"://\") {\n\t\turlString = \"http://\" + addr\n\t}\n\n\tu, err := url.Parse(urlString)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tif u.Port() == \"\" {\n\t\treturn \"\", errors.New(\"missing port\")\n\t}\n\n\tif u.Path == \"/\" || u.Path == \"\" {\n\t\tu.Path = \"/lookup\"\n\t}\n\n\tv, _ := url.ParseQuery(u.RawQuery)\n\tv.Add(\"topic\", topic)\n\tu.RawQuery = v.Encode()\n\treturn u.String(), nil\n}\n"
        },
        {
          "name": "consumer_test.go",
          "type": "blob",
          "size": 6.0263671875,
          "content": "package nsq\n\nimport (\n\t\"bytes\"\n\t\"crypto/tls\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"strconv\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n)\n\ntype MyTestHandler struct {\n\tt                *testing.T\n\tq                *Consumer\n\tmessagesSent     int\n\tmessagesReceived int\n\tmessagesFailed   int\n}\n\nvar nullLogger = log.New(io.Discard, \"\", log.LstdFlags)\n\nfunc (h *MyTestHandler) LogFailedMessage(message *Message) {\n\th.messagesFailed++\n\th.q.Stop()\n}\n\nfunc (h *MyTestHandler) HandleMessage(message *Message) error {\n\tif string(message.Body) == \"TOBEFAILED\" {\n\t\th.messagesReceived++\n\t\treturn errors.New(\"fail this message\")\n\t}\n\n\tdata := struct {\n\t\tMsg string\n\t}{}\n\n\terr := json.Unmarshal(message.Body, &data)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tmsg := data.Msg\n\tif msg != \"single\" && msg != \"double\" {\n\t\th.t.Error(\"message 'action' was not correct: \", msg, data)\n\t}\n\th.messagesReceived++\n\treturn nil\n}\n\nfunc SendMessage(t *testing.T, port int, topic string, method string, body []byte) {\n\thttpclient := &http.Client{}\n\tendpoint := fmt.Sprintf(\"http://127.0.0.1:%d/%s?topic=%s\", port, method, topic)\n\treq, _ := http.NewRequest(\"POST\", endpoint, bytes.NewBuffer(body))\n\tresp, err := httpclient.Do(req)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t\treturn\n\t}\n\tif resp.StatusCode != 200 {\n\t\tt.Fatalf(\"%s status code: %d\", method, resp.StatusCode)\n\t}\n\tresp.Body.Close()\n}\n\nfunc TestConsumer(t *testing.T) {\n\tconsumerTest(t, nil)\n}\n\nfunc TestConsumerTLS(t *testing.T) {\n\tconsumerTest(t, func(c *Config) {\n\t\tc.TlsV1 = true\n\t\tc.TlsConfig = &tls.Config{\n\t\t\tInsecureSkipVerify: true,\n\t\t}\n\t})\n}\n\nfunc TestConsumerDeflate(t *testing.T) {\n\tconsumerTest(t, func(c *Config) {\n\t\tc.Deflate = true\n\t})\n}\n\nfunc TestConsumerSnappy(t *testing.T) {\n\tconsumerTest(t, func(c *Config) {\n\t\tc.Snappy = true\n\t})\n}\n\nfunc TestConsumerTLSDeflate(t *testing.T) {\n\tconsumerTest(t, func(c *Config) {\n\t\tc.TlsV1 = true\n\t\tc.TlsConfig = &tls.Config{\n\t\t\tInsecureSkipVerify: true,\n\t\t}\n\t\tc.Deflate = true\n\t})\n}\n\nfunc TestConsumerTLSSnappy(t *testing.T) {\n\tconsumerTest(t, func(c *Config) {\n\t\tc.TlsV1 = true\n\t\tc.TlsConfig = &tls.Config{\n\t\t\tInsecureSkipVerify: true,\n\t\t}\n\t\tc.Snappy = true\n\t})\n}\n\nfunc TestConsumerTLSClientCert(t *testing.T) {\n\tcert, _ := tls.LoadX509KeyPair(\"./test/client.pem\", \"./test/client.key\")\n\tconsumerTest(t, func(c *Config) {\n\t\tc.TlsV1 = true\n\t\tc.TlsConfig = &tls.Config{\n\t\t\tCertificates:       []tls.Certificate{cert},\n\t\t\tInsecureSkipVerify: true,\n\t\t}\n\t})\n}\n\nfunc TestConsumerLookupdAuthorization(t *testing.T) {\n\t// confirm that LookupAuthorization = true sets Authorization header on lookudp call\n\tconfig := NewConfig()\n\tconfig.AuthSecret = \"AuthSecret\"\n\ttopicName := \"auth\" + strconv.Itoa(int(time.Now().Unix()))\n\tq, _ := NewConsumer(topicName, \"ch\", config)\n\tq.SetLogger(newTestLogger(t), LogLevelDebug)\n\n\tvar req bool\n\tlookupd := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treq = true\n\t\tif h := r.Header.Get(\"Authorization\"); h != \"Bearer AuthSecret\" {\n\t\t\tt.Errorf(\"got Auth header %q\", h)\n\t\t}\n\t\tw.WriteHeader(404)\n\t}))\n\tdefer lookupd.Close()\n\n\th := &MyTestHandler{\n\t\tt: t,\n\t\tq: q,\n\t}\n\tq.AddHandler(h)\n\n\tq.ConnectToNSQLookupd(lookupd.URL)\n\tif req == false {\n\t\tt.Errorf(\"lookupd call not completed\")\n\t}\n}\n\nfunc TestConsumerTLSClientCertViaSet(t *testing.T) {\n\tconsumerTest(t, func(c *Config) {\n\t\tc.Set(\"tls_v1\", true)\n\t\tc.Set(\"tls_cert\", \"./test/client.pem\")\n\t\tc.Set(\"tls_key\", \"./test/client.key\")\n\t\tc.Set(\"tls_insecure_skip_verify\", true)\n\t})\n}\n\nfunc consumerTest(t *testing.T, cb func(c *Config)) {\n\tconfig := NewConfig()\n\tladdr := \"127.0.0.1\"\n\t// so that the test can simulate binding consumer to specified address\n\tconfig.LocalAddr, _ = net.ResolveTCPAddr(\"tcp\", laddr+\":0\")\n\t// so that the test can simulate reaching max requeues and a call to LogFailedMessage\n\tconfig.DefaultRequeueDelay = 0\n\t// so that the test wont timeout from backing off\n\tconfig.MaxBackoffDuration = time.Millisecond * 50\n\tif cb != nil {\n\t\tcb(config)\n\t}\n\ttopicName := \"rdr_test\"\n\tif config.Deflate {\n\t\ttopicName = topicName + \"_deflate\"\n\t} else if config.Snappy {\n\t\ttopicName = topicName + \"_snappy\"\n\t}\n\tif config.TlsV1 {\n\t\ttopicName = topicName + \"_tls\"\n\t}\n\ttopicName = topicName + strconv.Itoa(int(time.Now().Unix()))\n\tq, _ := NewConsumer(topicName, \"ch\", config)\n\tq.SetLogger(newTestLogger(t), LogLevelDebug)\n\n\th := &MyTestHandler{\n\t\tt: t,\n\t\tq: q,\n\t}\n\tq.AddHandler(h)\n\n\tSendMessage(t, 4151, topicName, \"pub\", []byte(`{\"msg\":\"single\"}`))\n\tSendMessage(t, 4151, topicName, \"mpub\", []byte(\"{\\\"msg\\\":\\\"double\\\"}\\n{\\\"msg\\\":\\\"double\\\"}\"))\n\tSendMessage(t, 4151, topicName, \"pub\", []byte(\"TOBEFAILED\"))\n\th.messagesSent = 4\n\n\taddr := \"127.0.0.1:4150\"\n\terr := q.ConnectToNSQD(addr)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tstats := q.Stats()\n\tif stats.Connections == 0 {\n\t\tt.Fatal(\"stats report 0 connections (should be > 0)\")\n\t}\n\n\terr = q.ConnectToNSQD(addr)\n\tif err == nil {\n\t\tt.Fatal(\"should not be able to connect to the same NSQ twice\")\n\t}\n\n\tconn := q.conns()[0]\n\tif !strings.HasPrefix(conn.conn.LocalAddr().String(), laddr) {\n\t\tt.Fatal(\"connection should be bound to the specified address:\", conn.conn.LocalAddr())\n\t}\n\n\terr = q.DisconnectFromNSQD(\"1.2.3.4:4150\")\n\tif err == nil {\n\t\tt.Fatal(\"should not be able to disconnect from an unknown nsqd\")\n\t}\n\n\terr = q.ConnectToNSQD(\"1.2.3.4:4150\")\n\tif err == nil {\n\t\tt.Fatal(\"should not be able to connect to non-existent nsqd\")\n\t}\n\n\terr = q.DisconnectFromNSQD(\"1.2.3.4:4150\")\n\tif err != nil {\n\t\tt.Fatal(\"should be able to disconnect from an nsqd - \" + err.Error())\n\t}\n\n\t<-q.StopChan\n\n\tstats = q.Stats()\n\tif stats.Connections != 0 {\n\t\tt.Fatalf(\"stats report %d active connections (should be 0)\", stats.Connections)\n\t}\n\n\tstats = q.Stats()\n\tif stats.MessagesReceived != uint64(h.messagesReceived+h.messagesFailed) {\n\t\tt.Fatalf(\"stats report %d messages received (should be %d)\",\n\t\t\tstats.MessagesReceived,\n\t\t\th.messagesReceived+h.messagesFailed)\n\t}\n\n\tif h.messagesReceived != 8 || h.messagesSent != 4 {\n\t\tt.Fatalf(\"end of test. should have handled a diff number of messages (got %d, sent %d)\", h.messagesReceived, h.messagesSent)\n\t}\n\tif h.messagesFailed != 1 {\n\t\tt.Fatal(\"failed message not done\")\n\t}\n}\n"
        },
        {
          "name": "delegates.go",
          "type": "blob",
          "size": 4.9140625,
          "content": "package nsq\n\nimport \"time\"\n\ntype logger interface {\n\tOutput(calldepth int, s string) error\n}\n\n// LogLevel specifies the severity of a given log message\ntype LogLevel int\n\n// Log levels\nconst (\n\tLogLevelDebug LogLevel = iota\n\tLogLevelInfo\n\tLogLevelWarning\n\tLogLevelError\n\tLogLevelMax = iota - 1 // convenience - match highest log level\n)\n\n// String returns the string form for a given LogLevel\nfunc (lvl LogLevel) String() string {\n\tswitch lvl {\n\tcase LogLevelInfo:\n\t\treturn \"INF\"\n\tcase LogLevelWarning:\n\t\treturn \"WRN\"\n\tcase LogLevelError:\n\t\treturn \"ERR\"\n\t}\n\treturn \"DBG\"\n}\n\n// MessageDelegate is an interface of methods that are used as\n// callbacks in Message\ntype MessageDelegate interface {\n\t// OnFinish is called when the Finish() method\n\t// is triggered on the Message\n\tOnFinish(*Message)\n\n\t// OnRequeue is called when the Requeue() method\n\t// is triggered on the Message\n\tOnRequeue(m *Message, delay time.Duration, backoff bool)\n\n\t// OnTouch is called when the Touch() method\n\t// is triggered on the Message\n\tOnTouch(*Message)\n}\n\ntype connMessageDelegate struct {\n\tc *Conn\n}\n\nfunc (d *connMessageDelegate) OnFinish(m *Message) { d.c.onMessageFinish(m) }\nfunc (d *connMessageDelegate) OnRequeue(m *Message, t time.Duration, b bool) {\n\td.c.onMessageRequeue(m, t, b)\n}\nfunc (d *connMessageDelegate) OnTouch(m *Message) { d.c.onMessageTouch(m) }\n\n// ConnDelegate is an interface of methods that are used as\n// callbacks in Conn\ntype ConnDelegate interface {\n\t// OnResponse is called when the connection\n\t// receives a FrameTypeResponse from nsqd\n\tOnResponse(*Conn, []byte)\n\n\t// OnError is called when the connection\n\t// receives a FrameTypeError from nsqd\n\tOnError(*Conn, []byte)\n\n\t// OnMessage is called when the connection\n\t// receives a FrameTypeMessage from nsqd\n\tOnMessage(*Conn, *Message)\n\n\t// OnMessageFinished is called when the connection\n\t// handles a FIN command from a message handler\n\tOnMessageFinished(*Conn, *Message)\n\n\t// OnMessageRequeued is called when the connection\n\t// handles a REQ command from a message handler\n\tOnMessageRequeued(*Conn, *Message)\n\n\t// OnBackoff is called when the connection triggers a backoff state\n\tOnBackoff(*Conn)\n\n\t// OnContinue is called when the connection finishes a message without adjusting backoff state\n\tOnContinue(*Conn)\n\n\t// OnResume is called when the connection triggers a resume state\n\tOnResume(*Conn)\n\n\t// OnIOError is called when the connection experiences\n\t// a low-level TCP transport error\n\tOnIOError(*Conn, error)\n\n\t// OnHeartbeat is called when the connection\n\t// receives a heartbeat from nsqd\n\tOnHeartbeat(*Conn)\n\n\t// OnClose is called when the connection\n\t// closes, after all cleanup\n\tOnClose(*Conn)\n}\n\n// keeps the exported Consumer struct clean of the exported methods\n// required to implement the ConnDelegate interface\ntype consumerConnDelegate struct {\n\tr *Consumer\n}\n\nfunc (d *consumerConnDelegate) OnResponse(c *Conn, data []byte)       { d.r.onConnResponse(c, data) }\nfunc (d *consumerConnDelegate) OnError(c *Conn, data []byte)          { d.r.onConnError(c, data) }\nfunc (d *consumerConnDelegate) OnMessage(c *Conn, m *Message)         { d.r.onConnMessage(c, m) }\nfunc (d *consumerConnDelegate) OnMessageFinished(c *Conn, m *Message) { d.r.onConnMessageFinished(c, m) }\nfunc (d *consumerConnDelegate) OnMessageRequeued(c *Conn, m *Message) { d.r.onConnMessageRequeued(c, m) }\nfunc (d *consumerConnDelegate) OnBackoff(c *Conn)                     { d.r.onConnBackoff(c) }\nfunc (d *consumerConnDelegate) OnContinue(c *Conn)                    { d.r.onConnContinue(c) }\nfunc (d *consumerConnDelegate) OnResume(c *Conn)                      { d.r.onConnResume(c) }\nfunc (d *consumerConnDelegate) OnIOError(c *Conn, err error)          { d.r.onConnIOError(c, err) }\nfunc (d *consumerConnDelegate) OnHeartbeat(c *Conn)                   { d.r.onConnHeartbeat(c) }\nfunc (d *consumerConnDelegate) OnClose(c *Conn)                       { d.r.onConnClose(c) }\n\n// keeps the exported Producer struct clean of the exported methods\n// required to implement the ConnDelegate interface\ntype producerConnDelegate struct {\n\tw *Producer\n}\n\nfunc (d *producerConnDelegate) OnResponse(c *Conn, data []byte)       { d.w.onConnResponse(c, data) }\nfunc (d *producerConnDelegate) OnError(c *Conn, data []byte)          { d.w.onConnError(c, data) }\nfunc (d *producerConnDelegate) OnMessage(c *Conn, m *Message)         {}\nfunc (d *producerConnDelegate) OnMessageFinished(c *Conn, m *Message) {}\nfunc (d *producerConnDelegate) OnMessageRequeued(c *Conn, m *Message) {}\nfunc (d *producerConnDelegate) OnBackoff(c *Conn)                     {}\nfunc (d *producerConnDelegate) OnContinue(c *Conn)                    {}\nfunc (d *producerConnDelegate) OnResume(c *Conn)                      {}\nfunc (d *producerConnDelegate) OnIOError(c *Conn, err error)          { d.w.onConnIOError(c, err) }\nfunc (d *producerConnDelegate) OnHeartbeat(c *Conn)                   { d.w.onConnHeartbeat(c) }\nfunc (d *producerConnDelegate) OnClose(c *Conn)                       { d.w.onConnClose(c) }\n"
        },
        {
          "name": "doc.go",
          "type": "blob",
          "size": 2.33203125,
          "content": "/*\nPackage nsq is the official Go package for NSQ (http://nsq.io/).\n\nIt provides high-level Consumer and Producer types as well as low-level\nfunctions to communicate over the NSQ protocol.\n\nConsumer\n\nConsuming messages from NSQ can be done by creating an instance of a Consumer and supplying it a handler.\n\n\tpackage main\n\timport (\n\t\t\"log\"\n\t\t\"os/signal\"\n\t\t\"github.com/nsqio/go-nsq\"\n\t)\n\n\ttype myMessageHandler struct {}\n\n\t// HandleMessage implements the Handler interface.\n\tfunc (h *myMessageHandler) HandleMessage(m *nsq.Message) error {\n\t\tif len(m.Body) == 0 {\n\t\t\t// Returning nil will automatically send a FIN command to NSQ to mark the message as processed.\n\t\t\t// In this case, a message with an empty body is simply ignored/discarded.\n\t\t\treturn nil\n\t\t}\n\n\t\t// do whatever actual message processing is desired\n\t\terr := processMessage(m.Body)\n\n\t\t// Returning a non-nil error will automatically send a REQ command to NSQ to re-queue the message.\n\t\treturn err\n\t}\n\n\tfunc main() {\n\t\t// Instantiate a consumer that will subscribe to the provided channel.\n\t\tconfig := nsq.NewConfig()\n\t\tconsumer, err := nsq.NewConsumer(\"topic\", \"channel\", config)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\n\t\t// Set the Handler for messages received by this Consumer. Can be called multiple times.\n\t\t// See also AddConcurrentHandlers.\n\t\tconsumer.AddHandler(&myMessageHandler{})\n\n\t\t// Use nsqlookupd to discover nsqd instances.\n\t\t// See also ConnectToNSQD, ConnectToNSQDs, ConnectToNSQLookupds.\n\t\terr = consumer.ConnectToNSQLookupd(\"localhost:4161\")\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\n\t\t// wait for signal to exit\n\t\tsigChan := make(chan os.Signal, 1)\n\t\tsignal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)\n\t\t<-sigChan\n\n\t\t// Gracefully stop the consumer.\n\t\tconsumer.Stop()\n\t}\n\nProducer\n\nProducing messages can be done by creating an instance of a Producer.\n\n\t// Instantiate a producer.\n\tconfig := nsq.NewConfig()\n\tproducer, err := nsq.NewProducer(\"127.0.0.1:4150\", config)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tmessageBody := []byte(\"hello\")\n\ttopicName := \"topic\"\n\n\t// Synchronously publish a single message to the specified topic.\n\t// Messages can also be sent asynchronously and/or in batches.\n\terr = producer.Publish(topicName, messageBody)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Gracefully stop the producer when appropriate (e.g. before shutting down the service)\n\tproducer.Stop()\n\n*/\npackage nsq\n"
        },
        {
          "name": "errors.go",
          "type": "blob",
          "size": 1.1591796875,
          "content": "package nsq\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n)\n\n// ErrNotConnected is returned when a publish command is made\n// against a Producer that is not connected\nvar ErrNotConnected = errors.New(\"not connected\")\n\n// ErrStopped is returned when a publish command is\n// made against a Producer that has been stopped\nvar ErrStopped = errors.New(\"stopped\")\n\n// ErrClosing is returned when a connection is closing\nvar ErrClosing = errors.New(\"closing\")\n\n// ErrAlreadyConnected is returned from ConnectToNSQD when already connected\nvar ErrAlreadyConnected = errors.New(\"already connected\")\n\n// ErrOverMaxInFlight is returned from Consumer if over max-in-flight\nvar ErrOverMaxInFlight = errors.New(\"over configure max-inflight\")\n\n// ErrIdentify is returned from Conn as part of the IDENTIFY handshake\ntype ErrIdentify struct {\n\tReason string\n}\n\n// Error returns a stringified error\nfunc (e ErrIdentify) Error() string {\n\treturn fmt.Sprintf(\"failed to IDENTIFY - %s\", e.Reason)\n}\n\n// ErrProtocol is returned from Producer when encountering\n// an NSQ protocol level error\ntype ErrProtocol struct {\n\tReason string\n}\n\n// Error returns a stringified error\nfunc (e ErrProtocol) Error() string {\n\treturn e.Reason\n}\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.0791015625,
          "content": "module github.com/nsqio/go-nsq\n\ngo 1.17\n\nrequire github.com/golang/snappy v0.0.4\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 0.1630859375,
          "content": "github.com/golang/snappy v0.0.4 h1:yAGX7huGHXlcLOEtBnF4w7FQwA26wojNCwOYAEhLjQM=\ngithub.com/golang/snappy v0.0.4/go.mod h1:/XxbfmMg8lxefKM7IXC3fBNl/7bRcc72aCRzEWrmP2Q=\n"
        },
        {
          "name": "message.go",
          "type": "blob",
          "size": 4.2587890625,
          "content": "package nsq\n\nimport (\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"io\"\n\t\"sync/atomic\"\n\t\"time\"\n)\n\n// The number of bytes for a Message.ID\nconst MsgIDLength = 16\n\n// MessageID is the ASCII encoded hexadecimal message ID\ntype MessageID [MsgIDLength]byte\n\n// Message is the fundamental data type containing\n// the id, body, and metadata\ntype Message struct {\n\tID        MessageID\n\tBody      []byte\n\tTimestamp int64\n\tAttempts  uint16\n\n\tNSQDAddress string\n\n\tDelegate MessageDelegate\n\n\tautoResponseDisabled int32\n\tresponded            int32\n}\n\n// NewMessage creates a Message, initializes some metadata,\n// and returns a pointer\nfunc NewMessage(id MessageID, body []byte) *Message {\n\treturn &Message{\n\t\tID:        id,\n\t\tBody:      body,\n\t\tTimestamp: time.Now().UnixNano(),\n\t}\n}\n\n// DisableAutoResponse disables the automatic response that\n// would normally be sent when a handler.HandleMessage\n// returns (FIN/REQ based on the error value returned).\n//\n// This is useful if you want to batch, buffer, or asynchronously\n// respond to messages.\nfunc (m *Message) DisableAutoResponse() {\n\tatomic.StoreInt32(&m.autoResponseDisabled, 1)\n}\n\n// IsAutoResponseDisabled indicates whether or not this message\n// will be responded to automatically\nfunc (m *Message) IsAutoResponseDisabled() bool {\n\treturn atomic.LoadInt32(&m.autoResponseDisabled) == 1\n}\n\n// HasResponded indicates whether or not this message has been responded to\nfunc (m *Message) HasResponded() bool {\n\treturn atomic.LoadInt32(&m.responded) == 1\n}\n\n// Finish sends a FIN command to the nsqd which\n// sent this message\nfunc (m *Message) Finish() {\n\tif !atomic.CompareAndSwapInt32(&m.responded, 0, 1) {\n\t\treturn\n\t}\n\tm.Delegate.OnFinish(m)\n}\n\n// Touch sends a TOUCH command to the nsqd which\n// sent this message\nfunc (m *Message) Touch() {\n\tif m.HasResponded() {\n\t\treturn\n\t}\n\tm.Delegate.OnTouch(m)\n}\n\n// Requeue sends a REQ command to the nsqd which\n// sent this message, using the supplied delay.\n//\n// A delay of -1 will automatically calculate\n// based on the number of attempts and the\n// configured default_requeue_delay\nfunc (m *Message) Requeue(delay time.Duration) {\n\tm.doRequeue(delay, true)\n}\n\n// RequeueWithoutBackoff sends a REQ command to the nsqd which\n// sent this message, using the supplied delay.\n//\n// Notably, using this method to respond does not trigger a backoff\n// event on the configured Delegate.\nfunc (m *Message) RequeueWithoutBackoff(delay time.Duration) {\n\tm.doRequeue(delay, false)\n}\n\nfunc (m *Message) doRequeue(delay time.Duration, backoff bool) {\n\tif !atomic.CompareAndSwapInt32(&m.responded, 0, 1) {\n\t\treturn\n\t}\n\tm.Delegate.OnRequeue(m, delay, backoff)\n}\n\n// WriteTo implements the WriterTo interface and serializes\n// the message into the supplied producer.\n//\n// It is suggested that the target Writer is buffered to\n// avoid performing many system calls.\nfunc (m *Message) WriteTo(w io.Writer) (int64, error) {\n\tvar buf [10]byte\n\tvar total int64\n\n\tbinary.BigEndian.PutUint64(buf[:8], uint64(m.Timestamp))\n\tbinary.BigEndian.PutUint16(buf[8:10], uint16(m.Attempts))\n\n\tn, err := w.Write(buf[:])\n\ttotal += int64(n)\n\tif err != nil {\n\t\treturn total, err\n\t}\n\n\tn, err = w.Write(m.ID[:])\n\ttotal += int64(n)\n\tif err != nil {\n\t\treturn total, err\n\t}\n\n\tn, err = w.Write(m.Body)\n\ttotal += int64(n)\n\tif err != nil {\n\t\treturn total, err\n\t}\n\n\treturn total, nil\n}\n\n// DecodeMessage deserializes data (as []byte) and creates a new Message\n// message format:\n//  [x][x][x][x][x][x][x][x][x][x][x][x][x][x][x][x][x][x][x][x][x][x][x][x][x][x][x][x][x][x]...\n//  |       (int64)        ||    ||      (hex string encoded in ASCII)           || (binary)\n//  |       8-byte         ||    ||                 16-byte                      || N-byte\n//  ------------------------------------------------------------------------------------------...\n//    nanosecond timestamp    ^^                   message ID                       message body\n//                         (uint16)\n//                          2-byte\n//                         attempts\nfunc DecodeMessage(b []byte) (*Message, error) {\n\tvar msg Message\n\n\tif len(b) < 10+MsgIDLength {\n\t\treturn nil, errors.New(\"not enough data to decode valid message\")\n\t}\n\n\tmsg.Timestamp = int64(binary.BigEndian.Uint64(b[:8]))\n\tmsg.Attempts = binary.BigEndian.Uint16(b[8:10])\n\tcopy(msg.ID[:], b[10:10+MsgIDLength])\n\tmsg.Body = b[10+MsgIDLength:]\n\n\treturn &msg, nil\n}\n"
        },
        {
          "name": "mock_test.go",
          "type": "blob",
          "size": 13.251953125,
          "content": "package nsq\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"strconv\"\n\t\"testing\"\n\t\"time\"\n)\n\ntype tbLog interface {\n\tLog(...interface{})\n}\n\ntype testLogger struct {\n\ttbLog\n}\n\nfunc (tl *testLogger) Output(maxdepth int, s string) error {\n\ttl.Log(s)\n\treturn nil\n}\n\nfunc newTestLogger(tbl tbLog) logger {\n\treturn &testLogger{tbl}\n}\n\ntype instruction struct {\n\tdelay     time.Duration\n\tframeType int32\n\tbody      []byte\n}\n\ntype mockNSQD struct {\n\tt           *testing.T\n\tscript      []instruction\n\tgot         [][]byte\n\ttcpAddr     *net.TCPAddr\n\ttcpListener net.Listener\n\texitChan    chan int\n}\n\nfunc newMockNSQD(t *testing.T, script []instruction, addr string) *mockNSQD {\n\tn := &mockNSQD{\n\t\tt:        t,\n\t\tscript:   script,\n\t\texitChan: make(chan int),\n\t}\n\n\ttcpListener, err := net.Listen(\"tcp\", addr)\n\tif err != nil {\n\t\tn.t.Fatalf(\"FATAL: listen (%s) failed - %s\", n.tcpAddr, err)\n\t}\n\tn.tcpListener = tcpListener\n\tn.tcpAddr = tcpListener.Addr().(*net.TCPAddr)\n\n\tgo n.listen()\n\n\treturn n\n}\n\nfunc (n *mockNSQD) listen() {\n\tn.t.Logf(\"TCP: listening on %s\", n.tcpListener.Addr())\n\n\tfor {\n\t\tconn, err := n.tcpListener.Accept()\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n\t\tgo n.handle(conn)\n\t}\n\n\tn.t.Logf(\"TCP: closing %s\", n.tcpListener.Addr())\n\tclose(n.exitChan)\n}\n\nfunc (n *mockNSQD) handle(conn net.Conn) {\n\tvar idx int\n\n\tn.t.Logf(\"TCP: new client(%s)\", conn.RemoteAddr())\n\n\tbuf := make([]byte, 4)\n\t_, err := io.ReadFull(conn, buf)\n\tif err != nil {\n\t\tn.t.Fatalf(\"ERROR: failed to read protocol version - %s\", err)\n\t}\n\n\treadChan := make(chan []byte)\n\treadDoneChan := make(chan int)\n\tscriptTime := time.After(n.script[0].delay)\n\trdr := bufio.NewReader(conn)\n\n\tgo func() {\n\t\tfor {\n\t\t\tline, err := rdr.ReadBytes('\\n')\n\t\t\tif err != nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// trim the '\\n'\n\t\t\tline = line[:len(line)-1]\n\t\t\treadChan <- line\n\t\t\t<-readDoneChan\n\t\t}\n\t}()\n\n\tvar rdyCount int\n\tfor idx < len(n.script) {\n\t\tselect {\n\t\tcase line := <-readChan:\n\t\t\tn.t.Logf(\"mock: %s\", line)\n\t\t\tn.got = append(n.got, line)\n\t\t\tparams := bytes.Split(line, []byte(\" \"))\n\t\t\tswitch {\n\t\t\tcase bytes.Equal(params[0], []byte(\"IDENTIFY\")):\n\t\t\t\tl := make([]byte, 4)\n\t\t\t\t_, err := io.ReadFull(rdr, l)\n\t\t\t\tif err != nil {\n\t\t\t\t\tn.t.Log(err)\n\t\t\t\t\tgoto exit\n\t\t\t\t}\n\t\t\t\tsize := int32(binary.BigEndian.Uint32(l))\n\t\t\t\tb := make([]byte, size)\n\t\t\t\t_, err = io.ReadFull(rdr, b)\n\t\t\t\tif err != nil {\n\t\t\t\t\tn.t.Log(err)\n\t\t\t\t\tgoto exit\n\t\t\t\t}\n\t\t\t\tn.t.Logf(\"%s\", b)\n\t\t\tcase bytes.Equal(params[0], []byte(\"RDY\")):\n\t\t\t\trdy, _ := strconv.Atoi(string(params[1]))\n\t\t\t\trdyCount = rdy\n\t\t\tcase bytes.Equal(params[0], []byte(\"FIN\")):\n\t\t\tcase bytes.Equal(params[0], []byte(\"REQ\")):\n\t\t\t}\n\t\t\treadDoneChan <- 1\n\t\tcase <-scriptTime:\n\t\t\tinst := n.script[idx]\n\t\t\tif bytes.Equal(inst.body, []byte(\"exit\")) {\n\t\t\t\tgoto exit\n\t\t\t}\n\t\t\tif inst.frameType == FrameTypeMessage {\n\t\t\t\tif rdyCount == 0 {\n\t\t\t\t\tn.t.Log(\"!!! RDY == 0\")\n\t\t\t\t\tscriptTime = time.After(n.script[idx+1].delay)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\trdyCount--\n\t\t\t}\n\t\t\t_, err := conn.Write(framedResponse(inst.frameType, inst.body))\n\t\t\tif err != nil {\n\t\t\t\tn.t.Log(err)\n\t\t\t\tgoto exit\n\t\t\t}\n\t\t\tscriptTime = time.After(n.script[idx+1].delay)\n\t\t\tidx++\n\t\t}\n\t}\n\nexit:\n\tn.tcpListener.Close()\n\tconn.Close()\n}\n\nfunc framedResponse(frameType int32, data []byte) []byte {\n\tvar w bytes.Buffer\n\n\tbeBuf := make([]byte, 4)\n\tsize := uint32(len(data)) + 4\n\n\tbinary.BigEndian.PutUint32(beBuf, size)\n\t_, err := w.Write(beBuf)\n\tif err != nil {\n\t\treturn nil\n\t}\n\n\tbinary.BigEndian.PutUint32(beBuf, uint32(frameType))\n\t_, err = w.Write(beBuf)\n\tif err != nil {\n\t\treturn nil\n\t}\n\n\t_, _ = w.Write(data)\n\treturn w.Bytes()\n}\n\ntype testHandler struct{}\n\nfunc (h *testHandler) HandleMessage(message *Message) error {\n\tswitch string(message.Body) {\n\tcase \"requeue\":\n\t\tmessage.Requeue(-1)\n\t\treturn nil\n\tcase \"requeue_no_backoff_1\":\n\t\tif message.Attempts > 1 {\n\t\t\treturn nil\n\t\t}\n\t\tmessage.RequeueWithoutBackoff(-1)\n\t\treturn nil\n\tcase \"bad\":\n\t\treturn errors.New(\"bad\")\n\t}\n\treturn nil\n}\n\nfunc frameMessage(m *Message) []byte {\n\tvar b bytes.Buffer\n\tm.WriteTo(&b)\n\treturn b.Bytes()\n}\n\nfunc TestConsumerBackoff(t *testing.T) {\n\tmsgIDGood := MessageID{'1', '2', '3', '4', '5', '6', '7', '8', '9', '0', 'a', 's', 'd', 'f', 'g', 'h'}\n\tmsgGood := NewMessage(msgIDGood, []byte(\"good\"))\n\n\tmsgIDBad := MessageID{'z', 'x', 'c', 'v', 'b', '6', '7', '8', '9', '0', 'a', 's', 'd', 'f', 'g', 'h'}\n\tmsgBad := NewMessage(msgIDBad, []byte(\"bad\"))\n\n\tscript := []instruction{\n\t\t// IDENTIFY\n\t\tinstruction{0, FrameTypeResponse, []byte(\"OK\")},\n\t\t// SUB\n\t\tinstruction{0, FrameTypeResponse, []byte(\"OK\")},\n\t\tinstruction{20 * time.Millisecond, FrameTypeMessage, frameMessage(msgGood)},\n\t\tinstruction{20 * time.Millisecond, FrameTypeMessage, frameMessage(msgGood)},\n\t\tinstruction{20 * time.Millisecond, FrameTypeMessage, frameMessage(msgGood)},\n\t\tinstruction{20 * time.Millisecond, FrameTypeMessage, frameMessage(msgBad)},\n\t\tinstruction{20 * time.Millisecond, FrameTypeMessage, frameMessage(msgBad)},\n\t\tinstruction{20 * time.Millisecond, FrameTypeMessage, frameMessage(msgGood)},\n\t\tinstruction{20 * time.Millisecond, FrameTypeMessage, frameMessage(msgGood)},\n\t\t// needed to exit test\n\t\tinstruction{200 * time.Millisecond, -1, []byte(\"exit\")},\n\t}\n\n\taddr, _ := net.ResolveTCPAddr(\"tcp\", \"127.0.0.1:0\")\n\tn := newMockNSQD(t, script, addr.String())\n\n\ttopicName := \"test_consumer_commands\" + strconv.Itoa(int(time.Now().Unix()))\n\tconfig := NewConfig()\n\tconfig.MaxInFlight = 5\n\tconfig.BackoffMultiplier = 10 * time.Millisecond\n\tq, _ := NewConsumer(topicName, \"ch\", config)\n\tq.SetLogger(newTestLogger(t), LogLevelDebug)\n\tq.AddHandler(&testHandler{})\n\terr := q.ConnectToNSQD(n.tcpAddr.String())\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\t<-n.exitChan\n\n\tfor i, r := range n.got {\n\t\tt.Logf(\"%d: %s\", i, r)\n\t}\n\n\texpected := []string{\n\t\t\"IDENTIFY\",\n\t\t\"SUB \" + topicName + \" ch\",\n\t\t\"RDY 5\",\n\t\tfmt.Sprintf(\"FIN %s\", msgIDGood),\n\t\tfmt.Sprintf(\"FIN %s\", msgIDGood),\n\t\tfmt.Sprintf(\"FIN %s\", msgIDGood),\n\t\t\"RDY 0\",\n\t\tfmt.Sprintf(\"REQ %s 0\", msgIDBad),\n\t\t\"RDY 1\",\n\t\t\"RDY 0\",\n\t\tfmt.Sprintf(\"REQ %s 0\", msgIDBad),\n\t\t\"RDY 1\",\n\t\t\"RDY 0\",\n\t\tfmt.Sprintf(\"FIN %s\", msgIDGood),\n\t\t\"RDY 1\",\n\t\t\"RDY 5\",\n\t\tfmt.Sprintf(\"FIN %s\", msgIDGood),\n\t}\n\tif len(n.got) != len(expected) {\n\t\tt.Fatalf(\"we got %d commands != %d expected\", len(n.got), len(expected))\n\t}\n\tfor i, r := range n.got {\n\t\tif string(r) != expected[i] {\n\t\t\tt.Fatalf(\"cmd %d bad %s != %s\", i, r, expected[i])\n\t\t}\n\t}\n}\n\nfunc TestConsumerRequeueNoBackoff(t *testing.T) {\n\tmsgIDGood := MessageID{'1', '2', '3', '4', '5', '6', '7', '8', '9', '0', 'a', 's', 'd', 'f', 'g', 'h'}\n\tmsgIDRequeue := MessageID{'r', 'e', 'q', 'v', 'b', '6', '7', '8', '9', '0', 'a', 's', 'd', 'f', 'g', 'h'}\n\tmsgIDRequeueNoBackoff := MessageID{'r', 'e', 'q', 'n', 'b', 'a', 'c', 'k', '9', '0', 'a', 's', 'd', 'f', 'g', 'h'}\n\n\tmsgGood := NewMessage(msgIDGood, []byte(\"good\"))\n\tmsgRequeue := NewMessage(msgIDRequeue, []byte(\"requeue\"))\n\tmsgRequeueNoBackoff := NewMessage(msgIDRequeueNoBackoff, []byte(\"requeue_no_backoff_1\"))\n\n\tscript := []instruction{\n\t\t// IDENTIFY\n\t\tinstruction{0, FrameTypeResponse, []byte(\"OK\")},\n\t\t// SUB\n\t\tinstruction{0, FrameTypeResponse, []byte(\"OK\")},\n\t\tinstruction{20 * time.Millisecond, FrameTypeMessage, frameMessage(msgRequeue)},\n\t\tinstruction{20 * time.Millisecond, FrameTypeMessage, frameMessage(msgRequeueNoBackoff)},\n\t\tinstruction{20 * time.Millisecond, FrameTypeMessage, frameMessage(msgGood)},\n\t\t// needed to exit test\n\t\tinstruction{100 * time.Millisecond, -1, []byte(\"exit\")},\n\t}\n\n\taddr, _ := net.ResolveTCPAddr(\"tcp\", \"127.0.0.1:0\")\n\tn := newMockNSQD(t, script, addr.String())\n\n\ttopicName := \"test_requeue\" + strconv.Itoa(int(time.Now().Unix()))\n\tconfig := NewConfig()\n\tconfig.MaxInFlight = 1\n\tconfig.BackoffMultiplier = 10 * time.Millisecond\n\tq, _ := NewConsumer(topicName, \"ch\", config)\n\tq.SetLogger(newTestLogger(t), LogLevelDebug)\n\tq.AddHandler(&testHandler{})\n\terr := q.ConnectToNSQD(n.tcpAddr.String())\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\tselect {\n\tcase <-n.exitChan:\n\t\tt.Log(\"clean exit\")\n\tcase <-time.After(500 * time.Millisecond):\n\t\tt.Log(\"timeout\")\n\t}\n\n\tfor i, r := range n.got {\n\t\tt.Logf(\"%d: %s\", i, r)\n\t}\n\n\texpected := []string{\n\t\t\"IDENTIFY\",\n\t\t\"SUB \" + topicName + \" ch\",\n\t\t\"RDY 1\",\n\t\t\"RDY 0\",\n\t\tfmt.Sprintf(\"REQ %s 0\", msgIDRequeue),\n\t\t\"RDY 1\",\n\t\t\"RDY 0\",\n\t\tfmt.Sprintf(\"REQ %s 0\", msgIDRequeueNoBackoff),\n\t\t\"RDY 1\",\n\t\tfmt.Sprintf(\"FIN %s\", msgIDGood),\n\t}\n\tif len(n.got) != len(expected) {\n\t\tt.Fatalf(\"we got %d commands != %d expected\", len(n.got), len(expected))\n\t}\n\tfor i, r := range n.got {\n\t\tif string(r) != expected[i] {\n\t\t\tt.Fatalf(\"cmd %d bad %s != %s\", i, r, expected[i])\n\t\t}\n\t}\n}\n\nfunc TestConsumerBackoffDisconnect(t *testing.T) {\n\tmsgIDGood := MessageID{'1', '2', '3', '4', '5', '6', '7', '8', '9', '0', 'a', 's', 'd', 'f', 'g', 'h'}\n\tmsgIDRequeue := MessageID{'r', 'e', 'q', 'v', 'b', '6', '7', '8', '9', '0', 'a', 's', 'd', 'f', 'g', 'h'}\n\n\tmsgGood := NewMessage(msgIDGood, []byte(\"good\"))\n\tmsgRequeue := NewMessage(msgIDRequeue, []byte(\"requeue\"))\n\n\tscript := []instruction{\n\t\t// IDENTIFY\n\t\tinstruction{0, FrameTypeResponse, []byte(\"OK\")},\n\t\t// SUB\n\t\tinstruction{0, FrameTypeResponse, []byte(\"OK\")},\n\t\tinstruction{20 * time.Millisecond, FrameTypeMessage, frameMessage(msgGood)},\n\t\tinstruction{20 * time.Millisecond, FrameTypeMessage, frameMessage(msgRequeue)},\n\t\tinstruction{20 * time.Millisecond, FrameTypeMessage, frameMessage(msgRequeue)},\n\t\tinstruction{20 * time.Millisecond, FrameTypeMessage, frameMessage(msgGood)},\n\t\t// needed to exit test\n\t\tinstruction{100 * time.Millisecond, -1, []byte(\"exit\")},\n\t}\n\n\taddr, _ := net.ResolveTCPAddr(\"tcp\", \"127.0.0.1:0\")\n\tn := newMockNSQD(t, script, addr.String())\n\n\ttopicName := \"test_requeue\" + strconv.Itoa(int(time.Now().Unix()))\n\tconfig := NewConfig()\n\tconfig.MaxInFlight = 5\n\tconfig.BackoffMultiplier = 10 * time.Millisecond\n\tconfig.LookupdPollInterval = 10 * time.Millisecond\n\tconfig.RDYRedistributeInterval = 10 * time.Millisecond\n\tq, _ := NewConsumer(topicName, \"ch\", config)\n\tq.SetLogger(newTestLogger(t), LogLevelDebug)\n\tq.AddHandler(&testHandler{})\n\terr := q.ConnectToNSQD(n.tcpAddr.String())\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\tselect {\n\tcase <-n.exitChan:\n\t\tt.Log(\"clean exit\")\n\tcase <-time.After(500 * time.Millisecond):\n\t\tt.Log(\"timeout\")\n\t}\n\n\tfor i, r := range n.got {\n\t\tt.Logf(\"%d: %s\", i, r)\n\t}\n\n\texpected := []string{\n\t\t\"IDENTIFY\",\n\t\t\"SUB \" + topicName + \" ch\",\n\t\t\"RDY 5\",\n\t\tfmt.Sprintf(\"FIN %s\", msgIDGood),\n\t\t\"RDY 0\",\n\t\tfmt.Sprintf(\"REQ %s 0\", msgIDRequeue),\n\t\t\"RDY 1\",\n\t\t\"RDY 0\",\n\t\tfmt.Sprintf(\"REQ %s 0\", msgIDRequeue),\n\t\t\"RDY 1\",\n\t\t\"RDY 0\",\n\t\tfmt.Sprintf(\"FIN %s\", msgIDGood),\n\t\t\"RDY 1\",\n\t}\n\tif len(n.got) != len(expected) {\n\t\tt.Fatalf(\"we got %d commands != %d expected\", len(n.got), len(expected))\n\t}\n\tfor i, r := range n.got {\n\t\tif string(r) != expected[i] {\n\t\t\tt.Fatalf(\"cmd %d bad %s != %s\", i, r, expected[i])\n\t\t}\n\t}\n\n\tscript = []instruction{\n\t\t// IDENTIFY\n\t\tinstruction{0, FrameTypeResponse, []byte(\"OK\")},\n\t\t// SUB\n\t\tinstruction{0, FrameTypeResponse, []byte(\"OK\")},\n\t\tinstruction{20 * time.Millisecond, FrameTypeMessage, frameMessage(msgGood)},\n\t\tinstruction{20 * time.Millisecond, FrameTypeMessage, frameMessage(msgGood)},\n\t\t// needed to exit test\n\t\tinstruction{100 * time.Millisecond, -1, []byte(\"exit\")},\n\t}\n\n\tn = newMockNSQD(t, script, n.tcpAddr.String())\n\n\tselect {\n\tcase <-n.exitChan:\n\t\tt.Log(\"clean exit\")\n\tcase <-time.After(500 * time.Millisecond):\n\t\tt.Log(\"timeout\")\n\t}\n\n\tfor i, r := range n.got {\n\t\tt.Logf(\"%d: %s\", i, r)\n\t}\n\n\texpected = []string{\n\t\t\"IDENTIFY\",\n\t\t\"SUB \" + topicName + \" ch\",\n\t\t\"RDY 1\",\n\t\t\"RDY 5\",\n\t\tfmt.Sprintf(\"FIN %s\", msgIDGood),\n\t\tfmt.Sprintf(\"FIN %s\", msgIDGood),\n\t}\n\tif len(n.got) != len(expected) {\n\t\tt.Fatalf(\"we got %d commands != %d expected\", len(n.got), len(expected))\n\t}\n\tfor i, r := range n.got {\n\t\tif string(r) != expected[i] {\n\t\t\tt.Fatalf(\"cmd %d bad %s != %s\", i, r, expected[i])\n\t\t}\n\t}\n}\n\nfunc TestConsumerPause(t *testing.T) {\n\tmsgIDGood := MessageID{'1', '2', '3', '4', '5', '6', '7', '8', '9', '0', 'a', 's', 'd', 'f', 'g', 'h'}\n\n\tmsgGood := NewMessage(msgIDGood, []byte(\"good\"))\n\n\tscript := []instruction{\n\t\t// IDENTIFY\n\t\tinstruction{0, FrameTypeResponse, []byte(\"OK\")},\n\t\t// SUB\n\t\tinstruction{0, FrameTypeResponse, []byte(\"OK\")},\n\t\tinstruction{20 * time.Millisecond, FrameTypeMessage, frameMessage(msgGood)},\n\t\t// needed to exit test\n\t\tinstruction{200 * time.Millisecond, -1, []byte(\"exit\")},\n\t}\n\n\taddr, _ := net.ResolveTCPAddr(\"tcp\", \"127.0.0.1:0\")\n\tn := newMockNSQD(t, script, addr.String())\n\n\ttopicName := \"test_pause\" + strconv.Itoa(int(time.Now().Unix()))\n\tconfig := NewConfig()\n\tconfig.MaxInFlight = 5\n\tq, _ := NewConsumer(topicName, \"ch\", config)\n\tq.SetLogger(newTestLogger(t), LogLevelDebug)\n\tq.AddHandler(&testHandler{})\n\terr := q.ConnectToNSQD(n.tcpAddr.String())\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\ttimeoutCh := time.After(500 * time.Millisecond)\n\tpauseCh := time.After(50 * time.Millisecond)\n\tunpauseCh := time.After(75 * time.Millisecond)\n\tfor {\n\t\tselect {\n\t\tcase <-n.exitChan:\n\t\t\tt.Log(\"clean exit\")\n\t\t\tgoto done\n\t\tcase <-timeoutCh:\n\t\t\tt.Log(\"timeout\")\n\t\t\tgoto done\n\t\tcase <-pauseCh:\n\t\t\tq.ChangeMaxInFlight(0)\n\t\tcase <-unpauseCh:\n\t\t\tq.ChangeMaxInFlight(config.MaxInFlight)\n\t\t}\n\t}\ndone:\n\n\tfor i, r := range n.got {\n\t\tt.Logf(\"%d: %s\", i, r)\n\t}\n\n\texpected := []string{\n\t\t\"IDENTIFY\",\n\t\t\"SUB \" + topicName + \" ch\",\n\t\t\"RDY 5\",\n\t\tfmt.Sprintf(\"FIN %s\", msgIDGood),\n\t\t\"RDY 0\",\n\t\t\"RDY 5\",\n\t}\n\tif len(n.got) != len(expected) {\n\t\tt.Fatalf(\"we got %d commands != %d expected\", len(n.got), len(expected))\n\t}\n\tfor i, r := range n.got {\n\t\tif string(r) != expected[i] {\n\t\t\tt.Fatalf(\"cmd %d bad %s != %s\", i, r, expected[i])\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "producer.go",
          "type": "blob",
          "size": 11.318359375,
          "content": "package nsq\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n)\n\ntype producerConn interface {\n\tString() string\n\tSetLogger(logger, LogLevel, string)\n\tSetLoggerLevel(LogLevel)\n\tSetLoggerForLevel(logger, LogLevel, string)\n\tConnect() (*IdentifyResponse, error)\n\tClose() error\n\tWriteCommand(*Command) error\n}\n\n// Producer is a high-level type to publish to NSQ.\n//\n// A Producer instance is 1:1 with a destination `nsqd`\n// and will lazily connect to that instance (and re-connect)\n// when Publish commands are executed.\ntype Producer struct {\n\tid     int64\n\taddr   string\n\tconn   producerConn\n\tconfig Config\n\n\tlogger   []logger\n\tlogLvl   LogLevel\n\tlogGuard sync.RWMutex\n\n\tresponseChan chan []byte\n\terrorChan    chan []byte\n\tcloseChan    chan int\n\n\ttransactionChan chan *ProducerTransaction\n\ttransactions    []*ProducerTransaction\n\tstate           int32\n\n\tconcurrentProducers int32\n\tstopFlag            int32\n\texitChan            chan int\n\twg                  sync.WaitGroup\n\tguard               sync.Mutex\n}\n\n// ProducerTransaction is returned by the async publish methods\n// to retrieve metadata about the command after the\n// response is received.\ntype ProducerTransaction struct {\n\tcmd      *Command\n\tdoneChan chan *ProducerTransaction\n\tError    error         // the error (or nil) of the publish command\n\tArgs     []interface{} // the slice of variadic arguments passed to PublishAsync or MultiPublishAsync\n}\n\nfunc (t *ProducerTransaction) finish() {\n\tif t.doneChan != nil {\n\t\tt.doneChan <- t\n\t}\n}\n\n// NewProducer returns an instance of Producer for the specified address\n//\n// The only valid way to create a Config is via NewConfig, using a struct literal will panic.\n// After Config is passed into NewProducer the values are no longer mutable (they are copied).\nfunc NewProducer(addr string, config *Config) (*Producer, error) {\n\terr := config.Validate()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tp := &Producer{\n\t\tid: atomic.AddInt64(&instCount, 1),\n\n\t\taddr:   addr,\n\t\tconfig: *config,\n\n\t\tlogger: make([]logger, int(LogLevelMax+1)),\n\t\tlogLvl: LogLevelInfo,\n\n\t\ttransactionChan: make(chan *ProducerTransaction),\n\t\texitChan:        make(chan int),\n\t\tresponseChan:    make(chan []byte),\n\t\terrorChan:       make(chan []byte),\n\t}\n\n\t// Set default logger for all log levels\n\tl := log.New(os.Stderr, \"\", log.Flags())\n\tfor index := range p.logger {\n\t\tp.logger[index] = l\n\t}\n\treturn p, nil\n}\n\n// Ping causes the Producer to connect to it's configured nsqd (if not already\n// connected) and send a `Nop` command, returning any error that might occur.\n//\n// This method can be used to verify that a newly-created Producer instance is\n// configured correctly, rather than relying on the lazy \"connect on Publish\"\n// behavior of a Producer.\nfunc (w *Producer) Ping() error {\n\tif atomic.LoadInt32(&w.state) != StateConnected {\n\t\terr := w.connect()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn w.conn.WriteCommand(Nop())\n}\n\n// SetLogger assigns the logger to use as well as a level\n//\n// The logger parameter is an interface that requires the following\n// method to be implemented (such as the the stdlib log.Logger):\n//\n//\tOutput(calldepth int, s string)\nfunc (w *Producer) SetLogger(l logger, lvl LogLevel) {\n\tw.logGuard.Lock()\n\tdefer w.logGuard.Unlock()\n\n\tfor level := range w.logger {\n\t\tw.logger[level] = l\n\t}\n\tw.logLvl = lvl\n}\n\n// SetLoggerForLevel assigns the same logger for specified `level`.\nfunc (w *Producer) SetLoggerForLevel(l logger, lvl LogLevel) {\n\tw.logGuard.Lock()\n\tdefer w.logGuard.Unlock()\n\n\tw.logger[lvl] = l\n}\n\n// SetLoggerLevel sets the package logging level.\nfunc (w *Producer) SetLoggerLevel(lvl LogLevel) {\n\tw.logGuard.Lock()\n\tdefer w.logGuard.Unlock()\n\n\tw.logLvl = lvl\n}\n\nfunc (w *Producer) getLogger(lvl LogLevel) (logger, LogLevel) {\n\tw.logGuard.RLock()\n\tdefer w.logGuard.RUnlock()\n\n\treturn w.logger[lvl], w.logLvl\n}\n\nfunc (w *Producer) getLogLevel() LogLevel {\n\tw.logGuard.RLock()\n\tdefer w.logGuard.RUnlock()\n\n\treturn w.logLvl\n}\n\n// String returns the address of the Producer\nfunc (w *Producer) String() string {\n\treturn w.addr\n}\n\n// Stop initiates a graceful stop of the Producer (permanent)\n//\n// NOTE: this blocks until completion\nfunc (w *Producer) Stop() {\n\tw.guard.Lock()\n\tif !atomic.CompareAndSwapInt32(&w.stopFlag, 0, 1) {\n\t\tw.guard.Unlock()\n\t\treturn\n\t}\n\tw.log(LogLevelInfo, \"(%s) stopping\", w.addr)\n\tclose(w.exitChan)\n\tw.close()\n\tw.guard.Unlock()\n\tw.wg.Wait()\n}\n\n// PublishAsync publishes a message body to the specified topic\n// but does not wait for the response from `nsqd`.\n//\n// When the Producer eventually receives the response from `nsqd`,\n// the supplied `doneChan` (if specified)\n// will receive a `ProducerTransaction` instance with the supplied variadic arguments\n// and the response error if present\nfunc (w *Producer) PublishAsync(topic string, body []byte, doneChan chan *ProducerTransaction,\n\targs ...interface{}) error {\n\treturn w.sendCommandAsync(Publish(topic, body), doneChan, args)\n}\n\n// MultiPublishAsync publishes a slice of message bodies to the specified topic\n// but does not wait for the response from `nsqd`.\n//\n// When the Producer eventually receives the response from `nsqd`,\n// the supplied `doneChan` (if specified)\n// will receive a `ProducerTransaction` instance with the supplied variadic arguments\n// and the response error if present\nfunc (w *Producer) MultiPublishAsync(topic string, body [][]byte, doneChan chan *ProducerTransaction,\n\targs ...interface{}) error {\n\tcmd, err := MultiPublish(topic, body)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn w.sendCommandAsync(cmd, doneChan, args)\n}\n\n// Publish synchronously publishes a message body to the specified topic, returning\n// an error if publish failed\nfunc (w *Producer) Publish(topic string, body []byte) error {\n\treturn w.sendCommand(Publish(topic, body))\n}\n\n// MultiPublish synchronously publishes a slice of message bodies to the specified topic, returning\n// an error if publish failed\nfunc (w *Producer) MultiPublish(topic string, body [][]byte) error {\n\tcmd, err := MultiPublish(topic, body)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn w.sendCommand(cmd)\n}\n\n// DeferredPublish synchronously publishes a message body to the specified topic\n// where the message will queue at the channel level until the timeout expires, returning\n// an error if publish failed\nfunc (w *Producer) DeferredPublish(topic string, delay time.Duration, body []byte) error {\n\treturn w.sendCommand(DeferredPublish(topic, delay, body))\n}\n\n// DeferredPublishAsync publishes a message body to the specified topic\n// where the message will queue at the channel level until the timeout expires\n// but does not wait for the response from `nsqd`.\n//\n// When the Producer eventually receives the response from `nsqd`,\n// the supplied `doneChan` (if specified)\n// will receive a `ProducerTransaction` instance with the supplied variadic arguments\n// and the response error if present\nfunc (w *Producer) DeferredPublishAsync(topic string, delay time.Duration, body []byte,\n\tdoneChan chan *ProducerTransaction, args ...interface{}) error {\n\treturn w.sendCommandAsync(DeferredPublish(topic, delay, body), doneChan, args)\n}\n\nfunc (w *Producer) sendCommand(cmd *Command) error {\n\tdoneChan := make(chan *ProducerTransaction)\n\terr := w.sendCommandAsync(cmd, doneChan, nil)\n\tif err != nil {\n\t\tclose(doneChan)\n\t\treturn err\n\t}\n\tt := <-doneChan\n\treturn t.Error\n}\n\nfunc (w *Producer) sendCommandAsync(cmd *Command, doneChan chan *ProducerTransaction,\n\targs []interface{}) error {\n\t// keep track of how many outstanding producers we're dealing with\n\t// in order to later ensure that we clean them all up...\n\tatomic.AddInt32(&w.concurrentProducers, 1)\n\tdefer atomic.AddInt32(&w.concurrentProducers, -1)\n\n\tif atomic.LoadInt32(&w.state) != StateConnected {\n\t\terr := w.connect()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tt := &ProducerTransaction{\n\t\tcmd:      cmd,\n\t\tdoneChan: doneChan,\n\t\tArgs:     args,\n\t}\n\n\tselect {\n\tcase w.transactionChan <- t:\n\tcase <-w.exitChan:\n\t\treturn ErrStopped\n\t}\n\n\treturn nil\n}\n\nfunc (w *Producer) connect() error {\n\tw.guard.Lock()\n\tdefer w.guard.Unlock()\n\n\tif atomic.LoadInt32(&w.stopFlag) == 1 {\n\t\treturn ErrStopped\n\t}\n\n\tstate := atomic.LoadInt32(&w.state)\n\tswitch {\n\tcase state == StateConnected:\n\t\treturn nil\n\tcase state != StateInit:\n\t\treturn ErrNotConnected\n\t}\n\n\tw.log(LogLevelInfo, \"(%s) connecting to nsqd\", w.addr)\n\n\tw.conn = NewConn(w.addr, &w.config, &producerConnDelegate{w})\n\tw.conn.SetLoggerLevel(w.getLogLevel())\n\tformat := fmt.Sprintf(\"%3d (%%s)\", w.id)\n\tfor index := range w.logger {\n\t\tw.conn.SetLoggerForLevel(w.logger[index], LogLevel(index), format)\n\t}\n\n\t_, err := w.conn.Connect()\n\tif err != nil {\n\t\tw.conn.Close()\n\t\tw.log(LogLevelError, \"(%s) error connecting to nsqd - %s\", w.addr, err)\n\t\treturn err\n\t}\n\tatomic.StoreInt32(&w.state, StateConnected)\n\tw.closeChan = make(chan int)\n\tw.wg.Add(1)\n\tgo w.router()\n\n\treturn nil\n}\n\nfunc (w *Producer) close() {\n\tif !atomic.CompareAndSwapInt32(&w.state, StateConnected, StateDisconnected) {\n\t\treturn\n\t}\n\tw.conn.Close()\n\tgo func() {\n\t\t// we need to handle this in a goroutine so we don't\n\t\t// block the caller from making progress\n\t\tw.wg.Wait()\n\t\tatomic.StoreInt32(&w.state, StateInit)\n\t}()\n}\n\nfunc (w *Producer) router() {\n\tfor {\n\t\tselect {\n\t\tcase t := <-w.transactionChan:\n\t\t\tw.transactions = append(w.transactions, t)\n\t\t\terr := w.conn.WriteCommand(t.cmd)\n\t\t\tif err != nil {\n\t\t\t\tw.log(LogLevelError, \"(%s) sending command - %s\", w.conn.String(), err)\n\t\t\t\tw.close()\n\t\t\t}\n\t\tcase data := <-w.responseChan:\n\t\t\tw.popTransaction(FrameTypeResponse, data)\n\t\tcase data := <-w.errorChan:\n\t\t\tw.popTransaction(FrameTypeError, data)\n\t\tcase <-w.closeChan:\n\t\t\tgoto exit\n\t\tcase <-w.exitChan:\n\t\t\tgoto exit\n\t\t}\n\t}\n\nexit:\n\tw.transactionCleanup()\n\tw.wg.Done()\n\tw.log(LogLevelInfo, \"(%s) exiting router\", w.conn.String())\n}\n\nfunc (w *Producer) popTransaction(frameType int32, data []byte) {\n\tif len(w.transactions) == 0 {\n\t\tdataLen := len(data)\n\t\tif dataLen > 32 {\n\t\t\tdata = data[:32]\n\t\t}\n\t\tw.log(LogLevelError,\n\t\t\t\"(%s) unexpected response type=%d len=%d data[:32]=0x%x\",\n\t\t\tw.conn.String(), frameType, dataLen, data)\n\t\tw.close()\n\t\treturn\n\t}\n\tt := w.transactions[0]\n\tw.transactions = w.transactions[1:]\n\tif frameType == FrameTypeError {\n\t\tt.Error = ErrProtocol{string(data)}\n\t}\n\tt.finish()\n}\n\nfunc (w *Producer) transactionCleanup() {\n\t// clean up transactions we can easily account for\n\tfor _, t := range w.transactions {\n\t\tt.Error = ErrNotConnected\n\t\tt.finish()\n\t}\n\tw.transactions = w.transactions[:0]\n\n\t// spin and free up any writes that might have raced\n\t// with the cleanup process (blocked on writing\n\t// to transactionChan)\n\tfor {\n\t\tselect {\n\t\tcase t := <-w.transactionChan:\n\t\t\tt.Error = ErrNotConnected\n\t\t\tt.finish()\n\t\tdefault:\n\t\t\t// keep spinning until there are 0 concurrent producers\n\t\t\tif atomic.LoadInt32(&w.concurrentProducers) == 0 {\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// give the runtime a chance to schedule other racing goroutines\n\t\t\ttime.Sleep(5 * time.Millisecond)\n\t\t}\n\t}\n}\n\nfunc (w *Producer) log(lvl LogLevel, line string, args ...interface{}) {\n\tlogger, logLvl := w.getLogger(lvl)\n\n\tif logger == nil {\n\t\treturn\n\t}\n\n\tif logLvl > lvl {\n\t\treturn\n\t}\n\n\tlogger.Output(2, fmt.Sprintf(\"%-4s %3d %s\", lvl, w.id, fmt.Sprintf(line, args...)))\n}\n\nfunc (w *Producer) onConnResponse(c *Conn, data []byte) { w.responseChan <- data }\nfunc (w *Producer) onConnError(c *Conn, data []byte)    { w.errorChan <- data }\nfunc (w *Producer) onConnHeartbeat(c *Conn)             {}\nfunc (w *Producer) onConnIOError(c *Conn, err error)    { w.close() }\nfunc (w *Producer) onConnClose(c *Conn) {\n\tw.guard.Lock()\n\tdefer w.guard.Unlock()\n\tclose(w.closeChan)\n}\n"
        },
        {
          "name": "producer_test.go",
          "type": "blob",
          "size": 8.546875,
          "content": "package nsq\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"os\"\n\t\"runtime\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\ntype ConsumerHandler struct {\n\tt              *testing.T\n\tq              *Consumer\n\tmessagesGood   int\n\tmessagesFailed int\n}\n\nfunc (h *ConsumerHandler) LogFailedMessage(message *Message) {\n\th.messagesFailed++\n\th.q.Stop()\n}\n\nfunc (h *ConsumerHandler) HandleMessage(message *Message) error {\n\tmsg := string(message.Body)\n\tif msg == \"bad_test_case\" {\n\t\treturn errors.New(\"fail this message\")\n\t}\n\tif msg != \"multipublish_test_case\" && msg != \"publish_test_case\" {\n\t\th.t.Error(\"message 'action' was not correct:\", msg)\n\t}\n\th.messagesGood++\n\treturn nil\n}\n\nfunc TestProducerConnection(t *testing.T) {\n\tconfig := NewConfig()\n\tladdr := \"127.0.0.1\"\n\n\tconfig.LocalAddr, _ = net.ResolveTCPAddr(\"tcp\", laddr+\":0\")\n\n\tw, _ := NewProducer(\"127.0.0.1:4150\", config)\n\tw.SetLogger(nullLogger, LogLevelInfo)\n\n\terr := w.Publish(\"write_test\", []byte(\"test\"))\n\tif err != nil {\n\t\tt.Fatalf(\"should lazily connect - %s\", err)\n\t}\n\n\tw.Stop()\n\n\terr = w.Publish(\"write_test\", []byte(\"fail test\"))\n\tif err != ErrStopped {\n\t\tt.Fatalf(\"should not be able to write after Stop()\")\n\t}\n}\n\nfunc TestProducerPing(t *testing.T) {\n\tlog.SetOutput(io.Discard)\n\tdefer log.SetOutput(os.Stdout)\n\n\tconfig := NewConfig()\n\tw, _ := NewProducer(\"127.0.0.1:4150\", config)\n\tw.SetLogger(nullLogger, LogLevelInfo)\n\n\terr := w.Ping()\n\n\tif err != nil {\n\t\tt.Fatalf(\"should connect on ping\")\n\t}\n\n\tw.Stop()\n\n\terr = w.Ping()\n\tif err != ErrStopped {\n\t\tt.Fatalf(\"should not be able to ping after Stop()\")\n\t}\n}\n\nfunc TestProducerPublish(t *testing.T) {\n\ttopicName := \"publish\" + strconv.Itoa(int(time.Now().Unix()))\n\tmsgCount := 10\n\n\tconfig := NewConfig()\n\tw, _ := NewProducer(\"127.0.0.1:4150\", config)\n\tw.SetLogger(nullLogger, LogLevelInfo)\n\tdefer w.Stop()\n\n\tfor i := 0; i < msgCount; i++ {\n\t\terr := w.Publish(topicName, []byte(\"publish_test_case\"))\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"error %s\", err)\n\t\t}\n\t}\n\n\terr := w.Publish(topicName, []byte(\"bad_test_case\"))\n\tif err != nil {\n\t\tt.Fatalf(\"error %s\", err)\n\t}\n\n\treadMessages(topicName, t, msgCount)\n}\n\nfunc TestProducerMultiPublish(t *testing.T) {\n\ttopicName := \"multi_publish\" + strconv.Itoa(int(time.Now().Unix()))\n\tmsgCount := 10\n\n\tconfig := NewConfig()\n\tw, _ := NewProducer(\"127.0.0.1:4150\", config)\n\tw.SetLogger(nullLogger, LogLevelInfo)\n\tdefer w.Stop()\n\n\tvar testData [][]byte\n\tfor i := 0; i < msgCount; i++ {\n\t\ttestData = append(testData, []byte(\"multipublish_test_case\"))\n\t}\n\n\terr := w.MultiPublish(topicName, testData)\n\tif err != nil {\n\t\tt.Fatalf(\"error %s\", err)\n\t}\n\n\terr = w.Publish(topicName, []byte(\"bad_test_case\"))\n\tif err != nil {\n\t\tt.Fatalf(\"error %s\", err)\n\t}\n\n\treadMessages(topicName, t, msgCount)\n}\n\nfunc TestProducerPublishAsync(t *testing.T) {\n\ttopicName := \"async_publish\" + strconv.Itoa(int(time.Now().Unix()))\n\tmsgCount := 10\n\n\tconfig := NewConfig()\n\tw, _ := NewProducer(\"127.0.0.1:4150\", config)\n\tw.SetLogger(nullLogger, LogLevelInfo)\n\tdefer w.Stop()\n\n\tresponseChan := make(chan *ProducerTransaction, msgCount)\n\tfor i := 0; i < msgCount; i++ {\n\t\terr := w.PublishAsync(topicName, []byte(\"publish_test_case\"), responseChan, \"test\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(err.Error())\n\t\t}\n\t}\n\n\tfor i := 0; i < msgCount; i++ {\n\t\ttrans := <-responseChan\n\t\tif trans.Error != nil {\n\t\t\tt.Fatalf(trans.Error.Error())\n\t\t}\n\t\tif trans.Args[0].(string) != \"test\" {\n\t\t\tt.Fatalf(`proxied arg \"%s\" != \"test\"`, trans.Args[0].(string))\n\t\t}\n\t}\n\n\terr := w.Publish(topicName, []byte(\"bad_test_case\"))\n\tif err != nil {\n\t\tt.Fatalf(\"error %s\", err)\n\t}\n\n\treadMessages(topicName, t, msgCount)\n}\n\nfunc TestProducerMultiPublishAsync(t *testing.T) {\n\ttopicName := \"multi_publish\" + strconv.Itoa(int(time.Now().Unix()))\n\tmsgCount := 10\n\n\tconfig := NewConfig()\n\tw, _ := NewProducer(\"127.0.0.1:4150\", config)\n\tw.SetLogger(nullLogger, LogLevelInfo)\n\tdefer w.Stop()\n\n\tvar testData [][]byte\n\tfor i := 0; i < msgCount; i++ {\n\t\ttestData = append(testData, []byte(\"multipublish_test_case\"))\n\t}\n\n\tresponseChan := make(chan *ProducerTransaction)\n\terr := w.MultiPublishAsync(topicName, testData, responseChan, \"test0\", 1)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\ttrans := <-responseChan\n\tif trans.Error != nil {\n\t\tt.Fatalf(trans.Error.Error())\n\t}\n\tif trans.Args[0].(string) != \"test0\" {\n\t\tt.Fatalf(`proxied arg \"%s\" != \"test0\"`, trans.Args[0].(string))\n\t}\n\tif trans.Args[1].(int) != 1 {\n\t\tt.Fatalf(`proxied arg %d != 1`, trans.Args[1].(int))\n\t}\n\n\terr = w.Publish(topicName, []byte(\"bad_test_case\"))\n\tif err != nil {\n\t\tt.Fatalf(\"error %s\", err)\n\t}\n\n\treadMessages(topicName, t, msgCount)\n}\n\nfunc TestProducerHeartbeat(t *testing.T) {\n\ttopicName := \"heartbeat\" + strconv.Itoa(int(time.Now().Unix()))\n\n\tconfig := NewConfig()\n\tconfig.HeartbeatInterval = 100 * time.Millisecond\n\tw, _ := NewProducer(\"127.0.0.1:4150\", config)\n\tw.SetLogger(nullLogger, LogLevelInfo)\n\tdefer w.Stop()\n\n\terr := w.Publish(topicName, []byte(\"publish_test_case\"))\n\tif err == nil {\n\t\tt.Fatalf(\"error should not be nil\")\n\t}\n\tif identifyError, ok := err.(ErrIdentify); !ok ||\n\t\tidentifyError.Reason != \"E_BAD_BODY IDENTIFY heartbeat interval (100) is invalid\" {\n\t\tt.Fatalf(\"wrong error - %s\", err)\n\t}\n\n\tconfig = NewConfig()\n\tconfig.HeartbeatInterval = 1000 * time.Millisecond\n\tw, _ = NewProducer(\"127.0.0.1:4150\", config)\n\tw.SetLogger(nullLogger, LogLevelInfo)\n\tdefer w.Stop()\n\n\terr = w.Publish(topicName, []byte(\"publish_test_case\"))\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\ttime.Sleep(1100 * time.Millisecond)\n\n\tmsgCount := 10\n\tfor i := 0; i < msgCount; i++ {\n\t\terr := w.Publish(topicName, []byte(\"publish_test_case\"))\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"error %s\", err)\n\t\t}\n\t}\n\n\terr = w.Publish(topicName, []byte(\"bad_test_case\"))\n\tif err != nil {\n\t\tt.Fatalf(\"error %s\", err)\n\t}\n\n\treadMessages(topicName, t, msgCount+1)\n}\n\nfunc TestProducerHTTPConnectionFails(t *testing.T) {\n\tconfig := NewConfig()\n\tladdr := \"127.0.0.1\"\n\n\tconfig.LocalAddr, _ = net.ResolveTCPAddr(\"tcp\", laddr+\":0\")\n\tconfig.MaxMsgSize = 1048576\n\n\tw, _ := NewProducer(\"127.0.0.1:4151\", config)\n\tw.SetLogger(nullLogger, LogLevelInfo)\n\n\terr := w.Publish(\"write_test\", []byte(\"test\"))\n\tif err == nil {\n\t\tt.Fatal(\"should fail connecting to HTTP endpoint\", err)\n\t}\n\n\tif !strings.Contains(err.Error(), \"unexpected HTTP response\") {\n\t\tt.Fatalf(\"should detect unexpected HTTP response, but got err: %s\", err)\n\t}\n\n\tw.Stop()\n}\n\nfunc readMessages(topicName string, t *testing.T, msgCount int) {\n\tconfig := NewConfig()\n\tconfig.DefaultRequeueDelay = 0\n\tconfig.MaxBackoffDuration = 50 * time.Millisecond\n\tq, _ := NewConsumer(topicName, \"ch\", config)\n\tq.SetLogger(nullLogger, LogLevelInfo)\n\n\th := &ConsumerHandler{\n\t\tt: t,\n\t\tq: q,\n\t}\n\tq.AddHandler(h)\n\n\terr := q.ConnectToNSQD(\"127.0.0.1:4150\")\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\t<-q.StopChan\n\n\tif h.messagesGood != msgCount {\n\t\tt.Fatalf(\"end of test. should have handled a diff number of messages %d != %d\", h.messagesGood, msgCount)\n\t}\n\n\tif h.messagesFailed != 1 {\n\t\tt.Fatal(\"failed message not done\")\n\t}\n}\n\ntype mockProducerConn struct {\n\tdelegate ConnDelegate\n\tcloseCh  chan struct{}\n\tpubCh    chan struct{}\n}\n\nfunc newMockProducerConn(delegate ConnDelegate) producerConn {\n\tm := &mockProducerConn{\n\t\tdelegate: delegate,\n\t\tcloseCh:  make(chan struct{}),\n\t\tpubCh:    make(chan struct{}, 4),\n\t}\n\tgo m.router()\n\treturn m\n}\n\nfunc (m *mockProducerConn) String() string {\n\treturn \"127.0.0.1:0\"\n}\n\nfunc (m *mockProducerConn) SetLogger(logger logger, level LogLevel, prefix string) {}\n\nfunc (m *mockProducerConn) SetLoggerLevel(lvl LogLevel) {}\n\nfunc (m *mockProducerConn) SetLoggerForLevel(logger logger, level LogLevel, format string) {}\n\nfunc (m *mockProducerConn) Connect() (*IdentifyResponse, error) {\n\treturn &IdentifyResponse{}, nil\n}\n\nfunc (m *mockProducerConn) Close() error {\n\tclose(m.closeCh)\n\treturn nil\n}\n\nfunc (m *mockProducerConn) WriteCommand(cmd *Command) error {\n\tif bytes.Equal(cmd.Name, []byte(\"PUB\")) {\n\t\tm.pubCh <- struct{}{}\n\t}\n\treturn nil\n}\n\nfunc (m *mockProducerConn) router() {\n\tfor {\n\t\tselect {\n\t\tcase <-m.closeCh:\n\t\t\tgoto exit\n\t\tcase <-m.pubCh:\n\t\t\tm.delegate.OnResponse(nil, framedResponse(FrameTypeResponse, []byte(\"OK\")))\n\t\t}\n\t}\nexit:\n}\n\nfunc BenchmarkProducer(b *testing.B) {\n\tb.StopTimer()\n\tbody := make([]byte, 512)\n\n\tconfig := NewConfig()\n\tp, _ := NewProducer(\"127.0.0.1:0\", config)\n\n\tp.conn = newMockProducerConn(&producerConnDelegate{p})\n\tatomic.StoreInt32(&p.state, StateConnected)\n\tp.closeChan = make(chan int)\n\tgo p.router()\n\n\tstartCh := make(chan struct{})\n\tvar wg sync.WaitGroup\n\tparallel := runtime.GOMAXPROCS(0)\n\n\tfor j := 0; j < parallel; j++ {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\t<-startCh\n\t\t\tfor i := 0; i < b.N/parallel; i++ {\n\t\t\t\tp.Publish(\"test\", body)\n\t\t\t}\n\t\t\twg.Done()\n\t\t}()\n\t}\n\n\tb.StartTimer()\n\tclose(startCh)\n\twg.Wait()\n}\n"
        },
        {
          "name": "protocol.go",
          "type": "blob",
          "size": 2.7998046875,
          "content": "package nsq\n\nimport (\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"regexp\"\n)\n\n// MagicV1 is the initial identifier sent when connecting for V1 clients\nvar MagicV1 = []byte(\"  V1\")\n\n// MagicV2 is the initial identifier sent when connecting for V2 clients\nvar MagicV2 = []byte(\"  V2\")\n\n// frame types\nconst (\n\tFrameTypeResponse int32 = 0\n\tFrameTypeError    int32 = 1\n\tFrameTypeMessage  int32 = 2\n)\n\n// Used to detect if an unexpected HTTP response is read\nconst httpResponseMsgSize = 1213486160\n\nvar validTopicChannelNameRegex = regexp.MustCompile(`^[\\.a-zA-Z0-9_-]+(#ephemeral)?$`)\n\n// IsValidTopicName checks a topic name for correctness\nfunc IsValidTopicName(name string) bool {\n\treturn isValidName(name)\n}\n\n// IsValidChannelName checks a channel name for correctness\nfunc IsValidChannelName(name string) bool {\n\treturn isValidName(name)\n}\n\nfunc isValidName(name string) bool {\n\tif len(name) > 64 || len(name) < 1 {\n\t\treturn false\n\t}\n\treturn validTopicChannelNameRegex.MatchString(name)\n}\n\n// ReadResponse is a client-side utility function to read from the supplied Reader\n// according to the NSQ protocol spec:\n//\n//\t[x][x][x][x][x][x][x][x]...\n//\t|  (int32) || (binary)\n//\t|  4-byte  || N-byte\n//\t------------------------...\n//\t    size       data\nfunc ReadResponse(r io.Reader, maxMsgSize int32) ([]byte, error) {\n\tvar msgSize int32\n\n\t// message size\n\terr := binary.Read(r, binary.BigEndian, &msgSize)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif msgSize < 0 {\n\t\treturn nil, fmt.Errorf(\"response msg size is negative: %v\", msgSize)\n\t}\n\n\tif maxMsgSize > 0 && msgSize > maxMsgSize {\n\t\tif msgSize == httpResponseMsgSize {\n\t\t\treturn nil, fmt.Errorf(\"unexpected HTTP response, a nsqd TCP endpoint is required\")\n\t\t}\n\t\treturn nil, fmt.Errorf(\"response msg size %v exceeds configured maximum (%v)\", msgSize, maxMsgSize)\n\t}\n\n\t// message binary data\n\tbuf := make([]byte, msgSize)\n\t_, err = io.ReadFull(r, buf)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn buf, nil\n}\n\n// UnpackResponse is a client-side utility function that unpacks serialized data\n// according to NSQ protocol spec:\n//\n//\t[x][x][x][x][x][x][x][x]...\n//\t|  (int32) || (binary)\n//\t|  4-byte  || N-byte\n//\t------------------------...\n//\t  frame ID     data\n//\n// Returns a triplicate of: frame type, data ([]byte), error\nfunc UnpackResponse(response []byte) (int32, []byte, error) {\n\tif len(response) < 4 {\n\t\treturn -1, nil, errors.New(\"length of response is too small\")\n\t}\n\n\treturn int32(binary.BigEndian.Uint32(response)), response[4:], nil\n}\n\n// ReadUnpackedResponse reads and parses data from the underlying\n// TCP connection according to the NSQ TCP protocol spec and\n// returns the frameType, data or error\nfunc ReadUnpackedResponse(r io.Reader, maxMsgSize int32) (int32, []byte, error) {\n\tresp, err := ReadResponse(r, maxMsgSize)\n\tif err != nil {\n\t\treturn -1, nil, err\n\t}\n\treturn UnpackResponse(resp)\n}\n"
        },
        {
          "name": "states.go",
          "type": "blob",
          "size": 0.083984375,
          "content": "package nsq\n\n// states\nconst (\n\tStateInit = iota\n\tStateDisconnected\n\tStateConnected\n)\n"
        },
        {
          "name": "test.sh",
          "type": "blob",
          "size": 1.12109375,
          "content": "#!/bin/bash\nset -e\n\n# a helper script to run tests\n\nif ! which nsqd >/dev/null; then\n    echo \"missing nsqd binary\" && exit 1\nfi\n\nif ! which nsqlookupd >/dev/null; then\n    echo \"missing nsqlookupd binary\" && exit 1\nfi\n\n# run nsqlookupd\nLOOKUP_LOGFILE=$(mktemp -t nsqlookupd.XXXXXXX)\necho \"starting nsqlookupd\"\necho \"  logging to $LOOKUP_LOGFILE\"\nnsqlookupd >$LOOKUP_LOGFILE 2>&1 &\nLOOKUPD_PID=$!\n\n# run nsqd configured to use our lookupd above\nrm -f *.dat\nNSQD_LOGFILE=$(mktemp -t nsqlookupd.XXXXXXX)\necho \"starting nsqd --data-path=/tmp --lookupd-tcp-address=127.0.0.1:4160 --tls-cert=./test/server.pem --tls-key=./test/server.key --tls-root-ca-file=./test/ca.pem\"\necho \"  logging to $NSQD_LOGFILE\"\nnsqd --data-path=/tmp --lookupd-tcp-address=127.0.0.1:4160 --tls-cert=./test/server.pem --tls-key=./test/server.key --tls-root-ca-file=./test/ca.pem >$NSQD_LOGFILE 2>&1 &\nNSQD_PID=$!\n\nsleep 0.3\n\ncleanup() {\n    echo \"killing nsqd PID $NSQD_PID\"\n    kill -s TERM $NSQD_PID || cat $NSQD_LOGFILE\n    echo \"killing nsqlookupd PID $LOOKUPD_PID\"\n    kill -s TERM $LOOKUPD_PID || cat $LOOKUP_LOGFILE\n}\ntrap cleanup INT TERM EXIT\n\ngo test -v -timeout 60s\n"
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "version.go",
          "type": "blob",
          "size": 0.046875,
          "content": "package nsq\n\n// VERSION\nconst VERSION = \"1.1.0\"\n"
        }
      ]
    }
  ]
}