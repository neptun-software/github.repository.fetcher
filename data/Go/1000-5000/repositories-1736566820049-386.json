{
  "metadata": {
    "timestamp": 1736566820049,
    "page": 386,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjM5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "rcrowley/go-metrics",
      "stars": 3473,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.1318359375,
          "content": "*.[68]\n*.a\n*.out\n*.swp\n_obj\n_testmain.go\ncmd/metrics-bench/metrics-bench\ncmd/metrics-example/metrics-example\ncmd/never-read/never-read\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.3203125,
          "content": "language: go\n\ngo:\n    - \"1.3\"\n    - \"1.4\"\n    - \"1.5\"\n    - \"1.6\"\n    - \"1.7\"\n    - \"1.8\"\n    - \"1.9\"\n    - \"1.10\"\n    - \"1.11\"\n    - \"1.12\"\n    - \"1.13\"\n    - \"1.14\"\n    - \"1.15\"\n\nscript:\n    - ./validate.sh\n\n# this should give us faster builds according to \n# http://docs.travis-ci.com/user/migrating-from-legacy/\nsudo: false\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.48046875,
          "content": "Copyright 2012 Richard Crowley. All rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n    1.  Redistributions of source code must retain the above copyright\n        notice, this list of conditions and the following disclaimer.\n\n    2.  Redistributions in binary form must reproduce the above\n        copyright notice, this list of conditions and the following\n        disclaimer in the documentation and/or other materials provided\n        with the distribution.\n\nTHIS SOFTWARE IS PROVIDED BY RICHARD CROWLEY ``AS IS'' AND ANY EXPRESS\nOR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL RICHARD CROWLEY OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\nCONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\nSUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\nINTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\nCONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF\nTHE POSSIBILITY OF SUCH DAMAGE.\n\nThe views and conclusions contained in the software and documentation\nare those of the authors and should not be interpreted as representing\nofficial policies, either expressed or implied, of Richard Crowley.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 4.7041015625,
          "content": "go-metrics\n==========\n\n![travis build status](https://travis-ci.org/rcrowley/go-metrics.svg?branch=master)\n\nGo port of Coda Hale's Metrics library: <https://github.com/dropwizard/metrics>.\n\nDocumentation: <http://godoc.org/github.com/rcrowley/go-metrics>.\n\nUsage\n-----\n\nCreate and update metrics:\n\n```go\nc := metrics.NewCounter()\nmetrics.Register(\"foo\", c)\nc.Inc(47)\n\ng := metrics.NewGauge()\nmetrics.Register(\"bar\", g)\ng.Update(47)\n\nr := NewRegistry()\ng := metrics.NewRegisteredFunctionalGauge(\"cache-evictions\", r, func() int64 { return cache.getEvictionsCount() })\n\ns := metrics.NewExpDecaySample(1028, 0.015) // or metrics.NewUniformSample(1028)\nh := metrics.NewHistogram(s)\nmetrics.Register(\"baz\", h)\nh.Update(47)\n\nm := metrics.NewMeter()\nmetrics.Register(\"quux\", m)\nm.Mark(47)\n\nt := metrics.NewTimer()\nmetrics.Register(\"bang\", t)\nt.Time(func() {})\nt.Update(47)\n```\n\nRegister() is not threadsafe. For threadsafe metric registration use\nGetOrRegister:\n\n```go\nt := metrics.GetOrRegisterTimer(\"account.create.latency\", nil)\nt.Time(func() {})\nt.Update(47)\n```\n\n**NOTE:** Be sure to unregister short-lived meters and timers otherwise they will\nleak memory:\n\n```go\n// Will call Stop() on the Meter to allow for garbage collection\nmetrics.Unregister(\"quux\")\n// Or similarly for a Timer that embeds a Meter\nmetrics.Unregister(\"bang\")\n```\n\nPeriodically log every metric in human-readable form to standard error:\n\n```go\ngo metrics.Log(metrics.DefaultRegistry, 5 * time.Second, log.New(os.Stderr, \"metrics: \", log.Lmicroseconds))\n```\n\nPeriodically log every metric in slightly-more-parseable form to syslog:\n\n```go\nw, _ := syslog.Dial(\"unixgram\", \"/dev/log\", syslog.LOG_INFO, \"metrics\")\ngo metrics.Syslog(metrics.DefaultRegistry, 60e9, w)\n```\n\nPeriodically emit every metric to Graphite using the [Graphite client](https://github.com/cyberdelia/go-metrics-graphite):\n\n```go\n\nimport \"github.com/cyberdelia/go-metrics-graphite\"\n\naddr, _ := net.ResolveTCPAddr(\"tcp\", \"127.0.0.1:2003\")\ngo graphite.Graphite(metrics.DefaultRegistry, 10e9, \"metrics\", addr)\n```\n\nPeriodically emit every metric into InfluxDB:\n\n**NOTE:** this has been pulled out of the library due to constant fluctuations\nin the InfluxDB API. In fact, all client libraries are on their way out. see\nissues [#121](https://github.com/rcrowley/go-metrics/issues/121) and\n[#124](https://github.com/rcrowley/go-metrics/issues/124) for progress and details.\n\n```go\nimport \"github.com/vrischmann/go-metrics-influxdb\"\n\ngo influxdb.InfluxDB(metrics.DefaultRegistry,\n  10e9, \n  \"127.0.0.1:8086\", \n  \"database-name\", \n  \"username\", \n  \"password\"\n)\n```\n\nPeriodically upload every metric to Librato using the [Librato client](https://github.com/mihasya/go-metrics-librato):\n\n**Note**: the client included with this repository under the `librato` package\nhas been deprecated and moved to the repository linked above.\n\n```go\nimport \"github.com/mihasya/go-metrics-librato\"\n\ngo librato.Librato(metrics.DefaultRegistry,\n    10e9,                  // interval\n    \"example@example.com\", // account owner email address\n    \"token\",               // Librato API token\n    \"hostname\",            // source\n    []float64{0.95},       // percentiles to send\n    time.Millisecond,      // time unit\n)\n```\n\nPeriodically emit every metric to StatHat:\n\n```go\nimport \"github.com/rcrowley/go-metrics/stathat\"\n\ngo stathat.Stathat(metrics.DefaultRegistry, 10e9, \"example@example.com\")\n```\n\nMaintain all metrics along with expvars at `/debug/metrics`:\n\nThis uses the same mechanism as [the official expvar](http://golang.org/pkg/expvar/)\nbut exposed under `/debug/metrics`, which shows a json representation of all your usual expvars\nas well as all your go-metrics.\n\n\n```go\nimport \"github.com/rcrowley/go-metrics/exp\"\n\nexp.Exp(metrics.DefaultRegistry)\n```\n\nInstallation\n------------\n\n```sh\ngo get github.com/rcrowley/go-metrics\n```\n\nStatHat support additionally requires their Go client:\n\n```sh\ngo get github.com/stathat/go\n```\n\nPublishing Metrics\n------------------\n\nClients are available for the following destinations:\n\n* AppOptics - https://github.com/ysamlan/go-metrics-appoptics\n* Librato - https://github.com/mihasya/go-metrics-librato\n* Graphite - https://github.com/cyberdelia/go-metrics-graphite\n* InfluxDB - https://github.com/vrischmann/go-metrics-influxdb\n* Ganglia - https://github.com/appscode/metlia\n* Prometheus - https://github.com/deathowl/go-metrics-prometheus\n* DataDog - https://github.com/syntaqx/go-metrics-datadog\n* SignalFX - https://github.com/pascallouisperez/go-metrics-signalfx\n* Honeycomb - https://github.com/getspine/go-metrics-honeycomb\n* Wavefront - https://github.com/wavefrontHQ/go-metrics-wavefront\n* Open-Falcon - https://github.com/g4zhuj/go-metrics-falcon\n* AWS CloudWatch - [https://github.com/savaki/cloudmetrics](https://github.com/savaki/cloudmetrics)\n"
        },
        {
          "name": "cmd",
          "type": "tree",
          "content": null
        },
        {
          "name": "counter.go",
          "type": "blob",
          "size": 2.537109375,
          "content": "package metrics\n\nimport \"sync/atomic\"\n\n// Counters hold an int64 value that can be incremented and decremented.\ntype Counter interface {\n\tClear()\n\tCount() int64\n\tDec(int64)\n\tInc(int64)\n\tSnapshot() Counter\n}\n\n// GetOrRegisterCounter returns an existing Counter or constructs and registers\n// a new StandardCounter.\nfunc GetOrRegisterCounter(name string, r Registry) Counter {\n\tif nil == r {\n\t\tr = DefaultRegistry\n\t}\n\treturn r.GetOrRegister(name, NewCounter).(Counter)\n}\n\n// NewCounter constructs a new StandardCounter.\nfunc NewCounter() Counter {\n\tif UseNilMetrics {\n\t\treturn NilCounter{}\n\t}\n\treturn &StandardCounter{0}\n}\n\n// NewRegisteredCounter constructs and registers a new StandardCounter.\nfunc NewRegisteredCounter(name string, r Registry) Counter {\n\tc := NewCounter()\n\tif nil == r {\n\t\tr = DefaultRegistry\n\t}\n\tr.Register(name, c)\n\treturn c\n}\n\n// CounterSnapshot is a read-only copy of another Counter.\ntype CounterSnapshot int64\n\n// Clear panics.\nfunc (CounterSnapshot) Clear() {\n\tpanic(\"Clear called on a CounterSnapshot\")\n}\n\n// Count returns the count at the time the snapshot was taken.\nfunc (c CounterSnapshot) Count() int64 { return int64(c) }\n\n// Dec panics.\nfunc (CounterSnapshot) Dec(int64) {\n\tpanic(\"Dec called on a CounterSnapshot\")\n}\n\n// Inc panics.\nfunc (CounterSnapshot) Inc(int64) {\n\tpanic(\"Inc called on a CounterSnapshot\")\n}\n\n// Snapshot returns the snapshot.\nfunc (c CounterSnapshot) Snapshot() Counter { return c }\n\n// NilCounter is a no-op Counter.\ntype NilCounter struct{}\n\n// Clear is a no-op.\nfunc (NilCounter) Clear() {}\n\n// Count is a no-op.\nfunc (NilCounter) Count() int64 { return 0 }\n\n// Dec is a no-op.\nfunc (NilCounter) Dec(i int64) {}\n\n// Inc is a no-op.\nfunc (NilCounter) Inc(i int64) {}\n\n// Snapshot is a no-op.\nfunc (NilCounter) Snapshot() Counter { return NilCounter{} }\n\n// StandardCounter is the standard implementation of a Counter and uses the\n// sync/atomic package to manage a single int64 value.\ntype StandardCounter struct {\n\tcount int64\n}\n\n// Clear sets the counter to zero.\nfunc (c *StandardCounter) Clear() {\n\tatomic.StoreInt64(&c.count, 0)\n}\n\n// Count returns the current count.\nfunc (c *StandardCounter) Count() int64 {\n\treturn atomic.LoadInt64(&c.count)\n}\n\n// Dec decrements the counter by the given amount.\nfunc (c *StandardCounter) Dec(i int64) {\n\tatomic.AddInt64(&c.count, -i)\n}\n\n// Inc increments the counter by the given amount.\nfunc (c *StandardCounter) Inc(i int64) {\n\tatomic.AddInt64(&c.count, i)\n}\n\n// Snapshot returns a read-only copy of the counter.\nfunc (c *StandardCounter) Snapshot() Counter {\n\treturn CounterSnapshot(c.Count())\n}\n"
        },
        {
          "name": "counter_test.go",
          "type": "blob",
          "size": 1.412109375,
          "content": "package metrics\n\nimport \"testing\"\n\nfunc BenchmarkCounter(b *testing.B) {\n\tc := NewCounter()\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tc.Inc(1)\n\t}\n}\n\nfunc TestCounterClear(t *testing.T) {\n\tc := NewCounter()\n\tc.Inc(1)\n\tc.Clear()\n\tif count := c.Count(); 0 != count {\n\t\tt.Errorf(\"c.Count(): 0 != %v\\n\", count)\n\t}\n}\n\nfunc TestCounterDec1(t *testing.T) {\n\tc := NewCounter()\n\tc.Dec(1)\n\tif count := c.Count(); -1 != count {\n\t\tt.Errorf(\"c.Count(): -1 != %v\\n\", count)\n\t}\n}\n\nfunc TestCounterDec2(t *testing.T) {\n\tc := NewCounter()\n\tc.Dec(2)\n\tif count := c.Count(); -2 != count {\n\t\tt.Errorf(\"c.Count(): -2 != %v\\n\", count)\n\t}\n}\n\nfunc TestCounterInc1(t *testing.T) {\n\tc := NewCounter()\n\tc.Inc(1)\n\tif count := c.Count(); 1 != count {\n\t\tt.Errorf(\"c.Count(): 1 != %v\\n\", count)\n\t}\n}\n\nfunc TestCounterInc2(t *testing.T) {\n\tc := NewCounter()\n\tc.Inc(2)\n\tif count := c.Count(); 2 != count {\n\t\tt.Errorf(\"c.Count(): 2 != %v\\n\", count)\n\t}\n}\n\nfunc TestCounterSnapshot(t *testing.T) {\n\tc := NewCounter()\n\tc.Inc(1)\n\tsnapshot := c.Snapshot()\n\tc.Inc(1)\n\tif count := snapshot.Count(); 1 != count {\n\t\tt.Errorf(\"c.Count(): 1 != %v\\n\", count)\n\t}\n}\n\nfunc TestCounterZero(t *testing.T) {\n\tc := NewCounter()\n\tif count := c.Count(); 0 != count {\n\t\tt.Errorf(\"c.Count(): 0 != %v\\n\", count)\n\t}\n}\n\nfunc TestGetOrRegisterCounter(t *testing.T) {\n\tr := NewRegistry()\n\tNewRegisteredCounter(\"foo\", r).Inc(47)\n\tif c := GetOrRegisterCounter(\"foo\", r); 47 != c.Count() {\n\t\tt.Fatal(c)\n\t}\n}\n"
        },
        {
          "name": "debug.go",
          "type": "blob",
          "size": 2.6943359375,
          "content": "package metrics\n\nimport (\n\t\"runtime/debug\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar (\n\tdebugMetrics struct {\n\t\tGCStats struct {\n\t\t\tLastGC Gauge\n\t\t\tNumGC  Gauge\n\t\t\tPause  Histogram\n\t\t\t//PauseQuantiles Histogram\n\t\t\tPauseTotal Gauge\n\t\t}\n\t\tReadGCStats Timer\n\t}\n\tgcStats                  debug.GCStats\n\tregisterDebugMetricsOnce = sync.Once{}\n)\n\n// Capture new values for the Go garbage collector statistics exported in\n// debug.GCStats.  This is designed to be called as a goroutine.\nfunc CaptureDebugGCStats(r Registry, d time.Duration) {\n\tfor _ = range time.Tick(d) {\n\t\tCaptureDebugGCStatsOnce(r)\n\t}\n}\n\n// Capture new values for the Go garbage collector statistics exported in\n// debug.GCStats.  This is designed to be called in a background goroutine.\n// Giving a registry which has not been given to RegisterDebugGCStats will\n// panic.\n//\n// Be careful (but much less so) with this because debug.ReadGCStats calls\n// the C function runtime·lock(runtime·mheap) which, while not a stop-the-world\n// operation, isn't something you want to be doing all the time.\nfunc CaptureDebugGCStatsOnce(r Registry) {\n\tlastGC := gcStats.LastGC\n\tt := time.Now()\n\tdebug.ReadGCStats(&gcStats)\n\tdebugMetrics.ReadGCStats.UpdateSince(t)\n\n\tdebugMetrics.GCStats.LastGC.Update(int64(gcStats.LastGC.UnixNano()))\n\tdebugMetrics.GCStats.NumGC.Update(int64(gcStats.NumGC))\n\tif lastGC != gcStats.LastGC && 0 < len(gcStats.Pause) {\n\t\tdebugMetrics.GCStats.Pause.Update(int64(gcStats.Pause[0]))\n\t}\n\t//debugMetrics.GCStats.PauseQuantiles.Update(gcStats.PauseQuantiles)\n\tdebugMetrics.GCStats.PauseTotal.Update(int64(gcStats.PauseTotal))\n}\n\n// Register metrics for the Go garbage collector statistics exported in\n// debug.GCStats.  The metrics are named by their fully-qualified Go symbols,\n// i.e. debug.GCStats.PauseTotal.\nfunc RegisterDebugGCStats(r Registry) {\n\tregisterDebugMetricsOnce.Do(func() {\n\t\tdebugMetrics.GCStats.LastGC = NewGauge()\n\t\tdebugMetrics.GCStats.NumGC = NewGauge()\n\t\tdebugMetrics.GCStats.Pause = NewHistogram(NewExpDecaySample(1028, 0.015))\n\t\t//debugMetrics.GCStats.PauseQuantiles = NewHistogram(NewExpDecaySample(1028, 0.015))\n\t\tdebugMetrics.GCStats.PauseTotal = NewGauge()\n\t\tdebugMetrics.ReadGCStats = NewTimer()\n\n\t\tr.Register(\"debug.GCStats.LastGC\", debugMetrics.GCStats.LastGC)\n\t\tr.Register(\"debug.GCStats.NumGC\", debugMetrics.GCStats.NumGC)\n\t\tr.Register(\"debug.GCStats.Pause\", debugMetrics.GCStats.Pause)\n\t\t//r.Register(\"debug.GCStats.PauseQuantiles\", debugMetrics.GCStats.PauseQuantiles)\n\t\tr.Register(\"debug.GCStats.PauseTotal\", debugMetrics.GCStats.PauseTotal)\n\t\tr.Register(\"debug.ReadGCStats\", debugMetrics.ReadGCStats)\n\t})\n}\n\n// Allocate an initial slice for gcStats.Pause to avoid allocations during\n// normal operation.\nfunc init() {\n\tgcStats.Pause = make([]time.Duration, 11)\n}\n"
        },
        {
          "name": "debug_test.go",
          "type": "blob",
          "size": 1.353515625,
          "content": "package metrics\n\nimport (\n\t\"runtime\"\n\t\"runtime/debug\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc BenchmarkDebugGCStats(b *testing.B) {\n\tr := NewRegistry()\n\tRegisterDebugGCStats(r)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tCaptureDebugGCStatsOnce(r)\n\t}\n}\n\nfunc TestDebugGCStatsBlocking(t *testing.T) {\n\tif g := runtime.GOMAXPROCS(0); g < 2 {\n\t\tt.Skipf(\"skipping TestDebugGCMemStatsBlocking with GOMAXPROCS=%d\\n\", g)\n\t\treturn\n\t}\n\tch := make(chan int)\n\tgo testDebugGCStatsBlocking(ch)\n\tvar gcStats debug.GCStats\n\tt0 := time.Now()\n\tdebug.ReadGCStats(&gcStats)\n\tt1 := time.Now()\n\tt.Log(\"i++ during debug.ReadGCStats:\", <-ch)\n\tgo testDebugGCStatsBlocking(ch)\n\td := t1.Sub(t0)\n\tt.Log(d)\n\ttime.Sleep(d)\n\tt.Log(\"i++ during time.Sleep:\", <-ch)\n}\n\nfunc testDebugGCStatsBlocking(ch chan int) {\n\ti := 0\n\tfor {\n\t\tselect {\n\t\tcase ch <- i:\n\t\t\treturn\n\t\tdefault:\n\t\t\ti++\n\t\t}\n\t}\n}\n\nfunc TestDebugGCStatsDoubleRegister(t *testing.T) {\n\tr := NewRegistry()\n\tRegisterDebugGCStats(r)\n\tvar storedGauge = (r.Get(\"debug.GCStats.LastGC\")).(Gauge)\n\n\truntime.GC()\n\tCaptureDebugGCStatsOnce(r)\n\n\tfirstGC := storedGauge.Value()\n\tif 0 == firstGC {\n\t\tt.Errorf(\"firstGC got %d, expected > 0\", firstGC)\n\t}\n\n\ttime.Sleep(time.Millisecond)\n\n\tRegisterDebugGCStats(r)\n\truntime.GC()\n\tCaptureDebugGCStatsOnce(r)\n\tif lastGC := storedGauge.Value(); firstGC == lastGC {\n\t\tt.Errorf(\"lastGC got %d, expected a higher timestamp value\", lastGC)\n\t}\n}\n"
        },
        {
          "name": "ewma.go",
          "type": "blob",
          "size": 3.8310546875,
          "content": "package metrics\n\nimport (\n\t\"math\"\n\t\"sync\"\n\t\"sync/atomic\"\n)\n\n// EWMAs continuously calculate an exponentially-weighted moving average\n// based on an outside source of clock ticks.\ntype EWMA interface {\n\tRate() float64\n\tSnapshot() EWMA\n\tTick()\n\tUpdate(int64)\n}\n\n// NewEWMA constructs a new EWMA with the given alpha.\nfunc NewEWMA(alpha float64) EWMA {\n\tif UseNilMetrics {\n\t\treturn NilEWMA{}\n\t}\n\treturn &StandardEWMA{alpha: alpha}\n}\n\n// NewEWMA1 constructs a new EWMA for a one-minute moving average.\nfunc NewEWMA1() EWMA {\n\treturn NewEWMA(1 - math.Exp(-5.0/60.0/1))\n}\n\n// NewEWMA5 constructs a new EWMA for a five-minute moving average.\nfunc NewEWMA5() EWMA {\n\treturn NewEWMA(1 - math.Exp(-5.0/60.0/5))\n}\n\n// NewEWMA15 constructs a new EWMA for a fifteen-minute moving average.\nfunc NewEWMA15() EWMA {\n\treturn NewEWMA(1 - math.Exp(-5.0/60.0/15))\n}\n\n// EWMASnapshot is a read-only copy of another EWMA.\ntype EWMASnapshot float64\n\n// Rate returns the rate of events per second at the time the snapshot was\n// taken.\nfunc (a EWMASnapshot) Rate() float64 { return float64(a) }\n\n// Snapshot returns the snapshot.\nfunc (a EWMASnapshot) Snapshot() EWMA { return a }\n\n// Tick panics.\nfunc (EWMASnapshot) Tick() {\n\tpanic(\"Tick called on an EWMASnapshot\")\n}\n\n// Update panics.\nfunc (EWMASnapshot) Update(int64) {\n\tpanic(\"Update called on an EWMASnapshot\")\n}\n\n// NilEWMA is a no-op EWMA.\ntype NilEWMA struct{}\n\n// Rate is a no-op.\nfunc (NilEWMA) Rate() float64 { return 0.0 }\n\n// Snapshot is a no-op.\nfunc (NilEWMA) Snapshot() EWMA { return NilEWMA{} }\n\n// Tick is a no-op.\nfunc (NilEWMA) Tick() {}\n\n// Update is a no-op.\nfunc (NilEWMA) Update(n int64) {}\n\n// StandardEWMA is the standard implementation of an EWMA and tracks the number\n// of uncounted events and processes them on each tick.  It uses the\n// sync/atomic package to manage uncounted events.\ntype StandardEWMA struct {\n\tuncounted int64 // /!\\ this should be the first member to ensure 64-bit alignment\n\talpha     float64\n\trate      uint64\n\tinit      uint32\n\tmutex     sync.Mutex\n}\n\n// Rate returns the moving average rate of events per second.\nfunc (a *StandardEWMA) Rate() float64 {\n\tcurrentRate := math.Float64frombits(atomic.LoadUint64(&a.rate)) * float64(1e9)\n\treturn currentRate\n}\n\n// Snapshot returns a read-only copy of the EWMA.\nfunc (a *StandardEWMA) Snapshot() EWMA {\n\treturn EWMASnapshot(a.Rate())\n}\n\n// Tick ticks the clock to update the moving average.  It assumes it is called\n// every five seconds.\nfunc (a *StandardEWMA) Tick() {\n\t// Optimization to avoid mutex locking in the hot-path.\n\tif atomic.LoadUint32(&a.init) == 1 {\n\t\ta.updateRate(a.fetchInstantRate())\n\t} else {\n\t\t// Slow-path: this is only needed on the first Tick() and preserves transactional updating\n\t\t// of init and rate in the else block. The first conditional is needed below because\n\t\t// a different thread could have set a.init = 1 between the time of the first atomic load and when\n\t\t// the lock was acquired.\n\t\ta.mutex.Lock()\n\t\tif atomic.LoadUint32(&a.init) == 1 {\n\t\t\t// The fetchInstantRate() uses atomic loading, which is unecessary in this critical section\n\t\t\t// but again, this section is only invoked on the first successful Tick() operation.\n\t\t\ta.updateRate(a.fetchInstantRate())\n\t\t} else {\n\t\t\tatomic.StoreUint32(&a.init, 1)\n\t\t\tatomic.StoreUint64(&a.rate, math.Float64bits(a.fetchInstantRate()))\n\t\t}\n\t\ta.mutex.Unlock()\n\t}\n}\n\nfunc (a *StandardEWMA) fetchInstantRate() float64 {\n\tcount := atomic.LoadInt64(&a.uncounted)\n\tatomic.AddInt64(&a.uncounted, -count)\n\tinstantRate := float64(count) / float64(5e9)\n\treturn instantRate\n}\n\nfunc (a *StandardEWMA) updateRate(instantRate float64) {\n\tcurrentRate := math.Float64frombits(atomic.LoadUint64(&a.rate))\n\tcurrentRate += a.alpha * (instantRate - currentRate)\n\tatomic.StoreUint64(&a.rate, math.Float64bits(currentRate))\n}\n\n// Update adds n uncounted events.\nfunc (a *StandardEWMA) Update(n int64) {\n\tatomic.AddInt64(&a.uncounted, n)\n}\n"
        },
        {
          "name": "ewma_test.go",
          "type": "blob",
          "size": 7.4423828125,
          "content": "package metrics\n\nimport (\n\t\"math/rand\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc BenchmarkEWMA(b *testing.B) {\n\ta := NewEWMA1()\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\ta.Update(1)\n\t\ta.Tick()\n\t}\n}\n\nfunc BenchmarkEWMAParallel(b *testing.B) {\n\ta := NewEWMA1()\n\tb.ResetTimer()\n\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tfor pb.Next() {\n\t\t\ta.Update(1)\n\t\t\ta.Tick()\n\t\t}\n\t})\n}\n\n// exercise race detector\nfunc TestEWMAConcurrency(t *testing.T) {\n\trand.Seed(time.Now().Unix())\n\ta := NewEWMA1()\n\twg := &sync.WaitGroup{}\n\treps := 100\n\tfor i := 0; i < reps; i++ {\n\t\twg.Add(1)\n\t\tgo func(ewma EWMA, wg *sync.WaitGroup) {\n\t\t\ta.Update(rand.Int63())\n\t\t\twg.Done()\n\t\t}(a, wg)\n\t}\n\twg.Wait()\n}\n\nfunc TestEWMA1(t *testing.T) {\n\ta := NewEWMA1()\n\ta.Update(3)\n\ta.Tick()\n\tif rate := a.Rate(); 0.6 != rate {\n\t\tt.Errorf(\"initial a.Rate(): 0.6 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.22072766470286553 != rate {\n\t\tt.Errorf(\"1 minute a.Rate(): 0.22072766470286553 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.08120116994196772 != rate {\n\t\tt.Errorf(\"2 minute a.Rate(): 0.08120116994196772 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.029872241020718428 != rate {\n\t\tt.Errorf(\"3 minute a.Rate(): 0.029872241020718428 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.01098938333324054 != rate {\n\t\tt.Errorf(\"4 minute a.Rate(): 0.01098938333324054 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.004042768199451294 != rate {\n\t\tt.Errorf(\"5 minute a.Rate(): 0.004042768199451294 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.0014872513059998212 != rate {\n\t\tt.Errorf(\"6 minute a.Rate(): 0.0014872513059998212 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.0005471291793327122 != rate {\n\t\tt.Errorf(\"7 minute a.Rate(): 0.0005471291793327122 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.00020127757674150815 != rate {\n\t\tt.Errorf(\"8 minute a.Rate(): 0.00020127757674150815 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 7.404588245200814e-05 != rate {\n\t\tt.Errorf(\"9 minute a.Rate(): 7.404588245200814e-05 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 2.7239957857491083e-05 != rate {\n\t\tt.Errorf(\"10 minute a.Rate(): 2.7239957857491083e-05 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 1.0021020474147462e-05 != rate {\n\t\tt.Errorf(\"11 minute a.Rate(): 1.0021020474147462e-05 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 3.6865274119969525e-06 != rate {\n\t\tt.Errorf(\"12 minute a.Rate(): 3.6865274119969525e-06 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 1.3561976441886433e-06 != rate {\n\t\tt.Errorf(\"13 minute a.Rate(): 1.3561976441886433e-06 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 4.989172314621449e-07 != rate {\n\t\tt.Errorf(\"14 minute a.Rate(): 4.989172314621449e-07 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 1.8354139230109722e-07 != rate {\n\t\tt.Errorf(\"15 minute a.Rate(): 1.8354139230109722e-07 != %v\\n\", rate)\n\t}\n}\n\nfunc TestEWMA5(t *testing.T) {\n\ta := NewEWMA5()\n\ta.Update(3)\n\ta.Tick()\n\tif rate := a.Rate(); 0.6 != rate {\n\t\tt.Errorf(\"initial a.Rate(): 0.6 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.49123845184678905 != rate {\n\t\tt.Errorf(\"1 minute a.Rate(): 0.49123845184678905 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.4021920276213837 != rate {\n\t\tt.Errorf(\"2 minute a.Rate(): 0.4021920276213837 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.32928698165641596 != rate {\n\t\tt.Errorf(\"3 minute a.Rate(): 0.32928698165641596 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.269597378470333 != rate {\n\t\tt.Errorf(\"4 minute a.Rate(): 0.269597378470333 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.2207276647028654 != rate {\n\t\tt.Errorf(\"5 minute a.Rate(): 0.2207276647028654 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.18071652714732128 != rate {\n\t\tt.Errorf(\"6 minute a.Rate(): 0.18071652714732128 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.14795817836496392 != rate {\n\t\tt.Errorf(\"7 minute a.Rate(): 0.14795817836496392 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.12113791079679326 != rate {\n\t\tt.Errorf(\"8 minute a.Rate(): 0.12113791079679326 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.09917933293295193 != rate {\n\t\tt.Errorf(\"9 minute a.Rate(): 0.09917933293295193 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.08120116994196763 != rate {\n\t\tt.Errorf(\"10 minute a.Rate(): 0.08120116994196763 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.06648189501740036 != rate {\n\t\tt.Errorf(\"11 minute a.Rate(): 0.06648189501740036 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.05443077197364752 != rate {\n\t\tt.Errorf(\"12 minute a.Rate(): 0.05443077197364752 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.04456414692860035 != rate {\n\t\tt.Errorf(\"13 minute a.Rate(): 0.04456414692860035 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.03648603757513079 != rate {\n\t\tt.Errorf(\"14 minute a.Rate(): 0.03648603757513079 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.0298722410207183831020718428 != rate {\n\t\tt.Errorf(\"15 minute a.Rate(): 0.0298722410207183831020718428 != %v\\n\", rate)\n\t}\n}\n\nfunc TestEWMA15(t *testing.T) {\n\ta := NewEWMA15()\n\ta.Update(3)\n\ta.Tick()\n\tif rate := a.Rate(); 0.6 != rate {\n\t\tt.Errorf(\"initial a.Rate(): 0.6 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.5613041910189706 != rate {\n\t\tt.Errorf(\"1 minute a.Rate(): 0.5613041910189706 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.5251039914257684 != rate {\n\t\tt.Errorf(\"2 minute a.Rate(): 0.5251039914257684 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.4912384518467888184678905 != rate {\n\t\tt.Errorf(\"3 minute a.Rate(): 0.4912384518467888184678905 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.459557003018789 != rate {\n\t\tt.Errorf(\"4 minute a.Rate(): 0.459557003018789 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.4299187863442732 != rate {\n\t\tt.Errorf(\"5 minute a.Rate(): 0.4299187863442732 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.4021920276213831 != rate {\n\t\tt.Errorf(\"6 minute a.Rate(): 0.4021920276213831 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.37625345116383313 != rate {\n\t\tt.Errorf(\"7 minute a.Rate(): 0.37625345116383313 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.3519877317060185 != rate {\n\t\tt.Errorf(\"8 minute a.Rate(): 0.3519877317060185 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.3292869816564153165641596 != rate {\n\t\tt.Errorf(\"9 minute a.Rate(): 0.3292869816564153165641596 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.3080502714195546 != rate {\n\t\tt.Errorf(\"10 minute a.Rate(): 0.3080502714195546 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.2881831806538789 != rate {\n\t\tt.Errorf(\"11 minute a.Rate(): 0.2881831806538789 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.26959737847033216 != rate {\n\t\tt.Errorf(\"12 minute a.Rate(): 0.26959737847033216 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.2522102307052083 != rate {\n\t\tt.Errorf(\"13 minute a.Rate(): 0.2522102307052083 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.23594443252115815 != rate {\n\t\tt.Errorf(\"14 minute a.Rate(): 0.23594443252115815 != %v\\n\", rate)\n\t}\n\telapseMinute(a)\n\tif rate := a.Rate(); 0.2207276647028646247028654470286553 != rate {\n\t\tt.Errorf(\"15 minute a.Rate(): 0.2207276647028646247028654470286553 != %v\\n\", rate)\n\t}\n}\n\nfunc elapseMinute(a EWMA) {\n\tfor i := 0; i < 12; i++ {\n\t\ta.Tick()\n\t}\n}\n"
        },
        {
          "name": "exp",
          "type": "tree",
          "content": null
        },
        {
          "name": "gauge.go",
          "type": "blob",
          "size": 2.771484375,
          "content": "package metrics\n\nimport \"sync/atomic\"\n\n// Gauges hold an int64 value that can be set arbitrarily.\ntype Gauge interface {\n\tSnapshot() Gauge\n\tUpdate(int64)\n\tValue() int64\n}\n\n// GetOrRegisterGauge returns an existing Gauge or constructs and registers a\n// new StandardGauge.\nfunc GetOrRegisterGauge(name string, r Registry) Gauge {\n\tif nil == r {\n\t\tr = DefaultRegistry\n\t}\n\treturn r.GetOrRegister(name, NewGauge).(Gauge)\n}\n\n// NewGauge constructs a new StandardGauge.\nfunc NewGauge() Gauge {\n\tif UseNilMetrics {\n\t\treturn NilGauge{}\n\t}\n\treturn &StandardGauge{0}\n}\n\n// NewRegisteredGauge constructs and registers a new StandardGauge.\nfunc NewRegisteredGauge(name string, r Registry) Gauge {\n\tc := NewGauge()\n\tif nil == r {\n\t\tr = DefaultRegistry\n\t}\n\tr.Register(name, c)\n\treturn c\n}\n\n// NewFunctionalGauge constructs a new FunctionalGauge.\nfunc NewFunctionalGauge(f func() int64) Gauge {\n\tif UseNilMetrics {\n\t\treturn NilGauge{}\n\t}\n\treturn &FunctionalGauge{value: f}\n}\n\n// NewRegisteredFunctionalGauge constructs and registers a new StandardGauge.\nfunc NewRegisteredFunctionalGauge(name string, r Registry, f func() int64) Gauge {\n\tc := NewFunctionalGauge(f)\n\tif nil == r {\n\t\tr = DefaultRegistry\n\t}\n\tr.Register(name, c)\n\treturn c\n}\n\n// GaugeSnapshot is a read-only copy of another Gauge.\ntype GaugeSnapshot int64\n\n// Snapshot returns the snapshot.\nfunc (g GaugeSnapshot) Snapshot() Gauge { return g }\n\n// Update panics.\nfunc (GaugeSnapshot) Update(int64) {\n\tpanic(\"Update called on a GaugeSnapshot\")\n}\n\n// Value returns the value at the time the snapshot was taken.\nfunc (g GaugeSnapshot) Value() int64 { return int64(g) }\n\n// NilGauge is a no-op Gauge.\ntype NilGauge struct{}\n\n// Snapshot is a no-op.\nfunc (NilGauge) Snapshot() Gauge { return NilGauge{} }\n\n// Update is a no-op.\nfunc (NilGauge) Update(v int64) {}\n\n// Value is a no-op.\nfunc (NilGauge) Value() int64 { return 0 }\n\n// StandardGauge is the standard implementation of a Gauge and uses the\n// sync/atomic package to manage a single int64 value.\ntype StandardGauge struct {\n\tvalue int64\n}\n\n// Snapshot returns a read-only copy of the gauge.\nfunc (g *StandardGauge) Snapshot() Gauge {\n\treturn GaugeSnapshot(g.Value())\n}\n\n// Update updates the gauge's value.\nfunc (g *StandardGauge) Update(v int64) {\n\tatomic.StoreInt64(&g.value, v)\n}\n\n// Value returns the gauge's current value.\nfunc (g *StandardGauge) Value() int64 {\n\treturn atomic.LoadInt64(&g.value)\n}\n\n// FunctionalGauge returns value from given function\ntype FunctionalGauge struct {\n\tvalue func() int64\n}\n\n// Value returns the gauge's current value.\nfunc (g FunctionalGauge) Value() int64 {\n\treturn g.value()\n}\n\n// Snapshot returns the snapshot.\nfunc (g FunctionalGauge) Snapshot() Gauge { return GaugeSnapshot(g.Value()) }\n\n// Update panics.\nfunc (FunctionalGauge) Update(int64) {\n\tpanic(\"Update called on a FunctionalGauge\")\n}\n"
        },
        {
          "name": "gauge_float64.go",
          "type": "blob",
          "size": 3.2607421875,
          "content": "package metrics\n\nimport (\n\t\"math\"\n\t\"sync/atomic\"\n)\n\n// GaugeFloat64s hold a float64 value that can be set arbitrarily.\ntype GaugeFloat64 interface {\n\tSnapshot() GaugeFloat64\n\tUpdate(float64)\n\tValue() float64\n}\n\n// GetOrRegisterGaugeFloat64 returns an existing GaugeFloat64 or constructs and registers a\n// new StandardGaugeFloat64.\nfunc GetOrRegisterGaugeFloat64(name string, r Registry) GaugeFloat64 {\n\tif nil == r {\n\t\tr = DefaultRegistry\n\t}\n\treturn r.GetOrRegister(name, NewGaugeFloat64()).(GaugeFloat64)\n}\n\n// NewGaugeFloat64 constructs a new StandardGaugeFloat64.\nfunc NewGaugeFloat64() GaugeFloat64 {\n\tif UseNilMetrics {\n\t\treturn NilGaugeFloat64{}\n\t}\n\treturn &StandardGaugeFloat64{\n\t\tvalue: 0.0,\n\t}\n}\n\n// NewRegisteredGaugeFloat64 constructs and registers a new StandardGaugeFloat64.\nfunc NewRegisteredGaugeFloat64(name string, r Registry) GaugeFloat64 {\n\tc := NewGaugeFloat64()\n\tif nil == r {\n\t\tr = DefaultRegistry\n\t}\n\tr.Register(name, c)\n\treturn c\n}\n\n// NewFunctionalGauge constructs a new FunctionalGauge.\nfunc NewFunctionalGaugeFloat64(f func() float64) GaugeFloat64 {\n\tif UseNilMetrics {\n\t\treturn NilGaugeFloat64{}\n\t}\n\treturn &FunctionalGaugeFloat64{value: f}\n}\n\n// NewRegisteredFunctionalGauge constructs and registers a new StandardGauge.\nfunc NewRegisteredFunctionalGaugeFloat64(name string, r Registry, f func() float64) GaugeFloat64 {\n\tc := NewFunctionalGaugeFloat64(f)\n\tif nil == r {\n\t\tr = DefaultRegistry\n\t}\n\tr.Register(name, c)\n\treturn c\n}\n\n// GaugeFloat64Snapshot is a read-only copy of another GaugeFloat64.\ntype GaugeFloat64Snapshot float64\n\n// Snapshot returns the snapshot.\nfunc (g GaugeFloat64Snapshot) Snapshot() GaugeFloat64 { return g }\n\n// Update panics.\nfunc (GaugeFloat64Snapshot) Update(float64) {\n\tpanic(\"Update called on a GaugeFloat64Snapshot\")\n}\n\n// Value returns the value at the time the snapshot was taken.\nfunc (g GaugeFloat64Snapshot) Value() float64 { return float64(g) }\n\n// NilGauge is a no-op Gauge.\ntype NilGaugeFloat64 struct{}\n\n// Snapshot is a no-op.\nfunc (NilGaugeFloat64) Snapshot() GaugeFloat64 { return NilGaugeFloat64{} }\n\n// Update is a no-op.\nfunc (NilGaugeFloat64) Update(v float64) {}\n\n// Value is a no-op.\nfunc (NilGaugeFloat64) Value() float64 { return 0.0 }\n\n// StandardGaugeFloat64 is the standard implementation of a GaugeFloat64 and uses\n// sync.Mutex to manage a single float64 value.\ntype StandardGaugeFloat64 struct {\n\tvalue uint64\n}\n\n// Snapshot returns a read-only copy of the gauge.\nfunc (g *StandardGaugeFloat64) Snapshot() GaugeFloat64 {\n\treturn GaugeFloat64Snapshot(g.Value())\n}\n\n// Update updates the gauge's value.\nfunc (g *StandardGaugeFloat64) Update(v float64) {\n\tatomic.StoreUint64(&g.value, math.Float64bits(v))\n}\n\n// Value returns the gauge's current value.\nfunc (g *StandardGaugeFloat64) Value() float64 {\n\treturn math.Float64frombits(atomic.LoadUint64(&g.value))\n}\n\n// FunctionalGaugeFloat64 returns value from given function\ntype FunctionalGaugeFloat64 struct {\n\tvalue func() float64\n}\n\n// Value returns the gauge's current value.\nfunc (g FunctionalGaugeFloat64) Value() float64 {\n\treturn g.value()\n}\n\n// Snapshot returns the snapshot.\nfunc (g FunctionalGaugeFloat64) Snapshot() GaugeFloat64 { return GaugeFloat64Snapshot(g.Value()) }\n\n// Update panics.\nfunc (FunctionalGaugeFloat64) Update(float64) {\n\tpanic(\"Update called on a FunctionalGaugeFloat64\")\n}\n"
        },
        {
          "name": "gauge_float64_test.go",
          "type": "blob",
          "size": 1.453125,
          "content": "package metrics\n\nimport \"testing\"\n\nfunc BenchmarkGuageFloat64(b *testing.B) {\n\tg := NewGaugeFloat64()\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tg.Update(float64(i))\n\t}\n}\n\nfunc BenchmarkGuageFloat64Parallel(b *testing.B) {\n\tg := NewGaugeFloat64()\n\tb.ResetTimer()\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tfor pb.Next() {\n\t\t\tg.Update(float64(1))\n\t\t}\n\t})\n}\n\nfunc TestGaugeFloat64(t *testing.T) {\n\tg := NewGaugeFloat64()\n\tg.Update(float64(47.0))\n\tif v := g.Value(); float64(47.0) != v {\n\t\tt.Errorf(\"g.Value(): 47.0 != %v\\n\", v)\n\t}\n}\n\nfunc TestGaugeFloat64Snapshot(t *testing.T) {\n\tg := NewGaugeFloat64()\n\tg.Update(float64(47.0))\n\tsnapshot := g.Snapshot()\n\tg.Update(float64(0))\n\tif v := snapshot.Value(); float64(47.0) != v {\n\t\tt.Errorf(\"g.Value(): 47.0 != %v\\n\", v)\n\t}\n}\n\nfunc TestGetOrRegisterGaugeFloat64(t *testing.T) {\n\tr := NewRegistry()\n\tNewRegisteredGaugeFloat64(\"foo\", r).Update(float64(47.0))\n\tt.Logf(\"registry: %v\", r)\n\tif g := GetOrRegisterGaugeFloat64(\"foo\", r); float64(47.0) != g.Value() {\n\t\tt.Fatal(g)\n\t}\n}\n\nfunc TestFunctionalGaugeFloat64(t *testing.T) {\n\tvar counter float64\n\tfg := NewFunctionalGaugeFloat64(func() float64 {\n\t\tcounter++\n\t\treturn counter\n\t})\n\tfg.Value()\n\tfg.Value()\n\tif counter != 2 {\n\t\tt.Error(\"counter != 2\")\n\t}\n}\n\nfunc TestGetOrRegisterFunctionalGaugeFloat64(t *testing.T) {\n\tr := NewRegistry()\n\tNewRegisteredFunctionalGaugeFloat64(\"foo\", r, func() float64 { return 47 })\n\tif g := GetOrRegisterGaugeFloat64(\"foo\", r); 47 != g.Value() {\n\t\tt.Fatal(g)\n\t}\n}\n"
        },
        {
          "name": "gauge_test.go",
          "type": "blob",
          "size": 1.5693359375,
          "content": "package metrics\n\nimport (\n\t\"fmt\"\n\t\"math/rand\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc BenchmarkGuage(b *testing.B) {\n\tg := NewGauge()\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tg.Update(int64(i))\n\t}\n}\n\n// exercise race detector\nfunc TestGaugeConcurrency(t *testing.T) {\n\trand.Seed(time.Now().Unix())\n\tg := NewGauge()\n\twg := &sync.WaitGroup{}\n\treps := 100\n\tfor i := 0; i < reps; i++ {\n\t\twg.Add(1)\n\t\tgo func(g Gauge, wg *sync.WaitGroup) {\n\t\t\tg.Update(rand.Int63())\n\t\t\twg.Done()\n\t\t}(g, wg)\n\t}\n\twg.Wait()\n}\n\nfunc TestGauge(t *testing.T) {\n\tg := NewGauge()\n\tg.Update(int64(47))\n\tif v := g.Value(); 47 != v {\n\t\tt.Errorf(\"g.Value(): 47 != %v\\n\", v)\n\t}\n}\n\nfunc TestGaugeSnapshot(t *testing.T) {\n\tg := NewGauge()\n\tg.Update(int64(47))\n\tsnapshot := g.Snapshot()\n\tg.Update(int64(0))\n\tif v := snapshot.Value(); 47 != v {\n\t\tt.Errorf(\"g.Value(): 47 != %v\\n\", v)\n\t}\n}\n\nfunc TestGetOrRegisterGauge(t *testing.T) {\n\tr := NewRegistry()\n\tNewRegisteredGauge(\"foo\", r).Update(47)\n\tif g := GetOrRegisterGauge(\"foo\", r); 47 != g.Value() {\n\t\tt.Fatal(g)\n\t}\n}\n\nfunc TestFunctionalGauge(t *testing.T) {\n\tvar counter int64\n\tfg := NewFunctionalGauge(func() int64 {\n\t\tcounter++\n\t\treturn counter\n\t})\n\tfg.Value()\n\tfg.Value()\n\tif counter != 2 {\n\t\tt.Error(\"counter != 2\")\n\t}\n}\n\nfunc TestGetOrRegisterFunctionalGauge(t *testing.T) {\n\tr := NewRegistry()\n\tNewRegisteredFunctionalGauge(\"foo\", r, func() int64 { return 47 })\n\tif g := GetOrRegisterGauge(\"foo\", r); 47 != g.Value() {\n\t\tt.Fatal(g)\n\t}\n}\n\nfunc ExampleGetOrRegisterGauge() {\n\tm := \"server.bytes_sent\"\n\tg := GetOrRegisterGauge(m, nil)\n\tg.Update(47)\n\tfmt.Println(g.Value()) // Output: 47\n}\n"
        },
        {
          "name": "graphite.go",
          "type": "blob",
          "size": 4.67578125,
          "content": "package metrics\n\nimport (\n\t\"bufio\"\n\t\"fmt\"\n\t\"log\"\n\t\"net\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n)\n\n// GraphiteConfig provides a container with configuration parameters for\n// the Graphite exporter\ntype GraphiteConfig struct {\n\tAddr          *net.TCPAddr  // Network address to connect to\n\tRegistry      Registry      // Registry to be exported\n\tFlushInterval time.Duration // Flush interval\n\tDurationUnit  time.Duration // Time conversion unit for durations\n\tPrefix        string        // Prefix to be prepended to metric names\n\tPercentiles   []float64     // Percentiles to export from timers and histograms\n}\n\n// Graphite is a blocking exporter function which reports metrics in r\n// to a graphite server located at addr, flushing them every d duration\n// and prepending metric names with prefix.\nfunc Graphite(r Registry, d time.Duration, prefix string, addr *net.TCPAddr) {\n\tGraphiteWithConfig(GraphiteConfig{\n\t\tAddr:          addr,\n\t\tRegistry:      r,\n\t\tFlushInterval: d,\n\t\tDurationUnit:  time.Nanosecond,\n\t\tPrefix:        prefix,\n\t\tPercentiles:   []float64{0.5, 0.75, 0.95, 0.99, 0.999},\n\t})\n}\n\n// GraphiteWithConfig is a blocking exporter function just like Graphite,\n// but it takes a GraphiteConfig instead.\nfunc GraphiteWithConfig(c GraphiteConfig) {\n\tlog.Printf(\"WARNING: This go-metrics client has been DEPRECATED! It has been moved to https://github.com/cyberdelia/go-metrics-graphite and will be removed from rcrowley/go-metrics on August 12th 2015\")\n\tfor _ = range time.Tick(c.FlushInterval) {\n\t\tif err := graphite(&c); nil != err {\n\t\t\tlog.Println(err)\n\t\t}\n\t}\n}\n\n// GraphiteOnce performs a single submission to Graphite, returning a\n// non-nil error on failed connections. This can be used in a loop\n// similar to GraphiteWithConfig for custom error handling.\nfunc GraphiteOnce(c GraphiteConfig) error {\n\tlog.Printf(\"WARNING: This go-metrics client has been DEPRECATED! It has been moved to https://github.com/cyberdelia/go-metrics-graphite and will be removed from rcrowley/go-metrics on August 12th 2015\")\n\treturn graphite(&c)\n}\n\nfunc graphite(c *GraphiteConfig) error {\n\tnow := time.Now().Unix()\n\tdu := float64(c.DurationUnit)\n\tconn, err := net.DialTCP(\"tcp\", nil, c.Addr)\n\tif nil != err {\n\t\treturn err\n\t}\n\tdefer conn.Close()\n\tw := bufio.NewWriter(conn)\n\tc.Registry.Each(func(name string, i interface{}) {\n\t\tswitch metric := i.(type) {\n\t\tcase Counter:\n\t\t\tfmt.Fprintf(w, \"%s.%s.count %d %d\\n\", c.Prefix, name, metric.Count(), now)\n\t\tcase Gauge:\n\t\t\tfmt.Fprintf(w, \"%s.%s.value %d %d\\n\", c.Prefix, name, metric.Value(), now)\n\t\tcase GaugeFloat64:\n\t\t\tfmt.Fprintf(w, \"%s.%s.value %f %d\\n\", c.Prefix, name, metric.Value(), now)\n\t\tcase Histogram:\n\t\t\th := metric.Snapshot()\n\t\t\tps := h.Percentiles(c.Percentiles)\n\t\t\tfmt.Fprintf(w, \"%s.%s.count %d %d\\n\", c.Prefix, name, h.Count(), now)\n\t\t\tfmt.Fprintf(w, \"%s.%s.min %d %d\\n\", c.Prefix, name, h.Min(), now)\n\t\t\tfmt.Fprintf(w, \"%s.%s.max %d %d\\n\", c.Prefix, name, h.Max(), now)\n\t\t\tfmt.Fprintf(w, \"%s.%s.mean %.2f %d\\n\", c.Prefix, name, h.Mean(), now)\n\t\t\tfmt.Fprintf(w, \"%s.%s.std-dev %.2f %d\\n\", c.Prefix, name, h.StdDev(), now)\n\t\t\tfor psIdx, psKey := range c.Percentiles {\n\t\t\t\tkey := strings.Replace(strconv.FormatFloat(psKey*100.0, 'f', -1, 64), \".\", \"\", 1)\n\t\t\t\tfmt.Fprintf(w, \"%s.%s.%s-percentile %.2f %d\\n\", c.Prefix, name, key, ps[psIdx], now)\n\t\t\t}\n\t\tcase Meter:\n\t\t\tm := metric.Snapshot()\n\t\t\tfmt.Fprintf(w, \"%s.%s.count %d %d\\n\", c.Prefix, name, m.Count(), now)\n\t\t\tfmt.Fprintf(w, \"%s.%s.one-minute %.2f %d\\n\", c.Prefix, name, m.Rate1(), now)\n\t\t\tfmt.Fprintf(w, \"%s.%s.five-minute %.2f %d\\n\", c.Prefix, name, m.Rate5(), now)\n\t\t\tfmt.Fprintf(w, \"%s.%s.fifteen-minute %.2f %d\\n\", c.Prefix, name, m.Rate15(), now)\n\t\t\tfmt.Fprintf(w, \"%s.%s.mean %.2f %d\\n\", c.Prefix, name, m.RateMean(), now)\n\t\tcase Timer:\n\t\t\tt := metric.Snapshot()\n\t\t\tps := t.Percentiles(c.Percentiles)\n\t\t\tfmt.Fprintf(w, \"%s.%s.count %d %d\\n\", c.Prefix, name, t.Count(), now)\n\t\t\tfmt.Fprintf(w, \"%s.%s.min %d %d\\n\", c.Prefix, name, t.Min()/int64(du), now)\n\t\t\tfmt.Fprintf(w, \"%s.%s.max %d %d\\n\", c.Prefix, name, t.Max()/int64(du), now)\n\t\t\tfmt.Fprintf(w, \"%s.%s.mean %.2f %d\\n\", c.Prefix, name, t.Mean()/du, now)\n\t\t\tfmt.Fprintf(w, \"%s.%s.std-dev %.2f %d\\n\", c.Prefix, name, t.StdDev()/du, now)\n\t\t\tfor psIdx, psKey := range c.Percentiles {\n\t\t\t\tkey := strings.Replace(strconv.FormatFloat(psKey*100.0, 'f', -1, 64), \".\", \"\", 1)\n\t\t\t\tfmt.Fprintf(w, \"%s.%s.%s-percentile %.2f %d\\n\", c.Prefix, name, key, ps[psIdx], now)\n\t\t\t}\n\t\t\tfmt.Fprintf(w, \"%s.%s.one-minute %.2f %d\\n\", c.Prefix, name, t.Rate1(), now)\n\t\t\tfmt.Fprintf(w, \"%s.%s.five-minute %.2f %d\\n\", c.Prefix, name, t.Rate5(), now)\n\t\t\tfmt.Fprintf(w, \"%s.%s.fifteen-minute %.2f %d\\n\", c.Prefix, name, t.Rate15(), now)\n\t\t\tfmt.Fprintf(w, \"%s.%s.mean-rate %.2f %d\\n\", c.Prefix, name, t.RateMean(), now)\n\t\t}\n\t\tw.Flush()\n\t})\n\treturn nil\n}\n"
        },
        {
          "name": "graphite_test.go",
          "type": "blob",
          "size": 0.478515625,
          "content": "package metrics\n\nimport (\n\t\"net\"\n\t\"time\"\n)\n\nfunc ExampleGraphite() {\n\taddr, _ := net.ResolveTCPAddr(\"net\", \":2003\")\n\tgo Graphite(DefaultRegistry, 1*time.Second, \"some.prefix\", addr)\n}\n\nfunc ExampleGraphiteWithConfig() {\n\taddr, _ := net.ResolveTCPAddr(\"net\", \":2003\")\n\tgo GraphiteWithConfig(GraphiteConfig{\n\t\tAddr:          addr,\n\t\tRegistry:      DefaultRegistry,\n\t\tFlushInterval: 1 * time.Second,\n\t\tDurationUnit:  time.Millisecond,\n\t\tPercentiles:   []float64{0.5, 0.75, 0.99, 0.999},\n\t})\n}\n"
        },
        {
          "name": "healthcheck.go",
          "type": "blob",
          "size": 1.4736328125,
          "content": "package metrics\n\n// Healthchecks hold an error value describing an arbitrary up/down status.\ntype Healthcheck interface {\n\tCheck()\n\tError() error\n\tHealthy()\n\tUnhealthy(error)\n}\n\n// NewHealthcheck constructs a new Healthcheck which will use the given\n// function to update its status.\nfunc NewHealthcheck(f func(Healthcheck)) Healthcheck {\n\tif UseNilMetrics {\n\t\treturn NilHealthcheck{}\n\t}\n\treturn &StandardHealthcheck{nil, f}\n}\n\n// NilHealthcheck is a no-op.\ntype NilHealthcheck struct{}\n\n// Check is a no-op.\nfunc (NilHealthcheck) Check() {}\n\n// Error is a no-op.\nfunc (NilHealthcheck) Error() error { return nil }\n\n// Healthy is a no-op.\nfunc (NilHealthcheck) Healthy() {}\n\n// Unhealthy is a no-op.\nfunc (NilHealthcheck) Unhealthy(error) {}\n\n// StandardHealthcheck is the standard implementation of a Healthcheck and\n// stores the status and a function to call to update the status.\ntype StandardHealthcheck struct {\n\terr error\n\tf   func(Healthcheck)\n}\n\n// Check runs the healthcheck function to update the healthcheck's status.\nfunc (h *StandardHealthcheck) Check() {\n\th.f(h)\n}\n\n// Error returns the healthcheck's status, which will be nil if it is healthy.\nfunc (h *StandardHealthcheck) Error() error {\n\treturn h.err\n}\n\n// Healthy marks the healthcheck as healthy.\nfunc (h *StandardHealthcheck) Healthy() {\n\th.err = nil\n}\n\n// Unhealthy marks the healthcheck as unhealthy.  The error is stored and\n// may be retrieved by the Error method.\nfunc (h *StandardHealthcheck) Unhealthy(err error) {\n\th.err = err\n}\n"
        },
        {
          "name": "histogram.go",
          "type": "blob",
          "size": 6.0625,
          "content": "package metrics\n\n// Histograms calculate distribution statistics from a series of int64 values.\ntype Histogram interface {\n\tClear()\n\tCount() int64\n\tMax() int64\n\tMean() float64\n\tMin() int64\n\tPercentile(float64) float64\n\tPercentiles([]float64) []float64\n\tSample() Sample\n\tSnapshot() Histogram\n\tStdDev() float64\n\tSum() int64\n\tUpdate(int64)\n\tVariance() float64\n}\n\n// GetOrRegisterHistogram returns an existing Histogram or constructs and\n// registers a new StandardHistogram.\nfunc GetOrRegisterHistogram(name string, r Registry, s Sample) Histogram {\n\tif nil == r {\n\t\tr = DefaultRegistry\n\t}\n\treturn r.GetOrRegister(name, func() Histogram { return NewHistogram(s) }).(Histogram)\n}\n\n// NewHistogram constructs a new StandardHistogram from a Sample.\nfunc NewHistogram(s Sample) Histogram {\n\tif UseNilMetrics {\n\t\treturn NilHistogram{}\n\t}\n\treturn &StandardHistogram{sample: s}\n}\n\n// NewRegisteredHistogram constructs and registers a new StandardHistogram from\n// a Sample.\nfunc NewRegisteredHistogram(name string, r Registry, s Sample) Histogram {\n\tc := NewHistogram(s)\n\tif nil == r {\n\t\tr = DefaultRegistry\n\t}\n\tr.Register(name, c)\n\treturn c\n}\n\n// HistogramSnapshot is a read-only copy of another Histogram.\ntype HistogramSnapshot struct {\n\tsample *SampleSnapshot\n}\n\n// Clear panics.\nfunc (*HistogramSnapshot) Clear() {\n\tpanic(\"Clear called on a HistogramSnapshot\")\n}\n\n// Count returns the number of samples recorded at the time the snapshot was\n// taken.\nfunc (h *HistogramSnapshot) Count() int64 { return h.sample.Count() }\n\n// Max returns the maximum value in the sample at the time the snapshot was\n// taken.\nfunc (h *HistogramSnapshot) Max() int64 { return h.sample.Max() }\n\n// Mean returns the mean of the values in the sample at the time the snapshot\n// was taken.\nfunc (h *HistogramSnapshot) Mean() float64 { return h.sample.Mean() }\n\n// Min returns the minimum value in the sample at the time the snapshot was\n// taken.\nfunc (h *HistogramSnapshot) Min() int64 { return h.sample.Min() }\n\n// Percentile returns an arbitrary percentile of values in the sample at the\n// time the snapshot was taken.\nfunc (h *HistogramSnapshot) Percentile(p float64) float64 {\n\treturn h.sample.Percentile(p)\n}\n\n// Percentiles returns a slice of arbitrary percentiles of values in the sample\n// at the time the snapshot was taken.\nfunc (h *HistogramSnapshot) Percentiles(ps []float64) []float64 {\n\treturn h.sample.Percentiles(ps)\n}\n\n// Sample returns the Sample underlying the histogram.\nfunc (h *HistogramSnapshot) Sample() Sample { return h.sample }\n\n// Snapshot returns the snapshot.\nfunc (h *HistogramSnapshot) Snapshot() Histogram { return h }\n\n// StdDev returns the standard deviation of the values in the sample at the\n// time the snapshot was taken.\nfunc (h *HistogramSnapshot) StdDev() float64 { return h.sample.StdDev() }\n\n// Sum returns the sum in the sample at the time the snapshot was taken.\nfunc (h *HistogramSnapshot) Sum() int64 { return h.sample.Sum() }\n\n// Update panics.\nfunc (*HistogramSnapshot) Update(int64) {\n\tpanic(\"Update called on a HistogramSnapshot\")\n}\n\n// Variance returns the variance of inputs at the time the snapshot was taken.\nfunc (h *HistogramSnapshot) Variance() float64 { return h.sample.Variance() }\n\n// NilHistogram is a no-op Histogram.\ntype NilHistogram struct{}\n\n// Clear is a no-op.\nfunc (NilHistogram) Clear() {}\n\n// Count is a no-op.\nfunc (NilHistogram) Count() int64 { return 0 }\n\n// Max is a no-op.\nfunc (NilHistogram) Max() int64 { return 0 }\n\n// Mean is a no-op.\nfunc (NilHistogram) Mean() float64 { return 0.0 }\n\n// Min is a no-op.\nfunc (NilHistogram) Min() int64 { return 0 }\n\n// Percentile is a no-op.\nfunc (NilHistogram) Percentile(p float64) float64 { return 0.0 }\n\n// Percentiles is a no-op.\nfunc (NilHistogram) Percentiles(ps []float64) []float64 {\n\treturn make([]float64, len(ps))\n}\n\n// Sample is a no-op.\nfunc (NilHistogram) Sample() Sample { return NilSample{} }\n\n// Snapshot is a no-op.\nfunc (NilHistogram) Snapshot() Histogram { return NilHistogram{} }\n\n// StdDev is a no-op.\nfunc (NilHistogram) StdDev() float64 { return 0.0 }\n\n// Sum is a no-op.\nfunc (NilHistogram) Sum() int64 { return 0 }\n\n// Update is a no-op.\nfunc (NilHistogram) Update(v int64) {}\n\n// Variance is a no-op.\nfunc (NilHistogram) Variance() float64 { return 0.0 }\n\n// StandardHistogram is the standard implementation of a Histogram and uses a\n// Sample to bound its memory use.\ntype StandardHistogram struct {\n\tsample Sample\n}\n\n// Clear clears the histogram and its sample.\nfunc (h *StandardHistogram) Clear() { h.sample.Clear() }\n\n// Count returns the number of samples recorded since the histogram was last\n// cleared.\nfunc (h *StandardHistogram) Count() int64 { return h.sample.Count() }\n\n// Max returns the maximum value in the sample.\nfunc (h *StandardHistogram) Max() int64 { return h.sample.Max() }\n\n// Mean returns the mean of the values in the sample.\nfunc (h *StandardHistogram) Mean() float64 { return h.sample.Mean() }\n\n// Min returns the minimum value in the sample.\nfunc (h *StandardHistogram) Min() int64 { return h.sample.Min() }\n\n// Percentile returns an arbitrary percentile of the values in the sample.\nfunc (h *StandardHistogram) Percentile(p float64) float64 {\n\treturn h.sample.Percentile(p)\n}\n\n// Percentiles returns a slice of arbitrary percentiles of the values in the\n// sample.\nfunc (h *StandardHistogram) Percentiles(ps []float64) []float64 {\n\treturn h.sample.Percentiles(ps)\n}\n\n// Sample returns the Sample underlying the histogram.\nfunc (h *StandardHistogram) Sample() Sample { return h.sample }\n\n// Snapshot returns a read-only copy of the histogram.\nfunc (h *StandardHistogram) Snapshot() Histogram {\n\treturn &HistogramSnapshot{sample: h.sample.Snapshot().(*SampleSnapshot)}\n}\n\n// StdDev returns the standard deviation of the values in the sample.\nfunc (h *StandardHistogram) StdDev() float64 { return h.sample.StdDev() }\n\n// Sum returns the sum in the sample.\nfunc (h *StandardHistogram) Sum() int64 { return h.sample.Sum() }\n\n// Update samples a new value.\nfunc (h *StandardHistogram) Update(v int64) { h.sample.Update(v) }\n\n// Variance returns the variance of the values in the sample.\nfunc (h *StandardHistogram) Variance() float64 { return h.sample.Variance() }\n"
        },
        {
          "name": "histogram_test.go",
          "type": "blob",
          "size": 2.2666015625,
          "content": "package metrics\n\nimport \"testing\"\n\nfunc BenchmarkHistogram(b *testing.B) {\n\th := NewHistogram(NewUniformSample(100))\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\th.Update(int64(i))\n\t}\n}\n\nfunc TestGetOrRegisterHistogram(t *testing.T) {\n\tr := NewRegistry()\n\ts := NewUniformSample(100)\n\tNewRegisteredHistogram(\"foo\", r, s).Update(47)\n\tif h := GetOrRegisterHistogram(\"foo\", r, s); 1 != h.Count() {\n\t\tt.Fatal(h)\n\t}\n}\n\nfunc TestHistogram10000(t *testing.T) {\n\th := NewHistogram(NewUniformSample(100000))\n\tfor i := 1; i <= 10000; i++ {\n\t\th.Update(int64(i))\n\t}\n\ttestHistogram10000(t, h)\n}\n\nfunc TestHistogramEmpty(t *testing.T) {\n\th := NewHistogram(NewUniformSample(100))\n\tif count := h.Count(); 0 != count {\n\t\tt.Errorf(\"h.Count(): 0 != %v\\n\", count)\n\t}\n\tif min := h.Min(); 0 != min {\n\t\tt.Errorf(\"h.Min(): 0 != %v\\n\", min)\n\t}\n\tif max := h.Max(); 0 != max {\n\t\tt.Errorf(\"h.Max(): 0 != %v\\n\", max)\n\t}\n\tif mean := h.Mean(); 0.0 != mean {\n\t\tt.Errorf(\"h.Mean(): 0.0 != %v\\n\", mean)\n\t}\n\tif stdDev := h.StdDev(); 0.0 != stdDev {\n\t\tt.Errorf(\"h.StdDev(): 0.0 != %v\\n\", stdDev)\n\t}\n\tps := h.Percentiles([]float64{0.5, 0.75, 0.99})\n\tif 0.0 != ps[0] {\n\t\tt.Errorf(\"median: 0.0 != %v\\n\", ps[0])\n\t}\n\tif 0.0 != ps[1] {\n\t\tt.Errorf(\"75th percentile: 0.0 != %v\\n\", ps[1])\n\t}\n\tif 0.0 != ps[2] {\n\t\tt.Errorf(\"99th percentile: 0.0 != %v\\n\", ps[2])\n\t}\n}\n\nfunc TestHistogramSnapshot(t *testing.T) {\n\th := NewHistogram(NewUniformSample(100000))\n\tfor i := 1; i <= 10000; i++ {\n\t\th.Update(int64(i))\n\t}\n\tsnapshot := h.Snapshot()\n\th.Update(0)\n\ttestHistogram10000(t, snapshot)\n}\n\nfunc testHistogram10000(t *testing.T, h Histogram) {\n\tif count := h.Count(); 10000 != count {\n\t\tt.Errorf(\"h.Count(): 10000 != %v\\n\", count)\n\t}\n\tif min := h.Min(); 1 != min {\n\t\tt.Errorf(\"h.Min(): 1 != %v\\n\", min)\n\t}\n\tif max := h.Max(); 10000 != max {\n\t\tt.Errorf(\"h.Max(): 10000 != %v\\n\", max)\n\t}\n\tif mean := h.Mean(); 5000.5 != mean {\n\t\tt.Errorf(\"h.Mean(): 5000.5 != %v\\n\", mean)\n\t}\n\tif stdDev := h.StdDev(); 2886.751331514372 != stdDev {\n\t\tt.Errorf(\"h.StdDev(): 2886.751331514372 != %v\\n\", stdDev)\n\t}\n\tps := h.Percentiles([]float64{0.5, 0.75, 0.99})\n\tif 5000.5 != ps[0] {\n\t\tt.Errorf(\"median: 5000.5 != %v\\n\", ps[0])\n\t}\n\tif 7500.75 != ps[1] {\n\t\tt.Errorf(\"75th percentile: 7500.75 != %v\\n\", ps[1])\n\t}\n\tif 9900.99 != ps[2] {\n\t\tt.Errorf(\"99th percentile: 9900.99 != %v\\n\", ps[2])\n\t}\n}\n"
        },
        {
          "name": "json.go",
          "type": "blob",
          "size": 0.7353515625,
          "content": "package metrics\n\nimport (\n\t\"encoding/json\"\n\t\"io\"\n\t\"time\"\n)\n\n// MarshalJSON returns a byte slice containing a JSON representation of all\n// the metrics in the Registry.\nfunc (r *StandardRegistry) MarshalJSON() ([]byte, error) {\n\treturn json.Marshal(r.GetAll())\n}\n\n// WriteJSON writes metrics from the given registry  periodically to the\n// specified io.Writer as JSON.\nfunc WriteJSON(r Registry, d time.Duration, w io.Writer) {\n\tfor _ = range time.Tick(d) {\n\t\tWriteJSONOnce(r, w)\n\t}\n}\n\n// WriteJSONOnce writes metrics from the given registry to the specified\n// io.Writer as JSON.\nfunc WriteJSONOnce(r Registry, w io.Writer) {\n\tjson.NewEncoder(w).Encode(r)\n}\n\nfunc (p *PrefixedRegistry) MarshalJSON() ([]byte, error) {\n\treturn json.Marshal(p.GetAll())\n}\n"
        },
        {
          "name": "json_test.go",
          "type": "blob",
          "size": 0.5234375,
          "content": "package metrics\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"testing\"\n)\n\nfunc TestRegistryMarshallJSON(t *testing.T) {\n\tb := &bytes.Buffer{}\n\tenc := json.NewEncoder(b)\n\tr := NewRegistry()\n\tr.Register(\"counter\", NewCounter())\n\tenc.Encode(r)\n\tif s := b.String(); \"{\\\"counter\\\":{\\\"count\\\":0}}\\n\" != s {\n\t\tt.Fatalf(s)\n\t}\n}\n\nfunc TestRegistryWriteJSONOnce(t *testing.T) {\n\tr := NewRegistry()\n\tr.Register(\"counter\", NewCounter())\n\tb := &bytes.Buffer{}\n\tWriteJSONOnce(r, b)\n\tif s := b.String(); s != \"{\\\"counter\\\":{\\\"count\\\":0}}\\n\" {\n\t\tt.Fail()\n\t}\n}\n"
        },
        {
          "name": "librato",
          "type": "tree",
          "content": null
        },
        {
          "name": "log.go",
          "type": "blob",
          "size": 3.6689453125,
          "content": "package metrics\n\nimport (\n\t\"time\"\n)\n\ntype Logger interface {\n\tPrintf(format string, v ...interface{})\n}\n\n// Log outputs each metric in the given registry periodically using the given logger.\nfunc Log(r Registry, freq time.Duration, l Logger) {\n\tLogScaled(r, freq, time.Nanosecond, l)\n}\n\n// LogOnCue outputs each metric in the given registry on demand through the channel\n// using the given logger\nfunc LogOnCue(r Registry, ch chan interface{}, l Logger) {\n\tLogScaledOnCue(r, ch, time.Nanosecond, l)\n}\n\n// LogScaled outputs each metric in the given registry periodically using the given\n// logger. Print timings in `scale` units (eg time.Millisecond) rather than nanos.\nfunc LogScaled(r Registry, freq time.Duration, scale time.Duration, l Logger) {\n\tch := make(chan interface{})\n\tgo func(channel chan interface{}) {\n\t\tfor _ = range time.Tick(freq) {\n\t\t\tchannel <- struct{}{}\n\t\t}\n\t}(ch)\n\tLogScaledOnCue(r, ch, scale, l)\n}\n\n// LogScaledOnCue outputs each metric in the given registry on demand through the channel\n// using the given logger. Print timings in `scale` units (eg time.Millisecond) rather\n// than nanos.\nfunc LogScaledOnCue(r Registry, ch chan interface{}, scale time.Duration, l Logger) {\n\tdu := float64(scale)\n\tduSuffix := scale.String()[1:]\n\n\tfor _ = range ch {\n\t\tr.Each(func(name string, i interface{}) {\n\t\t\tswitch metric := i.(type) {\n\t\t\tcase Counter:\n\t\t\t\tl.Printf(\"counter %s\\n\", name)\n\t\t\t\tl.Printf(\"  count:       %9d\\n\", metric.Count())\n\t\t\tcase Gauge:\n\t\t\t\tl.Printf(\"gauge %s\\n\", name)\n\t\t\t\tl.Printf(\"  value:       %9d\\n\", metric.Value())\n\t\t\tcase GaugeFloat64:\n\t\t\t\tl.Printf(\"gauge %s\\n\", name)\n\t\t\t\tl.Printf(\"  value:       %f\\n\", metric.Value())\n\t\t\tcase Healthcheck:\n\t\t\t\tmetric.Check()\n\t\t\t\tl.Printf(\"healthcheck %s\\n\", name)\n\t\t\t\tl.Printf(\"  error:       %v\\n\", metric.Error())\n\t\t\tcase Histogram:\n\t\t\t\th := metric.Snapshot()\n\t\t\t\tps := h.Percentiles([]float64{0.5, 0.75, 0.95, 0.99, 0.999})\n\t\t\t\tl.Printf(\"histogram %s\\n\", name)\n\t\t\t\tl.Printf(\"  count:       %9d\\n\", h.Count())\n\t\t\t\tl.Printf(\"  min:         %9d\\n\", h.Min())\n\t\t\t\tl.Printf(\"  max:         %9d\\n\", h.Max())\n\t\t\t\tl.Printf(\"  mean:        %12.2f\\n\", h.Mean())\n\t\t\t\tl.Printf(\"  stddev:      %12.2f\\n\", h.StdDev())\n\t\t\t\tl.Printf(\"  median:      %12.2f\\n\", ps[0])\n\t\t\t\tl.Printf(\"  75%%:         %12.2f\\n\", ps[1])\n\t\t\t\tl.Printf(\"  95%%:         %12.2f\\n\", ps[2])\n\t\t\t\tl.Printf(\"  99%%:         %12.2f\\n\", ps[3])\n\t\t\t\tl.Printf(\"  99.9%%:       %12.2f\\n\", ps[4])\n\t\t\tcase Meter:\n\t\t\t\tm := metric.Snapshot()\n\t\t\t\tl.Printf(\"meter %s\\n\", name)\n\t\t\t\tl.Printf(\"  count:       %9d\\n\", m.Count())\n\t\t\t\tl.Printf(\"  1-min rate:  %12.2f\\n\", m.Rate1())\n\t\t\t\tl.Printf(\"  5-min rate:  %12.2f\\n\", m.Rate5())\n\t\t\t\tl.Printf(\"  15-min rate: %12.2f\\n\", m.Rate15())\n\t\t\t\tl.Printf(\"  mean rate:   %12.2f\\n\", m.RateMean())\n\t\t\tcase Timer:\n\t\t\t\tt := metric.Snapshot()\n\t\t\t\tps := t.Percentiles([]float64{0.5, 0.75, 0.95, 0.99, 0.999})\n\t\t\t\tl.Printf(\"timer %s\\n\", name)\n\t\t\t\tl.Printf(\"  count:       %9d\\n\", t.Count())\n\t\t\t\tl.Printf(\"  min:         %12.2f%s\\n\", float64(t.Min())/du, duSuffix)\n\t\t\t\tl.Printf(\"  max:         %12.2f%s\\n\", float64(t.Max())/du, duSuffix)\n\t\t\t\tl.Printf(\"  mean:        %12.2f%s\\n\", t.Mean()/du, duSuffix)\n\t\t\t\tl.Printf(\"  stddev:      %12.2f%s\\n\", t.StdDev()/du, duSuffix)\n\t\t\t\tl.Printf(\"  median:      %12.2f%s\\n\", ps[0]/du, duSuffix)\n\t\t\t\tl.Printf(\"  75%%:         %12.2f%s\\n\", ps[1]/du, duSuffix)\n\t\t\t\tl.Printf(\"  95%%:         %12.2f%s\\n\", ps[2]/du, duSuffix)\n\t\t\t\tl.Printf(\"  99%%:         %12.2f%s\\n\", ps[3]/du, duSuffix)\n\t\t\t\tl.Printf(\"  99.9%%:       %12.2f%s\\n\", ps[4]/du, duSuffix)\n\t\t\t\tl.Printf(\"  1-min rate:  %12.2f\\n\", t.Rate1())\n\t\t\t\tl.Printf(\"  5-min rate:  %12.2f\\n\", t.Rate5())\n\t\t\t\tl.Printf(\"  15-min rate: %12.2f\\n\", t.Rate15())\n\t\t\t\tl.Printf(\"  mean rate:   %12.2f\\n\", t.RateMean())\n\t\t\t}\n\t\t})\n\t}\n}\n"
        },
        {
          "name": "memory.md",
          "type": "blob",
          "size": 5.177734375,
          "content": "Memory usage\n============\n\n(Highly unscientific.)\n\nCommand used to gather static memory usage:\n\n```sh\ngrep ^Vm \"/proc/$(ps fax | grep [m]etrics-bench | awk '{print $1}')/status\"\n```\n\nProgram used to gather baseline memory usage:\n\n```go\npackage main\n\nimport \"time\"\n\nfunc main() {\n\ttime.Sleep(600e9)\n}\n```\n\nBaseline\n--------\n\n```\nVmPeak:    42604 kB\nVmSize:    42604 kB\nVmLck:         0 kB\nVmHWM:      1120 kB\nVmRSS:      1120 kB\nVmData:    35460 kB\nVmStk:       136 kB\nVmExe:      1020 kB\nVmLib:      1848 kB\nVmPTE:        36 kB\nVmSwap:        0 kB\n```\n\nProgram used to gather metric memory usage (with other metrics being similar):\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"metrics\"\n\t\"time\"\n)\n\nfunc main() {\n\tfmt.Sprintf(\"foo\")\n\tmetrics.NewRegistry()\n\ttime.Sleep(600e9)\n}\n```\n\n1000 counters registered\n------------------------\n\n```\nVmPeak:    44016 kB\nVmSize:    44016 kB\nVmLck:         0 kB\nVmHWM:      1928 kB\nVmRSS:      1928 kB\nVmData:    36868 kB\nVmStk:       136 kB\nVmExe:      1024 kB\nVmLib:      1848 kB\nVmPTE:        40 kB\nVmSwap:        0 kB\n```\n\n**1.412 kB virtual, TODO 0.808 kB resident per counter.**\n\n100000 counters registered\n--------------------------\n\n```\nVmPeak:    55024 kB\nVmSize:    55024 kB\nVmLck:         0 kB\nVmHWM:     12440 kB\nVmRSS:     12440 kB\nVmData:    47876 kB\nVmStk:       136 kB\nVmExe:      1024 kB\nVmLib:      1848 kB\nVmPTE:        64 kB\nVmSwap:        0 kB\n```\n\n**0.1242 kB virtual, 0.1132 kB resident per counter.**\n\n1000 gauges registered\n----------------------\n\n```\nVmPeak:    44012 kB\nVmSize:    44012 kB\nVmLck:         0 kB\nVmHWM:      1928 kB\nVmRSS:      1928 kB\nVmData:    36868 kB\nVmStk:       136 kB\nVmExe:      1020 kB\nVmLib:      1848 kB\nVmPTE:        40 kB\nVmSwap:        0 kB\n```\n\n**1.408 kB virtual, 0.808 kB resident per counter.**\n\n100000 gauges registered\n------------------------\n\n```\nVmPeak:    55020 kB\nVmSize:    55020 kB\nVmLck:         0 kB\nVmHWM:     12432 kB\nVmRSS:     12432 kB\nVmData:    47876 kB\nVmStk:       136 kB\nVmExe:      1020 kB\nVmLib:      1848 kB\nVmPTE:        60 kB\nVmSwap:        0 kB\n```\n\n**0.12416 kB virtual, 0.11312 resident per gauge.**\n\n1000 histograms with a uniform sample size of 1028\n--------------------------------------------------\n\n```\nVmPeak:    72272 kB\nVmSize:    72272 kB\nVmLck:         0 kB\nVmHWM:     16204 kB\nVmRSS:     16204 kB\nVmData:    65100 kB\nVmStk:       136 kB\nVmExe:      1048 kB\nVmLib:      1848 kB\nVmPTE:        80 kB\nVmSwap:        0 kB\n```\n\n**29.668 kB virtual, TODO 15.084 resident per histogram.**\n\n10000 histograms with a uniform sample size of 1028\n---------------------------------------------------\n\n```\nVmPeak:   256912 kB\nVmSize:   256912 kB\nVmLck:         0 kB\nVmHWM:    146204 kB\nVmRSS:    146204 kB\nVmData:   249740 kB\nVmStk:       136 kB\nVmExe:      1048 kB\nVmLib:      1848 kB\nVmPTE:       448 kB\nVmSwap:        0 kB\n```\n\n**21.4308 kB virtual, 14.5084 kB resident per histogram.**\n\n50000 histograms with a uniform sample size of 1028\n---------------------------------------------------\n\n```\nVmPeak:   908112 kB\nVmSize:   908112 kB\nVmLck:         0 kB\nVmHWM:    645832 kB\nVmRSS:    645588 kB\nVmData:   900940 kB\nVmStk:       136 kB\nVmExe:      1048 kB\nVmLib:      1848 kB\nVmPTE:      1716 kB\nVmSwap:     1544 kB\n```\n\n**17.31016 kB virtual, 12.88936 kB resident per histogram.**\n\n1000 histograms with an exponentially-decaying sample size of 1028 and alpha of 0.015\n-------------------------------------------------------------------------------------\n\n```\nVmPeak:    62480 kB\nVmSize:    62480 kB\nVmLck:         0 kB\nVmHWM:     11572 kB\nVmRSS:     11572 kB\nVmData:    55308 kB\nVmStk:       136 kB\nVmExe:      1048 kB\nVmLib:      1848 kB\nVmPTE:        64 kB\nVmSwap:        0 kB\n```\n\n**19.876 kB virtual, 10.452 kB resident per histogram.**\n\n10000 histograms with an exponentially-decaying sample size of 1028 and alpha of 0.015\n--------------------------------------------------------------------------------------\n\n```\nVmPeak:   153296 kB\nVmSize:   153296 kB\nVmLck:         0 kB\nVmHWM:    101176 kB\nVmRSS:    101176 kB\nVmData:   146124 kB\nVmStk:       136 kB\nVmExe:      1048 kB\nVmLib:      1848 kB\nVmPTE:       240 kB\nVmSwap:        0 kB\n```\n\n**11.0692 kB virtual, 10.0056 kB resident per histogram.**\n\n50000 histograms with an exponentially-decaying sample size of 1028 and alpha of 0.015\n--------------------------------------------------------------------------------------\n\n```\nVmPeak:   557264 kB\nVmSize:   557264 kB\nVmLck:         0 kB\nVmHWM:    501056 kB\nVmRSS:    501056 kB\nVmData:   550092 kB\nVmStk:       136 kB\nVmExe:      1048 kB\nVmLib:      1848 kB\nVmPTE:      1032 kB\nVmSwap:        0 kB\n```\n\n**10.2932 kB virtual, 9.99872 kB resident per histogram.**\n\n1000 meters\n-----------\n\n```\nVmPeak:    74504 kB\nVmSize:    74504 kB\nVmLck:         0 kB\nVmHWM:     24124 kB\nVmRSS:     24124 kB\nVmData:    67340 kB\nVmStk:       136 kB\nVmExe:      1040 kB\nVmLib:      1848 kB\nVmPTE:        92 kB\nVmSwap:        0 kB\n```\n\n**31.9 kB virtual, 23.004 kB resident per meter.**\n\n10000 meters\n------------\n\n```\nVmPeak:   278920 kB\nVmSize:   278920 kB\nVmLck:         0 kB\nVmHWM:    227300 kB\nVmRSS:    227300 kB\nVmData:   271756 kB\nVmStk:       136 kB\nVmExe:      1040 kB\nVmLib:      1848 kB\nVmPTE:       488 kB\nVmSwap:        0 kB\n```\n\n**23.6316 kB virtual, 22.618 kB resident per meter.**\n"
        },
        {
          "name": "meter.go",
          "type": "blob",
          "size": 6.51171875,
          "content": "package metrics\n\nimport (\n\t\"math\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n)\n\n// Meters count events to produce exponentially-weighted moving average rates\n// at one-, five-, and fifteen-minutes and a mean rate.\ntype Meter interface {\n\tCount() int64\n\tMark(int64)\n\tRate1() float64\n\tRate5() float64\n\tRate15() float64\n\tRateMean() float64\n\tSnapshot() Meter\n\tStop()\n}\n\n// GetOrRegisterMeter returns an existing Meter or constructs and registers a\n// new StandardMeter.\n// Be sure to unregister the meter from the registry once it is of no use to\n// allow for garbage collection.\nfunc GetOrRegisterMeter(name string, r Registry) Meter {\n\tif nil == r {\n\t\tr = DefaultRegistry\n\t}\n\treturn r.GetOrRegister(name, NewMeter).(Meter)\n}\n\n// NewMeter constructs a new StandardMeter and launches a goroutine.\n// Be sure to call Stop() once the meter is of no use to allow for garbage collection.\nfunc NewMeter() Meter {\n\tif UseNilMetrics {\n\t\treturn NilMeter{}\n\t}\n\tm := newStandardMeter()\n\tarbiter.Lock()\n\tdefer arbiter.Unlock()\n\tarbiter.meters[m] = struct{}{}\n\tif !arbiter.started {\n\t\tarbiter.started = true\n\t\tgo arbiter.tick()\n\t}\n\treturn m\n}\n\n// NewMeter constructs and registers a new StandardMeter and launches a\n// goroutine.\n// Be sure to unregister the meter from the registry once it is of no use to\n// allow for garbage collection.\nfunc NewRegisteredMeter(name string, r Registry) Meter {\n\tc := NewMeter()\n\tif nil == r {\n\t\tr = DefaultRegistry\n\t}\n\tr.Register(name, c)\n\treturn c\n}\n\n// MeterSnapshot is a read-only copy of another Meter.\ntype MeterSnapshot struct {\n\tcount                          int64\n\trate1, rate5, rate15, rateMean uint64\n}\n\n// Count returns the count of events at the time the snapshot was taken.\nfunc (m *MeterSnapshot) Count() int64 { return m.count }\n\n// Mark panics.\nfunc (*MeterSnapshot) Mark(n int64) {\n\tpanic(\"Mark called on a MeterSnapshot\")\n}\n\n// Rate1 returns the one-minute moving average rate of events per second at the\n// time the snapshot was taken.\nfunc (m *MeterSnapshot) Rate1() float64 { return math.Float64frombits(m.rate1) }\n\n// Rate5 returns the five-minute moving average rate of events per second at\n// the time the snapshot was taken.\nfunc (m *MeterSnapshot) Rate5() float64 { return math.Float64frombits(m.rate5) }\n\n// Rate15 returns the fifteen-minute moving average rate of events per second\n// at the time the snapshot was taken.\nfunc (m *MeterSnapshot) Rate15() float64 { return math.Float64frombits(m.rate15) }\n\n// RateMean returns the meter's mean rate of events per second at the time the\n// snapshot was taken.\nfunc (m *MeterSnapshot) RateMean() float64 { return math.Float64frombits(m.rateMean) }\n\n// Snapshot returns the snapshot.\nfunc (m *MeterSnapshot) Snapshot() Meter { return m }\n\n// Stop is a no-op.\nfunc (m *MeterSnapshot) Stop() {}\n\n// NilMeter is a no-op Meter.\ntype NilMeter struct{}\n\n// Count is a no-op.\nfunc (NilMeter) Count() int64 { return 0 }\n\n// Mark is a no-op.\nfunc (NilMeter) Mark(n int64) {}\n\n// Rate1 is a no-op.\nfunc (NilMeter) Rate1() float64 { return 0.0 }\n\n// Rate5 is a no-op.\nfunc (NilMeter) Rate5() float64 { return 0.0 }\n\n// Rate15is a no-op.\nfunc (NilMeter) Rate15() float64 { return 0.0 }\n\n// RateMean is a no-op.\nfunc (NilMeter) RateMean() float64 { return 0.0 }\n\n// Snapshot is a no-op.\nfunc (NilMeter) Snapshot() Meter { return NilMeter{} }\n\n// Stop is a no-op.\nfunc (NilMeter) Stop() {}\n\n// StandardMeter is the standard implementation of a Meter.\ntype StandardMeter struct {\n\tsnapshot    *MeterSnapshot\n\ta1, a5, a15 EWMA\n\tstartTime   time.Time\n\tstopped     uint32\n}\n\nfunc newStandardMeter() *StandardMeter {\n\treturn &StandardMeter{\n\t\tsnapshot:  &MeterSnapshot{},\n\t\ta1:        NewEWMA1(),\n\t\ta5:        NewEWMA5(),\n\t\ta15:       NewEWMA15(),\n\t\tstartTime: time.Now(),\n\t}\n}\n\n// Stop stops the meter, Mark() will be a no-op if you use it after being stopped.\nfunc (m *StandardMeter) Stop() {\n\tif atomic.CompareAndSwapUint32(&m.stopped, 0, 1) {\n\t\tarbiter.Lock()\n\t\tdelete(arbiter.meters, m)\n\t\tarbiter.Unlock()\n\t}\n}\n\n// Count returns the number of events recorded.\nfunc (m *StandardMeter) Count() int64 {\n\treturn atomic.LoadInt64(&m.snapshot.count)\n}\n\n// Mark records the occurance of n events.\nfunc (m *StandardMeter) Mark(n int64) {\n\tif atomic.LoadUint32(&m.stopped) == 1 {\n\t\treturn\n\t}\n\n\tatomic.AddInt64(&m.snapshot.count, n)\n\n\tm.a1.Update(n)\n\tm.a5.Update(n)\n\tm.a15.Update(n)\n\tm.updateSnapshot()\n}\n\n// Rate1 returns the one-minute moving average rate of events per second.\nfunc (m *StandardMeter) Rate1() float64 {\n\treturn math.Float64frombits(atomic.LoadUint64(&m.snapshot.rate1))\n}\n\n// Rate5 returns the five-minute moving average rate of events per second.\nfunc (m *StandardMeter) Rate5() float64 {\n\treturn math.Float64frombits(atomic.LoadUint64(&m.snapshot.rate5))\n}\n\n// Rate15 returns the fifteen-minute moving average rate of events per second.\nfunc (m *StandardMeter) Rate15() float64 {\n\treturn math.Float64frombits(atomic.LoadUint64(&m.snapshot.rate15))\n}\n\n// RateMean returns the meter's mean rate of events per second.\nfunc (m *StandardMeter) RateMean() float64 {\n\treturn math.Float64frombits(atomic.LoadUint64(&m.snapshot.rateMean))\n}\n\n// Snapshot returns a read-only copy of the meter.\nfunc (m *StandardMeter) Snapshot() Meter {\n\tcopiedSnapshot := MeterSnapshot{\n\t\tcount:    atomic.LoadInt64(&m.snapshot.count),\n\t\trate1:    atomic.LoadUint64(&m.snapshot.rate1),\n\t\trate5:    atomic.LoadUint64(&m.snapshot.rate5),\n\t\trate15:   atomic.LoadUint64(&m.snapshot.rate15),\n\t\trateMean: atomic.LoadUint64(&m.snapshot.rateMean),\n\t}\n\treturn &copiedSnapshot\n}\n\nfunc (m *StandardMeter) updateSnapshot() {\n\trate1 := math.Float64bits(m.a1.Rate())\n\trate5 := math.Float64bits(m.a5.Rate())\n\trate15 := math.Float64bits(m.a15.Rate())\n\trateMean := math.Float64bits(float64(m.Count()) / time.Since(m.startTime).Seconds())\n\n\tatomic.StoreUint64(&m.snapshot.rate1, rate1)\n\tatomic.StoreUint64(&m.snapshot.rate5, rate5)\n\tatomic.StoreUint64(&m.snapshot.rate15, rate15)\n\tatomic.StoreUint64(&m.snapshot.rateMean, rateMean)\n}\n\nfunc (m *StandardMeter) tick() {\n\tm.a1.Tick()\n\tm.a5.Tick()\n\tm.a15.Tick()\n\tm.updateSnapshot()\n}\n\n// meterArbiter ticks meters every 5s from a single goroutine.\n// meters are references in a set for future stopping.\ntype meterArbiter struct {\n\tsync.RWMutex\n\tstarted bool\n\tmeters  map[*StandardMeter]struct{}\n\tticker  *time.Ticker\n}\n\nvar arbiter = meterArbiter{ticker: time.NewTicker(5e9), meters: make(map[*StandardMeter]struct{})}\n\n// Ticks meters on the scheduled interval\nfunc (ma *meterArbiter) tick() {\n\tfor {\n\t\tselect {\n\t\tcase <-ma.ticker.C:\n\t\t\tma.tickMeters()\n\t\t}\n\t}\n}\n\nfunc (ma *meterArbiter) tickMeters() {\n\tma.RLock()\n\tdefer ma.RUnlock()\n\tfor meter := range ma.meters {\n\t\tmeter.tick()\n\t}\n}\n"
        },
        {
          "name": "meter_test.go",
          "type": "blob",
          "size": 2.1171875,
          "content": "package metrics\n\nimport (\n\t\"math/rand\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc BenchmarkMeter(b *testing.B) {\n\tm := NewMeter()\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tm.Mark(1)\n\t}\n}\n\nfunc BenchmarkMeterParallel(b *testing.B) {\n\tm := NewMeter()\n\tb.ResetTimer()\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tfor pb.Next() {\n\t\t\tm.Mark(1)\n\t\t}\n\t})\n}\n\n// exercise race detector\nfunc TestMeterConcurrency(t *testing.T) {\n\trand.Seed(time.Now().Unix())\n\tma := meterArbiter{\n\t\tticker: time.NewTicker(time.Millisecond),\n\t\tmeters: make(map[*StandardMeter]struct{}),\n\t}\n\tm := newStandardMeter()\n\tma.meters[m] = struct{}{}\n\tgo ma.tick()\n\twg := &sync.WaitGroup{}\n\treps := 100\n\tfor i := 0; i < reps; i++ {\n\t\twg.Add(1)\n\t\tgo func(m Meter, wg *sync.WaitGroup) {\n\t\t\tm.Mark(1)\n\t\t\twg.Done()\n\t\t}(m, wg)\n\t\twg.Add(1)\n\t\tgo func(m Meter, wg *sync.WaitGroup) {\n\t\t\tm.Stop()\n\t\t\twg.Done()\n\t\t}(m, wg)\n\t}\n\twg.Wait()\n}\n\nfunc TestGetOrRegisterMeter(t *testing.T) {\n\tr := NewRegistry()\n\tNewRegisteredMeter(\"foo\", r).Mark(47)\n\tif m := GetOrRegisterMeter(\"foo\", r); 47 != m.Count() {\n\t\tt.Fatal(m)\n\t}\n}\n\nfunc TestMeterDecay(t *testing.T) {\n\tma := meterArbiter{\n\t\tticker: time.NewTicker(time.Millisecond),\n\t\tmeters: make(map[*StandardMeter]struct{}),\n\t}\n\tm := newStandardMeter()\n\tma.meters[m] = struct{}{}\n\tgo ma.tick()\n\tm.Mark(1)\n\trateMean := m.RateMean()\n\ttime.Sleep(100 * time.Millisecond)\n\tif m.RateMean() >= rateMean {\n\t\tt.Error(\"m.RateMean() didn't decrease\")\n\t}\n}\n\nfunc TestMeterNonzero(t *testing.T) {\n\tm := NewMeter()\n\tm.Mark(3)\n\tif count := m.Count(); 3 != count {\n\t\tt.Errorf(\"m.Count(): 3 != %v\\n\", count)\n\t}\n}\n\nfunc TestMeterStop(t *testing.T) {\n\tl := len(arbiter.meters)\n\tm := NewMeter()\n\tif len(arbiter.meters) != l+1 {\n\t\tt.Errorf(\"arbiter.meters: %d != %d\\n\", l+1, len(arbiter.meters))\n\t}\n\tm.Stop()\n\tif len(arbiter.meters) != l {\n\t\tt.Errorf(\"arbiter.meters: %d != %d\\n\", l, len(arbiter.meters))\n\t}\n}\n\nfunc TestMeterSnapshot(t *testing.T) {\n\tm := NewMeter()\n\tm.Mark(1)\n\tif snapshot := m.Snapshot(); m.RateMean() != snapshot.RateMean() {\n\t\tt.Fatal(snapshot)\n\t}\n}\n\nfunc TestMeterZero(t *testing.T) {\n\tm := NewMeter()\n\tif count := m.Count(); 0 != count {\n\t\tt.Errorf(\"m.Count(): 0 != %v\\n\", count)\n\t}\n}\n"
        },
        {
          "name": "metrics.go",
          "type": "blob",
          "size": 0.4501953125,
          "content": "// Go port of Coda Hale's Metrics library\n//\n// <https://github.com/rcrowley/go-metrics>\n//\n// Coda Hale's original work: <https://github.com/codahale/metrics>\npackage metrics\n\n// UseNilMetrics is checked by the constructor functions for all of the\n// standard metrics.  If it is true, the metric returned is a stub.\n//\n// This global kill-switch helps quantify the observer effect and makes\n// for less cluttered pprof profiles.\nvar UseNilMetrics bool = false\n"
        },
        {
          "name": "metrics_test.go",
          "type": "blob",
          "size": 2.03125,
          "content": "package metrics\n\nimport (\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"sync\"\n\t\"testing\"\n)\n\nconst FANOUT = 128\n\n// Stop the compiler from complaining during debugging.\nvar (\n\t_ = ioutil.Discard\n\t_ = log.LstdFlags\n)\n\nfunc BenchmarkMetrics(b *testing.B) {\n\tr := NewRegistry()\n\tc := NewRegisteredCounter(\"counter\", r)\n\tg := NewRegisteredGauge(\"gauge\", r)\n\tgf := NewRegisteredGaugeFloat64(\"gaugefloat64\", r)\n\th := NewRegisteredHistogram(\"histogram\", r, NewUniformSample(100))\n\tm := NewRegisteredMeter(\"meter\", r)\n\tt := NewRegisteredTimer(\"timer\", r)\n\tRegisterDebugGCStats(r)\n\tRegisterRuntimeMemStats(r)\n\tb.ResetTimer()\n\tch := make(chan bool)\n\n\twgD := &sync.WaitGroup{}\n\t/*\n\t\twgD.Add(1)\n\t\tgo func() {\n\t\t\tdefer wgD.Done()\n\t\t\t//log.Println(\"go CaptureDebugGCStats\")\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ch:\n\t\t\t\t\t//log.Println(\"done CaptureDebugGCStats\")\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t\tCaptureDebugGCStatsOnce(r)\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t//*/\n\n\twgR := &sync.WaitGroup{}\n\t//*\n\twgR.Add(1)\n\tgo func() {\n\t\tdefer wgR.Done()\n\t\t//log.Println(\"go CaptureRuntimeMemStats\")\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ch:\n\t\t\t\t//log.Println(\"done CaptureRuntimeMemStats\")\n\t\t\t\treturn\n\t\t\tdefault:\n\t\t\t\tCaptureRuntimeMemStatsOnce(r)\n\t\t\t}\n\t\t}\n\t}()\n\t//*/\n\n\twgW := &sync.WaitGroup{}\n\t/*\n\t\twgW.Add(1)\n\t\tgo func() {\n\t\t\tdefer wgW.Done()\n\t\t\t//log.Println(\"go Write\")\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ch:\n\t\t\t\t\t//log.Println(\"done Write\")\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t\tWriteOnce(r, ioutil.Discard)\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t//*/\n\n\twg := &sync.WaitGroup{}\n\twg.Add(FANOUT)\n\tfor i := 0; i < FANOUT; i++ {\n\t\tgo func(i int) {\n\t\t\tdefer wg.Done()\n\t\t\t//log.Println(\"go\", i)\n\t\t\tfor i := 0; i < b.N; i++ {\n\t\t\t\tc.Inc(1)\n\t\t\t\tg.Update(int64(i))\n\t\t\t\tgf.Update(float64(i))\n\t\t\t\th.Update(int64(i))\n\t\t\t\tm.Mark(1)\n\t\t\t\tt.Update(1)\n\t\t\t}\n\t\t\t//log.Println(\"done\", i)\n\t\t}(i)\n\t}\n\twg.Wait()\n\tclose(ch)\n\twgD.Wait()\n\twgR.Wait()\n\twgW.Wait()\n}\n\nfunc Example() {\n\tc := NewCounter()\n\tRegister(\"money\", c)\n\tc.Inc(17)\n\n\t// Threadsafe registration\n\tt := GetOrRegisterTimer(\"db.get.latency\", nil)\n\tt.Time(func() {})\n\tt.Update(1)\n\n\tfmt.Println(c.Count())\n\tfmt.Println(t.Min())\n\t// Output: 17\n\t// 1\n}\n"
        },
        {
          "name": "opentsdb.go",
          "type": "blob",
          "size": 5.4150390625,
          "content": "package metrics\n\nimport (\n\t\"bufio\"\n\t\"fmt\"\n\t\"log\"\n\t\"net\"\n\t\"os\"\n\t\"strings\"\n\t\"time\"\n)\n\nvar shortHostName string = \"\"\n\n// OpenTSDBConfig provides a container with configuration parameters for\n// the OpenTSDB exporter\ntype OpenTSDBConfig struct {\n\tAddr          *net.TCPAddr  // Network address to connect to\n\tRegistry      Registry      // Registry to be exported\n\tFlushInterval time.Duration // Flush interval\n\tDurationUnit  time.Duration // Time conversion unit for durations\n\tPrefix        string        // Prefix to be prepended to metric names\n}\n\n// OpenTSDB is a blocking exporter function which reports metrics in r\n// to a TSDB server located at addr, flushing them every d duration\n// and prepending metric names with prefix.\nfunc OpenTSDB(r Registry, d time.Duration, prefix string, addr *net.TCPAddr) {\n\tOpenTSDBWithConfig(OpenTSDBConfig{\n\t\tAddr:          addr,\n\t\tRegistry:      r,\n\t\tFlushInterval: d,\n\t\tDurationUnit:  time.Nanosecond,\n\t\tPrefix:        prefix,\n\t})\n}\n\n// OpenTSDBWithConfig is a blocking exporter function just like OpenTSDB,\n// but it takes a OpenTSDBConfig instead.\nfunc OpenTSDBWithConfig(c OpenTSDBConfig) {\n\tfor _ = range time.Tick(c.FlushInterval) {\n\t\tif err := openTSDB(&c); nil != err {\n\t\t\tlog.Println(err)\n\t\t}\n\t}\n}\n\nfunc getShortHostname() string {\n\tif shortHostName == \"\" {\n\t\thost, _ := os.Hostname()\n\t\tif index := strings.Index(host, \".\"); index > 0 {\n\t\t\tshortHostName = host[:index]\n\t\t} else {\n\t\t\tshortHostName = host\n\t\t}\n\t}\n\treturn shortHostName\n}\n\nfunc openTSDB(c *OpenTSDBConfig) error {\n\tshortHostname := getShortHostname()\n\tnow := time.Now().Unix()\n\tdu := float64(c.DurationUnit)\n\tconn, err := net.DialTCP(\"tcp\", nil, c.Addr)\n\tif nil != err {\n\t\treturn err\n\t}\n\tdefer conn.Close()\n\tw := bufio.NewWriter(conn)\n\tc.Registry.Each(func(name string, i interface{}) {\n\t\tswitch metric := i.(type) {\n\t\tcase Counter:\n\t\t\tfmt.Fprintf(w, \"put %s.%s.count %d %d host=%s\\n\", c.Prefix, name, now, metric.Count(), shortHostname)\n\t\tcase Gauge:\n\t\t\tfmt.Fprintf(w, \"put %s.%s.value %d %d host=%s\\n\", c.Prefix, name, now, metric.Value(), shortHostname)\n\t\tcase GaugeFloat64:\n\t\t\tfmt.Fprintf(w, \"put %s.%s.value %d %f host=%s\\n\", c.Prefix, name, now, metric.Value(), shortHostname)\n\t\tcase Histogram:\n\t\t\th := metric.Snapshot()\n\t\t\tps := h.Percentiles([]float64{0.5, 0.75, 0.95, 0.99, 0.999})\n\t\t\tfmt.Fprintf(w, \"put %s.%s.count %d %d host=%s\\n\", c.Prefix, name, now, h.Count(), shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.min %d %d host=%s\\n\", c.Prefix, name, now, h.Min(), shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.max %d %d host=%s\\n\", c.Prefix, name, now, h.Max(), shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.mean %d %.2f host=%s\\n\", c.Prefix, name, now, h.Mean(), shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.std-dev %d %.2f host=%s\\n\", c.Prefix, name, now, h.StdDev(), shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.50-percentile %d %.2f host=%s\\n\", c.Prefix, name, now, ps[0], shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.75-percentile %d %.2f host=%s\\n\", c.Prefix, name, now, ps[1], shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.95-percentile %d %.2f host=%s\\n\", c.Prefix, name, now, ps[2], shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.99-percentile %d %.2f host=%s\\n\", c.Prefix, name, now, ps[3], shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.999-percentile %d %.2f host=%s\\n\", c.Prefix, name, now, ps[4], shortHostname)\n\t\tcase Meter:\n\t\t\tm := metric.Snapshot()\n\t\t\tfmt.Fprintf(w, \"put %s.%s.count %d %d host=%s\\n\", c.Prefix, name, now, m.Count(), shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.one-minute %d %.2f host=%s\\n\", c.Prefix, name, now, m.Rate1(), shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.five-minute %d %.2f host=%s\\n\", c.Prefix, name, now, m.Rate5(), shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.fifteen-minute %d %.2f host=%s\\n\", c.Prefix, name, now, m.Rate15(), shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.mean %d %.2f host=%s\\n\", c.Prefix, name, now, m.RateMean(), shortHostname)\n\t\tcase Timer:\n\t\t\tt := metric.Snapshot()\n\t\t\tps := t.Percentiles([]float64{0.5, 0.75, 0.95, 0.99, 0.999})\n\t\t\tfmt.Fprintf(w, \"put %s.%s.count %d %d host=%s\\n\", c.Prefix, name, now, t.Count(), shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.min %d %d host=%s\\n\", c.Prefix, name, now, t.Min()/int64(du), shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.max %d %d host=%s\\n\", c.Prefix, name, now, t.Max()/int64(du), shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.mean %d %.2f host=%s\\n\", c.Prefix, name, now, t.Mean()/du, shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.std-dev %d %.2f host=%s\\n\", c.Prefix, name, now, t.StdDev()/du, shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.50-percentile %d %.2f host=%s\\n\", c.Prefix, name, now, ps[0]/du, shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.75-percentile %d %.2f host=%s\\n\", c.Prefix, name, now, ps[1]/du, shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.95-percentile %d %.2f host=%s\\n\", c.Prefix, name, now, ps[2]/du, shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.99-percentile %d %.2f host=%s\\n\", c.Prefix, name, now, ps[3]/du, shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.999-percentile %d %.2f host=%s\\n\", c.Prefix, name, now, ps[4]/du, shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.one-minute %d %.2f host=%s\\n\", c.Prefix, name, now, t.Rate1(), shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.five-minute %d %.2f host=%s\\n\", c.Prefix, name, now, t.Rate5(), shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.fifteen-minute %d %.2f host=%s\\n\", c.Prefix, name, now, t.Rate15(), shortHostname)\n\t\t\tfmt.Fprintf(w, \"put %s.%s.mean-rate %d %.2f host=%s\\n\", c.Prefix, name, now, t.RateMean(), shortHostname)\n\t\t}\n\t\tw.Flush()\n\t})\n\treturn nil\n}\n"
        },
        {
          "name": "opentsdb_test.go",
          "type": "blob",
          "size": 0.427734375,
          "content": "package metrics\n\nimport (\n\t\"net\"\n\t\"time\"\n)\n\nfunc ExampleOpenTSDB() {\n\taddr, _ := net.ResolveTCPAddr(\"net\", \":2003\")\n\tgo OpenTSDB(DefaultRegistry, 1*time.Second, \"some.prefix\", addr)\n}\n\nfunc ExampleOpenTSDBWithConfig() {\n\taddr, _ := net.ResolveTCPAddr(\"net\", \":2003\")\n\tgo OpenTSDBWithConfig(OpenTSDBConfig{\n\t\tAddr:          addr,\n\t\tRegistry:      DefaultRegistry,\n\t\tFlushInterval: 1 * time.Second,\n\t\tDurationUnit:  time.Millisecond,\n\t})\n}\n"
        },
        {
          "name": "registry.go",
          "type": "blob",
          "size": 9.7890625,
          "content": "package metrics\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n\t\"strings\"\n\t\"sync\"\n)\n\n// DuplicateMetric is the error returned by Registry.Register when a metric\n// already exists.  If you mean to Register that metric you must first\n// Unregister the existing metric.\ntype DuplicateMetric string\n\nfunc (err DuplicateMetric) Error() string {\n\treturn fmt.Sprintf(\"duplicate metric: %s\", string(err))\n}\n\n// A Registry holds references to a set of metrics by name and can iterate\n// over them, calling callback functions provided by the user.\n//\n// This is an interface so as to encourage other structs to implement\n// the Registry API as appropriate.\ntype Registry interface {\n\n\t// Call the given function for each registered metric.\n\tEach(func(string, interface{}))\n\n\t// Get the metric by the given name or nil if none is registered.\n\tGet(string) interface{}\n\n\t// GetAll metrics in the Registry.\n\tGetAll() map[string]map[string]interface{}\n\n\t// Gets an existing metric or registers the given one.\n\t// The interface can be the metric to register if not found in registry,\n\t// or a function returning the metric for lazy instantiation.\n\tGetOrRegister(string, interface{}) interface{}\n\n\t// Register the given metric under the given name.\n\tRegister(string, interface{}) error\n\n\t// Run all registered healthchecks.\n\tRunHealthchecks()\n\n\t// Unregister the metric with the given name.\n\tUnregister(string)\n\n\t// Unregister all metrics.  (Mostly for testing.)\n\tUnregisterAll()\n}\n\n// The standard implementation of a Registry is a mutex-protected map\n// of names to metrics.\ntype StandardRegistry struct {\n\tmetrics map[string]interface{}\n\tmutex   sync.RWMutex\n}\n\n// Create a new registry.\nfunc NewRegistry() Registry {\n\treturn &StandardRegistry{metrics: make(map[string]interface{})}\n}\n\n// Call the given function for each registered metric.\nfunc (r *StandardRegistry) Each(f func(string, interface{})) {\n\tmetrics := r.registered()\n\tfor i := range metrics {\n\t\tkv := &metrics[i]\n\t\tf(kv.name, kv.value)\n\t}\n}\n\n// Get the metric by the given name or nil if none is registered.\nfunc (r *StandardRegistry) Get(name string) interface{} {\n\tr.mutex.RLock()\n\tdefer r.mutex.RUnlock()\n\treturn r.metrics[name]\n}\n\n// Gets an existing metric or creates and registers a new one. Threadsafe\n// alternative to calling Get and Register on failure.\n// The interface can be the metric to register if not found in registry,\n// or a function returning the metric for lazy instantiation.\nfunc (r *StandardRegistry) GetOrRegister(name string, i interface{}) interface{} {\n\t// access the read lock first which should be re-entrant\n\tr.mutex.RLock()\n\tmetric, ok := r.metrics[name]\n\tr.mutex.RUnlock()\n\tif ok {\n\t\treturn metric\n\t}\n\n\t// only take the write lock if we'll be modifying the metrics map\n\tr.mutex.Lock()\n\tdefer r.mutex.Unlock()\n\tif metric, ok := r.metrics[name]; ok {\n\t\treturn metric\n\t}\n\tif v := reflect.ValueOf(i); v.Kind() == reflect.Func {\n\t\ti = v.Call(nil)[0].Interface()\n\t}\n\tr.register(name, i)\n\treturn i\n}\n\n// Register the given metric under the given name.  Returns a DuplicateMetric\n// if a metric by the given name is already registered.\nfunc (r *StandardRegistry) Register(name string, i interface{}) error {\n\tr.mutex.Lock()\n\tdefer r.mutex.Unlock()\n\treturn r.register(name, i)\n}\n\n// Run all registered healthchecks.\nfunc (r *StandardRegistry) RunHealthchecks() {\n\tr.mutex.RLock()\n\tdefer r.mutex.RUnlock()\n\tfor _, i := range r.metrics {\n\t\tif h, ok := i.(Healthcheck); ok {\n\t\t\th.Check()\n\t\t}\n\t}\n}\n\n// GetAll metrics in the Registry\nfunc (r *StandardRegistry) GetAll() map[string]map[string]interface{} {\n\tdata := make(map[string]map[string]interface{})\n\tr.Each(func(name string, i interface{}) {\n\t\tvalues := make(map[string]interface{})\n\t\tswitch metric := i.(type) {\n\t\tcase Counter:\n\t\t\tvalues[\"count\"] = metric.Count()\n\t\tcase Gauge:\n\t\t\tvalues[\"value\"] = metric.Value()\n\t\tcase GaugeFloat64:\n\t\t\tvalues[\"value\"] = metric.Value()\n\t\tcase Healthcheck:\n\t\t\tvalues[\"error\"] = nil\n\t\t\tmetric.Check()\n\t\t\tif err := metric.Error(); nil != err {\n\t\t\t\tvalues[\"error\"] = metric.Error().Error()\n\t\t\t}\n\t\tcase Histogram:\n\t\t\th := metric.Snapshot()\n\t\t\tps := h.Percentiles([]float64{0.5, 0.75, 0.95, 0.99, 0.999})\n\t\t\tvalues[\"count\"] = h.Count()\n\t\t\tvalues[\"min\"] = h.Min()\n\t\t\tvalues[\"max\"] = h.Max()\n\t\t\tvalues[\"mean\"] = h.Mean()\n\t\t\tvalues[\"stddev\"] = h.StdDev()\n\t\t\tvalues[\"median\"] = ps[0]\n\t\t\tvalues[\"75%\"] = ps[1]\n\t\t\tvalues[\"95%\"] = ps[2]\n\t\t\tvalues[\"99%\"] = ps[3]\n\t\t\tvalues[\"99.9%\"] = ps[4]\n\t\tcase Meter:\n\t\t\tm := metric.Snapshot()\n\t\t\tvalues[\"count\"] = m.Count()\n\t\t\tvalues[\"1m.rate\"] = m.Rate1()\n\t\t\tvalues[\"5m.rate\"] = m.Rate5()\n\t\t\tvalues[\"15m.rate\"] = m.Rate15()\n\t\t\tvalues[\"mean.rate\"] = m.RateMean()\n\t\tcase Timer:\n\t\t\tt := metric.Snapshot()\n\t\t\tps := t.Percentiles([]float64{0.5, 0.75, 0.95, 0.99, 0.999})\n\t\t\tvalues[\"count\"] = t.Count()\n\t\t\tvalues[\"min\"] = t.Min()\n\t\t\tvalues[\"max\"] = t.Max()\n\t\t\tvalues[\"mean\"] = t.Mean()\n\t\t\tvalues[\"stddev\"] = t.StdDev()\n\t\t\tvalues[\"median\"] = ps[0]\n\t\t\tvalues[\"75%\"] = ps[1]\n\t\t\tvalues[\"95%\"] = ps[2]\n\t\t\tvalues[\"99%\"] = ps[3]\n\t\t\tvalues[\"99.9%\"] = ps[4]\n\t\t\tvalues[\"1m.rate\"] = t.Rate1()\n\t\t\tvalues[\"5m.rate\"] = t.Rate5()\n\t\t\tvalues[\"15m.rate\"] = t.Rate15()\n\t\t\tvalues[\"mean.rate\"] = t.RateMean()\n\t\t}\n\t\tdata[name] = values\n\t})\n\treturn data\n}\n\n// Unregister the metric with the given name.\nfunc (r *StandardRegistry) Unregister(name string) {\n\tr.mutex.Lock()\n\tdefer r.mutex.Unlock()\n\tr.stop(name)\n\tdelete(r.metrics, name)\n}\n\n// Unregister all metrics.  (Mostly for testing.)\nfunc (r *StandardRegistry) UnregisterAll() {\n\tr.mutex.Lock()\n\tdefer r.mutex.Unlock()\n\tfor name, _ := range r.metrics {\n\t\tr.stop(name)\n\t\tdelete(r.metrics, name)\n\t}\n}\n\nfunc (r *StandardRegistry) register(name string, i interface{}) error {\n\tif _, ok := r.metrics[name]; ok {\n\t\treturn DuplicateMetric(name)\n\t}\n\tswitch i.(type) {\n\tcase Counter, Gauge, GaugeFloat64, Healthcheck, Histogram, Meter, Timer:\n\t\tr.metrics[name] = i\n\t}\n\treturn nil\n}\n\ntype metricKV struct {\n\tname  string\n\tvalue interface{}\n}\n\nfunc (r *StandardRegistry) registered() []metricKV {\n\tr.mutex.RLock()\n\tdefer r.mutex.RUnlock()\n\tmetrics := make([]metricKV, 0, len(r.metrics))\n\tfor name, i := range r.metrics {\n\t\tmetrics = append(metrics, metricKV{\n\t\t\tname:  name,\n\t\t\tvalue: i,\n\t\t})\n\t}\n\treturn metrics\n}\n\nfunc (r *StandardRegistry) stop(name string) {\n\tif i, ok := r.metrics[name]; ok {\n\t\tif s, ok := i.(Stoppable); ok {\n\t\t\ts.Stop()\n\t\t}\n\t}\n}\n\n// Stoppable defines the metrics which has to be stopped.\ntype Stoppable interface {\n\tStop()\n}\n\ntype PrefixedRegistry struct {\n\tunderlying Registry\n\tprefix     string\n}\n\nfunc NewPrefixedRegistry(prefix string) Registry {\n\treturn &PrefixedRegistry{\n\t\tunderlying: NewRegistry(),\n\t\tprefix:     prefix,\n\t}\n}\n\nfunc NewPrefixedChildRegistry(parent Registry, prefix string) Registry {\n\treturn &PrefixedRegistry{\n\t\tunderlying: parent,\n\t\tprefix:     prefix,\n\t}\n}\n\n// Call the given function for each registered metric.\nfunc (r *PrefixedRegistry) Each(fn func(string, interface{})) {\n\twrappedFn := func(prefix string) func(string, interface{}) {\n\t\treturn func(name string, iface interface{}) {\n\t\t\tif strings.HasPrefix(name, prefix) {\n\t\t\t\tfn(name, iface)\n\t\t\t} else {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\n\tbaseRegistry, prefix := findPrefix(r, \"\")\n\tbaseRegistry.Each(wrappedFn(prefix))\n}\n\nfunc findPrefix(registry Registry, prefix string) (Registry, string) {\n\tswitch r := registry.(type) {\n\tcase *PrefixedRegistry:\n\t\treturn findPrefix(r.underlying, r.prefix+prefix)\n\tcase *StandardRegistry:\n\t\treturn r, prefix\n\t}\n\treturn nil, \"\"\n}\n\n// Get the metric by the given name or nil if none is registered.\nfunc (r *PrefixedRegistry) Get(name string) interface{} {\n\trealName := r.prefix + name\n\treturn r.underlying.Get(realName)\n}\n\n// Gets an existing metric or registers the given one.\n// The interface can be the metric to register if not found in registry,\n// or a function returning the metric for lazy instantiation.\nfunc (r *PrefixedRegistry) GetOrRegister(name string, metric interface{}) interface{} {\n\trealName := r.prefix + name\n\treturn r.underlying.GetOrRegister(realName, metric)\n}\n\n// Register the given metric under the given name. The name will be prefixed.\nfunc (r *PrefixedRegistry) Register(name string, metric interface{}) error {\n\trealName := r.prefix + name\n\treturn r.underlying.Register(realName, metric)\n}\n\n// Run all registered healthchecks.\nfunc (r *PrefixedRegistry) RunHealthchecks() {\n\tr.underlying.RunHealthchecks()\n}\n\n// GetAll metrics in the Registry\nfunc (r *PrefixedRegistry) GetAll() map[string]map[string]interface{} {\n\treturn r.underlying.GetAll()\n}\n\n// Unregister the metric with the given name. The name will be prefixed.\nfunc (r *PrefixedRegistry) Unregister(name string) {\n\trealName := r.prefix + name\n\tr.underlying.Unregister(realName)\n}\n\n// Unregister all metrics.  (Mostly for testing.)\nfunc (r *PrefixedRegistry) UnregisterAll() {\n\tr.underlying.UnregisterAll()\n}\n\nvar DefaultRegistry Registry = NewRegistry()\n\n// Call the given function for each registered metric.\nfunc Each(f func(string, interface{})) {\n\tDefaultRegistry.Each(f)\n}\n\n// Get the metric by the given name or nil if none is registered.\nfunc Get(name string) interface{} {\n\treturn DefaultRegistry.Get(name)\n}\n\n// Gets an existing metric or creates and registers a new one. Threadsafe\n// alternative to calling Get and Register on failure.\nfunc GetOrRegister(name string, i interface{}) interface{} {\n\treturn DefaultRegistry.GetOrRegister(name, i)\n}\n\n// Register the given metric under the given name.  Returns a DuplicateMetric\n// if a metric by the given name is already registered.\nfunc Register(name string, i interface{}) error {\n\treturn DefaultRegistry.Register(name, i)\n}\n\n// Register the given metric under the given name.  Panics if a metric by the\n// given name is already registered.\nfunc MustRegister(name string, i interface{}) {\n\tif err := Register(name, i); err != nil {\n\t\tpanic(err)\n\t}\n}\n\n// Run all registered healthchecks.\nfunc RunHealthchecks() {\n\tDefaultRegistry.RunHealthchecks()\n}\n\n// Unregister the metric with the given name.\nfunc Unregister(name string) {\n\tDefaultRegistry.Unregister(name)\n}\n"
        },
        {
          "name": "registry_test.go",
          "type": "blob",
          "size": 7.29296875,
          "content": "package metrics\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"testing\"\n)\n\nfunc BenchmarkRegistry(b *testing.B) {\n\tr := NewRegistry()\n\tr.Register(\"foo\", NewCounter())\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tr.Each(func(string, interface{}) {})\n\t}\n}\n\nfunc BenchmarkHugeRegistry(b *testing.B) {\n\tr := NewRegistry()\n\tfor i := 0; i < 10000; i++ {\n\t\tr.Register(fmt.Sprintf(\"foo%07d\", i), NewCounter())\n\t}\n\tv := make([]string, 10000)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tv := v[:0]\n\t\tr.Each(func(k string, _ interface{}) {\n\t\t\tv = append(v, k)\n\t\t})\n\t}\n}\n\nfunc BenchmarkRegistryParallel(b *testing.B) {\n\tr := NewRegistry()\n\tb.ResetTimer()\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tfor pb.Next() {\n\t\t\tr.GetOrRegister(\"foo\", NewCounter())\n\t\t}\n\t})\n}\n\nfunc TestRegistry(t *testing.T) {\n\tr := NewRegistry()\n\tr.Register(\"foo\", NewCounter())\n\ti := 0\n\tr.Each(func(name string, iface interface{}) {\n\t\ti++\n\t\tif \"foo\" != name {\n\t\t\tt.Fatal(name)\n\t\t}\n\t\tif _, ok := iface.(Counter); !ok {\n\t\t\tt.Fatal(iface)\n\t\t}\n\t})\n\tif 1 != i {\n\t\tt.Fatal(i)\n\t}\n\tr.Unregister(\"foo\")\n\ti = 0\n\tr.Each(func(string, interface{}) { i++ })\n\tif 0 != i {\n\t\tt.Fatal(i)\n\t}\n}\n\nfunc TestRegistryDuplicate(t *testing.T) {\n\tr := NewRegistry()\n\tif err := r.Register(\"foo\", NewCounter()); nil != err {\n\t\tt.Fatal(err)\n\t}\n\tif err := r.Register(\"foo\", NewGauge()); nil == err {\n\t\tt.Fatal(err)\n\t}\n\ti := 0\n\tr.Each(func(name string, iface interface{}) {\n\t\ti++\n\t\tif _, ok := iface.(Counter); !ok {\n\t\t\tt.Fatal(iface)\n\t\t}\n\t})\n\tif 1 != i {\n\t\tt.Fatal(i)\n\t}\n}\n\nfunc TestRegistryGet(t *testing.T) {\n\tr := NewRegistry()\n\tr.Register(\"foo\", NewCounter())\n\tif count := r.Get(\"foo\").(Counter).Count(); 0 != count {\n\t\tt.Fatal(count)\n\t}\n\tr.Get(\"foo\").(Counter).Inc(1)\n\tif count := r.Get(\"foo\").(Counter).Count(); 1 != count {\n\t\tt.Fatal(count)\n\t}\n}\n\nfunc TestRegistryGetOrRegister(t *testing.T) {\n\tr := NewRegistry()\n\n\t// First metric wins with GetOrRegister\n\t_ = r.GetOrRegister(\"foo\", NewCounter())\n\tm := r.GetOrRegister(\"foo\", NewGauge())\n\tif _, ok := m.(Counter); !ok {\n\t\tt.Fatal(m)\n\t}\n\n\ti := 0\n\tr.Each(func(name string, iface interface{}) {\n\t\ti++\n\t\tif name != \"foo\" {\n\t\t\tt.Fatal(name)\n\t\t}\n\t\tif _, ok := iface.(Counter); !ok {\n\t\t\tt.Fatal(iface)\n\t\t}\n\t})\n\tif i != 1 {\n\t\tt.Fatal(i)\n\t}\n}\n\nfunc TestRegistryGetOrRegisterWithLazyInstantiation(t *testing.T) {\n\tr := NewRegistry()\n\n\t// First metric wins with GetOrRegister\n\t_ = r.GetOrRegister(\"foo\", NewCounter)\n\tm := r.GetOrRegister(\"foo\", NewGauge)\n\tif _, ok := m.(Counter); !ok {\n\t\tt.Fatal(m)\n\t}\n\n\ti := 0\n\tr.Each(func(name string, iface interface{}) {\n\t\ti++\n\t\tif name != \"foo\" {\n\t\t\tt.Fatal(name)\n\t\t}\n\t\tif _, ok := iface.(Counter); !ok {\n\t\t\tt.Fatal(iface)\n\t\t}\n\t})\n\tif i != 1 {\n\t\tt.Fatal(i)\n\t}\n}\n\nfunc TestRegistryUnregister(t *testing.T) {\n\tl := len(arbiter.meters)\n\tr := NewRegistry()\n\tr.Register(\"foo\", NewCounter())\n\tr.Register(\"bar\", NewMeter())\n\tr.Register(\"baz\", NewTimer())\n\tif len(arbiter.meters) != l+2 {\n\t\tt.Errorf(\"arbiter.meters: %d != %d\\n\", l+2, len(arbiter.meters))\n\t}\n\tr.Unregister(\"foo\")\n\tr.Unregister(\"bar\")\n\tr.Unregister(\"baz\")\n\tif len(arbiter.meters) != l {\n\t\tt.Errorf(\"arbiter.meters: %d != %d\\n\", l+2, len(arbiter.meters))\n\t}\n}\n\nfunc TestPrefixedChildRegistryGetOrRegister(t *testing.T) {\n\tr := NewRegistry()\n\tpr := NewPrefixedChildRegistry(r, \"prefix.\")\n\n\t_ = pr.GetOrRegister(\"foo\", NewCounter())\n\n\ti := 0\n\tr.Each(func(name string, m interface{}) {\n\t\ti++\n\t\tif name != \"prefix.foo\" {\n\t\t\tt.Fatal(name)\n\t\t}\n\t})\n\tif i != 1 {\n\t\tt.Fatal(i)\n\t}\n}\n\nfunc TestPrefixedRegistryGetOrRegister(t *testing.T) {\n\tr := NewPrefixedRegistry(\"prefix.\")\n\n\t_ = r.GetOrRegister(\"foo\", NewCounter())\n\n\ti := 0\n\tr.Each(func(name string, m interface{}) {\n\t\ti++\n\t\tif name != \"prefix.foo\" {\n\t\t\tt.Fatal(name)\n\t\t}\n\t})\n\tif i != 1 {\n\t\tt.Fatal(i)\n\t}\n}\n\nfunc TestPrefixedRegistryRegister(t *testing.T) {\n\tr := NewPrefixedRegistry(\"prefix.\")\n\terr := r.Register(\"foo\", NewCounter())\n\tc := NewCounter()\n\tRegister(\"bar\", c)\n\tif err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\n\ti := 0\n\tr.Each(func(name string, m interface{}) {\n\t\ti++\n\t\tif name != \"prefix.foo\" {\n\t\t\tt.Fatal(name)\n\t\t}\n\t})\n\tif i != 1 {\n\t\tt.Fatal(i)\n\t}\n}\n\nfunc TestPrefixedRegistryUnregister(t *testing.T) {\n\tr := NewPrefixedRegistry(\"prefix.\")\n\n\t_ = r.Register(\"foo\", NewCounter())\n\n\ti := 0\n\tr.Each(func(name string, m interface{}) {\n\t\ti++\n\t\tif name != \"prefix.foo\" {\n\t\t\tt.Fatal(name)\n\t\t}\n\t})\n\tif i != 1 {\n\t\tt.Fatal(i)\n\t}\n\n\tr.Unregister(\"foo\")\n\n\ti = 0\n\tr.Each(func(name string, m interface{}) {\n\t\ti++\n\t})\n\n\tif i != 0 {\n\t\tt.Fatal(i)\n\t}\n}\n\nfunc TestPrefixedRegistryGet(t *testing.T) {\n\tpr := NewPrefixedRegistry(\"prefix.\")\n\tname := \"foo\"\n\tpr.Register(name, NewCounter())\n\n\tfooCounter := pr.Get(name)\n\tif fooCounter == nil {\n\t\tt.Fatal(name)\n\t}\n}\n\nfunc TestPrefixedChildRegistryGet(t *testing.T) {\n\tr := NewRegistry()\n\tpr := NewPrefixedChildRegistry(r, \"prefix.\")\n\tname := \"foo\"\n\tpr.Register(name, NewCounter())\n\tfooCounter := pr.Get(name)\n\tif fooCounter == nil {\n\t\tt.Fatal(name)\n\t}\n}\n\nfunc TestChildPrefixedRegistryRegister(t *testing.T) {\n\tr := NewPrefixedChildRegistry(DefaultRegistry, \"prefix.\")\n\terr := r.Register(\"foo\", NewCounter())\n\tc := NewCounter()\n\tRegister(\"bar\", c)\n\tif err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\n\ti := 0\n\tr.Each(func(name string, m interface{}) {\n\t\ti++\n\t\tif name != \"prefix.foo\" {\n\t\t\tt.Fatal(name)\n\t\t}\n\t})\n\tif i != 1 {\n\t\tt.Fatal(i)\n\t}\n}\n\nfunc TestChildPrefixedRegistryOfChildRegister(t *testing.T) {\n\tr := NewPrefixedChildRegistry(NewRegistry(), \"prefix.\")\n\tr2 := NewPrefixedChildRegistry(r, \"prefix2.\")\n\terr := r.Register(\"foo2\", NewCounter())\n\tif err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\terr = r2.Register(\"baz\", NewCounter())\n\tc := NewCounter()\n\tRegister(\"bars\", c)\n\n\ti := 0\n\tr2.Each(func(name string, m interface{}) {\n\t\ti++\n\t\tif name != \"prefix.prefix2.baz\" {\n\t\t\t//t.Fatal(name)\n\t\t}\n\t})\n\tif i != 1 {\n\t\tt.Fatal(i)\n\t}\n}\n\nfunc TestWalkRegistries(t *testing.T) {\n\tr := NewPrefixedChildRegistry(NewRegistry(), \"prefix.\")\n\tr2 := NewPrefixedChildRegistry(r, \"prefix2.\")\n\terr := r.Register(\"foo2\", NewCounter())\n\tif err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\terr = r2.Register(\"baz\", NewCounter())\n\tc := NewCounter()\n\tRegister(\"bars\", c)\n\n\t_, prefix := findPrefix(r2, \"\")\n\tif \"prefix.prefix2.\" != prefix {\n\t\tt.Fatal(prefix)\n\t}\n}\n\nfunc TestConcurrentRegistryAccess(t *testing.T) {\n\tr := NewRegistry()\n\n\tcounter := NewCounter()\n\n\tsignalChan := make(chan struct{})\n\n\tvar wg sync.WaitGroup\n\tfor i := 0; i < 10; i++ {\n\t\twg.Add(1)\n\t\tgo func(dowork chan struct{}) {\n\t\t\tdefer wg.Done()\n\t\t\tiface := r.GetOrRegister(\"foo\", counter)\n\t\t\tretCounter, ok := iface.(Counter)\n\t\t\tif !ok {\n\t\t\t\tt.Fatal(\"Expected a Counter type\")\n\t\t\t}\n\t\t\tif retCounter != counter {\n\t\t\t\tt.Fatal(\"Counter references don't match\")\n\t\t\t}\n\t\t}(signalChan)\n\t}\n\n\tclose(signalChan) // Closing will cause all go routines to execute at the same time\n\twg.Wait()         // Wait for all go routines to do their work\n\n\t// At the end of the test we should still only have a single \"foo\" Counter\n\ti := 0\n\tr.Each(func(name string, iface interface{}) {\n\t\ti++\n\t\tif \"foo\" != name {\n\t\t\tt.Fatal(name)\n\t\t}\n\t\tif _, ok := iface.(Counter); !ok {\n\t\t\tt.Fatal(iface)\n\t\t}\n\t})\n\tif 1 != i {\n\t\tt.Fatal(i)\n\t}\n\tr.Unregister(\"foo\")\n\ti = 0\n\tr.Each(func(string, interface{}) { i++ })\n\tif 0 != i {\n\t\tt.Fatal(i)\n\t}\n}\n\n// exercise race detector\nfunc TestRegisterAndRegisteredConcurrency(t *testing.T) {\n\tr := NewRegistry()\n\twg := &sync.WaitGroup{}\n\twg.Add(1)\n\tgo func(r Registry, wg *sync.WaitGroup) {\n\t\tdefer wg.Done()\n\t\tr.Each(func(name string, iface interface{}) {\n\t\t})\n\t}(r, wg)\n\tr.Register(\"foo\", NewCounter())\n\twg.Wait()\n}\n"
        },
        {
          "name": "runtime.go",
          "type": "blob",
          "size": 8.7900390625,
          "content": "package metrics\n\nimport (\n\t\"runtime\"\n\t\"runtime/pprof\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar (\n\tmemStats       runtime.MemStats\n\truntimeMetrics struct {\n\t\tMemStats struct {\n\t\t\tAlloc         Gauge\n\t\t\tBuckHashSys   Gauge\n\t\t\tDebugGC       Gauge\n\t\t\tEnableGC      Gauge\n\t\t\tFrees         Gauge\n\t\t\tHeapAlloc     Gauge\n\t\t\tHeapIdle      Gauge\n\t\t\tHeapInuse     Gauge\n\t\t\tHeapObjects   Gauge\n\t\t\tHeapReleased  Gauge\n\t\t\tHeapSys       Gauge\n\t\t\tLastGC        Gauge\n\t\t\tLookups       Gauge\n\t\t\tMallocs       Gauge\n\t\t\tMCacheInuse   Gauge\n\t\t\tMCacheSys     Gauge\n\t\t\tMSpanInuse    Gauge\n\t\t\tMSpanSys      Gauge\n\t\t\tNextGC        Gauge\n\t\t\tNumGC         Gauge\n\t\t\tGCCPUFraction GaugeFloat64\n\t\t\tPauseNs       Histogram\n\t\t\tPauseTotalNs  Gauge\n\t\t\tStackInuse    Gauge\n\t\t\tStackSys      Gauge\n\t\t\tSys           Gauge\n\t\t\tTotalAlloc    Gauge\n\t\t}\n\t\tNumCgoCall   Gauge\n\t\tNumGoroutine Gauge\n\t\tNumThread    Gauge\n\t\tReadMemStats Timer\n\t}\n\tfrees       uint64\n\tlookups     uint64\n\tmallocs     uint64\n\tnumGC       uint32\n\tnumCgoCalls int64\n\n\tthreadCreateProfile        = pprof.Lookup(\"threadcreate\")\n\tregisterRuntimeMetricsOnce = sync.Once{}\n)\n\n// Capture new values for the Go runtime statistics exported in\n// runtime.MemStats.  This is designed to be called as a goroutine.\nfunc CaptureRuntimeMemStats(r Registry, d time.Duration) {\n\tfor _ = range time.Tick(d) {\n\t\tCaptureRuntimeMemStatsOnce(r)\n\t}\n}\n\n// Capture new values for the Go runtime statistics exported in\n// runtime.MemStats.  This is designed to be called in a background\n// goroutine.  Giving a registry which has not been given to\n// RegisterRuntimeMemStats will panic.\n//\n// Be very careful with this because runtime.ReadMemStats calls the C\n// functions runtime·semacquire(&runtime·worldsema) and runtime·stoptheworld()\n// and that last one does what it says on the tin.\nfunc CaptureRuntimeMemStatsOnce(r Registry) {\n\tt := time.Now()\n\truntime.ReadMemStats(&memStats) // This takes 50-200us.\n\truntimeMetrics.ReadMemStats.UpdateSince(t)\n\n\truntimeMetrics.MemStats.Alloc.Update(int64(memStats.Alloc))\n\truntimeMetrics.MemStats.BuckHashSys.Update(int64(memStats.BuckHashSys))\n\tif memStats.DebugGC {\n\t\truntimeMetrics.MemStats.DebugGC.Update(1)\n\t} else {\n\t\truntimeMetrics.MemStats.DebugGC.Update(0)\n\t}\n\tif memStats.EnableGC {\n\t\truntimeMetrics.MemStats.EnableGC.Update(1)\n\t} else {\n\t\truntimeMetrics.MemStats.EnableGC.Update(0)\n\t}\n\n\truntimeMetrics.MemStats.Frees.Update(int64(memStats.Frees - frees))\n\truntimeMetrics.MemStats.HeapAlloc.Update(int64(memStats.HeapAlloc))\n\truntimeMetrics.MemStats.HeapIdle.Update(int64(memStats.HeapIdle))\n\truntimeMetrics.MemStats.HeapInuse.Update(int64(memStats.HeapInuse))\n\truntimeMetrics.MemStats.HeapObjects.Update(int64(memStats.HeapObjects))\n\truntimeMetrics.MemStats.HeapReleased.Update(int64(memStats.HeapReleased))\n\truntimeMetrics.MemStats.HeapSys.Update(int64(memStats.HeapSys))\n\truntimeMetrics.MemStats.LastGC.Update(int64(memStats.LastGC))\n\truntimeMetrics.MemStats.Lookups.Update(int64(memStats.Lookups - lookups))\n\truntimeMetrics.MemStats.Mallocs.Update(int64(memStats.Mallocs - mallocs))\n\truntimeMetrics.MemStats.MCacheInuse.Update(int64(memStats.MCacheInuse))\n\truntimeMetrics.MemStats.MCacheSys.Update(int64(memStats.MCacheSys))\n\truntimeMetrics.MemStats.MSpanInuse.Update(int64(memStats.MSpanInuse))\n\truntimeMetrics.MemStats.MSpanSys.Update(int64(memStats.MSpanSys))\n\truntimeMetrics.MemStats.NextGC.Update(int64(memStats.NextGC))\n\truntimeMetrics.MemStats.NumGC.Update(int64(memStats.NumGC - numGC))\n\truntimeMetrics.MemStats.GCCPUFraction.Update(gcCPUFraction(&memStats))\n\n\t// <https://code.google.com/p/go/source/browse/src/pkg/runtime/mgc0.c>\n\ti := numGC % uint32(len(memStats.PauseNs))\n\tii := memStats.NumGC % uint32(len(memStats.PauseNs))\n\tif memStats.NumGC-numGC >= uint32(len(memStats.PauseNs)) {\n\t\tfor i = 0; i < uint32(len(memStats.PauseNs)); i++ {\n\t\t\truntimeMetrics.MemStats.PauseNs.Update(int64(memStats.PauseNs[i]))\n\t\t}\n\t} else {\n\t\tif i > ii {\n\t\t\tfor ; i < uint32(len(memStats.PauseNs)); i++ {\n\t\t\t\truntimeMetrics.MemStats.PauseNs.Update(int64(memStats.PauseNs[i]))\n\t\t\t}\n\t\t\ti = 0\n\t\t}\n\t\tfor ; i < ii; i++ {\n\t\t\truntimeMetrics.MemStats.PauseNs.Update(int64(memStats.PauseNs[i]))\n\t\t}\n\t}\n\tfrees = memStats.Frees\n\tlookups = memStats.Lookups\n\tmallocs = memStats.Mallocs\n\tnumGC = memStats.NumGC\n\n\truntimeMetrics.MemStats.PauseTotalNs.Update(int64(memStats.PauseTotalNs))\n\truntimeMetrics.MemStats.StackInuse.Update(int64(memStats.StackInuse))\n\truntimeMetrics.MemStats.StackSys.Update(int64(memStats.StackSys))\n\truntimeMetrics.MemStats.Sys.Update(int64(memStats.Sys))\n\truntimeMetrics.MemStats.TotalAlloc.Update(int64(memStats.TotalAlloc))\n\n\tcurrentNumCgoCalls := numCgoCall()\n\truntimeMetrics.NumCgoCall.Update(currentNumCgoCalls - numCgoCalls)\n\tnumCgoCalls = currentNumCgoCalls\n\n\truntimeMetrics.NumGoroutine.Update(int64(runtime.NumGoroutine()))\n\n\truntimeMetrics.NumThread.Update(int64(threadCreateProfile.Count()))\n}\n\n// Register runtimeMetrics for the Go runtime statistics exported in runtime and\n// specifically runtime.MemStats.  The runtimeMetrics are named by their\n// fully-qualified Go symbols, i.e. runtime.MemStats.Alloc.\nfunc RegisterRuntimeMemStats(r Registry) {\n\tregisterRuntimeMetricsOnce.Do(func() {\n\t\truntimeMetrics.MemStats.Alloc = NewGauge()\n\t\truntimeMetrics.MemStats.BuckHashSys = NewGauge()\n\t\truntimeMetrics.MemStats.DebugGC = NewGauge()\n\t\truntimeMetrics.MemStats.EnableGC = NewGauge()\n\t\truntimeMetrics.MemStats.Frees = NewGauge()\n\t\truntimeMetrics.MemStats.HeapAlloc = NewGauge()\n\t\truntimeMetrics.MemStats.HeapIdle = NewGauge()\n\t\truntimeMetrics.MemStats.HeapInuse = NewGauge()\n\t\truntimeMetrics.MemStats.HeapObjects = NewGauge()\n\t\truntimeMetrics.MemStats.HeapReleased = NewGauge()\n\t\truntimeMetrics.MemStats.HeapSys = NewGauge()\n\t\truntimeMetrics.MemStats.LastGC = NewGauge()\n\t\truntimeMetrics.MemStats.Lookups = NewGauge()\n\t\truntimeMetrics.MemStats.Mallocs = NewGauge()\n\t\truntimeMetrics.MemStats.MCacheInuse = NewGauge()\n\t\truntimeMetrics.MemStats.MCacheSys = NewGauge()\n\t\truntimeMetrics.MemStats.MSpanInuse = NewGauge()\n\t\truntimeMetrics.MemStats.MSpanSys = NewGauge()\n\t\truntimeMetrics.MemStats.NextGC = NewGauge()\n\t\truntimeMetrics.MemStats.NumGC = NewGauge()\n\t\truntimeMetrics.MemStats.GCCPUFraction = NewGaugeFloat64()\n\t\truntimeMetrics.MemStats.PauseNs = NewHistogram(NewExpDecaySample(1028, 0.015))\n\t\truntimeMetrics.MemStats.PauseTotalNs = NewGauge()\n\t\truntimeMetrics.MemStats.StackInuse = NewGauge()\n\t\truntimeMetrics.MemStats.StackSys = NewGauge()\n\t\truntimeMetrics.MemStats.Sys = NewGauge()\n\t\truntimeMetrics.MemStats.TotalAlloc = NewGauge()\n\t\truntimeMetrics.NumCgoCall = NewGauge()\n\t\truntimeMetrics.NumGoroutine = NewGauge()\n\t\truntimeMetrics.NumThread = NewGauge()\n\t\truntimeMetrics.ReadMemStats = NewTimer()\n\n\t\tr.Register(\"runtime.MemStats.Alloc\", runtimeMetrics.MemStats.Alloc)\n\t\tr.Register(\"runtime.MemStats.BuckHashSys\", runtimeMetrics.MemStats.BuckHashSys)\n\t\tr.Register(\"runtime.MemStats.DebugGC\", runtimeMetrics.MemStats.DebugGC)\n\t\tr.Register(\"runtime.MemStats.EnableGC\", runtimeMetrics.MemStats.EnableGC)\n\t\tr.Register(\"runtime.MemStats.Frees\", runtimeMetrics.MemStats.Frees)\n\t\tr.Register(\"runtime.MemStats.HeapAlloc\", runtimeMetrics.MemStats.HeapAlloc)\n\t\tr.Register(\"runtime.MemStats.HeapIdle\", runtimeMetrics.MemStats.HeapIdle)\n\t\tr.Register(\"runtime.MemStats.HeapInuse\", runtimeMetrics.MemStats.HeapInuse)\n\t\tr.Register(\"runtime.MemStats.HeapObjects\", runtimeMetrics.MemStats.HeapObjects)\n\t\tr.Register(\"runtime.MemStats.HeapReleased\", runtimeMetrics.MemStats.HeapReleased)\n\t\tr.Register(\"runtime.MemStats.HeapSys\", runtimeMetrics.MemStats.HeapSys)\n\t\tr.Register(\"runtime.MemStats.LastGC\", runtimeMetrics.MemStats.LastGC)\n\t\tr.Register(\"runtime.MemStats.Lookups\", runtimeMetrics.MemStats.Lookups)\n\t\tr.Register(\"runtime.MemStats.Mallocs\", runtimeMetrics.MemStats.Mallocs)\n\t\tr.Register(\"runtime.MemStats.MCacheInuse\", runtimeMetrics.MemStats.MCacheInuse)\n\t\tr.Register(\"runtime.MemStats.MCacheSys\", runtimeMetrics.MemStats.MCacheSys)\n\t\tr.Register(\"runtime.MemStats.MSpanInuse\", runtimeMetrics.MemStats.MSpanInuse)\n\t\tr.Register(\"runtime.MemStats.MSpanSys\", runtimeMetrics.MemStats.MSpanSys)\n\t\tr.Register(\"runtime.MemStats.NextGC\", runtimeMetrics.MemStats.NextGC)\n\t\tr.Register(\"runtime.MemStats.NumGC\", runtimeMetrics.MemStats.NumGC)\n\t\tr.Register(\"runtime.MemStats.GCCPUFraction\", runtimeMetrics.MemStats.GCCPUFraction)\n\t\tr.Register(\"runtime.MemStats.PauseNs\", runtimeMetrics.MemStats.PauseNs)\n\t\tr.Register(\"runtime.MemStats.PauseTotalNs\", runtimeMetrics.MemStats.PauseTotalNs)\n\t\tr.Register(\"runtime.MemStats.StackInuse\", runtimeMetrics.MemStats.StackInuse)\n\t\tr.Register(\"runtime.MemStats.StackSys\", runtimeMetrics.MemStats.StackSys)\n\t\tr.Register(\"runtime.MemStats.Sys\", runtimeMetrics.MemStats.Sys)\n\t\tr.Register(\"runtime.MemStats.TotalAlloc\", runtimeMetrics.MemStats.TotalAlloc)\n\t\tr.Register(\"runtime.NumCgoCall\", runtimeMetrics.NumCgoCall)\n\t\tr.Register(\"runtime.NumGoroutine\", runtimeMetrics.NumGoroutine)\n\t\tr.Register(\"runtime.NumThread\", runtimeMetrics.NumThread)\n\t\tr.Register(\"runtime.ReadMemStats\", runtimeMetrics.ReadMemStats)\n\t})\n}\n"
        },
        {
          "name": "runtime_cgo.go",
          "type": "blob",
          "size": 0.125,
          "content": "// +build cgo\n// +build !appengine\n\npackage metrics\n\nimport \"runtime\"\n\nfunc numCgoCall() int64 {\n\treturn runtime.NumCgoCall()\n}\n"
        },
        {
          "name": "runtime_gccpufraction.go",
          "type": "blob",
          "size": 0.138671875,
          "content": "// +build go1.5\n\npackage metrics\n\nimport \"runtime\"\n\nfunc gcCPUFraction(memStats *runtime.MemStats) float64 {\n\treturn memStats.GCCPUFraction\n}\n"
        },
        {
          "name": "runtime_no_cgo.go",
          "type": "blob",
          "size": 0.0791015625,
          "content": "// +build !cgo appengine\n\npackage metrics\n\nfunc numCgoCall() int64 {\n\treturn 0\n}\n"
        },
        {
          "name": "runtime_no_gccpufraction.go",
          "type": "blob",
          "size": 0.119140625,
          "content": "// +build !go1.5\n\npackage metrics\n\nimport \"runtime\"\n\nfunc gcCPUFraction(memStats *runtime.MemStats) float64 {\n\treturn 0\n}\n"
        },
        {
          "name": "runtime_test.go",
          "type": "blob",
          "size": 2.5595703125,
          "content": "package metrics\n\nimport (\n\t\"runtime\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRuntimeMemStatsDoubleRegister(t *testing.T) {\n\tr := NewRegistry()\n\tRegisterRuntimeMemStats(r)\n\tstoredGauge := r.Get(\"runtime.MemStats.LastGC\").(Gauge)\n\n\truntime.GC()\n\tCaptureRuntimeMemStatsOnce(r)\n\n\tfirstGC := storedGauge.Value()\n\tif 0 == firstGC {\n\t\tt.Errorf(\"firstGC got %d, expected timestamp > 0\", firstGC)\n\t}\n\n\ttime.Sleep(time.Millisecond)\n\n\tRegisterRuntimeMemStats(r)\n\truntime.GC()\n\tCaptureRuntimeMemStatsOnce(r)\n\tif lastGC := storedGauge.Value(); firstGC == lastGC {\n\t\tt.Errorf(\"lastGC got %d, expected a higher timestamp value\", lastGC)\n\t}\n}\n\nfunc BenchmarkRuntimeMemStats(b *testing.B) {\n\tr := NewRegistry()\n\tRegisterRuntimeMemStats(r)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tCaptureRuntimeMemStatsOnce(r)\n\t}\n}\n\nfunc TestRuntimeMemStats(t *testing.T) {\n\tr := NewRegistry()\n\tRegisterRuntimeMemStats(r)\n\tCaptureRuntimeMemStatsOnce(r)\n\tzero := runtimeMetrics.MemStats.PauseNs.Count() // Get a \"zero\" since GC may have run before these tests.\n\truntime.GC()\n\tCaptureRuntimeMemStatsOnce(r)\n\tif count := runtimeMetrics.MemStats.PauseNs.Count(); 1 != count-zero {\n\t\tt.Fatal(count - zero)\n\t}\n\truntime.GC()\n\truntime.GC()\n\tCaptureRuntimeMemStatsOnce(r)\n\tif count := runtimeMetrics.MemStats.PauseNs.Count(); 3 != count-zero {\n\t\tt.Fatal(count - zero)\n\t}\n\tfor i := 0; i < 256; i++ {\n\t\truntime.GC()\n\t}\n\tCaptureRuntimeMemStatsOnce(r)\n\tif count := runtimeMetrics.MemStats.PauseNs.Count(); 259 != count-zero {\n\t\tt.Fatal(count - zero)\n\t}\n\tfor i := 0; i < 257; i++ {\n\t\truntime.GC()\n\t}\n\tCaptureRuntimeMemStatsOnce(r)\n\tif count := runtimeMetrics.MemStats.PauseNs.Count(); 515 != count-zero { // We lost one because there were too many GCs between captures.\n\t\tt.Fatal(count - zero)\n\t}\n}\n\nfunc TestRuntimeMemStatsNumThread(t *testing.T) {\n\tr := NewRegistry()\n\tRegisterRuntimeMemStats(r)\n\tCaptureRuntimeMemStatsOnce(r)\n\n\tif value := runtimeMetrics.NumThread.Value(); value < 1 {\n\t\tt.Fatalf(\"got NumThread: %d, wanted at least 1\", value)\n\t}\n}\n\nfunc TestRuntimeMemStatsBlocking(t *testing.T) {\n\tif g := runtime.GOMAXPROCS(0); g < 2 {\n\t\tt.Skipf(\"skipping TestRuntimeMemStatsBlocking with GOMAXPROCS=%d\\n\", g)\n\t}\n\tch := make(chan int)\n\tgo testRuntimeMemStatsBlocking(ch)\n\tvar memStats runtime.MemStats\n\tt0 := time.Now()\n\truntime.ReadMemStats(&memStats)\n\tt1 := time.Now()\n\tt.Log(\"i++ during runtime.ReadMemStats:\", <-ch)\n\tgo testRuntimeMemStatsBlocking(ch)\n\td := t1.Sub(t0)\n\tt.Log(d)\n\ttime.Sleep(d)\n\tt.Log(\"i++ during time.Sleep:\", <-ch)\n}\n\nfunc testRuntimeMemStatsBlocking(ch chan int) {\n\ti := 0\n\tfor {\n\t\tselect {\n\t\tcase ch <- i:\n\t\t\treturn\n\t\tdefault:\n\t\t\ti++\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "sample.go",
          "type": "blob",
          "size": 14.712890625,
          "content": "package metrics\n\nimport (\n\t\"math\"\n\t\"math/rand\"\n\t\"sort\"\n\t\"sync\"\n\t\"time\"\n)\n\nconst rescaleThreshold = time.Hour\n\n// Samples maintain a statistically-significant selection of values from\n// a stream.\ntype Sample interface {\n\tClear()\n\tCount() int64\n\tMax() int64\n\tMean() float64\n\tMin() int64\n\tPercentile(float64) float64\n\tPercentiles([]float64) []float64\n\tSize() int\n\tSnapshot() Sample\n\tStdDev() float64\n\tSum() int64\n\tUpdate(int64)\n\tValues() []int64\n\tVariance() float64\n}\n\n// ExpDecaySample is an exponentially-decaying sample using a forward-decaying\n// priority reservoir.  See Cormode et al's \"Forward Decay: A Practical Time\n// Decay Model for Streaming Systems\".\n//\n// <http://dimacs.rutgers.edu/~graham/pubs/papers/fwddecay.pdf>\ntype ExpDecaySample struct {\n\talpha         float64\n\tcount         int64\n\tmutex         sync.Mutex\n\treservoirSize int\n\tt0, t1        time.Time\n\tvalues        *expDecaySampleHeap\n}\n\n// NewExpDecaySample constructs a new exponentially-decaying sample with the\n// given reservoir size and alpha.\nfunc NewExpDecaySample(reservoirSize int, alpha float64) Sample {\n\tif UseNilMetrics {\n\t\treturn NilSample{}\n\t}\n\ts := &ExpDecaySample{\n\t\talpha:         alpha,\n\t\treservoirSize: reservoirSize,\n\t\tt0:            time.Now(),\n\t\tvalues:        newExpDecaySampleHeap(reservoirSize),\n\t}\n\ts.t1 = s.t0.Add(rescaleThreshold)\n\treturn s\n}\n\n// Clear clears all samples.\nfunc (s *ExpDecaySample) Clear() {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\ts.count = 0\n\ts.t0 = time.Now()\n\ts.t1 = s.t0.Add(rescaleThreshold)\n\ts.values.Clear()\n}\n\n// Count returns the number of samples recorded, which may exceed the\n// reservoir size.\nfunc (s *ExpDecaySample) Count() int64 {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\treturn s.count\n}\n\n// Max returns the maximum value in the sample, which may not be the maximum\n// value ever to be part of the sample.\nfunc (s *ExpDecaySample) Max() int64 {\n\treturn SampleMax(s.Values())\n}\n\n// Mean returns the mean of the values in the sample.\nfunc (s *ExpDecaySample) Mean() float64 {\n\treturn SampleMean(s.Values())\n}\n\n// Min returns the minimum value in the sample, which may not be the minimum\n// value ever to be part of the sample.\nfunc (s *ExpDecaySample) Min() int64 {\n\treturn SampleMin(s.Values())\n}\n\n// Percentile returns an arbitrary percentile of values in the sample.\nfunc (s *ExpDecaySample) Percentile(p float64) float64 {\n\treturn SamplePercentile(s.Values(), p)\n}\n\n// Percentiles returns a slice of arbitrary percentiles of values in the\n// sample.\nfunc (s *ExpDecaySample) Percentiles(ps []float64) []float64 {\n\treturn SamplePercentiles(s.Values(), ps)\n}\n\n// Size returns the size of the sample, which is at most the reservoir size.\nfunc (s *ExpDecaySample) Size() int {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\treturn s.values.Size()\n}\n\n// Snapshot returns a read-only copy of the sample.\nfunc (s *ExpDecaySample) Snapshot() Sample {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\tvals := s.values.Values()\n\tvalues := make([]int64, len(vals))\n\tfor i, v := range vals {\n\t\tvalues[i] = v.v\n\t}\n\treturn &SampleSnapshot{\n\t\tcount:  s.count,\n\t\tvalues: values,\n\t}\n}\n\n// StdDev returns the standard deviation of the values in the sample.\nfunc (s *ExpDecaySample) StdDev() float64 {\n\treturn SampleStdDev(s.Values())\n}\n\n// Sum returns the sum of the values in the sample.\nfunc (s *ExpDecaySample) Sum() int64 {\n\treturn SampleSum(s.Values())\n}\n\n// Update samples a new value.\nfunc (s *ExpDecaySample) Update(v int64) {\n\ts.update(time.Now(), v)\n}\n\n// Values returns a copy of the values in the sample.\nfunc (s *ExpDecaySample) Values() []int64 {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\tvals := s.values.Values()\n\tvalues := make([]int64, len(vals))\n\tfor i, v := range vals {\n\t\tvalues[i] = v.v\n\t}\n\treturn values\n}\n\n// Variance returns the variance of the values in the sample.\nfunc (s *ExpDecaySample) Variance() float64 {\n\treturn SampleVariance(s.Values())\n}\n\n// update samples a new value at a particular timestamp.  This is a method all\n// its own to facilitate testing.\nfunc (s *ExpDecaySample) update(t time.Time, v int64) {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\ts.count++\n\tif s.values.Size() == s.reservoirSize {\n\t\ts.values.Pop()\n\t}\n\ts.values.Push(expDecaySample{\n\t\tk: math.Exp(t.Sub(s.t0).Seconds()*s.alpha) / rand.Float64(),\n\t\tv: v,\n\t})\n\tif t.After(s.t1) {\n\t\tvalues := s.values.Values()\n\t\tt0 := s.t0\n\t\ts.values.Clear()\n\t\ts.t0 = t\n\t\ts.t1 = s.t0.Add(rescaleThreshold)\n\t\tfor _, v := range values {\n\t\t\tv.k = v.k * math.Exp(-s.alpha*s.t0.Sub(t0).Seconds())\n\t\t\ts.values.Push(v)\n\t\t}\n\t}\n}\n\n// NilSample is a no-op Sample.\ntype NilSample struct{}\n\n// Clear is a no-op.\nfunc (NilSample) Clear() {}\n\n// Count is a no-op.\nfunc (NilSample) Count() int64 { return 0 }\n\n// Max is a no-op.\nfunc (NilSample) Max() int64 { return 0 }\n\n// Mean is a no-op.\nfunc (NilSample) Mean() float64 { return 0.0 }\n\n// Min is a no-op.\nfunc (NilSample) Min() int64 { return 0 }\n\n// Percentile is a no-op.\nfunc (NilSample) Percentile(p float64) float64 { return 0.0 }\n\n// Percentiles is a no-op.\nfunc (NilSample) Percentiles(ps []float64) []float64 {\n\treturn make([]float64, len(ps))\n}\n\n// Size is a no-op.\nfunc (NilSample) Size() int { return 0 }\n\n// Sample is a no-op.\nfunc (NilSample) Snapshot() Sample { return NilSample{} }\n\n// StdDev is a no-op.\nfunc (NilSample) StdDev() float64 { return 0.0 }\n\n// Sum is a no-op.\nfunc (NilSample) Sum() int64 { return 0 }\n\n// Update is a no-op.\nfunc (NilSample) Update(v int64) {}\n\n// Values is a no-op.\nfunc (NilSample) Values() []int64 { return []int64{} }\n\n// Variance is a no-op.\nfunc (NilSample) Variance() float64 { return 0.0 }\n\n// SampleMax returns the maximum value of the slice of int64.\nfunc SampleMax(values []int64) int64 {\n\tif 0 == len(values) {\n\t\treturn 0\n\t}\n\tvar max int64 = math.MinInt64\n\tfor _, v := range values {\n\t\tif max < v {\n\t\t\tmax = v\n\t\t}\n\t}\n\treturn max\n}\n\n// SampleMean returns the mean value of the slice of int64.\nfunc SampleMean(values []int64) float64 {\n\tif 0 == len(values) {\n\t\treturn 0.0\n\t}\n\treturn float64(SampleSum(values)) / float64(len(values))\n}\n\n// SampleMin returns the minimum value of the slice of int64.\nfunc SampleMin(values []int64) int64 {\n\tif 0 == len(values) {\n\t\treturn 0\n\t}\n\tvar min int64 = math.MaxInt64\n\tfor _, v := range values {\n\t\tif min > v {\n\t\t\tmin = v\n\t\t}\n\t}\n\treturn min\n}\n\n// SamplePercentiles returns an arbitrary percentile of the slice of int64.\nfunc SamplePercentile(values int64Slice, p float64) float64 {\n\treturn SamplePercentiles(values, []float64{p})[0]\n}\n\n// SamplePercentiles returns a slice of arbitrary percentiles of the slice of\n// int64.\nfunc SamplePercentiles(values int64Slice, ps []float64) []float64 {\n\tscores := make([]float64, len(ps))\n\tsize := len(values)\n\tif size > 0 {\n\t\tsort.Sort(values)\n\t\tfor i, p := range ps {\n\t\t\tpos := p * float64(size+1)\n\t\t\tif pos < 1.0 {\n\t\t\t\tscores[i] = float64(values[0])\n\t\t\t} else if pos >= float64(size) {\n\t\t\t\tscores[i] = float64(values[size-1])\n\t\t\t} else {\n\t\t\t\tlower := float64(values[int(pos)-1])\n\t\t\t\tupper := float64(values[int(pos)])\n\t\t\t\tscores[i] = lower + (pos-math.Floor(pos))*(upper-lower)\n\t\t\t}\n\t\t}\n\t}\n\treturn scores\n}\n\n// SampleSnapshot is a read-only copy of another Sample.\ntype SampleSnapshot struct {\n\tcount  int64\n\tvalues []int64\n}\n\nfunc NewSampleSnapshot(count int64, values []int64) *SampleSnapshot {\n\treturn &SampleSnapshot{\n\t\tcount:  count,\n\t\tvalues: values,\n\t}\n}\n\n// Clear panics.\nfunc (*SampleSnapshot) Clear() {\n\tpanic(\"Clear called on a SampleSnapshot\")\n}\n\n// Count returns the count of inputs at the time the snapshot was taken.\nfunc (s *SampleSnapshot) Count() int64 { return s.count }\n\n// Max returns the maximal value at the time the snapshot was taken.\nfunc (s *SampleSnapshot) Max() int64 { return SampleMax(s.values) }\n\n// Mean returns the mean value at the time the snapshot was taken.\nfunc (s *SampleSnapshot) Mean() float64 { return SampleMean(s.values) }\n\n// Min returns the minimal value at the time the snapshot was taken.\nfunc (s *SampleSnapshot) Min() int64 { return SampleMin(s.values) }\n\n// Percentile returns an arbitrary percentile of values at the time the\n// snapshot was taken.\nfunc (s *SampleSnapshot) Percentile(p float64) float64 {\n\treturn SamplePercentile(s.values, p)\n}\n\n// Percentiles returns a slice of arbitrary percentiles of values at the time\n// the snapshot was taken.\nfunc (s *SampleSnapshot) Percentiles(ps []float64) []float64 {\n\treturn SamplePercentiles(s.values, ps)\n}\n\n// Size returns the size of the sample at the time the snapshot was taken.\nfunc (s *SampleSnapshot) Size() int { return len(s.values) }\n\n// Snapshot returns the snapshot.\nfunc (s *SampleSnapshot) Snapshot() Sample { return s }\n\n// StdDev returns the standard deviation of values at the time the snapshot was\n// taken.\nfunc (s *SampleSnapshot) StdDev() float64 { return SampleStdDev(s.values) }\n\n// Sum returns the sum of values at the time the snapshot was taken.\nfunc (s *SampleSnapshot) Sum() int64 { return SampleSum(s.values) }\n\n// Update panics.\nfunc (*SampleSnapshot) Update(int64) {\n\tpanic(\"Update called on a SampleSnapshot\")\n}\n\n// Values returns a copy of the values in the sample.\nfunc (s *SampleSnapshot) Values() []int64 {\n\tvalues := make([]int64, len(s.values))\n\tcopy(values, s.values)\n\treturn values\n}\n\n// Variance returns the variance of values at the time the snapshot was taken.\nfunc (s *SampleSnapshot) Variance() float64 { return SampleVariance(s.values) }\n\n// SampleStdDev returns the standard deviation of the slice of int64.\nfunc SampleStdDev(values []int64) float64 {\n\treturn math.Sqrt(SampleVariance(values))\n}\n\n// SampleSum returns the sum of the slice of int64.\nfunc SampleSum(values []int64) int64 {\n\tvar sum int64\n\tfor _, v := range values {\n\t\tsum += v\n\t}\n\treturn sum\n}\n\n// SampleVariance returns the variance of the slice of int64.\nfunc SampleVariance(values []int64) float64 {\n\tif 0 == len(values) {\n\t\treturn 0.0\n\t}\n\tm := SampleMean(values)\n\tvar sum float64\n\tfor _, v := range values {\n\t\td := float64(v) - m\n\t\tsum += d * d\n\t}\n\treturn sum / float64(len(values))\n}\n\n// A uniform sample using Vitter's Algorithm R.\n//\n// <http://www.cs.umd.edu/~samir/498/vitter.pdf>\ntype UniformSample struct {\n\tcount         int64\n\tmutex         sync.Mutex\n\treservoirSize int\n\tvalues        []int64\n}\n\n// NewUniformSample constructs a new uniform sample with the given reservoir\n// size.\nfunc NewUniformSample(reservoirSize int) Sample {\n\tif UseNilMetrics {\n\t\treturn NilSample{}\n\t}\n\treturn &UniformSample{\n\t\treservoirSize: reservoirSize,\n\t\tvalues:        make([]int64, 0, reservoirSize),\n\t}\n}\n\n// Clear clears all samples.\nfunc (s *UniformSample) Clear() {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\ts.count = 0\n\ts.values = make([]int64, 0, s.reservoirSize)\n}\n\n// Count returns the number of samples recorded, which may exceed the\n// reservoir size.\nfunc (s *UniformSample) Count() int64 {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\treturn s.count\n}\n\n// Max returns the maximum value in the sample, which may not be the maximum\n// value ever to be part of the sample.\nfunc (s *UniformSample) Max() int64 {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\treturn SampleMax(s.values)\n}\n\n// Mean returns the mean of the values in the sample.\nfunc (s *UniformSample) Mean() float64 {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\treturn SampleMean(s.values)\n}\n\n// Min returns the minimum value in the sample, which may not be the minimum\n// value ever to be part of the sample.\nfunc (s *UniformSample) Min() int64 {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\treturn SampleMin(s.values)\n}\n\n// Percentile returns an arbitrary percentile of values in the sample.\nfunc (s *UniformSample) Percentile(p float64) float64 {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\treturn SamplePercentile(s.values, p)\n}\n\n// Percentiles returns a slice of arbitrary percentiles of values in the\n// sample.\nfunc (s *UniformSample) Percentiles(ps []float64) []float64 {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\treturn SamplePercentiles(s.values, ps)\n}\n\n// Size returns the size of the sample, which is at most the reservoir size.\nfunc (s *UniformSample) Size() int {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\treturn len(s.values)\n}\n\n// Snapshot returns a read-only copy of the sample.\nfunc (s *UniformSample) Snapshot() Sample {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\tvalues := make([]int64, len(s.values))\n\tcopy(values, s.values)\n\treturn &SampleSnapshot{\n\t\tcount:  s.count,\n\t\tvalues: values,\n\t}\n}\n\n// StdDev returns the standard deviation of the values in the sample.\nfunc (s *UniformSample) StdDev() float64 {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\treturn SampleStdDev(s.values)\n}\n\n// Sum returns the sum of the values in the sample.\nfunc (s *UniformSample) Sum() int64 {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\treturn SampleSum(s.values)\n}\n\n// Update samples a new value.\nfunc (s *UniformSample) Update(v int64) {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\ts.count++\n\tif len(s.values) < s.reservoirSize {\n\t\ts.values = append(s.values, v)\n\t} else {\n\t\tr := rand.Int63n(s.count)\n\t\tif r < int64(len(s.values)) {\n\t\t\ts.values[int(r)] = v\n\t\t}\n\t}\n}\n\n// Values returns a copy of the values in the sample.\nfunc (s *UniformSample) Values() []int64 {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\tvalues := make([]int64, len(s.values))\n\tcopy(values, s.values)\n\treturn values\n}\n\n// Variance returns the variance of the values in the sample.\nfunc (s *UniformSample) Variance() float64 {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\treturn SampleVariance(s.values)\n}\n\n// expDecaySample represents an individual sample in a heap.\ntype expDecaySample struct {\n\tk float64\n\tv int64\n}\n\nfunc newExpDecaySampleHeap(reservoirSize int) *expDecaySampleHeap {\n\treturn &expDecaySampleHeap{make([]expDecaySample, 0, reservoirSize)}\n}\n\n// expDecaySampleHeap is a min-heap of expDecaySamples.\n// The internal implementation is copied from the standard library's container/heap\ntype expDecaySampleHeap struct {\n\ts []expDecaySample\n}\n\nfunc (h *expDecaySampleHeap) Clear() {\n\th.s = h.s[:0]\n}\n\nfunc (h *expDecaySampleHeap) Push(s expDecaySample) {\n\tn := len(h.s)\n\th.s = h.s[0 : n+1]\n\th.s[n] = s\n\th.up(n)\n}\n\nfunc (h *expDecaySampleHeap) Pop() expDecaySample {\n\tn := len(h.s) - 1\n\th.s[0], h.s[n] = h.s[n], h.s[0]\n\th.down(0, n)\n\n\tn = len(h.s)\n\ts := h.s[n-1]\n\th.s = h.s[0 : n-1]\n\treturn s\n}\n\nfunc (h *expDecaySampleHeap) Size() int {\n\treturn len(h.s)\n}\n\nfunc (h *expDecaySampleHeap) Values() []expDecaySample {\n\treturn h.s\n}\n\nfunc (h *expDecaySampleHeap) up(j int) {\n\tfor {\n\t\ti := (j - 1) / 2 // parent\n\t\tif i == j || !(h.s[j].k < h.s[i].k) {\n\t\t\tbreak\n\t\t}\n\t\th.s[i], h.s[j] = h.s[j], h.s[i]\n\t\tj = i\n\t}\n}\n\nfunc (h *expDecaySampleHeap) down(i, n int) {\n\tfor {\n\t\tj1 := 2*i + 1\n\t\tif j1 >= n || j1 < 0 { // j1 < 0 after int overflow\n\t\t\tbreak\n\t\t}\n\t\tj := j1 // left child\n\t\tif j2 := j1 + 1; j2 < n && !(h.s[j1].k < h.s[j2].k) {\n\t\t\tj = j2 // = 2*i + 2  // right child\n\t\t}\n\t\tif !(h.s[j].k < h.s[i].k) {\n\t\t\tbreak\n\t\t}\n\t\th.s[i], h.s[j] = h.s[j], h.s[i]\n\t\ti = j\n\t}\n}\n\ntype int64Slice []int64\n\nfunc (p int64Slice) Len() int           { return len(p) }\nfunc (p int64Slice) Less(i, j int) bool { return p[i] < p[j] }\nfunc (p int64Slice) Swap(i, j int)      { p[i], p[j] = p[j], p[i] }\n"
        },
        {
          "name": "sample_test.go",
          "type": "blob",
          "size": 8.4931640625,
          "content": "package metrics\n\nimport (\n\t\"math/rand\"\n\t\"runtime\"\n\t\"testing\"\n\t\"time\"\n)\n\n// Benchmark{Compute,Copy}{1000,1000000} demonstrate that, even for relatively\n// expensive computations like Variance, the cost of copying the Sample, as\n// approximated by a make and copy, is much greater than the cost of the\n// computation for small samples and only slightly less for large samples.\nfunc BenchmarkCompute1000(b *testing.B) {\n\ts := make([]int64, 1000)\n\tfor i := 0; i < len(s); i++ {\n\t\ts[i] = int64(i)\n\t}\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tSampleVariance(s)\n\t}\n}\nfunc BenchmarkCompute1000000(b *testing.B) {\n\ts := make([]int64, 1000000)\n\tfor i := 0; i < len(s); i++ {\n\t\ts[i] = int64(i)\n\t}\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tSampleVariance(s)\n\t}\n}\nfunc BenchmarkCopy1000(b *testing.B) {\n\ts := make([]int64, 1000)\n\tfor i := 0; i < len(s); i++ {\n\t\ts[i] = int64(i)\n\t}\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tsCopy := make([]int64, len(s))\n\t\tcopy(sCopy, s)\n\t}\n}\nfunc BenchmarkCopy1000000(b *testing.B) {\n\ts := make([]int64, 1000000)\n\tfor i := 0; i < len(s); i++ {\n\t\ts[i] = int64(i)\n\t}\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tsCopy := make([]int64, len(s))\n\t\tcopy(sCopy, s)\n\t}\n}\n\nfunc BenchmarkExpDecaySample257(b *testing.B) {\n\tbenchmarkSample(b, NewExpDecaySample(257, 0.015))\n}\n\nfunc BenchmarkExpDecaySample514(b *testing.B) {\n\tbenchmarkSample(b, NewExpDecaySample(514, 0.015))\n}\n\nfunc BenchmarkExpDecaySample1028(b *testing.B) {\n\tbenchmarkSample(b, NewExpDecaySample(1028, 0.015))\n}\n\nfunc BenchmarkUniformSample257(b *testing.B) {\n\tbenchmarkSample(b, NewUniformSample(257))\n}\n\nfunc BenchmarkUniformSample514(b *testing.B) {\n\tbenchmarkSample(b, NewUniformSample(514))\n}\n\nfunc BenchmarkUniformSample1028(b *testing.B) {\n\tbenchmarkSample(b, NewUniformSample(1028))\n}\n\nfunc TestExpDecaySample10(t *testing.T) {\n\trand.Seed(1)\n\ts := NewExpDecaySample(100, 0.99)\n\tfor i := 0; i < 10; i++ {\n\t\ts.Update(int64(i))\n\t}\n\tif size := s.Count(); 10 != size {\n\t\tt.Errorf(\"s.Count(): 10 != %v\\n\", size)\n\t}\n\tif size := s.Size(); 10 != size {\n\t\tt.Errorf(\"s.Size(): 10 != %v\\n\", size)\n\t}\n\tif l := len(s.Values()); 10 != l {\n\t\tt.Errorf(\"len(s.Values()): 10 != %v\\n\", l)\n\t}\n\tfor _, v := range s.Values() {\n\t\tif v > 10 || v < 0 {\n\t\t\tt.Errorf(\"out of range [0, 10): %v\\n\", v)\n\t\t}\n\t}\n}\n\nfunc TestExpDecaySample100(t *testing.T) {\n\trand.Seed(1)\n\ts := NewExpDecaySample(1000, 0.01)\n\tfor i := 0; i < 100; i++ {\n\t\ts.Update(int64(i))\n\t}\n\tif size := s.Count(); 100 != size {\n\t\tt.Errorf(\"s.Count(): 100 != %v\\n\", size)\n\t}\n\tif size := s.Size(); 100 != size {\n\t\tt.Errorf(\"s.Size(): 100 != %v\\n\", size)\n\t}\n\tif l := len(s.Values()); 100 != l {\n\t\tt.Errorf(\"len(s.Values()): 100 != %v\\n\", l)\n\t}\n\tfor _, v := range s.Values() {\n\t\tif v > 100 || v < 0 {\n\t\t\tt.Errorf(\"out of range [0, 100): %v\\n\", v)\n\t\t}\n\t}\n}\n\nfunc TestExpDecaySample1000(t *testing.T) {\n\trand.Seed(1)\n\ts := NewExpDecaySample(100, 0.99)\n\tfor i := 0; i < 1000; i++ {\n\t\ts.Update(int64(i))\n\t}\n\tif size := s.Count(); 1000 != size {\n\t\tt.Errorf(\"s.Count(): 1000 != %v\\n\", size)\n\t}\n\tif size := s.Size(); 100 != size {\n\t\tt.Errorf(\"s.Size(): 100 != %v\\n\", size)\n\t}\n\tif l := len(s.Values()); 100 != l {\n\t\tt.Errorf(\"len(s.Values()): 100 != %v\\n\", l)\n\t}\n\tfor _, v := range s.Values() {\n\t\tif v > 1000 || v < 0 {\n\t\t\tt.Errorf(\"out of range [0, 1000): %v\\n\", v)\n\t\t}\n\t}\n}\n\n// This test makes sure that the sample's priority is not amplified by using\n// nanosecond duration since start rather than second duration since start.\n// The priority becomes +Inf quickly after starting if this is done,\n// effectively freezing the set of samples until a rescale step happens.\nfunc TestExpDecaySampleNanosecondRegression(t *testing.T) {\n\trand.Seed(1)\n\ts := NewExpDecaySample(100, 0.99)\n\tfor i := 0; i < 100; i++ {\n\t\ts.Update(10)\n\t}\n\ttime.Sleep(1 * time.Millisecond)\n\tfor i := 0; i < 100; i++ {\n\t\ts.Update(20)\n\t}\n\tv := s.Values()\n\tavg := float64(0)\n\tfor i := 0; i < len(v); i++ {\n\t\tavg += float64(v[i])\n\t}\n\tavg /= float64(len(v))\n\tif avg > 16 || avg < 14 {\n\t\tt.Errorf(\"out of range [14, 16]: %v\\n\", avg)\n\t}\n}\n\nfunc TestExpDecaySampleRescale(t *testing.T) {\n\ts := NewExpDecaySample(2, 0.001).(*ExpDecaySample)\n\ts.update(time.Now(), 1)\n\ts.update(time.Now().Add(time.Hour+time.Microsecond), 1)\n\tfor _, v := range s.values.Values() {\n\t\tif v.k == 0.0 {\n\t\t\tt.Fatal(\"v.k == 0.0\")\n\t\t}\n\t}\n}\n\nfunc TestExpDecaySampleSnapshot(t *testing.T) {\n\tnow := time.Now()\n\trand.Seed(1)\n\ts := NewExpDecaySample(100, 0.99)\n\tfor i := 1; i <= 10000; i++ {\n\t\ts.(*ExpDecaySample).update(now.Add(time.Duration(i)), int64(i))\n\t}\n\tsnapshot := s.Snapshot()\n\ts.Update(1)\n\ttestExpDecaySampleStatistics(t, snapshot)\n}\n\nfunc TestExpDecaySampleStatistics(t *testing.T) {\n\tnow := time.Now()\n\trand.Seed(1)\n\ts := NewExpDecaySample(100, 0.99)\n\tfor i := 1; i <= 10000; i++ {\n\t\ts.(*ExpDecaySample).update(now.Add(time.Duration(i)), int64(i))\n\t}\n\ttestExpDecaySampleStatistics(t, s)\n}\n\nfunc TestUniformSample(t *testing.T) {\n\trand.Seed(1)\n\ts := NewUniformSample(100)\n\tfor i := 0; i < 1000; i++ {\n\t\ts.Update(int64(i))\n\t}\n\tif size := s.Count(); 1000 != size {\n\t\tt.Errorf(\"s.Count(): 1000 != %v\\n\", size)\n\t}\n\tif size := s.Size(); 100 != size {\n\t\tt.Errorf(\"s.Size(): 100 != %v\\n\", size)\n\t}\n\tif l := len(s.Values()); 100 != l {\n\t\tt.Errorf(\"len(s.Values()): 100 != %v\\n\", l)\n\t}\n\tfor _, v := range s.Values() {\n\t\tif v > 1000 || v < 0 {\n\t\t\tt.Errorf(\"out of range [0, 100): %v\\n\", v)\n\t\t}\n\t}\n}\n\nfunc TestUniformSampleIncludesTail(t *testing.T) {\n\trand.Seed(1)\n\ts := NewUniformSample(100)\n\tmax := 100\n\tfor i := 0; i < max; i++ {\n\t\ts.Update(int64(i))\n\t}\n\tv := s.Values()\n\tsum := 0\n\texp := (max - 1) * max / 2\n\tfor i := 0; i < len(v); i++ {\n\t\tsum += int(v[i])\n\t}\n\tif exp != sum {\n\t\tt.Errorf(\"sum: %v != %v\\n\", exp, sum)\n\t}\n}\n\nfunc TestUniformSampleSnapshot(t *testing.T) {\n\ts := NewUniformSample(100)\n\tfor i := 1; i <= 10000; i++ {\n\t\ts.Update(int64(i))\n\t}\n\tsnapshot := s.Snapshot()\n\ts.Update(1)\n\ttestUniformSampleStatistics(t, snapshot)\n}\n\nfunc TestUniformSampleStatistics(t *testing.T) {\n\trand.Seed(1)\n\ts := NewUniformSample(100)\n\tfor i := 1; i <= 10000; i++ {\n\t\ts.Update(int64(i))\n\t}\n\ttestUniformSampleStatistics(t, s)\n}\n\nfunc benchmarkSample(b *testing.B, s Sample) {\n\tvar memStats runtime.MemStats\n\truntime.ReadMemStats(&memStats)\n\tpauseTotalNs := memStats.PauseTotalNs\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\ts.Update(1)\n\t}\n\tb.StopTimer()\n\truntime.GC()\n\truntime.ReadMemStats(&memStats)\n\tb.Logf(\"GC cost: %d ns/op\", int(memStats.PauseTotalNs-pauseTotalNs)/b.N)\n}\n\nfunc testExpDecaySampleStatistics(t *testing.T, s Sample) {\n\tif count := s.Count(); 10000 != count {\n\t\tt.Errorf(\"s.Count(): 10000 != %v\\n\", count)\n\t}\n\tif min := s.Min(); 107 != min {\n\t\tt.Errorf(\"s.Min(): 107 != %v\\n\", min)\n\t}\n\tif max := s.Max(); 10000 != max {\n\t\tt.Errorf(\"s.Max(): 10000 != %v\\n\", max)\n\t}\n\tif mean := s.Mean(); 4965.98 != mean {\n\t\tt.Errorf(\"s.Mean(): 4965.98 != %v\\n\", mean)\n\t}\n\tif stdDev := s.StdDev(); 2959.825156930727 != stdDev {\n\t\tt.Errorf(\"s.StdDev(): 2959.825156930727 != %v\\n\", stdDev)\n\t}\n\tps := s.Percentiles([]float64{0.5, 0.75, 0.99})\n\tif 4615 != ps[0] {\n\t\tt.Errorf(\"median: 4615 != %v\\n\", ps[0])\n\t}\n\tif 7672 != ps[1] {\n\t\tt.Errorf(\"75th percentile: 7672 != %v\\n\", ps[1])\n\t}\n\tif 9998.99 != ps[2] {\n\t\tt.Errorf(\"99th percentile: 9998.99 != %v\\n\", ps[2])\n\t}\n}\n\nfunc testUniformSampleStatistics(t *testing.T, s Sample) {\n\tif count := s.Count(); 10000 != count {\n\t\tt.Errorf(\"s.Count(): 10000 != %v\\n\", count)\n\t}\n\tif min := s.Min(); 37 != min {\n\t\tt.Errorf(\"s.Min(): 37 != %v\\n\", min)\n\t}\n\tif max := s.Max(); 9989 != max {\n\t\tt.Errorf(\"s.Max(): 9989 != %v\\n\", max)\n\t}\n\tif mean := s.Mean(); 4748.14 != mean {\n\t\tt.Errorf(\"s.Mean(): 4748.14 != %v\\n\", mean)\n\t}\n\tif stdDev := s.StdDev(); 2826.684117548333 != stdDev {\n\t\tt.Errorf(\"s.StdDev(): 2826.684117548333 != %v\\n\", stdDev)\n\t}\n\tps := s.Percentiles([]float64{0.5, 0.75, 0.99})\n\tif 4599 != ps[0] {\n\t\tt.Errorf(\"median: 4599 != %v\\n\", ps[0])\n\t}\n\tif 7380.5 != ps[1] {\n\t\tt.Errorf(\"75th percentile: 7380.5 != %v\\n\", ps[1])\n\t}\n\tif 9986.429999999998 != ps[2] {\n\t\tt.Errorf(\"99th percentile: 9986.429999999998 != %v\\n\", ps[2])\n\t}\n}\n\n// TestUniformSampleConcurrentUpdateCount would expose data race problems with\n// concurrent Update and Count calls on Sample when test is called with -race\n// argument\nfunc TestUniformSampleConcurrentUpdateCount(t *testing.T) {\n\tif testing.Short() {\n\t\tt.Skip(\"skipping in short mode\")\n\t}\n\ts := NewUniformSample(100)\n\tfor i := 0; i < 100; i++ {\n\t\ts.Update(int64(i))\n\t}\n\tquit := make(chan struct{})\n\tgo func() {\n\t\tt := time.NewTicker(10 * time.Millisecond)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-t.C:\n\t\t\t\ts.Update(rand.Int63())\n\t\t\tcase <-quit:\n\t\t\t\tt.Stop()\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}()\n\tfor i := 0; i < 1000; i++ {\n\t\ts.Count()\n\t\ttime.Sleep(5 * time.Millisecond)\n\t}\n\tquit <- struct{}{}\n}\n"
        },
        {
          "name": "stathat",
          "type": "tree",
          "content": null
        },
        {
          "name": "syslog.go",
          "type": "blob",
          "size": 1.8857421875,
          "content": "// +build !windows\n\npackage metrics\n\nimport (\n\t\"fmt\"\n\t\"log/syslog\"\n\t\"time\"\n)\n\n// Output each metric in the given registry to syslog periodically using\n// the given syslogger.\nfunc Syslog(r Registry, d time.Duration, w *syslog.Writer) {\n\tfor _ = range time.Tick(d) {\n\t\tr.Each(func(name string, i interface{}) {\n\t\t\tswitch metric := i.(type) {\n\t\t\tcase Counter:\n\t\t\t\tw.Info(fmt.Sprintf(\"counter %s: count: %d\", name, metric.Count()))\n\t\t\tcase Gauge:\n\t\t\t\tw.Info(fmt.Sprintf(\"gauge %s: value: %d\", name, metric.Value()))\n\t\t\tcase GaugeFloat64:\n\t\t\t\tw.Info(fmt.Sprintf(\"gauge %s: value: %f\", name, metric.Value()))\n\t\t\tcase Healthcheck:\n\t\t\t\tmetric.Check()\n\t\t\t\tw.Info(fmt.Sprintf(\"healthcheck %s: error: %v\", name, metric.Error()))\n\t\t\tcase Histogram:\n\t\t\t\th := metric.Snapshot()\n\t\t\t\tps := h.Percentiles([]float64{0.5, 0.75, 0.95, 0.99, 0.999})\n\t\t\t\tw.Info(fmt.Sprintf(\n\t\t\t\t\t\"histogram %s: count: %d min: %d max: %d mean: %.2f stddev: %.2f median: %.2f 75%%: %.2f 95%%: %.2f 99%%: %.2f 99.9%%: %.2f\",\n\t\t\t\t\tname,\n\t\t\t\t\th.Count(),\n\t\t\t\t\th.Min(),\n\t\t\t\t\th.Max(),\n\t\t\t\t\th.Mean(),\n\t\t\t\t\th.StdDev(),\n\t\t\t\t\tps[0],\n\t\t\t\t\tps[1],\n\t\t\t\t\tps[2],\n\t\t\t\t\tps[3],\n\t\t\t\t\tps[4],\n\t\t\t\t))\n\t\t\tcase Meter:\n\t\t\t\tm := metric.Snapshot()\n\t\t\t\tw.Info(fmt.Sprintf(\n\t\t\t\t\t\"meter %s: count: %d 1-min: %.2f 5-min: %.2f 15-min: %.2f mean: %.2f\",\n\t\t\t\t\tname,\n\t\t\t\t\tm.Count(),\n\t\t\t\t\tm.Rate1(),\n\t\t\t\t\tm.Rate5(),\n\t\t\t\t\tm.Rate15(),\n\t\t\t\t\tm.RateMean(),\n\t\t\t\t))\n\t\t\tcase Timer:\n\t\t\t\tt := metric.Snapshot()\n\t\t\t\tps := t.Percentiles([]float64{0.5, 0.75, 0.95, 0.99, 0.999})\n\t\t\t\tw.Info(fmt.Sprintf(\n\t\t\t\t\t\"timer %s: count: %d min: %d max: %d mean: %.2f stddev: %.2f median: %.2f 75%%: %.2f 95%%: %.2f 99%%: %.2f 99.9%%: %.2f 1-min: %.2f 5-min: %.2f 15-min: %.2f mean-rate: %.2f\",\n\t\t\t\t\tname,\n\t\t\t\t\tt.Count(),\n\t\t\t\t\tt.Min(),\n\t\t\t\t\tt.Max(),\n\t\t\t\t\tt.Mean(),\n\t\t\t\t\tt.StdDev(),\n\t\t\t\t\tps[0],\n\t\t\t\t\tps[1],\n\t\t\t\t\tps[2],\n\t\t\t\t\tps[3],\n\t\t\t\t\tps[4],\n\t\t\t\t\tt.Rate1(),\n\t\t\t\t\tt.Rate5(),\n\t\t\t\t\tt.Rate15(),\n\t\t\t\t\tt.RateMean(),\n\t\t\t\t))\n\t\t\t}\n\t\t})\n\t}\n}\n"
        },
        {
          "name": "timer.go",
          "type": "blob",
          "size": 8.6640625,
          "content": "package metrics\n\nimport (\n\t\"sync\"\n\t\"time\"\n)\n\n// Timers capture the duration and rate of events.\ntype Timer interface {\n\tCount() int64\n\tMax() int64\n\tMean() float64\n\tMin() int64\n\tPercentile(float64) float64\n\tPercentiles([]float64) []float64\n\tRate1() float64\n\tRate5() float64\n\tRate15() float64\n\tRateMean() float64\n\tSnapshot() Timer\n\tStdDev() float64\n\tStop()\n\tSum() int64\n\tTime(func())\n\tUpdate(time.Duration)\n\tUpdateSince(time.Time)\n\tVariance() float64\n}\n\n// GetOrRegisterTimer returns an existing Timer or constructs and registers a\n// new StandardTimer.\n// Be sure to unregister the meter from the registry once it is of no use to\n// allow for garbage collection.\nfunc GetOrRegisterTimer(name string, r Registry) Timer {\n\tif nil == r {\n\t\tr = DefaultRegistry\n\t}\n\treturn r.GetOrRegister(name, NewTimer).(Timer)\n}\n\n// NewCustomTimer constructs a new StandardTimer from a Histogram and a Meter.\n// Be sure to call Stop() once the timer is of no use to allow for garbage collection.\nfunc NewCustomTimer(h Histogram, m Meter) Timer {\n\tif UseNilMetrics {\n\t\treturn NilTimer{}\n\t}\n\treturn &StandardTimer{\n\t\thistogram: h,\n\t\tmeter:     m,\n\t}\n}\n\n// NewRegisteredTimer constructs and registers a new StandardTimer.\n// Be sure to unregister the meter from the registry once it is of no use to\n// allow for garbage collection.\nfunc NewRegisteredTimer(name string, r Registry) Timer {\n\tc := NewTimer()\n\tif nil == r {\n\t\tr = DefaultRegistry\n\t}\n\tr.Register(name, c)\n\treturn c\n}\n\n// NewTimer constructs a new StandardTimer using an exponentially-decaying\n// sample with the same reservoir size and alpha as UNIX load averages.\n// Be sure to call Stop() once the timer is of no use to allow for garbage collection.\nfunc NewTimer() Timer {\n\tif UseNilMetrics {\n\t\treturn NilTimer{}\n\t}\n\treturn &StandardTimer{\n\t\thistogram: NewHistogram(NewExpDecaySample(1028, 0.015)),\n\t\tmeter:     NewMeter(),\n\t}\n}\n\n// NilTimer is a no-op Timer.\ntype NilTimer struct {\n\th Histogram\n\tm Meter\n}\n\n// Count is a no-op.\nfunc (NilTimer) Count() int64 { return 0 }\n\n// Max is a no-op.\nfunc (NilTimer) Max() int64 { return 0 }\n\n// Mean is a no-op.\nfunc (NilTimer) Mean() float64 { return 0.0 }\n\n// Min is a no-op.\nfunc (NilTimer) Min() int64 { return 0 }\n\n// Percentile is a no-op.\nfunc (NilTimer) Percentile(p float64) float64 { return 0.0 }\n\n// Percentiles is a no-op.\nfunc (NilTimer) Percentiles(ps []float64) []float64 {\n\treturn make([]float64, len(ps))\n}\n\n// Rate1 is a no-op.\nfunc (NilTimer) Rate1() float64 { return 0.0 }\n\n// Rate5 is a no-op.\nfunc (NilTimer) Rate5() float64 { return 0.0 }\n\n// Rate15 is a no-op.\nfunc (NilTimer) Rate15() float64 { return 0.0 }\n\n// RateMean is a no-op.\nfunc (NilTimer) RateMean() float64 { return 0.0 }\n\n// Snapshot is a no-op.\nfunc (NilTimer) Snapshot() Timer { return NilTimer{} }\n\n// StdDev is a no-op.\nfunc (NilTimer) StdDev() float64 { return 0.0 }\n\n// Stop is a no-op.\nfunc (NilTimer) Stop() {}\n\n// Sum is a no-op.\nfunc (NilTimer) Sum() int64 { return 0 }\n\n// Time is a no-op.\nfunc (NilTimer) Time(func()) {}\n\n// Update is a no-op.\nfunc (NilTimer) Update(time.Duration) {}\n\n// UpdateSince is a no-op.\nfunc (NilTimer) UpdateSince(time.Time) {}\n\n// Variance is a no-op.\nfunc (NilTimer) Variance() float64 { return 0.0 }\n\n// StandardTimer is the standard implementation of a Timer and uses a Histogram\n// and Meter.\ntype StandardTimer struct {\n\thistogram Histogram\n\tmeter     Meter\n\tmutex     sync.Mutex\n}\n\n// Count returns the number of events recorded.\nfunc (t *StandardTimer) Count() int64 {\n\treturn t.histogram.Count()\n}\n\n// Max returns the maximum value in the sample.\nfunc (t *StandardTimer) Max() int64 {\n\treturn t.histogram.Max()\n}\n\n// Mean returns the mean of the values in the sample.\nfunc (t *StandardTimer) Mean() float64 {\n\treturn t.histogram.Mean()\n}\n\n// Min returns the minimum value in the sample.\nfunc (t *StandardTimer) Min() int64 {\n\treturn t.histogram.Min()\n}\n\n// Percentile returns an arbitrary percentile of the values in the sample.\nfunc (t *StandardTimer) Percentile(p float64) float64 {\n\treturn t.histogram.Percentile(p)\n}\n\n// Percentiles returns a slice of arbitrary percentiles of the values in the\n// sample.\nfunc (t *StandardTimer) Percentiles(ps []float64) []float64 {\n\treturn t.histogram.Percentiles(ps)\n}\n\n// Rate1 returns the one-minute moving average rate of events per second.\nfunc (t *StandardTimer) Rate1() float64 {\n\treturn t.meter.Rate1()\n}\n\n// Rate5 returns the five-minute moving average rate of events per second.\nfunc (t *StandardTimer) Rate5() float64 {\n\treturn t.meter.Rate5()\n}\n\n// Rate15 returns the fifteen-minute moving average rate of events per second.\nfunc (t *StandardTimer) Rate15() float64 {\n\treturn t.meter.Rate15()\n}\n\n// RateMean returns the meter's mean rate of events per second.\nfunc (t *StandardTimer) RateMean() float64 {\n\treturn t.meter.RateMean()\n}\n\n// Snapshot returns a read-only copy of the timer.\nfunc (t *StandardTimer) Snapshot() Timer {\n\tt.mutex.Lock()\n\tdefer t.mutex.Unlock()\n\treturn &TimerSnapshot{\n\t\thistogram: t.histogram.Snapshot().(*HistogramSnapshot),\n\t\tmeter:     t.meter.Snapshot().(*MeterSnapshot),\n\t}\n}\n\n// StdDev returns the standard deviation of the values in the sample.\nfunc (t *StandardTimer) StdDev() float64 {\n\treturn t.histogram.StdDev()\n}\n\n// Stop stops the meter.\nfunc (t *StandardTimer) Stop() {\n\tt.meter.Stop()\n}\n\n// Sum returns the sum in the sample.\nfunc (t *StandardTimer) Sum() int64 {\n\treturn t.histogram.Sum()\n}\n\n// Record the duration of the execution of the given function.\nfunc (t *StandardTimer) Time(f func()) {\n\tts := time.Now()\n\tf()\n\tt.Update(time.Since(ts))\n}\n\n// Record the duration of an event.\nfunc (t *StandardTimer) Update(d time.Duration) {\n\tt.mutex.Lock()\n\tdefer t.mutex.Unlock()\n\tt.histogram.Update(int64(d))\n\tt.meter.Mark(1)\n}\n\n// Record the duration of an event that started at a time and ends now.\nfunc (t *StandardTimer) UpdateSince(ts time.Time) {\n\tt.mutex.Lock()\n\tdefer t.mutex.Unlock()\n\tt.histogram.Update(int64(time.Since(ts)))\n\tt.meter.Mark(1)\n}\n\n// Variance returns the variance of the values in the sample.\nfunc (t *StandardTimer) Variance() float64 {\n\treturn t.histogram.Variance()\n}\n\n// TimerSnapshot is a read-only copy of another Timer.\ntype TimerSnapshot struct {\n\thistogram *HistogramSnapshot\n\tmeter     *MeterSnapshot\n}\n\n// Count returns the number of events recorded at the time the snapshot was\n// taken.\nfunc (t *TimerSnapshot) Count() int64 { return t.histogram.Count() }\n\n// Max returns the maximum value at the time the snapshot was taken.\nfunc (t *TimerSnapshot) Max() int64 { return t.histogram.Max() }\n\n// Mean returns the mean value at the time the snapshot was taken.\nfunc (t *TimerSnapshot) Mean() float64 { return t.histogram.Mean() }\n\n// Min returns the minimum value at the time the snapshot was taken.\nfunc (t *TimerSnapshot) Min() int64 { return t.histogram.Min() }\n\n// Percentile returns an arbitrary percentile of sampled values at the time the\n// snapshot was taken.\nfunc (t *TimerSnapshot) Percentile(p float64) float64 {\n\treturn t.histogram.Percentile(p)\n}\n\n// Percentiles returns a slice of arbitrary percentiles of sampled values at\n// the time the snapshot was taken.\nfunc (t *TimerSnapshot) Percentiles(ps []float64) []float64 {\n\treturn t.histogram.Percentiles(ps)\n}\n\n// Rate1 returns the one-minute moving average rate of events per second at the\n// time the snapshot was taken.\nfunc (t *TimerSnapshot) Rate1() float64 { return t.meter.Rate1() }\n\n// Rate5 returns the five-minute moving average rate of events per second at\n// the time the snapshot was taken.\nfunc (t *TimerSnapshot) Rate5() float64 { return t.meter.Rate5() }\n\n// Rate15 returns the fifteen-minute moving average rate of events per second\n// at the time the snapshot was taken.\nfunc (t *TimerSnapshot) Rate15() float64 { return t.meter.Rate15() }\n\n// RateMean returns the meter's mean rate of events per second at the time the\n// snapshot was taken.\nfunc (t *TimerSnapshot) RateMean() float64 { return t.meter.RateMean() }\n\n// Snapshot returns the snapshot.\nfunc (t *TimerSnapshot) Snapshot() Timer { return t }\n\n// StdDev returns the standard deviation of the values at the time the snapshot\n// was taken.\nfunc (t *TimerSnapshot) StdDev() float64 { return t.histogram.StdDev() }\n\n// Stop is a no-op.\nfunc (t *TimerSnapshot) Stop() {}\n\n// Sum returns the sum at the time the snapshot was taken.\nfunc (t *TimerSnapshot) Sum() int64 { return t.histogram.Sum() }\n\n// Time panics.\nfunc (*TimerSnapshot) Time(func()) {\n\tpanic(\"Time called on a TimerSnapshot\")\n}\n\n// Update panics.\nfunc (*TimerSnapshot) Update(time.Duration) {\n\tpanic(\"Update called on a TimerSnapshot\")\n}\n\n// UpdateSince panics.\nfunc (*TimerSnapshot) UpdateSince(time.Time) {\n\tpanic(\"UpdateSince called on a TimerSnapshot\")\n}\n\n// Variance returns the variance of the values at the time the snapshot was\n// taken.\nfunc (t *TimerSnapshot) Variance() float64 { return t.histogram.Variance() }\n"
        },
        {
          "name": "timer_test.go",
          "type": "blob",
          "size": 2.2822265625,
          "content": "package metrics\n\nimport (\n\t\"fmt\"\n\t\"math\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc BenchmarkTimer(b *testing.B) {\n\ttm := NewTimer()\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\ttm.Update(1)\n\t}\n}\n\nfunc TestGetOrRegisterTimer(t *testing.T) {\n\tr := NewRegistry()\n\tNewRegisteredTimer(\"foo\", r).Update(47)\n\tif tm := GetOrRegisterTimer(\"foo\", r); 1 != tm.Count() {\n\t\tt.Fatal(tm)\n\t}\n}\n\nfunc TestTimerExtremes(t *testing.T) {\n\ttm := NewTimer()\n\ttm.Update(math.MaxInt64)\n\ttm.Update(0)\n\tif stdDev := tm.StdDev(); 4.611686018427388e+18 != stdDev {\n\t\tt.Errorf(\"tm.StdDev(): 4.611686018427388e+18 != %v\\n\", stdDev)\n\t}\n}\n\nfunc TestTimerStop(t *testing.T) {\n\tl := len(arbiter.meters)\n\ttm := NewTimer()\n\tif len(arbiter.meters) != l+1 {\n\t\tt.Errorf(\"arbiter.meters: %d != %d\\n\", l+1, len(arbiter.meters))\n\t}\n\ttm.Stop()\n\tif len(arbiter.meters) != l {\n\t\tt.Errorf(\"arbiter.meters: %d != %d\\n\", l, len(arbiter.meters))\n\t}\n}\n\nfunc TestTimerFunc(t *testing.T) {\n\ttm := NewTimer()\n\ttm.Time(func() { time.Sleep(50e6) })\n\tif max := tm.Max(); 45e6 > max || max > 55e6 {\n\t\tt.Errorf(\"tm.Max(): 45e6 > %v || %v > 55e6\\n\", max, max)\n\t}\n}\n\nfunc TestTimerZero(t *testing.T) {\n\ttm := NewTimer()\n\tif count := tm.Count(); 0 != count {\n\t\tt.Errorf(\"tm.Count(): 0 != %v\\n\", count)\n\t}\n\tif min := tm.Min(); 0 != min {\n\t\tt.Errorf(\"tm.Min(): 0 != %v\\n\", min)\n\t}\n\tif max := tm.Max(); 0 != max {\n\t\tt.Errorf(\"tm.Max(): 0 != %v\\n\", max)\n\t}\n\tif mean := tm.Mean(); 0.0 != mean {\n\t\tt.Errorf(\"tm.Mean(): 0.0 != %v\\n\", mean)\n\t}\n\tif stdDev := tm.StdDev(); 0.0 != stdDev {\n\t\tt.Errorf(\"tm.StdDev(): 0.0 != %v\\n\", stdDev)\n\t}\n\tps := tm.Percentiles([]float64{0.5, 0.75, 0.99})\n\tif 0.0 != ps[0] {\n\t\tt.Errorf(\"median: 0.0 != %v\\n\", ps[0])\n\t}\n\tif 0.0 != ps[1] {\n\t\tt.Errorf(\"75th percentile: 0.0 != %v\\n\", ps[1])\n\t}\n\tif 0.0 != ps[2] {\n\t\tt.Errorf(\"99th percentile: 0.0 != %v\\n\", ps[2])\n\t}\n\tif rate1 := tm.Rate1(); 0.0 != rate1 {\n\t\tt.Errorf(\"tm.Rate1(): 0.0 != %v\\n\", rate1)\n\t}\n\tif rate5 := tm.Rate5(); 0.0 != rate5 {\n\t\tt.Errorf(\"tm.Rate5(): 0.0 != %v\\n\", rate5)\n\t}\n\tif rate15 := tm.Rate15(); 0.0 != rate15 {\n\t\tt.Errorf(\"tm.Rate15(): 0.0 != %v\\n\", rate15)\n\t}\n\tif rateMean := tm.RateMean(); 0.0 != rateMean {\n\t\tt.Errorf(\"tm.RateMean(): 0.0 != %v\\n\", rateMean)\n\t}\n}\n\nfunc ExampleGetOrRegisterTimer() {\n\tm := \"account.create.latency\"\n\tt := GetOrRegisterTimer(m, nil)\n\tt.Update(47)\n\tfmt.Println(t.Max()) // Output: 47\n}\n"
        },
        {
          "name": "validate.sh",
          "type": "blob",
          "size": 0.2392578125,
          "content": "#!/bin/bash\n\nset -e\n\n# check there are no formatting issues\nGOFMT_LINES=`gofmt -l . | wc -l | xargs`\ntest $GOFMT_LINES -eq 0 || echo \"gofmt needs to be run, ${GOFMT_LINES} files have issues\"\n\n# run the tests for the root package\ngo test -race .\n"
        },
        {
          "name": "writer.go",
          "type": "blob",
          "size": 3.4775390625,
          "content": "package metrics\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"sort\"\n\t\"time\"\n)\n\n// Write sorts writes each metric in the given registry periodically to the\n// given io.Writer.\nfunc Write(r Registry, d time.Duration, w io.Writer) {\n\tfor _ = range time.Tick(d) {\n\t\tWriteOnce(r, w)\n\t}\n}\n\n// WriteOnce sorts and writes metrics in the given registry to the given\n// io.Writer.\nfunc WriteOnce(r Registry, w io.Writer) {\n\tvar namedMetrics namedMetricSlice\n\tr.Each(func(name string, i interface{}) {\n\t\tnamedMetrics = append(namedMetrics, namedMetric{name, i})\n\t})\n\n\tsort.Sort(namedMetrics)\n\tfor _, namedMetric := range namedMetrics {\n\t\tswitch metric := namedMetric.m.(type) {\n\t\tcase Counter:\n\t\t\tfmt.Fprintf(w, \"counter %s\\n\", namedMetric.name)\n\t\t\tfmt.Fprintf(w, \"  count:       %9d\\n\", metric.Count())\n\t\tcase Gauge:\n\t\t\tfmt.Fprintf(w, \"gauge %s\\n\", namedMetric.name)\n\t\t\tfmt.Fprintf(w, \"  value:       %9d\\n\", metric.Value())\n\t\tcase GaugeFloat64:\n\t\t\tfmt.Fprintf(w, \"gauge %s\\n\", namedMetric.name)\n\t\t\tfmt.Fprintf(w, \"  value:       %f\\n\", metric.Value())\n\t\tcase Healthcheck:\n\t\t\tmetric.Check()\n\t\t\tfmt.Fprintf(w, \"healthcheck %s\\n\", namedMetric.name)\n\t\t\tfmt.Fprintf(w, \"  error:       %v\\n\", metric.Error())\n\t\tcase Histogram:\n\t\t\th := metric.Snapshot()\n\t\t\tps := h.Percentiles([]float64{0.5, 0.75, 0.95, 0.99, 0.999})\n\t\t\tfmt.Fprintf(w, \"histogram %s\\n\", namedMetric.name)\n\t\t\tfmt.Fprintf(w, \"  count:       %9d\\n\", h.Count())\n\t\t\tfmt.Fprintf(w, \"  min:         %9d\\n\", h.Min())\n\t\t\tfmt.Fprintf(w, \"  max:         %9d\\n\", h.Max())\n\t\t\tfmt.Fprintf(w, \"  mean:        %12.2f\\n\", h.Mean())\n\t\t\tfmt.Fprintf(w, \"  stddev:      %12.2f\\n\", h.StdDev())\n\t\t\tfmt.Fprintf(w, \"  median:      %12.2f\\n\", ps[0])\n\t\t\tfmt.Fprintf(w, \"  75%%:         %12.2f\\n\", ps[1])\n\t\t\tfmt.Fprintf(w, \"  95%%:         %12.2f\\n\", ps[2])\n\t\t\tfmt.Fprintf(w, \"  99%%:         %12.2f\\n\", ps[3])\n\t\t\tfmt.Fprintf(w, \"  99.9%%:       %12.2f\\n\", ps[4])\n\t\tcase Meter:\n\t\t\tm := metric.Snapshot()\n\t\t\tfmt.Fprintf(w, \"meter %s\\n\", namedMetric.name)\n\t\t\tfmt.Fprintf(w, \"  count:       %9d\\n\", m.Count())\n\t\t\tfmt.Fprintf(w, \"  1-min rate:  %12.2f\\n\", m.Rate1())\n\t\t\tfmt.Fprintf(w, \"  5-min rate:  %12.2f\\n\", m.Rate5())\n\t\t\tfmt.Fprintf(w, \"  15-min rate: %12.2f\\n\", m.Rate15())\n\t\t\tfmt.Fprintf(w, \"  mean rate:   %12.2f\\n\", m.RateMean())\n\t\tcase Timer:\n\t\t\tt := metric.Snapshot()\n\t\t\tps := t.Percentiles([]float64{0.5, 0.75, 0.95, 0.99, 0.999})\n\t\t\tfmt.Fprintf(w, \"timer %s\\n\", namedMetric.name)\n\t\t\tfmt.Fprintf(w, \"  count:       %9d\\n\", t.Count())\n\t\t\tfmt.Fprintf(w, \"  min:         %9d\\n\", t.Min())\n\t\t\tfmt.Fprintf(w, \"  max:         %9d\\n\", t.Max())\n\t\t\tfmt.Fprintf(w, \"  mean:        %12.2f\\n\", t.Mean())\n\t\t\tfmt.Fprintf(w, \"  stddev:      %12.2f\\n\", t.StdDev())\n\t\t\tfmt.Fprintf(w, \"  median:      %12.2f\\n\", ps[0])\n\t\t\tfmt.Fprintf(w, \"  75%%:         %12.2f\\n\", ps[1])\n\t\t\tfmt.Fprintf(w, \"  95%%:         %12.2f\\n\", ps[2])\n\t\t\tfmt.Fprintf(w, \"  99%%:         %12.2f\\n\", ps[3])\n\t\t\tfmt.Fprintf(w, \"  99.9%%:       %12.2f\\n\", ps[4])\n\t\t\tfmt.Fprintf(w, \"  1-min rate:  %12.2f\\n\", t.Rate1())\n\t\t\tfmt.Fprintf(w, \"  5-min rate:  %12.2f\\n\", t.Rate5())\n\t\t\tfmt.Fprintf(w, \"  15-min rate: %12.2f\\n\", t.Rate15())\n\t\t\tfmt.Fprintf(w, \"  mean rate:   %12.2f\\n\", t.RateMean())\n\t\t}\n\t}\n}\n\ntype namedMetric struct {\n\tname string\n\tm    interface{}\n}\n\n// namedMetricSlice is a slice of namedMetrics that implements sort.Interface.\ntype namedMetricSlice []namedMetric\n\nfunc (nms namedMetricSlice) Len() int { return len(nms) }\n\nfunc (nms namedMetricSlice) Swap(i, j int) { nms[i], nms[j] = nms[j], nms[i] }\n\nfunc (nms namedMetricSlice) Less(i, j int) bool {\n\treturn nms[i].name < nms[j].name\n}\n"
        },
        {
          "name": "writer_test.go",
          "type": "blob",
          "size": 0.3330078125,
          "content": "package metrics\n\nimport (\n\t\"sort\"\n\t\"testing\"\n)\n\nfunc TestMetricsSorting(t *testing.T) {\n\tvar namedMetrics = namedMetricSlice{\n\t\t{name: \"zzz\"},\n\t\t{name: \"bbb\"},\n\t\t{name: \"fff\"},\n\t\t{name: \"ggg\"},\n\t}\n\n\tsort.Sort(namedMetrics)\n\tfor i, name := range []string{\"bbb\", \"fff\", \"ggg\", \"zzz\"} {\n\t\tif namedMetrics[i].name != name {\n\t\t\tt.Fail()\n\t\t}\n\t}\n}\n"
        }
      ]
    }
  ]
}