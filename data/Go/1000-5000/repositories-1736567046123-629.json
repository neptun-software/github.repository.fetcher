{
  "metadata": {
    "timestamp": 1736567046123,
    "page": 629,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjYzMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "benmanns/goworker",
      "stars": 2805,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.392578125,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2013 Benjamin Manns\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\nthe Software, and to permit persons to whom the Software is furnished to do so,\nsubject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\nCONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nThe goworker Logo\n\nThe goworker logo is a work by Rachel Falwell combining the Go mascot by Renée\nFrench (CC-BY) and the Ruby logo by the Ruby Visual Identity Team (CC-BY-SA).\nThe logo is released under a Creative Commons Attribution-ShareAlike 4.0\nInternational License in keeping with the restrictions of the works from which\nit is derived.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.58984375,
          "content": "# goworker\n\n![Build](https://github.com/benmanns/goworker/workflows/Go/badge.svg)\n[![GoDoc](https://godoc.org/github.com/benmanns/goworker?status.svg)](https://godoc.org/github.com/benmanns/goworker)\n\ngoworker is a Resque-compatible, Go-based background worker. It allows you to push jobs into a queue using an expressive language like Ruby while harnessing the efficiency and concurrency of Go to minimize job latency and cost.\n\ngoworker workers can run alongside Ruby Resque clients so that you can keep all but your most resource-intensive jobs in Ruby.\n\n## Installation\n\nTo install goworker, use\n\n```sh\ngo get github.com/benmanns/goworker\n```\n\nto install the package, and then from your worker\n\n```go\nimport \"github.com/benmanns/goworker\"\n```\n\n## Getting Started\n\nTo create a worker, write a function matching the signature\n\n```go\nfunc(string, ...interface{}) error\n```\n\nand register it using\n\n```go\ngoworker.Register(\"MyClass\", myFunc)\n```\n\nHere is a simple worker that prints its arguments:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"github.com/benmanns/goworker\"\n)\n\nfunc myFunc(queue string, args ...interface{}) error {\n\tfmt.Printf(\"From %s, %v\\n\", queue, args)\n\treturn nil\n}\n\nfunc init() {\n\tgoworker.Register(\"MyClass\", myFunc)\n}\n\nfunc main() {\n\tif err := goworker.Work(); err != nil {\n\t\tfmt.Println(\"Error:\", err)\n\t}\n}\n```\n\nTo create workers that share a database pool or other resources, use a closure to share variables.\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"github.com/benmanns/goworker\"\n)\n\nfunc newMyFunc(uri string) (func(queue string, args ...interface{}) error) {\n\tfoo := NewFoo(uri)\n\treturn func(queue string, args ...interface{}) error {\n\t\tfoo.Bar(args)\n\t\treturn nil\n\t}\n}\n\nfunc init() {\n\tgoworker.Register(\"MyClass\", newMyFunc(\"http://www.example.com/\"))\n}\n\nfunc main() {\n\tif err := goworker.Work(); err != nil {\n\t\tfmt.Println(\"Error:\", err)\n\t}\n}\n```\n\nHere is a simple worker with settings:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"github.com/benmanns/goworker\"\n)\n\nfunc myFunc(queue string, args ...interface{}) error {\n\tfmt.Printf(\"From %s, %v\\n\", queue, args)\n\treturn nil\n}\n\nfunc init() {\n\tsettings := goworker.WorkerSettings{\n\t\tURI:            \"redis://localhost:6379/\",\n\t\tConnections:    100,\n\t\tQueues:         []string{\"myqueue\", \"delimited\", \"queues\"},\n\t\tUseNumber:      true,\n\t\tExitOnComplete: false,\n\t\tConcurrency:    2,\n\t\tNamespace:      \"resque:\",\n\t\tInterval:       5.0,\n\t}\n\tgoworker.SetSettings(settings)\n\tgoworker.Register(\"MyClass\", myFunc)\n}\n\nfunc main() {\n\tif err := goworker.Work(); err != nil {\n\t\tfmt.Println(\"Error:\", err)\n\t}\n}\n```\n\ngoworker worker functions receive the queue they are serving and a slice of interfaces. To use them as parameters to other functions, use Go type assertions to convert them into usable types.\n\n```go\n// Expecting (int, string, float64)\nfunc myFunc(queue, args ...interface{}) error {\n\tidNum, ok := args[0].(json.Number)\n\tif !ok {\n\t\treturn errorInvalidParam\n\t}\n\tid, err := idNum.Int64()\n\tif err != nil {\n\t\treturn errorInvalidParam\n\t}\n\tname, ok := args[1].(string)\n\tif !ok {\n\t\treturn errorInvalidParam\n\t}\n\tweightNum, ok := args[2].(json.Number)\n\tif !ok {\n\t\treturn errorInvalidParam\n\t}\n\tweight, err := weightNum.Float64()\n\tif err != nil {\n\t\treturn errorInvalidParam\n\t}\n\tdoSomething(id, name, weight)\n\treturn nil\n}\n```\n\nFor testing, it is helpful to use the `redis-cli` program to insert jobs onto the Redis queue:\n\n```sh\nredis-cli -r 100 RPUSH resque:queue:myqueue '{\"class\":\"MyClass\",\"args\":[\"hi\",\"there\"]}'\n```\n\nwill insert 100 jobs for the `MyClass` worker onto the `myqueue` queue. It is equivalent to:\n\n```ruby\nclass MyClass\n  @queue = :myqueue\nend\n\n100.times do\n  Resque.enqueue MyClass, ['hi', 'there']\nend\n```\n\nor\n\n```golang\ngoworker.Enqueue(&goworker.Job{\n    Queue: \"myqueue\",\n    Payload: goworker.Payload{\n        Class: \"MyClass\",\n        Args: []interface{}{\"hi\", \"there\"},\n    },\n})\n```\n\n## Flags\n\nThere are several flags which control the operation of the goworker client.\n\n* `-queues=\"comma,delimited,queues\"` — This is the only required flag. The recommended practice is to separate your Resque workers from your goworkers with different queues. Otherwise, Resque worker classes that have no goworker analog will cause the goworker process to fail the jobs. Because of this, there is no default queue, nor is there a way to select all queues (à la Resque's `*` queue). If you have multiple queues you can assign them weights. A queue with a weight of 2 will be checked twice as often as a queue with a weight of 1: `-queues='high=2,low=1'`.\n* `-interval=5.0` — Specifies the wait period between polling if no job was in the queue the last time one was requested.\n* `-concurrency=25` — Specifies the number of concurrently executing workers. This number can be as low as 1 or rather comfortably as high as 100,000, and should be tuned to your workflow and the availability of outside resources.\n* `-connections=2` — Specifies the maximum number of Redis connections that goworker will consume between the poller and all workers. There is not much performance gain over two and a slight penalty when using only one. This is configurable in case you need to keep connection counts low for cloud Redis providers who limit plans on `maxclients`.\n* `-uri=redis://localhost:6379/` — Specifies the URI of the Redis database from which goworker polls for jobs. Accepts URIs of the format `redis://user:pass@host:port/db` or `unix:///path/to/redis.sock`. The flag may also be set by the environment variable `$($REDIS_PROVIDER)` or `$REDIS_URL`. E.g. set `$REDIS_PROVIDER` to `REDISTOGO_URL` on Heroku to let the Redis To Go add-on configure the Redis database.\n* `-namespace=resque:` — Specifies the namespace from which goworker retrieves jobs and stores stats on workers.\n* `-exit-on-complete=false` — Exits goworker when there are no jobs left in the queue. This is helpful in conjunction with the `time` command to benchmark different configurations.\n\nYou can also configure your own flags for use within your workers. Be sure to set them before calling `goworker.Main()`. It is okay to call `flags.Parse()` before calling `goworker.Main()` if you need to do additional processing on your flags.\n\n## Signal Handling in goworker\n\nTo stop goworker, send a `QUIT`, `TERM`, or `INT` signal to the process. This will immediately stop job polling. There can be up to `$CONCURRENCY` jobs currently running, which will continue to run until they are finished.\n\n## Failure Modes\n\nLike Resque, goworker makes no guarantees about the safety of jobs in the event of process shutdown. Workers must be both idempotent and tolerant to loss of the job in the event of failure.\n\nIf the process is killed with a `KILL` or by a system failure, there may be one job that is currently in the poller's buffer that will be lost without any representation in either the queue or the worker variable.\n\nIf you are running goworker on a system like Heroku, which sends a `TERM` to signal a process that it needs to stop, ten seconds later sends a `KILL` to force the process to stop, your jobs must finish within 10 seconds or they may be lost. Jobs will be recoverable from the Redis database under\n\n```\nresque:worker:<hostname>:<process-id>-<worker-id>:<queues>\n```\n\nas a JSON object with keys `queue`, `run_at`, and `payload`, but the process is manual. Additionally, there is no guarantee that the job in Redis under the worker key has not finished, if the process is killed before goworker can flush the update to Redis.\n\n## Contributing\n\n1. [Fork it](https://github.com/benmanns/goworker/fork)\n2. Create your feature branch (`git checkout -b my-new-feature`)\n3. Commit your changes (`git commit -am 'Add some feature'`)\n4. Push to the branch (`git push origin my-new-feature`)\n5. Create new Pull Request\n"
        },
        {
          "name": "doc.go",
          "type": "blob",
          "size": 2.7783203125,
          "content": "// Package goworker is a Resque-compatible, Go-based\n// background worker. It allows you to push jobs into a\n// queue using an expressive language like Ruby while\n// harnessing the efficiency and concurrency of Go to\n// minimize job latency and cost.\n//\n// goworker workers can run alongside Ruby Resque clients\n// so that you can keep all but your most\n// resource-intensive jobs in Ruby.\n//\n// To create a worker, write a function matching the\n// signature\n//\n//\tfunc(string, ...interface{}) error\n//\n// and register it using\n//\n//\tgoworker.Register(\"MyClass\", myFunc)\n//\n// Here is a simple worker that prints its arguments:\n//\n//\tpackage main\n//\n//\timport (\n//\t\t\"fmt\"\n//\t\t\"github.com/benmanns/goworker\"\n//\t)\n//\n//\tfunc myFunc(queue string, args ...interface{}) error {\n//\t\tfmt.Printf(\"From %s, %v\\n\", queue, args)\n//\t\treturn nil\n//\t}\n//\n//\tfunc init() {\n//\t\tgoworker.Register(\"MyClass\", myFunc)\n//\t}\n//\n//\tfunc main() {\n//\t\tif err := goworker.Work(); err != nil {\n//\t\t\tfmt.Println(\"Error:\", err)\n//\t\t}\n//\t}\n//\n// To create workers that share a database pool or other\n// resources, use a closure to share variables.\n//\n//\tpackage main\n//\n//\timport (\n//\t\t\"fmt\"\n//\t\t\"github.com/benmanns/goworker\"\n//\t)\n//\n//\tfunc newMyFunc(uri string) (func(queue string, args ...interface{}) error) {\n//\t\tfoo := NewFoo(uri)\n//\t\treturn func(queue string, args ...interface{}) error {\n//\t\t\tfoo.Bar(args)\n//\t\t\treturn nil\n//\t\t}\n//\t}\n//\n//\tfunc init() {\n//\t\tgoworker.Register(\"MyClass\", newMyFunc(\"http://www.example.com/\"))\n//\t}\n//\n//\tfunc main() {\n//\t\tif err := goworker.Work(); err != nil {\n//\t\t\tfmt.Println(\"Error:\", err)\n//\t\t}\n//\t}\n//\n// goworker worker functions receive the queue they are\n// serving and a slice of interfaces. To use them as\n// parameters to other functions, use Go type assertions\n// to convert them into usable types.\n//\n//\t// Expecting (int, string, float64)\n//\tfunc myFunc(queue, args ...interface{}) error {\n//\t\tidNum, ok := args[0].(json.Number)\n//\t\tif !ok {\n//\t\t\treturn errorInvalidParam\n//\t\t}\n//\t\tid, err := idNum.Int64()\n//\t\tif err != nil {\n//\t\t\treturn errorInvalidParam\n//\t\t}\n//\t\tname, ok := args[1].(string)\n//\t\tif !ok {\n//\t\t\treturn errorInvalidParam\n//\t\t}\n//\t\tweightNum, ok := args[2].(json.Number)\n//\t\tif !ok {\n//\t\t\treturn errorInvalidParam\n//\t\t}\n//\t\tweight, err := weightNum.Float64()\n//\t\tif err != nil {\n//\t\t\treturn errorInvalidParam\n//\t\t}\n//\t\tdoSomething(id, name, weight)\n//\t\treturn nil\n//\t}\n//\n// For testing, it is helpful to use the redis-cli program\n// to insert jobs onto the Redis queue:\n//\n//\tredis-cli -r 100 RPUSH resque:queue:myqueue '{\"class\":\"MyClass\",\"args\":[\"hi\",\"there\"]}'\n//\n// will insert 100 jobs for the MyClass worker onto the\n// myqueue queue. It is equivalent to:\n//\n//\tclass MyClass\n//\t  @queue = :myqueue\n//\tend\n//\n//\t100.times do\n//\t  Resque.enqueue MyClass, ['hi', 'there']\n//\tend\npackage goworker\n"
        },
        {
          "name": "failure.go",
          "type": "blob",
          "size": 0.3212890625,
          "content": "package goworker\n\nimport (\n\t\"time\"\n)\n\ntype failure struct {\n\tFailedAt  time.Time `json:\"failed_at\"`\n\tPayload   Payload   `json:\"payload\"`\n\tException string    `json:\"exception\"`\n\tError     string    `json:\"error\"`\n\tBacktrace []string  `json:\"backtrace\"`\n\tWorker    *worker   `json:\"worker\"`\n\tQueue     string    `json:\"queue\"`\n}\n"
        },
        {
          "name": "flags.go",
          "type": "blob",
          "size": 5.2509765625,
          "content": "// Running goworker\n//\n// After building your workers, you will have an\n// executable that you can run which will\n// automatically poll a Redis server and call\n// your workers as jobs arrive.\n//\n// Flags\n//\n// There are several flags which control the\n// operation of the goworker client.\n//\n// -queues=\"comma,delimited,queues\"\n// — This is the only required flag. The\n// recommended practice is to separate your\n// Resque workers from your goworkers with\n// different queues. Otherwise, Resque worker\n// classes that have no goworker analog will\n// cause the goworker process to fail the jobs.\n// Because of this, there is no default queue,\n// nor is there a way to select all queues (à la\n// Resque's * queue). Queues are processed in\n// the order they are specififed.\n// If you have multiple queues you can assign\n// them weights. A queue with a weight of 2 will\n// be checked twice as often as a queue with a\n// weight of 1: -queues='high=2,low=1'.\n//\n// -interval=5.0\n// — Specifies the wait period between polling if\n// no job was in the queue the last time one was\n// requested.\n//\n// -concurrency=25\n// — Specifies the number of concurrently\n// executing workers. This number can be as low\n// as 1 or rather comfortably as high as 100,000,\n// and should be tuned to your workflow and the\n// availability of outside resources.\n//\n// -connections=2\n// — Specifies the maximum number of Redis\n// connections that goworker will consume between\n// the poller and all workers. There is not much\n// performance gain over two and a slight penalty\n// when using only one. This is configurable in\n// case you need to keep connection counts low\n// for cloud Redis providers who limit plans on\n// maxclients.\n//\n// -uri=redis://localhost:6379/\n// — Specifies the URI of the Redis database from\n// which goworker polls for jobs. Accepts URIs of\n// the format redis://user:pass@host:port/db or\n// unix:///path/to/redis.sock. The flag may also\n// be set by the environment variable\n// $($REDIS_PROVIDER) or $REDIS_URL. E.g. set\n// $REDIS_PROVIDER to REDISTOGO_URL on Heroku to\n// let the Redis To Go add-on configure the Redis\n// database.\n//\n// -namespace=resque:\n// — Specifies the namespace from which goworker\n// retrieves jobs and stores stats on workers.\n//\n// -exit-on-complete=false\n// — Exits goworker when there are no jobs left\n// in the queue. This is helpful in conjunction\n// with the time command to benchmark different\n// configurations.\n//\n// -use-number=false\n// — Uses json.Number when decoding numbers in the\n// job payloads. This will avoid issues that\n// occur when goworker and the json package decode\n// large numbers as floats, which then get\n// encoded in scientific notation, losing\n// pecision. This will default to true soon.\n//\n// You can also configure your own flags for use\n// within your workers. Be sure to set them\n// before calling goworker.Main(). It is okay to\n// call flags.Parse() before calling\n// goworker.Main() if you need to do additional\n// processing on your flags.\npackage goworker\n\nimport (\n\t\"flag\"\n\t\"os\"\n\t\"strings\"\n)\n\n// Namespace returns the namespace flag for goworker. You\n// can use this with the GetConn and PutConn functions to\n// operate on the same namespace that goworker uses.\nfunc Namespace() string {\n\treturn workerSettings.Namespace\n}\n\nfunc init() {\n\tflag.StringVar(&workerSettings.QueuesString, \"queues\", \"\", \"a comma-separated list of Resque queues\")\n\n\tflag.Float64Var(&workerSettings.IntervalFloat, \"interval\", 5.0, \"sleep interval when no jobs are found\")\n\n\tflag.IntVar(&workerSettings.Concurrency, \"concurrency\", 25, \"the maximum number of concurrently executing jobs\")\n\n\tflag.IntVar(&workerSettings.Connections, \"connections\", 2, \"the maximum number of connections to the Redis database\")\n\n\tredisProvider := os.Getenv(\"REDIS_PROVIDER\")\n\tvar redisEnvURI string\n\tif redisProvider != \"\" {\n\t\tredisEnvURI = os.Getenv(redisProvider)\n\t} else {\n\t\tredisEnvURI = os.Getenv(\"REDIS_URL\")\n\t}\n\tif redisEnvURI == \"\" {\n\t\tredisEnvURI = \"redis://localhost:6379/\"\n\t}\n\tflag.StringVar(&workerSettings.URI, \"uri\", redisEnvURI, \"the URI of the Redis server\")\n\n\tflag.StringVar(&workerSettings.Namespace, \"namespace\", \"resque:\", \"the Redis namespace\")\n\n\tflag.StringVar(&workerSettings.TLSCertPath, \"tls-cert\", \"\", \"path to a custom CA cert\")\n\n\tflag.BoolVar(&workerSettings.ExitOnComplete, \"exit-on-complete\", false, \"exit when the queue is empty\")\n\n\tflag.BoolVar(&workerSettings.UseNumber, \"use-number\", false, \"use json.Number instead of float64 when decoding numbers in JSON. will default to true soon\")\n\n\tflag.BoolVar(&workerSettings.SkipTLSVerify, \"insecure-tls\", false, \"skip TLS validation\")\n}\n\nfunc flags() error {\n\tif !flag.Parsed() {\n\t\tflag.Parse()\n\t}\n\tif err := workerSettings.Queues.Set(workerSettings.QueuesString); err != nil {\n\t\treturn err\n\t}\n\tif err := workerSettings.Interval.SetFloat(workerSettings.IntervalFloat); err != nil {\n\t\treturn err\n\t}\n\tworkerSettings.IsStrict = strings.IndexRune(workerSettings.QueuesString, '=') == -1\n\n\tif !workerSettings.UseNumber {\n\t\tlogger.Warn(\"== DEPRECATION WARNING ==\")\n\t\tlogger.Warn(\"  Currently, encoding/json decodes numbers as float64.\")\n\t\tlogger.Warn(\"  This can cause numbers to lose precision as they are read from the Resque queue.\")\n\t\tlogger.Warn(\"  Set the -use-number flag to use json.Number when decoding numbers and remove this warning.\")\n\t}\n\n\treturn nil\n}\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.2724609375,
          "content": "module github.com/benmanns/goworker\n\ngo 1.14\n\nrequire (\n\tgithub.com/cihub/seelog v0.0.0-20140730094913-72ae425987bc\n\tgithub.com/gomodule/redigo v1.8.2\n\tgolang.org/x/net v0.0.0-20200822124328-c89045814202\n\tvitess.io/vitess v3.0.0-rc.3.0.20181212200900-e2c5239f54d1+incompatible\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 2.654296875,
          "content": "github.com/cihub/seelog v0.0.0-20140730094913-72ae425987bc h1:HSZdsOzV0MO6cEcf31hZoT6KJGI806Z523bkYPDwkQs=\ngithub.com/cihub/seelog v0.0.0-20140730094913-72ae425987bc/go.mod h1:9d6lWj8KzO/fd/NrVaLscBKmPigpZpn5YawRPw+e3Yo=\ngithub.com/davecgh/go-spew v1.1.0 h1:ZDRjVQ15GmhC3fiQ8ni8+OwkZQO4DARzQgrnXU1Liz8=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/gomodule/redigo v1.8.2 h1:H5XSIre1MB5NbPYFp+i1NBbb5qN1W8Y8YAQoAYbkm8k=\ngithub.com/gomodule/redigo v1.8.2/go.mod h1:P9dn9mFrCBvWhGE1wpxx6fgq7BAeLBk+UUUzlpkBYO0=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/testify v1.5.1 h1:nOGnQDM7FYENwehXlg/kFVnos3rEvtKTjRvOWSzb6H4=\ngithub.com/stretchr/testify v1.5.1/go.mod h1:5W2xD1RspED5o8YsWQXVCued0rvSQ+mT+I5cxcmMvtA=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2 h1:VklqNMn3ovrHsnt90PveolxSbWFaJdECFbxSq0Mqo2M=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20200622213623-75b288015ac9/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20200822124328-c89045814202 h1:VvcQYSHwXgi7W+TpUR6A9g6Up98WAHf3f/ulnJ62IyA=\ngolang.org/x/net v0.0.0-20200822124328-c89045814202/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200323222414-85ca7c5b95cd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/text v0.3.0 h1:g61tztE5qeGQ89tm6NTjjM9VPIm088od1l6aSorWRWg=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405 h1:yhCVgyC4o1eVCa2tZl7eS0r+SDo693bJlVdllGtEeKM=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/yaml.v2 v2.2.2 h1:ZCJp+EgiOT7lHqUV2J862kp8Qj64Jo6az82+3Td9dZw=\ngopkg.in/yaml.v2 v2.2.2/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\nvitess.io/vitess v3.0.0-rc.3.0.20181212200900-e2c5239f54d1+incompatible h1:TCG4ZGCiFNr7XGP8nhT++5Wwi1jRC6Xk9IPxZiBQXB0=\nvitess.io/vitess v3.0.0-rc.3.0.20181212200900-e2c5239f54d1+incompatible/go.mod h1:h4qvkyNYTOC0xI+vcidSWoka0gQAZc9ZPHbkHo48gP0=\n"
        },
        {
          "name": "goworker.go",
          "type": "blob",
          "size": 3.3671875,
          "content": "package goworker\n\nimport (\n\t\"os\"\n\t\"strconv\"\n\t\"sync\"\n\t\"time\"\n\n\t\"golang.org/x/net/context\"\n\n\t\"github.com/cihub/seelog\"\n\t\"vitess.io/vitess/go/pools\"\n)\n\nvar (\n\tlogger      seelog.LoggerInterface\n\tpool        *pools.ResourcePool\n\tctx         context.Context\n\tinitMutex   sync.Mutex\n\tinitialized bool\n)\n\nvar workerSettings WorkerSettings\n\ntype WorkerSettings struct {\n\tQueuesString   string\n\tQueues         queuesFlag\n\tIntervalFloat  float64\n\tInterval       intervalFlag\n\tConcurrency    int\n\tConnections    int\n\tURI            string\n\tNamespace      string\n\tExitOnComplete bool\n\tIsStrict       bool\n\tUseNumber      bool\n\tSkipTLSVerify  bool\n\tTLSCertPath    string\n}\n\nfunc SetSettings(settings WorkerSettings) {\n\tworkerSettings = settings\n}\n\n// Init initializes the goworker process. This will be\n// called by the Work function, but may be used by programs\n// that wish to access goworker functions and configuration\n// without actually processing jobs.\nfunc Init() error {\n\tinitMutex.Lock()\n\tdefer initMutex.Unlock()\n\tif !initialized {\n\t\tvar err error\n\t\tlogger, err = seelog.LoggerFromWriterWithMinLevel(os.Stdout, seelog.InfoLvl)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif err := flags(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tctx = context.Background()\n\n\t\tpool = newRedisPool(workerSettings.URI, workerSettings.Connections, workerSettings.Connections, time.Minute)\n\n\t\tinitialized = true\n\t}\n\treturn nil\n}\n\n// GetConn returns a connection from the goworker Redis\n// connection pool. When using the pool, check in\n// connections as quickly as possible, because holding a\n// connection will cause concurrent worker functions to lock\n// while they wait for an available connection. Expect this\n// API to change drastically.\nfunc GetConn() (*RedisConn, error) {\n\tresource, err := pool.Get(ctx)\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn resource.(*RedisConn), nil\n}\n\n// PutConn puts a connection back into the connection pool.\n// Run this as soon as you finish using a connection that\n// you got from GetConn. Expect this API to change\n// drastically.\nfunc PutConn(conn *RedisConn) {\n\tpool.Put(conn)\n}\n\n// Close cleans up resources initialized by goworker. This\n// will be called by Work when cleaning up. However, if you\n// are using the Init function to access goworker functions\n// and configuration without processing jobs by calling\n// Work, you should run this function when cleaning up. For\n// example,\n//\n//\tif err := goworker.Init(); err != nil {\n//\t\tfmt.Println(\"Error:\", err)\n//\t}\n//\tdefer goworker.Close()\nfunc Close() {\n\tinitMutex.Lock()\n\tdefer initMutex.Unlock()\n\tif initialized {\n\t\tpool.Close()\n\t\tinitialized = false\n\t}\n}\n\n// Work starts the goworker process. Check for errors in\n// the return value. Work will take over the Go executable\n// and will run until a QUIT, INT, or TERM signal is\n// received, or until the queues are empty if the\n// -exit-on-complete flag is set.\nfunc Work() error {\n\terr := Init()\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer Close()\n\n\tquit := signals()\n\n\tpoller, err := newPoller(workerSettings.Queues, workerSettings.IsStrict)\n\tif err != nil {\n\t\treturn err\n\t}\n\tjobs, err := poller.poll(time.Duration(workerSettings.Interval), quit)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvar monitor sync.WaitGroup\n\n\tfor id := 0; id < workerSettings.Concurrency; id++ {\n\t\tworker, err := newWorker(strconv.Itoa(id), workerSettings.Queues)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tworker.work(jobs, &monitor)\n\t}\n\n\tmonitor.Wait()\n\n\treturn nil\n}\n"
        },
        {
          "name": "interval_flag.go",
          "type": "blob",
          "size": 0.431640625,
          "content": "package goworker\n\nimport (\n\t\"fmt\"\n\t\"strconv\"\n\t\"time\"\n)\n\ntype intervalFlag time.Duration\n\nfunc (i *intervalFlag) Set(value string) error {\n\tf, err := strconv.ParseFloat(value, 64)\n\tif err != nil {\n\t\treturn err\n\t}\n\ti.SetFloat(f)\n\treturn nil\n}\n\nfunc (i *intervalFlag) SetFloat(value float64) error {\n\t*i = intervalFlag(time.Duration(value * float64(time.Second)))\n\treturn nil\n}\n\nfunc (i *intervalFlag) String() string {\n\treturn fmt.Sprint(*i)\n}\n"
        },
        {
          "name": "interval_flag_test.go",
          "type": "blob",
          "size": 1.69921875,
          "content": "package goworker\n\nimport (\n\t\"testing\"\n\t\"time\"\n)\n\nvar intervalFlagSetTests = []struct {\n\tv        string\n\texpected intervalFlag\n}{\n\t{\n\t\t\"0\",\n\t\tintervalFlag(0),\n\t},\n\t{\n\t\t\"1\",\n\t\tintervalFlag(1 * time.Second),\n\t},\n\t{\n\t\t\"1.5\",\n\t\tintervalFlag(1500 * time.Millisecond),\n\t},\n}\n\nfunc TestIntervalFlagSet(t *testing.T) {\n\tfor _, tt := range intervalFlagSetTests {\n\t\tactual := new(intervalFlag)\n\t\tif err := actual.Set(tt.v); err != nil {\n\t\t\tt.Errorf(\"IntervalFlag(%#v): set to %s error %s\", actual, tt.v, err)\n\t\t} else {\n\t\t\tif *actual != tt.expected {\n\t\t\t\tt.Errorf(\"IntervalFlag: set to %s expected %v, actual %v\", tt.v, tt.expected, actual)\n\t\t\t}\n\t\t}\n\t}\n}\n\nvar intervalFlagSetFloatTests = []struct {\n\tv        float64\n\texpected intervalFlag\n}{\n\t{\n\t\t0.0,\n\t\tintervalFlag(0),\n\t},\n\t{\n\t\t1.0,\n\t\tintervalFlag(1 * time.Second),\n\t},\n\t{\n\t\t1.5,\n\t\tintervalFlag(1500 * time.Millisecond),\n\t},\n}\n\nfunc TestIntervalFlagSetFloat(t *testing.T) {\n\tfor _, tt := range intervalFlagSetFloatTests {\n\t\tactual := new(intervalFlag)\n\t\tif err := actual.SetFloat(tt.v); err != nil {\n\t\t\tt.Errorf(\"IntervalFlag(%#v): set to %f error %s\", actual, tt.v, err)\n\t\t} else {\n\t\t\tif *actual != tt.expected {\n\t\t\t\tt.Errorf(\"IntervalFlag: set to %f expected %v, actual %v\", tt.v, tt.expected, actual)\n\t\t\t}\n\t\t}\n\t}\n}\n\nvar intervalFlagStringTests = []struct {\n\ti        intervalFlag\n\texpected string\n}{\n\t{\n\t\tintervalFlag(0),\n\t\t\"0\",\n\t},\n\t{\n\t\tintervalFlag(1 * time.Second),\n\t\t\"1000000000\",\n\t},\n\t{\n\t\tintervalFlag(1500 * time.Millisecond),\n\t\t\"1500000000\",\n\t},\n}\n\nfunc TestIntervalFlagString(t *testing.T) {\n\tfor _, tt := range intervalFlagStringTests {\n\t\tactual := tt.i.String()\n\t\tif actual != tt.expected {\n\t\t\tt.Errorf(\"IntervalFlag(%#v): expected %s, actual %s\", tt.i, tt.expected, actual)\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "job.go",
          "type": "blob",
          "size": 0.0693359375,
          "content": "package goworker\n\ntype Job struct {\n\tQueue   string\n\tPayload Payload\n}\n"
        },
        {
          "name": "payload.go",
          "type": "blob",
          "size": 0.1103515625,
          "content": "package goworker\n\ntype Payload struct {\n\tClass string        `json:\"class\"`\n\tArgs  []interface{} `json:\"args\"`\n}\n"
        },
        {
          "name": "poller.go",
          "type": "blob",
          "size": 2.8408203125,
          "content": "package goworker\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"time\"\n)\n\ntype poller struct {\n\tprocess\n\tisStrict bool\n}\n\nfunc newPoller(queues []string, isStrict bool) (*poller, error) {\n\tprocess, err := newProcess(\"poller\", queues)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &poller{\n\t\tprocess:  *process,\n\t\tisStrict: isStrict,\n\t}, nil\n}\n\nfunc (p *poller) getJob(conn *RedisConn) (*Job, error) {\n\tfor _, queue := range p.queues(p.isStrict) {\n\t\tlogger.Debugf(\"Checking %s\", queue)\n\n\t\treply, err := conn.Do(\"LPOP\", fmt.Sprintf(\"%squeue:%s\", workerSettings.Namespace, queue))\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif reply != nil {\n\t\t\tlogger.Debugf(\"Found job on %s\", queue)\n\n\t\t\tjob := &Job{Queue: queue}\n\n\t\t\tdecoder := json.NewDecoder(bytes.NewReader(reply.([]byte)))\n\t\t\tif workerSettings.UseNumber {\n\t\t\t\tdecoder.UseNumber()\n\t\t\t}\n\n\t\t\tif err := decoder.Decode(&job.Payload); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\treturn job, nil\n\t\t}\n\t}\n\n\treturn nil, nil\n}\n\nfunc (p *poller) poll(interval time.Duration, quit <-chan bool) (<-chan *Job, error) {\n\tjobs := make(chan *Job)\n\n\tconn, err := GetConn()\n\tif err != nil {\n\t\tlogger.Criticalf(\"Error on getting connection in poller %s: %v\", p, err)\n\t\tclose(jobs)\n\t\treturn nil, err\n\t} else {\n\t\tp.open(conn)\n\t\tp.start(conn)\n\t\tPutConn(conn)\n\t}\n\n\tgo func() {\n\t\tdefer func() {\n\t\t\tclose(jobs)\n\n\t\t\tconn, err := GetConn()\n\t\t\tif err != nil {\n\t\t\t\tlogger.Criticalf(\"Error on getting connection in poller %s: %v\", p, err)\n\t\t\t\treturn\n\t\t\t} else {\n\t\t\t\tp.finish(conn)\n\t\t\t\tp.close(conn)\n\t\t\t\tPutConn(conn)\n\t\t\t}\n\t\t}()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-quit:\n\t\t\t\treturn\n\t\t\tdefault:\n\t\t\t\tconn, err := GetConn()\n\t\t\t\tif err != nil {\n\t\t\t\t\tlogger.Criticalf(\"Error on getting connection in poller %s: %v\", p, err)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tjob, err := p.getJob(conn)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlogger.Criticalf(\"Error on %v getting job from %v: %v\", p, p.Queues, err)\n\t\t\t\t\tPutConn(conn)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job != nil {\n\t\t\t\t\tconn.Send(\"INCR\", fmt.Sprintf(\"%sstat:processed:%v\", workerSettings.Namespace, p))\n\t\t\t\t\tconn.Flush()\n\t\t\t\t\tPutConn(conn)\n\t\t\t\t\tselect {\n\t\t\t\t\tcase jobs <- job:\n\t\t\t\t\tcase <-quit:\n\t\t\t\t\t\tbuf, err := json.Marshal(job.Payload)\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\tlogger.Criticalf(\"Error requeueing %v: %v\", job, err)\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\t\t\t\t\t\tconn, err := GetConn()\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\tlogger.Criticalf(\"Error on getting connection in poller %s: %v\", p, err)\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tconn.Send(\"LPUSH\", fmt.Sprintf(\"%squeue:%s\", workerSettings.Namespace, job.Queue), buf)\n\t\t\t\t\t\tconn.Flush()\n\t\t\t\t\t\tPutConn(conn)\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tPutConn(conn)\n\t\t\t\t\tif workerSettings.ExitOnComplete {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tlogger.Debugf(\"Sleeping for %v\", interval)\n\t\t\t\t\tlogger.Debugf(\"Waiting for %v\", p.Queues)\n\n\t\t\t\t\ttimeout := time.After(interval)\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-quit:\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase <-timeout:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn jobs, nil\n}\n"
        },
        {
          "name": "process.go",
          "type": "blob",
          "size": 2.1640625,
          "content": "package goworker\n\nimport (\n\t\"fmt\"\n\t\"math/rand\"\n\t\"os\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype process struct {\n\tHostname string\n\tPid      int\n\tID       string\n\tQueues   []string\n}\n\nfunc newProcess(id string, queues []string) (*process, error) {\n\thostname, err := os.Hostname()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &process{\n\t\tHostname: hostname,\n\t\tPid:      os.Getpid(),\n\t\tID:       id,\n\t\tQueues:   queues,\n\t}, nil\n}\n\nfunc (p *process) String() string {\n\treturn fmt.Sprintf(\"%s:%d-%s:%s\", p.Hostname, p.Pid, p.ID, strings.Join(p.Queues, \",\"))\n}\n\nfunc (p *process) open(conn *RedisConn) error {\n\tconn.Send(\"SADD\", fmt.Sprintf(\"%sworkers\", workerSettings.Namespace), p)\n\tconn.Send(\"SET\", fmt.Sprintf(\"%sstat:processed:%v\", workerSettings.Namespace, p), \"0\")\n\tconn.Send(\"SET\", fmt.Sprintf(\"%sstat:failed:%v\", workerSettings.Namespace, p), \"0\")\n\tconn.Flush()\n\n\treturn nil\n}\n\nfunc (p *process) close(conn *RedisConn) error {\n\tlogger.Infof(\"%v shutdown\", p)\n\tconn.Send(\"SREM\", fmt.Sprintf(\"%sworkers\", workerSettings.Namespace), p)\n\tconn.Send(\"DEL\", fmt.Sprintf(\"%sstat:processed:%s\", workerSettings.Namespace, p))\n\tconn.Send(\"DEL\", fmt.Sprintf(\"%sstat:failed:%s\", workerSettings.Namespace, p))\n\tconn.Flush()\n\n\treturn nil\n}\n\nfunc (p *process) start(conn *RedisConn) error {\n\tconn.Send(\"SET\", fmt.Sprintf(\"%sworker:%s:started\", workerSettings.Namespace, p), time.Now().String())\n\tconn.Flush()\n\n\treturn nil\n}\n\nfunc (p *process) finish(conn *RedisConn) error {\n\tconn.Send(\"DEL\", fmt.Sprintf(\"%sworker:%s\", workerSettings.Namespace, p))\n\tconn.Send(\"DEL\", fmt.Sprintf(\"%sworker:%s:started\", workerSettings.Namespace, p))\n\tconn.Flush()\n\n\treturn nil\n}\n\nfunc (p *process) fail(conn *RedisConn) error {\n\tconn.Send(\"INCR\", fmt.Sprintf(\"%sstat:failed\", workerSettings.Namespace))\n\tconn.Send(\"INCR\", fmt.Sprintf(\"%sstat:failed:%s\", workerSettings.Namespace, p))\n\tconn.Flush()\n\n\treturn nil\n}\n\nfunc (p *process) queues(strict bool) []string {\n\t// If the queues order is strict then just return them.\n\tif strict {\n\t\treturn p.Queues\n\t}\n\n\t// If not then we want to to shuffle the queues before returning them.\n\tqueues := make([]string, len(p.Queues))\n\tfor i, v := range rand.Perm(len(p.Queues)) {\n\t\tqueues[i] = p.Queues[v]\n\t}\n\treturn queues\n}\n"
        },
        {
          "name": "process_test.go",
          "type": "blob",
          "size": 0.517578125,
          "content": "package goworker\n\nimport (\n\t\"testing\"\n)\n\nvar processStringTests = []struct {\n\tp        process\n\texpected string\n}{\n\t{\n\t\tprocess{},\n\t\t\":0-:\",\n\t},\n\t{\n\t\tprocess{\n\t\t\tHostname: \"hostname\",\n\t\t\tPid:      12345,\n\t\t\tID:       \"123\",\n\t\t\tQueues:   []string{\"high\", \"low\"},\n\t\t},\n\t\t\"hostname:12345-123:high,low\",\n\t},\n}\n\nfunc TestProcessString(t *testing.T) {\n\tfor _, tt := range processStringTests {\n\t\tactual := tt.p.String()\n\t\tif actual != tt.expected {\n\t\t\tt.Errorf(\"Process(%#v): expected %s, actual %s\", tt.p, tt.expected, actual)\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "queues_flag.go",
          "type": "blob",
          "size": 1.0078125,
          "content": "package goworker\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"strconv\"\n\t\"strings\"\n)\n\nvar (\n\terrorEmptyQueues      = errors.New(\"you must specify at least one queue\")\n\terrorNonNumericWeight = errors.New(\"the weight must be a numeric value\")\n)\n\ntype queuesFlag []string\n\nfunc (q *queuesFlag) Set(value string) error {\n\tfor _, queueAndWeight := range strings.Split(value, \",\") {\n\t\tif queueAndWeight == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\tqueue, weight, err := parseQueueAndWeight(queueAndWeight)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tfor i := 0; i < weight; i++ {\n\t\t\t*q = append(*q, queue)\n\t\t}\n\t}\n\tif len(*q) == 0 {\n\t\treturn errorEmptyQueues\n\t}\n\treturn nil\n}\n\nfunc (q *queuesFlag) String() string {\n\treturn fmt.Sprint(*q)\n}\n\nfunc parseQueueAndWeight(queueAndWeight string) (queue string, weight int, err error) {\n\tparts := strings.SplitN(queueAndWeight, \"=\", 2)\n\tqueue = parts[0]\n\n\tif queue == \"\" {\n\t\treturn\n\t}\n\n\tif len(parts) == 1 {\n\t\tweight = 1\n\t} else {\n\t\tweight, err = strconv.Atoi(parts[1])\n\t\tif err != nil {\n\t\t\terr = errorNonNumericWeight\n\t\t}\n\t}\n\treturn\n}\n"
        },
        {
          "name": "queues_flag_test.go",
          "type": "blob",
          "size": 2.0234375,
          "content": "package goworker\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"testing\"\n)\n\nvar queuesFlagSetTests = []struct {\n\tv        string\n\texpected queuesFlag\n\terr      error\n}{\n\t{\n\t\t\"\",\n\t\tnil,\n\t\terrors.New(\"you must specify at least one queue\"),\n\t},\n\t{\n\t\t\"high\",\n\t\tqueuesFlag([]string{\"high\"}),\n\t\tnil,\n\t},\n\t{\n\t\t\"high,low\",\n\t\tqueuesFlag([]string{\"high\", \"low\"}),\n\t\tnil,\n\t},\n\t{\n\t\t\"high=2,low=1\",\n\t\tqueuesFlag([]string{\"high\", \"high\", \"low\"}),\n\t\tnil,\n\t},\n\t{\n\t\t\"high=2,low\",\n\t\tqueuesFlag([]string{\"high\", \"high\", \"low\"}),\n\t\tnil,\n\t},\n\t{\n\t\t\"low=1,high=2\",\n\t\tqueuesFlag([]string{\"low\", \"high\", \"high\"}),\n\t\tnil,\n\t},\n\t{\n\t\t\"low=,high=2\",\n\t\tnil,\n\t\terrors.New(\"the weight must be a numeric value\"),\n\t},\n\t{\n\t\t\"low=a,high=2\",\n\t\tnil,\n\t\terrors.New(\"the weight must be a numeric value\"),\n\t},\n\t{\n\t\t\"low=\",\n\t\tnil,\n\t\terrors.New(\"the weight must be a numeric value\"),\n\t},\n\t{\n\t\t\"low=a\",\n\t\tnil,\n\t\terrors.New(\"the weight must be a numeric value\"),\n\t},\n\t{\n\t\t\"high=2,,,=1\",\n\t\tqueuesFlag([]string{\"high\", \"high\"}),\n\t\tnil,\n\t},\n\t{\n\t\t\",,,\",\n\t\tnil,\n\t\terrors.New(\"you must specify at least one queue\"),\n\t},\n\t{\n\t\t\"=1\",\n\t\tnil,\n\t\terrors.New(\"you must specify at least one queue\"),\n\t},\n}\n\nfunc TestQueuesFlagSet(t *testing.T) {\n\tfor _, tt := range queuesFlagSetTests {\n\t\tactual := new(queuesFlag)\n\t\terr := actual.Set(tt.v)\n\t\tif fmt.Sprint(actual) != fmt.Sprint(tt.expected) {\n\t\t\tt.Errorf(\"QueuesFlag: set to %s expected %v, actual %v\", tt.v, tt.expected, actual)\n\t\t}\n\t\tif (err != nil && tt.err == nil) ||\n\t\t\t(err == nil && tt.err != nil) ||\n\t\t\t(err != nil && tt.err != nil && err.Error() != tt.err.Error()) {\n\t\t\tt.Errorf(\"QueuesFlag: set to %s expected err %v, actual err %v\", tt.v, tt.err, err)\n\t\t}\n\t}\n}\n\nvar queuesFlagStringTests = []struct {\n\tq        queuesFlag\n\texpected string\n}{\n\t{\n\t\tqueuesFlag([]string{\"high\"}),\n\t\t\"[high]\",\n\t},\n\t{\n\t\tqueuesFlag([]string{\"high\", \"low\"}),\n\t\t\"[high low]\",\n\t},\n}\n\nfunc TestQueuesFlagString(t *testing.T) {\n\tfor _, tt := range queuesFlagStringTests {\n\t\tactual := tt.q.String()\n\t\tif actual != tt.expected {\n\t\t\tt.Errorf(\"QueuesFlag(%#v): expected %s, actual %s\", tt.q, tt.expected, actual)\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "redis.go",
          "type": "blob",
          "size": 2.4892578125,
          "content": "package goworker\n\nimport (\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/url\"\n\t\"time\"\n\n\t\"github.com/gomodule/redigo/redis\"\n\t\"vitess.io/vitess/go/pools\"\n)\n\nvar (\n\terrorInvalidScheme = errors.New(\"invalid Redis database URI scheme\")\n)\n\ntype RedisConn struct {\n\tredis.Conn\n}\n\nfunc (r *RedisConn) Close() {\n\t_ = r.Conn.Close()\n}\n\nfunc newRedisFactory(uri string) pools.Factory {\n\treturn func() (pools.Resource, error) {\n\t\treturn redisConnFromURI(uri)\n\t}\n}\n\nfunc newRedisPool(uri string, capacity int, maxCapacity int, idleTimout time.Duration) *pools.ResourcePool {\n\treturn pools.NewResourcePool(newRedisFactory(uri), capacity, maxCapacity, idleTimout)\n}\n\nfunc redisConnFromURI(uriString string) (*RedisConn, error) {\n\turi, err := url.Parse(uriString)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar network string\n\tvar host string\n\tvar password string\n\tvar db string\n\tvar dialOptions []redis.DialOption\n\n\tswitch uri.Scheme {\n\tcase \"redis\", \"rediss\":\n\t\tnetwork = \"tcp\"\n\t\thost = uri.Host\n\t\tif uri.User != nil {\n\t\t\tpassword, _ = uri.User.Password()\n\t\t}\n\t\tif len(uri.Path) > 1 {\n\t\t\tdb = uri.Path[1:]\n\t\t}\n\t\tif uri.Scheme == \"rediss\" {\n\t\t\tdialOptions = append(dialOptions, redis.DialUseTLS(true))\n\t\t\tdialOptions = append(dialOptions, redis.DialTLSSkipVerify(workerSettings.SkipTLSVerify))\n\t\t\tif len(workerSettings.TLSCertPath) > 0 {\n\t\t\t\tpool, err := getCertPool(workerSettings.TLSCertPath)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tconfig := &tls.Config{\n\t\t\t\t\tRootCAs: pool,\n\t\t\t\t}\n\t\t\t\tdialOptions = append(dialOptions, redis.DialTLSConfig(config))\n\t\t\t}\n\t\t}\n\tcase \"unix\":\n\t\tnetwork = \"unix\"\n\t\thost = uri.Path\n\tdefault:\n\t\treturn nil, errorInvalidScheme\n\t}\n\n\tconn, err := redis.Dial(network, host, dialOptions...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif password != \"\" {\n\t\t_, err := conn.Do(\"AUTH\", password)\n\t\tif err != nil {\n\t\t\tconn.Close()\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif db != \"\" {\n\t\t_, err := conn.Do(\"SELECT\", db)\n\t\tif err != nil {\n\t\t\tconn.Close()\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn &RedisConn{Conn: conn}, nil\n}\n\nfunc getCertPool(certPath string) (*x509.CertPool, error) {\n\trootCAs, _ := x509.SystemCertPool()\n\tif rootCAs == nil {\n\t\trootCAs = x509.NewCertPool()\n\t}\n\tcerts, err := ioutil.ReadFile(workerSettings.TLSCertPath)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Failed to read %q for the RootCA pool: %v\", workerSettings.TLSCertPath, err)\n\t}\n\tif ok := rootCAs.AppendCertsFromPEM(certs); !ok {\n\t\treturn nil, fmt.Errorf(\"Failed to append %q to the RootCA pool: %v\", workerSettings.TLSCertPath, err)\n\t}\n\treturn rootCAs, nil\n}\n"
        },
        {
          "name": "signal_stop_1.0.go",
          "type": "blob",
          "size": 0.16015625,
          "content": "// +build !go1.1\n\npackage goworker\n\nimport (\n\t\"os\"\n)\n\n// Stops signals channel. This does not exist in\n// Go less than 1.1.\nfunc signalStop(c chan<- os.Signal) {\n}\n"
        },
        {
          "name": "signal_stop_1.1.go",
          "type": "blob",
          "size": 0.1982421875,
          "content": "// +build go1.1\n\npackage goworker\n\nimport (\n\t\"os\"\n\t\"os/signal\"\n)\n\n// Stops signals channel. This function exists\n// in Go greater or equal to 1.1.\nfunc signalStop(c chan<- os.Signal) {\n\tsignal.Stop(c)\n}\n"
        },
        {
          "name": "signals.go",
          "type": "blob",
          "size": 1.6708984375,
          "content": "// Signal Handling in goworker\n//\n// To stop goworker, send a QUIT, TERM, or INT\n// signal to the process. This will immediately\n// stop job polling. There can be up to\n// $CONCURRENCY jobs currently running, which\n// will continue to run until they are finished.\n//\n// Failure Modes\n//\n// Like Resque, goworker makes no guarantees\n// about the safety of jobs in the event of\n// process shutdown. Workers must be both\n// idempotent and tolerant to loss of the job in\n// the event of failure.\n//\n// If the process is killed with a KILL or by a\n// system failure, there may be one job that is\n// currently in the poller's buffer that will be\n// lost without any representation in either the\n// queue or the worker variable.\n//\n// If you are running Goworker on a system like\n// Heroku, which sends a TERM to signal a process\n// that it needs to stop, ten seconds later sends\n// a KILL to force the process to stop, your jobs\n// must finish within 10 seconds or they may be\n// lost. Jobs will be recoverable from the Redis\n// database under\n//\n//\tresque:worker:<hostname>:<process-id>-<worker-id>:<queues>\n//\n// as a JSON object with keys queue, run_at, and\n// payload, but the process is manual.\n// Additionally, there is no guarantee that the\n// job in Redis under the worker key has not\n// finished, if the process is killed before\n// goworker can flush the update to Redis.\npackage goworker\n\nimport (\n\t\"os\"\n\t\"os/signal\"\n\t\"syscall\"\n)\n\nfunc signals() <-chan bool {\n\tquit := make(chan bool)\n\n\tgo func() {\n\t\tsignals := make(chan os.Signal)\n\t\tdefer close(signals)\n\n\t\tsignal.Notify(signals, syscall.SIGQUIT, syscall.SIGTERM, os.Interrupt)\n\t\tdefer signalStop(signals)\n\n\t\t<-signals\n\t\tquit <- true\n\t}()\n\n\treturn quit\n}\n"
        },
        {
          "name": "work.go",
          "type": "blob",
          "size": 0.16015625,
          "content": "package goworker\n\nimport (\n\t\"time\"\n)\n\ntype work struct {\n\tQueue   string    `json:\"queue\"`\n\tRunAt   time.Time `json:\"run_at\"`\n\tPayload Payload   `json:\"payload\"`\n}\n"
        },
        {
          "name": "worker.go",
          "type": "blob",
          "size": 3.3046875,
          "content": "package goworker\n\nimport (\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\ntype worker struct {\n\tprocess\n}\n\nfunc newWorker(id string, queues []string) (*worker, error) {\n\tprocess, err := newProcess(id, queues)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &worker{\n\t\tprocess: *process,\n\t}, nil\n}\n\nfunc (w *worker) MarshalJSON() ([]byte, error) {\n\treturn json.Marshal(w.String())\n}\n\nfunc (w *worker) start(conn *RedisConn, job *Job) error {\n\twork := &work{\n\t\tQueue:   job.Queue,\n\t\tRunAt:   time.Now(),\n\t\tPayload: job.Payload,\n\t}\n\n\tbuffer, err := json.Marshal(work)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tconn.Send(\"SET\", fmt.Sprintf(\"%sworker:%s\", workerSettings.Namespace, w), buffer)\n\tlogger.Debugf(\"Processing %s since %s [%v]\", work.Queue, work.RunAt, work.Payload.Class)\n\n\treturn w.process.start(conn)\n}\n\nfunc (w *worker) fail(conn *RedisConn, job *Job, err error) error {\n\tfailure := &failure{\n\t\tFailedAt:  time.Now(),\n\t\tPayload:   job.Payload,\n\t\tException: \"Error\",\n\t\tError:     err.Error(),\n\t\tWorker:    w,\n\t\tQueue:     job.Queue,\n\t}\n\tbuffer, err := json.Marshal(failure)\n\tif err != nil {\n\t\treturn err\n\t}\n\tconn.Send(\"RPUSH\", fmt.Sprintf(\"%sfailed\", workerSettings.Namespace), buffer)\n\n\treturn w.process.fail(conn)\n}\n\nfunc (w *worker) succeed(conn *RedisConn, job *Job) error {\n\tconn.Send(\"INCR\", fmt.Sprintf(\"%sstat:processed\", workerSettings.Namespace))\n\tconn.Send(\"INCR\", fmt.Sprintf(\"%sstat:processed:%s\", workerSettings.Namespace, w))\n\n\treturn nil\n}\n\nfunc (w *worker) finish(conn *RedisConn, job *Job, err error) error {\n\tif err != nil {\n\t\tw.fail(conn, job, err)\n\t} else {\n\t\tw.succeed(conn, job)\n\t}\n\treturn w.process.finish(conn)\n}\n\nfunc (w *worker) work(jobs <-chan *Job, monitor *sync.WaitGroup) {\n\tconn, err := GetConn()\n\tif err != nil {\n\t\tlogger.Criticalf(\"Error on getting connection in worker %v: %v\", w, err)\n\t\treturn\n\t} else {\n\t\tw.open(conn)\n\t\tPutConn(conn)\n\t}\n\n\tmonitor.Add(1)\n\n\tgo func() {\n\t\tdefer func() {\n\t\t\tdefer monitor.Done()\n\n\t\t\tconn, err := GetConn()\n\t\t\tif err != nil {\n\t\t\t\tlogger.Criticalf(\"Error on getting connection in worker %v: %v\", w, err)\n\t\t\t\treturn\n\t\t\t} else {\n\t\t\t\tw.close(conn)\n\t\t\t\tPutConn(conn)\n\t\t\t}\n\t\t}()\n\t\tfor job := range jobs {\n\t\t\tif workerFunc, ok := workers[job.Payload.Class]; ok {\n\t\t\t\tw.run(job, workerFunc)\n\n\t\t\t\tlogger.Debugf(\"done: (Job{%s} | %s | %v)\", job.Queue, job.Payload.Class, job.Payload.Args)\n\t\t\t} else {\n\t\t\t\terrorLog := fmt.Sprintf(\"No worker for %s in queue %s with args %v\", job.Payload.Class, job.Queue, job.Payload.Args)\n\t\t\t\tlogger.Critical(errorLog)\n\n\t\t\t\tconn, err := GetConn()\n\t\t\t\tif err != nil {\n\t\t\t\t\tlogger.Criticalf(\"Error on getting connection in worker %v: %v\", w, err)\n\t\t\t\t\treturn\n\t\t\t\t} else {\n\t\t\t\t\tw.finish(conn, job, errors.New(errorLog))\n\t\t\t\t\tPutConn(conn)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n}\n\nfunc (w *worker) run(job *Job, workerFunc workerFunc) {\n\tvar err error\n\tdefer func() {\n\t\tconn, errCon := GetConn()\n\t\tif errCon != nil {\n\t\t\tlogger.Criticalf(\"Error on getting connection in worker on finish %v: %v\", w, errCon)\n\t\t\treturn\n\t\t} else {\n\t\t\tw.finish(conn, job, err)\n\t\t\tPutConn(conn)\n\t\t}\n\t}()\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\terr = errors.New(fmt.Sprint(r))\n\t\t}\n\t}()\n\n\tconn, err := GetConn()\n\tif err != nil {\n\t\tlogger.Criticalf(\"Error on getting connection in worker on start %v: %v\", w, err)\n\t\treturn\n\t} else {\n\t\tw.start(conn, job)\n\t\tPutConn(conn)\n\t}\n\terr = workerFunc(job.Queue, job.Payload.Args...)\n}\n"
        },
        {
          "name": "worker_func.go",
          "type": "blob",
          "size": 0.0673828125,
          "content": "package goworker\n\ntype workerFunc func(string, ...interface{}) error\n"
        },
        {
          "name": "worker_test.go",
          "type": "blob",
          "size": 1.666015625,
          "content": "package goworker\n\nimport (\n\t\"reflect\"\n\t\"testing\"\n)\n\nvar workerMarshalJSONTests = []struct {\n\tw        worker\n\texpected []byte\n}{\n\t{\n\t\tworker{},\n\t\t[]byte(`\":0-:\"`),\n\t},\n\t{\n\t\tworker{\n\t\t\tprocess: process{\n\t\t\t\tHostname: \"hostname\",\n\t\t\t\tPid:      12345,\n\t\t\t\tID:       \"123\",\n\t\t\t\tQueues:   []string{\"high\", \"low\"},\n\t\t\t},\n\t\t},\n\t\t[]byte(`\"hostname:12345-123:high,low\"`),\n\t},\n}\n\nfunc TestWorkerMarshalJSON(t *testing.T) {\n\tfor _, tt := range workerMarshalJSONTests {\n\t\tactual, err := tt.w.MarshalJSON()\n\t\tif err != nil {\n\t\t\tt.Errorf(\"Worker(%#v): error %s\", tt.w, err)\n\t\t} else {\n\t\t\tif string(actual) != string(tt.expected) {\n\t\t\t\tt.Errorf(\"Worker(%#v): expected %s, actual %s\", tt.w, tt.expected, actual)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc TestEnqueue(t *testing.T) {\n\texpectedArgs := []interface{}{\"a\", \"lot\", \"of\", \"params\"}\n\tjobName := \"SomethingCool\"\n\tqueueName := \"testQueue\"\n\texpectedJob := &Job{\n\t\tQueue: queueName,\n\t\tPayload: Payload{\n\t\t\tClass: jobName,\n\t\t\tArgs:  expectedArgs,\n\t\t},\n\t}\n\n\tworkerSettings.Queues = []string{queueName}\n\tworkerSettings.UseNumber = true\n\tworkerSettings.ExitOnComplete = true\n\n\terr := Enqueue(expectedJob)\n\tif err != nil {\n\t\tt.Errorf(\"Error while enqueue %s\", err)\n\t}\n\n\tactualArgs := []interface{}{}\n\tactualQueueName := \"\"\n\tRegister(jobName, func(queue string, args ...interface{}) error {\n\t\tactualArgs = args\n\t\tactualQueueName = queue\n\t\treturn nil\n\t})\n\tif err := Work(); err != nil {\n\t\tt.Errorf(\"(Enqueue) Failed on work %s\", err)\n\t}\n\tif !reflect.DeepEqual(actualArgs, expectedArgs) {\n\t\tt.Errorf(\"(Enqueue) Expected %v, actual %v\", actualArgs, expectedArgs)\n\t}\n\tif !reflect.DeepEqual(actualQueueName, queueName) {\n\t\tt.Errorf(\"(Enqueue) Expected %v, actual %v\", actualQueueName, queueName)\n\t}\n}\n"
        },
        {
          "name": "workers.go",
          "type": "blob",
          "size": 1.150390625,
          "content": "package goworker\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n)\n\nvar (\n\tworkers map[string]workerFunc\n)\n\nfunc init() {\n\tworkers = make(map[string]workerFunc)\n}\n\n// Register registers a goworker worker function. Class\n// refers to the Ruby name of the class which enqueues the\n// job. Worker is a function which accepts a queue and an\n// arbitrary array of interfaces as arguments.\nfunc Register(class string, worker workerFunc) {\n\tworkers[class] = worker\n}\n\nfunc Enqueue(job *Job) error {\n\terr := Init()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tconn, err := GetConn()\n\tif err != nil {\n\t\tlogger.Criticalf(\"Error on getting connection on enqueue\")\n\t\treturn err\n\t}\n\tdefer PutConn(conn)\n\n\tbuffer, err := json.Marshal(job.Payload)\n\tif err != nil {\n\t\tlogger.Criticalf(\"Cant marshal payload on enqueue\")\n\t\treturn err\n\t}\n\n\terr = conn.Send(\"RPUSH\", fmt.Sprintf(\"%squeue:%s\", workerSettings.Namespace, job.Queue), buffer)\n\tif err != nil {\n\t\tlogger.Criticalf(\"Cant push to queue\")\n\t\treturn err\n\t}\n\n\terr = conn.Send(\"SADD\", fmt.Sprintf(\"%squeues\", workerSettings.Namespace), job.Queue)\n\tif err != nil {\n\t\tlogger.Criticalf(\"Cant register queue to list of use queues\")\n\t\treturn err\n\t}\n\n\treturn conn.Flush()\n}\n"
        }
      ]
    }
  ]
}