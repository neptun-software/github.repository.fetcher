{
  "metadata": {
    "timestamp": 1736567184858,
    "page": 780,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjc4MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "bits-and-blooms/bloom",
      "stars": 2485,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.2734375,
          "content": "# Compiled Object files, Static and Dynamic libs (Shared Objects)\n*.o\n*.a\n*.so\n\n# Folders\n_obj\n_test\n\n# Architecture specific extensions/prefixes\n*.[568vq]\n[568vq].out\n\n*.cgo1.go\n*.cgo2.c\n_cgo_defun.c\n_cgo_gotypes.go\n_cgo_export.*\n\n_testmain.go\n\n*.exe\n*.test\n*.prof\n\ntarget\n.idea\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.6533203125,
          "content": "language: go\n\nsudo: false\n\nbranches:\n  except:\n    - release\n\nbranches:\n  only:\n    - master\n    - develop\n    - travis\n\ngo:\n  - 1.8\n  - tip\n\nmatrix:\n  allow_failures:\n    - go: tip\n\nbefore_install:\n  - if [ -n \"$GH_USER\" ]; then git config --global github.user ${GH_USER}; fi;\n  - if [ -n \"$GH_TOKEN\" ]; then git config --global github.token ${GH_TOKEN}; fi;\n  - go get github.com/mattn/goveralls\n\nbefore_script:\n  - make deps\n\nscript:\n  - make qa\n\nafter_failure:\n  - cat ./target/test/report.xml\n\nafter_success:\n  - if [ \"$TRAVIS_GO_VERSION\" = \"1.8\" ]; then $HOME/gopath/bin/goveralls -covermode=count -coverprofile=target/report/coverage.out -service=travis-ci; fi;\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.265625,
          "content": "Copyright (c) 2014 Will Fitzgerald. All rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n   * Redistributions of source code must retain the above copyright\nnotice, this list of conditions and the following disclaimer.\n   * Redistributions in binary form must reproduce the above\ncopyright notice, this list of conditions and the following disclaimer\nin the documentation and/or other materials provided with the\ndistribution.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 6.4306640625,
          "content": "# MAKEFILE\n#\n# @author      Nicola Asuni <info@tecnick.com>\n# @link        https://github.com/bits-and-blooms/bloom\n# ------------------------------------------------------------------------------\n\n# List special make targets that are not associated with files\n.PHONY: help all test format fmtcheck vet lint coverage cyclo ineffassign misspell structcheck varcheck errcheck gosimple astscan qa deps clean nuke\n\n# Use bash as shell (Note: Ubuntu now uses dash which doesn't support PIPESTATUS).\nSHELL=/bin/bash\n\n# CVS path (path to the parent dir containing the project)\nCVSPATH=github.com/bits-and-blooms\n\n# Project owner\nOWNER=bits-and-blooms\n\n# Project vendor\nVENDOR=bits-and-blooms\n\n# Project name\nPROJECT=bloom\n\n# Project version\nVERSION=$(shell cat VERSION)\n\n# Name of RPM or DEB package\nPKGNAME=${VENDOR}-${PROJECT}\n\n# Current directory\nCURRENTDIR=$(shell pwd)\n\n# GO lang path\nifneq ($(GOPATH),)\n\tifeq ($(findstring $(GOPATH),$(CURRENTDIR)),)\n\t\t# the defined GOPATH is not valid\n\t\tGOPATH=\n\tendif\nendif\nifeq ($(GOPATH),)\n\t# extract the GOPATH\n\tGOPATH=$(firstword $(subst /src/, ,$(CURRENTDIR)))\nendif\n\n# --- MAKE TARGETS ---\n\n# Display general help about this command\nhelp:\n\t@echo \"\"\n\t@echo \"$(PROJECT) Makefile.\"\n\t@echo \"GOPATH=$(GOPATH)\"\n\t@echo \"The following commands are available:\"\n\t@echo \"\"\n\t@echo \"    make qa          : Run all the tests\"\n\t@echo \"    make test        : Run the unit tests\"\n\t@echo \"\"\n\t@echo \"    make format      : Format the source code\"\n\t@echo \"    make fmtcheck    : Check if the source code has been formatted\"\n\t@echo \"    make vet         : Check for suspicious constructs\"\n\t@echo \"    make lint        : Check for style errors\"\n\t@echo \"    make coverage    : Generate the coverage report\"\n\t@echo \"    make cyclo       : Generate the cyclomatic complexity report\"\n\t@echo \"    make ineffassign : Detect ineffectual assignments\"\n\t@echo \"    make misspell    : Detect commonly misspelled words in source files\"\n\t@echo \"    make structcheck : Find unused struct fields\"\n\t@echo \"    make varcheck    : Find unused global variables and constants\"\n\t@echo \"    make errcheck    : Check that error return values are used\"\n\t@echo \"    make gosimple    : Suggest code simplifications\"\n\t@echo \"    make astscan     : GO AST scanner\"\n\t@echo \"\"\n\t@echo \"    make docs        : Generate source code documentation\"\n\t@echo \"\"\n\t@echo \"    make deps        : Get the dependencies\"\n\t@echo \"    make clean       : Remove any build artifact\"\n\t@echo \"    make nuke        : Deletes any intermediate file\"\n\t@echo \"\"\n\n# Alias for help target\nall: help\n\n# Run the unit tests\ntest:\n\t@mkdir -p target/test\n\t@mkdir -p target/report\n\tGOPATH=$(GOPATH) \\\n\tgo test \\\n\t-covermode=atomic \\\n\t-bench=. \\\n\t-race \\\n\t-cpuprofile=target/report/cpu.out \\\n\t-memprofile=target/report/mem.out \\\n\t-mutexprofile=target/report/mutex.out \\\n\t-coverprofile=target/report/coverage.out \\\n\t-v ./... | \\\n\ttee >(PATH=$(GOPATH)/bin:$(PATH) go-junit-report > target/test/report.xml); \\\n\ttest $${PIPESTATUS[0]} -eq 0\n\n# Format the source code\nformat:\n\t@find . -type f -name \"*.go\" -exec gofmt -s -w {} \\;\n\n# Check if the source code has been formatted\nfmtcheck:\n\t@mkdir -p target\n\t@find . -type f -name \"*.go\" -exec gofmt -s -d {} \\; | tee target/format.diff\n\t@test ! -s target/format.diff || { echo \"ERROR: the source code has not been formatted - please use 'make format' or 'gofmt'\"; exit 1; }\n\n# Check for syntax errors\nvet:\n\tGOPATH=$(GOPATH) go vet .\n\n# Check for style errors\nlint:\n\tGOPATH=$(GOPATH) PATH=$(GOPATH)/bin:$(PATH) golint .\n\n# Generate the coverage report\ncoverage:\n\t@mkdir -p target/report\n\tGOPATH=$(GOPATH) \\\n\tgo tool cover -html=target/report/coverage.out -o target/report/coverage.html\n\n# Report cyclomatic complexity\ncyclo:\n\t@mkdir -p target/report\n\tGOPATH=$(GOPATH) gocyclo -avg ./ | tee target/report/cyclo.txt ; test $${PIPESTATUS[0]} -eq 0\n\n# Detect ineffectual assignments\nineffassign:\n\t@mkdir -p target/report\n\tGOPATH=$(GOPATH) ineffassign ./ | tee target/report/ineffassign.txt ; test $${PIPESTATUS[0]} -eq 0\n\n# Detect commonly misspelled words in source files\nmisspell:\n\t@mkdir -p target/report\n\tGOPATH=$(GOPATH) misspell -error ./  | tee target/report/misspell.txt ; test $${PIPESTATUS[0]} -eq 0\n\n# Find unused struct fields\nstructcheck:\n\t@mkdir -p target/report\n\tGOPATH=$(GOPATH) structcheck -a ./  | tee target/report/structcheck.txt\n\n# Find unused global variables and constants\nvarcheck:\n\t@mkdir -p target/report\n\tGOPATH=$(GOPATH) varcheck -e ./  | tee target/report/varcheck.txt\n\n# Check that error return values are used\nerrcheck:\n\t@mkdir -p target/report\n\tGOPATH=$(GOPATH) errcheck ./  | tee target/report/errcheck.txt\n\n# Suggest code simplifications\ngosimple:\n\t@mkdir -p target/report\n\tGOPATH=$(GOPATH) gosimple ./  | tee target/report/gosimple.txt\n\n# AST scanner\nastscan:\n\t@mkdir -p target/report\n\tGOPATH=$(GOPATH) gas .//*.go | tee target/report/astscan.txt ; test $${PIPESTATUS[0]} -eq 0\n\n# Generate source docs\ndocs:\n\t@mkdir -p target/docs\n\tnohup sh -c 'GOPATH=$(GOPATH) godoc -http=127.0.0.1:6060' > target/godoc_server.log 2>&1 &\n\twget --directory-prefix=target/docs/ --execute robots=off --retry-connrefused --recursive --no-parent --adjust-extension --page-requisites --convert-links http://127.0.0.1:6060/pkg/github.com/${VENDOR}/${PROJECT}/ ; kill -9 `lsof -ti :6060`\n\t@echo '<html><head><meta http-equiv=\"refresh\" content=\"0;./127.0.0.1:6060/pkg/'${CVSPATH}'/'${PROJECT}'/index.html\"/></head><a href=\"./127.0.0.1:6060/pkg/'${CVSPATH}'/'${PROJECT}'/index.html\">'${PKGNAME}' Documentation ...</a></html>' > target/docs/index.html\n\n# Alias to run all quality-assurance checks\nqa: fmtcheck test vet lint coverage cyclo ineffassign misspell structcheck varcheck errcheck gosimple astscan\n\n# --- INSTALL ---\n\n# Get the dependencies\ndeps:\n\tGOPATH=$(GOPATH) go get ./...\n\tGOPATH=$(GOPATH) go get github.com/golang/lint/golint\n\tGOPATH=$(GOPATH) go get github.com/jstemmer/go-junit-report\n\tGOPATH=$(GOPATH) go get github.com/axw/gocov/gocov\n\tGOPATH=$(GOPATH) go get github.com/fzipp/gocyclo\n\tGOPATH=$(GOPATH) go get github.com/gordonklaus/ineffassign\n\tGOPATH=$(GOPATH) go get github.com/client9/misspell/cmd/misspell\n\tGOPATH=$(GOPATH) go get github.com/opennota/check/cmd/structcheck\n\tGOPATH=$(GOPATH) go get github.com/opennota/check/cmd/varcheck\n\tGOPATH=$(GOPATH) go get github.com/kisielk/errcheck\n\tGOPATH=$(GOPATH) go get honnef.co/go/tools/cmd/gosimple\n\tGOPATH=$(GOPATH) go get github.com/securego/gosec\n\n# Remove any build artifact\nclean:\n\tGOPATH=$(GOPATH) go clean ./...\n\n# Deletes any intermediate file\nnuke:\n\trm -rf ./target\n\tGOPATH=$(GOPATH) go clean -i ./...\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 6.0517578125,
          "content": "Bloom filters\n-------------\n[![Test](https://github.com/bits-and-blooms/bloom/actions/workflows/test.yml/badge.svg)](https://github.com/bits-and-blooms/bloom/actions/workflows/test.yml)\n[![Go Report Card](https://goreportcard.com/badge/github.com/bits-and-blooms/bloom)](https://goreportcard.com/report/github.com/bits-and-blooms/bloom)\n[![Go Reference](https://pkg.go.dev/badge/github.com/bits-and-blooms/bloom.svg)](https://pkg.go.dev/github.com/bits-and-blooms/bloom/v3)\n\nThis library is used by popular systems such as [Milvus](https://github.com/milvus-io/milvus) and [beego](https://github.com/beego/Beego).\n\nA Bloom filter is a concise/compressed representation of a set, where the main\nrequirement is to make membership queries; _i.e._, whether an item is a\nmember of a set. A Bloom filter will always correctly report the presence\nof an element in the set when the element is indeed present. A Bloom filter \ncan use much less storage than the original set, but it allows for some 'false positives':\nit may sometimes report that an element is in the set whereas it is not.\n\nWhen you construct, you need to know how many elements you have (the desired capacity), and what is the desired false positive rate you are willing to tolerate. A common false-positive rate is 1%. The\nlower the false-positive rate, the more memory you are going to require. Similarly, the higher the\ncapacity, the more memory you will use.\nYou may construct the Bloom filter capable of receiving 1 million elements with a false-positive\nrate of 1% in the following manner. \n\n```Go\n    filter := bloom.NewWithEstimates(1000000, 0.01) \n```\n\nYou should call `NewWithEstimates` conservatively: if you specify a number of elements that it is\ntoo small, the false-positive bound might be exceeded. A Bloom filter is not a dynamic data structure:\nyou must know ahead of time what your desired capacity is.\n\nOur implementation accepts keys for setting and testing as `[]byte`. Thus, to\nadd a string item, `\"Love\"`:\n\n```Go\n    filter.Add([]byte(\"Love\"))\n```\n\nSimilarly, to test if `\"Love\"` is in bloom:\n\n```Go\n    if filter.Test([]byte(\"Love\"))\n```\n\nFor numerical data, we recommend that you look into the encoding/binary library. But, for example, to add a `uint32` to the filter:\n\n```Go\n    i := uint32(100)\n    n1 := make([]byte, 4)\n    binary.BigEndian.PutUint32(n1, i)\n    filter.Add(n1)\n```\n\nGodoc documentation:  https://pkg.go.dev/github.com/bits-and-blooms/bloom/v3 \n\n\n## Installation\n\n```bash\ngo get -u github.com/bits-and-blooms/bloom/v3\n```\n\n## Verifying the False Positive Rate\n\n\nSometimes, the actual false positive rate may differ (slightly) from the\ntheoretical false positive rate. We have a function to estimate the false positive rate of a\nBloom filter with _m_ bits and _k_ hashing functions for a set of size _n_:\n\n```Go\n    if bloom.EstimateFalsePositiveRate(20*n, 5, n) > 0.001 ...\n```\n\nYou can use it to validate the computed m, k parameters:\n\n```Go\n    m, k := bloom.EstimateParameters(n, fp)\n    ActualfpRate := bloom.EstimateFalsePositiveRate(m, k, n)\n```\n\nor\n\n```Go\n    f := bloom.NewWithEstimates(n, fp)\n    ActualfpRate := bloom.EstimateFalsePositiveRate(f.m, f.k, n)\n```\n\nYou would expect `ActualfpRate` to be close to the desired false-positive rate `fp` in these cases.\n\nThe `EstimateFalsePositiveRate` function creates a temporary Bloom filter. It is\nalso relatively expensive and only meant for validation.\n\n## Serialization\n\nYou can read and write the Bloom filters as follows:\n\n\n```Go\n\tf := New(1000, 4)\n\tvar buf bytes.Buffer\n\tbytesWritten, err := f.WriteTo(&buf)\n\tif err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\tvar g BloomFilter\n\tbytesRead, err := g.ReadFrom(&buf)\n\tif err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\tif bytesRead != bytesWritten {\n\t\tt.Errorf(\"read unexpected number of bytes %d != %d\", bytesRead, bytesWritten)\n\t}\n```\n\n*Performance tip*: \nWhen reading and writing to a file or a network connection, you may get better performance by \nwrapping your streams with `bufio` instances.\n\nE.g., \n```Go\n\tf, err := os.Create(\"myfile\")\n\tw := bufio.NewWriter(f)\n```\n```Go\n\tf, err := os.Open(\"myfile\")\n\tr := bufio.NewReader(f)\n```\n\n## Contributing\n\nIf you wish to contribute to this project, please branch and issue a pull request against master (\"[GitHub Flow](https://guides.github.com/introduction/flow/)\")\n\nThis project includes a Makefile that allows you to test and build the project with simple commands.\nTo see all available options:\n```bash\nmake help\n```\n\n## Running all tests\n\nBefore committing the code, please check if it passes all tests using (note: this will install some dependencies):\n```bash\nmake deps\nmake qa\n```\n\n## Design\n\nA Bloom filter has two parameters: _m_, the number of bits used in storage, and _k_, the number of hashing functions on elements of the set. (The actual hashing functions are important, too, but this is not a parameter for this implementation). A Bloom filter is backed by a [BitSet](https://github.com/bits-and-blooms/bitset); a key is represented in the filter by setting the bits at each value of the  hashing functions (modulo _m_). Set membership is done by _testing_ whether the bits at each value of the hashing functions (again, modulo _m_) are set. If so, the item is in the set. If the item is actually in the set, a Bloom filter will never fail (the true positive rate is 1.0); but it is susceptible to false positives. The art is to choose _k_ and _m_ correctly.\n\nIn this implementation, the hashing functions used is [murmurhash](github.com/twmb/murmur3), a non-cryptographic hashing function.\n\n\nGiven the particular hashing scheme, it's best to be empirical about this. Note\nthat estimating the FP rate will clear the Bloom filter.\n\n\n\n\n### Goroutine safety\n\nIn general, it not safe to access\nthe same filter using different goroutines--they are\nunsynchronized for performance. Should you want to access\na filter from more than one goroutine, you should\nprovide synchronization. Typically this is done by using channels (in Go style; so there is only ever one owner),\nor by using `sync.Mutex` to serialize operations. Exceptionally, you may access the same filter from different\ngoroutines if you never modify the content of the filter.\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.1376953125,
          "content": "# Security Policy\n\n## Reporting a Vulnerability\n\nYou can report privately a vulnerability by email at daniel@lemire.me (current maintainer).\n"
        },
        {
          "name": "bloom.go",
          "type": "blob",
          "size": 12.736328125,
          "content": "/*\nPackage bloom provides data structures and methods for creating Bloom filters.\n\nA Bloom filter is a representation of a set of _n_ items, where the main\nrequirement is to make membership queries; _i.e._, whether an item is a\nmember of a set.\n\nA Bloom filter has two parameters: _m_, a maximum size (typically a reasonably large\nmultiple of the cardinality of the set to represent) and _k_, the number of hashing\nfunctions on elements of the set. (The actual hashing functions are important, too,\nbut this is not a parameter for this implementation). A Bloom filter is backed by\na BitSet; a key is represented in the filter by setting the bits at each value of the\nhashing functions (modulo _m_). Set membership is done by _testing_ whether the\nbits at each value of the hashing functions (again, modulo _m_) are set. If so,\nthe item is in the set. If the item is actually in the set, a Bloom filter will\nnever fail (the true positive rate is 1.0); but it is susceptible to false\npositives. The art is to choose _k_ and _m_ correctly.\n\nIn this implementation, the hashing functions used is murmurhash,\na non-cryptographic hashing function.\n\nThis implementation accepts keys for setting as testing as []byte. Thus, to\nadd a string item, \"Love\":\n\n\tuint n = 1000\n\tfilter := bloom.New(20*n, 5) // load of 20, 5 keys\n\tfilter.Add([]byte(\"Love\"))\n\nSimilarly, to test if \"Love\" is in bloom:\n\n\tif filter.Test([]byte(\"Love\"))\n\nFor numeric data, I recommend that you look into the binary/encoding library. But,\nfor example, to add a uint32 to the filter:\n\n\ti := uint32(100)\n\tn1 := make([]byte,4)\n\tbinary.BigEndian.PutUint32(n1,i)\n\tf.Add(n1)\n\nFinally, there is a method to estimate the false positive rate of a\nBloom filter with _m_ bits and _k_ hashing functions for a set of size _n_:\n\n\tif bloom.EstimateFalsePositiveRate(20*n, 5, n) > 0.001 ...\n\nYou can use it to validate the computed m, k parameters:\n\n\tm, k := bloom.EstimateParameters(n, fp)\n\tActualfpRate := bloom.EstimateFalsePositiveRate(m, k, n)\n\nor\n\n\tf := bloom.NewWithEstimates(n, fp)\n\tActualfpRate := bloom.EstimateFalsePositiveRate(f.m, f.k, n)\n\nYou would expect ActualfpRate to be close to the desired fp in these cases.\n\nThe EstimateFalsePositiveRate function creates a temporary Bloom filter. It is\nalso relatively expensive and only meant for validation.\n*/\npackage bloom\n\nimport (\n\t\"bytes\"\n\t\"encoding/binary\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"math\"\n\n\t\"github.com/bits-and-blooms/bitset\"\n)\n\n// A BloomFilter is a representation of a set of _n_ items, where the main\n// requirement is to make membership queries; _i.e._, whether an item is a\n// member of a set.\ntype BloomFilter struct {\n\tm uint\n\tk uint\n\tb *bitset.BitSet\n}\n\nfunc max(x, y uint) uint {\n\tif x > y {\n\t\treturn x\n\t}\n\treturn y\n}\n\n// New creates a new Bloom filter with _m_ bits and _k_ hashing functions\n// We force _m_ and _k_ to be at least one to avoid panics.\nfunc New(m uint, k uint) *BloomFilter {\n\treturn &BloomFilter{max(1, m), max(1, k), bitset.New(m)}\n}\n\n// From creates a new Bloom filter with len(_data_) * 64 bits and _k_ hashing\n// functions. The data slice is not going to be reset.\nfunc From(data []uint64, k uint) *BloomFilter {\n\tm := uint(len(data) * 64)\n\treturn FromWithM(data, m, k)\n}\n\n// FromWithM creates a new Bloom filter with _m_ length, _k_ hashing functions.\n// The data slice is not going to be reset.\nfunc FromWithM(data []uint64, m, k uint) *BloomFilter {\n\treturn &BloomFilter{m, k, bitset.From(data)}\n}\n\n// baseHashes returns the four hash values of data that are used to create k\n// hashes\nfunc baseHashes(data []byte) [4]uint64 {\n\tvar d digest128 // murmur hashing\n\thash1, hash2, hash3, hash4 := d.sum256(data)\n\treturn [4]uint64{\n\t\thash1, hash2, hash3, hash4,\n\t}\n}\n\n// location returns the ith hashed location using the four base hash values\nfunc location(h [4]uint64, i uint) uint64 {\n\tii := uint64(i)\n\treturn h[ii%2] + ii*h[2+(((ii+(ii%2))%4)/2)]\n}\n\n// location returns the ith hashed location using the four base hash values\nfunc (f *BloomFilter) location(h [4]uint64, i uint) uint {\n\treturn uint(location(h, i) % uint64(f.m))\n}\n\n// EstimateParameters estimates requirements for m and k.\n// Based on https://bitbucket.org/ww/bloom/src/829aa19d01d9/bloom.go\n// used with permission.\nfunc EstimateParameters(n uint, p float64) (m uint, k uint) {\n\tm = uint(math.Ceil(-1 * float64(n) * math.Log(p) / math.Pow(math.Log(2), 2)))\n\tk = uint(math.Ceil(math.Log(2) * float64(m) / float64(n)))\n\treturn\n}\n\n// NewWithEstimates creates a new Bloom filter for about n items with fp\n// false positive rate\nfunc NewWithEstimates(n uint, fp float64) *BloomFilter {\n\tm, k := EstimateParameters(n, fp)\n\treturn New(m, k)\n}\n\n// Cap returns the capacity, _m_, of a Bloom filter\nfunc (f *BloomFilter) Cap() uint {\n\treturn f.m\n}\n\n// K returns the number of hash functions used in the BloomFilter\nfunc (f *BloomFilter) K() uint {\n\treturn f.k\n}\n\n// BitSet returns the underlying bitset for this filter.\nfunc (f *BloomFilter) BitSet() *bitset.BitSet {\n\treturn f.b\n}\n\n// Add data to the Bloom Filter. Returns the filter (allows chaining)\nfunc (f *BloomFilter) Add(data []byte) *BloomFilter {\n\th := baseHashes(data)\n\tfor i := uint(0); i < f.k; i++ {\n\t\tf.b.Set(f.location(h, i))\n\t}\n\treturn f\n}\n\n// Merge the data from two Bloom Filters.\nfunc (f *BloomFilter) Merge(g *BloomFilter) error {\n\t// Make sure the m's and k's are the same, otherwise merging has no real use.\n\tif f.m != g.m {\n\t\treturn fmt.Errorf(\"m's don't match: %d != %d\", f.m, g.m)\n\t}\n\n\tif f.k != g.k {\n\t\treturn fmt.Errorf(\"k's don't match: %d != %d\", f.m, g.m)\n\t}\n\n\tf.b.InPlaceUnion(g.b)\n\treturn nil\n}\n\n// Copy creates a copy of a Bloom filter.\nfunc (f *BloomFilter) Copy() *BloomFilter {\n\tfc := New(f.m, f.k)\n\tfc.Merge(f) // #nosec\n\treturn fc\n}\n\n// AddString to the Bloom Filter. Returns the filter (allows chaining)\nfunc (f *BloomFilter) AddString(data string) *BloomFilter {\n\treturn f.Add([]byte(data))\n}\n\n// Test returns true if the data is in the BloomFilter, false otherwise.\n// If true, the result might be a false positive. If false, the data\n// is definitely not in the set.\nfunc (f *BloomFilter) Test(data []byte) bool {\n\th := baseHashes(data)\n\tfor i := uint(0); i < f.k; i++ {\n\t\tif !f.b.Test(f.location(h, i)) {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\n// TestString returns true if the string is in the BloomFilter, false otherwise.\n// If true, the result might be a false positive. If false, the data\n// is definitely not in the set.\nfunc (f *BloomFilter) TestString(data string) bool {\n\treturn f.Test([]byte(data))\n}\n\n// TestLocations returns true if all locations are set in the BloomFilter, false\n// otherwise.\nfunc (f *BloomFilter) TestLocations(locs []uint64) bool {\n\tfor i := 0; i < len(locs); i++ {\n\t\tif !f.b.Test(uint(locs[i] % uint64(f.m))) {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\n// TestAndAdd is equivalent to calling Test(data) then Add(data).\n// The filter is written to unconditionnally: even if the element is present,\n// the corresponding bits are still set. See also TestOrAdd.\n// Returns the result of Test.\nfunc (f *BloomFilter) TestAndAdd(data []byte) bool {\n\tpresent := true\n\th := baseHashes(data)\n\tfor i := uint(0); i < f.k; i++ {\n\t\tl := f.location(h, i)\n\t\tif !f.b.Test(l) {\n\t\t\tpresent = false\n\t\t}\n\t\tf.b.Set(l)\n\t}\n\treturn present\n}\n\n// TestAndAddString is the equivalent to calling Test(string) then Add(string).\n// The filter is written to unconditionnally: even if the string is present,\n// the corresponding bits are still set. See also TestOrAdd.\n// Returns the result of Test.\nfunc (f *BloomFilter) TestAndAddString(data string) bool {\n\treturn f.TestAndAdd([]byte(data))\n}\n\n// TestOrAdd is equivalent to calling Test(data) then if not present Add(data).\n// If the element is already in the filter, then the filter is unchanged.\n// Returns the result of Test.\nfunc (f *BloomFilter) TestOrAdd(data []byte) bool {\n\tpresent := true\n\th := baseHashes(data)\n\tfor i := uint(0); i < f.k; i++ {\n\t\tl := f.location(h, i)\n\t\tif !f.b.Test(l) {\n\t\t\tpresent = false\n\t\t\tf.b.Set(l)\n\t\t}\n\t}\n\treturn present\n}\n\n// TestOrAddString is the equivalent to calling Test(string) then if not present Add(string).\n// If the string is already in the filter, then the filter is unchanged.\n// Returns the result of Test.\nfunc (f *BloomFilter) TestOrAddString(data string) bool {\n\treturn f.TestOrAdd([]byte(data))\n}\n\n// ClearAll clears all the data in a Bloom filter, removing all keys\nfunc (f *BloomFilter) ClearAll() *BloomFilter {\n\tf.b.ClearAll()\n\treturn f\n}\n\n// EstimateFalsePositiveRate returns, for a BloomFilter of m bits\n// and k hash functions, an estimation of the false positive rate when\n//\n//\tstoring n entries. This is an empirical, relatively slow\n//\n// test using integers as keys.\n// This function is useful to validate the implementation.\nfunc EstimateFalsePositiveRate(m, k, n uint) (fpRate float64) {\n\trounds := uint32(100000)\n\t// We construct a new filter.\n\tf := New(m, k)\n\tn1 := make([]byte, 4)\n\t// We populate the filter with n values.\n\tfor i := uint32(0); i < uint32(n); i++ {\n\t\tbinary.BigEndian.PutUint32(n1, i)\n\t\tf.Add(n1)\n\t}\n\tfp := 0\n\t// test for number of rounds\n\tfor i := uint32(0); i < rounds; i++ {\n\t\tbinary.BigEndian.PutUint32(n1, i+uint32(n)+1)\n\t\tif f.Test(n1) {\n\t\t\tfp++\n\t\t}\n\t}\n\tfpRate = float64(fp) / (float64(rounds))\n\treturn\n}\n\n// Approximating the number of items\n// https://en.wikipedia.org/wiki/Bloom_filter#Approximating_the_number_of_items_in_a_Bloom_filter\nfunc (f *BloomFilter) ApproximatedSize() uint32 {\n\tx := float64(f.b.Count())\n\tm := float64(f.Cap())\n\tk := float64(f.K())\n\tsize := -1 * m / k * math.Log(1-x/m) / math.Log(math.E)\n\treturn uint32(math.Floor(size + 0.5)) // round\n}\n\n// bloomFilterJSON is an unexported type for marshaling/unmarshaling BloomFilter struct.\ntype bloomFilterJSON struct {\n\tM uint           `json:\"m\"`\n\tK uint           `json:\"k\"`\n\tB *bitset.BitSet `json:\"b\"`\n}\n\n// MarshalJSON implements json.Marshaler interface.\nfunc (f BloomFilter) MarshalJSON() ([]byte, error) {\n\treturn json.Marshal(bloomFilterJSON{f.m, f.k, f.b})\n}\n\n// UnmarshalJSON implements json.Unmarshaler interface.\nfunc (f *BloomFilter) UnmarshalJSON(data []byte) error {\n\tvar j bloomFilterJSON\n\terr := json.Unmarshal(data, &j)\n\tif err != nil {\n\t\treturn err\n\t}\n\tf.m = j.M\n\tf.k = j.K\n\tf.b = j.B\n\treturn nil\n}\n\n// WriteTo writes a binary representation of the BloomFilter to an i/o stream.\n// It returns the number of bytes written.\n//\n// Performance: if this function is used to write to a disk or network\n// connection, it might be beneficial to wrap the stream in a bufio.Writer.\n// E.g.,\n//\n//\t      f, err := os.Create(\"myfile\")\n//\t\t       w := bufio.NewWriter(f)\nfunc (f *BloomFilter) WriteTo(stream io.Writer) (int64, error) {\n\terr := binary.Write(stream, binary.BigEndian, uint64(f.m))\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\terr = binary.Write(stream, binary.BigEndian, uint64(f.k))\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\tnumBytes, err := f.b.WriteTo(stream)\n\treturn numBytes + int64(2*binary.Size(uint64(0))), err\n}\n\n// ReadFrom reads a binary representation of the BloomFilter (such as might\n// have been written by WriteTo()) from an i/o stream. It returns the number\n// of bytes read.\n//\n// Performance: if this function is used to read from a disk or network\n// connection, it might be beneficial to wrap the stream in a bufio.Reader.\n// E.g.,\n//\n//\tf, err := os.Open(\"myfile\")\n//\tr := bufio.NewReader(f)\nfunc (f *BloomFilter) ReadFrom(stream io.Reader) (int64, error) {\n\tvar m, k uint64\n\terr := binary.Read(stream, binary.BigEndian, &m)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\terr = binary.Read(stream, binary.BigEndian, &k)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\tb := &bitset.BitSet{}\n\tnumBytes, err := b.ReadFrom(stream)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\tf.m = uint(m)\n\tf.k = uint(k)\n\tf.b = b\n\treturn numBytes + int64(2*binary.Size(uint64(0))), nil\n}\n\n// GobEncode implements gob.GobEncoder interface.\nfunc (f *BloomFilter) GobEncode() ([]byte, error) {\n\tvar buf bytes.Buffer\n\t_, err := f.WriteTo(&buf)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn buf.Bytes(), nil\n}\n\n// GobDecode implements gob.GobDecoder interface.\nfunc (f *BloomFilter) GobDecode(data []byte) error {\n\tbuf := bytes.NewBuffer(data)\n\t_, err := f.ReadFrom(buf)\n\n\treturn err\n}\n\n// MarshalBinary implements binary.BinaryMarshaler interface.\nfunc (f *BloomFilter) MarshalBinary() ([]byte, error) {\n\tvar buf bytes.Buffer\n\t_, err := f.WriteTo(&buf)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn buf.Bytes(), nil\n}\n\n// UnmarshalBinary implements binary.BinaryUnmarshaler interface.\nfunc (f *BloomFilter) UnmarshalBinary(data []byte) error {\n\tbuf := bytes.NewBuffer(data)\n\t_, err := f.ReadFrom(buf)\n\n\treturn err\n}\n\n// Equal tests for the equality of two Bloom filters\nfunc (f *BloomFilter) Equal(g *BloomFilter) bool {\n\treturn f.m == g.m && f.k == g.k && f.b.Equal(g.b)\n}\n\n// Locations returns a list of hash locations representing a data item.\nfunc Locations(data []byte, k uint) []uint64 {\n\tlocs := make([]uint64, k)\n\n\t// calculate locations\n\th := baseHashes(data)\n\tfor i := uint(0); i < k; i++ {\n\t\tlocs[i] = location(h, i)\n\t}\n\n\treturn locs\n}\n"
        },
        {
          "name": "bloom_test.go",
          "type": "blob",
          "size": 14.806640625,
          "content": "package bloom\n\nimport (\n\t\"fmt\"\n\t\"bytes\"\n\t\"encoding/binary\"\n\t\"encoding/gob\"\n\t\"encoding/json\"\n\t\"math\"\n\t\"testing\"\n\n\t\"github.com/bits-and-blooms/bitset\"\n)\n\n// This implementation of Bloom filters is _not_\n// safe for concurrent use. Uncomment the following\n// method and run go test -race\n//\n// func TestConcurrent(t *testing.T) {\n// \tgmp := runtime.GOMAXPROCS(2)\n// \tdefer runtime.GOMAXPROCS(gmp)\n//\n// \tf := New(1000, 4)\n// \tn1 := []byte(\"Bess\")\n// \tn2 := []byte(\"Jane\")\n// \tf.Add(n1)\n// \tf.Add(n2)\n//\n// \tvar wg sync.WaitGroup\n// \tconst try = 1000\n// \tvar err1, err2 error\n//\n// \twg.Add(1)\n// \tgo func() {\n// \t\tfor i := 0; i < try; i++ {\n// \t\t\tn1b := f.Test(n1)\n// \t\t\tif !n1b {\n// \t\t\t\terr1 = fmt.Errorf(\"%v should be in\", n1)\n// \t\t\t\tbreak\n// \t\t\t}\n// \t\t}\n// \t\twg.Done()\n// \t}()\n//\n// \twg.Add(1)\n// \tgo func() {\n// \t\tfor i := 0; i < try; i++ {\n// \t\t\tn2b := f.Test(n2)\n// \t\t\tif !n2b {\n// \t\t\t\terr2 = fmt.Errorf(\"%v should be in\", n2)\n// \t\t\t\tbreak\n// \t\t\t}\n// \t\t}\n// \t\twg.Done()\n// \t}()\n//\n// \twg.Wait()\n//\n// \tif err1 != nil {\n// \t\tt.Fatal(err1)\n// \t}\n// \tif err2 != nil {\n// \t\tt.Fatal(err2)\n// \t}\n// }\n\nfunc TestBasic(t *testing.T) {\n\tf := New(1000, 4)\n\tn1 := []byte(\"Bess\")\n\tn2 := []byte(\"Jane\")\n\tn3 := []byte(\"Emma\")\n\tf.Add(n1)\n\tn3a := f.TestAndAdd(n3)\n\tn1b := f.Test(n1)\n\tn2b := f.Test(n2)\n\tn3b := f.Test(n3)\n\tif !n1b {\n\t\tt.Errorf(\"%v should be in.\", n1)\n\t}\n\tif n2b {\n\t\tt.Errorf(\"%v should not be in.\", n2)\n\t}\n\tif n3a {\n\t\tt.Errorf(\"%v should not be in the first time we look.\", n3)\n\t}\n\tif !n3b {\n\t\tt.Errorf(\"%v should be in the second time we look.\", n3)\n\t}\n}\n\nfunc TestBasicUint32(t *testing.T) {\n\tf := New(1000, 4)\n\tn1 := make([]byte, 4)\n\tn2 := make([]byte, 4)\n\tn3 := make([]byte, 4)\n\tn4 := make([]byte, 4)\n\tn5 := make([]byte, 4)\n\tbinary.BigEndian.PutUint32(n1, 100)\n\tbinary.BigEndian.PutUint32(n2, 101)\n\tbinary.BigEndian.PutUint32(n3, 102)\n\tbinary.BigEndian.PutUint32(n4, 103)\n\tbinary.BigEndian.PutUint32(n5, 104)\n\tf.Add(n1)\n\tn3a := f.TestAndAdd(n3)\n\tn1b := f.Test(n1)\n\tn2b := f.Test(n2)\n\tn3b := f.Test(n3)\n\tn5a := f.TestOrAdd(n5)\n\tn5b := f.Test(n5)\n\tf.Test(n4)\n\tif !n1b {\n\t\tt.Errorf(\"%v should be in.\", n1)\n\t}\n\tif n2b {\n\t\tt.Errorf(\"%v should not be in.\", n2)\n\t}\n\tif n3a {\n\t\tt.Errorf(\"%v should not be in the first time we look.\", n3)\n\t}\n\tif !n3b {\n\t\tt.Errorf(\"%v should be in the second time we look.\", n3)\n\t}\n\tif n5a {\n\t\tt.Errorf(\"%v should not be in the first time we look.\", n5)\n\t}\n\tif !n5b {\n\t\tt.Errorf(\"%v should be in the second time we look.\", n5)\n\t}\n}\n\nfunc TestNewWithLowNumbers(t *testing.T) {\n\tf := New(0, 0)\n\tif f.k != 1 {\n\t\tt.Errorf(\"%v should be 1\", f.k)\n\t}\n\tif f.m != 1 {\n\t\tt.Errorf(\"%v should be 1\", f.m)\n\t}\n}\n\nfunc TestString(t *testing.T) {\n\tf := NewWithEstimates(1000, 0.001)\n\tn1 := \"Love\"\n\tn2 := \"is\"\n\tn3 := \"in\"\n\tn4 := \"bloom\"\n\tn5 := \"blooms\"\n\tf.AddString(n1)\n\tn3a := f.TestAndAddString(n3)\n\tn1b := f.TestString(n1)\n\tn2b := f.TestString(n2)\n\tn3b := f.TestString(n3)\n\tn5a := f.TestOrAddString(n5)\n\tn5b := f.TestString(n5)\n\tf.TestString(n4)\n\tif !n1b {\n\t\tt.Errorf(\"%v should be in.\", n1)\n\t}\n\tif n2b {\n\t\tt.Errorf(\"%v should not be in.\", n2)\n\t}\n\tif n3a {\n\t\tt.Errorf(\"%v should not be in the first time we look.\", n3)\n\t}\n\tif !n3b {\n\t\tt.Errorf(\"%v should be in the second time we look.\", n3)\n\t}\n\tif n5a {\n\t\tt.Errorf(\"%v should not be in the first time we look.\", n5)\n\t}\n\tif !n5b {\n\t\tt.Errorf(\"%v should be in the second time we look.\", n5)\n\t}\n\n}\n\nfunc testEstimated(n uint, maxFp float64, t *testing.T) {\n\tm, k := EstimateParameters(n, maxFp)\n\tfpRate := EstimateFalsePositiveRate(m, k, n)\n\tif fpRate > 1.5*maxFp {\n\t\tt.Errorf(\"False positive rate too high: n: %v; m: %v; k: %v; maxFp: %f; fpRate: %f, fpRate/maxFp: %f\", n, m, k, maxFp, fpRate, fpRate/maxFp)\n\t}\n}\n\nfunc TestEstimated1000_0001(t *testing.T)   { testEstimated(1000, 0.000100, t) }\nfunc TestEstimated10000_0001(t *testing.T)  { testEstimated(10000, 0.000100, t) }\nfunc TestEstimated100000_0001(t *testing.T) { testEstimated(100000, 0.000100, t) }\n\nfunc TestEstimated1000_001(t *testing.T)   { testEstimated(1000, 0.001000, t) }\nfunc TestEstimated10000_001(t *testing.T)  { testEstimated(10000, 0.001000, t) }\nfunc TestEstimated100000_001(t *testing.T) { testEstimated(100000, 0.001000, t) }\n\nfunc TestEstimated1000_01(t *testing.T)   { testEstimated(1000, 0.010000, t) }\nfunc TestEstimated10000_01(t *testing.T)  { testEstimated(10000, 0.010000, t) }\nfunc TestEstimated100000_01(t *testing.T) { testEstimated(100000, 0.010000, t) }\n\nfunc min(a, b uint) uint {\n\tif a < b {\n\t\treturn a\n\t}\n\treturn b\n}\n\n// The following function courtesy of Nick @turgon\n// This helper function ranges over the input data, applying the hashing\n// which returns the bit locations to set in the filter.\n// For each location, increment a counter for that bit address.\n//\n// If the Bloom Filter's location() method distributes locations uniformly\n// at random, a property it should inherit from its hash function, then\n// each bit location in the filter should end up with roughly the same\n// number of hits.  Importantly, the value of k should not matter.\n//\n// Once the results are collected, we can run a chi squared goodness of fit\n// test, comparing the result histogram with the uniform distribition.\n// This yields a test statistic with degrees-of-freedom of m-1.\nfunc chiTestBloom(m, k, rounds uint, elements [][]byte) (succeeds bool) {\n\tf := New(m, k)\n\tresults := make([]uint, m)\n\tchi := make([]float64, m)\n\n\tfor _, data := range elements {\n\t\th := baseHashes(data)\n\t\tfor i := uint(0); i < f.k; i++ {\n\t\t\tresults[f.location(h, i)]++\n\t\t}\n\t}\n\n\t// Each element of results should contain the same value: k * rounds / m.\n\t// Let's run a chi-square goodness of fit and see how it fares.\n\tvar chiStatistic float64\n\te := float64(k*rounds) / float64(m)\n\tfor i := uint(0); i < m; i++ {\n\t\tchi[i] = math.Pow(float64(results[i])-e, 2.0) / e\n\t\tchiStatistic += chi[i]\n\t}\n\n\t// this tests at significant level 0.005 up to 20 degrees of freedom\n\ttable := [20]float64{\n\t\t7.879, 10.597, 12.838, 14.86, 16.75, 18.548, 20.278,\n\t\t21.955, 23.589, 25.188, 26.757, 28.3, 29.819, 31.319, 32.801, 34.267,\n\t\t35.718, 37.156, 38.582, 39.997}\n\tdf := min(m-1, 20)\n\n\tsucceeds = table[df-1] > chiStatistic\n\treturn\n\n}\n\nfunc TestLocation(t *testing.T) {\n\tvar m, k, rounds uint\n\n\tm = 8\n\tk = 3\n\n\trounds = 100000 // 15000000\n\n\telements := make([][]byte, rounds)\n\n\tfor x := uint(0); x < rounds; x++ {\n\t\tctrlist := make([]uint8, 4)\n\t\tctrlist[0] = uint8(x)\n\t\tctrlist[1] = uint8(x >> 8)\n\t\tctrlist[2] = uint8(x >> 16)\n\t\tctrlist[3] = uint8(x >> 24)\n\t\tdata := []byte(ctrlist)\n\t\telements[x] = data\n\t}\n\n\tsucceeds := chiTestBloom(m, k, rounds, elements)\n\tif !succeeds {\n\t\tt.Error(\"random assignment is too unrandom\")\n\t}\n\n}\n\nfunc TestCap(t *testing.T) {\n\tf := New(1000, 4)\n\tif f.Cap() != f.m {\n\t\tt.Error(\"not accessing Cap() correctly\")\n\t}\n}\n\nfunc TestK(t *testing.T) {\n\tf := New(1000, 4)\n\tif f.K() != f.k {\n\t\tt.Error(\"not accessing K() correctly\")\n\t}\n}\n\nfunc TestMarshalUnmarshalJSON(t *testing.T) {\n\tf := New(1000, 4)\n\tdata, err := json.Marshal(f)\n\tif err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\tfmt.Println(string(data))\n\n\tvar g BloomFilter\n\terr = json.Unmarshal(data, &g)\n\tif err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\tif g.m != f.m {\n\t\tt.Error(\"invalid m value\")\n\t}\n\tif g.k != f.k {\n\t\tt.Error(\"invalid k value\")\n\t}\n\tif g.b == nil {\n\t\tt.Fatal(\"bitset is nil\")\n\t}\n\tif !g.b.Equal(f.b) {\n\t\tt.Error(\"bitsets are not equal\")\n\t}\n}\n\n\nfunc TestMarshalUnmarshalJSONValue(t *testing.T) {\n\tf:= BloomFilter{1000, 4, bitset.New(1000)}\n\tdata, err := json.Marshal(f)\n\tif err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\tfmt.Println(string(data))\n\n\tvar g BloomFilter\n\terr = json.Unmarshal(data, &g)\n\tif err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\tif g.m != f.m {\n\t\tt.Error(\"invalid m value\")\n\t}\n\tif g.k != f.k {\n\t\tt.Error(\"invalid k value\")\n\t}\n\tif g.b == nil {\n\t\tt.Fatal(\"bitset is nil\")\n\t}\n\tif !g.b.Equal(f.b) {\n\t\tt.Error(\"bitsets are not equal\")\n\t}\n}\n\nfunc TestUnmarshalInvalidJSON(t *testing.T) {\n\tdata := []byte(\"{invalid}\")\n\n\tvar g BloomFilter\n\terr := g.UnmarshalJSON(data)\n\tif err == nil {\n\t\tt.Error(\"expected error while unmarshalling invalid data\")\n\t}\n}\n\nfunc TestWriteToReadFrom(t *testing.T) {\n\tvar b bytes.Buffer\n\tf := New(1000, 4)\n\t_, err := f.WriteTo(&b)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tg := New(1000, 1)\n\t_, err = g.ReadFrom(&b)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif g.m != f.m {\n\t\tt.Error(\"invalid m value\")\n\t}\n\tif g.k != f.k {\n\t\tt.Error(\"invalid k value\")\n\t}\n\tif g.b == nil {\n\t\tt.Fatal(\"bitset is nil\")\n\t}\n\tif !g.b.Equal(f.b) {\n\t\tt.Error(\"bitsets are not equal\")\n\t}\n\n\tg.Test([]byte(\"\"))\n}\n\nfunc TestReadWriteBinary(t *testing.T) {\n\tf := New(1000, 4)\n\tvar buf bytes.Buffer\n\tbytesWritten, err := f.WriteTo(&buf)\n\tif err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\tif bytesWritten != int64(buf.Len()) {\n\t\tt.Errorf(\"incorrect write length %d != %d\", bytesWritten, buf.Len())\n\t}\n\n\tvar g BloomFilter\n\tbytesRead, err := g.ReadFrom(&buf)\n\tif err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\tif bytesRead != bytesWritten {\n\t\tt.Errorf(\"read unexpected number of bytes %d != %d\", bytesRead, bytesWritten)\n\t}\n\tif g.m != f.m {\n\t\tt.Error(\"invalid m value\")\n\t}\n\tif g.k != f.k {\n\t\tt.Error(\"invalid k value\")\n\t}\n\tif g.b == nil {\n\t\tt.Fatal(\"bitset is nil\")\n\t}\n\tif !g.b.Equal(f.b) {\n\t\tt.Error(\"bitsets are not equal\")\n\t}\n}\n\nfunc TestEncodeDecodeGob(t *testing.T) {\n\tf := New(1000, 4)\n\tf.Add([]byte(\"one\"))\n\tf.Add([]byte(\"two\"))\n\tf.Add([]byte(\"three\"))\n\tvar buf bytes.Buffer\n\terr := gob.NewEncoder(&buf).Encode(f)\n\tif err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\n\tvar g BloomFilter\n\terr = gob.NewDecoder(&buf).Decode(&g)\n\tif err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\tif g.m != f.m {\n\t\tt.Error(\"invalid m value\")\n\t}\n\tif g.k != f.k {\n\t\tt.Error(\"invalid k value\")\n\t}\n\tif g.b == nil {\n\t\tt.Fatal(\"bitset is nil\")\n\t}\n\tif !g.b.Equal(f.b) {\n\t\tt.Error(\"bitsets are not equal\")\n\t}\n\tif !g.Test([]byte(\"three\")) {\n\t\tt.Errorf(\"missing value 'three'\")\n\t}\n\tif !g.Test([]byte(\"two\")) {\n\t\tt.Errorf(\"missing value 'two'\")\n\t}\n\tif !g.Test([]byte(\"one\")) {\n\t\tt.Errorf(\"missing value 'one'\")\n\t}\n}\n\nfunc TestEqual(t *testing.T) {\n\tf := New(1000, 4)\n\tf1 := New(1000, 4)\n\tg := New(1000, 20)\n\th := New(10, 20)\n\tn1 := []byte(\"Bess\")\n\tf1.Add(n1)\n\tif !f.Equal(f) {\n\t\tt.Errorf(\"%v should be equal to itself\", f)\n\t}\n\tif f.Equal(f1) {\n\t\tt.Errorf(\"%v should not be equal to %v\", f, f1)\n\t}\n\tif f.Equal(g) {\n\t\tt.Errorf(\"%v should not be equal to %v\", f, g)\n\t}\n\tif f.Equal(h) {\n\t\tt.Errorf(\"%v should not be equal to %v\", f, h)\n\t}\n}\n\nfunc BenchmarkEstimated(b *testing.B) {\n\tfor n := uint(100000); n <= 100000; n *= 10 {\n\t\tfor fp := 0.1; fp >= 0.0001; fp /= 10.0 {\n\t\t\tf := NewWithEstimates(n, fp)\n\t\t\tEstimateFalsePositiveRate(f.m, f.k, n)\n\t\t}\n\t}\n}\n\nfunc BenchmarkSeparateTestAndAdd(b *testing.B) {\n\tf := NewWithEstimates(uint(b.N), 0.0001)\n\tkey := make([]byte, 100)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tbinary.BigEndian.PutUint32(key, uint32(i))\n\t\tf.Test(key)\n\t\tf.Add(key)\n\t}\n}\n\nfunc BenchmarkCombinedTestAndAdd(b *testing.B) {\n\tf := NewWithEstimates(uint(b.N), 0.0001)\n\tkey := make([]byte, 100)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tbinary.BigEndian.PutUint32(key, uint32(i))\n\t\tf.TestAndAdd(key)\n\t}\n}\n\nfunc TestMerge(t *testing.T) {\n\tf := New(1000, 4)\n\tn1 := []byte(\"f\")\n\tf.Add(n1)\n\n\tg := New(1000, 4)\n\tn2 := []byte(\"g\")\n\tg.Add(n2)\n\n\th := New(999, 4)\n\tn3 := []byte(\"h\")\n\th.Add(n3)\n\n\tj := New(1000, 5)\n\tn4 := []byte(\"j\")\n\tj.Add(n4)\n\n\terr := f.Merge(g)\n\tif err != nil {\n\t\tt.Errorf(\"There should be no error when merging two similar filters\")\n\t}\n\n\terr = f.Merge(h)\n\tif err == nil {\n\t\tt.Errorf(\"There should be an error when merging filters with mismatched m\")\n\t}\n\n\terr = f.Merge(j)\n\tif err == nil {\n\t\tt.Errorf(\"There should be an error when merging filters with mismatched k\")\n\t}\n\n\tn2b := f.Test(n2)\n\tif !n2b {\n\t\tt.Errorf(\"The value doesn't exist after a valid merge\")\n\t}\n\n\tn3b := f.Test(n3)\n\tif n3b {\n\t\tt.Errorf(\"The value exists after an invalid merge\")\n\t}\n\n\tn4b := f.Test(n4)\n\tif n4b {\n\t\tt.Errorf(\"The value exists after an invalid merge\")\n\t}\n}\n\nfunc TestCopy(t *testing.T) {\n\tf := New(1000, 4)\n\tn1 := []byte(\"f\")\n\tf.Add(n1)\n\n\t// copy here instead of New\n\tg := f.Copy()\n\tn2 := []byte(\"g\")\n\tg.Add(n2)\n\n\tn1fb := f.Test(n1)\n\tif !n1fb {\n\t\tt.Errorf(\"The value doesn't exist in original after making a copy\")\n\t}\n\n\tn1gb := g.Test(n1)\n\tif !n1gb {\n\t\tt.Errorf(\"The value doesn't exist in the copy\")\n\t}\n\n\tn2fb := f.Test(n2)\n\tif n2fb {\n\t\tt.Errorf(\"The value exists in the original, it should only exist in copy\")\n\t}\n\n\tn2gb := g.Test(n2)\n\tif !n2gb {\n\t\tt.Errorf(\"The value doesn't exist in copy after Add()\")\n\t}\n}\n\nfunc TestFrom(t *testing.T) {\n\tvar (\n\t\tk    = uint(5)\n\t\tdata = make([]uint64, 10)\n\t\ttest = []byte(\"test\")\n\t)\n\n\tbf := From(data, k)\n\tif bf.K() != k {\n\t\tt.Errorf(\"Constant k does not match the expected value\")\n\t}\n\n\tif bf.Cap() != uint(len(data)*64) {\n\t\tt.Errorf(\"Capacity does not match the expected value\")\n\t}\n\n\tif bf.Test(test) {\n\t\tt.Errorf(\"Bloom filter should not contain the value\")\n\t}\n\n\tbf.Add(test)\n\tif !bf.Test(test) {\n\t\tt.Errorf(\"Bloom filter should contain the value\")\n\t}\n\n\t// create a new Bloom filter from an existing (populated) data slice.\n\tbf = From(data, k)\n\tif !bf.Test(test) {\n\t\tt.Errorf(\"Bloom filter should contain the value\")\n\t}\n}\n\nfunc TestTestLocations(t *testing.T) {\n\tf := NewWithEstimates(1000, 0.001)\n\tn1 := []byte(\"Love\")\n\tn2 := []byte(\"is\")\n\tn3 := []byte(\"in\")\n\tn4 := []byte(\"bloom\")\n\tf.Add(n1)\n\tn3a := f.TestLocations(Locations(n3, f.K()))\n\tf.Add(n3)\n\tn1b := f.TestLocations(Locations(n1, f.K()))\n\tn2b := f.TestLocations(Locations(n2, f.K()))\n\tn3b := f.TestLocations(Locations(n3, f.K()))\n\tn4b := f.TestLocations(Locations(n4, f.K()))\n\tif !n1b {\n\t\tt.Errorf(\"%v should be in.\", n1)\n\t}\n\tif n2b {\n\t\tt.Errorf(\"%v should not be in.\", n2)\n\t}\n\tif n3a {\n\t\tt.Errorf(\"%v should not be in the first time we look.\", n3)\n\t}\n\tif !n3b {\n\t\tt.Errorf(\"%v should be in the second time we look.\", n3)\n\t}\n\tif n4b {\n\t\tt.Errorf(\"%v should be in.\", n4)\n\t}\n}\n\nfunc TestApproximatedSize(t *testing.T) {\n\tf := NewWithEstimates(1000, 0.001)\n\tf.Add([]byte(\"Love\"))\n\tf.Add([]byte(\"is\"))\n\tf.Add([]byte(\"in\"))\n\tf.Add([]byte(\"bloom\"))\n\tsize := f.ApproximatedSize()\n\tif size != 4 {\n\t\tt.Errorf(\"%d should equal 4.\", size)\n\t}\n}\n\nfunc TestFPP(t *testing.T) {\n\tf := NewWithEstimates(1000, 0.001)\n\tfor i := uint32(0); i < 1000; i++ {\n\t\tn := make([]byte, 4)\n\t\tbinary.BigEndian.PutUint32(n, i)\n\t\tf.Add(n)\n\t}\n\tcount := 0\n\n\tfor i := uint32(0); i < 1000; i++ {\n\t\tn := make([]byte, 4)\n\t\tbinary.BigEndian.PutUint32(n, i+1000)\n\t\tif f.Test(n) {\n\t\t\tcount += 1\n\t\t}\n\t}\n\tif float64(count)/1000.0 > 0.001 {\n\t\tt.Errorf(\"Excessive fpp\")\n\t}\n}\n\nfunc TestEncodeDecodeBinary(t *testing.T) {\n\tf := New(1000, 4)\n\tf.Add([]byte(\"one\"))\n\tf.Add([]byte(\"two\"))\n\tf.Add([]byte(\"three\"))\n\tdata, err := f.MarshalBinary()\n\tif err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\n\tvar g BloomFilter\n\terr = g.UnmarshalBinary(data)\n\tif err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\tif g.m != f.m {\n\t\tt.Error(\"invalid m value\")\n\t}\n\tif g.k != f.k {\n\t\tt.Error(\"invalid k value\")\n\t}\n\tif g.b == nil {\n\t\tt.Fatal(\"bitset is nil\")\n\t}\n\tif !g.b.Equal(f.b) {\n\t\tt.Error(\"bitsets are not equal\")\n\t}\n\tif !g.Test([]byte(\"three\")) {\n\t\tt.Errorf(\"missing value 'three'\")\n\t}\n\tif !g.Test([]byte(\"two\")) {\n\t\tt.Errorf(\"missing value 'two'\")\n\t}\n\tif !g.Test([]byte(\"one\")) {\n\t\tt.Errorf(\"missing value 'one'\")\n\t}\n}\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.13671875,
          "content": "module github.com/bits-and-blooms/bloom/v3\n\ngo 1.16\n\nrequire (\n\tgithub.com/bits-and-blooms/bitset v1.19.1\n\tgithub.com/twmb/murmur3 v1.1.6\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 0.34375,
          "content": "github.com/bits-and-blooms/bitset v1.19.1 h1:mv2yVhy96D2CuskLPXnc58oJNMs5PCWjAZuyYU0p12M=\ngithub.com/bits-and-blooms/bitset v1.19.1/go.mod h1:7hO7Gc7Pp1vODcmWvKMRA9BNmbv6a/7QIWpPxHddWR8=\ngithub.com/twmb/murmur3 v1.1.6 h1:mqrRot1BRxm+Yct+vavLMou2/iJt0tNVTTC0QoIjaZg=\ngithub.com/twmb/murmur3 v1.1.6/go.mod h1:Qq/R7NUyOfr65zD+6Q5IHKsJLwP7exErjN6lyyq3OSQ=\n"
        },
        {
          "name": "murmur.go",
          "type": "blob",
          "size": 7.130859375,
          "content": "/*\nThe bloom library relied on the excellent murmur library\nby Sébastien Paolacci. Unfortunately, it involved some heap\nallocation. We want to avoid any heap allocation whatsoever\nin the hashing process. To preserve backward compatibility, we roll\nour own hashing functions. They are designed to be strictly equivalent\nto Paolacci's implementation.\n\nLicense on original code:\n\n\nCopyright 2013, Sébastien Paolacci.\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in the\n      documentation and/or other materials provided with the distribution.\n    * Neither the name of the library nor the\n      names of its contributors may be used to endorse or promote products\n      derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n*/\n\npackage bloom\n\nimport (\n\t\"encoding/binary\"\n\t\"math/bits\"\n\t\"unsafe\"\n)\n\nconst (\n\tc1_128     = 0x87c37b91114253d5\n\tc2_128     = 0x4cf5ad432745937f\n\tblock_size = 16\n)\n\n// digest128 represents a partial evaluation of a 128 bites hash.\ntype digest128 struct {\n\th1 uint64 // Unfinalized running hash part 1.\n\th2 uint64 // Unfinalized running hash part 2.\n}\n\n// bmix will hash blocks (16 bytes)\nfunc (d *digest128) bmix(p []byte) {\n\tnblocks := len(p) / block_size\n\tfor i := 0; i < nblocks; i++ {\n\t\tb := (*[16]byte)(unsafe.Pointer(&p[i*block_size]))\n\t\tk1, k2 := binary.LittleEndian.Uint64(b[:8]), binary.LittleEndian.Uint64(b[8:])\n\t\td.bmix_words(k1, k2)\n\t}\n}\n\n// bmix_words will hash two 64-bit words (16 bytes)\nfunc (d *digest128) bmix_words(k1, k2 uint64) {\n\th1, h2 := d.h1, d.h2\n\n\tk1 *= c1_128\n\tk1 = bits.RotateLeft64(k1, 31)\n\tk1 *= c2_128\n\th1 ^= k1\n\n\th1 = bits.RotateLeft64(h1, 27)\n\th1 += h2\n\th1 = h1*5 + 0x52dce729\n\n\tk2 *= c2_128\n\tk2 = bits.RotateLeft64(k2, 33)\n\tk2 *= c1_128\n\th2 ^= k2\n\n\th2 = bits.RotateLeft64(h2, 31)\n\th2 += h1\n\th2 = h2*5 + 0x38495ab5\n\td.h1, d.h2 = h1, h2\n}\n\n// sum128 computers two 64-bit hash value. It is assumed that\n// bmix was first called on the data to process complete blocks\n// of 16 bytes. The 'tail' is a slice representing the 'tail' (leftover\n// elements, fewer than 16). If pad_tail is true, we make it seem like\n// there is an extra element with value 1 appended to the tail.\n// The length parameter represents the full length of the data (including\n// the blocks of 16 bytes, and, if pad_tail is true, an extra byte).\nfunc (d *digest128) sum128(pad_tail bool, length uint, tail []byte) (h1, h2 uint64) {\n\th1, h2 = d.h1, d.h2\n\n\tvar k1, k2 uint64\n\tif pad_tail {\n\t\tswitch (len(tail) + 1) & 15 {\n\t\tcase 15:\n\t\t\tk2 ^= uint64(1) << 48\n\t\t\tbreak\n\t\tcase 14:\n\t\t\tk2 ^= uint64(1) << 40\n\t\t\tbreak\n\t\tcase 13:\n\t\t\tk2 ^= uint64(1) << 32\n\t\t\tbreak\n\t\tcase 12:\n\t\t\tk2 ^= uint64(1) << 24\n\t\t\tbreak\n\t\tcase 11:\n\t\t\tk2 ^= uint64(1) << 16\n\t\t\tbreak\n\t\tcase 10:\n\t\t\tk2 ^= uint64(1) << 8\n\t\t\tbreak\n\t\tcase 9:\n\t\t\tk2 ^= uint64(1) << 0\n\n\t\t\tk2 *= c2_128\n\t\t\tk2 = bits.RotateLeft64(k2, 33)\n\t\t\tk2 *= c1_128\n\t\t\th2 ^= k2\n\n\t\t\tbreak\n\n\t\tcase 8:\n\t\t\tk1 ^= uint64(1) << 56\n\t\t\tbreak\n\t\tcase 7:\n\t\t\tk1 ^= uint64(1) << 48\n\t\t\tbreak\n\t\tcase 6:\n\t\t\tk1 ^= uint64(1) << 40\n\t\t\tbreak\n\t\tcase 5:\n\t\t\tk1 ^= uint64(1) << 32\n\t\t\tbreak\n\t\tcase 4:\n\t\t\tk1 ^= uint64(1) << 24\n\t\t\tbreak\n\t\tcase 3:\n\t\t\tk1 ^= uint64(1) << 16\n\t\t\tbreak\n\t\tcase 2:\n\t\t\tk1 ^= uint64(1) << 8\n\t\t\tbreak\n\t\tcase 1:\n\t\t\tk1 ^= uint64(1) << 0\n\t\t\tk1 *= c1_128\n\t\t\tk1 = bits.RotateLeft64(k1, 31)\n\t\t\tk1 *= c2_128\n\t\t\th1 ^= k1\n\t\t}\n\n\t}\n\tswitch len(tail) & 15 {\n\tcase 15:\n\t\tk2 ^= uint64(tail[14]) << 48\n\t\tfallthrough\n\tcase 14:\n\t\tk2 ^= uint64(tail[13]) << 40\n\t\tfallthrough\n\tcase 13:\n\t\tk2 ^= uint64(tail[12]) << 32\n\t\tfallthrough\n\tcase 12:\n\t\tk2 ^= uint64(tail[11]) << 24\n\t\tfallthrough\n\tcase 11:\n\t\tk2 ^= uint64(tail[10]) << 16\n\t\tfallthrough\n\tcase 10:\n\t\tk2 ^= uint64(tail[9]) << 8\n\t\tfallthrough\n\tcase 9:\n\t\tk2 ^= uint64(tail[8]) << 0\n\n\t\tk2 *= c2_128\n\t\tk2 = bits.RotateLeft64(k2, 33)\n\t\tk2 *= c1_128\n\t\th2 ^= k2\n\n\t\tfallthrough\n\n\tcase 8:\n\t\tk1 ^= uint64(tail[7]) << 56\n\t\tfallthrough\n\tcase 7:\n\t\tk1 ^= uint64(tail[6]) << 48\n\t\tfallthrough\n\tcase 6:\n\t\tk1 ^= uint64(tail[5]) << 40\n\t\tfallthrough\n\tcase 5:\n\t\tk1 ^= uint64(tail[4]) << 32\n\t\tfallthrough\n\tcase 4:\n\t\tk1 ^= uint64(tail[3]) << 24\n\t\tfallthrough\n\tcase 3:\n\t\tk1 ^= uint64(tail[2]) << 16\n\t\tfallthrough\n\tcase 2:\n\t\tk1 ^= uint64(tail[1]) << 8\n\t\tfallthrough\n\tcase 1:\n\t\tk1 ^= uint64(tail[0]) << 0\n\t\tk1 *= c1_128\n\t\tk1 = bits.RotateLeft64(k1, 31)\n\t\tk1 *= c2_128\n\t\th1 ^= k1\n\t}\n\n\th1 ^= uint64(length)\n\th2 ^= uint64(length)\n\n\th1 += h2\n\th2 += h1\n\n\th1 = fmix64(h1)\n\th2 = fmix64(h2)\n\n\th1 += h2\n\th2 += h1\n\n\treturn h1, h2\n}\n\nfunc fmix64(k uint64) uint64 {\n\tk ^= k >> 33\n\tk *= 0xff51afd7ed558ccd\n\tk ^= k >> 33\n\tk *= 0xc4ceb9fe1a85ec53\n\tk ^= k >> 33\n\treturn k\n}\n\n// sum256 will compute 4 64-bit hash values from the input.\n// It is designed to never allocate memory on the heap. So it\n// works without any byte buffer whatsoever.\n// It is designed to be strictly equivalent to\n//\n//\t\t\t\ta1 := []byte{1}\n//\t         hasher := murmur3.New128()\n//\t         hasher.Write(data) // #nosec\n//\t         v1, v2 := hasher.Sum128()\n//\t         hasher.Write(a1) // #nosec\n//\t         v3, v4 := hasher.Sum128()\n//\n// See TestHashRandom.\nfunc (d *digest128) sum256(data []byte) (hash1, hash2, hash3, hash4 uint64) {\n\t// We always start from zero.\n\td.h1, d.h2 = 0, 0\n\t// Process as many bytes as possible.\n\td.bmix(data)\n\t// We have enough to compute the first two 64-bit numbers\n\tlength := uint(len(data))\n\ttail_length := length % block_size\n\ttail := data[length-tail_length:]\n\thash1, hash2 = d.sum128(false, length, tail)\n\t// Next we want to 'virtually' append 1 to the input, but,\n\t// we do not want to append to an actual array!!!\n\tif tail_length+1 == block_size {\n\t\t// We are left with no tail!!!\n\t\tword1 := binary.LittleEndian.Uint64(tail[:8])\n\t\tword2 := uint64(binary.LittleEndian.Uint32(tail[8 : 8+4]))\n\t\tword2 = word2 | (uint64(tail[12]) << 32) | (uint64(tail[13]) << 40) | (uint64(tail[14]) << 48)\n\t\t// We append 1.\n\t\tword2 = word2 | (uint64(1) << 56)\n\t\t// We process the resulting 2 words.\n\t\td.bmix_words(word1, word2)\n\t\ttail := data[length:] // empty slice, deliberate.\n\t\thash3, hash4 = d.sum128(false, length+1, tail)\n\t} else {\n\t\t// We still have a tail (fewer than 15 bytes) but we\n\t\t// need to append '1' to it.\n\t\thash3, hash4 = d.sum128(true, length+1, tail)\n\t}\n\n\treturn hash1, hash2, hash3, hash4\n}\n"
        },
        {
          "name": "murmur_test.go",
          "type": "blob",
          "size": 1.5439453125,
          "content": "package bloom\n\nimport (\n\t\"math/rand\"\n\t\"testing\"\n\n\t\"github.com/twmb/murmur3\"\n)\n\n// We want to preserve backward compatibility\nfunc TestHashBasic(t *testing.T) {\n\tmax_length := 1000\n\tbigdata := make([]byte, max_length)\n\tfor i := 0; i < max_length; i++ {\n\t\tbigdata[i] = byte(i)\n\t}\n\tfor length := 0; length <= 1000; length++ {\n\t\tdata := bigdata[:length]\n\t\tvar d digest128\n\t\th1, h2, h3, h4 := d.sum256(data)\n\t\t//\n\t\ta1 := []byte{1} // to grab another bit of data\n\t\thasher := murmur3.New128()\n\t\thasher.Write(data) // #nosec\n\t\tv1, v2 := hasher.Sum128()\n\t\thasher.Write(a1) // #nosec\n\t\tv3, v4 := hasher.Sum128()\n\t\tif v1 != h1 || v2 != h2 || v3 != h3 || v4 != h4 {\n\t\t\tt.Errorf(\"Backward compatibillity break.\")\n\t\t}\n\t}\n}\n\nfunc TestDocumentation(t *testing.T) {\n\tfilter := NewWithEstimates(10000, 0.01)\n\tgot := EstimateFalsePositiveRate(filter.m, filter.k, 10000)\n\tif got > 0.011 || got < 0.009 {\n\t\tt.Errorf(\"Bad false positive rate %v\", got)\n\t}\n}\n\n// We want to preserve backward compatibility\nfunc TestHashRandom(t *testing.T) {\n\tmax_length := 1000\n\tbigdata := make([]byte, max_length)\n\tfor length := 0; length <= 1000; length++ {\n\t\tdata := bigdata[:length]\n\t\tfor trial := 1; trial < 10; trial++ {\n\t\t\trand.Read(data)\n\t\t\tvar d digest128\n\t\t\th1, h2, h3, h4 := d.sum256(data)\n\t\t\t//\n\t\t\ta1 := []byte{1} // to grab another bit of data\n\t\t\thasher := murmur3.New128()\n\t\t\thasher.Write(data) // #nosec\n\t\t\tv1, v2 := hasher.Sum128()\n\t\t\thasher.Write(a1) // #nosec\n\t\t\tv3, v4 := hasher.Sum128()\n\t\t\tif v1 != h1 || v2 != h2 || v3 != h3 || v4 != h4 {\n\t\t\t\tt.Errorf(\"Backward compatibillity break.\")\n\t\t\t}\n\t\t}\n\t}\n}\n"
        }
      ]
    }
  ]
}