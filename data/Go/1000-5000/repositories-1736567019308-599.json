{
  "metadata": {
    "timestamp": 1736567019308,
    "page": 599,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjYwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "prometheus-community/postgres_exporter",
      "stars": 2871,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.27734375,
          "content": "/.build\n/postgres_exporter\n/postgres_exporter_integration_test\n*.tar.gz\n*.test\n*-stamp\n/.idea\n/.vscode\n*.iml\n/cover.out\n/cover.*.out\n/.coverage\n/bin\n/release\n/*.prom\n/.metrics.*.*.prom\n/.metrics.*.*.prom.unique\n/.assets-branch\n/.metrics.*.added\n/.metrics.*.removed\n/tools/src\n/vendor\n"
        },
        {
          "name": ".golangci.yml",
          "type": "blob",
          "size": 0.439453125,
          "content": "---\nlinters:\n  enable:\n  - misspell\n  - revive\n\nissues:\n  exclude-rules:\n  - path: _test.go\n    linters:\n    - errcheck\n\nlinters-settings:\n  errcheck:\n    exclude-functions:\n      # Never check for logger errors.\n      - (github.com/go-kit/log.Logger).Log\n  revive:\n    rules:\n      # https://github.com/mgechev/revive/blob/master/RULES_DESCRIPTIONS.md#unused-parameter\n      - name: unused-parameter\n        severity: warning\n        disabled: true\n"
        },
        {
          "name": ".promu.yml",
          "type": "blob",
          "size": 0.6552734375,
          "content": "go:\n    # This must match .circle/config.yml.\n    version: 1.23\nrepository:\n    path: github.com/prometheus-community/postgres_exporter\nbuild:\n    binaries:\n        - name: postgres_exporter\n          path: ./cmd/postgres_exporter\n    ldflags: |\n        -X github.com/prometheus/common/version.Version={{.Version}}\n        -X github.com/prometheus/common/version.Revision={{.Revision}}\n        -X github.com/prometheus/common/version.Branch={{.Branch}}\n        -X github.com/prometheus/common/version.BuildUser={{user}}@{{host}}\n        -X github.com/prometheus/common/version.BuildDate={{date \"20060102-15:04:05\"}}\ntarball:\n    files:\n        - LICENSE\n        - NOTICE\n"
        },
        {
          "name": ".yamllint",
          "type": "blob",
          "size": 0.4521484375,
          "content": "---\nextends: default\nignore: |\n  **/node_modules\n\nrules:\n  braces:\n    max-spaces-inside: 1\n    level: error\n  brackets:\n    max-spaces-inside: 1\n    level: error\n  commas: disable\n  comments: disable\n  comments-indentation: disable\n  document-start: disable\n  indentation:\n    spaces: consistent\n    indent-sequences: consistent\n  key-duplicates:\n    ignore: |\n      config/testdata/section_key_dup.bad.yml\n  line-length: disable\n  truthy:\n    check-keys: false\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 12.3046875,
          "content": "## 0.16.0 / 2024-11-10\n\nBREAKING CHANGES:\n\nThe logging system has been replaced with log/slog from the stdlib. This change is being made across the prometheus ecosystem. The logging output has changed, but the messages and levels remain the same. The `ts` label for the timestamp has bewen replaced with `time`, the accuracy is less, and the timezone is not forced to UTC. The `caller` field has been replaced by the `source` field, which now includes the full path to the source file. The `level` field now exposes the log level in capital letters.\n\n* [CHANGE] Replace logging system #1073\n* [ENHANCEMENT] Add save_wal_size and wal_status to replication_slot collector #1027\n* [ENHANCEMENT] Add roles collector and connection limit metrics to database collector #997\n* [ENHANCEMENT] Excluded databases log messgae is now info level #1003\n* [ENHANCEMENT] Add active_time to stat_database collector #961\n* [ENHANCEMENT] Add slot_type label to replication_slot collector #960\n* [BUGFIX] Fix walreceiver collectore when no repmgr #1086\n* [BUGFIX] Remove logging errors on replicas #1048\n* [BUGFIX] Fix active_time query on postgres>=14 #1045\n\n## 0.15.0 / 2023-10-27\n\n* [ENHANCEMENT] Add 1kB and 2kB units #915\n* [BUGFIX] Add error log when probe collector creation fails #918\n* [BUGFIX] Fix test build failures on 32-bit arch #919\n* [BUGFIX] Adjust collector to use separate connection per scrape #936\n\n## 0.14.0 / 2023-09-11\n\n* [CHANGE] Add `state` label to pg_process_idle_seconds #862\n* [CHANGE] Change database connections to one per scrape #882 #902\n* [ENHANCEMENT] Add wal collector #858\n* [ENHANCEMENT] Add database_wraparound collector #834\n* [ENHANCEMENT] Add stat_activity_autovacuum collector #840\n* [ENHANCEMENT] Add stat_wal_receiver collector #844\n* [ENHANCEMENT] Add xlog_location collector #849\n* [ENHANCEMENT] Add statio_user_indexes collector #845\n* [ENHANCEMENT] Add long_running_transactions collector #836\n* [ENHANCEMENT] Add pg_stat_user_tables_size_bytes metric #904\n* [BUGFIX] Fix tests on 32-bit systems #857\n* [BUGFIX] Fix pg_stat_statements metrics on Postgres 13+ #874 #876\n* [BUGFIX] Fix pg_stat_database metrics for NULL stats_reset #877\n* [BUGFIX] Fix pg_replication_lag_seconds on Postgres 10+ when master is idle #895\n\n## 0.13.2 / 2023-07-21\n\n* [BUGFIX] Fix type issues on pg_postmaster metrics #828\n* [BUGFIX] Fix pg_replication collector instantiation #854\n* [BUGFIX] Fix pg_process_idle metrics #855\n\n## 0.13.1 / 2023-06-27\n\n* [BUGFIX] Make collectors not fail on null values #823\n\n## 0.13.0 / 2023-06-21\n\nBREAKING CHANGES:\n\nPlease note, the following features are deprecated and may be removed in a future release:\n- `auto-discover-databases`\n- `extend.query-path`\n- `constantLabels`\n- `exclude-databases`\n- `include-databases`\n\nThis exporter is meant to monitor PostgresSQL servers, not the user data/databases. If\nyou need a generic SQL report exporter https://github.com/burningalchemist/sql_exporter\nis recommended.\n\n* [CHANGE] Adjust log level for collector startup #784\n* [CHANGE] Move queries from queries.yaml to collectors #801\n* [CHANGE] Deprecate extend queries feature #811\n* [CHANGE] Deprecate additional database features #815\n* [CHANGE] Convert pg_stat_database to new collector #685\n* [ENHANCEMENT] Supports alternate postgres:// prefix in URLs #787\n* [BUGFIX] Fix pg_setting different help values #771\n* [BUGFIX] Fix column type for pg_replication_slots #777\n* [BUGFIX] Fix pg_stat_database collector #809\n\n## 0.12.1 / 2023-06-12\n* [BUGFIX] Fix column type for pg_replication_slots #777\n\n## 0.12.0 / 2023-03-21\n\nBREAKING CHANGES:\n\nThis release changes support for multiple postgres servers to use the\nmulti-target exporter pattern. This makes it much easier to monitor multiple\nPostgreSQL servers from a single exporter by passing the target via URL\nparams. See the Multi-Target Support section of the README.\n\n* [CHANGE] Add multi-target support #618\n* [CHANGE] Add usename and application_name to pg_stat_activity metrics #673\n* [FEATURE] Add replication metrics from pg_replication_slots #747\n* [BUGFIX] Add dsn type for handling datasources #678\n* [BUGFIX] Add 64kB unit for postgres 15 #740\n* [BUGFIX] Add 4kB unit for postgres compiled with small blocks #699\n\n## 0.11.1 / 2022-08-01\n\n* [BUGFIX] Fix checkpoint_write_time value type #666\n* [BUGFIX] Fix checkpoint_sync_time value type #667\n\n## 0.11.0 / 2022-07-28\n\nNOTE: pg_stat_bgwriter counter metrics had the `_total` suffix added #556\n\n* [CHANGE] refactor pg_stat_bgwriter metrics into standalone collector #556\n* [FEATURE] Add pg_database collector #613\n* [ENHANCEMENT] Add pg_database_size_bytes metric #613\n* [BUGFIX] Avoid parsing error from bogus Azure Flexible Server custom GUC #587\n* [BUGFIX] Fix pg_stat_archiver error in 9.4 and earlier. #599\n* [BUGFIX] Sanitize setting values because of Aurora irregularity #620\n\n## 0.10.1 / 2022-01-14\n\n* [BUGFIX] Fix broken log-level for values other than debug. #560\n\n## 0.10.0 / 2021-07-08\n\n* [ENHANCEMENT] Add ability to set included databases when autoDiscoverDatabases is enabled #499\n* [BUGFIX] fix pg_replication_slots on postgresql versions 9.4 <> 10.0 #537\n\n## 0.9.0 / 2021-03-01\n\nFirst release under the Prometheus Community organisation.\n\n* [CHANGE] Update build to use standard Prometheus promu/Dockerfile\n* [ENHANCEMENT] Remove duplicate column in queries.yml #433\n* [ENHANCEMENT] Add query for 'pg_replication_slots' #465\n* [ENHANCEMENT] Allow a custom prefix for metric namespace #387\n* [ENHANCEMENT] Improve PostgreSQL replication lag detection #395\n* [ENHANCEMENT] Support connstring syntax when discovering databases #473\n* [ENHANCEMENT] Detect SIReadLock locks in the pg_locks metric #421\n* [BUGFIX] Fix pg_database_size_bytes metric in queries.yaml #357\n* [BUGFIX] Don't ignore errors in parseUserQueries #362\n* [BUGFIX] Fix queries.yaml for AWS RDS #370\n* [BUGFIX] Recover when connection cannot be established at startup #415\n* [BUGFIX] Don't retry if an error occurs #426\n* [BUGFIX] Do not panic on incorrect env #457\n\n## 0.8.0 / 2019-11-25\n\n* Add a build info metric (#323)\n* Re-add pg_stat_bgwriter metrics which were accidentally removed in the previous version. (resolves #336)\n* Export pg_stat_archiver metrics (#324)\n* Add support for 'DATA_SOURCE_URI_FILE' envvar.\n* Resolve #329\n* Added new field \"master\" to queries.yaml. (credit to @sfalkon)\n  - If \"master\" is true, query will be call only on once database in instance\n* Change queries.yaml for work with autoDiscoveryDatabases options (credit to @sfalkon)\n  - added current database name to metrics because any database in cluster maybe have the same table names\n  - added \"master\" field for query instance metrics.\n\n## 0.7.0 / 2019-11-01\n\nIntroduces some more significant changes, hence the minor version bump in\nsuch a short time frame.\n\n* Rename pg_database_size to pg_database_size_bytes in queries.yml.\n* Add pg_stat_statements to sample queries.yml file.\n* Add support for optional namespace caching. (#319)\n* Fix some autodiscovery problems (#314) (resolves #308)\n* Yaml parsing refactor (#299)\n* Don't stop generating fingerprint while encountering value with \"=\" sign (#318)\n  (may resolve problems with passwords and special characters).\n\n## 0.6.0 / 2019-10-30\n\n* Add SQL for grant connect (#303)\n* Expose pg_current_wal_lsn_bytes (#307)\n* [minor] fix landing page content-type (#305)\n* Updated lib/pg driver to 1.2.0 in order to support stronger SCRAM-SHA-256 authentication. This drops support for Go < 1.11 and PostgreSQL < 9.4. (#304)\n* Provide more helpful default values for tables that have never been vacuumed (#310)\n* Add retries to getServer() (#316)\n* Fix pg_up metric returns last calculated value without explicit resetting (#291)\n* Discover only databases that are not templates and allow connections (#297)\n* Add --exclude-databases option (#298)\n\n## 0.5.1 / 2019-07-09\n\n* Add application_name as a label for pg_stat_replication metrics (#285).\n\n## 0.5.0 / 2019-07-03\n\nIt's been far too long since I've done a release and we have a lot of accumulated changes.\n\n* Docker image now runs as a non-root user named \"postgres_exporter\"\n* Add `--auto-discover-databases` option, which automatically discovers and scrapes all databases.\n* Add support for boolean data types as metrics\n* Replication lag is now expressed as a float and not truncated to an integer.\n* When default metrics are disabled, no version metrics are collected anymore either.\n* BUGFIX: Fix exporter panic when postgres server goes down.\n* Add support for collecting metrics from multiple servers.\n* PostgreSQL 11 is now supported in the integration tests.\n\n## 0.4.7 / 2018-10-02\n\n* Added a query for v9.1 pg_stat_activity.\n* Add `--constantLabels` flag to allow applying fixed constant labels to metrics.\n* queries.yml: dd pg_statio_user_tables.\n* Support 'B' suffix in units.\n\n## 0.4.6 / 2018-04-15\n\n* Fix issue #173 - 32 and 64mb unit sizes were not supported in pg_settings.\n\n## 0.4.5 / 2018-02-27\n\n* Add commandline flag to disable default metrics (thanks @hsun-cnnxty)\n\n## 0.4.4 / 2018-03-21\n\n* Bugfix for 0.4.3 which broke pg_up (it would always be 0).\n* pg_up is now refreshed based on database Ping() every scrape.\n* Re-release of 0.4.4 to fix version numbering.\n\n## 0.4.2 / 2018-02-19\n\n* Adds the following environment variables for overriding defaults:\n    * `PG_EXPORTER_WEB_LISTEN_ADDRESS`\n    * `PG_EXPORTER_WEB_TELEMETRY_PATH`\n    * `PG_EXPORTER_EXTEND_QUERY_PATH`\n\n* Add Content-Type to HTTP landing page.\n* Fix Makefile to produce .exe binaries for Windows.\n\n## 0.4.1 / 2017-11-30\n\n* No code changes to v0.4.0 for the exporter.\n* First release switching to tar-file based distribution.\n* First release with Windows and Darwin cross-builds.\\\\\n\n## 0.4.0 / 2017-11-29\n\n* Fix panic due to inconsistent label cardinality when using queries.yaml with\n  queries which return extra columns.\n* Add metric for whether the user queries YAML file parsed correctly. This also\n  includes the filename and SHA256 sum allowing tracking of updates.\n* Add pg_up metric to indicate whether the exporter was able to connect and\n  Ping() the PG instance before a scrape.\n* Fix broken link in landing page for `/metrics`\n\n## 0.3.0 / 2017-10-23\n\n* Add support for PostgreSQL 10.\n\n## 0.2.3 / 2017-09-07\n\n* Add support for the 16kB unit when decoding pg_settings. (#101)\n\n## 0.2.2 / 2017-08-04\n\n* Fix DSN logging. The exporter previously never actually logged the DSN when\n  database connections failed. This was also masking a logic error which could\n  potentially lead to a crash when DSN was unparseable, though no actual\n  crash could be produced in testing.\n\n## 0.2.1 / 2017-06-07\n\n* Ignore functions that cannot be executed during replication recovery (#52)\n* Add a `-version` flag finally.\n* Add confirmed_flush_lsn to pg_stat_replication.\n\n## 0.2.0 / 2017-04-18\n\n* Major change - use pg_settings to retrieve runtime variables. Adds >180\n  new metrics and descriptions (big thanks to Matt Bostock for this work).\n\n  Removes the following metrics:\n  ```\n  pg_runtime_variable_max_connections\n  pg_runtime_variable_max_files_per_process\n  pg_runtime_variable_max_function_args\n  pg_runtime_variable_max_identifier_length\n  pg_runtime_variable_max_index_keys\n  pg_runtime_variable_max_locks_per_transaction\n  pg_runtime_variable_max_pred_locks_per_transaction\n  pg_runtime_variable_max_prepared_transactions\n  pg_runtime_variable_max_standby_archive_delay_milliseconds\n  pg_runtime_variable_max_standby_streaming_delay_milliseconds\n  pg_runtime_variable_max_wal_senders\n  ```\n\n  They are replaced by equivalent names under `pg_settings` with the exception of\n  ```\n  pg_runtime_variable_max_standby_archive_delay_milliseconds\n  pg_runtime_variable_max_standby_streaming_delay_milliseconds\n  ```\n  which are replaced with\n  ```\n  pg_settings_max_standby_archive_delay_seconds\n  pg_settings_max_standby_streaming_delay_seconds\n  ```\n\n## 0.1.3 / 2017-02-21\n\n* Update the Go build to 1.7.5 to include a fix for NAT handling.\n* Fix passwords leaking in DB url error message on connection failure.\n\n## 0.1.2 / 2017-02-07\n\n* Use a connection pool of size 1 to reduce memory churn on target database.\n\n## 0.1.1 / 2016-11-29\n\n* Fix pg_stat_replication metrics not being collected due to semantic version\n  filter problem.\n\n## 0.1.0 / 2016-11-21\n\n* Change default port to 9187.\n* Fix regressions with pg_stat_replication on older versions of Postgres.\n* Add pg_static metric to store version strings as labels.\n* Much more thorough testing structure.\n* Move to semantic versioning for releases and docker image publications.\n\n## 0.0.1 / 2016-06-03\n\nInitial release for publication.\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 0.1484375,
          "content": "# Prometheus Community Code of Conduct\n\nPrometheus follows the [CNCF Code of Conduct](https://github.com/cncf/foundation/blob/main/code-of-conduct.md).\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.3349609375,
          "content": "ARG ARCH=\"amd64\"\nARG OS=\"linux\"\nFROM quay.io/prometheus/busybox-${OS}-${ARCH}:latest\nLABEL maintainer=\"The Prometheus Authors <prometheus-developers@googlegroups.com>\"\n\nARG ARCH=\"amd64\"\nARG OS=\"linux\"\nCOPY .build/${OS}-${ARCH}/postgres_exporter /bin/postgres_exporter\n\nEXPOSE     9187\nUSER       nobody\nENTRYPOINT [ \"/bin/postgres_exporter\" ]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MAINTAINERS.md",
          "type": "blob",
          "size": 0.13671875,
          "content": "* Ben Kochie <superq@gmail.com> @SuperQ\n* William Rouesnel <wrouesnel@wrouesnel.com> @wrouesnel\n* Joe Adams <github@joeadams.io> @sysadmind\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.330078125,
          "content": "# Ensure that 'all' is the default target otherwise it will be the first target from Makefile.common.\nall::\n\n# Needs to be defined before including Makefile.common to auto-generate targets\nDOCKER_ARCHS ?= amd64 armv7 arm64 ppc64le\nDOCKER_REPO  ?= prometheuscommunity\n\ninclude Makefile.common\n\nDOCKER_IMAGE_NAME       ?= postgres-exporter\n"
        },
        {
          "name": "Makefile.common",
          "type": "blob",
          "size": 9.1123046875,
          "content": "# Copyright 2018 The Prometheus Authors\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\n# A common Makefile that includes rules to be reused in different prometheus projects.\n# !!! Open PRs only against the prometheus/prometheus/Makefile.common repository!\n\n# Example usage :\n# Create the main Makefile in the root project directory.\n# include Makefile.common\n# customTarget:\n# \t@echo \">> Running customTarget\"\n#\n\n# Ensure GOBIN is not set during build so that promu is installed to the correct path\nunexport GOBIN\n\nGO           ?= go\nGOFMT        ?= $(GO)fmt\nFIRST_GOPATH := $(firstword $(subst :, ,$(shell $(GO) env GOPATH)))\nGOOPTS       ?=\nGOHOSTOS     ?= $(shell $(GO) env GOHOSTOS)\nGOHOSTARCH   ?= $(shell $(GO) env GOHOSTARCH)\n\nGO_VERSION        ?= $(shell $(GO) version)\nGO_VERSION_NUMBER ?= $(word 3, $(GO_VERSION))\nPRE_GO_111        ?= $(shell echo $(GO_VERSION_NUMBER) | grep -E 'go1\\.(10|[0-9])\\.')\n\nPROMU        := $(FIRST_GOPATH)/bin/promu\npkgs          = ./...\n\nifeq (arm, $(GOHOSTARCH))\n\tGOHOSTARM ?= $(shell GOARM= $(GO) env GOARM)\n\tGO_BUILD_PLATFORM ?= $(GOHOSTOS)-$(GOHOSTARCH)v$(GOHOSTARM)\nelse\n\tGO_BUILD_PLATFORM ?= $(GOHOSTOS)-$(GOHOSTARCH)\nendif\n\nGOTEST := $(GO) test\nGOTEST_DIR :=\nifneq ($(CIRCLE_JOB),)\nifneq ($(shell command -v gotestsum 2> /dev/null),)\n\tGOTEST_DIR := test-results\n\tGOTEST := gotestsum --junitfile $(GOTEST_DIR)/unit-tests.xml --\nendif\nendif\n\nPROMU_VERSION ?= 0.17.0\nPROMU_URL     := https://github.com/prometheus/promu/releases/download/v$(PROMU_VERSION)/promu-$(PROMU_VERSION).$(GO_BUILD_PLATFORM).tar.gz\n\nSKIP_GOLANGCI_LINT :=\nGOLANGCI_LINT :=\nGOLANGCI_LINT_OPTS ?=\nGOLANGCI_LINT_VERSION ?= v1.62.0\n# golangci-lint only supports linux, darwin and windows platforms on i386/amd64/arm64.\n# windows isn't included here because of the path separator being different.\nifeq ($(GOHOSTOS),$(filter $(GOHOSTOS),linux darwin))\n\tifeq ($(GOHOSTARCH),$(filter $(GOHOSTARCH),amd64 i386 arm64))\n\t\t# If we're in CI and there is an Actions file, that means the linter\n\t\t# is being run in Actions, so we don't need to run it here.\n\t\tifneq (,$(SKIP_GOLANGCI_LINT))\n\t\t\tGOLANGCI_LINT :=\n\t\telse ifeq (,$(CIRCLE_JOB))\n\t\t\tGOLANGCI_LINT := $(FIRST_GOPATH)/bin/golangci-lint\n\t\telse ifeq (,$(wildcard .github/workflows/golangci-lint.yml))\n\t\t\tGOLANGCI_LINT := $(FIRST_GOPATH)/bin/golangci-lint\n\t\tendif\n\tendif\nendif\n\nPREFIX                  ?= $(shell pwd)\nBIN_DIR                 ?= $(shell pwd)\nDOCKER_IMAGE_TAG        ?= $(subst /,-,$(shell git rev-parse --abbrev-ref HEAD))\nDOCKERFILE_PATH         ?= ./Dockerfile\nDOCKERBUILD_CONTEXT     ?= ./\nDOCKER_REPO             ?= prom\n\nDOCKER_ARCHS            ?= amd64\n\nBUILD_DOCKER_ARCHS = $(addprefix common-docker-,$(DOCKER_ARCHS))\nPUBLISH_DOCKER_ARCHS = $(addprefix common-docker-publish-,$(DOCKER_ARCHS))\nTAG_DOCKER_ARCHS = $(addprefix common-docker-tag-latest-,$(DOCKER_ARCHS))\n\nSANITIZED_DOCKER_IMAGE_TAG := $(subst +,-,$(DOCKER_IMAGE_TAG))\n\nifeq ($(GOHOSTARCH),amd64)\n        ifeq ($(GOHOSTOS),$(filter $(GOHOSTOS),linux freebsd darwin windows))\n                # Only supported on amd64\n                test-flags := -race\n        endif\nendif\n\n# This rule is used to forward a target like \"build\" to \"common-build\".  This\n# allows a new \"build\" target to be defined in a Makefile which includes this\n# one and override \"common-build\" without override warnings.\n%: common-% ;\n\n.PHONY: common-all\ncommon-all: precheck style check_license lint yamllint unused build test\n\n.PHONY: common-style\ncommon-style:\n\t@echo \">> checking code style\"\n\t@fmtRes=$$($(GOFMT) -d $$(find . -path ./vendor -prune -o -name '*.go' -print)); \\\n\tif [ -n \"$${fmtRes}\" ]; then \\\n\t\techo \"gofmt checking failed!\"; echo \"$${fmtRes}\"; echo; \\\n\t\techo \"Please ensure you are using $$($(GO) version) for formatting code.\"; \\\n\t\texit 1; \\\n\tfi\n\n.PHONY: common-check_license\ncommon-check_license:\n\t@echo \">> checking license header\"\n\t@licRes=$$(for file in $$(find . -type f -iname '*.go' ! -path './vendor/*') ; do \\\n               awk 'NR<=3' $$file | grep -Eq \"(Copyright|generated|GENERATED)\" || echo $$file; \\\n       done); \\\n       if [ -n \"$${licRes}\" ]; then \\\n               echo \"license header checking failed:\"; echo \"$${licRes}\"; \\\n               exit 1; \\\n       fi\n\n.PHONY: common-deps\ncommon-deps:\n\t@echo \">> getting dependencies\"\n\t$(GO) mod download\n\n.PHONY: update-go-deps\nupdate-go-deps:\n\t@echo \">> updating Go dependencies\"\n\t@for m in $$($(GO) list -mod=readonly -m -f '{{ if and (not .Indirect) (not .Main)}}{{.Path}}{{end}}' all); do \\\n\t\t$(GO) get -d $$m; \\\n\tdone\n\t$(GO) mod tidy\n\n.PHONY: common-test-short\ncommon-test-short: $(GOTEST_DIR)\n\t@echo \">> running short tests\"\n\t$(GOTEST) -short $(GOOPTS) $(pkgs)\n\n.PHONY: common-test\ncommon-test: $(GOTEST_DIR)\n\t@echo \">> running all tests\"\n\t$(GOTEST) $(test-flags) $(GOOPTS) $(pkgs)\n\n$(GOTEST_DIR):\n\t@mkdir -p $@\n\n.PHONY: common-format\ncommon-format:\n\t@echo \">> formatting code\"\n\t$(GO) fmt $(pkgs)\n\n.PHONY: common-vet\ncommon-vet:\n\t@echo \">> vetting code\"\n\t$(GO) vet $(GOOPTS) $(pkgs)\n\n.PHONY: common-lint\ncommon-lint: $(GOLANGCI_LINT)\nifdef GOLANGCI_LINT\n\t@echo \">> running golangci-lint\"\n\t$(GOLANGCI_LINT) run $(GOLANGCI_LINT_OPTS) $(pkgs)\nendif\n\n.PHONY: common-lint-fix\ncommon-lint-fix: $(GOLANGCI_LINT)\nifdef GOLANGCI_LINT\n\t@echo \">> running golangci-lint fix\"\n\t$(GOLANGCI_LINT) run --fix $(GOLANGCI_LINT_OPTS) $(pkgs)\nendif\n\n.PHONY: common-yamllint\ncommon-yamllint:\n\t@echo \">> running yamllint on all YAML files in the repository\"\nifeq (, $(shell command -v yamllint 2> /dev/null))\n\t@echo \"yamllint not installed so skipping\"\nelse\n\tyamllint .\nendif\n\n# For backward-compatibility.\n.PHONY: common-staticcheck\ncommon-staticcheck: lint\n\n.PHONY: common-unused\ncommon-unused:\n\t@echo \">> running check for unused/missing packages in go.mod\"\n\t$(GO) mod tidy\n\t@git diff --exit-code -- go.sum go.mod\n\n.PHONY: common-build\ncommon-build: promu\n\t@echo \">> building binaries\"\n\t$(PROMU) build --prefix $(PREFIX) $(PROMU_BINARIES)\n\n.PHONY: common-tarball\ncommon-tarball: promu\n\t@echo \">> building release tarball\"\n\t$(PROMU) tarball --prefix $(PREFIX) $(BIN_DIR)\n\n.PHONY: common-docker-repo-name\ncommon-docker-repo-name:\n\t@echo \"$(DOCKER_REPO)/$(DOCKER_IMAGE_NAME)\"\n\n.PHONY: common-docker $(BUILD_DOCKER_ARCHS)\ncommon-docker: $(BUILD_DOCKER_ARCHS)\n$(BUILD_DOCKER_ARCHS): common-docker-%:\n\tdocker build -t \"$(DOCKER_REPO)/$(DOCKER_IMAGE_NAME)-linux-$*:$(SANITIZED_DOCKER_IMAGE_TAG)\" \\\n\t\t-f $(DOCKERFILE_PATH) \\\n\t\t--build-arg ARCH=\"$*\" \\\n\t\t--build-arg OS=\"linux\" \\\n\t\t$(DOCKERBUILD_CONTEXT)\n\n.PHONY: common-docker-publish $(PUBLISH_DOCKER_ARCHS)\ncommon-docker-publish: $(PUBLISH_DOCKER_ARCHS)\n$(PUBLISH_DOCKER_ARCHS): common-docker-publish-%:\n\tdocker push \"$(DOCKER_REPO)/$(DOCKER_IMAGE_NAME)-linux-$*:$(SANITIZED_DOCKER_IMAGE_TAG)\"\n\nDOCKER_MAJOR_VERSION_TAG = $(firstword $(subst ., ,$(shell cat VERSION)))\n.PHONY: common-docker-tag-latest $(TAG_DOCKER_ARCHS)\ncommon-docker-tag-latest: $(TAG_DOCKER_ARCHS)\n$(TAG_DOCKER_ARCHS): common-docker-tag-latest-%:\n\tdocker tag \"$(DOCKER_REPO)/$(DOCKER_IMAGE_NAME)-linux-$*:$(SANITIZED_DOCKER_IMAGE_TAG)\" \"$(DOCKER_REPO)/$(DOCKER_IMAGE_NAME)-linux-$*:latest\"\n\tdocker tag \"$(DOCKER_REPO)/$(DOCKER_IMAGE_NAME)-linux-$*:$(SANITIZED_DOCKER_IMAGE_TAG)\" \"$(DOCKER_REPO)/$(DOCKER_IMAGE_NAME)-linux-$*:v$(DOCKER_MAJOR_VERSION_TAG)\"\n\n.PHONY: common-docker-manifest\ncommon-docker-manifest:\n\tDOCKER_CLI_EXPERIMENTAL=enabled docker manifest create -a \"$(DOCKER_REPO)/$(DOCKER_IMAGE_NAME):$(SANITIZED_DOCKER_IMAGE_TAG)\" $(foreach ARCH,$(DOCKER_ARCHS),$(DOCKER_REPO)/$(DOCKER_IMAGE_NAME)-linux-$(ARCH):$(SANITIZED_DOCKER_IMAGE_TAG))\n\tDOCKER_CLI_EXPERIMENTAL=enabled docker manifest push \"$(DOCKER_REPO)/$(DOCKER_IMAGE_NAME):$(SANITIZED_DOCKER_IMAGE_TAG)\"\n\n.PHONY: promu\npromu: $(PROMU)\n\n$(PROMU):\n\t$(eval PROMU_TMP := $(shell mktemp -d))\n\tcurl -s -L $(PROMU_URL) | tar -xvzf - -C $(PROMU_TMP)\n\tmkdir -p $(FIRST_GOPATH)/bin\n\tcp $(PROMU_TMP)/promu-$(PROMU_VERSION).$(GO_BUILD_PLATFORM)/promu $(FIRST_GOPATH)/bin/promu\n\trm -r $(PROMU_TMP)\n\n.PHONY: proto\nproto:\n\t@echo \">> generating code from proto files\"\n\t@./scripts/genproto.sh\n\nifdef GOLANGCI_LINT\n$(GOLANGCI_LINT):\n\tmkdir -p $(FIRST_GOPATH)/bin\n\tcurl -sfL https://raw.githubusercontent.com/golangci/golangci-lint/$(GOLANGCI_LINT_VERSION)/install.sh \\\n\t\t| sed -e '/install -d/d' \\\n\t\t| sh -s -- -b $(FIRST_GOPATH)/bin $(GOLANGCI_LINT_VERSION)\nendif\n\n.PHONY: precheck\nprecheck::\n\ndefine PRECHECK_COMMAND_template =\nprecheck:: $(1)_precheck\n\nPRECHECK_COMMAND_$(1) ?= $(1) $$(strip $$(PRECHECK_OPTIONS_$(1)))\n.PHONY: $(1)_precheck\n$(1)_precheck:\n\t@if ! $$(PRECHECK_COMMAND_$(1)) 1>/dev/null 2>&1; then \\\n\t\techo \"Execution of '$$(PRECHECK_COMMAND_$(1))' command failed. Is $(1) installed?\"; \\\n\t\texit 1; \\\n\tfi\nendef\n\ngovulncheck: install-govulncheck\n\tgovulncheck ./...\n\ninstall-govulncheck:\n\tcommand -v govulncheck > /dev/null || go install golang.org/x/vuln/cmd/govulncheck@latest\n"
        },
        {
          "name": "NOTICE",
          "type": "blob",
          "size": 0.068359375,
          "content": "Copyright 2018 William Rouesnel\nCopyright 2021 The Prometheus Authors\n"
        },
        {
          "name": "README-RDS.md",
          "type": "blob",
          "size": 1.556640625,
          "content": "# Using Postgres-Exporter with AWS:RDS\n\n### When using postgres-exporter with Amazon Web Services' RDS, the\n  rolname \"rdsadmin\" and datname \"rdsadmin\" must be excluded.\n\nI had success running docker container 'quay.io/prometheuscommunity/postgres-exporter:latest'\nwith queries.yaml as the PG_EXPORTER_EXTEND_QUERY_PATH.  errors\nmentioned in issue#335 appeared and I had to modify the\n'pg_stat_statements' query with the following:\n`WHERE t2.rolname != 'rdsadmin'`\n\nRunning postgres-exporter in a container like so:\n  ```\n  DBNAME='postgres'\n  PGUSER='postgres'\n  PGPASS='psqlpasswd123'\n  PGHOST='name.blahblah.us-east-1.rds.amazonaws.com'\n  docker run --rm --detach \\\n      --name \"postgresql_exporter_rds\" \\\n      --publish 9187:9187 \\\n      --volume=/etc/prometheus/postgresql-exporter/queries.yaml:/var/lib/postgresql/queries.yaml \\\n      -e DATA_SOURCE_NAME=\"postgresql://${PGUSER}:${PGPASS}@${PGHOST}:5432/${DBNAME}?sslmode=disable\" \\\n      -e PG_EXPORTER_EXCLUDE_DATABASES=rdsadmin \\\n      -e PG_EXPORTER_DISABLE_DEFAULT_METRICS=true \\\n      -e PG_EXPORTER_DISABLE_SETTINGS_METRICS=true \\\n      -e PG_EXPORTER_EXTEND_QUERY_PATH='/var/lib/postgresql/queries.yaml' \\\n      quay.io/prometheuscommunity/postgres-exporter\n  ```\n\n### Expected changes to RDS:\n+ see stackoverflow notes\n  (https://stackoverflow.com/questions/43926499/amazon-postgres-rds-pg-stat-statements-not-loaded#43931885)\n+ you must also use a specific RDS parameter_group that includes the following:\n  ```\n  shared_preload_libraries = \"pg_stat_statements,pg_hint_plan\"\n  ```\n+ lastly, you must reboot the RDS instance.\n\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 17.029296875,
          "content": "[![Build Status](https://circleci.com/gh/prometheus-community/postgres_exporter.svg?style=svg)](https://circleci.com/gh/prometheus-community/postgres_exporter)\n[![Coverage Status](https://coveralls.io/repos/github/prometheus-community/postgres_exporter/badge.svg?branch=master)](https://coveralls.io/github/prometheus-community/postgres_exporter?branch=master)\n[![Go Report Card](https://goreportcard.com/badge/github.com/prometheus-community/postgres_exporter)](https://goreportcard.com/report/github.com/prometheus-community/postgres_exporter)\n[![Docker Pulls](https://img.shields.io/docker/pulls/prometheuscommunity/postgres-exporter.svg)](https://hub.docker.com/r/prometheuscommunity/postgres-exporter/tags)\n\n# PostgreSQL Server Exporter\n\nPrometheus exporter for PostgreSQL server metrics.\n\nCI Tested PostgreSQL versions: `11`, `12`, `13`, `14`, `15`, `16`\n\n## Quick Start\nThis package is available for Docker:\n```\n# Start an example database\ndocker run --net=host -it --rm -e POSTGRES_PASSWORD=password postgres\n# Connect to it\ndocker run \\\n  --net=host \\\n  -e DATA_SOURCE_URI=\"localhost:5432/postgres?sslmode=disable\" \\\n  -e DATA_SOURCE_USER=postgres \\\n  -e DATA_SOURCE_PASS=password \\\n  quay.io/prometheuscommunity/postgres-exporter\n```\n\nTest with:\n```bash\ncurl \"http://localhost:9187/metrics\"\n```\n\nExample Prometheus config:\n```yaml\nscrape_configs:\n  - job_name: postgres\n    static_configs:\n      - targets: [\"127.0.0.1:9187\"] # Replace IP with the hostname of the docker container if you're running the container in a separate network\n```\n\nNow use the DATA_SOURCE_PASS_FILE with a mounted file containing the password to prevent having the password in an environment variable.\n\nThe container process runs with uid/gid 65534 (important for file permissions).\n\n## Multi-Target Support (BETA)\n**This Feature is in beta and may require changes in future releases. Feedback is welcome.**\n\nThis exporter supports the [multi-target pattern](https://prometheus.io/docs/guides/multi-target-exporter/). This allows running a single instance of this exporter for multiple postgres targets. Using the multi-target functionality of this exporter is **optional** and meant for cases where it is impossible to install the exporter as a sidecar, for example SaaS-managed services.\n\nTo use the multi-target functionality, send an http request to the endpoint `/probe?target=foo:5432` where target is set to the DSN of the postgres instance to scrape metrics from.\n\nTo avoid putting sensitive information like username and password in the URL, preconfigured auth modules are supported via the [auth_modules](#auth_modules) section of the config file. auth_modules for DSNs can be used with the `/probe` endpoint by specifying the `?auth_module=foo` http parameter.\n\nExample Prometheus config:\n```yaml\nscrape_configs:\n  - job_name: 'postgres'\n    static_configs:\n      - targets:\n        - server1:5432\n        - server2:5432\n    metrics_path: /probe\n    params:\n      auth_module: [foo]\n    relabel_configs:\n      - source_labels: [__address__]\n        target_label: __param_target\n      - source_labels: [__param_target]\n        target_label: instance\n      - target_label: __address__\n        replacement: 127.0.0.1:9116  # The postgres exporter's real hostname:port.\n```\n\n## Configuration File\n\nThe configuration file controls the behavior of the exporter. It can be set using the `--config.file` command line flag and defaults to `postgres_exporter.yml`.\n\n### auth_modules\nThis section defines preset authentication and connection parameters for use in the [multi-target endpoint](#multi-target-support-beta). `auth_modules` is a map of modules with the key being the identifier which can be used in the `/probe` endpoint.\nCurrently only the `userpass` type is supported.\n\nExample:\n```yaml\nauth_modules:\n  foo1: # Set this to any name you want\n    type: userpass\n    userpass:\n      username: first\n      password: firstpass\n    options:\n      # options become key=value parameters of the DSN\n      sslmode: disable\n```\n\n## Building and running\n\n    git clone https://github.com/prometheus-community/postgres_exporter.git\n    cd postgres_exporter\n    make build\n    ./postgres_exporter <flags>\n\nTo build the Docker image:\n\n    make promu\n    promu crossbuild -p linux/amd64 -p linux/armv7 -p linux/arm64 -p linux/ppc64le\n    make docker\n\nThis will build the docker image as `prometheuscommunity/postgres_exporter:${branch}`.\n\n### Flags\n\n* `help`\n  Show context-sensitive help (also try --help-long and --help-man).\n\n\n* `[no-]collector.database`\n  Enable the `database` collector (default: enabled).\n\n* `[no-]collector.database_wraparound`\n  Enable the `database_wraparound` collector (default: disabled).\n\n* `[no-]collector.locks`\n  Enable the `locks` collector (default: enabled).\n\n* `[no-]collector.long_running_transactions`\n  Enable the `long_running_transactions` collector (default: disabled).\n\n* `[no-]collector.postmaster`\n   Enable the `postmaster` collector (default: disabled).\n\n* `[no-]collector.process_idle`\n  Enable the `process_idle` collector (default: disabled).\n\n* `[no-]collector.replication`\n  Enable the `replication` collector (default: enabled).\n\n* `[no-]collector.replication_slot`\n  Enable the `replication_slot` collector (default: enabled).\n\n* `[no-]collector.stat_activity_autovacuum`\n  Enable the `stat_activity_autovacuum` collector (default: disabled).\n\n* `[no-]collector.stat_bgwriter`\n  Enable the `stat_bgwriter` collector (default: enabled).\n\n* `[no-]collector.stat_database`\n  Enable the `stat_database` collector (default: enabled).\n\n* `[no-]collector.stat_statements`\n  Enable the `stat_statements` collector (default: disabled).\n\n* `[no-]collector.stat_user_tables`\n  Enable the `stat_user_tables` collector (default: enabled).\n\n* `[no-]collector.stat_wal_receiver`\n  Enable the `stat_wal_receiver` collector (default: disabled).\n\n* `[no-]collector.statio_user_indexes`\n  Enable the `statio_user_indexes` collector (default: disabled).\n\n* `[no-]collector.statio_user_tables`\n  Enable the `statio_user_tables` collector (default: enabled).\n\n* `[no-]collector.wal`\n  Enable the `wal` collector (default: enabled).\n\n* `[no-]collector.xlog_location`\n  Enable the `xlog_location` collector (default: disabled).\n\n* `config.file`\n  Set the config file path. Default is `postgres_exporter.yml`\n\n* `web.systemd-socket`\n  Use systemd socket activation listeners instead of port listeners (Linux only). Default is `false`\n\n* `web.listen-address`\n  Address to listen on for web interface and telemetry. Default is `:9187`.\n\n* `web.config.file`\n  Configuration file to use TLS and/or basic authentication. The format of the\n  file is described [in the exporter-toolkit repository](https://github.com/prometheus/exporter-toolkit/blob/master/docs/web-configuration.md).\n\n* `web.telemetry-path`\n  Path under which to expose metrics. Default is `/metrics`.\n\n* `disable-default-metrics`\n  Use only metrics supplied from `queries.yaml` via `--extend.query-path`.  Default is `false`.\n\n* `disable-settings-metrics`\n  Use the flag if you don't want to scrape `pg_settings`.  Default is `false`.\n\n* `auto-discover-databases` (DEPRECATED)\n  Whether to discover the databases on a server dynamically.  Default is `false`.\n\n* `extend.query-path` (DEPRECATED)\n  Path to a YAML file containing custom queries to run. Check out [`queries.yaml`](queries.yaml)\n  for examples of the format.\n\n* `dumpmaps`\n  Do not run - print the internal representation of the metric maps. Useful when debugging a custom\n  queries file.\n\n* `constantLabels` (DEPRECATED)\n  Labels to set in all metrics. A list of `label=value` pairs, separated by commas.\n\n* `version`\n  Show application version.\n\n* `exclude-databases` (DEPRECATED)\n  A list of databases to remove when autoDiscoverDatabases is enabled.\n\n* `include-databases` (DEPRECATED)\n  A list of databases to only include when autoDiscoverDatabases is enabled.\n\n* `log.level`\n  Set logging level: one of `debug`, `info`, `warn`, `error`.\n\n* `log.format`\n  Set the log format: one of `logfmt`, `json`.\n\n### Environment Variables\n\nThe following environment variables configure the exporter:\n\n* `DATA_SOURCE_NAME`\n  the default legacy format. Accepts URI form and key=value form arguments. The\n  URI may contain the username and password to connect with.\n\n* `DATA_SOURCE_URI`\n   an alternative to `DATA_SOURCE_NAME` which exclusively accepts the hostname\n   without a username and password component. For example, `my_pg_hostname` or\n   `my_pg_hostname:5432/postgres?sslmode=disable`.\n\n* `DATA_SOURCE_URI_FILE`\n   The same as above but reads the URI from a file.\n\n* `DATA_SOURCE_USER`\n  When using `DATA_SOURCE_URI`, this environment variable is used to specify\n  the username.\n\n* `DATA_SOURCE_USER_FILE`\n  The same, but reads the username from a file.\n\n* `DATA_SOURCE_PASS`\n  When using `DATA_SOURCE_URI`, this environment variable is used to specify\n  the password to connect with.\n\n* `DATA_SOURCE_PASS_FILE`\n  The same as above but reads the password from a file.\n\n* `PG_EXPORTER_WEB_TELEMETRY_PATH`\n  Path under which to expose metrics. Default is `/metrics`.\n\n* `PG_EXPORTER_DISABLE_DEFAULT_METRICS`\n  Use only metrics supplied from `queries.yaml`. Value can be `true` or `false`. Default is `false`.\n\n* `PG_EXPORTER_DISABLE_SETTINGS_METRICS`\n  Use the flag if you don't want to scrape `pg_settings`. Value can be `true` or `false`. Default is `false`.\n\n* `PG_EXPORTER_AUTO_DISCOVER_DATABASES` (DEPRECATED)\n  Whether to discover the databases on a server dynamically. Value can be `true` or `false`. Default is `false`.\n\n* `PG_EXPORTER_EXTEND_QUERY_PATH`\n  Path to a YAML file containing custom queries to run. Check out [`queries.yaml`](queries.yaml)\n  for examples of the format.\n\n* `PG_EXPORTER_CONSTANT_LABELS` (DEPRECATED)\n  Labels to set in all metrics. A list of `label=value` pairs, separated by commas.\n\n* `PG_EXPORTER_EXCLUDE_DATABASES` (DEPRECATED)\n  A comma-separated list of databases to remove when autoDiscoverDatabases is enabled. Default is empty string.\n\n* `PG_EXPORTER_INCLUDE_DATABASES` (DEPRECATED)\n  A comma-separated list of databases to only include when autoDiscoverDatabases is enabled. Default is empty string,\n  means allow all.\n\n* `PG_EXPORTER_METRIC_PREFIX`\n  A prefix to use for each of the default metrics exported by postgres-exporter. Default is `pg`\n\nSettings set by environment variables starting with `PG_` will be overwritten by the corresponding CLI flag if given.\n\n### Setting the Postgres server's data source name\n\nThe PostgreSQL server's [data source name](http://en.wikipedia.org/wiki/Data_source_name)\nmust be set via the `DATA_SOURCE_NAME` environment variable.\n\nFor running it locally on a default Debian/Ubuntu install, this will work (transpose to init script as appropriate):\n\n    sudo -u postgres DATA_SOURCE_NAME=\"user=postgres host=/var/run/postgresql/ sslmode=disable\" postgres_exporter\n\nAlso, you can set a list of sources to scrape different instances from the one exporter setup. Just define a comma separated string.\n\n    sudo -u postgres DATA_SOURCE_NAME=\"port=5432,port=6432\" postgres_exporter\n\nSee the [github.com/lib/pq](http://github.com/lib/pq) module for other ways to format the connection string.\n\n### Adding new metrics\n\nThe exporter will attempt to dynamically export additional metrics if they are added in the\nfuture, but they will be marked as \"untyped\". Additional metric maps can be easily created\nfrom Postgres documentation by copying the tables and using the following Python snippet:\n\n```python\nx = \"\"\"tab separated raw text of a documentation table\"\"\"\nfor l in StringIO(x):\n    column, ctype, description = l.split('\\t')\n    print \"\"\"\"{0}\" : {{ prometheus.CounterValue, prometheus.NewDesc(\"pg_stat_database_{0}\", \"{2}\", nil, nil) }}, \"\"\".format(column.strip(), ctype, description.strip())\n```\nAdjust the value of the resultant prometheus value type appropriately. This helps build\nrich self-documenting metrics for the exporter.\n\n### Adding new metrics via a config file (DEPRECATED)\n\nThis feature is deprecated in favor of built-in collector functions. For generic SQL database monitoring see the [sql_exporter](https://github.com/burningalchemist/sql_exporter).\n\nThe -extend.query-path command-line argument specifies a YAML file containing additional queries to run.\nSome examples are provided in [queries.yaml](queries.yaml).\n\n### Disabling default metrics\nTo work with non-officially-supported postgres versions (e.g. 8.2.15),\nor variants of postgres (e.g. Greenplum), you can disable the default metrics with the `--disable-default-metrics`\nflag. This removes all built-in metrics, and uses only metrics defined by queries in the `queries.yaml` file you supply\n(so you must supply one, otherwise the exporter will return nothing but internal statuses and not your database).\n\n### Automatically discover databases (DEPRECATED)\nTo scrape metrics from all databases on a database server, the database DSN's can be dynamically discovered via the\n`--auto-discover-databases` flag. When true, `SELECT datname FROM pg_database WHERE datallowconn = true AND datistemplate = false and datname != current_database()` is run for all configured DSN's. From the\nresult a new set of DSN's is created for which the metrics are scraped.\n\nIn addition, the option `--exclude-databases` adds the possibily to filter the result from the auto discovery to discard databases you do not need.\n\nIf you want to include only subset of databases, you can use option `--include-databases`. Exporter still makes request to\n`pg_database` table, but do scrape from only if database is in include list.\n\n### Running as non-superuser\n\nTo be able to collect metrics from `pg_stat*` views as non-superuser in PostgreSQL\nserver versions >= 10 you can grant the `pg_monitor` or `pg_read_all_stats` [built-in roles](https://www.postgresql.org/docs/current/predefined-roles.html) to the user. If\nyou need to monitor older PostgreSQL servers, you will have to create functions\nand views as a superuser, and assign permissions separately to those.\n\n```sql\n-- To use IF statements, hence to be able to check if the user exists before\n-- attempting creation, we need to switch to procedural SQL (PL/pgSQL)\n-- instead of standard SQL.\n-- More: https://www.postgresql.org/docs/9.3/plpgsql-overview.html\n-- To preserve compatibility with <9.0, DO blocks are not used; instead,\n-- a function is created and dropped.\nCREATE OR REPLACE FUNCTION __tmp_create_user() returns void as $$\nBEGIN\n  IF NOT EXISTS (\n          SELECT                       -- SELECT list can stay empty for this\n          FROM   pg_catalog.pg_user\n          WHERE  usename = 'postgres_exporter') THEN\n    CREATE USER postgres_exporter;\n  END IF;\nEND;\n$$ language plpgsql;\n\nSELECT __tmp_create_user();\nDROP FUNCTION __tmp_create_user();\n\nALTER USER postgres_exporter WITH PASSWORD 'password';\nALTER USER postgres_exporter SET SEARCH_PATH TO postgres_exporter,pg_catalog;\n\n-- If deploying as non-superuser (for example in AWS RDS), uncomment the GRANT\n-- line below and replace <MASTER_USER> with your root user.\n-- GRANT postgres_exporter TO <MASTER_USER>;\n\nGRANT CONNECT ON DATABASE postgres TO postgres_exporter;\n```\n\nRun following command if you use PostgreSQL versions >= 10\n```sql\nGRANT pg_monitor to postgres_exporter;\n```\n\nRun following SQL commands only if you use PostgreSQL versions older than 10.\nIn PostgreSQL, views run with the permissions of the user that created them so\nthey can act as security barriers. Functions need to be created to share this\ndata with the non-superuser. Only creating the views will leave out the most\nimportant bits of data.\n```sql\nCREATE SCHEMA IF NOT EXISTS postgres_exporter;\nGRANT USAGE ON SCHEMA postgres_exporter TO postgres_exporter;\n\nCREATE OR REPLACE FUNCTION get_pg_stat_activity() RETURNS SETOF pg_stat_activity AS\n$$ SELECT * FROM pg_catalog.pg_stat_activity; $$\nLANGUAGE sql\nVOLATILE\nSECURITY DEFINER;\n\nCREATE OR REPLACE VIEW postgres_exporter.pg_stat_activity\nAS\n  SELECT * from get_pg_stat_activity();\n\nGRANT SELECT ON postgres_exporter.pg_stat_activity TO postgres_exporter;\n\nCREATE OR REPLACE FUNCTION get_pg_stat_replication() RETURNS SETOF pg_stat_replication AS\n$$ SELECT * FROM pg_catalog.pg_stat_replication; $$\nLANGUAGE sql\nVOLATILE\nSECURITY DEFINER;\n\nCREATE OR REPLACE VIEW postgres_exporter.pg_stat_replication\nAS\n  SELECT * FROM get_pg_stat_replication();\n\nGRANT SELECT ON postgres_exporter.pg_stat_replication TO postgres_exporter;\n\nCREATE EXTENSION IF NOT EXISTS pg_stat_statements;\nCREATE OR REPLACE FUNCTION get_pg_stat_statements() RETURNS SETOF pg_stat_statements AS\n$$ SELECT * FROM public.pg_stat_statements; $$\nLANGUAGE sql\nVOLATILE\nSECURITY DEFINER;\n\nCREATE OR REPLACE VIEW postgres_exporter.pg_stat_statements\nAS\n  SELECT * FROM get_pg_stat_statements();\n\nGRANT SELECT ON postgres_exporter.pg_stat_statements TO postgres_exporter;\n```\n\n> **NOTE**\n> <br />Remember to use `postgres` database name in the connection string:\n> ```\n> DATA_SOURCE_NAME=postgresql://postgres_exporter:password@localhost:5432/postgres?sslmode=disable\n> ```\n\n\n## Running the tests\n```\n# Run the unit tests\nmake test\n# Start the test database with docker\ndocker run -p 5432:5432 -e POSTGRES_DB=circle_test -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=test -d postgres\n# Run the integration tests\nDATA_SOURCE_NAME='postgresql://postgres:test@localhost:5432/circle_test?sslmode=disable' GOOPTS='-v -tags integration' make test\n```\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.16796875,
          "content": "# Reporting a security issue\n\nThe Prometheus security policy, including how to report vulnerabilities, can be\nfound here:\n\n<https://prometheus.io/docs/operating/security/>\n"
        },
        {
          "name": "VERSION",
          "type": "blob",
          "size": 0.0068359375,
          "content": "0.16.0\n"
        },
        {
          "name": "cmd",
          "type": "tree",
          "content": null
        },
        {
          "name": "collector",
          "type": "tree",
          "content": null
        },
        {
          "name": "config",
          "type": "tree",
          "content": null
        },
        {
          "name": "gh-assets-clone.sh",
          "type": "blob",
          "size": 0.51171875,
          "content": "#!/bin/bash\n# Script to setup the assets clone of the repository using GIT_ASSETS_BRANCH and\n# GIT_API_KEY.\n\n[ ! -z \"$GIT_ASSETS_BRANCH\" ] || exit 1\n\nsetup_git() {\n  git config --global user.email \"travis@travis-ci.org\" || exit 1\n  git config --global user.name \"Travis CI\" || exit 1\n}\n\n# Constants\nASSETS_DIR=\".assets-branch\"\n\n# Clone the assets branch with the correct credentials\ngit clone --single-branch -b \"$GIT_ASSETS_BRANCH\" \\\n    \"https://${GIT_API_KEY}@github.com/${TRAVIS_REPO_SLUG}.git\" \"$ASSETS_DIR\" || exit 1\n\n"
        },
        {
          "name": "gh-metrics-push.sh",
          "type": "blob",
          "size": 0.6806640625,
          "content": "#!/bin/bash\n# Script to copy and push new metric versions to the assets branch.\n\n[ ! -z \"$GIT_ASSETS_BRANCH\" ] || exit 1\n[ ! -z \"$GIT_API_KEY\" ] || exit 1\n\nversion=$(git describe HEAD) || exit 1\n\n# Constants\nASSETS_DIR=\".assets-branch\"\nMETRICS_DIR=\"$ASSETS_DIR/metriclists\"\n\n# Ensure metrics dir exists\nmkdir -p \"$METRICS_DIR/\"\n\n# Remove old files so we spot deletions\nrm -f \"$METRICS_DIR/.*.unique\"\n\n# Copy new files\ncp -f -t \"$METRICS_DIR/\" ./.metrics.*.prom.unique || exit 1\n\n# Enter the assets dir and push.\ncd \"$ASSETS_DIR\" || exit 1\n\ngit add \"metriclists\" || exit 1\ngit commit -m \"Added unique metrics for build from $version\" || exit 1\ngit push origin \"$GIT_ASSETS_BRANCH\" || exit 1\n\nexit 0"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 1.763671875,
          "content": "module github.com/prometheus-community/postgres_exporter\n\ngo 1.23.0\n\nrequire (\n\tgithub.com/DATA-DOG/go-sqlmock v1.5.2\n\tgithub.com/alecthomas/kingpin/v2 v2.4.0\n\tgithub.com/blang/semver/v4 v4.0.0\n\tgithub.com/lib/pq v1.10.9\n\tgithub.com/prometheus/client_golang v1.20.5\n\tgithub.com/prometheus/client_model v0.6.1\n\tgithub.com/prometheus/common v0.61.0\n\tgithub.com/prometheus/exporter-toolkit v0.13.2\n\tgithub.com/smartystreets/goconvey v1.8.1\n\tgopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c\n\tgopkg.in/yaml.v2 v2.4.0\n\tgopkg.in/yaml.v3 v3.0.1\n)\n\nrequire (\n\tgithub.com/alecthomas/units v0.0.0-20211218093645-b94a6e3cc137 // indirect\n\tgithub.com/beorn7/perks v1.0.1 // indirect\n\tgithub.com/cespare/xxhash/v2 v2.3.0 // indirect\n\tgithub.com/coreos/go-systemd/v22 v22.5.0 // indirect\n\tgithub.com/gopherjs/gopherjs v1.17.2 // indirect\n\tgithub.com/jpillora/backoff v1.0.0 // indirect\n\tgithub.com/jtolds/gls v4.20.0+incompatible // indirect\n\tgithub.com/klauspost/compress v1.17.9 // indirect\n\tgithub.com/kr/pretty v0.3.1 // indirect\n\tgithub.com/kr/text v0.2.0 // indirect\n\tgithub.com/mdlayher/socket v0.4.1 // indirect\n\tgithub.com/mdlayher/vsock v1.2.1 // indirect\n\tgithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 // indirect\n\tgithub.com/mwitkow/go-conntrack v0.0.0-20190716064945-2f068394615f // indirect\n\tgithub.com/prometheus/procfs v0.15.1 // indirect\n\tgithub.com/rogpeppe/go-internal v1.10.0 // indirect\n\tgithub.com/smarty/assertions v1.15.0 // indirect\n\tgithub.com/xhit/go-str2duration/v2 v2.1.0 // indirect\n\tgolang.org/x/crypto v0.31.0 // indirect\n\tgolang.org/x/net v0.32.0 // indirect\n\tgolang.org/x/oauth2 v0.24.0 // indirect\n\tgolang.org/x/sync v0.10.0 // indirect\n\tgolang.org/x/sys v0.28.0 // indirect\n\tgolang.org/x/text v0.21.0 // indirect\n\tgoogle.golang.org/protobuf v1.35.2 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 8.41796875,
          "content": "github.com/DATA-DOG/go-sqlmock v1.5.2 h1:OcvFkGmslmlZibjAjaHm3L//6LiuBgolP7OputlJIzU=\ngithub.com/DATA-DOG/go-sqlmock v1.5.2/go.mod h1:88MAG/4G7SMwSE3CeA0ZKzrT5CiOU3OJ+JlNzwDqpNU=\ngithub.com/alecthomas/kingpin/v2 v2.4.0 h1:f48lwail6p8zpO1bC4TxtqACaGqHYA22qkHjHpqDjYY=\ngithub.com/alecthomas/kingpin/v2 v2.4.0/go.mod h1:0gyi0zQnjuFk8xrkNKamJoyUo382HRL7ATRpFZCw6tE=\ngithub.com/alecthomas/units v0.0.0-20211218093645-b94a6e3cc137 h1:s6gZFSlWYmbqAuRjVTiNNhvNRfY2Wxp9nhfyel4rklc=\ngithub.com/alecthomas/units v0.0.0-20211218093645-b94a6e3cc137/go.mod h1:OMCwj8VM1Kc9e19TLln2VL61YJF0x1XFtfdL4JdbSyE=\ngithub.com/beorn7/perks v1.0.1 h1:VlbKKnNfV8bJzeqoa4cOKqO6bYr3WgKZxO8Z16+hsOM=\ngithub.com/beorn7/perks v1.0.1/go.mod h1:G2ZrVWU2WbWT9wwq4/hrbKbnv/1ERSJQ0ibhJ6rlkpw=\ngithub.com/blang/semver/v4 v4.0.0 h1:1PFHFE6yCCTv8C1TeyNNarDzntLi7wMI5i/pzqYIsAM=\ngithub.com/blang/semver/v4 v4.0.0/go.mod h1:IbckMUScFkM3pff0VJDNKRiT6TG/YpiHIM2yvyW5YoQ=\ngithub.com/cespare/xxhash/v2 v2.3.0 h1:UL815xU9SqsFlibzuggzjXhog7bL6oX9BbNZnL2UFvs=\ngithub.com/cespare/xxhash/v2 v2.3.0/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/coreos/go-systemd/v22 v22.5.0 h1:RrqgGjYQKalulkV8NGVIfkXQf6YYmOyiJKk8iXXhfZs=\ngithub.com/coreos/go-systemd/v22 v22.5.0/go.mod h1:Y58oyj3AT4RCenI/lSvhwexgC+NSVTIJ3seZv2GcEnc=\ngithub.com/creack/pty v1.1.9/go.mod h1:oKZEueFk5CKHvIhNR5MUki03XCEU+Q6VDXinZuGJ33E=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/godbus/dbus/v5 v5.0.4/go.mod h1:xhWf0FNVPg57R7Z0UbKHbJfkEywrmjJnf7w5xrFpKfA=\ngithub.com/google/go-cmp v0.6.0 h1:ofyhxvXcZhMsU5ulbFiLKl/XBFqE1GSq7atu8tAmTRI=\ngithub.com/google/go-cmp v0.6.0/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/gopherjs/gopherjs v1.17.2 h1:fQnZVsXk8uxXIStYb0N4bGk7jeyTalG/wsZjQ25dO0g=\ngithub.com/gopherjs/gopherjs v1.17.2/go.mod h1:pRRIvn/QzFLrKfvEz3qUuEhtE/zLCWfreZ6J5gM2i+k=\ngithub.com/jpillora/backoff v1.0.0 h1:uvFg412JmmHBHw7iwprIxkPMI+sGQ4kzOWsMeHnm2EA=\ngithub.com/jpillora/backoff v1.0.0/go.mod h1:J/6gKK9jxlEcS3zixgDgUAsiuZ7yrSoa/FX5e0EB2j4=\ngithub.com/jtolds/gls v4.20.0+incompatible h1:xdiiI2gbIgH/gLH7ADydsJ1uDOEzR8yvV7C0MuV77Wo=\ngithub.com/jtolds/gls v4.20.0+incompatible/go.mod h1:QJZ7F/aHp+rZTRtaJ1ow/lLfFfVYBRgL+9YlvaHOwJU=\ngithub.com/kisielk/sqlstruct v0.0.0-20201105191214-5f3e10d3ab46/go.mod h1:yyMNCyc/Ib3bDTKd379tNMpB/7/H5TjM2Y9QJ5THLbE=\ngithub.com/klauspost/compress v1.17.9 h1:6KIumPrER1LHsvBVuDa0r5xaG0Es51mhhB9BQB2qeMA=\ngithub.com/klauspost/compress v1.17.9/go.mod h1:Di0epgTjJY877eYKx5yC51cX2A2Vl2ibi7bDH9ttBbw=\ngithub.com/kr/pretty v0.2.1/go.mod h1:ipq/a2n7PKx3OHsz4KJII5eveXtPO4qwEXGdVfWzfnI=\ngithub.com/kr/pretty v0.3.1 h1:flRD4NNwYAUpkphVc1HcthR4KEIFJ65n8Mw5qdRn3LE=\ngithub.com/kr/pretty v0.3.1/go.mod h1:hoEshYVHaxMs3cyo3Yncou5ZscifuDolrwPKZanG3xk=\ngithub.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=\ngithub.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=\ngithub.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=\ngithub.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=\ngithub.com/kylelemons/godebug v1.1.0 h1:RPNrshWIDI6G2gRW9EHilWtl7Z6Sb1BR0xunSBf0SNc=\ngithub.com/kylelemons/godebug v1.1.0/go.mod h1:9/0rRGxNHcop5bhtWyNeEfOS8JIWk580+fNqagV/RAw=\ngithub.com/lib/pq v1.10.9 h1:YXG7RB+JIjhP29X+OtkiDnYaXQwpS4JEWq7dtCCRUEw=\ngithub.com/lib/pq v1.10.9/go.mod h1:AlVN5x4E4T544tWzH6hKfbfQvm3HdbOxrmggDNAPY9o=\ngithub.com/mdlayher/socket v0.4.1 h1:eM9y2/jlbs1M615oshPQOHZzj6R6wMT7bX5NPiQvn2U=\ngithub.com/mdlayher/socket v0.4.1/go.mod h1:cAqeGjoufqdxWkD7DkpyS+wcefOtmu5OQ8KuoJGIReA=\ngithub.com/mdlayher/vsock v1.2.1 h1:pC1mTJTvjo1r9n9fbm7S1j04rCgCzhCOS5DY0zqHlnQ=\ngithub.com/mdlayher/vsock v1.2.1/go.mod h1:NRfCibel++DgeMD8z/hP+PPTjlNJsdPOmxcnENvE+SE=\ngithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 h1:C3w9PqII01/Oq1c1nUAm88MOHcQC9l5mIlSMApZMrHA=\ngithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822/go.mod h1:+n7T8mK8HuQTcFwEeznm/DIxMOiR9yIdICNftLE1DvQ=\ngithub.com/mwitkow/go-conntrack v0.0.0-20190716064945-2f068394615f h1:KUppIJq7/+SVif2QVs3tOP0zanoHgBEVAwHxUSIzRqU=\ngithub.com/mwitkow/go-conntrack v0.0.0-20190716064945-2f068394615f/go.mod h1:qRWi+5nqEBWmkhHvq77mSJWrCKwh8bxhgT7d/eI7P4U=\ngithub.com/pkg/diff v0.0.0-20210226163009-20ebb0f2a09e/go.mod h1:pJLUxLENpZxwdsKMEsNbx1VGcRFpLqf3715MtcvvzbA=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/prometheus/client_golang v1.20.5 h1:cxppBPuYhUnsO6yo/aoRol4L7q7UFfdm+bR9r+8l63Y=\ngithub.com/prometheus/client_golang v1.20.5/go.mod h1:PIEt8X02hGcP8JWbeHyeZ53Y/jReSnHgO035n//V5WE=\ngithub.com/prometheus/client_model v0.6.1 h1:ZKSh/rekM+n3CeS952MLRAdFwIKqeY8b62p8ais2e9E=\ngithub.com/prometheus/client_model v0.6.1/go.mod h1:OrxVMOVHjw3lKMa8+x6HeMGkHMQyHDk9E3jmP2AmGiY=\ngithub.com/prometheus/common v0.61.0 h1:3gv/GThfX0cV2lpO7gkTUwZru38mxevy90Bj8YFSRQQ=\ngithub.com/prometheus/common v0.61.0/go.mod h1:zr29OCN/2BsJRaFwG8QOBr41D6kkchKbpeNH7pAjb/s=\ngithub.com/prometheus/exporter-toolkit v0.13.2 h1:Z02fYtbqTMy2i/f+xZ+UK5jy/bl1Ex3ndzh06T/Q9DQ=\ngithub.com/prometheus/exporter-toolkit v0.13.2/go.mod h1:tCqnfx21q6qN1KA4U3Bfb8uWzXfijIrJz3/kTIqMV7g=\ngithub.com/prometheus/procfs v0.15.1 h1:YagwOFzUgYfKKHX6Dr+sHT7km/hxC76UB0learggepc=\ngithub.com/prometheus/procfs v0.15.1/go.mod h1:fB45yRUv8NstnjriLhBQLuOUt+WW4BsoGhij/e3PBqk=\ngithub.com/rogpeppe/go-internal v1.9.0/go.mod h1:WtVeX8xhTBvf0smdhujwtBcq4Qrzq/fJaraNFVN+nFs=\ngithub.com/rogpeppe/go-internal v1.10.0 h1:TMyTOH3F/DB16zRVcYyreMH6GnZZrwQVAoYjRBZyWFQ=\ngithub.com/rogpeppe/go-internal v1.10.0/go.mod h1:UQnix2H7Ngw/k4C5ijL5+65zddjncjaFoBhdsK/akog=\ngithub.com/smarty/assertions v1.15.0 h1:cR//PqUBUiQRakZWqBiFFQ9wb8emQGDb0HeGdqGByCY=\ngithub.com/smarty/assertions v1.15.0/go.mod h1:yABtdzeQs6l1brC900WlRNwj6ZR55d7B+E8C6HtKdec=\ngithub.com/smartystreets/goconvey v1.8.1 h1:qGjIddxOk4grTu9JPOU31tVfq3cNdBlNa5sSznIX1xY=\ngithub.com/smartystreets/goconvey v1.8.1/go.mod h1:+/u4qLyY6x1jReYOp7GOM2FSt8aP9CzCZL03bI28W60=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/testify v1.4.0/go.mod h1:j7eGeouHqKxXV5pUuKE4zz7dFj8WfuZ+81PSLYec5m4=\ngithub.com/stretchr/testify v1.10.0 h1:Xv5erBjTwe/5IxqUQTdXv5kgmIvbHo3QQyRwhJsOfJA=\ngithub.com/stretchr/testify v1.10.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=\ngithub.com/xhit/go-str2duration/v2 v2.1.0 h1:lxklc02Drh6ynqX+DdPyp5pCKLUQpRT8bp8Ydu2Bstc=\ngithub.com/xhit/go-str2duration/v2 v2.1.0/go.mod h1:ohY8p+0f07DiV6Em5LKB0s2YpLtXVyJfNt1+BlmyAsU=\ngolang.org/x/crypto v0.31.0 h1:ihbySMvVjLAeSH1IbfcRTkD/iNscyz8rGzjF/E5hV6U=\ngolang.org/x/crypto v0.31.0/go.mod h1:kDsLvtWBEx7MV9tJOj9bnXsPbxwJQ6csT/x4KIN4Ssk=\ngolang.org/x/net v0.32.0 h1:ZqPmj8Kzc+Y6e0+skZsuACbx+wzMgo5MQsJh9Qd6aYI=\ngolang.org/x/net v0.32.0/go.mod h1:CwU0IoeOlnQQWJ6ioyFrfRuomB8GKF6KbYXZVyeXNfs=\ngolang.org/x/oauth2 v0.24.0 h1:KTBBxWqUa0ykRPLtV69rRto9TLXcqYkeswu48x/gvNE=\ngolang.org/x/oauth2 v0.24.0/go.mod h1:XYTD2NtWslqkgxebSiOHnXEap4TF09sJSc7H1sXbhtI=\ngolang.org/x/sync v0.10.0 h1:3NQrjDixjgGwUOCaF8w2+VYHv0Ve/vGYSbdkTa98gmQ=\ngolang.org/x/sync v0.10.0/go.mod h1:Czt+wKu1gCyEFDUtn0jG5QVvpJ6rzVqr5aXyt9drQfk=\ngolang.org/x/sys v0.28.0 h1:Fksou7UEQUWlKvIdsqzJmUmCX3cZuD2+P3XyyzwMhlA=\ngolang.org/x/sys v0.28.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/text v0.21.0 h1:zyQAAkrwaneQ066sspRyJaG9VNi/YJ1NfzcGB3hZ/qo=\ngolang.org/x/text v0.21.0/go.mod h1:4IBbMaMmOPCJ8SecivzSH54+73PCFmPWxNTLm+vZkEQ=\ngoogle.golang.org/protobuf v1.35.2 h1:8Ar7bF+apOIoThw1EdZl0p1oWvMqTHmpA2fRTyZO8io=\ngoogle.golang.org/protobuf v1.35.2/go.mod h1:9fA7Ob0pmnwhb644+1+CVWFRbNajQ6iRojtC/QF5bRE=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c h1:Hei/4ADfdWqJk1ZMxUNpqntNwaWcugrBjAiHlqqRiVk=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c/go.mod h1:JHkPIbrfpd72SG/EVd6muEfDQjcINNoR0C8j2r3qZ4Q=\ngopkg.in/yaml.v2 v2.2.2/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.4.0 h1:D8xgwECY7CYvx+Y2n4sBz93Jn9JRvxdiyyo8CTfuKaY=\ngopkg.in/yaml.v2 v2.4.0/go.mod h1:RDklbk79AGWmwhnvt/jBztapEOGDOx6ZbXqjP6csGnQ=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\n"
        },
        {
          "name": "postgres-metrics-get-changes.sh",
          "type": "blob",
          "size": 1.126953125,
          "content": "#!/bin/bash\n# Script to parse a text exposition format file into a unique list of metrics\n# output by the exporter and then build lists of added/removed metrics.\n\nold_src=\"$1\"\nif [ ! -d \"$old_src\" ] ; then\n    mkdir -p \"$old_src\"\nfi\n\nfunction generate_add_removed() {\n    type=\"$1\"\n    pg_version=\"$2\"\n    old_version=\"$3\"\n    new_version=\"$4\"\n    \n    if [ ! -e \"$old_version\" ] ; then\n        touch \"$old_version\"\n    fi\n\n    comm -23 \"$old_version\" \"$new_version\" > \".metrics.${type}.${pg_version}.removed\"\n    comm -13 \"$old_version\" \"$new_version\" > \".metrics.${type}.${pg_version}.added\"   \n}\n\nfor raw_prom in $(echo .*.prom) ; do\n    # Get the type and version\n    type=$(echo \"$raw_prom\" | cut -d'.' -f3)\n    pg_version=$(echo \"$raw_prom\" | cut -d'.' -f4- | sed 's/\\.prom$//g')\n\n    unique_file=\"${raw_prom}.unique\"\n    old_unique_file=\"$old_src/$unique_file\"\n\n    # Strip, sort and deduplicate the label names\n    grep -v '#' \"$raw_prom\" | \\\n        rev | cut -d' ' -f2- | \\\n        rev | cut -d'{' -f1 | \\\n        sort | \\\n        uniq > \"$unique_file\"\n    \n    generate_add_removed \"$type\" \"$pg_version\" \"$old_unique_file\" \"$unique_file\"\ndone\n"
        },
        {
          "name": "postgres_exporter.rc",
          "type": "blob",
          "size": 2.515625,
          "content": "#!/bin/sh\n\n# PROVIDE: postgres_exporter\n# REQUIRE: LOGIN\n# KEYWORD: shutdown\n#\n# rc-script for postgres_exporter\n#\n#\n# Add the following lines to /etc/rc.conf.local or /etc/rc.conf\n# to enable this service:\n#\n# postgres_exporter_enable (bool):          Set to NO by default.\n#               Set it to YES to enable postgres_exporter.\n# postgres_exporter_user (string):          Set user that postgres_exporter will run under\n#               Default is \"nobody\".\n# postgres_exporter_group (string):         Set group that postgres_exporter will run under\n#               Default is \"nobody\".\n# postgres_exporter_args (string):          Set extra arguments to pass to postgres_exporter\n#               Default is \"\".\n# postgres_exporter_listen_address (string):Set ip:port to listen on for web interface and telemetry.\n#\t\tDefaults to \":9187\"\n# postgres_exporter_pg_user (string):\t    Set the Postgres database user\n#\t\tDefaults to \"postgres_exporter\"\n# postgres_exporter_pg_pass (string):\t    Set the Postgres datase password\n#\t\tDefault is empty\n# postgres_exporter_pg_host (string):\t    Set the Postgres database server\n#\t\tDefaults to \"localhost\"\n# postgres_exporter_pg_port (string):  \t    Set the Postgres database port\n#\t\tDefaults to \"5432\"\n\n# Add extra arguments via \"postgres_exporter_args\"\n# (see $ postgres_exporter --help)\n\n\n. /etc/rc.subr\n\nname=postgres_exporter\nrcvar=postgres_exporter_enable\n\nload_rc_config $name\n\n: ${postgres_exporter_enable:=\"NO\"}\n: ${postgres_exporter_user:=\"nobody\"}\n: ${postgres_exporter_group:=\"nobody\"}\n: ${postgres_exporter_args:=\"\"}\n: ${postgres_exporter_listen_address:=\":9187\"}\n: ${postgres_exporter_pg_user:=\"postgres_exporter\"}\n: ${postgres_exporter_pg_pass:=\"\"}\n: ${postgres_exporter_pg_host:=\"localhost\"}\n: ${postgres_exporter_pg_port:=\"5432\"}\n\npostgres_exporter_data_source_name=\"postgresql://${postgres_exporter_pg_user}:${postgres_exporter_pg_pass}@${postgres_exporter_pg_host}:${postgres_exporter_pg_port}/postgres?sslmode=disable\"\n\n\npidfile=/var/run/postgres_exporter.pid\ncommand=\"/usr/sbin/daemon\"\nprocname=\"/usr/local/bin/postgres_exporter\"\ncommand_args=\"-f -p ${pidfile} -T ${name} \\\n    /usr/bin/env DATA_SOURCE_NAME=\"${postgres_exporter_data_source_name}\" ${procname} \\\n    --web.listen-address=${postgres_exporter_listen_address} \\\n    ${postgres_exporter_args}\"\n\nstart_precmd=postgres_exporter_startprecmd\n\npostgres_exporter_startprecmd()\n{\n    if [ ! -e ${pidfile} ]; then\n        install -o ${postgres_exporter_user} -g ${postgres_exporter_group} /dev/null ${pidfile};\n    fi\n}\n\nload_rc_config $name\nrun_rc_command \"$1\"\n"
        },
        {
          "name": "postgres_exporter_integration_test_script",
          "type": "blob",
          "size": 0.375,
          "content": "#!/bin/bash\n# This script wraps the integration test binary so it produces concatenated\n# test output.\n\ntest_binary=$1\nshift\noutput_cov=$1\nshift\n\necho \"Test Binary: $test_binary\" 1>&2\necho \"Coverage File: $output_cov\" 1>&2\n\necho \"mode: count\" > $output_cov\n\ntest_cov=$(mktemp)\n$test_binary -test.coverprofile=$test_cov $@ || exit 1\ntail -n +2 $test_cov >> $output_cov\nrm -f $test_cov\n"
        },
        {
          "name": "postgres_mixin",
          "type": "tree",
          "content": null
        },
        {
          "name": "queries.yaml",
          "type": "blob",
          "size": 0.09765625,
          "content": "# Adding queries to this file is deprecated\n# Example queries have been transformed into collectors."
        }
      ]
    }
  ]
}