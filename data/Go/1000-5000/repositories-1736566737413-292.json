{
  "metadata": {
    "timestamp": 1736566737413,
    "page": 292,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "go-gorp/gorp",
      "stars": 3734,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.078125,
          "content": "_test\n*.test\n_testmain.go\n_obj\n*~\n*.6\n6.out\ngorptest.bin\ntmp\n.idea\ncoverage.out\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.8896484375,
          "content": "language: go\ngo:\n- \"1.15.x\"\n- \"1.16.x\"\n- tip\n\nmatrix:\n  allow_failures:\n  - go: tip\n\nservices:\n- mysql\n- postgresql\n- sqlite3\n\nenv:\n  global:\n  - secure: RriLxF6+2yMl67hdVv8ImXlu0h62mhcpqjaOgYNU+IEbUQ7hx96CKY6gkpYubW3BgApvF5RH6j3+HKvh2kGp0XhDOYOQCODfBSaSipZ5Aa5RKjsEYLtuVIobvJ80awR9hUeql69+WXs0/s72WThG0qTbOUY4pqHWfteeY235hWM=\n\ninstall:\n  - go get -t -d\n  - go get -t -d -tags integration\n\nbefore_script:\n- mysql -e \"CREATE DATABASE gorptest;\"\n- mysql -u root -e \"GRANT ALL ON gorptest.* TO gorptest@localhost IDENTIFIED BY 'gorptest'\"\n- psql -c \"CREATE DATABASE gorptest;\" -U postgres\n- psql -c \"CREATE USER \"gorptest\" WITH SUPERUSER PASSWORD 'gorptest';\" -U postgres\n- go get github.com/lib/pq\n- go get github.com/mattn/go-sqlite3\n- go get github.com/ziutek/mymysql/godrv\n- go get github.com/go-sql-driver/mysql\n- go get golang.org/x/tools/cmd/cover\n- go get github.com/mattn/goveralls\n\nscript: ./test_all.sh\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1.0673828125,
          "content": "# Contributions are very welcome!\n\n## First: Create an Issue\n\nEven if your fix is simple, we'd like to have an issue to relate to\nthe PR.  Discussion about the architecture and value can go on the\nissue, leaving PR comments exclusively for coding style.\n\n## Second: Make Your PR\n\n- Fork the `master` branch\n- Make your change\n- Make a PR against the `master` branch\n\nYou don't need to wait for comments on the issue before making your\nPR.  If you do wait for comments, you'll have a better chance of\ngetting your PR accepted the first time around, but it's not\nnecessary.\n\n## Third: Be Patient\n\n- If your change breaks backward compatibility, this becomes\n  especially true.\n\nWe all have lives and jobs, and many of us are no longer on projects\nthat make use of `gorp`.  We will get back to you, but it might take a\nwhile.\n\n## Fourth: Consider Becoming a Maintainer\n\nWe really do need help.  We will likely ask you for help after a good\nPR, but if we don't, please create an issue requesting maintainership.\nConsidering how few of us are currently active, we are unlikely to\nrefuse good help.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0732421875,
          "content": "(The MIT License)\n\nCopyright (c) 2012 James Cooper <james@bitmechanic.com>\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n'Software'), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\nTORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\nSOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 23.21875,
          "content": "# Go Relational Persistence\n\n[![build status](https://github.com/go-gorp/gorp/actions/workflows/go.yml/badge.svg)](https://github.com/go-gorp/gorp/actions)\n[![issues](https://img.shields.io/github/issues/go-gorp/gorp.svg)](https://github.com/go-gorp/gorp/issues)\n[![Go Reference](https://pkg.go.dev/badge/github.com/go-gorp/gorp/v3.svg)](https://pkg.go.dev/github.com/go-gorp/gorp/v3)\n\n### Update 2016-11-13: Future versions\n\nAs many of the maintainers have become busy with other projects,\nprogress toward the ever-elusive v2 has slowed to the point that we're\nonly occasionally making progress outside of merging pull requests.\nIn the interest of continuing to release, I'd like to lean toward a\nmore maintainable path forward.\n\nFor the moment, I am releasing a v2 tag with the current feature set\nfrom master, as some of those features have been actively used and\nrelied on by more than one project.  Our next goal is to continue\ncleaning up the code base with non-breaking changes as much as\npossible, but if/when a breaking change is needed, we'll just release\nnew versions.  This allows us to continue development at whatever pace\nwe're capable of, without delaying the release of features or refusing\nPRs.\n\n## Introduction\n\nI hesitate to call gorp an ORM.  Go doesn't really have objects, at\nleast not in the classic Smalltalk/Java sense.  There goes the \"O\".\ngorp doesn't know anything about the relationships between your\nstructs (at least not yet).  So the \"R\" is questionable too (but I use\nit in the name because, well, it seemed more clever).\n\nThe \"M\" is alive and well.  Given some Go structs and a database, gorp\nshould remove a fair amount of boilerplate busy-work from your code.\n\nI hope that gorp saves you time, minimizes the drudgery of getting\ndata in and out of your database, and helps your code focus on\nalgorithms, not infrastructure.\n\n* Bind struct fields to table columns via API or tag\n* Support for embedded structs\n* Support for transactions\n* Forward engineer db schema from structs (great for unit tests)\n* Pre/post insert/update/delete hooks\n* Automatically generate insert/update/delete statements for a struct\n* Automatic binding of auto increment PKs back to struct after insert\n* Delete by primary key(s)\n* Select by primary key(s)\n* Optional trace sql logging\n* Bind arbitrary SQL queries to a struct\n* Bind slice to SELECT query results without type assertions\n* Use positional or named bind parameters in custom SELECT queries\n* Optional optimistic locking using a version column (for\n  update/deletes)\n\n## Installation\n\nUse `go get` or your favorite vendoring tool, using whichever import\npath you'd like.\n\n## Versioning\n\nWe use semantic version tags.  Feel free to import through `gopkg.in`\n(e.g. `gopkg.in/gorp.v2`) to get the latest tag for a major version,\nor check out the tag using your favorite vendoring tool.\n\nDevelopment is not very active right now, but we have plans to\nrestructure `gorp` as we continue to move toward a more extensible\nsystem.  Whenever a breaking change is needed, the major version will\nbe bumped.\n\nThe `master` branch is where all development is done, and breaking\nchanges may happen from time to time.  That said, if you want to live\non the bleeding edge and are comfortable updating your code when we\nmake a breaking change, you may use `github.com/go-gorp/gorp` as your\nimport path.\n\nCheck the version tags to see what's available.  We'll make a good\nfaith effort to add badges for new versions, but we make no\nguarantees.\n\n## Supported Go versions\n\nThis package is guaranteed to be compatible with the latest 2 major\nversions of Go.\n\nAny earlier versions are only supported on a best effort basis and can\nbe dropped any time.  Go has a great compatibility promise. Upgrading\nyour program to a newer version of Go should never really be a\nproblem.\n\n## Migration guide\n\n#### Pre-v2 to v2\nAutomatic mapping of the version column used in optimistic locking has\nbeen removed as it could cause problems if the type was not int. The\nversion column must now explicitly be set with\n`tablemap.SetVersionCol()`.\n\n## Help/Support\n\nUse our [`gitter` channel](https://gitter.im/go-gorp/gorp).  We used\nto use IRC, but with most of us being pulled in many directions, we\noften need the email notifications from `gitter` to yell at us to sign\nin.\n\n## Quickstart\n\n```go\npackage main\n\nimport (\n    \"database/sql\"\n    \"gopkg.in/gorp.v1\"\n    _ \"github.com/mattn/go-sqlite3\"\n    \"log\"\n    \"time\"\n)\n\nfunc main() {\n    // initialize the DbMap\n    dbmap := initDb()\n    defer dbmap.Db.Close()\n\n    // delete any existing rows\n    err := dbmap.TruncateTables()\n    checkErr(err, \"TruncateTables failed\")\n\n    // create two posts\n    p1 := newPost(\"Go 1.1 released!\", \"Lorem ipsum lorem ipsum\")\n    p2 := newPost(\"Go 1.2 released!\", \"Lorem ipsum lorem ipsum\")\n\n    // insert rows - auto increment PKs will be set properly after the insert\n    err = dbmap.Insert(&p1, &p2)\n    checkErr(err, \"Insert failed\")\n\n    // use convenience SelectInt\n    count, err := dbmap.SelectInt(\"select count(*) from posts\")\n    checkErr(err, \"select count(*) failed\")\n    log.Println(\"Rows after inserting:\", count)\n\n    // update a row\n    p2.Title = \"Go 1.2 is better than ever\"\n    count, err = dbmap.Update(&p2)\n    checkErr(err, \"Update failed\")\n    log.Println(\"Rows updated:\", count)\n\n    // fetch one row - note use of \"post_id\" instead of \"Id\" since column is aliased\n    //\n    // Postgres users should use $1 instead of ? placeholders\n    // See 'Known Issues' below\n    //\n    err = dbmap.SelectOne(&p2, \"select * from posts where post_id=?\", p2.Id)\n    checkErr(err, \"SelectOne failed\")\n    log.Println(\"p2 row:\", p2)\n\n    // fetch all rows\n    var posts []Post\n    _, err = dbmap.Select(&posts, \"select * from posts order by post_id\")\n    checkErr(err, \"Select failed\")\n    log.Println(\"All rows:\")\n    for x, p := range posts {\n        log.Printf(\"    %d: %v\\n\", x, p)\n    }\n\n    // delete row by PK\n    count, err = dbmap.Delete(&p1)\n    checkErr(err, \"Delete failed\")\n    log.Println(\"Rows deleted:\", count)\n\n    // delete row manually via Exec\n    _, err = dbmap.Exec(\"delete from posts where post_id=?\", p2.Id)\n    checkErr(err, \"Exec failed\")\n\n    // confirm count is zero\n    count, err = dbmap.SelectInt(\"select count(*) from posts\")\n    checkErr(err, \"select count(*) failed\")\n    log.Println(\"Row count - should be zero:\", count)\n\n    log.Println(\"Done!\")\n}\n\ntype Post struct {\n    // db tag lets you specify the column name if it differs from the struct field\n    Id      int64  `db:\"post_id\"`\n    Created int64\n    Title   string `db:\",size:50\"`               // Column size set to 50\n    Body    string `db:\"article_body,size:1024\"` // Set both column name and size\n}\n\nfunc newPost(title, body string) Post {\n    return Post{\n        Created: time.Now().UnixNano(),\n        Title:   title,\n        Body:    body,\n    }\n}\n\nfunc initDb() *gorp.DbMap {\n    // connect to db using standard Go database/sql API\n    // use whatever database/sql driver you wish\n    db, err := sql.Open(\"sqlite3\", \"/tmp/post_db.bin\")\n    checkErr(err, \"sql.Open failed\")\n\n    // construct a gorp DbMap\n    dbmap := &gorp.DbMap{Db: db, Dialect: gorp.SqliteDialect{}}\n\n    // add a table, setting the table name to 'posts' and\n    // specifying that the Id property is an auto incrementing PK\n    dbmap.AddTableWithName(Post{}, \"posts\").SetKeys(true, \"Id\")\n\n    // create the table. in a production system you'd generally\n    // use a migration tool, or create the tables via scripts\n    err = dbmap.CreateTablesIfNotExists()\n    checkErr(err, \"Create tables failed\")\n\n    return dbmap\n}\n\nfunc checkErr(err error, msg string) {\n    if err != nil {\n        log.Fatalln(msg, err)\n    }\n}\n```\n\n## Examples\n\n### Mapping structs to tables\n\nFirst define some types:\n\n```go\ntype Invoice struct {\n    Id       int64\n    Created  int64\n    Updated  int64\n    Memo     string\n    PersonId int64\n}\n\ntype Person struct {\n    Id      int64\n    Created int64\n    Updated int64\n    FName   string\n    LName   string\n}\n\n// Example of using tags to alias fields to column names\n// The 'db' value is the column name\n//\n// A hyphen will cause gorp to skip this field, similar to the\n// Go json package.\n//\n// This is equivalent to using the ColMap methods:\n//\n//   table := dbmap.AddTableWithName(Product{}, \"product\")\n//   table.ColMap(\"Id\").Rename(\"product_id\")\n//   table.ColMap(\"Price\").Rename(\"unit_price\")\n//   table.ColMap(\"IgnoreMe\").SetTransient(true)\n//\n// You can optionally declare the field to be a primary key and/or autoincrement\n//\ntype Product struct {\n    Id         int64     `db:\"product_id, primarykey, autoincrement\"`\n    Price      int64     `db:\"unit_price\"`\n    IgnoreMe   string    `db:\"-\"`\n}\n```\n\nThen create a mapper, typically you'd do this one time at app startup:\n\n```go\n// connect to db using standard Go database/sql API\n// use whatever database/sql driver you wish\ndb, err := sql.Open(\"mymysql\", \"tcp:localhost:3306*mydb/myuser/mypassword\")\n\n// construct a gorp DbMap\ndbmap := &gorp.DbMap{Db: db, Dialect: gorp.MySQLDialect{\"InnoDB\", \"UTF8\"}}\n\n// register the structs you wish to use with gorp\n// you can also use the shorter dbmap.AddTable() if you\n// don't want to override the table name\n//\n// SetKeys(true) means we have a auto increment primary key, which\n// will get automatically bound to your struct post-insert\n//\nt1 := dbmap.AddTableWithName(Invoice{}, \"invoice_test\").SetKeys(true, \"Id\")\nt2 := dbmap.AddTableWithName(Person{}, \"person_test\").SetKeys(true, \"Id\")\nt3 := dbmap.AddTableWithName(Product{}, \"product_test\").SetKeys(true, \"Id\")\n```\n\n### Struct Embedding\n\ngorp supports embedding structs.  For example:\n\n```go\ntype Names struct {\n    FirstName string\n    LastName  string\n}\n\ntype WithEmbeddedStruct struct {\n    Id int64\n    Names\n}\n\nes := &WithEmbeddedStruct{-1, Names{FirstName: \"Alice\", LastName: \"Smith\"}}\nerr := dbmap.Insert(es)\n```\n\nSee the `TestWithEmbeddedStruct` function in `gorp_test.go` for a full example.\n\n### Create/Drop Tables ###\n\nAutomatically create / drop registered tables.  This is useful for unit tests\nbut is entirely optional.  You can of course use gorp with tables created manually,\nor with a separate migration tool (like [sql-migrate](https://github.com/rubenv/sql-migrate), [goose](https://bitbucket.org/liamstask/goose) or [migrate](https://github.com/mattes/migrate)).\n\n```go\n// create all registered tables\ndbmap.CreateTables()\n\n// same as above, but uses \"if not exists\" clause to skip tables that are\n// already defined\ndbmap.CreateTablesIfNotExists()\n\n// drop\ndbmap.DropTables()\n```\n\n### SQL Logging\n\nOptionally you can pass in a logger to trace all SQL statements.\nI recommend enabling this initially while you're getting the feel for what\ngorp is doing on your behalf.\n\nGorp defines a `GorpLogger` interface that Go's built in `log.Logger` satisfies.\nHowever, you can write your own `GorpLogger` implementation, or use a package such\nas `glog` if you want more control over how statements are logged.\n\n```go\n// Will log all SQL statements + args as they are run\n// The first arg is a string prefix to prepend to all log messages\ndbmap.TraceOn(\"[gorp]\", log.New(os.Stdout, \"myapp:\", log.Lmicroseconds))\n\n// Turn off tracing\ndbmap.TraceOff()\n```\n\n### Insert\n\n```go\n// Must declare as pointers so optional callback hooks\n// can operate on your data, not copies\ninv1 := &Invoice{0, 100, 200, \"first order\", 0}\ninv2 := &Invoice{0, 100, 200, \"second order\", 0}\n\n// Insert your rows\nerr := dbmap.Insert(inv1, inv2)\n\n// Because we called SetKeys(true) on Invoice, the Id field\n// will be populated after the Insert() automatically\nfmt.Printf(\"inv1.Id=%d  inv2.Id=%d\\n\", inv1.Id, inv2.Id)\n```\n\n### Update\n\nContinuing the above example, use the `Update` method to modify an Invoice:\n\n```go\n// count is the # of rows updated, which should be 1 in this example\ncount, err := dbmap.Update(inv1)\n```\n\n### Delete\n\nIf you have primary key(s) defined for a struct, you can use the `Delete`\nmethod to remove rows:\n\n```go\ncount, err := dbmap.Delete(inv1)\n```\n\n### Select by Key\n\nUse the `Get` method to fetch a single row by primary key.  It returns\nnil if no row is found.\n\n```go\n// fetch Invoice with Id=99\nobj, err := dbmap.Get(Invoice{}, 99)\ninv := obj.(*Invoice)\n```\n\n### Ad Hoc SQL\n\n#### SELECT\n\n`Select()` and `SelectOne()` provide a simple way to bind arbitrary queries to a slice\nor a single struct.\n\n```go\n// Select a slice - first return value is not needed when a slice pointer is passed to Select()\nvar posts []Post\n_, err := dbmap.Select(&posts, \"select * from post order by id\")\n\n// You can also use primitive types\nvar ids []string\n_, err := dbmap.Select(&ids, \"select id from post\")\n\n// Select a single row.\n// Returns an error if no row found, or if more than one row is found\nvar post Post\nerr := dbmap.SelectOne(&post, \"select * from post where id=?\", id)\n```\n\nWant to do joins?  Just write the SQL and the struct. gorp will bind them:\n\n```go\n// Define a type for your join\n// It *must* contain all the columns in your SELECT statement\n//\n// The names here should match the aliased column names you specify\n// in your SQL - no additional binding work required.  simple.\n//\ntype InvoicePersonView struct {\n    InvoiceId   int64\n    PersonId    int64\n    Memo        string\n    FName       string\n}\n\n// Create some rows\np1 := &Person{0, 0, 0, \"bob\", \"smith\"}\nerr = dbmap.Insert(p1)\ncheckErr(err, \"Insert failed\")\n\n// notice how we can wire up p1.Id to the invoice easily\ninv1 := &Invoice{0, 0, 0, \"xmas order\", p1.Id}\nerr = dbmap.Insert(inv1)\ncheckErr(err, \"Insert failed\")\n\n// Run your query\nquery := \"select i.Id InvoiceId, p.Id PersonId, i.Memo, p.FName \" +\n\t\"from invoice_test i, person_test p \" +\n\t\"where i.PersonId = p.Id\"\n\n// pass a slice to Select()\nvar list []InvoicePersonView\n_, err := dbmap.Select(&list, query)\n\n// this should test true\nexpected := InvoicePersonView{inv1.Id, p1.Id, inv1.Memo, p1.FName}\nif reflect.DeepEqual(list[0], expected) {\n    fmt.Println(\"Woot! My join worked!\")\n}\n```\n\n#### SELECT string or int64\n\ngorp provides a few convenience methods for selecting a single string or int64.\n\n```go\n// select single int64 from db (use $1 instead of ? for postgresql)\ni64, err := dbmap.SelectInt(\"select count(*) from foo where blah=?\", blahVal)\n\n// select single string from db:\ns, err := dbmap.SelectStr(\"select name from foo where blah=?\", blahVal)\n\n```\n\n#### Named bind parameters\n\nYou may use a map or struct to bind parameters by name.  This is currently\nonly supported in SELECT queries.\n\n```go\n_, err := dbm.Select(&dest, \"select * from Foo where name = :name and age = :age\", map[string]interface{}{\n  \"name\": \"Rob\",\n  \"age\": 31,\n})\n```\n\n#### UPDATE / DELETE\n\nYou can execute raw SQL if you wish.  Particularly good for batch operations.\n\n```go\nres, err := dbmap.Exec(\"delete from invoice_test where PersonId=?\", 10)\n```\n\n### Transactions\n\nYou can batch operations into a transaction:\n\n```go\nfunc InsertInv(dbmap *DbMap, inv *Invoice, per *Person) error {\n    // Start a new transaction\n    trans, err := dbmap.Begin()\n    if err != nil {\n        return err\n    }\n\n    err = trans.Insert(per)\n    checkErr(err, \"Insert failed\")\n\n    inv.PersonId = per.Id\n    err = trans.Insert(inv)\n    checkErr(err, \"Insert failed\")\n\n    // if the commit is successful, a nil error is returned\n    return trans.Commit()\n}\n```\n\n### Hooks\n\nUse hooks to update data before/after saving to the db. Good for timestamps:\n\n```go\n// implement the PreInsert and PreUpdate hooks\nfunc (i *Invoice) PreInsert(s gorp.SqlExecutor) error {\n    i.Created = time.Now().UnixNano()\n    i.Updated = i.Created\n    return nil\n}\n\nfunc (i *Invoice) PreUpdate(s gorp.SqlExecutor) error {\n    i.Updated = time.Now().UnixNano()\n    return nil\n}\n\n// You can use the SqlExecutor to cascade additional SQL\n// Take care to avoid cycles. gorp won't prevent them.\n//\n// Here's an example of a cascading delete\n//\nfunc (p *Person) PreDelete(s gorp.SqlExecutor) error {\n    query := \"delete from invoice_test where PersonId=?\"\n    \n    _, err := s.Exec(query, p.Id)\n    \n    if err != nil {\n        return err\n    }\n    return nil\n}\n```\n\nFull list of hooks that you can implement:\n\n    PostGet\n    PreInsert\n    PostInsert\n    PreUpdate\n    PostUpdate\n    PreDelete\n    PostDelete\n\n    All have the same signature.  for example:\n\n    func (p *MyStruct) PostUpdate(s gorp.SqlExecutor) error\n\n### Optimistic Locking\n\n#### Note that this behaviour has changed in v2. See [Migration Guide](#migration-guide).\n\ngorp provides a simple optimistic locking feature, similar to Java's\nJPA, that will raise an error if you try to update/delete a row whose\n`version` column has a value different than the one in memory.  This\nprovides a safe way to do \"select then update\" style operations\nwithout explicit read and write locks.\n\n```go\n// Version is an auto-incremented number, managed by gorp\n// If this property is present on your struct, update\n// operations will be constrained\n//\n// For example, say we defined Person as:\n\ntype Person struct {\n    Id       int64\n    Created  int64\n    Updated  int64\n    FName    string\n    LName    string\n\n    // automatically used as the Version col\n    // use table.SetVersionCol(\"columnName\") to map a different\n    // struct field as the version field\n    Version  int64\n}\n\np1 := &Person{0, 0, 0, \"Bob\", \"Smith\", 0}\nerr = dbmap.Insert(p1)  // Version is now 1\ncheckErr(err, \"Insert failed\")\n\nobj, err := dbmap.Get(Person{}, p1.Id)\np2 := obj.(*Person)\np2.LName = \"Edwards\"\n_,err = dbmap.Update(p2)  // Version is now 2\ncheckErr(err, \"Update failed\")\n\np1.LName = \"Howard\"\n\n// Raises error because p1.Version == 1, which is out of date\ncount, err := dbmap.Update(p1)\n_, ok := err.(gorp.OptimisticLockError)\nif ok {\n    // should reach this statement\n\n    // in a real app you might reload the row and retry, or\n    // you might propegate this to the user, depending on the desired\n    // semantics\n    fmt.Printf(\"Tried to update row with stale data: %v\\n\", err)\n} else {\n    // some other db error occurred - log or return up the stack\n    fmt.Printf(\"Unknown db err: %v\\n\", err)\n}\n```\n### Adding INDEX(es) on column(s) beyond the primary key ###\n\nIndexes are frequently critical for performance. Here is how to add\nthem to your tables.\n\nNB: SqlServer and Oracle need testing and possible adjustment to the\nCreateIndexSuffix() and DropIndexSuffix() methods to make AddIndex()\nwork for them.\n\nIn the example below we put an index both on the Id field, and on the\nAcctId field.\n\n```\ntype Account struct {\n\tId      int64\n\tAcctId  string // e.g. this might be a long uuid for portability\n}\n\n// indexType (the 2nd param to AddIndex call) is \"Btree\" or \"Hash\" for MySQL.\n// demonstrate adding a second index on AcctId, and constrain that field to have unique values.\ndbm.AddTable(iptab.Account{}).SetKeys(true, \"Id\").AddIndex(\"AcctIdIndex\", \"Btree\", []string{\"AcctId\"}).SetUnique(true)\n\nerr = dbm.CreateTablesIfNotExists()\ncheckErr(err, \"CreateTablesIfNotExists failed\")\n\nerr = dbm.CreateIndex()\ncheckErr(err, \"CreateIndex failed\")\n\n```\nCheck the effect of the CreateIndex() call in mysql:\n```\n$ mysql\n\nMariaDB [test]> show create table Account;\n+---------+--------------------------+\n| Account | CREATE TABLE `Account` (\n  `Id` bigint(20) NOT NULL AUTO_INCREMENT,\n  `AcctId` varchar(255) DEFAULT NULL,\n  PRIMARY KEY (`Id`),\n  UNIQUE KEY `AcctIdIndex` (`AcctId`) USING BTREE   <<<--- yes! index added.\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 \n+---------+--------------------------+\n\n```\n\n\n## Database Drivers\n\ngorp uses the Go 1 `database/sql` package.  A full list of compliant\ndrivers is available here:\n\nhttp://code.google.com/p/go-wiki/wiki/SQLDrivers\n\nSadly, SQL databases differ on various issues. gorp provides a Dialect\ninterface that should be implemented per database vendor.  Dialects\nare provided for:\n\n* MySQL\n* PostgreSQL\n* sqlite3\n\nEach of these three databases pass the test suite.  See `gorp_test.go`\nfor example DSNs for these three databases.\n\nSupport is also provided for:\n\n* Oracle (contributed by @klaidliadon)\n* SQL Server (contributed by @qrawl) - use driver:\n  github.com/denisenkom/go-mssqldb\n\nNote that these databases are not covered by CI and I (@coopernurse)\nhave no good way to test them locally.  So please try them and send\npatches as needed, but expect a bit more unpredicability.\n\n## Sqlite3 Extensions\n\nIn order to use sqlite3 extensions you need to first register a custom driver:\n\n```go\nimport (\n\t\"database/sql\"\n\n\t// use whatever database/sql driver you wish\n\tsqlite \"github.com/mattn/go-sqlite3\"\n)\n\nfunc customDriver() (*sql.DB, error) {\n\n\t// create custom driver with extensions defined\n\tsql.Register(\"sqlite3-custom\", &sqlite.SQLiteDriver{\n\t\tExtensions: []string{\n\t\t\t\"mod_spatialite\",\n\t\t},\n\t})\n\n\t// now you can then connect using the 'sqlite3-custom' driver instead of 'sqlite3'\n\treturn sql.Open(\"sqlite3-custom\", \"/tmp/post_db.bin\")\n}\n```\n\n## Known Issues\n\n### SQL placeholder portability\n\nDifferent databases use different strings to indicate variable\nplaceholders in prepared SQL statements.  Unlike some database\nabstraction layers (such as JDBC), Go's `database/sql` does not\nstandardize this.\n\nSQL generated by gorp in the `Insert`, `Update`, `Delete`, and `Get`\nmethods delegates to a Dialect implementation for each database, and\nwill generate portable SQL.\n\nRaw SQL strings passed to `Exec`, `Select`, `SelectOne`, `SelectInt`,\netc will not be parsed.  Consequently you may have portability issues\nif you write a query like this:\n\n```go \n// works on MySQL and Sqlite3, but not with Postgresql err :=\ndbmap.SelectOne(&val, \"select * from foo where id = ?\", 30)\n```\n\nIn `Select` and `SelectOne` you can use named parameters to work\naround this.  The following is portable:\n\n```go \nerr := dbmap.SelectOne(&val, \"select * from foo where id = :id\",\nmap[string]interface{} { \"id\": 30})\n```\n\nAdditionally, when using Postgres as your database, you should utilize\n`$1` instead of `?` placeholders as utilizing `?` placeholders when\nquerying Postgres will result in `pq: operator does not exist`\nerrors. Alternatively, use `dbMap.Dialect.BindVar(varIdx)` to get the\nproper variable binding for your dialect.\n\n### time.Time and time zones\n\ngorp will pass `time.Time` fields through to the `database/sql`\ndriver, but note that the behavior of this type varies across database\ndrivers.\n\nMySQL users should be especially cautious.  See:\nhttps://github.com/ziutek/mymysql/pull/77\n\nTo avoid any potential issues with timezone/DST, consider:\n\n- Using an integer field for time data and storing UNIX time.\n- Using a custom time type that implements some SQL types:\n  - [`\"database/sql\".Scanner`](https://golang.org/pkg/database/sql/#Scanner)\n  - [`\"database/sql/driver\".Valuer`](https://golang.org/pkg/database/sql/driver/#Valuer)\n\n## Running the tests\n\nThe included tests may be run against MySQL, Postgresql, or sqlite3.\nYou must set two environment variables so the test code knows which\ndriver to use, and how to connect to your database.\n\n```sh\n# MySQL example:\nexport GORP_TEST_DSN=gomysql_test/gomysql_test/abc123\nexport GORP_TEST_DIALECT=mysql\n\n# run the tests\ngo test\n\n# run the tests and benchmarks\ngo test -bench=\"Bench\" -benchtime 10\n```\n\nValid `GORP_TEST_DIALECT` values are: \"mysql\"(for mymysql),\n\"gomysql\"(for go-sql-driver), \"postgres\", \"sqlite\" See the\n`test_all.sh` script for examples of all 3 databases.  This is the\nscript I run locally to test the library.\n\n## Performance\n\ngorp uses reflection to construct SQL queries and bind parameters.\nSee the BenchmarkNativeCrud vs BenchmarkGorpCrud in gorp_test.go for a\nsimple perf test.  On my MacBook Pro gorp is about 2-3% slower than\nhand written SQL.\n\n\n## Contributors\n\n* matthias-margush - column aliasing via tags\n* Rob Figueiredo - @robfig\n* Quinn Slack - @sqs\n"
        },
        {
          "name": "column.go",
          "type": "blob",
          "size": 2,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage gorp\n\nimport \"reflect\"\n\n// ColumnMap represents a mapping between a Go struct field and a single\n// column in a table.\n// Unique and MaxSize only inform the\n// CreateTables() function and are not used by Insert/Update/Delete/Get.\ntype ColumnMap struct {\n\t// Column name in db table\n\tColumnName string\n\n\t// If true, this column is skipped in generated SQL statements\n\tTransient bool\n\n\t// If true, \" unique\" is added to create table statements.\n\t// Not used elsewhere\n\tUnique bool\n\n\t// Query used for getting generated id after insert\n\tGeneratedIdQuery string\n\n\t// Passed to Dialect.ToSqlType() to assist in informing the\n\t// correct column type to map to in CreateTables()\n\tMaxSize int\n\n\tDefaultValue string\n\n\tfieldName  string\n\tgotype     reflect.Type\n\tisPK       bool\n\tisAutoIncr bool\n\tisNotNull  bool\n}\n\n// Rename allows you to specify the column name in the table\n//\n// Example:  table.ColMap(\"Updated\").Rename(\"date_updated\")\n//\nfunc (c *ColumnMap) Rename(colname string) *ColumnMap {\n\tc.ColumnName = colname\n\treturn c\n}\n\n// SetTransient allows you to mark the column as transient. If true\n// this column will be skipped when SQL statements are generated\nfunc (c *ColumnMap) SetTransient(b bool) *ColumnMap {\n\tc.Transient = b\n\treturn c\n}\n\n// SetUnique adds \"unique\" to the create table statements for this\n// column, if b is true.\nfunc (c *ColumnMap) SetUnique(b bool) *ColumnMap {\n\tc.Unique = b\n\treturn c\n}\n\n// SetNotNull adds \"not null\" to the create table statements for this\n// column, if nn is true.\nfunc (c *ColumnMap) SetNotNull(nn bool) *ColumnMap {\n\tc.isNotNull = nn\n\treturn c\n}\n\n// SetMaxSize specifies the max length of values of this column. This is\n// passed to the dialect.ToSqlType() function, which can use the value\n// to alter the generated type for \"create table\" statements\nfunc (c *ColumnMap) SetMaxSize(size int) *ColumnMap {\n\tc.MaxSize = size\n\treturn c\n}\n"
        },
        {
          "name": "context_test.go",
          "type": "blob",
          "size": 1.8955078125,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\n//go:build integration\n// +build integration\n\npackage gorp_test\n\nimport (\n\t\"context\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\n// Drivers that don't support cancellation.\nvar unsupportedDrivers map[string]bool = map[string]bool{\n\t\"mymysql\": true,\n}\n\ntype SleepDialect interface {\n\t// string to sleep for d duration\n\tSleepClause(d time.Duration) string\n}\n\nfunc TestWithNotCanceledContext(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tctx, cancel := context.WithTimeout(context.Background(), 100*time.Millisecond)\n\tdefer cancel()\n\n\twithCtx := dbmap.WithContext(ctx)\n\n\t_, err := withCtx.Exec(\"SELECT 1\")\n\tassert.Nil(t, err)\n}\n\nfunc TestWithCanceledContext(t *testing.T) {\n\tdialect, driver := dialectAndDriver()\n\tif unsupportedDrivers[driver] {\n\t\tt.Skipf(\"Cancellation is not yet supported by all drivers. Not known to be supported in %s.\", driver)\n\t}\n\n\tsleepDialect, ok := dialect.(SleepDialect)\n\tif !ok {\n\t\tt.Skipf(\"Sleep is not supported in all dialects. Not known to be supported in %s.\", driver)\n\t}\n\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tctx, cancel := context.WithTimeout(context.Background(), 100*time.Millisecond)\n\tdefer cancel()\n\n\twithCtx := dbmap.WithContext(ctx)\n\n\tstartTime := time.Now()\n\n\t_, err := withCtx.Exec(\"SELECT \" + sleepDialect.SleepClause(1*time.Second))\n\n\tif d := time.Since(startTime); d > 500*time.Millisecond {\n\t\tt.Errorf(\"too long execution time: %s\", d)\n\t}\n\n\tswitch driver {\n\tcase \"postgres\":\n\t\t// pq doesn't return standard deadline exceeded error\n\t\tif err.Error() != \"pq: canceling statement due to user request\" {\n\t\t\tt.Errorf(\"expected context.DeadlineExceeded, got %v\", err)\n\t\t}\n\tdefault:\n\t\tif err != context.DeadlineExceeded {\n\t\t\tt.Errorf(\"expected context.DeadlineExceeded, got %v\", err)\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "db.go",
          "type": "blob",
          "size": 27.6552734375,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage gorp\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"database/sql\"\n\t\"database/sql/driver\"\n\t\"errors\"\n\t\"fmt\"\n\t\"log\"\n\t\"reflect\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n)\n\n// DbMap is the root gorp mapping object. Create one of these for each\n// database schema you wish to map.  Each DbMap contains a list of\n// mapped tables.\n//\n// Example:\n//\n//     dialect := gorp.MySQLDialect{\"InnoDB\", \"UTF8\"}\n//     dbmap := &gorp.DbMap{Db: db, Dialect: dialect}\n//\ntype DbMap struct {\n\tctx context.Context\n\n\t// Db handle to use with this map\n\tDb *sql.DB\n\n\t// Dialect implementation to use with this map\n\tDialect Dialect\n\n\tTypeConverter TypeConverter\n\n\t// ExpandSlices when enabled will convert slice arguments in mappers into flat\n\t// values. It will modify the query, adding more placeholders, and the mapper,\n\t// adding each item of the slice as a new unique entry in the mapper. For\n\t// example, given the scenario bellow:\n\t//\n\t//     dbmap.Select(&output, \"SELECT 1 FROM example WHERE id IN (:IDs)\", map[string]interface{}{\n\t//       \"IDs\": []int64{1, 2, 3},\n\t//     })\n\t//\n\t// The executed query would be:\n\t//\n\t//     SELECT 1 FROM example WHERE id IN (:IDs0,:IDs1,:IDs2)\n\t//\n\t// With the mapper:\n\t//\n\t//     map[string]interface{}{\n\t//       \"IDs\":  []int64{1, 2, 3},\n\t//       \"IDs0\": int64(1),\n\t//       \"IDs1\": int64(2),\n\t//       \"IDs2\": int64(3),\n\t//     }\n\t//\n\t// It is also flexible for custom slice types. The value just need to\n\t// implement stringer or numberer interfaces.\n\t//\n\t//     type CustomValue string\n\t//\n\t//     const (\n\t//       CustomValueHey CustomValue = \"hey\"\n\t//       CustomValueOh  CustomValue = \"oh\"\n\t//     )\n\t//\n\t//     type CustomValues []CustomValue\n\t//\n\t//     func (c CustomValues) ToStringSlice() []string {\n\t//       values := make([]string, len(c))\n\t//       for i := range c {\n\t//         values[i] = string(c[i])\n\t//       }\n\t//       return values\n\t//     }\n\t//\n\t//     func query() {\n\t//       // ...\n\t//       result, err := dbmap.Select(&output, \"SELECT 1 FROM example WHERE value IN (:Values)\", map[string]interface{}{\n\t//         \"Values\": CustomValues([]CustomValue{CustomValueHey}),\n\t//       })\n\t//       // ...\n\t//     }\n\tExpandSliceArgs bool\n\n\ttables        []*TableMap\n\ttablesDynamic map[string]*TableMap // tables that use same go-struct and different db table names\n\tlogger        GorpLogger\n\tlogPrefix     string\n}\n\nfunc (m *DbMap) dynamicTableAdd(tableName string, tbl *TableMap) {\n\tif m.tablesDynamic == nil {\n\t\tm.tablesDynamic = make(map[string]*TableMap)\n\t}\n\tm.tablesDynamic[tableName] = tbl\n}\n\nfunc (m *DbMap) dynamicTableFind(tableName string) (*TableMap, bool) {\n\tif m.tablesDynamic == nil {\n\t\treturn nil, false\n\t}\n\ttbl, found := m.tablesDynamic[tableName]\n\treturn tbl, found\n}\n\nfunc (m *DbMap) dynamicTableMap() map[string]*TableMap {\n\tif m.tablesDynamic == nil {\n\t\tm.tablesDynamic = make(map[string]*TableMap)\n\t}\n\treturn m.tablesDynamic\n}\n\nfunc (m *DbMap) WithContext(ctx context.Context) SqlExecutor {\n\tcopy := &DbMap{}\n\t*copy = *m\n\tcopy.ctx = ctx\n\treturn copy\n}\n\nfunc (m *DbMap) CreateIndex() error {\n\tvar err error\n\tdialect := reflect.TypeOf(m.Dialect)\n\tfor _, table := range m.tables {\n\t\tfor _, index := range table.indexes {\n\t\t\terr = m.createIndexImpl(dialect, table, index)\n\t\t\tif err != nil {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, table := range m.dynamicTableMap() {\n\t\tfor _, index := range table.indexes {\n\t\t\terr = m.createIndexImpl(dialect, table, index)\n\t\t\tif err != nil {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\treturn err\n}\n\nfunc (m *DbMap) createIndexImpl(dialect reflect.Type,\n\ttable *TableMap,\n\tindex *IndexMap) error {\n\ts := bytes.Buffer{}\n\ts.WriteString(\"create\")\n\tif index.Unique {\n\t\ts.WriteString(\" unique\")\n\t}\n\ts.WriteString(\" index\")\n\ts.WriteString(fmt.Sprintf(\" %s on %s\", index.IndexName, table.TableName))\n\tif dname := dialect.Name(); dname == \"PostgresDialect\" && index.IndexType != \"\" {\n\t\ts.WriteString(fmt.Sprintf(\" %s %s\", m.Dialect.CreateIndexSuffix(), index.IndexType))\n\t}\n\ts.WriteString(\" (\")\n\tfor x, col := range index.columns {\n\t\tif x > 0 {\n\t\t\ts.WriteString(\", \")\n\t\t}\n\t\ts.WriteString(m.Dialect.QuoteField(col))\n\t}\n\ts.WriteString(\")\")\n\n\tif dname := dialect.Name(); dname == \"MySQLDialect\" && index.IndexType != \"\" {\n\t\ts.WriteString(fmt.Sprintf(\" %s %s\", m.Dialect.CreateIndexSuffix(), index.IndexType))\n\t}\n\ts.WriteString(\";\")\n\t_, err := m.Exec(s.String())\n\treturn err\n}\n\nfunc (t *TableMap) DropIndex(name string) error {\n\n\tvar err error\n\tdialect := reflect.TypeOf(t.dbmap.Dialect)\n\tfor _, idx := range t.indexes {\n\t\tif idx.IndexName == name {\n\t\t\ts := bytes.Buffer{}\n\t\t\ts.WriteString(fmt.Sprintf(\"DROP INDEX %s\", idx.IndexName))\n\n\t\t\tif dname := dialect.Name(); dname == \"MySQLDialect\" {\n\t\t\t\ts.WriteString(fmt.Sprintf(\" %s %s\", t.dbmap.Dialect.DropIndexSuffix(), t.TableName))\n\t\t\t}\n\t\t\ts.WriteString(\";\")\n\t\t\t_, e := t.dbmap.Exec(s.String())\n\t\t\tif e != nil {\n\t\t\t\terr = e\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t}\n\tt.ResetSql()\n\treturn err\n}\n\n// AddTable registers the given interface type with gorp. The table name\n// will be given the name of the TypeOf(i).  You must call this function,\n// or AddTableWithName, for any struct type you wish to persist with\n// the given DbMap.\n//\n// This operation is idempotent. If i's type is already mapped, the\n// existing *TableMap is returned\nfunc (m *DbMap) AddTable(i interface{}) *TableMap {\n\treturn m.AddTableWithName(i, \"\")\n}\n\n// AddTableWithName has the same behavior as AddTable, but sets\n// table.TableName to name.\nfunc (m *DbMap) AddTableWithName(i interface{}, name string) *TableMap {\n\treturn m.AddTableWithNameAndSchema(i, \"\", name)\n}\n\n// AddTableWithNameAndSchema has the same behavior as AddTable, but sets\n// table.TableName to name.\nfunc (m *DbMap) AddTableWithNameAndSchema(i interface{}, schema string, name string) *TableMap {\n\tt := reflect.TypeOf(i)\n\tif name == \"\" {\n\t\tname = t.Name()\n\t}\n\n\t// check if we have a table for this type already\n\t// if so, update the name and return the existing pointer\n\tfor i := range m.tables {\n\t\ttable := m.tables[i]\n\t\tif table.gotype == t {\n\t\t\ttable.TableName = name\n\t\t\treturn table\n\t\t}\n\t}\n\n\ttmap := &TableMap{gotype: t, TableName: name, SchemaName: schema, dbmap: m}\n\tvar primaryKey []*ColumnMap\n\ttmap.Columns, primaryKey = m.readStructColumns(t)\n\tm.tables = append(m.tables, tmap)\n\tif len(primaryKey) > 0 {\n\t\ttmap.keys = append(tmap.keys, primaryKey...)\n\t}\n\n\treturn tmap\n}\n\n// AddTableDynamic registers the given interface type with gorp.\n// The table name will be dynamically determined at runtime by\n// using the GetTableName method on DynamicTable interface\nfunc (m *DbMap) AddTableDynamic(inp DynamicTable, schema string) *TableMap {\n\n\tval := reflect.ValueOf(inp)\n\telm := val.Elem()\n\tt := elm.Type()\n\tname := inp.TableName()\n\tif name == \"\" {\n\t\tpanic(\"Missing table name in DynamicTable instance\")\n\t}\n\n\t// Check if there is another dynamic table with the same name\n\tif _, found := m.dynamicTableFind(name); found {\n\t\tpanic(fmt.Sprintf(\"A table with the same name %v already exists\", name))\n\t}\n\n\ttmap := &TableMap{gotype: t, TableName: name, SchemaName: schema, dbmap: m}\n\tvar primaryKey []*ColumnMap\n\ttmap.Columns, primaryKey = m.readStructColumns(t)\n\tif len(primaryKey) > 0 {\n\t\ttmap.keys = append(tmap.keys, primaryKey...)\n\t}\n\n\tm.dynamicTableAdd(name, tmap)\n\n\treturn tmap\n}\n\nfunc (m *DbMap) readStructColumns(t reflect.Type) (cols []*ColumnMap, primaryKey []*ColumnMap) {\n\tprimaryKey = make([]*ColumnMap, 0)\n\tn := t.NumField()\n\tfor i := 0; i < n; i++ {\n\t\tf := t.Field(i)\n\t\tif f.Anonymous && f.Type.Kind() == reflect.Struct {\n\t\t\t// Recursively add nested fields in embedded structs.\n\t\t\tsubcols, subpk := m.readStructColumns(f.Type)\n\t\t\t// Don't append nested fields that have the same field\n\t\t\t// name as an already-mapped field.\n\t\t\tfor _, subcol := range subcols {\n\t\t\t\tshouldAppend := true\n\t\t\t\tfor _, col := range cols {\n\t\t\t\t\tif !subcol.Transient && subcol.fieldName == col.fieldName {\n\t\t\t\t\t\tshouldAppend = false\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif shouldAppend {\n\t\t\t\t\tcols = append(cols, subcol)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif subpk != nil {\n\t\t\t\tprimaryKey = append(primaryKey, subpk...)\n\t\t\t}\n\t\t} else {\n\t\t\t// Tag = Name { ','  Option }\n\t\t\t// Option = OptionKey [ ':' OptionValue ]\n\t\t\tcArguments := strings.Split(f.Tag.Get(\"db\"), \",\")\n\t\t\tcolumnName := cArguments[0]\n\t\t\tvar maxSize int\n\t\t\tvar defaultValue string\n\t\t\tvar isAuto bool\n\t\t\tvar isPK bool\n\t\t\tvar isNotNull bool\n\t\t\tfor _, argString := range cArguments[1:] {\n\t\t\t\targString = strings.TrimSpace(argString)\n\t\t\t\targ := strings.SplitN(argString, \":\", 2)\n\n\t\t\t\t// check mandatory/unexpected option values\n\t\t\t\tswitch arg[0] {\n\t\t\t\tcase \"size\", \"default\":\n\t\t\t\t\t// options requiring value\n\t\t\t\t\tif len(arg) == 1 {\n\t\t\t\t\t\tpanic(fmt.Sprintf(\"missing option value for option %v on field %v\", arg[0], f.Name))\n\t\t\t\t\t}\n\t\t\t\tdefault:\n\t\t\t\t\t// options where value is invalid (currently all other options)\n\t\t\t\t\tif len(arg) == 2 {\n\t\t\t\t\t\tpanic(fmt.Sprintf(\"unexpected option value for option %v on field %v\", arg[0], f.Name))\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tswitch arg[0] {\n\t\t\t\tcase \"size\":\n\t\t\t\t\tmaxSize, _ = strconv.Atoi(arg[1])\n\t\t\t\tcase \"default\":\n\t\t\t\t\tdefaultValue = arg[1]\n\t\t\t\tcase \"primarykey\":\n\t\t\t\t\tisPK = true\n\t\t\t\tcase \"autoincrement\":\n\t\t\t\t\tisAuto = true\n\t\t\t\tcase \"notnull\":\n\t\t\t\t\tisNotNull = true\n\t\t\t\tdefault:\n\t\t\t\t\tpanic(fmt.Sprintf(\"Unrecognized tag option for field %v: %v\", f.Name, arg))\n\t\t\t\t}\n\t\t\t}\n\t\t\tif columnName == \"\" {\n\t\t\t\tcolumnName = f.Name\n\t\t\t}\n\n\t\t\tgotype := f.Type\n\t\t\tvalueType := gotype\n\t\t\tif valueType.Kind() == reflect.Ptr {\n\t\t\t\tvalueType = valueType.Elem()\n\t\t\t}\n\t\t\tvalue := reflect.New(valueType).Interface()\n\t\t\tif m.TypeConverter != nil {\n\t\t\t\t// Make a new pointer to a value of type gotype and\n\t\t\t\t// pass it to the TypeConverter's FromDb method to see\n\t\t\t\t// if a different type should be used for the column\n\t\t\t\t// type during table creation.\n\t\t\t\tscanner, useHolder := m.TypeConverter.FromDb(value)\n\t\t\t\tif useHolder {\n\t\t\t\t\tvalue = scanner.Holder\n\t\t\t\t\tgotype = reflect.TypeOf(value)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif typer, ok := value.(SqlTyper); ok {\n\t\t\t\tgotype = reflect.TypeOf(typer.SqlType())\n\t\t\t} else if typer, ok := value.(legacySqlTyper); ok {\n\t\t\t\tlog.Printf(\"Deprecation Warning: update your SqlType methods to return a driver.Value\")\n\t\t\t\tgotype = reflect.TypeOf(typer.SqlType())\n\t\t\t} else if valuer, ok := value.(driver.Valuer); ok {\n\t\t\t\t// Only check for driver.Valuer if SqlTyper wasn't\n\t\t\t\t// found.\n\t\t\t\tv, err := valuer.Value()\n\t\t\t\tif err == nil && v != nil {\n\t\t\t\t\tgotype = reflect.TypeOf(v)\n\t\t\t\t}\n\t\t\t}\n\t\t\tcm := &ColumnMap{\n\t\t\t\tColumnName:   columnName,\n\t\t\t\tDefaultValue: defaultValue,\n\t\t\t\tTransient:    columnName == \"-\",\n\t\t\t\tfieldName:    f.Name,\n\t\t\t\tgotype:       gotype,\n\t\t\t\tisPK:         isPK,\n\t\t\t\tisAutoIncr:   isAuto,\n\t\t\t\tisNotNull:    isNotNull,\n\t\t\t\tMaxSize:      maxSize,\n\t\t\t}\n\t\t\tif isPK {\n\t\t\t\tprimaryKey = append(primaryKey, cm)\n\t\t\t}\n\t\t\t// Check for nested fields of the same field name and\n\t\t\t// override them.\n\t\t\tshouldAppend := true\n\t\t\tfor index, col := range cols {\n\t\t\t\tif !col.Transient && col.fieldName == cm.fieldName {\n\t\t\t\t\tcols[index] = cm\n\t\t\t\t\tshouldAppend = false\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif shouldAppend {\n\t\t\t\tcols = append(cols, cm)\n\t\t\t}\n\t\t}\n\n\t}\n\treturn\n}\n\n// CreateTables iterates through TableMaps registered to this DbMap and\n// executes \"create table\" statements against the database for each.\n//\n// This is particularly useful in unit tests where you want to create\n// and destroy the schema automatically.\nfunc (m *DbMap) CreateTables() error {\n\treturn m.createTables(false)\n}\n\n// CreateTablesIfNotExists is similar to CreateTables, but starts\n// each statement with \"create table if not exists\" so that existing\n// tables do not raise errors\nfunc (m *DbMap) CreateTablesIfNotExists() error {\n\treturn m.createTables(true)\n}\n\nfunc (m *DbMap) createTables(ifNotExists bool) error {\n\tvar err error\n\tfor i := range m.tables {\n\t\ttable := m.tables[i]\n\t\tsql := table.SqlForCreate(ifNotExists)\n\t\t_, err = m.Exec(sql)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tfor _, tbl := range m.dynamicTableMap() {\n\t\tsql := tbl.SqlForCreate(ifNotExists)\n\t\t_, err = m.Exec(sql)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn err\n}\n\n// DropTable drops an individual table.\n// Returns an error when the table does not exist.\nfunc (m *DbMap) DropTable(table interface{}) error {\n\tt := reflect.TypeOf(table)\n\n\ttableName := \"\"\n\tif dyn, ok := table.(DynamicTable); ok {\n\t\ttableName = dyn.TableName()\n\t}\n\n\treturn m.dropTable(t, tableName, false)\n}\n\n// DropTableIfExists drops an individual table when the table exists.\nfunc (m *DbMap) DropTableIfExists(table interface{}) error {\n\tt := reflect.TypeOf(table)\n\n\ttableName := \"\"\n\tif dyn, ok := table.(DynamicTable); ok {\n\t\ttableName = dyn.TableName()\n\t}\n\n\treturn m.dropTable(t, tableName, true)\n}\n\n// DropTables iterates through TableMaps registered to this DbMap and\n// executes \"drop table\" statements against the database for each.\nfunc (m *DbMap) DropTables() error {\n\treturn m.dropTables(false)\n}\n\n// DropTablesIfExists is the same as DropTables, but uses the \"if exists\" clause to\n// avoid errors for tables that do not exist.\nfunc (m *DbMap) DropTablesIfExists() error {\n\treturn m.dropTables(true)\n}\n\n// Goes through all the registered tables, dropping them one by one.\n// If an error is encountered, then it is returned and the rest of\n// the tables are not dropped.\nfunc (m *DbMap) dropTables(addIfExists bool) (err error) {\n\tfor _, table := range m.tables {\n\t\terr = m.dropTableImpl(table, addIfExists)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tfor _, table := range m.dynamicTableMap() {\n\t\terr = m.dropTableImpl(table, addIfExists)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn err\n}\n\n// Implementation of dropping a single table.\nfunc (m *DbMap) dropTable(t reflect.Type, name string, addIfExists bool) error {\n\ttable := tableOrNil(m, t, name)\n\tif table == nil {\n\t\treturn fmt.Errorf(\"table %s was not registered\", table.TableName)\n\t}\n\n\treturn m.dropTableImpl(table, addIfExists)\n}\n\nfunc (m *DbMap) dropTableImpl(table *TableMap, ifExists bool) (err error) {\n\ttableDrop := \"drop table\"\n\tif ifExists {\n\t\ttableDrop = m.Dialect.IfTableExists(tableDrop, table.SchemaName, table.TableName)\n\t}\n\t_, err = m.Exec(fmt.Sprintf(\"%s %s;\", tableDrop, m.Dialect.QuotedTableForQuery(table.SchemaName, table.TableName)))\n\treturn err\n}\n\n// TruncateTables iterates through TableMaps registered to this DbMap and\n// executes \"truncate table\" statements against the database for each, or in the case of\n// sqlite, a \"delete from\" with no \"where\" clause, which uses the truncate optimization\n// (http://www.sqlite.org/lang_delete.html)\nfunc (m *DbMap) TruncateTables() error {\n\tvar err error\n\tfor i := range m.tables {\n\t\ttable := m.tables[i]\n\t\t_, e := m.Exec(fmt.Sprintf(\"%s %s;\", m.Dialect.TruncateClause(), m.Dialect.QuotedTableForQuery(table.SchemaName, table.TableName)))\n\t\tif e != nil {\n\t\t\terr = e\n\t\t}\n\t}\n\n\tfor _, table := range m.dynamicTableMap() {\n\t\t_, e := m.Exec(fmt.Sprintf(\"%s %s;\", m.Dialect.TruncateClause(), m.Dialect.QuotedTableForQuery(table.SchemaName, table.TableName)))\n\t\tif e != nil {\n\t\t\terr = e\n\t\t}\n\t}\n\n\treturn err\n}\n\n// Insert runs a SQL INSERT statement for each element in list.  List\n// items must be pointers.\n//\n// Any interface whose TableMap has an auto-increment primary key will\n// have its last insert id bound to the PK field on the struct.\n//\n// The hook functions PreInsert() and/or PostInsert() will be executed\n// before/after the INSERT statement if the interface defines them.\n//\n// Panics if any interface in the list has not been registered with AddTable\nfunc (m *DbMap) Insert(list ...interface{}) error {\n\treturn insert(m, m, list...)\n}\n\n// Update runs a SQL UPDATE statement for each element in list.  List\n// items must be pointers.\n//\n// The hook functions PreUpdate() and/or PostUpdate() will be executed\n// before/after the UPDATE statement if the interface defines them.\n//\n// Returns the number of rows updated.\n//\n// Returns an error if SetKeys has not been called on the TableMap\n// Panics if any interface in the list has not been registered with AddTable\nfunc (m *DbMap) Update(list ...interface{}) (int64, error) {\n\treturn update(m, m, nil, list...)\n}\n\n// UpdateColumns runs a SQL UPDATE statement for each element in list.  List\n// items must be pointers.\n//\n// Only the columns accepted by filter are included in the UPDATE.\n//\n// The hook functions PreUpdate() and/or PostUpdate() will be executed\n// before/after the UPDATE statement if the interface defines them.\n//\n// Returns the number of rows updated.\n//\n// Returns an error if SetKeys has not been called on the TableMap\n// Panics if any interface in the list has not been registered with AddTable\nfunc (m *DbMap) UpdateColumns(filter ColumnFilter, list ...interface{}) (int64, error) {\n\treturn update(m, m, filter, list...)\n}\n\n// Delete runs a SQL DELETE statement for each element in list.  List\n// items must be pointers.\n//\n// The hook functions PreDelete() and/or PostDelete() will be executed\n// before/after the DELETE statement if the interface defines them.\n//\n// Returns the number of rows deleted.\n//\n// Returns an error if SetKeys has not been called on the TableMap\n// Panics if any interface in the list has not been registered with AddTable\nfunc (m *DbMap) Delete(list ...interface{}) (int64, error) {\n\treturn delete(m, m, list...)\n}\n\n// Get runs a SQL SELECT to fetch a single row from the table based on the\n// primary key(s)\n//\n// i should be an empty value for the struct to load.  keys should be\n// the primary key value(s) for the row to load.  If multiple keys\n// exist on the table, the order should match the column order\n// specified in SetKeys() when the table mapping was defined.\n//\n// The hook function PostGet() will be executed after the SELECT\n// statement if the interface defines them.\n//\n// Returns a pointer to a struct that matches or nil if no row is found.\n//\n// Returns an error if SetKeys has not been called on the TableMap\n// Panics if any interface in the list has not been registered with AddTable\nfunc (m *DbMap) Get(i interface{}, keys ...interface{}) (interface{}, error) {\n\treturn get(m, m, i, keys...)\n}\n\n// Select runs an arbitrary SQL query, binding the columns in the result\n// to fields on the struct specified by i.  args represent the bind\n// parameters for the SQL statement.\n//\n// Column names on the SELECT statement should be aliased to the field names\n// on the struct i. Returns an error if one or more columns in the result\n// do not match.  It is OK if fields on i are not part of the SQL\n// statement.\n//\n// The hook function PostGet() will be executed after the SELECT\n// statement if the interface defines them.\n//\n// Values are returned in one of two ways:\n// 1. If i is a struct or a pointer to a struct, returns a slice of pointers to\n// matching rows of type i.\n// 2. If i is a pointer to a slice, the results will be appended to that slice\n// and nil returned.\n//\n// i does NOT need to be registered with AddTable()\nfunc (m *DbMap) Select(i interface{}, query string, args ...interface{}) ([]interface{}, error) {\n\tif m.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\treturn hookedselect(m, m, i, query, args...)\n}\n\n// Exec runs an arbitrary SQL statement.  args represent the bind parameters.\n// This is equivalent to running:  Exec() using database/sql\nfunc (m *DbMap) Exec(query string, args ...interface{}) (sql.Result, error) {\n\tif m.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\tif m.logger != nil {\n\t\tnow := time.Now()\n\t\tdefer m.trace(now, query, args...)\n\t}\n\treturn maybeExpandNamedQueryAndExec(m, query, args...)\n}\n\n// SelectInt is a convenience wrapper around the gorp.SelectInt function\nfunc (m *DbMap) SelectInt(query string, args ...interface{}) (int64, error) {\n\tif m.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\treturn SelectInt(m, query, args...)\n}\n\n// SelectNullInt is a convenience wrapper around the gorp.SelectNullInt function\nfunc (m *DbMap) SelectNullInt(query string, args ...interface{}) (sql.NullInt64, error) {\n\tif m.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\treturn SelectNullInt(m, query, args...)\n}\n\n// SelectFloat is a convenience wrapper around the gorp.SelectFloat function\nfunc (m *DbMap) SelectFloat(query string, args ...interface{}) (float64, error) {\n\tif m.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\treturn SelectFloat(m, query, args...)\n}\n\n// SelectNullFloat is a convenience wrapper around the gorp.SelectNullFloat function\nfunc (m *DbMap) SelectNullFloat(query string, args ...interface{}) (sql.NullFloat64, error) {\n\tif m.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\treturn SelectNullFloat(m, query, args...)\n}\n\n// SelectStr is a convenience wrapper around the gorp.SelectStr function\nfunc (m *DbMap) SelectStr(query string, args ...interface{}) (string, error) {\n\tif m.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\treturn SelectStr(m, query, args...)\n}\n\n// SelectNullStr is a convenience wrapper around the gorp.SelectNullStr function\nfunc (m *DbMap) SelectNullStr(query string, args ...interface{}) (sql.NullString, error) {\n\tif m.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\treturn SelectNullStr(m, query, args...)\n}\n\n// SelectOne is a convenience wrapper around the gorp.SelectOne function\nfunc (m *DbMap) SelectOne(holder interface{}, query string, args ...interface{}) error {\n\tif m.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\treturn SelectOne(m, m, holder, query, args...)\n}\n\n// Begin starts a gorp Transaction\nfunc (m *DbMap) Begin() (*Transaction, error) {\n\tif m.logger != nil {\n\t\tnow := time.Now()\n\t\tdefer m.trace(now, \"begin;\")\n\t}\n\ttx, err := begin(m)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &Transaction{\n\t\tdbmap:  m,\n\t\ttx:     tx,\n\t\tclosed: false,\n\t}, nil\n}\n\n// TableFor returns the *TableMap corresponding to the given Go Type\n// If no table is mapped to that type an error is returned.\n// If checkPK is true and the mapped table has no registered PKs, an error is returned.\nfunc (m *DbMap) TableFor(t reflect.Type, checkPK bool) (*TableMap, error) {\n\ttable := tableOrNil(m, t, \"\")\n\tif table == nil {\n\t\treturn nil, fmt.Errorf(\"no table found for type: %v\", t.Name())\n\t}\n\n\tif checkPK && len(table.keys) < 1 {\n\t\te := fmt.Sprintf(\"gorp: no keys defined for table: %s\",\n\t\t\ttable.TableName)\n\t\treturn nil, errors.New(e)\n\t}\n\n\treturn table, nil\n}\n\n// DynamicTableFor returns the *TableMap for the dynamic table corresponding\n// to the input tablename\n// If no table is mapped to that tablename an error is returned.\n// If checkPK is true and the mapped table has no registered PKs, an error is returned.\nfunc (m *DbMap) DynamicTableFor(tableName string, checkPK bool) (*TableMap, error) {\n\ttable, found := m.dynamicTableFind(tableName)\n\tif !found {\n\t\treturn nil, fmt.Errorf(\"gorp: no table found for name: %v\", tableName)\n\t}\n\n\tif checkPK && len(table.keys) < 1 {\n\t\te := fmt.Sprintf(\"gorp: no keys defined for table: %s\",\n\t\t\ttable.TableName)\n\t\treturn nil, errors.New(e)\n\t}\n\n\treturn table, nil\n}\n\n// Prepare creates a prepared statement for later queries or executions.\n// Multiple queries or executions may be run concurrently from the returned statement.\n// This is equivalent to running:  Prepare() using database/sql\nfunc (m *DbMap) Prepare(query string) (*sql.Stmt, error) {\n\tif m.logger != nil {\n\t\tnow := time.Now()\n\t\tdefer m.trace(now, query, nil)\n\t}\n\treturn prepare(m, query)\n}\n\nfunc tableOrNil(m *DbMap, t reflect.Type, name string) *TableMap {\n\tif name != \"\" {\n\t\t// Search by table name (dynamic tables)\n\t\tif table, found := m.dynamicTableFind(name); found {\n\t\t\treturn table\n\t\t}\n\t\treturn nil\n\t}\n\n\tfor i := range m.tables {\n\t\ttable := m.tables[i]\n\t\tif table.gotype == t {\n\t\t\treturn table\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (m *DbMap) tableForPointer(ptr interface{}, checkPK bool) (*TableMap, reflect.Value, error) {\n\tptrv := reflect.ValueOf(ptr)\n\tif ptrv.Kind() != reflect.Ptr {\n\t\te := fmt.Sprintf(\"gorp: passed non-pointer: %v (kind=%v)\", ptr,\n\t\t\tptrv.Kind())\n\t\treturn nil, reflect.Value{}, errors.New(e)\n\t}\n\telem := ptrv.Elem()\n\tifc := elem.Interface()\n\tvar t *TableMap\n\tvar err error\n\ttableName := \"\"\n\tif dyn, isDyn := ptr.(DynamicTable); isDyn {\n\t\ttableName = dyn.TableName()\n\t\tt, err = m.DynamicTableFor(tableName, checkPK)\n\t} else {\n\t\tetype := reflect.TypeOf(ifc)\n\t\tt, err = m.TableFor(etype, checkPK)\n\t}\n\n\tif err != nil {\n\t\treturn nil, reflect.Value{}, err\n\t}\n\n\treturn t, elem, nil\n}\n\nfunc (m *DbMap) QueryRow(query string, args ...interface{}) *sql.Row {\n\tif m.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\tif m.logger != nil {\n\t\tnow := time.Now()\n\t\tdefer m.trace(now, query, args...)\n\t}\n\treturn queryRow(m, query, args...)\n}\n\nfunc (m *DbMap) Query(q string, args ...interface{}) (*sql.Rows, error) {\n\tif m.ExpandSliceArgs {\n\t\texpandSliceArgs(&q, args...)\n\t}\n\n\tif m.logger != nil {\n\t\tnow := time.Now()\n\t\tdefer m.trace(now, q, args...)\n\t}\n\treturn query(m, q, args...)\n}\n\nfunc (m *DbMap) trace(started time.Time, query string, args ...interface{}) {\n\tif m.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\tif m.logger != nil {\n\t\tvar margs = argsString(args...)\n\t\tm.logger.Printf(\"%s%s [%s] (%v)\", m.logPrefix, query, margs, (time.Now().Sub(started)))\n\t}\n}\n\ntype stringer interface {\n\tToStringSlice() []string\n}\n\ntype numberer interface {\n\tToInt64Slice() []int64\n}\n\nfunc expandSliceArgs(query *string, args ...interface{}) {\n\tfor _, arg := range args {\n\t\tmapper, ok := arg.(map[string]interface{})\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\n\t\tfor key, value := range mapper {\n\t\t\tvar replacements []string\n\n\t\t\t// add flexibility for any custom type to be convert to one of the\n\t\t\t// acceptable formats.\n\t\t\tif v, ok := value.(stringer); ok {\n\t\t\t\tvalue = v.ToStringSlice()\n\t\t\t}\n\t\t\tif v, ok := value.(numberer); ok {\n\t\t\t\tvalue = v.ToInt64Slice()\n\t\t\t}\n\n\t\t\tswitch v := value.(type) {\n\t\t\tcase []string:\n\t\t\t\tfor id, replace := range v {\n\t\t\t\t\tmapper[fmt.Sprintf(\"%s%d\", key, id)] = replace\n\t\t\t\t\treplacements = append(replacements, fmt.Sprintf(\":%s%d\", key, id))\n\t\t\t\t}\n\t\t\tcase []uint:\n\t\t\t\tfor id, replace := range v {\n\t\t\t\t\tmapper[fmt.Sprintf(\"%s%d\", key, id)] = replace\n\t\t\t\t\treplacements = append(replacements, fmt.Sprintf(\":%s%d\", key, id))\n\t\t\t\t}\n\t\t\tcase []uint8:\n\t\t\t\tfor id, replace := range v {\n\t\t\t\t\tmapper[fmt.Sprintf(\"%s%d\", key, id)] = replace\n\t\t\t\t\treplacements = append(replacements, fmt.Sprintf(\":%s%d\", key, id))\n\t\t\t\t}\n\t\t\tcase []uint16:\n\t\t\t\tfor id, replace := range v {\n\t\t\t\t\tmapper[fmt.Sprintf(\"%s%d\", key, id)] = replace\n\t\t\t\t\treplacements = append(replacements, fmt.Sprintf(\":%s%d\", key, id))\n\t\t\t\t}\n\t\t\tcase []uint32:\n\t\t\t\tfor id, replace := range v {\n\t\t\t\t\tmapper[fmt.Sprintf(\"%s%d\", key, id)] = replace\n\t\t\t\t\treplacements = append(replacements, fmt.Sprintf(\":%s%d\", key, id))\n\t\t\t\t}\n\t\t\tcase []uint64:\n\t\t\t\tfor id, replace := range v {\n\t\t\t\t\tmapper[fmt.Sprintf(\"%s%d\", key, id)] = replace\n\t\t\t\t\treplacements = append(replacements, fmt.Sprintf(\":%s%d\", key, id))\n\t\t\t\t}\n\t\t\tcase []int:\n\t\t\t\tfor id, replace := range v {\n\t\t\t\t\tmapper[fmt.Sprintf(\"%s%d\", key, id)] = replace\n\t\t\t\t\treplacements = append(replacements, fmt.Sprintf(\":%s%d\", key, id))\n\t\t\t\t}\n\t\t\tcase []int8:\n\t\t\t\tfor id, replace := range v {\n\t\t\t\t\tmapper[fmt.Sprintf(\"%s%d\", key, id)] = replace\n\t\t\t\t\treplacements = append(replacements, fmt.Sprintf(\":%s%d\", key, id))\n\t\t\t\t}\n\t\t\tcase []int16:\n\t\t\t\tfor id, replace := range v {\n\t\t\t\t\tmapper[fmt.Sprintf(\"%s%d\", key, id)] = replace\n\t\t\t\t\treplacements = append(replacements, fmt.Sprintf(\":%s%d\", key, id))\n\t\t\t\t}\n\t\t\tcase []int32:\n\t\t\t\tfor id, replace := range v {\n\t\t\t\t\tmapper[fmt.Sprintf(\"%s%d\", key, id)] = replace\n\t\t\t\t\treplacements = append(replacements, fmt.Sprintf(\":%s%d\", key, id))\n\t\t\t\t}\n\t\t\tcase []int64:\n\t\t\t\tfor id, replace := range v {\n\t\t\t\t\tmapper[fmt.Sprintf(\"%s%d\", key, id)] = replace\n\t\t\t\t\treplacements = append(replacements, fmt.Sprintf(\":%s%d\", key, id))\n\t\t\t\t}\n\t\t\tcase []float32:\n\t\t\t\tfor id, replace := range v {\n\t\t\t\t\tmapper[fmt.Sprintf(\"%s%d\", key, id)] = replace\n\t\t\t\t\treplacements = append(replacements, fmt.Sprintf(\":%s%d\", key, id))\n\t\t\t\t}\n\t\t\tcase []float64:\n\t\t\t\tfor id, replace := range v {\n\t\t\t\t\tmapper[fmt.Sprintf(\"%s%d\", key, id)] = replace\n\t\t\t\t\treplacements = append(replacements, fmt.Sprintf(\":%s%d\", key, id))\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif len(replacements) == 0 {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t*query = strings.Replace(*query, fmt.Sprintf(\":%s\", key), strings.Join(replacements, \",\"), -1)\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "db_test.go",
          "type": "blob",
          "size": 3.931640625,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\n//go:build integration\n// +build integration\n\npackage gorp_test\n\nimport (\n\t\"testing\"\n)\n\ntype customType1 []string\n\nfunc (c customType1) ToStringSlice() []string {\n\treturn []string(c)\n}\n\ntype customType2 []int64\n\nfunc (c customType2) ToInt64Slice() []int64 {\n\treturn []int64(c)\n}\n\nfunc TestDbMap_Select_expandSliceArgs(t *testing.T) {\n\ttests := []struct {\n\t\tdescription string\n\t\tquery       string\n\t\targs        []interface{}\n\t\twantLen     int\n\t}{\n\t\t{\n\t\t\tdescription: \"it should handle slice placeholders correctly\",\n\t\t\tquery: `\nSELECT 1 FROM crazy_table\nWHERE field1 = :Field1\nAND field2 IN (:FieldStringList)\nAND field3 IN (:FieldUIntList)\nAND field4 IN (:FieldUInt8List)\nAND field5 IN (:FieldUInt16List)\nAND field6 IN (:FieldUInt32List)\nAND field7 IN (:FieldUInt64List)\nAND field8 IN (:FieldIntList)\nAND field9 IN (:FieldInt8List)\nAND field10 IN (:FieldInt16List)\nAND field11 IN (:FieldInt32List)\nAND field12 IN (:FieldInt64List)\nAND field13 IN (:FieldFloat32List)\nAND field14 IN (:FieldFloat64List)\n`,\n\t\t\targs: []interface{}{\n\t\t\t\tmap[string]interface{}{\n\t\t\t\t\t\"Field1\":           123,\n\t\t\t\t\t\"FieldStringList\":  []string{\"h\", \"e\", \"y\"},\n\t\t\t\t\t\"FieldUIntList\":    []uint{1, 2, 3, 4},\n\t\t\t\t\t\"FieldUInt8List\":   []uint8{1, 2, 3, 4},\n\t\t\t\t\t\"FieldUInt16List\":  []uint16{1, 2, 3, 4},\n\t\t\t\t\t\"FieldUInt32List\":  []uint32{1, 2, 3, 4},\n\t\t\t\t\t\"FieldUInt64List\":  []uint64{1, 2, 3, 4},\n\t\t\t\t\t\"FieldIntList\":     []int{1, 2, 3, 4},\n\t\t\t\t\t\"FieldInt8List\":    []int8{1, 2, 3, 4},\n\t\t\t\t\t\"FieldInt16List\":   []int16{1, 2, 3, 4},\n\t\t\t\t\t\"FieldInt32List\":   []int32{1, 2, 3, 4},\n\t\t\t\t\t\"FieldInt64List\":   []int64{1, 2, 3, 4},\n\t\t\t\t\t\"FieldFloat32List\": []float32{1, 2, 3, 4},\n\t\t\t\t\t\"FieldFloat64List\": []float64{1, 2, 3, 4},\n\t\t\t\t},\n\t\t\t},\n\t\t\twantLen: 1,\n\t\t},\n\t\t{\n\t\t\tdescription: \"it should handle slice placeholders correctly with custom types\",\n\t\t\tquery: `\nSELECT 1 FROM crazy_table\nWHERE field2 IN (:FieldStringList)\nAND field12 IN (:FieldIntList)\n`,\n\t\t\targs: []interface{}{\n\t\t\t\tmap[string]interface{}{\n\t\t\t\t\t\"FieldStringList\": customType1{\"h\", \"e\", \"y\"},\n\t\t\t\t\t\"FieldIntList\":    customType2{1, 2, 3, 4},\n\t\t\t\t},\n\t\t\t},\n\t\t\twantLen: 3,\n\t\t},\n\t}\n\n\ttype dataFormat struct {\n\t\tField1  int     `db:\"field1\"`\n\t\tField2  string  `db:\"field2\"`\n\t\tField3  uint    `db:\"field3\"`\n\t\tField4  uint8   `db:\"field4\"`\n\t\tField5  uint16  `db:\"field5\"`\n\t\tField6  uint32  `db:\"field6\"`\n\t\tField7  uint64  `db:\"field7\"`\n\t\tField8  int     `db:\"field8\"`\n\t\tField9  int8    `db:\"field9\"`\n\t\tField10 int16   `db:\"field10\"`\n\t\tField11 int32   `db:\"field11\"`\n\t\tField12 int64   `db:\"field12\"`\n\t\tField13 float32 `db:\"field13\"`\n\t\tField14 float64 `db:\"field14\"`\n\t}\n\n\tdbmap := newDBMap(t)\n\tdbmap.ExpandSliceArgs = true\n\tdbmap.AddTableWithName(dataFormat{}, \"crazy_table\")\n\n\terr := dbmap.CreateTables()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer dropAndClose(dbmap)\n\n\terr = dbmap.Insert(\n\t\t&dataFormat{\n\t\t\tField1:  123,\n\t\t\tField2:  \"h\",\n\t\t\tField3:  1,\n\t\t\tField4:  1,\n\t\t\tField5:  1,\n\t\t\tField6:  1,\n\t\t\tField7:  1,\n\t\t\tField8:  1,\n\t\t\tField9:  1,\n\t\t\tField10: 1,\n\t\t\tField11: 1,\n\t\t\tField12: 1,\n\t\t\tField13: 1,\n\t\t\tField14: 1,\n\t\t},\n\t\t&dataFormat{\n\t\t\tField1:  124,\n\t\t\tField2:  \"e\",\n\t\t\tField3:  2,\n\t\t\tField4:  2,\n\t\t\tField5:  2,\n\t\t\tField6:  2,\n\t\t\tField7:  2,\n\t\t\tField8:  2,\n\t\t\tField9:  2,\n\t\t\tField10: 2,\n\t\t\tField11: 2,\n\t\t\tField12: 2,\n\t\t\tField13: 2,\n\t\t\tField14: 2,\n\t\t},\n\t\t&dataFormat{\n\t\t\tField1:  125,\n\t\t\tField2:  \"y\",\n\t\t\tField3:  3,\n\t\t\tField4:  3,\n\t\t\tField5:  3,\n\t\t\tField6:  3,\n\t\t\tField7:  3,\n\t\t\tField8:  3,\n\t\t\tField9:  3,\n\t\t\tField10: 3,\n\t\t\tField11: 3,\n\t\t\tField12: 3,\n\t\t\tField13: 3,\n\t\t\tField14: 3,\n\t\t},\n\t)\n\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.description, func(t *testing.T) {\n\t\t\tvar dummy []int\n\t\t\t_, err := dbmap.Select(&dummy, tt.query, tt.args...)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\tif len(dummy) != tt.wantLen {\n\t\t\t\tt.Errorf(\"wrong result count\\ngot:  %d\\nwant: %d\", len(dummy), tt.wantLen)\n\t\t\t}\n\t\t})\n\t}\n}\n"
        },
        {
          "name": "dialect.go",
          "type": "blob",
          "size": 3.814453125,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage gorp\n\nimport (\n\t\"reflect\"\n)\n\n// The Dialect interface encapsulates behaviors that differ across\n// SQL databases.  At present the Dialect is only used by CreateTables()\n// but this could change in the future\ntype Dialect interface {\n\t// adds a suffix to any query, usually \";\"\n\tQuerySuffix() string\n\n\t// ToSqlType returns the SQL column type to use when creating a\n\t// table of the given Go Type.  maxsize can be used to switch based on\n\t// size.  For example, in MySQL []byte could map to BLOB, MEDIUMBLOB,\n\t// or LONGBLOB depending on the maxsize\n\tToSqlType(val reflect.Type, maxsize int, isAutoIncr bool) string\n\n\t// string to append to primary key column definitions\n\tAutoIncrStr() string\n\n\t// string to bind autoincrement columns to. Empty string will\n\t// remove reference to those columns in the INSERT statement.\n\tAutoIncrBindValue() string\n\n\tAutoIncrInsertSuffix(col *ColumnMap) string\n\n\t// string to append to \"create table\" statement for vendor specific\n\t// table attributes\n\tCreateTableSuffix() string\n\n\t// string to append to \"create index\" statement\n\tCreateIndexSuffix() string\n\n\t// string to append to \"drop index\" statement\n\tDropIndexSuffix() string\n\n\t// string to truncate tables\n\tTruncateClause() string\n\n\t// bind variable string to use when forming SQL statements\n\t// in many dbs it is \"?\", but Postgres appears to use $1\n\t//\n\t// i is a zero based index of the bind variable in this statement\n\t//\n\tBindVar(i int) string\n\n\t// Handles quoting of a field name to ensure that it doesn't raise any\n\t// SQL parsing exceptions by using a reserved word as a field name.\n\tQuoteField(field string) string\n\n\t// Handles building up of a schema.database string that is compatible with\n\t// the given dialect\n\t//\n\t// schema - The schema that <table> lives in\n\t// table - The table name\n\tQuotedTableForQuery(schema string, table string) string\n\n\t// Existence clause for table creation / deletion\n\tIfSchemaNotExists(command, schema string) string\n\tIfTableExists(command, schema, table string) string\n\tIfTableNotExists(command, schema, table string) string\n}\n\n// IntegerAutoIncrInserter is implemented by dialects that can perform\n// inserts with automatically incremented integer primary keys.  If\n// the dialect can handle automatic assignment of more than just\n// integers, see TargetedAutoIncrInserter.\ntype IntegerAutoIncrInserter interface {\n\tInsertAutoIncr(exec SqlExecutor, insertSql string, params ...interface{}) (int64, error)\n}\n\n// TargetedAutoIncrInserter is implemented by dialects that can\n// perform automatic assignment of any primary key type (i.e. strings\n// for uuids, integers for serials, etc).\ntype TargetedAutoIncrInserter interface {\n\t// InsertAutoIncrToTarget runs an insert operation and assigns the\n\t// automatically generated primary key directly to the passed in\n\t// target.  The target should be a pointer to the primary key\n\t// field of the value being inserted.\n\tInsertAutoIncrToTarget(exec SqlExecutor, insertSql string, target interface{}, params ...interface{}) error\n}\n\n// TargetQueryInserter is implemented by dialects that can perform\n// assignment of integer primary key type by executing a query\n// like \"select sequence.currval from dual\".\ntype TargetQueryInserter interface {\n\t// TargetQueryInserter runs an insert operation and assigns the\n\t// automatically generated primary key retrived by the query\n\t// extracted from the GeneratedIdQuery field of the id column.\n\tInsertQueryToTarget(exec SqlExecutor, insertSql, idSql string, target interface{}, params ...interface{}) error\n}\n\nfunc standardInsertAutoIncr(exec SqlExecutor, insertSql string, params ...interface{}) (int64, error) {\n\tres, err := exec.Exec(insertSql, params...)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\treturn res.LastInsertId()\n}\n"
        },
        {
          "name": "dialect_mysql.go",
          "type": "blob",
          "size": 3.9306640625,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage gorp\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n\t\"strings\"\n\t\"time\"\n)\n\n// Implementation of Dialect for MySQL databases.\ntype MySQLDialect struct {\n\n\t// Engine is the storage engine to use \"InnoDB\" vs \"MyISAM\" for example\n\tEngine string\n\n\t// Encoding is the character encoding to use for created tables\n\tEncoding string\n}\n\nfunc (d MySQLDialect) QuerySuffix() string { return \";\" }\n\nfunc (d MySQLDialect) ToSqlType(val reflect.Type, maxsize int, isAutoIncr bool) string {\n\tswitch val.Kind() {\n\tcase reflect.Ptr:\n\t\treturn d.ToSqlType(val.Elem(), maxsize, isAutoIncr)\n\tcase reflect.Bool:\n\t\treturn \"boolean\"\n\tcase reflect.Int8:\n\t\treturn \"tinyint\"\n\tcase reflect.Uint8:\n\t\treturn \"tinyint unsigned\"\n\tcase reflect.Int16:\n\t\treturn \"smallint\"\n\tcase reflect.Uint16:\n\t\treturn \"smallint unsigned\"\n\tcase reflect.Int, reflect.Int32:\n\t\treturn \"int\"\n\tcase reflect.Uint, reflect.Uint32:\n\t\treturn \"int unsigned\"\n\tcase reflect.Int64:\n\t\treturn \"bigint\"\n\tcase reflect.Uint64:\n\t\treturn \"bigint unsigned\"\n\tcase reflect.Float64, reflect.Float32:\n\t\treturn \"double\"\n\tcase reflect.Slice:\n\t\tif val.Elem().Kind() == reflect.Uint8 {\n\t\t\treturn \"mediumblob\"\n\t\t}\n\t}\n\n\tswitch val.Name() {\n\tcase \"NullInt64\":\n\t\treturn \"bigint\"\n\tcase \"NullFloat64\":\n\t\treturn \"double\"\n\tcase \"NullBool\":\n\t\treturn \"tinyint\"\n\tcase \"Time\":\n\t\treturn \"datetime\"\n\t}\n\n\tif maxsize < 1 {\n\t\tmaxsize = 255\n\t}\n\n\t/* == About varchar(N) ==\n\t * N is number of characters.\n\t * A varchar column can store up to 65535 bytes.\n\t * Remember that 1 character is 3 bytes in utf-8 charset.\n\t * Also remember that each row can store up to 65535 bytes,\n\t * and you have some overheads, so it's not possible for a\n\t * varchar column to have 65535/3 characters really.\n\t * So it would be better to use 'text' type in stead of\n\t * large varchar type.\n\t */\n\tif maxsize < 256 {\n\t\treturn fmt.Sprintf(\"varchar(%d)\", maxsize)\n\t} else {\n\t\treturn \"text\"\n\t}\n}\n\n// Returns auto_increment\nfunc (d MySQLDialect) AutoIncrStr() string {\n\treturn \"auto_increment\"\n}\n\nfunc (d MySQLDialect) AutoIncrBindValue() string {\n\treturn \"null\"\n}\n\nfunc (d MySQLDialect) AutoIncrInsertSuffix(col *ColumnMap) string {\n\treturn \"\"\n}\n\n// Returns engine=%s charset=%s  based on values stored on struct\nfunc (d MySQLDialect) CreateTableSuffix() string {\n\tif d.Engine == \"\" || d.Encoding == \"\" {\n\t\tmsg := \"gorp - undefined\"\n\n\t\tif d.Engine == \"\" {\n\t\t\tmsg += \" MySQLDialect.Engine\"\n\t\t}\n\t\tif d.Engine == \"\" && d.Encoding == \"\" {\n\t\t\tmsg += \",\"\n\t\t}\n\t\tif d.Encoding == \"\" {\n\t\t\tmsg += \" MySQLDialect.Encoding\"\n\t\t}\n\t\tmsg += \". Check that your MySQLDialect was correctly initialized when declared.\"\n\t\tpanic(msg)\n\t}\n\n\treturn fmt.Sprintf(\" engine=%s charset=%s\", d.Engine, d.Encoding)\n}\n\nfunc (d MySQLDialect) CreateIndexSuffix() string {\n\treturn \"using\"\n}\n\nfunc (d MySQLDialect) DropIndexSuffix() string {\n\treturn \"on\"\n}\n\nfunc (d MySQLDialect) TruncateClause() string {\n\treturn \"truncate\"\n}\n\nfunc (d MySQLDialect) SleepClause(s time.Duration) string {\n\treturn fmt.Sprintf(\"sleep(%f)\", s.Seconds())\n}\n\n// Returns \"?\"\nfunc (d MySQLDialect) BindVar(i int) string {\n\treturn \"?\"\n}\n\nfunc (d MySQLDialect) InsertAutoIncr(exec SqlExecutor, insertSql string, params ...interface{}) (int64, error) {\n\treturn standardInsertAutoIncr(exec, insertSql, params...)\n}\n\nfunc (d MySQLDialect) QuoteField(f string) string {\n\treturn \"`\" + f + \"`\"\n}\n\nfunc (d MySQLDialect) QuotedTableForQuery(schema string, table string) string {\n\tif strings.TrimSpace(schema) == \"\" {\n\t\treturn d.QuoteField(table)\n\t}\n\n\treturn schema + \".\" + d.QuoteField(table)\n}\n\nfunc (d MySQLDialect) IfSchemaNotExists(command, schema string) string {\n\treturn fmt.Sprintf(\"%s if not exists\", command)\n}\n\nfunc (d MySQLDialect) IfTableExists(command, schema, table string) string {\n\treturn fmt.Sprintf(\"%s if exists\", command)\n}\n\nfunc (d MySQLDialect) IfTableNotExists(command, schema, table string) string {\n\treturn fmt.Sprintf(\"%s if not exists\", command)\n}\n"
        },
        {
          "name": "dialect_mysql_test.go",
          "type": "blob",
          "size": 5.4013671875,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\n//go:build !integration\n// +build !integration\n\npackage gorp_test\n\nimport (\n\t\"database/sql\"\n\t\"errors\"\n\t\"fmt\"\n\t\"reflect\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/go-gorp/gorp/v3\"\n\t\"github.com/poy/onpar\"\n\t\"github.com/poy/onpar/expect\"\n\t\"github.com/poy/onpar/matchers\"\n)\n\nfunc TestMySQLDialect(t *testing.T) {\n\ttype testContext struct {\n\t\texpect  expect.Expectation\n\t\tdialect gorp.MySQLDialect\n\t}\n\n\to := onpar.BeforeEach(onpar.New(t), func(t *testing.T) testContext {\n\t\treturn testContext{\n\t\t\texpect: expect.New(t),\n\t\t\tdialect: gorp.MySQLDialect{\n\t\t\t\tEngine:   \"foo\",\n\t\t\t\tEncoding: \"bar\",\n\t\t\t},\n\t\t}\n\t})\n\tdefer o.Run()\n\n\to.Group(\"ToSqlType\", func() {\n\t\ttests := []struct {\n\t\t\tname     string\n\t\t\tvalue    interface{}\n\t\t\tmaxSize  int\n\t\t\tautoIncr bool\n\t\t\texpected string\n\t\t}{\n\t\t\t{\"bool\", true, 0, false, \"boolean\"},\n\t\t\t{\"int8\", int8(1), 0, false, \"tinyint\"},\n\t\t\t{\"uint8\", uint8(1), 0, false, \"tinyint unsigned\"},\n\t\t\t{\"int16\", int16(1), 0, false, \"smallint\"},\n\t\t\t{\"uint16\", uint16(1), 0, false, \"smallint unsigned\"},\n\t\t\t{\"int32\", int32(1), 0, false, \"int\"},\n\t\t\t{\"int (treated as int32)\", int(1), 0, false, \"int\"},\n\t\t\t{\"uint32\", uint32(1), 0, false, \"int unsigned\"},\n\t\t\t{\"uint (treated as uint32)\", uint(1), 0, false, \"int unsigned\"},\n\t\t\t{\"int64\", int64(1), 0, false, \"bigint\"},\n\t\t\t{\"uint64\", uint64(1), 0, false, \"bigint unsigned\"},\n\t\t\t{\"float32\", float32(1), 0, false, \"double\"},\n\t\t\t{\"float64\", float64(1), 0, false, \"double\"},\n\t\t\t{\"[]uint8\", []uint8{1}, 0, false, \"mediumblob\"},\n\t\t\t{\"NullInt64\", sql.NullInt64{}, 0, false, \"bigint\"},\n\t\t\t{\"NullFloat64\", sql.NullFloat64{}, 0, false, \"double\"},\n\t\t\t{\"NullBool\", sql.NullBool{}, 0, false, \"tinyint\"},\n\t\t\t{\"Time\", time.Time{}, 0, false, \"datetime\"},\n\t\t\t{\"default-size string\", \"\", 0, false, \"varchar(255)\"},\n\t\t\t{\"sized string\", \"\", 50, false, \"varchar(50)\"},\n\t\t\t{\"large string\", \"\", 1024, false, \"text\"},\n\t\t}\n\t\tfor _, t := range tests {\n\t\t\to.Spec(t.name, func(tt testContext) {\n\t\t\t\ttyp := reflect.TypeOf(t.value)\n\t\t\t\tsqlType := tt.dialect.ToSqlType(typ, t.maxSize, t.autoIncr)\n\t\t\t\ttt.expect(sqlType).To(matchers.Equal(t.expected))\n\t\t\t})\n\t\t}\n\t})\n\n\to.Spec(\"AutoIncrStr\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.AutoIncrStr()).To(matchers.Equal(\"auto_increment\"))\n\t})\n\n\to.Spec(\"AutoIncrBindValue\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.AutoIncrBindValue()).To(matchers.Equal(\"null\"))\n\t})\n\n\to.Spec(\"AutoIncrInsertSuffix\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.AutoIncrInsertSuffix(nil)).To(matchers.Equal(\"\"))\n\t})\n\n\to.Group(\"CreateTableSuffix\", func() {\n\t\to.Group(\"with an empty engine\", func() {\n\t\t\to := onpar.BeforeEach(o, func(tt testContext) testContext {\n\t\t\t\ttt.dialect.Engine = \"\"\n\t\t\t\treturn tt\n\t\t\t})\n\t\t\to.Spec(\"panics\", func(tt testContext) {\n\t\t\t\ttt.expect(func() { tt.dialect.CreateTableSuffix() }).To(Panic())\n\t\t\t})\n\t\t})\n\n\t\to.Group(\"with an empty encoding\", func() {\n\t\t\to := onpar.BeforeEach(o, func(tt testContext) testContext {\n\t\t\t\ttt.dialect.Encoding = \"\"\n\t\t\t\treturn tt\n\t\t\t})\n\t\t\to.Spec(\"panics\", func(tt testContext) {\n\t\t\t\ttt.expect(func() { tt.dialect.CreateTableSuffix() }).To(Panic())\n\t\t\t})\n\t\t})\n\n\t\to.Spec(\"with an engine and an encoding\", func(tt testContext) {\n\t\t\ttt.expect(tt.dialect.CreateTableSuffix()).To(matchers.Equal(\" engine=foo charset=bar\"))\n\t\t})\n\t})\n\n\to.Spec(\"CreateIndexSuffix\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.CreateIndexSuffix()).To(matchers.Equal(\"using\"))\n\t})\n\n\to.Spec(\"DropIndexSuffix\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.DropIndexSuffix()).To(matchers.Equal(\"on\"))\n\t})\n\n\to.Spec(\"TruncateClause\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.TruncateClause()).To(matchers.Equal(\"truncate\"))\n\t})\n\n\to.Spec(\"SleepClause\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.SleepClause(1 * time.Second)).To(matchers.Equal(\"sleep(1.000000)\"))\n\t\ttt.expect(tt.dialect.SleepClause(100 * time.Millisecond)).To(matchers.Equal(\"sleep(0.100000)\"))\n\t})\n\n\to.Spec(\"BindVar\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.BindVar(0)).To(matchers.Equal(\"?\"))\n\t})\n\n\to.Spec(\"QuoteField\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.QuoteField(\"foo\")).To(matchers.Equal(\"`foo`\"))\n\t})\n\n\to.Group(\"QuotedTableForQuery\", func() {\n\t\to.Spec(\"using the default schema\", func(tt testContext) {\n\t\t\ttt.expect(tt.dialect.QuotedTableForQuery(\"\", \"foo\")).To(matchers.Equal(\"`foo`\"))\n\t\t})\n\n\t\to.Spec(\"with a supplied schema\", func(tt testContext) {\n\t\t\ttt.expect(tt.dialect.QuotedTableForQuery(\"foo\", \"bar\")).To(matchers.Equal(\"foo.`bar`\"))\n\t\t})\n\t})\n\n\to.Spec(\"IfSchemaNotExists\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.IfSchemaNotExists(\"foo\", \"bar\")).To(matchers.Equal(\"foo if not exists\"))\n\t})\n\n\to.Spec(\"IfTableExists\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.IfTableExists(\"foo\", \"bar\", \"baz\")).To(matchers.Equal(\"foo if exists\"))\n\t})\n\n\to.Spec(\"IfTableNotExists\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.IfTableNotExists(\"foo\", \"bar\", \"baz\")).To(matchers.Equal(\"foo if not exists\"))\n\t})\n}\n\ntype panicMatcher struct {\n}\n\nfunc Panic() panicMatcher {\n\treturn panicMatcher{}\n}\n\nfunc (m panicMatcher) Match(actual interface{}) (resultValue interface{}, err error) {\n\tswitch f := actual.(type) {\n\tcase func():\n\t\tpanicked := false\n\t\tfunc() {\n\t\t\tdefer func() {\n\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\tpanicked = true\n\t\t\t\t}\n\t\t\t}()\n\t\t\tf()\n\t\t}()\n\t\tif panicked {\n\t\t\treturn f, nil\n\t\t}\n\t\treturn f, errors.New(\"function did not panic\")\n\tdefault:\n\t\treturn f, fmt.Errorf(\"%T is not func()\", f)\n\t}\n}\n"
        },
        {
          "name": "dialect_oracle.go",
          "type": "blob",
          "size": 3.16015625,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage gorp\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n\t\"strings\"\n)\n\n// Implementation of Dialect for Oracle databases.\ntype OracleDialect struct{}\n\nfunc (d OracleDialect) QuerySuffix() string { return \"\" }\n\nfunc (d OracleDialect) CreateIndexSuffix() string { return \"\" }\n\nfunc (d OracleDialect) DropIndexSuffix() string { return \"\" }\n\nfunc (d OracleDialect) ToSqlType(val reflect.Type, maxsize int, isAutoIncr bool) string {\n\tswitch val.Kind() {\n\tcase reflect.Ptr:\n\t\treturn d.ToSqlType(val.Elem(), maxsize, isAutoIncr)\n\tcase reflect.Bool:\n\t\treturn \"boolean\"\n\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32:\n\t\tif isAutoIncr {\n\t\t\treturn \"serial\"\n\t\t}\n\t\treturn \"integer\"\n\tcase reflect.Int64, reflect.Uint64:\n\t\tif isAutoIncr {\n\t\t\treturn \"bigserial\"\n\t\t}\n\t\treturn \"bigint\"\n\tcase reflect.Float64:\n\t\treturn \"double precision\"\n\tcase reflect.Float32:\n\t\treturn \"real\"\n\tcase reflect.Slice:\n\t\tif val.Elem().Kind() == reflect.Uint8 {\n\t\t\treturn \"bytea\"\n\t\t}\n\t}\n\n\tswitch val.Name() {\n\tcase \"NullInt64\":\n\t\treturn \"bigint\"\n\tcase \"NullFloat64\":\n\t\treturn \"double precision\"\n\tcase \"NullBool\":\n\t\treturn \"boolean\"\n\tcase \"NullTime\", \"Time\":\n\t\treturn \"timestamp with time zone\"\n\t}\n\n\tif maxsize > 0 {\n\t\treturn fmt.Sprintf(\"varchar(%d)\", maxsize)\n\t} else {\n\t\treturn \"text\"\n\t}\n\n}\n\n// Returns empty string\nfunc (d OracleDialect) AutoIncrStr() string {\n\treturn \"\"\n}\n\nfunc (d OracleDialect) AutoIncrBindValue() string {\n\treturn \"NULL\"\n}\n\nfunc (d OracleDialect) AutoIncrInsertSuffix(col *ColumnMap) string {\n\treturn \"\"\n}\n\n// Returns suffix\nfunc (d OracleDialect) CreateTableSuffix() string {\n\treturn \"\"\n}\n\nfunc (d OracleDialect) TruncateClause() string {\n\treturn \"truncate\"\n}\n\n// Returns \"$(i+1)\"\nfunc (d OracleDialect) BindVar(i int) string {\n\treturn fmt.Sprintf(\":%d\", i+1)\n}\n\n// After executing the insert uses the ColMap IdQuery to get the generated id\nfunc (d OracleDialect) InsertQueryToTarget(exec SqlExecutor, insertSql, idSql string, target interface{}, params ...interface{}) error {\n\t_, err := exec.Exec(insertSql, params...)\n\tif err != nil {\n\t\treturn err\n\t}\n\tid, err := exec.SelectInt(idSql)\n\tif err != nil {\n\t\treturn err\n\t}\n\tswitch target.(type) {\n\tcase *int64:\n\t\t*(target.(*int64)) = id\n\tcase *int32:\n\t\t*(target.(*int32)) = int32(id)\n\tcase int:\n\t\t*(target.(*int)) = int(id)\n\tdefault:\n\t\treturn fmt.Errorf(\"Id field can be int, int32 or int64\")\n\t}\n\treturn nil\n}\n\nfunc (d OracleDialect) QuoteField(f string) string {\n\treturn `\"` + strings.ToUpper(f) + `\"`\n}\n\nfunc (d OracleDialect) QuotedTableForQuery(schema string, table string) string {\n\tif strings.TrimSpace(schema) == \"\" {\n\t\treturn d.QuoteField(table)\n\t}\n\n\treturn schema + \".\" + d.QuoteField(table)\n}\n\nfunc (d OracleDialect) IfSchemaNotExists(command, schema string) string {\n\treturn fmt.Sprintf(\"%s if not exists\", command)\n}\n\nfunc (d OracleDialect) IfTableExists(command, schema, table string) string {\n\treturn fmt.Sprintf(\"%s if exists\", command)\n}\n\nfunc (d OracleDialect) IfTableNotExists(command, schema, table string) string {\n\treturn fmt.Sprintf(\"%s if not exists\", command)\n}\n"
        },
        {
          "name": "dialect_postgres.go",
          "type": "blob",
          "size": 3.373046875,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage gorp\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype PostgresDialect struct {\n\tsuffix          string\n\tLowercaseFields bool\n}\n\nfunc (d PostgresDialect) QuerySuffix() string { return \";\" }\n\nfunc (d PostgresDialect) ToSqlType(val reflect.Type, maxsize int, isAutoIncr bool) string {\n\tswitch val.Kind() {\n\tcase reflect.Ptr:\n\t\treturn d.ToSqlType(val.Elem(), maxsize, isAutoIncr)\n\tcase reflect.Bool:\n\t\treturn \"boolean\"\n\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32:\n\t\tif isAutoIncr {\n\t\t\treturn \"serial\"\n\t\t}\n\t\treturn \"integer\"\n\tcase reflect.Int64, reflect.Uint64:\n\t\tif isAutoIncr {\n\t\t\treturn \"bigserial\"\n\t\t}\n\t\treturn \"bigint\"\n\tcase reflect.Float64:\n\t\treturn \"double precision\"\n\tcase reflect.Float32:\n\t\treturn \"real\"\n\tcase reflect.Slice:\n\t\tif val.Elem().Kind() == reflect.Uint8 {\n\t\t\treturn \"bytea\"\n\t\t}\n\t}\n\n\tswitch val.Name() {\n\tcase \"NullInt64\":\n\t\treturn \"bigint\"\n\tcase \"NullFloat64\":\n\t\treturn \"double precision\"\n\tcase \"NullBool\":\n\t\treturn \"boolean\"\n\tcase \"Time\", \"NullTime\":\n\t\treturn \"timestamp with time zone\"\n\t}\n\n\tif maxsize > 0 {\n\t\treturn fmt.Sprintf(\"varchar(%d)\", maxsize)\n\t} else {\n\t\treturn \"text\"\n\t}\n\n}\n\n// Returns empty string\nfunc (d PostgresDialect) AutoIncrStr() string {\n\treturn \"\"\n}\n\nfunc (d PostgresDialect) AutoIncrBindValue() string {\n\treturn \"default\"\n}\n\nfunc (d PostgresDialect) AutoIncrInsertSuffix(col *ColumnMap) string {\n\treturn \" returning \" + d.QuoteField(col.ColumnName)\n}\n\n// Returns suffix\nfunc (d PostgresDialect) CreateTableSuffix() string {\n\treturn d.suffix\n}\n\nfunc (d PostgresDialect) CreateIndexSuffix() string {\n\treturn \"using\"\n}\n\nfunc (d PostgresDialect) DropIndexSuffix() string {\n\treturn \"\"\n}\n\nfunc (d PostgresDialect) TruncateClause() string {\n\treturn \"truncate\"\n}\n\nfunc (d PostgresDialect) SleepClause(s time.Duration) string {\n\treturn fmt.Sprintf(\"pg_sleep(%f)\", s.Seconds())\n}\n\n// Returns \"$(i+1)\"\nfunc (d PostgresDialect) BindVar(i int) string {\n\treturn fmt.Sprintf(\"$%d\", i+1)\n}\n\nfunc (d PostgresDialect) InsertAutoIncrToTarget(exec SqlExecutor, insertSql string, target interface{}, params ...interface{}) error {\n\trows, err := exec.Query(insertSql, params...)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer rows.Close()\n\n\tif !rows.Next() {\n\t\treturn fmt.Errorf(\"No serial value returned for insert: %s Encountered error: %s\", insertSql, rows.Err())\n\t}\n\tif err := rows.Scan(target); err != nil {\n\t\treturn err\n\t}\n\tif rows.Next() {\n\t\treturn fmt.Errorf(\"more than two serial value returned for insert: %s\", insertSql)\n\t}\n\treturn rows.Err()\n}\n\nfunc (d PostgresDialect) QuoteField(f string) string {\n\tif d.LowercaseFields {\n\t\treturn `\"` + strings.ToLower(f) + `\"`\n\t}\n\treturn `\"` + f + `\"`\n}\n\nfunc (d PostgresDialect) QuotedTableForQuery(schema string, table string) string {\n\tif strings.TrimSpace(schema) == \"\" {\n\t\treturn d.QuoteField(table)\n\t}\n\n\treturn schema + \".\" + d.QuoteField(table)\n}\n\nfunc (d PostgresDialect) IfSchemaNotExists(command, schema string) string {\n\treturn fmt.Sprintf(\"%s if not exists\", command)\n}\n\nfunc (d PostgresDialect) IfTableExists(command, schema, table string) string {\n\treturn fmt.Sprintf(\"%s if exists\", command)\n}\n\nfunc (d PostgresDialect) IfTableNotExists(command, schema, table string) string {\n\treturn fmt.Sprintf(\"%s if not exists\", command)\n}\n"
        },
        {
          "name": "dialect_postgres_test.go",
          "type": "blob",
          "size": 4.828125,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\n//go:build !integration\n// +build !integration\n\npackage gorp_test\n\nimport (\n\t\"database/sql\"\n\t\"reflect\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/go-gorp/gorp/v3\"\n\t\"github.com/poy/onpar\"\n\t\"github.com/poy/onpar/expect\"\n\t\"github.com/poy/onpar/matchers\"\n)\n\nfunc TestPostgresDialect(t *testing.T) {\n\ttype testContext struct {\n\t\texpect  expect.Expectation\n\t\tdialect gorp.PostgresDialect\n\t}\n\n\to := onpar.BeforeEach(onpar.New(t), func(t *testing.T) testContext {\n\t\treturn testContext{\n\t\t\texpect: expect.New(t),\n\t\t\tdialect: gorp.PostgresDialect{\n\t\t\t\tLowercaseFields: false,\n\t\t\t},\n\t\t}\n\t})\n\tdefer o.Run()\n\n\to.Group(\"ToSqlType\", func() {\n\t\ttests := []struct {\n\t\t\tname     string\n\t\t\tvalue    interface{}\n\t\t\tmaxSize  int\n\t\t\tautoIncr bool\n\t\t\texpected string\n\t\t}{\n\t\t\t{\"bool\", true, 0, false, \"boolean\"},\n\t\t\t{\"int8\", int8(1), 0, false, \"integer\"},\n\t\t\t{\"uint8\", uint8(1), 0, false, \"integer\"},\n\t\t\t{\"int16\", int16(1), 0, false, \"integer\"},\n\t\t\t{\"uint16\", uint16(1), 0, false, \"integer\"},\n\t\t\t{\"int32\", int32(1), 0, false, \"integer\"},\n\t\t\t{\"int (treated as int32)\", int(1), 0, false, \"integer\"},\n\t\t\t{\"uint32\", uint32(1), 0, false, \"integer\"},\n\t\t\t{\"uint (treated as uint32)\", uint(1), 0, false, \"integer\"},\n\t\t\t{\"int64\", int64(1), 0, false, \"bigint\"},\n\t\t\t{\"uint64\", uint64(1), 0, false, \"bigint\"},\n\t\t\t{\"float32\", float32(1), 0, false, \"real\"},\n\t\t\t{\"float64\", float64(1), 0, false, \"double precision\"},\n\t\t\t{\"[]uint8\", []uint8{1}, 0, false, \"bytea\"},\n\t\t\t{\"NullInt64\", sql.NullInt64{}, 0, false, \"bigint\"},\n\t\t\t{\"NullFloat64\", sql.NullFloat64{}, 0, false, \"double precision\"},\n\t\t\t{\"NullBool\", sql.NullBool{}, 0, false, \"boolean\"},\n\t\t\t{\"Time\", time.Time{}, 0, false, \"timestamp with time zone\"},\n\t\t\t{\"default-size string\", \"\", 0, false, \"text\"},\n\t\t\t{\"sized string\", \"\", 50, false, \"varchar(50)\"},\n\t\t\t{\"large string\", \"\", 1024, false, \"varchar(1024)\"},\n\t\t}\n\t\tfor _, t := range tests {\n\t\t\to.Spec(t.name, func(tt testContext) {\n\t\t\t\ttyp := reflect.TypeOf(t.value)\n\t\t\t\tsqlType := tt.dialect.ToSqlType(typ, t.maxSize, t.autoIncr)\n\t\t\t\ttt.expect(sqlType).To(matchers.Equal(t.expected))\n\t\t\t})\n\t\t}\n\t})\n\n\to.Spec(\"AutoIncrStr\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.AutoIncrStr()).To(matchers.Equal(\"\"))\n\t})\n\n\to.Spec(\"AutoIncrBindValue\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.AutoIncrBindValue()).To(matchers.Equal(\"default\"))\n\t})\n\n\to.Spec(\"AutoIncrInsertSuffix\", func(tt testContext) {\n\t\tcm := gorp.ColumnMap{\n\t\t\tColumnName: \"foo\",\n\t\t}\n\t\ttt.expect(tt.dialect.AutoIncrInsertSuffix(&cm)).To(matchers.Equal(` returning \"foo\"`))\n\t})\n\n\to.Spec(\"CreateTableSuffix\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.CreateTableSuffix()).To(matchers.Equal(\"\"))\n\t})\n\n\to.Spec(\"CreateIndexSuffix\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.CreateIndexSuffix()).To(matchers.Equal(\"using\"))\n\t})\n\n\to.Spec(\"DropIndexSuffix\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.DropIndexSuffix()).To(matchers.Equal(\"\"))\n\t})\n\n\to.Spec(\"TruncateClause\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.TruncateClause()).To(matchers.Equal(\"truncate\"))\n\t})\n\n\to.Spec(\"SleepClause\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.SleepClause(1 * time.Second)).To(matchers.Equal(\"pg_sleep(1.000000)\"))\n\t\ttt.expect(tt.dialect.SleepClause(100 * time.Millisecond)).To(matchers.Equal(\"pg_sleep(0.100000)\"))\n\t})\n\n\to.Spec(\"BindVar\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.BindVar(0)).To(matchers.Equal(\"$1\"))\n\t\ttt.expect(tt.dialect.BindVar(4)).To(matchers.Equal(\"$5\"))\n\t})\n\n\to.Group(\"QuoteField\", func() {\n\t\to.Spec(\"By default, case is preserved\", func(tt testContext) {\n\t\t\ttt.expect(tt.dialect.QuoteField(\"Foo\")).To(matchers.Equal(`\"Foo\"`))\n\t\t\ttt.expect(tt.dialect.QuoteField(\"bar\")).To(matchers.Equal(`\"bar\"`))\n\t\t})\n\n\t\to.Group(\"With LowercaseFields set to true\", func() {\n\t\t\to := onpar.BeforeEach(o, func(tt testContext) testContext {\n\t\t\t\ttt.dialect.LowercaseFields = true\n\t\t\t\treturn tt\n\t\t\t})\n\n\t\t\to.Spec(\"fields are lowercased\", func(tt testContext) {\n\t\t\t\ttt.expect(tt.dialect.QuoteField(\"Foo\")).To(matchers.Equal(`\"foo\"`))\n\t\t\t})\n\t\t})\n\t})\n\n\to.Group(\"QuotedTableForQuery\", func() {\n\t\to.Spec(\"using the default schema\", func(tt testContext) {\n\t\t\ttt.expect(tt.dialect.QuotedTableForQuery(\"\", \"foo\")).To(matchers.Equal(`\"foo\"`))\n\t\t})\n\n\t\to.Spec(\"with a supplied schema\", func(tt testContext) {\n\t\t\ttt.expect(tt.dialect.QuotedTableForQuery(\"foo\", \"bar\")).To(matchers.Equal(`foo.\"bar\"`))\n\t\t})\n\t})\n\n\to.Spec(\"IfSchemaNotExists\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.IfSchemaNotExists(\"foo\", \"bar\")).To(matchers.Equal(\"foo if not exists\"))\n\t})\n\n\to.Spec(\"IfTableExists\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.IfTableExists(\"foo\", \"bar\", \"baz\")).To(matchers.Equal(\"foo if exists\"))\n\t})\n\n\to.Spec(\"IfTableNotExists\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.IfTableNotExists(\"foo\", \"bar\", \"baz\")).To(matchers.Equal(\"foo if not exists\"))\n\t})\n}\n"
        },
        {
          "name": "dialect_snowflake.go",
          "type": "blob",
          "size": 3.3388671875,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage gorp\n\nimport (\n  \"fmt\"\n  \"reflect\"\n  \"strings\"\n)\n\ntype SnowflakeDialect struct {\n  suffix          string\n  LowercaseFields bool\n}\n\nfunc (d SnowflakeDialect) QuerySuffix() string { return \";\" }\n\nfunc (d SnowflakeDialect) ToSqlType(val reflect.Type, maxsize int, isAutoIncr bool) string {\n  switch val.Kind() {\n  case reflect.Ptr:\n    return d.ToSqlType(val.Elem(), maxsize, isAutoIncr)\n  case reflect.Bool:\n    return \"boolean\"\n  case reflect.Int,\n    reflect.Int8,\n    reflect.Int16,\n    reflect.Int32,\n    reflect.Uint,\n    reflect.Uint8,\n    reflect.Uint16,\n    reflect.Uint32:\n\n    if isAutoIncr {\n      return \"serial\"\n    }\n    return \"integer\"\n  case reflect.Int64, reflect.Uint64:\n    if isAutoIncr {\n      return \"bigserial\"\n    }\n    return \"bigint\"\n  case reflect.Float64:\n    return \"double precision\"\n  case reflect.Float32:\n    return \"real\"\n  case reflect.Slice:\n    if val.Elem().Kind() == reflect.Uint8 {\n      return \"binary\"\n    }\n  }\n\n  switch val.Name() {\n  case \"NullInt64\":\n    return \"bigint\"\n  case \"NullFloat64\":\n    return \"double precision\"\n  case \"NullBool\":\n    return \"boolean\"\n  case \"Time\", \"NullTime\":\n    return \"timestamp with time zone\"\n  }\n\n  if maxsize > 0 {\n    return fmt.Sprintf(\"varchar(%d)\", maxsize)\n  } else {\n    return \"text\"\n  }\n\n}\n\n// Returns empty string\nfunc (d SnowflakeDialect) AutoIncrStr() string {\n  return \"\"\n}\n\nfunc (d SnowflakeDialect) AutoIncrBindValue() string {\n  return \"default\"\n}\n\nfunc (d SnowflakeDialect) AutoIncrInsertSuffix(col *ColumnMap) string {\n  return \"\"\n}\n\n// Returns suffix\nfunc (d SnowflakeDialect) CreateTableSuffix() string {\n  return d.suffix\n}\n\nfunc (d SnowflakeDialect) CreateIndexSuffix() string {\n  return \"\"\n}\n\nfunc (d SnowflakeDialect) DropIndexSuffix() string {\n  return \"\"\n}\n\nfunc (d SnowflakeDialect) TruncateClause() string {\n  return \"truncate\"\n}\n\n// Returns \"$(i+1)\"\nfunc (d SnowflakeDialect) BindVar(i int) string {\n  return \"?\"\n}\n\nfunc (d SnowflakeDialect) InsertAutoIncrToTarget(exec SqlExecutor, insertSql string, target interface{}, params ...interface{}) error {\n  rows, err := exec.Query(insertSql, params...)\n  if err != nil {\n    return err\n  }\n  defer rows.Close()\n\n  if !rows.Next() {\n    return fmt.Errorf(\"No serial value returned for insert: %s Encountered error: %s\", insertSql, rows.Err())\n  }\n  if err := rows.Scan(target); err != nil {\n    return err\n  }\n  if rows.Next() {\n    return fmt.Errorf(\"more than two serial value returned for insert: %s\", insertSql)\n  }\n  return rows.Err()\n}\n\nfunc (d SnowflakeDialect) QuoteField(f string) string {\n  if d.LowercaseFields {\n    return `\"` + strings.ToLower(f) + `\"`\n  }\n  return `\"` + f + `\"`\n}\n\nfunc (d SnowflakeDialect) QuotedTableForQuery(schema string, table string) string {\n  if strings.TrimSpace(schema) == \"\" {\n    return d.QuoteField(table)\n  }\n\n  return schema + \".\" + d.QuoteField(table)\n}\n\nfunc (d SnowflakeDialect) IfSchemaNotExists(command, schema string) string {\n  return fmt.Sprintf(\"%s if not exists\", command)\n}\n\nfunc (d SnowflakeDialect) IfTableExists(command, schema, table string) string {\n  return fmt.Sprintf(\"%s if exists\", command)\n}\n\nfunc (d SnowflakeDialect) IfTableNotExists(command, schema, table string) string {\n  return fmt.Sprintf(\"%s if not exists\", command)\n}\n"
        },
        {
          "name": "dialect_snowflake_test.go",
          "type": "blob",
          "size": 4.51953125,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\n//go:build !integration\n// +build !integration\n\npackage gorp_test\n\nimport (\n\t\"database/sql\"\n\t\"reflect\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/go-gorp/gorp/v3\"\n\t\"github.com/poy/onpar\"\n\t\"github.com/poy/onpar/expect\"\n\t\"github.com/poy/onpar/matchers\"\n)\n\nfunc TestSnowflakeDialect(t *testing.T) {\n\ttype testContext struct {\n\t\texpect  expect.Expectation\n\t\tdialect gorp.SnowflakeDialect\n\t}\n\n\to := onpar.BeforeEach(onpar.New(t), func(t *testing.T) testContext {\n\t\treturn testContext{\n\t\t\texpect: expect.New(t),\n\t\t\tdialect: gorp.SnowflakeDialect{\n\t\t\t\tLowercaseFields: false,\n\t\t\t},\n\t\t}\n\t})\n\tdefer o.Run()\n\n\to.Group(\"ToSqlType\", func() {\n\t\ttests := []struct {\n\t\t\tname     string\n\t\t\tvalue    interface{}\n\t\t\tmaxSize  int\n\t\t\tautoIncr bool\n\t\t\texpected string\n\t\t}{\n\t\t\t{\"bool\", true, 0, false, \"boolean\"},\n\t\t\t{\"int8\", int8(1), 0, false, \"integer\"},\n\t\t\t{\"uint8\", uint8(1), 0, false, \"integer\"},\n\t\t\t{\"int16\", int16(1), 0, false, \"integer\"},\n\t\t\t{\"uint16\", uint16(1), 0, false, \"integer\"},\n\t\t\t{\"int32\", int32(1), 0, false, \"integer\"},\n\t\t\t{\"int (treated as int32)\", int(1), 0, false, \"integer\"},\n\t\t\t{\"uint32\", uint32(1), 0, false, \"integer\"},\n\t\t\t{\"uint (treated as uint32)\", uint(1), 0, false, \"integer\"},\n\t\t\t{\"int64\", int64(1), 0, false, \"bigint\"},\n\t\t\t{\"uint64\", uint64(1), 0, false, \"bigint\"},\n\t\t\t{\"float32\", float32(1), 0, false, \"real\"},\n\t\t\t{\"float64\", float64(1), 0, false, \"double precision\"},\n\t\t\t{\"[]uint8\", []uint8{1}, 0, false, \"bytea\"},\n\t\t\t{\"NullInt64\", sql.NullInt64{}, 0, false, \"bigint\"},\n\t\t\t{\"NullFloat64\", sql.NullFloat64{}, 0, false, \"double precision\"},\n\t\t\t{\"NullBool\", sql.NullBool{}, 0, false, \"boolean\"},\n\t\t\t{\"Time\", time.Time{}, 0, false, \"timestamp with time zone\"},\n\t\t\t{\"default-size string\", \"\", 0, false, \"text\"},\n\t\t\t{\"sized string\", \"\", 50, false, \"varchar(50)\"},\n\t\t\t{\"large string\", \"\", 1024, false, \"varchar(1024)\"},\n\t\t}\n\t\tfor _, t := range tests {\n\t\t\to.Spec(t.name, func(tt testContext) {\n\t\t\t\ttyp := reflect.TypeOf(t.value)\n\t\t\t\tsqlType := tt.dialect.ToSqlType(typ, t.maxSize, t.autoIncr)\n\t\t\t\ttt.expect(sqlType).To(matchers.Equal(t.expected))\n\t\t\t})\n\t\t}\n\t})\n\n\to.Spec(\"AutoIncrStr\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.AutoIncrStr()).To(matchers.Equal(\"\"))\n\t})\n\n\to.Spec(\"AutoIncrBindValue\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.AutoIncrBindValue()).To(matchers.Equal(\"default\"))\n\t})\n\n\to.Spec(\"AutoIncrInsertSuffix\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.AutoIncrInsertSuffix(nil)).To(matchers.Equal(\"\"))\n\t})\n\n\to.Spec(\"CreateTableSuffix\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.CreateTableSuffix()).To(matchers.Equal(\"\"))\n\t})\n\n\to.Spec(\"CreateIndexSuffix\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.CreateIndexSuffix()).To(matchers.Equal(\"\"))\n\t})\n\n\to.Spec(\"DropIndexSuffix\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.DropIndexSuffix()).To(matchers.Equal(\"\"))\n\t})\n\n\to.Spec(\"TruncateClause\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.TruncateClause()).To(matchers.Equal(\"truncate\"))\n\t})\n\n\to.Spec(\"BindVar\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.BindVar(0)).To(matchers.Equal(\"?\"))\n\t\ttt.expect(tt.dialect.BindVar(4)).To(matchers.Equal(\"?\"))\n\t})\n\n\to.Group(\"QuoteField\", func() {\n\t\to.Spec(\"By default, case is preserved\", func(tt testContext) {\n\t\t\ttt.expect(tt.dialect.QuoteField(\"Foo\")).To(matchers.Equal(`\"Foo\"`))\n\t\t\ttt.expect(tt.dialect.QuoteField(\"bar\")).To(matchers.Equal(`\"bar\"`))\n\t\t})\n\n\t\to.Group(\"With LowercaseFields set to true\", func() {\n\t\t\to := onpar.BeforeEach(o, func(tt testContext) testContext {\n\t\t\t\ttt.dialect.LowercaseFields = true\n\t\t\t\treturn tt\n\t\t\t})\n\n\t\t\to.Spec(\"fields are lowercased\", func(tt testContext) {\n\t\t\t\ttt.expect(tt.dialect.QuoteField(\"Foo\")).To(matchers.Equal(`\"foo\"`))\n\t\t\t})\n\t\t})\n\t})\n\n\to.Group(\"QuotedTableForQuery\", func() {\n\t\to.Spec(\"using the default schema\", func(tt testContext) {\n\t\t\ttt.expect(tt.dialect.QuotedTableForQuery(\"\", \"foo\")).To(matchers.Equal(`\"foo\"`))\n\t\t})\n\n\t\to.Spec(\"with a supplied schema\", func(tt testContext) {\n\t\t\ttt.expect(tt.dialect.QuotedTableForQuery(\"foo\", \"bar\")).To(matchers.Equal(`foo.\"bar\"`))\n\t\t})\n\t})\n\n\to.Spec(\"IfSchemaNotExists\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.IfSchemaNotExists(\"foo\", \"bar\")).To(matchers.Equal(\"foo if not exists\"))\n\t})\n\n\to.Spec(\"IfTableExists\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.IfTableExists(\"foo\", \"bar\", \"baz\")).To(matchers.Equal(\"foo if exists\"))\n\t})\n\n\to.Spec(\"IfTableNotExists\", func(tt testContext) {\n\t\ttt.expect(tt.dialect.IfTableNotExists(\"foo\", \"bar\", \"baz\")).To(matchers.Equal(\"foo if not exists\"))\n\t})\n}\n"
        },
        {
          "name": "dialect_sqlite.go",
          "type": "blob",
          "size": 2.6494140625,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage gorp\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n)\n\ntype SqliteDialect struct {\n\tsuffix string\n}\n\nfunc (d SqliteDialect) QuerySuffix() string { return \";\" }\n\nfunc (d SqliteDialect) ToSqlType(val reflect.Type, maxsize int, isAutoIncr bool) string {\n\tswitch val.Kind() {\n\tcase reflect.Ptr:\n\t\treturn d.ToSqlType(val.Elem(), maxsize, isAutoIncr)\n\tcase reflect.Bool:\n\t\treturn \"integer\"\n\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64, reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64:\n\t\treturn \"integer\"\n\tcase reflect.Float64, reflect.Float32:\n\t\treturn \"real\"\n\tcase reflect.Slice:\n\t\tif val.Elem().Kind() == reflect.Uint8 {\n\t\t\treturn \"blob\"\n\t\t}\n\t}\n\n\tswitch val.Name() {\n\tcase \"NullInt64\":\n\t\treturn \"integer\"\n\tcase \"NullFloat64\":\n\t\treturn \"real\"\n\tcase \"NullBool\":\n\t\treturn \"integer\"\n\tcase \"Time\":\n\t\treturn \"datetime\"\n\t}\n\n\tif maxsize < 1 {\n\t\tmaxsize = 255\n\t}\n\treturn fmt.Sprintf(\"varchar(%d)\", maxsize)\n}\n\n// Returns autoincrement\nfunc (d SqliteDialect) AutoIncrStr() string {\n\treturn \"autoincrement\"\n}\n\nfunc (d SqliteDialect) AutoIncrBindValue() string {\n\treturn \"null\"\n}\n\nfunc (d SqliteDialect) AutoIncrInsertSuffix(col *ColumnMap) string {\n\treturn \"\"\n}\n\n// Returns suffix\nfunc (d SqliteDialect) CreateTableSuffix() string {\n\treturn d.suffix\n}\n\nfunc (d SqliteDialect) CreateIndexSuffix() string {\n\treturn \"\"\n}\n\nfunc (d SqliteDialect) DropIndexSuffix() string {\n\treturn \"\"\n}\n\n// With sqlite, there technically isn't a TRUNCATE statement,\n// but a DELETE FROM uses a truncate optimization:\n// http://www.sqlite.org/lang_delete.html\nfunc (d SqliteDialect) TruncateClause() string {\n\treturn \"delete from\"\n}\n\n// Returns \"?\"\nfunc (d SqliteDialect) BindVar(i int) string {\n\treturn \"?\"\n}\n\nfunc (d SqliteDialect) InsertAutoIncr(exec SqlExecutor, insertSql string, params ...interface{}) (int64, error) {\n\treturn standardInsertAutoIncr(exec, insertSql, params...)\n}\n\nfunc (d SqliteDialect) QuoteField(f string) string {\n\treturn `\"` + f + `\"`\n}\n\n// sqlite does not have schemas like PostgreSQL does, so just escape it like normal\nfunc (d SqliteDialect) QuotedTableForQuery(schema string, table string) string {\n\treturn d.QuoteField(table)\n}\n\nfunc (d SqliteDialect) IfSchemaNotExists(command, schema string) string {\n\treturn fmt.Sprintf(\"%s if not exists\", command)\n}\n\nfunc (d SqliteDialect) IfTableExists(command, schema, table string) string {\n\treturn fmt.Sprintf(\"%s if exists\", command)\n}\n\nfunc (d SqliteDialect) IfTableNotExists(command, schema, table string) string {\n\treturn fmt.Sprintf(\"%s if not exists\", command)\n}\n"
        },
        {
          "name": "dialect_sqlserver.go",
          "type": "blob",
          "size": 3.59765625,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage gorp\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n\t\"strings\"\n)\n\n// Implementation of Dialect for Microsoft SQL Server databases.\n// Use gorp.SqlServerDialect{\"2005\"} for legacy datatypes.\n// Tested with driver: github.com/denisenkom/go-mssqldb\n\ntype SqlServerDialect struct {\n\n\t// If set to \"2005\" legacy datatypes will be used\n\tVersion string\n}\n\nfunc (d SqlServerDialect) ToSqlType(val reflect.Type, maxsize int, isAutoIncr bool) string {\n\tswitch val.Kind() {\n\tcase reflect.Ptr:\n\t\treturn d.ToSqlType(val.Elem(), maxsize, isAutoIncr)\n\tcase reflect.Bool:\n\t\treturn \"bit\"\n\tcase reflect.Int8:\n\t\treturn \"tinyint\"\n\tcase reflect.Uint8:\n\t\treturn \"smallint\"\n\tcase reflect.Int16:\n\t\treturn \"smallint\"\n\tcase reflect.Uint16:\n\t\treturn \"int\"\n\tcase reflect.Int, reflect.Int32:\n\t\treturn \"int\"\n\tcase reflect.Uint, reflect.Uint32:\n\t\treturn \"bigint\"\n\tcase reflect.Int64:\n\t\treturn \"bigint\"\n\tcase reflect.Uint64:\n\t\treturn \"numeric(20,0)\"\n\tcase reflect.Float32:\n\t\treturn \"float(24)\"\n\tcase reflect.Float64:\n\t\treturn \"float(53)\"\n\tcase reflect.Slice:\n\t\tif val.Elem().Kind() == reflect.Uint8 {\n\t\t\treturn \"varbinary\"\n\t\t}\n\t}\n\n\tswitch val.Name() {\n\tcase \"NullInt64\":\n\t\treturn \"bigint\"\n\tcase \"NullFloat64\":\n\t\treturn \"float(53)\"\n\tcase \"NullBool\":\n\t\treturn \"bit\"\n\tcase \"NullTime\", \"Time\":\n\t\tif d.Version == \"2005\" {\n\t\t\treturn \"datetime\"\n\t\t}\n\t\treturn \"datetime2\"\n\t}\n\n\tif maxsize < 1 {\n\t\tif d.Version == \"2005\" {\n\t\t\tmaxsize = 255\n\t\t} else {\n\t\t\treturn fmt.Sprintf(\"nvarchar(max)\")\n\t\t}\n\t}\n\treturn fmt.Sprintf(\"nvarchar(%d)\", maxsize)\n}\n\n// Returns auto_increment\nfunc (d SqlServerDialect) AutoIncrStr() string {\n\treturn \"identity(0,1)\"\n}\n\n// Empty string removes autoincrement columns from the INSERT statements.\nfunc (d SqlServerDialect) AutoIncrBindValue() string {\n\treturn \"\"\n}\n\nfunc (d SqlServerDialect) AutoIncrInsertSuffix(col *ColumnMap) string {\n\treturn \"\"\n}\n\nfunc (d SqlServerDialect) CreateTableSuffix() string { return \";\" }\n\nfunc (d SqlServerDialect) TruncateClause() string {\n\treturn \"truncate table\"\n}\n\n// Returns \"?\"\nfunc (d SqlServerDialect) BindVar(i int) string {\n\treturn \"?\"\n}\n\nfunc (d SqlServerDialect) InsertAutoIncr(exec SqlExecutor, insertSql string, params ...interface{}) (int64, error) {\n\treturn standardInsertAutoIncr(exec, insertSql, params...)\n}\n\nfunc (d SqlServerDialect) QuoteField(f string) string {\n\treturn \"[\" + strings.Replace(f, \"]\", \"]]\", -1) + \"]\"\n}\n\nfunc (d SqlServerDialect) QuotedTableForQuery(schema string, table string) string {\n\tif strings.TrimSpace(schema) == \"\" {\n\t\treturn d.QuoteField(table)\n\t}\n\treturn d.QuoteField(schema) + \".\" + d.QuoteField(table)\n}\n\nfunc (d SqlServerDialect) QuerySuffix() string { return \";\" }\n\nfunc (d SqlServerDialect) IfSchemaNotExists(command, schema string) string {\n\ts := fmt.Sprintf(\"if schema_id(N'%s') is null %s\", schema, command)\n\treturn s\n}\n\nfunc (d SqlServerDialect) IfTableExists(command, schema, table string) string {\n\tvar schema_clause string\n\tif strings.TrimSpace(schema) != \"\" {\n\t\tschema_clause = fmt.Sprintf(\"%s.\", d.QuoteField(schema))\n\t}\n\ts := fmt.Sprintf(\"if object_id('%s%s') is not null %s\", schema_clause, d.QuoteField(table), command)\n\treturn s\n}\n\nfunc (d SqlServerDialect) IfTableNotExists(command, schema, table string) string {\n\tvar schema_clause string\n\tif strings.TrimSpace(schema) != \"\" {\n\t\tschema_clause = fmt.Sprintf(\"%s.\", schema)\n\t}\n\ts := fmt.Sprintf(\"if object_id('%s%s') is null %s\", schema_clause, table, command)\n\treturn s\n}\n\nfunc (d SqlServerDialect) CreateIndexSuffix() string { return \"\" }\nfunc (d SqlServerDialect) DropIndexSuffix() string   { return \"\" }\n"
        },
        {
          "name": "doc.go",
          "type": "blob",
          "size": 0.416015625,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\n// Package gorp provides a simple way to marshal Go structs to and from\n// SQL databases.  It uses the database/sql package, and should work with any\n// compliant database/sql driver.\n//\n// Source code and project home:\n// https://github.com/go-gorp/gorp\npackage gorp\n"
        },
        {
          "name": "errors.go",
          "type": "blob",
          "size": 0.822265625,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage gorp\n\nimport (\n\t\"fmt\"\n)\n\n// A non-fatal error, when a select query returns columns that do not exist\n// as fields in the struct it is being mapped to\n// TODO: discuss wether this needs an error. encoding/json silently ignores missing fields\ntype NoFieldInTypeError struct {\n\tTypeName        string\n\tMissingColNames []string\n}\n\nfunc (err *NoFieldInTypeError) Error() string {\n\treturn fmt.Sprintf(\"gorp: no fields %+v in type %s\", err.MissingColNames, err.TypeName)\n}\n\n// returns true if the error is non-fatal (ie, we shouldn't immediately return)\nfunc NonFatalError(err error) bool {\n\tswitch err.(type) {\n\tcase *NoFieldInTypeError:\n\t\treturn true\n\tdefault:\n\t\treturn false\n\t}\n}\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.7265625,
          "content": "module github.com/go-gorp/gorp/v3\n\ngo 1.18\n\n// Versions prior to 3.0.4 had a vulnerability in the dependency graph.  While we don't\n// directly use yaml, I'm not comfortable encouraging people to use versions with a\n// CVE - so prior versions are retracted.\n//\n// See CVE-2019-11254\nretract [v3.0.0, v3.0.3]\n\nrequire (\n\tgithub.com/go-sql-driver/mysql v1.6.0\n\tgithub.com/lib/pq v1.10.7\n\tgithub.com/mattn/go-sqlite3 v1.14.15\n\tgithub.com/poy/onpar v0.3.2\n\tgithub.com/stretchr/testify v1.8.0\n)\n\nrequire (\n\tgithub.com/davecgh/go-spew v1.1.1 // indirect\n\tgithub.com/kr/pretty v0.3.1 // indirect\n\tgithub.com/pmezard/go-difflib v1.0.0 // indirect\n\tgopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c // indirect\n\tgopkg.in/yaml.v3 v3.0.1 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 3.0556640625,
          "content": "git.sr.ht/~nelsam/hel v0.4.3 h1:9W0zz8zv8CZhFsp8r9Wq6c8gFemBdtMurjZU/JKfvfM=\ngithub.com/creack/pty v1.1.9/go.mod h1:oKZEueFk5CKHvIhNR5MUki03XCEU+Q6VDXinZuGJ33E=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/go-sql-driver/mysql v1.6.0 h1:BCTh4TKNUYmOmMUcQ3IipzF5prigylS7XXjEkfCHuOE=\ngithub.com/go-sql-driver/mysql v1.6.0/go.mod h1:DCzpHaOWr8IXmIStZouvnhqoel9Qv2LBy8hT2VhHyBg=\ngithub.com/kr/pretty v0.2.1/go.mod h1:ipq/a2n7PKx3OHsz4KJII5eveXtPO4qwEXGdVfWzfnI=\ngithub.com/kr/pretty v0.3.1 h1:flRD4NNwYAUpkphVc1HcthR4KEIFJ65n8Mw5qdRn3LE=\ngithub.com/kr/pretty v0.3.1/go.mod h1:hoEshYVHaxMs3cyo3Yncou5ZscifuDolrwPKZanG3xk=\ngithub.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=\ngithub.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=\ngithub.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=\ngithub.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=\ngithub.com/lib/pq v1.10.7 h1:p7ZhMD+KsSRozJr34udlUrhboJwWAgCg34+/ZZNvZZw=\ngithub.com/lib/pq v1.10.7/go.mod h1:AlVN5x4E4T544tWzH6hKfbfQvm3HdbOxrmggDNAPY9o=\ngithub.com/mattn/go-sqlite3 v1.14.15 h1:vfoHhTN1af61xCRSWzFIWzx2YskyMTwHLrExkBOjvxI=\ngithub.com/mattn/go-sqlite3 v1.14.15/go.mod h1:2eHXhiwb8IkHr+BDWZGa96P6+rkvnG63S2DGjv9HUNg=\ngithub.com/pkg/diff v0.0.0-20210226163009-20ebb0f2a09e/go.mod h1:pJLUxLENpZxwdsKMEsNbx1VGcRFpLqf3715MtcvvzbA=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/poy/onpar v0.3.2 h1:yo8ZRqU3C4RlvkXPWUWfonQiTodAgpKQZ1g8VTNU9xU=\ngithub.com/poy/onpar v0.3.2/go.mod h1:6XDWG8DJ1HsFX6/Btn0pHl3Jz5d1SEEGNZ5N1gtYo+I=\ngithub.com/rogpeppe/go-internal v1.9.0 h1:73kH8U+JUqXU8lRuOHeVHaa/SZPifC7BkcraZVejAe8=\ngithub.com/rogpeppe/go-internal v1.9.0/go.mod h1:WtVeX8xhTBvf0smdhujwtBcq4Qrzq/fJaraNFVN+nFs=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.4.0/go.mod h1:YvHI0jy2hoMjB+UWwv71VJQ9isScKT/TqJzVSSt89Yw=\ngithub.com/stretchr/testify v1.7.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.8.0 h1:pSgiaMZlXftHpm5L7V1+rVB+AZJydKsMxsQBIJw4PKk=\ngithub.com/stretchr/testify v1.8.0/go.mod h1:yNjHg4UonilssWZ8iaSj1OCr/vHnekPRkoO+kdMU+MU=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c h1:Hei/4ADfdWqJk1ZMxUNpqntNwaWcugrBjAiHlqqRiVk=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c/go.mod h1:JHkPIbrfpd72SG/EVd6muEfDQjcINNoR0C8j2r3qZ4Q=\ngopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\n"
        },
        {
          "name": "gorp.go",
          "type": "blob",
          "size": 17.107421875,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage gorp\n\nimport (\n\t\"context\"\n\t\"database/sql\"\n\t\"database/sql/driver\"\n\t\"fmt\"\n\t\"reflect\"\n\t\"regexp\"\n\t\"strings\"\n\t\"time\"\n)\n\n// OracleString (empty string is null)\n// TODO: move to dialect/oracle?, rename to String?\ntype OracleString struct {\n\tsql.NullString\n}\n\n// Scan implements the Scanner interface.\nfunc (os *OracleString) Scan(value interface{}) error {\n\tif value == nil {\n\t\tos.String, os.Valid = \"\", false\n\t\treturn nil\n\t}\n\tos.Valid = true\n\treturn os.NullString.Scan(value)\n}\n\n// Value implements the driver Valuer interface.\nfunc (os OracleString) Value() (driver.Value, error) {\n\tif !os.Valid || os.String == \"\" {\n\t\treturn nil, nil\n\t}\n\treturn os.String, nil\n}\n\n// SqlTyper is a type that returns its database type.  Most of the\n// time, the type can just use \"database/sql/driver\".Valuer; but when\n// it returns nil for its empty value, it needs to implement SqlTyper\n// to have its column type detected properly during table creation.\ntype SqlTyper interface {\n\tSqlType() driver.Value\n}\n\n// legacySqlTyper prevents breaking clients who depended on the previous\n// SqlTyper interface\ntype legacySqlTyper interface {\n\tSqlType() driver.Valuer\n}\n\n// for fields that exists in DB table, but not exists in struct\ntype dummyField struct{}\n\n// Scan implements the Scanner interface.\nfunc (nt *dummyField) Scan(value interface{}) error {\n\treturn nil\n}\n\nvar zeroVal reflect.Value\nvar versFieldConst = \"[gorp_ver_field]\"\n\n// The TypeConverter interface provides a way to map a value of one\n// type to another type when persisting to, or loading from, a database.\n//\n// Example use cases: Implement type converter to convert bool types to \"y\"/\"n\" strings,\n// or serialize a struct member as a JSON blob.\ntype TypeConverter interface {\n\t// ToDb converts val to another type. Called before INSERT/UPDATE operations\n\tToDb(val interface{}) (interface{}, error)\n\n\t// FromDb returns a CustomScanner appropriate for this type. This will be used\n\t// to hold values returned from SELECT queries.\n\t//\n\t// In particular the CustomScanner returned should implement a Binder\n\t// function appropriate for the Go type you wish to convert the db value to\n\t//\n\t// If bool==false, then no custom scanner will be used for this field.\n\tFromDb(target interface{}) (CustomScanner, bool)\n}\n\n// SqlExecutor exposes gorp operations that can be run from Pre/Post\n// hooks.  This hides whether the current operation that triggered the\n// hook is in a transaction.\n//\n// See the DbMap function docs for each of the functions below for more\n// information.\ntype SqlExecutor interface {\n\tWithContext(ctx context.Context) SqlExecutor\n\tGet(i interface{}, keys ...interface{}) (interface{}, error)\n\tInsert(list ...interface{}) error\n\tUpdate(list ...interface{}) (int64, error)\n\tDelete(list ...interface{}) (int64, error)\n\tExec(query string, args ...interface{}) (sql.Result, error)\n\tSelect(i interface{}, query string, args ...interface{}) ([]interface{}, error)\n\tSelectInt(query string, args ...interface{}) (int64, error)\n\tSelectNullInt(query string, args ...interface{}) (sql.NullInt64, error)\n\tSelectFloat(query string, args ...interface{}) (float64, error)\n\tSelectNullFloat(query string, args ...interface{}) (sql.NullFloat64, error)\n\tSelectStr(query string, args ...interface{}) (string, error)\n\tSelectNullStr(query string, args ...interface{}) (sql.NullString, error)\n\tSelectOne(holder interface{}, query string, args ...interface{}) error\n\tQuery(query string, args ...interface{}) (*sql.Rows, error)\n\tQueryRow(query string, args ...interface{}) *sql.Row\n}\n\n// DynamicTable allows the users of gorp to dynamically\n// use different database table names during runtime\n// while sharing the same golang struct for in-memory data\ntype DynamicTable interface {\n\tTableName() string\n\tSetTableName(string)\n}\n\n// Compile-time check that DbMap and Transaction implement the SqlExecutor\n// interface.\nvar _, _ SqlExecutor = &DbMap{}, &Transaction{}\n\nfunc argValue(a interface{}) interface{} {\n\tv, ok := a.(driver.Valuer)\n\tif !ok {\n\t\treturn a\n\t}\n\tvV := reflect.ValueOf(v)\n\tif vV.Kind() == reflect.Ptr && vV.IsNil() {\n\t\treturn nil\n\t}\n\tret, err := v.Value()\n\tif err != nil {\n\t\treturn a\n\t}\n\treturn ret\n}\n\nfunc argsString(args ...interface{}) string {\n\tvar margs string\n\tfor i, a := range args {\n\t\tv := argValue(a)\n\t\tswitch v.(type) {\n\t\tcase string:\n\t\t\tv = fmt.Sprintf(\"%q\", v)\n\t\tdefault:\n\t\t\tv = fmt.Sprintf(\"%v\", v)\n\t\t}\n\t\tmargs += fmt.Sprintf(\"%d:%s\", i+1, v)\n\t\tif i+1 < len(args) {\n\t\t\tmargs += \" \"\n\t\t}\n\t}\n\treturn margs\n}\n\n// Calls the Exec function on the executor, but attempts to expand any eligible named\n// query arguments first.\nfunc maybeExpandNamedQueryAndExec(e SqlExecutor, query string, args ...interface{}) (sql.Result, error) {\n\tdbMap := extractDbMap(e)\n\n\tif len(args) == 1 {\n\t\tquery, args = maybeExpandNamedQuery(dbMap, query, args)\n\t}\n\n\treturn exec(e, query, args...)\n}\n\nfunc extractDbMap(e SqlExecutor) *DbMap {\n\tswitch m := e.(type) {\n\tcase *DbMap:\n\t\treturn m\n\tcase *Transaction:\n\t\treturn m.dbmap\n\t}\n\treturn nil\n}\n\n// executor exposes the sql.DB and sql.Tx functions so that it can be used\n// on internal functions that need to be agnostic to the underlying object.\ntype executor interface {\n\tExec(query string, args ...interface{}) (sql.Result, error)\n\tPrepare(query string) (*sql.Stmt, error)\n\tQueryRow(query string, args ...interface{}) *sql.Row\n\tQuery(query string, args ...interface{}) (*sql.Rows, error)\n\tExecContext(ctx context.Context, query string, args ...interface{}) (sql.Result, error)\n\tPrepareContext(ctx context.Context, query string) (*sql.Stmt, error)\n\tQueryRowContext(ctx context.Context, query string, args ...interface{}) *sql.Row\n\tQueryContext(ctx context.Context, query string, args ...interface{}) (*sql.Rows, error)\n}\n\nfunc extractExecutorAndContext(e SqlExecutor) (executor, context.Context) {\n\tswitch m := e.(type) {\n\tcase *DbMap:\n\t\treturn m.Db, m.ctx\n\tcase *Transaction:\n\t\treturn m.tx, m.ctx\n\t}\n\treturn nil, nil\n}\n\n// maybeExpandNamedQuery checks the given arg to see if it's eligible to be used\n// as input to a named query.  If so, it rewrites the query to use\n// dialect-dependent bindvars and instantiates the corresponding slice of\n// parameters by extracting data from the map / struct.\n// If not, returns the input values unchanged.\nfunc maybeExpandNamedQuery(m *DbMap, query string, args []interface{}) (string, []interface{}) {\n\tvar (\n\t\targ    = args[0]\n\t\targval = reflect.ValueOf(arg)\n\t)\n\tif argval.Kind() == reflect.Ptr {\n\t\targval = argval.Elem()\n\t}\n\n\tif argval.Kind() == reflect.Map && argval.Type().Key().Kind() == reflect.String {\n\t\treturn expandNamedQuery(m, query, func(key string) reflect.Value {\n\t\t\treturn argval.MapIndex(reflect.ValueOf(key))\n\t\t})\n\t}\n\tif argval.Kind() != reflect.Struct {\n\t\treturn query, args\n\t}\n\tif _, ok := arg.(time.Time); ok {\n\t\t// time.Time is driver.Value\n\t\treturn query, args\n\t}\n\tif _, ok := arg.(driver.Valuer); ok {\n\t\t// driver.Valuer will be converted to driver.Value.\n\t\treturn query, args\n\t}\n\n\treturn expandNamedQuery(m, query, argval.FieldByName)\n}\n\nvar keyRegexp = regexp.MustCompile(`:[[:word:]]+`)\n\n// expandNamedQuery accepts a query with placeholders of the form \":key\", and a\n// single arg of Kind Struct or Map[string].  It returns the query with the\n// dialect's placeholders, and a slice of args ready for positional insertion\n// into the query.\nfunc expandNamedQuery(m *DbMap, query string, keyGetter func(key string) reflect.Value) (string, []interface{}) {\n\tvar (\n\t\tn    int\n\t\targs []interface{}\n\t)\n\treturn keyRegexp.ReplaceAllStringFunc(query, func(key string) string {\n\t\tval := keyGetter(key[1:])\n\t\tif !val.IsValid() {\n\t\t\treturn key\n\t\t}\n\t\targs = append(args, val.Interface())\n\t\tnewVar := m.Dialect.BindVar(n)\n\t\tn++\n\t\treturn newVar\n\t}), args\n}\n\nfunc columnToFieldIndex(m *DbMap, t reflect.Type, name string, cols []string) ([][]int, error) {\n\tcolToFieldIndex := make([][]int, len(cols))\n\n\t// check if type t is a mapped table - if so we'll\n\t// check the table for column aliasing below\n\ttableMapped := false\n\ttable := tableOrNil(m, t, name)\n\tif table != nil {\n\t\ttableMapped = true\n\t}\n\n\t// Loop over column names and find field in i to bind to\n\t// based on column name. all returned columns must match\n\t// a field in the i struct\n\tmissingColNames := []string{}\n\tfor x := range cols {\n\t\tcolName := strings.ToLower(cols[x])\n\t\tfield, found := t.FieldByNameFunc(func(fieldName string) bool {\n\t\t\tfield, _ := t.FieldByName(fieldName)\n\t\t\tcArguments := strings.Split(field.Tag.Get(\"db\"), \",\")\n\t\t\tfieldName = cArguments[0]\n\n\t\t\tif fieldName == \"-\" {\n\t\t\t\treturn false\n\t\t\t} else if fieldName == \"\" {\n\t\t\t\tfieldName = field.Name\n\t\t\t}\n\t\t\tif tableMapped {\n\t\t\t\tcolMap := colMapOrNil(table, fieldName)\n\t\t\t\tif colMap != nil {\n\t\t\t\t\tfieldName = colMap.ColumnName\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn colName == strings.ToLower(fieldName)\n\t\t})\n\t\tif found {\n\t\t\tcolToFieldIndex[x] = field.Index\n\t\t}\n\t\tif colToFieldIndex[x] == nil {\n\t\t\tmissingColNames = append(missingColNames, colName)\n\t\t}\n\t}\n\tif len(missingColNames) > 0 {\n\t\treturn colToFieldIndex, &NoFieldInTypeError{\n\t\t\tTypeName:        t.Name(),\n\t\t\tMissingColNames: missingColNames,\n\t\t}\n\t}\n\treturn colToFieldIndex, nil\n}\n\nfunc fieldByName(val reflect.Value, fieldName string) *reflect.Value {\n\t// try to find field by exact match\n\tf := val.FieldByName(fieldName)\n\n\tif f != zeroVal {\n\t\treturn &f\n\t}\n\n\t// try to find by case insensitive match - only the Postgres driver\n\t// seems to require this - in the case where columns are aliased in the sql\n\tfieldNameL := strings.ToLower(fieldName)\n\tfieldCount := val.NumField()\n\tt := val.Type()\n\tfor i := 0; i < fieldCount; i++ {\n\t\tsf := t.Field(i)\n\t\tif strings.ToLower(sf.Name) == fieldNameL {\n\t\t\tf := val.Field(i)\n\t\t\treturn &f\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// toSliceType returns the element type of the given object, if the object is a\n// \"*[]*Element\" or \"*[]Element\". If not, returns nil.\n// err is returned if the user was trying to pass a pointer-to-slice but failed.\nfunc toSliceType(i interface{}) (reflect.Type, error) {\n\tt := reflect.TypeOf(i)\n\tif t.Kind() != reflect.Ptr {\n\t\t// If it's a slice, return a more helpful error message\n\t\tif t.Kind() == reflect.Slice {\n\t\t\treturn nil, fmt.Errorf(\"gorp: cannot SELECT into a non-pointer slice: %v\", t)\n\t\t}\n\t\treturn nil, nil\n\t}\n\tif t = t.Elem(); t.Kind() != reflect.Slice {\n\t\treturn nil, nil\n\t}\n\treturn t.Elem(), nil\n}\n\nfunc toType(i interface{}) (reflect.Type, error) {\n\tt := reflect.TypeOf(i)\n\n\t// If a Pointer to a type, follow\n\tfor t.Kind() == reflect.Ptr {\n\t\tt = t.Elem()\n\t}\n\n\tif t.Kind() != reflect.Struct {\n\t\treturn nil, fmt.Errorf(\"gorp: cannot SELECT into this type: %v\", reflect.TypeOf(i))\n\t}\n\treturn t, nil\n}\n\ntype foundTable struct {\n\ttable   *TableMap\n\tdynName *string\n}\n\nfunc tableFor(m *DbMap, t reflect.Type, i interface{}) (*foundTable, error) {\n\tif dyn, isDynamic := i.(DynamicTable); isDynamic {\n\t\ttableName := dyn.TableName()\n\t\ttable, err := m.DynamicTableFor(tableName, true)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn &foundTable{\n\t\t\ttable:   table,\n\t\t\tdynName: &tableName,\n\t\t}, nil\n\t}\n\ttable, err := m.TableFor(t, true)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &foundTable{table: table}, nil\n}\n\nfunc get(m *DbMap, exec SqlExecutor, i interface{},\n\tkeys ...interface{}) (interface{}, error) {\n\n\tt, err := toType(i)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfoundTable, err := tableFor(m, t, i)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ttable := foundTable.table\n\n\tplan := table.bindGet()\n\n\tv := reflect.New(t)\n\tif foundTable.dynName != nil {\n\t\tretDyn := v.Interface().(DynamicTable)\n\t\tretDyn.SetTableName(*foundTable.dynName)\n\t}\n\n\tdest := make([]interface{}, len(plan.argFields))\n\n\tconv := m.TypeConverter\n\tcustScan := make([]CustomScanner, 0)\n\n\tfor x, fieldName := range plan.argFields {\n\t\tf := v.Elem().FieldByName(fieldName)\n\t\ttarget := f.Addr().Interface()\n\t\tif conv != nil {\n\t\t\tscanner, ok := conv.FromDb(target)\n\t\t\tif ok {\n\t\t\t\ttarget = scanner.Holder\n\t\t\t\tcustScan = append(custScan, scanner)\n\t\t\t}\n\t\t}\n\t\tdest[x] = target\n\t}\n\n\trow := exec.QueryRow(plan.query, keys...)\n\terr = row.Scan(dest...)\n\tif err != nil {\n\t\tif err == sql.ErrNoRows {\n\t\t\terr = nil\n\t\t}\n\t\treturn nil, err\n\t}\n\n\tfor _, c := range custScan {\n\t\terr = c.Bind()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif v, ok := v.Interface().(HasPostGet); ok {\n\t\terr := v.PostGet(exec)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn v.Interface(), nil\n}\n\nfunc delete(m *DbMap, exec SqlExecutor, list ...interface{}) (int64, error) {\n\tcount := int64(0)\n\tfor _, ptr := range list {\n\t\ttable, elem, err := m.tableForPointer(ptr, true)\n\t\tif err != nil {\n\t\t\treturn -1, err\n\t\t}\n\n\t\teval := elem.Addr().Interface()\n\t\tif v, ok := eval.(HasPreDelete); ok {\n\t\t\terr = v.PreDelete(exec)\n\t\t\tif err != nil {\n\t\t\t\treturn -1, err\n\t\t\t}\n\t\t}\n\n\t\tbi, err := table.bindDelete(elem)\n\t\tif err != nil {\n\t\t\treturn -1, err\n\t\t}\n\n\t\tres, err := exec.Exec(bi.query, bi.args...)\n\t\tif err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\trows, err := res.RowsAffected()\n\t\tif err != nil {\n\t\t\treturn -1, err\n\t\t}\n\n\t\tif rows == 0 && bi.existingVersion > 0 {\n\t\t\treturn lockError(m, exec, table.TableName,\n\t\t\t\tbi.existingVersion, elem, bi.keys...)\n\t\t}\n\n\t\tcount += rows\n\n\t\tif v, ok := eval.(HasPostDelete); ok {\n\t\t\terr := v.PostDelete(exec)\n\t\t\tif err != nil {\n\t\t\t\treturn -1, err\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count, nil\n}\n\nfunc update(m *DbMap, exec SqlExecutor, colFilter ColumnFilter, list ...interface{}) (int64, error) {\n\tcount := int64(0)\n\tfor _, ptr := range list {\n\t\ttable, elem, err := m.tableForPointer(ptr, true)\n\t\tif err != nil {\n\t\t\treturn -1, err\n\t\t}\n\n\t\teval := elem.Addr().Interface()\n\t\tif v, ok := eval.(HasPreUpdate); ok {\n\t\t\terr = v.PreUpdate(exec)\n\t\t\tif err != nil {\n\t\t\t\treturn -1, err\n\t\t\t}\n\t\t}\n\n\t\tbi, err := table.bindUpdate(elem, colFilter)\n\t\tif err != nil {\n\t\t\treturn -1, err\n\t\t}\n\n\t\tres, err := exec.Exec(bi.query, bi.args...)\n\t\tif err != nil {\n\t\t\treturn -1, err\n\t\t}\n\n\t\trows, err := res.RowsAffected()\n\t\tif err != nil {\n\t\t\treturn -1, err\n\t\t}\n\n\t\tif rows == 0 && bi.existingVersion > 0 {\n\t\t\treturn lockError(m, exec, table.TableName,\n\t\t\t\tbi.existingVersion, elem, bi.keys...)\n\t\t}\n\n\t\tif bi.versField != \"\" {\n\t\t\telem.FieldByName(bi.versField).SetInt(bi.existingVersion + 1)\n\t\t}\n\n\t\tcount += rows\n\n\t\tif v, ok := eval.(HasPostUpdate); ok {\n\t\t\terr = v.PostUpdate(exec)\n\t\t\tif err != nil {\n\t\t\t\treturn -1, err\n\t\t\t}\n\t\t}\n\t}\n\treturn count, nil\n}\n\nfunc insert(m *DbMap, exec SqlExecutor, list ...interface{}) error {\n\tfor _, ptr := range list {\n\t\ttable, elem, err := m.tableForPointer(ptr, false)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\teval := elem.Addr().Interface()\n\t\tif v, ok := eval.(HasPreInsert); ok {\n\t\t\terr := v.PreInsert(exec)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\tbi, err := table.bindInsert(elem)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif bi.autoIncrIdx > -1 {\n\t\t\tf := elem.FieldByName(bi.autoIncrFieldName)\n\t\t\tswitch inserter := m.Dialect.(type) {\n\t\t\tcase IntegerAutoIncrInserter:\n\t\t\t\tid, err := inserter.InsertAutoIncr(exec, bi.query, bi.args...)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tk := f.Kind()\n\t\t\t\tif (k == reflect.Int) || (k == reflect.Int16) || (k == reflect.Int32) || (k == reflect.Int64) {\n\t\t\t\t\tf.SetInt(id)\n\t\t\t\t} else if (k == reflect.Uint) || (k == reflect.Uint16) || (k == reflect.Uint32) || (k == reflect.Uint64) {\n\t\t\t\t\tf.SetUint(uint64(id))\n\t\t\t\t} else {\n\t\t\t\t\treturn fmt.Errorf(\"gorp: cannot set autoincrement value on non-Int field. SQL=%s  autoIncrIdx=%d autoIncrFieldName=%s\", bi.query, bi.autoIncrIdx, bi.autoIncrFieldName)\n\t\t\t\t}\n\t\t\tcase TargetedAutoIncrInserter:\n\t\t\t\terr := inserter.InsertAutoIncrToTarget(exec, bi.query, f.Addr().Interface(), bi.args...)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\tcase TargetQueryInserter:\n\t\t\t\tvar idQuery = table.ColMap(bi.autoIncrFieldName).GeneratedIdQuery\n\t\t\t\tif idQuery == \"\" {\n\t\t\t\t\treturn fmt.Errorf(\"gorp: cannot set %s value if its ColumnMap.GeneratedIdQuery is empty\", bi.autoIncrFieldName)\n\t\t\t\t}\n\t\t\t\terr := inserter.InsertQueryToTarget(exec, bi.query, idQuery, f.Addr().Interface(), bi.args...)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\treturn fmt.Errorf(\"gorp: cannot use autoincrement fields on dialects that do not implement an autoincrementing interface\")\n\t\t\t}\n\t\t} else {\n\t\t\t_, err := exec.Exec(bi.query, bi.args...)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\tif v, ok := eval.(HasPostInsert); ok {\n\t\t\terr := v.PostInsert(exec)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc exec(e SqlExecutor, query string, args ...interface{}) (sql.Result, error) {\n\texecutor, ctx := extractExecutorAndContext(e)\n\n\tif ctx != nil {\n\t\treturn executor.ExecContext(ctx, query, args...)\n\t}\n\n\treturn executor.Exec(query, args...)\n}\n\nfunc prepare(e SqlExecutor, query string) (*sql.Stmt, error) {\n\texecutor, ctx := extractExecutorAndContext(e)\n\n\tif ctx != nil {\n\t\treturn executor.PrepareContext(ctx, query)\n\t}\n\n\treturn executor.Prepare(query)\n}\n\nfunc queryRow(e SqlExecutor, query string, args ...interface{}) *sql.Row {\n\texecutor, ctx := extractExecutorAndContext(e)\n\n\tif ctx != nil {\n\t\treturn executor.QueryRowContext(ctx, query, args...)\n\t}\n\n\treturn executor.QueryRow(query, args...)\n}\n\nfunc query(e SqlExecutor, query string, args ...interface{}) (*sql.Rows, error) {\n\texecutor, ctx := extractExecutorAndContext(e)\n\n\tif ctx != nil {\n\t\treturn executor.QueryContext(ctx, query, args...)\n\t}\n\n\treturn executor.Query(query, args...)\n}\n\nfunc begin(m *DbMap) (*sql.Tx, error) {\n\tif m.ctx != nil {\n\t\treturn m.Db.BeginTx(m.ctx, nil)\n\t}\n\n\treturn m.Db.Begin()\n}\n"
        },
        {
          "name": "gorp_test.go",
          "type": "blob",
          "size": 76.03125,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\n//go:build integration\n// +build integration\n\npackage gorp_test\n\nimport (\n\t\"bytes\"\n\t\"database/sql\"\n\t\"database/sql/driver\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"flag\"\n\t\"fmt\"\n\t\"log\"\n\t\"math/rand\"\n\t\"os\"\n\t\"reflect\"\n\t\"strconv\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/go-gorp/gorp/v3\"\n\n\t_ \"github.com/go-sql-driver/mysql\"\n\t_ \"github.com/lib/pq\"\n\t_ \"github.com/mattn/go-sqlite3\"\n)\n\nvar (\n\t// verify interface compliance\n\t_ = []gorp.Dialect{\n\t\tgorp.SqliteDialect{},\n\t\tgorp.PostgresDialect{},\n\t\tgorp.MySQLDialect{},\n\t\tgorp.SqlServerDialect{},\n\t\tgorp.OracleDialect{},\n\t}\n\n\tdebug bool\n)\n\nfunc TestMain(m *testing.M) {\n\tflag.BoolVar(&debug, \"trace\", true, \"Turn on or off database tracing (DbMap.TraceOn)\")\n\tflag.Parse()\n\tos.Exit(m.Run())\n}\n\ntype testable interface {\n\tGetId() int64\n\tRand()\n}\n\ntype Invoice struct {\n\tId       int64\n\tCreated  int64\n\tUpdated  int64\n\tMemo     string\n\tPersonId int64\n\tIsPaid   bool\n}\n\ntype InvoiceWithValuer struct {\n\tId      int64\n\tCreated int64\n\tUpdated int64\n\tMemo    string\n\tPerson  PersonValuerScanner `db:\"personid\"`\n\tIsPaid  bool\n}\n\nfunc (me *Invoice) GetId() int64 { return me.Id }\nfunc (me *Invoice) Rand() {\n\tme.Memo = fmt.Sprintf(\"random %d\", rand.Int63())\n\tme.Created = rand.Int63()\n\tme.Updated = rand.Int63()\n}\n\ntype InvoiceTag struct {\n\tId       int64 `db:\"myid, primarykey, autoincrement\"`\n\tCreated  int64 `db:\"myCreated\"`\n\tUpdated  int64 `db:\"date_updated\"`\n\tMemo     string\n\tPersonId int64 `db:\"person_id\"`\n\tIsPaid   bool  `db:\"is_Paid\"`\n}\n\nfunc (me *InvoiceTag) GetId() int64 { return me.Id }\nfunc (me *InvoiceTag) Rand() {\n\tme.Memo = fmt.Sprintf(\"random %d\", rand.Int63())\n\tme.Created = rand.Int63()\n\tme.Updated = rand.Int63()\n}\n\n// See: https://github.com/go-gorp/gorp/issues/175\ntype AliasTransientField struct {\n\tId     int64  `db:\"id\"`\n\tBar    int64  `db:\"-\"`\n\tBarStr string `db:\"bar\"`\n}\n\nfunc (me *AliasTransientField) GetId() int64 { return me.Id }\nfunc (me *AliasTransientField) Rand() {\n\tme.BarStr = fmt.Sprintf(\"random %d\", rand.Int63())\n}\n\ntype OverriddenInvoice struct {\n\tInvoice\n\tId string\n}\n\ntype Person struct {\n\tId      int64\n\tCreated int64\n\tUpdated int64\n\tFName   string\n\tLName   string\n\tVersion int64\n}\n\n// PersonValuerScanner is used as a field in test types to ensure that we\n// make use of \"database/sql/driver\".Valuer for choosing column types when\n// creating tables and that we don't get in the way of the underlying\n// database libraries when they make use of either Valuer or\n// \"database/sql\".Scanner.\ntype PersonValuerScanner struct {\n\tPerson\n}\n\n// Value implements \"database/sql/driver\".Valuer.  It will be automatically\n// run by the \"database/sql\" package when inserting/updating data.\nfunc (p PersonValuerScanner) Value() (driver.Value, error) {\n\treturn p.Id, nil\n}\n\n// Scan implements \"database/sql\".Scanner.  It will be automatically run\n// by the \"database/sql\" package when reading column data into a field\n// of type PersonValuerScanner.\nfunc (p *PersonValuerScanner) Scan(value interface{}) (err error) {\n\tswitch src := value.(type) {\n\tcase []byte:\n\t\t// TODO: this case is here for mysql only.  For some reason,\n\t\t// one (both?) of the mysql libraries opt to pass us a []byte\n\t\t// instead of an int64 for the bigint column.  We should add\n\t\t// table tests around valuers/scanners and try to solve these\n\t\t// types of odd discrepencies to make it easier for users of\n\t\t// gorp to migrate to other database engines.\n\t\tp.Id, err = strconv.ParseInt(string(src), 10, 64)\n\tcase int64:\n\t\t// Most libraries pass in the type we'd expect.\n\t\tp.Id = src\n\tdefault:\n\t\ttyp := reflect.TypeOf(value)\n\t\treturn fmt.Errorf(\"Expected person value to be convertible to int64, got %v (type %s)\", value, typ)\n\t}\n\treturn\n}\n\ntype FNameOnly struct {\n\tFName string\n}\n\ntype InvoicePersonView struct {\n\tInvoiceId     int64\n\tPersonId      int64\n\tMemo          string\n\tFName         string\n\tLegacyVersion int64\n}\n\ntype TableWithNull struct {\n\tId      int64\n\tStr     sql.NullString\n\tInt64   sql.NullInt64\n\tFloat64 sql.NullFloat64\n\tBool    sql.NullBool\n\tBytes   []byte\n}\n\ntype WithIgnoredColumn struct {\n\tinternal int64 `db:\"-\"`\n\tId       int64\n\tCreated  int64\n}\n\ntype IdCreated struct {\n\tId      int64\n\tCreated int64\n}\n\ntype IdCreatedExternal struct {\n\tIdCreated\n\tExternal int64\n}\n\ntype WithStringPk struct {\n\tId   string\n\tName string\n}\n\ntype CustomStringType string\n\ntype TypeConversionExample struct {\n\tId         int64\n\tPersonJSON Person\n\tName       CustomStringType\n}\n\ntype PersonUInt32 struct {\n\tId   uint32\n\tName string\n}\n\ntype PersonUInt64 struct {\n\tId   uint64\n\tName string\n}\n\ntype PersonUInt16 struct {\n\tId   uint16\n\tName string\n}\n\ntype WithEmbeddedStruct struct {\n\tId int64\n\tNames\n}\n\ntype WithEmbeddedStructConflictingEmbeddedMemberNames struct {\n\tId int64\n\tNames\n\tNamesConflict\n}\n\ntype WithEmbeddedStructSameMemberName struct {\n\tId int64\n\tSameName\n}\n\ntype WithEmbeddedStructBeforeAutoincrField struct {\n\tNames\n\tId int64\n}\n\ntype WithEmbeddedAutoincr struct {\n\tWithEmbeddedStruct\n\tMiddleName string\n}\n\ntype Names struct {\n\tFirstName string\n\tLastName  string\n}\n\ntype NamesConflict struct {\n\tFirstName string\n\tSurname   string\n}\n\ntype SameName struct {\n\tSameName string\n}\n\ntype UniqueColumns struct {\n\tFirstName string\n\tLastName  string\n\tCity      string\n\tZipCode   int64\n}\n\ntype SingleColumnTable struct {\n\tSomeId string\n}\n\ntype CustomDate struct {\n\ttime.Time\n}\n\ntype WithCustomDate struct {\n\tId    int64\n\tAdded CustomDate\n}\n\ntype WithNullTime struct {\n\tId   int64\n\tTime gorp.NullTime\n}\n\ntype testTypeConverter struct{}\n\nfunc (me testTypeConverter) ToDb(val interface{}) (interface{}, error) {\n\n\tswitch t := val.(type) {\n\tcase Person:\n\t\tb, err := json.Marshal(t)\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn string(b), nil\n\tcase CustomStringType:\n\t\treturn string(t), nil\n\tcase CustomDate:\n\t\treturn t.Time, nil\n\t}\n\n\treturn val, nil\n}\n\nfunc (me testTypeConverter) FromDb(target interface{}) (gorp.CustomScanner, bool) {\n\tswitch target.(type) {\n\tcase *Person:\n\t\tbinder := func(holder, target interface{}) error {\n\t\t\ts, ok := holder.(*string)\n\t\t\tif !ok {\n\t\t\t\treturn errors.New(\"FromDb: Unable to convert Person to *string\")\n\t\t\t}\n\t\t\tb := []byte(*s)\n\t\t\treturn json.Unmarshal(b, target)\n\t\t}\n\t\treturn gorp.CustomScanner{new(string), target, binder}, true\n\tcase *CustomStringType:\n\t\tbinder := func(holder, target interface{}) error {\n\t\t\ts, ok := holder.(*string)\n\t\t\tif !ok {\n\t\t\t\treturn errors.New(\"FromDb: Unable to convert CustomStringType to *string\")\n\t\t\t}\n\t\t\tst, ok := target.(*CustomStringType)\n\t\t\tif !ok {\n\t\t\t\treturn errors.New(fmt.Sprint(\"FromDb: Unable to convert target to *CustomStringType: \", reflect.TypeOf(target)))\n\t\t\t}\n\t\t\t*st = CustomStringType(*s)\n\t\t\treturn nil\n\t\t}\n\t\treturn gorp.CustomScanner{new(string), target, binder}, true\n\tcase *CustomDate:\n\t\tbinder := func(holder, target interface{}) error {\n\t\t\tt, ok := holder.(*time.Time)\n\t\t\tif !ok {\n\t\t\t\treturn errors.New(\"FromDb: Unable to convert CustomDate to *time.Time\")\n\t\t\t}\n\t\t\tdateTarget, ok := target.(*CustomDate)\n\t\t\tif !ok {\n\t\t\t\treturn errors.New(fmt.Sprint(\"FromDb: Unable to convert target to *CustomDate: \", reflect.TypeOf(target)))\n\t\t\t}\n\t\t\tdateTarget.Time = *t\n\t\t\treturn nil\n\t\t}\n\t\treturn gorp.CustomScanner{new(time.Time), target, binder}, true\n\t}\n\n\treturn gorp.CustomScanner{}, false\n}\n\nfunc (p *Person) PreInsert(s gorp.SqlExecutor) error {\n\tp.Created = time.Now().UnixNano()\n\tp.Updated = p.Created\n\tif p.FName == \"badname\" {\n\t\treturn fmt.Errorf(\"Invalid name: %s\", p.FName)\n\t}\n\treturn nil\n}\n\nfunc (p *Person) PostInsert(s gorp.SqlExecutor) error {\n\tp.LName = \"postinsert\"\n\treturn nil\n}\n\nfunc (p *Person) PreUpdate(s gorp.SqlExecutor) error {\n\tp.FName = \"preupdate\"\n\treturn nil\n}\n\nfunc (p *Person) PostUpdate(s gorp.SqlExecutor) error {\n\tp.LName = \"postupdate\"\n\treturn nil\n}\n\nfunc (p *Person) PreDelete(s gorp.SqlExecutor) error {\n\tp.FName = \"predelete\"\n\treturn nil\n}\n\nfunc (p *Person) PostDelete(s gorp.SqlExecutor) error {\n\tp.LName = \"postdelete\"\n\treturn nil\n}\n\nfunc (p *Person) PostGet(s gorp.SqlExecutor) error {\n\tp.LName = \"postget\"\n\treturn nil\n}\n\ntype PersistentUser struct {\n\tKey            int32\n\tId             string\n\tPassedTraining bool\n}\n\ntype TenantDynamic struct {\n\tId       int64 `db:\"id\"`\n\tName     string\n\tAddress  string\n\tcurTable string `db:\"-\"`\n}\n\nfunc (curObj *TenantDynamic) TableName() string {\n\treturn curObj.curTable\n}\nfunc (curObj *TenantDynamic) SetTableName(tblName string) {\n\tcurObj.curTable = tblName\n}\n\nvar dynTableInst1 = TenantDynamic{curTable: \"t_1_tenant_dynamic\"}\nvar dynTableInst2 = TenantDynamic{curTable: \"t_2_tenant_dynamic\"}\n\nfunc dynamicTablesTest(t *testing.T, dbmap *gorp.DbMap) {\n\n\tdynamicTablesTestTableMap(t, dbmap, &dynTableInst1)\n\tdynamicTablesTestTableMap(t, dbmap, &dynTableInst2)\n\n\t// TEST - dbmap.Insert using dynTableInst1\n\tdynTableInst1.Name = \"Test Name 1\"\n\tdynTableInst1.Address = \"Test Address 1\"\n\terr := dbmap.Insert(&dynTableInst1)\n\tif err != nil {\n\t\tt.Errorf(\"Errow while saving dynTableInst1. Details: %v\", err)\n\t}\n\n\t// TEST - dbmap.Insert using dynTableInst2\n\tdynTableInst2.Name = \"Test Name 2\"\n\tdynTableInst2.Address = \"Test Address 2\"\n\terr = dbmap.Insert(&dynTableInst2)\n\tif err != nil {\n\t\tt.Errorf(\"Errow while saving dynTableInst2. Details: %v\", err)\n\t}\n\n\tdynamicTablesTestSelect(t, dbmap, &dynTableInst1)\n\tdynamicTablesTestSelect(t, dbmap, &dynTableInst2)\n\tdynamicTablesTestSelectOne(t, dbmap, &dynTableInst1)\n\tdynamicTablesTestSelectOne(t, dbmap, &dynTableInst2)\n\tdynamicTablesTestGetUpdateGet(t, dbmap, &dynTableInst1)\n\tdynamicTablesTestGetUpdateGet(t, dbmap, &dynTableInst2)\n\tdynamicTablesTestDelete(t, dbmap, &dynTableInst1)\n\tdynamicTablesTestDelete(t, dbmap, &dynTableInst2)\n\n}\n\nfunc dynamicTablesTestTableMap(t *testing.T,\n\tdbmap *gorp.DbMap,\n\tinpInst *TenantDynamic) {\n\n\ttableName := inpInst.TableName()\n\n\ttblMap, err := dbmap.DynamicTableFor(tableName, true)\n\tif err != nil {\n\t\tt.Errorf(\"Error while searching for tablemap for tableName: %v, Error:%v\", tableName, err)\n\t}\n\tif tblMap == nil {\n\t\tt.Errorf(\"Unable to find tablemap for tableName:%v\", tableName)\n\t}\n}\n\nfunc dynamicTablesTestSelect(t *testing.T,\n\tdbmap *gorp.DbMap,\n\tinpInst *TenantDynamic) {\n\n\t// TEST - dbmap.Select using inpInst\n\n\t// read the data back from dynInst to see if the\n\t// table mapping is correct\n\tvar dbTenantInst1 = TenantDynamic{curTable: inpInst.curTable}\n\tselectSQL1 := \"select * from \" + inpInst.curTable\n\tdbObjs, err := dbmap.Select(&dbTenantInst1, selectSQL1)\n\tif err != nil {\n\t\tt.Errorf(\"Errow in dbmap.Select. SQL: %v, Details: %v\", selectSQL1, err)\n\t}\n\tif dbObjs == nil {\n\t\tt.Fatalf(\"Nil return from dbmap.Select\")\n\t}\n\trwCnt := len(dbObjs)\n\tif rwCnt != 1 {\n\t\tt.Errorf(\"Unexpected row count for tenantInst:%v\", rwCnt)\n\t}\n\n\tdbInst := dbObjs[0].(*TenantDynamic)\n\n\tinpTableName := inpInst.TableName()\n\tresTableName := dbInst.TableName()\n\tif inpTableName != resTableName {\n\t\tt.Errorf(\"Mismatched table names %v != %v \",\n\t\t\tinpTableName, resTableName)\n\t}\n\n\tif inpInst.Id != dbInst.Id {\n\t\tt.Errorf(\"Mismatched Id values %v != %v \",\n\t\t\tinpInst.Id, dbInst.Id)\n\t}\n\n\tif inpInst.Name != dbInst.Name {\n\t\tt.Errorf(\"Mismatched Name values %v != %v \",\n\t\t\tinpInst.Name, dbInst.Name)\n\t}\n\n\tif inpInst.Address != dbInst.Address {\n\t\tt.Errorf(\"Mismatched Address values %v != %v \",\n\t\t\tinpInst.Address, dbInst.Address)\n\t}\n}\n\nfunc dynamicTablesTestGetUpdateGet(t *testing.T,\n\tdbmap *gorp.DbMap,\n\tinpInst *TenantDynamic) {\n\n\t// TEST - dbmap.Get, dbmap.Update, dbmap.Get sequence\n\n\t// read and update one of the instances to make sure\n\t// that the common gorp APIs are working well with dynamic table\n\tvar inpIface2 = TenantDynamic{curTable: inpInst.curTable}\n\tdbObj, err := dbmap.Get(&inpIface2, inpInst.Id)\n\tif err != nil {\n\t\tt.Errorf(\"Errow in dbmap.Get. id: %v, Details: %v\", inpInst.Id, err)\n\t}\n\tif dbObj == nil {\n\t\tt.Errorf(\"Nil return from dbmap.Get\")\n\t}\n\n\tdbInst := dbObj.(*TenantDynamic)\n\n\t{\n\t\tinpTableName := inpInst.TableName()\n\t\tresTableName := dbInst.TableName()\n\t\tif inpTableName != resTableName {\n\t\t\tt.Errorf(\"Mismatched table names %v != %v \",\n\t\t\t\tinpTableName, resTableName)\n\t\t}\n\n\t\tif inpInst.Id != dbInst.Id {\n\t\t\tt.Errorf(\"Mismatched Id values %v != %v \",\n\t\t\t\tinpInst.Id, dbInst.Id)\n\t\t}\n\n\t\tif inpInst.Name != dbInst.Name {\n\t\t\tt.Errorf(\"Mismatched Name values %v != %v \",\n\t\t\t\tinpInst.Name, dbInst.Name)\n\t\t}\n\n\t\tif inpInst.Address != dbInst.Address {\n\t\t\tt.Errorf(\"Mismatched Address values %v != %v \",\n\t\t\t\tinpInst.Address, dbInst.Address)\n\t\t}\n\t}\n\n\t{\n\t\tupdatedName := \"Testing Updated Name2\"\n\t\tdbInst.Name = updatedName\n\t\tcnt, err := dbmap.Update(dbInst)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"Error from dbmap.Update: %v\", err.Error())\n\t\t}\n\t\tif cnt != 1 {\n\t\t\tt.Errorf(\"Update count must be 1, got %v\", cnt)\n\t\t}\n\n\t\t// Read the object again to make sure that the\n\t\t// data was updated in db\n\t\tdbObj2, err := dbmap.Get(&inpIface2, inpInst.Id)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"Errow in dbmap.Get. id: %v, Details: %v\", inpInst.Id, err)\n\t\t}\n\t\tif dbObj2 == nil {\n\t\t\tt.Errorf(\"Nil return from dbmap.Get\")\n\t\t}\n\n\t\tdbInst2 := dbObj2.(*TenantDynamic)\n\n\t\tinpTableName := inpInst.TableName()\n\t\tresTableName := dbInst2.TableName()\n\t\tif inpTableName != resTableName {\n\t\t\tt.Errorf(\"Mismatched table names %v != %v \",\n\t\t\t\tinpTableName, resTableName)\n\t\t}\n\n\t\tif inpInst.Id != dbInst2.Id {\n\t\t\tt.Errorf(\"Mismatched Id values %v != %v \",\n\t\t\t\tinpInst.Id, dbInst2.Id)\n\t\t}\n\n\t\tif updatedName != dbInst2.Name {\n\t\t\tt.Errorf(\"Mismatched Name values %v != %v \",\n\t\t\t\tupdatedName, dbInst2.Name)\n\t\t}\n\n\t\tif inpInst.Address != dbInst.Address {\n\t\t\tt.Errorf(\"Mismatched Address values %v != %v \",\n\t\t\t\tinpInst.Address, dbInst.Address)\n\t\t}\n\n\t}\n}\n\nfunc dynamicTablesTestSelectOne(t *testing.T,\n\tdbmap *gorp.DbMap,\n\tinpInst *TenantDynamic) {\n\n\t// TEST - dbmap.SelectOne\n\n\t// read the data back from inpInst to see if the\n\t// table mapping is correct\n\tvar dbTenantInst1 = TenantDynamic{curTable: inpInst.curTable}\n\tselectSQL1 := \"select * from \" + dbTenantInst1.curTable + \" where id = :idKey\"\n\tparams := map[string]interface{}{\"idKey\": inpInst.Id}\n\terr := dbmap.SelectOne(&dbTenantInst1, selectSQL1, params)\n\tif err != nil {\n\t\tt.Errorf(\"Errow in dbmap.SelectOne. SQL: %v, Details: %v\", selectSQL1, err)\n\t}\n\n\tinpTableName := inpInst.curTable\n\tresTableName := dbTenantInst1.TableName()\n\tif inpTableName != resTableName {\n\t\tt.Errorf(\"Mismatched table names %v != %v \",\n\t\t\tinpTableName, resTableName)\n\t}\n\n\tif inpInst.Id != dbTenantInst1.Id {\n\t\tt.Errorf(\"Mismatched Id values %v != %v \",\n\t\t\tinpInst.Id, dbTenantInst1.Id)\n\t}\n\n\tif inpInst.Name != dbTenantInst1.Name {\n\t\tt.Errorf(\"Mismatched Name values %v != %v \",\n\t\t\tinpInst.Name, dbTenantInst1.Name)\n\t}\n\n\tif inpInst.Address != dbTenantInst1.Address {\n\t\tt.Errorf(\"Mismatched Address values %v != %v \",\n\t\t\tinpInst.Address, dbTenantInst1.Address)\n\t}\n}\n\nfunc dynamicTablesTestDelete(t *testing.T,\n\tdbmap *gorp.DbMap,\n\tinpInst *TenantDynamic) {\n\n\t// TEST - dbmap.Delete\n\tcnt, err := dbmap.Delete(inpInst)\n\tif err != nil {\n\t\tt.Errorf(\"Errow in dbmap.Delete. Details: %v\", err)\n\t}\n\tif cnt != 1 {\n\t\tt.Errorf(\"Expected delete count for %v : 1, found count:%v\",\n\t\t\tinpInst.TableName(), cnt)\n\t}\n\n\t// Try reading again to make sure instance is gone from db\n\tgetInst := TenantDynamic{curTable: inpInst.TableName()}\n\tdbInst, err := dbmap.Get(&getInst, inpInst.Id)\n\tif err != nil {\n\t\tt.Errorf(\"Error while trying to read deleted %v object using id: %v\",\n\t\t\tinpInst.TableName(), inpInst.Id)\n\t}\n\n\tif dbInst != nil {\n\t\tt.Errorf(\"Found deleted %v instance using id: %v\",\n\t\t\tinpInst.TableName(), inpInst.Id)\n\t}\n\n\tif getInst.Name != \"\" {\n\t\tt.Errorf(\"Found data from deleted %v instance using id: %v\",\n\t\t\tinpInst.TableName(), inpInst.Id)\n\t}\n\n}\n\nfunc TestCreateTablesIfNotExists(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\terr := dbmap.CreateTablesIfNotExists()\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n}\n\nfunc TestTruncateTables(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\terr := dbmap.CreateTablesIfNotExists()\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\t// Insert some data\n\tp1 := &Person{0, 0, 0, \"Bob\", \"Smith\", 0}\n\tdbmap.Insert(p1)\n\tinv := &Invoice{0, 0, 1, \"my invoice\", 0, true}\n\tdbmap.Insert(inv)\n\n\terr = dbmap.TruncateTables()\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\t// Make sure all rows are deleted\n\trows, _ := dbmap.Select(Person{}, \"SELECT * FROM person_test\")\n\tif len(rows) != 0 {\n\t\tt.Errorf(\"Expected 0 person rows, got %d\", len(rows))\n\t}\n\trows, _ = dbmap.Select(Invoice{}, \"SELECT * FROM invoice_test\")\n\tif len(rows) != 0 {\n\t\tt.Errorf(\"Expected 0 invoice rows, got %d\", len(rows))\n\t}\n}\n\nfunc TestCustomDateType(t *testing.T) {\n\tdbmap := newDBMap(t)\n\tdbmap.TypeConverter = testTypeConverter{}\n\tdbmap.AddTable(WithCustomDate{}).SetKeys(true, \"Id\")\n\terr := dbmap.CreateTables()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer dropAndClose(dbmap)\n\n\ttest1 := &WithCustomDate{Added: CustomDate{Time: time.Now().Truncate(time.Second)}}\n\terr = dbmap.Insert(test1)\n\tif err != nil {\n\t\tt.Errorf(\"Could not insert struct with custom date field: %s\", err)\n\t\tt.FailNow()\n\t}\n\t// Unfortunately, the mysql driver doesn't handle time.Time\n\t// values properly during Get().  I can't find a way to work\n\t// around that problem - every other type that I've tried is just\n\t// silently converted.  time.Time is the only type that causes\n\t// the issue that this test checks for.  As such, if the driver is\n\t// mysql, we'll just skip the rest of this test.\n\tif _, driver := dialectAndDriver(); driver == \"mysql\" {\n\t\tt.Skip(\"TestCustomDateType can't run Get() with the mysql driver; skipping the rest of this test...\")\n\t}\n\tresult, err := dbmap.Get(new(WithCustomDate), test1.Id)\n\tif err != nil {\n\t\tt.Errorf(\"Could not get struct with custom date field: %s\", err)\n\t\tt.FailNow()\n\t}\n\ttest2 := result.(*WithCustomDate)\n\tif test2.Added.UTC() != test1.Added.UTC() {\n\t\tt.Errorf(\"Custom dates do not match: %v != %v\", test2.Added.UTC(), test1.Added.UTC())\n\t}\n}\n\nfunc TestUIntPrimaryKey(t *testing.T) {\n\tdbmap := newDBMap(t)\n\tdbmap.AddTable(PersonUInt64{}).SetKeys(true, \"Id\")\n\tdbmap.AddTable(PersonUInt32{}).SetKeys(true, \"Id\")\n\tdbmap.AddTable(PersonUInt16{}).SetKeys(true, \"Id\")\n\terr := dbmap.CreateTablesIfNotExists()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer dropAndClose(dbmap)\n\n\tp1 := &PersonUInt64{0, \"name1\"}\n\tp2 := &PersonUInt32{0, \"name2\"}\n\tp3 := &PersonUInt16{0, \"name3\"}\n\terr = dbmap.Insert(p1, p2, p3)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tif p1.Id != 1 {\n\t\tt.Errorf(\"%d != 1\", p1.Id)\n\t}\n\tif p2.Id != 1 {\n\t\tt.Errorf(\"%d != 1\", p2.Id)\n\t}\n\tif p3.Id != 1 {\n\t\tt.Errorf(\"%d != 1\", p3.Id)\n\t}\n}\n\nfunc TestSetUniqueTogether(t *testing.T) {\n\tdbmap := newDBMap(t)\n\tdbmap.AddTable(UniqueColumns{}).SetUniqueTogether(\"FirstName\", \"LastName\").SetUniqueTogether(\"City\", \"ZipCode\")\n\terr := dbmap.CreateTablesIfNotExists()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer dropAndClose(dbmap)\n\n\tn1 := &UniqueColumns{\"Steve\", \"Jobs\", \"Cupertino\", 95014}\n\terr = dbmap.Insert(n1)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\t// Should fail because of the first constraint\n\tn2 := &UniqueColumns{\"Steve\", \"Jobs\", \"Sunnyvale\", 94085}\n\terr = dbmap.Insert(n2)\n\tif err == nil {\n\t\tt.Error(err)\n\t}\n\t// \"unique\" for Postgres/SQLite, \"Duplicate entry\" for MySQL\n\terrLower := strings.ToLower(err.Error())\n\tif !strings.Contains(errLower, \"unique\") && !strings.Contains(errLower, \"duplicate entry\") {\n\t\tt.Error(err)\n\t}\n\n\t// Should also fail because of the second unique-together\n\tn3 := &UniqueColumns{\"Steve\", \"Wozniak\", \"Cupertino\", 95014}\n\terr = dbmap.Insert(n3)\n\tif err == nil {\n\t\tt.Error(err)\n\t}\n\t// \"unique\" for Postgres/SQLite, \"Duplicate entry\" for MySQL\n\terrLower = strings.ToLower(err.Error())\n\tif !strings.Contains(errLower, \"unique\") && !strings.Contains(errLower, \"duplicate entry\") {\n\t\tt.Error(err)\n\t}\n\n\t// This one should finally succeed\n\tn4 := &UniqueColumns{\"Steve\", \"Wozniak\", \"Sunnyvale\", 94085}\n\terr = dbmap.Insert(n4)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n}\n\nfunc TestSetUniqueTogetherIdempotent(t *testing.T) {\n\tdbmap := newDBMap(t)\n\ttable := dbmap.AddTable(UniqueColumns{}).SetUniqueTogether(\"FirstName\", \"LastName\")\n\ttable.SetUniqueTogether(\"FirstName\", \"LastName\")\n\terr := dbmap.CreateTablesIfNotExists()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer dropAndClose(dbmap)\n\n\tn1 := &UniqueColumns{\"Steve\", \"Jobs\", \"Cupertino\", 95014}\n\terr = dbmap.Insert(n1)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\t// Should still fail because of the constraint\n\tn2 := &UniqueColumns{\"Steve\", \"Jobs\", \"Sunnyvale\", 94085}\n\terr = dbmap.Insert(n2)\n\tif err == nil {\n\t\tt.Error(err)\n\t}\n\n\t// Should have only created one unique constraint\n\tactualCount := strings.Count(table.SqlForCreate(false), \"unique\")\n\tif actualCount != 1 {\n\t\tt.Errorf(\"expected one unique index, found %d: %s\", actualCount, table.SqlForCreate(false))\n\t}\n}\n\nfunc TestPersistentUser(t *testing.T) {\n\tdbmap := newDBMap(t)\n\tdbmap.Exec(\"drop table if exists PersistentUser\")\n\ttable := dbmap.AddTable(PersistentUser{}).SetKeys(false, \"Key\")\n\ttable.ColMap(\"Key\").Rename(\"mykey\")\n\terr := dbmap.CreateTablesIfNotExists()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer dropAndClose(dbmap)\n\tpu := &PersistentUser{43, \"33r\", false}\n\terr = dbmap.Insert(pu)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\t// prove we can pass a pointer into Get\n\tpu2, err := dbmap.Get(pu, pu.Key)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tif !reflect.DeepEqual(pu, pu2) {\n\t\tt.Errorf(\"%v!=%v\", pu, pu2)\n\t}\n\n\tarr, err := dbmap.Select(pu, \"select * from \"+tableName(dbmap, PersistentUser{}))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tif !reflect.DeepEqual(pu, arr[0]) {\n\t\tt.Errorf(\"%v!=%v\", pu, arr[0])\n\t}\n\n\t// prove we can get the results back in a slice\n\tvar puArr []*PersistentUser\n\t_, err = dbmap.Select(&puArr, \"select * from \"+tableName(dbmap, PersistentUser{}))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tif len(puArr) != 1 {\n\t\tt.Errorf(\"Expected one persistentuser, found none\")\n\t}\n\tif !reflect.DeepEqual(pu, puArr[0]) {\n\t\tt.Errorf(\"%v!=%v\", pu, puArr[0])\n\t}\n\n\t// prove we can get the results back in a non-pointer slice\n\tvar puValues []PersistentUser\n\t_, err = dbmap.Select(&puValues, \"select * from \"+tableName(dbmap, PersistentUser{}))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tif len(puValues) != 1 {\n\t\tt.Errorf(\"Expected one persistentuser, found none\")\n\t}\n\tif !reflect.DeepEqual(*pu, puValues[0]) {\n\t\tt.Errorf(\"%v!=%v\", *pu, puValues[0])\n\t}\n\n\t// prove we can get the results back in a string slice\n\tvar idArr []*string\n\t_, err = dbmap.Select(&idArr, \"select \"+columnName(dbmap, PersistentUser{}, \"Id\")+\" from \"+tableName(dbmap, PersistentUser{}))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tif len(idArr) != 1 {\n\t\tt.Errorf(\"Expected one persistentuser, found none\")\n\t}\n\tif !reflect.DeepEqual(pu.Id, *idArr[0]) {\n\t\tt.Errorf(\"%v!=%v\", pu.Id, *idArr[0])\n\t}\n\n\t// prove we can get the results back in an int slice\n\tvar keyArr []*int32\n\t_, err = dbmap.Select(&keyArr, \"select mykey from \"+tableName(dbmap, PersistentUser{}))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tif len(keyArr) != 1 {\n\t\tt.Errorf(\"Expected one persistentuser, found none\")\n\t}\n\tif !reflect.DeepEqual(pu.Key, *keyArr[0]) {\n\t\tt.Errorf(\"%v!=%v\", pu.Key, *keyArr[0])\n\t}\n\n\t// prove we can get the results back in a bool slice\n\tvar passedArr []*bool\n\t_, err = dbmap.Select(&passedArr, \"select \"+columnName(dbmap, PersistentUser{}, \"PassedTraining\")+\" from \"+tableName(dbmap, PersistentUser{}))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tif len(passedArr) != 1 {\n\t\tt.Errorf(\"Expected one persistentuser, found none\")\n\t}\n\tif !reflect.DeepEqual(pu.PassedTraining, *passedArr[0]) {\n\t\tt.Errorf(\"%v!=%v\", pu.PassedTraining, *passedArr[0])\n\t}\n\n\t// prove we can get the results back in a non-pointer slice\n\tvar stringArr []string\n\t_, err = dbmap.Select(&stringArr, \"select \"+columnName(dbmap, PersistentUser{}, \"Id\")+\" from \"+tableName(dbmap, PersistentUser{}))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tif len(stringArr) != 1 {\n\t\tt.Errorf(\"Expected one persistentuser, found none\")\n\t}\n\tif !reflect.DeepEqual(pu.Id, stringArr[0]) {\n\t\tt.Errorf(\"%v!=%v\", pu.Id, stringArr[0])\n\t}\n}\n\nfunc TestNamedQueryMap(t *testing.T) {\n\tdbmap := newDBMap(t)\n\tdbmap.Exec(\"drop table if exists PersistentUser\")\n\ttable := dbmap.AddTable(PersistentUser{}).SetKeys(false, \"Key\")\n\ttable.ColMap(\"Key\").Rename(\"mykey\")\n\terr := dbmap.CreateTablesIfNotExists()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer dropAndClose(dbmap)\n\tpu := &PersistentUser{43, \"33r\", false}\n\tpu2 := &PersistentUser{500, \"abc\", false}\n\terr = dbmap.Insert(pu, pu2)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\t// Test simple case\n\tvar puArr []*PersistentUser\n\t_, err = dbmap.Select(&puArr, \"select * from \"+tableName(dbmap, PersistentUser{})+\" where mykey = :Key\", map[string]interface{}{\n\t\t\"Key\": 43,\n\t})\n\tif err != nil {\n\t\tt.Errorf(\"Failed to select: %s\", err)\n\t\tt.FailNow()\n\t}\n\tif len(puArr) != 1 {\n\t\tt.Errorf(\"Expected one persistentuser, found none\")\n\t}\n\tif !reflect.DeepEqual(pu, puArr[0]) {\n\t\tt.Errorf(\"%v!=%v\", pu, puArr[0])\n\t}\n\n\t// Test more specific map value type is ok\n\tpuArr = nil\n\t_, err = dbmap.Select(&puArr, \"select * from \"+tableName(dbmap, PersistentUser{})+\" where mykey = :Key\", map[string]int{\n\t\t\"Key\": 43,\n\t})\n\tif err != nil {\n\t\tt.Errorf(\"Failed to select: %s\", err)\n\t\tt.FailNow()\n\t}\n\tif len(puArr) != 1 {\n\t\tt.Errorf(\"Expected one persistentuser, found none\")\n\t}\n\n\t// Test multiple parameters set.\n\tpuArr = nil\n\t_, err = dbmap.Select(&puArr, `\nselect * from `+tableName(dbmap, PersistentUser{})+`\n where mykey = :Key\n   and `+columnName(dbmap, PersistentUser{}, \"PassedTraining\")+` = :PassedTraining\n   and `+columnName(dbmap, PersistentUser{}, \"Id\")+` = :Id`, map[string]interface{}{\n\t\t\"Key\":            43,\n\t\t\"PassedTraining\": false,\n\t\t\"Id\":             \"33r\",\n\t})\n\tif err != nil {\n\t\tt.Errorf(\"Failed to select: %s\", err)\n\t\tt.FailNow()\n\t}\n\tif len(puArr) != 1 {\n\t\tt.Errorf(\"Expected one persistentuser, found none\")\n\t}\n\n\t// Test colon within a non-key string\n\t// Test having extra, unused properties in the map.\n\tpuArr = nil\n\t_, err = dbmap.Select(&puArr, `\nselect * from `+tableName(dbmap, PersistentUser{})+`\n where mykey = :Key\n   and `+columnName(dbmap, PersistentUser{}, \"Id\")+` != 'abc:def'`, map[string]interface{}{\n\t\t\"Key\":            43,\n\t\t\"PassedTraining\": false,\n\t})\n\tif err != nil {\n\t\tt.Errorf(\"Failed to select: %s\", err)\n\t\tt.FailNow()\n\t}\n\tif len(puArr) != 1 {\n\t\tt.Errorf(\"Expected one persistentuser, found none\")\n\t}\n\n\t// Test to delete with Exec and named params.\n\tresult, err := dbmap.Exec(\"delete from \"+tableName(dbmap, PersistentUser{})+\" where mykey = :Key\", map[string]interface{}{\n\t\t\"Key\": 43,\n\t})\n\tcount, err := result.RowsAffected()\n\tif err != nil {\n\t\tt.Errorf(\"Failed to exec: %s\", err)\n\t\tt.FailNow()\n\t}\n\tif count != 1 {\n\t\tt.Errorf(\"Expected 1 persistentuser to be deleted, but %d deleted\", count)\n\t}\n}\n\nfunc TestNamedQueryStruct(t *testing.T) {\n\tdbmap := newDBMap(t)\n\tdbmap.Exec(\"drop table if exists PersistentUser\")\n\ttable := dbmap.AddTable(PersistentUser{}).SetKeys(false, \"Key\")\n\ttable.ColMap(\"Key\").Rename(\"mykey\")\n\terr := dbmap.CreateTablesIfNotExists()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer dropAndClose(dbmap)\n\tpu := &PersistentUser{43, \"33r\", false}\n\tpu2 := &PersistentUser{500, \"abc\", false}\n\terr = dbmap.Insert(pu, pu2)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\t// Test select self\n\tvar puArr []*PersistentUser\n\t_, err = dbmap.Select(&puArr, `\nselect * from `+tableName(dbmap, PersistentUser{})+`\n where mykey = :Key\n   and `+columnName(dbmap, PersistentUser{}, \"PassedTraining\")+` = :PassedTraining\n   and `+columnName(dbmap, PersistentUser{}, \"Id\")+` = :Id`, pu)\n\tif err != nil {\n\t\tt.Errorf(\"Failed to select: %s\", err)\n\t\tt.FailNow()\n\t}\n\tif len(puArr) != 1 {\n\t\tt.Errorf(\"Expected one persistentuser, found none\")\n\t}\n\tif !reflect.DeepEqual(pu, puArr[0]) {\n\t\tt.Errorf(\"%v!=%v\", pu, puArr[0])\n\t}\n\n\t// Test delete self.\n\tresult, err := dbmap.Exec(`\ndelete from `+tableName(dbmap, PersistentUser{})+`\n where mykey = :Key\n   and `+columnName(dbmap, PersistentUser{}, \"PassedTraining\")+` = :PassedTraining\n   and `+columnName(dbmap, PersistentUser{}, \"Id\")+` = :Id`, pu)\n\tcount, err := result.RowsAffected()\n\tif err != nil {\n\t\tt.Errorf(\"Failed to exec: %s\", err)\n\t\tt.FailNow()\n\t}\n\tif count != 1 {\n\t\tt.Errorf(\"Expected 1 persistentuser to be deleted, but %d deleted\", count)\n\t}\n}\n\n// Ensure that the slices containing SQL results are non-nil when the result set is empty.\nfunc TestReturnsNonNilSlice(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\tnoResultsSQL := \"select * from invoice_test where \" + columnName(dbmap, Invoice{}, \"Id\") + \"=99999\"\n\tvar r1 []*Invoice\n\trawSelect(dbmap, &r1, noResultsSQL)\n\tif r1 == nil {\n\t\tt.Errorf(\"r1==nil\")\n\t}\n\n\tr2 := rawSelect(dbmap, Invoice{}, noResultsSQL)\n\tif r2 == nil {\n\t\tt.Errorf(\"r2==nil\")\n\t}\n}\n\nfunc TestOverrideVersionCol(t *testing.T) {\n\tdbmap := newDBMap(t)\n\tt1 := dbmap.AddTable(InvoicePersonView{}).SetKeys(false, \"InvoiceId\", \"PersonId\")\n\terr := dbmap.CreateTables()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer dropAndClose(dbmap)\n\tc1 := t1.SetVersionCol(\"LegacyVersion\")\n\tif c1.ColumnName != \"LegacyVersion\" {\n\t\tt.Errorf(\"Wrong col returned: %v\", c1)\n\t}\n\n\tipv := &InvoicePersonView{1, 2, \"memo\", \"fname\", 0}\n\t_update(dbmap, ipv)\n\tif ipv.LegacyVersion != 1 {\n\t\tt.Errorf(\"LegacyVersion not updated: %d\", ipv.LegacyVersion)\n\t}\n}\n\nfunc TestOptimisticLocking(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tp1 := &Person{0, 0, 0, \"Bob\", \"Smith\", 0}\n\tdbmap.Insert(p1) // Version is now 1\n\tif p1.Version != 1 {\n\t\tt.Errorf(\"Insert didn't incr Version: %d != %d\", 1, p1.Version)\n\t\treturn\n\t}\n\tif p1.Id == 0 {\n\t\tt.Errorf(\"Insert didn't return a generated PK\")\n\t\treturn\n\t}\n\n\tobj, err := dbmap.Get(Person{}, p1.Id)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tp2 := obj.(*Person)\n\tp2.LName = \"Edwards\"\n\tdbmap.Update(p2) // Version is now 2\n\tif p2.Version != 2 {\n\t\tt.Errorf(\"Update didn't incr Version: %d != %d\", 2, p2.Version)\n\t}\n\n\tp1.LName = \"Howard\"\n\tcount, err := dbmap.Update(p1)\n\tif _, ok := err.(gorp.OptimisticLockError); !ok {\n\t\tt.Errorf(\"update - Expected gorp.OptimisticLockError, got: %v\", err)\n\t}\n\tif count != -1 {\n\t\tt.Errorf(\"update - Expected -1 count, got: %d\", count)\n\t}\n\n\tcount, err = dbmap.Delete(p1)\n\tif _, ok := err.(gorp.OptimisticLockError); !ok {\n\t\tt.Errorf(\"delete - Expected gorp.OptimisticLockError, got: %v\", err)\n\t}\n\tif count != -1 {\n\t\tt.Errorf(\"delete - Expected -1 count, got: %d\", count)\n\t}\n}\n\n// what happens if a legacy table has a null value?\nfunc TestDoubleAddTable(t *testing.T) {\n\tdbmap := newDBMap(t)\n\tt1 := dbmap.AddTable(TableWithNull{}).SetKeys(false, \"Id\")\n\tt2 := dbmap.AddTable(TableWithNull{})\n\tif t1 != t2 {\n\t\tt.Errorf(\"%v != %v\", t1, t2)\n\t}\n}\n\n// what happens if a legacy table has a null value?\nfunc TestNullValues(t *testing.T) {\n\tdbmap := initDBMapNulls(t)\n\tdefer dropAndClose(dbmap)\n\n\t// insert a row directly\n\trawExec(dbmap, \"insert into \"+tableName(dbmap, TableWithNull{})+\" values (10, null, \"+\n\t\t\"null, null, null, null)\")\n\n\t// try to load it\n\texpected := &TableWithNull{Id: 10}\n\tobj := _get(dbmap, TableWithNull{}, 10)\n\tt1 := obj.(*TableWithNull)\n\tif !reflect.DeepEqual(expected, t1) {\n\t\tt.Errorf(\"%v != %v\", expected, t1)\n\t}\n\n\t// update it\n\tt1.Str = sql.NullString{\"hi\", true}\n\texpected.Str = t1.Str\n\tt1.Int64 = sql.NullInt64{999, true}\n\texpected.Int64 = t1.Int64\n\tt1.Float64 = sql.NullFloat64{53.33, true}\n\texpected.Float64 = t1.Float64\n\tt1.Bool = sql.NullBool{true, true}\n\texpected.Bool = t1.Bool\n\tt1.Bytes = []byte{1, 30, 31, 33}\n\texpected.Bytes = t1.Bytes\n\t_update(dbmap, t1)\n\n\tobj = _get(dbmap, TableWithNull{}, 10)\n\tt1 = obj.(*TableWithNull)\n\tif t1.Str.String != \"hi\" {\n\t\tt.Errorf(\"%s != hi\", t1.Str.String)\n\t}\n\tif !reflect.DeepEqual(expected, t1) {\n\t\tt.Errorf(\"%v != %v\", expected, t1)\n\t}\n}\n\nfunc TestScannerValuer(t *testing.T) {\n\tdbmap := newDBMap(t)\n\tdbmap.AddTableWithName(PersonValuerScanner{}, \"person_test\").SetKeys(true, \"Id\")\n\tdbmap.AddTableWithName(InvoiceWithValuer{}, \"invoice_test\").SetKeys(true, \"Id\")\n\terr := dbmap.CreateTables()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer dropAndClose(dbmap)\n\n\tpv := PersonValuerScanner{}\n\tpv.FName = \"foo\"\n\tpv.LName = \"bar\"\n\terr = dbmap.Insert(&pv)\n\tif err != nil {\n\t\tt.Errorf(\"Could not insert PersonValuerScanner using Person table: %v\", err)\n\t\tt.FailNow()\n\t}\n\n\tinv := InvoiceWithValuer{}\n\tinv.Memo = \"foo\"\n\tinv.Person = pv\n\terr = dbmap.Insert(&inv)\n\tif err != nil {\n\t\tt.Errorf(\"Could not insert InvoiceWithValuer using Invoice table: %v\", err)\n\t\tt.FailNow()\n\t}\n\n\tres, err := dbmap.Get(InvoiceWithValuer{}, inv.Id)\n\tif err != nil {\n\t\tt.Errorf(\"Could not get InvoiceWithValuer: %v\", err)\n\t\tt.FailNow()\n\t}\n\tdbInv := res.(*InvoiceWithValuer)\n\n\tif dbInv.Person.Id != pv.Id {\n\t\tt.Errorf(\"InvoiceWithValuer got wrong person ID: %d (expected) != %d (actual)\", pv.Id, dbInv.Person.Id)\n\t}\n}\n\nfunc TestColumnProps(t *testing.T) {\n\tdbmap := newDBMap(t)\n\tt1 := dbmap.AddTable(Invoice{}).SetKeys(true, \"Id\")\n\tt1.ColMap(\"Created\").Rename(\"date_created\")\n\tt1.ColMap(\"Updated\").SetTransient(true)\n\tt1.ColMap(\"Memo\").SetMaxSize(10)\n\tt1.ColMap(\"PersonId\").SetUnique(true)\n\n\terr := dbmap.CreateTables()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer dropAndClose(dbmap)\n\n\t// test transient\n\tinv := &Invoice{0, 0, 1, \"my invoice\", 0, true}\n\t_insert(dbmap, inv)\n\tobj := _get(dbmap, Invoice{}, inv.Id)\n\tinv = obj.(*Invoice)\n\tif inv.Updated != 0 {\n\t\tt.Errorf(\"Saved transient column 'Updated'\")\n\t}\n\n\t// test max size\n\tinv.Memo = \"this memo is too long\"\n\terr = dbmap.Insert(inv)\n\tif err == nil {\n\t\tt.Errorf(\"max size exceeded, but Insert did not fail.\")\n\t}\n\n\t// test unique - same person id\n\tinv = &Invoice{0, 0, 1, \"my invoice2\", 0, false}\n\terr = dbmap.Insert(inv)\n\tif err == nil {\n\t\tt.Errorf(\"same PersonId inserted, but Insert did not fail.\")\n\t}\n}\n\nfunc TestRawSelect(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tp1 := &Person{0, 0, 0, \"bob\", \"smith\", 0}\n\t_insert(dbmap, p1)\n\n\tinv1 := &Invoice{0, 0, 0, \"xmas order\", p1.Id, true}\n\t_insert(dbmap, inv1)\n\n\texpected := &InvoicePersonView{inv1.Id, p1.Id, inv1.Memo, p1.FName, 0}\n\n\tquery := \"select i.\" + columnName(dbmap, Invoice{}, \"Id\") + \" InvoiceId, p.\" + columnName(dbmap, Person{}, \"Id\") + \" PersonId, i.\" + columnName(dbmap, Invoice{}, \"Memo\") + \", p.\" + columnName(dbmap, Person{}, \"FName\") + \" \" +\n\t\t\"from invoice_test i, person_test p \" +\n\t\t\"where i.\" + columnName(dbmap, Invoice{}, \"PersonId\") + \" = p.\" + columnName(dbmap, Person{}, \"Id\")\n\tlist := rawSelect(dbmap, InvoicePersonView{}, query)\n\tif len(list) != 1 {\n\t\tt.Errorf(\"len(list) != 1: %d\", len(list))\n\t} else if !reflect.DeepEqual(expected, list[0]) {\n\t\tt.Errorf(\"%v != %v\", expected, list[0])\n\t}\n}\n\nfunc TestHooks(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tp1 := &Person{0, 0, 0, \"bob\", \"smith\", 0}\n\t_insert(dbmap, p1)\n\tif p1.Created == 0 || p1.Updated == 0 {\n\t\tt.Errorf(\"p1.PreInsert() didn't run: %v\", p1)\n\t} else if p1.LName != \"postinsert\" {\n\t\tt.Errorf(\"p1.PostInsert() didn't run: %v\", p1)\n\t}\n\n\tobj := _get(dbmap, Person{}, p1.Id)\n\tp1 = obj.(*Person)\n\tif p1.LName != \"postget\" {\n\t\tt.Errorf(\"p1.PostGet() didn't run: %v\", p1)\n\t}\n\n\t_update(dbmap, p1)\n\tif p1.FName != \"preupdate\" {\n\t\tt.Errorf(\"p1.PreUpdate() didn't run: %v\", p1)\n\t} else if p1.LName != \"postupdate\" {\n\t\tt.Errorf(\"p1.PostUpdate() didn't run: %v\", p1)\n\t}\n\n\tvar persons []*Person\n\tbindVar := dbmap.Dialect.BindVar(0)\n\trawSelect(dbmap, &persons, \"select * from person_test where \"+columnName(dbmap, Person{}, \"Id\")+\" = \"+bindVar, p1.Id)\n\tif persons[0].LName != \"postget\" {\n\t\tt.Errorf(\"p1.PostGet() didn't run after select: %v\", p1)\n\t}\n\n\t_del(dbmap, p1)\n\tif p1.FName != \"predelete\" {\n\t\tt.Errorf(\"p1.PreDelete() didn't run: %v\", p1)\n\t} else if p1.LName != \"postdelete\" {\n\t\tt.Errorf(\"p1.PostDelete() didn't run: %v\", p1)\n\t}\n\n\t// Test error case\n\tp2 := &Person{0, 0, 0, \"badname\", \"\", 0}\n\terr := dbmap.Insert(p2)\n\tif err == nil {\n\t\tt.Errorf(\"p2.PreInsert() didn't return an error\")\n\t}\n}\n\nfunc TestTransaction(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tinv1 := &Invoice{0, 100, 200, \"t1\", 0, true}\n\tinv2 := &Invoice{0, 100, 200, \"t2\", 0, false}\n\n\ttrans, err := dbmap.Begin()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\ttrans.Insert(inv1, inv2)\n\terr = trans.Commit()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tobj, err := dbmap.Get(Invoice{}, inv1.Id)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tif !reflect.DeepEqual(inv1, obj) {\n\t\tt.Errorf(\"%v != %v\", inv1, obj)\n\t}\n\tobj, err = dbmap.Get(Invoice{}, inv2.Id)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tif !reflect.DeepEqual(inv2, obj) {\n\t\tt.Errorf(\"%v != %v\", inv2, obj)\n\t}\n}\n\nfunc TestTransactionExecNamed(t *testing.T) {\n\tif os.Getenv(\"GORP_TEST_DIALECT\") == \"postgres\" {\n\t\treturn\n\t}\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\ttrans, err := dbmap.Begin()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer trans.Rollback()\n\t// exec should support named params\n\targs := map[string]interface{}{\n\t\t\"created\":  100,\n\t\t\"updated\":  200,\n\t\t\"memo\":     \"unpaid\",\n\t\t\"personID\": 0,\n\t\t\"isPaid\":   false,\n\t}\n\n\tresult, err := trans.Exec(`INSERT INTO invoice_test (Created, Updated, Memo, PersonId, IsPaid) Values(:created, :updated, :memo, :personID, :isPaid)`, args)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tid, err := result.LastInsertId()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tvar checkMemo = func(want string) {\n\t\targs := map[string]interface{}{\n\t\t\t\"id\": id,\n\t\t}\n\t\tmemo, err := trans.SelectStr(\"select memo from invoice_test where id = :id\", args)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\tif memo != want {\n\t\t\tt.Errorf(\"%q != %q\", want, memo)\n\t\t}\n\t}\n\tcheckMemo(\"unpaid\")\n\n\t// exec should still work with ? params\n\tresult, err = trans.Exec(`INSERT INTO invoice_test (Created, Updated, Memo, PersonId, IsPaid) Values(?, ?, ?, ?, ?)`, 10, 15, \"paid\", 0, true)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tid, err = result.LastInsertId()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tcheckMemo(\"paid\")\n\terr = trans.Commit()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n}\n\nfunc TestTransactionExecNamedPostgres(t *testing.T) {\n\tif os.Getenv(\"GORP_TEST_DIALECT\") != \"postgres\" {\n\t\treturn\n\t}\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\ttrans, err := dbmap.Begin()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\t// exec should support named params\n\targs := map[string]interface{}{\n\t\t\"created\":  100,\n\t\t\"updated\":  200,\n\t\t\"memo\":     \"zzTest\",\n\t\t\"personID\": 0,\n\t\t\"isPaid\":   false,\n\t}\n\t_, err = trans.Exec(`INSERT INTO invoice_test (\"Created\", \"Updated\", \"Memo\", \"PersonId\", \"IsPaid\") Values(:created, :updated, :memo, :personID, :isPaid)`, args)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tvar checkMemo = func(want string) {\n\t\targs := map[string]interface{}{\n\t\t\t\"memo\": want,\n\t\t}\n\t\tmemo, err := trans.SelectStr(`select \"Memo\" from invoice_test where \"Memo\" = :memo`, args)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\tif memo != want {\n\t\t\tt.Errorf(\"%q != %q\", want, memo)\n\t\t}\n\t}\n\tcheckMemo(\"zzTest\")\n\n\t// exec should still work with ? params\n\t_, err = trans.Exec(`INSERT INTO invoice_test (\"Created\", \"Updated\", \"Memo\", \"PersonId\", \"IsPaid\") Values($1, $2, $3, $4, $5)`, 10, 15, \"yyTest\", 0, true)\n\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tcheckMemo(\"yyTest\")\n\terr = trans.Commit()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n}\n\nfunc TestSavepoint(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tinv1 := &Invoice{0, 100, 200, \"unpaid\", 0, false}\n\n\ttrans, err := dbmap.Begin()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\ttrans.Insert(inv1)\n\n\tvar checkMemo = func(want string) {\n\t\tmemo, err := trans.SelectStr(\"select \" + columnName(dbmap, Invoice{}, \"Memo\") + \" from invoice_test\")\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\tif memo != want {\n\t\t\tt.Errorf(\"%q != %q\", want, memo)\n\t\t}\n\t}\n\tcheckMemo(\"unpaid\")\n\n\terr = trans.Savepoint(\"foo\")\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tcheckMemo(\"unpaid\")\n\n\tinv1.Memo = \"paid\"\n\t_, err = trans.Update(inv1)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tcheckMemo(\"paid\")\n\n\terr = trans.RollbackToSavepoint(\"foo\")\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tcheckMemo(\"unpaid\")\n\n\terr = trans.Rollback()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n}\n\nfunc TestMultiple(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tinv1 := &Invoice{0, 100, 200, \"a\", 0, false}\n\tinv2 := &Invoice{0, 100, 200, \"b\", 0, true}\n\t_insert(dbmap, inv1, inv2)\n\n\tinv1.Memo = \"c\"\n\tinv2.Memo = \"d\"\n\t_update(dbmap, inv1, inv2)\n\n\tcount := _del(dbmap, inv1, inv2)\n\tif count != 2 {\n\t\tt.Errorf(\"%d != 2\", count)\n\t}\n}\n\nfunc TestCrud(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tinv := &Invoice{0, 100, 200, \"first order\", 0, true}\n\ttestCrudInternal(t, dbmap, inv)\n\n\tinvtag := &InvoiceTag{0, 300, 400, \"some order\", 33, false}\n\ttestCrudInternal(t, dbmap, invtag)\n\n\tfoo := &AliasTransientField{BarStr: \"some bar\"}\n\ttestCrudInternal(t, dbmap, foo)\n\n\tdynamicTablesTest(t, dbmap)\n}\n\nfunc testCrudInternal(t *testing.T, dbmap *gorp.DbMap, val testable) {\n\ttable, err := dbmap.TableFor(reflect.TypeOf(val).Elem(), false)\n\tif err != nil {\n\t\tt.Errorf(\"couldn't call TableFor: val=%v err=%v\", val, err)\n\t}\n\n\t_, err = dbmap.Exec(\"delete from \" + table.TableName)\n\tif err != nil {\n\t\tt.Errorf(\"couldn't delete rows from: val=%v err=%v\", val, err)\n\t}\n\n\t// INSERT row\n\t_insert(dbmap, val)\n\tif val.GetId() == 0 {\n\t\tt.Errorf(\"val.GetId() was not set on INSERT\")\n\t\treturn\n\t}\n\n\t// SELECT row\n\tval2 := _get(dbmap, val, val.GetId())\n\tif !reflect.DeepEqual(val, val2) {\n\t\tt.Errorf(\"%v != %v\", val, val2)\n\t}\n\n\t// UPDATE row and SELECT\n\tval.Rand()\n\tcount := _update(dbmap, val)\n\tif count != 1 {\n\t\tt.Errorf(\"update 1 != %d\", count)\n\t}\n\tval2 = _get(dbmap, val, val.GetId())\n\tif !reflect.DeepEqual(val, val2) {\n\t\tt.Errorf(\"%v != %v\", val, val2)\n\t}\n\n\t// Select *\n\trows, err := dbmap.Select(val, \"select * from \"+dbmap.Dialect.QuoteField(table.TableName))\n\tif err != nil {\n\t\tt.Errorf(\"couldn't select * from %s err=%v\", dbmap.Dialect.QuoteField(table.TableName), err)\n\t} else if len(rows) != 1 {\n\t\tt.Errorf(\"unexpected row count in %s: %d\", dbmap.Dialect.QuoteField(table.TableName), len(rows))\n\t} else if !reflect.DeepEqual(val, rows[0]) {\n\t\tt.Errorf(\"select * result: %v != %v\", val, rows[0])\n\t}\n\n\t// DELETE row\n\tdeleted := _del(dbmap, val)\n\tif deleted != 1 {\n\t\tt.Errorf(\"Did not delete row with Id: %d\", val.GetId())\n\t\treturn\n\t}\n\n\t// VERIFY deleted\n\tval2 = _get(dbmap, val, val.GetId())\n\tif val2 != nil {\n\t\tt.Errorf(\"Found invoice with id: %d after Delete()\", val.GetId())\n\t}\n}\n\nfunc TestWithIgnoredColumn(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tic := &WithIgnoredColumn{-1, 0, 1}\n\t_insert(dbmap, ic)\n\texpected := &WithIgnoredColumn{0, 1, 1}\n\tic2 := _get(dbmap, WithIgnoredColumn{}, ic.Id).(*WithIgnoredColumn)\n\n\tif !reflect.DeepEqual(expected, ic2) {\n\t\tt.Errorf(\"%v != %v\", expected, ic2)\n\t}\n\tif _del(dbmap, ic) != 1 {\n\t\tt.Errorf(\"Did not delete row with Id: %d\", ic.Id)\n\t\treturn\n\t}\n\tif _get(dbmap, WithIgnoredColumn{}, ic.Id) != nil {\n\t\tt.Errorf(\"Found id: %d after Delete()\", ic.Id)\n\t}\n}\n\nfunc TestColumnFilter(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tinv1 := &Invoice{0, 100, 200, \"a\", 0, false}\n\t_insert(dbmap, inv1)\n\n\tinv1.Memo = \"c\"\n\tinv1.IsPaid = true\n\t_updateColumns(dbmap, func(col *gorp.ColumnMap) bool {\n\t\treturn col.ColumnName == \"Memo\"\n\t}, inv1)\n\n\tinv2 := &Invoice{}\n\tinv2 = _get(dbmap, inv2, inv1.Id).(*Invoice)\n\tif inv2.Memo != \"c\" {\n\t\tt.Errorf(\"Expected column to be updated (%#v)\", inv2)\n\t}\n\tif inv2.IsPaid {\n\t\tt.Error(\"IsPaid shouldn't have been updated\")\n\t}\n}\n\nfunc TestTypeConversionExample(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tp := Person{FName: \"Bob\", LName: \"Smith\"}\n\ttc := &TypeConversionExample{-1, p, CustomStringType(\"hi\")}\n\t_insert(dbmap, tc)\n\n\texpected := &TypeConversionExample{1, p, CustomStringType(\"hi\")}\n\ttc2 := _get(dbmap, TypeConversionExample{}, tc.Id).(*TypeConversionExample)\n\tif !reflect.DeepEqual(expected, tc2) {\n\t\tt.Errorf(\"tc2 %v != %v\", expected, tc2)\n\t}\n\n\ttc2.Name = CustomStringType(\"hi2\")\n\ttc2.PersonJSON = Person{FName: \"Jane\", LName: \"Doe\"}\n\t_update(dbmap, tc2)\n\n\texpected = &TypeConversionExample{1, tc2.PersonJSON, CustomStringType(\"hi2\")}\n\ttc3 := _get(dbmap, TypeConversionExample{}, tc.Id).(*TypeConversionExample)\n\tif !reflect.DeepEqual(expected, tc3) {\n\t\tt.Errorf(\"tc3 %v != %v\", expected, tc3)\n\t}\n\n\tif _del(dbmap, tc) != 1 {\n\t\tt.Errorf(\"Did not delete row with Id: %d\", tc.Id)\n\t}\n\n}\n\nfunc TestWithEmbeddedStruct(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tes := &WithEmbeddedStruct{-1, Names{FirstName: \"Alice\", LastName: \"Smith\"}}\n\t_insert(dbmap, es)\n\texpected := &WithEmbeddedStruct{1, Names{FirstName: \"Alice\", LastName: \"Smith\"}}\n\tes2 := _get(dbmap, WithEmbeddedStruct{}, es.Id).(*WithEmbeddedStruct)\n\tif !reflect.DeepEqual(expected, es2) {\n\t\tt.Errorf(\"%v != %v\", expected, es2)\n\t}\n\n\tes2.FirstName = \"Bob\"\n\texpected.FirstName = \"Bob\"\n\t_update(dbmap, es2)\n\tes2 = _get(dbmap, WithEmbeddedStruct{}, es.Id).(*WithEmbeddedStruct)\n\tif !reflect.DeepEqual(expected, es2) {\n\t\tt.Errorf(\"%v != %v\", expected, es2)\n\t}\n\n\tess := rawSelect(dbmap, WithEmbeddedStruct{}, \"select * from embedded_struct_test\")\n\tif !reflect.DeepEqual(es2, ess[0]) {\n\t\tt.Errorf(\"%v != %v\", es2, ess[0])\n\t}\n}\n\n/*\nfunc TestWithEmbeddedStructConflictingEmbeddedMemberNames(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tes := &WithEmbeddedStructConflictingEmbeddedMemberNames{-1, Names{FirstName: \"Alice\", LastName: \"Smith\"}, NamesConflict{FirstName: \"Andrew\", Surname: \"Wiggin\"}}\n\t_insert(dbmap, es)\n\texpected := &WithEmbeddedStructConflictingEmbeddedMemberNames{-1, Names{FirstName: \"Alice\", LastName: \"Smith\"}, NamesConflict{FirstName: \"Andrew\", Surname: \"Wiggin\"}}\n\tes2 := _get(dbmap, WithEmbeddedStructConflictingEmbeddedMemberNames{}, es.Id).(*WithEmbeddedStructConflictingEmbeddedMemberNames)\n\tif !reflect.DeepEqual(expected, es2) {\n\t\tt.Errorf(\"%v != %v\", expected, es2)\n\t}\n\n\tes2.Names.FirstName = \"Bob\"\n\texpected.Names.FirstName = \"Bob\"\n\t_update(dbmap, es2)\n\tes2 = _get(dbmap, WithEmbeddedStructConflictingEmbeddedMemberNames{}, es.Id).(*WithEmbeddedStructConflictingEmbeddedMemberNames)\n\tif !reflect.DeepEqual(expected, es2) {\n\t\tt.Errorf(\"%v != %v\", expected, es2)\n\t}\n\n\tess := rawSelect(dbmap, WithEmbeddedStructConflictingEmbeddedMemberNames{}, \"select * from embedded_struct_conflict_name_test\")\n\tif !reflect.DeepEqual(es2, ess[0]) {\n\t\tt.Errorf(\"%v != %v\", es2, ess[0])\n\t}\n}\n\nfunc TestWithEmbeddedStructSameMemberName(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tes := &WithEmbeddedStructSameMemberName{-1, SameName{SameName: \"Alice\"}}\n\t_insert(dbmap, es)\n\texpected := &WithEmbeddedStructSameMemberName{-1, SameName{SameName: \"Alice\"}}\n\tes2 := _get(dbmap, WithEmbeddedStructSameMemberName{}, es.Id).(*WithEmbeddedStructSameMemberName)\n\tif !reflect.DeepEqual(expected, es2) {\n\t\tt.Errorf(\"%v != %v\", expected, es2)\n\t}\n\n\tes2.SameName = SameName{\"Bob\"}\n\texpected.SameName = SameName{\"Bob\"}\n\t_update(dbmap, es2)\n\tes2 = _get(dbmap, WithEmbeddedStructSameMemberName{}, es.Id).(*WithEmbeddedStructSameMemberName)\n\tif !reflect.DeepEqual(expected, es2) {\n\t\tt.Errorf(\"%v != %v\", expected, es2)\n\t}\n\n\tess := rawSelect(dbmap, WithEmbeddedStructSameMemberName{}, \"select * from embedded_struct_same_member_name_test\")\n\tif !reflect.DeepEqual(es2, ess[0]) {\n\t\tt.Errorf(\"%v != %v\", es2, ess[0])\n\t}\n}\n//*/\n\nfunc TestWithEmbeddedStructBeforeAutoincr(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tesba := &WithEmbeddedStructBeforeAutoincrField{Names: Names{FirstName: \"Alice\", LastName: \"Smith\"}}\n\t_insert(dbmap, esba)\n\tvar expectedAutoincrId int64 = 1\n\tif esba.Id != expectedAutoincrId {\n\t\tt.Errorf(\"%d != %d\", expectedAutoincrId, esba.Id)\n\t}\n}\n\nfunc TestWithEmbeddedAutoincr(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tesa := &WithEmbeddedAutoincr{\n\t\tWithEmbeddedStruct: WithEmbeddedStruct{Names: Names{FirstName: \"Alice\", LastName: \"Smith\"}},\n\t\tMiddleName:         \"Rose\",\n\t}\n\t_insert(dbmap, esa)\n\tvar expectedAutoincrId int64 = 1\n\tif esa.Id != expectedAutoincrId {\n\t\tt.Errorf(\"%d != %d\", expectedAutoincrId, esa.Id)\n\t}\n}\n\nfunc TestSelectVal(t *testing.T) {\n\tdbmap := initDBMapNulls(t)\n\tdefer dropAndClose(dbmap)\n\n\tbindVar := dbmap.Dialect.BindVar(0)\n\n\tt1 := TableWithNull{Str: sql.NullString{\"abc\", true},\n\t\tInt64:   sql.NullInt64{78, true},\n\t\tFloat64: sql.NullFloat64{32.2, true},\n\t\tBool:    sql.NullBool{true, true},\n\t\tBytes:   []byte(\"hi\")}\n\t_insert(dbmap, &t1)\n\n\t// SelectInt\n\ti64 := selectInt(dbmap, \"select \"+columnName(dbmap, TableWithNull{}, \"Int64\")+\" from \"+tableName(dbmap, TableWithNull{})+\" where \"+columnName(dbmap, TableWithNull{}, \"Str\")+\"='abc'\")\n\tif i64 != 78 {\n\t\tt.Errorf(\"int64 %d != 78\", i64)\n\t}\n\ti64 = selectInt(dbmap, \"select count(*) from \"+tableName(dbmap, TableWithNull{}))\n\tif i64 != 1 {\n\t\tt.Errorf(\"int64 count %d != 1\", i64)\n\t}\n\ti64 = selectInt(dbmap, \"select count(*) from \"+tableName(dbmap, TableWithNull{})+\" where \"+columnName(dbmap, TableWithNull{}, \"Str\")+\"=\"+bindVar, \"asdfasdf\")\n\tif i64 != 0 {\n\t\tt.Errorf(\"int64 no rows %d != 0\", i64)\n\t}\n\n\t// SelectNullInt\n\tn := selectNullInt(dbmap, \"select \"+columnName(dbmap, TableWithNull{}, \"Int64\")+\" from \"+tableName(dbmap, TableWithNull{})+\" where \"+columnName(dbmap, TableWithNull{}, \"Str\")+\"='notfound'\")\n\tif !reflect.DeepEqual(n, sql.NullInt64{0, false}) {\n\t\tt.Errorf(\"nullint %v != 0,false\", n)\n\t}\n\n\tn = selectNullInt(dbmap, \"select \"+columnName(dbmap, TableWithNull{}, \"Int64\")+\" from \"+tableName(dbmap, TableWithNull{})+\" where \"+columnName(dbmap, TableWithNull{}, \"Str\")+\"='abc'\")\n\tif !reflect.DeepEqual(n, sql.NullInt64{78, true}) {\n\t\tt.Errorf(\"nullint %v != 78, true\", n)\n\t}\n\n\t// SelectFloat\n\tf64 := selectFloat(dbmap, \"select \"+columnName(dbmap, TableWithNull{}, \"Float64\")+\" from \"+tableName(dbmap, TableWithNull{})+\" where \"+columnName(dbmap, TableWithNull{}, \"Str\")+\"='abc'\")\n\tif f64 != 32.2 {\n\t\tt.Errorf(\"float64 %f != 32.2\", f64)\n\t}\n\tf64 = selectFloat(dbmap, \"select min(\"+columnName(dbmap, TableWithNull{}, \"Float64\")+\") from \"+tableName(dbmap, TableWithNull{}))\n\tif f64 != 32.2 {\n\t\tt.Errorf(\"float64 min %f != 32.2\", f64)\n\t}\n\tf64 = selectFloat(dbmap, \"select count(*) from \"+tableName(dbmap, TableWithNull{})+\" where \"+columnName(dbmap, TableWithNull{}, \"Str\")+\"=\"+bindVar, \"asdfasdf\")\n\tif f64 != 0 {\n\t\tt.Errorf(\"float64 no rows %f != 0\", f64)\n\t}\n\n\t// SelectNullFloat\n\tnf := selectNullFloat(dbmap, \"select \"+columnName(dbmap, TableWithNull{}, \"Float64\")+\" from \"+tableName(dbmap, TableWithNull{})+\" where \"+columnName(dbmap, TableWithNull{}, \"Str\")+\"='notfound'\")\n\tif !reflect.DeepEqual(nf, sql.NullFloat64{0, false}) {\n\t\tt.Errorf(\"nullfloat %v != 0,false\", nf)\n\t}\n\n\tnf = selectNullFloat(dbmap, \"select \"+columnName(dbmap, TableWithNull{}, \"Float64\")+\" from \"+tableName(dbmap, TableWithNull{})+\" where \"+columnName(dbmap, TableWithNull{}, \"Str\")+\"='abc'\")\n\tif !reflect.DeepEqual(nf, sql.NullFloat64{32.2, true}) {\n\t\tt.Errorf(\"nullfloat %v != 32.2, true\", nf)\n\t}\n\n\t// SelectStr\n\ts := selectStr(dbmap, \"select \"+columnName(dbmap, TableWithNull{}, \"Str\")+\" from \"+tableName(dbmap, TableWithNull{})+\" where \"+columnName(dbmap, TableWithNull{}, \"Int64\")+\"=\"+bindVar, 78)\n\tif s != \"abc\" {\n\t\tt.Errorf(\"s %s != abc\", s)\n\t}\n\ts = selectStr(dbmap, \"select \"+columnName(dbmap, TableWithNull{}, \"Str\")+\" from \"+tableName(dbmap, TableWithNull{})+\" where \"+columnName(dbmap, TableWithNull{}, \"Str\")+\"='asdfasdf'\")\n\tif s != \"\" {\n\t\tt.Errorf(\"s no rows %s != ''\", s)\n\t}\n\n\t// SelectNullStr\n\tns := selectNullStr(dbmap, \"select \"+columnName(dbmap, TableWithNull{}, \"Str\")+\" from \"+tableName(dbmap, TableWithNull{})+\" where \"+columnName(dbmap, TableWithNull{}, \"Int64\")+\"=\"+bindVar, 78)\n\tif !reflect.DeepEqual(ns, sql.NullString{\"abc\", true}) {\n\t\tt.Errorf(\"nullstr %v != abc,true\", ns)\n\t}\n\tns = selectNullStr(dbmap, \"select \"+columnName(dbmap, TableWithNull{}, \"Str\")+\" from \"+tableName(dbmap, TableWithNull{})+\" where \"+columnName(dbmap, TableWithNull{}, \"Str\")+\"='asdfasdf'\")\n\tif !reflect.DeepEqual(ns, sql.NullString{\"\", false}) {\n\t\tt.Errorf(\"nullstr no rows %v != '',false\", ns)\n\t}\n\n\t// SelectInt/Str with named parameters\n\ti64 = selectInt(dbmap, \"select \"+columnName(dbmap, TableWithNull{}, \"Int64\")+\" from \"+tableName(dbmap, TableWithNull{})+\" where \"+columnName(dbmap, TableWithNull{}, \"Str\")+\"=:abc\", map[string]string{\"abc\": \"abc\"})\n\tif i64 != 78 {\n\t\tt.Errorf(\"int64 %d != 78\", i64)\n\t}\n\tns = selectNullStr(dbmap, \"select \"+columnName(dbmap, TableWithNull{}, \"Str\")+\" from \"+tableName(dbmap, TableWithNull{})+\" where \"+columnName(dbmap, TableWithNull{}, \"Int64\")+\"=:num\", map[string]int{\"num\": 78})\n\tif !reflect.DeepEqual(ns, sql.NullString{\"abc\", true}) {\n\t\tt.Errorf(\"nullstr %v != abc,true\", ns)\n\t}\n}\n\nfunc TestVersionMultipleRows(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tpersons := []*Person{\n\t\t&Person{0, 0, 0, \"Bob\", \"Smith\", 0},\n\t\t&Person{0, 0, 0, \"Jane\", \"Smith\", 0},\n\t\t&Person{0, 0, 0, \"Mike\", \"Smith\", 0},\n\t}\n\n\t_insert(dbmap, persons[0], persons[1], persons[2])\n\n\tfor x, p := range persons {\n\t\tif p.Version != 1 {\n\t\t\tt.Errorf(\"person[%d].Version != 1: %d\", x, p.Version)\n\t\t}\n\t}\n}\n\nfunc TestWithStringPk(t *testing.T) {\n\tdbmap := newDBMap(t)\n\tdbmap.AddTableWithName(WithStringPk{}, \"string_pk_test\").SetKeys(true, \"Id\")\n\t_, err := dbmap.Exec(\"create table string_pk_test (Id varchar(255), Name varchar(255));\")\n\tif err != nil {\n\t\tt.Errorf(\"couldn't create string_pk_test: %v\", err)\n\t}\n\tdefer dropAndClose(dbmap)\n\n\trow := &WithStringPk{\"1\", \"foo\"}\n\terr = dbmap.Insert(row)\n\tif err == nil {\n\t\tt.Errorf(\"Expected error when inserting into table w/non Int PK and autoincr set true\")\n\t}\n}\n\n// TestSqlExecutorInterfaceSelects ensures that all gorp.DbMap methods starting with Select...\n// are also exposed in the gorp.SqlExecutor interface. Select...  functions can always\n// run on Pre/Post hooks.\nfunc TestSqlExecutorInterfaceSelects(t *testing.T) {\n\tdbMapType := reflect.TypeOf(&gorp.DbMap{})\n\tsqlExecutorType := reflect.TypeOf((*gorp.SqlExecutor)(nil)).Elem()\n\tnumDbMapMethods := dbMapType.NumMethod()\n\tfor i := 0; i < numDbMapMethods; i += 1 {\n\t\tdbMapMethod := dbMapType.Method(i)\n\t\tif !strings.HasPrefix(dbMapMethod.Name, \"Select\") {\n\t\t\tcontinue\n\t\t}\n\t\tif _, found := sqlExecutorType.MethodByName(dbMapMethod.Name); !found {\n\t\t\tt.Errorf(\"Method %s is defined on gorp.DbMap but not implemented in gorp.SqlExecutor\",\n\t\t\t\tdbMapMethod.Name)\n\t\t}\n\t}\n}\n\nfunc TestNullTime(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\t// if time is null\n\tent := &WithNullTime{\n\t\tId: 0,\n\t\tTime: gorp.NullTime{\n\t\t\tValid: false,\n\t\t}}\n\terr := dbmap.Insert(ent)\n\tif err != nil {\n\t\tt.Errorf(\"failed insert on %s\", err.Error())\n\t}\n\terr = dbmap.SelectOne(ent, `select * from nulltime_test where `+columnName(dbmap, WithNullTime{}, \"Id\")+`=:Id`, map[string]interface{}{\n\t\t\"Id\": ent.Id,\n\t})\n\tif err != nil {\n\t\tt.Errorf(\"failed select on %s\", err.Error())\n\t}\n\tif ent.Time.Valid {\n\t\tt.Error(\"gorp.NullTime returns valid but expected null.\")\n\t}\n\n\t// if time is not null\n\tts, err := time.Parse(time.RFC3339, \"2001-01-02T15:04:05-07:00\")\n\tif err != nil {\n\t\tt.Errorf(\"failed to parse time %s: %s\", time.Stamp, err.Error())\n\t}\n\tent = &WithNullTime{\n\t\tId: 1,\n\t\tTime: gorp.NullTime{\n\t\t\tValid: true,\n\t\t\tTime:  ts,\n\t\t}}\n\terr = dbmap.Insert(ent)\n\tif err != nil {\n\t\tt.Errorf(\"failed insert on %s\", err.Error())\n\t}\n\terr = dbmap.SelectOne(ent, `select * from nulltime_test where `+columnName(dbmap, WithNullTime{}, \"Id\")+`=:Id`, map[string]interface{}{\n\t\t\"Id\": ent.Id,\n\t})\n\tif err != nil {\n\t\tt.Errorf(\"failed select on %s\", err.Error())\n\t}\n\tif !ent.Time.Valid {\n\t\tt.Error(\"gorp.NullTime returns invalid but expected valid.\")\n\t}\n\tif ent.Time.Time.UTC() != ts.UTC() {\n\t\tt.Errorf(\"expect %v but got %v.\", ts, ent.Time.Time)\n\t}\n\n\treturn\n}\n\ntype WithTime struct {\n\tId   int64\n\tTime time.Time\n}\n\ntype Times struct {\n\tOne time.Time\n\tTwo time.Time\n}\n\ntype EmbeddedTime struct {\n\tId string\n\tTimes\n}\n\nfunc parseTimeOrPanic(format, date string) time.Time {\n\tt1, err := time.Parse(format, date)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn t1\n}\n\nfunc TestWithTime(t *testing.T) {\n\tif _, driver := dialectAndDriver(); driver == \"mysql\" {\n\t\tt.Skip(\"mysql drivers don't support time.Time, skipping...\")\n\t}\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tt1 := parseTimeOrPanic(\"2006-01-02 15:04:05 -0700 MST\",\n\t\t\"2013-08-09 21:30:43 +0800 CST\")\n\tw1 := WithTime{1, t1}\n\t_insert(dbmap, &w1)\n\n\tobj := _get(dbmap, WithTime{}, w1.Id)\n\tw2 := obj.(*WithTime)\n\tif w1.Time.UnixNano() != w2.Time.UnixNano() {\n\t\tt.Errorf(\"%v != %v\", w1, w2)\n\t}\n}\n\nfunc TestEmbeddedTime(t *testing.T) {\n\tif _, driver := dialectAndDriver(); driver == \"mysql\" {\n\t\tt.Skip(\"mysql drivers don't support time.Time, skipping...\")\n\t}\n\tdbmap := newDBMap(t)\n\tdbmap.AddTable(EmbeddedTime{}).SetKeys(false, \"Id\")\n\tdefer dropAndClose(dbmap)\n\terr := dbmap.CreateTables()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\ttime1 := parseTimeOrPanic(\"2006-01-02 15:04:05\", \"2013-08-09 21:30:43\")\n\n\tt1 := &EmbeddedTime{Id: \"abc\", Times: Times{One: time1, Two: time1.Add(10 * time.Second)}}\n\t_insert(dbmap, t1)\n\n\tx := _get(dbmap, EmbeddedTime{}, t1.Id)\n\tt2, _ := x.(*EmbeddedTime)\n\tif t1.One.UnixNano() != t2.One.UnixNano() || t1.Two.UnixNano() != t2.Two.UnixNano() {\n\t\tt.Errorf(\"%v != %v\", t1, t2)\n\t}\n}\n\nfunc TestWithTimeSelect(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\thalfhourago := time.Now().UTC().Add(-30 * time.Minute)\n\n\tw1 := WithTime{1, halfhourago.Add(time.Minute * -1)}\n\tw2 := WithTime{2, halfhourago.Add(time.Second)}\n\t_insert(dbmap, &w1, &w2)\n\n\tvar caseIds []int64\n\t_, err := dbmap.Select(&caseIds, \"SELECT \"+columnName(dbmap, WithTime{}, \"Id\")+\" FROM time_test WHERE \"+columnName(dbmap, WithTime{}, \"Time\")+\" < \"+dbmap.Dialect.BindVar(0), halfhourago)\n\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tif len(caseIds) != 1 {\n\t\tt.Errorf(\"%d != 1\", len(caseIds))\n\t}\n\tif caseIds[0] != w1.Id {\n\t\tt.Errorf(\"%d != %d\", caseIds[0], w1.Id)\n\t}\n}\n\nfunc TestInvoicePersonView(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\t// Create some rows\n\tp1 := &Person{0, 0, 0, \"bob\", \"smith\", 0}\n\tdbmap.Insert(p1)\n\n\t// notice how we can wire up p1.Id to the invoice easily\n\tinv1 := &Invoice{0, 0, 0, \"xmas order\", p1.Id, false}\n\tdbmap.Insert(inv1)\n\n\t// Run your query\n\tquery := \"select i.\" + columnName(dbmap, Invoice{}, \"Id\") + \" InvoiceId, p.\" + columnName(dbmap, Person{}, \"Id\") + \" PersonId, i.\" + columnName(dbmap, Invoice{}, \"Memo\") + \", p.\" + columnName(dbmap, Person{}, \"FName\") + \" \" +\n\t\t\"from invoice_test i, person_test p \" +\n\t\t\"where i.\" + columnName(dbmap, Invoice{}, \"PersonId\") + \" = p.\" + columnName(dbmap, Person{}, \"Id\")\n\n\t// pass a slice of pointers to Select()\n\t// this avoids the need to type assert after the query is run\n\tvar list []*InvoicePersonView\n\t_, err := dbmap.Select(&list, query)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\t// this should test true\n\texpected := &InvoicePersonView{inv1.Id, p1.Id, inv1.Memo, p1.FName, 0}\n\tif !reflect.DeepEqual(list[0], expected) {\n\t\tt.Errorf(\"%v != %v\", list[0], expected)\n\t}\n}\n\nfunc TestQuoteTableNames(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tquotedTableName := dbmap.Dialect.QuoteField(\"person_test\")\n\n\t// Use a buffer to hold the log to check generated queries\n\tlogBuffer := &bytes.Buffer{}\n\tdbmap.TraceOn(\"\", log.New(logBuffer, \"gorptest:\", log.Lmicroseconds))\n\n\t// Create some rows\n\tp1 := &Person{0, 0, 0, \"bob\", \"smith\", 0}\n\terrorTemplate := \"Expected quoted table name %v in query but didn't find it\"\n\n\t// Check if Insert quotes the table name\n\tid := dbmap.Insert(p1)\n\tif !bytes.Contains(logBuffer.Bytes(), []byte(quotedTableName)) {\n\t\tt.Errorf(errorTemplate, quotedTableName)\n\t}\n\tlogBuffer.Reset()\n\n\t// Check if Get quotes the table name\n\tdbmap.Get(Person{}, id)\n\tif !bytes.Contains(logBuffer.Bytes(), []byte(quotedTableName)) {\n\t\tt.Errorf(errorTemplate, quotedTableName)\n\t}\n\tlogBuffer.Reset()\n}\n\nfunc TestSelectTooManyCols(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tp1 := &Person{0, 0, 0, \"bob\", \"smith\", 0}\n\tp2 := &Person{0, 0, 0, \"jane\", \"doe\", 0}\n\t_insert(dbmap, p1)\n\t_insert(dbmap, p2)\n\n\tobj := _get(dbmap, Person{}, p1.Id)\n\tp1 = obj.(*Person)\n\tobj = _get(dbmap, Person{}, p2.Id)\n\tp2 = obj.(*Person)\n\n\tparams := map[string]interface{}{\n\t\t\"Id\": p1.Id,\n\t}\n\n\tvar p3 FNameOnly\n\terr := dbmap.SelectOne(&p3, \"select * from person_test where \"+columnName(dbmap, Person{}, \"Id\")+\"=:Id\", params)\n\tif err != nil {\n\t\tif !gorp.NonFatalError(err) {\n\t\t\tt.Error(err)\n\t\t}\n\t} else {\n\t\tt.Errorf(\"Non-fatal error expected\")\n\t}\n\n\tif p1.FName != p3.FName {\n\t\tt.Errorf(\"%v != %v\", p1.FName, p3.FName)\n\t}\n\n\tvar pSlice []FNameOnly\n\t_, err = dbmap.Select(&pSlice, \"select * from person_test order by \"+columnName(dbmap, Person{}, \"FName\")+\" asc\")\n\tif err != nil {\n\t\tif !gorp.NonFatalError(err) {\n\t\t\tt.Error(err)\n\t\t}\n\t} else {\n\t\tt.Errorf(\"Non-fatal error expected\")\n\t}\n\n\tif p1.FName != pSlice[0].FName {\n\t\tt.Errorf(\"%v != %v\", p1.FName, pSlice[0].FName)\n\t}\n\tif p2.FName != pSlice[1].FName {\n\t\tt.Errorf(\"%v != %v\", p2.FName, pSlice[1].FName)\n\t}\n}\n\nfunc TestSelectSingleVal(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tp1 := &Person{0, 0, 0, \"bob\", \"smith\", 0}\n\t_insert(dbmap, p1)\n\n\tobj := _get(dbmap, Person{}, p1.Id)\n\tp1 = obj.(*Person)\n\n\tparams := map[string]interface{}{\n\t\t\"Id\": p1.Id,\n\t}\n\n\tvar p2 Person\n\terr := dbmap.SelectOne(&p2, \"select * from person_test where \"+columnName(dbmap, Person{}, \"Id\")+\"=:Id\", params)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\tif !reflect.DeepEqual(p1, &p2) {\n\t\tt.Errorf(\"%v != %v\", p1, &p2)\n\t}\n\n\t// verify SelectOne allows non-struct holders\n\tvar s string\n\terr = dbmap.SelectOne(&s, \"select \"+columnName(dbmap, Person{}, \"FName\")+\" from person_test where \"+columnName(dbmap, Person{}, \"Id\")+\"=:Id\", params)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tif s != \"bob\" {\n\t\tt.Error(\"Expected bob but got: \" + s)\n\t}\n\n\t// verify SelectOne requires pointer receiver\n\terr = dbmap.SelectOne(s, \"select \"+columnName(dbmap, Person{}, \"FName\")+\" from person_test where \"+columnName(dbmap, Person{}, \"Id\")+\"=:Id\", params)\n\tif err == nil {\n\t\tt.Error(\"SelectOne should have returned error for non-pointer holder\")\n\t}\n\n\t// verify SelectOne works with uninitialized pointers\n\tvar p3 *Person\n\terr = dbmap.SelectOne(&p3, \"select * from person_test where \"+columnName(dbmap, Person{}, \"Id\")+\"=:Id\", params)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\tif !reflect.DeepEqual(p1, p3) {\n\t\tt.Errorf(\"%v != %v\", p1, p3)\n\t}\n\n\t// verify that the receiver is still nil if nothing was found\n\tvar p4 *Person\n\tdbmap.SelectOne(&p3, \"select * from person_test where 2<1 AND \"+columnName(dbmap, Person{}, \"Id\")+\"=:Id\", params)\n\tif p4 != nil {\n\t\tt.Error(\"SelectOne should not have changed a nil receiver when no rows were found\")\n\t}\n\n\t// verify that the error is set to sql.ErrNoRows if not found\n\terr = dbmap.SelectOne(&p2, \"select * from person_test where \"+columnName(dbmap, Person{}, \"Id\")+\"=:Id\", map[string]interface{}{\n\t\t\"Id\": -2222,\n\t})\n\tif err == nil || err != sql.ErrNoRows {\n\t\tt.Error(\"SelectOne should have returned an sql.ErrNoRows\")\n\t}\n\n\t_insert(dbmap, &Person{0, 0, 0, \"bob\", \"smith\", 0})\n\terr = dbmap.SelectOne(&p2, \"select * from person_test where \"+columnName(dbmap, Person{}, \"FName\")+\"='bob'\")\n\tif err == nil {\n\t\tt.Error(\"Expected error when two rows found\")\n\t}\n\n\t// tests for #150\n\tvar tInt int64\n\tvar tStr string\n\tvar tBool bool\n\tvar tFloat float64\n\tprimVals := []interface{}{tInt, tStr, tBool, tFloat}\n\tfor _, prim := range primVals {\n\t\terr = dbmap.SelectOne(&prim, \"select * from person_test where \"+columnName(dbmap, Person{}, \"Id\")+\"=-123\")\n\t\tif err == nil || err != sql.ErrNoRows {\n\t\t\tt.Error(\"primVals: SelectOne should have returned sql.ErrNoRows\")\n\t\t}\n\t}\n}\n\nfunc TestSelectAlias(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tp1 := &IdCreatedExternal{IdCreated: IdCreated{Id: 1, Created: 3}, External: 2}\n\n\t// Insert using embedded IdCreated, which reflects the structure of the table\n\t_insert(dbmap, &p1.IdCreated)\n\n\t// Select into IdCreatedExternal type, which includes some fields not present\n\t// in id_created_test\n\tvar p2 IdCreatedExternal\n\terr := dbmap.SelectOne(&p2, \"select * from id_created_test where \"+columnName(dbmap, IdCreatedExternal{}, \"Id\")+\"=1\")\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tif p2.Id != 1 || p2.Created != 3 || p2.External != 0 {\n\t\tt.Error(\"Expected ignored field defaults to not set\")\n\t}\n\n\t// Prove that we can supply an aliased value in the select, and that it will\n\t// automatically map to IdCreatedExternal.External\n\terr = dbmap.SelectOne(&p2, \"SELECT *, 1 AS external FROM id_created_test\")\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tif p2.External != 1 {\n\t\tt.Error(\"Expected select as can map to exported field.\")\n\t}\n\n\tvar rows *sql.Rows\n\tvar cols []string\n\trows, err = dbmap.Db.Query(\"SELECT * FROM id_created_test\")\n\tcols, err = rows.Columns()\n\tif err != nil || len(cols) != 2 {\n\t\tt.Error(\"Expected ignored column not created\")\n\t}\n}\n\nfunc TestMysqlPanicIfDialectNotInitialized(t *testing.T) {\n\t_, driver := dialectAndDriver()\n\t// this test only applies to MySQL\n\tif os.Getenv(\"GORP_TEST_DIALECT\") != \"mysql\" {\n\t\treturn\n\t}\n\n\t// The expected behaviour is to catch a panic.\n\t// Here is the deferred function which will check if a panic has indeed occurred :\n\tdefer func() {\n\t\tr := recover()\n\t\tif r == nil {\n\t\t\tt.Error(\"db.CreateTables() should panic if db is initialized with an incorrect gorp.MySQLDialect\")\n\t\t}\n\t}()\n\n\t// invalid MySQLDialect : does not contain Engine or Encoding specification\n\tdialect := gorp.MySQLDialect{}\n\tdb := &gorp.DbMap{Db: connect(driver), Dialect: dialect}\n\tdb.AddTableWithName(Invoice{}, \"invoice\")\n\t// the following call should panic :\n\tdb.CreateTables()\n}\n\nfunc TestSingleColumnKeyDbReturnsZeroRowsUpdatedOnPKChange(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\tdbmap.AddTableWithName(SingleColumnTable{}, \"single_column_table\").SetKeys(false, \"SomeId\")\n\terr := dbmap.DropTablesIfExists()\n\tif err != nil {\n\t\tt.Error(\"Drop tables failed\")\n\t}\n\terr = dbmap.CreateTablesIfNotExists()\n\tif err != nil {\n\t\tt.Error(\"Create tables failed\")\n\t}\n\terr = dbmap.TruncateTables()\n\tif err != nil {\n\t\tt.Error(\"Truncate tables failed\")\n\t}\n\n\tsct := SingleColumnTable{\n\t\tSomeId: \"A Unique Id String\",\n\t}\n\n\tcount, err := dbmap.Update(&sct)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tif count != 0 {\n\t\tt.Errorf(\"Expected 0 updated rows, got %d\", count)\n\t}\n\n}\n\nfunc TestPrepare(t *testing.T) {\n\tdbmap := initDBMap(t)\n\tdefer dropAndClose(dbmap)\n\n\tinv1 := &Invoice{0, 100, 200, \"prepare-foo\", 0, false}\n\tinv2 := &Invoice{0, 100, 200, \"prepare-bar\", 0, false}\n\t_insert(dbmap, inv1, inv2)\n\n\tbindVar0 := dbmap.Dialect.BindVar(0)\n\tbindVar1 := dbmap.Dialect.BindVar(1)\n\tstmt, err := dbmap.Prepare(fmt.Sprintf(\"UPDATE invoice_test SET \"+columnName(dbmap, Invoice{}, \"Memo\")+\"=%s WHERE \"+columnName(dbmap, Invoice{}, \"Id\")+\"=%s\", bindVar0, bindVar1))\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tdefer stmt.Close()\n\t_, err = stmt.Exec(\"prepare-baz\", inv1.Id)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\terr = dbmap.SelectOne(inv1, \"SELECT * from invoice_test WHERE \"+columnName(dbmap, Invoice{}, \"Memo\")+\"='prepare-baz'\")\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\ttrans, err := dbmap.Begin()\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\ttransStmt, err := trans.Prepare(fmt.Sprintf(\"UPDATE invoice_test SET \"+columnName(dbmap, Invoice{}, \"IsPaid\")+\"=%s WHERE \"+columnName(dbmap, Invoice{}, \"Id\")+\"=%s\", bindVar0, bindVar1))\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tdefer transStmt.Close()\n\t_, err = transStmt.Exec(true, inv2.Id)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\terr = dbmap.SelectOne(inv2, fmt.Sprintf(\"SELECT * from invoice_test WHERE \"+columnName(dbmap, Invoice{}, \"IsPaid\")+\"=%s\", bindVar0), true)\n\tif err == nil || err != sql.ErrNoRows {\n\t\tt.Error(\"SelectOne should have returned an sql.ErrNoRows\")\n\t}\n\terr = trans.SelectOne(inv2, fmt.Sprintf(\"SELECT * from invoice_test WHERE \"+columnName(dbmap, Invoice{}, \"IsPaid\")+\"=%s\", bindVar0), true)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\terr = trans.Commit()\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\terr = dbmap.SelectOne(inv2, fmt.Sprintf(\"SELECT * from invoice_test WHERE \"+columnName(dbmap, Invoice{}, \"IsPaid\")+\"=%s\", bindVar0), true)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n}\n\ntype UUID4 string\n\nfunc (u UUID4) Value() (driver.Value, error) {\n\tif u == \"\" {\n\t\treturn nil, nil\n\t}\n\n\treturn string(u), nil\n}\n\ntype NilPointer struct {\n\tID     string\n\tUserID *UUID4\n}\n\nfunc TestCallOfValueMethodOnNilPointer(t *testing.T) {\n\tdbmap := newDBMap(t)\n\tdbmap.AddTable(NilPointer{}).SetKeys(false, \"ID\")\n\tdefer dropAndClose(dbmap)\n\terr := dbmap.CreateTables()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tnilPointer := &NilPointer{ID: \"abc\", UserID: nil}\n\t_insert(dbmap, nilPointer)\n}\n\nfunc BenchmarkNativeCrud(b *testing.B) {\n\tb.StopTimer()\n\tdbmap := initDBMapBench(b)\n\tdefer dropAndClose(dbmap)\n\tcolumnId := columnName(dbmap, Invoice{}, \"Id\")\n\tcolumnCreated := columnName(dbmap, Invoice{}, \"Created\")\n\tcolumnUpdated := columnName(dbmap, Invoice{}, \"Updated\")\n\tcolumnMemo := columnName(dbmap, Invoice{}, \"Memo\")\n\tcolumnPersonId := columnName(dbmap, Invoice{}, \"PersonId\")\n\tb.StartTimer()\n\n\tvar insert, sel, update, delete string\n\tif os.Getenv(\"GORP_TEST_DIALECT\") != \"postgres\" {\n\t\tinsert = \"insert into invoice_test (\" + columnCreated + \", \" + columnUpdated + \", \" + columnMemo + \", \" + columnPersonId + \") values (?, ?, ?, ?)\"\n\t\tsel = \"select \" + columnId + \", \" + columnCreated + \", \" + columnUpdated + \", \" + columnMemo + \", \" + columnPersonId + \" from invoice_test where \" + columnId + \"=?\"\n\t\tupdate = \"update invoice_test set \" + columnCreated + \"=?, \" + columnUpdated + \"=?, \" + columnMemo + \"=?, \" + columnPersonId + \"=? where \" + columnId + \"=?\"\n\t\tdelete = \"delete from invoice_test where \" + columnId + \"=?\"\n\t} else {\n\t\tinsert = \"insert into invoice_test (\" + columnCreated + \", \" + columnUpdated + \", \" + columnMemo + \", \" + columnPersonId + \") values ($1, $2, $3, $4)\"\n\t\tsel = \"select \" + columnId + \", \" + columnCreated + \", \" + columnUpdated + \", \" + columnMemo + \", \" + columnPersonId + \" from invoice_test where \" + columnId + \"=$1\"\n\t\tupdate = \"update invoice_test set \" + columnCreated + \"=$1, \" + columnUpdated + \"=$2, \" + columnMemo + \"=$3, \" + columnPersonId + \"=$4 where \" + columnId + \"=$5\"\n\t\tdelete = \"delete from invoice_test where \" + columnId + \"=$1\"\n\t}\n\n\tinv := &Invoice{0, 100, 200, \"my memo\", 0, false}\n\n\tfor i := 0; i < b.N; i++ {\n\t\tres, err := dbmap.Db.Exec(insert, inv.Created, inv.Updated,\n\t\t\tinv.Memo, inv.PersonId)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\n\t\tnewid, err := res.LastInsertId()\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\tinv.Id = newid\n\n\t\trow := dbmap.Db.QueryRow(sel, inv.Id)\n\t\terr = row.Scan(&inv.Id, &inv.Created, &inv.Updated, &inv.Memo,\n\t\t\t&inv.PersonId)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\n\t\tinv.Created = 1000\n\t\tinv.Updated = 2000\n\t\tinv.Memo = \"my memo 2\"\n\t\tinv.PersonId = 3000\n\n\t\t_, err = dbmap.Db.Exec(update, inv.Created, inv.Updated, inv.Memo,\n\t\t\tinv.PersonId, inv.Id)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\n\t\t_, err = dbmap.Db.Exec(delete, inv.Id)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t}\n\n}\n\nfunc BenchmarkGorpCrud(b *testing.B) {\n\tb.StopTimer()\n\tdbmap := initDBMapBench(b)\n\tdefer dropAndClose(dbmap)\n\tb.StartTimer()\n\n\tinv := &Invoice{0, 100, 200, \"my memo\", 0, true}\n\tfor i := 0; i < b.N; i++ {\n\t\terr := dbmap.Insert(inv)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\n\t\tobj, err := dbmap.Get(Invoice{}, inv.Id)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\n\t\tinv2, ok := obj.(*Invoice)\n\t\tif !ok {\n\t\t\tpanic(fmt.Sprintf(\"expected *Invoice, got: %v\", obj))\n\t\t}\n\n\t\tinv2.Created = 1000\n\t\tinv2.Updated = 2000\n\t\tinv2.Memo = \"my memo 2\"\n\t\tinv2.PersonId = 3000\n\t\t_, err = dbmap.Update(inv2)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\n\t\t_, err = dbmap.Delete(inv2)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\n\t}\n}\n\nfunc initDBMapBench(b *testing.B) *gorp.DbMap {\n\tdbmap := newDBMap(b)\n\tdbmap.Db.Exec(\"drop table if exists invoice_test\")\n\tdbmap.AddTableWithName(Invoice{}, \"invoice_test\").SetKeys(true, \"Id\")\n\terr := dbmap.CreateTables()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn dbmap\n}\n\nfunc initDBMap(t *testing.T) *gorp.DbMap {\n\tdbmap := newDBMap(t)\n\tdbmap.AddTableWithName(Invoice{}, \"invoice_test\").SetKeys(true, \"Id\")\n\tdbmap.AddTableWithName(InvoiceTag{}, \"invoice_tag_test\") //key is set via primarykey attribute\n\tdbmap.AddTableWithName(AliasTransientField{}, \"alias_trans_field_test\").SetKeys(true, \"id\")\n\tdbmap.AddTableWithName(OverriddenInvoice{}, \"invoice_override_test\").SetKeys(false, \"Id\")\n\tdbmap.AddTableWithName(Person{}, \"person_test\").SetKeys(true, \"Id\").SetVersionCol(\"Version\")\n\tdbmap.AddTableWithName(WithIgnoredColumn{}, \"ignored_column_test\").SetKeys(true, \"Id\")\n\tdbmap.AddTableWithName(IdCreated{}, \"id_created_test\").SetKeys(true, \"Id\")\n\tdbmap.AddTableWithName(TypeConversionExample{}, \"type_conv_test\").SetKeys(true, \"Id\")\n\tdbmap.AddTableWithName(WithEmbeddedStruct{}, \"embedded_struct_test\").SetKeys(true, \"Id\")\n\t//dbmap.AddTableWithName(WithEmbeddedStructConflictingEmbeddedMemberNames{}, \"embedded_struct_conflict_name_test\").SetKeys(true, \"Id\")\n\t//dbmap.AddTableWithName(WithEmbeddedStructSameMemberName{}, \"embedded_struct_same_member_name_test\").SetKeys(true, \"Id\")\n\tdbmap.AddTableWithName(WithEmbeddedStructBeforeAutoincrField{}, \"embedded_struct_before_autoincr_test\").SetKeys(true, \"Id\")\n\tdbmap.AddTableDynamic(&dynTableInst1, \"\").SetKeys(true, \"Id\").AddIndex(\"TenantInst1Index\", \"Btree\", []string{\"Name\"}).SetUnique(true)\n\tdbmap.AddTableDynamic(&dynTableInst2, \"\").SetKeys(true, \"Id\").AddIndex(\"TenantInst2Index\", \"Btree\", []string{\"Name\"}).SetUnique(true)\n\tdbmap.AddTableWithName(WithEmbeddedAutoincr{}, \"embedded_autoincr_test\").SetKeys(true, \"Id\")\n\tdbmap.AddTableWithName(WithTime{}, \"time_test\").SetKeys(true, \"Id\")\n\tdbmap.AddTableWithName(WithNullTime{}, \"nulltime_test\").SetKeys(false, \"Id\")\n\tdbmap.TypeConverter = testTypeConverter{}\n\terr := dbmap.DropTablesIfExists()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\terr = dbmap.CreateTables()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\terr = dbmap.CreateIndex()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\t// See #146 and TestSelectAlias - this type is mapped to the same\n\t// table as IdCreated, but includes an extra field that isn't in the table\n\tdbmap.AddTableWithName(IdCreatedExternal{}, \"id_created_test\").SetKeys(true, \"Id\")\n\n\treturn dbmap\n}\n\nfunc initDBMapNulls(t *testing.T) *gorp.DbMap {\n\tdbmap := newDBMap(t)\n\tdbmap.AddTable(TableWithNull{}).SetKeys(false, \"Id\")\n\terr := dbmap.CreateTables()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn dbmap\n}\n\ntype Logger interface {\n\tLogf(format string, args ...any)\n}\n\ntype TestLogger struct {\n\tl Logger\n}\n\nfunc (l TestLogger) Printf(format string, args ...any) {\n\tl.l.Logf(format, args...)\n}\n\nfunc newDBMap(l Logger) *gorp.DbMap {\n\tdialect, driver := dialectAndDriver()\n\tdbmap := &gorp.DbMap{Db: connect(driver), Dialect: dialect}\n\tif debug {\n\t\tdbmap.TraceOn(\"\", TestLogger{l: l})\n\t}\n\treturn dbmap\n}\n\nfunc dropAndClose(dbmap *gorp.DbMap) {\n\tdbmap.DropTablesIfExists()\n\tdbmap.Db.Close()\n}\n\nfunc connect(driver string) *sql.DB {\n\tdsn := os.Getenv(\"GORP_TEST_DSN\")\n\tif dsn == \"\" {\n\t\tpanic(\"GORP_TEST_DSN env variable is not set. Please see README.md\")\n\t}\n\n\tdb, err := sql.Open(driver, dsn)\n\tif err != nil {\n\t\tpanic(\"Error connecting to db: \" + err.Error())\n\t}\n\treturn db\n}\n\nfunc dialectAndDriver() (gorp.Dialect, string) {\n\tswitch os.Getenv(\"GORP_TEST_DIALECT\") {\n\tcase \"mysql\", \"gomysql\":\n\t\t// NOTE: the 'mysql' driver used to use github.com/ziutek/mymysql, but that project\n\t\t// seems mostly unmaintained recently.  We've dropped it from tests, at least for\n\t\t// now.\n\t\treturn gorp.MySQLDialect{\"InnoDB\", \"UTF8\"}, \"mysql\"\n\tcase \"postgres\":\n\t\treturn gorp.PostgresDialect{}, \"postgres\"\n\tcase \"sqlite\":\n\t\treturn gorp.SqliteDialect{}, \"sqlite3\"\n\t}\n\tpanic(\"GORP_TEST_DIALECT env variable is not set or is invalid. Please see README.md\")\n}\n\nfunc _insert(dbmap *gorp.DbMap, list ...interface{}) {\n\terr := dbmap.Insert(list...)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n}\n\nfunc _update(dbmap *gorp.DbMap, list ...interface{}) int64 {\n\tcount, err := dbmap.Update(list...)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn count\n}\n\nfunc _updateColumns(dbmap *gorp.DbMap, filter gorp.ColumnFilter, list ...interface{}) int64 {\n\tcount, err := dbmap.UpdateColumns(filter, list...)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn count\n}\n\nfunc _del(dbmap *gorp.DbMap, list ...interface{}) int64 {\n\tcount, err := dbmap.Delete(list...)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\treturn count\n}\n\nfunc _get(dbmap *gorp.DbMap, i interface{}, keys ...interface{}) interface{} {\n\tobj, err := dbmap.Get(i, keys...)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\treturn obj\n}\n\nfunc selectInt(dbmap *gorp.DbMap, query string, args ...interface{}) int64 {\n\ti64, err := gorp.SelectInt(dbmap, query, args...)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\treturn i64\n}\n\nfunc selectNullInt(dbmap *gorp.DbMap, query string, args ...interface{}) sql.NullInt64 {\n\ti64, err := gorp.SelectNullInt(dbmap, query, args...)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\treturn i64\n}\n\nfunc selectFloat(dbmap *gorp.DbMap, query string, args ...interface{}) float64 {\n\tf64, err := gorp.SelectFloat(dbmap, query, args...)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\treturn f64\n}\n\nfunc selectNullFloat(dbmap *gorp.DbMap, query string, args ...interface{}) sql.NullFloat64 {\n\tf64, err := gorp.SelectNullFloat(dbmap, query, args...)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\treturn f64\n}\n\nfunc selectStr(dbmap *gorp.DbMap, query string, args ...interface{}) string {\n\ts, err := gorp.SelectStr(dbmap, query, args...)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\treturn s\n}\n\nfunc selectNullStr(dbmap *gorp.DbMap, query string, args ...interface{}) sql.NullString {\n\ts, err := gorp.SelectNullStr(dbmap, query, args...)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\treturn s\n}\n\nfunc rawExec(dbmap *gorp.DbMap, query string, args ...interface{}) sql.Result {\n\tres, err := dbmap.Exec(query, args...)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn res\n}\n\nfunc rawSelect(dbmap *gorp.DbMap, i interface{}, query string, args ...interface{}) []interface{} {\n\tlist, err := dbmap.Select(i, query, args...)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn list\n}\n\nfunc tableName(dbmap *gorp.DbMap, i interface{}) string {\n\tt := reflect.TypeOf(i)\n\tif table, err := dbmap.TableFor(t, false); table != nil && err == nil {\n\t\treturn dbmap.Dialect.QuoteField(table.TableName)\n\t}\n\treturn t.Name()\n}\n\nfunc columnName(dbmap *gorp.DbMap, i interface{}, fieldName string) string {\n\tt := reflect.TypeOf(i)\n\tif table, err := dbmap.TableFor(t, false); table != nil && err == nil {\n\t\treturn dbmap.Dialect.QuoteField(table.ColMap(fieldName).ColumnName)\n\t}\n\treturn fieldName\n}\n"
        },
        {
          "name": "hooks.go",
          "type": "blob",
          "size": 1.2734375,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage gorp\n\n//++ TODO v2-phase3: HasPostGet => PostGetter, HasPostDelete => PostDeleter, etc.\n\n// HasPostGet provides PostGet() which will be executed after the GET statement.\ntype HasPostGet interface {\n\tPostGet(SqlExecutor) error\n}\n\n// HasPostDelete provides PostDelete() which will be executed after the DELETE statement\ntype HasPostDelete interface {\n\tPostDelete(SqlExecutor) error\n}\n\n// HasPostUpdate provides PostUpdate() which will be executed after the UPDATE statement\ntype HasPostUpdate interface {\n\tPostUpdate(SqlExecutor) error\n}\n\n// HasPostInsert provides PostInsert() which will be executed after the INSERT statement\ntype HasPostInsert interface {\n\tPostInsert(SqlExecutor) error\n}\n\n// HasPreDelete provides PreDelete() which will be executed before the DELETE statement.\ntype HasPreDelete interface {\n\tPreDelete(SqlExecutor) error\n}\n\n// HasPreUpdate provides PreUpdate() which will be executed before UPDATE statement.\ntype HasPreUpdate interface {\n\tPreUpdate(SqlExecutor) error\n}\n\n// HasPreInsert provides PreInsert() which will be executed before INSERT statement.\ntype HasPreInsert interface {\n\tPreInsert(SqlExecutor) error\n}\n"
        },
        {
          "name": "index.go",
          "type": "blob",
          "size": 1.2998046875,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage gorp\n\n// IndexMap represents a mapping between a Go struct field and a single\n// index in a table.\n// Unique and MaxSize only inform the\n// CreateTables() function and are not used by Insert/Update/Delete/Get.\ntype IndexMap struct {\n\t// Index name in db table\n\tIndexName string\n\n\t// If true, \" unique\" is added to create index statements.\n\t// Not used elsewhere\n\tUnique bool\n\n\t// Index type supported by Dialect\n\t// Postgres:  B-tree, Hash, GiST and GIN.\n\t// Mysql: Btree, Hash.\n\t// Sqlite: nil.\n\tIndexType string\n\n\t// Columns name for single and multiple indexes\n\tcolumns []string\n}\n\n// Rename allows you to specify the index name in the table\n//\n// Example:  table.IndMap(\"customer_test_idx\").Rename(\"customer_idx\")\n//\nfunc (idx *IndexMap) Rename(indname string) *IndexMap {\n\tidx.IndexName = indname\n\treturn idx\n}\n\n// SetUnique adds \"unique\" to the create index statements for this\n// index, if b is true.\nfunc (idx *IndexMap) SetUnique(b bool) *IndexMap {\n\tidx.Unique = b\n\treturn idx\n}\n\n// SetIndexType specifies the index type supported by chousen SQL Dialect\nfunc (idx *IndexMap) SetIndexType(indtype string) *IndexMap {\n\tidx.IndexType = indtype\n\treturn idx\n}\n"
        },
        {
          "name": "lockerror.go",
          "type": "blob",
          "size": 1.62109375,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage gorp\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n)\n\n// OptimisticLockError is returned by Update() or Delete() if the\n// struct being modified has a Version field and the value is not equal to\n// the current value in the database\ntype OptimisticLockError struct {\n\t// Table name where the lock error occurred\n\tTableName string\n\n\t// Primary key values of the row being updated/deleted\n\tKeys []interface{}\n\n\t// true if a row was found with those keys, indicating the\n\t// LocalVersion is stale.  false if no value was found with those\n\t// keys, suggesting the row has been deleted since loaded, or\n\t// was never inserted to begin with\n\tRowExists bool\n\n\t// Version value on the struct passed to Update/Delete. This value is\n\t// out of sync with the database.\n\tLocalVersion int64\n}\n\n// Error returns a description of the cause of the lock error\nfunc (e OptimisticLockError) Error() string {\n\tif e.RowExists {\n\t\treturn fmt.Sprintf(\"gorp: OptimisticLockError table=%s keys=%v out of date version=%d\", e.TableName, e.Keys, e.LocalVersion)\n\t}\n\n\treturn fmt.Sprintf(\"gorp: OptimisticLockError no row found for table=%s keys=%v\", e.TableName, e.Keys)\n}\n\nfunc lockError(m *DbMap, exec SqlExecutor, tableName string,\n\texistingVer int64, elem reflect.Value,\n\tkeys ...interface{}) (int64, error) {\n\n\texisting, err := get(m, exec, elem.Interface(), keys...)\n\tif err != nil {\n\t\treturn -1, err\n\t}\n\n\tole := OptimisticLockError{tableName, keys, true, existingVer}\n\tif existing == nil {\n\t\tole.RowExists = false\n\t}\n\treturn -1, ole\n}\n"
        },
        {
          "name": "logging.go",
          "type": "blob",
          "size": 1.1904296875,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage gorp\n\nimport \"fmt\"\n\n// GorpLogger is a deprecated alias of Logger.\ntype GorpLogger = Logger\n\n// Logger is the type that gorp uses to log SQL statements.\n// See DbMap.TraceOn.\ntype Logger interface {\n\tPrintf(format string, v ...interface{})\n}\n\n// TraceOn turns on SQL statement logging for this DbMap.  After this is\n// called, all SQL statements will be sent to the logger.  If prefix is\n// a non-empty string, it will be written to the front of all logged\n// strings, which can aid in filtering log lines.\n//\n// Use TraceOn if you want to spy on the SQL statements that gorp\n// generates.\n//\n// Note that the base log.Logger type satisfies Logger, but adapters can\n// easily be written for other logging packages (e.g., the golang-sanctioned\n// glog framework).\nfunc (m *DbMap) TraceOn(prefix string, logger Logger) {\n\tm.logger = logger\n\tif prefix == \"\" {\n\t\tm.logPrefix = prefix\n\t} else {\n\t\tm.logPrefix = fmt.Sprintf(\"%s \", prefix)\n\t}\n}\n\n// TraceOff turns off tracing. It is idempotent.\nfunc (m *DbMap) TraceOff() {\n\tm.logger = nil\n\tm.logPrefix = \"\"\n}\n"
        },
        {
          "name": "nulltypes.go",
          "type": "blob",
          "size": 1.259765625,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage gorp\n\nimport (\n\t\"database/sql/driver\"\n\t\"log\"\n\t\"time\"\n)\n\n// A nullable Time value\ntype NullTime struct {\n\tTime  time.Time\n\tValid bool // Valid is true if Time is not NULL\n}\n\n// Scan implements the Scanner interface.\nfunc (nt *NullTime) Scan(value interface{}) error {\n\tlog.Printf(\"Time scan value is: %#v\", value)\n\tswitch t := value.(type) {\n\tcase time.Time:\n\t\tnt.Time, nt.Valid = t, true\n\tcase []byte:\n\t\tv := strToTime(string(t))\n\t\tif v != nil {\n\t\t\tnt.Valid = true\n\t\t\tnt.Time = *v\n\t\t}\n\tcase string:\n\t\tv := strToTime(t)\n\t\tif v != nil {\n\t\t\tnt.Valid = true\n\t\t\tnt.Time = *v\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc strToTime(v string) *time.Time {\n\tfor _, dtfmt := range []string{\n\t\t\"2006-01-02 15:04:05.999999999\",\n\t\t\"2006-01-02T15:04:05.999999999\",\n\t\t\"2006-01-02 15:04:05\",\n\t\t\"2006-01-02T15:04:05\",\n\t\t\"2006-01-02 15:04\",\n\t\t\"2006-01-02T15:04\",\n\t\t\"2006-01-02\",\n\t\t\"2006-01-02 15:04:05-07:00\",\n\t} {\n\t\tif t, err := time.Parse(dtfmt, v); err == nil {\n\t\t\treturn &t\n\t\t}\n\t}\n\treturn nil\n}\n\n// Value implements the driver Valuer interface.\nfunc (nt NullTime) Value() (driver.Value, error) {\n\tif !nt.Valid {\n\t\treturn nil, nil\n\t}\n\treturn nt.Time, nil\n}\n"
        },
        {
          "name": "select.go",
          "type": "blob",
          "size": 8.8779296875,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage gorp\n\nimport (\n\t\"database/sql\"\n\t\"fmt\"\n\t\"reflect\"\n)\n\n// SelectInt executes the given query, which should be a SELECT statement for a single\n// integer column, and returns the value of the first row returned.  If no rows are\n// found, zero is returned.\nfunc SelectInt(e SqlExecutor, query string, args ...interface{}) (int64, error) {\n\tvar h int64\n\terr := selectVal(e, &h, query, args...)\n\tif err != nil && err != sql.ErrNoRows {\n\t\treturn 0, err\n\t}\n\treturn h, nil\n}\n\n// SelectNullInt executes the given query, which should be a SELECT statement for a single\n// integer column, and returns the value of the first row returned.  If no rows are\n// found, the empty sql.NullInt64 value is returned.\nfunc SelectNullInt(e SqlExecutor, query string, args ...interface{}) (sql.NullInt64, error) {\n\tvar h sql.NullInt64\n\terr := selectVal(e, &h, query, args...)\n\tif err != nil && err != sql.ErrNoRows {\n\t\treturn h, err\n\t}\n\treturn h, nil\n}\n\n// SelectFloat executes the given query, which should be a SELECT statement for a single\n// float column, and returns the value of the first row returned. If no rows are\n// found, zero is returned.\nfunc SelectFloat(e SqlExecutor, query string, args ...interface{}) (float64, error) {\n\tvar h float64\n\terr := selectVal(e, &h, query, args...)\n\tif err != nil && err != sql.ErrNoRows {\n\t\treturn 0, err\n\t}\n\treturn h, nil\n}\n\n// SelectNullFloat executes the given query, which should be a SELECT statement for a single\n// float column, and returns the value of the first row returned. If no rows are\n// found, the empty sql.NullInt64 value is returned.\nfunc SelectNullFloat(e SqlExecutor, query string, args ...interface{}) (sql.NullFloat64, error) {\n\tvar h sql.NullFloat64\n\terr := selectVal(e, &h, query, args...)\n\tif err != nil && err != sql.ErrNoRows {\n\t\treturn h, err\n\t}\n\treturn h, nil\n}\n\n// SelectStr executes the given query, which should be a SELECT statement for a single\n// char/varchar column, and returns the value of the first row returned.  If no rows are\n// found, an empty string is returned.\nfunc SelectStr(e SqlExecutor, query string, args ...interface{}) (string, error) {\n\tvar h string\n\terr := selectVal(e, &h, query, args...)\n\tif err != nil && err != sql.ErrNoRows {\n\t\treturn \"\", err\n\t}\n\treturn h, nil\n}\n\n// SelectNullStr executes the given query, which should be a SELECT\n// statement for a single char/varchar column, and returns the value\n// of the first row returned.  If no rows are found, the empty\n// sql.NullString is returned.\nfunc SelectNullStr(e SqlExecutor, query string, args ...interface{}) (sql.NullString, error) {\n\tvar h sql.NullString\n\terr := selectVal(e, &h, query, args...)\n\tif err != nil && err != sql.ErrNoRows {\n\t\treturn h, err\n\t}\n\treturn h, nil\n}\n\n// SelectOne executes the given query (which should be a SELECT statement)\n// and binds the result to holder, which must be a pointer.\n//\n// If no row is found, an error (sql.ErrNoRows specifically) will be returned\n//\n// If more than one row is found, an error will be returned.\n//\nfunc SelectOne(m *DbMap, e SqlExecutor, holder interface{}, query string, args ...interface{}) error {\n\tt := reflect.TypeOf(holder)\n\tif t.Kind() == reflect.Ptr {\n\t\tt = t.Elem()\n\t} else {\n\t\treturn fmt.Errorf(\"gorp: SelectOne holder must be a pointer, but got: %t\", holder)\n\t}\n\n\t// Handle pointer to pointer\n\tisptr := false\n\tif t.Kind() == reflect.Ptr {\n\t\tisptr = true\n\t\tt = t.Elem()\n\t}\n\n\tif t.Kind() == reflect.Struct {\n\t\tvar nonFatalErr error\n\n\t\tlist, err := hookedselect(m, e, holder, query, args...)\n\t\tif err != nil {\n\t\t\tif !NonFatalError(err) { // FIXME: double negative, rename NonFatalError to FatalError\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tnonFatalErr = err\n\t\t}\n\n\t\tdest := reflect.ValueOf(holder)\n\t\tif isptr {\n\t\t\tdest = dest.Elem()\n\t\t}\n\n\t\tif list != nil && len(list) > 0 { // FIXME: invert if/else\n\t\t\t// check for multiple rows\n\t\t\tif len(list) > 1 {\n\t\t\t\treturn fmt.Errorf(\"gorp: multiple rows returned for: %s - %v\", query, args)\n\t\t\t}\n\n\t\t\t// Initialize if nil\n\t\t\tif dest.IsNil() {\n\t\t\t\tdest.Set(reflect.New(t))\n\t\t\t}\n\n\t\t\t// only one row found\n\t\t\tsrc := reflect.ValueOf(list[0])\n\t\t\tdest.Elem().Set(src.Elem())\n\t\t} else {\n\t\t\t// No rows found, return a proper error.\n\t\t\treturn sql.ErrNoRows\n\t\t}\n\n\t\treturn nonFatalErr\n\t}\n\n\treturn selectVal(e, holder, query, args...)\n}\n\nfunc selectVal(e SqlExecutor, holder interface{}, query string, args ...interface{}) error {\n\tif len(args) == 1 {\n\t\tswitch m := e.(type) {\n\t\tcase *DbMap:\n\t\t\tquery, args = maybeExpandNamedQuery(m, query, args)\n\t\tcase *Transaction:\n\t\t\tquery, args = maybeExpandNamedQuery(m.dbmap, query, args)\n\t\t}\n\t}\n\trows, err := e.Query(query, args...)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer rows.Close()\n\n\tif !rows.Next() {\n\t\tif err := rows.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn sql.ErrNoRows\n\t}\n\n\treturn rows.Scan(holder)\n}\n\nfunc hookedselect(m *DbMap, exec SqlExecutor, i interface{}, query string,\n\targs ...interface{}) ([]interface{}, error) {\n\n\tvar nonFatalErr error\n\n\tlist, err := rawselect(m, exec, i, query, args...)\n\tif err != nil {\n\t\tif !NonFatalError(err) {\n\t\t\treturn nil, err\n\t\t}\n\t\tnonFatalErr = err\n\t}\n\n\t// Determine where the results are: written to i, or returned in list\n\tif t, _ := toSliceType(i); t == nil {\n\t\tfor _, v := range list {\n\t\t\tif v, ok := v.(HasPostGet); ok {\n\t\t\t\terr := v.PostGet(exec)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\tresultsValue := reflect.Indirect(reflect.ValueOf(i))\n\t\tfor i := 0; i < resultsValue.Len(); i++ {\n\t\t\tif v, ok := resultsValue.Index(i).Interface().(HasPostGet); ok {\n\t\t\t\terr := v.PostGet(exec)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn list, nonFatalErr\n}\n\nfunc rawselect(m *DbMap, exec SqlExecutor, i interface{}, query string,\n\targs ...interface{}) ([]interface{}, error) {\n\tvar (\n\t\tappendToSlice   = false // Write results to i directly?\n\t\tintoStruct      = true  // Selecting into a struct?\n\t\tpointerElements = true  // Are the slice elements pointers (vs values)?\n\t)\n\n\tvar nonFatalErr error\n\n\ttableName := \"\"\n\tvar dynObj DynamicTable\n\tisDynamic := false\n\tif dynObj, isDynamic = i.(DynamicTable); isDynamic {\n\t\ttableName = dynObj.TableName()\n\t}\n\n\t// get type for i, verifying it's a supported destination\n\tt, err := toType(i)\n\tif err != nil {\n\t\tvar err2 error\n\t\tif t, err2 = toSliceType(i); t == nil {\n\t\t\tif err2 != nil {\n\t\t\t\treturn nil, err2\n\t\t\t}\n\t\t\treturn nil, err\n\t\t}\n\t\tpointerElements = t.Kind() == reflect.Ptr\n\t\tif pointerElements {\n\t\t\tt = t.Elem()\n\t\t}\n\t\tappendToSlice = true\n\t\tintoStruct = t.Kind() == reflect.Struct\n\t}\n\n\t// If the caller supplied a single struct/map argument, assume a \"named\n\t// parameter\" query.  Extract the named arguments from the struct/map, create\n\t// the flat arg slice, and rewrite the query to use the dialect's placeholder.\n\tif len(args) == 1 {\n\t\tquery, args = maybeExpandNamedQuery(m, query, args)\n\t}\n\n\t// Run the query\n\trows, err := exec.Query(query, args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer rows.Close()\n\n\t// Fetch the column names as returned from db\n\tcols, err := rows.Columns()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif !intoStruct && len(cols) > 1 {\n\t\treturn nil, fmt.Errorf(\"gorp: select into non-struct slice requires 1 column, got %d\", len(cols))\n\t}\n\n\tvar colToFieldIndex [][]int\n\tif intoStruct {\n\t\tcolToFieldIndex, err = columnToFieldIndex(m, t, tableName, cols)\n\t\tif err != nil {\n\t\t\tif !NonFatalError(err) {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tnonFatalErr = err\n\t\t}\n\t}\n\n\tconv := m.TypeConverter\n\n\t// Add results to one of these two slices.\n\tvar (\n\t\tlist       = make([]interface{}, 0)\n\t\tsliceValue = reflect.Indirect(reflect.ValueOf(i))\n\t)\n\n\tfor {\n\t\tif !rows.Next() {\n\t\t\t// if error occured return rawselect\n\t\t\tif rows.Err() != nil {\n\t\t\t\treturn nil, rows.Err()\n\t\t\t}\n\t\t\t// time to exit from outer \"for\" loop\n\t\t\tbreak\n\t\t}\n\t\tv := reflect.New(t)\n\n\t\tif isDynamic {\n\t\t\tv.Interface().(DynamicTable).SetTableName(tableName)\n\t\t}\n\n\t\tdest := make([]interface{}, len(cols))\n\n\t\tcustScan := make([]CustomScanner, 0)\n\n\t\tfor x := range cols {\n\t\t\tf := v.Elem()\n\t\t\tif intoStruct {\n\t\t\t\tindex := colToFieldIndex[x]\n\t\t\t\tif index == nil {\n\t\t\t\t\t// this field is not present in the struct, so create a dummy\n\t\t\t\t\t// value for rows.Scan to scan into\n\t\t\t\t\tvar dummy dummyField\n\t\t\t\t\tdest[x] = &dummy\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tf = f.FieldByIndex(index)\n\t\t\t}\n\t\t\ttarget := f.Addr().Interface()\n\t\t\tif conv != nil {\n\t\t\t\tscanner, ok := conv.FromDb(target)\n\t\t\t\tif ok {\n\t\t\t\t\ttarget = scanner.Holder\n\t\t\t\t\tcustScan = append(custScan, scanner)\n\t\t\t\t}\n\t\t\t}\n\t\t\tdest[x] = target\n\t\t}\n\n\t\terr = rows.Scan(dest...)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tfor _, c := range custScan {\n\t\t\terr = c.Bind()\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\n\t\tif appendToSlice {\n\t\t\tif !pointerElements {\n\t\t\t\tv = v.Elem()\n\t\t\t}\n\t\t\tsliceValue.Set(reflect.Append(sliceValue, v))\n\t\t} else {\n\t\t\tlist = append(list, v.Interface())\n\t\t}\n\t}\n\n\tif appendToSlice && sliceValue.IsNil() {\n\t\tsliceValue.Set(reflect.MakeSlice(sliceValue.Type(), 0, 0))\n\t}\n\n\treturn list, nonFatalErr\n}\n"
        },
        {
          "name": "table.go",
          "type": "blob",
          "size": 6.755859375,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage gorp\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"reflect\"\n\t\"strings\"\n)\n\n// TableMap represents a mapping between a Go struct and a database table\n// Use dbmap.AddTable() or dbmap.AddTableWithName() to create these\ntype TableMap struct {\n\t// Name of database table.\n\tTableName      string\n\tSchemaName     string\n\tgotype         reflect.Type\n\tColumns        []*ColumnMap\n\tkeys           []*ColumnMap\n\tindexes        []*IndexMap\n\tuniqueTogether [][]string\n\tversion        *ColumnMap\n\tinsertPlan     bindPlan\n\tupdatePlan     bindPlan\n\tdeletePlan     bindPlan\n\tgetPlan        bindPlan\n\tdbmap          *DbMap\n}\n\n// ResetSql removes cached insert/update/select/delete SQL strings\n// associated with this TableMap.  Call this if you've modified\n// any column names or the table name itself.\nfunc (t *TableMap) ResetSql() {\n\tt.insertPlan = bindPlan{}\n\tt.updatePlan = bindPlan{}\n\tt.deletePlan = bindPlan{}\n\tt.getPlan = bindPlan{}\n}\n\n// SetKeys lets you specify the fields on a struct that map to primary\n// key columns on the table.  If isAutoIncr is set, result.LastInsertId()\n// will be used after INSERT to bind the generated id to the Go struct.\n//\n// Automatically calls ResetSql() to ensure SQL statements are regenerated.\n//\n// Panics if isAutoIncr is true, and fieldNames length != 1\n//\nfunc (t *TableMap) SetKeys(isAutoIncr bool, fieldNames ...string) *TableMap {\n\tif isAutoIncr && len(fieldNames) != 1 {\n\t\tpanic(fmt.Sprintf(\n\t\t\t\"gorp: SetKeys: fieldNames length must be 1 if key is auto-increment. (Saw %v fieldNames)\",\n\t\t\tlen(fieldNames)))\n\t}\n\tt.keys = make([]*ColumnMap, 0)\n\tfor _, name := range fieldNames {\n\t\tcolmap := t.ColMap(name)\n\t\tcolmap.isPK = true\n\t\tcolmap.isAutoIncr = isAutoIncr\n\t\tt.keys = append(t.keys, colmap)\n\t}\n\tt.ResetSql()\n\n\treturn t\n}\n\n// SetUniqueTogether lets you specify uniqueness constraints across multiple\n// columns on the table. Each call adds an additional constraint for the\n// specified columns.\n//\n// Automatically calls ResetSql() to ensure SQL statements are regenerated.\n//\n// Panics if fieldNames length < 2.\n//\nfunc (t *TableMap) SetUniqueTogether(fieldNames ...string) *TableMap {\n\tif len(fieldNames) < 2 {\n\t\tpanic(fmt.Sprintf(\n\t\t\t\"gorp: SetUniqueTogether: must provide at least two fieldNames to set uniqueness constraint.\"))\n\t}\n\n\tcolumns := make([]string, 0, len(fieldNames))\n\tfor _, name := range fieldNames {\n\t\tcolumns = append(columns, name)\n\t}\n\n\tfor _, existingColumns := range t.uniqueTogether {\n\t\tif equal(existingColumns, columns) {\n\t\t\treturn t\n\t\t}\n\t}\n\tt.uniqueTogether = append(t.uniqueTogether, columns)\n\tt.ResetSql()\n\n\treturn t\n}\n\n// ColMap returns the ColumnMap pointer matching the given struct field\n// name.  It panics if the struct does not contain a field matching this\n// name.\nfunc (t *TableMap) ColMap(field string) *ColumnMap {\n\tcol := colMapOrNil(t, field)\n\tif col == nil {\n\t\te := fmt.Sprintf(\"No ColumnMap in table %s type %s with field %s\",\n\t\t\tt.TableName, t.gotype.Name(), field)\n\n\t\tpanic(e)\n\t}\n\treturn col\n}\n\nfunc colMapOrNil(t *TableMap, field string) *ColumnMap {\n\tfor _, col := range t.Columns {\n\t\tif col.fieldName == field || col.ColumnName == field {\n\t\t\treturn col\n\t\t}\n\t}\n\treturn nil\n}\n\n// IdxMap returns the IndexMap pointer matching the given index name.\nfunc (t *TableMap) IdxMap(field string) *IndexMap {\n\tfor _, idx := range t.indexes {\n\t\tif idx.IndexName == field {\n\t\t\treturn idx\n\t\t}\n\t}\n\treturn nil\n}\n\n// AddIndex registers the index with gorp for specified table with given parameters.\n// This operation is idempotent. If index is already mapped, the\n// existing *IndexMap is returned\n// Function will panic if one of the given for index columns does not exists\n//\n// Automatically calls ResetSql() to ensure SQL statements are regenerated.\n//\nfunc (t *TableMap) AddIndex(name string, idxtype string, columns []string) *IndexMap {\n\t// check if we have a index with this name already\n\tfor _, idx := range t.indexes {\n\t\tif idx.IndexName == name {\n\t\t\treturn idx\n\t\t}\n\t}\n\tfor _, icol := range columns {\n\t\tif res := t.ColMap(icol); res == nil {\n\t\t\te := fmt.Sprintf(\"No ColumnName in table %s to create index on\", t.TableName)\n\t\t\tpanic(e)\n\t\t}\n\t}\n\n\tidx := &IndexMap{IndexName: name, Unique: false, IndexType: idxtype, columns: columns}\n\tt.indexes = append(t.indexes, idx)\n\tt.ResetSql()\n\treturn idx\n}\n\n// SetVersionCol sets the column to use as the Version field.  By default\n// the \"Version\" field is used.  Returns the column found, or panics\n// if the struct does not contain a field matching this name.\n//\n// Automatically calls ResetSql() to ensure SQL statements are regenerated.\nfunc (t *TableMap) SetVersionCol(field string) *ColumnMap {\n\tc := t.ColMap(field)\n\tt.version = c\n\tt.ResetSql()\n\treturn c\n}\n\n// SqlForCreateTable gets a sequence of SQL commands that will create\n// the specified table and any associated schema\nfunc (t *TableMap) SqlForCreate(ifNotExists bool) string {\n\ts := bytes.Buffer{}\n\tdialect := t.dbmap.Dialect\n\n\tif strings.TrimSpace(t.SchemaName) != \"\" {\n\t\tschemaCreate := \"create schema\"\n\t\tif ifNotExists {\n\t\t\ts.WriteString(dialect.IfSchemaNotExists(schemaCreate, t.SchemaName))\n\t\t} else {\n\t\t\ts.WriteString(schemaCreate)\n\t\t}\n\t\ts.WriteString(fmt.Sprintf(\" %s;\", t.SchemaName))\n\t}\n\n\ttableCreate := \"create table\"\n\tif ifNotExists {\n\t\ts.WriteString(dialect.IfTableNotExists(tableCreate, t.SchemaName, t.TableName))\n\t} else {\n\t\ts.WriteString(tableCreate)\n\t}\n\ts.WriteString(fmt.Sprintf(\" %s (\", dialect.QuotedTableForQuery(t.SchemaName, t.TableName)))\n\n\tx := 0\n\tfor _, col := range t.Columns {\n\t\tif !col.Transient {\n\t\t\tif x > 0 {\n\t\t\t\ts.WriteString(\", \")\n\t\t\t}\n\t\t\tstype := dialect.ToSqlType(col.gotype, col.MaxSize, col.isAutoIncr)\n\t\t\ts.WriteString(fmt.Sprintf(\"%s %s\", dialect.QuoteField(col.ColumnName), stype))\n\n\t\t\tif col.isPK || col.isNotNull {\n\t\t\t\ts.WriteString(\" not null\")\n\t\t\t}\n\t\t\tif col.isPK && len(t.keys) == 1 {\n\t\t\t\ts.WriteString(\" primary key\")\n\t\t\t}\n\t\t\tif col.Unique {\n\t\t\t\ts.WriteString(\" unique\")\n\t\t\t}\n\t\t\tif col.isAutoIncr {\n\t\t\t\ts.WriteString(fmt.Sprintf(\" %s\", dialect.AutoIncrStr()))\n\t\t\t}\n\n\t\t\tx++\n\t\t}\n\t}\n\tif len(t.keys) > 1 {\n\t\ts.WriteString(\", primary key (\")\n\t\tfor x := range t.keys {\n\t\t\tif x > 0 {\n\t\t\t\ts.WriteString(\", \")\n\t\t\t}\n\t\t\ts.WriteString(dialect.QuoteField(t.keys[x].ColumnName))\n\t\t}\n\t\ts.WriteString(\")\")\n\t}\n\tif len(t.uniqueTogether) > 0 {\n\t\tfor _, columns := range t.uniqueTogether {\n\t\t\ts.WriteString(\", unique (\")\n\t\t\tfor i, column := range columns {\n\t\t\t\tif i > 0 {\n\t\t\t\t\ts.WriteString(\", \")\n\t\t\t\t}\n\t\t\t\ts.WriteString(dialect.QuoteField(column))\n\t\t\t}\n\t\t\ts.WriteString(\")\")\n\t\t}\n\t}\n\ts.WriteString(\") \")\n\ts.WriteString(dialect.CreateTableSuffix())\n\ts.WriteString(dialect.QuerySuffix())\n\treturn s.String()\n}\n\nfunc equal(a, b []string) bool {\n\tif len(a) != len(b) {\n\t\treturn false\n\t}\n\tfor i := range a {\n\t\tif a[i] != b[i] {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n"
        },
        {
          "name": "table_bindings.go",
          "type": "blob",
          "size": 7.8740234375,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage gorp\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"reflect\"\n\t\"sync\"\n)\n\n// CustomScanner binds a database column value to a Go type\ntype CustomScanner struct {\n\t// After a row is scanned, Holder will contain the value from the database column.\n\t// Initialize the CustomScanner with the concrete Go type you wish the database\n\t// driver to scan the raw column into.\n\tHolder interface{}\n\t// Target typically holds a pointer to the target struct field to bind the Holder\n\t// value to.\n\tTarget interface{}\n\t// Binder is a custom function that converts the holder value to the target type\n\t// and sets target accordingly.  This function should return error if a problem\n\t// occurs converting the holder to the target.\n\tBinder func(holder interface{}, target interface{}) error\n}\n\n// Used to filter columns when selectively updating\ntype ColumnFilter func(*ColumnMap) bool\n\nfunc acceptAllFilter(col *ColumnMap) bool {\n\treturn true\n}\n\n// Bind is called automatically by gorp after Scan()\nfunc (me CustomScanner) Bind() error {\n\treturn me.Binder(me.Holder, me.Target)\n}\n\ntype bindPlan struct {\n\tquery             string\n\targFields         []string\n\tkeyFields         []string\n\tversField         string\n\tautoIncrIdx       int\n\tautoIncrFieldName string\n\tonce              sync.Once\n}\n\nfunc (plan *bindPlan) createBindInstance(elem reflect.Value, conv TypeConverter) (bindInstance, error) {\n\tbi := bindInstance{query: plan.query, autoIncrIdx: plan.autoIncrIdx, autoIncrFieldName: plan.autoIncrFieldName, versField: plan.versField}\n\tif plan.versField != \"\" {\n\t\tbi.existingVersion = elem.FieldByName(plan.versField).Int()\n\t}\n\n\tvar err error\n\n\tfor i := 0; i < len(plan.argFields); i++ {\n\t\tk := plan.argFields[i]\n\t\tif k == versFieldConst {\n\t\t\tnewVer := bi.existingVersion + 1\n\t\t\tbi.args = append(bi.args, newVer)\n\t\t\tif bi.existingVersion == 0 {\n\t\t\t\telem.FieldByName(plan.versField).SetInt(int64(newVer))\n\t\t\t}\n\t\t} else {\n\t\t\tval := elem.FieldByName(k).Interface()\n\t\t\tif conv != nil {\n\t\t\t\tval, err = conv.ToDb(val)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn bindInstance{}, err\n\t\t\t\t}\n\t\t\t}\n\t\t\tbi.args = append(bi.args, val)\n\t\t}\n\t}\n\n\tfor i := 0; i < len(plan.keyFields); i++ {\n\t\tk := plan.keyFields[i]\n\t\tval := elem.FieldByName(k).Interface()\n\t\tif conv != nil {\n\t\t\tval, err = conv.ToDb(val)\n\t\t\tif err != nil {\n\t\t\t\treturn bindInstance{}, err\n\t\t\t}\n\t\t}\n\t\tbi.keys = append(bi.keys, val)\n\t}\n\n\treturn bi, nil\n}\n\ntype bindInstance struct {\n\tquery             string\n\targs              []interface{}\n\tkeys              []interface{}\n\texistingVersion   int64\n\tversField         string\n\tautoIncrIdx       int\n\tautoIncrFieldName string\n}\n\nfunc (t *TableMap) bindInsert(elem reflect.Value) (bindInstance, error) {\n\tplan := &t.insertPlan\n\tplan.once.Do(func() {\n\t\tplan.autoIncrIdx = -1\n\n\t\ts := bytes.Buffer{}\n\t\ts2 := bytes.Buffer{}\n\t\ts.WriteString(fmt.Sprintf(\"insert into %s (\", t.dbmap.Dialect.QuotedTableForQuery(t.SchemaName, t.TableName)))\n\n\t\tx := 0\n\t\tfirst := true\n\t\tfor y := range t.Columns {\n\t\t\tcol := t.Columns[y]\n\t\t\tif !(col.isAutoIncr && t.dbmap.Dialect.AutoIncrBindValue() == \"\") {\n\t\t\t\tif !col.Transient {\n\t\t\t\t\tif !first {\n\t\t\t\t\t\ts.WriteString(\",\")\n\t\t\t\t\t\ts2.WriteString(\",\")\n\t\t\t\t\t}\n\t\t\t\t\ts.WriteString(t.dbmap.Dialect.QuoteField(col.ColumnName))\n\n\t\t\t\t\tif col.isAutoIncr {\n\t\t\t\t\t\ts2.WriteString(t.dbmap.Dialect.AutoIncrBindValue())\n\t\t\t\t\t\tplan.autoIncrIdx = y\n\t\t\t\t\t\tplan.autoIncrFieldName = col.fieldName\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif col.DefaultValue == \"\" {\n\t\t\t\t\t\t\ts2.WriteString(t.dbmap.Dialect.BindVar(x))\n\t\t\t\t\t\t\tif col == t.version {\n\t\t\t\t\t\t\t\tplan.versField = col.fieldName\n\t\t\t\t\t\t\t\tplan.argFields = append(plan.argFields, versFieldConst)\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tplan.argFields = append(plan.argFields, col.fieldName)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tx++\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\ts2.WriteString(col.DefaultValue)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tfirst = false\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tplan.autoIncrIdx = y\n\t\t\t\tplan.autoIncrFieldName = col.fieldName\n\t\t\t}\n\t\t}\n\t\ts.WriteString(\") values (\")\n\t\ts.WriteString(s2.String())\n\t\ts.WriteString(\")\")\n\t\tif plan.autoIncrIdx > -1 {\n\t\t\ts.WriteString(t.dbmap.Dialect.AutoIncrInsertSuffix(t.Columns[plan.autoIncrIdx]))\n\t\t}\n\t\ts.WriteString(t.dbmap.Dialect.QuerySuffix())\n\n\t\tplan.query = s.String()\n\t})\n\n\treturn plan.createBindInstance(elem, t.dbmap.TypeConverter)\n}\n\nfunc (t *TableMap) bindUpdate(elem reflect.Value, colFilter ColumnFilter) (bindInstance, error) {\n\tif colFilter == nil {\n\t\tcolFilter = acceptAllFilter\n\t}\n\n\tplan := &t.updatePlan\n\tplan.once.Do(func() {\n\t\ts := bytes.Buffer{}\n\t\ts.WriteString(fmt.Sprintf(\"update %s set \", t.dbmap.Dialect.QuotedTableForQuery(t.SchemaName, t.TableName)))\n\t\tx := 0\n\n\t\tfor y := range t.Columns {\n\t\t\tcol := t.Columns[y]\n\t\t\tif !col.isAutoIncr && !col.Transient && colFilter(col) {\n\t\t\t\tif x > 0 {\n\t\t\t\t\ts.WriteString(\", \")\n\t\t\t\t}\n\t\t\t\ts.WriteString(t.dbmap.Dialect.QuoteField(col.ColumnName))\n\t\t\t\ts.WriteString(\"=\")\n\t\t\t\ts.WriteString(t.dbmap.Dialect.BindVar(x))\n\n\t\t\t\tif col == t.version {\n\t\t\t\t\tplan.versField = col.fieldName\n\t\t\t\t\tplan.argFields = append(plan.argFields, versFieldConst)\n\t\t\t\t} else {\n\t\t\t\t\tplan.argFields = append(plan.argFields, col.fieldName)\n\t\t\t\t}\n\t\t\t\tx++\n\t\t\t}\n\t\t}\n\n\t\ts.WriteString(\" where \")\n\t\tfor y := range t.keys {\n\t\t\tcol := t.keys[y]\n\t\t\tif y > 0 {\n\t\t\t\ts.WriteString(\" and \")\n\t\t\t}\n\t\t\ts.WriteString(t.dbmap.Dialect.QuoteField(col.ColumnName))\n\t\t\ts.WriteString(\"=\")\n\t\t\ts.WriteString(t.dbmap.Dialect.BindVar(x))\n\n\t\t\tplan.argFields = append(plan.argFields, col.fieldName)\n\t\t\tplan.keyFields = append(plan.keyFields, col.fieldName)\n\t\t\tx++\n\t\t}\n\t\tif plan.versField != \"\" {\n\t\t\ts.WriteString(\" and \")\n\t\t\ts.WriteString(t.dbmap.Dialect.QuoteField(t.version.ColumnName))\n\t\t\ts.WriteString(\"=\")\n\t\t\ts.WriteString(t.dbmap.Dialect.BindVar(x))\n\t\t\tplan.argFields = append(plan.argFields, plan.versField)\n\t\t}\n\t\ts.WriteString(t.dbmap.Dialect.QuerySuffix())\n\n\t\tplan.query = s.String()\n\t})\n\n\treturn plan.createBindInstance(elem, t.dbmap.TypeConverter)\n}\n\nfunc (t *TableMap) bindDelete(elem reflect.Value) (bindInstance, error) {\n\tplan := &t.deletePlan\n\tplan.once.Do(func() {\n\t\ts := bytes.Buffer{}\n\t\ts.WriteString(fmt.Sprintf(\"delete from %s\", t.dbmap.Dialect.QuotedTableForQuery(t.SchemaName, t.TableName)))\n\n\t\tfor y := range t.Columns {\n\t\t\tcol := t.Columns[y]\n\t\t\tif !col.Transient {\n\t\t\t\tif col == t.version {\n\t\t\t\t\tplan.versField = col.fieldName\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\ts.WriteString(\" where \")\n\t\tfor x := range t.keys {\n\t\t\tk := t.keys[x]\n\t\t\tif x > 0 {\n\t\t\t\ts.WriteString(\" and \")\n\t\t\t}\n\t\t\ts.WriteString(t.dbmap.Dialect.QuoteField(k.ColumnName))\n\t\t\ts.WriteString(\"=\")\n\t\t\ts.WriteString(t.dbmap.Dialect.BindVar(x))\n\n\t\t\tplan.keyFields = append(plan.keyFields, k.fieldName)\n\t\t\tplan.argFields = append(plan.argFields, k.fieldName)\n\t\t}\n\t\tif plan.versField != \"\" {\n\t\t\ts.WriteString(\" and \")\n\t\t\ts.WriteString(t.dbmap.Dialect.QuoteField(t.version.ColumnName))\n\t\t\ts.WriteString(\"=\")\n\t\t\ts.WriteString(t.dbmap.Dialect.BindVar(len(plan.argFields)))\n\n\t\t\tplan.argFields = append(plan.argFields, plan.versField)\n\t\t}\n\t\ts.WriteString(t.dbmap.Dialect.QuerySuffix())\n\n\t\tplan.query = s.String()\n\t})\n\n\treturn plan.createBindInstance(elem, t.dbmap.TypeConverter)\n}\n\nfunc (t *TableMap) bindGet() *bindPlan {\n\tplan := &t.getPlan\n\tplan.once.Do(func() {\n\t\ts := bytes.Buffer{}\n\t\ts.WriteString(\"select \")\n\n\t\tx := 0\n\t\tfor _, col := range t.Columns {\n\t\t\tif !col.Transient {\n\t\t\t\tif x > 0 {\n\t\t\t\t\ts.WriteString(\",\")\n\t\t\t\t}\n\t\t\t\ts.WriteString(t.dbmap.Dialect.QuoteField(col.ColumnName))\n\t\t\t\tplan.argFields = append(plan.argFields, col.fieldName)\n\t\t\t\tx++\n\t\t\t}\n\t\t}\n\t\ts.WriteString(\" from \")\n\t\ts.WriteString(t.dbmap.Dialect.QuotedTableForQuery(t.SchemaName, t.TableName))\n\t\ts.WriteString(\" where \")\n\t\tfor x := range t.keys {\n\t\t\tcol := t.keys[x]\n\t\t\tif x > 0 {\n\t\t\t\ts.WriteString(\" and \")\n\t\t\t}\n\t\t\ts.WriteString(t.dbmap.Dialect.QuoteField(col.ColumnName))\n\t\t\ts.WriteString(\"=\")\n\t\t\ts.WriteString(t.dbmap.Dialect.BindVar(x))\n\n\t\t\tplan.keyFields = append(plan.keyFields, col.fieldName)\n\t\t}\n\t\ts.WriteString(t.dbmap.Dialect.QuerySuffix())\n\n\t\tplan.query = s.String()\n\t})\n\n\treturn plan\n}\n"
        },
        {
          "name": "test_all.sh",
          "type": "blob",
          "size": 0.6669921875,
          "content": "#!/bin/bash -ex\n\n# on macs, you may need to:\n# export GOBUILDFLAG=-ldflags -linkmode=external\n\necho \"Running unit tests\"\ngo test -race\n\necho \"Testing against postgres\"\nexport GORP_TEST_DSN=\"host=postgres user=gorptest password=gorptest dbname=gorptest sslmode=disable\"\nexport GORP_TEST_DIALECT=postgres\ngo test -tags integration $GOBUILDFLAG $@ .\n\necho \"Testing against sqlite\"\nexport GORP_TEST_DSN=/tmp/gorptest.bin\nexport GORP_TEST_DIALECT=sqlite\ngo test -tags integration $GOBUILDFLAG $@ .\nrm -f /tmp/gorptest.bin\n\necho \"Testing against mysql\"\nexport GORP_TEST_DSN=\"gorptest:gorptest@tcp(mysql)/gorptest\"\nexport GORP_TEST_DIALECT=mysql\ngo test -tags integration $GOBUILDFLAG $@ .\n"
        },
        {
          "name": "transaction.go",
          "type": "blob",
          "size": 6.8974609375,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage gorp\n\nimport (\n\t\"context\"\n\t\"database/sql\"\n\t\"time\"\n)\n\n// Transaction represents a database transaction.\n// Insert/Update/Delete/Get/Exec operations will be run in the context\n// of that transaction.  Transactions should be terminated with\n// a call to Commit() or Rollback()\ntype Transaction struct {\n\tctx    context.Context\n\tdbmap  *DbMap\n\ttx     *sql.Tx\n\tclosed bool\n}\n\nfunc (t *Transaction) WithContext(ctx context.Context) SqlExecutor {\n\tcopy := &Transaction{}\n\t*copy = *t\n\tcopy.ctx = ctx\n\treturn copy\n}\n\n// Insert has the same behavior as DbMap.Insert(), but runs in a transaction.\nfunc (t *Transaction) Insert(list ...interface{}) error {\n\treturn insert(t.dbmap, t, list...)\n}\n\n// Update had the same behavior as DbMap.Update(), but runs in a transaction.\nfunc (t *Transaction) Update(list ...interface{}) (int64, error) {\n\treturn update(t.dbmap, t, nil, list...)\n}\n\n// UpdateColumns had the same behavior as DbMap.UpdateColumns(), but runs in a transaction.\nfunc (t *Transaction) UpdateColumns(filter ColumnFilter, list ...interface{}) (int64, error) {\n\treturn update(t.dbmap, t, filter, list...)\n}\n\n// Delete has the same behavior as DbMap.Delete(), but runs in a transaction.\nfunc (t *Transaction) Delete(list ...interface{}) (int64, error) {\n\treturn delete(t.dbmap, t, list...)\n}\n\n// Get has the same behavior as DbMap.Get(), but runs in a transaction.\nfunc (t *Transaction) Get(i interface{}, keys ...interface{}) (interface{}, error) {\n\treturn get(t.dbmap, t, i, keys...)\n}\n\n// Select has the same behavior as DbMap.Select(), but runs in a transaction.\nfunc (t *Transaction) Select(i interface{}, query string, args ...interface{}) ([]interface{}, error) {\n\tif t.dbmap.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\treturn hookedselect(t.dbmap, t, i, query, args...)\n}\n\n// Exec has the same behavior as DbMap.Exec(), but runs in a transaction.\nfunc (t *Transaction) Exec(query string, args ...interface{}) (sql.Result, error) {\n\tif t.dbmap.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\tif t.dbmap.logger != nil {\n\t\tnow := time.Now()\n\t\tdefer t.dbmap.trace(now, query, args...)\n\t}\n\treturn maybeExpandNamedQueryAndExec(t, query, args...)\n}\n\n// SelectInt is a convenience wrapper around the gorp.SelectInt function.\nfunc (t *Transaction) SelectInt(query string, args ...interface{}) (int64, error) {\n\tif t.dbmap.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\treturn SelectInt(t, query, args...)\n}\n\n// SelectNullInt is a convenience wrapper around the gorp.SelectNullInt function.\nfunc (t *Transaction) SelectNullInt(query string, args ...interface{}) (sql.NullInt64, error) {\n\tif t.dbmap.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\treturn SelectNullInt(t, query, args...)\n}\n\n// SelectFloat is a convenience wrapper around the gorp.SelectFloat function.\nfunc (t *Transaction) SelectFloat(query string, args ...interface{}) (float64, error) {\n\tif t.dbmap.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\treturn SelectFloat(t, query, args...)\n}\n\n// SelectNullFloat is a convenience wrapper around the gorp.SelectNullFloat function.\nfunc (t *Transaction) SelectNullFloat(query string, args ...interface{}) (sql.NullFloat64, error) {\n\tif t.dbmap.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\treturn SelectNullFloat(t, query, args...)\n}\n\n// SelectStr is a convenience wrapper around the gorp.SelectStr function.\nfunc (t *Transaction) SelectStr(query string, args ...interface{}) (string, error) {\n\tif t.dbmap.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\treturn SelectStr(t, query, args...)\n}\n\n// SelectNullStr is a convenience wrapper around the gorp.SelectNullStr function.\nfunc (t *Transaction) SelectNullStr(query string, args ...interface{}) (sql.NullString, error) {\n\tif t.dbmap.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\treturn SelectNullStr(t, query, args...)\n}\n\n// SelectOne is a convenience wrapper around the gorp.SelectOne function.\nfunc (t *Transaction) SelectOne(holder interface{}, query string, args ...interface{}) error {\n\tif t.dbmap.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\treturn SelectOne(t.dbmap, t, holder, query, args...)\n}\n\n// Commit commits the underlying database transaction.\nfunc (t *Transaction) Commit() error {\n\tif !t.closed {\n\t\tt.closed = true\n\t\tif t.dbmap.logger != nil {\n\t\t\tnow := time.Now()\n\t\t\tdefer t.dbmap.trace(now, \"commit;\")\n\t\t}\n\t\treturn t.tx.Commit()\n\t}\n\n\treturn sql.ErrTxDone\n}\n\n// Rollback rolls back the underlying database transaction.\nfunc (t *Transaction) Rollback() error {\n\tif !t.closed {\n\t\tt.closed = true\n\t\tif t.dbmap.logger != nil {\n\t\t\tnow := time.Now()\n\t\t\tdefer t.dbmap.trace(now, \"rollback;\")\n\t\t}\n\t\treturn t.tx.Rollback()\n\t}\n\n\treturn sql.ErrTxDone\n}\n\n// Savepoint creates a savepoint with the given name. The name is interpolated\n// directly into the SQL SAVEPOINT statement, so you must sanitize it if it is\n// derived from user input.\nfunc (t *Transaction) Savepoint(name string) error {\n\tquery := \"savepoint \" + t.dbmap.Dialect.QuoteField(name)\n\tif t.dbmap.logger != nil {\n\t\tnow := time.Now()\n\t\tdefer t.dbmap.trace(now, query, nil)\n\t}\n\t_, err := exec(t, query)\n\treturn err\n}\n\n// RollbackToSavepoint rolls back to the savepoint with the given name. The\n// name is interpolated directly into the SQL SAVEPOINT statement, so you must\n// sanitize it if it is derived from user input.\nfunc (t *Transaction) RollbackToSavepoint(savepoint string) error {\n\tquery := \"rollback to savepoint \" + t.dbmap.Dialect.QuoteField(savepoint)\n\tif t.dbmap.logger != nil {\n\t\tnow := time.Now()\n\t\tdefer t.dbmap.trace(now, query, nil)\n\t}\n\t_, err := exec(t, query)\n\treturn err\n}\n\n// ReleaseSavepint releases the savepoint with the given name. The name is\n// interpolated directly into the SQL SAVEPOINT statement, so you must sanitize\n// it if it is derived from user input.\nfunc (t *Transaction) ReleaseSavepoint(savepoint string) error {\n\tquery := \"release savepoint \" + t.dbmap.Dialect.QuoteField(savepoint)\n\tif t.dbmap.logger != nil {\n\t\tnow := time.Now()\n\t\tdefer t.dbmap.trace(now, query, nil)\n\t}\n\t_, err := exec(t, query)\n\treturn err\n}\n\n// Prepare has the same behavior as DbMap.Prepare(), but runs in a transaction.\nfunc (t *Transaction) Prepare(query string) (*sql.Stmt, error) {\n\tif t.dbmap.logger != nil {\n\t\tnow := time.Now()\n\t\tdefer t.dbmap.trace(now, query, nil)\n\t}\n\treturn prepare(t, query)\n}\n\nfunc (t *Transaction) QueryRow(query string, args ...interface{}) *sql.Row {\n\tif t.dbmap.ExpandSliceArgs {\n\t\texpandSliceArgs(&query, args...)\n\t}\n\n\tif t.dbmap.logger != nil {\n\t\tnow := time.Now()\n\t\tdefer t.dbmap.trace(now, query, args...)\n\t}\n\treturn queryRow(t, query, args...)\n}\n\nfunc (t *Transaction) Query(q string, args ...interface{}) (*sql.Rows, error) {\n\tif t.dbmap.ExpandSliceArgs {\n\t\texpandSliceArgs(&q, args...)\n\t}\n\n\tif t.dbmap.logger != nil {\n\t\tnow := time.Now()\n\t\tdefer t.dbmap.trace(now, q, args...)\n\t}\n\treturn query(t, q, args...)\n}\n"
        },
        {
          "name": "transaction_test.go",
          "type": "blob",
          "size": 7.2578125,
          "content": "// Copyright 2012 James Cooper. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\n// +build integration\n\npackage gorp_test\n\nimport \"testing\"\n\nfunc TestTransaction_Select_expandSliceArgs(t *testing.T) {\n\ttests := []struct {\n\t\tdescription string\n\t\tquery       string\n\t\targs        []interface{}\n\t\twantLen     int\n\t}{\n\t\t{\n\t\t\tdescription: \"it should handle slice placeholders correctly\",\n\t\t\tquery: `\nSELECT 1 FROM crazy_table\nWHERE field1 = :Field1\nAND field2 IN (:FieldStringList)\nAND field3 IN (:FieldUIntList)\nAND field4 IN (:FieldUInt8List)\nAND field5 IN (:FieldUInt16List)\nAND field6 IN (:FieldUInt32List)\nAND field7 IN (:FieldUInt64List)\nAND field8 IN (:FieldIntList)\nAND field9 IN (:FieldInt8List)\nAND field10 IN (:FieldInt16List)\nAND field11 IN (:FieldInt32List)\nAND field12 IN (:FieldInt64List)\nAND field13 IN (:FieldFloat32List)\nAND field14 IN (:FieldFloat64List)\n`,\n\t\t\targs: []interface{}{\n\t\t\t\tmap[string]interface{}{\n\t\t\t\t\t\"Field1\":           123,\n\t\t\t\t\t\"FieldStringList\":  []string{\"h\", \"e\", \"y\"},\n\t\t\t\t\t\"FieldUIntList\":    []uint{1, 2, 3, 4},\n\t\t\t\t\t\"FieldUInt8List\":   []uint8{1, 2, 3, 4},\n\t\t\t\t\t\"FieldUInt16List\":  []uint16{1, 2, 3, 4},\n\t\t\t\t\t\"FieldUInt32List\":  []uint32{1, 2, 3, 4},\n\t\t\t\t\t\"FieldUInt64List\":  []uint64{1, 2, 3, 4},\n\t\t\t\t\t\"FieldIntList\":     []int{1, 2, 3, 4},\n\t\t\t\t\t\"FieldInt8List\":    []int8{1, 2, 3, 4},\n\t\t\t\t\t\"FieldInt16List\":   []int16{1, 2, 3, 4},\n\t\t\t\t\t\"FieldInt32List\":   []int32{1, 2, 3, 4},\n\t\t\t\t\t\"FieldInt64List\":   []int64{1, 2, 3, 4},\n\t\t\t\t\t\"FieldFloat32List\": []float32{1, 2, 3, 4},\n\t\t\t\t\t\"FieldFloat64List\": []float64{1, 2, 3, 4},\n\t\t\t\t},\n\t\t\t},\n\t\t\twantLen: 1,\n\t\t},\n\t\t{\n\t\t\tdescription: \"it should handle slice placeholders correctly with custom types\",\n\t\t\tquery: `\nSELECT 1 FROM crazy_table\nWHERE field2 IN (:FieldStringList)\nAND field12 IN (:FieldIntList)\n`,\n\t\t\targs: []interface{}{\n\t\t\t\tmap[string]interface{}{\n\t\t\t\t\t\"FieldStringList\": customType1{\"h\", \"e\", \"y\"},\n\t\t\t\t\t\"FieldIntList\":    customType2{1, 2, 3, 4},\n\t\t\t\t},\n\t\t\t},\n\t\t\twantLen: 3,\n\t\t},\n\t}\n\n\ttype dataFormat struct {\n\t\tField1  int     `db:\"field1\"`\n\t\tField2  string  `db:\"field2\"`\n\t\tField3  uint    `db:\"field3\"`\n\t\tField4  uint8   `db:\"field4\"`\n\t\tField5  uint16  `db:\"field5\"`\n\t\tField6  uint32  `db:\"field6\"`\n\t\tField7  uint64  `db:\"field7\"`\n\t\tField8  int     `db:\"field8\"`\n\t\tField9  int8    `db:\"field9\"`\n\t\tField10 int16   `db:\"field10\"`\n\t\tField11 int32   `db:\"field11\"`\n\t\tField12 int64   `db:\"field12\"`\n\t\tField13 float32 `db:\"field13\"`\n\t\tField14 float64 `db:\"field14\"`\n\t}\n\n\tdbmap := newDBMap(t)\n\tdbmap.ExpandSliceArgs = true\n\tdbmap.AddTableWithName(dataFormat{}, \"crazy_table\")\n\n\terr := dbmap.CreateTables()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer dropAndClose(dbmap)\n\n\terr = dbmap.Insert(\n\t\t&dataFormat{\n\t\t\tField1:  123,\n\t\t\tField2:  \"h\",\n\t\t\tField3:  1,\n\t\t\tField4:  1,\n\t\t\tField5:  1,\n\t\t\tField6:  1,\n\t\t\tField7:  1,\n\t\t\tField8:  1,\n\t\t\tField9:  1,\n\t\t\tField10: 1,\n\t\t\tField11: 1,\n\t\t\tField12: 1,\n\t\t\tField13: 1,\n\t\t\tField14: 1,\n\t\t},\n\t\t&dataFormat{\n\t\t\tField1:  124,\n\t\t\tField2:  \"e\",\n\t\t\tField3:  2,\n\t\t\tField4:  2,\n\t\t\tField5:  2,\n\t\t\tField6:  2,\n\t\t\tField7:  2,\n\t\t\tField8:  2,\n\t\t\tField9:  2,\n\t\t\tField10: 2,\n\t\t\tField11: 2,\n\t\t\tField12: 2,\n\t\t\tField13: 2,\n\t\t\tField14: 2,\n\t\t},\n\t\t&dataFormat{\n\t\t\tField1:  125,\n\t\t\tField2:  \"y\",\n\t\t\tField3:  3,\n\t\t\tField4:  3,\n\t\t\tField5:  3,\n\t\t\tField6:  3,\n\t\t\tField7:  3,\n\t\t\tField8:  3,\n\t\t\tField9:  3,\n\t\t\tField10: 3,\n\t\t\tField11: 3,\n\t\t\tField12: 3,\n\t\t\tField13: 3,\n\t\t\tField14: 3,\n\t\t},\n\t)\n\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.description, func(t *testing.T) {\n\t\t\ttx, err := dbmap.Begin()\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tdefer tx.Rollback()\n\n\t\t\tvar dummy []int\n\t\t\t_, err = tx.Select(&dummy, tt.query, tt.args...)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\tif len(dummy) != tt.wantLen {\n\t\t\t\tt.Errorf(\"wrong result count\\ngot:  %d\\nwant: %d\", len(dummy), tt.wantLen)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestTransaction_Exec_expandSliceArgs(t *testing.T) {\n\ttests := []struct {\n\t\tdescription string\n\t\tquery       string\n\t\targs        []interface{}\n\t\twantLen     int\n\t}{\n\t\t{\n\t\t\tdescription: \"it should handle slice placeholders correctly\",\n\t\t\tquery: `\nDELETE FROM crazy_table\nWHERE field1 = :Field1\nAND field2 IN (:FieldStringList)\nAND field3 IN (:FieldUIntList)\nAND field4 IN (:FieldUInt8List)\nAND field5 IN (:FieldUInt16List)\nAND field6 IN (:FieldUInt32List)\nAND field7 IN (:FieldUInt64List)\nAND field8 IN (:FieldIntList)\nAND field9 IN (:FieldInt8List)\nAND field10 IN (:FieldInt16List)\nAND field11 IN (:FieldInt32List)\nAND field12 IN (:FieldInt64List)\nAND field13 IN (:FieldFloat32List)\nAND field14 IN (:FieldFloat64List)\n`,\n\t\t\targs: []interface{}{\n\t\t\t\tmap[string]interface{}{\n\t\t\t\t\t\"Field1\":           123,\n\t\t\t\t\t\"FieldStringList\":  []string{\"h\", \"e\", \"y\"},\n\t\t\t\t\t\"FieldUIntList\":    []uint{1, 2, 3, 4},\n\t\t\t\t\t\"FieldUInt8List\":   []uint8{1, 2, 3, 4},\n\t\t\t\t\t\"FieldUInt16List\":  []uint16{1, 2, 3, 4},\n\t\t\t\t\t\"FieldUInt32List\":  []uint32{1, 2, 3, 4},\n\t\t\t\t\t\"FieldUInt64List\":  []uint64{1, 2, 3, 4},\n\t\t\t\t\t\"FieldIntList\":     []int{1, 2, 3, 4},\n\t\t\t\t\t\"FieldInt8List\":    []int8{1, 2, 3, 4},\n\t\t\t\t\t\"FieldInt16List\":   []int16{1, 2, 3, 4},\n\t\t\t\t\t\"FieldInt32List\":   []int32{1, 2, 3, 4},\n\t\t\t\t\t\"FieldInt64List\":   []int64{1, 2, 3, 4},\n\t\t\t\t\t\"FieldFloat32List\": []float32{1, 2, 3, 4},\n\t\t\t\t\t\"FieldFloat64List\": []float64{1, 2, 3, 4},\n\t\t\t\t},\n\t\t\t},\n\t\t\twantLen: 1,\n\t\t},\n\t\t{\n\t\t\tdescription: \"it should handle slice placeholders correctly with custom types\",\n\t\t\tquery: `\nDELETE FROM crazy_table\nWHERE field2 IN (:FieldStringList)\nAND field12 IN (:FieldIntList)\n`,\n\t\t\targs: []interface{}{\n\t\t\t\tmap[string]interface{}{\n\t\t\t\t\t\"FieldStringList\": customType1{\"h\", \"e\", \"y\"},\n\t\t\t\t\t\"FieldIntList\":    customType2{1, 2, 3, 4},\n\t\t\t\t},\n\t\t\t},\n\t\t\twantLen: 3,\n\t\t},\n\t}\n\n\ttype dataFormat struct {\n\t\tField1  int     `db:\"field1\"`\n\t\tField2  string  `db:\"field2\"`\n\t\tField3  uint    `db:\"field3\"`\n\t\tField4  uint8   `db:\"field4\"`\n\t\tField5  uint16  `db:\"field5\"`\n\t\tField6  uint32  `db:\"field6\"`\n\t\tField7  uint64  `db:\"field7\"`\n\t\tField8  int     `db:\"field8\"`\n\t\tField9  int8    `db:\"field9\"`\n\t\tField10 int16   `db:\"field10\"`\n\t\tField11 int32   `db:\"field11\"`\n\t\tField12 int64   `db:\"field12\"`\n\t\tField13 float32 `db:\"field13\"`\n\t\tField14 float64 `db:\"field14\"`\n\t}\n\n\tdbmap := newDBMap(t)\n\tdbmap.ExpandSliceArgs = true\n\tdbmap.AddTableWithName(dataFormat{}, \"crazy_table\")\n\n\terr := dbmap.CreateTables()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer dropAndClose(dbmap)\n\n\terr = dbmap.Insert(\n\t\t&dataFormat{\n\t\t\tField1:  123,\n\t\t\tField2:  \"h\",\n\t\t\tField3:  1,\n\t\t\tField4:  1,\n\t\t\tField5:  1,\n\t\t\tField6:  1,\n\t\t\tField7:  1,\n\t\t\tField8:  1,\n\t\t\tField9:  1,\n\t\t\tField10: 1,\n\t\t\tField11: 1,\n\t\t\tField12: 1,\n\t\t\tField13: 1,\n\t\t\tField14: 1,\n\t\t},\n\t\t&dataFormat{\n\t\t\tField1:  124,\n\t\t\tField2:  \"e\",\n\t\t\tField3:  2,\n\t\t\tField4:  2,\n\t\t\tField5:  2,\n\t\t\tField6:  2,\n\t\t\tField7:  2,\n\t\t\tField8:  2,\n\t\t\tField9:  2,\n\t\t\tField10: 2,\n\t\t\tField11: 2,\n\t\t\tField12: 2,\n\t\t\tField13: 2,\n\t\t\tField14: 2,\n\t\t},\n\t\t&dataFormat{\n\t\t\tField1:  125,\n\t\t\tField2:  \"y\",\n\t\t\tField3:  3,\n\t\t\tField4:  3,\n\t\t\tField5:  3,\n\t\t\tField6:  3,\n\t\t\tField7:  3,\n\t\t\tField8:  3,\n\t\t\tField9:  3,\n\t\t\tField10: 3,\n\t\t\tField11: 3,\n\t\t\tField12: 3,\n\t\t\tField13: 3,\n\t\t\tField14: 3,\n\t\t},\n\t)\n\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.description, func(t *testing.T) {\n\t\t\ttx, err := dbmap.Begin()\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tdefer tx.Rollback()\n\n\t\t\t_, err = tx.Exec(tt.query, tt.args...)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t})\n\t}\n}\n"
        }
      ]
    }
  ]
}