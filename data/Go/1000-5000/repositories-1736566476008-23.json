{
  "metadata": {
    "timestamp": 1736566476008,
    "page": 23,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "src-d/go-git",
      "stars": 4895,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0400390625,
          "content": "coverage.out\n*~\ncoverage.txt\nprofile.out\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.6162109375,
          "content": "language: go\n\ngo:\n  - \"1.11\"\n  - \"1.12\"\n\ngo_import_path: gopkg.in/src-d/go-git.v4\n\nenv:\n  - GIT_VERSION=master\n  - GIT_VERSION=v1.9.3\n  - GIT_VERSION=v2.11.0\n\ncache:\n  directories:\n  - $HOME/.git-dist\n\nbefore_script:\n  - export GIT_DIST_PATH=$HOME/.git-dist\n  - make build-git\n\nbefore_install:\n  - git config --global user.email \"travis@example.com\"\n  - git config --global user.name \"Travis CI\"\n\ninstall:\n  - go get -v -t ./...\n\nscript:\n  - export GIT_EXEC_PATH=$GIT_DIST_PATH\n  - export PATH=$GIT_DIST_PATH:$PATH\n  - git version\n  - make test-coverage\n  - go vet ./...\n\nafter_success:\n  - bash <(curl -s https://codecov.io/bash)\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.1533203125,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to making participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, gender identity and expression, level of experience,\neducation, socio-economic status, nationality, personal appearance, race,\nreligion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n  advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n  address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces\nwhen an individual is representing the project or its community. Examples of\nrepresenting a project or community include using an official project e-mail\naddress, posting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event. Representation of a project may be\nfurther defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at conduct@sourced.tech. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\n"
        },
        {
          "name": "COMPATIBILITY.md",
          "type": "blob",
          "size": 5.4345703125,
          "content": "Supported Capabilities\n======================\n\nHere is a non-comprehensive table of git commands and features whose equivalent\nis supported by go-git.\n\n| Feature                               | Status | Notes |\n|---------------------------------------|--------|-------|\n| **config**                            |\n| config                                | ✔ | Reading and modifying per-repository configuration (`.git/config`) is supported. Global configuration (`$HOME/.gitconfig`) is not. |\n| **getting and creating repositories** |\n| init                                  | ✔ | Plain init and `--bare` are supported. Flags `--template`, `--separate-git-dir` and `--shared` are not. |\n| clone                                 | ✔ | Plain clone and equivalents to `--progress`,  `--single-branch`, `--depth`, `--origin`, `--recurse-submodules` are supported. Others are not. |\n| **basic snapshotting** |\n| add                                   | ✔ | Plain add is supported. Any other flags aren't supported |\n| status                                | ✔ |\n| commit                                | ✔ |\n| reset                                 | ✔ |\n| rm                                    | ✔ |\n| mv                                    | ✔ |\n| **branching and merging** |\n| branch                                | ✔ |\n| checkout                              | ✔ | Basic usages of checkout are supported. |\n| merge                                 | ✖ |\n| mergetool                             | ✖ |\n| stash                                 | ✖ |\n| tag                                   | ✔ |\n| **sharing and updating projects** |\n| fetch                                 | ✔ |\n| pull                                  | ✔ | Only supports merges where the merge can be resolved as a fast-forward. |\n| push                                  | ✔ |\n| remote                                | ✔ |\n| submodule                             | ✔ |\n| **inspection and comparison** |\n| show                                  | ✔ |\n| log                                   | ✔ |\n| shortlog                              | (see log) |\n| describe                              | |\n| **patching** |\n| apply                                 | ✖ |\n| cherry-pick                           | ✖ |\n| diff                                  | ✔ | Patch object with UnifiedDiff output representation |\n| rebase                                | ✖ |\n| revert                                | ✖ |\n| **debugging** |\n| bisect                                | ✖ |\n| blame                                 | ✔ |\n| grep                                  | ✔ |\n| **email** ||\n| am                                    | ✖ |\n| apply                                 | ✖ |\n| format-patch                          | ✖ |\n| send-email                            | ✖ |\n| request-pull                          | ✖ |\n| **external systems** |\n| svn                                   | ✖ |\n| fast-import                           | ✖ |\n| **administration** |\n| clean                                 | ✔ |\n| gc                                    | ✖ |\n| fsck                                  | ✖ |\n| reflog                                | ✖ |\n| filter-branch                         | ✖ |\n| instaweb                              | ✖ |\n| archive                               | ✖ |\n| bundle                                | ✖ |\n| prune                                 | ✖ |\n| repack                                | ✖ |\n| **server admin** |\n| daemon                                | |\n| update-server-info                    | |\n| **advanced** |\n| notes                                 | ✖ |\n| replace                               | ✖ |\n| worktree                              | ✖ |\n| annotate                              | (see blame) |\n| **gpg** |\n| git-verify-commit                     | ✔ |\n| git-verify-tag                        | ✔ |\n| **plumbing commands** |\n| cat-file                              | ✔ |\n| check-ignore                          | |\n| commit-tree                           | |\n| count-objects                         | |\n| diff-index                            | |\n| for-each-ref                          | ✔ |\n| hash-object                           | ✔ |\n| ls-files                              | ✔ |\n| merge-base                            | ✔ | Calculates the merge-base only between two commits, and supports `--independent` and `--is-ancestor` modifiers; Does not support `--fork-point` nor `--octopus` modifiers. |\n| read-tree                             | |\n| rev-list                              | ✔ |\n| rev-parse                             | |\n| show-ref                              | ✔ |\n| symbolic-ref                          | ✔ |\n| update-index                          | |\n| update-ref                            | |\n| verify-pack                           | |\n| write-tree                            | |\n| **protocols** |\n| http(s):// (dumb)                     | ✖ |\n| http(s):// (smart)                    | ✔ |\n| git://                                | ✔ |\n| ssh://                                | ✔ |\n| file://                               | ✔ |\n| custom                                | ✔ |\n| **other features** |\n| gitignore                             | ✔ |\n| gitattributes                         | ✖ |\n| index version                         | |\n| packfile version                      | |\n| push-certs                            | ✖ |\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 3.1884765625,
          "content": "# Contributing Guidelines\n\nsource{d} go-git project is [Apache 2.0 licensed](LICENSE) and accepts\ncontributions via GitHub pull requests.  This document outlines some of the\nconventions on development workflow, commit message formatting, contact points,\nand other resources to make it easier to get your contribution accepted.\n\n## Certificate of Origin\n\nBy contributing to this project you agree to the [Developer Certificate of\nOrigin (DCO)](DCO). This document was created by the Linux Kernel community and is a\nsimple statement that you, as a contributor, have the legal right to make the\ncontribution.\n\nIn order to show your agreement with the DCO you should include at the end of commit message,\nthe following line: `Signed-off-by: John Doe <john.doe@example.com>`, using your real name.\n\nThis can be done easily using the [`-s`](https://github.com/git/git/blob/b2c150d3aa82f6583b9aadfecc5f8fa1c74aca09/Documentation/git-commit.txt#L154-L161) flag on the `git commit`.\n\n## Support Channels\n\nThe official support channels, for both users and contributors, are:\n\n- [StackOverflow go-git tag](https://stackoverflow.com/questions/tagged/go-git) for user questions.\n- GitHub [Issues](https://github.com/src-d/go-git/issues)* for bug reports and feature requests.\n- Slack: #go-git room in the [source{d} Slack](https://join.slack.com/t/sourced-community/shared_invite/enQtMjc4Njk5MzEyNzM2LTFjNzY4NjEwZGEwMzRiNTM4MzRlMzQ4MmIzZjkwZmZlM2NjODUxZmJjNDI1OTcxNDAyMmZlNmFjODZlNTg0YWM)\n\n*Before opening a new issue or submitting a new pull request, it's helpful to\nsearch the project - it's likely that another user has already reported the\nissue you're facing, or it's a known issue that we're already aware of.\n\n\n## How to Contribute\n\nPull Requests (PRs) are the main and exclusive way to contribute to the official go-git project.\nIn order for a PR to be accepted it needs to pass a list of requirements:\n\n- You should be able to run the same query using `git`. We don't accept features that are not implemented in the official git implementation.\n- The expected behavior must match the [official git implementation](https://github.com/git/git).\n- The actual behavior must be correctly explained with natural language and providing a minimum working example in Go that reproduces it.\n- All PRs must be written in idiomatic Go, formatted according to [gofmt](https://golang.org/cmd/gofmt/), and without any warnings from [go lint](https://github.com/golang/lint) nor [go vet](https://golang.org/cmd/vet/).\n- They should in general include tests, and those shall pass.\n- If the PR is a bug fix, it has to include a suite of unit tests for the new functionality.\n- If the PR is a new feature, it has to come with a suite of unit tests, that tests the new functionality.\n- In any case, all the PRs have to pass the personal evaluation of at least one of the [maintainers](MAINTAINERS) of go-git.\n\n### Format of the commit message\n\nEvery commit message should describe what was changed, under which context and, if applicable, the GitHub issue it relates to:\n\n```\nplumbing: packp, Skip argument validations for unknown capabilities. Fixes #623\n```\n\nThe format can be described more formally as follows:\n\n```\n<package>: <subpackage>, <what changed>. [Fixes #<issue-number>]\n```\n"
        },
        {
          "name": "DCO",
          "type": "blob",
          "size": 1.3876953125,
          "content": "Developer Certificate of Origin\nVersion 1.1\n\nCopyright (C) 2004, 2006 The Linux Foundation and its contributors.\n660 York Street, Suite 102,\nSan Francisco, CA 94110 USA\n\nEveryone is permitted to copy and distribute verbatim copies of this\nlicense document, but changing it is not allowed.\n\n\nDeveloper's Certificate of Origin 1.1\n\nBy making a contribution to this project, I certify that:\n\n(a) The contribution was created in whole or in part by me and I\n    have the right to submit it under the open source license\n    indicated in the file; or\n\n(b) The contribution is based upon previous work that, to the best\n    of my knowledge, is covered under an appropriate open source\n    license and I have the right under that license to submit that\n    work with modifications, whether created in whole or in part\n    by me, under the same open source license (unless I am\n    permitted to submit under a different license), as indicated\n    in the file; or\n\n(c) The contribution was provided directly to me by some other\n    person who certified (a), (b) or (c) and I have not modified\n    it.\n\n(d) I understand and agree that this project and the contribution\n    are public and that a record of the contribution (including all\n    personal information I submit with it, including my sign-off) is\n    maintained indefinitely and may be redistributed consistent with\n    this project or the open source license(s) involved."
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.08984375,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"{}\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2018 Sourced Technologies, S.L.\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MAINTAINERS",
          "type": "blob",
          "size": 0.14453125,
          "content": "Máximo Cuadros <mcuadros@gmail.com> (@mcuadros)\nJeremy Stribling <strib@alum.mit.edu> (@strib)\nOri Rawlings <orirawlings@gmail.com> (@orirawlings)\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.8544921875,
          "content": "# General\nWORKDIR = $(PWD)\n\n# Go parameters\nGOCMD = go\nGOTEST = $(GOCMD) test -v\n\n# Git config\nGIT_VERSION ?=\nGIT_DIST_PATH ?= $(PWD)/.git-dist\nGIT_REPOSITORY = http://github.com/git/git.git\n\n# Coverage\nCOVERAGE_REPORT = coverage.txt\nCOVERAGE_MODE = atomic\n\nifneq ($(origin CI), undefined)\n\tWORKDIR := $(GOPATH)/src/gopkg.in/src-d/go-git.v4\nendif\n\nbuild-git:\n\t@if [ -f $(GIT_DIST_PATH)/git ]; then \\\n\t\techo \"nothing to do, using cache $(GIT_DIST_PATH)\"; \\\n\telse \\\n\t\tgit clone $(GIT_REPOSITORY) -b $(GIT_VERSION) --depth 1 --single-branch $(GIT_DIST_PATH); \\\n\t\tcd $(GIT_DIST_PATH); \\\n\t\tmake configure; \\\n\t\t./configure; \\\n\t\tmake all; \\\n\tfi\n\ntest:\n\t@cd $(WORKDIR); \\\n\t$(GOTEST) ./...\n\ntest-coverage:\n\t@cd $(WORKDIR); \\\n\techo \"\" > $(COVERAGE_REPORT); \\\n\t$(GOTEST) -coverprofile=$(COVERAGE_REPORT) -coverpkg=./... -covermode=$(COVERAGE_MODE) ./...\n\nclean:\n\trm -rf $(GIT_DIST_PATH)"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 4.73828125,
          "content": "## WE CONTINUE THE DEVELOPMENT AT [go-git/go-git](https://github.com/go-git/go-git). This repository is abandoned, and no further updates will be done on the code base, nor issue/prs will be answered or attended.\n\n![go-git logo](https://cdn.rawgit.com/src-d/artwork/02036484/go-git/files/go-git-github-readme-header.png)\n[![GoDoc](https://godoc.org/gopkg.in/src-d/go-git.v4?status.svg)](https://godoc.org/github.com/src-d/go-git) [![Build Status](https://travis-ci.org/src-d/go-git.svg)](https://travis-ci.org/src-d/go-git) [![Build status](https://ci.appveyor.com/api/projects/status/nyidskwifo4py6ub?svg=true)](https://ci.appveyor.com/project/mcuadros/go-git) [![codecov.io](https://codecov.io/github/src-d/go-git/coverage.svg)](https://codecov.io/github/src-d/go-git) [![Go Report Card](https://goreportcard.com/badge/github.com/src-d/go-git)](https://goreportcard.com/report/github.com/src-d/go-git)\n\n*go-git* is a highly extensible git implementation library written in **pure Go**.\n\nIt can be used to manipulate git repositories at low level *(plumbing)* or high level *(porcelain)*, through an idiomatic Go API. It also supports several types of storage, such as in-memory filesystems, or custom implementations thanks to the [`Storer`](https://godoc.org/gopkg.in/src-d/go-git.v4/plumbing/storer) interface.\n\nIt's being actively developed since 2015 and is being used extensively by [source{d}](https://sourced.tech/) and [Keybase](https://keybase.io/blog/encrypted-git-for-everyone), and by many other libraries and tools.\n\nComparison with git\n-------------------\n\n*go-git* aims to be fully compatible with [git](https://github.com/git/git), all the *porcelain* operations are implemented to work exactly as *git* does.\n\n*git* is a humongous project with years of development by thousands of contributors, making it challenging for *go-git* to implement all the features. You can find a comparison of *go-git* vs *git* in the [compatibility documentation](COMPATIBILITY.md).\n\n\nInstallation\n------------\n\nThe recommended way to install *go-git* is:\n\n```\ngo get -u gopkg.in/src-d/go-git.v4/...\n```\n\n> We use [gopkg.in](http://labix.org/gopkg.in) to version the API, this means that when `go get` clones the package, it's the latest tag matching `v4.*` that is cloned and not the master branch.\n\nExamples\n--------\n\n> Please note that the `CheckIfError` and `Info` functions  used in the examples are from the [examples package](https://github.com/src-d/go-git/blob/master/_examples/common.go#L17) just to be used in the examples.\n\n\n### Basic example\n\nA basic example that mimics the standard `git clone` command\n\n```go\n// Clone the given repository to the given directory\nInfo(\"git clone https://github.com/src-d/go-git\")\n\n_, err := git.PlainClone(\"/tmp/foo\", false, &git.CloneOptions{\n    URL:      \"https://github.com/src-d/go-git\",\n    Progress: os.Stdout,\n})\n\nCheckIfError(err)\n```\n\nOutputs:\n```\nCounting objects: 4924, done.\nCompressing objects: 100% (1333/1333), done.\nTotal 4924 (delta 530), reused 6 (delta 6), pack-reused 3533\n```\n\n### In-memory example\n\nCloning a repository into memory and printing the history of HEAD, just like `git log` does\n\n\n```go\n// Clones the given repository in memory, creating the remote, the local\n// branches and fetching the objects, exactly as:\nInfo(\"git clone https://github.com/src-d/go-siva\")\n\nr, err := git.Clone(memory.NewStorage(), nil, &git.CloneOptions{\n    URL: \"https://github.com/src-d/go-siva\",\n})\n\nCheckIfError(err)\n\n// Gets the HEAD history from HEAD, just like this command:\nInfo(\"git log\")\n\n// ... retrieves the branch pointed by HEAD\nref, err := r.Head()\nCheckIfError(err)\n\n\n// ... retrieves the commit history\ncIter, err := r.Log(&git.LogOptions{From: ref.Hash()})\nCheckIfError(err)\n\n// ... just iterates over the commits, printing it\nerr = cIter.ForEach(func(c *object.Commit) error {\n\tfmt.Println(c)\n\treturn nil\n})\nCheckIfError(err)\n```\n\nOutputs:\n```\ncommit ded8054fd0c3994453e9c8aacaf48d118d42991e\nAuthor: Santiago M. Mola <santi@mola.io>\nDate:   Sat Nov 12 21:18:41 2016 +0100\n\n    index: ReadFrom/WriteTo returns IndexReadError/IndexWriteError. (#9)\n\ncommit df707095626f384ce2dc1a83b30f9a21d69b9dfc\nAuthor: Santiago M. Mola <santi@mola.io>\nDate:   Fri Nov 11 13:23:22 2016 +0100\n\n    readwriter: fix bug when writing index. (#10)\n\n    When using ReadWriter on an existing siva file, absolute offset for\n    index entries was not being calculated correctly.\n...\n```\n\nYou can find this [example](_examples/log/main.go) and many others in the [examples](_examples) folder.\n\nContribute\n----------\n\n[Contributions](https://github.com/src-d/go-git/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22) are more than welcome, if you are interested please take a look to\nour [Contributing Guidelines](CONTRIBUTING.md).\n\nLicense\n-------\nApache License Version 2.0, see [LICENSE](LICENSE)\n"
        },
        {
          "name": "_examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "appveyor.yml",
          "type": "blob",
          "size": 0.4248046875,
          "content": "version: \"{build}\"\nplatform: x64\n\nmatrix:\n  allow_failures:\n    - platform: x64\n    \nclone_folder: c:\\gopath\\src\\gopkg.in\\src-d\\go-git.v4\n\nenvironment:\n  GOPATH: c:\\gopath\n\ninstall:\n  - set PATH=%GOPATH%\\bin;c:\\go\\bin;\"C:\\Program Files\\Git\\mingw64\\bin\";%PATH%\n  - go version\n  - go get -v -t ./...\n  - git config --global user.email \"travis@example.com\"\n  - git config --global user.name \"Travis CI\n\nbuild_script:\n  - go test -v ./...\n"
        },
        {
          "name": "blame.go",
          "type": "blob",
          "size": 8.109375,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\t\"unicode/utf8\"\n\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/object\"\n\t\"gopkg.in/src-d/go-git.v4/utils/diff\"\n)\n\n// BlameResult represents the result of a Blame operation.\ntype BlameResult struct {\n\t// Path is the path of the File that we're blaming.\n\tPath string\n\t// Rev (Revision) is the hash of the specified Commit used to generate this result.\n\tRev plumbing.Hash\n\t// Lines contains every line with its authorship.\n\tLines []*Line\n}\n\n// Blame returns a BlameResult with the information about the last author of\n// each line from file `path` at commit `c`.\nfunc Blame(c *object.Commit, path string) (*BlameResult, error) {\n\t// The file to blame is identified by the input arguments:\n\t// commit and path. commit is a Commit object obtained from a Repository. Path\n\t// represents a path to a specific file contained into the repository.\n\t//\n\t// Blaming a file is a two step process:\n\t//\n\t// 1. Create a linear history of the commits affecting a file. We use\n\t// revlist.New for that.\n\t//\n\t// 2. Then build a graph with a node for every line in every file in\n\t// the history of the file.\n\t//\n\t// Each node is assigned a commit: Start by the nodes in the first\n\t// commit. Assign that commit as the creator of all its lines.\n\t//\n\t// Then jump to the nodes in the next commit, and calculate the diff\n\t// between the two files. Newly created lines get\n\t// assigned the new commit as its origin. Modified lines also get\n\t// this new commit. Untouched lines retain the old commit.\n\t//\n\t// All this work is done in the assignOrigin function which holds all\n\t// the internal relevant data in a \"blame\" struct, that is not\n\t// exported.\n\t//\n\t// TODO: ways to improve the efficiency of this function:\n\t// 1. Improve revlist\n\t// 2. Improve how to traverse the history (example a backward traversal will\n\t// be much more efficient)\n\t//\n\t// TODO: ways to improve the function in general:\n\t// 1. Add memoization between revlist and assign.\n\t// 2. It is using much more memory than needed, see the TODOs below.\n\n\tb := new(blame)\n\tb.fRev = c\n\tb.path = path\n\n\t// get all the file revisions\n\tif err := b.fillRevs(); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// calculate the line tracking graph and fill in\n\t// file contents in data.\n\tif err := b.fillGraphAndData(); err != nil {\n\t\treturn nil, err\n\t}\n\n\tfile, err := b.fRev.File(b.path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfinalLines, err := file.Lines()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Each node (line) holds the commit where it was introduced or\n\t// last modified. To achieve that we use the FORWARD algorithm\n\t// described in Zimmermann, et al. \"Mining Version Archives for\n\t// Co-changed Lines\", in proceedings of the Mining Software\n\t// Repositories workshop, Shanghai, May 22-23, 2006.\n\tlines, err := newLines(finalLines, b.sliceGraph(len(b.graph)-1))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &BlameResult{\n\t\tPath:  path,\n\t\tRev:   c.Hash,\n\t\tLines: lines,\n\t}, nil\n}\n\n// Line values represent the contents and author of a line in BlamedResult values.\ntype Line struct {\n\t// Author is the email address of the last author that modified the line.\n\tAuthor string\n\t// Text is the original text of the line.\n\tText string\n\t// Date is when the original text of the line was introduced\n\tDate time.Time\n\t// Hash is the commit hash that introduced the original line\n\tHash plumbing.Hash\n}\n\nfunc newLine(author, text string, date time.Time, hash plumbing.Hash) *Line {\n\treturn &Line{\n\t\tAuthor: author,\n\t\tText:   text,\n\t\tHash:   hash,\n\t\tDate:   date,\n\t}\n}\n\nfunc newLines(contents []string, commits []*object.Commit) ([]*Line, error) {\n\tlcontents := len(contents)\n\tlcommits := len(commits)\n\n\tif lcontents != lcommits {\n\t\tif lcontents == lcommits-1 && contents[lcontents-1] != \"\\n\" {\n\t\t\tcontents = append(contents, \"\\n\")\n\t\t} else {\n\t\t\treturn nil, errors.New(\"contents and commits have different length\")\n\t\t}\n\t}\n\n\tresult := make([]*Line, 0, lcontents)\n\tfor i := range contents {\n\t\tresult = append(result, newLine(\n\t\t\tcommits[i].Author.Email, contents[i],\n\t\t\tcommits[i].Author.When, commits[i].Hash,\n\t\t))\n\t}\n\n\treturn result, nil\n}\n\n// this struct is internally used by the blame function to hold its\n// inputs, outputs and state.\ntype blame struct {\n\t// the path of the file to blame\n\tpath string\n\t// the commit of the final revision of the file to blame\n\tfRev *object.Commit\n\t// the chain of revisions affecting the the file to blame\n\trevs []*object.Commit\n\t// the contents of the file across all its revisions\n\tdata []string\n\t// the graph of the lines in the file across all the revisions\n\tgraph [][]*object.Commit\n}\n\n// calculate the history of a file \"path\", starting from commit \"from\", sorted by commit date.\nfunc (b *blame) fillRevs() error {\n\tvar err error\n\n\tb.revs, err = references(b.fRev, b.path)\n\treturn err\n}\n\n// build graph of a file from its revision history\nfunc (b *blame) fillGraphAndData() error {\n\t//TODO: not all commits are needed, only the current rev and the prev\n\tb.graph = make([][]*object.Commit, len(b.revs))\n\tb.data = make([]string, len(b.revs)) // file contents in all the revisions\n\t// for every revision of the file, starting with the first\n\t// one...\n\tfor i, rev := range b.revs {\n\t\t// get the contents of the file\n\t\tfile, err := rev.File(b.path)\n\t\tif err != nil {\n\t\t\treturn nil\n\t\t}\n\t\tb.data[i], err = file.Contents()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tnLines := countLines(b.data[i])\n\t\t// create a node for each line\n\t\tb.graph[i] = make([]*object.Commit, nLines)\n\t\t// assign a commit to each node\n\t\t// if this is the first revision, then the node is assigned to\n\t\t// this first commit.\n\t\tif i == 0 {\n\t\t\tfor j := 0; j < nLines; j++ {\n\t\t\t\tb.graph[i][j] = b.revs[i]\n\t\t\t}\n\t\t} else {\n\t\t\t// if this is not the first commit, then assign to the old\n\t\t\t// commit or to the new one, depending on what the diff\n\t\t\t// says.\n\t\t\tb.assignOrigin(i, i-1)\n\t\t}\n\t}\n\treturn nil\n}\n\n// sliceGraph returns a slice of commits (one per line) for a particular\n// revision of a file (0=first revision).\nfunc (b *blame) sliceGraph(i int) []*object.Commit {\n\tfVs := b.graph[i]\n\tresult := make([]*object.Commit, 0, len(fVs))\n\tfor _, v := range fVs {\n\t\tc := *v\n\t\tresult = append(result, &c)\n\t}\n\treturn result\n}\n\n// Assigns origin to vertexes in current (c) rev from data in its previous (p)\n// revision\nfunc (b *blame) assignOrigin(c, p int) {\n\t// assign origin based on diff info\n\thunks := diff.Do(b.data[p], b.data[c])\n\tsl := -1 // source line\n\tdl := -1 // destination line\n\tfor h := range hunks {\n\t\thLines := countLines(hunks[h].Text)\n\t\tfor hl := 0; hl < hLines; hl++ {\n\t\t\tswitch {\n\t\t\tcase hunks[h].Type == 0:\n\t\t\t\tsl++\n\t\t\t\tdl++\n\t\t\t\tb.graph[c][dl] = b.graph[p][sl]\n\t\t\tcase hunks[h].Type == 1:\n\t\t\t\tdl++\n\t\t\t\tb.graph[c][dl] = b.revs[c]\n\t\t\tcase hunks[h].Type == -1:\n\t\t\t\tsl++\n\t\t\tdefault:\n\t\t\t\tpanic(\"unreachable\")\n\t\t\t}\n\t\t}\n\t}\n}\n\n// GoString prints the results of a Blame using git-blame's style.\nfunc (b *blame) GoString() string {\n\tvar buf bytes.Buffer\n\n\tfile, err := b.fRev.File(b.path)\n\tif err != nil {\n\t\tpanic(\"PrettyPrint: internal error in repo.Data\")\n\t}\n\tcontents, err := file.Contents()\n\tif err != nil {\n\t\tpanic(\"PrettyPrint: internal error in repo.Data\")\n\t}\n\n\tlines := strings.Split(contents, \"\\n\")\n\t// max line number length\n\tmlnl := len(strconv.Itoa(len(lines)))\n\t// max author length\n\tmal := b.maxAuthorLength()\n\tformat := fmt.Sprintf(\"%%s (%%-%ds %%%dd) %%s\\n\",\n\t\tmal, mlnl)\n\n\tfVs := b.graph[len(b.graph)-1]\n\tfor ln, v := range fVs {\n\t\tfmt.Fprintf(&buf, format, v.Hash.String()[:8],\n\t\t\tprettyPrintAuthor(fVs[ln]), ln+1, lines[ln])\n\t}\n\treturn buf.String()\n}\n\n// utility function to pretty print the author.\nfunc prettyPrintAuthor(c *object.Commit) string {\n\treturn fmt.Sprintf(\"%s %s\", c.Author.Name, c.Author.When.Format(\"2006-01-02\"))\n}\n\n// utility function to calculate the number of runes needed\n// to print the longest author name in the blame of a file.\nfunc (b *blame) maxAuthorLength() int {\n\tmemo := make(map[plumbing.Hash]struct{}, len(b.graph)-1)\n\tfVs := b.graph[len(b.graph)-1]\n\tm := 0\n\tfor ln := range fVs {\n\t\tif _, ok := memo[fVs[ln].Hash]; ok {\n\t\t\tcontinue\n\t\t}\n\t\tmemo[fVs[ln].Hash] = struct{}{}\n\t\tm = max(m, utf8.RuneCountInString(prettyPrintAuthor(fVs[ln])))\n\t}\n\treturn m\n}\n\nfunc max(a, b int) int {\n\tif a > b {\n\t\treturn a\n\t}\n\treturn b\n}\n"
        },
        {
          "name": "blame_test.go",
          "type": "blob",
          "size": 26.46875,
          "content": "package git\n\nimport (\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/object\"\n\n\t. \"gopkg.in/check.v1\"\n\t\"gopkg.in/src-d/go-git-fixtures.v3\"\n)\n\ntype BlameSuite struct {\n\tBaseSuite\n}\n\nvar _ = Suite(&BlameSuite{})\n\nfunc (s *BlameSuite) TestNewLines(c *C) {\n\th := plumbing.NewHash(\"ce9f123d790717599aaeb76bc62510de437761be\")\n\tlines, err := newLines([]string{\"foo\"}, []*object.Commit{{\n\t\tHash:    h,\n\t\tMessage: \"foo\",\n\t}})\n\n\tc.Assert(err, IsNil)\n\tc.Assert(lines, HasLen, 1)\n\tc.Assert(lines[0].Text, Equals, \"foo\")\n\tc.Assert(lines[0].Hash, Equals, h)\n}\n\nfunc (s *BlameSuite) TestNewLinesWithNewLine(c *C) {\n\tlines, err := newLines([]string{\"foo\"}, []*object.Commit{\n\t\t{Message: \"foo\"},\n\t\t{Message: \"bar\"},\n\t})\n\n\tc.Assert(err, IsNil)\n\tc.Assert(lines, HasLen, 2)\n\tc.Assert(lines[0].Text, Equals, \"foo\")\n\tc.Assert(lines[1].Text, Equals, \"\\n\")\n}\n\ntype blameTest struct {\n\trepo   string\n\trev    string\n\tpath   string\n\tblames []string // the commits blamed for each line\n}\n\n// run a blame on all the suite's tests\nfunc (s *BlameSuite) TestBlame(c *C) {\n\tfor _, t := range blameTests {\n\t\tr := s.NewRepositoryFromPackfile(fixtures.ByURL(t.repo).One())\n\n\t\texp := s.mockBlame(c, t, r)\n\t\tcommit, err := r.CommitObject(plumbing.NewHash(t.rev))\n\t\tc.Assert(err, IsNil)\n\n\t\tobt, err := Blame(commit, t.path)\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(obt, DeepEquals, exp)\n\n\t\tfor i, l := range obt.Lines {\n\t\t\tc.Assert(l.Hash.String(), Equals, t.blames[i])\n\t\t}\n\t}\n}\n\nfunc (s *BlameSuite) mockBlame(c *C, t blameTest, r *Repository) (blame *BlameResult) {\n\tcommit, err := r.CommitObject(plumbing.NewHash(t.rev))\n\tc.Assert(err, IsNil, Commentf(\"%v: repo=%s, rev=%s\", err, t.repo, t.rev))\n\n\tf, err := commit.File(t.path)\n\tc.Assert(err, IsNil)\n\tlines, err := f.Lines()\n\tc.Assert(err, IsNil)\n\tc.Assert(len(t.blames), Equals, len(lines), Commentf(\n\t\t\"repo=%s, path=%s, rev=%s: the number of lines in the file and the number of expected blames differ (len(blames)=%d, len(lines)=%d)\\nblames=%#q\\nlines=%#q\", t.repo, t.path, t.rev, len(t.blames), len(lines), t.blames, lines))\n\n\tblamedLines := make([]*Line, 0, len(t.blames))\n\tfor i := range t.blames {\n\t\tcommit, err := r.CommitObject(plumbing.NewHash(t.blames[i]))\n\t\tc.Assert(err, IsNil)\n\t\tl := &Line{\n\t\t\tAuthor: commit.Author.Email,\n\t\t\tText:   lines[i],\n\t\t\tDate:   commit.Author.When,\n\t\t\tHash:   commit.Hash,\n\t\t}\n\t\tblamedLines = append(blamedLines, l)\n\t}\n\n\treturn &BlameResult{\n\t\tPath:  t.path,\n\t\tRev:   plumbing.NewHash(t.rev),\n\t\tLines: blamedLines,\n\t}\n}\n\n// utility function to avoid writing so many repeated commits\nfunc repeat(s string, n int) []string {\n\tif n < 0 {\n\t\tpanic(\"repeat: n < 0\")\n\t}\n\tr := make([]string, 0, n)\n\tfor i := 0; i < n; i++ {\n\t\tr = append(r, s)\n\t}\n\n\treturn r\n}\n\n// utility function to concat slices\nfunc concat(vargs ...[]string) []string {\n\tvar r []string\n\tfor _, ss := range vargs {\n\t\tr = append(r, ss...)\n\t}\n\n\treturn r\n}\n\nvar blameTests = [...]blameTest{\n\t// use the blame2humantest.bash script to easily add more tests.\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"binary.jpg\", concat(\n\t\trepeat(\"35e85108805c84807bc66a02d91535e1e24b38b9\", 285),\n\t)},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"CHANGELOG\", concat(\n\t\trepeat(\"b8e471f58bcbca63b07bda20e428190409c2db47\", 1),\n\t)},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"go/example.go\", concat(\n\t\trepeat(\"918c48b83bd081e863dbe1b80f8998f058cd8294\", 142),\n\t)},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"json/long.json\", concat(\n\t\trepeat(\"af2d6a6954d532f8ffb47615169c8fdf9d383a1a\", 6492),\n\t)},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"json/short.json\", concat(\n\t\trepeat(\"af2d6a6954d532f8ffb47615169c8fdf9d383a1a\", 22),\n\t)},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"LICENSE\", concat(\n\t\trepeat(\"b029517f6300c2da0f4b651b8642506cd6aaf45d\", 22),\n\t)},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"php/crappy.php\", concat(\n\t\trepeat(\"918c48b83bd081e863dbe1b80f8998f058cd8294\", 259),\n\t)},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"vendor/foo.go\", concat(\n\t\trepeat(\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", 7),\n\t)},\n\t/*\n\t\t// Failed\n\t\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"InstallSpinnaker.sh\", concat(\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 2),\n\t\t\trepeat(\"a47d0aaeda421f06df248ad65bd58230766bf118\", 1),\n\t\t\trepeat(\"23673af3ad70b50bba7fdafadc2323302f5ba520\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 29),\n\t\t\trepeat(\"9a06d3f20eabb254d0a1e2ff7735ef007ccd595e\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 4),\n\t\t\trepeat(\"a47d0aaeda421f06df248ad65bd58230766bf118\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 5),\n\t\t\trepeat(\"0c5bb1e4392e751f884f3c57de5d4aee72c40031\", 2),\n\t\t\trepeat(\"d4b48a39aba7d3bd3e8abef2274a95b112d1ae73\", 3),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 7),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"b7015a5d36990d69a054482556127b9c7404a24a\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 2),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 5),\n\t\t\trepeat(\"d4b48a39aba7d3bd3e8abef2274a95b112d1ae73\", 7),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 3),\n\t\t\trepeat(\"d4b48a39aba7d3bd3e8abef2274a95b112d1ae73\", 6),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 10),\n\t\t\trepeat(\"b7015a5d36990d69a054482556127b9c7404a24a\", 4),\n\t\t\trepeat(\"0c5bb1e4392e751f884f3c57de5d4aee72c40031\", 2),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 2),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 4),\n\t\t\trepeat(\"23673af3ad70b50bba7fdafadc2323302f5ba520\", 4),\n\t\t\trepeat(\"d4b48a39aba7d3bd3e8abef2274a95b112d1ae73\", 4),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 1),\n\t\t\trepeat(\"d4b48a39aba7d3bd3e8abef2274a95b112d1ae73\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 1),\n\t\t\trepeat(\"b7015a5d36990d69a054482556127b9c7404a24a\", 1),\n\t\t\trepeat(\"0c5bb1e4392e751f884f3c57de5d4aee72c40031\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 13),\n\t\t\trepeat(\"b7015a5d36990d69a054482556127b9c7404a24a\", 2),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 6),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 1),\n\t\t\trepeat(\"b7015a5d36990d69a054482556127b9c7404a24a\", 2),\n\t\t\trepeat(\"0c5bb1e4392e751f884f3c57de5d4aee72c40031\", 1),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 4),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 3),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 2),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 4),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 3),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 15),\n\t\t\trepeat(\"b41d7c0e5b20bbe7c8eb6606731a3ff68f4e3941\", 1),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 1),\n\t\t\trepeat(\"b41d7c0e5b20bbe7c8eb6606731a3ff68f4e3941\", 8),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 2),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 12),\n\t\t\trepeat(\"505577dc87d300cf562dc4702a05a5615d90d855\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 5),\n\t\t\trepeat(\"370d61cdbc1f3c90db6759f1599ccbabd40ad6c1\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 4),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 1),\n\t\t\trepeat(\"b41d7c0e5b20bbe7c8eb6606731a3ff68f4e3941\", 5),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 3),\n\t\t\trepeat(\"b41d7c0e5b20bbe7c8eb6606731a3ff68f4e3941\", 2),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 2),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 9),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 1),\n\t\t\trepeat(\"b41d7c0e5b20bbe7c8eb6606731a3ff68f4e3941\", 3),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 4),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 6),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 1),\n\t\t\trepeat(\"b7015a5d36990d69a054482556127b9c7404a24a\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 6),\n\t\t\trepeat(\"d2f6214b625db706384b378a29cc4c22237db97a\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 3),\n\t\t\trepeat(\"d2f6214b625db706384b378a29cc4c22237db97a\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 4),\n\t\t\trepeat(\"b7015a5d36990d69a054482556127b9c7404a24a\", 1),\n\t\t\trepeat(\"c9c2a0ec03968ab17e8b16fdec9661eb1dbea173\", 1),\n\t\t\trepeat(\"d2f6214b625db706384b378a29cc4c22237db97a\", 2),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"b7015a5d36990d69a054482556127b9c7404a24a\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 12),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 5),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 3),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"01e65d67eed8afcb67a6bdf1c962541f62b299c9\", 5),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 3),\n\t\t\trepeat(\"a47d0aaeda421f06df248ad65bd58230766bf118\", 5),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 5),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 1),\n\t\t\trepeat(\"01e65d67eed8afcb67a6bdf1c962541f62b299c9\", 2),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"01e65d67eed8afcb67a6bdf1c962541f62b299c9\", 1),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"b2c7142082d52b09ca20228606c31c7479c0833e\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 1),\n\t\t\trepeat(\"495c7118e7cf757aa04eab410b64bfb5b5149ad2\", 1),\n\t\t\trepeat(\"d4b48a39aba7d3bd3e8abef2274a95b112d1ae73\", 1),\n\t\t\trepeat(\"495c7118e7cf757aa04eab410b64bfb5b5149ad2\", 3),\n\t\t\trepeat(\"d4b48a39aba7d3bd3e8abef2274a95b112d1ae73\", 1),\n\t\t\trepeat(\"495c7118e7cf757aa04eab410b64bfb5b5149ad2\", 1),\n\t\t\trepeat(\"50d0556563599366f29cb286525780004fa5a317\", 1),\n\t\t\trepeat(\"dd2d03c19658ff96d371aef00e75e2e54702da0e\", 1),\n\t\t\trepeat(\"d4b48a39aba7d3bd3e8abef2274a95b112d1ae73\", 1),\n\t\t\trepeat(\"dd2d03c19658ff96d371aef00e75e2e54702da0e\", 2),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 2),\n\t\t\trepeat(\"01e65d67eed8afcb67a6bdf1c962541f62b299c9\", 1),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"b5c6053a46993b20d1b91e7b7206bffa54669ad7\", 1),\n\t\t\trepeat(\"9e74d009894d73dd07773ea6b3bdd8323db980f7\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 1),\n\t\t\trepeat(\"d4b48a39aba7d3bd3e8abef2274a95b112d1ae73\", 4),\n\t\t\trepeat(\"01e65d67eed8afcb67a6bdf1c962541f62b299c9\", 1),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 1),\n\t\t\trepeat(\"b7015a5d36990d69a054482556127b9c7404a24a\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 1),\n\t\t\trepeat(\"d2f6214b625db706384b378a29cc4c22237db97a\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 3),\n\t\t\trepeat(\"b41d7c0e5b20bbe7c8eb6606731a3ff68f4e3941\", 2),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 2),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 4),\n\t\t\trepeat(\"d2f6214b625db706384b378a29cc4c22237db97a\", 1),\n\t\t\trepeat(\"b7015a5d36990d69a054482556127b9c7404a24a\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 5),\n\t\t\trepeat(\"b41d7c0e5b20bbe7c8eb6606731a3ff68f4e3941\", 2),\n\t\t\trepeat(\"d2f6214b625db706384b378a29cc4c22237db97a\", 1),\n\t\t\trepeat(\"ce9f123d790717599aaeb76bc62510de437761be\", 5),\n\t\t\trepeat(\"ba486de7c025457963701114c683dcd4708e1dee\", 4),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"01e65d67eed8afcb67a6bdf1c962541f62b299c9\", 1),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"01e65d67eed8afcb67a6bdf1c962541f62b299c9\", 3),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 1),\n\t\t\trepeat(\"01e65d67eed8afcb67a6bdf1c962541f62b299c9\", 3),\n\t\t\trepeat(\"6328ee836affafc1b52127147b5ca07300ac78e6\", 2),\n\t\t\trepeat(\"01e65d67eed8afcb67a6bdf1c962541f62b299c9\", 3),\n\t\t\trepeat(\"3de4f77c105f700f50d9549d32b9a05a01b46c4b\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 2),\n\t\t\trepeat(\"370d61cdbc1f3c90db6759f1599ccbabd40ad6c1\", 6),\n\t\t\trepeat(\"dd7e66c862209e8b912694a582a09c0db3227f0d\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 2),\n\t\t\trepeat(\"dd7e66c862209e8b912694a582a09c0db3227f0d\", 3),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"dd7e66c862209e8b912694a582a09c0db3227f0d\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 3),\n\t\t)},\n\t*/\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"pylib/spinnaker/reconfigure_spinnaker.py\", concat(\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 22),\n\t\trepeat(\"c89dab0d42f1856d157357e9010f8cc6a12f5b1f\", 7),\n\t)},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"pylib/spinnaker/validate_configuration.py\", concat(\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 29),\n\t\trepeat(\"1e3d328a2cabda5d0aaddc5dec65271343e0dc37\", 19),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 15),\n\t\trepeat(\"b5d999e2986e190d81767cd3cfeda0260f9f6fb8\", 1),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 12),\n\t\trepeat(\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\", 1),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 4),\n\t\trepeat(\"b5d999e2986e190d81767cd3cfeda0260f9f6fb8\", 8),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 1),\n\t\trepeat(\"b5d999e2986e190d81767cd3cfeda0260f9f6fb8\", 4),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 46),\n\t\trepeat(\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\", 1),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 4),\n\t\trepeat(\"1e3d328a2cabda5d0aaddc5dec65271343e0dc37\", 42),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 1),\n\t\trepeat(\"1e3d328a2cabda5d0aaddc5dec65271343e0dc37\", 1),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 3),\n\t\trepeat(\"1e3d328a2cabda5d0aaddc5dec65271343e0dc37\", 1),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 1),\n\t\trepeat(\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\", 8),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 1),\n\t\trepeat(\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\", 2),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 3),\n\t\trepeat(\"1e3d328a2cabda5d0aaddc5dec65271343e0dc37\", 3),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 12),\n\t\trepeat(\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\", 10),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 69),\n\t\trepeat(\"b5d999e2986e190d81767cd3cfeda0260f9f6fb8\", 7),\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 4),\n\t)},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"pylib/spinnaker/run.py\", concat(\n\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 185),\n\t)},\n\t/*\n\t\t// Fail by 3\n\t\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"pylib/spinnaker/configurator.py\", concat(\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 53),\n\t\t\trepeat(\"c89dab0d42f1856d157357e9010f8cc6a12f5b1f\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 4),\n\t\t\trepeat(\"e805183c72f0426fb073728c01901c2fd2db1da6\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 6),\n\t\t\trepeat(\"023d4fb17b76e0fe0764971df8b8538b735a1d67\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 36),\n\t\t\trepeat(\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 3),\n\t\t\trepeat(\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\", 3),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 4),\n\t\t\trepeat(\"c89dab0d42f1856d157357e9010f8cc6a12f5b1f\", 13),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 2),\n\t\t\trepeat(\"c89dab0d42f1856d157357e9010f8cc6a12f5b1f\", 18),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 2),\n\t\t\trepeat(\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\", 1),\n\t\t\trepeat(\"023d4fb17b76e0fe0764971df8b8538b735a1d67\", 17),\n\t\t\trepeat(\"c89dab0d42f1856d157357e9010f8cc6a12f5b1f\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 43),\n\t\t)},\n\t*/\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"pylib/spinnaker/__init__.py\", []string{}},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"gradle/wrapper/gradle-wrapper.jar\", concat(\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 1),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 7),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 2),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 2),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 3),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 1),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 10),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 11),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 29),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 7),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 58),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 1),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 1),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 2),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 2),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 13),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 4),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 3),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 13),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 2),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 9),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 3),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 1),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 17),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 3),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 6),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 6),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 3),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 5),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 4),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 3),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 2),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 1),\n\t\trepeat(\"11d6c1020b1765e236ca65b2709d37b5bfdba0f4\", 6),\n\t\trepeat(\"bc02440df2ff95a014a7b3cb11b98c3a2bded777\", 55),\n\t)},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"config/settings.js\", concat(\n\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 17),\n\t\trepeat(\"99534ecc895fe17a1d562bb3049d4168a04d0865\", 1),\n\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 43),\n\t\trepeat(\"d2838db9f6ef9628645e7d04cd9658a83e8708ea\", 1),\n\t\trepeat(\"637ba49300f701cfbd859c1ccf13c4f39a9ba1c8\", 1),\n\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 13),\n\t)},\n\t/*\n\t\t// fail a few lines\n\t\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"config/default-spinnaker-local.yml\", concat(\n\t\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 9),\n\t\t\trepeat(\"5e09821cbd7d710405b61cab0a795c2982a71b9c\", 2),\n\t\t\trepeat(\"99534ecc895fe17a1d562bb3049d4168a04d0865\", 1),\n\t\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 2),\n\t\t\trepeat(\"a596972a661d9a7deca8abd18b52ce1a39516e89\", 1),\n\t\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 5),\n\t\t\trepeat(\"5e09821cbd7d710405b61cab0a795c2982a71b9c\", 2),\n\t\t\trepeat(\"a596972a661d9a7deca8abd18b52ce1a39516e89\", 1),\n\t\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 5),\n\t\t\trepeat(\"5e09821cbd7d710405b61cab0a795c2982a71b9c\", 1),\n\t\t\trepeat(\"8980daf661408a3faa1f22c225702a5c1d11d5c9\", 1),\n\t\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 25),\n\t\t\trepeat(\"caf6d62e8285d4681514dd8027356fb019bc97ff\", 1),\n\t\t\trepeat(\"eaf7614cad81e8ab5c813dd4821129d0c04ea449\", 1),\n\t\t\trepeat(\"caf6d62e8285d4681514dd8027356fb019bc97ff\", 1),\n\t\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 24),\n\t\t\trepeat(\"974b775a8978b120ff710cac93a21c7387b914c9\", 2),\n\t\t\trepeat(\"3ce7b902a51bac2f10994f7d1f251b616c975e54\", 1),\n\t\t\trepeat(\"5a2a845bc08974a36d599a4a4b7e25be833823b0\", 6),\n\t\t\trepeat(\"41e96c54a478e5d09dd07ed7feb2d8d08d8c7e3c\", 14),\n\t\t\trepeat(\"7c8d9a6081d9cb7a56c479bfe64d70540ea32795\", 5),\n\t\t\trepeat(\"5a2a845bc08974a36d599a4a4b7e25be833823b0\", 2),\n\t\t)},\n\t*/\n\t/*\n\t\t// fail one line\n\t\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"config/spinnaker.yml\", concat(\n\t\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 32),\n\t\t\trepeat(\"41e96c54a478e5d09dd07ed7feb2d8d08d8c7e3c\", 2),\n\t\t\trepeat(\"5a2a845bc08974a36d599a4a4b7e25be833823b0\", 1),\n\t\t\trepeat(\"41e96c54a478e5d09dd07ed7feb2d8d08d8c7e3c\", 6),\n\t\t\trepeat(\"5a2a845bc08974a36d599a4a4b7e25be833823b0\", 2),\n\t\t\trepeat(\"41e96c54a478e5d09dd07ed7feb2d8d08d8c7e3c\", 2),\n\t\t\trepeat(\"5a2a845bc08974a36d599a4a4b7e25be833823b0\", 2),\n\t\t\trepeat(\"41e96c54a478e5d09dd07ed7feb2d8d08d8c7e3c\", 3),\n\t\t\trepeat(\"7c8d9a6081d9cb7a56c479bfe64d70540ea32795\", 3),\n\t\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 50),\n\t\t\trepeat(\"974b775a8978b120ff710cac93a21c7387b914c9\", 2),\n\t\t\trepeat(\"d4553dac205023fa77652308af1a2d1cf52138fb\", 1),\n\t\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 9),\n\t\t\trepeat(\"caf6d62e8285d4681514dd8027356fb019bc97ff\", 1),\n\t\t\trepeat(\"eaf7614cad81e8ab5c813dd4821129d0c04ea449\", 1),\n\t\t\trepeat(\"caf6d62e8285d4681514dd8027356fb019bc97ff\", 1),\n\t\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 39),\n\t\t\trepeat(\"079e42e7c979541b6fab7343838f7b9fd4a360cd\", 6),\n\t\t\trepeat(\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\", 15),\n\t\t)},\n\t*/\n\t/*\n\t\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"dev/install_development.sh\", concat(\n\t\t\trepeat(\"99534ecc895fe17a1d562bb3049d4168a04d0865\", 1),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 71),\n\t\t)},\n\t*/\n\t/*\n\t\t// FAIL two lines interchanged\n\t\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"dev/bootstrap_dev.sh\", concat(\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 95),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 10),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 7),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 2),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 1),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 3),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 4),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 12),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 2),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 2),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 2),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 3),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 6),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 1),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 4),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 1),\n\t\t\trepeat(\"376599177551c3f04ccc94d71bbb4d037dec0c3f\", 2),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 17),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 2),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 2),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 2),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 3),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 3),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 5),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 5),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 8),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 4),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 1),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 6),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 1),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 4),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 10),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 2),\n\t\t\trepeat(\"fc28a378558cdb5bbc08b6dcb96ee77c5b716760\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 1),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 8),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 1),\n\t\t\trepeat(\"fc28a378558cdb5bbc08b6dcb96ee77c5b716760\", 1),\n\t\t\trepeat(\"d1ff4e13e9e0b500821aa558373878f93487e34b\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 4),\n\t\t\trepeat(\"24551a5d486969a2972ee05e87f16444890f9555\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 2),\n\t\t\trepeat(\"24551a5d486969a2972ee05e87f16444890f9555\", 1),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 8),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 13),\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 5),\n\t\t\trepeat(\"24551a5d486969a2972ee05e87f16444890f9555\", 1),\n\t\t\trepeat(\"838aed816872c52ed435e4876a7b64dba0bed500\", 8),\n\t\t)},\n\t*/\n\t/*\n\t\t// FAIL move?\n\t\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"dev/create_google_dev_vm.sh\", concat(\n\t\t\trepeat(\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\", 20),\n\t\t)},\n\t*/\n}\n"
        },
        {
          "name": "cli",
          "type": "tree",
          "content": null
        },
        {
          "name": "common.go",
          "type": "blob",
          "size": 0.4755859375,
          "content": "package git\n\nimport \"strings\"\n\nconst defaultDotGitPath = \".git\"\n\n// countLines returns the number of lines in a string à la git, this is\n// The newline character is assumed to be '\\n'.  The empty string\n// contains 0 lines.  If the last line of the string doesn't end with a\n// newline, it will still be considered a line.\nfunc countLines(s string) int {\n\tif s == \"\" {\n\t\treturn 0\n\t}\n\n\tnEOL := strings.Count(s, \"\\n\")\n\tif strings.HasSuffix(s, \"\\n\") {\n\t\treturn nEOL\n\t}\n\n\treturn nEOL + 1\n}\n"
        },
        {
          "name": "common_test.go",
          "type": "blob",
          "size": 3.681640625,
          "content": "package git\n\nimport (\n\t\"testing\"\n\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/cache\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/format/packfile\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/transport\"\n\t\"gopkg.in/src-d/go-git.v4/storage/filesystem\"\n\t\"gopkg.in/src-d/go-git.v4/storage/memory\"\n\n\t. \"gopkg.in/check.v1\"\n\t\"gopkg.in/src-d/go-billy.v4\"\n\t\"gopkg.in/src-d/go-billy.v4/memfs\"\n\t\"gopkg.in/src-d/go-billy.v4/util\"\n\t\"gopkg.in/src-d/go-git-fixtures.v3\"\n)\n\nfunc Test(t *testing.T) { TestingT(t) }\n\ntype BaseSuite struct {\n\tfixtures.Suite\n\tRepository *Repository\n\n\tbackupProtocol transport.Transport\n\tcache          map[string]*Repository\n}\n\nfunc (s *BaseSuite) SetUpSuite(c *C) {\n\ts.Suite.SetUpSuite(c)\n\ts.buildBasicRepository(c)\n\n\ts.cache = make(map[string]*Repository)\n}\n\nfunc (s *BaseSuite) TearDownSuite(c *C) {\n\ts.Suite.TearDownSuite(c)\n}\n\nfunc (s *BaseSuite) buildBasicRepository(c *C) {\n\tf := fixtures.Basic().One()\n\ts.Repository = s.NewRepository(f)\n}\n\n// NewRepository returns a new repository using the .git folder, if the fixture\n// is tagged as worktree the filesystem from fixture is used, otherwise a new\n// memfs filesystem is used as worktree.\nfunc (s *BaseSuite) NewRepository(f *fixtures.Fixture) *Repository {\n\tvar worktree, dotgit billy.Filesystem\n\tif f.Is(\"worktree\") {\n\t\tr, err := PlainOpen(f.Worktree().Root())\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\n\t\treturn r\n\t}\n\n\tdotgit = f.DotGit()\n\tworktree = memfs.New()\n\n\tst := filesystem.NewStorage(dotgit, cache.NewObjectLRUDefault())\n\n\tr, err := Open(st, worktree)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\treturn r\n}\n\n// NewRepositoryWithEmptyWorktree returns a new repository using the .git folder\n// from the fixture but without a empty memfs worktree, the index and the\n// modules are deleted from the .git folder.\nfunc (s *BaseSuite) NewRepositoryWithEmptyWorktree(f *fixtures.Fixture) *Repository {\n\tdotgit := f.DotGit()\n\terr := dotgit.Remove(\"index\")\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\terr = util.RemoveAll(dotgit, \"modules\")\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tworktree := memfs.New()\n\n\tst := filesystem.NewStorage(dotgit, cache.NewObjectLRUDefault())\n\n\tr, err := Open(st, worktree)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\treturn r\n\n}\n\nfunc (s *BaseSuite) NewRepositoryFromPackfile(f *fixtures.Fixture) *Repository {\n\th := f.PackfileHash.String()\n\tif r, ok := s.cache[h]; ok {\n\t\treturn r\n\t}\n\n\tstorer := memory.NewStorage()\n\tp := f.Packfile()\n\tdefer p.Close()\n\n\tif err := packfile.UpdateObjectStorage(storer, p); err != nil {\n\t\tpanic(err)\n\t}\n\n\tstorer.SetReference(plumbing.NewHashReference(plumbing.HEAD, f.Head))\n\n\tr, err := Open(storer, memfs.New())\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\ts.cache[h] = r\n\treturn r\n}\n\nfunc (s *BaseSuite) GetBasicLocalRepositoryURL() string {\n\tfixture := fixtures.Basic().One()\n\treturn s.GetLocalRepositoryURL(fixture)\n}\n\nfunc (s *BaseSuite) GetLocalRepositoryURL(f *fixtures.Fixture) string {\n\treturn f.DotGit().Root()\n}\n\ntype SuiteCommon struct{}\n\nvar _ = Suite(&SuiteCommon{})\n\nvar countLinesTests = [...]struct {\n\ti string // the string we want to count lines from\n\te int    // the expected number of lines in i\n}{\n\t{\"\", 0},\n\t{\"a\", 1},\n\t{\"a\\n\", 1},\n\t{\"a\\nb\", 2},\n\t{\"a\\nb\\n\", 2},\n\t{\"a\\nb\\nc\", 3},\n\t{\"a\\nb\\nc\\n\", 3},\n\t{\"a\\n\\n\\nb\\n\", 4},\n\t{\"first line\\n\\tsecond line\\nthird line\\n\", 3},\n}\n\nfunc (s *SuiteCommon) TestCountLines(c *C) {\n\tfor i, t := range countLinesTests {\n\t\to := countLines(t.i)\n\t\tc.Assert(o, Equals, t.e, Commentf(\"subtest %d, input=%q\", i, t.i))\n\t}\n}\n\nfunc AssertReferences(c *C, r *Repository, expected map[string]string) {\n\tfor name, target := range expected {\n\t\texpected := plumbing.NewReferenceFromStrings(name, target)\n\n\t\tobtained, err := r.Reference(expected.Name(), true)\n\t\tc.Assert(err, IsNil)\n\n\t\tc.Assert(obtained, DeepEquals, expected)\n\t}\n}\n"
        },
        {
          "name": "config",
          "type": "tree",
          "content": null
        },
        {
          "name": "doc.go",
          "type": "blob",
          "size": 0.5048828125,
          "content": "// A highly extensible git implementation in pure Go.\n//\n// go-git aims to reach the completeness of libgit2 or jgit, nowadays covers the\n// majority of the plumbing read operations and some of the main write\n// operations, but lacks the main porcelain operations such as merges.\n//\n// It is highly extensible, we have been following the open/close principle in\n// its design to facilitate extensions, mainly focusing the efforts on the\n// persistence of the objects.\npackage git // import \"gopkg.in/src-d/go-git.v4\"\n"
        },
        {
          "name": "example_test.go",
          "type": "blob",
          "size": 3.720703125,
          "content": "package git_test\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"os\"\n\t\"path/filepath\"\n\n\t\"gopkg.in/src-d/go-git.v4\"\n\t\"gopkg.in/src-d/go-git.v4/config\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/transport/http\"\n\t\"gopkg.in/src-d/go-git.v4/storage/memory\"\n\n\t\"gopkg.in/src-d/go-billy.v4/memfs\"\n)\n\nfunc ExampleClone() {\n\t// Filesystem abstraction based on memory\n\tfs := memfs.New()\n\t// Git objects storer based on memory\n\tstorer := memory.NewStorage()\n\n\t// Clones the repository into the worktree (fs) and storer all the .git\n\t// content into the storer\n\t_, err := git.Clone(storer, fs, &git.CloneOptions{\n\t\tURL: \"https://github.com/git-fixtures/basic.git\",\n\t})\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Prints the content of the CHANGELOG file from the cloned repository\n\tchangelog, err := fs.Open(\"CHANGELOG\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tio.Copy(os.Stdout, changelog)\n\t// Output: Initial changelog\n}\n\nfunc ExamplePlainClone() {\n\t// Tempdir to clone the repository\n\tdir, err := ioutil.TempDir(\"\", \"clone-example\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tdefer os.RemoveAll(dir) // clean up\n\n\t// Clones the repository into the given dir, just as a normal git clone does\n\t_, err = git.PlainClone(dir, false, &git.CloneOptions{\n\t\tURL: \"https://github.com/git-fixtures/basic.git\",\n\t})\n\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Prints the content of the CHANGELOG file from the cloned repository\n\tchangelog, err := os.Open(filepath.Join(dir, \"CHANGELOG\"))\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tio.Copy(os.Stdout, changelog)\n\t// Output: Initial changelog\n}\n\nfunc ExamplePlainClone_usernamePassword() {\n\t// Tempdir to clone the repository\n\tdir, err := ioutil.TempDir(\"\", \"clone-example\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tdefer os.RemoveAll(dir) // clean up\n\n\t// Clones the repository into the given dir, just as a normal git clone does\n\t_, err = git.PlainClone(dir, false, &git.CloneOptions{\n\t\tURL: \"https://github.com/git-fixtures/basic.git\",\n\t\tAuth: &http.BasicAuth{\n\t\t\tUsername: \"username\",\n\t\t\tPassword: \"password\",\n\t\t},\n\t})\n\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\nfunc ExamplePlainClone_accessToken() {\n\t// Tempdir to clone the repository\n\tdir, err := ioutil.TempDir(\"\", \"clone-example\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tdefer os.RemoveAll(dir) // clean up\n\n\t// Clones the repository into the given dir, just as a normal git clone does\n\t_, err = git.PlainClone(dir, false, &git.CloneOptions{\n\t\tURL: \"https://github.com/git-fixtures/basic.git\",\n\t\tAuth: &http.BasicAuth{\n\t\t\tUsername: \"abc123\", // anything except an empty string\n\t\t\tPassword: \"github_access_token\",\n\t\t},\n\t})\n\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\nfunc ExampleRepository_References() {\n\tr, _ := git.Clone(memory.NewStorage(), nil, &git.CloneOptions{\n\t\tURL: \"https://github.com/git-fixtures/basic.git\",\n\t})\n\n\t// simulating a git show-ref\n\trefs, _ := r.References()\n\trefs.ForEach(func(ref *plumbing.Reference) error {\n\t\tif ref.Type() == plumbing.HashReference {\n\t\t\tfmt.Println(ref)\n\t\t}\n\n\t\treturn nil\n\t})\n\n\t// Example Output:\n\t// 6ecf0ef2c2dffb796033e5a02219af86ec6584e5 refs/remotes/origin/master\n\t// e8d3ffab552895c19b9fcf7aa264d277cde33881 refs/remotes/origin/branch\n\t// 6ecf0ef2c2dffb796033e5a02219af86ec6584e5 refs/heads/master\n\n}\n\nfunc ExampleRepository_CreateRemote() {\n\tr, _ := git.Init(memory.NewStorage(), nil)\n\n\t// Add a new remote, with the default fetch refspec\n\t_, err := r.CreateRemote(&config.RemoteConfig{\n\t\tName: \"example\",\n\t\tURLs: []string{\"https://github.com/git-fixtures/basic.git\"},\n\t})\n\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tlist, err := r.Remotes()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tfor _, r := range list {\n\t\tfmt.Println(r)\n\t}\n\n\t// Example Output:\n\t// example https://github.com/git-fixtures/basic.git (fetch)\n\t// example https://github.com/git-fixtures/basic.git (push)\n}\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 1.228515625,
          "content": "module gopkg.in/src-d/go-git.v4\n\nrequire (\n\tgithub.com/alcortesm/tgz v0.0.0-20161220082320-9c5fe88206d7 // indirect\n\tgithub.com/anmitsu/go-shlex v0.0.0-20161002113705-648efa622239 // indirect\n\tgithub.com/armon/go-socks5 v0.0.0-20160902184237-e75332964ef5\n\tgithub.com/emirpasic/gods v1.12.0\n\tgithub.com/flynn/go-shlex v0.0.0-20150515145356-3f9db97f8568 // indirect\n\tgithub.com/gliderlabs/ssh v0.2.2\n\tgithub.com/google/go-cmp v0.3.0\n\tgithub.com/jbenet/go-context v0.0.0-20150711004518-d14ea06fba99\n\tgithub.com/jessevdk/go-flags v1.4.0\n\tgithub.com/kevinburke/ssh_config v0.0.0-20190725054713-01f96b0aa0cd\n\tgithub.com/mitchellh/go-homedir v1.1.0\n\tgithub.com/pelletier/go-buffruneio v0.2.0 // indirect\n\tgithub.com/pkg/errors v0.8.1 // indirect\n\tgithub.com/sergi/go-diff v1.0.0\n\tgithub.com/src-d/gcfg v1.4.0\n\tgithub.com/stretchr/objx v0.2.0 // indirect\n\tgithub.com/xanzy/ssh-agent v0.2.1\n\tgolang.org/x/crypto v0.0.0-20190701094942-4def268fd1a4\n\tgolang.org/x/net v0.0.0-20190724013045-ca1201d0de80\n\tgolang.org/x/text v0.3.2\n\tgolang.org/x/tools v0.0.0-20190729092621-ff9f1409240a // indirect\n\tgopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127\n\tgopkg.in/src-d/go-billy.v4 v4.3.2\n\tgopkg.in/src-d/go-git-fixtures.v3 v3.5.0\n\tgopkg.in/warnings.v0 v0.1.2 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 8.591796875,
          "content": "github.com/alcortesm/tgz v0.0.0-20161220082320-9c5fe88206d7 h1:uSoVVbwJiQipAclBbw+8quDsfcvFjOpI5iCf4p/cqCs=\ngithub.com/alcortesm/tgz v0.0.0-20161220082320-9c5fe88206d7/go.mod h1:6zEj6s6u/ghQa61ZWa/C2Aw3RkjiTBOix7dkqa1VLIs=\ngithub.com/anmitsu/go-shlex v0.0.0-20161002113705-648efa622239 h1:kFOfPq6dUM1hTo4JG6LR5AXSUEsOjtdm0kw0FtQtMJA=\ngithub.com/anmitsu/go-shlex v0.0.0-20161002113705-648efa622239/go.mod h1:2FmKhYUyUczH0OGQWaF5ceTx0UBShxjsH6f8oGKYe2c=\ngithub.com/armon/go-socks5 v0.0.0-20160902184237-e75332964ef5 h1:0CwZNZbxp69SHPdPJAN/hZIm0C4OItdklCFmMRWYpio=\ngithub.com/armon/go-socks5 v0.0.0-20160902184237-e75332964ef5/go.mod h1:wHh0iHkYZB8zMSxRWpUBQtwG5a7fFgvEO+odwuTv2gs=\ngithub.com/creack/pty v1.1.7/go.mod h1:lj5s0c3V2DBrqTV7llrYr5NG6My20zk30Fl46Y7DoTY=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/emirpasic/gods v1.12.0 h1:QAUIPSaCu4G+POclxeqb3F+WPpdKqFGlw36+yOzGlrg=\ngithub.com/emirpasic/gods v1.12.0/go.mod h1:YfzfFFoVP/catgzJb4IKIqXjX78Ha8FMSDh3ymbK86o=\ngithub.com/flynn/go-shlex v0.0.0-20150515145356-3f9db97f8568 h1:BHsljHzVlRcyQhjrss6TZTdY2VfCqZPbv5k3iBFa2ZQ=\ngithub.com/flynn/go-shlex v0.0.0-20150515145356-3f9db97f8568/go.mod h1:xEzjJPgXI435gkrCt3MPfRiAkVrwSbHsst4LCFVfpJc=\ngithub.com/gliderlabs/ssh v0.1.3 h1:cBU46h1lYQk5f2Z+jZbewFKy+1zzE2aUX/ilcPDAm9M=\ngithub.com/gliderlabs/ssh v0.1.3/go.mod h1:U7qILu1NlMHj9FlMhZLlkCdDnU1DBEAqr0aevW3Awn0=\ngithub.com/gliderlabs/ssh v0.2.2 h1:6zsha5zo/TWhRhwqCD3+EarCAgZ2yN28ipRnGPnwkI0=\ngithub.com/gliderlabs/ssh v0.2.2/go.mod h1:U7qILu1NlMHj9FlMhZLlkCdDnU1DBEAqr0aevW3Awn0=\ngithub.com/google/go-cmp v0.2.0 h1:+dTQ8DZQJz0Mb/HjFlkptS1FeQ4cWSnN941F8aEG4SQ=\ngithub.com/google/go-cmp v0.2.0/go.mod h1:oXzfMopK8JAjlY9xF4vHSVASa0yLyX7SntLO5aqRK0M=\ngithub.com/google/go-cmp v0.3.0/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/jbenet/go-context v0.0.0-20150711004518-d14ea06fba99 h1:BQSFePA1RWJOlocH6Fxy8MmwDt+yVQYULKfN0RoTN8A=\ngithub.com/jbenet/go-context v0.0.0-20150711004518-d14ea06fba99/go.mod h1:1lJo3i6rXxKeerYnT8Nvf0QmHCRC1n8sfWVwXF2Frvo=\ngithub.com/jessevdk/go-flags v1.4.0 h1:4IU2WS7AumrZ/40jfhf4QVDMsQwqA7VEHozFRrGARJA=\ngithub.com/jessevdk/go-flags v1.4.0/go.mod h1:4FA24M0QyGHXBuZZK/XkWh8h0e1EYbRYJSGM75WSRxI=\ngithub.com/kevinburke/ssh_config v0.0.0-20180830205328-81db2a75821e h1:RgQk53JHp/Cjunrr1WlsXSZpqXn+uREuHvUVcK82CV8=\ngithub.com/kevinburke/ssh_config v0.0.0-20180830205328-81db2a75821e/go.mod h1:CT57kijsi8u/K/BOFA39wgDQJ9CxiF4nAY/ojJ6r6mM=\ngithub.com/kevinburke/ssh_config v0.0.0-20190725054713-01f96b0aa0cd h1:Coekwdh0v2wtGp9Gmz1Ze3eVRAWJMLokvN3QjdzCHLY=\ngithub.com/kevinburke/ssh_config v0.0.0-20190725054713-01f96b0aa0cd/go.mod h1:CT57kijsi8u/K/BOFA39wgDQJ9CxiF4nAY/ojJ6r6mM=\ngithub.com/kr/pretty v0.1.0 h1:L/CwN0zerZDmRFUapSPitk6f+Q3+0za1rQkzVuMiMFI=\ngithub.com/kr/pretty v0.1.0/go.mod h1:dAy3ld7l9f0ibDNOQOHHMYYIIbhfbHSm3C4ZsoJORNo=\ngithub.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=\ngithub.com/kr/pty v1.1.8/go.mod h1:O1sed60cT9XZ5uDucP5qwvh+TE3NnUj51EiZO/lmSfw=\ngithub.com/kr/text v0.1.0 h1:45sCR5RtlFHMR4UwH9sdQ5TC8v0qDQCHnXt+kaKSTVE=\ngithub.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=\ngithub.com/mitchellh/go-homedir v1.1.0 h1:lukF9ziXFxDFPkA1vsr5zpc1XuPDn/wFntq5mG+4E0Y=\ngithub.com/mitchellh/go-homedir v1.1.0/go.mod h1:SfyaCUpYCn1Vlf4IUYiD9fPX4A5wJrkLzIz1N1q0pr0=\ngithub.com/pelletier/go-buffruneio v0.2.0 h1:U4t4R6YkofJ5xHm3dJzuRpPZ0mr5MMCoAWooScCR7aA=\ngithub.com/pelletier/go-buffruneio v0.2.0/go.mod h1:JkE26KsDizTr40EUHkXVtNPvgGtbSNq5BcowyYOWdKo=\ngithub.com/pkg/errors v0.8.1 h1:iURUrRGxPUNPdy5/HRSm+Yj6okJ6UtLINN0Q9M4+h3I=\ngithub.com/pkg/errors v0.8.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/sergi/go-diff v1.0.0 h1:Kpca3qRNrduNnOQeazBd0ysaKrUJiIuISHxogkT9RPQ=\ngithub.com/sergi/go-diff v1.0.0/go.mod h1:0CfEIISq7TuYL3j771MWULgwwjU+GofnZX9QAmXWZgo=\ngithub.com/src-d/gcfg v1.4.0 h1:xXbNR5AlLSA315x2UO+fTSSAXCDf+Ar38/6oyGbDKQ4=\ngithub.com/src-d/gcfg v1.4.0/go.mod h1:p/UMsR43ujA89BJY9duynAwIpvqEujIH/jFlfL7jWoI=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.2.0/go.mod h1:qt09Ya8vawLte6SNmTgCsAVtYtaKzEcn8ATUoHMkEqE=\ngithub.com/stretchr/testify v1.3.0 h1:TivCn/peBQ7UY8ooIcPgZFpTNSz0Q2U6UrFlUfqbe0Q=\ngithub.com/stretchr/testify v1.3.0/go.mod h1:M5WIy9Dh21IEIfnGCwXGc5bZfKNJtfHm1UVUgZn+9EI=\ngithub.com/xanzy/ssh-agent v0.2.1 h1:TCbipTQL2JiiCprBWx9frJ2eJlCYT00NmctrHxVAr70=\ngithub.com/xanzy/ssh-agent v0.2.1/go.mod h1:mLlQY/MoOhWBj+gOGMQkOeiEvkx+8pJSI+0Bx9h2kr4=\ngolang.org/x/crypto v0.0.0-20190219172222-a4c6cb3142f2/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20190422183909-d864b10871cd h1:sMHc2rZHuzQmrbVoSpt9HgerkXPyIeCSO6k0zUMGfFk=\ngolang.org/x/crypto v0.0.0-20190422183909-d864b10871cd/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20190701094942-4def268fd1a4 h1:HuIa8hRrWRSrqYzx1qI49NNxhdi2PrY7gxVSq1JjLDc=\ngolang.org/x/crypto v0.0.0-20190701094942-4def268fd1a4/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190420063019-afa5a82059c6 h1:HdqqaWmYAUI7/dmByKKEw+yxDksGSo+9GjkUc9Zp34E=\ngolang.org/x/net v0.0.0-20190420063019-afa5a82059c6/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190502183928-7f726cade0ab h1:9RfW3ktsOZxgo9YNbBAjq1FWzc/igwEcUzZz8IXgSbk=\ngolang.org/x/net v0.0.0-20190502183928-7f726cade0ab/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20190724013045-ca1201d0de80 h1:Ao/3l156eZf2AW5wK8a7/smtodRU+gha3+BeqJ69lRk=\ngolang.org/x/net v0.0.0-20190724013045-ca1201d0de80/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sys v0.0.0-20180903190138-2b024373dcd9 h1:lkiLiLBHGoH3XnqSLUIaBsilGMUjI+Uy2Xu2JLUtTas=\ngolang.org/x/sys v0.0.0-20180903190138-2b024373dcd9/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190221075227-b4e8571b14e0/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190422165155-953cdadca894 h1:Cz4ceDQGXuKRnVBDTS23GTn/pU5OE2C0WrNTOYK1Uuc=\ngolang.org/x/sys v0.0.0-20190422165155-953cdadca894/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190726091711-fc99dfbffb4e h1:D5TXcfTk7xF7hvieo4QErS3qqCB4teTffacDWr7CI+0=\ngolang.org/x/sys v0.0.0-20190726091711-fc99dfbffb4e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/text v0.3.0 h1:g61tztE5qeGQ89tm6NTjjM9VPIm088od1l6aSorWRWg=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.2/go.mod h1:bEr9sfX3Q8Zfm5fL9x+3itogRgK3+ptLWKqgva+5dAk=\ngolang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190729092621-ff9f1409240a/go.mod h1:jcCCGcm9btYwXyDqrUWc6MKQKKGJCWEQ3AfLSRIbEuI=\ngopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127 h1:qIbj1fsPNlZgppZ+VLlY7N33q108Sa+fhmuc+sWQYwY=\ngopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/src-d/go-billy.v4 v4.3.0 h1:KtlZ4c1OWbIs4jCv5ZXrTqG8EQocr0g/d4DjNg70aek=\ngopkg.in/src-d/go-billy.v4 v4.3.0/go.mod h1:tm33zBoOwxjYHZIE+OV8bxTWFMJLrconzFMd38aARFk=\ngopkg.in/src-d/go-billy.v4 v4.3.2 h1:0SQA1pRztfTFx2miS8sA97XvooFeNOmvUenF4o0EcVg=\ngopkg.in/src-d/go-billy.v4 v4.3.2/go.mod h1:nDjArDMp+XMs1aFAESLRjfGSgfvoYN0hDfzEk0GjC98=\ngopkg.in/src-d/go-git-fixtures.v3 v3.5.0 h1:ivZFOIltbce2Mo8IjzUHAFoq/IylO9WHhNOAJK+LsJg=\ngopkg.in/src-d/go-git-fixtures.v3 v3.5.0/go.mod h1:dLBcvytrw/TYZsNTWCnkNF2DSIlzWYqTe3rJR56Ac7g=\ngopkg.in/warnings.v0 v0.1.2 h1:wFXVbFY8DY5/xOe1ECiWdKCzZlxgshcYVNkBHstARME=\ngopkg.in/warnings.v0 v0.1.2/go.mod h1:jksf8JmL6Qr/oQM2OXTHunEvvTAsrWBLb6OOjuVWRNI=\n"
        },
        {
          "name": "internal",
          "type": "tree",
          "content": null
        },
        {
          "name": "object_walker.go",
          "type": "blob",
          "size": 2.7626953125,
          "content": "package git\n\nimport (\n\t\"fmt\"\n\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/filemode\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/object\"\n\t\"gopkg.in/src-d/go-git.v4/storage\"\n)\n\ntype objectWalker struct {\n\tStorer storage.Storer\n\t// seen is the set of objects seen in the repo.\n\t// seen map can become huge if walking over large\n\t// repos. Thus using struct{} as the value type.\n\tseen map[plumbing.Hash]struct{}\n}\n\nfunc newObjectWalker(s storage.Storer) *objectWalker {\n\treturn &objectWalker{s, map[plumbing.Hash]struct{}{}}\n}\n\n// walkAllRefs walks all (hash) references from the repo.\nfunc (p *objectWalker) walkAllRefs() error {\n\t// Walk over all the references in the repo.\n\tit, err := p.Storer.IterReferences()\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer it.Close()\n\terr = it.ForEach(func(ref *plumbing.Reference) error {\n\t\t// Exit this iteration early for non-hash references.\n\t\tif ref.Type() != plumbing.HashReference {\n\t\t\treturn nil\n\t\t}\n\t\treturn p.walkObjectTree(ref.Hash())\n\t})\n\treturn err\n}\n\nfunc (p *objectWalker) isSeen(hash plumbing.Hash) bool {\n\t_, seen := p.seen[hash]\n\treturn seen\n}\n\nfunc (p *objectWalker) add(hash plumbing.Hash) {\n\tp.seen[hash] = struct{}{}\n}\n\n// walkObjectTree walks over all objects and remembers references\n// to them in the objectWalker. This is used instead of the revlist\n// walks because memory usage is tight with huge repos.\nfunc (p *objectWalker) walkObjectTree(hash plumbing.Hash) error {\n\t// Check if we have already seen, and mark this object\n\tif p.isSeen(hash) {\n\t\treturn nil\n\t}\n\tp.add(hash)\n\t// Fetch the object.\n\tobj, err := object.GetObject(p.Storer, hash)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"Getting object %s failed: %v\", hash, err)\n\t}\n\t// Walk all children depending on object type.\n\tswitch obj := obj.(type) {\n\tcase *object.Commit:\n\t\terr = p.walkObjectTree(obj.TreeHash)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfor _, h := range obj.ParentHashes {\n\t\t\terr = p.walkObjectTree(h)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\tcase *object.Tree:\n\t\tfor i := range obj.Entries {\n\t\t\t// Shortcut for blob objects:\n\t\t\t// 'or' the lower bits of a mode and check that it\n\t\t\t// it matches a filemode.Executable. The type information\n\t\t\t// is in the higher bits, but this is the cleanest way\n\t\t\t// to handle plain files with different modes.\n\t\t\t// Other non-tree objects are somewhat rare, so they\n\t\t\t// are not special-cased.\n\t\t\tif obj.Entries[i].Mode|0755 == filemode.Executable {\n\t\t\t\tp.add(obj.Entries[i].Hash)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\t// Normal walk for sub-trees (and symlinks etc).\n\t\t\terr = p.walkObjectTree(obj.Entries[i].Hash)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\tcase *object.Tag:\n\t\treturn p.walkObjectTree(obj.Target)\n\tdefault:\n\t\t// Error out on unhandled object types.\n\t\treturn fmt.Errorf(\"Unknown object %X %s %T\\n\", obj.ID(), obj.Type(), obj)\n\t}\n\treturn nil\n}\n"
        },
        {
          "name": "options.go",
          "type": "blob",
          "size": 15.3818359375,
          "content": "package git\n\nimport (\n\t\"errors\"\n\t\"regexp\"\n\t\"strings\"\n\t\"time\"\n\n\t\"golang.org/x/crypto/openpgp\"\n\t\"gopkg.in/src-d/go-git.v4/config\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/object\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/protocol/packp/sideband\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/transport\"\n)\n\n// SubmoduleRescursivity defines how depth will affect any submodule recursive\n// operation.\ntype SubmoduleRescursivity uint\n\nconst (\n\t// DefaultRemoteName name of the default Remote, just like git command.\n\tDefaultRemoteName = \"origin\"\n\n\t// NoRecurseSubmodules disables the recursion for a submodule operation.\n\tNoRecurseSubmodules SubmoduleRescursivity = 0\n\t// DefaultSubmoduleRecursionDepth allow recursion in a submodule operation.\n\tDefaultSubmoduleRecursionDepth SubmoduleRescursivity = 10\n)\n\nvar (\n\tErrMissingURL = errors.New(\"URL field is required\")\n)\n\n// CloneOptions describes how a clone should be performed.\ntype CloneOptions struct {\n\t// The (possibly remote) repository URL to clone from.\n\tURL string\n\t// Auth credentials, if required, to use with the remote repository.\n\tAuth transport.AuthMethod\n\t// Name of the remote to be added, by default `origin`.\n\tRemoteName string\n\t// Remote branch to clone.\n\tReferenceName plumbing.ReferenceName\n\t// Fetch only ReferenceName if true.\n\tSingleBranch bool\n\t// No checkout of HEAD after clone if true.\n\tNoCheckout bool\n\t// Limit fetching to the specified number of commits.\n\tDepth int\n\t// RecurseSubmodules after the clone is created, initialize all submodules\n\t// within, using their default settings. This option is ignored if the\n\t// cloned repository does not have a worktree.\n\tRecurseSubmodules SubmoduleRescursivity\n\t// Progress is where the human readable information sent by the server is\n\t// stored, if nil nothing is stored and the capability (if supported)\n\t// no-progress, is sent to the server to avoid send this information.\n\tProgress sideband.Progress\n\t// Tags describe how the tags will be fetched from the remote repository,\n\t// by default is AllTags.\n\tTags TagMode\n}\n\n// Validate validates the fields and sets the default values.\nfunc (o *CloneOptions) Validate() error {\n\tif o.URL == \"\" {\n\t\treturn ErrMissingURL\n\t}\n\n\tif o.RemoteName == \"\" {\n\t\to.RemoteName = DefaultRemoteName\n\t}\n\n\tif o.ReferenceName == \"\" {\n\t\to.ReferenceName = plumbing.HEAD\n\t}\n\n\tif o.Tags == InvalidTagMode {\n\t\to.Tags = AllTags\n\t}\n\n\treturn nil\n}\n\n// PullOptions describes how a pull should be performed.\ntype PullOptions struct {\n\t// Name of the remote to be pulled. If empty, uses the default.\n\tRemoteName string\n\t// Remote branch to clone. If empty, uses HEAD.\n\tReferenceName plumbing.ReferenceName\n\t// Fetch only ReferenceName if true.\n\tSingleBranch bool\n\t// Limit fetching to the specified number of commits.\n\tDepth int\n\t// Auth credentials, if required, to use with the remote repository.\n\tAuth transport.AuthMethod\n\t// RecurseSubmodules controls if new commits of all populated submodules\n\t// should be fetched too.\n\tRecurseSubmodules SubmoduleRescursivity\n\t// Progress is where the human readable information sent by the server is\n\t// stored, if nil nothing is stored and the capability (if supported)\n\t// no-progress, is sent to the server to avoid send this information.\n\tProgress sideband.Progress\n\t// Force allows the pull to update a local branch even when the remote\n\t// branch does not descend from it.\n\tForce bool\n}\n\n// Validate validates the fields and sets the default values.\nfunc (o *PullOptions) Validate() error {\n\tif o.RemoteName == \"\" {\n\t\to.RemoteName = DefaultRemoteName\n\t}\n\n\tif o.ReferenceName == \"\" {\n\t\to.ReferenceName = plumbing.HEAD\n\t}\n\n\treturn nil\n}\n\ntype TagMode int\n\nconst (\n\tInvalidTagMode TagMode = iota\n\t// TagFollowing any tag that points into the histories being fetched is also\n\t// fetched. TagFollowing requires a server with `include-tag` capability\n\t// in order to fetch the annotated tags objects.\n\tTagFollowing\n\t// AllTags fetch all tags from the remote (i.e., fetch remote tags\n\t// refs/tags/* into local tags with the same name)\n\tAllTags\n\t//NoTags fetch no tags from the remote at all\n\tNoTags\n)\n\n// FetchOptions describes how a fetch should be performed\ntype FetchOptions struct {\n\t// Name of the remote to fetch from. Defaults to origin.\n\tRemoteName string\n\tRefSpecs   []config.RefSpec\n\t// Depth limit fetching to the specified number of commits from the tip of\n\t// each remote branch history.\n\tDepth int\n\t// Auth credentials, if required, to use with the remote repository.\n\tAuth transport.AuthMethod\n\t// Progress is where the human readable information sent by the server is\n\t// stored, if nil nothing is stored and the capability (if supported)\n\t// no-progress, is sent to the server to avoid send this information.\n\tProgress sideband.Progress\n\t// Tags describe how the tags will be fetched from the remote repository,\n\t// by default is TagFollowing.\n\tTags TagMode\n\t// Force allows the fetch to update a local branch even when the remote\n\t// branch does not descend from it.\n\tForce bool\n}\n\n// Validate validates the fields and sets the default values.\nfunc (o *FetchOptions) Validate() error {\n\tif o.RemoteName == \"\" {\n\t\to.RemoteName = DefaultRemoteName\n\t}\n\n\tif o.Tags == InvalidTagMode {\n\t\to.Tags = TagFollowing\n\t}\n\n\tfor _, r := range o.RefSpecs {\n\t\tif err := r.Validate(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// PushOptions describes how a push should be performed.\ntype PushOptions struct {\n\t// RemoteName is the name of the remote to be pushed to.\n\tRemoteName string\n\t// RefSpecs specify what destination ref to update with what source\n\t// object. A refspec with empty src can be used to delete a reference.\n\tRefSpecs []config.RefSpec\n\t// Auth credentials, if required, to use with the remote repository.\n\tAuth transport.AuthMethod\n\t// Progress is where the human readable information sent by the server is\n\t// stored, if nil nothing is stored.\n\tProgress sideband.Progress\n\t// Prune specify that remote refs that match given RefSpecs and that do\n\t// not exist locally will be removed.\n\tPrune bool\n}\n\n// Validate validates the fields and sets the default values.\nfunc (o *PushOptions) Validate() error {\n\tif o.RemoteName == \"\" {\n\t\to.RemoteName = DefaultRemoteName\n\t}\n\n\tif len(o.RefSpecs) == 0 {\n\t\to.RefSpecs = []config.RefSpec{\n\t\t\tconfig.RefSpec(config.DefaultPushRefSpec),\n\t\t}\n\t}\n\n\tfor _, r := range o.RefSpecs {\n\t\tif err := r.Validate(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// SubmoduleUpdateOptions describes how a submodule update should be performed.\ntype SubmoduleUpdateOptions struct {\n\t// Init, if true initializes the submodules recorded in the index.\n\tInit bool\n\t// NoFetch tell to the update command to not fetch new objects from the\n\t// remote site.\n\tNoFetch bool\n\t// RecurseSubmodules the update is performed not only in the submodules of\n\t// the current repository but also in any nested submodules inside those\n\t// submodules (and so on). Until the SubmoduleRescursivity is reached.\n\tRecurseSubmodules SubmoduleRescursivity\n\t// Auth credentials, if required, to use with the remote repository.\n\tAuth transport.AuthMethod\n}\n\nvar (\n\tErrBranchHashExclusive  = errors.New(\"Branch and Hash are mutually exclusive\")\n\tErrCreateRequiresBranch = errors.New(\"Branch is mandatory when Create is used\")\n)\n\n// CheckoutOptions describes how a checkout operation should be performed.\ntype CheckoutOptions struct {\n\t// Hash is the hash of the commit to be checked out. If used, HEAD will be\n\t// in detached mode. If Create is not used, Branch and Hash are mutually\n\t// exclusive.\n\tHash plumbing.Hash\n\t// Branch to be checked out, if Branch and Hash are empty is set to `master`.\n\tBranch plumbing.ReferenceName\n\t// Create a new branch named Branch and start it at Hash.\n\tCreate bool\n\t// Force, if true when switching branches, proceed even if the index or the\n\t// working tree differs from HEAD. This is used to throw away local changes\n\tForce bool\n\t// Keep, if true when switching branches, local changes (the index or the\n\t// working tree changes) will be kept so that they can be committed to the\n\t// target branch. Force and Keep are mutually exclusive, should not be both\n\t// set to true.\n\tKeep bool\n}\n\n// Validate validates the fields and sets the default values.\nfunc (o *CheckoutOptions) Validate() error {\n\tif !o.Create && !o.Hash.IsZero() && o.Branch != \"\" {\n\t\treturn ErrBranchHashExclusive\n\t}\n\n\tif o.Create && o.Branch == \"\" {\n\t\treturn ErrCreateRequiresBranch\n\t}\n\n\tif o.Branch == \"\" {\n\t\to.Branch = plumbing.Master\n\t}\n\n\treturn nil\n}\n\n// ResetMode defines the mode of a reset operation.\ntype ResetMode int8\n\nconst (\n\t// MixedReset resets the index but not the working tree (i.e., the changed\n\t// files are preserved but not marked for commit) and reports what has not\n\t// been updated. This is the default action.\n\tMixedReset ResetMode = iota\n\t// HardReset resets the index and working tree. Any changes to tracked files\n\t// in the working tree are discarded.\n\tHardReset\n\t// MergeReset resets the index and updates the files in the working tree\n\t// that are different between Commit and HEAD, but keeps those which are\n\t// different between the index and working tree (i.e. which have changes\n\t// which have not been added).\n\t//\n\t// If a file that is different between Commit and the index has unstaged\n\t// changes, reset is aborted.\n\tMergeReset\n\t// SoftReset does not touch the index file or the working tree at all (but\n\t// resets the head to <commit>, just like all modes do). This leaves all\n\t// your changed files \"Changes to be committed\", as git status would put it.\n\tSoftReset\n)\n\n// ResetOptions describes how a reset operation should be performed.\ntype ResetOptions struct {\n\t// Commit, if commit is present set the current branch head (HEAD) to it.\n\tCommit plumbing.Hash\n\t// Mode, form resets the current branch head to Commit and possibly updates\n\t// the index (resetting it to the tree of Commit) and the working tree\n\t// depending on Mode. If empty MixedReset is used.\n\tMode ResetMode\n}\n\n// Validate validates the fields and sets the default values.\nfunc (o *ResetOptions) Validate(r *Repository) error {\n\tif o.Commit == plumbing.ZeroHash {\n\t\tref, err := r.Head()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\to.Commit = ref.Hash()\n\t}\n\n\treturn nil\n}\n\ntype LogOrder int8\n\nconst (\n\tLogOrderDefault LogOrder = iota\n\tLogOrderDFS\n\tLogOrderDFSPost\n\tLogOrderBSF\n\tLogOrderCommitterTime\n)\n\n// LogOptions describes how a log action should be performed.\ntype LogOptions struct {\n\t// When the From option is set the log will only contain commits\n\t// reachable from it. If this option is not set, HEAD will be used as\n\t// the default From.\n\tFrom plumbing.Hash\n\n\t// The default traversal algorithm is Depth-first search\n\t// set Order=LogOrderCommitterTime for ordering by committer time (more compatible with `git log`)\n\t// set Order=LogOrderBSF for Breadth-first search\n\tOrder LogOrder\n\n\t// Show only those commits in which the specified file was inserted/updated.\n\t// It is equivalent to running `git log -- <file-name>`.\n\tFileName *string\n\n\t// Pretend as if all the refs in refs/, along with HEAD, are listed on the command line as <commit>.\n\t// It is equivalent to running `git log --all`.\n\t// If set on true, the From option will be ignored.\n\tAll bool\n\n\t// Show commits more recent than a specific date.\n\t// It is equivalent to running `git log --since <date>` or `git log --after <date>`.\n\tSince *time.Time\n\n\t// Show commits older than a specific date.\n\t// It is equivalent to running `git log --until <date>` or `git log --before <date>`.\n\tUntil *time.Time\n}\n\nvar (\n\tErrMissingAuthor = errors.New(\"author field is required\")\n)\n\n// CommitOptions describes how a commit operation should be performed.\ntype CommitOptions struct {\n\t// All automatically stage files that have been modified and deleted, but\n\t// new files you have not told Git about are not affected.\n\tAll bool\n\t// Author is the author's signature of the commit.\n\tAuthor *object.Signature\n\t// Committer is the committer's signature of the commit. If Committer is\n\t// nil the Author signature is used.\n\tCommitter *object.Signature\n\t// Parents are the parents commits for the new commit, by default when\n\t// len(Parents) is zero, the hash of HEAD reference is used.\n\tParents []plumbing.Hash\n\t// SignKey denotes a key to sign the commit with. A nil value here means the\n\t// commit will not be signed. The private key must be present and already\n\t// decrypted.\n\tSignKey *openpgp.Entity\n}\n\n// Validate validates the fields and sets the default values.\nfunc (o *CommitOptions) Validate(r *Repository) error {\n\tif o.Author == nil {\n\t\treturn ErrMissingAuthor\n\t}\n\n\tif o.Committer == nil {\n\t\to.Committer = o.Author\n\t}\n\n\tif len(o.Parents) == 0 {\n\t\thead, err := r.Head()\n\t\tif err != nil && err != plumbing.ErrReferenceNotFound {\n\t\t\treturn err\n\t\t}\n\n\t\tif head != nil {\n\t\t\to.Parents = []plumbing.Hash{head.Hash()}\n\t\t}\n\t}\n\n\treturn nil\n}\n\nvar (\n\tErrMissingName    = errors.New(\"name field is required\")\n\tErrMissingTagger  = errors.New(\"tagger field is required\")\n\tErrMissingMessage = errors.New(\"message field is required\")\n)\n\n// CreateTagOptions describes how a tag object should be created.\ntype CreateTagOptions struct {\n\t// Tagger defines the signature of the tag creator.\n\tTagger *object.Signature\n\t// Message defines the annotation of the tag. It is canonicalized during\n\t// validation into the format expected by git - no leading whitespace and\n\t// ending in a newline.\n\tMessage string\n\t// SignKey denotes a key to sign the tag with. A nil value here means the tag\n\t// will not be signed. The private key must be present and already decrypted.\n\tSignKey *openpgp.Entity\n}\n\n// Validate validates the fields and sets the default values.\nfunc (o *CreateTagOptions) Validate(r *Repository, hash plumbing.Hash) error {\n\tif o.Tagger == nil {\n\t\treturn ErrMissingTagger\n\t}\n\n\tif o.Message == \"\" {\n\t\treturn ErrMissingMessage\n\t}\n\n\t// Canonicalize the message into the expected message format.\n\to.Message = strings.TrimSpace(o.Message) + \"\\n\"\n\n\treturn nil\n}\n\n// ListOptions describes how a remote list should be performed.\ntype ListOptions struct {\n\t// Auth credentials, if required, to use with the remote repository.\n\tAuth transport.AuthMethod\n}\n\n// CleanOptions describes how a clean should be performed.\ntype CleanOptions struct {\n\tDir bool\n}\n\n// GrepOptions describes how a grep should be performed.\ntype GrepOptions struct {\n\t// Patterns are compiled Regexp objects to be matched.\n\tPatterns []*regexp.Regexp\n\t// InvertMatch selects non-matching lines.\n\tInvertMatch bool\n\t// CommitHash is the hash of the commit from which worktree should be derived.\n\tCommitHash plumbing.Hash\n\t// ReferenceName is the branch or tag name from which worktree should be derived.\n\tReferenceName plumbing.ReferenceName\n\t// PathSpecs are compiled Regexp objects of pathspec to use in the matching.\n\tPathSpecs []*regexp.Regexp\n}\n\nvar (\n\tErrHashOrReference = errors.New(\"ambiguous options, only one of CommitHash or ReferenceName can be passed\")\n)\n\n// Validate validates the fields and sets the default values.\nfunc (o *GrepOptions) Validate(w *Worktree) error {\n\tif !o.CommitHash.IsZero() && o.ReferenceName != \"\" {\n\t\treturn ErrHashOrReference\n\t}\n\n\t// If none of CommitHash and ReferenceName are provided, set commit hash of\n\t// the repository's head.\n\tif o.CommitHash.IsZero() && o.ReferenceName == \"\" {\n\t\tref, err := w.r.Head()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\to.CommitHash = ref.Hash()\n\t}\n\n\treturn nil\n}\n\n// PlainOpenOptions describes how opening a plain repository should be\n// performed.\ntype PlainOpenOptions struct {\n\t// DetectDotGit defines whether parent directories should be\n\t// walked until a .git directory or file is found.\n\tDetectDotGit bool\n}\n\n// Validate validates the fields and sets the default values.\nfunc (o *PlainOpenOptions) Validate() error { return nil }\n"
        },
        {
          "name": "options_test.go",
          "type": "blob",
          "size": 0.73046875,
          "content": "package git\n\nimport (\n\t. \"gopkg.in/check.v1\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/object\"\n)\n\ntype OptionsSuite struct {\n\tBaseSuite\n}\n\nvar _ = Suite(&OptionsSuite{})\n\nfunc (s *OptionsSuite) TestCommitOptionsParentsFromHEAD(c *C) {\n\to := CommitOptions{Author: &object.Signature{}}\n\terr := o.Validate(s.Repository)\n\tc.Assert(err, IsNil)\n\tc.Assert(o.Parents, HasLen, 1)\n}\n\nfunc (s *OptionsSuite) TestCommitOptionsMissingAuthor(c *C) {\n\to := CommitOptions{}\n\terr := o.Validate(s.Repository)\n\tc.Assert(err, Equals, ErrMissingAuthor)\n}\n\nfunc (s *OptionsSuite) TestCommitOptionsCommitter(c *C) {\n\tsig := &object.Signature{}\n\n\to := CommitOptions{Author: sig}\n\terr := o.Validate(s.Repository)\n\tc.Assert(err, IsNil)\n\n\tc.Assert(o.Committer, Equals, o.Author)\n}\n"
        },
        {
          "name": "plumbing",
          "type": "tree",
          "content": null
        },
        {
          "name": "prune.go",
          "type": "blob",
          "size": 1.64453125,
          "content": "package git\n\nimport (\n\t\"errors\"\n\t\"time\"\n\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/storer\"\n)\n\ntype PruneHandler func(unreferencedObjectHash plumbing.Hash) error\ntype PruneOptions struct {\n\t// OnlyObjectsOlderThan if set to non-zero value\n\t// selects only objects older than the time provided.\n\tOnlyObjectsOlderThan time.Time\n\t// Handler is called on matching objects\n\tHandler PruneHandler\n}\n\nvar ErrLooseObjectsNotSupported = errors.New(\"Loose objects not supported\")\n\n// DeleteObject deletes an object from a repository.\n// The type conveniently matches PruneHandler.\nfunc (r *Repository) DeleteObject(hash plumbing.Hash) error {\n\tlos, ok := r.Storer.(storer.LooseObjectStorer)\n\tif !ok {\n\t\treturn ErrLooseObjectsNotSupported\n\t}\n\n\treturn los.DeleteLooseObject(hash)\n}\n\nfunc (r *Repository) Prune(opt PruneOptions) error {\n\tlos, ok := r.Storer.(storer.LooseObjectStorer)\n\tif !ok {\n\t\treturn ErrLooseObjectsNotSupported\n\t}\n\n\tpw := newObjectWalker(r.Storer)\n\terr := pw.walkAllRefs()\n\tif err != nil {\n\t\treturn err\n\t}\n\t// Now walk all (loose) objects in storage.\n\treturn los.ForEachObjectHash(func(hash plumbing.Hash) error {\n\t\t// Get out if we have seen this object.\n\t\tif pw.isSeen(hash) {\n\t\t\treturn nil\n\t\t}\n\t\t// Otherwise it is a candidate for pruning.\n\t\t// Check out for too new objects next.\n\t\tif !opt.OnlyObjectsOlderThan.IsZero() {\n\t\t\t// Errors here are non-fatal. The object may be e.g. packed.\n\t\t\t// Or concurrently deleted. Skip such objects.\n\t\t\tt, err := los.LooseObjectTime(hash)\n\t\t\tif err != nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\t// Skip too new objects.\n\t\t\tif !t.Before(opt.OnlyObjectsOlderThan) {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\treturn opt.Handler(hash)\n\t})\n}\n"
        },
        {
          "name": "prune_test.go",
          "type": "blob",
          "size": 1.6533203125,
          "content": "package git\n\nimport (\n\t\"time\"\n\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/cache\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/storer\"\n\t\"gopkg.in/src-d/go-git.v4/storage\"\n\t\"gopkg.in/src-d/go-git.v4/storage/filesystem\"\n\n\t. \"gopkg.in/check.v1\"\n\t\"gopkg.in/src-d/go-git-fixtures.v3\"\n)\n\ntype PruneSuite struct {\n\tBaseSuite\n}\n\nvar _ = Suite(&PruneSuite{})\n\nfunc (s *PruneSuite) testPrune(c *C, deleteTime time.Time) {\n\tsrcFs := fixtures.ByTag(\"unpacked\").One().DotGit()\n\tvar sto storage.Storer\n\tvar err error\n\tsto = filesystem.NewStorage(srcFs, cache.NewObjectLRUDefault())\n\n\tlos := sto.(storer.LooseObjectStorer)\n\tc.Assert(los, NotNil)\n\n\tcount := 0\n\terr = los.ForEachObjectHash(func(_ plumbing.Hash) error {\n\t\tcount++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\n\tr, err := Open(sto, srcFs)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\t// Remove a branch so we can prune some objects.\n\terr = sto.RemoveReference(plumbing.ReferenceName(\"refs/heads/v4\"))\n\tc.Assert(err, IsNil)\n\terr = sto.RemoveReference(plumbing.ReferenceName(\"refs/remotes/origin/v4\"))\n\tc.Assert(err, IsNil)\n\n\terr = r.Prune(PruneOptions{\n\t\tOnlyObjectsOlderThan: deleteTime,\n\t\tHandler:              r.DeleteObject,\n\t})\n\tc.Assert(err, IsNil)\n\n\tnewCount := 0\n\terr = los.ForEachObjectHash(func(_ plumbing.Hash) error {\n\t\tnewCount++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\n\tif deleteTime.IsZero() {\n\t\tc.Assert(newCount < count, Equals, true)\n\t} else {\n\t\t// Assume a delete time older than any of the objects was passed in.\n\t\tc.Assert(newCount, Equals, count)\n\t}\n}\n\nfunc (s *PruneSuite) TestPrune(c *C) {\n\ts.testPrune(c, time.Time{})\n}\n\nfunc (s *PruneSuite) TestPruneWithNoDelete(c *C) {\n\ts.testPrune(c, time.Unix(0, 1))\n}\n"
        },
        {
          "name": "references.go",
          "type": "blob",
          "size": 6.7802734375,
          "content": "package git\n\nimport (\n\t\"io\"\n\t\"sort\"\n\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/object\"\n\t\"gopkg.in/src-d/go-git.v4/utils/diff\"\n\n\t\"github.com/sergi/go-diff/diffmatchpatch\"\n)\n\n// References returns a slice of Commits for the file at \"path\", starting from\n// the commit provided that contains the file from the provided path. The last\n// commit into the returned slice is the commit where the file was created.\n// If the provided commit does not contains the specified path, a nil slice is\n// returned. The commits are sorted in commit order, newer to older.\n//\n// Caveats:\n//\n// - Moves and copies are not currently supported.\n//\n// - Cherry-picks are not detected unless there are no commits between them and\n// therefore can appear repeated in the list. (see git path-id for hints on how\n// to fix this).\nfunc references(c *object.Commit, path string) ([]*object.Commit, error) {\n\tvar result []*object.Commit\n\tseen := make(map[plumbing.Hash]struct{})\n\tif err := walkGraph(&result, &seen, c, path); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// TODO result should be returned without ordering\n\tsortCommits(result)\n\n\t// for merges of identical cherry-picks\n\treturn removeComp(path, result, equivalent)\n}\n\ntype commitSorterer struct {\n\tl []*object.Commit\n}\n\nfunc (s commitSorterer) Len() int {\n\treturn len(s.l)\n}\n\nfunc (s commitSorterer) Less(i, j int) bool {\n\treturn s.l[i].Committer.When.Before(s.l[j].Committer.When) ||\n\t\ts.l[i].Committer.When.Equal(s.l[j].Committer.When) &&\n\t\t\ts.l[i].Author.When.Before(s.l[j].Author.When)\n}\n\nfunc (s commitSorterer) Swap(i, j int) {\n\ts.l[i], s.l[j] = s.l[j], s.l[i]\n}\n\n// SortCommits sorts a commit list by commit date, from older to newer.\nfunc sortCommits(l []*object.Commit) {\n\ts := &commitSorterer{l}\n\tsort.Sort(s)\n}\n\n// Recursive traversal of the commit graph, generating a linear history of the\n// path.\nfunc walkGraph(result *[]*object.Commit, seen *map[plumbing.Hash]struct{}, current *object.Commit, path string) error {\n\t// check and update seen\n\tif _, ok := (*seen)[current.Hash]; ok {\n\t\treturn nil\n\t}\n\t(*seen)[current.Hash] = struct{}{}\n\n\t// if the path is not in the current commit, stop searching.\n\tif _, err := current.File(path); err != nil {\n\t\treturn nil\n\t}\n\n\t// optimization: don't traverse branches that does not\n\t// contain the path.\n\tparents, err := parentsContainingPath(path, current)\n\tif err != nil {\n\t\treturn err\n\t}\n\tswitch len(parents) {\n\t// if the path is not found in any of its parents, the path was\n\t// created by this commit; we must add it to the revisions list and\n\t// stop searching. This includes the case when current is the\n\t// initial commit.\n\tcase 0:\n\t\t*result = append(*result, current)\n\t\treturn nil\n\tcase 1: // only one parent contains the path\n\t\t// if the file contents has change, add the current commit\n\t\tdifferent, err := differentContents(path, current, parents)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif len(different) == 1 {\n\t\t\t*result = append(*result, current)\n\t\t}\n\t\t// in any case, walk the parent\n\t\treturn walkGraph(result, seen, parents[0], path)\n\tdefault: // more than one parent contains the path\n\t\t// TODO: detect merges that had a conflict, because they must be\n\t\t// included in the result here.\n\t\tfor _, p := range parents {\n\t\t\terr := walkGraph(result, seen, p, path)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc parentsContainingPath(path string, c *object.Commit) ([]*object.Commit, error) {\n\t// TODO: benchmark this method making git.object.Commit.parent public instead of using\n\t// an iterator\n\tvar result []*object.Commit\n\titer := c.Parents()\n\tfor {\n\t\tparent, err := iter.Next()\n\t\tif err == io.EOF {\n\t\t\treturn result, nil\n\t\t}\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif _, err := parent.File(path); err == nil {\n\t\t\tresult = append(result, parent)\n\t\t}\n\t}\n}\n\n// Returns an slice of the commits in \"cs\" that has the file \"path\", but with different\n// contents than what can be found in \"c\".\nfunc differentContents(path string, c *object.Commit, cs []*object.Commit) ([]*object.Commit, error) {\n\tresult := make([]*object.Commit, 0, len(cs))\n\th, found := blobHash(path, c)\n\tif !found {\n\t\treturn nil, object.ErrFileNotFound\n\t}\n\tfor _, cx := range cs {\n\t\tif hx, found := blobHash(path, cx); found && h != hx {\n\t\t\tresult = append(result, cx)\n\t\t}\n\t}\n\treturn result, nil\n}\n\n// blobHash returns the hash of a path in a commit\nfunc blobHash(path string, commit *object.Commit) (hash plumbing.Hash, found bool) {\n\tfile, err := commit.File(path)\n\tif err != nil {\n\t\tvar empty plumbing.Hash\n\t\treturn empty, found\n\t}\n\treturn file.Hash, true\n}\n\ntype contentsComparatorFn func(path string, a, b *object.Commit) (bool, error)\n\n// Returns a new slice of commits, with duplicates removed.  Expects a\n// sorted commit list.  Duplication is defined according to \"comp\".  It\n// will always keep the first commit of a series of duplicated commits.\nfunc removeComp(path string, cs []*object.Commit, comp contentsComparatorFn) ([]*object.Commit, error) {\n\tresult := make([]*object.Commit, 0, len(cs))\n\tif len(cs) == 0 {\n\t\treturn result, nil\n\t}\n\tresult = append(result, cs[0])\n\tfor i := 1; i < len(cs); i++ {\n\t\tequals, err := comp(path, cs[i], cs[i-1])\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif !equals {\n\t\t\tresult = append(result, cs[i])\n\t\t}\n\t}\n\treturn result, nil\n}\n\n// Equivalent commits are commits whose patch is the same.\nfunc equivalent(path string, a, b *object.Commit) (bool, error) {\n\tnumParentsA := a.NumParents()\n\tnumParentsB := b.NumParents()\n\n\t// the first commit is not equivalent to anyone\n\t// and \"I think\" merges can not be equivalent to anything\n\tif numParentsA != 1 || numParentsB != 1 {\n\t\treturn false, nil\n\t}\n\n\tdiffsA, err := patch(a, path)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\tdiffsB, err := patch(b, path)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\treturn sameDiffs(diffsA, diffsB), nil\n}\n\nfunc patch(c *object.Commit, path string) ([]diffmatchpatch.Diff, error) {\n\t// get contents of the file in the commit\n\tfile, err := c.File(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tcontent, err := file.Contents()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// get contents of the file in the first parent of the commit\n\tvar contentParent string\n\titer := c.Parents()\n\tparent, err := iter.Next()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfile, err = parent.File(path)\n\tif err != nil {\n\t\tcontentParent = \"\"\n\t} else {\n\t\tcontentParent, err = file.Contents()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\t// compare the contents of parent and child\n\treturn diff.Do(content, contentParent), nil\n}\n\nfunc sameDiffs(a, b []diffmatchpatch.Diff) bool {\n\tif len(a) != len(b) {\n\t\treturn false\n\t}\n\tfor i := range a {\n\t\tif !sameDiff(a[i], b[i]) {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\nfunc sameDiff(a, b diffmatchpatch.Diff) bool {\n\tif a.Type != b.Type {\n\t\treturn false\n\t}\n\tswitch a.Type {\n\tcase 0:\n\t\treturn countLines(a.Text) == countLines(b.Text)\n\tcase 1, -1:\n\t\treturn a.Text == b.Text\n\tdefault:\n\t\tpanic(\"unreachable\")\n\t}\n}\n"
        },
        {
          "name": "references_test.go",
          "type": "blob",
          "size": 16.201171875,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/object\"\n\t\"gopkg.in/src-d/go-git.v4/storage/memory\"\n\n\t. \"gopkg.in/check.v1\"\n\t\"gopkg.in/src-d/go-git-fixtures.v3\"\n)\n\ntype ReferencesSuite struct {\n\tBaseSuite\n}\n\nvar _ = Suite(&ReferencesSuite{})\n\nvar referencesTests = [...]struct {\n\t// input data to revlist\n\trepo   string\n\tcommit string\n\tpath   string\n\t// expected output data form the revlist\n\trevs []string\n}{\n\t// Tyba git-fixture\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"binary.jpg\", []string{\n\t\t\"35e85108805c84807bc66a02d91535e1e24b38b9\",\n\t}},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"CHANGELOG\", []string{\n\t\t\"b8e471f58bcbca63b07bda20e428190409c2db47\",\n\t}},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"go/example.go\", []string{\n\t\t\"918c48b83bd081e863dbe1b80f8998f058cd8294\",\n\t}},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"json/long.json\", []string{\n\t\t\"af2d6a6954d532f8ffb47615169c8fdf9d383a1a\",\n\t}},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"json/short.json\", []string{\n\t\t\"af2d6a6954d532f8ffb47615169c8fdf9d383a1a\",\n\t}},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"LICENSE\", []string{\n\t\t\"b029517f6300c2da0f4b651b8642506cd6aaf45d\",\n\t}},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"php/crappy.php\", []string{\n\t\t\"918c48b83bd081e863dbe1b80f8998f058cd8294\",\n\t}},\n\t{\"https://github.com/git-fixtures/basic.git\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\", \"vendor/foo.go\", []string{\n\t\t\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t}},\n\t{\"https://github.com/jamesob/desk.git\", \"d4edaf0e8101fcea437ebd982d899fe2cc0f9f7b\", \"LICENSE\", []string{\n\t\t\"ffcda27c2de6768ee83f3f4a027fa4ab57d50f09\",\n\t}},\n\t{\"https://github.com/jamesob/desk.git\", \"d4edaf0e8101fcea437ebd982d899fe2cc0f9f7b\", \"README.md\", []string{\n\t\t\"ffcda27c2de6768ee83f3f4a027fa4ab57d50f09\",\n\t\t\"2e87a2dcc63a115f9a61bd969d1e85fb132a431b\",\n\t\t\"215b0ac06225b0671bc3460d10da88c3406f796f\",\n\t\t\"0260eb7a2623dd2309ab439f74e8681fccdc4285\",\n\t\t\"d46b48933e94f30992486374fa9a6becfd28ea17\",\n\t\t\"9cb4df2a88efee8836f9b8ad27ca2717f624164e\",\n\t\t\"8c49acdec2ed441706d8799f8b17878aae4c1ffe\",\n\t\t\"ebaca0c6f54c23193ee8175c3530e370cb2dabe3\",\n\t\t\"77675f82039551a19de4fbccbe69366fe63680df\",\n\t\t\"b9741594fb8ab7374f9be07d6a09a3bf96719816\",\n\t\t\"04db6acd94de714ca48128c606b17ee1149a630e\",\n\t\t\"ff737bd8a962a714a446d7592fae423a56e61e12\",\n\t\t\"eadd03f7a1cc54810bd10eef6747ad9562ad246d\",\n\t\t\"b5072ab5c1cf89191d71f1244eecc5d1f369ef7e\",\n\t\t\"bfa6ebc9948f1939402b063c0a2a24bf2b1c1cc3\",\n\t\t\"d9aef39828c670dfdb172502021a2ebcda8cf2fb\",\n\t\t\"1a6b6e45c91e1831494eb139ee3f8e21649c7fb0\",\n\t\t\"09fdbe4612066cf63ea46aee43c7cfaaff02ecfb\",\n\t\t\"236f6526b1150cc1f1723566b4738f443fc70777\",\n\t\t\"7862953f470b62397d22f6782a884f5bea6d760d\",\n\t\t\"b0b0152d08c2333680266977a5bc9c4e50e1e968\",\n\t\t\"13ce6c1c77c831f381974aa1c62008a414bd2b37\",\n\t\t\"d3f3c8faca048d11709969fbfc0cdf2901b87578\",\n\t\t\"8777dde1abe18c805d021366643218d3f3356dd9\",\n\t}},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"b32b2aecae2cfca4840dd480f8082da206a538da\", \"pylib/spinnaker/reconfigure_spinnaker.py\", []string{\n\t\t\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\",\n\t}},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"b32b2aecae2cfca4840dd480f8082da206a538da\", \"pylib/spinnaker/validate_configuration.py\", []string{\n\t\t\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\",\n\t\t\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\",\n\t\t\"1e3d328a2cabda5d0aaddc5dec65271343e0dc37\",\n\t\t\"b5d999e2986e190d81767cd3cfeda0260f9f6fb8\",\n\t}},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"b32b2aecae2cfca4840dd480f8082da206a538da\", \"pylib/spinnaker/fetch.py\", []string{\n\t\t\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\",\n\t}},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"b32b2aecae2cfca4840dd480f8082da206a538da\", \"pylib/spinnaker/yaml_util.py\", []string{\n\t\t\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\",\n\t\t\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\",\n\t\t\"b5d999e2986e190d81767cd3cfeda0260f9f6fb8\",\n\t\t\"023d4fb17b76e0fe0764971df8b8538b735a1d67\",\n\t}},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"b32b2aecae2cfca4840dd480f8082da206a538da\", \"dev/build_release.py\", []string{\n\t\t\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\",\n\t\t\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\",\n\t\t\"f42771ba298b93a7c4f5b16c5b30ab96c15305a8\",\n\t\t\"dd52703a50e71891f63fcf05df1f69836f4e7056\",\n\t\t\"0d9c9cef53af38cefcb6801bb492aaed3f2c9a42\",\n\t\t\"d375f1994ff4d0bdc32d614e698f1b50e1093f14\",\n\t\t\"abad497f11a366548aa95303c8c2f165fe7ae918\",\n\t\t\"6986d885626792dee4ef6b7474dfc9230c5bda54\",\n\t\t\"5422a86a10a8c5a1ef6728f5fc8894d9a4c54cb9\",\n\t\t\"09a4ea729b25714b6368959eea5113c99938f7b6\",\n\t}},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"b32b2aecae2cfca4840dd480f8082da206a538da\", \"pkg_scripts/postUninstall.sh\", []string{\n\t\t\"ce9f123d790717599aaeb76bc62510de437761be\",\n\t}},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"b32b2aecae2cfca4840dd480f8082da206a538da\", \"install/first_google_boot.sh\", []string{\n\t\t\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\",\n\t\t\"de25f576b888569192e6442b0202d30ca7b2d8ec\",\n\t\t\"a596972a661d9a7deca8abd18b52ce1a39516e89\",\n\t\t\"9467ec579708b3c71dd9e5b3906772841c144a30\",\n\t\t\"c4a9091e4076cb740fa46e790dd5b658e19012ad\",\n\t\t\"6eb5d9c5225224bfe59c401182a2939d6c27fc00\",\n\t\t\"495c7118e7cf757aa04eab410b64bfb5b5149ad2\",\n\t\t\"dd2d03c19658ff96d371aef00e75e2e54702da0e\",\n\t\t\"2a3b1d3b134e937c7bafdab6cc2950e264bf5dee\",\n\t\t\"a57b08a9072f6a865f760551be2a4944f72f804a\",\n\t\t\"0777fadf4ca6f458d7071de414f9bd5417911037\",\n\t}},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"b32b2aecae2cfca4840dd480f8082da206a538da\", \"install/install_spinnaker.sh\", []string{\n\t\t\"0d9c9cef53af38cefcb6801bb492aaed3f2c9a42\",\n\t}},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"b32b2aecae2cfca4840dd480f8082da206a538da\", \"install/install_fake_openjdk8.sh\", []string{\n\t\t\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\",\n\t}},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"b32b2aecae2cfca4840dd480f8082da206a538da\", \"install/install_spinnaker.py\", []string{\n\t\t\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\",\n\t\t\"37f94770d81232b1895fca447878f68d65aac652\",\n\t\t\"46c9dcbb55ca3f4735e82ad006e8cae2fdd050d9\",\n\t\t\"124a88cfda413cb7182ca9c739a284a9e50042a1\",\n\t\t\"eb4faf67a8b775d7985d07a708e3ffeac4273580\",\n\t\t\"0d9c9cef53af38cefcb6801bb492aaed3f2c9a42\",\n\t\t\"01171a8a2e843bef3a574ba73b258ac29e5d5405\",\n\t\t\"739d8c6fe16edcb6ef9185dc74197de561b84315\",\n\t\t\"d33c2d1e350b03fb989eefc612e8c9d5fa7cadc2\",\n\t}},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"b32b2aecae2cfca4840dd480f8082da206a538da\", \"install/__init__.py\", []string{\n\t\t\"a24001f6938d425d0e7504bdf5d27fc866a85c3d\",\n\t}},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"b32b2aecae2cfca4840dd480f8082da206a538da\", \"experimental/docker-compose/docker-compose.yml\", []string{\n\t\t\"fda357835d889595dc39dfebc6181d863cce7d4f\",\n\t\t\"57c59e7144354a76e1beba69ae2f85db6b1727af\",\n\t\t\"7682dff881029c722d893a112a64fea6849a0428\",\n\t\t\"66f1c938c380a4096674b27540086656076a597f\",\n\t\t\"56dc238f6f397e93f1d1aad702976889c830e8bf\",\n\t\t\"b95e442c064935709e789fa02126f17ddceef10b\",\n\t\t\"f98965a8f42037bd038b86c3401da7e6dfbf4f2e\",\n\t\t\"5344429749e8b68b168d2707b7903692436cc2ea\",\n\t\t\"6a31f5d219766b0cec4ea4fbbbfe47bdcdb0ab8e\",\n\t\t\"ddaae195b628150233b0a48f50a1674fd9d1a924\",\n\t\t\"7119ad9cf7d4e4d8b059e5337374baae4adc7458\",\n\t}},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"b32b2aecae2cfca4840dd480f8082da206a538da\", \"unittest/validate_configuration_test.py\", []string{\n\t\t\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\",\n\t\t\"1e3d328a2cabda5d0aaddc5dec65271343e0dc37\",\n\t}},\n\t{\"https://github.com/spinnaker/spinnaker.git\", \"f39d86f59a0781f130e8de6b2115329c1fbe9545\", \"README.adoc\", []string{\n\t\t\"638f61b3331695f46f1a88095e26dea0f09f176b\",\n\t\t\"bd42370d3fe8d410e78acb96f81cb3d838ad1c21\",\n\t\t\"d6905eab6fec1841c7cf8e4484499f5c8d7d423e\",\n\t\t\"c0a70a0f5aa494f0ae01c55ba191f2325556489a\",\n\t\t\"811795c8a185e88f5d269195cb68b29c8d0fe170\",\n\t\t\"d6e6fe0194447cc280f942d6a2e0521b68ea7796\",\n\t\t\"174bdbf9edfb0ca88415dd4a673852d5b22e7036\",\n\t\t\"9944d6cf72b8f82d622d85dad7434472bc8f397d\",\n\t\t\"e805183c72f0426fb073728c01901c2fd2db1da6\",\n\t\t\"8ef83dd443a05e9122681950399edaa58a38d466\",\n\t\t\"d73f9cee49a5ad27a42a6e18af7c49a8f28ad8a8\",\n\t}},\n\t// FAILS\n\t/*\n\t\t// this contains an empty move\n\t\t{\"https://github.com/spinnaker/spinnaker.git\", \"b32b2aecae2cfca4840dd480f8082da206a538da\", \"google/dev/build_google_tarball.py\", []string{\n\t\t\t\"88e60ac93f832efc2616b3c165e99a8f2ffc3e0c\",\n\t\t\t\"9e49443da49b8c862cc140b660744f84eebcfa51\",\n\t\t}},\n\t*/\n\t/*\n\t\t{\"https://github.com/spinnaker/spinnaker.git\", \"b32b2aecae2cfca4840dd480f8082da206a538da\", \"unittest/yaml_util_test.py\", []string{\n\t\t\t\"edf909edb9319c5e615e4ce73da47bbdca388ebe\",\n\t\t\t\"023d4fb17b76e0fe0764971df8b8538b735a1d67\",\n\t\t}},\n\t*/\n\t/*\n\t\t{\"https://github.com/spinnaker/spinnaker.git\", \"b32b2aecae2cfca4840dd480f8082da206a538da\", \"unittest/configurator_test.py\", []string{\n\t\t\t\"1e14f94bcf82694fdc7e2dcbbfdbbed58db0f4d9\",\n\t\t\t\"edf909edb9319c5e615e4ce73da47bbdca388ebe\",\n\t\t\t\"d14f793a6cd7169ef708a4fc276ad876bd3edd4e\",\n\t\t\t\"023d4fb17b76e0fe0764971df8b8538b735a1d67\",\n\t\t}},\n\t*/\n\t/*\n\t\t// this contains a cherry-pick at 094d0e7d5d691  (with 3f34438d)\n\t\t{\"https://github.com/jamesob/desk.git\", \"d4edaf0e8101fcea437ebd982d899fe2cc0f9f7b\", \"desk\", []string{\n\t\t\t\"ffcda27c2de6768ee83f3f4a027fa4ab57d50f09\",\n\t\t\t\"a0c1e853158ccbaf95574220bbf3b54509034a9f\",\n\t\t\t\"decfc524570c407d6bba0f217e534c8b47dbdbee\",\n\t\t\t\"1413872d5b3af7cd674bbe0e1f23387cd5d940e6\",\n\t\t\t\"40cd5a91d916e7b2f331e4e85fdc52636fd7cff7\",\n\t\t\t\"8e07d73aa0e3780f8c7cf8ad1a6b263df26a0a52\",\n\t\t\t\"19c56f95720ac3630efe9f29b1a252581d6cbc0c\",\n\t\t\t\"9ea46ccc6d253cffb4b7b66e936987d87de136e4\",\n\t\t\t\"094d0e7d5d69141c98a606910ba64786c5565da0\",\n\t\t\t\"801e62706a9e4fef75fcaca9c78744de0bc36e6a\",\n\t\t\t\"eddf335f31c73624ed3f40dc5fcad50136074b2b\",\n\t\t\t\"c659093f06eb2bd68c6252caeab605e5cd8aa49e\",\n\t\t\t\"d94b3fe8ce0e3a474874d742992d432cd040582f\",\n\t\t\t\"93cddf036df2d8509f910063696acd556ca7600f\",\n\t\t\t\"b3d4cb0c826b16b301f088581d681654d8de6c07\",\n\t\t\t\"52d90f9b513dd3c5330663cba39396e6b8a3ba4e\",\n\t\t\t\"15919e99ded03c6ceea9ff98558e77a322a4dadb\",\n\t\t\t\"803bf37847633e2f685a46a27b11facf22efebec\",\n\t\t\t\"c07ad524ee1e616c70bf2ea7a0ee4f4a01195d78\",\n\t\t\t\"b91aff30f318fda461d009c308490613b394f3e2\",\n\t\t\t\"67cec1e8a3f21c6eb11678e3f31ffd228b55b783\",\n\t\t\t\"bbe404c78af7525fabc57b9e7aa7c100b0d39f7a\",\n\t\t\t\"5dd078848786c2babc2511e9502fa98518cf3535\",\n\t\t\t\"7970ae7cc165c5205945dfb704d67d53031f550a\",\n\t\t\t\"33091ac904747747ff30f107d4d0f22fa872eccf\",\n\t\t\t\"069f81cab12d185ba1b509be946c47897cd4fb1f\",\n\t\t\t\"13ce6c1c77c831f381974aa1c62008a414bd2b37\",\n\t\t}},\n\t*/\n\t/*\n\t\t{\"https://github.com/spinnaker/spinnaker.git\", \"b32b2aecae2cfca4840dd480f8082da206a538da\", \"InstallSpinnaker.sh\", []string{\n\t\t\t\"ce9f123d790717599aaeb76bc62510de437761be\",\n\t\t\t\"23673af3ad70b50bba7fdafadc2323302f5ba520\",\n\t\t\t\"b7015a5d36990d69a054482556127b9c7404a24a\",\n\t\t\t\"582da9622e3a72a19cd261a017276d72b5b0051a\",\n\t\t\t\"0c5bb1e4392e751f884f3c57de5d4aee72c40031\",\n\t\t\t\"c9c2a0ec03968ab17e8b16fdec9661eb1dbea173\",\n\t\t\t\"a3cdf880826b4d9af42b93f4a2df29a91ab31d35\",\n\t\t\t\"18526c447f5174d33c96aac6d6433318b0e2021c\",\n\t\t\t\"2a6288be1c8ea160c443ca3cd0fe826ff2387d37\",\n\t\t\t\"9e74d009894d73dd07773ea6b3bdd8323db980f7\",\n\t\t\t\"d2f6214b625db706384b378a29cc4c22237db97a\",\n\t\t\t\"202a9c720b3ba8106e022a0ad027ebe279040c78\",\n\t\t\t\"791bcd1592828d9d5d16e83f3a825fb08b0ba22d\",\n\t\t\t\"01e65d67eed8afcb67a6bdf1c962541f62b299c9\",\n\t\t\t\"6328ee836affafc1b52127147b5ca07300ac78e6\",\n\t\t\t\"3de4f77c105f700f50d9549d32b9a05a01b46c4b\",\n\t\t\t\"8980daf661408a3faa1f22c225702a5c1d11d5c9\",\n\t\t\t\"8eb116de9128c314ac8a6f5310ca500b8c74f5db\",\n\t\t\t\"88e841aad37b71b78a8fb88bc75fe69499d527c7\",\n\t\t\t\"370d61cdbc1f3c90db6759f1599ccbabd40ad6c1\",\n\t\t\t\"505577dc87d300cf562dc4702a05a5615d90d855\",\n\t\t\t\"b5c6053a46993b20d1b91e7b7206bffa54669ad7\",\n\t\t\t\"ba486de7c025457963701114c683dcd4708e1dee\",\n\t\t\t\"b41d7c0e5b20bbe7c8eb6606731a3ff68f4e3941\",\n\t\t\t\"a47d0aaeda421f06df248ad65bd58230766bf118\",\n\t\t\t\"495c7118e7cf757aa04eab410b64bfb5b5149ad2\",\n\t\t\t\"46670eb6477c353d837dbaba3cf36c5f8b86f037\",\n\t\t\t\"dd2d03c19658ff96d371aef00e75e2e54702da0e\",\n\t\t\t\"4bbcad219ec55a465fb48ce236cb10ca52d43b1f\",\n\t\t\t\"50d0556563599366f29cb286525780004fa5a317\",\n\t\t\t\"9a06d3f20eabb254d0a1e2ff7735ef007ccd595e\",\n\t\t\t\"d4b48a39aba7d3bd3e8abef2274a95b112d1ae73\",\n\t\t}},\n\t*/\n\t/*\n\t\t{\"https://github.com/spinnaker/spinnaker.git\", \"b32b2aecae2cfca4840dd480f8082da206a538da\", \"config/default-spinnaker-local.yml\", []string{\n\t\t\t\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\",\n\t\t\t\"99534ecc895fe17a1d562bb3049d4168a04d0865\",\n\t\t\t\"caf6d62e8285d4681514dd8027356fb019bc97ff\",\n\t\t\t\"eaf7614cad81e8ab5c813dd4821129d0c04ea449\",\n\t\t\t\"5a2a845bc08974a36d599a4a4b7e25be833823b0\",\n\t\t\t\"41e96c54a478e5d09dd07ed7feb2d8d08d8c7e3c\",\n\t\t\t\"974b775a8978b120ff710cac93a21c7387b914c9\",\n\t\t\t\"87e459a9a044b3109dfeb943cc82c627b61d84a6\",\n\t\t\t\"5e09821cbd7d710405b61cab0a795c2982a71b9c\",\n\t\t\t\"8cc2d4bdb0a15aafc7fe02cdcb03ab90c974cafa\",\n\t\t\t\"3ce7b902a51bac2f10994f7d1f251b616c975e54\",\n\t\t\t\"a596972a661d9a7deca8abd18b52ce1a39516e89\",\n\t\t\t\"8980daf661408a3faa1f22c225702a5c1d11d5c9\",\n\t\t}},\n\t*/\n\t/*\n\t\t{\"https://github.com/spinnaker/spinnaker.git\", \"b32b2aecae2cfca4840dd480f8082da206a538da\", \"config/spinnaker.yml\", []string{\n\t\t\t\"ae904e8d60228c21c47368f6a10f1cc9ca3aeebf\",\n\t\t\t\"caf6d62e8285d4681514dd8027356fb019bc97ff\",\n\t\t\t\"eaf7614cad81e8ab5c813dd4821129d0c04ea449\",\n\t\t\t\"5a2a845bc08974a36d599a4a4b7e25be833823b0\",\n\t\t\t\"41e96c54a478e5d09dd07ed7feb2d8d08d8c7e3c\",\n\t\t\t\"974b775a8978b120ff710cac93a21c7387b914c9\",\n\t\t\t\"ed887f6547d7cd2b2d741184a06f97a0a704152b\",\n\t\t\t\"d4553dac205023fa77652308af1a2d1cf52138fb\",\n\t\t\t\"a596972a661d9a7deca8abd18b52ce1a39516e89\",\n\t\t\t\"66ac94f0b4442707fb6f695fbed91d62b3bd9d4a\",\n\t\t\t\"079e42e7c979541b6fab7343838f7b9fd4a360cd\",\n\t\t}},\n\t*/\n}\n\nfunc (s *ReferencesSuite) TestObjectNotFoundError(c *C) {\n\th1 := plumbing.NewHash(\"af2d6a6954d532f8ffb47615169c8fdf9d383a1a\")\n\thParent := plumbing.NewHash(\"1669dce138d9b841a518c64b10914d88f5e488ea\")\n\n\turl := fixtures.ByURL(\"https://github.com/git-fixtures/basic.git\").One().DotGit().Root()\n\tstorer := memory.NewStorage()\n\tr, err := Clone(storer, nil, &CloneOptions{\n\t\tURL: url,\n\t})\n\tc.Assert(err, IsNil)\n\n\tdelete(storer.Objects, hParent)\n\n\tcommit, err := r.CommitObject(h1)\n\tc.Assert(err, IsNil)\n\n\t_, err = references(commit, \"LICENSE\")\n\tc.Assert(err, Equals, plumbing.ErrObjectNotFound)\n}\n\nfunc (s *ReferencesSuite) TestRevList(c *C) {\n\tfor _, t := range referencesTests {\n\t\tr := s.NewRepositoryFromPackfile(fixtures.ByURL(t.repo).One())\n\n\t\tcommit, err := r.CommitObject(plumbing.NewHash(t.commit))\n\t\tc.Assert(err, IsNil)\n\n\t\trevs, err := references(commit, t.path)\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(len(revs), Equals, len(t.revs))\n\n\t\tfor i := range revs {\n\t\t\tif revs[i].Hash.String() != t.revs[i] {\n\t\t\t\tcommit, err := s.Repository.CommitObject(plumbing.NewHash(t.revs[i]))\n\t\t\t\tc.Assert(err, IsNil)\n\t\t\t\tequiv, err := equivalent(t.path, revs[i], commit)\n\t\t\t\tc.Assert(err, IsNil)\n\t\t\t\tif equiv {\n\t\t\t\t\tfmt.Printf(\"cherry-pick detected: %s    %s\\n\", revs[i].Hash.String(), t.revs[i])\n\t\t\t\t} else {\n\t\t\t\t\tc.Fatalf(\"\\nrepo=%s, commit=%s, path=%s, \\n%s\",\n\t\t\t\t\t\tt.repo, t.commit, t.path, compareSideBySide(t.revs, revs))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\n// same length is assumed\nfunc compareSideBySide(a []string, b []*object.Commit) string {\n\tvar buf bytes.Buffer\n\tbuf.WriteString(\"\\t              EXPECTED                                          OBTAINED        \")\n\tvar sep string\n\tvar obt string\n\tfor i := range a {\n\t\tobt = b[i].Hash.String()\n\t\tif a[i] != obt {\n\t\t\tsep = \"------\"\n\t\t} else {\n\t\t\tsep = \"      \"\n\t\t}\n\t\tbuf.WriteString(fmt.Sprintf(\"\\n%d\", i+1))\n\t\tbuf.WriteString(sep)\n\t\tbuf.WriteString(a[i])\n\t\tbuf.WriteString(sep)\n\t\tbuf.WriteString(obt)\n\t}\n\treturn buf.String()\n}\n\nvar cherryPicks = [...][]string{\n\t// repo, path, commit a, commit b\n\t{\"https://github.com/jamesob/desk.git\", \"desk\", \"094d0e7d5d69141c98a606910ba64786c5565da0\", \"3f34438d54f4a1ca86db8c0f03ed8eb38f20e22c\"},\n}\n\n// should detect cherry picks\nfunc (s *ReferencesSuite) TestEquivalent(c *C) {\n\tfor _, t := range cherryPicks {\n\t\tcs := s.commits(c, t[0], t[2], t[3])\n\t\tequiv, err := equivalent(t[1], cs[0], cs[1])\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(equiv, Equals, true, Commentf(\"repo=%s, file=%s, a=%s b=%s\", t[0], t[1], t[2], t[3]))\n\t}\n}\n\n// returns the commits from a slice of hashes\nfunc (s *ReferencesSuite) commits(c *C, repo string, hs ...string) []*object.Commit {\n\tr := s.NewRepositoryFromPackfile(fixtures.ByURL(repo).One())\n\n\tresult := make([]*object.Commit, 0, len(hs))\n\tfor _, h := range hs {\n\t\tcommit, err := r.CommitObject(plumbing.NewHash(h))\n\t\tc.Assert(err, IsNil)\n\n\t\tresult = append(result, commit)\n\t}\n\n\treturn result\n}\n"
        },
        {
          "name": "remote.go",
          "type": "blob",
          "size": 23.7451171875,
          "content": "package git\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\n\t\"gopkg.in/src-d/go-billy.v4/osfs\"\n\t\"gopkg.in/src-d/go-git.v4/config\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/cache\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/format/packfile\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/object\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/protocol/packp\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/protocol/packp/capability\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/protocol/packp/sideband\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/revlist\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/storer\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/transport\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/transport/client\"\n\t\"gopkg.in/src-d/go-git.v4/storage\"\n\t\"gopkg.in/src-d/go-git.v4/storage/filesystem\"\n\t\"gopkg.in/src-d/go-git.v4/storage/memory\"\n\t\"gopkg.in/src-d/go-git.v4/utils/ioutil\"\n)\n\nvar (\n\tNoErrAlreadyUpToDate     = errors.New(\"already up-to-date\")\n\tErrDeleteRefNotSupported = errors.New(\"server does not support delete-refs\")\n\tErrForceNeeded           = errors.New(\"some refs were not updated\")\n)\n\nconst (\n\t// This describes the maximum number of commits to walk when\n\t// computing the haves to send to a server, for each ref in the\n\t// repo containing this remote, when not using the multi-ack\n\t// protocol.  Setting this to 0 means there is no limit.\n\tmaxHavesToVisitPerRef = 100\n)\n\n// Remote represents a connection to a remote repository.\ntype Remote struct {\n\tc *config.RemoteConfig\n\ts storage.Storer\n}\n\n// NewRemote creates a new Remote.\n// The intended purpose is to use the Remote for tasks such as listing remote references (like using git ls-remote).\n// Otherwise Remotes should be created via the use of a Repository.\nfunc NewRemote(s storage.Storer, c *config.RemoteConfig) *Remote {\n\treturn &Remote{s: s, c: c}\n}\n\n// Config returns the RemoteConfig object used to instantiate this Remote.\nfunc (r *Remote) Config() *config.RemoteConfig {\n\treturn r.c\n}\n\nfunc (r *Remote) String() string {\n\tvar fetch, push string\n\tif len(r.c.URLs) > 0 {\n\t\tfetch = r.c.URLs[0]\n\t\tpush = r.c.URLs[0]\n\t}\n\n\treturn fmt.Sprintf(\"%s\\t%s (fetch)\\n%[1]s\\t%[3]s (push)\", r.c.Name, fetch, push)\n}\n\n// Push performs a push to the remote. Returns NoErrAlreadyUpToDate if the\n// remote was already up-to-date.\nfunc (r *Remote) Push(o *PushOptions) error {\n\treturn r.PushContext(context.Background(), o)\n}\n\n// PushContext performs a push to the remote. Returns NoErrAlreadyUpToDate if\n// the remote was already up-to-date.\n//\n// The provided Context must be non-nil. If the context expires before the\n// operation is complete, an error is returned. The context only affects to the\n// transport operations.\nfunc (r *Remote) PushContext(ctx context.Context, o *PushOptions) (err error) {\n\tif err := o.Validate(); err != nil {\n\t\treturn err\n\t}\n\n\tif o.RemoteName != r.c.Name {\n\t\treturn fmt.Errorf(\"remote names don't match: %s != %s\", o.RemoteName, r.c.Name)\n\t}\n\n\ts, err := newSendPackSession(r.c.URLs[0], o.Auth)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdefer ioutil.CheckClose(s, &err)\n\n\tar, err := s.AdvertisedReferences()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tremoteRefs, err := ar.AllReferences()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tisDelete := false\n\tallDelete := true\n\tfor _, rs := range o.RefSpecs {\n\t\tif rs.IsDelete() {\n\t\t\tisDelete = true\n\t\t} else {\n\t\t\tallDelete = false\n\t\t}\n\t\tif isDelete && !allDelete {\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif isDelete && !ar.Capabilities.Supports(capability.DeleteRefs) {\n\t\treturn ErrDeleteRefNotSupported\n\t}\n\n\tlocalRefs, err := r.references()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treq, err := r.newReferenceUpdateRequest(o, localRefs, remoteRefs, ar)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif len(req.Commands) == 0 {\n\t\treturn NoErrAlreadyUpToDate\n\t}\n\n\tobjects := objectsToPush(req.Commands)\n\n\thaves, err := referencesToHashes(remoteRefs)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tstop, err := r.s.Shallow()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// if we have shallow we should include this as part of the objects that\n\t// we are aware.\n\thaves = append(haves, stop...)\n\n\tvar hashesToPush []plumbing.Hash\n\t// Avoid the expensive revlist operation if we're only doing deletes.\n\tif !allDelete {\n\t\tif r.c.IsFirstURLLocal() {\n\t\t\t// If we're are pushing to a local repo, it might be much\n\t\t\t// faster to use a local storage layer to get the commits\n\t\t\t// to ignore, when calculating the object revlist.\n\t\t\tlocalStorer := filesystem.NewStorage(\n\t\t\t\tosfs.New(r.c.URLs[0]), cache.NewObjectLRUDefault())\n\t\t\thashesToPush, err = revlist.ObjectsWithStorageForIgnores(\n\t\t\t\tr.s, localStorer, objects, haves)\n\t\t} else {\n\t\t\thashesToPush, err = revlist.Objects(r.s, objects, haves)\n\t\t}\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif len(hashesToPush) == 0 {\n\t\tallDelete = true\n\t\tfor _, command := range req.Commands {\n\t\t\tif command.Action() != packp.Delete {\n\t\t\t\tallDelete = false\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\trs, err := pushHashes(ctx, s, r.s, req, hashesToPush, r.useRefDeltas(ar), allDelete)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err = rs.Error(); err != nil {\n\t\treturn err\n\t}\n\n\treturn r.updateRemoteReferenceStorage(req, rs)\n}\n\nfunc (r *Remote) useRefDeltas(ar *packp.AdvRefs) bool {\n\treturn !ar.Capabilities.Supports(capability.OFSDelta)\n}\n\nfunc (r *Remote) newReferenceUpdateRequest(\n\to *PushOptions,\n\tlocalRefs []*plumbing.Reference,\n\tremoteRefs storer.ReferenceStorer,\n\tar *packp.AdvRefs,\n) (*packp.ReferenceUpdateRequest, error) {\n\treq := packp.NewReferenceUpdateRequestFromCapabilities(ar.Capabilities)\n\n\tif o.Progress != nil {\n\t\treq.Progress = o.Progress\n\t\tif ar.Capabilities.Supports(capability.Sideband64k) {\n\t\t\treq.Capabilities.Set(capability.Sideband64k)\n\t\t} else if ar.Capabilities.Supports(capability.Sideband) {\n\t\t\treq.Capabilities.Set(capability.Sideband)\n\t\t}\n\t}\n\n\tif err := r.addReferencesToUpdate(o.RefSpecs, localRefs, remoteRefs, req, o.Prune); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn req, nil\n}\n\nfunc (r *Remote) updateRemoteReferenceStorage(\n\treq *packp.ReferenceUpdateRequest,\n\tresult *packp.ReportStatus,\n) error {\n\n\tfor _, spec := range r.c.Fetch {\n\t\tfor _, c := range req.Commands {\n\t\t\tif !spec.Match(c.Name) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tlocal := spec.Dst(c.Name)\n\t\t\tref := plumbing.NewHashReference(local, c.New)\n\t\t\tswitch c.Action() {\n\t\t\tcase packp.Create, packp.Update:\n\t\t\t\tif err := r.s.SetReference(ref); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\tcase packp.Delete:\n\t\t\t\tif err := r.s.RemoveReference(local); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// FetchContext fetches references along with the objects necessary to complete\n// their histories.\n//\n// Returns nil if the operation is successful, NoErrAlreadyUpToDate if there are\n// no changes to be fetched, or an error.\n//\n// The provided Context must be non-nil. If the context expires before the\n// operation is complete, an error is returned. The context only affects to the\n// transport operations.\nfunc (r *Remote) FetchContext(ctx context.Context, o *FetchOptions) error {\n\t_, err := r.fetch(ctx, o)\n\treturn err\n}\n\n// Fetch fetches references along with the objects necessary to complete their\n// histories.\n//\n// Returns nil if the operation is successful, NoErrAlreadyUpToDate if there are\n// no changes to be fetched, or an error.\nfunc (r *Remote) Fetch(o *FetchOptions) error {\n\treturn r.FetchContext(context.Background(), o)\n}\n\nfunc (r *Remote) fetch(ctx context.Context, o *FetchOptions) (sto storer.ReferenceStorer, err error) {\n\tif o.RemoteName == \"\" {\n\t\to.RemoteName = r.c.Name\n\t}\n\n\tif err = o.Validate(); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif len(o.RefSpecs) == 0 {\n\t\to.RefSpecs = r.c.Fetch\n\t}\n\n\ts, err := newUploadPackSession(r.c.URLs[0], o.Auth)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdefer ioutil.CheckClose(s, &err)\n\n\tar, err := s.AdvertisedReferences()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treq, err := r.newUploadPackRequest(o, ar)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tremoteRefs, err := ar.AllReferences()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tlocalRefs, err := r.references()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\trefs, err := calculateRefs(o.RefSpecs, remoteRefs, o.Tags)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treq.Wants, err = getWants(r.s, refs)\n\tif len(req.Wants) > 0 {\n\t\treq.Haves, err = getHaves(localRefs, remoteRefs, r.s)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tif err = r.fetchPack(ctx, o, s, req); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tupdated, err := r.updateLocalReferenceStorage(o.RefSpecs, refs, remoteRefs, o.Tags, o.Force)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif !updated {\n\t\treturn remoteRefs, NoErrAlreadyUpToDate\n\t}\n\n\treturn remoteRefs, nil\n}\n\nfunc newUploadPackSession(url string, auth transport.AuthMethod) (transport.UploadPackSession, error) {\n\tc, ep, err := newClient(url)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn c.NewUploadPackSession(ep, auth)\n}\n\nfunc newSendPackSession(url string, auth transport.AuthMethod) (transport.ReceivePackSession, error) {\n\tc, ep, err := newClient(url)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn c.NewReceivePackSession(ep, auth)\n}\n\nfunc newClient(url string) (transport.Transport, *transport.Endpoint, error) {\n\tep, err := transport.NewEndpoint(url)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tc, err := client.NewClient(ep)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\treturn c, ep, err\n}\n\nfunc (r *Remote) fetchPack(ctx context.Context, o *FetchOptions, s transport.UploadPackSession,\n\treq *packp.UploadPackRequest) (err error) {\n\n\treader, err := s.UploadPack(ctx, req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdefer ioutil.CheckClose(reader, &err)\n\n\tif err = r.updateShallow(o, reader); err != nil {\n\t\treturn err\n\t}\n\n\tif err = packfile.UpdateObjectStorage(r.s,\n\t\tbuildSidebandIfSupported(req.Capabilities, reader, o.Progress),\n\t); err != nil {\n\t\treturn err\n\t}\n\n\treturn err\n}\n\nfunc (r *Remote) addReferencesToUpdate(\n\trefspecs []config.RefSpec,\n\tlocalRefs []*plumbing.Reference,\n\tremoteRefs storer.ReferenceStorer,\n\treq *packp.ReferenceUpdateRequest,\n\tprune bool,\n) error {\n\t// This references dictionary will be used to search references by name.\n\trefsDict := make(map[string]*plumbing.Reference)\n\tfor _, ref := range localRefs {\n\t\trefsDict[ref.Name().String()] = ref\n\t}\n\n\tfor _, rs := range refspecs {\n\t\tif rs.IsDelete() {\n\t\t\tif err := r.deleteReferences(rs, remoteRefs, refsDict, req, false); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t} else {\n\t\t\terr := r.addOrUpdateReferences(rs, localRefs, refsDict, remoteRefs, req)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tif prune {\n\t\t\t\tif err := r.deleteReferences(rs, remoteRefs, refsDict, req, true); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (r *Remote) addOrUpdateReferences(\n\trs config.RefSpec,\n\tlocalRefs []*plumbing.Reference,\n\trefsDict map[string]*plumbing.Reference,\n\tremoteRefs storer.ReferenceStorer,\n\treq *packp.ReferenceUpdateRequest,\n) error {\n\t// If it is not a wilcard refspec we can directly search for the reference\n\t// in the references dictionary.\n\tif !rs.IsWildcard() {\n\t\tref, ok := refsDict[rs.Src()]\n\t\tif !ok {\n\t\t\treturn nil\n\t\t}\n\n\t\treturn r.addReferenceIfRefSpecMatches(rs, remoteRefs, ref, req)\n\t}\n\n\tfor _, ref := range localRefs {\n\t\terr := r.addReferenceIfRefSpecMatches(rs, remoteRefs, ref, req)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (r *Remote) deleteReferences(rs config.RefSpec,\n\tremoteRefs storer.ReferenceStorer,\n\trefsDict map[string]*plumbing.Reference,\n\treq *packp.ReferenceUpdateRequest,\n\tprune bool) error {\n\titer, err := remoteRefs.IterReferences()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn iter.ForEach(func(ref *plumbing.Reference) error {\n\t\tif ref.Type() != plumbing.HashReference {\n\t\t\treturn nil\n\t\t}\n\n\t\tif prune {\n\t\t\trs := rs.Reverse()\n\t\t\tif !rs.Match(ref.Name()) {\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\tif _, ok := refsDict[rs.Dst(ref.Name()).String()]; ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t} else {\n\t\t\tif rs.Dst(\"\") != ref.Name() {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\n\t\tcmd := &packp.Command{\n\t\t\tName: ref.Name(),\n\t\t\tOld:  ref.Hash(),\n\t\t\tNew:  plumbing.ZeroHash,\n\t\t}\n\t\treq.Commands = append(req.Commands, cmd)\n\t\treturn nil\n\t})\n}\n\nfunc (r *Remote) addReferenceIfRefSpecMatches(rs config.RefSpec,\n\tremoteRefs storer.ReferenceStorer, localRef *plumbing.Reference,\n\treq *packp.ReferenceUpdateRequest) error {\n\n\tif localRef.Type() != plumbing.HashReference {\n\t\treturn nil\n\t}\n\n\tif !rs.Match(localRef.Name()) {\n\t\treturn nil\n\t}\n\n\tcmd := &packp.Command{\n\t\tName: rs.Dst(localRef.Name()),\n\t\tOld:  plumbing.ZeroHash,\n\t\tNew:  localRef.Hash(),\n\t}\n\n\tremoteRef, err := remoteRefs.Reference(cmd.Name)\n\tif err == nil {\n\t\tif remoteRef.Type() != plumbing.HashReference {\n\t\t\t//TODO: check actual git behavior here\n\t\t\treturn nil\n\t\t}\n\n\t\tcmd.Old = remoteRef.Hash()\n\t} else if err != plumbing.ErrReferenceNotFound {\n\t\treturn err\n\t}\n\n\tif cmd.Old == cmd.New {\n\t\treturn nil\n\t}\n\n\tif !rs.IsForceUpdate() {\n\t\tif err := checkFastForwardUpdate(r.s, remoteRefs, cmd); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treq.Commands = append(req.Commands, cmd)\n\treturn nil\n}\n\nfunc (r *Remote) references() ([]*plumbing.Reference, error) {\n\tvar localRefs []*plumbing.Reference\n\titer, err := r.s.IterReferences()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor {\n\t\tref, err := iter.Next()\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tlocalRefs = append(localRefs, ref)\n\t}\n\n\treturn localRefs, nil\n}\n\nfunc getRemoteRefsFromStorer(remoteRefStorer storer.ReferenceStorer) (\n\tmap[plumbing.Hash]bool, error) {\n\tremoteRefs := map[plumbing.Hash]bool{}\n\titer, err := remoteRefStorer.IterReferences()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = iter.ForEach(func(ref *plumbing.Reference) error {\n\t\tif ref.Type() != plumbing.HashReference {\n\t\t\treturn nil\n\t\t}\n\t\tremoteRefs[ref.Hash()] = true\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn remoteRefs, nil\n}\n\n// getHavesFromRef populates the given `haves` map with the given\n// reference, and up to `maxHavesToVisitPerRef` ancestor commits.\nfunc getHavesFromRef(\n\tref *plumbing.Reference,\n\tremoteRefs map[plumbing.Hash]bool,\n\ts storage.Storer,\n\thaves map[plumbing.Hash]bool,\n) error {\n\th := ref.Hash()\n\tif haves[h] {\n\t\treturn nil\n\t}\n\n\t// No need to load the commit if we know the remote already\n\t// has this hash.\n\tif remoteRefs[h] {\n\t\thaves[h] = true\n\t\treturn nil\n\t}\n\n\tcommit, err := object.GetCommit(s, h)\n\tif err != nil {\n\t\t// Ignore the error if this isn't a commit.\n\t\thaves[ref.Hash()] = true\n\t\treturn nil\n\t}\n\n\t// Until go-git supports proper commit negotiation during an\n\t// upload pack request, include up to `maxHavesToVisitPerRef`\n\t// commits from the history of each ref.\n\twalker := object.NewCommitPreorderIter(commit, haves, nil)\n\ttoVisit := maxHavesToVisitPerRef\n\treturn walker.ForEach(func(c *object.Commit) error {\n\t\thaves[c.Hash] = true\n\t\ttoVisit--\n\t\t// If toVisit starts out at 0 (indicating there is no\n\t\t// max), then it will be negative here and we won't stop\n\t\t// early.\n\t\tif toVisit == 0 || remoteRefs[c.Hash] {\n\t\t\treturn storer.ErrStop\n\t\t}\n\t\treturn nil\n\t})\n}\n\nfunc getHaves(\n\tlocalRefs []*plumbing.Reference,\n\tremoteRefStorer storer.ReferenceStorer,\n\ts storage.Storer,\n) ([]plumbing.Hash, error) {\n\thaves := map[plumbing.Hash]bool{}\n\n\t// Build a map of all the remote references, to avoid loading too\n\t// many parent commits for references we know don't need to be\n\t// transferred.\n\tremoteRefs, err := getRemoteRefsFromStorer(remoteRefStorer)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, ref := range localRefs {\n\t\tif haves[ref.Hash()] {\n\t\t\tcontinue\n\t\t}\n\n\t\tif ref.Type() != plumbing.HashReference {\n\t\t\tcontinue\n\t\t}\n\n\t\terr = getHavesFromRef(ref, remoteRefs, s, haves)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tvar result []plumbing.Hash\n\tfor h := range haves {\n\t\tresult = append(result, h)\n\t}\n\n\treturn result, nil\n}\n\nconst refspecAllTags = \"+refs/tags/*:refs/tags/*\"\n\nfunc calculateRefs(\n\tspec []config.RefSpec,\n\tremoteRefs storer.ReferenceStorer,\n\ttagMode TagMode,\n) (memory.ReferenceStorage, error) {\n\tif tagMode == AllTags {\n\t\tspec = append(spec, refspecAllTags)\n\t}\n\n\trefs := make(memory.ReferenceStorage)\n\tfor _, s := range spec {\n\t\tif err := doCalculateRefs(s, remoteRefs, refs); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn refs, nil\n}\n\nfunc doCalculateRefs(\n\ts config.RefSpec,\n\tremoteRefs storer.ReferenceStorer,\n\trefs memory.ReferenceStorage,\n) error {\n\titer, err := remoteRefs.IterReferences()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvar matched bool\n\terr = iter.ForEach(func(ref *plumbing.Reference) error {\n\t\tif !s.Match(ref.Name()) {\n\t\t\treturn nil\n\t\t}\n\n\t\tif ref.Type() == plumbing.SymbolicReference {\n\t\t\ttarget, err := storer.ResolveReference(remoteRefs, ref.Name())\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tref = plumbing.NewHashReference(ref.Name(), target.Hash())\n\t\t}\n\n\t\tif ref.Type() != plumbing.HashReference {\n\t\t\treturn nil\n\t\t}\n\n\t\tmatched = true\n\t\tif err := refs.SetReference(ref); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif !s.IsWildcard() {\n\t\t\treturn storer.ErrStop\n\t\t}\n\n\t\treturn nil\n\t})\n\n\tif !matched && !s.IsWildcard() {\n\t\treturn fmt.Errorf(\"couldn't find remote ref %q\", s.Src())\n\t}\n\n\treturn err\n}\n\nfunc getWants(localStorer storage.Storer, refs memory.ReferenceStorage) ([]plumbing.Hash, error) {\n\twants := map[plumbing.Hash]bool{}\n\tfor _, ref := range refs {\n\t\thash := ref.Hash()\n\t\texists, err := objectExists(localStorer, ref.Hash())\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tif !exists {\n\t\t\twants[hash] = true\n\t\t}\n\t}\n\n\tvar result []plumbing.Hash\n\tfor h := range wants {\n\t\tresult = append(result, h)\n\t}\n\n\treturn result, nil\n}\n\nfunc objectExists(s storer.EncodedObjectStorer, h plumbing.Hash) (bool, error) {\n\t_, err := s.EncodedObject(plumbing.AnyObject, h)\n\tif err == plumbing.ErrObjectNotFound {\n\t\treturn false, nil\n\t}\n\n\treturn true, err\n}\n\nfunc checkFastForwardUpdate(s storer.EncodedObjectStorer, remoteRefs storer.ReferenceStorer, cmd *packp.Command) error {\n\tif cmd.Old == plumbing.ZeroHash {\n\t\t_, err := remoteRefs.Reference(cmd.Name)\n\t\tif err == plumbing.ErrReferenceNotFound {\n\t\t\treturn nil\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn fmt.Errorf(\"non-fast-forward update: %s\", cmd.Name.String())\n\t}\n\n\tff, err := isFastForward(s, cmd.Old, cmd.New)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif !ff {\n\t\treturn fmt.Errorf(\"non-fast-forward update: %s\", cmd.Name.String())\n\t}\n\n\treturn nil\n}\n\nfunc isFastForward(s storer.EncodedObjectStorer, old, new plumbing.Hash) (bool, error) {\n\tc, err := object.GetCommit(s, new)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tfound := false\n\titer := object.NewCommitPreorderIter(c, nil, nil)\n\terr = iter.ForEach(func(c *object.Commit) error {\n\t\tif c.Hash != old {\n\t\t\treturn nil\n\t\t}\n\n\t\tfound = true\n\t\treturn storer.ErrStop\n\t})\n\treturn found, err\n}\n\nfunc (r *Remote) newUploadPackRequest(o *FetchOptions,\n\tar *packp.AdvRefs) (*packp.UploadPackRequest, error) {\n\n\treq := packp.NewUploadPackRequestFromCapabilities(ar.Capabilities)\n\n\tif o.Depth != 0 {\n\t\treq.Depth = packp.DepthCommits(o.Depth)\n\t\tif err := req.Capabilities.Set(capability.Shallow); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif o.Progress == nil && ar.Capabilities.Supports(capability.NoProgress) {\n\t\tif err := req.Capabilities.Set(capability.NoProgress); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tisWildcard := true\n\tfor _, s := range o.RefSpecs {\n\t\tif !s.IsWildcard() {\n\t\t\tisWildcard = false\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif isWildcard && o.Tags == TagFollowing && ar.Capabilities.Supports(capability.IncludeTag) {\n\t\tif err := req.Capabilities.Set(capability.IncludeTag); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn req, nil\n}\n\nfunc buildSidebandIfSupported(l *capability.List, reader io.Reader, p sideband.Progress) io.Reader {\n\tvar t sideband.Type\n\n\tswitch {\n\tcase l.Supports(capability.Sideband):\n\t\tt = sideband.Sideband\n\tcase l.Supports(capability.Sideband64k):\n\t\tt = sideband.Sideband64k\n\tdefault:\n\t\treturn reader\n\t}\n\n\td := sideband.NewDemuxer(t, reader)\n\td.Progress = p\n\n\treturn d\n}\n\nfunc (r *Remote) updateLocalReferenceStorage(\n\tspecs []config.RefSpec,\n\tfetchedRefs, remoteRefs memory.ReferenceStorage,\n\ttagMode TagMode,\n\tforce bool,\n) (updated bool, err error) {\n\tisWildcard := true\n\tforceNeeded := false\n\n\tfor _, spec := range specs {\n\t\tif !spec.IsWildcard() {\n\t\t\tisWildcard = false\n\t\t}\n\n\t\tfor _, ref := range fetchedRefs {\n\t\t\tif !spec.Match(ref.Name()) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif ref.Type() != plumbing.HashReference {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tlocalName := spec.Dst(ref.Name())\n\t\t\told, _ := storer.ResolveReference(r.s, localName)\n\t\t\tnew := plumbing.NewHashReference(localName, ref.Hash())\n\n\t\t\t// If the ref exists locally as a branch and force is not specified,\n\t\t\t// only update if the new ref is an ancestor of the old\n\t\t\tif old != nil && old.Name().IsBranch() && !force && !spec.IsForceUpdate() {\n\t\t\t\tff, err := isFastForward(r.s, old.Hash(), new.Hash())\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn updated, err\n\t\t\t\t}\n\n\t\t\t\tif !ff {\n\t\t\t\t\tforceNeeded = true\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\n\t\t\trefUpdated, err := checkAndUpdateReferenceStorerIfNeeded(r.s, new, old)\n\t\t\tif err != nil {\n\t\t\t\treturn updated, err\n\t\t\t}\n\n\t\t\tif refUpdated {\n\t\t\t\tupdated = true\n\t\t\t}\n\t\t}\n\t}\n\n\tif tagMode == NoTags {\n\t\treturn updated, nil\n\t}\n\n\ttags := fetchedRefs\n\tif isWildcard {\n\t\ttags = remoteRefs\n\t}\n\ttagUpdated, err := r.buildFetchedTags(tags)\n\tif err != nil {\n\t\treturn updated, err\n\t}\n\n\tif tagUpdated {\n\t\tupdated = true\n\t}\n\n\tif forceNeeded {\n\t\terr = ErrForceNeeded\n\t}\n\n\treturn\n}\n\nfunc (r *Remote) buildFetchedTags(refs memory.ReferenceStorage) (updated bool, err error) {\n\tfor _, ref := range refs {\n\t\tif !ref.Name().IsTag() {\n\t\t\tcontinue\n\t\t}\n\n\t\t_, err := r.s.EncodedObject(plumbing.AnyObject, ref.Hash())\n\t\tif err == plumbing.ErrObjectNotFound {\n\t\t\tcontinue\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\n\t\trefUpdated, err := updateReferenceStorerIfNeeded(r.s, ref)\n\t\tif err != nil {\n\t\t\treturn updated, err\n\t\t}\n\n\t\tif refUpdated {\n\t\t\tupdated = true\n\t\t}\n\t}\n\n\treturn\n}\n\n// List the references on the remote repository.\nfunc (r *Remote) List(o *ListOptions) (rfs []*plumbing.Reference, err error) {\n\ts, err := newUploadPackSession(r.c.URLs[0], o.Auth)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdefer ioutil.CheckClose(s, &err)\n\n\tar, err := s.AdvertisedReferences()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tallRefs, err := ar.AllReferences()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\trefs, err := allRefs.IterReferences()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar resultRefs []*plumbing.Reference\n\trefs.ForEach(func(ref *plumbing.Reference) error {\n\t\tresultRefs = append(resultRefs, ref)\n\t\treturn nil\n\t})\n\n\treturn resultRefs, nil\n}\n\nfunc objectsToPush(commands []*packp.Command) []plumbing.Hash {\n\tvar objects []plumbing.Hash\n\tfor _, cmd := range commands {\n\t\tif cmd.New == plumbing.ZeroHash {\n\t\t\tcontinue\n\t\t}\n\n\t\tobjects = append(objects, cmd.New)\n\t}\n\treturn objects\n}\n\nfunc referencesToHashes(refs storer.ReferenceStorer) ([]plumbing.Hash, error) {\n\titer, err := refs.IterReferences()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar hs []plumbing.Hash\n\terr = iter.ForEach(func(ref *plumbing.Reference) error {\n\t\tif ref.Type() != plumbing.HashReference {\n\t\t\treturn nil\n\t\t}\n\n\t\ths = append(hs, ref.Hash())\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn hs, nil\n}\n\nfunc pushHashes(\n\tctx context.Context,\n\tsess transport.ReceivePackSession,\n\ts storage.Storer,\n\treq *packp.ReferenceUpdateRequest,\n\ths []plumbing.Hash,\n\tuseRefDeltas bool,\n\tallDelete bool,\n) (*packp.ReportStatus, error) {\n\n\trd, wr := io.Pipe()\n\n\tconfig, err := s.Config()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Set buffer size to 1 so the error message can be written when\n\t// ReceivePack fails. Otherwise the goroutine will be blocked writing\n\t// to the channel.\n\tdone := make(chan error, 1)\n\n\tif !allDelete {\n\t\treq.Packfile = rd\n\t\tgo func() {\n\t\t\te := packfile.NewEncoder(wr, s, useRefDeltas)\n\t\t\tif _, err := e.Encode(hs, config.Pack.Window); err != nil {\n\t\t\t\tdone <- wr.CloseWithError(err)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tdone <- wr.Close()\n\t\t}()\n\t} else {\n\t\tclose(done)\n\t}\n\n\trs, err := sess.ReceivePack(ctx, req)\n\tif err != nil {\n\t\t// close the pipe to unlock encode write\n\t\t_ = rd.Close()\n\t\treturn nil, err\n\t}\n\n\tif err := <-done; err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn rs, nil\n}\n\nfunc (r *Remote) updateShallow(o *FetchOptions, resp *packp.UploadPackResponse) error {\n\tif o.Depth == 0 || len(resp.Shallows) == 0 {\n\t\treturn nil\n\t}\n\n\tshallows, err := r.s.Shallow()\n\tif err != nil {\n\t\treturn err\n\t}\n\nouter:\n\tfor _, s := range resp.Shallows {\n\t\tfor _, oldS := range shallows {\n\t\t\tif s == oldS {\n\t\t\t\tcontinue outer\n\t\t\t}\n\t\t}\n\t\tshallows = append(shallows, s)\n\t}\n\n\treturn r.s.SetShallow(shallows)\n}\n"
        },
        {
          "name": "remote_test.go",
          "type": "blob",
          "size": 25.396484375,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"runtime\"\n\t\"time\"\n\n\t\"gopkg.in/src-d/go-git.v4/config\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/cache\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/protocol/packp\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/protocol/packp/capability\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/storer\"\n\t\"gopkg.in/src-d/go-git.v4/storage\"\n\t\"gopkg.in/src-d/go-git.v4/storage/filesystem\"\n\t\"gopkg.in/src-d/go-git.v4/storage/memory\"\n\n\t. \"gopkg.in/check.v1\"\n\t\"gopkg.in/src-d/go-billy.v4/osfs\"\n\tfixtures \"gopkg.in/src-d/go-git-fixtures.v3\"\n)\n\ntype RemoteSuite struct {\n\tBaseSuite\n}\n\nvar _ = Suite(&RemoteSuite{})\n\nfunc (s *RemoteSuite) TestFetchInvalidEndpoint(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{Name: \"foo\", URLs: []string{\"http://\\\\\"}})\n\terr := r.Fetch(&FetchOptions{RemoteName: \"foo\"})\n\tc.Assert(err, ErrorMatches, \".*invalid character.*\")\n}\n\nfunc (s *RemoteSuite) TestFetchNonExistentEndpoint(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{Name: \"foo\", URLs: []string{\"ssh://non-existent/foo.git\"}})\n\terr := r.Fetch(&FetchOptions{})\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *RemoteSuite) TestFetchInvalidSchemaEndpoint(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{Name: \"foo\", URLs: []string{\"qux://foo\"}})\n\terr := r.Fetch(&FetchOptions{})\n\tc.Assert(err, ErrorMatches, \".*unsupported scheme.*\")\n}\n\nfunc (s *RemoteSuite) TestFetchInvalidFetchOptions(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{Name: \"foo\", URLs: []string{\"qux://foo\"}})\n\tinvalid := config.RefSpec(\"^*$ñ\")\n\terr := r.Fetch(&FetchOptions{RefSpecs: []config.RefSpec{invalid}})\n\tc.Assert(err, Equals, config.ErrRefSpecMalformedSeparator)\n}\n\nfunc (s *RemoteSuite) TestFetchWildcard(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\n\ts.testFetch(c, r, &FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/*:refs/remotes/origin/*\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/remotes/origin/master\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/remotes/origin/branch\", \"e8d3ffab552895c19b9fcf7aa264d277cde33881\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/v1.0.0\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t})\n}\n\nfunc (s *RemoteSuite) TestFetchWildcardTags(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetLocalRepositoryURL(fixtures.ByTag(\"tags\").One())},\n\t})\n\n\ts.testFetch(c, r, &FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/*:refs/remotes/origin/*\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/remotes/origin/master\", \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/annotated-tag\", \"b742a2a9fa0afcfa9a6fad080980fbc26b007c69\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/tree-tag\", \"152175bf7e5580299fa1f0ba41ef6474cc043b70\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/commit-tag\", \"ad7897c0fb8e7d9a9ba41fa66072cf06095a6cfc\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/blob-tag\", \"fe6cb94756faa81e5ed9240f9191b833db5f40ae\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/lightweight-tag\", \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\"),\n\t})\n}\n\nfunc (s *RemoteSuite) TestFetch(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetLocalRepositoryURL(fixtures.ByTag(\"tags\").One())},\n\t})\n\n\ts.testFetch(c, r, &FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/master:refs/remotes/origin/master\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/remotes/origin/master\", \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\"),\n\t})\n}\n\nfunc (s *RemoteSuite) TestFetchNonExistantReference(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetLocalRepositoryURL(fixtures.ByTag(\"tags\").One())},\n\t})\n\n\terr := r.Fetch(&FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/foo:refs/remotes/origin/foo\"),\n\t\t},\n\t})\n\n\tc.Assert(err, ErrorMatches, \"couldn't find remote ref.*\")\n}\n\nfunc (s *RemoteSuite) TestFetchContext(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetLocalRepositoryURL(fixtures.ByTag(\"tags\").One())},\n\t})\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\n\terr := r.FetchContext(ctx, &FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/master:refs/remotes/origin/master\"),\n\t\t},\n\t})\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *RemoteSuite) TestFetchWithAllTags(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetLocalRepositoryURL(fixtures.ByTag(\"tags\").One())},\n\t})\n\n\ts.testFetch(c, r, &FetchOptions{\n\t\tTags: AllTags,\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/master:refs/remotes/origin/master\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/remotes/origin/master\", \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/annotated-tag\", \"b742a2a9fa0afcfa9a6fad080980fbc26b007c69\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/tree-tag\", \"152175bf7e5580299fa1f0ba41ef6474cc043b70\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/commit-tag\", \"ad7897c0fb8e7d9a9ba41fa66072cf06095a6cfc\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/blob-tag\", \"fe6cb94756faa81e5ed9240f9191b833db5f40ae\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/lightweight-tag\", \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\"),\n\t})\n}\n\nfunc (s *RemoteSuite) TestFetchWithNoTags(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetLocalRepositoryURL(fixtures.ByTag(\"tags\").One())},\n\t})\n\n\ts.testFetch(c, r, &FetchOptions{\n\t\tTags: NoTags,\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/*:refs/remotes/origin/*\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/remotes/origin/master\", \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\"),\n\t})\n\n}\n\nfunc (s *RemoteSuite) TestFetchWithDepth(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\n\ts.testFetch(c, r, &FetchOptions{\n\t\tDepth: 1,\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/*:refs/remotes/origin/*\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/remotes/origin/master\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/remotes/origin/branch\", \"e8d3ffab552895c19b9fcf7aa264d277cde33881\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/tags/v1.0.0\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t})\n\n\tc.Assert(r.s.(*memory.Storage).Objects, HasLen, 18)\n}\n\nfunc (s *RemoteSuite) testFetch(c *C, r *Remote, o *FetchOptions, expected []*plumbing.Reference) {\n\terr := r.Fetch(o)\n\tc.Assert(err, IsNil)\n\n\tvar refs int\n\tl, err := r.s.IterReferences()\n\tc.Assert(err, IsNil)\n\tl.ForEach(func(r *plumbing.Reference) error { refs++; return nil })\n\n\tc.Assert(refs, Equals, len(expected))\n\n\tfor _, exp := range expected {\n\t\tr, err := r.s.Reference(exp.Name())\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(exp.String(), Equals, r.String())\n\t}\n}\n\nfunc (s *RemoteSuite) TestFetchWithProgress(c *C) {\n\turl := s.GetBasicLocalRepositoryURL()\n\tsto := memory.NewStorage()\n\tbuf := bytes.NewBuffer(nil)\n\n\tr := NewRemote(sto, &config.RemoteConfig{Name: \"foo\", URLs: []string{url}})\n\n\trefspec := config.RefSpec(\"+refs/heads/*:refs/remotes/origin/*\")\n\terr := r.Fetch(&FetchOptions{\n\t\tRefSpecs: []config.RefSpec{refspec},\n\t\tProgress: buf,\n\t})\n\n\tc.Assert(err, IsNil)\n\tc.Assert(sto.Objects, HasLen, 31)\n\n\tc.Assert(buf.Len(), Not(Equals), 0)\n}\n\ntype mockPackfileWriter struct {\n\tstorage.Storer\n\tPackfileWriterCalled bool\n}\n\nfunc (m *mockPackfileWriter) PackfileWriter() (io.WriteCloser, error) {\n\tm.PackfileWriterCalled = true\n\treturn m.Storer.(storer.PackfileWriter).PackfileWriter()\n}\n\nfunc (s *RemoteSuite) TestFetchWithPackfileWriter(c *C) {\n\tdir, err := ioutil.TempDir(\"\", \"fetch\")\n\tc.Assert(err, IsNil)\n\n\tdefer os.RemoveAll(dir) // clean up\n\n\tfss := filesystem.NewStorage(osfs.New(dir), cache.NewObjectLRUDefault())\n\tc.Assert(err, IsNil)\n\n\tmock := &mockPackfileWriter{Storer: fss}\n\n\turl := s.GetBasicLocalRepositoryURL()\n\tr := NewRemote(mock, &config.RemoteConfig{Name: \"foo\", URLs: []string{url}})\n\n\trefspec := config.RefSpec(\"+refs/heads/*:refs/remotes/origin/*\")\n\terr = r.Fetch(&FetchOptions{\n\t\tRefSpecs: []config.RefSpec{refspec},\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tvar count int\n\titer, err := mock.IterEncodedObjects(plumbing.AnyObject)\n\tc.Assert(err, IsNil)\n\n\titer.ForEach(func(plumbing.EncodedObject) error {\n\t\tcount++\n\t\treturn nil\n\t})\n\n\tc.Assert(count, Equals, 31)\n\tc.Assert(mock.PackfileWriterCalled, Equals, true)\n}\n\nfunc (s *RemoteSuite) TestFetchNoErrAlreadyUpToDate(c *C) {\n\turl := s.GetBasicLocalRepositoryURL()\n\ts.doTestFetchNoErrAlreadyUpToDate(c, url)\n}\n\nfunc (s *RemoteSuite) TestFetchNoErrAlreadyUpToDateButStillUpdateLocalRemoteRefs(c *C) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\n\to := &FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/*:refs/remotes/origin/*\"),\n\t\t},\n\t}\n\n\terr := r.Fetch(o)\n\tc.Assert(err, IsNil)\n\n\t// Simulate an out of date remote ref even though we have the new commit locally\n\tr.s.SetReference(plumbing.NewReferenceFromStrings(\n\t\t\"refs/remotes/origin/master\", \"918c48b83bd081e863dbe1b80f8998f058cd8294\",\n\t))\n\n\terr = r.Fetch(o)\n\tc.Assert(err, IsNil)\n\n\texp := plumbing.NewReferenceFromStrings(\n\t\t\"refs/remotes/origin/master\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t)\n\n\tref, err := r.s.Reference(\"refs/remotes/origin/master\")\n\tc.Assert(err, IsNil)\n\tc.Assert(exp.String(), Equals, ref.String())\n}\n\nfunc (s *RemoteSuite) TestFetchNoErrAlreadyUpToDateWithNonCommitObjects(c *C) {\n\tfixture := fixtures.ByTag(\"tags\").One()\n\turl := s.GetLocalRepositoryURL(fixture)\n\ts.doTestFetchNoErrAlreadyUpToDate(c, url)\n}\n\nfunc (s *RemoteSuite) doTestFetchNoErrAlreadyUpToDate(c *C, url string) {\n\tr := NewRemote(memory.NewStorage(), &config.RemoteConfig{URLs: []string{url}})\n\n\to := &FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/*:refs/remotes/origin/*\"),\n\t\t},\n\t}\n\n\terr := r.Fetch(o)\n\tc.Assert(err, IsNil)\n\terr = r.Fetch(o)\n\tc.Assert(err, Equals, NoErrAlreadyUpToDate)\n}\n\nfunc (s *RemoteSuite) testFetchFastForward(c *C, sto storage.Storer) {\n\tr := NewRemote(sto, &config.RemoteConfig{\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\n\ts.testFetch(c, r, &FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/master:refs/heads/master\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/heads/master\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t})\n\n\t// First make sure that we error correctly when a force is required.\n\terr := r.Fetch(&FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"refs/heads/branch:refs/heads/master\"),\n\t\t},\n\t})\n\tc.Assert(err, Equals, ErrForceNeeded)\n\n\t// And that forcing it fixes the problem.\n\terr = r.Fetch(&FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"+refs/heads/branch:refs/heads/master\"),\n\t\t},\n\t})\n\tc.Assert(err, IsNil)\n\n\t// Now test that a fast-forward, non-force fetch works.\n\tr.s.SetReference(plumbing.NewReferenceFromStrings(\n\t\t\"refs/heads/master\", \"918c48b83bd081e863dbe1b80f8998f058cd8294\",\n\t))\n\ts.testFetch(c, r, &FetchOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"refs/heads/master:refs/heads/master\"),\n\t\t},\n\t}, []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\"refs/heads/master\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t})\n}\n\nfunc (s *RemoteSuite) TestFetchFastForwardMem(c *C) {\n\ts.testFetchFastForward(c, memory.NewStorage())\n}\n\nfunc (s *RemoteSuite) TestFetchFastForwardFS(c *C) {\n\tdir, err := ioutil.TempDir(\"\", \"fetch\")\n\tc.Assert(err, IsNil)\n\n\tdefer os.RemoveAll(dir) // clean up\n\n\tfss := filesystem.NewStorage(osfs.New(dir), cache.NewObjectLRUDefault())\n\n\t// This exercises `storage.filesystem.Storage.CheckAndSetReference()`.\n\ts.testFetchFastForward(c, fss)\n}\n\nfunc (s *RemoteSuite) TestString(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{\n\t\tName: \"foo\",\n\t\tURLs: []string{\"https://github.com/git-fixtures/basic.git\"},\n\t})\n\n\tc.Assert(r.String(), Equals, \"\"+\n\t\t\"foo\\thttps://github.com/git-fixtures/basic.git (fetch)\\n\"+\n\t\t\"foo\\thttps://github.com/git-fixtures/basic.git (push)\",\n\t)\n}\n\nfunc (s *RemoteSuite) TestPushToEmptyRepository(c *C) {\n\turl := c.MkDir()\n\tserver, err := PlainInit(url, true)\n\tc.Assert(err, IsNil)\n\n\tsrcFs := fixtures.Basic().One().DotGit()\n\tsto := filesystem.NewStorage(srcFs, cache.NewObjectLRUDefault())\n\n\tr := NewRemote(sto, &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{url},\n\t})\n\n\trs := config.RefSpec(\"refs/heads/*:refs/heads/*\")\n\terr = r.Push(&PushOptions{\n\t\tRefSpecs: []config.RefSpec{rs},\n\t})\n\tc.Assert(err, IsNil)\n\n\titer, err := r.s.IterReferences()\n\tc.Assert(err, IsNil)\n\n\texpected := make(map[string]string)\n\titer.ForEach(func(ref *plumbing.Reference) error {\n\t\tif !ref.Name().IsBranch() {\n\t\t\treturn nil\n\t\t}\n\n\t\texpected[ref.Name().String()] = ref.Hash().String()\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, server, expected)\n\n}\n\nfunc (s *RemoteSuite) TestPushContext(c *C) {\n\turl := c.MkDir()\n\t_, err := PlainInit(url, true)\n\tc.Assert(err, IsNil)\n\n\tfs := fixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One().DotGit()\n\tsto := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\n\tr := NewRemote(sto, &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{url},\n\t})\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\n\tnumGoroutines := runtime.NumGoroutine()\n\n\terr = r.PushContext(ctx, &PushOptions{\n\t\tRefSpecs: []config.RefSpec{\"refs/tags/*:refs/tags/*\"},\n\t})\n\tc.Assert(err, NotNil)\n\n\t// let the goroutine from pushHashes finish and check that the number of\n\t// goroutines is the same as before\n\ttime.Sleep(100 * time.Millisecond)\n\tc.Assert(runtime.NumGoroutine(), Equals, numGoroutines)\n}\n\nfunc (s *RemoteSuite) TestPushTags(c *C) {\n\turl := c.MkDir()\n\tserver, err := PlainInit(url, true)\n\tc.Assert(err, IsNil)\n\n\tfs := fixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One().DotGit()\n\tsto := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\n\tr := NewRemote(sto, &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{url},\n\t})\n\n\terr = r.Push(&PushOptions{\n\t\tRefSpecs: []config.RefSpec{\"refs/tags/*:refs/tags/*\"},\n\t})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, server, map[string]string{\n\t\t\"refs/tags/lightweight-tag\": \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\",\n\t\t\"refs/tags/annotated-tag\":   \"b742a2a9fa0afcfa9a6fad080980fbc26b007c69\",\n\t\t\"refs/tags/commit-tag\":      \"ad7897c0fb8e7d9a9ba41fa66072cf06095a6cfc\",\n\t\t\"refs/tags/blob-tag\":        \"fe6cb94756faa81e5ed9240f9191b833db5f40ae\",\n\t\t\"refs/tags/tree-tag\":        \"152175bf7e5580299fa1f0ba41ef6474cc043b70\",\n\t})\n}\n\nfunc (s *RemoteSuite) TestPushNoErrAlreadyUpToDate(c *C) {\n\tfs := fixtures.Basic().One().DotGit()\n\tsto := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\n\tr := NewRemote(sto, &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{fs.Root()},\n\t})\n\n\terr := r.Push(&PushOptions{\n\t\tRefSpecs: []config.RefSpec{\"refs/heads/*:refs/heads/*\"},\n\t})\n\tc.Assert(err, Equals, NoErrAlreadyUpToDate)\n}\n\nfunc (s *RemoteSuite) TestPushDeleteReference(c *C) {\n\tfs := fixtures.Basic().One().DotGit()\n\tsto := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\n\tr, err := PlainClone(c.MkDir(), true, &CloneOptions{\n\t\tURL: fs.Root(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tremote, err := r.Remote(DefaultRemoteName)\n\tc.Assert(err, IsNil)\n\n\terr = remote.Push(&PushOptions{\n\t\tRefSpecs: []config.RefSpec{\":refs/heads/branch\"},\n\t})\n\tc.Assert(err, IsNil)\n\n\t_, err = sto.Reference(plumbing.ReferenceName(\"refs/heads/branch\"))\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n\n\t_, err = r.Storer.Reference(plumbing.ReferenceName(\"refs/heads/branch\"))\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n}\n\nfunc (s *RemoteSuite) TestPushRejectNonFastForward(c *C) {\n\tfs := fixtures.Basic().One().DotGit()\n\tserver := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\n\tr, err := PlainClone(c.MkDir(), true, &CloneOptions{\n\t\tURL: fs.Root(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tremote, err := r.Remote(DefaultRemoteName)\n\tc.Assert(err, IsNil)\n\n\tbranch := plumbing.ReferenceName(\"refs/heads/branch\")\n\toldRef, err := server.Reference(branch)\n\tc.Assert(err, IsNil)\n\tc.Assert(oldRef, NotNil)\n\n\terr = remote.Push(&PushOptions{RefSpecs: []config.RefSpec{\n\t\t\"refs/heads/master:refs/heads/branch\",\n\t}})\n\tc.Assert(err, ErrorMatches, \"non-fast-forward update: refs/heads/branch\")\n\n\tnewRef, err := server.Reference(branch)\n\tc.Assert(err, IsNil)\n\tc.Assert(newRef, DeepEquals, oldRef)\n}\n\nfunc (s *RemoteSuite) TestPushForce(c *C) {\n\tf := fixtures.Basic().One()\n\tsto := filesystem.NewStorage(f.DotGit(), cache.NewObjectLRUDefault())\n\n\tdstFs := f.DotGit()\n\tdstSto := filesystem.NewStorage(dstFs, cache.NewObjectLRUDefault())\n\n\turl := dstFs.Root()\n\tr := NewRemote(sto, &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{url},\n\t})\n\n\toldRef, err := dstSto.Reference(plumbing.ReferenceName(\"refs/heads/branch\"))\n\tc.Assert(err, IsNil)\n\tc.Assert(oldRef, NotNil)\n\n\terr = r.Push(&PushOptions{RefSpecs: []config.RefSpec{\n\t\tconfig.RefSpec(\"+refs/heads/master:refs/heads/branch\"),\n\t}})\n\tc.Assert(err, IsNil)\n\n\tnewRef, err := dstSto.Reference(plumbing.ReferenceName(\"refs/heads/branch\"))\n\tc.Assert(err, IsNil)\n\tc.Assert(newRef, Not(DeepEquals), oldRef)\n}\n\nfunc (s *RemoteSuite) TestPushPrune(c *C) {\n\tfs := fixtures.Basic().One().DotGit()\n\turl := c.MkDir()\n\tserver, err := PlainClone(url, true, &CloneOptions{\n\t\tURL: fs.Root(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tr, err := PlainClone(c.MkDir(), true, &CloneOptions{\n\t\tURL: url,\n\t})\n\tc.Assert(err, IsNil)\n\n\ttag, err := r.Reference(plumbing.ReferenceName(\"refs/tags/v1.0.0\"), true)\n\tc.Assert(err, IsNil)\n\n\terr = r.DeleteTag(\"v1.0.0\")\n\tc.Assert(err, IsNil)\n\n\tremote, err := r.Remote(DefaultRemoteName)\n\tc.Assert(err, IsNil)\n\n\tref, err := r.Reference(plumbing.ReferenceName(\"refs/heads/master\"), true)\n\tc.Assert(err, IsNil)\n\n\terr = remote.Push(&PushOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"refs/heads/*:refs/heads/*\"),\n\t\t},\n\t\tPrune: true,\n\t})\n\tc.Assert(err, Equals, NoErrAlreadyUpToDate)\n\n\tAssertReferences(c, server, map[string]string{\n\t\t\"refs/tags/v1.0.0\": tag.Hash().String(),\n\t})\n\n\terr = remote.Push(&PushOptions{\n\t\tRefSpecs: []config.RefSpec{\n\t\t\tconfig.RefSpec(\"*:*\"),\n\t\t},\n\t\tPrune: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, server, map[string]string{\n\t\t\"refs/remotes/origin/master\": ref.Hash().String(),\n\t})\n\n\tAssertReferences(c, server, map[string]string{\n\t\t\"refs/remotes/origin/master\": ref.Hash().String(),\n\t})\n\n\tref, err = server.Reference(plumbing.ReferenceName(\"refs/tags/v1.0.0\"), true)\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n}\n\nfunc (s *RemoteSuite) TestPushNewReference(c *C) {\n\tfs := fixtures.Basic().One().DotGit()\n\turl := c.MkDir()\n\tserver, err := PlainClone(url, true, &CloneOptions{\n\t\tURL: fs.Root(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tr, err := PlainClone(c.MkDir(), true, &CloneOptions{\n\t\tURL: url,\n\t})\n\tc.Assert(err, IsNil)\n\n\tremote, err := r.Remote(DefaultRemoteName)\n\tc.Assert(err, IsNil)\n\n\tref, err := r.Reference(plumbing.ReferenceName(\"refs/heads/master\"), true)\n\tc.Assert(err, IsNil)\n\n\terr = remote.Push(&PushOptions{RefSpecs: []config.RefSpec{\n\t\t\"refs/heads/master:refs/heads/branch2\",\n\t}})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, server, map[string]string{\n\t\t\"refs/heads/branch2\": ref.Hash().String(),\n\t})\n\n\tAssertReferences(c, r, map[string]string{\n\t\t\"refs/remotes/origin/branch2\": ref.Hash().String(),\n\t})\n}\n\nfunc (s *RemoteSuite) TestPushNewReferenceAndDeleteInBatch(c *C) {\n\tfs := fixtures.Basic().One().DotGit()\n\turl := c.MkDir()\n\tserver, err := PlainClone(url, true, &CloneOptions{\n\t\tURL: fs.Root(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tr, err := PlainClone(c.MkDir(), true, &CloneOptions{\n\t\tURL: url,\n\t})\n\tc.Assert(err, IsNil)\n\n\tremote, err := r.Remote(DefaultRemoteName)\n\tc.Assert(err, IsNil)\n\n\tref, err := r.Reference(plumbing.ReferenceName(\"refs/heads/master\"), true)\n\tc.Assert(err, IsNil)\n\n\terr = remote.Push(&PushOptions{RefSpecs: []config.RefSpec{\n\t\t\"refs/heads/master:refs/heads/branch2\",\n\t\t\":refs/heads/branch\",\n\t}})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, server, map[string]string{\n\t\t\"refs/heads/branch2\": ref.Hash().String(),\n\t})\n\n\tAssertReferences(c, r, map[string]string{\n\t\t\"refs/remotes/origin/branch2\": ref.Hash().String(),\n\t})\n\n\t_, err = server.Storer.Reference(plumbing.ReferenceName(\"refs/heads/branch\"))\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n}\n\nfunc (s *RemoteSuite) TestPushInvalidEndpoint(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{Name: \"foo\", URLs: []string{\"http://\\\\\"}})\n\terr := r.Push(&PushOptions{RemoteName: \"foo\"})\n\tc.Assert(err, ErrorMatches, \".*invalid character.*\")\n}\n\nfunc (s *RemoteSuite) TestPushNonExistentEndpoint(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{Name: \"foo\", URLs: []string{\"ssh://non-existent/foo.git\"}})\n\terr := r.Push(&PushOptions{})\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *RemoteSuite) TestPushInvalidSchemaEndpoint(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{Name: \"origin\", URLs: []string{\"qux://foo\"}})\n\terr := r.Push(&PushOptions{})\n\tc.Assert(err, ErrorMatches, \".*unsupported scheme.*\")\n}\n\nfunc (s *RemoteSuite) TestPushInvalidFetchOptions(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{Name: \"foo\", URLs: []string{\"qux://foo\"}})\n\tinvalid := config.RefSpec(\"^*$ñ\")\n\terr := r.Push(&PushOptions{RefSpecs: []config.RefSpec{invalid}})\n\tc.Assert(err, Equals, config.ErrRefSpecMalformedSeparator)\n}\n\nfunc (s *RemoteSuite) TestPushInvalidRefSpec(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{\"some-url\"},\n\t})\n\n\trs := config.RefSpec(\"^*$**\")\n\terr := r.Push(&PushOptions{\n\t\tRefSpecs: []config.RefSpec{rs},\n\t})\n\tc.Assert(err, Equals, config.ErrRefSpecMalformedSeparator)\n}\n\nfunc (s *RemoteSuite) TestPushWrongRemoteName(c *C) {\n\tr := NewRemote(nil, &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{\"some-url\"},\n\t})\n\n\terr := r.Push(&PushOptions{\n\t\tRemoteName: \"other-remote\",\n\t})\n\tc.Assert(err, ErrorMatches, \".*remote names don't match.*\")\n}\n\nfunc (s *RemoteSuite) TestGetHaves(c *C) {\n\tf := fixtures.Basic().One()\n\tsto := filesystem.NewStorage(f.DotGit(), cache.NewObjectLRUDefault())\n\n\tvar localRefs = []*plumbing.Reference{\n\t\tplumbing.NewReferenceFromStrings(\n\t\t\t\"foo\",\n\t\t\t\"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\",\n\t\t),\n\t\tplumbing.NewReferenceFromStrings(\n\t\t\t\"bar\",\n\t\t\t\"fe6cb94756faa81e5ed9240f9191b833db5f40ae\",\n\t\t),\n\t\tplumbing.NewReferenceFromStrings(\n\t\t\t\"qux\",\n\t\t\t\"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\",\n\t\t),\n\t}\n\n\tl, err := getHaves(localRefs, memory.NewStorage(), sto)\n\tc.Assert(err, IsNil)\n\tc.Assert(l, HasLen, 2)\n}\n\nfunc (s *RemoteSuite) TestList(c *C) {\n\trepo := fixtures.Basic().One()\n\tremote := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{repo.URL},\n\t})\n\n\trefs, err := remote.List(&ListOptions{})\n\tc.Assert(err, IsNil)\n\n\texpected := []*plumbing.Reference{\n\t\tplumbing.NewSymbolicReference(\"HEAD\", \"refs/heads/master\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/heads/master\", \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/heads/branch\", \"e8d3ffab552895c19b9fcf7aa264d277cde33881\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/pull/1/head\", \"b8e471f58bcbca63b07bda20e428190409c2db47\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/pull/2/head\", \"9632f02833b2f9613afb5e75682132b0b22e4a31\"),\n\t\tplumbing.NewReferenceFromStrings(\"refs/pull/2/merge\", \"c37f58a130ca555e42ff96a071cb9ccb3f437504\"),\n\t}\n\tc.Assert(len(refs), Equals, len(expected))\n\tfor _, e := range expected {\n\t\tfound := false\n\t\tfor _, r := range refs {\n\t\t\tif r.Name() == e.Name() {\n\t\t\t\tfound = true\n\t\t\t\tc.Assert(r, DeepEquals, e)\n\t\t\t}\n\t\t}\n\t\tc.Assert(found, Equals, true)\n\t}\n}\n\nfunc (s *RemoteSuite) TestUpdateShallows(c *C) {\n\thashes := []plumbing.Hash{\n\t\tplumbing.NewHash(\"0000000000000000000000000000000000000001\"),\n\t\tplumbing.NewHash(\"0000000000000000000000000000000000000002\"),\n\t\tplumbing.NewHash(\"0000000000000000000000000000000000000003\"),\n\t\tplumbing.NewHash(\"0000000000000000000000000000000000000004\"),\n\t\tplumbing.NewHash(\"0000000000000000000000000000000000000005\"),\n\t\tplumbing.NewHash(\"0000000000000000000000000000000000000006\"),\n\t}\n\n\ttests := []struct {\n\t\thashes []plumbing.Hash\n\t\tresult []plumbing.Hash\n\t}{\n\t\t// add to empty shallows\n\t\t{hashes[0:2], hashes[0:2]},\n\t\t// add new hashes\n\t\t{hashes[2:4], hashes[0:4]},\n\t\t// add some hashes already in shallow list\n\t\t{hashes[2:6], hashes[0:6]},\n\t\t// add all hashes\n\t\t{hashes[0:6], hashes[0:6]},\n\t\t// add empty list\n\t\t{nil, hashes[0:6]},\n\t}\n\n\tremote := NewRemote(memory.NewStorage(), &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t})\n\n\tshallows, err := remote.s.Shallow()\n\tc.Assert(err, IsNil)\n\tc.Assert(len(shallows), Equals, 0)\n\n\tresp := new(packp.UploadPackResponse)\n\to := &FetchOptions{\n\t\tDepth: 1,\n\t}\n\n\tfor _, t := range tests {\n\t\tresp.Shallows = t.hashes\n\t\terr = remote.updateShallow(o, resp)\n\t\tc.Assert(err, IsNil)\n\n\t\tshallow, err := remote.s.Shallow()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(len(shallow), Equals, len(t.result))\n\t\tc.Assert(shallow, DeepEquals, t.result)\n\t}\n}\n\nfunc (s *RemoteSuite) TestUseRefDeltas(c *C) {\n\turl := c.MkDir()\n\t_, err := PlainInit(url, true)\n\tc.Assert(err, IsNil)\n\n\tfs := fixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One().DotGit()\n\tsto := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\n\tr := NewRemote(sto, &config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{url},\n\t})\n\n\tar := packp.NewAdvRefs()\n\n\tar.Capabilities.Add(capability.OFSDelta)\n\tc.Assert(r.useRefDeltas(ar), Equals, false)\n\n\tar.Capabilities.Delete(capability.OFSDelta)\n\tc.Assert(r.useRefDeltas(ar), Equals, true)\n}\n"
        },
        {
          "name": "repository.go",
          "type": "blob",
          "size": 38.5146484375,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\tstdioutil \"io/ioutil\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"time\"\n\n\t\"golang.org/x/crypto/openpgp\"\n\t\"gopkg.in/src-d/go-git.v4/config\"\n\t\"gopkg.in/src-d/go-git.v4/internal/revision\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/cache\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/format/packfile\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/object\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/storer\"\n\t\"gopkg.in/src-d/go-git.v4/storage\"\n\t\"gopkg.in/src-d/go-git.v4/storage/filesystem\"\n\t\"gopkg.in/src-d/go-git.v4/utils/ioutil\"\n\n\t\"gopkg.in/src-d/go-billy.v4\"\n\t\"gopkg.in/src-d/go-billy.v4/osfs\"\n)\n\n// GitDirName this is a special folder where all the git stuff is.\nconst GitDirName = \".git\"\n\nvar (\n\t// ErrBranchExists an error stating the specified branch already exists\n\tErrBranchExists = errors.New(\"branch already exists\")\n\t// ErrBranchNotFound an error stating the specified branch does not exist\n\tErrBranchNotFound = errors.New(\"branch not found\")\n\t// ErrTagExists an error stating the specified tag already exists\n\tErrTagExists = errors.New(\"tag already exists\")\n\t// ErrTagNotFound an error stating the specified tag does not exist\n\tErrTagNotFound = errors.New(\"tag not found\")\n\t// ErrFetching is returned when the packfile could not be downloaded\n\tErrFetching = errors.New(\"unable to fetch packfile\")\n\n\tErrInvalidReference          = errors.New(\"invalid reference, should be a tag or a branch\")\n\tErrRepositoryNotExists       = errors.New(\"repository does not exist\")\n\tErrRepositoryAlreadyExists   = errors.New(\"repository already exists\")\n\tErrRemoteNotFound            = errors.New(\"remote not found\")\n\tErrRemoteExists              = errors.New(\"remote already exists\")\n\tErrAnonymousRemoteName       = errors.New(\"anonymous remote name must be 'anonymous'\")\n\tErrWorktreeNotProvided       = errors.New(\"worktree should be provided\")\n\tErrIsBareRepository          = errors.New(\"worktree not available in a bare repository\")\n\tErrUnableToResolveCommit     = errors.New(\"unable to resolve commit\")\n\tErrPackedObjectsNotSupported = errors.New(\"Packed objects not supported\")\n)\n\n// Repository represents a git repository\ntype Repository struct {\n\tStorer storage.Storer\n\n\tr  map[string]*Remote\n\twt billy.Filesystem\n}\n\n// Init creates an empty git repository, based on the given Storer and worktree.\n// The worktree Filesystem is optional, if nil a bare repository is created. If\n// the given storer is not empty ErrRepositoryAlreadyExists is returned\nfunc Init(s storage.Storer, worktree billy.Filesystem) (*Repository, error) {\n\tif err := initStorer(s); err != nil {\n\t\treturn nil, err\n\t}\n\n\tr := newRepository(s, worktree)\n\t_, err := r.Reference(plumbing.HEAD, false)\n\tswitch err {\n\tcase plumbing.ErrReferenceNotFound:\n\tcase nil:\n\t\treturn nil, ErrRepositoryAlreadyExists\n\tdefault:\n\t\treturn nil, err\n\t}\n\n\th := plumbing.NewSymbolicReference(plumbing.HEAD, plumbing.Master)\n\tif err := s.SetReference(h); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif worktree == nil {\n\t\tr.setIsBare(true)\n\t\treturn r, nil\n\t}\n\n\treturn r, setWorktreeAndStoragePaths(r, worktree)\n}\n\nfunc initStorer(s storer.Storer) error {\n\ti, ok := s.(storer.Initializer)\n\tif !ok {\n\t\treturn nil\n\t}\n\n\treturn i.Init()\n}\n\nfunc setWorktreeAndStoragePaths(r *Repository, worktree billy.Filesystem) error {\n\ttype fsBased interface {\n\t\tFilesystem() billy.Filesystem\n\t}\n\n\t// .git file is only created if the storage is file based and the file\n\t// system is osfs.OS\n\tfs, isFSBased := r.Storer.(fsBased)\n\tif !isFSBased {\n\t\treturn nil\n\t}\n\n\tif err := createDotGitFile(worktree, fs.Filesystem()); err != nil {\n\t\treturn err\n\t}\n\n\treturn setConfigWorktree(r, worktree, fs.Filesystem())\n}\n\nfunc createDotGitFile(worktree, storage billy.Filesystem) error {\n\tpath, err := filepath.Rel(worktree.Root(), storage.Root())\n\tif err != nil {\n\t\tpath = storage.Root()\n\t}\n\n\tif path == GitDirName {\n\t\t// not needed, since the folder is the default place\n\t\treturn nil\n\t}\n\n\tf, err := worktree.Create(GitDirName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdefer f.Close()\n\t_, err = fmt.Fprintf(f, \"gitdir: %s\\n\", path)\n\treturn err\n}\n\nfunc setConfigWorktree(r *Repository, worktree, storage billy.Filesystem) error {\n\tpath, err := filepath.Rel(storage.Root(), worktree.Root())\n\tif err != nil {\n\t\tpath = worktree.Root()\n\t}\n\n\tif path == \"..\" {\n\t\t// not needed, since the folder is the default place\n\t\treturn nil\n\t}\n\n\tcfg, err := r.Storer.Config()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tcfg.Core.Worktree = path\n\treturn r.Storer.SetConfig(cfg)\n}\n\n// Open opens a git repository using the given Storer and worktree filesystem,\n// if the given storer is complete empty ErrRepositoryNotExists is returned.\n// The worktree can be nil when the repository being opened is bare, if the\n// repository is a normal one (not bare) and worktree is nil the err\n// ErrWorktreeNotProvided is returned\nfunc Open(s storage.Storer, worktree billy.Filesystem) (*Repository, error) {\n\t_, err := s.Reference(plumbing.HEAD)\n\tif err == plumbing.ErrReferenceNotFound {\n\t\treturn nil, ErrRepositoryNotExists\n\t}\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn newRepository(s, worktree), nil\n}\n\n// Clone a repository into the given Storer and worktree Filesystem with the\n// given options, if worktree is nil a bare repository is created. If the given\n// storer is not empty ErrRepositoryAlreadyExists is returned.\n//\n// The provided Context must be non-nil. If the context expires before the\n// operation is complete, an error is returned. The context only affects to the\n// transport operations.\nfunc Clone(s storage.Storer, worktree billy.Filesystem, o *CloneOptions) (*Repository, error) {\n\treturn CloneContext(context.Background(), s, worktree, o)\n}\n\n// CloneContext a repository into the given Storer and worktree Filesystem with\n// the given options, if worktree is nil a bare repository is created. If the\n// given storer is not empty ErrRepositoryAlreadyExists is returned.\n//\n// The provided Context must be non-nil. If the context expires before the\n// operation is complete, an error is returned. The context only affects to the\n// transport operations.\nfunc CloneContext(\n\tctx context.Context, s storage.Storer, worktree billy.Filesystem, o *CloneOptions,\n) (*Repository, error) {\n\tr, err := Init(s, worktree)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn r, r.clone(ctx, o)\n}\n\n// PlainInit create an empty git repository at the given path. isBare defines\n// if the repository will have worktree (non-bare) or not (bare), if the path\n// is not empty ErrRepositoryAlreadyExists is returned.\nfunc PlainInit(path string, isBare bool) (*Repository, error) {\n\tvar wt, dot billy.Filesystem\n\n\tif isBare {\n\t\tdot = osfs.New(path)\n\t} else {\n\t\twt = osfs.New(path)\n\t\tdot, _ = wt.Chroot(GitDirName)\n\t}\n\n\ts := filesystem.NewStorage(dot, cache.NewObjectLRUDefault())\n\n\treturn Init(s, wt)\n}\n\n// PlainOpen opens a git repository from the given path. It detects if the\n// repository is bare or a normal one. If the path doesn't contain a valid\n// repository ErrRepositoryNotExists is returned\nfunc PlainOpen(path string) (*Repository, error) {\n\treturn PlainOpenWithOptions(path, &PlainOpenOptions{})\n}\n\n// PlainOpenWithOptions opens a git repository from the given path with specific\n// options. See PlainOpen for more info.\nfunc PlainOpenWithOptions(path string, o *PlainOpenOptions) (*Repository, error) {\n\tdot, wt, err := dotGitToOSFilesystems(path, o.DetectDotGit)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif _, err := dot.Stat(\"\"); err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\treturn nil, ErrRepositoryNotExists\n\t\t}\n\n\t\treturn nil, err\n\t}\n\n\ts := filesystem.NewStorage(dot, cache.NewObjectLRUDefault())\n\n\treturn Open(s, wt)\n}\n\nfunc dotGitToOSFilesystems(path string, detect bool) (dot, wt billy.Filesystem, err error) {\n\tif path, err = filepath.Abs(path); err != nil {\n\t\treturn nil, nil, err\n\t}\n\tvar fs billy.Filesystem\n\tvar fi os.FileInfo\n\tfor {\n\t\tfs = osfs.New(path)\n\t\tfi, err = fs.Stat(GitDirName)\n\t\tif err == nil {\n\t\t\t// no error; stop\n\t\t\tbreak\n\t\t}\n\t\tif !os.IsNotExist(err) {\n\t\t\t// unknown error; stop\n\t\t\treturn nil, nil, err\n\t\t}\n\t\tif detect {\n\t\t\t// try its parent as long as we haven't reached\n\t\t\t// the root dir\n\t\t\tif dir := filepath.Dir(path); dir != path {\n\t\t\t\tpath = dir\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\t// not detecting via parent dirs and the dir does not exist;\n\t\t// stop\n\t\treturn fs, nil, nil\n\t}\n\n\tif fi.IsDir() {\n\t\tdot, err = fs.Chroot(GitDirName)\n\t\treturn dot, fs, err\n\t}\n\n\tdot, err = dotGitFileToOSFilesystem(path, fs)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\treturn dot, fs, nil\n}\n\nfunc dotGitFileToOSFilesystem(path string, fs billy.Filesystem) (bfs billy.Filesystem, err error) {\n\tf, err := fs.Open(GitDirName)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer ioutil.CheckClose(f, &err)\n\n\tb, err := stdioutil.ReadAll(f)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tline := string(b)\n\tconst prefix = \"gitdir: \"\n\tif !strings.HasPrefix(line, prefix) {\n\t\treturn nil, fmt.Errorf(\".git file has no %s prefix\", prefix)\n\t}\n\n\tgitdir := strings.Split(line[len(prefix):], \"\\n\")[0]\n\tgitdir = strings.TrimSpace(gitdir)\n\tif filepath.IsAbs(gitdir) {\n\t\treturn osfs.New(gitdir), nil\n\t}\n\n\treturn osfs.New(fs.Join(path, gitdir)), nil\n}\n\n// PlainClone a repository into the path with the given options, isBare defines\n// if the new repository will be bare or normal. If the path is not empty\n// ErrRepositoryAlreadyExists is returned.\n//\n// TODO(mcuadros): move isBare to CloneOptions in v5\nfunc PlainClone(path string, isBare bool, o *CloneOptions) (*Repository, error) {\n\treturn PlainCloneContext(context.Background(), path, isBare, o)\n}\n\n// PlainCloneContext a repository into the path with the given options, isBare\n// defines if the new repository will be bare or normal. If the path is not empty\n// ErrRepositoryAlreadyExists is returned.\n//\n// The provided Context must be non-nil. If the context expires before the\n// operation is complete, an error is returned. The context only affects to the\n// transport operations.\n//\n// TODO(mcuadros): move isBare to CloneOptions in v5\n// TODO(smola): refuse upfront to clone on a non-empty directory in v5, see #1027\nfunc PlainCloneContext(ctx context.Context, path string, isBare bool, o *CloneOptions) (*Repository, error) {\n\tcleanup, cleanupParent, err := checkIfCleanupIsNeeded(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tr, err := PlainInit(path, isBare)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\terr = r.clone(ctx, o)\n\tif err != nil && err != ErrRepositoryAlreadyExists {\n\t\tif cleanup {\n\t\t\tcleanUpDir(path, cleanupParent)\n\t\t}\n\t}\n\n\treturn r, err\n}\n\nfunc newRepository(s storage.Storer, worktree billy.Filesystem) *Repository {\n\treturn &Repository{\n\t\tStorer: s,\n\t\twt:     worktree,\n\t\tr:      make(map[string]*Remote),\n\t}\n}\n\nfunc checkIfCleanupIsNeeded(path string) (cleanup bool, cleanParent bool, err error) {\n\tfi, err := os.Stat(path)\n\tif err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\treturn true, true, nil\n\t\t}\n\n\t\treturn false, false, err\n\t}\n\n\tif !fi.IsDir() {\n\t\treturn false, false, fmt.Errorf(\"path is not a directory: %s\", path)\n\t}\n\n\tf, err := os.Open(path)\n\tif err != nil {\n\t\treturn false, false, err\n\t}\n\n\tdefer ioutil.CheckClose(f, &err)\n\n\t_, err = f.Readdirnames(1)\n\tif err == io.EOF {\n\t\treturn true, false, nil\n\t}\n\n\tif err != nil {\n\t\treturn false, false, err\n\t}\n\n\treturn false, false, nil\n}\n\nfunc cleanUpDir(path string, all bool) error {\n\tif all {\n\t\treturn os.RemoveAll(path)\n\t}\n\n\tf, err := os.Open(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdefer ioutil.CheckClose(f, &err)\n\n\tnames, err := f.Readdirnames(-1)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, name := range names {\n\t\tif err := os.RemoveAll(filepath.Join(path, name)); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn err\n}\n\n// Config return the repository config\nfunc (r *Repository) Config() (*config.Config, error) {\n\treturn r.Storer.Config()\n}\n\n// Remote return a remote if exists\nfunc (r *Repository) Remote(name string) (*Remote, error) {\n\tcfg, err := r.Storer.Config()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tc, ok := cfg.Remotes[name]\n\tif !ok {\n\t\treturn nil, ErrRemoteNotFound\n\t}\n\n\treturn NewRemote(r.Storer, c), nil\n}\n\n// Remotes returns a list with all the remotes\nfunc (r *Repository) Remotes() ([]*Remote, error) {\n\tcfg, err := r.Storer.Config()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tremotes := make([]*Remote, len(cfg.Remotes))\n\n\tvar i int\n\tfor _, c := range cfg.Remotes {\n\t\tremotes[i] = NewRemote(r.Storer, c)\n\t\ti++\n\t}\n\n\treturn remotes, nil\n}\n\n// CreateRemote creates a new remote\nfunc (r *Repository) CreateRemote(c *config.RemoteConfig) (*Remote, error) {\n\tif err := c.Validate(); err != nil {\n\t\treturn nil, err\n\t}\n\n\tremote := NewRemote(r.Storer, c)\n\n\tcfg, err := r.Storer.Config()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif _, ok := cfg.Remotes[c.Name]; ok {\n\t\treturn nil, ErrRemoteExists\n\t}\n\n\tcfg.Remotes[c.Name] = c\n\treturn remote, r.Storer.SetConfig(cfg)\n}\n\n// CreateRemoteAnonymous creates a new anonymous remote. c.Name must be \"anonymous\".\n// It's used like 'git fetch git@github.com:src-d/go-git.git master:master'.\nfunc (r *Repository) CreateRemoteAnonymous(c *config.RemoteConfig) (*Remote, error) {\n\tif err := c.Validate(); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif c.Name != \"anonymous\" {\n\t\treturn nil, ErrAnonymousRemoteName\n\t}\n\n\tremote := NewRemote(r.Storer, c)\n\n\treturn remote, nil\n}\n\n// DeleteRemote delete a remote from the repository and delete the config\nfunc (r *Repository) DeleteRemote(name string) error {\n\tcfg, err := r.Storer.Config()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif _, ok := cfg.Remotes[name]; !ok {\n\t\treturn ErrRemoteNotFound\n\t}\n\n\tdelete(cfg.Remotes, name)\n\treturn r.Storer.SetConfig(cfg)\n}\n\n// Branch return a Branch if exists\nfunc (r *Repository) Branch(name string) (*config.Branch, error) {\n\tcfg, err := r.Storer.Config()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tb, ok := cfg.Branches[name]\n\tif !ok {\n\t\treturn nil, ErrBranchNotFound\n\t}\n\n\treturn b, nil\n}\n\n// CreateBranch creates a new Branch\nfunc (r *Repository) CreateBranch(c *config.Branch) error {\n\tif err := c.Validate(); err != nil {\n\t\treturn err\n\t}\n\n\tcfg, err := r.Storer.Config()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif _, ok := cfg.Branches[c.Name]; ok {\n\t\treturn ErrBranchExists\n\t}\n\n\tcfg.Branches[c.Name] = c\n\treturn r.Storer.SetConfig(cfg)\n}\n\n// DeleteBranch delete a Branch from the repository and delete the config\nfunc (r *Repository) DeleteBranch(name string) error {\n\tcfg, err := r.Storer.Config()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif _, ok := cfg.Branches[name]; !ok {\n\t\treturn ErrBranchNotFound\n\t}\n\n\tdelete(cfg.Branches, name)\n\treturn r.Storer.SetConfig(cfg)\n}\n\n// CreateTag creates a tag. If opts is included, the tag is an annotated tag,\n// otherwise a lightweight tag is created.\nfunc (r *Repository) CreateTag(name string, hash plumbing.Hash, opts *CreateTagOptions) (*plumbing.Reference, error) {\n\trname := plumbing.ReferenceName(path.Join(\"refs\", \"tags\", name))\n\n\t_, err := r.Storer.Reference(rname)\n\tswitch err {\n\tcase nil:\n\t\t// Tag exists, this is an error\n\t\treturn nil, ErrTagExists\n\tcase plumbing.ErrReferenceNotFound:\n\t\t// Tag missing, available for creation, pass this\n\tdefault:\n\t\t// Some other error\n\t\treturn nil, err\n\t}\n\n\tvar target plumbing.Hash\n\tif opts != nil {\n\t\ttarget, err = r.createTagObject(name, hash, opts)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t} else {\n\t\ttarget = hash\n\t}\n\n\tref := plumbing.NewHashReference(rname, target)\n\tif err = r.Storer.SetReference(ref); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn ref, nil\n}\n\nfunc (r *Repository) createTagObject(name string, hash plumbing.Hash, opts *CreateTagOptions) (plumbing.Hash, error) {\n\tif err := opts.Validate(r, hash); err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\trawobj, err := object.GetObject(r.Storer, hash)\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\ttag := &object.Tag{\n\t\tName:       name,\n\t\tTagger:     *opts.Tagger,\n\t\tMessage:    opts.Message,\n\t\tTargetType: rawobj.Type(),\n\t\tTarget:     hash,\n\t}\n\n\tif opts.SignKey != nil {\n\t\tsig, err := r.buildTagSignature(tag, opts.SignKey)\n\t\tif err != nil {\n\t\t\treturn plumbing.ZeroHash, err\n\t\t}\n\n\t\ttag.PGPSignature = sig\n\t}\n\n\tobj := r.Storer.NewEncodedObject()\n\tif err := tag.Encode(obj); err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\treturn r.Storer.SetEncodedObject(obj)\n}\n\nfunc (r *Repository) buildTagSignature(tag *object.Tag, signKey *openpgp.Entity) (string, error) {\n\tencoded := &plumbing.MemoryObject{}\n\tif err := tag.Encode(encoded); err != nil {\n\t\treturn \"\", err\n\t}\n\n\trdr, err := encoded.Reader()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tvar b bytes.Buffer\n\tif err := openpgp.ArmoredDetachSign(&b, signKey, rdr, nil); err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn b.String(), nil\n}\n\n// Tag returns a tag from the repository.\n//\n// If you want to check to see if the tag is an annotated tag, you can call\n// TagObject on the hash of the reference in ForEach:\n//\n//   ref, err := r.Tag(\"v0.1.0\")\n//   if err != nil {\n//     // Handle error\n//   }\n//\n//   obj, err := r.TagObject(ref.Hash())\n//   switch err {\n//   case nil:\n//     // Tag object present\n//   case plumbing.ErrObjectNotFound:\n//     // Not a tag object\n//   default:\n//     // Some other error\n//   }\n//\nfunc (r *Repository) Tag(name string) (*plumbing.Reference, error) {\n\tref, err := r.Reference(plumbing.ReferenceName(path.Join(\"refs\", \"tags\", name)), false)\n\tif err != nil {\n\t\tif err == plumbing.ErrReferenceNotFound {\n\t\t\t// Return a friendly error for this one, versus just ReferenceNotFound.\n\t\t\treturn nil, ErrTagNotFound\n\t\t}\n\n\t\treturn nil, err\n\t}\n\n\treturn ref, nil\n}\n\n// DeleteTag deletes a tag from the repository.\nfunc (r *Repository) DeleteTag(name string) error {\n\t_, err := r.Tag(name)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn r.Storer.RemoveReference(plumbing.ReferenceName(path.Join(\"refs\", \"tags\", name)))\n}\n\nfunc (r *Repository) resolveToCommitHash(h plumbing.Hash) (plumbing.Hash, error) {\n\tobj, err := r.Storer.EncodedObject(plumbing.AnyObject, h)\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\tswitch obj.Type() {\n\tcase plumbing.TagObject:\n\t\tt, err := object.DecodeTag(r.Storer, obj)\n\t\tif err != nil {\n\t\t\treturn plumbing.ZeroHash, err\n\t\t}\n\t\treturn r.resolveToCommitHash(t.Target)\n\tcase plumbing.CommitObject:\n\t\treturn h, nil\n\tdefault:\n\t\treturn plumbing.ZeroHash, ErrUnableToResolveCommit\n\t}\n}\n\n// Clone clones a remote repository\nfunc (r *Repository) clone(ctx context.Context, o *CloneOptions) error {\n\tif err := o.Validate(); err != nil {\n\t\treturn err\n\t}\n\n\tc := &config.RemoteConfig{\n\t\tName:  o.RemoteName,\n\t\tURLs:  []string{o.URL},\n\t\tFetch: r.cloneRefSpec(o),\n\t}\n\n\tif _, err := r.CreateRemote(c); err != nil {\n\t\treturn err\n\t}\n\n\tref, err := r.fetchAndUpdateReferences(ctx, &FetchOptions{\n\t\tRefSpecs:   c.Fetch,\n\t\tDepth:      o.Depth,\n\t\tAuth:       o.Auth,\n\t\tProgress:   o.Progress,\n\t\tTags:       o.Tags,\n\t\tRemoteName: o.RemoteName,\n\t}, o.ReferenceName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif r.wt != nil && !o.NoCheckout {\n\t\tw, err := r.Worktree()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\thead, err := r.Head()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif err := w.Reset(&ResetOptions{\n\t\t\tMode:   MergeReset,\n\t\t\tCommit: head.Hash(),\n\t\t}); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif o.RecurseSubmodules != NoRecurseSubmodules {\n\t\t\tif err := w.updateSubmodules(&SubmoduleUpdateOptions{\n\t\t\t\tRecurseSubmodules: o.RecurseSubmodules,\n\t\t\t\tAuth:              o.Auth,\n\t\t\t}); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\tif err := r.updateRemoteConfigIfNeeded(o, c, ref); err != nil {\n\t\treturn err\n\t}\n\n\tif ref.Name().IsBranch() {\n\t\tbranchRef := ref.Name()\n\t\tbranchName := strings.Split(string(branchRef), \"refs/heads/\")[1]\n\n\t\tb := &config.Branch{\n\t\t\tName:  branchName,\n\t\t\tMerge: branchRef,\n\t\t}\n\t\tif o.RemoteName == \"\" {\n\t\t\tb.Remote = \"origin\"\n\t\t} else {\n\t\t\tb.Remote = o.RemoteName\n\t\t}\n\t\tif err := r.CreateBranch(b); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\nconst (\n\trefspecTag              = \"+refs/tags/%s:refs/tags/%[1]s\"\n\trefspecSingleBranch     = \"+refs/heads/%s:refs/remotes/%s/%[1]s\"\n\trefspecSingleBranchHEAD = \"+HEAD:refs/remotes/%s/HEAD\"\n)\n\nfunc (r *Repository) cloneRefSpec(o *CloneOptions) []config.RefSpec {\n\tswitch {\n\tcase o.ReferenceName.IsTag():\n\t\treturn []config.RefSpec{\n\t\t\tconfig.RefSpec(fmt.Sprintf(refspecTag, o.ReferenceName.Short())),\n\t\t}\n\tcase o.SingleBranch && o.ReferenceName == plumbing.HEAD:\n\t\treturn []config.RefSpec{\n\t\t\tconfig.RefSpec(fmt.Sprintf(refspecSingleBranchHEAD, o.RemoteName)),\n\t\t\tconfig.RefSpec(fmt.Sprintf(refspecSingleBranch, plumbing.Master.Short(), o.RemoteName)),\n\t\t}\n\tcase o.SingleBranch:\n\t\treturn []config.RefSpec{\n\t\t\tconfig.RefSpec(fmt.Sprintf(refspecSingleBranch, o.ReferenceName.Short(), o.RemoteName)),\n\t\t}\n\tdefault:\n\t\treturn []config.RefSpec{\n\t\t\tconfig.RefSpec(fmt.Sprintf(config.DefaultFetchRefSpec, o.RemoteName)),\n\t\t}\n\t}\n}\n\nfunc (r *Repository) setIsBare(isBare bool) error {\n\tcfg, err := r.Storer.Config()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tcfg.Core.IsBare = isBare\n\treturn r.Storer.SetConfig(cfg)\n}\n\nfunc (r *Repository) updateRemoteConfigIfNeeded(o *CloneOptions, c *config.RemoteConfig, head *plumbing.Reference) error {\n\tif !o.SingleBranch {\n\t\treturn nil\n\t}\n\n\tc.Fetch = r.cloneRefSpec(o)\n\n\tcfg, err := r.Storer.Config()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tcfg.Remotes[c.Name] = c\n\treturn r.Storer.SetConfig(cfg)\n}\n\nfunc (r *Repository) fetchAndUpdateReferences(\n\tctx context.Context, o *FetchOptions, ref plumbing.ReferenceName,\n) (*plumbing.Reference, error) {\n\n\tif err := o.Validate(); err != nil {\n\t\treturn nil, err\n\t}\n\n\tremote, err := r.Remote(o.RemoteName)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tobjsUpdated := true\n\tremoteRefs, err := remote.fetch(ctx, o)\n\tif err == NoErrAlreadyUpToDate {\n\t\tobjsUpdated = false\n\t} else if err == packfile.ErrEmptyPackfile {\n\t\treturn nil, ErrFetching\n\t} else if err != nil {\n\t\treturn nil, err\n\t}\n\n\tresolvedRef, err := storer.ResolveReference(remoteRefs, ref)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\trefsUpdated, err := r.updateReferences(remote.c.Fetch, resolvedRef)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif !objsUpdated && !refsUpdated {\n\t\treturn nil, NoErrAlreadyUpToDate\n\t}\n\n\treturn resolvedRef, nil\n}\n\nfunc (r *Repository) updateReferences(spec []config.RefSpec,\n\tresolvedRef *plumbing.Reference) (updated bool, err error) {\n\n\tif !resolvedRef.Name().IsBranch() {\n\t\t// Detached HEAD mode\n\t\th, err := r.resolveToCommitHash(resolvedRef.Hash())\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\thead := plumbing.NewHashReference(plumbing.HEAD, h)\n\t\treturn updateReferenceStorerIfNeeded(r.Storer, head)\n\t}\n\n\trefs := []*plumbing.Reference{\n\t\t// Create local reference for the resolved ref\n\t\tresolvedRef,\n\t\t// Create local symbolic HEAD\n\t\tplumbing.NewSymbolicReference(plumbing.HEAD, resolvedRef.Name()),\n\t}\n\n\trefs = append(refs, r.calculateRemoteHeadReference(spec, resolvedRef)...)\n\n\tfor _, ref := range refs {\n\t\tu, err := updateReferenceStorerIfNeeded(r.Storer, ref)\n\t\tif err != nil {\n\t\t\treturn updated, err\n\t\t}\n\n\t\tif u {\n\t\t\tupdated = true\n\t\t}\n\t}\n\n\treturn\n}\n\nfunc (r *Repository) calculateRemoteHeadReference(spec []config.RefSpec,\n\tresolvedHead *plumbing.Reference) []*plumbing.Reference {\n\n\tvar refs []*plumbing.Reference\n\n\t// Create resolved HEAD reference with remote prefix if it does not\n\t// exist. This is needed when using single branch and HEAD.\n\tfor _, rs := range spec {\n\t\tname := resolvedHead.Name()\n\t\tif !rs.Match(name) {\n\t\t\tcontinue\n\t\t}\n\n\t\tname = rs.Dst(name)\n\t\t_, err := r.Storer.Reference(name)\n\t\tif err == plumbing.ErrReferenceNotFound {\n\t\t\trefs = append(refs, plumbing.NewHashReference(name, resolvedHead.Hash()))\n\t\t}\n\t}\n\n\treturn refs\n}\n\nfunc checkAndUpdateReferenceStorerIfNeeded(\n\ts storer.ReferenceStorer, r, old *plumbing.Reference) (\n\tupdated bool, err error) {\n\tp, err := s.Reference(r.Name())\n\tif err != nil && err != plumbing.ErrReferenceNotFound {\n\t\treturn false, err\n\t}\n\n\t// we use the string method to compare references, is the easiest way\n\tif err == plumbing.ErrReferenceNotFound || r.String() != p.String() {\n\t\tif err := s.CheckAndSetReference(r, old); err != nil {\n\t\t\treturn false, err\n\t\t}\n\n\t\treturn true, nil\n\t}\n\n\treturn false, nil\n}\n\nfunc updateReferenceStorerIfNeeded(\n\ts storer.ReferenceStorer, r *plumbing.Reference) (updated bool, err error) {\n\treturn checkAndUpdateReferenceStorerIfNeeded(s, r, nil)\n}\n\n// Fetch fetches references along with the objects necessary to complete\n// their histories, from the remote named as FetchOptions.RemoteName.\n//\n// Returns nil if the operation is successful, NoErrAlreadyUpToDate if there are\n// no changes to be fetched, or an error.\nfunc (r *Repository) Fetch(o *FetchOptions) error {\n\treturn r.FetchContext(context.Background(), o)\n}\n\n// FetchContext fetches references along with the objects necessary to complete\n// their histories, from the remote named as FetchOptions.RemoteName.\n//\n// Returns nil if the operation is successful, NoErrAlreadyUpToDate if there are\n// no changes to be fetched, or an error.\n//\n// The provided Context must be non-nil. If the context expires before the\n// operation is complete, an error is returned. The context only affects to the\n// transport operations.\nfunc (r *Repository) FetchContext(ctx context.Context, o *FetchOptions) error {\n\tif err := o.Validate(); err != nil {\n\t\treturn err\n\t}\n\n\tremote, err := r.Remote(o.RemoteName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn remote.FetchContext(ctx, o)\n}\n\n// Push performs a push to the remote. Returns NoErrAlreadyUpToDate if\n// the remote was already up-to-date, from the remote named as\n// FetchOptions.RemoteName.\nfunc (r *Repository) Push(o *PushOptions) error {\n\treturn r.PushContext(context.Background(), o)\n}\n\n// PushContext performs a push to the remote. Returns NoErrAlreadyUpToDate if\n// the remote was already up-to-date, from the remote named as\n// FetchOptions.RemoteName.\n//\n// The provided Context must be non-nil. If the context expires before the\n// operation is complete, an error is returned. The context only affects to the\n// transport operations.\nfunc (r *Repository) PushContext(ctx context.Context, o *PushOptions) error {\n\tif err := o.Validate(); err != nil {\n\t\treturn err\n\t}\n\n\tremote, err := r.Remote(o.RemoteName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn remote.PushContext(ctx, o)\n}\n\n// Log returns the commit history from the given LogOptions.\nfunc (r *Repository) Log(o *LogOptions) (object.CommitIter, error) {\n\tfn := commitIterFunc(o.Order)\n\tif fn == nil {\n\t\treturn nil, fmt.Errorf(\"invalid Order=%v\", o.Order)\n\t}\n\n\tvar (\n\t\tit  object.CommitIter\n\t\terr error\n\t)\n\tif o.All {\n\t\tit, err = r.logAll(fn)\n\t} else {\n\t\tit, err = r.log(o.From, fn)\n\t}\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif o.FileName != nil {\n\t\t// for `git log --all` also check parent (if the next commit comes from the real parent)\n\t\tit = r.logWithFile(*o.FileName, it, o.All)\n\t}\n\n\tif o.Since != nil || o.Until != nil {\n\t\tlimitOptions := object.LogLimitOptions{Since: o.Since, Until: o.Until}\n\t\tit = r.logWithLimit(it, limitOptions)\n\t}\n\n\treturn it, nil\n}\n\nfunc (r *Repository) log(from plumbing.Hash, commitIterFunc func(*object.Commit) object.CommitIter) (object.CommitIter, error) {\n\th := from\n\tif from == plumbing.ZeroHash {\n\t\thead, err := r.Head()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\th = head.Hash()\n\t}\n\n\tcommit, err := r.CommitObject(h)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn commitIterFunc(commit), nil\n}\n\nfunc (r *Repository) logAll(commitIterFunc func(*object.Commit) object.CommitIter) (object.CommitIter, error) {\n\treturn object.NewCommitAllIter(r.Storer, commitIterFunc)\n}\n\nfunc (*Repository) logWithFile(fileName string, commitIter object.CommitIter, checkParent bool) object.CommitIter {\n\treturn object.NewCommitFileIterFromIter(fileName, commitIter, checkParent)\n}\n\nfunc (*Repository) logWithLimit(commitIter object.CommitIter, limitOptions object.LogLimitOptions) object.CommitIter {\n\treturn object.NewCommitLimitIterFromIter(commitIter, limitOptions)\n}\n\nfunc commitIterFunc(order LogOrder) func(c *object.Commit) object.CommitIter {\n\tswitch order {\n\tcase LogOrderDefault:\n\t\treturn func(c *object.Commit) object.CommitIter {\n\t\t\treturn object.NewCommitPreorderIter(c, nil, nil)\n\t\t}\n\tcase LogOrderDFS:\n\t\treturn func(c *object.Commit) object.CommitIter {\n\t\t\treturn object.NewCommitPreorderIter(c, nil, nil)\n\t\t}\n\tcase LogOrderDFSPost:\n\t\treturn func(c *object.Commit) object.CommitIter {\n\t\t\treturn object.NewCommitPostorderIter(c, nil)\n\t\t}\n\tcase LogOrderBSF:\n\t\treturn func(c *object.Commit) object.CommitIter {\n\t\t\treturn object.NewCommitIterBSF(c, nil, nil)\n\t\t}\n\tcase LogOrderCommitterTime:\n\t\treturn func(c *object.Commit) object.CommitIter {\n\t\t\treturn object.NewCommitIterCTime(c, nil, nil)\n\t\t}\n\t}\n\treturn nil\n}\n\n// Tags returns all the tag References in a repository.\n//\n// If you want to check to see if the tag is an annotated tag, you can call\n// TagObject on the hash Reference passed in through ForEach:\n//\n//   iter, err := r.Tags()\n//   if err != nil {\n//     // Handle error\n//   }\n//\n//   if err := iter.ForEach(func (ref *plumbing.Reference) error {\n//     obj, err := r.TagObject(ref.Hash())\n//     switch err {\n//     case nil:\n//       // Tag object present\n//     case plumbing.ErrObjectNotFound:\n//       // Not a tag object\n//     default:\n//       // Some other error\n//       return err\n//     }\n//   }); err != nil {\n//     // Handle outer iterator error\n//   }\n//\nfunc (r *Repository) Tags() (storer.ReferenceIter, error) {\n\trefIter, err := r.Storer.IterReferences()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn storer.NewReferenceFilteredIter(\n\t\tfunc(r *plumbing.Reference) bool {\n\t\t\treturn r.Name().IsTag()\n\t\t}, refIter), nil\n}\n\n// Branches returns all the References that are Branches.\nfunc (r *Repository) Branches() (storer.ReferenceIter, error) {\n\trefIter, err := r.Storer.IterReferences()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn storer.NewReferenceFilteredIter(\n\t\tfunc(r *plumbing.Reference) bool {\n\t\t\treturn r.Name().IsBranch()\n\t\t}, refIter), nil\n}\n\n// Notes returns all the References that are notes. For more information:\n// https://git-scm.com/docs/git-notes\nfunc (r *Repository) Notes() (storer.ReferenceIter, error) {\n\trefIter, err := r.Storer.IterReferences()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn storer.NewReferenceFilteredIter(\n\t\tfunc(r *plumbing.Reference) bool {\n\t\t\treturn r.Name().IsNote()\n\t\t}, refIter), nil\n}\n\n// TreeObject return a Tree with the given hash. If not found\n// plumbing.ErrObjectNotFound is returned\nfunc (r *Repository) TreeObject(h plumbing.Hash) (*object.Tree, error) {\n\treturn object.GetTree(r.Storer, h)\n}\n\n// TreeObjects returns an unsorted TreeIter with all the trees in the repository\nfunc (r *Repository) TreeObjects() (*object.TreeIter, error) {\n\titer, err := r.Storer.IterEncodedObjects(plumbing.TreeObject)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn object.NewTreeIter(r.Storer, iter), nil\n}\n\n// CommitObject return a Commit with the given hash. If not found\n// plumbing.ErrObjectNotFound is returned.\nfunc (r *Repository) CommitObject(h plumbing.Hash) (*object.Commit, error) {\n\treturn object.GetCommit(r.Storer, h)\n}\n\n// CommitObjects returns an unsorted CommitIter with all the commits in the repository.\nfunc (r *Repository) CommitObjects() (object.CommitIter, error) {\n\titer, err := r.Storer.IterEncodedObjects(plumbing.CommitObject)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn object.NewCommitIter(r.Storer, iter), nil\n}\n\n// BlobObject returns a Blob with the given hash. If not found\n// plumbing.ErrObjectNotFound is returned.\nfunc (r *Repository) BlobObject(h plumbing.Hash) (*object.Blob, error) {\n\treturn object.GetBlob(r.Storer, h)\n}\n\n// BlobObjects returns an unsorted BlobIter with all the blobs in the repository.\nfunc (r *Repository) BlobObjects() (*object.BlobIter, error) {\n\titer, err := r.Storer.IterEncodedObjects(plumbing.BlobObject)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn object.NewBlobIter(r.Storer, iter), nil\n}\n\n// TagObject returns a Tag with the given hash. If not found\n// plumbing.ErrObjectNotFound is returned. This method only returns\n// annotated Tags, no lightweight Tags.\nfunc (r *Repository) TagObject(h plumbing.Hash) (*object.Tag, error) {\n\treturn object.GetTag(r.Storer, h)\n}\n\n// TagObjects returns a unsorted TagIter that can step through all of the annotated\n// tags in the repository.\nfunc (r *Repository) TagObjects() (*object.TagIter, error) {\n\titer, err := r.Storer.IterEncodedObjects(plumbing.TagObject)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn object.NewTagIter(r.Storer, iter), nil\n}\n\n// Object returns an Object with the given hash. If not found\n// plumbing.ErrObjectNotFound is returned.\nfunc (r *Repository) Object(t plumbing.ObjectType, h plumbing.Hash) (object.Object, error) {\n\tobj, err := r.Storer.EncodedObject(t, h)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn object.DecodeObject(r.Storer, obj)\n}\n\n// Objects returns an unsorted ObjectIter with all the objects in the repository.\nfunc (r *Repository) Objects() (*object.ObjectIter, error) {\n\titer, err := r.Storer.IterEncodedObjects(plumbing.AnyObject)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn object.NewObjectIter(r.Storer, iter), nil\n}\n\n// Head returns the reference where HEAD is pointing to.\nfunc (r *Repository) Head() (*plumbing.Reference, error) {\n\treturn storer.ResolveReference(r.Storer, plumbing.HEAD)\n}\n\n// Reference returns the reference for a given reference name. If resolved is\n// true, any symbolic reference will be resolved.\nfunc (r *Repository) Reference(name plumbing.ReferenceName, resolved bool) (\n\t*plumbing.Reference, error) {\n\n\tif resolved {\n\t\treturn storer.ResolveReference(r.Storer, name)\n\t}\n\n\treturn r.Storer.Reference(name)\n}\n\n// References returns an unsorted ReferenceIter for all references.\nfunc (r *Repository) References() (storer.ReferenceIter, error) {\n\treturn r.Storer.IterReferences()\n}\n\n// Worktree returns a worktree based on the given fs, if nil the default\n// worktree will be used.\nfunc (r *Repository) Worktree() (*Worktree, error) {\n\tif r.wt == nil {\n\t\treturn nil, ErrIsBareRepository\n\t}\n\n\treturn &Worktree{r: r, Filesystem: r.wt}, nil\n}\n\n// ResolveRevision resolves revision to corresponding hash. It will always\n// resolve to a commit hash, not a tree or annotated tag.\n//\n// Implemented resolvers : HEAD, branch, tag, heads/branch, refs/heads/branch,\n// refs/tags/tag, refs/remotes/origin/branch, refs/remotes/origin/HEAD, tilde and caret (HEAD~1, master~^, tag~2, ref/heads/master~1, ...), selection by text (HEAD^{/fix nasty bug})\nfunc (r *Repository) ResolveRevision(rev plumbing.Revision) (*plumbing.Hash, error) {\n\tp := revision.NewParserFromString(string(rev))\n\n\titems, err := p.Parse()\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar commit *object.Commit\n\n\tfor _, item := range items {\n\t\tswitch item.(type) {\n\t\tcase revision.Ref:\n\t\t\trevisionRef := item.(revision.Ref)\n\n\t\t\tvar tryHashes []plumbing.Hash\n\n\t\t\tmaybeHash := plumbing.NewHash(string(revisionRef))\n\n\t\t\tif !maybeHash.IsZero() {\n\t\t\t\ttryHashes = append(tryHashes, maybeHash)\n\t\t\t}\n\n\t\t\tfor _, rule := range append([]string{\"%s\"}, plumbing.RefRevParseRules...) {\n\t\t\t\tref, err := storer.ResolveReference(r.Storer, plumbing.ReferenceName(fmt.Sprintf(rule, revisionRef)))\n\n\t\t\t\tif err == nil {\n\t\t\t\t\ttryHashes = append(tryHashes, ref.Hash())\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// in ambiguous cases, `git rev-parse` will emit a warning, but\n\t\t\t// will always return the oid in preference to a ref; we don't have\n\t\t\t// the ability to emit a warning here, so (for speed purposes)\n\t\t\t// don't bother to detect the ambiguity either, just return in the\n\t\t\t// priority that git would.\n\t\t\tgotOne := false\n\t\t\tfor _, hash := range tryHashes {\n\t\t\t\tcommitObj, err := r.CommitObject(hash)\n\t\t\t\tif err == nil {\n\t\t\t\t\tcommit = commitObj\n\t\t\t\t\tgotOne = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\n\t\t\t\ttagObj, err := r.TagObject(hash)\n\t\t\t\tif err == nil {\n\t\t\t\t\t// If the tag target lookup fails here, this most likely\n\t\t\t\t\t// represents some sort of repo corruption, so let the\n\t\t\t\t\t// error bubble up.\n\t\t\t\t\ttagCommit, err := tagObj.Commit()\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn &plumbing.ZeroHash, err\n\t\t\t\t\t}\n\t\t\t\t\tcommit = tagCommit\n\t\t\t\t\tgotOne = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif !gotOne {\n\t\t\t\treturn &plumbing.ZeroHash, plumbing.ErrReferenceNotFound\n\t\t\t}\n\n\t\tcase revision.CaretPath:\n\t\t\tdepth := item.(revision.CaretPath).Depth\n\n\t\t\tif depth == 0 {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\titer := commit.Parents()\n\n\t\t\tc, err := iter.Next()\n\n\t\t\tif err != nil {\n\t\t\t\treturn &plumbing.ZeroHash, err\n\t\t\t}\n\n\t\t\tif depth == 1 {\n\t\t\t\tcommit = c\n\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\tc, err = iter.Next()\n\n\t\t\tif err != nil {\n\t\t\t\treturn &plumbing.ZeroHash, err\n\t\t\t}\n\n\t\t\tcommit = c\n\t\tcase revision.TildePath:\n\t\t\tfor i := 0; i < item.(revision.TildePath).Depth; i++ {\n\t\t\t\tc, err := commit.Parents().Next()\n\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn &plumbing.ZeroHash, err\n\t\t\t\t}\n\n\t\t\t\tcommit = c\n\t\t\t}\n\t\tcase revision.CaretReg:\n\t\t\thistory := object.NewCommitPreorderIter(commit, nil, nil)\n\n\t\t\tre := item.(revision.CaretReg).Regexp\n\t\t\tnegate := item.(revision.CaretReg).Negate\n\n\t\t\tvar c *object.Commit\n\n\t\t\terr := history.ForEach(func(hc *object.Commit) error {\n\t\t\t\tif !negate && re.MatchString(hc.Message) {\n\t\t\t\t\tc = hc\n\t\t\t\t\treturn storer.ErrStop\n\t\t\t\t}\n\n\t\t\t\tif negate && !re.MatchString(hc.Message) {\n\t\t\t\t\tc = hc\n\t\t\t\t\treturn storer.ErrStop\n\t\t\t\t}\n\n\t\t\t\treturn nil\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\treturn &plumbing.ZeroHash, err\n\t\t\t}\n\n\t\t\tif c == nil {\n\t\t\t\treturn &plumbing.ZeroHash, fmt.Errorf(`No commit message match regexp : \"%s\"`, re.String())\n\t\t\t}\n\n\t\t\tcommit = c\n\t\t}\n\t}\n\n\treturn &commit.Hash, nil\n}\n\ntype RepackConfig struct {\n\t// UseRefDeltas configures whether packfile encoder will use reference deltas.\n\t// By default OFSDeltaObject is used.\n\tUseRefDeltas bool\n\t// OnlyDeletePacksOlderThan if set to non-zero value\n\t// selects only objects older than the time provided.\n\tOnlyDeletePacksOlderThan time.Time\n}\n\nfunc (r *Repository) RepackObjects(cfg *RepackConfig) (err error) {\n\tpos, ok := r.Storer.(storer.PackedObjectStorer)\n\tif !ok {\n\t\treturn ErrPackedObjectsNotSupported\n\t}\n\n\t// Get the existing object packs.\n\ths, err := pos.ObjectPacks()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Create a new pack.\n\tnh, err := r.createNewObjectPack(cfg)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Delete old packs.\n\tfor _, h := range hs {\n\t\t// Skip if new hash is the same as an old one.\n\t\tif h == nh {\n\t\t\tcontinue\n\t\t}\n\t\terr = pos.DeleteOldObjectPackAndIndex(h, cfg.OnlyDeletePacksOlderThan)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// createNewObjectPack is a helper for RepackObjects taking care\n// of creating a new pack. It is used so the the PackfileWriter\n// deferred close has the right scope.\nfunc (r *Repository) createNewObjectPack(cfg *RepackConfig) (h plumbing.Hash, err error) {\n\tow := newObjectWalker(r.Storer)\n\terr = ow.walkAllRefs()\n\tif err != nil {\n\t\treturn h, err\n\t}\n\tobjs := make([]plumbing.Hash, 0, len(ow.seen))\n\tfor h := range ow.seen {\n\t\tobjs = append(objs, h)\n\t}\n\tpfw, ok := r.Storer.(storer.PackfileWriter)\n\tif !ok {\n\t\treturn h, fmt.Errorf(\"Repository storer is not a storer.PackfileWriter\")\n\t}\n\twc, err := pfw.PackfileWriter()\n\tif err != nil {\n\t\treturn h, err\n\t}\n\tdefer ioutil.CheckClose(wc, &err)\n\tscfg, err := r.Storer.Config()\n\tif err != nil {\n\t\treturn h, err\n\t}\n\tenc := packfile.NewEncoder(wc, r.Storer, cfg.UseRefDeltas)\n\th, err = enc.Encode(objs, scfg.Pack.Window)\n\tif err != nil {\n\t\treturn h, err\n\t}\n\n\t// Delete the packed, loose objects.\n\tif los, ok := r.Storer.(storer.LooseObjectStorer); ok {\n\t\terr = los.ForEachObjectHash(func(hash plumbing.Hash) error {\n\t\t\tif ow.isSeen(hash) {\n\t\t\t\terr = los.DeleteLooseObject(hash)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t\tif err != nil {\n\t\t\treturn h, err\n\t\t}\n\t}\n\n\treturn h, err\n}\n"
        },
        {
          "name": "repository_test.go",
          "type": "blob",
          "size": 73.8544921875,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"os/exec\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\tfixtures \"gopkg.in/src-d/go-git-fixtures.v3\"\n\n\t\"golang.org/x/crypto/openpgp\"\n\t\"golang.org/x/crypto/openpgp/armor\"\n\topenpgperr \"golang.org/x/crypto/openpgp/errors\"\n\n\t\"gopkg.in/src-d/go-git.v4/config\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/cache\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/object\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/storer\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/transport\"\n\t\"gopkg.in/src-d/go-git.v4/storage\"\n\t\"gopkg.in/src-d/go-git.v4/storage/filesystem\"\n\t\"gopkg.in/src-d/go-git.v4/storage/memory\"\n\n\t. \"gopkg.in/check.v1\"\n\t\"gopkg.in/src-d/go-billy.v4/memfs\"\n\t\"gopkg.in/src-d/go-billy.v4/osfs\"\n\t\"gopkg.in/src-d/go-billy.v4/util\"\n)\n\ntype RepositorySuite struct {\n\tBaseSuite\n}\n\nvar _ = Suite(&RepositorySuite{})\n\nfunc (s *RepositorySuite) TestInit(c *C) {\n\tr, err := Init(memory.NewStorage(), memfs.New())\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Core.IsBare, Equals, false)\n}\n\nfunc (s *RepositorySuite) TestInitNonStandardDotGit(c *C) {\n\tdir, err := ioutil.TempDir(\"\", \"init-non-standard\")\n\tc.Assert(err, IsNil)\n\tc.Assert(os.RemoveAll(dir), IsNil)\n\n\tfs := osfs.New(dir)\n\tdot, _ := fs.Chroot(\"storage\")\n\tstorage := filesystem.NewStorage(dot, cache.NewObjectLRUDefault())\n\n\twt, _ := fs.Chroot(\"worktree\")\n\tr, err := Init(storage, wt)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tf, err := fs.Open(fs.Join(\"worktree\", \".git\"))\n\tc.Assert(err, IsNil)\n\n\tall, err := ioutil.ReadAll(f)\n\tc.Assert(err, IsNil)\n\tc.Assert(string(all), Equals, fmt.Sprintf(\"gitdir: %s\\n\", filepath.Join(\"..\", \"storage\")))\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Core.Worktree, Equals, filepath.Join(\"..\", \"worktree\"))\n}\n\nfunc (s *RepositorySuite) TestInitStandardDotGit(c *C) {\n\tdir, err := ioutil.TempDir(\"\", \"init-standard\")\n\tc.Assert(err, IsNil)\n\tc.Assert(os.RemoveAll(dir), IsNil)\n\n\tfs := osfs.New(dir)\n\tdot, _ := fs.Chroot(\".git\")\n\tstorage := filesystem.NewStorage(dot, cache.NewObjectLRUDefault())\n\n\tr, err := Init(storage, fs)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tl, err := fs.ReadDir(\".git\")\n\tc.Assert(err, IsNil)\n\tc.Assert(len(l) > 0, Equals, true)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Core.Worktree, Equals, \"\")\n}\n\nfunc (s *RepositorySuite) TestInitBare(c *C) {\n\tr, err := Init(memory.NewStorage(), nil)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Core.IsBare, Equals, true)\n\n}\n\nfunc (s *RepositorySuite) TestInitAlreadyExists(c *C) {\n\tst := memory.NewStorage()\n\n\tr, err := Init(st, nil)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tr, err = Init(st, nil)\n\tc.Assert(err, Equals, ErrRepositoryAlreadyExists)\n\tc.Assert(r, IsNil)\n}\n\nfunc (s *RepositorySuite) TestOpen(c *C) {\n\tst := memory.NewStorage()\n\n\tr, err := Init(st, memfs.New())\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tr, err = Open(st, memfs.New())\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n}\n\nfunc (s *RepositorySuite) TestOpenBare(c *C) {\n\tst := memory.NewStorage()\n\n\tr, err := Init(st, nil)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tr, err = Open(st, nil)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n}\n\nfunc (s *RepositorySuite) TestOpenBareMissingWorktree(c *C) {\n\tst := memory.NewStorage()\n\n\tr, err := Init(st, memfs.New())\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tr, err = Open(st, nil)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n}\n\nfunc (s *RepositorySuite) TestOpenNotExists(c *C) {\n\tr, err := Open(memory.NewStorage(), nil)\n\tc.Assert(err, Equals, ErrRepositoryNotExists)\n\tc.Assert(r, IsNil)\n}\n\nfunc (s *RepositorySuite) TestClone(c *C) {\n\tr, err := Clone(memory.NewStorage(), nil, &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tremotes, err := r.Remotes()\n\tc.Assert(err, IsNil)\n\tc.Assert(remotes, HasLen, 1)\n}\n\nfunc (s *RepositorySuite) TestCloneContext(c *C) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\n\tr, err := CloneContext(ctx, memory.NewStorage(), nil, &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(r, NotNil)\n\tc.Assert(err, ErrorMatches, \".* context canceled\")\n}\n\nfunc (s *RepositorySuite) TestCloneWithTags(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, err := Clone(memory.NewStorage(), nil, &CloneOptions{URL: url, Tags: NoTags})\n\tc.Assert(err, IsNil)\n\n\tremotes, err := r.Remotes()\n\tc.Assert(err, IsNil)\n\tc.Assert(remotes, HasLen, 1)\n\n\ti, err := r.References()\n\tc.Assert(err, IsNil)\n\n\tvar count int\n\ti.ForEach(func(r *plumbing.Reference) error { count++; return nil })\n\n\tc.Assert(count, Equals, 3)\n}\n\nfunc (s *RepositorySuite) TestCreateRemoteAndRemote(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\tremote, err := r.CreateRemote(&config.RemoteConfig{\n\t\tName: \"foo\",\n\t\tURLs: []string{\"http://foo/foo.git\"},\n\t})\n\n\tc.Assert(err, IsNil)\n\tc.Assert(remote.Config().Name, Equals, \"foo\")\n\n\talt, err := r.Remote(\"foo\")\n\tc.Assert(err, IsNil)\n\tc.Assert(alt, Not(Equals), remote)\n\tc.Assert(alt.Config().Name, Equals, \"foo\")\n}\n\nfunc (s *RepositorySuite) TestCreateRemoteInvalid(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\tremote, err := r.CreateRemote(&config.RemoteConfig{})\n\n\tc.Assert(err, Equals, config.ErrRemoteConfigEmptyName)\n\tc.Assert(remote, IsNil)\n}\n\nfunc (s *RepositorySuite) TestCreateRemoteAnonymous(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\tremote, err := r.CreateRemoteAnonymous(&config.RemoteConfig{\n\t\tName: \"anonymous\",\n\t\tURLs: []string{\"http://foo/foo.git\"},\n\t})\n\n\tc.Assert(err, IsNil)\n\tc.Assert(remote.Config().Name, Equals, \"anonymous\")\n}\n\nfunc (s *RepositorySuite) TestCreateRemoteAnonymousInvalidName(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\tremote, err := r.CreateRemoteAnonymous(&config.RemoteConfig{\n\t\tName: \"not_anonymous\",\n\t\tURLs: []string{\"http://foo/foo.git\"},\n\t})\n\n\tc.Assert(err, Equals, ErrAnonymousRemoteName)\n\tc.Assert(remote, IsNil)\n}\n\nfunc (s *RepositorySuite) TestCreateRemoteAnonymousInvalid(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\tremote, err := r.CreateRemoteAnonymous(&config.RemoteConfig{})\n\n\tc.Assert(err, Equals, config.ErrRemoteConfigEmptyName)\n\tc.Assert(remote, IsNil)\n}\n\nfunc (s *RepositorySuite) TestDeleteRemote(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\t_, err := r.CreateRemote(&config.RemoteConfig{\n\t\tName: \"foo\",\n\t\tURLs: []string{\"http://foo/foo.git\"},\n\t})\n\n\tc.Assert(err, IsNil)\n\n\terr = r.DeleteRemote(\"foo\")\n\tc.Assert(err, IsNil)\n\n\talt, err := r.Remote(\"foo\")\n\tc.Assert(err, Equals, ErrRemoteNotFound)\n\tc.Assert(alt, IsNil)\n}\n\nfunc (s *RepositorySuite) TestCreateBranchAndBranch(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\ttestBranch := &config.Branch{\n\t\tName:   \"foo\",\n\t\tRemote: \"origin\",\n\t\tMerge:  \"refs/heads/foo\",\n\t}\n\terr := r.CreateBranch(testBranch)\n\n\tc.Assert(err, IsNil)\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(len(cfg.Branches), Equals, 1)\n\tbranch := cfg.Branches[\"foo\"]\n\tc.Assert(branch.Name, Equals, testBranch.Name)\n\tc.Assert(branch.Remote, Equals, testBranch.Remote)\n\tc.Assert(branch.Merge, Equals, testBranch.Merge)\n\n\tbranch, err = r.Branch(\"foo\")\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Name, Equals, testBranch.Name)\n\tc.Assert(branch.Remote, Equals, testBranch.Remote)\n\tc.Assert(branch.Merge, Equals, testBranch.Merge)\n}\n\nfunc (s *RepositorySuite) TestCreateBranchUnmarshal(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\n\texpected := []byte(`[core]\n\tbare = true\n[remote \"foo\"]\n\turl = http://foo/foo.git\n\tfetch = +refs/heads/*:refs/remotes/foo/*\n[branch \"foo\"]\n\tremote = origin\n\tmerge = refs/heads/foo\n[branch \"master\"]\n\tremote = origin\n\tmerge = refs/heads/master\n`)\n\n\t_, err := r.CreateRemote(&config.RemoteConfig{\n\t\tName: \"foo\",\n\t\tURLs: []string{\"http://foo/foo.git\"},\n\t})\n\tc.Assert(err, IsNil)\n\ttestBranch1 := &config.Branch{\n\t\tName:   \"master\",\n\t\tRemote: \"origin\",\n\t\tMerge:  \"refs/heads/master\",\n\t}\n\ttestBranch2 := &config.Branch{\n\t\tName:   \"foo\",\n\t\tRemote: \"origin\",\n\t\tMerge:  \"refs/heads/foo\",\n\t}\n\terr = r.CreateBranch(testBranch1)\n\tc.Assert(err, IsNil)\n\terr = r.CreateBranch(testBranch2)\n\tc.Assert(err, IsNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tmarshaled, err := cfg.Marshal()\n\tc.Assert(err, IsNil)\n\tc.Assert(string(expected), Equals, string(marshaled))\n}\n\nfunc (s *RepositorySuite) TestBranchInvalid(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\tbranch, err := r.Branch(\"foo\")\n\n\tc.Assert(err, NotNil)\n\tc.Assert(branch, IsNil)\n}\n\nfunc (s *RepositorySuite) TestCreateBranchInvalid(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.CreateBranch(&config.Branch{})\n\n\tc.Assert(err, NotNil)\n\n\ttestBranch := &config.Branch{\n\t\tName:   \"foo\",\n\t\tRemote: \"origin\",\n\t\tMerge:  \"refs/heads/foo\",\n\t}\n\terr = r.CreateBranch(testBranch)\n\tc.Assert(err, IsNil)\n\terr = r.CreateBranch(testBranch)\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *RepositorySuite) TestDeleteBranch(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\ttestBranch := &config.Branch{\n\t\tName:   \"foo\",\n\t\tRemote: \"origin\",\n\t\tMerge:  \"refs/heads/foo\",\n\t}\n\terr := r.CreateBranch(testBranch)\n\n\tc.Assert(err, IsNil)\n\n\terr = r.DeleteBranch(\"foo\")\n\tc.Assert(err, IsNil)\n\n\tb, err := r.Branch(\"foo\")\n\tc.Assert(err, Equals, ErrBranchNotFound)\n\tc.Assert(b, IsNil)\n\n\terr = r.DeleteBranch(\"foo\")\n\tc.Assert(err, Equals, ErrBranchNotFound)\n}\n\nfunc (s *RepositorySuite) TestPlainInit(c *C) {\n\tdir, err := ioutil.TempDir(\"\", \"plain-init\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(dir)\n\n\tr, err := PlainInit(dir, true)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Core.IsBare, Equals, true)\n}\n\nfunc (s *RepositorySuite) TestPlainInitAlreadyExists(c *C) {\n\tdir, err := ioutil.TempDir(\"\", \"plain-init\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(dir)\n\n\tr, err := PlainInit(dir, true)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tr, err = PlainInit(dir, true)\n\tc.Assert(err, Equals, ErrRepositoryAlreadyExists)\n\tc.Assert(r, IsNil)\n}\n\nfunc (s *RepositorySuite) TestPlainOpen(c *C) {\n\tdir, err := ioutil.TempDir(\"\", \"plain-open\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(dir)\n\n\tr, err := PlainInit(dir, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tr, err = PlainOpen(dir)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n}\n\nfunc (s *RepositorySuite) TestPlainOpenBare(c *C) {\n\tdir, err := ioutil.TempDir(\"\", \"plain-open\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(dir)\n\n\tr, err := PlainInit(dir, true)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tr, err = PlainOpen(dir)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n}\n\nfunc (s *RepositorySuite) TestPlainOpenNotBare(c *C) {\n\tdir, err := ioutil.TempDir(\"\", \"plain-open\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(dir)\n\n\tr, err := PlainInit(dir, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\tr, err = PlainOpen(filepath.Join(dir, \".git\"))\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n}\n\nfunc (s *RepositorySuite) testPlainOpenGitFile(c *C, f func(string, string) string) {\n\tdir, err := ioutil.TempDir(\"\", \"plain-open\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(dir)\n\n\tr, err := PlainInit(dir, true)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\taltDir, err := ioutil.TempDir(\"\", \"plain-open\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(altDir)\n\n\terr = ioutil.WriteFile(filepath.Join(altDir, \".git\"), []byte(f(dir, altDir)), 0644)\n\tc.Assert(err, IsNil)\n\n\tr, err = PlainOpen(altDir)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n}\n\nfunc (s *RepositorySuite) TestPlainOpenBareAbsoluteGitDirFile(c *C) {\n\ts.testPlainOpenGitFile(c, func(dir, altDir string) string {\n\t\treturn fmt.Sprintf(\"gitdir: %s\\n\", dir)\n\t})\n}\n\nfunc (s *RepositorySuite) TestPlainOpenBareAbsoluteGitDirFileNoEOL(c *C) {\n\ts.testPlainOpenGitFile(c, func(dir, altDir string) string {\n\t\treturn fmt.Sprintf(\"gitdir: %s\", dir)\n\t})\n}\n\nfunc (s *RepositorySuite) TestPlainOpenBareRelativeGitDirFile(c *C) {\n\ts.testPlainOpenGitFile(c, func(dir, altDir string) string {\n\t\tdir, err := filepath.Rel(altDir, dir)\n\t\tc.Assert(err, IsNil)\n\t\treturn fmt.Sprintf(\"gitdir: %s\\n\", dir)\n\t})\n}\n\nfunc (s *RepositorySuite) TestPlainOpenBareRelativeGitDirFileNoEOL(c *C) {\n\ts.testPlainOpenGitFile(c, func(dir, altDir string) string {\n\t\tdir, err := filepath.Rel(altDir, dir)\n\t\tc.Assert(err, IsNil)\n\t\treturn fmt.Sprintf(\"gitdir: %s\\n\", dir)\n\t})\n}\n\nfunc (s *RepositorySuite) TestPlainOpenBareRelativeGitDirFileTrailingGarbage(c *C) {\n\tdir, err := ioutil.TempDir(\"\", \"plain-open\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(dir)\n\n\tr, err := PlainInit(dir, true)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\taltDir, err := ioutil.TempDir(\"\", \"plain-open\")\n\tc.Assert(err, IsNil)\n\terr = ioutil.WriteFile(filepath.Join(altDir, \".git\"), []byte(fmt.Sprintf(\"gitdir: %s\\nTRAILING\", altDir)), 0644)\n\tc.Assert(err, IsNil)\n\n\tr, err = PlainOpen(altDir)\n\tc.Assert(err, Equals, ErrRepositoryNotExists)\n\tc.Assert(r, IsNil)\n}\n\nfunc (s *RepositorySuite) TestPlainOpenBareRelativeGitDirFileBadPrefix(c *C) {\n\tdir, err := ioutil.TempDir(\"\", \"plain-open\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(dir)\n\n\tr, err := PlainInit(dir, true)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\taltDir, err := ioutil.TempDir(\"\", \"plain-open\")\n\tc.Assert(err, IsNil)\n\terr = ioutil.WriteFile(filepath.Join(altDir, \".git\"), []byte(fmt.Sprintf(\"xgitdir: %s\\n\", dir)), 0644)\n\tc.Assert(err, IsNil)\n\n\tr, err = PlainOpen(altDir)\n\tc.Assert(err, ErrorMatches, \".*gitdir.*\")\n\tc.Assert(r, IsNil)\n}\n\nfunc (s *RepositorySuite) TestPlainOpenNotExists(c *C) {\n\tr, err := PlainOpen(\"/not-exists/\")\n\tc.Assert(err, Equals, ErrRepositoryNotExists)\n\tc.Assert(r, IsNil)\n}\n\nfunc (s *RepositorySuite) TestPlainOpenDetectDotGit(c *C) {\n\tdir, err := ioutil.TempDir(\"\", \"plain-open\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(dir)\n\n\tsubdir := filepath.Join(dir, \"a\", \"b\")\n\terr = os.MkdirAll(subdir, 0755)\n\tc.Assert(err, IsNil)\n\n\tr, err := PlainInit(dir, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\topt := &PlainOpenOptions{DetectDotGit: true}\n\tr, err = PlainOpenWithOptions(subdir, opt)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n}\n\nfunc (s *RepositorySuite) TestPlainOpenNotExistsDetectDotGit(c *C) {\n\tdir, err := ioutil.TempDir(\"\", \"plain-open\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(dir)\n\n\topt := &PlainOpenOptions{DetectDotGit: true}\n\tr, err := PlainOpenWithOptions(dir, opt)\n\tc.Assert(err, Equals, ErrRepositoryNotExists)\n\tc.Assert(r, IsNil)\n}\n\nfunc (s *RepositorySuite) TestPlainClone(c *C) {\n\tr, err := PlainClone(c.MkDir(), false, &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tremotes, err := r.Remotes()\n\tc.Assert(err, IsNil)\n\tc.Assert(remotes, HasLen, 1)\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Branches, HasLen, 1)\n\tc.Assert(cfg.Branches[\"master\"].Name, Equals, \"master\")\n}\n\nfunc (s *RepositorySuite) TestPlainCloneWithRemoteName(c *C) {\n\tr, err := PlainClone(c.MkDir(), false, &CloneOptions{\n\t\tURL:        s.GetBasicLocalRepositoryURL(),\n\t\tRemoteName: \"test\",\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tremote, err := r.Remote(\"test\")\n\tc.Assert(err, IsNil)\n\tc.Assert(remote, NotNil)\n}\n\nfunc (s *RepositorySuite) TestPlainCloneOverExistingGitDirectory(c *C) {\n\ttmpDir := c.MkDir()\n\tr, err := PlainInit(tmpDir, false)\n\tc.Assert(r, NotNil)\n\tc.Assert(err, IsNil)\n\n\tr, err = PlainClone(tmpDir, false, &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(r, IsNil)\n\tc.Assert(err, Equals, ErrRepositoryAlreadyExists)\n}\n\nfunc (s *RepositorySuite) TestPlainCloneContextCancel(c *C) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\n\tr, err := PlainCloneContext(ctx, c.MkDir(), false, &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(r, NotNil)\n\tc.Assert(err, ErrorMatches, \".* context canceled\")\n}\n\nfunc (s *RepositorySuite) TestPlainCloneContextNonExistentWithExistentDir(c *C) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\n\ttmpDir := c.MkDir()\n\trepoDir := tmpDir\n\n\tr, err := PlainCloneContext(ctx, repoDir, false, &CloneOptions{\n\t\tURL: \"incorrectOnPurpose\",\n\t})\n\tc.Assert(r, NotNil)\n\tc.Assert(err, Equals, transport.ErrRepositoryNotFound)\n\n\t_, err = os.Stat(repoDir)\n\tc.Assert(os.IsNotExist(err), Equals, false)\n\n\tnames, err := ioutil.ReadDir(repoDir)\n\tc.Assert(err, IsNil)\n\tc.Assert(names, HasLen, 0)\n}\n\nfunc (s *RepositorySuite) TestPlainCloneContextNonExistentWithNonExistentDir(c *C) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\n\ttmpDir := c.MkDir()\n\trepoDir := filepath.Join(tmpDir, \"repoDir\")\n\n\tr, err := PlainCloneContext(ctx, repoDir, false, &CloneOptions{\n\t\tURL: \"incorrectOnPurpose\",\n\t})\n\tc.Assert(r, NotNil)\n\tc.Assert(err, Equals, transport.ErrRepositoryNotFound)\n\n\t_, err = os.Stat(repoDir)\n\tc.Assert(os.IsNotExist(err), Equals, true)\n}\n\nfunc (s *RepositorySuite) TestPlainCloneContextNonExistentWithNotDir(c *C) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\n\ttmpDir := c.MkDir()\n\trepoDir := filepath.Join(tmpDir, \"repoDir\")\n\tf, err := os.Create(repoDir)\n\tc.Assert(err, IsNil)\n\tc.Assert(f.Close(), IsNil)\n\n\tr, err := PlainCloneContext(ctx, repoDir, false, &CloneOptions{\n\t\tURL: \"incorrectOnPurpose\",\n\t})\n\tc.Assert(r, IsNil)\n\tc.Assert(err, ErrorMatches, \".*not a directory.*\")\n\n\tfi, err := os.Stat(repoDir)\n\tc.Assert(err, IsNil)\n\tc.Assert(fi.IsDir(), Equals, false)\n}\n\nfunc (s *RepositorySuite) TestPlainCloneContextNonExistentWithNotEmptyDir(c *C) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\n\ttmpDir := c.MkDir()\n\trepoDirPath := filepath.Join(tmpDir, \"repoDir\")\n\terr := os.Mkdir(repoDirPath, 0777)\n\tc.Assert(err, IsNil)\n\n\tdummyFile := filepath.Join(repoDirPath, \"dummyFile\")\n\terr = ioutil.WriteFile(dummyFile, []byte(fmt.Sprint(\"dummyContent\")), 0644)\n\tc.Assert(err, IsNil)\n\n\tr, err := PlainCloneContext(ctx, repoDirPath, false, &CloneOptions{\n\t\tURL: \"incorrectOnPurpose\",\n\t})\n\tc.Assert(r, NotNil)\n\tc.Assert(err, Equals, transport.ErrRepositoryNotFound)\n\n\t_, err = os.Stat(dummyFile)\n\tc.Assert(err, IsNil)\n\n}\n\nfunc (s *RepositorySuite) TestPlainCloneContextNonExistingOverExistingGitDirectory(c *C) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\n\ttmpDir := c.MkDir()\n\tr, err := PlainInit(tmpDir, false)\n\tc.Assert(r, NotNil)\n\tc.Assert(err, IsNil)\n\n\tr, err = PlainCloneContext(ctx, tmpDir, false, &CloneOptions{\n\t\tURL: \"incorrectOnPurpose\",\n\t})\n\tc.Assert(r, IsNil)\n\tc.Assert(err, Equals, ErrRepositoryAlreadyExists)\n}\n\nfunc (s *RepositorySuite) TestPlainCloneWithRecurseSubmodules(c *C) {\n\tif testing.Short() {\n\t\tc.Skip(\"skipping test in short mode.\")\n\t}\n\n\tdir, err := ioutil.TempDir(\"\", \"plain-clone-submodule\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(dir)\n\n\tpath := fixtures.ByTag(\"submodule\").One().Worktree().Root()\n\tr, err := PlainClone(dir, false, &CloneOptions{\n\t\tURL:               path,\n\t\tRecurseSubmodules: DefaultSubmoduleRecursionDepth,\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Remotes, HasLen, 1)\n\tc.Assert(cfg.Branches, HasLen, 1)\n\tc.Assert(cfg.Submodules, HasLen, 2)\n}\n\nfunc (s *RepositorySuite) TestPlainCloneNoCheckout(c *C) {\n\tdir, err := ioutil.TempDir(\"\", \"plain-clone-no-checkout\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(dir)\n\n\tpath := fixtures.ByTag(\"submodule\").One().Worktree().Root()\n\tr, err := PlainClone(dir, false, &CloneOptions{\n\t\tURL:               path,\n\t\tNoCheckout:        true,\n\t\tRecurseSubmodules: DefaultSubmoduleRecursionDepth,\n\t})\n\tc.Assert(err, IsNil)\n\n\th, err := r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(h.Hash().String(), Equals, \"b685400c1f9316f350965a5993d350bc746b0bf4\")\n\n\tfi, err := osfs.New(dir).ReadDir(\"\")\n\tc.Assert(err, IsNil)\n\tc.Assert(fi, HasLen, 1) // .git\n}\n\nfunc (s *RepositorySuite) TestFetch(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\t_, err := r.CreateRemote(&config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(r.Fetch(&FetchOptions{}), IsNil)\n\n\tremotes, err := r.Remotes()\n\tc.Assert(err, IsNil)\n\tc.Assert(remotes, HasLen, 1)\n\n\t_, err = r.Head()\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n\n\tbranch, err := r.Reference(\"refs/remotes/origin/master\", false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch, NotNil)\n\tc.Assert(branch.Type(), Equals, plumbing.HashReference)\n\tc.Assert(branch.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n}\n\nfunc (s *RepositorySuite) TestFetchContext(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\t_, err := r.CreateRemote(&config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\tc.Assert(err, IsNil)\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\n\tc.Assert(r.FetchContext(ctx, &FetchOptions{}), NotNil)\n}\n\nfunc (s *RepositorySuite) TestCloneWithProgress(c *C) {\n\tfs := memfs.New()\n\n\tbuf := bytes.NewBuffer(nil)\n\t_, err := Clone(memory.NewStorage(), fs, &CloneOptions{\n\t\tURL:      s.GetBasicLocalRepositoryURL(),\n\t\tProgress: buf,\n\t})\n\n\tc.Assert(err, IsNil)\n\tc.Assert(buf.Len(), Not(Equals), 0)\n}\n\nfunc (s *RepositorySuite) TestCloneDeep(c *C) {\n\tfs := memfs.New()\n\tr, _ := Init(memory.NewStorage(), fs)\n\n\thead, err := r.Head()\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n\tc.Assert(head, IsNil)\n\n\terr = r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tremotes, err := r.Remotes()\n\tc.Assert(err, IsNil)\n\tc.Assert(remotes, HasLen, 1)\n\n\thead, err = r.Reference(plumbing.HEAD, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(head, NotNil)\n\tc.Assert(head.Type(), Equals, plumbing.SymbolicReference)\n\tc.Assert(head.Target().String(), Equals, \"refs/heads/master\")\n\n\tbranch, err := r.Reference(head.Target(), false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch, NotNil)\n\tc.Assert(branch.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\tbranch, err = r.Reference(\"refs/remotes/origin/master\", false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch, NotNil)\n\tc.Assert(branch.Type(), Equals, plumbing.HashReference)\n\tc.Assert(branch.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\tfi, err := fs.ReadDir(\"\")\n\tc.Assert(err, IsNil)\n\tc.Assert(fi, HasLen, 8)\n}\n\nfunc (s *RepositorySuite) TestCloneConfig(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\n\thead, err := r.Head()\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n\tc.Assert(head, IsNil)\n\n\terr = r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\n\tc.Assert(cfg.Core.IsBare, Equals, true)\n\tc.Assert(cfg.Remotes, HasLen, 1)\n\tc.Assert(cfg.Remotes[\"origin\"].Name, Equals, \"origin\")\n\tc.Assert(cfg.Remotes[\"origin\"].URLs, HasLen, 1)\n\tc.Assert(cfg.Branches, HasLen, 1)\n\tc.Assert(cfg.Branches[\"master\"].Name, Equals, \"master\")\n}\n\nfunc (s *RepositorySuite) TestCloneSingleBranchAndNonHEAD(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\n\thead, err := r.Head()\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n\tc.Assert(head, IsNil)\n\n\terr = r.clone(context.Background(), &CloneOptions{\n\t\tURL:           s.GetBasicLocalRepositoryURL(),\n\t\tReferenceName: plumbing.ReferenceName(\"refs/heads/branch\"),\n\t\tSingleBranch:  true,\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tremotes, err := r.Remotes()\n\tc.Assert(err, IsNil)\n\tc.Assert(remotes, HasLen, 1)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Branches, HasLen, 1)\n\tc.Assert(cfg.Branches[\"branch\"].Name, Equals, \"branch\")\n\tc.Assert(cfg.Branches[\"branch\"].Remote, Equals, \"origin\")\n\tc.Assert(cfg.Branches[\"branch\"].Merge, Equals, plumbing.ReferenceName(\"refs/heads/branch\"))\n\n\thead, err = r.Reference(plumbing.HEAD, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(head, NotNil)\n\tc.Assert(head.Type(), Equals, plumbing.SymbolicReference)\n\tc.Assert(head.Target().String(), Equals, \"refs/heads/branch\")\n\n\tbranch, err := r.Reference(head.Target(), false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch, NotNil)\n\tc.Assert(branch.Hash().String(), Equals, \"e8d3ffab552895c19b9fcf7aa264d277cde33881\")\n\n\tbranch, err = r.Reference(\"refs/remotes/origin/branch\", false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch, NotNil)\n\tc.Assert(branch.Type(), Equals, plumbing.HashReference)\n\tc.Assert(branch.Hash().String(), Equals, \"e8d3ffab552895c19b9fcf7aa264d277cde33881\")\n}\n\nfunc (s *RepositorySuite) TestCloneSingleBranch(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\n\thead, err := r.Head()\n\tc.Assert(err, Equals, plumbing.ErrReferenceNotFound)\n\tc.Assert(head, IsNil)\n\n\terr = r.clone(context.Background(), &CloneOptions{\n\t\tURL:          s.GetBasicLocalRepositoryURL(),\n\t\tSingleBranch: true,\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tremotes, err := r.Remotes()\n\tc.Assert(err, IsNil)\n\tc.Assert(remotes, HasLen, 1)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Branches, HasLen, 1)\n\tc.Assert(cfg.Branches[\"master\"].Name, Equals, \"master\")\n\tc.Assert(cfg.Branches[\"master\"].Remote, Equals, \"origin\")\n\tc.Assert(cfg.Branches[\"master\"].Merge, Equals, plumbing.ReferenceName(\"refs/heads/master\"))\n\n\thead, err = r.Reference(plumbing.HEAD, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(head, NotNil)\n\tc.Assert(head.Type(), Equals, plumbing.SymbolicReference)\n\tc.Assert(head.Target().String(), Equals, \"refs/heads/master\")\n\n\tbranch, err := r.Reference(head.Target(), false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch, NotNil)\n\tc.Assert(branch.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\tbranch, err = r.Reference(\"refs/remotes/origin/master\", false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch, NotNil)\n\tc.Assert(branch.Type(), Equals, plumbing.HashReference)\n\tc.Assert(branch.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n}\n\nfunc (s *RepositorySuite) TestCloneSingleTag(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL:           url,\n\t\tSingleBranch:  true,\n\t\tReferenceName: plumbing.ReferenceName(\"refs/tags/commit-tag\"),\n\t})\n\tc.Assert(err, IsNil)\n\n\tbranch, err := r.Reference(\"refs/tags/commit-tag\", false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch, NotNil)\n\n\tconf, err := r.Config()\n\tc.Assert(err, IsNil)\n\toriginRemote := conf.Remotes[\"origin\"]\n\tc.Assert(originRemote, NotNil)\n\tc.Assert(originRemote.Fetch, HasLen, 1)\n\tc.Assert(originRemote.Fetch[0].String(), Equals, \"+refs/tags/commit-tag:refs/tags/commit-tag\")\n}\n\nfunc (s *RepositorySuite) TestCloneDetachedHEAD(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL:           s.GetBasicLocalRepositoryURL(),\n\t\tReferenceName: plumbing.ReferenceName(\"refs/tags/v1.0.0\"),\n\t})\n\tc.Assert(err, IsNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Branches, HasLen, 0)\n\n\thead, err := r.Reference(plumbing.HEAD, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(head, NotNil)\n\tc.Assert(head.Type(), Equals, plumbing.HashReference)\n\tc.Assert(head.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\tcount := 0\n\tobjects, err := r.Objects()\n\tc.Assert(err, IsNil)\n\tobjects.ForEach(func(object.Object) error { count++; return nil })\n\tc.Assert(count, Equals, 28)\n}\n\nfunc (s *RepositorySuite) TestCloneDetachedHEADAndSingle(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL:           s.GetBasicLocalRepositoryURL(),\n\t\tReferenceName: plumbing.ReferenceName(\"refs/tags/v1.0.0\"),\n\t\tSingleBranch:  true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Branches, HasLen, 0)\n\n\thead, err := r.Reference(plumbing.HEAD, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(head, NotNil)\n\tc.Assert(head.Type(), Equals, plumbing.HashReference)\n\tc.Assert(head.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\tcount := 0\n\tobjects, err := r.Objects()\n\tc.Assert(err, IsNil)\n\tobjects.ForEach(func(object.Object) error { count++; return nil })\n\tc.Assert(count, Equals, 28)\n}\n\nfunc (s *RepositorySuite) TestCloneDetachedHEADAndShallow(c *C) {\n\tr, _ := Init(memory.NewStorage(), memfs.New())\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL:           s.GetBasicLocalRepositoryURL(),\n\t\tReferenceName: plumbing.ReferenceName(\"refs/tags/v1.0.0\"),\n\t\tDepth:         1,\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Branches, HasLen, 0)\n\n\thead, err := r.Reference(plumbing.HEAD, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(head, NotNil)\n\tc.Assert(head.Type(), Equals, plumbing.HashReference)\n\tc.Assert(head.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\tcount := 0\n\tobjects, err := r.Objects()\n\tc.Assert(err, IsNil)\n\tobjects.ForEach(func(object.Object) error { count++; return nil })\n\tc.Assert(count, Equals, 15)\n}\n\nfunc (s *RepositorySuite) TestCloneDetachedHEADAnnotatedTag(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL:           s.GetLocalRepositoryURL(fixtures.ByTag(\"tags\").One()),\n\t\tReferenceName: plumbing.ReferenceName(\"refs/tags/annotated-tag\"),\n\t})\n\tc.Assert(err, IsNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Branches, HasLen, 0)\n\n\thead, err := r.Reference(plumbing.HEAD, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(head, NotNil)\n\tc.Assert(head.Type(), Equals, plumbing.HashReference)\n\tc.Assert(head.Hash().String(), Equals, \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\")\n\n\tcount := 0\n\tobjects, err := r.Objects()\n\tc.Assert(err, IsNil)\n\tobjects.ForEach(func(object.Object) error { count++; return nil })\n\tc.Assert(count, Equals, 7)\n}\n\nfunc (s *RepositorySuite) TestPush(c *C) {\n\turl := c.MkDir()\n\tserver, err := PlainInit(url, true)\n\tc.Assert(err, IsNil)\n\n\t_, err = s.Repository.CreateRemote(&config.RemoteConfig{\n\t\tName: \"test\",\n\t\tURLs: []string{url},\n\t})\n\tc.Assert(err, IsNil)\n\n\terr = s.Repository.Push(&PushOptions{\n\t\tRemoteName: \"test\",\n\t})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, server, map[string]string{\n\t\t\"refs/heads/master\": \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"refs/heads/branch\": \"e8d3ffab552895c19b9fcf7aa264d277cde33881\",\n\t})\n\n\tAssertReferences(c, s.Repository, map[string]string{\n\t\t\"refs/remotes/test/master\": \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"refs/remotes/test/branch\": \"e8d3ffab552895c19b9fcf7aa264d277cde33881\",\n\t})\n}\n\nfunc (s *RepositorySuite) TestPushContext(c *C) {\n\turl := c.MkDir()\n\t_, err := PlainInit(url, true)\n\tc.Assert(err, IsNil)\n\n\t_, err = s.Repository.CreateRemote(&config.RemoteConfig{\n\t\tName: \"foo\",\n\t\tURLs: []string{url},\n\t})\n\tc.Assert(err, IsNil)\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\n\terr = s.Repository.PushContext(ctx, &PushOptions{\n\t\tRemoteName: \"foo\",\n\t})\n\tc.Assert(err, NotNil)\n}\n\n// installPreReceiveHook installs a pre-receive hook in the .git\n// directory at path which prints message m before exiting\n// successfully.\nfunc installPreReceiveHook(c *C, path, m string) {\n\thooks := filepath.Join(path, \"hooks\")\n\terr := os.MkdirAll(hooks, 0777)\n\tc.Assert(err, IsNil)\n\n\terr = ioutil.WriteFile(filepath.Join(hooks, \"pre-receive\"), preReceiveHook(m), 0777)\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *RepositorySuite) TestPushWithProgress(c *C) {\n\turl := c.MkDir()\n\tserver, err := PlainInit(url, true)\n\tc.Assert(err, IsNil)\n\n\tm := \"Receiving...\"\n\tinstallPreReceiveHook(c, url, m)\n\n\t_, err = s.Repository.CreateRemote(&config.RemoteConfig{\n\t\tName: \"bar\",\n\t\tURLs: []string{url},\n\t})\n\tc.Assert(err, IsNil)\n\n\tvar p bytes.Buffer\n\terr = s.Repository.Push(&PushOptions{\n\t\tRemoteName: \"bar\",\n\t\tProgress:   &p,\n\t})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, server, map[string]string{\n\t\t\"refs/heads/master\": \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"refs/heads/branch\": \"e8d3ffab552895c19b9fcf7aa264d277cde33881\",\n\t})\n\n\tc.Assert((&p).Bytes(), DeepEquals, []byte(m))\n}\n\nfunc (s *RepositorySuite) TestPushDepth(c *C) {\n\turl := c.MkDir()\n\tserver, err := PlainClone(url, true, &CloneOptions{\n\t\tURL: fixtures.Basic().One().DotGit().Root(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tr, err := Clone(memory.NewStorage(), memfs.New(), &CloneOptions{\n\t\tURL:   url,\n\t\tDepth: 1,\n\t})\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(r.wt, \"foo\", nil, 0755)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\t_, err = w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Commit(\"foo\", &CommitOptions{\n\t\tAuthor:    defaultSignature(),\n\t\tCommitter: defaultSignature(),\n\t})\n\tc.Assert(err, IsNil)\n\n\terr = r.Push(&PushOptions{})\n\tc.Assert(err, IsNil)\n\n\tAssertReferences(c, server, map[string]string{\n\t\t\"refs/heads/master\": hash.String(),\n\t})\n\n\tAssertReferences(c, r, map[string]string{\n\t\t\"refs/remotes/origin/master\": hash.String(),\n\t})\n}\n\nfunc (s *RepositorySuite) TestPushNonExistentRemote(c *C) {\n\tsrcFs := fixtures.Basic().One().DotGit()\n\tsto := filesystem.NewStorage(srcFs, cache.NewObjectLRUDefault())\n\n\tr, err := Open(sto, srcFs)\n\tc.Assert(err, IsNil)\n\n\terr = r.Push(&PushOptions{RemoteName: \"myremote\"})\n\tc.Assert(err, ErrorMatches, \".*remote not found.*\")\n}\n\nfunc (s *RepositorySuite) TestLog(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tcIter, err := r.Log(&LogOptions{\n\t\tFrom: plumbing.NewHash(\"b8e471f58bcbca63b07bda20e428190409c2db47\"),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"b8e471f58bcbca63b07bda20e428190409c2db47\"),\n\t\tplumbing.NewHash(\"b029517f6300c2da0f4b651b8642506cd6aaf45d\"),\n\t}\n\n\tfor _, o := range commitOrder {\n\t\tcommit, err := cIter.Next()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(commit.Hash, Equals, o)\n\t}\n\t_, err = cIter.Next()\n\tc.Assert(err, Equals, io.EOF)\n}\n\nfunc (s *RepositorySuite) TestLogAll(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(err, IsNil)\n\n\trIter, err := r.Storer.IterReferences()\n\tc.Assert(err, IsNil)\n\n\trefCount := 0\n\terr = rIter.ForEach(func(ref *plumbing.Reference) error {\n\t\trefCount++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(refCount, Equals, 5)\n\n\tcIter, err := r.Log(&LogOptions{\n\t\tAll: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t\tplumbing.NewHash(\"e8d3ffab552895c19b9fcf7aa264d277cde33881\"),\n\t\tplumbing.NewHash(\"918c48b83bd081e863dbe1b80f8998f058cd8294\"),\n\t\tplumbing.NewHash(\"af2d6a6954d532f8ffb47615169c8fdf9d383a1a\"),\n\t\tplumbing.NewHash(\"1669dce138d9b841a518c64b10914d88f5e488ea\"),\n\t\tplumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t\tplumbing.NewHash(\"b029517f6300c2da0f4b651b8642506cd6aaf45d\"),\n\t\tplumbing.NewHash(\"a5b8b09e2f8fcb0bb99d3ccb0958157b40890d69\"),\n\t\tplumbing.NewHash(\"b8e471f58bcbca63b07bda20e428190409c2db47\"),\n\t}\n\n\tfor _, o := range commitOrder {\n\t\tcommit, err := cIter.Next()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(commit.Hash, Equals, o)\n\t}\n\t_, err = cIter.Next()\n\tc.Assert(err, Equals, io.EOF)\n\tcIter.Close()\n}\n\nfunc (s *RepositorySuite) TestLogAllMissingReferences(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(err, IsNil)\n\terr = r.Storer.RemoveReference(plumbing.HEAD)\n\tc.Assert(err, IsNil)\n\n\trIter, err := r.Storer.IterReferences()\n\tc.Assert(err, IsNil)\n\n\trefCount := 0\n\terr = rIter.ForEach(func(ref *plumbing.Reference) error {\n\t\trefCount++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(refCount, Equals, 4)\n\n\terr = r.Storer.SetReference(plumbing.NewHashReference(plumbing.ReferenceName(\"DUMMY\"), plumbing.NewHash(\"DUMMY\")))\n\tc.Assert(err, IsNil)\n\n\trIter, err = r.Storer.IterReferences()\n\tc.Assert(err, IsNil)\n\n\trefCount = 0\n\terr = rIter.ForEach(func(ref *plumbing.Reference) error {\n\t\trefCount++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(refCount, Equals, 5)\n\n\tcIter, err := r.Log(&LogOptions{\n\t\tAll: true,\n\t})\n\tc.Assert(cIter, NotNil)\n\tc.Assert(err, IsNil)\n\n\tcCount := 0\n\tcIter.ForEach(func(c *object.Commit) error {\n\t\tcCount++\n\t\treturn nil\n\t})\n\tc.Assert(cCount, Equals, 9)\n\n\t_, err = cIter.Next()\n\tc.Assert(err, Equals, io.EOF)\n\tcIter.Close()\n}\n\nfunc (s *RepositorySuite) TestLogAllOrderByTime(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tcIter, err := r.Log(&LogOptions{\n\t\tOrder: LogOrderCommitterTime,\n\t\tAll:   true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t\tplumbing.NewHash(\"e8d3ffab552895c19b9fcf7aa264d277cde33881\"),\n\t\tplumbing.NewHash(\"918c48b83bd081e863dbe1b80f8998f058cd8294\"),\n\t\tplumbing.NewHash(\"af2d6a6954d532f8ffb47615169c8fdf9d383a1a\"),\n\t\tplumbing.NewHash(\"1669dce138d9b841a518c64b10914d88f5e488ea\"),\n\t\tplumbing.NewHash(\"a5b8b09e2f8fcb0bb99d3ccb0958157b40890d69\"),\n\t\tplumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t\tplumbing.NewHash(\"b8e471f58bcbca63b07bda20e428190409c2db47\"),\n\t\tplumbing.NewHash(\"b029517f6300c2da0f4b651b8642506cd6aaf45d\"),\n\t}\n\n\tfor _, o := range commitOrder {\n\t\tcommit, err := cIter.Next()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(commit.Hash, Equals, o)\n\t}\n\t_, err = cIter.Next()\n\tc.Assert(err, Equals, io.EOF)\n\tcIter.Close()\n}\n\nfunc (s *RepositorySuite) TestLogHead(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tcIter, err := r.Log(&LogOptions{})\n\n\tc.Assert(err, IsNil)\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t\tplumbing.NewHash(\"918c48b83bd081e863dbe1b80f8998f058cd8294\"),\n\t\tplumbing.NewHash(\"af2d6a6954d532f8ffb47615169c8fdf9d383a1a\"),\n\t\tplumbing.NewHash(\"1669dce138d9b841a518c64b10914d88f5e488ea\"),\n\t\tplumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t\tplumbing.NewHash(\"b029517f6300c2da0f4b651b8642506cd6aaf45d\"),\n\t\tplumbing.NewHash(\"a5b8b09e2f8fcb0bb99d3ccb0958157b40890d69\"),\n\t\tplumbing.NewHash(\"b8e471f58bcbca63b07bda20e428190409c2db47\"),\n\t}\n\n\tfor _, o := range commitOrder {\n\t\tcommit, err := cIter.Next()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(commit.Hash, Equals, o)\n\t}\n\t_, err = cIter.Next()\n\tc.Assert(err, Equals, io.EOF)\n}\n\nfunc (s *RepositorySuite) TestLogError(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\t_, err = r.Log(&LogOptions{\n\t\tFrom: plumbing.NewHash(\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"),\n\t})\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *RepositorySuite) TestLogFileNext(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tfileName := \"vendor/foo.go\"\n\tcIter, err := r.Log(&LogOptions{FileName: &fileName})\n\n\tc.Assert(err, IsNil)\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t}\n\n\tfor _, o := range commitOrder {\n\t\tcommit, err := cIter.Next()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(commit.Hash, Equals, o)\n\t}\n\t_, err = cIter.Next()\n\tc.Assert(err, Equals, io.EOF)\n}\n\nfunc (s *RepositorySuite) TestLogFileForEach(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tfileName := \"php/crappy.php\"\n\tcIter, err := r.Log(&LogOptions{FileName: &fileName})\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"918c48b83bd081e863dbe1b80f8998f058cd8294\"),\n\t}\n\n\texpectedIndex := 0\n\terr = cIter.ForEach(func(commit *object.Commit) error {\n\t\texpectedCommitHash := commitOrder[expectedIndex]\n\t\tc.Assert(commit.Hash.String(), Equals, expectedCommitHash.String())\n\t\texpectedIndex++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(expectedIndex, Equals, 1)\n}\n\nfunc (s *RepositorySuite) TestLogNonHeadFile(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tfileName := \"README\"\n\tcIter, err := r.Log(&LogOptions{FileName: &fileName})\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\t_, err = cIter.Next()\n\tc.Assert(err, Equals, io.EOF)\n}\n\nfunc (s *RepositorySuite) TestLogAllFileForEach(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tfileName := \"README\"\n\tcIter, err := r.Log(&LogOptions{FileName: &fileName, All: true})\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"e8d3ffab552895c19b9fcf7aa264d277cde33881\"),\n\t}\n\n\texpectedIndex := 0\n\terr = cIter.ForEach(func(commit *object.Commit) error {\n\t\texpectedCommitHash := commitOrder[expectedIndex]\n\t\tc.Assert(commit.Hash.String(), Equals, expectedCommitHash.String())\n\t\texpectedIndex++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(expectedIndex, Equals, 1)\n}\n\nfunc (s *RepositorySuite) TestLogInvalidFile(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(err, IsNil)\n\n\t// Throwing in a file that does not exist\n\tfileName := \"vendor/foo12.go\"\n\tcIter, err := r.Log(&LogOptions{FileName: &fileName})\n\t// Not raising an error since `git log -- vendor/foo12.go` responds silently\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\t_, err = cIter.Next()\n\tc.Assert(err, Equals, io.EOF)\n}\n\nfunc (s *RepositorySuite) TestLogFileInitialCommit(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tfileName := \"LICENSE\"\n\tcIter, err := r.Log(&LogOptions{\n\t\tOrder:    LogOrderCommitterTime,\n\t\tFileName: &fileName,\n\t})\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"b029517f6300c2da0f4b651b8642506cd6aaf45d\"),\n\t}\n\n\texpectedIndex := 0\n\terr = cIter.ForEach(func(commit *object.Commit) error {\n\t\texpectedCommitHash := commitOrder[expectedIndex]\n\t\tc.Assert(commit.Hash.String(), Equals, expectedCommitHash.String())\n\t\texpectedIndex++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(expectedIndex, Equals, 1)\n}\n\nfunc (s *RepositorySuite) TestLogFileWithOtherParamsFail(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tfileName := \"vendor/foo.go\"\n\tcIter, err := r.Log(&LogOptions{\n\t\tOrder:    LogOrderCommitterTime,\n\t\tFileName: &fileName,\n\t\tFrom:     plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t})\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\t_, iterErr := cIter.Next()\n\tc.Assert(iterErr, Equals, io.EOF)\n}\n\nfunc (s *RepositorySuite) TestLogFileWithOtherParamsPass(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tfileName := \"LICENSE\"\n\tcIter, err := r.Log(&LogOptions{\n\t\tOrder:    LogOrderCommitterTime,\n\t\tFileName: &fileName,\n\t\tFrom:     plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t})\n\tc.Assert(err, IsNil)\n\tcommitVal, iterErr := cIter.Next()\n\tc.Assert(iterErr, Equals, nil)\n\tc.Assert(commitVal.Hash.String(), Equals, \"b029517f6300c2da0f4b651b8642506cd6aaf45d\")\n\n\t_, iterErr = cIter.Next()\n\tc.Assert(iterErr, Equals, io.EOF)\n}\n\ntype mockErrCommitIter struct{}\n\nfunc (m *mockErrCommitIter) Next() (*object.Commit, error) {\n\treturn nil, errors.New(\"mock next error\")\n}\nfunc (m *mockErrCommitIter) ForEach(func(*object.Commit) error) error {\n\treturn errors.New(\"mock foreach error\")\n}\n\nfunc (m *mockErrCommitIter) Close() {}\n\nfunc (s *RepositorySuite) TestLogFileWithError(c *C) {\n\tfileName := \"README\"\n\tcIter := object.NewCommitFileIterFromIter(fileName, &mockErrCommitIter{}, false)\n\tdefer cIter.Close()\n\n\terr := cIter.ForEach(func(commit *object.Commit) error {\n\t\treturn nil\n\t})\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *RepositorySuite) TestLogLimitNext(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tsince := time.Date(2015, 4, 1, 0, 0, 0, 0, time.UTC)\n\tcIter, err := r.Log(&LogOptions{Since: &since})\n\n\tc.Assert(err, IsNil)\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"),\n\t}\n\n\tfor _, o := range commitOrder {\n\t\tcommit, err := cIter.Next()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(commit.Hash, Equals, o)\n\t}\n\t_, err = cIter.Next()\n\tc.Assert(err, Equals, io.EOF)\n}\n\nfunc (s *RepositorySuite) TestLogLimitForEach(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tsince := time.Date(2015, 3, 31, 11, 54, 0, 0, time.UTC)\n\tuntil := time.Date(2015, 4, 1, 0, 0, 0, 0, time.UTC)\n\tcIter, err := r.Log(&LogOptions{Since: &since, Until: &until})\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"918c48b83bd081e863dbe1b80f8998f058cd8294\"),\n\t}\n\n\texpectedIndex := 0\n\terr = cIter.ForEach(func(commit *object.Commit) error {\n\t\texpectedCommitHash := commitOrder[expectedIndex]\n\t\tc.Assert(commit.Hash.String(), Equals, expectedCommitHash.String())\n\t\texpectedIndex++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(expectedIndex, Equals, 1)\n}\n\nfunc (s *RepositorySuite) TestLogAllLimitForEach(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tsince := time.Date(2015, 3, 31, 11, 54, 0, 0, time.UTC)\n\tuntil := time.Date(2015, 4, 1, 0, 0, 0, 0, time.UTC)\n\tcIter, err := r.Log(&LogOptions{Since: &since, Until: &until, All: true})\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\tcommitOrder := []plumbing.Hash{\n\t\tplumbing.NewHash(\"e8d3ffab552895c19b9fcf7aa264d277cde33881\"),\n\t\tplumbing.NewHash(\"918c48b83bd081e863dbe1b80f8998f058cd8294\"),\n\t}\n\n\texpectedIndex := 0\n\terr = cIter.ForEach(func(commit *object.Commit) error {\n\t\texpectedCommitHash := commitOrder[expectedIndex]\n\t\tc.Assert(commit.Hash.String(), Equals, expectedCommitHash.String())\n\t\texpectedIndex++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(expectedIndex, Equals, 2)\n}\n\nfunc (s *RepositorySuite) TestLogLimitWithOtherParamsFail(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tsince := time.Date(2015, 3, 31, 11, 54, 0, 0, time.UTC)\n\tcIter, err := r.Log(&LogOptions{\n\t\tOrder: LogOrderCommitterTime,\n\t\tSince: &since,\n\t\tFrom:  plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t})\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\t_, iterErr := cIter.Next()\n\tc.Assert(iterErr, Equals, io.EOF)\n}\n\nfunc (s *RepositorySuite) TestLogLimitWithOtherParamsPass(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tuntil := time.Date(2015, 3, 31, 11, 43, 0, 0, time.UTC)\n\tcIter, err := r.Log(&LogOptions{\n\t\tOrder: LogOrderCommitterTime,\n\t\tUntil: &until,\n\t\tFrom:  plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t})\n\tc.Assert(err, IsNil)\n\tdefer cIter.Close()\n\n\tcommitVal, iterErr := cIter.Next()\n\tc.Assert(iterErr, Equals, nil)\n\tc.Assert(commitVal.Hash.String(), Equals, \"b029517f6300c2da0f4b651b8642506cd6aaf45d\")\n\n\t_, iterErr = cIter.Next()\n\tc.Assert(iterErr, Equals, io.EOF)\n}\n\nfunc (s *RepositorySuite) TestCommit(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\thash := plumbing.NewHash(\"b8e471f58bcbca63b07bda20e428190409c2db47\")\n\tcommit, err := r.CommitObject(hash)\n\tc.Assert(err, IsNil)\n\n\tc.Assert(commit.Hash.IsZero(), Equals, false)\n\tc.Assert(commit.Hash, Equals, commit.ID())\n\tc.Assert(commit.Hash, Equals, hash)\n\tc.Assert(commit.Type(), Equals, plumbing.CommitObject)\n\n\ttree, err := commit.Tree()\n\tc.Assert(err, IsNil)\n\tc.Assert(tree.Hash.IsZero(), Equals, false)\n\n\tc.Assert(commit.Author.Email, Equals, \"daniel@lordran.local\")\n}\n\nfunc (s *RepositorySuite) TestCommits(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: s.GetBasicLocalRepositoryURL()})\n\tc.Assert(err, IsNil)\n\n\tcount := 0\n\tcommits, err := r.CommitObjects()\n\tc.Assert(err, IsNil)\n\tfor {\n\t\tcommit, err := commits.Next()\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n\n\t\tcount++\n\t\tc.Assert(commit.Hash.IsZero(), Equals, false)\n\t\tc.Assert(commit.Hash, Equals, commit.ID())\n\t\tc.Assert(commit.Type(), Equals, plumbing.CommitObject)\n\t}\n\n\tc.Assert(count, Equals, 9)\n}\n\nfunc (s *RepositorySuite) TestBlob(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tblob, err := r.BlobObject(plumbing.NewHash(\"b8e471f58bcbca63b07bda20e428190409c2db47\"))\n\tc.Assert(err, NotNil)\n\tc.Assert(blob, IsNil)\n\n\tblobHash := plumbing.NewHash(\"9a48f23120e880dfbe41f7c9b7b708e9ee62a492\")\n\tblob, err = r.BlobObject(blobHash)\n\tc.Assert(err, IsNil)\n\n\tc.Assert(blob.Hash.IsZero(), Equals, false)\n\tc.Assert(blob.Hash, Equals, blob.ID())\n\tc.Assert(blob.Hash, Equals, blobHash)\n\tc.Assert(blob.Type(), Equals, plumbing.BlobObject)\n}\n\nfunc (s *RepositorySuite) TestBlobs(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: s.GetBasicLocalRepositoryURL()})\n\tc.Assert(err, IsNil)\n\n\tcount := 0\n\tblobs, err := r.BlobObjects()\n\tc.Assert(err, IsNil)\n\tfor {\n\t\tblob, err := blobs.Next()\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n\n\t\tcount++\n\t\tc.Assert(blob.Hash.IsZero(), Equals, false)\n\t\tc.Assert(blob.Hash, Equals, blob.ID())\n\t\tc.Assert(blob.Type(), Equals, plumbing.BlobObject)\n\t}\n\n\tc.Assert(count, Equals, 10)\n}\n\nfunc (s *RepositorySuite) TestTagObject(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\thash := plumbing.NewHash(\"ad7897c0fb8e7d9a9ba41fa66072cf06095a6cfc\")\n\ttag, err := r.TagObject(hash)\n\tc.Assert(err, IsNil)\n\n\tc.Assert(tag.Hash.IsZero(), Equals, false)\n\tc.Assert(tag.Hash, Equals, hash)\n\tc.Assert(tag.Type(), Equals, plumbing.TagObject)\n}\n\nfunc (s *RepositorySuite) TestTags(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\tcount := 0\n\ttags, err := r.Tags()\n\tc.Assert(err, IsNil)\n\n\ttags.ForEach(func(tag *plumbing.Reference) error {\n\t\tcount++\n\t\tc.Assert(tag.Hash().IsZero(), Equals, false)\n\t\tc.Assert(tag.Name().IsTag(), Equals, true)\n\t\treturn nil\n\t})\n\n\tc.Assert(count, Equals, 5)\n}\n\nfunc (s *RepositorySuite) TestCreateTagLightweight(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\texpected, err := r.Head()\n\tc.Assert(err, IsNil)\n\n\tref, err := r.CreateTag(\"foobar\", expected.Hash(), nil)\n\tc.Assert(err, IsNil)\n\tc.Assert(ref, NotNil)\n\n\tactual, err := r.Tag(\"foobar\")\n\tc.Assert(err, IsNil)\n\n\tc.Assert(expected.Hash(), Equals, actual.Hash())\n}\n\nfunc (s *RepositorySuite) TestCreateTagLightweightExists(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\texpected, err := r.Head()\n\tc.Assert(err, IsNil)\n\n\tref, err := r.CreateTag(\"lightweight-tag\", expected.Hash(), nil)\n\tc.Assert(ref, IsNil)\n\tc.Assert(err, Equals, ErrTagExists)\n}\n\nfunc (s *RepositorySuite) TestCreateTagAnnotated(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\th, err := r.Head()\n\tc.Assert(err, IsNil)\n\n\texpectedHash := h.Hash()\n\n\tref, err := r.CreateTag(\"foobar\", expectedHash, &CreateTagOptions{\n\t\tTagger:  defaultSignature(),\n\t\tMessage: \"foo bar baz qux\",\n\t})\n\tc.Assert(err, IsNil)\n\n\ttag, err := r.Tag(\"foobar\")\n\tc.Assert(err, IsNil)\n\n\tobj, err := r.TagObject(tag.Hash())\n\tc.Assert(err, IsNil)\n\n\tc.Assert(ref, DeepEquals, tag)\n\tc.Assert(obj.Hash, Equals, ref.Hash())\n\tc.Assert(obj.Type(), Equals, plumbing.TagObject)\n\tc.Assert(obj.Target, Equals, expectedHash)\n}\n\nfunc (s *RepositorySuite) TestCreateTagAnnotatedBadOpts(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\th, err := r.Head()\n\tc.Assert(err, IsNil)\n\n\texpectedHash := h.Hash()\n\n\tref, err := r.CreateTag(\"foobar\", expectedHash, &CreateTagOptions{\n\t\tMessage: \"foo bar baz qux\",\n\t})\n\tc.Assert(ref, IsNil)\n\tc.Assert(err, Equals, ErrMissingTagger)\n\n\tref, err = r.CreateTag(\"foobar\", expectedHash, &CreateTagOptions{\n\t\tTagger: defaultSignature(),\n\t})\n\tc.Assert(ref, IsNil)\n\tc.Assert(err, Equals, ErrMissingMessage)\n}\n\nfunc (s *RepositorySuite) TestCreateTagAnnotatedBadHash(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\tref, err := r.CreateTag(\"foobar\", plumbing.ZeroHash, &CreateTagOptions{\n\t\tTagger:  defaultSignature(),\n\t\tMessage: \"foo bar baz qux\",\n\t})\n\tc.Assert(ref, IsNil)\n\tc.Assert(err, Equals, plumbing.ErrObjectNotFound)\n}\n\nfunc (s *RepositorySuite) TestCreateTagSigned(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\th, err := r.Head()\n\tc.Assert(err, IsNil)\n\n\tkey := commitSignKey(c, true)\n\t_, err = r.CreateTag(\"foobar\", h.Hash(), &CreateTagOptions{\n\t\tTagger:  defaultSignature(),\n\t\tMessage: \"foo bar baz qux\",\n\t\tSignKey: key,\n\t})\n\tc.Assert(err, IsNil)\n\n\ttag, err := r.Tag(\"foobar\")\n\tc.Assert(err, IsNil)\n\n\tobj, err := r.TagObject(tag.Hash())\n\tc.Assert(err, IsNil)\n\n\t// Verify the tag.\n\tpks := new(bytes.Buffer)\n\tpkw, err := armor.Encode(pks, openpgp.PublicKeyType, nil)\n\tc.Assert(err, IsNil)\n\n\terr = key.Serialize(pkw)\n\tc.Assert(err, IsNil)\n\terr = pkw.Close()\n\tc.Assert(err, IsNil)\n\n\tactual, err := obj.Verify(pks.String())\n\tc.Assert(err, IsNil)\n\tc.Assert(actual.PrimaryKey, DeepEquals, key.PrimaryKey)\n}\n\nfunc (s *RepositorySuite) TestCreateTagSignedBadKey(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\th, err := r.Head()\n\tc.Assert(err, IsNil)\n\n\tkey := commitSignKey(c, false)\n\t_, err = r.CreateTag(\"foobar\", h.Hash(), &CreateTagOptions{\n\t\tTagger:  defaultSignature(),\n\t\tMessage: \"foo bar baz qux\",\n\t\tSignKey: key,\n\t})\n\tc.Assert(err, Equals, openpgperr.InvalidArgumentError(\"signing key is encrypted\"))\n}\n\nfunc (s *RepositorySuite) TestCreateTagCanonicalize(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\th, err := r.Head()\n\tc.Assert(err, IsNil)\n\n\tkey := commitSignKey(c, true)\n\t_, err = r.CreateTag(\"foobar\", h.Hash(), &CreateTagOptions{\n\t\tTagger:  defaultSignature(),\n\t\tMessage: \"\\n\\nfoo bar baz qux\\n\\nsome message here\",\n\t\tSignKey: key,\n\t})\n\tc.Assert(err, IsNil)\n\n\ttag, err := r.Tag(\"foobar\")\n\tc.Assert(err, IsNil)\n\n\tobj, err := r.TagObject(tag.Hash())\n\tc.Assert(err, IsNil)\n\n\t// Assert the new canonicalized message.\n\tc.Assert(obj.Message, Equals, \"foo bar baz qux\\n\\nsome message here\\n\")\n\n\t// Verify the tag.\n\tpks := new(bytes.Buffer)\n\tpkw, err := armor.Encode(pks, openpgp.PublicKeyType, nil)\n\tc.Assert(err, IsNil)\n\n\terr = key.Serialize(pkw)\n\tc.Assert(err, IsNil)\n\terr = pkw.Close()\n\tc.Assert(err, IsNil)\n\n\tactual, err := obj.Verify(pks.String())\n\tc.Assert(err, IsNil)\n\tc.Assert(actual.PrimaryKey, DeepEquals, key.PrimaryKey)\n}\n\nfunc (s *RepositorySuite) TestTagLightweight(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\texpected := plumbing.NewHash(\"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\")\n\n\ttag, err := r.Tag(\"lightweight-tag\")\n\tc.Assert(err, IsNil)\n\n\tactual := tag.Hash()\n\tc.Assert(expected, Equals, actual)\n}\n\nfunc (s *RepositorySuite) TestTagLightweightMissingTag(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\ttag, err := r.Tag(\"lightweight-tag-tag\")\n\tc.Assert(tag, IsNil)\n\tc.Assert(err, Equals, ErrTagNotFound)\n}\n\nfunc (s *RepositorySuite) TestDeleteTag(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\terr = r.DeleteTag(\"lightweight-tag\")\n\tc.Assert(err, IsNil)\n\n\t_, err = r.Tag(\"lightweight-tag\")\n\tc.Assert(err, Equals, ErrTagNotFound)\n}\n\nfunc (s *RepositorySuite) TestDeleteTagMissingTag(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\terr = r.DeleteTag(\"lightweight-tag-tag\")\n\tc.Assert(err, Equals, ErrTagNotFound)\n}\n\nfunc (s *RepositorySuite) TestDeleteTagAnnotated(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tdir, err := ioutil.TempDir(\"\", \"go-git-test-deletetag-annotated\")\n\tc.Assert(err, IsNil)\n\n\tdefer os.RemoveAll(dir) // clean up\n\n\tfss := filesystem.NewStorage(osfs.New(dir), cache.NewObjectLRUDefault())\n\n\tr, _ := Init(fss, nil)\n\terr = r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\tref, err := r.Tag(\"annotated-tag\")\n\tc.Assert(ref, NotNil)\n\tc.Assert(err, IsNil)\n\n\tobj, err := r.TagObject(ref.Hash())\n\tc.Assert(obj, NotNil)\n\tc.Assert(err, IsNil)\n\n\terr = r.DeleteTag(\"annotated-tag\")\n\tc.Assert(err, IsNil)\n\n\t_, err = r.Tag(\"annotated-tag\")\n\tc.Assert(err, Equals, ErrTagNotFound)\n\n\t// Run a prune (and repack, to ensure that we are GCing everything regardless\n\t// of the fixture in use) and try to get the tag object again.\n\t//\n\t// The repo needs to be re-opened after the repack.\n\terr = r.Prune(PruneOptions{Handler: r.DeleteObject})\n\tc.Assert(err, IsNil)\n\n\terr = r.RepackObjects(&RepackConfig{})\n\tc.Assert(err, IsNil)\n\n\tr, err = PlainOpen(dir)\n\tc.Assert(r, NotNil)\n\tc.Assert(err, IsNil)\n\n\t// Now check to see if the GC was effective in removing the tag object.\n\tobj, err = r.TagObject(ref.Hash())\n\tc.Assert(obj, IsNil)\n\tc.Assert(err, Equals, plumbing.ErrObjectNotFound)\n}\n\nfunc (s *RepositorySuite) TestDeleteTagAnnotatedUnpacked(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tdir, err := ioutil.TempDir(\"\", \"go-git-test-deletetag-annotated-unpacked\")\n\tc.Assert(err, IsNil)\n\n\tdefer os.RemoveAll(dir) // clean up\n\n\tfss := filesystem.NewStorage(osfs.New(dir), cache.NewObjectLRUDefault())\n\n\tr, _ := Init(fss, nil)\n\terr = r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\t// Create a tag for the deletion test. This ensures that the ultimate loose\n\t// object will be unpacked (as we aren't doing anything that should pack it),\n\t// so that we can effectively test that a prune deletes it, without having to\n\t// resort to a repack.\n\th, err := r.Head()\n\tc.Assert(err, IsNil)\n\n\texpectedHash := h.Hash()\n\n\tref, err := r.CreateTag(\"foobar\", expectedHash, &CreateTagOptions{\n\t\tTagger:  defaultSignature(),\n\t\tMessage: \"foo bar baz qux\",\n\t})\n\tc.Assert(err, IsNil)\n\n\ttag, err := r.Tag(\"foobar\")\n\tc.Assert(err, IsNil)\n\n\tobj, err := r.TagObject(tag.Hash())\n\tc.Assert(obj, NotNil)\n\tc.Assert(err, IsNil)\n\n\terr = r.DeleteTag(\"foobar\")\n\tc.Assert(err, IsNil)\n\n\t_, err = r.Tag(\"foobar\")\n\tc.Assert(err, Equals, ErrTagNotFound)\n\n\t// As mentioned, only run a prune. We are not testing for packed objects\n\t// here.\n\terr = r.Prune(PruneOptions{Handler: r.DeleteObject})\n\tc.Assert(err, IsNil)\n\n\t// Now check to see if the GC was effective in removing the tag object.\n\tobj, err = r.TagObject(ref.Hash())\n\tc.Assert(obj, IsNil)\n\tc.Assert(err, Equals, plumbing.ErrObjectNotFound)\n}\n\nfunc (s *RepositorySuite) TestBranches(c *C) {\n\tf := fixtures.ByURL(\"https://github.com/git-fixtures/root-references.git\").One()\n\tsto := filesystem.NewStorage(f.DotGit(), cache.NewObjectLRUDefault())\n\tr, err := Open(sto, f.DotGit())\n\tc.Assert(err, IsNil)\n\n\tcount := 0\n\tbranches, err := r.Branches()\n\tc.Assert(err, IsNil)\n\n\tbranches.ForEach(func(branch *plumbing.Reference) error {\n\t\tcount++\n\t\tc.Assert(branch.Hash().IsZero(), Equals, false)\n\t\tc.Assert(branch.Name().IsBranch(), Equals, true)\n\t\treturn nil\n\t})\n\n\tc.Assert(count, Equals, 8)\n}\n\nfunc (s *RepositorySuite) TestNotes(c *C) {\n\t// TODO add fixture with Notes\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\tcount := 0\n\tnotes, err := r.Notes()\n\tc.Assert(err, IsNil)\n\n\tnotes.ForEach(func(note *plumbing.Reference) error {\n\t\tcount++\n\t\tc.Assert(note.Hash().IsZero(), Equals, false)\n\t\tc.Assert(note.Name().IsNote(), Equals, true)\n\t\treturn nil\n\t})\n\n\tc.Assert(count, Equals, 0)\n}\n\nfunc (s *RepositorySuite) TestTree(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL: s.GetBasicLocalRepositoryURL(),\n\t})\n\tc.Assert(err, IsNil)\n\n\tinvalidHash := plumbing.NewHash(\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\")\n\ttree, err := r.TreeObject(invalidHash)\n\tc.Assert(tree, IsNil)\n\tc.Assert(err, NotNil)\n\n\thash := plumbing.NewHash(\"dbd3641b371024f44d0e469a9c8f5457b0660de1\")\n\ttree, err = r.TreeObject(hash)\n\tc.Assert(err, IsNil)\n\n\tc.Assert(tree.Hash.IsZero(), Equals, false)\n\tc.Assert(tree.Hash, Equals, tree.ID())\n\tc.Assert(tree.Hash, Equals, hash)\n\tc.Assert(tree.Type(), Equals, plumbing.TreeObject)\n\tc.Assert(len(tree.Entries), Not(Equals), 0)\n}\n\nfunc (s *RepositorySuite) TestTrees(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: s.GetBasicLocalRepositoryURL()})\n\tc.Assert(err, IsNil)\n\n\tcount := 0\n\ttrees, err := r.TreeObjects()\n\tc.Assert(err, IsNil)\n\tfor {\n\t\ttree, err := trees.Next()\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n\n\t\tcount++\n\t\tc.Assert(tree.Hash.IsZero(), Equals, false)\n\t\tc.Assert(tree.Hash, Equals, tree.ID())\n\t\tc.Assert(tree.Type(), Equals, plumbing.TreeObject)\n\t\tc.Assert(len(tree.Entries), Not(Equals), 0)\n\t}\n\n\tc.Assert(count, Equals, 12)\n}\n\nfunc (s *RepositorySuite) TestTagObjects(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\tcount := 0\n\ttags, err := r.TagObjects()\n\tc.Assert(err, IsNil)\n\n\ttags.ForEach(func(tag *object.Tag) error {\n\t\tcount++\n\n\t\tc.Assert(tag.Hash.IsZero(), Equals, false)\n\t\tc.Assert(tag.Type(), Equals, plumbing.TagObject)\n\t\treturn nil\n\t})\n\n\trefs, _ := r.References()\n\trefs.ForEach(func(ref *plumbing.Reference) error {\n\t\treturn nil\n\t})\n\n\tc.Assert(count, Equals, 4)\n}\n\nfunc (s *RepositorySuite) TestCommitIterClosePanic(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: s.GetBasicLocalRepositoryURL()})\n\tc.Assert(err, IsNil)\n\n\tcommits, err := r.CommitObjects()\n\tc.Assert(err, IsNil)\n\tcommits.Close()\n}\n\nfunc (s *RepositorySuite) TestRef(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: s.GetBasicLocalRepositoryURL()})\n\tc.Assert(err, IsNil)\n\n\tref, err := r.Reference(plumbing.HEAD, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(ref.Name(), Equals, plumbing.HEAD)\n\n\tref, err = r.Reference(plumbing.HEAD, true)\n\tc.Assert(err, IsNil)\n\tc.Assert(ref.Name(), Equals, plumbing.ReferenceName(\"refs/heads/master\"))\n}\n\nfunc (s *RepositorySuite) TestRefs(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: s.GetBasicLocalRepositoryURL()})\n\tc.Assert(err, IsNil)\n\n\tc.Assert(err, IsNil)\n\n\titer, err := r.References()\n\tc.Assert(err, IsNil)\n\tc.Assert(iter, NotNil)\n}\n\nfunc (s *RepositorySuite) TestObject(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: s.GetBasicLocalRepositoryURL()})\n\tc.Assert(err, IsNil)\n\n\thash := plumbing.NewHash(\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\to, err := r.Object(plumbing.CommitObject, hash)\n\tc.Assert(err, IsNil)\n\n\tc.Assert(o.ID().IsZero(), Equals, false)\n\tc.Assert(o.Type(), Equals, plumbing.CommitObject)\n}\n\nfunc (s *RepositorySuite) TestObjects(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: s.GetBasicLocalRepositoryURL()})\n\tc.Assert(err, IsNil)\n\n\tcount := 0\n\tobjects, err := r.Objects()\n\tc.Assert(err, IsNil)\n\tfor {\n\t\to, err := objects.Next()\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n\n\t\tcount++\n\t\tc.Assert(o.ID().IsZero(), Equals, false)\n\t\tc.Assert(o.Type(), Not(Equals), plumbing.AnyObject)\n\t}\n\n\tc.Assert(count, Equals, 31)\n}\n\nfunc (s *RepositorySuite) TestObjectNotFound(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: s.GetBasicLocalRepositoryURL()})\n\tc.Assert(err, IsNil)\n\n\thash := plumbing.NewHash(\"0a3fb06ff80156fb153bcdcc58b5e16c2d27625c\")\n\ttag, err := r.Object(plumbing.TagObject, hash)\n\tc.Assert(err, DeepEquals, plumbing.ErrObjectNotFound)\n\tc.Assert(tag, IsNil)\n}\n\nfunc (s *RepositorySuite) TestWorktree(c *C) {\n\tdef := memfs.New()\n\tr, _ := Init(memory.NewStorage(), def)\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\tc.Assert(w.Filesystem, Equals, def)\n}\n\nfunc (s *RepositorySuite) TestWorktreeBare(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\tw, err := r.Worktree()\n\tc.Assert(err, Equals, ErrIsBareRepository)\n\tc.Assert(w, IsNil)\n}\n\nfunc (s *RepositorySuite) TestResolveRevision(c *C) {\n\tf := fixtures.ByURL(\"https://github.com/git-fixtures/basic.git\").One()\n\tsto := filesystem.NewStorage(f.DotGit(), cache.NewObjectLRUDefault())\n\tr, err := Open(sto, f.DotGit())\n\tc.Assert(err, IsNil)\n\n\tdatas := map[string]string{\n\t\t\"HEAD\":                       \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"heads/master\":               \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"heads/master~1\":             \"918c48b83bd081e863dbe1b80f8998f058cd8294\",\n\t\t\"refs/heads/master\":          \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"refs/heads/master~2^^~\":     \"b029517f6300c2da0f4b651b8642506cd6aaf45d\",\n\t\t\"refs/tags/v1.0.0\":           \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"refs/remotes/origin/master\": \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"refs/remotes/origin/HEAD\":   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"HEAD~2^^~\":                  \"b029517f6300c2da0f4b651b8642506cd6aaf45d\",\n\t\t\"HEAD~3^2\":                   \"a5b8b09e2f8fcb0bb99d3ccb0958157b40890d69\",\n\t\t\"HEAD~3^2^0\":                 \"a5b8b09e2f8fcb0bb99d3ccb0958157b40890d69\",\n\t\t\"HEAD~2^{/binary file}\":      \"35e85108805c84807bc66a02d91535e1e24b38b9\",\n\t\t\"HEAD~^{/!-some}\":            \"1669dce138d9b841a518c64b10914d88f5e488ea\",\n\t\t\"master\":                     \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"branch\":                     \"e8d3ffab552895c19b9fcf7aa264d277cde33881\",\n\t\t\"v1.0.0\":                     \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\"branch~1\":                   \"918c48b83bd081e863dbe1b80f8998f058cd8294\",\n\t\t\"v1.0.0~1\":                   \"918c48b83bd081e863dbe1b80f8998f058cd8294\",\n\t\t\"master~1\":                   \"918c48b83bd081e863dbe1b80f8998f058cd8294\",\n\t\t\"918c48b83bd081e863dbe1b80f8998f058cd8294\": \"918c48b83bd081e863dbe1b80f8998f058cd8294\",\n\t}\n\n\tfor rev, hash := range datas {\n\t\th, err := r.ResolveRevision(plumbing.Revision(rev))\n\n\t\tc.Assert(err, IsNil, Commentf(\"while checking %s\", rev))\n\t\tc.Check(h.String(), Equals, hash, Commentf(\"while checking %s\", rev))\n\t}\n}\n\nfunc (s *RepositorySuite) TestResolveRevisionAnnotated(c *C) {\n\tf := fixtures.ByURL(\"https://github.com/git-fixtures/tags.git\").One()\n\tsto := filesystem.NewStorage(f.DotGit(), cache.NewObjectLRUDefault())\n\tr, err := Open(sto, f.DotGit())\n\tc.Assert(err, IsNil)\n\n\tdatas := map[string]string{\n\t\t\"refs/tags/annotated-tag\":                  \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\",\n\t\t\"b742a2a9fa0afcfa9a6fad080980fbc26b007c69\": \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\",\n\t}\n\n\tfor rev, hash := range datas {\n\t\th, err := r.ResolveRevision(plumbing.Revision(rev))\n\n\t\tc.Assert(err, IsNil, Commentf(\"while checking %s\", rev))\n\t\tc.Check(h.String(), Equals, hash, Commentf(\"while checking %s\", rev))\n\t}\n}\n\nfunc (s *RepositorySuite) TestResolveRevisionWithErrors(c *C) {\n\turl := s.GetLocalRepositoryURL(\n\t\tfixtures.ByURL(\"https://github.com/git-fixtures/basic.git\").One(),\n\t)\n\n\tr, _ := Init(memory.NewStorage(), nil)\n\terr := r.clone(context.Background(), &CloneOptions{URL: url})\n\tc.Assert(err, IsNil)\n\n\theadRef, err := r.Head()\n\tc.Assert(err, IsNil)\n\n\tref := plumbing.NewHashReference(\"refs/heads/918c48b83bd081e863dbe1b80f8998f058cd8294\", headRef.Hash())\n\terr = r.Storer.SetReference(ref)\n\tc.Assert(err, IsNil)\n\n\tdatas := map[string]string{\n\t\t\"efs/heads/master~\": \"reference not found\",\n\t\t\"HEAD^3\":            `Revision invalid : \"3\" found must be 0, 1 or 2 after \"^\"`,\n\t\t\"HEAD^{/whatever}\":  `No commit message match regexp : \"whatever\"`,\n\t\t\"4e1243bd22c66e76c2ba9eddc1f91394e57f9f83\": \"reference not found\",\n\t}\n\n\tfor rev, rerr := range datas {\n\t\t_, err := r.ResolveRevision(plumbing.Revision(rev))\n\t\tc.Assert(err, NotNil)\n\t\tc.Assert(err.Error(), Equals, rerr)\n\t}\n}\n\nfunc (s *RepositorySuite) testRepackObjects(\n\tc *C, deleteTime time.Time, expectedPacks int) {\n\tsrcFs := fixtures.ByTag(\"unpacked\").One().DotGit()\n\tvar sto storage.Storer\n\tvar err error\n\tsto = filesystem.NewStorage(srcFs, cache.NewObjectLRUDefault())\n\n\tlos := sto.(storer.LooseObjectStorer)\n\tc.Assert(los, NotNil)\n\n\tnumLooseStart := 0\n\terr = los.ForEachObjectHash(func(_ plumbing.Hash) error {\n\t\tnumLooseStart++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(numLooseStart > 0, Equals, true)\n\n\tpos := sto.(storer.PackedObjectStorer)\n\tc.Assert(los, NotNil)\n\n\tpacks, err := pos.ObjectPacks()\n\tc.Assert(err, IsNil)\n\tnumPacksStart := len(packs)\n\tc.Assert(numPacksStart > 1, Equals, true)\n\n\tr, err := Open(sto, srcFs)\n\tc.Assert(err, IsNil)\n\tc.Assert(r, NotNil)\n\n\terr = r.RepackObjects(&RepackConfig{\n\t\tOnlyDeletePacksOlderThan: deleteTime,\n\t})\n\tc.Assert(err, IsNil)\n\n\tnumLooseEnd := 0\n\terr = los.ForEachObjectHash(func(_ plumbing.Hash) error {\n\t\tnumLooseEnd++\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\tc.Assert(numLooseEnd, Equals, 0)\n\n\tpacks, err = pos.ObjectPacks()\n\tc.Assert(err, IsNil)\n\tnumPacksEnd := len(packs)\n\tc.Assert(numPacksEnd, Equals, expectedPacks)\n}\n\nfunc (s *RepositorySuite) TestRepackObjects(c *C) {\n\tif testing.Short() {\n\t\tc.Skip(\"skipping test in short mode.\")\n\t}\n\n\ts.testRepackObjects(c, time.Time{}, 1)\n}\n\nfunc (s *RepositorySuite) TestRepackObjectsWithNoDelete(c *C) {\n\tif testing.Short() {\n\t\tc.Skip(\"skipping test in short mode.\")\n\t}\n\n\ts.testRepackObjects(c, time.Unix(0, 1), 3)\n}\n\nfunc ExecuteOnPath(c *C, path string, cmds ...string) error {\n\tfor _, cmd := range cmds {\n\t\terr := executeOnPath(path, cmd)\n\t\tc.Assert(err, IsNil)\n\t}\n\n\treturn nil\n}\n\nfunc executeOnPath(path, cmd string) error {\n\targs := strings.Split(cmd, \" \")\n\tc := exec.Command(args[0], args[1:]...)\n\tc.Dir = path\n\tc.Env = os.Environ()\n\n\tbuf := bytes.NewBuffer(nil)\n\tc.Stderr = buf\n\tc.Stdout = buf\n\n\treturn c.Run()\n}\n\nfunc (s *RepositorySuite) TestBrokenMultipleShallowFetch(c *C) {\n\tr, _ := Init(memory.NewStorage(), nil)\n\t_, err := r.CreateRemote(&config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\tc.Assert(err, IsNil)\n\n\tc.Assert(r.Fetch(&FetchOptions{\n\t\tDepth:    2,\n\t\tRefSpecs: []config.RefSpec{config.RefSpec(\"refs/heads/master:refs/heads/master\")},\n\t}), IsNil)\n\n\tshallows, err := r.Storer.Shallow()\n\tc.Assert(err, IsNil)\n\tc.Assert(len(shallows), Equals, 1)\n\n\tref, err := r.Reference(\"refs/heads/master\", true)\n\tc.Assert(err, IsNil)\n\tcobj, err := r.CommitObject(ref.Hash())\n\tc.Assert(err, IsNil)\n\tc.Assert(cobj, NotNil)\n\terr = object.NewCommitPreorderIter(cobj, nil, nil).ForEach(func(c *object.Commit) error {\n\t\tfor _, ph := range c.ParentHashes {\n\t\t\tfor _, h := range shallows {\n\t\t\t\tif ph == h {\n\t\t\t\t\treturn storer.ErrStop\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\n\tc.Assert(r.Fetch(&FetchOptions{\n\t\tDepth:    5,\n\t\tRefSpecs: []config.RefSpec{config.RefSpec(\"refs/heads/*:refs/heads/*\")},\n\t}), IsNil)\n\n\tshallows, err = r.Storer.Shallow()\n\tc.Assert(err, IsNil)\n\tc.Assert(len(shallows), Equals, 3)\n\n\tref, err = r.Reference(\"refs/heads/master\", true)\n\tc.Assert(err, IsNil)\n\tcobj, err = r.CommitObject(ref.Hash())\n\tc.Assert(err, IsNil)\n\tc.Assert(cobj, NotNil)\n\terr = object.NewCommitPreorderIter(cobj, nil, nil).ForEach(func(c *object.Commit) error {\n\t\tfor _, ph := range c.ParentHashes {\n\t\t\tfor _, h := range shallows {\n\t\t\t\tif ph == h {\n\t\t\t\t\treturn storer.ErrStop\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n}\n\nfunc BenchmarkObjects(b *testing.B) {\n\tif err := fixtures.Init(); err != nil {\n\t\tb.Fatal(err)\n\t}\n\n\tdefer func() {\n\t\tif err := fixtures.Clean(); err != nil {\n\t\t\tb.Fatal(err)\n\t\t}\n\t}()\n\n\tfor _, f := range fixtures.ByTag(\"packfile\") {\n\t\tif f.DotGitHash == plumbing.ZeroHash {\n\t\t\tcontinue\n\t\t}\n\n\t\tb.Run(f.URL, func(b *testing.B) {\n\t\t\tfs := f.DotGit()\n\t\t\tstorer := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\n\t\t\tworktree, err := fs.Chroot(filepath.Dir(fs.Root()))\n\t\t\tif err != nil {\n\t\t\t\tb.Fatal(err)\n\t\t\t}\n\n\t\t\trepo, err := Open(storer, worktree)\n\t\t\tif err != nil {\n\t\t\t\tb.Fatal(err)\n\t\t\t}\n\n\t\t\tfor i := 0; i < b.N; i++ {\n\t\t\t\titer, err := repo.Objects()\n\t\t\t\tif err != nil {\n\t\t\t\t\tb.Fatal(err)\n\t\t\t\t}\n\n\t\t\t\tfor {\n\t\t\t\t\t_, err := iter.Next()\n\t\t\t\t\tif err == io.EOF {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tb.Fatal(err)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\titer.Close()\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc BenchmarkPlainClone(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tt, err := ioutil.TempDir(\"\", \"\")\n\t\tif err != nil {\n\t\t\tb.Fatal(err)\n\t\t}\n\t\t_, err = PlainClone(t, false, &CloneOptions{\n\t\t\tURL:   \"https://github.com/knqyf263/vuln-list\",\n\t\t\tDepth: 1,\n\t\t})\n\t\tif err != nil {\n\t\t\tb.Error(err)\n\t\t}\n\t\tb.StopTimer()\n\t\tos.RemoveAll(t)\n\t\tb.StartTimer()\n\t}\n}\n"
        },
        {
          "name": "repository_unix_test.go",
          "type": "blob",
          "size": 0.2578125,
          "content": "// +build !plan9,!windows\n\npackage git\n\nimport \"fmt\"\n\n// preReceiveHook returns the bytes of a pre-receive hook script\n// that prints m before exiting successfully\nfunc preReceiveHook(m string) []byte {\n\treturn []byte(fmt.Sprintf(\"#!/bin/sh\\nprintf '%s'\\n\", m))\n}\n"
        },
        {
          "name": "repository_windows_test.go",
          "type": "blob",
          "size": 0.2607421875,
          "content": "package git\n\nimport \"fmt\"\n\n// preReceiveHook returns the bytes of a pre-receive hook script\n// that prints m before exiting successfully\nfunc preReceiveHook(m string) []byte {\n\treturn []byte(fmt.Sprintf(\"#!C:/Program\\\\ Files/Git/usr/bin/sh.exe\\nprintf '%s'\\n\", m))\n}\n"
        },
        {
          "name": "status.go",
          "type": "blob",
          "size": 1.96875,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"path/filepath\"\n)\n\n// Status represents the current status of a Worktree.\n// The key of the map is the path of the file.\ntype Status map[string]*FileStatus\n\n// File returns the FileStatus for a given path, if the FileStatus doesn't\n// exists a new FileStatus is added to the map using the path as key.\nfunc (s Status) File(path string) *FileStatus {\n\tif _, ok := (s)[path]; !ok {\n\t\ts[path] = &FileStatus{Worktree: Untracked, Staging: Untracked}\n\t}\n\n\treturn s[path]\n}\n\n// IsUntracked checks if file for given path is 'Untracked'\nfunc (s Status) IsUntracked(path string) bool {\n\tstat, ok := (s)[filepath.ToSlash(path)]\n\treturn ok && stat.Worktree == Untracked\n}\n\n// IsClean returns true if all the files are in Unmodified status.\nfunc (s Status) IsClean() bool {\n\tfor _, status := range s {\n\t\tif status.Worktree != Unmodified || status.Staging != Unmodified {\n\t\t\treturn false\n\t\t}\n\t}\n\n\treturn true\n}\n\nfunc (s Status) String() string {\n\tbuf := bytes.NewBuffer(nil)\n\tfor path, status := range s {\n\t\tif status.Staging == Unmodified && status.Worktree == Unmodified {\n\t\t\tcontinue\n\t\t}\n\n\t\tif status.Staging == Renamed {\n\t\t\tpath = fmt.Sprintf(\"%s -> %s\", path, status.Extra)\n\t\t}\n\n\t\tfmt.Fprintf(buf, \"%c%c %s\\n\", status.Staging, status.Worktree, path)\n\t}\n\n\treturn buf.String()\n}\n\n// FileStatus contains the status of a file in the worktree\ntype FileStatus struct {\n\t// Staging is the status of a file in the staging area\n\tStaging StatusCode\n\t// Worktree is the status of a file in the worktree\n\tWorktree StatusCode\n\t// Extra contains extra information, such as the previous name in a rename\n\tExtra string\n}\n\n// StatusCode status code of a file in the Worktree\ntype StatusCode byte\n\nconst (\n\tUnmodified         StatusCode = ' '\n\tUntracked          StatusCode = '?'\n\tModified           StatusCode = 'M'\n\tAdded              StatusCode = 'A'\n\tDeleted            StatusCode = 'D'\n\tRenamed            StatusCode = 'R'\n\tCopied             StatusCode = 'C'\n\tUpdatedButUnmerged StatusCode = 'U'\n)\n"
        },
        {
          "name": "storage",
          "type": "tree",
          "content": null
        },
        {
          "name": "submodule.go",
          "type": "blob",
          "size": 7.71875,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\n\t\"gopkg.in/src-d/go-billy.v4\"\n\t\"gopkg.in/src-d/go-git.v4/config\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/format/index\"\n)\n\nvar (\n\tErrSubmoduleAlreadyInitialized = errors.New(\"submodule already initialized\")\n\tErrSubmoduleNotInitialized     = errors.New(\"submodule not initialized\")\n)\n\n// Submodule a submodule allows you to keep another Git repository in a\n// subdirectory of your repository.\ntype Submodule struct {\n\t// initialized defines if a submodule was already initialized.\n\tinitialized bool\n\n\tc *config.Submodule\n\tw *Worktree\n}\n\n// Config returns the submodule config\nfunc (s *Submodule) Config() *config.Submodule {\n\treturn s.c\n}\n\n// Init initialize the submodule reading the recorded Entry in the index for\n// the given submodule\nfunc (s *Submodule) Init() error {\n\tcfg, err := s.w.r.Storer.Config()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t_, ok := cfg.Submodules[s.c.Name]\n\tif ok {\n\t\treturn ErrSubmoduleAlreadyInitialized\n\t}\n\n\ts.initialized = true\n\n\tcfg.Submodules[s.c.Name] = s.c\n\treturn s.w.r.Storer.SetConfig(cfg)\n}\n\n// Status returns the status of the submodule.\nfunc (s *Submodule) Status() (*SubmoduleStatus, error) {\n\tidx, err := s.w.r.Storer.Index()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn s.status(idx)\n}\n\nfunc (s *Submodule) status(idx *index.Index) (*SubmoduleStatus, error) {\n\tstatus := &SubmoduleStatus{\n\t\tPath: s.c.Path,\n\t}\n\n\te, err := idx.Entry(s.c.Path)\n\tif err != nil && err != index.ErrEntryNotFound {\n\t\treturn nil, err\n\t}\n\n\tif e != nil {\n\t\tstatus.Expected = e.Hash\n\t}\n\n\tif !s.initialized {\n\t\treturn status, nil\n\t}\n\n\tr, err := s.Repository()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\thead, err := r.Head()\n\tif err == nil {\n\t\tstatus.Current = head.Hash()\n\t}\n\n\tif err != nil && err == plumbing.ErrReferenceNotFound {\n\t\terr = nil\n\t}\n\n\treturn status, err\n}\n\n// Repository returns the Repository represented by this submodule\nfunc (s *Submodule) Repository() (*Repository, error) {\n\tif !s.initialized {\n\t\treturn nil, ErrSubmoduleNotInitialized\n\t}\n\n\tstorer, err := s.w.r.Storer.Module(s.c.Name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t_, err = storer.Reference(plumbing.HEAD)\n\tif err != nil && err != plumbing.ErrReferenceNotFound {\n\t\treturn nil, err\n\t}\n\n\tvar exists bool\n\tif err == nil {\n\t\texists = true\n\t}\n\n\tvar worktree billy.Filesystem\n\tif worktree, err = s.w.Filesystem.Chroot(s.c.Path); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif exists {\n\t\treturn Open(storer, worktree)\n\t}\n\n\tr, err := Init(storer, worktree)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t_, err = r.CreateRemote(&config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{s.c.URL},\n\t})\n\n\treturn r, err\n}\n\n// Update the registered submodule to match what the superproject expects, the\n// submodule should be initialized first calling the Init method or setting in\n// the options SubmoduleUpdateOptions.Init equals true\nfunc (s *Submodule) Update(o *SubmoduleUpdateOptions) error {\n\treturn s.UpdateContext(context.Background(), o)\n}\n\n// UpdateContext the registered submodule to match what the superproject\n// expects, the submodule should be initialized first calling the Init method or\n// setting in the options SubmoduleUpdateOptions.Init equals true.\n//\n// The provided Context must be non-nil. If the context expires before the\n// operation is complete, an error is returned. The context only affects to the\n// transport operations.\nfunc (s *Submodule) UpdateContext(ctx context.Context, o *SubmoduleUpdateOptions) error {\n\treturn s.update(ctx, o, plumbing.ZeroHash)\n}\n\nfunc (s *Submodule) update(ctx context.Context, o *SubmoduleUpdateOptions, forceHash plumbing.Hash) error {\n\tif !s.initialized && !o.Init {\n\t\treturn ErrSubmoduleNotInitialized\n\t}\n\n\tif !s.initialized && o.Init {\n\t\tif err := s.Init(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tidx, err := s.w.r.Storer.Index()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\thash := forceHash\n\tif hash.IsZero() {\n\t\te, err := idx.Entry(s.c.Path)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\thash = e.Hash\n\t}\n\n\tr, err := s.Repository()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := s.fetchAndCheckout(ctx, r, o, hash); err != nil {\n\t\treturn err\n\t}\n\n\treturn s.doRecursiveUpdate(r, o)\n}\n\nfunc (s *Submodule) doRecursiveUpdate(r *Repository, o *SubmoduleUpdateOptions) error {\n\tif o.RecurseSubmodules == NoRecurseSubmodules {\n\t\treturn nil\n\t}\n\n\tw, err := r.Worktree()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tl, err := w.Submodules()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tnew := &SubmoduleUpdateOptions{}\n\t*new = *o\n\n\tnew.RecurseSubmodules--\n\treturn l.Update(new)\n}\n\nfunc (s *Submodule) fetchAndCheckout(\n\tctx context.Context, r *Repository, o *SubmoduleUpdateOptions, hash plumbing.Hash,\n) error {\n\tif !o.NoFetch {\n\t\terr := r.FetchContext(ctx, &FetchOptions{Auth: o.Auth})\n\t\tif err != nil && err != NoErrAlreadyUpToDate {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tw, err := r.Worktree()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := w.Checkout(&CheckoutOptions{Hash: hash}); err != nil {\n\t\treturn err\n\t}\n\n\thead := plumbing.NewHashReference(plumbing.HEAD, hash)\n\treturn r.Storer.SetReference(head)\n}\n\n// Submodules list of several submodules from the same repository.\ntype Submodules []*Submodule\n\n// Init initializes the submodules in this list.\nfunc (s Submodules) Init() error {\n\tfor _, sub := range s {\n\t\tif err := sub.Init(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// Update updates all the submodules in this list.\nfunc (s Submodules) Update(o *SubmoduleUpdateOptions) error {\n\treturn s.UpdateContext(context.Background(), o)\n}\n\n// UpdateContext updates all the submodules in this list.\n//\n// The provided Context must be non-nil. If the context expires before the\n// operation is complete, an error is returned. The context only affects to the\n// transport operations.\nfunc (s Submodules) UpdateContext(ctx context.Context, o *SubmoduleUpdateOptions) error {\n\tfor _, sub := range s {\n\t\tif err := sub.UpdateContext(ctx, o); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// Status returns the status of the submodules.\nfunc (s Submodules) Status() (SubmodulesStatus, error) {\n\tvar list SubmodulesStatus\n\n\tvar r *Repository\n\tfor _, sub := range s {\n\t\tif r == nil {\n\t\t\tr = sub.w.r\n\t\t}\n\n\t\tidx, err := r.Storer.Index()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tstatus, err := sub.status(idx)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tlist = append(list, status)\n\t}\n\n\treturn list, nil\n}\n\n// SubmodulesStatus contains the status for all submodiles in the worktree\ntype SubmodulesStatus []*SubmoduleStatus\n\n// String is equivalent to `git submodule status`\nfunc (s SubmodulesStatus) String() string {\n\tbuf := bytes.NewBuffer(nil)\n\tfor _, sub := range s {\n\t\tfmt.Fprintln(buf, sub)\n\t}\n\n\treturn buf.String()\n}\n\n// SubmoduleStatus contains the status for a submodule in the worktree\ntype SubmoduleStatus struct {\n\tPath     string\n\tCurrent  plumbing.Hash\n\tExpected plumbing.Hash\n\tBranch   plumbing.ReferenceName\n}\n\n// IsClean is the HEAD of the submodule is equals to the expected commit\nfunc (s *SubmoduleStatus) IsClean() bool {\n\treturn s.Current == s.Expected\n}\n\n// String is equivalent to `git submodule status <submodule>`\n//\n// This will print the SHA-1 of the currently checked out commit for a\n// submodule, along with the submodule path and the output of git describe fo\n// the SHA-1. Each SHA-1 will be prefixed with - if the submodule is not\n// initialized, + if the currently checked out submodule commit does not match\n// the SHA-1 found in the index of the containing repository.\nfunc (s *SubmoduleStatus) String() string {\n\tvar extra string\n\tvar status = ' '\n\n\tif s.Current.IsZero() {\n\t\tstatus = '-'\n\t} else if !s.IsClean() {\n\t\tstatus = '+'\n\t}\n\n\tif len(s.Branch) != 0 {\n\t\textra = string(s.Branch[5:])\n\t} else if !s.Current.IsZero() {\n\t\textra = s.Current.String()[:7]\n\t}\n\n\tif extra != \"\" {\n\t\textra = fmt.Sprintf(\" (%s)\", extra)\n\t}\n\n\treturn fmt.Sprintf(\"%c%s %s%s\", status, s.Expected, s.Path, extra)\n}\n"
        },
        {
          "name": "submodule_test.go",
          "type": "blob",
          "size": 4.9052734375,
          "content": "package git\n\nimport (\n\t\"context\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"testing\"\n\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\n\t. \"gopkg.in/check.v1\"\n\t\"gopkg.in/src-d/go-git-fixtures.v3\"\n)\n\ntype SubmoduleSuite struct {\n\tBaseSuite\n\tWorktree *Worktree\n\tpath     string\n}\n\nvar _ = Suite(&SubmoduleSuite{})\n\nfunc (s *SubmoduleSuite) SetUpTest(c *C) {\n\tpath := fixtures.ByTag(\"submodule\").One().Worktree().Root()\n\n\tdir, err := ioutil.TempDir(\"\", \"submodule\")\n\tc.Assert(err, IsNil)\n\n\tr, err := PlainClone(filepath.Join(dir, \"worktree\"), false, &CloneOptions{\n\t\tURL: path,\n\t})\n\n\tc.Assert(err, IsNil)\n\n\ts.Repository = r\n\ts.Worktree, err = r.Worktree()\n\tc.Assert(err, IsNil)\n\n\ts.path = dir\n}\n\nfunc (s *SubmoduleSuite) TearDownTest(c *C) {\n\terr := os.RemoveAll(s.path)\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *SubmoduleSuite) TestInit(c *C) {\n\tsm, err := s.Worktree.Submodule(\"basic\")\n\tc.Assert(err, IsNil)\n\n\tc.Assert(sm.initialized, Equals, false)\n\terr = sm.Init()\n\tc.Assert(err, IsNil)\n\n\tc.Assert(sm.initialized, Equals, true)\n\n\tcfg, err := s.Repository.Config()\n\tc.Assert(err, IsNil)\n\n\tc.Assert(cfg.Submodules, HasLen, 1)\n\tc.Assert(cfg.Submodules[\"basic\"], NotNil)\n\n\tstatus, err := sm.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, false)\n}\n\nfunc (s *SubmoduleSuite) TestUpdate(c *C) {\n\tif testing.Short() {\n\t\tc.Skip(\"skipping test in short mode.\")\n\t}\n\n\tsm, err := s.Worktree.Submodule(\"basic\")\n\tc.Assert(err, IsNil)\n\n\terr = sm.Update(&SubmoduleUpdateOptions{\n\t\tInit: true,\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tr, err := sm.Repository()\n\tc.Assert(err, IsNil)\n\n\tref, err := r.Reference(plumbing.HEAD, true)\n\tc.Assert(err, IsNil)\n\tc.Assert(ref.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\tstatus, err := sm.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *SubmoduleSuite) TestRepositoryWithoutInit(c *C) {\n\tsm, err := s.Worktree.Submodule(\"basic\")\n\tc.Assert(err, IsNil)\n\n\tr, err := sm.Repository()\n\tc.Assert(err, Equals, ErrSubmoduleNotInitialized)\n\tc.Assert(r, IsNil)\n}\n\nfunc (s *SubmoduleSuite) TestUpdateWithoutInit(c *C) {\n\tsm, err := s.Worktree.Submodule(\"basic\")\n\tc.Assert(err, IsNil)\n\n\terr = sm.Update(&SubmoduleUpdateOptions{})\n\tc.Assert(err, Equals, ErrSubmoduleNotInitialized)\n}\n\nfunc (s *SubmoduleSuite) TestUpdateWithNotFetch(c *C) {\n\tsm, err := s.Worktree.Submodule(\"basic\")\n\tc.Assert(err, IsNil)\n\n\terr = sm.Update(&SubmoduleUpdateOptions{\n\t\tInit:    true,\n\t\tNoFetch: true,\n\t})\n\n\t// Since we are not fetching, the object is not there\n\tc.Assert(err, Equals, plumbing.ErrObjectNotFound)\n}\n\nfunc (s *SubmoduleSuite) TestUpdateWithRecursion(c *C) {\n\tif testing.Short() {\n\t\tc.Skip(\"skipping test in short mode.\")\n\t}\n\n\tsm, err := s.Worktree.Submodule(\"itself\")\n\tc.Assert(err, IsNil)\n\n\terr = sm.Update(&SubmoduleUpdateOptions{\n\t\tInit:              true,\n\t\tRecurseSubmodules: 2,\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tfs := s.Worktree.Filesystem\n\t_, err = fs.Stat(fs.Join(\"itself\", \"basic\", \"LICENSE\"))\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *SubmoduleSuite) TestUpdateWithInitAndUpdate(c *C) {\n\tif testing.Short() {\n\t\tc.Skip(\"skipping test in short mode.\")\n\t}\n\n\tsm, err := s.Worktree.Submodule(\"basic\")\n\tc.Assert(err, IsNil)\n\n\terr = sm.Update(&SubmoduleUpdateOptions{\n\t\tInit: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tidx, err := s.Repository.Storer.Index()\n\tc.Assert(err, IsNil)\n\n\tfor i, e := range idx.Entries {\n\t\tif e.Name == \"basic\" {\n\t\t\te.Hash = plumbing.NewHash(\"b029517f6300c2da0f4b651b8642506cd6aaf45d\")\n\t\t}\n\n\t\tidx.Entries[i] = e\n\t}\n\n\terr = s.Repository.Storer.SetIndex(idx)\n\tc.Assert(err, IsNil)\n\n\terr = sm.Update(&SubmoduleUpdateOptions{})\n\tc.Assert(err, IsNil)\n\n\tr, err := sm.Repository()\n\tc.Assert(err, IsNil)\n\n\tref, err := r.Reference(plumbing.HEAD, true)\n\tc.Assert(err, IsNil)\n\tc.Assert(ref.Hash().String(), Equals, \"b029517f6300c2da0f4b651b8642506cd6aaf45d\")\n\n}\n\nfunc (s *SubmoduleSuite) TestSubmodulesInit(c *C) {\n\tsm, err := s.Worktree.Submodules()\n\tc.Assert(err, IsNil)\n\n\terr = sm.Init()\n\tc.Assert(err, IsNil)\n\n\tsm, err = s.Worktree.Submodules()\n\tc.Assert(err, IsNil)\n\n\tfor _, m := range sm {\n\t\tc.Assert(m.initialized, Equals, true)\n\t}\n}\n\nfunc (s *SubmoduleSuite) TestGitSubmodulesSymlink(c *C) {\n\tf, err := s.Worktree.Filesystem.Create(\"badfile\")\n\tc.Assert(err, IsNil)\n\tdefer f.Close()\n\n\terr = s.Worktree.Filesystem.Remove(gitmodulesFile)\n\tc.Assert(err, IsNil)\n\n\terr = s.Worktree.Filesystem.Symlink(\"badfile\", gitmodulesFile)\n\tc.Assert(err, IsNil)\n\n\t_, err = s.Worktree.Submodules()\n\tc.Assert(err, Equals, ErrGitModulesSymlink)\n}\n\nfunc (s *SubmoduleSuite) TestSubmodulesStatus(c *C) {\n\tsm, err := s.Worktree.Submodules()\n\tc.Assert(err, IsNil)\n\n\tstatus, err := sm.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 2)\n}\n\nfunc (s *SubmoduleSuite) TestSubmodulesUpdateContext(c *C) {\n\tif testing.Short() {\n\t\tc.Skip(\"skipping test in short mode.\")\n\t}\n\n\tsm, err := s.Worktree.Submodules()\n\tc.Assert(err, IsNil)\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\n\terr = sm.UpdateContext(ctx, &SubmoduleUpdateOptions{Init: true})\n\tc.Assert(err, NotNil)\n}\n"
        },
        {
          "name": "utils",
          "type": "tree",
          "content": null
        },
        {
          "name": "worktree.go",
          "type": "blob",
          "size": 20.056640625,
          "content": "package git\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\tstdioutil \"io/ioutil\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"sync\"\n\n\t\"gopkg.in/src-d/go-git.v4/config\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/filemode\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/format/gitignore\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/format/index\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/object\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/storer\"\n\t\"gopkg.in/src-d/go-git.v4/utils/ioutil\"\n\t\"gopkg.in/src-d/go-git.v4/utils/merkletrie\"\n\n\t\"gopkg.in/src-d/go-billy.v4\"\n\t\"gopkg.in/src-d/go-billy.v4/util\"\n)\n\nvar (\n\tErrWorktreeNotClean     = errors.New(\"worktree is not clean\")\n\tErrSubmoduleNotFound    = errors.New(\"submodule not found\")\n\tErrUnstagedChanges      = errors.New(\"worktree contains unstaged changes\")\n\tErrGitModulesSymlink    = errors.New(gitmodulesFile + \" is a symlink\")\n\tErrNonFastForwardUpdate = errors.New(\"non-fast-forward update\")\n)\n\n// Worktree represents a git worktree.\ntype Worktree struct {\n\t// Filesystem underlying filesystem.\n\tFilesystem billy.Filesystem\n\t// External excludes not found in the repository .gitignore\n\tExcludes []gitignore.Pattern\n\n\tr *Repository\n}\n\n// Pull incorporates changes from a remote repository into the current branch.\n// Returns nil if the operation is successful, NoErrAlreadyUpToDate if there are\n// no changes to be fetched, or an error.\n//\n// Pull only supports merges where the can be resolved as a fast-forward.\nfunc (w *Worktree) Pull(o *PullOptions) error {\n\treturn w.PullContext(context.Background(), o)\n}\n\n// PullContext incorporates changes from a remote repository into the current\n// branch. Returns nil if the operation is successful, NoErrAlreadyUpToDate if\n// there are no changes to be fetched, or an error.\n//\n// Pull only supports merges where the can be resolved as a fast-forward.\n//\n// The provided Context must be non-nil. If the context expires before the\n// operation is complete, an error is returned. The context only affects to the\n// transport operations.\nfunc (w *Worktree) PullContext(ctx context.Context, o *PullOptions) error {\n\tif err := o.Validate(); err != nil {\n\t\treturn err\n\t}\n\n\tremote, err := w.r.Remote(o.RemoteName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfetchHead, err := remote.fetch(ctx, &FetchOptions{\n\t\tRemoteName: o.RemoteName,\n\t\tDepth:      o.Depth,\n\t\tAuth:       o.Auth,\n\t\tProgress:   o.Progress,\n\t\tForce:      o.Force,\n\t})\n\n\tupdated := true\n\tif err == NoErrAlreadyUpToDate {\n\t\tupdated = false\n\t} else if err != nil {\n\t\treturn err\n\t}\n\n\tref, err := storer.ResolveReference(fetchHead, o.ReferenceName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\thead, err := w.r.Head()\n\tif err == nil {\n\t\tif !updated && head.Hash() == ref.Hash() {\n\t\t\treturn NoErrAlreadyUpToDate\n\t\t}\n\n\t\tff, err := isFastForward(w.r.Storer, head.Hash(), ref.Hash())\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif !ff {\n\t\t\treturn ErrNonFastForwardUpdate\n\t\t}\n\t}\n\n\tif err != nil && err != plumbing.ErrReferenceNotFound {\n\t\treturn err\n\t}\n\n\tif err := w.updateHEAD(ref.Hash()); err != nil {\n\t\treturn err\n\t}\n\n\tif err := w.Reset(&ResetOptions{\n\t\tMode:   MergeReset,\n\t\tCommit: ref.Hash(),\n\t}); err != nil {\n\t\treturn err\n\t}\n\n\tif o.RecurseSubmodules != NoRecurseSubmodules {\n\t\treturn w.updateSubmodules(&SubmoduleUpdateOptions{\n\t\t\tRecurseSubmodules: o.RecurseSubmodules,\n\t\t\tAuth:              o.Auth,\n\t\t})\n\t}\n\n\treturn nil\n}\n\nfunc (w *Worktree) updateSubmodules(o *SubmoduleUpdateOptions) error {\n\ts, err := w.Submodules()\n\tif err != nil {\n\t\treturn err\n\t}\n\to.Init = true\n\treturn s.Update(o)\n}\n\n// Checkout switch branches or restore working tree files.\nfunc (w *Worktree) Checkout(opts *CheckoutOptions) error {\n\tif err := opts.Validate(); err != nil {\n\t\treturn err\n\t}\n\n\tif opts.Create {\n\t\tif err := w.createBranch(opts); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tc, err := w.getCommitFromCheckoutOptions(opts)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tro := &ResetOptions{Commit: c, Mode: MergeReset}\n\tif opts.Force {\n\t\tro.Mode = HardReset\n\t} else if opts.Keep {\n\t\tro.Mode = SoftReset\n\t}\n\n\tif !opts.Hash.IsZero() && !opts.Create {\n\t\terr = w.setHEADToCommit(opts.Hash)\n\t} else {\n\t\terr = w.setHEADToBranch(opts.Branch, c)\n\t}\n\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn w.Reset(ro)\n}\nfunc (w *Worktree) createBranch(opts *CheckoutOptions) error {\n\t_, err := w.r.Storer.Reference(opts.Branch)\n\tif err == nil {\n\t\treturn fmt.Errorf(\"a branch named %q already exists\", opts.Branch)\n\t}\n\n\tif err != plumbing.ErrReferenceNotFound {\n\t\treturn err\n\t}\n\n\tif opts.Hash.IsZero() {\n\t\tref, err := w.r.Head()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\topts.Hash = ref.Hash()\n\t}\n\n\treturn w.r.Storer.SetReference(\n\t\tplumbing.NewHashReference(opts.Branch, opts.Hash),\n\t)\n}\n\nfunc (w *Worktree) getCommitFromCheckoutOptions(opts *CheckoutOptions) (plumbing.Hash, error) {\n\tif !opts.Hash.IsZero() {\n\t\treturn opts.Hash, nil\n\t}\n\n\tb, err := w.r.Reference(opts.Branch, true)\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\tif !b.Name().IsTag() {\n\t\treturn b.Hash(), nil\n\t}\n\n\to, err := w.r.Object(plumbing.AnyObject, b.Hash())\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\tswitch o := o.(type) {\n\tcase *object.Tag:\n\t\tif o.TargetType != plumbing.CommitObject {\n\t\t\treturn plumbing.ZeroHash, fmt.Errorf(\"unsupported tag object target %q\", o.TargetType)\n\t\t}\n\n\t\treturn o.Target, nil\n\tcase *object.Commit:\n\t\treturn o.Hash, nil\n\t}\n\n\treturn plumbing.ZeroHash, fmt.Errorf(\"unsupported tag target %q\", o.Type())\n}\n\nfunc (w *Worktree) setHEADToCommit(commit plumbing.Hash) error {\n\thead := plumbing.NewHashReference(plumbing.HEAD, commit)\n\treturn w.r.Storer.SetReference(head)\n}\n\nfunc (w *Worktree) setHEADToBranch(branch plumbing.ReferenceName, commit plumbing.Hash) error {\n\ttarget, err := w.r.Storer.Reference(branch)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvar head *plumbing.Reference\n\tif target.Name().IsBranch() {\n\t\thead = plumbing.NewSymbolicReference(plumbing.HEAD, target.Name())\n\t} else {\n\t\thead = plumbing.NewHashReference(plumbing.HEAD, commit)\n\t}\n\n\treturn w.r.Storer.SetReference(head)\n}\n\n// Reset the worktree to a specified state.\nfunc (w *Worktree) Reset(opts *ResetOptions) error {\n\tif err := opts.Validate(w.r); err != nil {\n\t\treturn err\n\t}\n\n\tif opts.Mode == MergeReset {\n\t\tunstaged, err := w.containsUnstagedChanges()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif unstaged {\n\t\t\treturn ErrUnstagedChanges\n\t\t}\n\t}\n\n\tif err := w.setHEADCommit(opts.Commit); err != nil {\n\t\treturn err\n\t}\n\n\tif opts.Mode == SoftReset {\n\t\treturn nil\n\t}\n\n\tt, err := w.getTreeFromCommitHash(opts.Commit)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif opts.Mode == MixedReset || opts.Mode == MergeReset || opts.Mode == HardReset {\n\t\tif err := w.resetIndex(t); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif opts.Mode == MergeReset || opts.Mode == HardReset {\n\t\tif err := w.resetWorktree(t); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (w *Worktree) resetIndex(t *object.Tree) error {\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn err\n\t}\n\tb := newIndexBuilder(idx)\n\n\tchanges, err := w.diffTreeWithStaging(t, true)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, ch := range changes {\n\t\ta, err := ch.Action()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tvar name string\n\t\tvar e *object.TreeEntry\n\n\t\tswitch a {\n\t\tcase merkletrie.Modify, merkletrie.Insert:\n\t\t\tname = ch.To.String()\n\t\t\te, err = t.FindEntry(name)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\tcase merkletrie.Delete:\n\t\t\tname = ch.From.String()\n\t\t}\n\n\t\tb.Remove(name)\n\t\tif e == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tb.Add(&index.Entry{\n\t\t\tName: name,\n\t\t\tHash: e.Hash,\n\t\t\tMode: e.Mode,\n\t\t})\n\n\t}\n\n\tb.Write(idx)\n\treturn w.r.Storer.SetIndex(idx)\n}\n\nfunc (w *Worktree) resetWorktree(t *object.Tree) error {\n\tchanges, err := w.diffStagingWithWorktree(true)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn err\n\t}\n\tb := newIndexBuilder(idx)\n\n\tfor _, ch := range changes {\n\t\tif err := w.checkoutChange(ch, t, b); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tb.Write(idx)\n\treturn w.r.Storer.SetIndex(idx)\n}\n\nfunc (w *Worktree) checkoutChange(ch merkletrie.Change, t *object.Tree, idx *indexBuilder) error {\n\ta, err := ch.Action()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvar e *object.TreeEntry\n\tvar name string\n\tvar isSubmodule bool\n\n\tswitch a {\n\tcase merkletrie.Modify, merkletrie.Insert:\n\t\tname = ch.To.String()\n\t\te, err = t.FindEntry(name)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tisSubmodule = e.Mode == filemode.Submodule\n\tcase merkletrie.Delete:\n\t\treturn rmFileAndDirIfEmpty(w.Filesystem, ch.From.String())\n\t}\n\n\tif isSubmodule {\n\t\treturn w.checkoutChangeSubmodule(name, a, e, idx)\n\t}\n\n\treturn w.checkoutChangeRegularFile(name, a, t, e, idx)\n}\n\nfunc (w *Worktree) containsUnstagedChanges() (bool, error) {\n\tch, err := w.diffStagingWithWorktree(false)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tfor _, c := range ch {\n\t\ta, err := c.Action()\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\n\t\tif a == merkletrie.Insert {\n\t\t\tcontinue\n\t\t}\n\n\t\treturn true, nil\n\t}\n\n\treturn false, nil\n}\n\nfunc (w *Worktree) setHEADCommit(commit plumbing.Hash) error {\n\thead, err := w.r.Reference(plumbing.HEAD, false)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif head.Type() == plumbing.HashReference {\n\t\thead = plumbing.NewHashReference(plumbing.HEAD, commit)\n\t\treturn w.r.Storer.SetReference(head)\n\t}\n\n\tbranch, err := w.r.Reference(head.Target(), false)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif !branch.Name().IsBranch() {\n\t\treturn fmt.Errorf(\"invalid HEAD target should be a branch, found %s\", branch.Type())\n\t}\n\n\tbranch = plumbing.NewHashReference(branch.Name(), commit)\n\treturn w.r.Storer.SetReference(branch)\n}\n\nfunc (w *Worktree) checkoutChangeSubmodule(name string,\n\ta merkletrie.Action,\n\te *object.TreeEntry,\n\tidx *indexBuilder,\n) error {\n\tswitch a {\n\tcase merkletrie.Modify:\n\t\tsub, err := w.Submodule(name)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif !sub.initialized {\n\t\t\treturn nil\n\t\t}\n\n\t\treturn w.addIndexFromTreeEntry(name, e, idx)\n\tcase merkletrie.Insert:\n\t\tmode, err := e.Mode.ToOSFileMode()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif err := w.Filesystem.MkdirAll(name, mode); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn w.addIndexFromTreeEntry(name, e, idx)\n\t}\n\n\treturn nil\n}\n\nfunc (w *Worktree) checkoutChangeRegularFile(name string,\n\ta merkletrie.Action,\n\tt *object.Tree,\n\te *object.TreeEntry,\n\tidx *indexBuilder,\n) error {\n\tswitch a {\n\tcase merkletrie.Modify:\n\t\tidx.Remove(name)\n\n\t\t// to apply perm changes the file is deleted, billy doesn't implement\n\t\t// chmod\n\t\tif err := w.Filesystem.Remove(name); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tfallthrough\n\tcase merkletrie.Insert:\n\t\tf, err := t.File(name)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif err := w.checkoutFile(f); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn w.addIndexFromFile(name, e.Hash, idx)\n\t}\n\n\treturn nil\n}\n\nvar copyBufferPool = sync.Pool{\n\tNew: func() interface{} {\n\t\treturn make([]byte, 32*1024)\n\t},\n}\n\nfunc (w *Worktree) checkoutFile(f *object.File) (err error) {\n\tmode, err := f.Mode.ToOSFileMode()\n\tif err != nil {\n\t\treturn\n\t}\n\n\tif mode&os.ModeSymlink != 0 {\n\t\treturn w.checkoutFileSymlink(f)\n\t}\n\n\tfrom, err := f.Reader()\n\tif err != nil {\n\t\treturn\n\t}\n\n\tdefer ioutil.CheckClose(from, &err)\n\n\tto, err := w.Filesystem.OpenFile(f.Name, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, mode.Perm())\n\tif err != nil {\n\t\treturn\n\t}\n\n\tdefer ioutil.CheckClose(to, &err)\n\tbuf := copyBufferPool.Get().([]byte)\n\t_, err = io.CopyBuffer(to, from, buf)\n\tcopyBufferPool.Put(buf)\n\treturn\n}\n\nfunc (w *Worktree) checkoutFileSymlink(f *object.File) (err error) {\n\tfrom, err := f.Reader()\n\tif err != nil {\n\t\treturn\n\t}\n\n\tdefer ioutil.CheckClose(from, &err)\n\n\tbytes, err := stdioutil.ReadAll(from)\n\tif err != nil {\n\t\treturn\n\t}\n\n\terr = w.Filesystem.Symlink(string(bytes), f.Name)\n\n\t// On windows, this might fail.\n\t// Follow Git on Windows behavior by writing the link as it is.\n\tif err != nil && isSymlinkWindowsNonAdmin(err) {\n\t\tmode, _ := f.Mode.ToOSFileMode()\n\n\t\tto, err := w.Filesystem.OpenFile(f.Name, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, mode.Perm())\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tdefer ioutil.CheckClose(to, &err)\n\n\t\t_, err = to.Write(bytes)\n\t\treturn err\n\t}\n\treturn\n}\n\nfunc (w *Worktree) addIndexFromTreeEntry(name string, f *object.TreeEntry, idx *indexBuilder) error {\n\tidx.Remove(name)\n\tidx.Add(&index.Entry{\n\t\tHash: f.Hash,\n\t\tName: name,\n\t\tMode: filemode.Submodule,\n\t})\n\treturn nil\n}\n\nfunc (w *Worktree) addIndexFromFile(name string, h plumbing.Hash, idx *indexBuilder) error {\n\tidx.Remove(name)\n\tfi, err := w.Filesystem.Lstat(name)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tmode, err := filemode.NewFromOSFileMode(fi.Mode())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\te := &index.Entry{\n\t\tHash:       h,\n\t\tName:       name,\n\t\tMode:       mode,\n\t\tModifiedAt: fi.ModTime(),\n\t\tSize:       uint32(fi.Size()),\n\t}\n\n\t// if the FileInfo.Sys() comes from os the ctime, dev, inode, uid and gid\n\t// can be retrieved, otherwise this doesn't apply\n\tif fillSystemInfo != nil {\n\t\tfillSystemInfo(e, fi.Sys())\n\t}\n\tidx.Add(e)\n\treturn nil\n}\n\nfunc (w *Worktree) getTreeFromCommitHash(commit plumbing.Hash) (*object.Tree, error) {\n\tc, err := w.r.CommitObject(commit)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn c.Tree()\n}\n\nvar fillSystemInfo func(e *index.Entry, sys interface{})\n\nconst gitmodulesFile = \".gitmodules\"\n\n// Submodule returns the submodule with the given name\nfunc (w *Worktree) Submodule(name string) (*Submodule, error) {\n\tl, err := w.Submodules()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, m := range l {\n\t\tif m.Config().Name == name {\n\t\t\treturn m, nil\n\t\t}\n\t}\n\n\treturn nil, ErrSubmoduleNotFound\n}\n\n// Submodules returns all the available submodules\nfunc (w *Worktree) Submodules() (Submodules, error) {\n\tl := make(Submodules, 0)\n\tm, err := w.readGitmodulesFile()\n\tif err != nil || m == nil {\n\t\treturn l, err\n\t}\n\n\tc, err := w.r.Config()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, s := range m.Submodules {\n\t\tl = append(l, w.newSubmodule(s, c.Submodules[s.Name]))\n\t}\n\n\treturn l, nil\n}\n\nfunc (w *Worktree) newSubmodule(fromModules, fromConfig *config.Submodule) *Submodule {\n\tm := &Submodule{w: w}\n\tm.initialized = fromConfig != nil\n\n\tif !m.initialized {\n\t\tm.c = fromModules\n\t\treturn m\n\t}\n\n\tm.c = fromConfig\n\tm.c.Path = fromModules.Path\n\treturn m\n}\n\nfunc (w *Worktree) isSymlink(path string) bool {\n\tif s, err := w.Filesystem.Lstat(path); err == nil {\n\t\treturn s.Mode()&os.ModeSymlink != 0\n\t}\n\treturn false\n}\n\nfunc (w *Worktree) readGitmodulesFile() (*config.Modules, error) {\n\tif w.isSymlink(gitmodulesFile) {\n\t\treturn nil, ErrGitModulesSymlink\n\t}\n\n\tf, err := w.Filesystem.Open(gitmodulesFile)\n\tif err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\treturn nil, nil\n\t\t}\n\n\t\treturn nil, err\n\t}\n\n\tdefer f.Close()\n\tinput, err := stdioutil.ReadAll(f)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tm := config.NewModules()\n\treturn m, m.Unmarshal(input)\n}\n\n// Clean the worktree by removing untracked files.\n// An empty dir could be removed - this is what  `git clean -f -d .` does.\nfunc (w *Worktree) Clean(opts *CleanOptions) error {\n\ts, err := w.Status()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\troot := \"\"\n\tfiles, err := w.Filesystem.ReadDir(root)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn w.doClean(s, opts, root, files)\n}\n\nfunc (w *Worktree) doClean(status Status, opts *CleanOptions, dir string, files []os.FileInfo) error {\n\tfor _, fi := range files {\n\t\tif fi.Name() == GitDirName {\n\t\t\tcontinue\n\t\t}\n\n\t\t// relative path under the root\n\t\tpath := filepath.Join(dir, fi.Name())\n\t\tif fi.IsDir() {\n\t\t\tif !opts.Dir {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tsubfiles, err := w.Filesystem.ReadDir(path)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\terr = w.doClean(status, opts, path, subfiles)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t} else {\n\t\t\tif status.IsUntracked(path) {\n\t\t\t\tif err := w.Filesystem.Remove(path); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif opts.Dir {\n\t\treturn doCleanDirectories(w.Filesystem, dir)\n\t}\n\treturn nil\n}\n\n// GrepResult is structure of a grep result.\ntype GrepResult struct {\n\t// FileName is the name of file which contains match.\n\tFileName string\n\t// LineNumber is the line number of a file at which a match was found.\n\tLineNumber int\n\t// Content is the content of the file at the matching line.\n\tContent string\n\t// TreeName is the name of the tree (reference name/commit hash) at\n\t// which the match was performed.\n\tTreeName string\n}\n\nfunc (gr GrepResult) String() string {\n\treturn fmt.Sprintf(\"%s:%s:%d:%s\", gr.TreeName, gr.FileName, gr.LineNumber, gr.Content)\n}\n\n// Grep performs grep on a worktree.\nfunc (w *Worktree) Grep(opts *GrepOptions) ([]GrepResult, error) {\n\tif err := opts.Validate(w); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Obtain commit hash from options (CommitHash or ReferenceName).\n\tvar commitHash plumbing.Hash\n\t// treeName contains the value of TreeName in GrepResult.\n\tvar treeName string\n\n\tif opts.ReferenceName != \"\" {\n\t\tref, err := w.r.Reference(opts.ReferenceName, true)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tcommitHash = ref.Hash()\n\t\ttreeName = opts.ReferenceName.String()\n\t} else if !opts.CommitHash.IsZero() {\n\t\tcommitHash = opts.CommitHash\n\t\ttreeName = opts.CommitHash.String()\n\t}\n\n\t// Obtain a tree from the commit hash and get a tracked files iterator from\n\t// the tree.\n\ttree, err := w.getTreeFromCommitHash(commitHash)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfileiter := tree.Files()\n\n\treturn findMatchInFiles(fileiter, treeName, opts)\n}\n\n// findMatchInFiles takes a FileIter, worktree name and GrepOptions, and\n// returns a slice of GrepResult containing the result of regex pattern matching\n// in content of all the files.\nfunc findMatchInFiles(fileiter *object.FileIter, treeName string, opts *GrepOptions) ([]GrepResult, error) {\n\tvar results []GrepResult\n\n\terr := fileiter.ForEach(func(file *object.File) error {\n\t\tvar fileInPathSpec bool\n\n\t\t// When no pathspecs are provided, search all the files.\n\t\tif len(opts.PathSpecs) == 0 {\n\t\t\tfileInPathSpec = true\n\t\t}\n\n\t\t// Check if the file name matches with the pathspec. Break out of the\n\t\t// loop once a match is found.\n\t\tfor _, pathSpec := range opts.PathSpecs {\n\t\t\tif pathSpec != nil && pathSpec.MatchString(file.Name) {\n\t\t\t\tfileInPathSpec = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\t// If the file does not match with any of the pathspec, skip it.\n\t\tif !fileInPathSpec {\n\t\t\treturn nil\n\t\t}\n\n\t\tgrepResults, err := findMatchInFile(file, treeName, opts)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tresults = append(results, grepResults...)\n\n\t\treturn nil\n\t})\n\n\treturn results, err\n}\n\n// findMatchInFile takes a single File, worktree name and GrepOptions,\n// and returns a slice of GrepResult containing the result of regex pattern\n// matching in the given file.\nfunc findMatchInFile(file *object.File, treeName string, opts *GrepOptions) ([]GrepResult, error) {\n\tvar grepResults []GrepResult\n\n\tcontent, err := file.Contents()\n\tif err != nil {\n\t\treturn grepResults, err\n\t}\n\n\t// Split the file content and parse line-by-line.\n\tcontentByLine := strings.Split(content, \"\\n\")\n\tfor lineNum, cnt := range contentByLine {\n\t\taddToResult := false\n\n\t\t// Match the patterns and content. Break out of the loop once a\n\t\t// match is found.\n\t\tfor _, pattern := range opts.Patterns {\n\t\t\tif pattern != nil && pattern.MatchString(cnt) {\n\t\t\t\t// Add to result only if invert match is not enabled.\n\t\t\t\tif !opts.InvertMatch {\n\t\t\t\t\taddToResult = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t} else if opts.InvertMatch {\n\t\t\t\t// If matching fails, and invert match is enabled, add to\n\t\t\t\t// results.\n\t\t\t\taddToResult = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif addToResult {\n\t\t\tgrepResults = append(grepResults, GrepResult{\n\t\t\t\tFileName:   file.Name,\n\t\t\t\tLineNumber: lineNum + 1,\n\t\t\t\tContent:    cnt,\n\t\t\t\tTreeName:   treeName,\n\t\t\t})\n\t\t}\n\t}\n\n\treturn grepResults, nil\n}\n\nfunc rmFileAndDirIfEmpty(fs billy.Filesystem, name string) error {\n\tif err := util.RemoveAll(fs, name); err != nil {\n\t\treturn err\n\t}\n\n\tdir := filepath.Dir(name)\n\treturn doCleanDirectories(fs, dir)\n}\n\n// doCleanDirectories removes empty subdirs (without files)\nfunc doCleanDirectories(fs billy.Filesystem, dir string) error {\n\tfiles, err := fs.ReadDir(dir)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif len(files) == 0 {\n\t\treturn fs.Remove(dir)\n\t}\n\treturn nil\n}\n\ntype indexBuilder struct {\n\tentries map[string]*index.Entry\n}\n\nfunc newIndexBuilder(idx *index.Index) *indexBuilder {\n\tentries := make(map[string]*index.Entry, len(idx.Entries))\n\tfor _, e := range idx.Entries {\n\t\tentries[e.Name] = e\n\t}\n\treturn &indexBuilder{\n\t\tentries: entries,\n\t}\n}\n\nfunc (b *indexBuilder) Write(idx *index.Index) {\n\tidx.Entries = idx.Entries[:0]\n\tfor _, e := range b.entries {\n\t\tidx.Entries = append(idx.Entries, e)\n\t}\n}\n\nfunc (b *indexBuilder) Add(e *index.Entry) {\n\tb.entries[e.Name] = e\n}\n\nfunc (b *indexBuilder) Remove(name string) {\n\tdelete(b.entries, filepath.ToSlash(name))\n}\n"
        },
        {
          "name": "worktree_bsd.go",
          "type": "blob",
          "size": 0.4736328125,
          "content": "// +build darwin freebsd netbsd\n\npackage git\n\nimport (\n\t\"syscall\"\n\t\"time\"\n\n\t\"gopkg.in/src-d/go-git.v4/plumbing/format/index\"\n)\n\nfunc init() {\n\tfillSystemInfo = func(e *index.Entry, sys interface{}) {\n\t\tif os, ok := sys.(*syscall.Stat_t); ok {\n\t\t\te.CreatedAt = time.Unix(int64(os.Atimespec.Sec), int64(os.Atimespec.Nsec))\n\t\t\te.Dev = uint32(os.Dev)\n\t\t\te.Inode = uint32(os.Ino)\n\t\t\te.GID = os.Gid\n\t\t\te.UID = os.Uid\n\t\t}\n\t}\n}\n\nfunc isSymlinkWindowsNonAdmin(err error) bool {\n\treturn false\n}\n"
        },
        {
          "name": "worktree_commit.go",
          "type": "blob",
          "size": 5.2353515625,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"path\"\n\t\"sort\"\n\t\"strings\"\n\n\t\"golang.org/x/crypto/openpgp\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/filemode\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/format/index\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/object\"\n\t\"gopkg.in/src-d/go-git.v4/storage\"\n\n\t\"gopkg.in/src-d/go-billy.v4\"\n)\n\n// Commit stores the current contents of the index in a new commit along with\n// a log message from the user describing the changes.\nfunc (w *Worktree) Commit(msg string, opts *CommitOptions) (plumbing.Hash, error) {\n\tif err := opts.Validate(w.r); err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\tif opts.All {\n\t\tif err := w.autoAddModifiedAndDeleted(); err != nil {\n\t\t\treturn plumbing.ZeroHash, err\n\t\t}\n\t}\n\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\th := &buildTreeHelper{\n\t\tfs: w.Filesystem,\n\t\ts:  w.r.Storer,\n\t}\n\n\ttree, err := h.BuildTree(idx)\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\tcommit, err := w.buildCommitObject(msg, opts, tree)\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\treturn commit, w.updateHEAD(commit)\n}\n\nfunc (w *Worktree) autoAddModifiedAndDeleted() error {\n\ts, err := w.Status()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor path, fs := range s {\n\t\tif fs.Worktree != Modified && fs.Worktree != Deleted {\n\t\t\tcontinue\n\t\t}\n\n\t\tif _, err := w.Add(path); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (w *Worktree) updateHEAD(commit plumbing.Hash) error {\n\thead, err := w.r.Storer.Reference(plumbing.HEAD)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tname := plumbing.HEAD\n\tif head.Type() != plumbing.HashReference {\n\t\tname = head.Target()\n\t}\n\n\tref := plumbing.NewHashReference(name, commit)\n\treturn w.r.Storer.SetReference(ref)\n}\n\nfunc (w *Worktree) buildCommitObject(msg string, opts *CommitOptions, tree plumbing.Hash) (plumbing.Hash, error) {\n\tcommit := &object.Commit{\n\t\tAuthor:       *opts.Author,\n\t\tCommitter:    *opts.Committer,\n\t\tMessage:      msg,\n\t\tTreeHash:     tree,\n\t\tParentHashes: opts.Parents,\n\t}\n\n\tif opts.SignKey != nil {\n\t\tsig, err := w.buildCommitSignature(commit, opts.SignKey)\n\t\tif err != nil {\n\t\t\treturn plumbing.ZeroHash, err\n\t\t}\n\t\tcommit.PGPSignature = sig\n\t}\n\n\tobj := w.r.Storer.NewEncodedObject()\n\tif err := commit.Encode(obj); err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\treturn w.r.Storer.SetEncodedObject(obj)\n}\n\nfunc (w *Worktree) buildCommitSignature(commit *object.Commit, signKey *openpgp.Entity) (string, error) {\n\tencoded := &plumbing.MemoryObject{}\n\tif err := commit.Encode(encoded); err != nil {\n\t\treturn \"\", err\n\t}\n\tr, err := encoded.Reader()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tvar b bytes.Buffer\n\tif err := openpgp.ArmoredDetachSign(&b, signKey, r, nil); err != nil {\n\t\treturn \"\", err\n\t}\n\treturn b.String(), nil\n}\n\n// buildTreeHelper converts a given index.Index file into multiple git objects\n// reading the blobs from the given filesystem and creating the trees from the\n// index structure. The created objects are pushed to a given Storer.\ntype buildTreeHelper struct {\n\tfs billy.Filesystem\n\ts  storage.Storer\n\n\ttrees   map[string]*object.Tree\n\tentries map[string]*object.TreeEntry\n}\n\n// BuildTree builds the tree objects and push its to the storer, the hash\n// of the root tree is returned.\nfunc (h *buildTreeHelper) BuildTree(idx *index.Index) (plumbing.Hash, error) {\n\tconst rootNode = \"\"\n\th.trees = map[string]*object.Tree{rootNode: {}}\n\th.entries = map[string]*object.TreeEntry{}\n\n\tfor _, e := range idx.Entries {\n\t\tif err := h.commitIndexEntry(e); err != nil {\n\t\t\treturn plumbing.ZeroHash, err\n\t\t}\n\t}\n\n\treturn h.copyTreeToStorageRecursive(rootNode, h.trees[rootNode])\n}\n\nfunc (h *buildTreeHelper) commitIndexEntry(e *index.Entry) error {\n\tparts := strings.Split(e.Name, \"/\")\n\n\tvar fullpath string\n\tfor _, part := range parts {\n\t\tparent := fullpath\n\t\tfullpath = path.Join(fullpath, part)\n\n\t\th.doBuildTree(e, parent, fullpath)\n\t}\n\n\treturn nil\n}\n\nfunc (h *buildTreeHelper) doBuildTree(e *index.Entry, parent, fullpath string) {\n\tif _, ok := h.trees[fullpath]; ok {\n\t\treturn\n\t}\n\n\tif _, ok := h.entries[fullpath]; ok {\n\t\treturn\n\t}\n\n\tte := object.TreeEntry{Name: path.Base(fullpath)}\n\n\tif fullpath == e.Name {\n\t\tte.Mode = e.Mode\n\t\tte.Hash = e.Hash\n\t} else {\n\t\tte.Mode = filemode.Dir\n\t\th.trees[fullpath] = &object.Tree{}\n\t}\n\n\th.trees[parent].Entries = append(h.trees[parent].Entries, te)\n}\n\ntype sortableEntries []object.TreeEntry\n\nfunc (sortableEntries) sortName(te object.TreeEntry) string {\n\tif te.Mode == filemode.Dir {\n\t\treturn te.Name + \"/\"\n\t}\n\treturn te.Name\n}\nfunc (se sortableEntries) Len() int               { return len(se) }\nfunc (se sortableEntries) Less(i int, j int) bool { return se.sortName(se[i]) < se.sortName(se[j]) }\nfunc (se sortableEntries) Swap(i int, j int)      { se[i], se[j] = se[j], se[i] }\n\nfunc (h *buildTreeHelper) copyTreeToStorageRecursive(parent string, t *object.Tree) (plumbing.Hash, error) {\n\tsort.Sort(sortableEntries(t.Entries))\n\tfor i, e := range t.Entries {\n\t\tif e.Mode != filemode.Dir && !e.Hash.IsZero() {\n\t\t\tcontinue\n\t\t}\n\n\t\tpath := path.Join(parent, e.Name)\n\n\t\tvar err error\n\t\te.Hash, err = h.copyTreeToStorageRecursive(path, h.trees[path])\n\t\tif err != nil {\n\t\t\treturn plumbing.ZeroHash, err\n\t\t}\n\n\t\tt.Entries[i] = e\n\t}\n\n\to := h.s.NewEncodedObject()\n\tif err := t.Encode(o); err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\treturn h.s.SetEncodedObject(o)\n}\n"
        },
        {
          "name": "worktree_commit_test.go",
          "type": "blob",
          "size": 10.53125,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"os/exec\"\n\t\"strings\"\n\t\"time\"\n\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/cache\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/object\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/storer\"\n\t\"gopkg.in/src-d/go-git.v4/storage/filesystem\"\n\t\"gopkg.in/src-d/go-git.v4/storage/memory\"\n\n\t\"golang.org/x/crypto/openpgp\"\n\t\"golang.org/x/crypto/openpgp/armor\"\n\t\"golang.org/x/crypto/openpgp/errors\"\n\t. \"gopkg.in/check.v1\"\n\t\"gopkg.in/src-d/go-billy.v4/memfs\"\n\t\"gopkg.in/src-d/go-billy.v4/osfs\"\n\t\"gopkg.in/src-d/go-billy.v4/util\"\n)\n\nfunc (s *WorktreeSuite) TestCommitInvalidOptions(c *C) {\n\tr, err := Init(memory.NewStorage(), memfs.New())\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Commit(\"\", &CommitOptions{})\n\tc.Assert(err, Equals, ErrMissingAuthor)\n\tc.Assert(hash.IsZero(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestCommitInitial(c *C) {\n\texpected := plumbing.NewHash(\"98c4ac7c29c913f7461eae06e024dc18e80d23a4\")\n\n\tfs := memfs.New()\n\tstorage := memory.NewStorage()\n\n\tr, err := Init(storage, fs)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tutil.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\n\t_, err = w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Commit(\"foo\\n\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(hash, Equals, expected)\n\tc.Assert(err, IsNil)\n\n\tassertStorageStatus(c, r, 1, 1, 1, expected)\n}\n\nfunc (s *WorktreeSuite) TestCommitParent(c *C) {\n\texpected := plumbing.NewHash(\"ef3ca05477530b37f48564be33ddd48063fc7a22\")\n\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tutil.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\n\t_, err = w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Commit(\"foo\\n\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(hash, Equals, expected)\n\tc.Assert(err, IsNil)\n\n\tassertStorageStatus(c, s.Repository, 13, 11, 10, expected)\n}\n\nfunc (s *WorktreeSuite) TestCommitAll(c *C) {\n\texpected := plumbing.NewHash(\"aede6f8c9c1c7ec9ca8d287c64b8ed151276fa28\")\n\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tutil.WriteFile(fs, \"LICENSE\", []byte(\"foo\"), 0644)\n\tutil.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\n\thash, err := w.Commit(\"foo\\n\", &CommitOptions{\n\t\tAll:    true,\n\t\tAuthor: defaultSignature(),\n\t})\n\n\tc.Assert(hash, Equals, expected)\n\tc.Assert(err, IsNil)\n\n\tassertStorageStatus(c, s.Repository, 13, 11, 10, expected)\n}\n\nfunc (s *WorktreeSuite) TestRemoveAndCommitAll(c *C) {\n\texpected := plumbing.NewHash(\"907cd576c6ced2ecd3dab34a72bf9cf65944b9a9\")\n\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tutil.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\t_, err = w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\n\t_, errFirst := w.Commit(\"Add in Repo\\n\", &CommitOptions{\n\t\tAuthor: defaultSignature(),\n\t})\n\tc.Assert(errFirst, IsNil)\n\n\terrRemove := fs.Remove(\"foo\")\n\tc.Assert(errRemove, IsNil)\n\n\thash, errSecond := w.Commit(\"Remove foo\\n\", &CommitOptions{\n\t\tAll:    true,\n\t\tAuthor: defaultSignature(),\n\t})\n\tc.Assert(errSecond, IsNil)\n\n\tc.Assert(hash, Equals, expected)\n\tc.Assert(err, IsNil)\n\n\tassertStorageStatus(c, s.Repository, 13, 11, 11, expected)\n}\n\nfunc (s *WorktreeSuite) TestCommitSign(c *C) {\n\tfs := memfs.New()\n\tstorage := memory.NewStorage()\n\n\tr, err := Init(storage, fs)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tutil.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\n\t_, err = w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\n\tkey := commitSignKey(c, true)\n\thash, err := w.Commit(\"foo\\n\", &CommitOptions{Author: defaultSignature(), SignKey: key})\n\tc.Assert(err, IsNil)\n\n\t// Verify the commit.\n\tpks := new(bytes.Buffer)\n\tpkw, err := armor.Encode(pks, openpgp.PublicKeyType, nil)\n\tc.Assert(err, IsNil)\n\n\terr = key.Serialize(pkw)\n\tc.Assert(err, IsNil)\n\terr = pkw.Close()\n\tc.Assert(err, IsNil)\n\n\texpectedCommit, err := r.CommitObject(hash)\n\tc.Assert(err, IsNil)\n\tactual, err := expectedCommit.Verify(pks.String())\n\tc.Assert(err, IsNil)\n\tc.Assert(actual.PrimaryKey, DeepEquals, key.PrimaryKey)\n}\n\nfunc (s *WorktreeSuite) TestCommitSignBadKey(c *C) {\n\tfs := memfs.New()\n\tstorage := memory.NewStorage()\n\n\tr, err := Init(storage, fs)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tutil.WriteFile(fs, \"foo\", []byte(\"foo\"), 0644)\n\n\t_, err = w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\n\tkey := commitSignKey(c, false)\n\t_, err = w.Commit(\"foo\\n\", &CommitOptions{Author: defaultSignature(), SignKey: key})\n\tc.Assert(err, Equals, errors.InvalidArgumentError(\"signing key is encrypted\"))\n}\n\nfunc (s *WorktreeSuite) TestCommitTreeSort(c *C) {\n\tpath, err := ioutil.TempDir(os.TempDir(), \"test-commit-tree-sort\")\n\tc.Assert(err, IsNil)\n\tfs := osfs.New(path)\n\tst := filesystem.NewStorage(fs, cache.NewObjectLRUDefault())\n\tr, err := Init(st, nil)\n\tc.Assert(err, IsNil)\n\n\tr, _ = Clone(memory.NewStorage(), memfs.New(), &CloneOptions{\n\t\tURL: path,\n\t})\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tmfs := w.Filesystem\n\n\terr = mfs.MkdirAll(\"delta\", 0755)\n\tc.Assert(err, IsNil)\n\n\tfor _, p := range []string{\"delta_last\", \"Gamma\", \"delta/middle\", \"Beta\", \"delta-first\", \"alpha\"} {\n\t\tutil.WriteFile(mfs, p, []byte(\"foo\"), 0644)\n\t\t_, err = w.Add(p)\n\t\tc.Assert(err, IsNil)\n\t}\n\n\t_, err = w.Commit(\"foo\\n\", &CommitOptions{\n\t\tAll:    true,\n\t\tAuthor: defaultSignature(),\n\t})\n\tc.Assert(err, IsNil)\n\n\terr = r.Push(&PushOptions{})\n\tc.Assert(err, IsNil)\n\n\tcmd := exec.Command(\"git\", \"fsck\")\n\tcmd.Dir = path\n\tcmd.Env = os.Environ()\n\tbuf := &bytes.Buffer{}\n\tcmd.Stderr = buf\n\tcmd.Stdout = buf\n\n\terr = cmd.Run()\n\n\tc.Assert(err, IsNil, Commentf(\"%s\", buf.Bytes()))\n}\n\nfunc assertStorageStatus(\n\tc *C, r *Repository,\n\ttreesCount, blobCount, commitCount int, head plumbing.Hash,\n) {\n\ttrees, err := r.Storer.IterEncodedObjects(plumbing.TreeObject)\n\tc.Assert(err, IsNil)\n\tblobs, err := r.Storer.IterEncodedObjects(plumbing.BlobObject)\n\tc.Assert(err, IsNil)\n\tcommits, err := r.Storer.IterEncodedObjects(plumbing.CommitObject)\n\tc.Assert(err, IsNil)\n\n\tc.Assert(lenIterEncodedObjects(trees), Equals, treesCount)\n\tc.Assert(lenIterEncodedObjects(blobs), Equals, blobCount)\n\tc.Assert(lenIterEncodedObjects(commits), Equals, commitCount)\n\n\tref, err := r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(ref.Hash(), Equals, head)\n}\n\nfunc lenIterEncodedObjects(iter storer.EncodedObjectIter) int {\n\tcount := 0\n\titer.ForEach(func(plumbing.EncodedObject) error {\n\t\tcount++\n\t\treturn nil\n\t})\n\n\treturn count\n}\n\nfunc defaultSignature() *object.Signature {\n\twhen, _ := time.Parse(object.DateFormat, \"Thu May 04 00:03:43 2017 +0200\")\n\treturn &object.Signature{\n\t\tName:  \"foo\",\n\t\tEmail: \"foo@foo.foo\",\n\t\tWhen:  when,\n\t}\n}\n\nfunc commitSignKey(c *C, decrypt bool) *openpgp.Entity {\n\ts := strings.NewReader(armoredKeyRing)\n\tes, err := openpgp.ReadArmoredKeyRing(s)\n\tc.Assert(err, IsNil)\n\n\tc.Assert(es, HasLen, 1)\n\tc.Assert(es[0].Identities, HasLen, 1)\n\t_, ok := es[0].Identities[\"foo bar <foo@foo.foo>\"]\n\tc.Assert(ok, Equals, true)\n\n\tkey := es[0]\n\tif decrypt {\n\t\terr = key.PrivateKey.Decrypt([]byte(keyPassphrase))\n\t\tc.Assert(err, IsNil)\n\t}\n\n\treturn key\n}\n\nconst armoredKeyRing = `\n-----BEGIN PGP PRIVATE KEY BLOCK-----\n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\nCgLH6twOqdSFWqB/4ASDMsNeLeKX3WOYKYYMlE01cj3T1m6dpRUO\n=gIM9\n-----END PGP PRIVATE KEY BLOCK-----\n`\n\nconst keyPassphrase = \"abcdef0123456789\"\n"
        },
        {
          "name": "worktree_linux.go",
          "type": "blob",
          "size": 0.4482421875,
          "content": "// +build linux\n\npackage git\n\nimport (\n\t\"syscall\"\n\t\"time\"\n\n\t\"gopkg.in/src-d/go-git.v4/plumbing/format/index\"\n)\n\nfunc init() {\n\tfillSystemInfo = func(e *index.Entry, sys interface{}) {\n\t\tif os, ok := sys.(*syscall.Stat_t); ok {\n\t\t\te.CreatedAt = time.Unix(int64(os.Ctim.Sec), int64(os.Ctim.Nsec))\n\t\t\te.Dev = uint32(os.Dev)\n\t\t\te.Inode = uint32(os.Ino)\n\t\t\te.GID = os.Gid\n\t\t\te.UID = os.Uid\n\t\t}\n\t}\n}\n\nfunc isSymlinkWindowsNonAdmin(err error) bool {\n\treturn false\n}\n"
        },
        {
          "name": "worktree_status.go",
          "type": "blob",
          "size": 13.9345703125,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"io\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\n\t\"gopkg.in/src-d/go-billy.v4/util\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/filemode\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/format/gitignore\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/format/index\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/object\"\n\t\"gopkg.in/src-d/go-git.v4/utils/ioutil\"\n\t\"gopkg.in/src-d/go-git.v4/utils/merkletrie\"\n\t\"gopkg.in/src-d/go-git.v4/utils/merkletrie/filesystem\"\n\tmindex \"gopkg.in/src-d/go-git.v4/utils/merkletrie/index\"\n\t\"gopkg.in/src-d/go-git.v4/utils/merkletrie/noder\"\n)\n\nvar (\n\t// ErrDestinationExists in an Move operation means that the target exists on\n\t// the worktree.\n\tErrDestinationExists = errors.New(\"destination exists\")\n\t// ErrGlobNoMatches in an AddGlob if the glob pattern does not match any\n\t// files in the worktree.\n\tErrGlobNoMatches = errors.New(\"glob pattern did not match any files\")\n)\n\n// Status returns the working tree status.\nfunc (w *Worktree) Status() (Status, error) {\n\tvar hash plumbing.Hash\n\n\tref, err := w.r.Head()\n\tif err != nil && err != plumbing.ErrReferenceNotFound {\n\t\treturn nil, err\n\t}\n\n\tif err == nil {\n\t\thash = ref.Hash()\n\t}\n\n\treturn w.status(hash)\n}\n\nfunc (w *Worktree) status(commit plumbing.Hash) (Status, error) {\n\ts := make(Status)\n\n\tleft, err := w.diffCommitWithStaging(commit, false)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, ch := range left {\n\t\ta, err := ch.Action()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tfs := s.File(nameFromAction(&ch))\n\t\tfs.Worktree = Unmodified\n\n\t\tswitch a {\n\t\tcase merkletrie.Delete:\n\t\t\ts.File(ch.From.String()).Staging = Deleted\n\t\tcase merkletrie.Insert:\n\t\t\ts.File(ch.To.String()).Staging = Added\n\t\tcase merkletrie.Modify:\n\t\t\ts.File(ch.To.String()).Staging = Modified\n\t\t}\n\t}\n\n\tright, err := w.diffStagingWithWorktree(false)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, ch := range right {\n\t\ta, err := ch.Action()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tfs := s.File(nameFromAction(&ch))\n\t\tif fs.Staging == Untracked {\n\t\t\tfs.Staging = Unmodified\n\t\t}\n\n\t\tswitch a {\n\t\tcase merkletrie.Delete:\n\t\t\tfs.Worktree = Deleted\n\t\tcase merkletrie.Insert:\n\t\t\tfs.Worktree = Untracked\n\t\t\tfs.Staging = Untracked\n\t\tcase merkletrie.Modify:\n\t\t\tfs.Worktree = Modified\n\t\t}\n\t}\n\n\treturn s, nil\n}\n\nfunc nameFromAction(ch *merkletrie.Change) string {\n\tname := ch.To.String()\n\tif name == \"\" {\n\t\treturn ch.From.String()\n\t}\n\n\treturn name\n}\n\nfunc (w *Worktree) diffStagingWithWorktree(reverse bool) (merkletrie.Changes, error) {\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfrom := mindex.NewRootNode(idx)\n\tsubmodules, err := w.getSubmodulesStatus()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tto := filesystem.NewRootNode(w.Filesystem, submodules)\n\n\tvar c merkletrie.Changes\n\tif reverse {\n\t\tc, err = merkletrie.DiffTree(to, from, diffTreeIsEquals)\n\t} else {\n\t\tc, err = merkletrie.DiffTree(from, to, diffTreeIsEquals)\n\t}\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn w.excludeIgnoredChanges(c), nil\n}\n\nfunc (w *Worktree) excludeIgnoredChanges(changes merkletrie.Changes) merkletrie.Changes {\n\tpatterns, err := gitignore.ReadPatterns(w.Filesystem, nil)\n\tif err != nil {\n\t\treturn changes\n\t}\n\n\tpatterns = append(patterns, w.Excludes...)\n\n\tif len(patterns) == 0 {\n\t\treturn changes\n\t}\n\n\tm := gitignore.NewMatcher(patterns)\n\n\tvar res merkletrie.Changes\n\tfor _, ch := range changes {\n\t\tvar path []string\n\t\tfor _, n := range ch.To {\n\t\t\tpath = append(path, n.Name())\n\t\t}\n\t\tif len(path) == 0 {\n\t\t\tfor _, n := range ch.From {\n\t\t\t\tpath = append(path, n.Name())\n\t\t\t}\n\t\t}\n\t\tif len(path) != 0 {\n\t\t\tisDir := (len(ch.To) > 0 && ch.To.IsDir()) || (len(ch.From) > 0 && ch.From.IsDir())\n\t\t\tif m.Match(path, isDir) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\tres = append(res, ch)\n\t}\n\treturn res\n}\n\nfunc (w *Worktree) getSubmodulesStatus() (map[string]plumbing.Hash, error) {\n\to := map[string]plumbing.Hash{}\n\n\tsub, err := w.Submodules()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tstatus, err := sub.Status()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, s := range status {\n\t\tif s.Current.IsZero() {\n\t\t\to[s.Path] = s.Expected\n\t\t\tcontinue\n\t\t}\n\n\t\to[s.Path] = s.Current\n\t}\n\n\treturn o, nil\n}\n\nfunc (w *Worktree) diffCommitWithStaging(commit plumbing.Hash, reverse bool) (merkletrie.Changes, error) {\n\tvar t *object.Tree\n\tif !commit.IsZero() {\n\t\tc, err := w.r.CommitObject(commit)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tt, err = c.Tree()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn w.diffTreeWithStaging(t, reverse)\n}\n\nfunc (w *Worktree) diffTreeWithStaging(t *object.Tree, reverse bool) (merkletrie.Changes, error) {\n\tvar from noder.Noder\n\tif t != nil {\n\t\tfrom = object.NewTreeRootNode(t)\n\t}\n\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tto := mindex.NewRootNode(idx)\n\n\tif reverse {\n\t\treturn merkletrie.DiffTree(to, from, diffTreeIsEquals)\n\t}\n\n\treturn merkletrie.DiffTree(from, to, diffTreeIsEquals)\n}\n\nvar emptyNoderHash = make([]byte, 24)\n\n// diffTreeIsEquals is a implementation of noder.Equals, used to compare\n// noder.Noder, it compare the content and the length of the hashes.\n//\n// Since some of the noder.Noder implementations doesn't compute a hash for\n// some directories, if any of the hashes is a 24-byte slice of zero values\n// the comparison is not done and the hashes are take as different.\nfunc diffTreeIsEquals(a, b noder.Hasher) bool {\n\thashA := a.Hash()\n\thashB := b.Hash()\n\n\tif bytes.Equal(hashA, emptyNoderHash) || bytes.Equal(hashB, emptyNoderHash) {\n\t\treturn false\n\t}\n\n\treturn bytes.Equal(hashA, hashB)\n}\n\n// Add adds the file contents of a file in the worktree to the index. if the\n// file is already staged in the index no error is returned. If a file deleted\n// from the Workspace is given, the file is removed from the index. If a\n// directory given, adds the files and all his sub-directories recursively in\n// the worktree to the index. If any of the files is already staged in the index\n// no error is returned. When path is a file, the blob.Hash is returned.\nfunc (w *Worktree) Add(path string) (plumbing.Hash, error) {\n\t// TODO(mcuadros): remove plumbing.Hash from signature at v5.\n\ts, err := w.Status()\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\tvar h plumbing.Hash\n\tvar added bool\n\n\tfi, err := w.Filesystem.Lstat(path)\n\tif err != nil || !fi.IsDir() {\n\t\tadded, h, err = w.doAddFile(idx, s, path)\n\t} else {\n\t\tadded, err = w.doAddDirectory(idx, s, path)\n\t}\n\n\tif err != nil {\n\t\treturn h, err\n\t}\n\n\tif !added {\n\t\treturn h, nil\n\t}\n\n\treturn h, w.r.Storer.SetIndex(idx)\n}\n\nfunc (w *Worktree) doAddDirectory(idx *index.Index, s Status, directory string) (added bool, err error) {\n\tfiles, err := w.Filesystem.ReadDir(directory)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tfor _, file := range files {\n\t\tname := path.Join(directory, file.Name())\n\n\t\tvar a bool\n\t\tif file.IsDir() {\n\t\t\tif file.Name() == GitDirName {\n\t\t\t\t// ignore special git directory\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\ta, err = w.doAddDirectory(idx, s, name)\n\t\t} else {\n\t\t\ta, _, err = w.doAddFile(idx, s, name)\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\n\t\tif !added && a {\n\t\t\tadded = true\n\t\t}\n\t}\n\n\treturn\n}\n\n// AddGlob adds all paths, matching pattern, to the index. If pattern matches a\n// directory path, all directory contents are added to the index recursively. No\n// error is returned if all matching paths are already staged in index.\nfunc (w *Worktree) AddGlob(pattern string) error {\n\tfiles, err := util.Glob(w.Filesystem, pattern)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif len(files) == 0 {\n\t\treturn ErrGlobNoMatches\n\t}\n\n\ts, err := w.Status()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvar saveIndex bool\n\tfor _, file := range files {\n\t\tfi, err := w.Filesystem.Lstat(file)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tvar added bool\n\t\tif fi.IsDir() {\n\t\t\tadded, err = w.doAddDirectory(idx, s, file)\n\t\t} else {\n\t\t\tadded, _, err = w.doAddFile(idx, s, file)\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif !saveIndex && added {\n\t\t\tsaveIndex = true\n\t\t}\n\t}\n\n\tif saveIndex {\n\t\treturn w.r.Storer.SetIndex(idx)\n\t}\n\n\treturn nil\n}\n\n// doAddFile create a new blob from path and update the index, added is true if\n// the file added is different from the index.\nfunc (w *Worktree) doAddFile(idx *index.Index, s Status, path string) (added bool, h plumbing.Hash, err error) {\n\tif s.File(path).Worktree == Unmodified {\n\t\treturn false, h, nil\n\t}\n\n\th, err = w.copyFileToStorage(path)\n\tif err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\tadded = true\n\t\t\th, err = w.deleteFromIndex(idx, path)\n\t\t}\n\n\t\treturn\n\t}\n\n\tif err := w.addOrUpdateFileToIndex(idx, path, h); err != nil {\n\t\treturn false, h, err\n\t}\n\n\treturn true, h, err\n}\n\nfunc (w *Worktree) copyFileToStorage(path string) (hash plumbing.Hash, err error) {\n\tfi, err := w.Filesystem.Lstat(path)\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\tobj := w.r.Storer.NewEncodedObject()\n\tobj.SetType(plumbing.BlobObject)\n\tobj.SetSize(fi.Size())\n\n\twriter, err := obj.Writer()\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\tdefer ioutil.CheckClose(writer, &err)\n\n\tif fi.Mode()&os.ModeSymlink != 0 {\n\t\terr = w.fillEncodedObjectFromSymlink(writer, path, fi)\n\t} else {\n\t\terr = w.fillEncodedObjectFromFile(writer, path, fi)\n\t}\n\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\treturn w.r.Storer.SetEncodedObject(obj)\n}\n\nfunc (w *Worktree) fillEncodedObjectFromFile(dst io.Writer, path string, fi os.FileInfo) (err error) {\n\tsrc, err := w.Filesystem.Open(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdefer ioutil.CheckClose(src, &err)\n\n\tif _, err := io.Copy(dst, src); err != nil {\n\t\treturn err\n\t}\n\n\treturn err\n}\n\nfunc (w *Worktree) fillEncodedObjectFromSymlink(dst io.Writer, path string, fi os.FileInfo) error {\n\ttarget, err := w.Filesystem.Readlink(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t_, err = dst.Write([]byte(target))\n\treturn err\n}\n\nfunc (w *Worktree) addOrUpdateFileToIndex(idx *index.Index, filename string, h plumbing.Hash) error {\n\te, err := idx.Entry(filename)\n\tif err != nil && err != index.ErrEntryNotFound {\n\t\treturn err\n\t}\n\n\tif err == index.ErrEntryNotFound {\n\t\treturn w.doAddFileToIndex(idx, filename, h)\n\t}\n\n\treturn w.doUpdateFileToIndex(e, filename, h)\n}\n\nfunc (w *Worktree) doAddFileToIndex(idx *index.Index, filename string, h plumbing.Hash) error {\n\treturn w.doUpdateFileToIndex(idx.Add(filename), filename, h)\n}\n\nfunc (w *Worktree) doUpdateFileToIndex(e *index.Entry, filename string, h plumbing.Hash) error {\n\tinfo, err := w.Filesystem.Lstat(filename)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\te.Hash = h\n\te.ModifiedAt = info.ModTime()\n\te.Mode, err = filemode.NewFromOSFileMode(info.Mode())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif e.Mode.IsRegular() {\n\t\te.Size = uint32(info.Size())\n\t}\n\n\tfillSystemInfo(e, info.Sys())\n\treturn nil\n}\n\n// Remove removes files from the working tree and from the index.\nfunc (w *Worktree) Remove(path string) (plumbing.Hash, error) {\n\t// TODO(mcuadros): remove plumbing.Hash from signature at v5.\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\tvar h plumbing.Hash\n\n\tfi, err := w.Filesystem.Lstat(path)\n\tif err != nil || !fi.IsDir() {\n\t\th, err = w.doRemoveFile(idx, path)\n\t} else {\n\t\t_, err = w.doRemoveDirectory(idx, path)\n\t}\n\tif err != nil {\n\t\treturn h, err\n\t}\n\n\treturn h, w.r.Storer.SetIndex(idx)\n}\n\nfunc (w *Worktree) doRemoveDirectory(idx *index.Index, directory string) (removed bool, err error) {\n\tfiles, err := w.Filesystem.ReadDir(directory)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tfor _, file := range files {\n\t\tname := path.Join(directory, file.Name())\n\n\t\tvar r bool\n\t\tif file.IsDir() {\n\t\t\tr, err = w.doRemoveDirectory(idx, name)\n\t\t} else {\n\t\t\t_, err = w.doRemoveFile(idx, name)\n\t\t\tif err == index.ErrEntryNotFound {\n\t\t\t\terr = nil\n\t\t\t}\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\n\t\tif !removed && r {\n\t\t\tremoved = true\n\t\t}\n\t}\n\n\terr = w.removeEmptyDirectory(directory)\n\treturn\n}\n\nfunc (w *Worktree) removeEmptyDirectory(path string) error {\n\tfiles, err := w.Filesystem.ReadDir(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif len(files) != 0 {\n\t\treturn nil\n\t}\n\n\treturn w.Filesystem.Remove(path)\n}\n\nfunc (w *Worktree) doRemoveFile(idx *index.Index, path string) (plumbing.Hash, error) {\n\thash, err := w.deleteFromIndex(idx, path)\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\treturn hash, w.deleteFromFilesystem(path)\n}\n\nfunc (w *Worktree) deleteFromIndex(idx *index.Index, path string) (plumbing.Hash, error) {\n\te, err := idx.Remove(path)\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\treturn e.Hash, nil\n}\n\nfunc (w *Worktree) deleteFromFilesystem(path string) error {\n\terr := w.Filesystem.Remove(path)\n\tif os.IsNotExist(err) {\n\t\treturn nil\n\t}\n\n\treturn err\n}\n\n// RemoveGlob removes all paths, matching pattern, from the index. If pattern\n// matches a directory path, all directory contents are removed from the index\n// recursively.\nfunc (w *Worktree) RemoveGlob(pattern string) error {\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tentries, err := idx.Glob(pattern)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, e := range entries {\n\t\tfile := filepath.FromSlash(e.Name)\n\t\tif _, err := w.Filesystem.Lstat(file); err != nil && !os.IsNotExist(err) {\n\t\t\treturn err\n\t\t}\n\n\t\tif _, err := w.doRemoveFile(idx, file); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tdir, _ := filepath.Split(file)\n\t\tif err := w.removeEmptyDirectory(dir); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn w.r.Storer.SetIndex(idx)\n}\n\n// Move moves or rename a file in the worktree and the index, directories are\n// not supported.\nfunc (w *Worktree) Move(from, to string) (plumbing.Hash, error) {\n\t// TODO(mcuadros): support directories and/or implement support for glob\n\tif _, err := w.Filesystem.Lstat(from); err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\tif _, err := w.Filesystem.Lstat(to); err == nil {\n\t\treturn plumbing.ZeroHash, ErrDestinationExists\n\t}\n\n\tidx, err := w.r.Storer.Index()\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\thash, err := w.deleteFromIndex(idx, from)\n\tif err != nil {\n\t\treturn plumbing.ZeroHash, err\n\t}\n\n\tif err := w.Filesystem.Rename(from, to); err != nil {\n\t\treturn hash, err\n\t}\n\n\tif err := w.addOrUpdateFileToIndex(idx, to, hash); err != nil {\n\t\treturn hash, err\n\t}\n\n\treturn hash, w.r.Storer.SetIndex(idx)\n}\n"
        },
        {
          "name": "worktree_test.go",
          "type": "blob",
          "size": 48,
          "content": "package git\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"errors\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"runtime\"\n\t\"testing\"\n\t\"time\"\n\n\t\"gopkg.in/src-d/go-git.v4/config\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/filemode\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/format/gitignore\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/format/index\"\n\t\"gopkg.in/src-d/go-git.v4/plumbing/object\"\n\t\"gopkg.in/src-d/go-git.v4/storage/memory\"\n\n\t\"golang.org/x/text/unicode/norm\"\n\t. \"gopkg.in/check.v1\"\n\t\"gopkg.in/src-d/go-billy.v4/memfs\"\n\t\"gopkg.in/src-d/go-billy.v4/osfs\"\n\t\"gopkg.in/src-d/go-billy.v4/util\"\n\t\"gopkg.in/src-d/go-git-fixtures.v3\"\n)\n\ntype WorktreeSuite struct {\n\tBaseSuite\n}\n\nvar _ = Suite(&WorktreeSuite{})\n\nfunc (s *WorktreeSuite) SetUpTest(c *C) {\n\tf := fixtures.Basic().One()\n\ts.Repository = s.NewRepositoryWithEmptyWorktree(f)\n}\n\nfunc (s *WorktreeSuite) TestPullCheckout(c *C) {\n\tfs := memfs.New()\n\tr, _ := Init(memory.NewStorage(), fs)\n\tr.CreateRemote(&config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\terr = w.Pull(&PullOptions{})\n\tc.Assert(err, IsNil)\n\n\tfi, err := fs.ReadDir(\"\")\n\tc.Assert(err, IsNil)\n\tc.Assert(fi, HasLen, 8)\n}\n\nfunc (s *WorktreeSuite) TestPullFastForward(c *C) {\n\turl := c.MkDir()\n\tpath := fixtures.Basic().ByTag(\"worktree\").One().Worktree().Root()\n\n\tserver, err := PlainClone(url, false, &CloneOptions{\n\t\tURL: path,\n\t})\n\tc.Assert(err, IsNil)\n\n\tr, err := PlainClone(c.MkDir(), false, &CloneOptions{\n\t\tURL: url,\n\t})\n\tc.Assert(err, IsNil)\n\n\tw, err := server.Worktree()\n\tc.Assert(err, IsNil)\n\terr = ioutil.WriteFile(filepath.Join(path, \"foo\"), []byte(\"foo\"), 0755)\n\tc.Assert(err, IsNil)\n\thash, err := w.Commit(\"foo\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(err, IsNil)\n\n\tw, err = r.Worktree()\n\tc.Assert(err, IsNil)\n\n\terr = w.Pull(&PullOptions{})\n\tc.Assert(err, IsNil)\n\n\thead, err := r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Hash(), Equals, hash)\n}\n\nfunc (s *WorktreeSuite) TestPullNonFastForward(c *C) {\n\turl := c.MkDir()\n\tpath := fixtures.Basic().ByTag(\"worktree\").One().Worktree().Root()\n\n\tserver, err := PlainClone(url, false, &CloneOptions{\n\t\tURL: path,\n\t})\n\tc.Assert(err, IsNil)\n\n\tr, err := PlainClone(c.MkDir(), false, &CloneOptions{\n\t\tURL: url,\n\t})\n\tc.Assert(err, IsNil)\n\n\tw, err := server.Worktree()\n\tc.Assert(err, IsNil)\n\terr = ioutil.WriteFile(filepath.Join(path, \"foo\"), []byte(\"foo\"), 0755)\n\tc.Assert(err, IsNil)\n\t_, err = w.Commit(\"foo\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(err, IsNil)\n\n\tw, err = r.Worktree()\n\tc.Assert(err, IsNil)\n\terr = ioutil.WriteFile(filepath.Join(path, \"bar\"), []byte(\"bar\"), 0755)\n\tc.Assert(err, IsNil)\n\t_, err = w.Commit(\"bar\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(err, IsNil)\n\n\terr = w.Pull(&PullOptions{})\n\tc.Assert(err, Equals, ErrNonFastForwardUpdate)\n}\n\nfunc (s *WorktreeSuite) TestPullUpdateReferencesIfNeeded(c *C) {\n\tr, _ := Init(memory.NewStorage(), memfs.New())\n\tr.CreateRemote(&config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\n\terr := r.Fetch(&FetchOptions{})\n\tc.Assert(err, IsNil)\n\n\t_, err = r.Reference(\"refs/heads/master\", false)\n\tc.Assert(err, NotNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\terr = w.Pull(&PullOptions{})\n\tc.Assert(err, IsNil)\n\n\thead, err := r.Reference(plumbing.HEAD, true)\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\tbranch, err := r.Reference(\"refs/heads/master\", false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\terr = w.Pull(&PullOptions{})\n\tc.Assert(err, Equals, NoErrAlreadyUpToDate)\n}\n\nfunc (s *WorktreeSuite) TestPullInSingleBranch(c *C) {\n\tr, _ := Init(memory.NewStorage(), memfs.New())\n\terr := r.clone(context.Background(), &CloneOptions{\n\t\tURL:          s.GetBasicLocalRepositoryURL(),\n\t\tSingleBranch: true,\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\terr = w.Pull(&PullOptions{})\n\tc.Assert(err, Equals, NoErrAlreadyUpToDate)\n\n\tbranch, err := r.Reference(\"refs/heads/master\", false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\tbranch, err = r.Reference(\"refs/remotes/foo/branch\", false)\n\tc.Assert(err, NotNil)\n\n\tstorage := r.Storer.(*memory.Storage)\n\tc.Assert(storage.Objects, HasLen, 28)\n}\n\nfunc (s *WorktreeSuite) TestPullProgress(c *C) {\n\tr, _ := Init(memory.NewStorage(), memfs.New())\n\n\tr.CreateRemote(&config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{s.GetBasicLocalRepositoryURL()},\n\t})\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tbuf := bytes.NewBuffer(nil)\n\terr = w.Pull(&PullOptions{\n\t\tProgress: buf,\n\t})\n\n\tc.Assert(err, IsNil)\n\tc.Assert(buf.Len(), Not(Equals), 0)\n}\n\nfunc (s *WorktreeSuite) TestPullProgressWithRecursion(c *C) {\n\tif testing.Short() {\n\t\tc.Skip(\"skipping test in short mode.\")\n\t}\n\n\tpath := fixtures.ByTag(\"submodule\").One().Worktree().Root()\n\n\tdir, err := ioutil.TempDir(\"\", \"plain-clone-submodule\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(dir)\n\n\tr, _ := PlainInit(dir, false)\n\tr.CreateRemote(&config.RemoteConfig{\n\t\tName: DefaultRemoteName,\n\t\tURLs: []string{path},\n\t})\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\terr = w.Pull(&PullOptions{\n\t\tRecurseSubmodules: DefaultSubmoduleRecursionDepth,\n\t})\n\tc.Assert(err, IsNil)\n\n\tcfg, err := r.Config()\n\tc.Assert(err, IsNil)\n\tc.Assert(cfg.Submodules, HasLen, 2)\n}\n\nfunc (s *RepositorySuite) TestPullAdd(c *C) {\n\tpath := fixtures.Basic().ByTag(\"worktree\").One().Worktree().Root()\n\n\tr, err := Clone(memory.NewStorage(), memfs.New(), &CloneOptions{\n\t\tURL: filepath.Join(path, \".git\"),\n\t})\n\n\tc.Assert(err, IsNil)\n\n\tstorage := r.Storer.(*memory.Storage)\n\tc.Assert(storage.Objects, HasLen, 28)\n\n\tbranch, err := r.Reference(\"refs/heads/master\", false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash().String(), Equals, \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n\n\tExecuteOnPath(c, path,\n\t\t\"touch foo\",\n\t\t\"git add foo\",\n\t\t\"git commit -m foo foo\",\n\t)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\terr = w.Pull(&PullOptions{RemoteName: \"origin\"})\n\tc.Assert(err, IsNil)\n\n\t// the commit command has introduced a new commit, tree and blob\n\tc.Assert(storage.Objects, HasLen, 31)\n\n\tbranch, err = r.Reference(\"refs/heads/master\", false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash().String(), Not(Equals), \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\")\n}\n\nfunc (s *WorktreeSuite) TestCheckout(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{\n\t\tForce: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tentries, err := fs.ReadDir(\"/\")\n\tc.Assert(err, IsNil)\n\n\tc.Assert(entries, HasLen, 8)\n\tch, err := fs.Open(\"CHANGELOG\")\n\tc.Assert(err, IsNil)\n\n\tcontent, err := ioutil.ReadAll(ch)\n\tc.Assert(err, IsNil)\n\tc.Assert(string(content), Equals, \"Initial changelog\\n\")\n\n\tidx, err := s.Repository.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutForce(c *C) {\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: memfs.New(),\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tw.Filesystem = memfs.New()\n\n\terr = w.Checkout(&CheckoutOptions{\n\t\tForce: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tentries, err := w.Filesystem.ReadDir(\"/\")\n\tc.Assert(err, IsNil)\n\tc.Assert(entries, HasLen, 8)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutKeep(c *C) {\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: memfs.New(),\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{\n\t\tForce: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\t// Create a new branch and create a new file.\n\terr = w.Checkout(&CheckoutOptions{\n\t\tBranch: plumbing.NewBranchReferenceName(\"new-branch\"),\n\t\tCreate: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tw.Filesystem = memfs.New()\n\tf, err := w.Filesystem.Create(\"new-file.txt\")\n\tc.Assert(err, IsNil)\n\t_, err = f.Write([]byte(\"DUMMY\"))\n\tc.Assert(err, IsNil)\n\tc.Assert(f.Close(), IsNil)\n\n\t// Add the file to staging.\n\t_, err = w.Add(\"new-file.txt\")\n\tc.Assert(err, IsNil)\n\n\t// Switch branch to master, and verify that the new file was kept in staging.\n\terr = w.Checkout(&CheckoutOptions{\n\t\tKeep: true,\n\t})\n\tc.Assert(err, IsNil)\n\n\tfi, err := w.Filesystem.Stat(\"new-file.txt\")\n\tc.Assert(err, IsNil)\n\tc.Assert(fi.Size(), Equals, int64(5))\n}\n\nfunc (s *WorktreeSuite) TestCheckoutSymlink(c *C) {\n\tif runtime.GOOS == \"windows\" {\n\t\tc.Skip(\"git doesn't support symlinks by default in windows\")\n\t}\n\n\tdir, err := ioutil.TempDir(\"\", \"checkout\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(dir)\n\n\tr, err := PlainInit(dir, false)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tw.Filesystem.Symlink(\"not-exists\", \"bar\")\n\tw.Add(\"bar\")\n\tw.Commit(\"foo\", &CommitOptions{Author: defaultSignature()})\n\n\tr.Storer.SetIndex(&index.Index{Version: 2})\n\tw.Filesystem = osfs.New(filepath.Join(dir, \"worktree-empty\"))\n\n\terr = w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n\n\ttarget, err := w.Filesystem.Readlink(\"bar\")\n\tc.Assert(target, Equals, \"not-exists\")\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *WorktreeSuite) TestFilenameNormalization(c *C) {\n\tif runtime.GOOS == \"windows\" {\n\t\tc.Skip(\"windows paths may contain non utf-8 sequences\")\n\t}\n\n\turl := c.MkDir()\n\tpath := fixtures.Basic().ByTag(\"worktree\").One().Worktree().Root()\n\n\tserver, err := PlainClone(url, false, &CloneOptions{\n\t\tURL: path,\n\t})\n\tc.Assert(err, IsNil)\n\n\tfilename := \"페\"\n\n\tw, err := server.Worktree()\n\tc.Assert(err, IsNil)\n\n\twriteFile := func(path string) {\n\t\terr := util.WriteFile(w.Filesystem, path, []byte(\"foo\"), 0755)\n\t\tc.Assert(err, IsNil)\n\t}\n\n\twriteFile(filename)\n\torigHash, err := w.Add(filename)\n\tc.Assert(err, IsNil)\n\t_, err = w.Commit(\"foo\", &CommitOptions{Author: defaultSignature()})\n\tc.Assert(err, IsNil)\n\n\tr, err := Clone(memory.NewStorage(), memfs.New(), &CloneOptions{\n\t\tURL: url,\n\t})\n\tc.Assert(err, IsNil)\n\n\tw, err = r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n\n\terr = w.Filesystem.Remove(filename)\n\tc.Assert(err, IsNil)\n\n\tmodFilename := norm.NFKD.String(filename)\n\twriteFile(modFilename)\n\n\t_, err = w.Add(filename)\n\tc.Assert(err, IsNil)\n\tmodHash, err := w.Add(modFilename)\n\tc.Assert(err, IsNil)\n\t// At this point we've got two files with the same content.\n\t// Hence their hashes must be the same.\n\tc.Assert(origHash == modHash, Equals, true)\n\n\tstatus, err = w.Status()\n\tc.Assert(err, IsNil)\n\t// However, their names are different and the work tree is still dirty.\n\tc.Assert(status.IsClean(), Equals, false)\n\n\t// Revert back the deletion of the first file.\n\twriteFile(filename)\n\t_, err = w.Add(filename)\n\tc.Assert(err, IsNil)\n\n\tstatus, err = w.Status()\n\tc.Assert(err, IsNil)\n\t// Still dirty - the second file is added.\n\tc.Assert(status.IsClean(), Equals, false)\n\n\t_, err = w.Remove(modFilename)\n\tc.Assert(err, IsNil)\n\n\tstatus, err = w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutSubmodule(c *C) {\n\turl := \"https://github.com/git-fixtures/submodule.git\"\n\tr := s.NewRepositoryWithEmptyWorktree(fixtures.ByURL(url).One())\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\terr = w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutSubmoduleInitialized(c *C) {\n\turl := \"https://github.com/git-fixtures/submodule.git\"\n\tr := s.NewRepository(fixtures.ByURL(url).One())\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tsub, err := w.Submodules()\n\tc.Assert(err, IsNil)\n\n\terr = sub.Update(&SubmoduleUpdateOptions{Init: true})\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutIndexMem(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tidx, err := s.Repository.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\tc.Assert(idx.Entries[0].Hash.String(), Equals, \"32858aad3c383ed1ff0a0f9bdf231d54a00c9e88\")\n\tc.Assert(idx.Entries[0].Name, Equals, \".gitignore\")\n\tc.Assert(idx.Entries[0].Mode, Equals, filemode.Regular)\n\tc.Assert(idx.Entries[0].ModifiedAt.IsZero(), Equals, false)\n\tc.Assert(idx.Entries[0].Size, Equals, uint32(189))\n\n\t// ctime, dev, inode, uid and gid are not supported on memfs fs\n\tc.Assert(idx.Entries[0].CreatedAt.IsZero(), Equals, true)\n\tc.Assert(idx.Entries[0].Dev, Equals, uint32(0))\n\tc.Assert(idx.Entries[0].Inode, Equals, uint32(0))\n\tc.Assert(idx.Entries[0].UID, Equals, uint32(0))\n\tc.Assert(idx.Entries[0].GID, Equals, uint32(0))\n}\n\nfunc (s *WorktreeSuite) TestCheckoutIndexOS(c *C) {\n\tdir, err := ioutil.TempDir(\"\", \"checkout\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(dir)\n\n\tfs := osfs.New(filepath.Join(dir, \"worktree\"))\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr = w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tidx, err := s.Repository.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\tc.Assert(idx.Entries[0].Hash.String(), Equals, \"32858aad3c383ed1ff0a0f9bdf231d54a00c9e88\")\n\tc.Assert(idx.Entries[0].Name, Equals, \".gitignore\")\n\tc.Assert(idx.Entries[0].Mode, Equals, filemode.Regular)\n\tc.Assert(idx.Entries[0].ModifiedAt.IsZero(), Equals, false)\n\tc.Assert(idx.Entries[0].Size, Equals, uint32(189))\n\n\tc.Assert(idx.Entries[0].CreatedAt.IsZero(), Equals, false)\n\tif runtime.GOOS != \"windows\" {\n\t\tc.Assert(idx.Entries[0].Dev, Not(Equals), uint32(0))\n\t\tc.Assert(idx.Entries[0].Inode, Not(Equals), uint32(0))\n\t\tc.Assert(idx.Entries[0].UID, Not(Equals), uint32(0))\n\t\tc.Assert(idx.Entries[0].GID, Not(Equals), uint32(0))\n\t}\n}\n\nfunc (s *WorktreeSuite) TestCheckoutBranch(c *C) {\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: memfs.New(),\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{\n\t\tBranch: \"refs/heads/branch\",\n\t})\n\tc.Assert(err, IsNil)\n\n\thead, err := w.r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Name().String(), Equals, \"refs/heads/branch\")\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutCreateWithHash(c *C) {\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: memfs.New(),\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{\n\t\tCreate: true,\n\t\tBranch: \"refs/heads/foo\",\n\t\tHash:   plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t})\n\tc.Assert(err, IsNil)\n\n\thead, err := w.r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Name().String(), Equals, \"refs/heads/foo\")\n\tc.Assert(head.Hash(), Equals, plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"))\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutCreate(c *C) {\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: memfs.New(),\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{\n\t\tCreate: true,\n\t\tBranch: \"refs/heads/foo\",\n\t})\n\tc.Assert(err, IsNil)\n\n\thead, err := w.r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Name().String(), Equals, \"refs/heads/foo\")\n\tc.Assert(head.Hash(), Equals, plumbing.NewHash(\"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\"))\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutBranchAndHash(c *C) {\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: memfs.New(),\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{\n\t\tBranch: \"refs/heads/foo\",\n\t\tHash:   plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\"),\n\t})\n\n\tc.Assert(err, Equals, ErrBranchHashExclusive)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutCreateMissingBranch(c *C) {\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: memfs.New(),\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{\n\t\tCreate: true,\n\t})\n\n\tc.Assert(err, Equals, ErrCreateRequiresBranch)\n}\n\nfunc (s *WorktreeSuite) TestCheckoutTag(c *C) {\n\tf := fixtures.ByTag(\"tags\").One()\n\tr := s.NewRepositoryWithEmptyWorktree(f)\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\terr = w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\thead, err := w.r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Name().String(), Equals, \"refs/heads/master\")\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n\n\terr = w.Checkout(&CheckoutOptions{Branch: \"refs/tags/lightweight-tag\"})\n\tc.Assert(err, IsNil)\n\thead, err = w.r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Name().String(), Equals, \"HEAD\")\n\tc.Assert(head.Hash().String(), Equals, \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\")\n\n\terr = w.Checkout(&CheckoutOptions{Branch: \"refs/tags/commit-tag\"})\n\tc.Assert(err, IsNil)\n\thead, err = w.r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Name().String(), Equals, \"HEAD\")\n\tc.Assert(head.Hash().String(), Equals, \"f7b877701fbf855b44c0a9e86f3fdce2c298b07f\")\n\n\terr = w.Checkout(&CheckoutOptions{Branch: \"refs/tags/tree-tag\"})\n\tc.Assert(err, NotNil)\n\thead, err = w.r.Head()\n\tc.Assert(err, IsNil)\n\tc.Assert(head.Name().String(), Equals, \"HEAD\")\n}\n\nfunc (s *WorktreeSuite) TestCheckoutBisect(c *C) {\n\tif testing.Short() {\n\t\tc.Skip(\"skipping test in short mode.\")\n\t}\n\n\ts.testCheckoutBisect(c, \"https://github.com/src-d/go-git.git\")\n}\n\nfunc (s *WorktreeSuite) TestCheckoutBisectSubmodules(c *C) {\n\ts.testCheckoutBisect(c, \"https://github.com/git-fixtures/submodule.git\")\n}\n\n// TestCheckoutBisect simulates a git bisect going through the git history and\n// checking every commit over the previous commit\nfunc (s *WorktreeSuite) testCheckoutBisect(c *C, url string) {\n\tf := fixtures.ByURL(url).One()\n\tr := s.NewRepositoryWithEmptyWorktree(f)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\titer, err := w.r.Log(&LogOptions{})\n\tc.Assert(err, IsNil)\n\n\titer.ForEach(func(commit *object.Commit) error {\n\t\terr := w.Checkout(&CheckoutOptions{Hash: commit.Hash})\n\t\tc.Assert(err, IsNil)\n\n\t\tstatus, err := w.Status()\n\t\tc.Assert(err, IsNil)\n\t\tc.Assert(status.IsClean(), Equals, true)\n\n\t\treturn nil\n\t})\n}\n\nfunc (s *WorktreeSuite) TestStatus(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\n\tc.Assert(status.IsClean(), Equals, false)\n\tc.Assert(status, HasLen, 9)\n}\n\nfunc (s *WorktreeSuite) TestStatusEmpty(c *C) {\n\tfs := memfs.New()\n\tstorage := memory.NewStorage()\n\n\tr, err := Init(storage, fs)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n\tc.Assert(status, NotNil)\n}\n\nfunc (s *WorktreeSuite) TestStatusEmptyDirty(c *C) {\n\tfs := memfs.New()\n\terr := util.WriteFile(fs, \"foo\", []byte(\"foo\"), 0755)\n\tc.Assert(err, IsNil)\n\n\tstorage := memory.NewStorage()\n\n\tr, err := Init(storage, fs)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, false)\n\tc.Assert(status, HasLen, 1)\n}\n\nfunc (s *WorktreeSuite) TestReset(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\tcommit := plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\")\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tbranch, err := w.r.Reference(plumbing.Master, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash(), Not(Equals), commit)\n\n\terr = w.Reset(&ResetOptions{Mode: MergeReset, Commit: commit})\n\tc.Assert(err, IsNil)\n\n\tbranch, err = w.r.Reference(plumbing.Master, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash(), Equals, commit)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestResetWithUntracked(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\tcommit := plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\")\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(fs, \"foo\", nil, 0755)\n\tc.Assert(err, IsNil)\n\n\terr = w.Reset(&ResetOptions{Mode: MergeReset, Commit: commit})\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestResetSoft(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\tcommit := plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\")\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\terr = w.Reset(&ResetOptions{Mode: SoftReset, Commit: commit})\n\tc.Assert(err, IsNil)\n\n\tbranch, err := w.r.Reference(plumbing.Master, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash(), Equals, commit)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, false)\n\tc.Assert(status.File(\"CHANGELOG\").Staging, Equals, Added)\n}\n\nfunc (s *WorktreeSuite) TestResetMixed(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\tcommit := plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\")\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\terr = w.Reset(&ResetOptions{Mode: MixedReset, Commit: commit})\n\tc.Assert(err, IsNil)\n\n\tbranch, err := w.r.Reference(plumbing.Master, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash(), Equals, commit)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, false)\n\tc.Assert(status.File(\"CHANGELOG\").Staging, Equals, Untracked)\n}\n\nfunc (s *WorktreeSuite) TestResetMerge(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\tcommitA := plumbing.NewHash(\"918c48b83bd081e863dbe1b80f8998f058cd8294\")\n\tcommitB := plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\")\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\terr = w.Reset(&ResetOptions{Mode: MergeReset, Commit: commitA})\n\tc.Assert(err, IsNil)\n\n\tbranch, err := w.r.Reference(plumbing.Master, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash(), Equals, commitA)\n\n\tf, err := fs.Create(\".gitignore\")\n\tc.Assert(err, IsNil)\n\t_, err = f.Write([]byte(\"foo\"))\n\tc.Assert(err, IsNil)\n\terr = f.Close()\n\tc.Assert(err, IsNil)\n\n\terr = w.Reset(&ResetOptions{Mode: MergeReset, Commit: commitB})\n\tc.Assert(err, Equals, ErrUnstagedChanges)\n\n\tbranch, err = w.r.Reference(plumbing.Master, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash(), Equals, commitA)\n}\n\nfunc (s *WorktreeSuite) TestResetHard(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\tcommit := plumbing.NewHash(\"35e85108805c84807bc66a02d91535e1e24b38b9\")\n\n\terr := w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tf, err := fs.Create(\".gitignore\")\n\tc.Assert(err, IsNil)\n\t_, err = f.Write([]byte(\"foo\"))\n\tc.Assert(err, IsNil)\n\terr = f.Close()\n\tc.Assert(err, IsNil)\n\n\terr = w.Reset(&ResetOptions{Mode: HardReset, Commit: commit})\n\tc.Assert(err, IsNil)\n\n\tbranch, err := w.r.Reference(plumbing.Master, false)\n\tc.Assert(err, IsNil)\n\tc.Assert(branch.Hash(), Equals, commit)\n}\n\nfunc (s *WorktreeSuite) TestStatusAfterCheckout(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, true)\n\n}\n\nfunc (s *WorktreeSuite) TestStatusModified(c *C) {\n\tdir, err := ioutil.TempDir(\"\", \"status\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(dir)\n\n\tfs := osfs.New(filepath.Join(dir, \"worktree\"))\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr = w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\tf, err := fs.Create(\".gitignore\")\n\tc.Assert(err, IsNil)\n\t_, err = f.Write([]byte(\"foo\"))\n\tc.Assert(err, IsNil)\n\terr = f.Close()\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, false)\n\tc.Assert(status.File(\".gitignore\").Worktree, Equals, Modified)\n}\n\nfunc (s *WorktreeSuite) TestStatusIgnored(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\tw.Checkout(&CheckoutOptions{})\n\n\tfs.MkdirAll(\"another\", os.ModePerm)\n\tf, _ := fs.Create(\"another/file\")\n\tf.Close()\n\tfs.MkdirAll(\"vendor/github.com\", os.ModePerm)\n\tf, _ = fs.Create(\"vendor/github.com/file\")\n\tf.Close()\n\tfs.MkdirAll(\"vendor/gopkg.in\", os.ModePerm)\n\tf, _ = fs.Create(\"vendor/gopkg.in/file\")\n\tf.Close()\n\n\tstatus, _ := w.Status()\n\tc.Assert(len(status), Equals, 3)\n\t_, ok := status[\"another/file\"]\n\tc.Assert(ok, Equals, true)\n\t_, ok = status[\"vendor/github.com/file\"]\n\tc.Assert(ok, Equals, true)\n\t_, ok = status[\"vendor/gopkg.in/file\"]\n\tc.Assert(ok, Equals, true)\n\n\tf, _ = fs.Create(\".gitignore\")\n\tf.Write([]byte(\"vendor/g*/\"))\n\tf.Close()\n\tf, _ = fs.Create(\"vendor/.gitignore\")\n\tf.Write([]byte(\"!github.com/\\n\"))\n\tf.Close()\n\n\tstatus, _ = w.Status()\n\tc.Assert(len(status), Equals, 4)\n\t_, ok = status[\".gitignore\"]\n\tc.Assert(ok, Equals, true)\n\t_, ok = status[\"another/file\"]\n\tc.Assert(ok, Equals, true)\n\t_, ok = status[\"vendor/.gitignore\"]\n\tc.Assert(ok, Equals, true)\n\t_, ok = status[\"vendor/github.com/file\"]\n\tc.Assert(ok, Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestStatusUntracked(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tf, err := w.Filesystem.Create(\"foo\")\n\tc.Assert(err, IsNil)\n\tc.Assert(f.Close(), IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.File(\"foo\").Staging, Equals, Untracked)\n\tc.Assert(status.File(\"foo\").Worktree, Equals, Untracked)\n}\n\nfunc (s *WorktreeSuite) TestStatusDeleted(c *C) {\n\tdir, err := ioutil.TempDir(\"\", \"status\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(dir)\n\n\tfs := osfs.New(filepath.Join(dir, \"worktree\"))\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr = w.Checkout(&CheckoutOptions{})\n\tc.Assert(err, IsNil)\n\n\terr = fs.Remove(\".gitignore\")\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status.IsClean(), Equals, false)\n\tc.Assert(status.File(\".gitignore\").Worktree, Equals, Deleted)\n}\n\nfunc (s *WorktreeSuite) TestSubmodule(c *C) {\n\tpath := fixtures.ByTag(\"submodule\").One().Worktree().Root()\n\tr, err := PlainOpen(path)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tm, err := w.Submodule(\"basic\")\n\tc.Assert(err, IsNil)\n\n\tc.Assert(m.Config().Name, Equals, \"basic\")\n}\n\nfunc (s *WorktreeSuite) TestSubmodules(c *C) {\n\tpath := fixtures.ByTag(\"submodule\").One().Worktree().Root()\n\tr, err := PlainOpen(path)\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\tl, err := w.Submodules()\n\tc.Assert(err, IsNil)\n\n\tc.Assert(l, HasLen, 2)\n}\n\nfunc (s *WorktreeSuite) TestAddUntracked(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err := w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\terr = util.WriteFile(w.Filesystem, \"foo\", []byte(\"FOO\"), 0755)\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Add(\"foo\")\n\tc.Assert(hash.String(), Equals, \"d96c7efbfec2814ae0301ad054dc8d9fc416c9b5\")\n\tc.Assert(err, IsNil)\n\n\tidx, err = w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 10)\n\n\te, err := idx.Entry(\"foo\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Hash, Equals, hash)\n\tc.Assert(e.Mode, Equals, filemode.Executable)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 1)\n\n\tfile := status.File(\"foo\")\n\tc.Assert(file.Staging, Equals, Added)\n\tc.Assert(file.Worktree, Equals, Unmodified)\n\n\tobj, err := w.r.Storer.EncodedObject(plumbing.BlobObject, hash)\n\tc.Assert(err, IsNil)\n\tc.Assert(obj, NotNil)\n\tc.Assert(obj.Size(), Equals, int64(3))\n}\n\nfunc (s *WorktreeSuite) TestIgnored(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\tw.Excludes = make([]gitignore.Pattern, 0)\n\tw.Excludes = append(w.Excludes, gitignore.ParsePattern(\"foo\", nil))\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err := w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\terr = util.WriteFile(w.Filesystem, \"foo\", []byte(\"FOO\"), 0755)\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 0)\n\n\tfile := status.File(\"foo\")\n\tc.Assert(file.Staging, Equals, Untracked)\n\tc.Assert(file.Worktree, Equals, Untracked)\n}\n\nfunc (s *WorktreeSuite) TestExcludedNoGitignore(c *C) {\n\tf := fixtures.ByTag(\"empty\").One()\n\tr := s.NewRepository(f)\n\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          r,\n\t\tFilesystem: fs,\n\t}\n\n\t_, err := fs.Open(\".gitignore\")\n\tc.Assert(err, Equals, os.ErrNotExist)\n\n\tw.Excludes = make([]gitignore.Pattern, 0)\n\tw.Excludes = append(w.Excludes, gitignore.ParsePattern(\"foo\", nil))\n\n\terr = util.WriteFile(w.Filesystem, \"foo\", []byte(\"FOO\"), 0755)\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 0)\n\n\tfile := status.File(\"foo\")\n\tc.Assert(file.Staging, Equals, Untracked)\n\tc.Assert(file.Worktree, Equals, Untracked)\n}\n\nfunc (s *WorktreeSuite) TestAddModified(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err := w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\terr = util.WriteFile(w.Filesystem, \"LICENSE\", []byte(\"FOO\"), 0644)\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Add(\"LICENSE\")\n\tc.Assert(err, IsNil)\n\tc.Assert(hash.String(), Equals, \"d96c7efbfec2814ae0301ad054dc8d9fc416c9b5\")\n\n\tidx, err = w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\te, err := idx.Entry(\"LICENSE\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Hash, Equals, hash)\n\tc.Assert(e.Mode, Equals, filemode.Regular)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 1)\n\n\tfile := status.File(\"LICENSE\")\n\tc.Assert(file.Staging, Equals, Modified)\n\tc.Assert(file.Worktree, Equals, Unmodified)\n}\n\nfunc (s *WorktreeSuite) TestAddUnmodified(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Add(\"LICENSE\")\n\tc.Assert(hash.String(), Equals, \"c192bd6a24ea1ab01d78686e417c8bdc7c3d197f\")\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *WorktreeSuite) TestAddRemoved(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err := w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\terr = w.Filesystem.Remove(\"LICENSE\")\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Add(\"LICENSE\")\n\tc.Assert(err, IsNil)\n\tc.Assert(hash.String(), Equals, \"c192bd6a24ea1ab01d78686e417c8bdc7c3d197f\")\n\n\te, err := idx.Entry(\"LICENSE\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Hash, Equals, hash)\n\tc.Assert(e.Mode, Equals, filemode.Regular)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 1)\n\n\tfile := status.File(\"LICENSE\")\n\tc.Assert(file.Staging, Equals, Deleted)\n}\n\nfunc (s *WorktreeSuite) TestAddSymlink(c *C) {\n\tdir, err := ioutil.TempDir(\"\", \"checkout\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(dir)\n\n\tr, err := PlainInit(dir, false)\n\tc.Assert(err, IsNil)\n\terr = util.WriteFile(r.wt, \"foo\", []byte(\"qux\"), 0644)\n\tc.Assert(err, IsNil)\n\terr = r.wt.Symlink(\"foo\", \"bar\")\n\tc.Assert(err, IsNil)\n\n\tw, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\th, err := w.Add(\"foo\")\n\tc.Assert(err, IsNil)\n\tc.Assert(h, Not(Equals), plumbing.NewHash(\"19102815663d23f8b75a47e7a01965dcdc96468c\"))\n\n\th, err = w.Add(\"bar\")\n\tc.Assert(err, IsNil)\n\tc.Assert(h, Equals, plumbing.NewHash(\"19102815663d23f8b75a47e7a01965dcdc96468c\"))\n\n\tobj, err := w.r.Storer.EncodedObject(plumbing.BlobObject, h)\n\tc.Assert(err, IsNil)\n\tc.Assert(obj, NotNil)\n\tc.Assert(obj.Size(), Equals, int64(3))\n}\n\nfunc (s *WorktreeSuite) TestAddDirectory(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err := w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\terr = util.WriteFile(w.Filesystem, \"qux/foo\", []byte(\"FOO\"), 0755)\n\tc.Assert(err, IsNil)\n\terr = util.WriteFile(w.Filesystem, \"qux/baz/bar\", []byte(\"BAR\"), 0755)\n\tc.Assert(err, IsNil)\n\n\th, err := w.Add(\"qux\")\n\tc.Assert(err, IsNil)\n\tc.Assert(h.IsZero(), Equals, true)\n\n\tidx, err = w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 11)\n\n\te, err := idx.Entry(\"qux/foo\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Mode, Equals, filemode.Executable)\n\n\te, err = idx.Entry(\"qux/baz/bar\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Mode, Equals, filemode.Executable)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 2)\n\n\tfile := status.File(\"qux/foo\")\n\tc.Assert(file.Staging, Equals, Added)\n\tc.Assert(file.Worktree, Equals, Unmodified)\n\n\tfile = status.File(\"qux/baz/bar\")\n\tc.Assert(file.Staging, Equals, Added)\n\tc.Assert(file.Worktree, Equals, Unmodified)\n}\n\nfunc (s *WorktreeSuite) TestAddDirectoryErrorNotFound(c *C) {\n\tr, _ := Init(memory.NewStorage(), memfs.New())\n\tw, _ := r.Worktree()\n\n\th, err := w.Add(\"foo\")\n\tc.Assert(err, NotNil)\n\tc.Assert(h.IsZero(), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestAddGlob(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\tidx, err := w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 9)\n\n\terr = util.WriteFile(w.Filesystem, \"qux/qux\", []byte(\"QUX\"), 0755)\n\tc.Assert(err, IsNil)\n\terr = util.WriteFile(w.Filesystem, \"qux/baz\", []byte(\"BAZ\"), 0755)\n\tc.Assert(err, IsNil)\n\terr = util.WriteFile(w.Filesystem, \"qux/bar/baz\", []byte(\"BAZ\"), 0755)\n\tc.Assert(err, IsNil)\n\n\terr = w.AddGlob(w.Filesystem.Join(\"qux\", \"b*\"))\n\tc.Assert(err, IsNil)\n\n\tidx, err = w.r.Storer.Index()\n\tc.Assert(err, IsNil)\n\tc.Assert(idx.Entries, HasLen, 11)\n\n\te, err := idx.Entry(\"qux/baz\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Mode, Equals, filemode.Executable)\n\n\te, err = idx.Entry(\"qux/bar/baz\")\n\tc.Assert(err, IsNil)\n\tc.Assert(e.Mode, Equals, filemode.Executable)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 3)\n\n\tfile := status.File(\"qux/qux\")\n\tc.Assert(file.Staging, Equals, Untracked)\n\tc.Assert(file.Worktree, Equals, Untracked)\n\n\tfile = status.File(\"qux/baz\")\n\tc.Assert(file.Staging, Equals, Added)\n\tc.Assert(file.Worktree, Equals, Unmodified)\n\n\tfile = status.File(\"qux/bar/baz\")\n\tc.Assert(file.Staging, Equals, Added)\n\tc.Assert(file.Worktree, Equals, Unmodified)\n}\n\nfunc (s *WorktreeSuite) TestAddGlobErrorNoMatches(c *C) {\n\tr, _ := Init(memory.NewStorage(), memfs.New())\n\tw, _ := r.Worktree()\n\n\terr := w.AddGlob(\"foo\")\n\tc.Assert(err, Equals, ErrGlobNoMatches)\n}\n\nfunc (s *WorktreeSuite) TestRemove(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Remove(\"LICENSE\")\n\tc.Assert(hash.String(), Equals, \"c192bd6a24ea1ab01d78686e417c8bdc7c3d197f\")\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 1)\n\tc.Assert(status.File(\"LICENSE\").Staging, Equals, Deleted)\n}\n\nfunc (s *WorktreeSuite) TestRemoveNotExistentEntry(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Remove(\"not-exists\")\n\tc.Assert(hash.IsZero(), Equals, true)\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *WorktreeSuite) TestRemoveDirectory(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Remove(\"json\")\n\tc.Assert(hash.IsZero(), Equals, true)\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 2)\n\tc.Assert(status.File(\"json/long.json\").Staging, Equals, Deleted)\n\tc.Assert(status.File(\"json/short.json\").Staging, Equals, Deleted)\n\n\t_, err = w.Filesystem.Stat(\"json\")\n\tc.Assert(os.IsNotExist(err), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestRemoveDirectoryUntracked(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(w.Filesystem, \"json/foo\", []byte(\"FOO\"), 0755)\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Remove(\"json\")\n\tc.Assert(hash.IsZero(), Equals, true)\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 3)\n\tc.Assert(status.File(\"json/long.json\").Staging, Equals, Deleted)\n\tc.Assert(status.File(\"json/short.json\").Staging, Equals, Deleted)\n\tc.Assert(status.File(\"json/foo\").Staging, Equals, Untracked)\n\n\t_, err = w.Filesystem.Stat(\"json\")\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *WorktreeSuite) TestRemoveDeletedFromWorktree(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\terr = fs.Remove(\"LICENSE\")\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Remove(\"LICENSE\")\n\tc.Assert(hash.String(), Equals, \"c192bd6a24ea1ab01d78686e417c8bdc7c3d197f\")\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 1)\n\tc.Assert(status.File(\"LICENSE\").Staging, Equals, Deleted)\n}\n\nfunc (s *WorktreeSuite) TestRemoveGlob(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\terr = w.RemoveGlob(w.Filesystem.Join(\"json\", \"l*\"))\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 1)\n\tc.Assert(status.File(\"json/long.json\").Staging, Equals, Deleted)\n}\n\nfunc (s *WorktreeSuite) TestRemoveGlobDirectory(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\terr = w.RemoveGlob(\"js*\")\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 2)\n\tc.Assert(status.File(\"json/short.json\").Staging, Equals, Deleted)\n\tc.Assert(status.File(\"json/long.json\").Staging, Equals, Deleted)\n\n\t_, err = w.Filesystem.Stat(\"json\")\n\tc.Assert(os.IsNotExist(err), Equals, true)\n}\n\nfunc (s *WorktreeSuite) TestRemoveGlobDirectoryDeleted(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\terr = fs.Remove(\"json/short.json\")\n\tc.Assert(err, IsNil)\n\n\terr = util.WriteFile(w.Filesystem, \"json/foo\", []byte(\"FOO\"), 0755)\n\tc.Assert(err, IsNil)\n\n\terr = w.RemoveGlob(\"js*\")\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 3)\n\tc.Assert(status.File(\"json/short.json\").Staging, Equals, Deleted)\n\tc.Assert(status.File(\"json/long.json\").Staging, Equals, Deleted)\n}\n\nfunc (s *WorktreeSuite) TestMove(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Move(\"LICENSE\", \"foo\")\n\tc.Check(hash.String(), Equals, \"c192bd6a24ea1ab01d78686e417c8bdc7c3d197f\")\n\tc.Assert(err, IsNil)\n\n\tstatus, err := w.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(status, HasLen, 2)\n\tc.Assert(status.File(\"LICENSE\").Staging, Equals, Deleted)\n\tc.Assert(status.File(\"foo\").Staging, Equals, Added)\n\n}\n\nfunc (s *WorktreeSuite) TestMoveNotExistentEntry(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Move(\"not-exists\", \"foo\")\n\tc.Assert(hash.IsZero(), Equals, true)\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *WorktreeSuite) TestMoveToExistent(c *C) {\n\tfs := memfs.New()\n\tw := &Worktree{\n\t\tr:          s.Repository,\n\t\tFilesystem: fs,\n\t}\n\n\terr := w.Checkout(&CheckoutOptions{Force: true})\n\tc.Assert(err, IsNil)\n\n\thash, err := w.Move(\".gitignore\", \"LICENSE\")\n\tc.Assert(hash.IsZero(), Equals, true)\n\tc.Assert(err, Equals, ErrDestinationExists)\n}\n\nfunc (s *WorktreeSuite) TestClean(c *C) {\n\tfs := fixtures.ByTag(\"dirty\").One().Worktree()\n\n\t// Open the repo.\n\tfs, err := fs.Chroot(\"repo\")\n\tc.Assert(err, IsNil)\n\tr, err := PlainOpen(fs.Root())\n\tc.Assert(err, IsNil)\n\n\twt, err := r.Worktree()\n\tc.Assert(err, IsNil)\n\n\t// Status before cleaning.\n\tstatus, err := wt.Status()\n\tc.Assert(err, IsNil)\n\tc.Assert(len(status), Equals, 2)\n\n\terr = wt.Clean(&CleanOptions{})\n\tc.Assert(err, IsNil)\n\n\t// Status after cleaning.\n\tstatus, err = wt.Status()\n\tc.Assert(err, IsNil)\n\n\tc.Assert(len(status), Equals, 1)\n\n\tfi, err := fs.Lstat(\"pkgA\")\n\tc.Assert(err, IsNil)\n\tc.Assert(fi.IsDir(), Equals, true)\n\n\t// Clean with Dir: true.\n\terr = wt.Clean(&CleanOptions{Dir: true})\n\tc.Assert(err, IsNil)\n\n\tstatus, err = wt.Status()\n\tc.Assert(err, IsNil)\n\n\tc.Assert(len(status), Equals, 0)\n\n\t// An empty dir should be deleted, as well.\n\t_, err = fs.Lstat(\"pkgA\")\n\tc.Assert(err, ErrorMatches, \".*(no such file or directory.*|.*file does not exist)*.\")\n\n}\n\nfunc (s *WorktreeSuite) TestAlternatesRepo(c *C) {\n\tfs := fixtures.ByTag(\"alternates\").One().Worktree()\n\n\t// Open 1st repo.\n\trep1fs, err := fs.Chroot(\"rep1\")\n\tc.Assert(err, IsNil)\n\trep1, err := PlainOpen(rep1fs.Root())\n\tc.Assert(err, IsNil)\n\n\t// Open 2nd repo.\n\trep2fs, err := fs.Chroot(\"rep2\")\n\tc.Assert(err, IsNil)\n\trep2, err := PlainOpen(rep2fs.Root())\n\tc.Assert(err, IsNil)\n\n\t// Get the HEAD commit from the main repo.\n\th, err := rep1.Head()\n\tc.Assert(err, IsNil)\n\tcommit1, err := rep1.CommitObject(h.Hash())\n\tc.Assert(err, IsNil)\n\n\t// Get the HEAD commit from the shared repo.\n\th, err = rep2.Head()\n\tc.Assert(err, IsNil)\n\tcommit2, err := rep2.CommitObject(h.Hash())\n\tc.Assert(err, IsNil)\n\n\tc.Assert(commit1.String(), Equals, commit2.String())\n}\n\nfunc (s *WorktreeSuite) TestGrep(c *C) {\n\tcases := []struct {\n\t\tname           string\n\t\toptions        GrepOptions\n\t\twantResult     []GrepResult\n\t\tdontWantResult []GrepResult\n\t\twantError      error\n\t}{\n\t\t{\n\t\t\tname: \"basic word match\",\n\t\t\toptions: GrepOptions{\n\t\t\t\tPatterns: []*regexp.Regexp{regexp.MustCompile(\"import\")},\n\t\t\t},\n\t\t\twantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"go/example.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import (\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"vendor/foo.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import \\\"fmt\\\"\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t},\n\t\t}, {\n\t\t\tname: \"case insensitive match\",\n\t\t\toptions: GrepOptions{\n\t\t\t\tPatterns: []*regexp.Regexp{regexp.MustCompile(`(?i)IMport`)},\n\t\t\t},\n\t\t\twantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"go/example.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import (\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"vendor/foo.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import \\\"fmt\\\"\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t},\n\t\t}, {\n\t\t\tname: \"invert match\",\n\t\t\toptions: GrepOptions{\n\t\t\t\tPatterns:    []*regexp.Regexp{regexp.MustCompile(\"import\")},\n\t\t\t\tInvertMatch: true,\n\t\t\t},\n\t\t\tdontWantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"go/example.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import (\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"vendor/foo.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import \\\"fmt\\\"\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t},\n\t\t}, {\n\t\t\tname: \"match at a given commit hash\",\n\t\t\toptions: GrepOptions{\n\t\t\t\tPatterns:   []*regexp.Regexp{regexp.MustCompile(\"The MIT License\")},\n\t\t\t\tCommitHash: plumbing.NewHash(\"b029517f6300c2da0f4b651b8642506cd6aaf45d\"),\n\t\t\t},\n\t\t\twantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"LICENSE\",\n\t\t\t\t\tLineNumber: 1,\n\t\t\t\t\tContent:    \"The MIT License (MIT)\",\n\t\t\t\t\tTreeName:   \"b029517f6300c2da0f4b651b8642506cd6aaf45d\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tdontWantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"go/example.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import (\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t},\n\t\t}, {\n\t\t\tname: \"match for a given pathspec\",\n\t\t\toptions: GrepOptions{\n\t\t\t\tPatterns:  []*regexp.Regexp{regexp.MustCompile(\"import\")},\n\t\t\t\tPathSpecs: []*regexp.Regexp{regexp.MustCompile(\"go/\")},\n\t\t\t},\n\t\t\twantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"go/example.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import (\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tdontWantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"vendor/foo.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import \\\"fmt\\\"\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t},\n\t\t}, {\n\t\t\tname: \"match at a given reference name\",\n\t\t\toptions: GrepOptions{\n\t\t\t\tPatterns:      []*regexp.Regexp{regexp.MustCompile(\"import\")},\n\t\t\t\tReferenceName: \"refs/heads/master\",\n\t\t\t},\n\t\t\twantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"go/example.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import (\",\n\t\t\t\t\tTreeName:   \"refs/heads/master\",\n\t\t\t\t},\n\t\t\t},\n\t\t}, {\n\t\t\tname: \"ambiguous options\",\n\t\t\toptions: GrepOptions{\n\t\t\t\tPatterns:      []*regexp.Regexp{regexp.MustCompile(\"import\")},\n\t\t\t\tCommitHash:    plumbing.NewHash(\"2d55a722f3c3ecc36da919dfd8b6de38352f3507\"),\n\t\t\t\tReferenceName: \"somereferencename\",\n\t\t\t},\n\t\t\twantError: ErrHashOrReference,\n\t\t}, {\n\t\t\tname: \"multiple patterns\",\n\t\t\toptions: GrepOptions{\n\t\t\t\tPatterns: []*regexp.Regexp{\n\t\t\t\t\tregexp.MustCompile(\"import\"),\n\t\t\t\t\tregexp.MustCompile(\"License\"),\n\t\t\t\t},\n\t\t\t},\n\t\t\twantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"go/example.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import (\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"vendor/foo.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import \\\"fmt\\\"\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"LICENSE\",\n\t\t\t\t\tLineNumber: 1,\n\t\t\t\t\tContent:    \"The MIT License (MIT)\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t},\n\t\t}, {\n\t\t\tname: \"multiple pathspecs\",\n\t\t\toptions: GrepOptions{\n\t\t\t\tPatterns: []*regexp.Regexp{regexp.MustCompile(\"import\")},\n\t\t\t\tPathSpecs: []*regexp.Regexp{\n\t\t\t\t\tregexp.MustCompile(\"go/\"),\n\t\t\t\t\tregexp.MustCompile(\"vendor/\"),\n\t\t\t\t},\n\t\t\t},\n\t\t\twantResult: []GrepResult{\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"go/example.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import (\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tFileName:   \"vendor/foo.go\",\n\t\t\t\t\tLineNumber: 3,\n\t\t\t\t\tContent:    \"import \\\"fmt\\\"\",\n\t\t\t\t\tTreeName:   \"6ecf0ef2c2dffb796033e5a02219af86ec6584e5\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tpath := fixtures.Basic().ByTag(\"worktree\").One().Worktree().Root()\n\tserver, err := PlainClone(c.MkDir(), false, &CloneOptions{\n\t\tURL: path,\n\t})\n\tc.Assert(err, IsNil)\n\n\tw, err := server.Worktree()\n\tc.Assert(err, IsNil)\n\n\tfor _, tc := range cases {\n\t\tgr, err := w.Grep(&tc.options)\n\t\tif tc.wantError != nil {\n\t\t\tc.Assert(err, Equals, tc.wantError)\n\t\t} else {\n\t\t\tc.Assert(err, IsNil)\n\t\t}\n\n\t\t// Iterate through the results and check if the wanted result is present\n\t\t// in the got result.\n\t\tfor _, wantResult := range tc.wantResult {\n\t\t\tfound := false\n\t\t\tfor _, gotResult := range gr {\n\t\t\t\tif wantResult == gotResult {\n\t\t\t\t\tfound = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !found {\n\t\t\t\tc.Errorf(\"unexpected grep results for %q, expected result to contain: %v\", tc.name, wantResult)\n\t\t\t}\n\t\t}\n\n\t\t// Iterate through the results and check if the not wanted result is\n\t\t// present in the got result.\n\t\tfor _, dontWantResult := range tc.dontWantResult {\n\t\t\tfound := false\n\t\t\tfor _, gotResult := range gr {\n\t\t\t\tif dontWantResult == gotResult {\n\t\t\t\t\tfound = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif found {\n\t\t\t\tc.Errorf(\"unexpected grep results for %q, expected result to NOT contain: %v\", tc.name, dontWantResult)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (s *WorktreeSuite) TestAddAndCommit(c *C) {\n\tdir, err := ioutil.TempDir(\"\", \"plain-repo\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(dir)\n\n\trepo, err := PlainInit(dir, false)\n\tc.Assert(err, IsNil)\n\n\tw, err := repo.Worktree()\n\tc.Assert(err, IsNil)\n\n\t_, err = w.Add(\".\")\n\tc.Assert(err, IsNil)\n\n\tw.Commit(\"Test Add And Commit\", &CommitOptions{Author: &object.Signature{\n\t\tName:  \"foo\",\n\t\tEmail: \"foo@foo.foo\",\n\t\tWhen:  time.Now(),\n\t}})\n\n\titer, err := w.r.Log(&LogOptions{})\n\tc.Assert(err, IsNil)\n\terr = iter.ForEach(func(c *object.Commit) error {\n\t\tfiles, err := c.Files()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\terr = files.ForEach(func(f *object.File) error {\n\t\t\treturn errors.New(\"Expected no files, got at least 1\")\n\t\t})\n\t\treturn err\n\t})\n\tc.Assert(err, IsNil)\n}\n"
        },
        {
          "name": "worktree_unix_other.go",
          "type": "blob",
          "size": 0.4677734375,
          "content": "// +build openbsd dragonfly solaris\n\npackage git\n\nimport (\n\t\"syscall\"\n\t\"time\"\n\n\t\"gopkg.in/src-d/go-git.v4/plumbing/format/index\"\n)\n\nfunc init() {\n\tfillSystemInfo = func(e *index.Entry, sys interface{}) {\n\t\tif os, ok := sys.(*syscall.Stat_t); ok {\n\t\t\te.CreatedAt = time.Unix(int64(os.Atim.Sec), int64(os.Atim.Nsec))\n\t\t\te.Dev = uint32(os.Dev)\n\t\t\te.Inode = uint32(os.Ino)\n\t\t\te.GID = os.Gid\n\t\t\te.UID = os.Uid\n\t\t}\n\t}\n}\n\nfunc isSymlinkWindowsNonAdmin(err error) bool {\n\treturn false\n}\n"
        },
        {
          "name": "worktree_windows.go",
          "type": "blob",
          "size": 0.7109375,
          "content": "// +build windows\n\npackage git\n\nimport (\n\t\"os\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"gopkg.in/src-d/go-git.v4/plumbing/format/index\"\n)\n\nfunc init() {\n\tfillSystemInfo = func(e *index.Entry, sys interface{}) {\n\t\tif os, ok := sys.(*syscall.Win32FileAttributeData); ok {\n\t\t\tseconds := os.CreationTime.Nanoseconds() / 1000000000\n\t\t\tnanoseconds := os.CreationTime.Nanoseconds() - seconds*1000000000\n\t\t\te.CreatedAt = time.Unix(seconds, nanoseconds)\n\t\t}\n\t}\n}\n\nfunc isSymlinkWindowsNonAdmin(err error) bool {\n\tconst ERROR_PRIVILEGE_NOT_HELD syscall.Errno = 1314\n\n\tif err != nil {\n\t\tif errLink, ok := err.(*os.LinkError); ok {\n\t\t\tif errNo, ok := errLink.Err.(syscall.Errno); ok {\n\t\t\t\treturn errNo == ERROR_PRIVILEGE_NOT_HELD\n\t\t\t}\n\t\t}\n\t}\n\n\treturn false\n}\n"
        }
      ]
    }
  ]
}