{
  "metadata": {
    "timestamp": 1736567282361,
    "page": 879,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjg4MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "influxdata/kapacitor",
      "stars": 2322,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.0107421875,
          "content": ".git\nbuild\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.0244140625,
          "content": "CHANGELOG.md merge=union\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.3447265625,
          "content": ".*.swp\n/.idea/\ndist/*\n/build/*\n/*.conf\nkapacitor_linux*\nkapacitord_linux*\n/*.tick\n*~\n*#\nkapacitor*.rpm\nkapacitor*.deb\nkapacitor*.tar\nkapacitor*.zip\n*.pyc\n*.test\n/test-logs\n*.prof\n/.idea/\n\n# Ignore any built binaries\n/kapacitor\n/kapacitord\n/tickfmt\n/tickdoc\n\n# Ignore go vendor directory\n/vendor\n\n#don't ignore staticcheck.conf files\n!/staticcheck.conf\n\n"
        },
        {
          "name": ".hooks",
          "type": "tree",
          "content": null
        },
        {
          "name": "BLOB_STORE_DESIGN.md",
          "type": "blob",
          "size": 2.02734375,
          "content": "# Blob Store\n\nThe blob store is a mechanism to store arbitrary data in Kapacitor.\nThe data stored is immutable and opaque to Kapacitor.\n\nData is stored as blobs where each blob has a unique ID.\nA tagging system is used to refer various blobs within the store.\nA blob may be tagged with a given name.\nA blob may be retrieved by its ID or a tag name.\nWhen retrieving a blob via a tag name, the most recently associated blob is returned for that tag.\nTags may be updated, meaning they can be modified to point at a different blob.\nThe history of a tag to blob associations are preserved.\n\nThere are no specific limits on the size of a blob, and blobs can be streamed in and out of the store.\n\n## Uses\n\nThe following details the various uses of the Kapacitor blob store.\n\n### Snapshots\n\nKapacitor will periodically snapshot the state of a running task. (Currently only implemented for UDFs).\nWhen a task is started its previous snapshot or a named snapshot is restored.\n\nKapacitor tasks construct a [DAG](https://en.wikipedia.org/wiki/Directed_acyclic_graph) of the data pipeline.\nEach step in this DAG is called a node.\nSnapshots are associated with a single node within a single task.\nAll nodes are assigned IDs based on the DAG structure.\nWhen the DAG changes the previous snapshots are considered invalid an are no longer used to restore task state.\n\n### UDFs\n\nUDFs can explicitly save and request blobs from the store via the protobuf socket connection with Kapacitor.\nA common use case is to load and store trained model data.\nHowever you use the blob store within your UDF is up to you.\n\n\n## Design\n\nThe blob store will use content addressable IDs(i.e. shasum of the content) and be exposed via the HTTP API of Kapacitor.\n\nBlobs can be created, named and deleted.\nCreating a blob will accept only the content of the blob data and return the ID of the blob.\nNaming a blob associates a specified name to the content of the blob.\nA naming history is recorded, allowing the users to determine the \"version\" history for a given name.\nDeleting a blob removes it from the store.\n\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 85.50390625,
          "content": "CHANGELOG for Kapacitor master commit 71a5e1e036b81a2f4cd4de56fdf298090d0ee13a\n\n## v1.7.6 [2024-10-28]\n----------------------\n\n### Features\n\n1. [2834](https://github.com/influxdata/kapacitor/pull/2834): Kafka event handler - add SASL OAUTH token refreshing\n2. [2832](https://github.com/influxdata/kapacitor/pull/2832): Kafka event handler - allow setting and sending SASL extensions\n\n### Bug Fixes\n\n1. [2831](https://github.com/influxdata/kapacitor/pull/2831): Using UTC timezone for alert levels\n1. [2833](https://github.com/influxdata/kapacitor/pull/2833): Fix Kafka mock server\n\n### Other\n\n1. [2835](https://github.com/influxdata/kapacitor/pull/2835): Upgrade Go to 1.22.7\n\n## v1.7.5 [2024-06-12]\n----------------------\n\n### Other\n\n1. [2819](https://github.com/influxdata/kapacitor/pull/2819), [2823](https://github.com/influxdata/kapacitor/pull/2823): Upgrade Go to 1.21.10, use custom builder instead of `cross-builder`\n\n## v1.7.4 [2024-04-22]\n----------------------\n\n### Other\n\n1. [2808](https://github.com/influxdata/kapacitor/pull/2808): Add SECURITY.md\n1. [2810](https://github.com/influxdata/kapacitor/pull/2810): Upgrade aws-sdk-go to 1.51.12\n1. [2812](https://github.com/influxdata/kapacitor/pull/2812): Upgrade Go to 1.21.9\n1. [2813](https://github.com/influxdata/kapacitor/pull/2813): Upgrade golang.org/x/net from 0.17.0 to 0.23.0\n\n## v1.7.3 [2024-03-22]\n----------------------\n\n### Bug Fixes\n\n1. [2803](https://github.com/influxdata/kapacitor/pull/2803): Do not migrate events with empty ID\n\n### Other\n\n1. [2804](https://github.com/influxdata/kapacitor/pull/2804): Upgrade Go to 1.21.8\n1. [2799](https://github.com/influxdata/kapacitor/pull/2799): Remove \"v\" prefix from package version\n1. [2805](https://github.com/influxdata/kapacitor/pull/2805): Upgrade github.com/docker/docker from 24.0.7 to 24.0.9\n1. [2801](https://github.com/influxdata/kapacitor/pull/2801): Upgrade google.golang.org/protobuf from 1.30.0 to 1.33.0\n\n## v1.7.2 [2024-02-26]\n----------------------\n\n### Other\n\n1. [2787](https://github.com/influxdata/kapacitor/pull/2787): Upgrade google.golang.org/grpc from 1.44.0 to 1.56.3\n1. [2788](https://github.com/influxdata/kapacitor/pull/2788): Upgrade github.com/docker/docker to 24.0.7\n1. [2795](https://github.com/influxdata/kapacitor/pull/2795): Upgrade Go to 1.20.13\n\n## v1.7.1 [2023-10-20]\n----------------------\n\n### Bug Fixes\n\n1. [2784](https://github.com/influxdata/kapacitor/pull/2784): Security fix (CVE-2023-44487: HTTP/2 Rapid Reset attack)\n1. [2783](https://github.com/influxdata/kapacitor/pull/2783): Security fix (CVE-2023-44487: HTTP/2 Rapid Reset attack)\n\n## v1.7.0 [2023-08-18]\n----------------------\n\n### Features\n\n1. [dbcc77e3](https://github.com/influxdata/kapacitor/commit/dbcc77e3) Rewrite topic store for incremental update\n\n## v1.6.6 [2023-04-12]\n----------------------\n\n### Features\n\n1. [025c7067](https://github.com/influxdata/kapacitor/commit/025c7067) Add JWT meta API authentication\n\n#### Bug Fixes\n\n1. [3bfeb14a](https://github.com/influxdata/kapacitor/commit/3bfeb14a) Support InfluxDB 1.9.6 and OpenTSB by implementing WritePointsPrivileged\n\n## v1.6.5 [2021-07-12]\n----------------------\n\n### Features\n\n1. [b69fc92](https://github.com/influxdata/kapacitor/commit/b69fc92): Rand function for tick lambdas\n1. [c05878b](https://github.com/influxdata/kapacitor/commit/c05878b): Newer influxql\n\n### Bug Fixes\n\n1. [d467fea](https://github.com/influxdata/kapacitor/commit/d467fea): Updated kafka client to fix a bug in the library\n1. [933e5d0](https://github.com/influxdata/kapacitor/commit/933e5d0): Update flux to 0.171 for: 'interface {} is nil, not string'\n\n\n## v1.6.4 [2022-03-15]\n----------------------\n\n### Features\n\n1. [839e032](https://github.com/influxdata/kapacitor/commit/839e032): This adds SASL support to kafka alerts\n\n### Bug Fixes\n\n1. [d4fcc6b](https://github.com/influxdata/kapacitor/commit/d4fcc6b): Flux limits and bad flux httpclient\n1. [1959476](https://github.com/influxdata/kapacitor/commit/1959476): Update sarama for  https://github.com/Shopify/sarama/issues/2129\n1. [95dd289](https://github.com/influxdata/kapacitor/commit/95dd289): properly depreciate TLS<1.2, DES and RC4 based ciphers\n\n\n## v1.6.3 [2021-12-10]\n----------------------\n\n### Features\n\n1. [935fdf0](https://github.com/influxdata/kapacitor/commit/935fdf0): Support the \"attributes\" attribute in Alerta node\n1. [8c9ed5d](https://github.com/influxdata/kapacitor/commit/8c9ed5d): Add BigPanda handler options\n1. [a353257](https://github.com/influxdata/kapacitor/commit/a353257): Env var config can now add new items\n1. [af204c7](https://github.com/influxdata/kapacitor/commit/af204c7): Make topic queue length configurable\n1. [4c2b965](https://github.com/influxdata/kapacitor/commit/4c2b965): Templating for address in email alert\n\n### Bug Fixes\n\n1. [720aba1](https://github.com/influxdata/kapacitor/commit/720aba1): Deprecations in response to sweet32\n1. [2526656](https://github.com/influxdata/kapacitor/commit/2526656): Better error message for missing flux data\n\n\n## v1.6.2 [2021-09-29]\n----------------------\n\n### Features\n\n1. [cbcd989](https://github.com/influxdata/kapacitor/commit/cbcd989): Add template-id to task list\n1. [b498fce](https://github.com/influxdata/kapacitor/commit/b498fce): Auto-create 1.x DB or 2.x bucket for flux task logs\n1. [b4091b8](https://github.com/influxdata/kapacitor/commit/b4091b8): Allow for compact json in templates and BP\n\n### Bug Fixes\n\n1. [10535e8](https://github.com/influxdata/kapacitor/commit/10535e8): Switch flux formatter to one that preserves comments\n\n\n## v1.6.1 [2021-07-22]\n----------------------\n\n### Features\n\n1. [815bf2b](https://github.com/influxdata/kapacitor/commit/815bf2b): Flag to allow blacklisting CIDR ranges\n\n### Bug Fixes\n\n1. [df99b44](https://github.com/influxdata/kapacitor/commit/df99b44): Fields of alerting data point are serialized to proper types\n1. [2bd467c](https://github.com/influxdata/kapacitor/commit/2bd467c): Fields of alerting data point should be serialized as a string\n\n\n## v1.6.0 [2021-06-14]\n----------------------\n\n### Features\n\n1. [226f1ca](https://github.com/influxdata/kapacitor/commit/226f1ca): Flux tasks skeleton in Kapacitor\n1. [5c162cd](https://github.com/influxdata/kapacitor/commit/5c162cd): Run flux tasks with built-in flux engine\n1. [a731363](https://github.com/influxdata/kapacitor/commit/a731363): Kapacitor cli supports flux tasks\n1. [5a1ba2c](https://github.com/influxdata/kapacitor/commit/5a1ba2c): Enable new-style slack apps\n1. [fef0d30](https://github.com/influxdata/kapacitor/commit/fef0d30): Tricklenode\n1. [a6a0c27](https://github.com/influxdata/kapacitor/commit/a6a0c27): Flux batch queries in TICKscripts\n1. [e5cd456](https://github.com/influxdata/kapacitor/commit/e5cd456): Shared secret auth to influxdb in OSS\n\n### Bug Fixes\n\n1. [c5603f3](https://github.com/influxdata/kapacitor/commit/c5603f3): Race in sideload update\n1. [4ca7790](https://github.com/influxdata/kapacitor/commit/4ca7790): Add TICKscript AST processing\n1. [f6f7229](https://github.com/influxdata/kapacitor/commit/f6f7229): External ServiceNow testability\n1. [1f2c956](https://github.com/influxdata/kapacitor/commit/1f2c956): External BigPanda testability\n1. [ebee9bf](https://github.com/influxdata/kapacitor/commit/ebee9bf): Make ChannelURL naming consistent\n1. [53a1d22](https://github.com/influxdata/kapacitor/commit/53a1d22): Zenoss config handling\n1. [452f2b2](https://github.com/influxdata/kapacitor/commit/452f2b2): Property name compatibility\n1. [6ceb6ec](https://github.com/influxdata/kapacitor/commit/6ceb6ec): Setup test options from configuration\n1. [22315fb](https://github.com/influxdata/kapacitor/commit/22315fb): Null pointer panic in scraper handler\n1. [53cf295](https://github.com/influxdata/kapacitor/commit/53cf295): Revert ChannelURL mapping to preserve backward compatibility with saved TICKscripts\n1. [931e72a](https://github.com/influxdata/kapacitor/commit/931e72a): Cli auth and error handling for flux tasks\n\n## v1.5.9 [2021-04-01]\n\n### Bugfixes\n- [#2479](https://github.com/influxdata/kapacitor/pull/2479): Fix influx gzip writes for large writes.\n- [#2488](https://github.com/influxdata/kapacitor/pull/2488): Fix function node name for ServiceNow handler so it is properly camelcased. \n- [#2489](https://github.com/influxdata/kapacitor/pull/2489): Fix memory leaks in JoinNode and UnionNode.\n- [#2498](https://github.com/influxdata/kapacitor/pull/2498): Avoid infinite hang when closing Kakfa writer, this also prevents the timeout error on an http update to Kafka config.\n- [#2536](https://github.com/influxdata/kapacitor/pull/2536): Update prometheus dependency for service discovery\n\n### Features\n- [#2472](https://github.com/influxdata/kapacitor/pull/2472): Send full event payload on pagerduty resolve, thanks @asvinours!\n- [#2474](https://github.com/influxdata/kapacitor/pull/2474): Add barrier handling to FlattenNode.\n- [#2475](https://github.com/influxdata/kapacitor/pull/2475): Added default color theme to teams alerts, thanks @NoamShaish!\n- [#2491](https://github.com/influxdata/kapacitor/pull/2491): Fix TICKScript AST for bigpanda. \n\n## v1.5.8 [2021-01-11]\n\n### Bugfixes\n- [#2448](https://github.com/influxdata/kapacitor/pull/2448): Changes the alert-handler match function duration() to be alertDuration() to avoid name collision with the type conversion function of the same name.\n\n\n### Features\n- [#1839](https://github.com/influxdata/kapacitor/pull/1839): Add Subscription path configuration option to allow Kapacitor to run behind a reverse proxy, thanks @aspring\n- [#1894](https://github.com/influxdata/kapacitor/pull/1894): Add HTTP sources for sideload configuration, thanks @jregovic!\n- [#2055](https://github.com/influxdata/kapacitor/pull/2055): Add support for correlate in the Alerta AlertNode, thanks @nermolaev!\n- [#2409](https://github.com/influxdata/kapacitor/pull/2409): Optionally use kapacitor alert details as opsgenie description text,  thanks @JamesClonk!\n- [#2441](https://github.com/influxdata/kapacitor/pull/2441): Preallocate GroupIDs for increased performance by reducing allocations.\n- [#2456](https://github.com/influxdata/kapacitor/pull/2456): Gzip data by default that is sent to influxdb.\n- [#2454](https://github.com/influxdata/kapacitor/pull/2454): Add PrimaryProperty and SecondaryProperty methods to BigPanda AlertNode.\n- [#2462](https://github.com/influxdata/kapacitor/pull/2462): BREAKING: we are forced to remove support for 386/darwin builds as go doesn't support them anymore.\n- [#2475](https://github.com/influxdata/kapacitor/pull/2475): Add default color theme to teams alerts\n\n## v1.5.7 [2020-10-27]\n\n### Features\n- [#2301](https://github.com/influxdata/kapacitor/pull/2301): Allow for overriding OpsGenieV2's alert recovery action in tickSCRIPT, thanks @zabullet!\n- [#2388](https://github.com/influxdata/kapacitor/pull/2388): Added templating for the url in the `httpPost` node and the `alert().post()` node.\n- [#2351](https://github.com/influxdata/kapacitor/pull/2351): Upgraded github.com/gorhill/cronexpr, thanks @wuguanyu!\n- [#2416](https://github.com/influxdata/kapacitor/pull/2416): Added a ServiceNow event handler.\n### Bugfixes\n- [#2201](https://github.com/influxdata/kapacitor/pull/2201): Added missing err check of a buf scanner, thanks @johncming!\n- [#2395](http://github.com/influxdata/kapacitor/pull/2395): Added missing .Details to AlertTemplate.\n\n## v1.5.6 [2020-07-17]\n\n### Features\n- [#1965](https://github.com/influxdata/kapacitor/pull/1965): Alert handler for Microsoft Teams, thanks @mmindenhall!\n- [#2287](https://github.com/influxdata/kapacitor/pull/2287): Added Discord Webhook Alert Handler, thanks @mattnotmitt!\n- [#2311](https://github.com/influxdata/kapacitor/pull/2311): UDF Agent Python3 fixes, thanks @elohmeier!\n- [#2312](https://github.com/influxdata/kapacitor/pull/2312): feat(build): switch from md5 to sha256\n- [#2322](https://github.com/influxdata/kapacitor/pull/2322): Add support for TLS 1.3.\n\n### Bugfixes\n- [#1980](https://github.com/influxdata/kapacitor/pull/1980): Fix discovery service lost config, thanks @flisky!\n- [#2156](https://github.com/influxdata/kapacitor/pull/2156): Use Systemd for Amazon Linux 2\n- [#2282](https://github.com/influxdata/kapacitor/pull/2282): fix small typo.\n- [#2286](https://github.com/influxdata/kapacitor/pull/2286): Corrected issue with `go vet` invocation in .hooks/pre-commit which would cause the hook to fail, thanks @mattnotmitt!\n- [#2289](https://github.com/influxdata/kapacitor/pull/2289): Update build.py to support arm64, thanks @povlhp\n- [#2335](https://github.com/influxdata/kapacitor/pull/2335): Fix panic when setting a zero interval for ticker, this affected deadman and stats nodes.\n- [#2340](https://github.com/influxdata/kapacitor/pull/2340): Fix a panic on int div-by-zero, instead return an error.\n- [#2358](https://github.com/influxdata/kapacitor/pull/2360): Fix Kapacitor ignoring the pushover().userKey('') TICKScript operation.\n\n## v1.5.5 [2020-04-20]\n\n### bugfixes\n- [#2319](https://github.com/influxdata/kapacitor/pull/2319): Update kafka lib; make kafka errors unsilent.\n\n### features\n- [#2312](https://github.com/influxdata/kapacitor/pull/2312): Switched from md5 to sha256 for release checksums.\n\n## v1.5.4 [2020-01-16]\n\n### Features\n\n- [#2202](https://github.com/influxdata/kapacitor/pull/2202): Add templating for MQTT topics.\n- [#2276](https://github.com/influxdata/kapacitor/pull/2276): Upgrade to support python 3 for UDFs, Thanks @N-Coder !\n\n### Bugfixes\n\n- [#2253](https://github.com/influxdata/kapacitor/pull/2253): Upgrade the kafka library to set the timestamp correctly.\n- [#2274](https://github.com/influxdata/kapacitor/pull/2274): Upgrade to Go 1.13, fixes various go vet issues.\n\n## v1.5.3 [2019-06-18]\n\n### Features\n\n- [#2154](https://github.com/influxdata/kapacitor/pull/2154): Add ability to skip ssl verification with an alert post node. Thanks @itsHabib!\n- [#2193](https://github.com/influxdata/kapacitor/issues/2193): Add TLS configuration options.\n\n### Bugfixes\n\n- [#2167](https://github.com/influxdata/kapacitor/pull/2167): Use default transport consistently.\n- [#2144](https://github.com/influxdata/kapacitor/issues/2144): Fix deadlock in barrier node when delete is used.\n- [#2186](https://github.com/influxdata/kapacitor/pull/2186): Make RPM create files with correct ownership on install.\n- [#2189](https://github.com/influxdata/kapacitor/pull/2189): Delete group stats when a group is deleted\n- [#2207](https://github.com/influxdata/kapacitor/pull/2207): Avoid extra allocation when building GroupID\n\n## v1.5.2 [2018-12-12]\n\n### Features\n\n- [#2095](https://github.com/influxdata/kapacitor/issues/2095): Add barrier node support to join node.\n- [#1157](https://github.com/influxdata/kapacitor/issues/1157): Add ability to expire groups using the barrier node.\n- [#2099](https://github.com/influxdata/kapacitor/issues/2099): Add `alert/persist-topics` to config\n- [#2101](https://github.com/influxdata/kapacitor/issues/2101): Add multiple field support to the change detect node.\n- [#1961](https://github.com/influxdata/kapacitor/pull/1961): Add links to pagerduty2 alerts\n- [#1974](https://github.com/influxdata/kapacitor/issues/1974): Add additional metadata to Sensu alerts.\n\n### Bugfixes\n\n- [#2048](https://github.com/influxdata/kapacitor/pull/2048): Fix join not catching up fast enough after a pause in the data stream.\n\n## v1.5.1 [2018-08-06]\n\n### Bugfixes\n\n- [#1938](https://github.com/influxdata/kapacitor/issues/1938): pagerduty2 should use routingKey rather than serviceKey\n- [#1982](https://github.com/influxdata/kapacitor/pull/1982): Fix KafkaTopic not working from TICKscript\n- [#1989](https://github.com/influxdata/kapacitor/pull/1989): Improve Kafka alert throughput.\n\n## v1.5.0 [2018-05-17]\n\n### Features\n- [#1842](https://github.com/influxdata/kapacitor/pull/1842): Add alert inhibitors that allow an alert to suppress events from other matching alerts.\n- [#1833](https://github.com/influxdata/kapacitor/pull/1833): Config format updated to allow for more than one slack configuration.  \n- [#1844](https://github.com/influxdata/kapacitor/pull/1844): Added a new kapacitor node changeDetect that emits a value\n    for each time a series field changes.\n- [#1828](https://github.com/influxdata/kapacitor/pull/1828): Add recoverable field to JSON alert response to indicate whether the\nalert will auto-recover.\n- [#1823](https://github.com/influxdata/kapacitor/pull/1823): Update OpsGenie integration to use the v2 API.\n    To upgrade to using the new API simply update your config and TICKscripts to use opsgenie2 instead of opsgenie.\n    If your `opsgenie` config uses the `recovery_url` option, for `opsgenie2` you will need to change it to the `recovery_action` option.\n    This is because the new v2 API is not structured with static URLs, and so only the action can be defined and not the entire URL.\n- [#1690](https://github.com/influxdata/kapacitor/issues/1690): Add https-private-key option to httpd config.\n- [#1561](https://github.com/influxdata/kapacitor/issues/1561): Add .quiet to all nodes to silence any errors reported by the node.\n- [#1826](https://github.com/influxdata/kapacitor/issues/1826): Add Kafka alert handler.\n\n### Bugfixes\n- [#1794](https://github.com/influxdata/kapacitor/issues/1794): Kapacitor ticks generating a hash instead of their actual given name.\n- [#1827](https://github.com/influxdata/kapacitor/pull/1827): Fix deadlock in load service when task has an error.\n- [#1795](https://github.com/influxdata/kapacitor/pull/1795): Support PagerDuty API v2\n- [#1776](https://github.com/influxdata/kapacitor/issues/1776): Fix bug where you could not delete a topic handler with the same name as its topic.\n- [#1905](https://github.com/influxdata/kapacitor/pull/1905): Adjust PagerDuty v2 service-test names and capture detailed error messages.\n- [#1913](https://github.com/influxdata/kapacitor/pull/1913): Fix Kafka configuration.\n\n## v1.4.1 [2018-03-13]\n\n### Bugfixes\n\n- [#1834](https://github.com/influxdata/kapacitor/issues/1834): Fix bug where task type was invalid when using var for stream/batch\n\n## v1.4.0 [2017-12-08]\n\nThe v1.4.0 release has many new features, here is a list of some of the highlights:\n\n1. Load TICKscripts and alert handlers from a directory.\n2. Structed Logging  with a logging API endpoints to be able to tail logs for given tasks.\n3. Autoscale support for Docker Swarm and EC2 Autoscaling.\n4. Sideload data into your TICKscript streams from external sources.\n5. Fully customizable POST body for the alert POST handler and the httpPost node.\n\nSee the complete list of bug fixes and features below.\n\n### Bugfixes\n\n- [#1710](https://github.com/influxdata/kapacitor/issues/1710): Idle Barrier is dropping all messages when source has clock offset\n- [#1719](https://github.com/influxdata/kapacitor/pull/1719): Fix oddly generated TOML for mqtt & httppost\n\n## v1.4.0-rc3 [2017-12-04]\n\n### Bugfixes\n\n- [#1703](https://github.com/influxdata/kapacitor/pull/1703): Fix issues where log API checked the wrong header for the desired content type.\n\n## v1.4.0-rc2 [2017-11-28]\n\n### Features\n\n- [#1622](https://github.com/influxdata/kapacitor/pull/1622): Add support for AWS EC2 autoscaling services.\n- [#1566](https://github.com/influxdata/kapacitor/pull/1566): Add BarrierNode to emit BarrierMessage periodically\n\n### Bugfixes\n\n- [#1250](https://github.com/influxdata/kapacitor/issues/1250): Fix VictorOps \"data\" field being a string instead of actual JSON.\n- [#1697](https://github.com/influxdata/kapacitor/issues/1697): Fix panic with MQTT toml configuration generation.\n\n## v1.4.0-rc1 [2017-11-09]\n\n### Features\n\n- [#1408](https://github.com/influxdata/kapacitor/issues/1408): Add Previous state\n- [#1575](https://github.com/influxdata/kapacitor/issues/1575): Add support to persist replay status after it finishes.\n- [#1461](https://github.com/influxdata/kapacitor/issues/1461): alert.post and https_post timeouts needed.\n- [#1413](https://github.com/influxdata/kapacitor/issues/1413): Add subscriptions modes to InfluxDB subscriptions.\n- [#1436](https://github.com/influxdata/kapacitor/issues/1436): Add linear fill support for QueryNode.\n- [#1345](https://github.com/influxdata/kapacitor/issues/1345): Add MQTT Alert Handler\n- [#1390](https://github.com/influxdata/kapacitor/issues/1390): Add built in functions to convert timestamps to integers\n- [#1425](https://github.com/influxdata/kapacitor/pull/1425): BREAKING: Change over internal API to use message passing semantics.\n    The breaking change is that the Combine and Flatten nodes previously, but erroneously, operated across batch boundaries; this has been fixed.\n- [#1497](https://github.com/influxdata/kapacitor/pull/1497): Add support for Docker Swarm autoscaling services.\n- [#1485](https://github.com/influxdata/kapacitor/issues/1485): Add bools field types to UDFs.\n- [#1549](https://github.com/influxdata/kapacitor/issues/1549): Add stateless now() function to get the current local time.\n- [#1545](https://github.com/influxdata/kapacitor/pull/1545): Add support for timeout, tags and service template in the Alerta AlertNode\n- [#1568](https://github.com/influxdata/kapacitor/issues/1568): Add support for custom HTTP Post bodies via a template system.\n- [#1569](https://github.com/influxdata/kapacitor/issues/1569): Add support for add the HTTP status code as a field when using httpPost\n- [#1535](https://github.com/influxdata/kapacitor/pull/1535): Add logfmt support and refactor logging.\n- [#1481](https://github.com/influxdata/kapacitor/pull/1481): Add ability to load tasks/handlers from dir.\n    TICKscript was extended to be able to describe a task exclusively through a tickscript.\n      * tasks no longer need to specify their TaskType (Batch, Stream).\n      * `dbrp` expressions were added to tickscript.\n    Topic-Handler file format was modified to include the TopicID and HandlerID in the file.\n    Load service was added; the service can load tasks/handlers from a directory.\n- [#1606](https://github.com/influxdata/kapacitor/pull/1606): Update Go version to 1.9.1\n- [#1578](https://github.com/influxdata/kapacitor/pull/1578): Add support for exposing logs via the API. API is released as a technical preview.\n- [#1605](https://github.com/influxdata/kapacitor/issues/1605): Add support for {{ .Duration }} on Alert Message property.\n- [#1644](https://github.com/influxdata/kapacitor/issues/1644): Add support for [JSON lines](https://en.wikipedia.org/wiki/JSON_Streaming#Line_delimited_JSON) for steaming HTTP logs.\n- [#1637](https://github.com/influxdata/kapacitor/issues/1637): Add new node Sideload, that allows loading data from files into the stream of data. Data can be loaded using a hierarchy.\n- [#1667](https://github.com/influxdata/kapacitor/pull/1667): Promote Alert API to stable v1 path.\n- [#1668](https://github.com/influxdata/kapacitor/pull/1668): Change WARN level logs to INFO level.\n\n### Bugfixes\n\n- [#916](https://github.com/influxdata/kapacitor/issues/916): Crash of Kapacitor on Windows x64 when starting a recording\n- [#1400](https://github.com/influxdata/kapacitor/issues/1400): Allow for `.yml` file extensions in `define-topic-handler`\n- [#1402](https://github.com/influxdata/kapacitor/pull/1402): Fix http server error logging.\n- [#1500](https://github.com/influxdata/kapacitor/pull/1500): Fix bugs with stopping running UDF agent.\n- [#1470](https://github.com/influxdata/kapacitor/pull/1470): Fix error messages for missing fields which are arguments to functions are not clear\n- [#1516](https://github.com/influxdata/kapacitor/pull/1516): Fix bad PagerDuty test the required server info.\n- [#1581](https://github.com/influxdata/kapacitor/pull/1581): Add SNMP sysUpTime to SNMP Trap service\n- [#1547](https://github.com/influxdata/kapacitor/issues/1547): Fix panic on recording replay with HTTPPostHandler.\n- [#1623](https://github.com/influxdata/kapacitor/issues/1623): Fix k8s incluster master api dns resolution\n- [#1630](https://github.com/influxdata/kapacitor/issues/1630): Remove the pidfile after the server has exited.\n- [#1641](https://github.com/influxdata/kapacitor/issues/1641): Logs API writes multiple http headers.\n- [#1657](https://github.com/influxdata/kapacitor/issues/1657): Fix missing dependency in rpm package.\n- [#1660](https://github.com/influxdata/kapacitor/pull/1660): Force tar owner/group to be root.\n- [#1663](https://github.com/influxdata/kapacitor/pull/1663): Fixed install/remove of kapacitor on non-systemd Debian/Ubuntu systems.\n    Fixes packaging to not enable services on RHEL systems.\n    Fixes issues with recusive symlinks on systemd systems.\n- [#1662](https://github.com/influxdata/kapacitor/issues/1662): Fix invalid default MQTT config.\n\n## v1.3.3 [2017-08-11]\n\n### Bugfixes\n- [#1520](https://github.com/influxdata/kapacitor/pull/1520): Expose pprof without authentication if enabled\n\n## v1.3.2 [2017-08-08]\n\n### Bugfixes\n- [#1512](https://github.com/influxdata/kapacitor/pull/1512): Use details field from alert node in PagerDuty.\n\n## v1.3.1 [2017-06-02]\n\n### Bugfixes\n\n- [#1415](https://github.com/influxdata/kapacitor/pull/1415): Proxy from environment for HTTP request to slack\n- [#1414](https://github.com/influxdata/kapacitor/pull/1414): Fix derivative node preserving fields from previous point in stream tasks.\n\n## v1.3.0 [2017-05-22]\n\n### Release Notes\n\nThe v1.3.0 release has two major features.\n\n1. Addition of scraping and discovering for Prometheus style data collection.\n2. Updates to the Alert Topic system\n\nHere is a quick example of how to configure Kapacitor to scrape discovered targets.\nFirst configure a discoverer, here we use the file-discovery discoverer.\nNext configure a scraper to use that discoverer.\n\n>NOTE: The scraping and discovering features are released under technical preview,\nmeaning that the configuration or API around the feature may change in a future release.\n\n```\n# Configure file discoverer\n[[file-discovery]]\n enabled = true\n id = \"discover_files\"\n refresh-interval = \"10s\"\n ##### This will look for prometheus json files\n ##### File format is here https://prometheus.io/docs/operating/configuration/#%3Cfile_sd_config%3E\n files = [\"/tmp/prom/*.json\"]\n\n# Configure scraper\n[[scraper]]\n enabled = true\n name = \"node_exporter\"\n discoverer-id = \"discover_files\"\n discoverer-service = \"file-discovery\"\n db = \"prometheus\"\n rp = \"autogen\"\n type = \"prometheus\"\n scheme = \"http\"\n metrics-path = \"/metrics\"\n scrape-interval = \"2s\"\n scrape-timeout = \"10s\"\n```\n\nAdd the above snippet to your kapacitor.conf file.\n\nCreate the below snippet as the file `/tmp/prom/localhost.json`:\n\n```\n[{\n \"targets\": [\"localhost:9100\"]\n}]\n```\n\nStart the Prometheus node_exporter locally.\n\nNow startup Kapacitor and it will discover the `localhost:9100` node_exporter target and begin scrapping it for metrics.\nFor more details on the scraping and discovery systems see the full documentation [here](https://docs.influxdata.com/kapacitor/v1.3/scraping).\n\nThe second major feature with this release, are changes to the alert topic system.\nThe previous release introduce this new system as a technical preview, with this release the alerting service has been simplified.\nAlert handlers now only ever have a single action and belong to a single topic.\n\nThe handler definition has been simplified as a result.\nHere are some example alert handlers using the new structure:\n\n```yaml\nid: my_handler\nkind: pagerDuty\noptions:\n  serviceKey: XXX\n```\n\n```yaml\nid: aggregate_by_1m\nkind: aggregate\noptions:\n  interval: 1m\n  topic: aggregated\n```\n\n```yaml\nid: publish_to_system\nkind: publish\noptions:\n  topics: [ system ]\n```\n\nTo define a handler now you must specify which topic the handler belongs to.\nFor example to define the above aggregate handler on the system topic use this command:\n\n```sh\nkapacitor define-handler system aggregate_by_1m.yaml\n```\n\nFor more details on the alerting system see the full documentation [here](https://docs.influxdata.com/kapacitor/v1.3/alerts).\n\n# Bugfixes\n\n- [#1396](https://github.com/influxdata/kapacitor/pull/1396): Fix broken ENV var config overrides for the kubernetes section.\n- [#1397](https://github.com/influxdata/kapacitor/pull/1397): Update default configuration file to include sections for each discoverer service.\n\n## v1.3.0-rc4 [2017-05-19]\n\n# Bugfixes\n\n- [#1379](https://github.com/influxdata/kapacitor/issues/1379): Copy batch points slice before modification, fixes potential panics and data corruption.\n- [#1394](https://github.com/influxdata/kapacitor/pull/1394): Use the Prometheus metric name as the measurement name by default for scrape data.\n- [#1392](https://github.com/influxdata/kapacitor/pull/1392): Fix possible deadlock for scraper configuration updating.\n\n## v1.3.0-rc3 [2017-05-18]\n\n### Bugfixes\n\n- [#1369](https://github.com/influxdata/kapacitor/issues/1369): Fix panic with concurrent writes to same points in state tracking nodes.\n- [#1387](https://github.com/influxdata/kapacitor/pull/1387): static-discovery configuration simplified\n- [#1378](https://github.com/influxdata/kapacitor/issues/1378): Fix panic in InfluxQL node with missing field.\n\n## v1.3.0-rc2 [2017-05-11]\n\n### Bugfixes\n\n- [#1370](https://github.com/influxdata/kapacitor/issues/1370): Fix missing working_cardinality stats on stateDuration and stateCount nodes.\n\n## v1.3.0-rc1 [2017-05-08]\n\n### Features\n\n- [#1299](https://github.com/influxdata/kapacitor/pull/1299): Allowing sensu handler to be specified\n- [#1284](https://github.com/influxdata/kapacitor/pull/1284): Add type signatures to Kapacitor functions.\n- [#1203](https://github.com/influxdata/kapacitor/issues/1203): Add `isPresent` operator for verifying whether a value is present (part of [#1284](https://github.com/influxdata/kapacitor/pull/1284)).\n- [#1354](https://github.com/influxdata/kapacitor/pull/1354): Add Kubernetes scraping support.\n- [#1359](https://github.com/influxdata/kapacitor/pull/1359): Add groupBy exclude and Add dropOriginalFieldName to flatten.\n- [#1360](https://github.com/influxdata/kapacitor/pull/1360): Add KapacitorLoopback node to be able to send data from a task back into Kapacitor.\n\n### Bugfixes\n\n- [#1329](https://github.com/influxdata/kapacitor/issues/1329): BREAKING: A bug was fixed around missing fields in the derivative node.\n    The behavior of the node changes slightly in order to provide a consistent fix to the bug.\n    The breaking change is that now, the time of the points returned are from the right hand or current point time, instead of the left hand or previous point time.\n- [#1353](https://github.com/influxdata/kapacitor/issues/1353): Fix panic in scraping TargetManager.\n- [#1238](https://github.com/influxdata/kapacitor/pull/1238): Use ProxyFromEnvironment for all outgoing HTTP traffic.\n\n## v1.3.0-beta2 [2017-05-01]\n\n### Features\n\n- [#117](https://github.com/influxdata/kapacitor/issues/117): Add headers to alert POST requests.\n\n### Bugfixes\n\n- [#1294](https://github.com/influxdata/kapacitor/issues/1294): Fix bug where batch queries would be missing all fields after the first nil field.\n- [#1343](https://github.com/influxdata/kapacitor/issues/1343): BREAKING: The UDF agent Go API has changed, the changes now make it so that the agent package is self contained.\n\n## v1.3.0-beta1 [2017-04-29]\n\n### Features\n\n- [#1322](https://github.com/influxdata/kapacitor/pull/1322): TLS configuration in Slack service for Mattermost compatibility\n- [#1330](https://github.com/influxdata/kapacitor/issues/1330): Generic HTTP Post node\n- [#1159](https://github.com/influxdata/kapacitor/pulls/1159): Go version 1.7.4 -> 1.7.5\n- [#1175](https://github.com/influxdata/kapacitor/pull/1175): BREAKING: Add generic error counters to every node type.\n    Renamed `query_errors` to `errors` in batch node.\n    Renamed `eval_errors` to `errors` in eval node.\n- [#922](https://github.com/influxdata/kapacitor/issues/922): Expose server specific information in alert templates.\n- [#1162](https://github.com/influxdata/kapacitor/pulls/1162): Add Pushover integration.\n- [#1221](https://github.com/influxdata/kapacitor/pull/1221): Add `working_cardinality` stat to each node type that tracks the number of groups per node.\n- [#1211](https://github.com/influxdata/kapacitor/issues/1211): Add StateDuration node.\n- [#1209](https://github.com/influxdata/kapacitor/issues/1209): BREAKING: Refactor the Alerting service.\n    The change is completely breaking for the technical preview alerting service, a.k.a. the new alert topic handler features.\n    The change boils down to simplifying how you define and interact with topics.\n    Alert handlers now only ever have a single action and belong to a single topic.\n    An automatic migration from old to new handler definitions will be performed during startup.\n    See the updated API docs.\n- [#1286](https://github.com/influxdata/kapacitor/issues/1286): Default HipChat URL should be blank\n- [#507](https://github.com/influxdata/kapacitor/issues/507): Add API endpoint for performing Kapacitor database backups.\n- [#1132](https://github.com/influxdata/kapacitor/issues/1132): Adding source for sensu alert as parameter\n- [#1346](https://github.com/influxdata/kapacitor/pull/1346): Add discovery and scraping services.\n\n### Bugfixes\n\n- [#1133](https://github.com/influxdata/kapacitor/issues/1133): Fix case-sensitivity for Telegram `parseMode` value.\n- [#1147](https://github.com/influxdata/kapacitor/issues/1147): Fix pprof debug endpoint\n- [#1164](https://github.com/influxdata/kapacitor/pull/1164): Fix hang in config API to update a config section.\n    Now if the service update process takes too long the request will timeout and return an error.\n    Previously the request would block forever.\n- [#1165](https://github.com/influxdata/kapacitor/issues/1165): Make the alerta auth token prefix configurable and default it to Bearer.\n- [#1184](https://github.com/influxdata/kapacitor/pull/1184): Fix logrotate file to correctly rotate error log.\n- [#1200](https://github.com/influxdata/kapacitor/pull/1200): Fix bug with alert duration being incorrect after restoring alert state.\n- [#1199](https://github.com/influxdata/kapacitor/pull/1199): BREAKING: Fix inconsistency with JSON data from alerts.\n    The alert handlers Alerta, Log, OpsGenie, PagerDuty, Post and VictorOps allow extra opaque data to be attached to alert notifications.\n    That opaque data was inconsistent and this change fixes that.\n    Depending on how that data was consumed this could result in a breaking change, since the original behavior was inconsistent\n    we decided it would be best to fix the issue now and make it consistent for all future builds.\n    Specifically in the JSON result data the old key `Series` is always `series`, and the old key `Err` is now always `error` instead of for only some of the outputs.\n- [#1181](https://github.com/influxdata/kapacitor/pull/1181): Fix bug parsing dbrp values with quotes.\n- [#1228](https://github.com/influxdata/kapacitor/pull/1228): Fix panic on loading replay files without a file extension.\n- [#1192](https://github.com/influxdata/kapacitor/issues/1192): Fix bug in Default Node not updating batch tags and groupID.\n    Also empty string on a tag value is now a sufficient condition for the default conditions to be applied.\n    See [#1233](https://github.com/influxdata/kapacitor/pull/1233) for more information.\n- [#1068](https://github.com/influxdata/kapacitor/issues/1068): Fix dot view syntax to use xlabels and not create invalid quotes.\n- [#1295](https://github.com/influxdata/kapacitor/issues/1295): Fix curruption of recordings list after deleting all recordings.\n- [#1237](https://github.com/influxdata/kapacitor/issues/1237): Fix missing \"vars\" key when listing tasks.\n- [#1271](https://github.com/influxdata/kapacitor/issues/1271): Fix bug where aggregates would not be able to change type.\n- [#1261](https://github.com/influxdata/kapacitor/issues/1261): Fix panic when the process cannot stat the data dir.\n\n## v1.2.1 [2017-04-13]\n\n### Bugfixes\n\n- [#1323](https://github.com/influxdata/kapacitor/pull/1323): Fix issue where credentials to InfluxDB could not be updated dynamically.\n\n## v1.2.0 [2017-01-23]\n\n### Release Notes\n\nA new system for working with alerts has been introduced.\nThis alerting system allows you to configure topics for alert events and then configure handlers for various topics.\nThis way alert generation is decoupled from alert handling.\n\nExisting TICKscripts will continue to work without modification.\n\nTo use this new alerting system remove any explicit alert handlers from your TICKscript and specify a topic.\nThen configure the handlers for the topic.\n\n```\nstream\n    |from()\n      .measurement('cpu')\n      .groupBy('host')\n    |alert()\n      // Specify the topic for the alert\n      .topic('cpu')\n      .info(lambda: \"value\" > 60)\n      .warn(lambda: \"value\" > 70)\n      .crit(lambda: \"value\" > 80)\n      // No handlers are configured in the script, they are instead defined on the topic via the API.\n```\n\nThe API exposes endpoints to query the state of each alert and endpoints for configuring alert handlers.\nSee the [API docs](https://docs.influxdata.com/kapacitor/latest/api/api/) for more details.\nThe kapacitor CLI has been updated with commands for defining alert handlers.\n\nThis release introduces a new feature where you can window based off the number of points instead of their time.\nFor example:\n\n```\nstream\n    |from()\n        .measurement('my-measurement')\n    // Emit window for every 10 points with 100 points per window.\n    |window()\n        .periodCount(100)\n        .everyCount(10)\n    |mean('value')\n    |alert()\n         .crit(lambda: \"mean\" > 100)\n         .slack()\n         .channel('#alerts')\n```\n\n\nWith this change alert nodes will have an anonymous topic created for them.\nThis topic is managed like all other topics preserving state etc. across restarts.\nAs a result existing alert nodes will now remember the state of alerts after restarts and disiabling/enabling a task.\n\n>NOTE: The new alerting features are being released under technical preview.\nThis means breaking changes may be made in later releases until the feature is considered complete.\nSee the [API docs on technical preview](https://docs.influxdata.com/kapacitor/v1.2/api/api/#technical-preview) for specifics of how this effects the API.\n\n### Features\n\n- [#1110](https://github.com/influxdata/kapacitor/pull/1110): Add new query property for aligning group by intervals to start times.\n- [#1095](https://github.com/influxdata/kapacitor/pull/1095): Add new alert API, with support for configuring handlers and topics.\n- [#1052](https://github.com/influxdata/kapacitor/issues/1052): Move alerta api token to header and add option to skip TLS verification.\n- [#929](https://github.com/influxdata/kapacitor/pull/929): Add SNMP trap service for alerting.\n- [#913](https://github.com/influxdata/kapacitor/issues/913): Add fillPeriod option to Window node, so that the first emit waits till the period has elapsed before emitting.\n- [#898](https://github.com/influxdata/kapacitor/issues/898): Now when the Window node every value is zero, the window will be emitted immediately for each new point.\n- [#744](https://github.com/influxdata/kapacitor/issues/744): Preserve alert state across restarts and disable/enable actions.\n- [#327](https://github.com/influxdata/kapacitor/issues/327): You can now window based on count in addition to time.\n- [#251](https://github.com/influxdata/kapacitor/issues/251): Enable markdown in slack attachments.\n\n\n### Bugfixes\n\n- [#1100](https://github.com/influxdata/kapacitor/issues/1100): Fix issue with the Union node buffering more points than necessary.\n- [#1087](https://github.com/influxdata/kapacitor/issues/1087): Fix panic during close of failed startup when connecting to InfluxDB.\n- [#1045](https://github.com/influxdata/kapacitor/issues/1045): Fix panic during replays.\n- [#1043](https://github.com/influxdata/kapacitor/issues/1043): logrotate.d ignores kapacitor configuration due to bad file mode.\n- [#872](https://github.com/influxdata/kapacitor/issues/872): Fix panic during failed aggregate results.\n\n## v1.1.1 [2016-12-02]\n\n### Release Notes\n\nNo changes to Kapacitor, only upgrading to go 1.7.4 for security patches.\n\n## v1.1.0 [2016-10-07]\n\n### Release Notes\n\nNew K8sAutoscale node that allows you to auotmatically scale Kubernetes deployments driven by any metrics Kapacitor consumes.\nFor example, to scale a deployment `myapp` based off requests per second:\n\n```\n// The target requests per second per host\nvar target = 100.0\n\nstream\n    |from()\n        .measurement('requests')\n        .where(lambda: \"deployment\" == 'myapp')\n    // Compute the moving average of the last 5 minutes\n    |movingAverage('requests', 5*60)\n        .as('mean_requests_per_second')\n    |k8sAutoscale()\n        .resourceName('app')\n        .kind('deployments')\n        .min(4)\n        .max(100)\n        // Compute the desired number of replicas based on target.\n        .replicas(lambda: int(ceil(\"mean_requests_per_second\" / target)))\n```\n\n\nNew API endpoints have been added to be able to configure InfluxDB clusters and alert handlers dynamically without needing to restart the Kapacitor daemon.\nAlong with the ability to dynamically configure a service, API endpoints have been added to test the configurable services.\nSee the [API docs](https://docs.influxdata.com/kapacitor/latest/api/api/) for more details.\n\n>NOTE: The `connect_errors` stat from the query node was removed since the client changed, all errors are now counted in the `query_errors` stat.\n\n### Features\n\n- [#931](https://github.com/influxdata/kapacitor/issues/931): Add a Kubernetes autoscaler node. You can now autoscale your Kubernetes deployments via Kapacitor.\n- [#928](https://github.com/influxdata/kapacitor/issues/928): Add new API endpoint for dynamically overriding sections of the configuration.\n- [#980](https://github.com/influxdata/kapacitor/pull/980): Upgrade to using go 1.7\n- [#957](https://github.com/influxdata/kapacitor/issues/957): Add API endpoints for testing service integrations.\n- [#958](https://github.com/influxdata/kapacitor/issues/958): Add support for Slack icon emojis and custom usernames.\n- [#991](https://github.com/influxdata/kapacitor/pull/991): Bring Kapacitor up to parity with available InfluxQL functions in 1.1\n\n### Bugfixes\n\n- [#984](https://github.com/influxdata/kapacitor/issues/984): Fix bug where keeping a list of fields that where not referenced in the eval expressions would cause an error.\n- [#955](https://github.com/influxdata/kapacitor/issues/955): Fix the number of subscriptions statistic.\n- [#999](https://github.com/influxdata/kapacitor/issues/999): Fix inconsistency with InfluxDB by adding config option to set a default retention policy.\n- [#1018](https://github.com/influxdata/kapacitor/pull/1018): Sort and dynamically adjust column width in CLI output. Fixes #785\n- [#1019](https://github.com/influxdata/kapacitor/pull/1019): Adds missing strLength function.\n\n## v1.0.2 [2016-10-06]\n\n### Release Notes\n\n### Features\n\n### Bugfixes\n\n- [#951](https://github.com/influxdata/kapacitor/pull/951): Fix bug where errors to save cluster/server ID files were ignored.\n- [#954](https://github.com/influxdata/kapacitor/pull/954): Create data_dir on startup if it does not exist.\n\n## v1.0.1 [2016-09-26]\n\n### Release Notes\n\n### Features\n\n- [#873](https://github.com/influxdata/kapacitor/pull/873): Add TCP alert handler\n- [#869](https://github.com/influxdata/kapacitor/issues/869): Add ability to set alert message as a field\n- [#854](https://github.com/influxdata/kapacitor/issues/854): Add `.create` property to InfluxDBOut node, which when set will create the database\n    and retention policy on task start.\n- [#909](https://github.com/influxdata/kapacitor/pull/909): Allow duration / duration in TICKscript.\n- [#777](https://github.com/influxdata/kapacitor/issues/777): Add support for string manipulation functions.\n- [#886](https://github.com/influxdata/kapacitor/issues/886): Add ability to set specific HTTP port and hostname per configured InfluxDB cluster.\n\n### Bugfixes\n\n- [#889](https://github.com/influxdata/kapacitor/issues/889): Some typo in the default config file\n- [#914](https://github.com/influxdata/kapacitor/pull/914): Change |log() output to be in JSON format so its self documenting structure.\n- [#915](https://github.com/influxdata/kapacitor/pull/915): Fix issue with TMax and the Holt-Winters method.\n- [#927](https://github.com/influxdata/kapacitor/pull/927): Fix bug with TMax and group by time.\n\n## v1.0.0 [2016-09-02]\n\n### Release Notes\n\nFinal release of v1.0.0.\n\n## v1.0.0-rc3 [2016-09-01]\n\n### Release Notes\n\n### Features\n\n### Bugfixes\n\n- [#842](https://github.com/influxdata/kapacitor/issues/842): Fix side-effecting modification in batch WhereNode.\n\n## v1.0.0-rc2 [2016-08-29]\n\n### Release Notes\n\n### Features\n\n- [#827](https://github.com/influxdata/kapacitor/issues/827): Bring Kapacitor up to parity with available InfluxQL functions in 1.0\n\n### Bugfixes\n\n- [#763](https://github.com/influxdata/kapacitor/issues/763): Fix NaNs begin returned from the `sigma` stateful function.\n- [#468](https://github.com/influxdata/kapacitor/issues/468): Fix tickfmt munging escaped slashes in regexes.\n\n## v1.0.0-rc1 [2016-08-22]\n\n### Release Notes\n\n#### Alert reset expressions\n\nKapacitor now supports alert reset expressions.\nThis way when an alert enters a state, it can only be lowered in severity if its reset expression evaluates to true.\n\nExample:\n\n```go\nstream\n    |from()\n      .measurement('cpu')\n      .where(lambda: \"host\" == 'serverA')\n      .groupBy('host')\n    |alert()\n      .info(lambda: \"value\" > 60)\n      .infoReset(lambda: \"value\" < 50)\n      .warn(lambda: \"value\" > 70)\n      .warnReset(lambda: \"value\" < 60)\n      .crit(lambda: \"value\" > 80)\n      .critReset(lambda: \"value\" < 70)\n```\n\nFor example given the following values:\n\n    61 73 64 85 62 56 47\n\nThe corresponding alert states are:\n\n    INFO WARNING WARNING CRITICAL INFO INFO OK\n\n### Features\n\n- [#740](https://github.com/influxdata/kapacitor/pull/740): Support reset expressions to prevent an alert from being lowered in severity. Thanks @minhdanh!\n- [#670](https://github.com/influxdata/kapacitor/issues/670): Add ability to supress OK recovery alert events.\n- [#804](https://github.com/influxdata/kapacitor/pull/804): Add API endpoint for refreshing subscriptions.\n    Also fixes issue where subs were not relinked if the sub was deleted.\n    UDP listen ports are closed when a database is dropped.\n\n### Bugfixes\n\n- [#783](https://github.com/influxdata/kapacitor/pull/783): Fix panic when revoking tokens not already defined.\n- [#784](https://github.com/influxdata/kapacitor/pull/784): Fix several issues with comment formatting in TICKscript.\n- [#786](https://github.com/influxdata/kapacitor/issues/786): Deleting tags now updates the group by dimensions if needed.\n- [#772](https://github.com/influxdata/kapacitor/issues/772): Delete task snapshot data when a task is deleted.\n- [#797](https://github.com/influxdata/kapacitor/issues/797): Fix panic from race condition in task master.\n- [#811](https://github.com/influxdata/kapacitor/pull/811): Fix bug where subscriptions + tokens would not work with more than one InfluxDB cluster.\n- [#812](https://github.com/influxdata/kapacitor/issues/812): Upgrade to use protobuf version 3.0.0\n\n## v1.0.0-beta4 [2016-07-27]\n\n### Release Notes\n\n#### Group By Fields\n\nKapacitor now supports grouping by fields.\nFirst convert a field into a tag using the EvalNode.\nThen group by the new tag.\n\nExample:\n\n```go\nstream\n    |from()\n        .measurement('alerts')\n    // Convert field 'level' to tag.\n    |eval(lambda: string(\"level\"))\n        .as('level')\n        .tags('level')\n    // Group by new tag 'level'.\n    |groupBy('alert', 'level')\n    |...\n```\n\nNote the field `level` is now removed from the point since `.keep` was not used.\nSee the [docs](https://docs.influxdata.com/kapacitor/v1.0/nodes/eval_node/#tags) for more details on how `.tags` works.\n\n\n#### Delete Fields or Tags\n\nIn companion with being able to create new tags, you can now delete tags or fields.\n\n\nExample:\n\n```go\nstream\n    |from()\n        .measurement('alerts')\n    |delete()\n        // Remove the field `extra` and tag `uuid` from all points.\n        .field('extra')\n        .tag('uuid')\n    |...\n```\n\n\n\n### Features\n\n- [#702](https://github.com/influxdata/kapacitor/pull/702): Add plumbing for authentication backends.\n- [#624](https://github.com/influxdata/kapacitor/issue/624): BREAKING: Add ability to GroupBy fields. First use EvalNode to create a tag from a field and then group by the new tag.\n    Also allows for grouping by measurement.\n    The breaking change is that the group ID format has changed to allow for the measurement name.\n- [#759](https://github.com/influxdata/kapacitor/pull/759): Add mechanism for token based subscription auth.\n- [#745](https://github.com/influxdata/kapacitor/pull/745): Add if function for tick script, for example: `if(\"value\" > 6, 1, 2)`.\n\n### Bugfixes\n\n- [#710](https://github.com/influxdata/kapacitor/pull/710): Fix infinite loop when parsing unterminated regex in TICKscript.\n- [#711](https://github.com/influxdata/kapacitor/issues/711): Fix where database name with quotes breaks subscription startup logic.\n- [#719](https://github.com/influxdata/kapacitor/pull/719): Fix panic on replay.\n- [#723](https://github.com/influxdata/kapacitor/pull/723): BREAKING: Search for valid configuration on startup in ~/.kapacitor and /etc/kapacitor/.\n    This is so that the -config CLI flag is not required if the configuration is found in a standard location.\n    The configuration file being used is always logged to STDERR.\n- [#298](https://github.com/influxdata/kapacitor/issues/298): BREAKING: Change alert level evaluation so each level is independent and not required to be a subset of the previous level.\n    The breaking change is that expression evaluation order changed.\n    As a result stateful expressions that relied on that order are broken.\n- [#749](https://github.com/influxdata/kapacitor/issues/749): Fix issue with tasks with empty DAG.\n- [#718](https://github.com/influxdata/kapacitor/issues/718): Fix broken extra expressions for deadman's switch.\n- [#752](https://github.com/influxdata/kapacitor/issues/752): Fix various bugs relating to the `fill` operation on a JoinNode.\n    Fill with batches and fill when using the `on` property were broken.\n    Also changes the DefaultNode set defaults for nil fields.\n\n## v1.0.0-beta3 [2016-07-09]\n\n### Release Notes\n\n### Features\n\n- [#662](https://github.com/influxdata/kapacitor/pull/662): Add `-skipVerify` flag to `kapacitor` CLI tool to skip SSL verification.\n- [#680](https://github.com/influxdata/kapacitor/pull/680): Add Telegram Alerting option, thanks @burdandrei!\n- [#46](https://github.com/influxdata/kapacitor/issues/46): Can now create combinations of points within the same stream.\n  This is kind of like join but instead joining a stream with itself.\n- [#669](https://github.com/influxdata/kapacitor/pull/669): Add size function for humanize byte size. thanks @jsvisa!\n- [#697](https://github.com/influxdata/kapacitor/pull/697): Can now flatten a set of points into a single points creating dynamcially named fields.\n- [#698](https://github.com/influxdata/kapacitor/pull/698): Join delimiter can be specified.\n- [#695](https://github.com/influxdata/kapacitor/pull/695): Bash completion filters by enabled disabled status. Thanks @bbczeuz!\n- [#706](https://github.com/influxdata/kapacitor/pull/706): Package UDF agents\n- [#707](https://github.com/influxdata/kapacitor/pull/707): Add size field to BeginBatch struct of UDF protocol. Provides hint as to size of incoming batch.\n\n### Bugfixes\n\n- [#656](https://github.com/influxdata/kapacitor/pull/656): Fix issues where an expression could not be passed as a function parameter in TICKscript.\n- [#627](https://github.com/influxdata/kapacitor/issues/627): Fix where InfluxQL functions that returned a batch could drop tags.\n- [#674](https://github.com/influxdata/kapacitor/issues/674): Fix panic with Join On and batches.\n- [#665](https://github.com/influxdata/kapacitor/issues/665): BREAKING: Fix file mode not being correct for Alert.Log files.\n  Breaking change is that integers numbers prefixed with a 0 in TICKscript are interpreted as octal numbers.\n- [#667](https://github.com/influxdata/kapacitor/issues/667): Align deadman timestamps to interval.\n\n## v1.0.0-beta2 [2016-06-17]\n\n### Release Notes\n\n### Features\n\n- [#636](https://github.com/influxdata/kapacitor/pull/636): Change HTTP logs to be in Common Log format.\n- [#652](https://github.com/influxdata/kapacitor/pull/652): Add optional replay ID to the task API so that you can get information about a task inside a running replay.\n\n### Bugfixes\n\n- [#621](https://github.com/influxdata/kapacitor/pull/621): Fix obscure error about single vs double quotes.\n- [#623](https://github.com/influxdata/kapacitor/pull/623): Fix issues with recording metadata missing data url.\n- [#631](https://github.com/influxdata/kapacitor/issues/631): Fix issues with using iterative lambda expressions in an EvalNode.\n- [#628](https://github.com/influxdata/kapacitor/issues/628): BREAKING: Change `kapacitord config` to not search default location for configuration files but rather require the `-config` option.\n    Since the `kapacitord run` command behaves this way they should be consistent.\n    Fix issue with `kapacitord config > kapacitor.conf` when the output file was a default location for the config.\n- [#626](https://github.com/influxdata/kapacitor/issues/626): Fix issues when changing the ID of an enabled task.\n- [#624](https://github.com/influxdata/kapacitor/pull/624): Fix issues where you could get a read error on a closed UDF socket.\n- [#651](https://github.com/influxdata/kapacitor/pull/651): Fix issues where an error during a batch replay would hang because the task wouldn't stop.\n- [#650](https://github.com/influxdata/kapacitor/pull/650): BREAKING: The default retention policy name was changed to `autogen` in InfluxDB.\n    This changes Kapacitor to use `autogen` for the default retention policy for the stats.\n    You may need to update your task DBRPs to use `autogen` instead of `default`.\n\n\n## v1.0.0-beta1 [2016-06-06]\n\n### Release Notes\n\n#### Template Tasks\n\nThe ability to create and use template tasks has been added.\nyou can define a template for a task and reuse that template across multiple tasks.\n\nA simple example:\n\n```go\n// Which measurement to consume\nvar measurement string\n// Optional where filter\nvar where_filter = lambda: TRUE\n// Optional list of group by dimensions\nvar groups = [*]\n// Which field to process\nvar field string\n// Warning criteria, has access to 'mean' field\nvar warn lambda\n// Critical criteria, has access to 'mean' field\nvar crit lambda\n// How much data to window\nvar window = 5m\n// The slack channel for alerts\nvar slack_channel = '#alerts'\n\nstream\n    |from()\n        .measurement(measurement)\n        .where(where_filter)\n        .groupBy(groups)\n    |window()\n        .period(window)\n        .every(window)\n    |mean(field)\n    |alert()\n         .warn(warn)\n         .crit(crit)\n         .slack()\n         .channel(slack_channel)\n```\n\nThen you can define the template like so:\n\n```\nkapacitor define-template generic_mean_alert -tick path/to/above/script.tick -type stream\n```\n\nNext define a task that uses the template:\n\n```\nkapacitor define cpu_alert -template generic_mean_alert -vars cpu_vars.json -dbrp telegraf.default\n```\n\nWhere `cpu_vars.json` would like like this:\n\n```json\n{\n    \"measurement\": {\"type\" : \"string\", \"value\" : \"cpu\" },\n    \"where_filter\": {\"type\": \"lambda\", \"value\": \"\\\"cpu\\\" == 'cpu-total'\"},\n    \"groups\": {\"type\": \"list\", \"value\": [{\"type\":\"string\", \"value\":\"host\"},{\"type\":\"string\", \"value\":\"dc\"}]},\n    \"field\": {\"type\" : \"string\", \"value\" : \"usage_idle\" },\n    \"warn\": {\"type\" : \"lambda\", \"value\" : \" \\\"mean\\\" < 30.0\" },\n    \"crit\": {\"type\" : \"lambda\", \"value\" : \" \\\"mean\\\" < 10.0\" },\n    \"window\": {\"type\" : \"duration\", \"value\" : \"1m\" },\n    \"slack_channel\": {\"type\" : \"string\", \"value\" : \"#alerts_testing\" }\n}\n```\n\n\n#### Live Replays\n\nWith this release you can now replay data directly against a task from InfluxDB without having to first create a recording.\nReplay the queries defined in the batch task `cpu_alert` for the past 10 hours.\n```sh\nkapacitor replay-live batch -task cpu_alert -past 10h\n```\n\nOr for a stream task with use a query directly:\n\n```sh\nkapacitor replay-live query -task cpu_alert -query 'SELECT usage_idle FROM telegraf.\"default\".cpu WHERE time > now() - 10h'\n```\n\n#### HTTP based subscriptions\n\nNow InfluxDB and Kapacitor support HTTP/S based subscriptions.\nThis means that Kapacitor need only listen on a single port for the HTTP service, greatly simplifying configuration and setup.\n\nIn order to start using HTTP subscriptions change the `subscription-protocol` option for your configured InfluxDB clusters.\n\nFor example:\n\n```\n[[influxdb]]\n  enabled = true\n  urls = [\"http://localhost:8086\",]\n  subscription-protocol = \"http\"\n  # or to use https\n  #subscription-protocol = \"https\"\n```\n\nOn startup Kapacitor will detect the change and recreate the subscriptions in InfluxDB to use the HTTP protocol.\n\n>NOTE: While HTTP itself is a TCP transport such that packet loss shouldn't be an issue, if Kapacitor starts to slow down for whatever reason, InfluxDB will drop the subscription writes to Kapacitor.\nIn order to know if subscription writes are being dropped you should monitor the measurement `_internal.monitor.subscriber` for the field `writeFailures`.\n\n#### Holt-Winters Forecasting\n\nThis release contains an new Holt Winters InfluxQL function.\n\nWith this forecasting method one can now define an alert based off forecasted future values.\n\nFor example, the following TICKscript will take the last 30 days of disk usage stats and using holt-winters forecast the next 7 days.\nIf the forecasted value crosses a threshold an alert is triggered.\n\nThe result is now Kapacitor will alert you 7 days in advance of a disk filling up.\nThis assumes a slow growth but by changing the vars in the script you could check for shorter growth intervals.\n\n```go\n// The interval on which to aggregate the disk usage\nvar growth_interval = 1d\n// The number of `growth_interval`s to forecast into the future\nvar forecast_count = 7\n// The amount of historical data to use for the fit\nvar history = 30d\n\n// The critical threshold on used_percent\nvar threshold = 90.0\n\nbatch\n    |query('''\n    SELECT max(used_percent) as used_percent\n    FROM \"telegraf\".\"default\".\"disk\"\n''')\n        .period(history)\n        .every(growth_interval)\n        .align()\n        .groupBy(time(growth_interval), *)\n    |holtWinters('used_percent', forecast_count, 0, growth_interval)\n        .as('used_percent')\n    |max('used_percent')\n        .as('used_percent')\n    |alert()\n         // Trigger alert if the forecasted disk usage is greater than threshold\n        .crit(lambda: \"used_percent\" > threshold)\n```\n\n\n### Features\n\n- [#283](https://github.com/influxdata/kapacitor/issues/283): Add live replays.\n- [#500](https://github.com/influxdata/kapacitor/issues/500): Support Float,Integer,String and Boolean types.\n- [#82](https://github.com/influxdata/kapacitor/issues/82): Multiple services for PagerDuty alert. thanks @savagegus!\n- [#558](https://github.com/influxdata/kapacitor/pull/558): Preserve fields as well as tags on selector InfluxQL functions.\n- [#259](https://github.com/influxdata/kapacitor/issues/259): Template Tasks have been added.\n- [#562](https://github.com/influxdata/kapacitor/pull/562): HTTP based subscriptions.\n- [#595](https://github.com/influxdata/kapacitor/pull/595): Support counting and summing empty batches to 0.\n- [#596](https://github.com/influxdata/kapacitor/pull/596): Support new group by time offset i.e. time(30s, 5s)\n- [#416](https://github.com/influxdata/kapacitor/issues/416): Track ingress counts by database, retention policy, and measurement. Expose stats via cli.\n- [#586](https://github.com/influxdata/kapacitor/pull/586): Add spread stateful function. thanks @upccup!\n- [#600](https://github.com/influxdata/kapacitor/pull/600): Add close http response after handler laert post, thanks @jsvisa!\n- [#606](https://github.com/influxdata/kapacitor/pull/606): Add Holt-Winters forecasting method.\n- [#605](https://github.com/influxdata/kapacitor/pull/605): BREAKING: StatsNode for batch edge now count the number of points in a batch instead of count batches as a whole.\n    This is only breaking if you have a deadman switch configured on a batch edge.\n- [#611](https://github.com/influxdata/kapacitor/pull/611): Adds bash completion to the kapacitor CLI tool.\n\n\n### Bugfixes\n\n- [#540](https://github.com/influxdata/kapacitor/issues/540): Fixes bug with log level API endpoint.\n- [#521](https://github.com/influxdata/kapacitor/issues/521): EvalNode now honors groups.\n- [#561](https://github.com/influxdata/kapacitor/issues/561): Fixes bug when lambda expressions would return error about types with nested binary expressions.\n- [#555](https://github.com/influxdata/kapacitor/issues/555): Fixes bug where \"time\" functions didn't work in lambda expressions.\n- [#570](https://github.com/influxdata/kapacitor/issues/570): Removes panic in SMTP service on failed close connection.\n- [#587](https://github.com/influxdata/kapacitor/issues/587): Allow number literals without leading zeros.\n- [#584](https://github.com/influxdata/kapacitor/issues/584): Do not block during startup to send usage stats.\n- [#553](https://github.com/influxdata/kapacitor/issues/553): Periodically check if new InfluxDB DBRPs have been created.\n- [#602](https://github.com/influxdata/kapacitor/issues/602): Fix missing To property on email alert handler.\n- [#581](https://github.com/influxdata/kapacitor/issues/581): Record/Replay batch tasks get cluster info from task not API.\n- [#613](https://github.com/influxdata/kapacitor/issues/613): BREAKING: Allow the ID of templates and tasks to be updated via the PATCH method.\n    The breaking change is that now PATCH request return a 200 with the template or task definition, where before they returned 204.\n\n## v0.13.1 [2016-05-13]\n\n### Release Notes\n\n>**Breaking changes may require special upgrade steps from versions <= 0.12, please read the 0.13.0 release notes**\n\nAlong with the API changes of 0.13.0, validation logic was added to task IDs, but this was not well documented.\nThis minor release remedies that.\n\nAll IDs (tasks, recordings, replays) must match this regex `^[-\\._\\p{L}0-9]+$`, which is essentially numbers, unicode letters, '-', '.' and '_'.\n\nIf you have existing tasks which do not match this pattern they should continue to function normally.\n\n### Features\n\n### Bugfixes\n\n- [#545](https://github.com/influxdata/kapacitor/issues/545): Fixes inconsistency with API docs for creating a task.\n- [#544](https://github.com/influxdata/kapacitor/issues/544): Fixes issues with existings tasks and invalid names.\n- [#543](https://github.com/influxdata/kapacitor/issues/543): Fixes default values not being set correctly in API calls.\n\n\n## v0.13.0 [2016-05-11]\n\n### Release Notes\n\n>**Breaking changes may require special upgrade steps please read below.**\n\n#### Upgrade Steps\n\nChanges to how and where task data is store have been made.\nIn order to safely upgrade to version 0.13 you need to follow these steps:\n\n1. Upgrade InfluxDB to version 0.13 first.\n2. Update all TICKscripts to use the new `|` and `@` operators. Once Kapacitor no longer issues any `DEPRECATION` warnings you are ready to begin the upgrade.\nThe upgrade will work without this step but tasks using the old syntax cannot be enabled, until modified to use the new syntax.\n3. Upgrade the Kapacitor binary/package.\n4. Configure new database location. By default the location `/var/lib/kapacitor/kapacitor.db` is chosen for package installs or `./kapacitor.db` for manual installs.\nDo **not** remove the configuration for the location of the old task.db database file since it is still needed to do the migration.\n\n    ```\n    [storage]\n    boltdb = \"/var/lib/kapacitor/kapacitor.db\"\n    ```\n\n5. Restart Kapacitor. At this point Kapacitor will migrate all existing data to the new database file.\nIf any errors occur Kapacitor will log them and fail to startup. This way if Kapacitor starts up you can be sure the migration was a success and can continue normal operation.\nThe old database is opened in read only mode so that existing data cannot be corrupted.\nIts recommended to start Kapacitor in debug logging mode for the migration so you can follow the details of the migration process.\n\nAt this point you may remove the configuration for the old `task` `dir` and restart Kapacitor to ensure everything is working.\nKapacitor will attempt the migration on every startup while the old configuration and db file exist, but will skip any data that was already migrated.\n\n\n#### API Changes\n\nWith this release the API has been updated to what we believe will be the stable version for a 1.0 release.\nSmall changes may still be made but the significant work to create a RESTful HTTP API is complete.\nMany breaking changes introduced, see the [client/API.md](http://github.com/influxdata/kapacitor/blob/master/client/API.md) doc for details on how the API works now.\n\n#### CLI Changes\n\nAlong with the API changes, breaking changes where also made to the `kapacitor` CLI command.\nHere is a break down of the CLI changes:\n\n* Every thing has an ID now: tasks, recordings, even replays.\n    The `name` used before to define a task is now its `ID`.\n    As such instead of using `-name` and `-id` to refer to tasks and recordings,\n    the flags have been changed to `-task` and `-recording` accordingly.\n* Replays can be listed and deleted like tasks and recordings.\n* Replays default to `fast` clock mode.\n* The record and replay commands now have a `-no-wait` option to start but not wait for the recording/replay to complete.\n* Listing recordings and replays displays the status of the respective action.\n* Record and Replay command now have an optional flag `-replay-id`/`-recording-id` to specify the ID of the replay or recording.\n    If not set then a random ID will be chosen like the previous behavior.\n\n#### Notable features\n\nUDF can now be managed externally to Kapacitor via Unix sockets.\nA process or container can be launched independent of Kapacitor exposing a socket.\nOn startup Kapacitor will connect to the socket and begin communication.\n\nExample UDF config for a socket based UDF.\n\n```\n[udf]\n[udf.functions]\n    [udf.functions.myCustomUDF]\n       socket = \"/path/to/socket\"\n       timeout = \"10s\"\n```\n\nAlert data can now be consumed directly from within TICKscripts.\nFor example, let's say we want to store all data that triggered an alert in InfluxDB with a tag `level` containing the level string value (i.e CRITICAL).\n\n```javascript\n...\n    |alert()\n        .warn(...)\n        .crit(...)\n        .levelTag('level')\n        // and/or use a field\n        //.levelField('level')\n        // Also tag the data with the alert ID\n        .idTag('id')\n        // and/or use a field\n        //.idField('id')\n    |influxDBOut()\n        .database('alerts')\n        ...\n```\n\n\n### Features\n\n- [#360](https://github.com/influxdata/kapacitor/pull/360): Forking tasks by measurement in order to improve performance\n- [#386](https://github.com/influxdata/kapacitor/issues/386): Adds official Go HTTP client package.\n- [#399](https://github.com/influxdata/kapacitor/issues/399): Allow disabling of subscriptions.\n- [#417](https://github.com/influxdata/kapacitor/issues/417): UDFs can be connected over a Unix socket. This enables UDFs from across Docker containers.\n- [#451](https://github.com/influxdata/kapacitor/issues/451): StreamNode supports `|groupBy` and `|where` methods.\n- [#93](https://github.com/influxdata/kapacitor/issues/93): AlertNode now outputs data to child nodes. The output data can have either a tag or field indicating the alert level.\n- [#281](https://github.com/influxdata/kapacitor/issues/281): AlertNode now has an `.all()` property that specifies that all points in a batch must match the criteria in order to trigger an alert.\n- [#384](https://github.com/influxdata/kapacitor/issues/384): Add `elapsed` function to compute the time difference between subsequent points.\n- [#230](https://github.com/influxdata/kapacitor/issues/230): Alert.StateChangesOnly now accepts optional duration arg. An alert will be triggered for every interval even if the state has not changed.\n- [#426](https://github.com/influxdata/kapacitor/issues/426): Add `skip-format` query parameter to the `GET /task` endpoint so that returned TICKscript content is left unmodified from the user input.\n- [#388](https://github.com/influxdata/kapacitor/issues/388): The duration of an alert is now tracked and exposed as part of the alert data as well as can be set as a field via `.durationField('duration')`.\n- [#486](https://github.com/influxdata/kapacitor/pull/486): Default config file location.\n- [#461](https://github.com/influxdata/kapacitor/pull/461): Make Alerta `event` property configurable.\n- [#491](https://github.com/influxdata/kapacitor/pull/491): BREAKING: Rewriting stateful expression in order to improve performance, the only breaking change is: short circuit evaluation for booleans - for example: ``lambda: \"bool_value\" && (count() > 100)`` if \"bool_value\" is false, we won't evaluate \"count\".\n- [#504](https://github.com/influxdata/kapacitor/pull/504): BREAKING: Many changes to the API and underlying storage system. This release requires a special upgrade process.\n- [#511](https://github.com/influxdata/kapacitor/pull/511): Adds DefaultNode for providing default values for missing fields or tags.\n- [#285](https://github.com/influxdata/kapacitor/pull/285): Track created,modified and last enabled dates on tasks.\n- [#533](https://github.com/influxdata/kapacitor/pull/533): Add useful statistics for nodes.\n\n### Bugfixes\n\n- [#499](https://github.com/influxdata/kapacitor/issues/499): Fix panic in InfluxQL nodes if field is missing or incorrect type.\n- [#441](https://github.com/influxdata/kapacitor/issues/441): Fix panic in UDF code.\n- [#429](https://github.com/influxdata/kapacitor/issues/429): BREAKING: Change TICKscript parser to be left-associative on equal precedence operators. For example previously this statement `(1+2-3*4/5)` was evaluated as `(1+(2-(3*(4/5))))`\n    which is not the typical/expected behavior. Now using left-associative parsing the statement is evaluated as `((1+2)-((3*4)/5))`.\n- [#456](https://github.com/influxdata/kapacitor/pull/456): Fixes Alerta integration to let server set status, fix `rawData` attribute and set default severity to `indeterminate`.\n- [#425](https://github.com/influxdata/kapacitor/pull/425): BREAKING: Preserving tags on influxql simple selectors - first, last, max, min, percentile\n- [#423](https://github.com/influxdata/kapacitor/issues/423): Recording stream queries with group by now correctly saves data in time order not group by order.\n- [#331](https://github.com/influxdata/kapacitor/issues/331): Fix panic when missing `.as()` for JoinNode.\n- [#523](https://github.com/influxdata/kapacitor/pull/523): JoinNode will now emit join sets as soon as they are ready. If multiple joinable sets arrive in the same tolerance window than each will be emitted (previously the first points were dropped).\n- [#537](https://github.com/influxdata/kapacitor/issues/537): Fix panic in alert node when batch is empty.\n\n## v0.12.0 [2016-04-04]\n\n### Release Notes\n\nNew TICKscript syntax that uses a different operators for chaining methods vs property methods vs UDF methods.\n\n* A chaining method is a method that creates a new node in the pipeline. Uses the `|` operator.\n* A property method is a method that changes a property on a node. Uses the `.` operator.\n* A UDF method is a method that calls out to a UDF. Uses the `@` operator.\n\nFor example below the `from`, `mean`, and `alert` methods create new nodes,\nthe `detectAnomalies` method calls a UDF,\nand the other methods modify the nodes as property methods.\n\n```javascript\nstream\n    |from()\n        .measurement('cpu')\n        .where(lambda: \"cpu\" == 'cpu-total')\n    |mean('usage_idle')\n        .as('value')\n    @detectAnomalies()\n        .field('mean')\n    |alert()\n        .crit(lambda: \"anomaly_score\" > 10)\n        .log('/tmp/cpu.log')\n```\n\nWith this change a new binary is provided with Kapacitor `tickfmt` which will\nformat a TICKscript file according to a common standard.\n\n\n### Features\n\n- [#299](https://github.com/influxdata/kapacitor/issues/299): Changes TICKscript chaining method operators and adds `tickfmt` binary.\n- [#389](https://github.com/influxdata/kapacitor/pull/389): Adds benchmarks to Kapacitor for basic use cases.\n- [#390](https://github.com/influxdata/kapacitor/issues/390): BREAKING: Remove old `.mapReduce` functions.\n- [#381](https://github.com/influxdata/kapacitor/pull/381): Adding enable/disable/delete/reload tasks by glob.\n- [#401](https://github.com/influxdata/kapacitor/issues/401): Add `.align()` property to BatchNode so you can align query start and stop times.\n\n### Bugfixes\n\n- [#378](https://github.com/influxdata/kapacitor/issues/378): Fix issue where derivative would divide by zero.\n- [#387](https://github.com/influxdata/kapacitor/issues/387): Add `.quiet()` option to EvalNode so errors can be suppressed if expected.\n- [#400](https://github.com/influxdata/kapacitor/issues/400): All query/connection errors are counted and reported in BatchNode stats.\n- [#412](https://github.com/influxdata/kapacitor/pull/412): Fix issues with batch queries dropping points because of nil fields.\n- [#413](https://github.com/influxdata/kapacitor/pull/413): Allow disambiguation between \".groupBy\" and \"|groupBy\".\n\n\n## v0.11.0 [2016-03-22]\n\n### Release Notes\n\nKapacitor is now using the functions from the new query engine in InfluxDB core.\nAlong with this change is a change in the TICKscript API so that using the InfluxQL functions is easier.\nSimply call the desired method directly no need to call `.mapReduce` explicitly.\nThis change now hides the mapReduce aspect and handles it internally.\nUsing `.mapReduce` is officially deprecated in this release and will be remove in the next major release.\nWe feel that this change improves the readability of TICKscripts and exposes less implementation details\nto the end user.\nUpdating your exising TICKscripts is simple.\nIf previously you had code like this:\n\n```javascript\nstream.from()...\n    .window()...\n    .mapReduce(influxql.count('value'))\n```\nthen update it to look like this:\n\n```javascript\nstream.from()...\n    .window()...\n    .count('value')\n```\n\na simple regex could fix all your existing scripts.\n\nKapacitor now exposes more internal metrics for determining the performance of a given task.\nThe internal statistics includes a new measurement named `node` that contains any stats a node provides, tagged by the task, node, task type and kind of node (i.e. window vs union).\nAll nodes provide an averaged execution time for the node.\nThese stats are also available in the DOT output of the Kapacitor show command.\n\nSignificant performance improvements have also been added.\nIn some cases Kapacitor throughput has improved by 4X.\n\nKapacitor can now connect to different InfluxDB clusters.\nMultiple InfluxDB config sections can be defined and one will be marked as default.\nTo upgrade convert an `influxdb` config.\n\nFrom this:\n\n```\n[influxdb]\n  enabled = true\n  ...\n```\n\nto this:\n\n```\n[[influxdb]]\n  enabled = true\n  default = true\n  name = \"localhost\"\n  ...\n```\n\nVarious improvements to joining features have been implemented.\nWith #144 you can now join streams with differing group by dimensions.\n\nIf you previously configured Email, Slack or HipChat globally now you must also set the `state-changes-only` option to true as well if you want to preserve the original behavior.\nFor example:\n\n```\n[slack]\n   enable = true\n   global = true\n   state-changes-only = true\n```\n\n### Features\n- [#236](https://github.com/influxdata/kapacitor/issues/236): Implement batched group by\n- [#231](https://github.com/influxdata/kapacitor/pull/231): Add ShiftNode so values can be shifted in time for joining/comparisons.\n- [#190](https://github.com/influxdata/kapacitor/issues/190): BREAKING: Deadman's switch now triggers off emitted counts and is grouped by to original grouping of the data.\n    The breaking change is that the 'collected' stat is no longer output for `.stats` and has been replaced by `emitted`.\n- [#145](https://github.com/influxdata/kapacitor/issues/145): The InfluxDB Out Node now writes data to InfluxDB in buffers.\n- [#215](https://github.com/influxdata/kapacitor/issues/215): Add performance metrics to nodes for average execution times and node throughput values.\n- [#144](https://github.com/influxdata/kapacitor/issues/144): Can now join streams with differing dimensions using the join.On property.\n- [#249](https://github.com/influxdata/kapacitor/issues/249): Can now use InfluxQL functions directly instead of via the MapReduce method. Example `stream.from().count()`.\n- [#233](https://github.com/influxdata/kapacitor/issues/233): BREAKING: Now you can use multiple InfluxDB clusters. The config changes to make this possible are breaking. See notes above for changes.\n- [#302](https://github.com/influxdata/kapacitor/issues/302): Can now use .Time in alert message.\n- [#239](https://github.com/influxdata/kapacitor/issues/239): Support more detailed TLS config when connecting to an InfluxDB host.\n- [#323](https://github.com/influxdata/kapacitor/pull/323): Stats for task execution are provided via JSON HTTP request instead of just DOT string. thanks @yosiat\n- [#358](https://github.com/influxdata/kapacitor/issues/358): Improved logging. Adds LogNode so any data in a pipeline can be logged.\n- [#366](https://github.com/influxdata/kapacitor/issues/366): HttpOutNode now allows chaining methods.\n\n\n### Bugfixes\n- [#199](https://github.com/influxdata/kapacitor/issues/199): BREAKING: Various fixes for the Alerta integration.\n    The `event` property has been removed from the Alerta node and is now set as the value of the alert ID.\n- [#232](https://github.com/influxdata/kapacitor/issues/232): Better error message for alert integrations. Better error message for VictorOps 404 response.\n- [#231](https://github.com/influxdata/kapacitor/issues/231): Fix window logic when there were gaps in the data stream longer than window every value.\n- [#213](https://github.com/influxdata/kapacitor/issues/231): Add SourceStreamNode so that yuou must always first call `.from` on the `stream` object before filtering it, so as to not create confusing to understand TICKscripts.\n- [#255](https://github.com/influxdata/kapacitor/issues/255): Add OPTIONS handler for task delete method so it can be preflighted.\n- [#258](https://github.com/influxdata/kapacitor/issues/258): Fix UDP internal metrics, change subscriptions to use clusterID.\n- [#240](https://github.com/influxdata/kapacitor/issues/240): BREAKING: Fix issues with Sensu integration. The breaking change is that the config no longer takes a `url` but rather a `host` option since the communication is raw TCP rather HTTP.\n- [#270](https://github.com/influxdata/kapacitor/issues/270): The HTTP server will now gracefully stop.\n- [#300](https://github.com/influxdata/kapacitor/issues/300): Add OPTIONS method to /recording endpoint for deletes.\n- [#304](https://github.com/influxdata/kapacitor/issues/304): Fix panic if recording query but do not have an InfluxDB instance configured\n- [#289](https://github.com/influxdata/kapacitor/issues/289): Add better error handling to batch node.\n- [#142](https://github.com/influxdata/kapacitor/issues/142): Fixes bug when defining multiple influxdb hosts.\n- [#266](https://github.com/influxdata/kapacitor/issues/266): Fixes error log for HipChat that is not an error.\n- [#333](https://github.com/influxdata/kapacitor/issues/333): Fixes hang when replaying with .stats node. Fixes issues with batch and stats.\n- [#340](https://github.com/influxdata/kapacitor/issues/340): BREAKING: Decouples global setting for alert handlers from the state changes only setting.\n- [#348](https://github.com/influxdata/kapacitor/issues/348): config.go: refactor to simplify structure and fix support for array elements\n- [#362](https://github.com/influxdata/kapacitor/issues/362): Fix bug with join tolerance and batches.\n\n## v0.10.1 [2016-02-08]\n\n### Release Notes\n\nThis is a bug fix release that fixes many issues releated to the recent 0.10.0 release.\nThe few additional features are focused on usability improvements from recent feedback.\n\nImproved UDFs, lots of bug fixes and improvements on the API. There was a breaking change for UDFs protobuf messages, see #176.\n\nThere was a breaking change to the `define` command, see [#173](https://github.com/influxdata/kapacitor/issues/173) below.\n\n### Features\n\n- [#176](https://github.com/influxdata/kapacitor/issues/176): BREAKING: Improved UDFs and groups. Now it is easy to deal with groups from the UDF process.\n    There is a breaking change in the BeginBatch protobuf message for this change.\n- [#196](https://github.com/influxdata/kapacitor/issues/196): Adds a 'details' property to the alert node so that the email body can be defined. See also [#75](https://github.com/influxdata/kapacitor/issues/75).\n- [#132](https://github.com/influxdata/kapacitor/issues/132): Make is so multiple calls to `where` simply `AND` expressions together instead of replacing or creating extra nodes in the pipeline.\n- [#173](https://github.com/influxdata/kapacitor/issues/173): BREAKING: Added a `-no-reload` flag to the define command in the CLI. Now if the task is enabled define will automatically reload it unless `-no-reload` is passed.\n- [#194](https://github.com/influxdata/kapacitor/pull/194): Adds Talk integration for alerts. Thanks @wutaizeng!\n- [#320](https://github.com/influxdata/kapacitor/pull/320): Upgrade to go 1.6\n\n### Bugfixes\n\n- [#177](https://github.com/influxdata/kapacitor/issues/177): Fix panic for show command on batch tasks.\n- [#185](https://github.com/influxdata/kapacitor/issues/185): Fix panic in define command with invalid dbrp value.\n- [#195](https://github.com/influxdata/kapacitor/issues/195): Fix panic in where node.\n- [#208](https://github.com/influxdata/kapacitor/issues/208): Add default stats dbrp to default subscription excludes.\n- [#203](https://github.com/influxdata/kapacitor/issues/203): Fix hang when deleteing invalid batch task.\n- [#182](https://github.com/influxdata/kapacitor/issues/182): Fix missing/incorrect Content-Type headers for various HTTP endpoints.\n- [#187](https://github.com/influxdata/kapacitor/issues/187): Retry connecting to InfluxDB on startup for up to 5 minutes by default.\n\n## v0.10.0 [2016-01-26]\n\n### Release Notes\n\nThis release marks the next major release of Kapacitor.\nWith this release you can now run your own custom code for processing data within Kapacitor.\nSee [udf/agent/README.md](https://github.com/influxdata/kapacitor/blob/master/udf/agent/README.md) for more details.\n\nWith the addition of UDFs it is now possible to run custom anomaly detection alogrithms suited to your needs.\nThere are simple examples of how to use UDFs in [udf/agent/examples](https://github.com/influxdata/kapacitor/tree/master/udf/agent/examples/).\n\nThe version has jumped significantly so that it is inline with other projects in the TICK stack.\nThis way you can easily tell which versions of Telegraf, InfluxDB, Chronograf and Kapacitor work together.\n\nSee note on a breaking change in the HTTP API below. #163\n\n\n### Features\n- [#137](https://github.com/influxdata/kapacitor/issues/137): Add deadman's switch. Can be setup via TICKscript and globally via configuration.\n- [#72](https://github.com/influxdata/kapacitor/issues/72): Add support for User Defined Functions (UDFs).\n- [#139](https://github.com/influxdata/kapacitor/issues/139): Alerta.io support thanks! @md14454\n- [#85](https://github.com/influxdata/kapacitor/issues/85): Sensu support using JIT clients. Thanks @sstarcher!\n- [#141](https://github.com/influxdata/kapacitor/issues/141): Time of day expressions for silencing alerts.\n\n### Bugfixes\n- [#153](https://github.com/influxdata/kapacitor/issues/153): Fix panic if referencing non existant field in MapReduce function.\n- [#138](https://github.com/influxdata/kapacitor/issues/138): Change over to influxdata github org.\n- [#164](https://github.com/influxdata/kapacitor/issues/164): Update imports etc from InfluxDB as per the new meta store/client changes.\n- [#163](https://github.com/influxdata/kapacitor/issues/163): BREAKING CHANGE: Removed the 'api/v1' pathing from the HTTP API so that Kapacitor is\n    path compatible with InfluxDB. While this is a breaking change the kapacitor cli has been updated accordingly and you will not experience any distruptions unless you\n    were calling the HTTP API directly.\n- [#147](https://github.com/influxdata/kapacitor/issues/147): Compress .tar archives from builds.\n\n## v0.2.4 [2016-01-07]\n\n### Release Notes\n\n### Features\n- [#118](https://github.com/influxdata/kapacitor/issues/118): Can now define multiple handlers of the same type on an AlertNode.\n- [#119](https://github.com/influxdata/kapacitor/issues/119): HipChat support thanks! @ericiles *2\n- [#113](https://github.com/influxdata/kapacitor/issues/113): OpsGenie support thanks! @ericiles\n- [#107](https://github.com/influxdata/kapacitor/issues/107): Enable TICKscript variables to be defined and then referenced from lambda expressions.\n        Also fixes various bugs around using regexes.\n\n### Bugfixes\n- [#124](https://github.com/influxdata/kapacitor/issues/124): Fix panic where there is an error starting a task.\n- [#122](https://github.com/influxdata/kapacitor/issues/122): Fixes panic when using WhereNode.\n- [#128](https://github.com/influxdata/kapacitor/issues/128): Fix not sending emails when using recipient list from config.\n\n## v0.2.3 [2015-12-22]\n\n### Release Notes\n\nBugfix #106 made a breaking change to the internal HTTP API. This was to facilitate integration testing and overall better design.\nNow POSTing a recording request will start the recording and immediately return. If you want to wait till it is complete do\na GET for the recording info and it will block until its complete. The kapacitor cli has been updated accordingly.\n\n### Features\n- [#96](https://github.com/influxdata/kapacitor/issues/96): Use KAPACITOR_URL env var for setting the kapacitord url in the client.\n- [#109](https://github.com/influxdata/kapacitor/pull/109): Add throughput counts to DOT format in `kapacitor show` command, if task is executing.\n\n### Bugfixes\n- [#102](https://github.com/influxdata/kapacitor/issues/102): Fix race when start/stoping timeTicker in batch.go\n- [#106](https://github.com/influxdata/kapacitor/pull/106): Fix hang when replaying stream recording.\n\n\n## v0.2.2 [2015-12-16]\n\n### Release Notes\n\nSome bug fixes including one that cause Kapacitor to deadlock.\n\n### Features\n- [#83](https://github.com/influxdata/kapacitor/pull/83): Use enterprise usage client, remove deprecated enterprise register and reporting features.\n\n### Bugfixes\n\n- [#86](https://github.com/influxdata/kapacitor/issues/86): Fix dealock form errors in tasks. Also fixes issue where task failures did not get logged.\n- [#95](https://github.com/influxdata/kapacitor/pull/95): Fix race in bolt usage when starting enabled tasks at startup.\n\n## v0.2.0 [2015-12-8]\n\n### Release Notes\n\nMajor public release.\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 9.17578125,
          "content": "Contributing to Kapacitor\n=========================\n\nBug reports\n---------------\nBefore you file an issue, please search existing issues in case it has already been filed, or perhaps even fixed.\nIf you file an issue, please include the following.\n* Full details of your operating system (or distribution) e.g. 64-bit Ubuntu 14.04.\n* The version of Kapacitor you are running\n* Whether you installed it using a pre-built package, or built it from source.\n* A small test case, if applicable, that demonstrates the issues.\n\nRemember the golden rule of bug reports: **The easier you make it for us to reproduce the problem, the faster it will get fixed.**\nIf you have never written a bug report before, or if you want to brush up on your bug reporting skills, we recommend reading [Simon Tatham's essay \"How to Report Bugs Effectively.\"](http://www.chiark.greenend.org.uk/~sgtatham/bugs.html)\n\nPlease note that issues are *not the place to file general questions* such as \"how do I use InfluxDB with Kapacitor?\" Questions of this nature should be sent to the [Google Group](https://groups.google.com/forum/#!forum/influxdb), not filed as issues. Issues like this will be closed.\n\nFeature requests\n---------------\nWe really like to receive feature requests, as it helps us prioritize our work.\nPlease be clear about your requirements, as incomplete feature requests may simply be closed if we don't understand what you would like to see added to Kapacitor.\n\nContributing to the source code\n---------------\n\nKapacitor follows standard Go project structure.\nThis means that all your go development are done in `$GOPATH/src`.\nGOPATH can be any directory under which InfluxDB and all its dependencies will be cloned.\nFor more details on recommended go project's structure, see [How to Write Go Code](http://golang.org/doc/code.html) and\n[Go: Best Practices for Production Environments](http://peter.bourgon.org/go-in-production/), or you can just follow the steps below.\n\nSubmitting a pull request\n------------\nTo submit a pull request you should fork the Kapacitor repository, and make your change on a feature branch of your fork.\nThen generate a pull request from your branch against *master* of the Kapacitor repository.\nInclude in your pull request details of your change -- the why *and* the how -- as well as the testing your performed.\nAlso, be sure to run the test suite with your change in place. Changes that cause tests to fail cannot be merged.\n\nThere will usually be some back and forth as we finalize the change, but once that completes it may be merged.\n\nTo assist in review for the PR, please add the following to your pull request comment:\n\n```md\n- [ ] CHANGELOG.md updated\n- [ ] Rebased/mergable\n- [ ] Tests pass\n- [ ] Sign [CLA](http://influxdb.com/community/cla.html) (if not already signed)\n```\n\nUse of third-party packages\n---------------------------\nA third-party package is defined as one that is not part of the standard Go distribution.\nGenerally speaking we prefer to minimize our use of third-party packages, and avoid them unless absolutely necessarily.\nWe'll often write a little bit of code rather than pull in a third-party package.\nSo to maximise the chance your change will be accepted by us, use only the standard libraries, or the third-party packages we have decided to use.\n\nFor rationale, check out the post [The Case Against Third Party Libraries](http://blog.gopheracademy.com/advent-2014/case-against-3pl/).\n\nSigning the CLA\n---------------\n\nIf you are going to be contributing back to Kapacitor please take a second to sign our CLA, which can be found\n[on our website](https://www.influxdata.com/legal/cla/).\n\nInstalling Go\n-------------\n\nKapacitor typically requires the lastest version of Go.\n\nTo install go see https://golang.org/dl/\n\nGetting the source\n------\nSetup the project structure and fetch the repo like so:\n\n    mkdir $HOME/go\n    export GOPATH=$HOME/go\n    go get github.com/influxdata/kapacitor\n\nYou can add the line `export GOPATH=$HOME/go` to your bash/zsh file to be set for every shell instead of having to manually run it everytime.\n\nCloning a fork\n-------------\nIf you wish to work with fork of Kapacitor, your own fork for example, you must still follow the directory structure above.\nBut instead of cloning the main repo, instead clone your fork. Follow the steps below to work with a fork:\n\n    export GOPATH=$HOME/go\n    mkdir -p $GOPATH/src/github.com/influxdata\n    cd $GOPATH/src/github.com/influxdata\n    git clone git@github.com:<username>/kapacitor.git\n\nRetaining the directory structure `$GOPATH/src/github.com/influxdata` is necessary so that Go imports work correctly.\n\nPre-commit checks\n-------------\n\nWe have a pre-commit hook to make sure code is formatted properly and vetted before you commit any changes. We strongly recommend using the pre-commit hook to guard against accidentally committing unformatted code. To use the pre-commit hook, run the following:\n\n    cd $GOPATH/src/github.com/influxdata/kapacitor\n    cp .hooks/pre-commit .git/hooks/\n\nIn case the commit is rejected because it's not formatted you can run\nthe following to format the code:\n\n```\ngo fmt ./...\ngo vet ./...\n```\n\nFor more information on `go vet`, [read the GoDoc](https://golang.org/pkg/cmd/go/internal/vet/).\n\nBuild and Test\n--------------\n\nMake sure you have Go installed and the project structure as shown above. To then build the project, execute the following commands:\n\n```bash\ncd $GOPATH/src/github.com/influxdata/kapacitor\ngo build ./cmd/kapacitor\ngo build ./cmd/kapacitord\n```\nKapacitor builds two binares is named `kapacitor`, and `kapacitord`.\n\nTo run the tests, execute the following commands:\n\n```\nexport CIRCLE_BUILD_NUM=0 CIRCLE_NODE_INDEX=0 CIRCLE_NODE_TOTAL=1\n./circle-test.sh\n```\n\nDependencies\n------------\n\nKapacitor vendors all dependencies.\nKapacitor uses the golang [dep](https://github.com/golang/dep) tool.\n\nInstall the dep tool:\n\n```\ngo get -v -u github.com/golang/dep/cmd/dep\n```\n\nSee the dep help for usage and documentation.\n\nKapacitor commits vendored deps into the repo, as a result always run `dep prune` after any `dep ensure` operation.\nThis helps keep the amount of code committed to a minimum.\n\n\nGenerating Code\n---------------\n\nKapacitor uses generated code.\nThe generated code is committed to the repository so normally it is not necessary to regenerate it.\nBut if you modify one of the templates for code generation you must re-run the generate commands.\n\nGo provides a consistent command for generating all necessary code:\n\n```bash\ngo generate ./...\n```\n\nFor the generate command to succeed you will need a few dependencies installed on your system.\nThese dependencies are already vendored in the code and and can be installed from there.\n\n* tmpl -- A utility used to generate code from templates. Install via `go install ./vendor/github.com/benbjohnson/tmpl`\n* protoc + protoc-gen-go -- A protobuf compiler plus the protoc-gen-go extension.\n    You need version 3.0.0 of protoc.\n    To install the go plugin run `go install ./vendor/google.golang.org/protobuf/cmd/protoc-gen-go`\n\nThe Build Script\n----------------\n\nThe above commands have all be encapsulated for you in a `build.py` script.\nThe script has flags for testing code, building binaries and complete distribution packages.\n\nTo build kapacitor use:\n\n```bash\n./build.py\n```\n\nTo run the tests use:\n\n```bash\n./build.py --test\n```\n\nIf you want to generate code run:\n\n```bash\n./build.py --generate\n```\n\nIf you want to build packages run:\n\n```bash\n./build.py --package\n```\n\nThere are many more options available see\n\n```bash\n./build.py --help\n```\n\n\nThe Build Script + Docker\n-------------------------\n\nKapacitor requires a few extra dependencies to perform certain build actions.\nSpecifically to build packages or to regenerate any of the generated code you will need a few extra tools.\nA `build.sh` script is provided that will run `build.py` in a docker container with all the needed dependencies installed with correct versions.\n\nAll you need is to have docker installed and then use the `./build.sh` command as if it were the `./build.py` command.\n\n\nProfiling\n---------\nWhen troubleshooting problems with CPU or memory the Go toolchain can be helpful. You can start InfluxDB with CPU or memory profiling turned on. For example:\n\n```sh\n# start kapacitord with profiling\n./kapacitord -cpuprofile kapacitord.prof\n# run task, replays whatever you're testing\n# Quit out of kapacitord and kapacitord.prof will then be written.\n# open up pprof to examine the profiling data.\ngo tool pprof ./kapacitord kapacitord.prof\n# once inside run \"web\", opens up browser with the CPU graph\n# can also run \"web <function name>\" to zoom in. Or \"list <function name>\" to see specific lines\n```\nNote that when you pass the binary to `go tool pprof` *you must specify the path to the binary*.\n\nContinuous Integration testing\n------------------------------\nKapacitor uses CircleCI for continuous integration testing.\n\nUseful links\n------------\n- [Useful techniques in Go](http://arslan.io/ten-useful-techniques-in-go)\n- [Go in production](http://peter.bourgon.org/go-in-production/)\n- [Principles of designing Go APIs with channels](https://inconshreveable.com/07-08-2014/principles-of-designing-go-apis-with-channels/)\n- [Common mistakes in Golang](http://soryy.com/blog/2014/common-mistakes-with-go-lang/). Especially this section `Loops, Closures, and Local Variables`\n"
        },
        {
          "name": "DESIGN.md",
          "type": "blob",
          "size": 8.95703125,
          "content": "# Kapacitor Internal Design\n\nThis document is meant to layout both the high level design of Kapacitor as well and discuss the details\nof the implementation.\n\nIt should be accessible to someone wanting to contribute to Kapacitor.\n\n\n## Topic\n\n* Key Concepts\n* Data Flow -- How data flows through Kapacitor\n* TICKscript -- How TICKscript is implemented (not written yet)\n* kapacitord/kapacitor -- How the daemon ties all the pieces together. (not written yet)\n\n\n## Key Concepts\n\nKapacitor is a framework for processing time series data.\nIt follows a [flow based programing](https://en.wikipedia.org/wiki/Flow-based_programming) model.\nData flows from node to node and each node is a *black box* process that can manipulate the data in any way.\nThe data model used to transport data from node to node matches the schema used by InfluxDB, namely measurements, tags and fields.\nNodes can be arranged in a directed acyclic graph [(DAG)](https://en.wikipedia.org/wiki/Directed_acyclic_graph).\n\n### Tasks\n\nUsers define tasks for Kapacitor to run.\nA task defines a DAG of nodes that process the data.\nThis task is defined via a DSL named TICKscript.\nTo learn more about how to use and interact with Kapacitor see the [docs](https://docs.influxdata.com/kapacitor/).\n\nA task defines a potentially infinite amount of work to be done.\nThe amount work is determined by the data that is received by the task.\nOnce the source data stream is *closed* the task is complete.\nIt is normal for a task to never complete but rather run indefinitely.\nAs a result, tasks can be in one of three states, disabled, enabled not executing, and enabled executing.\nAn enabled task is not executing if it encountered an error or its data source was closed.\n\n## Data Flow\n\nData flows from node to node and each node is a black box that can process the data the however it sees fit.\nIn order for a system like this to work the transport method and data model needs to be well defined.\n\n### Models\n\nThe data model for transporting data has two types:\n\n* Stream -- Data points are passed as single entities.\n* Batch -- Data points are passed in groups of data.\n\nA batch consists of a type that describes the common attributes of all data points within the batch\nand a list of all the individual data points.\n\nA data point consists of a timestamp, a map of fields, and a map of tags.\nWhen data points are transferred as a stream not within the context of a batch they\nalso contain information on their scope, i.e database, retention policy and measurement.\nThis data model is schemaless in that the names of fields and tags are arbitrary and opaque to Kapacitor.\n\nLastly both batches and streamed data points contain information about the *group* they belong two if\nthe data set has been grouped by any number of dimensions. More on that later.\n\n### Time\n\nTime is measured based on the timestamps of the data flowing through a node.\nIf data flow stops so does time.\nIf a node performs a transformation dependent on time then it is always consistent based on a given data set.\n\n### Edges\n\nKapacitor models data transfer along *edges*.\nAn edge connects exactly two nodes and data flows from the *parent* node to the *child* node.\nThere are two actions performed on an edge:\n\n* Collect -- The parent presents a data point for the edge to consume.\n* Emit -- The child retrieves a data point from the edge.\n\nFrom the perspective of an *edge* data is collected from a parent and then emitted to a child.\nFrom the perspective of a *node*, data is pulled off from any number of parent\nedges and collected into any number of child edges.\nNodes, not edges, control the flow of the data. Edges simply provide the transport mechanism.\nMeaning that if a child node stops pulling data from its parent edge, data flow stops.\n\nEdges are typed, meaning that a given edge only transports a certain type of data, i.e. streams or batches.\nNodes are said to *want* parent edges of a certain type and to *provide* child edges of a certain type.\nA node can want and provide the same or different type of edges. For example the `WindowNode` wants a stream edge\nwhile providing a batch edge.\n\nModeling data flow through edges allows for the transport mechanism to be abstracted.\nIf the data is being transferred within the same process then it can be sent via in-memory structures;\nif the data is being transferred to another Kapacitor host it can be serialized and transferred accordingly.\n\nThe current implementation of an edge uses Go channels and can be found in `edge.go`.\nThere are three channel per edge instance but only ever one channel is non nil based on the type of the edge.\nDirect access to the channel is not provided but rather wrapper methods for collecting and emitting the data.\nThis allows for the edge to keep counts on throughput and be aborted at any point.\nThe channels are currently unbuffered, this will probably need to change eventually, but for now the simplicity is useful.\n\nPassing batch data can be accomplished in one of two ways.\nFirst, pass the data as a single object containing the complete batch and all points.\nSecond, pass marker objects that indicate the beginning and end of batches and stream individual points between the markers.\nThe marker objects can also contain the common data to the batch.\nCurrently the first option is used.\nThis has the advantage that fewer objects are passing through the channels.\nIt also works better with the current map-reduce functions in core sense they expect all the data in a single object.\nIt has the disadvantage that the whole batch has to be held in memory.\nIn some cases the entire batch does need to live in memory but not in all.\nFor example a node that is counting points per batch need only maintain a counter in memory and not the entire batch.\n\n### Source Mapping\n\nKapacitor can receive data from many different sources, including querying InfluxDB.\nThe type TaskMaster in`task_master.go` is responsible for managing which tasks are receiving which data.\n\nFor stream tasks this is done by having on global edge.\nAll sources (graphite, collectd, http, etc) write their data to the TaskMaster, who writes the data to the global *stream* edge.\nWhen a stream task is started it gets a *fork* of the global stream filtered down by the databases and retention policies its allowed to access.\nThen the task can further process the data stream.\n\nIn the case of the batch tasks, the TaskMaster manages starting the schedules for querying InfluxDB.\nThe results of the queries are passed to the root nodes of the task directly.\n\n\n### Windowing\n\nWindowing data is an important piece to creating pipelines.\nWindowing is concerned with how you can slice a data stream into multiple windows and is orthogonal to how batches are transferred.\nKapacitor handles windowing explicitly, by allowing the user to define a WindowNode\nthat has two parameters. First, the `period` is the length of the window in time.\nSecond, the `every` property defines how often an window should be emitted into the stream.\nThis allows for creating windows that overlap, have no overlap, or have gaps between the windows.\nAs a result the concept of a window does not exist inherently in the data stream, but rather windowing is the method of converting a stream of data into a batch of data.\n\nExample TICKscript:\n\n```javascript\nstream\n    .window()\n        .period(10s)\n        .every(5s)\n```\n\nThe above script slices the incoming stream into overlapping windows.\nEach window contains the last 10s of data and a new window is emitted every 5s.\n\n\n### Challenges\n\nChallenges with the current implementation:\n\n* For stream tasks: If a single node stop processing data all nodes will eventually stop including nodes from other tasks.\n    This is because of the global stream to aggregate all incoming sources and the fact the edges just block instead of dropping data.\n    This could be mitigated further by creating independent streams for each database retention policy pair, but this only provides isolation and not a solution.\n    We need a contract in place for what to do when a given node stops processing data.\n* Nodes are responsible for not creating deadlock in the way they read and write data from their parent and child edges.\n    For example the `JoinNode` has multiple parents and has to guarantee that the goroutines that are reading from the parents never block on each other.\n    Otherwise a deadlock can be created since a parent may be blocked writing to the JoinNode while the JoinNode is blocked reading from a different parent.\n    Since both parents could have a common ancestor the blocked parent will eventually block the ancestor which in turn will block the other parent.\n* Fragile, so far the smallest of changes to the way the system work almost always results in a deadlock, because of the order of processing data.\n* If data flow stops so does time. In many use cases this is exactly what you want, but in some cases you would still like the data in transit to be flushed out.\n    As for monitoring the throughput of tasks this is possible out-of-band of the task so even if the task stop processing data you can still trigger an event in a different task.\n"
        },
        {
          "name": "Dockerfile_build_ubuntu64",
          "type": "blob",
          "size": 0.974609375,
          "content": "FROM quay.io/influxdb/builder:kapacitor-20240919\n\n# This dockerfile is capabable of performing all\n# build/test/package/deploy actions needed for Kapacitor.\n\nMAINTAINER support@influxdb.com\n\n# Install protobuf3 python library\n# NOTE: PROTO_VERSION env var is inherited from the parent builder image.\nRUN wget -q https://github.com/google/protobuf/releases/download/v${PROTO_VERSION}/protobuf-python-${PROTO_VERSION}.tar.gz \\\n    && tar -xf protobuf-python-${PROTO_VERSION}.tar.gz \\\n    && cd protobuf-${PROTO_VERSION}/python \\\n    && python2 setup.py install \\\n    && python3 setup.py install \\\n    && cd ../../ \\\n    && rm -rf /protobuf-${PROTO_VERSION} protobuf-python-${PROTO_VERSION}.tar.gz\n\nENV PROJECT_DIR=/kapacitor\nRUN mkdir -p $PROJECT_DIR\nWORKDIR $PROJECT_DIR\n\n# Configure local git\nRUN git config --global --add safe.directory $PROJECT_DIR\nRUN git config --global user.email \"support@influxdb.com\"\nRUN git config --global user.Name \"Docker Builder\"\n\nENTRYPOINT [ \"/kapacitor/build.py\" ]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0625,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2015-2018 InfluxData Inc.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n"
        },
        {
          "name": "LICENSE_OF_DEPENDENCIES.md",
          "type": "blob",
          "size": 2.2587890625,
          "content": "Dependencies\n============\n\n* github.com/BurntSushi/toml [MIT](https://github.com/BurntSushi/toml/blob/master/COPYING)\n* github.com/boltdb/bolt [MIT](https://github.com/boltdb/bolt/blob/master/LICENSE)\n* github.com/cenkalti/backoff [MIT](https://github.com/cenkalti/backoff/blob/master/LICENSE)\n* github.com/golang-jwt/jwt [MIT](https://github.com/golang-jwt/jwt/blob/master/LICENSE)\n* github.com/dustin/go-humanize [MIT](https://github.com/dustin/go-humanize/blob/master/LICENSE)\n* github.com/google/uuid [BSD](https://github.com/google/uuid/blob/master/LICENSE)\n* github.com/gorhill/cronexpr [APLv2](https://github.com/gorhill/cronexpr/blob/master/APLv2)\n* github.com/k-sone/snmpgo [MIT](https://github.com/k-sone/snmpgo/blob/master/LICENSE)\n* github.com/kimor79/gollectd [BSD](https://github.com/kimor79/gollectd/blob/master/LICENSE)\n* github.com/mattn/go-runewidth [MIT](https://github.com/mattn/go-runewidth/blob/master/README.mkd)\n* github.com/mitchellh/copystructure[MIT](https://github.com/mitchellh/copystructure/blob/master/LICENSE)\n* github.com/mitchellh/reflectwalk [MIT](https://github.com/mitchellh/reflectwalk/blob/master/LICENSE)\n* github.com/pkg/errors [BSD](https://github.com/pkg/errors/blob/master/LICENSE)\n* github.com/russross/blackfriday [BSD](https://github.com/russross/blackfriday/blob/master/LICENSE.txt)\n* github.com/segmentio/kafka-go [MIT](https://github.com/segmentio/kafka-go/blob/master/LICENSE)\n* github.com/serenize/snaker [MIT](https://github.com/serenize/snaker/blob/master/LICENSE.txt)\n* github.com/shurcooL/go [MIT](https://github.com/shurcooL/go/blob/master/README.md)\n* github.com/shurcooL/markdownfmt [MIT](https://github.com/shurcooL/markdownfmt/blob/master/README.md)\n* github.com/shurcooL/sanitized\\_anchor\\_name [MIT](https://github.com/shurcooL/sanitized_anchor_name/blob/master/LICENSE)\n* github.com/stretchr/testify [MIT](https://github.com/stretchr/testify/blob/master/LICENSE)\n* gopkg.in/gomail.v2 [MIT](https://github.com/go-gomail/gomail/blob/v2/LICENSE)\n* github.com/mailru/easyjson [MIT](https://github.com/mailru/easyjson/blob/3fdea8d05856a0c8df22ed4bc71b3219245e4485/LICENSE)\n* google.golang.org/protobuf [BSD](https://github.com/protocolbuffers/protobuf-go/blob/master/LICENSE)\n* github.com/IBM/sarama [MIT](https://github.com/IBM/sarama/blob/main/LICENSE)"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 2.640625,
          "content": "# Kapacitor [![Circle CI](https://circleci.com/gh/influxdata/kapacitor/tree/master.svg?style=svg&circle-token=78c97422cf89526309e502a290c230e8a463229f)](https://circleci.com/gh/influxdata/kapacitor/tree/master) [![Docker pulls](https://img.shields.io/docker/pulls/library/kapacitor.svg)](https://hub.docker.com/_/kapacitor/)\nOpen source framework for processing, monitoring, and alerting on time series data\n\n# Installation\n\nKapacitor has two binaries:\n\n* kapacitor – a CLI program for calling the Kapacitor API.\n* kapacitord – the Kapacitor server daemon.\n\nYou can either download the binaries directly from the [downloads](https://influxdata.com/downloads/#kapacitor) page or go get them:\n\n```sh\ngo get github.com/influxdata/kapacitor/cmd/kapacitor\ngo get github.com/influxdata/kapacitor/cmd/kapacitord\n```\n\n# Configuration\nAn example configuration file can be found [here](https://github.com/influxdata/kapacitor/blob/master/etc/kapacitor/kapacitor.conf)\n\nKapacitor can also provide an example config for you using this command:\n\n```sh\nkapacitord config\n```\n\n\n# Getting Started\n\nThis README gives you a high level overview of what Kapacitor is and what its like to use it. As well as some details of how it works.\nTo get started using Kapacitor see [this guide](https://docs.influxdata.com/kapacitor/latest/introduction/getting-started/). After you finish the getting started exercise you can check out the [TICKscripts](https://github.com/influxdata/kapacitor/tree/master/examples/telegraf) for different Telegraf plugins.\n\n# Basic Example\n\nKapacitor uses a DSL named [TICKscript](https://docs.influxdata.com/kapacitor/latest/tick/) to define tasks.\n\nA simple TICKscript that alerts on high cpu usage looks like this:\n\n```javascript\nstream\n    |from()\n        .measurement('cpu_usage_idle')\n        .groupBy('host')\n    |window()\n        .period(1m)\n        .every(1m)\n    |mean('value')\n    |eval(lambda: 100.0 - \"mean\")\n        .as('used')\n    |alert()\n        .message('{{ .Level}}: {{ .Name }}/{{ index .Tags \"host\" }} has high cpu usage: {{ index .Fields \"used\" }}')\n        .warn(lambda: \"used\" > 70.0)\n        .crit(lambda: \"used\" > 85.0)\n\n        // Send alert to hander of choice.\n\n        // Slack\n        .slack()\n        .channel('#alerts')\n\n        // VictorOps\n        .victorOps()\n        .routingKey('team_rocket')\n\n        // PagerDuty\n        .pagerDuty()\n```\n\nPlace the above script into a file `cpu_alert.tick` then run these commands to start the task:\n\n```sh\n# Define the task (assumes cpu data is in db 'telegraf')\nkapacitor define \\\n    cpu_alert \\\n    -type stream \\\n    -dbrp telegraf.default \\\n    -tick ./cpu_alert.tick\n# Start the task\nkapacitor enable cpu_alert\n```\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.4833984375,
          "content": "# Security Policy\n\n## Reporting a Vulnerability\n\nInfluxData takes security and our users' trust seriously. If you believe you\nhave found a security issue in any of our open source projects, please\nresponsibly disclose it by contacting `security@influxdata.com`. More details\nabout security vulnerability reporting can be found on the\n[InfluxData How to Report Vulnerabilities page][InfluxData Security].\n\n[InfluxData Security]: https://www.influxdata.com/how-to-report-security-vulnerabilities/\n"
        },
        {
          "name": "alert.go",
          "type": "blob",
          "size": 38.57421875,
          "content": "package kapacitor\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\thtml \"html/template\"\n\t\"os\"\n\t\"sync\"\n\ttext \"text/template\"\n\t\"time\"\n\n\t\"github.com/influxdata/kapacitor/alert\"\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/expvar\"\n\t\"github.com/influxdata/kapacitor/keyvalue\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n\talertservice \"github.com/influxdata/kapacitor/services/alert\"\n\t\"github.com/influxdata/kapacitor/services/bigpanda\"\n\t\"github.com/influxdata/kapacitor/services/discord\"\n\t\"github.com/influxdata/kapacitor/services/hipchat\"\n\t\"github.com/influxdata/kapacitor/services/httppost\"\n\t\"github.com/influxdata/kapacitor/services/kafka\"\n\t\"github.com/influxdata/kapacitor/services/mqtt\"\n\t\"github.com/influxdata/kapacitor/services/opsgenie\"\n\t\"github.com/influxdata/kapacitor/services/opsgenie2\"\n\t\"github.com/influxdata/kapacitor/services/pagerduty\"\n\t\"github.com/influxdata/kapacitor/services/pagerduty2\"\n\t\"github.com/influxdata/kapacitor/services/pushover\"\n\t\"github.com/influxdata/kapacitor/services/sensu\"\n\t\"github.com/influxdata/kapacitor/services/servicenow\"\n\t\"github.com/influxdata/kapacitor/services/slack\"\n\t\"github.com/influxdata/kapacitor/services/smtp\"\n\t\"github.com/influxdata/kapacitor/services/snmptrap\"\n\t\"github.com/influxdata/kapacitor/services/teams\"\n\t\"github.com/influxdata/kapacitor/services/telegram\"\n\t\"github.com/influxdata/kapacitor/services/victorops\"\n\t\"github.com/influxdata/kapacitor/services/zenoss\"\n\t\"github.com/influxdata/kapacitor/tick/ast\"\n\t\"github.com/influxdata/kapacitor/tick/stateful\"\n\t\"github.com/pkg/errors\"\n)\n\nconst (\n\tstatsAlertsTriggered = \"alerts_triggered\"\n\tstatsAlertsInhibited = \"alerts_inhibited\"\n\tstatsOKsTriggered    = \"oks_triggered\"\n\tstatsInfosTriggered  = \"infos_triggered\"\n\tstatsWarnsTriggered  = \"warns_triggered\"\n\tstatsCritsTriggered  = \"crits_triggered\"\n\tstatsEventsDropped   = \"events_dropped\"\n)\n\n// The newest state change is weighted 'weightDiff' times more than oldest state change.\nconst weightDiff = 1.5\n\n// Maximum weight applied to newest state change.\nconst maxWeight = 1.2\n\ntype AlertNode struct {\n\tnode\n\ta           *pipeline.AlertNode\n\ttopic       string\n\tanonTopic   string\n\thandlers    []alert.Handler\n\tlevels      []stateful.Expression\n\tscopePools  []stateful.ScopePool\n\tidTmpl      *text.Template\n\tmessageTmpl *text.Template\n\tdetailsTmpl *html.Template\n\n\talertsTriggered *expvar.Int\n\talertsInhibited *expvar.Int\n\toksTriggered    *expvar.Int\n\tinfosTriggered  *expvar.Int\n\twarnsTriggered  *expvar.Int\n\tcritsTriggered  *expvar.Int\n\teventsDropped   *expvar.Int\n\n\tbufPool sync.Pool\n\n\tlevelResets  []stateful.Expression\n\tlrScopePools []stateful.ScopePool\n}\n\n// Create a new  AlertNode which caches the most recent item and exposes it over the HTTP API.\nfunc newAlertNode(et *ExecutingTask, n *pipeline.AlertNode, d NodeDiagnostic) (an *AlertNode, err error) {\n\tconst oneMeg = 2 << 19\n\tctx := []keyvalue.T{\n\t\tkeyvalue.KV(\"task\", et.Task.ID),\n\t}\n\n\tan = &AlertNode{\n\t\tnode: node{Node: n, et: et, diag: d},\n\t\ta:    n,\n\t}\n\tan.node.runF = an.runAlert\n\n\tan.topic = n.Topic\n\t// Create anonymous topic name\n\tan.anonTopic = fmt.Sprintf(\"%s:%s:%s\", et.tm.ID(), et.Task.ID, an.Name())\n\n\t// Create buffer pool for the templates\n\tan.bufPool = sync.Pool{\n\t\tNew: func() interface{} {\n\t\t\treturn new(bytes.Buffer)\n\t\t},\n\t}\n\n\t// Parse templates\n\tan.idTmpl, err = text.New(\"id\").Parse(n.Id)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tan.messageTmpl, err = text.New(\"message\").Parse(n.Message)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tan.detailsTmpl, err = html.New(\"details\").Funcs(html.FuncMap{\n\t\t\"jsonCompact\": func(v interface{}) html.JS {\n\t\t\ttmpBuffer := an.bufPool.Get().(*bytes.Buffer)\n\t\t\ttmpBuffer2 := an.bufPool.Get().(*bytes.Buffer)\n\n\t\t\tdefer func() {\n\t\t\t\tif tmpBuffer.Cap() < oneMeg { // only reuse the buffer if it is less than 500kb\n\t\t\t\t\ttmpBuffer.Reset()\n\t\t\t\t\tan.bufPool.Put(tmpBuffer)\n\t\t\t\t}\n\t\t\t\tif tmpBuffer2.Cap() < oneMeg { // only reuse the buffer if it is less than 500kb\n\t\t\t\t\ttmpBuffer2.Reset()\n\t\t\t\t\tan.bufPool.Put(tmpBuffer2)\n\t\t\t\t}\n\t\t\t}()\n\n\t\t\t_ = json.NewEncoder(tmpBuffer).Encode(v)\n\t\t\t_ = json.Compact(tmpBuffer2, tmpBuffer.Bytes())\n\t\t\treturn html.JS(tmpBuffer2.String())\n\t\t},\n\t\t\"json\": func(v interface{}) html.JS {\n\t\t\ttmpBuffer := an.bufPool.Get().(*bytes.Buffer)\n\n\t\t\tdefer func() {\n\t\t\t\tif tmpBuffer.Cap() < oneMeg { // only reuse the buffer if it is less than 500kb\n\t\t\t\t\ttmpBuffer.Reset()\n\t\t\t\t\tan.bufPool.Put(tmpBuffer)\n\t\t\t\t}\n\t\t\t}()\n\n\t\t\t_ = json.NewEncoder(tmpBuffer).Encode(v)\n\t\t\treturn html.JS(tmpBuffer.String())\n\t\t},\n\t}).Parse(n.Details)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, tcp := range n.TcpHandlers {\n\t\tc := alertservice.TCPHandlerConfig{\n\t\t\tAddress: tcp.Address,\n\t\t}\n\t\th := alertservice.NewTCPHandler(c, an.diag)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\n\tfor _, email := range n.EmailHandlers {\n\t\tc := smtp.HandlerConfig{\n\t\t\tTo:          email.ToList,\n\t\t\tToTemplates: email.ToTemplatesList,\n\t\t}\n\t\th := et.tm.SMTPService.Handler(c, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\tif len(n.EmailHandlers) == 0 && (et.tm.SMTPService != nil && et.tm.SMTPService.Global()) {\n\t\tc := smtp.HandlerConfig{}\n\t\th := et.tm.SMTPService.Handler(c, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\t// If email has been configured with state changes only set it.\n\tif et.tm.SMTPService != nil &&\n\t\tet.tm.SMTPService.Global() &&\n\t\tet.tm.SMTPService.StateChangesOnly() {\n\t\tn.IsStateChangesOnly = true\n\t}\n\n\tfor _, e := range n.ExecHandlers {\n\t\tc := alertservice.ExecHandlerConfig{\n\t\t\tProg:      e.Command[0],\n\t\t\tArgs:      e.Command[1:],\n\t\t\tCommander: et.tm.Commander,\n\t\t}\n\t\th := alertservice.NewExecHandler(c, an.diag)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\n\tfor _, log := range n.LogHandlers {\n\t\tc := alertservice.DefaultLogHandlerConfig()\n\t\tc.Path = log.FilePath\n\t\tif log.Mode != 0 {\n\t\t\tc.Mode = os.FileMode(log.Mode)\n\t\t}\n\t\th, err := alertservice.NewLogHandler(c, an.diag)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to create log alert handler\")\n\t\t}\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\n\tfor _, vo := range n.VictorOpsHandlers {\n\t\tc := victorops.HandlerConfig{\n\t\t\tRoutingKey: vo.RoutingKey,\n\t\t}\n\t\th := et.tm.VictorOpsService.Handler(c, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\tif len(n.VictorOpsHandlers) == 0 && (et.tm.VictorOpsService != nil && et.tm.VictorOpsService.Global()) {\n\t\tc := victorops.HandlerConfig{}\n\t\th := et.tm.VictorOpsService.Handler(c, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\n\tfor _, pd := range n.PagerDutyHandlers {\n\t\tc := pagerduty.HandlerConfig{\n\t\t\tServiceKey: pd.ServiceKey,\n\t\t}\n\t\th := et.tm.PagerDutyService.Handler(c, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\tif len(n.PagerDutyHandlers) == 0 && (et.tm.PagerDutyService != nil && et.tm.PagerDutyService.Global()) {\n\t\tc := pagerduty.HandlerConfig{}\n\t\th := et.tm.PagerDutyService.Handler(c, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\n\tfor _, pd := range n.PagerDuty2Handlers {\n\t\tlinks := make([]pagerduty2.LinkTemplate, len(pd.Links))\n\t\tfor i, l := range pd.Links {\n\t\t\tlinks[i] = pagerduty2.LinkTemplate{\n\t\t\t\tHref: l.Href,\n\t\t\t\tText: l.Text,\n\t\t\t}\n\t\t}\n\t\tc := pagerduty2.HandlerConfig{\n\t\t\tRoutingKey: pd.RoutingKey,\n\t\t\tLinks:      links,\n\t\t}\n\t\th, err := et.tm.PagerDuty2Service.Handler(c, ctx...)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"failed to create PagerDuty2 handler\")\n\t\t}\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\tif len(n.PagerDuty2Handlers) == 0 && (et.tm.PagerDuty2Service != nil && et.tm.PagerDuty2Service.Global()) {\n\t\tc := pagerduty2.HandlerConfig{}\n\n\t\th, err := et.tm.PagerDuty2Service.Handler(c, ctx...)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"failed to create PagerDuty2 handler\")\n\t\t}\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\n\tfor _, s := range n.SensuHandlers {\n\t\tc := sensu.HandlerConfig{\n\t\t\tSource:   s.Source,\n\t\t\tHandlers: s.HandlersList,\n\t\t\tMetadata: s.MetadataMap,\n\t\t}\n\t\th, err := et.tm.SensuService.Handler(c, ctx...)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to create sensu alert handler\")\n\t\t}\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\n\tfor _, s := range n.SlackHandlers {\n\t\tc := slack.HandlerConfig{\n\t\t\tWorkspace: s.Workspace,\n\t\t\tChannel:   s.Channel,\n\t\t\tUsername:  s.Username,\n\t\t\tIconEmoji: s.IconEmoji,\n\t\t}\n\t\th := et.tm.SlackService.Handler(c, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\tif len(n.SlackHandlers) == 0 && (et.tm.SlackService != nil && et.tm.SlackService.Global()) {\n\t\th := et.tm.SlackService.Handler(slack.HandlerConfig{}, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\t// If slack has been configured with state changes only set it.\n\tif et.tm.SlackService != nil &&\n\t\tet.tm.SlackService.Global() &&\n\t\tet.tm.SlackService.StateChangesOnly() {\n\t\tn.IsStateChangesOnly = true\n\t}\n\n\tfor _, t := range n.TelegramHandlers {\n\t\tc := telegram.HandlerConfig{\n\t\t\tChatId:                t.ChatId,\n\t\t\tParseMode:             t.ParseMode,\n\t\t\tDisableWebPagePreview: t.IsDisableWebPagePreview,\n\t\t\tDisableNotification:   t.IsDisableNotification,\n\t\t}\n\t\th := et.tm.TelegramService.Handler(c, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\n\tfor _, s := range n.SNMPTrapHandlers {\n\t\tdataList := make([]snmptrap.Data, len(s.DataList))\n\t\tfor i, d := range s.DataList {\n\t\t\tdataList[i] = snmptrap.Data{\n\t\t\t\tOid:   d.Oid,\n\t\t\t\tType:  d.Type,\n\t\t\t\tValue: d.Value,\n\t\t\t}\n\t\t}\n\t\tc := snmptrap.HandlerConfig{\n\t\t\tTrapOid:  s.TrapOid,\n\t\t\tDataList: dataList,\n\t\t}\n\t\th, err := et.tm.SNMPTrapService.Handler(c, ctx...)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"failed to create SNMP handler\")\n\t\t}\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\n\tif len(n.TelegramHandlers) == 0 && (et.tm.TelegramService != nil && et.tm.TelegramService.Global()) {\n\t\tc := telegram.HandlerConfig{}\n\t\th := et.tm.TelegramService.Handler(c, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\t// If telegram has been configured with state changes only set it.\n\tif et.tm.TelegramService != nil &&\n\t\tet.tm.TelegramService.Global() &&\n\t\tet.tm.TelegramService.StateChangesOnly() {\n\t\tn.IsStateChangesOnly = true\n\t}\n\n\tfor _, hc := range n.HipChatHandlers {\n\t\tc := hipchat.HandlerConfig{\n\t\t\tRoom:  hc.Room,\n\t\t\tToken: hc.Token,\n\t\t}\n\t\th := et.tm.HipChatService.Handler(c, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\tif len(n.HipChatHandlers) == 0 && (et.tm.HipChatService != nil && et.tm.HipChatService.Global()) {\n\t\tc := hipchat.HandlerConfig{}\n\t\th := et.tm.HipChatService.Handler(c, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\t// If HipChat has been configured with state changes only set it.\n\tif et.tm.HipChatService != nil &&\n\t\tet.tm.HipChatService.Global() &&\n\t\tet.tm.HipChatService.StateChangesOnly() {\n\t\tn.IsStateChangesOnly = true\n\t}\n\n\tfor _, k := range n.KafkaHandlers {\n\t\tc := kafka.HandlerConfig{\n\t\t\tCluster:              k.Cluster,\n\t\t\tTopic:                k.KafkaTopic,\n\t\t\tTemplate:             k.Template,\n\t\t\tDisablePartitionById: k.IsDisablePartitionById,\n\t\t\tPartitionAlgorithm:   k.PartitionHashAlgorithm,\n\t\t}\n\t\th, err := et.tm.KafkaService.Handler(c, ctx...)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"failed to create kafka handler\")\n\t\t}\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\n\tfor _, a := range n.AlertaHandlers {\n\t\tc := et.tm.AlertaService.DefaultHandlerConfig()\n\t\tif a.Token != \"\" {\n\t\t\tc.Token = a.Token\n\t\t}\n\t\tif a.Resource != \"\" {\n\t\t\tc.Resource = a.Resource\n\t\t}\n\t\tif a.Event != \"\" {\n\t\t\tc.Event = a.Event\n\t\t}\n\t\tif a.Environment != \"\" {\n\t\t\tc.Environment = a.Environment\n\t\t}\n\t\tif a.Group != \"\" {\n\t\t\tc.Group = a.Group\n\t\t}\n\t\tif a.Value != \"\" {\n\t\t\tc.Value = a.Value\n\t\t}\n\t\tif a.Origin != \"\" {\n\t\t\tc.Origin = a.Origin\n\t\t}\n\t\tif len(a.Service) != 0 {\n\t\t\tc.Service = a.Service\n\t\t}\n\t\tif len(a.Correlate) != 0 {\n\t\t\tc.Correlate = a.Correlate\n\t\t}\n\t\tif len(a.Attributes) != 0 {\n\t\t\tc.Attributes = a.Attributes\n\t\t}\n\t\tif a.Timeout != 0 {\n\t\t\tc.Timeout = a.Timeout\n\t\t}\n\t\th, err := et.tm.AlertaService.Handler(c, ctx...)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to create Alerta handler\")\n\t\t}\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\n\tfor _, p := range n.PushoverHandlers {\n\t\tc := pushover.HandlerConfig{}\n\t\tif p.Device != \"\" {\n\t\t\tc.Device = p.Device\n\t\t}\n\t\tif p.Title != \"\" {\n\t\t\tc.Title = p.Title\n\t\t}\n\t\tif p.URL != \"\" {\n\t\t\tc.URL = p.URL\n\t\t}\n\t\tif p.URLTitle != \"\" {\n\t\t\tc.URLTitle = p.URLTitle\n\t\t}\n\t\tif p.Sound != \"\" {\n\t\t\tc.Sound = p.Sound\n\t\t}\n\t\tif p.UserKey != \"\" {\n\t\t\tc.UserKey = p.UserKey\n\t\t}\n\t\th := et.tm.PushoverService.Handler(c, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\n\tfor _, p := range n.HTTPPostHandlers {\n\t\tif p.Endpoint == \"\" && p.URL == \"\" {\n\t\t\treturn nil, errors.New(\"Either URL or endpoint must be non-empty\")\n\t\t}\n\t\tc := httppost.HandlerConfig{\n\t\t\tURL:             p.URL,\n\t\t\tEndpoint:        p.Endpoint,\n\t\t\tHeaders:         p.Headers,\n\t\t\tCaptureResponse: p.CaptureResponseFlag,\n\t\t\tTimeout:         p.Timeout,\n\t\t}\n\t\th, err := et.tm.HTTPPostService.Handler(c, ctx...)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to create HTTPPostService.Handler\")\n\t\t}\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\n\tfor _, og := range n.OpsGenieHandlers {\n\t\tc := opsgenie.HandlerConfig{\n\t\t\tTeamsList:      og.TeamsList,\n\t\t\tRecipientsList: og.RecipientsList,\n\t\t}\n\t\th := et.tm.OpsGenieService.Handler(c, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\tif len(n.OpsGenieHandlers) == 0 && (et.tm.OpsGenieService != nil && et.tm.OpsGenieService.Global()) {\n\t\tc := opsgenie.HandlerConfig{}\n\t\th := et.tm.OpsGenieService.Handler(c, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\tfor _, og := range n.OpsGenie2Handlers {\n\t\tc := opsgenie2.HandlerConfig{\n\t\t\tTeamsList:      og.TeamsList,\n\t\t\tRecipientsList: og.RecipientsList,\n\t\t\tRecoveryAction: og.RecoveryActionString,\n\t\t}\n\t\th := et.tm.OpsGenie2Service.Handler(c, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\tif len(n.OpsGenie2Handlers) == 0 && (et.tm.OpsGenie2Service != nil && et.tm.OpsGenie2Service.Global()) {\n\t\tc := opsgenie2.HandlerConfig{}\n\t\th := et.tm.OpsGenie2Service.Handler(c, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\n\tfor range n.TalkHandlers {\n\t\th := et.tm.TalkService.Handler(ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\n\tfor _, m := range n.MQTTHandlers {\n\t\tc := mqtt.HandlerConfig{\n\t\t\tBrokerName: m.BrokerName,\n\t\t\tTopic:      m.Topic,\n\t\t\tQoS:        mqtt.QoSLevel(m.Qos),\n\t\t\tRetained:   m.Retained,\n\t\t}\n\t\th, err := et.tm.MQTTService.Handler(c, ctx...)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to create MQTT handler\")\n\t\t}\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\n\tfor _, s := range n.DiscordHandlers {\n\t\tc := discord.HandlerConfig{\n\t\t\tWorkspace:  s.Workspace,\n\t\t\tUsername:   s.Username,\n\t\t\tAvatarURL:  s.AvatarURL,\n\t\t\tEmbedTitle: s.EmbedTitle,\n\t\t}\n\t\th, err := et.tm.DiscordService.Handler(c, ctx...)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to create Discord handler\")\n\t\t}\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\n\tfor _, s := range n.BigPandaHandlers {\n\t\tc := bigpanda.HandlerConfig{\n\t\t\tAppKey:            s.AppKey,\n\t\t\tHost:              s.Host,\n\t\t\tPrimaryProperty:   s.PrimaryProperty,\n\t\t\tSecondaryProperty: s.SecondaryProperty,\n\t\t\tAttributes:        s.Attributes,\n\t\t}\n\t\th, err := et.tm.BigPandaService.Handler(c, ctx...)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to create BigPanda handler\")\n\t\t}\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\n\tfor _, t := range n.TeamsHandlers {\n\t\tc := teams.HandlerConfig{\n\t\t\tChannelURL: t.ChannelURL,\n\t\t}\n\t\th := et.tm.TeamsService.Handler(c, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\tif len(n.TeamsHandlers) == 0 && (et.tm.TeamsService != nil && et.tm.TeamsService.Global()) {\n\t\tc := teams.HandlerConfig{}\n\t\th := et.tm.TeamsService.Handler(c, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\t// If Teams has been configured with state changes only set it.\n\tif et.tm.TeamsService != nil &&\n\t\tet.tm.TeamsService.Global() &&\n\t\tet.tm.TeamsService.StateChangesOnly() {\n\t\tn.IsStateChangesOnly = true\n\t}\n\n\tif len(n.DiscordHandlers) == 0 && (et.tm.DiscordService != nil && et.tm.DiscordService.Global()) {\n\t\th, err := et.tm.DiscordService.Handler(discord.HandlerConfig{}, ctx...)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to create Discord handler\")\n\t\t}\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\t// If discord has been configured with state changes only set it.\n\tif et.tm.DiscordService != nil &&\n\t\tet.tm.DiscordService.Global() &&\n\t\tet.tm.DiscordService.StateChangesOnly() {\n\t\tn.IsStateChangesOnly = true\n\t}\n\n\tfor _, s := range n.ServiceNowHandlers {\n\t\tc := servicenow.HandlerConfig{\n\t\t\tURL:            s.URL,\n\t\t\tSource:         s.Source,\n\t\t\tNode:           s.Node,\n\t\t\tType:           s.Type,\n\t\t\tResource:       s.Resource,\n\t\t\tMetricName:     s.MetricName,\n\t\t\tMessageKey:     s.MessageKey,\n\t\t\tAdditionalInfo: s.AdditionalInfoMap,\n\t\t}\n\t\th := et.tm.ServiceNowService.Handler(c, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\tif len(n.ServiceNowHandlers) == 0 && (et.tm.ServiceNowService != nil && et.tm.ServiceNowService.Global()) {\n\t\th := et.tm.ServiceNowService.Handler(servicenow.HandlerConfig{}, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\t// If servicenow has been configured with state changes only set it.\n\tif et.tm.ServiceNowService != nil &&\n\t\tet.tm.ServiceNowService.Global() &&\n\t\tet.tm.ServiceNowService.StateChangesOnly() {\n\t\tn.IsStateChangesOnly = true\n\t}\n\n\tif len(n.BigPandaHandlers) == 0 && (et.tm.BigPandaService != nil && et.tm.BigPandaService.Global()) {\n\t\th, err := et.tm.BigPandaService.Handler(bigpanda.HandlerConfig{}, ctx...)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to create BigPanda handler\")\n\t\t}\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\t// If BigPanda has been configured with state changes only set it.\n\tif et.tm.BigPandaService != nil &&\n\t\tet.tm.BigPandaService.Global() &&\n\t\tet.tm.BigPandaService.StateChangesOnly() {\n\t\tn.IsStateChangesOnly = true\n\t}\n\n\tfor _, s := range n.ZenossHandlers {\n\t\tc := zenoss.HandlerConfig{\n\t\t\tAction:        s.Action,\n\t\t\tMethod:        s.Method,\n\t\t\tType:          s.Type,\n\t\t\tTID:           s.Tid,\n\t\t\tSummary:       s.Summary,\n\t\t\tDevice:        s.Device,\n\t\t\tComponent:     s.Component,\n\t\t\tEventClassKey: s.EventClassKey,\n\t\t\tEventClass:    s.EventClass,\n\t\t\tMessage:       s.Message,\n\t\t\tCollector:     s.Collector,\n\t\t\tCustomFields:  s.CustomFieldsMap,\n\t\t}\n\t\th := et.tm.ZenossService.Handler(c, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\tif len(n.ZenossHandlers) == 0 && (et.tm.ZenossService != nil && et.tm.ZenossService.Global()) {\n\t\th := et.tm.ZenossService.Handler(zenoss.HandlerConfig{}, ctx...)\n\t\tan.handlers = append(an.handlers, h)\n\t}\n\t// If zenoss has been configured with state changes only set it.\n\tif et.tm.ZenossService != nil &&\n\t\tet.tm.ZenossService.Global() &&\n\t\tet.tm.ZenossService.StateChangesOnly() {\n\t\tn.IsStateChangesOnly = true\n\t}\n\n\t// Parse level expressions\n\tan.levels = make([]stateful.Expression, alert.Critical+1)\n\tan.scopePools = make([]stateful.ScopePool, alert.Critical+1)\n\n\tan.levelResets = make([]stateful.Expression, alert.Critical+1)\n\tan.lrScopePools = make([]stateful.ScopePool, alert.Critical+1)\n\n\tif n.Info != nil {\n\t\tstatefulExpression, expressionCompileError := stateful.NewExpression(n.Info.Expression)\n\t\tif expressionCompileError != nil {\n\t\t\treturn nil, fmt.Errorf(\"Failed to compile stateful expression for info: %s\", expressionCompileError)\n\t\t}\n\n\t\tan.levels[alert.Info] = statefulExpression\n\t\tan.scopePools[alert.Info] = stateful.NewScopePool(ast.FindReferenceVariables(n.Info.Expression))\n\t\tif n.InfoReset != nil {\n\t\t\tlstatefulExpression, lexpressionCompileError := stateful.NewExpression(n.InfoReset.Expression)\n\t\t\tif lexpressionCompileError != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"Failed to compile stateful expression for infoReset: %s\", lexpressionCompileError)\n\t\t\t}\n\t\t\tan.levelResets[alert.Info] = lstatefulExpression\n\t\t\tan.lrScopePools[alert.Info] = stateful.NewScopePool(ast.FindReferenceVariables(n.InfoReset.Expression))\n\t\t}\n\t}\n\n\tif n.Warn != nil {\n\t\tstatefulExpression, expressionCompileError := stateful.NewExpression(n.Warn.Expression)\n\t\tif expressionCompileError != nil {\n\t\t\treturn nil, fmt.Errorf(\"Failed to compile stateful expression for warn: %s\", expressionCompileError)\n\t\t}\n\t\tan.levels[alert.Warning] = statefulExpression\n\t\tan.scopePools[alert.Warning] = stateful.NewScopePool(ast.FindReferenceVariables(n.Warn.Expression))\n\t\tif n.WarnReset != nil {\n\t\t\tlstatefulExpression, lexpressionCompileError := stateful.NewExpression(n.WarnReset.Expression)\n\t\t\tif lexpressionCompileError != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"Failed to compile stateful expression for warnReset: %s\", lexpressionCompileError)\n\t\t\t}\n\t\t\tan.levelResets[alert.Warning] = lstatefulExpression\n\t\t\tan.lrScopePools[alert.Warning] = stateful.NewScopePool(ast.FindReferenceVariables(n.WarnReset.Expression))\n\t\t}\n\t}\n\n\tif n.Crit != nil {\n\t\tstatefulExpression, expressionCompileError := stateful.NewExpression(n.Crit.Expression)\n\t\tif expressionCompileError != nil {\n\t\t\treturn nil, fmt.Errorf(\"Failed to compile stateful expression for crit: %s\", expressionCompileError)\n\t\t}\n\t\tan.levels[alert.Critical] = statefulExpression\n\t\tan.scopePools[alert.Critical] = stateful.NewScopePool(ast.FindReferenceVariables(n.Crit.Expression))\n\t\tif n.CritReset != nil {\n\t\t\tlstatefulExpression, lexpressionCompileError := stateful.NewExpression(n.CritReset.Expression)\n\t\t\tif lexpressionCompileError != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"Failed to compile stateful expression for critReset: %s\", lexpressionCompileError)\n\t\t\t}\n\t\t\tan.levelResets[alert.Critical] = lstatefulExpression\n\t\t\tan.lrScopePools[alert.Critical] = stateful.NewScopePool(ast.FindReferenceVariables(n.CritReset.Expression))\n\t\t}\n\t}\n\n\t// Setup states\n\tif n.History < 2 {\n\t\tn.History = 2\n\t}\n\n\t// Configure flapping\n\tif n.UseFlapping {\n\t\tif n.FlapLow > 1 || n.FlapHigh > 1 {\n\t\t\treturn nil, errors.New(\"alert flap thresholds are percentages and should be between 0 and 1\")\n\t\t}\n\t}\n\n\treturn\n}\n\nfunc (n *AlertNode) runAlert([]byte) error {\n\t// Register delete hook\n\tif n.hasAnonTopic() {\n\t\tn.et.tm.registerDeleteHookForTask(n.et.Task.ID, deleteAlertHook(n.anonTopic))\n\n\t\t// Register Handlers on topic\n\t\tfor _, h := range n.handlers {\n\t\t\tn.et.tm.AlertService.RegisterAnonHandler(n.anonTopic, h)\n\t\t}\n\t\t// Restore anonTopic\n\t\tn.et.tm.AlertService.RestoreTopic(n.anonTopic)\n\t}\n\n\t// Setup stats\n\tn.alertsTriggered = &expvar.Int{}\n\tn.statMap.Set(statsAlertsTriggered, n.alertsTriggered)\n\n\tn.alertsInhibited = &expvar.Int{}\n\tn.statMap.Set(statsAlertsInhibited, n.alertsInhibited)\n\n\tn.oksTriggered = &expvar.Int{}\n\tn.statMap.Set(statsOKsTriggered, n.oksTriggered)\n\n\tn.infosTriggered = &expvar.Int{}\n\tn.statMap.Set(statsInfosTriggered, n.infosTriggered)\n\n\tn.warnsTriggered = &expvar.Int{}\n\tn.statMap.Set(statsWarnsTriggered, n.warnsTriggered)\n\n\tn.critsTriggered = &expvar.Int{}\n\tn.statMap.Set(statsCritsTriggered, n.critsTriggered)\n\n\tn.eventsDropped = &expvar.Int{}\n\tn.statMap.Set(statsCritsTriggered, n.critsTriggered)\n\n\t// Setup consumer\n\tconsumer := edge.NewGroupedConsumer(\n\t\tn.ins[0],\n\t\tn,\n\t)\n\tn.statMap.Set(statCardinalityGauge, consumer.CardinalityVar())\n\n\tif err := consumer.Consume(); err != nil {\n\t\treturn err\n\t}\n\n\t// Close the anonymous topic.\n\tn.et.tm.AlertService.CloseTopic(n.anonTopic)\n\n\t// Deregister Handlers on topic\n\tfor _, h := range n.handlers {\n\t\tn.et.tm.AlertService.DeregisterAnonHandler(n.anonTopic, h)\n\t}\n\n\treturn nil\n}\n\nfunc (n *AlertNode) NewGroup(group edge.GroupInfo, first edge.PointMeta) (edge.Receiver, error) {\n\tid, err := n.renderID(first.Name(), first.GroupID(), first.Tags())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tt := first.Time()\n\n\tstate := n.restoreEventState(id, t, group.Tags)\n\n\treturn edge.NewReceiverFromForwardReceiverWithStats(\n\t\tn.outs,\n\t\tedge.NewTimedForwardReceiver(\n\t\t\tn.timer,\n\t\t\tstate,\n\t\t),\n\t), nil\n}\n\nfunc (n *AlertNode) restoreEventState(id string, t time.Time, tags models.Tags) *alertState {\n\tstate := n.newAlertState(tags)\n\tcurrentLevel, triggered := n.restoreEvent(id)\n\tif currentLevel != alert.OK {\n\t\t// Add initial event\n\t\tstate.addEvent(t, currentLevel)\n\t\t// Record triggered time\n\t\tstate.triggered(triggered)\n\t}\n\treturn state\n}\n\nfunc (n *AlertNode) newAlertState(tags models.Tags) *alertState {\n\tinhibitors := make([]*alert.Inhibitor, len(n.a.Inhibitors))\n\tfor i, in := range n.a.Inhibitors {\n\t\ttagset := make(models.Tags, len(in.EqualTags))\n\t\tfor _, t := range in.EqualTags {\n\t\t\ttagset[t] = tags[t]\n\t\t}\n\n\t\tinhibitor := alert.NewInhibitor(in.Category, tagset)\n\t\tinhibitors[i] = inhibitor\n\t\tn.et.tm.AlertService.AddInhibitor(inhibitor)\n\t}\n\treturn &alertState{\n\t\thistory:    make([]alert.Level, n.a.History),\n\t\tn:          n,\n\t\tbuffer:     new(edge.BatchBuffer),\n\t\tinhibitors: inhibitors,\n\t}\n}\n\nfunc (n *AlertNode) restoreEvent(id string) (alert.Level, time.Time) {\n\tvar topicState, anonTopicState alert.EventState\n\tvar anonFound, topicFound bool\n\t// Check for previous state on anonTopic\n\tif n.hasAnonTopic() {\n\t\tif state, ok, err := n.et.tm.AlertService.EventState(n.anonTopic, id); err != nil {\n\t\t\tn.diag.Error(\"failed to get event state for anonymous topic\", err,\n\t\t\t\tkeyvalue.KV(\"topic\", n.anonTopic), keyvalue.KV(\"event\", id))\n\t\t} else if ok {\n\t\t\tanonTopicState = state\n\t\t\tanonFound = true\n\t\t}\n\t}\n\t// Check for previous state on topic.\n\tif n.hasTopic() {\n\t\tif state, ok, err := n.et.tm.AlertService.EventState(n.topic, id); err != nil {\n\t\t\tn.diag.Error(\"failed to get event state for topic\", err,\n\t\t\t\tkeyvalue.KV(\"topic\", n.anonTopic), keyvalue.KV(\"event\", id))\n\t\t} else if ok {\n\t\t\ttopicState = state\n\t\t\ttopicFound = true\n\t\t}\n\t}\n\tif topicState.Level != anonTopicState.Level {\n\t\tif anonFound && topicFound {\n\t\t\t// Anon topic takes precedence\n\t\t\tif err := n.et.tm.AlertService.UpdateEvent(n.topic, anonTopicState); err != nil {\n\t\t\t\tn.diag.Error(\"failed to update topic event state\", err, keyvalue.KV(\"topic\", n.topic), keyvalue.KV(\"event\", id))\n\t\t\t}\n\t\t} else if topicFound && n.hasAnonTopic() {\n\t\t\t// Update event state for topic\n\t\t\tif err := n.et.tm.AlertService.UpdateEvent(n.anonTopic, topicState); err != nil {\n\t\t\t\tn.diag.Error(\"failed to update topic event state\", err, keyvalue.KV(\"topic\", n.topic), keyvalue.KV(\"event\", id))\n\t\t\t}\n\t\t} // else nothing was found, nothing to do\n\t}\n\tif anonFound {\n\t\treturn anonTopicState.Level, anonTopicState.Time\n\t}\n\treturn topicState.Level, topicState.Time\n}\n\nfunc deleteAlertHook(anonTopic string) deleteHook {\n\treturn func(tm *TaskMaster) {\n\t\ttm.AlertService.DeleteTopic(anonTopic)\n\t}\n}\n\nfunc (n *AlertNode) hasAnonTopic() bool {\n\treturn len(n.handlers) > 0\n}\nfunc (n *AlertNode) hasTopic() bool {\n\treturn n.topic != \"\"\n}\n\nfunc (n *AlertNode) handleEvent(event alert.Event) {\n\t// Check if alert is inhibited\n\tif n.et.tm.AlertService.IsInhibited(event.Data.Category, event.Data.Tags) {\n\t\tn.alertsInhibited.Add(1)\n\t\treturn\n\t}\n\n\tn.alertsTriggered.Add(1)\n\tswitch event.State.Level {\n\tcase alert.OK:\n\t\tn.oksTriggered.Add(1)\n\tcase alert.Info:\n\t\tn.infosTriggered.Add(1)\n\tcase alert.Warning:\n\t\tn.warnsTriggered.Add(1)\n\tcase alert.Critical:\n\t\tn.critsTriggered.Add(1)\n\t}\n\tn.diag.AlertTriggered(event.State.Level, event.State.ID, event.State.Message, event.Data.Result.Series[0])\n\n\t// If we have anon handlers, emit event to the anonTopic\n\tif n.hasAnonTopic() {\n\t\tevent.Topic = n.anonTopic\n\t\terr := n.et.tm.AlertService.Collect(event)\n\t\tif err != nil {\n\t\t\tn.eventsDropped.Add(1)\n\t\t\tn.diag.Error(\"encountered error collecting event\", err)\n\t\t}\n\t}\n\n\t// If we have a user define topic, emit event to the topic.\n\tif n.hasTopic() {\n\t\tevent.Topic = n.topic\n\t\terr := n.et.tm.AlertService.Collect(event)\n\t\tif err != nil {\n\t\t\tn.eventsDropped.Add(1)\n\t\t\tn.diag.Error(\"encountered error collecting event\", err)\n\t\t}\n\t}\n}\n\nfunc (n *AlertNode) determineLevel(p edge.FieldsTagsTimeGetter, currentLevel alert.Level) alert.Level {\n\tif higherLevel, found := n.findFirstMatchLevel(alert.Critical, currentLevel-1, p); found {\n\t\treturn higherLevel\n\t}\n\tif rse := n.levelResets[currentLevel]; rse != nil {\n\t\tif pass, err := EvalPredicate(rse, n.lrScopePools[currentLevel], p); err != nil {\n\t\t\tn.diag.Error(\"error evaluating reset expression for current level\", err, keyvalue.KV(\"level\", currentLevel.String()))\n\t\t} else if !pass {\n\t\t\treturn currentLevel\n\t\t}\n\t}\n\tif newLevel, found := n.findFirstMatchLevel(currentLevel, alert.OK, p); found {\n\t\treturn newLevel\n\t}\n\treturn alert.OK\n}\n\nfunc (n *AlertNode) findFirstMatchLevel(start alert.Level, stop alert.Level, p edge.FieldsTagsTimeGetter) (alert.Level, bool) {\n\tif stop < alert.OK {\n\t\tstop = alert.OK\n\t}\n\tfor l := start; l > stop; l-- {\n\t\tse := n.levels[l]\n\t\tif se == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif pass, err := EvalPredicate(se, n.scopePools[l], p); err != nil {\n\t\t\tn.diag.Error(\"error evaluating expression for level\", err, keyvalue.KV(\"level\", alert.Level(l).String()))\n\t\t\tcontinue\n\t\t} else if pass {\n\t\t\treturn alert.Level(l), true\n\t\t}\n\t}\n\treturn alert.OK, false\n}\n\nfunc (n *AlertNode) event(\n\tid, name string,\n\tgroup models.GroupID,\n\ttags models.Tags,\n\tfields models.Fields,\n\tlevel alert.Level,\n\tt time.Time,\n\td time.Duration,\n\tresult models.Result,\n) (alert.Event, error) {\n\tmsg, details, err := n.renderMessageAndDetails(id, name, t, group, tags, fields, level, d)\n\tif err != nil {\n\t\treturn alert.Event{}, err\n\t}\n\tevent := alert.Event{\n\t\tTopic: n.anonTopic,\n\t\tState: alert.EventState{\n\t\t\tID:       id,\n\t\t\tMessage:  msg,\n\t\t\tDetails:  details,\n\t\t\tTime:     t,\n\t\t\tDuration: d,\n\t\t\tLevel:    level,\n\t\t},\n\t\tData: alert.EventData{\n\t\t\tName:        name,\n\t\t\tTaskName:    n.et.Task.ID,\n\t\t\tCategory:    n.a.Category,\n\t\t\tGroup:       string(group),\n\t\t\tTags:        tags,\n\t\t\tFields:      fields,\n\t\t\tResult:      result,\n\t\t\tRecoverable: !n.a.NoRecoveriesFlag,\n\t\t},\n\t}\n\treturn event, nil\n}\n\ntype alertState struct {\n\tn *AlertNode\n\n\tbuffer *edge.BatchBuffer\n\n\thistory []alert.Level\n\tidx     int\n\n\tflapping bool\n\n\tchanged bool\n\t// Time when first alert was triggered\n\tfirstTriggered time.Time\n\t// Time when last alert was triggered.\n\t// Note: Alerts are not triggered for every event.\n\tlastTriggered time.Time\n\texpired       bool\n\n\tinhibitors []*alert.Inhibitor\n}\n\nfunc (a *alertState) BeginBatch(begin edge.BeginBatchMessage) (edge.Message, error) {\n\treturn nil, a.buffer.BeginBatch(begin)\n}\n\nfunc (a *alertState) BatchPoint(bp edge.BatchPointMessage) (edge.Message, error) {\n\treturn nil, a.buffer.BatchPoint(bp)\n}\n\nfunc (a *alertState) EndBatch(end edge.EndBatchMessage) (edge.Message, error) {\n\treturn a.BufferedBatch(a.buffer.BufferedBatchMessage(end))\n}\n\nfunc (a *alertState) BufferedBatch(b edge.BufferedBatchMessage) (edge.Message, error) {\n\tbegin := b.Begin()\n\tid, err := a.n.renderID(begin.Name(), begin.GroupID(), begin.Tags())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(b.Points()) == 0 {\n\t\treturn nil, nil\n\t}\n\t// Keep track of lowest level for any point\n\tlowestLevel := alert.Critical\n\t// Keep track of highest level and point\n\thighestLevel := alert.OK\n\tvar highestPoint edge.BatchPointMessage\n\n\tcurrentLevel := a.currentLevel()\n\tfor _, bp := range b.Points() {\n\t\tl := a.n.determineLevel(bp, currentLevel)\n\t\tif l < lowestLevel {\n\t\t\tlowestLevel = l\n\t\t}\n\t\tif l > highestLevel || highestPoint == nil {\n\t\t\thighestLevel = l\n\t\t\thighestPoint = bp\n\t\t}\n\t}\n\n\t// Default the determined level to lowest.\n\tl := lowestLevel\n\t// Update determined level to highest if we don't care about all\n\tif !a.n.a.AllFlag {\n\t\tl = highestLevel\n\t}\n\t// Create alert Data\n\tt := highestPoint.Time()\n\tif a.n.a.AllFlag || l == alert.OK {\n\t\tt = begin.Time()\n\t}\n\tt = t.UTC()\n\n\ta.addEvent(t, l)\n\n\t// Trigger alert only if:\n\t//  l == OK and state.changed (aka recovery)\n\t//    OR\n\t//  l != OK and flapping/statechanges checkout\n\tif !(a.changed && l == alert.OK ||\n\t\t(l != alert.OK &&\n\t\t\t!((a.n.a.UseFlapping && a.flapping) ||\n\t\t\t\t(a.n.a.IsStateChangesOnly && !a.changed && !a.expired)))) {\n\t\treturn nil, nil\n\t}\n\n\ta.triggered(t)\n\n\t// Suppress the recovery event.\n\tif a.n.a.NoRecoveriesFlag && l == alert.OK {\n\t\treturn nil, nil\n\t}\n\n\tduration := a.duration()\n\tevent, err := a.n.event(id, begin.Name(), begin.GroupID(), begin.Tags(), highestPoint.Fields(), l, t, duration, b.ToResult())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\ta.n.handleEvent(event)\n\n\t// Update tags or fields with event state\n\tif a.n.a.LevelTag != \"\" ||\n\t\ta.n.a.LevelField != \"\" ||\n\t\ta.n.a.IdTag != \"\" ||\n\t\ta.n.a.IdField != \"\" ||\n\t\ta.n.a.DurationField != \"\" ||\n\t\ta.n.a.MessageField != \"\" {\n\n\t\tb = b.ShallowCopy()\n\t\tpoints := make([]edge.BatchPointMessage, len(b.Points()))\n\t\tfor i, bp := range b.Points() {\n\t\t\tbp = bp.ShallowCopy()\n\t\t\ta.augmentTagsWithEventState(bp, event.State)\n\t\t\ta.augmentFieldsWithEventState(bp, event.State)\n\t\t\tpoints[i] = bp\n\t\t}\n\t\tb.SetPoints(points)\n\n\t\tnewBegin := begin.ShallowCopy()\n\t\ta.augmentTagsWithEventState(newBegin, event.State)\n\t\tb.SetBegin(newBegin)\n\t}\n\treturn b, nil\n}\n\nfunc (a *alertState) Point(p edge.PointMessage) (edge.Message, error) {\n\tid, err := a.n.renderID(p.Name(), p.GroupID(), p.Tags())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tl := a.n.determineLevel(p, a.currentLevel())\n\n\ta.addEvent(p.Time(), l)\n\n\tif (a.n.a.UseFlapping && a.flapping) || (a.n.a.IsStateChangesOnly && !a.changed && !a.expired) {\n\t\treturn nil, nil\n\t}\n\t// send alert if we are not OK or we are OK and state changed (i.e recovery)\n\tif l != alert.OK || a.changed {\n\t\ta.triggered(p.Time())\n\t\t// Suppress the recovery event.\n\t\tif a.n.a.NoRecoveriesFlag && l == alert.OK {\n\t\t\treturn nil, nil\n\t\t}\n\t\t// Create an alert event\n\t\tduration := a.duration()\n\t\tevent, err := a.n.event(\n\t\t\tid,\n\t\t\tp.Name(),\n\t\t\tp.GroupID(),\n\t\t\tp.Tags(),\n\t\t\tp.Fields(),\n\t\t\tl,\n\t\t\tp.Time(),\n\t\t\tduration,\n\t\t\tp.ToResult(),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\ta.n.handleEvent(event)\n\n\t\t// Prepare an augmented point to return\n\t\tp = p.ShallowCopy()\n\t\ta.augmentTagsWithEventState(p, event.State)\n\t\ta.augmentFieldsWithEventState(p, event.State)\n\t\treturn p, nil\n\t}\n\treturn nil, nil\n}\n\nfunc (a *alertState) augmentTagsWithEventState(p edge.TagSetter, eventState alert.EventState) {\n\tif a.n.a.LevelTag != \"\" || a.n.a.IdTag != \"\" {\n\t\ttags := p.Tags().Copy()\n\t\tif a.n.a.LevelTag != \"\" {\n\t\t\ttags[a.n.a.LevelTag] = eventState.Level.String()\n\t\t}\n\t\tif a.n.a.IdTag != \"\" {\n\t\t\ttags[a.n.a.IdTag] = eventState.ID\n\t\t}\n\t\tp.SetTags(tags)\n\t}\n}\n\nfunc (a *alertState) augmentFieldsWithEventState(p edge.FieldSetter, eventState alert.EventState) {\n\tif a.n.a.LevelField != \"\" || a.n.a.IdField != \"\" || a.n.a.DurationField != \"\" || a.n.a.MessageField != \"\" {\n\t\tfields := p.Fields().Copy()\n\t\tif a.n.a.LevelField != \"\" {\n\t\t\tfields[a.n.a.LevelField] = eventState.Level.String()\n\t\t}\n\t\tif a.n.a.MessageField != \"\" {\n\t\t\tfields[a.n.a.MessageField] = eventState.Message\n\t\t}\n\t\tif a.n.a.IdField != \"\" {\n\t\t\tfields[a.n.a.IdField] = eventState.ID\n\t\t}\n\t\tif a.n.a.DurationField != \"\" {\n\t\t\tfields[a.n.a.DurationField] = int64(eventState.Duration)\n\t\t}\n\t\tp.SetFields(fields)\n\t}\n}\n\nfunc (a *alertState) Barrier(b edge.BarrierMessage) (edge.Message, error) {\n\treturn b, nil\n}\n\nfunc (a *alertState) DeleteGroup(d edge.DeleteGroupMessage) (edge.Message, error) {\n\treturn d, nil\n}\nfunc (a *alertState) Done() {\n\tfor _, inhibitor := range a.inhibitors {\n\t\ta.n.et.tm.AlertService.RemoveInhibitor(inhibitor)\n\t}\n}\n\n// Return the duration of the current alert state.\nfunc (a *alertState) duration() time.Duration {\n\treturn a.lastTriggered.Sub(a.firstTriggered)\n}\n\n// Record that the alert was triggered at time t.\nfunc (a *alertState) triggered(t time.Time) {\n\ta.lastTriggered = t\n\t// Check if we are being triggered for first time since an alert.OKAlert\n\t// If so reset firstTriggered time\n\tp := a.idx - 1\n\tif p == -1 {\n\t\tp = len(a.history) - 1\n\t}\n\tif a.history[p] == alert.OK {\n\t\ta.firstTriggered = t\n\t}\n\n\t// Update inhibitor state\n\tinhibited := a.history[a.idx] != alert.OK\n\tfor _, in := range a.inhibitors {\n\t\tin.Set(inhibited)\n\t}\n}\n\n// Record an event in the alert history.\nfunc (a *alertState) addEvent(t time.Time, level alert.Level) {\n\t// Check for changes\n\ta.changed = a.history[a.idx] != level\n\n\t// Add event to history\n\ta.idx = (a.idx + 1) % len(a.history)\n\ta.history[a.idx] = level\n\n\ta.updateFlapping()\n\ta.updateExpired(t)\n\n}\n\n// Return current level of this state\nfunc (a *alertState) currentLevel() alert.Level {\n\treturn a.history[a.idx]\n}\n\n// Compute the percentage change in the alert history.\nfunc (a *alertState) percentChange() float64 {\n\tl := len(a.history)\n\tchanges := 0.0\n\tweight := (maxWeight / weightDiff)\n\tstep := (maxWeight - weight) / float64(l-1)\n\tfor i := 0; i < l-1; i++ {\n\t\t// get current index\n\t\tc := (i + a.idx) % l\n\t\t// get previous index\n\t\tp := c - 1\n\t\t// check for wrap around\n\t\tif p < 0 {\n\t\t\tp = l - 1\n\t\t}\n\t\tif a.history[c] != a.history[p] {\n\t\t\tchanges += weight\n\t\t}\n\t\tweight += step\n\t}\n\n\tp := changes / float64(l-1)\n\treturn p\n}\n\nfunc (a *alertState) updateFlapping() {\n\tif !a.n.a.UseFlapping {\n\t\treturn\n\t}\n\tp := a.percentChange()\n\tif a.flapping && p < a.n.a.FlapLow {\n\t\ta.flapping = false\n\t} else if !a.flapping && p > a.n.a.FlapHigh {\n\t\ta.flapping = true\n\t}\n}\n\nfunc (a *alertState) updateExpired(t time.Time) {\n\ta.expired = !a.changed && a.n.a.StateChangesOnlyDuration != 0 && t.Sub(a.lastTriggered) >= a.n.a.StateChangesOnlyDuration\n}\n\ntype serverInfo struct {\n\tHostname  string\n\tClusterID string\n\tServerID  string\n}\n\n// Type containing information available to ID template.\ntype idInfo struct {\n\t// Measurement name\n\tName string\n\n\t// Task name\n\tTaskName string\n\n\t// Concatenation of all group-by tags of the form [key=value,]+.\n\t// If not groupBy is performed equal to literal 'nil'\n\tGroup string\n\n\t// Map of tags\n\tTags map[string]string\n\n\tServerInfo serverInfo\n}\n\ntype messageInfo struct {\n\tidInfo\n\n\t// The ID of the alert.\n\tID string\n\n\t// Fields of alerting data point.\n\tFields map[string]interface{}\n\n\t// Alert Level, one of: INFO, WARNING, CRITICAL.\n\tLevel string\n\n\t// Time\n\tTime time.Time\n\n\t// Duration of the alert\n\tDuration time.Duration\n}\n\ntype detailsInfo struct {\n\tmessageInfo\n\t// The Message of the Alert\n\tMessage string\n}\n\nfunc (n *AlertNode) serverInfo() serverInfo {\n\treturn serverInfo{\n\t\tHostname:  n.et.tm.ServerInfo.Hostname(),\n\t\tClusterID: n.et.tm.ServerInfo.ClusterID().String(),\n\t\tServerID:  n.et.tm.ServerInfo.ServerID().String(),\n\t}\n\n}\nfunc (n *AlertNode) renderID(name string, group models.GroupID, tags models.Tags) (string, error) {\n\tg := string(group)\n\tif group == models.NilGroup {\n\t\tg = \"nil\"\n\t}\n\tinfo := idInfo{\n\t\tName:       name,\n\t\tTaskName:   n.et.Task.ID,\n\t\tGroup:      g,\n\t\tTags:       tags,\n\t\tServerInfo: n.serverInfo(),\n\t}\n\tid := n.bufPool.Get().(*bytes.Buffer)\n\tdefer func() {\n\t\tid.Reset()\n\t\tn.bufPool.Put(id)\n\t}()\n\n\terr := n.idTmpl.Execute(id, info)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn id.String(), nil\n}\n\nfunc (n *AlertNode) renderMessageAndDetails(id, name string, t time.Time, group models.GroupID, tags models.Tags, fields models.Fields, level alert.Level, d time.Duration) (string, string, error) {\n\tg := string(group)\n\tif group == models.NilGroup {\n\t\tg = \"nil\"\n\t}\n\tminfo := messageInfo{\n\t\tidInfo: idInfo{\n\t\t\tName:       name,\n\t\t\tTaskName:   n.et.Task.ID,\n\t\t\tGroup:      g,\n\t\t\tTags:       tags,\n\t\t\tServerInfo: n.serverInfo(),\n\t\t},\n\t\tID:       id,\n\t\tFields:   fields,\n\t\tLevel:    level.String(),\n\t\tTime:     t,\n\t\tDuration: d,\n\t}\n\n\t// Grab a buffer for the message template and the details template\n\ttmpBuffer := n.bufPool.Get().(*bytes.Buffer)\n\tdefer func() {\n\t\ttmpBuffer.Reset()\n\t\tn.bufPool.Put(tmpBuffer)\n\t}()\n\ttmpBuffer.Reset()\n\n\terr := n.messageTmpl.Execute(tmpBuffer, minfo)\n\tif err != nil {\n\t\treturn \"\", \"\", err\n\t}\n\n\tmsg := tmpBuffer.String()\n\tdinfo := detailsInfo{\n\t\tmessageInfo: minfo,\n\t\tMessage:     msg,\n\t}\n\n\t// Reuse the buffer, for the details template\n\ttmpBuffer.Reset()\n\terr = n.detailsTmpl.Execute(tmpBuffer, dinfo)\n\tif err != nil {\n\t\treturn \"\", \"\", err\n\t}\n\n\tdetails := tmpBuffer.String()\n\treturn msg, details, nil\n}\n"
        },
        {
          "name": "alert",
          "type": "tree",
          "content": null
        },
        {
          "name": "auth",
          "type": "tree",
          "content": null
        },
        {
          "name": "autoscale.go",
          "type": "blob",
          "size": 14.791015625,
          "content": "package kapacitor\n\nimport (\n\t\"fmt\"\n\t\"time\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/expvar\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n\tec2 \"github.com/influxdata/kapacitor/services/ec2/client\"\n\tk8s \"github.com/influxdata/kapacitor/services/k8s/client\"\n\tswarm \"github.com/influxdata/kapacitor/services/swarm/client\"\n\t\"github.com/influxdata/kapacitor/tick/ast\"\n\t\"github.com/influxdata/kapacitor/tick/stateful\"\n\t\"github.com/pkg/errors\"\n)\n\nconst (\n\tstatsAutoscaleIncreaseEventsCount = \"increase_events\"\n\tstatsAutoscaleDecreaseEventsCount = \"decrease_events\"\n\tstatsAutoscaleCooldownDropsCount  = \"cooldown_drops\"\n)\n\ntype resourceID interface {\n\tID() string\n}\n\ntype autoscaler interface {\n\tResourceIDFromTags(models.Tags) (resourceID, error)\n\tReplicas(id resourceID) (int, error)\n\tSetReplicas(id resourceID, replicas int) error\n\tSetResourceIDOnTags(id resourceID, tags models.Tags)\n}\n\ntype resourceState struct {\n\tlastIncrease time.Time\n\tlastDecrease time.Time\n\tcurrent      int\n}\n\ntype event struct {\n\tID  resourceID\n\tOld int\n\tNew int\n}\n\ntype AutoscaleNode struct {\n\tnode\n\n\ta autoscaler\n\n\treplicasExpr      stateful.Expression\n\treplicasScopePool stateful.ScopePool\n\n\tresourceStates map[string]resourceState\n\n\tincreaseCount      *expvar.Int\n\tdecreaseCount      *expvar.Int\n\tcooldownDropsCount *expvar.Int\n\n\tmin int\n\tmax int\n\n\tincreaseCooldown time.Duration\n\tdecreaseCooldown time.Duration\n\n\tcurrentField string\n}\n\n// Create a new AutoscaleNode which can trigger autoscale events.\nfunc newAutoscaleNode(\n\tet *ExecutingTask,\n\td NodeDiagnostic,\n\tn pipeline.Node,\n\ta autoscaler,\n\tmin,\n\tmax int,\n\tincreaseCooldown,\n\tdecreaseCooldown time.Duration,\n\tcurrentField string,\n\treplicas *ast.LambdaNode,\n) (*AutoscaleNode, error) {\n\tif min < 1 {\n\t\treturn nil, fmt.Errorf(\"minimum count must be >= 1, got %d\", min)\n\t}\n\t// Initialize the replicas lambda expression scope pool\n\treplicasExpr, err := stateful.NewExpression(replicas.Expression)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"invalid replicas expression\")\n\t}\n\treplicasScopePool := stateful.NewScopePool(ast.FindReferenceVariables(replicas.Expression))\n\tkn := &AutoscaleNode{\n\t\tnode:              node{Node: n, et: et, diag: d},\n\t\tresourceStates:    make(map[string]resourceState),\n\t\tmin:               min,\n\t\tmax:               max,\n\t\tincreaseCooldown:  increaseCooldown,\n\t\tdecreaseCooldown:  decreaseCooldown,\n\t\tcurrentField:      currentField,\n\t\ta:                 a,\n\t\treplicasExpr:      replicasExpr,\n\t\treplicasScopePool: replicasScopePool,\n\t}\n\tkn.node.runF = kn.runAutoscale\n\treturn kn, nil\n}\n\nfunc (n *AutoscaleNode) runAutoscale([]byte) error {\n\tn.increaseCount = &expvar.Int{}\n\tn.decreaseCount = &expvar.Int{}\n\tn.cooldownDropsCount = &expvar.Int{}\n\n\tn.statMap.Set(statsAutoscaleIncreaseEventsCount, n.increaseCount)\n\tn.statMap.Set(statsAutoscaleDecreaseEventsCount, n.decreaseCount)\n\tn.statMap.Set(statsAutoscaleCooldownDropsCount, n.cooldownDropsCount)\n\n\tconsumer := edge.NewGroupedConsumer(\n\t\tn.ins[0],\n\t\tn,\n\t)\n\tn.statMap.Set(statCardinalityGauge, consumer.CardinalityVar())\n\treturn consumer.Consume()\n}\n\nfunc (n *AutoscaleNode) NewGroup(group edge.GroupInfo, first edge.PointMeta) (edge.Receiver, error) {\n\treturn edge.NewReceiverFromForwardReceiverWithStats(\n\t\tn.outs,\n\t\tedge.NewTimedForwardReceiver(n.timer, n.newGroup()),\n\t), nil\n}\n\nfunc (n *AutoscaleNode) newGroup() *autoscaleGroup {\n\treturn &autoscaleGroup{\n\t\tn:    n,\n\t\texpr: n.replicasExpr.CopyReset(),\n\t}\n}\n\ntype autoscaleGroup struct {\n\tn *AutoscaleNode\n\n\texpr stateful.Expression\n\n\tbegin edge.BeginBatchMessage\n}\n\nfunc (g *autoscaleGroup) BeginBatch(begin edge.BeginBatchMessage) (edge.Message, error) {\n\tg.begin = begin\n\treturn nil, nil\n}\n\nfunc (g *autoscaleGroup) BatchPoint(bp edge.BatchPointMessage) (edge.Message, error) {\n\tnp, err := g.n.handlePoint(g.begin.Name(), g.begin.Dimensions(), bp, g.expr)\n\tif err != nil {\n\t\tg.n.diag.Error(\"error batch handling point\", err)\n\t}\n\treturn np, nil\n}\n\nfunc (g *autoscaleGroup) EndBatch(end edge.EndBatchMessage) (edge.Message, error) {\n\treturn nil, nil\n}\n\nfunc (g *autoscaleGroup) Point(p edge.PointMessage) (edge.Message, error) {\n\tnp, err := g.n.handlePoint(p.Name(), p.Dimensions(), p, g.expr)\n\tif err != nil {\n\t\tg.n.diag.Error(\"error handling point\", err)\n\t}\n\treturn np, nil\n}\n\nfunc (g *autoscaleGroup) Barrier(b edge.BarrierMessage) (edge.Message, error) {\n\treturn b, nil\n}\nfunc (g *autoscaleGroup) DeleteGroup(d edge.DeleteGroupMessage) (edge.Message, error) {\n\treturn d, nil\n}\nfunc (g *autoscaleGroup) Done() {}\n\nfunc (n *AutoscaleNode) handlePoint(streamName string, dims models.Dimensions, p edge.FieldsTagsTimeGetter, expr stateful.Expression) (edge.PointMessage, error) {\n\tid, err := n.a.ResourceIDFromTags(p.Tags())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tstate, ok := n.resourceStates[id.ID()]\n\tif !ok {\n\t\t// If we haven't seen this resource before, get its state\n\t\treplicas, err := n.a.Replicas(id)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"could not determine initial scale for %q\", id)\n\t\t}\n\t\tstate = resourceState{\n\t\t\tcurrent: replicas,\n\t\t}\n\t\tn.resourceStates[id.ID()] = state\n\t}\n\n\t// Eval the replicas expression\n\tnewReplicas, err := n.evalExpr(state.current, expr, p)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to evaluate the replicas expression\")\n\t}\n\n\t// Create the event\n\te := event{\n\t\tID:  id,\n\t\tOld: state.current,\n\t\tNew: newReplicas,\n\t}\n\t// Check bounds\n\tif n.max > 0 && e.New > n.max {\n\t\te.New = n.max\n\t}\n\tif e.New < n.min {\n\t\te.New = n.min\n\t}\n\n\t// Validate something changed\n\tif e.New == e.Old {\n\t\t// Nothing to do\n\t\treturn nil, nil\n\t}\n\n\t// Update local copy of state\n\tchange := e.New - e.Old\n\tstate.current = e.New\n\n\t// Check last change cooldown times\n\tt := p.Time()\n\tvar counter *expvar.Int\n\tswitch {\n\tcase change > 0:\n\t\tif t.Before(state.lastIncrease.Add(n.increaseCooldown)) {\n\t\t\t// Still hot, nothing to do\n\t\t\tn.cooldownDropsCount.Add(1)\n\t\t\treturn nil, nil\n\t\t}\n\t\tstate.lastIncrease = t\n\t\tcounter = n.increaseCount\n\tcase change < 0:\n\t\tif t.Before(state.lastDecrease.Add(n.decreaseCooldown)) {\n\t\t\t// Still hot, nothing to do\n\t\t\tn.cooldownDropsCount.Add(1)\n\t\t\treturn nil, nil\n\t\t}\n\t\tstate.lastDecrease = t\n\t\tcounter = n.decreaseCount\n\t}\n\n\t// We have a valid event to apply\n\tif err := n.applyEvent(e); err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to apply scaling event\")\n\t}\n\n\t// Only save the updated state if we were successful\n\tn.resourceStates[id.ID()] = state\n\n\t// Count event\n\tcounter.Add(1)\n\n\t// Create new tags for the point.\n\t// Leave room for the namespace,kind, and resource tags.\n\tnewTags := make(models.Tags, len(dims.TagNames)+3)\n\n\t// Copy group by tags\n\tfor _, d := range dims.TagNames {\n\t\tnewTags[d] = p.Tags()[d]\n\t}\n\tn.a.SetResourceIDOnTags(id, newTags)\n\n\t// Create point representing the event\n\treturn edge.NewPointMessage(\n\t\tstreamName, \"\", \"\",\n\t\tdims,\n\t\tmodels.Fields{\n\t\t\t\"old\": int64(e.Old),\n\t\t\t\"new\": int64(e.New),\n\t\t},\n\t\tnewTags,\n\t\tt,\n\t), nil\n}\n\nfunc (n *AutoscaleNode) applyEvent(e event) error {\n\tn.diag.SettingReplicas(e.New, e.Old, e.ID.ID())\n\terr := n.a.SetReplicas(e.ID, e.New)\n\treturn errors.Wrapf(err, \"failed to set new replica count for %q\", e.ID)\n}\n\nfunc (n *AutoscaleNode) evalExpr(\n\tcurrent int,\n\texpr stateful.Expression,\n\tp edge.FieldsTagsTimeGetter,\n) (int, error) {\n\tvars := n.replicasScopePool.Get()\n\tdefer n.replicasScopePool.Put(vars)\n\n\t// Set the current replicas value on the scope if requested.\n\tif n.currentField != \"\" {\n\t\tvars.Set(n.currentField, current)\n\t}\n\n\t// Fill the scope with the rest of the values\n\terr := fillScope(vars, n.replicasScopePool.ReferenceVariables(), p)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\ti, err := expr.EvalInt(vars)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\treturn int(i), err\n}\n\n////////////////////////////////////\n// K8s implementation of Autoscaler\n\ntype k8sAutoscaler struct {\n\tclient k8s.Client\n\n\tresourceName    string\n\tresourceNameTag string\n\n\tnamespaceTag string\n\tkindTag      string\n\tnameTag      string\n\n\tkind string\n\n\tnamespace string\n}\n\nfunc newK8sAutoscaleNode(et *ExecutingTask, n *pipeline.K8sAutoscaleNode, d NodeDiagnostic) (*AutoscaleNode, error) {\n\tclient, err := et.tm.K8sService.Client(n.Cluster)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot use the k8sAutoscale node, could not create kubernetes client: %v\", err)\n\t}\n\ta := &k8sAutoscaler{\n\t\tclient:          client,\n\t\tresourceName:    n.ResourceName,\n\t\tresourceNameTag: n.ResourceNameTag,\n\t\tnamespaceTag:    n.NamespaceTag,\n\t\tkindTag:         n.KindTag,\n\t\tnameTag:         n.ResourceTag,\n\t\tkind:            n.Kind,\n\t\tnamespace:       n.Namespace,\n\t}\n\treturn newAutoscaleNode(\n\t\tet,\n\t\td,\n\t\tn,\n\t\ta,\n\t\tint(n.Min),\n\t\tint(n.Max),\n\t\tn.IncreaseCooldown,\n\t\tn.DecreaseCooldown,\n\t\tn.CurrentField,\n\t\tn.Replicas,\n\t)\n}\n\ntype k8sResourceID struct {\n\tNamespace,\n\tKind,\n\tName string\n}\n\nfunc (id k8sResourceID) ID() string {\n\treturn id.Name\n}\n\nfunc (id k8sResourceID) String() string {\n\treturn fmt.Sprintf(\"%s/%s/%s\", id.Namespace, id.Kind, id.Name)\n}\n\nfunc (a *k8sAutoscaler) ResourceIDFromTags(tags models.Tags) (resourceID, error) {\n\t// Get the name of the resource\n\tvar name string\n\tswitch {\n\tcase a.resourceName != \"\":\n\t\tname = a.resourceName\n\tcase a.resourceNameTag != \"\":\n\t\tt, ok := tags[a.resourceNameTag]\n\t\tif ok {\n\t\t\tname = t\n\t\t}\n\tdefault:\n\t\treturn nil, errors.New(\"expected one of ResourceName or ResourceNameTag to be set\")\n\t}\n\tif name == \"\" {\n\t\treturn nil, errors.New(\"could not determine the name of the resource\")\n\t}\n\tnamespace := a.namespace\n\tif namespace == \"\" {\n\t\tnamespace = k8s.NamespaceDefault\n\t}\n\treturn k8sResourceID{\n\t\tNamespace: namespace,\n\t\tKind:      a.kind,\n\t\tName:      name,\n\t}, nil\n}\n\nfunc (a *k8sAutoscaler) getScale(kid k8sResourceID) (*k8s.Scale, error) {\n\tscales := a.client.Scales(kid.Namespace)\n\tscale, err := scales.Get(kid.Kind, kid.Name)\n\treturn scale, err\n}\n\nfunc (a *k8sAutoscaler) Replicas(id resourceID) (int, error) {\n\tkid := id.(k8sResourceID)\n\tscale, err := a.getScale(kid)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\treturn int(scale.Spec.Replicas), nil\n}\n\nfunc (a *k8sAutoscaler) SetReplicas(id resourceID, replicas int) error {\n\tkid := id.(k8sResourceID)\n\tscale, err := a.getScale(kid)\n\tif err != nil {\n\t\treturn err\n\t}\n\tscale.Spec.Replicas = int32(replicas)\n\tscales := a.client.Scales(kid.Namespace)\n\tif err := scales.Update(kid.Kind, scale); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc (a *k8sAutoscaler) SetResourceIDOnTags(id resourceID, tags models.Tags) {\n\tkid := id.(k8sResourceID)\n\t// Set namespace,kind,resource tags\n\tif a.namespaceTag != \"\" {\n\t\ttags[a.namespaceTag] = kid.Namespace\n\t}\n\tif a.kindTag != \"\" {\n\t\ttags[a.kindTag] = kid.Kind\n\t}\n\tif a.nameTag != \"\" {\n\t\ttags[a.nameTag] = kid.Name\n\t}\n}\n\n/////////////////////////////////////////////\n// Docker Swarm implementation of Autoscaler\n\ntype swarmAutoscaler struct {\n\tclient swarm.Client\n\n\tserviceName          string\n\tserviceNameTag       string\n\toutputServiceNameTag string\n}\n\nfunc newSwarmAutoscaleNode(et *ExecutingTask, n *pipeline.SwarmAutoscaleNode, d NodeDiagnostic) (*AutoscaleNode, error) {\n\tclient, err := et.tm.SwarmService.Client(n.Cluster)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot use the swarmAutoscale node, could not create swarm client: %v\", err)\n\t}\n\toutputServiceNameTag := n.OutputServiceNameTag\n\tif outputServiceNameTag == \"\" {\n\t\toutputServiceNameTag = n.ServiceNameTag\n\t}\n\ta := &swarmAutoscaler{\n\t\tclient:               client,\n\t\tserviceName:          n.ServiceName,\n\t\tserviceNameTag:       n.ServiceNameTag,\n\t\toutputServiceNameTag: outputServiceNameTag,\n\t}\n\treturn newAutoscaleNode(\n\t\tet,\n\t\td,\n\t\tn,\n\t\ta,\n\t\tint(n.Min),\n\t\tint(n.Max),\n\t\tn.IncreaseCooldown,\n\t\tn.DecreaseCooldown,\n\t\tn.CurrentField,\n\t\tn.Replicas,\n\t)\n}\n\ntype swarmResourceID string\n\nfunc (id swarmResourceID) ID() string {\n\treturn string(id)\n}\n\nfunc (a *swarmAutoscaler) ResourceIDFromTags(tags models.Tags) (resourceID, error) {\n\t// Get the name of the resource\n\tvar name string\n\tswitch {\n\tcase a.serviceName != \"\":\n\t\tname = a.serviceName\n\tcase a.serviceNameTag != \"\":\n\t\tt, ok := tags[a.serviceNameTag]\n\t\tif ok {\n\t\t\tname = t\n\t\t}\n\tdefault:\n\t\treturn nil, errors.New(\"expected one of ServiceName or ServiceNameTag to be set\")\n\t}\n\tif name == \"\" {\n\t\treturn nil, errors.New(\"could not determine the name of the resource\")\n\t}\n\treturn swarmResourceID(name), nil\n}\n\nfunc (a *swarmAutoscaler) Replicas(id resourceID) (int, error) {\n\tsid := id.ID()\n\tservice, err := a.client.Service(sid)\n\tif err != nil {\n\t\treturn 0, errors.Wrapf(err, \"failed to get swarm service for %q\", id)\n\t}\n\treturn int(*service.Spec.Mode.Replicated.Replicas), nil\n\n}\n\nfunc (a *swarmAutoscaler) SetReplicas(id resourceID, replicas int) error {\n\tsid := id.ID()\n\tservice, err := a.client.Service(sid)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"failed to get swarm service for %q\", id)\n\t}\n\t*service.Spec.Mode.Replicated.Replicas = uint64(replicas)\n\n\treturn a.client.UpdateService(service)\n}\n\nfunc (a *swarmAutoscaler) SetResourceIDOnTags(id resourceID, tags models.Tags) {\n\tif a.outputServiceNameTag != \"\" {\n\t\ttags[a.outputServiceNameTag] = id.ID()\n\t}\n}\n\n/////////////////////////////////////////////\n// EC2 implementation of Autoscaler\n\ntype ec2Autoscaler struct {\n\tclient ec2.Client\n\n\tgroupName          string\n\tgroupNameTag       string\n\toutputGroupNameTag string\n}\n\nfunc newEc2AutoscaleNode(et *ExecutingTask, n *pipeline.Ec2AutoscaleNode, d NodeDiagnostic) (*AutoscaleNode, error) {\n\tclient, err := et.tm.EC2Service.Client(n.Cluster)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot use the EC2Autoscale node, could not create ec2 client: %v\", err)\n\t}\n\toutputGroupNameTag := n.OutputGroupNameTag\n\tif outputGroupNameTag == \"\" {\n\t\toutputGroupNameTag = n.GroupNameTag\n\t}\n\ta := &ec2Autoscaler{\n\t\tclient: client,\n\n\t\tgroupName:          n.GroupName,\n\t\tgroupNameTag:       n.GroupNameTag,\n\t\toutputGroupNameTag: outputGroupNameTag,\n\t}\n\treturn newAutoscaleNode(\n\t\tet,\n\t\td,\n\t\tn,\n\t\ta,\n\t\tint(n.Min),\n\t\tint(n.Max),\n\t\tn.IncreaseCooldown,\n\t\tn.DecreaseCooldown,\n\t\tn.CurrentField,\n\t\tn.Replicas,\n\t)\n}\n\nfunc (a *ec2Autoscaler) ResourceIDFromTags(tags models.Tags) (resourceID, error) {\n\t// Get the name of the resource\n\tvar name string\n\tswitch {\n\tcase a.groupName != \"\":\n\t\tname = a.groupName\n\tcase a.groupNameTag != \"\":\n\t\tt, ok := tags[a.groupNameTag]\n\t\tif ok {\n\t\t\tname = t\n\t\t}\n\tdefault:\n\t\treturn nil, errors.New(\"expected one of GroupName or GroupNameTag to be set\")\n\t}\n\tif name == \"\" {\n\t\treturn nil, errors.New(\"could not determine the name of the resource\")\n\t}\n\treturn swarmResourceID(name), nil\n}\n\nfunc (a *ec2Autoscaler) Replicas(id resourceID) (int, error) {\n\tsid := id.ID()\n\tgroup, err := a.client.Group(sid)\n\tif err != nil {\n\t\treturn 0, errors.Wrapf(err, \"failed to get ec2 autoscaleGroup for %q\", id)\n\t}\n\tvar desiredcapacity int64\n\tfor _, resp := range group.AutoScalingGroups {\n\t\tdesiredcapacity = *resp.DesiredCapacity\n\t}\n\treturn int(desiredcapacity), nil\n\n}\n\nfunc (a *ec2Autoscaler) SetReplicas(id resourceID, replicas int) error {\n\tsid := id.ID()\n\n\treturn a.client.UpdateGroup(sid, int64(replicas))\n}\n\nfunc (a *ec2Autoscaler) SetResourceIDOnTags(id resourceID, tags models.Tags) {\n\tif a.outputGroupNameTag != \"\" {\n\t\ttags[a.outputGroupNameTag] = id.ID()\n\t}\n}\n"
        },
        {
          "name": "barrier.go",
          "type": "blob",
          "size": 7.5087890625,
          "content": "package kapacitor\n\nimport (\n\t\"errors\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n)\n\ntype BarrierNode struct {\n\tnode\n\tb              *pipeline.BarrierNode\n\tbarrierStopper map[models.GroupID]func()\n}\n\n// Create a new  BarrierNode, which emits a barrier if data traffic has been idle for the configured amount of time.\nfunc newBarrierNode(et *ExecutingTask, n *pipeline.BarrierNode, d NodeDiagnostic) (*BarrierNode, error) {\n\tif n.Idle == 0 && n.Period == 0 {\n\t\treturn nil, errors.New(\"barrier node must have either a non zero idle or a non zero period\")\n\t}\n\tbn := &BarrierNode{\n\t\tnode:           node{Node: n, et: et, diag: d},\n\t\tb:              n,\n\t\tbarrierStopper: map[models.GroupID]func(){},\n\t}\n\tbn.node.runF = bn.runBarrierEmitter\n\treturn bn, nil\n}\n\nfunc (n *BarrierNode) runBarrierEmitter([]byte) error {\n\tdefer n.stopBarrierEmitter()\n\tconsumer := edge.NewGroupedConsumer(n.ins[0], n)\n\tn.statMap.Set(statCardinalityGauge, consumer.CardinalityVar())\n\treturn consumer.Consume()\n}\n\nfunc (n *BarrierNode) stopBarrierEmitter() {\n\tfor _, stopF := range n.barrierStopper {\n\t\tstopF()\n\t}\n}\n\nfunc (n *BarrierNode) NewGroup(group edge.GroupInfo, first edge.PointMeta) (edge.Receiver, error) {\n\tr, stopF, err := n.newBarrier(group, first)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tn.barrierStopper[group.ID] = stopF\n\treturn edge.NewReceiverFromForwardReceiverWithStats(\n\t\tn.outs,\n\t\tedge.NewTimedForwardReceiver(n.timer, r),\n\t), nil\n}\n\nfunc (n *BarrierNode) newBarrier(group edge.GroupInfo, first edge.PointMeta) (edge.ForwardReceiver, func(), error) {\n\tswitch {\n\tcase n.b.Idle > 0:\n\t\tidleBarrier := newIdleBarrier(\n\t\t\tfirst.Name(),\n\t\t\tgroup,\n\t\t\tn.ins[0],\n\t\t\tn.b.Idle,\n\t\t\tn.outs,\n\t\t\tn.b.Delete,\n\t\t)\n\t\treturn idleBarrier, idleBarrier.Stop, nil\n\tcase n.b.Period > 0:\n\t\tperiodicBarrier := newPeriodicBarrier(\n\t\t\tfirst.Name(),\n\t\t\tgroup,\n\t\t\tn.ins[0],\n\t\t\tn.b.Period,\n\t\t\tn.outs,\n\t\t\tn.b.Delete,\n\t\t)\n\t\treturn periodicBarrier, periodicBarrier.Stop, nil\n\tdefault:\n\t\treturn nil, nil, errors.New(\"unreachable code, barrier node should have positive idle or positive period\")\n\t}\n}\n\ntype idleBarrier struct {\n\tname  string\n\tgroup edge.GroupInfo\n\tin    edge.Edge\n\n\tdel          bool\n\tidle         time.Duration\n\tlastPointT   atomic.Value\n\tlastBarrierT atomic.Value\n\twg           sync.WaitGroup\n\touts         []edge.StatsEdge\n\tstopC        chan struct{}\n\tresetTimerC  chan struct{}\n}\n\nfunc newIdleBarrier(name string, group edge.GroupInfo, in edge.Edge, idle time.Duration, outs []edge.StatsEdge, del bool) *idleBarrier {\n\tr := &idleBarrier{\n\t\tname:         name,\n\t\tgroup:        group,\n\t\tin:           in,\n\t\tidle:         idle,\n\t\tlastPointT:   atomic.Value{},\n\t\tlastBarrierT: atomic.Value{},\n\t\twg:           sync.WaitGroup{},\n\t\touts:         outs,\n\t\tstopC:        make(chan struct{}, 1),\n\t\tresetTimerC:  make(chan struct{}, 1),\n\t\tdel:          del,\n\t}\n\n\tr.Init()\n\n\treturn r\n}\n\nfunc (n *idleBarrier) Init() {\n\tn.lastPointT.Store(time.Now().UTC())\n\tn.lastBarrierT.Store(time.Time{})\n\tn.wg.Add(1)\n\n\tgo n.idleHandler()\n}\n\nfunc (n *idleBarrier) Stop() {\n\tn.stop()\n\tn.wg.Wait()\n}\n\nfunc (n *idleBarrier) stop() {\n\t// Send a stop signal at least once to the stop channel.\n\t// The stop channel has a buffer of size one and only the\n\t// first stop signal matters.\n\tselect {\n\tcase n.stopC <- struct{}{}:\n\tdefault:\n\t}\n}\n\nfunc (n *idleBarrier) BeginBatch(m edge.BeginBatchMessage) (edge.Message, error) {\n\treturn m, nil\n}\nfunc (n *idleBarrier) BatchPoint(m edge.BatchPointMessage) (edge.Message, error) {\n\tif !m.Time().Before(n.lastBarrierT.Load().(time.Time)) {\n\t\tn.resetTimer()\n\t\tn.lastPointT.Store(m.Time())\n\t\treturn m, nil\n\t}\n\treturn nil, nil\n}\nfunc (n *idleBarrier) EndBatch(m edge.EndBatchMessage) (edge.Message, error) {\n\treturn m, nil\n}\nfunc (n *idleBarrier) Barrier(m edge.BarrierMessage) (edge.Message, error) {\n\tif !m.Time().Before(n.lastBarrierT.Load().(time.Time)) {\n\t\tn.resetTimer()\n\t\tn.lastPointT.Store(m.Time())\n\t\tn.lastBarrierT.Store(m.Time())\n\t\treturn m, nil\n\t}\n\treturn nil, nil\n}\nfunc (n *idleBarrier) DeleteGroup(m edge.DeleteGroupMessage) (edge.Message, error) {\n\tif m.GroupID() == n.group.ID {\n\t\t// Signal that the idle barrier should stop.\n\t\tn.stop()\n\t}\n\treturn m, nil\n}\nfunc (n *idleBarrier) Done() {}\n\nfunc (n *idleBarrier) Point(m edge.PointMessage) (edge.Message, error) {\n\tif !m.Time().Before(n.lastBarrierT.Load().(time.Time)) {\n\t\tn.resetTimer()\n\t\tn.lastPointT.Store(m.Time())\n\t\treturn m, nil\n\t}\n\treturn nil, nil\n}\n\nfunc (n *idleBarrier) resetTimer() {\n\t// The first reset will be buffered and subsequent resets when the\n\t// channel is full can be safely discarded because the reset signal\n\t// has already been sent.\n\tselect {\n\tcase n.resetTimerC <- struct{}{}:\n\tdefault:\n\t}\n}\n\nfunc (n *idleBarrier) emitBarrier() error {\n\tnewT := n.lastPointT.Load().(time.Time).Add(n.idle)\n\tn.lastPointT.Store(newT)\n\tn.lastBarrierT.Store(newT)\n\n\terr := edge.Forward(n.outs, edge.NewBarrierMessage(n.group, newT))\n\tif err != nil {\n\t\treturn err\n\t}\n\tif n.del {\n\t\treturn n.in.Collect(edge.NewDeleteGroupMessage(n.group))\n\t}\n\treturn nil\n}\n\nfunc (n *idleBarrier) idleHandler() {\n\tdefer n.wg.Done()\n\tidleTimer := time.NewTimer(n.idle)\n\tfor {\n\t\tselect {\n\t\tcase <-n.resetTimerC:\n\t\t\tif !idleTimer.Stop() {\n\t\t\t\t<-idleTimer.C\n\t\t\t}\n\t\t\tidleTimer.Reset(n.idle)\n\t\tcase <-idleTimer.C:\n\t\t\tn.emitBarrier()\n\t\t\tidleTimer.Reset(n.idle)\n\t\tcase <-n.stopC:\n\t\t\tidleTimer.Stop()\n\t\t\treturn\n\t\t}\n\t}\n}\n\ntype periodicBarrier struct {\n\tname  string\n\tgroup edge.GroupInfo\n\tin    edge.Edge\n\n\tdel    bool\n\tlastT  atomic.Value\n\tticker *time.Ticker\n\twg     sync.WaitGroup\n\touts   []edge.StatsEdge\n\tstopC  chan struct{}\n}\n\nfunc newPeriodicBarrier(name string, group edge.GroupInfo, in edge.Edge, period time.Duration, outs []edge.StatsEdge, del bool) *periodicBarrier {\n\tr := &periodicBarrier{\n\t\tname:   name,\n\t\tgroup:  group,\n\t\tin:     in,\n\t\tlastT:  atomic.Value{},\n\t\tticker: time.NewTicker(period),\n\t\twg:     sync.WaitGroup{},\n\t\touts:   outs,\n\t\tstopC:  make(chan struct{}),\n\t\tdel:    del,\n\t}\n\n\tr.Init()\n\n\treturn r\n}\n\nfunc (n *periodicBarrier) Init() {\n\tn.lastT.Store(time.Time{})\n\tn.wg.Add(1)\n\n\tgo n.periodicEmitter()\n}\n\nfunc (n *periodicBarrier) Stop() {\n\tselect {\n\tcase <-n.stopC:\n\tdefault:\n\t\tclose(n.stopC)\n\t\tn.ticker.Stop()\n\t\tn.wg.Wait()\n\t}\n}\n\nfunc (n *periodicBarrier) BeginBatch(m edge.BeginBatchMessage) (edge.Message, error) {\n\treturn m, nil\n}\nfunc (n *periodicBarrier) BatchPoint(m edge.BatchPointMessage) (edge.Message, error) {\n\tif !m.Time().Before(n.lastT.Load().(time.Time)) {\n\t\treturn m, nil\n\t}\n\treturn nil, nil\n}\nfunc (n *periodicBarrier) EndBatch(m edge.EndBatchMessage) (edge.Message, error) {\n\treturn m, nil\n}\nfunc (n *periodicBarrier) Barrier(m edge.BarrierMessage) (edge.Message, error) {\n\tif !m.Time().Before(n.lastT.Load().(time.Time)) {\n\t\treturn m, nil\n\t}\n\treturn nil, nil\n}\nfunc (n *periodicBarrier) DeleteGroup(m edge.DeleteGroupMessage) (edge.Message, error) {\n\tif m.GroupID() == n.group.ID {\n\t\tn.Stop()\n\t}\n\treturn m, nil\n}\nfunc (n *periodicBarrier) Done() {}\n\nfunc (n *periodicBarrier) Point(m edge.PointMessage) (edge.Message, error) {\n\tif !m.Time().Before(n.lastT.Load().(time.Time)) {\n\t\treturn m, nil\n\t}\n\treturn nil, nil\n}\n\nfunc (n *periodicBarrier) emitBarrier() error {\n\tnowT := time.Now().UTC()\n\tn.lastT.Store(nowT)\n\terr := edge.Forward(n.outs, edge.NewBarrierMessage(n.group, nowT))\n\tif err != nil {\n\t\treturn err\n\t}\n\tif n.del {\n\t\t// Send DeleteGroupMessage into self\n\t\treturn n.in.Collect(edge.NewDeleteGroupMessage(n.group))\n\t}\n\treturn nil\n}\n\nfunc (n *periodicBarrier) periodicEmitter() {\n\tdefer n.wg.Done()\n\tfor {\n\t\tselect {\n\t\tcase <-n.ticker.C:\n\t\t\tn.emitBarrier()\n\t\tcase <-n.stopC:\n\t\t\treturn\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "batch.go",
          "type": "blob",
          "size": 16.177734375,
          "content": "package kapacitor\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/gorhill/cronexpr\"\n\t\"github.com/influxdata/influxql\"\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/expvar\"\n\t\"github.com/influxdata/kapacitor/influxdb\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n\t\"github.com/pkg/errors\"\n)\n\nconst (\n\tstatsBatchesQueried = \"batches_queried\"\n\tstatsPointsQueried  = \"points_queried\"\n)\n\ntype BatchNode struct {\n\tnode\n\ts   *pipeline.BatchNode\n\tidx int\n}\n\nfunc newBatchNode(et *ExecutingTask, n *pipeline.BatchNode, d NodeDiagnostic) (*BatchNode, error) {\n\tsn := &BatchNode{\n\t\tnode: node{Node: n, et: et, diag: d},\n\t\ts:    n,\n\t}\n\treturn sn, nil\n}\n\nfunc (n *BatchNode) linkChild(c Node) error {\n\n\t// add child\n\tif n.Provides() != c.Wants() {\n\t\treturn fmt.Errorf(\"cannot add child mismatched edges: %s -> %s\", n.Provides(), c.Wants())\n\t}\n\tn.children = append(n.children, c)\n\n\t// add parent\n\tc.addParent(n)\n\n\treturn nil\n}\n\nfunc (n *BatchNode) addParentEdge(in edge.StatsEdge) {\n\t// Pass edges down to children\n\tn.children[n.idx].addParentEdge(in)\n\tn.idx++\n}\n\nfunc (n *BatchNode) start([]byte) {\n}\n\nfunc (n *BatchNode) Wait() error {\n\treturn nil\n}\n\n// Return list of databases and retention policies\n// the batcher will query.\nfunc (n *BatchNode) DBRPs() ([]DBRP, error) {\n\tvar dbrps []DBRP\n\tfor _, b := range n.children {\n\t\tswitch b := b.(type) {\n\t\tcase *QueryNode:\n\t\t\tif b != nil {\n\t\t\t\td, err := b.DBRPs()\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tdbrps = append(dbrps, d...)\n\t\t\t}\n\t\tcase *FluxQueryNode:\n\t\t\t// flux queries don't really have DBRPs\n\t\tdefault:\n\t\t\tpanic(\"BatchNode shouldn't be followed by anything except QueryNode or QueryFluxNode\")\n\t\t}\n\t}\n\treturn dbrps, nil\n}\n\nfunc (n *BatchNode) Count() int {\n\treturn len(n.children)\n}\n\nfunc (n *BatchNode) Start() {\n\tfor _, b := range n.children {\n\t\tswitch b := b.(type) {\n\t\tcase *QueryNode:\n\t\t\tb.Start()\n\t\tcase *FluxQueryNode:\n\t\t\tb.Start()\n\t\tdefault:\n\t\t\tpanic(\"BatchNode shouldn't be followed by anything except QueryNode or QueryFluxNode\")\n\t\t}\n\t}\n}\n\nfunc (n *BatchNode) Abort() {\n\tfor _, b := range n.children {\n\t\tswitch b := b.(type) {\n\t\tcase *QueryNode:\n\t\t\tb.Abort()\n\t\tcase *FluxQueryNode:\n\t\t\tb.Abort()\n\t\tdefault:\n\t\t\tpanic(\"BatchNode shouldn't be followed by anything except QueryNode or QueryFluxNode\")\n\t\t}\n\t}\n}\n\ntype BatchQueries struct {\n\tQueries            []*Query\n\tFluxQueries        []*QueryFlux\n\tCluster            string\n\tGroupByMeasurement bool\n}\n\nfunc (n *BatchNode) Queries(start, stop time.Time) ([]BatchQueries, error) {\n\tqueries := make([]BatchQueries, len(n.children))\n\tfor i, qn := range n.children {\n\t\tswitch qn := qn.(type) {\n\t\tcase *QueryNode:\n\t\t\tqs, err := qn.Queries(start, stop)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tqueries[i] = BatchQueries{\n\t\t\t\tQueries:            qs,\n\t\t\t\tCluster:            qn.Cluster(),\n\t\t\t\tGroupByMeasurement: qn.GroupByMeasurement(),\n\t\t\t}\n\n\t\tcase *FluxQueryNode:\n\t\t\tqs, err := qn.Queries(start, stop)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tqueries[i] = BatchQueries{\n\t\t\t\tFluxQueries: qs,\n\t\t\t\tCluster:     qn.Cluster(),\n\t\t\t}\n\n\t\tdefault:\n\t\t\tpanic(\"BatchNode shouldn't be followed by anything except QueryNode or QueryFluxNode\")\n\t\t}\n\n\t}\n\treturn queries, nil\n}\n\n// Do not add the source batch node to the dot output\n// since its not really an edge.\nfunc (n *BatchNode) edot(*bytes.Buffer, bool) {}\n\nfunc (n *BatchNode) collectedCount() (count int64) {\n\tfor _, child := range n.children {\n\t\tcount += child.collectedCount()\n\t}\n\treturn\n}\n\ntype QueryNode struct {\n\tnode\n\tb        *pipeline.QueryNode\n\tquery    *Query\n\tticker   ticker\n\tqueryMu  sync.Mutex\n\tqueryErr chan error\n\tclosing  chan struct{}\n\taborting chan struct{}\n\n\tbatchesQueried *expvar.Int\n\tpointsQueried  *expvar.Int\n\tbyName         bool\n}\n\nfunc newQueryNode(et *ExecutingTask, n *pipeline.QueryNode, d NodeDiagnostic) (*QueryNode, error) {\n\tbn := &QueryNode{\n\t\tnode:     node{Node: n, et: et, diag: d},\n\t\tb:        n,\n\t\tclosing:  make(chan struct{}),\n\t\taborting: make(chan struct{}),\n\t\tbyName:   n.GroupByMeasurementFlag,\n\t}\n\tbn.node.runF = bn.runBatch\n\tbn.node.stopF = bn.stopBatch\n\n\t// Create query\n\tq, err := NewQuery(n.QueryStr)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tbn.query = q\n\t// Add in dimensions\n\terr = bn.query.Dimensions(n.Dimensions)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// Set offset alignment\n\tif n.AlignGroupFlag {\n\t\tbn.query.AlignGroup()\n\t}\n\t// Set fill\n\tswitch fill := n.Fill.(type) {\n\tcase string:\n\t\tswitch fill {\n\t\tcase \"null\":\n\t\t\tbn.query.Fill(influxql.NullFill, nil)\n\t\tcase \"none\":\n\t\t\tbn.query.Fill(influxql.NoFill, nil)\n\t\tcase \"previous\":\n\t\t\tbn.query.Fill(influxql.PreviousFill, nil)\n\t\tcase \"linear\":\n\t\t\tbn.query.Fill(influxql.LinearFill, nil)\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"unexpected fill option %s\", fill)\n\t\t}\n\tcase int64, float64:\n\t\tbn.query.Fill(influxql.NumberFill, fill)\n\t}\n\n\t// Determine schedule\n\tif n.Every != 0 && n.Cron != \"\" {\n\t\treturn nil, errors.New(\"must not set both 'every' and 'cron' properties\")\n\t}\n\tswitch {\n\tcase n.Every > 0:\n\t\tbn.ticker = newTimeTicker(n.Every, n.AlignFlag)\n\tcase n.Cron != \"\":\n\t\tvar err error\n\t\tbn.ticker, err = newCronTicker(n.Cron)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\tcase n.Every < 0:\n\t\treturn nil, errors.New(\"'every' duration must must non-negative\")\n\tdefault:\n\t\treturn nil, errors.New(\"must define one of 'every' or 'cron'\")\n\t}\n\n\treturn bn, nil\n}\n\nfunc (n *QueryNode) GroupByMeasurement() bool {\n\treturn n.byName\n}\n\n// Return list of databases and retention policies\n// the batcher will query.\nfunc (n *QueryNode) DBRPs() ([]DBRP, error) {\n\treturn n.query.DBRPs()\n}\n\nfunc (n *QueryNode) Start() {\n\tn.queryMu.Lock()\n\tdefer n.queryMu.Unlock()\n\tn.queryErr = make(chan error, 1)\n\tgo func() {\n\t\tn.queryErr <- n.doQuery(n.ins[0])\n\t}()\n}\n\nfunc (n *QueryNode) Abort() {\n\tclose(n.aborting)\n}\n\nfunc (n *QueryNode) Cluster() string {\n\treturn n.b.Cluster\n}\n\nfunc (n *QueryNode) Queries(start, stop time.Time) ([]*Query, error) {\n\tnow := time.Now()\n\tif stop.IsZero() {\n\t\tstop = now\n\t}\n\t// Crons are sensitive to timezones.\n\t// Make sure we are using local time.\n\tcurrent := start.Local()\n\tqueries := make([]*Query, 0)\n\tfor {\n\t\tcurrent = n.ticker.Next(current)\n\t\tif current.IsZero() || current.After(stop) {\n\t\t\tbreak\n\t\t}\n\t\tqstop := current.Add(-1 * n.b.Offset)\n\t\tif qstop.After(now) {\n\t\t\tbreak\n\t\t}\n\n\t\tq, err := n.query.Clone()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tq.SetStartTime(qstop.Add(-1 * n.b.Period))\n\t\tq.SetStopTime(qstop)\n\t\tqueries = append(queries, q)\n\t}\n\treturn queries, nil\n}\n\n// Query InfluxDB and collect batches on batch collector.\nfunc (n *QueryNode) doQuery(in edge.Edge) error {\n\tdefer in.Close()\n\tn.batchesQueried = &expvar.Int{}\n\tn.pointsQueried = &expvar.Int{}\n\n\tn.statMap.Set(statsBatchesQueried, n.batchesQueried)\n\tn.statMap.Set(statsPointsQueried, n.pointsQueried)\n\n\tif n.et.tm.InfluxDBService == nil {\n\t\treturn errors.New(\"InfluxDB not configured, cannot query InfluxDB for batch query\")\n\t}\n\n\tcon, err := n.et.tm.InfluxDBService.NewNamedClient(n.b.Cluster)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"failed to get InfluxDB client\")\n\t}\n\ttickC := n.ticker.Start()\n\tfor {\n\t\tselect {\n\t\tcase <-n.closing:\n\t\t\treturn nil\n\t\tcase <-n.aborting:\n\t\t\treturn errors.New(\"batch doQuery aborted\")\n\t\tcase now := <-tickC:\n\t\t\tn.timer.Start()\n\t\t\t// Update times for query\n\t\t\tstop := now.Add(-1 * n.b.Offset)\n\t\t\tn.query.SetStartTime(stop.Add(-1 * n.b.Period))\n\t\t\tn.query.SetStopTime(stop)\n\n\t\t\tqStr := n.query.String()\n\t\t\tn.diag.StartingBatchQuery(qStr)\n\n\t\t\t// Execute query\n\t\t\tq := influxdb.Query{\n\t\t\t\tCommand: qStr,\n\t\t\t}\n\t\t\tresp, err := con.Query(q)\n\t\t\tif err != nil {\n\t\t\t\tn.diag.Error(\"error executing query\", err)\n\t\t\t\tn.timer.Stop()\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// Collect batches\n\t\t\tfor _, res := range resp.Results {\n\t\t\t\tbatches, err := edge.ResultToBufferedBatches(res, n.byName)\n\t\t\t\tif err != nil {\n\t\t\t\t\tn.diag.Error(\"failed to understand query result\", err)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tfor _, bch := range batches {\n\t\t\t\t\t// Set stop time based off query bounds\n\t\t\t\t\tif bch.Begin().Time().IsZero() || !n.query.IsGroupedByTime() {\n\t\t\t\t\t\tbch.Begin().SetTime(stop)\n\t\t\t\t\t}\n\n\t\t\t\t\tn.batchesQueried.Add(1)\n\t\t\t\t\tn.pointsQueried.Add(int64(len(bch.Points())))\n\n\t\t\t\t\tn.timer.Pause()\n\t\t\t\t\tif err := in.Collect(bch); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tn.timer.Resume()\n\t\t\t\t}\n\t\t\t}\n\t\t\tn.timer.Stop()\n\t\t}\n\t}\n}\n\nfunc (n *QueryNode) runBatch([]byte) error {\n\terrC := make(chan error, 1)\n\tgo func() {\n\t\tdefer func() {\n\t\t\terr := recover()\n\t\t\tif err != nil {\n\t\t\t\terrC <- fmt.Errorf(\"%v\", err)\n\t\t\t}\n\t\t}()\n\t\tfor bt, ok := n.ins[0].Emit(); ok; bt, ok = n.ins[0].Emit() {\n\t\t\tfor _, child := range n.outs {\n\t\t\t\terr := child.Collect(bt)\n\t\t\t\tif err != nil {\n\t\t\t\t\terrC <- err\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\terrC <- nil\n\t}()\n\tvar queryErr error\n\tn.queryMu.Lock()\n\tif n.queryErr != nil {\n\t\tn.queryMu.Unlock()\n\t\tselect {\n\t\tcase queryErr = <-n.queryErr:\n\t\tcase <-n.aborting:\n\t\t\tqueryErr = errors.New(\"batch queryErr aborted\")\n\t\t}\n\t} else {\n\t\tn.queryMu.Unlock()\n\t}\n\n\tvar err error\n\tselect {\n\tcase err = <-errC:\n\tcase <-n.aborting:\n\t\terr = errors.New(\"batch run aborted\")\n\t}\n\tif queryErr != nil {\n\t\treturn queryErr\n\t}\n\treturn err\n}\n\nfunc (n *QueryNode) stopBatch() {\n\tif n.ticker != nil {\n\t\tn.ticker.Stop()\n\t}\n\tclose(n.closing)\n}\n\ntype ticker interface {\n\tStart() <-chan time.Time\n\tStop()\n\t// Return the next time the ticker will tick after now.\n\tNext(now time.Time) time.Time\n}\n\ntype timeTicker struct {\n\tevery     time.Duration\n\talign     bool\n\talignChan chan time.Time\n\tstopping  chan struct{}\n\tticker    *time.Ticker\n\tmu        sync.Mutex\n\twg        sync.WaitGroup\n}\n\nfunc newTimeTicker(every time.Duration, align bool) *timeTicker {\n\tt := &timeTicker{\n\t\talign: align,\n\t\tevery: every,\n\t}\n\tif align {\n\t\tt.alignChan = make(chan time.Time)\n\t\tt.stopping = make(chan struct{})\n\t}\n\treturn t\n}\n\nfunc (t *timeTicker) Start() <-chan time.Time {\n\tt.mu.Lock()\n\tdefer t.mu.Unlock()\n\tif t.alignChan != nil {\n\t\tt.wg.Add(1)\n\t\tgo func() {\n\t\t\tdefer t.wg.Done()\n\t\t\t// Sleep until we are roughly aligned\n\t\t\tnow := time.Now()\n\t\t\tnext := now.Truncate(t.every).Add(t.every)\n\t\t\tafter := time.NewTicker(next.Sub(now))\n\t\t\tselect {\n\t\t\tcase <-after.C:\n\t\t\t\tafter.Stop()\n\t\t\tcase <-t.stopping:\n\t\t\t\tafter.Stop()\n\t\t\t\treturn\n\t\t\t}\n\t\t\tt.ticker = time.NewTicker(t.every)\n\t\t\t// Send first event since we waited for it explicitly\n\t\t\tt.alignChan <- next\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-t.stopping:\n\t\t\t\t\treturn\n\t\t\t\tcase now := <-t.ticker.C:\n\t\t\t\t\tnow = now.Round(t.every)\n\t\t\t\t\tt.alignChan <- now\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t\treturn t.alignChan\n\t} else {\n\t\tt.ticker = time.NewTicker(t.every)\n\t\treturn t.ticker.C\n\t}\n}\n\nfunc (t *timeTicker) Stop() {\n\tt.mu.Lock()\n\tdefer t.mu.Unlock()\n\tif t.ticker != nil {\n\t\tt.ticker.Stop()\n\t}\n\tif t.alignChan != nil {\n\t\tclose(t.stopping)\n\t}\n\tt.wg.Wait()\n}\n\nfunc (t *timeTicker) Next(now time.Time) time.Time {\n\tnext := now.Add(t.every)\n\tif t.align {\n\t\tnext = next.Round(t.every)\n\t}\n\treturn next\n}\n\ntype cronTicker struct {\n\texpr    *cronexpr.Expression\n\tticker  chan time.Time\n\tclosing chan struct{}\n\twg      sync.WaitGroup\n}\n\nfunc newCronTicker(cronExpr string) (*cronTicker, error) {\n\texpr, err := cronexpr.Parse(cronExpr)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &cronTicker{\n\t\texpr:    expr,\n\t\tticker:  make(chan time.Time),\n\t\tclosing: make(chan struct{}),\n\t}, nil\n}\n\nfunc (c *cronTicker) Start() <-chan time.Time {\n\tc.wg.Add(1)\n\tgo func() {\n\t\tdefer c.wg.Done()\n\t\tfor {\n\t\t\tnow := time.Now()\n\t\t\tnext := c.expr.Next(now)\n\t\t\tdiff := next.Sub(now)\n\t\t\tselect {\n\t\t\tcase <-time.After(diff):\n\t\t\t\tc.ticker <- next\n\t\t\tcase <-c.closing:\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}()\n\treturn c.ticker\n}\n\nfunc (c *cronTicker) Stop() {\n\tclose(c.closing)\n\tc.wg.Wait()\n}\n\nfunc (c *cronTicker) Next(now time.Time) time.Time {\n\treturn c.expr.Next(now)\n}\n\n// FluxQueryNode is a node for making flux queries\ntype FluxQueryNode struct {\n\tnode\n\tb        *pipeline.QueryFluxNode\n\tquery    *QueryFlux\n\tticker   ticker\n\tqueryMu  sync.Mutex\n\tqueryErr chan error\n\tclosing  chan struct{}\n\taborting chan struct{}\n\n\tbatchesQueried *expvar.Int\n\tpointsQueried  *expvar.Int\n\tbyName         bool\n}\n\nfunc newQueryFluxNode(et *ExecutingTask, n *pipeline.QueryFluxNode, d NodeDiagnostic) (*FluxQueryNode, error) {\n\tbn := &FluxQueryNode{\n\t\tnode:     node{Node: n, et: et, diag: d},\n\t\tb:        n,\n\t\tclosing:  make(chan struct{}),\n\t\taborting: make(chan struct{}),\n\t}\n\tbn.node.runF = bn.runBatch\n\tbn.node.stopF = bn.stopBatch\n\n\t// Create query\n\tq, err := NewQueryFlux(n.QueryStr, n.Org, n.OrgID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tbn.query = q\n\t// Determine schedule\n\tif n.Every != 0 && n.Cron != \"\" {\n\t\treturn nil, errors.New(\"must not set both 'every' and 'cron' properties\")\n\t}\n\tswitch {\n\tcase n.Every > 0:\n\t\tbn.ticker = newTimeTicker(n.Every, n.AlignFlag)\n\tcase n.Cron != \"\":\n\t\tvar err error\n\t\tbn.ticker, err = newCronTicker(n.Cron)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\tcase n.Every < 0:\n\t\treturn nil, errors.New(\"'every' duration must must non-negative\")\n\tdefault:\n\t\treturn nil, errors.New(\"must define one of 'every' or 'cron'\")\n\t}\n\n\treturn bn, nil\n}\n\nfunc (n *FluxQueryNode) Start() {\n\tn.queryMu.Lock()\n\tdefer n.queryMu.Unlock()\n\tn.queryErr = make(chan error, 1)\n\tgo func() {\n\t\tn.queryErr <- n.doQuery(n.ins[0])\n\t}()\n}\n\nfunc (n *FluxQueryNode) Abort() {\n\tclose(n.aborting)\n}\n\nfunc (n *FluxQueryNode) Cluster() string {\n\treturn n.b.Cluster\n}\n\nfunc (n *FluxQueryNode) Queries(start, stop time.Time) ([]*QueryFlux, error) {\n\tnow := time.Now()\n\tif stop.IsZero() {\n\t\tstop = now\n\t}\n\t// Crons are sensitive to timezones.\n\t// Make sure we are using local time.\n\tcurrent := start.Local()\n\tqueries := make([]*QueryFlux, 0)\n\tfor {\n\t\tcurrent = n.ticker.Next(current)\n\t\tif current.IsZero() || current.After(stop) {\n\t\t\tbreak\n\t\t}\n\t\tqstop := current.Add(-1 * n.b.Offset)\n\t\tif qstop.After(now) {\n\t\t\tbreak\n\t\t}\n\n\t\tq, err := n.query.Clone()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tq.Now = now\n\t\tqueries = append(queries, q)\n\t}\n\treturn queries, nil\n}\n\n// Query InfluxDB and collect batches on batch collector.\nfunc (n *FluxQueryNode) doQuery(in edge.Edge) (err error) {\n\tdefer in.Close()\n\tn.batchesQueried = &expvar.Int{}\n\tn.pointsQueried = &expvar.Int{}\n\n\tn.statMap.Set(statsBatchesQueried, n.batchesQueried)\n\tn.statMap.Set(statsPointsQueried, n.pointsQueried)\n\n\tif n.et.tm.InfluxDBService == nil {\n\t\treturn errors.New(\"InfluxDB not configured, cannot query InfluxDB for batch query\")\n\t}\n\n\tcon, err := n.et.tm.InfluxDBService.NewNamedClient(n.b.Cluster)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"failed to get InfluxDB client\")\n\t}\n\ttickC := n.ticker.Start()\n\tfor {\n\t\tselect {\n\t\tcase <-n.closing:\n\t\t\treturn nil\n\t\tcase <-n.aborting:\n\t\t\treturn errors.New(\"batch doQuery aborted\")\n\t\tcase now := <-tickC:\n\t\t\tn.timer.Start()\n\t\t\t// Update times for query\n\t\t\tn.query.Now = now.Add(-1 * n.b.Offset) //SetStartTime(stop.Add(-1 * n.b.Period))\n\t\t\tn.diag.StartingBatchQuery(n.query.stmt)\n\n\t\t\t// Execute query\n\t\t\tresp, err := con.QueryFluxResponse(influxdb.FluxQuery{\n\t\t\t\tQuery: n.query.stmt,\n\t\t\t\tOrg:   n.query.org,\n\t\t\t\tOrgID: n.query.orgID,\n\t\t\t\tNow:   n.query.Now,\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\tn.diag.Error(\"error executing query\", err)\n\t\t\t\tn.timer.Stop()\n\t\t\t\tbreak\n\t\t\t}\n\t\t\t//Collect batches\n\t\t\tfor _, res := range resp.Results {\n\t\t\t\tbatches, err := edge.ResultToBufferedBatches(res, n.byName)\n\t\t\t\tif err != nil {\n\t\t\t\t\tn.diag.Error(\"failed to understand query result\", err)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tfor _, bch := range batches {\n\t\t\t\t\t// Set stop time based off query bounds\n\t\t\t\t\tif bch.Begin().Time().IsZero() {\n\t\t\t\t\t\tbch.Begin().SetTime(now)\n\t\t\t\t\t}\n\t\t\t\t\tn.batchesQueried.Add(1)\n\t\t\t\t\tn.pointsQueried.Add(int64(len(bch.Points())))\n\n\t\t\t\t\tn.timer.Pause()\n\t\t\t\t\tif err := in.Collect(bch); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tn.timer.Resume()\n\t\t\t\t}\n\t\t\t}\n\t\t\tn.timer.Stop()\n\t\t}\n\t}\n}\n\nfunc (n *FluxQueryNode) runBatch([]byte) error {\n\terrC := make(chan error, 1)\n\tgo func() {\n\t\tdefer func() {\n\t\t\terr := recover()\n\t\t\tif err != nil {\n\t\t\t\terrC <- fmt.Errorf(\"%v\", err)\n\t\t\t}\n\t\t}()\n\t\tfor bt, ok := n.ins[0].Emit(); ok; bt, ok = n.ins[0].Emit() {\n\t\t\tfor _, child := range n.outs {\n\t\t\t\terr := child.Collect(bt)\n\t\t\t\tif err != nil {\n\t\t\t\t\terrC <- err\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\terrC <- nil\n\t}()\n\tvar queryErr error\n\tn.queryMu.Lock()\n\tif n.queryErr != nil {\n\t\tn.queryMu.Unlock()\n\t\tselect {\n\t\tcase queryErr = <-n.queryErr:\n\t\tcase <-n.aborting:\n\t\t\tqueryErr = errors.New(\"batch queryErr aborted\")\n\t\t}\n\t} else {\n\t\tn.queryMu.Unlock()\n\t}\n\n\tvar err error\n\tselect {\n\tcase err = <-errC:\n\tcase <-n.aborting:\n\t\terr = errors.New(\"batch run aborted\")\n\t}\n\tif queryErr != nil {\n\t\treturn queryErr\n\t}\n\treturn err\n}\n\nfunc (n *FluxQueryNode) stopBatch() {\n\tif n.ticker != nil {\n\t\tn.ticker.Stop()\n\t}\n\tclose(n.closing)\n}\n"
        },
        {
          "name": "bufpool",
          "type": "tree",
          "content": null
        },
        {
          "name": "build.py",
          "type": "blob",
          "size": 39.052734375,
          "content": "#!/usr/bin/python3\n\nimport argparse\nimport hashlib\nimport logging\nimport os\nimport re\nimport shutil\nimport subprocess\nimport sys\nimport tempfile\nfrom datetime import datetime\n\n################\n#### Kapacitor Variables\n################\n\n# Enable Go vendoring\nos.environ[\"GO15VENDOREXPERIMENT\"] = \"1\"\n\n# PACKAGING VARIABLES\nPACKAGE_NAME = \"kapacitor\"\nUSER = \"kapacitor\"\nGROUP = \"kapacitor\"\nINSTALL_ROOT_DIR = \"/usr/bin\"\nLOG_DIR = \"/var/log/kapacitor\"\nDATA_DIR = \"/var/lib/kapacitor\"\nSCRIPT_DIR = \"/usr/lib/kapacitor/scripts\"\n\nINIT_SCRIPT = \"scripts/init.sh\"\nSYSTEMD_SCRIPT = \"scripts/kapacitor.service\"\nPREINST_SCRIPT = \"scripts/pre-install.sh\"\nPOSTINST_SCRIPT = \"scripts/post-install.sh\"\nPOSTUNINST_SCRIPT = \"scripts/post-uninstall.sh\"\nLOGROTATE_CONFIG = \"etc/logrotate.d/kapacitor\"\nBASH_COMPLETION_SH = \"usr/share/bash-completion/completions/kapacitor\"\nDEFAULT_CONFIG = \"etc/kapacitor/kapacitor.conf\"\n\n# Default AWS S3 bucket for uploads\nDEFAULT_BUCKET = \"dl.influxdata.com/kapacitor/artifacts\"\n\n# META-PACKAGE VARIABLES\nPACKAGE_LICENSE = \"MIT\"\nPACKAGE_URL = \"github.com/influxdata/kapacitor\"\nMAINTAINER = \"support@influxdb.com\"\nVENDOR = \"InfluxData\"\nDESCRIPTION = \"Time series data processing engine\"\n\n# SCRIPT START\ngo_vet_command = \"go vet ./...\"\nprereqs = [ 'git', 'go' ]\noptional_prereqs = [ 'fpm', 'rpmbuild', 'gpg' ]\n\nfpm_common_args = \"-f -s dir --log error \\\n --vendor {} \\\n --url {} \\\n --before-install {} \\\n --after-install {} \\\n --after-remove {} \\\n --license {} \\\n --maintainer {} \\\n --config-files {} \\\n --config-files {} \\\n --directories {} \\\n --rpm-attr 755,{},{}:{} \\\n --rpm-attr 755,{},{}:{} \\\n --description \\\"{}\\\"\".format(\n        VENDOR,\n        PACKAGE_URL,\n        PREINST_SCRIPT,\n        POSTINST_SCRIPT,\n        POSTUNINST_SCRIPT,\n        PACKAGE_LICENSE,\n        MAINTAINER,\n        DEFAULT_CONFIG,\n        LOGROTATE_CONFIG,\n        ' --directories '.join([\n                         LOG_DIR[1:],\n                         DATA_DIR[1:],\n                         SCRIPT_DIR[1:],\n                         os.path.dirname(SCRIPT_DIR[1:]),\n                         os.path.dirname(DEFAULT_CONFIG),\n                    ]),\n        USER, GROUP, LOG_DIR,\n        USER, GROUP, DATA_DIR,\n        DESCRIPTION)\n\ntargets = {\n    'kapacitor' : './cmd/kapacitor',\n    'kapacitord' : './cmd/kapacitord',\n    'tickfmt' : './tick/cmd/tickfmt'\n}\n\nsupported_builds = {\n    'darwin': [ \"amd64\" ],\n    'linux': [ \"arm64\", \"amd64\" ],\n    'windows': [ \"amd64\" ]\n}\n\nsupported_packages = {\n    \"darwin\": [ \"tar\"],\n    \"linux\": [ \"deb\", \"rpm\", \"tar\"],\n    # experimental\n    \"windows\": [ \"zip\" ]\n}\n\n################\n#### Kapacitor Functions\n################\n\ndef print_banner():\n    logging.info(\"\"\"\n\n'##:::'##::::'###::::'########:::::'###:::::'######::'####:'########::'#######::'########::\n ##::'##::::'## ##::: ##.... ##:::'## ##:::'##... ##:. ##::... ##..::'##.... ##: ##.... ##:\n ##:'##::::'##:. ##:: ##:::: ##::'##:. ##:: ##:::..::: ##::::: ##:::: ##:::: ##: ##:::: ##:\n #####::::'##:::. ##: ########::'##:::. ##: ##:::::::: ##::::: ##:::: ##:::: ##: ########::\n ##. ##::: #########: ##.....::: #########: ##:::::::: ##::::: ##:::: ##:::: ##: ##.. ##:::\n ##:. ##:: ##.... ##: ##:::::::: ##.... ##: ##::: ##:: ##::::: ##:::: ##:::: ##: ##::. ##::\n ##::. ##: ##:::: ##: ##:::::::: ##:::: ##:. ######::'####:::: ##::::. #######:: ##:::. ##:\n..::::..::..:::::..::..:::::::::..:::::..:::......:::....:::::..::::::.......:::..:::::..::\n Build Script\n\"\"\")\n\ndef create_package_fs(build_root):\n    \"\"\"Create a filesystem structure to mimic the package filesystem.\n    \"\"\"\n    logging.debug(\"Creating a filesystem hierarchy from directory: {}\".format(build_root))\n    # Using [1:] for the path names due to them being absolute\n    # (will overwrite previous paths, per 'os.path.join' documentation)\n    os.makedirs(os.path.join(build_root, INSTALL_ROOT_DIR[1:]))\n    os.makedirs(os.path.join(build_root, LOG_DIR[1:]))\n    os.makedirs(os.path.join(build_root, DATA_DIR[1:]))\n    os.makedirs(os.path.join(build_root, SCRIPT_DIR[1:]))\n    os.makedirs(os.path.join(build_root, os.path.dirname(DEFAULT_CONFIG)))\n    os.makedirs(os.path.join(build_root, os.path.dirname(LOGROTATE_CONFIG)))\n    os.makedirs(os.path.join(build_root, os.path.dirname(BASH_COMPLETION_SH)))\n\ndef package_scripts(build_root, config_only=False):\n    \"\"\"Copy the necessary scripts and configuration files to the package\n    filesystem.\n    \"\"\"\n    if config_only:\n        logging.info(\"Copying configuration to build directory.\")\n        conf_name = os.path.basename(DEFAULT_CONFIG)\n        shutil.copyfile(DEFAULT_CONFIG, os.path.join(build_root, conf_name))\n        os.chmod(os.path.join(build_root, conf_name), 0o644)\n    else:\n        logging.info(\"Copying scripts and configuration to build directory\")\n        shutil.copy(INIT_SCRIPT, os.path.join(build_root, SCRIPT_DIR[1:], INIT_SCRIPT.split('/')[1]))\n        shutil.copy(SYSTEMD_SCRIPT, os.path.join(build_root, SCRIPT_DIR[1:], SYSTEMD_SCRIPT.split('/')[1]))\n        shutil.copy(LOGROTATE_CONFIG, os.path.join(build_root, LOGROTATE_CONFIG))\n        shutil.copy(BASH_COMPLETION_SH, os.path.join(build_root, BASH_COMPLETION_SH))\n        shutil.copy(DEFAULT_CONFIG, os.path.join(build_root, DEFAULT_CONFIG))\n        os.chmod(os.path.join(build_root, LOGROTATE_CONFIG), 0o644)\n\ndef run_generate():\n    \"\"\"Run 'go generate' to rebuild any static assets.\n    \"\"\"\n    logging.info(\"Running generate...\")\n    run(\"\"\"go install -mod=mod\n        google.golang.org/protobuf/cmd/protoc-gen-go \\\n        github.com/benbjohnson/tmpl \\\n        github.com/mailru/easyjson/easyjson \\\n        github.com/influxdata/pkg-config\"\"\")\n    try:\n         subprocess.check_output([\"go\", \"generate\", \"./...\"])\n    except subprocess.CalledProcessError as exc:\n        print(\"Status : FAIL\", exc.returncode, exc.output)\n        return False\n    return True\n\ndef go_get():\n    \"\"\"\n    Retrieve build dependencies or restore pinned dependencies.\n    \"\"\"\n    return True\n\n\ndef run_tests(race, parallel, timeout, verbose):\n    \"\"\"Run the Go test suite on binary output.\n    \"\"\"\n    # NOTE: We download deps here because go fmt on go1.17 first downloads missing deps, printing their names and\n    # giving the appearance of files that need reformatted.\n    logging.info(\"Downloading dependencies...\")\n    try:\n        download_cmd = [\"go\", \"mod\", \"download\"]\n        if verbose:\n            download_cmd.append(\"-x\")\n        subprocess.check_output(download_cmd)\n    except subprocess.CalledProcessError as exc:\n        logging.error(\"Downloading dependencies failed, see logs for details\")\n        logging.error(\"{}\".format(exc.output))\n\n    logging.info(\"Starting tests...\")\n    if race:\n        logging.info(\"Race is enabled.\")\n    if parallel is not None:\n        logging.info(\"Using parallel: {}\".format(parallel))\n    if timeout is not None:\n        logging.info(\"Using timeout: {}\".format(timeout))\n\n    test_command = \"go test --failfast\"\n    if verbose:\n        test_command += \" -v\"\n    if race:\n        test_command += \" -race\"\n    if parallel is not None:\n        test_command += \" -parallel {}\".format(parallel)\n    if timeout is not None:\n        test_command += \" -timeout {}\".format(timeout)\n    test_command += \" ./...\"\n    logging.info(\"Running tests...\")\n    logging.info(\"Test command: \" + test_command)\n    output = run(test_command, printOutput=logging.getLogger().getEffectiveLevel() == logging.DEBUG)\n    return True\n\ndef package_udfs(version, dist_dir):\n    \"\"\"\n    Create packages for UDF agents\n    \"\"\"\n    logging.info(\"Packaging UDF agents\")\n    packages = package_python_udf(version, dist_dir)\n    return packages\n\ndef package_python_udf(version, dist_dir):\n    \"\"\"\n    Bundle python sources for UDF agent\n    \"\"\"\n    logging.debug(\"Packaging python UDF agent\")\n\n    # Update python package version\n    version_file = './udf/agent/py/kapacitor/udf/__init__.py'\n    with open(version_file, 'w') as f:\n        f.write('VERSION = \"{}\"\\n'.format(version))\n\n    # Create tar of python sources\n    fname = \"python-kapacitor_udf-{}.tar.gz\".format(version)\n    outfile = os.path.join(dist_dir, fname)\n\n    tar_cmd = ['tar', '-cz', '-C', './udf/agent/py', '--owner=root', '--group=root', '--transform', 's/^./kapacitor_udf-{}/'.format(version), '-f']\n    tar_cmd.append(outfile)\n    exclude_list = ['*.pyc', '*.pyo', '__pycache__']\n    for e in exclude_list:\n        tar_cmd.append('--exclude='+e)\n    tar_cmd.append('./')\n    p = subprocess.Popen(tar_cmd)\n    code = p.wait()\n    if code != 0:\n        logging.error(\"Python UDF tar failed.\")\n        sys.exit(1)\n\n    # Revert version file\n    version_file = './udf/agent/py/kapacitor/udf/__init__.py'\n    with open(version_file, 'w') as f:\n        f.write('VERSION = \"\"\\n')\n\n    return [outfile]\n\n\n################\n#### All Kapacitor-specific content above this line\n################\n\ndef run(command, allow_failure=False, shell=False, printOutput=False):\n    \"\"\"\n    Run shell command (convenience wrapper around subprocess).\n\n    If printOutput is True then the output is sent to STDOUT and not returned\n    \"\"\"\n    out = None\n    logging.debug(\"{}\".format(command))\n    try:\n        cmd = command\n        if not shell:\n            cmd = command.split()\n\n        stdout = subprocess.PIPE\n        stderr = subprocess.STDOUT\n        if printOutput:\n            stdout = None\n\n        p = subprocess.Popen(cmd, shell=shell, stdout=stdout, stderr=stderr)\n        out, _ = p.communicate()\n        if out is not None:\n            out = out.decode('utf-8').strip()\n        if p.returncode != 0:\n            if allow_failure:\n                logging.warn(u\"Command '{}' failed with error: {}\".format(command, out))\n                return None\n            else:\n                logging.error(u\"Command '{}' failed with error: {}\".format(command, out))\n                sys.exit(1)\n    except OSError as e:\n        if allow_failure:\n            logging.warn(\"Command '{}' failed with error: {}\".format(command, e))\n            return out\n        else:\n            logging.error(\"Command '{}' failed with error: {}\".format(command, e))\n            sys.exit(1)\n    else:\n        return out\n\ndef create_temp_dir(prefix = None):\n    \"\"\" Create temporary directory with optional prefix.\n    \"\"\"\n    if prefix is None:\n        return tempfile.mkdtemp(prefix=\"{}-build.\".format(PACKAGE_NAME))\n    else:\n        return tempfile.mkdtemp(prefix=prefix)\n\ndef increment_minor_version(version):\n    \"\"\"Return the version with the minor version incremented and patch\n    version set to zero.\n    \"\"\"\n    ver_list = version.split('.')\n    if len(ver_list) != 3:\n        logging.warn(\"Could not determine how to increment version '{}', will just use provided version.\".format(version))\n        return version\n    ver_list[1] = str(int(ver_list[1]) + 1)\n    ver_list[2] = str(0)\n    inc_version = '.'.join(ver_list)\n    logging.debug(\"Incremented version from '{}' to '{}'.\".format(version, inc_version))\n    return inc_version\n\ndef get_current_version_tag():\n    \"\"\"Retrieve the raw git version tag.\n    \"\"\"\n    version = run(\"git describe --always --tags --abbrev=0\")\n    return version\n\ndef get_current_version():\n    \"\"\"Parse version information from git tag output.\n    \"\"\"\n    version_tag = get_current_version_tag()\n    # Remove leading 'v'\n    if version_tag[0] == 'v':\n        version_tag = version_tag[1:]\n    # Replace any '-'/'_' with '~'\n    if '-' in version_tag:\n        version_tag = version_tag.replace(\"-\",\"~\")\n    if '_' in version_tag:\n        version_tag = version_tag.replace(\"_\",\"~\")\n    return version_tag\n\ndef get_current_commit(short=False):\n    \"\"\"Retrieve the current git commit.\n    \"\"\"\n    command = None\n    if short:\n        command = \"git log --pretty=format:'%h' -n 1\"\n    else:\n        command = \"git rev-parse HEAD\"\n    out = run(command)\n    return out.strip('\\'\\n\\r ')\n\ndef get_current_branch():\n    \"\"\"Retrieve the current git branch.\n    \"\"\"\n    command = \"git rev-parse --abbrev-ref HEAD\"\n    out = run(command)\n    return out.strip()\n\ndef local_changes():\n    \"\"\"Return True if there are local un-committed changes.\n    \"\"\"\n    output = run(\"git diff-files --ignore-submodules --\").strip()\n    if len(output) > 0:\n        return True\n    return False\n\ndef get_system_arch():\n    \"\"\"Retrieve current system architecture.\n    \"\"\"\n    arch = os.uname()[4]\n    if arch == \"x86_64\":\n        arch = \"amd64\"\n    elif arch == \"aarch64\":\n        arch = \"arm64\"\n    elif 'arm' in arch:\n        # Prevent uname from reporting full ARM arch (eg 'armv7l')\n        arch = \"arm64\"\n    return arch\n\ndef get_system_platform():\n    \"\"\"Retrieve current system platform.\n    \"\"\"\n    if sys.platform.startswith(\"linux\"):\n        return \"linux\"\n    else:\n        return sys.platform\n\ndef get_go_version():\n    \"\"\"Retrieve version information for Go.\n    \"\"\"\n    out = run(\"go version\")\n    matches = re.search('go version go(\\S+)', out)\n    if matches is not None:\n        return matches.groups()[0].strip()\n    return None\n\ndef check_path_for(b):\n    \"\"\"Check the the user's path for the provided binary.\n    \"\"\"\n    def is_exe(fpath):\n        return os.path.isfile(fpath) and os.access(fpath, os.X_OK)\n\n    for path in os.environ[\"PATH\"].split(os.pathsep):\n        path = path.strip('\"')\n        full_path = os.path.join(path, b)\n        if os.path.isfile(full_path) and os.access(full_path, os.X_OK):\n            return full_path\n\ndef check_prereqs():\n    \"\"\"Check user path for required dependencies.\n    \"\"\"\n    logging.info(\"Checking for dependencies...\")\n    for req in prereqs:\n        if not check_path_for(req):\n            logging.error(\"Could not find dependency: {}\".format(req))\n            return False\n    return True\n\ndef upload_packages(packages, bucket_name=None, overwrite=False):\n    \"\"\"Upload provided package output to AWS S3.\n    \"\"\"\n    logging.debug(\"Uploading files to bucket '{}': {}\".format(bucket_name, packages))\n    try:\n        import boto\n        from boto.s3.key import Key\n        from boto.s3.connection import OrdinaryCallingFormat\n        logging.getLogger(\"boto\").setLevel(logging.WARNING)\n    except ImportError:\n        logging.warn(\"Cannot upload packages without 'boto' Python library!\")\n        return False\n    logging.info(\"Connecting to AWS S3...\")\n    # Up the number of attempts to 10 from default of 1\n    boto.config.add_section(\"Boto\")\n    boto.config.set(\"Boto\", \"metadata_service_num_attempts\", \"10\")\n    c = boto.connect_s3(calling_format=OrdinaryCallingFormat())\n    if bucket_name is None:\n        bucket_name = DEFAULT_BUCKET\n    bucket = c.get_bucket(bucket_name.split('/')[0])\n    for p in packages:\n        if '/' in bucket_name:\n            # Allow for nested paths within the bucket name (ex:\n            # bucket/folder). Assuming forward-slashes as path\n            # delimiter.\n            name = os.path.join('/'.join(bucket_name.split('/')[1:]),\n                                os.path.basename(p))\n        else:\n            name = os.path.basename(p)\n        logging.debug(\"Using key: {}\".format(name))\n        if bucket.get_key(name) is None or overwrite:\n            logging.info(\"Uploading file {}\".format(name))\n            k = Key(bucket)\n            k.key = name\n            if overwrite:\n                n = k.set_contents_from_filename(p, replace=True)\n            else:\n                n = k.set_contents_from_filename(p, replace=False)\n            k.make_public()\n        else:\n            logging.warn(\"Not uploading file {}, as it already exists in the target bucket.\".format(name))\n    return True\n\ndef build(version=None,\n          platform=None,\n          arch=None,\n          nightly=False,\n          race=False,\n          clean=False,\n          cc=\"\",\n          outdir=\".\",\n          tags=[],\n          static=False):\n    \"\"\"Build each target for the specified architecture and platform.\n    \"\"\"\n    logging.info(\"Starting build for {}/{}...\".format(platform, arch))\n    logging.info(\"Using Go version: {}\".format(get_go_version()))\n    logging.info(\"Using git branch: {}\".format(get_current_branch()))\n    logging.info(\"Using git commit: {}\".format(get_current_commit()))\n    if static:\n        logging.info(\"Using statically-compiled output.\")\n    if race:\n        logging.info(\"Race is enabled.\")\n    if len(tags) > 0:\n        logging.info(\"Using build tags: {}\".format(','.join(tags)))\n\n    logging.info(\"Sending build output to: {}\".format(outdir))\n    if not os.path.exists(outdir):\n        os.makedirs(outdir)\n    elif clean and outdir != '/' and outdir != \".\":\n        logging.info(\"Cleaning build directory '{}' before building.\".format(outdir))\n        shutil.rmtree(outdir)\n        os.makedirs(outdir)\n\n    logging.info(\"Using version '{}' for build.\".format(version))\n\n    tmp_build_dir = create_temp_dir()\n    for target, path in targets.items():\n        logging.info(\"Building target: {}\".format(target))\n        build_command = \". /root/.cargo/env && \"\n\n        build_command += \"CGO_ENABLED=1 \"\n\n        # Handle variations in architecture output\n        fullarch = arch\n        if  arch == \"aarch64\" or arch == \"arm64\":\n            arch = \"arm64\"\n\n        if platform == \"linux\":\n            if arch == \"amd64\":\n                tags += [\"netgo\", \"osusergo\", \"static_build\"]\n            if arch == \"arm64\":\n                cc = \"/musl/aarch64/bin/musl-gcc\"\n                tags += [\"netgo\", \"osusergo\", \"static_build\", \"noasm\"]\n        elif platform == \"darwin\" and arch == \"amd64\":\n            cc = \"x86_64-apple-darwin18-clang\"\n            tags += [ \"netgo\", \"osusergo\"]\n        elif  platform == \"windows\" and arch == \"amd64\":\n            cc = \"x86_64-w64-mingw32-gcc\"\n        build_command += \"CC={} GOOS={} GOARCH={} \".format(cc, platform, arch)\n\n        if \"arm\" in fullarch:\n            if  fullarch != \"arm64\":\n                logging.error(\"Invalid ARM architecture specified: {} only arm64 is supported\".format(arch))\n                return False\n        if platform == 'windows':\n            target = target + '.exe'\n            build_command += \"go build -buildmode=exe -o {} \".format(os.path.join(outdir, target))\n        else:\n            build_command += \"go build -o {} \".format(os.path.join(outdir, target))\n        if race:\n            build_command += \"-race \"\n        if len(tags) > 0:\n            build_command += \"-tags \\\"{}\\\" \".format(' '.join(tags))\n\n            # Starting with Go 1.5, the linker flag arguments changed to 'name=value' from 'name value'\n        build_command += \"-ldflags=\\\"\"\n        if static:\n            build_command +=\"-s \"\n        if platform == \"linux\":\n            build_command += r'-extldflags \\\"-fno-PIC -Wl,-z,stack-size=8388608,--allow-multiple-definition\\\"  '\n        build_command += '-X main.version={} -X main.branch={} -X main.commit={} -X main.platform=OSS\" '.format(version,\n                                                                                                            get_current_branch(),\n                                                                                                            get_current_commit())\n        if static:\n            build_command += \"-a -installsuffix cgo \"\n        build_command += path\n        start_time = datetime.utcnow()\n        run(build_command, shell=True)\n        end_time = datetime.utcnow()\n        logging.info(\"Time taken: {}s\".format((end_time - start_time).total_seconds()))\n    return True\n\ndef generate_sha256_from_file(path):\n    \"\"\"Generate SHA256 signature based on the contents of the file at path.\n    \"\"\"\n    m = hashlib.sha256()\n    with open(path, 'rb') as f:\n        for chunk in iter(lambda: f.read(4096), b\"\"):\n            m.update(chunk)\n    return m.hexdigest()\n\ndef generate_sig_from_file(path):\n    \"\"\"Generate a detached GPG signature from the file at path.\n    \"\"\"\n    logging.debug(\"Generating GPG signature for file: {}\".format(path))\n    gpg_path = check_path_for('gpg')\n    if gpg_path is None:\n        logging.warn(\"gpg binary not found on path! Skipping signature creation.\")\n        return False\n    if os.environ.get(\"GNUPG_HOME\") is not None:\n        run('gpg --homedir {} --armor --yes --detach-sign {}'.format(os.environ.get(\"GNUPG_HOME\"), path))\n    else:\n        run('gpg --armor --detach-sign --yes {}'.format(path))\n    return True\n\ndef package(build_output, pkg_name, version, nightly=False, iteration=1, static=False, release=False):\n    \"\"\"Package the output of the build process.\n    \"\"\"\n    outfiles = []\n    tmp_build_dir = create_temp_dir()\n    logging.debug(\"Packaging for build output: {}\".format(build_output))\n    logging.info(\"Using temporary directory: {}\".format(tmp_build_dir))\n    try:\n        for platform in build_output:\n            # Create top-level folder displaying which platform (linux, etc)\n            os.makedirs(os.path.join(tmp_build_dir, platform))\n            for arch in build_output[platform]:\n                logging.info(\"Creating packages for {}/{}\".format(platform, arch))\n                # Create second-level directory displaying the architecture (amd64, etc)\n                current_location = build_output[platform][arch]\n\n                # Create directory tree to mimic file system of package\n                build_root = os.path.join(tmp_build_dir,\n                                          platform,\n                                          arch,\n                                          '{}-{}-{}'.format(PACKAGE_NAME, version, iteration))\n                os.makedirs(build_root)\n\n                # Copy packaging scripts to build directory\n                if platform == \"windows\" or static or \"static_\" in arch:\n                    # For windows and static builds, just copy\n                    # binaries to root of package (no other scripts or\n                    # directories)\n                    package_scripts(build_root, config_only=True)\n                else:\n                    create_package_fs(build_root)\n                    package_scripts(build_root)\n\n                for binary in targets:\n                    # Copy newly-built binaries to packaging directory\n                    if platform == 'windows':\n                        binary = binary + '.exe'\n                    if platform == 'windows' or static or \"static_\" in arch:\n                        # Where the binary should go in the package filesystem\n                        to = os.path.join(build_root, binary)\n                        # Where the binary currently is located\n                        fr = os.path.join(current_location, binary)\n                    else:\n                        # Where the binary currently is located\n                        fr = os.path.join(current_location, binary)\n                        # Where the binary should go in the package filesystem\n                        to = os.path.join(build_root, INSTALL_ROOT_DIR[1:], binary)\n                    shutil.copy(fr, to)\n\n                for package_type in supported_packages[platform]:\n                    # Package the directory structure for each package type for the platform\n                    logging.debug(\"Packaging directory '{}' as '{}'.\".format(build_root, package_type))\n                    name = pkg_name\n                    # Reset version, iteration, and current location on each run\n                    # since they may be modified below.\n                    package_version = version\n                    package_iteration = iteration\n                    if \"static_\" in arch:\n                        # Remove the \"static_\" from the displayed arch on the package\n                        package_arch = arch.replace(\"static_\", \"\")\n                    else:\n                        package_arch = arch\n                    if not release and not nightly:\n                        # For non-release builds, just use the commit hash as the version\n                        package_version = \"{}~{}\".format(version,\n                                                         get_current_commit(short=True))\n                        package_iteration = \"0\"\n                    package_build_root = build_root\n                    current_location = build_output[platform][arch]\n\n                    if package_type in ['zip', 'tar']:\n                        # For tars and zips, start the packaging one folder above\n                        # the build root (to include the package name)\n                        package_build_root = os.path.join('/', '/'.join(build_root.split('/')[:-1]))\n                        if nightly:\n                            if static or \"static_\" in arch:\n                                name = '{}-static-nightly_{}_{}'.format(name,\n                                                                        platform,\n                                                                        package_arch)\n                            else:\n                                name = '{}-nightly_{}_{}'.format(name,\n                                                                 platform,\n                                                                 package_arch)\n                        else:\n                            if static or \"static_\" in arch:\n                                name = '{}-{}-static_{}_{}'.format(name,\n                                                                   package_version,\n                                                                   platform,\n                                                                   package_arch)\n                            else:\n                                name = '{}-{}_{}_{}'.format(name,\n                                                            package_version,\n                                                            platform,\n                                                            package_arch)\n                        current_location = os.path.join(os.getcwd(), current_location)\n                        if package_type == 'tar':\n                            tar_command = \"cd {} && tar -cvzf {}.tar.gz --owner=root --group=root ./*\".format(package_build_root, name)\n                            run(tar_command, shell=True)\n                            run(\"mv {}.tar.gz {}\".format(os.path.join(package_build_root, name), current_location), shell=True)\n                            outfile = os.path.join(current_location, name + \".tar.gz\")\n                            outfiles.append(outfile)\n                        elif package_type == 'zip':\n                            zip_command = \"cd {} && zip -r {}.zip ./*\".format(package_build_root, name)\n                            run(zip_command, shell=True)\n                            run(\"mv {}.zip {}\".format(os.path.join(package_build_root, name), current_location), shell=True)\n                            outfile = os.path.join(current_location, name + \".zip\")\n                            outfiles.append(outfile)\n                    elif package_type not in ['zip', 'tar'] and static or \"static_\" in arch:\n                        logging.info(\"Skipping package type '{}' for static builds.\".format(package_type))\n                    else:\n                        fpm_command = \"fpm {} --name {} -a {} -t {} --version {} --iteration {} -C {} -p {} \".format(\n                            fpm_common_args,\n                            name,\n                            package_arch,\n                            package_type,\n                            package_version,\n                            package_iteration,\n                            package_build_root,\n                            current_location)\n                        if package_type == \"rpm\":\n                            fpm_command += \"--depends coreutils --depends shadow-utils --rpm-posttrans {}\".format(POSTINST_SCRIPT)\n                        out = run(fpm_command, shell=True)\n                        matches = re.search(':path=>\"(.*)\"', out)\n                        outfile = None\n                        if matches is not None:\n                            outfile = matches.groups()[0]\n                        if outfile is None:\n                            logging.warn(\"Could not determine output from packaging output!\")\n                        else:\n                            if nightly:\n                                # Strip nightly version from package name\n                                new_outfile = outfile.replace(\"{}-{}\".format(package_version, package_iteration), \"nightly\")\n                                os.rename(outfile, new_outfile)\n                                outfile = new_outfile\n                            outfiles.append(os.path.join(os.getcwd(), outfile))\n        logging.debug(\"Produced package files: {}\".format(outfiles))\n        return outfiles\n    finally:\n        # Cleanup\n        shutil.rmtree(tmp_build_dir)\n\ndef main(args):\n    global PACKAGE_NAME\n\n    if args.release and args.nightly:\n        logging.error(\"Cannot be both a nightly and a release.\")\n        return 1\n\n    if args.nightly:\n        args.version = \"n{}-{}\".format(\n                                       datetime.utcnow().strftime(\"%Y%m%d%H%M\"),\n                                       args.commit)\n        args.iteration = 0\n\n    # Validate version\n    if not re.match(r'^[-\\d\\w\\.]+', args.version):\n        logging.error(\"Invalid version {}\".format(args.version))\n        return 1\n\n    # Pre-build checks\n    if not check_prereqs():\n        return 1\n    if args.build_tags is None:\n        args.build_tags = []\n    else:\n        args.build_tags = args.build_tags.split(',')\n\n    orig_commit = get_current_commit(short=True)\n    orig_branch = get_current_branch()\n\n    if args.platform not in supported_builds and args.platform != 'all':\n        logging.error(\"Invalid build platform: {}\".format(args.platform))\n        return 1\n\n    build_output = {}\n\n    if args.branch != orig_branch and args.commit != orig_commit:\n        logging.error(\"Can only specify one branch or commit to build from.\")\n        return 1\n    elif args.branch != orig_branch:\n        logging.info(\"Moving to git branch: {}\".format(args.branch))\n        run(\"git checkout {}\".format(args.branch))\n    elif args.commit != orig_commit:\n        logging.info(\"Moving to git commit: {}\".format(args.commit))\n        run(\"git checkout {}\".format(args.commit))\n\n    if not args.no_get:\n        if not go_get():\n            return 1\n\n    if args.generate:\n        if not run_generate():\n            return 1\n\n    if args.test:\n        if not run_tests(args.race, args.parallel, args.timeout, args.verbose):\n            return 1\n\n    platforms = []\n    single_build = True\n    if args.platform == 'all':\n        platforms = supported_builds.keys()\n        single_build = False\n    else:\n        platforms = [args.platform]\n\n    for platform in platforms:\n        build_output.update( { platform : {} } )\n        archs = []\n        if args.arch == \"all\":\n            single_build = False\n            archs = supported_builds.get(platform)\n        else:\n            archs = [args.arch]\n\n        for arch in archs:\n            od = args.outdir\n            if not single_build:\n                od = os.path.join(args.outdir, platform, arch)\n            if not build(version=args.version,\n                         platform=platform,\n                         arch=arch,\n                         nightly=args.nightly,\n                         race=args.race,\n                         clean=args.clean,\n                         outdir=od,\n                         tags=args.build_tags,\n                         static=args.static):\n                return 1\n            build_output.get(platform).update( { arch : od } )\n\n    # Build packages\n    if args.package:\n        if not check_path_for(\"fpm\"):\n            logging.error(\"FPM ruby gem required for packaging. Stopping.\")\n            return 1\n        packages = package(build_output,\n                           args.name,\n                           args.version,\n                           nightly=args.nightly,\n                           iteration=args.iteration,\n                           static=args.static,\n                           release=args.release)\n\n        if args.package_udfs:\n            packages += package_udfs(args.version, args.outdir)\n\n        if args.checksum:\n            logging.debug(\"Generating checksums for packages: {}\".format(packages))\n            checksums = []\n            for p in packages:\n                checksum = generate_sha256_from_file(p)\n                sha_filename = p + '.sha256'\n                with open(sha_filename, 'w+') as fp:\n                    fp.write(checksum)\n                checksums.append(sha_filename)\n\n            packages += checksums\n        if args.sign:\n            logging.debug(\"Generating GPG signatures for packages: {}\".format(packages))\n            sigs = [] # retain signatures so they can be uploaded with packages\n            for p in packages:\n                if generate_sig_from_file(p):\n                    sigs.append(p + '.asc')\n                else:\n                    logging.error(\"Creation of signature for package [{}] failed!\".format(p))\n                    return 1\n            packages += sigs\n        if args.upload:\n            logging.debug(\"Files staged for upload: {}\".format(packages))\n            if args.nightly:\n                args.upload_overwrite = True\n            if not upload_packages(packages, bucket_name=args.bucket, overwrite=args.upload_overwrite):\n                return 1\n        logging.info(\"Packages and files created:\")\n        for p in packages:\n            logging.info(\"{}\".format(p.split('/')[-1:][0]))\n\n\n    if orig_branch != get_current_branch():\n        logging.info(\"Moving back to original git branch: {}\".format(args.branch))\n        run(\"git checkout {}\".format(orig_branch))\n\n    return 0\n\nif __name__ == '__main__':\n    LOG_LEVEL = logging.INFO\n    if '--debug' in sys.argv[1:]:\n        LOG_LEVEL = logging.DEBUG\n    log_format = '[%(levelname)s] %(funcName)s: %(message)s'\n    logging.basicConfig(level=LOG_LEVEL,\n                        format=log_format)\n\n    parser = argparse.ArgumentParser(description='InfluxDB build and packaging script.')\n    parser.add_argument('--verbose','-v','--debug',\n                        action='store_true',\n                        help='Use debug output')\n    parser.add_argument('--outdir', '-o',\n                        metavar='<output directory>',\n                        default='./build/',\n                        type=os.path.abspath,\n                        help='Output directory')\n    parser.add_argument('--name', '-n',\n                        metavar='<name>',\n                        default=PACKAGE_NAME,\n                        type=str,\n                        help='Name to use for package name (when package is specified)')\n    parser.add_argument('--arch',\n                        metavar='<amd64|arm64|all>',\n                        type=str,\n                        default=get_system_arch(),\n                        help='Target architecture for build output')\n    parser.add_argument('--platform',\n                        metavar='<linux|darwin|windows|all>',\n                        type=str,\n                        default=get_system_platform(),\n                        help='Target platform for build output')\n    parser.add_argument('--branch',\n                        metavar='<branch>',\n                        type=str,\n                        default=get_current_branch(),\n                        help='Build from a specific branch')\n    parser.add_argument('--commit',\n                        metavar='<commit>',\n                        type=str,\n                        default=get_current_commit(short=True),\n                        help='Build from a specific commit')\n    parser.add_argument('--version',\n                        metavar='<version>',\n                        type=str,\n                        default=get_current_version(),\n                        help='Version information to apply to build output (ex: 0.12.0)')\n    parser.add_argument('--iteration',\n                        metavar='<package iteration>',\n                        type=str,\n                        default=\"1\",\n                        help='Package iteration to apply to build output (defaults to 1)')\n    parser.add_argument('--stats',\n                        action='store_true',\n                        help='Emit build metrics (requires InfluxDB Python client)')\n    parser.add_argument('--stats-server',\n                        metavar='<hostname:port>',\n                        type=str,\n                        help='Send build stats to InfluxDB using provided hostname and port')\n    parser.add_argument('--stats-db',\n                        metavar='<database name>',\n                        type=str,\n                        help='Send build stats to InfluxDB using provided database name')\n    parser.add_argument('--nightly',\n                        action='store_true',\n                        help='Mark build output as nightly build (will incremement the minor version)')\n    parser.add_argument('--update',\n                        action='store_true',\n                        help='Update build dependencies prior to building')\n    parser.add_argument('--package',\n                        action='store_true',\n                        help='Package binary output')\n    parser.add_argument('--package-udfs',\n                        action='store_true',\n                        help='Package UDF agents')\n    parser.add_argument('--release',\n                        action='store_true',\n                        help='Mark build output as release')\n    parser.add_argument('--clean',\n                        action='store_true',\n                        help='Clean output directory before building')\n    parser.add_argument('--no-get',\n                        action='store_true',\n                        help='Do not retrieve pinned dependencies when building')\n    parser.add_argument('--upload',\n                        action='store_true',\n                        help='Upload output packages to AWS S3')\n    parser.add_argument('--upload-overwrite','-w',\n                        action='store_true',\n                        help='Upload output packages to AWS S3')\n    parser.add_argument('--bucket',\n                        metavar='<S3 bucket name>',\n                        type=str,\n                        default=DEFAULT_BUCKET,\n                        help='Destination bucket for uploads')\n    parser.add_argument('--generate',\n                        action='store_true',\n                        help='Run \"go generate\" before building')\n    parser.add_argument('--build-tags',\n                        metavar='<tags>',\n                        help='Optional build tags to use for compilation')\n    parser.add_argument('--static',\n                        action='store_true',\n                        help='Create statically-compiled binary output')\n    parser.add_argument('--sign',\n                        action='store_true',\n                        help='Create GPG detached signatures for packages (when package is specified)')\n    parser.add_argument('--checksum',\n                        action='store_true',\n                        help='Create md5 and sha256 checksums for packages (when package is specified)')\n    parser.add_argument('--test',\n                        action='store_true',\n                        help='Run tests (does not produce build output)')\n    parser.add_argument('--race',\n                        action='store_true',\n                        help='Enable race flag for build output')\n    parser.add_argument('--parallel',\n                        metavar='<num threads>',\n                        type=int,\n                        help='Number of tests to run simultaneously')\n    parser.add_argument('--timeout',\n                        metavar='<timeout>',\n                        type=str,\n                        help='Timeout for tests before failing')\n    args = parser.parse_args()\n    print_banner()\n    sys.exit(main(args))\n"
        },
        {
          "name": "build.sh",
          "type": "blob",
          "size": 0.6669921875,
          "content": "#!/bin/bash\n# Run the build utility via Docker\n\nset -e\n\n# Make sure our working dir is the dir of the script\nDIR=$(cd $(dirname ${BASH_SOURCE[0]}) && pwd)\ncd $DIR\n\n# Unique number for this build\nBUILD_NUM=${BUILD_NUM-$RANDOM}\n# Home dir of the docker user\nHOME_DIR=/root\n\nimagename=kapacitor-builder-img-$BUILD_NUM\nPROTO_VERSION=3.18.3\n\n# Build new docker image\ndocker build -f Dockerfile_build_ubuntu64 --build-arg PROTO_VERSION=$PROTO_VERSION -t $imagename $DIR\n\necho \"Running build.py\"\n# Run docker\ndocker run \\\n    --rm \\\n    -v \"$DIR:/kapacitor\" \\\n    -e AWS_ACCESS_KEY_ID=\"$AWS_ACCESS_KEY_ID\" \\\n    -e AWS_SECRET_ACCESS_KEY=\"$AWS_SECRET_ACCESS_KEY\" \\\n    $imagename \\\n    \"$@\"\n"
        },
        {
          "name": "builder",
          "type": "tree",
          "content": null
        },
        {
          "name": "change_detect.go",
          "type": "blob",
          "size": 2.9921875,
          "content": "package kapacitor\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/keyvalue\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n)\n\ntype ChangeDetectNode struct {\n\tnode\n\td *pipeline.ChangeDetectNode\n}\n\n// Create a new changeDetect node.\nfunc newChangeDetectNode(et *ExecutingTask, n *pipeline.ChangeDetectNode, d NodeDiagnostic) (*ChangeDetectNode, error) {\n\tdn := &ChangeDetectNode{\n\t\tnode: node{Node: n, et: et, diag: d},\n\t\td:    n,\n\t}\n\t// Create stateful expressions\n\tdn.node.runF = dn.runChangeDetect\n\treturn dn, nil\n}\n\nfunc (n *ChangeDetectNode) runChangeDetect([]byte) error {\n\tconsumer := edge.NewGroupedConsumer(\n\t\tn.ins[0],\n\t\tn,\n\t)\n\tn.statMap.Set(statCardinalityGauge, consumer.CardinalityVar())\n\treturn consumer.Consume()\n}\n\nfunc (n *ChangeDetectNode) NewGroup(group edge.GroupInfo, first edge.PointMeta) (edge.Receiver, error) {\n\treturn edge.NewReceiverFromForwardReceiverWithStats(\n\t\tn.outs,\n\t\tedge.NewTimedForwardReceiver(n.timer, n.newGroup()),\n\t), nil\n}\n\nfunc (n *ChangeDetectNode) newGroup() *changeDetectGroup {\n\treturn &changeDetectGroup{\n\t\tn: n,\n\t}\n}\n\ntype changeDetectGroup struct {\n\tn        *ChangeDetectNode\n\tprevious edge.FieldsTagsTimeGetter\n}\n\nfunc (g *changeDetectGroup) BeginBatch(begin edge.BeginBatchMessage) (edge.Message, error) {\n\tif s := begin.SizeHint(); s > 0 {\n\t\tbegin = begin.ShallowCopy()\n\t\tbegin.SetSizeHint(0)\n\t}\n\tg.previous = nil\n\treturn begin, nil\n}\n\nfunc (g *changeDetectGroup) BatchPoint(bp edge.BatchPointMessage) (edge.Message, error) {\n\tchanged := g.doChangeDetect(bp)\n\tif changed {\n\t\treturn bp, nil\n\t}\n\treturn nil, nil\n}\n\nfunc (g *changeDetectGroup) EndBatch(end edge.EndBatchMessage) (edge.Message, error) {\n\treturn end, nil\n}\n\nfunc (g *changeDetectGroup) Point(p edge.PointMessage) (edge.Message, error) {\n\tchanged := g.doChangeDetect(p)\n\tif changed {\n\t\treturn p, nil\n\t}\n\treturn nil, nil\n}\n\n// doChangeDetect computes the changeDetect with respect to g.previous and p.\n// The resulting changeDetect value will be set on n.\nfunc (g *changeDetectGroup) doChangeDetect(p edge.FieldsTagsTimeGetter) bool {\n\tvar prevFields, currFields models.Fields\n\tif g.previous != nil {\n\t\tprevFields = g.previous.Fields()\n\t}\n\tcurrFields = p.Fields()\n\tchanged := g.n.changeDetect(prevFields, currFields)\n\n\tif !changed {\n\t\treturn false\n\t}\n\tg.previous = p\n\treturn true\n}\n\nfunc (g *changeDetectGroup) Barrier(b edge.BarrierMessage) (edge.Message, error) {\n\treturn b, nil\n}\nfunc (g *changeDetectGroup) DeleteGroup(d edge.DeleteGroupMessage) (edge.Message, error) {\n\treturn d, nil\n}\nfunc (g *changeDetectGroup) Done() {}\n\n// changeDetect reports whether there was a change between prev and cur.\nfunc (n *ChangeDetectNode) changeDetect(prev, curr models.Fields) bool {\n\tfor _, field := range n.d.Fields {\n\t\tvalue, ok := curr[field]\n\t\tif !ok {\n\t\t\tn.diag.Error(\"Invalid field in change detect\",\n\t\t\t\tfmt.Errorf(\"expected field %s not found\", field),\n\t\t\t\tkeyvalue.KV(\"field\", field))\n\t\t\tcontinue\n\t\t}\n\t\tif prev[field] != value {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n"
        },
        {
          "name": "checkfmt.sh",
          "type": "blob",
          "size": 1.205078125,
          "content": "#!/bin/bash\n\ngo install golang.org/x/tools/cmd/goimports\n\nHAS_FMT_ERR=0\n# For every Go file in the project, excluding vendor...\n\nfor file in $(go list -f '{{$dir := .Dir}}{{range .GoFiles}}{{printf \"%s/%s\\n\" $dir .}}{{end}}{{range .TestGoFiles}}{{printf \"%s/%s\\n\" $dir .}}{{end}}{{range .IgnoredGoFiles}}{{printf \"%s/%s\\n\" $dir .}}{{end}}{{range .CgoFiles}}{{printf \"%s/%s\\n\" $dir .}}{{end}}' ./... ); do\n  # ... if file does not contain standard generated code comment (https://golang.org/s/generatedcode)...\n  if ! grep -Exq '^// Code generated .* DO NOT EDIT\\.$' $file; then\n    FMT_OUT=\"$(goimports -l -d $file)\"\n    # ... and if goimports had any output...\n    if [[ -n \"$FMT_OUT\" ]]; then\n      if [ \"$HAS_FMT_ERR\" -eq \"0\" ]; then\n        # Only print this once.\n        HAS_FMT_ERR=1\n        echo 'Commit includes files that are not gofmt-ed' && \\\n        echo 'run \"make fmt\"' && \\\n        echo ''\n      fi\n      echo \"$FMT_OUT\" # Print output and continue, so developers don't fix one file at a t\n    fi\n   fi\ndone\n\n## print at the end too... sometimes it is nice to see what to do at the end.\nif [ \"$HAS_FMT_ERR\" -eq \"1\" ]; then\n    echo 'Commit includes files that are not gofmt-ed' && \\\n    echo ''\nfi\nexit \"$HAS_FMT_ERR\"\n"
        },
        {
          "name": "circle-test.sh",
          "type": "blob",
          "size": 0.79296875,
          "content": "#!/bin/bash\n#\n# This is the InfluxDB test script for CircleCI, it is a light wrapper around ./test.sh.\n\n# Exit if any command fails\nset -e\n\n# Get dir of script and make it is our working directory.\nDIR=$(cd $(dirname \"${BASH_SOURCE[0]}\") && pwd)\ncd $DIR\n\n\nexport NO_UNCOMMITTED=true\nexport BUILD_NUM=$CIRCLE_BUILD_NUM\n\n# Get number of test environments.\ncount=$(./test.sh count)\n# Check that we aren't wasting CircleCI nodes.\nif [ $CIRCLE_NODE_TOTAL -gt $count ]\nthen\n    echo \"More CircleCI nodes allocated than tests environments to run!\"\n    exit 1\nfi\n\n# Map CircleCI nodes to test environments.\ntests=$(seq 0 $((count - 1)))\nfor i in $tests\ndo\n    mine=$(( $i % $CIRCLE_NODE_TOTAL ))\n    if [ $mine -eq $CIRCLE_NODE_INDEX ]\n    then\n        echo \"Running test env index: $i\"\n        ./test.sh $i\n    fi\ndone\n"
        },
        {
          "name": "circularqueue.go",
          "type": "blob",
          "size": 1.9921875,
          "content": "package kapacitor\n\n// CircularQueue defines a circular queue, always use the contructor to create one.\ntype CircularQueue[T any] struct {\n\tdata []T\n\thead int\n\ttail int\n\tLen  int\n}\n\nfunc NewCircularQueue[T any](buf ...T) *CircularQueue[T] {\n\t// if we have a useless buffer, make one that is at least useful\n\tif cap(buf) < 4 {\n\t\tbuf = append(make([]T, 0, 4), buf...)\n\t}\n\treturn &CircularQueue[T]{\n\t\tdata: buf[:cap(buf)],\n\t\ttail: len(buf), // tail is here we insert\n\t\tLen:  len(buf),\n\t}\n}\n\n// Enqueue adds an item to the queue.\nfunc (q *CircularQueue[T]) Enqueue(v T) {\n\t// if full we must grow and insert together. This is an expensive op\n\tif cap(q.data) > q.Len { // no need to grow\n\t\tif q.tail == len(q.data) {\n\t\t\tq.tail = 0\n\t\t}\n\t\tq.data[q.tail] = v\n\t} else { // we need to grow\n\t\tbuf := make([]T, cap(q.data)*2)\n\t\tif q.head < q.tail {\n\t\t\tcopy(buf, q.data[q.head:q.tail])\n\t\t} else {\n\t\t\tpartialWriteLen := copy(buf, q.data[q.head:])\n\t\t\tcopy(buf[partialWriteLen:], q.data[:q.tail])\n\t\t}\n\t\tq.head = 0\n\t\tq.tail = cap(q.data)\n\t\tbuf[q.tail] = v\n\t\tq.data = buf\n\t}\n\tq.Len++\n\tq.tail++\n}\n\n// Dequeue removes n items from the queue. If n is longer than the number of the items in the queue it will clear them all out.\nfunc (q *CircularQueue[T]) Dequeue(n int) {\n\tif n <= 0 {\n\t\treturn\n\t}\n\tif q.Len <= n {\n\t\tn = q.Len\n\t}\n\tni := n\n\tvar fill T\n\tif q.head > q.tail {\n\t\tfor i := q.head; i < len(q.data) && ni > 0; i++ {\n\t\t\tq.data[i] = fill\n\t\t\tni--\n\t\t}\n\t\tfor i := 0; i < q.tail && ni > 0; i++ {\n\t\t\tq.data[i] = fill\n\t\t\tni--\n\t\t}\n\t} else {\n\t\tfor i := q.head; i < q.tail && ni > 0; i++ {\n\t\t\tq.data[i] = fill\n\t\t\tni--\n\t\t}\n\t}\n\tq.head += n\n\tif q.head > len(q.data) {\n\t\tq.head -= len(q.data)\n\t}\n\tq.Len -= n\n\tif q.Len == 0 {\n\t\tq.head = 0\n\t\tq.tail = 0\n\t}\n}\n\n// Peek peeks i ahead of the current head of queue.  It should be used in conjunction with .Len() to prevent a panic.\nfunc (q *CircularQueue[x]) Peek(i int) x {\n\tif i < 0 || i >= q.Len {\n\t\tpanic(\"peek index is out of bounds\")\n\t}\n\tp := q.head + i\n\n\tif p >= len(q.data) {\n\t\tp -= len(q.data)\n\t}\n\treturn q.data[p]\n}\n"
        },
        {
          "name": "circularqueue_test.go",
          "type": "blob",
          "size": 6.8837890625,
          "content": "package kapacitor\n\nimport (\n\t\"math\"\n\t\"reflect\"\n\t\"runtime\"\n\t\"sort\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc Test_intCircularBufPeek(t *testing.T) {\n\texp := []int{1, 2, 3, 4, 5, 6, 7}\n\tpeekRes := []int{}\n\tq := NewCircularQueue([]int{1, 2, 3, 4, 5, 6, 7}...)\n\tfor i := 0; i < q.Len; i++ {\n\t\tpeekRes = append(peekRes, q.Peek(i))\n\t}\n\tif !reflect.DeepEqual(peekRes, exp) {\n\t\tt.Errorf(\"expected peeking, we would see %v, got %v\", exp, peekRes)\n\n\t}\n\tpeekRes = []int{}\n\tfor i := 0; i < q.Len; i++ {\n\t\tpeekRes = append(peekRes, q.Peek(i))\n\t}\n\n\tif !reflect.DeepEqual(peekRes, exp) {\n\t\tt.Errorf(\"expected peeking after next, we would see %v, got %v\", exp, peekRes)\n\t}\n\n}\n\nfunc Test_intCircularBuf(t *testing.T) {\n\tcases := []struct {\n\t\tstarting        []int\n\t\tname            string\n\t\texpected        []int\n\t\texpectedPrePeek [][]int\n\t\texpectedPeek    [][]int\n\t\tadd             [][]int\n\t\tdequeueTimes    []int\n\t}{\n\n\t\t{\n\t\t\tstarting:     []int{1, 2, 3, 4, 5, 6, 7},\n\t\t\tname:         \"remove everything but one then fill it up again\",\n\t\t\texpected:     []int{1, 2, 3, 4, 5, 6, 7},\n\t\t\texpectedPeek: [][]int{{6, 7}, {}, {8, 9, 10, 11}},\n\t\t\tadd:          [][]int{{}, {}, {8, 9, 10, 11}},\n\t\t\tdequeueTimes: []int{5, 3, 0},\n\t\t},\n\t\t{\n\t\t\tstarting:     []int{1, 2, 3, 4, 5, 6, 7},\n\t\t\tname:         \"regular\",\n\t\t\texpected:     []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10},\n\t\t\texpectedPeek: [][]int{{11}},\n\t\t\tadd:          [][]int{{8, 9, 10, 11}},\n\t\t\tdequeueTimes: []int{10},\n\t\t},\n\t\t{\n\t\t\tstarting:     nil,\n\t\t\tname:         \"empty\",\n\t\t\texpected:     []int{},\n\t\t\texpectedPeek: [][]int{{}},\n\t\t\tadd:          [][]int{nil},\n\t\t\tdequeueTimes: []int{1},\n\t\t},\n\t\t{\n\t\t\tstarting:     nil,\n\t\t\tname:         \"empty way past zero\",\n\t\t\texpected:     []int{},\n\t\t\texpectedPeek: [][]int{{}, {}, {}},\n\t\t\tadd:          [][]int{nil, nil, nil},\n\t\t\tdequeueTimes: []int{1, 2, 4},\n\t\t},\n\t\t{\n\t\t\tstarting:     nil,\n\t\t\tname:         \"add to empty\",\n\t\t\texpected:     []int{},\n\t\t\texpectedPeek: [][]int{{1}},\n\t\t\tadd:          [][]int{{1}},\n\t\t\tdequeueTimes: []int{0},\n\t\t},\n\t\t{\n\t\t\tstarting:     []int{1, 2, 3, 4, 5, 6, 7},\n\t\t\tname:         \"remove then add\",\n\t\t\texpected:     []int{1, 2, 3, 4, 5, 6},\n\t\t\texpectedPeek: [][]int{{6, 7}, {7, 8, 9, 10}},\n\t\t\tadd:          [][]int{nil, {8, 9, 10}},\n\t\t\tdequeueTimes: []int{5, 1},\n\t\t},\n\t\t{\n\t\t\tstarting:     []int{1, 2, 3, 4, 5, 6, 7},\n\t\t\tname:         \"remove then add #2\",\n\t\t\texpected:     []int{1, 2, 3, 4, 5, 6},\n\t\t\texpectedPeek: [][]int{{6, 7, 8, 9}, {7, 8, 9, 10, 11, 12}},\n\t\t\tadd:          [][]int{{8, 9}, {10, 11, 12}},\n\t\t\tdequeueTimes: []int{5, 1},\n\t\t},\n\t\t{\n\t\t\tstarting:     []int{1, 2, 3, 4, 5, 6, 7},\n\t\t\tname:         \"remove then add #3\",\n\t\t\texpected:     []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12},\n\t\t\texpectedPeek: [][]int{{6, 7, 8}, {}, {13}},\n\t\t\tadd:          [][]int{{8}, {9, 10, 11}, {12, 13}},\n\t\t\tdequeueTimes: []int{5, 7, 1},\n\t\t},\n\t\t{\n\t\t\tstarting:     []int{1, 2, 3, 4, 5, 6, 7},\n\t\t\tname:         \"remove then add #4\",\n\t\t\texpected:     []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11},\n\t\t\texpectedPeek: [][]int{{6, 7, 8}, {11}, {12}},\n\t\t\tadd:          [][]int{{8}, {9, 10, 11}, {12}},\n\t\t\tdequeueTimes: []int{5, 5, 1},\n\t\t},\n\t\t{\n\t\t\tstarting:     []int{1, 2, 3, 4, 5, 6, 7},\n\t\t\tname:         \"remove too many too early then add one in\",\n\t\t\texpected:     []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11},\n\t\t\texpectedPeek: [][]int{{6, 7, 8}, {}, {12}},\n\t\t\tadd:          [][]int{{8}, {9, 10, 11}, {12}},\n\t\t\tdequeueTimes: []int{5, 33, 0},\n\t\t},\n\t\t{\n\t\t\tstarting:     []int{1, 2, 3, 4, 5, 6, 7},\n\t\t\tname:         \"remove everyone\",\n\t\t\texpected:     []int{1, 2, 3, 4, 5, 6, 7},\n\t\t\texpectedPeek: [][]int{{6, 7}, {}},\n\t\t\tadd:          [][]int{{}, {}},\n\t\t\tdequeueTimes: []int{5, 3},\n\t\t},\n\t\t{\n\t\t\tstarting:     []int{1, 2, 3, 4, 5, 6, 7},\n\t\t\tname:         \"remove everything but one then fill it up again\",\n\t\t\texpected:     []int{1, 2, 3, 4, 5, 6, 7},\n\t\t\texpectedPeek: [][]int{{6, 7}, {}, {8, 9, 10, 11}},\n\t\t\tadd:          [][]int{{}, {}, {8, 9, 10, 11}},\n\t\t\tdequeueTimes: []int{5, 3, 0},\n\t\t},\n\t}\n\tfor _, c := range cases {\n\t\tt.Run(c.name, func(t *testing.T) {\n\t\t\tq := NewCircularQueue(c.starting...)\n\t\t\tres := []int{}\n\t\t\tfor j := 0; j < len(c.dequeueTimes); j++ {\n\t\t\t\tfor i := range c.add[j] {\n\t\t\t\t\tq.Enqueue(c.add[j][i])\n\t\t\t\t}\n\t\t\t\tpeekRes := []int{}\n\t\t\t\tif len(peekRes) > 0 {\n\t\t\t\t\tfor i := 0; i < q.Len; i++ {\n\t\t\t\t\t\tpeekRes = append(peekRes, q.Peek(i))\n\t\t\t\t\t}\n\t\t\t\t\tif !reflect.DeepEqual(peekRes, c.expectedPrePeek[j]) {\n\t\t\t\t\t\tt.Errorf(\"expected peeking before we called next, on step %d we would see %v, got %v\", j, c.expectedPeek[j], peekRes)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfor i := 0; i < c.dequeueTimes[j]; i++ {\n\t\t\t\t\tif q.Len > 0 {\n\t\t\t\t\t\tres = append(res, q.Peek(0))\n\t\t\t\t\t\tq.Dequeue(1)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tpeekRes = []int{}\n\t\t\t\tfor i := 0; i < q.Len; i++ {\n\t\t\t\t\tpeekRes = append(peekRes, q.Peek(i))\n\t\t\t\t}\n\t\t\t\tif !reflect.DeepEqual(peekRes, c.expectedPeek[j]) {\n\t\t\t\t\tt.Errorf(\"expected peeking, on step %d we would see %v, got %v\", j, c.expectedPeek[j], peekRes)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !reflect.DeepEqual(res, c.expected) {\n\t\t\t\tt.Errorf(\"expected %v, got %v\", c.expected, res)\n\t\t\t}\n\t\t})\n\n\t}\n}\n\nfunc Test_leakCircularBuf(t *testing.T) {\n\tif testing.Short() {\n\t\tt.Skip(\"Testing for leaks can be slow, because of the way finalizers work\")\n\t}\n\tvar finalizedItems []int // this can't be pointers because we need the objects to leave memory\n\tfinalizedLock := &sync.Mutex{}\n\tvar expectedFinalizedItems []int\n\t// fill the expectedFinalizedItems\n\tfor i := 0; i < 20; i++ {\n\t\texpectedFinalizedItems = append(expectedFinalizedItems, i)\n\t}\n\n\tq := NewCircularQueue[*int](nil)\n\tfor i := 0; i < len(expectedFinalizedItems); i++ {\n\t\ti := i // make i a local object\n\t\titem := &i\n\t\truntime.SetFinalizer(item, func(q *int) {\n\t\t\t// if the finalizer is called, that means that the GC believes the objects should be freed\n\t\t\tfinalizedLock.Lock()\n\t\t\tfinalizedItems = append(finalizedItems, *q)\n\t\t\tfinalizedLock.Unlock()\n\t\t})\n\t\tq.Enqueue(item)\n\t}\n\n\t// go through the queue till it is empty\n\tq.Dequeue(q.Len)\n\n\t// the items should eventually be collected.\n\t// sometimes they won't be because the GC is optimizing for low latency so we try a bunch\n\tfor i := 0; i < 100; i++ {\n\t\tfinalizedLock.Lock()\n\t\tl := len(finalizedItems)\n\t\tfinalizedLock.Unlock()\n\t\tif l == len(expectedFinalizedItems) {\n\t\t\tbreak\n\t\t}\n\t\truntime.GC()\n\t\t// we have to sleep here because finalizers are async\n\t\ttime.Sleep(50 * time.Millisecond)\n\t}\n\tif len(finalizedItems) != len(expectedFinalizedItems) {\n\t\tt.Errorf(\"expected %d objects to be freed, but got %d\", len(expectedFinalizedItems), len(finalizedItems))\n\t}\n\n\tsort.Ints(finalizedItems)\n\tif !reflect.DeepEqual(finalizedItems, expectedFinalizedItems) {\n\t\tt.Errorf(\"The wrong items were finalized expected %v got %v\", expectedFinalizedItems, finalizedItems)\n\t}\n\t// we don't want q to be freed above, when we are checking if the elements are freed,\n\t// so what is below is to prevent the calls to runtime.GC from freeing the whole queue early\n\t// the code below isn't important, just that it does something with q.data, and doesn't get\n\t// elided out by the compiler\n\tif len(q.data) == math.MaxInt32 {\n\t\tpanic(q)\n\t}\n}\n"
        },
        {
          "name": "client",
          "type": "tree",
          "content": null
        },
        {
          "name": "clock",
          "type": "tree",
          "content": null
        },
        {
          "name": "cmd",
          "type": "tree",
          "content": null
        },
        {
          "name": "combine.go",
          "type": "blob",
          "size": 6.6845703125,
          "content": "package kapacitor\n\nimport (\n\t\"fmt\"\n\t\"time\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n\t\"github.com/influxdata/kapacitor/tick/ast\"\n\t\"github.com/influxdata/kapacitor/tick/stateful\"\n)\n\ntype CombineNode struct {\n\tnode\n\tc *pipeline.CombineNode\n\n\texpressions []stateful.Expression\n\tscopePools  []stateful.ScopePool\n\n\tcombination combination\n}\n\n// Create a new CombineNode, which combines a stream with itself dynamically.\nfunc newCombineNode(et *ExecutingTask, n *pipeline.CombineNode, d NodeDiagnostic) (*CombineNode, error) {\n\tcn := &CombineNode{\n\t\tc:           n,\n\t\tnode:        node{Node: n, et: et, diag: d},\n\t\tcombination: combination{max: n.Max},\n\t}\n\n\t// Create stateful expressions\n\tcn.expressions = make([]stateful.Expression, len(n.Lambdas))\n\tcn.scopePools = make([]stateful.ScopePool, len(n.Lambdas))\n\tfor i, lambda := range n.Lambdas {\n\t\tstatefulExpr, err := stateful.NewExpression(lambda.Expression)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"Failed to compile %v expression: %v\", i, err)\n\t\t}\n\t\tcn.expressions[i] = statefulExpr\n\t\tcn.scopePools[i] = stateful.NewScopePool(ast.FindReferenceVariables(lambda.Expression))\n\t}\n\tcn.node.runF = cn.runCombine\n\treturn cn, nil\n}\n\nfunc (n *CombineNode) runCombine([]byte) error {\n\tconsumer := edge.NewGroupedConsumer(\n\t\tn.ins[0],\n\t\tn,\n\t)\n\tn.statMap.Set(statCardinalityGauge, consumer.CardinalityVar())\n\treturn consumer.Consume()\n}\n\nfunc (n *CombineNode) NewGroup(group edge.GroupInfo, first edge.PointMeta) (edge.Receiver, error) {\n\texpressions := make([]stateful.Expression, len(n.expressions))\n\tfor i, expr := range n.expressions {\n\t\texpressions[i] = expr.CopyReset()\n\t}\n\treturn &combineBuffer{\n\t\tn:           n,\n\t\ttime:        first.Time(),\n\t\tname:        first.Name(),\n\t\tgroupInfo:   group,\n\t\texpressions: expressions,\n\t\tc:           n.combination,\n\t}, nil\n}\n\ntype combineBuffer struct {\n\tn           *CombineNode\n\ttime        time.Time\n\tname        string\n\tgroupInfo   edge.GroupInfo\n\tpoints      []edge.FieldsTagsTimeSetter\n\texpressions []stateful.Expression\n\tc           combination\n}\n\nfunc (b *combineBuffer) BeginBatch(begin edge.BeginBatchMessage) error {\n\tb.n.timer.Start()\n\tdefer b.n.timer.Stop()\n\n\tb.name = begin.Name()\n\tb.time = time.Time{}\n\tif s := begin.SizeHint(); s > cap(b.points) {\n\t\tb.points = make([]edge.FieldsTagsTimeSetter, 0, s)\n\t}\n\treturn nil\n}\n\nfunc (b *combineBuffer) BatchPoint(bp edge.BatchPointMessage) error {\n\tb.n.timer.Start()\n\tdefer b.n.timer.Stop()\n\tbp = bp.ShallowCopy()\n\treturn b.addPoint(bp)\n}\n\nfunc (b *combineBuffer) EndBatch(end edge.EndBatchMessage) error {\n\tb.n.timer.Start()\n\tdefer b.n.timer.Stop()\n\tif err := b.combine(); err != nil {\n\t\treturn err\n\t}\n\tb.points = b.points[0:0]\n\treturn nil\n}\n\nfunc (b *combineBuffer) Point(p edge.PointMessage) error {\n\tb.n.timer.Start()\n\tdefer b.n.timer.Stop()\n\tp = p.ShallowCopy()\n\treturn b.addPoint(p)\n}\n\nfunc (b *combineBuffer) addPoint(p edge.FieldsTagsTimeSetter) error {\n\tt := p.Time().Round(b.n.c.Tolerance)\n\tp.SetTime(t)\n\tif t.Equal(b.time) {\n\t\tb.points = append(b.points, p)\n\t} else {\n\t\tif err := b.combine(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tb.time = t\n\t\tb.points = b.points[0:1]\n\t\tb.points[0] = p\n\t}\n\treturn nil\n}\n\nfunc (b *combineBuffer) Barrier(barrier edge.BarrierMessage) error {\n\treturn edge.Forward(b.n.outs, barrier)\n}\nfunc (b *combineBuffer) DeleteGroup(d edge.DeleteGroupMessage) error {\n\treturn edge.Forward(b.n.outs, d)\n}\nfunc (b *combineBuffer) Done() {}\n\n// Combine a set of points into all their combinations.\nfunc (b *combineBuffer) combine() error {\n\tif len(b.points) == 0 {\n\t\treturn nil\n\t}\n\n\tl := len(b.expressions)\n\n\t// Compute matching result for all points\n\tmatches := make([]map[int]bool, l)\n\tfor i := 0; i < l; i++ {\n\t\tmatches[i] = make(map[int]bool, len(b.points))\n\t}\n\tfor idx, p := range b.points {\n\t\tfor i := range b.expressions {\n\t\t\tmatched, err := EvalPredicate(b.expressions[i], b.n.scopePools[i], p)\n\t\t\tif err != nil {\n\t\t\t\tb.n.diag.Error(\"error evaluating lambda expression\", err)\n\t\t\t}\n\t\t\tmatches[i][idx] = matched\n\t\t}\n\t}\n\n\tp := edge.NewPointMessage(\n\t\tb.name, \"\", \"\",\n\t\tb.groupInfo.Dimensions,\n\t\tnil,\n\t\tnil,\n\t\ttime.Time{},\n\t)\n\n\tdimensions := p.Dimensions().ToSet()\n\tset := make([]edge.FieldsTagsTimeSetter, l)\n\treturn b.c.Do(len(b.points), l, func(indices []int) error {\n\t\tvalid := true\n\t\tfor s := 0; s < l; s++ {\n\t\t\tfound := false\n\t\t\tfor i := range indices {\n\t\t\t\tif matches[s][indices[i]] {\n\t\t\t\t\tset[s] = b.points[indices[i]]\n\t\t\t\t\tindices = append(indices[0:i], indices[i+1:]...)\n\t\t\t\t\tfound = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !found {\n\t\t\t\tvalid = false\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif valid {\n\t\t\tfields, tags, t := b.merge(set, dimensions)\n\n\t\t\tnp := p.ShallowCopy()\n\t\t\tnp.SetFields(fields)\n\t\t\tnp.SetTags(tags)\n\t\t\tnp.SetTime(t.Round(b.n.c.Tolerance))\n\n\t\t\tb.n.timer.Pause()\n\t\t\terr := edge.Forward(b.n.outs, np)\n\t\t\tb.n.timer.Resume()\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n}\n\n// Merge a set of points into a single point.\nfunc (b *combineBuffer) merge(points []edge.FieldsTagsTimeSetter, dimensions map[string]bool) (models.Fields, models.Tags, time.Time) {\n\tfields := make(models.Fields, len(points[0].Fields())*len(points))\n\ttags := make(models.Tags, len(points[0].Tags())*len(points))\n\n\tfor i, p := range points {\n\t\tfor field, value := range p.Fields() {\n\t\t\tfields[b.n.c.Names[i]+b.n.c.Delimiter+field] = value\n\t\t}\n\t\tfor tag, value := range p.Tags() {\n\t\t\tif !dimensions[tag] {\n\t\t\t\ttags[b.n.c.Names[i]+b.n.c.Delimiter+tag] = value\n\t\t\t} else {\n\t\t\t\ttags[tag] = value\n\t\t\t}\n\t\t}\n\t}\n\n\treturn fields, tags, points[0].Time()\n}\n\n// Type for performing actions on a set of combinations.\ntype combination struct {\n\tmax int64\n}\n\n// Do action for each combination, based on combinatorial logic n choose k.\n// If n choose k > max an error is returned\nfunc (c combination) Do(n, k int, f func(indices []int) error) error {\n\tif count := c.Count(int64(n), int64(k)); count > c.max {\n\t\treturn fmt.Errorf(\"refusing to perform combination as total combinations %d exceeds max combinations %d\", count, c.max)\n\t} else if count == -1 {\n\t\t// Nothing to do\n\t\treturn nil\n\t}\n\n\tindices := make([]int, k)\n\tindicesCopy := make([]int, k)\n\tfor i := 0; i < k; i++ {\n\t\tindices[i] = i\n\t}\n\tcopy(indicesCopy, indices)\n\tif err := f(indicesCopy); err != nil {\n\t\treturn err\n\t}\n\tfor {\n\t\ti := k - 1\n\t\tfor ; i >= 0; i-- {\n\t\t\tif indices[i] != i+n-k {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif i == -1 {\n\t\t\treturn nil\n\t\t}\n\t\tindices[i]++\n\t\tfor j := i + 1; j < k; j++ {\n\t\t\tindices[j] = indices[j-1] + 1\n\t\t}\n\t\tcopy(indicesCopy, indices)\n\t\tif err := f(indicesCopy); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n}\n\n// Count the number of possible combinations of n choose k.\nfunc (c combination) Count(n, k int64) int64 {\n\tif n < k {\n\t\treturn -1\n\t}\n\tcount := int64(1)\n\tfor i := int64(0); i < k; i++ {\n\t\tcount = (count * (n - i)) / (i + 1)\n\t}\n\treturn count\n}\n"
        },
        {
          "name": "combine_test.go",
          "type": "blob",
          "size": 2.1416015625,
          "content": "package kapacitor\n\nimport (\n\t\"reflect\"\n\t\"testing\"\n)\n\nfunc Test_Combination_Count(t *testing.T) {\n\tc := combination{max: 1e9}\n\ttestCases := []struct {\n\t\tn, k, exp int64\n\t}{\n\t\t{\n\t\t\tn:   1,\n\t\t\tk:   0,\n\t\t\texp: 1,\n\t\t},\n\t\t{\n\t\t\tn:   1,\n\t\t\tk:   1,\n\t\t\texp: 1,\n\t\t},\n\t\t{\n\t\t\tn:   2,\n\t\t\tk:   1,\n\t\t\texp: 2,\n\t\t},\n\t\t{\n\t\t\tn:   5,\n\t\t\tk:   2,\n\t\t\texp: 10,\n\t\t},\n\t\t{\n\t\t\tn:   5,\n\t\t\tk:   3,\n\t\t\texp: 10,\n\t\t},\n\t\t{\n\t\t\tn:   52,\n\t\t\tk:   5,\n\t\t\texp: 2598960,\n\t\t},\n\t}\n\tfor _, tc := range testCases {\n\t\tif exp, got := tc.exp, c.Count(tc.n, tc.k); exp != got {\n\t\t\tt.Errorf(\"unexpected combination count for %d choose %d: got %d exp %d\", tc.n, tc.k, got, exp)\n\t\t}\n\t}\n}\nfunc Test_Combination_Do(t *testing.T) {\n\tc := combination{max: 1e9}\n\ttestCases := []struct {\n\t\tn, k int\n\t\texp  [][]int\n\t}{\n\t\t{\n\t\t\tn:   1,\n\t\t\tk:   1,\n\t\t\texp: [][]int{{0}},\n\t\t},\n\t\t{\n\t\t\tn: 5,\n\t\t\tk: 2,\n\t\t\texp: [][]int{\n\t\t\t\t{0, 1},\n\t\t\t\t{0, 2},\n\t\t\t\t{0, 3},\n\t\t\t\t{0, 4},\n\t\t\t\t{1, 2},\n\t\t\t\t{1, 3},\n\t\t\t\t{1, 4},\n\t\t\t\t{2, 3},\n\t\t\t\t{2, 4},\n\t\t\t\t{3, 4},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tn: 5,\n\t\t\tk: 3,\n\t\t\texp: [][]int{\n\t\t\t\t{0, 1, 2},\n\t\t\t\t{0, 1, 3},\n\t\t\t\t{0, 1, 4},\n\t\t\t\t{0, 2, 3},\n\t\t\t\t{0, 2, 4},\n\t\t\t\t{0, 3, 4},\n\t\t\t\t{1, 2, 3},\n\t\t\t\t{1, 2, 4},\n\t\t\t\t{1, 3, 4},\n\t\t\t\t{2, 3, 4},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tn: 7,\n\t\t\tk: 5,\n\t\t\texp: [][]int{\n\t\t\t\t{0, 1, 2, 3, 4},\n\t\t\t\t{0, 1, 2, 3, 5},\n\t\t\t\t{0, 1, 2, 3, 6},\n\t\t\t\t{0, 1, 2, 4, 5},\n\t\t\t\t{0, 1, 2, 4, 6},\n\t\t\t\t{0, 1, 2, 5, 6},\n\t\t\t\t{0, 1, 3, 4, 5},\n\t\t\t\t{0, 1, 3, 4, 6},\n\t\t\t\t{0, 1, 3, 5, 6},\n\t\t\t\t{0, 1, 4, 5, 6},\n\t\t\t\t{0, 2, 3, 4, 5},\n\t\t\t\t{0, 2, 3, 4, 6},\n\t\t\t\t{0, 2, 3, 5, 6},\n\t\t\t\t{0, 2, 4, 5, 6},\n\t\t\t\t{0, 3, 4, 5, 6},\n\t\t\t\t{1, 2, 3, 4, 5},\n\t\t\t\t{1, 2, 3, 4, 6},\n\t\t\t\t{1, 2, 3, 5, 6},\n\t\t\t\t{1, 2, 4, 5, 6},\n\t\t\t\t{1, 3, 4, 5, 6},\n\t\t\t\t{2, 3, 4, 5, 6},\n\t\t\t},\n\t\t},\n\t}\n\tfor _, tc := range testCases {\n\t\ti := 0\n\t\tc.Do(tc.n, tc.k, func(indices []int) error {\n\t\t\tif i == len(tc.exp) {\n\t\t\t\tt.Fatalf(\"too many combinations returned for %d choose %d: got %v\", tc.n, tc.k, indices)\n\t\t\t}\n\t\t\tif !reflect.DeepEqual(tc.exp[i], indices) {\n\t\t\t\tt.Errorf(\"unexpected combination set for %d choose %d index %d: got %v exp %v\", tc.n, tc.k, i, indices, tc.exp[i])\n\t\t\t}\n\t\t\ti++\n\t\t\treturn nil\n\t\t})\n\t\tif i != len(tc.exp) {\n\t\t\tt.Errorf(\"not enough combinations returned for %d choose %d\", tc.n, tc.k)\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "command",
          "type": "tree",
          "content": null
        },
        {
          "name": "default.go",
          "type": "blob",
          "size": 2.7509765625,
          "content": "package kapacitor\n\nimport (\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/expvar\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n)\n\nconst (\n\tstatsFieldsDefaulted = \"fields_defaulted\"\n\tstatsTagsDefaulted   = \"tags_defaulted\"\n)\n\ntype DefaultNode struct {\n\tnode\n\td *pipeline.DefaultNode\n\n\tfieldsDefaulted *expvar.Int\n\ttagsDefaulted   *expvar.Int\n}\n\n// Create a new  DefaultNode which applies a transformation func to each point in a stream and returns a single point.\nfunc newDefaultNode(et *ExecutingTask, n *pipeline.DefaultNode, d NodeDiagnostic) (*DefaultNode, error) {\n\tdn := &DefaultNode{\n\t\tnode:            node{Node: n, et: et, diag: d},\n\t\td:               n,\n\t\tfieldsDefaulted: new(expvar.Int),\n\t\ttagsDefaulted:   new(expvar.Int),\n\t}\n\tdn.node.runF = dn.runDefault\n\treturn dn, nil\n}\n\nfunc (n *DefaultNode) runDefault(snapshot []byte) error {\n\tn.statMap.Set(statsFieldsDefaulted, n.fieldsDefaulted)\n\tn.statMap.Set(statsTagsDefaulted, n.tagsDefaulted)\n\n\tconsumer := edge.NewConsumerWithReceiver(\n\t\tn.ins[0],\n\t\tedge.NewReceiverFromForwardReceiverWithStats(\n\t\t\tn.outs,\n\t\t\tedge.NewTimedForwardReceiver(n.timer, n),\n\t\t),\n\t)\n\treturn consumer.Consume()\n}\n\nfunc (n *DefaultNode) BeginBatch(begin edge.BeginBatchMessage) (edge.Message, error) {\n\tbegin = begin.ShallowCopy()\n\t_, tags := n.setDefaults(nil, begin.Tags())\n\tbegin.SetTags(tags)\n\treturn begin, nil\n}\n\nfunc (n *DefaultNode) BatchPoint(bp edge.BatchPointMessage) (edge.Message, error) {\n\tbp = bp.ShallowCopy()\n\tfields, tags := n.setDefaults(bp.Fields(), bp.Tags())\n\tbp.SetFields(fields)\n\tbp.SetTags(tags)\n\treturn bp, nil\n}\n\nfunc (n *DefaultNode) EndBatch(end edge.EndBatchMessage) (edge.Message, error) {\n\treturn end, nil\n}\n\nfunc (n *DefaultNode) Point(p edge.PointMessage) (edge.Message, error) {\n\tp = p.ShallowCopy()\n\tfields, tags := n.setDefaults(p.Fields(), p.Tags())\n\tp.SetFields(fields)\n\tp.SetTags(tags)\n\treturn p, nil\n}\n\nfunc (n *DefaultNode) Barrier(b edge.BarrierMessage) (edge.Message, error) {\n\treturn b, nil\n}\nfunc (n *DefaultNode) DeleteGroup(d edge.DeleteGroupMessage) (edge.Message, error) {\n\treturn d, nil\n}\nfunc (n *DefaultNode) Done() {}\n\nfunc (n *DefaultNode) setDefaults(fields models.Fields, tags models.Tags) (models.Fields, models.Tags) {\n\tnewFields := fields\n\tfieldsCopied := false\n\tfor field, value := range n.d.Fields {\n\t\tif v := fields[field]; v == nil {\n\t\t\tif !fieldsCopied {\n\t\t\t\tnewFields = newFields.Copy()\n\t\t\t\tfieldsCopied = true\n\t\t\t}\n\t\t\tn.fieldsDefaulted.Add(1)\n\t\t\tnewFields[field] = value\n\t\t}\n\t}\n\tnewTags := tags\n\ttagsCopied := false\n\tfor tag, value := range n.d.Tags {\n\t\tif v := tags[tag]; v == \"\" {\n\t\t\tif !tagsCopied {\n\t\t\t\tnewTags = newTags.Copy()\n\t\t\t\ttagsCopied = true\n\t\t\t}\n\t\t\tn.tagsDefaulted.Add(1)\n\t\t\tnewTags[tag] = value\n\t\t}\n\t}\n\treturn newFields, newTags\n}\n"
        },
        {
          "name": "delete.go",
          "type": "blob",
          "size": 3.484375,
          "content": "package kapacitor\n\nimport (\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/expvar\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n)\n\nconst (\n\tstatsFieldsDeleted = \"fields_deleted\"\n\tstatsTagsDeleted   = \"tags_deleted\"\n)\n\ntype DeleteNode struct {\n\tnode\n\td *pipeline.DeleteNode\n\n\tfieldsDeleted *expvar.Int\n\ttagsDeleted   *expvar.Int\n\n\ttags map[string]bool\n}\n\n// Create a new  DeleteNode which applies a transformation func to each point in a stream and returns a single point.\nfunc newDeleteNode(et *ExecutingTask, n *pipeline.DeleteNode, d NodeDiagnostic) (*DeleteNode, error) {\n\ttags := make(map[string]bool)\n\tfor _, tag := range n.Tags {\n\t\ttags[tag] = true\n\t}\n\n\tdn := &DeleteNode{\n\t\tnode:          node{Node: n, et: et, diag: d},\n\t\td:             n,\n\t\tfieldsDeleted: new(expvar.Int),\n\t\ttagsDeleted:   new(expvar.Int),\n\t\ttags:          tags,\n\t}\n\tdn.node.runF = dn.runDelete\n\treturn dn, nil\n}\n\nfunc (n *DeleteNode) runDelete(snapshot []byte) error {\n\tn.statMap.Set(statsFieldsDeleted, n.fieldsDeleted)\n\tn.statMap.Set(statsTagsDeleted, n.tagsDeleted)\n\tconsumer := edge.NewConsumerWithReceiver(\n\t\tn.ins[0],\n\t\tedge.NewReceiverFromForwardReceiverWithStats(\n\t\t\tn.outs,\n\t\t\tedge.NewTimedForwardReceiver(n.timer, n),\n\t\t),\n\t)\n\treturn consumer.Consume()\n}\n\nfunc (n *DeleteNode) BeginBatch(begin edge.BeginBatchMessage) (edge.Message, error) {\n\tbegin = begin.ShallowCopy()\n\t_, tags := n.doDeletes(nil, begin.Tags())\n\tbegin.SetTags(tags)\n\treturn begin, nil\n}\n\nfunc (n *DeleteNode) BatchPoint(bp edge.BatchPointMessage) (edge.Message, error) {\n\tbp = bp.ShallowCopy()\n\tfields, tags := n.doDeletes(bp.Fields(), bp.Tags())\n\tbp.SetFields(fields)\n\tbp.SetTags(tags)\n\treturn bp, nil\n}\n\nfunc (n *DeleteNode) EndBatch(end edge.EndBatchMessage) (edge.Message, error) {\n\treturn end, nil\n}\n\nfunc (n *DeleteNode) Point(p edge.PointMessage) (edge.Message, error) {\n\tp = p.ShallowCopy()\n\tfields, tags := n.doDeletes(p.Fields(), p.Tags())\n\tp.SetFields(fields)\n\tp.SetTags(tags)\n\tdims := p.Dimensions()\n\tif n.checkForDeletedDimension(dims) {\n\t\tp.SetDimensions(n.deleteDimensions(dims))\n\t}\n\treturn p, nil\n}\n\nfunc (n *DeleteNode) Barrier(b edge.BarrierMessage) (edge.Message, error) {\n\treturn b, nil\n}\nfunc (n *DeleteNode) DeleteGroup(d edge.DeleteGroupMessage) (edge.Message, error) {\n\treturn d, nil\n}\nfunc (n *DeleteNode) Done() {}\n\n// checkForDeletedDimension checks if we deleted a group by dimension\nfunc (n *DeleteNode) checkForDeletedDimension(dimensions models.Dimensions) bool {\n\tfor _, dim := range dimensions.TagNames {\n\t\tif n.tags[dim] {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (n *DeleteNode) deleteDimensions(dims models.Dimensions) models.Dimensions {\n\tnewTagNames := make([]string, 0, len(dims.TagNames)-1)\n\tfor _, dim := range dims.TagNames {\n\t\tif !n.tags[dim] {\n\t\t\tnewTagNames = append(newTagNames, dim)\n\t\t}\n\t}\n\treturn models.Dimensions{\n\t\tTagNames: newTagNames,\n\t\tByName:   dims.ByName,\n\t}\n}\n\nfunc (n *DeleteNode) doDeletes(fields models.Fields, tags models.Tags) (models.Fields, models.Tags) {\n\tnewFields := fields\n\tfieldsCopied := false\n\tfor _, field := range n.d.Fields {\n\t\tif _, ok := fields[field]; ok {\n\t\t\tif !fieldsCopied {\n\t\t\t\tnewFields = newFields.Copy()\n\t\t\t\tfieldsCopied = true\n\t\t\t}\n\t\t\tn.fieldsDeleted.Add(1)\n\t\t\tdelete(newFields, field)\n\t\t}\n\t}\n\tnewTags := tags\n\ttagsCopied := false\n\tfor _, tag := range n.d.Tags {\n\t\tif _, ok := tags[tag]; ok {\n\t\t\tif !tagsCopied {\n\t\t\t\tnewTags = newTags.Copy()\n\t\t\t\ttagsCopied = true\n\t\t\t}\n\t\t\tn.tagsDeleted.Add(1)\n\t\t\tdelete(newTags, tag)\n\t\t}\n\t}\n\treturn newFields, newTags\n}\n"
        },
        {
          "name": "derivative.go",
          "type": "blob",
          "size": 4.20703125,
          "content": "package kapacitor\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"time\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/keyvalue\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n)\n\ntype DerivativeNode struct {\n\tnode\n\td *pipeline.DerivativeNode\n}\n\n// Create a new derivative node.\nfunc newDerivativeNode(et *ExecutingTask, n *pipeline.DerivativeNode, d NodeDiagnostic) (*DerivativeNode, error) {\n\tdn := &DerivativeNode{\n\t\tnode: node{Node: n, et: et, diag: d},\n\t\td:    n,\n\t}\n\t// Create stateful expressions\n\tdn.node.runF = dn.runDerivative\n\treturn dn, nil\n}\n\nfunc (n *DerivativeNode) runDerivative([]byte) error {\n\tconsumer := edge.NewGroupedConsumer(\n\t\tn.ins[0],\n\t\tn,\n\t)\n\tn.statMap.Set(statCardinalityGauge, consumer.CardinalityVar())\n\treturn consumer.Consume()\n}\n\nfunc (n *DerivativeNode) NewGroup(group edge.GroupInfo, first edge.PointMeta) (edge.Receiver, error) {\n\treturn edge.NewReceiverFromForwardReceiverWithStats(\n\t\tn.outs,\n\t\tedge.NewTimedForwardReceiver(n.timer, n.newGroup()),\n\t), nil\n}\n\nfunc (n *DerivativeNode) newGroup() *derivativeGroup {\n\treturn &derivativeGroup{\n\t\tn: n,\n\t}\n}\n\ntype derivativeGroup struct {\n\tn        *DerivativeNode\n\tprevious edge.FieldsTagsTimeGetter\n}\n\nfunc (g *derivativeGroup) BeginBatch(begin edge.BeginBatchMessage) (edge.Message, error) {\n\tif s := begin.SizeHint(); s > 0 {\n\t\tbegin = begin.ShallowCopy()\n\t\tbegin.SetSizeHint(s - 1)\n\t}\n\tg.previous = nil\n\treturn begin, nil\n}\n\nfunc (g *derivativeGroup) BatchPoint(bp edge.BatchPointMessage) (edge.Message, error) {\n\tnp := bp.ShallowCopy()\n\temit := g.doDerivative(bp, np)\n\tif emit {\n\t\treturn np, nil\n\t}\n\treturn nil, nil\n}\n\nfunc (g *derivativeGroup) EndBatch(end edge.EndBatchMessage) (edge.Message, error) {\n\treturn end, nil\n}\n\nfunc (g *derivativeGroup) Point(p edge.PointMessage) (edge.Message, error) {\n\tnp := p.ShallowCopy()\n\temit := g.doDerivative(p, np)\n\tif emit {\n\t\treturn np, nil\n\t}\n\treturn nil, nil\n}\n\n// doDerivative computes the derivative with respect to g.previous and p.\n// The resulting derivative value will be set on n.\nfunc (g *derivativeGroup) doDerivative(p edge.FieldsTagsTimeGetter, n edge.FieldsTagsTimeSetter) bool {\n\tvar prevFields, currFields models.Fields\n\tvar prevTime, currTime time.Time\n\tif g.previous != nil {\n\t\tprevFields = g.previous.Fields()\n\t\tprevTime = g.previous.Time()\n\t}\n\tcurrFields = p.Fields()\n\tcurrTime = p.Time()\n\tvalue, store, emit := g.n.derivative(\n\t\tprevFields, currFields,\n\t\tprevTime, currTime,\n\t)\n\tif store {\n\t\tg.previous = p\n\t}\n\tif !emit {\n\t\treturn false\n\t}\n\n\tfields := n.Fields().Copy()\n\tfields[g.n.d.As] = value\n\tn.SetFields(fields)\n\treturn true\n}\n\nfunc (g *derivativeGroup) Barrier(b edge.BarrierMessage) (edge.Message, error) {\n\treturn b, nil\n}\nfunc (g *derivativeGroup) DeleteGroup(d edge.DeleteGroupMessage) (edge.Message, error) {\n\treturn d, nil\n}\nfunc (g *derivativeGroup) Done() {}\n\n// derivative calculates the derivative between prev and cur.\n// Return is the resulting derivative, whether the current point should be\n// stored as previous, and whether the point result should be emitted.\nfunc (n *DerivativeNode) derivative(prev, curr models.Fields, prevTime, currTime time.Time) (float64, bool, bool) {\n\tf1, ok := numToFloat(curr[n.d.Field])\n\tif !ok {\n\t\tn.diag.Error(\"cannot perform derivative\",\n\t\t\terrors.New(\"field is the wrong type\"),\n\t\t\tkeyvalue.KV(\"field\", n.d.Field),\n\t\t\tkeyvalue.KV(\"type\", fmt.Sprintf(\"%T\", curr[n.d.Field])),\n\t\t)\n\t\treturn 0, false, false\n\t}\n\n\tf0, ok := numToFloat(prev[n.d.Field])\n\tif !ok {\n\t\t// The only time this will fail to parse is if there is no previous.\n\t\t// Because we only return `store=true` if current parses successfully, we will\n\t\t// never get a previous which doesn't parse.\n\t\treturn 0, true, false\n\t}\n\n\telapsed := float64(currTime.Sub(prevTime))\n\tif elapsed == 0 {\n\t\tn.diag.Error(\"cannot perform derivative\", errors.New(\"elaspsed time was 0\"))\n\t\treturn 0, true, false\n\t}\n\tdiff := f1 - f0\n\t// Drop negative values for non-negative derivatives\n\tif n.d.NonNegativeFlag && diff < 0 {\n\t\treturn 0, true, false\n\t}\n\n\tvalue := float64(diff) / (elapsed / float64(n.d.Unit))\n\treturn value, true, true\n}\n\nfunc numToFloat(num interface{}) (float64, bool) {\n\tswitch n := num.(type) {\n\tcase int64:\n\t\treturn float64(n), true\n\tcase float64:\n\t\treturn n, true\n\tdefault:\n\t\treturn 0, false\n\t}\n}\n"
        },
        {
          "name": "doc.go",
          "type": "blob",
          "size": 0.9130859375,
          "content": "/*\nA data pipeline processing engine.\n\nSee the README for more complete examples and guides.\n\nCode Organization:\n\nThe pipeline package provides an API for how nodes can be connected to form a pipeline.\nThe individual implementations of each node exist in this kapacitor package.\nThe reason for the separation is to keep the exported API from the pipeline package\nclean as it is consumed via the TICKscripts (a DSL for Kapacitor).\n\nOther Concepts:\n\nStream vs Batch -- Use of the word 'stream'  indicates data arrives a single data point at a time.\nUse of the word 'batch' indicates data arrives in sets or batches or data points.\n\nTask -- A task represents a concrete workload to perform.\nIt consists of a pipeline and an identifying name.\nBasic CRUD operations can be performed on tasks.\n\nTask Master -- Responsible for executing a task in a specific environment.\n\nReplay -- Replays static datasets against tasks.\n*/\npackage kapacitor\n"
        },
        {
          "name": "edge.go",
          "type": "blob",
          "size": 1.2958984375,
          "content": "package kapacitor\n\nimport (\n\t\"errors\"\n\t\"sync\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/expvar\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n\t\"github.com/influxdata/kapacitor/server/vars\"\n)\n\nconst (\n\tstatCollected = \"collected\"\n\tstatEmitted   = \"emitted\"\n\n\tdefaultEdgeBufferSize = 1000\n)\n\nvar ErrAborted = errors.New(\"edged aborted\")\n\ntype EdgeDiagnostic interface {\n\tClosingEdge(collected, emitted int64)\n}\n\ntype Edge struct {\n\tedge.StatsEdge\n\n\tmu     sync.Mutex\n\tclosed bool\n\n\tstatsKey string\n\tstatMap  *expvar.Map\n\tdiag     EdgeDiagnostic\n}\n\nfunc newEdge(taskName, parentName, childName string, t pipeline.EdgeType, size int, d EdgeDiagnostic) edge.StatsEdge {\n\te := edge.NewStatsEdge(edge.NewChannelEdge(t, defaultEdgeBufferSize))\n\ttags := map[string]string{\n\t\t\"task\":   taskName,\n\t\t\"parent\": parentName,\n\t\t\"child\":  childName,\n\t\t\"type\":   t.String(),\n\t}\n\tkey, sm := vars.NewStatistic(\"edges\", tags)\n\tsm.Set(statCollected, e.CollectedVar())\n\tsm.Set(statEmitted, e.EmittedVar())\n\treturn &Edge{\n\t\tStatsEdge: e,\n\t\tstatsKey:  key,\n\t\tstatMap:   sm,\n\t\tdiag:      d,\n\t}\n}\n\nfunc (e *Edge) Close() error {\n\te.mu.Lock()\n\tdefer e.mu.Unlock()\n\tif e.closed {\n\t\treturn nil\n\t}\n\te.closed = true\n\tvars.DeleteStatistic(e.statsKey)\n\te.diag.ClosingEdge(e.Collected(), e.Emitted())\n\treturn e.StatsEdge.Close()\n}\n"
        },
        {
          "name": "edge",
          "type": "tree",
          "content": null
        },
        {
          "name": "etc",
          "type": "tree",
          "content": null
        },
        {
          "name": "eval.go",
          "type": "blob",
          "size": 5.302734375,
          "content": "package kapacitor\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n\t\"github.com/influxdata/kapacitor/tick/ast\"\n\t\"github.com/influxdata/kapacitor/tick/stateful\"\n)\n\ntype EvalNode struct {\n\tnode\n\te           *pipeline.EvalNode\n\texpressions []stateful.Expression\n\trefVarList  [][]string\n\tscopePool   stateful.ScopePool\n\ttags        map[string]bool\n}\n\n// Create a new  EvalNode which applies a transformation func to each point in a stream and returns a single point.\nfunc newEvalNode(et *ExecutingTask, n *pipeline.EvalNode, d NodeDiagnostic) (*EvalNode, error) {\n\tif len(n.AsList) != len(n.Lambdas) {\n\t\treturn nil, errors.New(\"must provide one name per expression via the 'As' property\")\n\t}\n\ten := &EvalNode{\n\t\tnode: node{Node: n, et: et, diag: d},\n\t\te:    n,\n\t}\n\n\t// Create stateful expressions\n\ten.expressions = make([]stateful.Expression, len(n.Lambdas))\n\ten.refVarList = make([][]string, len(n.Lambdas))\n\texpressions := make([]ast.Node, len(n.Lambdas))\n\tfor i, lambda := range n.Lambdas {\n\t\texpressions[i] = lambda.Expression\n\t\tstatefulExpr, err := stateful.NewExpression(lambda.Expression)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"Failed to compile %v expression: %v\", i, err)\n\t\t}\n\t\ten.expressions[i] = statefulExpr\n\t\trefVars := ast.FindReferenceVariables(lambda.Expression)\n\t\ten.refVarList[i] = refVars\n\t}\n\t// Create a single pool for the combination of all expressions\n\ten.scopePool = stateful.NewScopePool(ast.FindReferenceVariables(expressions...))\n\n\t// Create map of tags\n\tif l := len(n.TagsList); l > 0 {\n\t\ten.tags = make(map[string]bool, l)\n\t\tfor _, tag := range n.TagsList {\n\t\t\ten.tags[tag] = true\n\t\t}\n\t}\n\n\ten.node.runF = en.runEval\n\treturn en, nil\n}\n\nfunc (n *EvalNode) runEval(snapshot []byte) error {\n\tconsumer := edge.NewGroupedConsumer(\n\t\tn.ins[0],\n\t\tn,\n\t)\n\tn.statMap.Set(statCardinalityGauge, consumer.CardinalityVar())\n\n\treturn consumer.Consume()\n\n}\n\nfunc (n *EvalNode) NewGroup(group edge.GroupInfo, first edge.PointMeta) (edge.Receiver, error) {\n\treturn edge.NewReceiverFromForwardReceiverWithStats(\n\t\tn.outs,\n\t\tedge.NewTimedForwardReceiver(n.timer, n.newGroup()),\n\t), nil\n}\n\nfunc (n *EvalNode) newGroup() *evalGroup {\n\texpressions := make([]stateful.Expression, len(n.expressions))\n\tfor i, exp := range n.expressions {\n\t\texpressions[i] = exp.CopyReset()\n\t}\n\treturn &evalGroup{\n\t\tn:           n,\n\t\texpressions: expressions,\n\t}\n}\n\nfunc (n *EvalNode) eval(expressions []stateful.Expression, p edge.FieldsTagsTimeSetter) (err error) {\n\tvars := n.scopePool.Get()\n\tdefer n.scopePool.Put(vars)\n\n\tfor i, expr := range expressions {\n\t\terr := fillScope(vars, n.refVarList[i], p)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tv, err := expr.Eval(vars)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tname := n.e.AsList[i]\n\t\tvars.Set(name, v)\n\t}\n\tfields := p.Fields()\n\ttags := p.Tags()\n\tnewTags := tags\n\tif len(n.tags) > 0 {\n\t\tnewTags = newTags.Copy()\n\t\tfor tag := range n.tags {\n\t\t\tv, err := vars.Get(tag)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif s, ok := v.(string); !ok {\n\t\t\t\treturn fmt.Errorf(\"result of a tag expression must be of type string, got %T\", v)\n\t\t\t} else {\n\t\t\t\tnewTags[tag] = s\n\t\t\t}\n\t\t}\n\t}\n\tvar newFields models.Fields\n\tif n.e.KeepFlag {\n\t\tif l := len(n.e.KeepList); l != 0 {\n\t\t\tnewFields = make(models.Fields, l)\n\t\t\tfor _, f := range n.e.KeepList {\n\t\t\t\t// Try the vars scope first\n\t\t\t\tif vars.Has(f) {\n\t\t\t\t\tv, err := vars.Get(f)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tnewFields[f] = v\n\t\t\t\t} else if v, ok := fields[f]; ok {\n\t\t\t\t\t// Try the raw fields next, since it may not have been a referenced var.\n\t\t\t\t\tnewFields[f] = v\n\t\t\t\t} else {\n\t\t\t\t\treturn fmt.Errorf(\"cannot keep field %q, field does not exist\", f)\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tnewFields = make(models.Fields, len(fields)+len(n.e.AsList))\n\t\t\tfor f, v := range fields {\n\t\t\t\tnewFields[f] = v\n\t\t\t}\n\t\t\tfor _, f := range n.e.AsList {\n\t\t\t\tv, err := vars.Get(f)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tnewFields[f] = v\n\t\t\t}\n\t\t}\n\t} else {\n\t\tnewFields = make(models.Fields, len(n.e.AsList)-len(n.tags))\n\t\tfor _, f := range n.e.AsList {\n\t\t\tif n.tags[f] {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tv, err := vars.Get(f)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tnewFields[f] = v\n\t\t}\n\t}\n\tp.SetFields(newFields)\n\tp.SetTags(newTags)\n\treturn\n}\n\ntype evalGroup struct {\n\tn           *EvalNode\n\texpressions []stateful.Expression\n}\n\nfunc (g *evalGroup) BeginBatch(begin edge.BeginBatchMessage) (edge.Message, error) {\n\tbegin = begin.ShallowCopy()\n\tbegin.SetSizeHint(0)\n\treturn begin, nil\n}\n\nfunc (g *evalGroup) BatchPoint(bp edge.BatchPointMessage) (edge.Message, error) {\n\tbp = bp.ShallowCopy()\n\tif g.doEval(bp) {\n\t\treturn bp, nil\n\t}\n\treturn nil, nil\n}\n\nfunc (g *evalGroup) EndBatch(end edge.EndBatchMessage) (edge.Message, error) {\n\treturn end, nil\n}\n\nfunc (g *evalGroup) Point(p edge.PointMessage) (edge.Message, error) {\n\tp = p.ShallowCopy()\n\tif g.doEval(p) {\n\t\treturn p, nil\n\t}\n\treturn nil, nil\n}\n\nfunc (g *evalGroup) doEval(p edge.FieldsTagsTimeSetter) bool {\n\terr := g.n.eval(g.expressions, p)\n\tif err != nil {\n\t\tif !g.n.e.QuietFlag {\n\t\t\tg.n.diag.Error(\"error evaluating expression\", err)\n\t\t}\n\t\t// Skip bad point\n\t\treturn false\n\t}\n\treturn true\n}\n\nfunc (g *evalGroup) Barrier(b edge.BarrierMessage) (edge.Message, error) {\n\treturn b, nil\n}\nfunc (g *evalGroup) DeleteGroup(d edge.DeleteGroupMessage) (edge.Message, error) {\n\treturn d, nil\n}\nfunc (g *evalGroup) Done() {}\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "expr.go",
          "type": "blob",
          "size": 1.689453125,
          "content": "package kapacitor\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/tick/ast\"\n\t\"github.com/influxdata/kapacitor/tick/stateful\"\n)\n\n// EvalPredicate - Evaluate a given expression as a boolean predicate against a set of fields and tags\nfunc EvalPredicate(se stateful.Expression, scopePool stateful.ScopePool, p edge.FieldsTagsTimeGetter) (bool, error) {\n\tvars := scopePool.Get()\n\tdefer scopePool.Put(vars)\n\terr := fillScope(vars, scopePool.ReferenceVariables(), p)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\t// for function signature check\n\tif _, err := se.Type(vars); err != nil {\n\t\treturn false, err\n\t}\n\n\treturn se.EvalBool(vars)\n}\n\n// fillScope - given a scope and reference variables, we fill the exact variables from the now, fields and tags.\nfunc fillScope(vars *stateful.Scope, referenceVariables []string, p edge.FieldsTagsTimeGetter) error {\n\tnow := p.Time()\n\tfields := p.Fields()\n\ttags := p.Tags()\n\tfor _, refVariableName := range referenceVariables {\n\t\tif refVariableName == \"time\" {\n\t\t\tvars.Set(\"time\", now.Local())\n\t\t\tcontinue\n\t\t}\n\n\t\t// Support the error with tags/fields collision\n\t\tvar fieldValue interface{}\n\t\tvar isFieldExists bool\n\t\tvar tagValue interface{}\n\t\tvar isTagExists bool\n\n\t\tif fieldValue, isFieldExists = fields[refVariableName]; isFieldExists {\n\t\t\tvars.Set(refVariableName, fieldValue)\n\t\t}\n\n\t\tif tagValue, isTagExists = tags[refVariableName]; isTagExists {\n\t\t\tif isFieldExists {\n\t\t\t\treturn fmt.Errorf(\"cannot have field and tags with same name %q\", refVariableName)\n\t\t\t}\n\t\t\tvars.Set(refVariableName, tagValue)\n\t\t}\n\t\tif !isFieldExists && !isTagExists {\n\t\t\tif !vars.Has(refVariableName) {\n\t\t\t\tvars.Set(refVariableName, ast.MissingValue)\n\t\t\t}\n\n\t\t}\n\t}\n\n\treturn nil\n}\n"
        },
        {
          "name": "expvar",
          "type": "tree",
          "content": null
        },
        {
          "name": "flatten.go",
          "type": "blob",
          "size": 5.271484375,
          "content": "package kapacitor\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n)\n\ntype FlattenNode struct {\n\tnode\n\tf *pipeline.FlattenNode\n\n\tbufPool sync.Pool\n}\n\n// Create a new FlattenNode, which takes pairs from parent streams combines them into a single point.\nfunc newFlattenNode(et *ExecutingTask, n *pipeline.FlattenNode, d NodeDiagnostic) (*FlattenNode, error) {\n\tfn := &FlattenNode{\n\t\tf:    n,\n\t\tnode: node{Node: n, et: et, diag: d},\n\t\tbufPool: sync.Pool{\n\t\t\tNew: func() interface{} { return &bytes.Buffer{} },\n\t\t},\n\t}\n\tfn.node.runF = fn.runFlatten\n\treturn fn, nil\n}\n\nfunc (n *FlattenNode) runFlatten([]byte) error {\n\tconsumer := edge.NewGroupedConsumer(\n\t\tn.ins[0],\n\t\tn,\n\t)\n\tn.statMap.Set(statCardinalityGauge, consumer.CardinalityVar())\n\treturn consumer.Consume()\n}\n\nfunc (n *FlattenNode) NewGroup(group edge.GroupInfo, first edge.PointMeta) (edge.Receiver, error) {\n\tt := first.Time().Round(n.f.Tolerance)\n\treturn &flattenBuffer{\n\t\tn:         n,\n\t\ttime:      t,\n\t\tname:      first.Name(),\n\t\tgroupInfo: group,\n\t}, nil\n}\n\ntype flattenBuffer struct {\n\tn         *FlattenNode\n\ttime      time.Time\n\tname      string\n\tgroupInfo edge.GroupInfo\n\tpoints    []edge.FieldsTagsTimeGetter\n}\n\nfunc (b *flattenBuffer) BeginBatch(begin edge.BeginBatchMessage) error {\n\tb.n.timer.Start()\n\tdefer b.n.timer.Stop()\n\tb.name = begin.Name()\n\tb.time = time.Time{}\n\tif s := begin.SizeHint(); s > cap(b.points) {\n\t\tb.points = make([]edge.FieldsTagsTimeGetter, 0, s)\n\t}\n\n\tbegin = begin.ShallowCopy()\n\tbegin.SetSizeHint(0)\n\tb.n.timer.Pause()\n\terr := edge.Forward(b.n.outs, begin)\n\tb.n.timer.Resume()\n\treturn err\n}\n\nfunc (b *flattenBuffer) BatchPoint(bp edge.BatchPointMessage) error {\n\tb.n.timer.Start()\n\tdefer b.n.timer.Stop()\n\n\tt := bp.Time().Round(b.n.f.Tolerance)\n\tbp = bp.ShallowCopy()\n\tbp.SetTime(t)\n\n\tt, fields, err := b.addPoint(bp)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif len(fields) == 0 {\n\t\treturn nil\n\t}\n\n\treturn b.emitBatchPoint(t, fields)\n}\n\nfunc (b *flattenBuffer) emitBatchPoint(t time.Time, fields models.Fields) error {\n\t// Emit batch point\n\tflatP := edge.NewBatchPointMessage(\n\t\tfields,\n\t\tb.groupInfo.Tags,\n\t\tt,\n\t)\n\tb.n.timer.Pause()\n\terr := edge.Forward(b.n.outs, flatP)\n\tb.n.timer.Resume()\n\treturn err\n}\n\nfunc (b *flattenBuffer) EndBatch(end edge.EndBatchMessage) error {\n\tb.n.timer.Start()\n\tdefer b.n.timer.Stop()\n\n\tif len(b.points) > 0 {\n\t\tfields, err := b.n.flatten(b.points)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := b.emitBatchPoint(b.time, fields); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tb.points = b.points[0:0]\n\t}\n\tb.n.timer.Pause()\n\terr := edge.Forward(b.n.outs, end)\n\tb.n.timer.Resume()\n\treturn err\n}\n\nfunc (b *flattenBuffer) Point(p edge.PointMessage) error {\n\tb.n.timer.Start()\n\tdefer b.n.timer.Stop()\n\n\tt := p.Time().Round(b.n.f.Tolerance)\n\tp = p.ShallowCopy()\n\tp.SetTime(t)\n\n\tt, fields, err := b.addPoint(p)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif len(fields) == 0 {\n\t\treturn nil\n\t}\n\n\t// Emit point\n\tflatP := edge.NewPointMessage(\n\t\tb.name, \"\", \"\",\n\t\tb.groupInfo.Dimensions,\n\t\tfields,\n\t\tb.groupInfo.Tags,\n\t\tt,\n\t)\n\t// update the time\n\tif t.After(b.time) {\n\t\tb.time = t\n\t}\n\tb.n.timer.Pause()\n\terr = edge.Forward(b.n.outs, flatP)\n\tb.n.timer.Resume()\n\treturn err\n}\n\nfunc (b *flattenBuffer) addPoint(p edge.FieldsTagsTimeGetter) (next time.Time, fields models.Fields, err error) {\n\tt := p.Time()\n\tif !t.Equal(b.time) {\n\t\tif len(b.points) > 0 {\n\t\t\tfields, err = b.n.flatten(b.points)\n\t\t\tif err != nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tnext = b.time\n\t\t\tb.points = b.points[0:0]\n\t\t}\n\t\t// Update buffer with new time\n\t\tb.time = t\n\t}\n\tb.points = append(b.points, p)\n\treturn\n}\n\nfunc (b *flattenBuffer) Barrier(barrier edge.BarrierMessage) error {\n\tb.n.timer.Start()\n\tdefer b.n.timer.Stop()\n\n\tif barrier.Time().After(b.time) && len(b.points) > 0 {\n\t\tfields, err := b.n.flatten(b.points)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tmsg := edge.NewPointMessage(\n\t\t\tb.name, \"\", \"\",\n\t\t\tb.groupInfo.Dimensions,\n\t\t\tfields,\n\t\t\tb.groupInfo.Tags,\n\t\t\tb.time,\n\t\t)\n\t\tb.n.timer.Pause()\n\t\terr = edge.Forward(b.n.outs, msg)\n\t\tb.n.timer.Resume()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tb.points = b.points[0:0]\n\t}\n\tb.n.timer.Pause()\n\terr := edge.Forward(b.n.outs, barrier)\n\tb.n.timer.Resume()\n\treturn err\n}\n\nfunc (b *flattenBuffer) DeleteGroup(d edge.DeleteGroupMessage) error {\n\tb.points = b.points[0:0]\n\treturn edge.Forward(b.n.outs, d)\n}\n\nfunc (b *flattenBuffer) Done() {}\n\nfunc (n *FlattenNode) flatten(points []edge.FieldsTagsTimeGetter) (models.Fields, error) {\n\tfields := make(models.Fields)\n\tif len(points) == 0 {\n\t\treturn fields, nil\n\t}\n\tfieldPrefix := n.bufPool.Get().(*bytes.Buffer)\n\tdefer n.bufPool.Put(fieldPrefix)\nPOINTS:\n\tfor _, p := range points {\n\t\ttags := p.Tags()\n\t\tfor i, tag := range n.f.Dimensions {\n\t\t\tif v, ok := tags[tag]; ok {\n\t\t\t\tif i > 0 {\n\t\t\t\t\tfieldPrefix.WriteString(n.f.Delimiter)\n\t\t\t\t}\n\t\t\t\tfieldPrefix.WriteString(v)\n\t\t\t} else {\n\t\t\t\tn.diag.Error(\"point missing tag for flatten operation\", fmt.Errorf(\"tag %s is missing from point\", tag))\n\t\t\t\tcontinue POINTS\n\t\t\t}\n\t\t}\n\t\tl := fieldPrefix.Len()\n\t\tfor fname, value := range p.Fields() {\n\t\t\tif !n.f.DropOriginalFieldNameFlag {\n\t\t\t\tif l > 0 {\n\t\t\t\t\tfieldPrefix.WriteString(n.f.Delimiter)\n\t\t\t\t}\n\t\t\t\tfieldPrefix.WriteString(fname)\n\t\t\t}\n\t\t\tfields[fieldPrefix.String()] = value\n\t\t\tfieldPrefix.Truncate(l)\n\t\t}\n\t\tfieldPrefix.Reset()\n\t}\n\treturn fields, nil\n}\n"
        },
        {
          "name": "fluxquery.go",
          "type": "blob",
          "size": 0.5625,
          "content": "package kapacitor\n\nimport (\n\t\"sync\"\n\t\"time\"\n)\n\ntype QueryFlux struct {\n\torg     string\n\torgID   string\n\tstmt    string\n\tqueryMu sync.Mutex\n\tNow     time.Time\n}\n\nfunc NewQueryFlux(queryString, org, orgID string) (*QueryFlux, error) {\n\treturn &QueryFlux{org: org, orgID: orgID, stmt: queryString}, nil\n}\n\n// Deep clone this query\nfunc (q *QueryFlux) Clone() (*QueryFlux, error) {\n\tq.queryMu.Lock()\n\tdefer q.queryMu.Unlock()\n\treturn &QueryFlux{\n\t\tstmt:  q.stmt,\n\t\torg:   q.org,\n\t\torgID: q.orgID,\n\t\tNow:   q.Now,\n\t}, nil\n\n}\n\nfunc (q *QueryFlux) String() string {\n\treturn q.stmt\n}\n"
        },
        {
          "name": "generate.sh",
          "type": "blob",
          "size": 0.4609375,
          "content": "#!/bin/bash -e\n\ngo install google.golang.org/protobuf/cmd/protoc-gen-go\ngo install github.com/benbjohnson/tmpl\ngo install github.com/mailru/easyjson/easyjson\n\nfunction check_changes () {\n  changes=\"$(git status --porcelain=v1 2>/dev/null)\"\n  if [ -n \"$changes\" ] ; then\n    echo $1\n    echo \"$changes\"\n    git --no-pager diff\n    exit 1\n  fi\n}\n\ncheck_changes \"git is dirty before running generate!\"\n\ngo generate ./...\n\ncheck_changes \"git is dirty after running generate!\"\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 13.9453125,
          "content": "module github.com/influxdata/kapacitor\n\ngo 1.22\n\nrequire (\n\tgithub.com/BurntSushi/toml v1.2.1\n\tgithub.com/IBM/sarama v1.43.3\n\tgithub.com/aws/aws-sdk-go v1.51.12\n\tgithub.com/benbjohnson/clock v1.1.0\n\tgithub.com/benbjohnson/tmpl v1.0.0\n\tgithub.com/cenkalti/backoff v2.2.1+incompatible\n\tgithub.com/cespare/xxhash v1.1.0\n\tgithub.com/davecgh/go-spew v1.1.1\n\tgithub.com/docker/docker v24.0.9+incompatible\n\tgithub.com/dustin/go-humanize v1.0.0\n\tgithub.com/eclipse/paho.mqtt.golang v1.2.0\n\tgithub.com/evanphx/json-patch v4.9.0+incompatible\n\tgithub.com/ghodss/yaml v1.0.0\n\tgithub.com/golang-jwt/jwt v3.2.2+incompatible\n\tgithub.com/google/btree v1.0.1\n\tgithub.com/google/go-cmp v0.6.0\n\tgithub.com/google/uuid v1.3.0\n\tgithub.com/gorhill/cronexpr v0.0.0-20180427100037-88b0669f7d75\n\tgithub.com/h2non/gock v1.2.0\n\tgithub.com/influxdata/cron v0.0.0-20201006132531-4bb0a200dcbe\n\tgithub.com/influxdata/flux v0.171.0\n\tgithub.com/influxdata/httprouter v1.3.1-0.20191122104820-ee83e2772f69\n\tgithub.com/influxdata/influx-cli/v2 v2.0.0-20210526124422-63da8eccbdb7\n\tgithub.com/influxdata/influxdb v1.9.6\n\tgithub.com/influxdata/influxdb/v2 v2.0.1-alpha.10.0.20210507184756-dc72dc3f0c07\n\tgithub.com/influxdata/influxql v1.1.1-0.20211004132434-7e7d61973256\n\tgithub.com/influxdata/pkg-config v0.2.12\n\tgithub.com/influxdata/usage-client v0.0.0-20160829180054-6d3895376368\n\tgithub.com/influxdata/wlog v0.0.0-20160411224016-7c63b0a71ef8\n\tgithub.com/k-sone/snmpgo v3.2.0+incompatible\n\tgithub.com/mailru/easyjson v0.7.7\n\tgithub.com/mitchellh/copystructure v1.0.0\n\tgithub.com/mitchellh/mapstructure v1.4.1\n\tgithub.com/mitchellh/reflectwalk v1.0.1\n\tgithub.com/opentracing/opentracing-go v1.2.0\n\tgithub.com/pkg/errors v0.9.1\n\tgithub.com/prometheus/client_golang v1.10.0\n\tgithub.com/prometheus/common v0.20.0\n\tgithub.com/prometheus/prometheus v1.8.2-0.20210331101223-3cafc58827d1\n\tgithub.com/rcrowley/go-metrics v0.0.0-20201227073835-cf1acfcdf475\n\tgithub.com/serenize/snaker v0.0.0-20161123064335-543781d2b79b\n\tgithub.com/shurcooL/markdownfmt v0.0.0-20170214213350-10aae0a270ab\n\tgithub.com/spaolacci/murmur3 v0.0.0-20180118202830-f09979ecbc72\n\tgithub.com/stretchr/testify v1.9.0\n\tgithub.com/uber/jaeger-client-go v2.28.0+incompatible\n\tgithub.com/urfave/cli/v2 v2.3.0\n\tgithub.com/xdg/scram v0.0.0-20180814205039-7eeb5667e42c\n\tgithub.com/zeebo/mwc v0.0.4\n\tgo.etcd.io/bbolt v1.3.7\n\tgo.uber.org/zap v1.16.0\n\tgolang.org/x/crypto v0.31.0\n\tgolang.org/x/oauth2 v0.23.0\n\tgolang.org/x/tools v0.21.1-0.20240508182429-e35e4ccd0d2d\n\tgoogle.golang.org/protobuf v1.33.0\n\tgopkg.in/gomail.v2 v2.0.0-20160411212932-81ebce5c23df\n\thonnef.co/go/tools v0.4.3\n)\n\nrequire (\n\tcloud.google.com/go v0.110.0 // indirect\n\tcloud.google.com/go/bigquery v1.50.0 // indirect\n\tcloud.google.com/go/bigtable v1.10.1 // indirect\n\tcloud.google.com/go/compute/metadata v0.3.0 // indirect\n\tcloud.google.com/go/iam v0.13.0 // indirect\n\tcloud.google.com/go/longrunning v0.4.1 // indirect\n\tcollectd.org v0.3.0 // indirect\n\tgithub.com/AlecAivazis/survey/v2 v2.2.9 // indirect\n\tgithub.com/Azure/azure-pipeline-go v0.2.3 // indirect\n\tgithub.com/Azure/azure-sdk-for-go v52.5.0+incompatible // indirect\n\tgithub.com/Azure/azure-storage-blob-go v0.14.0 // indirect\n\tgithub.com/Azure/go-autorest v14.2.0+incompatible // indirect\n\tgithub.com/Azure/go-autorest/autorest v0.11.18 // indirect\n\tgithub.com/Azure/go-autorest/autorest/adal v0.9.23 // indirect\n\tgithub.com/Azure/go-autorest/autorest/azure/auth v0.5.3 // indirect\n\tgithub.com/Azure/go-autorest/autorest/azure/cli v0.4.2 // indirect\n\tgithub.com/Azure/go-autorest/autorest/date v0.3.0 // indirect\n\tgithub.com/Azure/go-autorest/autorest/to v0.4.0 // indirect\n\tgithub.com/Azure/go-autorest/autorest/validation v0.3.1 // indirect\n\tgithub.com/Azure/go-autorest/logger v0.2.1 // indirect\n\tgithub.com/Azure/go-autorest/tracing v0.6.0 // indirect\n\tgithub.com/DATA-DOG/go-sqlmock v1.4.1 // indirect\n\tgithub.com/Masterminds/semver v1.4.2 // indirect\n\tgithub.com/Masterminds/sprig v2.16.0+incompatible // indirect\n\tgithub.com/SAP/go-hdb v0.14.1 // indirect\n\tgithub.com/alecthomas/template v0.0.0-20190718012654-fb15b899a751 // indirect\n\tgithub.com/alecthomas/units v0.0.0-20210208195552-ff826a37aa15 // indirect\n\tgithub.com/andreyvit/diff v0.0.0-20170406064948-c7f18ee00883 // indirect\n\tgithub.com/andybalholm/brotli v1.0.4 // indirect\n\tgithub.com/aokoli/goutils v1.0.1 // indirect\n\tgithub.com/apache/arrow/go/arrow v0.0.0-20211112161151-bc219186db40 // indirect\n\tgithub.com/apache/arrow/go/v11 v11.0.0 // indirect\n\tgithub.com/apache/arrow/go/v7 v7.0.0 // indirect\n\tgithub.com/apache/thrift v0.16.0 // indirect\n\tgithub.com/armon/go-metrics v0.3.6 // indirect\n\tgithub.com/asaskevich/govalidator v0.0.0-20200907205600-7a23bdc65eef // indirect\n\tgithub.com/aws/aws-sdk-go-v2 v1.11.0 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/aws/protocol/eventstream v1.0.0 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/credentials v1.6.1 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/feature/s3/manager v1.7.1 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/internal/configsources v1.1.0 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/internal/endpoints/v2 v2.0.0 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/service/internal/accept-encoding v1.5.0 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/service/internal/presigned-url v1.5.0 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/service/internal/s3shared v1.9.0 // indirect\n\tgithub.com/aws/aws-sdk-go-v2/service/s3 v1.19.0 // indirect\n\tgithub.com/aws/smithy-go v1.9.0 // indirect\n\tgithub.com/benbjohnson/immutable v0.3.0 // indirect\n\tgithub.com/beorn7/perks v1.0.1 // indirect\n\tgithub.com/bonitoo-io/go-sql-bigquery v0.3.4-1.4.0 // indirect\n\tgithub.com/cespare/xxhash/v2 v2.2.0 // indirect\n\tgithub.com/cpuguy83/go-md2man/v2 v2.0.0 // indirect\n\tgithub.com/deepmap/oapi-codegen v1.6.0 // indirect\n\tgithub.com/denisenkom/go-mssqldb v0.10.0 // indirect\n\tgithub.com/dimchansky/utfbom v1.1.0 // indirect\n\tgithub.com/docker/go-connections v0.4.0 // indirect\n\tgithub.com/docker/go-units v0.4.0 // indirect\n\tgithub.com/eapache/go-resiliency v1.7.0 // indirect\n\tgithub.com/eapache/go-xerial-snappy v0.0.0-20230731223053-c322873962e3 // indirect\n\tgithub.com/eapache/queue v1.1.0 // indirect\n\tgithub.com/editorconfig-checker/editorconfig-checker v0.0.0-20190819115812-1474bdeaf2a2 // indirect\n\tgithub.com/editorconfig/editorconfig-core-go/v2 v2.1.1 // indirect\n\tgithub.com/fatih/color v1.9.0 // indirect\n\tgithub.com/form3tech-oss/jwt-go v3.2.5+incompatible // indirect\n\tgithub.com/gabriel-vasile/mimetype v1.4.0 // indirect\n\tgithub.com/geoffgarside/ber v0.0.0-20170306085127-854377f11dfb // indirect\n\tgithub.com/glycerine/go-unsnap-stream v0.0.0-20181221182339-f9677308dec2 // indirect\n\tgithub.com/go-chi/chi v4.1.0+incompatible // indirect\n\tgithub.com/go-kit/kit v0.10.0 // indirect\n\tgithub.com/go-logfmt/logfmt v0.5.0 // indirect\n\tgithub.com/go-logr/logr v0.4.0 // indirect\n\tgithub.com/go-openapi/errors v0.19.9 // indirect\n\tgithub.com/go-openapi/strfmt v0.20.0 // indirect\n\tgithub.com/go-sql-driver/mysql v1.5.0 // indirect\n\tgithub.com/go-stack/stack v1.8.0 // indirect\n\tgithub.com/go-zookeeper/zk v1.0.2 // indirect\n\tgithub.com/goccy/go-json v0.9.11 // indirect\n\tgithub.com/gofrs/uuid v3.3.0+incompatible // indirect\n\tgithub.com/gogo/protobuf v1.3.2 // indirect\n\tgithub.com/golang-jwt/jwt/v4 v4.5.1 // indirect\n\tgithub.com/golang-sql/civil v0.0.0-20190719163853-cb61b32ac6fe // indirect\n\tgithub.com/golang/geo v0.0.0-20190916061304-5b978397cfec // indirect\n\tgithub.com/golang/groupcache v0.0.0-20200121045136-8c9f03a8e57e // indirect\n\tgithub.com/golang/protobuf v1.5.3 // indirect\n\tgithub.com/golang/snappy v0.0.4 // indirect\n\tgithub.com/google/flatbuffers v2.0.8+incompatible // indirect\n\tgithub.com/google/gofuzz v1.2.0 // indirect\n\tgithub.com/googleapis/enterprise-certificate-proxy v0.2.3 // indirect\n\tgithub.com/googleapis/gax-go/v2 v2.7.1 // indirect\n\tgithub.com/googleapis/gnostic v0.4.1 // indirect\n\tgithub.com/gophercloud/gophercloud v0.17.0 // indirect\n\tgithub.com/h2non/parth v0.0.0-20190131123155-b4df798d6542 // indirect\n\tgithub.com/hashicorp/consul/api v1.8.1 // indirect\n\tgithub.com/hashicorp/errwrap v1.0.0 // indirect\n\tgithub.com/hashicorp/go-cleanhttp v0.5.1 // indirect\n\tgithub.com/hashicorp/go-hclog v0.14.1 // indirect\n\tgithub.com/hashicorp/go-immutable-radix v1.3.0 // indirect\n\tgithub.com/hashicorp/go-msgpack v1.1.5 // indirect\n\tgithub.com/hashicorp/go-multierror v1.1.1 // indirect\n\tgithub.com/hashicorp/go-rootcerts v1.0.2 // indirect\n\tgithub.com/hashicorp/go-uuid v1.0.3 // indirect\n\tgithub.com/hashicorp/golang-lru v0.5.4 // indirect\n\tgithub.com/hashicorp/serf v0.9.5 // indirect\n\tgithub.com/huandu/xstrings v1.0.0 // indirect\n\tgithub.com/imdario/mergo v0.3.9 // indirect\n\tgithub.com/influxdata/gosnowflake v1.6.9 // indirect\n\tgithub.com/influxdata/influxdb-client-go/v2 v2.3.1-0.20210518120617-5d1fff431040 // indirect\n\tgithub.com/influxdata/line-protocol v0.0.0-20200327222509-2487e7298839 // indirect\n\tgithub.com/influxdata/roaring v0.4.13-0.20180809181101-fc520f41fab6 // indirect\n\tgithub.com/influxdata/tdigest v0.0.2-0.20210216194612-fc98d27c9e8b // indirect\n\tgithub.com/jcmturner/aescts/v2 v2.0.0 // indirect\n\tgithub.com/jcmturner/dnsutils/v2 v2.0.0 // indirect\n\tgithub.com/jcmturner/gofork v1.7.6 // indirect\n\tgithub.com/jcmturner/gokrb5/v8 v8.4.4 // indirect\n\tgithub.com/jcmturner/rpc/v2 v2.0.3 // indirect\n\tgithub.com/jedib0t/go-pretty v4.3.0+incompatible // indirect\n\tgithub.com/jmespath/go-jmespath v0.4.0 // indirect\n\tgithub.com/josharian/intern v1.0.0 // indirect\n\tgithub.com/jpillora/backoff v1.0.0 // indirect\n\tgithub.com/json-iterator/go v1.1.10 // indirect\n\tgithub.com/jsternberg/zap-logfmt v1.2.0 // indirect\n\tgithub.com/kballard/go-shellquote v0.0.0-20180428030007-95032a82bc51 // indirect\n\tgithub.com/kevinburke/go-bindata v3.11.0+incompatible // indirect\n\tgithub.com/klauspost/asmfmt v1.3.2 // indirect\n\tgithub.com/klauspost/compress v1.17.9 // indirect\n\tgithub.com/klauspost/cpuid/v2 v2.0.9 // indirect\n\tgithub.com/lib/pq v1.2.0 // indirect\n\tgithub.com/mattn/go-colorable v0.1.8 // indirect\n\tgithub.com/mattn/go-ieproxy v0.0.1 // indirect\n\tgithub.com/mattn/go-isatty v0.0.16 // indirect\n\tgithub.com/mattn/go-runewidth v0.0.9 // indirect\n\tgithub.com/matttproud/golang_protobuf_extensions v1.0.1 // indirect\n\tgithub.com/mgutz/ansi v0.0.0-20170206155736-9520e82c474b // indirect\n\tgithub.com/miekg/dns v1.1.41 // indirect\n\tgithub.com/mileusna/useragent v0.0.0-20190129205925-3e331f0949a5 // indirect\n\tgithub.com/minio/asm2plan9s v0.0.0-20200509001527-cdd76441f9d8 // indirect\n\tgithub.com/minio/c2goasm v0.0.0-20190812172519-36a3d3bbc4f3 // indirect\n\tgithub.com/mitchellh/go-homedir v1.1.0 // indirect\n\tgithub.com/mitchellh/go-testing-interface v1.14.0 // indirect\n\tgithub.com/mna/pigeon v1.0.1-0.20180808201053-bb0192cfc2ae // indirect\n\tgithub.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd // indirect\n\tgithub.com/modern-go/reflect2 v1.0.1 // indirect\n\tgithub.com/mschoch/smat v0.0.0-20160514031455-90eadee771ae // indirect\n\tgithub.com/mwitkow/go-conntrack v0.0.0-20190716064945-2f068394615f // indirect\n\tgithub.com/onsi/ginkgo v1.14.2 // indirect\n\tgithub.com/onsi/gomega v1.10.3 // indirect\n\tgithub.com/opencontainers/go-digest v1.0.0 // indirect\n\tgithub.com/opencontainers/image-spec v1.0.2 // indirect\n\tgithub.com/philhofer/fwd v1.0.0 // indirect\n\tgithub.com/pierrec/lz4 v2.6.1+incompatible // indirect\n\tgithub.com/pierrec/lz4/v4 v4.1.21 // indirect\n\tgithub.com/pkg/browser v0.0.0-20210911075715-681adbf594b8 // indirect\n\tgithub.com/pmezard/go-difflib v1.0.0 // indirect\n\tgithub.com/prometheus/client_model v0.2.0 // indirect\n\tgithub.com/prometheus/procfs v0.6.0 // indirect\n\tgithub.com/russross/blackfriday v1.5.2 // indirect\n\tgithub.com/russross/blackfriday/v2 v2.0.1 // indirect\n\tgithub.com/segmentio/kafka-go v0.3.10 // indirect\n\tgithub.com/sergi/go-diff v1.0.0 // indirect\n\tgithub.com/shurcooL/go v0.0.0-20170331015642-20b4b0a35211 // indirect\n\tgithub.com/shurcooL/sanitized_anchor_name v1.0.0 // indirect\n\tgithub.com/sirupsen/logrus v1.8.1 // indirect\n\tgithub.com/spf13/pflag v1.0.5 // indirect\n\tgithub.com/tinylib/msgp v1.1.0 // indirect\n\tgithub.com/uber-go/tally v3.3.17+incompatible // indirect\n\tgithub.com/uber/athenadriver v1.1.13 // indirect\n\tgithub.com/uber/jaeger-lib v2.4.1+incompatible // indirect\n\tgithub.com/vertica/vertica-sql-go v1.1.1 // indirect\n\tgithub.com/willf/bitset v1.1.9 // indirect\n\tgithub.com/xdg/stringprep v1.0.0 // indirect\n\tgithub.com/xlab/treeprint v1.0.0 // indirect\n\tgithub.com/xwb1989/sqlparser v0.0.0-20180606152119-120387863bf2 // indirect\n\tgithub.com/zeebo/xxh3 v1.0.2 // indirect\n\tgo.mongodb.org/mongo-driver v1.5.1 // indirect\n\tgo.opencensus.io v0.24.0 // indirect\n\tgo.uber.org/atomic v1.7.0 // indirect\n\tgo.uber.org/multierr v1.6.0 // indirect\n\tgolang.org/x/exp/typeparams v0.0.0-20221208152030-732eee02a75a // indirect\n\tgolang.org/x/mod v0.17.0 // indirect\n\tgolang.org/x/net v0.28.0 // indirect\n\tgolang.org/x/sync v0.10.0 // indirect\n\tgolang.org/x/sys v0.28.0 // indirect\n\tgolang.org/x/term v0.27.0 // indirect\n\tgolang.org/x/text v0.21.0 // indirect\n\tgolang.org/x/time v0.0.0-20210220033141-f8bda1e9f3ba // indirect\n\tgolang.org/x/xerrors v0.0.0-20220907171357-04be3eba64a2 // indirect\n\tgoogle.golang.org/api v0.114.0 // indirect\n\tgoogle.golang.org/appengine v1.6.7 // indirect\n\tgoogle.golang.org/genproto v0.0.0-20230410155749-daa745c078e1 // indirect\n\tgoogle.golang.org/grpc v1.56.3 // indirect\n\tgopkg.in/alecthomas/kingpin.v2 v2.2.6 // indirect\n\tgopkg.in/alexcesaro/quotedprintable.v3 v3.0.0-20150716171945-2caba252f4dc // indirect\n\tgopkg.in/fsnotify/fsnotify.v1 v1.4.7 // indirect\n\tgopkg.in/inf.v0 v0.9.1 // indirect\n\tgopkg.in/ini.v1 v1.51.0 // indirect\n\tgopkg.in/yaml.v2 v2.4.0 // indirect\n\tgopkg.in/yaml.v3 v3.0.1 // indirect\n\tk8s.io/api v0.21.0 // indirect\n\tk8s.io/apimachinery v0.21.0 // indirect\n\tk8s.io/client-go v0.21.0 // indirect\n\tk8s.io/klog/v2 v2.8.0 // indirect\n\tk8s.io/utils v0.0.0-20201110183641-67b214c5f920 // indirect\n\tsigs.k8s.io/structured-merge-diff/v4 v4.1.0 // indirect\n\tsigs.k8s.io/yaml v1.2.0 // indirect\n)\n\nreplace gopkg.in/fsnotify.v1 => github.com/fsnotify/fsnotify v1.4.2\n\nreplace k8s.io/client-go => k8s.io/client-go v0.20.5\n\nreplace k8s.io/api => k8s.io/api v0.20.5\n\nreplace github.com/dgrijalva/jwt-go => github.com/Waterdrips/jwt-go v3.2.1-0.20200915121943-f6506928b72e+incompatible\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 202.2919921875,
          "content": "cloud.google.com/go v0.26.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=\ncloud.google.com/go v0.34.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=\ncloud.google.com/go v0.38.0/go.mod h1:990N+gfupTy94rShfmMCWGDn0LpTmnzTp2qbd1dvSRU=\ncloud.google.com/go v0.43.0/go.mod h1:BOSR3VbTLkk6FDC/TcffxP4NF/FFBGA5ku+jvKOP7pg=\ncloud.google.com/go v0.44.1/go.mod h1:iSa0KzasP4Uvy3f1mN/7PiObzGgflwredwwASm/v6AU=\ncloud.google.com/go v0.44.2/go.mod h1:60680Gw3Yr4ikxnPRS/oxxkBccT6SA1yMk63TGekxKY=\ncloud.google.com/go v0.45.1/go.mod h1:RpBamKRgapWJb87xiFSdk4g1CME7QZg3uwTez+TSTjc=\ncloud.google.com/go v0.46.3/go.mod h1:a6bKKbmY7er1mI7TEI4lsAkts/mkhTSZK8w33B4RAg0=\ncloud.google.com/go v0.50.0/go.mod h1:r9sluTvynVuxRIOHXQEHMFffphuXHOMZMycpNR5e6To=\ncloud.google.com/go v0.51.0/go.mod h1:hWtGJ6gnXH+KgDv+V0zFGDvpi07n3z8ZNj3T1RW0Gcw=\ncloud.google.com/go v0.52.0/go.mod h1:pXajvRH/6o3+F9jDHZWQ5PbGhn+o8w9qiu/CffaVdO4=\ncloud.google.com/go v0.53.0/go.mod h1:fp/UouUEsRkN6ryDKNW/Upv/JBKnv6WDthjR6+vze6M=\ncloud.google.com/go v0.54.0/go.mod h1:1rq2OEkV3YMf6n/9ZvGWI3GWw0VoqH/1x2nd8Is/bPc=\ncloud.google.com/go v0.56.0/go.mod h1:jr7tqZxxKOVYizybht9+26Z/gUq7tiRzu+ACVAMbKVk=\ncloud.google.com/go v0.57.0/go.mod h1:oXiQ6Rzq3RAkkY7N6t3TcE6jE+CIBBbA36lwQ1JyzZs=\ncloud.google.com/go v0.62.0/go.mod h1:jmCYTdRCQuc1PHIIJ/maLInMho30T/Y0M4hTdTShOYc=\ncloud.google.com/go v0.65.0/go.mod h1:O5N8zS7uWy9vkA9vayVHs65eM1ubvY4h553ofrNHObY=\ncloud.google.com/go v0.72.0/go.mod h1:M+5Vjvlc2wnp6tjzE102Dw08nGShTscUx2nZMufOKPI=\ncloud.google.com/go v0.74.0/go.mod h1:VV1xSbzvo+9QJOxLDaJfTjx5e+MePCpCWwvftOeQmWk=\ncloud.google.com/go v0.78.0/go.mod h1:QjdrLG0uq+YwhjoVOLsS1t7TW8fs36kLs4XO5R5ECHg=\ncloud.google.com/go v0.79.0/go.mod h1:3bzgcEeQlzbuEAYu4mrWhKqWjmpprinYgKJLgKHnbb8=\ncloud.google.com/go v0.81.0/go.mod h1:mk/AM35KwGk/Nm2YSeZbxXdrNK3KZOYHmLkOqC2V6E0=\ncloud.google.com/go v0.82.0/go.mod h1:vlKccHJGuFBFufnAnuB08dfEH9Y3H7dzDzRECFdC2TA=\ncloud.google.com/go v0.110.0 h1:Zc8gqp3+a9/Eyph2KDmcGaPtbKRIoqq4YTlL4NMD0Ys=\ncloud.google.com/go v0.110.0/go.mod h1:SJnCLqQ0FCFGSZMUNUf84MV3Aia54kn7pi8st7tMzaY=\ncloud.google.com/go/bigquery v1.0.1/go.mod h1:i/xbL2UlR5RvWAURpBYZTtm/cXjCha9lbfbpx4poX+o=\ncloud.google.com/go/bigquery v1.3.0/go.mod h1:PjpwJnslEMmckchkHFfq+HTD2DmtT67aNFKH1/VBDHE=\ncloud.google.com/go/bigquery v1.4.0/go.mod h1:S8dzgnTigyfTmLBfrtrhyYhwRxG72rYxvftPBK2Dvzc=\ncloud.google.com/go/bigquery v1.5.0/go.mod h1:snEHRnqQbz117VIFhE8bmtwIDY80NLUZUMb4Nv6dBIg=\ncloud.google.com/go/bigquery v1.7.0/go.mod h1://okPTzCYNXSlb24MZs83e2Do+h+VXtc4gLoIoXIAPc=\ncloud.google.com/go/bigquery v1.8.0/go.mod h1:J5hqkt3O0uAFnINi6JXValWIb1v0goeZM77hZzJN/fQ=\ncloud.google.com/go/bigquery v1.50.0 h1:RscMV6LbnAmhAzD893Lv9nXXy2WCaJmbxYPWDLbGqNQ=\ncloud.google.com/go/bigquery v1.50.0/go.mod h1:YrleYEh2pSEbgTBZYMJ5SuSr0ML3ypjRB1zgf7pvQLU=\ncloud.google.com/go/bigtable v1.2.0/go.mod h1:JcVAOl45lrTmQfLj7T6TxyMzIN/3FGGcFm+2xVAli2o=\ncloud.google.com/go/bigtable v1.3.0/go.mod h1:z5EyKrPE8OQmeg4h5MNdKvuSnI9CCT49Ki3f23aBzio=\ncloud.google.com/go/bigtable v1.10.1 h1:QKcRHeAsraxIlrdCZ3LLobXKBvITqcOEnSbHG2rzL9g=\ncloud.google.com/go/bigtable v1.10.1/go.mod h1:cyHeKlx6dcZCO0oSQucYdauseD8kIENGuDOJPKMCVg8=\ncloud.google.com/go/compute/metadata v0.3.0 h1:Tz+eQXMEqDIKRsmY3cHTL6FVaynIjX2QxYC4trgAKZc=\ncloud.google.com/go/compute/metadata v0.3.0/go.mod h1:zFmK7XCadkQkj6TtorcaGlCW1hT1fIilQDwofLpJ20k=\ncloud.google.com/go/datacatalog v1.13.0 h1:4H5IJiyUE0X6ShQBqgFFZvGGcrwGVndTwUSLP4c52gw=\ncloud.google.com/go/datacatalog v1.13.0/go.mod h1:E4Rj9a5ZtAxcQJlEBTLgMTphfP11/lNaAshpoBgemX8=\ncloud.google.com/go/datastore v1.0.0/go.mod h1:LXYbyblFSglQ5pkeyhO+Qmw7ukd3C+pD7TKLgZqpHYE=\ncloud.google.com/go/datastore v1.1.0/go.mod h1:umbIZjpQpHh4hmRpGhH4tLFup+FVzqBi1b3c64qFpCk=\ncloud.google.com/go/iam v0.13.0 h1:+CmB+K0J/33d0zSQ9SlFWUeCCEn5XJA0ZMZ3pHE9u8k=\ncloud.google.com/go/iam v0.13.0/go.mod h1:ljOg+rcNfzZ5d6f1nAUJ8ZIxOaZUVoS14bKCtaLZ/D0=\ncloud.google.com/go/longrunning v0.4.1 h1:v+yFJOfKC3yZdY6ZUI933pIYdhyhV8S3NpWrXWmg7jM=\ncloud.google.com/go/longrunning v0.4.1/go.mod h1:4iWDqhBZ70CvZ6BfETbvam3T8FMvLK+eFj0E6AaRQTo=\ncloud.google.com/go/pubsub v1.0.1/go.mod h1:R0Gpsv3s54REJCy4fxDixWD93lHJMoZTyQ2kNxGRt3I=\ncloud.google.com/go/pubsub v1.1.0/go.mod h1:EwwdRX2sKPjnvnqCa270oGRyludottCI76h+R3AArQw=\ncloud.google.com/go/pubsub v1.2.0/go.mod h1:jhfEVHT8odbXTkndysNHCcx0awwzvfOlguIAii9o8iA=\ncloud.google.com/go/pubsub v1.3.1/go.mod h1:i+ucay31+CNRpDW4Lu78I4xXG+O1r/MAHgjpRVR+TSU=\ncloud.google.com/go/storage v1.0.0/go.mod h1:IhtSnM/ZTZV8YYJWCY8RULGVqBDmpoyjwiyrjsg+URw=\ncloud.google.com/go/storage v1.5.0/go.mod h1:tpKbwo567HUNpVclU5sGELwQWBDZ8gh0ZeosJ0Rtdos=\ncloud.google.com/go/storage v1.6.0/go.mod h1:N7U0C8pVQ/+NIKOBQyamJIeKQKkZ+mxpohlUTyfDhBk=\ncloud.google.com/go/storage v1.8.0/go.mod h1:Wv1Oy7z6Yz3DshWRJFhqM/UCfaWIRTdp0RXyy7KQOVs=\ncloud.google.com/go/storage v1.10.0/go.mod h1:FLPqc6j+Ki4BU591ie1oL6qBQGu2Bl/tZ9ullr3+Kg0=\ncloud.google.com/go/storage v1.29.0 h1:6weCgzRvMg7lzuUurI4697AqIRPU1SvzHhynwpW31jI=\ncloud.google.com/go/storage v1.29.0/go.mod h1:4puEjyTKnku6gfKoTfNOU/W+a9JyuVNxjpS5GBrB8h4=\ncollectd.org v0.3.0 h1:iNBHGw1VvPJxH2B6RiFWFZ+vsjo1lCdRszBeOuwGi00=\ncollectd.org v0.3.0/go.mod h1:A/8DzQBkF6abtvrT2j/AU/4tiBgJWYyh0y/oB/4MlWE=\ndmitri.shuralyov.com/gpu/mtl v0.0.0-20190408044501-666a987793e9/go.mod h1:H6x//7gZCb22OMCxBHrMx7a5I7Hp++hsVxbQ4BYO7hU=\ndmitri.shuralyov.com/gpu/mtl v0.0.0-20201218220906-28db891af037/go.mod h1:H6x//7gZCb22OMCxBHrMx7a5I7Hp++hsVxbQ4BYO7hU=\ngioui.org v0.0.0-20210308172011-57750fc8a0a6/go.mod h1:RSH6KIUZ0p2xy5zHDxgAM4zumjgTw83q2ge/PI+yyw8=\ngithub.com/AlecAivazis/survey/v2 v2.2.9 h1:LWvJtUswz/W9/zVVXELrmlvdwWcKE60ZAw0FWV9vssk=\ngithub.com/AlecAivazis/survey/v2 v2.2.9/go.mod h1:9DYvHgXtiXm6nCn+jXnOXLKbH+Yo9u8fAS/SduGdoPk=\ngithub.com/Azure/azure-pipeline-go v0.2.3 h1:7U9HBg1JFK3jHl5qmo4CTZKFTVgMwdFHMVtCdfBE21U=\ngithub.com/Azure/azure-pipeline-go v0.2.3/go.mod h1:x841ezTBIMG6O3lAcl8ATHnsOPVl2bqk7S3ta6S6u4k=\ngithub.com/Azure/azure-sdk-for-go v52.5.0+incompatible h1:/NLBWHCnIHtZyLPc1P7WIqi4Te4CC23kIQyK3Ep/7lA=\ngithub.com/Azure/azure-sdk-for-go v52.5.0+incompatible/go.mod h1:9XXNKU+eRnpl9moKnB4QOLf1HestfXbmab5FXxiDBjc=\ngithub.com/Azure/azure-storage-blob-go v0.14.0 h1:1BCg74AmVdYwO3dlKwtFU1V0wU2PZdREkXvAmZJRUlM=\ngithub.com/Azure/azure-storage-blob-go v0.14.0/go.mod h1:SMqIBi+SuiQH32bvyjngEewEeXoPfKMgWlBDaYf6fck=\ngithub.com/Azure/go-ansiterm v0.0.0-20170929234023-d6e3b3328b78/go.mod h1:LmzpDX56iTiv29bbRTIsUNlaFfuhWRQBWjQdVyAevI8=\ngithub.com/Azure/go-autorest v14.2.0+incompatible h1:V5VMDjClD3GiElqLWO7mz2MxNAK/vTfRHdAubSIPRgs=\ngithub.com/Azure/go-autorest v14.2.0+incompatible/go.mod h1:r+4oMnoxhatjLLJ6zxSWATqVooLgysK6ZNox3g/xq24=\ngithub.com/Azure/go-autorest/autorest v0.9.0/go.mod h1:xyHB1BMZT0cuDHU7I0+g046+BFDTQ8rEZB0s4Yfa6bI=\ngithub.com/Azure/go-autorest/autorest v0.9.3/go.mod h1:GsRuLYvwzLjjjRoWEIyMUaYq8GNUx2nRB378IPt/1p0=\ngithub.com/Azure/go-autorest/autorest v0.10.1/go.mod h1:/FALq9T/kS7b5J5qsQ+RSTUdAmGFqi0vUdVNNx8q630=\ngithub.com/Azure/go-autorest/autorest v0.11.1/go.mod h1:JFgpikqFJ/MleTTxwepExTKnFUKKszPS8UavbQYUMuw=\ngithub.com/Azure/go-autorest/autorest v0.11.9/go.mod h1:eipySxLmqSyC5s5k1CLupqet0PSENBEDP93LQ9a8QYw=\ngithub.com/Azure/go-autorest/autorest v0.11.18 h1:90Y4srNYrwOtAgVo3ndrQkTYn6kf1Eg/AjTFJ8Is2aM=\ngithub.com/Azure/go-autorest/autorest v0.11.18/go.mod h1:dSiJPy22c3u0OtOKDNttNgqpNFY/GeWa7GH/Pz56QRA=\ngithub.com/Azure/go-autorest/autorest/adal v0.5.0/go.mod h1:8Z9fGy2MpX0PvDjB1pEgQTmVqjGhiHBW7RJJEciWzS0=\ngithub.com/Azure/go-autorest/autorest/adal v0.8.0/go.mod h1:Z6vX6WXXuyieHAXwMj0S6HY6e6wcHn37qQMBQlvY3lc=\ngithub.com/Azure/go-autorest/autorest/adal v0.8.1/go.mod h1:ZjhuQClTqx435SRJ2iMlOxPYt3d2C/T/7TiQCVZSn3Q=\ngithub.com/Azure/go-autorest/autorest/adal v0.8.2/go.mod h1:ZjhuQClTqx435SRJ2iMlOxPYt3d2C/T/7TiQCVZSn3Q=\ngithub.com/Azure/go-autorest/autorest/adal v0.8.3/go.mod h1:ZjhuQClTqx435SRJ2iMlOxPYt3d2C/T/7TiQCVZSn3Q=\ngithub.com/Azure/go-autorest/autorest/adal v0.9.0/go.mod h1:/c022QCutn2P7uY+/oQWWNcK9YU+MH96NgK+jErpbcg=\ngithub.com/Azure/go-autorest/autorest/adal v0.9.5/go.mod h1:B7KF7jKIeC9Mct5spmyCB/A8CG/sEz1vwIRGv/bbw7A=\ngithub.com/Azure/go-autorest/autorest/adal v0.9.13/go.mod h1:W/MM4U6nLxnIskrw4UwWzlHfGjwUS50aOsc/I3yuU8M=\ngithub.com/Azure/go-autorest/autorest/adal v0.9.23 h1:Yepx8CvFxwNKpH6ja7RZ+sKX+DWYNldbLiALMC3BTz8=\ngithub.com/Azure/go-autorest/autorest/adal v0.9.23/go.mod h1:5pcMqFkdPhviJdlEy3kC/v1ZLnQl0MH6XA5YCcMhy4c=\ngithub.com/Azure/go-autorest/autorest/azure/auth v0.4.2/go.mod h1:90gmfKdlmKgfjUpnCEpOJzsUEjrWDSLwHIG73tSXddM=\ngithub.com/Azure/go-autorest/autorest/azure/auth v0.5.3 h1:lZifaPRAk1bqg5vGqreL6F8uLC5V0fDpY8nFvc3boFc=\ngithub.com/Azure/go-autorest/autorest/azure/auth v0.5.3/go.mod h1:4bJZhUhcq8LB20TruwHbAQsmUs2Xh+QR7utuJpLXX3A=\ngithub.com/Azure/go-autorest/autorest/azure/cli v0.3.1/go.mod h1:ZG5p860J94/0kI9mNJVoIoLgXcirM2gF5i2kWloofxw=\ngithub.com/Azure/go-autorest/autorest/azure/cli v0.4.2 h1:dMOmEJfkLKW/7JsokJqkyoYSgmR08hi9KrhjZb+JALY=\ngithub.com/Azure/go-autorest/autorest/azure/cli v0.4.2/go.mod h1:7qkJkT+j6b+hIpzMOwPChJhTqS8VbsqqgULzMNRugoM=\ngithub.com/Azure/go-autorest/autorest/date v0.1.0/go.mod h1:plvfp3oPSKwf2DNjlBjWF/7vwR+cUD/ELuzDCXwHUVA=\ngithub.com/Azure/go-autorest/autorest/date v0.2.0/go.mod h1:vcORJHLJEh643/Ioh9+vPmf1Ij9AEBM5FuBIXLmIy0g=\ngithub.com/Azure/go-autorest/autorest/date v0.3.0 h1:7gUk1U5M/CQbp9WoqinNzJar+8KY+LPI6wiWrP/myHw=\ngithub.com/Azure/go-autorest/autorest/date v0.3.0/go.mod h1:BI0uouVdmngYNUzGWeSYnokU+TrmwEsOqdt8Y6sso74=\ngithub.com/Azure/go-autorest/autorest/mocks v0.1.0/go.mod h1:OTyCOPRA2IgIlWxVYxBee2F5Gr4kF2zd2J5cFRaIDN0=\ngithub.com/Azure/go-autorest/autorest/mocks v0.2.0/go.mod h1:OTyCOPRA2IgIlWxVYxBee2F5Gr4kF2zd2J5cFRaIDN0=\ngithub.com/Azure/go-autorest/autorest/mocks v0.3.0/go.mod h1:a8FDP3DYzQ4RYfVAxAN3SVSiiO77gL2j2ronKKP0syM=\ngithub.com/Azure/go-autorest/autorest/mocks v0.4.0/go.mod h1:LTp+uSrOhSkaKrUy935gNZuuIPPVsHlr9DSOxSayd+k=\ngithub.com/Azure/go-autorest/autorest/mocks v0.4.1 h1:K0laFcLE6VLTOwNgSxaGbUcLPuGXlNkbVvq4cW4nIHk=\ngithub.com/Azure/go-autorest/autorest/mocks v0.4.1/go.mod h1:LTp+uSrOhSkaKrUy935gNZuuIPPVsHlr9DSOxSayd+k=\ngithub.com/Azure/go-autorest/autorest/to v0.4.0 h1:oXVqrxakqqV1UZdSazDOPOLvOIz+XA683u8EctwboHk=\ngithub.com/Azure/go-autorest/autorest/to v0.4.0/go.mod h1:fE8iZBn7LQR7zH/9XU2NcPR4o9jEImooCeWJcYV/zLE=\ngithub.com/Azure/go-autorest/autorest/validation v0.3.1 h1:AgyqjAd94fwNAoTjl/WQXg4VvFeRFpO+UhNyRXqF1ac=\ngithub.com/Azure/go-autorest/autorest/validation v0.3.1/go.mod h1:yhLgjC0Wda5DYXl6JAsWyUe4KVNffhoDhG0zVzUMo3E=\ngithub.com/Azure/go-autorest/logger v0.1.0/go.mod h1:oExouG+K6PryycPJfVSxi/koC6LSNgds39diKLz7Vrc=\ngithub.com/Azure/go-autorest/logger v0.2.0/go.mod h1:T9E3cAhj2VqvPOtCYAvby9aBXkZmbF5NWuPV8+WeEW8=\ngithub.com/Azure/go-autorest/logger v0.2.1 h1:IG7i4p/mDa2Ce4TRyAO8IHnVhAVF3RFU+ZtXWSmf4Tg=\ngithub.com/Azure/go-autorest/logger v0.2.1/go.mod h1:T9E3cAhj2VqvPOtCYAvby9aBXkZmbF5NWuPV8+WeEW8=\ngithub.com/Azure/go-autorest/tracing v0.5.0/go.mod h1:r/s2XiOKccPW3HrqB+W0TQzfbtp2fGCgRFtBroKn4Dk=\ngithub.com/Azure/go-autorest/tracing v0.6.0 h1:TYi4+3m5t6K48TGI9AUdb+IzbnSxvnvUMfuitfgcfuo=\ngithub.com/Azure/go-autorest/tracing v0.6.0/go.mod h1:+vhtPC754Xsa23ID7GlGsrdKBpUA79WCAKPPZVC2DeU=\ngithub.com/BurntSushi/toml v0.3.1/go.mod h1:xHWCNGjB5oqiDr8zfno3MHue2Ht5sIBksp03qcyfWMU=\ngithub.com/BurntSushi/toml v1.2.1 h1:9F2/+DoOYIOksmaJFPw1tGFy1eDnIJXg+UHjuD8lTak=\ngithub.com/BurntSushi/toml v1.2.1/go.mod h1:CxXYINrC8qIiEnFrOxCa7Jy5BFHlXnUU2pbicEuybxQ=\ngithub.com/BurntSushi/xgb v0.0.0-20160522181843-27f122750802/go.mod h1:IVnqGOEym/WlBOVXweHU+Q+/VP0lqqI8lqeDx9IjBqo=\ngithub.com/DATA-DOG/go-sqlmock v1.3.3/go.mod h1:f/Ixk793poVmq4qj/V1dPUg2JEAKC73Q5eFN3EC/SaM=\ngithub.com/DATA-DOG/go-sqlmock v1.4.1 h1:ThlnYciV1iM/V0OSF/dtkqWb6xo5qITT1TJBG1MRDJM=\ngithub.com/DATA-DOG/go-sqlmock v1.4.1/go.mod h1:f/Ixk793poVmq4qj/V1dPUg2JEAKC73Q5eFN3EC/SaM=\ngithub.com/DataDog/datadog-go v3.2.0+incompatible/go.mod h1:LButxg5PwREeZtORoXG3tL4fMGNddJ+vMq1mwgfaqoQ=\ngithub.com/HdrHistogram/hdrhistogram-go v1.0.1/go.mod h1:BWJ+nMSHY3L41Zj7CA3uXnloDp7xxV0YvstAE7nKTaM=\ngithub.com/HdrHistogram/hdrhistogram-go v1.1.0 h1:6dpdDPTRoo78HxAJ6T1HfMiKSnqhgRRqzCuPshRkQ7I=\ngithub.com/HdrHistogram/hdrhistogram-go v1.1.0/go.mod h1:yDgFjdqOqDEKOvasDdhWNXYg9BVp4O+o5f6V/ehm6Oo=\ngithub.com/IBM/sarama v1.43.3 h1:Yj6L2IaNvb2mRBop39N7mmJAHBVY3dTPncr3qGVkxPA=\ngithub.com/IBM/sarama v1.43.3/go.mod h1:FVIRaLrhK3Cla/9FfRF5X9Zua2KpS3SYIXxhac1H+FQ=\ngithub.com/JohnCGriffin/overflow v0.0.0-20211019200055-46fa312c352c h1:RGWPOewvKIROun94nF7v2cua9qP+thov/7M50KEoeSU=\ngithub.com/JohnCGriffin/overflow v0.0.0-20211019200055-46fa312c352c/go.mod h1:X0CRv0ky0k6m906ixxpzmDRLvX58TFUKS2eePweuyxk=\ngithub.com/Knetic/govaluate v3.0.1-0.20171022003610-9aa49832a739+incompatible/go.mod h1:r7JcOSlj0wfOMncg0iLm8Leh48TZaKVeNIfJntJ2wa0=\ngithub.com/MakeNowJust/heredoc/v2 v2.0.1/go.mod h1:6/2Abh5s+hc3g9nbWLe9ObDIOhaRrqsyY9MWy+4JdRM=\ngithub.com/Masterminds/semver v1.4.2 h1:WBLTQ37jOCzSLtXNdoo8bNM8876KhNqOKvrlGITgsTc=\ngithub.com/Masterminds/semver v1.4.2/go.mod h1:MB6lktGJrhw8PrUyiEoblNEGEQ+RzHPF078ddwwvV3Y=\ngithub.com/Masterminds/sprig v2.16.0+incompatible h1:QZbMUPxRQ50EKAq3LFMnxddMu88/EUUG3qmxwtDmPsY=\ngithub.com/Masterminds/sprig v2.16.0+incompatible/go.mod h1:y6hNFY5UBTIWBxnzTeuNhlNS5hqE0NB0E6fgfo2Br3o=\ngithub.com/Microsoft/go-winio v0.4.11/go.mod h1:VhR8bwka0BXejwEJY73c50VrPtXAaKcyvVC4A4RozmA=\ngithub.com/Microsoft/go-winio v0.4.16 h1:FtSW/jqD+l4ba5iPBj9CODVtgfYAD8w2wS923g/cFDk=\ngithub.com/Microsoft/go-winio v0.4.16/go.mod h1:XB6nPKklQyQ7GC9LdcBEcBl8PF76WugXOPRXwdLnMv0=\ngithub.com/NYTimes/gziphandler v0.0.0-20170623195520-56545f4a5d46/go.mod h1:3wb06e3pkSAbeQ52E9H9iFoQsEEwGN64994WTCIhntQ=\ngithub.com/NYTimes/gziphandler v1.0.1 h1:iLrQrdwjDd52kHDA5op2UBJFjmOb9g+7scBan4RN8F0=\ngithub.com/NYTimes/gziphandler v1.0.1/go.mod h1:3wb06e3pkSAbeQ52E9H9iFoQsEEwGN64994WTCIhntQ=\ngithub.com/Netflix/go-expect v0.0.0-20180615182759-c93bf25de8e8 h1:xzYJEypr/85nBpB11F9br+3HUrpgb+fcm5iADzXXYEw=\ngithub.com/Netflix/go-expect v0.0.0-20180615182759-c93bf25de8e8/go.mod h1:oX5x61PbNXchhh0oikYAH+4Pcfw5LKv21+Jnpr6r6Pc=\ngithub.com/Nvveen/Gotty v0.0.0-20120604004816-cd527374f1e5/go.mod h1:lmUJ/7eu/Q8D7ML55dXQrVaamCz2vxCfdQBasLZfHKk=\ngithub.com/OneOfOne/xxhash v1.2.2 h1:KMrpdQIwFcEqXDklaen+P1axHaj9BSKzvpUUfnHldSE=\ngithub.com/OneOfOne/xxhash v1.2.2/go.mod h1:HSdplMjZKSmBqAxg5vPj2TmRDmfkzw+cTzAElWljhcU=\ngithub.com/PuerkitoBio/purell v1.1.0/go.mod h1:c11w/QuzBsJSee3cPx9rAFu61PvFxuPbtSwDGJws/X0=\ngithub.com/PuerkitoBio/purell v1.1.1/go.mod h1:c11w/QuzBsJSee3cPx9rAFu61PvFxuPbtSwDGJws/X0=\ngithub.com/PuerkitoBio/urlesc v0.0.0-20170810143723-de5bf2ad4578/go.mod h1:uGdkoq3SwY9Y+13GIhn11/XLaGBb4BfwItxLd5jeuXE=\ngithub.com/RoaringBitmap/roaring v0.4.16 h1:NholfewybRLOwACgfqfzn/N5xa6keKNs4fP00t0cwLo=\ngithub.com/RoaringBitmap/roaring v0.4.16/go.mod h1:8khRDP4HmeXns4xIj9oGrKSz7XTQiJx2zgh7AcNke4w=\ngithub.com/SAP/go-hdb v0.14.1 h1:hkw4ozGZ/i4eak7ZuGkY5e0hxiXFdNUBNhr4AvZVNFE=\ngithub.com/SAP/go-hdb v0.14.1/go.mod h1:7fdQLVC2lER3urZLjZCm0AuMQfApof92n3aylBPEkMo=\ngithub.com/Shopify/sarama v1.19.0/go.mod h1:FVkBWblsNy7DGZRfXLU0O9RCGt5g3g3yEuWXgklEdEo=\ngithub.com/Shopify/toxiproxy v2.1.4+incompatible/go.mod h1:OXgGpZ6Cli1/URJOF1DMxUHB2q5Ap20/P/eIdh4G0pI=\ngithub.com/VividCortex/gohistogram v1.0.0/go.mod h1:Pf5mBqqDxYaXu3hDrrU+w6nw50o/4+TcAqDqk/vUH7g=\ngithub.com/Waterdrips/jwt-go v3.2.1-0.20200915121943-f6506928b72e+incompatible h1:2v2bayIp0qe5893oRu3/jGHEPyc2mLCSYLeL3ecu4T0=\ngithub.com/Waterdrips/jwt-go v3.2.1-0.20200915121943-f6506928b72e+incompatible/go.mod h1:wk3RCbTKyKexJpL5CPBnS/xvNvTHGnpOLt1Qp48kCes=\ngithub.com/afex/hystrix-go v0.0.0-20180502004556-fa1af6a1f4f5/go.mod h1:SkGFH1ia65gfNATL8TAiHDNxPzPdmEL5uirI2Uyuz6c=\ngithub.com/agnivade/levenshtein v1.0.1/go.mod h1:CURSv5d9Uaml+FovSIICkLbAUZ9S4RqaHDIsdSBg7lM=\ngithub.com/ajstarks/svgo v0.0.0-20180226025133-644b8db467af/go.mod h1:K08gAheRH3/J6wwsYMMT4xOr94bZjxIelGM0+d/wbFw=\ngithub.com/alecthomas/template v0.0.0-20160405071501-a0175ee3bccc/go.mod h1:LOuyumcjzFXgccqObfd/Ljyb9UuFJ6TxHnclSeseNhc=\ngithub.com/alecthomas/template v0.0.0-20190718012654-fb15b899a751 h1:JYp7IbQjafoB+tBA3gMyHYHrpOtNuDiK/uB5uXxq5wM=\ngithub.com/alecthomas/template v0.0.0-20190718012654-fb15b899a751/go.mod h1:LOuyumcjzFXgccqObfd/Ljyb9UuFJ6TxHnclSeseNhc=\ngithub.com/alecthomas/units v0.0.0-20151022065526-2efee857e7cf/go.mod h1:ybxpYRFXyAe+OPACYpWeL0wqObRcbAqCMya13uyzqw0=\ngithub.com/alecthomas/units v0.0.0-20190717042225-c3de453c63f4/go.mod h1:ybxpYRFXyAe+OPACYpWeL0wqObRcbAqCMya13uyzqw0=\ngithub.com/alecthomas/units v0.0.0-20190924025748-f65c72e2690d/go.mod h1:rBZYJk541a8SKzHPHnH3zbiI+7dagKZ0cgpgrD7Fyho=\ngithub.com/alecthomas/units v0.0.0-20210208195552-ff826a37aa15 h1:AUNCr9CiJuwrRYS3XieqF+Z9B9gNxo/eANAJCF2eiN4=\ngithub.com/alecthomas/units v0.0.0-20210208195552-ff826a37aa15/go.mod h1:OMCwj8VM1Kc9e19TLln2VL61YJF0x1XFtfdL4JdbSyE=\ngithub.com/andreyvit/diff v0.0.0-20170406064948-c7f18ee00883 h1:bvNMNQO63//z+xNgfBlViaCIJKLlCJ6/fmUseuG0wVQ=\ngithub.com/andreyvit/diff v0.0.0-20170406064948-c7f18ee00883/go.mod h1:rCTlJbsFo29Kk6CurOXKm700vrz8f0KW0JNfpkRJY/8=\ngithub.com/andybalholm/brotli v1.0.3/go.mod h1:fO7iG3H7G2nSZ7m0zPUDn85XEX2GTukHGRSepvi9Eig=\ngithub.com/andybalholm/brotli v1.0.4 h1:V7DdXeJtZscaqfNuAdSRuRFzuiKlHSC/Zh3zl9qY3JY=\ngithub.com/andybalholm/brotli v1.0.4/go.mod h1:fO7iG3H7G2nSZ7m0zPUDn85XEX2GTukHGRSepvi9Eig=\ngithub.com/antihax/optional v1.0.0/go.mod h1:uupD/76wgC+ih3iEmQUL+0Ugr19nfwCT1kdvxnR2qWY=\ngithub.com/aokoli/goutils v1.0.1 h1:7fpzNGoJ3VA8qcrm++XEE1QUe0mIwNeLa02Nwq7RDkg=\ngithub.com/aokoli/goutils v1.0.1/go.mod h1:SijmP0QR8LtwsmDs8Yii5Z/S4trXFGFC2oO5g9DP+DQ=\ngithub.com/apache/arrow/go/arrow v0.0.0-20191024131854-af6fa24be0db/go.mod h1:VTxUBvSJ3s3eHAg65PNgrsn5BtqCRPdmyXh6rAfdxN0=\ngithub.com/apache/arrow/go/arrow v0.0.0-20200923215132-ac86123a3f01/go.mod h1:QNYViu/X0HXDHw7m3KXzWSVXIbfUvJqBFe6Gj8/pYA0=\ngithub.com/apache/arrow/go/arrow v0.0.0-20211112161151-bc219186db40 h1:q4dksr6ICHXqG5hm0ZW5IHyeEJXoIJSOZeBLmWPNeIQ=\ngithub.com/apache/arrow/go/arrow v0.0.0-20211112161151-bc219186db40/go.mod h1:Q7yQnSMnLvcXlZ8RV+jwz/6y1rQTqbX6C82SndT52Zs=\ngithub.com/apache/arrow/go/v11 v11.0.0 h1:hqauxvFQxww+0mEU/2XHG6LT7eZternCZq+A5Yly2uM=\ngithub.com/apache/arrow/go/v11 v11.0.0/go.mod h1:Eg5OsL5H+e299f7u5ssuXsuHQVEGC4xei5aX110hRiI=\ngithub.com/apache/arrow/go/v7 v7.0.0 h1:3d+Qgwo/r75bNhC6N0MMzZXQhsOyB0TSn6wljfuBNWo=\ngithub.com/apache/arrow/go/v7 v7.0.0/go.mod h1:vG2y+fH8mEUcX29tM6hOULGE06/XqEI8sG5fANM6T5w=\ngithub.com/apache/thrift v0.12.0/go.mod h1:cp2SuWMxlEZw2r+iP2GNCdIi4C1qmUzdZFSVb+bacwQ=\ngithub.com/apache/thrift v0.13.0/go.mod h1:cp2SuWMxlEZw2r+iP2GNCdIi4C1qmUzdZFSVb+bacwQ=\ngithub.com/apache/thrift v0.15.0/go.mod h1:PHK3hniurgQaNMZYaCLEqXKsYK8upmhPbmdP2FXSqgU=\ngithub.com/apache/thrift v0.16.0 h1:qEy6UW60iVOlUy+b9ZR0d5WzUWYGOo4HfopoyBaNmoY=\ngithub.com/apache/thrift v0.16.0/go.mod h1:PHK3hniurgQaNMZYaCLEqXKsYK8upmhPbmdP2FXSqgU=\ngithub.com/armon/circbuf v0.0.0-20150827004946-bbbad097214e/go.mod h1:3U/XgcO3hCbHZ8TKRvWD2dDTCfh9M9ya+I9JpbB7O8o=\ngithub.com/armon/consul-api v0.0.0-20180202201655-eb2c6b5be1b6/go.mod h1:grANhF5doyWs3UAsr3K4I6qtAmlQcZDesFNEHPZAzj8=\ngithub.com/armon/go-metrics v0.0.0-20180917152333-f0300d1749da/go.mod h1:Q73ZrmVTwzkszR9V5SSuryQ31EELlFMUz1kKyl939pY=\ngithub.com/armon/go-metrics v0.3.6 h1:x/tmtOF9cDBoXH7XoAGOz2qqm1DknFD1590XmD/DUJ8=\ngithub.com/armon/go-metrics v0.3.6/go.mod h1:4O98XIr/9W0sxpJ8UaYkvjk10Iff7SnFrb4QAOwNTFc=\ngithub.com/armon/go-radix v0.0.0-20180808171621-7fddfc383310/go.mod h1:ufUuZ+zHj4x4TnLV4JWEpy2hxWSpsRywHrMgIH9cCH8=\ngithub.com/armon/go-radix v1.0.0/go.mod h1:ufUuZ+zHj4x4TnLV4JWEpy2hxWSpsRywHrMgIH9cCH8=\ngithub.com/aryann/difflib v0.0.0-20170710044230-e206f873d14a/go.mod h1:DAHtR1m6lCRdSC2Tm3DSWRPvIPr6xNKyeHdqDQSQT+A=\ngithub.com/asaskevich/govalidator v0.0.0-20180720115003-f9ffefc3facf/go.mod h1:lB+ZfQJz7igIIfQNfa7Ml4HSf2uFQQRzpGGRXenZAgY=\ngithub.com/asaskevich/govalidator v0.0.0-20190424111038-f61b66f89f4a/go.mod h1:lB+ZfQJz7igIIfQNfa7Ml4HSf2uFQQRzpGGRXenZAgY=\ngithub.com/asaskevich/govalidator v0.0.0-20200108200545-475eaeb16496/go.mod h1:oGkLhpf+kjZl6xBf758TQhh5XrAeiJv/7FRz/2spLIg=\ngithub.com/asaskevich/govalidator v0.0.0-20200428143746-21a406dcc535/go.mod h1:oGkLhpf+kjZl6xBf758TQhh5XrAeiJv/7FRz/2spLIg=\ngithub.com/asaskevich/govalidator v0.0.0-20200907205600-7a23bdc65eef h1:46PFijGLmAjMPwCCCo7Jf0W6f9slllCkkv7vyc1yOSg=\ngithub.com/asaskevich/govalidator v0.0.0-20200907205600-7a23bdc65eef/go.mod h1:WaHUgvxTVq04UNunO+XhnAqY/wQc+bxr74GqbsZ/Jqw=\ngithub.com/aws/aws-lambda-go v1.13.3/go.mod h1:4UKl9IzQMoD+QF79YdCuzCwp8VbmG4VAQwij/eHl5CU=\ngithub.com/aws/aws-sdk-go v1.27.0/go.mod h1:KmX6BPdI08NWTb3/sm4ZGu5ShLoqVDhKgpiN924inxo=\ngithub.com/aws/aws-sdk-go v1.29.16/go.mod h1:1KvfttTE3SPKMpo8g2c6jL3ZKfXtFvKscTgahTma5Xg=\ngithub.com/aws/aws-sdk-go v1.34.28/go.mod h1:H7NKnBqNVzoTJpGfLrQkkD+ytBA93eiDYi/+8rV9s48=\ngithub.com/aws/aws-sdk-go v1.37.32/go.mod h1:hcU610XS61/+aQV88ixoOzUoG7v3b31pl2zKMmprdro=\ngithub.com/aws/aws-sdk-go v1.38.3/go.mod h1:hcU610XS61/+aQV88ixoOzUoG7v3b31pl2zKMmprdro=\ngithub.com/aws/aws-sdk-go v1.51.12 h1:DvuhIHZXwnjaR1/Gu19gUe1EGPw4J0qSJw4Qs/5PA8g=\ngithub.com/aws/aws-sdk-go v1.51.12/go.mod h1:LF8svs817+Nz+DmiMQKTO3ubZ/6IaTpq3TjupRn3Eqk=\ngithub.com/aws/aws-sdk-go-v2 v0.18.0/go.mod h1:JWVYvqSMppoMJC0x5wdwiImzgXTI9FuZwxzkQq9wy+g=\ngithub.com/aws/aws-sdk-go-v2 v1.11.0 h1:HxyD62DyNhCfiFGUHqJ/xITD6rAjJ7Dm/2nLxLmO4Ag=\ngithub.com/aws/aws-sdk-go-v2 v1.11.0/go.mod h1:SQfA+m2ltnu1cA0soUkj4dRSsmITiVQUJvBIZjzfPyQ=\ngithub.com/aws/aws-sdk-go-v2/aws/protocol/eventstream v1.0.0 h1:yVUAwvJC/0WNPbyl0nA3j1L6CW1CN8wBubCRqtG7JLI=\ngithub.com/aws/aws-sdk-go-v2/aws/protocol/eventstream v1.0.0/go.mod h1:Xn6sxgRuIDflLRJFj5Ev7UxABIkNbccFPV/p8itDReM=\ngithub.com/aws/aws-sdk-go-v2/config v1.10.1 h1:z/ViqIjW6ZeuLWgTWMTSyZzaVWo/1cWeVf1Uu+RF01E=\ngithub.com/aws/aws-sdk-go-v2/config v1.10.1/go.mod h1:auIv5pIIn3jIBHNRcVQcsczn6Pfa6Dyv80Fai0ueoJU=\ngithub.com/aws/aws-sdk-go-v2/credentials v1.6.1 h1:A39JYth2fFCx+omN/gib/jIppx3rRnt2r7UKPq7Mh5Y=\ngithub.com/aws/aws-sdk-go-v2/credentials v1.6.1/go.mod h1:QyvQk1IYTqBWSi1T6UgT/W8DMxBVa5pVuLFSRLLhGf8=\ngithub.com/aws/aws-sdk-go-v2/feature/ec2/imds v1.8.0 h1:OpZjuUy8Jt3CA1WgJgBC5Bz+uOjE5Ppx4NFTRaooUuA=\ngithub.com/aws/aws-sdk-go-v2/feature/ec2/imds v1.8.0/go.mod h1:5E1J3/TTYy6z909QNR0QnXGBpfESYGDqd3O0zqONghU=\ngithub.com/aws/aws-sdk-go-v2/feature/s3/manager v1.7.1 h1:p9Dys1g2YdaqMalnp6AwCA+tpMMdJNGw5YYKP/u3sUk=\ngithub.com/aws/aws-sdk-go-v2/feature/s3/manager v1.7.1/go.mod h1:wN/mvkow08GauDwJ70jnzJ1e+hE+Q3Q7TwpYLXOe9oI=\ngithub.com/aws/aws-sdk-go-v2/internal/configsources v1.1.0 h1:zY8cNmbBXt3pzjgWgdIbzpQ6qxoCwt+Nx9JbrAf2mbY=\ngithub.com/aws/aws-sdk-go-v2/internal/configsources v1.1.0/go.mod h1:NO3Q5ZTTQtO2xIg2+xTXYDiT7knSejfeDm7WGDaOo0U=\ngithub.com/aws/aws-sdk-go-v2/internal/endpoints/v2 v2.0.0 h1:Z3aR/OXBnkYK9zXkNkfitHX6SmUBzSsx8VMHbH4Lvhw=\ngithub.com/aws/aws-sdk-go-v2/internal/endpoints/v2 v2.0.0/go.mod h1:anlUzBoEWglcUxUQwZA7HQOEVEnQALVZsizAapB2hq8=\ngithub.com/aws/aws-sdk-go-v2/internal/ini v1.3.0 h1:c10Z7fWxtJCoyc8rv06jdh9xrKnu7bAJiRaKWvTb2mU=\ngithub.com/aws/aws-sdk-go-v2/internal/ini v1.3.0/go.mod h1:6oXGy4GLpypD3uCh8wcqztigGgmhLToMfjavgh+VySg=\ngithub.com/aws/aws-sdk-go-v2/service/internal/accept-encoding v1.5.0 h1:lPLbw4Gn59uoKqvOfSnkJr54XWk5Ak1NK20ZEiSWb3U=\ngithub.com/aws/aws-sdk-go-v2/service/internal/accept-encoding v1.5.0/go.mod h1:80NaCIH9YU3rzTTs/J/ECATjXuRqzo/wB6ukO6MZ0XY=\ngithub.com/aws/aws-sdk-go-v2/service/internal/presigned-url v1.5.0 h1:qGZWS/WgiFY+Zgad2u0gwBHpJxz6Ne401JE7iQI1nKs=\ngithub.com/aws/aws-sdk-go-v2/service/internal/presigned-url v1.5.0/go.mod h1:Mq6AEc+oEjCUlBuLiK5YwW4shSOAKCQ3tXN0sQeYoBA=\ngithub.com/aws/aws-sdk-go-v2/service/internal/s3shared v1.9.0 h1:0BOlTqnNnrEO04oYKzDxMMe68t107pmIotn18HtVonY=\ngithub.com/aws/aws-sdk-go-v2/service/internal/s3shared v1.9.0/go.mod h1:xKCZ4YFSF2s4Hnb/J0TLeOsKuGzICzcElaOKNGrVnx4=\ngithub.com/aws/aws-sdk-go-v2/service/s3 v1.19.0 h1:5mRAms4TjSTOGYsqKYte5kHr1PzpMJSyLThjF3J+hw0=\ngithub.com/aws/aws-sdk-go-v2/service/s3 v1.19.0/go.mod h1:Gwz3aVctJe6mUY9T//bcALArPUaFmNAy2rTB9qN4No8=\ngithub.com/aws/aws-sdk-go-v2/service/sso v1.6.0 h1:JDgKIUZOmLFu/Rv6zXLrVTWCmzA0jcTdvsT8iFIKrAI=\ngithub.com/aws/aws-sdk-go-v2/service/sso v1.6.0/go.mod h1:Q/l0ON1annSU+mc0JybDy1Gy6dnJxIcWjphO6qJPzvM=\ngithub.com/aws/aws-sdk-go-v2/service/sts v1.10.0 h1:1jh8J+JjYRp+QWKOsaZt7rGUgoyrqiiVwIm+w0ymeUw=\ngithub.com/aws/aws-sdk-go-v2/service/sts v1.10.0/go.mod h1:jLKCFqS+1T4i7HDqCP9GM4Uk75YW1cS0o82LdxpMyOE=\ngithub.com/aws/smithy-go v1.9.0 h1:c7FUdEqrQA1/UVKKCNDFQPNKGp4FQg3YW4Ck5SLTG58=\ngithub.com/aws/smithy-go v1.9.0/go.mod h1:SObp3lf9smib00L/v3U2eAKG8FyQ7iLrJnQiAmR5n+E=\ngithub.com/benbjohnson/clock v0.0.0-20161215174838-7dc76406b6d3/go.mod h1:UMqtWQTnOe4byzwe7Zhwh8f8s+36uszN51sJrSIZlTE=\ngithub.com/benbjohnson/clock v1.1.0 h1:Q92kusRqC1XV2MjkWETPvjJVqKetz1OzxZB7mHJLju8=\ngithub.com/benbjohnson/clock v1.1.0/go.mod h1:J11/hYXuz8f4ySSvYwY0FKfm+ezbsZBKZxNJlLklBHA=\ngithub.com/benbjohnson/immutable v0.2.1/go.mod h1:uc6OHo6PN2++n98KHLxW8ef4W42ylHiQSENghE1ezxI=\ngithub.com/benbjohnson/immutable v0.3.0 h1:TVRhuZx2wG9SZ0LRdqlbs9S5BZ6Y24hJEHTCgWHZEIw=\ngithub.com/benbjohnson/immutable v0.3.0/go.mod h1:uc6OHo6PN2++n98KHLxW8ef4W42ylHiQSENghE1ezxI=\ngithub.com/benbjohnson/tmpl v1.0.0 h1:T5QPGJD0W6JJxyEEAlVnX3co/IkUrfHen1/42nlgAHo=\ngithub.com/benbjohnson/tmpl v1.0.0/go.mod h1:igT620JFIi44B6awvU9IsDhR77IXWtFigTLil/RPdps=\ngithub.com/beorn7/perks v0.0.0-20180321164747-3a771d992973/go.mod h1:Dwedo/Wpr24TaqPxmxbtue+5NUziq4I4S80YR8gNf3Q=\ngithub.com/beorn7/perks v1.0.0/go.mod h1:KWe93zE9D1o94FZ5RNwFwVgaQK1VOXiVxmqh+CedLV8=\ngithub.com/beorn7/perks v1.0.1 h1:VlbKKnNfV8bJzeqoa4cOKqO6bYr3WgKZxO8Z16+hsOM=\ngithub.com/beorn7/perks v1.0.1/go.mod h1:G2ZrVWU2WbWT9wwq4/hrbKbnv/1ERSJQ0ibhJ6rlkpw=\ngithub.com/bgentry/speakeasy v0.1.0/go.mod h1:+zsyZBPWlz7T6j88CTgSN5bM796AkVf0kBD4zp0CCIs=\ngithub.com/bmizerany/pat v0.0.0-20170815010413-6226ea591a40 h1:y4B3+GPxKlrigF1ha5FFErxK+sr6sWxQovRMzwMhejo=\ngithub.com/bmizerany/pat v0.0.0-20170815010413-6226ea591a40/go.mod h1:8rLXio+WjiTceGBHIoTvn60HIbs7Hm7bcHjyrSqYB9c=\ngithub.com/boltdb/bolt v1.3.1 h1:JQmyP4ZBrce+ZQu0dY660FMfatumYDLun9hBCUVIkF4=\ngithub.com/boltdb/bolt v1.3.1/go.mod h1:clJnj/oiGkjum5o1McbSZDSLxVThjynRyGBgiAx27Ps=\ngithub.com/bonitoo-io/go-sql-bigquery v0.3.4-1.4.0 h1:MaVh0h9+KaMnJcoDvvIGp+O3fefdWm+8MBUX6ELTJTM=\ngithub.com/bonitoo-io/go-sql-bigquery v0.3.4-1.4.0/go.mod h1:J4Y6YJm0qTWB9aFziB7cPeSyc6dOZFyJdteSeybVpXQ=\ngithub.com/boombuler/barcode v1.0.0/go.mod h1:paBWMcWSl3LHKBqUq+rly7CNSldXjb2rDl3JlRe0mD8=\ngithub.com/bouk/httprouter v0.0.0-20160817010721-ee8b3818a7f5 h1:kS0dw4K730x7cxT+bVyTyYJZHuSoH7ofSr/Ijit56Qw=\ngithub.com/bouk/httprouter v0.0.0-20160817010721-ee8b3818a7f5/go.mod h1:CDReaxg1cmLrtcasZy43l4EYPAknXLiQSrb7tLw5zXM=\ngithub.com/buger/jsonparser v0.0.0-20191004114745-ee4c978eae7e/go.mod h1:errmMKH8tTB49UR2A8C8DPYkyudelsYJwJFaZHQ6ik8=\ngithub.com/c-bata/go-prompt v0.2.2 h1:uyKRz6Z6DUyj49QVijyM339UJV9yhbr70gESwbNU3e0=\ngithub.com/c-bata/go-prompt v0.2.2/go.mod h1:VzqtzE2ksDBcdln8G7mk2RX9QyGjH+OVqOCSiVIqS34=\ngithub.com/cactus/go-statsd-client/statsd v0.0.0-20191106001114-12b4e2b38748/go.mod h1:l/bIBLeOl9eX+wxJAzxS4TveKRtAqlyDpHjhkfO0MEI=\ngithub.com/cactus/go-statsd-client/statsd v0.0.0-20200423205355-cb0885a1018c/go.mod h1:l/bIBLeOl9eX+wxJAzxS4TveKRtAqlyDpHjhkfO0MEI=\ngithub.com/casbin/casbin/v2 v2.1.2/go.mod h1:YcPU1XXisHhLzuxH9coDNf2FbKpjGlbCg3n9yuLkIJQ=\ngithub.com/cenkalti/backoff v2.2.1+incompatible h1:tNowT99t7UNflLxfYYSlKYsBpXdEet03Pg2g16Swow4=\ngithub.com/cenkalti/backoff v2.2.1+incompatible/go.mod h1:90ReRw6GdpyfrHakVjL/QHaoyV4aDUVVkXQJJJ3NXXM=\ngithub.com/cenkalti/backoff/v4 v4.0.2/go.mod h1:eEew/i+1Q6OrCDZh3WiXYv3+nJwBASZ8Bog/87DQnVg=\ngithub.com/census-instrumentation/opencensus-proto v0.2.1/go.mod h1:f6KPmirojxKA12rnyqOA5BBL4O983OfeGPqjHWSTneU=\ngithub.com/cespare/xxhash v1.1.0 h1:a6HrQnmkObjyL+Gs60czilIUGqrzKutQD6XZog3p+ko=\ngithub.com/cespare/xxhash v1.1.0/go.mod h1:XrSqR1VqqWfGrhpAt58auRo0WTKS1nRRg3ghfAqPWnc=\ngithub.com/cespare/xxhash/v2 v2.1.1/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/cespare/xxhash/v2 v2.2.0 h1:DC2CZ1Ep5Y4k3ZQ899DldepgrayRUGE6BBZ/cd9Cj44=\ngithub.com/cespare/xxhash/v2 v2.2.0/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/chzyer/logex v1.1.10/go.mod h1:+Ywpsq7O8HXn0nuIou7OrIPyXbp3wmkHB+jjWRnGsAI=\ngithub.com/chzyer/readline v0.0.0-20180603132655-2972be24d48e/go.mod h1:nSuG5e5PlCu98SY8svDHJxuZscDgtXS6KTTbou5AhLI=\ngithub.com/chzyer/test v0.0.0-20180213035817-a1ea475d72b1/go.mod h1:Q3SI9o4m/ZMnBNeIyt5eFwwo7qiLfzFZmjNmxjkiQlU=\ngithub.com/circonus-labs/circonus-gometrics v2.3.1+incompatible/go.mod h1:nmEj6Dob7S7YxXgwXpfOuvO54S+tGdZdw9fuRZt25Ag=\ngithub.com/circonus-labs/circonusllhist v0.1.3/go.mod h1:kMXHVDlOchFAehlya5ePtbp5jckzBHf4XRpQvBOLI+I=\ngithub.com/clbanning/x2j v0.0.0-20191024224557-825249438eec/go.mod h1:jMjuTZXRI4dUb/I5gc9Hdhagfvm9+RyrPryS/auMzxE=\ngithub.com/client9/misspell v0.3.4/go.mod h1:qj6jICC3Q7zFZvVWo7KLAzC3yx5G7kyvSDkc90ppPyw=\ngithub.com/cncf/udpa/go v0.0.0-20191209042840-269d4d468f6f/go.mod h1:M8M6+tZqaGXZJjfX53e64911xZQV5JYwmTeXPW+k8Sc=\ngithub.com/cncf/udpa/go v0.0.0-20200629203442-efcf912fb354/go.mod h1:WmhPx2Nbnhtbo57+VJT5O0JRkEi1Wbu0z5j0R8u5Hbk=\ngithub.com/cncf/udpa/go v0.0.0-20201120205902-5459f2c99403/go.mod h1:WmhPx2Nbnhtbo57+VJT5O0JRkEi1Wbu0z5j0R8u5Hbk=\ngithub.com/cncf/xds/go v0.0.0-20210312221358-fbca930ec8ed/go.mod h1:eXthEFrGJvWHgFFCl3hGmgk+/aYT6PnTQLykKQRLhEs=\ngithub.com/cncf/xds/go v0.0.0-20210805033703-aa0b78936158/go.mod h1:eXthEFrGJvWHgFFCl3hGmgk+/aYT6PnTQLykKQRLhEs=\ngithub.com/cockroachdb/datadriven v0.0.0-20190809214429-80d97fb3cbaa/go.mod h1:zn76sxSg3SzpJ0PPJaLDCu+Bu0Lg3sKTORVIj19EIF8=\ngithub.com/codahale/hdrhistogram v0.0.0-20161010025455-3a0bb77429bd/go.mod h1:sE/e/2PUdi/liOCUjSTXgM1o87ZssimdTWN964YiIeI=\ngithub.com/containerd/containerd v1.4.3/go.mod h1:bC6axHOhabU15QhwfG7w5PipXdVtMXFTttgp+kVtyUA=\ngithub.com/coreos/bbolt v1.3.2/go.mod h1:iRUV2dpdMOn7Bo10OQBFzIJO9kkE559Wcmn+qkEiiKk=\ngithub.com/coreos/etcd v3.3.10+incompatible/go.mod h1:uF7uidLiAD3TWHmW31ZFd/JWoc32PjwdhPthX9715RE=\ngithub.com/coreos/go-etcd v2.0.0+incompatible/go.mod h1:Jez6KQU2B/sWsbdaef3ED8NzMklzPG4d5KIOhIy30Tk=\ngithub.com/coreos/go-semver v0.2.0/go.mod h1:nnelYz7RCh+5ahJtPPxZlU+153eP4D4r3EedlOD2RNk=\ngithub.com/coreos/go-systemd v0.0.0-20180511133405-39ca1b05acc7/go.mod h1:F5haX7vjVVG0kc13fIWeqUViNPyEJxv/OmvnBo0Yme4=\ngithub.com/coreos/go-systemd v0.0.0-20190321100706-95778dfbb74e/go.mod h1:F5haX7vjVVG0kc13fIWeqUViNPyEJxv/OmvnBo0Yme4=\ngithub.com/coreos/pkg v0.0.0-20160727233714-3ac0863d7acf/go.mod h1:E3G3o1h8I7cfcXa63jLwjI0eiQQMgzzUDFVpN/nH/eA=\ngithub.com/coreos/pkg v0.0.0-20180928190104-399ea9e2e55f/go.mod h1:E3G3o1h8I7cfcXa63jLwjI0eiQQMgzzUDFVpN/nH/eA=\ngithub.com/cpuguy83/go-md2man v1.0.10/go.mod h1:SmD6nW6nTyfqj6ABTjUi3V3JVMnlJmwcJI5acqYI6dE=\ngithub.com/cpuguy83/go-md2man/v2 v2.0.0-20190314233015-f79a8a8ca69d/go.mod h1:maD7wRr/U5Z6m/iR4s+kqSMx2CaBsrgA7czyZG/E6dU=\ngithub.com/cpuguy83/go-md2man/v2 v2.0.0 h1:EoUDS0afbrsXAZ9YQ9jdu/mZ2sXgT1/2yyNng4PGlyM=\ngithub.com/cpuguy83/go-md2man/v2 v2.0.0/go.mod h1:maD7wRr/U5Z6m/iR4s+kqSMx2CaBsrgA7czyZG/E6dU=\ngithub.com/creack/pty v1.1.7/go.mod h1:lj5s0c3V2DBrqTV7llrYr5NG6My20zk30Fl46Y7DoTY=\ngithub.com/creack/pty v1.1.9/go.mod h1:oKZEueFk5CKHvIhNR5MUki03XCEU+Q6VDXinZuGJ33E=\ngithub.com/creack/pty v1.1.11/go.mod h1:oKZEueFk5CKHvIhNR5MUki03XCEU+Q6VDXinZuGJ33E=\ngithub.com/cyberdelia/templates v0.0.0-20141128023046-ca7fffd4298c/go.mod h1:GyV+0YP4qX0UQ7r2MoYZ+AvYDp12OF5yg4q8rGnyNh4=\ngithub.com/daixiang0/gci v0.2.8/go.mod h1:+4dZ7TISfSmqfAGv59ePaHfNzgGtIkHAhhdKggP1JAc=\ngithub.com/dave/jennifer v1.2.0/go.mod h1:fIb+770HOpJ2fmN9EPPKOqm1vMGhB+TwXKMZhrIygKg=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/deepmap/oapi-codegen v1.6.0 h1:w/d1ntwh91XI0b/8ja7+u5SvA4IFfM0UNNLmiDR1gg0=\ngithub.com/deepmap/oapi-codegen v1.6.0/go.mod h1:ryDa9AgbELGeB+YEXE1dR53yAjHwFvE9iAUlWl9Al3M=\ngithub.com/denisenkom/go-mssqldb v0.10.0 h1:QykgLZBorFE95+gO3u9esLd0BmbvpWp0/waNNZfHBM8=\ngithub.com/denisenkom/go-mssqldb v0.10.0/go.mod h1:xbL0rPBG9cCiLr28tMa8zpbdarY27NDyej4t/EjAShU=\ngithub.com/dgryski/go-bitstream v0.0.0-20180413035011-3522498ce2c8 h1:akOQj8IVgoeFfBTzGOEQakCYshWD6RNo1M5pivFXt70=\ngithub.com/dgryski/go-bitstream v0.0.0-20180413035011-3522498ce2c8/go.mod h1:VMaSuZ+SZcx/wljOQKvp5srsbCiKDEb6K2wC4+PiBmQ=\ngithub.com/dgryski/go-sip13 v0.0.0-20181026042036-e10d5fee7954/go.mod h1:vAd38F8PWV+bWy6jNmig1y/TA+kYO4g3RSRF0IAv0no=\ngithub.com/dgryski/go-sip13 v0.0.0-20200911182023-62edffca9245/go.mod h1:vAd38F8PWV+bWy6jNmig1y/TA+kYO4g3RSRF0IAv0no=\ngithub.com/digitalocean/godo v1.58.0 h1:Iy8ULTvgCAxH8dlxZ54qRYpm5uTEb2deUqijywLH7Lo=\ngithub.com/digitalocean/godo v1.58.0/go.mod h1:p7dOjjtSBqCTUksqtA5Fd3uaKs9kyTq2xcz76ulEJRU=\ngithub.com/dimchansky/utfbom v1.1.0 h1:FcM3g+nofKgUteL8dm/UpdRXNC9KmADgTpLKsu0TRo4=\ngithub.com/dimchansky/utfbom v1.1.0/go.mod h1:rO41eb7gLfo8SF1jd9F8HplJm1Fewwi4mQvIirEdv+8=\ngithub.com/dnaeon/go-vcr v1.0.1/go.mod h1:aBB1+wY4s93YsC3HHjMBMrwTj2R9FHDzUr9KyGc8n1E=\ngithub.com/docker/distribution v2.7.0+incompatible/go.mod h1:J2gT2udsDAN96Uj4KfcMRqY0/ypR+oyYUYmja8H+y+w=\ngithub.com/docker/distribution v2.7.1+incompatible h1:a5mlkVzth6W5A4fOsS3D2EO5BUmsJpcB+cRlLU7cSug=\ngithub.com/docker/distribution v2.7.1+incompatible/go.mod h1:J2gT2udsDAN96Uj4KfcMRqY0/ypR+oyYUYmja8H+y+w=\ngithub.com/docker/docker v0.7.3-0.20180815000130-e05b657120a6/go.mod h1:eEKB0N0r5NX/I1kEveEz05bcu8tLC/8azJZsviup8Sk=\ngithub.com/docker/docker v1.13.1/go.mod h1:eEKB0N0r5NX/I1kEveEz05bcu8tLC/8azJZsviup8Sk=\ngithub.com/docker/docker v20.10.5+incompatible/go.mod h1:eEKB0N0r5NX/I1kEveEz05bcu8tLC/8azJZsviup8Sk=\ngithub.com/docker/docker v24.0.9+incompatible h1:HPGzNmwfLZWdxHqK9/II92pyi1EpYKsAqcl4G0Of9v0=\ngithub.com/docker/docker v24.0.9+incompatible/go.mod h1:eEKB0N0r5NX/I1kEveEz05bcu8tLC/8azJZsviup8Sk=\ngithub.com/docker/go-connections v0.4.0 h1:El9xVISelRB7BuFusrZozjnkIM5YnzCViNKohAFqRJQ=\ngithub.com/docker/go-connections v0.4.0/go.mod h1:Gbd7IOopHjR8Iph03tsViu4nIes5XhDvyHbTtUxmeec=\ngithub.com/docker/go-units v0.3.3/go.mod h1:fgPhTUdO+D/Jk86RDLlptpiXQzgHJF7gydDDbaIK4Dk=\ngithub.com/docker/go-units v0.4.0 h1:3uh0PgVws3nIA0Q+MwDC8yjEPf9zjRfZZWXZYDct3Tw=\ngithub.com/docker/go-units v0.4.0/go.mod h1:fgPhTUdO+D/Jk86RDLlptpiXQzgHJF7gydDDbaIK4Dk=\ngithub.com/docker/spdystream v0.0.0-20160310174837-449fdfce4d96/go.mod h1:Qh8CwZgvJUkLughtfhJv5dyTYa91l1fOUCrgjqmcifM=\ngithub.com/docopt/docopt-go v0.0.0-20180111231733-ee0de3bc6815/go.mod h1:WwZ+bS3ebgob9U8Nd0kOddGdZWjyMGR8Wziv+TBNwSE=\ngithub.com/dustin/go-humanize v0.0.0-20171111073723-bb3d318650d4/go.mod h1:HtrtbFcZ19U5GC7JDqmcUSB87Iq5E25KnS6fMYU6eOk=\ngithub.com/dustin/go-humanize v1.0.0 h1:VSnTsYCnlFHaM2/igO1h6X3HA71jcobQuxemgkq4zYo=\ngithub.com/dustin/go-humanize v1.0.0/go.mod h1:HtrtbFcZ19U5GC7JDqmcUSB87Iq5E25KnS6fMYU6eOk=\ngithub.com/eapache/go-resiliency v1.1.0/go.mod h1:kFI+JgMyC7bLPUVY133qvEBtVayf5mFgVsvEsIPBvNs=\ngithub.com/eapache/go-resiliency v1.7.0 h1:n3NRTnBn5N0Cbi/IeOHuQn9s2UwVUH7Ga0ZWcP+9JTA=\ngithub.com/eapache/go-resiliency v1.7.0/go.mod h1:5yPzW0MIvSe0JDsv0v+DvcjEv2FyD6iZYSs1ZI+iQho=\ngithub.com/eapache/go-xerial-snappy v0.0.0-20180814174437-776d5712da21/go.mod h1:+020luEh2TKB4/GOp8oxxtq0Daoen/Cii55CzbTV6DU=\ngithub.com/eapache/go-xerial-snappy v0.0.0-20230731223053-c322873962e3 h1:Oy0F4ALJ04o5Qqpdz8XLIpNA3WM/iSIXqxtqo7UGVws=\ngithub.com/eapache/go-xerial-snappy v0.0.0-20230731223053-c322873962e3/go.mod h1:YvSRo5mw33fLEx1+DlK6L2VV43tJt5Eyel9n9XBcR+0=\ngithub.com/eapache/queue v1.1.0 h1:YOEu7KNc61ntiQlcEeUIoDTJ2o8mQznoNvUhiigpIqc=\ngithub.com/eapache/queue v1.1.0/go.mod h1:6eCeP0CKFpHLu8blIFXhExK/dRa7WDZfr6jVFPTqq+I=\ngithub.com/eclipse/paho.mqtt.golang v1.2.0 h1:1F8mhG9+aO5/xpdtFkW4SxOJB67ukuDC3t2y2qayIX0=\ngithub.com/eclipse/paho.mqtt.golang v1.2.0/go.mod h1:H9keYFcgq3Qr5OUJm/JZI/i6U7joQ8SYLhZwfeOo6Ts=\ngithub.com/editorconfig-checker/editorconfig-checker v0.0.0-20190819115812-1474bdeaf2a2 h1:BoejGRtu+FygJB/0ZpkhTSmaM7QbsPxFgcspAbTElNI=\ngithub.com/editorconfig-checker/editorconfig-checker v0.0.0-20190819115812-1474bdeaf2a2/go.mod h1:nnr6DXFepwb2+GC7evku5Mak3wGGRShiYy6fPkdIwVM=\ngithub.com/editorconfig/editorconfig-core-go/v2 v2.1.1 h1:mhPg/0hGebcpiiQLqJD2PWWyoHRLEdZ3sXKaEvT1EQU=\ngithub.com/editorconfig/editorconfig-core-go/v2 v2.1.1/go.mod h1:/LuhWJiQ9Gvo1DhVpa4ssm5qeg8rrztdtI7j/iCie2k=\ngithub.com/edsrzf/mmap-go v1.0.0/go.mod h1:YO35OhQPt3KJa3ryjFM5Bs14WD66h8eGKpfaBNrHW5M=\ngithub.com/elazarl/go-bindata-assetfs v1.0.0 h1:G/bYguwHIzWq9ZoyUQqrjTmJbbYn3j3CKKpKinvZLFk=\ngithub.com/elazarl/go-bindata-assetfs v1.0.0/go.mod h1:v+YaWX3bdea5J/mo8dSETolEo7R71Vk1u8bnjau5yw4=\ngithub.com/elazarl/goproxy v0.0.0-20180725130230-947c36da3153/go.mod h1:/Zj4wYkgs4iZTTu3o/KG3Itv/qCCa8VVMlb3i9OVuzc=\ngithub.com/emicklei/go-restful v0.0.0-20170410110728-ff4f55a20633/go.mod h1:otzb+WCGbkyDHkqmQmT5YD2WR4BBwUdeQoFo8l/7tVs=\ngithub.com/envoyproxy/go-control-plane v0.6.9/go.mod h1:SBwIajubJHhxtWwsL9s8ss4safvEdbitLhGGK48rN6g=\ngithub.com/envoyproxy/go-control-plane v0.9.0/go.mod h1:YTl/9mNaCwkRvm6d1a2C3ymFceY/DCBVvsKhRF0iEA4=\ngithub.com/envoyproxy/go-control-plane v0.9.1-0.20191026205805-5f8ba28d4473/go.mod h1:YTl/9mNaCwkRvm6d1a2C3ymFceY/DCBVvsKhRF0iEA4=\ngithub.com/envoyproxy/go-control-plane v0.9.4/go.mod h1:6rpuAdCZL397s3pYoYcLgu1mIlRU8Am5FuJP05cCM98=\ngithub.com/envoyproxy/go-control-plane v0.9.7/go.mod h1:cwu0lG7PUMfa9snN8LXBig5ynNVH9qI8YYLbd1fK2po=\ngithub.com/envoyproxy/go-control-plane v0.9.9-0.20201210154907-fd9021fe5dad/go.mod h1:cXg6YxExXjJnVBQHBLXeUAgxn2UodCpnH306RInaBQk=\ngithub.com/envoyproxy/go-control-plane v0.9.9-0.20210217033140-668b12f5399d/go.mod h1:cXg6YxExXjJnVBQHBLXeUAgxn2UodCpnH306RInaBQk=\ngithub.com/envoyproxy/go-control-plane v0.9.9-0.20210512163311-63b5d3c536b0/go.mod h1:hliV/p42l8fGbc6Y9bQ70uLwIvmJyVE5k4iMKlh8wCQ=\ngithub.com/envoyproxy/go-control-plane v0.9.10-0.20210907150352-cf90f659a021/go.mod h1:AFq3mo9L8Lqqiid3OhADV3RfLJnjiw63cSpi+fDTRC0=\ngithub.com/envoyproxy/protoc-gen-validate v0.1.0/go.mod h1:iSmxcyjqTsJpI2R4NaDN7+kN2VEUnK/pcBlmesArF7c=\ngithub.com/evanphx/json-patch v4.9.0+incompatible h1:kLcOMZeuLAJvL2BPWLMIj5oaZQobrkAqrL+WFZwQses=\ngithub.com/evanphx/json-patch v4.9.0+incompatible/go.mod h1:50XU6AFN0ol/bzJsmQLiYLvXMP4fmwYFNcr97nuDLSk=\ngithub.com/fatih/color v1.7.0/go.mod h1:Zm6kSWBoL9eyXnKyktHP6abPY2pDugNf5KwzbycvMj4=\ngithub.com/fatih/color v1.9.0 h1:8xPHl4/q1VyqGIPif1F+1V3Y3lSmrq01EabUW3CoW5s=\ngithub.com/fatih/color v1.9.0/go.mod h1:eQcE1qtQxscV5RaZvpXrrb8Drkc3/DdQ+uUYCNjL+zU=\ngithub.com/fatih/structs v1.1.0/go.mod h1:9NiDSp5zOcgEDl+j00MP/WkGVPOlPRLejGD8Ga6PJ7M=\ngithub.com/fogleman/gg v1.2.1-0.20190220221249-0403632d5b90/go.mod h1:R/bRT+9gY/C5z7JzPU0zXsXHKM4/ayA+zqcVNZzPa1k=\ngithub.com/fogleman/gg v1.3.0/go.mod h1:R/bRT+9gY/C5z7JzPU0zXsXHKM4/ayA+zqcVNZzPa1k=\ngithub.com/form3tech-oss/jwt-go v3.2.2+incompatible/go.mod h1:pbq4aXjuKjdthFRnoDwaVPLA+WlJuPGy+QneDUgJi2k=\ngithub.com/form3tech-oss/jwt-go v3.2.5+incompatible h1:/l4kBbb4/vGSsdtB5nUe8L7B9mImVMaBPw9L/0TBHU8=\ngithub.com/form3tech-oss/jwt-go v3.2.5+incompatible/go.mod h1:pbq4aXjuKjdthFRnoDwaVPLA+WlJuPGy+QneDUgJi2k=\ngithub.com/fortytw2/leaktest v1.3.0 h1:u8491cBMTQ8ft8aeV+adlcytMZylmA5nnwwkRZjI8vw=\ngithub.com/fortytw2/leaktest v1.3.0/go.mod h1:jDsjWgpAGjm2CA7WthBh/CdZYEPF31XHquHwclZch5g=\ngithub.com/foxcpp/go-mockdns v0.0.0-20201212160233-ede2f9158d15 h1:nLPjjvpUAODOR6vY/7o0hBIk8iTr19Fvmf8aFx/kC7A=\ngithub.com/foxcpp/go-mockdns v0.0.0-20201212160233-ede2f9158d15/go.mod h1:tPg4cp4nseejPd+UKxtCVQ2hUxNTZ7qQZJa7CLriIeo=\ngithub.com/franela/goblin v0.0.0-20200105215937-c9ffbefa60db/go.mod h1:7dvUGVsVBjqR7JHJk0brhHOZYGmfBYOrK0ZhYMEtBr4=\ngithub.com/franela/goreq v0.0.0-20171204163338-bcd34c9993f8/go.mod h1:ZhphrRTfi2rbfLwlschooIH4+wKKDR4Pdxhh+TRoA20=\ngithub.com/fsnotify/fsnotify v1.4.2/go.mod h1:jwhsz4b93w/PPRr/qN1Yymfu8t87LnFCMoQvtojpjFo=\ngithub.com/fsnotify/fsnotify v1.4.7/go.mod h1:jwhsz4b93w/PPRr/qN1Yymfu8t87LnFCMoQvtojpjFo=\ngithub.com/fsnotify/fsnotify v1.4.9 h1:hsms1Qyu0jgnwNXIxa+/V/PDsU6CfLf6CNO8H7IWoS4=\ngithub.com/fsnotify/fsnotify v1.4.9/go.mod h1:znqG4EE+3YCdAaPaxE2ZRY/06pZUdp0tY4IgpuI1SZQ=\ngithub.com/fujiwara/shapeio v0.0.0-20170602072123-c073257dd745/go.mod h1:/WpqsrSkjgwEG2Es2qnZXbXwHDVbawpdlXJIjJMmnZs=\ngithub.com/fujiwara/shapeio v1.0.0/go.mod h1:LmEmu6L/8jetyj1oewewFb7bZCNRwE7wLCUNzDLaLVA=\ngithub.com/gabriel-vasile/mimetype v1.4.0 h1:Cn9dkdYsMIu56tGho+fqzh7XmvY2YyGU0FnbhiOsEro=\ngithub.com/gabriel-vasile/mimetype v1.4.0/go.mod h1:fA8fi6KUiG7MgQQ+mEWotXoEOvmxRtOJlERCzSmRvr8=\ngithub.com/geoffgarside/ber v0.0.0-20170306085127-854377f11dfb h1:iPZjQyOswR6paObEw+1XFfTV6isPKm3vWenA+6NF4AM=\ngithub.com/geoffgarside/ber v0.0.0-20170306085127-854377f11dfb/go.mod h1:x6zPZPDIQQKmaIDbeEzUGnxSmj7raqK6G8m6jkTlgbU=\ngithub.com/getkin/kin-openapi v0.2.0/go.mod h1:V1z9xl9oF5Wt7v32ne4FmiF1alpS4dM6mNzoywPOXlk=\ngithub.com/getkin/kin-openapi v0.53.0/go.mod h1:7Yn5whZr5kJi6t+kShccXS8ae1APpYTW6yheSwk8Yi4=\ngithub.com/ghodss/yaml v0.0.0-20150909031657-73d445a93680/go.mod h1:4dBDuWmgqj2HViK6kFavaiC9ZROes6MMH2rRYeMEF04=\ngithub.com/ghodss/yaml v1.0.0 h1:wQHKEahhL6wmXdzwWG11gIVCkOv05bNOh+Rxn0yngAk=\ngithub.com/ghodss/yaml v1.0.0/go.mod h1:4dBDuWmgqj2HViK6kFavaiC9ZROes6MMH2rRYeMEF04=\ngithub.com/globalsign/mgo v0.0.0-20180905125535-1ca0a4f7cbcb/go.mod h1:xkRDCp4j0OGD1HRkm4kmhM+pmpv3AKq5SU7GMg4oO/Q=\ngithub.com/globalsign/mgo v0.0.0-20181015135952-eeefdecb41b8/go.mod h1:xkRDCp4j0OGD1HRkm4kmhM+pmpv3AKq5SU7GMg4oO/Q=\ngithub.com/glycerine/go-unsnap-stream v0.0.0-20180323001048-9f0cb55181dd/go.mod h1:/20jfyN9Y5QPEAprSgKAUr+glWDY39ZiUEAYOEv5dsE=\ngithub.com/glycerine/go-unsnap-stream v0.0.0-20181221182339-f9677308dec2 h1:Ujru1hufTHVb++eG6OuNDKMxZnGIvF6o/u8q/8h2+I4=\ngithub.com/glycerine/go-unsnap-stream v0.0.0-20181221182339-f9677308dec2/go.mod h1:/20jfyN9Y5QPEAprSgKAUr+glWDY39ZiUEAYOEv5dsE=\ngithub.com/glycerine/goconvey v0.0.0-20180728074245-46e3a41ad493/go.mod h1:Ogl1Tioa0aV7gstGFO7KhffUsb9M4ydbEbbxpcEDc24=\ngithub.com/glycerine/goconvey v0.0.0-20190410193231-58a59202ab31 h1:gclg6gY70GLy3PbkQ1AERPfmLMMagS60DKF78eWwLn8=\ngithub.com/glycerine/goconvey v0.0.0-20190410193231-58a59202ab31/go.mod h1:Ogl1Tioa0aV7gstGFO7KhffUsb9M4ydbEbbxpcEDc24=\ngithub.com/go-chi/chi v4.1.0+incompatible h1:ETj3cggsVIY2Xao5ExCu6YhEh5MD6JTfcBzS37R260w=\ngithub.com/go-chi/chi v4.1.0+incompatible/go.mod h1:eB3wogJHnLi3x/kFX2A+IbTBlXxmMeXJVKy9tTv1XzQ=\ngithub.com/go-chi/chi/v5 v5.0.0/go.mod h1:BBug9lr0cqtdAhsu6R4AAdvufI0/XBzAQSsUqJpoZOs=\ngithub.com/go-fonts/dejavu v0.1.0/go.mod h1:4Wt4I4OU2Nq9asgDCteaAaWZOV24E+0/Pwo0gppep4g=\ngithub.com/go-fonts/latin-modern v0.2.0/go.mod h1:rQVLdDMK+mK1xscDwsqM5J8U2jrRa3T0ecnM9pNujks=\ngithub.com/go-fonts/liberation v0.1.1/go.mod h1:K6qoJYypsmfVjWg8KOVDQhLc8UDgIK2HYqyqAO9z7GY=\ngithub.com/go-fonts/stix v0.1.0/go.mod h1:w/c1f0ldAUlJmLBvlbkvVXLAD+tAMqobIIQpmnUIzUY=\ngithub.com/go-gl/glfw v0.0.0-20190409004039-e6da0acd62b1/go.mod h1:vR7hzQXu2zJy9AVAgeJqvqgH9Q5CA+iKCZ2gyEVpxRU=\ngithub.com/go-gl/glfw/v3.3/glfw v0.0.0-20191125211704-12ad95a8df72/go.mod h1:tQ2UAYgL5IevRw8kRxooKSPJfGvJ9fJQFa0TUsXzTg8=\ngithub.com/go-gl/glfw/v3.3/glfw v0.0.0-20200222043503-6f7a984d4dc4/go.mod h1:tQ2UAYgL5IevRw8kRxooKSPJfGvJ9fJQFa0TUsXzTg8=\ngithub.com/go-kit/kit v0.8.0/go.mod h1:xBxKIO96dXMWWy0MnWVtmwkA9/13aqxPnvrjFYMA2as=\ngithub.com/go-kit/kit v0.9.0/go.mod h1:xBxKIO96dXMWWy0MnWVtmwkA9/13aqxPnvrjFYMA2as=\ngithub.com/go-kit/kit v0.10.0 h1:dXFJfIHVvUcpSgDOV+Ne6t7jXri8Tfv2uOLHUZ2XNuo=\ngithub.com/go-kit/kit v0.10.0/go.mod h1:xUsJbQ/Fp4kEt7AFgCuvyX4a71u8h9jB8tj/ORgOZ7o=\ngithub.com/go-latex/latex v0.0.0-20210118124228-b3d85cf34e07/go.mod h1:CO1AlKB2CSIqUrmQPqA0gdRIlnLEY0gK5JGjh37zN5U=\ngithub.com/go-ldap/ldap v3.0.2+incompatible/go.mod h1:qfd9rJvER9Q0/D/Sqn1DfHRoBp40uXYvFoEVrNEPqRc=\ngithub.com/go-logfmt/logfmt v0.3.0/go.mod h1:Qt1PoO58o5twSAckw1HlFXLmHsOX5/0LbT9GBnD5lWE=\ngithub.com/go-logfmt/logfmt v0.4.0/go.mod h1:3RMwSq7FuexP4Kalkev3ejPJsZTpXXBr9+V4qmtdjCk=\ngithub.com/go-logfmt/logfmt v0.5.0 h1:TrB8swr/68K7m9CcGut2g3UOihhbcbiMAYiuTXdEih4=\ngithub.com/go-logfmt/logfmt v0.5.0/go.mod h1:wCYkCAKZfumFQihp8CzCvQ3paCTfi41vtzG1KdI/P7A=\ngithub.com/go-logr/logr v0.1.0/go.mod h1:ixOQHD9gLJUVQQ2ZOR7zLEifBX6tGkNJF4QyIY7sIas=\ngithub.com/go-logr/logr v0.2.0/go.mod h1:z6/tIYblkpsD+a4lm/fGIIU9mZ+XfAiaFtq7xTgseGU=\ngithub.com/go-logr/logr v0.4.0 h1:K7/B1jt6fIBQVd4Owv2MqGQClcgf0R266+7C/QjRcLc=\ngithub.com/go-logr/logr v0.4.0/go.mod h1:z6/tIYblkpsD+a4lm/fGIIU9mZ+XfAiaFtq7xTgseGU=\ngithub.com/go-openapi/analysis v0.0.0-20180825180245-b006789cd277/go.mod h1:k70tL6pCuVxPJOHXQ+wIac1FUrvNkHolPie/cLEU6hI=\ngithub.com/go-openapi/analysis v0.17.0/go.mod h1:IowGgpVeD0vNm45So8nr+IcQ3pxVtpRoBWb8PVZO0ik=\ngithub.com/go-openapi/analysis v0.18.0/go.mod h1:IowGgpVeD0vNm45So8nr+IcQ3pxVtpRoBWb8PVZO0ik=\ngithub.com/go-openapi/analysis v0.19.2/go.mod h1:3P1osvZa9jKjb8ed2TPng3f0i/UY9snX6gxi44djMjk=\ngithub.com/go-openapi/analysis v0.19.4/go.mod h1:3P1osvZa9jKjb8ed2TPng3f0i/UY9snX6gxi44djMjk=\ngithub.com/go-openapi/analysis v0.19.5/go.mod h1:hkEAkxagaIvIP7VTn8ygJNkd4kAYON2rCu0v0ObL0AU=\ngithub.com/go-openapi/analysis v0.19.10/go.mod h1:qmhS3VNFxBlquFJ0RGoDtylO9y4pgTAUNE9AEEMdlJQ=\ngithub.com/go-openapi/analysis v0.19.16/go.mod h1:GLInF007N83Ad3m8a/CbQ5TPzdnGT7workfHwuVjNVk=\ngithub.com/go-openapi/analysis v0.20.0/go.mod h1:BMchjvaHDykmRMsK40iPtvyOfFdMMxlOmQr9FBZk+Og=\ngithub.com/go-openapi/errors v0.17.0/go.mod h1:LcZQpmvG4wyF5j4IhA73wkLFQg+QJXOQHVjmcZxhka0=\ngithub.com/go-openapi/errors v0.18.0/go.mod h1:LcZQpmvG4wyF5j4IhA73wkLFQg+QJXOQHVjmcZxhka0=\ngithub.com/go-openapi/errors v0.19.2/go.mod h1:qX0BLWsyaKfvhluLejVpVNwNRdXZhEbTA4kxxpKBC94=\ngithub.com/go-openapi/errors v0.19.3/go.mod h1:qX0BLWsyaKfvhluLejVpVNwNRdXZhEbTA4kxxpKBC94=\ngithub.com/go-openapi/errors v0.19.4/go.mod h1:qX0BLWsyaKfvhluLejVpVNwNRdXZhEbTA4kxxpKBC94=\ngithub.com/go-openapi/errors v0.19.6/go.mod h1:cM//ZKUKyO06HSwqAelJ5NsEMMcpa6VpXe8DOa1Mi1M=\ngithub.com/go-openapi/errors v0.19.7/go.mod h1:cM//ZKUKyO06HSwqAelJ5NsEMMcpa6VpXe8DOa1Mi1M=\ngithub.com/go-openapi/errors v0.19.8/go.mod h1:cM//ZKUKyO06HSwqAelJ5NsEMMcpa6VpXe8DOa1Mi1M=\ngithub.com/go-openapi/errors v0.19.9 h1:9SnKdGhiPZHF3ttwFMiCBEb8jQ4IDdrK+5+a0oTygA4=\ngithub.com/go-openapi/errors v0.19.9/go.mod h1:cM//ZKUKyO06HSwqAelJ5NsEMMcpa6VpXe8DOa1Mi1M=\ngithub.com/go-openapi/jsonpointer v0.17.0/go.mod h1:cOnomiV+CVVwFLk0A/MExoFMjwdsUdVpsRhURCKh+3M=\ngithub.com/go-openapi/jsonpointer v0.18.0/go.mod h1:cOnomiV+CVVwFLk0A/MExoFMjwdsUdVpsRhURCKh+3M=\ngithub.com/go-openapi/jsonpointer v0.19.2/go.mod h1:3akKfEdA7DF1sugOqz1dVQHBcuDBPKZGEoHC/NkiQRg=\ngithub.com/go-openapi/jsonpointer v0.19.3/go.mod h1:Pl9vOtqEWErmShwVjC8pYs9cog34VGT37dQOVbmoatg=\ngithub.com/go-openapi/jsonpointer v0.19.5/go.mod h1:Pl9vOtqEWErmShwVjC8pYs9cog34VGT37dQOVbmoatg=\ngithub.com/go-openapi/jsonreference v0.17.0/go.mod h1:g4xxGn04lDIRh0GJb5QlpE3HfopLOL6uZrK/VgnsK9I=\ngithub.com/go-openapi/jsonreference v0.18.0/go.mod h1:g4xxGn04lDIRh0GJb5QlpE3HfopLOL6uZrK/VgnsK9I=\ngithub.com/go-openapi/jsonreference v0.19.2/go.mod h1:jMjeRr2HHw6nAVajTXJ4eiUwohSTlpa0o73RUL1owJc=\ngithub.com/go-openapi/jsonreference v0.19.3/go.mod h1:rjx6GuL8TTa9VaixXglHmQmIL98+wF9xc8zWvFonSJ8=\ngithub.com/go-openapi/jsonreference v0.19.5/go.mod h1:RdybgQwPxbL4UEjuAruzK1x3nE69AqPYEJeo/TWfEeg=\ngithub.com/go-openapi/loads v0.17.0/go.mod h1:72tmFy5wsWx89uEVddd0RjRWPZm92WRLhf7AC+0+OOU=\ngithub.com/go-openapi/loads v0.18.0/go.mod h1:72tmFy5wsWx89uEVddd0RjRWPZm92WRLhf7AC+0+OOU=\ngithub.com/go-openapi/loads v0.19.0/go.mod h1:72tmFy5wsWx89uEVddd0RjRWPZm92WRLhf7AC+0+OOU=\ngithub.com/go-openapi/loads v0.19.2/go.mod h1:QAskZPMX5V0C2gvfkGZzJlINuP7Hx/4+ix5jWFxsNPs=\ngithub.com/go-openapi/loads v0.19.3/go.mod h1:YVfqhUCdahYwR3f3iiwQLhicVRvLlU/WO5WPaZvcvSI=\ngithub.com/go-openapi/loads v0.19.4/go.mod h1:zZVHonKd8DXyxyw4yfnVjPzBjIQcLt0CCsn0N0ZrQsk=\ngithub.com/go-openapi/loads v0.19.5/go.mod h1:dswLCAdonkRufe/gSUC3gN8nTSaB9uaS2es0x5/IbjY=\ngithub.com/go-openapi/loads v0.19.6/go.mod h1:brCsvE6j8mnbmGBh103PT/QLHfbyDxA4hsKvYBNEGVc=\ngithub.com/go-openapi/loads v0.19.7/go.mod h1:brCsvE6j8mnbmGBh103PT/QLHfbyDxA4hsKvYBNEGVc=\ngithub.com/go-openapi/loads v0.20.0/go.mod h1:2LhKquiE513rN5xC6Aan6lYOSddlL8Mp20AW9kpviM4=\ngithub.com/go-openapi/loads v0.20.2/go.mod h1:hTVUotJ+UonAMMZsvakEgmWKgtulweO9vYP2bQYKA/o=\ngithub.com/go-openapi/runtime v0.0.0-20180920151709-4f900dc2ade9/go.mod h1:6v9a6LTXWQCdL8k1AO3cvqx5OtZY/Y9wKTgaoP6YRfA=\ngithub.com/go-openapi/runtime v0.19.0/go.mod h1:OwNfisksmmaZse4+gpV3Ne9AyMOlP1lt4sK4FXt0O64=\ngithub.com/go-openapi/runtime v0.19.4/go.mod h1:X277bwSUBxVlCYR3r7xgZZGKVvBd/29gLDlFGtJ8NL4=\ngithub.com/go-openapi/runtime v0.19.15/go.mod h1:dhGWCTKRXlAfGnQG0ONViOZpjfg0m2gUt9nTQPQZuoo=\ngithub.com/go-openapi/runtime v0.19.16/go.mod h1:5P9104EJgYcizotuXhEuUrzVc+j1RiSjahULvYmlv98=\ngithub.com/go-openapi/runtime v0.19.24/go.mod h1:Lm9YGCeecBnUUkFTxPC4s1+lwrkJ0pthx8YvyjCfkgk=\ngithub.com/go-openapi/spec v0.17.0/go.mod h1:XkF/MOi14NmjsfZ8VtAKf8pIlbZzyoTvZsdfssdxcBI=\ngithub.com/go-openapi/spec v0.18.0/go.mod h1:XkF/MOi14NmjsfZ8VtAKf8pIlbZzyoTvZsdfssdxcBI=\ngithub.com/go-openapi/spec v0.19.2/go.mod h1:sCxk3jxKgioEJikev4fgkNmwS+3kuYdJtcsZsD5zxMY=\ngithub.com/go-openapi/spec v0.19.3/go.mod h1:FpwSN1ksY1eteniUU7X0N/BgJ7a4WvBFVA8Lj9mJglo=\ngithub.com/go-openapi/spec v0.19.6/go.mod h1:Hm2Jr4jv8G1ciIAo+frC/Ft+rR2kQDh8JHKHb3gWUSk=\ngithub.com/go-openapi/spec v0.19.8/go.mod h1:Hm2Jr4jv8G1ciIAo+frC/Ft+rR2kQDh8JHKHb3gWUSk=\ngithub.com/go-openapi/spec v0.19.15/go.mod h1:+81FIL1JwC5P3/Iuuozq3pPE9dXdIEGxFutcFKaVbmU=\ngithub.com/go-openapi/spec v0.20.0/go.mod h1:+81FIL1JwC5P3/Iuuozq3pPE9dXdIEGxFutcFKaVbmU=\ngithub.com/go-openapi/spec v0.20.1/go.mod h1:93x7oh+d+FQsmsieroS4cmR3u0p/ywH649a3qwC9OsQ=\ngithub.com/go-openapi/spec v0.20.3/go.mod h1:gG4F8wdEDN+YPBMVnzE85Rbhf+Th2DTvA9nFPQ5AYEg=\ngithub.com/go-openapi/strfmt v0.17.0/go.mod h1:P82hnJI0CXkErkXi8IKjPbNBM6lV6+5pLP5l494TcyU=\ngithub.com/go-openapi/strfmt v0.18.0/go.mod h1:P82hnJI0CXkErkXi8IKjPbNBM6lV6+5pLP5l494TcyU=\ngithub.com/go-openapi/strfmt v0.19.0/go.mod h1:+uW+93UVvGGq2qGaZxdDeJqSAqBqBdl+ZPMF/cC8nDY=\ngithub.com/go-openapi/strfmt v0.19.2/go.mod h1:0yX7dbo8mKIvc3XSKp7MNfxw4JytCfCD6+bY1AVL9LU=\ngithub.com/go-openapi/strfmt v0.19.3/go.mod h1:0yX7dbo8mKIvc3XSKp7MNfxw4JytCfCD6+bY1AVL9LU=\ngithub.com/go-openapi/strfmt v0.19.4/go.mod h1:eftuHTlB/dI8Uq8JJOyRlieZf+WkkxUuk0dgdHXr2Qk=\ngithub.com/go-openapi/strfmt v0.19.5/go.mod h1:eftuHTlB/dI8Uq8JJOyRlieZf+WkkxUuk0dgdHXr2Qk=\ngithub.com/go-openapi/strfmt v0.19.11/go.mod h1:UukAYgTaQfqJuAFlNxxMWNvMYiwiXtLsF2VwmoFtbtc=\ngithub.com/go-openapi/strfmt v0.20.0 h1:l2omNtmNbMc39IGptl9BuXBEKcZfS8zjrTsPKTiJiDM=\ngithub.com/go-openapi/strfmt v0.20.0/go.mod h1:UukAYgTaQfqJuAFlNxxMWNvMYiwiXtLsF2VwmoFtbtc=\ngithub.com/go-openapi/swag v0.17.0/go.mod h1:AByQ+nYG6gQg71GINrmuDXCPWdL640yX49/kXLo40Tg=\ngithub.com/go-openapi/swag v0.18.0/go.mod h1:AByQ+nYG6gQg71GINrmuDXCPWdL640yX49/kXLo40Tg=\ngithub.com/go-openapi/swag v0.19.2/go.mod h1:POnQmlKehdgb5mhVOsnJFsivZCEZ/vjK9gh66Z9tfKk=\ngithub.com/go-openapi/swag v0.19.5/go.mod h1:POnQmlKehdgb5mhVOsnJFsivZCEZ/vjK9gh66Z9tfKk=\ngithub.com/go-openapi/swag v0.19.7/go.mod h1:ao+8BpOPyKdpQz3AOJfbeEVpLmWAvlT1IfTe5McPyhY=\ngithub.com/go-openapi/swag v0.19.9/go.mod h1:ao+8BpOPyKdpQz3AOJfbeEVpLmWAvlT1IfTe5McPyhY=\ngithub.com/go-openapi/swag v0.19.12/go.mod h1:eFdyEBkTdoAf/9RXBvj4cr1nH7GD8Kzo5HTt47gr72M=\ngithub.com/go-openapi/swag v0.19.13/go.mod h1:QYRuS/SOXUCsnplDa677K7+DxSOj6IPNl/eQntq43wQ=\ngithub.com/go-openapi/swag v0.19.14/go.mod h1:QYRuS/SOXUCsnplDa677K7+DxSOj6IPNl/eQntq43wQ=\ngithub.com/go-openapi/validate v0.18.0/go.mod h1:Uh4HdOzKt19xGIGm1qHf/ofbX1YQ4Y+MYsct2VUrAJ4=\ngithub.com/go-openapi/validate v0.19.2/go.mod h1:1tRCw7m3jtI8eNWEEliiAqUIcBztB2KDnRCRMUi7GTA=\ngithub.com/go-openapi/validate v0.19.3/go.mod h1:90Vh6jjkTn+OT1Eefm0ZixWNFjhtOH7vS9k0lo6zwJo=\ngithub.com/go-openapi/validate v0.19.8/go.mod h1:8DJv2CVJQ6kGNpFW6eV9N3JviE1C85nY1c2z52x1Gk4=\ngithub.com/go-openapi/validate v0.19.10/go.mod h1:RKEZTUWDkxKQxN2jDT7ZnZi2bhZlbNMAuKvKB+IaGx8=\ngithub.com/go-openapi/validate v0.19.12/go.mod h1:Rzou8hA/CBw8donlS6WNEUQupNvUZ0waH08tGe6kAQ4=\ngithub.com/go-openapi/validate v0.19.15/go.mod h1:tbn/fdOwYHgrhPBzidZfJC2MIVvs9GA7monOmWBbeCI=\ngithub.com/go-openapi/validate v0.20.1/go.mod h1:b60iJT+xNNLfaQJUqLI7946tYiFEOuE9E4k54HpKcJ0=\ngithub.com/go-openapi/validate v0.20.2/go.mod h1:e7OJoKNgd0twXZwIn0A43tHbvIcr/rZIVCbJBpTUoY0=\ngithub.com/go-sql-driver/mysql v1.4.0/go.mod h1:zAC/RDZ24gD3HViQzih4MyKcchzm+sOG5ZlKdlhCg5w=\ngithub.com/go-sql-driver/mysql v1.4.1/go.mod h1:zAC/RDZ24gD3HViQzih4MyKcchzm+sOG5ZlKdlhCg5w=\ngithub.com/go-sql-driver/mysql v1.5.0 h1:ozyZYNQW3x3HtqT1jira07DN2PArx2v7/mN66gGcHOs=\ngithub.com/go-sql-driver/mysql v1.5.0/go.mod h1:DCzpHaOWr8IXmIStZouvnhqoel9Qv2LBy8hT2VhHyBg=\ngithub.com/go-stack/stack v1.8.0 h1:5SgMzNM5HxrEjV0ww2lTmX6E2Izsfxas4+YHWRs3Lsk=\ngithub.com/go-stack/stack v1.8.0/go.mod h1:v0f6uXyyMGvRgIKkXu+yp6POWl0qKG85gN/melR3HDY=\ngithub.com/go-test/deep v1.0.1/go.mod h1:wGDj63lr65AM2AQyKZd/NYHGb0R+1RLqB8NKt3aSFNA=\ngithub.com/go-zookeeper/zk v1.0.2 h1:4mx0EYENAdX/B/rbunjlt5+4RTA/a9SMHBRuSKdGxPM=\ngithub.com/go-zookeeper/zk v1.0.2/go.mod h1:nOB03cncLtlp4t+UAkGSV+9beXP/akpekBwL+UX1Qcw=\ngithub.com/gobuffalo/attrs v0.0.0-20190224210810-a9411de4debd/go.mod h1:4duuawTqi2wkkpB4ePgWMaai6/Kc6WEz83bhFwpHzj0=\ngithub.com/gobuffalo/depgen v0.0.0-20190329151759-d478694a28d3/go.mod h1:3STtPUQYuzV0gBVOY3vy6CfMm/ljR4pABfrTeHNLHUY=\ngithub.com/gobuffalo/depgen v0.1.0/go.mod h1:+ifsuy7fhi15RWncXQQKjWS9JPkdah5sZvtHc2RXGlg=\ngithub.com/gobuffalo/envy v1.6.15/go.mod h1:n7DRkBerg/aorDM8kbduw5dN3oXGswK5liaSCx4T5NI=\ngithub.com/gobuffalo/envy v1.7.0/go.mod h1:n7DRkBerg/aorDM8kbduw5dN3oXGswK5liaSCx4T5NI=\ngithub.com/gobuffalo/flect v0.1.0/go.mod h1:d2ehjJqGOH/Kjqcoz+F7jHTBbmDb38yXA598Hb50EGs=\ngithub.com/gobuffalo/flect v0.1.1/go.mod h1:8JCgGVbRjJhVgD6399mQr4fx5rRfGKVzFjbj6RE/9UI=\ngithub.com/gobuffalo/flect v0.1.3/go.mod h1:8JCgGVbRjJhVgD6399mQr4fx5rRfGKVzFjbj6RE/9UI=\ngithub.com/gobuffalo/genny v0.0.0-20190329151137-27723ad26ef9/go.mod h1:rWs4Z12d1Zbf19rlsn0nurr75KqhYp52EAGGxTbBhNk=\ngithub.com/gobuffalo/genny v0.0.0-20190403191548-3ca520ef0d9e/go.mod h1:80lIj3kVJWwOrXWWMRzzdhW3DsrdjILVil/SFKBzF28=\ngithub.com/gobuffalo/genny v0.1.0/go.mod h1:XidbUqzak3lHdS//TPu2OgiFB+51Ur5f7CSnXZ/JDvo=\ngithub.com/gobuffalo/genny v0.1.1/go.mod h1:5TExbEyY48pfunL4QSXxlDOmdsD44RRq4mVZ0Ex28Xk=\ngithub.com/gobuffalo/gitgen v0.0.0-20190315122116-cc086187d211/go.mod h1:vEHJk/E9DmhejeLeNt7UVvlSGv3ziL+djtTr3yyzcOw=\ngithub.com/gobuffalo/gogen v0.0.0-20190315121717-8f38393713f5/go.mod h1:V9QVDIxsgKNZs6L2IYiGR8datgMhB577vzTDqypH360=\ngithub.com/gobuffalo/gogen v0.1.0/go.mod h1:8NTelM5qd8RZ15VjQTFkAW6qOMx5wBbW4dSCS3BY8gg=\ngithub.com/gobuffalo/gogen v0.1.1/go.mod h1:y8iBtmHmGc4qa3urIyo1shvOD8JftTtfcKi+71xfDNE=\ngithub.com/gobuffalo/logger v0.0.0-20190315122211-86e12af44bc2/go.mod h1:QdxcLw541hSGtBnhUc4gaNIXRjiDppFGaDqzbrBd3v8=\ngithub.com/gobuffalo/mapi v1.0.1/go.mod h1:4VAGh89y6rVOvm5A8fKFxYG+wIW6LO1FMTG9hnKStFc=\ngithub.com/gobuffalo/mapi v1.0.2/go.mod h1:4VAGh89y6rVOvm5A8fKFxYG+wIW6LO1FMTG9hnKStFc=\ngithub.com/gobuffalo/packd v0.0.0-20190315124812-a385830c7fc0/go.mod h1:M2Juc+hhDXf/PnmBANFCqx4DM3wRbgDvnVWeG2RIxq4=\ngithub.com/gobuffalo/packd v0.1.0/go.mod h1:M2Juc+hhDXf/PnmBANFCqx4DM3wRbgDvnVWeG2RIxq4=\ngithub.com/gobuffalo/packr/v2 v2.0.9/go.mod h1:emmyGweYTm6Kdper+iywB6YK5YzuKchGtJQZ0Odn4pQ=\ngithub.com/gobuffalo/packr/v2 v2.2.0/go.mod h1:CaAwI0GPIAv+5wKLtv8Afwl+Cm78K/I/VCm/3ptBN+0=\ngithub.com/gobuffalo/syncx v0.0.0-20190224160051-33c29581e754/go.mod h1:HhnNqWY95UYwwW3uSASeV7vtgYkT2t16hJgV3AEPUpw=\ngithub.com/gocarina/gocsv v0.0.0-20210408192840-02d7211d929d/go.mod h1:5YoVOkjYAQumqlV356Hj3xeYh4BdZuLE0/nRkf2NKkI=\ngithub.com/goccy/go-json v0.7.10/go.mod h1:6MelG93GURQebXPDq3khkgXZkazVtN9CRI+MGFi0w8I=\ngithub.com/goccy/go-json v0.9.11 h1:/pAaQDLHEoCq/5FFmSKBswWmK6H0e8g4159Kc/X/nqk=\ngithub.com/goccy/go-json v0.9.11/go.mod h1:6MelG93GURQebXPDq3khkgXZkazVtN9CRI+MGFi0w8I=\ngithub.com/gofrs/uuid v3.3.0+incompatible h1:8K4tyRfvU1CYPgJsveYFQMhpFd/wXNM7iK6rR7UHz84=\ngithub.com/gofrs/uuid v3.3.0+incompatible/go.mod h1:b2aQJv3Z4Fp6yNu3cdSllBxTCLRxnplIgP/c0N/04lM=\ngithub.com/gogo/googleapis v1.1.0/go.mod h1:gf4bu3Q80BeJ6H1S1vYPm8/ELATdvryBaNFGgqEef3s=\ngithub.com/gogo/protobuf v1.1.1/go.mod h1:r8qH/GZQm5c6nD/R0oafs1akxWv10x8SbQlK7atdtwQ=\ngithub.com/gogo/protobuf v1.2.0/go.mod h1:r8qH/GZQm5c6nD/R0oafs1akxWv10x8SbQlK7atdtwQ=\ngithub.com/gogo/protobuf v1.2.1/go.mod h1:hp+jE20tsWTFYpLwKvXlhS1hjn+gTNwPg2I6zVXpSg4=\ngithub.com/gogo/protobuf v1.2.2-0.20190730201129-28a6bbf47e48/go.mod h1:SlYgWuQ5SjCEi6WLHjHCa1yvBfUnHcTbrrZtXPKa29o=\ngithub.com/gogo/protobuf v1.3.1/go.mod h1:SlYgWuQ5SjCEi6WLHjHCa1yvBfUnHcTbrrZtXPKa29o=\ngithub.com/gogo/protobuf v1.3.2 h1:Ov1cvc58UF3b5XjBnZv7+opcTcQFZebYjWzi34vdm4Q=\ngithub.com/gogo/protobuf v1.3.2/go.mod h1:P1XiOD3dCwIKUDQYPy72D8LYyHL2YPYrpS2s69NZV8Q=\ngithub.com/golang-jwt/jwt v3.2.2+incompatible h1:IfV12K8xAKAnZqdXVzCZ+TOjboZ2keLg81eXfW3O+oY=\ngithub.com/golang-jwt/jwt v3.2.2+incompatible/go.mod h1:8pz2t5EyA70fFQQSrl6XZXzqecmYZeUEB8OUGHkxJ+I=\ngithub.com/golang-jwt/jwt/v4 v4.5.0/go.mod h1:m21LjoU+eqJr34lmDMbreY2eSTRJ1cv77w39/MY0Ch0=\ngithub.com/golang-jwt/jwt/v4 v4.5.1 h1:JdqV9zKUdtaa9gdPlywC3aeoEsR681PlKC+4F5gQgeo=\ngithub.com/golang-jwt/jwt/v4 v4.5.1/go.mod h1:m21LjoU+eqJr34lmDMbreY2eSTRJ1cv77w39/MY0Ch0=\ngithub.com/golang-sql/civil v0.0.0-20190719163853-cb61b32ac6fe h1:lXe2qZdvpiX5WZkZR4hgp4KJVfY3nMkvmwbVkpv1rVY=\ngithub.com/golang-sql/civil v0.0.0-20190719163853-cb61b32ac6fe/go.mod h1:8vg3r2VgvsThLBIFL93Qb5yWzgyZWhEmBwUJWevAkK0=\ngithub.com/golang/freetype v0.0.0-20170609003504-e2365dfdc4a0/go.mod h1:E/TSTwGwJL78qG/PmXZO1EjYhfJinVAhrmmHX6Z8B9k=\ngithub.com/golang/gddo v0.0.0-20181116215533-9bd4a3295021 h1:HYV500jCgk+IC68L5sWrLFIWMpaUFfXXpJSAb7XOoBk=\ngithub.com/golang/gddo v0.0.0-20181116215533-9bd4a3295021/go.mod h1:xEhNfoBDX1hzLm2Nf80qUvZ2sVwoMZ8d6IE2SrsQfh4=\ngithub.com/golang/geo v0.0.0-20190916061304-5b978397cfec h1:lJwO/92dFXWeXOZdoGXgptLmNLwynMSHUmU6besqtiw=\ngithub.com/golang/geo v0.0.0-20190916061304-5b978397cfec/go.mod h1:QZ0nwyI2jOfgRAoBvP+ab5aRr7c9x7lhGEJrKvBwjWI=\ngithub.com/golang/glog v0.0.0-20160126235308-23def4e6c14b/go.mod h1:SBH7ygxi8pfUlaOkMMuAQtPIUF8ecWP5IEl/CR7VP2Q=\ngithub.com/golang/groupcache v0.0.0-20160516000752-02826c3e7903/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=\ngithub.com/golang/groupcache v0.0.0-20190129154638-5b532d6fd5ef/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=\ngithub.com/golang/groupcache v0.0.0-20190702054246-869f871628b6/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=\ngithub.com/golang/groupcache v0.0.0-20191227052852-215e87163ea7/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=\ngithub.com/golang/groupcache v0.0.0-20200121045136-8c9f03a8e57e h1:1r7pUrabqp18hOBcwBwiTsbnFeTZHV9eER/QT5JVZxY=\ngithub.com/golang/groupcache v0.0.0-20200121045136-8c9f03a8e57e/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=\ngithub.com/golang/mock v1.1.1/go.mod h1:oTYuIxOrZwtPieC+H1uAHpcLFnEyAGVDL/k47Jfbm0A=\ngithub.com/golang/mock v1.2.0/go.mod h1:oTYuIxOrZwtPieC+H1uAHpcLFnEyAGVDL/k47Jfbm0A=\ngithub.com/golang/mock v1.3.1/go.mod h1:sBzyDLLjw3U8JLTeZvSv8jJB+tU5PVekmnlKIyFUx0Y=\ngithub.com/golang/mock v1.4.0/go.mod h1:UOMv5ysSaYNkG+OFQykRIcU/QvvxJf3p21QfJ2Bt3cw=\ngithub.com/golang/mock v1.4.1/go.mod h1:UOMv5ysSaYNkG+OFQykRIcU/QvvxJf3p21QfJ2Bt3cw=\ngithub.com/golang/mock v1.4.3/go.mod h1:UOMv5ysSaYNkG+OFQykRIcU/QvvxJf3p21QfJ2Bt3cw=\ngithub.com/golang/mock v1.4.4/go.mod h1:l3mdAwkq5BuhzHwde/uurv3sEJeZMXNpwsxVWU71h+4=\ngithub.com/golang/mock v1.5.0 h1:jlYHihg//f7RRwuPfptm04yp4s7O6Kw8EZiVYIGcH0g=\ngithub.com/golang/mock v1.5.0/go.mod h1:CWnOUgYIOo4TcNZ0wHX3YZCqsaM1I1Jvs6v3mP3KVu8=\ngithub.com/golang/protobuf v1.2.0/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.1/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.2/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.3/go.mod h1:vzj43D7+SQXF/4pzW/hwtAqwc6iTitCiVSaWz5lYuqw=\ngithub.com/golang/protobuf v1.3.4/go.mod h1:vzj43D7+SQXF/4pzW/hwtAqwc6iTitCiVSaWz5lYuqw=\ngithub.com/golang/protobuf v1.3.5/go.mod h1:6O5/vntMXwX2lRkT1hjjk0nAC1IDOTvTlVgjlRvqsdk=\ngithub.com/golang/protobuf v1.4.0-rc.1/go.mod h1:ceaxUfeHdC40wWswd/P6IGgMaK3YpKi5j83Wpe3EHw8=\ngithub.com/golang/protobuf v1.4.0-rc.1.0.20200221234624-67d41d38c208/go.mod h1:xKAWHe0F5eneWXFV3EuXVDTCmh+JuBKY0li0aMyXATA=\ngithub.com/golang/protobuf v1.4.0-rc.2/go.mod h1:LlEzMj4AhA7rCAGe4KMBDvJI+AwstrUpVNzEA03Pprs=\ngithub.com/golang/protobuf v1.4.0-rc.4.0.20200313231945-b860323f09d0/go.mod h1:WU3c8KckQ9AFe+yFwt9sWVRKCVIyN9cPHBJSNnbL67w=\ngithub.com/golang/protobuf v1.4.0/go.mod h1:jodUvKwWbYaEsadDk5Fwe5c77LiNKVO9IDvqG2KuDX0=\ngithub.com/golang/protobuf v1.4.1/go.mod h1:U8fpvMrcmy5pZrNK1lt4xCsGvpyWQ/VVv6QDs8UjoX8=\ngithub.com/golang/protobuf v1.4.2/go.mod h1:oDoupMAO8OvCJWAcko0GGGIgR6R6ocIYbsSw735rRwI=\ngithub.com/golang/protobuf v1.4.3/go.mod h1:oDoupMAO8OvCJWAcko0GGGIgR6R6ocIYbsSw735rRwI=\ngithub.com/golang/protobuf v1.5.0/go.mod h1:FsONVRAS9T7sI+LIUmWTfcYkHO4aIWwzhcaSAoJOfIk=\ngithub.com/golang/protobuf v1.5.1/go.mod h1:DopwsBzvsk0Fs44TXzsVbJyPhcCPeIwnvohx4u74HPM=\ngithub.com/golang/protobuf v1.5.2/go.mod h1:XVQd3VNwM+JqD3oG2Ue2ip4fOMUkwXdXDdiuN0vRsmY=\ngithub.com/golang/protobuf v1.5.3 h1:KhyjKVUg7Usr/dYsdSqoFveMYd5ko72D+zANwlG1mmg=\ngithub.com/golang/protobuf v1.5.3/go.mod h1:XVQd3VNwM+JqD3oG2Ue2ip4fOMUkwXdXDdiuN0vRsmY=\ngithub.com/golang/snappy v0.0.0-20180518054509-2e65f85255db/go.mod h1:/XxbfmMg8lxefKM7IXC3fBNl/7bRcc72aCRzEWrmP2Q=\ngithub.com/golang/snappy v0.0.1/go.mod h1:/XxbfmMg8lxefKM7IXC3fBNl/7bRcc72aCRzEWrmP2Q=\ngithub.com/golang/snappy v0.0.3/go.mod h1:/XxbfmMg8lxefKM7IXC3fBNl/7bRcc72aCRzEWrmP2Q=\ngithub.com/golang/snappy v0.0.4 h1:yAGX7huGHXlcLOEtBnF4w7FQwA26wojNCwOYAEhLjQM=\ngithub.com/golang/snappy v0.0.4/go.mod h1:/XxbfmMg8lxefKM7IXC3fBNl/7bRcc72aCRzEWrmP2Q=\ngithub.com/golangci/lint-1 v0.0.0-20181222135242-d2cdd8c08219/go.mod h1:/X8TswGSh1pIozq4ZwCfxS0WA5JGXguxk94ar/4c87Y=\ngithub.com/google/btree v0.0.0-20180813153112-4030bb1f1f0c/go.mod h1:lNA+9X1NB3Zf8V7Ke586lFgjr2dZNuvo3lPJSGZ5JPQ=\ngithub.com/google/btree v1.0.0/go.mod h1:lNA+9X1NB3Zf8V7Ke586lFgjr2dZNuvo3lPJSGZ5JPQ=\ngithub.com/google/btree v1.0.1 h1:gK4Kx5IaGY9CD5sPJ36FHiBJ6ZXl0kilRiiCj+jdYp4=\ngithub.com/google/btree v1.0.1/go.mod h1:xXMiIv4Fb/0kKde4SpL7qlzvu5cMJDRkFDxJfI9uaxA=\ngithub.com/google/flatbuffers v1.11.0/go.mod h1:1AeVuKshWv4vARoZatz6mlQ0JxURH0Kv5+zNeJKJCa8=\ngithub.com/google/flatbuffers v2.0.0+incompatible/go.mod h1:1AeVuKshWv4vARoZatz6mlQ0JxURH0Kv5+zNeJKJCa8=\ngithub.com/google/flatbuffers v2.0.8+incompatible h1:ivUb1cGomAB101ZM1T0nOiWz9pSrTMoa9+EiY7igmkM=\ngithub.com/google/flatbuffers v2.0.8+incompatible/go.mod h1:1AeVuKshWv4vARoZatz6mlQ0JxURH0Kv5+zNeJKJCa8=\ngithub.com/google/go-cmp v0.2.0/go.mod h1:oXzfMopK8JAjlY9xF4vHSVASa0yLyX7SntLO5aqRK0M=\ngithub.com/google/go-cmp v0.3.0/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.3.1/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.4.0/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.4.1/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.0/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.1/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.2/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.3/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.4/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.5/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.6/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.6.0 h1:ofyhxvXcZhMsU5ulbFiLKl/XBFqE1GSq7atu8tAmTRI=\ngithub.com/google/go-cmp v0.6.0/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/google/go-github v17.0.0+incompatible h1:N0LgJ1j65A7kfXrZnUDaYCs/Sf4rEjNlfyDHW9dolSY=\ngithub.com/google/go-github v17.0.0+incompatible/go.mod h1:zLgOLi98H3fifZn+44m+umXrS52loVEgC2AApnigrVQ=\ngithub.com/google/go-jsonnet v0.14.0/go.mod h1:zPGC9lj/TbjkBtUACIvYR/ILHrFqKRhxeEA+bLyeMnY=\ngithub.com/google/go-querystring v1.0.0 h1:Xkwi/a1rcvNg1PPYe5vI8GbeBY/jrVuDX5ASuANWTrk=\ngithub.com/google/go-querystring v1.0.0/go.mod h1:odCYkC5MyYFN7vkCjXpyrEuKhc/BUO6wN/zVPAxq5ck=\ngithub.com/google/gofuzz v1.0.0/go.mod h1:dBl0BpW6vV/+mYPU4Po3pmUjxk6FQPldtuIdl/M65Eg=\ngithub.com/google/gofuzz v1.1.0/go.mod h1:dBl0BpW6vV/+mYPU4Po3pmUjxk6FQPldtuIdl/M65Eg=\ngithub.com/google/gofuzz v1.2.0 h1:xRy4A+RhZaiKjJ1bPfwQ8sedCA+YS2YcCHW6ec7JMi0=\ngithub.com/google/gofuzz v1.2.0/go.mod h1:dBl0BpW6vV/+mYPU4Po3pmUjxk6FQPldtuIdl/M65Eg=\ngithub.com/google/martian v2.1.0+incompatible/go.mod h1:9I4somxYTbIHy5NJKHRl3wXiIaQGbYVAs8BPL6v8lEs=\ngithub.com/google/martian v2.1.1-0.20190517191504-25dcb96d9e51+incompatible h1:xmapqc1AyLoB+ddYT6r04bD9lIjlOqGaREovi0SzFaE=\ngithub.com/google/martian v2.1.1-0.20190517191504-25dcb96d9e51+incompatible/go.mod h1:9I4somxYTbIHy5NJKHRl3wXiIaQGbYVAs8BPL6v8lEs=\ngithub.com/google/martian/v3 v3.0.0/go.mod h1:y5Zk1BBys9G+gd6Jrk0W3cC1+ELVxBWuIGO+w/tUAp0=\ngithub.com/google/martian/v3 v3.1.0/go.mod h1:y5Zk1BBys9G+gd6Jrk0W3cC1+ELVxBWuIGO+w/tUAp0=\ngithub.com/google/martian/v3 v3.3.2 h1:IqNFLAmvJOgVlpdEBiQbDc2EwKW77amAycfTuWKdfvw=\ngithub.com/google/martian/v3 v3.3.2/go.mod h1:oBOf6HBosgwRXnUGWUB05QECsc6uvmMiJ3+6W4l/CUk=\ngithub.com/google/pprof v0.0.0-20181206194817-3ea8567a2e57/go.mod h1:zfwlbNMJ+OItoe0UupaVj+oy1omPYYDuagoSzA8v9mc=\ngithub.com/google/pprof v0.0.0-20190515194954-54271f7e092f/go.mod h1:zfwlbNMJ+OItoe0UupaVj+oy1omPYYDuagoSzA8v9mc=\ngithub.com/google/pprof v0.0.0-20191218002539-d4f498aebedc/go.mod h1:ZgVRPoUq/hfqzAqh7sHMqb3I9Rq5C59dIz2SbBwJ4eM=\ngithub.com/google/pprof v0.0.0-20200212024743-f11f1df84d12/go.mod h1:ZgVRPoUq/hfqzAqh7sHMqb3I9Rq5C59dIz2SbBwJ4eM=\ngithub.com/google/pprof v0.0.0-20200229191704-1ebb73c60ed3/go.mod h1:ZgVRPoUq/hfqzAqh7sHMqb3I9Rq5C59dIz2SbBwJ4eM=\ngithub.com/google/pprof v0.0.0-20200430221834-fc25d7d30c6d/go.mod h1:ZgVRPoUq/hfqzAqh7sHMqb3I9Rq5C59dIz2SbBwJ4eM=\ngithub.com/google/pprof v0.0.0-20200708004538-1a94d8640e99/go.mod h1:ZgVRPoUq/hfqzAqh7sHMqb3I9Rq5C59dIz2SbBwJ4eM=\ngithub.com/google/pprof v0.0.0-20201023163331-3e6fc7fc9c4c/go.mod h1:kpwsk12EmLew5upagYY7GY0pfYCcupk39gWOCRROcvE=\ngithub.com/google/pprof v0.0.0-20201203190320-1bf35d6f28c2/go.mod h1:kpwsk12EmLew5upagYY7GY0pfYCcupk39gWOCRROcvE=\ngithub.com/google/pprof v0.0.0-20210122040257-d980be63207e/go.mod h1:kpwsk12EmLew5upagYY7GY0pfYCcupk39gWOCRROcvE=\ngithub.com/google/pprof v0.0.0-20210226084205-cbba55b83ad5/go.mod h1:kpwsk12EmLew5upagYY7GY0pfYCcupk39gWOCRROcvE=\ngithub.com/google/pprof v0.0.0-20210323184331-8eee2492667d/go.mod h1:kpwsk12EmLew5upagYY7GY0pfYCcupk39gWOCRROcvE=\ngithub.com/google/pprof v0.0.0-20210506205249-923b5ab0fc1a/go.mod h1:kpwsk12EmLew5upagYY7GY0pfYCcupk39gWOCRROcvE=\ngithub.com/google/renameio v0.1.0/go.mod h1:KWCgfxg9yswjAJkECMjeO8J8rahYeXnNhOm40UhjYkI=\ngithub.com/google/uuid v1.0.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/google/uuid v1.1.1/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/google/uuid v1.1.2/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/google/uuid v1.2.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/google/uuid v1.3.0 h1:t6JiXgmwXMjEs8VusXIJk2BXHsn+wx8BZdTaoZ5fu7I=\ngithub.com/google/uuid v1.3.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/googleapis/enterprise-certificate-proxy v0.2.3 h1:yk9/cqRKtT9wXZSsRH9aurXEpJX+U6FLtpYTdC3R06k=\ngithub.com/googleapis/enterprise-certificate-proxy v0.2.3/go.mod h1:AwSRAtLfXpU5Nm3pW+v7rGDHp09LsPtGY9MduiEsR9k=\ngithub.com/googleapis/gax-go/v2 v2.0.4/go.mod h1:0Wqv26UfaUD9n4G6kQubkQ+KchISgw+vpHVxEJEs9eg=\ngithub.com/googleapis/gax-go/v2 v2.0.5/go.mod h1:DWXyrwAJ9X0FpwwEdw+IPEYBICEFu5mhpdKc/us6bOk=\ngithub.com/googleapis/gax-go/v2 v2.7.1 h1:gF4c0zjUP2H/s/hEGyLA3I0fA2ZWjzYiONAD6cvPr8A=\ngithub.com/googleapis/gax-go/v2 v2.7.1/go.mod h1:4orTrqY6hXxxaUL4LHIPl6lGo8vAE38/qKbhSAKP6QI=\ngithub.com/googleapis/gnostic v0.4.1 h1:DLJCy1n/vrD4HPjOvYcT8aYQXpPIzoRZONaYwyycI+I=\ngithub.com/googleapis/gnostic v0.4.1/go.mod h1:LRhVm6pbyptWbWbuZ38d1eyptfvIytN3ir6b65WBswg=\ngithub.com/gophercloud/gophercloud v0.16.0/go.mod h1:wRtmUelyIIv3CSSDI47aUwbs075O6i+LY+pXsKCBsb4=\ngithub.com/gophercloud/gophercloud v0.17.0 h1:BgVw0saxyeHWH5us/SQe1ltp0GRnytjmOLXDA8pO77E=\ngithub.com/gophercloud/gophercloud v0.17.0/go.mod h1:wRtmUelyIIv3CSSDI47aUwbs075O6i+LY+pXsKCBsb4=\ngithub.com/gopherjs/gopherjs v0.0.0-20181017120253-0766667cb4d1/go.mod h1:wJfORRmW1u3UXTncJ5qlYoELFm8eSnnEO6hX4iZ3EWY=\ngithub.com/gopherjs/gopherjs v0.0.0-20190812055157-5d271430af9f h1:KMlcu9X58lhTA/KrfX8Bi1LQSO4pzoVjTiL3h4Jk+Zk=\ngithub.com/gopherjs/gopherjs v0.0.0-20190812055157-5d271430af9f/go.mod h1:wJfORRmW1u3UXTncJ5qlYoELFm8eSnnEO6hX4iZ3EWY=\ngithub.com/gorhill/cronexpr v0.0.0-20180427100037-88b0669f7d75 h1:f0n1xnMSmBLzVfsMMvriDyA75NB/oBgILX2GcHXIQzY=\ngithub.com/gorhill/cronexpr v0.0.0-20180427100037-88b0669f7d75/go.mod h1:g2644b03hfBX9Ov0ZBDgXXens4rxSxmqFBbhvKv2yVA=\ngithub.com/gorilla/context v1.1.1/go.mod h1:kBGZzfjB9CEq2AlWe17Uuf7NDRt0dE0s8S51q0aT7Yg=\ngithub.com/gorilla/mux v1.6.2/go.mod h1:1lud6UwP+6orDFRuTfBEV8e9/aOM/c4fVVCaMa2zaAs=\ngithub.com/gorilla/mux v1.7.3/go.mod h1:1lud6UwP+6orDFRuTfBEV8e9/aOM/c4fVVCaMa2zaAs=\ngithub.com/gorilla/mux v1.8.0/go.mod h1:DVbg23sWSpFRCP0SfiEN6jmj59UnW/n46BH5rLB71So=\ngithub.com/gorilla/securecookie v1.1.1/go.mod h1:ra0sb63/xPlUeL+yeDciTfxMRAA+MP+HVt/4epWDjd4=\ngithub.com/gorilla/sessions v1.2.1/go.mod h1:dk2InVEVJ0sfLlnXv9EAgkf6ecYs/i80K/zI+bUmuGM=\ngithub.com/gorilla/websocket v0.0.0-20170926233335-4201258b820c/go.mod h1:E7qHFY5m1UJ88s3WnNqhKjPHQ0heANvMoAMk2YaljkQ=\ngithub.com/gorilla/websocket v1.4.0/go.mod h1:E7qHFY5m1UJ88s3WnNqhKjPHQ0heANvMoAMk2YaljkQ=\ngithub.com/gorilla/websocket v1.4.2/go.mod h1:YR8l580nyteQvAITg2hZ9XVh4b55+EU/adAjf1fMHhE=\ngithub.com/gregjones/httpcache v0.0.0-20180305231024-9cad4c3443a7/go.mod h1:FecbI9+v66THATjSRHfNgh1IVFe/9kFxbXtjV0ctIMA=\ngithub.com/grpc-ecosystem/go-grpc-middleware v1.0.0/go.mod h1:FiyG127CGDf3tlThmgyCl78X/SZQqEOJBCDaAfeWzPs=\ngithub.com/grpc-ecosystem/go-grpc-middleware v1.0.1-0.20190118093823-f849b5445de4/go.mod h1:FiyG127CGDf3tlThmgyCl78X/SZQqEOJBCDaAfeWzPs=\ngithub.com/grpc-ecosystem/go-grpc-prometheus v1.2.0/go.mod h1:8NvIoxWQoOIhqOTXgfV/d3M/q6VIi02HzZEHgUlZvzk=\ngithub.com/grpc-ecosystem/grpc-gateway v1.9.0/go.mod h1:vNeuVxBJEsws4ogUvrchl83t/GYV9WGTSLVdBhOQFDY=\ngithub.com/grpc-ecosystem/grpc-gateway v1.9.5/go.mod h1:vNeuVxBJEsws4ogUvrchl83t/GYV9WGTSLVdBhOQFDY=\ngithub.com/grpc-ecosystem/grpc-gateway v1.16.0/go.mod h1:BDjrQk3hbvj6Nolgz8mAMFbcEtjT1g+wF4CSlocrBnw=\ngithub.com/h2non/gock v1.2.0 h1:K6ol8rfrRkUOefooBC8elXoaNGYkpp7y2qcxGG6BzUE=\ngithub.com/h2non/gock v1.2.0/go.mod h1:tNhoxHYW2W42cYkYb1WqzdbYIieALC99kpYr7rH/BQk=\ngithub.com/h2non/parth v0.0.0-20190131123155-b4df798d6542 h1:2VTzZjLZBgl62/EtslCrtky5vbi9dd7HrQPQIx6wqiw=\ngithub.com/h2non/parth v0.0.0-20190131123155-b4df798d6542/go.mod h1:Ow0tF8D4Kplbc8s8sSb3V2oUCygFHVp8gC3Dn6U4MNI=\ngithub.com/hashicorp/consul/api v1.3.0/go.mod h1:MmDNSzIMUjNpY/mQ398R4bk2FnqQLoPndWW5VkKPlCE=\ngithub.com/hashicorp/consul/api v1.8.1 h1:BOEQaMWoGMhmQ29fC26bi0qb7/rId9JzZP2V0Xmx7m8=\ngithub.com/hashicorp/consul/api v1.8.1/go.mod h1:sDjTOq0yUyv5G4h+BqSea7Fn6BU+XbolEz1952UB+mk=\ngithub.com/hashicorp/consul/sdk v0.3.0/go.mod h1:VKf9jXwCTEY1QZP2MOLRhb5i/I/ssyNV1vwHyQBF0x8=\ngithub.com/hashicorp/consul/sdk v0.7.0 h1:H6R9d008jDcHPQPAqPNuydAshJ4v5/8URdFnUvK/+sc=\ngithub.com/hashicorp/consul/sdk v0.7.0/go.mod h1:fY08Y9z5SvJqevyZNy6WWPXiG3KwBPAvlcdx16zZ0fM=\ngithub.com/hashicorp/errwrap v1.0.0 h1:hLrqtEDnRye3+sgx6z4qVLNuviH3MR5aQ0ykNJa/UYA=\ngithub.com/hashicorp/errwrap v1.0.0/go.mod h1:YH+1FKiLXxHSkmPseP+kNlulaMuP3n2brvKWEqk/Jc4=\ngithub.com/hashicorp/go-cleanhttp v0.5.0/go.mod h1:JpRdi6/HCYpAwUzNwuwqhbovhLtngrth3wmdIIUrZ80=\ngithub.com/hashicorp/go-cleanhttp v0.5.1 h1:dH3aiDG9Jvb5r5+bYHsikaOUIpcM0xvgMXVoDkXMzJM=\ngithub.com/hashicorp/go-cleanhttp v0.5.1/go.mod h1:JpRdi6/HCYpAwUzNwuwqhbovhLtngrth3wmdIIUrZ80=\ngithub.com/hashicorp/go-hclog v0.0.0-20180709165350-ff2cf002a8dd/go.mod h1:9bjs9uLqI8l75knNv3lV1kA55veR+WUPSiKIWcQHudI=\ngithub.com/hashicorp/go-hclog v0.8.0/go.mod h1:5CU+agLiy3J7N7QjHK5d05KxGsuXiQLrjA0H7acj2lQ=\ngithub.com/hashicorp/go-hclog v0.9.2/go.mod h1:5CU+agLiy3J7N7QjHK5d05KxGsuXiQLrjA0H7acj2lQ=\ngithub.com/hashicorp/go-hclog v0.12.0/go.mod h1:whpDNt7SSdeAju8AWKIWsul05p54N/39EeqMAyrmvFQ=\ngithub.com/hashicorp/go-hclog v0.14.1 h1:nQcJDQwIAGnmoUWp8ubocEX40cCml/17YkF6csQLReU=\ngithub.com/hashicorp/go-hclog v0.14.1/go.mod h1:whpDNt7SSdeAju8AWKIWsul05p54N/39EeqMAyrmvFQ=\ngithub.com/hashicorp/go-immutable-radix v1.0.0/go.mod h1:0y9vanUI8NX6FsYoO3zeMjhV/C5i9g4Q3DwcSNZ4P60=\ngithub.com/hashicorp/go-immutable-radix v1.3.0 h1:8exGP7ego3OmkfksihtSouGMZ+hQrhxx+FVELeXpVPE=\ngithub.com/hashicorp/go-immutable-radix v1.3.0/go.mod h1:0y9vanUI8NX6FsYoO3zeMjhV/C5i9g4Q3DwcSNZ4P60=\ngithub.com/hashicorp/go-msgpack v0.0.0-20150518234257-fa3f63826f7c/go.mod h1:ahLV/dePpqEmjfWmKiqvPkv/twdG7iPBM1vqhUKIvfM=\ngithub.com/hashicorp/go-msgpack v0.5.3/go.mod h1:ahLV/dePpqEmjfWmKiqvPkv/twdG7iPBM1vqhUKIvfM=\ngithub.com/hashicorp/go-msgpack v1.1.5 h1:9byZdVjKTe5mce63pRVNP1L7UAmdHOTEMGehn6KvJWs=\ngithub.com/hashicorp/go-msgpack v1.1.5/go.mod h1:gWVc3sv/wbDmR3rQsj1CAktEZzoz1YNK9NfGLXJ69/4=\ngithub.com/hashicorp/go-multierror v1.0.0/go.mod h1:dHtQlpGsu+cZNNAkkCN/P3hoUDHhCYQXV3UM06sGGrk=\ngithub.com/hashicorp/go-multierror v1.1.0/go.mod h1:spPvp8C1qA32ftKqdAHm4hHTbPw+vmowP0z+KUhOZdA=\ngithub.com/hashicorp/go-multierror v1.1.1 h1:H5DkEtf6CXdFp0N0Em5UCwQpXMWke8IA0+lD48awMYo=\ngithub.com/hashicorp/go-multierror v1.1.1/go.mod h1:iw975J/qwKPdAO1clOe2L8331t/9/fmwbPZ6JB6eMoM=\ngithub.com/hashicorp/go-plugin v1.0.0/go.mod h1:++UyYGoz3o5w9ZzAdZxtQKrWWP+iqPBn3cQptSMzBuY=\ngithub.com/hashicorp/go-retryablehttp v0.5.3/go.mod h1:9B5zBasrRhHXnJnui7y6sL7es7NDiJgTc6Er0maI1Xs=\ngithub.com/hashicorp/go-retryablehttp v0.6.4/go.mod h1:vAew36LZh98gCBJNLH42IQ1ER/9wtLZZ8meHqQvEYWY=\ngithub.com/hashicorp/go-rootcerts v1.0.0/go.mod h1:K6zTfqpRlCUIjkwsN4Z+hiSfzSTQa6eBIzfwKfwNnHU=\ngithub.com/hashicorp/go-rootcerts v1.0.2 h1:jzhAVGtqPKbwpyCPELlgNWhE1znq+qwJtW5Oi2viEzc=\ngithub.com/hashicorp/go-rootcerts v1.0.2/go.mod h1:pqUvnprVnM5bf7AOirdbb01K4ccR319Vf4pU3K5EGc8=\ngithub.com/hashicorp/go-sockaddr v1.0.0/go.mod h1:7Xibr9yA9JjQq1JpNB2Vw7kxv8xerXegt+ozgdvDeDU=\ngithub.com/hashicorp/go-sockaddr v1.0.2 h1:ztczhD1jLxIRjVejw8gFomI1BQZOe2WoVOu0SyteCQc=\ngithub.com/hashicorp/go-sockaddr v1.0.2/go.mod h1:rB4wwRAUzs07qva3c5SdrY/NEtAUjGlgmH/UkBUC97A=\ngithub.com/hashicorp/go-syslog v1.0.0/go.mod h1:qPfqrKkXGihmCqbJM2mZgkZGvKG1dFdvsLplgctolz4=\ngithub.com/hashicorp/go-uuid v1.0.0/go.mod h1:6SBZvOh/SIDV7/2o3Jml5SYk/TvGqwFJ/bN7x4byOro=\ngithub.com/hashicorp/go-uuid v1.0.1/go.mod h1:6SBZvOh/SIDV7/2o3Jml5SYk/TvGqwFJ/bN7x4byOro=\ngithub.com/hashicorp/go-uuid v1.0.2/go.mod h1:6SBZvOh/SIDV7/2o3Jml5SYk/TvGqwFJ/bN7x4byOro=\ngithub.com/hashicorp/go-uuid v1.0.3 h1:2gKiV6YVmrJ1i2CKKa9obLvRieoRGviZFL26PcT/Co8=\ngithub.com/hashicorp/go-uuid v1.0.3/go.mod h1:6SBZvOh/SIDV7/2o3Jml5SYk/TvGqwFJ/bN7x4byOro=\ngithub.com/hashicorp/go-version v1.1.0/go.mod h1:fltr4n8CU8Ke44wwGCBoEymUuxUHl09ZGVZPK5anwXA=\ngithub.com/hashicorp/go-version v1.2.0/go.mod h1:fltr4n8CU8Ke44wwGCBoEymUuxUHl09ZGVZPK5anwXA=\ngithub.com/hashicorp/go.net v0.0.1/go.mod h1:hjKkEWcCURg++eb33jQU7oqQcI9XDCnUzHA0oac0k90=\ngithub.com/hashicorp/golang-lru v0.5.0/go.mod h1:/m3WP610KZHVQ1SGc6re/UDhFvYD7pJ4Ao+sR/qLZy8=\ngithub.com/hashicorp/golang-lru v0.5.1/go.mod h1:/m3WP610KZHVQ1SGc6re/UDhFvYD7pJ4Ao+sR/qLZy8=\ngithub.com/hashicorp/golang-lru v0.5.4 h1:YDjusn29QI/Das2iO9M0BHnIbxPeyuCHsjMW+lJfyTc=\ngithub.com/hashicorp/golang-lru v0.5.4/go.mod h1:iADmTwqILo4mZ8BN3D2Q6+9jd8WM5uGBxy+E8yxSoD4=\ngithub.com/hashicorp/hcl v1.0.0 h1:0Anlzjpi4vEasTeNFn2mLJgTSwt0+6sfsiTG8qcWGx4=\ngithub.com/hashicorp/hcl v1.0.0/go.mod h1:E5yfLk+7swimpb2L/Alb/PJmXilQ/rhwaUYs4T20WEQ=\ngithub.com/hashicorp/logutils v1.0.0/go.mod h1:QIAnNjmIWmVIIkWDTG1z5v++HQmx9WQRO+LraFDTW64=\ngithub.com/hashicorp/mdns v1.0.0/go.mod h1:tL+uN++7HEJ6SQLQ2/p+z2pH24WQKWjBPkE0mNTz8vQ=\ngithub.com/hashicorp/mdns v1.0.1/go.mod h1:4gW7WsVCke5TE7EPeYliwHlRUyBtfCwuFwuMg2DmyNY=\ngithub.com/hashicorp/memberlist v0.1.3/go.mod h1:ajVTdAv/9Im8oMAAj5G31PhhMCZJV2pPBoIllUwCN7I=\ngithub.com/hashicorp/memberlist v0.2.2 h1:5+RffWKwqJ71YPu9mWsF7ZOscZmwfasdA8kbdC7AO2g=\ngithub.com/hashicorp/memberlist v0.2.2/go.mod h1:MS2lj3INKhZjWNqd3N0m3J+Jxf3DAOnAH9VT3Sh9MUE=\ngithub.com/hashicorp/raft v1.0.0 h1:htBVktAOtGs4Le5Z7K8SF5H2+oWsQFYVmOgH5loro7Y=\ngithub.com/hashicorp/raft v1.0.0/go.mod h1:DVSAWItjLjTOkVbSpWQ0j0kUADIvDaCtBxIcbNAQLkI=\ngithub.com/hashicorp/serf v0.8.2/go.mod h1:6hOLApaqBFA1NXqRQAsxw9QxuDEvNxSQRwA/JwenrHc=\ngithub.com/hashicorp/serf v0.9.5 h1:EBWvyu9tcRszt3Bxp3KNssBMP1KuHWyO51lz9+786iM=\ngithub.com/hashicorp/serf v0.9.5/go.mod h1:UWDWwZeL5cuWDJdl0C6wrvrUwEqtQ4ZKBKKENpqIUyk=\ngithub.com/hashicorp/vault/api v1.0.2/go.mod h1:AV/+M5VPDpB90arloVX0rVDUIHkONiwz5Uza9HRtpUE=\ngithub.com/hashicorp/vault/sdk v0.1.8/go.mod h1:tHZfc6St71twLizWNHvnnbiGFo1aq0eD2jGPLtP8kAU=\ngithub.com/hashicorp/yamux v0.0.0-20180604194846-3520598351bb/go.mod h1:+NfK9FKeTrX5uv1uIXGdwYDTeHna2qgaIlx54MXqjAM=\ngithub.com/hashicorp/yamux v0.0.0-20181012175058-2f1d1f20f75d/go.mod h1:+NfK9FKeTrX5uv1uIXGdwYDTeHna2qgaIlx54MXqjAM=\ngithub.com/hetznercloud/hcloud-go v1.24.0 h1:/CeHDzhH3Fhm83pjxvE3xNNLbvACl0Lu1/auJ83gG5U=\ngithub.com/hetznercloud/hcloud-go v1.24.0/go.mod h1:3YmyK8yaZZ48syie6xpm3dt26rtB6s65AisBHylXYFA=\ngithub.com/hinshun/vt10x v0.0.0-20180616224451-1954e6464174 h1:WlZsjVhE8Af9IcZDGgJGQpNflI3+MJSBhsgT5PCtzBQ=\ngithub.com/hinshun/vt10x v0.0.0-20180616224451-1954e6464174/go.mod h1:DqJ97dSdRW1W22yXSB90986pcOyQ7r45iio1KN2ez1A=\ngithub.com/howeyc/fsnotify v0.9.0/go.mod h1:41HzSPxBGeFRQKEEwgh49TRw/nKBsYZ2cF1OzPjSJsA=\ngithub.com/hpcloud/tail v1.0.0/go.mod h1:ab1qPbhIpdTxEkNHXyeSf5vhxWSCs/tWer42PpOxQnU=\ngithub.com/huandu/xstrings v1.0.0 h1:pO2K/gKgKaat5LdpAhxhluX2GPQMaI3W5FUz/I/UnWk=\ngithub.com/huandu/xstrings v1.0.0/go.mod h1:4qWG/gcEcfX4z/mBDHJ++3ReCw9ibxbsNJbcucJdbSo=\ngithub.com/hudl/fargo v1.3.0/go.mod h1:y3CKSmjA+wD2gak7sUSXTAoopbhU08POFhmITJgmKTg=\ngithub.com/ianlancetaylor/demangle v0.0.0-20181102032728-5e5cf60278f6/go.mod h1:aSSvb/t6k1mPoxDqO4vJh6VOCGPwU4O0C2/Eqndh1Sc=\ngithub.com/ianlancetaylor/demangle v0.0.0-20200824232613-28f6c0f3b639/go.mod h1:aSSvb/t6k1mPoxDqO4vJh6VOCGPwU4O0C2/Eqndh1Sc=\ngithub.com/imdario/mergo v0.3.4/go.mod h1:2EnlNZ0deacrJVfApfmtdGgDfMuh/nq6Ok1EcJh5FfA=\ngithub.com/imdario/mergo v0.3.5/go.mod h1:2EnlNZ0deacrJVfApfmtdGgDfMuh/nq6Ok1EcJh5FfA=\ngithub.com/imdario/mergo v0.3.9 h1:UauaLniWCFHWd+Jp9oCEkTBj8VO/9DKg3PV3VCNMDIg=\ngithub.com/imdario/mergo v0.3.9/go.mod h1:2EnlNZ0deacrJVfApfmtdGgDfMuh/nq6Ok1EcJh5FfA=\ngithub.com/inconshreveable/mousetrap v1.0.0 h1:Z8tu5sraLXCXIcARxBp/8cbvlwVa7Z1NHg9XEKhtSvM=\ngithub.com/inconshreveable/mousetrap v1.0.0/go.mod h1:PxqpIevigyE2G7u3NXJIT2ANytuPF1OarO4DADm73n8=\ngithub.com/influxdata/cron v0.0.0-20191203200038-ded12750aac6/go.mod h1:XabtPPW2qsCg0tl+kjaPU+cFS+CjQXEXbT1VJvHT4og=\ngithub.com/influxdata/cron v0.0.0-20201006132531-4bb0a200dcbe h1:7j4SdN/BvQwN6WoUq7mv0kg5U9NhnFBxPGMafYRKym0=\ngithub.com/influxdata/cron v0.0.0-20201006132531-4bb0a200dcbe/go.mod h1:XabtPPW2qsCg0tl+kjaPU+cFS+CjQXEXbT1VJvHT4og=\ngithub.com/influxdata/flux v0.65.1/go.mod h1:J754/zds0vvpfwuq7Gc2wRdVwEodfpCFM7mYlOw2LqY=\ngithub.com/influxdata/flux v0.114.1/go.mod h1:dfG4vbsLSehtyx2h75GQM64jiPx5IObAfSaVGYHjDrg=\ngithub.com/influxdata/flux v0.171.0 h1:9s0MA0bGXPRmzeAvZPYl1412qYSdeTNQb1cgW83nu2M=\ngithub.com/influxdata/flux v0.171.0/go.mod h1:fNtcZ8tqtVDjwWYcPRvCdlY5t3n+NYCc5xunKCmigQA=\ngithub.com/influxdata/gosnowflake v1.6.9 h1:BhE39Mmh8bC+Rvd4QQsP2gHypfeYIH1wqW1AjGWxxrE=\ngithub.com/influxdata/gosnowflake v1.6.9/go.mod h1:9W/BvCXOKx2gJtQ+jdi1Vudev9t9/UDOEHnlJZ/y1nU=\ngithub.com/influxdata/httprouter v1.3.1-0.20191122104820-ee83e2772f69 h1:WQsmW0fXO4ZE/lFGIE84G6rIV5SJN3P3sjIXAP1a8eU=\ngithub.com/influxdata/httprouter v1.3.1-0.20191122104820-ee83e2772f69/go.mod h1:pwymjR6SrP3gD3pRj9RJwdl1j5s3doEEV8gS4X9qSzA=\ngithub.com/influxdata/influx-cli/v2 v2.0.0-20210526124422-63da8eccbdb7 h1:9ibK8LdGVXx90F31gUpHYzCCwgjR9/WnZz5l/EK2gq0=\ngithub.com/influxdata/influx-cli/v2 v2.0.0-20210526124422-63da8eccbdb7/go.mod h1:A+JS4qejFQBmcfJIrYHVGejDcEOlcMVbCz4up86lAQ8=\ngithub.com/influxdata/influxdb v1.8.4/go.mod h1:JugdFhsvvI8gadxOI6noqNeeBHvWNTbfYGtiAn+2jhI=\ngithub.com/influxdata/influxdb v1.9.6 h1:S9Mdwp501HRUnX2in/hs7DoIyCrcF7asfnNq/v5EvZ8=\ngithub.com/influxdata/influxdb v1.9.6/go.mod h1:6waddyyJKoeLqfmLVrNxoOKxvQT/6t2Zuzdx8QyVcw4=\ngithub.com/influxdata/influxdb-client-go/v2 v2.3.1-0.20210518120617-5d1fff431040 h1:MBLCfcSsUyFPDJp6T7EoHp/Ph3Jkrm4EuUKLD2rUWHg=\ngithub.com/influxdata/influxdb-client-go/v2 v2.3.1-0.20210518120617-5d1fff431040/go.mod h1:vLNHdxTJkIf2mSLvGrpj8TCcISApPoXkaxP8g9uRlW8=\ngithub.com/influxdata/influxdb/v2 v2.0.1-alpha.10.0.20210507184756-dc72dc3f0c07 h1:ERHPVZofgMpPCS+vfWLOZk7UETeV/iVzsDhkEqkE8tY=\ngithub.com/influxdata/influxdb/v2 v2.0.1-alpha.10.0.20210507184756-dc72dc3f0c07/go.mod h1:JUtdw2axzK6sXrmCQ81TcK4yh7O94A3FFrwzm6xLwOI=\ngithub.com/influxdata/influxdb1-client v0.0.0-20191209144304-8bf82d3c094d/go.mod h1:qj24IKcXYK6Iy9ceXlo3Tc+vtHo9lIhSX5JddghvEPo=\ngithub.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6/go.mod h1:KpVI7okXjK6PRi3Z5B+mtKZli+R1DnZgb3N+tzevNgo=\ngithub.com/influxdata/influxql v1.1.1-0.20200828144457-65d3ef77d385/go.mod h1:gHp9y86a/pxhjJ+zMjNXiQAA197Xk9wLxaz+fGG+kWk=\ngithub.com/influxdata/influxql v1.1.1-0.20211004132434-7e7d61973256 h1:8io3jjCJ0j9NFvq3/m/rMrDiEILpsfOqWDPItUt/078=\ngithub.com/influxdata/influxql v1.1.1-0.20211004132434-7e7d61973256/go.mod h1:gHp9y86a/pxhjJ+zMjNXiQAA197Xk9wLxaz+fGG+kWk=\ngithub.com/influxdata/line-protocol v0.0.0-20180522152040-32c6aa80de5e/go.mod h1:4kt73NQhadE3daL3WhR5EJ/J2ocX0PZzwxQ0gXJ7oFE=\ngithub.com/influxdata/line-protocol v0.0.0-20200327222509-2487e7298839 h1:W9WBk7wlPfJLvMCdtV4zPulc4uCPrlywQOmbFOhgQNU=\ngithub.com/influxdata/line-protocol v0.0.0-20200327222509-2487e7298839/go.mod h1:xaLFMmpvUxqXtVkUJfg9QmT88cDaCJ3ZKgdZ78oO8Qo=\ngithub.com/influxdata/pkg-config v0.2.6/go.mod h1:EMS7Ll0S4qkzDk53XS3Z72/egBsPInt+BeRxb0WeSwk=\ngithub.com/influxdata/pkg-config v0.2.7/go.mod h1:EMS7Ll0S4qkzDk53XS3Z72/egBsPInt+BeRxb0WeSwk=\ngithub.com/influxdata/pkg-config v0.2.12 h1:KQ3Aw8ZEodq0uJwiNwc4d3wR2oGvr+HZ7RLF5rbgezk=\ngithub.com/influxdata/pkg-config v0.2.12/go.mod h1:EMS7Ll0S4qkzDk53XS3Z72/egBsPInt+BeRxb0WeSwk=\ngithub.com/influxdata/promql/v2 v2.12.0/go.mod h1:fxOPu+DY0bqCTCECchSRtWfc+0X19ybifQhZoQNF5D8=\ngithub.com/influxdata/roaring v0.4.13-0.20180809181101-fc520f41fab6 h1:UzJnB7VRL4PSkUJHwsyzseGOmrO/r4yA+AuxGJxiZmA=\ngithub.com/influxdata/roaring v0.4.13-0.20180809181101-fc520f41fab6/go.mod h1:bSgUQ7q5ZLSO+bKBGqJiCBGAl+9DxyW63zLTujjUlOE=\ngithub.com/influxdata/tdigest v0.0.0-20181121200506-bf2b5ad3c0a9/go.mod h1:Js0mqiSBE6Ffsg94weZZ2c+v/ciT8QRHFOap7EKDrR0=\ngithub.com/influxdata/tdigest v0.0.2-0.20210216194612-fc98d27c9e8b h1:i44CesU68ZBRvtCjBi3QSosCIKrjmMbYlQMFAwVLds4=\ngithub.com/influxdata/tdigest v0.0.2-0.20210216194612-fc98d27c9e8b/go.mod h1:Z0kXnxzbTC2qrx4NaIzYkE1k66+6oEDQTvL95hQFh5Y=\ngithub.com/influxdata/usage-client v0.0.0-20160829180054-6d3895376368 h1:+TUUmaFa4YD1Q+7bH9o5NCHQGPMqZCYJiNW6lIIS9z4=\ngithub.com/influxdata/usage-client v0.0.0-20160829180054-6d3895376368/go.mod h1:Wbbw6tYNvwa5dlB6304Sd+82Z3f7PmVZHVKU637d4po=\ngithub.com/influxdata/wlog v0.0.0-20160411224016-7c63b0a71ef8 h1:W2IgzRCb0L9VzMujq/QuTaZUKcH8096jWwP519mHN6Q=\ngithub.com/influxdata/wlog v0.0.0-20160411224016-7c63b0a71ef8/go.mod h1:/2NMgWB1DHM1ti/gqhOlg+LJeBVk6FqR5aVGYY0hlwI=\ngithub.com/jcmturner/aescts/v2 v2.0.0 h1:9YKLH6ey7H4eDBXW8khjYslgyqG2xZikXP0EQFKrle8=\ngithub.com/jcmturner/aescts/v2 v2.0.0/go.mod h1:AiaICIRyfYg35RUkr8yESTqvSy7csK90qZ5xfvvsoNs=\ngithub.com/jcmturner/dnsutils/v2 v2.0.0 h1:lltnkeZGL0wILNvrNiVCR6Ro5PGU/SeBvVO/8c/iPbo=\ngithub.com/jcmturner/dnsutils/v2 v2.0.0/go.mod h1:b0TnjGOvI/n42bZa+hmXL+kFJZsFT7G4t3HTlQ184QM=\ngithub.com/jcmturner/gofork v1.7.6 h1:QH0l3hzAU1tfT3rZCnW5zXl+orbkNMMRGJfdJjHVETg=\ngithub.com/jcmturner/gofork v1.7.6/go.mod h1:1622LH6i/EZqLloHfE7IeZ0uEJwMSUyQ/nDd82IeqRo=\ngithub.com/jcmturner/goidentity/v6 v6.0.1 h1:VKnZd2oEIMorCTsFBnJWbExfNN7yZr3EhJAxwOkZg6o=\ngithub.com/jcmturner/goidentity/v6 v6.0.1/go.mod h1:X1YW3bgtvwAXju7V3LCIMpY0Gbxyjn/mY9zx4tFonSg=\ngithub.com/jcmturner/gokrb5/v8 v8.4.4 h1:x1Sv4HaTpepFkXbt2IkL29DXRf8sOfZXo8eRKh687T8=\ngithub.com/jcmturner/gokrb5/v8 v8.4.4/go.mod h1:1btQEpgT6k+unzCwX1KdWMEwPPkkgBtP+F6aCACiMrs=\ngithub.com/jcmturner/rpc/v2 v2.0.3 h1:7FXXj8Ti1IaVFpSAziCZWNzbNuZmnvw/i6CqLNdWfZY=\ngithub.com/jcmturner/rpc/v2 v2.0.3/go.mod h1:VUJYCIDm3PVOEHw8sgt091/20OJjskO/YJki3ELg/Hc=\ngithub.com/jedib0t/go-pretty v4.3.0+incompatible h1:CGs8AVhEKg/n9YbUenWmNStRW2PHJzaeDodcfvRAbIo=\ngithub.com/jedib0t/go-pretty v4.3.0+incompatible/go.mod h1:XemHduiw8R651AF9Pt4FwCTKeG3oo7hrHJAoznj9nag=\ngithub.com/jessevdk/go-flags v1.4.0 h1:4IU2WS7AumrZ/40jfhf4QVDMsQwqA7VEHozFRrGARJA=\ngithub.com/jessevdk/go-flags v1.4.0/go.mod h1:4FA24M0QyGHXBuZZK/XkWh8h0e1EYbRYJSGM75WSRxI=\ngithub.com/jmespath/go-jmespath v0.0.0-20180206201540-c2b33e8439af/go.mod h1:Nht3zPeWKUH0NzdCt2Blrr5ys8VGpn0CEB0cQHVjt7k=\ngithub.com/jmespath/go-jmespath v0.4.0 h1:BEgLn5cpjn8UN1mAw4NjwDrS35OdebyEtFe+9YPoQUg=\ngithub.com/jmespath/go-jmespath v0.4.0/go.mod h1:T8mJZnbsbmF+m6zOOFylbeCJqk5+pHWvzYPziyZiYoo=\ngithub.com/jmespath/go-jmespath/internal/testify v1.5.1 h1:shLQSRRSCCPj3f2gpwzGwWFoC7ycTf1rcQZHOlsJ6N8=\ngithub.com/jmespath/go-jmespath/internal/testify v1.5.1/go.mod h1:L3OGu8Wl2/fWfCI6z80xFu9LTZmf1ZRjMHUOPmWr69U=\ngithub.com/joho/godotenv v1.3.0/go.mod h1:7hK45KPybAkOC6peb+G5yklZfMxEjkZhHbwpqxOKXbg=\ngithub.com/jonboulle/clockwork v0.1.0/go.mod h1:Ii8DK3G1RaLaWxj9trq07+26W01tbo22gdxWY5EU2bo=\ngithub.com/josharian/intern v1.0.0 h1:vlS4z54oSdjm0bgjRigI+G1HpF+tI+9rE5LLzOg8HmY=\ngithub.com/josharian/intern v1.0.0/go.mod h1:5DoeVV0s6jJacbCEi61lwdGj/aVlrQvzHFFd8Hwg//Y=\ngithub.com/jpillora/backoff v1.0.0 h1:uvFg412JmmHBHw7iwprIxkPMI+sGQ4kzOWsMeHnm2EA=\ngithub.com/jpillora/backoff v1.0.0/go.mod h1:J/6gKK9jxlEcS3zixgDgUAsiuZ7yrSoa/FX5e0EB2j4=\ngithub.com/json-iterator/go v1.1.6/go.mod h1:+SdeFBvtyEkXs7REEP0seUULqWtbJapLOCVDaaPEHmU=\ngithub.com/json-iterator/go v1.1.7/go.mod h1:KdQUCv79m/52Kvf8AW2vK1V8akMuk1QjK/uOdHXbAo4=\ngithub.com/json-iterator/go v1.1.8/go.mod h1:KdQUCv79m/52Kvf8AW2vK1V8akMuk1QjK/uOdHXbAo4=\ngithub.com/json-iterator/go v1.1.9/go.mod h1:KdQUCv79m/52Kvf8AW2vK1V8akMuk1QjK/uOdHXbAo4=\ngithub.com/json-iterator/go v1.1.10 h1:Kz6Cvnvv2wGdaG/V8yMvfkmNiXq9Ya2KUv4rouJJr68=\ngithub.com/json-iterator/go v1.1.10/go.mod h1:KdQUCv79m/52Kvf8AW2vK1V8akMuk1QjK/uOdHXbAo4=\ngithub.com/jstemmer/go-junit-report v0.0.0-20190106144839-af01ea7f8024/go.mod h1:6v2b51hI/fHJwM22ozAgKL4VKDeJcHhJFhtBdhmNjmU=\ngithub.com/jstemmer/go-junit-report v0.9.1/go.mod h1:Brl9GWCQeLvo8nXZwPNNblvFj/XSXhF0NWZEnDohbsk=\ngithub.com/jsternberg/zap-logfmt v1.0.0/go.mod h1:uvPs/4X51zdkcm5jXl5SYoN+4RK21K8mysFmDaM/h+o=\ngithub.com/jsternberg/zap-logfmt v1.2.0 h1:1v+PK4/B48cy8cfQbxL4FmmNZrjnIMr2BsnyEmXqv2o=\ngithub.com/jsternberg/zap-logfmt v1.2.0/go.mod h1:kz+1CUmCutPWABnNkOu9hOHKdT2q3TDYCcsFy9hpqb0=\ngithub.com/jtolds/gls v4.20.0+incompatible h1:xdiiI2gbIgH/gLH7ADydsJ1uDOEzR8yvV7C0MuV77Wo=\ngithub.com/jtolds/gls v4.20.0+incompatible/go.mod h1:QJZ7F/aHp+rZTRtaJ1ow/lLfFfVYBRgL+9YlvaHOwJU=\ngithub.com/julienschmidt/httprouter v1.2.0/go.mod h1:SYymIcj16QtmaHHD7aYtjjsJG7VTCxuUUipMqKk8s4w=\ngithub.com/julienschmidt/httprouter v1.3.0/go.mod h1:JR6WtHb+2LUe8TCKY3cZOxFyyO8IZAc4RVcycCCAKdM=\ngithub.com/jung-kurt/gofpdf v1.0.0/go.mod h1:7Id9E/uU8ce6rXgefFLlgrJj/GYY22cpxn+r32jIOes=\ngithub.com/jung-kurt/gofpdf v1.0.3-0.20190309125859-24315acbbda5/go.mod h1:7Id9E/uU8ce6rXgefFLlgrJj/GYY22cpxn+r32jIOes=\ngithub.com/jwilder/encoding v0.0.0-20170811194829-b4e1701a28ef h1:2jNeR4YUziVtswNP9sEFAI913cVrzH85T+8Q6LpYbT0=\ngithub.com/jwilder/encoding v0.0.0-20170811194829-b4e1701a28ef/go.mod h1:Ct9fl0F6iIOGgxJ5npU/IUOhOhqlVrGjyIZc8/MagT0=\ngithub.com/k-sone/snmpgo v3.2.0+incompatible h1:2NogYilKYSia0f+seO9P7aRa6MKG6RcnNc1L74L8WOw=\ngithub.com/k-sone/snmpgo v3.2.0+incompatible/go.mod h1:9MC6LeG1sGPgrwnmu/V/ncg9P2M5zS5IvE+c4KZj25g=\ngithub.com/k0kubun/colorstring v0.0.0-20150214042306-9440f1994b88/go.mod h1:3w7q1U84EfirKl04SVQ/s7nPm1ZPhiXd34z40TNz36k=\ngithub.com/karrick/godirwalk v1.8.0/go.mod h1:H5KPZjojv4lE+QYImBI8xVtrBRgYrIVsaRPx4tDPEn4=\ngithub.com/karrick/godirwalk v1.10.3/go.mod h1:RoGL9dQei4vP9ilrpETWE8CLOZ1kiN0LhBygSwrAsHA=\ngithub.com/kballard/go-shellquote v0.0.0-20180428030007-95032a82bc51 h1:Z9n2FFNUXsshfwJMBgNA0RU6/i7WVaAegv3PtuIHPMs=\ngithub.com/kballard/go-shellquote v0.0.0-20180428030007-95032a82bc51/go.mod h1:CzGEWj7cYgsdH8dAjBGEr58BoE7ScuLd+fwFZ44+/x8=\ngithub.com/kevinburke/go-bindata v3.11.0+incompatible h1:RcC+GJNmrBHbGaOpQ9MBD8z22rdzlIm0esDRDkyxd4s=\ngithub.com/kevinburke/go-bindata v3.11.0+incompatible/go.mod h1:/pEEZ72flUW2p0yi30bslSp9YqD9pysLxunQDdb2CPM=\ngithub.com/kisielk/errcheck v1.1.0/go.mod h1:EZBBE59ingxPouuu3KfxchcWSUPOHkagtvWXihfKN4Q=\ngithub.com/kisielk/errcheck v1.2.0/go.mod h1:/BMXB+zMLi60iA8Vv6Ksmxu/1UDYcXs4uQLJ+jE2L00=\ngithub.com/kisielk/errcheck v1.5.0/go.mod h1:pFxgyoBC7bSaBwPgfKdkLd5X25qrDl4LWUI2bnpBCr8=\ngithub.com/kisielk/gotool v1.0.0/go.mod h1:XhKaO+MFFWcvkIS/tQcRk01m1F5IRFswLeQ+oQHNcck=\ngithub.com/klauspost/asmfmt v1.3.1/go.mod h1:AG8TuvYojzulgDAMCnYn50l/5QV3Bs/tp6j0HLHbNSE=\ngithub.com/klauspost/asmfmt v1.3.2 h1:4Ri7ox3EwapiOjCki+hw14RyKk201CN4rzyCJRFLpK4=\ngithub.com/klauspost/asmfmt v1.3.2/go.mod h1:AG8TuvYojzulgDAMCnYn50l/5QV3Bs/tp6j0HLHbNSE=\ngithub.com/klauspost/compress v1.4.0/go.mod h1:RyIbtBH6LamlWaDj8nUwkbUhJ87Yi3uG0guNDohfE1A=\ngithub.com/klauspost/compress v1.9.5/go.mod h1:RyIbtBH6LamlWaDj8nUwkbUhJ87Yi3uG0guNDohfE1A=\ngithub.com/klauspost/compress v1.9.8/go.mod h1:RyIbtBH6LamlWaDj8nUwkbUhJ87Yi3uG0guNDohfE1A=\ngithub.com/klauspost/compress v1.13.1/go.mod h1:8dP1Hq4DHOhN9w426knH3Rhby4rFm6D8eO+e+Dq5Gzg=\ngithub.com/klauspost/compress v1.13.6/go.mod h1:/3/Vjq9QcHkK5uEr5lBEmyoZ1iFhe47etQ6QUkpK6sk=\ngithub.com/klauspost/compress v1.17.9 h1:6KIumPrER1LHsvBVuDa0r5xaG0Es51mhhB9BQB2qeMA=\ngithub.com/klauspost/compress v1.17.9/go.mod h1:Di0epgTjJY877eYKx5yC51cX2A2Vl2ibi7bDH9ttBbw=\ngithub.com/klauspost/cpuid v0.0.0-20170728055534-ae7887de9fa5/go.mod h1:Pj4uuM528wm8OyEC2QMXAi2YiTZ96dNQPGgoMS4s3ek=\ngithub.com/klauspost/cpuid/v2 v2.0.9 h1:lgaqFMSdTdQYdZ04uHyN2d/eKdOMyi2YLSvlQIBFYa4=\ngithub.com/klauspost/cpuid/v2 v2.0.9/go.mod h1:FInQzS24/EEf25PyTYn52gqo7WaD8xa0213Md/qVLRg=\ngithub.com/klauspost/crc32 v0.0.0-20161016154125-cb6bfca970f6/go.mod h1:+ZoRqAPRLkC4NPOvfYeR5KNOrY6TD+/sAC3HXPZgDYg=\ngithub.com/klauspost/pgzip v1.0.2-0.20170402124221-0bf5dcad4ada/go.mod h1:Ch1tH69qFZu15pkjo5kYi6mth2Zzwzt50oCQKQE9RUs=\ngithub.com/konsorten/go-windows-terminal-sequences v1.0.1/go.mod h1:T0+1ngSBFLxvqU3pZ+m/2kptfBszLMUkC4ZK/EgS/cQ=\ngithub.com/konsorten/go-windows-terminal-sequences v1.0.2/go.mod h1:T0+1ngSBFLxvqU3pZ+m/2kptfBszLMUkC4ZK/EgS/cQ=\ngithub.com/konsorten/go-windows-terminal-sequences v1.0.3/go.mod h1:T0+1ngSBFLxvqU3pZ+m/2kptfBszLMUkC4ZK/EgS/cQ=\ngithub.com/kr/logfmt v0.0.0-20140226030751-b84e30acd515/go.mod h1:+0opPa2QZZtGFBFZlji/RkVcI2GknAs/DXo4wKdlNEc=\ngithub.com/kr/pretty v0.1.0/go.mod h1:dAy3ld7l9f0ibDNOQOHHMYYIIbhfbHSm3C4ZsoJORNo=\ngithub.com/kr/pretty v0.2.0/go.mod h1:ipq/a2n7PKx3OHsz4KJII5eveXtPO4qwEXGdVfWzfnI=\ngithub.com/kr/pretty v0.2.1/go.mod h1:ipq/a2n7PKx3OHsz4KJII5eveXtPO4qwEXGdVfWzfnI=\ngithub.com/kr/pretty v0.3.0 h1:WgNl7dwNpEZ6jJ9k1snq4pZsg7DOEN8hP9Xw0Tsjwk0=\ngithub.com/kr/pretty v0.3.0/go.mod h1:640gp4NfQd8pI5XOwp5fnNeVWj67G7CFk/SaSQn7NBk=\ngithub.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=\ngithub.com/kr/pty v1.1.4/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=\ngithub.com/kr/pty v1.1.5 h1:hyz3dwM5QLc1Rfoz4FuWJQG5BN7tc6K1MndAUnGpQr4=\ngithub.com/kr/pty v1.1.5/go.mod h1:9r2w37qlBe7rQ6e1fg1S/9xpWHSnaqNdHD3WcMdbPDA=\ngithub.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=\ngithub.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=\ngithub.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=\ngithub.com/kylelemons/godebug v1.1.0/go.mod h1:9/0rRGxNHcop5bhtWyNeEfOS8JIWk580+fNqagV/RAw=\ngithub.com/labstack/echo/v4 v4.2.1/go.mod h1:AA49e0DZ8kk5jTOOCKNuPR6oTnBS0dYiM4FW1e6jwpg=\ngithub.com/labstack/gommon v0.3.0/go.mod h1:MULnywXg0yavhxWKc+lOruYdAhDwPK9wf0OL7NoOu+k=\ngithub.com/lib/pq v1.0.0/go.mod h1:5WUZQaWbwv1U+lTReE5YruASi9Al49XbQIvNi/34Woo=\ngithub.com/lib/pq v1.2.0 h1:LXpIM/LZ5xGFhOpXAQUIMM1HdyqzVYM13zNdjCEEcA0=\ngithub.com/lib/pq v1.2.0/go.mod h1:5WUZQaWbwv1U+lTReE5YruASi9Al49XbQIvNi/34Woo=\ngithub.com/lightstep/lightstep-tracer-common/golang/gogo v0.0.0-20190605223551-bc2310a04743/go.mod h1:qklhhLq1aX+mtWk9cPHPzaBjWImj5ULL6C7HFJtXQMM=\ngithub.com/lightstep/lightstep-tracer-go v0.18.1/go.mod h1:jlF1pusYV4pidLvZ+XD0UBX0ZE6WURAspgAczcDHrL4=\ngithub.com/lyft/protoc-gen-validate v0.0.13/go.mod h1:XbGvPuh87YZc5TdIa2/I4pLk0QoUACkjt2znoq26NVQ=\ngithub.com/magiconair/properties v1.8.0/go.mod h1:PppfXfuXeibc/6YijjN8zIbojt8czPbwD3XqdrwzmxQ=\ngithub.com/magiconair/properties v1.8.1 h1:ZC2Vc7/ZFkGmsVC9KvOjumD+G5lXy2RtTKyzRKO2BQ4=\ngithub.com/magiconair/properties v1.8.1/go.mod h1:PppfXfuXeibc/6YijjN8zIbojt8czPbwD3XqdrwzmxQ=\ngithub.com/mailru/easyjson v0.0.0-20180823135443-60711f1a8329/go.mod h1:C1wdFJiN94OJF2b5HbByQZoLdCWB1Yqtg26g4irojpc=\ngithub.com/mailru/easyjson v0.0.0-20190312143242-1de009706dbe/go.mod h1:C1wdFJiN94OJF2b5HbByQZoLdCWB1Yqtg26g4irojpc=\ngithub.com/mailru/easyjson v0.0.0-20190614124828-94de47d64c63/go.mod h1:C1wdFJiN94OJF2b5HbByQZoLdCWB1Yqtg26g4irojpc=\ngithub.com/mailru/easyjson v0.0.0-20190626092158-b2ccc519800e/go.mod h1:C1wdFJiN94OJF2b5HbByQZoLdCWB1Yqtg26g4irojpc=\ngithub.com/mailru/easyjson v0.7.0/go.mod h1:KAzv3t3aY1NaHWoQz1+4F1ccyAH66Jk7yos7ldAVICs=\ngithub.com/mailru/easyjson v0.7.1/go.mod h1:KAzv3t3aY1NaHWoQz1+4F1ccyAH66Jk7yos7ldAVICs=\ngithub.com/mailru/easyjson v0.7.6/go.mod h1:xzfreul335JAWq5oZzymOObrkdz5UnU4kGfJJLY9Nlc=\ngithub.com/mailru/easyjson v0.7.7 h1:UGYAvKxe3sBsEDzO8ZeWOSlIQfWFlxbzLZe7hwFURr0=\ngithub.com/mailru/easyjson v0.7.7/go.mod h1:xzfreul335JAWq5oZzymOObrkdz5UnU4kGfJJLY9Nlc=\ngithub.com/markbates/oncer v0.0.0-20181203154359-bf2de49a0be2/go.mod h1:Ld9puTsIW75CHf65OeIOkyKbteujpZVXDpWK6YGZbxE=\ngithub.com/markbates/safe v1.0.1/go.mod h1:nAqgmRi7cY2nqMc92/bSEeQA+R4OheNU2T1kNSCBdG0=\ngithub.com/matryer/moq v0.0.0-20190312154309-6cfb0558e1bd/go.mod h1:9ELz6aaclSIGnZBoaSLZ3NAl1VTufbOrXBPvtcy6WiQ=\ngithub.com/mattn/go-colorable v0.0.9/go.mod h1:9vuHe8Xs5qXnSaW/c/ABM9alt+Vo+STaOChaDxuIBZU=\ngithub.com/mattn/go-colorable v0.1.1/go.mod h1:FuOcm+DKB9mbwrcAfNl7/TZVBZ6rcnceauSikq3lYCQ=\ngithub.com/mattn/go-colorable v0.1.2/go.mod h1:U0ppj6V5qS13XJ6of8GYAs25YV2eR4EVcfRqFIhoBtE=\ngithub.com/mattn/go-colorable v0.1.4/go.mod h1:U0ppj6V5qS13XJ6of8GYAs25YV2eR4EVcfRqFIhoBtE=\ngithub.com/mattn/go-colorable v0.1.6/go.mod h1:u6P/XSegPjTcexA+o6vUJrdnUu04hMope9wVRipJSqc=\ngithub.com/mattn/go-colorable v0.1.7/go.mod h1:u6P/XSegPjTcexA+o6vUJrdnUu04hMope9wVRipJSqc=\ngithub.com/mattn/go-colorable v0.1.8 h1:c1ghPdyEDarC70ftn0y+A/Ee++9zz8ljHG1b13eJ0s8=\ngithub.com/mattn/go-colorable v0.1.8/go.mod h1:u6P/XSegPjTcexA+o6vUJrdnUu04hMope9wVRipJSqc=\ngithub.com/mattn/go-ieproxy v0.0.1 h1:qiyop7gCflfhwCzGyeT0gro3sF9AIg9HU98JORTkqfI=\ngithub.com/mattn/go-ieproxy v0.0.1/go.mod h1:pYabZ6IHcRpFh7vIaLfK7rdcWgFEb3SFJ6/gNWuh88E=\ngithub.com/mattn/go-isatty v0.0.3/go.mod h1:M+lRXTBqGeGNdLjl/ufCoiOlB5xdOkqRJdNxMWT7Zi4=\ngithub.com/mattn/go-isatty v0.0.4/go.mod h1:M+lRXTBqGeGNdLjl/ufCoiOlB5xdOkqRJdNxMWT7Zi4=\ngithub.com/mattn/go-isatty v0.0.5/go.mod h1:Iq45c/XA43vh69/j3iqttzPXn0bhXyGjM0Hdxcsrc5s=\ngithub.com/mattn/go-isatty v0.0.7/go.mod h1:Iq45c/XA43vh69/j3iqttzPXn0bhXyGjM0Hdxcsrc5s=\ngithub.com/mattn/go-isatty v0.0.8/go.mod h1:Iq45c/XA43vh69/j3iqttzPXn0bhXyGjM0Hdxcsrc5s=\ngithub.com/mattn/go-isatty v0.0.9/go.mod h1:YNRxwqDuOph6SZLI9vUUz6OYw3QyUt7WiY2yME+cCiQ=\ngithub.com/mattn/go-isatty v0.0.10/go.mod h1:qgIWMr58cqv1PHHyhnkY9lrL7etaEgOFcMEpPG5Rm84=\ngithub.com/mattn/go-isatty v0.0.11/go.mod h1:PhnuNfih5lzO57/f3n+odYbM4JtupLOxQOAqxQCu2WE=\ngithub.com/mattn/go-isatty v0.0.12/go.mod h1:cbi8OIDigv2wuxKPP5vlRcQ1OAZbq2CE4Kysco4FUpU=\ngithub.com/mattn/go-isatty v0.0.16 h1:bq3VjFmv/sOjHtdEhmkEV4x1AJtvUvOJ2PFAZ5+peKQ=\ngithub.com/mattn/go-isatty v0.0.16/go.mod h1:kYGgaQfpe5nmfYZH+SKPsOc2e4SrIfOl2e/yFXSvRLM=\ngithub.com/mattn/go-runewidth v0.0.2/go.mod h1:LwmH8dsx7+W8Uxz3IHJYH5QSwggIsqBzpuz5H//U1FU=\ngithub.com/mattn/go-runewidth v0.0.3/go.mod h1:LwmH8dsx7+W8Uxz3IHJYH5QSwggIsqBzpuz5H//U1FU=\ngithub.com/mattn/go-runewidth v0.0.7/go.mod h1:H031xJmbD/WCDINGzjvQ9THkh0rPKHF+m2gUSrubnMI=\ngithub.com/mattn/go-runewidth v0.0.9 h1:Lm995f3rfxdpd6TSmuVCHVb/QhupuXlYr8sCI/QdE+0=\ngithub.com/mattn/go-runewidth v0.0.9/go.mod h1:H031xJmbD/WCDINGzjvQ9THkh0rPKHF+m2gUSrubnMI=\ngithub.com/mattn/go-sqlite3 v1.11.0 h1:LDdKkqtYlom37fkvqs8rMPFKAMe8+SgjbwZ6ex1/A/Q=\ngithub.com/mattn/go-sqlite3 v1.11.0/go.mod h1:FPy6KqzDD04eiIsT53CuJW3U88zkxoIYsOqkbpncsNc=\ngithub.com/mattn/go-tty v0.0.0-20180907095812-13ff1204f104 h1:d8RFOZ2IiFtFWBcKEHAFYJcPTf0wY5q0exFNJZVWa1U=\ngithub.com/mattn/go-tty v0.0.0-20180907095812-13ff1204f104/go.mod h1:XPvLUNfbS4fJH25nqRHfWLMa1ONC8Amw+mIA639KxkE=\ngithub.com/matttproud/golang_protobuf_extensions v1.0.1 h1:4hp9jkHxhMHkqkrB3Ix0jegS5sx/RkqARlsWZ6pIwiU=\ngithub.com/matttproud/golang_protobuf_extensions v1.0.1/go.mod h1:D8He9yQNgCq6Z5Ld7szi9bcBfOoFv/3dc6xSMkL2PC0=\ngithub.com/mgutz/ansi v0.0.0-20170206155736-9520e82c474b h1:j7+1HpAFS1zy5+Q4qx1fWh90gTKwiN4QCGoY9TWyyO4=\ngithub.com/mgutz/ansi v0.0.0-20170206155736-9520e82c474b/go.mod h1:01TrycV0kFyexm33Z7vhZRXopbI8J3TDReVlkTgMUxE=\ngithub.com/miekg/dns v1.0.14/go.mod h1:W1PPwlIAgtquWBMBEV9nkV9Cazfe8ScdGz/Lj7v3Nrg=\ngithub.com/miekg/dns v1.1.22/go.mod h1:bPDLeHnStXmXAq1m/Ch/hvfNHr14JKNPMBo3VZKjuso=\ngithub.com/miekg/dns v1.1.26/go.mod h1:bPDLeHnStXmXAq1m/Ch/hvfNHr14JKNPMBo3VZKjuso=\ngithub.com/miekg/dns v1.1.41 h1:WMszZWJG0XmzbK9FEmzH2TVcqYzFesusSIB41b8KHxY=\ngithub.com/miekg/dns v1.1.41/go.mod h1:p6aan82bvRIyn+zDIv9xYNUpwa73JcSh9BKwknJysuI=\ngithub.com/mileusna/useragent v0.0.0-20190129205925-3e331f0949a5 h1:pXqZHmHOz6LN+zbbUgqyGgAWRnnZEI40IzG3tMsXcSI=\ngithub.com/mileusna/useragent v0.0.0-20190129205925-3e331f0949a5/go.mod h1:JWhYAp2EXqUtsxTKdeGlY8Wp44M7VxThC9FEoNGi2IE=\ngithub.com/minio/asm2plan9s v0.0.0-20200509001527-cdd76441f9d8 h1:AMFGa4R4MiIpspGNG7Z948v4n35fFGB3RR3G/ry4FWs=\ngithub.com/minio/asm2plan9s v0.0.0-20200509001527-cdd76441f9d8/go.mod h1:mC1jAcsrzbxHt8iiaC+zU4b1ylILSosueou12R++wfY=\ngithub.com/minio/c2goasm v0.0.0-20190812172519-36a3d3bbc4f3 h1:+n/aFZefKZp7spd8DFdX7uMikMLXX4oubIzJF4kv/wI=\ngithub.com/minio/c2goasm v0.0.0-20190812172519-36a3d3bbc4f3/go.mod h1:RagcQ7I8IeTMnF8JTXieKnO4Z6JCsikNEzj0DwauVzE=\ngithub.com/mitchellh/cli v1.0.0/go.mod h1:hNIlj7HEI86fIcpObd7a0FcrxTWetlwJDGcceTlRvqc=\ngithub.com/mitchellh/cli v1.1.0/go.mod h1:xcISNoH86gajksDmfB23e/pu+B+GeFRMYmoHXxx3xhI=\ngithub.com/mitchellh/copystructure v1.0.0 h1:Laisrj+bAB6b/yJwB5Bt3ITZhGJdqmxquMKeZ+mmkFQ=\ngithub.com/mitchellh/copystructure v1.0.0/go.mod h1:SNtv71yrdKgLRyLFxmLdkAbkKEFWgYaq1OVrnRcwhnw=\ngithub.com/mitchellh/go-homedir v1.0.0/go.mod h1:SfyaCUpYCn1Vlf4IUYiD9fPX4A5wJrkLzIz1N1q0pr0=\ngithub.com/mitchellh/go-homedir v1.1.0 h1:lukF9ziXFxDFPkA1vsr5zpc1XuPDn/wFntq5mG+4E0Y=\ngithub.com/mitchellh/go-homedir v1.1.0/go.mod h1:SfyaCUpYCn1Vlf4IUYiD9fPX4A5wJrkLzIz1N1q0pr0=\ngithub.com/mitchellh/go-testing-interface v0.0.0-20171004221916-a61a99592b77/go.mod h1:kRemZodwjscx+RGhAo8eIhFbs2+BFgRtFPeD/KE+zxI=\ngithub.com/mitchellh/go-testing-interface v1.0.0/go.mod h1:kRemZodwjscx+RGhAo8eIhFbs2+BFgRtFPeD/KE+zxI=\ngithub.com/mitchellh/go-testing-interface v1.14.0 h1:/x0XQ6h+3U3nAyk1yx+bHPURrKa9sVVvYbuqZ7pIAtI=\ngithub.com/mitchellh/go-testing-interface v1.14.0/go.mod h1:gfgS7OtZj6MA4U1UrDRp04twqAjfvlZyCfX3sDjEym8=\ngithub.com/mitchellh/go-wordwrap v1.0.0/go.mod h1:ZXFpozHsX6DPmq2I0TCekCxypsnAUbP2oI0UX1GXzOo=\ngithub.com/mitchellh/gox v0.4.0/go.mod h1:Sd9lOJ0+aimLBi73mGofS1ycjY8lL3uZM3JPS42BGNg=\ngithub.com/mitchellh/iochan v1.0.0/go.mod h1:JwYml1nuB7xOzsp52dPpHFffvOCDupsG0QubkSMEySY=\ngithub.com/mitchellh/mapstructure v0.0.0-20160808181253-ca63d7c062ee/go.mod h1:FVVH3fgwuzCH5S8UJGiWEs2h04kUh9fWfEaFds41c1Y=\ngithub.com/mitchellh/mapstructure v1.1.2/go.mod h1:FVVH3fgwuzCH5S8UJGiWEs2h04kUh9fWfEaFds41c1Y=\ngithub.com/mitchellh/mapstructure v1.3.2/go.mod h1:bFUtVrKA4DC2yAKiSyO/QUcy7e+RRV2QTWOzhPopBRo=\ngithub.com/mitchellh/mapstructure v1.3.3/go.mod h1:bFUtVrKA4DC2yAKiSyO/QUcy7e+RRV2QTWOzhPopBRo=\ngithub.com/mitchellh/mapstructure v1.4.0/go.mod h1:bFUtVrKA4DC2yAKiSyO/QUcy7e+RRV2QTWOzhPopBRo=\ngithub.com/mitchellh/mapstructure v1.4.1 h1:CpVNEelQCZBooIPDn+AR3NpivK/TIKU8bDxdASFVQag=\ngithub.com/mitchellh/mapstructure v1.4.1/go.mod h1:bFUtVrKA4DC2yAKiSyO/QUcy7e+RRV2QTWOzhPopBRo=\ngithub.com/mitchellh/reflectwalk v1.0.0/go.mod h1:mSTlrgnPZtwu0c4WaC2kGObEpuNDbx0jmZXqmk4esnw=\ngithub.com/mitchellh/reflectwalk v1.0.1 h1:FVzMWA5RllMAKIdUSC8mdWo3XtwoecrH79BY70sEEpE=\ngithub.com/mitchellh/reflectwalk v1.0.1/go.mod h1:mSTlrgnPZtwu0c4WaC2kGObEpuNDbx0jmZXqmk4esnw=\ngithub.com/mna/pigeon v1.0.1-0.20180808201053-bb0192cfc2ae h1:mQO+oxi0kpii/TX+ltfTCFuYkOjEn53JhaOObiMuvnk=\ngithub.com/mna/pigeon v1.0.1-0.20180808201053-bb0192cfc2ae/go.mod h1:Iym28+kJVnC1hfQvv5MUtI6AiFFzvQjHcvI4RFTG/04=\ngithub.com/moby/spdystream v0.2.0/go.mod h1:f7i0iNDQJ059oMTcWxx8MA/zKFIuD/lY+0GqbN2Wy8c=\ngithub.com/moby/term v0.0.0-20201216013528-df9cb8a40635/go.mod h1:FBS0z0QWA44HXygs7VXDUOGoN/1TV3RuWkLO04am3wc=\ngithub.com/modern-go/concurrent v0.0.0-20180228061459-e0a39a4cb421/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=\ngithub.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd h1:TRLaZ9cD/w8PVh93nsPXa1VrQ6jlwL5oN8l14QlcNfg=\ngithub.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=\ngithub.com/modern-go/reflect2 v0.0.0-20180701023420-4b7aa43c6742/go.mod h1:bx2lNnkwVCuqBIxFjflWJWanXIb3RllmbCylyMrvgv0=\ngithub.com/modern-go/reflect2 v1.0.1 h1:9f412s+6RmYXLWZSEzVVgPGK7C2PphHj5RJrvfx9AWI=\ngithub.com/modern-go/reflect2 v1.0.1/go.mod h1:bx2lNnkwVCuqBIxFjflWJWanXIb3RllmbCylyMrvgv0=\ngithub.com/montanaflynn/stats v0.0.0-20171201202039-1bf9dbcd8cbe/go.mod h1:wL8QJuTMNUDYhXwkmfOly8iTdp5TEcJFWZD2D7SIkUc=\ngithub.com/morikuni/aec v1.0.0/go.mod h1:BbKIizmSmc5MMPqRYbxO4ZU0S0+P200+tUnFx7PXmsc=\ngithub.com/mschoch/smat v0.0.0-20160514031455-90eadee771ae h1:VeRdUYdCw49yizlSbMEn2SZ+gT+3IUKx8BqxyQdz+BY=\ngithub.com/mschoch/smat v0.0.0-20160514031455-90eadee771ae/go.mod h1:qAyveg+e4CE+eKJXWVjKXM4ck2QobLqTDytGJbLLhJg=\ngithub.com/munnerz/goautoneg v0.0.0-20120707110453-a547fc61f48d/go.mod h1:+n7T8mK8HuQTcFwEeznm/DIxMOiR9yIdICNftLE1DvQ=\ngithub.com/mwitkow/go-conntrack v0.0.0-20161129095857-cc309e4a2223/go.mod h1:qRWi+5nqEBWmkhHvq77mSJWrCKwh8bxhgT7d/eI7P4U=\ngithub.com/mwitkow/go-conntrack v0.0.0-20190716064945-2f068394615f h1:KUppIJq7/+SVif2QVs3tOP0zanoHgBEVAwHxUSIzRqU=\ngithub.com/mwitkow/go-conntrack v0.0.0-20190716064945-2f068394615f/go.mod h1:qRWi+5nqEBWmkhHvq77mSJWrCKwh8bxhgT7d/eI7P4U=\ngithub.com/mxk/go-flowrate v0.0.0-20140419014527-cca7078d478f/go.mod h1:ZdcZmHo+o7JKHSa8/e818NopupXU1YMK5fe1lsApnBw=\ngithub.com/natefinch/lumberjack v2.0.0+incompatible h1:4QJd3OLAMgj7ph+yZTuX13Ld4UpgHp07nNdFX7mqFfM=\ngithub.com/natefinch/lumberjack v2.0.0+incompatible/go.mod h1:Wi9p2TTF5DG5oU+6YfsmYQpsTIOm0B1VNzQg9Mw6nPk=\ngithub.com/nats-io/gnatsd v1.3.0 h1:+5d80klu3QaJgNbdavVBjWJP7cHd11U2CLnRTFM9ICI=\ngithub.com/nats-io/gnatsd v1.3.0/go.mod h1:nqco77VO78hLCJpIcVfygDP2rPGfsEHkGTUk94uh5DQ=\ngithub.com/nats-io/go-nats v1.7.0 h1:oQOfHcLr8hb43QG8yeVyY2jtarIaTjOv41CGdF3tTvQ=\ngithub.com/nats-io/go-nats v1.7.0/go.mod h1:+t7RHT5ApZebkrQdnn6AhQJmhJJiKAvJUio1PiiCtj0=\ngithub.com/nats-io/go-nats-streaming v0.4.0 h1:00wOBnTKzZGvQOFRSxj18kUm4X2TvXzv8LS0skZegPc=\ngithub.com/nats-io/go-nats-streaming v0.4.0/go.mod h1:gfq4R3c9sKAINOpelo0gn/b9QDMBZnmrttcsNF+lqyo=\ngithub.com/nats-io/jwt v0.3.0/go.mod h1:fRYCDE99xlTsqUzISS1Bi75UBJ6ljOJQOAAu5VglpSg=\ngithub.com/nats-io/jwt v0.3.2/go.mod h1:/euKqTS1ZD+zzjYrY7pseZrTtWQSjujC7xjPc8wL6eU=\ngithub.com/nats-io/nats-server/v2 v2.1.2/go.mod h1:Afk+wRZqkMQs/p45uXdrVLuab3gwv3Z8C4HTBu8GD/k=\ngithub.com/nats-io/nats-streaming-server v0.11.2 h1:UCqZbfXUKs9Ejw7KiNaFZEbbiVbK7uA8jbK2TsdGbqg=\ngithub.com/nats-io/nats-streaming-server v0.11.2/go.mod h1:RyqtDJZvMZO66YmyjIYdIvS69zu/wDAkyNWa8PIUa5c=\ngithub.com/nats-io/nats.go v1.9.1/go.mod h1:ZjDU1L/7fJ09jvUSRVBR2e7+RnLiiIQyqyzEE/Zbp4w=\ngithub.com/nats-io/nkeys v0.0.2/go.mod h1:dab7URMsZm6Z/jp9Z5UGa87Uutgc2mVpXLC4B7TDb/4=\ngithub.com/nats-io/nkeys v0.1.0/go.mod h1:xpnFELMwJABBLVhffcfd1MZx6VsNRFpEugbxziKVo7w=\ngithub.com/nats-io/nkeys v0.1.3 h1:6JrEfig+HzTH85yxzhSVbjHRJv9cn0p6n3IngIcM5/k=\ngithub.com/nats-io/nkeys v0.1.3/go.mod h1:xpnFELMwJABBLVhffcfd1MZx6VsNRFpEugbxziKVo7w=\ngithub.com/nats-io/nuid v1.0.0/go.mod h1:19wcPz3Ph3q0Jbyiqsd0kePYG7A95tJPxeL+1OSON2c=\ngithub.com/nats-io/nuid v1.0.1 h1:5iA8DT8V7q8WK2EScv2padNa/rTESc1KdnPw4TC2paw=\ngithub.com/nats-io/nuid v1.0.1/go.mod h1:19wcPz3Ph3q0Jbyiqsd0kePYG7A95tJPxeL+1OSON2c=\ngithub.com/nbio/st v0.0.0-20140626010706-e9e8d9816f32 h1:W6apQkHrMkS0Muv8G/TipAy/FJl/rCYT0+EuS8+Z0z4=\ngithub.com/nbio/st v0.0.0-20140626010706-e9e8d9816f32/go.mod h1:9wM+0iRr9ahx58uYLpLIr5fm8diHn0JbqRycJi6w0Ms=\ngithub.com/niemeyer/pretty v0.0.0-20200227124842-a10e7caefd8e/go.mod h1:zD1mROLANZcx1PVRCS0qkT7pwLkGfwJo4zjcN/Tysno=\ngithub.com/nxadm/tail v1.4.4 h1:DQuhQpB1tVlglWS2hLQ5OV6B5r8aGxSrPc5Qo6uTN78=\ngithub.com/nxadm/tail v1.4.4/go.mod h1:kenIhsEOeOJmVchQTgglprH7qJGnHDVpk1VPCcaMI8A=\ngithub.com/oklog/oklog v0.3.2/go.mod h1:FCV+B7mhrz4o+ueLpx+KqkyXRGMWOYEvfiXtdGtbWGs=\ngithub.com/oklog/run v1.0.0/go.mod h1:dlhp/R75TPv97u0XWUtDeV/lRKWPKSdTuV0TZvrmrQA=\ngithub.com/oklog/run v1.1.0/go.mod h1:sVPdnTZT1zYwAJeCMu2Th4T21pA3FPOQRfWjQlk7DVU=\ngithub.com/oklog/ulid v1.3.1 h1:EGfNDEx6MqHz8B3uNV6QAib1UR2Lm97sHi3ocA6ESJ4=\ngithub.com/oklog/ulid v1.3.1/go.mod h1:CirwcVhetQ6Lv90oh/F+FBtV6XMibvdAFo93nm5qn4U=\ngithub.com/olekukonko/tablewriter v0.0.0-20170122224234-a0225b3f23b5/go.mod h1:vsDQFd/mU46D+Z4whnwzcISnGGzXWMclvtLoiIKAKIo=\ngithub.com/olekukonko/tablewriter v0.0.4/go.mod h1:zq6QwlOf5SlnkVbMSr5EoBv3636FWnp+qbPhuoO21uA=\ngithub.com/onsi/ginkgo v0.0.0-20170829012221-11459a886d9c/go.mod h1:lLunBs/Ym6LB5Z9jYTR76FiuTmxDTDusOGeTQH+WWjE=\ngithub.com/onsi/ginkgo v1.6.0/go.mod h1:lLunBs/Ym6LB5Z9jYTR76FiuTmxDTDusOGeTQH+WWjE=\ngithub.com/onsi/ginkgo v1.7.0/go.mod h1:lLunBs/Ym6LB5Z9jYTR76FiuTmxDTDusOGeTQH+WWjE=\ngithub.com/onsi/ginkgo v1.11.0/go.mod h1:lLunBs/Ym6LB5Z9jYTR76FiuTmxDTDusOGeTQH+WWjE=\ngithub.com/onsi/ginkgo v1.12.1/go.mod h1:zj2OWP4+oCPe1qIXoGWkgMRwljMUYCdkwsT2108oapk=\ngithub.com/onsi/ginkgo v1.14.2 h1:8mVmC9kjFFmA8H4pKMUhcblgifdkOIXPvbhN1T36q1M=\ngithub.com/onsi/ginkgo v1.14.2/go.mod h1:iSB4RoI2tjJc9BBv4NKIKWKya62Rps+oPG/Lv9klQyY=\ngithub.com/onsi/gomega v0.0.0-20170829124025-dcabb60a477c/go.mod h1:C1qb7wdrVGGVU+Z6iS04AVkA3Q65CEZX59MT0QO5uiA=\ngithub.com/onsi/gomega v1.4.3/go.mod h1:ex+gbHU/CVuBBDIJjb2X0qEXbFg53c61hWP/1CpauHY=\ngithub.com/onsi/gomega v1.5.0/go.mod h1:ex+gbHU/CVuBBDIJjb2X0qEXbFg53c61hWP/1CpauHY=\ngithub.com/onsi/gomega v1.7.0/go.mod h1:ex+gbHU/CVuBBDIJjb2X0qEXbFg53c61hWP/1CpauHY=\ngithub.com/onsi/gomega v1.7.1/go.mod h1:XdKZgCCFLUoM/7CFJVPcG8C1xQ1AJ0vpAezJrB7JYyY=\ngithub.com/onsi/gomega v1.8.1/go.mod h1:Ho0h+IUsWyvy1OpqCwxlQ/21gkhVunqlU8fDGcoTdcA=\ngithub.com/onsi/gomega v1.10.1/go.mod h1:iN09h71vgCQne3DLsj+A5owkum+a2tYe+TOCB1ybHNo=\ngithub.com/onsi/gomega v1.10.3 h1:gph6h/qe9GSUw1NhH1gp+qb+h8rXD8Cy60Z32Qw3ELA=\ngithub.com/onsi/gomega v1.10.3/go.mod h1:V9xEwhxec5O8UDM77eCW8vLymOMltsqPVYWrpDsH8xc=\ngithub.com/op/go-logging v0.0.0-20160315200505-970db520ece7/go.mod h1:HzydrMdWErDVzsI23lYNej1Htcns9BCg93Dk0bBINWk=\ngithub.com/opencontainers/go-digest v1.0.0-rc1/go.mod h1:cMLVZDEM3+U2I4VmLI6N8jQYUd2OVphdqWwCJHrFt2s=\ngithub.com/opencontainers/go-digest v1.0.0 h1:apOUWs51W5PlhuyGyz9FCeeBIOUDA/6nW8Oi/yOhh5U=\ngithub.com/opencontainers/go-digest v1.0.0/go.mod h1:0JzlMkj0TRzQZfJkVvzbP0HBR3IKzErnv2BNG4W4MAM=\ngithub.com/opencontainers/image-spec v1.0.1/go.mod h1:BtxoFyWECRxE4U/7sNtV5W15zMzWCbyJoFRP3s7yZA0=\ngithub.com/opencontainers/image-spec v1.0.2 h1:9yCKha/T5XdGtO0q9Q9a6T5NUCsTn/DrBg0D7ufOcFM=\ngithub.com/opencontainers/image-spec v1.0.2/go.mod h1:BtxoFyWECRxE4U/7sNtV5W15zMzWCbyJoFRP3s7yZA0=\ngithub.com/opentracing-contrib/go-observer v0.0.0-20170622124052-a52f23424492/go.mod h1:Ngi6UdF0k5OKD5t5wlmGhe/EDKPoUM3BXZSSfIuJbis=\ngithub.com/opentracing-contrib/go-stdlib v1.0.0/go.mod h1:qtI1ogk+2JhVPIXVc6q+NHziSmy2W5GbdQZFUHADCBU=\ngithub.com/opentracing/basictracer-go v1.0.0/go.mod h1:QfBfYuafItcjQuMwinw9GhYKwFXS9KnPs5lxoYwgW74=\ngithub.com/opentracing/opentracing-go v1.0.2/go.mod h1:UkNAQd3GIcIGf0SeVgPpRdFStlNbqXla1AfSYxPUl2o=\ngithub.com/opentracing/opentracing-go v1.0.3-0.20180606204148-bd9c31933947/go.mod h1:UkNAQd3GIcIGf0SeVgPpRdFStlNbqXla1AfSYxPUl2o=\ngithub.com/opentracing/opentracing-go v1.1.0/go.mod h1:UkNAQd3GIcIGf0SeVgPpRdFStlNbqXla1AfSYxPUl2o=\ngithub.com/opentracing/opentracing-go v1.2.0 h1:uEJPy/1a5RIPAJ0Ov+OIO8OxWu77jEv+1B0VhjKrZUs=\ngithub.com/opentracing/opentracing-go v1.2.0/go.mod h1:GxEUsuufX4nBwe+T+Wl9TAgYrxe9dPLANfrWvHYVTgc=\ngithub.com/openzipkin-contrib/zipkin-go-opentracing v0.4.5/go.mod h1:/wsWhb9smxSfWAKL3wpBW7V8scJMt8N8gnaMCS9E/cA=\ngithub.com/openzipkin/zipkin-go v0.1.6/go.mod h1:QgAqvLzwWbR/WpD4A3cGpPtJrZXNIiJc5AZX7/PBEpw=\ngithub.com/openzipkin/zipkin-go v0.2.1/go.mod h1:NaW6tEwdmWMaCDZzg8sh+IBNOxHMPnhQw8ySjnjRyN4=\ngithub.com/openzipkin/zipkin-go v0.2.2/go.mod h1:NaW6tEwdmWMaCDZzg8sh+IBNOxHMPnhQw8ySjnjRyN4=\ngithub.com/pact-foundation/pact-go v1.0.4/go.mod h1:uExwJY4kCzNPcHRj+hCR/HBbOOIwwtUjcrb0b5/5kLM=\ngithub.com/pascaldekloe/goe v0.0.0-20180627143212-57f6aae5913c/go.mod h1:lzWF7FIEvWOWxwDKqyGYQf6ZUaNfKdP144TG7ZOy1lc=\ngithub.com/pascaldekloe/goe v0.1.0 h1:cBOtyMzM9HTpWjXfbbunk26uA6nG3a8n06Wieeh0MwY=\ngithub.com/pascaldekloe/goe v0.1.0/go.mod h1:lzWF7FIEvWOWxwDKqyGYQf6ZUaNfKdP144TG7ZOy1lc=\ngithub.com/paulbellamy/ratecounter v0.2.0/go.mod h1:Hfx1hDpSGoqxkVVpBi/IlYD7kChlfo5C6hzIHwPqfFE=\ngithub.com/pborman/uuid v1.2.0/go.mod h1:X/NO0urCmaxf9VXbdlT7C2Yzkj2IKimNn4k+gtPdI/k=\ngithub.com/pelletier/go-toml v1.2.0/go.mod h1:5z9KED0ma1S8pY6P1sdut58dfprrGBbd/94hg7ilaic=\ngithub.com/pelletier/go-toml v1.4.0/go.mod h1:PN7xzY2wHTK0K9p34ErDQMlFxa51Fk0OUruD3k1mMwo=\ngithub.com/pelletier/go-toml v1.7.0 h1:7utD74fnzVc/cpcyy8sjrlFr5vYpypUixARcHIMIGuI=\ngithub.com/pelletier/go-toml v1.7.0/go.mod h1:vwGMzjaWMwyfHwgIBhI2YUM4fB6nL6lVAvS1LBMMhTE=\ngithub.com/performancecopilot/speed v3.0.0+incompatible/go.mod h1:/CLtqpZ5gBg1M9iaPbIdPPGyKcA8hKdoy6hAWba7Yac=\ngithub.com/peterbourgon/diskv v2.0.1+incompatible/go.mod h1:uqqh8zWWbv1HBMNONnaR/tNboyR3/BZd58JJSHlUSCU=\ngithub.com/peterh/liner v1.0.1-0.20180619022028-8c1271fcf47f/go.mod h1:xIteQHvHuaLYG9IFj6mSxM0fCKrs34IrEQUhOYuGPHc=\ngithub.com/philhofer/fwd v1.0.0 h1:UbZqGr5Y38ApvM/V/jEljVxwocdweyH+vmYvRPBnbqQ=\ngithub.com/philhofer/fwd v1.0.0/go.mod h1:gk3iGcWd9+svBvR0sR+KPcfE+RNWozjowpeBVG3ZVNU=\ngithub.com/phpdave11/gofpdf v1.4.2/go.mod h1:zpO6xFn9yxo3YLyMvW8HcKWVdbNqgIfOOp2dXMnm1mY=\ngithub.com/phpdave11/gofpdi v1.0.12/go.mod h1:vBmVV0Do6hSBHC8uKUQ71JGW+ZGQq74llk/7bXwjDoI=\ngithub.com/pierrec/lz4 v1.0.2-0.20190131084431-473cd7ce01a1/go.mod h1:3/3N9NVKO0jef7pBehbT1qWhCMrIgbYNnFAZCqQ5LRc=\ngithub.com/pierrec/lz4 v2.0.5+incompatible/go.mod h1:pdkljMzZIN41W+lC3N2tnIh5sFi+IEE17M5jbnwPHcY=\ngithub.com/pierrec/lz4 v2.6.1+incompatible h1:9UY3+iC23yxF0UfGaYrGplQ+79Rg+h/q9FV9ix19jjM=\ngithub.com/pierrec/lz4 v2.6.1+incompatible/go.mod h1:pdkljMzZIN41W+lC3N2tnIh5sFi+IEE17M5jbnwPHcY=\ngithub.com/pierrec/lz4/v4 v4.1.8/go.mod h1:gZWDp/Ze/IJXGXf23ltt2EXimqmTUXEy0GFuRQyBid4=\ngithub.com/pierrec/lz4/v4 v4.1.9/go.mod h1:gZWDp/Ze/IJXGXf23ltt2EXimqmTUXEy0GFuRQyBid4=\ngithub.com/pierrec/lz4/v4 v4.1.11/go.mod h1:gZWDp/Ze/IJXGXf23ltt2EXimqmTUXEy0GFuRQyBid4=\ngithub.com/pierrec/lz4/v4 v4.1.21 h1:yOVMLb6qSIDP67pl/5F7RepeKYu/VmTyEXvuMI5d9mQ=\ngithub.com/pierrec/lz4/v4 v4.1.21/go.mod h1:gZWDp/Ze/IJXGXf23ltt2EXimqmTUXEy0GFuRQyBid4=\ngithub.com/pkg/browser v0.0.0-20180916011732-0a3d74bf9ce4/go.mod h1:4OwLy04Bl9Ef3GJJCoec+30X3LQs/0/m4HFRt/2LUSA=\ngithub.com/pkg/browser v0.0.0-20210911075715-681adbf594b8 h1:KoWmjvw+nsYOo29YJK9vDA65RGE3NrOnUtO7a+RF9HU=\ngithub.com/pkg/browser v0.0.0-20210911075715-681adbf594b8/go.mod h1:HKlIX3XHQyzLZPlr7++PzdhaXEj94dEiJgZDTsxEqUI=\ngithub.com/pkg/errors v0.8.0/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pkg/errors v0.8.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pkg/errors v0.9.1 h1:FEBLx1zS214owpjy7qsBeixbURkuhQAwrK5UwLGTwt4=\ngithub.com/pkg/errors v0.9.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pkg/profile v1.2.1/go.mod h1:hJw3o1OdXxsrSjjVksARp5W95eeEaEfptyVZyv6JUPA=\ngithub.com/pkg/term v0.0.0-20180730021639-bffc007b7fd5 h1:tFwafIEMf0B7NlcxV/zJ6leBIa81D3hgGSgsE5hCkOQ=\ngithub.com/pkg/term v0.0.0-20180730021639-bffc007b7fd5/go.mod h1:eCbImbZ95eXtAUIbLAuAVnBnwf83mjf6QIVH8SHYwqQ=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/posener/complete v1.1.1/go.mod h1:em0nMJCgc9GFtwrmVmEMR/ZL6WyhyjMBndrE9hABlRI=\ngithub.com/posener/complete v1.2.3/go.mod h1:WZIdtGGp+qx0sLrYKtIRAruyNpv6hFCicSgv7Sy7s/s=\ngithub.com/prometheus/alertmanager v0.21.0/go.mod h1:h7tJ81NA0VLWvWEayi1QltevFkLF3KxmC/malTcT8Go=\ngithub.com/prometheus/client_golang v0.9.1/go.mod h1:7SWBe2y4D6OKWSNQJUaRYU/AaXPKyh/dDVn+NZz0KFw=\ngithub.com/prometheus/client_golang v0.9.3-0.20190127221311-3c4408c8b829/go.mod h1:p2iRAGwDERtqlqzRXnrOVns+ignqQo//hLXqYxZYVNs=\ngithub.com/prometheus/client_golang v0.9.3/go.mod h1:/TN21ttK/J9q6uSwhBd54HahCDft0ttaMvbicHlPoso=\ngithub.com/prometheus/client_golang v0.9.4/go.mod h1:oCXIBxdI62A4cR6aTRJCgetEjecSIYzOEaeAn4iYEpM=\ngithub.com/prometheus/client_golang v1.0.0/go.mod h1:db9x61etRT2tGnBNRi70OPL5FsnadC4Ky3P0J6CfImo=\ngithub.com/prometheus/client_golang v1.3.0/go.mod h1:hJaj2vgQTGQmVCsAACORcieXFeDPbaTKGT+JTgUa3og=\ngithub.com/prometheus/client_golang v1.4.0/go.mod h1:e9GMxYsXl05ICDXkRhurwBS4Q3OK1iX/F2sw+iXX5zU=\ngithub.com/prometheus/client_golang v1.5.1/go.mod h1:e9GMxYsXl05ICDXkRhurwBS4Q3OK1iX/F2sw+iXX5zU=\ngithub.com/prometheus/client_golang v1.6.0/go.mod h1:ZLOG9ck3JLRdB5MgO8f+lLTe83AXG6ro35rLTxvnIl4=\ngithub.com/prometheus/client_golang v1.7.1/go.mod h1:PY5Wy2awLA44sXw4AOSfFBetzPP4j5+D6mVACh+pe2M=\ngithub.com/prometheus/client_golang v1.10.0 h1:/o0BDeWzLWXNZ+4q5gXltUvaMpJqckTa+jTNoB+z4cg=\ngithub.com/prometheus/client_golang v1.10.0/go.mod h1:WJM3cc3yu7XKBKa/I8WeZm+V3eltZnBwfENSU7mdogU=\ngithub.com/prometheus/client_model v0.0.0-20180712105110-5c3871d89910/go.mod h1:MbSGuTsp3dbXC40dX6PRTWyKYBIrTGTE9sqQNg2J8bo=\ngithub.com/prometheus/client_model v0.0.0-20190115171406-56726106282f/go.mod h1:MbSGuTsp3dbXC40dX6PRTWyKYBIrTGTE9sqQNg2J8bo=\ngithub.com/prometheus/client_model v0.0.0-20190129233127-fd36f4220a90/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6Tm2C1GtYGdfGttqA=\ngithub.com/prometheus/client_model v0.0.0-20190812154241-14fe0d1b01d4/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6Tm2C1GtYGdfGttqA=\ngithub.com/prometheus/client_model v0.1.0/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6Tm2C1GtYGdfGttqA=\ngithub.com/prometheus/client_model v0.2.0 h1:uq5h0d+GuxiXLJLNABMgp2qUWDPiLvgCzz2dUR+/W/M=\ngithub.com/prometheus/client_model v0.2.0/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6Tm2C1GtYGdfGttqA=\ngithub.com/prometheus/common v0.0.0-20181113130724-41aa239b4cce/go.mod h1:daVV7qP5qjZbuso7PdcryaAu0sAZbrN9i7WWcTMWvro=\ngithub.com/prometheus/common v0.0.0-20181126121408-4724e9255275/go.mod h1:daVV7qP5qjZbuso7PdcryaAu0sAZbrN9i7WWcTMWvro=\ngithub.com/prometheus/common v0.2.0/go.mod h1:TNfzLD0ON7rHzMJeJkieUDPYmFC7Snx/y86RQel1bk4=\ngithub.com/prometheus/common v0.4.0/go.mod h1:TNfzLD0ON7rHzMJeJkieUDPYmFC7Snx/y86RQel1bk4=\ngithub.com/prometheus/common v0.4.1/go.mod h1:TNfzLD0ON7rHzMJeJkieUDPYmFC7Snx/y86RQel1bk4=\ngithub.com/prometheus/common v0.6.0/go.mod h1:eBmuwkDJBwy6iBfxCBob6t6dR6ENT/y+J+Zk0j9GMYc=\ngithub.com/prometheus/common v0.7.0/go.mod h1:DjGbpBbp5NYNiECxcL/VnbXCCaQpKd3tt26CguLLsqA=\ngithub.com/prometheus/common v0.9.1/go.mod h1:yhUN8i9wzaXS3w1O07YhxHEBxD+W35wd8bs7vj7HSQ4=\ngithub.com/prometheus/common v0.10.0/go.mod h1:Tlit/dnDKsSWFlCLTWaA1cyBgKHSMdTB80sz/V91rCo=\ngithub.com/prometheus/common v0.15.0/go.mod h1:U+gB1OBLb1lF3O42bTCL+FK18tX9Oar16Clt/msog/s=\ngithub.com/prometheus/common v0.18.0/go.mod h1:U+gB1OBLb1lF3O42bTCL+FK18tX9Oar16Clt/msog/s=\ngithub.com/prometheus/common v0.20.0 h1:pfeDeUdQcIxOMutNjCejsEFp7qeP+/iltHSSmLpE+hU=\ngithub.com/prometheus/common v0.20.0/go.mod h1:U+gB1OBLb1lF3O42bTCL+FK18tX9Oar16Clt/msog/s=\ngithub.com/prometheus/exporter-toolkit v0.5.1/go.mod h1:OCkM4805mmisBhLmVFw858QYi3v0wKdY6/UxrT0pZVg=\ngithub.com/prometheus/procfs v0.0.0-20181005140218-185b4288413d/go.mod h1:c3At6R/oaqEKCNdg8wHV1ftS6bRYblBhIjjI8uT2IGk=\ngithub.com/prometheus/procfs v0.0.0-20190117184657-bf6a532e95b1/go.mod h1:c3At6R/oaqEKCNdg8wHV1ftS6bRYblBhIjjI8uT2IGk=\ngithub.com/prometheus/procfs v0.0.0-20190507164030-5867b95ac084/go.mod h1:TjEm7ze935MbeOT/UhFTIMYKhuLP4wbCsTZCD3I8kEA=\ngithub.com/prometheus/procfs v0.0.2/go.mod h1:TjEm7ze935MbeOT/UhFTIMYKhuLP4wbCsTZCD3I8kEA=\ngithub.com/prometheus/procfs v0.0.8/go.mod h1:7Qr8sr6344vo1JqZ6HhLceV9o3AJ1Ff+GxbHq6oeK9A=\ngithub.com/prometheus/procfs v0.0.11/go.mod h1:lV6e/gmhEcM9IjHGsFOCxxuZ+z1YqCvr4OA4YeYWdaU=\ngithub.com/prometheus/procfs v0.1.3/go.mod h1:lV6e/gmhEcM9IjHGsFOCxxuZ+z1YqCvr4OA4YeYWdaU=\ngithub.com/prometheus/procfs v0.6.0 h1:mxy4L2jP6qMonqmq+aTtOx1ifVWUgG/TAmntgbh3xv4=\ngithub.com/prometheus/procfs v0.6.0/go.mod h1:cz+aTbrPOrUb4q7XlbU9ygM+/jj0fzG6c1xBZuNvfVA=\ngithub.com/prometheus/prom2json v1.1.0/go.mod h1:v7OY1795b9fEUZgq4UU2+15YjRv0LfpxKejIQCy3L7o=\ngithub.com/prometheus/prometheus v1.8.2-0.20210331101223-3cafc58827d1 h1:qHnjnMuVa8egkjH3KhD5PZxFKKtDchh/T6ygHSv14Fw=\ngithub.com/prometheus/prometheus v1.8.2-0.20210331101223-3cafc58827d1/go.mod h1:sf7j/iAbhZahjeC0s3wwMmp5dksrJ/Za1UKdR+j6Hmw=\ngithub.com/prometheus/tsdb v0.7.1/go.mod h1:qhTCs0VvXwvX/y3TZrWD7rabWM+ijKTux40TwIPHuXU=\ngithub.com/rcrowley/go-metrics v0.0.0-20181016184325-3113b8401b8a/go.mod h1:bCqnVzQkZxMG4s8nGwiZ5l3QUCyqpo9Y+/ZMZ9VjZe4=\ngithub.com/rcrowley/go-metrics v0.0.0-20201227073835-cf1acfcdf475 h1:N/ElC8H3+5XpJzTSTfLsJV/mx9Q9g7kxmchpfZyxgzM=\ngithub.com/rcrowley/go-metrics v0.0.0-20201227073835-cf1acfcdf475/go.mod h1:bCqnVzQkZxMG4s8nGwiZ5l3QUCyqpo9Y+/ZMZ9VjZe4=\ngithub.com/retailnext/hllpp v1.0.1-0.20180308014038-101a6d2f8b52/go.mod h1:RDpi1RftBQPUCDRw6SmxeaREsAaRKnOclghuzp/WRzc=\ngithub.com/rogpeppe/fastuuid v0.0.0-20150106093220-6724a57986af/go.mod h1:XWv6SoW27p1b0cqNHllgS5HIMJraePCO15w5zCzIWYg=\ngithub.com/rogpeppe/fastuuid v1.2.0/go.mod h1:jVj6XXZzXRy/MSR5jhDC/2q6DgLz+nrA6LYCDYWNEvQ=\ngithub.com/rogpeppe/go-internal v1.1.0/go.mod h1:M8bDsm7K2OlrFYOpmOWEs/qY81heoFRclV5y23lUDJ4=\ngithub.com/rogpeppe/go-internal v1.2.2/go.mod h1:M8bDsm7K2OlrFYOpmOWEs/qY81heoFRclV5y23lUDJ4=\ngithub.com/rogpeppe/go-internal v1.3.0/go.mod h1:M8bDsm7K2OlrFYOpmOWEs/qY81heoFRclV5y23lUDJ4=\ngithub.com/rogpeppe/go-internal v1.9.0 h1:73kH8U+JUqXU8lRuOHeVHaa/SZPifC7BkcraZVejAe8=\ngithub.com/rogpeppe/go-internal v1.9.0/go.mod h1:WtVeX8xhTBvf0smdhujwtBcq4Qrzq/fJaraNFVN+nFs=\ngithub.com/rs/cors v1.7.0/go.mod h1:gFx+x8UowdsKA9AchylcLynDq+nNFfI8FkUZdN/jGCU=\ngithub.com/rs/xid v1.2.1/go.mod h1:+uKXf+4Djp6Md1KODXJxgGQPKngRmWyn10oCKFzNHOQ=\ngithub.com/rs/zerolog v1.21.0/go.mod h1:ZPhntP/xmq1nnND05hhpAh2QMhSsA4UN3MGZ6O2J3hM=\ngithub.com/russross/blackfriday v1.5.2 h1:HyvC0ARfnZBqnXwABFeSZHpKvJHJJfPz81GNueLj0oo=\ngithub.com/russross/blackfriday v1.5.2/go.mod h1:JO/DiYxRf+HjHt06OyowR9PTA263kcR/rfWxYHBV53g=\ngithub.com/russross/blackfriday/v2 v2.0.1 h1:lPqVAte+HuHNfhJ/0LC98ESWRz8afy9tM/0RK8m9o+Q=\ngithub.com/russross/blackfriday/v2 v2.0.1/go.mod h1:+Rmxgy9KzJVeS9/2gXHxylqXiyQDYRxCVz55jmeOWTM=\ngithub.com/ruudk/golang-pdf417 v0.0.0-20181029194003-1af4ab5afa58/go.mod h1:6lfFZQK844Gfx8o5WFuvpxWRwnSoipWe/p622j1v06w=\ngithub.com/ryanuber/columnize v0.0.0-20160712163229-9b3edd62028f/go.mod h1:sm1tb6uqfes/u+d4ooFouqFdy9/2g9QGwK3SQygK0Ts=\ngithub.com/ryanuber/columnize v2.1.0+incompatible/go.mod h1:sm1tb6uqfes/u+d4ooFouqFdy9/2g9QGwK3SQygK0Ts=\ngithub.com/ryanuber/go-glob v1.0.0/go.mod h1:807d1WSdnB0XRJzKNil9Om6lcp/3a0v4qIHxIXzX/Yc=\ngithub.com/samuel/go-zookeeper v0.0.0-20190923202752-2cc03de413da/go.mod h1:gi+0XIa01GRL2eRQVjQkKGqKF3SF9vZR/HnPullcV2E=\ngithub.com/satori/go.uuid v1.2.0/go.mod h1:dA0hQrYB0VpLJoorglMZABFdXlWrHn1NEOzdhQKdks0=\ngithub.com/satori/go.uuid v1.2.1-0.20181028125025-b2ce2384e17b h1:gQZ0qzfKHQIybLANtM3mBXNUtOfsCFXeTsnBqCsx1KM=\ngithub.com/satori/go.uuid v1.2.1-0.20181028125025-b2ce2384e17b/go.mod h1:dA0hQrYB0VpLJoorglMZABFdXlWrHn1NEOzdhQKdks0=\ngithub.com/scaleway/scaleway-sdk-go v1.0.0-beta.7.0.20210223165440-c65ae3540d44 h1:3egqo0Vut6daANFm7tOXdNAa8v5/uLU+sgCJrc88Meo=\ngithub.com/scaleway/scaleway-sdk-go v1.0.0-beta.7.0.20210223165440-c65ae3540d44/go.mod h1:CJJ5VAbozOl0yEw7nHB9+7BXTJbIn6h7W+f6Gau5IP8=\ngithub.com/sean-/seed v0.0.0-20170313163322-e2103e2c3529 h1:nn5Wsu0esKSJiIVhscUtVbo7ada43DJhG55ua/hjS5I=\ngithub.com/sean-/seed v0.0.0-20170313163322-e2103e2c3529/go.mod h1:DxrIzT+xaE7yg65j358z/aeFdxmN0P9QXhEzd20vsDc=\ngithub.com/segmentio/kafka-go v0.1.0/go.mod h1:X6itGqS9L4jDletMsxZ7Dz+JFWxM6JHfPOCvTvk+EJo=\ngithub.com/segmentio/kafka-go v0.2.0/go.mod h1:X6itGqS9L4jDletMsxZ7Dz+JFWxM6JHfPOCvTvk+EJo=\ngithub.com/segmentio/kafka-go v0.3.10 h1:h/1aSu7gWp6DXLmp0csxm8wrYD6rRYyaqclu2aQ/PWo=\ngithub.com/segmentio/kafka-go v0.3.10/go.mod h1:8rEphJEczp+yDE/R5vwmaqZgF1wllrl4ioQcNKB8wVA=\ngithub.com/serenize/snaker v0.0.0-20161123064335-543781d2b79b h1:B6dcIy62mIVH3xZ+Alc5J4fLDWthEa1RPzK7L7/glTw=\ngithub.com/serenize/snaker v0.0.0-20161123064335-543781d2b79b/go.mod h1:Yow6lPLSAXx2ifx470yD/nUe22Dv5vBvxK/UK9UUTVs=\ngithub.com/sergi/go-diff v1.0.0 h1:Kpca3qRNrduNnOQeazBd0ysaKrUJiIuISHxogkT9RPQ=\ngithub.com/sergi/go-diff v1.0.0/go.mod h1:0CfEIISq7TuYL3j771MWULgwwjU+GofnZX9QAmXWZgo=\ngithub.com/shurcooL/go v0.0.0-20170331015642-20b4b0a35211 h1:+OTcQECFnrdh6oabESXRUNFuM3Ol347YZvD+sL/Nfv0=\ngithub.com/shurcooL/go v0.0.0-20170331015642-20b4b0a35211/go.mod h1:TDJrrUr11Vxrven61rcy3hJMUqaf/CLWYhHNPmT14Lk=\ngithub.com/shurcooL/httpfs v0.0.0-20190707220628-8d4bc4ba7749/go.mod h1:ZY1cvUeJuFPAdZ/B6v7RHavJWZn2YPVFQ1OSXhCGOkg=\ngithub.com/shurcooL/markdownfmt v0.0.0-20170214213350-10aae0a270ab h1:3IXOl4NXdcTFFqBEjb4YESwjBVIz0bRdk4gq1OZBCbA=\ngithub.com/shurcooL/markdownfmt v0.0.0-20170214213350-10aae0a270ab/go.mod h1:VG1x2wwXWWypMlh60na9fO4qoO7SNkZbDyeZp+/Pt4g=\ngithub.com/shurcooL/sanitized_anchor_name v1.0.0 h1:PdmoCO6wvbs+7yrJyMORt4/BmY5IYyJwS/kOiWx8mHo=\ngithub.com/shurcooL/sanitized_anchor_name v1.0.0/go.mod h1:1NzhyTcUVG4SuEtjjoZeVRXNmyL/1OwPU0+IJeTBvfc=\ngithub.com/shurcooL/vfsgen v0.0.0-20181202132449-6a9ea43bcacd/go.mod h1:TrYk7fJVaAttu97ZZKrO9UbRa8izdowaMIZcxYMbVaw=\ngithub.com/shurcooL/vfsgen v0.0.0-20200824052919-0d455de96546/go.mod h1:TrYk7fJVaAttu97ZZKrO9UbRa8izdowaMIZcxYMbVaw=\ngithub.com/sirupsen/logrus v1.2.0/go.mod h1:LxeOpSwHxABJmUn/MG1IvRgCAasNZTLOkJPxbbu5VWo=\ngithub.com/sirupsen/logrus v1.4.0/go.mod h1:LxeOpSwHxABJmUn/MG1IvRgCAasNZTLOkJPxbbu5VWo=\ngithub.com/sirupsen/logrus v1.4.1/go.mod h1:ni0Sbl8bgC9z8RoU9G6nDWqqs/fq4eDPysMBDgk/93Q=\ngithub.com/sirupsen/logrus v1.4.2/go.mod h1:tLMulIdttU9McNUspp0xgXVQah82FyeX6MwdIuYE2rE=\ngithub.com/sirupsen/logrus v1.6.0/go.mod h1:7uNnSEd1DgxDLC74fIahvMZmmYsHGZGEOFrfsX/uA88=\ngithub.com/sirupsen/logrus v1.8.1 h1:dJKuHgqk1NNQlqoA6BTlM1Wf9DOH3NBjQyu0h9+AZZE=\ngithub.com/sirupsen/logrus v1.8.1/go.mod h1:yWOB1SBYBC5VeMP7gHvWumXLIWorT60ONWic61uBYv0=\ngithub.com/smartystreets/assertions v0.0.0-20180927180507-b2de0cb4f26d/go.mod h1:OnSkiWE9lh6wB0YB77sQom3nweQdgAjqCqsofrRNTgc=\ngithub.com/smartystreets/assertions v1.0.1 h1:voD4ITNjPL5jjBfgR/r8fPIIBrliWrWHeiJApdr3r4w=\ngithub.com/smartystreets/assertions v1.0.1/go.mod h1:kHHU4qYBaI3q23Pp3VPrmWhuIUrLW/7eUrw0BU5VaoM=\ngithub.com/smartystreets/goconvey v0.0.0-20190330032615-68dc04aab96a/go.mod h1:syvi0/a8iFYH4r/RixwvyeAJjdLS9QV7WQ/tjFTllLA=\ngithub.com/smartystreets/goconvey v0.0.0-20190731233626-505e41936337/go.mod h1:syvi0/a8iFYH4r/RixwvyeAJjdLS9QV7WQ/tjFTllLA=\ngithub.com/smartystreets/goconvey v1.6.4 h1:fv0U8FUIMPNf1L9lnHLvLhgicrIVChEkdzIKYqbNC9s=\ngithub.com/smartystreets/goconvey v1.6.4/go.mod h1:syvi0/a8iFYH4r/RixwvyeAJjdLS9QV7WQ/tjFTllLA=\ngithub.com/snowflakedb/gosnowflake v1.3.4/go.mod h1:NsRq2QeiMUuoNUJhp5Q6xGC4uBrsS9g6LwZVEkTWgsE=\ngithub.com/soheilhy/cmux v0.1.4/go.mod h1:IM3LyeVVIOuxMH7sFAkER9+bJ4dT7Ms6E4xg4kGIyLM=\ngithub.com/sony/gobreaker v0.4.1/go.mod h1:ZKptC7FHNvhBz7dN2LGjPVBz2sZJmc0/PkyDJOjmxWY=\ngithub.com/spaolacci/murmur3 v0.0.0-20180118202830-f09979ecbc72 h1:qLC7fQah7D6K1B0ujays3HV9gkFtllcxhzImRR7ArPQ=\ngithub.com/spaolacci/murmur3 v0.0.0-20180118202830-f09979ecbc72/go.mod h1:JwIasOWyU6f++ZhiEuf87xNszmSA2myDM2Kzu9HwQUA=\ngithub.com/spf13/afero v1.1.2/go.mod h1:j4pytiNVoe2o6bmDsKpLACNPDBIoEAkihy7loJ1B0CQ=\ngithub.com/spf13/afero v1.2.2 h1:5jhuqJyZCZf2JRofRvN/nIFgIWNzPa3/Vz8mYylgbWc=\ngithub.com/spf13/afero v1.2.2/go.mod h1:9ZxEEn6pIJ8Rxe320qSDBk6AsU0r9pR7Q4OcevTdifk=\ngithub.com/spf13/cast v1.3.0 h1:oget//CVOEoFewqQxwr0Ej5yjygnqGkvggSE/gB35Q8=\ngithub.com/spf13/cast v1.3.0/go.mod h1:Qx5cxh0v+4UWYiBimWS+eyWzqEqokIECu5etghLkUJE=\ngithub.com/spf13/cobra v0.0.3/go.mod h1:1l0Ry5zgKvJasoi3XT1TypsSe7PqH0Sj9dhYf7v3XqQ=\ngithub.com/spf13/cobra v0.0.5/go.mod h1:3K3wKZymM7VvHMDS9+Akkh4K60UwM26emMESw8tLCHU=\ngithub.com/spf13/cobra v1.0.0 h1:6m/oheQuQ13N9ks4hubMG6BnvwOeaJrqSPLahSnczz8=\ngithub.com/spf13/cobra v1.0.0/go.mod h1:/6GTrnGXV9HjY+aR4k0oJ5tcvakLuG6EuKReYlHNrgE=\ngithub.com/spf13/jwalterweatherman v1.0.0 h1:XHEdyB+EcvlqZamSM4ZOMGlc93t6AcsBEu9Gc1vn7yk=\ngithub.com/spf13/jwalterweatherman v1.0.0/go.mod h1:cQK4TGJAtQXfYWX+Ddv3mKDzgVb68N+wFjFa4jdeBTo=\ngithub.com/spf13/pflag v0.0.0-20170130214245-9ff6c6923cff/go.mod h1:DYY7MBk1bdzusC3SYhjObp+wFpr4gzcvqqNjLnInEg4=\ngithub.com/spf13/pflag v1.0.1/go.mod h1:DYY7MBk1bdzusC3SYhjObp+wFpr4gzcvqqNjLnInEg4=\ngithub.com/spf13/pflag v1.0.3/go.mod h1:DYY7MBk1bdzusC3SYhjObp+wFpr4gzcvqqNjLnInEg4=\ngithub.com/spf13/pflag v1.0.5 h1:iy+VFUOCP1a+8yFto/drg2CJ5u0yRoB7fZw3DKv/JXA=\ngithub.com/spf13/pflag v1.0.5/go.mod h1:McXfInJRrz4CZXVZOBLb0bTZqETkiAhM9Iw0y3An2Bg=\ngithub.com/spf13/viper v1.3.2/go.mod h1:ZiWeW+zYFKm7srdB9IoDzzZXaJaI5eL9QjNiN/DMA2s=\ngithub.com/spf13/viper v1.4.0/go.mod h1:PTJ7Z/lr49W6bUbkmS1V3by4uWynFiR9p7+dSq/yZzE=\ngithub.com/spf13/viper v1.6.1 h1:VPZzIkznI1YhVMRi6vNFLHSwhnhReBfgTxIPccpfdZk=\ngithub.com/spf13/viper v1.6.1/go.mod h1:t3iDnF5Jlj76alVNuyFBk5oUMCvsrkbvZK0WQdfDi5k=\ngithub.com/streadway/amqp v0.0.0-20190404075320-75d898a42a94/go.mod h1:AZpEONHx3DKn8O/DFsRAY58/XVQiIPMTMB1SddzLXVw=\ngithub.com/streadway/amqp v0.0.0-20190827072141-edfb9018d271/go.mod h1:AZpEONHx3DKn8O/DFsRAY58/XVQiIPMTMB1SddzLXVw=\ngithub.com/streadway/handy v0.0.0-20190108123426-d5acb3125c2a/go.mod h1:qNTQ5P5JnDBl6z3cMAg/SywNDC5ABu5ApDIw6lUbRmI=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.1.1/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.2.0/go.mod h1:qt09Ya8vawLte6SNmTgCsAVtYtaKzEcn8ATUoHMkEqE=\ngithub.com/stretchr/objx v0.4.0/go.mod h1:YvHI0jy2hoMjB+UWwv71VJQ9isScKT/TqJzVSSt89Yw=\ngithub.com/stretchr/objx v0.5.0/go.mod h1:Yh+to48EsGEfYuaHDzXPcE3xhTkx73EhmCGUpEOglKo=\ngithub.com/stretchr/objx v0.5.2 h1:xuMeJ0Sdp5ZMRXx/aWO6RZxdr3beISkG5/G/aIRr3pY=\ngithub.com/stretchr/objx v0.5.2/go.mod h1:FRsXN1f5AsAjCGJKqEizvkpNtU+EGNCLh3NxZ/8L+MA=\ngithub.com/stretchr/testify v1.2.0/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=\ngithub.com/stretchr/testify v1.2.1/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=\ngithub.com/stretchr/testify v1.2.2/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=\ngithub.com/stretchr/testify v1.3.0/go.mod h1:M5WIy9Dh21IEIfnGCwXGc5bZfKNJtfHm1UVUgZn+9EI=\ngithub.com/stretchr/testify v1.4.0/go.mod h1:j7eGeouHqKxXV5pUuKE4zz7dFj8WfuZ+81PSLYec5m4=\ngithub.com/stretchr/testify v1.5.1/go.mod h1:5W2xD1RspED5o8YsWQXVCued0rvSQ+mT+I5cxcmMvtA=\ngithub.com/stretchr/testify v1.6.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.7.0/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.7.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.8.0/go.mod h1:yNjHg4UonilssWZ8iaSj1OCr/vHnekPRkoO+kdMU+MU=\ngithub.com/stretchr/testify v1.8.1/go.mod h1:w2LPCIKwWwSfY2zedu0+kehJoqGctiVI29o6fzry7u4=\ngithub.com/stretchr/testify v1.8.2/go.mod h1:w2LPCIKwWwSfY2zedu0+kehJoqGctiVI29o6fzry7u4=\ngithub.com/stretchr/testify v1.9.0 h1:HtqpIVDClZ4nwg75+f6Lvsy/wHu+3BoSGCbBAcpTsTg=\ngithub.com/stretchr/testify v1.9.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=\ngithub.com/subosito/gotenv v1.2.0 h1:Slr1R9HxAlEKefgq5jn9U+DnETlIUa6HfgEzj0g5d7s=\ngithub.com/subosito/gotenv v1.2.0/go.mod h1:N0PQaV/YGNqwC0u51sEeR/aUtSLEXKX9iv69rRypqCw=\ngithub.com/tcnksm/go-input v0.0.0-20180404061846-548a7d7a8ee8/go.mod h1:IlWNj9v/13q7xFbaK4mbyzMNwrZLaWSHx/aibKIZuIg=\ngithub.com/testcontainers/testcontainers-go v0.0.0-20190108154635-47c0da630f72/go.mod h1:wt/nMz68+kIO4RoguOZzsdv1B3kTYw+SuIKyJYRQpgE=\ngithub.com/tidwall/pretty v1.0.0 h1:HsD+QiTn7sK6flMKIvNmpqz1qrpP3Ps6jOKIKMooyg4=\ngithub.com/tidwall/pretty v1.0.0/go.mod h1:XNkn88O1ChpSDQmQeStsy+sBenx6DDtFZJxhVysOjyk=\ngithub.com/tinylib/msgp v1.0.2/go.mod h1:+d+yLhGm8mzTaHzB+wgMYrodPfmZrzkirds8fDWklFE=\ngithub.com/tinylib/msgp v1.1.0 h1:9fQd+ICuRIu/ue4vxJZu6/LzxN0HwMds2nq/0cFvxHU=\ngithub.com/tinylib/msgp v1.1.0/go.mod h1:+d+yLhGm8mzTaHzB+wgMYrodPfmZrzkirds8fDWklFE=\ngithub.com/tmc/grpc-websocket-proxy v0.0.0-20170815181823-89b8d40f7ca8/go.mod h1:ncp9v5uamzpCO7NfCPTXjqaC+bZgJeR0sMTm6dMHP7U=\ngithub.com/tmc/grpc-websocket-proxy v0.0.0-20190109142713-0ad062ec5ee5/go.mod h1:ncp9v5uamzpCO7NfCPTXjqaC+bZgJeR0sMTm6dMHP7U=\ngithub.com/tv42/httpunix v0.0.0-20150427012821-b75d8614f926/go.mod h1:9ESjWnEqriFuLhtthL60Sar/7RFoluCcXsuvEwTV5KM=\ngithub.com/tylerb/graceful v1.2.15 h1:B0x01Y8fsJpogzZTkDg6BDi6eMf03s01lEKGdrv83oA=\ngithub.com/tylerb/graceful v1.2.15/go.mod h1:LPYTbOYmUTdabwRt0TGhLllQ0MUNbs0Y5q1WXJOI9II=\ngithub.com/uber-go/atomic v1.3.2/go.mod h1:/Ct5t2lcmbJ4OSe/waGBoaVvVqtO0bmtfVNex1PFV8g=\ngithub.com/uber-go/tally v3.3.15+incompatible/go.mod h1:YDTIBxdXyOU/sCWilKB4bgyufu1cEi0jdVnRdxvjnmU=\ngithub.com/uber-go/tally v3.3.17+incompatible h1:nFHIuW3VQ22wItiE9kPXic8dEgExWOsVOHwpmoIvsMw=\ngithub.com/uber-go/tally v3.3.17+incompatible/go.mod h1:YDTIBxdXyOU/sCWilKB4bgyufu1cEi0jdVnRdxvjnmU=\ngithub.com/uber/athenadriver v1.1.4/go.mod h1:tQjho4NzXw55LGfSZEcETuYydpY1vtmixUabHkC1K/E=\ngithub.com/uber/athenadriver v1.1.13 h1:h67yRqRl0Vj5f30bn6Nsn42bI08rY+yielMn1pdUhV0=\ngithub.com/uber/athenadriver v1.1.13/go.mod h1:mpa8cVqc/JH/xnViFoWFvNkoYyIj5ohn9mxAnBj3fik=\ngithub.com/uber/jaeger-client-go v2.16.0+incompatible/go.mod h1:WVhlPFC8FDjOFMMWRy2pZqQJSXxYSwNYOkTr/Z6d3Kk=\ngithub.com/uber/jaeger-client-go v2.25.0+incompatible/go.mod h1:WVhlPFC8FDjOFMMWRy2pZqQJSXxYSwNYOkTr/Z6d3Kk=\ngithub.com/uber/jaeger-client-go v2.28.0+incompatible h1:G4QSBfvPKvg5ZM2j9MrJFdfI5iSljY/WnJqOGFao6HI=\ngithub.com/uber/jaeger-client-go v2.28.0+incompatible/go.mod h1:WVhlPFC8FDjOFMMWRy2pZqQJSXxYSwNYOkTr/Z6d3Kk=\ngithub.com/uber/jaeger-lib v2.2.0+incompatible/go.mod h1:ComeNDZlWwrWnDv8aPp0Ba6+uUTzImX/AauajbLI56U=\ngithub.com/uber/jaeger-lib v2.4.0+incompatible/go.mod h1:ComeNDZlWwrWnDv8aPp0Ba6+uUTzImX/AauajbLI56U=\ngithub.com/uber/jaeger-lib v2.4.1+incompatible h1:td4jdvLcExb4cBISKIpHuGoVXh+dVKhn2Um6rjCsSsg=\ngithub.com/uber/jaeger-lib v2.4.1+incompatible/go.mod h1:ComeNDZlWwrWnDv8aPp0Ba6+uUTzImX/AauajbLI56U=\ngithub.com/ugorji/go v1.1.4/go.mod h1:uQMGLiO92mf5W77hV/PUCpI3pbzQx3CRekS0kk+RGrc=\ngithub.com/ugorji/go/codec v0.0.0-20181204163529-d75b2dcb6bc8/go.mod h1:VFNgLljTbGfSG7qAOspJ7OScBnGdDN/yBr0sguwnwf0=\ngithub.com/urfave/cli v1.20.0/go.mod h1:70zkFmudgCuE/ngEzBv17Jvp/497gISqfk5gWijbERA=\ngithub.com/urfave/cli v1.22.1/go.mod h1:Gos4lmkARVdJ6EkW0WaNv/tZAAMe9V7XWyB60NtXRu0=\ngithub.com/urfave/cli/v2 v2.3.0 h1:qph92Y649prgesehzOrQjdWyxFOp/QVM+6imKHad91M=\ngithub.com/urfave/cli/v2 v2.3.0/go.mod h1:LJmUH05zAU44vOAcrfzZQKsZbVcdbOG8rtL3/XcUArI=\ngithub.com/valyala/bytebufferpool v1.0.0/go.mod h1:6bBcMArwyJ5K/AmCkWv1jt77kVWyCJ6HpOuEn7z0Csc=\ngithub.com/valyala/fasttemplate v1.0.1/go.mod h1:UQGH1tvbgY+Nz5t2n7tXsz52dQxojPUpymEIMZ47gx8=\ngithub.com/valyala/fasttemplate v1.2.1/go.mod h1:KHLXt3tVN2HBp8eijSv/kGJopbvo7S+qRAEEKiv+SiQ=\ngithub.com/vektah/gqlparser v1.1.2/go.mod h1:1ycwN7Ij5njmMkPPAOaRFY4rET2Enx7IkVv3vaXspKw=\ngithub.com/vertica/vertica-sql-go v1.1.1 h1:sZYijzBbvdAbJcl4cYlKjR+Eh/X1hGKzukWuhh8PjvI=\ngithub.com/vertica/vertica-sql-go v1.1.1/go.mod h1:fGr44VWdEvL+f+Qt5LkKLOT7GoxaWdoUCnPBU9h6t04=\ngithub.com/willf/bitset v1.1.3/go.mod h1:RjeCKbqT1RxIR/KWY6phxZiaY1IyutSBfGjNPySAYV4=\ngithub.com/willf/bitset v1.1.9 h1:GBtFynGY9ZWZmEC9sWuu41/7VBXPFCOAbCbqTflOg9c=\ngithub.com/willf/bitset v1.1.9/go.mod h1:RjeCKbqT1RxIR/KWY6phxZiaY1IyutSBfGjNPySAYV4=\ngithub.com/xdg-go/pbkdf2 v1.0.0/go.mod h1:jrpuAogTd400dnrH08LKmI/xc1MbPOebTwRqcT5RDeI=\ngithub.com/xdg-go/scram v1.0.2/go.mod h1:1WAq6h33pAW+iRreB34OORO2Nf7qel3VV3fjBj+hCSs=\ngithub.com/xdg-go/stringprep v1.0.2/go.mod h1:8F9zXuvzgwmyT5DUm4GUfZGDdT3W+LCvS6+da4O5kxM=\ngithub.com/xdg/scram v0.0.0-20180814205039-7eeb5667e42c h1:u40Z8hqBAAQyv+vATcGgV0YCnDjqSL7/q/JyPhhJSPk=\ngithub.com/xdg/scram v0.0.0-20180814205039-7eeb5667e42c/go.mod h1:lB8K/P019DLNhemzwFU4jHLhdvlE6uDZjXFejJXr49I=\ngithub.com/xdg/stringprep v0.0.0-20180714160509-73f8eece6fdc/go.mod h1:Jhud4/sHMO4oL310DaZAKk9ZaJ08SJfe+sJh0HrGL1Y=\ngithub.com/xdg/stringprep v1.0.0 h1:d9X0esnoa3dFsV0FG35rAT0RIhYFlPq7MiP+DW89La0=\ngithub.com/xdg/stringprep v1.0.0/go.mod h1:Jhud4/sHMO4oL310DaZAKk9ZaJ08SJfe+sJh0HrGL1Y=\ngithub.com/xiang90/probing v0.0.0-20190116061207-43a291ad63a2/go.mod h1:UETIi67q53MR2AWcXfiuqkDkRtnGDLqkBTpCHuJHxtU=\ngithub.com/xlab/treeprint v0.0.0-20180616005107-d6fb6747feb6/go.mod h1:ce1O1j6UtZfjr22oyGxGLbauSBp2YVXpARAosm7dHBg=\ngithub.com/xlab/treeprint v1.0.0 h1:J0TkWtiuYgtdlrkkrDLISYBQ92M+X5m4LrIIMKrbDTs=\ngithub.com/xlab/treeprint v1.0.0/go.mod h1:IoImgRak9i3zJyuxOKUP1v4UZd1tMoKkq/Cimt1uhCg=\ngithub.com/xordataexchange/crypt v0.0.3-0.20170626215501-b2862e3d0a77/go.mod h1:aYKd//L2LvnjZzWKhF00oedf4jCCReLcmhLdhm1A27Q=\ngithub.com/xwb1989/sqlparser v0.0.0-20180606152119-120387863bf2 h1:zzrxE1FKn5ryBNl9eKOeqQ58Y/Qpo3Q9QNxKHX5uzzQ=\ngithub.com/xwb1989/sqlparser v0.0.0-20180606152119-120387863bf2/go.mod h1:hzfGeIUDq/j97IG+FhNqkowIyEcD88LrW6fyU3K3WqY=\ngithub.com/youmark/pkcs8 v0.0.0-20181117223130-1be2e3e5546d/go.mod h1:rHwXgn7JulP+udvsHwJoVG1YGAP6VLg4y9I5dyZdqmA=\ngithub.com/yudai/gojsondiff v1.0.0/go.mod h1:AY32+k2cwILAkW1fbgxQ5mUmMiZFgLIV+FBNExI05xg=\ngithub.com/yudai/golcs v0.0.0-20170316035057-ecda9a501e82/go.mod h1:lgjkn3NuSvDfVJdfcVVdX+jpBxNmX4rDAzaS45IcYoM=\ngithub.com/yudai/pp v2.0.1+incompatible/go.mod h1:PuxR/8QJ7cyCkFp/aUDS+JY727OFEZkTdatxwunjIkc=\ngithub.com/yuin/goldmark v1.1.25/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngithub.com/yuin/goldmark v1.1.27/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngithub.com/yuin/goldmark v1.1.32/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngithub.com/yuin/goldmark v1.2.1/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngithub.com/yuin/goldmark v1.3.5/go.mod h1:mwnBkeHKe2W/ZEtQ+71ViKU8L12m81fl3OWwC1Zlc8k=\ngithub.com/yuin/goldmark v1.4.13/go.mod h1:6yULJ656Px+3vBD8DxQVa3kxgyrAnzto9xy5taEt/CY=\ngithub.com/zeebo/assert v1.3.0 h1:g7C04CbJuIDKNPFHmsk4hwZDO5O+kntRxzaUoNXj+IQ=\ngithub.com/zeebo/assert v1.3.0/go.mod h1:Pq9JiuJQpG8JLJdtkwrJESF0Foym2/D9XMU5ciN/wJ0=\ngithub.com/zeebo/mwc v0.0.4 h1:9dNXNLtUB4lUXoXgyhy3YrKoV0OD7oRiu907YMS0nl0=\ngithub.com/zeebo/mwc v0.0.4/go.mod h1:qNHfgp/ZCpQNcJHwKcO5EP3VgaBrW6DPohsK4QfyxxE=\ngithub.com/zeebo/xxh3 v0.13.0/go.mod h1:AQY73TOrhF3jNsdiM9zZOb8MThrYbZONHj7ryDBaLpg=\ngithub.com/zeebo/xxh3 v1.0.2 h1:xZmwmqxHZA8AI603jOQ0tMqmBr9lPeFwGg6d+xy9DC0=\ngithub.com/zeebo/xxh3 v1.0.2/go.mod h1:5NWz9Sef7zIDm2JHfFlcQvNekmcEl9ekUZQQKCYaDcA=\ngo.etcd.io/bbolt v1.3.2/go.mod h1:IbVyRI1SCnLcuJnV2u8VeU0CEYM7e686BmAb1XKL+uU=\ngo.etcd.io/bbolt v1.3.3/go.mod h1:IbVyRI1SCnLcuJnV2u8VeU0CEYM7e686BmAb1XKL+uU=\ngo.etcd.io/bbolt v1.3.5/go.mod h1:G5EMThwa9y8QZGBClrRx5EY+Yw9kAhnjy3bSjsnlVTQ=\ngo.etcd.io/bbolt v1.3.7 h1:j+zJOnnEjF/kyHlDDgGnVL/AIqIJPq8UoB2GSNfkUfQ=\ngo.etcd.io/bbolt v1.3.7/go.mod h1:N9Mkw9X8x5fupy0IKsmuqVtoGDyxsaDlbk4Rd05IAQw=\ngo.etcd.io/etcd v0.0.0-20191023171146-3cf2f69b5738/go.mod h1:dnLIgRNXwCJa5e+c6mIZCrds/GIG4ncV9HhK5PX7jPg=\ngo.mongodb.org/mongo-driver v1.0.3/go.mod h1:u7ryQJ+DOzQmeO7zB6MHyr8jkEQvC8vH7qLUO4lqsUM=\ngo.mongodb.org/mongo-driver v1.1.1/go.mod h1:u7ryQJ+DOzQmeO7zB6MHyr8jkEQvC8vH7qLUO4lqsUM=\ngo.mongodb.org/mongo-driver v1.1.2/go.mod h1:u7ryQJ+DOzQmeO7zB6MHyr8jkEQvC8vH7qLUO4lqsUM=\ngo.mongodb.org/mongo-driver v1.3.0/go.mod h1:MSWZXKOynuguX+JSvwP8i+58jYCXxbia8HS3gZBapIE=\ngo.mongodb.org/mongo-driver v1.3.4/go.mod h1:MSWZXKOynuguX+JSvwP8i+58jYCXxbia8HS3gZBapIE=\ngo.mongodb.org/mongo-driver v1.4.3/go.mod h1:WcMNYLx/IlOxLe6JRJiv2uXuCz6zBLndR4SoGjYphSc=\ngo.mongodb.org/mongo-driver v1.4.4/go.mod h1:WcMNYLx/IlOxLe6JRJiv2uXuCz6zBLndR4SoGjYphSc=\ngo.mongodb.org/mongo-driver v1.4.6/go.mod h1:WcMNYLx/IlOxLe6JRJiv2uXuCz6zBLndR4SoGjYphSc=\ngo.mongodb.org/mongo-driver v1.5.1 h1:9nOVLGDfOaZ9R0tBumx/BcuqkbFpyTCU2r/Po7A2azI=\ngo.mongodb.org/mongo-driver v1.5.1/go.mod h1:gRXCHX4Jo7J0IJ1oDQyUxF7jfy19UfxniMS4xxMmUqw=\ngo.opencensus.io v0.20.1/go.mod h1:6WKK9ahsWS3RSO+PY9ZHZUfv2irvY6gN279GOPZjmmk=\ngo.opencensus.io v0.20.2/go.mod h1:6WKK9ahsWS3RSO+PY9ZHZUfv2irvY6gN279GOPZjmmk=\ngo.opencensus.io v0.21.0/go.mod h1:mSImk1erAIZhrmZN+AvHh14ztQfjbGwt4TtuofqLduU=\ngo.opencensus.io v0.22.0/go.mod h1:+kGneAE2xo2IficOXnaByMWTGM9T73dGwxeWcUqIpI8=\ngo.opencensus.io v0.22.2/go.mod h1:yxeiOL68Rb0Xd1ddK5vPZ/oVn4vY4Ynel7k9FzqtOIw=\ngo.opencensus.io v0.22.3/go.mod h1:yxeiOL68Rb0Xd1ddK5vPZ/oVn4vY4Ynel7k9FzqtOIw=\ngo.opencensus.io v0.22.4/go.mod h1:yxeiOL68Rb0Xd1ddK5vPZ/oVn4vY4Ynel7k9FzqtOIw=\ngo.opencensus.io v0.22.5/go.mod h1:5pWMHQbX5EPX2/62yrJeAkowc+lfs/XD7Uxpq3pI6kk=\ngo.opencensus.io v0.23.0/go.mod h1:XItmlyltB5F7CS4xOC1DcqMoFqwtC6OG2xF7mCv7P7E=\ngo.opencensus.io v0.24.0 h1:y73uSU6J157QMP2kn2r30vwW1A2W2WFwSCGnAVxeaD0=\ngo.opencensus.io v0.24.0/go.mod h1:vNK8G9p7aAivkbmorf4v+7Hgx+Zs0yY+0fOtgBfjQKo=\ngo.opentelemetry.io/otel v0.20.0/go.mod h1:Y3ugLH2oa81t5QO+Lty+zXf8zC9L26ax4Nzoxm/dooo=\ngo.opentelemetry.io/otel/metric v0.20.0/go.mod h1:598I5tYlH1vzBjn+BTuhzTCSb/9debfNp6R3s7Pr1eU=\ngo.opentelemetry.io/otel/oteltest v0.20.0/go.mod h1:L7bgKf9ZB7qCwT9Up7i9/pn0PWIa9FqQ2IQ8LoxiGnw=\ngo.opentelemetry.io/otel/sdk v0.20.0/go.mod h1:g/IcepuwNsoiX5Byy2nNV0ySUF1em498m7hBWC279Yc=\ngo.opentelemetry.io/otel/trace v0.20.0/go.mod h1:6GjCW8zgDjwGHGa6GkyeB8+/5vjT16gUEi0Nf1iBdgw=\ngo.opentelemetry.io/proto/otlp v0.7.0/go.mod h1:PqfVotwruBrMGOCsRd/89rSnXhoiJIqeYNgFYFoEGnI=\ngo.uber.org/atomic v1.3.2/go.mod h1:gD2HeocX3+yG+ygLZcrzQJaqmWj9AIm7n08wl/qW/PE=\ngo.uber.org/atomic v1.4.0/go.mod h1:gD2HeocX3+yG+ygLZcrzQJaqmWj9AIm7n08wl/qW/PE=\ngo.uber.org/atomic v1.5.0/go.mod h1:sABNBOSYdrvTF6hTgEIbc7YasKWGhgEQZyfxyTvoXHQ=\ngo.uber.org/atomic v1.5.1/go.mod h1:sABNBOSYdrvTF6hTgEIbc7YasKWGhgEQZyfxyTvoXHQ=\ngo.uber.org/atomic v1.6.0/go.mod h1:sABNBOSYdrvTF6hTgEIbc7YasKWGhgEQZyfxyTvoXHQ=\ngo.uber.org/atomic v1.7.0 h1:ADUqmZGgLDDfbSL9ZmPxKTybcoEYHgpYfELNoN+7hsw=\ngo.uber.org/atomic v1.7.0/go.mod h1:fEN4uk6kAWBTFdckzkM89CLk9XfWZrxpCo0nPH17wJc=\ngo.uber.org/config v1.4.0/go.mod h1:aCyrMHmUAc/s2h9sv1koP84M9ZF/4K+g2oleyESO/Ig=\ngo.uber.org/dig v1.9.0/go.mod h1:X34SnWGr8Fyla9zQNO2GSO2D+TIuqB14OS8JhYocIyw=\ngo.uber.org/fx v1.12.0/go.mod h1:egT3Kyg1JFYQkvKLZ3EsykxkNrZxgXS+gKoKo7abERY=\ngo.uber.org/goleak v0.10.0/go.mod h1:VCZuO8V8mFPlL0F5J5GK1rtHV3DrFcQ1R8ryq7FK0aI=\ngo.uber.org/goleak v1.1.10 h1:z+mqJhf6ss6BSfSM671tgKyZBFPTTJM+HLxnhPC3wu0=\ngo.uber.org/goleak v1.1.10/go.mod h1:8a7PlsEVH3e/a/GLqe5IIrQx6GzcnRmZEufDUTk4A7A=\ngo.uber.org/multierr v1.1.0/go.mod h1:wR5kodmAFQ0UK8QlbwjlSNy0Z68gJhDJUG5sjR94q/0=\ngo.uber.org/multierr v1.3.0/go.mod h1:VgVr7evmIr6uPjLBxg28wmKNXyqE9akIJ5XnfpiKl+4=\ngo.uber.org/multierr v1.4.0/go.mod h1:VgVr7evmIr6uPjLBxg28wmKNXyqE9akIJ5XnfpiKl+4=\ngo.uber.org/multierr v1.5.0/go.mod h1:FeouvMocqHpRaaGuG9EjoKcStLC43Zu/fmqdUMPcKYU=\ngo.uber.org/multierr v1.6.0 h1:y6IPFStTAIT5Ytl7/XYmHvzXQ7S3g/IeZW9hyZ5thw4=\ngo.uber.org/multierr v1.6.0/go.mod h1:cdWPpRnG4AhwMwsgIHip0KRBQjJy5kYEpYjJxpXp9iU=\ngo.uber.org/tools v0.0.0-20190618225709-2cfd321de3ee/go.mod h1:vJERXedbb3MVM5f9Ejo0C68/HhF8uaILCdgjnY+goOA=\ngo.uber.org/zap v1.9.1/go.mod h1:vwi/ZaCAaUcBkycHslxD9B2zi4UTXhF60s6SWpuDF0Q=\ngo.uber.org/zap v1.10.0/go.mod h1:vwi/ZaCAaUcBkycHslxD9B2zi4UTXhF60s6SWpuDF0Q=\ngo.uber.org/zap v1.13.0/go.mod h1:zwrFLgMcdUuIBviXEYEH1YKNaOBnKXsx2IPda5bBwHM=\ngo.uber.org/zap v1.14.0/go.mod h1:zwrFLgMcdUuIBviXEYEH1YKNaOBnKXsx2IPda5bBwHM=\ngo.uber.org/zap v1.14.1/go.mod h1:Mb2vm2krFEG5DV0W9qcHBYFtp/Wku1cvYaqPsS/WYfc=\ngo.uber.org/zap v1.15.0/go.mod h1:Mb2vm2krFEG5DV0W9qcHBYFtp/Wku1cvYaqPsS/WYfc=\ngo.uber.org/zap v1.16.0 h1:uFRZXykJGK9lLY4HtgSw44DnIcAM+kRBP7x5m+NpAOM=\ngo.uber.org/zap v1.16.0/go.mod h1:MA8QOfq0BHJwdXa996Y4dYkAqRKB8/1K1QMMZVaNZjQ=\ngolang.org/x/crypto v0.0.0-20180505025534-4ec37c66abab/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\ngolang.org/x/crypto v0.0.0-20180904163835-0709b304e793/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\ngolang.org/x/crypto v0.0.0-20181029021203-45a5f77698d3/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\ngolang.org/x/crypto v0.0.0-20181203042331-505ab145d0a9/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20190320223903-b7391e95e576/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20190325154230-a5d413f7728c/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20190422162423-af44ce270edf/go.mod h1:WFFai1msRO1wXaEeE5yQxYXgSfI8pQAWXbQop6sCtWE=\ngolang.org/x/crypto v0.0.0-20190506204251-e1dfcc566284/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20190510104115-cbcb75029529/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20190530122614-20be4c3c3ed5/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20190605123033-f99c8df09eb5/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20190611184440-5c40567a22f8/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20190617133340-57b3e21c3d56/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20190701094942-4def268fd1a4/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20190923035154-9ee001bba392/go.mod h1:/lpIB1dKB+9EgE3H3cr1v9wB50oz8l4C4h62xy7jSTY=\ngolang.org/x/crypto v0.0.0-20191011191535-87dc89f01550/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20191206172530-e9b2fee46413/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/crypto v0.0.0-20200302210943-78000ba7a073/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/crypto v0.0.0-20200622213623-75b288015ac9/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/crypto v0.0.0-20200820211705-5c72a883971a/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/crypto v0.0.0-20201002170205-7f63de1d35b0/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/crypto v0.0.0-20201208171446-5f87f3452ae9/go.mod h1:jdWPYTVW3xRLrWPugEBEK3UY2ZEsg3UU495nc5E+M+I=\ngolang.org/x/crypto v0.0.0-20201221181555-eec23a3978ad/go.mod h1:jdWPYTVW3xRLrWPugEBEK3UY2ZEsg3UU495nc5E+M+I=\ngolang.org/x/crypto v0.0.0-20210921155107-089bfa567519/go.mod h1:GvvjBRRGRdwPK5ydBHafDWAxML/pGHZbMvKqRZ5+Abc=\ngolang.org/x/crypto v0.0.0-20211117183948-ae814b36b871/go.mod h1:IxCIyHEi3zRg3s0A5j5BB6A9Jmi73HwBIUl50j+osU4=\ngolang.org/x/crypto v0.6.0/go.mod h1:OFC/31mSvZgRz0V1QTNCzfAI1aIRzbiufJtkMIlEp58=\ngolang.org/x/crypto v0.31.0 h1:ihbySMvVjLAeSH1IbfcRTkD/iNscyz8rGzjF/E5hV6U=\ngolang.org/x/crypto v0.31.0/go.mod h1:kDsLvtWBEx7MV9tJOj9bnXsPbxwJQ6csT/x4KIN4Ssk=\ngolang.org/x/exp v0.0.0-20180321215751-8460e604b9de/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\ngolang.org/x/exp v0.0.0-20180807140117-3d87b88a115f/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\ngolang.org/x/exp v0.0.0-20190121172915-509febef88a4/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\ngolang.org/x/exp v0.0.0-20190125153040-c74c464bbbf2/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\ngolang.org/x/exp v0.0.0-20190306152737-a1d7652674e8/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\ngolang.org/x/exp v0.0.0-20190510132918-efd6b22b2522/go.mod h1:ZjyILWgesfNpC6sMxTJOJm9Kp84zZh5NQWvqDGG3Qr8=\ngolang.org/x/exp v0.0.0-20190731235908-ec7cb31e5a56/go.mod h1:JhuoJpWY28nO4Vef9tZUw9qufEGTyX1+7lmHxV5q5G4=\ngolang.org/x/exp v0.0.0-20190829153037-c13cbed26979/go.mod h1:86+5VVa7VpoJ4kLfm080zCjGlMRFzhUhsZKEZO7MGek=\ngolang.org/x/exp v0.0.0-20191002040644-a1355ae1e2c3/go.mod h1:NOZ3BPKG0ec/BKJQgnvsSFpcKLM5xXVWnvZS97DWHgE=\ngolang.org/x/exp v0.0.0-20191030013958-a1ab85dbe136/go.mod h1:JXzH8nQsPlswgeRAPE3MuO9GYsAcnJvJ4vnMwN/5qkY=\ngolang.org/x/exp v0.0.0-20191129062945-2f5052295587/go.mod h1:2RIsYlXP63K8oxa1u096TMicItID8zy7Y6sNkU49FU4=\ngolang.org/x/exp v0.0.0-20191227195350-da58074b4299/go.mod h1:2RIsYlXP63K8oxa1u096TMicItID8zy7Y6sNkU49FU4=\ngolang.org/x/exp v0.0.0-20200119233911-0405dc783f0a/go.mod h1:2RIsYlXP63K8oxa1u096TMicItID8zy7Y6sNkU49FU4=\ngolang.org/x/exp v0.0.0-20200207192155-f17229e696bd/go.mod h1:J/WKrq2StrnmMY6+EHIKF9dgMWnmCNThgcyBT1FY9mM=\ngolang.org/x/exp v0.0.0-20200224162631-6cc2880d07d6/go.mod h1:3jZMyOhIsHpP37uCMkUooju7aAi5cS1Q23tOzKc+0MU=\ngolang.org/x/exp v0.0.0-20211028214138-64b4c8e87d1a/go.mod h1:a3o/VtDNHN+dCVLEpzjjUHOzR+Ln3DHX056ZPzoZGGA=\ngolang.org/x/exp v0.0.0-20220827204233-334a2380cb91 h1:tnebWN09GYg9OLPss1KXj8txwZc6X6uMr6VFdcGNbHw=\ngolang.org/x/exp v0.0.0-20220827204233-334a2380cb91/go.mod h1:cyybsKvd6eL0RnXn6p/Grxp8F5bW7iYuBgsNCOHpMYE=\ngolang.org/x/exp/typeparams v0.0.0-20221208152030-732eee02a75a h1:Jw5wfR+h9mnIYH+OtGT2im5wV1YGGDora5vTv/aa5bE=\ngolang.org/x/exp/typeparams v0.0.0-20221208152030-732eee02a75a/go.mod h1:AbB0pIl9nAr9wVwH+Z2ZpaocVmF5I4GyWCDIsVjR0bk=\ngolang.org/x/image v0.0.0-20180708004352-c73c2afc3b81/go.mod h1:ux5Hcp/YLpHSI86hEcLt0YII63i6oz57MZXIpbrjZUs=\ngolang.org/x/image v0.0.0-20190227222117-0694c2d4d067/go.mod h1:kZ7UVZpmo3dzQBMxlp+ypCbDeSB+sBbTgSJuh5dn5js=\ngolang.org/x/image v0.0.0-20190802002840-cff245a6509b/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\ngolang.org/x/image v0.0.0-20190910094157-69e4b8554b2a/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\ngolang.org/x/image v0.0.0-20200119044424-58c23975cae1/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\ngolang.org/x/image v0.0.0-20200430140353-33d19683fad8/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\ngolang.org/x/image v0.0.0-20200618115811-c13761719519/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\ngolang.org/x/image v0.0.0-20201208152932-35266b937fa6/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\ngolang.org/x/image v0.0.0-20210216034530-4410531fe030/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\ngolang.org/x/lint v0.0.0-20181026193005-c67002cb31c3/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=\ngolang.org/x/lint v0.0.0-20190227174305-5b3e6a55c961/go.mod h1:wehouNa3lNwaWXcvxsM5YxQ5yQlVC4a0KAMCusXpPoU=\ngolang.org/x/lint v0.0.0-20190301231843-5614ed5bae6f/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=\ngolang.org/x/lint v0.0.0-20190313153728-d0100b6bd8b3/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/lint v0.0.0-20190409202823-959b441ac422/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/lint v0.0.0-20190909230951-414d861bb4ac/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/lint v0.0.0-20190930215403-16217165b5de/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/lint v0.0.0-20191125180803-fdd1cda4f05f/go.mod h1:5qLYkcX4OjUUV8bRuDixDT3tpyyb+LUpUlRWLxfhWrs=\ngolang.org/x/lint v0.0.0-20200130185559-910be7a94367/go.mod h1:3xt1FjdF8hUf6vQPIChWIBhFzV8gjjsPE/fR3IyQdNY=\ngolang.org/x/lint v0.0.0-20200302205851-738671d3881b/go.mod h1:3xt1FjdF8hUf6vQPIChWIBhFzV8gjjsPE/fR3IyQdNY=\ngolang.org/x/lint v0.0.0-20201208152925-83fdc39ff7b5/go.mod h1:3xt1FjdF8hUf6vQPIChWIBhFzV8gjjsPE/fR3IyQdNY=\ngolang.org/x/lint v0.0.0-20210508222113-6edffad5e616 h1:VLliZ0d+/avPrXXH+OakdXhpJuEoBZuwh1m2j7U6Iug=\ngolang.org/x/lint v0.0.0-20210508222113-6edffad5e616/go.mod h1:3xt1FjdF8hUf6vQPIChWIBhFzV8gjjsPE/fR3IyQdNY=\ngolang.org/x/mobile v0.0.0-20190312151609-d3739f865fa6/go.mod h1:z+o9i4GpDbdi3rU15maQ/Ox0txvL9dWGYEHz965HBQE=\ngolang.org/x/mobile v0.0.0-20190719004257-d2bd2a29d028/go.mod h1:E/iHnbuqvinMTCcRqshq8CkpyQDoeVncDDYHnLhea+o=\ngolang.org/x/mobile v0.0.0-20201217150744-e6ae53a27f4f/go.mod h1:skQtrUTUwhdJvXM/2KKJzY8pDgNr9I/FOMqDVRPBUS4=\ngolang.org/x/mod v0.0.0-20190513183733-4bf6d317e70e/go.mod h1:mXi4GBBbnImb6dmsKGUJ2LatrhH/nqhxcFungHvyanc=\ngolang.org/x/mod v0.1.0/go.mod h1:0QHyrYULN0/3qlju5TqG8bIK38QM8yzMo5ekMj3DlcY=\ngolang.org/x/mod v0.1.1-0.20191105210325-c90efee705ee/go.mod h1:QqPTAvyqsEbceGzBzNggFXnrqF1CaUcvgkdR5Ot7KZg=\ngolang.org/x/mod v0.1.1-0.20191107180719-034126e5016b/go.mod h1:QqPTAvyqsEbceGzBzNggFXnrqF1CaUcvgkdR5Ot7KZg=\ngolang.org/x/mod v0.1.1-0.20191209134235-331c550502dd/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/mod v0.2.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/mod v0.3.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/mod v0.4.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/mod v0.4.1/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/mod v0.4.2/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/mod v0.5.1-0.20210830214625-1b1db11ec8f4/go.mod h1:5OXOZSfqPIIbmVBIIKWRFfZjPR0E5r58TLhUjH0a2Ro=\ngolang.org/x/mod v0.6.0-dev.0.20220419223038-86c51ed26bb4/go.mod h1:jJ57K6gSWd91VN4djpZkiMVwK6gcyfeH4XE8wZrZaV4=\ngolang.org/x/mod v0.17.0 h1:zY54UmvipHiNd+pm+m0x9KhZ9hl1/7QNMyxXbc6ICqA=\ngolang.org/x/mod v0.17.0/go.mod h1:hTbmBsO62+eylJbnUtE2MGJUyE7QWk4xUqPFrRgJ+7c=\ngolang.org/x/net v0.0.0-20180724234803-3673e40ba225/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20180826012351-8a410e7b638d/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20180906233101-161cd47e91fd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20181005035420-146acd28ed58/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20181023162649-9b4f9f5ad519/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20181114220301-adae6a3d119a/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20181201002055-351d144fa1fc/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20181220203305-927f97764cc3/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190108225652-1e06a53dbb7e/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190125091013-d26f9f9a57f3/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190213061140-3a22650c66bd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190311183353-d8887717615a/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190320064053-1272bf9dcd53/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190501004415-9ce7a6920f09/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190503192946-f4e77d36d62c/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190522155817-f3200d17e092/go.mod h1:HSz+uSET+XFnRR8LxR5pz3Of3rY3CfYBVs4xY44aLks=\ngolang.org/x/net v0.0.0-20190603091049-60506f45cf65/go.mod h1:HSz+uSET+XFnRR8LxR5pz3Of3rY3CfYBVs4xY44aLks=\ngolang.org/x/net v0.0.0-20190613194153-d28f0bde5980/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20190628185345-da137c7871d7/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20190724013045-ca1201d0de80/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20190812203447-cdfb69ac37fc/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190813141303-74dc4d7220e7/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20190827160401-ba9fcec4b297/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20190923162816-aa69164e4478/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20191112182307-2180aed22343/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20191209160850-c0dbc17a3553/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200114155413-6afb5195e5aa/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200202094626-16171245cfb2/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200222125558-5a598a2470a0/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200226121028-0de0cce0169b/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200301022130-244492dfa37a/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200324143707-d3edc9973b7e/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/net v0.0.0-20200501053045-e0ff5e5a1de5/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/net v0.0.0-20200506145744-7e3656a0809f/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/net v0.0.0-20200513185701-a91f0712d120/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/net v0.0.0-20200520004742-59133d7f0dd7/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/net v0.0.0-20200520182314-0ba52f642ac2/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/net v0.0.0-20200602114024-627f9648deb9/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/net v0.0.0-20200625001655-4c5254603344/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=\ngolang.org/x/net v0.0.0-20200707034311-ab3426394381/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=\ngolang.org/x/net v0.0.0-20200822124328-c89045814202/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=\ngolang.org/x/net v0.0.0-20201006153459-a7d1128ccaa0/go.mod h1:sp8m0HH+o8qH0wwXwYZr8TS3Oi6o0r6Gce1SSxlDquU=\ngolang.org/x/net v0.0.0-20201021035429-f5854403a974/go.mod h1:sp8m0HH+o8qH0wwXwYZr8TS3Oi6o0r6Gce1SSxlDquU=\ngolang.org/x/net v0.0.0-20201031054903-ff519b6c9102/go.mod h1:sp8m0HH+o8qH0wwXwYZr8TS3Oi6o0r6Gce1SSxlDquU=\ngolang.org/x/net v0.0.0-20201110031124-69a78807bb2b/go.mod h1:sp8m0HH+o8qH0wwXwYZr8TS3Oi6o0r6Gce1SSxlDquU=\ngolang.org/x/net v0.0.0-20201202161906-c7110b5ffcbb/go.mod h1:sp8m0HH+o8qH0wwXwYZr8TS3Oi6o0r6Gce1SSxlDquU=\ngolang.org/x/net v0.0.0-20201209123823-ac852fbbde11/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=\ngolang.org/x/net v0.0.0-20201224014010-6772e930b67b/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=\ngolang.org/x/net v0.0.0-20210119194325-5f4716e94777/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=\ngolang.org/x/net v0.0.0-20210224082022-3d97a244fca7/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=\ngolang.org/x/net v0.0.0-20210226172049-e18ecbb05110/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=\ngolang.org/x/net v0.0.0-20210316092652-d523dce5a7f4/go.mod h1:RBQZq4jEuRlivfhVLdyRGr576XBO4/greRjx4P4O3yc=\ngolang.org/x/net v0.0.0-20210324051636-2c4c8ecb7826/go.mod h1:RBQZq4jEuRlivfhVLdyRGr576XBO4/greRjx4P4O3yc=\ngolang.org/x/net v0.0.0-20210405180319-a5a99cb37ef4/go.mod h1:p54w0d4576C0XHj96bSt6lcn1PtDYWL6XObtHCRCNQM=\ngolang.org/x/net v0.0.0-20210503060351-7fd8e65b6420/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=\ngolang.org/x/net v0.0.0-20210505024714-0287a6fb4125/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=\ngolang.org/x/net v0.0.0-20210614182718-04defd469f4e/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=\ngolang.org/x/net v0.0.0-20211112202133-69e39bad7dc2/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=\ngolang.org/x/net v0.0.0-20211118161319-6a13c67c3ce4/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=\ngolang.org/x/net v0.0.0-20220722155237-a158d28d115b/go.mod h1:XRhObCWvk6IyKnWLug+ECip1KBveYUHfp+8e9klMJ9c=\ngolang.org/x/net v0.6.0/go.mod h1:2Tu9+aMcznHK/AK1HMvgo6xiTLG5rD5rZLDS+rp2Bjs=\ngolang.org/x/net v0.7.0/go.mod h1:2Tu9+aMcznHK/AK1HMvgo6xiTLG5rD5rZLDS+rp2Bjs=\ngolang.org/x/net v0.28.0 h1:a9JDOJc5GMUJ0+UDqmLT86WiEy7iWyIhz8gz8E4e5hE=\ngolang.org/x/net v0.28.0/go.mod h1:yqtgsTWOOnlGLG9GFRrK3++bGOUEkNBoHZc8MEDWPNg=\ngolang.org/x/oauth2 v0.0.0-20180821212333-d2e6202438be/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=\ngolang.org/x/oauth2 v0.0.0-20190226205417-e64efc72b421/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\ngolang.org/x/oauth2 v0.0.0-20190604053449-0f29369cfe45/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\ngolang.org/x/oauth2 v0.0.0-20191202225959-858c2ad4c8b6/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\ngolang.org/x/oauth2 v0.0.0-20200107190931-bf48bf16ab8d/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\ngolang.org/x/oauth2 v0.0.0-20200902213428-5d25da1a8d43/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=\ngolang.org/x/oauth2 v0.0.0-20201109201403-9fd604954f58/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=\ngolang.org/x/oauth2 v0.0.0-20201208152858-08078c50e5b5/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=\ngolang.org/x/oauth2 v0.0.0-20210218202405-ba52d332ba99/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=\ngolang.org/x/oauth2 v0.0.0-20210220000619-9bb904979d93/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=\ngolang.org/x/oauth2 v0.0.0-20210313182246-cd4f82c27b84/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=\ngolang.org/x/oauth2 v0.0.0-20210323180902-22b0adad7558/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=\ngolang.org/x/oauth2 v0.0.0-20210427180440-81ed05c6b58c/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=\ngolang.org/x/oauth2 v0.0.0-20210514164344-f6687ab2804c/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=\ngolang.org/x/oauth2 v0.23.0 h1:PbgcYx2W7i4LvjJWEbf0ngHV6qJYr86PkAV3bXdLEbs=\ngolang.org/x/oauth2 v0.23.0/go.mod h1:XYTD2NtWslqkgxebSiOHnXEap4TF09sJSc7H1sXbhtI=\ngolang.org/x/sync v0.0.0-20180314180146-1d60e4601c6f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20181108010431-42b317875d0f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20181221193216-37e7f081c4d4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190227155943-e225da77a7e6/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190412183630-56d357773e84/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190911185100-cd5d95a43a6e/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20200317015054-43a5402ce75a/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20200625203802-6e8e738ad208/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20201020160332-67f06af15bc9/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20201207232520-09787c993a3a/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20210220032951-036812b2e83c/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20220722155255-886fb9371eb4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.10.0 h1:3NQrjDixjgGwUOCaF8w2+VYHv0Ve/vGYSbdkTa98gmQ=\ngolang.org/x/sync v0.10.0/go.mod h1:Czt+wKu1gCyEFDUtn0jG5QVvpJ6rzVqr5aXyt9drQfk=\ngolang.org/x/sys v0.0.0-20180823144017-11551d06cbcc/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20180830151530-49385e6e1522/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20180905080454-ebe1bf3edb33/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20180909124046-d0be0721c37e/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20181026203630-95b1ffbd15a5/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20181107165924-66b7b1311ac8/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20181116152217-5ac8a444bdc5/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20181122145206-62eef0e2fa9b/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20181205085412-a5c9d58dba9a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20181206074257-70b957f3b65e/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20181228144115-9a3f9b0469bb/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190129075346-302c3dd5f1cc/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190222072716-a9d3bda3a223/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190312061237-fead79001313/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190321052220-f7bb7a8bee54/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190403152447-81d4e9dc473e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190419153524-e8e3143a4f4a/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190422165155-953cdadca894/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190502145724-3ef323f4f1fd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190507160741-ecd444e8653b/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190530182044-ad28b68e88f1/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190531175056-4c3a928424d2/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190606165138-5da285871e9c/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190616124812-15dcb6c0061f/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190624142023-c5567b49c5d0/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190626221950-04f50cda93cb/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190726091711-fc99dfbffb4e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190813064441-fde4db37ae7a/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190826190057-c7b8b68b1456/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190904154756-749cb33beabd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190916202348-b4ddaad3f8a3/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190922100055-0a153f010e69/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190924154521-2837fb4f24fe/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191001151750-bb3f8db39f24/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191005200804-aed5e4c7ecf9/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191008105621-543471e840be/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191026070338-33540a1f6037/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191112214154-59a1497f0cea/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191120155948-bd437916bb0e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191204072324-ce4227a45e2e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191220142924-d4481acd189f/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191228213918-04cbcbbfeed8/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200106162015-b016eb3dc98e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200107162124-548cf772de50/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200113162924-86b910548bc1/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200116001909-b77594299b42/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200122134326-e047566fdf82/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200124204421-9fbb57f87de9/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200202164722-d101bd2416d5/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200212091648-12a6c2dcc1e4/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200223170610-d5e6a3e2c0ae/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200302150141-5c8b2ff67527/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200323222414-85ca7c5b95cd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200331124033-c3d80250170d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200420163511-1957bb5e6d1f/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200501052902-10377860bb8e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200511232937-7e40ca221e25/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200515095857-1151b9dac4a9/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200519105757-fe76b779f299/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200523222454-059865788121/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200615200032-f1bc736245b1/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200625212154-ddb9806d33ae/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200727154430-2d971f7391a4/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200803210538-64077c9b5642/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200826173525-f9321e4c35a6/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200828194041-157a740278f4/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200831180312-196b9ba8737a/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200905004654-be1d3432aa8f/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200930185726-fdedc70b468f/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20201112073958-5cba982894dd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20201201145000-ef89a241ccb3/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210104204734-6f8348627aad/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210119212857-b64e53b001e4/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210124154548-22da62e12c0c/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210220050731-9a76102bfb43/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210225134936-a50acf3fe073/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210303074136-134d130e1a04/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210304124612-50617c2ba197/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210305230114-8fe3ee5dd75b/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210309074719-68d13333faf2/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210314195730-07df6a141424/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210315160823-c6e025ad8005/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210320140829-1e4c9ba3b0c4/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210324051608-47abb6519492/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210330210617-4fbd30eecc44/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210423082822-04245dca01da/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210503080704-8803ae5d1324/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210510120138-977fb7262007/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20210514084401-e8d321eab015/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20210601080250-7ecdf8ef093b/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20210615035016-665e8c7367d1/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20210616045830-e2b7044e8c71/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20210630005230-0f9fa26af87c/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20211025201205-69cdffdb9359/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20211117180635-dee7805ff2e1/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220520151302-bc2c85ada10a/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220722155257-8c9f86f7a55f/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220811171246-fbc7d0a398ab/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.5.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.28.0 h1:Fksou7UEQUWlKvIdsqzJmUmCX3cZuD2+P3XyyzwMhlA=\ngolang.org/x/sys v0.28.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/term v0.0.0-20201117132131-f5c789dd3221/go.mod h1:Nr5EML6q2oocZ2LXRh80K7BxOlk5/8JxuGnuhpl+muw=\ngolang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=\ngolang.org/x/term v0.0.0-20210927222741-03fcf44c2211/go.mod h1:jbD1KX2456YbFQfuXm/mYQcufACuNUgVhRMnK/tPxf8=\ngolang.org/x/term v0.5.0/go.mod h1:jMB1sMXY+tzblOD4FWmEbocvup2/aLOaQEp7JmGp78k=\ngolang.org/x/term v0.27.0 h1:WP60Sv1nlK1T6SupCHbXzSaN0b9wUmsPoRS9b61A23Q=\ngolang.org/x/term v0.27.0/go.mod h1:iMsnZpn0cago0GOrHO2+Y7u7JPn5AylBrcoWkElMTSM=\ngolang.org/x/text v0.0.0-20170915032832-14c0d48ead0c/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.1-0.20180807135948-17ff2d5776d2/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.1-0.20181227161524-e6919f6577db/go.mod h1:bEr9sfX3Q8Zfm5fL9x+3itogRgK3+ptLWKqgva+5dAk=\ngolang.org/x/text v0.3.2/go.mod h1:bEr9sfX3Q8Zfm5fL9x+3itogRgK3+ptLWKqgva+5dAk=\ngolang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.4/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.5/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.6/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.7/go.mod h1:u+2+/6zg+i71rQMx5EYifcz6MCKuco9NR6JIITiCfzQ=\ngolang.org/x/text v0.7.0/go.mod h1:mrYo+phRRbMaCq/xk9113O4dZlRixOauAjOtrjsXDZ8=\ngolang.org/x/text v0.21.0 h1:zyQAAkrwaneQ066sspRyJaG9VNi/YJ1NfzcGB3hZ/qo=\ngolang.org/x/text v0.21.0/go.mod h1:4IBbMaMmOPCJ8SecivzSH54+73PCFmPWxNTLm+vZkEQ=\ngolang.org/x/time v0.0.0-20180412165947-fbb02b2291d2/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/time v0.0.0-20181108054448-85acf8d2951c/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/time v0.0.0-20190308202827-9d24e82272b4/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/time v0.0.0-20191024005414-555d28b269f0/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/time v0.0.0-20200630173020-3af7569d3a1e/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/time v0.0.0-20201208040808-7e3f01d25324/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/time v0.0.0-20210220033141-f8bda1e9f3ba h1:O8mE0/t419eoIwhTFpKVkHiTs/Igowgfkj25AcZrtiE=\ngolang.org/x/time v0.0.0-20210220033141-f8bda1e9f3ba/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/tools v0.0.0-20180221164845-07fd8470d635/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20180525024113-a5b4c53f6e8b/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20180828015842-6cd1fcedba52/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20181030221726-6c7e314b6563/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190114222345-bf090417da8b/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190125232054-d66bd3c5d5a6/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190206041539-40960b6deb8e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190226205152-f727befe758c/go.mod h1:9Yl7xja0Znq3iFh3HoIrodX9oNMXvdceNzlUR8zjMvY=\ngolang.org/x/tools v0.0.0-20190311212946-11955173bddd/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190312151545-0bb0c0a6e846/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190312170243-e65039ee4138/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190328211700-ab21143f2384/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190329151228-23e29df326fe/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190416151739-9c9e1878f421/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190420181800-aa740d480789/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190424220101-1e8e1cfdf96b/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=\ngolang.org/x/tools v0.0.0-20190425150028-36563e24a262/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=\ngolang.org/x/tools v0.0.0-20190506145303-2d16b83fe98c/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=\ngolang.org/x/tools v0.0.0-20190524140312-2c0ae7006135/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=\ngolang.org/x/tools v0.0.0-20190531172133-b3315ee88b7d/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=\ngolang.org/x/tools v0.0.0-20190606124116-d0a3d012864b/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=\ngolang.org/x/tools v0.0.0-20190614205625-5aca471b1d59/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=\ngolang.org/x/tools v0.0.0-20190617190820-da514acc4774/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=\ngolang.org/x/tools v0.0.0-20190621195816-6e04913cbbac/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=\ngolang.org/x/tools v0.0.0-20190624222133-a101b041ded4/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=\ngolang.org/x/tools v0.0.0-20190628153133-6cdbf07be9d0/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=\ngolang.org/x/tools v0.0.0-20190816200558-6889da9d5479/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20190907020128-2ca718005c18/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20190911174233-4f2ddba30aff/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20190927191325-030b2cf1153e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191012152004-8de300cfc20a/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191029041327-9cc4af7d6b2c/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191029190741-b9c20aec41a5/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191030062658-86caa796c7ab/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191104232314-dc038396d1f0/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191108193012-7d206e10da11/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191113191852-77e3bb0ad9e7/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191114200427-caa0b0f7d508/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191115202509-3a792d9c32b2/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191125144606-a911d9008d1f/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191130070609-6e064ea0cf2d/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191216173652-a0e659d51361/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20191227053925-7b8e75db28f4/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200103221440-774c71fcf114/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200108203644-89082a384178/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200117012304-6edc0a871e69/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200117161641-43d50277825c/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200122220014-bf1340f18c4a/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200130002326-2f3ba24bd6e7/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200204074204-1cc6d1ef6c74/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200207183749-b753a1ba74fa/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200212150539-ea181f53ac56/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200224181240-023911ca70b2/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200227222343-706bc42d1f0d/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200304024140-c4206d458c3f/go.mod h1:o4KQGtdN14AW+yjsvvwRTJJuXz8XRtIHtEnmAXLyFUw=\ngolang.org/x/tools v0.0.0-20200304193943-95d2e580d8eb/go.mod h1:o4KQGtdN14AW+yjsvvwRTJJuXz8XRtIHtEnmAXLyFUw=\ngolang.org/x/tools v0.0.0-20200312045724-11d5b4c81c7d/go.mod h1:o4KQGtdN14AW+yjsvvwRTJJuXz8XRtIHtEnmAXLyFUw=\ngolang.org/x/tools v0.0.0-20200331025713-a30bf2db82d4/go.mod h1:Sl4aGygMT6LrqrWclx+PTx3U+LnKx/seiNR+3G19Ar8=\ngolang.org/x/tools v0.0.0-20200501065659-ab2804fb9c9d/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\ngolang.org/x/tools v0.0.0-20200512131952-2bc93b1c0c88/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\ngolang.org/x/tools v0.0.0-20200513201620-d5fe73897c97/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\ngolang.org/x/tools v0.0.0-20200515010526-7d3b6ebf133d/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\ngolang.org/x/tools v0.0.0-20200618134242-20370b0cb4b2/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\ngolang.org/x/tools v0.0.0-20200619180055-7c47624df98f/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\ngolang.org/x/tools v0.0.0-20200721032237-77f530d86f9a/go.mod h1:njjCfa9FT2d7l9Bc6FUM5FLjQPp3cFF28FI3qnDFljA=\ngolang.org/x/tools v0.0.0-20200729194436-6467de6f59a7/go.mod h1:njjCfa9FT2d7l9Bc6FUM5FLjQPp3cFF28FI3qnDFljA=\ngolang.org/x/tools v0.0.0-20200804011535-6c149bb5ef0d/go.mod h1:njjCfa9FT2d7l9Bc6FUM5FLjQPp3cFF28FI3qnDFljA=\ngolang.org/x/tools v0.0.0-20200825202427-b303f430e36d/go.mod h1:njjCfa9FT2d7l9Bc6FUM5FLjQPp3cFF28FI3qnDFljA=\ngolang.org/x/tools v0.0.0-20200904185747-39188db58858/go.mod h1:Cj7w3i3Rnn0Xh82ur9kSqwfTHTeVxaDqrfMjpcNT6bE=\ngolang.org/x/tools v0.0.0-20201110124207-079ba7bd75cd/go.mod h1:emZCQorbCU4vsT4fOWvOPXz4eW1wZW4PmDk9uLelYpA=\ngolang.org/x/tools v0.0.0-20201118003311-bd56c0adb394/go.mod h1:emZCQorbCU4vsT4fOWvOPXz4eW1wZW4PmDk9uLelYpA=\ngolang.org/x/tools v0.0.0-20201201161351-ac6f37ff4c2a/go.mod h1:emZCQorbCU4vsT4fOWvOPXz4eW1wZW4PmDk9uLelYpA=\ngolang.org/x/tools v0.0.0-20201208233053-a543418bbed2/go.mod h1:emZCQorbCU4vsT4fOWvOPXz4eW1wZW4PmDk9uLelYpA=\ngolang.org/x/tools v0.0.0-20210105154028-b0ab187a4818/go.mod h1:emZCQorbCU4vsT4fOWvOPXz4eW1wZW4PmDk9uLelYpA=\ngolang.org/x/tools v0.0.0-20210106214847-113979e3529a/go.mod h1:emZCQorbCU4vsT4fOWvOPXz4eW1wZW4PmDk9uLelYpA=\ngolang.org/x/tools v0.1.0/go.mod h1:xkSsbof2nBLbhDlRMhhhyNLN/zl3eTqcnHD5viDpcZ0=\ngolang.org/x/tools v0.1.1/go.mod h1:o0xws9oXOQQZyjljx8fwUC0k7L1pTE6eaCbjGeHmOkk=\ngolang.org/x/tools v0.1.4/go.mod h1:o0xws9oXOQQZyjljx8fwUC0k7L1pTE6eaCbjGeHmOkk=\ngolang.org/x/tools v0.1.12/go.mod h1:hNGJHUnrk76NpqgfD5Aqm5Crs+Hm0VOH/i9J2+nxYbc=\ngolang.org/x/tools v0.21.1-0.20240508182429-e35e4ccd0d2d h1:vU5i/LfpvrRCpgM/VPfJLg5KjxD3E+hfT1SH+d9zLwg=\ngolang.org/x/tools v0.21.1-0.20240508182429-e35e4ccd0d2d/go.mod h1:aiJjzUbINMkxbQROHiO6hDPo2LHcIPhhQsa9DLh0yGk=\ngolang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20220907171357-04be3eba64a2 h1:H2TDz8ibqkAF6YGhCdN3jS9O0/s90v0rJh3X/OLHEUk=\ngolang.org/x/xerrors v0.0.0-20220907171357-04be3eba64a2/go.mod h1:K8+ghG5WaK9qNqU5K3HdILfMLy1f3aNYFI/wnl100a8=\ngonum.org/v1/gonum v0.0.0-20180816165407-929014505bf4/go.mod h1:Y+Yx5eoAFn32cQvJDxZx5Dpnq+c3wtXuadVZAcxbbBo=\ngonum.org/v1/gonum v0.0.0-20181121035319-3f7ecaa7e8ca/go.mod h1:Y+Yx5eoAFn32cQvJDxZx5Dpnq+c3wtXuadVZAcxbbBo=\ngonum.org/v1/gonum v0.6.0/go.mod h1:9mxDZsDKxgMAuccQkewq682L+0eCu4dCN2yonUJTCLU=\ngonum.org/v1/gonum v0.8.2/go.mod h1:oe/vMfY3deqTw+1EZJhuvEW2iwGF1bW9wwu7XCu0+v0=\ngonum.org/v1/gonum v0.9.3/go.mod h1:TZumC3NeyVQskjXqmyWt4S3bINhy7B4eYwW69EbyX+0=\ngonum.org/v1/gonum v0.11.0 h1:f1IJhK4Km5tBJmaiJXtk/PkL4cdVX6J+tGiM187uT5E=\ngonum.org/v1/gonum v0.11.0/go.mod h1:fSG4YDCxxUZQJ7rKsQrj0gMOg00Il0Z96/qMA4bVQhA=\ngonum.org/v1/netlib v0.0.0-20181029234149-ec6d1f5cefe6/go.mod h1:wa6Ws7BG/ESfp6dHfk7C6KdzKA7wR7u/rKwOGE66zvw=\ngonum.org/v1/netlib v0.0.0-20190313105609-8cb42192e0e0/go.mod h1:wa6Ws7BG/ESfp6dHfk7C6KdzKA7wR7u/rKwOGE66zvw=\ngonum.org/v1/plot v0.0.0-20190515093506-e2840ee46a6b/go.mod h1:Wt8AAjI+ypCyYX3nZBvf6cAIx93T+c/OS2HFAYskSZc=\ngonum.org/v1/plot v0.9.0/go.mod h1:3Pcqqmp6RHvJI72kgb8fThyUnav364FOsdDo2aGW5lY=\ngoogle.golang.org/api v0.3.1/go.mod h1:6wY9I6uQWHQ8EM57III9mq/AjF+i8G65rmVagqKMtkk=\ngoogle.golang.org/api v0.4.0/go.mod h1:8k5glujaEP+g9n7WNsDg8QP6cUVNI86fCNMcbazEtwE=\ngoogle.golang.org/api v0.7.0/go.mod h1:WtwebWUNSVBH/HAw79HIFXZNqEvBhG+Ra+ax0hx3E3M=\ngoogle.golang.org/api v0.8.0/go.mod h1:o4eAsZoiT+ibD93RtjEohWalFOjRDx6CVaqeizhEnKg=\ngoogle.golang.org/api v0.9.0/go.mod h1:o4eAsZoiT+ibD93RtjEohWalFOjRDx6CVaqeizhEnKg=\ngoogle.golang.org/api v0.13.0/go.mod h1:iLdEw5Ide6rF15KTC1Kkl0iskquN2gFfn9o9XIsbkAI=\ngoogle.golang.org/api v0.14.0/go.mod h1:iLdEw5Ide6rF15KTC1Kkl0iskquN2gFfn9o9XIsbkAI=\ngoogle.golang.org/api v0.15.0/go.mod h1:iLdEw5Ide6rF15KTC1Kkl0iskquN2gFfn9o9XIsbkAI=\ngoogle.golang.org/api v0.17.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=\ngoogle.golang.org/api v0.18.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=\ngoogle.golang.org/api v0.19.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=\ngoogle.golang.org/api v0.20.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=\ngoogle.golang.org/api v0.22.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=\ngoogle.golang.org/api v0.24.0/go.mod h1:lIXQywCXRcnZPGlsd8NbLnOjtAoL6em04bJ9+z0MncE=\ngoogle.golang.org/api v0.28.0/go.mod h1:lIXQywCXRcnZPGlsd8NbLnOjtAoL6em04bJ9+z0MncE=\ngoogle.golang.org/api v0.29.0/go.mod h1:Lcubydp8VUV7KeIHD9z2Bys/sm/vGKnG1UHuDBSrHWM=\ngoogle.golang.org/api v0.30.0/go.mod h1:QGmEvQ87FHZNiUVJkT14jQNYJ4ZJjdRF23ZXz5138Fc=\ngoogle.golang.org/api v0.35.0/go.mod h1:/XrVsuzM0rZmrsbjJutiuftIzeuTQcEeaYcSk/mQ1dg=\ngoogle.golang.org/api v0.36.0/go.mod h1:+z5ficQTmoYpPn8LCUNVpK5I7hwkpjbcgqA7I34qYtE=\ngoogle.golang.org/api v0.40.0/go.mod h1:fYKFpnQN0DsDSKRVRcQSDQNtqWPfM9i+zNPxepjRCQ8=\ngoogle.golang.org/api v0.41.0/go.mod h1:RkxM5lITDfTzmyKFPt+wGrCJbVfniCr2ool8kTBzRTU=\ngoogle.golang.org/api v0.42.0/go.mod h1:+Oj4s6ch2SEGtPjGqfUfZonBH0GjQH89gTeKKAEGZKI=\ngoogle.golang.org/api v0.43.0/go.mod h1:nQsDGjRXMo4lvh5hP0TKqF244gqhGcr/YSIykhUk/94=\ngoogle.golang.org/api v0.46.0/go.mod h1:ceL4oozhkAiTID8XMmJBsIxID/9wMXJVVFXPg4ylg3I=\ngoogle.golang.org/api v0.47.0/go.mod h1:Wbvgpq1HddcWVtzsVLyfLp8lDg6AA241LmgIL59tHXo=\ngoogle.golang.org/api v0.114.0 h1:1xQPji6cO2E2vLiI+C/XiFAnsn1WV3mjaEwGLhi3grE=\ngoogle.golang.org/api v0.114.0/go.mod h1:ifYI2ZsFK6/uGddGfAD5BMxlnkBqCmqHSDUVi45N5Yg=\ngoogle.golang.org/appengine v1.1.0/go.mod h1:EbEs0AVv82hx2wNQdGPgUI5lhzA/G0D9YwlJXL52JkM=\ngoogle.golang.org/appengine v1.2.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=\ngoogle.golang.org/appengine v1.4.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=\ngoogle.golang.org/appengine v1.5.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=\ngoogle.golang.org/appengine v1.6.1/go.mod h1:i06prIuMbXzDqacNJfV5OdTW448YApPu5ww/cMBSeb0=\ngoogle.golang.org/appengine v1.6.5/go.mod h1:8WjMMxjGQR8xUklV/ARdw2HLXBOI7O7uCIDZVag1xfc=\ngoogle.golang.org/appengine v1.6.6/go.mod h1:8WjMMxjGQR8xUklV/ARdw2HLXBOI7O7uCIDZVag1xfc=\ngoogle.golang.org/appengine v1.6.7 h1:FZR1q0exgwxzPzp/aF+VccGrSfxfPpkBqjIIEq3ru6c=\ngoogle.golang.org/appengine v1.6.7/go.mod h1:8WjMMxjGQR8xUklV/ARdw2HLXBOI7O7uCIDZVag1xfc=\ngoogle.golang.org/genproto v0.0.0-20180817151627-c66870c02cf8/go.mod h1:JiN7NxoALGmiZfu7CAH4rXhgtRTLTxftemlI0sWmxmc=\ngoogle.golang.org/genproto v0.0.0-20190307195333-5fe7a883aa19/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=\ngoogle.golang.org/genproto v0.0.0-20190404172233-64821d5d2107/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=\ngoogle.golang.org/genproto v0.0.0-20190418145605-e7d98fc518a7/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=\ngoogle.golang.org/genproto v0.0.0-20190425155659-357c62f0e4bb/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=\ngoogle.golang.org/genproto v0.0.0-20190502173448-54afdca5d873/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=\ngoogle.golang.org/genproto v0.0.0-20190530194941-fb225487d101/go.mod h1:z3L6/3dTEVtUr6QSP8miRzeRqwQOioJ9I66odjN4I7s=\ngoogle.golang.org/genproto v0.0.0-20190716160619-c506a9f90610/go.mod h1:DMBHOl98Agz4BDEuKkezgsaosCRResVns1a3J2ZsMNc=\ngoogle.golang.org/genproto v0.0.0-20190801165951-fa694d86fc64/go.mod h1:DMBHOl98Agz4BDEuKkezgsaosCRResVns1a3J2ZsMNc=\ngoogle.golang.org/genproto v0.0.0-20190819201941-24fa4b261c55/go.mod h1:DMBHOl98Agz4BDEuKkezgsaosCRResVns1a3J2ZsMNc=\ngoogle.golang.org/genproto v0.0.0-20190911173649-1774047e7e51/go.mod h1:IbNlFCBrqXvoKpeg0TB2l7cyZUmoaFKYIwrEpbDKLA8=\ngoogle.golang.org/genproto v0.0.0-20191108220845-16a3f7862a1a/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20191115194625-c23dd37a84c9/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20191216164720-4f79533eabd1/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20191230161307-f3c370f40bfb/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20200108215221-bd8f9a0ef82f/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20200115191322-ca5a22157cba/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20200122232147-0452cf42e150/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20200204135345-fa8e72b47b90/go.mod h1:GmwEX6Z4W5gMy59cAlVYjN9JhxgbQH6Gn+gFDQe2lzA=\ngoogle.golang.org/genproto v0.0.0-20200212174721-66ed5ce911ce/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200224152610-e50cd9704f63/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200228133532-8c2c7df3a383/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200305110556-506484158171/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200312145019-da6875a35672/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200331122359-1ee6d9798940/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200430143042-b979b6f78d84/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200511104702-f5ebc3bea380/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200513103714-09dca8ec2884/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200515170657-fc4c6c6a6587/go.mod h1:YsZOwe1myG/8QRHRsmBRE1LrgQY60beZKjly0O1fX9U=\ngoogle.golang.org/genproto v0.0.0-20200526211855-cb27e3aa2013/go.mod h1:NbSheEEYHJ7i3ixzK3sjbqSGDJWnxyFXZblF3eUsNvo=\ngoogle.golang.org/genproto v0.0.0-20200618031413-b414f8b61790/go.mod h1:jDfRM7FcilCzHH/e9qn6dsT145K34l5v+OpcnNgKAAA=\ngoogle.golang.org/genproto v0.0.0-20200729003335-053ba62fc06f/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=\ngoogle.golang.org/genproto v0.0.0-20200804131852-c06518451d9c/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=\ngoogle.golang.org/genproto v0.0.0-20200825200019-8632dd797987/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=\ngoogle.golang.org/genproto v0.0.0-20200904004341-0bd0a958aa1d/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=\ngoogle.golang.org/genproto v0.0.0-20201109203340-2640f1f9cdfb/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=\ngoogle.golang.org/genproto v0.0.0-20201201144952-b05cb90ed32e/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=\ngoogle.golang.org/genproto v0.0.0-20201210142538-e3217bee35cc/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=\ngoogle.golang.org/genproto v0.0.0-20201214200347-8c77b98c765d/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=\ngoogle.golang.org/genproto v0.0.0-20210222152913-aa3ee6e6a81c/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=\ngoogle.golang.org/genproto v0.0.0-20210303154014-9728d6b83eeb/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=\ngoogle.golang.org/genproto v0.0.0-20210310155132-4ce2db91004e/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=\ngoogle.golang.org/genproto v0.0.0-20210312152112-fc591d9ea70f/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=\ngoogle.golang.org/genproto v0.0.0-20210319143718-93e7006c17a6/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=\ngoogle.golang.org/genproto v0.0.0-20210402141018-6c239bbf2bb1/go.mod h1:9lPAdzaEmUacj36I+k7YKbEc5CXzPIeORRgDAUOu28A=\ngoogle.golang.org/genproto v0.0.0-20210429181445-86c259c2b4ab/go.mod h1:P3QM42oQyzQSnHPnZ/vqoCdDmzH28fzWByN9asMeM8A=\ngoogle.golang.org/genproto v0.0.0-20210513213006-bf773b8c8384/go.mod h1:P3QM42oQyzQSnHPnZ/vqoCdDmzH28fzWByN9asMeM8A=\ngoogle.golang.org/genproto v0.0.0-20210517163617-5e0236093d7a/go.mod h1:P3QM42oQyzQSnHPnZ/vqoCdDmzH28fzWByN9asMeM8A=\ngoogle.golang.org/genproto v0.0.0-20210601144548-a796c710e9b6/go.mod h1:P3QM42oQyzQSnHPnZ/vqoCdDmzH28fzWByN9asMeM8A=\ngoogle.golang.org/genproto v0.0.0-20210630183607-d20f26d13c79/go.mod h1:yiaVoXHpRzHGyxV3o4DktVWY4mSUErTKaeEOq6C3t3U=\ngoogle.golang.org/genproto v0.0.0-20230410155749-daa745c078e1 h1:KpwkzHKEF7B9Zxg18WzOa7djJ+Ha5DzthMyZYQfEn2A=\ngoogle.golang.org/genproto v0.0.0-20230410155749-daa745c078e1/go.mod h1:nKE/iIaLqn2bQwXBg8f1g2Ylh6r5MN5CmZvuzZCgsCU=\ngoogle.golang.org/grpc v1.14.0/go.mod h1:yo6s7OP7yaDglbqo1J04qKzAhqBH6lvTonzMVmEdcZw=\ngoogle.golang.org/grpc v1.17.0/go.mod h1:6QZJwpn2B+Zp71q/5VxRsJ6NXXVCE5NRUHRo+f3cWCs=\ngoogle.golang.org/grpc v1.19.0/go.mod h1:mqu4LbDTu4XGKhr4mRzUsmM4RtVoemTSY81AxZiDr8c=\ngoogle.golang.org/grpc v1.19.1/go.mod h1:mqu4LbDTu4XGKhr4mRzUsmM4RtVoemTSY81AxZiDr8c=\ngoogle.golang.org/grpc v1.20.0/go.mod h1:chYK+tFQF0nDUGJgXMSgLCQk3phJEuONr2DCgLDdAQM=\ngoogle.golang.org/grpc v1.20.1/go.mod h1:10oTOabMzJvdu6/UiuZezV6QK5dSlG84ov/aaiqXj38=\ngoogle.golang.org/grpc v1.21.0/go.mod h1:oYelfM1adQP15Ek0mdvEgi9Df8B9CZIaU1084ijfRaM=\ngoogle.golang.org/grpc v1.21.1/go.mod h1:oYelfM1adQP15Ek0mdvEgi9Df8B9CZIaU1084ijfRaM=\ngoogle.golang.org/grpc v1.22.1/go.mod h1:Y5yQAOtifL1yxbo5wqy6BxZv8vAUGQwXBOALyacEbxg=\ngoogle.golang.org/grpc v1.23.0/go.mod h1:Y5yQAOtifL1yxbo5wqy6BxZv8vAUGQwXBOALyacEbxg=\ngoogle.golang.org/grpc v1.23.1/go.mod h1:Y5yQAOtifL1yxbo5wqy6BxZv8vAUGQwXBOALyacEbxg=\ngoogle.golang.org/grpc v1.25.1/go.mod h1:c3i+UQWmh7LiEpx4sFZnkU36qjEYZ0imhYfXVyQciAY=\ngoogle.golang.org/grpc v1.26.0/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8abTk=\ngoogle.golang.org/grpc v1.27.0/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8abTk=\ngoogle.golang.org/grpc v1.27.1/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8abTk=\ngoogle.golang.org/grpc v1.28.0/go.mod h1:rpkK4SK4GF4Ach/+MFLZUBavHOvF2JJB5uozKKal+60=\ngoogle.golang.org/grpc v1.29.1/go.mod h1:itym6AZVZYACWQqET3MqgPpjcuV5QH3BxFS3IjizoKk=\ngoogle.golang.org/grpc v1.30.0/go.mod h1:N36X2cJ7JwdamYAgDz+s+rVMFjt3numwzf/HckM8pak=\ngoogle.golang.org/grpc v1.31.0/go.mod h1:N36X2cJ7JwdamYAgDz+s+rVMFjt3numwzf/HckM8pak=\ngoogle.golang.org/grpc v1.31.1/go.mod h1:N36X2cJ7JwdamYAgDz+s+rVMFjt3numwzf/HckM8pak=\ngoogle.golang.org/grpc v1.33.1/go.mod h1:fr5YgcSWrqhRRxogOsw7RzIpsmvOZ6IcH4kBYTpR3n0=\ngoogle.golang.org/grpc v1.33.2/go.mod h1:JMHMWHQWaTccqQQlmk3MJZS+GWXOdAesneDmEnv2fbc=\ngoogle.golang.org/grpc v1.34.0/go.mod h1:WotjhfgOW/POjDeRt8vscBtXq+2VjORFy659qA51WJ8=\ngoogle.golang.org/grpc v1.35.0/go.mod h1:qjiiYl8FncCW8feJPdyg3v6XW24KsRHe+dy9BAGRRjU=\ngoogle.golang.org/grpc v1.36.0/go.mod h1:qjiiYl8FncCW8feJPdyg3v6XW24KsRHe+dy9BAGRRjU=\ngoogle.golang.org/grpc v1.36.1/go.mod h1:qjiiYl8FncCW8feJPdyg3v6XW24KsRHe+dy9BAGRRjU=\ngoogle.golang.org/grpc v1.37.0/go.mod h1:NREThFqKR1f3iQ6oBuvc5LadQuXVGo9rkm5ZGrQdJfM=\ngoogle.golang.org/grpc v1.37.1/go.mod h1:NREThFqKR1f3iQ6oBuvc5LadQuXVGo9rkm5ZGrQdJfM=\ngoogle.golang.org/grpc v1.38.0/go.mod h1:NREThFqKR1f3iQ6oBuvc5LadQuXVGo9rkm5ZGrQdJfM=\ngoogle.golang.org/grpc v1.39.0/go.mod h1:PImNr+rS9TWYb2O4/emRugxiyHZ5JyHW5F+RPnDzfrE=\ngoogle.golang.org/grpc v1.41.0/go.mod h1:U3l9uK9J0sini8mHphKoXyaqDA/8VyGnDee1zzIUK6k=\ngoogle.golang.org/grpc v1.56.3 h1:8I4C0Yq1EjstUzUJzpcRVbuYA2mODtEmpWiQoN/b2nc=\ngoogle.golang.org/grpc v1.56.3/go.mod h1:I9bI3vqKfayGqPUAwGdOSu7kt6oIJLixfffKrpXqQ9s=\ngoogle.golang.org/protobuf v0.0.0-20200109180630-ec00e32a8dfd/go.mod h1:DFci5gLYBciE7Vtevhsrf46CRTquxDuWsQurQQe4oz8=\ngoogle.golang.org/protobuf v0.0.0-20200221191635-4d8936d0db64/go.mod h1:kwYJMbMJ01Woi6D6+Kah6886xMZcty6N08ah7+eCXa0=\ngoogle.golang.org/protobuf v0.0.0-20200228230310-ab0ca4ff8a60/go.mod h1:cfTl7dwQJ+fmap5saPgwCLgHXTUD7jkjRqWcaiX5VyM=\ngoogle.golang.org/protobuf v1.20.1-0.20200309200217-e05f789c0967/go.mod h1:A+miEFZTKqfCUM6K7xSMQL9OKL/b6hQv+e19PK+JZNE=\ngoogle.golang.org/protobuf v1.21.0/go.mod h1:47Nbq4nVaFHyn7ilMalzfO3qCViNmqZ2kzikPIcrTAo=\ngoogle.golang.org/protobuf v1.22.0/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngoogle.golang.org/protobuf v1.23.0/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngoogle.golang.org/protobuf v1.23.1-0.20200526195155-81db48ad09cc/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngoogle.golang.org/protobuf v1.24.0/go.mod h1:r/3tXBNzIEhYS9I1OUVjXDlt8tc493IdKGjtUeSXeh4=\ngoogle.golang.org/protobuf v1.25.0/go.mod h1:9JNX74DMeImyA3h4bdi1ymwjUzf21/xIlbajtzgsN7c=\ngoogle.golang.org/protobuf v1.26.0-rc.1/go.mod h1:jlhhOSvTdKEhbULTjvd4ARK9grFBp09yW+WbY/TyQbw=\ngoogle.golang.org/protobuf v1.26.0/go.mod h1:9q0QmTI4eRPtz6boOQmLYwt+qCgq0jsYwAQnmE0givc=\ngoogle.golang.org/protobuf v1.27.1/go.mod h1:9q0QmTI4eRPtz6boOQmLYwt+qCgq0jsYwAQnmE0givc=\ngoogle.golang.org/protobuf v1.33.0 h1:uNO2rsAINq/JlFpSdYEKIZ0uKD/R9cpdv0T+yoGwGmI=\ngoogle.golang.org/protobuf v1.33.0/go.mod h1:c6P6GXX6sHbq/GpV6MGZEdwhWPcYBgnhAHhKbcUYpos=\ngopkg.in/alecthomas/kingpin.v2 v2.2.6 h1:jMFz6MfLP0/4fUyZle81rXUoxOBFi19VUFKVDOQfozc=\ngopkg.in/alecthomas/kingpin.v2 v2.2.6/go.mod h1:FMv+mEhP44yOT+4EoQTLFTRgOQ1FBLkstjWtayDeSgw=\ngopkg.in/alexcesaro/quotedprintable.v3 v3.0.0-20150716171945-2caba252f4dc h1:2gGKlE2+asNV9m7xrywl36YYNnBG5ZQ0r/BOOxqPpmk=\ngopkg.in/alexcesaro/quotedprintable.v3 v3.0.0-20150716171945-2caba252f4dc/go.mod h1:m7x9LTH6d71AHyAX77c9yqWCCa3UKHcVEj9y7hAtKDk=\ngopkg.in/asn1-ber.v1 v1.0.0-20181015200546-f715ec2f112d/go.mod h1:cuepJuh7vyXfUyUwEgHQXw849cJrilpS5NeIjOWESAw=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20190902080502-41f04d3bba15/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20200227125254-8fa46927fb4f/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c h1:Hei/4ADfdWqJk1ZMxUNpqntNwaWcugrBjAiHlqqRiVk=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c/go.mod h1:JHkPIbrfpd72SG/EVd6muEfDQjcINNoR0C8j2r3qZ4Q=\ngopkg.in/cheggaaa/pb.v1 v1.0.25/go.mod h1:V/YB90LKu/1FcN3WVnfiiE5oMCibMjukxqG/qStrOgw=\ngopkg.in/errgo.v2 v2.1.0/go.mod h1:hNsd1EY+bozCKY1Ytp96fpM3vjJbqLJn88ws8XvfDNI=\ngopkg.in/fsnotify/fsnotify.v1 v1.4.7 h1:XNNYLJHt73EyYiCZi6+xjupS9CpvmiDgjPTAjrBlQbo=\ngopkg.in/fsnotify/fsnotify.v1 v1.4.7/go.mod h1:Fyux9zXlo4rWoMSIzpn9fDAYjalPqJ/K1qJ27s+7ltE=\ngopkg.in/gcfg.v1 v1.2.3/go.mod h1:yesOnuUOFQAhST5vPY4nbZsb/huCgGGXlipJsBn0b3o=\ngopkg.in/gomail.v2 v2.0.0-20160411212932-81ebce5c23df h1:n7WqCuqOuCbNr617RXOY0AWRXxgwEyPp2z+p0+hgMuE=\ngopkg.in/gomail.v2 v2.0.0-20160411212932-81ebce5c23df/go.mod h1:LRQQ+SO6ZHR7tOkpBDuZnXENFzX8qRjMDMyPD6BRkCw=\ngopkg.in/inf.v0 v0.9.1 h1:73M5CoZyi3ZLMOyDlQh031Cx6N9NDJ2Vvfl76EDAgDc=\ngopkg.in/inf.v0 v0.9.1/go.mod h1:cWUDdTG/fYaXco+Dcufb5Vnc6Gp2YChqWtbxRZE0mXw=\ngopkg.in/ini.v1 v1.42.0/go.mod h1:pNLf8WUiyNEtQjuu5G5vTm06TEv9tsIgeAvK8hOrP4k=\ngopkg.in/ini.v1 v1.46.0/go.mod h1:pNLf8WUiyNEtQjuu5G5vTm06TEv9tsIgeAvK8hOrP4k=\ngopkg.in/ini.v1 v1.51.0 h1:AQvPpx3LzTDM0AjnIRlVFwFFGC+npRopjZxLJj6gdno=\ngopkg.in/ini.v1 v1.51.0/go.mod h1:pNLf8WUiyNEtQjuu5G5vTm06TEv9tsIgeAvK8hOrP4k=\ngopkg.in/natefinch/lumberjack.v2 v2.0.0/go.mod h1:l0ndWWf7gzL7RNwBG7wST/UCcT4T24xpD6X8LsfU/+k=\ngopkg.in/resty.v1 v1.12.0/go.mod h1:mDo4pnntr5jdWRML875a/NmxYqAlA73dVijT2AXvQQo=\ngopkg.in/square/go-jose.v2 v2.3.1/go.mod h1:M9dMgbHiYLoDGQrXy7OpJDJWiKiU//h+vD76mk0e1AI=\ngopkg.in/tomb.v1 v1.0.0-20141024135613-dd632973f1e7 h1:uRGJdciOHaEIrze2W8Q3AKkepLTh2hOroT7a+7czfdQ=\ngopkg.in/tomb.v1 v1.0.0-20141024135613-dd632973f1e7/go.mod h1:dt/ZhP58zS4L8KSrWDmTeBkI65Dw0HsyUHuEVlX15mw=\ngopkg.in/vmihailenco/msgpack.v2 v2.9.1/go.mod h1:/3Dn1Npt9+MYyLpYYXjInO/5jvMLamn+AEGwNEOatn8=\ngopkg.in/warnings.v0 v0.1.2/go.mod h1:jksf8JmL6Qr/oQM2OXTHunEvvTAsrWBLb6OOjuVWRNI=\ngopkg.in/yaml.v2 v2.0.0-20170812160011-eb3733d160e7/go.mod h1:JAlM8MvJe8wmxCU4Bli9HhUf9+ttbYbLASfIpnQbh74=\ngopkg.in/yaml.v2 v2.2.1/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.2/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.3/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.4/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.5/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.7/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.8/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.3.0/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.4.0 h1:D8xgwECY7CYvx+Y2n4sBz93Jn9JRvxdiyyo8CTfuKaY=\ngopkg.in/yaml.v2 v2.4.0/go.mod h1:RDklbk79AGWmwhnvt/jBztapEOGDOx6ZbXqjP6csGnQ=\ngopkg.in/yaml.v3 v3.0.0-20200121175148-a6ecf24a6d71/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.0-20200605160147-a5ece683394c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.0-20200615113413-eeeca48fe776/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.0-20210107192922-496545a6307b/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngotest.tools v2.2.0+incompatible h1:VsBPFP1AI068pPrMxtb/S8Zkgf9xEmTLJjfM+P5UIEo=\ngotest.tools v2.2.0+incompatible/go.mod h1:DsYFclhRJ6vuDpmuTbkuFWG+y2sxOXAzmJt81HFBacw=\ngotest.tools/v3 v3.0.2/go.mod h1:3SzNCllyD9/Y+b5r9JIKQ474KzkZyqLqEfYqMsX94Bk=\ngotest.tools/v3 v3.0.3 h1:4AuOwCGf4lLR9u3YOe2awrHygurzhO/HeQ6laiA6Sx0=\ngotest.tools/v3 v3.0.3/go.mod h1:Z7Lb0S5l+klDB31fvDQX8ss/FlKDxtlFlw3Oa8Ymbl8=\nhonnef.co/go/tools v0.0.0-20180728063816-88497007e858/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190102054323-c2f93a96b099/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190106161140-3f1c8253044a/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190418001031-e561f6794a2a/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190523083050-ea95bdfd59fc/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.1-2019.2.3/go.mod h1:a3bituU0lyd329TUQxRnasdCoJDkEUEAqEt0JzvZhAg=\nhonnef.co/go/tools v0.0.1-2020.1.3/go.mod h1:X/FiERA/W4tHapMX5mGpAtMSVEeEUOyHaw9vFzvIQ3k=\nhonnef.co/go/tools v0.0.1-2020.1.4/go.mod h1:X/FiERA/W4tHapMX5mGpAtMSVEeEUOyHaw9vFzvIQ3k=\nhonnef.co/go/tools v0.1.3/go.mod h1:NgwopIslSNH47DimFoV78dnkksY2EFtX0ajyb3K/las=\nhonnef.co/go/tools v0.4.3 h1:o/n5/K5gXqk8Gozvs2cnL0F2S1/g1vcGCAx2vETjITw=\nhonnef.co/go/tools v0.4.3/go.mod h1:36ZgoUOrqOk1GxwHhyryEkq8FQWkUO2xGuSMhUCcdvA=\nistio.io/api v0.0.0-20190515205759-982e5c3888c6/go.mod h1:hhLFQmpHia8zgaM37vb2ml9iS5NfNfqZGRt1pS9aVEo=\nistio.io/pkg v0.0.0-20200606170016-70c5172b9cdf h1:iNpiPvg8fcQxebYPrd9Dhjvqd+SIF7OFH+1qp89/nHQ=\nistio.io/pkg v0.0.0-20200606170016-70c5172b9cdf/go.mod h1:EwvmercDF5DLCg5qUQlkM40xHwCxGoY1H/2LhI1p2YU=\nk8s.io/api v0.20.5 h1:zsMTffV0Le2EiI0aKvlTHEnXGxk1HiqGRhJcCPiI7JI=\nk8s.io/api v0.20.5/go.mod h1:FQjAceXnVaWDeov2YUWhOb6Yt+5UjErkp6UO3nczO1Y=\nk8s.io/apimachinery v0.20.5/go.mod h1:WlLqWAHZGg07AeltaI0MV5uk1Omp8xaN0JGLY6gkRpU=\nk8s.io/apimachinery v0.21.0 h1:3Fx+41if+IRavNcKOz09FwEXDBG6ORh6iMsTSelhkMA=\nk8s.io/apimachinery v0.21.0/go.mod h1:jbreFvJo3ov9rj7eWT7+sYiRx+qZuCYXwWT1bcDswPY=\nk8s.io/client-go v0.20.5 h1:dJGtYUvFrFGjQ+GjXEIby0gZWdlAOc0xJBJqY3VyDxA=\nk8s.io/client-go v0.20.5/go.mod h1:Ee5OOMMYvlH8FCZhDsacjMlCBwetbGZETwo1OA+e6Zw=\nk8s.io/gengo v0.0.0-20200413195148-3a45101e95ac/go.mod h1:ezvh/TsK7cY6rbqRK0oQQ8IAqLxYwwyPxAX1Pzy0ii0=\nk8s.io/klog v1.0.0/go.mod h1:4Bi6QPql/J/LkTDqv7R/cd3hPo4k2DG6Ptcz060Ez5I=\nk8s.io/klog/v2 v2.0.0/go.mod h1:PBfzABfn139FHAV07az/IF9Wp1bkk3vpT2XSJ76fSDE=\nk8s.io/klog/v2 v2.4.0/go.mod h1:Od+F08eJP+W3HUb4pSrPpgp9DGU4GzlpG/TmITuYh/Y=\nk8s.io/klog/v2 v2.8.0 h1:Q3gmuM9hKEjefWFFYF0Mat+YyFJvsUyYuwyNNJ5C9Ts=\nk8s.io/klog/v2 v2.8.0/go.mod h1:hy9LJ/NvuK+iVyP4Ehqva4HxZG/oXyIS3n3Jmire4Ec=\nk8s.io/kube-openapi v0.0.0-20201113171705-d219536bb9fd/go.mod h1:WOJ3KddDSol4tAGcJo0Tvi+dK12EcqSLqcWsryKMpfM=\nk8s.io/kube-openapi v0.0.0-20210305001622-591a79e4bda7 h1:vEx13qjvaZ4yfObSSXW7BrMc/KQBBT/Jyee8XtLf4x0=\nk8s.io/kube-openapi v0.0.0-20210305001622-591a79e4bda7/go.mod h1:wXW5VT87nVfh/iLV8FpR2uDvrFyomxbtb1KivDbvPTE=\nk8s.io/utils v0.0.0-20201110183641-67b214c5f920 h1:CbnUZsM497iRC5QMVkHwyl8s2tB3g7yaSHkYPkpgelw=\nk8s.io/utils v0.0.0-20201110183641-67b214c5f920/go.mod h1:jPW/WVKK9YHAvNhRxK0md/EJ228hCsBRufyofKtW8HA=\nlabix.org/v2/mgo v0.0.0-20140701140051-000000000287/go.mod h1:Lg7AYkt1uXJoR9oeSZ3W/8IXLdvOfIITgZnommstyz4=\nlaunchpad.net/gocheck v0.0.0-20140225173054-000000000087/go.mod h1:hj7XX3B/0A+80Vse0e+BUHsHMTEhd0O4cpUHr/e/BUM=\nrsc.io/binaryregexp v0.2.0 h1:HfqmD5MEmC0zvwBuF187nq9mdnXjXsSivRiXN7SmRkE=\nrsc.io/binaryregexp v0.2.0/go.mod h1:qTv7/COck+e2FymRvadv62gMdZztPaShugOCi3I+8D8=\nrsc.io/pdf v0.1.1/go.mod h1:n8OzWcQ6Sp37PL01nO98y4iUCRdTGarVfzxY20ICaU4=\nrsc.io/quote/v3 v3.1.0/go.mod h1:yEA65RcK8LyAZtP9Kv3t0HmxON59tX3rD+tICJqUlj0=\nrsc.io/sampler v1.3.0/go.mod h1:T1hPZKmBbMNahiBKFy5HrXp6adAjACjK9JXDnKaTXpA=\nsigs.k8s.io/structured-merge-diff/v4 v4.0.2/go.mod h1:bJZC9H9iH24zzfZ/41RGcq60oK1F7G282QMXDPYydCw=\nsigs.k8s.io/structured-merge-diff/v4 v4.1.0 h1:C4r9BgJ98vrKnnVCjwCSXcWjWe0NKcUQkmzDXZXGwH8=\nsigs.k8s.io/structured-merge-diff/v4 v4.1.0/go.mod h1:bJZC9H9iH24zzfZ/41RGcq60oK1F7G282QMXDPYydCw=\nsigs.k8s.io/yaml v1.1.0/go.mod h1:UJmg0vDUVViEyp3mgSv9WPwZCDxu4rQW1olrI1uml+o=\nsigs.k8s.io/yaml v1.2.0 h1:kr/MCeFWJWTwyaHoR9c8EjH9OumOmoF9YGiZd7lFm/Q=\nsigs.k8s.io/yaml v1.2.0/go.mod h1:yfXDCHCao9+ENCvLSE62v9VSji2MKu5jeNfTrofGhJc=\nsourcegraph.com/sourcegraph/appdash v0.0.0-20190731080439-ebfcffb1b5c0/go.mod h1:hI742Nqp5OhwiqlzhgfbWU4mW4yO10fP+LoT9WOswdU=\n"
        },
        {
          "name": "gobuild.sh",
          "type": "blob",
          "size": 0.431640625,
          "content": "#!/bin/bash\n# This script run inside the Dockerfile_build_ubuntu64_git container and\n# gets the latests Go source code and compiles it.\n# Then passes control over to the normal build.py script\n\nset -e\n\ncd /go/src\ngit fetch --all\ngit checkout $GO_CHECKOUT\n# Merge in recent changes if we are on a branch\n# if we checked out a tag just ignore the error\ngit pull || true\n./make.bash\n\n# Run normal build.py\ncd \"$PROJECT_DIR\"\nexec ./build.py \"$@\"\n"
        },
        {
          "name": "group_by.go",
          "type": "blob",
          "size": 4.904296875,
          "content": "package kapacitor\n\nimport (\n\t\"sort\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/expvar\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n\t\"github.com/influxdata/kapacitor/tick/ast\"\n)\n\ntype GroupByNode struct {\n\tnode\n\tg *pipeline.GroupByNode\n\n\tbyName   bool\n\ttagNames []string\n\n\tbegin      edge.BeginBatchMessage\n\tdimensions models.Dimensions\n\n\tallDimensions bool\n\n\tmu       sync.RWMutex\n\tlastTime time.Time\n\tgroups   map[models.GroupID]edge.BufferedBatchMessage\n}\n\n// Create a new GroupByNode which splits the stream dynamically based on the specified dimensions.\nfunc newGroupByNode(et *ExecutingTask, n *pipeline.GroupByNode, d NodeDiagnostic) (*GroupByNode, error) {\n\tgn := &GroupByNode{\n\t\tnode:   node{Node: n, et: et, diag: d},\n\t\tg:      n,\n\t\tgroups: make(map[models.GroupID]edge.BufferedBatchMessage),\n\t}\n\tgn.node.runF = gn.runGroupBy\n\n\tgn.allDimensions, gn.tagNames = determineTagNames(n.Dimensions, n.ExcludedDimensions)\n\tgn.byName = n.ByMeasurementFlag\n\treturn gn, nil\n}\n\nfunc (n *GroupByNode) runGroupBy([]byte) error {\n\tvalueF := func() int64 {\n\t\tn.mu.RLock()\n\t\tl := len(n.groups)\n\t\tn.mu.RUnlock()\n\t\treturn int64(l)\n\t}\n\tn.statMap.Set(statCardinalityGauge, expvar.NewIntFuncGauge(valueF))\n\n\tconsumer := edge.NewConsumerWithReceiver(\n\t\tn.ins[0],\n\t\tn,\n\t)\n\treturn consumer.Consume()\n}\n\nfunc (n *GroupByNode) Point(p edge.PointMessage) error {\n\tp = p.ShallowCopy()\n\tn.timer.Start()\n\tdims := p.Dimensions()\n\tdims.ByName = dims.ByName || n.byName\n\tdims.TagNames = computeTagNames(p.Tags(), n.allDimensions, n.tagNames, n.g.ExcludedDimensions)\n\tp.SetDimensions(dims)\n\tn.timer.Stop()\n\tif err := edge.Forward(n.outs, p); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc (n *GroupByNode) BeginBatch(begin edge.BeginBatchMessage) error {\n\tn.timer.Start()\n\tdefer n.timer.Stop()\n\n\tif err := n.emit(begin.Time()); err != nil {\n\t\treturn err\n\t}\n\n\tn.begin = begin\n\tn.dimensions = begin.Dimensions()\n\tn.dimensions.ByName = n.dimensions.ByName || n.byName\n\n\treturn nil\n}\n\nfunc (n *GroupByNode) BatchPoint(bp edge.BatchPointMessage) error {\n\tn.timer.Start()\n\tdefer n.timer.Stop()\n\n\tn.dimensions.TagNames = computeTagNames(bp.Tags(), n.allDimensions, n.tagNames, n.g.ExcludedDimensions)\n\tgroupID := models.ToGroupID(n.begin.Name(), bp.Tags(), n.dimensions)\n\tgroup, ok := n.groups[groupID]\n\tif !ok {\n\t\t// Create new begin message\n\t\tnewBegin := n.begin.ShallowCopy()\n\t\tnewBegin.SetTagsAndDimensions(bp.Tags(), n.dimensions)\n\n\t\t// Create buffer for group batch\n\t\tgroup = edge.NewBufferedBatchMessage(\n\t\t\tnewBegin,\n\t\t\tmake([]edge.BatchPointMessage, 0, newBegin.SizeHint()),\n\t\t\tedge.NewEndBatchMessage(),\n\t\t)\n\t\tn.mu.Lock()\n\t\tn.groups[groupID] = group\n\t\tn.mu.Unlock()\n\t}\n\tgroup.SetPoints(append(group.Points(), bp))\n\n\treturn nil\n}\n\nfunc (n *GroupByNode) EndBatch(end edge.EndBatchMessage) error {\n\treturn nil\n}\n\nfunc (n *GroupByNode) Barrier(b edge.BarrierMessage) error {\n\tn.timer.Start()\n\terr := n.emit(b.Time())\n\tn.timer.Stop()\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn edge.Forward(n.outs, b)\n}\n\nfunc (n *GroupByNode) DeleteGroup(d edge.DeleteGroupMessage) error {\n\tn.timer.Start()\n\tn.mu.Lock()\n\tdelete(n.groups, d.GroupID())\n\tn.mu.Unlock()\n\tn.timer.Stop()\n\treturn edge.Forward(n.outs, d)\n}\n\nfunc (n *GroupByNode) Done() {}\n\n// emit sends all groups before time t to children nodes.\n// The node timer must be started when calling this method.\nfunc (n *GroupByNode) emit(t time.Time) error {\n\t// TODO: ensure this time comparison works with barrier messages\n\tif !t.Equal(n.lastTime) {\n\t\tn.lastTime = t\n\t\t// Emit all groups\n\t\tfor id, group := range n.groups {\n\t\t\t// Update SizeHint since we know the final point count\n\t\t\tgroup.Begin().SetSizeHint(len(group.Points()))\n\t\t\t// Sort points since we didn't guarantee insertion order was sorted\n\t\t\tsort.Sort(edge.BatchPointMessages(group.Points()))\n\t\t\t// Send group batch to all children\n\t\t\tn.timer.Pause()\n\t\t\tif err := edge.Forward(n.outs, group); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tn.timer.Resume()\n\t\t\tn.mu.Lock()\n\t\t\t// Remove from group\n\t\t\tdelete(n.groups, id)\n\t\t\tn.mu.Unlock()\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc determineTagNames(dimensions []interface{}, excluded []string) (allDimensions bool, realDimensions []string) {\n\tfor _, dim := range dimensions {\n\t\tswitch d := dim.(type) {\n\t\tcase string:\n\t\t\trealDimensions = append(realDimensions, d)\n\t\tcase *ast.StarNode:\n\t\t\tallDimensions = true\n\t\t}\n\t}\n\tsort.Strings(realDimensions)\n\trealDimensions = filterExcludedTagNames(realDimensions, excluded)\n\treturn\n}\n\nfunc filterExcludedTagNames(tagNames, excluded []string) []string {\n\tfiltered := tagNames[0:0]\n\tfor _, t := range tagNames {\n\t\tfound := false\n\t\tfor _, x := range excluded {\n\t\t\tif x == t {\n\t\t\t\tfound = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif !found {\n\t\t\tfiltered = append(filtered, t)\n\t\t}\n\t}\n\treturn filtered\n}\n\nfunc computeTagNames(tags models.Tags, allDimensions bool, tagNames, excluded []string) []string {\n\tif allDimensions {\n\t\treturn filterExcludedTagNames(models.SortedKeys(tags), excluded)\n\t}\n\treturn tagNames\n}\n"
        },
        {
          "name": "http",
          "type": "tree",
          "content": null
        },
        {
          "name": "http_out.go",
          "type": "blob",
          "size": 3.984375,
          "content": "package kapacitor\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"path\"\n\t\"sync\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n\t\"github.com/influxdata/kapacitor/services/httpd\"\n)\n\ntype HTTPOutNode struct {\n\tnode\n\tc *pipeline.HTTPOutNode\n\n\tendpoint string\n\n\tmu      sync.RWMutex\n\troutes  []httpd.Route\n\tresult  *models.Result\n\tindexes []*httpOutGroup\n}\n\n// Create a new  HTTPOutNode which caches the most recent item and exposes it over the HTTP API.\nfunc newHTTPOutNode(et *ExecutingTask, n *pipeline.HTTPOutNode, d NodeDiagnostic) (*HTTPOutNode, error) {\n\thn := &HTTPOutNode{\n\t\tnode:   node{Node: n, et: et, diag: d},\n\t\tc:      n,\n\t\tresult: new(models.Result),\n\t}\n\tet.registerOutput(hn.c.Endpoint, hn)\n\thn.node.runF = hn.runOut\n\thn.node.stopF = hn.stopOut\n\treturn hn, nil\n}\n\nfunc (n *HTTPOutNode) Endpoint() string {\n\treturn n.endpoint\n}\n\nfunc (n *HTTPOutNode) runOut([]byte) error {\n\thndl := func(w http.ResponseWriter, req *http.Request) {\n\t\tn.mu.RLock()\n\t\tdefer n.mu.RUnlock()\n\n\t\tif b, err := json.Marshal(n.result); err != nil {\n\t\t\thttpd.HttpError(\n\t\t\t\tw,\n\t\t\t\terr.Error(),\n\t\t\t\ttrue,\n\t\t\t\thttp.StatusInternalServerError,\n\t\t\t)\n\t\t} else {\n\t\t\t_, _ = w.Write(b)\n\t\t}\n\t}\n\n\tp := path.Join(\"/tasks/\", n.et.Task.ID, n.c.Endpoint)\n\n\tr := []httpd.Route{{\n\t\tMethod:      \"GET\",\n\t\tPattern:     p,\n\t\tHandlerFunc: hndl,\n\t}}\n\n\tn.endpoint = n.et.tm.HTTPDService.URL() + p\n\tn.mu.Lock()\n\tn.routes = r\n\tn.mu.Unlock()\n\n\terr := n.et.tm.HTTPDService.AddRoutes(r)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tconsumer := edge.NewGroupedConsumer(\n\t\tn.ins[0],\n\t\tn,\n\t)\n\tn.statMap.Set(statCardinalityGauge, consumer.CardinalityVar())\n\n\treturn consumer.Consume()\n}\n\n// Update the result structure with a row.\nfunc (n *HTTPOutNode) updateResultWithRow(idx int, row *models.Row) {\n\tn.mu.Lock()\n\tdefer n.mu.Unlock()\n\tif idx >= len(n.result.Series) {\n\t\tn.diag.Error(\"index out of range for row update\",\n\t\t\tfmt.Errorf(\"index %v is larger than number of series %v\", idx, len(n.result.Series)))\n\t\treturn\n\t}\n\tn.result.Series[idx] = row\n}\n\nfunc (n *HTTPOutNode) stopOut() {\n\tn.mu.Lock()\n\tdefer n.mu.Unlock()\n\tn.et.tm.HTTPDService.DelRoutes(n.routes)\n}\n\nfunc (n *HTTPOutNode) NewGroup(group edge.GroupInfo, first edge.PointMeta) (edge.Receiver, error) {\n\treturn edge.NewReceiverFromForwardReceiverWithStats(\n\t\tn.outs,\n\t\tedge.NewTimedForwardReceiver(n.timer, n.newGroup(group.ID)),\n\t), nil\n}\n\nfunc (n *HTTPOutNode) newGroup(groupID models.GroupID) *httpOutGroup {\n\tn.mu.Lock()\n\tdefer n.mu.Unlock()\n\n\tidx := len(n.result.Series)\n\tn.result.Series = append(n.result.Series, nil)\n\tg := &httpOutGroup{\n\t\tn:      n,\n\t\tidx:    idx,\n\t\tbuffer: new(edge.BatchBuffer),\n\t}\n\tn.indexes = append(n.indexes, g)\n\treturn g\n}\nfunc (n *HTTPOutNode) deleteGroup(idx int) {\n\tn.mu.Lock()\n\tdefer n.mu.Unlock()\n\n\tfor _, g := range n.indexes[idx+1:] {\n\t\tg.idx--\n\t}\n\tn.indexes = append(n.indexes[0:idx], n.indexes[idx+1:]...)\n\tn.result.Series = append(n.result.Series[0:idx], n.result.Series[idx+1:]...)\n}\n\ntype httpOutGroup struct {\n\tn      *HTTPOutNode\n\tidx    int\n\tbuffer *edge.BatchBuffer\n}\n\nfunc (g *httpOutGroup) BeginBatch(begin edge.BeginBatchMessage) (edge.Message, error) {\n\treturn nil, g.buffer.BeginBatch(begin)\n}\n\nfunc (g *httpOutGroup) BatchPoint(bp edge.BatchPointMessage) (edge.Message, error) {\n\treturn nil, g.buffer.BatchPoint(bp)\n}\n\nfunc (g *httpOutGroup) EndBatch(end edge.EndBatchMessage) (edge.Message, error) {\n\treturn g.BufferedBatch(g.buffer.BufferedBatchMessage(end))\n}\n\nfunc (g *httpOutGroup) BufferedBatch(batch edge.BufferedBatchMessage) (edge.Message, error) {\n\trow := batch.ToRow()\n\tg.n.updateResultWithRow(g.idx, row)\n\treturn batch, nil\n}\n\nfunc (g *httpOutGroup) Point(p edge.PointMessage) (edge.Message, error) {\n\trow := p.ToRow()\n\tg.n.updateResultWithRow(g.idx, row)\n\treturn p, nil\n}\n\nfunc (g *httpOutGroup) Barrier(b edge.BarrierMessage) (edge.Message, error) {\n\treturn b, nil\n}\nfunc (g *httpOutGroup) DeleteGroup(d edge.DeleteGroupMessage) (edge.Message, error) {\n\tg.n.deleteGroup(g.idx)\n\treturn d, nil\n}\nfunc (g *httpOutGroup) Done() {}\n"
        },
        {
          "name": "http_post.go",
          "type": "blob",
          "size": 5.6650390625,
          "content": "package kapacitor\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"strconv\"\n\t\"time\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/keyvalue\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n\t\"github.com/influxdata/kapacitor/services/httppost\"\n\t\"github.com/pkg/errors\"\n)\n\ntype HTTPPostNode struct {\n\tnode\n\tc        *pipeline.HTTPPostNode\n\tendpoint *httppost.Endpoint\n\ttimeout  time.Duration\n}\n\n// Create a new  HTTPPostNode which submits received items via POST to an HTTP endpoint\nfunc newHTTPPostNode(et *ExecutingTask, n *pipeline.HTTPPostNode, d NodeDiagnostic) (*HTTPPostNode, error) {\n\n\thn := &HTTPPostNode{\n\t\tnode:    node{Node: n, et: et, diag: d},\n\t\tc:       n,\n\t\ttimeout: n.Timeout,\n\t}\n\n\t// Should only ever be 0 or 1 from validation of n\n\tif len(n.URLs) == 1 {\n\t\ttemp, err := httppost.GetTemplate(n.URLs[0], \"\")\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"error in url templating\")\n\t\t}\n\n\t\te := httppost.NewEndpoint(temp, nil, httppost.BasicAuth{}, nil, nil)\n\t\thn.endpoint = e\n\t}\n\n\t// Should only ever be 0 or 1 from validation of n\n\tif len(n.Endpoints) == 1 {\n\t\tendpointName := n.Endpoints[0]\n\t\te, ok := et.tm.HTTPPostService.Endpoint(endpointName)\n\t\tif !ok {\n\t\t\treturn nil, fmt.Errorf(\"endpoint '%s' does not exist\", endpointName)\n\t\t}\n\t\thn.endpoint = e\n\t}\n\n\thn.node.runF = hn.runPost\n\treturn hn, nil\n}\n\nfunc (n *HTTPPostNode) runPost([]byte) error {\n\tconsumer := edge.NewGroupedConsumer(\n\t\tn.ins[0],\n\t\tn,\n\t)\n\tn.statMap.Set(statCardinalityGauge, consumer.CardinalityVar())\n\n\treturn consumer.Consume()\n\n}\n\nfunc (n *HTTPPostNode) NewGroup(group edge.GroupInfo, first edge.PointMeta) (edge.Receiver, error) {\n\tg := &httpPostGroup{\n\t\tn:      n,\n\t\tbuffer: new(edge.BatchBuffer),\n\t}\n\treturn edge.NewReceiverFromForwardReceiverWithStats(\n\t\tn.outs,\n\t\tedge.NewTimedForwardReceiver(n.timer, g),\n\t), nil\n}\n\ntype httpPostGroup struct {\n\tn      *HTTPPostNode\n\tbuffer *edge.BatchBuffer\n}\n\nfunc (g *httpPostGroup) BeginBatch(begin edge.BeginBatchMessage) (edge.Message, error) {\n\treturn nil, g.buffer.BeginBatch(begin)\n}\n\nfunc (g *httpPostGroup) BatchPoint(bp edge.BatchPointMessage) (edge.Message, error) {\n\treturn nil, g.buffer.BatchPoint(bp)\n}\n\nfunc (g *httpPostGroup) EndBatch(end edge.EndBatchMessage) (edge.Message, error) {\n\treturn g.BufferedBatch(g.buffer.BufferedBatchMessage(end))\n}\n\nfunc (g *httpPostGroup) BufferedBatch(batch edge.BufferedBatchMessage) (edge.Message, error) {\n\trow := batch.ToRow()\n\tcode := g.n.doPost(row)\n\tif g.n.c.CodeField != \"\" {\n\t\t//Add code to all points\n\t\tbatch = batch.ShallowCopy()\n\t\tpoints := make([]edge.BatchPointMessage, len(batch.Points()))\n\t\tfor i, bp := range batch.Points() {\n\t\t\tfields := bp.Fields().Copy()\n\t\t\tfields[g.n.c.CodeField] = int64(code)\n\t\t\tpoints[i] = edge.NewBatchPointMessage(\n\t\t\t\tfields,\n\t\t\t\tbp.Tags(),\n\t\t\t\tbp.Time(),\n\t\t\t)\n\t\t}\n\t\tbatch.SetPoints(points)\n\t}\n\treturn batch, nil\n}\n\nfunc (g *httpPostGroup) Point(p edge.PointMessage) (edge.Message, error) {\n\trow := p.ToRow()\n\tcode := g.n.doPost(row)\n\tif g.n.c.CodeField != \"\" {\n\t\t//Add code to point\n\t\tp = p.ShallowCopy()\n\t\tfields := p.Fields().Copy()\n\t\tfields[g.n.c.CodeField] = int64(code)\n\t\tp.SetFields(fields)\n\t}\n\treturn p, nil\n}\n\nfunc (g *httpPostGroup) Barrier(b edge.BarrierMessage) (edge.Message, error) {\n\treturn b, nil\n}\nfunc (g *httpPostGroup) DeleteGroup(d edge.DeleteGroupMessage) (edge.Message, error) {\n\treturn d, nil\n}\nfunc (g *httpPostGroup) Done() {}\n\nfunc (n *HTTPPostNode) doPost(row *models.Row) int {\n\tresp, err := n.postRow(row)\n\tif err != nil {\n\t\tn.diag.Error(\"failed to POST data\", err)\n\t\treturn 0\n\t}\n\tdefer resp.Body.Close()\n\tif resp.StatusCode/100 != 2 {\n\t\tvar err error\n\t\tif n.c.CaptureResponseFlag {\n\t\t\tvar body []byte\n\t\t\tbody, err = io.ReadAll(resp.Body)\n\t\t\tif err == nil {\n\t\t\t\t// Use the body content as the error\n\t\t\t\terr = errors.New(string(body))\n\t\t\t}\n\t\t} else {\n\t\t\terr = errors.New(\"unknown error, use .captureResponse() to capture the HTTP response\")\n\t\t}\n\t\tn.diag.Error(\"POST returned non 2xx status code\", err, keyvalue.KV(\"code\", strconv.Itoa(resp.StatusCode)))\n\t}\n\treturn resp.StatusCode\n}\n\nfunc (n *HTTPPostNode) postRow(row *models.Row) (*http.Response, error) {\n\tbody := new(bytes.Buffer)\n\n\tvar contentType string\n\tvar mr *mappedRow\n\tif n.endpoint.RowTemplate() != nil || n.endpoint.URL() != nil {\n\t\tmr = newMappedRow(row)\n\t}\n\tif n.endpoint.RowTemplate() != nil {\n\t\terr := n.endpoint.RowTemplate().Execute(body, mr)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to execute template\")\n\t\t}\n\t} else {\n\t\tresult := new(models.Result)\n\t\tresult.Series = []*models.Row{row}\n\t\terr := json.NewEncoder(body).Encode(result)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to marshal row data json\")\n\t\t}\n\t\tcontentType = \"application/json\"\n\t}\n\treq, err := n.endpoint.NewHTTPRequest(body, mr)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to marshal row data json\")\n\t}\n\n\t// Set content type and other headers\n\tif contentType != \"\" {\n\t\treq.Header.Set(\"Content-Type\", contentType)\n\t}\n\tfor k, v := range n.c.Headers {\n\t\treq.Header.Set(k, v)\n\t}\n\n\t// Set timeout\n\tif n.timeout > 0 {\n\t\tctx, cancel := context.WithTimeout(req.Context(), n.timeout)\n\t\tdefer cancel()\n\t\treq = req.WithContext(ctx)\n\t}\n\n\tresp, err := http.DefaultClient.Do(req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn resp, nil\n}\n\ntype mappedRow struct {\n\tName   string\n\tTags   map[string]string\n\tValues []map[string]interface{}\n}\n\nfunc newMappedRow(row *models.Row) *mappedRow {\n\tvalues := make([]map[string]interface{}, len(row.Values))\n\tfor i, v := range row.Values {\n\t\tvalues[i] = make(map[string]interface{}, len(row.Columns))\n\t\tfor c, col := range row.Columns {\n\t\t\tvalues[i][col] = v[c]\n\t\t}\n\t}\n\treturn &mappedRow{\n\t\tName:   row.Name,\n\t\tTags:   row.Tags,\n\t\tValues: values,\n\t}\n}\n"
        },
        {
          "name": "influxdb",
          "type": "tree",
          "content": null
        },
        {
          "name": "influxdb_out.go",
          "type": "blob",
          "size": 7.14453125,
          "content": "package kapacitor\n\nimport (\n\t\"bytes\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/influxdata/influxql\"\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/expvar\"\n\t\"github.com/influxdata/kapacitor/influxdb\"\n\t\"github.com/influxdata/kapacitor/keyvalue\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n\t\"github.com/pkg/errors\"\n)\n\nconst (\n\tstatsInfluxDBPointsWritten = \"points_written\"\n\tstatsInfluxDBWriteErrors   = \"write_errors\"\n)\n\ntype InfluxDBOutNode struct {\n\tnode\n\ti  *pipeline.InfluxDBOutNode\n\twb *writeBuffer\n\n\tpointsWritten *expvar.Int\n\twriteErrors   *expvar.Int\n\n\tbatchBuffer *edge.BatchBuffer\n}\n\nfunc newInfluxDBOutNode(et *ExecutingTask, n *pipeline.InfluxDBOutNode, d NodeDiagnostic) (*InfluxDBOutNode, error) {\n\tif et.tm.InfluxDBService == nil {\n\t\treturn nil, errors.New(\"no InfluxDB cluster configured cannot use the InfluxDBOutNode\")\n\t}\n\tcli, err := et.tm.InfluxDBService.NewNamedClient(n.Cluster)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to get InfluxDB client\")\n\t}\n\tin := &InfluxDBOutNode{\n\t\tnode:        node{Node: n, et: et, diag: d},\n\t\ti:           n,\n\t\twb:          newWriteBuffer(int(n.Buffer), n.FlushInterval, cli),\n\t\tbatchBuffer: new(edge.BatchBuffer),\n\t}\n\tin.node.runF = in.runOut\n\tin.node.stopF = in.stopOut\n\tin.wb.i = in\n\treturn in, nil\n}\n\nfunc (n *InfluxDBOutNode) runOut([]byte) error {\n\tn.pointsWritten = &expvar.Int{}\n\tn.writeErrors = &expvar.Int{}\n\n\tn.statMap.Set(statsInfluxDBPointsWritten, n.pointsWritten)\n\tn.statMap.Set(statsInfluxDBWriteErrors, n.writeErrors)\n\n\t// Start the write buffer\n\tn.wb.start()\n\n\t// Create the database and retention policy\n\tif n.i.CreateFlag {\n\t\terr := func() error {\n\t\t\tcli, err := n.et.tm.InfluxDBService.NewNamedClient(n.i.Cluster)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tvar createDb bytes.Buffer\n\t\t\tcreateDb.WriteString(\"CREATE DATABASE \")\n\t\t\tcreateDb.WriteString(influxql.QuoteIdent(n.i.Database))\n\t\t\tif n.i.RetentionPolicy != \"\" {\n\t\t\t\tcreateDb.WriteString(\" WITH NAME \")\n\t\t\t\tcreateDb.WriteString(influxql.QuoteIdent(n.i.RetentionPolicy))\n\t\t\t}\n\t\t\t_, err = cli.Query(influxdb.Query{Command: createDb.String()})\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\treturn nil\n\t\t}()\n\t\tif err != nil {\n\t\t\tn.diag.Error(\"failed to create database\", err, keyvalue.KV(\"database\", n.i.Database), keyvalue.KV(\"cluster\", n.i.Cluster))\n\t\t}\n\t}\n\n\t// Setup consumer\n\tconsumer := edge.NewConsumerWithReceiver(\n\t\tn.ins[0],\n\t\tedge.NewReceiverFromForwardReceiverWithStats(\n\t\t\tn.outs,\n\t\t\tedge.NewTimedForwardReceiver(n.timer, n),\n\t\t),\n\t)\n\treturn consumer.Consume()\n}\n\nfunc (n *InfluxDBOutNode) BeginBatch(begin edge.BeginBatchMessage) (edge.Message, error) {\n\treturn nil, n.batchBuffer.BeginBatch(begin)\n}\n\nfunc (n *InfluxDBOutNode) BatchPoint(bp edge.BatchPointMessage) (edge.Message, error) {\n\treturn nil, n.batchBuffer.BatchPoint(bp)\n}\n\nfunc (n *InfluxDBOutNode) EndBatch(end edge.EndBatchMessage) (edge.Message, error) {\n\treturn n.BufferedBatch(n.batchBuffer.BufferedBatchMessage(end))\n}\n\nfunc (n *InfluxDBOutNode) BufferedBatch(batch edge.BufferedBatchMessage) (edge.Message, error) {\n\tn.write(\"\", \"\", batch)\n\treturn batch, nil\n}\n\nfunc (n *InfluxDBOutNode) Point(p edge.PointMessage) (edge.Message, error) {\n\tbatch := edge.NewBufferedBatchMessage(\n\t\tedge.NewBeginBatchMessage(\n\t\t\tp.Name(),\n\t\t\tp.Tags(),\n\t\t\tp.Dimensions().ByName,\n\t\t\tp.Time(),\n\t\t\t1,\n\t\t),\n\t\t[]edge.BatchPointMessage{\n\t\t\tedge.NewBatchPointMessage(\n\t\t\t\tp.Fields(),\n\t\t\t\tp.Tags(),\n\t\t\t\tp.Time(),\n\t\t\t),\n\t\t},\n\t\tedge.NewEndBatchMessage(),\n\t)\n\tn.write(p.Database(), p.RetentionPolicy(), batch)\n\treturn p, nil\n}\n\nfunc (n *InfluxDBOutNode) Barrier(b edge.BarrierMessage) (edge.Message, error) {\n\treturn b, nil\n}\nfunc (n *InfluxDBOutNode) DeleteGroup(d edge.DeleteGroupMessage) (edge.Message, error) {\n\treturn d, nil\n}\nfunc (n *InfluxDBOutNode) Done() {}\n\nfunc (n *InfluxDBOutNode) stopOut() {\n\tn.wb.flush()\n\tn.wb.abort()\n}\n\nfunc (n *InfluxDBOutNode) write(db, rp string, batch edge.BufferedBatchMessage) error {\n\tif n.i.Database != \"\" {\n\t\tdb = n.i.Database\n\t}\n\tif n.i.RetentionPolicy != \"\" {\n\t\trp = n.i.RetentionPolicy\n\t}\n\tname := n.i.Measurement\n\tif name == \"\" {\n\t\tname = batch.Name()\n\t}\n\n\tpoints := make([]influxdb.Point, len(batch.Points()))\n\tfor j, p := range batch.Points() {\n\t\tvar tags map[string]string\n\t\tif len(n.i.Tags) > 0 {\n\t\t\ttags = make(map[string]string, len(p.Tags())+len(n.i.Tags))\n\t\t\tfor k, v := range p.Tags() {\n\t\t\t\ttags[k] = v\n\t\t\t}\n\t\t\tfor k, v := range n.i.Tags {\n\t\t\t\ttags[k] = v\n\t\t\t}\n\t\t} else {\n\t\t\ttags = p.Tags()\n\t\t}\n\t\tpoints[j] = influxdb.Point{\n\t\t\tName:   name,\n\t\t\tTags:   tags,\n\t\t\tFields: p.Fields(),\n\t\t\tTime:   p.Time(),\n\t\t}\n\t}\n\tbpc := influxdb.BatchPointsConfig{\n\t\tDatabase:         db,\n\t\tRetentionPolicy:  rp,\n\t\tWriteConsistency: n.i.WriteConsistency,\n\t\tPrecision:        n.i.Precision,\n\t}\n\tn.wb.enqueue(bpc, points)\n\treturn nil\n}\n\ntype writeBuffer struct {\n\tsize          int\n\tflushInterval time.Duration\n\tqueue         chan queueEntry\n\tbuffer        map[influxdb.BatchPointsConfig]influxdb.BatchPoints\n\n\tflushing chan struct{}\n\tflushed  chan struct{}\n\n\tstopping chan struct{}\n\twg       sync.WaitGroup\n\tcli      influxdb.Client\n\n\ti *InfluxDBOutNode\n}\n\ntype queueEntry struct {\n\tbpc    influxdb.BatchPointsConfig\n\tpoints []influxdb.Point\n}\n\nfunc newWriteBuffer(size int, flushInterval time.Duration, cli influxdb.Client) *writeBuffer {\n\treturn &writeBuffer{\n\t\tcli:           cli,\n\t\tsize:          size,\n\t\tflushInterval: flushInterval,\n\t\tflushing:      make(chan struct{}),\n\t\tflushed:       make(chan struct{}),\n\t\tqueue:         make(chan queueEntry),\n\t\tbuffer:        make(map[influxdb.BatchPointsConfig]influxdb.BatchPoints),\n\t\tstopping:      make(chan struct{}),\n\t}\n}\n\nfunc (w *writeBuffer) enqueue(bpc influxdb.BatchPointsConfig, points []influxdb.Point) {\n\tqe := queueEntry{\n\t\tbpc:    bpc,\n\t\tpoints: points,\n\t}\n\tselect {\n\tcase w.queue <- qe:\n\tcase <-w.stopping:\n\t}\n}\n\nfunc (w *writeBuffer) start() {\n\tw.wg.Add(1)\n\tgo w.run()\n}\n\nfunc (w *writeBuffer) flush() {\n\tw.flushing <- struct{}{}\n\t<-w.flushed\n}\n\nfunc (w *writeBuffer) abort() {\n\tclose(w.stopping)\n\tw.wg.Wait()\n}\n\nfunc (w *writeBuffer) run() {\n\tdefer w.wg.Done()\n\tflushTick := time.NewTicker(w.flushInterval)\n\tdefer flushTick.Stop()\n\tvar err error\n\tfor {\n\t\tselect {\n\t\tcase qe := <-w.queue:\n\t\t\t// Read incoming points off queue\n\t\t\tbp, ok := w.buffer[qe.bpc]\n\t\t\tif !ok {\n\t\t\t\tbp, err = influxdb.NewBatchPoints(qe.bpc)\n\t\t\t\tif err != nil {\n\t\t\t\t\tw.i.diag.Error(\"failed to write points to InfluxDB\", err)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\tw.buffer[qe.bpc] = bp\n\t\t\t}\n\t\t\tbp.AddPoints(qe.points)\n\t\t\t// Check if we hit buffer size\n\t\t\tif len(bp.Points()) >= w.size {\n\t\t\t\terr = w.write(bp)\n\t\t\t\tif err != nil {\n\t\t\t\t\tw.i.diag.Error(\"failed to write points to InfluxDB\", err)\n\t\t\t\t}\n\t\t\t\tdelete(w.buffer, qe.bpc)\n\t\t\t}\n\t\tcase <-w.flushing:\n\t\t\t// Explicit flush called\n\t\t\tw.writeAll()\n\t\t\tw.flushed <- struct{}{}\n\t\tcase <-flushTick.C:\n\t\t\t// Flush all points after flush interval timeout\n\t\t\tw.writeAll()\n\t\tcase <-w.stopping:\n\t\t\treturn\n\t\t}\n\t}\n}\n\nfunc (w *writeBuffer) writeAll() {\n\tfor bpc, bp := range w.buffer {\n\t\terr := w.write(bp)\n\t\tif err != nil {\n\t\t\tw.i.diag.Error(\"failed to write points to InfluxDB\", err)\n\t\t}\n\t\tdelete(w.buffer, bpc)\n\t}\n}\n\nfunc (w *writeBuffer) write(bp influxdb.BatchPoints) error {\n\terr := w.cli.Write(bp)\n\tif err != nil {\n\t\tw.i.writeErrors.Add(1)\n\t\treturn err\n\t}\n\tw.i.pointsWritten.Add(int64(len(bp.Points())))\n\treturn nil\n}\n"
        },
        {
          "name": "influxql.gen.go",
          "type": "blob",
          "size": 25.9677734375,
          "content": "// Generated by tmpl\n// https://github.com/benbjohnson/tmpl\n//\n// DO NOT EDIT!\n// Source: influxql.gen.go.tmpl\n\npackage kapacitor\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n\t\"time\"\n\n\t\"github.com/influxdata/influxdb/query\"\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n)\n\nfunc convertFloatPoint(\n\tname string,\n\tp edge.FieldsTagsTimeGetter,\n\tfield string,\n\tisSimpleSelector bool,\n\ttopBottomInfo *pipeline.TopBottomCallInfo,\n) (*query.FloatPoint, error) {\n\tvalue, ok := p.Fields()[field]\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"field %s missing from point cannot aggregate\", field)\n\t}\n\ttyped, ok := value.(float64)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"field %s has wrong type: got %T exp float64\", field, value)\n\t}\n\tap := &query.FloatPoint{\n\t\tName:  name,\n\t\tTags:  query.NewTags(p.Tags()),\n\t\tTime:  p.Time().UnixNano(),\n\t\tValue: typed,\n\t}\n\tif topBottomInfo != nil {\n\t\t// We need to populate the Aux fields\n\t\tfloatPopulateAuxFieldsAndTags(ap, topBottomInfo.FieldsAndTags, p.Fields(), p.Tags())\n\t}\n\n\tif isSimpleSelector {\n\t\tap.Aux = []interface{}{p.Tags(), p.Fields()}\n\t}\n\n\treturn ap, nil\n}\n\ntype floatPointAggregator struct {\n\tfield            string\n\ttopBottomInfo    *pipeline.TopBottomCallInfo\n\tisSimpleSelector bool\n\taggregator       query.FloatPointAggregator\n}\n\nfunc floatPopulateAuxFieldsAndTags(ap *query.FloatPoint, fieldsAndTags []string, fields models.Fields, tags models.Tags) {\n\tap.Aux = make([]interface{}, len(fieldsAndTags))\n\tfor i, name := range fieldsAndTags {\n\t\tif f, ok := fields[name]; ok {\n\t\t\tap.Aux[i] = f\n\t\t} else {\n\t\t\tap.Aux[i] = tags[name]\n\t\t}\n\t}\n}\n\nfunc (a *floatPointAggregator) AggregatePoint(name string, p edge.FieldsTagsTimeGetter) error {\n\tap, err := convertFloatPoint(name, p, a.field, a.isSimpleSelector, a.topBottomInfo)\n\tif err != nil {\n\t\treturn err\n\t}\n\ta.aggregator.AggregateFloat(ap)\n\treturn nil\n}\n\ntype floatPointEmitter struct {\n\tbaseReduceContext\n\temitter          query.FloatPointEmitter\n\tisSimpleSelector bool\n}\n\nfunc (e *floatPointEmitter) EmitPoint() (edge.PointMessage, error) {\n\tslice := e.emitter.Emit()\n\tif len(slice) != 1 {\n\t\treturn nil, nil\n\t}\n\tap := slice[0]\n\tvar t time.Time\n\tif e.pointTimes {\n\t\tif ap.Time == query.ZeroTime {\n\t\t\tt = e.time\n\t\t} else {\n\t\t\tt = time.Unix(0, ap.Time).UTC()\n\t\t}\n\t} else {\n\t\tt = e.time\n\t}\n\n\tvar fields models.Fields\n\tvar tags models.Tags\n\tif e.isSimpleSelector {\n\t\ttags = ap.Aux[0].(models.Tags)\n\t\tfields = ap.Aux[1].(models.Fields)\n\t\tif e.as != e.field {\n\t\t\tfields = fields.Copy()\n\t\t\tfields[e.as] = fields[e.field]\n\t\t\tdelete(fields, e.field)\n\t\t}\n\t} else {\n\t\ttags = e.groupInfo.Tags\n\t\tfields = map[string]interface{}{e.as: ap.Value}\n\t}\n\n\treturn edge.NewPointMessage(\n\t\te.name, \"\", \"\",\n\t\te.groupInfo.Dimensions,\n\t\tfields,\n\t\ttags,\n\t\tt,\n\t), nil\n}\n\nfunc (e *floatPointEmitter) EmitBatch() edge.BufferedBatchMessage {\n\tslice := e.emitter.Emit()\n\tbegin := edge.NewBeginBatchMessage(\n\t\te.name,\n\t\te.groupInfo.Tags,\n\t\te.groupInfo.Dimensions.ByName,\n\t\te.time,\n\t\tlen(slice),\n\t)\n\tpoints := make([]edge.BatchPointMessage, len(slice))\n\tvar t time.Time\n\tfor i, ap := range slice {\n\t\tif e.pointTimes {\n\t\t\tif ap.Time == query.ZeroTime {\n\t\t\t\tt = e.time\n\t\t\t} else {\n\t\t\t\tt = time.Unix(0, ap.Time).UTC()\n\t\t\t}\n\t\t} else {\n\t\t\tt = e.time\n\t\t}\n\t\tvar tags models.Tags\n\t\tif l := len(ap.Tags.KeyValues()); l > 0 {\n\t\t\t// Merge batch and point specific tags\n\t\t\ttags = make(models.Tags, len(e.groupInfo.Tags)+l)\n\t\t\tfor k, v := range e.groupInfo.Tags {\n\t\t\t\ttags[k] = v\n\t\t\t}\n\t\t\tfor k, v := range ap.Tags.KeyValues() {\n\t\t\t\ttags[k] = v\n\t\t\t}\n\t\t} else {\n\t\t\ttags = e.groupInfo.Tags\n\t\t}\n\t\tpoints[i] = edge.NewBatchPointMessage(\n\t\t\tmodels.Fields{e.as: ap.Value},\n\t\t\ttags,\n\t\t\tt,\n\t\t)\n\t\tif t.After(begin.Time()) {\n\t\t\tbegin.SetTime(t)\n\t\t}\n\t}\n\treturn edge.NewBufferedBatchMessage(\n\t\tbegin,\n\t\tpoints,\n\t\tedge.NewEndBatchMessage(),\n\t)\n}\n\nfunc convertIntegerPoint(\n\tname string,\n\tp edge.FieldsTagsTimeGetter,\n\tfield string,\n\tisSimpleSelector bool,\n\ttopBottomInfo *pipeline.TopBottomCallInfo,\n) (*query.IntegerPoint, error) {\n\tvalue, ok := p.Fields()[field]\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"field %s missing from point cannot aggregate\", field)\n\t}\n\ttyped, ok := value.(int64)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"field %s has wrong type: got %T exp int64\", field, value)\n\t}\n\tap := &query.IntegerPoint{\n\t\tName:  name,\n\t\tTags:  query.NewTags(p.Tags()),\n\t\tTime:  p.Time().UnixNano(),\n\t\tValue: typed,\n\t}\n\tif topBottomInfo != nil {\n\t\t// We need to populate the Aux fields\n\t\tintegerPopulateAuxFieldsAndTags(ap, topBottomInfo.FieldsAndTags, p.Fields(), p.Tags())\n\t}\n\n\tif isSimpleSelector {\n\t\tap.Aux = []interface{}{p.Tags(), p.Fields()}\n\t}\n\n\treturn ap, nil\n}\n\ntype integerPointAggregator struct {\n\tfield            string\n\ttopBottomInfo    *pipeline.TopBottomCallInfo\n\tisSimpleSelector bool\n\taggregator       query.IntegerPointAggregator\n}\n\nfunc integerPopulateAuxFieldsAndTags(ap *query.IntegerPoint, fieldsAndTags []string, fields models.Fields, tags models.Tags) {\n\tap.Aux = make([]interface{}, len(fieldsAndTags))\n\tfor i, name := range fieldsAndTags {\n\t\tif f, ok := fields[name]; ok {\n\t\t\tap.Aux[i] = f\n\t\t} else {\n\t\t\tap.Aux[i] = tags[name]\n\t\t}\n\t}\n}\n\nfunc (a *integerPointAggregator) AggregatePoint(name string, p edge.FieldsTagsTimeGetter) error {\n\tap, err := convertIntegerPoint(name, p, a.field, a.isSimpleSelector, a.topBottomInfo)\n\tif err != nil {\n\t\treturn err\n\t}\n\ta.aggregator.AggregateInteger(ap)\n\treturn nil\n}\n\ntype integerPointEmitter struct {\n\tbaseReduceContext\n\temitter          query.IntegerPointEmitter\n\tisSimpleSelector bool\n}\n\nfunc (e *integerPointEmitter) EmitPoint() (edge.PointMessage, error) {\n\tslice := e.emitter.Emit()\n\tif len(slice) != 1 {\n\t\treturn nil, nil\n\t}\n\tap := slice[0]\n\tvar t time.Time\n\tif e.pointTimes {\n\t\tif ap.Time == query.ZeroTime {\n\t\t\tt = e.time\n\t\t} else {\n\t\t\tt = time.Unix(0, ap.Time).UTC()\n\t\t}\n\t} else {\n\t\tt = e.time\n\t}\n\n\tvar fields models.Fields\n\tvar tags models.Tags\n\tif e.isSimpleSelector {\n\t\ttags = ap.Aux[0].(models.Tags)\n\t\tfields = ap.Aux[1].(models.Fields)\n\t\tif e.as != e.field {\n\t\t\tfields = fields.Copy()\n\t\t\tfields[e.as] = fields[e.field]\n\t\t\tdelete(fields, e.field)\n\t\t}\n\t} else {\n\t\ttags = e.groupInfo.Tags\n\t\tfields = map[string]interface{}{e.as: ap.Value}\n\t}\n\n\treturn edge.NewPointMessage(\n\t\te.name, \"\", \"\",\n\t\te.groupInfo.Dimensions,\n\t\tfields,\n\t\ttags,\n\t\tt,\n\t), nil\n}\n\nfunc (e *integerPointEmitter) EmitBatch() edge.BufferedBatchMessage {\n\tslice := e.emitter.Emit()\n\tbegin := edge.NewBeginBatchMessage(\n\t\te.name,\n\t\te.groupInfo.Tags,\n\t\te.groupInfo.Dimensions.ByName,\n\t\te.time,\n\t\tlen(slice),\n\t)\n\tpoints := make([]edge.BatchPointMessage, len(slice))\n\tvar t time.Time\n\tfor i, ap := range slice {\n\t\tif e.pointTimes {\n\t\t\tif ap.Time == query.ZeroTime {\n\t\t\t\tt = e.time\n\t\t\t} else {\n\t\t\t\tt = time.Unix(0, ap.Time).UTC()\n\t\t\t}\n\t\t} else {\n\t\t\tt = e.time\n\t\t}\n\t\tvar tags models.Tags\n\t\tif l := len(ap.Tags.KeyValues()); l > 0 {\n\t\t\t// Merge batch and point specific tags\n\t\t\ttags = make(models.Tags, len(e.groupInfo.Tags)+l)\n\t\t\tfor k, v := range e.groupInfo.Tags {\n\t\t\t\ttags[k] = v\n\t\t\t}\n\t\t\tfor k, v := range ap.Tags.KeyValues() {\n\t\t\t\ttags[k] = v\n\t\t\t}\n\t\t} else {\n\t\t\ttags = e.groupInfo.Tags\n\t\t}\n\t\tpoints[i] = edge.NewBatchPointMessage(\n\t\t\tmodels.Fields{e.as: ap.Value},\n\t\t\ttags,\n\t\t\tt,\n\t\t)\n\t\tif t.After(begin.Time()) {\n\t\t\tbegin.SetTime(t)\n\t\t}\n\t}\n\treturn edge.NewBufferedBatchMessage(\n\t\tbegin,\n\t\tpoints,\n\t\tedge.NewEndBatchMessage(),\n\t)\n}\n\nfunc convertStringPoint(\n\tname string,\n\tp edge.FieldsTagsTimeGetter,\n\tfield string,\n\tisSimpleSelector bool,\n\ttopBottomInfo *pipeline.TopBottomCallInfo,\n) (*query.StringPoint, error) {\n\tvalue, ok := p.Fields()[field]\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"field %s missing from point cannot aggregate\", field)\n\t}\n\ttyped, ok := value.(string)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"field %s has wrong type: got %T exp string\", field, value)\n\t}\n\tap := &query.StringPoint{\n\t\tName:  name,\n\t\tTags:  query.NewTags(p.Tags()),\n\t\tTime:  p.Time().UnixNano(),\n\t\tValue: typed,\n\t}\n\tif topBottomInfo != nil {\n\t\t// We need to populate the Aux fields\n\t\tstringPopulateAuxFieldsAndTags(ap, topBottomInfo.FieldsAndTags, p.Fields(), p.Tags())\n\t}\n\n\tif isSimpleSelector {\n\t\tap.Aux = []interface{}{p.Tags(), p.Fields()}\n\t}\n\n\treturn ap, nil\n}\n\ntype stringPointAggregator struct {\n\tfield            string\n\ttopBottomInfo    *pipeline.TopBottomCallInfo\n\tisSimpleSelector bool\n\taggregator       query.StringPointAggregator\n}\n\nfunc stringPopulateAuxFieldsAndTags(ap *query.StringPoint, fieldsAndTags []string, fields models.Fields, tags models.Tags) {\n\tap.Aux = make([]interface{}, len(fieldsAndTags))\n\tfor i, name := range fieldsAndTags {\n\t\tif f, ok := fields[name]; ok {\n\t\t\tap.Aux[i] = f\n\t\t} else {\n\t\t\tap.Aux[i] = tags[name]\n\t\t}\n\t}\n}\n\nfunc (a *stringPointAggregator) AggregatePoint(name string, p edge.FieldsTagsTimeGetter) error {\n\tap, err := convertStringPoint(name, p, a.field, a.isSimpleSelector, a.topBottomInfo)\n\tif err != nil {\n\t\treturn err\n\t}\n\ta.aggregator.AggregateString(ap)\n\treturn nil\n}\n\ntype stringPointEmitter struct {\n\tbaseReduceContext\n\temitter          query.StringPointEmitter\n\tisSimpleSelector bool\n}\n\nfunc (e *stringPointEmitter) EmitPoint() (edge.PointMessage, error) {\n\tslice := e.emitter.Emit()\n\tif len(slice) != 1 {\n\t\treturn nil, nil\n\t}\n\tap := slice[0]\n\tvar t time.Time\n\tif e.pointTimes {\n\t\tif ap.Time == query.ZeroTime {\n\t\t\tt = e.time\n\t\t} else {\n\t\t\tt = time.Unix(0, ap.Time).UTC()\n\t\t}\n\t} else {\n\t\tt = e.time\n\t}\n\n\tvar fields models.Fields\n\tvar tags models.Tags\n\tif e.isSimpleSelector {\n\t\ttags = ap.Aux[0].(models.Tags)\n\t\tfields = ap.Aux[1].(models.Fields)\n\t\tif e.as != e.field {\n\t\t\tfields = fields.Copy()\n\t\t\tfields[e.as] = fields[e.field]\n\t\t\tdelete(fields, e.field)\n\t\t}\n\t} else {\n\t\ttags = e.groupInfo.Tags\n\t\tfields = map[string]interface{}{e.as: ap.Value}\n\t}\n\n\treturn edge.NewPointMessage(\n\t\te.name, \"\", \"\",\n\t\te.groupInfo.Dimensions,\n\t\tfields,\n\t\ttags,\n\t\tt,\n\t), nil\n}\n\nfunc (e *stringPointEmitter) EmitBatch() edge.BufferedBatchMessage {\n\tslice := e.emitter.Emit()\n\tbegin := edge.NewBeginBatchMessage(\n\t\te.name,\n\t\te.groupInfo.Tags,\n\t\te.groupInfo.Dimensions.ByName,\n\t\te.time,\n\t\tlen(slice),\n\t)\n\tpoints := make([]edge.BatchPointMessage, len(slice))\n\tvar t time.Time\n\tfor i, ap := range slice {\n\t\tif e.pointTimes {\n\t\t\tif ap.Time == query.ZeroTime {\n\t\t\t\tt = e.time\n\t\t\t} else {\n\t\t\t\tt = time.Unix(0, ap.Time).UTC()\n\t\t\t}\n\t\t} else {\n\t\t\tt = e.time\n\t\t}\n\t\tvar tags models.Tags\n\t\tif l := len(ap.Tags.KeyValues()); l > 0 {\n\t\t\t// Merge batch and point specific tags\n\t\t\ttags = make(models.Tags, len(e.groupInfo.Tags)+l)\n\t\t\tfor k, v := range e.groupInfo.Tags {\n\t\t\t\ttags[k] = v\n\t\t\t}\n\t\t\tfor k, v := range ap.Tags.KeyValues() {\n\t\t\t\ttags[k] = v\n\t\t\t}\n\t\t} else {\n\t\t\ttags = e.groupInfo.Tags\n\t\t}\n\t\tpoints[i] = edge.NewBatchPointMessage(\n\t\t\tmodels.Fields{e.as: ap.Value},\n\t\t\ttags,\n\t\t\tt,\n\t\t)\n\t\tif t.After(begin.Time()) {\n\t\t\tbegin.SetTime(t)\n\t\t}\n\t}\n\treturn edge.NewBufferedBatchMessage(\n\t\tbegin,\n\t\tpoints,\n\t\tedge.NewEndBatchMessage(),\n\t)\n}\n\nfunc convertBooleanPoint(\n\tname string,\n\tp edge.FieldsTagsTimeGetter,\n\tfield string,\n\tisSimpleSelector bool,\n\ttopBottomInfo *pipeline.TopBottomCallInfo,\n) (*query.BooleanPoint, error) {\n\tvalue, ok := p.Fields()[field]\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"field %s missing from point cannot aggregate\", field)\n\t}\n\ttyped, ok := value.(bool)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"field %s has wrong type: got %T exp bool\", field, value)\n\t}\n\tap := &query.BooleanPoint{\n\t\tName:  name,\n\t\tTags:  query.NewTags(p.Tags()),\n\t\tTime:  p.Time().UnixNano(),\n\t\tValue: typed,\n\t}\n\tif topBottomInfo != nil {\n\t\t// We need to populate the Aux fields\n\t\tbooleanPopulateAuxFieldsAndTags(ap, topBottomInfo.FieldsAndTags, p.Fields(), p.Tags())\n\t}\n\n\tif isSimpleSelector {\n\t\tap.Aux = []interface{}{p.Tags(), p.Fields()}\n\t}\n\n\treturn ap, nil\n}\n\ntype booleanPointAggregator struct {\n\tfield            string\n\ttopBottomInfo    *pipeline.TopBottomCallInfo\n\tisSimpleSelector bool\n\taggregator       query.BooleanPointAggregator\n}\n\nfunc booleanPopulateAuxFieldsAndTags(ap *query.BooleanPoint, fieldsAndTags []string, fields models.Fields, tags models.Tags) {\n\tap.Aux = make([]interface{}, len(fieldsAndTags))\n\tfor i, name := range fieldsAndTags {\n\t\tif f, ok := fields[name]; ok {\n\t\t\tap.Aux[i] = f\n\t\t} else {\n\t\t\tap.Aux[i] = tags[name]\n\t\t}\n\t}\n}\n\nfunc (a *booleanPointAggregator) AggregatePoint(name string, p edge.FieldsTagsTimeGetter) error {\n\tap, err := convertBooleanPoint(name, p, a.field, a.isSimpleSelector, a.topBottomInfo)\n\tif err != nil {\n\t\treturn err\n\t}\n\ta.aggregator.AggregateBoolean(ap)\n\treturn nil\n}\n\ntype booleanPointEmitter struct {\n\tbaseReduceContext\n\temitter          query.BooleanPointEmitter\n\tisSimpleSelector bool\n}\n\nfunc (e *booleanPointEmitter) EmitPoint() (edge.PointMessage, error) {\n\tslice := e.emitter.Emit()\n\tif len(slice) != 1 {\n\t\treturn nil, nil\n\t}\n\tap := slice[0]\n\tvar t time.Time\n\tif e.pointTimes {\n\t\tif ap.Time == query.ZeroTime {\n\t\t\tt = e.time\n\t\t} else {\n\t\t\tt = time.Unix(0, ap.Time).UTC()\n\t\t}\n\t} else {\n\t\tt = e.time\n\t}\n\n\tvar fields models.Fields\n\tvar tags models.Tags\n\tif e.isSimpleSelector {\n\t\ttags = ap.Aux[0].(models.Tags)\n\t\tfields = ap.Aux[1].(models.Fields)\n\t\tif e.as != e.field {\n\t\t\tfields = fields.Copy()\n\t\t\tfields[e.as] = fields[e.field]\n\t\t\tdelete(fields, e.field)\n\t\t}\n\t} else {\n\t\ttags = e.groupInfo.Tags\n\t\tfields = map[string]interface{}{e.as: ap.Value}\n\t}\n\n\treturn edge.NewPointMessage(\n\t\te.name, \"\", \"\",\n\t\te.groupInfo.Dimensions,\n\t\tfields,\n\t\ttags,\n\t\tt,\n\t), nil\n}\n\nfunc (e *booleanPointEmitter) EmitBatch() edge.BufferedBatchMessage {\n\tslice := e.emitter.Emit()\n\tbegin := edge.NewBeginBatchMessage(\n\t\te.name,\n\t\te.groupInfo.Tags,\n\t\te.groupInfo.Dimensions.ByName,\n\t\te.time,\n\t\tlen(slice),\n\t)\n\tpoints := make([]edge.BatchPointMessage, len(slice))\n\tvar t time.Time\n\tfor i, ap := range slice {\n\t\tif e.pointTimes {\n\t\t\tif ap.Time == query.ZeroTime {\n\t\t\t\tt = e.time\n\t\t\t} else {\n\t\t\t\tt = time.Unix(0, ap.Time).UTC()\n\t\t\t}\n\t\t} else {\n\t\t\tt = e.time\n\t\t}\n\t\tvar tags models.Tags\n\t\tif l := len(ap.Tags.KeyValues()); l > 0 {\n\t\t\t// Merge batch and point specific tags\n\t\t\ttags = make(models.Tags, len(e.groupInfo.Tags)+l)\n\t\t\tfor k, v := range e.groupInfo.Tags {\n\t\t\t\ttags[k] = v\n\t\t\t}\n\t\t\tfor k, v := range ap.Tags.KeyValues() {\n\t\t\t\ttags[k] = v\n\t\t\t}\n\t\t} else {\n\t\t\ttags = e.groupInfo.Tags\n\t\t}\n\t\tpoints[i] = edge.NewBatchPointMessage(\n\t\t\tmodels.Fields{e.as: ap.Value},\n\t\t\ttags,\n\t\t\tt,\n\t\t)\n\t\tif t.After(begin.Time()) {\n\t\t\tbegin.SetTime(t)\n\t\t}\n\t}\n\treturn edge.NewBufferedBatchMessage(\n\t\tbegin,\n\t\tpoints,\n\t\tedge.NewEndBatchMessage(),\n\t)\n}\n\n// floatReduceContext uses composition to implement the reduceContext interface\ntype floatReduceContext struct {\n\tfloatPointAggregator\n\tfloatPointEmitter\n}\n\n// floatIntegerReduceContext uses composition to implement the reduceContext interface\ntype floatIntegerReduceContext struct {\n\tfloatPointAggregator\n\tintegerPointEmitter\n}\n\n// floatStringReduceContext uses composition to implement the reduceContext interface\ntype floatStringReduceContext struct {\n\tfloatPointAggregator\n\tstringPointEmitter\n}\n\n// floatBooleanReduceContext uses composition to implement the reduceContext interface\ntype floatBooleanReduceContext struct {\n\tfloatPointAggregator\n\tbooleanPointEmitter\n}\n\n// integerFloatReduceContext uses composition to implement the reduceContext interface\ntype integerFloatReduceContext struct {\n\tintegerPointAggregator\n\tfloatPointEmitter\n}\n\n// integerReduceContext uses composition to implement the reduceContext interface\ntype integerReduceContext struct {\n\tintegerPointAggregator\n\tintegerPointEmitter\n}\n\n// integerStringReduceContext uses composition to implement the reduceContext interface\ntype integerStringReduceContext struct {\n\tintegerPointAggregator\n\tstringPointEmitter\n}\n\n// integerBooleanReduceContext uses composition to implement the reduceContext interface\ntype integerBooleanReduceContext struct {\n\tintegerPointAggregator\n\tbooleanPointEmitter\n}\n\n// stringFloatReduceContext uses composition to implement the reduceContext interface\ntype stringFloatReduceContext struct {\n\tstringPointAggregator\n\tfloatPointEmitter\n}\n\n// stringIntegerReduceContext uses composition to implement the reduceContext interface\ntype stringIntegerReduceContext struct {\n\tstringPointAggregator\n\tintegerPointEmitter\n}\n\n// stringReduceContext uses composition to implement the reduceContext interface\ntype stringReduceContext struct {\n\tstringPointAggregator\n\tstringPointEmitter\n}\n\n// stringBooleanReduceContext uses composition to implement the reduceContext interface\ntype stringBooleanReduceContext struct {\n\tstringPointAggregator\n\tbooleanPointEmitter\n}\n\n// booleanFloatReduceContext uses composition to implement the reduceContext interface\ntype booleanFloatReduceContext struct {\n\tbooleanPointAggregator\n\tfloatPointEmitter\n}\n\n// booleanIntegerReduceContext uses composition to implement the reduceContext interface\ntype booleanIntegerReduceContext struct {\n\tbooleanPointAggregator\n\tintegerPointEmitter\n}\n\n// booleanStringReduceContext uses composition to implement the reduceContext interface\ntype booleanStringReduceContext struct {\n\tbooleanPointAggregator\n\tstringPointEmitter\n}\n\n// booleanReduceContext uses composition to implement the reduceContext interface\ntype booleanReduceContext struct {\n\tbooleanPointAggregator\n\tbooleanPointEmitter\n}\n\nfunc determineReduceContextCreateFn(method string, kind reflect.Kind, rc pipeline.ReduceCreater) (fn createReduceContextFunc, err error) {\n\tswitch kind {\n\n\tcase reflect.Float64:\n\t\tswitch {\n\n\t\tcase rc.CreateFloatReducer != nil:\n\t\t\tfn = func(c baseReduceContext) reduceContext {\n\t\t\t\ta, e := rc.CreateFloatReducer()\n\t\t\t\treturn &floatReduceContext{\n\t\t\t\t\tfloatPointAggregator: floatPointAggregator{\n\t\t\t\t\t\tfield:            c.field,\n\t\t\t\t\t\ttopBottomInfo:    rc.TopBottomCallInfo,\n\t\t\t\t\t\tisSimpleSelector: rc.IsSimpleSelector,\n\t\t\t\t\t\taggregator:       a,\n\t\t\t\t\t},\n\t\t\t\t\tfloatPointEmitter: floatPointEmitter{\n\t\t\t\t\t\tbaseReduceContext: c,\n\t\t\t\t\t\temitter:           e,\n\t\t\t\t\t\tisSimpleSelector:  rc.IsSimpleSelector,\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase rc.CreateFloatIntegerReducer != nil:\n\t\t\tfn = func(c baseReduceContext) reduceContext {\n\t\t\t\ta, e := rc.CreateFloatIntegerReducer()\n\t\t\t\treturn &floatIntegerReduceContext{\n\t\t\t\t\tfloatPointAggregator: floatPointAggregator{\n\t\t\t\t\t\tfield:            c.field,\n\t\t\t\t\t\ttopBottomInfo:    rc.TopBottomCallInfo,\n\t\t\t\t\t\tisSimpleSelector: rc.IsSimpleSelector,\n\t\t\t\t\t\taggregator:       a,\n\t\t\t\t\t},\n\t\t\t\t\tintegerPointEmitter: integerPointEmitter{\n\t\t\t\t\t\tbaseReduceContext: c,\n\t\t\t\t\t\temitter:           e,\n\t\t\t\t\t\tisSimpleSelector:  rc.IsSimpleSelector,\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase rc.CreateFloatStringReducer != nil:\n\t\t\tfn = func(c baseReduceContext) reduceContext {\n\t\t\t\ta, e := rc.CreateFloatStringReducer()\n\t\t\t\treturn &floatStringReduceContext{\n\t\t\t\t\tfloatPointAggregator: floatPointAggregator{\n\t\t\t\t\t\tfield:            c.field,\n\t\t\t\t\t\ttopBottomInfo:    rc.TopBottomCallInfo,\n\t\t\t\t\t\tisSimpleSelector: rc.IsSimpleSelector,\n\t\t\t\t\t\taggregator:       a,\n\t\t\t\t\t},\n\t\t\t\t\tstringPointEmitter: stringPointEmitter{\n\t\t\t\t\t\tbaseReduceContext: c,\n\t\t\t\t\t\temitter:           e,\n\t\t\t\t\t\tisSimpleSelector:  rc.IsSimpleSelector,\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase rc.CreateFloatBooleanReducer != nil:\n\t\t\tfn = func(c baseReduceContext) reduceContext {\n\t\t\t\ta, e := rc.CreateFloatBooleanReducer()\n\t\t\t\treturn &floatBooleanReduceContext{\n\t\t\t\t\tfloatPointAggregator: floatPointAggregator{\n\t\t\t\t\t\tfield:            c.field,\n\t\t\t\t\t\ttopBottomInfo:    rc.TopBottomCallInfo,\n\t\t\t\t\t\tisSimpleSelector: rc.IsSimpleSelector,\n\t\t\t\t\t\taggregator:       a,\n\t\t\t\t\t},\n\t\t\t\t\tbooleanPointEmitter: booleanPointEmitter{\n\t\t\t\t\t\tbaseReduceContext: c,\n\t\t\t\t\t\temitter:           e,\n\t\t\t\t\t\tisSimpleSelector:  rc.IsSimpleSelector,\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n\n\t\tdefault:\n\t\t\terr = fmt.Errorf(\"cannot apply %s to float64 field\", method)\n\t\t}\n\n\tcase reflect.Int64:\n\t\tswitch {\n\n\t\tcase rc.CreateIntegerFloatReducer != nil:\n\t\t\tfn = func(c baseReduceContext) reduceContext {\n\t\t\t\ta, e := rc.CreateIntegerFloatReducer()\n\t\t\t\treturn &integerFloatReduceContext{\n\t\t\t\t\tintegerPointAggregator: integerPointAggregator{\n\t\t\t\t\t\tfield:            c.field,\n\t\t\t\t\t\ttopBottomInfo:    rc.TopBottomCallInfo,\n\t\t\t\t\t\tisSimpleSelector: rc.IsSimpleSelector,\n\t\t\t\t\t\taggregator:       a,\n\t\t\t\t\t},\n\t\t\t\t\tfloatPointEmitter: floatPointEmitter{\n\t\t\t\t\t\tbaseReduceContext: c,\n\t\t\t\t\t\temitter:           e,\n\t\t\t\t\t\tisSimpleSelector:  rc.IsSimpleSelector,\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase rc.CreateIntegerReducer != nil:\n\t\t\tfn = func(c baseReduceContext) reduceContext {\n\t\t\t\ta, e := rc.CreateIntegerReducer()\n\t\t\t\treturn &integerReduceContext{\n\t\t\t\t\tintegerPointAggregator: integerPointAggregator{\n\t\t\t\t\t\tfield:            c.field,\n\t\t\t\t\t\ttopBottomInfo:    rc.TopBottomCallInfo,\n\t\t\t\t\t\tisSimpleSelector: rc.IsSimpleSelector,\n\t\t\t\t\t\taggregator:       a,\n\t\t\t\t\t},\n\t\t\t\t\tintegerPointEmitter: integerPointEmitter{\n\t\t\t\t\t\tbaseReduceContext: c,\n\t\t\t\t\t\temitter:           e,\n\t\t\t\t\t\tisSimpleSelector:  rc.IsSimpleSelector,\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase rc.CreateIntegerStringReducer != nil:\n\t\t\tfn = func(c baseReduceContext) reduceContext {\n\t\t\t\ta, e := rc.CreateIntegerStringReducer()\n\t\t\t\treturn &integerStringReduceContext{\n\t\t\t\t\tintegerPointAggregator: integerPointAggregator{\n\t\t\t\t\t\tfield:            c.field,\n\t\t\t\t\t\ttopBottomInfo:    rc.TopBottomCallInfo,\n\t\t\t\t\t\tisSimpleSelector: rc.IsSimpleSelector,\n\t\t\t\t\t\taggregator:       a,\n\t\t\t\t\t},\n\t\t\t\t\tstringPointEmitter: stringPointEmitter{\n\t\t\t\t\t\tbaseReduceContext: c,\n\t\t\t\t\t\temitter:           e,\n\t\t\t\t\t\tisSimpleSelector:  rc.IsSimpleSelector,\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase rc.CreateIntegerBooleanReducer != nil:\n\t\t\tfn = func(c baseReduceContext) reduceContext {\n\t\t\t\ta, e := rc.CreateIntegerBooleanReducer()\n\t\t\t\treturn &integerBooleanReduceContext{\n\t\t\t\t\tintegerPointAggregator: integerPointAggregator{\n\t\t\t\t\t\tfield:            c.field,\n\t\t\t\t\t\ttopBottomInfo:    rc.TopBottomCallInfo,\n\t\t\t\t\t\tisSimpleSelector: rc.IsSimpleSelector,\n\t\t\t\t\t\taggregator:       a,\n\t\t\t\t\t},\n\t\t\t\t\tbooleanPointEmitter: booleanPointEmitter{\n\t\t\t\t\t\tbaseReduceContext: c,\n\t\t\t\t\t\temitter:           e,\n\t\t\t\t\t\tisSimpleSelector:  rc.IsSimpleSelector,\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n\n\t\tdefault:\n\t\t\terr = fmt.Errorf(\"cannot apply %s to int64 field\", method)\n\t\t}\n\n\tcase reflect.String:\n\t\tswitch {\n\n\t\tcase rc.CreateStringFloatReducer != nil:\n\t\t\tfn = func(c baseReduceContext) reduceContext {\n\t\t\t\ta, e := rc.CreateStringFloatReducer()\n\t\t\t\treturn &stringFloatReduceContext{\n\t\t\t\t\tstringPointAggregator: stringPointAggregator{\n\t\t\t\t\t\tfield:            c.field,\n\t\t\t\t\t\ttopBottomInfo:    rc.TopBottomCallInfo,\n\t\t\t\t\t\tisSimpleSelector: rc.IsSimpleSelector,\n\t\t\t\t\t\taggregator:       a,\n\t\t\t\t\t},\n\t\t\t\t\tfloatPointEmitter: floatPointEmitter{\n\t\t\t\t\t\tbaseReduceContext: c,\n\t\t\t\t\t\temitter:           e,\n\t\t\t\t\t\tisSimpleSelector:  rc.IsSimpleSelector,\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase rc.CreateStringIntegerReducer != nil:\n\t\t\tfn = func(c baseReduceContext) reduceContext {\n\t\t\t\ta, e := rc.CreateStringIntegerReducer()\n\t\t\t\treturn &stringIntegerReduceContext{\n\t\t\t\t\tstringPointAggregator: stringPointAggregator{\n\t\t\t\t\t\tfield:            c.field,\n\t\t\t\t\t\ttopBottomInfo:    rc.TopBottomCallInfo,\n\t\t\t\t\t\tisSimpleSelector: rc.IsSimpleSelector,\n\t\t\t\t\t\taggregator:       a,\n\t\t\t\t\t},\n\t\t\t\t\tintegerPointEmitter: integerPointEmitter{\n\t\t\t\t\t\tbaseReduceContext: c,\n\t\t\t\t\t\temitter:           e,\n\t\t\t\t\t\tisSimpleSelector:  rc.IsSimpleSelector,\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase rc.CreateStringReducer != nil:\n\t\t\tfn = func(c baseReduceContext) reduceContext {\n\t\t\t\ta, e := rc.CreateStringReducer()\n\t\t\t\treturn &stringReduceContext{\n\t\t\t\t\tstringPointAggregator: stringPointAggregator{\n\t\t\t\t\t\tfield:            c.field,\n\t\t\t\t\t\ttopBottomInfo:    rc.TopBottomCallInfo,\n\t\t\t\t\t\tisSimpleSelector: rc.IsSimpleSelector,\n\t\t\t\t\t\taggregator:       a,\n\t\t\t\t\t},\n\t\t\t\t\tstringPointEmitter: stringPointEmitter{\n\t\t\t\t\t\tbaseReduceContext: c,\n\t\t\t\t\t\temitter:           e,\n\t\t\t\t\t\tisSimpleSelector:  rc.IsSimpleSelector,\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase rc.CreateStringBooleanReducer != nil:\n\t\t\tfn = func(c baseReduceContext) reduceContext {\n\t\t\t\ta, e := rc.CreateStringBooleanReducer()\n\t\t\t\treturn &stringBooleanReduceContext{\n\t\t\t\t\tstringPointAggregator: stringPointAggregator{\n\t\t\t\t\t\tfield:            c.field,\n\t\t\t\t\t\ttopBottomInfo:    rc.TopBottomCallInfo,\n\t\t\t\t\t\tisSimpleSelector: rc.IsSimpleSelector,\n\t\t\t\t\t\taggregator:       a,\n\t\t\t\t\t},\n\t\t\t\t\tbooleanPointEmitter: booleanPointEmitter{\n\t\t\t\t\t\tbaseReduceContext: c,\n\t\t\t\t\t\temitter:           e,\n\t\t\t\t\t\tisSimpleSelector:  rc.IsSimpleSelector,\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n\n\t\tdefault:\n\t\t\terr = fmt.Errorf(\"cannot apply %s to string field\", method)\n\t\t}\n\n\tcase reflect.Bool:\n\t\tswitch {\n\n\t\tcase rc.CreateBooleanFloatReducer != nil:\n\t\t\tfn = func(c baseReduceContext) reduceContext {\n\t\t\t\ta, e := rc.CreateBooleanFloatReducer()\n\t\t\t\treturn &booleanFloatReduceContext{\n\t\t\t\t\tbooleanPointAggregator: booleanPointAggregator{\n\t\t\t\t\t\tfield:            c.field,\n\t\t\t\t\t\ttopBottomInfo:    rc.TopBottomCallInfo,\n\t\t\t\t\t\tisSimpleSelector: rc.IsSimpleSelector,\n\t\t\t\t\t\taggregator:       a,\n\t\t\t\t\t},\n\t\t\t\t\tfloatPointEmitter: floatPointEmitter{\n\t\t\t\t\t\tbaseReduceContext: c,\n\t\t\t\t\t\temitter:           e,\n\t\t\t\t\t\tisSimpleSelector:  rc.IsSimpleSelector,\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase rc.CreateBooleanIntegerReducer != nil:\n\t\t\tfn = func(c baseReduceContext) reduceContext {\n\t\t\t\ta, e := rc.CreateBooleanIntegerReducer()\n\t\t\t\treturn &booleanIntegerReduceContext{\n\t\t\t\t\tbooleanPointAggregator: booleanPointAggregator{\n\t\t\t\t\t\tfield:            c.field,\n\t\t\t\t\t\ttopBottomInfo:    rc.TopBottomCallInfo,\n\t\t\t\t\t\tisSimpleSelector: rc.IsSimpleSelector,\n\t\t\t\t\t\taggregator:       a,\n\t\t\t\t\t},\n\t\t\t\t\tintegerPointEmitter: integerPointEmitter{\n\t\t\t\t\t\tbaseReduceContext: c,\n\t\t\t\t\t\temitter:           e,\n\t\t\t\t\t\tisSimpleSelector:  rc.IsSimpleSelector,\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase rc.CreateBooleanStringReducer != nil:\n\t\t\tfn = func(c baseReduceContext) reduceContext {\n\t\t\t\ta, e := rc.CreateBooleanStringReducer()\n\t\t\t\treturn &booleanStringReduceContext{\n\t\t\t\t\tbooleanPointAggregator: booleanPointAggregator{\n\t\t\t\t\t\tfield:            c.field,\n\t\t\t\t\t\ttopBottomInfo:    rc.TopBottomCallInfo,\n\t\t\t\t\t\tisSimpleSelector: rc.IsSimpleSelector,\n\t\t\t\t\t\taggregator:       a,\n\t\t\t\t\t},\n\t\t\t\t\tstringPointEmitter: stringPointEmitter{\n\t\t\t\t\t\tbaseReduceContext: c,\n\t\t\t\t\t\temitter:           e,\n\t\t\t\t\t\tisSimpleSelector:  rc.IsSimpleSelector,\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase rc.CreateBooleanReducer != nil:\n\t\t\tfn = func(c baseReduceContext) reduceContext {\n\t\t\t\ta, e := rc.CreateBooleanReducer()\n\t\t\t\treturn &booleanReduceContext{\n\t\t\t\t\tbooleanPointAggregator: booleanPointAggregator{\n\t\t\t\t\t\tfield:            c.field,\n\t\t\t\t\t\ttopBottomInfo:    rc.TopBottomCallInfo,\n\t\t\t\t\t\tisSimpleSelector: rc.IsSimpleSelector,\n\t\t\t\t\t\taggregator:       a,\n\t\t\t\t\t},\n\t\t\t\t\tbooleanPointEmitter: booleanPointEmitter{\n\t\t\t\t\t\tbaseReduceContext: c,\n\t\t\t\t\t\temitter:           e,\n\t\t\t\t\t\tisSimpleSelector:  rc.IsSimpleSelector,\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n\n\t\tdefault:\n\t\t\terr = fmt.Errorf(\"cannot apply %s to bool field\", method)\n\t\t}\n\n\tdefault:\n\t\terr = fmt.Errorf(\"invalid field kind: %v\", kind)\n\t}\n\treturn\n}\n"
        },
        {
          "name": "influxql.gen.go.tmpl",
          "type": "blob",
          "size": 5.2626953125,
          "content": "package kapacitor\n\n\nimport (\n\t\"fmt\"\n\t\"time\"\n\t\"reflect\"\n\n\t\"github.com/influxdata/influxdb/query\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n)\n\n{{/* Define typed Aggregate/Emit types */}}\n{{range .}}\n\nfunc convert{{.Name}}Point(\n\tname string,\n\tp edge.FieldsTagsTimeGetter,\n\tfield string,\n\tisSimpleSelector bool,\n\ttopBottomInfo *pipeline.TopBottomCallInfo,\n) (*query.{{.Name}}Point, error) {\n\tvalue, ok := p.Fields()[field]\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"field %s missing from point cannot aggregate\", field)\n\t}\n\ttyped, ok := value.({{.Type}})\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"field %s has wrong type: got %T exp {{.Type}}\", field, value)\n\t}\n\tap := &query.{{.Name}}Point{\n\t\tName:  name,\n\t\tTags:  query.NewTags(p.Tags()),\n\t\tTime:  p.Time().UnixNano(),\n\t\tValue: typed,\n\t}\n\tif topBottomInfo != nil {\n\t\t// We need to populate the Aux fields\n\t\t{{.name}}PopulateAuxFieldsAndTags(ap, topBottomInfo.FieldsAndTags, p.Fields(), p.Tags())\n\t}\n\n\tif isSimpleSelector {\n\t\tap.Aux = []interface{}{ p.Tags(), p.Fields() }\n\t}\n\n\treturn ap, nil\n}\n\ntype {{.name}}PointAggregator struct {\n\tfield         string\n\ttopBottomInfo *pipeline.TopBottomCallInfo\n\tisSimpleSelector bool\n\taggregator query.{{.Name}}PointAggregator\n}\n\nfunc {{.name}}PopulateAuxFieldsAndTags(ap *query.{{.Name}}Point, fieldsAndTags []string, fields models.Fields, tags models.Tags) {\n\tap.Aux = make([]interface{}, len(fieldsAndTags))\n\tfor i, name := range fieldsAndTags {\n\t\tif f, ok := fields[name]; ok {\n\t\t\tap.Aux[i] = f\n\t\t} else {\n\t\t\tap.Aux[i] = tags[name]\n\t\t}\n\t}\n}\n\nfunc (a *{{.name}}PointAggregator) AggregatePoint(name string, p edge.FieldsTagsTimeGetter) error {\n\tap, err := convert{{.Name}}Point(name, p, a.field, a.isSimpleSelector, a.topBottomInfo)\n\tif err != nil {\n\t\treturn err\n\t}\n\ta.aggregator.Aggregate{{.Name}}(ap)\n\treturn nil\n}\n\ntype {{.name}}PointEmitter struct {\n\tbaseReduceContext\n\temitter query.{{.Name}}PointEmitter\n\tisSimpleSelector bool\n}\n\nfunc (e *{{.name}}PointEmitter) EmitPoint() (edge.PointMessage, error) {\n\tslice := e.emitter.Emit()\n\tif len(slice) != 1 {\n\t\treturn nil, nil\n\t}\n\tap := slice[0]\n\tvar t time.Time\n\tif e.pointTimes {\n\t\tif ap.Time == query.ZeroTime {\n\t\t\tt = e.time\n\t\t} else {\n\t\t\tt = time.Unix(0, ap.Time).UTC()\n\t\t}\n\t} else {\n\t\tt = e.time\n\t}\n\n\tvar fields models.Fields\n\tvar tags models.Tags\n\tif e.isSimpleSelector {\n\t\ttags = ap.Aux[0].(models.Tags)\n\t\tfields = ap.Aux[1].(models.Fields)\n\t\tif e.as != e.field {\n\t\t\tfields = fields.Copy()\n\t\t\tfields[e.as] = fields[e.field]\n\t\t\tdelete(fields, e.field)\n\t\t}\n\t} else {\n\t\ttags = e.groupInfo.Tags\n\t\tfields = map[string]interface{}{e.as: ap.Value}\n\t}\n\n\treturn edge.NewPointMessage(\n\t\te.name, \"\", \"\",\n\t\te.groupInfo.Dimensions,\n\t\tfields,\n\t\ttags,\n\t\tt,\n\t), nil\n}\n\nfunc (e *{{.name}}PointEmitter) EmitBatch() edge.BufferedBatchMessage {\n\tslice := e.emitter.Emit()\n\tbegin := edge.NewBeginBatchMessage(\n\t\te.name,\n\t\te.groupInfo.Tags,\n\t\te.groupInfo.Dimensions.ByName,\n\t\te.time,\n\t\tlen(slice),\n\t)\n\tpoints := make([]edge.BatchPointMessage, len(slice))\n\tvar t time.Time\n\tfor i, ap := range slice {\n\t\tif e.pointTimes {\n\t\t\tif ap.Time == query.ZeroTime {\n\t\t\t\tt = e.time\n\t\t\t} else {\n\t\t\t\tt = time.Unix(0, ap.Time).UTC()\n\t\t\t}\n\t\t} else {\n\t\t\tt = e.time\n\t\t}\n\t\tvar tags models.Tags\n\t\tif l := len(ap.Tags.KeyValues()); l > 0 {\n\t\t\t// Merge batch and point specific tags\n\t\t\ttags = make(models.Tags, len(e.groupInfo.Tags)+l)\n\t\t\tfor k, v := range e.groupInfo.Tags {\n\t\t\t\ttags[k] = v\n\t\t\t}\n\t\t\tfor k, v := range ap.Tags.KeyValues() {\n\t\t\t\ttags[k] = v\n\t\t\t}\n\t\t} else {\n\t\t\ttags = e.groupInfo.Tags\n\t\t}\n\t\tpoints[i] = edge.NewBatchPointMessage(\n\t\t\tmodels.Fields{e.as: ap.Value},\n\t\t\ttags,\n\t\t\tt,\n\t\t)\n\t\tif t.After(begin.Time()) {\n\t\t\tbegin.SetTime(t)\n\t\t}\n\t}\n\treturn edge.NewBufferedBatchMessage(\n\t\tbegin,\n\t\tpoints,\n\t\tedge.NewEndBatchMessage(),\n\t)\n}\n\n{{end}}\n\n{{/* Define composite types for reduceContext */}}\n{{with $types := .}}\n{{range $a := $types}}\n{{range $e := $types}}\n\n// {{$a.name}}{{if ne $a.Name $e.Name}}{{$e.Name}}{{end}}ReduceContext uses composition to implement the reduceContext interface\ntype {{$a.name}}{{if ne $a.Name $e.Name}}{{$e.Name}}{{end}}ReduceContext struct {\n    {{$a.name}}PointAggregator\n    {{$e.name}}PointEmitter\n}\n\n{{end}}{{end}}\n\n\n{{/* Define switch cases for reduceContext contruction */}}\n\nfunc determineReduceContextCreateFn(method string, kind reflect.Kind, rc pipeline.ReduceCreater)  (fn createReduceContextFunc, err error) {\n\tswitch kind {\n{{range $a := $types}}\n\tcase {{.Kind}}:\n\t\tswitch {\n{{range $e := $types}}\n\t\tcase rc.Create{{$a.Name}}{{if ne $a.Name $e.Name}}{{$e.Name}}{{end}}Reducer != nil:\n\t\t\t fn = func(c baseReduceContext) reduceContext {\n\t\t\t\ta, e := rc.Create{{$a.Name}}{{if ne $a.Name $e.Name}}{{$e.Name}}{{end}}Reducer()\n\t\t\t\treturn &{{$a.name}}{{if ne $a.Name $e.Name}}{{$e.Name}}{{end}}ReduceContext{\n\t\t\t\t\t{{$a.name}}PointAggregator: {{$a.name}}PointAggregator{\n\t\t\t\t\t\tfield:      c.field,\n\t\t\t\t\t\ttopBottomInfo: rc.TopBottomCallInfo,\n\t\t\t\t\t\tisSimpleSelector: rc.IsSimpleSelector,\n\t\t\t\t\t\taggregator: a,\n\t\t\t\t\t},\n\t\t\t\t\t{{$e.name}}PointEmitter: {{$e.name}}PointEmitter{\n\t\t\t\t\t\tbaseReduceContext: c,\n\t\t\t\t\t\temitter:           e,\n\t\t\t\t\t\tisSimpleSelector: rc.IsSimpleSelector,\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n{{end}}\n\t\tdefault:\n\t\t\terr = fmt.Errorf(\"cannot apply %s to {{$a.Type}} field\", method)\n\t\t}\n{{end}}\n\tdefault:\n\t\terr = fmt.Errorf(\"invalid field kind: %v\", kind)\n\t}\n\treturn\n}\n{{end}}\n"
        },
        {
          "name": "influxql.go",
          "type": "blob",
          "size": 7.3876953125,
          "content": "package kapacitor\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n\t\"time\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n\t\"github.com/pkg/errors\"\n)\n\n// tmpl -- go get github.com/benbjohnson/tmpl\n//go:generate tmpl -data=@tmpldata.json influxql.gen.go.tmpl\n\ntype createReduceContextFunc func(c baseReduceContext) reduceContext\n\ntype InfluxQLNode struct {\n\tnode\n\tn                      *pipeline.InfluxQLNode\n\tcreateFn               createReduceContextFunc\n\tisStreamTransformation bool\n\n\tcurrentKind reflect.Kind\n}\n\nfunc newInfluxQLNode(et *ExecutingTask, n *pipeline.InfluxQLNode, d NodeDiagnostic) (*InfluxQLNode, error) {\n\tm := &InfluxQLNode{\n\t\tnode:                   node{Node: n, et: et, diag: d},\n\t\tn:                      n,\n\t\tisStreamTransformation: n.ReduceCreater.IsStreamTransformation,\n\t}\n\tm.node.runF = m.runInfluxQL\n\treturn m, nil\n}\n\ntype reduceContext interface {\n\tAggregatePoint(name string, p edge.FieldsTagsTimeGetter) error\n\tEmitPoint() (edge.PointMessage, error)\n\tEmitBatch() edge.BufferedBatchMessage\n}\n\ntype baseReduceContext struct {\n\tas         string\n\tfield      string\n\tname       string\n\tgroupInfo  edge.GroupInfo\n\ttime       time.Time\n\tpointTimes bool\n}\n\nfunc (n *InfluxQLNode) runInfluxQL([]byte) error {\n\tconsumer := edge.NewGroupedConsumer(\n\t\tn.ins[0],\n\t\tn,\n\t)\n\tn.statMap.Set(statCardinalityGauge, consumer.CardinalityVar())\n\treturn consumer.Consume()\n}\n\nfunc (n *InfluxQLNode) NewGroup(group edge.GroupInfo, first edge.PointMeta) (edge.Receiver, error) {\n\treturn edge.NewReceiverFromForwardReceiverWithStats(\n\t\tn.outs,\n\t\tedge.NewTimedForwardReceiver(n.timer, n.newGroup(first)),\n\t), nil\n}\n\nfunc (n *InfluxQLNode) newGroup(first edge.PointMeta) edge.ForwardReceiver {\n\tbc := baseReduceContext{\n\t\tas:         n.n.As,\n\t\tfield:      n.n.Field,\n\t\tname:       first.Name(),\n\t\tgroupInfo:  first.GroupInfo(),\n\t\ttime:       first.Time(),\n\t\tpointTimes: n.n.PointTimes || n.isStreamTransformation,\n\t}\n\tg := influxqlGroup{\n\t\tn:  n,\n\t\tbc: bc,\n\t}\n\tif n.isStreamTransformation {\n\t\treturn &influxqlStreamingTransformGroup{\n\t\t\tinfluxqlGroup: g,\n\t\t}\n\t}\n\treturn &g\n}\n\ntype influxqlGroup struct {\n\tn *InfluxQLNode\n\n\tbc baseReduceContext\n\trc reduceContext\n\n\tbatchSize int\n\tbegin     edge.BeginBatchMessage\n}\n\nfunc (g *influxqlGroup) BeginBatch(begin edge.BeginBatchMessage) (edge.Message, error) {\n\tg.begin = begin\n\tg.batchSize = 0\n\tg.bc.time = begin.Time()\n\tg.rc = nil\n\treturn nil, nil\n}\n\nfunc (g *influxqlGroup) BatchPoint(bp edge.BatchPointMessage) (edge.Message, error) {\n\tif g.rc == nil {\n\t\tif err := g.realizeReduceContextFromFields(bp.Fields()); err != nil {\n\t\t\tg.n.diag.Error(\"failed to realize reduce context from fields\", err)\n\t\t\treturn nil, nil\n\t\t}\n\t}\n\tif err := g.rc.AggregatePoint(g.begin.Name(), bp); err != nil {\n\t\tg.n.diag.Error(\"failed to aggregate point in batch\", err)\n\t}\n\tg.batchSize++\n\treturn nil, nil\n}\n\nfunc (g *influxqlGroup) EndBatch(end edge.EndBatchMessage) (edge.Message, error) {\n\tif g.batchSize == 0 && !g.n.n.ReduceCreater.IsEmptyOK {\n\t\t// Do not call Emit on the reducer since it can't handle empty batches.\n\t\treturn nil, nil\n\t}\n\tif g.rc == nil {\n\t\t// Assume float64 type since we do not have any data.\n\t\tif err := g.realizeReduceContext(reflect.Float64); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tm, err := g.n.emit(g.rc)\n\tif err != nil {\n\t\tg.n.diag.Error(\"failed to emit batch\", err)\n\t\treturn nil, nil\n\t}\n\treturn m, nil\n}\n\nfunc (g *influxqlGroup) Point(p edge.PointMessage) (edge.Message, error) {\n\tif p.Time().Equal(g.bc.time) {\n\t\tg.aggregatePoint(p)\n\t} else {\n\t\t// Time has elapsed, emit current context\n\t\tvar msg edge.Message\n\t\tif g.rc != nil {\n\t\t\tm, err := g.n.emit(g.rc)\n\t\t\tif err != nil {\n\t\t\t\tg.n.diag.Error(\"failed to emit stream\", err)\n\t\t\t}\n\t\t\tmsg = m\n\t\t}\n\n\t\t// Reset context\n\t\tg.bc.name = p.Name()\n\t\tg.bc.time = p.Time()\n\t\tg.rc = nil\n\n\t\t// Aggregate the current point\n\t\tg.aggregatePoint(p)\n\n\t\treturn msg, nil\n\t}\n\treturn nil, nil\n}\n\nfunc (g *influxqlGroup) aggregatePoint(p edge.PointMessage) {\n\tif g.rc == nil {\n\t\tif err := g.realizeReduceContextFromFields(p.Fields()); err != nil {\n\t\t\tg.n.diag.Error(\"failed to realize reduce context from fields\", err)\n\t\t\treturn\n\t\t}\n\t}\n\terr := g.rc.AggregatePoint(p.Name(), p)\n\tif err != nil {\n\t\tg.n.diag.Error(\"failed to aggregate point\", err)\n\t}\n}\n\nfunc (g *influxqlGroup) getFieldKind(fields models.Fields) (reflect.Kind, error) {\n\tf, exists := fields[g.bc.field]\n\tif !exists {\n\t\treturn reflect.Invalid, fmt.Errorf(\"field %q missing from point\", g.bc.field)\n\t}\n\n\treturn reflect.TypeOf(f).Kind(), nil\n}\nfunc (g *influxqlGroup) realizeReduceContextFromFields(fields models.Fields) error {\n\tk, err := g.getFieldKind(fields)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn g.realizeReduceContext(k)\n}\n\nfunc (g *influxqlGroup) realizeReduceContext(kind reflect.Kind) error {\n\tcreateFn, err := g.n.getCreateFn(kind)\n\tif err != nil {\n\t\treturn err\n\t}\n\tg.rc = createFn(g.bc)\n\treturn nil\n}\n\nfunc (g *influxqlGroup) Barrier(b edge.BarrierMessage) (edge.Message, error) {\n\treturn b, nil\n}\nfunc (g *influxqlGroup) DeleteGroup(d edge.DeleteGroupMessage) (edge.Message, error) {\n\treturn d, nil\n}\nfunc (g *influxqlGroup) Done() {}\n\ntype influxqlStreamingTransformGroup struct {\n\tinfluxqlGroup\n}\n\nfunc (g *influxqlStreamingTransformGroup) BeginBatch(begin edge.BeginBatchMessage) (edge.Message, error) {\n\tg.begin = begin.ShallowCopy()\n\tg.begin.SetSizeHint(0)\n\tg.bc.time = begin.Time()\n\tg.rc = nil\n\treturn begin, nil\n}\n\nfunc (g *influxqlStreamingTransformGroup) BatchPoint(bp edge.BatchPointMessage) (edge.Message, error) {\n\tif g.rc == nil {\n\t\tif err := g.realizeReduceContextFromFields(bp.Fields()); err != nil {\n\t\t\tg.n.diag.Error(\"failed to realize reduce context from fields\", err)\n\t\t\treturn nil, nil\n\t\t}\n\t}\n\tif err := g.rc.AggregatePoint(g.begin.Name(), bp); err != nil {\n\t\tg.n.diag.Error(\"failed to aggregate batch point\", err)\n\t}\n\tif ep, err := g.rc.EmitPoint(); err != nil {\n\t\tg.n.diag.Error(\"failed to emit batch point\", err)\n\t} else if ep != nil {\n\t\treturn edge.NewBatchPointMessage(\n\t\t\tep.Fields(),\n\t\t\tep.Tags(),\n\t\t\tep.Time(),\n\t\t), nil\n\t}\n\treturn nil, nil\n}\n\nfunc (g *influxqlStreamingTransformGroup) EndBatch(end edge.EndBatchMessage) (edge.Message, error) {\n\treturn end, nil\n}\n\nfunc (g *influxqlStreamingTransformGroup) Point(p edge.PointMessage) (edge.Message, error) {\n\tif g.rc == nil {\n\t\tif err := g.realizeReduceContextFromFields(p.Fields()); err != nil {\n\t\t\tg.n.diag.Error(\"failed to realize reduce context from fields\", err)\n\t\t\t// Skip point\n\t\t\treturn nil, nil\n\t\t}\n\t}\n\terr := g.rc.AggregatePoint(p.Name(), p)\n\tif err != nil {\n\t\tg.n.diag.Error(\"failed to aggregate point\", err)\n\t}\n\n\tm, err := g.n.emit(g.rc)\n\tif err != nil {\n\t\tg.n.diag.Error(\"failed to emit stream\", err)\n\t\treturn nil, nil\n\t}\n\treturn m, nil\n}\n\nfunc (g *influxqlStreamingTransformGroup) Barrier(b edge.BarrierMessage) (edge.Message, error) {\n\treturn b, nil\n}\n\nfunc (n *InfluxQLNode) getCreateFn(kind reflect.Kind) (createReduceContextFunc, error) {\n\tchanged := n.currentKind != kind\n\tif !changed && n.createFn != nil {\n\t\treturn n.createFn, nil\n\t}\n\tn.currentKind = kind\n\tcreateFn, err := determineReduceContextCreateFn(n.n.Method, kind, n.n.ReduceCreater)\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"invalid influxql func %s with field %s\", n.n.Method, n.n.Field)\n\t}\n\tn.createFn = createFn\n\treturn n.createFn, nil\n}\n\nfunc (n *InfluxQLNode) emit(context reduceContext) (edge.Message, error) {\n\tswitch n.Provides() {\n\tcase pipeline.StreamEdge:\n\t\treturn context.EmitPoint()\n\tcase pipeline.BatchEdge:\n\t\treturn context.EmitBatch(), nil\n\t}\n\treturn nil, nil\n}\n"
        },
        {
          "name": "integrations",
          "type": "tree",
          "content": null
        },
        {
          "name": "join.go",
          "type": "blob",
          "size": 17.9013671875,
          "content": "package kapacitor\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/influxdata/influxql\"\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/expvar\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n\t\"github.com/pkg/errors\"\n)\n\ntype JoinNode struct {\n\tnode\n\tj         *pipeline.JoinNode\n\tfill      influxql.FillOption\n\tfillValue interface{}\n\n\tgroupsMu sync.RWMutex\n\tgroups   map[models.GroupID]*joinGroup\n\n\t// Represents the lower bound of times per group per source\n\tlowMarks map[srcGroup]time.Time\n\n\t// Buffer for caching points that need to be matched with specific points.\n\tmatchGroupsBuffer map[models.GroupID]*CircularQueue[srcPoint]\n\t// Buffer for caching specific points until their match arrivces.\n\tspecificGroupsBuffer map[models.GroupID]*CircularQueue[srcPoint]\n\n\treported    map[int]bool\n\tallReported bool\n}\n\n// Create a new JoinNode, which takes pairs from parent streams combines them into a single point.\nfunc newJoinNode(et *ExecutingTask, n *pipeline.JoinNode, d NodeDiagnostic) (*JoinNode, error) {\n\tjn := &JoinNode{\n\t\tj:                    n,\n\t\tnode:                 node{Node: n, et: et, diag: d},\n\t\tgroups:               make(map[models.GroupID]*joinGroup),\n\t\tmatchGroupsBuffer:    make(map[models.GroupID]*CircularQueue[srcPoint]),\n\t\tspecificGroupsBuffer: make(map[models.GroupID]*CircularQueue[srcPoint]),\n\t\tlowMarks:             make(map[srcGroup]time.Time),\n\t\treported:             make(map[int]bool),\n\t}\n\t// Set fill\n\tswitch fill := n.Fill.(type) {\n\tcase string:\n\t\tswitch fill {\n\t\tcase \"null\":\n\t\t\tjn.fill = influxql.NullFill\n\t\tcase \"none\":\n\t\t\tjn.fill = influxql.NoFill\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"unexpected fill option %s\", fill)\n\t\t}\n\tcase int64, float64:\n\t\tjn.fill = influxql.NumberFill\n\t\tjn.fillValue = fill\n\tdefault:\n\t\tjn.fill = influxql.NoFill\n\t}\n\tjn.node.runF = jn.runJoin\n\treturn jn, nil\n}\n\nfunc (n *JoinNode) runJoin([]byte) error {\n\tconsumer := edge.NewMultiConsumerWithStats(n.ins, n)\n\tvalueF := func() int64 {\n\t\tn.groupsMu.RLock()\n\t\tl := len(n.groups)\n\t\tn.groupsMu.RUnlock()\n\t\treturn int64(l)\n\t}\n\tn.statMap.Set(statCardinalityGauge, expvar.NewIntFuncGauge(valueF))\n\n\treturn consumer.Consume()\n}\n\nfunc (n *JoinNode) BufferedBatch(src int, batch edge.BufferedBatchMessage) error {\n\treturn n.doMessage(src, batch)\n}\n\nfunc (n *JoinNode) Point(src int, p edge.PointMessage) error {\n\treturn n.doMessage(src, p)\n}\n\nfunc (n *JoinNode) Barrier(src int, b edge.BarrierMessage) error {\n\tg := n.getOrCreateGroup(b.GroupID())\n\tif err := g.Barrier(src, b.Time()); err != nil {\n\t\treturn err\n\t}\n\treturn edge.Forward(n.outs, b)\n}\n\n// Delete deletes the group from the JoinNode, and resets the Low Marks for from the group from that source.\n// if deleteAll is set on the pipeline.Joinnode, then it any delete will delete\nfunc (n *JoinNode) Delete(src int, d edge.DeleteGroupMessage) error {\n\tgroupID := d.GroupID()\n\tn.groupsMu.Lock()\n\tdelete(n.groups, groupID)\n\tdelete(n.matchGroupsBuffer, groupID)\n\tdelete(n.specificGroupsBuffer, groupID)\n\tif n.j.DeleteAll {\n\t\tfor x := range n.lowMarks {\n\t\t\tdelete(n.lowMarks, x)\n\t\t}\n\t} else {\n\t\tdelete(n.lowMarks, srcGroup{src: src, groupId: groupID})\n\t}\n\tn.groupsMu.Unlock()\n\treturn edge.Forward(n.outs, d)\n}\n\nfunc (n *JoinNode) Finish() error {\n\t// No more points are coming signal all groups to finish up.\n\tfor _, group := range n.groups {\n\t\tif err := group.Finish(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\ntype messageMeta interface {\n\tedge.Message\n\tedge.PointMeta\n}\n\ntype srcPoint struct {\n\tSrc int\n\tMsg messageMeta\n}\n\nfunc (n *JoinNode) doMessage(src int, m messageMeta) error {\n\tn.timer.Start()\n\tdefer n.timer.Stop()\n\tif len(n.j.Dimensions) > 0 {\n\t\t// Match points with their group based on join dimensions.\n\t\tn.matchPoints(srcPoint{Src: src, Msg: m})\n\t} else {\n\t\t// Just send point on to group, we are not joining on specific dimensions.\n\t\tgroup := n.getOrCreateGroup(m.GroupID())\n\t\tif err := group.Collect(src, m); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// The purpose of this method is to match more-specific points\n// with the less-specific points as they arrive.\n//\n// Where 'more-specific' means, that a point has more dimensions than the join.on dimensions.\nfunc (n *JoinNode) matchPoints(p srcPoint) {\n\t// Specific points may be sent to the joinset without a matching point, but not the other way around.\n\t// This is because the specific points have the needed specific tag data.\n\t// The joinset will later handle the fill inner/outer join operations.\n\n\tif !n.allReported {\n\t\tn.reported[p.Src] = true\n\t\tn.allReported = len(n.reported) == len(n.ins)\n\t}\n\tt := p.Msg.Time().Round(n.j.Tolerance)\n\n\tgroupId := models.ToGroupID(\n\t\tp.Msg.Name(),\n\t\tp.Msg.GroupInfo().Tags,\n\t\tmodels.Dimensions{\n\t\t\tByName:   p.Msg.Dimensions().ByName,\n\t\t\tTagNames: n.j.Dimensions,\n\t\t},\n\t)\n\t// Update current srcGroup lowMark\n\tsrcG := srcGroup{src: p.Src, groupId: groupId}\n\tn.lowMarks[srcG] = t\n\n\t// Determine lowMark, the oldest time per parent per group.\n\tvar lowMark time.Time\n\tif n.allReported {\n\t\tfor s := 0; s < len(n.ins); s++ {\n\t\t\tsg := srcGroup{src: s, groupId: groupId}\n\t\t\tif lm := n.lowMarks[sg]; lowMark.IsZero() || lm.Before(lowMark) {\n\t\t\t\tlowMark = lm\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check for cached specific points that can now be sent alone.\n\tif n.allReported {\n\t\t// Send all cached specific point that won't match anymore.\n\t\tvar i int\n\t\tbuf := n.specificGroupsBuffer[groupId]\n\t\tif buf != nil {\n\t\t\tl := buf.Len\n\t\t\tfor i = 0; i < l; i++ {\n\t\t\t\tpt := buf.Peek(i)\n\t\t\t\tst := pt.Msg.Time().Round(n.j.Tolerance)\n\t\t\t\tif st.Before(lowMark) {\n\t\t\t\t\t// Send point by itself since it won't get a match.\n\t\t\t\t\tn.sendSpecificPoint(pt)\n\t\t\t\t} else {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Remove all sent points.\n\t\t\tbuf.Dequeue(i)\n\t\t}\n\t}\n\n\tif len(p.Msg.Dimensions().TagNames) > len(n.j.Dimensions) {\n\t\t// We have a specific point and three options:\n\t\t// 1. Find the cached match point and send both to group.\n\t\t// 2. Cache the specific point for later.\n\t\t// 3. Send the specific point alone if it is no longer possible that a match will arrive.\n\n\t\t// Search for a match.\n\t\t// Also purge any old match points.\n\t\tmatches := n.matchGroupsBuffer[groupId]\n\t\tmatched := false\n\t\tif matches != nil {\n\t\t\tvar i int\n\t\t\tl := matches.Len\n\t\t\tfor i = 0; i < l; i++ {\n\t\t\t\tmatch := matches.Peek(i)\n\t\t\t\tpt := match.Msg.Time().Round(n.j.Tolerance)\n\t\t\t\tif pt.Equal(t) {\n\t\t\t\t\t// Option 1, send both points\n\t\t\t\t\tn.sendMatchPoint(p, match)\n\t\t\t\t\tmatched = true\n\t\t\t\t}\n\t\t\t\tif !pt.Before(lowMark) {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif n.allReported {\n\t\t\t\t// Can't trust lowMark until all parents have reported.\n\t\t\t\t// Remove any unneeded match points.\n\t\t\t\tn.matchGroupsBuffer[groupId].Dequeue(i)\n\t\t\t}\n\t\t}\n\n\t\t// If the point didn't match that leaves us with options 2 and 3.\n\t\tif !matched {\n\t\t\tif n.allReported && t.Before(lowMark) {\n\t\t\t\t// Option 3\n\t\t\t\t// Send this specific point by itself since it won't get a match.\n\t\t\t\tn.sendSpecificPoint(p)\n\t\t\t} else {\n\t\t\t\t// Option 2\n\t\t\t\t// Cache this point for when its match arrives.\n\t\t\t\tn.getOrCreateSpecificGroup(groupId).Enqueue(p)\n\t\t\t}\n\t\t}\n\t} else {\n\t\t// Cache match point.\n\t\tn.getOrCreateMatchGroup(groupId).Enqueue(p)\n\n\t\t// Send all specific points that match, to the group.\n\t\tvar i int\n\t\tbuf := n.specificGroupsBuffer[groupId]\n\t\tif buf != nil {\n\t\t\tl := buf.Len\n\t\t\tfor i = 0; i < l; i++ {\n\t\t\t\tpt := buf.Peek(i)\n\t\t\t\tst := pt.Msg.Time().Round(n.j.Tolerance)\n\t\t\t\tif st.Equal(t) {\n\t\t\t\t\tn.sendMatchPoint(pt, p)\n\t\t\t\t} else {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Remove all sent points\n\t\t\tn.specificGroupsBuffer[groupId].Dequeue(i)\n\t\t}\n\t}\n}\n\n// Add the specific tags from the specific point to the matched point\n// and then send both on to the group.\nfunc (n *JoinNode) sendMatchPoint(specific, matched srcPoint) {\n\tvar newMatched messageMeta\n\tswitch msg := matched.Msg.(type) {\n\tcase edge.BufferedBatchMessage:\n\t\tb := msg.ShallowCopy()\n\t\tb.SetBegin(b.Begin().ShallowCopy())\n\t\tb.Begin().SetTags(specific.Msg.GroupInfo().Tags)\n\t\tnewMatched = b\n\tcase edge.PointMessage:\n\t\tp := msg.ShallowCopy()\n\t\tinfo := specific.Msg.GroupInfo()\n\t\tp.SetTagsAndDimensions(info.Tags, info.Dimensions)\n\t\tnewMatched = p\n\t}\n\tgroup := n.getOrCreateGroup(specific.Msg.GroupID())\n\t// Collect specific point\n\tgroup.Collect(specific.Src, specific.Msg)\n\t// Collect new matched point\n\tgroup.Collect(matched.Src, newMatched)\n}\n\n// Send only the specific point to the group\nfunc (n *JoinNode) sendSpecificPoint(specific srcPoint) {\n\tgroup := n.getOrCreateGroup(specific.Msg.GroupID())\n\tgroup.Collect(specific.Src, specific.Msg)\n}\n\n// safely get the group for the point or create one if it doesn't exist.\nfunc (n *JoinNode) getOrCreateGroup(groupID models.GroupID) *joinGroup {\n\tgroup := n.groups[groupID]\n\tif group == nil {\n\t\tgroup = n.newGroup(len(n.ins))\n\t\tn.groupsMu.Lock()\n\t\tn.groups[groupID] = group\n\t\tn.groupsMu.Unlock()\n\t}\n\treturn group\n}\n\nfunc (n *JoinNode) newGroup(count int) *joinGroup {\n\treturn &joinGroup{\n\t\tn:    n,\n\t\tsets: make(map[time.Time]*CircularQueue[*joinset]),\n\t\thead: make([]time.Time, count),\n\t}\n}\n\nfunc (n *JoinNode) getOrCreateMatchGroup(id models.GroupID) *CircularQueue[srcPoint] {\n\tbuf := n.matchGroupsBuffer[id]\n\tif buf == nil {\n\t\tbuf = NewCircularQueue[srcPoint]()\n\t\tn.matchGroupsBuffer[id] = buf\n\t}\n\n\treturn buf\n}\n\nfunc (n *JoinNode) getOrCreateSpecificGroup(id models.GroupID) *CircularQueue[srcPoint] {\n\tbuf := n.specificGroupsBuffer[id]\n\tif buf == nil {\n\t\tbuf = NewCircularQueue[srcPoint]()\n\t\tn.specificGroupsBuffer[id] = buf\n\t}\n\treturn buf\n}\n\n// handles emitting joined sets once enough data has arrived from parents.\ntype joinGroup struct {\n\tn *JoinNode\n\n\tsets       map[time.Time]*CircularQueue[*joinset]\n\thead       []time.Time\n\toldestTime time.Time\n}\n\nfunc (g *joinGroup) Finish() error {\n\treturn g.emitAll()\n}\n\n// Collect a point from a given parent.\n// emit the oldest set if we have collected enough data.\nfunc (g *joinGroup) Collect(src int, p timeMessage) error {\n\tt := p.Time().Round(g.n.j.Tolerance)\n\tif t.Before(g.oldestTime) || g.oldestTime.IsZero() {\n\t\tg.oldestTime = t\n\t}\n\n\tvar set *joinset\n\tsets := g.sets[t]\n\tif sets == nil {\n\t\tsets = NewCircularQueue[*joinset](g.newJoinset(t))\n\t\tg.sets[t] = sets\n\t}\n\tl := sets.Len\n\tfor i := 0; i < l; i++ {\n\t\tif x := sets.Peek(i); !x.Has(src) {\n\t\t\tset = x\n\t\t\tbreak\n\t\t}\n\t}\n\tif set == nil {\n\t\tset = g.newJoinset(t)\n\t\tg.sets[t].Enqueue(set)\n\t}\n\tset.Set(src, p)\n\n\t// Update head\n\tg.head[src] = t\n\n\tonlyReadySets := g.checkOnlyReadSets()\n\terr := g.emit(onlyReadySets)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\n// Barrier signals a src will not produce points older than time.\n// Emit the oldest set if we have collected enough data.\nfunc (g *joinGroup) Barrier(src int, t time.Time) error {\n\tt = t.Round(g.n.j.Tolerance)\n\tif t.Before(g.oldestTime) || g.oldestTime.IsZero() {\n\t\tg.oldestTime = t\n\t}\n\n\t// Update head\n\tg.head[src] = t\n\n\tonlyReadySets := g.checkOnlyReadSets()\n\terr := g.emit(onlyReadySets)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc (g *joinGroup) newJoinset(t time.Time) *joinset {\n\treturn newJoinset(\n\t\tg.n,\n\t\tg.n.j.StreamName,\n\t\tg.n.fill,\n\t\tg.n.fillValue,\n\t\tg.n.j.Names,\n\t\tg.n.j.Delimiter,\n\t\tg.n.j.Tolerance,\n\t\tt,\n\t\tg.n.diag,\n\t)\n}\n\n// emit a set and update the oldestTime.\nfunc (g *joinGroup) emit(onlyReadySets bool) error {\n\tif len(g.sets) == 0 {\n\t\treturn nil\n\t}\n\tsets := g.sets[g.oldestTime]\n\ti := 0\n\tl := sets.Len\n\tfor ; i < l; i++ {\n\t\tset := sets.Peek(i)\n\t\tif set.Ready() || !onlyReadySets {\n\t\t\terr := g.emitJoinedSet(set)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t} else {\n\t\t\tbreak\n\t\t}\n\t}\n\tif i == sets.Len {\n\t\tdelete(g.sets, g.oldestTime)\n\t} else {\n\t\tg.sets[g.oldestTime].Dequeue(i)\n\t}\n\n\tg.oldestTime = time.Time{}\n\tfor t := range g.sets {\n\t\tif g.oldestTime.IsZero() || t.Before(g.oldestTime) {\n\t\t\tg.oldestTime = t\n\t\t}\n\t}\n\t// Check if there are more non ready sets we can emit.\n\t// This occurs when one of the parents missed a section of data\n\t// while the other parents continued on.\n\t// We need to emit all the buffered sets as soon as all the parent heads have passed the oldesttime.\n\tif !onlyReadySets {\n\t\tonlyReadySets = g.checkOnlyReadSets()\n\t\treturn g.emit(onlyReadySets)\n\t}\n\treturn nil\n}\n\n// checkOnlyReadSets reports if all heads are past the oldesttime,\n// indicated whether its ok to emit non ready sets.\nfunc (g *joinGroup) checkOnlyReadSets() bool {\n\tonlyReadySets := false\n\t// Check if heads are past oldest time\n\tfor _, t := range g.head {\n\t\tif !t.After(g.oldestTime) {\n\t\t\tonlyReadySets = true\n\t\t\tbreak\n\t\t}\n\t}\n\treturn onlyReadySets\n}\n\n// emit sets until we have none left.\nfunc (g *joinGroup) emitAll() error {\n\tvar lastErr error\n\tfor len(g.sets) > 0 {\n\t\terr := g.emit(false)\n\t\tif err != nil {\n\t\t\tlastErr = err\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// emit a single joined set\nfunc (g *joinGroup) emitJoinedSet(set *joinset) error {\n\tif set.name == \"\" {\n\t\tset.name = set.First().(edge.NameGetter).Name()\n\t}\n\tswitch g.n.Wants() {\n\tcase pipeline.StreamEdge:\n\t\tp, err := set.JoinIntoPoint()\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"failed to join into point\")\n\t\t}\n\t\tif p != nil {\n\t\t\tif err := edge.Forward(g.n.outs, p); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\tcase pipeline.BatchEdge:\n\t\tb, err := set.JoinIntoBatch()\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"failed to join into batch\")\n\t\t}\n\t\tif b != nil {\n\t\t\tif err := edge.Forward(g.n.outs, b); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}\n\n// A groupId and its parent\ntype srcGroup struct {\n\tsrc     int\n\tgroupId models.GroupID\n}\n\n// represents a set of points or batches from the same joined time\ntype joinset struct {\n\tj         *JoinNode\n\tname      string\n\tfill      influxql.FillOption\n\tfillValue interface{}\n\tprefixes  []string\n\tdelimiter string\n\n\ttime      time.Time\n\ttolerance time.Duration\n\tvalues    []edge.Message\n\n\texpected int\n\tsize     int\n\n\tfirst int\n\n\tdiag NodeDiagnostic\n}\n\nfunc newJoinset(\n\tn *JoinNode,\n\tname string,\n\tfill influxql.FillOption,\n\tfillValue interface{},\n\tprefixes []string,\n\tdelimiter string,\n\ttolerance time.Duration,\n\ttime time.Time,\n\td NodeDiagnostic,\n) *joinset {\n\texpected := len(prefixes)\n\treturn &joinset{\n\t\tj:         n,\n\t\tname:      name,\n\t\tfill:      fill,\n\t\tfillValue: fillValue,\n\t\tprefixes:  prefixes,\n\t\tdelimiter: delimiter,\n\t\texpected:  expected,\n\t\tvalues:    make([]edge.Message, expected),\n\t\tfirst:     expected,\n\t\ttime:      time,\n\t\ttolerance: tolerance,\n\t\tdiag:      d,\n\t}\n}\n\nfunc (js *joinset) Ready() bool {\n\treturn js.size == js.expected\n}\n\nfunc (js *joinset) Has(i int) bool {\n\treturn js.values[i] != nil\n}\n\n// add a point to the set from a given parent index.\nfunc (js *joinset) Set(i int, v edge.Message) {\n\tif i < js.first {\n\t\tjs.first = i\n\t}\n\tjs.values[i] = v\n\tjs.size++\n}\n\n// a valid point in the set\nfunc (js *joinset) First() edge.Message {\n\treturn js.values[js.first]\n}\n\n// join all points into a single point\nfunc (js *joinset) JoinIntoPoint() (edge.PointMessage, error) {\n\tfirst, ok := js.First().(edge.PointMessage)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"unexpected type of first value %T\", js.First())\n\t}\n\tfirstFields := first.Fields()\n\tfields := make(models.Fields, js.size*len(firstFields))\n\tfor i, v := range js.values {\n\t\tif v == nil {\n\t\t\tswitch js.fill {\n\t\t\tcase influxql.NullFill:\n\t\t\t\tfor k := range firstFields {\n\t\t\t\t\tfields[js.prefixes[i]+js.delimiter+k] = nil\n\t\t\t\t}\n\t\t\tcase influxql.NumberFill:\n\t\t\t\tfor k := range firstFields {\n\t\t\t\t\tfields[js.prefixes[i]+js.delimiter+k] = js.fillValue\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\t// inner join no valid point possible\n\t\t\t\treturn nil, nil\n\t\t\t}\n\t\t} else {\n\t\t\tp, ok := v.(edge.FieldGetter)\n\t\t\tif !ok {\n\t\t\t\treturn nil, fmt.Errorf(\"unexpected type %T\", v)\n\t\t\t}\n\t\t\tfor k, v := range p.Fields() {\n\t\t\t\tfields[js.prefixes[i]+js.delimiter+k] = v\n\t\t\t}\n\t\t}\n\t}\n\tnp := edge.NewPointMessage(\n\t\tjs.name, \"\", \"\",\n\t\tfirst.Dimensions(),\n\t\tfields,\n\t\tfirst.GroupInfo().Tags,\n\t\tjs.time,\n\t)\n\treturn np, nil\n}\n\n// join all batches the set into a single batch\nfunc (js *joinset) JoinIntoBatch() (edge.BufferedBatchMessage, error) {\n\tfirst, ok := js.First().(edge.BufferedBatchMessage)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"unexpected type of first value %T\", js.First())\n\t}\n\tnewBegin := edge.NewBeginBatchMessage(\n\t\tjs.name,\n\t\tfirst.Tags(),\n\t\tfirst.Dimensions().ByName,\n\t\tjs.time,\n\t\t0,\n\t)\n\tnewPoints := make([]edge.BatchPointMessage, 0, len(first.Points()))\n\tempty := make([]bool, js.expected)\n\temptyCount := 0\n\tindexes := make([]int, js.expected)\n\tvar fieldNames []string\n\nBATCH_POINT:\n\tfor emptyCount < js.expected {\n\t\tset := make([]edge.BatchPointMessage, js.expected)\n\t\tsetTime := time.Time{}\n\t\tcount := 0\n\t\tfor i, batch := range js.values {\n\t\t\tif empty[i] {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif batch == nil {\n\t\t\t\temptyCount++\n\t\t\t\tempty[i] = true\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tb, ok := batch.(edge.BufferedBatchMessage)\n\t\t\tif !ok {\n\t\t\t\treturn nil, fmt.Errorf(\"unexpected type of batch value %T\", batch)\n\t\t\t}\n\t\t\tif indexes[i] == len(b.Points()) {\n\t\t\t\temptyCount++\n\t\t\t\tempty[i] = true\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tbp := b.Points()[indexes[i]]\n\t\t\tt := bp.Time().Round(js.tolerance)\n\t\t\tif setTime.IsZero() {\n\t\t\t\tsetTime = t\n\t\t\t}\n\t\t\tif t.Before(setTime) {\n\t\t\t\t// We need to backup\n\t\t\t\tsetTime = t\n\t\t\t\tfor j := range set {\n\t\t\t\t\tif set[j] != nil {\n\t\t\t\t\t\tindexes[j]--\n\t\t\t\t\t}\n\t\t\t\t\tset[j] = nil\n\t\t\t\t}\n\t\t\t\tset[i] = bp\n\t\t\t\tindexes[i]++\n\t\t\t\tcount = 1\n\t\t\t} else if t.Equal(setTime) {\n\t\t\t\tif fieldNames == nil {\n\t\t\t\t\tfor k := range bp.Fields() {\n\t\t\t\t\t\tfieldNames = append(fieldNames, k)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tset[i] = bp\n\t\t\t\tindexes[i]++\n\t\t\t\tcount++\n\t\t\t}\n\t\t}\n\t\t// we didn't get any points from any group we must be empty\n\t\t// skip this set\n\t\tif count == 0 {\n\t\t\tcontinue\n\t\t}\n\t\t// Join all batch points in set\n\t\tfields := make(models.Fields, js.expected*len(fieldNames))\n\t\tfor i, bp := range set {\n\t\t\tif bp == nil {\n\t\t\t\tswitch js.fill {\n\t\t\t\tcase influxql.NullFill:\n\t\t\t\t\tfor _, k := range fieldNames {\n\t\t\t\t\t\tfields[js.prefixes[i]+js.delimiter+k] = nil\n\t\t\t\t\t}\n\t\t\t\tcase influxql.NumberFill:\n\t\t\t\t\tfor _, k := range fieldNames {\n\t\t\t\t\t\tfields[js.prefixes[i]+js.delimiter+k] = js.fillValue\n\t\t\t\t\t}\n\t\t\t\tdefault:\n\t\t\t\t\t// inner join no valid point possible\n\t\t\t\t\tcontinue BATCH_POINT\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfor k, v := range bp.Fields() {\n\t\t\t\t\tfields[js.prefixes[i]+js.delimiter+k] = v\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tbp := edge.NewBatchPointMessage(\n\t\t\tfields,\n\t\t\tnewBegin.Tags(),\n\t\t\tsetTime,\n\t\t)\n\t\tnewPoints = append(newPoints, bp)\n\t}\n\tnewBegin.SetSizeHint(len(newPoints))\n\treturn edge.NewBufferedBatchMessage(\n\t\tnewBegin,\n\t\tnewPoints,\n\t\tedge.NewEndBatchMessage(),\n\t), nil\n}\n"
        },
        {
          "name": "kapacitor_loopback.go",
          "type": "blob",
          "size": 2.654296875,
          "content": "package kapacitor\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/expvar\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n)\n\ntype KapacitorLoopbackNode struct {\n\tnode\n\tk *pipeline.KapacitorLoopbackNode\n\n\tpointsWritten *expvar.Int\n\n\tbegin edge.BeginBatchMessage\n}\n\nfunc newKapacitorLoopbackNode(et *ExecutingTask, n *pipeline.KapacitorLoopbackNode, d NodeDiagnostic) (*KapacitorLoopbackNode, error) {\n\tkn := &KapacitorLoopbackNode{\n\t\tnode: node{Node: n, et: et, diag: d},\n\t\tk:    n,\n\t}\n\tkn.node.runF = kn.runOut\n\t// Check that a loop has not been created within this task\n\tfor _, dbrp := range et.Task.DBRPs {\n\t\tif dbrp.Database == n.Database && dbrp.RetentionPolicy == n.RetentionPolicy {\n\t\t\treturn nil, fmt.Errorf(\"loop detected on dbrp: %v\", dbrp)\n\t\t}\n\t}\n\treturn kn, nil\n}\n\nfunc (n *KapacitorLoopbackNode) runOut([]byte) error {\n\tn.pointsWritten = &expvar.Int{}\n\tn.statMap.Set(statsInfluxDBPointsWritten, n.pointsWritten)\n\n\tconsumer := edge.NewConsumerWithReceiver(\n\t\tn.ins[0],\n\t\tn,\n\t)\n\treturn consumer.Consume()\n}\n\nfunc (n *KapacitorLoopbackNode) Point(p edge.PointMessage) error {\n\tn.timer.Start()\n\tdefer n.timer.Stop()\n\n\tp = p.ShallowCopy()\n\n\tif n.k.Database != \"\" {\n\t\tp.SetDatabase(n.k.Database)\n\t}\n\tif n.k.RetentionPolicy != \"\" {\n\t\tp.SetRetentionPolicy(n.k.RetentionPolicy)\n\t}\n\tif n.k.Measurement != \"\" {\n\t\tp.SetName(n.k.Measurement)\n\t}\n\tif len(n.k.Tags) > 0 {\n\t\ttags := p.Tags().Copy()\n\t\tfor k, v := range n.k.Tags {\n\t\t\ttags[k] = v\n\t\t}\n\t\tp.SetTags(tags)\n\t}\n\n\tn.timer.Pause()\n\terr := n.et.tm.WriteKapacitorPoint(p)\n\tn.timer.Resume()\n\n\tif err != nil {\n\t\tn.diag.Error(\"failed to write point over loopback\", err)\n\n\t} else {\n\t\tn.pointsWritten.Add(1)\n\t}\n\treturn nil\n}\n\nfunc (n *KapacitorLoopbackNode) BeginBatch(begin edge.BeginBatchMessage) error {\n\tn.begin = begin\n\treturn nil\n}\n\nfunc (n *KapacitorLoopbackNode) BatchPoint(bp edge.BatchPointMessage) error {\n\ttags := bp.Tags()\n\tif len(n.k.Tags) > 0 {\n\t\ttags = bp.Tags().Copy()\n\t\tfor k, v := range n.k.Tags {\n\t\t\ttags[k] = v\n\t\t}\n\t}\n\tp := edge.NewPointMessage(\n\t\tn.begin.Name(),\n\t\tn.k.Database,\n\t\tn.k.RetentionPolicy,\n\t\tmodels.Dimensions{},\n\t\tbp.Fields(),\n\t\ttags,\n\t\tbp.Time(),\n\t)\n\n\tn.timer.Pause()\n\terr := n.et.tm.WriteKapacitorPoint(p)\n\tn.timer.Resume()\n\n\tif err != nil {\n\t\tn.diag.Error(\"failed to write point over loopback\", err)\n\t} else {\n\t\tn.pointsWritten.Add(1)\n\t}\n\treturn nil\n}\nfunc (n *KapacitorLoopbackNode) EndBatch(edge.EndBatchMessage) error {\n\treturn nil\n}\nfunc (n *KapacitorLoopbackNode) Barrier(edge.BarrierMessage) error {\n\treturn nil\n}\nfunc (n *KapacitorLoopbackNode) DeleteGroup(edge.DeleteGroupMessage) error {\n\treturn nil\n}\nfunc (n *KapacitorLoopbackNode) Done() {}\n"
        },
        {
          "name": "keyvalue",
          "type": "tree",
          "content": null
        },
        {
          "name": "list-deps",
          "type": "blob",
          "size": 1.080078125,
          "content": "#!/bin/bash\n\n# Make sure we are in the dir of the script\nDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\ncd $DIR\n\n# List all dependent packages and whether they have been vendored.\ndeps() {\n    local package packages allDeps paths\n\n    # Get the current package\n    package=$(go list .)\n    # Get the sub packages excluding vendored packages\n    packages=$(go list ./... | grep -v \"^$package/vendor\")\n    allDeps=$(go list -f '{{ join .Deps \"\\n\"}}' $packages)\n\n    for dep in $allDeps\n    do\n        # Skip standard lib deps\n        paths=(${dep//\\// })\n        if ! [[ \"${paths[0]}\" =~ .*\\..* ]]\n        then\n            continue\n        fi\n        # Skip deps from within current package\n        if [[ \"$dep\" =~ ^$package ]]\n        then\n            if [[ \"$dep\" =~ ^$package/vendor ]]\n            then\n                # Rewrite vendored deps as normal deps\n                dep=\"v ${dep/$package\\/vendor\\//}\"\n            else\n                continue\n            fi\n        else\n            dep=\"n $dep\"\n        fi\n\n        echo $dep\n    done\n}\n\n\n# Deduplicate and sort the output\ndeps | sort -k 2 -u\n\n"
        },
        {
          "name": "listmap",
          "type": "tree",
          "content": null
        },
        {
          "name": "log.go",
          "type": "blob",
          "size": 1.79296875,
          "content": "package kapacitor\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"strings\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n)\n\ntype LogNode struct {\n\tnode\n\n\tlevel  string\n\tprefix string\n\tbuf    bytes.Buffer\n\tenc    *json.Encoder\n\n\tbatchBuffer *edge.BatchBuffer\n}\n\n// Create a new  LogNode which logs all data it receives\nfunc newLogNode(et *ExecutingTask, n *pipeline.LogNode, d NodeDiagnostic) (*LogNode, error) {\n\tnn := &LogNode{\n\t\tnode:        node{Node: n, et: et, diag: d},\n\t\tlevel:       strings.ToUpper(n.Level),\n\t\tprefix:      n.Prefix,\n\t\tbatchBuffer: new(edge.BatchBuffer),\n\t}\n\tnn.enc = json.NewEncoder(&nn.buf)\n\tnn.node.runF = nn.runLog\n\treturn nn, nil\n}\n\nfunc (n *LogNode) runLog([]byte) error {\n\tconsumer := edge.NewConsumerWithReceiver(\n\t\tn.ins[0],\n\t\tedge.NewReceiverFromForwardReceiverWithStats(\n\t\t\tn.outs,\n\t\t\tedge.NewTimedForwardReceiver(n.timer, n),\n\t\t),\n\t)\n\treturn consumer.Consume()\n\n}\n\nfunc (n *LogNode) BeginBatch(begin edge.BeginBatchMessage) (edge.Message, error) {\n\treturn nil, n.batchBuffer.BeginBatch(begin)\n}\n\nfunc (n *LogNode) BatchPoint(bp edge.BatchPointMessage) (edge.Message, error) {\n\treturn nil, n.batchBuffer.BatchPoint(bp)\n}\n\nfunc (n *LogNode) EndBatch(end edge.EndBatchMessage) (edge.Message, error) {\n\treturn n.BufferedBatch(n.batchBuffer.BufferedBatchMessage(end))\n}\n\nfunc (n *LogNode) BufferedBatch(batch edge.BufferedBatchMessage) (edge.Message, error) {\n\tn.diag.LogBatchData(n.level, n.prefix, batch)\n\treturn batch, nil\n}\n\nfunc (n *LogNode) Point(p edge.PointMessage) (edge.Message, error) {\n\tn.diag.LogPointData(n.level, n.prefix, p)\n\treturn p, nil\n}\n\nfunc (n *LogNode) Barrier(b edge.BarrierMessage) (edge.Message, error) {\n\treturn b, nil\n}\nfunc (n *LogNode) DeleteGroup(d edge.DeleteGroupMessage) (edge.Message, error) {\n\treturn d, nil\n}\nfunc (n *LogNode) Done() {}\n"
        },
        {
          "name": "metaclient.go",
          "type": "blob",
          "size": 1.0810546875,
          "content": "package kapacitor\n\nimport (\n\t\"errors\"\n\t\"time\"\n\n\t\"github.com/influxdata/influxdb/services/meta\"\n)\n\ntype NoopMetaClient struct{}\n\nfunc (m *NoopMetaClient) WaitForLeader(d time.Duration) error {\n\treturn nil\n}\nfunc (m *NoopMetaClient) CreateDatabase(name string) (*meta.DatabaseInfo, error) {\n\treturn nil, nil\n}\nfunc (m *NoopMetaClient) CreateDatabaseWithRetentionPolicy(name string, rpi *meta.RetentionPolicySpec) (*meta.DatabaseInfo, error) {\n\treturn nil, nil\n}\nfunc (m *NoopMetaClient) CreateRetentionPolicy(database string, spec *meta.RetentionPolicySpec, makeDefault bool) (*meta.RetentionPolicyInfo, error) {\n\treturn nil, nil\n}\nfunc (m *NoopMetaClient) Database(name string) *meta.DatabaseInfo {\n\treturn &meta.DatabaseInfo{\n\t\tName: name,\n\t}\n}\nfunc (m *NoopMetaClient) RetentionPolicy(database, name string) (*meta.RetentionPolicyInfo, error) {\n\treturn nil, nil\n}\nfunc (m *NoopMetaClient) Authenticate(username, password string) (ui *meta.UserInfo, err error) {\n\treturn nil, errors.New(\"not authenticated\")\n}\nfunc (m *NoopMetaClient) Users() ([]meta.UserInfo, error) {\n\treturn nil, errors.New(\"no user\")\n}\n"
        },
        {
          "name": "models",
          "type": "tree",
          "content": null
        },
        {
          "name": "node.go",
          "type": "blob",
          "size": 9.279296875,
          "content": "package kapacitor\n\nimport (\n\t\"bytes\"\n\t\"expvar\"\n\t\"fmt\"\n\t\"runtime\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"github.com/influxdata/kapacitor/alert\"\n\t\"github.com/influxdata/kapacitor/edge\"\n\tkexpvar \"github.com/influxdata/kapacitor/expvar\"\n\t\"github.com/influxdata/kapacitor/keyvalue\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n\t\"github.com/influxdata/kapacitor/server/vars\"\n\t\"github.com/influxdata/kapacitor/timer\"\n\t\"github.com/pkg/errors\"\n)\n\nconst (\n\tstatErrorCount       = \"errors\"\n\tstatCardinalityGauge = \"working_cardinality\"\n\tstatAverageExecTime  = \"avg_exec_time_ns\"\n)\n\ntype NodeDiagnostic interface {\n\tError(msg string, err error, ctx ...keyvalue.T)\n\n\t// AlertNode\n\tAlertTriggered(level alert.Level, id string, message string, rows *models.Row)\n\n\t// AutoscaleNode\n\tSettingReplicas(new int, old int, id string)\n\n\t// QueryNode\n\tStartingBatchQuery(q string)\n\n\t// LogNode\n\tLogPointData(key, prefix string, data edge.PointMessage)\n\tLogBatchData(key, prefix string, data edge.BufferedBatchMessage)\n\n\t//UDF\n\tUDFLog(s string)\n}\n\ntype nodeDiagnostic struct {\n\tNodeDiagnostic\n\tnode *node\n}\n\nfunc newNodeDiagnostic(n *node, diag NodeDiagnostic) *nodeDiagnostic {\n\treturn &nodeDiagnostic{\n\t\tNodeDiagnostic: diag,\n\t\tnode:           n,\n\t}\n}\n\nfunc (n *nodeDiagnostic) Error(msg string, err error, ctx ...keyvalue.T) {\n\tn.node.incrementErrorCount()\n\tif !n.node.quiet {\n\t\tn.NodeDiagnostic.Error(msg, err, ctx...)\n\t}\n}\n\n// A node that can be  in an executor.\ntype Node interface {\n\tpipeline.Node\n\n\taddParentEdge(edge.StatsEdge)\n\n\tinit(quiet bool)\n\n\t// start the node and its children\n\tstart(snapshot []byte)\n\tstop()\n\n\t// snapshot running state\n\tsnapshot() ([]byte, error)\n\trestore(snapshot []byte) error\n\n\t// wait for the node to finish processing and return any errors\n\tWait() error\n\n\t// link specified child\n\tlinkChild(c Node) error\n\taddParent(p Node)\n\n\t// close children edges\n\tcloseChildEdges()\n\t// abort parent edges\n\tabortParentEdges()\n\n\t// executing dot\n\tedot(buf *bytes.Buffer, labels bool)\n\n\tnodeStatsByGroup() map[models.GroupID]nodeStats\n\n\tcollectedCount() int64\n\n\temittedCount() int64\n\n\tincrementErrorCount()\n\n\tstats() map[string]interface{}\n}\n\n// implementation of Node\ntype node struct {\n\tpipeline.Node\n\tet         *ExecutingTask\n\tparents    []Node\n\tchildren   []Node\n\trunF       func(snapshot []byte) error\n\tstopF      func()\n\terrCh      chan error\n\terr        error\n\tfinishedMu sync.Mutex\n\tfinished   bool\n\tins        []edge.StatsEdge\n\touts       []edge.StatsEdge\n\tdiag       NodeDiagnostic\n\ttimer      timer.Timer\n\tstatsKey   string\n\tstatMap    *kexpvar.Map\n\n\tquiet bool\n\n\tnodeErrors *kexpvar.Int\n}\n\nfunc (n *node) addParentEdge(e edge.StatsEdge) {\n\tn.ins = append(n.ins, e)\n}\n\nfunc (n *node) abortParentEdges() {\n\tfor _, in := range n.ins {\n\t\tin.Abort()\n\t}\n}\n\nfunc (n *node) init(quiet bool) {\n\ttags := map[string]string{\n\t\t\"task\": n.et.Task.ID,\n\t\t\"node\": n.Name(),\n\t\t\"type\": n.et.Task.Type.String(),\n\t\t\"kind\": n.Desc(),\n\t}\n\tn.statsKey, n.statMap = vars.NewStatistic(\"nodes\", tags)\n\tavgExecVar := &MaxDuration{}\n\tn.statMap.Set(statAverageExecTime, avgExecVar)\n\tn.nodeErrors = &kexpvar.Int{}\n\tn.statMap.Set(statErrorCount, n.nodeErrors)\n\tn.diag = newNodeDiagnostic(n, n.diag)\n\tn.statMap.Set(statCardinalityGauge, kexpvar.NewIntFuncGauge(nil))\n\tn.timer = n.et.tm.TimingService.NewTimer(avgExecVar)\n\tn.errCh = make(chan error, 1)\n\tn.quiet = quiet\n}\n\nfunc (n *node) start(snapshot []byte) {\n\tgo func() {\n\t\tvar err error\n\t\tdefer func() {\n\t\t\t// Always close children edges\n\t\t\tn.closeChildEdges()\n\t\t\t// Propagate error up\n\t\t\tif err != nil {\n\t\t\t\t// Handle panic in runF\n\t\t\t\tr := recover()\n\t\t\t\tif r != nil {\n\t\t\t\t\ttrace := make([]byte, 512)\n\t\t\t\t\tn := runtime.Stack(trace, false)\n\t\t\t\t\terr = fmt.Errorf(\"%s: Trace:%s\", r, string(trace[:n]))\n\t\t\t\t}\n\t\t\t\tn.abortParentEdges()\n\t\t\t\tn.diag.Error(\"node failed\", err)\n\n\t\t\t\terr = errors.Wrap(err, n.Name())\n\t\t\t}\n\t\t\tn.errCh <- err\n\t\t}()\n\t\t// Run node\n\t\terr = n.runF(snapshot)\n\t}()\n}\n\nfunc (n *node) stop() {\n\tif n.stopF != nil {\n\t\tn.stopF()\n\t}\n\tvars.DeleteStatistic(n.statsKey)\n}\n\n// no-op snapshot\nfunc (n *node) snapshot() (b []byte, err error) { return }\n\n// no-op restore\nfunc (n *node) restore([]byte) error { return nil }\n\nfunc (n *node) Wait() error {\n\tn.finishedMu.Lock()\n\tdefer n.finishedMu.Unlock()\n\tif !n.finished {\n\t\tn.finished = true\n\t\tn.err = <-n.errCh\n\t}\n\treturn n.err\n}\n\nfunc (n *node) addChild(c Node) (edge.StatsEdge, error) {\n\tif n.Provides() != c.Wants() {\n\t\treturn nil, fmt.Errorf(\"cannot add child mismatched edges: %s:%s -> %s:%s\", n.Name(), n.Provides(), c.Name(), c.Wants())\n\t}\n\tif n.Provides() == pipeline.NoEdge {\n\t\treturn nil, fmt.Errorf(\"cannot add child no edge expected: %s:%s -> %s:%s\", n.Name(), n.Provides(), c.Name(), c.Wants())\n\t}\n\tn.children = append(n.children, c)\n\n\td := n.et.tm.diag.WithEdgeContext(n.et.Task.ID, n.Name(), c.Name())\n\tedge := newEdge(n.et.Task.ID, n.Name(), c.Name(), n.Provides(), defaultEdgeBufferSize, d)\n\tif edge == nil {\n\t\treturn nil, fmt.Errorf(\"unknown edge type %s\", n.Provides())\n\t}\n\tc.addParentEdge(edge)\n\treturn edge, nil\n}\n\nfunc (n *node) addParent(p Node) {\n\tn.parents = append(n.parents, p)\n}\n\nfunc (n *node) linkChild(c Node) error {\n\t// add child\n\tedge, err := n.addChild(c)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// add parent\n\tc.addParent(n)\n\n\t// store edge to child\n\tn.outs = append(n.outs, edge)\n\treturn nil\n}\n\nfunc (n *node) closeChildEdges() {\n\tfor _, child := range n.outs {\n\t\tchild.Close()\n\t}\n}\n\nfunc (n *node) edot(buf *bytes.Buffer, labels bool) {\n\tif labels {\n\t\t// Print all stats on node.\n\t\tbuf.WriteString(\n\t\t\tfmt.Sprintf(\"\\n%s [xlabel=\\\"\",\n\t\t\t\tn.Name(),\n\t\t\t),\n\t\t)\n\t\ti := 0\n\t\tn.statMap.DoSorted(func(kv expvar.KeyValue) {\n\t\t\tif i != 0 {\n\t\t\t\t// NOTE: A literal \\r, indicates a newline right justified in graphviz syntax.\n\t\t\t\tbuf.WriteString(`\\r`)\n\t\t\t}\n\t\t\ti++\n\t\t\tvar s string\n\t\t\tif sv, ok := kv.Value.(kexpvar.StringVar); ok {\n\t\t\t\ts = sv.StringValue()\n\t\t\t} else {\n\t\t\t\ts = kv.Value.String()\n\t\t\t}\n\t\t\tbuf.WriteString(\n\t\t\t\tfmt.Sprintf(\"%s=%s\",\n\t\t\t\t\tkv.Key,\n\t\t\t\t\ts,\n\t\t\t\t),\n\t\t\t)\n\t\t})\n\t\tbuf.Write([]byte(\"\\\"];\\n\"))\n\n\t\tfor i, c := range n.children {\n\t\t\tbuf.Write([]byte(\n\t\t\t\tfmt.Sprintf(\"%s -> %s [label=\\\"processed=%d\\\"];\\n\",\n\t\t\t\t\tn.Name(),\n\t\t\t\t\tc.Name(),\n\t\t\t\t\tn.outs[i].Collected(),\n\t\t\t\t),\n\t\t\t))\n\t\t}\n\n\t} else {\n\t\t// Print all stats on node.\n\t\tbuf.Write([]byte(\n\t\t\tfmt.Sprintf(\"\\n%s [\",\n\t\t\t\tn.Name(),\n\t\t\t),\n\t\t))\n\t\tn.statMap.DoSorted(func(kv expvar.KeyValue) {\n\t\t\tvar s string\n\t\t\tif sv, ok := kv.Value.(kexpvar.StringVar); ok {\n\t\t\t\ts = sv.StringValue()\n\t\t\t} else {\n\t\t\t\ts = kv.Value.String()\n\t\t\t}\n\t\t\tbuf.Write([]byte(\n\t\t\t\tfmt.Sprintf(\"%s=\\\"%s\\\" \",\n\t\t\t\t\tkv.Key,\n\t\t\t\t\ts,\n\t\t\t\t),\n\t\t\t))\n\t\t})\n\t\tbuf.Write([]byte(\"];\\n\"))\n\t\tfor i, c := range n.children {\n\t\t\tbuf.Write([]byte(\n\t\t\t\tfmt.Sprintf(\"%s -> %s [processed=\\\"%d\\\"];\\n\",\n\t\t\t\t\tn.Name(),\n\t\t\t\t\tc.Name(),\n\t\t\t\t\tn.outs[i].Collected(),\n\t\t\t\t),\n\t\t\t))\n\t\t}\n\t}\n}\n\n// node collected count is the sum of emitted counts of parent edges\nfunc (n *node) collectedCount() (count int64) {\n\tfor _, in := range n.ins {\n\t\tcount += in.Emitted()\n\t}\n\treturn\n}\n\n// node emitted count is the sum of collected counts of children edges\nfunc (n *node) emittedCount() (count int64) {\n\tfor _, out := range n.outs {\n\t\tcount += out.Collected()\n\t}\n\treturn\n}\n\n// node increment error count increments a nodes error_count stat\nfunc (n *node) incrementErrorCount() {\n\tn.nodeErrors.Add(1)\n}\n\nfunc (n *node) stats() map[string]interface{} {\n\tstats := make(map[string]interface{})\n\n\tn.statMap.Do(func(kv expvar.KeyValue) {\n\t\tswitch v := kv.Value.(type) {\n\t\tcase kexpvar.IntVar:\n\t\t\tstats[kv.Key] = v.IntValue()\n\t\tcase kexpvar.FloatVar:\n\t\t\tstats[kv.Key] = v.FloatValue()\n\t\tdefault:\n\t\t\tstats[kv.Key] = v.String()\n\t\t}\n\t})\n\n\treturn stats\n}\n\n// Statistics for a node\ntype nodeStats struct {\n\tFields     models.Fields\n\tTags       models.Tags\n\tDimensions models.Dimensions\n}\n\n// Return a copy of the current node statistics.\n// If if no groups have been seen yet a NilGroup will be created with zero stats.\nfunc (n *node) nodeStatsByGroup() (stats map[models.GroupID]nodeStats) {\n\t// Get the counts for just one output.\n\tstats = make(map[models.GroupID]nodeStats)\n\tif len(n.outs) > 0 {\n\t\tn.outs[0].ReadGroupStats(func(g *edge.GroupStats) {\n\t\t\tstats[g.GroupInfo.ID] = nodeStats{\n\t\t\t\tFields: models.Fields{\n\t\t\t\t\t// A node's emitted count is the collected count of its output.\n\t\t\t\t\t\"emitted\": g.Collected,\n\t\t\t\t},\n\t\t\t\tTags:       g.GroupInfo.Tags,\n\t\t\t\tDimensions: g.GroupInfo.Dimensions,\n\t\t\t}\n\t\t})\n\t}\n\tif len(stats) == 0 {\n\t\t// If we have no groups/stats add nil group with emitted = 0\n\t\tstats[\"\"] = nodeStats{\n\t\t\tFields: models.Fields{\n\t\t\t\t\"emitted\": int64(0),\n\t\t\t},\n\t\t}\n\t}\n\treturn\n}\n\n// MaxDuration is a 64-bit int variable representing a duration in nanoseconds,that satisfies the expvar.Var interface.\n// When setting a value it will only be set if it is greater than the current value.\ntype MaxDuration struct {\n\td      int64\n\tsetter timer.Setter\n}\n\nfunc (v *MaxDuration) String() string {\n\treturn `\"` + v.StringValue() + `\"`\n}\n\nfunc (v *MaxDuration) StringValue() string {\n\treturn time.Duration(v.IntValue()).String()\n}\n\nfunc (v *MaxDuration) IntValue() int64 {\n\treturn atomic.LoadInt64(&v.d)\n}\n\n// Set sets value if it is greater than current value.\n// If set was successful and a setter exists, will pass on value to setter.\nfunc (v *MaxDuration) Set(next int64) {\n\tfor {\n\t\tcur := v.IntValue()\n\t\tif next > cur {\n\t\t\tif atomic.CompareAndSwapInt64(&v.d, cur, next) {\n\t\t\t\tif v.setter != nil {\n\t\t\t\t\tv.setter.Set(next)\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\t\t} else {\n\t\t\treturn\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "noop.go",
          "type": "blob",
          "size": 0.6123046875,
          "content": "package kapacitor\n\nimport (\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n)\n\ntype NoOpNode struct {\n\tnode\n}\n\n// Create a new  NoOpNode which does nothing with the data and just passes it through.\nfunc newNoOpNode(et *ExecutingTask, n *pipeline.NoOpNode, d NodeDiagnostic) (*NoOpNode, error) {\n\tnn := &NoOpNode{\n\t\tnode: node{Node: n, et: et, diag: d},\n\t}\n\tnn.node.runF = nn.runNoOp\n\treturn nn, nil\n}\n\nfunc (n *NoOpNode) runNoOp([]byte) error {\n\tfor m, ok := n.ins[0].Emit(); ok; m, ok = n.ins[0].Emit() {\n\t\tif err := edge.Forward(n.outs, m); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n"
        },
        {
          "name": "output.go",
          "type": "blob",
          "size": 0.1630859375,
          "content": "package kapacitor\n\n// An output of a pipeline. Still need to improve this interface to expose different types of outputs.\ntype Output interface {\n\tEndpoint() string\n}\n"
        },
        {
          "name": "pipeline",
          "type": "tree",
          "content": null
        },
        {
          "name": "pkg-config.sh",
          "type": "blob",
          "size": 0.4453125,
          "content": "#!/usr/bin/env bash\n\ntmpdir=$(mktemp -d)\ntrap \"{ rm -rf ${tmpdir}; }\" EXIT\n\n# \"go build\" can be noisy, and when Go invokes pkg-config (by calling this script) it will merge stdout and stderr.\n# Discard any output unless \"go build\" terminates with an error.\ngo build -o ${tmpdir}/pkg-config github.com/influxdata/pkg-config &> ${tmpdir}/go_build_output\nif [ \"$?\" -ne 0 ]; then\n    cat ${tmpdir}/go_build_output 1>&2\n    exit 1\nfi\n\n${tmpdir}/pkg-config \"$@\"\n"
        },
        {
          "name": "query.go",
          "type": "blob",
          "size": 6.626953125,
          "content": "package kapacitor\n\nimport (\n\t\"fmt\"\n\t\"time\"\n\n\t\"github.com/influxdata/influxql\"\n\t\"github.com/influxdata/kapacitor/tick/ast\"\n\t\"github.com/pkg/errors\"\n)\n\ntype Query struct {\n\tstartTL         *influxql.TimeLiteral\n\tstopTL          *influxql.TimeLiteral\n\tgroupByTimeDL   *influxql.DurationLiteral\n\tgroupByOffsetDL *influxql.DurationLiteral\n\tstmt            *influxql.SelectStatement\n\talignGroup      bool\n}\n\nfunc NewQuery(queryString string) (*Query, error) {\n\tquery := &Query{}\n\t// Parse and validate query\n\tq, err := influxql.ParseQuery(queryString)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to parse InfluxQL query\")\n\t}\n\tif l := len(q.Statements); l != 1 {\n\t\treturn nil, fmt.Errorf(\"query must be a single select statement, got %d statements\", l)\n\t}\n\tvar ok bool\n\tquery.stmt, ok = q.Statements[0].(*influxql.SelectStatement)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"query is not a select statement %q\", q)\n\t}\n\n\t// Add in time condition nodes\n\tquery.startTL = &influxql.TimeLiteral{}\n\tstartExpr := &influxql.BinaryExpr{\n\t\tOp:  influxql.GTE,\n\t\tLHS: &influxql.VarRef{Val: \"time\"},\n\t\tRHS: query.startTL,\n\t}\n\n\tquery.stopTL = &influxql.TimeLiteral{}\n\tstopExpr := &influxql.BinaryExpr{\n\t\tOp:  influxql.LT,\n\t\tLHS: &influxql.VarRef{Val: \"time\"},\n\t\tRHS: query.stopTL,\n\t}\n\n\tif query.stmt.Condition != nil {\n\t\tquery.stmt.Condition = &influxql.BinaryExpr{\n\t\t\tOp:  influxql.AND,\n\t\t\tLHS: query.stmt.Condition,\n\t\t\tRHS: &influxql.BinaryExpr{\n\t\t\t\tOp:  influxql.AND,\n\t\t\t\tLHS: startExpr,\n\t\t\t\tRHS: stopExpr,\n\t\t\t},\n\t\t}\n\t} else {\n\t\tquery.stmt.Condition = &influxql.BinaryExpr{\n\t\t\tOp:  influxql.AND,\n\t\t\tLHS: startExpr,\n\t\t\tRHS: stopExpr,\n\t\t}\n\t}\n\treturn query, nil\n}\n\n// Return the db rp pairs of the query\nfunc (q *Query) DBRPs() ([]DBRP, error) {\n\tdbrps := make([]DBRP, len(q.stmt.Sources))\n\tfor i, s := range q.stmt.Sources {\n\t\tm, ok := s.(*influxql.Measurement)\n\t\tif !ok {\n\t\t\treturn nil, fmt.Errorf(\"unknown query source %T\", s)\n\t\t}\n\t\tdbrps[i] = DBRP{\n\t\t\tDatabase:        m.Database,\n\t\t\tRetentionPolicy: m.RetentionPolicy,\n\t\t}\n\t}\n\treturn dbrps, nil\n}\n\n// Set the start time of the query\nfunc (q *Query) StartTime() time.Time {\n\treturn q.startTL.Val\n}\n\n// Set the stop time of the query\nfunc (q *Query) StopTime() time.Time {\n\treturn q.stopTL.Val\n}\n\n// Set the start time of the query\nfunc (q *Query) SetStartTime(s time.Time) {\n\tq.startTL.Val = s\n\tif q.alignGroup && q.groupByTimeDL != nil && q.groupByOffsetDL != nil {\n\t\tq.groupByOffsetDL.Val = s.Sub(time.Unix(0, 0)) % q.groupByTimeDL.Val\n\t}\n}\n\n// Set the stop time of the query\nfunc (q *Query) SetStopTime(s time.Time) {\n\tq.stopTL.Val = s\n}\n\n// Deep clone this query\nfunc (q *Query) Clone() (*Query, error) {\n\tn := &Query{\n\t\tstmt:       q.stmt.Clone(),\n\t\talignGroup: q.alignGroup,\n\t}\n\t// Find the start/stop time literals\n\tvar err error\n\tinfluxql.WalkFunc(n.stmt.Condition, func(qlNode influxql.Node) {\n\t\tif bn, ok := qlNode.(*influxql.BinaryExpr); ok {\n\t\t\tswitch bn.Op {\n\t\t\tcase influxql.GTE:\n\t\t\t\tif vf, ok := bn.LHS.(*influxql.VarRef); !ok || vf.Val != \"time\" {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif tl, ok := bn.RHS.(*influxql.TimeLiteral); ok {\n\t\t\t\t\t// We have a \"time\" >= 'time literal'\n\t\t\t\t\tif n.startTL == nil {\n\t\t\t\t\t\tn.startTL = tl\n\t\t\t\t\t} else {\n\t\t\t\t\t\terr = errors.New(\"invalid query, found multiple start time conditions\")\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tcase influxql.LT:\n\t\t\t\tif vf, ok := bn.LHS.(*influxql.VarRef); !ok || vf.Val != \"time\" {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif tl, ok := bn.RHS.(*influxql.TimeLiteral); ok {\n\t\t\t\t\t// We have a \"time\" < 'time literal'\n\t\t\t\t\tif n.stopTL == nil {\n\t\t\t\t\t\tn.stopTL = tl\n\t\t\t\t\t} else {\n\t\t\t\t\t\terr = errors.New(\"invalid query, found multiple stop time conditions\")\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n\tinfluxql.WalkFunc(n.stmt.Dimensions, func(qlNode influxql.Node) {\n\t\tif cn, ok := qlNode.(*influxql.Call); ok {\n\t\t\tif cn.Name == \"time\" {\n\t\t\t\tif dln, ok := cn.Args[0].(*influxql.DurationLiteral); ok {\n\t\t\t\t\tn.groupByTimeDL = &influxql.DurationLiteral{\n\t\t\t\t\t\tVal: dln.Val,\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif don, ok := cn.Args[1].(*influxql.DurationLiteral); ok {\n\t\t\t\t\tn.groupByOffsetDL = &influxql.DurationLiteral{\n\t\t\t\t\t\tVal: don.Val,\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n\tif n.startTL == nil {\n\t\terr = errors.New(\"invalid query, missing start time condition\")\n\t}\n\tif n.stopTL == nil {\n\t\terr = errors.New(\"invalid query, missing stop time condition\")\n\t}\n\treturn n, err\n}\n\n// Set the dimensions on the query\nfunc (q *Query) Dimensions(dims []interface{}) error {\n\tq.stmt.Dimensions = q.stmt.Dimensions[:0]\n\tq.groupByTimeDL = nil\n\tq.groupByOffsetDL = &influxql.DurationLiteral{\n\t\tVal: 0,\n\t}\n\t// Add in dimensions\n\thasTime := false\n\tfor _, d := range dims {\n\t\tswitch dim := d.(type) {\n\t\tcase time.Duration:\n\t\t\tif hasTime {\n\t\t\t\treturn fmt.Errorf(\"groupBy cannot have more than one time dimension\")\n\t\t\t}\n\t\t\t// Add time dimension\n\t\t\thasTime = true\n\t\t\tq.groupByTimeDL = &influxql.DurationLiteral{\n\t\t\t\tVal: dim,\n\t\t\t}\n\t\t\tif q.alignGroup {\n\t\t\t\tq.SetStartTime(q.StartTime())\n\t\t\t}\n\t\t\tq.stmt.Dimensions = append(q.stmt.Dimensions,\n\t\t\t\t&influxql.Dimension{\n\t\t\t\t\tExpr: &influxql.Call{\n\t\t\t\t\t\tName: \"time\",\n\t\t\t\t\t\tArgs: []influxql.Expr{\n\t\t\t\t\t\t\tq.groupByTimeDL,\n\t\t\t\t\t\t\tq.groupByOffsetDL,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t})\n\t\tcase string:\n\t\t\tq.stmt.Dimensions = append(q.stmt.Dimensions,\n\t\t\t\t&influxql.Dimension{\n\t\t\t\t\tExpr: &influxql.VarRef{\n\t\t\t\t\t\tVal: dim,\n\t\t\t\t\t},\n\t\t\t\t})\n\t\tcase *ast.StarNode:\n\t\t\tq.stmt.Dimensions = append(q.stmt.Dimensions,\n\t\t\t\t&influxql.Dimension{\n\t\t\t\t\tExpr: &influxql.Wildcard{},\n\t\t\t\t})\n\t\tcase TimeDimension:\n\t\t\tif hasTime {\n\t\t\t\treturn fmt.Errorf(\"groupBy cannot have more than one time dimension\")\n\t\t\t}\n\t\t\t// Add time dimension\n\t\t\thasTime = true\n\t\t\tq.groupByTimeDL = &influxql.DurationLiteral{\n\t\t\t\tVal: dim.Length,\n\t\t\t}\n\t\t\tq.groupByOffsetDL.Val = dim.Offset\n\t\t\tif q.alignGroup {\n\t\t\t\tq.SetStartTime(q.StartTime())\n\t\t\t}\n\t\t\tq.stmt.Dimensions = append(q.stmt.Dimensions,\n\t\t\t\t&influxql.Dimension{\n\t\t\t\t\tExpr: &influxql.Call{\n\t\t\t\t\t\tName: \"time\",\n\t\t\t\t\t\tArgs: []influxql.Expr{\n\t\t\t\t\t\t\tq.groupByTimeDL,\n\t\t\t\t\t\t\tq.groupByOffsetDL,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t})\n\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"invalid dimension type:%T, must be string or time.Duration\", d)\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (q *Query) IsGroupedByTime() bool {\n\treturn q.groupByTimeDL != nil\n}\n\nfunc (q *Query) AlignGroup() {\n\tq.alignGroup = true\n}\n\nfunc (q *Query) Fill(option influxql.FillOption, value interface{}) {\n\tq.stmt.Fill = option\n\tq.stmt.FillValue = value\n}\n\nfunc (q *Query) String() string {\n\treturn q.stmt.String()\n}\n\ntype TimeDimension struct {\n\tLength time.Duration\n\tOffset time.Duration\n}\n\nfunc groupByTime(length time.Duration, offset ...time.Duration) (TimeDimension, error) {\n\tvar o time.Duration\n\tif l := len(offset); l == 1 {\n\t\to = offset[0]\n\n\t} else if l != 0 {\n\t\treturn TimeDimension{}, fmt.Errorf(\"time() function expects 1 or 2 args, got %d\", l+1)\n\t}\n\treturn TimeDimension{\n\t\tLength: length,\n\t\tOffset: o,\n\t}, nil\n}\n"
        },
        {
          "name": "query_test.go",
          "type": "blob",
          "size": 4.2626953125,
          "content": "package kapacitor_test\n\nimport (\n\t\"fmt\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/influxdata/kapacitor\"\n)\n\nfunc TestQuery_Clone(t *testing.T) {\n\ttestCases := []string{\n\t\t\"SELECT usage FROM telegraf.autogen.cpu\",\n\t\t\"SELECT mean(usage) FROM telegraf.autogen.cpu WHERE host = 'serverA'\",\n\t\t\"SELECT mean(usage) FROM telegraf.autogen.cpu WHERE host = 'serverA' AND dc = 'slc'\",\n\t\t\"SELECT mean(usage) FROM telegraf.autogen.cpu WHERE host = 'serverA' AND dc = 'slc' OR product = 'login'\",\n\t\t\"SELECT mean(usage) FROM telegraf.autogen.cpu WHERE host = 'serverA' AND (dc = 'slc' OR product = 'login')\",\n\t\t\"SELECT * from (SELECT usage FROM telegraf.autogen.cpu)\",\n\t\t\"SELECT * INTO telegraf.autogen.cpu FROM (SELECT usage FROM telegraf.autogen.cpu)\",\n\t}\n\n\tequal := func(q0, q1 *kapacitor.Query) error {\n\t\tif got, exp := q0.String(), q1.String(); got != exp {\n\t\t\treturn fmt.Errorf(\"unequal query string: got %s exp %s\", got, exp)\n\t\t}\n\t\tif got, exp := q0.StartTime(), q1.StartTime(); got != exp {\n\t\t\treturn fmt.Errorf(\"unequal query start time: got %v exp %v\", got, exp)\n\t\t}\n\t\tif got, exp := q0.StopTime(), q1.StopTime(); got != exp {\n\t\t\treturn fmt.Errorf(\"unequal query stop time: got %v exp %v\", got, exp)\n\t\t}\n\t\tif got, exp := q0.IsGroupedByTime(), q1.IsGroupedByTime(); got != exp {\n\t\t\treturn fmt.Errorf(\"unequal query IsGroupedByTime: got %v exp %v\", got, exp)\n\t\t}\n\t\treturn nil\n\t}\n\tfor _, query := range testCases {\n\t\tq, err := kapacitor.NewQuery(query)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t\tclone, err := q.Clone()\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t\tif err := equal(clone, q); err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\n\t\t// Modify original start time\n\t\tstart := time.Date(1975, 1, 1, 0, 0, 0, 0, time.UTC)\n\t\tq.SetStartTime(start)\n\n\t\tif err := equal(clone, q); err == nil {\n\t\t\tt.Errorf(\"equal after modification: got %v\", clone)\n\t\t}\n\n\t\t// Modify clone in the same way\n\t\tclone.SetStartTime(start)\n\t\tif err := equal(clone, q); err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\n\t\t// Re-clone\n\t\tclone, err = q.Clone()\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t\tif err := equal(clone, q); err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\n\t\t// Modify original stop time\n\t\tstop := time.Date(1975, 1, 2, 0, 0, 0, 0, time.UTC)\n\t\tq.SetStopTime(stop)\n\n\t\tif err := equal(clone, q); err == nil {\n\t\t\tt.Errorf(\"equal after modification: got %v\", clone)\n\t\t}\n\n\t\t// Modify clone in the same way\n\t\tclone.SetStopTime(stop)\n\t\tif err := equal(clone, q); err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\n\t\t// Re-clone\n\t\tclone, err = q.Clone()\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t\tif err := equal(clone, q); err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\n\t\t// Set dimensions\n\t\tq.Dimensions([]interface{}{time.Hour})\n\t\tif err := equal(clone, q); err == nil {\n\t\t\tt.Errorf(\"equal after modification: got %v\", clone)\n\t\t}\n\t\t// Set dimesions on the clone in the same way\n\t\tclone.Dimensions([]interface{}{time.Hour})\n\t\tif err := equal(clone, q); err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\t\t// Re-clone\n\t\tclone, err = q.Clone()\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t\tif err := equal(clone, q); err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\n\t\t// Set group align and dimensions\n\t\tq.AlignGroup()\n\t\tq.Dimensions([]interface{}{kapacitor.TimeDimension{\n\t\t\tLength: time.Minute,\n\t\t\tOffset: time.Second,\n\t\t}})\n\t\tif err := equal(clone, q); err == nil {\n\t\t\tt.Errorf(\"equal after modification: got %v\", clone)\n\t\t\treturn\n\t\t}\n\t\t// Set group align and dimesions on the clone in the same way\n\t\tclone.AlignGroup()\n\t\tclone.Dimensions([]interface{}{kapacitor.TimeDimension{\n\t\t\tLength: time.Minute,\n\t\t\tOffset: time.Second,\n\t\t}})\n\t\tif err := equal(clone, q); err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\t\t// Re-clone\n\t\tclone, err = q.Clone()\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t\tif err := equal(clone, q); err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\t}\n}\n\nfunc TestQuery_IsGroupedByTime(t *testing.T) {\n\tq, err := kapacitor.NewQuery(\"SELECT usage FROM telegraf.autogen.cpu\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tq.Dimensions([]interface{}{time.Hour})\n\tif !q.IsGroupedByTime() {\n\t\tt.Error(\"expected query to be grouped by time\")\n\t}\n\n\tq, err = kapacitor.NewQuery(\"SELECT usage FROM telegraf.autogen.cpu\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tq.Dimensions([]interface{}{kapacitor.TimeDimension{Length: time.Hour, Offset: time.Minute}})\n\tif !q.IsGroupedByTime() {\n\t\tt.Error(\"expected query to be grouped by time\")\n\t}\n\n\tq.Dimensions([]interface{}{\"host\"})\n\tif q.IsGroupedByTime() {\n\t\tt.Error(\"expected query to not be grouped by time\")\n\t}\n}\n"
        },
        {
          "name": "replay.go",
          "type": "blob",
          "size": 6.7109375,
          "content": "package kapacitor\n\nimport (\n\t\"bufio\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"time\"\n\n\tdbmodels \"github.com/influxdata/influxdb/models\"\n\t\"github.com/influxdata/kapacitor/clock\"\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/models\"\n)\n\n// Replay stream data from a channel source.\nfunc ReplayStreamFromChan(clck clock.Clock, points <-chan edge.PointMessage, collector StreamCollector, recTime bool) <-chan error {\n\terrC := make(chan error, 1)\n\tgo func() {\n\t\terrC <- replayStreamFromChan(clck, points, collector, recTime)\n\t}()\n\treturn errC\n}\n\n// Replay stream data from an IO source.\nfunc ReplayStreamFromIO(clck clock.Clock, data io.ReadCloser, collector StreamCollector, recTime bool, precision string) <-chan error {\n\tallErrs := make(chan error, 2)\n\terrC := make(chan error, 1)\n\tpoints := make(chan edge.PointMessage)\n\tgo func() {\n\t\tallErrs <- replayStreamFromChan(clck, points, collector, recTime)\n\t}()\n\tgo func() {\n\t\tallErrs <- readPointsFromIO(data, points, precision)\n\t}()\n\tgo func() {\n\t\tfor i := 0; i < cap(allErrs); i++ {\n\t\t\terr := <-allErrs\n\t\t\tif err != nil {\n\t\t\t\terrC <- err\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\terrC <- nil\n\t}()\n\treturn errC\n}\n\nfunc replayStreamFromChan(clck clock.Clock, points <-chan edge.PointMessage, collector StreamCollector, recTime bool) error {\n\tdefer collector.Close()\n\tstart := time.Time{}\n\tvar diff time.Duration\n\tzero := clck.Zero()\n\tfor p := range points {\n\t\tif start.IsZero() {\n\t\t\tstart = p.Time()\n\t\t\tdiff = zero.Sub(start)\n\t\t}\n\t\twaitTime := p.Time().Add(diff).UTC()\n\t\tif !recTime {\n\t\t\tp = p.ShallowCopy()\n\t\t\tp.SetTime(waitTime)\n\t\t}\n\t\tclck.Until(waitTime)\n\t\terr := collector.CollectPoint(p)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc readPointsFromIO(data io.ReadCloser, points chan<- edge.PointMessage, precision string) error {\n\tdefer data.Close()\n\tdefer close(points)\n\n\tnow := time.Time{}\n\n\tin := bufio.NewScanner(data)\n\tfor in.Scan() {\n\t\tdb := in.Text()\n\t\tif !in.Scan() {\n\t\t\treturn fmt.Errorf(\"invalid replay file format, expected another line\")\n\t\t}\n\t\trp := in.Text()\n\t\tif !in.Scan() {\n\t\t\treturn fmt.Errorf(\"invalid replay file format, expected another line\")\n\t\t}\n\t\tmps, err := dbmodels.ParsePointsWithPrecision(\n\t\t\tin.Bytes(),\n\t\t\tnow,\n\t\t\tprecision,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tmp := mps[0]\n\n\t\tmpfields, err := mp.Fields()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tp := edge.NewPointMessage(\n\t\t\tstring(mp.Name()), //TODO(docmerlin): there has to be a better way of handling things so we don't allocate everywhere\n\t\t\tdb,\n\t\t\trp,\n\t\t\tmodels.Dimensions{},\n\t\t\tmodels.Fields(mpfields),\n\t\t\tmodels.Tags(mp.Tags().Map()),\n\t\t\tmp.Time().UTC(),\n\t\t)\n\t\tpoints <- p\n\t}\n\tif err := in.Err(); err != nil {\n\t\treturn fmt.Errorf(\"read replay file failed: %s\", err)\n\t}\n\treturn nil\n}\n\n// Replay batch data from a channel source.\nfunc ReplayBatchFromChan(clck clock.Clock, batches []<-chan edge.BufferedBatchMessage, collectors []BatchCollector, recTime bool) <-chan error {\n\terrC := make(chan error, 1)\n\tif e, g := len(batches), len(collectors); e != g {\n\t\terrC <- fmt.Errorf(\"unexpected number of batch collectors. exp %d got %d\", e, g)\n\t\treturn errC\n\t}\n\n\tallErrs := make(chan error, len(batches))\n\tfor i := range batches {\n\t\tgo func(collector BatchCollector, batches <-chan edge.BufferedBatchMessage, clck clock.Clock, recTime bool) {\n\t\t\tallErrs <- replayBatchFromChan(clck, batches, collector, recTime)\n\t\t}(collectors[i], batches[i], clck, recTime)\n\t}\n\tgo func() {\n\t\t// Wait for each one to finish and report first error if any\n\t\tfor i := 0; i < cap(allErrs); i++ {\n\t\t\terr := <-allErrs\n\t\t\tif err != nil {\n\t\t\t\terrC <- err\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\terrC <- nil\n\t}()\n\treturn errC\n\n}\n\n// Replay batch data from an IO source.\nfunc ReplayBatchFromIO(clck clock.Clock, data []io.ReadCloser, collectors []BatchCollector, recTime bool) <-chan error {\n\terrC := make(chan error, 1)\n\tif e, g := len(data), len(collectors); e != g {\n\t\terrC <- fmt.Errorf(\"unexpected number of batch collectors. exp %d got %d\", e, g)\n\t\treturn errC\n\t}\n\n\tallErrs := make(chan error, len(data)*2)\n\tfor i := range data {\n\t\tbatches := make(chan edge.BufferedBatchMessage)\n\t\tgo func(collector BatchCollector, batches <-chan edge.BufferedBatchMessage, clck clock.Clock, recTime bool) {\n\t\t\tallErrs <- replayBatchFromChan(clck, batches, collector, recTime)\n\t\t}(collectors[i], batches, clck, recTime)\n\t\tgo func(data io.ReadCloser, batches chan<- edge.BufferedBatchMessage) {\n\t\t\tallErrs <- readBatchFromIO(data, batches)\n\t\t}(data[i], batches)\n\t}\n\tgo func() {\n\t\t// Wait for each one to finish and report first error if any\n\t\tfor i := 0; i < cap(allErrs); i++ {\n\t\t\terr := <-allErrs\n\t\t\tif err != nil {\n\t\t\t\terrC <- err\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\terrC <- nil\n\t}()\n\treturn errC\n}\n\n// Replay the batch data from a single source\nfunc replayBatchFromChan(clck clock.Clock, batches <-chan edge.BufferedBatchMessage, collector BatchCollector, recTime bool) error {\n\tdefer collector.Close()\n\n\t// Find relative times\n\tvar start, tmax time.Time\n\tvar diff time.Duration\n\tzero := clck.Zero()\n\n\tfor b := range batches {\n\t\tif len(b.Points()) == 0 {\n\t\t\t// Emit empty batch\n\t\t\tif b.Begin().Time().IsZero() {\n\t\t\t\t// Set tmax to last batch if not set.\n\t\t\t\tb.Begin().SetTime(tmax)\n\t\t\t} else {\n\t\t\t\ttmax = b.Begin().Time().UTC()\n\t\t\t\tb.Begin().SetTime(tmax)\n\t\t\t}\n\t\t\tif err := collector.CollectBatch(b); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\tpoints := b.Points()\n\t\tif start.IsZero() {\n\t\t\tstart = points[0].Time()\n\t\t\tdiff = zero.Sub(start)\n\t\t}\n\t\tvar lastTime time.Time\n\t\tif !recTime {\n\t\t\tfor i := range points {\n\t\t\t\tpoints[i].SetTime(points[i].Time().Add(diff).UTC())\n\t\t\t}\n\t\t\tlastTime = points[len(points)-1].Time()\n\t\t} else {\n\t\t\tlastTime = points[len(points)-1].Time().Add(diff).UTC()\n\t\t}\n\t\tclck.Until(lastTime)\n\t\tif lpt := points[len(points)-1].Time(); b.Begin().Time().Before(lpt) {\n\t\t\tb.Begin().SetTime(lpt)\n\t\t}\n\t\ttmax = b.Begin().Time().UTC()\n\t\tb.Begin().SetTime(tmax)\n\t\tif err := collector.CollectBatch(b); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// Replay the batch data from a single source\nfunc readBatchFromIO(data io.ReadCloser, batches chan<- edge.BufferedBatchMessage) error {\n\tdefer close(batches)\n\tdefer data.Close()\n\tdec := edge.NewBufferedBatchMessageDecoder(data)\n\tfor dec.More() {\n\t\tb, err := dec.Decode()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif len(b.Points()) == 0 {\n\t\t\t// do nothing\n\t\t\tcontinue\n\t\t}\n\t\tbatches <- b\n\t}\n\treturn nil\n}\n\nfunc WritePointForRecording(w io.Writer, p edge.PointMessage, precision string) error {\n\tif _, err := fmt.Fprintf(w, \"%s\\n%s\\n\", p.Database(), p.RetentionPolicy()); err != nil {\n\t\treturn err\n\t}\n\tif _, err := w.Write(p.Bytes(precision)); err != nil {\n\t\treturn err\n\t}\n\tif _, err := w.Write([]byte(\"\\n\")); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc WriteBatchForRecording(w io.Writer, b edge.BufferedBatchMessage) error {\n\tenc := json.NewEncoder(w)\n\terr := enc.Encode(b)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n"
        },
        {
          "name": "result.go",
          "type": "blob",
          "size": 0.77734375,
          "content": "package kapacitor\n\nimport (\n\t\"encoding/json\"\n\t\"io\"\n\t\"time\"\n\n\t\"github.com/influxdata/influxdb/query\"\n)\n\n// The result from an output.\ntype Result query.Result\n\n// Unmarshal a Result object from JSON.\nfunc ResultFromJSON(in io.Reader) (r Result) {\n\tb, err := io.ReadAll(in)\n\tif err != nil {\n\t\tr.Err = err\n\t\treturn\n\t}\n\n\t_ = json.Unmarshal(b, &r)\n\t// Convert all times to time.Time\n\tConvertResultTimes(&r)\n\treturn\n}\n\nfunc ConvertResultTimes(r *Result) {\n\tfor _, series := range r.Series {\n\t\tfor i, v := range series.Values {\n\t\t\tfor j, c := range series.Columns {\n\t\t\t\tif c == \"time\" {\n\t\t\t\t\ttStr, ok := v[j].(string)\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tt, err := time.Parse(time.RFC3339, tStr)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tseries.Values[i][j] = t\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "sample.go",
          "type": "blob",
          "size": 2.3037109375,
          "content": "package kapacitor\n\nimport (\n\t\"errors\"\n\t\"time\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n)\n\ntype SampleNode struct {\n\tnode\n\ts *pipeline.SampleNode\n\n\tcounts   map[models.GroupID]int64\n\tduration time.Duration\n}\n\n// Create a new  SampleNode which filters data from a source.\nfunc newSampleNode(et *ExecutingTask, n *pipeline.SampleNode, d NodeDiagnostic) (*SampleNode, error) {\n\tsn := &SampleNode{\n\t\tnode:     node{Node: n, et: et, diag: d},\n\t\ts:        n,\n\t\tcounts:   make(map[models.GroupID]int64),\n\t\tduration: n.Duration,\n\t}\n\tsn.node.runF = sn.runSample\n\tif n.Duration == 0 && n.N == 0 {\n\t\treturn nil, errors.New(\"invalid sample rate: must be positive integer or duration\")\n\t}\n\treturn sn, nil\n}\n\nfunc (n *SampleNode) runSample([]byte) error {\n\tconsumer := edge.NewGroupedConsumer(\n\t\tn.ins[0],\n\t\tn,\n\t)\n\tn.statMap.Set(statCardinalityGauge, consumer.CardinalityVar())\n\treturn consumer.Consume()\n}\n\nfunc (n *SampleNode) NewGroup(group edge.GroupInfo, first edge.PointMeta) (edge.Receiver, error) {\n\treturn edge.NewReceiverFromForwardReceiverWithStats(\n\t\tn.outs,\n\t\tedge.NewTimedForwardReceiver(n.timer, n.newGroup()),\n\t), nil\n}\nfunc (n *SampleNode) newGroup() *sampleGroup {\n\treturn &sampleGroup{\n\t\tn: n,\n\t}\n}\n\ntype sampleGroup struct {\n\tn *SampleNode\n\n\tcount int64\n}\n\nfunc (g *sampleGroup) BeginBatch(begin edge.BeginBatchMessage) (edge.Message, error) {\n\tg.count = 0\n\treturn begin, nil\n}\n\nfunc (g *sampleGroup) BatchPoint(bp edge.BatchPointMessage) (edge.Message, error) {\n\tkeep := g.n.shouldKeep(g.count, bp.Time())\n\tg.count++\n\tif keep {\n\t\treturn bp, nil\n\t}\n\treturn nil, nil\n}\n\nfunc (g *sampleGroup) EndBatch(end edge.EndBatchMessage) (edge.Message, error) {\n\treturn end, nil\n}\n\nfunc (g *sampleGroup) Point(p edge.PointMessage) (edge.Message, error) {\n\tkeep := g.n.shouldKeep(g.count, p.Time())\n\tg.count++\n\tif keep {\n\t\treturn p, nil\n\t}\n\treturn nil, nil\n}\n\nfunc (g *sampleGroup) Barrier(b edge.BarrierMessage) (edge.Message, error) {\n\treturn b, nil\n}\nfunc (g *sampleGroup) DeleteGroup(d edge.DeleteGroupMessage) (edge.Message, error) {\n\treturn d, nil\n}\nfunc (g *sampleGroup) Done() {}\n\nfunc (n *SampleNode) shouldKeep(count int64, t time.Time) bool {\n\tif n.duration != 0 {\n\t\tkeepTime := t.Truncate(n.duration)\n\t\treturn t.Equal(keepTime)\n\t} else {\n\t\treturn count%n.s.N == 0\n\t}\n}\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "server",
          "type": "tree",
          "content": null
        },
        {
          "name": "services",
          "type": "tree",
          "content": null
        },
        {
          "name": "shift.go",
          "type": "blob",
          "size": 1.6435546875,
          "content": "package kapacitor\n\nimport (\n\t\"errors\"\n\t\"time\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n)\n\ntype ShiftNode struct {\n\tnode\n\ts *pipeline.ShiftNode\n\n\tshift time.Duration\n}\n\n// Create a new  ShiftNode which shifts points and batches in time.\nfunc newShiftNode(et *ExecutingTask, n *pipeline.ShiftNode, d NodeDiagnostic) (*ShiftNode, error) {\n\tsn := &ShiftNode{\n\t\tnode:  node{Node: n, et: et, diag: d},\n\t\ts:     n,\n\t\tshift: n.Shift,\n\t}\n\tsn.node.runF = sn.runShift\n\tif n.Shift == 0 {\n\t\treturn nil, errors.New(\"invalid shift value: must be non zero duration\")\n\t}\n\treturn sn, nil\n}\n\nfunc (n *ShiftNode) runShift([]byte) error {\n\tconsumer := edge.NewConsumerWithReceiver(\n\t\tn.ins[0],\n\t\tedge.NewReceiverFromForwardReceiverWithStats(\n\t\t\tn.outs,\n\t\t\tedge.NewTimedForwardReceiver(n.timer, n),\n\t\t),\n\t)\n\treturn consumer.Consume()\n}\n\nfunc (n *ShiftNode) doShift(t edge.TimeSetter) {\n\tt.SetTime(t.Time().Add(n.shift))\n}\n\nfunc (n *ShiftNode) BeginBatch(begin edge.BeginBatchMessage) (edge.Message, error) {\n\tbegin = begin.ShallowCopy()\n\tn.doShift(begin)\n\treturn begin, nil\n}\n\nfunc (n *ShiftNode) BatchPoint(bp edge.BatchPointMessage) (edge.Message, error) {\n\tbp = bp.ShallowCopy()\n\tn.doShift(bp)\n\treturn bp, nil\n}\n\nfunc (n *ShiftNode) EndBatch(end edge.EndBatchMessage) (edge.Message, error) {\n\treturn end, nil\n}\n\nfunc (n *ShiftNode) Point(p edge.PointMessage) (edge.Message, error) {\n\tp = p.ShallowCopy()\n\tn.doShift(p)\n\treturn p, nil\n}\n\nfunc (n *ShiftNode) Barrier(b edge.BarrierMessage) (edge.Message, error) {\n\treturn b, nil\n}\nfunc (n *ShiftNode) DeleteGroup(d edge.DeleteGroupMessage) (edge.Message, error) {\n\treturn d, nil\n}\nfunc (n *ShiftNode) Done() {}\n"
        },
        {
          "name": "sideload.go",
          "type": "blob",
          "size": 5.8359375,
          "content": "package kapacitor\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"net/url\"\n\t\"strconv\"\n\ttext \"text/template\"\n\n\t\"github.com/influxdata/kapacitor/bufpool\"\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/keyvalue\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n\t\"github.com/influxdata/kapacitor/services/httppost\"\n\t\"github.com/influxdata/kapacitor/services/sideload\"\n\t\"github.com/pkg/errors\"\n)\n\ntype SideloadNode struct {\n\tnode\n\ts          *pipeline.SideloadNode\n\tsource     sideload.Source\n\torderTmpls []orderTmpl\n\tEndpoint   *httppost.Endpoint\n\torder      []string\n\tbufferPool *bufpool.Pool\n}\n\n// Create a new SideloadNode which loads fields and tags from external sources.\nfunc newSideloadNode(et *ExecutingTask, n *pipeline.SideloadNode, d NodeDiagnostic) (*SideloadNode, error) {\n\tvar e *httppost.Endpoint\n\tvar ok bool\n\tsn := &SideloadNode{\n\t\tnode:       node{Node: n, et: et, diag: d},\n\t\ts:          n,\n\t\tbufferPool: bufpool.New(),\n\t\torder:      make([]string, len(n.OrderList)),\n\t\torderTmpls: make([]orderTmpl, len(n.OrderList)),\n\t}\n\tu, err := url.Parse(n.Source)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tif u.Scheme == \"\" {\n\t\te, ok = et.tm.HTTPPostService.Endpoint(n.Source)\n\t\tif !ok {\n\t\t\tlog.Fatal(\"Specified endpoint does not exist: \" + n.Source)\n\t\t}\n\t} else {\n\t\tconf := httppost.Config{URLTemplate: n.Source}\n\t\te = &httppost.Endpoint{}\n\t\tif err := e.Update(conf); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tsn.Endpoint = e\n\tsrc, err := et.tm.SideloadService.Source(e)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsn.source = src\n\n\tfor i, o := range n.OrderList {\n\t\top, err := newOrderTmpl(o, sn.bufferPool)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tsn.orderTmpls[i] = op\n\t}\n\tsn.node.runF = sn.runSideload\n\tsn.node.stopF = sn.stopSideload\n\treturn sn, nil\n}\n\nfunc (n *SideloadNode) runSideload([]byte) error {\n\tconsumer := edge.NewConsumerWithReceiver(\n\t\tn.ins[0],\n\t\tedge.NewReceiverFromForwardReceiverWithStats(\n\t\t\tn.outs,\n\t\t\tedge.NewTimedForwardReceiver(n.timer, n),\n\t\t),\n\t)\n\treturn consumer.Consume()\n}\nfunc (n *SideloadNode) stopSideload() {\n\tn.source.Close()\n}\n\ntype orderTmpl struct {\n\traw        string\n\ttmpl       *text.Template\n\tbufferPool *bufpool.Pool\n}\n\nfunc newOrderTmpl(tmpl string, bp *bufpool.Pool) (orderTmpl, error) {\n\tt, err := text.New(\"order\").Parse(tmpl)\n\tif err != nil {\n\t\treturn orderTmpl{}, err\n\t}\n\treturn orderTmpl{\n\t\traw:        tmpl,\n\t\ttmpl:       t,\n\t\tbufferPool: bp,\n\t}, nil\n}\n\nfunc (t orderTmpl) Path(tags models.Tags) (string, error) {\n\tbuf := t.bufferPool.Get()\n\tdefer t.bufferPool.Put(buf)\n\terr := t.tmpl.Execute(buf, tags)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn buf.String(), nil\n}\n\nfunc (n *SideloadNode) doSideload(p edge.FieldsTagsTimeSetter) {\n\tfor i, o := range n.orderTmpls {\n\t\tp, err := o.Path(p.Tags())\n\t\tif err != nil {\n\t\t\tn.diag.Error(\"failed to evaluate order template\", err, keyvalue.KV(\"order\", o.raw))\n\t\t\treturn\n\t\t}\n\t\tn.order[i] = p\n\t}\n\tif len(n.s.Fields) > 0 {\n\t\tfields := p.Fields().Copy()\n\t\tfor key, dflt := range n.s.Fields {\n\t\t\tvalue := n.source.Lookup(n.order, key)\n\t\t\tif value == nil {\n\t\t\t\t// Use default\n\t\t\t\tfields[key] = dflt\n\t\t\t} else {\n\t\t\t\tv, err := convertType(value, dflt)\n\t\t\t\tif err != nil {\n\t\t\t\t\tn.diag.Error(\"failed to load key\", err, keyvalue.KV(\"key\", key), keyvalue.KV(\"expected\", fmt.Sprintf(\"%T\", dflt)), keyvalue.KV(\"got\", fmt.Sprintf(\"%T\", value)))\n\t\t\t\t\tfields[key] = dflt\n\t\t\t\t} else {\n\t\t\t\t\tfields[key] = v\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tp.SetFields(fields)\n\t}\n\tif len(n.s.Tags) > 0 {\n\t\ttags := p.Tags().Copy()\n\t\tfor key, dflt := range n.s.Tags {\n\t\t\tvalue := n.source.Lookup(n.order, key)\n\t\t\tif value == nil {\n\t\t\t\ttags[key] = dflt\n\t\t\t} else {\n\t\t\t\tv, err := convertType(value, dflt)\n\t\t\t\tif err != nil {\n\t\t\t\t\tn.diag.Error(\"failed to load key\", err, keyvalue.KV(\"key\", key), keyvalue.KV(\"expected\", \"string\"), keyvalue.KV(\"got\", fmt.Sprintf(\"%T\", value)))\n\t\t\t\t\ttags[key] = dflt\n\t\t\t\t} else {\n\t\t\t\t\ttags[key] = v.(string)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tp.SetTags(tags)\n\t}\n}\n\nfunc (n *SideloadNode) BeginBatch(begin edge.BeginBatchMessage) (edge.Message, error) {\n\tbegin = begin.ShallowCopy()\n\treturn begin, nil\n}\n\nfunc (n *SideloadNode) BatchPoint(bp edge.BatchPointMessage) (edge.Message, error) {\n\tbp = bp.ShallowCopy()\n\tn.doSideload(bp)\n\treturn bp, nil\n}\n\nfunc (n *SideloadNode) EndBatch(end edge.EndBatchMessage) (edge.Message, error) {\n\treturn end, nil\n}\n\nfunc (n *SideloadNode) Point(p edge.PointMessage) (edge.Message, error) {\n\tp = p.ShallowCopy()\n\tn.doSideload(p)\n\treturn p, nil\n}\n\nfunc (n *SideloadNode) Barrier(b edge.BarrierMessage) (edge.Message, error) {\n\treturn b, nil\n}\nfunc (n *SideloadNode) DeleteGroup(d edge.DeleteGroupMessage) (edge.Message, error) {\n\treturn d, nil\n}\nfunc (n *SideloadNode) Done() {}\n\nfunc convertType(src, dflt interface{}) (interface{}, error) {\n\tswitch dflt.(type) {\n\tcase int64:\n\t\tswitch src := src.(type) {\n\t\tcase int64:\n\t\t\treturn src, nil\n\t\tcase float64:\n\t\t\ti := int64(src)\n\t\t\tif float64(i) == src {\n\t\t\t\treturn i, nil\n\t\t\t}\n\t\tcase string:\n\t\t\ti, err := strconv.Atoi(src)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, errors.Wrap(err, \"cannot convert string to int64\")\n\t\t\t}\n\t\t\treturn i, nil\n\t\t}\n\tcase float64:\n\t\tswitch src := src.(type) {\n\t\tcase int64:\n\t\t\treturn float64(src), nil\n\t\tcase float64:\n\t\t\treturn src, nil\n\t\tcase string:\n\t\t\tf, err := strconv.ParseFloat(src, 64)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, errors.Wrap(err, \"cannot convert string to float64\")\n\t\t\t}\n\t\t\treturn f, nil\n\t\t}\n\tcase bool:\n\t\tswitch src := src.(type) {\n\t\tcase bool:\n\t\t\treturn src, nil\n\t\tcase string:\n\t\t\tb, err := strconv.ParseBool(src)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, errors.Wrap(err, \"cannot convert string to bool\")\n\t\t\t}\n\t\t\treturn b, nil\n\t\t}\n\tcase string:\n\t\tswitch src := src.(type) {\n\t\tcase int64:\n\t\t\treturn strconv.FormatInt(src, 10), nil\n\t\tcase float64:\n\t\t\treturn strconv.FormatFloat(src, 'f', -1, 64), nil\n\t\tcase bool:\n\t\t\treturn strconv.FormatBool(src), nil\n\t\tcase string:\n\t\t\treturn src, nil\n\t\t}\n\t}\n\treturn nil, fmt.Errorf(\"cannot convert value of type %T to type %T\", src, dflt)\n}\n"
        },
        {
          "name": "state_tracking.go",
          "type": "blob",
          "size": 4.421875,
          "content": "package kapacitor\n\nimport (\n\t\"fmt\"\n\t\"time\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n\t\"github.com/influxdata/kapacitor/tick/ast\"\n\t\"github.com/influxdata/kapacitor/tick/stateful\"\n)\n\ntype stateTracker interface {\n\ttrack(t time.Time, inState bool) interface{}\n\treset()\n}\n\ntype stateTrackingGroup struct {\n\tn *StateTrackingNode\n\tstateful.Expression\n\ttracker stateTracker\n}\n\ntype StateTrackingNode struct {\n\tnode\n\tas string\n\n\texpr      stateful.Expression\n\tscopePool stateful.ScopePool\n\n\tnewTracker func() stateTracker\n}\n\nfunc (n *StateTrackingNode) runStateTracking(_ []byte) error {\n\tconsumer := edge.NewGroupedConsumer(\n\t\tn.ins[0],\n\t\tn,\n\t)\n\tn.statMap.Set(statCardinalityGauge, consumer.CardinalityVar())\n\treturn consumer.Consume()\n}\n\nfunc (n *StateTrackingNode) NewGroup(group edge.GroupInfo, first edge.PointMeta) (edge.Receiver, error) {\n\treturn edge.NewReceiverFromForwardReceiverWithStats(\n\t\tn.outs,\n\t\tedge.NewTimedForwardReceiver(n.timer, n.newGroup()),\n\t), nil\n}\n\nfunc (n *StateTrackingNode) newGroup() *stateTrackingGroup {\n\t// Create a new tracking group\n\tg := &stateTrackingGroup{\n\t\tn: n,\n\t}\n\n\tg.Expression = n.expr.CopyReset()\n\n\tg.tracker = n.newTracker()\n\treturn g\n}\n\nfunc (g *stateTrackingGroup) BeginBatch(begin edge.BeginBatchMessage) (edge.Message, error) {\n\tg.tracker.reset()\n\treturn begin, nil\n}\n\nfunc (g *stateTrackingGroup) BatchPoint(bp edge.BatchPointMessage) (edge.Message, error) {\n\tbp = bp.ShallowCopy()\n\terr := g.track(bp)\n\tif err != nil {\n\t\tg.n.diag.Error(\"error while evaluating expression\", err)\n\t\treturn nil, nil\n\t}\n\treturn bp, nil\n}\n\nfunc (g *stateTrackingGroup) EndBatch(end edge.EndBatchMessage) (edge.Message, error) {\n\treturn end, nil\n}\n\nfunc (g *stateTrackingGroup) Point(p edge.PointMessage) (edge.Message, error) {\n\tp = p.ShallowCopy()\n\terr := g.track(p)\n\tif err != nil {\n\t\tg.n.diag.Error(\"error while evaluating expression\", err)\n\t\treturn nil, nil\n\t}\n\treturn p, nil\n}\n\nfunc (g *stateTrackingGroup) track(p edge.FieldsTagsTimeSetter) error {\n\tpass, err := EvalPredicate(g.Expression, g.n.scopePool, p)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfields := p.Fields().Copy()\n\tfields[g.n.as] = g.tracker.track(p.Time(), pass)\n\tp.SetFields(fields)\n\treturn nil\n}\n\nfunc (g *stateTrackingGroup) Barrier(b edge.BarrierMessage) (edge.Message, error) {\n\treturn b, nil\n}\nfunc (g *stateTrackingGroup) DeleteGroup(d edge.DeleteGroupMessage) (edge.Message, error) {\n\treturn d, nil\n}\nfunc (g *stateTrackingGroup) Done() {}\n\ntype stateDurationTracker struct {\n\tsd *pipeline.StateDurationNode\n\n\tstartTime time.Time\n}\n\nfunc (sdt *stateDurationTracker) reset() {\n\tsdt.startTime = time.Time{}\n}\n\nfunc (sdt *stateDurationTracker) track(t time.Time, inState bool) interface{} {\n\tif !inState {\n\t\tsdt.startTime = time.Time{}\n\t\treturn float64(-1)\n\t}\n\n\tif sdt.startTime.IsZero() {\n\t\tsdt.startTime = t\n\t}\n\treturn float64(t.Sub(sdt.startTime)) / float64(sdt.sd.Unit)\n}\n\nfunc newStateDurationNode(et *ExecutingTask, sd *pipeline.StateDurationNode, d NodeDiagnostic) (*StateTrackingNode, error) {\n\tif sd.Lambda == nil {\n\t\treturn nil, fmt.Errorf(\"nil expression passed to StateDurationNode\")\n\t}\n\t// Validate lambda expression\n\texpr, err := stateful.NewExpression(sd.Lambda.Expression)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tn := &StateTrackingNode{\n\t\tnode:       node{Node: sd, et: et, diag: d},\n\t\tas:         sd.As,\n\t\tnewTracker: func() stateTracker { return &stateDurationTracker{sd: sd} },\n\t\texpr:       expr,\n\t\tscopePool:  stateful.NewScopePool(ast.FindReferenceVariables(sd.Lambda.Expression)),\n\t}\n\tn.node.runF = n.runStateTracking\n\treturn n, nil\n}\n\ntype stateCountTracker struct {\n\tcount int64\n}\n\nfunc (sct *stateCountTracker) reset() {\n\tsct.count = 0\n}\n\nfunc (sct *stateCountTracker) track(t time.Time, inState bool) interface{} {\n\tif !inState {\n\t\tsct.count = 0\n\t\treturn int64(-1)\n\t}\n\n\tsct.count++\n\treturn sct.count\n}\n\nfunc newStateCountNode(et *ExecutingTask, sc *pipeline.StateCountNode, d NodeDiagnostic) (*StateTrackingNode, error) {\n\tif sc.Lambda == nil {\n\t\treturn nil, fmt.Errorf(\"nil expression passed to StateCountNode\")\n\t}\n\t// Validate lambda expression\n\texpr, err := stateful.NewExpression(sc.Lambda.Expression)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tn := &StateTrackingNode{\n\t\tnode:       node{Node: sc, et: et, diag: d},\n\t\tas:         sc.As,\n\t\tnewTracker: func() stateTracker { return &stateCountTracker{} },\n\t\texpr:       expr,\n\t\tscopePool:  stateful.NewScopePool(ast.FindReferenceVariables(sc.Lambda.Expression)),\n\t}\n\tn.node.runF = n.runStateTracking\n\treturn n, nil\n}\n"
        },
        {
          "name": "staticcheck.conf",
          "type": "blob",
          "size": 0.0927734375,
          "content": "checks = [\"all\", \"-ST1000\", \"-ST1003\", \"-ST1005\" ,\"-ST1016\", \"-ST1020\", \"-ST1021\", \"-ST1022\"]\n\n"
        },
        {
          "name": "stats.go",
          "type": "blob",
          "size": 2.4326171875,
          "content": "package kapacitor\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n)\n\ntype StatsNode struct {\n\tnode\n\ts       *pipeline.StatsNode\n\ten      Node\n\tclosing chan struct{}\n\tclosed  bool\n\tmu      sync.Mutex\n}\n\n// Create a new  FromNode which filters data from a source.\nfunc newStatsNode(et *ExecutingTask, n *pipeline.StatsNode, d NodeDiagnostic) (*StatsNode, error) {\n\t// Lookup the executing node for stats.\n\ten := et.lookup[n.SourceNode.ID()]\n\tif en == nil {\n\t\treturn nil, fmt.Errorf(\"no node found for %s\", n.SourceNode.Name())\n\t}\n\n\tif n.Interval <= 0 {\n\t\treturn nil, errors.New(\"stats node must have positive interval\")\n\t}\n\n\tsn := &StatsNode{\n\t\tnode:    node{Node: n, et: et, diag: d},\n\t\ts:       n,\n\t\ten:      en,\n\t\tclosing: make(chan struct{}),\n\t}\n\tsn.node.runF = sn.runStats\n\tsn.node.stopF = sn.stopStats\n\treturn sn, nil\n}\n\nfunc (n *StatsNode) runStats([]byte) error {\n\tif n.s.AlignFlag {\n\t\t// Wait till we are roughly aligned with the interval.\n\t\tnow := time.Now()\n\t\tnext := now.Truncate(n.s.Interval).Add(n.s.Interval)\n\t\tdur := next.Sub(now)\n\t\tif dur <= 0 { // this can happen during a time-changeover like a leap second, or if something is messing about with the system\n\t\t\treturn errors.New(\"alignment interval should be positive but was not\")\n\t\t}\n\t\tafter := time.NewTicker(dur)\n\t\tselect {\n\t\tcase <-after.C:\n\t\t\tafter.Stop()\n\t\tcase <-n.closing:\n\t\t\tafter.Stop()\n\t\t\treturn nil\n\t\t}\n\t\tif err := n.emit(now); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tif n.s.Interval <= 0 {\n\t\treturn errors.New(\"stats interval should be positive but was not\")\n\t}\n\tticker := time.NewTicker(n.s.Interval)\n\tdefer ticker.Stop()\n\tfor {\n\t\tselect {\n\t\tcase <-n.closing:\n\t\t\treturn nil\n\t\tcase now := <-ticker.C:\n\t\t\tif err := n.emit(now); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n}\n\n// Emit a set of stats data points.\nfunc (n *StatsNode) emit(now time.Time) error {\n\tn.timer.Start()\n\tdefer n.timer.Stop()\n\n\tname := \"stats\"\n\tt := now.UTC()\n\tif n.s.AlignFlag {\n\t\tt = t.Round(n.s.Interval)\n\t}\n\tstats := n.en.nodeStatsByGroup()\n\tfor _, stat := range stats {\n\t\tpoint := edge.NewPointMessage(\n\t\t\tname, \"\", \"\",\n\t\t\tstat.Dimensions,\n\t\t\tstat.Fields,\n\t\t\tstat.Tags,\n\t\t\tt,\n\t\t)\n\t\tn.timer.Pause()\n\t\tfor _, out := range n.outs {\n\t\t\terr := out.Collect(point)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tn.timer.Resume()\n\t}\n\treturn nil\n}\n\nfunc (n *StatsNode) stopStats() {\n\tn.mu.Lock()\n\tdefer n.mu.Unlock()\n\tif !n.closed {\n\t\tn.closed = true\n\t\tclose(n.closing)\n\t}\n}\n"
        },
        {
          "name": "stream.go",
          "type": "blob",
          "size": 3.5146484375,
          "content": "package kapacitor\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n\t\"github.com/influxdata/kapacitor/tick/ast\"\n\t\"github.com/influxdata/kapacitor/tick/stateful\"\n)\n\ntype StreamNode struct {\n\tnode\n\ts *pipeline.StreamNode\n}\n\n// Create a new  StreamNode which copies all data to children\nfunc newStreamNode(et *ExecutingTask, n *pipeline.StreamNode, d NodeDiagnostic) (*StreamNode, error) {\n\tsn := &StreamNode{\n\t\tnode: node{Node: n, et: et, diag: d},\n\t\ts:    n,\n\t}\n\tsn.node.runF = sn.runSourceStream\n\treturn sn, nil\n}\n\nfunc (n *StreamNode) runSourceStream([]byte) error {\n\tfor m, ok := n.ins[0].Emit(); ok; m, ok = n.ins[0].Emit() {\n\t\tfor _, child := range n.outs {\n\t\t\terr := child.Collect(m)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}\n\ntype FromNode struct {\n\tnode\n\ts             *pipeline.FromNode\n\texpression    stateful.Expression\n\tscopePool     stateful.ScopePool\n\ttagNames      []string\n\tallDimensions bool\n\tdb            string\n\trp            string\n\tname          string\n}\n\n// Create a new  FromNode which filters data from a source.\nfunc newFromNode(et *ExecutingTask, n *pipeline.FromNode, d NodeDiagnostic) (*FromNode, error) {\n\tsn := &FromNode{\n\t\tnode: node{Node: n, et: et, diag: d},\n\t\ts:    n,\n\t\tdb:   n.Database,\n\t\trp:   n.RetentionPolicy,\n\t\tname: n.Measurement,\n\t}\n\tsn.node.runF = sn.runStream\n\tsn.allDimensions, sn.tagNames = determineTagNames(n.Dimensions, nil)\n\n\tif n.Lambda != nil {\n\t\texpr, err := stateful.NewExpression(n.Lambda.Expression)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"Failed to compile from expression: %v\", err)\n\t\t}\n\n\t\tsn.expression = expr\n\t\tsn.scopePool = stateful.NewScopePool(ast.FindReferenceVariables(n.Lambda.Expression))\n\t}\n\n\treturn sn, nil\n}\n\nfunc (n *FromNode) runStream([]byte) error {\n\tconsumer := edge.NewConsumerWithReceiver(\n\t\tn.ins[0],\n\t\tedge.NewReceiverFromForwardReceiverWithStats(\n\t\t\tn.outs,\n\t\t\tedge.NewTimedForwardReceiver(n.timer, n),\n\t\t),\n\t)\n\treturn consumer.Consume()\n}\nfunc (n *FromNode) BeginBatch(edge.BeginBatchMessage) (edge.Message, error) {\n\treturn nil, errors.New(\"from does not support batch data\")\n}\nfunc (n *FromNode) BatchPoint(edge.BatchPointMessage) (edge.Message, error) {\n\treturn nil, errors.New(\"from does not support batch data\")\n}\nfunc (n *FromNode) EndBatch(edge.EndBatchMessage) (edge.Message, error) {\n\treturn nil, errors.New(\"from does not support batch data\")\n}\n\nfunc (n *FromNode) Point(p edge.PointMessage) (edge.Message, error) {\n\tif n.matches(p) {\n\t\tp = p.ShallowCopy()\n\t\tif n.s.Truncate != 0 {\n\t\t\tp.SetTime(p.Time().Truncate(n.s.Truncate))\n\t\t}\n\t\tif n.s.Round != 0 {\n\t\t\tp.SetTime(p.Time().Round(n.s.Round))\n\t\t}\n\t\tp.SetDimensions(models.Dimensions{\n\t\t\tByName:   n.s.GroupByMeasurementFlag,\n\t\t\tTagNames: computeTagNames(p.Tags(), n.allDimensions, n.tagNames, nil),\n\t\t})\n\t\treturn p, nil\n\t}\n\treturn nil, nil\n}\n\nfunc (n *FromNode) Barrier(b edge.BarrierMessage) (edge.Message, error) {\n\treturn b, nil\n}\nfunc (n *FromNode) DeleteGroup(d edge.DeleteGroupMessage) (edge.Message, error) {\n\treturn d, nil\n}\nfunc (n *FromNode) Done() {}\n\nfunc (n *FromNode) matches(p edge.PointMessage) bool {\n\tif n.db != \"\" && p.Database() != n.db {\n\t\treturn false\n\t}\n\tif n.rp != \"\" && p.RetentionPolicy() != n.rp {\n\t\treturn false\n\t}\n\tif n.name != \"\" && p.Name() != n.name {\n\t\treturn false\n\t}\n\tif n.expression != nil {\n\t\tif pass, err := EvalPredicate(n.expression, n.scopePool, p); err != nil {\n\t\t\tn.diag.Error(\"failed to evaluate WHERE expression\", err)\n\t\t\treturn false\n\t\t} else {\n\t\t\treturn pass\n\t\t}\n\t}\n\treturn true\n}\n"
        },
        {
          "name": "task.go",
          "type": "blob",
          "size": 12.796875,
          "content": "package kapacitor\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math/rand\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/keyvalue\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n)\n\ntype TaskDiagnostic interface {\n\tWithNodeContext(node string) NodeDiagnostic\n\n\tError(msg string, err error, ctx ...keyvalue.T)\n}\n\n// The type of a task\ntype TaskType int\n\nconst (\n\tStreamTask TaskType = iota\n\tBatchTask\n\tInvalidTask\n)\n\nfunc (t TaskType) String() string {\n\tswitch t {\n\tcase StreamTask:\n\t\treturn \"stream\"\n\tcase BatchTask:\n\t\treturn \"batch\"\n\tdefault:\n\t\treturn \"unknown\"\n\t}\n}\n\nfunc (t TaskType) MarshalText() ([]byte, error) {\n\treturn []byte(t.String()), nil\n}\n\nfunc (t *TaskType) UnmarshalText(text []byte) error {\n\tswitch string(text) {\n\tcase \"stream\":\n\t\t*t = StreamTask\n\tcase \"batch\":\n\t\t*t = BatchTask\n\tdefault:\n\t\treturn fmt.Errorf(\"unknown task type %s\", string(text))\n\t}\n\treturn nil\n}\n\ntype DBRP struct {\n\tDatabase        string `json:\"db\"`\n\tRetentionPolicy string `json:\"rp\"`\n}\n\nfunc CreateDBRPMap(dbrps []DBRP) map[DBRP]bool {\n\tdbMap := make(map[DBRP]bool, len(dbrps))\n\tfor _, dbrp := range dbrps {\n\t\tdbMap[dbrp] = true\n\t}\n\treturn dbMap\n}\n\nfunc (d DBRP) String() string {\n\treturn fmt.Sprintf(\"%q.%q\", d.Database, d.RetentionPolicy)\n}\n\n// The complete definition of a task, its id, pipeline and type.\ntype Task struct {\n\tID               string\n\tPipeline         *pipeline.Pipeline\n\tType             TaskType\n\tDBRPs            []DBRP\n\tSnapshotInterval time.Duration\n}\n\nfunc (t *Task) Dot() []byte {\n\treturn t.Pipeline.Dot(t.ID)\n}\n\n// returns all the measurements from a FromNode\nfunc (t *Task) Measurements() []string {\n\tmeasurements := make([]string, 0)\n\n\t_ = t.Pipeline.Walk(func(node pipeline.Node) error {\n\t\tswitch streamNode := node.(type) {\n\t\tcase *pipeline.FromNode:\n\t\t\tmeasurements = append(measurements, streamNode.Measurement)\n\t\t}\n\t\treturn nil\n\t})\n\n\treturn measurements\n}\n\n// ----------------------------------\n// ExecutingTask\n\n// A task that is ready for execution.\ntype ExecutingTask struct {\n\ttm      *TaskMaster\n\tTask    *Task\n\tsource  Node\n\toutputs map[string]Output\n\t// node lookup from pipeline.ID -> Node\n\tlookup   map[pipeline.ID]Node\n\tnodes    []Node\n\tstopping chan struct{}\n\twg       sync.WaitGroup\n\tdiag     TaskDiagnostic\n\n\t// Mutex for throughput var\n\ttmu        sync.RWMutex\n\tthroughput float64\n}\n\n// Create a new  task from a defined kapacitor.\nfunc NewExecutingTask(tm *TaskMaster, t *Task) (*ExecutingTask, error) {\n\td := tm.diag.WithTaskContext(t.ID)\n\tet := &ExecutingTask{\n\t\ttm:      tm,\n\t\tTask:    t,\n\t\toutputs: make(map[string]Output),\n\t\tlookup:  make(map[pipeline.ID]Node),\n\t\tdiag:    d,\n\t}\n\terr := et.link()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn et, nil\n}\n\n// walks the entire pipeline applying function f.\nfunc (et *ExecutingTask) walk(f func(n Node) error) error {\n\tfor _, n := range et.nodes {\n\t\terr := f(n)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// walks the entire pipeline in reverse order applying function f.\nfunc (et *ExecutingTask) rwalk(f func(n Node) error) error {\n\tfor i := len(et.nodes) - 1; i >= 0; i-- {\n\t\terr := f(et.nodes[i])\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// Link all the nodes together based on the task pipeline.\nfunc (et *ExecutingTask) link() error {\n\n\t// Walk Pipeline and create equivalent executing nodes\n\terr := et.Task.Pipeline.Walk(func(n pipeline.Node) error {\n\t\td := et.diag.WithNodeContext(n.Name())\n\t\ten, err := et.createNode(n, d)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tet.lookup[n.ID()] = en\n\t\t// Save the walk order\n\t\tet.nodes = append(et.nodes, en)\n\t\t// Duplicate the Edges\n\t\tfor _, p := range n.Parents() {\n\t\t\tep := et.lookup[p.ID()]\n\t\t\terr := ep.linkChild(en)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn err\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// The first node is always the source node\n\tet.source = et.nodes[0]\n\treturn nil\n}\n\n// Start the task.\nfunc (et *ExecutingTask) start(ins []edge.StatsEdge, snapshot *TaskSnapshot) error {\n\n\tfor _, in := range ins {\n\t\tet.source.addParentEdge(in)\n\t}\n\tvalidSnapshot := false\n\tif snapshot != nil {\n\t\terr := et.walk(func(n Node) error {\n\t\t\t_, ok := snapshot.NodeSnapshots[n.Name()]\n\t\t\tif !ok {\n\t\t\t\treturn fmt.Errorf(\"task pipeline changed not using snapshot\")\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t\tvalidSnapshot = err == nil\n\t}\n\n\terr := et.walk(func(n Node) error {\n\t\tif validSnapshot {\n\t\t\tn.start(snapshot.NodeSnapshots[n.Name()])\n\t\t} else {\n\t\t\tn.start(nil)\n\t\t}\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\tet.stopping = make(chan struct{})\n\tif et.Task.SnapshotInterval > 0 {\n\t\tet.wg.Add(1)\n\t\tgo et.runSnapshotter()\n\t}\n\t// Start calcThroughput\n\tet.wg.Add(1)\n\tgo et.calcThroughput()\n\treturn nil\n}\n\nfunc (et *ExecutingTask) stop() (err error) {\n\tclose(et.stopping)\n\t_ = et.walk(func(n Node) error {\n\t\tn.stop()\n\t\te := n.Wait()\n\t\tif e != nil {\n\t\t\terr = e\n\t\t}\n\t\treturn nil\n\t})\n\tet.wg.Wait()\n\treturn\n}\n\nvar ErrWrongTaskType = errors.New(\"wrong task type\")\n\n// Instruct source batch node to start querying and sending batches of data\nfunc (et *ExecutingTask) StartBatching() error {\n\tif et.Task.Type != BatchTask {\n\t\treturn ErrWrongTaskType\n\t}\n\tbatcher := et.source.(*BatchNode)\n\n\terr := et.checkDBRPs(batcher)\n\tif err != nil {\n\t\tbatcher.Abort()\n\t\treturn err\n\t}\n\n\tbatcher.Start()\n\treturn nil\n}\n\nfunc (et *ExecutingTask) BatchCount() (int, error) {\n\tif et.Task.Type != BatchTask {\n\t\treturn 0, ErrWrongTaskType\n\t}\n\n\tbatcher := et.source.(*BatchNode)\n\treturn batcher.Count(), nil\n}\n\n// Get the next `num` batch queries that the batcher will run starting at time `start`.\nfunc (et *ExecutingTask) BatchQueries(start, stop time.Time) ([]BatchQueries, error) {\n\tif et.Task.Type != BatchTask {\n\t\treturn nil, ErrWrongTaskType\n\t}\n\n\tbatcher := et.source.(*BatchNode)\n\n\terr := et.checkDBRPs(batcher)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn batcher.Queries(start, stop)\n}\n\n// Check that the task allows access to DBRPs\nfunc (et *ExecutingTask) checkDBRPs(batcher *BatchNode) error {\n\tdbMap := CreateDBRPMap(et.Task.DBRPs)\n\tdbrps, err := batcher.DBRPs()\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor _, dbrp := range dbrps {\n\t\tif !dbMap[dbrp] {\n\t\t\treturn fmt.Errorf(\"batch query is not allowed to request data from %v\", dbrp)\n\t\t}\n\t}\n\treturn nil\n}\n\n// Stop all stats nodes\nfunc (et *ExecutingTask) StopStats() {\n\t_ = et.walk(func(n Node) error {\n\t\tif s, ok := n.(*StatsNode); ok {\n\t\t\ts.stopStats()\n\t\t}\n\t\treturn nil\n\t})\n}\n\n// Wait till the task finishes and return any error\nfunc (et *ExecutingTask) Wait() error {\n\treturn et.rwalk(func(n Node) error {\n\t\treturn n.Wait()\n\t})\n}\n\n// Get a named output.\nfunc (et *ExecutingTask) GetOutput(name string) (Output, error) {\n\tif o, ok := et.outputs[name]; ok {\n\t\treturn o, nil\n\t} else {\n\t\treturn nil, fmt.Errorf(\"unknown output %s\", name)\n\t}\n}\n\n// Register a named output.\nfunc (et *ExecutingTask) registerOutput(name string, o Output) {\n\tet.outputs[name] = o\n}\n\ntype ExecutionStats struct {\n\tTaskStats map[string]interface{}\n\tNodeStats map[string]map[string]interface{}\n}\n\nfunc (et *ExecutingTask) ExecutionStats() (ExecutionStats, error) {\n\texecutionStats := ExecutionStats{\n\t\tTaskStats: make(map[string]interface{}),\n\t\tNodeStats: make(map[string]map[string]interface{}),\n\t}\n\n\t// Fill the task stats\n\texecutionStats.TaskStats[\"throughput\"] = et.getThroughput()\n\n\t// Fill the nodes stats\n\terr := et.walk(func(node Node) error {\n\t\tnodeStats := node.stats()\n\n\t\t// Add collected and emitted\n\t\tnodeStats[\"collected\"] = node.collectedCount()\n\t\tnodeStats[\"emitted\"] = node.emittedCount()\n\n\t\texecutionStats.NodeStats[node.Name()] = nodeStats\n\n\t\treturn nil\n\t})\n\n\tif err != nil {\n\t\treturn executionStats, err\n\t}\n\n\treturn executionStats, nil\n}\n\n// Return a graphviz .dot formatted byte array.\n// Label edges with relavant execution information.\nfunc (et *ExecutingTask) EDot(labels bool) []byte {\n\n\tvar buf bytes.Buffer\n\n\tbuf.WriteString(\"digraph \")\n\tbuf.WriteString(et.Task.ID)\n\tbuf.WriteString(\" {\\n\")\n\t// Write graph attributes\n\tunit := \"points\"\n\tif et.Task.Type == BatchTask {\n\t\tunit = \"batches\"\n\t}\n\tbuf.WriteString(\"graph [\")\n\tif labels {\n\t\tbuf.WriteString(\n\t\t\tfmt.Sprintf(\"label=\\\"Throughput: %0.2f %s/s\\\" forcelabels=true pad=\\\"0.8,0.5\\\"\",\n\t\t\t\tet.getThroughput(),\n\t\t\t\tunit,\n\t\t\t),\n\t\t)\n\t} else {\n\t\tbuf.WriteString(\n\t\t\tfmt.Sprintf(\"throughput=\\\"%0.2f %s/s\\\"\",\n\t\t\t\tet.getThroughput(),\n\t\t\t\tunit,\n\t\t\t),\n\t\t)\n\t}\n\tbuf.WriteString(\"];\\n\")\n\n\t_ = et.walk(func(n Node) error {\n\t\tn.edot(&buf, labels)\n\t\treturn nil\n\t})\n\tbuf.Write([]byte(\"}\"))\n\n\treturn buf.Bytes()\n}\n\n// Return the current throughput value.\nfunc (et *ExecutingTask) getThroughput() float64 {\n\tet.tmu.RLock()\n\tdefer et.tmu.RUnlock()\n\treturn et.throughput\n}\n\nfunc (et *ExecutingTask) calcThroughput() {\n\tdefer et.wg.Done()\n\tvar previous int64\n\tlast := time.Now()\n\tticker := time.NewTicker(time.Second)\n\tdefer ticker.Stop()\n\tfor {\n\t\tselect {\n\t\tcase <-ticker.C:\n\t\t\tcurrent := et.source.collectedCount()\n\t\t\tnow := time.Now()\n\t\t\telapsed := float64(now.Sub(last)) / float64(time.Second)\n\n\t\t\tet.tmu.Lock()\n\t\t\tet.throughput = float64(current-previous) / elapsed\n\t\t\tet.tmu.Unlock()\n\n\t\t\tlast = now\n\t\t\tprevious = current\n\n\t\tcase <-et.stopping:\n\t\t\treturn\n\t\t}\n\t}\n}\n\n// Create a  node from a given pipeline node.\nfunc (et *ExecutingTask) createNode(p pipeline.Node, d NodeDiagnostic) (n Node, err error) {\n\tswitch t := p.(type) {\n\tcase *pipeline.FromNode:\n\t\tn, err = newFromNode(et, t, d)\n\tcase *pipeline.StreamNode:\n\t\tn, err = newStreamNode(et, t, d)\n\tcase *pipeline.BatchNode:\n\t\tn, err = newBatchNode(et, t, d)\n\tcase *pipeline.QueryNode:\n\t\tn, err = newQueryNode(et, t, d)\n\tcase *pipeline.QueryFluxNode:\n\t\tn, err = newQueryFluxNode(et, t, d)\n\tcase *pipeline.WindowNode:\n\t\tn, err = newWindowNode(et, t, d)\n\tcase *pipeline.HTTPOutNode:\n\t\tn, err = newHTTPOutNode(et, t, d)\n\tcase *pipeline.HTTPPostNode:\n\t\tn, err = newHTTPPostNode(et, t, d)\n\tcase *pipeline.InfluxDBOutNode:\n\t\tn, err = newInfluxDBOutNode(et, t, d)\n\tcase *pipeline.KapacitorLoopbackNode:\n\t\tn, err = newKapacitorLoopbackNode(et, t, d)\n\tcase *pipeline.AlertNode:\n\t\tn, err = newAlertNode(et, t, d)\n\tcase *pipeline.GroupByNode:\n\t\tn, err = newGroupByNode(et, t, d)\n\tcase *pipeline.UnionNode:\n\t\tn, err = newUnionNode(et, t, d)\n\tcase *pipeline.JoinNode:\n\t\tn, err = newJoinNode(et, t, d)\n\tcase *pipeline.FlattenNode:\n\t\tn, err = newFlattenNode(et, t, d)\n\tcase *pipeline.EvalNode:\n\t\tn, err = newEvalNode(et, t, d)\n\tcase *pipeline.WhereNode:\n\t\tn, err = newWhereNode(et, t, d)\n\tcase *pipeline.SampleNode:\n\t\tn, err = newSampleNode(et, t, d)\n\tcase *pipeline.DerivativeNode:\n\t\tn, err = newDerivativeNode(et, t, d)\n\tcase *pipeline.ChangeDetectNode:\n\t\tn, err = newChangeDetectNode(et, t, d)\n\tcase *pipeline.UDFNode:\n\t\tn, err = newUDFNode(et, t, d)\n\tcase *pipeline.StatsNode:\n\t\tn, err = newStatsNode(et, t, d)\n\tcase *pipeline.ShiftNode:\n\t\tn, err = newShiftNode(et, t, d)\n\tcase *pipeline.NoOpNode:\n\t\tn, err = newNoOpNode(et, t, d)\n\tcase *pipeline.InfluxQLNode:\n\t\tn, err = newInfluxQLNode(et, t, d)\n\tcase *pipeline.LogNode:\n\t\tn, err = newLogNode(et, t, d)\n\tcase *pipeline.DefaultNode:\n\t\tn, err = newDefaultNode(et, t, d)\n\tcase *pipeline.DeleteNode:\n\t\tn, err = newDeleteNode(et, t, d)\n\tcase *pipeline.CombineNode:\n\t\tn, err = newCombineNode(et, t, d)\n\tcase *pipeline.K8sAutoscaleNode:\n\t\tn, err = newK8sAutoscaleNode(et, t, d)\n\tcase *pipeline.SwarmAutoscaleNode:\n\t\tn, err = newSwarmAutoscaleNode(et, t, d)\n\tcase *pipeline.Ec2AutoscaleNode:\n\t\tn, err = newEc2AutoscaleNode(et, t, d)\n\tcase *pipeline.StateDurationNode:\n\t\tn, err = newStateDurationNode(et, t, d)\n\tcase *pipeline.StateCountNode:\n\t\tn, err = newStateCountNode(et, t, d)\n\tcase *pipeline.SideloadNode:\n\t\tn, err = newSideloadNode(et, t, d)\n\tcase *pipeline.TrickleNode:\n\t\tn = newTrickleNode(et, t, d)\n\tcase *pipeline.BarrierNode:\n\t\tn, err = newBarrierNode(et, t, d)\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"unknown pipeline node type %T\", p)\n\t}\n\tif err == nil && n != nil {\n\t\tn.init(p.IsQuiet())\n\t}\n\treturn n, err\n}\n\ntype TaskSnapshot struct {\n\tNodeSnapshots map[string][]byte\n}\n\nfunc (et *ExecutingTask) Snapshot() (*TaskSnapshot, error) {\n\tsnapshot := &TaskSnapshot{\n\t\tNodeSnapshots: make(map[string][]byte),\n\t}\n\terr := et.walk(func(n Node) error {\n\t\tdata, err := n.snapshot()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tsnapshot.NodeSnapshots[n.Name()] = data\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn snapshot, nil\n}\n\nfunc (et *ExecutingTask) runSnapshotter() {\n\tdefer et.wg.Done()\n\t// Wait random duration to splay snapshot events across interval\n\tselect {\n\tcase <-time.After(time.Duration(rand.Float64() * float64(et.Task.SnapshotInterval))):\n\tcase <-et.stopping:\n\t\treturn\n\t}\n\tticker := time.NewTicker(et.Task.SnapshotInterval)\n\tdefer ticker.Stop()\n\tfor {\n\t\tselect {\n\t\tcase <-ticker.C:\n\t\t\tsnapshot, err := et.Snapshot()\n\t\t\tif err != nil {\n\t\t\t\tet.diag.Error(\"failed to snapshot task\", err)\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tsize := 0\n\t\t\tfor _, data := range snapshot.NodeSnapshots {\n\t\t\t\tsize += len(data)\n\t\t\t}\n\t\t\t// Only save the snapshot if it has content\n\t\t\tif size > 0 {\n\t\t\t\terr = et.tm.TaskStore.SaveSnapshot(et.Task.ID, snapshot)\n\t\t\t\tif err != nil {\n\t\t\t\t\tet.diag.Error(\"failed to save task snapshot\", err)\n\t\t\t\t}\n\t\t\t}\n\t\tcase <-et.stopping:\n\t\t\treturn\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "task",
          "type": "tree",
          "content": null
        },
        {
          "name": "task_master.go",
          "type": "blob",
          "size": 23.513671875,
          "content": "package kapacitor\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/influxdata/influxdb/tsdb\"\n\n\timodels \"github.com/influxdata/influxdb/models\"\n\t\"github.com/influxdata/kapacitor/alert\"\n\t\"github.com/influxdata/kapacitor/command\"\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/expvar\"\n\t\"github.com/influxdata/kapacitor/influxdb\"\n\t\"github.com/influxdata/kapacitor/keyvalue\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n\t\"github.com/influxdata/kapacitor/server/vars\"\n\talertservice \"github.com/influxdata/kapacitor/services/alert\"\n\t\"github.com/influxdata/kapacitor/services/alerta\"\n\t\"github.com/influxdata/kapacitor/services/bigpanda\"\n\t\"github.com/influxdata/kapacitor/services/discord\"\n\tec2 \"github.com/influxdata/kapacitor/services/ec2/client\"\n\t\"github.com/influxdata/kapacitor/services/hipchat\"\n\t\"github.com/influxdata/kapacitor/services/httpd\"\n\t\"github.com/influxdata/kapacitor/services/httppost\"\n\tk8s \"github.com/influxdata/kapacitor/services/k8s/client\"\n\t\"github.com/influxdata/kapacitor/services/kafka\"\n\t\"github.com/influxdata/kapacitor/services/mqtt\"\n\t\"github.com/influxdata/kapacitor/services/opsgenie\"\n\t\"github.com/influxdata/kapacitor/services/opsgenie2\"\n\t\"github.com/influxdata/kapacitor/services/pagerduty\"\n\t\"github.com/influxdata/kapacitor/services/pagerduty2\"\n\t\"github.com/influxdata/kapacitor/services/pushover\"\n\t\"github.com/influxdata/kapacitor/services/sensu\"\n\t\"github.com/influxdata/kapacitor/services/servicenow\"\n\t\"github.com/influxdata/kapacitor/services/sideload\"\n\t\"github.com/influxdata/kapacitor/services/slack\"\n\t\"github.com/influxdata/kapacitor/services/smtp\"\n\t\"github.com/influxdata/kapacitor/services/snmptrap\"\n\tswarm \"github.com/influxdata/kapacitor/services/swarm/client\"\n\t\"github.com/influxdata/kapacitor/services/teams\"\n\t\"github.com/influxdata/kapacitor/services/telegram\"\n\t\"github.com/influxdata/kapacitor/services/victorops\"\n\t\"github.com/influxdata/kapacitor/services/zenoss\"\n\t\"github.com/influxdata/kapacitor/tick\"\n\t\"github.com/influxdata/kapacitor/tick/stateful\"\n\t\"github.com/influxdata/kapacitor/timer\"\n\t\"github.com/influxdata/kapacitor/udf\"\n)\n\nconst (\n\tstatPointsReceived = \"points_received\"\n\tMainTaskMaster     = \"main\"\n)\n\ntype LogService interface {\n\tNewLogger(prefix string, flag int) *log.Logger\n}\n\ntype Diagnostic interface {\n\tWithTaskContext(task string) TaskDiagnostic\n\tWithTaskMasterContext(tm string) Diagnostic\n\tWithNodeContext(node string) NodeDiagnostic\n\tWithEdgeContext(task, parent, child string) EdgeDiagnostic\n\n\tTaskMasterOpened()\n\tTaskMasterClosed()\n\n\tStartingTask(id string)\n\tStartedTask(id string)\n\n\tStoppedTask(id string)\n\tStoppedTaskWithError(id string, err error)\n\n\tTaskMasterDot(d string)\n}\n\ntype UDFService interface {\n\tList() []string\n\tInfo(name string) (udf.Info, bool)\n\tCreate(name, taskID, nodeID string, d udf.Diagnostic, abortCallback func()) (udf.Interface, error)\n}\n\nvar ErrTaskMasterClosed = errors.New(\"TaskMaster is closed\")\nvar ErrTaskMasterOpen = errors.New(\"TaskMaster is open\")\n\ntype deleteHook func(*TaskMaster)\n\n// An execution framework for  a set of tasks.\ntype TaskMaster struct {\n\t// Unique id for this task master instance\n\tid string\n\n\tServerInfo vars.Infoer\n\n\tHTTPDService interface {\n\t\tAddRoutes([]httpd.Route) error\n\t\tDelRoutes([]httpd.Route)\n\t\tURL() string\n\t}\n\tTaskStore interface {\n\t\tSaveSnapshot(id string, snapshot *TaskSnapshot) error\n\t\tHasSnapshot(id string) bool\n\t\tLoadSnapshot(id string) (*TaskSnapshot, error)\n\t}\n\tDeadmanService pipeline.DeadmanService\n\n\tUDFService UDFService\n\n\tAlertService interface {\n\t\talertservice.AnonHandlerRegistrar\n\t\talertservice.Events\n\t\talertservice.TopicPersister\n\t\talertservice.InhibitorLookup\n\t}\n\tInfluxDBService interface {\n\t\tNewNamedClient(name string) (influxdb.Client, error)\n\t}\n\tSMTPService interface {\n\t\tGlobal() bool\n\t\tStateChangesOnly() bool\n\t\tHandler(smtp.HandlerConfig, ...keyvalue.T) alert.Handler\n\t}\n\tMQTTService interface {\n\t\tHandler(mqtt.HandlerConfig, ...keyvalue.T) (alert.Handler, error)\n\t}\n\n\tOpsGenieService interface {\n\t\tGlobal() bool\n\t\tHandler(opsgenie.HandlerConfig, ...keyvalue.T) alert.Handler\n\t}\n\tOpsGenie2Service interface {\n\t\tGlobal() bool\n\t\tHandler(opsgenie2.HandlerConfig, ...keyvalue.T) alert.Handler\n\t}\n\tVictorOpsService interface {\n\t\tGlobal() bool\n\t\tHandler(victorops.HandlerConfig, ...keyvalue.T) alert.Handler\n\t}\n\tPagerDutyService interface {\n\t\tGlobal() bool\n\t\tHandler(pagerduty.HandlerConfig, ...keyvalue.T) alert.Handler\n\t}\n\tPagerDuty2Service interface {\n\t\tGlobal() bool\n\t\tHandler(pagerduty2.HandlerConfig, ...keyvalue.T) (alert.Handler, error)\n\t}\n\tPushoverService interface {\n\t\tHandler(pushover.HandlerConfig, ...keyvalue.T) alert.Handler\n\t}\n\tHTTPPostService interface {\n\t\tHandler(httppost.HandlerConfig, ...keyvalue.T) (alert.Handler, error)\n\t\tEndpoint(string) (*httppost.Endpoint, bool)\n\t}\n\tDiscordService interface {\n\t\tGlobal() bool\n\t\tStateChangesOnly() bool\n\t\tHandler(discord.HandlerConfig, ...keyvalue.T) (alert.Handler, error)\n\t}\n\tBigPandaService interface {\n\t\tGlobal() bool\n\t\tStateChangesOnly() bool\n\t\tHandler(bigpanda.HandlerConfig, ...keyvalue.T) (alert.Handler, error)\n\t}\n\tSlackService interface {\n\t\tGlobal() bool\n\t\tStateChangesOnly() bool\n\t\tHandler(slack.HandlerConfig, ...keyvalue.T) alert.Handler\n\t}\n\tSNMPTrapService interface {\n\t\tHandler(snmptrap.HandlerConfig, ...keyvalue.T) (alert.Handler, error)\n\t}\n\tTelegramService interface {\n\t\tGlobal() bool\n\t\tStateChangesOnly() bool\n\t\tHandler(telegram.HandlerConfig, ...keyvalue.T) alert.Handler\n\t}\n\tHipChatService interface {\n\t\tGlobal() bool\n\t\tStateChangesOnly() bool\n\t\tHandler(hipchat.HandlerConfig, ...keyvalue.T) alert.Handler\n\t}\n\tKafkaService interface {\n\t\tHandler(kafka.HandlerConfig, ...keyvalue.T) (alert.Handler, error)\n\t}\n\tAlertaService interface {\n\t\tDefaultHandlerConfig() alerta.HandlerConfig\n\t\tHandler(alerta.HandlerConfig, ...keyvalue.T) (alert.Handler, error)\n\t}\n\tSensuService interface {\n\t\tHandler(sensu.HandlerConfig, ...keyvalue.T) (alert.Handler, error)\n\t}\n\tTalkService interface {\n\t\tHandler(...keyvalue.T) alert.Handler\n\t}\n\tTimingService interface {\n\t\tNewTimer(timer.Setter) timer.Timer\n\t}\n\tK8sService interface {\n\t\tClient(string) (k8s.Client, error)\n\t}\n\tSwarmService interface {\n\t\tClient(string) (swarm.Client, error)\n\t}\n\tEC2Service interface {\n\t\tClient(string) (ec2.Client, error)\n\t}\n\n\tSideloadService interface {\n\t\tSource(*httppost.Endpoint) (sideload.Source, error)\n\t}\n\n\tTeamsService interface {\n\t\tGlobal() bool\n\t\tStateChangesOnly() bool\n\t\tHandler(teams.HandlerConfig, ...keyvalue.T) alert.Handler\n\t}\n\tServiceNowService interface {\n\t\tGlobal() bool\n\t\tStateChangesOnly() bool\n\t\tHandler(servicenow.HandlerConfig, ...keyvalue.T) alert.Handler\n\t}\n\tZenossService interface {\n\t\tGlobal() bool\n\t\tStateChangesOnly() bool\n\t\tHandler(zenoss.HandlerConfig, ...keyvalue.T) alert.Handler\n\t}\n\n\tCommander command.Commander\n\n\tDefaultRetentionPolicy string\n\n\t// Incoming streams\n\twritePointsIn StreamCollector\n\twritesClosed  bool\n\twritesMu      sync.RWMutex\n\n\t// Forks of incoming streams\n\t// We are mapping from (db, rp, measurement) to map of task ids to their edges\n\t// The outer map (from dbrp&measurement) is for fast access on forkPoint\n\t// While the inner map is for handling fork deletions better (see taskToForkKeys)\n\tforks map[forkKey]map[string]edge.Edge\n\n\t// Stats for number of points each fork has received\n\tforkStats map[forkKey]*expvar.Int\n\n\t// Task to fork keys is map to help in deletes, in deletes\n\t// we have only the task id, and they are called after the task is deleted from TaskMaster.tasks\n\ttaskToForkKeys map[string][]forkKey\n\n\t// Set of incoming batches\n\tbatches map[string][]BatchCollector\n\n\t// Executing tasks\n\ttasks map[string]*ExecutingTask\n\n\t// DeleteHooks for tasks\n\tdeleteHooks map[string][]deleteHook\n\n\tdiag Diagnostic\n\n\tclosed  bool\n\tdrained bool\n\tmu      sync.RWMutex\n\twg      sync.WaitGroup\n\n\tTestCloser io.Closer\n}\n\nfunc (tm *TaskMaster) WritePointsPrivileged(ctx tsdb.WriteContext, database, retentionPolicy string, consistencyLevel imodels.ConsistencyLevel, points []imodels.Point) error {\n\treturn tm.WritePoints(database, retentionPolicy, consistencyLevel, points)\n}\n\ntype forkKey struct {\n\tDatabase        string\n\tRetentionPolicy string\n\tMeasurement     string\n}\n\n// Create a new Executor with a given clock.\nfunc NewTaskMaster(id string, info vars.Infoer, d Diagnostic) *TaskMaster {\n\treturn &TaskMaster{\n\t\tid:             id,\n\t\tforks:          make(map[forkKey]map[string]edge.Edge),\n\t\tforkStats:      make(map[forkKey]*expvar.Int),\n\t\ttaskToForkKeys: make(map[string][]forkKey),\n\t\tbatches:        make(map[string][]BatchCollector),\n\t\ttasks:          make(map[string]*ExecutingTask),\n\t\tdeleteHooks:    make(map[string][]deleteHook),\n\t\tServerInfo:     info,\n\t\tdiag:           d.WithTaskMasterContext(id),\n\n\t\tclosed:        true,\n\t\tTimingService: noOpTimingService{},\n\n\t\t// Any cleanup/close function for test purposes. Not to be used in production\n\t\tTestCloser: nil,\n\t}\n}\n\n// Returns a new TaskMaster instance with the same services as the current one.\nfunc (tm *TaskMaster) New(id string) *TaskMaster {\n\tn := NewTaskMaster(id, tm.ServerInfo, tm.diag)\n\tn.DefaultRetentionPolicy = tm.DefaultRetentionPolicy\n\tn.HTTPDService = tm.HTTPDService\n\tn.TaskStore = tm.TaskStore\n\tn.DeadmanService = tm.DeadmanService\n\tn.UDFService = tm.UDFService\n\tn.AlertService = tm.AlertService\n\tn.InfluxDBService = tm.InfluxDBService\n\tn.SMTPService = tm.SMTPService\n\tn.MQTTService = tm.MQTTService\n\tn.OpsGenieService = tm.OpsGenieService\n\tn.OpsGenie2Service = tm.OpsGenie2Service\n\tn.VictorOpsService = tm.VictorOpsService\n\tn.PagerDutyService = tm.PagerDutyService\n\tn.PagerDuty2Service = tm.PagerDuty2Service\n\tn.PushoverService = tm.PushoverService\n\tn.HTTPPostService = tm.HTTPPostService\n\tn.DiscordService = tm.DiscordService\n\tn.BigPandaService = tm.BigPandaService\n\tn.SlackService = tm.SlackService\n\tn.TelegramService = tm.TelegramService\n\tn.SNMPTrapService = tm.SNMPTrapService\n\tn.HipChatService = tm.HipChatService\n\tn.AlertaService = tm.AlertaService\n\tn.SensuService = tm.SensuService\n\tn.TalkService = tm.TalkService\n\tn.TimingService = tm.TimingService\n\tn.K8sService = tm.K8sService\n\tn.Commander = tm.Commander\n\tn.SideloadService = tm.SideloadService\n\tn.TeamsService = tm.TeamsService\n\tn.ServiceNowService = tm.ServiceNowService\n\tn.ZenossService = tm.ZenossService\n\tn.TestCloser = tm.TestCloser\n\treturn n\n}\n\nfunc (tm *TaskMaster) ID() string {\n\treturn tm.id\n}\n\nfunc (tm *TaskMaster) Open() (err error) {\n\ttm.mu.Lock()\n\tdefer tm.mu.Unlock()\n\tif !tm.closed {\n\t\treturn ErrTaskMasterOpen\n\t}\n\ttm.closed = false\n\ttm.drained = false\n\ttm.writePointsIn, err = tm.stream(\"write_points\")\n\tif err != nil {\n\t\ttm.closed = true\n\t\treturn\n\t}\n\ttm.diag.TaskMasterOpened()\n\treturn\n}\n\nfunc (tm *TaskMaster) StopTasks() {\n\ttm.mu.Lock()\n\tdefer tm.mu.Unlock()\n\tfor _, et := range tm.tasks {\n\t\t_ = tm.stopTask(et.Task.ID)\n\t}\n}\n\nfunc (tm *TaskMaster) Close() error {\n\ttm.mu.Lock()\n\tclosed := tm.closed\n\ttm.mu.Unlock()\n\n\tif closed {\n\t\treturn ErrTaskMasterClosed\n\t}\n\n\ttm.Drain()\n\n\ttm.mu.Lock()\n\tdefer tm.mu.Unlock()\n\ttm.closed = true\n\tfor _, et := range tm.tasks {\n\t\t_ = tm.stopTask(et.Task.ID)\n\t}\n\ttm.diag.TaskMasterClosed()\n\tif tm.TestCloser != nil {\n\t\treturn tm.TestCloser.Close()\n\t}\n\treturn nil\n}\n\nfunc (tm *TaskMaster) Drain() {\n\ttm.waitForForks()\n\ttm.mu.Lock()\n\tdefer tm.mu.Unlock()\n\n\tfor id := range tm.taskToForkKeys {\n\t\ttm.delFork(id)\n\t}\n}\n\n// Create a new template in the context of a TaskMaster\nfunc (tm *TaskMaster) NewTemplate(\n\tid,\n\tscript string,\n\ttt TaskType,\n) (*Template, error) {\n\tt := &Template{\n\t\tid: id,\n\t}\n\tscope := tm.CreateTICKScope()\n\n\tvar srcEdge pipeline.EdgeType\n\tswitch tt {\n\tcase StreamTask:\n\t\tsrcEdge = pipeline.StreamEdge\n\tcase BatchTask:\n\t\tsrcEdge = pipeline.BatchEdge\n\t}\n\n\ttp, err := pipeline.CreateTemplatePipeline(script, srcEdge, scope, tm.DeadmanService)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tt.tp = tp\n\treturn t, nil\n}\n\n// Create a new task in the context of a TaskMaster\nfunc (tm *TaskMaster) NewTask(\n\tid,\n\tscript string,\n\ttt TaskType,\n\tdbrps []DBRP,\n\tsnapshotInterval time.Duration,\n\tvars map[string]tick.Var,\n) (*Task, error) {\n\tt := &Task{\n\t\tID:               id,\n\t\tType:             tt,\n\t\tDBRPs:            dbrps,\n\t\tSnapshotInterval: snapshotInterval,\n\t}\n\tscope := tm.CreateTICKScope()\n\n\tvar srcEdge pipeline.EdgeType\n\tswitch tt {\n\tcase StreamTask:\n\t\tsrcEdge = pipeline.StreamEdge\n\tcase BatchTask:\n\t\tsrcEdge = pipeline.BatchEdge\n\t}\n\n\tp, err := pipeline.CreatePipeline(script, srcEdge, scope, tm.DeadmanService, vars)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// A task will always have a stream or batch node.\n\t// If it doesn't have anything more then the task does nothing with the data.\n\tif p.Len() <= 1 {\n\t\treturn nil, fmt.Errorf(\"task does nothing\")\n\t}\n\tt.Pipeline = p\n\treturn t, nil\n}\n\nfunc (tm *TaskMaster) waitForForks() {\n\ttm.mu.Lock()\n\tdrained := tm.drained\n\ttm.mu.Unlock()\n\n\tif drained {\n\t\treturn\n\t}\n\n\ttm.mu.Lock()\n\ttm.drained = true\n\ttm.mu.Unlock()\n\n\ttm.writesMu.Lock()\n\ttm.writesClosed = true\n\ttm.writesMu.Unlock()\n\n\t// Close the write points in stream\n\ttm.writePointsIn.Close()\n\n\t// Don't hold the lock while we wait\n\ttm.wg.Wait()\n}\n\nfunc (tm *TaskMaster) CreateTICKScope() *stateful.Scope {\n\tscope := stateful.NewScope()\n\tscope.Set(\"time\", groupByTime)\n\t// Add dynamic methods to the scope for UDFs\n\tif tm.UDFService != nil {\n\t\tfor _, f := range tm.UDFService.List() {\n\t\t\tf := f\n\t\t\tinfo, _ := tm.UDFService.Info(f)\n\t\t\tscope.SetDynamicMethod(\n\t\t\t\tf,\n\t\t\t\tfunc(self interface{}, args ...interface{}) (interface{}, error) {\n\t\t\t\t\tparent, ok := self.(pipeline.Node)\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn nil, fmt.Errorf(\"cannot call %s on %T\", f, self)\n\t\t\t\t\t}\n\t\t\t\t\tudf := pipeline.NewUDF(\n\t\t\t\t\t\tparent,\n\t\t\t\t\t\tf,\n\t\t\t\t\t\tinfo.Wants,\n\t\t\t\t\t\tinfo.Provides,\n\t\t\t\t\t\tinfo.Options,\n\t\t\t\t\t)\n\t\t\t\t\treturn udf, nil\n\t\t\t\t},\n\t\t\t)\n\t\t}\n\t}\n\treturn scope\n}\n\nfunc (tm *TaskMaster) StartTask(t *Task) (*ExecutingTask, error) {\n\ttm.mu.Lock()\n\tdefer tm.mu.Unlock()\n\tif tm.closed {\n\t\treturn nil, errors.New(\"task master is closed cannot start a task\")\n\t}\n\tif len(t.DBRPs) == 0 {\n\t\treturn nil, errors.New(\"task does contain any dbrps\")\n\t}\n\ttm.diag.StartingTask(t.ID)\n\tet, err := NewExecutingTask(tm, t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar ins []edge.StatsEdge\n\tswitch et.Task.Type {\n\tcase StreamTask:\n\t\te, err := tm.newFork(et.Task.ID, et.Task.DBRPs, et.Task.Measurements())\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tins = []edge.StatsEdge{e}\n\tcase BatchTask:\n\t\tcount, err := et.BatchCount()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tins = make([]edge.StatsEdge, count)\n\t\tfor i := 0; i < count; i++ {\n\t\t\td := tm.diag.WithEdgeContext(t.ID, \"batch\", fmt.Sprintf(\"batch%d\", i))\n\t\t\tin := newEdge(t.ID, \"batch\", fmt.Sprintf(\"batch%d\", i), pipeline.BatchEdge, defaultEdgeBufferSize, d)\n\t\t\tins[i] = in\n\t\t\ttm.batches[t.ID] = append(tm.batches[t.ID], &batchCollector{edge: in})\n\t\t}\n\t}\n\n\tvar snapshot *TaskSnapshot\n\tif tm.TaskStore.HasSnapshot(t.ID) {\n\t\tsnapshot, err = tm.TaskStore.LoadSnapshot(t.ID)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\terr = et.start(ins, snapshot)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\ttm.tasks[et.Task.ID] = et\n\ttm.diag.StartedTask(t.ID)\n\ttm.diag.TaskMasterDot(string(t.Dot()))\n\n\treturn et, nil\n}\n\nfunc (tm *TaskMaster) BatchCollectors(id string) []BatchCollector {\n\treturn tm.batches[id]\n}\n\nfunc (tm *TaskMaster) StopTask(id string) error {\n\ttm.mu.Lock()\n\tdefer tm.mu.Unlock()\n\treturn tm.stopTask(id)\n}\n\nfunc (tm *TaskMaster) DeleteTask(id string) error {\n\ttm.mu.Lock()\n\tdefer tm.mu.Unlock()\n\tif err := tm.stopTask(id); err != nil {\n\t\treturn err\n\t}\n\ttm.deleteTask(id)\n\treturn nil\n}\n\n// internal stopTask function. The caller must have acquired\n// the lock in order to call this function\nfunc (tm *TaskMaster) stopTask(id string) (err error) {\n\tif et, ok := tm.tasks[id]; ok {\n\n\t\tdelete(tm.tasks, id)\n\n\t\tswitch et.Task.Type {\n\t\tcase StreamTask:\n\t\t\ttm.delFork(id)\n\t\tcase BatchTask:\n\t\t\tdelete(tm.batches, id)\n\t\t}\n\t\terr = et.stop()\n\t\tif err != nil {\n\t\t\ttm.diag.StoppedTaskWithError(id, err)\n\t\t} else {\n\t\t\ttm.diag.StoppedTask(id)\n\t\t}\n\t}\n\treturn\n}\n\n// internal deleteTask function. The caller must have acquired\n// the lock in order to call this function\nfunc (tm *TaskMaster) deleteTask(id string) {\n\thooks := tm.deleteHooks[id]\n\tfor _, deleteHook := range hooks {\n\t\tdeleteHook(tm)\n\t}\n}\n\nfunc (tm *TaskMaster) registerDeleteHookForTask(id string, hook deleteHook) {\n\ttm.mu.Lock()\n\tdefer tm.mu.Unlock()\n\ttm.deleteHooks[id] = append(tm.deleteHooks[id], hook)\n}\n\nfunc (tm *TaskMaster) IsExecuting(id string) bool {\n\ttm.mu.RLock()\n\tdefer tm.mu.RUnlock()\n\t_, executing := tm.tasks[id]\n\treturn executing\n}\n\nfunc (tm *TaskMaster) ExecutionStats(id string) (ExecutionStats, error) {\n\ttm.mu.RLock()\n\tdefer tm.mu.RUnlock()\n\ttask, executing := tm.tasks[id]\n\tif !executing {\n\t\treturn ExecutionStats{}, nil\n\t}\n\n\treturn task.ExecutionStats()\n}\n\nfunc (tm *TaskMaster) ExecutingDot(id string, labels bool) string {\n\ttm.mu.RLock()\n\tdefer tm.mu.RUnlock()\n\tet, executing := tm.tasks[id]\n\tif executing {\n\t\treturn string(et.EDot(labels))\n\t}\n\treturn \"\"\n}\n\nfunc (tm *TaskMaster) Stream(name string) (StreamCollector, error) {\n\ttm.mu.Lock()\n\tdefer tm.mu.Unlock()\n\treturn tm.stream(name)\n}\n\nfunc (tm *TaskMaster) stream(name string) (StreamCollector, error) {\n\tif tm.closed {\n\t\treturn nil, ErrTaskMasterClosed\n\t}\n\td := tm.diag.WithEdgeContext(fmt.Sprintf(\"task_master:%s\", tm.id), name, \"stream\")\n\tin := newEdge(fmt.Sprintf(\"task_master:%s\", tm.id), name, \"stream\", pipeline.StreamEdge, defaultEdgeBufferSize, d)\n\tse := &streamEdge{edge: in}\n\ttm.wg.Add(1)\n\tgo func() {\n\t\tdefer tm.wg.Done()\n\t\ttm.runForking(se)\n\t}()\n\treturn se, nil\n}\n\ntype StreamCollector interface {\n\tCollectPoint(edge.PointMessage) error\n\tClose() error\n}\n\ntype StreamEdge interface {\n\tCollectPoint(edge.PointMessage) error\n\tEmitPoint() (edge.PointMessage, bool)\n\tClose() error\n}\n\ntype streamEdge struct {\n\tedge edge.Edge\n}\n\nfunc (s *streamEdge) CollectPoint(p edge.PointMessage) error {\n\treturn s.edge.Collect(p)\n}\nfunc (s *streamEdge) EmitPoint() (edge.PointMessage, bool) {\n\tm, ok := s.edge.Emit()\n\tif !ok {\n\t\treturn nil, false\n\t}\n\tp, ok := m.(edge.PointMessage)\n\tif !ok {\n\t\tpanic(\"impossible to receive non PointMessage message\")\n\t}\n\treturn p, true\n}\nfunc (s *streamEdge) Close() error {\n\treturn s.edge.Close()\n}\n\nfunc (tm *TaskMaster) runForking(in StreamEdge) {\n\tfor p, ok := in.EmitPoint(); ok; p, ok = in.EmitPoint() {\n\t\ttm.forkPoint(p)\n\t}\n}\n\nfunc (tm *TaskMaster) forkPoint(p edge.PointMessage) {\n\ttm.mu.RLock()\n\tlocked := true\n\tdefer func() {\n\t\tif locked {\n\t\t\ttm.mu.RUnlock()\n\t\t}\n\t}()\n\n\t// Create the fork keys - which is (db, rp, measurement)\n\tkey := forkKey{\n\t\tDatabase:        p.Database(),\n\t\tRetentionPolicy: p.RetentionPolicy(),\n\t\tMeasurement:     p.Name(),\n\t}\n\n\t// If we have empty measurement in this db,rp we need to send it all\n\t// the points\n\temptyMeasurementKey := forkKey{\n\t\tDatabase:        p.Database(),\n\t\tRetentionPolicy: p.RetentionPolicy(),\n\t\tMeasurement:     \"\",\n\t}\n\n\t// Merge the results to the forks map\n\tfor _, edge := range tm.forks[key] {\n\t\t_ = edge.Collect(p)\n\t}\n\n\tfor _, edge := range tm.forks[emptyMeasurementKey] {\n\t\t_ = edge.Collect(p)\n\t}\n\n\tc, ok := tm.forkStats[key]\n\tif !ok {\n\t\t// Release read lock\n\t\ttm.mu.RUnlock()\n\t\tlocked = false\n\n\t\t// Get write lock\n\t\ttm.mu.Lock()\n\t\t// Now with write lock check again\n\t\tc, ok = tm.forkStats[key]\n\t\tif !ok {\n\t\t\t// Create statistics\n\t\t\tc = &expvar.Int{}\n\t\t\ttm.forkStats[key] = c\n\t\t}\n\t\ttm.mu.Unlock()\n\n\t\ttags := map[string]string{\n\t\t\t\"task_master\":      tm.id,\n\t\t\t\"database\":         key.Database,\n\t\t\t\"retention_policy\": key.RetentionPolicy,\n\t\t\t\"measurement\":      key.Measurement,\n\t\t}\n\t\t_, statMap := vars.NewStatistic(\"ingress\", tags)\n\t\tstatMap.Set(statPointsReceived, c)\n\t}\n\tc.Add(1)\n}\n\nfunc (tm *TaskMaster) WritePoints(database, retentionPolicy string, consistencyLevel imodels.ConsistencyLevel, points []imodels.Point) error {\n\ttm.writesMu.RLock()\n\tdefer tm.writesMu.RUnlock()\n\tif tm.writesClosed {\n\t\treturn ErrTaskMasterClosed\n\t}\n\tif retentionPolicy == \"\" {\n\t\tretentionPolicy = tm.DefaultRetentionPolicy\n\t}\n\n\tfor _, mp := range points {\n\t\tmpFields, err := mp.Fields()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tp := edge.NewPointMessage(\n\t\t\tstring(mp.Name()),\n\t\t\tdatabase,\n\t\t\tretentionPolicy,\n\t\t\tmodels.Dimensions{},\n\t\t\tmodels.Fields(mpFields),\n\t\t\tmodels.Tags(mp.Tags().Map()),\n\t\t\tmp.Time(),\n\t\t)\n\t\terr = tm.writePointsIn.CollectPoint(p)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (tm *TaskMaster) WriteKapacitorPoint(p edge.PointMessage) error {\n\ttm.writesMu.RLock()\n\tdefer tm.writesMu.RUnlock()\n\tif tm.writesClosed {\n\t\treturn ErrTaskMasterClosed\n\t}\n\tp = p.ShallowCopy()\n\tp.SetDimensions(models.Dimensions{})\n\treturn tm.writePointsIn.CollectPoint(p)\n}\n\nfunc (tm *TaskMaster) NewFork(taskName string, dbrps []DBRP, measurements []string) (edge.StatsEdge, error) {\n\ttm.mu.Lock()\n\tdefer tm.mu.Unlock()\n\treturn tm.newFork(taskName, dbrps, measurements)\n}\n\nfunc forkKeys(dbrps []DBRP, measurements []string) []forkKey {\n\tkeys := make([]forkKey, 0)\n\n\tfor _, dbrp := range dbrps {\n\t\tfor _, measurement := range measurements {\n\t\t\tkey := forkKey{\n\t\t\t\tRetentionPolicy: dbrp.RetentionPolicy,\n\t\t\t\tDatabase:        dbrp.Database,\n\t\t\t\tMeasurement:     measurement,\n\t\t\t}\n\n\t\t\tkeys = append(keys, key)\n\t\t}\n\t}\n\n\treturn keys\n}\n\n// internal newFork, must have acquired lock before calling.\nfunc (tm *TaskMaster) newFork(taskName string, dbrps []DBRP, measurements []string) (edge.StatsEdge, error) {\n\tif tm.closed {\n\t\treturn nil, ErrTaskMasterClosed\n\t}\n\n\td := tm.diag.WithEdgeContext(taskName, \"stream\", \"stream0\")\n\te := newEdge(taskName, \"stream\", \"stream0\", pipeline.StreamEdge, defaultEdgeBufferSize, d)\n\n\tfor _, key := range forkKeys(dbrps, measurements) {\n\t\ttm.taskToForkKeys[taskName] = append(tm.taskToForkKeys[taskName], key)\n\n\t\t// Add the task to the tasksMap if it doesn't exists\n\t\ttasksMap, ok := tm.forks[key]\n\t\tif !ok {\n\t\t\ttasksMap = make(map[string]edge.Edge, 0)\n\t\t}\n\n\t\t// Add the edge to task map\n\t\ttasksMap[taskName] = e\n\n\t\t// update the task map in the forks\n\t\ttm.forks[key] = tasksMap\n\t}\n\n\treturn e, nil\n}\n\nfunc (tm *TaskMaster) DelFork(id string) {\n\ttm.mu.Lock()\n\tdefer tm.mu.Unlock()\n\ttm.delFork(id)\n}\n\n// internal delFork function, must have lock to call\nfunc (tm *TaskMaster) delFork(id string) {\n\n\t// mark if we already closed the edge because the edge is replicated\n\t// by it's fork keys (db,rp,measurement)\n\tisEdgeClosed := false\n\n\t// Find the fork keys\n\tfor _, key := range tm.taskToForkKeys[id] {\n\n\t\t// check if the edge exists\n\t\tedge, ok := tm.forks[key][id]\n\t\tif ok {\n\n\t\t\t// Only close the edge if we are already didn't closed it\n\t\t\tif edge != nil && !isEdgeClosed {\n\t\t\t\tisEdgeClosed = true\n\t\t\t\tedge.Close()\n\t\t\t}\n\n\t\t\t// remove the task in fork map\n\t\t\tdelete(tm.forks[key], id)\n\t\t}\n\t}\n\n\t// remove mapping from task id to it's keys\n\tdelete(tm.taskToForkKeys, id)\n}\n\nfunc (tm *TaskMaster) SnapshotTask(id string) (*TaskSnapshot, error) {\n\ttm.mu.RLock()\n\tet, ok := tm.tasks[id]\n\ttm.mu.RUnlock()\n\n\tif ok {\n\t\treturn et.Snapshot()\n\t}\n\treturn nil, fmt.Errorf(\"task %s is not running or does not exist\", id)\n}\n\ntype noOpTimingService struct{}\n\nfunc (noOpTimingService) NewTimer(timer.Setter) timer.Timer {\n\treturn timer.NewNoOp()\n}\n\ntype TaskMasterLookup struct {\n\tsync.Mutex\n\ttaskMasters map[string]*TaskMaster\n}\n\nfunc NewTaskMasterLookup() *TaskMasterLookup {\n\treturn &TaskMasterLookup{\n\t\ttaskMasters: make(map[string]*TaskMaster),\n\t}\n}\n\nfunc (tml *TaskMasterLookup) Get(id string) *TaskMaster {\n\ttml.Lock()\n\tdefer tml.Unlock()\n\treturn tml.taskMasters[id]\n}\n\nfunc (tml *TaskMasterLookup) Main() *TaskMaster {\n\treturn tml.Get(MainTaskMaster)\n}\n\nfunc (tml *TaskMasterLookup) Set(tm *TaskMaster) {\n\ttml.Lock()\n\tdefer tml.Unlock()\n\ttml.taskMasters[tm.id] = tm\n}\n\nfunc (tml *TaskMasterLookup) Delete(tm *TaskMaster) {\n\ttml.Lock()\n\tdefer tml.Unlock()\n\tdelete(tml.taskMasters, tm.id)\n}\n\ntype BatchCollector interface {\n\tCollectBatch(edge.BufferedBatchMessage) error\n\tClose() error\n}\n\ntype batchCollector struct {\n\tedge edge.Edge\n}\n\nfunc (c *batchCollector) CollectBatch(batch edge.BufferedBatchMessage) error {\n\treturn c.edge.Collect(batch)\n}\nfunc (c *batchCollector) Close() error {\n\treturn c.edge.Close()\n}\n"
        },
        {
          "name": "template.go",
          "type": "blob",
          "size": 0.3134765625,
          "content": "package kapacitor\n\nimport (\n\t\"github.com/influxdata/kapacitor/pipeline\"\n\t\"github.com/influxdata/kapacitor/tick\"\n)\n\ntype Template struct {\n\tid string\n\ttp *pipeline.TemplatePipeline\n}\n\nfunc (t *Template) Vars() map[string]tick.Var {\n\treturn t.tp.Vars()\n}\n\nfunc (t *Template) Dot() string {\n\treturn string(t.tp.Dot(t.id))\n}\n"
        },
        {
          "name": "test.sh",
          "type": "blob",
          "size": 3.5859375,
          "content": "#!/bin/bash -x\n#\n# This is the Kapacitor test script.\n# This script can run tests in different environments.\n# # Usage: ./test.sh <environment_index>\n# Corresponding environments for environment_index:\n#      0: normal 64bit tests\n#      1: race enabled 64bit tests\n#      count: print the number of test environments\n#      *: to run all tests in parallel containers\n#\n# Logs from the test runs will be saved in OUTPUT_DIR, which defaults to ./test-logs\n#\n\nset -eo pipefail\n\n# Get dir of script and make it is our working directory.\nDIR=$(cd $(dirname \"${BASH_SOURCE[0]}\") && pwd)\ncd $DIR\n\n# Unique number for this build\nBUILD_NUM=${BUILD_NUM-$RANDOM}\n# Index for which test environment to use\nENVIRONMENT_INDEX=$1\n# Set the default OUTPUT_DIR\nOUTPUT_DIR=${OUTPUT_DIR-./test-logs}\n# Set the default DOCKER_SAVE_DIR\nDOCKER_SAVE_DIR=${DOCKER_SAVE_DIR-$HOME/docker}\n# Set default parallelism\nPARALLELISM=${PARALLELISM-1}\n# Set default timeout\nTIMEOUT=${TIMEOUT-1000s}\n# No uncommitted changes\nNO_UNCOMMITTED=${NO_UNCOMMITTED-false}\n# Home dir of the docker user\nHOME_DIR=/root\n# GOPATH\nGOPATH=/go\n# PROTO VERSION\nPROTO_VERSION=3.18.3\n\nno_uncomitted_arg=\"$no_uncommitted_arg\"\nif [ ! $NO_UNCOMMITTED ]\nthen\n    no_uncomitted_arg=\"\"\nfi\n\n# Update this value if you add a new test environment.\nENV_COUNT=2\n\n# Default return code 0\nrc=0\n\n# Convert dockerfile name to valid docker image tag name.\nfunction filename2imagename {\n    echo ${1/Dockerfile/kapacitor}\n}\n\n# Run a test in a docker container\n# Usage: run_test_docker <Dockerfile> <env_name>\nfunction run_test_docker {\n    local dockerfile=$1\n    local imagename=$(filename2imagename \"$dockerfile\")\n    shift\n    local name=$1\n    shift\n    local logfile=\"$OUTPUT_DIR/${name}.log\"\n\n    imagename=\"$imagename-$BUILD_NUM\"\n\n    echo \"Building docker image $imagename\"\n    docker build -f \"$dockerfile\" --build-arg  PROTO_VERSION=$PROTO_VERSION -t \"$imagename\" .\n\n    echo \"Running test in docker $name with args $@\"\n\n    # Run tests in docker\n    docker run \\\n         --rm \\\n         -v \"$DIR:/kapacitor\" \\\n         -e \"GORACE=$GORACE\" \\\n         -e \"AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID\" \\\n         -e \"AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY\" \\\n         \"$imagename\" \\\n         \"--test\" \\\n         \"--generate\" \\\n         \"--parallel=$PARALLELISM\" \\\n         \"--timeout=$TIMEOUT\" \\\n         \"--verbose\" \\\n         \"$@\" \\\n         2>&1 | tee \"$logfile\"\n}\n\nif [ ! -d \"$OUTPUT_DIR\" ]\nthen\n    mkdir -p \"$OUTPUT_DIR\"\nfi\n\n# Run the tests.\ncase $ENVIRONMENT_INDEX in\n    0)\n        # 64 bit tests\n        run_test_docker Dockerfile_build_ubuntu64 test_64bit $no_uncommitted_arg\n        rc=$?\n        ;;\n    1)\n        # 64 bit race tests\n        GORACE=\"halt_on_error=1\"\n        run_test_docker Dockerfile_build_ubuntu64 test_64bit_race $no_uncommitted_arg --race\n        rc=$?\n        ;;\n    \"count\")\n        echo $ENV_COUNT\n        ;;\n    *)\n        echo \"No individual test environment specified running tests for all $ENV_COUNT environments.\"\n        # Run all test environments\n        pids=()\n        for t in $(seq 0 \"$(($ENV_COUNT - 1))\")\n        do\n            $0 $t 2>&1 > /dev/null &\n            # add PID to list\n            pids+=($!)\n        done\n\n        echo \"Started all tests. Follow logs in ${OUTPUT_DIR}. Waiting...\"\n\n        # Wait for all tests to finish\n        for pid in \"${pids[@]}\"\n        do\n            wait $pid\n            rc=$(($? + $rc))\n        done\n\n        # Check if all tests passed\n        if [ $rc -eq 0 ]\n        then\n            echo \"All test have passed\"\n        else\n            echo \"Some tests failed check logs in $OUTPUT_DIR for results\"\n        fi\n        ;;\nesac\n\nexit $rc\n\n"
        },
        {
          "name": "tick",
          "type": "tree",
          "content": null
        },
        {
          "name": "tickdoc.conf",
          "type": "blob",
          "size": 0.7197265625,
          "content": "root = \"/kapacitor/v1.4/nodes\"\npage-header = '''---\ntitle: {{ .Title }}\nnote: Auto generated by tickdoc\n\nmenu:\n  kapacitor_1_5:\n    name: {{ .Name }}\n    identifier: {{ .Identifier }}\n    weight: {{ .Weight }}\n    parent: nodes\n---\n'''\n\n\nchain-method-desc = '''Chaining methods create a new node in the pipeline as a child of the calling node.\nThey do not modify the calling node.\nChaining methods are marked using the `|` operator.\n'''\n\n\nproperty-method-desc = '''Property methods modify state on the calling node.\nThey do not add another node to the pipeline, and always return a reference to the calling node.\nProperty methods are marked using the `.` operator.\n'''\n\n\nindex-width = 10\n[weights]\n    BatchNode = 4\n    StreamNode = 5\n\n\n"
        },
        {
          "name": "timer",
          "type": "tree",
          "content": null
        },
        {
          "name": "tlsconfig",
          "type": "tree",
          "content": null
        },
        {
          "name": "tmpldata.json",
          "type": "blob",
          "size": 0.4873046875,
          "content": "[\n\t{\n\t\t\"Name\":\"Float\",\n\t\t\"name\":\"float\",\n\t\t\"Type\":\"float64\",\n\t\t\"Kind\":\"reflect.Float64\",\n\t\t\"Nil\":\"0\",\n\t\t\"Zero\":\"float64(0)\"\n\t},\n\t{\n\t\t\"Name\":\"Integer\",\n\t\t\"name\":\"integer\",\n\t\t\"Type\":\"int64\",\n\t\t\"Kind\":\"reflect.Int64\",\n\t\t\"Nil\":\"0\",\n\t\t\"Zero\":\"int64(0)\"\n\t},\n\t{\n\t\t\"Name\":\"String\",\n\t\t\"name\":\"string\",\n\t\t\"Type\":\"string\",\n\t\t\"Kind\":\"reflect.String\",\n\t\t\"Nil\":\"\\\"\\\"\",\n\t\t\"Zero\":\"\\\"\\\"\"\n\t},\n\t{\n\t\t\"Name\":\"Boolean\",\n\t\t\"name\":\"boolean\",\n\t\t\"Type\":\"bool\",\n\t\t\"Kind\":\"reflect.Bool\",\n\t\t\"Nil\":\"false\",\n\t\t\"Zero\":\"false\"\n\t}\n]\n"
        },
        {
          "name": "tools.go",
          "type": "blob",
          "size": 0.5234375,
          "content": "// Tools is for building out tools so mod can version them, add any tools you need at runtime to this file as _ imports.\n// This is to follow along with best practices for mod.  https://github.com/golang/go/issues/25922\n\n//go:build tools\n// +build tools\n\npackage kapacitor\n\nimport (\n\t_ \"github.com/benbjohnson/tmpl\"\n\t_ \"google.golang.org/protobuf/cmd/protoc-gen-go\"\n\n\t// so we can use the rust dependencies of flux\n\t_ \"github.com/influxdata/pkg-config\"\n\t_ \"github.com/mailru/easyjson/easyjson\"\n\t_ \"honnef.co/go/tools/cmd/staticcheck\"\n)\n"
        },
        {
          "name": "trickle.go",
          "type": "blob",
          "size": 1.3828125,
          "content": "package kapacitor\n\nimport (\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n)\n\nfunc newTrickleNode(et *ExecutingTask, n *pipeline.TrickleNode, d NodeDiagnostic) *TrickleNode {\n\tsn := &TrickleNode{\n\t\tnode: node{Node: n, et: et, diag: d},\n\t}\n\tsn.node.runF = sn.runTrickle\n\treturn sn\n}\n\ntype TrickleNode struct {\n\tnode\n\tdims models.Dimensions\n\tname string\n}\n\nfunc (n *TrickleNode) runTrickle(_ []byte) error {\n\tconsumer := edge.NewConsumerWithReceiver(\n\t\tn.ins[0],\n\t\tn,\n\t)\n\treturn consumer.Consume()\n}\n\n// BeginBatch sets some batch variables on the node, and isn't forwarded.\nfunc (n *TrickleNode) BeginBatch(b edge.BeginBatchMessage) error {\n\tn.dims = b.Dimensions()\n\tn.name = b.Name()\n\treturn nil\n}\n\n// BatchPoint forwards a PointMessage\nfunc (n *TrickleNode) BatchPoint(bp edge.BatchPointMessage) error {\n\treturn n.outs[0].Collect(edge.NewPointMessage(\n\t\tn.name,\n\t\t\"\",\n\t\t\"\",\n\t\tn.dims,\n\t\tbp.Fields(),\n\t\tbp.Tags(),\n\t\tbp.Time()))\n}\n\nfunc (n *TrickleNode) EndBatch(end edge.EndBatchMessage) error {\n\treturn nil\n}\n\nfunc (n *TrickleNode) Point(p edge.PointMessage) error {\n\treturn n.outs[0].Collect(p)\n}\n\nfunc (n *TrickleNode) Barrier(barrier edge.BarrierMessage) error {\n\treturn n.outs[0].Collect(barrier)\n}\n\nfunc (n *TrickleNode) DeleteGroup(d edge.DeleteGroupMessage) error {\n\treturn n.outs[0].Collect(d)\n}\n\nfunc (n *TrickleNode) Done() {}\n"
        },
        {
          "name": "udf.go",
          "type": "blob",
          "size": 8.4267578125,
          "content": "package kapacitor\n\nimport (\n\t\"bufio\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/cenkalti/backoff\"\n\t\"github.com/influxdata/kapacitor/command\"\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n\t\"github.com/influxdata/kapacitor/udf\"\n\t\"github.com/influxdata/kapacitor/udf/agent\"\n\t\"github.com/pkg/errors\"\n)\n\n// User defined function\ntype UDFNode struct {\n\tnode\n\tu       *pipeline.UDFNode\n\tudf     udf.Interface\n\taborted chan struct{}\n\n\twg      sync.WaitGroup\n\tmu      sync.Mutex\n\tstopped bool\n}\n\n// Create a new UDFNode that sends incoming data to child udf\nfunc newUDFNode(et *ExecutingTask, n *pipeline.UDFNode, d NodeDiagnostic) (*UDFNode, error) {\n\tun := &UDFNode{\n\t\tnode:    node{Node: n, et: et, diag: d},\n\t\tu:       n,\n\t\taborted: make(chan struct{}),\n\t}\n\t// Create the UDF\n\tf, err := et.tm.UDFService.Create(\n\t\tn.UDFName,\n\t\tet.Task.ID,\n\t\tn.Name(),\n\t\td,\n\t\tun.abortedCallback,\n\t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tun.udf = f\n\tun.node.runF = un.runUDF\n\tun.node.stopF = un.stopUDF\n\treturn un, nil\n}\n\nvar errNodeAborted = errors.New(\"node aborted\")\n\nfunc (n *UDFNode) stopUDF() {\n\tn.mu.Lock()\n\tdefer n.mu.Unlock()\n\tif !n.stopped {\n\t\tn.stopped = true\n\t\tif n.udf != nil {\n\t\t\tn.udf.Abort(errNodeAborted)\n\t\t}\n\t}\n}\n\nfunc (n *UDFNode) runUDF(snapshot []byte) (err error) {\n\tdefer func() {\n\t\tn.mu.Lock()\n\t\tdefer n.mu.Unlock()\n\t\t//Ignore stopped errors if the udf was stopped externally\n\t\tif n.stopped && (err == udf.ErrServerStopped || err == errNodeAborted) {\n\t\t\terr = nil\n\t\t}\n\t\tn.stopped = true\n\t}()\n\n\tif err := n.udf.Open(); err != nil {\n\t\treturn err\n\t}\n\tif err := n.udf.Init(n.u.Options); err != nil {\n\t\treturn err\n\t}\n\tif snapshot != nil {\n\t\tif err := n.udf.Restore(snapshot); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tforwardErr := make(chan error, 1)\n\tgo func() {\n\t\tout := n.udf.Out()\n\t\tfor m := range out {\n\t\t\tif err := edge.Forward(n.outs, m); err != nil {\n\t\t\t\tforwardErr <- err\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tforwardErr <- nil\n\t}()\n\n\t// The abort callback needs to know when we are done writing\n\t// so we wrap in a wait group.\n\tn.wg.Add(1)\n\tgo func() {\n\t\tdefer n.wg.Done()\n\t\tin := n.udf.In()\n\t\tfor m, ok := n.ins[0].Emit(); ok; m, ok = n.ins[0].Emit() {\n\t\t\tn.timer.Start()\n\t\t\tselect {\n\t\t\tcase in <- m:\n\t\t\tcase <-n.aborted:\n\t\t\t\treturn\n\t\t\t}\n\t\t\tn.timer.Stop()\n\t\t}\n\t}()\n\n\t// wait till we are done writing\n\tn.wg.Wait()\n\n\t// Close the udf\n\tif err := n.udf.Close(); err != nil {\n\t\treturn err\n\t}\n\n\t// Wait/Return any error from the forwarding goroutine\n\treturn <-forwardErr\n}\n\nfunc (n *UDFNode) abortedCallback() {\n\tclose(n.aborted)\n\t// wait till we are done writing\n\tn.wg.Wait()\n}\n\nfunc (n *UDFNode) snapshot() ([]byte, error) {\n\treturn n.udf.Snapshot()\n}\n\n// UDFProcess wraps an external process and sends and receives data\n// over STDIN and STDOUT. Lines received over STDERR are logged\n// via normal Kapacitor logging.\ntype UDFProcess struct {\n\ttaskName string\n\tnodeName string\n\n\tserver    *udf.Server\n\tcommander command.Commander\n\tcmdSpec   command.Spec\n\tcmd       command.Command\n\n\tstderr io.Reader\n\n\t// Group for waiting on the process itself\n\tprocessGroup   sync.WaitGroup\n\tlogStdErrGroup sync.WaitGroup\n\n\tmu sync.Mutex\n\n\tdiag          udf.Diagnostic\n\ttimeout       time.Duration\n\tabortCallback func()\n}\n\nfunc NewUDFProcess(\n\ttaskName, nodeName string,\n\tcommander command.Commander,\n\tcmdSpec command.Spec,\n\td udf.Diagnostic,\n\ttimeout time.Duration,\n\tabortCallback func(),\n) *UDFProcess {\n\treturn &UDFProcess{\n\t\ttaskName:      taskName,\n\t\tnodeName:      nodeName,\n\t\tcommander:     commander,\n\t\tdiag:          d,\n\t\tcmdSpec:       cmdSpec,\n\t\ttimeout:       timeout,\n\t\tabortCallback: abortCallback,\n\t}\n}\n\n// Open the UDFProcess\nfunc (p *UDFProcess) Open() error {\n\tp.mu.Lock()\n\tdefer p.mu.Unlock()\n\n\tcmd := p.commander.NewCommand(p.cmdSpec)\n\tstdin, err := cmd.StdinPipe()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tstdout, err := cmd.StdoutPipe()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tstderr, err := cmd.StderrPipe()\n\tif err != nil {\n\t\treturn err\n\t}\n\tp.stderr = stderr\n\n\terr = cmd.Start()\n\tif err != nil {\n\t\treturn err\n\t}\n\tp.cmd = cmd\n\n\toutBuf := bufio.NewReader(stdout)\n\n\tp.server = udf.NewServer(\n\t\tp.taskName,\n\t\tp.nodeName,\n\t\toutBuf,\n\t\tstdin,\n\t\tp.diag,\n\t\tp.timeout,\n\t\tp.abortCallback,\n\t\tcmd.Kill,\n\t)\n\tif err := p.server.Start(); err != nil {\n\t\treturn err\n\t}\n\n\tp.logStdErrGroup.Add(1)\n\tgo p.logStdErr()\n\n\t// Wait for process to terminate\n\tp.processGroup.Add(1)\n\tgo func() {\n\t\t// First wait for the pipe read writes to finish\n\t\tp.logStdErrGroup.Wait()\n\t\tp.server.WaitIO()\n\t\terr := cmd.Wait()\n\t\tif err != nil {\n\t\t\terr = fmt.Errorf(\"process exited unexpectedly: %v\", err)\n\t\t\tdefer p.server.Abort(err)\n\t\t}\n\t\tp.processGroup.Done()\n\t}()\n\n\treturn nil\n}\n\n// Stop the UDFProcess cleanly.\n//\n// Calling Close should only be done once the owner has stopped writing to the *In channel,\n// at which point the remaining data will be processed and the subprocess will be allowed to exit cleanly.\nfunc (p *UDFProcess) Close() error {\n\tp.mu.Lock()\n\tdefer p.mu.Unlock()\n\terr := p.server.Stop()\n\tp.processGroup.Wait()\n\treturn err\n}\n\n// Replay any lines from STDERR of the process to the Kapacitor log.\nfunc (p *UDFProcess) logStdErr() {\n\tdefer p.logStdErrGroup.Done()\n\tscanner := bufio.NewScanner(p.stderr)\n\tfor scanner.Scan() {\n\t\tp.diag.UDFLog(scanner.Text())\n\t}\n}\n\nfunc (p *UDFProcess) Abort(err error)                    { p.server.Abort(err) }\nfunc (p *UDFProcess) Init(options []*agent.Option) error { return p.server.Init(options) }\nfunc (p *UDFProcess) Snapshot() ([]byte, error)          { return p.server.Snapshot() }\nfunc (p *UDFProcess) Restore(snapshot []byte) error      { return p.server.Restore(snapshot) }\nfunc (p *UDFProcess) In() chan<- edge.Message            { return p.server.In() }\nfunc (p *UDFProcess) Out() <-chan edge.Message           { return p.server.Out() }\nfunc (p *UDFProcess) Info() (udf.Info, error)            { return p.server.Info() }\n\ntype UDFSocket struct {\n\ttaskName string\n\tnodeName string\n\n\tserver *udf.Server\n\tsocket Socket\n\n\tdiag          udf.Diagnostic\n\ttimeout       time.Duration\n\tabortCallback func()\n}\n\ntype Socket interface {\n\tOpen() error\n\tClose() error\n\tIn() io.WriteCloser\n\tOut() io.Reader\n}\n\nfunc NewUDFSocket(\n\ttaskName, nodeName string,\n\tsocket Socket,\n\td udf.Diagnostic,\n\ttimeout time.Duration,\n\tabortCallback func(),\n) *UDFSocket {\n\treturn &UDFSocket{\n\t\ttaskName:      taskName,\n\t\tnodeName:      nodeName,\n\t\tsocket:        socket,\n\t\tdiag:          d,\n\t\ttimeout:       timeout,\n\t\tabortCallback: abortCallback,\n\t}\n}\n\nfunc (s *UDFSocket) Open() error {\n\terr := s.socket.Open()\n\tif err != nil {\n\t\treturn err\n\t}\n\tin := s.socket.In()\n\tout := s.socket.Out()\n\toutBuf := bufio.NewReader(out)\n\n\ts.server = udf.NewServer(\n\t\ts.taskName,\n\t\ts.nodeName,\n\t\toutBuf,\n\t\tin,\n\t\ts.diag,\n\t\ts.timeout,\n\t\ts.abortCallback,\n\t\tfunc() { s.socket.Close() },\n\t)\n\treturn s.server.Start()\n}\n\nfunc (s *UDFSocket) Close() error {\n\tif err := s.server.Stop(); err != nil {\n\t\t// Always close the socket\n\t\ts.socket.Close()\n\t\treturn errors.Wrap(err, \"stopping UDF server\")\n\t}\n\tif err := s.socket.Close(); err != nil {\n\t\treturn errors.Wrap(err, \"closing UDF socket connection\")\n\t}\n\treturn nil\n}\n\nfunc (s *UDFSocket) Abort(err error)                    { s.server.Abort(err) }\nfunc (s *UDFSocket) Init(options []*agent.Option) error { return s.server.Init(options) }\nfunc (s *UDFSocket) Snapshot() ([]byte, error)          { return s.server.Snapshot() }\nfunc (s *UDFSocket) Restore(snapshot []byte) error      { return s.server.Restore(snapshot) }\nfunc (s *UDFSocket) In() chan<- edge.Message            { return s.server.In() }\nfunc (s *UDFSocket) Out() <-chan edge.Message           { return s.server.Out() }\nfunc (s *UDFSocket) Info() (udf.Info, error)            { return s.server.Info() }\n\ntype socket struct {\n\tpath string\n\tconn *net.UnixConn\n}\n\nfunc NewSocketConn(path string) Socket {\n\treturn &socket{\n\t\tpath: path,\n\t}\n}\n\nfunc (s *socket) Open() error {\n\taddr, err := net.ResolveUnixAddr(\"unix\", s.path)\n\tif err != nil {\n\t\treturn err\n\t}\n\t// Connect to socket\n\tb := backoff.NewExponentialBackOff()\n\tb.MaxElapsedTime = time.Minute * 5\n\n\terr = backoff.Retry(func() error {\n\t\tconn, err := net.DialUnix(\"unix\", nil, addr)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\ts.conn = conn\n\t\treturn nil\n\t},\n\t\tb,\n\t)\n\treturn err\n}\n\nfunc (s *socket) Close() error {\n\treturn s.conn.Close()\n}\n\ntype unixCloser struct {\n\t*net.UnixConn\n}\n\nfunc (u unixCloser) Close() error {\n\t// Only close the write end of the socket connection.\n\t// The socket connection as a whole will be closed later.\n\treturn u.CloseWrite()\n}\n\nfunc (s *socket) In() io.WriteCloser {\n\treturn unixCloser{s.conn}\n}\n\nfunc (s *socket) Out() io.Reader {\n\treturn s.conn\n}\n"
        },
        {
          "name": "udf",
          "type": "tree",
          "content": null
        },
        {
          "name": "udf_test.go",
          "type": "blob",
          "size": 6.498046875,
          "content": "package kapacitor_test\n\nimport (\n\t\"bytes\"\n\t\"io\"\n\t\"reflect\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/influxdata/kapacitor\"\n\t\"github.com/influxdata/kapacitor/command\"\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/services/diagnostic\"\n\t\"github.com/influxdata/kapacitor/udf\"\n\t\"github.com/influxdata/kapacitor/udf/agent\"\n\tudf_test \"github.com/influxdata/kapacitor/udf/test\"\n)\n\nvar diagService *diagnostic.Service\n\nvar kapacitorDiag kapacitor.Diagnostic\n\nfunc init() {\n\tdiagService = diagnostic.NewService(diagnostic.NewConfig(), io.Discard, io.Discard)\n\tdiagService.Open()\n\tkapacitorDiag = diagService.NewKapacitorHandler()\n}\n\nfunc newUDFSocket(name string) (*kapacitor.UDFSocket, *udf_test.IO) {\n\tuio := udf_test.NewIO()\n\td := kapacitorDiag.WithNodeContext(name)\n\tu := kapacitor.NewUDFSocket(name, \"testNode\", newTestSocket(uio), d, 0, nil)\n\treturn u, uio\n}\n\nfunc newUDFProcess(name string) (*kapacitor.UDFProcess, *udf_test.IO) {\n\tuio := udf_test.NewIO()\n\tcmd := newTestCommander(uio)\n\td := kapacitorDiag.WithNodeContext(name)\n\tu := kapacitor.NewUDFProcess(name, \"testNode\", cmd, command.Spec{}, d, 0, nil)\n\treturn u, uio\n}\n\nfunc TestUDFSocket_OpenClose(t *testing.T) {\n\tu, uio := newUDFSocket(\"OpenClose\")\n\ttestUDF_OpenClose(u, uio, t)\n}\nfunc TestUDFProcess_OpenClose(t *testing.T) {\n\tu, uio := newUDFProcess(\"OpenClose\")\n\ttestUDF_OpenClose(u, uio, t)\n}\n\nfunc testUDF_OpenClose(u udf.Interface, uio *udf_test.IO, t *testing.T) {\n\tu.Open()\n\n\tclose(uio.Responses)\n\tu.Close()\n\t// read all requests and wait till the chan is closed\n\tfor range uio.Requests {\n\t}\n\tif err := <-uio.ErrC; err != nil {\n\t\tt.Error(err)\n\t}\n}\n\nfunc TestUDFSocket_WritePoint(t *testing.T) {\n\tu, uio := newUDFSocket(\"WritePoint\")\n\ttestUDF_WritePoint(u, uio, t)\n}\n\nfunc TestUDFProcess_WritePoint(t *testing.T) {\n\tu, uio := newUDFProcess(\"WritePoint\")\n\ttestUDF_WritePoint(u, uio, t)\n}\n\nfunc testUDF_WritePoint(u udf.Interface, uio *udf_test.IO, t *testing.T) {\n\tgo func() {\n\t\treq := <-uio.Requests\n\t\t_, ok := req.Message.(*agent.Request_Init)\n\t\tif !ok {\n\t\t\tt.Errorf(\"expected init message got %T\", req.Message)\n\t\t}\n\t\tres := &agent.Response{\n\t\t\tMessage: &agent.Response_Init{\n\t\t\t\tInit: &agent.InitResponse{\n\t\t\t\t\tSuccess: true,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tuio.Responses <- res\n\t\treq = <-uio.Requests\n\t\tpt, ok := req.Message.(*agent.Request_Point)\n\t\tif !ok {\n\t\t\tt.Errorf(\"expected point message got %T\", req.Message)\n\t\t}\n\t\tres = &agent.Response{\n\t\t\tMessage: &agent.Response_Point{\n\t\t\t\tPoint: pt.Point,\n\t\t\t},\n\t\t}\n\t\tuio.Responses <- res\n\t\tclose(uio.Responses)\n\t}()\n\n\terr := u.Open()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\terr = u.Init(nil)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// Write point to server\n\tp := edge.NewPointMessage(\n\t\t\"test\",\n\t\t\"db\",\n\t\t\"rp\",\n\t\tmodels.Dimensions{},\n\t\tmodels.Fields{\"f1\": 1.0, \"f2\": 2.0},\n\t\tmodels.Tags{\"t1\": \"v1\", \"t2\": \"v2\"},\n\t\ttime.Date(1971, 1, 1, 0, 0, 0, 0, time.UTC),\n\t)\n\tu.In() <- p\n\trp := <-u.Out()\n\tif !reflect.DeepEqual(rp, p) {\n\t\tt.Errorf(\"unexpected returned point got: %v exp %v\", rp, p)\n\t}\n\n\tu.Close()\n\t// read all requests and wait till the chan is closed\n\tfor range uio.Requests {\n\t}\n\tif err := <-uio.ErrC; err != nil {\n\t\tt.Error(err)\n\t}\n}\n\nfunc TestUDFSocket_WriteBatch(t *testing.T) {\n\tu, uio := newUDFSocket(\"WriteBatch\")\n\ttestUDF_WriteBatch(u, uio, t)\n}\n\nfunc TestUDFProcess_WriteBatch(t *testing.T) {\n\tu, uio := newUDFProcess(\"WriteBatch\")\n\ttestUDF_WriteBatch(u, uio, t)\n}\n\nfunc testUDF_WriteBatch(u udf.Interface, uio *udf_test.IO, t *testing.T) {\n\tgo func() {\n\t\treq := <-uio.Requests\n\t\t_, ok := req.Message.(*agent.Request_Init)\n\t\tif !ok {\n\t\t\tt.Errorf(\"expected init message got %T\", req.Message)\n\t\t}\n\t\tres := &agent.Response{\n\t\t\tMessage: &agent.Response_Init{\n\t\t\t\tInit: &agent.InitResponse{\n\t\t\t\t\tSuccess: true,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tuio.Responses <- res\n\t\t// Begin batch\n\t\treq = <-uio.Requests\n\t\tbb, ok := req.Message.(*agent.Request_Begin)\n\t\tif !ok {\n\t\t\tt.Errorf(\"expected begin message got %T\", req.Message)\n\t\t}\n\t\tres = &agent.Response{\n\t\t\tMessage: &agent.Response_Begin{\n\t\t\t\tBegin: bb.Begin,\n\t\t\t},\n\t\t}\n\t\tuio.Responses <- res\n\n\t\t// Point\n\t\treq = <-uio.Requests\n\t\tpt, ok := req.Message.(*agent.Request_Point)\n\t\tif !ok {\n\t\t\tt.Errorf(\"expected point message got %T\", req.Message)\n\t\t}\n\t\tres = &agent.Response{\n\t\t\tMessage: &agent.Response_Point{\n\t\t\t\tPoint: pt.Point,\n\t\t\t},\n\t\t}\n\t\tuio.Responses <- res\n\n\t\t// End batch\n\t\treq = <-uio.Requests\n\t\teb, ok := req.Message.(*agent.Request_End)\n\t\tif !ok {\n\t\t\tt.Errorf(\"expected end message got %T\", req.Message)\n\t\t}\n\t\tres = &agent.Response{\n\t\t\tMessage: &agent.Response_End{\n\t\t\t\tEnd: eb.End,\n\t\t\t},\n\t\t}\n\t\tuio.Responses <- res\n\t\tclose(uio.Responses)\n\t}()\n\n\terr := u.Open()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\terr = u.Init(nil)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// Write point to server\n\tb := edge.NewBufferedBatchMessage(\n\t\tedge.NewBeginBatchMessage(\n\t\t\t\"test\",\n\t\t\tmodels.Tags{\"t1\": \"v1\"},\n\t\t\tfalse,\n\t\t\ttime.Date(1971, 1, 1, 0, 0, 0, 0, time.UTC),\n\t\t\t1,\n\t\t),\n\t\t[]edge.BatchPointMessage{\n\t\t\tedge.NewBatchPointMessage(\n\t\t\t\tmodels.Fields{\"f1\": 1.0, \"f2\": 2.0, \"f3\": int64(1), \"f4\": \"str\"},\n\t\t\t\tmodels.Tags{\"t1\": \"v1\", \"t2\": \"v2\"},\n\t\t\t\ttime.Date(1971, 1, 1, 0, 0, 0, 0, time.UTC),\n\t\t\t),\n\t\t},\n\t\tedge.NewEndBatchMessage(),\n\t)\n\tu.In() <- b\n\trb := <-u.Out()\n\tif !reflect.DeepEqual(b, rb) {\n\t\tt.Errorf(\"unexpected returned batch got: %v exp %v\", rb, b)\n\t}\n\n\tu.Close()\n\t// read all requests and wait till the chan is closed\n\tfor range uio.Requests {\n\t}\n\tif err := <-uio.ErrC; err != nil {\n\t\tt.Error(err)\n\t}\n}\n\ntype testCommander struct {\n\tuio *udf_test.IO\n}\n\nfunc newTestCommander(uio *udf_test.IO) command.Commander {\n\treturn &testCommander{\n\t\tuio: uio,\n\t}\n}\n\nfunc (c *testCommander) NewCommand(command.Spec) command.Command {\n\treturn c\n}\n\nfunc (c *testCommander) Start() error { return nil }\n\nfunc (c *testCommander) Wait() error { return nil }\n\nfunc (c *testCommander) Stdin(io.Reader)  {}\nfunc (c *testCommander) Stdout(io.Writer) {}\nfunc (c *testCommander) Stderr(io.Writer) {}\n\nfunc (c *testCommander) StdinPipe() (io.WriteCloser, error) {\n\treturn c.uio.In(), nil\n}\n\nfunc (c *testCommander) StdoutPipe() (io.Reader, error) {\n\treturn c.uio.Out(), nil\n}\n\nfunc (c *testCommander) StderrPipe() (io.Reader, error) {\n\treturn &bytes.Buffer{}, nil\n}\n\nfunc (c *testCommander) Kill() {\n\tc.uio.Kill()\n}\n\ntype testSocket struct {\n\tuio *udf_test.IO\n}\n\nfunc newTestSocket(uio *udf_test.IO) kapacitor.Socket {\n\treturn &testSocket{\n\t\tuio: uio,\n\t}\n}\nfunc (s *testSocket) Open() error {\n\treturn nil\n}\n\nfunc (s *testSocket) Close() error {\n\treturn nil\n}\n\nfunc (s *testSocket) In() io.WriteCloser {\n\treturn s.uio.In()\n}\n\nfunc (s *testSocket) Out() io.Reader {\n\treturn s.uio.Out()\n}\n"
        },
        {
          "name": "union.go",
          "type": "blob",
          "size": 3.609375,
          "content": "package kapacitor\n\nimport (\n\t\"time\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n)\n\ntype UnionNode struct {\n\tnode\n\tu *pipeline.UnionNode\n\n\t// Buffer of points/batches from each source.\n\tsources []*CircularQueue[timeMessage]\n\t// the low water marks for each source.\n\tlowMarks []time.Time\n\trename   string\n}\n\ntype timeMessage interface {\n\tedge.Message\n\tedge.TimeGetter\n}\n\n// Create a new  UnionNode which combines all parent data streams into a single stream.\n// No transformation of any kind is performed.\nfunc newUnionNode(et *ExecutingTask, n *pipeline.UnionNode, d NodeDiagnostic) (*UnionNode, error) {\n\tun := &UnionNode{\n\t\tu:      n,\n\t\tnode:   node{Node: n, et: et, diag: d},\n\t\trename: n.Rename,\n\t}\n\tun.node.runF = un.runUnion\n\treturn un, nil\n}\n\nfunc (n *UnionNode) runUnion([]byte) error {\n\t// Keep buffer of values from parents so they can be ordered.\n\n\tn.sources = make([]*CircularQueue[timeMessage], len(n.ins))\n\tfor i := range n.ins {\n\t\tn.sources[i] = NewCircularQueue[timeMessage]()\n\t}\n\tn.lowMarks = make([]time.Time, len(n.ins))\n\n\tconsumer := edge.NewMultiConsumerWithStats(n.ins, n)\n\treturn consumer.Consume()\n}\n\nfunc (n *UnionNode) BufferedBatch(src int, batch edge.BufferedBatchMessage) error {\n\tn.timer.Start()\n\tdefer n.timer.Stop()\n\n\tif n.rename != \"\" {\n\t\tbatch = batch.ShallowCopy()\n\t\tbatch.SetBegin(batch.Begin().ShallowCopy())\n\t\tbatch.Begin().SetName(n.rename)\n\t}\n\n\t// Add newest point to buffer\n\tn.sources[src].Enqueue(batch)\n\n\t// Emit the next values\n\treturn n.emitReady(false)\n}\n\nfunc (n *UnionNode) Delete(src int, d edge.DeleteGroupMessage) error {\n\treturn edge.Forward(n.outs, d)\n}\n\nfunc (n *UnionNode) Point(src int, p edge.PointMessage) error {\n\tn.timer.Start()\n\tdefer n.timer.Stop()\n\n\tif n.rename != \"\" {\n\t\tp = p.ShallowCopy()\n\t\tp.SetName(n.rename)\n\t}\n\n\t// Add newest point to buffer\n\tn.sources[src].Enqueue(p)\n\n\t// Emit the next values\n\treturn n.emitReady(false)\n}\n\nfunc (n *UnionNode) Barrier(src int, b edge.BarrierMessage) error {\n\tn.timer.Start()\n\tdefer n.timer.Stop()\n\n\t// Add newest point to buffer\n\tn.sources[src].Enqueue(b)\n\n\t// Emit the next values\n\treturn n.emitReady(false)\n}\n\nfunc (n *UnionNode) Finish() error {\n\t// We are done, emit all buffered\n\treturn n.emitReady(true)\n}\n\nfunc (n *UnionNode) emitReady(drain bool) error {\n\temitted := true\n\tvar v timeMessage\n\tvar i int\n\t// Emit all points until nothing changes\n\tfor emitted {\n\t\temitted = false\n\t\t// Find low water mark\n\t\tvar mark time.Time\n\t\tvalidSources := 0\n\t\tfor i, values := range n.sources {\n\t\t\tsourceMark := n.lowMarks[i]\n\t\t\tif values.Len > 0 {\n\t\t\t\tt := values.Peek(0).Time()\n\t\t\t\tif mark.IsZero() || t.Before(mark) {\n\t\t\t\t\tmark = t\n\t\t\t\t}\n\t\t\t\tsourceMark = t\n\t\t\t}\n\t\t\tn.lowMarks[i] = sourceMark\n\t\t\tif !sourceMark.IsZero() {\n\t\t\t\tvalidSources++\n\t\t\t\t// Only consider the sourceMark if we are not draining\n\t\t\t\tif !drain && (mark.IsZero() || sourceMark.Before(mark)) {\n\t\t\t\t\tmark = sourceMark\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif !drain && validSources != len(n.sources) {\n\t\t\t// We can't continue processing until we have\n\t\t\t// at least one value from each parent.\n\t\t\t// Unless we are draining the buffer than we can continue.\n\t\t\treturn nil\n\t\t}\n\n\t\t// Emit all values that are at or below the mark.\n\t\tfor i = range n.sources {\n\t\t\tl := n.sources[i].Len\n\t\t\tj := 0\n\t\t\tfor j = 0; j < l; j++ {\n\t\t\t\tv = n.sources[i].Peek(j)\n\t\t\t\tif !v.Time().After(mark) {\n\t\t\t\t\terr := n.emit(v)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\t// Note that we emitted something\n\t\t\t\t\temitted = true\n\t\t\t\t} else {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tn.sources[i].Dequeue(j)\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (n *UnionNode) emit(m edge.Message) error {\n\tn.timer.Pause()\n\tdefer n.timer.Resume()\n\treturn edge.Forward(n.outs, m)\n}\n"
        },
        {
          "name": "update_tick_docs.sh",
          "type": "blob",
          "size": 0.36328125,
          "content": "#!/bin/bash\n\n# To generate the tick docs we use a little utility similar\n# to godoc called tickdoc. It organizes the fields and method\n# of structs into property methods and chaining methods.\n\ndest=$1 # output path for the .md files\n\nif [ -z \"$dest\" ]\nthen\n    echo \"Usage: ./update_tick_docs.sh output_path\"\n    exit 1\nfi\n\ntickdoc -config tickdoc.conf ./pipeline $dest\n\n\n"
        },
        {
          "name": "usr",
          "type": "tree",
          "content": null
        },
        {
          "name": "uuid",
          "type": "tree",
          "content": null
        },
        {
          "name": "waiter",
          "type": "tree",
          "content": null
        },
        {
          "name": "where.go",
          "type": "blob",
          "size": 2.5380859375,
          "content": "package kapacitor\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n\t\"github.com/influxdata/kapacitor/tick/ast\"\n\t\"github.com/influxdata/kapacitor/tick/stateful\"\n)\n\ntype WhereNode struct {\n\tnode\n\tw *pipeline.WhereNode\n\n\texpression stateful.Expression\n\tscopePool  stateful.ScopePool\n}\n\n// Create a new WhereNode which filters down the batch or stream by a condition\nfunc newWhereNode(et *ExecutingTask, n *pipeline.WhereNode, d NodeDiagnostic) (wn *WhereNode, err error) {\n\twn = &WhereNode{\n\t\tnode: node{Node: n, et: et, diag: d},\n\t\tw:    n,\n\t}\n\n\texpr, err := stateful.NewExpression(n.Lambda.Expression)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Failed to compile expression in where clause: %v\", err)\n\t}\n\twn.expression = expr\n\twn.scopePool = stateful.NewScopePool(ast.FindReferenceVariables(n.Lambda.Expression))\n\n\twn.runF = wn.runWhere\n\tif n.Lambda == nil {\n\t\treturn nil, errors.New(\"nil expression passed to WhereNode\")\n\t}\n\treturn\n}\n\nfunc (n *WhereNode) runWhere(snapshot []byte) error {\n\tconsumer := edge.NewGroupedConsumer(\n\t\tn.ins[0],\n\t\tn,\n\t)\n\tn.statMap.Set(statCardinalityGauge, consumer.CardinalityVar())\n\n\treturn consumer.Consume()\n}\n\nfunc (n *WhereNode) NewGroup(group edge.GroupInfo, first edge.PointMeta) (edge.Receiver, error) {\n\treturn edge.NewReceiverFromForwardReceiverWithStats(\n\t\tn.outs,\n\t\tedge.NewTimedForwardReceiver(n.timer, n.newGroup()),\n\t), nil\n}\n\nfunc (n *WhereNode) newGroup() *whereGroup {\n\treturn &whereGroup{\n\t\tn:    n,\n\t\texpr: n.expression.CopyReset(),\n\t}\n}\n\ntype whereGroup struct {\n\tn    *WhereNode\n\texpr stateful.Expression\n}\n\nfunc (g *whereGroup) BeginBatch(begin edge.BeginBatchMessage) (edge.Message, error) {\n\tbegin = begin.ShallowCopy()\n\tbegin.SetSizeHint(0)\n\treturn begin, nil\n}\n\nfunc (g *whereGroup) BatchPoint(bp edge.BatchPointMessage) (edge.Message, error) {\n\treturn g.doWhere(bp)\n}\n\nfunc (g *whereGroup) EndBatch(end edge.EndBatchMessage) (edge.Message, error) {\n\treturn end, nil\n}\n\nfunc (g *whereGroup) Point(p edge.PointMessage) (edge.Message, error) {\n\treturn g.doWhere(p)\n}\n\nfunc (g *whereGroup) doWhere(p edge.FieldsTagsTimeGetterMessage) (edge.Message, error) {\n\tpass, err := EvalPredicate(g.expr, g.n.scopePool, p)\n\tif err != nil {\n\t\tg.n.diag.Error(\"error while evaluating expression\", err)\n\t\treturn nil, nil\n\t}\n\tif pass {\n\t\treturn p, nil\n\t}\n\treturn nil, nil\n}\n\nfunc (g *whereGroup) Barrier(b edge.BarrierMessage) (edge.Message, error) {\n\treturn b, nil\n}\nfunc (g *whereGroup) DeleteGroup(d edge.DeleteGroupMessage) (edge.Message, error) {\n\treturn d, nil\n}\nfunc (g *whereGroup) Done() {}\n"
        },
        {
          "name": "window.go",
          "type": "blob",
          "size": 10.9345703125,
          "content": "package kapacitor\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"time\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/influxdata/kapacitor/pipeline\"\n)\n\ntype WindowNode struct {\n\tnode\n\tw *pipeline.WindowNode\n}\n\n// Create a new  WindowNode, which windows data for a period of time and emits the window.\nfunc newWindowNode(et *ExecutingTask, n *pipeline.WindowNode, d NodeDiagnostic) (*WindowNode, error) {\n\tif n.Period == 0 && n.PeriodCount == 0 {\n\t\treturn nil, errors.New(\"window node must have either a non zero period or non zero period count\")\n\t}\n\twn := &WindowNode{\n\t\tw:    n,\n\t\tnode: node{Node: n, et: et, diag: d},\n\t}\n\twn.node.runF = wn.runWindow\n\treturn wn, nil\n}\n\nfunc (n *WindowNode) runWindow([]byte) (err error) {\n\tconsumer := edge.NewGroupedConsumer(n.ins[0], n)\n\tn.statMap.Set(statCardinalityGauge, consumer.CardinalityVar())\n\terr = consumer.Consume()\n\treturn\n}\n\nfunc (n *WindowNode) NewGroup(group edge.GroupInfo, first edge.PointMeta) (edge.Receiver, error) {\n\tr, err := n.newWindow(group, first)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn edge.NewReceiverFromForwardReceiverWithStats(\n\t\tn.outs,\n\t\tedge.NewTimedForwardReceiver(n.timer, r),\n\t), nil\n}\n\nfunc (n *WindowNode) DeleteGroup(group models.GroupID) {\n\t// Nothing to do\n}\n\nfunc (n *WindowNode) newWindow(group edge.GroupInfo, first edge.PointMeta) (edge.ForwardReceiver, error) {\n\tswitch {\n\tcase n.w.Period != 0:\n\t\treturn newWindowByTime(\n\t\t\tfirst.Name(),\n\t\t\tfirst.Time(),\n\t\t\tgroup,\n\t\t\tn.w.Period,\n\t\t\tn.w.Every,\n\t\t\tn.w.AlignFlag,\n\t\t\tn.w.FillPeriodFlag,\n\t\t\tn.diag,\n\t\t), nil\n\tcase n.w.PeriodCount != 0:\n\t\treturn newWindowByCount(\n\t\t\tfirst.Name(),\n\t\t\tgroup,\n\t\t\tint(n.w.PeriodCount),\n\t\t\tint(n.w.EveryCount),\n\t\t\tn.w.FillPeriodFlag,\n\t\t\tn.diag,\n\t\t), nil\n\tdefault:\n\t\treturn nil, errors.New(\"unreachable code, window node should have a non-zero period or period count\")\n\t}\n}\n\ntype windowByTime struct {\n\tname  string\n\tgroup edge.GroupInfo\n\n\tnextEmit time.Time\n\n\tbuf *windowTimeBuffer\n\n\talign,\n\tfillPeriod bool\n\n\tperiod time.Duration\n\tevery  time.Duration\n\n\tdiag NodeDiagnostic\n}\n\nfunc newWindowByTime(\n\tname string,\n\tt time.Time,\n\tgroup edge.GroupInfo,\n\tperiod,\n\tevery time.Duration,\n\talign,\n\tfillPeriod bool,\n\td NodeDiagnostic,\n\n) *windowByTime {\n\t// Determine nextEmit time.\n\tvar nextEmit time.Time\n\tif fillPeriod {\n\t\tnextEmit = t.Add(period)\n\t\tif align {\n\t\t\tfirstPeriod := nextEmit\n\t\t\t// Needs to be aligned with Every and be greater than now+Period\n\t\t\tnextEmit = nextEmit.Truncate(every)\n\t\t\tif !nextEmit.After(firstPeriod) {\n\t\t\t\t// This means we will drop the first few points\n\t\t\t\tnextEmit = nextEmit.Add(every)\n\t\t\t}\n\t\t}\n\t} else {\n\t\tnextEmit = t.Add(every)\n\t\tif align {\n\t\t\tnextEmit = nextEmit.Truncate(every)\n\t\t}\n\t}\n\treturn &windowByTime{\n\t\tname:       name,\n\t\tgroup:      group,\n\t\tnextEmit:   nextEmit,\n\t\tbuf:        &windowTimeBuffer{diag: d},\n\t\talign:      align,\n\t\tfillPeriod: fillPeriod,\n\t\tperiod:     period,\n\t\tevery:      every,\n\t\tdiag:       d,\n\t}\n}\n\nfunc (w *windowByTime) BeginBatch(edge.BeginBatchMessage) (edge.Message, error) {\n\treturn nil, errors.New(\"window does not support batch data\")\n}\nfunc (w *windowByTime) BatchPoint(edge.BatchPointMessage) (edge.Message, error) {\n\treturn nil, errors.New(\"window does not support batch data\")\n}\nfunc (w *windowByTime) EndBatch(edge.EndBatchMessage) (edge.Message, error) {\n\treturn nil, errors.New(\"window does not support batch data\")\n}\nfunc (w *windowByTime) Barrier(b edge.BarrierMessage) (msg edge.Message, err error) {\n\tif w.every == 0 {\n\t\t// Since we are emitting every point we can use a right aligned window (oldest, now]\n\t\tif !b.Time().Before(w.nextEmit) {\n\t\t\t// purge old points\n\t\t\toldest := b.Time().Add(-1 * w.period)\n\t\t\tw.buf.purge(oldest, false)\n\n\t\t\t// get current batch\n\t\t\tmsg = w.batch(b.Time())\n\n\t\t\t// Next emit time is now\n\t\t\tw.nextEmit = b.Time()\n\t\t}\n\t} else {\n\t\t// Since more points can arrive with the same time we need to use a left aligned window [oldest, now).\n\t\tif !b.Time().Before(w.nextEmit) {\n\t\t\t// purge old points\n\t\t\toldest := w.nextEmit.Add(-1 * w.period)\n\t\t\tw.buf.purge(oldest, true)\n\n\t\t\t// get current batch\n\t\t\tmsg = w.batch(w.nextEmit)\n\n\t\t\t// Determine next emit time.\n\t\t\t// This is dependent on the current time not the last time we emitted.\n\t\t\tw.nextEmit = b.Time().Add(w.every)\n\t\t\tif w.align {\n\t\t\t\tw.nextEmit = w.nextEmit.Truncate(w.every)\n\t\t\t}\n\t\t}\n\t}\n\treturn\n}\nfunc (w *windowByTime) DeleteGroup(d edge.DeleteGroupMessage) (edge.Message, error) {\n\treturn d, nil\n}\nfunc (w *windowByTime) Done() {}\n\nfunc (w *windowByTime) Point(p edge.PointMessage) (msg edge.Message, err error) {\n\tif w.every == 0 {\n\t\t// Insert point before.\n\t\tw.buf.insert(p)\n\t\t// Since we are emitting every point we can use a right aligned window (oldest, now]\n\t\tif !p.Time().Before(w.nextEmit) {\n\t\t\t// purge old points\n\t\t\toldest := p.Time().Add(-1 * w.period)\n\t\t\tw.buf.purge(oldest, false)\n\n\t\t\t// get current batch\n\t\t\tmsg = w.batch(p.Time())\n\n\t\t\t// Next emit time is now\n\t\t\tw.nextEmit = p.Time()\n\t\t}\n\t} else {\n\t\t// Since more points can arrive with the same time we need to use a left aligned window [oldest, now).\n\t\tif !p.Time().Before(w.nextEmit) {\n\t\t\t// purge old points\n\t\t\toldest := w.nextEmit.Add(-1 * w.period)\n\t\t\tw.buf.purge(oldest, true)\n\n\t\t\t// get current batch\n\t\t\tmsg = w.batch(w.nextEmit)\n\n\t\t\t// Determine next emit time.\n\t\t\t// This is dependent on the current time not the last time we emitted.\n\t\t\tw.nextEmit = p.Time().Add(w.every)\n\t\t\tif w.align {\n\t\t\t\tw.nextEmit = w.nextEmit.Truncate(w.every)\n\t\t\t}\n\t\t}\n\t\t// Insert point after.\n\t\tw.buf.insert(p)\n\t}\n\treturn\n}\n\n// batch returns the current window buffer as a batch message.\n// TODO(nathanielc): A possible optimization could be to not buffer the data at all if we know that we do not have overlapping windows.\nfunc (w *windowByTime) batch(tmax time.Time) edge.BufferedBatchMessage {\n\tpoints := w.buf.points()\n\treturn edge.NewBufferedBatchMessage(\n\t\tedge.NewBeginBatchMessage(\n\t\t\tw.name,\n\t\t\tw.group.Tags,\n\t\t\tw.group.Dimensions.ByName,\n\t\t\ttmax,\n\t\t\tlen(points),\n\t\t),\n\t\tpoints,\n\t\tedge.NewEndBatchMessage(),\n\t)\n}\n\n// implements a purpose built ring buffer for the window of points\ntype windowTimeBuffer struct {\n\twindow []edge.PointMessage\n\tstart  int\n\tstop   int\n\tsize   int\n\tdiag   NodeDiagnostic\n}\n\n// Insert a single point into the buffer.\nfunc (b *windowTimeBuffer) insert(p edge.PointMessage) {\n\tif b.size == cap(b.window) {\n\t\t//Increase our buffer\n\t\tc := 2 * (b.size + 1)\n\t\tw := make([]edge.PointMessage, b.size+1, c)\n\t\tif b.size == 0 {\n\t\t\t//do nothing\n\t\t} else if b.stop > b.start {\n\t\t\tn := copy(w, b.window[b.start:b.stop])\n\t\t\tif n != b.size {\n\t\t\t\tpanic(fmt.Sprintf(\"did not copy all the data: copied: %d size: %d start: %d stop: %d\\n\", n, b.size, b.start, b.stop))\n\t\t\t}\n\t\t} else {\n\t\t\tn := 0\n\t\t\tn += copy(w, b.window[b.start:])\n\t\t\tn += copy(w[b.size-b.start:], b.window[:b.stop])\n\t\t\tif n != b.size {\n\t\t\t\tpanic(fmt.Sprintf(\"did not copy all the data: copied: %d size: %d start: %d stop: %d\\n\", n, b.size, b.start, b.stop))\n\t\t\t}\n\t\t}\n\t\tb.window = w\n\t\tb.start = 0\n\t\tb.stop = b.size\n\t}\n\n\t// Check if we need to wrap around\n\tif len(b.window) == cap(b.window) && b.stop == len(b.window) {\n\t\tb.stop = 0\n\t}\n\n\t// Insert point\n\tif b.stop == len(b.window) {\n\t\tb.window = append(b.window, p)\n\t} else {\n\t\tb.window[b.stop] = p\n\t}\n\tb.size++\n\tb.stop++\n}\n\n// Purge expired data from the window.\nfunc (b *windowTimeBuffer) purge(oldest time.Time, inclusive bool) {\n\tinclude := func(t time.Time) bool {\n\t\tif inclusive {\n\t\t\treturn !t.Before(oldest)\n\t\t}\n\t\treturn t.After(oldest)\n\t}\n\tl := len(b.window)\n\tif l == 0 {\n\t\treturn\n\t}\n\tif b.start < b.stop {\n\t\tfor ; b.start < b.stop; b.start++ {\n\t\t\tif include(b.window[b.start].Time()) {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tb.size = b.stop - b.start\n\t} else {\n\t\tif include(b.window[l-1].Time()) {\n\t\t\tfor ; b.start < l; b.start++ {\n\t\t\t\tif include(b.window[b.start].Time()) {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tb.size = l - b.start + b.stop\n\t\t} else {\n\t\t\tfor b.start = 0; b.start < b.stop; b.start++ {\n\t\t\t\tif include(b.window[b.start].Time()) {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tb.size = b.stop - b.start\n\t\t}\n\t}\n}\n\n// Returns a copy of the current buffer.\n// TODO(nathanielc): Optimize this function use buffered vs unbuffered batch messages.\nfunc (b *windowTimeBuffer) points() []edge.BatchPointMessage {\n\tif b.size == 0 {\n\t\treturn nil\n\t}\n\tpoints := make([]edge.BatchPointMessage, b.size)\n\tif b.stop > b.start {\n\t\tfor i, p := range b.window[b.start:b.stop] {\n\t\t\tpoints[i] = edge.BatchPointFromPoint(p)\n\t\t}\n\t} else {\n\t\tj := 0\n\t\tl := len(b.window)\n\t\tfor i := b.start; i < l; i++ {\n\t\t\tp := b.window[i]\n\t\t\tpoints[j] = edge.BatchPointFromPoint(p)\n\t\t\tj++\n\t\t}\n\t\tfor i := 0; i < b.stop; i++ {\n\t\t\tp := b.window[i]\n\t\t\tpoints[j] = edge.BatchPointFromPoint(p)\n\t\t\tj++\n\t\t}\n\t}\n\treturn points\n}\n\ntype windowByCount struct {\n\tname  string\n\tgroup edge.GroupInfo\n\n\tbuf      []edge.BatchPointMessage\n\tstart    int\n\tstop     int\n\tperiod   int\n\tevery    int\n\tnextEmit int\n\tsize     int\n\tcount    int\n\n\tdiag NodeDiagnostic\n}\n\nfunc newWindowByCount(\n\tname string,\n\tgroup edge.GroupInfo,\n\tperiod,\n\tevery int,\n\tfillPeriod bool,\n\td NodeDiagnostic,\n) *windowByCount {\n\t// Determine the first nextEmit index\n\tnextEmit := every\n\tif fillPeriod {\n\t\tnextEmit = period\n\t}\n\treturn &windowByCount{\n\t\tname:     name,\n\t\tgroup:    group,\n\t\tbuf:      make([]edge.BatchPointMessage, period),\n\t\tperiod:   period,\n\t\tevery:    every,\n\t\tnextEmit: nextEmit,\n\t\tdiag:     d,\n\t}\n}\nfunc (w *windowByCount) BeginBatch(edge.BeginBatchMessage) (edge.Message, error) {\n\treturn nil, errors.New(\"window does not support batch data\")\n}\nfunc (w *windowByCount) BatchPoint(edge.BatchPointMessage) (edge.Message, error) {\n\treturn nil, errors.New(\"window does not support batch data\")\n}\nfunc (w *windowByCount) EndBatch(edge.EndBatchMessage) (edge.Message, error) {\n\treturn nil, errors.New(\"window does not support batch data\")\n}\nfunc (w *windowByCount) Barrier(b edge.BarrierMessage) (edge.Message, error) {\n\t//TODO(nathanielc): Implement barrier messages to flush window\n\treturn b, nil\n}\nfunc (w *windowByCount) DeleteGroup(d edge.DeleteGroupMessage) (edge.Message, error) {\n\treturn d, nil\n}\nfunc (w *windowByCount) Done() {}\n\nfunc (w *windowByCount) Point(p edge.PointMessage) (msg edge.Message, err error) {\n\tw.buf[w.stop] = edge.BatchPointFromPoint(p)\n\tw.stop = (w.stop + 1) % w.period\n\tif w.size == w.period {\n\t\tw.start = (w.start + 1) % w.period\n\t} else {\n\t\tw.size++\n\t}\n\tw.count++\n\t//Check if its time to emit\n\tif w.count == w.nextEmit {\n\t\tw.nextEmit += w.every\n\t\tmsg = w.batch()\n\t}\n\treturn\n}\n\nfunc (w *windowByCount) batch() edge.BufferedBatchMessage {\n\tpoints := w.points()\n\treturn edge.NewBufferedBatchMessage(\n\t\tedge.NewBeginBatchMessage(\n\t\t\tw.name,\n\t\t\tw.group.Tags,\n\t\t\tw.group.Dimensions.ByName,\n\t\t\tpoints[len(points)-1].Time(),\n\t\t\tlen(points),\n\t\t),\n\t\tpoints,\n\t\tedge.NewEndBatchMessage(),\n\t)\n}\n\n// Returns a copy of the current buffer.\nfunc (w *windowByCount) points() []edge.BatchPointMessage {\n\tif w.size == 0 {\n\t\treturn nil\n\t}\n\tpoints := make([]edge.BatchPointMessage, w.size)\n\tif w.stop > w.start {\n\t\tcopy(points, w.buf[w.start:w.stop])\n\t} else {\n\t\tj := 0\n\t\tl := len(w.buf)\n\t\tfor i := w.start; i < l; i++ {\n\t\t\tpoints[j] = w.buf[i]\n\t\t\tj++\n\t\t}\n\t\tfor i := 0; i < w.stop; i++ {\n\t\t\tpoints[j] = w.buf[i]\n\t\t\tj++\n\t\t}\n\t}\n\treturn points\n}\n"
        },
        {
          "name": "window_test.go",
          "type": "blob",
          "size": 3.943359375,
          "content": "package kapacitor\n\nimport (\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/influxdata/kapacitor/edge\"\n\t\"github.com/influxdata/kapacitor/models\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestWindowBufferByTime(t *testing.T) {\n\tassert := assert.New(t)\n\n\tbuf := &windowTimeBuffer{}\n\n\tsize := 100\n\n\t// fill buffer\n\tfor i := 1; i <= size; i++ {\n\n\t\tt := time.Unix(int64(i), 0)\n\t\tp := edge.NewPointMessage(\n\t\t\t\"name\", \"db\", \"rp\",\n\t\t\tmodels.Dimensions{},\n\t\t\tnil,\n\t\t\tnil,\n\t\t\tt,\n\t\t)\n\t\tbuf.insert(p)\n\n\t\tassert.Equal(i, buf.size)\n\t\tassert.Equal(0, buf.start)\n\t\tassert.Equal(i, buf.stop)\n\t}\n\n\t// purge entire buffer\n\tfor i := 0; i <= size; i++ {\n\n\t\toldest := time.Unix(int64(i+1), 0).UTC()\n\t\tbuf.purge(oldest, true)\n\n\t\tassert.Equal(size-i, buf.size, \"i: %d\", i)\n\t\tassert.Equal(i, buf.start, \"i: %d\", i)\n\t\tassert.Equal(size, buf.stop, \"i: %d\", i)\n\n\t\tpoints := buf.points()\n\t\tif assert.Equal(size-i, len(points)) {\n\t\t\tfor _, p := range points {\n\t\t\t\tassert.True(!p.Time().Before(oldest), \"Point %s is not after oldest time %s\", p.Time(), oldest)\n\t\t\t}\n\t\t}\n\t}\n\n\tassert.Equal(0, buf.size)\n\n\t// fill buffer again\n\toldest := time.Unix(int64(size), 0).UTC()\n\tfor i := 1; i <= size*2; i++ {\n\n\t\tt := time.Unix(int64(i+size), 0)\n\t\tp := edge.NewPointMessage(\n\t\t\t\"name\", \"db\", \"rp\",\n\t\t\tmodels.Dimensions{},\n\t\t\tnil,\n\t\t\tnil,\n\t\t\tt,\n\t\t)\n\t\tbuf.insert(p)\n\n\t\tassert.Equal(i, buf.size)\n\n\t\tpoints := buf.points()\n\t\tif assert.Equal(i, len(points)) {\n\t\t\tfor _, p := range points {\n\t\t\t\tif assert.NotNil(p, \"i:%d\", i) {\n\t\t\t\t\tassert.True(!p.Time().Before(oldest), \"Point %s is not after oldest time %s\", p.Time(), oldest)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc TestWindowBufferByCount(t *testing.T) {\n\ttestCases := []struct {\n\t\tsize       int\n\t\tevery      int\n\t\tperiod     int\n\t\tfillPeriod bool\n\t}{\n\t\t{\n\t\t\tsize:   100,\n\t\t\tevery:  10,\n\t\t\tperiod: 10,\n\t\t},\n\t\t{\n\t\t\tsize:   100,\n\t\t\tevery:  3,\n\t\t\tperiod: 10,\n\t\t},\n\t\t{\n\t\t\tsize:   100,\n\t\t\tevery:  1,\n\t\t\tperiod: 2,\n\t\t},\n\t\t{\n\t\t\tsize:   100,\n\t\t\tevery:  1,\n\t\t\tperiod: 1,\n\t\t},\n\t\t{\n\t\t\tsize:   100,\n\t\t\tevery:  10,\n\t\t\tperiod: 5,\n\t\t},\n\t\t{\n\t\t\tsize:   100,\n\t\t\tevery:  1,\n\t\t\tperiod: 5,\n\t\t},\n\t}\n\tfor _, tc := range testCases {\n\t\tt.Logf(\"Starting test size %d period %d every %d\", tc.size, tc.period, tc.every)\n\t\tw := newWindowByCount(\n\t\t\t\"test\",\n\t\t\tedge.GroupInfo{},\n\t\t\ttc.period,\n\t\t\ttc.every,\n\t\t\ttc.fillPeriod,\n\t\t\t&nodeDiagnostic{},\n\t\t)\n\n\t\t// fill buffer\n\t\tfor i := 1; i <= tc.size; i++ {\n\t\t\tp := edge.NewPointMessage(\n\t\t\t\t\"name\", \"db\", \"rp\",\n\t\t\t\tmodels.Dimensions{},\n\t\t\t\tnil,\n\t\t\t\tnil,\n\t\t\t\ttime.Unix(int64(i), 0).UTC(),\n\t\t\t)\n\t\t\tmsg, err := w.Point(p)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\texpEmit := tc.every == 0 || i%tc.every == 0\n\t\t\tif tc.fillPeriod {\n\t\t\t\texpEmit = i > tc.period && expEmit\n\t\t\t}\n\t\t\tif expEmit && msg == nil {\n\t\t\t\tt.Errorf(\"%d unexpected nil forward message: got nil message, expected non nil message\", i)\n\t\t\t}\n\t\t\tif !expEmit && msg != nil {\n\t\t\t\tt.Errorf(\"%d unexpected forward message: got non-nil message %v, expected nil message\", i, msg)\n\t\t\t}\n\n\t\t\tsize := i\n\t\t\tif size > tc.period {\n\t\t\t\tsize = tc.period\n\t\t\t}\n\t\t\tif got, exp := w.size, size; got != exp {\n\t\t\t\tt.Errorf(\"%d unexpected size: got %d exp %d\", i, got, exp)\n\t\t\t}\n\t\t\tstart := (i - tc.period) % tc.period\n\t\t\tif start < 0 {\n\t\t\t\tstart = 0\n\t\t\t}\n\t\t\tif got, exp := w.start, start; got != exp {\n\t\t\t\tt.Errorf(\"%d unexpected start: got %d exp %d\", i, got, exp)\n\t\t\t}\n\t\t\tif got, exp := w.stop, i%tc.period; got != exp {\n\t\t\t\tt.Errorf(\"%d unexpected stop: got %d exp %d\", i, got, exp)\n\t\t\t}\n\n\t\t\tif msg != nil {\n\t\t\t\tif msg.Type() != edge.BufferedBatch {\n\t\t\t\t\tt.Fatalf(\"unexpected message type %v\", msg.Type())\n\t\t\t\t}\n\t\t\t\tb := msg.(edge.BufferedBatchMessage)\n\t\t\t\tl := i\n\t\t\t\tif l > tc.period {\n\t\t\t\t\tl = tc.period\n\t\t\t\t}\n\t\t\t\tpoints := b.Points()\n\t\t\t\tif got, exp := len(points), l; got != exp {\n\t\t\t\t\tt.Fatalf(\"%d unexpected number of points got %d exp %d\", i, got, exp)\n\t\t\t\t}\n\n\t\t\t\tfor j, p := range points {\n\t\t\t\t\tif got, exp := p.Time(), time.Unix(int64(i+j-len(points)+1), 0).UTC(); !got.Equal(exp) {\n\t\t\t\t\t\tt.Errorf(\"%d unexpected point[%d].Time: got %v exp %v\", i, j, got, exp)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n"
        }
      ]
    }
  ]
}