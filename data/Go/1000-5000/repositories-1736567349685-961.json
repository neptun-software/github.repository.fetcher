{
  "metadata": {
    "timestamp": 1736567349685,
    "page": 961,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjk3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "prometheus/mysqld_exporter",
      "stars": 2189,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0888671875,
          "content": "/.build\n/mysqld_exporter\n/.release\n/.tarballs\n\n*.tar.gz\n*.test\n*-stamp\n.idea\n*.iml\n/vendor\n"
        },
        {
          "name": ".golangci.yml",
          "type": "blob",
          "size": 0.166015625,
          "content": "---\n# Run only staticcheck for now. Additional linters will be enabled one-by-one.\nlinters:\n  enable:\n    - misspell\n    - staticcheck\n    - sloglint\n  disable-all: true\n"
        },
        {
          "name": ".promu.yml",
          "type": "blob",
          "size": 0.6103515625,
          "content": "go:\n    # Whenever the Go version is updated here, .circle/config.yml should also\n    # be updated.\n    version: 1.23\nrepository:\n    path: github.com/prometheus/mysqld_exporter\nbuild:\n    ldflags: |\n        -X github.com/prometheus/common/version.Version={{.Version}}\n        -X github.com/prometheus/common/version.Revision={{.Revision}}\n        -X github.com/prometheus/common/version.Branch={{.Branch}}\n        -X github.com/prometheus/common/version.BuildUser={{user}}@{{host}}\n        -X github.com/prometheus/common/version.BuildDate={{date \"20060102-15:04:05\"}}\ntarball:\n    files:\n        - LICENSE\n        - NOTICE\n"
        },
        {
          "name": ".yamllint",
          "type": "blob",
          "size": 0.4521484375,
          "content": "---\nextends: default\nignore: |\n  **/node_modules\n\nrules:\n  braces:\n    max-spaces-inside: 1\n    level: error\n  brackets:\n    max-spaces-inside: 1\n    level: error\n  commas: disable\n  comments: disable\n  comments-indentation: disable\n  document-start: disable\n  indentation:\n    spaces: consistent\n    indent-sequences: consistent\n  key-duplicates:\n    ignore: |\n      config/testdata/section_key_dup.bad.yml\n  line-length: disable\n  truthy:\n    check-keys: false\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 12.9521484375,
          "content": "## master / unreleased\n\nBREAKING CHANGES:\n\nChanges:\n\n* [CHANGE]\n* [FEATURE]\n* [ENHANCEMENT]\n* [BUGFIX]\n\n## 0.16.0 / 2024-11-08\n\nChanges:\n\n* [CHANGE] Replace logging library go-kit/log with slog #875\n* [FEATURE] Support for prometheus scrape timeout in probe endpoint #828\n* [ENHANCEMENT] Support MySQL 8.4 replicas syntax #837\n* [ENHANCEMENT] Fetch lock time and cpu time from performance schema #862\n* [ENHANCEMENT] Add the instance struct to handle connections #859\n* [ENHANCEMENT] Optimize code by using built-in constants in the standard lib #844\n* [BUGFIX] Fix fetching tmpTables vs tmpDiskTables from performance_schema #853\n* [BUGFIX] Skip SPACE_TYPE column for MariaDB >=10.5 #860\n* [BUGFIX] Fixed parsing of timestamps with non-zero padded days #841\n* [BUGFIX] Fix auto_increment metric collection errors caused by using collation in INFORMATION_SCHEMA searches #833\n* [BUGFIX] Fix race condition in ReloadConfig #760\n* [BUGFIX] Change processlist query to support ONLY_FULL_GROUP_BY sql_mode #684\n* [BUGFIX] replication_applier_status_by_worker requires mysql 8.0 #683\n* [BUGFIX] Update docker registry link in README.md #813\n* [BUGFIX] Fix Docker run command and update documentation for cnf file handling #843\n* [BUGFIX] info_schema_tables: do not collect the sys schema #879\n\n## 0.15.1 / 2023-12-12\n\n* Rebuild for dependency updates\n\n## 0.15.0 / 2023-06-16\n\nBREAKING CHANGES:\n\nThe exporter no longer supports the monolithic `DATA_SOURCE_NAME` environment variable.\nTo configure connections to MySQL you can either use a `my.cnf` style config file or command line arguments.\n\nFor example:\n\n    export MYSQLD_EXPORTER_PASSWORD=secret\n    mysqld_exporter --mysqld.address=localhost:3306 --mysqld.username=exporter\n\nWe have also dropped some internal scrape metrics:\n- `mysql_exporter_scrapes_total`\n- `mysql_exporter_scrape_errors_total`\n- `mysql_last_scrape_failed`\n\nThe default client configuration file is now `.my.cnf` in the process working directory. Use `--config.my-cnf=\"$HOME/.my.cnf\"` to retain the previous default.\n\nChanges:\n\n* [CHANGE] Allow `tlsCfg.InsecureSkipVerify` outside of mTLS #631\n* [CHANGE] Update to exporter-toolkit v0.8.1 #677\n* [CHANGE] Fix shared metrics between requests #722\n* [CHANGE] Allow empty passwords #742\n* [CHANGE] Don't use HOME env in the my-cnf config path. #745\n* [FEATURE] Add support for collecting metrics from `sys.user_summary` #628\n* [FEATURE] Support for multi-target mysqld probes #651\n* [FEATURE] Add MySQL TLS configurations #718\n* [FEATURE] Add config reload via /-/reload #734\n* [ENHANCEMENT] Add UNIX domain socket support for multi-target scraping #707\n* [ENHANCEMENT] Use `STRAIGHT_JOIN` in infoSchemaAutoIncrementQuery #726\n* [BUGFIX] Fix `infoSchemaInnodbMetricsEnabledColumnQuery` #687\n* [BUGFIX] Allow empty passwords #742\n\n## 0.14.0 / 2022-01-05\n\nBREAKING CHANGES:\n\nMetric names in the info_schema.processlist collector have been changed. #603\nMetric names in the info_schema.replica_host collector have been changed. #496\n\n* [CHANGE] Rewrite processlist collector #603\n* [FEATURE] Add collector for `replica_host_status` #496\n* [ENHANCEMENT] Expose dates as timestamps grom GLOBAL STATUS #561\n* [BUGFIX] Fix mysql_slave_hosts_info for mysql 5.5 and mariadb 10.5 #577\n* [BUGFIX] Fix logging issues #562 #602\n\n## 0.13.0 / 2021-05-18\n\nBREAKING CHANGES:\n\nChanges related to `replication_group_member_stats` collector:\n* metric \"transaction_in_queue\" was Counter instead of Gauge\n* renamed 3 metrics starting with `mysql_perf_schema_transaction_` to start with `mysql_perf_schema_transactions_` to be consistent with column names\n* exposing only server's own stats by matching MEMBER_ID with @@server_uuid resulting \"member_id\" label to be dropped.\n\nChanges:\n\n* [CHANGE] Switch to go-kit for logs. #433\n* [FEATURE] Add `tls.insecure-skip-verify` flag to ignore tls verification errors #417\n* [FEATURE] Add collector for AWS Aurora information_schema.replica_host_status #435\n* [FEATURE] Add collector for `replication_group_members` #459\n* [FEATURE] Add new metrics to `replication_group_member_stats` collector to support MySQL 8.x. #462\n* [FEATURE] Add collector for `performance_schema.memory_summary_global_by_event_name` #515\n* [FEATURE] Support authenticating using mTLS client cert and no password #539\n* [FEATURE] Add TLS and basic authentication #522\n* [ENHANCEMENT] Support heartbeats in UTC #471\n* [ENHANCEMENT] Improve parsing of boolean strings #548\n* [BUGFIX] Fix binlog metrics on mysql 8.x #419\n* [BUGFIX] Fix output value of wsrep_cluster_status #473\n* [BUGFIX] Fix collect.info_schema.innodb_metrics for new field names (mariadb 10.5+) #494\n* [BUGFIX] Fix log output of collect[] params #505\n* [BUGFIX] Fix collect.info_schema.innodb_tablespaces for new table names #516\n* [BUGFIX] Fix innodb_metrics for mariadb 10.5+ #523\n* [BUGFIX] Allow perf_schema.memory summary current_bytes to be negative #517\n\n\n## 0.12.1 / 2019-07-10\n\n### Changes:\n\n* Rebuild to update Docker packages.\n\n## 0.12.0 / 2019-07-10\n\n### BREAKING CHANGES:\n\nThe minimum supported MySQL version is now 5.5.\n\nCollector `info_schema.tables` is now disabled by default due to high cardinality danger.\n\n### Changes:\n\n* [CHANGE] Update defaults for MySQL 5.5 #318\n* [CHANGE] Update innodb buffer pool mappings #369\n* [CHANGE] Disable info_schema.tables collector by default #406\n* [BUGFIX] Sanitize metric names in global variables #307\n* [BUGFIX] Use GLOBAL to prevent mysql deadlock #336\n* [BUGFIX] Clear last_scrape_error on every scrape (PR #368) #367\n* [ENHANCEMENT] Add help for some GLOBAL VARIABLES metrics. #326\n* [FEATURE] Abort on timeout. #323\n* [FEATURE] Add minimal MySQL version to Scraper interface #328\n* [FEATURE] Add by_user and by_host metrics to info_schema.processlist collector (PR #333) #334\n* [FEATURE] Add wsrep_evs_repl_latency metric collecting. (PR #338)\n* [FEATURE] Add collector for mysql.user (PR #341)\n* [FEATURE] Add perf_schema.eventsstatementssum collector #347\n* [FEATURE] Add collector to get table stats grouped by schema (PR #354)\n* [FEATURE] Add replication_applier_status_by_worker metric collecting. (PR #366)\n\n## 0.11.0 / 2018-06-29\n\n### BREAKING CHANGES:\n* Flags now use the Kingpin library, and require double-dashes. #222\n\nThis also changes the behavior of boolean flags.\n* Enable: `--collect.global_status`\n* Disable: `--no-collect.global_status`\n\n### Changes:\n* [CHANGE] Limit number and lifetime of connections #208\n* [ENHANCEMENT] Move session params to DSN #259\n* [ENHANCEMENT] Use native DB.Ping() instead of self-written implementation #210\n* [FEATURE] Add collector duration metrics #197\n* [FEATURE] Add 'collect[]' URL parameter to filter enabled collectors #235\n* [FEATURE] Set a `lock_wait_timeout` on the MySQL connection #252\n* [FEATURE] Set `last_scrape_error` when an error occurs #237\n* [FEATURE] Collect metrics from `performance_schema.replication_group_member_stats` #271\n* [FEATURE] Add innodb compression statistic #275\n* [FEATURE] Add metrics for the output of `SHOW SLAVE HOSTS` #279\n* [FEATURE] Support custom CA truststore and client SSL keypair. #255\n* [BUGFIX] Fix perfEventsStatementsQuery #213\n* [BUGFIX] Fix `file_instances` metric collector #205\n* [BUGFIX] Fix prefix removal in `perf_schema_file_instances` #257\n* [BUGFIX] Fix 32bit compile issue #273\n* [BUGFIX] Ignore boolean keys in my.cnf. #283\n\n## 0.10.0 / 2017-04-25\n\n### BREAKING CHANGES:\n* `mysql_slave_...` metrics now include an additional `connection_name` label to support mariadb multi-source replication. (#178)\n\n### Changes:\n* [FEATURE] Add read/write query response time #166\n* [FEATURE] Add Galera gcache size metric #169\n* [FEATURE] Add MariaDB multi source replication support #178\n* [FEATURE] Implement heartbeat metrics #183\n* [FEATURE] Add basic `file_summary_by_instance` metrics #189\n* [BUGFIX] Workaround MySQL bug 79533 #173\n\n## 0.9.0 / 2016-09-26\n\n### BREAKING CHANGES:\n* InnoDB buffer pool page stats have been renamed/fixed to better support aggregations (#130)\n\n### Changes:\n* [FEATURE] scrape slave status for multisource replication #134\n* [FEATURE] Add client statistics support (+ add tests on users & clients statistics) #138\n* [IMPROVEMENT] Consistency of error logging. #144\n* [IMPROVEMENT] Add label aggregation for innodb buffer metrics #130\n* [IMPROVEMENT] Improved and fixed user/client statistics #149\n* [FEATURE] Added the last binlog file number metric. #152\n* [MISC] Add an example recording rules file #156\n* [FEATURE] Added PXC/Galera info metrics. #155\n* [FEATURE] Added metrics from SHOW ENGINE INNODB STATUS. #160\n* [IMPROVEMENT] Fix `wsrep_cluster_status` #146\n\n\n## 0.8.1 / 2016-05-05\n\n### Changes:\n* [BUGFIX] Fix `collect.info_schema.innodb_tablespaces` #119\n* [BUGFIX] Fix SLAVE STATUS \"Connecting\" #125\n* [MISC] New release process using docker, circleci and a centralized building tool #120\n* [MISC] Typos #121\n\n## 0.8.0 / 2016-04-19\n\n### BREAKING CHANGES:\n* global status `innodb_buffer_pool_pages` have been renamed/labeled.\n* innodb metrics `buffer_page_io` have been renamed/labeled.\n\n### Changes:\n* [MISC] Add Travis CI automatic testing.\n* [MISC] Refactor `mysqld_exporter.go` into collector package.\n* [FEATURE] Add `mysql_up` metric (PR #99)\n* [FEATURE] Collect time metrics for processlist (PR #87)\n* [CHANGE] Separate `innodb_buffer_pool_pages` status metrics (PR #101)\n* [FEATURE] Added metrics from SHOW ENGINE TOKUDB STATUS (PR #103)\n* [CHANGE] Add special handling of `buffer_page_io` subsystem (PR #115)\n* [FEATURE] Add collector for `innodb_sys_tablespaces` (PR #116)\n\n## 0.7.1 / 2016-02-16\n\n### Changes:\n* [IMPROVEMENT] Soft error on collector failure (PR #84)\n* [BUGFIX] Fix `innodb_metrics` collector (PR #85)\n* [BUGFIX] Parse auto increment values and maximum as float64 (PR #88)\n\n## 0.7.0 / 2016-02-12\n\n### BREAKING CHANGES:\n* Global status metrics for \"handlers\" have been renamed\n\n### Changes:\n* [FEATURE] New collector for `information_schema.table_statistics` (PR #57)\n* [FEATURE] New server version metric (PR #59)\n* [FEATURE] New collector for `information_schema.innodb_metrics` (PR #69)\n* [FEATURE] Read credentials from \".my.cnf\" files (PR #77)\n* [FEATURE] New collector for query response time distribution (PR #79)\n* [FEATURE] Add minimum time flag for processlist metrics (PR #82)\n* [IMPROVEMENT] Collect more metrics from `performance_schema.events_statements_summary_by_digest` (PR #58)\n* [IMPROVEMENT] Add option to filter metrics queries from the slow log (PR #60)\n* [IMPROVEMENT] Leverage lock-free SHOW SLAVE STATUS (PR #61)\n* [IMPROVEMENT] Add labels to global status \"handlers\" counters (PR #68)\n* [IMPROVEMENT] Update Makefile.COMMON from utils repo (PR #73)\n* [BUGFIX] Fix broken error return in the scrape function and log an error (PR #64)\n* [BUGFIX] Check `log_bin` before running SHOW BINARY LOGS (PR #74)\n* [BUGFIX] Fixed uint for scrapeInnodbMetrics() and gofmt (PR #81)\n\n## 0.6.0 / 2015-10-28\n\n### BREAKING CHANGES:\n* The `digest_text` mapping metric has been removed, now included in all digest metrics (PR #50)\n* Flags for timing metrics have been removed, now included with related counter flag (PR #48)\n\n### Changes:\n* [FEATURE] New collector for metrics from information_schema.processlist (PR #34)\n* [FEATURE] New collector for binlog counts/sizes (PR #35)\n* [FEATURE] New collector for `performance_schema.{file_summary_by_event_name,events_waits_summary_global_by_event_name}` (PR #49)\n* [FEATURE] New collector for `information_schema.tables` (PR #51)\n* [IMPROVEMENT] All collection methods now have enable flags (PR #46)\n* [IMPROVEMENT] Consolidate `performance_schema` metrics flags (PR #48)\n* [IMPROVEMENT] Removed need for `digest_text` mapping metric (PR #50)\n* [IMPROVEMENT] Update docs (PR #52)\n\n## 0.5.0 / 2015-09-22\n\n### Changes:\n* [FEATURE] Add metrics for table locks\n* [BUGFIX] Use uint64 to prevent int64 overflow\n* [BUGFIX] Correct picsecond times to correct second values\n\n## 0.4.0 / 2015-09-21\n\n### Changes:\n* [CHANGE] Limit `events_statements` to recently used\n* [FEATURE] Add `digest_text` mapping metric\n* [IMPROVEMENT] General refactoring\n\n## 0.3.0 / 2015-08-31\n\n### BREAKING CHANGES:\n* Most metrics have been prefixed with Prometheus subsystem names to avoid conflicts between different collection methods.\n\n### Changes:\n* [BUGFIX] Separate `slave_status` and `global_status` into separate subsystems.\n* [IMPROVEMENT] Refactor metrics creation.\n* [IMPROVEMENT] Add support for `performance_schema.table_io_waits_summary_by_table` collection.\n* [IMPROVEMENT] Add support for `performance_schema.table_io_waits_summary_by_index_usage` collection.\n* [IMPROVEMENT] Add support for `performance_schema.events_statements_summary_by_digest` collection.\n* [IMPROVEMENT] Add support for Percona userstats output collection.\n* [IMPROVEMENT] Add support for `auto_increment` column metrics collection.\n* [IMPROVEMENT] Add support for `SHOW GLOBAL VARIABLES` metrics collection.\n\n## 0.2.0 / 2015-06-24\n\n### BREAKING CHANGES:\n* Logging-related flags have changed. Metric names have changed.\n\n### Changes:\n* [IMPROVEMENT] Add Docker support.\n* [CHANGE] Switch logging to Prometheus' logging library.\n* [BUGFIX] Fix slave status parsing.\n* [BUGFIX] Fix truncated numbers.\n* [CHANGE] Reorganize metrics names and types.\n\n## 0.1.0 / 2015-05-05\n\n### Initial release\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 0.1484375,
          "content": "# Prometheus Community Code of Conduct\n\nPrometheus follows the [CNCF Code of Conduct](https://github.com/cncf/foundation/blob/main/code-of-conduct.md).\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.982421875,
          "content": "# Contributing\n\nPrometheus uses GitHub to manage reviews of pull requests.\n\n* If you have a trivial fix or improvement, go ahead and create a pull request,\n  addressing (with `@...`) the maintainer of this repository (see\n  [MAINTAINERS.md](MAINTAINERS.md)) in the description of the pull request.\n\n* If you plan to do something more involved, first discuss your ideas\n  on our [mailing list](https://groups.google.com/forum/?fromgroups#!forum/prometheus-developers).\n  This will avoid unnecessary work and surely give you and us a good deal\n  of inspiration.\n\n* Relevant coding style guidelines are the [Go Code Review\n  Comments](https://code.google.com/p/go-wiki/wiki/CodeReviewComments)\n  and the _Formatting and style_ section of Peter Bourgon's [Go: Best\n  Practices for Production\n  Environments](http://peter.bourgon.org/go-in-production/#formatting-and-style).\n\n\n## Local setup\n\nThe easiest way to make a local development setup is to use Docker Compose.\n\n```\ndocker-compose up\nmake\nmake test\n```\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.33203125,
          "content": "ARG ARCH=\"amd64\"\nARG OS=\"linux\"\nFROM quay.io/prometheus/busybox-${OS}-${ARCH}:latest\nLABEL maintainer=\"The Prometheus Authors <prometheus-developers@googlegroups.com>\"\n\nARG ARCH=\"amd64\"\nARG OS=\"linux\"\nCOPY .build/${OS}-${ARCH}/mysqld_exporter /bin/mysqld_exporter\n\nEXPOSE      9104\nUSER        nobody\nENTRYPOINT  [ \"/bin/mysqld_exporter\" ]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MAINTAINERS.md",
          "type": "blob",
          "size": 0.03125,
          "content": "* Ben Kochie <superq@gmail.com>\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.9716796875,
          "content": "# Copyright 2015 The Prometheus Authors\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Needs to be defined before including Makefile.common to auto-generate targets\nDOCKER_ARCHS ?= amd64 armv7 arm64\n\nall: vet\n\ninclude Makefile.common\n\nSTATICCHECK_IGNORE =\n\nDOCKER_IMAGE_NAME ?= mysqld-exporter\n\n.PHONY: test-docker-single-exporter\ntest-docker-single-exporter:\n\t@echo \">> testing docker image for single exporter\"\n\t./test_image.sh \"$(DOCKER_IMAGE_NAME):$(DOCKER_IMAGE_TAG)\" 9104\n\n.PHONY: test-docker\n"
        },
        {
          "name": "Makefile.common",
          "type": "blob",
          "size": 9.1123046875,
          "content": "# Copyright 2018 The Prometheus Authors\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\n# A common Makefile that includes rules to be reused in different prometheus projects.\n# !!! Open PRs only against the prometheus/prometheus/Makefile.common repository!\n\n# Example usage :\n# Create the main Makefile in the root project directory.\n# include Makefile.common\n# customTarget:\n# \t@echo \">> Running customTarget\"\n#\n\n# Ensure GOBIN is not set during build so that promu is installed to the correct path\nunexport GOBIN\n\nGO           ?= go\nGOFMT        ?= $(GO)fmt\nFIRST_GOPATH := $(firstword $(subst :, ,$(shell $(GO) env GOPATH)))\nGOOPTS       ?=\nGOHOSTOS     ?= $(shell $(GO) env GOHOSTOS)\nGOHOSTARCH   ?= $(shell $(GO) env GOHOSTARCH)\n\nGO_VERSION        ?= $(shell $(GO) version)\nGO_VERSION_NUMBER ?= $(word 3, $(GO_VERSION))\nPRE_GO_111        ?= $(shell echo $(GO_VERSION_NUMBER) | grep -E 'go1\\.(10|[0-9])\\.')\n\nPROMU        := $(FIRST_GOPATH)/bin/promu\npkgs          = ./...\n\nifeq (arm, $(GOHOSTARCH))\n\tGOHOSTARM ?= $(shell GOARM= $(GO) env GOARM)\n\tGO_BUILD_PLATFORM ?= $(GOHOSTOS)-$(GOHOSTARCH)v$(GOHOSTARM)\nelse\n\tGO_BUILD_PLATFORM ?= $(GOHOSTOS)-$(GOHOSTARCH)\nendif\n\nGOTEST := $(GO) test\nGOTEST_DIR :=\nifneq ($(CIRCLE_JOB),)\nifneq ($(shell command -v gotestsum 2> /dev/null),)\n\tGOTEST_DIR := test-results\n\tGOTEST := gotestsum --junitfile $(GOTEST_DIR)/unit-tests.xml --\nendif\nendif\n\nPROMU_VERSION ?= 0.17.0\nPROMU_URL     := https://github.com/prometheus/promu/releases/download/v$(PROMU_VERSION)/promu-$(PROMU_VERSION).$(GO_BUILD_PLATFORM).tar.gz\n\nSKIP_GOLANGCI_LINT :=\nGOLANGCI_LINT :=\nGOLANGCI_LINT_OPTS ?=\nGOLANGCI_LINT_VERSION ?= v1.62.0\n# golangci-lint only supports linux, darwin and windows platforms on i386/amd64/arm64.\n# windows isn't included here because of the path separator being different.\nifeq ($(GOHOSTOS),$(filter $(GOHOSTOS),linux darwin))\n\tifeq ($(GOHOSTARCH),$(filter $(GOHOSTARCH),amd64 i386 arm64))\n\t\t# If we're in CI and there is an Actions file, that means the linter\n\t\t# is being run in Actions, so we don't need to run it here.\n\t\tifneq (,$(SKIP_GOLANGCI_LINT))\n\t\t\tGOLANGCI_LINT :=\n\t\telse ifeq (,$(CIRCLE_JOB))\n\t\t\tGOLANGCI_LINT := $(FIRST_GOPATH)/bin/golangci-lint\n\t\telse ifeq (,$(wildcard .github/workflows/golangci-lint.yml))\n\t\t\tGOLANGCI_LINT := $(FIRST_GOPATH)/bin/golangci-lint\n\t\tendif\n\tendif\nendif\n\nPREFIX                  ?= $(shell pwd)\nBIN_DIR                 ?= $(shell pwd)\nDOCKER_IMAGE_TAG        ?= $(subst /,-,$(shell git rev-parse --abbrev-ref HEAD))\nDOCKERFILE_PATH         ?= ./Dockerfile\nDOCKERBUILD_CONTEXT     ?= ./\nDOCKER_REPO             ?= prom\n\nDOCKER_ARCHS            ?= amd64\n\nBUILD_DOCKER_ARCHS = $(addprefix common-docker-,$(DOCKER_ARCHS))\nPUBLISH_DOCKER_ARCHS = $(addprefix common-docker-publish-,$(DOCKER_ARCHS))\nTAG_DOCKER_ARCHS = $(addprefix common-docker-tag-latest-,$(DOCKER_ARCHS))\n\nSANITIZED_DOCKER_IMAGE_TAG := $(subst +,-,$(DOCKER_IMAGE_TAG))\n\nifeq ($(GOHOSTARCH),amd64)\n        ifeq ($(GOHOSTOS),$(filter $(GOHOSTOS),linux freebsd darwin windows))\n                # Only supported on amd64\n                test-flags := -race\n        endif\nendif\n\n# This rule is used to forward a target like \"build\" to \"common-build\".  This\n# allows a new \"build\" target to be defined in a Makefile which includes this\n# one and override \"common-build\" without override warnings.\n%: common-% ;\n\n.PHONY: common-all\ncommon-all: precheck style check_license lint yamllint unused build test\n\n.PHONY: common-style\ncommon-style:\n\t@echo \">> checking code style\"\n\t@fmtRes=$$($(GOFMT) -d $$(find . -path ./vendor -prune -o -name '*.go' -print)); \\\n\tif [ -n \"$${fmtRes}\" ]; then \\\n\t\techo \"gofmt checking failed!\"; echo \"$${fmtRes}\"; echo; \\\n\t\techo \"Please ensure you are using $$($(GO) version) for formatting code.\"; \\\n\t\texit 1; \\\n\tfi\n\n.PHONY: common-check_license\ncommon-check_license:\n\t@echo \">> checking license header\"\n\t@licRes=$$(for file in $$(find . -type f -iname '*.go' ! -path './vendor/*') ; do \\\n               awk 'NR<=3' $$file | grep -Eq \"(Copyright|generated|GENERATED)\" || echo $$file; \\\n       done); \\\n       if [ -n \"$${licRes}\" ]; then \\\n               echo \"license header checking failed:\"; echo \"$${licRes}\"; \\\n               exit 1; \\\n       fi\n\n.PHONY: common-deps\ncommon-deps:\n\t@echo \">> getting dependencies\"\n\t$(GO) mod download\n\n.PHONY: update-go-deps\nupdate-go-deps:\n\t@echo \">> updating Go dependencies\"\n\t@for m in $$($(GO) list -mod=readonly -m -f '{{ if and (not .Indirect) (not .Main)}}{{.Path}}{{end}}' all); do \\\n\t\t$(GO) get -d $$m; \\\n\tdone\n\t$(GO) mod tidy\n\n.PHONY: common-test-short\ncommon-test-short: $(GOTEST_DIR)\n\t@echo \">> running short tests\"\n\t$(GOTEST) -short $(GOOPTS) $(pkgs)\n\n.PHONY: common-test\ncommon-test: $(GOTEST_DIR)\n\t@echo \">> running all tests\"\n\t$(GOTEST) $(test-flags) $(GOOPTS) $(pkgs)\n\n$(GOTEST_DIR):\n\t@mkdir -p $@\n\n.PHONY: common-format\ncommon-format:\n\t@echo \">> formatting code\"\n\t$(GO) fmt $(pkgs)\n\n.PHONY: common-vet\ncommon-vet:\n\t@echo \">> vetting code\"\n\t$(GO) vet $(GOOPTS) $(pkgs)\n\n.PHONY: common-lint\ncommon-lint: $(GOLANGCI_LINT)\nifdef GOLANGCI_LINT\n\t@echo \">> running golangci-lint\"\n\t$(GOLANGCI_LINT) run $(GOLANGCI_LINT_OPTS) $(pkgs)\nendif\n\n.PHONY: common-lint-fix\ncommon-lint-fix: $(GOLANGCI_LINT)\nifdef GOLANGCI_LINT\n\t@echo \">> running golangci-lint fix\"\n\t$(GOLANGCI_LINT) run --fix $(GOLANGCI_LINT_OPTS) $(pkgs)\nendif\n\n.PHONY: common-yamllint\ncommon-yamllint:\n\t@echo \">> running yamllint on all YAML files in the repository\"\nifeq (, $(shell command -v yamllint 2> /dev/null))\n\t@echo \"yamllint not installed so skipping\"\nelse\n\tyamllint .\nendif\n\n# For backward-compatibility.\n.PHONY: common-staticcheck\ncommon-staticcheck: lint\n\n.PHONY: common-unused\ncommon-unused:\n\t@echo \">> running check for unused/missing packages in go.mod\"\n\t$(GO) mod tidy\n\t@git diff --exit-code -- go.sum go.mod\n\n.PHONY: common-build\ncommon-build: promu\n\t@echo \">> building binaries\"\n\t$(PROMU) build --prefix $(PREFIX) $(PROMU_BINARIES)\n\n.PHONY: common-tarball\ncommon-tarball: promu\n\t@echo \">> building release tarball\"\n\t$(PROMU) tarball --prefix $(PREFIX) $(BIN_DIR)\n\n.PHONY: common-docker-repo-name\ncommon-docker-repo-name:\n\t@echo \"$(DOCKER_REPO)/$(DOCKER_IMAGE_NAME)\"\n\n.PHONY: common-docker $(BUILD_DOCKER_ARCHS)\ncommon-docker: $(BUILD_DOCKER_ARCHS)\n$(BUILD_DOCKER_ARCHS): common-docker-%:\n\tdocker build -t \"$(DOCKER_REPO)/$(DOCKER_IMAGE_NAME)-linux-$*:$(SANITIZED_DOCKER_IMAGE_TAG)\" \\\n\t\t-f $(DOCKERFILE_PATH) \\\n\t\t--build-arg ARCH=\"$*\" \\\n\t\t--build-arg OS=\"linux\" \\\n\t\t$(DOCKERBUILD_CONTEXT)\n\n.PHONY: common-docker-publish $(PUBLISH_DOCKER_ARCHS)\ncommon-docker-publish: $(PUBLISH_DOCKER_ARCHS)\n$(PUBLISH_DOCKER_ARCHS): common-docker-publish-%:\n\tdocker push \"$(DOCKER_REPO)/$(DOCKER_IMAGE_NAME)-linux-$*:$(SANITIZED_DOCKER_IMAGE_TAG)\"\n\nDOCKER_MAJOR_VERSION_TAG = $(firstword $(subst ., ,$(shell cat VERSION)))\n.PHONY: common-docker-tag-latest $(TAG_DOCKER_ARCHS)\ncommon-docker-tag-latest: $(TAG_DOCKER_ARCHS)\n$(TAG_DOCKER_ARCHS): common-docker-tag-latest-%:\n\tdocker tag \"$(DOCKER_REPO)/$(DOCKER_IMAGE_NAME)-linux-$*:$(SANITIZED_DOCKER_IMAGE_TAG)\" \"$(DOCKER_REPO)/$(DOCKER_IMAGE_NAME)-linux-$*:latest\"\n\tdocker tag \"$(DOCKER_REPO)/$(DOCKER_IMAGE_NAME)-linux-$*:$(SANITIZED_DOCKER_IMAGE_TAG)\" \"$(DOCKER_REPO)/$(DOCKER_IMAGE_NAME)-linux-$*:v$(DOCKER_MAJOR_VERSION_TAG)\"\n\n.PHONY: common-docker-manifest\ncommon-docker-manifest:\n\tDOCKER_CLI_EXPERIMENTAL=enabled docker manifest create -a \"$(DOCKER_REPO)/$(DOCKER_IMAGE_NAME):$(SANITIZED_DOCKER_IMAGE_TAG)\" $(foreach ARCH,$(DOCKER_ARCHS),$(DOCKER_REPO)/$(DOCKER_IMAGE_NAME)-linux-$(ARCH):$(SANITIZED_DOCKER_IMAGE_TAG))\n\tDOCKER_CLI_EXPERIMENTAL=enabled docker manifest push \"$(DOCKER_REPO)/$(DOCKER_IMAGE_NAME):$(SANITIZED_DOCKER_IMAGE_TAG)\"\n\n.PHONY: promu\npromu: $(PROMU)\n\n$(PROMU):\n\t$(eval PROMU_TMP := $(shell mktemp -d))\n\tcurl -s -L $(PROMU_URL) | tar -xvzf - -C $(PROMU_TMP)\n\tmkdir -p $(FIRST_GOPATH)/bin\n\tcp $(PROMU_TMP)/promu-$(PROMU_VERSION).$(GO_BUILD_PLATFORM)/promu $(FIRST_GOPATH)/bin/promu\n\trm -r $(PROMU_TMP)\n\n.PHONY: proto\nproto:\n\t@echo \">> generating code from proto files\"\n\t@./scripts/genproto.sh\n\nifdef GOLANGCI_LINT\n$(GOLANGCI_LINT):\n\tmkdir -p $(FIRST_GOPATH)/bin\n\tcurl -sfL https://raw.githubusercontent.com/golangci/golangci-lint/$(GOLANGCI_LINT_VERSION)/install.sh \\\n\t\t| sed -e '/install -d/d' \\\n\t\t| sh -s -- -b $(FIRST_GOPATH)/bin $(GOLANGCI_LINT_VERSION)\nendif\n\n.PHONY: precheck\nprecheck::\n\ndefine PRECHECK_COMMAND_template =\nprecheck:: $(1)_precheck\n\nPRECHECK_COMMAND_$(1) ?= $(1) $$(strip $$(PRECHECK_OPTIONS_$(1)))\n.PHONY: $(1)_precheck\n$(1)_precheck:\n\t@if ! $$(PRECHECK_COMMAND_$(1)) 1>/dev/null 2>&1; then \\\n\t\techo \"Execution of '$$(PRECHECK_COMMAND_$(1))' command failed. Is $(1) installed?\"; \\\n\t\texit 1; \\\n\tfi\nendef\n\ngovulncheck: install-govulncheck\n\tgovulncheck ./...\n\ninstall-govulncheck:\n\tcommand -v govulncheck > /dev/null || go install golang.org/x/vuln/cmd/govulncheck@latest\n"
        },
        {
          "name": "NOTICE",
          "type": "blob",
          "size": 0.0634765625,
          "content": "Exporter for MySQL daemon.\nCopyright 2015 The Prometheus Authors\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 14.4013671875,
          "content": "# MySQL Server Exporter [![Build Status](https://travis-ci.org/prometheus/mysqld_exporter.svg)][travis]\n\n[![CircleCI](https://circleci.com/gh/prometheus/mysqld_exporter/tree/main.svg?style=shield)][circleci]\n[![Docker Repository on Quay](https://quay.io/repository/prometheus/mysqld-exporter/status)][quay]\n[![Docker Pulls](https://img.shields.io/docker/pulls/prom/mysqld-exporter.svg?maxAge=604800)][hub]\n[![Go Report Card](https://goreportcard.com/badge/github.com/prometheus/mysqld_exporter)](https://goreportcard.com/report/github.com/prometheus/mysqld_exporter)\n\nPrometheus exporter for MySQL server metrics.\n\nSupported versions:\n* MySQL >= 5.6.\n* MariaDB >= 10.3\n\nNOTE: Not all collection methods are supported on MySQL/MariaDB < 5.6\n\n## Building and running\n\n### Required Grants\n\n```sql\nCREATE USER 'exporter'@'localhost' IDENTIFIED BY 'XXXXXXXX' WITH MAX_USER_CONNECTIONS 3;\nGRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO 'exporter'@'localhost';\n```\n\nNOTE: It is recommended to set a max connection limit for the user to avoid overloading the server with monitoring scrapes under heavy load. This is not supported on all MySQL/MariaDB versions; for example, MariaDB 10.1 (provided with Ubuntu 18.04) [does _not_ support this feature](https://mariadb.com/kb/en/library/create-user/#resource-limit-options).\n\n### Build\n\n    make build\n\n### Running\n\n#####  Single exporter mode\n\nRunning using `.my.cnf` from the current directory:\n\n    ./mysqld_exporter <flags>\n\n#####  Multi-target support\n\nThis exporter supports the multi-target pattern. This allows running a single instance of this exporter for multiple MySQL targets.\n\nTo use the multi-target functionality, send an http request to the endpoint `/probe?target=foo:3306` where target is set to the DSN of the MySQL instance to scrape metrics from.\n\nTo avoid putting sensitive information like username and password in the URL, you can have multiple configurations in `config.my-cnf` file and match it by adding `&auth_module=<section>` to the request.\n \nSample config file for multiple configurations\n\n        [client]\n        user = foo\n        password = foo123\n        [client.servers]\n        user = bar\n        password = bar123\n\nOn the prometheus side you can set a scrape config as follows\n\n        - job_name: mysql # To get metrics about the mysql exporter’s targets\n          params:\n            # Not required. Will match value to child in config file. Default value is `client`.\n            auth_module: [client.servers]\n          static_configs:\n            - targets:\n              # All mysql hostnames or unix sockets to monitor.\n              - server1:3306\n              - server2:3306\n              - unix:///run/mysqld/mysqld.sock\n          relabel_configs:\n            - source_labels: [__address__]\n              target_label: __param_target\n            - source_labels: [__param_target]\n              target_label: instance\n            - target_label: __address__\n              # The mysqld_exporter host:port\n              replacement: localhost:9104\n\n#####  Flag format\nExample format for flags for version > 0.10.0:\n\n    --collect.auto_increment.columns\n    --no-collect.auto_increment.columns\n\nExample format for flags for version <= 0.10.0:\n\n    -collect.auto_increment.columns\n    -collect.auto_increment.columns=[true|false]\n\n### Collector Flags\n\nName                                                         | MySQL Version | Description\n-------------------------------------------------------------|---------------|------------------------------------------------------------------------------------\ncollect.auto_increment.columns                               | 5.1           | Collect auto_increment columns and max values from information_schema.\ncollect.binlog_size                                          | 5.1           | Collect the current size of all registered binlog files\ncollect.engine_innodb_status                                 | 5.1           | Collect from SHOW ENGINE INNODB STATUS.\ncollect.engine_tokudb_status                                 | 5.6           | Collect from SHOW ENGINE TOKUDB STATUS.\ncollect.global_status                                        | 5.1           | Collect from SHOW GLOBAL STATUS (Enabled by default)\ncollect.global_variables                                     | 5.1           | Collect from SHOW GLOBAL VARIABLES (Enabled by default)\ncollect.heartbeat                                            | 5.1           | Collect from [heartbeat](#heartbeat).\ncollect.heartbeat.database                                   | 5.1           | Database from where to collect heartbeat data. (default: heartbeat)\ncollect.heartbeat.table                                      | 5.1           | Table from where to collect heartbeat data. (default: heartbeat)\ncollect.heartbeat.utc                                        | 5.1           | Use UTC for timestamps of the current server (`pt-heartbeat` is called with `--utc`). (default: false)\ncollect.info_schema.clientstats                              | 5.5           | If running with userstat=1, set to true to collect client statistics.\ncollect.info_schema.innodb_metrics                           | 5.6           | Collect metrics from information_schema.innodb_metrics.\ncollect.info_schema.innodb_tablespaces                       | 5.7           | Collect metrics from information_schema.innodb_sys_tablespaces.\ncollect.info_schema.innodb_cmp                               | 5.5           | Collect InnoDB compressed tables metrics from information_schema.innodb_cmp.\ncollect.info_schema.innodb_cmpmem                            | 5.5           | Collect InnoDB buffer pool compression metrics from information_schema.innodb_cmpmem.\ncollect.info_schema.processlist                              | 5.1           | Collect thread state counts from information_schema.processlist.\ncollect.info_schema.processlist.min_time                     | 5.1           | Minimum time a thread must be in each state to be counted. (default: 0)\ncollect.info_schema.query_response_time                      | 5.5           | Collect query response time distribution if query_response_time_stats is ON.\ncollect.info_schema.replica_host                             | 5.6           | Collect metrics from information_schema.replica_host_status.\ncollect.info_schema.tables                                   | 5.1           | Collect metrics from information_schema.tables.\ncollect.info_schema.tables.databases                         | 5.1           | The list of databases to collect table stats for, or '`*`' for all.\ncollect.info_schema.tablestats                               | 5.1           | If running with userstat=1, set to true to collect table statistics.\ncollect.info_schema.schemastats                              | 5.1           | If running with userstat=1, set to true to collect schema statistics\ncollect.info_schema.userstats                                | 5.1           | If running with userstat=1, set to true to collect user statistics.\ncollect.mysql.user                                           | 5.5             | Collect data from mysql.user table\ncollect.perf_schema.eventsstatements                         | 5.6           | Collect metrics from performance_schema.events_statements_summary_by_digest.\ncollect.perf_schema.eventsstatements.digest_text_limit       | 5.6           | Maximum length of the normalized statement text. (default: 120)\ncollect.perf_schema.eventsstatements.limit                   | 5.6           | Limit the number of events statements digests by response time. (default: 250)\ncollect.perf_schema.eventsstatements.timelimit               | 5.6           | Limit how old the 'last_seen' events statements can be, in seconds. (default: 86400)\ncollect.perf_schema.eventsstatementssum                      | 5.7           | Collect metrics from performance_schema.events_statements_summary_by_digest summed.\ncollect.perf_schema.eventswaits                              | 5.5           | Collect metrics from performance_schema.events_waits_summary_global_by_event_name.\ncollect.perf_schema.file_events                              | 5.6           | Collect metrics from performance_schema.file_summary_by_event_name.\ncollect.perf_schema.file_instances                           | 5.5           | Collect metrics from performance_schema.file_summary_by_instance.\ncollect.perf_schema.file_instances.remove_prefix             | 5.5           | Remove path prefix in performance_schema.file_summary_by_instance.\ncollect.perf_schema.indexiowaits                             | 5.6           | Collect metrics from performance_schema.table_io_waits_summary_by_index_usage.\ncollect.perf_schema.memory_events                            | 5.7           | Collect metrics from performance_schema.memory_summary_global_by_event_name.\ncollect.perf_schema.memory_events.remove_prefix              | 5.7           | Remove instrument prefix in performance_schema.memory_summary_global_by_event_name.\ncollect.perf_schema.tableiowaits                             | 5.6           | Collect metrics from performance_schema.table_io_waits_summary_by_table.\ncollect.perf_schema.tablelocks                               | 5.6           | Collect metrics from performance_schema.table_lock_waits_summary_by_table.\ncollect.perf_schema.replication_group_members                | 5.7           | Collect metrics from performance_schema.replication_group_members.\ncollect.perf_schema.replication_group_member_stats           | 5.7           | Collect metrics from performance_schema.replication_group_member_stats.\ncollect.perf_schema.replication_applier_status_by_worker     | 5.7           | Collect metrics from performance_schema.replication_applier_status_by_worker.\ncollect.slave_status                                         | 5.1           | Collect from SHOW SLAVE STATUS (Enabled by default)\ncollect.slave_hosts                                          | 5.1           | Collect from SHOW SLAVE HOSTS\ncollect.sys.user_summary                                     | 5.7           | Collect metrics from sys.x$user_summary (disabled by default).\n\n\n### General Flags\nName                                       | Description\n-------------------------------------------|--------------------------------------------------------------------------------------------------\nmysqld.address                             | Hostname and port used for connecting to MySQL server, format: `host:port`. (default: `locahost:3306`)\nmysqld.username                            | Username to be used for connecting to MySQL Server\nconfig.my-cnf                              | Path to .my.cnf file to read MySQL credentials from. (default: `~/.my.cnf`)\nlog.level                                  | Logging verbosity (default: info)\nexporter.lock_wait_timeout                 | Set a lock_wait_timeout (in seconds) on the connection to avoid long metadata locking. (default: 2)\nexporter.log_slow_filter                   | Add a log_slow_filter to avoid slow query logging of scrapes.  NOTE: Not supported by Oracle MySQL.\ntls.insecure-skip-verify                   | Ignore tls verification errors.\nweb.config.file                            | Path to a [web configuration file](#tls-and-basic-authentication)\nweb.listen-address                         | Address to listen on for web interface and telemetry.\nweb.telemetry-path                         | Path under which to expose metrics.\nversion                                    | Print the version information.\n\n### Environment Variables\nName                                       | Description\n-------------------------------------------|--------------------------------------------------------------------------------------------------\nMYSQLD_EXPORTER_PASSWORD                   | Password to be used for connecting to MySQL Server\n\n### Configuration precedence\n\nIf you have configured cli with both `mysqld` flags and a valid configuration file, the options in the configuration file will override the flags for `client` section.\n\n## TLS and basic authentication\n\nThe MySQLd Exporter supports TLS and basic authentication.\n\nTo use TLS and/or basic authentication, you need to pass a configuration file\nusing the `--web.config.file` parameter. The format of the file is described\n[in the exporter-toolkit repository](https://github.com/prometheus/exporter-toolkit/blob/master/docs/web-configuration.md).\n\n## Customizing Configuration for a SSL Connection\n\nIf The MySQL server supports SSL, you may need to specify a CA truststore to verify the server's chain-of-trust. You may also need to specify a SSL keypair for the client side of the SSL connection. To configure the mysqld exporter to use a custom CA certificate, add the following to the mysql cnf file:\n\n```\nssl-ca=/path/to/ca/file\n```\n\nTo specify the client SSL keypair, add the following to the cnf.\n\n```\nssl-key=/path/to/ssl/client/key\nssl-cert=/path/to/ssl/client/cert\n```\n\n\n## Using Docker\n\nYou can deploy this exporter using the [prom/mysqld-exporter](https://hub.docker.com/r/prom/mysqld-exporter/) Docker image.\n\nFor example:\n\n```bash\ndocker network create my-mysql-network\ndocker pull prom/mysqld-exporter\n\ndocker run -d \\\n  -p 9104:9104 \\\n  -v /home/user/user_my.cnf:/.my.cnf \\\n  --network my-mysql-network  \\\n  prom/mysqld-exporter\n```\n\n## heartbeat\n\nWith `collect.heartbeat` enabled, mysqld_exporter will scrape replication delay\nmeasured by heartbeat mechanisms. [Pt-heartbeat][pth] is the\nreference heartbeat implementation supported.\n\n[pth]:https://www.percona.com/doc/percona-toolkit/2.2/pt-heartbeat.html\n\n\n## Filtering enabled collectors\n\nThe `mysqld_exporter` will expose all metrics from enabled collectors by default. This is the recommended way to collect metrics to avoid errors when comparing metrics of different families.\n\nFor advanced use the `mysqld_exporter` can be passed an optional list of collectors to filter metrics. The `collect[]` parameter may be used multiple times.  In Prometheus configuration you can use this syntax under the [scrape config](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#<scrape_config>).\n\n```yaml\nparams:\n  collect[]:\n  - foo\n  - bar\n```\n\nThis can be useful for having different Prometheus servers collect specific metrics from targets.\n\n## Example Rules\n\nThere is a set of sample rules, alerts and dashboards available in the [mysqld-mixin](mysqld-mixin/)\n\n[circleci]: https://circleci.com/gh/prometheus/mysqld_exporter\n[hub]: https://hub.docker.com/r/prom/mysqld-exporter/\n[travis]: https://travis-ci.org/prometheus/mysqld_exporter\n[quay]: https://quay.io/repository/prometheus/mysqld-exporter\n[parsetime]: https://github.com/go-sql-driver/mysql#parsetime\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.16796875,
          "content": "# Reporting a security issue\n\nThe Prometheus security policy, including how to report vulnerabilities, can be\nfound here:\n\n<https://prometheus.io/docs/operating/security/>\n"
        },
        {
          "name": "VERSION",
          "type": "blob",
          "size": 0.0068359375,
          "content": "0.16.0\n"
        },
        {
          "name": "collector",
          "type": "tree",
          "content": null
        },
        {
          "name": "config",
          "type": "tree",
          "content": null
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 1.6962890625,
          "content": "module github.com/prometheus/mysqld_exporter\n\ngo 1.22\n\nrequire (\n\tgithub.com/DATA-DOG/go-sqlmock v1.5.2\n\tgithub.com/alecthomas/kingpin/v2 v2.4.0\n\tgithub.com/blang/semver/v4 v4.0.0\n\tgithub.com/go-sql-driver/mysql v1.8.1\n\tgithub.com/google/go-cmp v0.6.0\n\tgithub.com/google/uuid v1.6.0\n\tgithub.com/prometheus/client_golang v1.20.5\n\tgithub.com/prometheus/client_model v0.6.1\n\tgithub.com/prometheus/common v0.61.0\n\tgithub.com/prometheus/exporter-toolkit v0.13.2\n\tgithub.com/smartystreets/goconvey v1.8.1\n\tgopkg.in/ini.v1 v1.67.0\n)\n\nrequire (\n\tfilippo.io/edwards25519 v1.1.0 // indirect\n\tgithub.com/alecthomas/units v0.0.0-20211218093645-b94a6e3cc137 // indirect\n\tgithub.com/beorn7/perks v1.0.1 // indirect\n\tgithub.com/cespare/xxhash/v2 v2.3.0 // indirect\n\tgithub.com/coreos/go-systemd/v22 v22.5.0 // indirect\n\tgithub.com/gopherjs/gopherjs v1.17.2 // indirect\n\tgithub.com/jpillora/backoff v1.0.0 // indirect\n\tgithub.com/jtolds/gls v4.20.0+incompatible // indirect\n\tgithub.com/klauspost/compress v1.17.9 // indirect\n\tgithub.com/mdlayher/socket v0.4.1 // indirect\n\tgithub.com/mdlayher/vsock v1.2.1 // indirect\n\tgithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 // indirect\n\tgithub.com/mwitkow/go-conntrack v0.0.0-20190716064945-2f068394615f // indirect\n\tgithub.com/prometheus/procfs v0.15.1 // indirect\n\tgithub.com/smarty/assertions v1.15.0 // indirect\n\tgithub.com/xhit/go-str2duration/v2 v2.1.0 // indirect\n\tgolang.org/x/crypto v0.31.0 // indirect\n\tgolang.org/x/net v0.32.0 // indirect\n\tgolang.org/x/oauth2 v0.24.0 // indirect\n\tgolang.org/x/sync v0.10.0 // indirect\n\tgolang.org/x/sys v0.28.0 // indirect\n\tgolang.org/x/text v0.21.0 // indirect\n\tgoogle.golang.org/protobuf v1.35.2 // indirect\n\tgopkg.in/yaml.v2 v2.4.0 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 8.3896484375,
          "content": "filippo.io/edwards25519 v1.1.0 h1:FNf4tywRC1HmFuKW5xopWpigGjJKiJSV0Cqo0cJWDaA=\nfilippo.io/edwards25519 v1.1.0/go.mod h1:BxyFTGdWcka3PhytdK4V28tE5sGfRvvvRV7EaN4VDT4=\ngithub.com/DATA-DOG/go-sqlmock v1.5.2 h1:OcvFkGmslmlZibjAjaHm3L//6LiuBgolP7OputlJIzU=\ngithub.com/DATA-DOG/go-sqlmock v1.5.2/go.mod h1:88MAG/4G7SMwSE3CeA0ZKzrT5CiOU3OJ+JlNzwDqpNU=\ngithub.com/alecthomas/kingpin/v2 v2.4.0 h1:f48lwail6p8zpO1bC4TxtqACaGqHYA22qkHjHpqDjYY=\ngithub.com/alecthomas/kingpin/v2 v2.4.0/go.mod h1:0gyi0zQnjuFk8xrkNKamJoyUo382HRL7ATRpFZCw6tE=\ngithub.com/alecthomas/units v0.0.0-20211218093645-b94a6e3cc137 h1:s6gZFSlWYmbqAuRjVTiNNhvNRfY2Wxp9nhfyel4rklc=\ngithub.com/alecthomas/units v0.0.0-20211218093645-b94a6e3cc137/go.mod h1:OMCwj8VM1Kc9e19TLln2VL61YJF0x1XFtfdL4JdbSyE=\ngithub.com/beorn7/perks v1.0.1 h1:VlbKKnNfV8bJzeqoa4cOKqO6bYr3WgKZxO8Z16+hsOM=\ngithub.com/beorn7/perks v1.0.1/go.mod h1:G2ZrVWU2WbWT9wwq4/hrbKbnv/1ERSJQ0ibhJ6rlkpw=\ngithub.com/blang/semver/v4 v4.0.0 h1:1PFHFE6yCCTv8C1TeyNNarDzntLi7wMI5i/pzqYIsAM=\ngithub.com/blang/semver/v4 v4.0.0/go.mod h1:IbckMUScFkM3pff0VJDNKRiT6TG/YpiHIM2yvyW5YoQ=\ngithub.com/cespare/xxhash/v2 v2.3.0 h1:UL815xU9SqsFlibzuggzjXhog7bL6oX9BbNZnL2UFvs=\ngithub.com/cespare/xxhash/v2 v2.3.0/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/coreos/go-systemd/v22 v22.5.0 h1:RrqgGjYQKalulkV8NGVIfkXQf6YYmOyiJKk8iXXhfZs=\ngithub.com/coreos/go-systemd/v22 v22.5.0/go.mod h1:Y58oyj3AT4RCenI/lSvhwexgC+NSVTIJ3seZv2GcEnc=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/go-sql-driver/mysql v1.8.1 h1:LedoTUt/eveggdHS9qUFC1EFSa8bU2+1pZjSRpvNJ1Y=\ngithub.com/go-sql-driver/mysql v1.8.1/go.mod h1:wEBSXgmK//2ZFJyE+qWnIsVGmvmEKlqwuVSjsCm7DZg=\ngithub.com/godbus/dbus/v5 v5.0.4/go.mod h1:xhWf0FNVPg57R7Z0UbKHbJfkEywrmjJnf7w5xrFpKfA=\ngithub.com/google/go-cmp v0.6.0 h1:ofyhxvXcZhMsU5ulbFiLKl/XBFqE1GSq7atu8tAmTRI=\ngithub.com/google/go-cmp v0.6.0/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/google/uuid v1.6.0 h1:NIvaJDMOsjHA8n1jAhLSgzrAzy1Hgr+hNrb57e+94F0=\ngithub.com/google/uuid v1.6.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/gopherjs/gopherjs v1.17.2 h1:fQnZVsXk8uxXIStYb0N4bGk7jeyTalG/wsZjQ25dO0g=\ngithub.com/gopherjs/gopherjs v1.17.2/go.mod h1:pRRIvn/QzFLrKfvEz3qUuEhtE/zLCWfreZ6J5gM2i+k=\ngithub.com/jpillora/backoff v1.0.0 h1:uvFg412JmmHBHw7iwprIxkPMI+sGQ4kzOWsMeHnm2EA=\ngithub.com/jpillora/backoff v1.0.0/go.mod h1:J/6gKK9jxlEcS3zixgDgUAsiuZ7yrSoa/FX5e0EB2j4=\ngithub.com/jtolds/gls v4.20.0+incompatible h1:xdiiI2gbIgH/gLH7ADydsJ1uDOEzR8yvV7C0MuV77Wo=\ngithub.com/jtolds/gls v4.20.0+incompatible/go.mod h1:QJZ7F/aHp+rZTRtaJ1ow/lLfFfVYBRgL+9YlvaHOwJU=\ngithub.com/kisielk/sqlstruct v0.0.0-20201105191214-5f3e10d3ab46/go.mod h1:yyMNCyc/Ib3bDTKd379tNMpB/7/H5TjM2Y9QJ5THLbE=\ngithub.com/klauspost/compress v1.17.9 h1:6KIumPrER1LHsvBVuDa0r5xaG0Es51mhhB9BQB2qeMA=\ngithub.com/klauspost/compress v1.17.9/go.mod h1:Di0epgTjJY877eYKx5yC51cX2A2Vl2ibi7bDH9ttBbw=\ngithub.com/kr/pretty v0.3.1 h1:flRD4NNwYAUpkphVc1HcthR4KEIFJ65n8Mw5qdRn3LE=\ngithub.com/kr/pretty v0.3.1/go.mod h1:hoEshYVHaxMs3cyo3Yncou5ZscifuDolrwPKZanG3xk=\ngithub.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=\ngithub.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=\ngithub.com/kylelemons/godebug v1.1.0 h1:RPNrshWIDI6G2gRW9EHilWtl7Z6Sb1BR0xunSBf0SNc=\ngithub.com/kylelemons/godebug v1.1.0/go.mod h1:9/0rRGxNHcop5bhtWyNeEfOS8JIWk580+fNqagV/RAw=\ngithub.com/mdlayher/socket v0.4.1 h1:eM9y2/jlbs1M615oshPQOHZzj6R6wMT7bX5NPiQvn2U=\ngithub.com/mdlayher/socket v0.4.1/go.mod h1:cAqeGjoufqdxWkD7DkpyS+wcefOtmu5OQ8KuoJGIReA=\ngithub.com/mdlayher/vsock v1.2.1 h1:pC1mTJTvjo1r9n9fbm7S1j04rCgCzhCOS5DY0zqHlnQ=\ngithub.com/mdlayher/vsock v1.2.1/go.mod h1:NRfCibel++DgeMD8z/hP+PPTjlNJsdPOmxcnENvE+SE=\ngithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 h1:C3w9PqII01/Oq1c1nUAm88MOHcQC9l5mIlSMApZMrHA=\ngithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822/go.mod h1:+n7T8mK8HuQTcFwEeznm/DIxMOiR9yIdICNftLE1DvQ=\ngithub.com/mwitkow/go-conntrack v0.0.0-20190716064945-2f068394615f h1:KUppIJq7/+SVif2QVs3tOP0zanoHgBEVAwHxUSIzRqU=\ngithub.com/mwitkow/go-conntrack v0.0.0-20190716064945-2f068394615f/go.mod h1:qRWi+5nqEBWmkhHvq77mSJWrCKwh8bxhgT7d/eI7P4U=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/prometheus/client_golang v1.20.5 h1:cxppBPuYhUnsO6yo/aoRol4L7q7UFfdm+bR9r+8l63Y=\ngithub.com/prometheus/client_golang v1.20.5/go.mod h1:PIEt8X02hGcP8JWbeHyeZ53Y/jReSnHgO035n//V5WE=\ngithub.com/prometheus/client_model v0.6.1 h1:ZKSh/rekM+n3CeS952MLRAdFwIKqeY8b62p8ais2e9E=\ngithub.com/prometheus/client_model v0.6.1/go.mod h1:OrxVMOVHjw3lKMa8+x6HeMGkHMQyHDk9E3jmP2AmGiY=\ngithub.com/prometheus/common v0.61.0 h1:3gv/GThfX0cV2lpO7gkTUwZru38mxevy90Bj8YFSRQQ=\ngithub.com/prometheus/common v0.61.0/go.mod h1:zr29OCN/2BsJRaFwG8QOBr41D6kkchKbpeNH7pAjb/s=\ngithub.com/prometheus/exporter-toolkit v0.13.2 h1:Z02fYtbqTMy2i/f+xZ+UK5jy/bl1Ex3ndzh06T/Q9DQ=\ngithub.com/prometheus/exporter-toolkit v0.13.2/go.mod h1:tCqnfx21q6qN1KA4U3Bfb8uWzXfijIrJz3/kTIqMV7g=\ngithub.com/prometheus/procfs v0.15.1 h1:YagwOFzUgYfKKHX6Dr+sHT7km/hxC76UB0learggepc=\ngithub.com/prometheus/procfs v0.15.1/go.mod h1:fB45yRUv8NstnjriLhBQLuOUt+WW4BsoGhij/e3PBqk=\ngithub.com/rogpeppe/go-internal v1.10.0 h1:TMyTOH3F/DB16zRVcYyreMH6GnZZrwQVAoYjRBZyWFQ=\ngithub.com/rogpeppe/go-internal v1.10.0/go.mod h1:UQnix2H7Ngw/k4C5ijL5+65zddjncjaFoBhdsK/akog=\ngithub.com/smarty/assertions v1.15.0 h1:cR//PqUBUiQRakZWqBiFFQ9wb8emQGDb0HeGdqGByCY=\ngithub.com/smarty/assertions v1.15.0/go.mod h1:yABtdzeQs6l1brC900WlRNwj6ZR55d7B+E8C6HtKdec=\ngithub.com/smartystreets/goconvey v1.8.1 h1:qGjIddxOk4grTu9JPOU31tVfq3cNdBlNa5sSznIX1xY=\ngithub.com/smartystreets/goconvey v1.8.1/go.mod h1:+/u4qLyY6x1jReYOp7GOM2FSt8aP9CzCZL03bI28W60=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/testify v1.4.0/go.mod h1:j7eGeouHqKxXV5pUuKE4zz7dFj8WfuZ+81PSLYec5m4=\ngithub.com/stretchr/testify v1.10.0 h1:Xv5erBjTwe/5IxqUQTdXv5kgmIvbHo3QQyRwhJsOfJA=\ngithub.com/stretchr/testify v1.10.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=\ngithub.com/xhit/go-str2duration/v2 v2.1.0 h1:lxklc02Drh6ynqX+DdPyp5pCKLUQpRT8bp8Ydu2Bstc=\ngithub.com/xhit/go-str2duration/v2 v2.1.0/go.mod h1:ohY8p+0f07DiV6Em5LKB0s2YpLtXVyJfNt1+BlmyAsU=\ngolang.org/x/crypto v0.31.0 h1:ihbySMvVjLAeSH1IbfcRTkD/iNscyz8rGzjF/E5hV6U=\ngolang.org/x/crypto v0.31.0/go.mod h1:kDsLvtWBEx7MV9tJOj9bnXsPbxwJQ6csT/x4KIN4Ssk=\ngolang.org/x/net v0.32.0 h1:ZqPmj8Kzc+Y6e0+skZsuACbx+wzMgo5MQsJh9Qd6aYI=\ngolang.org/x/net v0.32.0/go.mod h1:CwU0IoeOlnQQWJ6ioyFrfRuomB8GKF6KbYXZVyeXNfs=\ngolang.org/x/oauth2 v0.24.0 h1:KTBBxWqUa0ykRPLtV69rRto9TLXcqYkeswu48x/gvNE=\ngolang.org/x/oauth2 v0.24.0/go.mod h1:XYTD2NtWslqkgxebSiOHnXEap4TF09sJSc7H1sXbhtI=\ngolang.org/x/sync v0.10.0 h1:3NQrjDixjgGwUOCaF8w2+VYHv0Ve/vGYSbdkTa98gmQ=\ngolang.org/x/sync v0.10.0/go.mod h1:Czt+wKu1gCyEFDUtn0jG5QVvpJ6rzVqr5aXyt9drQfk=\ngolang.org/x/sys v0.28.0 h1:Fksou7UEQUWlKvIdsqzJmUmCX3cZuD2+P3XyyzwMhlA=\ngolang.org/x/sys v0.28.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/text v0.21.0 h1:zyQAAkrwaneQ066sspRyJaG9VNi/YJ1NfzcGB3hZ/qo=\ngolang.org/x/text v0.21.0/go.mod h1:4IBbMaMmOPCJ8SecivzSH54+73PCFmPWxNTLm+vZkEQ=\ngoogle.golang.org/protobuf v1.35.2 h1:8Ar7bF+apOIoThw1EdZl0p1oWvMqTHmpA2fRTyZO8io=\ngoogle.golang.org/protobuf v1.35.2/go.mod h1:9fA7Ob0pmnwhb644+1+CVWFRbNajQ6iRojtC/QF5bRE=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c h1:Hei/4ADfdWqJk1ZMxUNpqntNwaWcugrBjAiHlqqRiVk=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c/go.mod h1:JHkPIbrfpd72SG/EVd6muEfDQjcINNoR0C8j2r3qZ4Q=\ngopkg.in/ini.v1 v1.67.0 h1:Dgnx+6+nfE+IfzjUEISNeydPJh9AXNNsWbGP9KzCsOA=\ngopkg.in/ini.v1 v1.67.0/go.mod h1:pNLf8WUiyNEtQjuu5G5vTm06TEv9tsIgeAvK8hOrP4k=\ngopkg.in/yaml.v2 v2.2.2/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.4.0 h1:D8xgwECY7CYvx+Y2n4sBz93Jn9JRvxdiyyo8CTfuKaY=\ngopkg.in/yaml.v2 v2.4.0/go.mod h1:RDklbk79AGWmwhnvt/jBztapEOGDOx6ZbXqjP6csGnQ=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\n"
        },
        {
          "name": "mysqld-mixin",
          "type": "tree",
          "content": null
        },
        {
          "name": "mysqld_exporter.go",
          "type": "blob",
          "size": 9.9208984375,
          "content": "// Copyright 2018 The Prometheus Authors\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n// http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"log/slog\"\n\t\"net/http\"\n\t\"os\"\n\t\"strconv\"\n\t\"time\"\n\n\t\"github.com/alecthomas/kingpin/v2\"\n\t\"github.com/prometheus/client_golang/prometheus\"\n\tversioncollector \"github.com/prometheus/client_golang/prometheus/collectors/version\"\n\t\"github.com/prometheus/client_golang/prometheus/promhttp\"\n\t\"github.com/prometheus/common/promslog\"\n\t\"github.com/prometheus/common/promslog/flag\"\n\t\"github.com/prometheus/common/version\"\n\t\"github.com/prometheus/exporter-toolkit/web\"\n\twebflag \"github.com/prometheus/exporter-toolkit/web/kingpinflag\"\n\n\t\"github.com/prometheus/mysqld_exporter/collector\"\n\t\"github.com/prometheus/mysqld_exporter/config\"\n)\n\nvar (\n\tmetricsPath = kingpin.Flag(\n\t\t\"web.telemetry-path\",\n\t\t\"Path under which to expose metrics.\",\n\t).Default(\"/metrics\").String()\n\ttimeoutOffset = kingpin.Flag(\n\t\t\"timeout-offset\",\n\t\t\"Offset to subtract from timeout in seconds.\",\n\t).Default(\"0.25\").Float64()\n\tconfigMycnf = kingpin.Flag(\n\t\t\"config.my-cnf\",\n\t\t\"Path to .my.cnf file to read MySQL credentials from.\",\n\t).Default(\".my.cnf\").String()\n\tmysqldAddress = kingpin.Flag(\n\t\t\"mysqld.address\",\n\t\t\"Address to use for connecting to MySQL\",\n\t).Default(\"localhost:3306\").String()\n\tmysqldUser = kingpin.Flag(\n\t\t\"mysqld.username\",\n\t\t\"Hostname to use for connecting to MySQL\",\n\t).String()\n\ttlsInsecureSkipVerify = kingpin.Flag(\n\t\t\"tls.insecure-skip-verify\",\n\t\t\"Ignore certificate and server verification when using a tls connection.\",\n\t).Bool()\n\ttoolkitFlags = webflag.AddFlags(kingpin.CommandLine, \":9104\")\n\tc            = config.MySqlConfigHandler{\n\t\tConfig: &config.Config{},\n\t}\n)\n\n// scrapers lists all possible collection methods and if they should be enabled by default.\nvar scrapers = map[collector.Scraper]bool{\n\tcollector.ScrapeGlobalStatus{}:                        true,\n\tcollector.ScrapeGlobalVariables{}:                     true,\n\tcollector.ScrapeSlaveStatus{}:                         true,\n\tcollector.ScrapeProcesslist{}:                         false,\n\tcollector.ScrapeUser{}:                                false,\n\tcollector.ScrapeTableSchema{}:                         false,\n\tcollector.ScrapeInfoSchemaInnodbTablespaces{}:         false,\n\tcollector.ScrapeInnodbMetrics{}:                       false,\n\tcollector.ScrapeAutoIncrementColumns{}:                false,\n\tcollector.ScrapeBinlogSize{}:                          false,\n\tcollector.ScrapePerfTableIOWaits{}:                    false,\n\tcollector.ScrapePerfIndexIOWaits{}:                    false,\n\tcollector.ScrapePerfTableLockWaits{}:                  false,\n\tcollector.ScrapePerfEventsStatements{}:                false,\n\tcollector.ScrapePerfEventsStatementsSum{}:             false,\n\tcollector.ScrapePerfEventsWaits{}:                     false,\n\tcollector.ScrapePerfFileEvents{}:                      false,\n\tcollector.ScrapePerfFileInstances{}:                   false,\n\tcollector.ScrapePerfMemoryEvents{}:                    false,\n\tcollector.ScrapePerfReplicationGroupMembers{}:         false,\n\tcollector.ScrapePerfReplicationGroupMemberStats{}:     false,\n\tcollector.ScrapePerfReplicationApplierStatsByWorker{}: false,\n\tcollector.ScrapeSysUserSummary{}:                      false,\n\tcollector.ScrapeUserStat{}:                            false,\n\tcollector.ScrapeClientStat{}:                          false,\n\tcollector.ScrapeTableStat{}:                           false,\n\tcollector.ScrapeSchemaStat{}:                          false,\n\tcollector.ScrapeInnodbCmp{}:                           true,\n\tcollector.ScrapeInnodbCmpMem{}:                        true,\n\tcollector.ScrapeQueryResponseTime{}:                   true,\n\tcollector.ScrapeEngineTokudbStatus{}:                  false,\n\tcollector.ScrapeEngineInnodbStatus{}:                  false,\n\tcollector.ScrapeHeartbeat{}:                           false,\n\tcollector.ScrapeSlaveHosts{}:                          false,\n\tcollector.ScrapeReplicaHost{}:                         false,\n}\n\nfunc filterScrapers(scrapers []collector.Scraper, collectParams []string) []collector.Scraper {\n\tvar filteredScrapers []collector.Scraper\n\n\t// Check if we have some \"collect[]\" query parameters.\n\tif len(collectParams) > 0 {\n\t\tfilters := make(map[string]bool)\n\t\tfor _, param := range collectParams {\n\t\t\tfilters[param] = true\n\t\t}\n\n\t\tfor _, scraper := range scrapers {\n\t\t\tif filters[scraper.Name()] {\n\t\t\t\tfilteredScrapers = append(filteredScrapers, scraper)\n\t\t\t}\n\t\t}\n\t}\n\tif len(filteredScrapers) == 0 {\n\t\treturn scrapers\n\t}\n\treturn filteredScrapers\n}\n\nfunc getScrapeTimeoutSeconds(r *http.Request, offset float64) (float64, error) {\n\tvar timeoutSeconds float64\n\tif v := r.Header.Get(\"X-Prometheus-Scrape-Timeout-Seconds\"); v != \"\" {\n\t\tvar err error\n\t\ttimeoutSeconds, err = strconv.ParseFloat(v, 64)\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"failed to parse timeout from Prometheus header: %v\", err)\n\t\t}\n\t}\n\tif timeoutSeconds == 0 {\n\t\treturn 0, nil\n\t}\n\tif timeoutSeconds < 0 {\n\t\treturn 0, fmt.Errorf(\"timeout value from Prometheus header is invalid: %f\", timeoutSeconds)\n\t}\n\n\tif offset >= timeoutSeconds {\n\t\t// Ignore timeout offset if it doesn't leave time to scrape.\n\t\treturn 0, fmt.Errorf(\"timeout offset (%f) should be lower than prometheus scrape timeout (%f)\", offset, timeoutSeconds)\n\t} else {\n\t\t// Subtract timeout offset from timeout.\n\t\ttimeoutSeconds -= offset\n\t}\n\treturn timeoutSeconds, nil\n}\n\nfunc init() {\n\tprometheus.MustRegister(versioncollector.NewCollector(\"mysqld_exporter\"))\n}\n\nfunc newHandler(scrapers []collector.Scraper, logger *slog.Logger) http.HandlerFunc {\n\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tvar dsn string\n\t\tvar err error\n\t\ttarget := \"\"\n\t\tq := r.URL.Query()\n\t\tif q.Has(\"target\") {\n\t\t\ttarget = q.Get(\"target\")\n\t\t}\n\n\t\tcfg := c.GetConfig()\n\t\tcfgsection, ok := cfg.Sections[\"client\"]\n\t\tif !ok {\n\t\t\tlogger.Error(\"Failed to parse section [client] from config file\", \"err\", err)\n\t\t}\n\t\tif dsn, err = cfgsection.FormDSN(target); err != nil {\n\t\t\tlogger.Error(\"Failed to form dsn from section [client]\", \"err\", err)\n\t\t}\n\n\t\tcollect := q[\"collect[]\"]\n\n\t\t// Use request context for cancellation when connection gets closed.\n\t\tctx := r.Context()\n\t\t// If a timeout is configured via the Prometheus header, add it to the context.\n\t\ttimeoutSeconds, err := getScrapeTimeoutSeconds(r, *timeoutOffset)\n\t\tif err != nil {\n\t\t\tlogger.Error(\"Error getting timeout from Prometheus header\", \"err\", err)\n\t\t}\n\t\tif timeoutSeconds > 0 {\n\t\t\t// Create new timeout context with request context as parent.\n\t\t\tvar cancel context.CancelFunc\n\t\t\tctx, cancel = context.WithTimeout(ctx, time.Duration(timeoutSeconds*float64(time.Second)))\n\t\t\tdefer cancel()\n\t\t\t// Overwrite request with timeout context.\n\t\t\tr = r.WithContext(ctx)\n\t\t}\n\n\t\tfilteredScrapers := filterScrapers(scrapers, collect)\n\n\t\tregistry := prometheus.NewRegistry()\n\n\t\tregistry.MustRegister(collector.New(ctx, dsn, filteredScrapers, logger))\n\n\t\tgatherers := prometheus.Gatherers{\n\t\t\tprometheus.DefaultGatherer,\n\t\t\tregistry,\n\t\t}\n\t\t// Delegate http serving to Prometheus client library, which will call collector.Collect.\n\t\th := promhttp.HandlerFor(gatherers, promhttp.HandlerOpts{})\n\t\th.ServeHTTP(w, r)\n\t}\n}\n\nfunc main() {\n\t// Generate ON/OFF flags for all scrapers.\n\tscraperFlags := map[collector.Scraper]*bool{}\n\tfor scraper, enabledByDefault := range scrapers {\n\t\tdefaultOn := \"false\"\n\t\tif enabledByDefault {\n\t\t\tdefaultOn = \"true\"\n\t\t}\n\n\t\tf := kingpin.Flag(\n\t\t\t\"collect.\"+scraper.Name(),\n\t\t\tscraper.Help(),\n\t\t).Default(defaultOn).Bool()\n\n\t\tscraperFlags[scraper] = f\n\t}\n\n\t// Parse flags.\n\tpromslogConfig := &promslog.Config{}\n\tflag.AddFlags(kingpin.CommandLine, promslogConfig)\n\tkingpin.Version(version.Print(\"mysqld_exporter\"))\n\tkingpin.HelpFlag.Short('h')\n\tkingpin.Parse()\n\tlogger := promslog.New(promslogConfig)\n\n\tlogger.Info(\"Starting mysqld_exporter\", \"version\", version.Info())\n\tlogger.Info(\"Build context\", \"build_context\", version.BuildContext())\n\n\tvar err error\n\tif err = c.ReloadConfig(*configMycnf, *mysqldAddress, *mysqldUser, *tlsInsecureSkipVerify, logger); err != nil {\n\t\tlogger.Info(\"Error parsing host config\", \"file\", *configMycnf, \"err\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Register only scrapers enabled by flag.\n\tenabledScrapers := []collector.Scraper{}\n\tfor scraper, enabled := range scraperFlags {\n\t\tif *enabled {\n\t\t\tlogger.Info(\"Scraper enabled\", \"scraper\", scraper.Name())\n\t\t\tenabledScrapers = append(enabledScrapers, scraper)\n\t\t}\n\t}\n\thandlerFunc := newHandler(enabledScrapers, logger)\n\thttp.Handle(*metricsPath, promhttp.InstrumentMetricHandler(prometheus.DefaultRegisterer, handlerFunc))\n\tif *metricsPath != \"/\" && *metricsPath != \"\" {\n\t\tlandingConfig := web.LandingConfig{\n\t\t\tName:        \"MySQLd Exporter\",\n\t\t\tDescription: \"Prometheus Exporter for MySQL servers\",\n\t\t\tVersion:     version.Info(),\n\t\t\tLinks: []web.LandingLinks{\n\t\t\t\t{\n\t\t\t\t\tAddress: *metricsPath,\n\t\t\t\t\tText:    \"Metrics\",\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tlandingPage, err := web.NewLandingPage(landingConfig)\n\t\tif err != nil {\n\t\t\tlogger.Error(\"Error creating landing page\", \"err\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\thttp.Handle(\"/\", landingPage)\n\t}\n\thttp.HandleFunc(\"/probe\", handleProbe(enabledScrapers, logger))\n\thttp.HandleFunc(\"/-/reload\", func(w http.ResponseWriter, r *http.Request) {\n\t\tif err = c.ReloadConfig(*configMycnf, *mysqldAddress, *mysqldUser, *tlsInsecureSkipVerify, logger); err != nil {\n\t\t\tlogger.Warn(\"Error reloading host config\", \"file\", *configMycnf, \"error\", err)\n\t\t\treturn\n\t\t}\n\t\t_, _ = w.Write([]byte(`ok`))\n\t})\n\tsrv := &http.Server{}\n\tif err := web.ListenAndServe(srv, toolkitFlags, logger); err != nil {\n\t\tlogger.Error(\"Error starting HTTP server\", \"err\", err)\n\t\tos.Exit(1)\n\t}\n}\n"
        },
        {
          "name": "mysqld_exporter_test.go",
          "type": "blob",
          "size": 8.890625,
          "content": "// Copyright 2018 The Prometheus Authors\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n// http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"os/exec\"\n\t\"reflect\"\n\t\"runtime\"\n\t\"strings\"\n\t\"syscall\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/google/go-cmp/cmp\"\n\t\"github.com/prometheus/mysqld_exporter/collector\"\n)\n\n// bin stores information about path of executable and attached port\ntype bin struct {\n\tpath string\n\tport int\n}\n\n// TestBin builds, runs and tests binary.\nfunc TestBin(t *testing.T) {\n\tvar err error\n\tbinName := \"mysqld_exporter\"\n\n\tbinDir, err := os.MkdirTemp(\"/tmp\", binName+\"-test-bindir-\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer func() {\n\t\terr := os.RemoveAll(binDir)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}()\n\n\timportpath := \"github.com/prometheus/common\"\n\tpath := binDir + \"/\" + binName\n\txVariables := map[string]string{\n\t\timportpath + \"/version.Version\":  \"gotest-version\",\n\t\timportpath + \"/version.Branch\":   \"gotest-branch\",\n\t\timportpath + \"/version.Revision\": \"gotest-revision\",\n\t}\n\tvar ldflags []string\n\tfor x, value := range xVariables {\n\t\tldflags = append(ldflags, fmt.Sprintf(\"-X %s=%s\", x, value))\n\t}\n\tcmd := exec.Command(\n\t\t\"go\",\n\t\t\"build\",\n\t\t\"-o\",\n\t\tpath,\n\t\t\"-ldflags\",\n\t\tstrings.Join(ldflags, \" \"),\n\t)\n\tcmd.Stdout = os.Stdout\n\tcmd.Stderr = os.Stderr\n\terr = cmd.Run()\n\tif err != nil {\n\t\tt.Fatalf(\"Failed to build: %s\", err)\n\t}\n\n\ttests := []func(*testing.T, bin){\n\t\ttestLanding,\n\t\ttestProbe,\n\t}\n\n\tportStart := 56000\n\tt.Run(binName, func(t *testing.T) {\n\t\tfor _, f := range tests {\n\t\t\tf := f // capture range variable\n\t\t\tfName := runtime.FuncForPC(reflect.ValueOf(f).Pointer()).Name()\n\t\t\tportStart++\n\t\t\tdata := bin{\n\t\t\t\tpath: path,\n\t\t\t\tport: portStart,\n\t\t\t}\n\t\t\tt.Run(fName, func(t *testing.T) {\n\t\t\t\tt.Parallel()\n\t\t\t\tf(t, data)\n\t\t\t})\n\t\t}\n\t})\n}\n\nfunc testLanding(t *testing.T, data bin) {\n\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n\tdefer cancel()\n\n\t// Run exporter.\n\tcmd := exec.CommandContext(\n\t\tctx,\n\t\tdata.path,\n\t\t\"--web.listen-address\", fmt.Sprintf(\":%d\", data.port),\n\t\t\"--config.my-cnf=test_exporter.cnf\",\n\t)\n\tif err := cmd.Start(); err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer cmd.Wait()\n\tdefer cmd.Process.Kill()\n\n\t// Get the main page.\n\turlToGet := fmt.Sprintf(\"http://127.0.0.1:%d\", data.port)\n\tbody, err := waitForBody(urlToGet)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tgot := string(body)\n\n\texpected := `<html lang=\"en\">\n  <head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>MySQLd Exporter</title>\n    <style>body {\n  font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,Liberation Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;\n  margin: 0;\n}\nheader {\n  background-color: #e6522c;\n  color: #fff;\n  font-size: 1rem;\n  padding: 1rem;\n}\nmain {\n  padding: 1rem;\n}\nlabel {\n  display: inline-block;\n  width: 0.5em;\n}\n#pprof {\n  border: black 2px solid;\n  padding: 1rem;\n  width: fit-content;\n}\n\n</style>\n  </head>\n  <body>\n    <header>\n      <h1>MySQLd Exporter</h1>\n    </header>\n    <main>\n      <h2>Prometheus Exporter for MySQL servers</h2>\n      <div>Version: (version=gotest-version, branch=gotest-branch, revision=gotest-revision)</div>\n      <div>\n        <ul>\n          \n          <li><a href=\"/metrics\">Metrics</a></li>\n          \n        </ul>\n      </div>\n      \n      \n      <div id=\"pprof\">\n      Download a detailed report of resource usage (pprof format, from the Go runtime):\n      <ul>\n        <li><a href=\"debug/pprof/heap\">heap usage (memory)</a>\n        <li><a href=\"debug/pprof/profile?seconds=60\">CPU usage (60 second profile)</a>\n      </ul>\n      To visualize and share profiles you can upload to <a href=\"https://pprof.me\" target=\"_blank\">pprof.me</a>\n      </div>\n    </main>\n  </body>\n</html>\n`\n\tif diff := cmp.Diff(expected, got); diff != \"\" {\n\t\tt.Fatalf(\"expected != got \\n%v\\n\", diff)\n\t}\n}\n\nfunc testProbe(t *testing.T, data bin) {\n\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n\tdefer cancel()\n\n\t// Run exporter.\n\tcmd := exec.CommandContext(\n\t\tctx,\n\t\tdata.path,\n\t\t\"--web.listen-address\", fmt.Sprintf(\":%d\", data.port),\n\t\t\"--config.my-cnf=test_exporter.cnf\",\n\t)\n\tif err := cmd.Start(); err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer cmd.Wait()\n\tdefer cmd.Process.Kill()\n\n\t// Get the main page.\n\turlToGet := fmt.Sprintf(\"http://127.0.0.1:%d/probe\", data.port)\n\tbody, err := waitForBody(urlToGet)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tgot := strings.TrimSpace(string(body))\n\n\texpected := `target is required`\n\n\tif got != expected {\n\t\tt.Fatalf(\"got '%s' but expected '%s'\", got, expected)\n\t}\n}\n\n// waitForBody is a helper function which makes http calls until http server is up\n// and then returns body of the successful call.\nfunc waitForBody(urlToGet string) (body []byte, err error) {\n\ttries := 60\n\n\t// Get data, but we need to wait a bit for http server.\n\tfor i := 0; i <= tries; i++ {\n\t\t// Try to get web page.\n\t\tbody, err = getBody(urlToGet)\n\t\tif err == nil {\n\t\t\treturn body, err\n\t\t}\n\n\t\t// If there is a syscall.ECONNREFUSED error (web server not available) then retry.\n\t\tif urlError, ok := err.(*url.Error); ok {\n\t\t\tif opError, ok := urlError.Err.(*net.OpError); ok {\n\t\t\t\tif osSyscallError, ok := opError.Err.(*os.SyscallError); ok {\n\t\t\t\t\tif osSyscallError.Err == syscall.ECONNREFUSED {\n\t\t\t\t\t\ttime.Sleep(1 * time.Second)\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// There was an error, and it wasn't syscall.ECONNREFUSED.\n\t\treturn nil, err\n\t}\n\n\treturn nil, fmt.Errorf(\"failed to GET %s after %d tries: %s\", urlToGet, tries, err)\n}\n\n// getBody is a helper function which retrieves http body from given address.\nfunc getBody(urlToGet string) ([]byte, error) {\n\tresp, err := http.Get(urlToGet)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer resp.Body.Close()\n\n\tbody, err := io.ReadAll(resp.Body)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn body, nil\n}\n\nfunc Test_filterScrapers(t *testing.T) {\n\ttype args struct {\n\t\tscrapers      []collector.Scraper\n\t\tcollectParams []string\n\t}\n\ttests := []struct {\n\t\tname string\n\t\targs args\n\t\twant []collector.Scraper\n\t}{\n\t\t{\"args_appears_in_collector\",\n\t\t\targs{\n\t\t\t\t[]collector.Scraper{collector.ScrapeGlobalStatus{}},\n\t\t\t\t[]string{collector.ScrapeGlobalStatus{}.Name()},\n\t\t\t},\n\t\t\t[]collector.Scraper{\n\t\t\t\tcollector.ScrapeGlobalStatus{},\n\t\t\t}},\n\t\t{\"args_absent_in_collector\",\n\t\t\targs{\n\t\t\t\t[]collector.Scraper{collector.ScrapeGlobalStatus{}},\n\t\t\t\t[]string{collector.ScrapeGlobalVariables{}.Name()},\n\t\t\t},\n\t\t\t[]collector.Scraper{collector.ScrapeGlobalStatus{}}},\n\t\t{\"respect_params\",\n\t\t\targs{\n\t\t\t\t[]collector.Scraper{\n\t\t\t\t\tcollector.ScrapeGlobalStatus{},\n\t\t\t\t\tcollector.ScrapeGlobalVariables{},\n\t\t\t\t},\n\t\t\t\t[]string{collector.ScrapeGlobalStatus{}.Name()},\n\t\t\t},\n\t\t\t[]collector.Scraper{\n\t\t\t\tcollector.ScrapeGlobalStatus{},\n\t\t\t},\n\t\t},\n\t}\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tif got := filterScrapers(tt.args.scrapers, tt.args.collectParams); !reflect.DeepEqual(got, tt.want) {\n\t\t\t\tt.Errorf(\"filterScrapers() = %v, want %v\", got, tt.want)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc Test_getScrapeTimeoutSeconds(t *testing.T) {\n\ttype args struct {\n\t\ttimeoutHeader string\n\t\toffset        float64\n\t}\n\ttests := []struct {\n\t\tname        string\n\t\targs        args\n\t\twantTimeout float64\n\t\twantErr     bool\n\t}{\n\t\t{\"no_timeout_header\",\n\t\t\targs{},\n\t\t\t0, false,\n\t\t},\n\t\t{\"zero_timeout_header\",\n\t\t\targs{\n\t\t\t\ttimeoutHeader: \"0\",\n\t\t\t},\n\t\t\t0, false,\n\t\t},\n\t\t{\"negative_timeout_header\",\n\t\t\targs{\n\t\t\t\ttimeoutHeader: \"-5\",\n\t\t\t},\n\t\t\t0, true,\n\t\t},\n\t\t{\"offset_greater_than_timeout\",\n\t\t\targs{\n\t\t\t\ttimeoutHeader: \"5\",\n\t\t\t\toffset:        6,\n\t\t\t},\n\t\t\t0, true,\n\t\t},\n\t\t{\"offset_equal_timeout\",\n\t\t\targs{\n\t\t\t\ttimeoutHeader: \"5\",\n\t\t\t\toffset:        5,\n\t\t\t},\n\t\t\t0, true,\n\t\t},\n\t\t{\"offset_less_than_timeout\",\n\t\t\targs{\n\t\t\t\ttimeoutHeader: \"5\",\n\t\t\t\toffset:        1,\n\t\t\t},\n\t\t\t4, false,\n\t\t},\n\t\t{\"no_offset\",\n\t\t\targs{\n\t\t\t\ttimeoutHeader: \"5\",\n\t\t\t},\n\t\t\t5, false,\n\t\t},\n\t}\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\trequest, err := http.NewRequest(http.MethodGet, \"\", nil)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"unexpected error creating http request: %v\", err)\n\t\t\t}\n\t\t\trequest.Header.Set(\"X-Prometheus-Scrape-Timeout-Seconds\", tt.args.timeoutHeader)\n\n\t\t\ttimeout, err := getScrapeTimeoutSeconds(request, tt.args.offset)\n\t\t\tif err != nil && !tt.wantErr {\n\t\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t\t}\n\t\t\tif err == nil && tt.wantErr {\n\t\t\t\tt.Fatal(\"expecting an error, got nil\")\n\t\t\t}\n\t\t\tif timeout != tt.wantTimeout {\n\t\t\t\tt.Fatalf(\"unexpected timeout, got '%f' but expected '%f'\", timeout, tt.wantTimeout)\n\t\t\t}\n\t\t})\n\t}\n}\n"
        },
        {
          "name": "probe.go",
          "type": "blob",
          "size": 2.6162109375,
          "content": "// Copyright 2022 The Prometheus Authors\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n// http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"log/slog\"\n\t\"net/http\"\n\t\"time\"\n\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"github.com/prometheus/client_golang/prometheus/promhttp\"\n\t\"github.com/prometheus/mysqld_exporter/collector\"\n)\n\nfunc handleProbe(scrapers []collector.Scraper, logger *slog.Logger) http.HandlerFunc {\n\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tctx := r.Context()\n\t\tparams := r.URL.Query()\n\t\ttarget := params.Get(\"target\")\n\t\tif target == \"\" {\n\t\t\thttp.Error(w, \"target is required\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcollectParams := r.URL.Query()[\"collect[]\"]\n\n\t\tauthModule := params.Get(\"auth_module\")\n\t\tif authModule == \"\" {\n\t\t\tauthModule = \"client\"\n\t\t}\n\n\t\tcfg := c.GetConfig()\n\t\tcfgsection, ok := cfg.Sections[authModule]\n\t\tif !ok {\n\t\t\tlogger.Error(fmt.Sprintf(\"Could not find section [%s] from config file\", authModule))\n\t\t\thttp.Error(w, fmt.Sprintf(\"Could not find config section [%s]\", authModule), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdsn, err := cfgsection.FormDSN(target)\n\t\tif err != nil {\n\t\t\tlogger.Error(fmt.Sprintf(\"Failed to form dsn from section [%s]\", authModule), \"err\", err)\n\t\t\thttp.Error(w, fmt.Sprintf(\"Error forming dsn from config section [%s]\", authModule), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\t// If a timeout is configured via the Prometheus header, add it to the context.\n\t\ttimeoutSeconds, err := getScrapeTimeoutSeconds(r, *timeoutOffset)\n\t\tif err != nil {\n\t\t\tlogger.Error(\"Error getting timeout from Prometheus header\", \"err\", err)\n\t\t}\n\t\tif timeoutSeconds > 0 {\n\t\t\t// Create new timeout context with request context as parent.\n\t\t\tvar cancel context.CancelFunc\n\t\t\tctx, cancel = context.WithTimeout(ctx, time.Duration(timeoutSeconds*float64(time.Second)))\n\t\t\tdefer cancel()\n\t\t\t// Overwrite request with timeout context.\n\t\t\tr = r.WithContext(ctx)\n\t\t}\n\n\t\tfilteredScrapers := filterScrapers(scrapers, collectParams)\n\n\t\tregistry := prometheus.NewRegistry()\n\t\tregistry.MustRegister(collector.New(ctx, dsn, filteredScrapers, logger))\n\n\t\th := promhttp.HandlerFor(registry, promhttp.HandlerOpts{})\n\t\th.ServeHTTP(w, r)\n\t}\n}\n"
        },
        {
          "name": "test_exporter.cnf",
          "type": "blob",
          "size": 0.1337890625,
          "content": "[client]\nhost=localhost\nport=3306\nsocket=/var/run/mysqld/mysqld.sock\nuser=foo\npassword=bar\n[client.server1]\nuser = bar\npassword = bar123\n"
        },
        {
          "name": "test_image.sh",
          "type": "blob",
          "size": 0.6513671875,
          "content": "#!/bin/bash\nset -exo pipefail\n\ndocker_image=$1\nport=$2\n\ncontainer_id=''\n\nwait_start() {\n    for in in {1..10}; do\n        if  /usr/bin/curl -s -m 5 -f \"http://localhost:${port}/metrics\" > /dev/null; then\n            docker_cleanup\n            exit 0\n        else\n            sleep 1\n        fi\n    done\n    \n    exit 1\n}\n\ndocker_start() {\n    container_id=$(docker run -d --network mysql-test -p \"${port}\":\"${port}\" \"${docker_image}\" --config.my-cnf=test_exporter.cnf)\n}\n\ndocker_cleanup() {\n    docker kill \"${container_id}\"\n}\n\nif [[ \"$#\" -ne 2 ]] ; then\n    echo \"Usage: $0 quay.io/prometheus/mysqld-exporter:v0.10.0 9104\" >&2\n    exit 1\nfi\n\ndocker_start\nwait_start\n"
        }
      ]
    }
  ]
}