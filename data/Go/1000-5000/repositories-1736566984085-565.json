{
  "metadata": {
    "timestamp": 1736566984085,
    "page": 565,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjU3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "felixge/fgprof",
      "stars": 2949,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": "BenchmarkProfilerGoroutines.txt",
          "type": "blob",
          "size": 1.66015625,
          "content": "$ go test -bench=BenchmarkProfilerGoroutines\ngoos: darwin\ngoarch: amd64\npkg: github.com/felixge/fgprof\nBenchmarkProfilerGoroutines/1_goroutines-8         \t  43431\t    26860 ns/op\nBenchmarkProfilerGoroutines/2_goroutines-8         \t  42590\t    27648 ns/op\nBenchmarkProfilerGoroutines/4_goroutines-8         \t  40725\t    28694 ns/op\nBenchmarkProfilerGoroutines/8_goroutines-8         \t  37874\t    31067 ns/op\nBenchmarkProfilerGoroutines/16_goroutines-8        \t  32778\t    37302 ns/op\nBenchmarkProfilerGoroutines/32_goroutines-8        \t  25447\t    47171 ns/op\nBenchmarkProfilerGoroutines/64_goroutines-8        \t  17937\t    66803 ns/op\nBenchmarkProfilerGoroutines/128_goroutines-8       \t  11138\t   108283 ns/op\nBenchmarkProfilerGoroutines/256_goroutines-8       \t   5232\t   191830 ns/op\nBenchmarkProfilerGoroutines/512_goroutines-8       \t   2848\t   351686 ns/op\nBenchmarkProfilerGoroutines/1024_goroutines-8      \t   1611\t   681412 ns/op\nBenchmarkProfilerGoroutines/2048_goroutines-8      \t    846\t  1396125 ns/op\nBenchmarkProfilerGoroutines/4096_goroutines-8      \t    358\t  3286943 ns/op\nBenchmarkProfilerGoroutines/8192_goroutines-8      \t    153\t  7813804 ns/op\nBenchmarkProfilerGoroutines/16384_goroutines-8     \t     70\t 16440643 ns/op\nBenchmarkProfilerGoroutines/32768_goroutines-8     \t     33\t 34101649 ns/op\nBenchmarkProfilerGoroutines/65536_goroutines-8     \t     16\t 68460458 ns/op\nBenchmarkProfilerGoroutines/131072_goroutines-8    \t      8\t134481118 ns/op\nBenchmarkProfilerGoroutines/262144_goroutines-8    \t      4\t270522885 ns/op\nBenchmarkProfilerGoroutines/524288_goroutines-8    \t      2\t567821104 ns/op\nBenchmarkProfilerGoroutines/1048576_goroutines-8   \t      1\t1202184643 ns/op\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 1.0849609375,
          "content": "The MIT License (MIT)\nCopyright © 2020 Felix Geisendörfer <felix@felixge.de>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 8.4248046875,
          "content": "[![go.dev reference](https://img.shields.io/badge/go.dev-reference-007d9c?logo=go)](https://pkg.go.dev/github.com/felixge/fgprof)\n![GitHub Workflow Status](https://img.shields.io/github/workflow/status/felixge/fgprof/Go)\n![GitHub](https://img.shields.io/github/license/felixge/fgprof)\n[![go-recipes](https://raw.githubusercontent.com/nikolaydubina/go-recipes/main/badge.svg?raw=true)](https://github.com/nikolaydubina/go-recipes)\n\n# :rocket: fgprof - The Full Go Profiler\n\nfgprof is a sampling [Go](https://golang.org/) profiler that allows you to analyze On-CPU as well as [Off-CPU](http://www.brendangregg.com/offcpuanalysis.html) (e.g. I/O) time together.\n\nGo's builtin sampling CPU profiler can only show On-CPU time, but it's better than fgprof at that. Go also includes tracing profilers that can analyze I/O, but they can't be combined with the CPU profiler.\n\nfgprof is designed for analyzing applications with mixed I/O and CPU workloads. This kind of profiling is also known as wall-clock profiling.\n\n⚠️ Please upgrade to Go 1.19 or newer. In older versions of Go fgprof can cause significant STW latencies in applications with a lot of goroutines (> 1-10k). See [CL 387415](https://go-review.googlesource.com/c/go/+/387415) for more details.\n\n## Quick Start\n\nIf this is the first time you hear about fgprof, you should start by reading about [The Problem](#the-problem) & [How it Works](#how-it-works).\n\nThere is no need to choose between fgprof and the builtin profiler. Here is how to add both to your application:\n\n```go\npackage main\n\nimport(\n\t_ \"net/http/pprof\"\n\t\"github.com/felixge/fgprof\"\n)\n\nfunc main() {\n\thttp.DefaultServeMux.Handle(\"/debug/fgprof\", fgprof.Handler())\n\tgo func() {\n\t\tlog.Println(http.ListenAndServe(\":6060\", nil))\n\t}()\n\n\t// <code to profile>\n}\n```\n\nfgprof is compatible with the `go tool pprof` visualizer, so taking and analyzing a 3s profile is as simple as:\n\n```\ngo tool pprof --http=:6061 http://localhost:6060/debug/fgprof?seconds=3\n```\n\n![](./assets/fgprof_pprof.png)\n\nAdditionally fgprof supports the plain text format used by Brendan Gregg's [FlameGraph](http://www.brendangregg.com/flamegraphs.html) utility:\n\n```\ngit clone https://github.com/brendangregg/FlameGraph\ncd FlameGraph\ncurl -s 'localhost:6060/debug/fgprof?seconds=3&format=folded' > fgprof.folded\n./flamegraph.pl fgprof.folded > fgprof.svg\n```\n\n![](./assets/fgprof_gregg.png)\n\nWhich tool you prefer is up to you, but one thing I like about Gregg's tool is that you can filter the plaintext files using grep which can be very useful when analyzing large programs.\n\nIf you don't have a program to profile right now, you can `go run ./example` which should allow you to reproduce the graphs you see above. If you've never seen such graphs before, and are unsure how to read them, head over to Brendan Gregg's [Flame Graph](http://www.brendangregg.com/flamegraphs.html) page.\n\n## The Problem\n\nLet's say you've been tasked to optimize a simple program that has a loop calling out to three functions:\n\n```go\nfunc main() {\n\tfor {\n\t\t// Http request to a web service that might be slow.\n\t\tslowNetworkRequest()\n\t\t// Some heavy CPU computation.\n\t\tcpuIntensiveTask()\n\t\t// Poorly named function that you don't understand yet.\n\t\tweirdFunction()\n\t}\n}\n```\n\nOne way to decide which of these three functions you should focus your attention on would be to wrap each function call like this:\n\n```go\nstart := time.Start()\nslowNetworkRequest()\nfmt.Printf(\"slowNetworkRequest: %s\\n\", time.Since(start))\n// ...\n```\n\nHowever, this can be very tedious for large programs. You'll also have to figure out how to average the numbers in case they fluctuate. And once you've done that, you'll have to repeat the process for the functions called by the function you decide to focus on.\n\n### /debug/pprof/profile\n\nSo, this seems like a perfect use case for a profiler. Let's try the `/debug/pprof/profile` endpoint of the builtin `net/http/pprof` pkg to analyze our program for 10s:\n\n```go\nimport _ \"net/http/pprof\"\n\nfunc main() {\n\tgo func() {\n\t\tlog.Println(http.ListenAndServe(\":6060\", nil))\n\t}()\n\n\t// <code to profile>\n}\n```\n\n```\ngo tool pprof -http=:6061 http://localhost:6060/debug/pprof/profile?seconds=10\n```\n\nThat was easy! Looks like we're spending all our time in `cpuIntensiveTask()`, so let's focus on that?\n\n![](./assets/pprof_cpu.png)\n\nBut before we get carried away, let's quickly double check this assumption by manually timing our function calls with `time.Since()` as described above:\n\n```\nslowNetworkRequest: 66.815041ms\ncpuIntensiveTask: 30.000672ms\nweirdFunction: 10.64764ms\nslowNetworkRequest: 67.194516ms\ncpuIntensiveTask: 30.000912ms\nweirdFunction: 10.105371ms\n// ...\n```\n\nOh no, the builtin CPU profiler is misleading us! How is that possible? Well, it turns out the builtin profiler only shows On-CPU time. Time spent waiting on I/O is completely hidden from us.\n\n### /debug/pprof/trace\n\nLet's try something else. The `/debug/pprof/trace` endpoint includes a \"synchronization blocking profile\", maybe that's what we need?\n\n```\ncurl -so pprof.trace http://localhost:6060/debug/pprof/trace?seconds=10\ngo tool trace --pprof=sync pprof.trace > sync.pprof\ngo tool pprof --http=:6061 sync.pprof\n```\n\nOh no, we're being mislead again. This profiler thinks all our time is spent on `slowNetworkRequest()`. It's completely missing `cpuIntensiveTask()`. And what about `weirdFunction()`? It seems like no builtin profiler can see it?\n\n![](./assets/pprof_trace.png)\n\n### /debug/fgprof\n\nSo what can we do? Let's try fgprof, which is designed to analyze mixed I/O and CPU workloads like the one we're dealing with here. We can easily add it alongside the builtin profilers.\n\n```go\nimport(\n\t_ \"net/http/pprof\"\n\t\"github.com/felixge/fgprof\"\n)\n\nfunc main() {\n\thttp.DefaultServeMux.Handle(\"/debug/fgprof\", fgprof.Handler())\n\tgo func() {\n\t\tlog.Println(http.ListenAndServe(\":6060\", nil))\n\t}()\n\n\t// <code to profile>\n}\n```\n\n\n\n```\ngo tool pprof --http=:6061 http://localhost:6060/debug/fgprof?seconds=10\n```\n\nFinally, a profile that shows all three of our functions and how much time we're spending on them. It also turns out our `weirdFunction()` was simply calling `time.Sleep()`, how weird indeed!\n\n![](./assets/fgprof_pprof.png)\n\n## How it Works\n\n### fgprof\n\nfgprof is implemented as a background goroutine that wakes up 99 times per second and calls `runtime.GoroutineProfile`. This returns a list of all goroutines regardless of their current On/Off CPU scheduling status and their call stacks.\n\nThis data is used to maintain an in-memory stack counter which can be converted to the pprof or folded output format. The meat of the implementation is super simple and < 100 lines of code, you should [check it out](./fgprof.go).\n\nThe overhead of fgprof increases with the number of active goroutines (including those waiting on I/O, Channels, Locks, etc.) executed by your program. If your program typically has less than 1000 active goroutines, you shouldn't have much to worry about. However, at 10k or more goroutines fgprof might start to cause some noticeable overhead.\n\n### Go's builtin CPU Profiler\n\nThe builtin Go CPU profiler uses the [setitimer(2)](https://linux.die.net/man/2/setitimer) system call to ask the operating system to be sent a `SIGPROF` signal 100 times a second. Each signal stops the Go process and gets delivered to a random thread's `sigtrampgo()` function. This function then proceeds to call `sigprof()` or `sigprofNonGo()` to record the thread's current stack.\n\nSince Go uses non-blocking I/O, Goroutines that wait on I/O are parked and not running on any threads. Therefore they end up being largely invisible to Go's builtin CPU profiler.\n\n## Known Issues\n\nThere is no perfect approach to profiling, and fgprof is no exception. Below is a list of known issues that will hopefully not be of practical concern for most users, but are important to highlight.\n\n- Internal C functions are not showing up in the stack traces, e.g. `runtime.nanotime` which is called by `time.Since` in the example program.\n- The current implementation is relying on the Go scheduler to schedule the internal goroutine at a fixed sample rate. Scheduler delays, especially biased ones, might cause inaccuracies.\n\n## Credits\n\nThe following articles helped me to learn more about how profilers in general, and the Go profiler in particular work.\n\n- [How do Ruby & Python profilers work?](https://jvns.ca/blog/2017/12/17/how-do-ruby---python-profilers-work-/) by Julia Evans\n- [Profiling Go programs with pprof](https://jvns.ca/blog/2017/09/24/profiling-go-with-pprof/) by Julia Evans\n\n## License\n\nfgprof is licensed under the MIT License.\n"
        },
        {
          "name": "assets",
          "type": "tree",
          "content": null
        },
        {
          "name": "example",
          "type": "tree",
          "content": null
        },
        {
          "name": "fgprof.go",
          "type": "blob",
          "size": 8.845703125,
          "content": "// fgprof is a sampling Go profiler that allows you to analyze On-CPU as well\n// as [Off-CPU](http://www.brendangregg.com/offcpuanalysis.html) (e.g. I/O)\n// time together.\npackage fgprof\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"math\"\n\t\"runtime\"\n\t\"sort\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/google/pprof/profile\"\n)\n\n// Format decides how the output is rendered to the user.\ntype Format string\n\nconst (\n\t// FormatFolded is used by Brendan Gregg's FlameGraph utility, see\n\t// https://github.com/brendangregg/FlameGraph#2-fold-stacks.\n\tFormatFolded Format = \"folded\"\n\t// FormatPprof is used by Google's pprof utility, see\n\t// https://github.com/google/pprof/blob/master/proto/README.md.\n\tFormatPprof Format = \"pprof\"\n)\n\n// Start begins profiling the goroutines of the program and returns a function\n// that needs to be invoked by the caller to stop the profiling and write the\n// results to w using the given format.\nfunc Start(w io.Writer, format Format) func() error {\n\tstartTime := time.Now()\n\n\t// Go's CPU profiler uses 100hz, but 99hz might be less likely to result in\n\t// accidental synchronization with the program we're profiling.\n\tconst hz = 99\n\tticker := time.NewTicker(time.Second / hz)\n\tstopCh := make(chan struct{})\n\tprof := &profiler{}\n\tprofile := newWallclockProfile()\n\n\tvar sampleCount int64\n\n\tgo func() {\n\t\tdefer ticker.Stop()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ticker.C:\n\t\t\t\tsampleCount++\n\n\t\t\t\tstacks := prof.GoroutineProfile()\n\t\t\t\tprofile.Add(stacks)\n\t\t\tcase <-stopCh:\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn func() error {\n\t\tstopCh <- struct{}{}\n\t\tendTime := time.Now()\n\t\tprofile.Ignore(prof.SelfFrames()...)\n\n\t\t// Compute actual sample rate in case, due to performance issues, we\n\t\t// were not actually able to sample at the given hz. Converting\n\t\t// everything to float avoids integers being rounded in the wrong\n\t\t// direction and improves the correctness of times in profiles.\n\t\tduration := endTime.Sub(startTime)\n\t\tactualHz := float64(sampleCount) / (float64(duration) / 1e9)\n\t\treturn profile.Export(w, format, int(math.Round(actualHz)), startTime, endTime)\n\t}\n}\n\n// profiler provides a convenient and performant way to access\n// runtime.GoroutineProfile().\ntype profiler struct {\n\tstacks    []runtime.StackRecord\n\tselfFrame *runtime.Frame\n}\n\n// nullTerminationWorkaround deals with a regression in go1.23, see:\n// - https://github.com/felixge/fgprof/issues/33\n// - https://go-review.googlesource.com/c/go/+/609815\nvar nullTerminationWorkaround = runtime.Version() == \"go1.23.0\"\n\n// GoroutineProfile returns the stacks of all goroutines currently managed by\n// the scheduler. This includes both goroutines that are currently running\n// (On-CPU), as well as waiting (Off-CPU).\nfunc (p *profiler) GoroutineProfile() []runtime.StackRecord {\n\tif p.selfFrame == nil {\n\t\t// Determine the runtime.Frame of this func so we can hide it from our\n\t\t// profiling output.\n\t\trpc := make([]uintptr, 1)\n\t\tn := runtime.Callers(1, rpc)\n\t\tif n < 1 {\n\t\t\tpanic(\"could not determine selfFrame\")\n\t\t}\n\t\tselfFrame, _ := runtime.CallersFrames(rpc).Next()\n\t\tp.selfFrame = &selfFrame\n\t}\n\n\t// We don't know how many goroutines exist, so we have to grow p.stacks\n\t// dynamically. We overshoot by 10% since it's possible that more goroutines\n\t// are launched in between two calls to GoroutineProfile. Once p.stacks\n\t// reaches the maximum number of goroutines used by the program, it will get\n\t// reused indefinitely, eliminating GoroutineProfile calls and allocations.\n\t//\n\t// TODO(fg) There might be workloads where it would be nice to shrink\n\t// p.stacks dynamically as well, but let's not over-engineer this until we\n\t// understand those cases better.\n\tfor {\n\t\tif nullTerminationWorkaround {\n\t\t\tfor i := range p.stacks {\n\t\t\t\tp.stacks[i].Stack0 = [32]uintptr{}\n\t\t\t}\n\t\t}\n\t\tn, ok := runtime.GoroutineProfile(p.stacks)\n\t\tif !ok {\n\t\t\tp.stacks = make([]runtime.StackRecord, int(float64(n)*1.1))\n\t\t} else {\n\t\t\treturn p.stacks[0:n]\n\t\t}\n\t}\n}\n\n// SelfFrames returns frames that belong to the profiler so that we can ignore\n// them when exporting the final profile.\nfunc (p *profiler) SelfFrames() []*runtime.Frame {\n\tif p.selfFrame != nil {\n\t\treturn []*runtime.Frame{p.selfFrame}\n\t}\n\treturn nil\n}\n\nfunc newWallclockProfile() *wallclockProfile {\n\treturn &wallclockProfile{stacks: map[[32]uintptr]*wallclockStack{}}\n}\n\n// wallclockProfile holds a wallclock profile that can be exported in different\n// formats.\ntype wallclockProfile struct {\n\tstacks map[[32]uintptr]*wallclockStack\n\tignore []*runtime.Frame\n}\n\n// wallclockStack holds the symbolized frames of a stack trace and the number\n// of times it has been seen.\ntype wallclockStack struct {\n\tframes []*runtime.Frame\n\tcount  int\n}\n\n// Ignore sets a list of frames that should be ignored when exporting the\n// profile.\nfunc (p *wallclockProfile) Ignore(frames ...*runtime.Frame) {\n\tp.ignore = frames\n}\n\n// Add adds the given stack traces to the profile.\nfunc (p *wallclockProfile) Add(stackRecords []runtime.StackRecord) {\n\tfor _, stackRecord := range stackRecords {\n\t\tif _, ok := p.stacks[stackRecord.Stack0]; !ok {\n\t\t\tws := &wallclockStack{}\n\t\t\t// symbolize pcs into frames\n\t\t\tframes := runtime.CallersFrames(stackRecord.Stack())\n\t\t\tfor {\n\t\t\t\tframe, more := frames.Next()\n\t\t\t\tws.frames = append(ws.frames, &frame)\n\t\t\t\tif !more {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tp.stacks[stackRecord.Stack0] = ws\n\t\t}\n\t\tp.stacks[stackRecord.Stack0].count++\n\t}\n}\n\nfunc (p *wallclockProfile) Export(w io.Writer, f Format, hz int, startTime, endTime time.Time) error {\n\tswitch f {\n\tcase FormatFolded:\n\t\treturn p.exportFolded(w)\n\tcase FormatPprof:\n\t\treturn p.exportPprof(hz, startTime, endTime).Write(w)\n\tdefault:\n\t\treturn fmt.Errorf(\"unknown format: %q\", f)\n\t}\n}\n\n// exportStacks returns the stacks in this profile except those that have been\n// set to Ignore().\nfunc (p *wallclockProfile) exportStacks() []*wallclockStack {\n\tstacks := make([]*wallclockStack, 0, len(p.stacks))\nnextStack:\n\tfor _, ws := range p.stacks {\n\t\tfor _, f := range ws.frames {\n\t\t\tfor _, igf := range p.ignore {\n\t\t\t\tif f.Entry == igf.Entry {\n\t\t\t\t\tcontinue nextStack\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tstacks = append(stacks, ws)\n\t}\n\treturn stacks\n}\n\nfunc (p *wallclockProfile) exportFolded(w io.Writer) error {\n\tvar lines []string\n\tstacks := p.exportStacks()\n\tfor _, ws := range stacks {\n\t\tvar foldedStack []string\n\t\tfor _, f := range ws.frames {\n\t\t\tfoldedStack = append(foldedStack, f.Function)\n\t\t}\n\t\tline := fmt.Sprintf(\"%s %d\", strings.Join(foldedStack, \";\"), ws.count)\n\t\tlines = append(lines, line)\n\t}\n\tsort.Strings(lines)\n\t_, err := io.WriteString(w, strings.Join(lines, \"\\n\")+\"\\n\")\n\treturn err\n}\n\nfunc (p *wallclockProfile) exportPprof(hz int, startTime, endTime time.Time) *profile.Profile {\n\tprof := &profile.Profile{}\n\tm := &profile.Mapping{ID: 1, HasFunctions: true}\n\tprof.Period = int64(1e9 / hz) // Number of nanoseconds between samples.\n\tprof.TimeNanos = startTime.UnixNano()\n\tprof.DurationNanos = int64(endTime.Sub(startTime))\n\tprof.Mapping = []*profile.Mapping{m}\n\tprof.SampleType = []*profile.ValueType{\n\t\t{\n\t\t\tType: \"samples\",\n\t\t\tUnit: \"count\",\n\t\t},\n\t\t{\n\t\t\tType: \"time\",\n\t\t\tUnit: \"nanoseconds\",\n\t\t},\n\t}\n\tprof.PeriodType = &profile.ValueType{\n\t\tType: \"wallclock\",\n\t\tUnit: \"nanoseconds\",\n\t}\n\n\ttype functionKey struct {\n\t\tName     string\n\t\tFilename string\n\t}\n\tfuncIdx := map[functionKey]*profile.Function{}\n\n\ttype locationKey struct {\n\t\tFunction functionKey\n\t\tLine     int\n\t}\n\tlocationIdx := map[locationKey]*profile.Location{}\n\tfor _, ws := range p.exportStacks() {\n\t\tsample := &profile.Sample{\n\t\t\tValue: []int64{\n\t\t\t\tint64(ws.count),\n\t\t\t\tint64(1000 * 1000 * 1000 / hz * ws.count),\n\t\t\t},\n\t\t}\n\n\t\tfor _, frame := range ws.frames {\n\t\t\tfnKey := functionKey{Name: frame.Function, Filename: frame.File}\n\t\t\tfunction, ok := funcIdx[fnKey]\n\t\t\tif !ok {\n\t\t\t\tfunction = &profile.Function{\n\t\t\t\t\tID:         uint64(len(prof.Function)) + 1,\n\t\t\t\t\tName:       frame.Function,\n\t\t\t\t\tSystemName: frame.Function,\n\t\t\t\t\tFilename:   frame.File,\n\t\t\t\t}\n\t\t\t\tfuncIdx[fnKey] = function\n\t\t\t\tprof.Function = append(prof.Function, function)\n\t\t\t}\n\n\t\t\tlocKey := locationKey{Function: fnKey, Line: frame.Line}\n\t\t\tlocation, ok := locationIdx[locKey]\n\t\t\tif !ok {\n\t\t\t\tlocation = &profile.Location{\n\t\t\t\t\tID:      uint64(len(prof.Location)) + 1,\n\t\t\t\t\tMapping: m,\n\t\t\t\t\tLine: []profile.Line{{\n\t\t\t\t\t\tFunction: function,\n\t\t\t\t\t\tLine:     int64(frame.Line),\n\t\t\t\t\t}},\n\t\t\t\t}\n\t\t\t\tlocationIdx[locKey] = location\n\t\t\t\tprof.Location = append(prof.Location, location)\n\t\t\t}\n\t\t\tsample.Location = append(sample.Location, location)\n\t\t}\n\t\tprof.Sample = append(prof.Sample, sample)\n\t}\n\treturn prof\n}\n\ntype symbolizedStacks map[[32]uintptr][]frameCount\n\nfunc (w wallclockProfile) Symbolize(exclude *runtime.Frame) symbolizedStacks {\n\tm := make(symbolizedStacks)\nouter:\n\tfor stack0, ws := range w.stacks {\n\t\tframes := runtime.CallersFrames((&runtime.StackRecord{Stack0: stack0}).Stack())\n\n\t\tfor {\n\t\t\tframe, more := frames.Next()\n\t\t\tif frame.Entry == exclude.Entry {\n\t\t\t\tcontinue outer\n\t\t\t}\n\t\t\tm[stack0] = append(m[stack0], frameCount{Frame: &frame, Count: ws.count})\n\t\t\tif !more {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\treturn m\n}\n\ntype frameCount struct {\n\t*runtime.Frame\n\tCount int\n}\n"
        },
        {
          "name": "fgprof_test.go",
          "type": "blob",
          "size": 4.021484375,
          "content": "package fgprof\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"runtime\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/google/pprof/profile\"\n\t\"github.com/stretchr/testify/require\"\n)\n\n// TestStart is a smoke test that checks that the profiler produces a profiles\n// in different formats with the expected stack frames.\nfunc TestStart(t *testing.T) {\n\ttests := []struct {\n\t\t// Format is the export format being tested\n\t\tFormat Format\n\t\t// ContainsStack returns true if the given profile contains a frame with the given name\n\t\tContainsStack func(t *testing.T, prof *bytes.Buffer, frame string) bool\n\t}{\n\t\t{\n\t\t\tFormat: FormatFolded,\n\t\t\tContainsStack: func(t *testing.T, prof *bytes.Buffer, frame string) bool {\n\t\t\t\treturn strings.Contains(prof.String(), frame)\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tFormat: FormatPprof,\n\t\t\tContainsStack: func(t *testing.T, prof *bytes.Buffer, frame string) bool {\n\t\t\t\tpprof, err := profile.ParseData(prof.Bytes())\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.NoError(t, pprof.CheckValid())\n\t\t\t\tfor _, s := range pprof.Sample {\n\t\t\t\t\tfor _, loc := range s.Location {\n\t\t\t\t\t\tfor _, line := range loc.Line {\n\t\t\t\t\t\t\tif strings.Contains(line.Function.Name, frame) {\n\t\t\t\t\t\t\t\treturn true\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn false\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tt.Run(string(test.Format), func(t *testing.T) {\n\t\t\tprof := &bytes.Buffer{}\n\t\t\tstop := Start(prof, test.Format)\n\t\t\ttime.Sleep(100 * time.Millisecond)\n\t\t\tif err := stop(); err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\trequire.True(t, test.ContainsStack(t, prof, \"fgprof.TestStart\"))\n\t\t\trequire.False(t, test.ContainsStack(t, prof, \"GoroutineProfile\"))\n\t\t})\n\t}\n}\n\nfunc Test_toPprof(t *testing.T) {\n\tfoo := &runtime.Frame{PC: 1, Function: \"foo\", File: \"foo.go\", Line: 23}\n\tbar := &runtime.Frame{PC: 2, Function: \"bar\", File: \"bar.go\", Line: 42}\n\tprof := &wallclockProfile{\n\t\tstacks: map[[32]uintptr]*wallclockStack{\n\t\t\t{foo.PC}: {\n\t\t\t\tframes: []*runtime.Frame{foo},\n\t\t\t\tcount:  1,\n\t\t\t},\n\t\t\t{bar.PC, foo.PC}: {\n\t\t\t\tframes: []*runtime.Frame{bar, foo},\n\t\t\t\tcount:  2,\n\t\t\t},\n\t\t},\n\t}\n\n\tbefore := time.Local\n\tdefer func() { time.Local = before }()\n\ttime.Local = time.UTC\n\n\tstart := time.Date(2022, 8, 27, 14, 32, 23, 0, time.UTC)\n\tend := start.Add(time.Second)\n\tp := prof.exportPprof(99, start, end)\n\tif err := p.CheckValid(); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\twant := strings.TrimSpace(`\nPeriodType: wallclock nanoseconds\nPeriod: 10101010\nTime: 2022-08-27 14:32:23 +0000 UTC\nDuration: 1s\nSamples:\nsamples/count time/nanoseconds\n          1   10101010: 1 \n          2   20202020: 2 1 \nLocations\n     1: 0x0 M=1 foo foo.go:23:0 s=0\n     2: 0x0 M=1 bar bar.go:42:0 s=0\nMappings\n1: 0x0/0x0/0x0   [FN]\n`)\n\tgot := strings.TrimSpace(p.String())\n\trequire.Equal(t, want, got)\n}\n\nfunc BenchmarkProfiler(b *testing.B) {\n\tprof := &profiler{}\n\tfor i := 0; i < b.N; i++ {\n\t\tprof.GoroutineProfile()\n\t}\n}\n\nfunc BenchmarkProfilerGoroutines(b *testing.B) {\n\tfor g := 1; g <= 1024*1024; g = g * 2 {\n\t\tg := g\n\t\tname := fmt.Sprintf(\"%d goroutines\", g)\n\n\t\tb.Run(name, func(b *testing.B) {\n\t\t\tprof := &profiler{}\n\t\t\tinitalRoutines := len(prof.GoroutineProfile())\n\n\t\t\treadyCh := make(chan struct{})\n\t\t\tstopCh := make(chan struct{})\n\t\t\tfor i := 0; i < g; i++ {\n\t\t\t\tgo func() {\n\t\t\t\t\tdefer func() { stopCh <- struct{}{} }()\n\t\t\t\t\treadyCh <- struct{}{}\n\t\t\t\t}()\n\t\t\t\t<-readyCh\n\t\t\t}\n\n\t\t\tb.ResetTimer()\n\t\t\tfor i := 0; i < b.N; i++ {\n\t\t\t\tstacks := prof.GoroutineProfile()\n\t\t\t\tgotRoutines := len(stacks) - initalRoutines\n\t\t\t\tif gotRoutines != g {\n\t\t\t\t\tb.Logf(\"want %d goroutines, but got %d on iteration %d\", g, len(stacks), i)\n\t\t\t\t}\n\t\t\t}\n\t\t\tb.StopTimer()\n\t\t\tfor i := 0; i < g; i++ {\n\t\t\t\t<-stopCh\n\t\t\t}\n\t\t\tstart := time.Now()\n\t\t\tfor i := 0; ; i++ {\n\t\t\t\tif len(prof.GoroutineProfile()) == initalRoutines {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\ttime.Sleep(20 * time.Millisecond)\n\t\t\t\tif time.Since(start) > 10*time.Second {\n\t\t\t\t\tb.Fatalf(\"%d goroutines still running, want %d\", len(prof.GoroutineProfile()), initalRoutines)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc BenchmarkStackCounter(b *testing.B) {\n\tprof := &profiler{}\n\tstacks := prof.GoroutineProfile()\n\tsc := wallclockProfile{}\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tsc.Add(stacks)\n\t}\n}\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.1474609375,
          "content": "module github.com/felixge/fgprof\n\ngo 1.14\n\nrequire (\n\tgithub.com/google/pprof v0.0.0-20240625030939-27f56978b8b0\n\tgithub.com/stretchr/testify v1.8.0\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 2.0830078125,
          "content": "github.com/chzyer/logex v1.2.1/go.mod h1:JLbx6lG2kDbNRFnfkgvh4eRJRPX1QCoOIWomwysCBrQ=\ngithub.com/chzyer/readline v1.5.1/go.mod h1:Eh+b79XXUwfKfcPLepksvw2tcLE/Ct21YObkaSkeBlk=\ngithub.com/chzyer/test v1.0.0/go.mod h1:2JlltgoNkt4TW/z9V/IzDdFaMTM2JPIi26O1pF38GC8=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/google/pprof v0.0.0-20240625030939-27f56978b8b0 h1:e+8XbKB6IMn8A4OAyZccO4pYfB3s7bt6azNIPE7AnPg=\ngithub.com/google/pprof v0.0.0-20240625030939-27f56978b8b0/go.mod h1:K1liHPHnj73Fdn/EKuT8nrFqBihUSKXoLYU0BuatOYo=\ngithub.com/ianlancetaylor/demangle v0.0.0-20240312041847-bd984b5ce465/go.mod h1:gx7rwoVhcfuVKG5uya9Hs3Sxj7EIvldVofAWIUtGouw=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.4.0/go.mod h1:YvHI0jy2hoMjB+UWwv71VJQ9isScKT/TqJzVSSt89Yw=\ngithub.com/stretchr/testify v1.7.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.8.0 h1:pSgiaMZlXftHpm5L7V1+rVB+AZJydKsMxsQBIJw4PKk=\ngithub.com/stretchr/testify v1.8.0/go.mod h1:yNjHg4UonilssWZ8iaSj1OCr/vHnekPRkoO+kdMU+MU=\ngolang.org/x/sys v0.0.0-20220310020820-b874c991c1a5/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.6.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405 h1:yhCVgyC4o1eVCa2tZl7eS0r+SDo693bJlVdllGtEeKM=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\n"
        },
        {
          "name": "handler.go",
          "type": "blob",
          "size": 0.9287109375,
          "content": "package fgprof\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"strconv\"\n\t\"time\"\n)\n\n// Handler returns an http handler that takes an optional \"seconds\" query\n// argument that defaults to \"30\" and produces a profile over this duration.\n// The optional \"format\" parameter controls if the output is written in\n// Google's \"pprof\" format (default) or Brendan Gregg's \"folded\" stack format.\nfunc Handler() http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tvar seconds int\n\t\tvar err error\n\t\tif s := r.URL.Query().Get(\"seconds\"); s == \"\" {\n\t\t\tseconds = 30\n\t\t} else if seconds, err = strconv.Atoi(s); err != nil || seconds <= 0 {\n\t\t\tw.WriteHeader(http.StatusBadRequest)\n\t\t\tfmt.Fprintf(w, \"bad seconds: %d: %s\\n\", seconds, err)\n\t\t\treturn\n\t\t}\n\n\t\tformat := Format(r.URL.Query().Get(\"format\"))\n\t\tif format == \"\" {\n\t\t\tformat = FormatPprof\n\t\t}\n\n\t\tstop := Start(w, format)\n\t\tdefer stop()\n\t\ttime.Sleep(time.Duration(seconds) * time.Second)\n\t})\n}\n"
        }
      ]
    }
  ]
}