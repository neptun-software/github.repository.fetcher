{
  "metadata": {
    "timestamp": 1736566765545,
    "page": 320,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMyMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "kubernetes-sigs/cluster-api",
      "stars": 3626,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.982421875,
          "content": ".git\n.github\n.vscode\nbin/\n**/*.yaml\nhack/\ndocs/\nlogos/\nscripts/\n**/*.md\ntilt-settings.json\ntilt-settings.yaml\ntilt.d/\nTiltfile\n**/.tiltbuild\n**/config/**/*.yaml\n**/config/**/*.yaml-e\n_artifacts\nMakefile\n**/Makefile\n\n# We need the following yaml files while building clusterctl in the container\n!cmd/clusterctl/config/manifest/clusterctl-api.yaml\n!cmd/clusterctl/client/cluster/assets/cert-manager-test-resources.yaml\n\n# ignores changes to test-only code to avoid extra rebuilds\ntest/e2e/**\ntest/framework/**\ntest/infrastructure/docker/e2e/**\n\n.dockerignore\n# We want to ignore any frequently modified files to avoid cache-busting the COPY ./ ./\n# Binaries for programs and plugins\n**/*.exe\n**/*.dll\n**/*.so\n**/*.dylib\ncmd/clusterctl/clusterctl/**\n**/bin/**\n**/out/**\n\n# go.work files\ngo.work\ngo.work.sum\n\n# Test binary, build with `go test -c`\n**/*.test\n\n# Output of the go coverage tool, specifically when used with LiteIDE\n**/*.out\n\n# Common editor / temporary files\n**/*~\n**/*.tmp\n**/.DS_Store\n**/*.swp\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.1806640625,
          "content": "# Hide generated crd yamls by default in the Github diff UX\n**/config/crd/bases/*.yaml linguist-generated=true\ncmd/clusterctl/config/manifest/clusterctl-api.yaml linguist-generated=true"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.9609375,
          "content": "# Binaries for programs and plugins\n*.exe\n*.dll\n*.so\n*.dylib\ncmd/clusterctl/clusterctl\nbin\nhack/tools/bin\n\n# Test binary, build with `go test -c`\n*.test\n\n# E2E test templates\ntest/e2e/data/infrastructure-docker/**/cluster-template*.yaml\n!test/e2e/data/infrastructure-docker/**/clusterclass-quick-start.yaml\n!test/e2e/data/infrastructure-docker/**/clusterclass-quick-start-runtimesdk.yaml\ntest/e2e/data/infrastructure-docker/**/clusterclass-*.yaml\ntest/e2e/data/infrastructure-inmemory/**/cluster-template*.yaml\n\n# Output of Makefile targets using sed on MacOS systems\n*.yaml-e\n\n# Output of the go coverage tool, specifically when used with LiteIDE\n*.out\n\n# IntelliJ\n.idea/\n*.iml\n\n# VSCode\n.vscode/\n*.code-workspace\n\n# go.work files\ngo.work\ngo.work.sum\n\n# kubeconfigs\nminikube.kubeconfig\n\n# Book\ndocs/book/book/\n\n# Common editor / temporary files\n*~\n*.tmp\n.DS_Store\n\n# rbac and manager config for example provider\nconfig/ci/rbac/role_binding.yaml\nconfig/ci/rbac/role.yaml\nconfig/ci/rbac/aggregated_role.yaml\nconfig/ci/rbac/auth_proxy_role.yaml\nconfig/ci/rbac/auth_proxy_role_binding.yaml\nconfig/ci/rbac/auth_proxy_service.yaml\nconfig/ci/manager/manager.yaml\n\n# Sample config files auto-generated by kubebuilder\nconfig/samples\n\n# Temporary clusterctl directory\ncmd/clusterctl/config/manifest\n\n# The golang vendor directory that contains local copies of external\n# dependencies that satisfy Go imports in this project.\nvendor\n\n# User-supplied Tiltfile extensions, settings, and builds\ntilt.d\ntilt-settings.json\ntilt-settings.yaml\n.tiltbuild\n\n# User-supplied clusterctl hacks settings\nclusterctl-settings.json\n\n# test results\n_artifacts\n\n# release artifacts\nout\n\n# Helm\n.helm\n\n# Used during parts of the build process. Files _should_ get cleaned up automatically.\n# This is also a good location for any temporary manfiests used during development\ntmp\n\n# asdf (not a typo! ;) used to manage multiple versions of tools\n.tool-versions\n\n# Development container configurations (https://containers.dev/)\n.devcontainer\n"
        },
        {
          "name": ".golangci.yml",
          "type": "blob",
          "size": 15.341796875,
          "content": "run:\n  timeout: 10m\n  go: \"1.22\"\n  build-tags:\n    - tools\n    - e2e\n  allow-parallel-runners: true\n\nlinters:\n  disable-all: true\n  enable:\n    - asasalint # warns about passing []any to func(...any) without expanding it\n    - asciicheck # non ascii symbols\n    - bidichk # dangerous unicode sequences\n    - bodyclose # unclosed http bodies\n    - containedctx # context.Context nested in a struct\n    - copyloopvar # copying loop variables\n    - dogsled # too many blank identifiers in assignments\n    - dupword # duplicate words\n    - durationcheck # multiplying two durations\n    - errcheck # unchecked errors\n    - errchkjson # invalid types passed to json encoder\n    - gci # ensures imports are organized\n    - ginkgolinter # ginkgo and gomega\n    - goconst # strings that can be replaced by constants\n    - gocritic # bugs, performance, style (we could add custom ones to this one)\n    - godot # checks that comments end in a period\n    - gofmt # warns about incorrect use of fmt functions\n    - goimports # import formatting\n    - goprintffuncname # printft-like functions should be named with f at the end\n    - gosec # potential security problems\n    - gosimple # simplify code\n    - govet # basically 'go vet'\n    - importas # consistent import aliases\n    - ineffassign # ineffectual assignments\n    - intrange # suggest using integer range in for loops\n    - loggercheck # check for even key/value pairs in logger calls\n    - misspell # spelling\n    - nakedret # naked returns (named return parameters and an empty return)\n    - nilerr # returning nil after checking err is not nil\n    - noctx # http requests without context.Context\n    - nolintlint # badly formatted nolint directives\n    - nosprintfhostport # using sprintf to construct host:port in a URL\n    - prealloc # suggest preallocating slices\n    - predeclared # shadowing predeclared identifiers\n    - revive # better version of golint\n    - staticcheck # some of staticcheck's rules\n    - stylecheck # another replacement for golint\n    - tenv # using os.Setenv instead of t.Setenv in tests\n    - thelper # test helpers not starting with t.Helper()\n    - unconvert # unnecessary type conversions\n    - unparam # unused function parameters\n    - unused # unused constants, variables,functions, types\n    - usestdlibvars # using variables/constants from the standard library\n    - whitespace # unnecessary newlines\n\nlinters-settings:\n  gosec:\n    excludes:\n    # integer overflow conversion int -> int32\n      - G115\n  gci:\n    sections:\n      - standard # Standard section: captures all standard packages.\n      - default # Default section: contains all imports that could not be matched to another section type.\n      - prefix(sigs.k8s.io/cluster-api) # Custom section: groups all imports with the specified Prefix.\n    custom-order: true\n  ginkgolinter:\n    forbid-focus-container: true\n  godot:\n    #   declarations - for top level declaration comments (default);\n    #   toplevel     - for top level comments;\n    #   all          - for all comments.\n    scope: toplevel\n    exclude:\n      - '^ \\+.*'\n      - '^ ANCHOR.*'\n  gocritic:\n    enabled-tags:\n      - diagnostic\n      - experimental\n      - performance\n    disabled-checks:\n      - appendAssign\n      - dupImport # https://github.com/go-critic/go-critic/issues/845\n      - evalOrder\n      - ifElseChain\n      - octalLiteral\n      - regexpSimplify\n      - sloppyReassign\n      - truncateCmp\n      - typeDefFirst\n      - unnamedResult\n      - unnecessaryDefer\n      - whyNoLint\n      - wrapperFunc\n      - rangeValCopy\n      - hugeParam\n  importas:\n    no-unaliased: true\n    alias:\n      # Kubernetes\n      - pkg: k8s.io/api/core/v1\n        alias: corev1\n      - pkg: k8s.io/apiextensions-apiserver/pkg/apis/apiextensions/v1\n        alias: apiextensionsv1\n      - pkg: k8s.io/apimachinery/pkg/apis/meta/v1\n        alias: metav1\n      - pkg: k8s.io/apimachinery/pkg/api/errors\n        alias: apierrors\n      - pkg: k8s.io/apimachinery/pkg/util/errors\n        alias: kerrors\n      - pkg: k8s.io/component-base/logs/api/v1\n        alias: logsv1\n      # Controller Runtime\n      - pkg: sigs.k8s.io/controller-runtime\n        alias: ctrl\n      # CABPK\n      - pkg: sigs.k8s.io/cluster-api/internal/apis/bootstrap/kubeadm/v1alpha3\n        alias: bootstrapv1alpha3\n      - pkg: sigs.k8s.io/cluster-api/internal/apis/bootstrap/kubeadm/v1alpha4\n        alias: bootstrapv1alpha4\n      - pkg: sigs.k8s.io/cluster-api/bootstrap/kubeadm/api/v1beta1\n        alias: bootstrapv1\n      # KCP\n      - pkg: sigs.k8s.io/cluster-api/internal/apis/controlplane/kubeadm/v1alpha3\n        alias: controlplanev1alpha3\n      - pkg: sigs.k8s.io/cluster-api/internal/apis/controlplane/kubeadm/v1alpha4\n        alias: controlplanev1alpha4\n      - pkg: sigs.k8s.io/cluster-api/controlplane/kubeadm/api/v1beta1\n        alias: controlplanev1\n      # CAPI\n      - pkg: sigs.k8s.io/cluster-api/internal/apis/core/v1alpha3\n        alias: clusterv1alpha3\n      - pkg: sigs.k8s.io/cluster-api/internal/apis/core/v1alpha4\n        alias: clusterv1alpha4\n      - pkg: sigs.k8s.io/cluster-api/api/v1beta1\n        alias: clusterv1\n      # CAPI exp\n      - pkg: sigs.k8s.io/cluster-api/internal/apis/core/exp/v1alpha3\n        alias: expv1alpha3\n      - pkg: sigs.k8s.io/cluster-api/internal/apis/core/exp/v1alpha4\n        alias: expv1alpha4\n      - pkg: sigs.k8s.io/cluster-api/exp/api/v1beta1\n        alias: expv1\n      # CAPI exp addons\n      - pkg: sigs.k8s.io/cluster-api/internal/apis/core/exp/addons/v1alpha3\n        alias: addonsv1alpha3\n      - pkg: sigs.k8s.io/cluster-api/internal/apis/core/exp/addons/v1alpha4\n        alias: addonsv1alpha4\n      - pkg: sigs.k8s.io/cluster-api/exp/addons/api/v1beta1\n        alias: addonsv1\n      # CAPI exp IPAM\n      - pkg: sigs.k8s.io/cluster-api/exp/ipam/api/v1beta1\n        alias: ipamv1\n      # CAPI exp runtime\n      - pkg: sigs.k8s.io/cluster-api/exp/runtime/api/v1alpha1\n        alias: runtimev1\n      - pkg: sigs.k8s.io/cluster-api/exp/runtime/hooks/api/v1alpha1\n        alias: runtimehooksv1\n      - pkg: sigs.k8s.io/cluster-api/exp/runtime/controllers\n        alias: runtimecontrollers\n      - pkg: sigs.k8s.io/cluster-api/exp/runtime/catalog\n        alias: runtimecatalog\n      - pkg: sigs.k8s.io/cluster-api/internal/runtime/client\n        alias: internalruntimeclient\n      - pkg: sigs.k8s.io/cluster-api/exp/runtime/client\n        alias: runtimeclient\n      - pkg: sigs.k8s.io/cluster-api/internal/runtime/registry\n        alias: runtimeregistry\n      - pkg: sigs.k8s.io/cluster-api/internal/webhooks/runtime\n        alias: runtimewebhooks\n      # CAPI utils\n      - pkg: sigs.k8s.io/cluster-api/util/conditions/v1beta2\n        alias: v1beta2conditions\n      # CAPD\n      - pkg: sigs.k8s.io/cluster-api/test/infrastructure/docker/api/v1alpha3\n        alias: infrav1alpha3\n      - pkg: sigs.k8s.io/cluster-api/test/infrastructure/docker/api/v1alpha4\n        alias: infrav1alpha4\n      - pkg: sigs.k8s.io/cluster-api/test/infrastructure/docker/api/v1beta1\n        alias: infrav1\n      # CAPD exp\n      - pkg: sigs.k8s.io/cluster-api/test/infrastructure/docker/exp/api/v1alpha3\n        alias: infraexpv1alpha3\n      - pkg: sigs.k8s.io/cluster-api/test/infrastructure/docker/exp/api/v1alpha4\n        alias: infraexpv1alpha4\n      - pkg: sigs.k8s.io/cluster-api/test/infrastructure/docker/exp/api/v1beta1\n        alias: infraexpv1\n  nolintlint:\n    allow-unused: false\n    require-specific: true\n  revive:\n    rules:\n      # The following rules are recommended https://github.com/mgechev/revive#recommended-configuration\n      - name: blank-imports\n      - name: context-as-argument\n      - name: context-keys-type\n      - name: dot-imports\n      - name: error-return\n      - name: error-strings\n      - name: error-naming\n      - name: exported\n      - name: if-return\n      - name: increment-decrement\n      - name: var-naming\n      - name: var-declaration\n      - name: package-comments\n      - name: range\n      - name: receiver-naming\n      - name: time-naming\n      - name: unexported-return\n      - name: indent-error-flow\n      - name: errorf\n      - name: empty-block\n      - name: superfluous-else\n      - name: unused-parameter\n      - name: unreachable-code\n      - name: redefines-builtin-id\n      #\n      # Rules in addition to the recommended configuration above.\n      #\n      - name: bool-literal-in-expr\n      - name: constant-logical-expr\n  goconst:\n    ignore-tests: true\nissues:\n  exclude-files:\n    - \"zz_generated.*\\\\.go$\"\n    - \"vendored_openapi\\\\.go$\"\n    # We don't want to invest time to fix new linter findings in old API types.\n    - \"internal/apis/.*\"\n\n  max-same-issues: 0\n  max-issues-per-linter: 0\n  # We are disabling default golangci exclusions because we want to help reviewers to focus on reviewing the most relevant\n  # changes in PRs and avoid nitpicking.\n  exclude-use-default: false\n  exclude-rules:\n  # Specific exclude rules for deprecated fields that are still part of the codebase. These\n  # should be removed as the referenced deprecated item is removed from the project.\n  - linters:\n      - staticcheck\n    text: \"SA1019: (bootstrapv1.ClusterStatus|KubeadmConfigSpec.UseExperimentalRetryJoin|scope.Config.Spec.UseExperimentalRetryJoin|DockerMachine.Spec.Bootstrapped|machineStatus.Bootstrapped|c.TopologyPlan|clusterv1.ClusterClassVariableMetadata|(variable|currentDefinition|specVar|newVariableDefinition|statusVarDefinition).Metadata) is deprecated\"\n  # Deprecations for MD revision management\n  - linters:\n      - staticcheck\n    text: \"SA1019: ((deployment|m|md).Spec.RevisionHistoryLimit|clusterv1.RevisionHistoryAnnotation|c.RolloutUndo) is deprecated\"\n    # Deprecations for MD revision management\n  - linters:\n      - staticcheck\n    text: \"SA1019: (m|md).Spec.ProgressDeadlineSeconds is deprecated: This field is deprecated and is going to be removed in the next apiVersion. Please see https://github.com/kubernetes-sigs/cluster-api/issues/11470 for more details.\"\n    # Deprecations for MHC MaxUnhealthy, UnhealthyRange\n  - linters:\n      - staticcheck\n    text: \"SA1019: (mhc|m)(.Spec.MaxUnhealthy|.Spec.UnhealthyRange) is deprecated\"\n  # Deprecations for FailureMessage, FailureReason, UnavailableReplicas and FullyLabeledReplicas\n  - linters:\n      - staticcheck\n    text: \"SA1019: .*\\\\.Status\\\\.(FailureMessage|FailureReason|UnavailableReplicas|FullyLabeledReplicas) is deprecated: This field is deprecated and is going to be removed in the next apiVersion. Please see https://github.com/kubernetes-sigs/cluster-api/blob/main/docs/proposals/20240916-improve-status-in-CAPI-resources.md for more details.\"\n  - linters:\n      - staticcheck\n    text: \"SA1019: newStatus.FullyLabeledReplicas is deprecated: This field is deprecated and is going to be removed in the next apiVersion. Please see https://github.com/kubernetes-sigs/cluster-api/blob/main/docs/proposals/20240916-improve-status-in-CAPI-resources.md for more details.\"\n  # Specific exclude rules for deprecated packages that are still part of the codebase. These\n  # should be removed as the referenced deprecated packages are removed from the project.\n  - linters:\n    - staticcheck\n    text: \"SA1019: .* is deprecated: This package will be removed in one of the next releases.\"\n  # Specific exclude rules for deprecated types that are still part of the codebase. These\n  # should be removed as the referenced deprecated types are removed from the project.\n  - linters:\n    - staticcheck\n    text: \"SA1019: (clusterv1alpha3.*|clusterv1alpha4.*) is deprecated: This type will be removed in one of the next releases.\"\n  - linters:\n    - revive\n    text: \"exported: exported method .*\\\\.(Reconcile|SetupWithManager|SetupWebhookWithManager) should have comment or be unexported\"\n  - linters:\n    - errcheck\n    text: Error return value of .((os\\.)?std(out|err)\\..*|.*Close|.*Flush|os\\.Remove(All)?|.*print(f|ln)?|os\\.(Un)?Setenv). is not checked\n  # Exclude some packages or code to require comments, for example test code, or fake clients.\n  - linters:\n    - revive\n    text: exported (method|function|type|const) (.+) should have comment or be unexported\n    source: (func|type).*Fake.*\n  - linters:\n    - revive\n    text: exported (method|function|type|const) (.+) should have comment or be unexported\n    path: fake_\\.go\n  - linters:\n    - revive\n    text: exported (method|function|type|const) (.+) should have comment or be unexported\n    path: cmd/clusterctl/internal/test/providers.*.go\n  - linters:\n    - revive\n    text: exported (method|function|type|const) (.+) should have comment or be unexported\n    path: \"(framework|e2e)/.*.go\"\n  # Disable unparam \"always receives\" which might not be really\n  # useful when building libraries.\n  - linters:\n    - unparam\n    text: always receives\n  # Dot imports for gomega and ginkgo are allowed\n  # within test files and test utils.\n  - linters:\n    - revive\n    - stylecheck\n    path: _test\\.go\n    text: should not use dot imports\n  - linters:\n    - revive\n    - stylecheck\n    path: (framework|e2e)/.*.go\n    text: should not use dot imports\n  - linters:\n    - revive\n    - stylecheck\n    path: util/defaulting/defaulting.go\n    text: should not use dot imports\n  # Large parts of this file are duplicate from k/k. Let's ignore \"emptyStringTest\" to reduce the noise in diffs\n  # and to avoid making mistakes by diverging from upstream just because of this purely stylistic linter finding.\n  - linters:\n      - gocritic\n    text: \"emptyStringTest\"\n    path: internal/topology/variables/clusterclass_variable_validation.go\n  # Append should be able to assign to a different var/slice.\n  - linters:\n    - gocritic\n    text: \"appendAssign: append result not assigned to the same slice\"\n # Disable linters for conversion\n  - linters:\n    - staticcheck\n    text: \"SA1019: in.(.+) is deprecated\"\n    path: .*(api|types)\\/.*\\/conversion.*\\.go$\n  - linters:\n      - revive\n    # Checking if an error is nil to just after return the error or nil is redundant\n    text: \"if-return: redundant if ...; err != nil check, just return error instead\"\n    # Ignoring stylistic checks for generated code\n    path: .*(api|types|test)\\/.*\\/conversion.*\\.go$\n  - linters:\n    - revive\n    # Exported function and methods should have comments. This warns on undocumented exported functions and methods.\n    text: exported (method|function|type|const) (.+) should have comment or be unexported\n    # Ignoring stylistic checks for generated code\n    path: .*(api|types|test)\\/.*\\/conversion.*\\.go$\n  - linters:\n    - revive\n    # This rule warns when initialism, variable or package naming conventions are not followed.\n    text: \"var-naming: don't use underscores in Go names;\"\n    # Ignoring stylistic checks for generated code\n    path: .*(api|types|test)\\/.*\\/conversion.*\\.go$\n  - linters:\n    - revive\n    # By convention, receiver names in a method should reflect their identity.\n    text: \"receiver-naming: receiver name\"\n    # Ignoring stylistic checks for generated code\n    path: .*(api|types)\\/.*\\/conversion.*\\.go$\n  - linters:\n    - stylecheck\n    text: \"ST1003: should not use underscores in Go names;\"\n    path: .*(api|types|test)\\/.*\\/conversion.*\\.go$\n  - linters:\n    - stylecheck\n    text: \"ST1016: methods on the same type should have the same receiver name\"\n    path: .*(api|types)\\/.*\\/conversion.*\\.go$\n  # We don't care about defer in for loops in test files.\n  - linters:\n    - gocritic\n    text: \"deferInLoop: Possible resource leak, 'defer' is called in the 'for' loop\"\n    path: _test\\.go\n    # Ignore non-constant format string in call to condition utils\n  - linters:\n      - govet\n    text: \"non-constant format string in call to sigs\\\\.k8s\\\\.io\\\\/cluster-api\\\\/util\\\\/conditions\\\\.\"\n"
        },
        {
          "name": ".markdownlinkcheck.json",
          "type": "blob",
          "size": 0.560546875,
          "content": "{\n    \"ignorePatterns\": [{\n        \"pattern\": \"^http://localhost\"\n    },{\n        \"pattern\": \"https://azure.microsoft.com/en-us/products/kubernetes-service\"\n    }],\n    \"httpHeaders\": [{\n        \"comment\": \"Workaround as suggested here: https://github.com/tcort/markdown-link-check/issues/201\",\n        \"urls\": [\"https://docs.github.com/\"],\n        \"headers\": {\n            \"Accept-Encoding\": \"zstd, br, gzip, deflate\"\n        }\n    }],\n    \"timeout\": \"10s\",\n    \"retryOn429\": true,\n    \"retryCount\": 5,\n    \"fallbackRetryDelay\": \"30s\",\n    \"aliveStatusCodes\": [200, 206]\n}\n"
        },
        {
          "name": "CHANGELOG",
          "type": "tree",
          "content": null
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 35.1796875,
          "content": "# Contributing Guidelines\n<!-- START doctoc generated TOC please keep comment here to allow auto update -->\n<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\n\n- [Contributor License Agreements](#contributor-license-agreements)\n- [Finding Things That Need Help](#finding-things-that-need-help)\n- [Versioning](#versioning)\n  - [Codebase and Go Modules](#codebase-and-go-modules)\n    - [Backporting a patch](#backporting-a-patch)\n  - [APIs](#apis)\n  - [CLIs](#clis)\n- [Branches](#branches)\n  - [Support and guarantees](#support-and-guarantees)\n  - [Removal of v1alpha3 & v1alpha4 apiVersions](#removal-of-v1alpha3--v1alpha4-apiversions)\n- [Contributing a Patch](#contributing-a-patch)\n- [Documentation changes](#documentation-changes)\n- [Releases](#releases)\n- [Proposal process (CAEP)](#proposal-process-caep)\n- [Triaging issues](#triaging-issues)\n- [Triaging E2E test failures](#triaging-e2e-test-failures)\n- [Reviewing a Patch](#reviewing-a-patch)\n  - [Reviews](#reviews)\n  - [Approvals](#approvals)\n- [Features and bugs](#features-and-bugs)\n- [Experiments](#experiments)\n- [Breaking Changes](#breaking-changes)\n- [Dependency Licence Management](#dependency-licence-management)\n- [API conventions](#api-conventions)\n  - [Optional vs. Required](#optional-vs-required)\n    - [Example](#example)\n    - [Exceptions](#exceptions)\n  - [CRD additionalPrinterColumns](#crd-additionalprintercolumns)\n- [Google Doc Viewing Permissions](#google-doc-viewing-permissions)\n- [Issue and Pull Request Management](#issue-and-pull-request-management)\n- [Contributors Ladder](#contributors-ladder)\n\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\n\nRead the following guide if you're interested in contributing to cluster-api.\n\nContributors who are not used to working in the Kubernetes ecosystem should also take a look at the Kubernetes [New Contributor Course.](https://www.kubernetes.dev/docs/onboarding/)\n\n## Contributor License Agreements\n\nWe'd love to accept your patches! Before we can take them, we have to jump a couple of legal hurdles.\n\nPlease fill out either the individual or corporate Contributor License Agreement (CLA). More information about the CLA\nand instructions for signing it [can be found here](https://git.k8s.io/community/CLA.md).\n\n***NOTE***: Only original source code from you and other people that have signed the CLA can be accepted into the\n*repository.\n\n## Finding Things That Need Help\n\nIf you're new to the project and want to help, but don't know where to start, we have a semi-curated list of issues that\nshould not need deep knowledge of the system. [Have a look and see if anything sounds\ninteresting](https://github.com/kubernetes-sigs/cluster-api/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22).\nBefore starting to work on the issue, make sure that it doesn't have a [lifecycle/active](https://github.com/kubernetes-sigs/cluster-api/labels/lifecycle%2Factive) label. If the issue has been assigned, reach out to the assignee.\nAlternatively, read some docs on other controllers and try to write your own, file and fix any/all issues that\ncome up, including gaps in documentation!\n\nIf you're a more experienced contributor, looking at unassigned issues in the next release milestone is a good way to find work that has been prioritized. For example, if the latest minor release is `v1.0`, the next release milestone is `v1.1`.\n\nHelp and contributions are very welcome in the form of code contributions but also in helping to moderate office hours, triaging issues, fixing/investigating flaky tests, being part of the [release team](https://github.com/kubernetes-sigs/cluster-api/blob/main/docs/release/release-team.md), helping new contributors with their questions, reviewing proposals, etc.\n\n## Versioning\n\n### Codebase and Go Modules\n\n> ⚠ The project does not follow Go Modules guidelines for compatibility requirements for 1.x semver releases.\n\nCluster API follows upstream Kubernetes semantic versioning. With the v1 release of our codebase, we guarantee the following:\n\n- A (*minor*) release CAN include:\n  - Introduction of new API versions, or new Kinds.\n  - Compatible API changes like field additions, deprecation notices, etc.\n  - Breaking API changes for deprecated APIs, fields, or code.\n  - Features, promotion or removal of feature gates.\n  - And more!\n\n- A (*patch*) release SHOULD only include backwards compatible set of bugfixes.\n\nThese guarantees extend to all code exposed in our Go Module, including\n*types from dependencies in public APIs*.\nTypes and functions not in public APIs are not considered part of the guarantee.\nThe test module, clusterctl, and experiments do not provide any backward compatible guarantees.\n\n#### Backporting a patch\n\nPull Requests against the main branch can be backported using `/cherry-pick` prow command.\nAny backport MUST NOT be breaking for API or behavioral changes.\n\nWe usually backport critical bugs or security fixes, changes to support new Kubernetes minor versions (see [supported Kubernetes versions](https://cluster-api.sigs.k8s.io/reference/versions.html#supported-kubernetes-versions)), documentation and test signal improvements. Everything else is considered case by case.\n\n[Out of support](https://github.com/kubernetes-sigs/cluster-api/blob/main/CONTRIBUTING.md#support-and-guarantees) release branches are usually frozen,\nalthough maintainers may allow backports in specific situations like CVEs, security, and other critical bug fixes.\n\n### APIs\n\nAPI versioning and guarantees are inspired by the [Kubernetes deprecation policy](https://kubernetes.io/docs/reference/using-api/deprecation-policy/)\nand [API change guidelines](https://github.com/kubernetes/community/blob/f0eec4d19d407c13681431b3c436be67da8c448d/contributors/devel/sig-architecture/api_changes.md).\nWe follow the API guidelines as much as possible adapting them if necessary and on a case-by-case basis to CustomResourceDefinition.\n\n### CLIs\n\nAny command line interface in Cluster API (e.g. clusterctl) share the same versioning schema of the codebase.\nCLI guarantees are inspired by [Kubernetes deprecation policy for CLI](https://kubernetes.io/docs/reference/using-api/deprecation-policy/#deprecating-a-flag-or-cli),\nhowever we allow breaking changes after 8 months or 2 releases (whichever is longer) from deprecation.\n\n## Branches\n\nCluster API has two types of branches: the *main* branch and\n*release-X* branches.\n\nThe *main* branch is where development happens. All the latest and\ngreatest code, including breaking changes, happens on main.\n\nThe *release-X* branches contain stable, backwards compatible code. On every\nmajor or minor release, a new branch is created. It is from these\nbranches that minor and patch releases are tagged. In some cases, it may\nbe necessary to open PRs for bugfixes directly against stable branches, but\nthis should generally not be the case.\n\n### Support and guarantees\n\nCluster API maintains the most recent release/releases for all supported API and contract versions. Support for this section refers to the ability to backport and release patch versions;\n[backport policy](#backporting-a-patch) is defined above.\n\n- The API version is determined from the GroupVersion defined in the top-level `api/` package.\n- The EOL date of each API Version is determined from the last release available once a new API version is published.\n\n| API Version  | Supported Until                                                                         |\n|--------------|-----------------------------------------------------------------------------------------|\n| **v1beta1**  | TBD (current stable)                                                                    |\n\n- For the current stable API version (v1beta1) we support the two most recent minor releases; older minor releases are immediately unsupported when a new major/minor release is available.\n- For older API versions we only support the most recent minor release until the API version reaches EOL.\n- We will maintain test coverage for all supported minor releases and for one additional release for the current stable API version in case we have to do an emergency patch release.\n  For example, if v1.6 and v1.7 are currently supported, we will also maintain test coverage for v1.5 for one additional release cycle. When v1.8 is released, tests for v1.5 will be removed.\n\n| Minor Release | API Version  | Supported Until                                |\n|---------------|--------------|------------------------------------------------|\n| v1.9.x        | **v1beta1**  | when v1.11.0 will be released                  |\n| v1.8.x        | **v1beta1**  | when v1.10.0 will be released                  |\n| v1.7.x        | **v1beta1**  | EOL since 2024-12-10 - v1.9.0 release date     |\n| v1.6.x        | **v1beta1**  | EOL since 2024-08-12 - v1.8.0 release date     |\n| v1.5.x        | **v1beta1**  | EOL since 2024-04-16 - v1.7.0 release date     |\n| v1.4.x        | **v1beta1**  | EOL since 2023-12-05 - v1.6.0 release date     |\n| v1.3.x        | **v1beta1**  | EOL since 2023-07-25 - v1.5.0 release date     |\n| v1.2.x        | **v1beta1**  | EOL since 2023-03-28 - v1.4.0 release date     |\n| v1.1.x        | **v1beta1**  | EOL since 2022-07-18 - v1.2.0 release date (*) |\n| v1.0.x        | **v1beta1**  | EOL since 2022-02-02 - v1.1.0 release date (*) |\n| v0.4.x        | **v1alpha4** | EOL since 2022-04-06 - API version EOL         |\n| v0.3.x        | **v1alpha3** | EOL since 2022-02-23 - API version EOL         |\n\n(*) Previous support policy applies, older minor releases were immediately unsupported when a new major/minor release was available\n\n- Exceptions can be filed with maintainers and taken into consideration on a case-by-case basis.\n\n### Removal of v1alpha3 & v1alpha4 apiVersions\n\nCluster API stopped to serve v1alpha3 API types from the v1.5 release and v1alpha4 types starting from the v1.6 release.\nThose types still exist in Cluster API while we work to a fix (or a workaround) for https://github.com/kubernetes-sigs/cluster-api/issues/10051.\nIMPORTANT! v1alpha3 and v1alpha4 types only exist for conversion and cannot be used by clients anymore.\n\nNote: Removal of a deprecated APIVersion in Kubernetes [can cause issues with garbage collection by the kube-controller-manager](https://github.com/kubernetes/kubernetes/issues/102641)\nThis means that some objects which rely on garbage collection for cleanup - e.g. MachineSets and their descendent objects, like Machines and InfrastructureMachines, may not be cleaned up properly if those\nobjects were created with an APIVersion which is no longer served.\nTo avoid these issues it's advised to ensure a restart to the kube-controller-manager is done after upgrading to a version of Cluster API which drops support for an APIVersion - e.g. v1.5 and v1.6.\nThis can be accomplished with any Kubernetes control-plane rollout, including a Kubernetes version upgrade, or by manually stopping and restarting the kube-controller-manager.\n\n## Contributing a Patch\n\n1. If you haven't already done so, sign a Contributor License Agreement (see details above).\n1. If working on an issue, signal other contributors that you are actively working on it using `/lifecycle active`.\n1. Fork the desired repo, develop and test your code changes.\n1. Submit a pull request.\n    1. All code PR must be labeled with one of\n        - ⚠️ (`:warning:`, major or breaking changes)\n        - ✨ (`:sparkles:`, feature additions)\n        - 🐛 (`:bug:`, patch and bugfixes)\n        - 📖 (`:book:`, documentation or proposals)\n        - 🌱 (`:seedling:`, minor or other)\n1. If your PR has multiple commits, you must [squash them into a single commit](https://kubernetes.io/docs/contribute/new-content/open-a-pr/#squashing-commits) before merging your PR.\n\nIndividual commits should not be tagged separately, but will generally be\nassumed to match the PR. For instance, if you have a bugfix in with\na breaking change, it's generally encouraged to submit the bugfix\nseparately, but if you must put them in one PR, mark the commit\nseparately.\n\nAll changes must be code reviewed. Coding conventions and standards are explained in the official [developer\ndocs](https://git.k8s.io/community/contributors/devel). Expect reviewers to request that you\navoid common [go style mistakes](https://github.com/golang/go/wiki/CodeReviewComments) in your PRs.\n\n## Documentation changes\n\nThe documentation is published in form of a book at:\n\n- [Current stable release](https://cluster-api.sigs.k8s.io)\n- [Tip of the main branch](https://main.cluster-api.sigs.k8s.io/)\n- [v1alpha4 release branch](https://release-0-4.cluster-api.sigs.k8s.io/)\n- [v1alpha3 release branch](https://release-0-3.cluster-api.sigs.k8s.io/)\n- [v1alpha2 release branch](https://release-0-2.cluster-api.sigs.k8s.io/)\n\nThe source for the book is [this folder](https://github.com/kubernetes-sigs/cluster-api/tree/main/docs/book/src)\ncontaining markdown files and we use [mdBook][] to build it into a static\nwebsite.\n\nAfter making changes locally you can run `make serve-book` which will build the HTML version\nand start a web server, so you can preview if the changes render correctly at\nhttp://localhost:3000; the preview auto-updates when changes are detected.\n\nNote: you don't need to have [mdBook][] installed, `make serve-book` will ensure\nappropriate binaries for mdBook and any used plugins are downloaded into\n`hack/tools/bin/` directory.\n\nWhen submitting the PR remember to label it with the 📖 (:book:) icon.\n\n[mdBook]: https://github.com/rust-lang/mdBook\n\n## Releases\n\nCluster API release process is described in [this document](https://github.com/kubernetes-sigs/cluster-api/blob/main/docs/release/release-cycle.md).\n\n## Proposal process (CAEP)\n\nThe Cluster API Enhancement Proposal is the process this project uses to adopt new features, changes to the APIs, changes to contracts between components, or changes to CLI interfaces.\n\nThe [template](https://github.com/kubernetes-sigs/cluster-api/blob/main/docs/proposals/YYYYMMDD-template.md), and accepted proposals live under [docs/proposals](https://github.com/kubernetes-sigs/cluster-api/tree/main/docs/proposals).\n\n- Proposals or requests for enhancements (RFEs) MUST be associated with an issue.\n  - Issues can be placed on the roadmap during planning if there is one or more folks\n    that can dedicate time to writing a CAEP and/or implementing it after approval.\n- A proposal SHOULD be introduced and discussed during the weekly community meetings or on the\n [SIG Cluster Lifecycle mailing list](https://groups.google.com/a/kubernetes.io/g/sig-cluster-lifecycle).\n  - Submit and discuss proposals using a collaborative writing platform, preferably Google Docs, share documents with edit permissions with the [SIG Cluster Lifecycle mailing list](https://groups.google.com/a/kubernetes.io/g/sig-cluster-lifecycle).\n- A proposal in a Google Doc MUST turn into a [Pull Request](https://github.com/kubernetes-sigs/cluster-api/pulls).\n- Proposals MUST be merged and in `implementable` state to be considered part of a major or minor release.\n\n## Triaging issues\n\nIssue triage in Cluster API follows the best practices of the Kubernetes project while seeking balance with\nthe different size of this project.\n\nWhile the maintainers play an important role in the triage process described below, the help of the community is crucial\nto ensure that this task is performed timely and be sustainable long term.\n\n| Phase               | Responsible | What is required to move forward                                                                                                                                                                          |\n|---------------------|-------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Initial triage      | Maintainers | The issue MUST have: <br/> - [priority/*](https://github.com/kubernetes-sigs/cluster-api/labels?q=priority) label<br/>- [kind/*](https://github.com/kubernetes-sigs/cluster-api/labels?q=kind) label<br/> |\n| Triage finalization | Everyone    | There should be consensus on the way forward and enough details for the issue being actionable                                                                                                            |\n| Triage finalization | Maintainers | The issue MUST have: <br/> - `triage/accepted` label<br/> label, plus eventually `help` or `good-first-issue` label                                                                                       |\n| Actionable          | Everyone    | Contributors volunteering time to do the work and reviewers/approvers bandwidth<br/>The issue being fixed                                                                                                 |\n\nPlease note that:\n\n- Priority provides an indication to everyone looking at issues.\n  - When assigning priority several factors are taken into consideration, including impact on users, relevance\n    for the upcoming releases, maturity of the issue (consensus + completeness).\n  - `priority/awaiting-more-evidence` is used to mark issue where there is not enough info to take a decision for\n    one of the other [priorities values](https://github.com/kubernetes-sigs/cluster-api/labels?q=priority).\n  - Priority can change over time, and everyone is welcome to provide constructive feedback about updating an issue's priority.\n  - Applying a priority label is not a commitment to execute within a certain time frame, because implementation\n    depends on contributors volunteering time to do the work and on reviewers/approvers bandwidth.\n\n- Closing inactive issues which are stuck in the \"triage\" phases is a crucial task for maintaining an\n  actionable backlog. Accordingly, the following automation applies to issues in the \"triage\" or the \"refinement\" phase:\n  - After 90 days of inactivity, issues will be marked with the `lifecycle/stale` label\n  - After 30 days of inactivity from when `lifecycle/stale` was applied, issues will be marked with the `lifecycle/rotten` label\n  - After 30 days of inactivity from when `lifecycle/rotten` was applied, issues will be closed.\n    With this regard, it is important to notice that closed issues are and will always be a highly valuable part of the\n    knowledge base about the Cluster API project, and they will never go away.\n  - Note:\n    - The automation above does not apply to issues triaged as `priority/critical-urgent`, `priority/important-soon` or `priority/important-longterm`\n    - Maintainers could apply the `lifecycle/frozen` label if they want to exclude an issue from the automation above\n    - Issues excluded from the automation above will be re-triaged periodically\n\n- If you really care about an issue stuck in the \"triage\" phases, you can engage with the community or\n  try to figure out what is holding back the issue by yourself, e.g.:\n  - Issue too generic or not yet actionable\n  - Lack of consensus or the issue is not relevant for other contributors\n  - Lack of contributors; in this case, finding ways to help and free up maintainers/other contributors time from other tasks\n    can really help to unblock your issues.\n\n- Issues in the \"actionable\" state are not subject to the stale/rotten/closed process; however, it is required to re-assess\n  them periodically given that the project change quickly. Accordingly, the following automation applies to issues\n  in the \"actionable\" phase:\n  - After 30 days of inactivity, the `triage/accepted` label will be removed from issues with `priority/critical-urgent`\n  - After 90 days of inactivity the `triage/accepted` label will be removed from issues with `priority/important-soon`\n  - After 1 year of inactivity the `triage/accepted` label will be removed from issues without `priority/critical-urgent` or `priority/important-soon`\n\n- If you really care about an issue stuck in the \"actionable\" phase, you can try to figure out what is holding back\n  the issue implementation (usually lack of contributors), engage with the community, find ways to help and free up\n  maintainers/other contributors time from other tasks, or `/assign` the issue and send a PR.\n\n## Triaging E2E test failures\n\nWhen you submit a change to the Cluster API repository as set of validation jobs is automatically executed by\nprow and the results report is added to a comment at the end of your PR.\n\nSome jobs run linters or unit test, and in case of failures, you can repeat the same operation locally using `make test lint [etc..]`\nin order to investigate and potential issues. Prow logs usually provide hints about the make target you should use\n(there might be more than one command that needs to be run).\n\nEnd-to-end (E2E) jobs create real Kubernetes clusters by building Cluster API artifacts with the latest changes.\nIn case of E2E test failures, usually it's required to access the \"Artifacts\" link on the top of the prow logs page to triage the problem.\n\nThe artifact folder contains:\n- A folder with the clusterctl local repository used for the test, where you can find components yaml and cluster templates.\n- A folder with logs for all the clusters created during the test. Following logs/info are available:\n    - Controller logs (only if the cluster is a management cluster).\n    - Dump of the Cluster API resources (only if the cluster is a management cluster).\n    - Machine logs (only if the cluster is a workload cluster)\n\nIn case you want to run E2E test locally, please refer to the [Testing](https://cluster-api.sigs.k8s.io/developer/core/testing#running-unit-and-integration-tests) guide. All our e2e test jobs (and also all our other jobs) can be found in [k8s.io/test-infra](https://github.com/kubernetes/test-infra/tree/master/config/jobs/kubernetes-sigs/cluster-api).\n\n## Reviewing a Patch\n\n### Reviews\n\n> Parts of the following content have been adapted from https://google.github.io/eng-practices/review.\n\nAny Kubernetes organization member can leave reviews and `/lgtm` a pull request.\n\nCode reviews should generally look at:\n\n- **Design**: Is the code well-designed and consistent with the rest of the system?\n- **Functionality**: Does the code behave as the author (or linked issue) intended? Is the way the code behaves good for its users?\n- **Complexity**: Could the code be made simpler?  Would another developer be able to easily understand and use this code when they come across it in the future?\n- **Tests**: Does the code have correct and well-designed tests?\n- **Naming**: Did the developer choose clear names for variable, types, methods, functions, etc.?\n- **Comments**: Are the comments clear and useful? Do they explain why rather than what?\n- **Documentation**: Did the developer also update relevant documentation?\n\nSee [Code Review in Cluster API](REVIEWING.md) for a more focused list of review items.\n\n### Approvals\n\nPlease see the [Kubernetes community document on pull\nrequests](https://git.k8s.io/community/contributors/guide/pull-requests.md) for more information about the merge\nprocess.\n\n- A PR is approved by one of the project maintainers and owners after reviews.\n- Approvals should be the very last action a maintainer takes on a pull request.\n\n## Features and bugs\n\nOpen [issues](https://github.com/kubernetes-sigs/cluster-api/issues/new/choose) to report bugs, or discuss minor feature implementation.\n\nEach new issue will be automatically labeled as `needs-triage`; after being triaged by the maintainers the label\nwill be removed and replaced by one of the following:\n\n- `triage/accepted`: Indicates an issue or PR is ready to be actively worked on.\n- `triage/duplicate`: Indicates an issue is a duplicate of another open issue.\n- `triage/needs-information`: Indicates an issue needs more information in order to work on it.\n- `triage/not-reproducible`: Indicates an issue can not be reproduced as described.\n- `triage/unresolved`: Indicates an issue that can not or will not be resolved.\n\nFor big feature, API and contract amendments, we follow the CAEP process as outlined below.\n\n## Experiments\n\nProof of concepts, code experiments, or other initiatives can live under the `exp` folder or behind a feature gate.\n\n- Experiments SHOULD not modify any of the publicly exposed APIs (e.g. CRDs).\n- Experiments SHOULD not modify any existing CRD types outside the experimental API group(s).\n- Experiments SHOULD not modify any existing command line contracts.\n- Experiments MUST not cause any breaking changes to existing (non-experimental) Go APIs.\n- Experiments SHOULD introduce utility helpers in the go APIs for experiments that cross multiple components\n  and require support from bootstrap, control plane, or infrastructure providers.\n- Experiments follow a strict lifecycle: Alpha -> Beta prior to Graduation.\n  - Alpha-stage experiments:\n    - SHOULD not be enabled by default and any feature gates MUST be marked as 'Alpha'\n    - MUST be associated with a CAEP that is merged and in at least a provisional state\n    - MAY be considered inactive and marked as deprecated if the following does not happen within the course of 1 minor release cycle:\n      - Transition to Beta-stage\n      - Active development towards progressing to Beta-stage\n      - Either direct or downstream user evaluation\n    - Any deprecated Alpha-stage experiment MAY be removed in the next minor release.\n  - Beta-stage experiments:\n    - SHOULD be enabled by default, and any feature gates MUST be marked as 'Beta'\n    - MUST be associated with a CAEP that is at least in the experimental state\n    - MUST support conversions for any type changes\n    - MUST remain backwards compatible unless updates are coinciding with a breaking Cluster API release\n    - MAY be considered inactive and marked as deprecated if the following does not happen within the course of 1 minor release cycle:\n      - Graduate\n      - Active development towards Graduation\n      - Either direct or downstream user consumption\n    - Any deprecated Beta-stage experiment MAY be removed after being deprecated for an entire minor release.\n- Experiment Graduation MUST coincide with a breaking Cluster API release\n- Experiment Graduation checklist:\n  - [ ] MAY provide a way to be disabled, any feature gates MUST be marked as 'GA'\n  - [ ] MUST undergo a full Kubernetes-style API review and update the CAEP with the plan to address any issues raised\n  - [ ] CAEP MUST be in an implementable state and is fully up-to-date with the current implementation\n  - [ ] CAEP MUST define transition plan for moving out of the experimental api group and code directories\n  - [ ] CAEP MUST define any upgrade steps required for Existing Management and Workload Clusters\n  - [ ] CAEP MUST define any upgrade steps required to be implemented by out-of-tree bootstrap, control plane, and infrastructure providers.\n\n## Breaking Changes\n\nBreaking changes are generally allowed in the `main` branch, as this is the branch used to develop the next minor\nrelease of Cluster API.\n\nThere may be times, however, when `main` is closed for breaking changes. This is likely to happen as we near the\nrelease of a new minor version.\n\nBreaking changes are not allowed in release branches, as these represent minor versions that have already been released.\nThese versions have consumers who expect the APIs, behaviors, etc. to remain stable during the lifetime of the patch\nstream for the minor release.\n\nExamples of breaking changes include:\n\n- Removing or renaming a field in a CRD\n- Removing or renaming a CRD\n- Removing or renaming an exported constant, variable, type, or function\n- Updating the version of critical libraries such as controller-runtime, client-go, apimachinery, etc.\n    - Some version updates may be acceptable, for picking up bug fixes, but maintainers must exercise caution when\n      reviewing.\n\nThere may, at times, need to be exceptions where breaking changes are allowed in release branches. These are at the\ndiscretion of the project's maintainers, and must be carefully considered before merging. An example of an allowed\nbreaking change might be a fix for a behavioral bug that was released in an initial minor version (such as `v0.3.0`).\n\n## Dependency Licence Management\n\nCluster API follows the [license policy of the CNCF](https://github.com/cncf/foundation/blob/main/allowed-third-party-license-policy.md). This sets limits on which\nlicenses dependencies and other artifacts use. For go dependencies only dependencies listed in the `go.mod` are considered dependencies. This is in line with [how dependencies are reviewed in Kubernetes](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/vendor.md#reviewing-and-approving-dependency-changes).\n\n## API conventions\n\nThis project follows the [Kubernetes API conventions](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md). Minor modifications or additions to the conventions are listed below.\n\n### Optional vs. Required\n\n* Status fields MUST be optional. Our controllers are patching selected fields instead of updating the entire status in every reconciliation.\n\n* If a field is required (for our controllers to work) and has a default value specified via OpenAPI schema, but we don't want to force users to set the field, we have to mark the field as optional. Otherwise, the client-side kubectl OpenAPI schema validation will force the user to set it even though it would be defaulted on the server-side.\n\nOptional fields have the following properties:\n* An optional field MUST be marked with `+optional` and include an `omitempty` JSON tag.\n* Fields SHOULD be pointers if there is a good reason for it, for example:\n  * the nil and the zero values (by Go standards) have semantic differences.\n    * Note: This doesn't apply to map or slice types as they are assignable to `nil`.\n  * the field is of a struct type, contains only fields with `omitempty` and you want\n    to prevent that it shows up as an empty object after marshalling (e.g. `kubectl get`)\n\n#### Example\n\nWhen using ClusterClass, the semantic difference is important when you have a field in a template which will\nhave instance-specific different values in derived objects. Because in this case it's possible to set the field to `nil`\nin the template and then the value can be set in derived objects without being overwritten by the cluster topology controller.\n\n#### Exceptions\n\n* Fields in root objects should be kept as scaffolded by kubebuilder, e.g.:\n  ```golang\n  type Machine struct {\n    metav1.TypeMeta   `json:\",inline\"`\n    metav1.ObjectMeta `json:\"metadata,omitempty\"`\n\n    Spec   MachineSpec   `json:\"spec,omitempty\"`\n    Status MachineStatus `json:\"status,omitempty\"`\n  }\n  type MachineList struct {\n    metav1.TypeMeta `json:\",inline\"`\n    metav1.ListMeta `json:\"metadata,omitempty\"`\n    Items           []Machine `json:\"items\"`\n  }\n  ```\n\n* Top-level fields in `status` must always have the `+optional` annotation. If we want the field to be always visible even if it\n  has the zero value, it must **not** have the `omitempty` JSON tag, e.g.:\n  * Replica counters like `availableReplicas` in the `MachineDeployment`\n  * Flags expressing progress in the object lifecycle like `infrastructureReady` in `Machine`\n\n### CRD additionalPrinterColumns\n\nAll our CRD objects should have the following `additionalPrinterColumns` order (if the respective field exists in the CRD):\n* Namespace (added automatically)\n* Name (added automatically)\n* Cluster\n* Other fields\n* Replica-related fields\n* Phase\n* Age (mandatory field for all CRDs)\n* Version\n* Other fields for -o wide (fields with priority `1` are only shown with `-o wide` and not per default)\n\n***NOTE***: The columns can be configured via the `kubebuilder:printcolumn` annotation on root objects. For examples, please see the `./api` package.\n\nExamples:\n```bash\nkubectl get kubeadmcontrolplane\n```\n```bash\nNAMESPACE            NAME                               INITIALIZED   API SERVER AVAILABLE   REPLICAS   READY   UPDATED   UNAVAILABLE   AGE     VERSION\nquick-start-d5ufye   quick-start-ntysk0-control-plane   true          true                   1          1       1                       2m44s   v1.23.3\n```\n```bash\nkubectl get machinedeployment\n```\n```bash\nNAMESPACE            NAME                      CLUSTER              REPLICAS   READY   UPDATED   UNAVAILABLE   PHASE       AGE     VERSION\nquick-start-d5ufye   quick-start-ntysk0-md-0   quick-start-ntysk0   1                  1         1             ScalingUp   3m28s   v1.23.3\n```\n\n## Google Doc Viewing Permissions\n\nTo gain viewing permissions to google docs in this project, please join either the\n[kubernetes-dev](https://groups.google.com/forum/#!forum/kubernetes-dev) or\n[sig-cluster-lifecycle](https://groups.google.com/a/kubernetes.io/g/sig-cluster-lifecycle) google group.\n\n## Issue and Pull Request Management\n\nAnyone may comment on issues and submit reviews for pull requests. However, in order to be assigned an issue or pull\nrequest, you must be a member of the [Kubernetes SIGs](https://github.com/kubernetes-sigs) GitHub organization.\n\nIf you are a Kubernetes GitHub organization member, you are eligible for membership in the Kubernetes SIGs GitHub\norganization and can request membership by [opening an\nissue](https://github.com/kubernetes/org/issues/new?template=membership.md&title=REQUEST%3A%20New%20membership%20for%20%3Cyour-GH-handle%3E)\nagainst the kubernetes/org repo.\n\nHowever, if you are a member of the related Kubernetes GitHub organizations but not of the Kubernetes org, you\nwill need explicit sponsorship for your membership request. You can read more about Kubernetes membership and\nsponsorship [here](https://git.k8s.io/community/community-membership.md).\n\nCluster API maintainers can assign you an issue or pull request by leaving a `/assign <your Github ID>` comment on the\nissue or pull request.\n\n## Contributors Ladder\n\nNew contributors are welcomed to the community by existing members, helped with PR workflow, and directed to relevant documentation and communication channels.\nWe are also committed in helping people willing to do so in stepping up through the contributor ladder and this paragraph describes how we are trying to make this to happen.\n\nAs the project adoption increases and the codebase keeps growing, we’re trying to break down ownership into self-driven subareas of interest.\nRequirements from the [Kubernetes community membership guidelines](https://github.com/kubernetes/community/blob/master/community-membership.md) apply for reviewers, maintainers and any member of these subareas.\nWhenever you meet requisites for taking responsibilities in a subarea, the following procedure should be followed:\n1. Submit a PR.\n2. Propose at community meeting.\n3. Get positive feedback and +1s in the PR and wait one week lazy consensus after agreement.\n\nAs of today there are following OWNERS files/Owner groups defining sub areas:\n- [Clusterctl](https://github.com/kubernetes-sigs/cluster-api/tree/main/cmd/clusterctl)\n- [kubeadm Bootstrap Provider (CABPK)](https://github.com/kubernetes-sigs/cluster-api/tree/main/bootstrap/kubeadm)\n- [kubeadm Control Plane Provider (KCP)](https://github.com/kubernetes-sigs/cluster-api/tree/main/controlplane/kubeadm)\n- [Cluster Managed topologies, ClusterClass](https://github.com/kubernetes-sigs/cluster-api/tree/main/internal/controllers/topology)\n- [Infrastructure Provider Docker (CAPD)](https://github.com/kubernetes-sigs/cluster-api/tree/main/test/infrastructure/docker)\n- [Infrastructure Provider in-memory](https://github.com/kubernetes-sigs/cluster-api/tree/main/test/infrastructure/inmemory)\n- [Test](https://github.com/kubernetes-sigs/cluster-api/tree/main/test)\n- [Test Framework](https://github.com/kubernetes-sigs/cluster-api/tree/main/test/framework)\n- [Docs](https://github.com/kubernetes-sigs/cluster-api/tree/main/docs)\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 2.4580078125,
          "content": "# syntax=docker/dockerfile:1.4\n\n# Copyright 2018 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Build the manager binary\n# Run this with docker build --build-arg builder_image=<golang:x.y.z>\nARG builder_image\n\n# Build architecture\nARG ARCH\n\n# Ignore Hadolint rule \"Always tag the version of an image explicitly.\"\n# It's an invalid finding since the image is explicitly set in the Makefile.\n# https://github.com/hadolint/hadolint/wiki/DL3006\n# hadolint ignore=DL3006\nFROM ${builder_image} as builder\nWORKDIR /workspace\n\n# Run this with docker build --build-arg goproxy=$(go env GOPROXY) to override the goproxy\nARG goproxy=https://proxy.golang.org\n# Run this with docker build --build-arg package=./controlplane/kubeadm or --build-arg package=./bootstrap/kubeadm\nENV GOPROXY=$goproxy\n\n# Copy the Go Modules manifests\nCOPY go.mod go.mod\nCOPY go.sum go.sum\n\n# Cache deps before building and copying source so that we don't need to re-download as much\n# and so that source changes don't invalidate our downloaded layer\nRUN --mount=type=cache,target=/go/pkg/mod \\\n    go mod download\n\n# Copy the sources\nCOPY ./ ./\n\n# Cache the go build into the Go’s compiler cache folder so we take benefits of compiler caching across docker build calls\nRUN --mount=type=cache,target=/root/.cache/go-build \\\n    --mount=type=cache,target=/go/pkg/mod \\\n    go build .\n\n# Build\nARG package=.\nARG ARCH\nARG ldflags\n\n# Do not force rebuild of up-to-date packages (do not use -a) and use the compiler cache folder\nRUN --mount=type=cache,target=/root/.cache/go-build \\\n    --mount=type=cache,target=/go/pkg/mod \\\n    CGO_ENABLED=0 GOOS=linux GOARCH=${ARCH} \\\n    go build -trimpath -ldflags \"${ldflags} -extldflags '-static'\" \\\n    -o manager ${package}\n\n# Production image\nFROM gcr.io/distroless/static:nonroot-${ARCH}\nWORKDIR /\nCOPY --from=builder /workspace/manager .\n# Use uid of nonroot user (65532) because kubernetes expects numeric user when applying pod security policies\nUSER 65532\nENTRYPOINT [\"/manager\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 78.6826171875,
          "content": "# Copyright 2018 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# If you update this file, please follow\n# https://www.thapaliya.com/en/writings/well-documented-makefiles/\n\n# Ensure Make is run with bash shell as some syntax below is bash-specific\nSHELL:=/usr/bin/env bash\n\n.DEFAULT_GOAL:=help\n\n#\n# Go.\n#\nGO_VERSION ?= 1.22.10\nGO_DIRECTIVE_VERSION ?= 1.22.0\nGO_CONTAINER_IMAGE ?= docker.io/library/golang:$(GO_VERSION)\n\n# Use GOPROXY environment variable if set\nGOPROXY := $(shell go env GOPROXY)\nifeq ($(GOPROXY),)\nGOPROXY := https://proxy.golang.org\nendif\nexport GOPROXY\n\n# Active module mode, as we use go modules to manage dependencies\nexport GO111MODULE=on\n\n#\n# Kubebuilder.\n#\nexport KUBEBUILDER_ENVTEST_KUBERNETES_VERSION ?= 1.32.0\nexport KUBEBUILDER_CONTROLPLANE_START_TIMEOUT ?= 60s\nexport KUBEBUILDER_CONTROLPLANE_STOP_TIMEOUT ?= 60s\n\n# This option is for running docker manifest command\nexport DOCKER_CLI_EXPERIMENTAL := enabled\n\n# Enables shell script tracing. Enable by running: TRACE=1 make <target>\nTRACE ?= 0\n\n#\n# Directories.\n#\n# Full directory of where the Makefile resides\nROOT_DIR:=$(shell dirname $(realpath $(firstword $(MAKEFILE_LIST))))\nEXP_DIR := exp\nBIN_DIR := bin\nTEST_DIR := test\nTOOLS_DIR := hack/tools\nTOOLS_BIN_DIR := $(abspath $(TOOLS_DIR)/$(BIN_DIR))\nDOCS_DIR := docs\nE2E_FRAMEWORK_DIR := $(TEST_DIR)/framework\nCAPD_DIR := $(TEST_DIR)/infrastructure/docker\nCAPIM_DIR := $(TEST_DIR)/infrastructure/inmemory\nTEST_EXTENSION_DIR := $(TEST_DIR)/extension\nGO_INSTALL := ./scripts/go_install.sh\nOBSERVABILITY_DIR := hack/observability\n\nexport PATH := $(abspath $(TOOLS_BIN_DIR)):$(PATH)\n\n#\n# Ginkgo configuration.\n#\nGINKGO_FOCUS ?=\nGINKGO_SKIP ?=\nGINKGO_NODES ?= 1\nGINKGO_TIMEOUT ?= 2h\nGINKGO_POLL_PROGRESS_AFTER ?= 60m\nGINKGO_POLL_PROGRESS_INTERVAL ?= 5m\nE2E_CONF_FILE ?= $(ROOT_DIR)/$(TEST_DIR)/e2e/config/docker.yaml\nSKIP_RESOURCE_CLEANUP ?= false\nUSE_EXISTING_CLUSTER ?= false\nGINKGO_NOCOLOR ?= false\n\n# to set multiple ginkgo skip flags, if any\nifneq ($(strip $(GINKGO_SKIP)),)\n_SKIP_ARGS := $(foreach arg,$(strip $(GINKGO_SKIP)),-skip=\"$(arg)\")\nendif\n\n# Helper function to get dependency version from go.mod\nget_go_version = $(shell go list -m $1 | awk '{print $$2}')\n\n#\n# Binaries.\n#\n# Note: Need to use abspath so we can invoke these from subdirectories\nKUSTOMIZE_VER := v5.3.0\nKUSTOMIZE_BIN := kustomize\nKUSTOMIZE := $(abspath $(TOOLS_BIN_DIR)/$(KUSTOMIZE_BIN)-$(KUSTOMIZE_VER))\nKUSTOMIZE_PKG := sigs.k8s.io/kustomize/kustomize/v5\n\nSETUP_ENVTEST_VER := release-0.19\nSETUP_ENVTEST_BIN := setup-envtest\nSETUP_ENVTEST := $(abspath $(TOOLS_BIN_DIR)/$(SETUP_ENVTEST_BIN)-$(SETUP_ENVTEST_VER))\nSETUP_ENVTEST_PKG := sigs.k8s.io/controller-runtime/tools/setup-envtest\n\nCONTROLLER_GEN_VER := v0.16.1\nCONTROLLER_GEN_BIN := controller-gen\nCONTROLLER_GEN := $(abspath $(TOOLS_BIN_DIR)/$(CONTROLLER_GEN_BIN)-$(CONTROLLER_GEN_VER))\nCONTROLLER_GEN_PKG := sigs.k8s.io/controller-tools/cmd/controller-gen\n\nGOTESTSUM_VER := v1.11.0\nGOTESTSUM_BIN := gotestsum\nGOTESTSUM := $(abspath $(TOOLS_BIN_DIR)/$(GOTESTSUM_BIN)-$(GOTESTSUM_VER))\nGOTESTSUM_PKG := gotest.tools/gotestsum\n\nCONVERSION_GEN_VER := v0.31.0\nCONVERSION_GEN_BIN := conversion-gen\n# We are intentionally using the binary without version suffix, to avoid the version\n# in generated files.\nCONVERSION_GEN := $(abspath $(TOOLS_BIN_DIR)/$(CONVERSION_GEN_BIN))\nCONVERSION_GEN_PKG := k8s.io/code-generator/cmd/conversion-gen\n\nENVSUBST_BIN := envsubst\nENVSUBST_VER := $(call get_go_version,github.com/drone/envsubst/v2)\nENVSUBST := $(abspath $(TOOLS_BIN_DIR)/$(ENVSUBST_BIN)-$(ENVSUBST_VER))\nENVSUBST_PKG := github.com/drone/envsubst/v2/cmd/envsubst\n\nGO_APIDIFF_VER := v0.8.2\nGO_APIDIFF_BIN := go-apidiff\nGO_APIDIFF := $(abspath $(TOOLS_BIN_DIR)/$(GO_APIDIFF_BIN)-$(GO_APIDIFF_VER))\nGO_APIDIFF_PKG := github.com/joelanford/go-apidiff\n\nHADOLINT_VER := v2.12.0\nHADOLINT_FAILURE_THRESHOLD = warning\n\nSHELLCHECK_VER := v0.9.0\n\nTRIVY_VER := 0.49.1\n\nKPROMO_VER := 5ab0dbc74b0228c22a93d240596dff77464aee8f\nKPROMO_BIN := kpromo\nKPROMO :=  $(abspath $(TOOLS_BIN_DIR)/$(KPROMO_BIN)-$(KPROMO_VER))\n# KPROMO_PKG may have to be changed if KPROMO_VER increases its major version.\nKPROMO_PKG := sigs.k8s.io/promo-tools/v4/cmd/kpromo\n\nYQ_VER := v4.35.2\nYQ_BIN := yq\nYQ :=  $(abspath $(TOOLS_BIN_DIR)/$(YQ_BIN)-$(YQ_VER))\nYQ_PKG := github.com/mikefarah/yq/v4\n\nPLANTUML_VER := 1.2024.3\n\nGINKGO_BIN := ginkgo\nGINKGO_VER := $(call get_go_version,github.com/onsi/ginkgo/v2)\nGINKGO := $(abspath $(TOOLS_BIN_DIR)/$(GINKGO_BIN)-$(GINKGO_VER))\nGINKGO_PKG := github.com/onsi/ginkgo/v2/ginkgo\n\nGOLANGCI_LINT_BIN := golangci-lint\nGOLANGCI_LINT_VER := $(shell cat .github/workflows/pr-golangci-lint.yaml | grep [[:space:]]version: | sed 's/.*version: //')\nGOLANGCI_LINT := $(abspath $(TOOLS_BIN_DIR)/$(GOLANGCI_LINT_BIN)-$(GOLANGCI_LINT_VER))\nGOLANGCI_LINT_PKG := github.com/golangci/golangci-lint/cmd/golangci-lint\n\nGOVULNCHECK_BIN := govulncheck\nGOVULNCHECK_VER := v1.0.4\nGOVULNCHECK := $(abspath $(TOOLS_BIN_DIR)/$(GOVULNCHECK_BIN)-$(GOVULNCHECK_VER))\nGOVULNCHECK_PKG := golang.org/x/vuln/cmd/govulncheck\n\nIMPORT_BOSS_BIN := import-boss\nIMPORT_BOSS_VER := v0.28.1\nIMPORT_BOSS := $(abspath $(TOOLS_BIN_DIR)/$(IMPORT_BOSS_BIN))\nIMPORT_BOSS_PKG := k8s.io/code-generator/cmd/import-boss\n\nTRIAGE_PARTY_IMAGE_NAME ?= extra/triage-party\nTRIAGE_PARTY_CONTROLLER_IMG ?= $(STAGING_REGISTRY)/$(TRIAGE_PARTY_IMAGE_NAME)\nTRIAGE_PARTY_DIR := hack/tools/triage\nTRIAGE_PARTY_TMP_DIR ?= $(TRIAGE_PARTY_DIR)/triage-party.tmp\nTRIAGE_PARTY_VERSION ?= v1.6.0\n\nCONVERSION_VERIFIER_BIN := conversion-verifier\nCONVERSION_VERIFIER := $(abspath $(TOOLS_BIN_DIR)/$(CONVERSION_VERIFIER_BIN))\n\nOPENAPI_GEN_VER := dc4e619 # main branch as of 22.04.2024\nOPENAPI_GEN_BIN := openapi-gen\n# We are intentionally using the binary without version suffix, to avoid the version\n# in generated files.\nOPENAPI_GEN := $(abspath $(TOOLS_BIN_DIR)/$(OPENAPI_GEN_BIN))\nOPENAPI_GEN_PKG := k8s.io/kube-openapi/cmd/openapi-gen\n\nPROWJOB_GEN_BIN := prowjob-gen\nPROWJOB_GEN := $(abspath $(TOOLS_BIN_DIR)/$(PROWJOB_GEN_BIN))\n\nRUNTIME_OPENAPI_GEN_BIN := runtime-openapi-gen\nRUNTIME_OPENAPI_GEN := $(abspath $(TOOLS_BIN_DIR)/$(RUNTIME_OPENAPI_GEN_BIN))\n\nTILT_PREPARE_BIN := tilt-prepare\nTILT_PREPARE := $(abspath $(TOOLS_BIN_DIR)/$(TILT_PREPARE_BIN))\n\n# Define Docker related variables. Releases should modify and double check these vars.\nREGISTRY ?= gcr.io/$(shell gcloud config get-value project)\nPROD_REGISTRY ?= registry.k8s.io/cluster-api\n\nSTAGING_REGISTRY ?= gcr.io/k8s-staging-cluster-api\nSTAGING_BUCKET ?= k8s-staging-cluster-api\n\n# core\nIMAGE_NAME ?= cluster-api-controller\nCONTROLLER_IMG ?= $(REGISTRY)/$(IMAGE_NAME)\n\n# bootstrap\nKUBEADM_BOOTSTRAP_IMAGE_NAME ?= kubeadm-bootstrap-controller\nKUBEADM_BOOTSTRAP_CONTROLLER_IMG ?= $(REGISTRY)/$(KUBEADM_BOOTSTRAP_IMAGE_NAME)\n\n# control plane\nKUBEADM_CONTROL_PLANE_IMAGE_NAME ?= kubeadm-control-plane-controller\nKUBEADM_CONTROL_PLANE_CONTROLLER_IMG ?= $(REGISTRY)/$(KUBEADM_CONTROL_PLANE_IMAGE_NAME)\n\n# capd\nCAPD_IMAGE_NAME ?= capd-manager\nCAPD_CONTROLLER_IMG ?= $(REGISTRY)/$(CAPD_IMAGE_NAME)\n\n# capim\nCAPIM_IMAGE_NAME ?= capim-manager\nCAPIM_CONTROLLER_IMG ?= $(REGISTRY)/$(CAPIM_IMAGE_NAME)\n\n# clusterctl\nCLUSTERCTL_MANIFEST_DIR := cmd/clusterctl/config\nCLUSTERCTL_IMAGE_NAME ?= clusterctl\nCLUSTERCTL_IMG ?= $(REGISTRY)/$(CLUSTERCTL_IMAGE_NAME)\n\n# test extension\nTEST_EXTENSION_IMAGE_NAME ?= test-extension\nTEST_EXTENSION_IMG ?= $(REGISTRY)/$(TEST_EXTENSION_IMAGE_NAME)\n\n# kind\nCAPI_KIND_CLUSTER_NAME ?= capi-test\n\n# It is set by Prow GIT_TAG, a git-based tag of the form vYYYYMMDD-hash, e.g., v20210120-v0.3.10-308-gc61521971\n\nTAG ?= dev\nARCH ?= $(shell go env GOARCH)\nALL_ARCH ?= amd64 arm arm64 ppc64le s390x\n\n# Allow overriding the imagePullPolicy\nPULL_POLICY ?= Always\n\n# Hosts running SELinux need :z added to volume mounts\nSELINUX_ENABLED := $(shell cat /sys/fs/selinux/enforce 2> /dev/null || echo 0)\n\nifeq ($(SELINUX_ENABLED),1)\n  DOCKER_VOL_OPTS?=:z\nendif\n\n# Set build time variables including version details\nLDFLAGS := $(shell hack/version.sh)\n\nall: test managers clusterctl\n\nhelp:  # Display this help\n\t@awk 'BEGIN {FS = \":.*##\"; printf \"\\nUsage:\\n  make \\033[36m<target>\\033[0m\\n\"} /^[0-9A-Za-z_-]+:.*?##/ { printf \"  \\033[36m%-50s\\033[0m %s\\n\", $$1, $$2 } /^\\$$\\([0-9A-Za-z_-]+\\):.*?##/ { gsub(\"_\",\"-\", $$1); printf \"  \\033[36m%-50s\\033[0m %s\\n\", tolower(substr($$1, 3, length($$1)-7)), $$2 } /^##@/ { printf \"\\n\\033[1m%s\\033[0m\\n\", substr($$0, 5) } ' $(MAKEFILE_LIST)\n\n## --------------------------------------\n## Generate / Manifests\n## --------------------------------------\n\n##@ generate:\n\nALL_GENERATE_MODULES = core kubeadm-bootstrap kubeadm-control-plane docker-infrastructure in-memory-infrastructure test-extension\n\n.PHONY: generate\ngenerate: ## Run all generate-manifests-*, generate-go-deepcopy-*, generate-go-conversions-* and generate-go-openapi targets\n\t$(MAKE) generate-modules generate-manifests generate-go-deepcopy generate-go-conversions generate-go-openapi generate-metrics-config\n\n.PHONY: generate-manifests\ngenerate-manifests: $(addprefix generate-manifests-,$(ALL_GENERATE_MODULES)) ## Run all generate-manifests-* targets\n\n.PHONY: generate-manifests-core\ngenerate-manifests-core: $(CONTROLLER_GEN) $(KUSTOMIZE) ## Generate manifests e.g. CRD, RBAC etc. for core\n\t$(MAKE) clean-generated-yaml SRC_DIRS=\"./config/crd/bases,./config/webhook/manifests.yaml\"\n\t$(CONTROLLER_GEN) \\\n\t\tpaths=./ \\\n\t\tpaths=./api/... \\\n\t\tpaths=./internal/apis/core/... \\\n\t\tpaths=./internal/controllers/... \\\n\t\tpaths=./internal/webhooks/... \\\n\t\tpaths=./$(EXP_DIR)/api/... \\\n\t\tpaths=./$(EXP_DIR)/internal/controllers/... \\\n\t\tpaths=./$(EXP_DIR)/internal/webhooks/... \\\n\t\tpaths=./$(EXP_DIR)/addons/api/... \\\n\t\tpaths=./$(EXP_DIR)/addons/internal/controllers/... \\\n\t\tpaths=./$(EXP_DIR)/addons/internal/webhooks/... \\\n\t\tpaths=./$(EXP_DIR)/ipam/api/... \\\n\t\tpaths=./$(EXP_DIR)/ipam/internal/webhooks/... \\\n\t\tpaths=./$(EXP_DIR)/runtime/api/... \\\n\t\tpaths=./$(EXP_DIR)/runtime/internal/controllers/... \\\n\t\tcrd:crdVersions=v1 \\\n\t\trbac:roleName=manager-role \\\n\t\toutput:crd:dir=./config/crd/bases \\\n\t\toutput:webhook:dir=./config/webhook \\\n\t\twebhook\n\t$(CONTROLLER_GEN) \\\n\t\tpaths=./cmd/clusterctl/api/... \\\n\t\tcrd:crdVersions=v1 \\\n\t\toutput:crd:dir=./cmd/clusterctl/config/crd/bases\n\t$(KUSTOMIZE) build $(CLUSTERCTL_MANIFEST_DIR)/crd > $(CLUSTERCTL_MANIFEST_DIR)/manifest/clusterctl-api.yaml\n\t$(CONTROLLER_GEN) \\\n\t\tpaths=./util/test/builder/... \\\n\t\tcrd:crdVersions=v1 \\\n\t\toutput:crd:dir=./util/test/builder/crd\n\n.PHONY: generate-manifests-kubeadm-bootstrap\ngenerate-manifests-kubeadm-bootstrap: $(CONTROLLER_GEN) ## Generate manifests e.g. CRD, RBAC etc. for kubeadm bootstrap\n\t$(MAKE) clean-generated-yaml SRC_DIRS=\"./bootstrap/kubeadm/config/crd/bases,./bootstrap/kubeadm/config/webhook/manifests.yaml\"\n\t$(CONTROLLER_GEN) \\\n\t\tpaths=./bootstrap/kubeadm \\\n\t\tpaths=./bootstrap/kubeadm/api/... \\\n\t\tpaths=./bootstrap/kubeadm/internal/controllers/... \\\n\t\tpaths=./bootstrap/kubeadm/internal/webhooks/... \\\n\t\tpaths=./internal/apis/bootstrap/kubeadm/... \\\n\t\tcrd:crdVersions=v1 \\\n\t\trbac:roleName=manager-role \\\n\t\toutput:crd:dir=./bootstrap/kubeadm/config/crd/bases \\\n\t\toutput:rbac:dir=./bootstrap/kubeadm/config/rbac \\\n\t\toutput:webhook:dir=./bootstrap/kubeadm/config/webhook \\\n\t\twebhook\n\n.PHONY: generate-manifests-kubeadm-control-plane\ngenerate-manifests-kubeadm-control-plane: $(CONTROLLER_GEN) ## Generate manifests e.g. CRD, RBAC etc. for kubeadm control plane\n\t$(MAKE) clean-generated-yaml SRC_DIRS=\"./controlplane/kubeadm/config/crd/bases,./controlplane/kubeadm/config/webhook/manifests.yaml\"\n\t$(CONTROLLER_GEN) \\\n\t\tpaths=./controlplane/kubeadm \\\n\t\tpaths=./controlplane/kubeadm/api/... \\\n\t\tpaths=./controlplane/kubeadm/internal/controllers/... \\\n\t\tpaths=./controlplane/kubeadm/internal/webhooks/... \\\n\t\tpaths=./internal/apis/controlplane/kubeadm/... \\\n\t\tcrd:crdVersions=v1 \\\n\t\trbac:roleName=manager-role \\\n\t\toutput:crd:dir=./controlplane/kubeadm/config/crd/bases \\\n\t\toutput:rbac:dir=./controlplane/kubeadm/config/rbac \\\n\t\toutput:webhook:dir=./controlplane/kubeadm/config/webhook \\\n\t\twebhook\n\n.PHONY: generate-manifests-docker-infrastructure\ngenerate-manifests-docker-infrastructure: $(CONTROLLER_GEN) ## Generate manifests e.g. CRD, RBAC etc. for docker infrastructure provider\n\t$(MAKE) clean-generated-yaml SRC_DIRS=\"$(CAPD_DIR)/config/crd/bases,$(CAPD_DIR)/config/webhook/manifests.yaml\"\n\tcd $(CAPD_DIR); $(CONTROLLER_GEN) \\\n\t\tpaths=./ \\\n\t\tpaths=./api/... \\\n\t\tpaths=./$(EXP_DIR)/api/... \\\n\t\tpaths=./$(EXP_DIR)/internal/controllers/... \\\n\t\tpaths=./$(EXP_DIR)/internal/webhooks/... \\\n\t\tpaths=./internal/controllers/... \\\n\t\tpaths=./internal/webhooks/... \\\n\t\tcrd:crdVersions=v1 \\\n\t\trbac:roleName=manager-role \\\n\t\toutput:crd:dir=./config/crd/bases \\\n\t\toutput:webhook:dir=./config/webhook \\\n\t\twebhook\n\n\n.PHONY: generate-manifests-in-memory-infrastructure\ngenerate-manifests-in-memory-infrastructure: $(CONTROLLER_GEN) ## Generate manifests e.g. CRD, RBAC etc. for in-memory infrastructure provider\n\t$(MAKE) clean-generated-yaml SRC_DIRS=\"$(CAPIM_DIR)/config/crd/bases,$(CAPIM_DIR)/config/webhook/manifests.yaml\"\n\tcd $(CAPIM_DIR); $(CONTROLLER_GEN) \\\n\t\tpaths=./ \\\n\t\tpaths=./api/... \\\n\t\tpaths=./internal/controllers/... \\\n\t\tpaths=./internal/webhooks/... \\\n\t\tcrd:crdVersions=v1 \\\n\t\trbac:roleName=manager-role \\\n\t\toutput:crd:dir=./config/crd/bases \\\n\t\toutput:webhook:dir=./config/webhook \\\n\t\twebhook\n\n.PHONY: generate-manifests-test-extension\ngenerate-manifests-test-extension: $(CONTROLLER_GEN) ## Generate manifests e.g. RBAC for test-extension provider\n\tcd ./test/extension; $(CONTROLLER_GEN) \\\n\t\tpaths=./... \\\n\t\toutput:rbac:dir=./config/rbac \\\n\t\trbac:roleName=manager-role\n\n.PHONY: generate-go-deepcopy\ngenerate-go-deepcopy:  ## Run all generate-go-deepcopy-* targets\n\t$(MAKE) $(addprefix generate-go-deepcopy-,$(ALL_GENERATE_MODULES))\n\n.PHONY: generate-go-deepcopy-core\ngenerate-go-deepcopy-core: $(CONTROLLER_GEN) ## Generate deepcopy go code for core\n\t$(MAKE) clean-generated-deepcopy SRC_DIRS=\"./api,./$(EXP_DIR)/api,./$(EXP_DIR)/addons/api,./$(EXP_DIR)/runtime/api,./$(EXP_DIR)/runtime/hooks/api\"\n\t$(CONTROLLER_GEN) \\\n\t\tobject:headerFile=./hack/boilerplate/boilerplate.generatego.txt \\\n\t\tpaths=./api/... \\\n\t\tpaths=./$(EXP_DIR)/api/... \\\n\t\tpaths=./$(EXP_DIR)/addons/api/... \\\n\t\tpaths=./$(EXP_DIR)/ipam/api/... \\\n\t\tpaths=./$(EXP_DIR)/runtime/api/... \\\n\t\tpaths=./$(EXP_DIR)/runtime/hooks/api/... \\\n\t\tpaths=./internal/runtime/test/... \\\n\t\tpaths=./cmd/clusterctl/... \\\n\t\tpaths=./util/test/builder/...\n\n.PHONY: generate-go-deepcopy-kubeadm-bootstrap\ngenerate-go-deepcopy-kubeadm-bootstrap: $(CONTROLLER_GEN) ## Generate deepcopy go code for kubeadm bootstrap\n\t$(MAKE) clean-generated-deepcopy SRC_DIRS=\"./bootstrap/kubeadm/api,./bootstrap/kubeadm/types\"\n\t$(CONTROLLER_GEN) \\\n\t\tobject:headerFile=./hack/boilerplate/boilerplate.generatego.txt \\\n\t\tpaths=./bootstrap/kubeadm/api/... \\\n\t\tpaths=./bootstrap/kubeadm/types/...\n\n.PHONY: generate-go-deepcopy-kubeadm-control-plane\ngenerate-go-deepcopy-kubeadm-control-plane: $(CONTROLLER_GEN) ## Generate deepcopy go code for kubeadm control plane\n\t$(MAKE) clean-generated-deepcopy SRC_DIRS=\"./controlplane/kubeadm/api\"\n\t$(CONTROLLER_GEN) \\\n\t\tobject:headerFile=./hack/boilerplate/boilerplate.generatego.txt \\\n\t\tpaths=./controlplane/kubeadm/api/...\n\n.PHONY: generate-go-deepcopy-docker-infrastructure\ngenerate-go-deepcopy-docker-infrastructure: $(CONTROLLER_GEN) ## Generate deepcopy go code for docker infrastructure provider\n\t$(MAKE) clean-generated-deepcopy SRC_DIRS=\"$(CAPD_DIR)/api,$(CAPD_DIR)/$(EXP_DIR)/api\"\n\tcd $(CAPD_DIR); $(CONTROLLER_GEN) \\\n\t\tobject:headerFile=../../../hack/boilerplate/boilerplate.generatego.txt \\\n\t\tpaths=./api/... \\\n\t\tpaths=./$(EXP_DIR)/api/...\n\n.PHONY: generate-go-deepcopy-in-memory-infrastructure\ngenerate-go-deepcopy-in-memory-infrastructure: $(CONTROLLER_GEN) ## Generate deepcopy go code for in-memory infrastructure provider\n\t$(MAKE) clean-generated-deepcopy SRC_DIRS=\"$(CAPIM_DIR)/api,$(CAPIM_DIR)/internal/cloud/api\"\n\tcd $(CAPIM_DIR); $(CONTROLLER_GEN) \\\n\t\tobject:headerFile=../../../hack/boilerplate/boilerplate.generatego.txt \\\n\t\tpaths=./api/... \\\n        paths=./internal/cloud/api/...\n\n.PHONY: generate-go-deepcopy-test-extension\ngenerate-go-deepcopy-test-extension: $(CONTROLLER_GEN) ## Generate deepcopy go code for test-extension\n\n.PHONY: generate-go-conversions\ngenerate-go-conversions: ## Run all generate-go-conversions-* targets\n\t$(MAKE) $(addprefix generate-go-conversions-,$(ALL_GENERATE_MODULES))\n\n.PHONY: generate-go-conversions-core\ngenerate-go-conversions-core: ## Run all generate-go-conversions-core-* targets\n\t$(MAKE) generate-go-conversions-core-api\n\t$(MAKE) generate-go-conversions-core-exp\n\t$(MAKE) generate-go-conversions-core-exp-ipam\n\t$(MAKE) generate-go-conversions-core-runtime\n\n.PHONY: generate-go-conversions-core-api\ngenerate-go-conversions-core-api: $(CONVERSION_GEN) ## Generate conversions go code for core api\n\t$(MAKE) clean-generated-conversions SRC_DIRS=\"./internal/apis/core/v1alpha3,./internal/apis/core/v1alpha4\"\n\t$(CONVERSION_GEN) \\\n\t\t--output-file=zz_generated.conversion.go \\\n\t\t--go-header-file=./hack/boilerplate/boilerplate.generatego.txt \\\n\t\t./internal/apis/core/v1alpha3 \\\n\t\t./internal/apis/core/v1alpha4\n\n.PHONY: generate-go-conversions-core-exp\ngenerate-go-conversions-core-exp: $(CONVERSION_GEN) ## Generate conversions go code for core exp\n\t$(MAKE) clean-generated-conversions SRC_DIRS=\"./internal/apis/core/exp/v1alpha3,./internal/apis/core/exp/addons/v1alpha3,./internal/apis/core/exp/v1alpha4,./internal/apis/core/exp/addons/v1alpha4\"\n\t$(CONVERSION_GEN) \\\n\t\t--extra-dirs=sigs.k8s.io/cluster-api/internal/apis/core/v1alpha3 \\\n\t\t--extra-dirs=sigs.k8s.io/cluster-api/internal/apis/core/v1alpha4 \\\n\t\t--output-file=zz_generated.conversion.go \\\n\t\t--go-header-file=./hack/boilerplate/boilerplate.generatego.txt \\\n\t\t./internal/apis/core/exp/v1alpha3 \\\n\t\t./internal/apis/core/exp/v1alpha4 \\\n\t\t./internal/apis/core/exp/addons/v1alpha3 \\\n\t\t./internal/apis/core/exp/addons/v1alpha4\n\n.PHONY: generate-go-conversions-core-exp-ipam\ngenerate-go-conversions-core-exp-ipam: $(CONVERSION_GEN) ## Generate conversions go code for core exp IPAM\n\t$(MAKE) clean-generated-conversions SRC_DIRS=\"./$(EXP_DIR)/ipam/api/v1alpha1\"\n\t$(CONVERSION_GEN) \\\n\t\t--output-file=zz_generated.conversion.go \\\n\t\t--go-header-file=./hack/boilerplate/boilerplate.generatego.txt \\\n\t\t./$(EXP_DIR)/ipam/api/v1alpha1\n\n.PHONY: generate-go-conversions-core-runtime\ngenerate-go-conversions-core-runtime: $(CONVERSION_GEN) ## Generate conversions go code for core runtime\n\t$(MAKE) clean-generated-conversions SRC_DIRS=\"./internal/runtime/test/v1alpha1,./internal/runtime/test/v1alpha2\"\n\t$(CONVERSION_GEN) \\\n\t\t--output-file=zz_generated.conversion.go \\\n\t\t--go-header-file=./hack/boilerplate/boilerplate.generatego.txt \\\n\t\t./internal/runtime/test/v1alpha1 \\\n\t\t./internal/runtime/test/v1alpha2\n\n.PHONY: generate-go-conversions-kubeadm-bootstrap\ngenerate-go-conversions-kubeadm-bootstrap: $(CONVERSION_GEN) ## Generate conversions go code for kubeadm bootstrap\n\t$(MAKE) clean-generated-conversions SRC_DIRS=\"./internal/apis/bootstrap/kubeadm\"\n\t$(CONVERSION_GEN) \\\n\t\t--output-file=zz_generated.conversion.go \\\n\t\t--go-header-file=./hack/boilerplate/boilerplate.generatego.txt \\\n\t\t./internal/apis/bootstrap/kubeadm/v1alpha3 \\\n\t\t./internal/apis/bootstrap/kubeadm/v1alpha4\n\t$(MAKE) clean-generated-conversions SRC_DIRS=\"./bootstrap/kubeadm/types/upstreamv1beta1,./bootstrap/kubeadm/types/upstreamv1beta2,./bootstrap/kubeadm/types/upstreamv1beta3,./bootstrap/kubeadm/types/upstreamv1beta4\"\n\t$(CONVERSION_GEN) \\\n\t\t--output-file=zz_generated.conversion.go \\\n\t\t--go-header-file=./hack/boilerplate/boilerplate.generatego.txt \\\n\t\t./bootstrap/kubeadm/types/upstreamv1beta1 \\\n\t\t./bootstrap/kubeadm/types/upstreamv1beta2 \\\n\t\t./bootstrap/kubeadm/types/upstreamv1beta3 \\\n\t\t./bootstrap/kubeadm/types/upstreamv1beta4\n\n.PHONY: generate-go-conversions-kubeadm-control-plane\ngenerate-go-conversions-kubeadm-control-plane: $(CONVERSION_GEN) ## Generate conversions go code for kubeadm control plane\n\t$(MAKE) clean-generated-conversions SRC_DIRS=\"./internal/apis/controlplane/kubeadm\"\n\t$(CONVERSION_GEN) \\\n\t\t--extra-dirs=sigs.k8s.io/cluster-api/internal/apis/core/v1alpha3 \\\n\t\t--extra-dirs=sigs.k8s.io/cluster-api/internal/apis/core/v1alpha4 \\\n\t\t--extra-dirs=sigs.k8s.io/cluster-api/internal/apis/bootstrap/kubeadm/v1alpha3 \\\n\t\t--extra-dirs=sigs.k8s.io/cluster-api/internal/apis/bootstrap/kubeadm/v1alpha4 \\\n\t\t--output-file=zz_generated.conversion.go \\\n\t\t--go-header-file=./hack/boilerplate/boilerplate.generatego.txt \\\n\t\t./internal/apis/controlplane/kubeadm/v1alpha3 \\\n\t\t./internal/apis/controlplane/kubeadm/v1alpha4\n\n.PHONY: generate-go-conversions-docker-infrastructure\ngenerate-go-conversions-docker-infrastructure: $(CONVERSION_GEN) ## Generate conversions go code for docker infrastructure provider\n\tcd $(CAPD_DIR); $(CONVERSION_GEN) \\\n\t\t--output-file=zz_generated.conversion.go \\\n\t\t--go-header-file=../../../hack/boilerplate/boilerplate.generatego.txt \\\n\t\t./api/v1alpha3 \\\n\t\t./api/v1alpha4 \\\n\t\t./$(EXP_DIR)/api/v1alpha3 \\\n\t\t./$(EXP_DIR)/api/v1alpha4\n\n.PHONY: generate-go-conversions-in-memory-infrastructure\ngenerate-go-conversions-in-memory-infrastructure: $(CONVERSION_GEN) ## Generate conversions go code for in-memory infrastructure provider\n\tcd $(CAPIM_DIR)\n\n.PHONY: generate-go-conversions-test-extension\ngenerate-go-conversions-test-extension: $(CONVERSION_GEN) ## Generate conversions go code for in-memory infrastructure provider\n\n# The tmp/sigs.k8s.io/cluster-api symlink is a workaround to make this target run outside of GOPATH\n.PHONY: generate-go-openapi\ngenerate-go-openapi: $(OPENAPI_GEN) $(CONTROLLER_GEN) ## Generate openapi go code for runtime SDK\n\t@mkdir -p ./tmp/sigs.k8s.io; ln -s $(ROOT_DIR) ./tmp/sigs.k8s.io/; cd ./tmp; \\\n\tfor pkg in \"api/v1beta1\" \"$(EXP_DIR)/runtime/hooks/api/v1alpha1\"; do \\\n\t\t(cd ../ && $(MAKE) clean-generated-openapi-definitions SRC_DIRS=\"./$${pkg}\"); \\\n\t\techo \"** Generating openapi schema for types in ./$${pkg} **\"; \\\n\t\t$(OPENAPI_GEN) \\\n\t\t\t--output-dir=../$${pkg} \\\n\t\t\t--output-file=zz_generated.openapi.go \\\n\t\t\t--output-pkg=sigs.k8s.io/cluster-api/$${pkg} \\\n\t\t\t--go-header-file=../hack/boilerplate/boilerplate.generatego.txt \\\n\t\t\tsigs.k8s.io/cluster-api/$${pkg}; \\\n\tdone; \\\n\trm sigs.k8s.io/cluster-api\n\n.PHONY: generate-modules\ngenerate-modules: ## Run go mod tidy to ensure modules are up to date\n\tgo mod tidy\n\tcd $(TOOLS_DIR); go mod tidy\n\tcd $(TEST_DIR); go mod tidy\n\n.PHONY: generate-doctoc\ngenerate-doctoc:\n\tTRACE=$(TRACE) ./hack/generate-doctoc.sh\n\n.PHONY: generate-e2e-templates\ngenerate-e2e-templates: $(KUSTOMIZE) $(addprefix generate-e2e-templates-, v0.3 v0.4 v1.0 v1.5 v1.6 v1.8 v1.9 main) ## Generate cluster templates for all versions\n\nDOCKER_TEMPLATES := test/e2e/data/infrastructure-docker\nINMEMORY_TEMPLATES := test/e2e/data/infrastructure-inmemory\n\n.PHONY: generate-e2e-templates-v0.3\ngenerate-e2e-templates-v0.3: $(KUSTOMIZE)\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/v0.3/cluster-template --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/v0.3/cluster-template.yaml\n\n.PHONY: generate-e2e-templates-v0.4\ngenerate-e2e-templates-v0.4: $(KUSTOMIZE)\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/v0.4/cluster-template --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/v0.4/cluster-template.yaml\n\n.PHONY: generate-e2e-templates-v1.0\ngenerate-e2e-templates-v1.0: $(KUSTOMIZE)\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/v1.0/cluster-template --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/v1.0/cluster-template.yaml\n\n.PHONY: generate-e2e-templates-v1.5\ngenerate-e2e-templates-v1.5: $(KUSTOMIZE)\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/v1.5/cluster-template --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/v1.5/cluster-template.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/v1.5/cluster-template-topology --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/v1.5/cluster-template-topology.yaml\n\n.PHONY: generate-e2e-templates-v1.6\ngenerate-e2e-templates-v1.6: $(KUSTOMIZE)\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/v1.6/cluster-template --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/v1.6/cluster-template.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/v1.6/cluster-template-topology --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/v1.6/cluster-template-topology.yaml\n\n.PHONY: generate-e2e-templates-v1.8\ngenerate-e2e-templates-v1.8: $(KUSTOMIZE)\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/v1.8/cluster-template --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/v1.8/cluster-template.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/v1.8/cluster-template-topology --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/v1.8/cluster-template-topology.yaml\n\n.PHONY: generate-e2e-templates-v1.9\ngenerate-e2e-templates-v1.9: $(KUSTOMIZE)\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/v1.9/cluster-template --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/v1.9/cluster-template.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/v1.9/cluster-template-topology --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/v1.9/cluster-template-topology.yaml\n\n.PHONY: generate-e2e-templates-main\ngenerate-e2e-templates-main: $(KUSTOMIZE)\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/main/cluster-template --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/main/cluster-template.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/main/cluster-template-md-remediation --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/main/cluster-template-md-remediation.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/main/cluster-template-kcp-remediation --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/main/cluster-template-kcp-remediation.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/main/cluster-template-kcp-adoption/step1 --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/main/cluster-template-kcp-adoption.yaml\n\techo \"---\" >> $(DOCKER_TEMPLATES)/main/cluster-template-kcp-adoption.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/main/cluster-template-kcp-adoption/step2 --load-restrictor LoadRestrictionsNone >> $(DOCKER_TEMPLATES)/main/cluster-template-kcp-adoption.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/main/cluster-template-machine-pool --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/main/cluster-template-machine-pool.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/main/cluster-template-upgrades --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/main/cluster-template-upgrades.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/main/cluster-template-upgrades-runtimesdk --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/main/cluster-template-upgrades-runtimesdk.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/main/cluster-template-kcp-pre-drain --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/main/cluster-template-kcp-pre-drain.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/main/cluster-template-kcp-scale-in --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/main/cluster-template-kcp-scale-in.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/main/cluster-template-ipv6 --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/main/cluster-template-ipv6.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/main/cluster-template-topology-dualstack-ipv6-primary --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/main/cluster-template-topology-dualstack-ipv6-primary.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/main/cluster-template-topology-dualstack-ipv4-primary --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/main/cluster-template-topology-dualstack-ipv4-primary.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/main/cluster-template-topology-no-workers --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/main/cluster-template-topology-no-workers.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/main/cluster-template-topology-kcp-only --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/main/cluster-template-topology-kcp-only.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/main/cluster-template-topology-autoscaler --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/main/cluster-template-topology-autoscaler.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/main/cluster-template-topology --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/main/cluster-template-topology.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/main/cluster-template-ignition --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/main/cluster-template-ignition.yaml\n\t$(KUSTOMIZE) build $(DOCKER_TEMPLATES)/main/clusterclass-quick-start-kcp-only --load-restrictor LoadRestrictionsNone > $(DOCKER_TEMPLATES)/main/clusterclass-quick-start-kcp-only.yaml\n\n\t$(KUSTOMIZE) build $(INMEMORY_TEMPLATES)/main/cluster-template --load-restrictor LoadRestrictionsNone > $(INMEMORY_TEMPLATES)/main/cluster-template.yaml\n\n.PHONY: generate-metrics-config\ngenerate-metrics-config: $(ENVSUBST_BIN) ## Generate ./config/metrics/crd-metrics-config.yaml\n\tOUTPUT_FILE=\"./config/metrics/crd-metrics-config.yaml\"; \\\n\tMETRIC_TEMPLATES_DIR=\"./config/metrics/templates\"; \\\n\techo \"# This file was auto-generated via: make generate-metrics-config\" > \"$${OUTPUT_FILE}\"; \\\n\tcat \"$${METRIC_TEMPLATES_DIR}/header.yaml\" >> \"$${OUTPUT_FILE}\"; \\\n\tfor resource in clusterclass cluster kubeadmcontrolplane kubeadmconfig machine machinedeployment machinehealthcheck machineset machinepool; do \\\n\t\tcat \"$${METRIC_TEMPLATES_DIR}/$${resource}.yaml\"; \\\n\t\tRESOURCE=\"$${resource}\" ${ENVSUBST_BIN} < \"$${METRIC_TEMPLATES_DIR}/common_metrics.yaml\"; \\\n\t\tif [[ \"$${resource}\" != \"cluster\" ]]; then \\\n\t\t\tcat \"$${METRIC_TEMPLATES_DIR}/owner_metric.yaml\"; \\\n\t\tfi \\\n\tdone >> \"$${OUTPUT_FILE}\"; \\\n\n.PHONY: generate-diagrams\ngenerate-diagrams: ## Generate diagrams for *.plantuml files\n\t$(MAKE) generate-diagrams-book\n\t$(MAKE) generate-diagrams-proposals\n\n.PHONY: generate-diagrams-book\ngenerate-diagrams-book: ## Generate diagrams for *.plantuml files in book\n\tdocker run -v $(ROOT_DIR)/$(DOCS_DIR):/$(DOCS_DIR)$(DOCKER_VOL_OPTS)  plantuml/plantuml:$(PLANTUML_VER) /$(DOCS_DIR)/book/**/*.plantuml\n\n.PHONY: generate-diagrams-proposals\ngenerate-diagrams-proposals: ## Generate diagrams for *.plantuml files in proposals\n\tdocker run -v $(ROOT_DIR)/$(DOCS_DIR):/$(DOCS_DIR)$(DOCKER_VOL_OPTS)  plantuml/plantuml:$(PLANTUML_VER) /$(DOCS_DIR)/proposals/**/*.plantuml\n\n.PHONY: generate-test-infra-prowjobs\ngenerate-test-infra-prowjobs: $(PROWJOB_GEN) ## Generates the prowjob configurations in test-infra\n\t@if [ -z \"${TEST_INFRA_DIR}\" ]; then echo \"TEST_INFRA_DIR is not set\"; exit 1; fi\n\t$(PROWJOB_GEN) \\\n\t\t-config \"$(TEST_INFRA_DIR)/config/jobs/kubernetes-sigs/cluster-api/cluster-api-prowjob-gen.yaml\" \\\n\t\t-templates-dir \"$(TEST_INFRA_DIR)/config/jobs/kubernetes-sigs/cluster-api/templates\" \\\n\t\t-output-dir \"$(TEST_INFRA_DIR)/config/jobs/kubernetes-sigs/cluster-api\"\n\n## --------------------------------------\n## Lint / Verify\n## --------------------------------------\n\n##@ lint and verify:\n\n.PHONY: lint\nlint: $(GOLANGCI_LINT) ## Lint the codebase\n\t$(GOLANGCI_LINT) run -v $(GOLANGCI_LINT_EXTRA_ARGS)\n\tcd $(TEST_DIR); $(GOLANGCI_LINT) run --path-prefix $(TEST_DIR) --config $(ROOT_DIR)/.golangci.yml -v $(GOLANGCI_LINT_EXTRA_ARGS)\n\tcd $(TOOLS_DIR); $(GOLANGCI_LINT) run --path-prefix $(TOOLS_DIR) --config $(ROOT_DIR)/.golangci.yml -v $(GOLANGCI_LINT_EXTRA_ARGS)\n\t./scripts/lint-dockerfiles.sh $(HADOLINT_VER) $(HADOLINT_FAILURE_THRESHOLD)\n\n.PHONY: lint-dockerfiles\nlint-dockerfiles:\n\t./scripts/lint-dockerfiles.sh $(HADOLINT_VER) $(HADOLINT_FAILURE_THRESHOLD)\n\n.PHONY: lint-fix\nlint-fix: $(GOLANGCI_LINT) ## Lint the codebase and run auto-fixers if supported by the linter\n\tGOLANGCI_LINT_EXTRA_ARGS=--fix $(MAKE) lint\n\n.PHONY: tiltfile-fix\ntiltfile-fix: ## Format the Tiltfile\n\tTRACE=$(TRACE) ./hack/verify-starlark.sh fix\n\nAPIDIFF_OLD_COMMIT ?= $(shell git rev-parse origin/main)\n\n.PHONY: apidiff\napidiff: $(GO_APIDIFF) ## Check for API differences\n\t$(GO_APIDIFF) $(APIDIFF_OLD_COMMIT) --print-compatible\n\nALL_VERIFY_CHECKS = licenses boilerplate shellcheck tiltfile modules gen conversions doctoc capi-book-summary diagrams import-restrictions go-directive\n\n.PHONY: verify\nverify: $(addprefix verify-,$(ALL_VERIFY_CHECKS)) lint-dockerfiles ## Run all verify-* targets\n\n.PHONY: verify-go-directive\nverify-go-directive:\n\tTRACE=$(TRACE) ./hack/verify-go-directive.sh -g $(GO_DIRECTIVE_VERSION)\n\n.PHONY: verify-modules\nverify-modules: generate-modules  ## Verify go modules are up to date\n\t@if !(git diff --quiet HEAD -- go.sum go.mod $(TOOLS_DIR)/go.mod $(TOOLS_DIR)/go.sum $(TEST_DIR)/go.mod $(TEST_DIR)/go.sum); then \\\n\t\tgit diff; \\\n\t\techo \"go module files are out of date\"; exit 1; \\\n\tfi\n\t@if (find . -name 'go.mod' | xargs -n1 grep -q -i 'k8s.io/client-go.*+incompatible'); then \\\n\t\tfind . -name \"go.mod\" -exec grep -i 'k8s.io/client-go.*+incompatible' {} \\; -print; \\\n\t\techo \"go module contains an incompatible client-go version\"; exit 1; \\\n\tfi\n\n.PHONY: verify-gen\nverify-gen: generate  ## Verify go generated files are up to date\n\t@if !(git diff --quiet HEAD); then \\\n\t\tgit diff; \\\n\t\techo \"generated files are out of date, run make generate\"; exit 1; \\\n\tfi\n\n.PHONY: verify-conversions\nverify-conversions: $(CONVERSION_VERIFIER)  ## Verifies expected API conversion are in place\n\t$(CONVERSION_VERIFIER)\n\n.PHONY: verify-doctoc\nverify-doctoc: generate-doctoc\n\t@if !(git diff --quiet HEAD); then \\\n\t\tgit diff; \\\n\t\techo \"doctoc is out of date, run make generate-doctoc\"; exit 1; \\\n\tfi\n\n.PHONY: verify-capi-book-summary\nverify-capi-book-summary:\n\tTRACE=$(TRACE) ./hack/verify-capi-book-summary.sh\n\n.PHONY: verify-boilerplate\nverify-boilerplate: ## Verify boilerplate text exists in each file\n\tTRACE=$(TRACE) ./hack/verify-boilerplate.sh\n\n.PHONY: verify-shellcheck\nverify-shellcheck: ## Verify shell files\n\tTRACE=$(TRACE) ./hack/verify-shellcheck.sh $(SHELLCHECK_VER)\n\n.PHONY: verify-tiltfile\nverify-tiltfile: ## Verify Tiltfile format\n\tTRACE=$(TRACE) ./hack/verify-starlark.sh\n\n.PHONY: verify-container-images\nverify-container-images: ## Verify container images\n\tTRACE=$(TRACE) ./hack/verify-container-images.sh $(TRIVY_VER)\n\n.PHONY: verify-licenses\nverify-licenses: ## Verify licenses\n\tTRACE=$(TRACE) ./hack/verify-licenses.sh $(TRIVY_VER)\n\n.PHONY: verify-govulncheck\nverify-govulncheck: $(GOVULNCHECK) ## Verify code for vulnerabilities\n\t$(GOVULNCHECK) ./... && R1=$$? || R1=$$?; \\\n\t$(GOVULNCHECK) -C \"$(TOOLS_DIR)\" ./... && R2=$$? || R2=$$?; \\\n\t$(GOVULNCHECK) -C \"$(TEST_DIR)\" ./... && R3=$$? || R3=$$?; \\\n\tif [ \"$$R1\" -ne \"0\" ] || [ \"$$R2\" -ne \"0\" ] || [ \"$$R3\" -ne \"0\" ]; then \\\n\t\texit 1; \\\n\tfi\n\n.PHONY: verify-diagrams\nverify-diagrams: generate-diagrams ## Verify generated diagrams are up to date\n\t@if !(git diff --quiet HEAD); then \\\n\t\tgit diff; \\\n\t\techo \"generated diagrams are out of date, run make generate-diagrams\"; exit 1; \\\n\tfi\n\n.PHONY: verify-security\nverify-security: ## Verify code and images for vulnerabilities\n\t$(MAKE) verify-container-images && R1=$$? || R1=$$?; \\\n\t$(MAKE) verify-govulncheck && R2=$$? || R2=$$?; \\\n\tif [ \"$$R1\" -ne \"0\" ] || [ \"$$R2\" -ne \"0\" ]; then \\\n\t  echo \"Check for vulnerabilities failed! There are vulnerabilities to be fixed\"; \\\n\t\texit 1; \\\n\tfi\n\n.PHONY: verify-import-restrictions\nverify-import-restrictions: $(IMPORT_BOSS) ## Verify import restrictions with import-boss\n\t./hack/verify-import-restrictions.sh\n\n## --------------------------------------\n## Binaries\n## --------------------------------------\n\n##@ build:\n\n.PHONY: clusterctl\nclusterctl: ## Build the clusterctl binary\n\tgo build -trimpath -ldflags \"$(LDFLAGS)\" -o $(BIN_DIR)/clusterctl sigs.k8s.io/cluster-api/cmd/clusterctl\n\nALL_MANAGERS = core kubeadm-bootstrap kubeadm-control-plane docker-infrastructure in-memory-infrastructure\n\n.PHONY: managers\nmanagers: $(addprefix manager-,$(ALL_MANAGERS)) ## Run all manager-* targets\n\n.PHONY: manager-core\nmanager-core: ## Build the core manager binary into the ./bin folder\n\tgo build -trimpath -ldflags \"$(LDFLAGS)\" -o $(BIN_DIR)/manager sigs.k8s.io/cluster-api\n\n.PHONY: manager-kubeadm-bootstrap\nmanager-kubeadm-bootstrap: ## Build the kubeadm bootstrap manager binary into the ./bin folder\n\tgo build -trimpath -ldflags \"$(LDFLAGS)\" -o $(BIN_DIR)/kubeadm-bootstrap-manager sigs.k8s.io/cluster-api/bootstrap/kubeadm\n\n.PHONY: manager-kubeadm-control-plane\nmanager-kubeadm-control-plane: ## Build the kubeadm control plane manager binary into the ./bin folder\n\tgo build -trimpath -ldflags \"$(LDFLAGS)\" -o $(BIN_DIR)/kubeadm-control-plane-manager sigs.k8s.io/cluster-api/controlplane/kubeadm\n\n.PHONY: manager-docker-infrastructure\nmanager-docker-infrastructure: ## Build the docker infrastructure manager binary into the ./bin folder\n\tcd $(CAPD_DIR); go build -trimpath -ldflags \"$(LDFLAGS)\" -o ../../../$(BIN_DIR)/capd-manager sigs.k8s.io/cluster-api/test/infrastructure/docker\n\n.PHONY: manager-in-memory-infrastructure\nmanager-in-memory-infrastructure: ## Build the in-memory-infrastructure infrastructure manager binary into the ./bin folder\n\tcd $(CAPIM_DIR); go build -trimpath -ldflags \"$(LDFLAGS)\" -o ../../../$(BIN_DIR)/capim-manager sigs.k8s.io/cluster-api/test/infrastructure/inmemory\n\n.PHONY: docker-pull-prerequisites\ndocker-pull-prerequisites:\n\tdocker pull docker.io/docker/dockerfile:1.4\n\tdocker pull $(GO_CONTAINER_IMAGE)\n\tdocker pull gcr.io/distroless/static:latest\n\n.PHONY: docker-build-all\ndocker-build-all: $(addprefix docker-build-,$(ALL_ARCH)) ## Build docker images for all architectures\n\ndocker-build-%:\n\t$(MAKE) ARCH=$* docker-build\n\n# Choice of images to build/push\nALL_DOCKER_BUILD ?= core kubeadm-bootstrap kubeadm-control-plane docker-infrastructure in-memory-infrastructure test-extension clusterctl\n\n.PHONY: docker-build\ndocker-build: docker-pull-prerequisites ## Run docker-build-* targets for all the images\n\t$(MAKE) ARCH=$(ARCH) $(addprefix docker-build-,$(ALL_DOCKER_BUILD))\n\nALL_DOCKER_BUILD_E2E = core kubeadm-bootstrap kubeadm-control-plane docker-infrastructure in-memory-infrastructure test-extension\n\n.PHONY: docker-build-e2e\ndocker-build-e2e: ## Run docker-build-* targets for all the images with settings to be used for the e2e tests\n    # please ensure the generated image name matches image names used in the E2E_CONF_FILE;\n    # also the same settings must exist in ci-e2e-lib.sh, capi:buildDockerImage func.\n\t$(MAKE) REGISTRY=gcr.io/k8s-staging-cluster-api PULL_POLICY=IfNotPresent TAG=dev $(addprefix docker-build-,$(ALL_DOCKER_BUILD_E2E))\n\n.PHONY: docker-build-core\ndocker-build-core: ## Build the docker image for core controller manager\n## reads Dockerfile from stdin to avoid an incorrectly cached Dockerfile (https://github.com/moby/buildkit/issues/1368)\n\tcat ./Dockerfile | DOCKER_BUILDKIT=1 docker build --build-arg builder_image=$(GO_CONTAINER_IMAGE) --build-arg goproxy=$(GOPROXY) --build-arg ARCH=$(ARCH) --build-arg ldflags=\"$(LDFLAGS)\" . -t $(CONTROLLER_IMG)-$(ARCH):$(TAG) --file -\n\t$(MAKE) set-manifest-image MANIFEST_IMG=$(CONTROLLER_IMG)-$(ARCH) MANIFEST_TAG=$(TAG) TARGET_RESOURCE=\"./config/default/manager_image_patch.yaml\"\n\t$(MAKE) set-manifest-pull-policy TARGET_RESOURCE=\"./config/default/manager_pull_policy.yaml\"\n\n.PHONY: docker-build-kubeadm-bootstrap\ndocker-build-kubeadm-bootstrap: ## Build the docker image for kubeadm bootstrap controller manager\n## reads Dockerfile from stdin to avoid an incorrectly cached Dockerfile (https://github.com/moby/buildkit/issues/1368)\n\tcat ./Dockerfile | DOCKER_BUILDKIT=1 docker build --build-arg builder_image=$(GO_CONTAINER_IMAGE) --build-arg goproxy=$(GOPROXY) --build-arg ARCH=$(ARCH) --build-arg package=./bootstrap/kubeadm --build-arg ldflags=\"$(LDFLAGS)\" . -t $(KUBEADM_BOOTSTRAP_CONTROLLER_IMG)-$(ARCH):$(TAG) --file -\n\t$(MAKE) set-manifest-image MANIFEST_IMG=$(KUBEADM_BOOTSTRAP_CONTROLLER_IMG)-$(ARCH) MANIFEST_TAG=$(TAG) TARGET_RESOURCE=\"./bootstrap/kubeadm/config/default/manager_image_patch.yaml\"\n\t$(MAKE) set-manifest-pull-policy TARGET_RESOURCE=\"./bootstrap/kubeadm/config/default/manager_pull_policy.yaml\"\n\n.PHONY: docker-build-kubeadm-control-plane\ndocker-build-kubeadm-control-plane: ## Build the docker image for kubeadm control plane controller manager\n## reads Dockerfile from stdin to avoid an incorrectly cached Dockerfile (https://github.com/moby/buildkit/issues/1368)\n\tcat ./Dockerfile | DOCKER_BUILDKIT=1 docker build --build-arg builder_image=$(GO_CONTAINER_IMAGE) --build-arg goproxy=$(GOPROXY) --build-arg ARCH=$(ARCH) --build-arg package=./controlplane/kubeadm --build-arg ldflags=\"$(LDFLAGS)\" . -t $(KUBEADM_CONTROL_PLANE_CONTROLLER_IMG)-$(ARCH):$(TAG) --file -\n\t$(MAKE) set-manifest-image MANIFEST_IMG=$(KUBEADM_CONTROL_PLANE_CONTROLLER_IMG)-$(ARCH) MANIFEST_TAG=$(TAG) TARGET_RESOURCE=\"./controlplane/kubeadm/config/default/manager_image_patch.yaml\"\n\t$(MAKE) set-manifest-pull-policy TARGET_RESOURCE=\"./controlplane/kubeadm/config/default/manager_pull_policy.yaml\"\n\n.PHONY: docker-build-docker-infrastructure\ndocker-build-docker-infrastructure: ## Build the docker image for docker infrastructure controller manager\n## reads Dockerfile from stdin to avoid an incorrectly cached Dockerfile (https://github.com/moby/buildkit/issues/1368)\n\tcat $(CAPD_DIR)/Dockerfile | DOCKER_BUILDKIT=1 docker build --build-arg builder_image=$(GO_CONTAINER_IMAGE) --build-arg goproxy=$(GOPROXY) --build-arg ARCH=$(ARCH) --build-arg ldflags=\"$(LDFLAGS)\" . -t $(CAPD_CONTROLLER_IMG)-$(ARCH):$(TAG) --file -\n\t$(MAKE) set-manifest-image MANIFEST_IMG=$(CAPD_CONTROLLER_IMG)-$(ARCH) MANIFEST_TAG=$(TAG) TARGET_RESOURCE=\"$(CAPD_DIR)/config/default/manager_image_patch.yaml\"\n\t$(MAKE) set-manifest-pull-policy TARGET_RESOURCE=\"$(CAPD_DIR)/config/default/manager_pull_policy.yaml\"\n\n.PHONY: docker-build-in-memory-infrastructure\ndocker-build-in-memory-infrastructure: ## Build the docker image for in-memory infrastructure controller manager\n## reads Dockerfile from stdin to avoid an incorrectly cached Dockerfile (https://github.com/moby/buildkit/issues/1368)\n\tcat $(CAPIM_DIR)/Dockerfile | DOCKER_BUILDKIT=1 docker build --build-arg builder_image=$(GO_CONTAINER_IMAGE) --build-arg goproxy=$(GOPROXY) --build-arg ARCH=$(ARCH) --build-arg ldflags=\"$(LDFLAGS)\" . -t $(CAPIM_CONTROLLER_IMG)-$(ARCH):$(TAG) --file -\n\t$(MAKE) set-manifest-image MANIFEST_IMG=$(CAPIM_CONTROLLER_IMG)-$(ARCH) MANIFEST_TAG=$(TAG) TARGET_RESOURCE=\"$(CAPIM_DIR)/config/default/manager_image_patch.yaml\"\n\t$(MAKE) set-manifest-pull-policy TARGET_RESOURCE=\"$(CAPIM_DIR)/config/default/manager_pull_policy.yaml\"\n\n.PHONY: docker-build-clusterctl\ndocker-build-clusterctl: ## Build the docker image for clusterctl\n## reads Dockerfile from stdin to avoid an incorrectly cached Dockerfile (https://github.com/moby/buildkit/issues/1368)\n\tcat ./cmd/clusterctl/Dockerfile | DOCKER_BUILDKIT=1 docker build --build-arg builder_image=$(GO_CONTAINER_IMAGE) --build-arg goproxy=$(GOPROXY) --build-arg ARCH=$(ARCH) --build-arg package=./cmd/clusterctl --build-arg ldflags=\"$(LDFLAGS)\" . -t $(CLUSTERCTL_IMG)-$(ARCH):$(TAG) --file -\n\n.PHONY: docker-build-test-extension\ndocker-build-test-extension: ## Build the docker image for core controller manager\n## reads Dockerfile from stdin to avoid an incorrectly cached Dockerfile (https://github.com/moby/buildkit/issues/1368)\n\tcat ./test/extension/Dockerfile | DOCKER_BUILDKIT=1 docker build --build-arg builder_image=$(GO_CONTAINER_IMAGE) --build-arg goproxy=$(GOPROXY) --build-arg ARCH=$(ARCH) --build-arg ldflags=\"$(LDFLAGS)\" . -t $(TEST_EXTENSION_IMG)-$(ARCH):$(TAG) --file -\n\t$(MAKE) set-manifest-image MANIFEST_IMG=$(TEST_EXTENSION_IMG)-$(ARCH) MANIFEST_TAG=$(TAG) TARGET_RESOURCE=\"./test/extension/config/default/manager_image_patch.yaml\"\n\t$(MAKE) set-manifest-pull-policy TARGET_RESOURCE=\"./test/extension/config/default/manager_pull_policy.yaml\"\n\n.PHONY: e2e-framework\ne2e-framework: ## Builds the CAPI e2e framework\n\tcd $(E2E_FRAMEWORK_DIR); go build ./...\n\n.PHONY: build-book\nbuild-book: ## Build the book\n\t$(MAKE) -C docs/book build\n\n## --------------------------------------\n## Testing\n## --------------------------------------\n\n##@ test:\n\nARTIFACTS ?= ${ROOT_DIR}/_artifacts\n\nKUBEBUILDER_ASSETS ?= $(shell $(SETUP_ENVTEST) use --use-env -p path $(KUBEBUILDER_ENVTEST_KUBERNETES_VERSION))\n\n.PHONY: setup-envtest\nsetup-envtest: $(SETUP_ENVTEST) ## Set up envtest (download kubebuilder assets)\n\t@echo KUBEBUILDER_ASSETS=$(KUBEBUILDER_ASSETS)\n\n.PHONY: test-no-race\ntest-no-race: $(SETUP_ENVTEST) ## Run unit and integration tests\n\tKUBEBUILDER_ASSETS=\"$(KUBEBUILDER_ASSETS)\" go test ./... $(TEST_ARGS)\n\n.PHONY: test\ntest: $(SETUP_ENVTEST) ## Run unit and integration tests with race detector\n\t# Note: Fuzz tests are not executed with race detector because they would just time out.\n\t# To achieve that, all files with fuzz tests have the \"!race\" build tag, to still run fuzz tests\n\t# we have an additional `go test` run that focuses on \"TestFuzzyConversion\".\n\tKUBEBUILDER_ASSETS=\"$(KUBEBUILDER_ASSETS)\" go test -race ./... $(TEST_ARGS)\n\tKUBEBUILDER_ASSETS=\"$(KUBEBUILDER_ASSETS)\" go test -run \"^TestFuzzyConversion$$\" ./... $(TEST_ARGS)\n\n.PHONY: test-verbose\ntest-verbose: ## Run unit and integration tests with race detector and with verbose flag\n\t$(MAKE) test TEST_ARGS=\"$(TEST_ARGS) -v\"\n\n.PHONY: test-junit\ntest-junit: $(SETUP_ENVTEST) $(GOTESTSUM) ## Run unit and integration tests with race detector and generate a junit report\n\tset +o errexit; (KUBEBUILDER_ASSETS=\"$(KUBEBUILDER_ASSETS)\" go test -race -json ./... $(TEST_ARGS); echo $$? > $(ARTIFACTS)/junit.exitcode) | tee $(ARTIFACTS)/junit.stdout\n\t$(GOTESTSUM) --junitfile $(ARTIFACTS)/junit.xml --raw-command cat $(ARTIFACTS)/junit.stdout\n\texit $$(cat $(ARTIFACTS)/junit.exitcode)\n\tset +o errexit; (KUBEBUILDER_ASSETS=\"$(KUBEBUILDER_ASSETS)\" go test -run \"^TestFuzzyConversion$$\" -json ./... $(TEST_ARGS); echo $$? > $(ARTIFACTS)/junit-fuzz.exitcode) | tee $(ARTIFACTS)/junit-fuzz.stdout\n\t$(GOTESTSUM) --junitfile $(ARTIFACTS)/junit-fuzz.xml --raw-command cat $(ARTIFACTS)/junit-fuzz.stdout\n\texit $$(cat $(ARTIFACTS)/junit-fuzz.exitcode)\n\n.PHONY: test-cover\ntest-cover: ## Run unit and integration tests and generate a coverage report\n\t$(MAKE) test TEST_ARGS=\"$(TEST_ARGS) -coverprofile=out/coverage.out\"\n\tgo tool cover -func=out/coverage.out -o out/coverage.txt\n\tgo tool cover -html=out/coverage.out -o out/coverage.html\n\n.PHONY: test-docker-infrastructure\ntest-docker-infrastructure: $(SETUP_ENVTEST) ## Run unit and integration tests for docker infrastructure provider\n\tcd $(CAPD_DIR); KUBEBUILDER_ASSETS=\"$(KUBEBUILDER_ASSETS)\" go test -race ./... $(TEST_ARGS)\n\n.PHONY: test-docker-infrastructure-verbose\ntest-docker-infrastructure-verbose: ## Run unit and integration tests for docker infrastructure provider with verbose flag\n\t$(MAKE) test-docker-infrastructure TEST_ARGS=\"$(TEST_ARGS) -v\"\n\n.PHONY: test-docker-infrastructure-junit\ntest-docker-infrastructure-junit: $(SETUP_ENVTEST) $(GOTESTSUM) ## Run unit and integration tests and generate a junit report for docker infrastructure provider\n\tcd $(CAPD_DIR); set +o errexit; (KUBEBUILDER_ASSETS=\"$(KUBEBUILDER_ASSETS)\" go test -race -json ./... $(TEST_ARGS); echo $$? > $(ARTIFACTS)/junit.infra_docker.exitcode) | tee $(ARTIFACTS)/junit.infra_docker.stdout\n\t$(GOTESTSUM) --junitfile $(ARTIFACTS)/junit.infra_docker.xml --raw-command cat $(ARTIFACTS)/junit.infra_docker.stdout\n\texit $$(cat $(ARTIFACTS)/junit.infra_docker.exitcode)\n\n.PHONY: test-in-memory-infrastructure\ntest-in-memory-infrastructure: $(SETUP_ENVTEST) ## Run unit and integration tests for in-memory infrastructure provider\n\tcd $(CAPIM_DIR); KUBEBUILDER_ASSETS=\"$(KUBEBUILDER_ASSETS)\" go test -race ./... $(TEST_ARGS)\n\n.PHONY: test-in-memory-infrastructure-verbose\ntest-in-memory-infrastructure-verbose: ## Run unit and integration tests for in-memory infrastructure provider with verbose flag\n\t$(MAKE) test-in-memory-infrastructure TEST_ARGS=\"$(TEST_ARGS) -v\"\n\n.PHONY: test-in-memory-infrastructure-junit\ntest-in-memory-infrastructure-junit: $(SETUP_ENVTEST) $(GOTESTSUM) ## Run unit and integration tests and generate a junit report for in-memory infrastructure provider\n\tcd $(CAPIM_DIR); set +o errexit; (KUBEBUILDER_ASSETS=\"$(KUBEBUILDER_ASSETS)\" go test -race -json ./... $(TEST_ARGS); echo $$? > $(ARTIFACTS)/junit.infra_inmemory.exitcode) | tee $(ARTIFACTS)/junit.infra_inmemory.stdout\n\t$(GOTESTSUM) --junitfile $(ARTIFACTS)/junit.infra_inmemory.xml --raw-command cat $(ARTIFACTS)/junit.infra_inmemory.stdout\n\texit $$(cat $(ARTIFACTS)/junit.infra_inmemory.exitcode)\n\n.PHONY: test-test-extension\ntest-test-extension: $(SETUP_ENVTEST) ## Run unit and integration tests for the test extension\n\tcd $(TEST_EXTENSION_DIR); KUBEBUILDER_ASSETS=\"$(KUBEBUILDER_ASSETS)\" go test -race ./... $(TEST_ARGS)\n\n.PHONY: test-test-extension-verbose\ntest-test-extension-verbose: ## Run unit and integration tests with verbose flag\n\t$(MAKE) test-test-extension TEST_ARGS=\"$(TEST_ARGS) -v\"\n\n.PHONY: test-test-extension-junit\ntest-test-extension-junit: $(SETUP_ENVTEST) $(GOTESTSUM) ## Run unit and integration tests and generate a junit report for the test extension\n\tcd $(TEST_EXTENSION_DIR); set +o errexit; (KUBEBUILDER_ASSETS=\"$(KUBEBUILDER_ASSETS)\" go test -race -json ./... $(TEST_ARGS); echo $$? > $(ARTIFACTS)/junit.test_extension.exitcode) | tee $(ARTIFACTS)/junit.test_extension.stdout\n\t$(GOTESTSUM) --junitfile $(ARTIFACTS)/junit.test_extension.xml --raw-command cat $(ARTIFACTS)/junit.test_extension.stdout\n\texit $$(cat $(ARTIFACTS)/junit.test_extension.exitcode)\n\n.PHONY: test-e2e\ntest-e2e: $(GINKGO) generate-e2e-templates ## Run the end-to-end tests\n\t$(GINKGO) -v --trace -poll-progress-after=$(GINKGO_POLL_PROGRESS_AFTER) \\\n\t\t-poll-progress-interval=$(GINKGO_POLL_PROGRESS_INTERVAL) --tags=e2e --focus=\"$(GINKGO_FOCUS)\" \\\n\t\t$(_SKIP_ARGS) --nodes=$(GINKGO_NODES) --timeout=$(GINKGO_TIMEOUT) --no-color=$(GINKGO_NOCOLOR) \\\n\t\t--output-dir=\"$(ARTIFACTS)\" --junit-report=\"junit.e2e_suite.1.xml\" $(GINKGO_ARGS) $(ROOT_DIR)/$(TEST_DIR)/e2e -- \\\n\t    -e2e.artifacts-folder=\"$(ARTIFACTS)\" \\\n\t    -e2e.config=\"$(E2E_CONF_FILE)\" \\\n\t    -e2e.skip-resource-cleanup=$(SKIP_RESOURCE_CLEANUP) -e2e.use-existing-cluster=$(USE_EXISTING_CLUSTER)\n\n\n.PHONY: kind-cluster\nkind-cluster: ## Create a new kind cluster designed for development with Tilt\n\thack/kind-install-for-capd.sh\n\n.PHONY: tilt-e2e-prerequisites\ntilt-e2e-prerequisites: ## Build the corresponding kindest/node images required for e2e testing and generate the e2e templates\n\tscripts/build-kind.sh\n\t$(MAKE) generate-e2e-templates\n\n.PHONY: tilt-up\ntilt-up: kind-cluster ## Start tilt and build kind cluster if needed.\n\ttilt up\n\n.PHONY: serve-book\nserve-book: ## Build and serve the book (with live-reload)\n\t$(MAKE) -C docs/book serve\n\n## --------------------------------------\n## Release\n## --------------------------------------\n\n##@ release:\n\n## latest git tag for the commit, e.g., v0.3.10\nRELEASE_TAG ?= $(shell git describe --abbrev=0 2>/dev/null)\n## set by Prow, ref name of the base branch, e.g., main\nRELEASE_ALIAS_TAG := $(PULL_BASE_REF)\nRELEASE_DIR := out\nRELEASE_NOTES_DIR := CHANGELOG\nUSER_FORK ?= $(shell git config --get remote.origin.url | cut -d/ -f4) # only works on https://github.com/<username>/cluster-api.git style URLs\nifeq ($(USER_FORK),)\nUSER_FORK := $(shell git config --get remote.origin.url | cut -d: -f2 | cut -d/ -f1) # for git@github.com:<username>/cluster-api.git style URLs\nendif\nIMAGE_REVIEWERS ?= $(shell ./hack/get-project-maintainers.sh)\n\n.PHONY: $(RELEASE_DIR)\n$(RELEASE_DIR):\n\tmkdir -p $(RELEASE_DIR)/\n\n.PHONY: $(RELEASE_NOTES_DIR)\n$(RELEASE_NOTES_DIR):\n\tmkdir -p $(RELEASE_NOTES_DIR)/\n\n.PHONY: release\nrelease: clean-release ## Build and push container images using the latest git tag for the commit\n\t@if [ -z \"${RELEASE_TAG}\" ]; then echo \"RELEASE_TAG is not set\"; exit 1; fi\n\t@if ! [ -z \"$$(git status --porcelain)\" ]; then echo \"Your local git repository contains uncommitted changes, use git clean before proceeding.\"; exit 1; fi\n\tgit checkout \"${RELEASE_TAG}\"\n\t# Build binaries first.\n\tGIT_VERSION=$(RELEASE_TAG) $(MAKE) release-binaries\n\t# Set the manifest images to the staging/production bucket and Builds the manifests to publish with a release.\n\t$(MAKE) release-manifests-all\n\n.PHONY: release-manifests-all\nrelease-manifests-all: # Set the manifest images to the staging/production bucket and Builds the manifests to publish with a release.\n\t# Set the manifest image to the production bucket.\n\t$(MAKE) manifest-modification REGISTRY=$(PROD_REGISTRY)\n\t## Build the manifests\n\t$(MAKE) release-manifests\n\t# Set the development manifest image to the staging bucket.\n\t$(MAKE) manifest-modification-dev REGISTRY=$(STAGING_REGISTRY)\n\t## Build the development manifests\n\t$(MAKE) release-manifests-dev\n\t## Clean the git artifacts modified in the release process\n\t$(MAKE) clean-release-git\n\n.PHONY: manifest-modification\nmanifest-modification: # Set the manifest images to the staging/production bucket.\n\t$(MAKE) set-manifest-image \\\n\t\tMANIFEST_IMG=$(REGISTRY)/$(IMAGE_NAME) MANIFEST_TAG=$(RELEASE_TAG) \\\n\t\tTARGET_RESOURCE=\"./config/default/manager_image_patch.yaml\"\n\t$(MAKE) set-manifest-image \\\n\t\tMANIFEST_IMG=$(REGISTRY)/$(KUBEADM_BOOTSTRAP_IMAGE_NAME) MANIFEST_TAG=$(RELEASE_TAG) \\\n\t\tTARGET_RESOURCE=\"./bootstrap/kubeadm/config/default/manager_image_patch.yaml\"\n\t$(MAKE) set-manifest-image \\\n\t\tMANIFEST_IMG=$(REGISTRY)/$(KUBEADM_CONTROL_PLANE_IMAGE_NAME) MANIFEST_TAG=$(RELEASE_TAG) \\\n\t\tTARGET_RESOURCE=\"./controlplane/kubeadm/config/default/manager_image_patch.yaml\"\n\t$(MAKE) set-manifest-pull-policy PULL_POLICY=IfNotPresent TARGET_RESOURCE=\"./config/default/manager_pull_policy.yaml\"\n\t$(MAKE) set-manifest-pull-policy PULL_POLICY=IfNotPresent TARGET_RESOURCE=\"./bootstrap/kubeadm/config/default/manager_pull_policy.yaml\"\n\t$(MAKE) set-manifest-pull-policy PULL_POLICY=IfNotPresent TARGET_RESOURCE=\"./controlplane/kubeadm/config/default/manager_pull_policy.yaml\"\n\n.PHONY: manifest-modification-dev\nmanifest-modification-dev: # Set the manifest images to the staging bucket.\n\t$(MAKE) set-manifest-image \\\n\t\tMANIFEST_IMG=$(REGISTRY)/$(CAPD_IMAGE_NAME) MANIFEST_TAG=$(RELEASE_TAG) \\\n\t\tTARGET_RESOURCE=\"$(CAPD_DIR)/config/default/manager_image_patch.yaml\"\n\t$(MAKE) set-manifest-pull-policy PULL_POLICY=IfNotPresent TARGET_RESOURCE=\"$(CAPD_DIR)/config/default/manager_pull_policy.yaml\"\n\t$(MAKE) set-manifest-image \\\n\t\tMANIFEST_IMG=$(REGISTRY)/$(CAPIM_IMAGE_NAME) MANIFEST_TAG=$(RELEASE_TAG) \\\n\t\tTARGET_RESOURCE=\"$(CAPIM_DIR)/config/default/manager_image_patch.yaml\"\n\t$(MAKE) set-manifest-pull-policy PULL_POLICY=IfNotPresent TARGET_RESOURCE=\"$(CAPIM_DIR)/config/default/manager_pull_policy.yaml\"\n\t$(MAKE) set-manifest-image \\\n\t\tMANIFEST_IMG=$(REGISTRY)/$(TEST_EXTENSION_IMAGE_NAME) MANIFEST_TAG=$(RELEASE_TAG) \\\n\t\tTARGET_RESOURCE=\"$(TEST_EXTENSION_DIR)/config/default/manager_image_patch.yaml\"\n\t$(MAKE) set-manifest-pull-policy PULL_POLICY=IfNotPresent TARGET_RESOURCE=\"$(CAPD_DIR)/config/default/manager_pull_policy.yaml\"\n\n\n.PHONY: release-manifests\nrelease-manifests: $(RELEASE_DIR) $(KUSTOMIZE) $(RUNTIME_OPENAPI_GEN) ## Build the manifests to publish with a release\n\t# Build core-components.\n\t$(KUSTOMIZE) build config/default > $(RELEASE_DIR)/core-components.yaml\n\t# Build bootstrap-components.\n\t$(KUSTOMIZE) build bootstrap/kubeadm/config/default > $(RELEASE_DIR)/bootstrap-components.yaml\n\t# Build control-plane-components.\n\t$(KUSTOMIZE) build controlplane/kubeadm/config/default > $(RELEASE_DIR)/control-plane-components.yaml\n\n\t## Build cluster-api-components (aggregate of all of the above).\n\tcat $(RELEASE_DIR)/core-components.yaml > $(RELEASE_DIR)/cluster-api-components.yaml\n\techo \"---\" >> $(RELEASE_DIR)/cluster-api-components.yaml\n\tcat $(RELEASE_DIR)/bootstrap-components.yaml >> $(RELEASE_DIR)/cluster-api-components.yaml\n\techo \"---\" >> $(RELEASE_DIR)/cluster-api-components.yaml\n\tcat $(RELEASE_DIR)/control-plane-components.yaml >> $(RELEASE_DIR)/cluster-api-components.yaml\n\t# Add metadata to the release artifacts\n\tcp metadata.yaml $(RELEASE_DIR)/metadata.yaml\n\n\t# Generate OpenAPI specification.\n\t$(RUNTIME_OPENAPI_GEN) --version $(RELEASE_TAG) --output-file $(RELEASE_DIR)/runtime-sdk-openapi.yaml\n\n.PHONY: release-manifests-dev\nrelease-manifests-dev: $(RELEASE_DIR) $(KUSTOMIZE) ## Build the development manifests and copies them in the release folder\n\tcd $(CAPD_DIR); $(KUSTOMIZE) build config/default > ../../../$(RELEASE_DIR)/infrastructure-components-development.yaml\n\tcp $(CAPD_DIR)/templates/* $(RELEASE_DIR)/\n\tcd $(CAPIM_DIR); $(KUSTOMIZE) build config/default > ../../../$(RELEASE_DIR)/infrastructure-components-in-memory-development.yaml\n\tcp $(CAPIM_DIR)/templates/* $(RELEASE_DIR)/\n\tcd $(TEST_EXTENSION_DIR); $(KUSTOMIZE) build config/default > ../../$(RELEASE_DIR)/runtime-extension-components-development.yaml\n\n.PHONY: release-binaries\nrelease-binaries: ## Build the binaries to publish with a release\n\tRELEASE_BINARY=clusterctl-linux-amd64 BUILD_PATH=./cmd/clusterctl GOOS=linux GOARCH=amd64 $(MAKE) release-binary\n\tRELEASE_BINARY=clusterctl-linux-arm64 BUILD_PATH=./cmd/clusterctl GOOS=linux GOARCH=arm64 $(MAKE) release-binary\n\tRELEASE_BINARY=clusterctl-darwin-amd64 BUILD_PATH=./cmd/clusterctl GOOS=darwin GOARCH=amd64 $(MAKE) release-binary\n\tRELEASE_BINARY=clusterctl-darwin-arm64 BUILD_PATH=./cmd/clusterctl GOOS=darwin GOARCH=arm64 $(MAKE) release-binary\n\tRELEASE_BINARY=clusterctl-windows-amd64.exe BUILD_PATH=./cmd/clusterctl GOOS=windows GOARCH=amd64 $(MAKE) release-binary\n\tRELEASE_BINARY=clusterctl-linux-ppc64le BUILD_PATH=./cmd/clusterctl GOOS=linux GOARCH=ppc64le $(MAKE) release-binary\n\n.PHONY: release-binary\nrelease-binary: $(RELEASE_DIR)\n\tdocker run \\\n\t\t--rm \\\n\t\t-e CGO_ENABLED=0 \\\n\t\t-e GOOS=$(GOOS) \\\n\t\t-e GOARCH=$(GOARCH) \\\n\t\t-e GOCACHE=/tmp/ \\\n\t\t--user $$(id -u):$$(id -g) \\\n\t\t-v \"$$(pwd):/workspace$(DOCKER_VOL_OPTS)\" \\\n\t\t-w /workspace \\\n\t\tgolang:$(GO_VERSION) \\\n\t\tgo build -a -trimpath -ldflags \"$(LDFLAGS) -extldflags '-static'\" \\\n\t\t-o $(RELEASE_DIR)/$(notdir $(RELEASE_BINARY)) $(BUILD_PATH)\n\n.PHONY: release-staging\nrelease-staging: ## Build and push container images to the staging bucket\n\tREGISTRY=$(STAGING_REGISTRY) $(MAKE) docker-build-all\n\tREGISTRY=$(STAGING_REGISTRY) $(MAKE) docker-image-verify\n\tREGISTRY=$(STAGING_REGISTRY) $(MAKE) docker-push-all\n\tREGISTRY=$(STAGING_REGISTRY) $(MAKE) release-alias-tag\n\t# Set the manifest image to the staging bucket.\n\t$(MAKE) manifest-modification REGISTRY=$(STAGING_REGISTRY) RELEASE_TAG=$(RELEASE_ALIAS_TAG)\n\t## Build the manifests\n\t$(MAKE) release-manifests\n\t# Set the manifest image to the staging bucket.\n\t$(MAKE) manifest-modification-dev REGISTRY=$(STAGING_REGISTRY) RELEASE_TAG=$(RELEASE_ALIAS_TAG)\n\t## Build the dev manifests\n\t$(MAKE) release-manifests-dev\n\t# Example manifest location: https://storage.googleapis.com/k8s-staging-cluster-api/components/main/core-components.yaml\n\t# Please note that these files are deleted after a certain period, at the time of this writing 60 days after file creation.\n\tgsutil cp $(RELEASE_DIR)/* gs://$(STAGING_BUCKET)/components/$(RELEASE_ALIAS_TAG)\n\n.PHONY: release-staging-nightly\nrelease-staging-nightly: ## Tag and push container images to the staging bucket. Example image tag: cluster-api-controller:nightly_main_20210121\n\t$(eval NEW_RELEASE_ALIAS_TAG := nightly_$(RELEASE_ALIAS_TAG)_$(shell date +'%Y%m%d'))\n\techo $(NEW_RELEASE_ALIAS_TAG)\n\t$(MAKE) release-alias-tag TAG=$(RELEASE_ALIAS_TAG) RELEASE_ALIAS_TAG=$(NEW_RELEASE_ALIAS_TAG)\n\t# Set the manifest image to the staging bucket.\n\t$(MAKE) manifest-modification REGISTRY=$(STAGING_REGISTRY) RELEASE_TAG=$(NEW_RELEASE_ALIAS_TAG)\n\t## Build the manifests\n\t$(MAKE) release-manifests\n\t# Set the manifest image to the staging bucket.\n\t$(MAKE) manifest-modification-dev REGISTRY=$(STAGING_REGISTRY) RELEASE_TAG=$(NEW_RELEASE_ALIAS_TAG)\n\t## Build the dev manifests\n\t$(MAKE) release-manifests-dev\n\t# Example manifest location: https://storage.googleapis.com/k8s-staging-cluster-api/components/nightly_main_20240425/core-components.yaml\n\t# Please note that these files are deleted after a certain period, at the time of this writing 60 days after file creation.\n\tgsutil cp $(RELEASE_DIR)/* gs://$(STAGING_BUCKET)/components/$(NEW_RELEASE_ALIAS_TAG)\n\n.PHONY: release-alias-tag\nrelease-alias-tag: ## Add the release alias tag to the last build tag\n\tgcloud container images add-tag $(CONTROLLER_IMG):$(TAG) $(CONTROLLER_IMG):$(RELEASE_ALIAS_TAG)\n\tgcloud container images add-tag $(KUBEADM_BOOTSTRAP_CONTROLLER_IMG):$(TAG) $(KUBEADM_BOOTSTRAP_CONTROLLER_IMG):$(RELEASE_ALIAS_TAG)\n\tgcloud container images add-tag $(KUBEADM_CONTROL_PLANE_CONTROLLER_IMG):$(TAG) $(KUBEADM_CONTROL_PLANE_CONTROLLER_IMG):$(RELEASE_ALIAS_TAG)\n\tgcloud container images add-tag $(CLUSTERCTL_IMG):$(TAG) $(CLUSTERCTL_IMG):$(RELEASE_ALIAS_TAG)\n\tgcloud container images add-tag $(CAPD_CONTROLLER_IMG):$(TAG) $(CAPD_CONTROLLER_IMG):$(RELEASE_ALIAS_TAG)\n\tgcloud container images add-tag $(CAPIM_CONTROLLER_IMG):$(TAG) $(CAPIM_CONTROLLER_IMG):$(RELEASE_ALIAS_TAG)\n\tgcloud container images add-tag $(TEST_EXTENSION_IMG):$(TAG) $(TEST_EXTENSION_IMG):$(RELEASE_ALIAS_TAG)\n\n.PHONY: release-notes-tool\nrelease-notes-tool:\n\tgo build -C hack/tools -o $(ROOT_DIR)/bin/notes -tags tools sigs.k8s.io/cluster-api/hack/tools/release/notes\n\n.PHONY: release-notes\nrelease-notes: release-notes-tool\n\t./bin/notes --release $(RELEASE_TAG) --previous-release-version \"$(PREVIOUS_RELEASE_TAG)\" > CHANGELOG/$(RELEASE_TAG).md\n\n.PHONY: test-release-notes-tool\ntest-release-notes-tool:\n\tgo test -race -C hack/tools -v -tags tools,integration sigs.k8s.io/cluster-api/hack/tools/release/notes\n\n.PHONY: release-provider-issues-tool\nrelease-provider-issues-tool: # Creates GitHub issues in a pre-defined list of CAPI provider repositories\n\t@go run ./hack/tools/release/internal/update_providers/provider_issues.go\n\n.PHONY: release-weekly-update-tool\nrelease-weekly-update-tool:\n\tgo build -C hack/tools -o $(ROOT_DIR)/bin/weekly -tags tools sigs.k8s.io/cluster-api/hack/tools/release/weekly\n\n.PHONY: promote-images\npromote-images: $(KPROMO)\n\t$(KPROMO) pr --project cluster-api --tag $(RELEASE_TAG) --reviewers \"$(IMAGE_REVIEWERS)\" --fork $(USER_FORK) --image cluster-api-controller --image kubeadm-control-plane-controller --image kubeadm-bootstrap-controller --image clusterctl\n\n## --------------------------------------\n## Docker\n## --------------------------------------\n\n.PHONY: docker-image-verify\ndocker-image-verify: ## Verifies all built images to contain the correct binary in the expected arch\n\tALL_ARCH=\"$(ALL_ARCH)\" TAG=\"$(TAG)\" ./hack/docker-image-verify.sh\n\n.PHONY: docker-push-all\ndocker-push-all: $(addprefix docker-push-,$(ALL_ARCH))  ## Push the docker images to be included in the release for all architectures + related multiarch manifests\n\t$(MAKE) ALL_ARCH=\"$(ALL_ARCH)\" $(addprefix docker-push-manifest-,$(ALL_DOCKER_BUILD))\n\ndocker-push-%:\n\t$(MAKE) ARCH=$* docker-push\n\n.PHONY: docker-push\ndocker-push: $(addprefix docker-push-,$(ALL_DOCKER_BUILD)) ## Push the docker images to be included in the release\n\n.PHONY: docker-push-core\ndocker-push-core: ## Push the core docker image\n\tdocker push $(CONTROLLER_IMG)-$(ARCH):$(TAG)\n\n.PHONY: docker-push-manifest-core\ndocker-push-manifest-core: ## Push the multiarch manifest for the core docker images\n\tdocker manifest create --amend $(CONTROLLER_IMG):$(TAG) $(shell echo $(ALL_ARCH) | sed -e \"s~[^ ]*~$(CONTROLLER_IMG)\\-&:$(TAG)~g\")\n\t@for arch in $(ALL_ARCH); do docker manifest annotate --arch $${arch} ${CONTROLLER_IMG}:${TAG} ${CONTROLLER_IMG}-$${arch}:${TAG}; done\n\tdocker manifest push --purge $(CONTROLLER_IMG):$(TAG)\n\t$(MAKE) set-manifest-image MANIFEST_IMG=$(CONTROLLER_IMG) MANIFEST_TAG=$(TAG) TARGET_RESOURCE=\"./config/default/manager_image_patch.yaml\"\n\t$(MAKE) set-manifest-pull-policy TARGET_RESOURCE=\"./config/default/manager_pull_policy.yaml\"\n\n.PHONY: docker-push-kubeadm-bootstrap\ndocker-push-kubeadm-bootstrap: ## Push the kubeadm bootstrap docker image\n\tdocker push $(KUBEADM_BOOTSTRAP_CONTROLLER_IMG)-$(ARCH):$(TAG)\n\n.PHONY: docker-push-manifest-kubeadm-bootstrap\ndocker-push-manifest-kubeadm-bootstrap: ## Push the multiarch manifest for the kubeadm bootstrap docker images\n\tdocker manifest create --amend $(KUBEADM_BOOTSTRAP_CONTROLLER_IMG):$(TAG) $(shell echo $(ALL_ARCH) | sed -e \"s~[^ ]*~$(KUBEADM_BOOTSTRAP_CONTROLLER_IMG)\\-&:$(TAG)~g\")\n\t@for arch in $(ALL_ARCH); do docker manifest annotate --arch $${arch} ${KUBEADM_BOOTSTRAP_CONTROLLER_IMG}:${TAG} ${KUBEADM_BOOTSTRAP_CONTROLLER_IMG}-$${arch}:${TAG}; done\n\tdocker manifest push --purge $(KUBEADM_BOOTSTRAP_CONTROLLER_IMG):$(TAG)\n\t$(MAKE) set-manifest-image MANIFEST_IMG=$(KUBEADM_BOOTSTRAP_CONTROLLER_IMG) MANIFEST_TAG=$(TAG) TARGET_RESOURCE=\"./bootstrap/kubeadm/config/default/manager_image_patch.yaml\"\n\t$(MAKE) set-manifest-pull-policy TARGET_RESOURCE=\"./bootstrap/kubeadm/config/default/manager_pull_policy.yaml\"\n\n.PHONY: docker-push-kubeadm-control-plane\ndocker-push-kubeadm-control-plane: ## Push the kubeadm control plane docker image\n\tdocker push $(KUBEADM_CONTROL_PLANE_CONTROLLER_IMG)-$(ARCH):$(TAG)\n\n.PHONY: docker-push-manifest-kubeadm-control-plane\ndocker-push-manifest-kubeadm-control-plane: ## Push the multiarch manifest for the kubeadm control plane docker images\n\tdocker manifest create --amend $(KUBEADM_CONTROL_PLANE_CONTROLLER_IMG):$(TAG) $(shell echo $(ALL_ARCH) | sed -e \"s~[^ ]*~$(KUBEADM_CONTROL_PLANE_CONTROLLER_IMG)\\-&:$(TAG)~g\")\n\t@for arch in $(ALL_ARCH); do docker manifest annotate --arch $${arch} ${KUBEADM_CONTROL_PLANE_CONTROLLER_IMG}:${TAG} ${KUBEADM_CONTROL_PLANE_CONTROLLER_IMG}-$${arch}:${TAG}; done\n\tdocker manifest push --purge $(KUBEADM_CONTROL_PLANE_CONTROLLER_IMG):$(TAG)\n\t$(MAKE) set-manifest-image MANIFEST_IMG=$(KUBEADM_CONTROL_PLANE_CONTROLLER_IMG) MANIFEST_TAG=$(TAG) TARGET_RESOURCE=\"./controlplane/kubeadm/config/default/manager_image_patch.yaml\"\n\t$(MAKE) set-manifest-pull-policy TARGET_RESOURCE=\"./controlplane/kubeadm/config/default/manager_pull_policy.yaml\"\n\n.PHONY: docker-push-docker-infrastructure\ndocker-push-docker-infrastructure: ## Push the docker infrastructure provider image\n\tdocker push $(CAPD_CONTROLLER_IMG)-$(ARCH):$(TAG)\n\n.PHONY: docker-push-manifest-docker-infrastructure\ndocker-push-manifest-docker-infrastructure: ## Push the multiarch manifest for the docker infrastructure provider images\n\tdocker manifest create --amend $(CAPD_CONTROLLER_IMG):$(TAG) $(shell echo $(ALL_ARCH) | sed -e \"s~[^ ]*~$(CAPD_CONTROLLER_IMG)\\-&:$(TAG)~g\")\n\t@for arch in $(ALL_ARCH); do docker manifest annotate --arch $${arch} ${CAPD_CONTROLLER_IMG}:${TAG} ${CAPD_CONTROLLER_IMG}-$${arch}:${TAG}; done\n\tdocker manifest push --purge $(CAPD_CONTROLLER_IMG):$(TAG)\n\t$(MAKE) set-manifest-image MANIFEST_IMG=$(CAPD_CONTROLLER_IMG) MANIFEST_TAG=$(TAG) TARGET_RESOURCE=\"$(CAPD_DIR)/config/default/manager_image_patch.yaml\"\n\t$(MAKE) set-manifest-pull-policy TARGET_RESOURCE=\"$(CAPD_DIR)/config/default/manager_pull_policy.yaml\"\n\n.PHONY: docker-push-in-memory-infrastructure\ndocker-push-in-memory-infrastructure: ## Push the in-memory infrastructure provider image\n\tdocker push $(CAPIM_CONTROLLER_IMG)-$(ARCH):$(TAG)\n\n.PHONY: docker-push-manifest-in-memory-infrastructure\ndocker-push-manifest-in-memory-infrastructure: ## Push the multiarch manifest for the in-memory infrastructure provider images\n\tdocker manifest create --amend $(CAPIM_CONTROLLER_IMG):$(TAG) $(shell echo $(ALL_ARCH) | sed -e \"s~[^ ]*~$(CAPIM_CONTROLLER_IMG)\\-&:$(TAG)~g\")\n\t@for arch in $(ALL_ARCH); do docker manifest annotate --arch $${arch} ${CAPIM_CONTROLLER_IMG}:${TAG} ${CAPIM_CONTROLLER_IMG}-$${arch}:${TAG}; done\n\tdocker manifest push --purge $(CAPIM_CONTROLLER_IMG):$(TAG)\n\t$(MAKE) set-manifest-image MANIFEST_IMG=$(CAPIM_CONTROLLER_IMG) MANIFEST_TAG=$(TAG) TARGET_RESOURCE=\"$(CAPIM_DIR)/config/default/manager_image_patch.yaml\"\n\t$(MAKE) set-manifest-pull-policy TARGET_RESOURCE=\"$(CAPIM_DIR)/config/default/manager_pull_policy.yaml\"\n\n.PHONY: docker-push-test-extension\ndocker-push-test-extension: ## Push the test extension provider image\n\tdocker push $(TEST_EXTENSION_IMG)-$(ARCH):$(TAG)\n\n.PHONY: docker-push-manifest-test-extension\ndocker-push-manifest-test-extension: ## Push the multiarch manifest for the test extension provider images\n\tdocker manifest create --amend $(TEST_EXTENSION_IMG):$(TAG) $(shell echo $(ALL_ARCH) | sed -e \"s~[^ ]*~$(TEST_EXTENSION_IMG)\\-&:$(TAG)~g\")\n\t@for arch in $(ALL_ARCH); do docker manifest annotate --arch $${arch} ${TEST_EXTENSION_IMG}:${TAG} ${TEST_EXTENSION_IMG}-$${arch}:${TAG}; done\n\tdocker manifest push --purge $(TEST_EXTENSION_IMG):$(TAG)\n\t$(MAKE) set-manifest-image MANIFEST_IMG=$(TEST_EXTENSION_IMG) MANIFEST_TAG=$(TAG) TARGET_RESOURCE=\"./test/extension/config/default/manager_image_patch.yaml\"\n\t$(MAKE) set-manifest-pull-policy TARGET_RESOURCE=\"./test/extension/config/default/manager_pull_policy.yaml\"\n\n.PHONY: docker-push-clusterctl\ndocker-push-clusterctl: ## Push the clusterctl image\n\tdocker push $(CLUSTERCTL_IMG)-$(ARCH):$(TAG)\n\n.PHONY: docker-push-manifest-clusterctl\ndocker-push-manifest-clusterctl: ## Push the multiarch manifest for the clusterctl images\n\tdocker manifest create --amend $(CLUSTERCTL_IMG):$(TAG) $(shell echo $(ALL_ARCH) | sed -e \"s~[^ ]*~$(CLUSTERCTL_IMG)\\-&:$(TAG)~g\")\n\t@for arch in $(ALL_ARCH); do docker manifest annotate --arch $${arch} ${CLUSTERCTL_IMG}:${TAG} ${CLUSTERCTL_IMG}-$${arch}:${TAG}; done\n\tdocker manifest push --purge $(CLUSTERCTL_IMG):$(TAG)\n\n.PHONY: set-manifest-pull-policy\nset-manifest-pull-policy:\n\t$(info Updating kustomize pull policy file for manager resources)\n\tsed -i'' -e 's@imagePullPolicy: .*@imagePullPolicy: '\"$(PULL_POLICY)\"'@' $(TARGET_RESOURCE)\n\n.PHONY: set-manifest-image\nset-manifest-image:\n\t$(info Updating kustomize image patch file for manager resource)\n\tsed -i'' -e 's@image: .*@image: '\"${MANIFEST_IMG}:$(MANIFEST_TAG)\"'@' $(TARGET_RESOURCE)\n\n## --------------------------------------\n## Cleanup / Verification\n## --------------------------------------\n\n##@ clean:\n\n.PHONY: clean\nclean: ## Remove generated binaries, GitBook files, Helm charts, and Tilt build files\n\t$(MAKE) clean-bin\n\t$(MAKE) clean-book\n\t$(MAKE) clean-charts\n\t$(MAKE) clean-tilt\n\n.PHONY: clean-kind\nclean-kind: ## Cleans up the kind cluster with the name $CAPI_KIND_CLUSTER_NAME\n\tkind delete cluster --name=\"$(CAPI_KIND_CLUSTER_NAME)\" || true\n\n.PHONY: clean-bin\nclean-bin: ## Remove all generated binaries\n\trm -rf $(BIN_DIR)\n\trm -rf $(TOOLS_BIN_DIR)\n\n.PHONY: clean-tilt\nclean-tilt: clean-charts clean-kind ## Remove all files generated by Tilt\n\trm -rf ./.tiltbuild\n\trm -rf ./controlplane/kubeadm/.tiltbuild\n\trm -rf ./bootstrap/kubeadm/.tiltbuild\n\trm -rf ./test/infrastructure/docker/.tiltbuild\n\trm -rf ./test/infrastructure/inmemory/.tiltbuild\n\n.PHONY: clean-charts\nclean-charts: ## Remove all local copies of Helm charts in ./hack/observability\n\t(for path in \"./hack/observability/*\"; do rm -rf $$path/.charts ; done)\n\n.PHONY: clean-book\nclean-book: ## Remove all generated GitBook files\n\trm -rf ./docs/book/_book\n\n.PHONY: clean-release\nclean-release: ## Remove the release folder\n\trm -rf $(RELEASE_DIR)\n\n.PHONY: clean-manifests ## Reset manifests in config directories back to main\nclean-manifests:\n\t@read -p \"WARNING: This will reset all config directories to local main. Press [ENTER] to continue.\"\n\tgit checkout main config bootstrap/kubeadm/config controlplane/kubeadm/config $(CAPD_DIR)/config\n\n.PHONY: clean-release-git\nclean-release-git: ## Restores the git files usually modified during a release\n\tgit restore ./*manager_image_patch.yaml ./*manager_pull_policy.yaml\n\n.PHONY: clean-generated-yaml\nclean-generated-yaml: ## Remove files generated by conversion-gen from the mentioned dirs. Example SRC_DIRS=\"./api/v1alpha4\"\n\t(IFS=','; for i in $(SRC_DIRS); do find $$i -type f -name '*.yaml' -exec rm -f {} \\;; done)\n\n.PHONY: clean-generated-deepcopy\nclean-generated-deepcopy: ## Remove files generated by conversion-gen from the mentioned dirs. Example SRC_DIRS=\"./api/v1alpha4\"\n\t(IFS=','; for i in $(SRC_DIRS); do find $$i -type f -name 'zz_generated.deepcopy*' -exec rm -f {} \\;; done)\n\n.PHONY: clean-generated-conversions\nclean-generated-conversions: ## Remove files generated by conversion-gen from the mentioned dirs. Example SRC_DIRS=\"./api/v1alpha4\"\n\t(IFS=','; for i in $(SRC_DIRS); do find $$i -type f -name 'zz_generated.conversion*' -exec rm -f {} \\;; done)\n\n.PHONY: clean-generated-openapi-definitions\nclean-generated-openapi-definitions: ## Remove files generated by openapi-gen from the mentioned dirs. Example SRC_DIRS=\"./api/v1alpha4\"\n\t(IFS=','; for i in $(SRC_DIRS); do find $$i -type f -name 'zz_generated.openapi*' -exec rm -f {} \\;; done)\n\n## --------------------------------------\n## Hack / Tools\n## --------------------------------------\n\n##@ hack/tools:\n\n.PHONY: $(CONTROLLER_GEN_BIN)\n$(CONTROLLER_GEN_BIN): $(CONTROLLER_GEN) ## Build a local copy of controller-gen.\n\n.PHONY: $(CONVERSION_GEN_BIN)\n$(CONVERSION_GEN_BIN): $(CONVERSION_GEN) ## Build a local copy of conversion-gen.\n\n.PHONY: $(OPENAPI_GEN_BIN)\n$(OPENAPI_GEN_BIN): $(OPENAPI_GEN) ## Build a local copy of openapi-gen.\n\n.PHONY: $(RUNTIME_OPENAPI_GEN_BIN)\n$(RUNTIME_OPENAPI_GEN_BIN): $(RUNTIME_OPENAPI_GEN) ## Build a local copy of runtime-openapi-gen.\n\n.PHONY: $(PROWJOB_GEN_BIN)\n$(PROWJOB_GEN_BIN): $(PROWJOB_GEN) ## Build a local copy of prowjob-gen.\n\n.PHONY: $(CONVERSION_VERIFIER_BIN)\n$(CONVERSION_VERIFIER_BIN): $(CONVERSION_VERIFIER) ## Build a local copy of conversion-verifier.\n\n.PHONY: $(GOTESTSUM_BIN)\n$(GOTESTSUM_BIN): $(GOTESTSUM) ## Build a local copy of gotestsum.\n\n.PHONY: $(GO_APIDIFF_BIN)\n$(GO_APIDIFF_BIN): $(GO_APIDIFF) ## Build a local copy of go-apidiff\n\n.PHONY: $(ENVSUBST_BIN)\n$(ENVSUBST_BIN): $(ENVSUBST) ## Build a local copy of envsubst.\n\n.PHONY: $(KUSTOMIZE_BIN)\n$(KUSTOMIZE_BIN): $(KUSTOMIZE) ## Build a local copy of kustomize.\n\n.PHONY: $(SETUP_ENVTEST_BIN)\n$(SETUP_ENVTEST_BIN): $(SETUP_ENVTEST) ## Build a local copy of setup-envtest.\n\n.PHONY: $(KPROMO_BIN)\n$(KPROMO_BIN): $(KPROMO) ## Build a local copy of kpromo\n\n.PHONY: $(YQ_BIN)\n$(YQ_BIN): $(YQ) ## Build a local copy of yq\n\n.PHONY: $(TILT_PREPARE_BIN)\n$(TILT_PREPARE_BIN): $(TILT_PREPARE) ## Build a local copy of tilt-prepare.\n\n.PHONY: $(GINKGO_BIN)\n$(GINKGO_BIN): $(GINKGO) ## Build a local copy of ginkgo.\n\n.PHONY: $(GOLANGCI_LINT_BIN)\n$(GOLANGCI_LINT_BIN): $(GOLANGCI_LINT) ## Build a local copy of golangci-lint.\n\n.PHONY: $(GOVULNCHECK_BIN)\n$(GOVULNCHECK_BIN): $(GOVULNCHECK) ## Build a local copy of govulncheck.\n\n.PHONY: $(IMPORT_BOSS_BIN)\n$(IMPORT_BOSS_BIN): $(IMPORT_BOSS)\n\n$(CONTROLLER_GEN): # Build controller-gen from tools folder.\n\tGOBIN=$(TOOLS_BIN_DIR) $(GO_INSTALL) $(CONTROLLER_GEN_PKG) $(CONTROLLER_GEN_BIN) $(CONTROLLER_GEN_VER)\n\n## We are forcing a rebuilt of conversion-gen via PHONY so that we're always using an up-to-date version.\n## We can't use a versioned name for the binary, because that would be reflected in generated files.\n.PHONY: $(CONVERSION_GEN)\n$(CONVERSION_GEN): # Build conversion-gen from tools folder.\n\tGOBIN=$(TOOLS_BIN_DIR) $(GO_INSTALL) $(CONVERSION_GEN_PKG) $(CONVERSION_GEN_BIN) $(CONVERSION_GEN_VER)\n\n$(CONVERSION_VERIFIER): $(TOOLS_DIR)/go.mod # Build conversion-verifier from tools folder.\n\tcd $(TOOLS_DIR); go build -tags=tools -o $(BIN_DIR)/$(CONVERSION_VERIFIER_BIN) sigs.k8s.io/cluster-api/hack/tools/conversion-verifier\n\n.PHONY: $(OPENAPI_GEN)\n$(OPENAPI_GEN): # Build openapi-gen from tools folder.\n\tGOBIN=$(TOOLS_BIN_DIR) $(GO_INSTALL) $(OPENAPI_GEN_PKG) $(OPENAPI_GEN_BIN) $(OPENAPI_GEN_VER)\n\n## We are forcing a rebuilt of runtime-openapi-gen via PHONY so that we're always using an up-to-date version.\n.PHONY: $(RUNTIME_OPENAPI_GEN)\n$(RUNTIME_OPENAPI_GEN): $(TOOLS_DIR)/go.mod # Build openapi-gen from tools folder.\n\tcd $(TOOLS_DIR); go build -tags=tools -o $(BIN_DIR)/$(RUNTIME_OPENAPI_GEN_BIN) sigs.k8s.io/cluster-api/hack/tools/runtime-openapi-gen\n\n.PHONY: $(PROWJOB_GEN)\n$(PROWJOB_GEN): $(TOOLS_DIR)/go.mod # Build prowjob-gen from tools folder.\n\tcd $(TOOLS_DIR); go build -tags=tools -o $(BIN_DIR)/$(PROWJOB_GEN_BIN) sigs.k8s.io/cluster-api/hack/tools/prowjob-gen\n\n$(GOTESTSUM): # Build gotestsum from tools folder.\n\tGOBIN=$(TOOLS_BIN_DIR) $(GO_INSTALL) $(GOTESTSUM_PKG) $(GOTESTSUM_BIN) $(GOTESTSUM_VER)\n\n$(GO_APIDIFF): # Build go-apidiff from tools folder.\n\tGOBIN=$(TOOLS_BIN_DIR) $(GO_INSTALL) $(GO_APIDIFF_PKG) $(GO_APIDIFF_BIN) $(GO_APIDIFF_VER)\n\n$(ENVSUBST): # Build gotestsum from tools folder.\n\tGOBIN=$(TOOLS_BIN_DIR) $(GO_INSTALL) $(ENVSUBST_PKG) $(ENVSUBST_BIN) $(ENVSUBST_VER)\n\n$(KUSTOMIZE): # Build kustomize from tools folder.\n\tCGO_ENABLED=0 GOBIN=$(TOOLS_BIN_DIR) $(GO_INSTALL) $(KUSTOMIZE_PKG) $(KUSTOMIZE_BIN) $(KUSTOMIZE_VER)\n\n$(SETUP_ENVTEST): # Build setup-envtest from tools folder.\n\tGOBIN=$(TOOLS_BIN_DIR) $(GO_INSTALL) $(SETUP_ENVTEST_PKG) $(SETUP_ENVTEST_BIN) $(SETUP_ENVTEST_VER)\n\n$(TILT_PREPARE): $(TOOLS_DIR)/go.mod # Build tilt-prepare from tools folder.\n\tcd $(TOOLS_DIR); go build -tags=tools -o $(BIN_DIR)/tilt-prepare sigs.k8s.io/cluster-api/hack/tools/internal/tilt-prepare\n\n$(KPROMO):\n\tGOBIN=$(TOOLS_BIN_DIR) $(GO_INSTALL) $(KPROMO_PKG) $(KPROMO_BIN) ${KPROMO_VER}\n\n$(YQ):\n\tGOBIN=$(TOOLS_BIN_DIR) $(GO_INSTALL) $(YQ_PKG) $(YQ_BIN) ${YQ_VER}\n\n$(GINKGO): # Build ginkgo from tools folder.\n\tGOBIN=$(TOOLS_BIN_DIR) $(GO_INSTALL) $(GINKGO_PKG) $(GINKGO_BIN) $(GINKGO_VER)\n\n$(GOLANGCI_LINT): # Build golangci-lint from tools folder.\n\tGOBIN=$(TOOLS_BIN_DIR) $(GO_INSTALL) $(GOLANGCI_LINT_PKG) $(GOLANGCI_LINT_BIN) $(GOLANGCI_LINT_VER)\n\n$(GOVULNCHECK): # Build govulncheck.\n\tGOBIN=$(TOOLS_BIN_DIR) $(GO_INSTALL) $(GOVULNCHECK_PKG) $(GOVULNCHECK_BIN) $(GOVULNCHECK_VER)\n\n$(IMPORT_BOSS): # Build import-boss\n\tGOBIN=$(TOOLS_BIN_DIR) $(GO_INSTALL) $(IMPORT_BOSS_PKG) $(IMPORT_BOSS_BIN) $(IMPORT_BOSS_VER)\n\n## --------------------------------------\n## triage-party\n## --------------------------------------\n\n.PHONY: release-triage-party\nrelease-triage-party: docker-build-triage-party docker-push-triage-party clean-triage-party\n\n.PHONY: release-triage-party-local\nrelease-triage-party-local: docker-build-triage-party clean-triage-party ## Release the triage party image for local use only\n\n.PHONY: checkout-triage-party\ncheckout-triage-party:\n\t@if [ -z \"${TRIAGE_PARTY_VERSION}\" ]; then echo \"TRIAGE_PARTY_VERSION is not set\"; exit 1; fi\n\t@if [ -d \"$(TRIAGE_PARTY_TMP_DIR)\" ]; then \\\n\t\techo \"$(TRIAGE_PARTY_TMP_DIR) exists, skipping clone\"; \\\n\telse \\\n\t\tgit clone \"https://github.com/google/triage-party.git\" \"$(TRIAGE_PARTY_TMP_DIR)\"; \\\n\t\tcd \"$(TRIAGE_PARTY_TMP_DIR)\"; \\\n\t\tgit checkout \"$(TRIAGE_PARTY_VERSION)\"; \\\n\t\tgit apply \"$(ROOT_DIR)/$(TRIAGE_PARTY_DIR)/triage-improvements.patch\"; \\\n\tfi\n\t@cd \"$(ROOT_DIR)/$(TRIAGE_PARTY_TMP_DIR)\"; \\\n\tif [ \"$$(git describe --tag 2> /dev/null)\" != \"$(TRIAGE_PARTY_VERSION)\" ]; then \\\n\t\techo \"ERROR: checked out version $$(git describe --tag 2> /dev/null) does not match expected version $(TRIAGE_PARTY_VERSION)\"; \\\n\t\texit 1; \\\n\tfi\n\n.PHONY: docker-build-triage-party\ndocker-build-triage-party: checkout-triage-party\n\t@if [ -z \"${TRIAGE_PARTY_VERSION}\" ]; then echo \"TRIAGE_PARTY_VERSION is not set\"; exit 1; fi\n\tcd $(TRIAGE_PARTY_TMP_DIR) && \\\n\tdocker buildx build --platform linux/amd64 -t $(TRIAGE_PARTY_CONTROLLER_IMG):$(TRIAGE_PARTY_VERSION) .\n\n.PHONY: docker-push-triage-party\ndocker-push-triage-party:\n\t@if [ -z \"${TRIAGE_PARTY_VERSION}\" ]; then echo \"TRIAGE_PARTY_VERSION is not set\"; exit 1; fi\n\tdocker push $(TRIAGE_PARTY_CONTROLLER_IMG):$(TRIAGE_PARTY_VERSION)\n\n.PHONY: clean-triage-party\nclean-triage-party:\n\trm -fr \"$(TRIAGE_PARTY_TMP_DIR)\"\n\n.PHONY: triage-party\ntriage-party: ## Start a local instance of triage party\n\t@if [ -z \"${GITHUB_TOKEN}\" ]; then echo \"GITHUB_TOKEN is not set\"; exit 1; fi\n\tdocker run --platform linux/amd64 --rm \\\n\t\t-e GITHUB_TOKEN \\\n\t\t-e \"PERSIST_BACKEND=disk\" \\\n\t\t-e \"PERSIST_PATH=/app/.cache\" \\\n\t\t-v \"$(ROOT_DIR)/$(TRIAGE_PARTY_DIR)/.cache:/app/.cache\" \\\n\t\t-v \"$(ROOT_DIR)/$(TRIAGE_PARTY_DIR)/config.yaml:/app/config/config.yaml\" \\\n\t\t-p 8080:8080 \\\n\t\t$(TRIAGE_PARTY_CONTROLLER_IMG):$(TRIAGE_PARTY_VERSION)\n\n## --------------------------------------\n## Helpers\n## --------------------------------------\n\n##@ helpers:\n\ngo-version: ## Print the go version we use to compile our binaries and images\n\t@echo $(GO_VERSION)\n"
        },
        {
          "name": "OWNERS",
          "type": "blob",
          "size": 0.533203125,
          "content": "# See the OWNERS docs at https://go.k8s.io/owners for information on OWNERS files.\n# See the OWNERS_ALIASES file at https://github.com/kubernetes-sigs/cluster-api/blob/main/OWNERS_ALIASES for a list of members for each alias.\n\napprovers:\n  - sig-cluster-lifecycle-leads\n  - cluster-api-admins\n  - cluster-api-maintainers\n\nreviewers:\n  - cluster-api-maintainers\n  - cluster-api-reviewers\n\nemeritus_approvers:\n  - CecileRobertMichon\n  - chuckha\n  - detiber\n  - kris-nova\n  - ncdc\n  - roberthbailey\n  - davidewatson\n  - ykakarap\n  - killianmuldoon\n\n"
        },
        {
          "name": "OWNERS_ALIASES",
          "type": "blob",
          "size": 4.01953125,
          "content": "# See the OWNERS docs: https://git.k8s.io/community/contributors/guide/owners.md\n\naliases:\n  sig-cluster-lifecycle-leads:\n  - fabriziopandini\n  - justinsb\n  - neolit123\n  - vincepri\n\n  # -----------------------------------------------------------\n  # OWNER_ALIASES for Cluster API\n  # -----------------------------------------------------------\n\n  # active folks who can be contacted to perform admin-related\n  # tasks on the repo, or otherwise approve any PRS.\n  cluster-api-admins:\n  - fabriziopandini\n  - sbueringer\n  - vincepri\n\n  # non-admin folks who have write-access and can approve any PRs in the repo\n  cluster-api-maintainers:\n  - chrischdi\n  - enxebre\n  - fabriziopandini\n  - sbueringer\n  - vincepri\n\n  # folks who can review and LGTM any PRs in the repo\n  cluster-api-reviewers:\n  - jackfrancis\n  - JoelSpeed\n  - richardcase\n\n  # -----------------------------------------------------------\n  # OWNER_ALIASES for controllers/topology\n  # -----------------------------------------------------------\n\n  cluster-api-topology-maintainers:\n  cluster-api-topology-reviewers:\n\n  # -----------------------------------------------------------\n  # OWNER_ALIASES for bootstrap/kubeadm\n  # -----------------------------------------------------------\n\n  cluster-api-bootstrap-provider-kubeadm-maintainers:\n  cluster-api-bootstrap-provider-kubeadm-reviewers:\n  - g-gaston\n\n  # -----------------------------------------------------------\n  # OWNER_ALIASES for bootstrap/kubeadm/internal/ignition\n  # -----------------------------------------------------------\n\n  cluster-api-bootstrap-provider-kubeadm-ignition-maintainers:\n  cluster-api-bootstrap-provider-kubeadm-ignition-reviewers: []\n\n  # -----------------------------------------------------------\n  # OWNER_ALIASES for controlplane/kubeadm\n  # -----------------------------------------------------------\n\n  cluster-api-controlplane-provider-kubeadm-maintainers:\n  cluster-api-controlplane-provider-kubeadm-reviewers:\n  - g-gaston\n\n  # -----------------------------------------------------------\n  # OWNER_ALIASES for cmd/clusterctl\n  # -----------------------------------------------------------\n\n  cluster-api-clusterctl-maintainers:\n  cluster-api-clusterctl-reviewers:\n  - Jont828\n\n  # -----------------------------------------------------------\n  # OWNER_ALIASES for test\n  # -----------------------------------------------------------\n\n  cluster-api-test-maintainers:\n  cluster-api-test-reviewers:\n  - elmiko\n\n  # -----------------------------------------------------------\n  # OWNER_ALIASES for test/framework\n  # -----------------------------------------------------------\n\n  cluster-api-test-framework-maintainers:\n  cluster-api-test-framework-reviewers:\n  - elmiko\n\n  # -----------------------------------------------------------\n  # OWNER_ALIASES for test/infrastructure/docker\n  # -----------------------------------------------------------\n\n  cluster-api-provider-docker-maintainers:\n  cluster-api-provider-docker-reviewers:\n  - elmiko\n\n  # -----------------------------------------------------------\n  # OWNER_ALIASES for test/infrastructure/inmemory\n  # -----------------------------------------------------------\n\n  cluster-api-provider-inmemory-maintainers:\n  cluster-api-provider-inmemory-reviewers:\n\n  # -----------------------------------------------------------\n  # OWNER_ALIASES for docs\n  # -----------------------------------------------------------\n\n  cluster-api-docs-maintainers: []\n  cluster-api-docs-reviewers:\n  - elmiko\n\n  # -----------------------------------------------------------\n  # OWNER_ALIASES for v1.9 release-team\n  # -----------------------------------------------------------\n\n  cluster-api-release-lead:\n  - mboersma\n\n  cluster-api-release-team:\n  # members added in commented lines have a pending membership\n  # and will be added back once it is acquired.\n  # - AttyXY\n  # - blind3dd\n  - cahillsf\n  - chandankumar4\n  - cprivitere\n  - hackeramitkumar\n  - mboersma\n  # - mbrow137\n  # - pratik-mahalle\n  # - ramessesii2\n  # - RansherSingh\n  - serngawy\n  - shecodesmagic\n  - sreeram-venkitesh\n  - Sunnatillo\n  - wendy-ha18\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 4.14453125,
          "content": "<a href=\"https://cluster-api.sigs.k8s.io\"><img alt=\"capi\" src=\"./logos/kubernetes-cluster-logos_final-02.svg\" width=\"160x\" /></a>\n<p>\n<a href=\"https://godoc.org/sigs.k8s.io/cluster-api\"><img src=\"https://godoc.org/sigs.k8s.io/cluster-api?status.svg\"></a>\n<!-- join kubernetes slack channel for cluster-api -->\n<a href=\"http://slack.k8s.io/\">\n<img src=\"https://img.shields.io/badge/join%20slack-%23cluster--api-brightgreen\"></a>\n<!-- latest stable release badge -->\n<img alt=\"GitHub release (latest SemVer)\" src=\"https://img.shields.io/github/v/release/kubernetes-sigs/cluster-api\">\n</p>\n\n# Cluster API\n\n### 👋 Welcome to our project! Our [Book](https://cluster-api.sigs.k8s.io) can help you get started and provides lots of in-depth information.\n\n#### Useful links\n- [Feature proposals](./docs/proposals)\n- [Quick Start](https://cluster-api.sigs.k8s.io/user/quick-start.html)\n\n## ✨ What is the Cluster API?\n\nCluster API is a Kubernetes subproject focused on providing declarative APIs and tooling to simplify provisioning, upgrading, and operating multiple Kubernetes clusters.\n\nStarted by the Kubernetes Special Interest Group (SIG) Cluster Lifecycle, the Cluster API project uses Kubernetes-style APIs and patterns to automate cluster lifecycle management for platform operators. The supporting infrastructure, like virtual machines, networks, load balancers, and VPCs, as well as the Kubernetes cluster configuration are all defined in the same way that application developers operate deploying and managing their workloads. This enables consistent and repeatable cluster deployments across a wide variety of infrastructure environments.\n\n### ⚙️ Providers\n\nCluster API can be extended to support any infrastructure (AWS, Azure, vSphere, etc.), bootstrap or control plane (kubeadm is built-in) provider. There is a growing list of [supported providers](https://cluster-api.sigs.k8s.io/reference/providers.html) available.\n\n<!-- ANCHOR: Community -->\n\n## 🤗 Community, discussion, contribution, and support\n\nCluster API is developed in the open, and is constantly being improved by our users, contributors, and maintainers. It is because of you that we are able to automate cluster lifecycle management for the community. Join us!\n\nIf you have questions or want to get the latest project news, you can connect with us in the following ways:\n\n- Chat with us on the Kubernetes [Slack](http://slack.k8s.io/) in the [#cluster-api][#cluster-api slack] channel\n- Subscribe to the [SIG Cluster Lifecycle](https://groups.google.com/a/kubernetes.io/g/sig-cluster-lifecycle) Google Group for access to documents and calendars\n- Join our Cluster API working group sessions where we share the latest project news, demos, answer questions, and triage issues\n    - Weekly on Wednesdays @ 10:00 PT on [Zoom][zoomMeeting]\n    - Previous meetings: \\[ [notes][notes] | [recordings][recordings] \\]\n\nPull Requests and feedback on issues are very welcome!\nSee the [issue tracker] if you're unsure where to start, especially the [Good first issue] and [Help wanted] tags, and\nalso feel free to reach out to discuss.\n\nSee also our [contributor guide](CONTRIBUTING.md) and the Kubernetes [community page] for more details on how to get involved.\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).\n\n[community page]: https://kubernetes.io/community\n[notes]: https://cluster-api.sigs.k8s.io/agenda\n[recordings]: https://www.youtube.com/playlist?list=PL69nYSiGNLP29D0nYgAGWt1ZFqS9Z7lw4\n[zoomMeeting]: https://zoom.us/j/861487554\n[implementerNotes]: https://docs.google.com/document/d/1IZ2-AZhe4r3CYiJuttyciS7bGZTTx4iMppcA8_Pr3xE/edit\n[providerZoomMeetingTues]: https://zoom.us/j/140808484\n[providerZoomMeetingWed]: https://zoom.us/j/424743530\n[issue tracker]: https://github.com/kubernetes-sigs/cluster-api/issues\n[#cluster-api slack]: https://kubernetes.slack.com/archives/C8TSNPY4T\n[Good first issue]: https://github.com/kubernetes-sigs/cluster-api/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22\n[Help wanted]: https://github.com/kubernetes-sigs/cluster-api/issues?utf8=%E2%9C%93&q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22+\n\n<!-- ANCHOR_END: Community -->\n"
        },
        {
          "name": "REVIEWING.md",
          "type": "blob",
          "size": 6.45703125,
          "content": "# Code Review in Cluster API\n\n## Goal of this document\n\n- To help newcomers to the project in implementing better PRs given the knowledge of what will be evaluated \n  during the review.\n- To help contributors in stepping up as a reviewer given a common understanding of what are the most relevant\n  things to be evaluated during the review.\n\nIMPORTANT: improving and maintaining this document is a collaborative effort, so we are encouraging constructive\nfeedback and suggestions.\n\n   * [Code Review in Cluster API](#code-review-in-cluster-api)\n      * [Goal of this document](#goal-of-this-document)\n      * [Resources](#resources)\n      * [Definition](#definition)\n         * [Controller reentrancy](#controller-reentrancy)\n         * [API design](#api-design)\n            * [Serialization](#serialization)\n            * [Owner References](#owner-references)\n         * [The Cluster API contract](#the-cluster-api-contract)\n         * [Logging](#logging)\n         * [Testing](#testing)\n\n## Resources\n\n- [Writing inclusive documentation](https://developers.google.com/style/inclusive-documentation)\n- [Contributor Summit NA 2019: Keeping the Bar High - How to be a bad-ass Code Reviewer](https://www.youtube.com/watch?v=OZVv7-o8i40)\n- [Code Review Developer Guide - Google](https://google.github.io/eng-practices/review/)\n- [The Gentle Art Of Patch Review](https://sage.thesharps.us/2014/09/01/the-gentle-art-of-patch-review/)\n\n## Definition\n\n(from [Code Review Developer Guide - Google](https://google.github.io/eng-practices/review/)) \n\n_\"A code review is a process where someone other than the author(s) of a piece of code examines that code\"_\n\nWithin the context of cluster API the following design items should be carefully evaluated when reviewing a PR:\n\n### Controller reentrancy\n\nIn CAPI most of the coding activities happen in controllers, and in order to make robust controllers,\nwe should strive for implementing reentrant code.\n\nA reentrant code can be interrupted in the middle of its execution and then safely be called again\n(\"re-entered\"); this concept, applied to Kubernetes controllers, means that a controller should be capable\nof recovering from interruptions, observe the current state of things, and act accordingly. e.g.\n \n- We should not rely on flags/conditions from previous reconciliations since we are the controller\n  setting the conditions. Instead, we should detect the status of things through introspection at\n  every reconciliation and act accordingly.\n- It is acceptable to rely on status flags/conditions that we've previously set as part\n  of the current reconciliation.\n- It is acceptable to rely on status flags/conditions set by other controllers.\n\nNOTE: An important use case for reentrancy is the move operation, where Cluster API objects gets moved\nto a different management cluster and the controller running on the target cluster has to\nrebuild the object status from scratch by observing the current state of the underlying infrastructure.\n\n### API design\n\nThe API defines the main contract with the Cluster API users. As most of the APIs in Kubernetes,\neach API version encompasses a set of guarantees to the user in terms of support window, stability,\nand upgradability. \n\nThis makes API design a critical part of Cluster API development and usually:\n\n- Breaking/major API changes should go through the CAEP process and be strictly synchronized with the major\n  release cadence.\n- Non-breaking/minor API changes can go in minor releases; non-breaking changes are generally:\n  - additive in nature\n  - default to pre-existing behavior\n  - optional as part of the API contract\n\nOn top of that, following API design considerations apply.\n\n#### Serialization\n\nThe Kubernetes API-machinery that is used for API serialization is build on top of three\ntechnologies, most specifically:\n\n- JSON serialization\n- Open-API (for CRDs)\n- the go type system\n\nOne of the areas where the interaction between those technologies is critical in the handling of optional\nvalues in the API; also the usage of nested slices might lead to problems in case of concurrent\nedits of the object.\n\n#### Owner References\n\nCluster API leverages the owner ref chain of objects for several tasks, so it is crucial to evaluate the\nimpacts of any change that can impact this area. Above all:\n\n- The delete operation leverages on the owner ref chain for ensuring the cleanup of all the resources when\n  a cluster is deleted; \n- clusterctl move uses the owner ref chain for determining which object to move and the create/delete order.\n\n### The Cluster API contract\n\nThe Cluster API rules define a set of rules/conventions the different provider authors should follow in\norder to implement providers that can interact with the core Cluster API controllers, as \ndocumented [here](https://cluster-api.sigs.k8s.io/developer/guide.html) and [here](https://cluster-api.sigs.k8s.io/clusterctl/provider-contract.html).\n\nBy extension, the Cluster API contract includes all the util methods that Cluster API exposes for\nmaking the development of providers simpler and consistent (e.g. everything under `/util` or in  `/test/framework`);\ndocumentation of the utility is available [here](https://pkg.go.dev/sigs.k8s.io/cluster-api?tab=subdirectories).\n\nThe Cluster API contract is linked to the version of the API (e.g. v1beta1 Contract), and it is expected to\nprovide the same set of guarantees in terms of support window, stability, and upgradability. \n\nThis makes any change that can impact the Cluster API contract critical and usually:\n\n- Breaking/major contract changes should go through the CAEP process and be strictly synchronized with the major\n  release cadence.\n- Non-breaking/minor changes can go in minor releases; non-breaking changes are generally:\n  - Additive in nature\n  - Default to pre-existing behavior\n  - Optional as part of the API contract\n\n### Logging\n\nWhile developing controllers in Cluster API a key requirement is to add logging to observe the system and\nto help troubleshooting issues.\n\n- For CAPI controllers see [Cluster API logging conventions](https://cluster-api.sigs.k8s.io/developer/logging.html).\n- For clusterctl see [clusterctl logging conventions](https://github.com/kubernetes-sigs/cluster-api/blob/main/cmd/clusterctl/log/doc.go).\n\n### Testing\n\nTesting plays a crucial role in ensuring the long term maintainability of the project.\n\nIn Cluster API we are committed to have a good test coverage and also to have a nice and consistent style in implementing\ntests. For more information see [testing Cluster API](https://cluster-api.sigs.k8s.io/developer/testing.html).  "
        },
        {
          "name": "SECURITY_CONTACTS",
          "type": "blob",
          "size": 0.6123046875,
          "content": "# Defined below are the security contacts for this repo.\n#\n# They are the contact point for the Product Security Team to reach out\n# to for triaging and handling of incoming issues.\n#\n# The below names agree to abide by the\n# [Embargo Policy](https://git.k8s.io/sig-release/security-release-process-documentation/security-release-process.md#embargo-policy)\n# and will be removed and replaced if they violate that agreement.\n#\n# DO NOT REPORT SECURITY VULNERABILITIES DIRECTLY TO THESE NAMES, FOLLOW THE\n# INSTRUCTIONS AT https://kubernetes.io/security/\n\nfabriziopandini\njustinsb\nneolit123\ntimothysc\nvincepri\nCecileRobertMichon\n"
        },
        {
          "name": "Tiltfile",
          "type": "blob",
          "size": 27.759765625,
          "content": "# -*- mode: Python -*-\n\nenvsubst_cmd = \"./hack/tools/bin/envsubst\"\nclusterctl_cmd = \"./bin/clusterctl\"\nkubectl_cmd = \"kubectl\"\nkubernetes_version = \"v1.31.2\"\n\nload(\"ext://uibutton\", \"cmd_button\", \"location\", \"text_input\")\n\n# set defaults\nversion_settings(True, \">=0.30.8\")\n\nsettings = {\n    \"enable_providers\": [\"docker\"],\n    \"kind_cluster_name\": os.getenv(\"CAPI_KIND_CLUSTER_NAME\", \"capi-test\"),\n    \"debug\": {},\n    \"build_engine\": \"docker\",\n}\n\n# global settings\ntilt_file = \"./tilt-settings.yaml\" if os.path.exists(\"./tilt-settings.yaml\") else \"./tilt-settings.json\"\nsettings.update(read_yaml(\n    tilt_file,\n    default = {},\n))\n\nos.putenv(\"CAPI_KIND_CLUSTER_NAME\", settings.get(\"kind_cluster_name\"))\n\nallow_k8s_contexts(settings.get(\"allowed_contexts\"))\n\nif str(local(\"command -v \" + kubectl_cmd + \" || true\", quiet = True)) == \"\":\n    fail(\"Required command '\" + kubectl_cmd + \"' not found in PATH\")\n\n# detect if docker images should be built using podman\nif \"Podman Engine\" in str(local(\"docker version || podman version\", quiet = True)):\n    settings[\"build_engine\"] = \"podman\"\n\nos_name = str(local(\"go env GOOS\")).rstrip(\"\\n\")\nos_arch = str(local(\"go env GOARCH\")).rstrip(\"\\n\")\n\nif settings.get(\"trigger_mode\") == \"manual\":\n    trigger_mode(TRIGGER_MODE_MANUAL)\n\nusingLocalRegistry = str(local(kubectl_cmd + \" get cm -n kube-public local-registry-hosting || true\", quiet = True))\nif not usingLocalRegistry:\n    if settings.get(\"default_registry\", \"\") == \"\":\n        fail(\"default_registry is required when not using a local registry, please add it to your tilt-settings.yaml/json\")\n\n    protectedRegistries = [\"gcr.io/k8s-staging-cluster-api\"]\n    if settings.get(\"default_registry\") in protectedRegistries:\n        fail(\"current default_registry '{}' is protected, tilt cannot push images to it. Please select another default_registry in your tilt-settings.yaml/json\".format(settings.get(\"default_registry\")))\n\nif settings.get(\"default_registry\", \"\") != \"\":\n    default_registry(settings.get(\"default_registry\"))\n\nalways_enable_providers = [\"core\"]\n\nproviders = {\n    \"core\": {\n        \"context\": \".\",  # NOTE: this should be kept in sync with corresponding setting in tilt-prepare\n        \"image\": \"gcr.io/k8s-staging-cluster-api/cluster-api-controller\",\n        \"live_reload_deps\": [\n            \"main.go\",\n            \"go.mod\",\n            \"go.sum\",\n            \"api\",\n            \"cmd\",\n            \"controllers\",\n            \"errors\",\n            \"exp\",\n            \"feature\",\n            \"internal\",\n            \"util\",\n            \"webhooks\",\n        ],\n        \"label\": \"CAPI\",\n    },\n    \"kubeadm-bootstrap\": {\n        \"context\": \"bootstrap/kubeadm\",  # NOTE: this should be kept in sync with corresponding setting in tilt-prepare\n        \"image\": \"gcr.io/k8s-staging-cluster-api/kubeadm-bootstrap-controller\",\n        \"live_reload_deps\": [\n            \"main.go\",\n            \"api\",\n            \"controllers\",\n            \"internal\",\n            \"types\",\n            \"../../go.mod\",\n            \"../../go.sum\",\n        ],\n        \"label\": \"CABPK\",\n    },\n    \"kubeadm-control-plane\": {\n        \"context\": \"controlplane/kubeadm\",  # NOTE: this should be kept in sync with corresponding setting in tilt-prepare\n        \"image\": \"gcr.io/k8s-staging-cluster-api/kubeadm-control-plane-controller\",\n        \"live_reload_deps\": [\n            \"main.go\",\n            \"api\",\n            \"controllers\",\n            \"internal\",\n            \"../../go.mod\",\n            \"../../go.sum\",\n        ],\n        \"label\": \"KCP\",\n    },\n    \"docker\": {\n        \"context\": \"test/infrastructure/docker\",  # NOTE: this should be kept in sync with corresponding setting in tilt-prepare\n        \"image\": \"gcr.io/k8s-staging-cluster-api/capd-manager\",\n        \"live_reload_deps\": [\n            \"main.go\",\n            \"../../go.mod\",\n            \"../../go.sum\",\n            \"../container\",\n            \"api\",\n            \"controllers\",\n            \"docker\",\n            \"exp\",\n            \"internal\",\n        ],\n        \"label\": \"CAPD\",\n    },\n    \"in-memory\": {\n        \"context\": \"test/infrastructure/inmemory\",  # NOTE: this should be kept in sync with corresponding setting in tilt-prepare\n        \"image\": \"gcr.io/k8s-staging-cluster-api/capim-manager\",\n        \"live_reload_deps\": [\n            \"main.go\",\n            \"../../go.mod\",\n            \"../../go.sum\",\n            \"api\",\n            \"controllers\",\n            \"internal\",\n        ],\n        \"label\": \"CAPIM\",\n    },\n    \"test-extension\": {\n        \"context\": \"test/extension\",  # NOTE: this should be kept in sync with corresponding setting in tilt-prepare\n        \"image\": \"gcr.io/k8s-staging-cluster-api/test-extension\",\n        \"live_reload_deps\": [\n            \"main.go\",\n            \"handlers\",\n        ],\n        \"label\": \"test-extension\",\n        # Add the ExtensionConfig for this Runtime extension; given that the ExtensionConfig can be installed only when capi_controller\n        # are up and running, it is required to set a resource_deps to ensure proper install order.\n        \"additional_resources\": [\n            \"config/tilt/extensionconfig.yaml\",\n        ],\n        \"resource_deps\": [\"capi_controller\"],\n    },\n}\n\n# Reads a provider's tilt-provider.json file and merges it into the providers map.\n# A list of dictionaries is also supported by enclosing it in brackets []\n# An example file looks like this:\n# {\n#     \"name\": \"aws\",\n#     \"config\": {\n#         \"image\": \"gcr.io/k8s-staging-cluster-api-aws/cluster-api-aws-controller\",\n#         \"live_reload_deps\": [\n#             \"main.go\", \"go.mod\", \"go.sum\", \"api\", \"cmd\", \"controllers\", \"pkg\"\n#         ]\n#     }\n# }\n\ndef load_provider_tiltfiles():\n    provider_repos = settings.get(\"provider_repos\", [])\n\n    for repo in provider_repos:\n        file = repo + \"/tilt-provider.yaml\" if os.path.exists(repo + \"/tilt-provider.yaml\") else repo + \"/tilt-provider.json\"\n        if not os.path.exists(file):\n            fail(\"Failed to load provider. No tilt-provider.{yaml|json} file found in \" + repo)\n        provider_details = read_yaml(file, default = {})\n        if type(provider_details) != type([]):\n            provider_details = [provider_details]\n        for item in provider_details:\n            provider_name = item[\"name\"]\n            provider_config = item[\"config\"]\n            if \"context\" in provider_config:\n                provider_config[\"context\"] = repo + \"/\" + provider_config[\"context\"]\n            else:\n                provider_config[\"context\"] = repo\n            if \"go_main\" not in provider_config:\n                provider_config[\"go_main\"] = \"main.go\"\n            providers[provider_name] = provider_config\n\ntilt_helper_dockerfile_header = \"\"\"\n# Tilt image\nFROM golang:1.22.10 as tilt-helper\n# Install delve. Note this should be kept in step with the Go release minor version.\nRUN go install github.com/go-delve/delve/cmd/dlv@v1.22\n# Support live reloading with Tilt\nRUN wget --output-document /restart.sh --quiet https://raw.githubusercontent.com/tilt-dev/rerun-process-wrapper/master/restart.sh  && \\\n    wget --output-document /start.sh --quiet https://raw.githubusercontent.com/tilt-dev/rerun-process-wrapper/master/start.sh && \\\n    chmod +x /start.sh && chmod +x /restart.sh && chmod +x /go/bin/dlv && \\\n    touch /process.txt && chmod 0777 /process.txt `# pre-create PID file to allow even non-root users to run the image`\n\"\"\"\n\ntilt_dockerfile_header = \"\"\"\nFROM golang:1.22.10 as tilt\nWORKDIR /\nCOPY --from=tilt-helper /process.txt .\nCOPY --from=tilt-helper /start.sh .\nCOPY --from=tilt-helper /restart.sh .\nCOPY --from=tilt-helper /go/bin/dlv .\nCOPY $binary_name .\n\"\"\"\n\ndef build_go_binary(context, reload_deps, debug, go_main, binary_name, label):\n    # Set up a local_resource build of a go binary. The target repo is expected to have a main.go in\n    # the context path or the main.go must be provided via go_main option. The binary is written to .tiltbuild/bin/{$binary_name}.\n    # TODO @randomvariable: Race detector mode only currently works on x86-64 Linux.\n    # Need to switch to building inside Docker when architecture is mismatched\n    race_detector_enabled = debug.get(\"race_detector\", False)\n    if race_detector_enabled:\n        if os_name != \"linux\" or os_arch != \"amd64\":\n            fail(\"race_detector is only supported on Linux x86-64\")\n        cgo_enabled = \"1\"\n        build_options = \"-race\"\n        ldflags = \"-linkmode external -extldflags \\\"-static\\\"\"\n    else:\n        cgo_enabled = \"0\"\n        build_options = \"\"\n        ldflags = \"-extldflags \\\"-static\\\"\"\n\n    debug_port = int(debug.get(\"port\", 0))\n    if debug_port != 0:\n        # disable optimisations and include line numbers when debugging\n        gcflags = \"all=-N -l\"\n    else:\n        gcflags = \"\"\n\n    build_env = \"CGO_ENABLED={cgo_enabled} GOOS=linux GOARCH={arch}\".format(\n        cgo_enabled = cgo_enabled,\n        arch = os_arch,\n    )\n\n    build_cmd = \"{build_env} go build {build_options} -gcflags '{gcflags}' -ldflags '{ldflags}' -o .tiltbuild/bin/{binary_name} {go_main}\".format(\n        build_env = build_env,\n        build_options = build_options,\n        gcflags = gcflags,\n        go_main = go_main,\n        ldflags = ldflags,\n        binary_name = binary_name,\n    )\n\n    # Prefix each live reload dependency with context. For example, for if the context is\n    # test/infra/docker and main.go is listed as a dep, the result is test/infra/docker/main.go. This adjustment is\n    # needed so Tilt can watch the correct paths for changes.\n    live_reload_deps = []\n    for d in reload_deps:\n        live_reload_deps.append(context + \"/\" + d)\n\n    # Ensure the {context}/.tiltbuild/bin directory before any other resources\n    # `local` is evaluated immediately, other resources are executed later in the startup/when triggered\n    local(\"mkdir -p {context}/.tiltbuild/bin\".format(context = shlex.quote(context)), quiet = True)\n\n    # Build the go binary\n    local_resource(\n        label.lower() + \"_binary\",\n        cmd = \"cd {context};{build_cmd}\".format(\n            context = context,\n            build_cmd = build_cmd,\n        ),\n        deps = live_reload_deps,\n        labels = [label, \"ALL.binaries\"],\n    )\n\ndef build_docker_image(image, context, binary_name, additional_docker_build_commands, additional_docker_helper_commands, port_forwards):\n    links = []\n\n    dockerfile_contents = \"\\n\".join([\n        tilt_helper_dockerfile_header,\n        additional_docker_helper_commands,\n        tilt_dockerfile_header,\n        additional_docker_build_commands,\n    ])\n\n    # Set up an image build for the provider. The live update configuration syncs the output from the local_resource\n    # build into the container.\n    if settings.get(\"build_engine\") == \"podman\":\n        bin_context = context + \"/.tiltbuild/bin/\"\n\n        # Write dockerfile_contents to a Dockerfile as custom_build doesn't support dockerfile_contents nor stdin.\n        # The Dockerfile is in the context path to simplify the below podman command.\n        local(\"tee %s/Dockerfile\" % (shlex.quote(bin_context)), quiet = True, stdin = dockerfile_contents)\n\n        custom_build(\n            ref = image,\n            command = (\n                \"set -ex\\n\" +\n                \"podman build -t $EXPECTED_REF --build-arg binary_name=%s --target tilt %s\\n\" +\n                \"podman push --format=docker $EXPECTED_REF\\n\"\n            ) % (binary_name, shlex.quote(bin_context)),\n            deps = [bin_context],\n            skips_local_docker = True,\n            live_update = [\n                sync(bin_context + binary_name, \"/\" + binary_name),\n                run(\"sh /restart.sh\"),\n            ],\n        )\n    else:\n        docker_build(\n            ref = image,\n            context = context + \"/.tiltbuild/bin/\",\n            dockerfile_contents = dockerfile_contents,\n            build_args = {\"binary_name\": binary_name},\n            target = \"tilt\",\n            only = binary_name,\n            live_update = [\n                sync(context + \"/.tiltbuild/bin/\" + binary_name, \"/\" + binary_name),\n                run(\"sh /restart.sh\"),\n            ],\n        )\n\ndef get_port_forwards(debug):\n    port_forwards = []\n    links = []\n\n    debug_port = int(debug.get(\"port\", 0))\n    if debug_port != 0:\n        port_forwards.append(port_forward(debug_port, 30000))\n\n    metrics_port = int(debug.get(\"metrics_port\", 0))\n    profiler_port = int(debug.get(\"profiler_port\", 0))\n    if metrics_port != 0:\n        port_forwards.append(port_forward(metrics_port, 8080))\n        links.append(link(\"http://localhost:\" + str(metrics_port) + \"/metrics\", \"metrics\"))\n\n    if profiler_port != 0:\n        port_forwards.append(port_forward(profiler_port, 6060))\n        links.append(link(\"http://localhost:\" + str(profiler_port) + \"/debug/pprof\", \"profiler\"))\n\n    return port_forwards, links\n\n# Configures a provider by doing the following:\n#\n# 1. Enables a local_resource go build of the provider's manager binary\n# 2. Configures a docker build for the provider, with live updating of the manager binary\n# 3. Runs kustomize for the provider's config/default and applies it\ndef enable_provider(name, debug):\n    p = providers.get(name)\n    label = p.get(\"label\")\n\n    port_forwards, links = get_port_forwards(debug)\n\n    if p.get(\"image\"):\n        build_go_binary(\n            context = p.get(\"context\"),\n            reload_deps = p.get(\"live_reload_deps\"),\n            debug = debug,\n            go_main = p.get(\"go_main\", \"main.go\"),\n            binary_name = \"manager\",\n            label = label,\n        )\n\n        build_docker_image(\n            image = p.get(\"image\"),\n            context = p.get(\"context\"),\n            binary_name = \"manager\",\n            additional_docker_helper_commands = p.get(\"additional_docker_helper_commands\", \"\"),\n            additional_docker_build_commands = p.get(\"additional_docker_build_commands\", \"\"),\n            port_forwards = port_forwards,\n        )\n\n    additional_objs = []\n    p_resources = p.get(\"additional_resources\", [])\n    for resource in p_resources:\n        k8s_yaml(p.get(\"context\") + \"/\" + resource)\n        additional_objs = additional_objs + decode_yaml_stream(read_file(p.get(\"context\") + \"/\" + resource))\n\n    if p.get(\"apply_provider_yaml\", True):\n        yaml = read_file(\"./.tiltbuild/yaml/{}.provider.yaml\".format(name))\n        k8s_yaml(yaml, allow_duplicates = True)\n        objs = decode_yaml_stream(yaml)\n        k8s_resource(\n            workload = find_object_name(objs, \"Deployment\"),\n            objects = [find_object_qualified_name(objs, \"Provider\")] + find_all_objects_names(additional_objs),\n            new_name = label.lower() + \"_controller\",\n            labels = [label, \"ALL.controllers\"],\n            port_forwards = port_forwards,\n            links = links,\n            resource_deps = [\"provider_crd\"] + p.get(\"resource_deps\", []),\n        )\n\ndef find_object_name(objs, kind):\n    for o in objs:\n        # Ignore objects that are not part of the provider, e.g. the ASO Deployment in CAPZ.\n        if o[\"kind\"] == kind and \"cluster.x-k8s.io/provider\" in o[\"metadata\"][\"labels\"]:\n            return o[\"metadata\"][\"name\"]\n    return \"\"\n\ndef find_object_qualified_name(objs, kind):\n    for o in objs:\n        if o[\"kind\"] == kind:\n            return \"{}:{}:{}\".format(o[\"metadata\"][\"name\"], kind, o[\"metadata\"][\"namespace\"])\n    return \"\"\n\ndef find_all_objects_names(objs):\n    qualified_names = []\n    for o in objs:\n        if \"namespace\" in o[\"metadata\"] and o[\"metadata\"][\"namespace\"] != \"\":\n            qualified_names = qualified_names + [\"{}:{}:{}\".format(o[\"metadata\"][\"name\"], o[\"kind\"], o[\"metadata\"][\"namespace\"])]\n        else:\n            qualified_names = qualified_names + [\"{}:{}\".format(o[\"metadata\"][\"name\"], o[\"kind\"])]\n    return qualified_names\n\n# Users may define their own Tilt customizations in tilt.d. This directory is excluded from git and these files will\n# not be checked in to version control.\ndef include_user_tilt_files():\n    user_tiltfiles = listdir(\"tilt.d\")\n    for f in user_tiltfiles:\n        include(f)\n\n# Enable core cluster-api plus everything listed in 'enable_providers' in tilt-settings.json\ndef enable_providers():\n    for name in get_providers():\n        enable_provider(name, settings.get(\"debug\").get(name, {}))\n\ndef get_providers():\n    user_enable_providers = settings.get(\"enable_providers\", [])\n    return {k: \"\" for k in user_enable_providers + always_enable_providers}.keys()\n\ndef deploy_provider_crds():\n    # NOTE: we are applying raw yaml for clusterctl resources (vs delegating this to clusterctl methods) because\n    # it is required to control precedence between creating this CRDs and creating providers.\n    k8s_yaml(read_file(\"./.tiltbuild/yaml/clusterctl.crd.yaml\"))\n    k8s_resource(\n        objects = [\"providers.clusterctl.cluster.x-k8s.io:CustomResourceDefinition:default\"],\n        new_name = \"provider_crd\",\n    )\n\ndef deploy_observability():\n    if \"promtail\" in settings.get(\"deploy_observability\", []):\n        k8s_yaml(read_file(\"./.tiltbuild/yaml/promtail.observability.yaml\"), allow_duplicates = True)\n        k8s_resource(workload = \"promtail\", extra_pod_selectors = [{\"app\": \"promtail\"}], labels = [\"observability\"], resource_deps = [\"loki\"], objects = [\"promtail:serviceaccount\"])\n\n    if \"loki\" in settings.get(\"deploy_observability\", []):\n        k8s_yaml(read_file(\"./.tiltbuild/yaml/loki.observability.yaml\"), allow_duplicates = True)\n        k8s_resource(workload = \"loki\", port_forwards = \"3100\", extra_pod_selectors = [{\"app\": \"loki\"}], labels = [\"observability\"], objects = [\"loki:serviceaccount\"])\n\n        cmd_button(\n            \"loki:import logs\",\n            argv = [\"sh\", \"-c\", \"cd ./hack/tools/internal/log-push && go run ./main.go --log-path=$LOG_PATH\"],\n            resource = \"loki\",\n            icon_name = \"import_export\",\n            text = \"Import logs\",\n            inputs = [\n                text_input(\"LOG_PATH\", label = \"Log path, one of: GCS path, ProwJob URL or local folder\"),\n            ],\n        )\n\n    if \"tempo\" in settings.get(\"deploy_observability\", []):\n        k8s_yaml(read_file(\"./.tiltbuild/yaml/tempo.observability.yaml\"), allow_duplicates = True)\n\n        # Port-forward the tracing port to localhost, so we can also send traces from local.\n        k8s_resource(workload = \"tempo\", port_forwards = \"4317:4317\", extra_pod_selectors = [{\"app\": \"tempo\"}], labels = [\"observability\"])\n\n    if \"grafana\" in settings.get(\"deploy_observability\", []):\n        k8s_yaml(read_file(\"./.tiltbuild/yaml/grafana.observability.yaml\"), allow_duplicates = True)\n        k8s_resource(workload = \"grafana\", port_forwards = \"3001:3000\", extra_pod_selectors = [{\"app\": \"grafana\"}], labels = [\"observability\"], objects = [\"grafana:serviceaccount\"])\n\n    if \"prometheus\" in settings.get(\"deploy_observability\", []):\n        k8s_yaml(read_file(\"./.tiltbuild/yaml/prometheus.observability.yaml\"), allow_duplicates = True)\n        k8s_resource(workload = \"prometheus-server\", new_name = \"prometheus\", port_forwards = \"9090\", extra_pod_selectors = [{\"app\": \"prometheus\"}], labels = [\"observability\"], objects = [\"prometheus-server:serviceaccount\"])\n\n    if \"kube-state-metrics\" in settings.get(\"deploy_observability\", []):\n        k8s_yaml(read_file(\"./.tiltbuild/yaml/kube-state-metrics.observability.yaml\"), allow_duplicates = True)\n        k8s_resource(workload = \"kube-state-metrics\", new_name = \"kube-state-metrics\", extra_pod_selectors = [{\"app\": \"kube-state-metrics\"}], labels = [\"observability\"], objects = [\"kube-state-metrics:serviceaccount\"])\n\n    if \"parca\" in settings.get(\"deploy_observability\", []):\n        k8s_yaml(read_file(\"./.tiltbuild/yaml/parca.observability.yaml\"), allow_duplicates = True)\n        k8s_resource(workload = \"parca\", new_name = \"parca\", port_forwards = \"7070\", extra_pod_selectors = [{\"app\": \"parca\"}], labels = [\"observability\"], objects = [\"parca:serviceaccount\"])\n\n    if \"metrics-server\" in settings.get(\"deploy_observability\", []):\n        k8s_yaml(read_file(\"./.tiltbuild/yaml/metrics-server.observability.yaml\"), allow_duplicates = True)\n        k8s_resource(workload = \"metrics-server\", new_name = \"metrics-server\", extra_pod_selectors = [{\"app\": \"metrics-server\"}], labels = [\"observability\"], objects = [\"metrics-server:serviceaccount\"])\n\n    if \"visualizer\" in settings.get(\"deploy_observability\", []):\n        k8s_yaml(read_file(\"./.tiltbuild/yaml/visualizer.observability.yaml\"), allow_duplicates = True)\n        k8s_resource(\n            workload = \"capi-visualizer\",\n            new_name = \"visualizer\",\n            port_forwards = [port_forward(local_port = 8000, container_port = 8081, name = \"View visualization\")],\n            labels = [\"observability\"],\n            objects = [\"capi-visualizer:serviceaccount\"],\n        )\n\ndef deploy_additional_kustomizations():\n    for name in settings.get(\"additional_kustomizations\", []):\n        yaml = read_file(\"./.tiltbuild/yaml/{}.kustomization.yaml\".format(name))\n        k8s_yaml(yaml)\n        objs = decode_yaml_stream(yaml)\n        print(\"objects\")\n        print(find_all_objects_names(objs))\n        k8s_resource(\n            new_name = name,\n            objects = find_all_objects_names(objs),\n            labels = [\"kustomization\"],\n        )\n\ndef prepare_all():\n    tools_arg = \"--tools kustomize,envsubst,clusterctl \"\n    tilt_settings_file_arg = \"--tilt-settings-file \" + tilt_file\n\n    cmd = \"make -B tilt-prepare && ./hack/tools/bin/tilt-prepare {tools_arg}{tilt_settings_file_arg}\".format(\n        tools_arg = tools_arg,\n        tilt_settings_file_arg = tilt_settings_file_arg,\n    )\n    local(cmd, env = settings.get(\"kustomize_substitutions\", {}))\n\n# create cluster template resources from cluster-template files in the templates directory\ndef cluster_templates():\n    substitutions = settings.get(\"kustomize_substitutions\", {})\n\n    # Ensure we have default values for a small set of well-known variables\n    substitutions[\"NAMESPACE\"] = substitutions.get(\"NAMESPACE\", \"default\")\n    substitutions[\"KUBERNETES_VERSION\"] = substitutions.get(\"KUBERNETES_VERSION\", kubernetes_version)\n    substitutions[\"CONTROL_PLANE_MACHINE_COUNT\"] = substitutions.get(\"CONTROL_PLANE_MACHINE_COUNT\", \"1\")\n    substitutions[\"WORKER_MACHINE_COUNT\"] = substitutions.get(\"WORKER_MACHINE_COUNT\", \"1\")\n\n    template_dirs = settings.get(\"template_dirs\", {\n        \"docker\": [\"./test/infrastructure/docker/templates\"],\n        \"in-memory\": [\"./test/infrastructure/inmemory/templates\"],\n    })\n\n    for provider, provider_dirs in template_dirs.items():\n        if provider not in get_providers():\n            continue\n\n        p = providers.get(provider)\n        label = p.get(\"label\", provider)\n\n        for template_dir in provider_dirs:\n            template_list = [filename for filename in listdir(template_dir) if os.path.basename(filename).endswith(\"yaml\")]\n            for filename in template_list:\n                deploy_templates(filename, label, substitutions)\n\ndef deploy_templates(filename, label, substitutions):\n    # validate filename exists\n    if not os.path.exists(filename):\n        fail(filename + \" not found\")\n\n    basename = os.path.basename(filename)\n    if basename.endswith(\".yaml\"):\n        if basename.startswith(\"clusterclass-\"):\n            clusterclass_name = basename.replace(\"clusterclass-\", \"\").replace(\".yaml\", \"\")\n            deploy_clusterclass(clusterclass_name, label, filename, substitutions)\n        elif basename.startswith(\"cluster-template-\"):\n            template_name = basename.replace(\"cluster-template-\", \"\").replace(\".yaml\", \"\")\n            deploy_cluster_template(template_name, label, filename, substitutions)\n        elif basename == \"cluster-template.yaml\":\n            template_name = \"default\"\n            deploy_cluster_template(template_name, label, filename, substitutions)\n\ndef deploy_clusterclass(clusterclass_name, label, filename, substitutions):\n    apply_clusterclass_cmd = \"cat \" + filename + \" | \" + envsubst_cmd + \" | \" + kubectl_cmd + \" apply --namespace=$NAMESPACE -f - && echo \\\"ClusterClass created from\\'\" + filename + \"\\', don't forget to delete\\n\\\"\"\n    delete_clusterclass_cmd = kubectl_cmd + \" --namespace=$NAMESPACE delete clusterclass \" + clusterclass_name + ' --ignore-not-found=true; echo \"\\n\"'\n\n    local_resource(\n        name = clusterclass_name,\n        cmd = [\"bash\", \"-c\", apply_clusterclass_cmd],\n        env = substitutions,\n        auto_init = False,\n        trigger_mode = TRIGGER_MODE_MANUAL,\n        labels = [label + \".clusterclasses\"],\n    )\n\n    cmd_button(\n        clusterclass_name + \":apply\",\n        argv = [\"bash\", \"-c\", apply_clusterclass_cmd],\n        env = dictonary_to_list_of_string(substitutions),\n        resource = clusterclass_name,\n        icon_name = \"note_add\",\n        text = \"Apply `\" + clusterclass_name + \"` ClusterClass\",\n        inputs = [\n            text_input(\"NAMESPACE\", default = substitutions.get(\"NAMESPACE\")),\n        ],\n    )\n\n    cmd_button(\n        clusterclass_name + \":delete\",\n        argv = [\"bash\", \"-c\", delete_clusterclass_cmd],\n        env = dictonary_to_list_of_string(substitutions),\n        resource = clusterclass_name,\n        icon_name = \"delete_forever\",\n        text = \"Delete `\" + clusterclass_name + \"` ClusterClass\",\n        inputs = [\n            text_input(\"NAMESPACE\", default = substitutions.get(\"NAMESPACE\")),\n        ],\n    )\n\ndef deploy_cluster_template(template_name, label, filename, substitutions):\n    apply_cluster_template_cmd = \"CLUSTER_NAME=\" + template_name + \"-$RANDOM;\" + clusterctl_cmd + \" generate cluster -n $NAMESPACE $CLUSTER_NAME --from \" + filename + \" | \" + kubectl_cmd + \" apply -f - && echo \\\"Cluster '$CLUSTER_NAME' created, don't forget to delete\\n\\\"\"\n    delete_clusters_cmd = 'DELETED=$(echo \"$(bash -c \"' + kubectl_cmd + ' --namespace=$NAMESPACE get clusters -A --no-headers -o custom-columns=\":metadata.name\"\")\" | grep -E \"^' + template_name + '-[[:digit:]]{1,5}$\"); if [ -z \"$DELETED\" ]; then echo \"Nothing to delete for cluster template ' + template_name + '\"; else echo \"Deleting clusters:\\n$DELETED\\n\"; echo $DELETED | xargs -L1 ' + kubectl_cmd + ' delete cluster; fi; echo \"\\n\"'\n\n    local_resource(\n        name = template_name,\n        cmd = [\"bash\", \"-c\", apply_cluster_template_cmd],\n        env = substitutions,\n        auto_init = False,\n        trigger_mode = TRIGGER_MODE_MANUAL,\n        labels = [label + \".templates\"],\n    )\n\n    cmd_button(\n        template_name + \":apply\",\n        argv = [\"bash\", \"-c\", apply_cluster_template_cmd],\n        env = dictonary_to_list_of_string(substitutions),\n        resource = template_name,\n        icon_name = \"add_box\",\n        text = \"Create `\" + template_name + \"` cluster\",\n        inputs = [\n            text_input(\"NAMESPACE\", default = substitutions.get(\"NAMESPACE\")),\n            text_input(\"KUBERNETES_VERSION\", default = substitutions.get(\"KUBERNETES_VERSION\")),\n            text_input(\"CONTROL_PLANE_MACHINE_COUNT\", default = substitutions.get(\"CONTROL_PLANE_MACHINE_COUNT\")),\n            text_input(\"WORKER_MACHINE_COUNT\", default = substitutions.get(\"WORKER_MACHINE_COUNT\")),\n        ],\n    )\n\n    cmd_button(\n        template_name + \":delete\",\n        argv = [\"bash\", \"-c\", delete_clusters_cmd],\n        env = dictonary_to_list_of_string(substitutions),\n        resource = template_name,\n        icon_name = \"delete_forever\",\n        text = \"Delete `\" + template_name + \"` clusters\",\n        inputs = [\n            text_input(\"NAMESPACE\", default = substitutions.get(\"NAMESPACE\")),\n        ],\n    )\n\n    cmd_button(\n        template_name + \":delete-all\",\n        argv = [\"bash\", \"-c\", kubectl_cmd + \" delete clusters --all --wait=false\"],\n        env = dictonary_to_list_of_string(substitutions),\n        resource = template_name,\n        icon_name = \"delete_sweep\",\n        text = \"Delete all workload clusters\",\n    )\n\n# A function to convert dictonary to list of strings in a format of \"name=value\"\ndef dictonary_to_list_of_string(substitutions):\n    substitutions_list = []\n    for name, value in substitutions.items():\n        substitutions_list.append(name + \"=\" + value)\n    return substitutions_list\n\n##############################\n# Actual work happens here\n##############################\n\ninclude_user_tilt_files()\n\nload_provider_tiltfiles()\n\nprepare_all()\n\ndeploy_provider_crds()\n\ndeploy_observability()\n\ndeploy_additional_kustomizations()\n\nenable_providers()\n\ncluster_templates()\n"
        },
        {
          "name": "api",
          "type": "tree",
          "content": null
        },
        {
          "name": "bootstrap",
          "type": "tree",
          "content": null
        },
        {
          "name": "cloudbuild-nightly.yaml",
          "type": "blob",
          "size": 0.7685546875,
          "content": "# See https://cloud.google.com/cloud-build/docs/build-config\n# See https://console.cloud.google.com/gcr/images/k8s-staging-test-infra/global/gcb-docker-gcloud\ntimeout: 2700s\noptions:\n  substitution_option: ALLOW_LOOSE\n  machineType: 'E2_HIGHCPU_8'\nsteps:\n  - name: 'gcr.io/k8s-staging-test-infra/gcb-docker-gcloud@sha256:de53ba7cd20326776a00adb065430a8bb51beaf24876ffcbd4e8f71b74dbc22d' # v20240210-29014a6e3a\n    entrypoint: make\n    env:\n    - DOCKER_CLI_EXPERIMENTAL=enabled\n    - TAG=$_GIT_TAG\n    - PULL_BASE_REF=$_PULL_BASE_REF\n    - DOCKER_BUILDKIT=1\n    args:\n    - release-staging-nightly\nsubstitutions:\n  # _GIT_TAG will be filled with a git-based tag for the image, of the form vYYYYMMDD-hash, and\n  # can be used as a substitution\n  _GIT_TAG: '12345'\n  _PULL_BASE_REF: 'dev'\n"
        },
        {
          "name": "cloudbuild.yaml",
          "type": "blob",
          "size": 0.7744140625,
          "content": "# See https://cloud.google.com/cloud-build/docs/build-config\n# See https://console.cloud.google.com/gcr/images/k8s-staging-test-infra/global/gcb-docker-gcloud\ntimeout: 2700s\noptions:\n  substitution_option: ALLOW_LOOSE\n  machineType: 'E2_HIGHCPU_8'\nsteps:\n  - name: 'gcr.io/k8s-staging-test-infra/gcb-docker-gcloud@sha256:de53ba7cd20326776a00adb065430a8bb51beaf24876ffcbd4e8f71b74dbc22d' # v20240210-29014a6e3a\n    entrypoint: make\n    env:\n    - DOCKER_CLI_EXPERIMENTAL=enabled\n    - TAG=$_GIT_TAG\n    - PULL_BASE_REF=$_PULL_BASE_REF\n    - DOCKER_BUILDKIT=1\n    args: ['release-staging', '-j', '8', '-O']\nsubstitutions:\n  # _GIT_TAG will be filled with a git-based tag for the image, of the form vYYYYMMDD-hash, and\n  # can be used as a substitution\n  _GIT_TAG: '12345'\n  _PULL_BASE_REF: 'dev'"
        },
        {
          "name": "cmd",
          "type": "tree",
          "content": null
        },
        {
          "name": "code-of-conduct.md",
          "type": "blob",
          "size": 0.14453125,
          "content": "# Kubernetes Community Code of Conduct\n\nPlease refer to our [Kubernetes Community Code of Conduct](https://git.k8s.io/community/code-of-conduct.md)\n"
        },
        {
          "name": "config",
          "type": "tree",
          "content": null
        },
        {
          "name": "controllers",
          "type": "tree",
          "content": null
        },
        {
          "name": "controlplane",
          "type": "tree",
          "content": null
        },
        {
          "name": "dev",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "errors",
          "type": "tree",
          "content": null
        },
        {
          "name": "exp",
          "type": "tree",
          "content": null
        },
        {
          "name": "feature",
          "type": "tree",
          "content": null
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 7.111328125,
          "content": "module sigs.k8s.io/cluster-api\n\ngo 1.22.0\n\nrequire (\n\tgithub.com/MakeNowJust/heredoc v1.0.0\n\tgithub.com/Masterminds/sprig/v3 v3.3.0\n\tgithub.com/adrg/xdg v0.5.3\n\tgithub.com/blang/semver/v4 v4.0.0\n\tgithub.com/coredns/corefile-migration v1.0.24\n\tgithub.com/davecgh/go-spew v1.1.2-0.20180830191138-d8f796af33cc\n\tgithub.com/distribution/reference v0.6.0\n\tgithub.com/drone/envsubst/v2 v2.0.0-20210730161058-179042472c46\n\tgithub.com/evanphx/json-patch/v5 v5.9.0\n\tgithub.com/fatih/color v1.18.0\n\tgithub.com/flatcar/container-linux-config-transpiler v0.9.4\n\tgithub.com/flatcar/ignition v0.36.2\n\tgithub.com/go-logr/logr v1.4.2\n\tgithub.com/gobuffalo/flect v1.0.3\n\t// Note: This must be kept in sync with the version used by k8s.io.\n\tgithub.com/google/cel-go v0.20.1\n\tgithub.com/google/go-cmp v0.6.0\n\tgithub.com/google/go-github/v53 v53.2.0\n\tgithub.com/google/gofuzz v1.2.0\n\tgithub.com/olekukonko/tablewriter v0.0.5\n\tgithub.com/onsi/ginkgo/v2 v2.22.2\n\tgithub.com/onsi/gomega v1.36.2\n\tgithub.com/pkg/errors v0.9.1\n\tgithub.com/prometheus/client_golang v1.19.1\n\tgithub.com/spf13/cobra v1.8.1\n\tgithub.com/spf13/pflag v1.0.5\n\tgithub.com/spf13/viper v1.19.0\n\tgithub.com/valyala/fastjson v1.6.4\n\tgo.etcd.io/etcd/api/v3 v3.5.17\n\tgo.etcd.io/etcd/client/v3 v3.5.17\n\tgolang.org/x/exp v0.0.0-20240719175910-8a7402abbf56\n\tgolang.org/x/oauth2 v0.24.0\n\tgolang.org/x/text v0.21.0\n\tgomodules.xyz/jsonpatch/v2 v2.4.0\n\tgoogle.golang.org/grpc v1.65.1\n\tk8s.io/api v0.31.4\n\tk8s.io/apiextensions-apiserver v0.31.4\n\tk8s.io/apimachinery v0.31.4\n\tk8s.io/apiserver v0.31.4\n\tk8s.io/client-go v0.31.4\n\tk8s.io/cluster-bootstrap v0.31.4\n\tk8s.io/component-base v0.31.4\n\tk8s.io/klog/v2 v2.130.1\n\tk8s.io/kube-openapi v0.0.0-20240228011516-70dd3763d340\n\tk8s.io/utils v0.0.0-20240711033017-18e509b52bc8\n\tsigs.k8s.io/controller-runtime v0.19.4\n\tsigs.k8s.io/yaml v1.4.0\n)\n\nrequire (\n\tdario.cat/mergo v1.0.1 // indirect\n\tgithub.com/Masterminds/goutils v1.1.1 // indirect\n\tgithub.com/Masterminds/semver/v3 v3.3.0 // indirect\n\tgithub.com/NYTimes/gziphandler v1.1.1 // indirect\n\tgithub.com/ProtonMail/go-crypto v0.0.0-20230217124315-7d5c6f04bbb8 // indirect\n\tgithub.com/ajeddeloh/go-json v0.0.0-20200220154158-5ae607161559 // indirect\n\tgithub.com/alecthomas/units v0.0.0-20211218093645-b94a6e3cc137 // indirect\n\tgithub.com/antlr4-go/antlr/v4 v4.13.0 // indirect\n\tgithub.com/asaskevich/govalidator v0.0.0-20190424111038-f61b66f89f4a // indirect\n\tgithub.com/beorn7/perks v1.0.1 // indirect\n\tgithub.com/cenkalti/backoff/v4 v4.3.0 // indirect\n\tgithub.com/cespare/xxhash/v2 v2.3.0 // indirect\n\tgithub.com/cloudflare/circl v1.3.7 // indirect\n\tgithub.com/coredns/caddy v1.1.1 // indirect\n\tgithub.com/coreos/go-semver v0.3.1 // indirect\n\tgithub.com/coreos/go-systemd v0.0.0-20191104093116-d3cd4ed1dbcf // indirect\n\tgithub.com/coreos/go-systemd/v22 v22.5.0 // indirect\n\tgithub.com/emicklei/go-restful/v3 v3.12.1 // indirect\n\tgithub.com/evanphx/json-patch v5.7.0+incompatible // indirect\n\tgithub.com/felixge/httpsnoop v1.0.4 // indirect\n\tgithub.com/fsnotify/fsnotify v1.7.0 // indirect\n\tgithub.com/fxamacker/cbor/v2 v2.7.0 // indirect\n\tgithub.com/go-logr/stdr v1.2.2 // indirect\n\tgithub.com/go-logr/zapr v1.3.0 // indirect\n\tgithub.com/go-openapi/jsonpointer v0.19.6 // indirect\n\tgithub.com/go-openapi/jsonreference v0.20.2 // indirect\n\tgithub.com/go-openapi/swag v0.22.4 // indirect\n\tgithub.com/go-task/slim-sprig/v3 v3.0.0 // indirect\n\tgithub.com/gogo/protobuf v1.3.2 // indirect\n\tgithub.com/golang/groupcache v0.0.0-20210331224755-41bb18bfe9da // indirect\n\tgithub.com/golang/protobuf v1.5.4 // indirect\n\tgithub.com/google/gnostic-models v0.6.8 // indirect\n\tgithub.com/google/go-querystring v1.1.0 // indirect\n\tgithub.com/google/pprof v0.0.0-20241210010833-40e02aabc2ad // indirect\n\tgithub.com/google/uuid v1.6.0 // indirect\n\tgithub.com/gorilla/websocket v1.5.0 // indirect\n\tgithub.com/grpc-ecosystem/grpc-gateway/v2 v2.20.0 // indirect\n\tgithub.com/hashicorp/hcl v1.0.0 // indirect\n\tgithub.com/huandu/xstrings v1.5.0 // indirect\n\tgithub.com/imdario/mergo v0.3.13 // indirect\n\tgithub.com/inconshreveable/mousetrap v1.1.0 // indirect\n\tgithub.com/josharian/intern v1.0.0 // indirect\n\tgithub.com/json-iterator/go v1.1.12 // indirect\n\tgithub.com/magiconair/properties v1.8.7 // indirect\n\tgithub.com/mailru/easyjson v0.7.7 // indirect\n\tgithub.com/mattn/go-colorable v0.1.13 // indirect\n\tgithub.com/mattn/go-isatty v0.0.20 // indirect\n\tgithub.com/mattn/go-runewidth v0.0.14 // indirect\n\tgithub.com/mitchellh/copystructure v1.2.0 // indirect\n\tgithub.com/mitchellh/mapstructure v1.5.0 // indirect\n\tgithub.com/mitchellh/reflectwalk v1.0.2 // indirect\n\tgithub.com/moby/spdystream v0.4.0 // indirect\n\tgithub.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd // indirect\n\tgithub.com/modern-go/reflect2 v1.0.2 // indirect\n\tgithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 // indirect\n\tgithub.com/mxk/go-flowrate v0.0.0-20140419014527-cca7078d478f // indirect\n\tgithub.com/opencontainers/go-digest v1.0.0 // indirect\n\tgithub.com/pelletier/go-toml/v2 v2.2.2 // indirect\n\tgithub.com/prometheus/client_model v0.6.1 // indirect\n\tgithub.com/prometheus/common v0.55.0 // indirect\n\tgithub.com/prometheus/procfs v0.15.1 // indirect\n\tgithub.com/rivo/uniseg v0.4.2 // indirect\n\tgithub.com/sagikazarmark/locafero v0.4.0 // indirect\n\tgithub.com/sagikazarmark/slog-shim v0.1.0 // indirect\n\tgithub.com/shopspring/decimal v1.4.0 // indirect\n\tgithub.com/sourcegraph/conc v0.3.0 // indirect\n\tgithub.com/spf13/afero v1.11.0 // indirect\n\tgithub.com/spf13/cast v1.7.0 // indirect\n\tgithub.com/stoewer/go-strcase v1.2.0 // indirect\n\tgithub.com/subosito/gotenv v1.6.0 // indirect\n\tgithub.com/vincent-petithory/dataurl v1.0.0 // indirect\n\tgithub.com/x448/float16 v0.8.4 // indirect\n\tgo.etcd.io/etcd/client/pkg/v3 v3.5.17 // indirect\n\tgo.opentelemetry.io/contrib/instrumentation/net/http/otelhttp v0.53.0 // indirect\n\tgo.opentelemetry.io/otel v1.28.0 // indirect\n\tgo.opentelemetry.io/otel/exporters/otlp/otlptrace v1.28.0 // indirect\n\tgo.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc v1.27.0 // indirect\n\tgo.opentelemetry.io/otel/metric v1.28.0 // indirect\n\tgo.opentelemetry.io/otel/sdk v1.28.0 // indirect\n\tgo.opentelemetry.io/otel/trace v1.28.0 // indirect\n\tgo.opentelemetry.io/proto/otlp v1.3.1 // indirect\n\tgo.uber.org/multierr v1.11.0 // indirect\n\tgo.uber.org/zap v1.27.0 // indirect\n\tgo4.org v0.0.0-20201209231011-d4a079459e60 // indirect\n\tgolang.org/x/crypto v0.31.0 // indirect\n\tgolang.org/x/net v0.33.0 // indirect\n\tgolang.org/x/sync v0.10.0 // indirect\n\tgolang.org/x/sys v0.28.0 // indirect\n\tgolang.org/x/term v0.27.0 // indirect\n\tgolang.org/x/time v0.5.0 // indirect\n\tgolang.org/x/tools v0.28.0 // indirect\n\tgoogle.golang.org/genproto/googleapis/api v0.0.0-20240528184218-531527333157 // indirect\n\tgoogle.golang.org/genproto/googleapis/rpc v0.0.0-20240701130421-f6361c86f094 // indirect\n\tgoogle.golang.org/protobuf v1.36.1 // indirect\n\tgopkg.in/evanphx/json-patch.v4 v4.12.0 // indirect\n\tgopkg.in/inf.v0 v0.9.1 // indirect\n\tgopkg.in/ini.v1 v1.67.0 // indirect\n\tgopkg.in/yaml.v2 v2.4.0 // indirect\n\tgopkg.in/yaml.v3 v3.0.1 // indirect\n\tsigs.k8s.io/apiserver-network-proxy/konnectivity-client v0.30.3 // indirect\n\tsigs.k8s.io/json v0.0.0-20221116044647-bc3834ca7abd // indirect\n\tsigs.k8s.io/structured-merge-diff/v4 v4.4.1 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 60.322265625,
          "content": "cloud.google.com/go v0.26.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=\ncloud.google.com/go v0.34.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=\ncloud.google.com/go v0.38.0/go.mod h1:990N+gfupTy94rShfmMCWGDn0LpTmnzTp2qbd1dvSRU=\ncloud.google.com/go v0.44.1/go.mod h1:iSa0KzasP4Uvy3f1mN/7PiObzGgflwredwwASm/v6AU=\ncloud.google.com/go v0.44.2/go.mod h1:60680Gw3Yr4ikxnPRS/oxxkBccT6SA1yMk63TGekxKY=\ncloud.google.com/go v0.45.1/go.mod h1:RpBamKRgapWJb87xiFSdk4g1CME7QZg3uwTez+TSTjc=\ncloud.google.com/go v0.46.3/go.mod h1:a6bKKbmY7er1mI7TEI4lsAkts/mkhTSZK8w33B4RAg0=\ncloud.google.com/go v0.50.0/go.mod h1:r9sluTvynVuxRIOHXQEHMFffphuXHOMZMycpNR5e6To=\ncloud.google.com/go v0.53.0/go.mod h1:fp/UouUEsRkN6ryDKNW/Upv/JBKnv6WDthjR6+vze6M=\ncloud.google.com/go/bigquery v1.0.1/go.mod h1:i/xbL2UlR5RvWAURpBYZTtm/cXjCha9lbfbpx4poX+o=\ncloud.google.com/go/bigquery v1.3.0/go.mod h1:PjpwJnslEMmckchkHFfq+HTD2DmtT67aNFKH1/VBDHE=\ncloud.google.com/go/datastore v1.0.0/go.mod h1:LXYbyblFSglQ5pkeyhO+Qmw7ukd3C+pD7TKLgZqpHYE=\ncloud.google.com/go/pubsub v1.0.1/go.mod h1:R0Gpsv3s54REJCy4fxDixWD93lHJMoZTyQ2kNxGRt3I=\ncloud.google.com/go/pubsub v1.1.0/go.mod h1:EwwdRX2sKPjnvnqCa270oGRyludottCI76h+R3AArQw=\ncloud.google.com/go/storage v1.0.0/go.mod h1:IhtSnM/ZTZV8YYJWCY8RULGVqBDmpoyjwiyrjsg+URw=\ncloud.google.com/go/storage v1.5.0/go.mod h1:tpKbwo567HUNpVclU5sGELwQWBDZ8gh0ZeosJ0Rtdos=\ndario.cat/mergo v1.0.1 h1:Ra4+bf83h2ztPIQYNP99R6m+Y7KfnARDfID+a+vLl4s=\ndario.cat/mergo v1.0.1/go.mod h1:uNxQE+84aUszobStD9th8a29P2fMDhsBdgRYvZOxGmk=\ndmitri.shuralyov.com/gpu/mtl v0.0.0-20190408044501-666a987793e9/go.mod h1:H6x//7gZCb22OMCxBHrMx7a5I7Hp++hsVxbQ4BYO7hU=\ngithub.com/BurntSushi/toml v0.3.1/go.mod h1:xHWCNGjB5oqiDr8zfno3MHue2Ht5sIBksp03qcyfWMU=\ngithub.com/BurntSushi/xgb v0.0.0-20160522181843-27f122750802/go.mod h1:IVnqGOEym/WlBOVXweHU+Q+/VP0lqqI8lqeDx9IjBqo=\ngithub.com/MakeNowJust/heredoc v1.0.0 h1:cXCdzVdstXyiTqTvfqk9SDHpKNjxuom+DOlyEeQ4pzQ=\ngithub.com/MakeNowJust/heredoc v1.0.0/go.mod h1:mG5amYoWBHf8vpLOuehzbGGw0EHxpZZ6lCpQ4fNJ8LE=\ngithub.com/Masterminds/goutils v1.1.1 h1:5nUrii3FMTL5diU80unEVvNevw1nH4+ZV4DSLVJLSYI=\ngithub.com/Masterminds/goutils v1.1.1/go.mod h1:8cTjp+g8YejhMuvIA5y2vz3BpJxksy863GQaJW2MFNU=\ngithub.com/Masterminds/semver/v3 v3.3.0 h1:B8LGeaivUe71a5qox1ICM/JLl0NqZSW5CHyL+hmvYS0=\ngithub.com/Masterminds/semver/v3 v3.3.0/go.mod h1:4V+yj/TJE1HU9XfppCwVMZq3I84lprf4nC11bSS5beM=\ngithub.com/Masterminds/sprig/v3 v3.3.0 h1:mQh0Yrg1XPo6vjYXgtf5OtijNAKJRNcTdOOGZe3tPhs=\ngithub.com/Masterminds/sprig/v3 v3.3.0/go.mod h1:Zy1iXRYNqNLUolqCpL4uhk6SHUMAOSCzdgBfDb35Lz0=\ngithub.com/NYTimes/gziphandler v1.1.1 h1:ZUDjpQae29j0ryrS0u/B8HZfJBtBQHjqw2rQ2cqUQ3I=\ngithub.com/NYTimes/gziphandler v1.1.1/go.mod h1:n/CVRwUEOgIxrgPvAQhUUr9oeUtvrhMomdKFjzJNB0c=\ngithub.com/ProtonMail/go-crypto v0.0.0-20230217124315-7d5c6f04bbb8 h1:wPbRQzjjwFc0ih8puEVAOFGELsn1zoIIYdxvML7mDxA=\ngithub.com/ProtonMail/go-crypto v0.0.0-20230217124315-7d5c6f04bbb8/go.mod h1:I0gYDMZ6Z5GRU7l58bNFSkPTFN6Yl12dsUlAZ8xy98g=\ngithub.com/adrg/xdg v0.5.3 h1:xRnxJXne7+oWDatRhR1JLnvuccuIeCoBu2rtuLqQB78=\ngithub.com/adrg/xdg v0.5.3/go.mod h1:nlTsY+NNiCBGCK2tpm09vRqfVzrc2fLmXGpBLF0zlTQ=\ngithub.com/ajeddeloh/go-json v0.0.0-20160803184958-73d058cf8437/go.mod h1:otnto4/Icqn88WCcM4bhIJNSgsh9VLBuspyyCfvof9c=\ngithub.com/ajeddeloh/go-json v0.0.0-20200220154158-5ae607161559 h1:4SPQljF/GJ8Q+QlCWMWxRBepub4DresnOm4eI2ebFGc=\ngithub.com/ajeddeloh/go-json v0.0.0-20200220154158-5ae607161559/go.mod h1:otnto4/Icqn88WCcM4bhIJNSgsh9VLBuspyyCfvof9c=\ngithub.com/alecthomas/units v0.0.0-20210208195552-ff826a37aa15/go.mod h1:OMCwj8VM1Kc9e19TLln2VL61YJF0x1XFtfdL4JdbSyE=\ngithub.com/alecthomas/units v0.0.0-20211218093645-b94a6e3cc137 h1:s6gZFSlWYmbqAuRjVTiNNhvNRfY2Wxp9nhfyel4rklc=\ngithub.com/alecthomas/units v0.0.0-20211218093645-b94a6e3cc137/go.mod h1:OMCwj8VM1Kc9e19TLln2VL61YJF0x1XFtfdL4JdbSyE=\ngithub.com/antlr4-go/antlr/v4 v4.13.0 h1:lxCg3LAv+EUK6t1i0y1V6/SLeUi0eKEKdhQAlS8TVTI=\ngithub.com/antlr4-go/antlr/v4 v4.13.0/go.mod h1:pfChB/xh/Unjila75QW7+VU4TSnWnnk9UTnmpPaOR2g=\ngithub.com/armon/go-socks5 v0.0.0-20160902184237-e75332964ef5 h1:0CwZNZbxp69SHPdPJAN/hZIm0C4OItdklCFmMRWYpio=\ngithub.com/armon/go-socks5 v0.0.0-20160902184237-e75332964ef5/go.mod h1:wHh0iHkYZB8zMSxRWpUBQtwG5a7fFgvEO+odwuTv2gs=\ngithub.com/asaskevich/govalidator v0.0.0-20190424111038-f61b66f89f4a h1:idn718Q4B6AGu/h5Sxe66HYVdqdGu2l9Iebqhi/AEoA=\ngithub.com/asaskevich/govalidator v0.0.0-20190424111038-f61b66f89f4a/go.mod h1:lB+ZfQJz7igIIfQNfa7Ml4HSf2uFQQRzpGGRXenZAgY=\ngithub.com/aws/aws-sdk-go v1.8.39/go.mod h1:ZRmQr0FajVIyZ4ZzBYKG5P3ZqPz9IHG41ZoMu1ADI3k=\ngithub.com/beorn7/perks v1.0.1 h1:VlbKKnNfV8bJzeqoa4cOKqO6bYr3WgKZxO8Z16+hsOM=\ngithub.com/beorn7/perks v1.0.1/go.mod h1:G2ZrVWU2WbWT9wwq4/hrbKbnv/1ERSJQ0ibhJ6rlkpw=\ngithub.com/blang/semver/v4 v4.0.0 h1:1PFHFE6yCCTv8C1TeyNNarDzntLi7wMI5i/pzqYIsAM=\ngithub.com/blang/semver/v4 v4.0.0/go.mod h1:IbckMUScFkM3pff0VJDNKRiT6TG/YpiHIM2yvyW5YoQ=\ngithub.com/bwesterb/go-ristretto v1.2.0/go.mod h1:fUIoIZaG73pV5biE2Blr2xEzDoMj7NFEuV9ekS419A0=\ngithub.com/cenkalti/backoff/v4 v4.3.0 h1:MyRJ/UdXutAwSAT+s3wNd7MfTIcy71VQueUuFK343L8=\ngithub.com/cenkalti/backoff/v4 v4.3.0/go.mod h1:Y3VNntkOUPxTVeUxJ/G5vcM//AlwfmyYozVcomhLiZE=\ngithub.com/census-instrumentation/opencensus-proto v0.2.1/go.mod h1:f6KPmirojxKA12rnyqOA5BBL4O983OfeGPqjHWSTneU=\ngithub.com/cespare/xxhash/v2 v2.3.0 h1:UL815xU9SqsFlibzuggzjXhog7bL6oX9BbNZnL2UFvs=\ngithub.com/cespare/xxhash/v2 v2.3.0/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/chzyer/logex v1.1.10/go.mod h1:+Ywpsq7O8HXn0nuIou7OrIPyXbp3wmkHB+jjWRnGsAI=\ngithub.com/chzyer/readline v0.0.0-20180603132655-2972be24d48e/go.mod h1:nSuG5e5PlCu98SY8svDHJxuZscDgtXS6KTTbou5AhLI=\ngithub.com/chzyer/test v0.0.0-20180213035817-a1ea475d72b1/go.mod h1:Q3SI9o4m/ZMnBNeIyt5eFwwo7qiLfzFZmjNmxjkiQlU=\ngithub.com/client9/misspell v0.3.4/go.mod h1:qj6jICC3Q7zFZvVWo7KLAzC3yx5G7kyvSDkc90ppPyw=\ngithub.com/cloudflare/circl v1.1.0/go.mod h1:prBCrKB9DV4poKZY1l9zBXg2QJY7mvgRvtMxxK7fi4I=\ngithub.com/cloudflare/circl v1.3.7 h1:qlCDlTPz2n9fu58M0Nh1J/JzcFpfgkFHHX3O35r5vcU=\ngithub.com/cloudflare/circl v1.3.7/go.mod h1:sRTcRWXGLrKw6yIGJ+l7amYJFfAXbZG0kBSc8r4zxgA=\ngithub.com/coredns/caddy v1.1.1 h1:2eYKZT7i6yxIfGP3qLJoJ7HAsDJqYB+X68g4NYjSrE0=\ngithub.com/coredns/caddy v1.1.1/go.mod h1:A6ntJQlAWuQfFlsd9hvigKbo2WS0VUs2l1e2F+BawD4=\ngithub.com/coredns/corefile-migration v1.0.24 h1:NL/zRKijhJZLYlNnMr891DRv5jXgfd3Noons1M6oTpc=\ngithub.com/coredns/corefile-migration v1.0.24/go.mod h1:56DPqONc3njpVPsdilEnfijCwNGC3/kTJLl7i7SPavY=\ngithub.com/coreos/go-semver v0.1.0/go.mod h1:nnelYz7RCh+5ahJtPPxZlU+153eP4D4r3EedlOD2RNk=\ngithub.com/coreos/go-semver v0.3.0/go.mod h1:nnelYz7RCh+5ahJtPPxZlU+153eP4D4r3EedlOD2RNk=\ngithub.com/coreos/go-semver v0.3.1 h1:yi21YpKnrx1gt5R+la8n5WgS0kCrsPp33dmEyHReZr4=\ngithub.com/coreos/go-semver v0.3.1/go.mod h1:irMmmIw/7yzSRPWryHsK7EYSg09caPQL03VsM8rvUec=\ngithub.com/coreos/go-systemd v0.0.0-20181031085051-9002847aa142/go.mod h1:F5haX7vjVVG0kc13fIWeqUViNPyEJxv/OmvnBo0Yme4=\ngithub.com/coreos/go-systemd v0.0.0-20191104093116-d3cd4ed1dbcf h1:iW4rZ826su+pqaw19uhpSCzhj44qo35pNgKFGqzDKkU=\ngithub.com/coreos/go-systemd v0.0.0-20191104093116-d3cd4ed1dbcf/go.mod h1:F5haX7vjVVG0kc13fIWeqUViNPyEJxv/OmvnBo0Yme4=\ngithub.com/coreos/go-systemd/v22 v22.5.0 h1:RrqgGjYQKalulkV8NGVIfkXQf6YYmOyiJKk8iXXhfZs=\ngithub.com/coreos/go-systemd/v22 v22.5.0/go.mod h1:Y58oyj3AT4RCenI/lSvhwexgC+NSVTIJ3seZv2GcEnc=\ngithub.com/cpuguy83/go-md2man/v2 v2.0.4/go.mod h1:tgQtvFlXSQOSOSIRvRPT7W67SCa46tRHOmNcaadrF8o=\ngithub.com/creack/pty v1.1.9/go.mod h1:oKZEueFk5CKHvIhNR5MUki03XCEU+Q6VDXinZuGJ33E=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.2-0.20180830191138-d8f796af33cc h1:U9qPSI2PIWSS1VwoXQT9A3Wy9MM3WgvqSxFWenqJduM=\ngithub.com/davecgh/go-spew v1.1.2-0.20180830191138-d8f796af33cc/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/distribution/reference v0.6.0 h1:0IXCQ5g4/QMHHkarYzh5l+u8T3t73zM5QvfrDyIgxBk=\ngithub.com/distribution/reference v0.6.0/go.mod h1:BbU0aIcezP1/5jX/8MP0YiH4SdvB5Y4f/wlDRiLyi3E=\ngithub.com/drone/envsubst/v2 v2.0.0-20210730161058-179042472c46 h1:7QPwrLT79GlD5sizHf27aoY2RTvw62mO6x7mxkScNk0=\ngithub.com/drone/envsubst/v2 v2.0.0-20210730161058-179042472c46/go.mod h1:esf2rsHFNlZlxsqsZDojNBcnNs5REqIvRrWRHqX0vEU=\ngithub.com/dustin/go-humanize v1.0.1 h1:GzkhY7T5VNhEkwH0PVJgjz+fX1rhBrR7pRT3mDkpeCY=\ngithub.com/dustin/go-humanize v1.0.1/go.mod h1:Mu1zIs6XwVuF/gI1OepvI0qD18qycQx+mFykh5fBlto=\ngithub.com/emicklei/go-restful/v3 v3.12.1 h1:PJMDIM/ak7btuL8Ex0iYET9hxM3CI2sjZtzpL63nKAU=\ngithub.com/emicklei/go-restful/v3 v3.12.1/go.mod h1:6n3XBCmQQb25CM2LCACGz8ukIrRry+4bhvbpWn3mrbc=\ngithub.com/envoyproxy/go-control-plane v0.9.1-0.20191026205805-5f8ba28d4473/go.mod h1:YTl/9mNaCwkRvm6d1a2C3ymFceY/DCBVvsKhRF0iEA4=\ngithub.com/envoyproxy/protoc-gen-validate v0.1.0/go.mod h1:iSmxcyjqTsJpI2R4NaDN7+kN2VEUnK/pcBlmesArF7c=\ngithub.com/evanphx/json-patch v5.7.0+incompatible h1:vgGkfT/9f8zE6tvSCe74nfpAVDQ2tG6yudJd8LBksgI=\ngithub.com/evanphx/json-patch v5.7.0+incompatible/go.mod h1:50XU6AFN0ol/bzJsmQLiYLvXMP4fmwYFNcr97nuDLSk=\ngithub.com/evanphx/json-patch/v5 v5.9.0 h1:kcBlZQbplgElYIlo/n1hJbls2z/1awpXxpRi0/FOJfg=\ngithub.com/evanphx/json-patch/v5 v5.9.0/go.mod h1:VNkHZ/282BpEyt/tObQO8s5CMPmYYq14uClGH4abBuQ=\ngithub.com/fatih/color v1.18.0 h1:S8gINlzdQ840/4pfAwic/ZE0djQEH3wM94VfqLTZcOM=\ngithub.com/fatih/color v1.18.0/go.mod h1:4FelSpRwEGDpQ12mAdzqdOukCy4u8WUtOY6lkT/6HfU=\ngithub.com/felixge/httpsnoop v1.0.4 h1:NFTV2Zj1bL4mc9sqWACXbQFVBBg2W3GPvqp8/ESS2Wg=\ngithub.com/felixge/httpsnoop v1.0.4/go.mod h1:m8KPJKqk1gH5J9DgRY2ASl2lWCfGKXixSwevea8zH2U=\ngithub.com/flatcar/container-linux-config-transpiler v0.9.4 h1:yXQ0NB8PeNrKJPrZvbv5/DV63PNhTqt8vaf8YxmX/RA=\ngithub.com/flatcar/container-linux-config-transpiler v0.9.4/go.mod h1:LxanhPvXkWgHG9PrkT4rX/p7YhUPdDGGsUdkNpV3L5U=\ngithub.com/flatcar/ignition v0.36.2 h1:xGHgScUe0P4Fkprjqv7L2CE58emiQgP833OCCn9z2v4=\ngithub.com/flatcar/ignition v0.36.2/go.mod h1:uk1tpzLFRXus4RrvzgMI+IqmmB8a/RGFSBlI+tMTbbA=\ngithub.com/flynn/go-shlex v0.0.0-20150515145356-3f9db97f8568/go.mod h1:xEzjJPgXI435gkrCt3MPfRiAkVrwSbHsst4LCFVfpJc=\ngithub.com/frankban/quicktest v1.14.6 h1:7Xjx+VpznH+oBnejlPUj8oUpdxnVs4f8XU8WnHkI4W8=\ngithub.com/frankban/quicktest v1.14.6/go.mod h1:4ptaffx2x8+WTWXmUCuVU6aPUX1/Mz7zb5vbUoiM6w0=\ngithub.com/fsnotify/fsnotify v1.7.0 h1:8JEhPFa5W2WU7YfeZzPNqzMP6Lwt7L2715Ggo0nosvA=\ngithub.com/fsnotify/fsnotify v1.7.0/go.mod h1:40Bi/Hjc2AVfZrqy+aj+yEI+/bRxZnMJyTJwOpGvigM=\ngithub.com/fxamacker/cbor/v2 v2.7.0 h1:iM5WgngdRBanHcxugY4JySA0nk1wZorNOpTgCMedv5E=\ngithub.com/fxamacker/cbor/v2 v2.7.0/go.mod h1:pxXPTn3joSm21Gbwsv0w9OSA2y1HFR9qXEeXQVeNoDQ=\ngithub.com/go-gl/glfw v0.0.0-20190409004039-e6da0acd62b1/go.mod h1:vR7hzQXu2zJy9AVAgeJqvqgH9Q5CA+iKCZ2gyEVpxRU=\ngithub.com/go-gl/glfw/v3.3/glfw v0.0.0-20191125211704-12ad95a8df72/go.mod h1:tQ2UAYgL5IevRw8kRxooKSPJfGvJ9fJQFa0TUsXzTg8=\ngithub.com/go-ini/ini v1.25.4/go.mod h1:ByCAeIL28uOIIG0E3PJtZPDL8WnHpFKFOtgjp+3Ies8=\ngithub.com/go-logr/logr v1.2.2/go.mod h1:jdQByPbusPIv2/zmleS9BjJVeZ6kBagPoEUsqbVz/1A=\ngithub.com/go-logr/logr v1.4.2 h1:6pFjapn8bFcIbiKo3XT4j/BhANplGihG6tvd+8rYgrY=\ngithub.com/go-logr/logr v1.4.2/go.mod h1:9T104GzyrTigFIr8wt5mBrctHMim0Nb2HLGrmQ40KvY=\ngithub.com/go-logr/stdr v1.2.2 h1:hSWxHoqTgW2S2qGc0LTAI563KZ5YKYRhT3MFKZMbjag=\ngithub.com/go-logr/stdr v1.2.2/go.mod h1:mMo/vtBO5dYbehREoey6XUKy/eSumjCCveDpRre4VKE=\ngithub.com/go-logr/zapr v1.3.0 h1:XGdV8XW8zdwFiwOA2Dryh1gj2KRQyOOoNmBy4EplIcQ=\ngithub.com/go-logr/zapr v1.3.0/go.mod h1:YKepepNBd1u/oyhd/yQmtjVXmm9uML4IXUgMOwR8/Gg=\ngithub.com/go-openapi/jsonpointer v0.19.6 h1:eCs3fxoIi3Wh6vtgmLTOjdhSpiqphQ+DaPn38N2ZdrE=\ngithub.com/go-openapi/jsonpointer v0.19.6/go.mod h1:osyAmYz/mB/C3I+WsTTSgw1ONzaLJoLCyoi6/zppojs=\ngithub.com/go-openapi/jsonreference v0.20.2 h1:3sVjiK66+uXK/6oQ8xgcRKcFgQ5KXa2KvnJRumpMGbE=\ngithub.com/go-openapi/jsonreference v0.20.2/go.mod h1:Bl1zwGIM8/wsvqjsOQLJ/SH+En5Ap4rVB5KVcIDZG2k=\ngithub.com/go-openapi/swag v0.22.3/go.mod h1:UzaqsxGiab7freDnrUUra0MwWfN/q7tE4j+VcZ0yl14=\ngithub.com/go-openapi/swag v0.22.4 h1:QLMzNJnMGPRNDCbySlcj1x01tzU8/9LTTL9hZZZogBU=\ngithub.com/go-openapi/swag v0.22.4/go.mod h1:UzaqsxGiab7freDnrUUra0MwWfN/q7tE4j+VcZ0yl14=\ngithub.com/go-task/slim-sprig/v3 v3.0.0 h1:sUs3vkvUymDpBKi3qH1YSqBQk9+9D/8M2mN1vB6EwHI=\ngithub.com/go-task/slim-sprig/v3 v3.0.0/go.mod h1:W848ghGpv3Qj3dhTPRyJypKRiqCdHZiAzKg9hl15HA8=\ngithub.com/gobuffalo/flect v1.0.3 h1:xeWBM2nui+qnVvNM4S3foBhCAL2XgPU+a7FdpelbTq4=\ngithub.com/gobuffalo/flect v1.0.3/go.mod h1:A5msMlrHtLqh9umBSnvabjsMrCcCpAyzglnDvkbYKHs=\ngithub.com/godbus/dbus v0.0.0-20181025153459-66d97aec3384/go.mod h1:/YcGZj5zSblfDWMMoOzV4fas9FZnQYTkDnsGvmh2Grw=\ngithub.com/godbus/dbus/v5 v5.0.4/go.mod h1:xhWf0FNVPg57R7Z0UbKHbJfkEywrmjJnf7w5xrFpKfA=\ngithub.com/gogo/protobuf v1.3.2 h1:Ov1cvc58UF3b5XjBnZv7+opcTcQFZebYjWzi34vdm4Q=\ngithub.com/gogo/protobuf v1.3.2/go.mod h1:P1XiOD3dCwIKUDQYPy72D8LYyHL2YPYrpS2s69NZV8Q=\ngithub.com/golang-jwt/jwt/v4 v4.5.0 h1:7cYmW1XlMY7h7ii7UhUyChSgS5wUJEnm9uZVTGqOWzg=\ngithub.com/golang-jwt/jwt/v4 v4.5.0/go.mod h1:m21LjoU+eqJr34lmDMbreY2eSTRJ1cv77w39/MY0Ch0=\ngithub.com/golang/glog v0.0.0-20160126235308-23def4e6c14b/go.mod h1:SBH7ygxi8pfUlaOkMMuAQtPIUF8ecWP5IEl/CR7VP2Q=\ngithub.com/golang/groupcache v0.0.0-20190702054246-869f871628b6/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=\ngithub.com/golang/groupcache v0.0.0-20191227052852-215e87163ea7/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=\ngithub.com/golang/groupcache v0.0.0-20200121045136-8c9f03a8e57e/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=\ngithub.com/golang/groupcache v0.0.0-20210331224755-41bb18bfe9da h1:oI5xCqsCo564l8iNU+DwB5epxmsaqB+rhGL0m5jtYqE=\ngithub.com/golang/groupcache v0.0.0-20210331224755-41bb18bfe9da/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=\ngithub.com/golang/mock v1.1.1/go.mod h1:oTYuIxOrZwtPieC+H1uAHpcLFnEyAGVDL/k47Jfbm0A=\ngithub.com/golang/mock v1.2.0/go.mod h1:oTYuIxOrZwtPieC+H1uAHpcLFnEyAGVDL/k47Jfbm0A=\ngithub.com/golang/mock v1.3.1/go.mod h1:sBzyDLLjw3U8JLTeZvSv8jJB+tU5PVekmnlKIyFUx0Y=\ngithub.com/golang/mock v1.4.0/go.mod h1:UOMv5ysSaYNkG+OFQykRIcU/QvvxJf3p21QfJ2Bt3cw=\ngithub.com/golang/protobuf v1.2.0/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.1/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.2/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.3/go.mod h1:vzj43D7+SQXF/4pzW/hwtAqwc6iTitCiVSaWz5lYuqw=\ngithub.com/golang/protobuf v1.5.4 h1:i7eJL8qZTpSEXOPTxNKhASYpMn+8e5Q6AdndVa1dWek=\ngithub.com/golang/protobuf v1.5.4/go.mod h1:lnTiLA8Wa4RWRcIUkrtSVa5nRhsEGBg48fD6rSs7xps=\ngithub.com/google/btree v0.0.0-20180813153112-4030bb1f1f0c/go.mod h1:lNA+9X1NB3Zf8V7Ke586lFgjr2dZNuvo3lPJSGZ5JPQ=\ngithub.com/google/btree v1.0.0/go.mod h1:lNA+9X1NB3Zf8V7Ke586lFgjr2dZNuvo3lPJSGZ5JPQ=\ngithub.com/google/btree v1.0.1 h1:gK4Kx5IaGY9CD5sPJ36FHiBJ6ZXl0kilRiiCj+jdYp4=\ngithub.com/google/btree v1.0.1/go.mod h1:xXMiIv4Fb/0kKde4SpL7qlzvu5cMJDRkFDxJfI9uaxA=\ngithub.com/google/cel-go v0.20.1 h1:nDx9r8S3L4pE61eDdt8igGj8rf5kjYR3ILxWIpWNi84=\ngithub.com/google/cel-go v0.20.1/go.mod h1:kWcIzTsPX0zmQ+H3TirHstLLf9ep5QTsZBN9u4dOYLg=\ngithub.com/google/gnostic-models v0.6.8 h1:yo/ABAfM5IMRsS1VnXjTBvUb61tFIHozhlYvRgGre9I=\ngithub.com/google/gnostic-models v0.6.8/go.mod h1:5n7qKqH0f5wFt+aWF8CW6pZLLNOfYuF5OpfBSENuI8U=\ngithub.com/google/go-cmp v0.2.0/go.mod h1:oXzfMopK8JAjlY9xF4vHSVASa0yLyX7SntLO5aqRK0M=\ngithub.com/google/go-cmp v0.3.0/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.3.1/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.4.0/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.2/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.9/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/google/go-cmp v0.6.0 h1:ofyhxvXcZhMsU5ulbFiLKl/XBFqE1GSq7atu8tAmTRI=\ngithub.com/google/go-cmp v0.6.0/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/google/go-github/v53 v53.2.0 h1:wvz3FyF53v4BK+AsnvCmeNhf8AkTaeh2SoYu/XUvTtI=\ngithub.com/google/go-github/v53 v53.2.0/go.mod h1:XhFRObz+m/l+UCm9b7KSIC3lT3NWSXGt7mOsAWEloao=\ngithub.com/google/go-querystring v1.1.0 h1:AnCroh3fv4ZBgVIf1Iwtovgjaw/GiKJo8M8yD/fhyJ8=\ngithub.com/google/go-querystring v1.1.0/go.mod h1:Kcdr2DB4koayq7X8pmAG4sNG59So17icRSOU623lUBU=\ngithub.com/google/gofuzz v1.0.0/go.mod h1:dBl0BpW6vV/+mYPU4Po3pmUjxk6FQPldtuIdl/M65Eg=\ngithub.com/google/gofuzz v1.2.0 h1:xRy4A+RhZaiKjJ1bPfwQ8sedCA+YS2YcCHW6ec7JMi0=\ngithub.com/google/gofuzz v1.2.0/go.mod h1:dBl0BpW6vV/+mYPU4Po3pmUjxk6FQPldtuIdl/M65Eg=\ngithub.com/google/martian v2.1.0+incompatible/go.mod h1:9I4somxYTbIHy5NJKHRl3wXiIaQGbYVAs8BPL6v8lEs=\ngithub.com/google/pprof v0.0.0-20181206194817-3ea8567a2e57/go.mod h1:zfwlbNMJ+OItoe0UupaVj+oy1omPYYDuagoSzA8v9mc=\ngithub.com/google/pprof v0.0.0-20190515194954-54271f7e092f/go.mod h1:zfwlbNMJ+OItoe0UupaVj+oy1omPYYDuagoSzA8v9mc=\ngithub.com/google/pprof v0.0.0-20200212024743-f11f1df84d12/go.mod h1:ZgVRPoUq/hfqzAqh7sHMqb3I9Rq5C59dIz2SbBwJ4eM=\ngithub.com/google/pprof v0.0.0-20241210010833-40e02aabc2ad h1:a6HEuzUHeKH6hwfN/ZoQgRgVIWFJljSWa/zetS2WTvg=\ngithub.com/google/pprof v0.0.0-20241210010833-40e02aabc2ad/go.mod h1:vavhavw2zAxS5dIdcRluK6cSGGPlZynqzFM8NdvU144=\ngithub.com/google/renameio v0.1.0/go.mod h1:KWCgfxg9yswjAJkECMjeO8J8rahYeXnNhOm40UhjYkI=\ngithub.com/google/uuid v1.1.1/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/google/uuid v1.6.0 h1:NIvaJDMOsjHA8n1jAhLSgzrAzy1Hgr+hNrb57e+94F0=\ngithub.com/google/uuid v1.6.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/googleapis/gax-go/v2 v2.0.4/go.mod h1:0Wqv26UfaUD9n4G6kQubkQ+KchISgw+vpHVxEJEs9eg=\ngithub.com/googleapis/gax-go/v2 v2.0.5/go.mod h1:DWXyrwAJ9X0FpwwEdw+IPEYBICEFu5mhpdKc/us6bOk=\ngithub.com/gopherjs/gopherjs v0.0.0-20181017120253-0766667cb4d1/go.mod h1:wJfORRmW1u3UXTncJ5qlYoELFm8eSnnEO6hX4iZ3EWY=\ngithub.com/gorilla/websocket v1.5.0 h1:PPwGk2jz7EePpoHN/+ClbZu8SPxiqlu12wZP/3sWmnc=\ngithub.com/gorilla/websocket v1.5.0/go.mod h1:YR8l580nyteQvAITg2hZ9XVh4b55+EU/adAjf1fMHhE=\ngithub.com/grpc-ecosystem/go-grpc-middleware v1.3.0 h1:+9834+KizmvFV7pXQGSXQTsaWhq2GjuNUt0aUU0YBYw=\ngithub.com/grpc-ecosystem/go-grpc-middleware v1.3.0/go.mod h1:z0ButlSOZa5vEBq9m2m2hlwIgKw+rp3sdCBRoJY+30Y=\ngithub.com/grpc-ecosystem/go-grpc-prometheus v1.2.0 h1:Ovs26xHkKqVztRpIrF/92BcuyuQ/YW4NSIpoGtfXNho=\ngithub.com/grpc-ecosystem/go-grpc-prometheus v1.2.0/go.mod h1:8NvIoxWQoOIhqOTXgfV/d3M/q6VIi02HzZEHgUlZvzk=\ngithub.com/grpc-ecosystem/grpc-gateway v1.16.0 h1:gmcG1KaJ57LophUzW0Hy8NmPhnMZb4M0+kPpLofRdBo=\ngithub.com/grpc-ecosystem/grpc-gateway v1.16.0/go.mod h1:BDjrQk3hbvj6Nolgz8mAMFbcEtjT1g+wF4CSlocrBnw=\ngithub.com/grpc-ecosystem/grpc-gateway/v2 v2.20.0 h1:bkypFPDjIYGfCYD5mRBvpqxfYX1YCS1PXdKYWi8FsN0=\ngithub.com/grpc-ecosystem/grpc-gateway/v2 v2.20.0/go.mod h1:P+Lt/0by1T8bfcF3z737NnSbmxQAppXMRziHUxPOC8k=\ngithub.com/hashicorp/golang-lru v0.5.0/go.mod h1:/m3WP610KZHVQ1SGc6re/UDhFvYD7pJ4Ao+sR/qLZy8=\ngithub.com/hashicorp/golang-lru v0.5.1/go.mod h1:/m3WP610KZHVQ1SGc6re/UDhFvYD7pJ4Ao+sR/qLZy8=\ngithub.com/hashicorp/hcl v1.0.0 h1:0Anlzjpi4vEasTeNFn2mLJgTSwt0+6sfsiTG8qcWGx4=\ngithub.com/hashicorp/hcl v1.0.0/go.mod h1:E5yfLk+7swimpb2L/Alb/PJmXilQ/rhwaUYs4T20WEQ=\ngithub.com/huandu/xstrings v1.5.0 h1:2ag3IFq9ZDANvthTwTiqSSZLjDc+BedvHPAp5tJy2TI=\ngithub.com/huandu/xstrings v1.5.0/go.mod h1:y5/lhBue+AyNmUVz9RLU9xbLR0o4KIIExikq4ovT0aE=\ngithub.com/ianlancetaylor/demangle v0.0.0-20181102032728-5e5cf60278f6/go.mod h1:aSSvb/t6k1mPoxDqO4vJh6VOCGPwU4O0C2/Eqndh1Sc=\ngithub.com/imdario/mergo v0.3.13 h1:lFzP57bqS/wsqKssCGmtLAb8A0wKjLGrve2q3PPVcBk=\ngithub.com/imdario/mergo v0.3.13/go.mod h1:4lJ1jqUDcsbIECGy0RUJAXNIhg+6ocWgb1ALK2O4oXg=\ngithub.com/inconshreveable/mousetrap v1.1.0 h1:wN+x4NVGpMsO7ErUn/mUI3vEoE6Jt13X2s0bqwp9tc8=\ngithub.com/inconshreveable/mousetrap v1.1.0/go.mod h1:vpF70FUmC8bwa3OWnCshd2FqLfsEA9PFc4w1p2J65bw=\ngithub.com/jmespath/go-jmespath v0.0.0-20160202185014-0b12d6b521d8/go.mod h1:Nht3zPeWKUH0NzdCt2Blrr5ys8VGpn0CEB0cQHVjt7k=\ngithub.com/jonboulle/clockwork v0.2.2 h1:UOGuzwb1PwsrDAObMuhUnj0p5ULPj8V/xJ7Kx9qUBdQ=\ngithub.com/jonboulle/clockwork v0.2.2/go.mod h1:Pkfl5aHPm1nk2H9h0bjmnJD/BcgbGXUBGnn1kMkgxc8=\ngithub.com/josharian/intern v1.0.0 h1:vlS4z54oSdjm0bgjRigI+G1HpF+tI+9rE5LLzOg8HmY=\ngithub.com/josharian/intern v1.0.0/go.mod h1:5DoeVV0s6jJacbCEi61lwdGj/aVlrQvzHFFd8Hwg//Y=\ngithub.com/json-iterator/go v1.1.12 h1:PV8peI4a0ysnczrg+LtxykD8LfKY9ML6u2jnxaEnrnM=\ngithub.com/json-iterator/go v1.1.12/go.mod h1:e30LSqwooZae/UwlEbR2852Gd8hjQvJoHmT4TnhNGBo=\ngithub.com/jstemmer/go-junit-report v0.0.0-20190106144839-af01ea7f8024/go.mod h1:6v2b51hI/fHJwM22ozAgKL4VKDeJcHhJFhtBdhmNjmU=\ngithub.com/jstemmer/go-junit-report v0.9.1/go.mod h1:Brl9GWCQeLvo8nXZwPNNblvFj/XSXhF0NWZEnDohbsk=\ngithub.com/jtolds/gls v4.20.0+incompatible/go.mod h1:QJZ7F/aHp+rZTRtaJ1ow/lLfFfVYBRgL+9YlvaHOwJU=\ngithub.com/kisielk/errcheck v1.5.0/go.mod h1:pFxgyoBC7bSaBwPgfKdkLd5X25qrDl4LWUI2bnpBCr8=\ngithub.com/kisielk/gotool v1.0.0/go.mod h1:XhKaO+MFFWcvkIS/tQcRk01m1F5IRFswLeQ+oQHNcck=\ngithub.com/kr/pretty v0.1.0/go.mod h1:dAy3ld7l9f0ibDNOQOHHMYYIIbhfbHSm3C4ZsoJORNo=\ngithub.com/kr/pretty v0.2.1/go.mod h1:ipq/a2n7PKx3OHsz4KJII5eveXtPO4qwEXGdVfWzfnI=\ngithub.com/kr/pretty v0.3.1 h1:flRD4NNwYAUpkphVc1HcthR4KEIFJ65n8Mw5qdRn3LE=\ngithub.com/kr/pretty v0.3.1/go.mod h1:hoEshYVHaxMs3cyo3Yncou5ZscifuDolrwPKZanG3xk=\ngithub.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=\ngithub.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=\ngithub.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=\ngithub.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=\ngithub.com/magiconair/properties v1.8.7 h1:IeQXZAiQcpL9mgcAe1Nu6cX9LLw6ExEHKjN0VQdvPDY=\ngithub.com/magiconair/properties v1.8.7/go.mod h1:Dhd985XPs7jluiymwWYZ0G4Z61jb3vdS329zhj2hYo0=\ngithub.com/mailru/easyjson v0.7.7 h1:UGYAvKxe3sBsEDzO8ZeWOSlIQfWFlxbzLZe7hwFURr0=\ngithub.com/mailru/easyjson v0.7.7/go.mod h1:xzfreul335JAWq5oZzymOObrkdz5UnU4kGfJJLY9Nlc=\ngithub.com/mattn/go-colorable v0.1.13 h1:fFA4WZxdEF4tXPZVKMLwD8oUnCTTo08duU7wxecdEvA=\ngithub.com/mattn/go-colorable v0.1.13/go.mod h1:7S9/ev0klgBDR4GtXTXX8a3vIGJpMovkB8vQcUbaXHg=\ngithub.com/mattn/go-isatty v0.0.16/go.mod h1:kYGgaQfpe5nmfYZH+SKPsOc2e4SrIfOl2e/yFXSvRLM=\ngithub.com/mattn/go-isatty v0.0.20 h1:xfD0iDuEKnDkl03q4limB+vH+GxLEtL/jb4xVJSWWEY=\ngithub.com/mattn/go-isatty v0.0.20/go.mod h1:W+V8PltTTMOvKvAeJH7IuucS94S2C6jfK/D7dTCTo3Y=\ngithub.com/mattn/go-runewidth v0.0.9/go.mod h1:H031xJmbD/WCDINGzjvQ9THkh0rPKHF+m2gUSrubnMI=\ngithub.com/mattn/go-runewidth v0.0.14 h1:+xnbZSEeDbOIg5/mE6JF0w6n9duR1l3/WmbinWVwUuU=\ngithub.com/mattn/go-runewidth v0.0.14/go.mod h1:Jdepj2loyihRzMpdS35Xk/zdY8IAYHsh153qUoGf23w=\ngithub.com/mitchellh/copystructure v1.2.0 h1:vpKXTN4ewci03Vljg/q9QvCGUDttBOGBIa15WveJJGw=\ngithub.com/mitchellh/copystructure v1.2.0/go.mod h1:qLl+cE2AmVv+CoeAwDPye/v+N2HKCj9FbZEVFJRxO9s=\ngithub.com/mitchellh/mapstructure v1.5.0 h1:jeMsZIYE/09sWLaz43PL7Gy6RuMjD2eJVyuac5Z2hdY=\ngithub.com/mitchellh/mapstructure v1.5.0/go.mod h1:bFUtVrKA4DC2yAKiSyO/QUcy7e+RRV2QTWOzhPopBRo=\ngithub.com/mitchellh/reflectwalk v1.0.2 h1:G2LzWKi524PWgd3mLHV8Y5k7s6XUvT0Gef6zxSIeXaQ=\ngithub.com/mitchellh/reflectwalk v1.0.2/go.mod h1:mSTlrgnPZtwu0c4WaC2kGObEpuNDbx0jmZXqmk4esnw=\ngithub.com/moby/spdystream v0.4.0 h1:Vy79D6mHeJJjiPdFEL2yku1kl0chZpJfZcPpb16BRl8=\ngithub.com/moby/spdystream v0.4.0/go.mod h1:xBAYlnt/ay+11ShkdFKNAG7LsyK/tmNBVvVOwrfMgdI=\ngithub.com/modern-go/concurrent v0.0.0-20180228061459-e0a39a4cb421/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=\ngithub.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd h1:TRLaZ9cD/w8PVh93nsPXa1VrQ6jlwL5oN8l14QlcNfg=\ngithub.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=\ngithub.com/modern-go/reflect2 v1.0.2 h1:xBagoLtFs94CBntxluKeaWgTMpvLxC4ur3nMaC9Gz0M=\ngithub.com/modern-go/reflect2 v1.0.2/go.mod h1:yWuevngMOJpCy52FWWMvUC8ws7m/LJsjYzDa0/r8luk=\ngithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 h1:C3w9PqII01/Oq1c1nUAm88MOHcQC9l5mIlSMApZMrHA=\ngithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822/go.mod h1:+n7T8mK8HuQTcFwEeznm/DIxMOiR9yIdICNftLE1DvQ=\ngithub.com/mxk/go-flowrate v0.0.0-20140419014527-cca7078d478f h1:y5//uYreIhSUg3J1GEMiLbxo1LJaP8RfCpH6pymGZus=\ngithub.com/mxk/go-flowrate v0.0.0-20140419014527-cca7078d478f/go.mod h1:ZdcZmHo+o7JKHSa8/e818NopupXU1YMK5fe1lsApnBw=\ngithub.com/olekukonko/tablewriter v0.0.5 h1:P2Ga83D34wi1o9J6Wh1mRuqd4mF/x/lgBS7N7AbDhec=\ngithub.com/olekukonko/tablewriter v0.0.5/go.mod h1:hPp6KlRPjbx+hW8ykQs1w3UBbZlj6HuIJcUGPhkA7kY=\ngithub.com/onsi/ginkgo/v2 v2.22.2 h1:/3X8Panh8/WwhU/3Ssa6rCKqPLuAkVY2I0RoyDLySlU=\ngithub.com/onsi/ginkgo/v2 v2.22.2/go.mod h1:oeMosUL+8LtarXBHu/c0bx2D/K9zyQ6uX3cTyztHwsk=\ngithub.com/onsi/gomega v1.36.2 h1:koNYke6TVk6ZmnyHrCXba/T/MoLBXFjeC1PtvYgw0A8=\ngithub.com/onsi/gomega v1.36.2/go.mod h1:DdwyADRjrc825LhMEkD76cHR5+pUnjhUN8GlHlRPHzY=\ngithub.com/opencontainers/go-digest v1.0.0 h1:apOUWs51W5PlhuyGyz9FCeeBIOUDA/6nW8Oi/yOhh5U=\ngithub.com/opencontainers/go-digest v1.0.0/go.mod h1:0JzlMkj0TRzQZfJkVvzbP0HBR3IKzErnv2BNG4W4MAM=\ngithub.com/pborman/uuid v0.0.0-20170612153648-e790cca94e6c/go.mod h1:VyrYX9gd7irzKovcSS6BIIEwPRkP2Wm2m9ufcdFSJ34=\ngithub.com/pelletier/go-toml/v2 v2.2.2 h1:aYUidT7k73Pcl9nb2gScu7NSrKCSHIDE89b3+6Wq+LM=\ngithub.com/pelletier/go-toml/v2 v2.2.2/go.mod h1:1t835xjRzz80PqgE6HHgN2JOsmgYu/h4qDAS4n929Rs=\ngithub.com/pin/tftp v2.1.0+incompatible/go.mod h1:xVpZOMCXTy+A5QMjEVN0Glwa1sUvaJhFXbr/aAxuxGY=\ngithub.com/pkg/errors v0.9.1 h1:FEBLx1zS214owpjy7qsBeixbURkuhQAwrK5UwLGTwt4=\ngithub.com/pkg/errors v0.9.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/pmezard/go-difflib v1.0.1-0.20181226105442-5d4384ee4fb2 h1:Jamvg5psRIccs7FGNTlIRMkT8wgtp5eCXdBlqhYGL6U=\ngithub.com/pmezard/go-difflib v1.0.1-0.20181226105442-5d4384ee4fb2/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/prometheus/client_golang v1.19.1 h1:wZWJDwK+NameRJuPGDhlnFgx8e8HN3XHQeLaYJFJBOE=\ngithub.com/prometheus/client_golang v1.19.1/go.mod h1:mP78NwGzrVks5S2H6ab8+ZZGJLZUq1hoULYBAYBw1Ho=\ngithub.com/prometheus/client_model v0.0.0-20190812154241-14fe0d1b01d4/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6Tm2C1GtYGdfGttqA=\ngithub.com/prometheus/client_model v0.6.1 h1:ZKSh/rekM+n3CeS952MLRAdFwIKqeY8b62p8ais2e9E=\ngithub.com/prometheus/client_model v0.6.1/go.mod h1:OrxVMOVHjw3lKMa8+x6HeMGkHMQyHDk9E3jmP2AmGiY=\ngithub.com/prometheus/common v0.55.0 h1:KEi6DK7lXW/m7Ig5i47x0vRzuBsHuvJdi5ee6Y3G1dc=\ngithub.com/prometheus/common v0.55.0/go.mod h1:2SECS4xJG1kd8XF9IcM1gMX6510RAEL65zxzNImwdc8=\ngithub.com/prometheus/procfs v0.15.1 h1:YagwOFzUgYfKKHX6Dr+sHT7km/hxC76UB0learggepc=\ngithub.com/prometheus/procfs v0.15.1/go.mod h1:fB45yRUv8NstnjriLhBQLuOUt+WW4BsoGhij/e3PBqk=\ngithub.com/rivo/uniseg v0.2.0/go.mod h1:J6wj4VEh+S6ZtnVlnTBMWIodfgj8LQOQFoIToxlJtxc=\ngithub.com/rivo/uniseg v0.4.2 h1:YwD0ulJSJytLpiaWua0sBDusfsCZohxjxzVTYjwxfV8=\ngithub.com/rivo/uniseg v0.4.2/go.mod h1:FN3SvrM+Zdj16jyLfmOkMNblXMcoc8DfTHruCPUcx88=\ngithub.com/rogpeppe/go-internal v1.3.0/go.mod h1:M8bDsm7K2OlrFYOpmOWEs/qY81heoFRclV5y23lUDJ4=\ngithub.com/rogpeppe/go-internal v1.12.0 h1:exVL4IDcn6na9z1rAb56Vxr+CgyK3nn3O+epU5NdKM8=\ngithub.com/rogpeppe/go-internal v1.12.0/go.mod h1:E+RYuTGaKKdloAfM02xzb0FW3Paa99yedzYV+kq4uf4=\ngithub.com/russross/blackfriday/v2 v2.1.0/go.mod h1:+Rmxgy9KzJVeS9/2gXHxylqXiyQDYRxCVz55jmeOWTM=\ngithub.com/rwcarlsen/goexif v0.0.0-20190401172101-9e8deecbddbd/go.mod h1:hPqNNc0+uJM6H+SuU8sEs5K5IQeKccPqeSjfgcKGgPk=\ngithub.com/sagikazarmark/locafero v0.4.0 h1:HApY1R9zGo4DBgr7dqsTH/JJxLTTsOt7u6keLGt6kNQ=\ngithub.com/sagikazarmark/locafero v0.4.0/go.mod h1:Pe1W6UlPYUk/+wc/6KFhbORCfqzgYEpgQ3O5fPuL3H4=\ngithub.com/sagikazarmark/slog-shim v0.1.0 h1:diDBnUNK9N/354PgrxMywXnAwEr1QZcOr6gto+ugjYE=\ngithub.com/sagikazarmark/slog-shim v0.1.0/go.mod h1:SrcSrq8aKtyuqEI1uvTDTK1arOWRIczQRv+GVI1AkeQ=\ngithub.com/shopspring/decimal v1.4.0 h1:bxl37RwXBklmTi0C79JfXCEBD1cqqHt0bbgBAGFp81k=\ngithub.com/shopspring/decimal v1.4.0/go.mod h1:gawqmDU56v4yIKSwfBSFip1HdCCXN8/+DMd9qYNcwME=\ngithub.com/sigma/bdoor v0.0.0-20160202064022-babf2a4017b0/go.mod h1:WBu7REWbxC/s/J06jsk//d+9DOz9BbsmcIrimuGRFbs=\ngithub.com/sigma/vmw-guestinfo v0.0.0-20160204083807-95dd4126d6e8/go.mod h1:JrRFFC0veyh0cibh0DAhriSY7/gV3kDdNaVUOmfx01U=\ngithub.com/sirupsen/logrus v1.9.3 h1:dueUQJ1C2q9oE3F7wvmSGAaVtTmUizReu6fjN8uqzbQ=\ngithub.com/sirupsen/logrus v1.9.3/go.mod h1:naHLuLoDiP4jHNo9R0sCBMtWGeIprob74mVsIT4qYEQ=\ngithub.com/smartystreets/assertions v1.2.0/go.mod h1:tcbTF8ujkAEcZ8TElKY+i30BzYlVhC/LOxJk7iOWnoo=\ngithub.com/smartystreets/goconvey v1.7.2/go.mod h1:Vw0tHAZW6lzCRk3xgdin6fKYcG+G3Pg9vgXWeJpQFMM=\ngithub.com/soheilhy/cmux v0.1.5 h1:jjzc5WVemNEDTLwv9tlmemhC73tI08BNOIGwBOo10Js=\ngithub.com/soheilhy/cmux v0.1.5/go.mod h1:T7TcVDs9LWfQgPlPsdngu6I6QIoyIFZDDC6sNE1GqG0=\ngithub.com/sourcegraph/conc v0.3.0 h1:OQTbbt6P72L20UqAkXXuLOj79LfEanQ+YQFNpLA9ySo=\ngithub.com/sourcegraph/conc v0.3.0/go.mod h1:Sdozi7LEKbFPqYX2/J+iBAM6HpqSLTASQIKqDmF7Mt0=\ngithub.com/spf13/afero v1.11.0 h1:WJQKhtpdm3v2IzqG8VMqrr6Rf3UYpEF239Jy9wNepM8=\ngithub.com/spf13/afero v1.11.0/go.mod h1:GH9Y3pIexgf1MTIWtNGyogA5MwRIDXGUr+hbWNoBjkY=\ngithub.com/spf13/cast v1.7.0 h1:ntdiHjuueXFgm5nzDRdOS4yfT43P5Fnud6DH50rz/7w=\ngithub.com/spf13/cast v1.7.0/go.mod h1:ancEpBxwJDODSW/UG4rDrAqiKolqNNh2DX3mk86cAdo=\ngithub.com/spf13/cobra v1.8.1 h1:e5/vxKd/rZsfSJMUX1agtjeTDf+qv1/JdBF8gg5k9ZM=\ngithub.com/spf13/cobra v1.8.1/go.mod h1:wHxEcudfqmLYa8iTfL+OuZPbBZkmvliBWKIezN3kD9Y=\ngithub.com/spf13/pflag v1.0.5 h1:iy+VFUOCP1a+8yFto/drg2CJ5u0yRoB7fZw3DKv/JXA=\ngithub.com/spf13/pflag v1.0.5/go.mod h1:McXfInJRrz4CZXVZOBLb0bTZqETkiAhM9Iw0y3An2Bg=\ngithub.com/spf13/viper v1.19.0 h1:RWq5SEjt8o25SROyN3z2OrDB9l7RPd3lwTWU8EcEdcI=\ngithub.com/spf13/viper v1.19.0/go.mod h1:GQUN9bilAbhU/jgc1bKs99f/suXKeUMct8Adx5+Ntkg=\ngithub.com/stoewer/go-strcase v1.2.0 h1:Z2iHWqGXH00XYgqDmNgQbIBxf3wrNq0F3feEy0ainaU=\ngithub.com/stoewer/go-strcase v1.2.0/go.mod h1:IBiWB2sKIp3wVVQ3Y035++gc+knqhUQag1KpM8ahLw8=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.4.0/go.mod h1:YvHI0jy2hoMjB+UWwv71VJQ9isScKT/TqJzVSSt89Yw=\ngithub.com/stretchr/objx v0.5.0/go.mod h1:Yh+to48EsGEfYuaHDzXPcE3xhTkx73EhmCGUpEOglKo=\ngithub.com/stretchr/objx v0.5.2/go.mod h1:FRsXN1f5AsAjCGJKqEizvkpNtU+EGNCLh3NxZ/8L+MA=\ngithub.com/stretchr/testify v1.3.0/go.mod h1:M5WIy9Dh21IEIfnGCwXGc5bZfKNJtfHm1UVUgZn+9EI=\ngithub.com/stretchr/testify v1.4.0/go.mod h1:j7eGeouHqKxXV5pUuKE4zz7dFj8WfuZ+81PSLYec5m4=\ngithub.com/stretchr/testify v1.5.1/go.mod h1:5W2xD1RspED5o8YsWQXVCued0rvSQ+mT+I5cxcmMvtA=\ngithub.com/stretchr/testify v1.7.0/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.7.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.8.0/go.mod h1:yNjHg4UonilssWZ8iaSj1OCr/vHnekPRkoO+kdMU+MU=\ngithub.com/stretchr/testify v1.8.1/go.mod h1:w2LPCIKwWwSfY2zedu0+kehJoqGctiVI29o6fzry7u4=\ngithub.com/stretchr/testify v1.8.4/go.mod h1:sz/lmYIOXD/1dqDmKjjqLyZ2RngseejIcXlSw2iwfAo=\ngithub.com/stretchr/testify v1.9.0 h1:HtqpIVDClZ4nwg75+f6Lvsy/wHu+3BoSGCbBAcpTsTg=\ngithub.com/stretchr/testify v1.9.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=\ngithub.com/subosito/gotenv v1.6.0 h1:9NlTDc1FTs4qu0DDq7AEtTPNw6SVm7uBMsUCUjABIf8=\ngithub.com/subosito/gotenv v1.6.0/go.mod h1:Dk4QP5c2W3ibzajGcXpNraDfq2IrhjMIvMSWPKKo0FU=\ngithub.com/tmc/grpc-websocket-proxy v0.0.0-20220101234140-673ab2c3ae75 h1:6fotK7otjonDflCTK0BCfls4SPy3NcCVb5dqqmbRknE=\ngithub.com/tmc/grpc-websocket-proxy v0.0.0-20220101234140-673ab2c3ae75/go.mod h1:KO6IkyS8Y3j8OdNO85qEYBsRPuteD+YciPomcXdrMnk=\ngithub.com/valyala/fastjson v1.6.4 h1:uAUNq9Z6ymTgGhcm0UynUAB6tlbakBrz6CQFax3BXVQ=\ngithub.com/valyala/fastjson v1.6.4/go.mod h1:CLCAqky6SMuOcxStkYQvblddUtoRxhYMGLrsQns1aXY=\ngithub.com/vincent-petithory/dataurl v1.0.0 h1:cXw+kPto8NLuJtlMsI152irrVw9fRDX8AbShPRpg2CI=\ngithub.com/vincent-petithory/dataurl v1.0.0/go.mod h1:FHafX5vmDzyP+1CQATJn7WFKc9CvnvxyvZy6I1MrG/U=\ngithub.com/vmware/vmw-guestinfo v0.0.0-20170707015358-25eff159a728/go.mod h1:x9oS4Wk2s2u4tS29nEaDLdzvuHdB19CvSGJjPgkZJNk=\ngithub.com/vmware/vmw-ovflib v0.0.0-20170608004843-1f217b9dc714/go.mod h1:jiPk45kn7klhByRvUq5i2vo1RtHKBHj+iWGFpxbXuuI=\ngithub.com/x448/float16 v0.8.4 h1:qLwI1I70+NjRFUR3zs1JPUCgaCXSh3SW62uAKT1mSBM=\ngithub.com/x448/float16 v0.8.4/go.mod h1:14CWIYCyZA/cWjXOioeEpHeN/83MdbZDRQHoFcYsOfg=\ngithub.com/xiang90/probing v0.0.0-20190116061207-43a291ad63a2 h1:eY9dn8+vbi4tKz5Qo6v2eYzo7kUS51QINcR5jNpbZS8=\ngithub.com/xiang90/probing v0.0.0-20190116061207-43a291ad63a2/go.mod h1:UETIi67q53MR2AWcXfiuqkDkRtnGDLqkBTpCHuJHxtU=\ngithub.com/yuin/goldmark v1.1.27/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngithub.com/yuin/goldmark v1.2.1/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngo.etcd.io/bbolt v1.3.9 h1:8x7aARPEXiXbHmtUwAIv7eV2fQFHrLLavdiJ3uzJXoI=\ngo.etcd.io/bbolt v1.3.9/go.mod h1:zaO32+Ti0PK1ivdPtgMESzuzL2VPoIG1PCQNvOdo/dE=\ngo.etcd.io/etcd/api/v3 v3.5.17 h1:cQB8eb8bxwuxOilBpMJAEo8fAONyrdXTHUNcMd8yT1w=\ngo.etcd.io/etcd/api/v3 v3.5.17/go.mod h1:d1hvkRuXkts6PmaYk2Vrgqbv7H4ADfAKhyJqHNLJCB4=\ngo.etcd.io/etcd/client/pkg/v3 v3.5.17 h1:XxnDXAWq2pnxqx76ljWwiQ9jylbpC4rvkAeRVOUKKVw=\ngo.etcd.io/etcd/client/pkg/v3 v3.5.17/go.mod h1:4DqK1TKacp/86nJk4FLQqo6Mn2vvQFBmruW3pP14H/w=\ngo.etcd.io/etcd/client/v2 v2.305.13 h1:RWfV1SX5jTU0lbCvpVQe3iPQeAHETWdOTb6pxhd77C8=\ngo.etcd.io/etcd/client/v2 v2.305.13/go.mod h1:iQnL7fepbiomdXMb3om1rHq96htNNGv2sJkEcZGDRRg=\ngo.etcd.io/etcd/client/v3 v3.5.17 h1:o48sINNeWz5+pjy/Z0+HKpj/xSnBkuVhVvXkjEXbqZY=\ngo.etcd.io/etcd/client/v3 v3.5.17/go.mod h1:j2d4eXTHWkT2ClBgnnEPm/Wuu7jsqku41v9DZ3OtjQo=\ngo.etcd.io/etcd/pkg/v3 v3.5.13 h1:st9bDWNsKkBNpP4PR1MvM/9NqUPfvYZx/YXegsYEH8M=\ngo.etcd.io/etcd/pkg/v3 v3.5.13/go.mod h1:N+4PLrp7agI/Viy+dUYpX7iRtSPvKq+w8Y14d1vX+m0=\ngo.etcd.io/etcd/raft/v3 v3.5.13 h1:7r/NKAOups1YnKcfro2RvGGo2PTuizF/xh26Z2CTAzA=\ngo.etcd.io/etcd/raft/v3 v3.5.13/go.mod h1:uUFibGLn2Ksm2URMxN1fICGhk8Wu96EfDQyuLhAcAmw=\ngo.etcd.io/etcd/server/v3 v3.5.13 h1:V6KG+yMfMSqWt+lGnhFpP5z5dRUj1BDRJ5k1fQ9DFok=\ngo.etcd.io/etcd/server/v3 v3.5.13/go.mod h1:K/8nbsGupHqmr5MkgaZpLlH1QdX1pcNQLAkODy44XcQ=\ngo.opencensus.io v0.21.0/go.mod h1:mSImk1erAIZhrmZN+AvHh14ztQfjbGwt4TtuofqLduU=\ngo.opencensus.io v0.22.0/go.mod h1:+kGneAE2xo2IficOXnaByMWTGM9T73dGwxeWcUqIpI8=\ngo.opencensus.io v0.22.2/go.mod h1:yxeiOL68Rb0Xd1ddK5vPZ/oVn4vY4Ynel7k9FzqtOIw=\ngo.opencensus.io v0.22.3/go.mod h1:yxeiOL68Rb0Xd1ddK5vPZ/oVn4vY4Ynel7k9FzqtOIw=\ngo.opentelemetry.io/contrib/instrumentation/google.golang.org/grpc/otelgrpc v0.53.0 h1:9G6E0TXzGFVfTnawRzrPl83iHOAV7L8NJiR8RSGYV1g=\ngo.opentelemetry.io/contrib/instrumentation/google.golang.org/grpc/otelgrpc v0.53.0/go.mod h1:azvtTADFQJA8mX80jIH/akaE7h+dbm/sVuaHqN13w74=\ngo.opentelemetry.io/contrib/instrumentation/net/http/otelhttp v0.53.0 h1:4K4tsIXefpVJtvA/8srF4V4y0akAoPHkIslgAkjixJA=\ngo.opentelemetry.io/contrib/instrumentation/net/http/otelhttp v0.53.0/go.mod h1:jjdQuTGVsXV4vSs+CJ2qYDeDPf9yIJV23qlIzBm73Vg=\ngo.opentelemetry.io/otel v1.28.0 h1:/SqNcYk+idO0CxKEUOtKQClMK/MimZihKYMruSMViUo=\ngo.opentelemetry.io/otel v1.28.0/go.mod h1:q68ijF8Fc8CnMHKyzqL6akLO46ePnjkgfIMIjUIX9z4=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace v1.28.0 h1:3Q/xZUyC1BBkualc9ROb4G8qkH90LXEIICcs5zv1OYY=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace v1.28.0/go.mod h1:s75jGIWA9OfCMzF0xr+ZgfrB5FEbbV7UuYo32ahUiFI=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc v1.27.0 h1:qFffATk0X+HD+f1Z8lswGiOQYKHRlzfmdJm0wEaVrFA=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc v1.27.0/go.mod h1:MOiCmryaYtc+V0Ei+Tx9o5S1ZjA7kzLucuVuyzBZloQ=\ngo.opentelemetry.io/otel/metric v1.28.0 h1:f0HGvSl1KRAU1DLgLGFjrwVyismPlnuU6JD6bOeuA5Q=\ngo.opentelemetry.io/otel/metric v1.28.0/go.mod h1:Fb1eVBFZmLVTMb6PPohq3TO9IIhUisDsbJoL/+uQW4s=\ngo.opentelemetry.io/otel/sdk v1.28.0 h1:b9d7hIry8yZsgtbmM0DKyPWMMUMlK9NEKuIG4aBqWyE=\ngo.opentelemetry.io/otel/sdk v1.28.0/go.mod h1:oYj7ClPUA7Iw3m+r7GeEjz0qckQRJK2B8zjcZEfu7Pg=\ngo.opentelemetry.io/otel/trace v1.28.0 h1:GhQ9cUuQGmNDd5BTCP2dAvv75RdMxEfTmYejp+lkx9g=\ngo.opentelemetry.io/otel/trace v1.28.0/go.mod h1:jPyXzNPg6da9+38HEwElrQiHlVMTnVfM3/yv2OlIHaI=\ngo.opentelemetry.io/proto/otlp v1.3.1 h1:TrMUixzpM0yuc/znrFTP9MMRh8trP93mkCiDVeXrui0=\ngo.opentelemetry.io/proto/otlp v1.3.1/go.mod h1:0X1WI4de4ZsLrrJNLAQbFeLCm3T7yBkR0XqQ7niQU+8=\ngo.uber.org/goleak v1.3.0 h1:2K3zAYmnTNqV73imy9J1T3WC+gmCePx2hEGkimedGto=\ngo.uber.org/goleak v1.3.0/go.mod h1:CoHD4mav9JJNrW/WLlf7HGZPjdw8EucARQHekz1X6bE=\ngo.uber.org/multierr v1.11.0 h1:blXXJkSxSSfBVBlC76pxqeO+LN3aDfLQo+309xJstO0=\ngo.uber.org/multierr v1.11.0/go.mod h1:20+QtiLqy0Nd6FdQB9TLXag12DsQkrbs3htMFfDN80Y=\ngo.uber.org/zap v1.27.0 h1:aJMhYGrd5QSmlpLMr2MftRKl7t8J8PTZPA732ud/XR8=\ngo.uber.org/zap v1.27.0/go.mod h1:GB2qFLM7cTU87MWRP2mPIjqfIDnGu+VIO4V/SdhGo2E=\ngo4.org v0.0.0-20160314031811-03efcb870d84/go.mod h1:MkTOUMDaeVYJUOUsaDXIhWPZYa1yOyC1qaOBpL57BhE=\ngo4.org v0.0.0-20201209231011-d4a079459e60 h1:iqAGo78tVOJXELHQFRjR6TMwItrvXH4hrGJ32I/NFF8=\ngo4.org v0.0.0-20201209231011-d4a079459e60/go.mod h1:CIiUVy99QCPfoE13bO4EZaz5GZMZXMSBGhxRdsvzbkg=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20190510104115-cbcb75029529/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20190605123033-f99c8df09eb5/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20191011191535-87dc89f01550/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20200622213623-75b288015ac9/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/crypto v0.0.0-20210921155107-089bfa567519/go.mod h1:GvvjBRRGRdwPK5ydBHafDWAxML/pGHZbMvKqRZ5+Abc=\ngolang.org/x/crypto v0.31.0 h1:ihbySMvVjLAeSH1IbfcRTkD/iNscyz8rGzjF/E5hV6U=\ngolang.org/x/crypto v0.31.0/go.mod h1:kDsLvtWBEx7MV9tJOj9bnXsPbxwJQ6csT/x4KIN4Ssk=\ngolang.org/x/exp v0.0.0-20190121172915-509febef88a4/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\ngolang.org/x/exp v0.0.0-20190306152737-a1d7652674e8/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\ngolang.org/x/exp v0.0.0-20190510132918-efd6b22b2522/go.mod h1:ZjyILWgesfNpC6sMxTJOJm9Kp84zZh5NQWvqDGG3Qr8=\ngolang.org/x/exp v0.0.0-20190829153037-c13cbed26979/go.mod h1:86+5VVa7VpoJ4kLfm080zCjGlMRFzhUhsZKEZO7MGek=\ngolang.org/x/exp v0.0.0-20191030013958-a1ab85dbe136/go.mod h1:JXzH8nQsPlswgeRAPE3MuO9GYsAcnJvJ4vnMwN/5qkY=\ngolang.org/x/exp v0.0.0-20191129062945-2f5052295587/go.mod h1:2RIsYlXP63K8oxa1u096TMicItID8zy7Y6sNkU49FU4=\ngolang.org/x/exp v0.0.0-20191227195350-da58074b4299/go.mod h1:2RIsYlXP63K8oxa1u096TMicItID8zy7Y6sNkU49FU4=\ngolang.org/x/exp v0.0.0-20200207192155-f17229e696bd/go.mod h1:J/WKrq2StrnmMY6+EHIKF9dgMWnmCNThgcyBT1FY9mM=\ngolang.org/x/exp v0.0.0-20240719175910-8a7402abbf56 h1:2dVuKD2vS7b0QIHQbpyTISPd0LeHDbnYEryqj5Q1ug8=\ngolang.org/x/exp v0.0.0-20240719175910-8a7402abbf56/go.mod h1:M4RDyNAINzryxdtnbRXRL/OHtkFuWGRjvuhBJpk2IlY=\ngolang.org/x/image v0.0.0-20190227222117-0694c2d4d067/go.mod h1:kZ7UVZpmo3dzQBMxlp+ypCbDeSB+sBbTgSJuh5dn5js=\ngolang.org/x/image v0.0.0-20190802002840-cff245a6509b/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\ngolang.org/x/lint v0.0.0-20181026193005-c67002cb31c3/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=\ngolang.org/x/lint v0.0.0-20190227174305-5b3e6a55c961/go.mod h1:wehouNa3lNwaWXcvxsM5YxQ5yQlVC4a0KAMCusXpPoU=\ngolang.org/x/lint v0.0.0-20190301231843-5614ed5bae6f/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=\ngolang.org/x/lint v0.0.0-20190313153728-d0100b6bd8b3/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/lint v0.0.0-20190409202823-959b441ac422/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/lint v0.0.0-20190909230951-414d861bb4ac/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/lint v0.0.0-20190930215403-16217165b5de/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/lint v0.0.0-20191125180803-fdd1cda4f05f/go.mod h1:5qLYkcX4OjUUV8bRuDixDT3tpyyb+LUpUlRWLxfhWrs=\ngolang.org/x/lint v0.0.0-20200130185559-910be7a94367/go.mod h1:3xt1FjdF8hUf6vQPIChWIBhFzV8gjjsPE/fR3IyQdNY=\ngolang.org/x/mobile v0.0.0-20190312151609-d3739f865fa6/go.mod h1:z+o9i4GpDbdi3rU15maQ/Ox0txvL9dWGYEHz965HBQE=\ngolang.org/x/mobile v0.0.0-20190719004257-d2bd2a29d028/go.mod h1:E/iHnbuqvinMTCcRqshq8CkpyQDoeVncDDYHnLhea+o=\ngolang.org/x/mod v0.0.0-20190513183733-4bf6d317e70e/go.mod h1:mXi4GBBbnImb6dmsKGUJ2LatrhH/nqhxcFungHvyanc=\ngolang.org/x/mod v0.1.0/go.mod h1:0QHyrYULN0/3qlju5TqG8bIK38QM8yzMo5ekMj3DlcY=\ngolang.org/x/mod v0.1.1-0.20191105210325-c90efee705ee/go.mod h1:QqPTAvyqsEbceGzBzNggFXnrqF1CaUcvgkdR5Ot7KZg=\ngolang.org/x/mod v0.2.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/mod v0.3.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/net v0.0.0-20180724234803-3673e40ba225/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20180826012351-8a410e7b638d/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190108225652-1e06a53dbb7e/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190213061140-3a22650c66bd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190311183353-d8887717615a/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190320064053-1272bf9dcd53/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190501004415-9ce7a6920f09/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190503192946-f4e77d36d62c/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190603091049-60506f45cf65/go.mod h1:HSz+uSET+XFnRR8LxR5pz3Of3rY3CfYBVs4xY44aLks=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20190724013045-ca1201d0de80/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20191209160850-c0dbc17a3553/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200202094626-16171245cfb2/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200222125558-5a598a2470a0/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200226121028-0de0cce0169b/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20201021035429-f5854403a974/go.mod h1:sp8m0HH+o8qH0wwXwYZr8TS3Oi6o0r6Gce1SSxlDquU=\ngolang.org/x/net v0.0.0-20210226172049-e18ecbb05110/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=\ngolang.org/x/net v0.33.0 h1:74SYHlV8BIgHIFC/LrYkOGIwL19eTYXQ5wc6TBuO36I=\ngolang.org/x/net v0.33.0/go.mod h1:HXLR5J+9DxmrqMwG9qjGCxZ+zKXxBru04zlTvWlWuN4=\ngolang.org/x/oauth2 v0.0.0-20180821212333-d2e6202438be/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=\ngolang.org/x/oauth2 v0.0.0-20190226205417-e64efc72b421/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\ngolang.org/x/oauth2 v0.0.0-20190604053449-0f29369cfe45/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\ngolang.org/x/oauth2 v0.0.0-20191202225959-858c2ad4c8b6/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\ngolang.org/x/oauth2 v0.0.0-20200107190931-bf48bf16ab8d/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\ngolang.org/x/oauth2 v0.24.0 h1:KTBBxWqUa0ykRPLtV69rRto9TLXcqYkeswu48x/gvNE=\ngolang.org/x/oauth2 v0.24.0/go.mod h1:XYTD2NtWslqkgxebSiOHnXEap4TF09sJSc7H1sXbhtI=\ngolang.org/x/sync v0.0.0-20180314180146-1d60e4601c6f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20181108010431-42b317875d0f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20181221193216-37e7f081c4d4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190227155943-e225da77a7e6/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190911185100-cd5d95a43a6e/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20201020160332-67f06af15bc9/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.10.0 h1:3NQrjDixjgGwUOCaF8w2+VYHv0Ve/vGYSbdkTa98gmQ=\ngolang.org/x/sync v0.10.0/go.mod h1:Czt+wKu1gCyEFDUtn0jG5QVvpJ6rzVqr5aXyt9drQfk=\ngolang.org/x/sys v0.0.0-20180830151530-49385e6e1522/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190312061237-fead79001313/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190502145724-3ef323f4f1fd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190507160741-ecd444e8653b/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190606165138-5da285871e9c/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190624142023-c5567b49c5d0/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190726091711-fc99dfbffb4e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191204072324-ce4227a45e2e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191228213918-04cbcbbfeed8/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200212091648-12a6c2dcc1e4/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200223170610-d5e6a3e2c0ae/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200930185726-fdedc70b468f/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210615035016-665e8c7367d1/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20211007075335-d3039528d8ac/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220811171246-fbc7d0a398ab/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.6.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.28.0 h1:Fksou7UEQUWlKvIdsqzJmUmCX3cZuD2+P3XyyzwMhlA=\ngolang.org/x/sys v0.28.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=\ngolang.org/x/term v0.27.0 h1:WP60Sv1nlK1T6SupCHbXzSaN0b9wUmsPoRS9b61A23Q=\ngolang.org/x/term v0.27.0/go.mod h1:iMsnZpn0cago0GOrHO2+Y7u7JPn5AylBrcoWkElMTSM=\ngolang.org/x/text v0.0.0-20170915032832-14c0d48ead0c/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.1-0.20180807135948-17ff2d5776d2/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.2/go.mod h1:bEr9sfX3Q8Zfm5fL9x+3itogRgK3+ptLWKqgva+5dAk=\ngolang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.7/go.mod h1:u+2+/6zg+i71rQMx5EYifcz6MCKuco9NR6JIITiCfzQ=\ngolang.org/x/text v0.21.0 h1:zyQAAkrwaneQ066sspRyJaG9VNi/YJ1NfzcGB3hZ/qo=\ngolang.org/x/text v0.21.0/go.mod h1:4IBbMaMmOPCJ8SecivzSH54+73PCFmPWxNTLm+vZkEQ=\ngolang.org/x/time v0.0.0-20181108054448-85acf8d2951c/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/time v0.0.0-20190308202827-9d24e82272b4/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/time v0.5.0 h1:o7cqy6amK/52YcAKIPlM3a+Fpj35zvRj2TP+e1xFSfk=\ngolang.org/x/time v0.5.0/go.mod h1:3BpzKBy/shNhVucY/MWOyx10tF3SFh9QdLuxbVysPQM=\ngolang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190114222345-bf090417da8b/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190226205152-f727befe758c/go.mod h1:9Yl7xja0Znq3iFh3HoIrodX9oNMXvdceNzlUR8zjMvY=\ngolang.org/x/tools v0.0.0-20190311212946-11955173bddd/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190312151545-0bb0c0a6e846/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190312170243-e65039ee4138/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190328211700-ab21143f2384/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190425150028-36563e24a262/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=\ngolang.org/x/tools v0.0.0-20190506145303-2d16b83fe98c/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=\ngolang.org/x/tools v0.0.0-20190524140312-2c0ae7006135/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=\ngolang.org/x/tools v0.0.0-20190606124116-d0a3d012864b/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=\ngolang.org/x/tools v0.0.0-20190621195816-6e04913cbbac/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=\ngolang.org/x/tools v0.0.0-20190628153133-6cdbf07be9d0/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=\ngolang.org/x/tools v0.0.0-20190816200558-6889da9d5479/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20190911174233-4f2ddba30aff/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191012152004-8de300cfc20a/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191113191852-77e3bb0ad9e7/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191115202509-3a792d9c32b2/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191125144606-a911d9008d1f/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191216173652-a0e659d51361/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20191227053925-7b8e75db28f4/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200130002326-2f3ba24bd6e7/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200207183749-b753a1ba74fa/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200212150539-ea181f53ac56/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200619180055-7c47624df98f/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\ngolang.org/x/tools v0.0.0-20210106214847-113979e3529a/go.mod h1:emZCQorbCU4vsT4fOWvOPXz4eW1wZW4PmDk9uLelYpA=\ngolang.org/x/tools v0.28.0 h1:WuB6qZ4RPCQo5aP3WdKZS7i595EdWqWR8vqJTlwTVK8=\ngolang.org/x/tools v0.28.0/go.mod h1:dcIOrVd3mfQKTgrDVQHqCPMWy6lnhfhtX3hLXYVLfRw=\ngolang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngomodules.xyz/jsonpatch/v2 v2.4.0 h1:Ci3iUJyx9UeRx7CeFN8ARgGbkESwJK+KB9lLcWxY/Zw=\ngomodules.xyz/jsonpatch/v2 v2.4.0/go.mod h1:AH3dM2RI6uoBZxn3LVrfvJ3E0/9dG4cSrbuBJT4moAY=\ngoogle.golang.org/api v0.4.0/go.mod h1:8k5glujaEP+g9n7WNsDg8QP6cUVNI86fCNMcbazEtwE=\ngoogle.golang.org/api v0.7.0/go.mod h1:WtwebWUNSVBH/HAw79HIFXZNqEvBhG+Ra+ax0hx3E3M=\ngoogle.golang.org/api v0.8.0/go.mod h1:o4eAsZoiT+ibD93RtjEohWalFOjRDx6CVaqeizhEnKg=\ngoogle.golang.org/api v0.9.0/go.mod h1:o4eAsZoiT+ibD93RtjEohWalFOjRDx6CVaqeizhEnKg=\ngoogle.golang.org/api v0.13.0/go.mod h1:iLdEw5Ide6rF15KTC1Kkl0iskquN2gFfn9o9XIsbkAI=\ngoogle.golang.org/api v0.14.0/go.mod h1:iLdEw5Ide6rF15KTC1Kkl0iskquN2gFfn9o9XIsbkAI=\ngoogle.golang.org/api v0.15.0/go.mod h1:iLdEw5Ide6rF15KTC1Kkl0iskquN2gFfn9o9XIsbkAI=\ngoogle.golang.org/api v0.17.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=\ngoogle.golang.org/appengine v1.1.0/go.mod h1:EbEs0AVv82hx2wNQdGPgUI5lhzA/G0D9YwlJXL52JkM=\ngoogle.golang.org/appengine v1.4.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=\ngoogle.golang.org/appengine v1.5.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=\ngoogle.golang.org/appengine v1.6.1/go.mod h1:i06prIuMbXzDqacNJfV5OdTW448YApPu5ww/cMBSeb0=\ngoogle.golang.org/appengine v1.6.5/go.mod h1:8WjMMxjGQR8xUklV/ARdw2HLXBOI7O7uCIDZVag1xfc=\ngoogle.golang.org/genproto v0.0.0-20180817151627-c66870c02cf8/go.mod h1:JiN7NxoALGmiZfu7CAH4rXhgtRTLTxftemlI0sWmxmc=\ngoogle.golang.org/genproto v0.0.0-20190307195333-5fe7a883aa19/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=\ngoogle.golang.org/genproto v0.0.0-20190418145605-e7d98fc518a7/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=\ngoogle.golang.org/genproto v0.0.0-20190425155659-357c62f0e4bb/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=\ngoogle.golang.org/genproto v0.0.0-20190502173448-54afdca5d873/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=\ngoogle.golang.org/genproto v0.0.0-20190801165951-fa694d86fc64/go.mod h1:DMBHOl98Agz4BDEuKkezgsaosCRResVns1a3J2ZsMNc=\ngoogle.golang.org/genproto v0.0.0-20190819201941-24fa4b261c55/go.mod h1:DMBHOl98Agz4BDEuKkezgsaosCRResVns1a3J2ZsMNc=\ngoogle.golang.org/genproto v0.0.0-20190911173649-1774047e7e51/go.mod h1:IbNlFCBrqXvoKpeg0TB2l7cyZUmoaFKYIwrEpbDKLA8=\ngoogle.golang.org/genproto v0.0.0-20191108220845-16a3f7862a1a/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20191115194625-c23dd37a84c9/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20191216164720-4f79533eabd1/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20191230161307-f3c370f40bfb/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20200212174721-66ed5ce911ce/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20240213162025-012b6fc9bca9 h1:9+tzLLstTlPTRyJTh+ah5wIMsBW5c4tQwGTN3thOW9Y=\ngoogle.golang.org/genproto v0.0.0-20240213162025-012b6fc9bca9/go.mod h1:mqHbVIp48Muh7Ywss/AD6I5kNVKZMmAa/QEW58Gxp2s=\ngoogle.golang.org/genproto/googleapis/api v0.0.0-20240528184218-531527333157 h1:7whR9kGa5LUwFtpLm2ArCEejtnxlGeLbAyjFY8sGNFw=\ngoogle.golang.org/genproto/googleapis/api v0.0.0-20240528184218-531527333157/go.mod h1:99sLkeliLXfdj2J75X3Ho+rrVCaJze0uwN7zDDkjPVU=\ngoogle.golang.org/genproto/googleapis/rpc v0.0.0-20240701130421-f6361c86f094 h1:BwIjyKYGsK9dMCBOorzRri8MQwmi7mT9rGHsCEinZkA=\ngoogle.golang.org/genproto/googleapis/rpc v0.0.0-20240701130421-f6361c86f094/go.mod h1:Ue6ibwXGpU+dqIcODieyLOcgj7z8+IcskoNIgZxtrFY=\ngoogle.golang.org/grpc v1.19.0/go.mod h1:mqu4LbDTu4XGKhr4mRzUsmM4RtVoemTSY81AxZiDr8c=\ngoogle.golang.org/grpc v1.20.1/go.mod h1:10oTOabMzJvdu6/UiuZezV6QK5dSlG84ov/aaiqXj38=\ngoogle.golang.org/grpc v1.21.1/go.mod h1:oYelfM1adQP15Ek0mdvEgi9Df8B9CZIaU1084ijfRaM=\ngoogle.golang.org/grpc v1.23.0/go.mod h1:Y5yQAOtifL1yxbo5wqy6BxZv8vAUGQwXBOALyacEbxg=\ngoogle.golang.org/grpc v1.26.0/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8abTk=\ngoogle.golang.org/grpc v1.27.0/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8abTk=\ngoogle.golang.org/grpc v1.27.1/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8abTk=\ngoogle.golang.org/grpc v1.65.1 h1:toSN4j5/Xju+HVovfaY5g1YZVuJeHzQZhP8eJ0L0f1I=\ngoogle.golang.org/grpc v1.65.1/go.mod h1:WgYC2ypjlB0EiQi6wdKixMqukr6lBc0Vo+oOgjrM5ZQ=\ngoogle.golang.org/protobuf v1.36.1 h1:yBPeRvTftaleIgM3PZ/WBIZ7XM/eEYAaEyCwvyjq/gk=\ngoogle.golang.org/protobuf v1.36.1/go.mod h1:9fA7Ob0pmnwhb644+1+CVWFRbNajQ6iRojtC/QF5bRE=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c h1:Hei/4ADfdWqJk1ZMxUNpqntNwaWcugrBjAiHlqqRiVk=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c/go.mod h1:JHkPIbrfpd72SG/EVd6muEfDQjcINNoR0C8j2r3qZ4Q=\ngopkg.in/errgo.v2 v2.1.0/go.mod h1:hNsd1EY+bozCKY1Ytp96fpM3vjJbqLJn88ws8XvfDNI=\ngopkg.in/evanphx/json-patch.v4 v4.12.0 h1:n6jtcsulIzXPJaxegRbvFNNrZDjbij7ny3gmSPG+6V4=\ngopkg.in/evanphx/json-patch.v4 v4.12.0/go.mod h1:p8EYWUEYMpynmqDbY58zCKCFZw8pRWMG4EsWvDvM72M=\ngopkg.in/inf.v0 v0.9.1 h1:73M5CoZyi3ZLMOyDlQh031Cx6N9NDJ2Vvfl76EDAgDc=\ngopkg.in/inf.v0 v0.9.1/go.mod h1:cWUDdTG/fYaXco+Dcufb5Vnc6Gp2YChqWtbxRZE0mXw=\ngopkg.in/ini.v1 v1.67.0 h1:Dgnx+6+nfE+IfzjUEISNeydPJh9AXNNsWbGP9KzCsOA=\ngopkg.in/ini.v1 v1.67.0/go.mod h1:pNLf8WUiyNEtQjuu5G5vTm06TEv9tsIgeAvK8hOrP4k=\ngopkg.in/natefinch/lumberjack.v2 v2.2.1 h1:bBRl1b0OH9s/DuPhuXpNl+VtCaJXFZ5/uEFST95x9zc=\ngopkg.in/natefinch/lumberjack.v2 v2.2.1/go.mod h1:YD8tP3GAjkrDg1eZH7EGmyESg/lsYskCTPBJVb9jqSc=\ngopkg.in/yaml.v2 v2.2.2/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.8/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.4.0 h1:D8xgwECY7CYvx+Y2n4sBz93Jn9JRvxdiyyo8CTfuKaY=\ngopkg.in/yaml.v2 v2.4.0/go.mod h1:RDklbk79AGWmwhnvt/jBztapEOGDOx6ZbXqjP6csGnQ=\ngopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.0-20210107192922-496545a6307b/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.0/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\nhonnef.co/go/tools v0.0.0-20190102054323-c2f93a96b099/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190106161140-3f1c8253044a/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190418001031-e561f6794a2a/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190523083050-ea95bdfd59fc/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.1-2019.2.3/go.mod h1:a3bituU0lyd329TUQxRnasdCoJDkEUEAqEt0JzvZhAg=\nk8s.io/api v0.31.4 h1:I2QNzitPVsPeLQvexMEsj945QumYraqv9m74isPDKhM=\nk8s.io/api v0.31.4/go.mod h1:d+7vgXLvmcdT1BCo79VEgJxHHryww3V5np2OYTr6jdw=\nk8s.io/apiextensions-apiserver v0.31.4 h1:FxbqzSvy92Ca9DIs5jqot883G0Ln/PGXfm/07t39LS0=\nk8s.io/apiextensions-apiserver v0.31.4/go.mod h1:hIW9YU8UsqZqIWGG99/gsdIU0Ar45Qd3A12QOe/rvpg=\nk8s.io/apimachinery v0.31.4 h1:8xjE2C4CzhYVm9DGf60yohpNUh5AEBnPxCryPBECmlM=\nk8s.io/apimachinery v0.31.4/go.mod h1:rsPdaZJfTfLsNJSQzNHQvYoTmxhoOEofxtOsF3rtsMo=\nk8s.io/apiserver v0.31.4 h1:JbtnTaXVYEAYIHJil6Wd74Wif9sd8jVcBw84kwEmp7o=\nk8s.io/apiserver v0.31.4/go.mod h1:JJjoTjZ9PTMLdIFq7mmcJy2B9xLN3HeAUebW6xZyIP0=\nk8s.io/client-go v0.31.4 h1:t4QEXt4jgHIkKKlx06+W3+1JOwAFU/2OPiOo7H92eRQ=\nk8s.io/client-go v0.31.4/go.mod h1:kvuMro4sFYIa8sulL5Gi5GFqUPvfH2O/dXuKstbaaeg=\nk8s.io/cluster-bootstrap v0.31.4 h1:/jLYowVtnU3OCkEUOsiqWduBsHJyz8CrW3aHjyB5t/8=\nk8s.io/cluster-bootstrap v0.31.4/go.mod h1:J36a0uLKbTAYcJuf4k0oxcGvtA5iGGJFYqmnH+aaVTM=\nk8s.io/component-base v0.31.4 h1:wCquJh4ul9O8nNBSB8N/o8+gbfu3BVQkVw9jAUY/Qtw=\nk8s.io/component-base v0.31.4/go.mod h1:G4dgtf5BccwiDT9DdejK0qM6zTK0jwDGEKnCmb9+u/s=\nk8s.io/klog/v2 v2.130.1 h1:n9Xl7H1Xvksem4KFG4PYbdQCQxqc/tTUyrgXaOhHSzk=\nk8s.io/klog/v2 v2.130.1/go.mod h1:3Jpz1GvMt720eyJH1ckRHK1EDfpxISzJ7I9OYgaDtPE=\nk8s.io/kube-openapi v0.0.0-20240228011516-70dd3763d340 h1:BZqlfIlq5YbRMFko6/PM7FjZpUb45WallggurYhKGag=\nk8s.io/kube-openapi v0.0.0-20240228011516-70dd3763d340/go.mod h1:yD4MZYeKMBwQKVht279WycxKyM84kkAx2DPrTXaeb98=\nk8s.io/utils v0.0.0-20240711033017-18e509b52bc8 h1:pUdcCO1Lk/tbT5ztQWOBi5HBgbBP1J8+AsQnQCKsi8A=\nk8s.io/utils v0.0.0-20240711033017-18e509b52bc8/go.mod h1:OLgZIPagt7ERELqWJFomSt595RzquPNLL48iOWgYOg0=\nrsc.io/binaryregexp v0.2.0/go.mod h1:qTv7/COck+e2FymRvadv62gMdZztPaShugOCi3I+8D8=\nrsc.io/quote/v3 v3.1.0/go.mod h1:yEA65RcK8LyAZtP9Kv3t0HmxON59tX3rD+tICJqUlj0=\nrsc.io/sampler v1.3.0/go.mod h1:T1hPZKmBbMNahiBKFy5HrXp6adAjACjK9JXDnKaTXpA=\nsigs.k8s.io/apiserver-network-proxy/konnectivity-client v0.30.3 h1:2770sDpzrjjsAtVhSeUFseziht227YAWYHLGNM8QPwY=\nsigs.k8s.io/apiserver-network-proxy/konnectivity-client v0.30.3/go.mod h1:Ve9uj1L+deCXFrPOk1LpFXqTg7LCFzFso6PA48q/XZw=\nsigs.k8s.io/controller-runtime v0.19.4 h1:SUmheabttt0nx8uJtoII4oIP27BVVvAKFvdvGFwV/Qo=\nsigs.k8s.io/controller-runtime v0.19.4/go.mod h1:iRmWllt8IlaLjvTTDLhRBXIEtkCK6hwVBJJsYS9Ajf4=\nsigs.k8s.io/json v0.0.0-20221116044647-bc3834ca7abd h1:EDPBXCAspyGV4jQlpZSudPeMmr1bNJefnuqLsRAsHZo=\nsigs.k8s.io/json v0.0.0-20221116044647-bc3834ca7abd/go.mod h1:B8JuhiUyNFVKdsE8h686QcCxMaH6HrOAZj4vswFpcB0=\nsigs.k8s.io/structured-merge-diff/v4 v4.4.1 h1:150L+0vs/8DA78h1u02ooW1/fFq/Lwr+sGiqlzvrtq4=\nsigs.k8s.io/structured-merge-diff/v4 v4.4.1/go.mod h1:N8hJocpFajUSSeSJ9bOZ77VzejKZaXsTtZo4/u7Io08=\nsigs.k8s.io/yaml v1.4.0 h1:Mk1wCc2gy/F0THH0TAp1QYyJNzRm2KCLy3o5ASXVI5E=\nsigs.k8s.io/yaml v1.4.0/go.mod h1:Ejl7/uTz7PSA4eKMyQCUTnhZYNmLIl+5c2lQPGR2BPY=\n"
        },
        {
          "name": "hack",
          "type": "tree",
          "content": null
        },
        {
          "name": "internal",
          "type": "tree",
          "content": null
        },
        {
          "name": "logos",
          "type": "tree",
          "content": null
        },
        {
          "name": "main.go",
          "type": "blob",
          "size": 28.0595703125,
          "content": "/*\nCopyright 2019 The Kubernetes Authors.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\n// main is the main package for the Cluster API Core Provider.\npackage main\n\nimport (\n\t\"context\"\n\t\"flag\"\n\t\"fmt\"\n\t\"os\"\n\tgoruntime \"runtime\"\n\t\"time\"\n\n\t\"github.com/pkg/errors\"\n\t\"github.com/spf13/pflag\"\n\tappsv1 \"k8s.io/api/apps/v1\"\n\tcorev1 \"k8s.io/api/core/v1\"\n\tstoragev1 \"k8s.io/api/storage/v1\"\n\tapiextensionsv1 \"k8s.io/apiextensions-apiserver/pkg/apis/apiextensions/v1\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/labels\"\n\t\"k8s.io/apimachinery/pkg/runtime\"\n\t\"k8s.io/apimachinery/pkg/selection\"\n\tclientgoscheme \"k8s.io/client-go/kubernetes/scheme\"\n\t\"k8s.io/client-go/tools/leaderelection/resourcelock\"\n\tcliflag \"k8s.io/component-base/cli/flag\"\n\t\"k8s.io/component-base/logs\"\n\tlogsv1 \"k8s.io/component-base/logs/api/v1\"\n\t_ \"k8s.io/component-base/logs/json/register\"\n\t\"k8s.io/klog/v2\"\n\tctrl \"sigs.k8s.io/controller-runtime\"\n\t\"sigs.k8s.io/controller-runtime/pkg/cache\"\n\t\"sigs.k8s.io/controller-runtime/pkg/client\"\n\t\"sigs.k8s.io/controller-runtime/pkg/controller\"\n\t\"sigs.k8s.io/controller-runtime/pkg/webhook\"\n\n\tclusterv1 \"sigs.k8s.io/cluster-api/api/v1beta1\"\n\t\"sigs.k8s.io/cluster-api/api/v1beta1/index\"\n\t\"sigs.k8s.io/cluster-api/controllers\"\n\t\"sigs.k8s.io/cluster-api/controllers/clustercache\"\n\t\"sigs.k8s.io/cluster-api/controllers/remote\"\n\taddonsv1 \"sigs.k8s.io/cluster-api/exp/addons/api/v1beta1\"\n\taddonscontrollers \"sigs.k8s.io/cluster-api/exp/addons/controllers\"\n\taddonswebhooks \"sigs.k8s.io/cluster-api/exp/addons/webhooks\"\n\texpv1 \"sigs.k8s.io/cluster-api/exp/api/v1beta1\"\n\texpcontrollers \"sigs.k8s.io/cluster-api/exp/controllers\"\n\tipamv1 \"sigs.k8s.io/cluster-api/exp/ipam/api/v1beta1\"\n\texpipamwebhooks \"sigs.k8s.io/cluster-api/exp/ipam/webhooks\"\n\truntimev1 \"sigs.k8s.io/cluster-api/exp/runtime/api/v1alpha1\"\n\truntimecatalog \"sigs.k8s.io/cluster-api/exp/runtime/catalog\"\n\truntimeclient \"sigs.k8s.io/cluster-api/exp/runtime/client\"\n\truntimecontrollers \"sigs.k8s.io/cluster-api/exp/runtime/controllers\"\n\truntimehooksv1 \"sigs.k8s.io/cluster-api/exp/runtime/hooks/api/v1alpha1\"\n\texpwebhooks \"sigs.k8s.io/cluster-api/exp/webhooks\"\n\t\"sigs.k8s.io/cluster-api/feature\"\n\taddonsv1alpha3 \"sigs.k8s.io/cluster-api/internal/apis/core/exp/addons/v1alpha3\"\n\taddonsv1alpha4 \"sigs.k8s.io/cluster-api/internal/apis/core/exp/addons/v1alpha4\"\n\texpv1alpha3 \"sigs.k8s.io/cluster-api/internal/apis/core/exp/v1alpha3\"\n\texpv1alpha4 \"sigs.k8s.io/cluster-api/internal/apis/core/exp/v1alpha4\"\n\tclusterv1alpha3 \"sigs.k8s.io/cluster-api/internal/apis/core/v1alpha3\"\n\tclusterv1alpha4 \"sigs.k8s.io/cluster-api/internal/apis/core/v1alpha4\"\n\tinternalruntimeclient \"sigs.k8s.io/cluster-api/internal/runtime/client\"\n\truntimeregistry \"sigs.k8s.io/cluster-api/internal/runtime/registry\"\n\truntimewebhooks \"sigs.k8s.io/cluster-api/internal/webhooks/runtime\"\n\t\"sigs.k8s.io/cluster-api/util/apiwarnings\"\n\t\"sigs.k8s.io/cluster-api/util/flags\"\n\t\"sigs.k8s.io/cluster-api/version\"\n\t\"sigs.k8s.io/cluster-api/webhooks\"\n)\n\nvar (\n\tcatalog        = runtimecatalog.New()\n\tscheme         = runtime.NewScheme()\n\tsetupLog       = ctrl.Log.WithName(\"setup\")\n\tcontrollerName = \"cluster-api-controller-manager\"\n\n\t// flags.\n\tenableLeaderElection        bool\n\tleaderElectionLeaseDuration time.Duration\n\tleaderElectionRenewDeadline time.Duration\n\tleaderElectionRetryPeriod   time.Duration\n\twatchFilterValue            string\n\twatchNamespace              string\n\tprofilerAddress             string\n\tenableContentionProfiling   bool\n\tsyncPeriod                  time.Duration\n\trestConfigQPS               float32\n\trestConfigBurst             int\n\tclusterCacheClientQPS       float32\n\tclusterCacheClientBurst     int\n\twebhookPort                 int\n\twebhookCertDir              string\n\twebhookCertName             string\n\twebhookKeyName              string\n\thealthAddr                  string\n\tmanagerOptions              = flags.ManagerOptions{}\n\tlogOptions                  = logs.NewOptions()\n\t// core Cluster API specific flags.\n\tremoteConnectionGracePeriod     time.Duration\n\tremoteConditionsGracePeriod     time.Duration\n\tclusterTopologyConcurrency      int\n\tclusterCacheConcurrency         int\n\tclusterClassConcurrency         int\n\tclusterConcurrency              int\n\textensionConfigConcurrency      int\n\tmachineConcurrency              int\n\tmachineSetConcurrency           int\n\tmachineDeploymentConcurrency    int\n\tmachinePoolConcurrency          int\n\tclusterResourceSetConcurrency   int\n\tmachineHealthCheckConcurrency   int\n\tuseDeprecatedInfraMachineNaming bool\n)\n\nfunc init() {\n\t_ = clientgoscheme.AddToScheme(scheme)\n\t_ = apiextensionsv1.AddToScheme(scheme)\n\t_ = storagev1.AddToScheme(scheme)\n\n\t_ = clusterv1alpha3.AddToScheme(scheme)\n\t_ = clusterv1alpha4.AddToScheme(scheme)\n\t_ = clusterv1.AddToScheme(scheme)\n\n\t_ = expv1alpha3.AddToScheme(scheme)\n\t_ = expv1alpha4.AddToScheme(scheme)\n\t_ = expv1.AddToScheme(scheme)\n\n\t_ = addonsv1alpha3.AddToScheme(scheme)\n\t_ = addonsv1alpha4.AddToScheme(scheme)\n\t_ = addonsv1.AddToScheme(scheme)\n\n\t_ = runtimev1.AddToScheme(scheme)\n\n\t_ = ipamv1.AddToScheme(scheme)\n\n\t// Register the RuntimeHook types into the catalog.\n\t_ = runtimehooksv1.AddToCatalog(catalog)\n}\n\n// InitFlags initializes the flags.\nfunc InitFlags(fs *pflag.FlagSet) {\n\tlogsv1.AddFlags(logOptions, fs)\n\n\tfs.BoolVar(&enableLeaderElection, \"leader-elect\", false,\n\t\t\"Enable leader election for controller manager. Enabling this will ensure there is only one active controller manager.\")\n\n\tfs.DurationVar(&leaderElectionLeaseDuration, \"leader-elect-lease-duration\", 15*time.Second,\n\t\t\"Interval at which non-leader candidates will wait to force acquire leadership (duration string)\")\n\n\tfs.DurationVar(&leaderElectionRenewDeadline, \"leader-elect-renew-deadline\", 10*time.Second,\n\t\t\"Duration that the leading controller manager will retry refreshing leadership before giving up (duration string)\")\n\n\tfs.DurationVar(&leaderElectionRetryPeriod, \"leader-elect-retry-period\", 2*time.Second,\n\t\t\"Duration the LeaderElector clients should wait between tries of actions (duration string)\")\n\n\tfs.StringVar(&watchNamespace, \"namespace\", \"\",\n\t\t\"Namespace that the controller watches to reconcile cluster-api objects. If unspecified, the controller watches for cluster-api objects across all namespaces.\")\n\n\tfs.StringVar(&watchFilterValue, \"watch-filter\", \"\",\n\t\tfmt.Sprintf(\"Label value that the controller watches to reconcile cluster-api objects. Label key is always %s. If unspecified, the controller watches for all cluster-api objects.\", clusterv1.WatchLabel))\n\n\tfs.StringVar(&profilerAddress, \"profiler-address\", \"\",\n\t\t\"Bind address to expose the pprof profiler (e.g. localhost:6060)\")\n\n\tfs.BoolVar(&enableContentionProfiling, \"contention-profiling\", false,\n\t\t\"Enable block profiling\")\n\n\tfs.DurationVar(&remoteConnectionGracePeriod, \"remote-connection-grace-period\", 50*time.Second,\n\t\t\"Grace period after which the RemoteConnectionProbe condition on a Cluster goes to `False`, \"+\n\t\t\t\"the grace period starts from the last successful health probe to the workload cluster\")\n\n\tfs.DurationVar(&remoteConditionsGracePeriod, \"remote-conditions-grace-period\", 5*time.Minute,\n\t\t\"Grace period after which remote conditions (e.g. `NodeHealthy`) are set to `Unknown`, \"+\n\t\t\t\"the grace period starts from the last successful health probe to the workload cluster\")\n\n\tfs.IntVar(&clusterTopologyConcurrency, \"clustertopology-concurrency\", 10,\n\t\t\"Number of clusters to process simultaneously\")\n\n\tfs.IntVar(&clusterClassConcurrency, \"clusterclass-concurrency\", 10,\n\t\t\"Number of ClusterClasses to process simultaneously\")\n\n\tfs.IntVar(&clusterConcurrency, \"cluster-concurrency\", 10,\n\t\t\"Number of clusters to process simultaneously\")\n\n\tfs.IntVar(&clusterCacheConcurrency, \"clustercache-concurrency\", 100,\n\t\t\"Number of clusters to process simultaneously\")\n\n\tfs.IntVar(&extensionConfigConcurrency, \"extensionconfig-concurrency\", 10,\n\t\t\"Number of extension configs to process simultaneously\")\n\n\tfs.IntVar(&machineConcurrency, \"machine-concurrency\", 10,\n\t\t\"Number of machines to process simultaneously\")\n\n\tfs.IntVar(&machineSetConcurrency, \"machineset-concurrency\", 10,\n\t\t\"Number of machine sets to process simultaneously\")\n\n\tfs.IntVar(&machineDeploymentConcurrency, \"machinedeployment-concurrency\", 10,\n\t\t\"Number of machine deployments to process simultaneously\")\n\n\tfs.IntVar(&machinePoolConcurrency, \"machinepool-concurrency\", 10,\n\t\t\"Number of machine pools to process simultaneously\")\n\n\tfs.IntVar(&clusterResourceSetConcurrency, \"clusterresourceset-concurrency\", 10,\n\t\t\"Number of cluster resource sets to process simultaneously\")\n\n\tfs.IntVar(&machineHealthCheckConcurrency, \"machinehealthcheck-concurrency\", 10,\n\t\t\"Number of machine health checks to process simultaneously\")\n\n\tfs.DurationVar(&syncPeriod, \"sync-period\", 10*time.Minute,\n\t\t\"The minimum interval at which watched resources are reconciled (e.g. 15m)\")\n\n\tfs.Float32Var(&restConfigQPS, \"kube-api-qps\", 20,\n\t\t\"Maximum queries per second from the controller client to the Kubernetes API server.\")\n\n\tfs.IntVar(&restConfigBurst, \"kube-api-burst\", 30,\n\t\t\"Maximum number of queries that should be allowed in one burst from the controller client to the Kubernetes API server.\")\n\n\tfs.Float32Var(&clusterCacheClientQPS, \"clustercache-client-qps\", 20,\n\t\t\"Maximum queries per second from the cluster cache clients to the Kubernetes API server of workload clusters.\")\n\n\tfs.IntVar(&clusterCacheClientBurst, \"clustercache-client-burst\", 30,\n\t\t\"Maximum number of queries that should be allowed in one burst from the cluster cache clients to the Kubernetes API server of workload clusters.\")\n\n\tfs.IntVar(&webhookPort, \"webhook-port\", 9443,\n\t\t\"Webhook Server port\")\n\n\tfs.StringVar(&webhookCertDir, \"webhook-cert-dir\", \"/tmp/k8s-webhook-server/serving-certs/\",\n\t\t\"Webhook cert dir.\")\n\n\tfs.StringVar(&webhookCertName, \"webhook-cert-name\", \"tls.crt\",\n\t\t\"Webhook cert name.\")\n\n\tfs.StringVar(&webhookKeyName, \"webhook-key-name\", \"tls.key\",\n\t\t\"Webhook key name.\")\n\n\tfs.StringVar(&healthAddr, \"health-addr\", \":9440\",\n\t\t\"The address the health endpoint binds to.\")\n\n\tfs.BoolVar(&useDeprecatedInfraMachineNaming, \"use-deprecated-infra-machine-naming\", false,\n\t\t\"Use deprecated infrastructure machine naming\")\n\t_ = fs.MarkDeprecated(\"use-deprecated-infra-machine-naming\", \"This flag will be removed in v1.9.\")\n\n\tflags.AddManagerOptions(fs, &managerOptions)\n\n\tfeature.MutableGates.AddFlag(fs)\n}\n\n// Add RBAC for the authorized diagnostics endpoint.\n// +kubebuilder:rbac:groups=authentication.k8s.io,resources=tokenreviews,verbs=create\n// +kubebuilder:rbac:groups=authorization.k8s.io,resources=subjectaccessreviews,verbs=create\n\nfunc main() {\n\tInitFlags(pflag.CommandLine)\n\tpflag.CommandLine.SetNormalizeFunc(cliflag.WordSepNormalizeFunc)\n\tpflag.CommandLine.AddGoFlagSet(flag.CommandLine)\n\t// Set log level 2 as default.\n\tif err := pflag.CommandLine.Set(\"v\", \"2\"); err != nil {\n\t\tsetupLog.Error(err, \"Failed to set default log level\")\n\t\tos.Exit(1)\n\t}\n\tpflag.Parse()\n\n\tif err := logsv1.ValidateAndApply(logOptions, nil); err != nil {\n\t\tsetupLog.Error(err, \"Unable to start manager\")\n\t\tos.Exit(1)\n\t}\n\n\t// klog.Background will automatically use the right logger.\n\tctrl.SetLogger(klog.Background())\n\n\trestConfig := ctrl.GetConfigOrDie()\n\trestConfig.QPS = restConfigQPS\n\trestConfig.Burst = restConfigBurst\n\trestConfig.UserAgent = remote.DefaultClusterAPIUserAgent(controllerName)\n\trestConfig.WarningHandler = apiwarnings.DefaultHandler(klog.Background().WithName(\"API Server Warning\"))\n\n\tminVer := version.MinimumKubernetesVersion\n\tif feature.Gates.Enabled(feature.ClusterTopology) {\n\t\tminVer = version.MinimumKubernetesVersionClusterTopology\n\t}\n\n\tif !(remoteConditionsGracePeriod > remoteConnectionGracePeriod) {\n\t\tsetupLog.Error(errors.Errorf(\"--remote-conditions-grace-period must be greater than --remote-connection-grace-period\"), \"Unable to start manager\")\n\t\tos.Exit(1)\n\t}\n\tif remoteConditionsGracePeriod < 2*time.Minute {\n\t\t// A minimum of 2m is enforced to ensure the ClusterCache always drops the connection before the grace period is reached.\n\t\t// In the worst case the ClusterCache will take FailureThreshold x (Interval + Timeout) = 5x(10s+5s) = 75s to drop a\n\t\t// connection. There might be some additional delays in health checking under high load. So we use 2m as a minimum\n\t\t// to have some buffer.\n\t\tsetupLog.Error(errors.Errorf(\"--remote-conditions-grace-period must be at least 2m\"), \"Unable to start manager\")\n\t\tos.Exit(1)\n\t}\n\n\tif err := version.CheckKubernetesVersion(restConfig, minVer); err != nil {\n\t\tsetupLog.Error(err, \"Unable to start manager\")\n\t\tos.Exit(1)\n\t}\n\n\ttlsOptions, metricsOptions, err := flags.GetManagerOptions(managerOptions)\n\tif err != nil {\n\t\tsetupLog.Error(err, \"Unable to start manager: invalid flags\")\n\t\tos.Exit(1)\n\t}\n\n\tvar watchNamespaces map[string]cache.Config\n\tif watchNamespace != \"\" {\n\t\twatchNamespaces = map[string]cache.Config{\n\t\t\twatchNamespace: {},\n\t\t}\n\t}\n\n\tif enableContentionProfiling {\n\t\tgoruntime.SetBlockProfileRate(1)\n\t}\n\n\treq, _ := labels.NewRequirement(clusterv1.ClusterNameLabel, selection.Exists, nil)\n\tclusterSecretCacheSelector := labels.NewSelector().Add(*req)\n\n\tctrlOptions := ctrl.Options{\n\t\tScheme:                     scheme,\n\t\tLeaderElection:             enableLeaderElection,\n\t\tLeaderElectionID:           \"controller-leader-election-capi\",\n\t\tLeaseDuration:              &leaderElectionLeaseDuration,\n\t\tRenewDeadline:              &leaderElectionRenewDeadline,\n\t\tRetryPeriod:                &leaderElectionRetryPeriod,\n\t\tLeaderElectionResourceLock: resourcelock.LeasesResourceLock,\n\t\tHealthProbeBindAddress:     healthAddr,\n\t\tPprofBindAddress:           profilerAddress,\n\t\tMetrics:                    *metricsOptions,\n\t\tCache: cache.Options{\n\t\t\tDefaultNamespaces: watchNamespaces,\n\t\t\tSyncPeriod:        &syncPeriod,\n\t\t\tByObject: map[client.Object]cache.ByObject{\n\t\t\t\t// Note: Only Secrets with the cluster name label are cached.\n\t\t\t\t// The default client of the manager won't use the cache for secrets at all (see Client.Cache.DisableFor).\n\t\t\t\t// The cached secrets will only be used by the secretCachingClient we create below.\n\t\t\t\t&corev1.Secret{}: {\n\t\t\t\t\tLabel: clusterSecretCacheSelector,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tClient: client.Options{\n\t\t\tCache: &client.CacheOptions{\n\t\t\t\tDisableFor: []client.Object{\n\t\t\t\t\t&corev1.ConfigMap{},\n\t\t\t\t\t&corev1.Secret{},\n\t\t\t\t},\n\t\t\t\t// Use the cache for all Unstructured get/list calls.\n\t\t\t\tUnstructured: true,\n\t\t\t},\n\t\t},\n\t\tWebhookServer: webhook.NewServer(\n\t\t\twebhook.Options{\n\t\t\t\tPort:     webhookPort,\n\t\t\t\tCertDir:  webhookCertDir,\n\t\t\t\tCertName: webhookCertName,\n\t\t\t\tKeyName:  webhookKeyName,\n\t\t\t\tTLSOpts:  tlsOptions,\n\t\t\t},\n\t\t),\n\t}\n\n\tmgr, err := ctrl.NewManager(restConfig, ctrlOptions)\n\tif err != nil {\n\t\tsetupLog.Error(err, \"Unable to start manager\")\n\t\tos.Exit(1)\n\t}\n\n\t// Setup the context that's going to be used in controllers and for the manager.\n\tctx := ctrl.SetupSignalHandler()\n\n\tsetupChecks(mgr)\n\tsetupIndexes(ctx, mgr)\n\tclusterCache := setupReconcilers(ctx, mgr, watchNamespaces, &syncPeriod)\n\tsetupWebhooks(mgr, clusterCache)\n\n\tsetupLog.Info(\"Starting manager\", \"version\", version.Get().String())\n\tif err := mgr.Start(ctx); err != nil {\n\t\tsetupLog.Error(err, \"Problem running manager\")\n\t\tos.Exit(1)\n\t}\n}\n\nfunc setupChecks(mgr ctrl.Manager) {\n\tif err := mgr.AddReadyzCheck(\"webhook\", mgr.GetWebhookServer().StartedChecker()); err != nil {\n\t\tsetupLog.Error(err, \"Unable to create ready check\")\n\t\tos.Exit(1)\n\t}\n\n\tif err := mgr.AddHealthzCheck(\"webhook\", mgr.GetWebhookServer().StartedChecker()); err != nil {\n\t\tsetupLog.Error(err, \"Unable to create health check\")\n\t\tos.Exit(1)\n\t}\n}\n\nfunc setupIndexes(ctx context.Context, mgr ctrl.Manager) {\n\tif err := index.AddDefaultIndexes(ctx, mgr); err != nil {\n\t\tsetupLog.Error(err, \"Unable to setup indexes\")\n\t\tos.Exit(1)\n\t}\n}\n\nfunc setupReconcilers(ctx context.Context, mgr ctrl.Manager, watchNamespaces map[string]cache.Config, syncPeriod *time.Duration) clustercache.ClusterCache {\n\tsecretCachingClient, err := client.New(mgr.GetConfig(), client.Options{\n\t\tHTTPClient: mgr.GetHTTPClient(),\n\t\tCache: &client.CacheOptions{\n\t\t\tReader: mgr.GetCache(),\n\t\t},\n\t})\n\tif err != nil {\n\t\tsetupLog.Error(err, \"Unable to create secret caching client\")\n\t\tos.Exit(1)\n\t}\n\n\tclusterCache, err := clustercache.SetupWithManager(ctx, mgr, clustercache.Options{\n\t\tSecretClient: secretCachingClient,\n\t\tCache: clustercache.CacheOptions{\n\t\t\tIndexes: []clustercache.CacheOptionsIndex{clustercache.NodeProviderIDIndex},\n\t\t},\n\t\tClient: clustercache.ClientOptions{\n\t\t\tQPS:       clusterCacheClientQPS,\n\t\t\tBurst:     clusterCacheClientBurst,\n\t\t\tUserAgent: remote.DefaultClusterAPIUserAgent(controllerName),\n\t\t\tCache: clustercache.ClientCacheOptions{\n\t\t\t\tDisableFor: []client.Object{\n\t\t\t\t\t// Don't cache ConfigMaps & Secrets.\n\t\t\t\t\t&corev1.ConfigMap{},\n\t\t\t\t\t&corev1.Secret{},\n\t\t\t\t\t// Don't cache Pods & DaemonSets (we get/list them e.g. during drain).\n\t\t\t\t\t&corev1.Pod{},\n\t\t\t\t\t&appsv1.DaemonSet{},\n\t\t\t\t\t// Don't cache PersistentVolumes and VolumeAttachments (we get/list them e.g. during wait for volumes to detach)\n\t\t\t\t\t&storagev1.VolumeAttachment{},\n\t\t\t\t\t&corev1.PersistentVolume{},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tWatchFilterValue: watchFilterValue,\n\t}, concurrency(clusterCacheConcurrency))\n\tif err != nil {\n\t\tsetupLog.Error(err, \"Unable to create ClusterCache\")\n\t\tos.Exit(1)\n\t}\n\n\tvar runtimeClient runtimeclient.Client\n\tif feature.Gates.Enabled(feature.RuntimeSDK) {\n\t\t// This is the creation of the runtimeClient for the controllers, embedding a shared catalog and registry instance.\n\t\truntimeClient = internalruntimeclient.New(internalruntimeclient.Options{\n\t\t\tCatalog:  catalog,\n\t\t\tRegistry: runtimeregistry.New(),\n\t\t\tClient:   mgr.GetClient(),\n\t\t})\n\t}\n\n\t// Setup a separate cache without label selector for secrets, to be used\n\t// when we need to watch for secrets that are not specific to a single cluster (e.g. ClusterResourceSet or ExtensionConfig controllers).\n\tpartialSecretCache, err := cache.New(mgr.GetConfig(), cache.Options{\n\t\tScheme:            mgr.GetScheme(),\n\t\tMapper:            mgr.GetRESTMapper(),\n\t\tHTTPClient:        mgr.GetHTTPClient(),\n\t\tSyncPeriod:        syncPeriod,\n\t\tDefaultNamespaces: watchNamespaces,\n\t\tDefaultTransform: func(in interface{}) (interface{}, error) {\n\t\t\t// Use DefaultTransform to drop objects we don't expect to get into this cache.\n\t\t\tobj, ok := in.(*metav1.PartialObjectMetadata)\n\t\t\tif !ok {\n\t\t\t\tpanic(fmt.Sprintf(\"cache expected to only get PartialObjectMetadata, got %T\", in))\n\t\t\t}\n\t\t\tif obj.GetObjectKind().GroupVersionKind() != corev1.SchemeGroupVersion.WithKind(\"Secret\") {\n\t\t\t\tpanic(fmt.Sprintf(\"cache expected to only get Secrets, got %s\", obj.GetObjectKind()))\n\t\t\t}\n\t\t\t// Additionally strip managed fields.\n\t\t\treturn cache.TransformStripManagedFields()(obj)\n\t\t},\n\t})\n\tif err != nil {\n\t\tsetupLog.Error(err, \"Failed to create cache for metadata only Secret watches\")\n\t\tos.Exit(1)\n\t}\n\tif err := mgr.Add(partialSecretCache); err != nil {\n\t\tsetupLog.Error(err, \"Failed to start cache for metadata only Secret watches\")\n\t\tos.Exit(1)\n\t}\n\n\tif feature.Gates.Enabled(feature.ClusterTopology) {\n\t\tif err := (&controllers.ClusterClassReconciler{\n\t\t\tClient:           mgr.GetClient(),\n\t\t\tRuntimeClient:    runtimeClient,\n\t\t\tWatchFilterValue: watchFilterValue,\n\t\t}).SetupWithManager(ctx, mgr, concurrency(clusterClassConcurrency)); err != nil {\n\t\t\tsetupLog.Error(err, \"Unable to create controller\", \"controller\", \"ClusterClass\")\n\t\t\tos.Exit(1)\n\t\t}\n\n\t\tif err := (&controllers.ClusterTopologyReconciler{\n\t\t\tClient:           mgr.GetClient(),\n\t\t\tAPIReader:        mgr.GetAPIReader(),\n\t\t\tRuntimeClient:    runtimeClient,\n\t\t\tClusterCache:     clusterCache,\n\t\t\tWatchFilterValue: watchFilterValue,\n\t\t}).SetupWithManager(ctx, mgr, concurrency(clusterTopologyConcurrency)); err != nil {\n\t\t\tsetupLog.Error(err, \"Unable to create controller\", \"controller\", \"ClusterTopology\")\n\t\t\tos.Exit(1)\n\t\t}\n\n\t\tif err := (&controllers.MachineDeploymentTopologyReconciler{\n\t\t\tClient:           mgr.GetClient(),\n\t\t\tAPIReader:        mgr.GetAPIReader(),\n\t\t\tWatchFilterValue: watchFilterValue,\n\t\t}).SetupWithManager(ctx, mgr, controller.Options{}); err != nil {\n\t\t\tsetupLog.Error(err, \"Unable to create controller\", \"controller\", \"MachineDeploymentTopology\")\n\t\t\tos.Exit(1)\n\t\t}\n\n\t\tif err := (&controllers.MachineSetTopologyReconciler{\n\t\t\tClient:           mgr.GetClient(),\n\t\t\tAPIReader:        mgr.GetAPIReader(),\n\t\t\tWatchFilterValue: watchFilterValue,\n\t\t}).SetupWithManager(ctx, mgr, controller.Options{}); err != nil {\n\t\t\tsetupLog.Error(err, \"Unable to create controller\", \"controller\", \"MachineSetTopology\")\n\t\t\tos.Exit(1)\n\t\t}\n\t}\n\n\tif feature.Gates.Enabled(feature.RuntimeSDK) {\n\t\tif err = (&runtimecontrollers.ExtensionConfigReconciler{\n\t\t\tClient:           mgr.GetClient(),\n\t\t\tAPIReader:        mgr.GetAPIReader(),\n\t\t\tRuntimeClient:    runtimeClient,\n\t\t\tWatchFilterValue: watchFilterValue,\n\t\t}).SetupWithManager(ctx, mgr, concurrency(extensionConfigConcurrency), partialSecretCache); err != nil {\n\t\t\tsetupLog.Error(err, \"Unable to create controller\", \"controller\", \"ExtensionConfig\")\n\t\t\tos.Exit(1)\n\t\t}\n\t}\n\n\tif err := (&controllers.ClusterReconciler{\n\t\tClient:                      mgr.GetClient(),\n\t\tAPIReader:                   mgr.GetAPIReader(),\n\t\tClusterCache:                clusterCache,\n\t\tWatchFilterValue:            watchFilterValue,\n\t\tRemoteConnectionGracePeriod: remoteConnectionGracePeriod,\n\t}).SetupWithManager(ctx, mgr, concurrency(clusterConcurrency)); err != nil {\n\t\tsetupLog.Error(err, \"Unable to create controller\", \"controller\", \"Cluster\")\n\t\tos.Exit(1)\n\t}\n\tif err := (&controllers.MachineReconciler{\n\t\tClient:                      mgr.GetClient(),\n\t\tAPIReader:                   mgr.GetAPIReader(),\n\t\tClusterCache:                clusterCache,\n\t\tWatchFilterValue:            watchFilterValue,\n\t\tRemoteConditionsGracePeriod: remoteConditionsGracePeriod,\n\t}).SetupWithManager(ctx, mgr, concurrency(machineConcurrency)); err != nil {\n\t\tsetupLog.Error(err, \"Unable to create controller\", \"controller\", \"Machine\")\n\t\tos.Exit(1)\n\t}\n\tif err := (&controllers.MachineSetReconciler{\n\t\tClient:                       mgr.GetClient(),\n\t\tAPIReader:                    mgr.GetAPIReader(),\n\t\tClusterCache:                 clusterCache,\n\t\tWatchFilterValue:             watchFilterValue,\n\t\tDeprecatedInfraMachineNaming: useDeprecatedInfraMachineNaming,\n\t}).SetupWithManager(ctx, mgr, concurrency(machineSetConcurrency)); err != nil {\n\t\tsetupLog.Error(err, \"Unable to create controller\", \"controller\", \"MachineSet\")\n\t\tos.Exit(1)\n\t}\n\tif err := (&controllers.MachineDeploymentReconciler{\n\t\tClient:           mgr.GetClient(),\n\t\tAPIReader:        mgr.GetAPIReader(),\n\t\tWatchFilterValue: watchFilterValue,\n\t}).SetupWithManager(ctx, mgr, concurrency(machineDeploymentConcurrency)); err != nil {\n\t\tsetupLog.Error(err, \"Unable to create controller\", \"controller\", \"MachineDeployment\")\n\t\tos.Exit(1)\n\t}\n\n\tif feature.Gates.Enabled(feature.MachinePool) {\n\t\tif err := (&expcontrollers.MachinePoolReconciler{\n\t\t\tClient:           mgr.GetClient(),\n\t\t\tAPIReader:        mgr.GetAPIReader(),\n\t\t\tClusterCache:     clusterCache,\n\t\t\tWatchFilterValue: watchFilterValue,\n\t\t}).SetupWithManager(ctx, mgr, concurrency(machinePoolConcurrency)); err != nil {\n\t\t\tsetupLog.Error(err, \"Unable to create controller\", \"controller\", \"MachinePool\")\n\t\t\tos.Exit(1)\n\t\t}\n\t}\n\n\tif feature.Gates.Enabled(feature.ClusterResourceSet) {\n\t\tif err := (&addonscontrollers.ClusterResourceSetReconciler{\n\t\t\tClient:           mgr.GetClient(),\n\t\t\tClusterCache:     clusterCache,\n\t\t\tWatchFilterValue: watchFilterValue,\n\t\t}).SetupWithManager(ctx, mgr, concurrency(clusterResourceSetConcurrency), partialSecretCache); err != nil {\n\t\t\tsetupLog.Error(err, \"Unable to create controller\", \"controller\", \"ClusterResourceSet\")\n\t\t\tos.Exit(1)\n\t\t}\n\t\tif err := (&addonscontrollers.ClusterResourceSetBindingReconciler{\n\t\t\tClient:           mgr.GetClient(),\n\t\t\tWatchFilterValue: watchFilterValue,\n\t\t}).SetupWithManager(ctx, mgr, concurrency(clusterResourceSetConcurrency)); err != nil {\n\t\t\tsetupLog.Error(err, \"Unable to create controller\", \"controller\", \"ClusterResourceSetBinding\")\n\t\t\tos.Exit(1)\n\t\t}\n\t}\n\n\tif err := (&controllers.MachineHealthCheckReconciler{\n\t\tClient:           mgr.GetClient(),\n\t\tClusterCache:     clusterCache,\n\t\tWatchFilterValue: watchFilterValue,\n\t}).SetupWithManager(ctx, mgr, concurrency(machineHealthCheckConcurrency)); err != nil {\n\t\tsetupLog.Error(err, \"Unable to create controller\", \"controller\", \"MachineHealthCheck\")\n\t\tos.Exit(1)\n\t}\n\n\treturn clusterCache\n}\n\nfunc setupWebhooks(mgr ctrl.Manager, clusterCacheReader webhooks.ClusterCacheReader) {\n\t// NOTE: ClusterClass and managed topologies are behind ClusterTopology feature gate flag; the webhook\n\t// is going to prevent creating or updating new objects in case the feature flag is disabled.\n\tif err := (&webhooks.ClusterClass{Client: mgr.GetClient()}).SetupWebhookWithManager(mgr); err != nil {\n\t\tsetupLog.Error(err, \"Unable to create webhook\", \"webhook\", \"ClusterClass\")\n\t\tos.Exit(1)\n\t}\n\n\t// NOTE: ClusterClass and managed topologies are behind ClusterTopology feature gate flag; the webhook\n\t// is going to prevent usage of Cluster.Topology in case the feature flag is disabled.\n\tif err := (&webhooks.Cluster{Client: mgr.GetClient(), ClusterCacheReader: clusterCacheReader}).SetupWebhookWithManager(mgr); err != nil {\n\t\tsetupLog.Error(err, \"Unable to create webhook\", \"webhook\", \"Cluster\")\n\t\tos.Exit(1)\n\t}\n\n\tif err := (&webhooks.Machine{}).SetupWebhookWithManager(mgr); err != nil {\n\t\tsetupLog.Error(err, \"Unable to create webhook\", \"webhook\", \"Machine\")\n\t\tos.Exit(1)\n\t}\n\n\tif err := (&webhooks.MachineSet{}).SetupWebhookWithManager(mgr); err != nil {\n\t\tsetupLog.Error(err, \"Unable to create webhook\", \"webhook\", \"MachineSet\")\n\t\tos.Exit(1)\n\t}\n\n\tif err := (&webhooks.MachineDeployment{}).SetupWebhookWithManager(mgr); err != nil {\n\t\tsetupLog.Error(err, \"Unable to create webhook\", \"webhook\", \"MachineDeployment\")\n\t\tos.Exit(1)\n\t}\n\n\tif err := (&webhooks.MachineDrainRule{}).SetupWebhookWithManager(mgr); err != nil {\n\t\tsetupLog.Error(err, \"Unable to create webhook\", \"webhook\", \"MachineDrainRule\")\n\t\tos.Exit(1)\n\t}\n\n\t// NOTE: MachinePool is behind MachinePool feature gate flag; the webhook\n\t// is going to prevent creating or updating new objects in case the feature flag is disabled\n\tif err := (&expwebhooks.MachinePool{}).SetupWebhookWithManager(mgr); err != nil {\n\t\tsetupLog.Error(err, \"Unable to create webhook\", \"webhook\", \"MachinePool\")\n\t\tos.Exit(1)\n\t}\n\n\t// NOTE: ClusterResourceSet is behind ClusterResourceSet feature gate flag; the webhook\n\t// is going to prevent creating or updating new objects in case the feature flag is disabled\n\tif err := (&addonswebhooks.ClusterResourceSet{}).SetupWebhookWithManager(mgr); err != nil {\n\t\tsetupLog.Error(err, \"Unable to create webhook\", \"webhook\", \"ClusterResourceSet\")\n\t\tos.Exit(1)\n\t}\n\t// NOTE: ClusterResourceSetBinding is behind ClusterResourceSet feature gate flag; the webhook\n\t// is going to prevent creating or updating new objects in case the feature flag is disabled\n\tif err := (&addonswebhooks.ClusterResourceSetBinding{}).SetupWebhookWithManager(mgr); err != nil {\n\t\tsetupLog.Error(err, \"Unable to create webhook\", \"webhook\", \"ClusterResourceSetBinding\")\n\t\tos.Exit(1)\n\t}\n\n\tif err := (&webhooks.MachineHealthCheck{}).SetupWebhookWithManager(mgr); err != nil {\n\t\tsetupLog.Error(err, \"Unable to create webhook\", \"webhook\", \"MachineHealthCheck\")\n\t\tos.Exit(1)\n\t}\n\n\t// NOTE: ExtensionConfig is behind the RuntimeSDK feature gate flag. The webhook will prevent creating or updating\n\t// new objects if the feature flag is disabled.\n\tif err := (&runtimewebhooks.ExtensionConfig{}).SetupWebhookWithManager(mgr); err != nil {\n\t\tsetupLog.Error(err, \"Unable to create webhook\", \"webhook\", \"ExtensionConfig\")\n\t\tos.Exit(1)\n\t}\n\n\tif err := (&expipamwebhooks.IPAddress{\n\t\t// We are using GetAPIReader here to avoid caching all IPAddressClaims\n\t\tClient: mgr.GetAPIReader(),\n\t}).SetupWebhookWithManager(mgr); err != nil {\n\t\tsetupLog.Error(err, \"Unable to create webhook\", \"webhook\", \"IPAddress\")\n\t\tos.Exit(1)\n\t}\n\tif err := (&expipamwebhooks.IPAddressClaim{}).SetupWebhookWithManager(mgr); err != nil {\n\t\tsetupLog.Error(err, \"Unable to create webhook\", \"webhook\", \"IPAddressClaim\")\n\t\tos.Exit(1)\n\t}\n}\n\nfunc concurrency(c int) controller.Options {\n\treturn controller.Options{MaxConcurrentReconciles: c}\n}\n"
        },
        {
          "name": "metadata.yaml",
          "type": "blob",
          "size": 0.83203125,
          "content": "# maps release series of major.minor to cluster-api contract version\n# the contract version may change between minor or major versions, but *not*\n# between patch versions.\n#\n# update this file only when a new major or minor version is released\napiVersion: clusterctl.cluster.x-k8s.io/v1alpha3\nkind: Metadata\nreleaseSeries:\n  - major: 1\n    minor: 10\n    contract: v1beta1\n  - major: 1\n    minor: 9\n    contract: v1beta1\n  - major: 1\n    minor: 8\n    contract: v1beta1\n  - major: 1\n    minor: 7\n    contract: v1beta1\n  - major: 1\n    minor: 6\n    contract: v1beta1\n  - major: 1\n    minor: 5\n    contract: v1beta1\n  - major: 1\n    minor: 4\n    contract: v1beta1\n  - major: 1\n    minor: 3\n    contract: v1beta1\n  - major: 1\n    minor: 2\n    contract: v1beta1\n  - major: 1\n    minor: 1\n    contract: v1beta1\n  - major: 1\n    minor: 0\n    contract: v1beta1\n"
        },
        {
          "name": "netlify.toml",
          "type": "blob",
          "size": 0.880859375,
          "content": "# Netlify build instructions\n[build]\n    command = \"make -C docs/book build\"\n    publish = \"docs/book/book\"\n\n[build.environment]\n    GO_VERSION = \"1.22.4\"\n\n# Standard Netlify redirects\n[[redirects]]\n    from = \"https://main--kubernetes-sigs-cluster-api.netlify.com/*\"\n    to = \"https://main.cluster-api.sigs.k8s.io/:splat\"\n    status = 301\n    force = true\n\n# HTTP-to-HTTPS rules\n[[redirects]]\n    from = \"http://main.cluster-api.sigs.k8s.io/*\"\n    to = \"https://main.cluster-api.sigs.k8s.io/:splat\"\n    status = 301\n    force = true\n\n[[redirects]]\n    from = \"http://main--kubernetes-sigs-cluster-api.netlify.com/*\"\n    to = \"http://main.cluster-api.sigs.k8s.io/:splat\"\n    status = 301\n    force = true\n\n[[headers]]\n    for = \"/tasks/experimental-features/runtime-sdk/runtime-sdk-openapi.yaml\"\n    [headers.values]\n        Access-Control-Allow-Origin = \"*\"\n        Access-Control-Allow-Methods = \"*\"\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "util",
          "type": "tree",
          "content": null
        },
        {
          "name": "version",
          "type": "tree",
          "content": null
        },
        {
          "name": "webhooks",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}