{
  "metadata": {
    "timestamp": 1736566679553,
    "page": 234,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "Jeffail/tunny",
      "stars": 3938,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".golangci.yml",
          "type": "blob",
          "size": 0.6103515625,
          "content": "run:\n  timeout: 30s\n\nissues:\n  max-issues-per-linter: 0\n  max-same-issues: 0\n\nlinters-settings:\n  gocritic:\n    enabled-tags:\n      - diagnostic\n      - experimental\n      - opinionated\n      - performance\n      - style\n\nlinters:\n  disable-all: true\n  enable:\n    # Default linters reported by golangci-lint help linters` in v1.39.0\n    - deadcode\n    - errcheck\n    - gosimple\n    - govet\n    - gosimple\n    - ineffassign\n    - staticcheck\n    - structcheck\n    - stylecheck\n    - typecheck\n    - unused\n    - varcheck\n    # Extra linters:\n    - gofmt\n    - goimports\n    - gocritic\n    - revive\n    - bodyclose\n    - gosec\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.03125,
          "content": "Copyright (c) 2014 Ashley Jeffs\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 3.6455078125,
          "content": "![Tunny](tunny_logo.png \"Tunny\")\n\n[![godoc for Jeffail/tunny][1]][2]\n[![goreportcard for Jeffail/tunny][3]][4]\n\nTunny is a Golang library for spawning and managing a goroutine pool, allowing\nyou to limit work coming from any number of goroutines with a synchronous API.\n\nA fixed goroutine pool is helpful when you have work coming from an arbitrary\nnumber of asynchronous sources, but a limited capacity for parallel processing.\nFor example, when processing jobs from HTTP requests that are CPU heavy you can\ncreate a pool with a size that matches your CPU count.\n\n## Install\n\n``` sh\ngo get github.com/Jeffail/tunny\n```\n\nOr, using dep:\n\n``` sh\ndep ensure -add github.com/Jeffail/tunny\n```\n\n## Use\n\nFor most cases your heavy work can be expressed in a simple `func()`, where you\ncan use `NewFunc`. Let's see how this looks using our HTTP requests to CPU count\nexample:\n\n``` go\npackage main\n\nimport (\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"runtime\"\n\n\t\"github.com/Jeffail/tunny\"\n)\n\nfunc main() {\n\tnumCPUs := runtime.NumCPU()\n\n\tpool := tunny.NewFunc(numCPUs, func(payload interface{}) interface{} {\n\t\tvar result []byte\n\n\t\t// TODO: Something CPU heavy with payload\n\n\t\treturn result\n\t})\n\tdefer pool.Close()\n\n\thttp.HandleFunc(\"/work\", func(w http.ResponseWriter, r *http.Request) {\n\t\tinput, err := ioutil.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"Internal error\", http.StatusInternalServerError)\n\t\t}\n\t\tdefer r.Body.Close()\n\n\t\t// Funnel this work into our pool. This call is synchronous and will\n\t\t// block until the job is completed.\n\t\tresult := pool.Process(input)\n\n\t\tw.Write(result.([]byte))\n\t})\n\n\thttp.ListenAndServe(\":8080\", nil)\n}\n```\n\nTunny also supports timeouts. You can replace the `Process` call above to the\nfollowing:\n\n``` go\nresult, err := pool.ProcessTimed(input, time.Second*5)\nif err == tunny.ErrJobTimedOut {\n\thttp.Error(w, \"Request timed out\", http.StatusRequestTimeout)\n}\n```\n\nYou can also use the context from the request (or any other context) to handle timeouts and deadlines. Simply replace the `Process` call to the following:\n\n``` go\nresult, err := pool.ProcessCtx(r.Context(), input)\nif err == context.DeadlineExceeded {\n\thttp.Error(w, \"Request timed out\", http.StatusRequestTimeout)\n}\n```\n\n## Changing Pool Size\n\nThe size of a Tunny pool can be changed at any time with `SetSize(int)`:\n\n``` go\npool.SetSize(10) // 10 goroutines\npool.SetSize(100) // 100 goroutines\n```\n\nThis is safe to perform from any goroutine even if others are still processing.\n\n## Goroutines With State\n\nSometimes each goroutine within a Tunny pool will require its own managed state.\nIn this case you should implement [`tunny.Worker`][tunny-worker], which includes\ncalls for terminating, interrupting (in case a job times out and is no longer\nneeded) and blocking the next job allocation until a condition is met.\n\nWhen creating a pool using `Worker` types you will need to provide a constructor\nfunction for spawning your custom implementation:\n\n``` go\npool := tunny.New(poolSize, func() Worker {\n\t// TODO: Any per-goroutine state allocation here.\n\treturn newCustomWorker()\n})\n```\n\nThis allows Tunny to create and destroy `Worker` types cleanly when the pool\nsize is changed.\n\n## Ordering\n\nBacklogged jobs are not guaranteed to be processed in order. Due to the current\nimplementation of channels and select blocks a stack of backlogged jobs will be\nprocessed as a FIFO queue. However, this behaviour is not part of the spec and\nshould not be relied upon.\n\n[1]: https://godoc.org/github.com/Jeffail/tunny?status.svg\n[2]: http://godoc.org/github.com/Jeffail/tunny\n[3]: https://goreportcard.com/badge/github.com/Jeffail/tunny\n[4]: https://goreportcard.com/report/Jeffail/tunny\n[tunny-worker]: https://godoc.org/github.com/Jeffail/tunny#Worker\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.0400390625,
          "content": "module github.com/Jeffail/tunny\n\ngo 1.13\n"
        },
        {
          "name": "tunny.go",
          "type": "blob",
          "size": 8.5732421875,
          "content": "// Copyright (c) 2014 Ashley Jeffs\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\npackage tunny\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n)\n\n//------------------------------------------------------------------------------\n\n// Errors that are used throughout the Tunny API.\nvar (\n\tErrPoolNotRunning = errors.New(\"the pool is not running\")\n\tErrJobNotFunc     = errors.New(\"generic worker not given a func()\")\n\tErrWorkerClosed   = errors.New(\"worker was closed\")\n\tErrJobTimedOut    = errors.New(\"job request timed out\")\n)\n\n// Worker is an interface representing a Tunny working agent. It will be used to\n// block a calling goroutine until ready to process a job, process that job\n// synchronously, interrupt its own process call when jobs are abandoned, and\n// clean up its resources when being removed from the pool.\n//\n// Each of these duties are implemented as a single method and can be averted\n// when not needed by simply implementing an empty func.\ntype Worker interface {\n\t// Process will synchronously perform a job and return the result.\n\tProcess(interface{}) interface{}\n\n\t// BlockUntilReady is called before each job is processed and must block the\n\t// calling goroutine until the Worker is ready to process the next job.\n\tBlockUntilReady()\n\n\t// Interrupt is called when a job is cancelled. The worker is responsible\n\t// for unblocking the Process implementation.\n\tInterrupt()\n\n\t// Terminate is called when a Worker is removed from the processing pool\n\t// and is responsible for cleaning up any held resources.\n\tTerminate()\n}\n\n//------------------------------------------------------------------------------\n\n// closureWorker is a minimal Worker implementation that simply wraps a\n// func(interface{}) interface{}\ntype closureWorker struct {\n\tprocessor func(interface{}) interface{}\n}\n\nfunc (w *closureWorker) Process(payload interface{}) interface{} {\n\treturn w.processor(payload)\n}\n\nfunc (w *closureWorker) BlockUntilReady() {}\nfunc (w *closureWorker) Interrupt()       {}\nfunc (w *closureWorker) Terminate()       {}\n\n//------------------------------------------------------------------------------\n\n// callbackWorker is a minimal Worker implementation that attempts to cast\n// each job into func() and either calls it if successful or returns\n// ErrJobNotFunc.\ntype callbackWorker struct{}\n\nfunc (w *callbackWorker) Process(payload interface{}) interface{} {\n\tf, ok := payload.(func())\n\tif !ok {\n\t\treturn ErrJobNotFunc\n\t}\n\tf()\n\treturn nil\n}\n\nfunc (w *callbackWorker) BlockUntilReady() {}\nfunc (w *callbackWorker) Interrupt()       {}\nfunc (w *callbackWorker) Terminate()       {}\n\n//------------------------------------------------------------------------------\n\n// Pool is a struct that manages a collection of workers, each with their own\n// goroutine. The Pool can initialize, expand, compress and close the workers,\n// as well as processing jobs with the workers synchronously.\ntype Pool struct {\n\tqueuedJobs int64\n\n\tctor    func() Worker\n\tworkers []*workerWrapper\n\treqChan chan workRequest\n\n\tworkerMut sync.Mutex\n}\n\n// New creates a new Pool of workers that starts with n workers. You must\n// provide a constructor function that creates new Worker types and when you\n// change the size of the pool the constructor will be called to create each new\n// Worker.\nfunc New(n int, ctor func() Worker) *Pool {\n\tp := &Pool{\n\t\tctor:    ctor,\n\t\treqChan: make(chan workRequest),\n\t}\n\tp.SetSize(n)\n\n\treturn p\n}\n\n// NewFunc creates a new Pool of workers where each worker will process using\n// the provided func.\nfunc NewFunc(n int, f func(interface{}) interface{}) *Pool {\n\treturn New(n, func() Worker {\n\t\treturn &closureWorker{\n\t\t\tprocessor: f,\n\t\t}\n\t})\n}\n\n// NewCallback creates a new Pool of workers where workers cast the job payload\n// into a func() and runs it, or returns ErrNotFunc if the cast failed.\nfunc NewCallback(n int) *Pool {\n\treturn New(n, func() Worker {\n\t\treturn &callbackWorker{}\n\t})\n}\n\n//------------------------------------------------------------------------------\n\n// Process will use the Pool to process a payload and synchronously return the\n// result. Process can be called safely by any goroutines, but will panic if the\n// Pool has been stopped.\nfunc (p *Pool) Process(payload interface{}) interface{} {\n\tatomic.AddInt64(&p.queuedJobs, 1)\n\n\trequest, open := <-p.reqChan\n\tif !open {\n\t\tpanic(ErrPoolNotRunning)\n\t}\n\n\trequest.jobChan <- payload\n\n\tpayload, open = <-request.retChan\n\tif !open {\n\t\tpanic(ErrWorkerClosed)\n\t}\n\n\tatomic.AddInt64(&p.queuedJobs, -1)\n\treturn payload\n}\n\n// ProcessTimed will use the Pool to process a payload and synchronously return\n// the result. If the timeout occurs before the job has finished the worker will\n// be interrupted and ErrJobTimedOut will be returned. ProcessTimed can be\n// called safely by any goroutines.\nfunc (p *Pool) ProcessTimed(\n\tpayload interface{},\n\ttimeout time.Duration,\n) (interface{}, error) {\n\tatomic.AddInt64(&p.queuedJobs, 1)\n\tdefer atomic.AddInt64(&p.queuedJobs, -1)\n\n\ttout := time.NewTimer(timeout)\n\n\tvar request workRequest\n\tvar open bool\n\n\tselect {\n\tcase request, open = <-p.reqChan:\n\t\tif !open {\n\t\t\treturn nil, ErrPoolNotRunning\n\t\t}\n\tcase <-tout.C:\n\t\treturn nil, ErrJobTimedOut\n\t}\n\n\tselect {\n\tcase request.jobChan <- payload:\n\tcase <-tout.C:\n\t\trequest.interruptFunc()\n\t\treturn nil, ErrJobTimedOut\n\t}\n\n\tselect {\n\tcase payload, open = <-request.retChan:\n\t\tif !open {\n\t\t\treturn nil, ErrWorkerClosed\n\t\t}\n\tcase <-tout.C:\n\t\trequest.interruptFunc()\n\t\treturn nil, ErrJobTimedOut\n\t}\n\n\ttout.Stop()\n\treturn payload, nil\n}\n\n// ProcessCtx will use the Pool to process a payload and synchronously return\n// the result. If the context cancels before the job has finished the worker will\n// be interrupted and ErrJobTimedOut will be returned. ProcessCtx can be\n// called safely by any goroutines.\nfunc (p *Pool) ProcessCtx(ctx context.Context, payload interface{}) (interface{}, error) {\n\tatomic.AddInt64(&p.queuedJobs, 1)\n\tdefer atomic.AddInt64(&p.queuedJobs, -1)\n\n\tvar request workRequest\n\tvar open bool\n\n\tselect {\n\tcase request, open = <-p.reqChan:\n\t\tif !open {\n\t\t\treturn nil, ErrPoolNotRunning\n\t\t}\n\tcase <-ctx.Done():\n\t\treturn nil, ctx.Err()\n\t}\n\n\tselect {\n\tcase request.jobChan <- payload:\n\tcase <-ctx.Done():\n\t\trequest.interruptFunc()\n\t\treturn nil, ctx.Err()\n\t}\n\n\tselect {\n\tcase payload, open = <-request.retChan:\n\t\tif !open {\n\t\t\treturn nil, ErrWorkerClosed\n\t\t}\n\tcase <-ctx.Done():\n\t\trequest.interruptFunc()\n\t\treturn nil, ctx.Err()\n\t}\n\n\treturn payload, nil\n}\n\n// QueueLength returns the current count of pending queued jobs.\nfunc (p *Pool) QueueLength() int64 {\n\treturn atomic.LoadInt64(&p.queuedJobs)\n}\n\n// SetSize changes the total number of workers in the Pool. This can be called\n// by any goroutine at any time unless the Pool has been stopped, in which case\n// a panic will occur.\nfunc (p *Pool) SetSize(n int) {\n\tp.workerMut.Lock()\n\tdefer p.workerMut.Unlock()\n\n\tlWorkers := len(p.workers)\n\tif lWorkers == n {\n\t\treturn\n\t}\n\n\t// Add extra workers if N > len(workers)\n\tfor i := lWorkers; i < n; i++ {\n\t\tp.workers = append(p.workers, newWorkerWrapper(p.reqChan, p.ctor()))\n\t}\n\n\t// Asynchronously stop all workers > N\n\tfor i := n; i < lWorkers; i++ {\n\t\tp.workers[i].stop()\n\t}\n\n\t// Synchronously wait for all workers > N to stop\n\tfor i := n; i < lWorkers; i++ {\n\t\tp.workers[i].join()\n\t\tp.workers[i] = nil\n\t}\n\n\t// Remove stopped workers from slice\n\tp.workers = p.workers[:n]\n}\n\n// GetSize returns the current size of the pool.\nfunc (p *Pool) GetSize() int {\n\tp.workerMut.Lock()\n\tdefer p.workerMut.Unlock()\n\n\treturn len(p.workers)\n}\n\n// Close will terminate all workers and close the job channel of this Pool.\nfunc (p *Pool) Close() {\n\tp.SetSize(0)\n\tclose(p.reqChan)\n}\n\n//------------------------------------------------------------------------------\n"
        },
        {
          "name": "tunny_logo.png",
          "type": "blob",
          "size": 52.0322265625,
          "content": null
        },
        {
          "name": "tunny_test.go",
          "type": "blob",
          "size": 8.375,
          "content": "// Copyright (c) 2014 Ashley Jeffs\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\npackage tunny\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\n//------------------------------------------------------------------------------\n\nfunc TestPoolSizeAdjustment(t *testing.T) {\n\tpool := NewFunc(10, func(interface{}) interface{} { return \"foo\" })\n\tif exp, act := 10, len(pool.workers); exp != act {\n\t\tt.Errorf(\"Wrong size of pool: %v != %v\", act, exp)\n\t}\n\n\tpool.SetSize(10)\n\tif exp, act := 10, pool.GetSize(); exp != act {\n\t\tt.Errorf(\"Wrong size of pool: %v != %v\", act, exp)\n\t}\n\n\tpool.SetSize(9)\n\tif exp, act := 9, pool.GetSize(); exp != act {\n\t\tt.Errorf(\"Wrong size of pool: %v != %v\", act, exp)\n\t}\n\n\tpool.SetSize(10)\n\tif exp, act := 10, pool.GetSize(); exp != act {\n\t\tt.Errorf(\"Wrong size of pool: %v != %v\", act, exp)\n\t}\n\n\tpool.SetSize(0)\n\tif exp, act := 0, pool.GetSize(); exp != act {\n\t\tt.Errorf(\"Wrong size of pool: %v != %v\", act, exp)\n\t}\n\n\tpool.SetSize(10)\n\tif exp, act := 10, pool.GetSize(); exp != act {\n\t\tt.Errorf(\"Wrong size of pool: %v != %v\", act, exp)\n\t}\n\n\t// Finally, make sure we still have actual active workers.\n\tif exp, act := \"foo\", pool.Process(0).(string); exp != act {\n\t\tt.Errorf(\"Wrong result: %v != %v\", act, exp)\n\t}\n\n\tpool.Close()\n\tif exp, act := 0, pool.GetSize(); exp != act {\n\t\tt.Errorf(\"Wrong size of pool: %v != %v\", act, exp)\n\t}\n}\n\n//------------------------------------------------------------------------------\n\nfunc TestFuncJob(t *testing.T) {\n\tpool := NewFunc(10, func(in interface{}) interface{} {\n\t\tintVal := in.(int)\n\t\treturn intVal * 2\n\t})\n\tdefer pool.Close()\n\n\tfor i := 0; i < 10; i++ {\n\t\tret := pool.Process(10)\n\t\tif exp, act := 20, ret.(int); exp != act {\n\t\t\tt.Errorf(\"Wrong result: %v != %v\", act, exp)\n\t\t}\n\t}\n}\n\nfunc TestFuncJobTimed(t *testing.T) {\n\tpool := NewFunc(10, func(in interface{}) interface{} {\n\t\tintVal := in.(int)\n\t\treturn intVal * 2\n\t})\n\tdefer pool.Close()\n\n\tfor i := 0; i < 10; i++ {\n\t\tret, err := pool.ProcessTimed(10, time.Millisecond)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Failed to process: %v\", err)\n\t\t}\n\t\tif exp, act := 20, ret.(int); exp != act {\n\t\t\tt.Errorf(\"Wrong result: %v != %v\", act, exp)\n\t\t}\n\t}\n}\n\nfunc TestFuncJobCtx(t *testing.T) {\n\tt.Run(\"Completes when ctx not canceled\", func(t *testing.T) {\n\t\tpool := NewFunc(10, func(in interface{}) interface{} {\n\t\t\tintVal := in.(int)\n\t\t\treturn intVal * 2\n\t\t})\n\t\tdefer pool.Close()\n\n\t\tfor i := 0; i < 10; i++ {\n\t\t\tret, err := pool.ProcessCtx(context.Background(), 10)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Failed to process: %v\", err)\n\t\t\t}\n\t\t\tif exp, act := 20, ret.(int); exp != act {\n\t\t\t\tt.Errorf(\"Wrong result: %v != %v\", act, exp)\n\t\t\t}\n\t\t}\n\t})\n\n\tt.Run(\"Returns err when ctx canceled\", func(t *testing.T) {\n\t\tpool := NewFunc(1, func(in interface{}) interface{} {\n\t\t\tintVal := in.(int)\n\t\t\t<-time.After(time.Millisecond)\n\t\t\treturn intVal * 2\n\t\t})\n\t\tdefer pool.Close()\n\n\t\tctx, cancel := context.WithTimeout(context.Background(), time.Nanosecond)\n\t\tdefer cancel()\n\t\t_, act := pool.ProcessCtx(ctx, 10)\n\t\tif exp := context.DeadlineExceeded; exp != act {\n\t\t\tt.Errorf(\"Wrong error returned: %v != %v\", act, exp)\n\t\t}\n\t})\n}\n\nfunc TestCallbackJob(t *testing.T) {\n\tpool := NewCallback(10)\n\tdefer pool.Close()\n\n\tvar counter int32\n\tfor i := 0; i < 10; i++ {\n\t\tret := pool.Process(func() {\n\t\t\tatomic.AddInt32(&counter, 1)\n\t\t})\n\t\tif ret != nil {\n\t\t\tt.Errorf(\"Non-nil callback response: %v\", ret)\n\t\t}\n\t}\n\n\tret := pool.Process(\"foo\")\n\tif exp, act := ErrJobNotFunc, ret; exp != act {\n\t\tt.Errorf(\"Wrong result from non-func: %v != %v\", act, exp)\n\t}\n\n\tif exp, act := int32(10), counter; exp != act {\n\t\tt.Errorf(\"Wrong result: %v != %v\", act, exp)\n\t}\n}\n\nfunc TestTimeout(t *testing.T) {\n\tpool := NewFunc(1, func(in interface{}) interface{} {\n\t\tintVal := in.(int)\n\t\t<-time.After(time.Millisecond)\n\t\treturn intVal * 2\n\t})\n\tdefer pool.Close()\n\n\t_, act := pool.ProcessTimed(10, time.Duration(1))\n\tif exp := ErrJobTimedOut; exp != act {\n\t\tt.Errorf(\"Wrong error returned: %v != %v\", act, exp)\n\t}\n}\n\nfunc TestTimedJobsAfterClose(t *testing.T) {\n\tpool := NewFunc(1, func(in interface{}) interface{} {\n\t\treturn 1\n\t})\n\tpool.Close()\n\n\t_, act := pool.ProcessTimed(10, time.Duration(10*time.Millisecond))\n\tif exp := ErrPoolNotRunning; exp != act {\n\t\tt.Errorf(\"Wrong error returned: %v != %v\", act, exp)\n\t}\n}\n\nfunc TestJobsAfterClose(t *testing.T) {\n\tpool := NewFunc(1, func(in interface{}) interface{} {\n\t\treturn 1\n\t})\n\tpool.Close()\n\n\tdefer func() {\n\t\tif r := recover(); r == nil {\n\t\t\tt.Errorf(\"Process after Stop() did not panic\")\n\t\t}\n\t}()\n\n\tpool.Process(10)\n}\n\nfunc TestParallelJobs(t *testing.T) {\n\tnWorkers := 10\n\n\tjobGroup := sync.WaitGroup{}\n\ttestGroup := sync.WaitGroup{}\n\n\tpool := NewFunc(nWorkers, func(in interface{}) interface{} {\n\t\tjobGroup.Done()\n\t\tjobGroup.Wait()\n\n\t\tintVal := in.(int)\n\t\treturn intVal * 2\n\t})\n\tdefer pool.Close()\n\n\tfor j := 0; j < 1; j++ {\n\t\tjobGroup.Add(nWorkers)\n\t\ttestGroup.Add(nWorkers)\n\n\t\tfor i := 0; i < nWorkers; i++ {\n\t\t\tgo func() {\n\t\t\t\tret := pool.Process(10)\n\t\t\t\tif exp, act := 20, ret.(int); exp != act {\n\t\t\t\t\tt.Errorf(\"Wrong result: %v != %v\", act, exp)\n\t\t\t\t}\n\t\t\t\ttestGroup.Done()\n\t\t\t}()\n\t\t}\n\n\t\ttestGroup.Wait()\n\t}\n}\n\n//------------------------------------------------------------------------------\n\ntype mockWorker struct {\n\tblockProcChan  chan struct{}\n\tblockReadyChan chan struct{}\n\tinterruptChan  chan struct{}\n\tterminated     bool\n}\n\nfunc (m *mockWorker) Process(in interface{}) interface{} {\n\tselect {\n\tcase <-m.blockProcChan:\n\tcase <-m.interruptChan:\n\t}\n\treturn in\n}\n\nfunc (m *mockWorker) BlockUntilReady() {\n\t<-m.blockReadyChan\n}\n\nfunc (m *mockWorker) Interrupt() {\n\tm.interruptChan <- struct{}{}\n}\n\nfunc (m *mockWorker) Terminate() {\n\tm.terminated = true\n}\n\nfunc TestCustomWorker(t *testing.T) {\n\tpool := New(1, func() Worker {\n\t\treturn &mockWorker{\n\t\t\tblockProcChan:  make(chan struct{}),\n\t\t\tblockReadyChan: make(chan struct{}),\n\t\t\tinterruptChan:  make(chan struct{}),\n\t\t}\n\t})\n\n\tworker1, ok := pool.workers[0].worker.(*mockWorker)\n\tif !ok {\n\t\tt.Fatal(\"Wrong type of worker in pool\")\n\t}\n\n\tif worker1.terminated {\n\t\tt.Fatal(\"Worker started off terminated\")\n\t}\n\n\t_, err := pool.ProcessTimed(10, time.Millisecond)\n\tif exp, act := ErrJobTimedOut, err; exp != act {\n\t\tt.Errorf(\"Wrong error: %v != %v\", act, exp)\n\t}\n\n\tclose(worker1.blockReadyChan)\n\t_, err = pool.ProcessTimed(10, time.Millisecond)\n\tif exp, act := ErrJobTimedOut, err; exp != act {\n\t\tt.Errorf(\"Wrong error: %v != %v\", act, exp)\n\t}\n\n\tclose(worker1.blockProcChan)\n\tif exp, act := 10, pool.Process(10).(int); exp != act {\n\t\tt.Errorf(\"Wrong result: %v != %v\", act, exp)\n\t}\n\n\tpool.Close()\n\tif !worker1.terminated {\n\t\tt.Fatal(\"Worker was not terminated\")\n\t}\n}\n\n//------------------------------------------------------------------------------\n\nfunc BenchmarkFuncJob(b *testing.B) {\n\tpool := NewFunc(10, func(in interface{}) interface{} {\n\t\tintVal := in.(int)\n\t\treturn intVal * 2\n\t})\n\tdefer pool.Close()\n\n\tb.ResetTimer()\n\n\tfor i := 0; i < b.N; i++ {\n\t\tret := pool.Process(10)\n\t\tif exp, act := 20, ret.(int); exp != act {\n\t\t\tb.Errorf(\"Wrong result: %v != %v\", act, exp)\n\t\t}\n\t}\n}\n\nfunc BenchmarkFuncTimedJob(b *testing.B) {\n\tpool := NewFunc(10, func(in interface{}) interface{} {\n\t\tintVal := in.(int)\n\t\treturn intVal * 2\n\t})\n\tdefer pool.Close()\n\n\tb.ResetTimer()\n\n\tfor i := 0; i < b.N; i++ {\n\t\tret, err := pool.ProcessTimed(10, time.Second)\n\t\tif err != nil {\n\t\t\tb.Error(err)\n\t\t}\n\t\tif exp, act := 20, ret.(int); exp != act {\n\t\t\tb.Errorf(\"Wrong result: %v != %v\", act, exp)\n\t\t}\n\t}\n}\n\n//------------------------------------------------------------------------------\n"
        },
        {
          "name": "worker.go",
          "type": "blob",
          "size": 3.7158203125,
          "content": "// Copyright (c) 2014 Ashley Jeffs\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\npackage tunny\n\n//------------------------------------------------------------------------------\n\n// workRequest is a struct containing context representing a workers intention\n// to receive a work payload.\ntype workRequest struct {\n\t// jobChan is used to send the payload to this worker.\n\tjobChan chan<- interface{}\n\n\t// retChan is used to read the result from this worker.\n\tretChan <-chan interface{}\n\n\t// interruptFunc can be called to cancel a running job. When called it is no\n\t// longer necessary to read from retChan.\n\tinterruptFunc func()\n}\n\n//------------------------------------------------------------------------------\n\n// workerWrapper takes a Worker implementation and wraps it within a goroutine\n// and channel arrangement. The workerWrapper is responsible for managing the\n// lifetime of both the Worker and the goroutine.\ntype workerWrapper struct {\n\tworker        Worker\n\tinterruptChan chan struct{}\n\n\t// reqChan is NOT owned by this type, it is used to send requests for work.\n\treqChan chan<- workRequest\n\n\t// closeChan can be closed in order to cleanly shutdown this worker.\n\tcloseChan chan struct{}\n\n\t// closedChan is closed by the run() goroutine when it exits.\n\tclosedChan chan struct{}\n}\n\nfunc newWorkerWrapper(\n\treqChan chan<- workRequest,\n\tworker Worker,\n) *workerWrapper {\n\tw := workerWrapper{\n\t\tworker:        worker,\n\t\tinterruptChan: make(chan struct{}),\n\t\treqChan:       reqChan,\n\t\tcloseChan:     make(chan struct{}),\n\t\tclosedChan:    make(chan struct{}),\n\t}\n\n\tgo w.run()\n\n\treturn &w\n}\n\n//------------------------------------------------------------------------------\n\nfunc (w *workerWrapper) interrupt() {\n\tclose(w.interruptChan)\n\tw.worker.Interrupt()\n}\n\nfunc (w *workerWrapper) run() {\n\tjobChan, retChan := make(chan interface{}), make(chan interface{})\n\tdefer func() {\n\t\tw.worker.Terminate()\n\t\tclose(retChan)\n\t\tclose(w.closedChan)\n\t}()\n\n\tfor {\n\t\t// NOTE: Blocking here will prevent the worker from closing down.\n\t\tw.worker.BlockUntilReady()\n\t\tselect {\n\t\tcase w.reqChan <- workRequest{\n\t\t\tjobChan:       jobChan,\n\t\t\tretChan:       retChan,\n\t\t\tinterruptFunc: w.interrupt,\n\t\t}:\n\t\t\tselect {\n\t\t\tcase payload := <-jobChan:\n\t\t\t\tresult := w.worker.Process(payload)\n\t\t\t\tselect {\n\t\t\t\tcase retChan <- result:\n\t\t\t\tcase <-w.interruptChan:\n\t\t\t\t\tw.interruptChan = make(chan struct{})\n\t\t\t\t}\n\t\t\tcase <-w.interruptChan:\n\t\t\t\tw.interruptChan = make(chan struct{})\n\t\t\t}\n\t\tcase <-w.closeChan:\n\t\t\treturn\n\t\t}\n\t}\n}\n\n//------------------------------------------------------------------------------\n\nfunc (w *workerWrapper) stop() {\n\tclose(w.closeChan)\n}\n\nfunc (w *workerWrapper) join() {\n\t<-w.closedChan\n}\n\n//------------------------------------------------------------------------------\n"
        }
      ]
    }
  ]
}