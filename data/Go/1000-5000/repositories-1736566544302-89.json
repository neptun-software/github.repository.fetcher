{
  "metadata": {
    "timestamp": 1736566544302,
    "page": 89,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjkw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "BurntSushi/toml",
      "stars": 4618,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.021484375,
          "content": "/toml.test\n/toml-test\n"
        },
        {
          "name": "COPYING",
          "type": "blob",
          "size": 1.0537109375,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2013 TOML authors\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 2.666015625,
          "content": "TOML stands for Tom's Obvious, Minimal Language. This Go package provides a\nreflection interface similar to Go's standard library `json` and `xml` packages.\n\nCompatible with TOML version [v1.0.0](https://toml.io/en/v1.0.0).\n\nDocumentation: https://pkg.go.dev/github.com/BurntSushi/toml\n\nSee the [releases page](https://github.com/BurntSushi/toml/releases) for a\nchangelog; this information is also in the git tag annotations (e.g. `git show\nv0.4.0`).\n\nThis library requires Go 1.18 or newer; add it to your go.mod with:\n\n    % go get github.com/BurntSushi/toml@latest\n\nIt also comes with a TOML validator CLI tool:\n\n    % go install github.com/BurntSushi/toml/cmd/tomlv@latest\n    % tomlv some-toml-file.toml\n\n### Examples\nFor the simplest example, consider some TOML file as just a list of keys and\nvalues:\n\n```toml\nAge = 25\nCats = [ \"Cauchy\", \"Plato\" ]\nPi = 3.14\nPerfection = [ 6, 28, 496, 8128 ]\nDOB = 1987-07-05T05:45:00Z\n```\n\nWhich can be decoded with:\n\n```go\ntype Config struct {\n\tAge        int\n\tCats       []string\n\tPi         float64\n\tPerfection []int\n\tDOB        time.Time\n}\n\nvar conf Config\n_, err := toml.Decode(tomlData, &conf)\n```\n\nYou can also use struct tags if your struct field name doesn't map to a TOML key\nvalue directly:\n\n```toml\nsome_key_NAME = \"wat\"\n```\n\n```go\ntype TOML struct {\n    ObscureKey string `toml:\"some_key_NAME\"`\n}\n```\n\nBeware that like other decoders **only exported fields** are considered when\nencoding and decoding; private fields are silently ignored.\n\n### Using the `Marshaler` and `encoding.TextUnmarshaler` interfaces\nHere's an example that automatically parses values in a `mail.Address`:\n\n```toml\ncontacts = [\n    \"Donald Duck <donald@duckburg.com>\",\n    \"Scrooge McDuck <scrooge@duckburg.com>\",\n]\n```\n\nCan be decoded with:\n\n```go\n// Create address type which satisfies the encoding.TextUnmarshaler interface.\ntype address struct {\n\t*mail.Address\n}\n\nfunc (a *address) UnmarshalText(text []byte) error {\n\tvar err error\n\ta.Address, err = mail.ParseAddress(string(text))\n\treturn err\n}\n\n// Decode it.\nfunc decode() {\n\tblob := `\n\t\tcontacts = [\n\t\t\t\"Donald Duck <donald@duckburg.com>\",\n\t\t\t\"Scrooge McDuck <scrooge@duckburg.com>\",\n\t\t]\n\t`\n\n\tvar contacts struct {\n\t\tContacts []address\n\t}\n\n\t_, err := toml.Decode(blob, &contacts)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tfor _, c := range contacts.Contacts {\n\t\tfmt.Printf(\"%#v\\n\", c.Address)\n\t}\n\n\t// Output:\n\t// &mail.Address{Name:\"Donald Duck\", Address:\"donald@duckburg.com\"}\n\t// &mail.Address{Name:\"Scrooge McDuck\", Address:\"scrooge@duckburg.com\"}\n}\n```\n\nTo target TOML specifically you can implement `UnmarshalTOML` TOML interface in\na similar way.\n\n### More complex usage\nSee the [`_example/`](/_example) directory for a more complex example.\n"
        },
        {
          "name": "_example",
          "type": "tree",
          "content": null
        },
        {
          "name": "bench_test.go",
          "type": "blob",
          "size": 4.2509765625,
          "content": "package toml_test\n\nimport (\n\t\"bytes\"\n\t\"io/fs\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"sort\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/BurntSushi/toml\"\n\ttomltest \"github.com/BurntSushi/toml/internal/toml-test\"\n)\n\nfunc BenchmarkDecode(b *testing.B) {\n\tfiles := make(map[string][]string)\n\tfs.WalkDir(tomltest.EmbeddedTests(), \".\", func(path string, d fs.DirEntry, err error) error {\n\t\tif strings.HasPrefix(path, \"valid/\") && strings.HasSuffix(path, \".toml\") {\n\t\t\td, _ := fs.ReadFile(tomltest.EmbeddedTests(), path)\n\t\t\tg := filepath.Dir(path[6:])\n\t\t\tif g == \".\" {\n\t\t\t\tg = \"top\"\n\t\t\t}\n\t\t\tfiles[g] = append(files[g], string(d))\n\t\t}\n\t\treturn nil\n\t})\n\n\ttype test struct {\n\t\tgroup string\n\t\ttoml  []string\n\t}\n\ttests := make([]test, 0, len(files))\n\tfor k, v := range files {\n\t\ttests = append(tests, test{group: k, toml: v})\n\t}\n\tsort.Slice(tests, func(i, j int) bool { return tests[i].group < tests[j].group })\n\n\tb.ResetTimer()\n\tfor _, tt := range tests {\n\t\tb.Run(tt.group, func(b *testing.B) {\n\t\t\tb.ResetTimer()\n\t\t\tfor n := 0; n < b.N; n++ {\n\t\t\t\tfor _, f := range tt.toml {\n\t\t\t\t\tvar val map[string]any\n\t\t\t\t\ttoml.Decode(f, &val)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n\n\tb.Run(\"large-doc\", func(b *testing.B) {\n\t\td, err := os.ReadFile(\"testdata/Cargo.toml\")\n\t\tif err != nil {\n\t\t\tb.Fatal(err)\n\t\t}\n\t\tdoc := string(d)\n\n\t\tb.ResetTimer()\n\t\tfor n := 0; n < b.N; n++ {\n\t\t\tvar val map[string]any\n\t\t\ttoml.Decode(doc, &val)\n\t\t}\n\t})\n}\n\nfunc BenchmarkEncode(b *testing.B) {\n\tfiles := make(map[string][]map[string]any)\n\tfs.WalkDir(tomltest.EmbeddedTests(), \".\", func(path string, d fs.DirEntry, err error) error {\n\t\tif strings.HasPrefix(path, \"valid/\") && strings.HasSuffix(path, \".toml\") {\n\t\t\td, _ := fs.ReadFile(tomltest.EmbeddedTests(), path)\n\t\t\tg := filepath.Dir(path[6:])\n\t\t\tif g == \".\" {\n\t\t\t\tg = \"top\"\n\t\t\t}\n\n\t\t\t// \"next\" version of TOML.\n\t\t\tswitch path {\n\t\t\tcase \"valid/string/escape-esc.toml\", \"valid/datetime/no-seconds.toml\",\n\t\t\t\t\"valid/string/hex-escape.toml\", \"valid/inline-table/newline.toml\":\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\tvar dec map[string]any\n\t\t\t_, err := toml.Decode(string(d), &dec)\n\t\t\tif err != nil {\n\t\t\t\tb.Fatalf(\"decode %q: %s\", path, err)\n\t\t\t}\n\n\t\t\tbuf := new(bytes.Buffer)\n\t\t\terr = toml.NewEncoder(buf).Encode(dec)\n\t\t\tif err != nil {\n\t\t\t\tb.Logf(\"encode failed for %q (skipping): %s\", path, err)\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\tfiles[g] = append(files[g], dec)\n\t\t}\n\t\treturn nil\n\t})\n\n\ttype test struct {\n\t\tgroup string\n\t\tdata  []map[string]any\n\t}\n\ttests := make([]test, 0, len(files))\n\tfor k, v := range files {\n\t\ttests = append(tests, test{group: k, data: v})\n\t}\n\tsort.Slice(tests, func(i, j int) bool { return tests[i].group < tests[j].group })\n\n\tb.ResetTimer()\n\tfor _, tt := range tests {\n\t\tb.Run(tt.group, func(b *testing.B) {\n\t\t\tbuf := new(bytes.Buffer)\n\t\t\tbuf.Grow(1024 * 64)\n\t\t\tb.ResetTimer()\n\t\t\tfor n := 0; n < b.N; n++ {\n\t\t\t\tfor _, f := range tt.data {\n\t\t\t\t\ttoml.NewEncoder(buf).Encode(f)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc BenchmarkExample(b *testing.B) {\n\td, err := os.ReadFile(\"_example/example.toml\")\n\tif err != nil {\n\t\tb.Fatal(err)\n\t}\n\tt := string(d)\n\n\tvar decoded example\n\t_, err = toml.Decode(t, &decoded)\n\tif err != nil {\n\t\tb.Fatal(err)\n\t}\n\n\tbuf := new(bytes.Buffer)\n\terr = toml.NewEncoder(buf).Encode(decoded)\n\tif err != nil {\n\t\tb.Fatal(err)\n\t}\n\n\tb.ResetTimer()\n\tb.Run(\"decode\", func(b *testing.B) {\n\t\tfor n := 0; n < b.N; n++ {\n\t\t\tvar c example\n\t\t\ttoml.Decode(t, &c)\n\t\t}\n\t})\n\n\tb.Run(\"encode\", func(b *testing.B) {\n\t\tfor n := 0; n < b.N; n++ {\n\t\t\tbuf.Reset()\n\t\t\ttoml.NewEncoder(buf).Encode(decoded)\n\t\t}\n\t})\n}\n\n// Copy from _example/example.go\ntype (\n\texample struct {\n\t\tTitle      string\n\t\tIntegers   []int\n\t\tTimes      []fmtTime\n\t\tDuration   []duration\n\t\tDistros    []distro\n\t\tServers    map[string]server\n\t\tCharacters map[string][]struct {\n\t\t\tName string\n\t\t\tRank string\n\t\t}\n\t}\n\n\tserver struct {\n\t\tIP       string\n\t\tHostname string\n\t\tEnabled  bool\n\t}\n\n\tdistro struct {\n\t\tName     string\n\t\tPackages string\n\t}\n\n\tduration struct{ time.Duration }\n\tfmtTime  struct{ time.Time }\n)\n\nfunc (d *duration) UnmarshalText(text []byte) (err error) {\n\td.Duration, err = time.ParseDuration(string(text))\n\treturn err\n}\n\nfunc (t fmtTime) String() string {\n\tf := \"2006-01-02 15:04:05.999999999\"\n\tif t.Time.Hour() == 0 {\n\t\tf = \"2006-01-02\"\n\t}\n\tif t.Time.Year() == 0 {\n\t\tf = \"15:04:05.999999999\"\n\t}\n\tif t.Time.Location() == time.UTC {\n\t\tf += \" UTC\"\n\t} else {\n\t\tf += \" -0700\"\n\t}\n\treturn t.Time.Format(`\"` + f + `\"`)\n}\n"
        },
        {
          "name": "cmd",
          "type": "tree",
          "content": null
        },
        {
          "name": "decode.go",
          "type": "blob",
          "size": 16.6591796875,
          "content": "package toml\n\nimport (\n\t\"bytes\"\n\t\"encoding\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/fs\"\n\t\"math\"\n\t\"os\"\n\t\"reflect\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n)\n\n// Unmarshaler is the interface implemented by objects that can unmarshal a\n// TOML description of themselves.\ntype Unmarshaler interface {\n\tUnmarshalTOML(any) error\n}\n\n// Unmarshal decodes the contents of data in TOML format into a pointer v.\n//\n// See [Decoder] for a description of the decoding process.\nfunc Unmarshal(data []byte, v any) error {\n\t_, err := NewDecoder(bytes.NewReader(data)).Decode(v)\n\treturn err\n}\n\n// Decode the TOML data in to the pointer v.\n//\n// See [Decoder] for a description of the decoding process.\nfunc Decode(data string, v any) (MetaData, error) {\n\treturn NewDecoder(strings.NewReader(data)).Decode(v)\n}\n\n// DecodeFile reads the contents of a file and decodes it with [Decode].\nfunc DecodeFile(path string, v any) (MetaData, error) {\n\tfp, err := os.Open(path)\n\tif err != nil {\n\t\treturn MetaData{}, err\n\t}\n\tdefer fp.Close()\n\treturn NewDecoder(fp).Decode(v)\n}\n\n// DecodeFS reads the contents of a file from [fs.FS] and decodes it with\n// [Decode].\nfunc DecodeFS(fsys fs.FS, path string, v any) (MetaData, error) {\n\tfp, err := fsys.Open(path)\n\tif err != nil {\n\t\treturn MetaData{}, err\n\t}\n\tdefer fp.Close()\n\treturn NewDecoder(fp).Decode(v)\n}\n\n// Primitive is a TOML value that hasn't been decoded into a Go value.\n//\n// This type can be used for any value, which will cause decoding to be delayed.\n// You can use [PrimitiveDecode] to \"manually\" decode these values.\n//\n// NOTE: The underlying representation of a `Primitive` value is subject to\n// change. Do not rely on it.\n//\n// NOTE: Primitive values are still parsed, so using them will only avoid the\n// overhead of reflection. They can be useful when you don't know the exact type\n// of TOML data until runtime.\ntype Primitive struct {\n\tundecoded any\n\tcontext   Key\n}\n\n// The significand precision for float32 and float64 is 24 and 53 bits; this is\n// the range a natural number can be stored in a float without loss of data.\nconst (\n\tmaxSafeFloat32Int = 16777215                // 2^24-1\n\tmaxSafeFloat64Int = int64(9007199254740991) // 2^53-1\n)\n\n// Decoder decodes TOML data.\n//\n// TOML tables correspond to Go structs or maps; they can be used\n// interchangeably, but structs offer better type safety.\n//\n// TOML table arrays correspond to either a slice of structs or a slice of maps.\n//\n// TOML datetimes correspond to [time.Time]. Local datetimes are parsed in the\n// local timezone.\n//\n// [time.Duration] types are treated as nanoseconds if the TOML value is an\n// integer, or they're parsed with time.ParseDuration() if they're strings.\n//\n// All other TOML types (float, string, int, bool and array) correspond to the\n// obvious Go types.\n//\n// An exception to the above rules is if a type implements the TextUnmarshaler\n// interface, in which case any primitive TOML value (floats, strings, integers,\n// booleans, datetimes) will be converted to a []byte and given to the value's\n// UnmarshalText method. See the Unmarshaler example for a demonstration with\n// email addresses.\n//\n// # Key mapping\n//\n// TOML keys can map to either keys in a Go map or field names in a Go struct.\n// The special `toml` struct tag can be used to map TOML keys to struct fields\n// that don't match the key name exactly (see the example). A case insensitive\n// match to struct names will be tried if an exact match can't be found.\n//\n// The mapping between TOML values and Go values is loose. That is, there may\n// exist TOML values that cannot be placed into your representation, and there\n// may be parts of your representation that do not correspond to TOML values.\n// This loose mapping can be made stricter by using the IsDefined and/or\n// Undecoded methods on the MetaData returned.\n//\n// This decoder does not handle cyclic types. Decode will not terminate if a\n// cyclic type is passed.\ntype Decoder struct {\n\tr io.Reader\n}\n\n// NewDecoder creates a new Decoder.\nfunc NewDecoder(r io.Reader) *Decoder {\n\treturn &Decoder{r: r}\n}\n\nvar (\n\tunmarshalToml = reflect.TypeOf((*Unmarshaler)(nil)).Elem()\n\tunmarshalText = reflect.TypeOf((*encoding.TextUnmarshaler)(nil)).Elem()\n\tprimitiveType = reflect.TypeOf((*Primitive)(nil)).Elem()\n)\n\n// Decode TOML data in to the pointer `v`.\nfunc (dec *Decoder) Decode(v any) (MetaData, error) {\n\trv := reflect.ValueOf(v)\n\tif rv.Kind() != reflect.Ptr {\n\t\ts := \"%q\"\n\t\tif reflect.TypeOf(v) == nil {\n\t\t\ts = \"%v\"\n\t\t}\n\n\t\treturn MetaData{}, fmt.Errorf(\"toml: cannot decode to non-pointer \"+s, reflect.TypeOf(v))\n\t}\n\tif rv.IsNil() {\n\t\treturn MetaData{}, fmt.Errorf(\"toml: cannot decode to nil value of %q\", reflect.TypeOf(v))\n\t}\n\n\t// Check if this is a supported type: struct, map, any, or something that\n\t// implements UnmarshalTOML or UnmarshalText.\n\trv = indirect(rv)\n\trt := rv.Type()\n\tif rv.Kind() != reflect.Struct && rv.Kind() != reflect.Map &&\n\t\t!(rv.Kind() == reflect.Interface && rv.NumMethod() == 0) &&\n\t\t!rt.Implements(unmarshalToml) && !rt.Implements(unmarshalText) {\n\t\treturn MetaData{}, fmt.Errorf(\"toml: cannot decode to type %s\", rt)\n\t}\n\n\t// TODO: parser should read from io.Reader? Or at the very least, make it\n\t// read from []byte rather than string\n\tdata, err := io.ReadAll(dec.r)\n\tif err != nil {\n\t\treturn MetaData{}, err\n\t}\n\n\tp, err := parse(string(data))\n\tif err != nil {\n\t\treturn MetaData{}, err\n\t}\n\n\tmd := MetaData{\n\t\tmapping: p.mapping,\n\t\tkeyInfo: p.keyInfo,\n\t\tkeys:    p.ordered,\n\t\tdecoded: make(map[string]struct{}, len(p.ordered)),\n\t\tcontext: nil,\n\t\tdata:    data,\n\t}\n\treturn md, md.unify(p.mapping, rv)\n}\n\n// PrimitiveDecode is just like the other Decode* functions, except it decodes a\n// TOML value that has already been parsed. Valid primitive values can *only* be\n// obtained from values filled by the decoder functions, including this method.\n// (i.e., v may contain more [Primitive] values.)\n//\n// Meta data for primitive values is included in the meta data returned by the\n// Decode* functions with one exception: keys returned by the Undecoded method\n// will only reflect keys that were decoded. Namely, any keys hidden behind a\n// Primitive will be considered undecoded. Executing this method will update the\n// undecoded keys in the meta data. (See the example.)\nfunc (md *MetaData) PrimitiveDecode(primValue Primitive, v any) error {\n\tmd.context = primValue.context\n\tdefer func() { md.context = nil }()\n\treturn md.unify(primValue.undecoded, rvalue(v))\n}\n\n// unify performs a sort of type unification based on the structure of `rv`,\n// which is the client representation.\n//\n// Any type mismatch produces an error. Finding a type that we don't know\n// how to handle produces an unsupported type error.\nfunc (md *MetaData) unify(data any, rv reflect.Value) error {\n\t// Special case. Look for a `Primitive` value.\n\t// TODO: #76 would make this superfluous after implemented.\n\tif rv.Type() == primitiveType {\n\t\t// Save the undecoded data and the key context into the primitive\n\t\t// value.\n\t\tcontext := make(Key, len(md.context))\n\t\tcopy(context, md.context)\n\t\trv.Set(reflect.ValueOf(Primitive{\n\t\t\tundecoded: data,\n\t\t\tcontext:   context,\n\t\t}))\n\t\treturn nil\n\t}\n\n\trvi := rv.Interface()\n\tif v, ok := rvi.(Unmarshaler); ok {\n\t\terr := v.UnmarshalTOML(data)\n\t\tif err != nil {\n\t\t\treturn md.parseErr(err)\n\t\t}\n\t\treturn nil\n\t}\n\tif v, ok := rvi.(encoding.TextUnmarshaler); ok {\n\t\treturn md.unifyText(data, v)\n\t}\n\n\t// TODO:\n\t// The behavior here is incorrect whenever a Go type satisfies the\n\t// encoding.TextUnmarshaler interface but also corresponds to a TOML hash or\n\t// array. In particular, the unmarshaler should only be applied to primitive\n\t// TOML values. But at this point, it will be applied to all kinds of values\n\t// and produce an incorrect error whenever those values are hashes or arrays\n\t// (including arrays of tables).\n\n\tk := rv.Kind()\n\n\tif k >= reflect.Int && k <= reflect.Uint64 {\n\t\treturn md.unifyInt(data, rv)\n\t}\n\tswitch k {\n\tcase reflect.Struct:\n\t\treturn md.unifyStruct(data, rv)\n\tcase reflect.Map:\n\t\treturn md.unifyMap(data, rv)\n\tcase reflect.Array:\n\t\treturn md.unifyArray(data, rv)\n\tcase reflect.Slice:\n\t\treturn md.unifySlice(data, rv)\n\tcase reflect.String:\n\t\treturn md.unifyString(data, rv)\n\tcase reflect.Bool:\n\t\treturn md.unifyBool(data, rv)\n\tcase reflect.Interface:\n\t\tif rv.NumMethod() > 0 { /// Only empty interfaces are supported.\n\t\t\treturn md.e(\"unsupported type %s\", rv.Type())\n\t\t}\n\t\treturn md.unifyAnything(data, rv)\n\tcase reflect.Float32, reflect.Float64:\n\t\treturn md.unifyFloat64(data, rv)\n\t}\n\treturn md.e(\"unsupported type %s\", rv.Kind())\n}\n\nfunc (md *MetaData) unifyStruct(mapping any, rv reflect.Value) error {\n\ttmap, ok := mapping.(map[string]any)\n\tif !ok {\n\t\tif mapping == nil {\n\t\t\treturn nil\n\t\t}\n\t\treturn md.e(\"type mismatch for %s: expected table but found %s\", rv.Type().String(), fmtType(mapping))\n\t}\n\n\tfor key, datum := range tmap {\n\t\tvar f *field\n\t\tfields := cachedTypeFields(rv.Type())\n\t\tfor i := range fields {\n\t\t\tff := &fields[i]\n\t\t\tif ff.name == key {\n\t\t\t\tf = ff\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tif f == nil && strings.EqualFold(ff.name, key) {\n\t\t\t\tf = ff\n\t\t\t}\n\t\t}\n\t\tif f != nil {\n\t\t\tsubv := rv\n\t\t\tfor _, i := range f.index {\n\t\t\t\tsubv = indirect(subv.Field(i))\n\t\t\t}\n\n\t\t\tif isUnifiable(subv) {\n\t\t\t\tmd.decoded[md.context.add(key).String()] = struct{}{}\n\t\t\t\tmd.context = append(md.context, key)\n\n\t\t\t\terr := md.unify(datum, subv)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tmd.context = md.context[0 : len(md.context)-1]\n\t\t\t} else if f.name != \"\" {\n\t\t\t\treturn md.e(\"cannot write unexported field %s.%s\", rv.Type().String(), f.name)\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (md *MetaData) unifyMap(mapping any, rv reflect.Value) error {\n\tkeyType := rv.Type().Key().Kind()\n\tif keyType != reflect.String && keyType != reflect.Interface {\n\t\treturn fmt.Errorf(\"toml: cannot decode to a map with non-string key type (%s in %q)\",\n\t\t\tkeyType, rv.Type())\n\t}\n\n\ttmap, ok := mapping.(map[string]any)\n\tif !ok {\n\t\tif tmap == nil {\n\t\t\treturn nil\n\t\t}\n\t\treturn md.badtype(\"map\", mapping)\n\t}\n\tif rv.IsNil() {\n\t\trv.Set(reflect.MakeMap(rv.Type()))\n\t}\n\tfor k, v := range tmap {\n\t\tmd.decoded[md.context.add(k).String()] = struct{}{}\n\t\tmd.context = append(md.context, k)\n\n\t\trvval := reflect.Indirect(reflect.New(rv.Type().Elem()))\n\n\t\terr := md.unify(v, indirect(rvval))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tmd.context = md.context[0 : len(md.context)-1]\n\n\t\trvkey := indirect(reflect.New(rv.Type().Key()))\n\n\t\tswitch keyType {\n\t\tcase reflect.Interface:\n\t\t\trvkey.Set(reflect.ValueOf(k))\n\t\tcase reflect.String:\n\t\t\trvkey.SetString(k)\n\t\t}\n\n\t\trv.SetMapIndex(rvkey, rvval)\n\t}\n\treturn nil\n}\n\nfunc (md *MetaData) unifyArray(data any, rv reflect.Value) error {\n\tdatav := reflect.ValueOf(data)\n\tif datav.Kind() != reflect.Slice {\n\t\tif !datav.IsValid() {\n\t\t\treturn nil\n\t\t}\n\t\treturn md.badtype(\"slice\", data)\n\t}\n\tif l := datav.Len(); l != rv.Len() {\n\t\treturn md.e(\"expected array length %d; got TOML array of length %d\", rv.Len(), l)\n\t}\n\treturn md.unifySliceArray(datav, rv)\n}\n\nfunc (md *MetaData) unifySlice(data any, rv reflect.Value) error {\n\tdatav := reflect.ValueOf(data)\n\tif datav.Kind() != reflect.Slice {\n\t\tif !datav.IsValid() {\n\t\t\treturn nil\n\t\t}\n\t\treturn md.badtype(\"slice\", data)\n\t}\n\tn := datav.Len()\n\tif rv.IsNil() || rv.Cap() < n {\n\t\trv.Set(reflect.MakeSlice(rv.Type(), n, n))\n\t}\n\trv.SetLen(n)\n\treturn md.unifySliceArray(datav, rv)\n}\n\nfunc (md *MetaData) unifySliceArray(data, rv reflect.Value) error {\n\tl := data.Len()\n\tfor i := 0; i < l; i++ {\n\t\terr := md.unify(data.Index(i).Interface(), indirect(rv.Index(i)))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (md *MetaData) unifyString(data any, rv reflect.Value) error {\n\t_, ok := rv.Interface().(json.Number)\n\tif ok {\n\t\tif i, ok := data.(int64); ok {\n\t\t\trv.SetString(strconv.FormatInt(i, 10))\n\t\t} else if f, ok := data.(float64); ok {\n\t\t\trv.SetString(strconv.FormatFloat(f, 'f', -1, 64))\n\t\t} else {\n\t\t\treturn md.badtype(\"string\", data)\n\t\t}\n\t\treturn nil\n\t}\n\n\tif s, ok := data.(string); ok {\n\t\trv.SetString(s)\n\t\treturn nil\n\t}\n\treturn md.badtype(\"string\", data)\n}\n\nfunc (md *MetaData) unifyFloat64(data any, rv reflect.Value) error {\n\trvk := rv.Kind()\n\n\tif num, ok := data.(float64); ok {\n\t\tswitch rvk {\n\t\tcase reflect.Float32:\n\t\t\tif num < -math.MaxFloat32 || num > math.MaxFloat32 {\n\t\t\t\treturn md.parseErr(errParseRange{i: num, size: rvk.String()})\n\t\t\t}\n\t\t\tfallthrough\n\t\tcase reflect.Float64:\n\t\t\trv.SetFloat(num)\n\t\tdefault:\n\t\t\tpanic(\"bug\")\n\t\t}\n\t\treturn nil\n\t}\n\n\tif num, ok := data.(int64); ok {\n\t\tif (rvk == reflect.Float32 && (num < -maxSafeFloat32Int || num > maxSafeFloat32Int)) ||\n\t\t\t(rvk == reflect.Float64 && (num < -maxSafeFloat64Int || num > maxSafeFloat64Int)) {\n\t\t\treturn md.parseErr(errUnsafeFloat{i: num, size: rvk.String()})\n\t\t}\n\t\trv.SetFloat(float64(num))\n\t\treturn nil\n\t}\n\n\treturn md.badtype(\"float\", data)\n}\n\nfunc (md *MetaData) unifyInt(data any, rv reflect.Value) error {\n\t_, ok := rv.Interface().(time.Duration)\n\tif ok {\n\t\t// Parse as string duration, and fall back to regular integer parsing\n\t\t// (as nanosecond) if this is not a string.\n\t\tif s, ok := data.(string); ok {\n\t\t\tdur, err := time.ParseDuration(s)\n\t\t\tif err != nil {\n\t\t\t\treturn md.parseErr(errParseDuration{s})\n\t\t\t}\n\t\t\trv.SetInt(int64(dur))\n\t\t\treturn nil\n\t\t}\n\t}\n\n\tnum, ok := data.(int64)\n\tif !ok {\n\t\treturn md.badtype(\"integer\", data)\n\t}\n\n\trvk := rv.Kind()\n\tswitch {\n\tcase rvk >= reflect.Int && rvk <= reflect.Int64:\n\t\tif (rvk == reflect.Int8 && (num < math.MinInt8 || num > math.MaxInt8)) ||\n\t\t\t(rvk == reflect.Int16 && (num < math.MinInt16 || num > math.MaxInt16)) ||\n\t\t\t(rvk == reflect.Int32 && (num < math.MinInt32 || num > math.MaxInt32)) {\n\t\t\treturn md.parseErr(errParseRange{i: num, size: rvk.String()})\n\t\t}\n\t\trv.SetInt(num)\n\tcase rvk >= reflect.Uint && rvk <= reflect.Uint64:\n\t\tunum := uint64(num)\n\t\tif rvk == reflect.Uint8 && (num < 0 || unum > math.MaxUint8) ||\n\t\t\trvk == reflect.Uint16 && (num < 0 || unum > math.MaxUint16) ||\n\t\t\trvk == reflect.Uint32 && (num < 0 || unum > math.MaxUint32) {\n\t\t\treturn md.parseErr(errParseRange{i: num, size: rvk.String()})\n\t\t}\n\t\trv.SetUint(unum)\n\tdefault:\n\t\tpanic(\"unreachable\")\n\t}\n\treturn nil\n}\n\nfunc (md *MetaData) unifyBool(data any, rv reflect.Value) error {\n\tif b, ok := data.(bool); ok {\n\t\trv.SetBool(b)\n\t\treturn nil\n\t}\n\treturn md.badtype(\"boolean\", data)\n}\n\nfunc (md *MetaData) unifyAnything(data any, rv reflect.Value) error {\n\trv.Set(reflect.ValueOf(data))\n\treturn nil\n}\n\nfunc (md *MetaData) unifyText(data any, v encoding.TextUnmarshaler) error {\n\tvar s string\n\tswitch sdata := data.(type) {\n\tcase Marshaler:\n\t\ttext, err := sdata.MarshalTOML()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\ts = string(text)\n\tcase encoding.TextMarshaler:\n\t\ttext, err := sdata.MarshalText()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\ts = string(text)\n\tcase fmt.Stringer:\n\t\ts = sdata.String()\n\tcase string:\n\t\ts = sdata\n\tcase bool:\n\t\ts = fmt.Sprintf(\"%v\", sdata)\n\tcase int64:\n\t\ts = fmt.Sprintf(\"%d\", sdata)\n\tcase float64:\n\t\ts = fmt.Sprintf(\"%f\", sdata)\n\tdefault:\n\t\treturn md.badtype(\"primitive (string-like)\", data)\n\t}\n\tif err := v.UnmarshalText([]byte(s)); err != nil {\n\t\treturn md.parseErr(err)\n\t}\n\treturn nil\n}\n\nfunc (md *MetaData) badtype(dst string, data any) error {\n\treturn md.e(\"incompatible types: TOML value has type %s; destination has type %s\", fmtType(data), dst)\n}\n\nfunc (md *MetaData) parseErr(err error) error {\n\tk := md.context.String()\n\td := string(md.data)\n\treturn ParseError{\n\t\tMessage:  err.Error(),\n\t\terr:      err,\n\t\tLastKey:  k,\n\t\tPosition: md.keyInfo[k].pos.withCol(d),\n\t\tLine:     md.keyInfo[k].pos.Line,\n\t\tinput:    d,\n\t}\n}\n\nfunc (md *MetaData) e(format string, args ...any) error {\n\tf := \"toml: \"\n\tif len(md.context) > 0 {\n\t\tf = fmt.Sprintf(\"toml: (last key %q): \", md.context)\n\t\tp := md.keyInfo[md.context.String()].pos\n\t\tif p.Line > 0 {\n\t\t\tf = fmt.Sprintf(\"toml: line %d (last key %q): \", p.Line, md.context)\n\t\t}\n\t}\n\treturn fmt.Errorf(f+format, args...)\n}\n\n// rvalue returns a reflect.Value of `v`. All pointers are resolved.\nfunc rvalue(v any) reflect.Value {\n\treturn indirect(reflect.ValueOf(v))\n}\n\n// indirect returns the value pointed to by a pointer.\n//\n// Pointers are followed until the value is not a pointer. New values are\n// allocated for each nil pointer.\n//\n// An exception to this rule is if the value satisfies an interface of interest\n// to us (like encoding.TextUnmarshaler).\nfunc indirect(v reflect.Value) reflect.Value {\n\tif v.Kind() != reflect.Ptr {\n\t\tif v.CanSet() {\n\t\t\tpv := v.Addr()\n\t\t\tpvi := pv.Interface()\n\t\t\tif _, ok := pvi.(encoding.TextUnmarshaler); ok {\n\t\t\t\treturn pv\n\t\t\t}\n\t\t\tif _, ok := pvi.(Unmarshaler); ok {\n\t\t\t\treturn pv\n\t\t\t}\n\t\t}\n\t\treturn v\n\t}\n\tif v.IsNil() {\n\t\tv.Set(reflect.New(v.Type().Elem()))\n\t}\n\treturn indirect(reflect.Indirect(v))\n}\n\nfunc isUnifiable(rv reflect.Value) bool {\n\tif rv.CanSet() {\n\t\treturn true\n\t}\n\trvi := rv.Interface()\n\tif _, ok := rvi.(encoding.TextUnmarshaler); ok {\n\t\treturn true\n\t}\n\tif _, ok := rvi.(Unmarshaler); ok {\n\t\treturn true\n\t}\n\treturn false\n}\n\n// fmt %T with \"interface {}\" replaced with \"any\", which is far more readable.\nfunc fmtType(t any) string {\n\treturn strings.ReplaceAll(fmt.Sprintf(\"%T\", t), \"interface {}\", \"any\")\n}\n"
        },
        {
          "name": "decode_test.go",
          "type": "blob",
          "size": 27.19140625,
          "content": "package toml\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math\"\n\t\"os\"\n\t\"reflect\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"testing/fstest\"\n\t\"time\"\n\n\t\"github.com/BurntSushi/toml/internal\"\n)\n\nfunc WithTomlNext(f func()) {\n\tos.Setenv(\"BURNTSUSHI_TOML_110\", \"\")\n\tdefer func() { os.Unsetenv(\"BURNTSUSHI_TOML_110\") }()\n\tf()\n}\n\nfunc TestDecodeReader(t *testing.T) {\n\tvar i struct{ A int }\n\tmeta, err := DecodeReader(strings.NewReader(\"a = 42\"), &i)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\thave := fmt.Sprintf(\"%v %v %v\", i, meta.Keys(), meta.Type(\"a\"))\n\twant := \"{42} [a] Integer\"\n\tif have != want {\n\t\tt.Errorf(\"\\nhave: %s\\nwant: %s\", have, want)\n\t}\n}\n\nfunc TestDecodeFile(t *testing.T) {\n\ttmp, err := os.CreateTemp(\"\", \"toml-\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer os.Remove(tmp.Name())\n\tif _, err := tmp.WriteString(\"a = 42\"); err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif err := tmp.Close(); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvar i struct{ A int }\n\tmeta, err := DecodeFile(tmp.Name(), &i)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\thave := fmt.Sprintf(\"%v %v %v\", i, meta.Keys(), meta.Type(\"a\"))\n\twant := \"{42} [a] Integer\"\n\tif have != want {\n\t\tt.Errorf(\"\\nhave: %s\\nwant: %s\", have, want)\n\t}\n}\n\nfunc TestDecodeFS(t *testing.T) {\n\tfsys := fstest.MapFS{\n\t\t\"test.toml\": &fstest.MapFile{\n\t\t\tData: []byte(\"a = 42\"),\n\t\t},\n\t}\n\n\tvar i struct{ A int }\n\tmeta, err := DecodeFS(fsys, \"test.toml\", &i)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\thave := fmt.Sprintf(\"%v %v %v\", i, meta.Keys(), meta.Type(\"a\"))\n\twant := \"{42} [a] Integer\"\n\tif have != want {\n\t\tt.Errorf(\"\\nhave: %s\\nwant: %s\", have, want)\n\t}\n}\n\nfunc TestDecodeBOM(t *testing.T) {\n\tfor _, tt := range [][]byte{\n\t\t[]byte(\"\\xff\\xfea = \\\"b\\\"\"),\n\t\t[]byte(\"\\xfe\\xffa = \\\"b\\\"\"),\n\t\t[]byte(\"\\xef\\xbb\\xbfa = \\\"b\\\"\"),\n\t} {\n\t\tt.Run(\"\", func(t *testing.T) {\n\t\t\tvar s struct{ A string }\n\t\t\t_, err := Decode(string(tt), &s)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tif s.A != \"b\" {\n\t\t\t\tt.Errorf(`s.A is not \"b\" but %q`, s.A)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestDecodeEmbedded(t *testing.T) {\n\ttype Dog struct{ Name string }\n\ttype Age int\n\ttype cat struct{ Name string }\n\n\tfor _, test := range []struct {\n\t\tlabel       string\n\t\tinput       string\n\t\tdecodeInto  any\n\t\twantDecoded any\n\t}{\n\t\t{\n\t\t\tlabel:       \"embedded struct\",\n\t\t\tinput:       `Name = \"milton\"`,\n\t\t\tdecodeInto:  &struct{ Dog }{},\n\t\t\twantDecoded: &struct{ Dog }{Dog{\"milton\"}},\n\t\t},\n\t\t{\n\t\t\tlabel:       \"embedded non-nil pointer to struct\",\n\t\t\tinput:       `Name = \"milton\"`,\n\t\t\tdecodeInto:  &struct{ *Dog }{},\n\t\t\twantDecoded: &struct{ *Dog }{&Dog{\"milton\"}},\n\t\t},\n\t\t{\n\t\t\tlabel:       \"embedded nil pointer to struct\",\n\t\t\tinput:       ``,\n\t\t\tdecodeInto:  &struct{ *Dog }{},\n\t\t\twantDecoded: &struct{ *Dog }{nil},\n\t\t},\n\t\t{\n\t\t\tlabel:       \"unexported embedded struct\",\n\t\t\tinput:       `Name = \"socks\"`,\n\t\t\tdecodeInto:  &struct{ cat }{},\n\t\t\twantDecoded: &struct{ cat }{cat{\"socks\"}},\n\t\t},\n\t\t{\n\t\t\tlabel:       \"embedded int\",\n\t\t\tinput:       `Age = -5`,\n\t\t\tdecodeInto:  &struct{ Age }{},\n\t\t\twantDecoded: &struct{ Age }{-5},\n\t\t},\n\t} {\n\t\t_, err := Decode(test.input, test.decodeInto)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t\tif !reflect.DeepEqual(test.wantDecoded, test.decodeInto) {\n\t\t\tt.Errorf(\"%s: want decoded == %+v, got %+v\",\n\t\t\t\ttest.label, test.wantDecoded, test.decodeInto)\n\t\t}\n\t}\n}\n\nfunc TestDecodeErrors(t *testing.T) {\n\ttests := []struct {\n\t\ts       any\n\t\ttoml    string\n\t\twantErr string\n\t}{\n\t\t{\n\t\t\t&struct{ V int8 }{},\n\t\t\t`V = 999`,\n\t\t\t`toml: line 1 (last key \"V\"): 999 is out of range for int8`,\n\t\t},\n\t\t{\n\t\t\t&struct{ V float32 }{},\n\t\t\t`V = 999999999999999`,\n\t\t\t`toml: line 1 (last key \"V\"): 999999999999999 is out of the safe float32 range`,\n\t\t},\n\t\t{\n\t\t\t&struct{ V string }{},\n\t\t\t`V = 5`,\n\t\t\t`toml: line 1 (last key \"V\"): incompatible types: TOML value has type int64; destination has type string`,\n\t\t},\n\t\t{\n\t\t\t&struct{ V interface{ ASD() } }{},\n\t\t\t`V = 999`,\n\t\t\t`toml: line 1 (last key \"V\"): unsupported type interface { ASD() }`,\n\t\t},\n\t\t{\n\t\t\t&struct{ V struct{ V int } }{},\n\t\t\t`V = 999`,\n\t\t\t`toml: line 1 (last key \"V\"): type mismatch for struct { V int }: expected table but found int64`,\n\t\t},\n\t\t{\n\t\t\t&struct{ V [1]int }{},\n\t\t\t`V = [1,2,3]`,\n\t\t\t`toml: line 1 (last key \"V\"): expected array length 1; got TOML array of length 3`,\n\t\t},\n\t\t{\n\t\t\t&struct{ V struct{ N int8 } }{},\n\t\t\t`V.N = 999`,\n\t\t\t`toml: line 1 (last key \"V.N\"): 999 is out of range for int8`,\n\t\t},\n\t\t{\n\t\t\t&struct{ V struct{ N float32 } }{},\n\t\t\t`V.N = 999999999999999`,\n\t\t\t`toml: line 1 (last key \"V.N\"): 999999999999999 is out of the safe float32 range`,\n\t\t},\n\t\t{\n\t\t\t&struct{ V struct{ N string } }{},\n\t\t\t`V.N = 5`,\n\t\t\t`toml: line 1 (last key \"V.N\"): incompatible types: TOML value has type int64; destination has type string`,\n\t\t},\n\t\t{\n\t\t\t&struct {\n\t\t\t\tV struct{ N interface{ ASD() } }\n\t\t\t}{},\n\t\t\t`V.N = 999`,\n\t\t\t`toml: line 1 (last key \"V.N\"): unsupported type interface { ASD() }`,\n\t\t},\n\t\t{\n\t\t\t&struct{ V struct{ N struct{ V int } } }{},\n\t\t\t`V.N = 999`,\n\t\t\t`toml: line 1 (last key \"V.N\"): type mismatch for struct { V int }: expected table but found int64`,\n\t\t},\n\t\t{\n\t\t\t&struct{ V struct{ N [1]int } }{},\n\t\t\t`V.N = [1,2,3]`,\n\t\t\t`toml: line 1 (last key \"V.N\"): expected array length 1; got TOML array of length 3`,\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(\"\", func(t *testing.T) {\n\t\t\t_, err := Decode(tt.toml, tt.s)\n\t\t\tif err == nil {\n\t\t\t\tt.Fatal(\"err is nil\")\n\t\t\t}\n\t\t\tif err.Error() != tt.wantErr {\n\t\t\t\tt.Errorf(\"\\nhave: %q\\nwant: %q\", err, tt.wantErr)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestDecodeIgnoreFields(t *testing.T) {\n\tconst input = `\nNumber = 123\n- = 234\n`\n\tvar s struct {\n\t\tNumber int `toml:\"-\"`\n\t}\n\tif _, err := Decode(input, &s); err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif s.Number != 0 {\n\t\tt.Errorf(\"got: %d; want 0\", s.Number)\n\t}\n}\n\nfunc TestDecodePointers(t *testing.T) {\n\ttype Object struct {\n\t\tType        string\n\t\tDescription string\n\t}\n\n\ttype Dict struct {\n\t\tNamedObject map[string]*Object\n\t\tBaseObject  *Object\n\t\tStrptr      *string\n\t\tStrptrs     []*string\n\t}\n\ts1, s2, s3 := \"blah\", \"abc\", \"def\"\n\texpected := &Dict{\n\t\tStrptr:  &s1,\n\t\tStrptrs: []*string{&s2, &s3},\n\t\tNamedObject: map[string]*Object{\n\t\t\t\"foo\": {\"FOO\", \"fooooo!!!\"},\n\t\t\t\"bar\": {\"BAR\", \"ba-ba-ba-ba-barrrr!!!\"},\n\t\t},\n\t\tBaseObject: &Object{\"BASE\", \"da base\"},\n\t}\n\n\tex1 := `\nStrptr = \"blah\"\nStrptrs = [\"abc\", \"def\"]\n\n[NamedObject.foo]\nType = \"FOO\"\nDescription = \"fooooo!!!\"\n\n[NamedObject.bar]\nType = \"BAR\"\nDescription = \"ba-ba-ba-ba-barrrr!!!\"\n\n[BaseObject]\nType = \"BASE\"\nDescription = \"da base\"\n`\n\tdict := new(Dict)\n\t_, err := Decode(ex1, dict)\n\tif err != nil {\n\t\tt.Errorf(\"Decode error: %v\", err)\n\t}\n\tif !reflect.DeepEqual(expected, dict) {\n\t\tt.Fatalf(\"\\n%#v\\n!=\\n%#v\\n\", expected, dict)\n\t}\n}\n\nfunc TestDecodeBadDatetime(t *testing.T) {\n\tvar x struct{ T time.Time }\n\tfor _, s := range []string{\"123\", \"1230\"} {\n\t\tinput := \"T = \" + s\n\t\tif _, err := Decode(input, &x); err == nil {\n\t\t\tt.Errorf(\"Expected invalid DateTime error for %q\", s)\n\t\t}\n\t}\n}\n\ntype sphere struct {\n\tCenter [3]float64\n\tRadius float64\n}\n\nfunc TestDecodeArrayWrongSize(t *testing.T) {\n\tvar s1 sphere\n\tif _, err := Decode(`center = [0.1, 2.3]`, &s1); err == nil {\n\t\tt.Fatal(\"Expected array type mismatch error\")\n\t}\n}\n\nfunc TestDecodeIntOverflow(t *testing.T) {\n\ttype table struct {\n\t\tValue int8\n\t}\n\tvar tab table\n\tif _, err := Decode(`value = 500`, &tab); err == nil {\n\t\tt.Fatal(\"Expected integer out-of-bounds error.\")\n\t}\n}\n\nfunc TestDecodeFloatOverflow(t *testing.T) {\n\ttests := []struct {\n\t\tvalue    string\n\t\toverflow bool\n\t}{\n\t\t{fmt.Sprintf(`F32 = %f`, math.MaxFloat64), true},\n\t\t{fmt.Sprintf(`F32 = %f`, -math.MaxFloat64), true},\n\t\t{fmt.Sprintf(`F32 = %f`, math.MaxFloat32*1.1), true},\n\t\t{fmt.Sprintf(`F32 = %f`, -math.MaxFloat32*1.1), true},\n\t\t{fmt.Sprintf(`F32 = %d`, maxSafeFloat32Int+1), true},\n\t\t{fmt.Sprintf(`F32 = %d`, -maxSafeFloat32Int-1), true},\n\t\t{fmt.Sprintf(`F64 = %d`, maxSafeFloat64Int+1), true},\n\t\t{fmt.Sprintf(`F64 = %d`, -maxSafeFloat64Int-1), true},\n\n\t\t{fmt.Sprintf(`F32 = %f`, math.MaxFloat32), false},\n\t\t{fmt.Sprintf(`F32 = %f`, -math.MaxFloat32), false},\n\t\t{fmt.Sprintf(`F32 = %d`, maxSafeFloat32Int), false},\n\t\t{fmt.Sprintf(`F32 = %d`, -maxSafeFloat32Int), false},\n\t\t{fmt.Sprintf(`F64 = %f`, math.MaxFloat64), false},\n\t\t{fmt.Sprintf(`F64 = %f`, -math.MaxFloat64), false},\n\t\t{fmt.Sprintf(`F64 = %f`, math.MaxFloat32), false},\n\t\t{fmt.Sprintf(`F64 = %f`, -math.MaxFloat32), false},\n\t\t{fmt.Sprintf(`F64 = %d`, maxSafeFloat64Int), false},\n\t\t{fmt.Sprintf(`F64 = %d`, -maxSafeFloat64Int), false},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(\"\", func(t *testing.T) {\n\t\t\tvar tab struct {\n\t\t\t\tF32 float32\n\t\t\t\tF64 float64\n\t\t\t}\n\t\t\t_, err := Decode(tt.value, &tab)\n\n\t\t\tif tt.overflow && err == nil {\n\t\t\t\tt.Fatal(\"expected error, but err is nil\")\n\t\t\t}\n\t\t\tif (tt.overflow && !errorContains(err, \"out of the safe float\") && !errorContains(err, \"out of range\")) || (!tt.overflow && err != nil) {\n\t\t\t\tt.Fatalf(\"unexpected error:\\n%T: %[1]v\", err)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestDecodeSignbit(t *testing.T) {\n\tvar m struct {\n\t\tN1, N2   float64\n\t\tI1, I2   float64\n\t\tZ1, Z2   float64\n\t\tZF1, ZF2 float64\n\t}\n\t_, err := Decode(`\nn1 = nan\nn2 = -nan\ni1 = inf\ni2 = -inf\nz1 = 0\nz2 = -0\nzf1 = 0.0\nzf2 = -0.0\n`, &m)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif h := fmt.Sprintf(\"%v %v\", m.N1, math.Signbit(m.N1)); h != \"NaN false\" {\n\t\tt.Error(\"N1:\", h)\n\t}\n\tif h := fmt.Sprintf(\"%v %v\", m.I1, math.Signbit(m.I1)); h != \"+Inf false\" {\n\t\tt.Error(\"I1:\", h)\n\t}\n\tif h := fmt.Sprintf(\"%v %v\", m.Z1, math.Signbit(m.Z1)); h != \"0 false\" {\n\t\tt.Error(\"Z1:\", h)\n\t}\n\tif h := fmt.Sprintf(\"%v %v\", m.ZF1, math.Signbit(m.ZF1)); h != \"0 false\" {\n\t\tt.Error(\"ZF1:\", h)\n\t}\n\n\tif h := fmt.Sprintf(\"%v %v\", m.N2, math.Signbit(m.N2)); h != \"NaN true\" {\n\t\tt.Error(\"N2:\", h)\n\t}\n\tif h := fmt.Sprintf(\"%v %v\", m.I2, math.Signbit(m.I2)); h != \"-Inf true\" {\n\t\tt.Error(\"I2:\", h)\n\t}\n\tif h := fmt.Sprintf(\"%v %v\", m.Z2, math.Signbit(m.Z2)); h != \"0 false\" { // Correct: -0 is same as 0\n\t\tt.Error(\"Z2:\", h)\n\t}\n\tif h := fmt.Sprintf(\"%v %v\", m.ZF2, math.Signbit(m.ZF2)); h != \"-0 true\" {\n\t\tt.Error(\"ZF2:\", h)\n\t}\n\n\tbuf := new(bytes.Buffer)\n\terr = NewEncoder(buf).Encode(m)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\twant := strings.ReplaceAll(`\n\t\tN1 = nan\n\t\tN2 = -nan\n\t\tI1 = inf\n\t\tI2 = -inf\n\t\tZ1 = 0.0\n\t\tZ2 = 0.0\n\t\tZF1 = 0.0\n\t\tZF2 = -0.0\n\t`, \"\\t\", \"\")[1:]\n\tif buf.String() != want {\n\t\tt.Errorf(\"\\nwant:\\n%s\\nhave:\\n%s\", want, buf.String())\n\t}\n}\n\nfunc TestDecodeSizedInts(t *testing.T) {\n\ttype table struct {\n\t\tU8  uint8\n\t\tU16 uint16\n\t\tU32 uint32\n\t\tU64 uint64\n\t\tU   uint\n\t\tI8  int8\n\t\tI16 int16\n\t\tI32 int32\n\t\tI64 int64\n\t\tI   int\n\t}\n\tanswer := table{1, 1, 1, 1, 1, -1, -1, -1, -1, -1}\n\ttoml := `\n\tu8 = 1\n\tu16 = 1\n\tu32 = 1\n\tu64 = 1\n\tu = 1\n\ti8 = -1\n\ti16 = -1\n\ti32 = -1\n\ti64 = -1\n\ti = -1\n\t`\n\tvar tab table\n\tif _, err := Decode(toml, &tab); err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\tif answer != tab {\n\t\tt.Fatalf(\"Expected %#v but got %#v\", answer, tab)\n\t}\n}\n\ntype NopUnmarshalTOML int\n\nfunc (n *NopUnmarshalTOML) UnmarshalTOML(p any) error {\n\t*n = 42\n\treturn nil\n}\n\nfunc TestDecodeTypes(t *testing.T) {\n\ttype (\n\t\tmystr   string\n\t\tmyiface any\n\t)\n\n\tfor _, tt := range []struct {\n\t\tv       any\n\t\twant    string\n\t\twantErr string\n\t}{\n\t\t{new(map[string]bool), \"&map[F:true]\", \"\"},\n\t\t{new(map[mystr]bool), \"&map[F:true]\", \"\"},\n\t\t{new(NopUnmarshalTOML), \"42\", \"\"},\n\t\t{new(map[any]bool), \"&map[F:true]\", \"\"},\n\t\t{new(map[myiface]bool), \"&map[F:true]\", \"\"},\n\n\t\t{3, \"\", `toml: cannot decode to non-pointer \"int\"`},\n\t\t{map[string]any{}, \"\", `toml: cannot decode to non-pointer \"map[string]interface {}\"`},\n\n\t\t{(*int)(nil), \"\", `toml: cannot decode to nil value of \"*int\"`},\n\t\t{(*Unmarshaler)(nil), \"\", `toml: cannot decode to nil value of \"*toml.Unmarshaler\"`},\n\t\t{nil, \"\", `toml: cannot decode to non-pointer <nil>`},\n\n\t\t{new(map[int]string), \"\", \"toml: cannot decode to a map with non-string key type\"},\n\n\t\t{new(struct{ F int }), \"\", `toml: line 1 (last key \"F\"): incompatible types: TOML value has type bool; destination has type integer`},\n\t\t{new(map[string]int), \"\", `toml: line 1 (last key \"F\"): incompatible types: TOML value has type bool; destination has type integer`},\n\t\t{new(int), \"\", `toml: cannot decode to type int`},\n\t\t{new([]int), \"\", \"toml: cannot decode to type []int\"},\n\t} {\n\t\tt.Run(fmt.Sprintf(\"%T\", tt.v), func(t *testing.T) {\n\t\t\t_, err := Decode(`F = true`, tt.v)\n\t\t\tif !errorContains(err, tt.wantErr) {\n\t\t\t\tt.Fatalf(\"wrong error\\nhave: %q\\nwant: %q\", err, tt.wantErr)\n\t\t\t}\n\n\t\t\tif err == nil {\n\t\t\t\thave := fmt.Sprintf(\"%v\", tt.v)\n\t\t\t\tif n, ok := tt.v.(*NopUnmarshalTOML); ok {\n\t\t\t\t\thave = fmt.Sprintf(\"%v\", *n)\n\t\t\t\t}\n\t\t\t\tif have != tt.want {\n\t\t\t\t\tt.Errorf(\"\\nhave: %s\\nwant: %s\", have, tt.want)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestUnmarshaler(t *testing.T) {\n\tvar tomlBlob = `\n[dishes.hamboogie]\nname = \"Hamboogie with fries\"\nprice = 10.99\n\n[[dishes.hamboogie.ingredients]]\nname = \"Bread Bun\"\n\n[[dishes.hamboogie.ingredients]]\nname = \"Lettuce\"\n\n[[dishes.hamboogie.ingredients]]\nname = \"Real Beef Patty\"\n\n[[dishes.hamboogie.ingredients]]\nname = \"Tomato\"\n\n[dishes.eggsalad]\nname = \"Egg Salad with rice\"\nprice = 3.99\n\n[[dishes.eggsalad.ingredients]]\nname = \"Egg\"\n\n[[dishes.eggsalad.ingredients]]\nname = \"Mayo\"\n\n[[dishes.eggsalad.ingredients]]\nname = \"Rice\"\n`\n\tm := &menu{}\n\tif _, err := Decode(tomlBlob, m); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif len(m.Dishes) != 2 {\n\t\tt.Log(\"two dishes should be loaded with UnmarshalTOML()\")\n\t\tt.Errorf(\"expected %d but got %d\", 2, len(m.Dishes))\n\t}\n\n\teggSalad := m.Dishes[\"eggsalad\"]\n\tif _, ok := any(eggSalad).(dish); !ok {\n\t\tt.Errorf(\"expected a dish\")\n\t}\n\n\tif eggSalad.Name != \"Egg Salad with rice\" {\n\t\tt.Errorf(\"expected the dish to be named 'Egg Salad with rice'\")\n\t}\n\n\tif len(eggSalad.Ingredients) != 3 {\n\t\tt.Log(\"dish should be loaded with UnmarshalTOML()\")\n\t\tt.Errorf(\"expected %d but got %d\", 3, len(eggSalad.Ingredients))\n\t}\n\n\tfound := false\n\tfor _, i := range eggSalad.Ingredients {\n\t\tif i.Name == \"Rice\" {\n\t\t\tfound = true\n\t\t\tbreak\n\t\t}\n\t}\n\tif !found {\n\t\tt.Error(\"Rice was not loaded in UnmarshalTOML()\")\n\t}\n\n\t// test on a value - must be passed as *\n\to := menu{}\n\tif _, err := Decode(tomlBlob, &o); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n}\n\ntype menu struct {\n\tDishes map[string]dish\n}\n\nfunc (m *menu) UnmarshalTOML(p any) error {\n\tm.Dishes = make(map[string]dish)\n\tdata, _ := p.(map[string]any)\n\tdishes := data[\"dishes\"].(map[string]any)\n\tfor n, v := range dishes {\n\t\tif d, ok := v.(map[string]any); ok {\n\t\t\tnd := dish{}\n\t\t\tnd.UnmarshalTOML(d)\n\t\t\tm.Dishes[n] = nd\n\t\t} else {\n\t\t\treturn fmt.Errorf(\"not a dish\")\n\t\t}\n\t}\n\treturn nil\n}\n\ntype dish struct {\n\tName        string\n\tPrice       float32\n\tIngredients []ingredient\n}\n\nfunc (d *dish) UnmarshalTOML(p any) error {\n\tdata, _ := p.(map[string]any)\n\td.Name, _ = data[\"name\"].(string)\n\td.Price, _ = data[\"price\"].(float32)\n\tingredients, _ := data[\"ingredients\"].([]map[string]any)\n\tfor _, e := range ingredients {\n\t\tn, _ := any(e).(map[string]any)\n\t\tname, _ := n[\"name\"].(string)\n\t\ti := ingredient{name}\n\t\td.Ingredients = append(d.Ingredients, i)\n\t}\n\treturn nil\n}\n\ntype ingredient struct {\n\tName string\n}\n\nfunc TestDecodePrimitive(t *testing.T) {\n\ttype S struct {\n\t\tP Primitive\n\t}\n\ttype T struct {\n\t\tS []int\n\t}\n\tslicep := func(s []int) *[]int { return &s }\n\tarrayp := func(a [2]int) *[2]int { return &a }\n\tmapp := func(m map[string]int) *map[string]int { return &m }\n\tfor i, tt := range []struct {\n\t\tv     any\n\t\tinput string\n\t\twant  any\n\t}{\n\t\t// slices\n\t\t{slicep(nil), \"\", slicep(nil)},\n\t\t{slicep([]int{}), \"\", slicep([]int{})},\n\t\t{slicep([]int{1, 2, 3}), \"\", slicep([]int{1, 2, 3})},\n\t\t{slicep(nil), \"P = [1,2]\", slicep([]int{1, 2})},\n\t\t{slicep([]int{}), \"P = [1,2]\", slicep([]int{1, 2})},\n\t\t{slicep([]int{1, 2, 3}), \"P = [1,2]\", slicep([]int{1, 2})},\n\n\t\t// arrays\n\t\t{arrayp([2]int{2, 3}), \"\", arrayp([2]int{2, 3})},\n\t\t{arrayp([2]int{2, 3}), \"P = [3,4]\", arrayp([2]int{3, 4})},\n\n\t\t// maps\n\t\t{mapp(nil), \"\", mapp(nil)},\n\t\t{mapp(map[string]int{}), \"\", mapp(map[string]int{})},\n\t\t{mapp(map[string]int{\"a\": 1}), \"\", mapp(map[string]int{\"a\": 1})},\n\t\t{mapp(nil), \"[P]\\na = 2\", mapp(map[string]int{\"a\": 2})},\n\t\t{mapp(map[string]int{}), \"[P]\\na = 2\", mapp(map[string]int{\"a\": 2})},\n\t\t{mapp(map[string]int{\"a\": 1, \"b\": 3}), \"[P]\\na = 2\", mapp(map[string]int{\"a\": 2, \"b\": 3})},\n\n\t\t// structs\n\t\t{&T{nil}, \"[P]\", &T{nil}},\n\t\t{&T{[]int{}}, \"[P]\", &T{[]int{}}},\n\t\t{&T{[]int{1, 2, 3}}, \"[P]\", &T{[]int{1, 2, 3}}},\n\t\t{&T{nil}, \"[P]\\nS = [1,2]\", &T{[]int{1, 2}}},\n\t\t{&T{[]int{}}, \"[P]\\nS = [1,2]\", &T{[]int{1, 2}}},\n\t\t{&T{[]int{1, 2, 3}}, \"[P]\\nS = [1,2]\", &T{[]int{1, 2}}},\n\t} {\n\t\tvar s S\n\t\tmd, err := Decode(tt.input, &s)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"[%d] Decode error: %s\", i, err)\n\t\t\tcontinue\n\t\t}\n\t\tif err := md.PrimitiveDecode(s.P, tt.v); err != nil {\n\t\t\tt.Errorf(\"[%d] PrimitiveDecode error: %s\", i, err)\n\t\t\tcontinue\n\t\t}\n\t\tif !reflect.DeepEqual(tt.v, tt.want) {\n\t\t\tt.Errorf(\"[%d] got %#v; want %#v\", i, tt.v, tt.want)\n\t\t}\n\t}\n}\n\nfunc TestDecodeDatetime(t *testing.T) {\n\t// Test here in addition to toml-test to ensure the TZs are correct.\n\ttz7 := time.FixedZone(\"\", -3600*7)\n\n\tfor _, tt := range []struct {\n\t\tin   string\n\t\twant time.Time\n\t}{\n\t\t// Offset datetime\n\t\t{\"1979-05-27T07:32:00Z\", time.Date(1979, 05, 27, 07, 32, 0, 0, time.UTC)},\n\t\t{\"1979-05-27T07:32:00.999999Z\", time.Date(1979, 05, 27, 07, 32, 0, 999999000, time.UTC)},\n\t\t{\"1979-05-27T00:32:00-07:00\", time.Date(1979, 05, 27, 00, 32, 0, 0, tz7)},\n\t\t{\"1979-05-27T00:32:00.999999-07:00\", time.Date(1979, 05, 27, 00, 32, 0, 999999000, tz7)},\n\t\t{\"1979-05-27T00:32:00.24-07:00\", time.Date(1979, 05, 27, 00, 32, 0, 240000000, tz7)},\n\t\t{\"1979-05-27 07:32:00Z\", time.Date(1979, 05, 27, 07, 32, 0, 0, time.UTC)},\n\t\t{\"1979-05-27t07:32:00z\", time.Date(1979, 05, 27, 07, 32, 0, 0, time.UTC)},\n\n\t\t// Make sure the space between the datetime and \"#\" isn't lexed.\n\t\t{\"1979-05-27T07:32:12-07:00  # c\", time.Date(1979, 05, 27, 07, 32, 12, 0, tz7)},\n\n\t\t// Local times.\n\t\t{\"1979-05-27T07:32:00\", time.Date(1979, 05, 27, 07, 32, 0, 0, internal.LocalDatetime)},\n\t\t{\"1979-05-27T07:32:00.999999\", time.Date(1979, 05, 27, 07, 32, 0, 999999000, internal.LocalDatetime)},\n\t\t{\"1979-05-27T07:32:00.25\", time.Date(1979, 05, 27, 07, 32, 0, 250000000, internal.LocalDatetime)},\n\t\t{\"1979-05-27\", time.Date(1979, 05, 27, 0, 0, 0, 0, internal.LocalDate)},\n\t\t{\"07:32:00\", time.Date(0, 1, 1, 07, 32, 0, 0, internal.LocalTime)},\n\t\t{\"07:32:00.999999\", time.Date(0, 1, 1, 07, 32, 0, 999999000, internal.LocalTime)},\n\t} {\n\t\tt.Run(tt.in, func(t *testing.T) {\n\t\t\tvar x struct{ D time.Time }\n\t\t\tinput := \"d = \" + tt.in\n\t\t\tif _, err := Decode(input, &x); err != nil {\n\t\t\t\tt.Fatalf(\"got error: %s\", err)\n\t\t\t}\n\n\t\t\tif h, w := x.D.Format(time.RFC3339Nano), tt.want.Format(time.RFC3339Nano); h != w {\n\t\t\t\tt.Errorf(\"\\nhave: %s\\nwant: %s\", h, w)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestDecodeTextUnmarshaler(t *testing.T) {\n\ttests := []struct {\n\t\tname string\n\t\tt    any\n\t\ttoml string\n\t\twant string\n\t}{\n\t\t{\n\t\t\t\"time.Time\",\n\t\t\tstruct{ Time time.Time }{},\n\t\t\t\"Time = 1987-07-05T05:45:00Z\",\n\t\t\t\"map[Time:1987-07-05 05:45:00 +0000 UTC]\",\n\t\t},\n\t\t{\n\t\t\t\"*time.Time\",\n\t\t\tstruct{ Time *time.Time }{},\n\t\t\t\"Time = 1988-07-05T05:45:00Z\",\n\t\t\t\"map[Time:1988-07-05 05:45:00 +0000 UTC]\",\n\t\t},\n\t\t{\n\t\t\t\"map[string]time.Time\",\n\t\t\tstruct{ Times map[string]time.Time }{},\n\t\t\t\"Times.one = 1989-07-05T05:45:00Z\\nTimes.two = 1990-07-05T05:45:00Z\",\n\t\t\t\"map[Times:map[one:1989-07-05 05:45:00 +0000 UTC two:1990-07-05 05:45:00 +0000 UTC]]\",\n\t\t},\n\t\t{\n\t\t\t\"map[string]*time.Time\",\n\t\t\tstruct{ Times map[string]*time.Time }{},\n\t\t\t\"Times.one = 1989-07-05T05:45:00Z\\nTimes.two = 1990-07-05T05:45:00Z\",\n\t\t\t\"map[Times:map[one:1989-07-05 05:45:00 +0000 UTC two:1990-07-05 05:45:00 +0000 UTC]]\",\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\t_, err := Decode(tt.toml, &tt.t)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\thave := fmt.Sprintf(\"%v\", tt.t)\n\t\t\tif have != tt.want {\n\t\t\t\tt.Errorf(\"\\nhave: %s\\nwant: %s\", have, tt.want)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestDecodeDuration(t *testing.T) {\n\ttests := []struct {\n\t\tin                  any\n\t\ttoml, want, wantErr string\n\t}{\n\t\t{&struct{ T time.Duration }{}, `t = \"0s\"`,\n\t\t\t\"&{0s}\", \"\"},\n\t\t{&struct{ T time.Duration }{}, `t = \"5m4s\"`,\n\t\t\t\"&{5m4s}\", \"\"},\n\t\t{&struct{ T time.Duration }{}, `t = \"4.000000002s\"`,\n\t\t\t\"&{4.000000002s}\", \"\"},\n\n\t\t{&struct{ T time.Duration }{}, `t = 0`,\n\t\t\t\"&{0s}\", \"\"},\n\t\t{&struct{ T time.Duration }{}, `t = 12345678`,\n\t\t\t\"&{12.345678ms}\", \"\"},\n\n\t\t{&struct{ T *time.Duration }{}, `T = \"5s\"`,\n\t\t\t\"&{5s}\", \"\"},\n\t\t{&struct{ T *time.Duration }{}, `T = 5`,\n\t\t\t\"&{5ns}\", \"\"},\n\n\t\t{&struct{ T map[string]time.Duration }{}, `T.dur = \"5s\"`,\n\t\t\t\"&{map[dur:5s]}\", \"\"},\n\t\t{&struct{ T map[string]*time.Duration }{}, `T.dur = \"5s\"`,\n\t\t\t\"&{map[dur:5s]}\", \"\"},\n\n\t\t{&struct{ T []time.Duration }{}, `T = [\"5s\"]`,\n\t\t\t\"&{[5s]}\", \"\"},\n\t\t{&struct{ T []*time.Duration }{}, `T = [\"5s\"]`,\n\t\t\t\"&{[5s]}\", \"\"},\n\n\t\t{&struct{ T time.Duration }{}, `t = \"99 bottles of beer\"`, \"&{0s}\", `invalid duration: \"99 bottles of beer\"`},\n\t\t{&struct{ T time.Duration }{}, `t = \"one bottle of beer\"`, \"&{0s}\", `invalid duration: \"one bottle of beer\"`},\n\t\t{&struct{ T time.Duration }{}, `t = 1.2`, \"&{0s}\", \"incompatible types:\"},\n\t\t{&struct{ T time.Duration }{}, `t = {}`, \"&{0s}\", \"incompatible types:\"},\n\t\t{&struct{ T time.Duration }{}, `t = []`, \"&{0s}\", \"incompatible types:\"},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(\"\", func(t *testing.T) {\n\t\t\t_, err := Decode(tt.toml, tt.in)\n\t\t\tif !errorContains(err, tt.wantErr) {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\thave := fmt.Sprintf(\"%s\", tt.in)\n\t\t\tif have != tt.want {\n\t\t\t\tt.Errorf(\"\\nhave: %s\\nwant: %s\", have, tt.want)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestDecodeJSONNumber(t *testing.T) {\n\ttests := []struct {\n\t\tin                  any\n\t\ttoml, want, wantErr string\n\t}{\n\t\t{&struct{ D json.Number }{}, `D = 2`, \"&{2}\", \"\"},\n\t\t{&struct{ D json.Number }{}, `D = 2.002`, \"&{2.002}\", \"\"},\n\t\t{&struct{ D *json.Number }{}, `D = 2`, \"&{2}\", \"\"},\n\t\t{&struct{ D *json.Number }{}, `D = 2.002`, \"&{2.002}\", \"\"},\n\t\t{&struct{ D []json.Number }{}, `D = [2, 3.03]`, \"&{[2 3.03]}\", \"\"},\n\t\t{&struct{ D []*json.Number }{}, `D = [2, 3.03]`, \"&{[2 3.03]}\", \"\"},\n\t\t{&struct{ D map[string]json.Number }{}, `D = {a=2, b=3.03}`, \"&{map[a:2 b:3.03]}\", \"\"},\n\t\t{&struct{ D map[string]*json.Number }{}, `D = {a=2, b=3.03}`, \"&{map[a:2 b:3.03]}\", \"\"},\n\n\t\t{&struct{ D json.Number }{}, `D = {}`, \"&{}\", \"incompatible types\"},\n\t\t{&struct{ D json.Number }{}, `D = []`, \"&{}\", \"incompatible types\"},\n\t\t{&struct{ D json.Number }{}, `D = \"2\"`, \"&{}\", \"incompatible types\"},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(\"\", func(t *testing.T) {\n\t\t\t_, err := Decode(tt.toml, tt.in)\n\t\t\tif !errorContains(err, tt.wantErr) {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\thave := fmt.Sprintf(\"%s\", tt.in)\n\t\t\tif have != tt.want {\n\t\t\t\tt.Errorf(\"\\nhave: %s\\nwant: %s\", have, tt.want)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestMetaDotConflict(t *testing.T) {\n\tvar m map[string]any\n\tmeta, err := Decode(`\n\t\t\"a.b\" = \"str\"\n\t\ta.b   = 1\n\t\t\"\"    = 2\n\t`, &m)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\twant := `\"a.b\"=String; a.b=Integer; \"\"=Integer`\n\thave := \"\"\n\tfor i, k := range meta.Keys() {\n\t\tif i > 0 {\n\t\t\thave += \"; \"\n\t\t}\n\t\thave += k.String() + \"=\" + meta.Type(k...)\n\t}\n\tif have != want {\n\t\tt.Errorf(\"\\nhave: %s\\nwant: %s\", have, want)\n\t}\n}\n\ntype (\n\tOuter struct {\n\t\tInt   *InnerInt\n\t\tEnum  *Enum\n\t\tSlice *InnerArrayString\n\t}\n\tEnum             int\n\tInnerInt         struct{ value int }\n\tInnerArrayString struct{ value []string }\n)\n\nconst (\n\tNoValue Enum = iota\n\tOtherValue\n)\n\nfunc (e *Enum) Value() string {\n\tswitch *e {\n\tcase OtherValue:\n\t\treturn \"OTHER_VALUE\"\n\t}\n\treturn \"\"\n}\n\nfunc (e *Enum) MarshalTOML() ([]byte, error) {\n\treturn []byte(`\"` + e.Value() + `\"`), nil\n}\n\nfunc (e *Enum) UnmarshalTOML(value any) error {\n\tsValue, ok := value.(string)\n\tif !ok {\n\t\treturn fmt.Errorf(\"value %v is not a string type\", value)\n\t}\n\tfor _, enum := range []Enum{NoValue, OtherValue} {\n\t\tif enum.Value() == sValue {\n\t\t\t*e = enum\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn errors.New(\"invalid enum value\")\n}\n\nfunc (i *InnerInt) MarshalTOML() ([]byte, error) {\n\treturn []byte(strconv.Itoa(i.value)), nil\n}\nfunc (i *InnerInt) UnmarshalTOML(value any) error {\n\tiValue, ok := value.(int64)\n\tif !ok {\n\t\treturn fmt.Errorf(\"value %v is not a int type\", value)\n\t}\n\ti.value = int(iValue)\n\treturn nil\n}\n\nfunc (as *InnerArrayString) MarshalTOML() ([]byte, error) {\n\treturn []byte(\"[\\\"\" + strings.Join(as.value, \"\\\", \\\"\") + \"\\\"]\"), nil\n}\n\nfunc (as *InnerArrayString) UnmarshalTOML(value any) error {\n\tif value != nil {\n\t\tasValue, ok := value.([]any)\n\t\tif !ok {\n\t\t\treturn fmt.Errorf(\"value %v is not a [] type\", value)\n\t\t}\n\t\tas.value = []string{}\n\t\tfor _, value := range asValue {\n\t\t\tas.value = append(as.value, value.(string))\n\t\t}\n\t}\n\treturn nil\n}\n\n// Test for #341\nfunc TestCustomEncode(t *testing.T) {\n\tenum := OtherValue\n\touter := Outer{\n\t\tInt:   &InnerInt{value: 10},\n\t\tEnum:  &enum,\n\t\tSlice: &InnerArrayString{value: []string{\"text1\", \"text2\"}},\n\t}\n\n\tvar buf bytes.Buffer\n\terr := NewEncoder(&buf).Encode(outer)\n\tif err != nil {\n\t\tt.Errorf(\"Encode failed: %s\", err)\n\t}\n\n\thave := strings.TrimSpace(buf.String())\n\twant := strings.ReplaceAll(strings.TrimSpace(`\n\t\tInt = 10\n\t\tEnum = \"OTHER_VALUE\"\n\t\tSlice = [\"text1\", \"text2\"]\n\t`), \"\\t\", \"\")\n\tif want != have {\n\t\tt.Errorf(\"\\nhave: %s\\nwant: %s\\n\", have, want)\n\t}\n}\n\n// Test for #341\nfunc TestCustomDecode(t *testing.T) {\n\tvar outer Outer\n\t_, err := Decode(`\n\t\tInt = 10\n\t\tEnum = \"OTHER_VALUE\"\n\t\tSlice = [\"text1\", \"text2\"]\n\t`, &outer)\n\tif err != nil {\n\t\tt.Fatalf(\"Decode failed: %s\", err)\n\t}\n\n\tif outer.Int.value != 10 {\n\t\tt.Errorf(\"\\nhave:\\n%v\\nwant:\\n%v\\n\", outer.Int.value, 10)\n\t}\n\tif *outer.Enum != OtherValue {\n\t\tt.Errorf(\"\\nhave:\\n%v\\nwant:\\n%v\\n\", outer.Enum, OtherValue)\n\t}\n\tif fmt.Sprint(outer.Slice.value) != fmt.Sprint([]string{\"text1\", \"text2\"}) {\n\t\tt.Errorf(\"\\nhave:\\n%v\\nwant:\\n%v\\n\", outer.Slice.value, []string{\"text1\", \"text2\"})\n\t}\n}\n\n// TODO: this should be improved for v2:\n// https://github.com/BurntSushi/toml/issues/384\nfunc TestDecodeDoubleTags(t *testing.T) {\n\tvar s struct {\n\t\tA int `toml:\"a\"`\n\t\tB int `toml:\"a\"`\n\t\tC int `toml:\"c\"`\n\t}\n\t_, err := Decode(`\n\t\ta = 1\n\t\tb = 2\n\t\tc = 3\n\t`, &s)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\twant := `{0 0 3}`\n\thave := fmt.Sprintf(\"%v\", s)\n\tif want != have {\n\t\tt.Errorf(\"\\nhave: %s\\nwant: %s\\n\", have, want)\n\t}\n}\n\nfunc TestMetaKeys(t *testing.T) {\n\ttests := []struct {\n\t\tin   string\n\t\twant []Key\n\t}{\n\t\t{\"\", []Key{}},\n\t\t{\"b=1\\na=1\", []Key{Key{\"b\"}, Key{\"a\"}}},\n\t\t{\"a.b=1\\na.a=1\", []Key{Key{\"a\", \"b\"}, Key{\"a\", \"a\"}}}, // TODO: should include \"a\"\n\t\t{\"[tbl]\\na=1\", []Key{Key{\"tbl\"}, Key{\"tbl\", \"a\"}}},\n\t\t{\"[tbl]\\na.a=1\", []Key{Key{\"tbl\"}, Key{\"tbl\", \"a\", \"a\"}}}, // TODO: should include \"a.a\"\n\t\t{\"tbl={a=1}\", []Key{Key{\"tbl\"}, Key{\"tbl\", \"a\"}}},\n\t\t{\"tbl={a={b=1}}\", []Key{Key{\"tbl\"}, Key{\"tbl\", \"a\"}, Key{\"tbl\", \"a\", \"b\"}}},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(\"\", func(t *testing.T) {\n\t\t\tvar x any\n\t\t\tmeta, err := Decode(tt.in, &x)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\thave := meta.Keys()\n\t\t\tif !reflect.DeepEqual(tt.want, have) {\n\t\t\t\tt.Errorf(\"\\nhave: %s\\nwant: %s\\n\", have, tt.want)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestDecodeParallel(t *testing.T) {\n\tdoc, err := os.ReadFile(\"testdata/Cargo.toml\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvar wg sync.WaitGroup\n\tfor i := 0; i < 10; i++ {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\terr := Unmarshal(doc, new(map[string]any))\n\t\t\tif err != nil {\n\t\t\t\tpanic(err)\n\t\t\t}\n\t\t}()\n\t}\n\twg.Wait()\n}\n\n// errorContains checks if the error message in have contains the text in\n// want.\n//\n// This is safe when have is nil. Use an empty string for want if you want to\n// test that err is nil.\nfunc errorContains(have error, want string) bool {\n\tif have == nil {\n\t\treturn want == \"\"\n\t}\n\tif want == \"\" {\n\t\treturn false\n\t}\n\treturn strings.Contains(have.Error(), want)\n}\n\nfunc BenchmarkEscapes(b *testing.B) {\n\tp := new(parser)\n\tit := item{}\n\tstr := strings.Repeat(\"hello, world!\\n\", 10)\n\tb.ResetTimer()\n\tfor n := 0; n < b.N; n++ {\n\t\tp.replaceEscapes(it, str)\n\t}\n}\n\nfunc BenchmarkKey(b *testing.B) {\n\tk := Key{\"cargo-credential-macos-keychain\", \"version\"}\n\tb.ResetTimer()\n\tfor n := 0; n < b.N; n++ {\n\t\tk.String()\n\t}\n}\n"
        },
        {
          "name": "deprecated.go",
          "type": "blob",
          "size": 0.8017578125,
          "content": "package toml\n\nimport (\n\t\"encoding\"\n\t\"io\"\n)\n\n// TextMarshaler is an alias for encoding.TextMarshaler.\n//\n// Deprecated: use encoding.TextMarshaler\ntype TextMarshaler encoding.TextMarshaler\n\n// TextUnmarshaler is an alias for encoding.TextUnmarshaler.\n//\n// Deprecated: use encoding.TextUnmarshaler\ntype TextUnmarshaler encoding.TextUnmarshaler\n\n// DecodeReader is an alias for NewDecoder(r).Decode(v).\n//\n// Deprecated: use NewDecoder(reader).Decode(&value).\nfunc DecodeReader(r io.Reader, v any) (MetaData, error) { return NewDecoder(r).Decode(v) }\n\n// PrimitiveDecode is an alias for MetaData.PrimitiveDecode().\n//\n// Deprecated: use MetaData.PrimitiveDecode.\nfunc PrimitiveDecode(primValue Primitive, v any) error {\n\tmd := MetaData{decoded: make(map[string]struct{})}\n\treturn md.unify(primValue.undecoded, rvalue(v))\n}\n"
        },
        {
          "name": "doc.go",
          "type": "blob",
          "size": 0.3359375,
          "content": "// Package toml implements decoding and encoding of TOML files.\n//\n// This package supports TOML v1.0.0, as specified at https://toml.io\n//\n// The github.com/BurntSushi/toml/cmd/tomlv package implements a TOML validator,\n// and can be used to verify if TOML document is valid. It can also be used to\n// print the type of each key.\npackage toml\n"
        },
        {
          "name": "encode.go",
          "type": "blob",
          "size": 18.8994140625,
          "content": "package toml\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"encoding\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"math\"\n\t\"reflect\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/BurntSushi/toml/internal\"\n)\n\ntype tomlEncodeError struct{ error }\n\nvar (\n\terrArrayNilElement = errors.New(\"toml: cannot encode array with nil element\")\n\terrNonString       = errors.New(\"toml: cannot encode a map with non-string key type\")\n\terrNoKey           = errors.New(\"toml: top-level values must be Go maps or structs\")\n\terrAnything        = errors.New(\"\") // used in testing\n)\n\nvar dblQuotedReplacer = strings.NewReplacer(\n\t\"\\\"\", \"\\\\\\\"\",\n\t\"\\\\\", \"\\\\\\\\\",\n\t\"\\x00\", `\\u0000`,\n\t\"\\x01\", `\\u0001`,\n\t\"\\x02\", `\\u0002`,\n\t\"\\x03\", `\\u0003`,\n\t\"\\x04\", `\\u0004`,\n\t\"\\x05\", `\\u0005`,\n\t\"\\x06\", `\\u0006`,\n\t\"\\x07\", `\\u0007`,\n\t\"\\b\", `\\b`,\n\t\"\\t\", `\\t`,\n\t\"\\n\", `\\n`,\n\t\"\\x0b\", `\\u000b`,\n\t\"\\f\", `\\f`,\n\t\"\\r\", `\\r`,\n\t\"\\x0e\", `\\u000e`,\n\t\"\\x0f\", `\\u000f`,\n\t\"\\x10\", `\\u0010`,\n\t\"\\x11\", `\\u0011`,\n\t\"\\x12\", `\\u0012`,\n\t\"\\x13\", `\\u0013`,\n\t\"\\x14\", `\\u0014`,\n\t\"\\x15\", `\\u0015`,\n\t\"\\x16\", `\\u0016`,\n\t\"\\x17\", `\\u0017`,\n\t\"\\x18\", `\\u0018`,\n\t\"\\x19\", `\\u0019`,\n\t\"\\x1a\", `\\u001a`,\n\t\"\\x1b\", `\\u001b`,\n\t\"\\x1c\", `\\u001c`,\n\t\"\\x1d\", `\\u001d`,\n\t\"\\x1e\", `\\u001e`,\n\t\"\\x1f\", `\\u001f`,\n\t\"\\x7f\", `\\u007f`,\n)\n\nvar (\n\tmarshalToml = reflect.TypeOf((*Marshaler)(nil)).Elem()\n\tmarshalText = reflect.TypeOf((*encoding.TextMarshaler)(nil)).Elem()\n\ttimeType    = reflect.TypeOf((*time.Time)(nil)).Elem()\n)\n\n// Marshaler is the interface implemented by types that can marshal themselves\n// into valid TOML.\ntype Marshaler interface {\n\tMarshalTOML() ([]byte, error)\n}\n\n// Marshal returns a TOML representation of the Go value.\n//\n// See [Encoder] for a description of the encoding process.\nfunc Marshal(v any) ([]byte, error) {\n\tbuff := new(bytes.Buffer)\n\tif err := NewEncoder(buff).Encode(v); err != nil {\n\t\treturn nil, err\n\t}\n\treturn buff.Bytes(), nil\n}\n\n// Encoder encodes a Go to a TOML document.\n//\n// The mapping between Go values and TOML values should be precisely the same as\n// for [Decode].\n//\n// time.Time is encoded as a RFC 3339 string, and time.Duration as its string\n// representation.\n//\n// The [Marshaler] and [encoding.TextMarshaler] interfaces are supported to\n// encoding the value as custom TOML.\n//\n// If you want to write arbitrary binary data then you will need to use\n// something like base64 since TOML does not have any binary types.\n//\n// When encoding TOML hashes (Go maps or structs), keys without any sub-hashes\n// are encoded first.\n//\n// Go maps will be sorted alphabetically by key for deterministic output.\n//\n// The toml struct tag can be used to provide the key name; if omitted the\n// struct field name will be used. If the \"omitempty\" option is present the\n// following value will be skipped:\n//\n//   - arrays, slices, maps, and string with len of 0\n//   - struct with all zero values\n//   - bool false\n//\n// If omitzero is given all int and float types with a value of 0 will be\n// skipped.\n//\n// Encoding Go values without a corresponding TOML representation will return an\n// error. Examples of this includes maps with non-string keys, slices with nil\n// elements, embedded non-struct types, and nested slices containing maps or\n// structs. (e.g. [][]map[string]string is not allowed but []map[string]string\n// is okay, as is []map[string][]string).\n//\n// NOTE: only exported keys are encoded due to the use of reflection. Unexported\n// keys are silently discarded.\ntype Encoder struct {\n\tIndent     string // string for a single indentation level; default is two spaces.\n\thasWritten bool   // written any output to w yet?\n\tw          *bufio.Writer\n}\n\n// NewEncoder create a new Encoder.\nfunc NewEncoder(w io.Writer) *Encoder {\n\treturn &Encoder{w: bufio.NewWriter(w), Indent: \"  \"}\n}\n\n// Encode writes a TOML representation of the Go value to the [Encoder]'s writer.\n//\n// An error is returned if the value given cannot be encoded to a valid TOML\n// document.\nfunc (enc *Encoder) Encode(v any) error {\n\trv := eindirect(reflect.ValueOf(v))\n\terr := enc.safeEncode(Key([]string{}), rv)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn enc.w.Flush()\n}\n\nfunc (enc *Encoder) safeEncode(key Key, rv reflect.Value) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tif terr, ok := r.(tomlEncodeError); ok {\n\t\t\t\terr = terr.error\n\t\t\t\treturn\n\t\t\t}\n\t\t\tpanic(r)\n\t\t}\n\t}()\n\tenc.encode(key, rv)\n\treturn nil\n}\n\nfunc (enc *Encoder) encode(key Key, rv reflect.Value) {\n\t// If we can marshal the type to text, then we use that. This prevents the\n\t// encoder for handling these types as generic structs (or whatever the\n\t// underlying type of a TextMarshaler is).\n\tswitch {\n\tcase isMarshaler(rv):\n\t\tenc.writeKeyValue(key, rv, false)\n\t\treturn\n\tcase rv.Type() == primitiveType: // TODO: #76 would make this superfluous after implemented.\n\t\tenc.encode(key, reflect.ValueOf(rv.Interface().(Primitive).undecoded))\n\t\treturn\n\t}\n\n\tk := rv.Kind()\n\tswitch k {\n\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32,\n\t\treflect.Int64,\n\t\treflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32,\n\t\treflect.Uint64,\n\t\treflect.Float32, reflect.Float64, reflect.String, reflect.Bool:\n\t\tenc.writeKeyValue(key, rv, false)\n\tcase reflect.Array, reflect.Slice:\n\t\tif typeEqual(tomlArrayHash, tomlTypeOfGo(rv)) {\n\t\t\tenc.eArrayOfTables(key, rv)\n\t\t} else {\n\t\t\tenc.writeKeyValue(key, rv, false)\n\t\t}\n\tcase reflect.Interface:\n\t\tif rv.IsNil() {\n\t\t\treturn\n\t\t}\n\t\tenc.encode(key, rv.Elem())\n\tcase reflect.Map:\n\t\tif rv.IsNil() {\n\t\t\treturn\n\t\t}\n\t\tenc.eTable(key, rv)\n\tcase reflect.Ptr:\n\t\tif rv.IsNil() {\n\t\t\treturn\n\t\t}\n\t\tenc.encode(key, rv.Elem())\n\tcase reflect.Struct:\n\t\tenc.eTable(key, rv)\n\tdefault:\n\t\tencPanic(fmt.Errorf(\"unsupported type for key '%s': %s\", key, k))\n\t}\n}\n\n// eElement encodes any value that can be an array element.\nfunc (enc *Encoder) eElement(rv reflect.Value) {\n\tswitch v := rv.Interface().(type) {\n\tcase time.Time: // Using TextMarshaler adds extra quotes, which we don't want.\n\t\tformat := time.RFC3339Nano\n\t\tswitch v.Location() {\n\t\tcase internal.LocalDatetime:\n\t\t\tformat = \"2006-01-02T15:04:05.999999999\"\n\t\tcase internal.LocalDate:\n\t\t\tformat = \"2006-01-02\"\n\t\tcase internal.LocalTime:\n\t\t\tformat = \"15:04:05.999999999\"\n\t\t}\n\t\tswitch v.Location() {\n\t\tdefault:\n\t\t\tenc.wf(v.Format(format))\n\t\tcase internal.LocalDatetime, internal.LocalDate, internal.LocalTime:\n\t\t\tenc.wf(v.In(time.UTC).Format(format))\n\t\t}\n\t\treturn\n\tcase Marshaler:\n\t\ts, err := v.MarshalTOML()\n\t\tif err != nil {\n\t\t\tencPanic(err)\n\t\t}\n\t\tif s == nil {\n\t\t\tencPanic(errors.New(\"MarshalTOML returned nil and no error\"))\n\t\t}\n\t\tenc.w.Write(s)\n\t\treturn\n\tcase encoding.TextMarshaler:\n\t\ts, err := v.MarshalText()\n\t\tif err != nil {\n\t\t\tencPanic(err)\n\t\t}\n\t\tif s == nil {\n\t\t\tencPanic(errors.New(\"MarshalText returned nil and no error\"))\n\t\t}\n\t\tenc.writeQuoted(string(s))\n\t\treturn\n\tcase time.Duration:\n\t\tenc.writeQuoted(v.String())\n\t\treturn\n\tcase json.Number:\n\t\tn, _ := rv.Interface().(json.Number)\n\n\t\tif n == \"\" { /// Useful zero value.\n\t\t\tenc.w.WriteByte('0')\n\t\t\treturn\n\t\t} else if v, err := n.Int64(); err == nil {\n\t\t\tenc.eElement(reflect.ValueOf(v))\n\t\t\treturn\n\t\t} else if v, err := n.Float64(); err == nil {\n\t\t\tenc.eElement(reflect.ValueOf(v))\n\t\t\treturn\n\t\t}\n\t\tencPanic(fmt.Errorf(\"unable to convert %q to int64 or float64\", n))\n\t}\n\n\tswitch rv.Kind() {\n\tcase reflect.Ptr:\n\t\tenc.eElement(rv.Elem())\n\t\treturn\n\tcase reflect.String:\n\t\tenc.writeQuoted(rv.String())\n\tcase reflect.Bool:\n\t\tenc.wf(strconv.FormatBool(rv.Bool()))\n\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\n\t\tenc.wf(strconv.FormatInt(rv.Int(), 10))\n\tcase reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64:\n\t\tenc.wf(strconv.FormatUint(rv.Uint(), 10))\n\tcase reflect.Float32:\n\t\tf := rv.Float()\n\t\tif math.IsNaN(f) {\n\t\t\tif math.Signbit(f) {\n\t\t\t\tenc.wf(\"-\")\n\t\t\t}\n\t\t\tenc.wf(\"nan\")\n\t\t} else if math.IsInf(f, 0) {\n\t\t\tif math.Signbit(f) {\n\t\t\t\tenc.wf(\"-\")\n\t\t\t}\n\t\t\tenc.wf(\"inf\")\n\t\t} else {\n\t\t\tenc.wf(floatAddDecimal(strconv.FormatFloat(f, 'f', -1, 32)))\n\t\t}\n\tcase reflect.Float64:\n\t\tf := rv.Float()\n\t\tif math.IsNaN(f) {\n\t\t\tif math.Signbit(f) {\n\t\t\t\tenc.wf(\"-\")\n\t\t\t}\n\t\t\tenc.wf(\"nan\")\n\t\t} else if math.IsInf(f, 0) {\n\t\t\tif math.Signbit(f) {\n\t\t\t\tenc.wf(\"-\")\n\t\t\t}\n\t\t\tenc.wf(\"inf\")\n\t\t} else {\n\t\t\tenc.wf(floatAddDecimal(strconv.FormatFloat(f, 'f', -1, 64)))\n\t\t}\n\tcase reflect.Array, reflect.Slice:\n\t\tenc.eArrayOrSliceElement(rv)\n\tcase reflect.Struct:\n\t\tenc.eStruct(nil, rv, true)\n\tcase reflect.Map:\n\t\tenc.eMap(nil, rv, true)\n\tcase reflect.Interface:\n\t\tenc.eElement(rv.Elem())\n\tdefault:\n\t\tencPanic(fmt.Errorf(\"unexpected type: %s\", fmtType(rv.Interface())))\n\t}\n}\n\n// By the TOML spec, all floats must have a decimal with at least one number on\n// either side.\nfunc floatAddDecimal(fstr string) string {\n\tif !strings.Contains(fstr, \".\") {\n\t\treturn fstr + \".0\"\n\t}\n\treturn fstr\n}\n\nfunc (enc *Encoder) writeQuoted(s string) {\n\tenc.wf(\"\\\"%s\\\"\", dblQuotedReplacer.Replace(s))\n}\n\nfunc (enc *Encoder) eArrayOrSliceElement(rv reflect.Value) {\n\tlength := rv.Len()\n\tenc.wf(\"[\")\n\tfor i := 0; i < length; i++ {\n\t\telem := eindirect(rv.Index(i))\n\t\tenc.eElement(elem)\n\t\tif i != length-1 {\n\t\t\tenc.wf(\", \")\n\t\t}\n\t}\n\tenc.wf(\"]\")\n}\n\nfunc (enc *Encoder) eArrayOfTables(key Key, rv reflect.Value) {\n\tif len(key) == 0 {\n\t\tencPanic(errNoKey)\n\t}\n\tfor i := 0; i < rv.Len(); i++ {\n\t\ttrv := eindirect(rv.Index(i))\n\t\tif isNil(trv) {\n\t\t\tcontinue\n\t\t}\n\t\tenc.newline()\n\t\tenc.wf(\"%s[[%s]]\", enc.indentStr(key), key)\n\t\tenc.newline()\n\t\tenc.eMapOrStruct(key, trv, false)\n\t}\n}\n\nfunc (enc *Encoder) eTable(key Key, rv reflect.Value) {\n\tif len(key) == 1 {\n\t\t// Output an extra newline between top-level tables.\n\t\t// (The newline isn't written if nothing else has been written though.)\n\t\tenc.newline()\n\t}\n\tif len(key) > 0 {\n\t\tenc.wf(\"%s[%s]\", enc.indentStr(key), key)\n\t\tenc.newline()\n\t}\n\tenc.eMapOrStruct(key, rv, false)\n}\n\nfunc (enc *Encoder) eMapOrStruct(key Key, rv reflect.Value, inline bool) {\n\tswitch rv.Kind() {\n\tcase reflect.Map:\n\t\tenc.eMap(key, rv, inline)\n\tcase reflect.Struct:\n\t\tenc.eStruct(key, rv, inline)\n\tdefault:\n\t\t// Should never happen?\n\t\tpanic(\"eTable: unhandled reflect.Value Kind: \" + rv.Kind().String())\n\t}\n}\n\nfunc (enc *Encoder) eMap(key Key, rv reflect.Value, inline bool) {\n\trt := rv.Type()\n\tif rt.Key().Kind() != reflect.String {\n\t\tencPanic(errNonString)\n\t}\n\n\t// Sort keys so that we have deterministic output. And write keys directly\n\t// underneath this key first, before writing sub-structs or sub-maps.\n\tvar mapKeysDirect, mapKeysSub []reflect.Value\n\tfor _, mapKey := range rv.MapKeys() {\n\t\tif typeIsTable(tomlTypeOfGo(eindirect(rv.MapIndex(mapKey)))) {\n\t\t\tmapKeysSub = append(mapKeysSub, mapKey)\n\t\t} else {\n\t\t\tmapKeysDirect = append(mapKeysDirect, mapKey)\n\t\t}\n\t}\n\n\twriteMapKeys := func(mapKeys []reflect.Value, trailC bool) {\n\t\tsort.Slice(mapKeys, func(i, j int) bool { return mapKeys[i].String() < mapKeys[j].String() })\n\t\tfor i, mapKey := range mapKeys {\n\t\t\tval := eindirect(rv.MapIndex(mapKey))\n\t\t\tif isNil(val) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif inline {\n\t\t\t\tenc.writeKeyValue(Key{mapKey.String()}, val, true)\n\t\t\t\tif trailC || i != len(mapKeys)-1 {\n\t\t\t\t\tenc.wf(\", \")\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tenc.encode(key.add(mapKey.String()), val)\n\t\t\t}\n\t\t}\n\t}\n\n\tif inline {\n\t\tenc.wf(\"{\")\n\t}\n\twriteMapKeys(mapKeysDirect, len(mapKeysSub) > 0)\n\twriteMapKeys(mapKeysSub, false)\n\tif inline {\n\t\tenc.wf(\"}\")\n\t}\n}\n\nconst is32Bit = (32 << (^uint(0) >> 63)) == 32\n\nfunc pointerTo(t reflect.Type) reflect.Type {\n\tif t.Kind() == reflect.Ptr {\n\t\treturn pointerTo(t.Elem())\n\t}\n\treturn t\n}\n\nfunc (enc *Encoder) eStruct(key Key, rv reflect.Value, inline bool) {\n\t// Write keys for fields directly under this key first, because if we write\n\t// a field that creates a new table then all keys under it will be in that\n\t// table (not the one we're writing here).\n\t//\n\t// Fields is a [][]int: for fieldsDirect this always has one entry (the\n\t// struct index). For fieldsSub it contains two entries: the parent field\n\t// index from tv, and the field indexes for the fields of the sub.\n\tvar (\n\t\trt                      = rv.Type()\n\t\tfieldsDirect, fieldsSub [][]int\n\t\taddFields               func(rt reflect.Type, rv reflect.Value, start []int)\n\t)\n\taddFields = func(rt reflect.Type, rv reflect.Value, start []int) {\n\t\tfor i := 0; i < rt.NumField(); i++ {\n\t\t\tf := rt.Field(i)\n\t\t\tisEmbed := f.Anonymous && pointerTo(f.Type).Kind() == reflect.Struct\n\t\t\tif f.PkgPath != \"\" && !isEmbed { /// Skip unexported fields.\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\topts := getOptions(f.Tag)\n\t\t\tif opts.skip {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tfrv := eindirect(rv.Field(i))\n\n\t\t\tif is32Bit {\n\t\t\t\t// Copy so it works correct on 32bit archs; not clear why this\n\t\t\t\t// is needed. See #314, and https://www.reddit.com/r/golang/comments/pnx8v4\n\t\t\t\t// This also works fine on 64bit, but 32bit archs are somewhat\n\t\t\t\t// rare and this is a wee bit faster.\n\t\t\t\tcopyStart := make([]int, len(start))\n\t\t\t\tcopy(copyStart, start)\n\t\t\t\tstart = copyStart\n\t\t\t}\n\n\t\t\t// Treat anonymous struct fields with tag names as though they are\n\t\t\t// not anonymous, like encoding/json does.\n\t\t\t//\n\t\t\t// Non-struct anonymous fields use the normal encoding logic.\n\t\t\tif isEmbed {\n\t\t\t\tif getOptions(f.Tag).name == \"\" && frv.Kind() == reflect.Struct {\n\t\t\t\t\taddFields(frv.Type(), frv, append(start, f.Index...))\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif typeIsTable(tomlTypeOfGo(frv)) {\n\t\t\t\tfieldsSub = append(fieldsSub, append(start, f.Index...))\n\t\t\t} else {\n\t\t\t\tfieldsDirect = append(fieldsDirect, append(start, f.Index...))\n\t\t\t}\n\t\t}\n\t}\n\taddFields(rt, rv, nil)\n\n\twriteFields := func(fields [][]int) {\n\t\tfor _, fieldIndex := range fields {\n\t\t\tfieldType := rt.FieldByIndex(fieldIndex)\n\t\t\tfieldVal := rv.FieldByIndex(fieldIndex)\n\n\t\t\topts := getOptions(fieldType.Tag)\n\t\t\tif opts.skip {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif opts.omitempty && isEmpty(fieldVal) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tfieldVal = eindirect(fieldVal)\n\n\t\t\tif isNil(fieldVal) { /// Don't write anything for nil fields.\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tkeyName := fieldType.Name\n\t\t\tif opts.name != \"\" {\n\t\t\t\tkeyName = opts.name\n\t\t\t}\n\n\t\t\tif opts.omitzero && isZero(fieldVal) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif inline {\n\t\t\t\tenc.writeKeyValue(Key{keyName}, fieldVal, true)\n\t\t\t\tif fieldIndex[0] != len(fields)-1 {\n\t\t\t\t\tenc.wf(\", \")\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tenc.encode(key.add(keyName), fieldVal)\n\t\t\t}\n\t\t}\n\t}\n\n\tif inline {\n\t\tenc.wf(\"{\")\n\t}\n\twriteFields(fieldsDirect)\n\twriteFields(fieldsSub)\n\tif inline {\n\t\tenc.wf(\"}\")\n\t}\n}\n\n// tomlTypeOfGo returns the TOML type name of the Go value's type.\n//\n// It is used to determine whether the types of array elements are mixed (which\n// is forbidden). If the Go value is nil, then it is illegal for it to be an\n// array element, and valueIsNil is returned as true.\n//\n// The type may be `nil`, which means no concrete TOML type could be found.\nfunc tomlTypeOfGo(rv reflect.Value) tomlType {\n\tif isNil(rv) || !rv.IsValid() {\n\t\treturn nil\n\t}\n\n\tif rv.Kind() == reflect.Struct {\n\t\tif rv.Type() == timeType {\n\t\t\treturn tomlDatetime\n\t\t}\n\t\tif isMarshaler(rv) {\n\t\t\treturn tomlString\n\t\t}\n\t\treturn tomlHash\n\t}\n\n\tif isMarshaler(rv) {\n\t\treturn tomlString\n\t}\n\n\tswitch rv.Kind() {\n\tcase reflect.Bool:\n\t\treturn tomlBool\n\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32,\n\t\treflect.Int64,\n\t\treflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32,\n\t\treflect.Uint64:\n\t\treturn tomlInteger\n\tcase reflect.Float32, reflect.Float64:\n\t\treturn tomlFloat\n\tcase reflect.Array, reflect.Slice:\n\t\tif isTableArray(rv) {\n\t\t\treturn tomlArrayHash\n\t\t}\n\t\treturn tomlArray\n\tcase reflect.Ptr, reflect.Interface:\n\t\treturn tomlTypeOfGo(rv.Elem())\n\tcase reflect.String:\n\t\treturn tomlString\n\tcase reflect.Map:\n\t\treturn tomlHash\n\tdefault:\n\t\tencPanic(errors.New(\"unsupported type: \" + rv.Kind().String()))\n\t\tpanic(\"unreachable\")\n\t}\n}\n\nfunc isMarshaler(rv reflect.Value) bool {\n\treturn rv.Type().Implements(marshalText) || rv.Type().Implements(marshalToml)\n}\n\n// isTableArray reports if all entries in the array or slice are a table.\nfunc isTableArray(arr reflect.Value) bool {\n\tif isNil(arr) || !arr.IsValid() || arr.Len() == 0 {\n\t\treturn false\n\t}\n\n\tret := true\n\tfor i := 0; i < arr.Len(); i++ {\n\t\ttt := tomlTypeOfGo(eindirect(arr.Index(i)))\n\t\t// Don't allow nil.\n\t\tif tt == nil {\n\t\t\tencPanic(errArrayNilElement)\n\t\t}\n\n\t\tif ret && !typeEqual(tomlHash, tt) {\n\t\t\tret = false\n\t\t}\n\t}\n\treturn ret\n}\n\ntype tagOptions struct {\n\tskip      bool // \"-\"\n\tname      string\n\tomitempty bool\n\tomitzero  bool\n}\n\nfunc getOptions(tag reflect.StructTag) tagOptions {\n\tt := tag.Get(\"toml\")\n\tif t == \"-\" {\n\t\treturn tagOptions{skip: true}\n\t}\n\tvar opts tagOptions\n\tparts := strings.Split(t, \",\")\n\topts.name = parts[0]\n\tfor _, s := range parts[1:] {\n\t\tswitch s {\n\t\tcase \"omitempty\":\n\t\t\topts.omitempty = true\n\t\tcase \"omitzero\":\n\t\t\topts.omitzero = true\n\t\t}\n\t}\n\treturn opts\n}\n\nfunc isZero(rv reflect.Value) bool {\n\tswitch rv.Kind() {\n\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\n\t\treturn rv.Int() == 0\n\tcase reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64:\n\t\treturn rv.Uint() == 0\n\tcase reflect.Float32, reflect.Float64:\n\t\treturn rv.Float() == 0.0\n\t}\n\treturn false\n}\n\nfunc isEmpty(rv reflect.Value) bool {\n\tswitch rv.Kind() {\n\tcase reflect.Array, reflect.Slice, reflect.Map, reflect.String:\n\t\treturn rv.Len() == 0\n\tcase reflect.Struct:\n\t\tif rv.Type().Comparable() {\n\t\t\treturn reflect.Zero(rv.Type()).Interface() == rv.Interface()\n\t\t}\n\t\t// Need to also check if all the fields are empty, otherwise something\n\t\t// like this with uncomparable types will always return true:\n\t\t//\n\t\t//   type a struct{ field b }\n\t\t//   type b struct{ s []string }\n\t\t//   s := a{field: b{s: []string{\"AAA\"}}}\n\t\tfor i := 0; i < rv.NumField(); i++ {\n\t\t\tif !isEmpty(rv.Field(i)) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase reflect.Bool:\n\t\treturn !rv.Bool()\n\tcase reflect.Ptr:\n\t\treturn rv.IsNil()\n\t}\n\treturn false\n}\n\nfunc (enc *Encoder) newline() {\n\tif enc.hasWritten {\n\t\tenc.wf(\"\\n\")\n\t}\n}\n\n// Write a key/value pair:\n//\n//\tkey = <any value>\n//\n// This is also used for \"k = v\" in inline tables; so something like this will\n// be written in three calls:\n//\n//\t\n//\t        \n//\tv      v   v  v    vv\n//\tkey = {k = 1, k2 = 2}\nfunc (enc *Encoder) writeKeyValue(key Key, val reflect.Value, inline bool) {\n\t/// Marshaler used on top-level document; call eElement() to just call\n\t/// Marshal{TOML,Text}.\n\tif len(key) == 0 {\n\t\tenc.eElement(val)\n\t\treturn\n\t}\n\tenc.wf(\"%s%s = \", enc.indentStr(key), key.maybeQuoted(len(key)-1))\n\tenc.eElement(val)\n\tif !inline {\n\t\tenc.newline()\n\t}\n}\n\nfunc (enc *Encoder) wf(format string, v ...any) {\n\t_, err := fmt.Fprintf(enc.w, format, v...)\n\tif err != nil {\n\t\tencPanic(err)\n\t}\n\tenc.hasWritten = true\n}\n\nfunc (enc *Encoder) indentStr(key Key) string {\n\treturn strings.Repeat(enc.Indent, len(key)-1)\n}\n\nfunc encPanic(err error) {\n\tpanic(tomlEncodeError{err})\n}\n\n// Resolve any level of pointers to the actual value (e.g. **string  string).\nfunc eindirect(v reflect.Value) reflect.Value {\n\tif v.Kind() != reflect.Ptr && v.Kind() != reflect.Interface {\n\t\tif isMarshaler(v) {\n\t\t\treturn v\n\t\t}\n\t\tif v.CanAddr() { /// Special case for marshalers; see #358.\n\t\t\tif pv := v.Addr(); isMarshaler(pv) {\n\t\t\t\treturn pv\n\t\t\t}\n\t\t}\n\t\treturn v\n\t}\n\n\tif v.IsNil() {\n\t\treturn v\n\t}\n\n\treturn eindirect(v.Elem())\n}\n\nfunc isNil(rv reflect.Value) bool {\n\tswitch rv.Kind() {\n\tcase reflect.Interface, reflect.Map, reflect.Ptr, reflect.Slice:\n\t\treturn rv.IsNil()\n\tdefault:\n\t\treturn false\n\t}\n}\n"
        },
        {
          "name": "encode_test.go",
          "type": "blob",
          "size": 30.4189453125,
          "content": "package toml\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"math\"\n\t\"net\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestEncodeRoundTrip(t *testing.T) {\n\ttype Config struct {\n\t\tAge        int\n\t\tCats       []string\n\t\tPi         float64\n\t\tPerfection []int\n\t\tDOB        time.Time\n\t\tIpaddress  net.IP\n\t}\n\n\tvar inputs = Config{\n\t\tAge:        13,\n\t\tCats:       []string{\"one\", \"two\", \"three\"},\n\t\tPi:         3.145,\n\t\tPerfection: []int{11, 2, 3, 4},\n\t\tDOB:        time.Now(),\n\t\tIpaddress:  net.ParseIP(\"192.168.59.254\"),\n\t}\n\n\tvar (\n\t\tfirstBuffer  bytes.Buffer\n\t\tsecondBuffer bytes.Buffer\n\t\toutputs      Config\n\t)\n\terr := NewEncoder(&firstBuffer).Encode(inputs)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\t_, err = Decode(firstBuffer.String(), &outputs)\n\tif err != nil {\n\t\tt.Logf(\"Could not decode:\\n%s\\n\", firstBuffer.String())\n\t\tt.Fatal(err)\n\t}\n\terr = NewEncoder(&secondBuffer).Encode(outputs)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif firstBuffer.String() != secondBuffer.String() {\n\t\tt.Errorf(\"%s\\n\\nIS NOT IDENTICAL TO\\n\\n%s\", firstBuffer.String(), secondBuffer.String())\n\t}\n\tout, err := Marshal(inputs)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif firstBuffer.String() != string(out) {\n\t\tt.Errorf(\"%s\\n\\nIS NOT IDENTICAL TO\\n\\n%s\", firstBuffer.String(), string(out))\n\t}\n}\n\nfunc TestEncodeArrayHashWithNormalHashOrder(t *testing.T) {\n\ttype Alpha struct {\n\t\tV int\n\t}\n\ttype Beta struct {\n\t\tV int\n\t}\n\ttype Conf struct {\n\t\tV int\n\t\tA Alpha\n\t\tB []Beta\n\t}\n\n\tval := Conf{\n\t\tV: 1,\n\t\tA: Alpha{2},\n\t\tB: []Beta{{3}},\n\t}\n\texpected := \"V = 1\\n\\n[A]\\n  V = 2\\n\\n[[B]]\\n  V = 3\\n\"\n\tencodeExpected(t, \"array hash with normal hash order\", val, expected, nil)\n}\n\nfunc TestEncodeOmitEmptyStruct(t *testing.T) {\n\ttype (\n\t\tT     struct{ Int int }\n\t\tTpriv struct {\n\t\t\tInt     int\n\t\t\tprivate int\n\t\t}\n\t\tTtime struct {\n\t\t\tTime time.Time\n\t\t}\n\t)\n\n\ttests := []struct {\n\t\tin   any\n\t\twant string\n\t}{\n\t\t{struct {\n\t\t\tF T `toml:\"f,omitempty\"`\n\t\t}{}, \"\"},\n\t\t{struct {\n\t\t\tF T `toml:\"f,omitempty\"`\n\t\t}{T{1}}, \"[f]\\n  Int = 1\"},\n\n\t\t{struct {\n\t\t\tF Tpriv `toml:\"f,omitempty\"`\n\t\t}{}, \"\"},\n\t\t{struct {\n\t\t\tF Tpriv `toml:\"f,omitempty\"`\n\t\t}{Tpriv{1, 0}}, \"[f]\\n  Int = 1\"},\n\n\t\t// Private field being set also counts as \"not empty\".\n\t\t{struct {\n\t\t\tF Tpriv `toml:\"f,omitempty\"`\n\t\t}{Tpriv{0, 1}}, \"[f]\\n  Int = 0\"},\n\n\t\t// time.Time is common use case, so test that explicitly.\n\t\t{struct {\n\t\t\tF Ttime `toml:\"t,omitempty\"`\n\t\t}{}, \"\"},\n\t\t{struct {\n\t\t\tF Ttime `toml:\"t,omitempty\"`\n\t\t}{Ttime{time.Time{}.Add(1)}}, \"[t]\\n  Time = 0001-01-01T00:00:00.000000001Z\"},\n\n\t\t// TODO: also test with MarshalText, MarshalTOML returning non-zero\n\t\t// value.\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(\"\", func(t *testing.T) {\n\t\t\tbuf := new(bytes.Buffer)\n\n\t\t\terr := NewEncoder(buf).Encode(tt.in)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\thave := strings.TrimSpace(buf.String())\n\t\t\tif have != tt.want {\n\t\t\t\tt.Errorf(\"\\nhave:\\n%s\\nwant:\\n%s\", have, tt.want)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestEncodeOmitEmpty(t *testing.T) {\n\ttype compareable struct {\n\t\tBool bool `toml:\"bool,omitempty\"`\n\t}\n\ttype uncomparable struct {\n\t\tField []string `toml:\"field,omitempty\"`\n\t}\n\ttype nestedUncomparable struct {\n\t\tField uncomparable `toml:\"uncomparable,omitempty\"`\n\t\tBool  bool         `toml:\"bool,omitempty\"`\n\t}\n\ttype simple struct {\n\t\tBool                bool               `toml:\"bool,omitempty\"`\n\t\tString              string             `toml:\"string,omitempty\"`\n\t\tArray               [0]byte            `toml:\"array,omitempty\"`\n\t\tSlice               []int              `toml:\"slice,omitempty\"`\n\t\tMap                 map[string]string  `toml:\"map,omitempty\"`\n\t\tTime                time.Time          `toml:\"time,omitempty\"`\n\t\tCompareable1        compareable        `toml:\"compareable1,omitempty\"`\n\t\tCompareable2        compareable        `toml:\"compareable2,omitempty\"`\n\t\tUncomparable1       uncomparable       `toml:\"uncomparable1,omitempty\"`\n\t\tUncomparable2       uncomparable       `toml:\"uncomparable2,omitempty\"`\n\t\tNestedUncomparable1 nestedUncomparable `toml:\"nesteduncomparable1,omitempty\"`\n\t\tNestedUncomparable2 nestedUncomparable `toml:\"nesteduncomparable2,omitempty\"`\n\t}\n\n\tvar v simple\n\tencodeExpected(t, \"fields with omitempty are omitted when empty\", v, \"\", nil)\n\tv = simple{\n\t\tBool:                true,\n\t\tString:              \" \",\n\t\tSlice:               []int{2, 3, 4},\n\t\tMap:                 map[string]string{\"foo\": \"bar\"},\n\t\tTime:                time.Date(1985, 6, 18, 15, 16, 17, 0, time.UTC),\n\t\tCompareable2:        compareable{true},\n\t\tUncomparable2:       uncomparable{[]string{\"XXX\"}},\n\t\tNestedUncomparable1: nestedUncomparable{uncomparable{[]string{\"XXX\"}}, false},\n\t\tNestedUncomparable2: nestedUncomparable{uncomparable{}, true},\n\t}\n\texpected := `bool = true\nstring = \" \"\nslice = [2, 3, 4]\ntime = 1985-06-18T15:16:17Z\n\n[map]\n  foo = \"bar\"\n\n[compareable2]\n  bool = true\n\n[uncomparable2]\n  field = [\"XXX\"]\n\n[nesteduncomparable1]\n  [nesteduncomparable1.uncomparable]\n    field = [\"XXX\"]\n\n[nesteduncomparable2]\n  bool = true\n`\n\tencodeExpected(t, \"fields with omitempty are not omitted when non-empty\",\n\t\tv, expected, nil)\n}\n\nfunc TestEncodeOmitEmptyPointer(t *testing.T) {\n\ttype s struct {\n\t\tString *string `toml:\"string,omitempty\"`\n\t}\n\n\tt.Run(\"nil pointers\", func(t *testing.T) {\n\t\tvar v struct {\n\t\t\tString *string            `toml:\"string,omitempty\"`\n\t\t\tSlice  *[]string          `toml:\"slice,omitempty\"`\n\t\t\tMap    *map[string]string `toml:\"map,omitempty\"`\n\t\t\tStruct *s                 `toml:\"struct,omitempty\"`\n\t\t}\n\t\tencodeExpected(t, \"\", v, ``, nil)\n\t})\n\n\tt.Run(\"zero values\", func(t *testing.T) {\n\t\tstr := \"\"\n\t\tsl := []string{}\n\t\tm := map[string]string{}\n\n\t\tv := struct {\n\t\t\tString *string            `toml:\"string,omitempty\"`\n\t\t\tSlice  *[]string          `toml:\"slice,omitempty\"`\n\t\t\tMap    *map[string]string `toml:\"map,omitempty\"`\n\t\t\tStruct *s                 `toml:\"struct,omitempty\"`\n\t\t}{&str, &sl, &m, &s{&str}}\n\t\twant := `string = \"\"\nslice = []\n\n[map]\n\n[struct]\n  string = \"\"\n`\n\t\tencodeExpected(t, \"\", v, want, nil)\n\t})\n\n\tt.Run(\"with values\", func(t *testing.T) {\n\t\tstr := \"XXX\"\n\t\tsl := []string{\"XXX\"}\n\t\tm := map[string]string{\"XXX\": \"XXX\"}\n\n\t\tv := struct {\n\t\t\tString *string            `toml:\"string,omitempty\"`\n\t\t\tSlice  *[]string          `toml:\"slice,omitempty\"`\n\t\t\tMap    *map[string]string `toml:\"map,omitempty\"`\n\t\t\tStruct *s                 `toml:\"struct,omitempty\"`\n\t\t}{&str, &sl, &m, &s{&str}}\n\t\twant := `string = \"XXX\"\nslice = [\"XXX\"]\n\n[map]\n  XXX = \"XXX\"\n\n[struct]\n  string = \"XXX\"\n`\n\t\tencodeExpected(t, \"\", v, want, nil)\n\t})\n}\n\nfunc TestEncodeOmitZero(t *testing.T) {\n\ttype simple struct {\n\t\tNumber   int     `toml:\"number,omitzero\"`\n\t\tReal     float64 `toml:\"real,omitzero\"`\n\t\tUnsigned uint    `toml:\"unsigned,omitzero\"`\n\t}\n\n\tvalue := simple{0, 0.0, uint(0)}\n\texpected := \"\"\n\n\tencodeExpected(t, \"simple with omitzero, all zero\", value, expected, nil)\n\n\tvalue.Number = 10\n\tvalue.Real = 20\n\tvalue.Unsigned = 5\n\texpected = `number = 10\nreal = 20.0\nunsigned = 5\n`\n\tencodeExpected(t, \"simple with omitzero, non-zero\", value, expected, nil)\n}\n\nfunc TestEncodeOmitemptyEmptyName(t *testing.T) {\n\ttype simple struct {\n\t\tS []int `toml:\",omitempty\"`\n\t}\n\tv := simple{[]int{1, 2, 3}}\n\texpected := \"S = [1, 2, 3]\\n\"\n\tencodeExpected(t, \"simple with omitempty, no name, non-empty field\",\n\t\tv, expected, nil)\n}\n\nfunc TestEncodeAnonymousStruct(t *testing.T) {\n\ttype Inner struct{ N int }\n\ttype inner struct{ B int }\n\ttype Embedded struct {\n\t\tInner1 Inner\n\t\tInner2 Inner\n\t}\n\ttype Outer0 struct {\n\t\tInner\n\t\tinner\n\t}\n\ttype Outer1 struct {\n\t\tInner `toml:\"inner\"`\n\t\tinner `toml:\"innerb\"`\n\t}\n\ttype Outer3 struct {\n\t\tEmbedded\n\t}\n\n\tv0 := Outer0{Inner{3}, inner{4}}\n\texpected := \"N = 3\\nB = 4\\n\"\n\tencodeExpected(t, \"embedded anonymous untagged struct\", v0, expected, nil)\n\n\tv1 := Outer1{Inner{3}, inner{4}}\n\texpected = \"[inner]\\n  N = 3\\n\\n[innerb]\\n  B = 4\\n\"\n\tencodeExpected(t, \"embedded anonymous tagged struct\", v1, expected, nil)\n\n\tv3 := Outer3{Embedded: Embedded{Inner{3}, Inner{4}}}\n\texpected = \"[Inner1]\\n  N = 3\\n\\n[Inner2]\\n  N = 4\\n\"\n\tencodeExpected(t, \"embedded anonymous multiple fields\", v3, expected, nil)\n}\n\nfunc TestEncodeAnonymousStructPointerField(t *testing.T) {\n\ttype Inner struct{ N int }\n\ttype Outer0 struct{ *Inner }\n\ttype Outer1 struct {\n\t\t*Inner `toml:\"inner\"`\n\t}\n\n\tv0 := Outer0{}\n\texpected := \"\"\n\tencodeExpected(t, \"nil anonymous untagged struct pointer field\", v0, expected, nil)\n\n\tv0 = Outer0{&Inner{3}}\n\texpected = \"N = 3\\n\"\n\tencodeExpected(t, \"non-nil anonymous untagged struct pointer field\", v0, expected, nil)\n\n\tv1 := Outer1{}\n\texpected = \"\"\n\tencodeExpected(t, \"nil anonymous tagged struct pointer field\", v1, expected, nil)\n\n\tv1 = Outer1{&Inner{3}}\n\texpected = \"[inner]\\n  N = 3\\n\"\n\tencodeExpected(t, \"non-nil anonymous tagged struct pointer field\", v1, expected, nil)\n}\n\nfunc TestEncodeNestedAnonymousStructs(t *testing.T) {\n\ttype A struct{ A string }\n\ttype B struct{ B string }\n\ttype C struct{ C string }\n\ttype BC struct {\n\t\tB\n\t\tC\n\t}\n\ttype Outer struct {\n\t\tA\n\t\tBC\n\t}\n\n\tv := &Outer{\n\t\tA: A{\n\t\t\tA: \"a\",\n\t\t},\n\t\tBC: BC{\n\t\t\tB: B{\n\t\t\t\tB: \"b\",\n\t\t\t},\n\t\t\tC: C{\n\t\t\t\tC: \"c\",\n\t\t\t},\n\t\t},\n\t}\n\n\texpected := \"A = \\\"a\\\"\\nB = \\\"b\\\"\\nC = \\\"c\\\"\\n\"\n\tencodeExpected(t, \"nested anonymous untagged structs\", v, expected, nil)\n}\n\ntype InnerForNextTest struct{ N int }\n\nfunc (InnerForNextTest) F() {}\nfunc (InnerForNextTest) G() {}\n\nfunc TestEncodeAnonymousNoStructField(t *testing.T) {\n\ttype Inner interface{ F() }\n\ttype inner interface{ G() }\n\ttype IntS []int\n\ttype intS []int\n\ttype Outer0 struct {\n\t\tInner\n\t\tinner\n\t\tIntS\n\t\tintS\n\t}\n\n\tv0 := Outer0{\n\t\tInner: InnerForNextTest{3},\n\t\tinner: InnerForNextTest{4},\n\t\tIntS:  []int{5, 6},\n\t\tintS:  []int{7, 8},\n\t}\n\texpected := \"IntS = [5, 6]\\n\\n[Inner]\\n  N = 3\\n\"\n\tencodeExpected(t, \"non struct anonymous field\", v0, expected, nil)\n}\n\nfunc TestEncodeIgnoredFields(t *testing.T) {\n\ttype simple struct {\n\t\tNumber int `toml:\"-\"`\n\t}\n\tvalue := simple{}\n\texpected := \"\"\n\tencodeExpected(t, \"ignored field\", value, expected, nil)\n}\n\nfunc TestEncodeNaN(t *testing.T) {\n\ts1 := struct {\n\t\tNan float64 `toml:\"nan\"`\n\t\tInf float64 `toml:\"inf\"`\n\t}{math.NaN(), math.Inf(1)}\n\ts2 := struct {\n\t\tNan float32 `toml:\"nan\"`\n\t\tInf float32 `toml:\"inf\"`\n\t}{float32(math.NaN()), float32(math.Inf(-1))}\n\tencodeExpected(t, \"\", s1, \"nan = nan\\ninf = inf\\n\", nil)\n\tencodeExpected(t, \"\", s2, \"nan = nan\\ninf = -inf\\n\", nil)\n}\n\nfunc TestEncodePrimitive(t *testing.T) {\n\ttype MyStruct struct {\n\t\tData  Primitive\n\t\tDataA int\n\t\tDataB string\n\t}\n\n\tdecodeAndEncode := func(toml string) string {\n\t\tvar s MyStruct\n\t\t_, err := Decode(toml, &s)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\tvar buf bytes.Buffer\n\t\terr = NewEncoder(&buf).Encode(s)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t\treturn buf.String()\n\t}\n\n\toriginal := `DataA = 1\nDataB = \"bbb\"\nData = [\"Foo\", \"Bar\"]\n`\n\treEncoded := decodeAndEncode(decodeAndEncode(original))\n\n\tif reEncoded != original {\n\t\tt.Errorf(\n\t\t\t\"re-encoded not the same as original\\noriginal:   %q\\nre-encoded: %q\",\n\t\t\toriginal, reEncoded)\n\t}\n}\n\nfunc TestEncodeError(t *testing.T) {\n\ttests := []struct {\n\t\tin      any\n\t\twantErr string\n\t}{\n\t\t{make(chan int), \"unsupported type for key '': chan\"},\n\t\t{struct{ C complex128 }{0}, \"unsupported type: complex128\"},\n\t\t{[]complex128{0}, \"unsupported type: complex128\"},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(\"\", func(t *testing.T) {\n\t\t\terr := NewEncoder(os.Stderr).Encode(tt.in)\n\t\t\tif err == nil {\n\t\t\t\tt.Fatal(\"err is nil\")\n\t\t\t}\n\t\t\tif !errorContains(err, tt.wantErr) {\n\t\t\t\tt.Errorf(\"wrong error\\nhave: %q\\nwant: %q\", err, tt.wantErr)\n\t\t\t}\n\t\t})\n\t}\n}\n\ntype (\n\tsound struct{ S string }\n\tfood  struct{ F []string }\n\tfun   func()\n\tcplx  complex128\n\tints  []int\n\n\tsound2 struct{ S string }\n\tfood2  struct{ F []string }\n\tfun2   func()\n\tcplx2  complex128\n\tints2  []int\n)\n\n// This is intentionally wrong (pointer receiver)\nfunc (s *sound) MarshalText() ([]byte, error) { return []byte(s.S), nil }\nfunc (f food) MarshalText() ([]byte, error)   { return []byte(strings.Join(f.F, \", \")), nil }\nfunc (f fun) MarshalText() ([]byte, error)    { return []byte(\"why would you do this?\"), nil }\nfunc (c cplx) MarshalText() ([]byte, error) {\n\tcplx := complex128(c)\n\treturn []byte(fmt.Sprintf(\"(%f+%fi)\", real(cplx), imag(cplx))), nil\n}\n\nfunc intsValue(is []int) []byte {\n\tvar buf bytes.Buffer\n\tbuf.WriteByte('<')\n\tfor i, v := range is {\n\t\tif i > 0 {\n\t\t\tbuf.WriteByte(',')\n\t\t}\n\t\tbuf.WriteString(strconv.Itoa(v))\n\t}\n\tbuf.WriteByte('>')\n\treturn buf.Bytes()\n}\n\nfunc (is *ints) MarshalText() ([]byte, error) {\n\tif is == nil {\n\t\treturn []byte(\"[]\"), nil\n\t}\n\treturn intsValue(*is), nil\n}\n\nfunc (s *sound2) MarshalTOML() ([]byte, error) { return []byte(\"\\\"\" + s.S + \"\\\"\"), nil }\nfunc (f food2) MarshalTOML() ([]byte, error) {\n\treturn []byte(\"[\\\"\" + strings.Join(f.F, \"\\\", \\\"\") + \"\\\"]\"), nil\n}\nfunc (f fun2) MarshalTOML() ([]byte, error) { return []byte(\"\\\"why would you do this?\\\"\"), nil }\nfunc (c cplx2) MarshalTOML() ([]byte, error) {\n\tcplx := complex128(c)\n\treturn []byte(fmt.Sprintf(\"\\\"(%f+%fi)\\\"\", real(cplx), imag(cplx))), nil\n}\nfunc (is *ints2) MarshalTOML() ([]byte, error) {\n\t// MarshalTOML must quote by self\n\tif is == nil {\n\t\treturn []byte(`\"[]\"`), nil\n\t}\n\treturn []byte(fmt.Sprintf(`\"%s\"`, intsValue(*is))), nil\n}\n\nfunc TestEncodeTextMarshaler(t *testing.T) {\n\tx := struct {\n\t\tName    string\n\t\tLabels  map[string]string\n\t\tSound   sound\n\t\tSound2  *sound\n\t\tFood    food\n\t\tFood2   *food\n\t\tComplex cplx\n\t\tFun     fun\n\t\tInts    ints\n\t\tInts2   *ints2\n\t}{\n\t\tName:   \"Goblok\",\n\t\tSound:  sound{\"miauw\"},\n\t\tSound2: &sound{\"miauw\"},\n\t\tLabels: map[string]string{\n\t\t\t\"type\":  \"cat\",\n\t\t\t\"color\": \"black\",\n\t\t},\n\t\tFood:    food{[]string{\"chicken\", \"fish\"}},\n\t\tFood2:   &food{[]string{\"chicken\", \"fish\"}},\n\t\tComplex: complex(42, 666),\n\t\tFun:     func() { panic(\"x\") },\n\t\tInts:    ints{1, 2, 3, 4},\n\t\tInts2:   &ints2{1, 2, 3, 4},\n\t}\n\n\tvar buf bytes.Buffer\n\tif err := NewEncoder(&buf).Encode(&x); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\twant := `Name = \"Goblok\"\nSound = \"miauw\"\nSound2 = \"miauw\"\nFood = \"chicken, fish\"\nFood2 = \"chicken, fish\"\nComplex = \"(42.000000+666.000000i)\"\nFun = \"why would you do this?\"\nInts = \"<1,2,3,4>\"\nInts2 = \"<1,2,3,4>\"\n\n[Labels]\n  color = \"black\"\n  type = \"cat\"\n`\n\n\tif buf.String() != want {\n\t\tt.Error(\"\\n\" + buf.String())\n\t}\n}\n\nfunc TestEncodeTOMLMarshaler(t *testing.T) {\n\tx := struct {\n\t\tName    string\n\t\tLabels  map[string]string\n\t\tSound   sound2\n\t\tSound2  *sound2\n\t\tFood    food2\n\t\tFood2   *food2\n\t\tComplex cplx2\n\t\tFun     fun2\n\t}{\n\t\tName:   \"Goblok\",\n\t\tSound:  sound2{\"miauw\"},\n\t\tSound2: &sound2{\"miauw\"},\n\t\tLabels: map[string]string{\n\t\t\t\"type\":  \"cat\",\n\t\t\t\"color\": \"black\",\n\t\t},\n\t\tFood:    food2{[]string{\"chicken\", \"fish\"}},\n\t\tFood2:   &food2{[]string{\"chicken\", \"fish\"}},\n\t\tComplex: complex(42, 666),\n\t\tFun:     func() { panic(\"x\") },\n\t}\n\n\tvar buf bytes.Buffer\n\tif err := NewEncoder(&buf).Encode(x); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\twant := `Name = \"Goblok\"\nSound2 = \"miauw\"\nFood = [\"chicken\", \"fish\"]\nFood2 = [\"chicken\", \"fish\"]\nComplex = \"(42.000000+666.000000i)\"\nFun = \"why would you do this?\"\n\n[Labels]\n  color = \"black\"\n  type = \"cat\"\n\n[Sound]\n  S = \"miauw\"\n`\n\n\tif buf.String() != want {\n\t\tt.Error(\"\\n\" + buf.String())\n\t}\n}\n\ntype (\n\tretNil1 string\n\tretNil2 string\n)\n\nfunc (r retNil1) MarshalText() ([]byte, error) { return nil, nil }\nfunc (r retNil2) MarshalTOML() ([]byte, error) { return nil, nil }\n\nfunc TestEncodeEmpty(t *testing.T) {\n\tt.Run(\"text\", func(t *testing.T) {\n\t\tvar (\n\t\t\ts   struct{ Text retNil1 }\n\t\t\tbuf bytes.Buffer\n\t\t)\n\t\terr := NewEncoder(&buf).Encode(s)\n\t\tif err == nil {\n\t\t\tt.Fatalf(\"no error, but expected an error; output:\\n%s\", buf.String())\n\t\t}\n\t\tif buf.String() != \"\" {\n\t\t\tt.Error(\"\\n\" + buf.String())\n\t\t}\n\t})\n\n\tt.Run(\"toml\", func(t *testing.T) {\n\t\tvar (\n\t\t\ts   struct{ Text retNil2 }\n\t\t\tbuf bytes.Buffer\n\t\t)\n\t\terr := NewEncoder(&buf).Encode(s)\n\t\tif err == nil {\n\t\t\tt.Fatalf(\"no error, but expected an error; output:\\n%s\", buf.String())\n\t\t}\n\t\tif buf.String() != \"\" {\n\t\t\tt.Error(\"\\n\" + buf.String())\n\t\t}\n\t})\n}\n\n// Would previously fail on 32bit architectures; can test with:\n//\n//\tGOARCH=386         go test -c &&  ./toml.test\n//\tGOARCH=arm GOARM=7 go test -c && qemu-arm ./toml.test\nfunc TestEncode32bit(t *testing.T) {\n\ttype Inner struct {\n\t\tA, B, C string\n\t}\n\ttype Outer struct{ Inner }\n\n\tencodeExpected(t, \"embedded anonymous untagged struct\",\n\t\tOuter{Inner{\"a\", \"b\", \"c\"}},\n\t\t\"A = \\\"a\\\"\\nB = \\\"b\\\"\\nC = \\\"c\\\"\\n\",\n\t\tnil)\n}\n\n// Skip invalid types if it has toml:\"-\"\n//\n// https://github.com/BurntSushi/toml/issues/345\nfunc TestEncodeSkipInvalidType(t *testing.T) {\n\tbuf := new(bytes.Buffer)\n\terr := NewEncoder(buf).Encode(struct {\n\t\tStr  string         `toml:\"str\"`\n\t\tArr  []func()       `toml:\"-\"`\n\t\tMap  map[string]any `toml:\"-\"`\n\t\tFunc func()         `toml:\"-\"`\n\t}{\n\t\tStr:  \"a\",\n\t\tArr:  []func(){func() {}},\n\t\tMap:  map[string]any{\"f\": func() {}},\n\t\tFunc: func() {},\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\thave := buf.String()\n\twant := \"str = \\\"a\\\"\\n\"\n\tif have != want {\n\t\tt.Errorf(\"\\nwant: %q\\nhave: %q\\n\", want, have)\n\t}\n}\n\nfunc TestEncodeDuration(t *testing.T) {\n\ttests := []time.Duration{\n\t\t0,\n\t\ttime.Second,\n\t\ttime.Minute,\n\t\ttime.Hour,\n\t\t248*time.Hour + 45*time.Minute + 24*time.Second,\n\t\t12345678 * time.Nanosecond,\n\t\t12345678 * time.Second,\n\t\t4*time.Second + 2*time.Nanosecond,\n\t}\n\n\tfor _, tt := range tests {\n\t\tencodeExpected(t, tt.String(),\n\t\t\tstruct{ Dur time.Duration }{Dur: tt},\n\t\t\tfmt.Sprintf(\"Dur = %q\", tt), nil)\n\t}\n}\n\ntype jsonT struct {\n\tNum  json.Number\n\tNumP *json.Number\n\tArr  []json.Number\n\tArrP []*json.Number\n\tTbl  map[string]json.Number\n\tTblP map[string]*json.Number\n}\n\nvar (\n\tn2, n4, n6 = json.Number(\"2\"), json.Number(\"4\"), json.Number(\"6\")\n\tf2, f4, f6 = json.Number(\"2.2\"), json.Number(\"4.4\"), json.Number(\"6.6\")\n)\n\nfunc TestEncodeJSONNumber(t *testing.T) {\n\ttests := []struct {\n\t\tin   jsonT\n\t\twant string\n\t}{\n\t\t{jsonT{}, \"Num = 0\"},\n\t\t{jsonT{\n\t\t\tNum:  \"1\",\n\t\t\tNumP: &n2,\n\t\t\tArr:  []json.Number{\"3\"},\n\t\t\tArrP: []*json.Number{&n4},\n\t\t\tTbl:  map[string]json.Number{\"k1\": \"5\"},\n\t\t\tTblP: map[string]*json.Number{\"k2\": &n6}}, `\n\t\t\t\tNum = 1\n\t\t\t\tNumP = 2\n\t\t\t\tArr = [3]\n\t\t\t\tArrP = [4]\n\n\t\t\t\t[Tbl]\n\t\t\t\t  k1 = 5\n\n\t\t\t\t[TblP]\n\t\t\t\t  k2 = 6\n\t\t`},\n\t\t{jsonT{\n\t\t\tNum:  \"1.1\",\n\t\t\tNumP: &f2,\n\t\t\tArr:  []json.Number{\"3.3\"},\n\t\t\tArrP: []*json.Number{&f4},\n\t\t\tTbl:  map[string]json.Number{\"k1\": \"5.5\"},\n\t\t\tTblP: map[string]*json.Number{\"k2\": &f6}}, `\n\t\t\t\tNum = 1.1\n\t\t\t\tNumP = 2.2\n\t\t\t\tArr = [3.3]\n\t\t\t\tArrP = [4.4]\n\n\t\t\t\t[Tbl]\n\t\t\t\t  k1 = 5.5\n\n\t\t\t\t[TblP]\n\t\t\t\t  k2 = 6.6\n\t\t`},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(\"\", func(t *testing.T) {\n\t\t\tvar buf bytes.Buffer\n\t\t\terr := NewEncoder(&buf).Encode(tt.in)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\thave := strings.TrimSpace(buf.String())\n\t\t\twant := strings.ReplaceAll(strings.TrimSpace(tt.want), \"\\t\", \"\")\n\t\t\tif have != want {\n\t\t\t\tt.Errorf(\"\\nwant:\\n%s\\nhave:\\n%s\\n\", want, have)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestEncode(t *testing.T) {\n\ttype (\n\t\tEmbedded struct {\n\t\t\tInt int `toml:\"_int\"`\n\t\t}\n\t\tNonStruct int\n\t\tMyInt     int\n\t)\n\n\tdate := time.Date(2014, 5, 11, 19, 30, 40, 0, time.UTC)\n\tdateStr := \"2014-05-11T19:30:40Z\"\n\n\ttests := map[string]struct {\n\t\tinput      any\n\t\twantOutput string\n\t\twantError  error\n\t}{\n\t\t\"bool field\": {\n\t\t\tinput: struct {\n\t\t\t\tBoolTrue  bool\n\t\t\t\tBoolFalse bool\n\t\t\t}{true, false},\n\t\t\twantOutput: \"BoolTrue = true\\nBoolFalse = false\\n\",\n\t\t},\n\t\t\"int fields\": {\n\t\t\tinput: struct {\n\t\t\t\tInt   int\n\t\t\t\tInt8  int8\n\t\t\t\tInt16 int16\n\t\t\t\tInt32 int32\n\t\t\t\tInt64 int64\n\t\t\t}{1, 2, 3, 4, 5},\n\t\t\twantOutput: \"Int = 1\\nInt8 = 2\\nInt16 = 3\\nInt32 = 4\\nInt64 = 5\\n\",\n\t\t},\n\t\t\"uint fields\": {\n\t\t\tinput: struct {\n\t\t\t\tUint   uint\n\t\t\t\tUint8  uint8\n\t\t\t\tUint16 uint16\n\t\t\t\tUint32 uint32\n\t\t\t\tUint64 uint64\n\t\t\t}{1, 2, 3, 4, 5},\n\t\t\twantOutput: \"Uint = 1\\nUint8 = 2\\nUint16 = 3\\nUint32 = 4\" +\n\t\t\t\t\"\\nUint64 = 5\\n\",\n\t\t},\n\t\t\"float fields\": {\n\t\t\tinput: struct {\n\t\t\t\tFloat32 float32\n\t\t\t\tFloat64 float64\n\t\t\t}{1.5, 2.5},\n\t\t\twantOutput: \"Float32 = 1.5\\nFloat64 = 2.5\\n\",\n\t\t},\n\t\t\"string field\": {\n\t\t\tinput:      struct{ String string }{\"foo\"},\n\t\t\twantOutput: \"String = \\\"foo\\\"\\n\",\n\t\t},\n\t\t\"string field with \\\\n escape\": {\n\t\t\tinput:      struct{ String string }{\"foo\\n\"},\n\t\t\twantOutput: \"String = \\\"foo\\\\n\\\"\\n\",\n\t\t},\n\t\t\"string field and unexported field\": {\n\t\t\tinput: struct {\n\t\t\t\tString     string\n\t\t\t\tunexported int\n\t\t\t}{\"foo\", 0},\n\t\t\twantOutput: \"String = \\\"foo\\\"\\n\",\n\t\t},\n\t\t\"datetime field in UTC\": {\n\t\t\tinput:      struct{ Date time.Time }{date},\n\t\t\twantOutput: fmt.Sprintf(\"Date = %s\\n\", dateStr),\n\t\t},\n\t\t\"datetime field as primitive\": {\n\t\t\t// Using a map here to fail if isStructOrMap() returns true for\n\t\t\t// time.Time.\n\t\t\tinput: map[string]any{\n\t\t\t\t\"Date\": date,\n\t\t\t\t\"Int\":  1,\n\t\t\t},\n\t\t\twantOutput: fmt.Sprintf(\"Date = %s\\nInt = 1\\n\", dateStr),\n\t\t},\n\t\t\"array fields\": {\n\t\t\tinput: struct {\n\t\t\t\tIntArray0 [0]int\n\t\t\t\tIntArray3 [3]int\n\t\t\t}{[0]int{}, [3]int{1, 2, 3}},\n\t\t\twantOutput: \"IntArray0 = []\\nIntArray3 = [1, 2, 3]\\n\",\n\t\t},\n\t\t\"slice fields\": {\n\t\t\tinput: struct{ IntSliceNil, IntSlice0, IntSlice3 []int }{\n\t\t\t\tnil, []int{}, []int{1, 2, 3},\n\t\t\t},\n\t\t\twantOutput: \"IntSlice0 = []\\nIntSlice3 = [1, 2, 3]\\n\",\n\t\t},\n\t\t\"datetime slices\": {\n\t\t\tinput: struct{ DatetimeSlice []time.Time }{\n\t\t\t\t[]time.Time{date, date},\n\t\t\t},\n\t\t\twantOutput: fmt.Sprintf(\"DatetimeSlice = [%s, %s]\\n\",\n\t\t\t\tdateStr, dateStr),\n\t\t},\n\t\t\"nested arrays and slices\": {\n\t\t\tinput: struct {\n\t\t\t\tSliceOfArrays         [][2]int\n\t\t\t\tArrayOfSlices         [2][]int\n\t\t\t\tSliceOfArraysOfSlices [][2][]int\n\t\t\t\tArrayOfSlicesOfArrays [2][][2]int\n\t\t\t\tSliceOfMixedArrays    [][2]any\n\t\t\t\tArrayOfMixedSlices    [2][]any\n\t\t\t}{\n\t\t\t\t[][2]int{{1, 2}, {3, 4}},\n\t\t\t\t[2][]int{{1, 2}, {3, 4}},\n\t\t\t\t[][2][]int{\n\t\t\t\t\t{\n\t\t\t\t\t\t{1, 2}, {3, 4},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t{5, 6}, {7, 8},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t[2][][2]int{\n\t\t\t\t\t{\n\t\t\t\t\t\t{1, 2}, {3, 4},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t{5, 6}, {7, 8},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t[][2]any{\n\t\t\t\t\t{1, 2}, {\"a\", \"b\"},\n\t\t\t\t},\n\t\t\t\t[2][]any{\n\t\t\t\t\t{1, 2}, {\"a\", \"b\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\twantOutput: `SliceOfArrays = [[1, 2], [3, 4]]\nArrayOfSlices = [[1, 2], [3, 4]]\nSliceOfArraysOfSlices = [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\nArrayOfSlicesOfArrays = [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\nSliceOfMixedArrays = [[1, 2], [\"a\", \"b\"]]\nArrayOfMixedSlices = [[1, 2], [\"a\", \"b\"]]\n`,\n\t\t},\n\t\t\"empty slice\": {\n\t\t\tinput:      struct{ Empty []any }{[]any{}},\n\t\t\twantOutput: \"Empty = []\\n\",\n\t\t},\n\t\t\"(error) slice with element type mismatch (string and integer)\": {\n\t\t\tinput:      struct{ Mixed []any }{[]any{1, \"a\"}},\n\t\t\twantOutput: \"Mixed = [1, \\\"a\\\"]\\n\",\n\t\t},\n\t\t\"(error) slice with element type mismatch (integer and float)\": {\n\t\t\tinput:      struct{ Mixed []any }{[]any{1, 2.5}},\n\t\t\twantOutput: \"Mixed = [1, 2.5]\\n\",\n\t\t},\n\t\t\"slice with elems of differing Go types, same TOML types\": {\n\t\t\tinput: struct {\n\t\t\t\tMixedInts   []any\n\t\t\t\tMixedFloats []any\n\t\t\t}{\n\t\t\t\t[]any{\n\t\t\t\t\tint(1), int8(2), int16(3), int32(4), int64(5),\n\t\t\t\t\tuint(1), uint8(2), uint16(3), uint32(4), uint64(5),\n\t\t\t\t},\n\t\t\t\t[]any{float32(1.5), float64(2.5)},\n\t\t\t},\n\t\t\twantOutput: \"MixedInts = [1, 2, 3, 4, 5, 1, 2, 3, 4, 5]\\n\" +\n\t\t\t\t\"MixedFloats = [1.5, 2.5]\\n\",\n\t\t},\n\t\t\"(error) slice w/ element type mismatch (one is nested array)\": {\n\t\t\tinput: struct{ Mixed []any }{\n\t\t\t\t[]any{1, []any{2}},\n\t\t\t},\n\t\t\twantOutput: \"Mixed = [1, [2]]\\n\",\n\t\t},\n\t\t\"(error) slice with 1 nil element\": {\n\t\t\tinput:     struct{ NilElement1 []any }{[]any{nil}},\n\t\t\twantError: errArrayNilElement,\n\t\t},\n\t\t\"(error) slice with 1 nil element (and other non-nil elements)\": {\n\t\t\tinput: struct{ NilElement []any }{\n\t\t\t\t[]any{1, nil},\n\t\t\t},\n\t\t\twantError: errArrayNilElement,\n\t\t},\n\t\t\"simple map\": {\n\t\t\tinput:      map[string]int{\"a\": 1, \"b\": 2},\n\t\t\twantOutput: \"a = 1\\nb = 2\\n\",\n\t\t},\n\t\t\"map with any value type\": {\n\t\t\tinput:      map[string]any{\"a\": 1, \"b\": \"c\"},\n\t\t\twantOutput: \"a = 1\\nb = \\\"c\\\"\\n\",\n\t\t},\n\t\t\"map with any value type, some of which are structs\": {\n\t\t\tinput: map[string]any{\n\t\t\t\t\"a\": struct{ Int int }{2},\n\t\t\t\t\"b\": 1,\n\t\t\t},\n\t\t\twantOutput: \"b = 1\\n\\n[a]\\n  Int = 2\\n\",\n\t\t},\n\t\t\"nested map\": {\n\t\t\tinput: map[string]map[string]int{\n\t\t\t\t\"a\": {\"b\": 1},\n\t\t\t\t\"c\": {\"d\": 2},\n\t\t\t},\n\t\t\twantOutput: \"[a]\\n  b = 1\\n\\n[c]\\n  d = 2\\n\",\n\t\t},\n\t\t\"nested struct\": {\n\t\t\tinput: struct{ Struct struct{ Int int } }{\n\t\t\t\tstruct{ Int int }{1},\n\t\t\t},\n\t\t\twantOutput: \"[Struct]\\n  Int = 1\\n\",\n\t\t},\n\t\t\"nested struct and non-struct field\": {\n\t\t\tinput: struct {\n\t\t\t\tStruct struct{ Int int }\n\t\t\t\tBool   bool\n\t\t\t}{struct{ Int int }{1}, true},\n\t\t\twantOutput: \"Bool = true\\n\\n[Struct]\\n  Int = 1\\n\",\n\t\t},\n\t\t\"2 nested structs\": {\n\t\t\tinput: struct{ Struct1, Struct2 struct{ Int int } }{\n\t\t\t\tstruct{ Int int }{1}, struct{ Int int }{2},\n\t\t\t},\n\t\t\twantOutput: \"[Struct1]\\n  Int = 1\\n\\n[Struct2]\\n  Int = 2\\n\",\n\t\t},\n\t\t\"deeply nested structs\": {\n\t\t\tinput: struct {\n\t\t\t\tStruct1, Struct2 struct{ Struct3 *struct{ Int int } }\n\t\t\t}{\n\t\t\t\tstruct{ Struct3 *struct{ Int int } }{&struct{ Int int }{1}},\n\t\t\t\tstruct{ Struct3 *struct{ Int int } }{nil},\n\t\t\t},\n\t\t\twantOutput: \"[Struct1]\\n  [Struct1.Struct3]\\n    Int = 1\" +\n\t\t\t\t\"\\n\\n[Struct2]\\n\",\n\t\t},\n\t\t\"nested struct with nil struct elem\": {\n\t\t\tinput: struct {\n\t\t\t\tStruct struct{ Inner *struct{ Int int } }\n\t\t\t}{\n\t\t\t\tstruct{ Inner *struct{ Int int } }{nil},\n\t\t\t},\n\t\t\twantOutput: \"[Struct]\\n\",\n\t\t},\n\t\t\"nested struct with no fields\": {\n\t\t\tinput: struct {\n\t\t\t\tStruct struct{ Inner struct{} }\n\t\t\t}{\n\t\t\t\tstruct{ Inner struct{} }{struct{}{}},\n\t\t\t},\n\t\t\twantOutput: \"[Struct]\\n  [Struct.Inner]\\n\",\n\t\t},\n\t\t\"struct with tags\": {\n\t\t\tinput: struct {\n\t\t\t\tStruct struct {\n\t\t\t\t\tInt int `toml:\"_int\"`\n\t\t\t\t} `toml:\"_struct\"`\n\t\t\t\tBool bool `toml:\"_bool\"`\n\t\t\t}{\n\t\t\t\tstruct {\n\t\t\t\t\tInt int `toml:\"_int\"`\n\t\t\t\t}{1}, true,\n\t\t\t},\n\t\t\twantOutput: \"_bool = true\\n\\n[_struct]\\n  _int = 1\\n\",\n\t\t},\n\t\t\"embedded struct\": {\n\t\t\tinput:      struct{ Embedded }{Embedded{1}},\n\t\t\twantOutput: \"_int = 1\\n\",\n\t\t},\n\t\t\"embedded *struct\": {\n\t\t\tinput:      struct{ *Embedded }{&Embedded{1}},\n\t\t\twantOutput: \"_int = 1\\n\",\n\t\t},\n\t\t\"nested embedded struct\": {\n\t\t\tinput: struct {\n\t\t\t\tStruct struct{ Embedded } `toml:\"_struct\"`\n\t\t\t}{struct{ Embedded }{Embedded{1}}},\n\t\t\twantOutput: \"[_struct]\\n  _int = 1\\n\",\n\t\t},\n\t\t\"nested embedded *struct\": {\n\t\t\tinput: struct {\n\t\t\t\tStruct struct{ *Embedded } `toml:\"_struct\"`\n\t\t\t}{struct{ *Embedded }{&Embedded{1}}},\n\t\t\twantOutput: \"[_struct]\\n  _int = 1\\n\",\n\t\t},\n\t\t\"embedded non-struct\": {\n\t\t\tinput:      struct{ NonStruct }{5},\n\t\t\twantOutput: \"NonStruct = 5\\n\",\n\t\t},\n\t\t\"array of tables\": {\n\t\t\tinput: struct {\n\t\t\t\tStructs []*struct{ Int int } `toml:\"struct\"`\n\t\t\t}{\n\t\t\t\t[]*struct{ Int int }{{1}, {3}},\n\t\t\t},\n\t\t\twantOutput: \"[[struct]]\\n  Int = 1\\n\\n[[struct]]\\n  Int = 3\\n\",\n\t\t},\n\t\t\"array of tables order\": {\n\t\t\tinput: map[string]any{\n\t\t\t\t\"map\": map[string]any{\n\t\t\t\t\t\"zero\": 5,\n\t\t\t\t\t\"arr\": []map[string]int{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"friend\": 5,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\twantOutput: \"[map]\\n  zero = 5\\n\\n  [[map.arr]]\\n    friend = 5\\n\",\n\t\t},\n\t\t\"empty key name\": {\n\t\t\tinput:      map[string]int{\"\": 1},\n\t\t\twantOutput: `\"\" = 1` + \"\\n\",\n\t\t},\n\t\t\"key with \\\\n escape\": {\n\t\t\tinput:      map[string]string{\"\\n\": \"\\n\"},\n\t\t\twantOutput: `\"\\n\" = \"\\n\"` + \"\\n\",\n\t\t},\n\n\t\t\"empty map name\": {\n\t\t\tinput: map[string]any{\n\t\t\t\t\"\": map[string]int{\"v\": 1},\n\t\t\t},\n\t\t\twantOutput: \"[\\\"\\\"]\\n  v = 1\\n\",\n\t\t},\n\t\t\"(error) top-level slice\": {\n\t\t\tinput:     []struct{ Int int }{{1}, {2}, {3}},\n\t\t\twantError: errNoKey,\n\t\t},\n\t\t\"(error) map no string key\": {\n\t\t\tinput:     map[int]string{1: \"\"},\n\t\t\twantError: errNonString,\n\t\t},\n\t\t\"(error) map no string key indirect\": {\n\t\t\tinput:     map[MyInt]string{1: \"\"},\n\t\t\twantError: errNonString,\n\t\t},\n\n\t\t\"tbl-in-arr-struct\": {\n\t\t\tinput: struct {\n\t\t\t\tArr [][]struct{ A, B, C int }\n\t\t\t}{[][]struct{ A, B, C int }{{{1, 2, 3}, {4, 5, 6}}}},\n\t\t\twantOutput: \"Arr = [[{A = 1, B = 2, C = 3}, {A = 4, B = 5, C = 6}]]\",\n\t\t},\n\n\t\t\"tbl-in-arr-map\": {\n\t\t\tinput: map[string]any{\n\t\t\t\t\"arr\": []any{[]any{\n\t\t\t\t\tmap[string]any{\n\t\t\t\t\t\t\"a\": []any{\"hello\", \"world\"},\n\t\t\t\t\t\t\"b\": []any{1.12, 4.1},\n\t\t\t\t\t\t\"c\": 1,\n\t\t\t\t\t\t\"d\": map[string]any{\"e\": \"E\"},\n\t\t\t\t\t\t\"f\": struct{ A, B int }{1, 2},\n\t\t\t\t\t\t\"g\": []struct{ A, B int }{{3, 4}, {5, 6}},\n\t\t\t\t\t},\n\t\t\t\t}},\n\t\t\t},\n\t\t\twantOutput: `arr = [[{a = [\"hello\", \"world\"], b = [1.12, 4.1], c = 1, d = {e = \"E\"}, f = {A = 1, B = 2}, g = [{A = 3, B = 4}, {A = 5, B = 6}]}]]`,\n\t\t},\n\n\t\t\"slice of slice\": {\n\t\t\tinput: struct {\n\t\t\t\tSlices [][]struct{ Int int }\n\t\t\t}{\n\t\t\t\t[][]struct{ Int int }{{{1}}, {{2}}, {{3}}},\n\t\t\t},\n\t\t\twantOutput: \"Slices = [[{Int = 1}], [{Int = 2}], [{Int = 3}]]\",\n\t\t},\n\t}\n\tfor label, test := range tests {\n\t\tencodeExpected(t, label, test.input, test.wantOutput, test.wantError)\n\t}\n}\n\nfunc TestEncodeDoubleTags(t *testing.T) {\n\t// This writes two \"a\" keys to the TOML doc, which isn't valid. I don't\n\t// think it's worth spending effort preventing this: best we can do is issue\n\t// an error, and should be clear what the problem is anyway. Not even worth\n\t// documenting really.\n\t//\n\t// The json package silently skips these fields, which is worse behaviour\n\t// IMO.\n\ts := struct {\n\t\tA int `toml:\"a\"`\n\t\tB int `toml:\"a\"`\n\t\tC int `toml:\"c\"`\n\t}{1, 2, 3}\n\tbuf := new(strings.Builder)\n\terr := NewEncoder(buf).Encode(s)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\twant := `a = 1\na = 2\nc = 3\n`\n\tif want != buf.String() {\n\t\tt.Errorf(\"\\nhave: %s\\nwant: %s\\n\", buf.String(), want)\n\t}\n}\n\ntype (\n\tDoc1 struct{ N string }\n\tDoc2 struct{ N string }\n)\n\nfunc (d Doc1) MarshalTOML() ([]byte, error) { return []byte(`marshal_toml = \"` + d.N + `\"`), nil }\nfunc (d Doc2) MarshalText() ([]byte, error) { return []byte(`marshal_text = \"` + d.N + `\"`), nil }\n\n// MarshalTOML and MarshalText on the top level type, rather than a field.\nfunc TestMarshalDoc(t *testing.T) {\n\tt.Run(\"toml\", func(t *testing.T) {\n\t\tvar buf bytes.Buffer\n\t\terr := NewEncoder(&buf).Encode(Doc1{\"asd\"})\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\twant := `marshal_toml = \"asd\"`\n\t\tif want != buf.String() {\n\t\t\tt.Errorf(\"\\nhave: %s\\nwant: %s\\n\", buf.String(), want)\n\t\t}\n\t})\n\n\tt.Run(\"text\", func(t *testing.T) {\n\t\tvar buf bytes.Buffer\n\t\terr := NewEncoder(&buf).Encode(Doc2{\"asd\"})\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\twant := `\"marshal_text = \\\"asd\\\"\"`\n\t\tif want != buf.String() {\n\t\t\tt.Errorf(\"\\nhave: %s\\nwant: %s\\n\", buf.String(), want)\n\t\t}\n\t})\n}\n\nfunc encodeExpected(t *testing.T, label string, val any, want string, wantErr error) {\n\tt.Helper()\n\tt.Run(label, func(t *testing.T) {\n\t\tt.Helper()\n\t\tvar buf bytes.Buffer\n\t\terr := NewEncoder(&buf).Encode(val)\n\t\tif err != wantErr {\n\t\t\tif wantErr != nil {\n\t\t\t\tif wantErr == errAnything && err != nil {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tt.Errorf(\"wrong error:\\nwant: %v\\nhave: %v\", wantErr, err)\n\t\t\t} else {\n\t\t\t\tt.Errorf(\"Encode failed: %s\", err)\n\t\t\t}\n\t\t}\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\n\t\thave := strings.TrimSpace(buf.String())\n\t\twant = strings.TrimSpace(want)\n\t\tif want != have {\n\t\t\tt.Errorf(\"\\nhave:\\n%s\\nwant:\\n%s\\n\",\n\t\t\t\t\"\\t\"+strings.ReplaceAll(have, \"\\n\", \"\\n\\t\"),\n\t\t\t\t\"\\t\"+strings.ReplaceAll(want, \"\\n\", \"\\n\\t\"))\n\t\t}\n\t})\n}\n\nfunc TestMapCustomKeytype(t *testing.T) {\n\ttype (\n\t\tMyString string\n\t\tMyMap    map[MyString]any\n\t)\n\n\tm := MyMap{\n\t\t\"k1\":     \"a\",\n\t\t\"nested\": MyMap{\"k2\": \"b\"},\n\t}\n\thave := new(bytes.Buffer)\n\terr := NewEncoder(have).Encode(m)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\twant := `\nk1 = \"a\"\n\n[nested]\n  k2 = \"b\"\n`[1:]\n\n\tif have.String() != want {\n\t\tt.Fatalf(\"\\nhave: %q\\nwant: %q\", have, want)\n\t}\n\n\tvar m2 MyMap\n\t_, err = Decode(have.String(), &m2)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif h, w := fmt.Sprintf(\"%s\", m2), fmt.Sprintf(\"%s\", m); h != w {\n\t\tt.Fatalf(\"\\nhave: %s\\nwant: %s\", h, w)\n\t}\n}\n"
        },
        {
          "name": "error.go",
          "type": "blob",
          "size": 10.037109375,
          "content": "package toml\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n)\n\n// ParseError is returned when there is an error parsing the TOML syntax such as\n// invalid syntax, duplicate keys, etc.\n//\n// In addition to the error message itself, you can also print detailed location\n// information with context by using [ErrorWithPosition]:\n//\n//\ttoml: error: Key 'fruit' was already created and cannot be used as an array.\n//\n//\tAt line 4, column 2-7:\n//\n//\t      2 | fruit = []\n//\t      3 |\n//\t      4 | [[fruit]] # Not allowed\n//\t            ^^^^^\n//\n// [ErrorWithUsage] can be used to print the above with some more detailed usage\n// guidance:\n//\n//\ttoml: error: newlines not allowed within inline tables\n//\n//\tAt line 1, column 18:\n//\n//\t      1 | x = [{ key = 42 #\n//\t                           ^\n//\n//\tError help:\n//\n//\t  Inline tables must always be on a single line:\n//\n//\t      table = {key = 42, second = 43}\n//\n//\t  It is invalid to split them over multiple lines like so:\n//\n//\t      # INVALID\n//\t      table = {\n//\t          key    = 42,\n//\t          second = 43\n//\t      }\n//\n//\t  Use regular for this:\n//\n//\t      [table]\n//\t      key    = 42\n//\t      second = 43\ntype ParseError struct {\n\tMessage  string   // Short technical message.\n\tUsage    string   // Longer message with usage guidance; may be blank.\n\tPosition Position // Position of the error\n\tLastKey  string   // Last parsed key, may be blank.\n\n\t// Line the error occurred.\n\t//\n\t// Deprecated: use [Position].\n\tLine int\n\n\terr   error\n\tinput string\n}\n\n// Position of an error.\ntype Position struct {\n\tLine  int // Line number, starting at 1.\n\tCol   int // Error column, starting at 1.\n\tStart int // Start of error, as byte offset starting at 0.\n\tLen   int // Lenght of the error in bytes.\n}\n\nfunc (p Position) withCol(tomlFile string) Position {\n\tvar (\n\t\tpos   int\n\t\tlines = strings.Split(tomlFile, \"\\n\")\n\t)\n\tfor i := range lines {\n\t\tll := len(lines[i]) + 1 // +1 for the removed newline\n\t\tif pos+ll >= p.Start {\n\t\t\tp.Col = p.Start - pos + 1\n\t\t\tif p.Col < 1 { // Should never happen, but just in case.\n\t\t\t\tp.Col = 1\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t\tpos += ll\n\t}\n\treturn p\n}\n\nfunc (pe ParseError) Error() string {\n\tif pe.LastKey == \"\" {\n\t\treturn fmt.Sprintf(\"toml: line %d: %s\", pe.Position.Line, pe.Message)\n\t}\n\treturn fmt.Sprintf(\"toml: line %d (last key %q): %s\",\n\t\tpe.Position.Line, pe.LastKey, pe.Message)\n}\n\n// ErrorWithPosition returns the error with detailed location context.\n//\n// See the documentation on [ParseError].\nfunc (pe ParseError) ErrorWithPosition() string {\n\tif pe.input == \"\" { // Should never happen, but just in case.\n\t\treturn pe.Error()\n\t}\n\n\t// TODO: don't show control characters as literals? This may not show up\n\t// well everywhere.\n\n\tvar (\n\t\tlines = strings.Split(pe.input, \"\\n\")\n\t\tb     = new(strings.Builder)\n\t)\n\tif pe.Position.Len == 1 {\n\t\tfmt.Fprintf(b, \"toml: error: %s\\n\\nAt line %d, column %d:\\n\\n\",\n\t\t\tpe.Message, pe.Position.Line, pe.Position.Col)\n\t} else {\n\t\tfmt.Fprintf(b, \"toml: error: %s\\n\\nAt line %d, column %d-%d:\\n\\n\",\n\t\t\tpe.Message, pe.Position.Line, pe.Position.Col, pe.Position.Col+pe.Position.Len-1)\n\t}\n\tif pe.Position.Line > 2 {\n\t\tfmt.Fprintf(b, \"% 7d | %s\\n\", pe.Position.Line-2, expandTab(lines[pe.Position.Line-3]))\n\t}\n\tif pe.Position.Line > 1 {\n\t\tfmt.Fprintf(b, \"% 7d | %s\\n\", pe.Position.Line-1, expandTab(lines[pe.Position.Line-2]))\n\t}\n\n\t/// Expand tabs, so that the ^^^s are at the correct position, but leave\n\t/// \"column 10-13\" intact. Adjusting this to the visual column would be\n\t/// better, but we don't know the tabsize of the user in their editor, which\n\t/// can be 8, 4, 2, or something else. We can't know. So leaving it as the\n\t/// character index is probably the \"most correct\".\n\texpanded := expandTab(lines[pe.Position.Line-1])\n\tdiff := len(expanded) - len(lines[pe.Position.Line-1])\n\n\tfmt.Fprintf(b, \"% 7d | %s\\n\", pe.Position.Line, expanded)\n\tfmt.Fprintf(b, \"% 10s%s%s\\n\", \"\", strings.Repeat(\" \", pe.Position.Col-1+diff), strings.Repeat(\"^\", pe.Position.Len))\n\treturn b.String()\n}\n\n// ErrorWithUsage returns the error with detailed location context and usage\n// guidance.\n//\n// See the documentation on [ParseError].\nfunc (pe ParseError) ErrorWithUsage() string {\n\tm := pe.ErrorWithPosition()\n\tif u, ok := pe.err.(interface{ Usage() string }); ok && u.Usage() != \"\" {\n\t\tlines := strings.Split(strings.TrimSpace(u.Usage()), \"\\n\")\n\t\tfor i := range lines {\n\t\t\tif lines[i] != \"\" {\n\t\t\t\tlines[i] = \"    \" + lines[i]\n\t\t\t}\n\t\t}\n\t\treturn m + \"Error help:\\n\\n\" + strings.Join(lines, \"\\n\") + \"\\n\"\n\t}\n\treturn m\n}\n\nfunc expandTab(s string) string {\n\tvar (\n\t\tb    strings.Builder\n\t\tl    int\n\t\tfill = func(n int) string {\n\t\t\tb := make([]byte, n)\n\t\t\tfor i := range b {\n\t\t\t\tb[i] = ' '\n\t\t\t}\n\t\t\treturn string(b)\n\t\t}\n\t)\n\tb.Grow(len(s))\n\tfor _, r := range s {\n\t\tswitch r {\n\t\tcase '\\t':\n\t\t\ttw := 8 - l%8\n\t\t\tb.WriteString(fill(tw))\n\t\t\tl += tw\n\t\tdefault:\n\t\t\tb.WriteRune(r)\n\t\t\tl += 1\n\t\t}\n\t}\n\treturn b.String()\n}\n\ntype (\n\terrLexControl       struct{ r rune }\n\terrLexEscape        struct{ r rune }\n\terrLexUTF8          struct{ b byte }\n\terrParseDate        struct{ v string }\n\terrLexInlineTableNL struct{}\n\terrLexStringNL      struct{}\n\terrParseRange       struct {\n\t\ti    any    // int or float\n\t\tsize string // \"int64\", \"uint16\", etc.\n\t}\n\terrUnsafeFloat struct {\n\t\ti    interface{} // float32 or float64\n\t\tsize string      // \"float32\" or \"float64\"\n\t}\n\terrParseDuration struct{ d string }\n)\n\nfunc (e errLexControl) Error() string {\n\treturn fmt.Sprintf(\"TOML files cannot contain control characters: '0x%02x'\", e.r)\n}\nfunc (e errLexControl) Usage() string { return \"\" }\n\nfunc (e errLexEscape) Error() string        { return fmt.Sprintf(`invalid escape in string '\\%c'`, e.r) }\nfunc (e errLexEscape) Usage() string        { return usageEscape }\nfunc (e errLexUTF8) Error() string          { return fmt.Sprintf(\"invalid UTF-8 byte: 0x%02x\", e.b) }\nfunc (e errLexUTF8) Usage() string          { return \"\" }\nfunc (e errParseDate) Error() string        { return fmt.Sprintf(\"invalid datetime: %q\", e.v) }\nfunc (e errParseDate) Usage() string        { return usageDate }\nfunc (e errLexInlineTableNL) Error() string { return \"newlines not allowed within inline tables\" }\nfunc (e errLexInlineTableNL) Usage() string { return usageInlineNewline }\nfunc (e errLexStringNL) Error() string      { return \"strings cannot contain newlines\" }\nfunc (e errLexStringNL) Usage() string      { return usageStringNewline }\nfunc (e errParseRange) Error() string       { return fmt.Sprintf(\"%v is out of range for %s\", e.i, e.size) }\nfunc (e errParseRange) Usage() string       { return usageIntOverflow }\nfunc (e errUnsafeFloat) Error() string {\n\treturn fmt.Sprintf(\"%v is out of the safe %s range\", e.i, e.size)\n}\nfunc (e errUnsafeFloat) Usage() string   { return usageUnsafeFloat }\nfunc (e errParseDuration) Error() string { return fmt.Sprintf(\"invalid duration: %q\", e.d) }\nfunc (e errParseDuration) Usage() string { return usageDuration }\n\nconst usageEscape = `\nA '\\' inside a \"-delimited string is interpreted as an escape character.\n\nThe following escape sequences are supported:\n\\b, \\t, \\n, \\f, \\r, \\\", \\\\, \\uXXXX, and \\UXXXXXXXX\n\nTo prevent a '\\' from being recognized as an escape character, use either:\n\n- a ' or '''-delimited string; escape characters aren't processed in them; or\n- write two backslashes to get a single backslash: '\\\\'.\n\nIf you're trying to add a Windows path (e.g. \"C:\\Users\\martin\") then using '/'\ninstead of '\\' will usually also work: \"C:/Users/martin\".\n`\n\nconst usageInlineNewline = `\nInline tables must always be on a single line:\n\n    table = {key = 42, second = 43}\n\nIt is invalid to split them over multiple lines like so:\n\n    # INVALID\n    table = {\n        key    = 42,\n        second = 43\n    }\n\nUse regular for this:\n\n    [table]\n    key    = 42\n    second = 43\n`\n\nconst usageStringNewline = `\nStrings must always be on a single line, and cannot span more than one line:\n\n    # INVALID\n    string = \"Hello,\n    world!\"\n\nInstead use \"\"\" or ''' to split strings over multiple lines:\n\n    string = \"\"\"Hello,\n    world!\"\"\"\n`\n\nconst usageIntOverflow = `\nThis number is too large; this may be an error in the TOML, but it can also be a\nbug in the program that uses too small of an integer.\n\nThe maximum and minimum values are:\n\n    size    lowest          highest\n    \n    int8    -128            127\n    int16   -32,768         32,767\n    int32   -2,147,483,648  2,147,483,647\n    int64   -9.2  10     9.2  10\n    uint8   0               255\n    uint16  0               65,535\n    uint32  0               4,294,967,295\n    uint64  0               1.8  10\n\nint refers to int32 on 32-bit systems and int64 on 64-bit systems.\n`\n\nconst usageUnsafeFloat = `\nThis number is outside of the \"safe\" range for floating point numbers; whole\n(non-fractional) numbers outside the below range can not always be represented\naccurately in a float, leading to some loss of accuracy.\n\nExplicitly mark a number as a fractional unit by adding \".0\", which will incur\nsome loss of accuracy; for example:\n\n\tf = 2_000_000_000.0\n\nAccuracy ranges:\n\n\tfloat32 =            16,777,215\n\tfloat64 = 9,007,199,254,740,991\n`\n\nconst usageDuration = `\nA duration must be as \"number<unit>\", without any spaces. Valid units are:\n\n    ns         nanoseconds (billionth of a second)\n    us, s     microseconds (millionth of a second)\n    ms         milliseconds (thousands of a second)\n    s          seconds\n    m          minutes\n    h          hours\n\nYou can combine multiple units; for example \"5m10s\" for 5 minutes and 10\nseconds.\n`\n\nconst usageDate = `\nA TOML datetime must be in one of the following formats:\n\n    2006-01-02T15:04:05Z07:00   Date and time, with timezone.\n    2006-01-02T15:04:05         Date and time, but without timezone.\n    2006-01-02                  Date without a time or timezone.\n    15:04:05                    Just a time, without any timezone.\n\nSeconds may optionally have a fraction, up to nanosecond precision:\n\n    15:04:05.123\n    15:04:05.856018510\n`\n\n// TOML 1.1:\n// The seconds part in times is optional, and may be omitted:\n//     2006-01-02T15:04Z07:00\n//     2006-01-02T15:04\n//     15:04\n"
        },
        {
          "name": "error_test.go",
          "type": "blob",
          "size": 11.31640625,
          "content": "package toml_test\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"io/fs\"\n\t\"math\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/BurntSushi/toml\"\n\ttomltest \"github.com/BurntSushi/toml/internal/toml-test\"\n)\n\nfunc TestErrorPosition(t *testing.T) {\n\t// Note: take care to use leading spaces (not tabs).\n\ttests := []struct {\n\t\ttest, err string\n\t}{\n\t\t{\"array/missing-separator-2.toml\", `\ntoml: error: expected a comma (',') or array terminator (']'), but got '2'\n\nAt line 1, column 13:\n\n      1 | wrong = [ 1 2 3 ]\n                      ^`},\n\n\t\t{\"array/no-close-1.toml\", `\ntoml: error: expected a comma (',') or array terminator (']'), but got end of file\n\nAt line 1, column 23:\n\n      1 | no-close-1 = [ 1, 2, 3\n                                ^`},\n\n\t\t{\"array/tables-2.toml\", `\ntoml: error: Key 'fruit.variety' has already been defined.\n\nAt line 9, column 4-8:\n\n      7 | \n      8 |   # This table conflicts with the previous table\n      9 |   [fruit.variety]\n             ^^^^^`},\n\t\t{\"local-date/trailing-t.toml\", `\ntoml: error: invalid datetime: \"2006-01-30T\"\n\nAt line 2, column 5-15:\n\n      1 | # Date cannot end with trailing T\n      2 | d = 2006-01-30T\n              ^^^^^^^^^^^`},\n\n\t\t{\"key/without-value-1.toml\", `\ntoml: error: expected '.' or '=', but got '\\n' instead\n\nAt line 1, column 4:\n\n      1 | key\n             ^`},\n\t\t// Position looks wonky, but test has trailing space, so it's correct.\n\t\t{\"key/without-value-2.toml\", `\ntoml: error: expected value but found '\\n' instead\n\nAt line 1, column 7:\n\n      1 | key = \n                ^`},\n\t}\n\tfsys := tomltest.EmbeddedTests()\n\tfor _, tt := range tests {\n\t\tt.Run(tt.test, func(t *testing.T) {\n\t\t\tinput, err := fs.ReadFile(fsys, \"invalid/\"+tt.test)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\tvar x any\n\t\t\t_, err = toml.Decode(string(input), &x)\n\t\t\tif err == nil {\n\t\t\t\tt.Fatal(\"err is nil\")\n\t\t\t}\n\n\t\t\tvar pErr toml.ParseError\n\t\t\tif !errors.As(err, &pErr) {\n\t\t\t\tt.Errorf(\"err is not a ParseError: %T %[1]v\", err)\n\t\t\t}\n\n\t\t\ttt.err = tt.err[1:] + \"\\n\" // Remove first newline, and add trailing.\n\t\t\twant := pErr.ErrorWithUsage()\n\n\t\t\tif !strings.Contains(want, tt.err) {\n\t\t\t\tt.Fatalf(\"\\nwant:\\n%s\\nhave:\\n%s\", tt.err, want)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestParseError(t *testing.T) {\n\ttests := []struct {\n\t\tin        any\n\t\ttoml, err string\n\t}{\n\t\t{\n\t\t\t&struct{ Int int8 }{},\n\t\t\t\"Int = 200\",\n\t\t\t`| toml: error: 200 is out of range for int8\n\t\t\t |\n\t\t\t | At line 1, column 7-9:\n\t\t\t |\n\t\t\t |       1 | Int = 200\n\t\t\t |                 ^^^\n\t\t\t | Error help:\n             |\n\t\t\t |     This number is too large; this may be an error in the TOML, but it can also be a\n\t\t\t |     bug in the program that uses too small of an integer.\n             |\n\t\t\t |     The maximum and minimum values are:\n             |\n\t\t\t |         size    lowest          highest\n\t\t\t |         \n\t\t\t |         int8    -128            127\n\t\t\t |         int16   -32,768         32,767\n\t\t\t |         int32   -2,147,483,648  2,147,483,647\n\t\t\t |         int64   -9.2  10     9.2  10\n\t\t\t |         uint8   0               255\n\t\t\t |         uint16  0               65,535\n\t\t\t |         uint32  0               4,294,967,295\n\t\t\t |         uint64  0               1.8  10\n             |\n\t\t\t |     int refers to int32 on 32-bit systems and int64 on 64-bit systems.\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\t&struct{ Int int }{},\n\t\t\tfmt.Sprintf(\"Int = %d\", uint64(math.MaxInt64+1)),\n\t\t\t`| toml: error: 9223372036854775808 is out of range for int64\n\t\t\t |\n\t\t\t | At line 1, column 7-25:\n\t\t\t |\n\t\t\t |       1 | Int = 9223372036854775808\n\t\t\t |                 ^^^^^^^^^^^^^^^^^^^\n\t\t\t | Error help:\n             |\n\t\t\t |     This number is too large; this may be an error in the TOML, but it can also be a\n\t\t\t |     bug in the program that uses too small of an integer.\n             |\n\t\t\t |     The maximum and minimum values are:\n             |\n\t\t\t |         size    lowest          highest\n\t\t\t |         \n\t\t\t |         int8    -128            127\n\t\t\t |         int16   -32,768         32,767\n\t\t\t |         int32   -2,147,483,648  2,147,483,647\n\t\t\t |         int64   -9.2  10     9.2  10\n\t\t\t |         uint8   0               255\n\t\t\t |         uint16  0               65,535\n\t\t\t |         uint32  0               4,294,967,295\n\t\t\t |         uint64  0               1.8  10\n             |\n\t\t\t |     int refers to int32 on 32-bit systems and int64 on 64-bit systems.\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\t&struct{ Float float32 }{},\n\t\t\t\"Float = 1.1e99\",\n\t\t\t`\n            | toml: error: 1.1e+99 is out of range for float32\n            |\n            | At line 1, column 9-14:\n            |\n            |       1 | Float = 1.1e99\n            |                   ^^^^^^\n            | Error help:\n            |\n            |     This number is too large; this may be an error in the TOML, but it can also be a\n            |     bug in the program that uses too small of an integer.\n            |\n            |     The maximum and minimum values are:\n            |\n            |         size    lowest          highest\n            |         \n            |         int8    -128            127\n            |         int16   -32,768         32,767\n            |         int32   -2,147,483,648  2,147,483,647\n            |         int64   -9.2  10     9.2  10\n            |         uint8   0               255\n            |         uint16  0               65,535\n            |         uint32  0               4,294,967,295\n            |         uint64  0               1.8  10\n            |\n            |     int refers to int32 on 32-bit systems and int64 on 64-bit systems.\n\t\t\t`,\n\t\t},\n\n\t\t{\n\t\t\t&struct{ D time.Duration }{},\n\t\t\t`D = \"99 bottles\"`,\n\t\t\t`\n\t\t\t| toml: error: invalid duration: \"99 bottles\"\n\t\t\t|\n\t\t\t| At line 1, column 6-15:\n\t\t\t|\n\t\t\t|       1 | D = \"99 bottles\"\n\t\t\t|                ^^^^^^^^^^\n\t\t\t| Error help:\n\t\t\t|\n\t\t\t|     A duration must be as \"number<unit>\", without any spaces. Valid units are:\n\t\t\t|\n\t\t\t|         ns         nanoseconds (billionth of a second)\n\t\t\t|         us, s     microseconds (millionth of a second)\n\t\t\t|         ms         milliseconds (thousands of a second)\n\t\t\t|         s          seconds\n\t\t\t|         m          minutes\n\t\t\t|         h          hours\n\t\t\t|\n\t\t\t|     You can combine multiple units; for example \"5m10s\" for 5 minutes and 10\n\t\t\t|     seconds.\n\t\t\t`,\n\t\t},\n\n\t\t{\n\t\t\t&struct{ D time.Time }{},\n\t\t\t`D = 2006-01-99`,\n\t\t\t`\n            | toml: error: invalid datetime: \"2006-01-99\"\n            |\n            | At line 1, column 5-14:\n            |\n            |       1 | D = 2006-01-99\n            |               ^^^^^^^^^^\n            | Error help:\n            |\n            |     A TOML datetime must be in one of the following formats:\n            |\n            |         2006-01-02T15:04:05Z07:00   Date and time, with timezone.\n            |         2006-01-02T15:04:05         Date and time, but without timezone.\n            |         2006-01-02                  Date without a time or timezone.\n            |         15:04:05                    Just a time, without any timezone.\n            |\n            |     Seconds may optionally have a fraction, up to nanosecond precision:\n            |\n            |         15:04:05.123\n            |         15:04:05.856018510\n\t\t\t`,\n\t\t},\n\t}\n\n\tprep := func(s string) string {\n\t\tlines := strings.Split(strings.TrimSpace(s), \"\\n\")\n\t\tfor i := range lines {\n\t\t\tif j := strings.IndexByte(lines[i], '|'); j >= 0 {\n\t\t\t\tlines[i] = lines[i][j+1:]\n\t\t\t\tlines[i] = strings.Replace(lines[i], \" \", \"\", 1)\n\t\t\t}\n\t\t}\n\t\treturn strings.Join(lines, \"\\n\") + \"\\n\"\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(\"\", func(t *testing.T) {\n\t\t\t_, err := toml.Decode(tt.toml, tt.in)\n\t\t\tif err == nil {\n\t\t\t\tt.Fatalf(\"err is nil; decoded: %#v\", tt.in)\n\t\t\t}\n\n\t\t\tvar pErr toml.ParseError\n\t\t\tif !errors.As(err, &pErr) {\n\t\t\t\tt.Fatalf(\"err is not a ParseError: %#v\", err)\n\t\t\t}\n\n\t\t\ttt.err = prep(tt.err)\n\t\t\thave := pErr.ErrorWithUsage()\n\n\t\t\t// have = strings.ReplaceAll(have, \" \", \"\")\n\t\t\t// tt.err = strings.ReplaceAll(tt.err, \" \", \"\")\n\t\t\tif have != tt.err {\n\t\t\t\tt.Fatalf(\"\\nwant:\\n%s\\nhave:\\n%s\", tt.err, have)\n\t\t\t}\n\t\t})\n\t}\n}\n\ntype Enum1 uint8\n\nfunc (n *Enum1) UnmarshalText(text []byte) error {\n\tswitch t := strings.TrimSpace(string(text)); t {\n\tcase \"ok\":\n\t\t*n = 1\n\tdefault:\n\t\treturn fmt.Errorf(\"invalid value: %q\", t)\n\t}\n\treturn nil\n}\n\n// Make sure custom types are wrapped in ParseError with correct location.\nfunc TestUnmarshalTypeError(t *testing.T) {\n\tvar c struct {\n\t\tK1 string `toml:\"k1\"`\n\t\tK2 Enum1  `toml:\"k2\"`\n\t\tK3 Enum1  `toml:\"k3\"`\n\t}\n\t_, err := toml.Decode(\"k1 = 'asd'\\nk2 = 'ok'\\nk3 = 'invalid'\\nk4 = 'ok'\", &c)\n\tif err == nil {\n\t\tt.Fatal(\"error is nil\")\n\t}\n\tvar pErr toml.ParseError\n\tif !errors.As(err, &pErr) {\n\t\tt.Fatalf(\"not a ParseError: %#v\", err)\n\t}\n\n\twant := `toml: error: invalid value: \"invalid\"\n\nAt line 3, column 7-13:\n\n      1 | k1 = 'asd'\n      2 | k2 = 'ok'\n      3 | k3 = 'invalid'\n                ^^^^^^^\n`\n\n\tif have := pErr.ErrorWithUsage(); have != want {\n\t\tt.Errorf(\"\\nwant:\\n%s\\nhave:\\n%s\", want, have)\n\t}\n}\n\ntype Enum2 uint8\n\nfunc (n *Enum2) UnmarshalTOML(text any) error {\n\tswitch t := strings.TrimSpace(text.(string)); t {\n\tcase \"ok\":\n\t\t*n = 1\n\tdefault:\n\t\treturn fmt.Errorf(\"invalid value: %q\", t)\n\t}\n\treturn nil\n}\n\nfunc TestMarhsalError(t *testing.T) {\n\tvar c struct {\n\t\tK1 string `toml:\"k1\"`\n\t\tK2 Enum2  `toml:\"k2\"`\n\t\tK3 Enum2  `toml:\"k3\"`\n\t}\n\t_, err := toml.Decode(\"k1 = 'asd'\\nk2 = 'ok'\\nk3 = 'invalid'\\nk4 = 'ok'\", &c)\n\tif err == nil {\n\t\tt.Fatal(\"error is nil\")\n\t}\n\tvar pErr toml.ParseError\n\tif !errors.As(err, &pErr) {\n\t\tt.Fatalf(\"not a ParseError: %#v\", err)\n\t}\n\n\twant := `toml: error: invalid value: \"invalid\"\n\nAt line 3, column 7-13:\n\n      1 | k1 = 'asd'\n      2 | k2 = 'ok'\n      3 | k3 = 'invalid'\n                ^^^^^^^\n`\n\n\tif have := pErr.ErrorWithUsage(); have != want {\n\t\tt.Errorf(\"\\nwant:\\n%s\\nhave:\\n%s\", want, have)\n\t}\n}\n\nfunc TestErrorIndent(t *testing.T) {\n\tgetErr := func(t *testing.T, tml string) toml.ParseError {\n\t\tvar m map[string]any\n\t\t_, err := toml.Decode(tml, &m)\n\t\tif err == nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t\tvar pErr toml.ParseError\n\t\tif !errors.As(err, &pErr) {\n\t\t\tt.Fatalf(\"not a ParseError: %#v\", err)\n\t\t}\n\t\treturn pErr\n\t}\n\n\terr := getErr(t, \"\\tspaces = xxx\")\n\twant := `toml: error: expected value but found \"xxx\" instead\n\nAt line 1, column 11-13:\n\n      1 |         spaces = xxx\n                           ^^^\n`\n\n\tif have := err.ErrorWithUsage(); have != want {\n\t\tt.Errorf(\"\\nwant:\\n%s\\nhave:\\n%s\", want, have)\n\t}\n\n\terr = getErr(t, \"\\tspaces\\t=\\txxx\")\n\twant = `toml: error: expected value but found \"xxx\" instead\n\nAt line 1, column 11-13:\n\n      1 |         spaces  =       xxx\n                                  ^^^\n`\n\tif have := err.ErrorWithUsage(); have != want {\n\t\tt.Errorf(\"\\nwant:\\n%s\\nhave:\\n%s\", want, have)\n\t}\n\n\terr = getErr(t, \"\\txxx \\t = \\t 1\\n\\tspaces\\t=\\txxx\")\n\twant = `toml: error: expected value but found \"xxx\" instead\n\nAt line 2, column 11-13:\n\n      1 |         xxx      =       1\n      2 |         spaces  =       xxx\n                                  ^^^\n`\n\tif have := err.ErrorWithUsage(); have != want {\n\t\tt.Errorf(\"\\nwant:\\n%s\\nhave:\\n%s\", want, have)\n\t}\n}\n"
        },
        {
          "name": "example_test.go",
          "type": "blob",
          "size": 7.6357421875,
          "content": "package toml_test\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"log\"\n\t\"net/mail\"\n\t\"time\"\n\n\t\"github.com/BurntSushi/toml\"\n)\n\nfunc ExampleEncoder_Encode() {\n\tvar (\n\t\tdate, _ = time.Parse(time.RFC822, \"14 Mar 10 18:00 UTC\")\n\t\tbuf     = new(bytes.Buffer)\n\t)\n\terr := toml.NewEncoder(buf).Encode(map[string]any{\n\t\t\"date\":   date,\n\t\t\"counts\": []int{1, 1, 2, 3, 5, 8},\n\t\t\"hash\": map[string]string{\n\t\t\t\"key1\": \"val1\",\n\t\t\t\"key2\": \"val2\",\n\t\t},\n\t})\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfmt.Println(buf.String())\n\n\t// Output:\n\t// counts = [1, 1, 2, 3, 5, 8]\n\t// date = 2010-03-14T18:00:00Z\n\t//\n\t// [hash]\n\t//   key1 = \"val1\"\n\t//   key2 = \"val2\"\n}\n\nfunc ExampleMetaData_PrimitiveDecode() {\n\ttomlBlob := `\n\t\tranking = [\"Springsteen\", \"J Geils\"]\n\n\t\t[bands.Springsteen]\n\t\tstarted = 1973\n\t\talbums = [\"Greetings\", \"WIESS\", \"Born to Run\", \"Darkness\"]\n\n\t\t[bands.\"J Geils\"]\n\t\tstarted = 1970\n\t\talbums = [\"The J. Geils Band\", \"Full House\", \"Blow Your Face Out\"]\n\t\t`\n\n\ttype (\n\t\tband struct {\n\t\t\tStarted int\n\t\t\tAlbums  []string\n\t\t}\n\t\tclassics struct {\n\t\t\tRanking []string\n\t\t\tBands   map[string]toml.Primitive\n\t\t}\n\t)\n\n\t// Do the initial decode; reflection is delayed on Primitive values.\n\tvar music classics\n\tmd, err := toml.Decode(tomlBlob, &music)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// MetaData still includes information on Primitive values.\n\tfmt.Printf(\"Is `bands.Springsteen` defined? %v\\n\",\n\t\tmd.IsDefined(\"bands\", \"Springsteen\"))\n\n\t// Decode primitive data into Go values.\n\tfor _, artist := range music.Ranking {\n\t\t// A band is a primitive value, so we need to decode it to get a real\n\t\t// `band` value.\n\t\tprimValue := music.Bands[artist]\n\n\t\tvar aBand band\n\t\terr = md.PrimitiveDecode(primValue, &aBand)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\tfmt.Printf(\"%s started in %d.\\n\", artist, aBand.Started)\n\t}\n\n\t// Check to see if there were any fields left undecoded. Note that this\n\t// won't be empty before decoding the Primitive value!\n\tfmt.Printf(\"Undecoded: %q\\n\", md.Undecoded())\n\n\t// Output:\n\t// Is `bands.Springsteen` defined? true\n\t// Springsteen started in 1973.\n\t// J Geils started in 1970.\n\t// Undecoded: []\n}\n\nfunc ExampleDecode() {\n\ttomlBlob := `\n\t\t# Some comments.\n\t\t[alpha]\n\t\tip = \"10.0.0.1\"\n\n\t\t\t[alpha.config]\n\t\t\tPorts = [ 8001, 8002 ]\n\t\t\tLocation = \"Toronto\"\n\t\t\tCreated = 1987-07-05T05:45:00Z\n\n\t\t[beta]\n\t\tip = \"10.0.0.2\"\n\n\t\t\t[beta.config]\n\t\t\tPorts = [ 9001, 9002 ]\n\t\t\tLocation = \"New Jersey\"\n\t\t\tCreated = 1887-01-05T05:55:00Z\n\t`\n\n\ttype (\n\t\tserverConfig struct {\n\t\t\tPorts    []int\n\t\t\tLocation string\n\t\t\tCreated  time.Time\n\t\t}\n\t\tserver struct {\n\t\t\tIP     string       `toml:\"ip,omitempty\"`\n\t\t\tConfig serverConfig `toml:\"config\"`\n\t\t}\n\t\tservers map[string]server\n\t)\n\n\tvar config servers\n\t_, err := toml.Decode(tomlBlob, &config)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tfor _, name := range []string{\"alpha\", \"beta\"} {\n\t\ts := config[name]\n\t\tfmt.Printf(\"Server: %s (ip: %s) in %s created on %s\\n\",\n\t\t\tname, s.IP, s.Config.Location,\n\t\t\ts.Config.Created.Format(\"2006-01-02\"))\n\t\tfmt.Printf(\"Ports: %v\\n\", s.Config.Ports)\n\t}\n\n\t// Output:\n\t// Server: alpha (ip: 10.0.0.1) in Toronto created on 1987-07-05\n\t// Ports: [8001 8002]\n\t// Server: beta (ip: 10.0.0.2) in New Jersey created on 1887-01-05\n\t// Ports: [9001 9002]\n}\n\ntype address struct{ *mail.Address }\n\nfunc (a *address) UnmarshalText(text []byte) error {\n\tvar err error\n\ta.Address, err = mail.ParseAddress(string(text))\n\treturn err\n}\n\n// Example Unmarshaler shows how to decode TOML strings into your own\n// custom data type.\nfunc Example_unmarshaler() {\n\tblob := `\n\t\tcontacts = [\n\t\t\t\"Donald Duck <donald@duckburg.com>\",\n\t\t\t\"Scrooge McDuck <scrooge@duckburg.com>\",\n\t\t]\n\t`\n\n\tvar contacts struct {\n\t\t// Implementation of the address type:\n\t\t//\n\t\t//     type address struct{ *mail.Address }\n\t\t//\n\t\t//     func (a *address) UnmarshalText(text []byte) error {\n\t\t//         var err error\n\t\t//         a.Address, err = mail.ParseAddress(string(text))\n\t\t//         return err\n\t\t//     }\n\n\t\tContacts []address\n\t}\n\n\t_, err := toml.Decode(blob, &contacts)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tfor _, c := range contacts.Contacts {\n\t\tfmt.Printf(\"%#v\\n\", c.Address)\n\t}\n\n\t// Output:\n\t// &mail.Address{Name:\"Donald Duck\", Address:\"donald@duckburg.com\"}\n\t// &mail.Address{Name:\"Scrooge McDuck\", Address:\"scrooge@duckburg.com\"}\n}\n\n// Example StrictDecoding shows how to detect if there are keys in the TOML\n// document that weren't decoded into the value given. This is useful for\n// returning an error to the user if they've included extraneous fields in their\n// configuration.\nfunc Example_strictDecoding() {\n\tvar blob = `\n\t\tkey1 = \"value1\"\n\t\tkey2 = \"value2\"\n\t\tkey3 = \"value3\"\n\t`\n\n\tvar conf struct {\n\t\tKey1 string\n\t\tKey3 string\n\t}\n\tmd, err := toml.Decode(blob, &conf)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tfmt.Printf(\"Undecoded keys: %q\\n\", md.Undecoded())\n\t// Output:\n\t// Undecoded keys: [\"key2\"]\n}\n\ntype order struct {\n\t// NOTE `order.parts` is a private slice of type `part` which is an\n\t// interface and may only be loaded from toml using the UnmarshalTOML()\n\t// method of the Umarshaler interface.\n\tparts parts\n}\n\ntype parts []part\n\ntype part interface {\n\tName() string\n}\n\ntype valve struct {\n\tType   string\n\tID     string\n\tSize   float32\n\tRating int\n}\n\nfunc (v *valve) Name() string {\n\treturn fmt.Sprintf(\"VALVE: %s\", v.ID)\n}\n\ntype pipe struct {\n\tType     string\n\tID       string\n\tLength   float32\n\tDiameter int\n}\n\nfunc (p *pipe) Name() string {\n\treturn fmt.Sprintf(\"PIPE: %s\", p.ID)\n}\n\ntype cable struct {\n\tType   string\n\tID     string\n\tLength int\n\tRating float32\n}\n\nfunc (c *cable) Name() string {\n\treturn fmt.Sprintf(\"CABLE: %s\", c.ID)\n}\n\nfunc (o *order) UnmarshalTOML(data any) error {\n\t// NOTE the example below contains detailed type casting to show how the\n\t// 'data' is retrieved. In operational use, a type cast wrapper may be\n\t// preferred e.g.\n\t//\n\t// func AsMap(v any) (map[string]any, error) {\n\t// \t\treturn v.(map[string]any)\n\t// }\n\t//\n\t// resulting in:\n\t// d, _ := AsMap(data)\n\t//\n\n\td, _ := data.(map[string]any)\n\tparts, _ := d[\"parts\"].([]map[string]any)\n\n\tfor _, p := range parts {\n\n\t\ttyp, _ := p[\"type\"].(string)\n\t\tid, _ := p[\"id\"].(string)\n\n\t\t// detect the type of part and handle each case\n\t\tswitch p[\"type\"] {\n\t\tcase \"valve\":\n\n\t\t\tsize := float32(p[\"size\"].(float64))\n\t\t\trating := int(p[\"rating\"].(int64))\n\n\t\t\tvalve := &valve{\n\t\t\t\tType:   typ,\n\t\t\t\tID:     id,\n\t\t\t\tSize:   size,\n\t\t\t\tRating: rating,\n\t\t\t}\n\n\t\t\to.parts = append(o.parts, valve)\n\n\t\tcase \"pipe\":\n\n\t\t\tlength := float32(p[\"length\"].(float64))\n\t\t\tdiameter := int(p[\"diameter\"].(int64))\n\n\t\t\tpipe := &pipe{\n\t\t\t\tType:     typ,\n\t\t\t\tID:       id,\n\t\t\t\tLength:   length,\n\t\t\t\tDiameter: diameter,\n\t\t\t}\n\n\t\t\to.parts = append(o.parts, pipe)\n\n\t\tcase \"cable\":\n\n\t\t\tlength := int(p[\"length\"].(int64))\n\t\t\trating := float32(p[\"rating\"].(float64))\n\n\t\t\tcable := &cable{\n\t\t\t\tType:   typ,\n\t\t\t\tID:     id,\n\t\t\t\tLength: length,\n\t\t\t\tRating: rating,\n\t\t\t}\n\n\t\t\to.parts = append(o.parts, cable)\n\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// Example UnmarshalTOML shows how to implement a struct type that knows how to\n// unmarshal itself. The struct must take full responsibility for mapping the\n// values passed into the struct. The method may be used with interfaces in a\n// struct in cases where the actual type is not known until the data is\n// examined.\nfunc Example_unmarshalTOML() {\n\tblob := `\n\t\t[[parts]]\n\t\ttype = \"valve\"\n\t\tid = \"valve-1\"\n\t\tsize = 1.2\n\t\trating = 4\n\n\t\t[[parts]]\n\t\ttype = \"valve\"\n\t\tid = \"valve-2\"\n\t\tsize = 2.1\n\t\trating = 5\n\n\t\t[[parts]]\n\t\ttype = \"pipe\"\n\t\tid = \"pipe-1\"\n\t\tlength = 2.1\n\t\tdiameter = 12\n\n\t\t[[parts]]\n\t\ttype = \"cable\"\n\t\tid = \"cable-1\"\n\t\tlength = 12\n\t\trating = 3.1\n\t`\n\n\t// See example_test.go in the source for the implementation of the order\n\t// type.\n\to := &order{}\n\n\terr := toml.Unmarshal([]byte(blob), o)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tfmt.Println(len(o.parts))\n\tfor _, part := range o.parts {\n\t\tfmt.Println(part.Name())\n\t}\n}\n"
        },
        {
          "name": "fuzz_test.go",
          "type": "blob",
          "size": 1.8115234375,
          "content": "package toml\n\nimport (\n\t\"bytes\"\n\t\"testing\"\n)\n\nfunc FuzzDecode(f *testing.F) {\n\tbuf := make([]byte, 0, 2048)\n\n\tf.Add(`\n# This is an example TOML document which shows most of its features.\n\n# Simple key/value with a string.\ntitle = \"TOML example \\U0001F60A\"\n\ndesc = \"\"\"\nAn example TOML document. \\\n\"\"\"\n\n# Array with integers and floats in the various allowed formats.\nintegers = [42, 0x42, 0o42, 0b0110]\nfloats   = [1.42, 1e-02]\n\n# Array with supported datetime formats.\ntimes = [\n\t2021-11-09T15:16:17+01:00,  # datetime with timezone.\n\t2021-11-09T15:16:17Z,       # UTC datetime.\n\t2021-11-09T15:16:17,        # local datetime.\n\t2021-11-09,                 # local date.\n\t15:16:17,                   # local time.\n]\n\n# Durations.\nduration = [\"4m49s\", \"8m03s\", \"1231h15m55s\"]\n\n# Table with inline tables.\ndistros = [\n\t{name = \"Arch Linux\", packages = \"pacman\"},\n\t{name = \"Void Linux\", packages = \"xbps\"},\n\t{name = \"Debian\",     packages = \"apt\"},\n]\n\n# Create new table; note the \"servers\" table is created implicitly.\n[servers.alpha]\n\t# You can indent as you please, tabs or spaces.\n\tip        = '10.0.0.1'\n\thostname  = 'server1'\n\tenabled   = false\n[servers.beta]\n\tip        = '10.0.0.2'\n\thostname  = 'server2'\n\tenabled   = true\n\n# Start a new table array; note that the \"characters\" table is created implicitly.\n[[characters.star-trek]]\n\tname = \"James Kirk\"\n\trank = \"Captain\\u0012 \\t\"\n[[characters.star-trek]]\n\tname = \"Spock\"\n\trank = \"Science officer\"\n\n[undecoded] # To show the MetaData.Undecoded() feature.\n\tkey = \"This table intentionally left undecoded\"\n`)\n\tf.Fuzz(func(t *testing.T, file string) {\n\t\tvar m map[string]any\n\t\t_, err := Decode(file, &m)\n\t\tif err != nil {\n\t\t\tt.Skip()\n\t\t}\n\n\t\tNewEncoder(bytes.NewBuffer(buf)).Encode(m)\n\n\t\t// TODO: should check if the output is equal to the input, too, but some\n\t\t// information is lost when encoding.\n\t})\n}\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.0419921875,
          "content": "module github.com/BurntSushi/toml\n\ngo 1.18\n"
        },
        {
          "name": "internal",
          "type": "tree",
          "content": null
        },
        {
          "name": "lex.go",
          "type": "blob",
          "size": 29.7822265625,
          "content": "package toml\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n\t\"runtime\"\n\t\"strings\"\n\t\"unicode\"\n\t\"unicode/utf8\"\n)\n\ntype itemType int\n\nconst (\n\titemError itemType = iota\n\titemNIL            // used in the parser to indicate no type\n\titemEOF\n\titemText\n\titemString\n\titemStringEsc\n\titemRawString\n\titemMultilineString\n\titemRawMultilineString\n\titemBool\n\titemInteger\n\titemFloat\n\titemDatetime\n\titemArray // the start of an array\n\titemArrayEnd\n\titemTableStart\n\titemTableEnd\n\titemArrayTableStart\n\titemArrayTableEnd\n\titemKeyStart\n\titemKeyEnd\n\titemCommentStart\n\titemInlineTableStart\n\titemInlineTableEnd\n)\n\nconst eof = 0\n\ntype stateFn func(lx *lexer) stateFn\n\nfunc (p Position) String() string {\n\treturn fmt.Sprintf(\"at line %d; start %d; length %d\", p.Line, p.Start, p.Len)\n}\n\ntype lexer struct {\n\tinput    string\n\tstart    int\n\tpos      int\n\tline     int\n\tstate    stateFn\n\titems    chan item\n\ttomlNext bool\n\tesc      bool\n\n\t// Allow for backing up up to 4 runes. This is necessary because TOML\n\t// contains 3-rune tokens (\"\"\" and ''').\n\tprevWidths [4]int\n\tnprev      int  // how many of prevWidths are in use\n\tatEOF      bool // If we emit an eof, we can still back up, but it is not OK to call next again.\n\n\t// A stack of state functions used to maintain context.\n\t//\n\t// The idea is to reuse parts of the state machine in various places. For\n\t// example, values can appear at the top level or within arbitrarily nested\n\t// arrays. The last state on the stack is used after a value has been lexed.\n\t// Similarly for comments.\n\tstack []stateFn\n}\n\ntype item struct {\n\ttyp itemType\n\tval string\n\terr error\n\tpos Position\n}\n\nfunc (lx *lexer) nextItem() item {\n\tfor {\n\t\tselect {\n\t\tcase item := <-lx.items:\n\t\t\treturn item\n\t\tdefault:\n\t\t\tlx.state = lx.state(lx)\n\t\t\t//fmt.Printf(\"     STATE %-24s  current: %-10s\tstack: %s\\n\", lx.state, lx.current(), lx.stack)\n\t\t}\n\t}\n}\n\nfunc lex(input string, tomlNext bool) *lexer {\n\tlx := &lexer{\n\t\tinput:    input,\n\t\tstate:    lexTop,\n\t\titems:    make(chan item, 10),\n\t\tstack:    make([]stateFn, 0, 10),\n\t\tline:     1,\n\t\ttomlNext: tomlNext,\n\t}\n\treturn lx\n}\n\nfunc (lx *lexer) push(state stateFn) {\n\tlx.stack = append(lx.stack, state)\n}\n\nfunc (lx *lexer) pop() stateFn {\n\tif len(lx.stack) == 0 {\n\t\treturn lx.errorf(\"BUG in lexer: no states to pop\")\n\t}\n\tlast := lx.stack[len(lx.stack)-1]\n\tlx.stack = lx.stack[0 : len(lx.stack)-1]\n\treturn last\n}\n\nfunc (lx *lexer) current() string {\n\treturn lx.input[lx.start:lx.pos]\n}\n\nfunc (lx lexer) getPos() Position {\n\tp := Position{\n\t\tLine:  lx.line,\n\t\tStart: lx.start,\n\t\tLen:   lx.pos - lx.start,\n\t}\n\tif p.Len <= 0 {\n\t\tp.Len = 1\n\t}\n\treturn p\n}\n\nfunc (lx *lexer) emit(typ itemType) {\n\t// Needed for multiline strings ending with an incomplete UTF-8 sequence.\n\tif lx.start > lx.pos {\n\t\tlx.error(errLexUTF8{lx.input[lx.pos]})\n\t\treturn\n\t}\n\tlx.items <- item{typ: typ, pos: lx.getPos(), val: lx.current()}\n\tlx.start = lx.pos\n}\n\nfunc (lx *lexer) emitTrim(typ itemType) {\n\tlx.items <- item{typ: typ, pos: lx.getPos(), val: strings.TrimSpace(lx.current())}\n\tlx.start = lx.pos\n}\n\nfunc (lx *lexer) next() (r rune) {\n\tif lx.atEOF {\n\t\tpanic(\"BUG in lexer: next called after EOF\")\n\t}\n\tif lx.pos >= len(lx.input) {\n\t\tlx.atEOF = true\n\t\treturn eof\n\t}\n\n\tif lx.input[lx.pos] == '\\n' {\n\t\tlx.line++\n\t}\n\tlx.prevWidths[3] = lx.prevWidths[2]\n\tlx.prevWidths[2] = lx.prevWidths[1]\n\tlx.prevWidths[1] = lx.prevWidths[0]\n\tif lx.nprev < 4 {\n\t\tlx.nprev++\n\t}\n\n\tr, w := utf8.DecodeRuneInString(lx.input[lx.pos:])\n\tif r == utf8.RuneError && w == 1 {\n\t\tlx.error(errLexUTF8{lx.input[lx.pos]})\n\t\treturn utf8.RuneError\n\t}\n\n\t// Note: don't use peek() here, as this calls next().\n\tif isControl(r) || (r == '\\r' && (len(lx.input)-1 == lx.pos || lx.input[lx.pos+1] != '\\n')) {\n\t\tlx.errorControlChar(r)\n\t\treturn utf8.RuneError\n\t}\n\n\tlx.prevWidths[0] = w\n\tlx.pos += w\n\treturn r\n}\n\n// ignore skips over the pending input before this point.\nfunc (lx *lexer) ignore() {\n\tlx.start = lx.pos\n}\n\n// backup steps back one rune. Can be called 4 times between calls to next.\nfunc (lx *lexer) backup() {\n\tif lx.atEOF {\n\t\tlx.atEOF = false\n\t\treturn\n\t}\n\tif lx.nprev < 1 {\n\t\tpanic(\"BUG in lexer: backed up too far\")\n\t}\n\tw := lx.prevWidths[0]\n\tlx.prevWidths[0] = lx.prevWidths[1]\n\tlx.prevWidths[1] = lx.prevWidths[2]\n\tlx.prevWidths[2] = lx.prevWidths[3]\n\tlx.nprev--\n\n\tlx.pos -= w\n\tif lx.pos < len(lx.input) && lx.input[lx.pos] == '\\n' {\n\t\tlx.line--\n\t}\n}\n\n// accept consumes the next rune if it's equal to `valid`.\nfunc (lx *lexer) accept(valid rune) bool {\n\tif lx.next() == valid {\n\t\treturn true\n\t}\n\tlx.backup()\n\treturn false\n}\n\n// peek returns but does not consume the next rune in the input.\nfunc (lx *lexer) peek() rune {\n\tr := lx.next()\n\tlx.backup()\n\treturn r\n}\n\n// skip ignores all input that matches the given predicate.\nfunc (lx *lexer) skip(pred func(rune) bool) {\n\tfor {\n\t\tr := lx.next()\n\t\tif pred(r) {\n\t\t\tcontinue\n\t\t}\n\t\tlx.backup()\n\t\tlx.ignore()\n\t\treturn\n\t}\n}\n\n// error stops all lexing by emitting an error and returning `nil`.\n//\n// Note that any value that is a character is escaped if it's a special\n// character (newlines, tabs, etc.).\nfunc (lx *lexer) error(err error) stateFn {\n\tif lx.atEOF {\n\t\treturn lx.errorPrevLine(err)\n\t}\n\tlx.items <- item{typ: itemError, pos: lx.getPos(), err: err}\n\treturn nil\n}\n\n// errorfPrevline is like error(), but sets the position to the last column of\n// the previous line.\n//\n// This is so that unexpected EOF or NL errors don't show on a new blank line.\nfunc (lx *lexer) errorPrevLine(err error) stateFn {\n\tpos := lx.getPos()\n\tpos.Line--\n\tpos.Len = 1\n\tpos.Start = lx.pos - 1\n\tlx.items <- item{typ: itemError, pos: pos, err: err}\n\treturn nil\n}\n\n// errorPos is like error(), but allows explicitly setting the position.\nfunc (lx *lexer) errorPos(start, length int, err error) stateFn {\n\tpos := lx.getPos()\n\tpos.Start = start\n\tpos.Len = length\n\tlx.items <- item{typ: itemError, pos: pos, err: err}\n\treturn nil\n}\n\n// errorf is like error, and creates a new error.\nfunc (lx *lexer) errorf(format string, values ...any) stateFn {\n\tif lx.atEOF {\n\t\tpos := lx.getPos()\n\t\tpos.Line--\n\t\tpos.Len = 1\n\t\tpos.Start = lx.pos - 1\n\t\tlx.items <- item{typ: itemError, pos: pos, err: fmt.Errorf(format, values...)}\n\t\treturn nil\n\t}\n\tlx.items <- item{typ: itemError, pos: lx.getPos(), err: fmt.Errorf(format, values...)}\n\treturn nil\n}\n\nfunc (lx *lexer) errorControlChar(cc rune) stateFn {\n\treturn lx.errorPos(lx.pos-1, 1, errLexControl{cc})\n}\n\n// lexTop consumes elements at the top level of TOML data.\nfunc lexTop(lx *lexer) stateFn {\n\tr := lx.next()\n\tif isWhitespace(r) || isNL(r) {\n\t\treturn lexSkip(lx, lexTop)\n\t}\n\tswitch r {\n\tcase '#':\n\t\tlx.push(lexTop)\n\t\treturn lexCommentStart\n\tcase '[':\n\t\treturn lexTableStart\n\tcase eof:\n\t\tif lx.pos > lx.start {\n\t\t\treturn lx.errorf(\"unexpected EOF\")\n\t\t}\n\t\tlx.emit(itemEOF)\n\t\treturn nil\n\t}\n\n\t// At this point, the only valid item can be a key, so we back up\n\t// and let the key lexer do the rest.\n\tlx.backup()\n\tlx.push(lexTopEnd)\n\treturn lexKeyStart\n}\n\n// lexTopEnd is entered whenever a top-level item has been consumed. (A value\n// or a table.) It must see only whitespace, and will turn back to lexTop\n// upon a newline. If it sees EOF, it will quit the lexer successfully.\nfunc lexTopEnd(lx *lexer) stateFn {\n\tr := lx.next()\n\tswitch {\n\tcase r == '#':\n\t\t// a comment will read to a newline for us.\n\t\tlx.push(lexTop)\n\t\treturn lexCommentStart\n\tcase isWhitespace(r):\n\t\treturn lexTopEnd\n\tcase isNL(r):\n\t\tlx.ignore()\n\t\treturn lexTop\n\tcase r == eof:\n\t\tlx.emit(itemEOF)\n\t\treturn nil\n\t}\n\treturn lx.errorf(\"expected a top-level item to end with a newline, comment, or EOF, but got %q instead\", r)\n}\n\n// lexTable lexes the beginning of a table. Namely, it makes sure that\n// it starts with a character other than '.' and ']'.\n// It assumes that '[' has already been consumed.\n// It also handles the case that this is an item in an array of tables.\n// e.g., '[[name]]'.\nfunc lexTableStart(lx *lexer) stateFn {\n\tif lx.peek() == '[' {\n\t\tlx.next()\n\t\tlx.emit(itemArrayTableStart)\n\t\tlx.push(lexArrayTableEnd)\n\t} else {\n\t\tlx.emit(itemTableStart)\n\t\tlx.push(lexTableEnd)\n\t}\n\treturn lexTableNameStart\n}\n\nfunc lexTableEnd(lx *lexer) stateFn {\n\tlx.emit(itemTableEnd)\n\treturn lexTopEnd\n}\n\nfunc lexArrayTableEnd(lx *lexer) stateFn {\n\tif r := lx.next(); r != ']' {\n\t\treturn lx.errorf(\"expected end of table array name delimiter ']', but got %q instead\", r)\n\t}\n\tlx.emit(itemArrayTableEnd)\n\treturn lexTopEnd\n}\n\nfunc lexTableNameStart(lx *lexer) stateFn {\n\tlx.skip(isWhitespace)\n\tswitch r := lx.peek(); {\n\tcase r == ']' || r == eof:\n\t\treturn lx.errorf(\"unexpected end of table name (table names cannot be empty)\")\n\tcase r == '.':\n\t\treturn lx.errorf(\"unexpected table separator (table names cannot be empty)\")\n\tcase r == '\"' || r == '\\'':\n\t\tlx.ignore()\n\t\tlx.push(lexTableNameEnd)\n\t\treturn lexQuotedName\n\tdefault:\n\t\tlx.push(lexTableNameEnd)\n\t\treturn lexBareName\n\t}\n}\n\n// lexTableNameEnd reads the end of a piece of a table name, optionally\n// consuming whitespace.\nfunc lexTableNameEnd(lx *lexer) stateFn {\n\tlx.skip(isWhitespace)\n\tswitch r := lx.next(); {\n\tcase isWhitespace(r):\n\t\treturn lexTableNameEnd\n\tcase r == '.':\n\t\tlx.ignore()\n\t\treturn lexTableNameStart\n\tcase r == ']':\n\t\treturn lx.pop()\n\tdefault:\n\t\treturn lx.errorf(\"expected '.' or ']' to end table name, but got %q instead\", r)\n\t}\n}\n\n// lexBareName lexes one part of a key or table.\n//\n// It assumes that at least one valid character for the table has already been\n// read.\n//\n// Lexes only one part, e.g. only 'a' inside 'a.b'.\nfunc lexBareName(lx *lexer) stateFn {\n\tr := lx.next()\n\tif isBareKeyChar(r, lx.tomlNext) {\n\t\treturn lexBareName\n\t}\n\tlx.backup()\n\tlx.emit(itemText)\n\treturn lx.pop()\n}\n\n// lexBareName lexes one part of a key or table.\n//\n// It assumes that at least one valid character for the table has already been\n// read.\n//\n// Lexes only one part, e.g. only '\"a\"' inside '\"a\".b'.\nfunc lexQuotedName(lx *lexer) stateFn {\n\tr := lx.next()\n\tswitch {\n\tcase isWhitespace(r):\n\t\treturn lexSkip(lx, lexValue)\n\tcase r == '\"':\n\t\tlx.ignore() // ignore the '\"'\n\t\treturn lexString\n\tcase r == '\\'':\n\t\tlx.ignore() // ignore the \"'\"\n\t\treturn lexRawString\n\tcase r == eof:\n\t\treturn lx.errorf(\"unexpected EOF; expected value\")\n\tdefault:\n\t\treturn lx.errorf(\"expected value but found %q instead\", r)\n\t}\n}\n\n// lexKeyStart consumes all key parts until a '='.\nfunc lexKeyStart(lx *lexer) stateFn {\n\tlx.skip(isWhitespace)\n\tswitch r := lx.peek(); {\n\tcase r == '=' || r == eof:\n\t\treturn lx.errorf(\"unexpected '=': key name appears blank\")\n\tcase r == '.':\n\t\treturn lx.errorf(\"unexpected '.': keys cannot start with a '.'\")\n\tcase r == '\"' || r == '\\'':\n\t\tlx.ignore()\n\t\tfallthrough\n\tdefault: // Bare key\n\t\tlx.emit(itemKeyStart)\n\t\treturn lexKeyNameStart\n\t}\n}\n\nfunc lexKeyNameStart(lx *lexer) stateFn {\n\tlx.skip(isWhitespace)\n\tswitch r := lx.peek(); {\n\tcase r == '=' || r == eof:\n\t\treturn lx.errorf(\"unexpected '='\")\n\tcase r == '.':\n\t\treturn lx.errorf(\"unexpected '.'\")\n\tcase r == '\"' || r == '\\'':\n\t\tlx.ignore()\n\t\tlx.push(lexKeyEnd)\n\t\treturn lexQuotedName\n\tdefault:\n\t\tlx.push(lexKeyEnd)\n\t\treturn lexBareName\n\t}\n}\n\n// lexKeyEnd consumes the end of a key and trims whitespace (up to the key\n// separator).\nfunc lexKeyEnd(lx *lexer) stateFn {\n\tlx.skip(isWhitespace)\n\tswitch r := lx.next(); {\n\tcase isWhitespace(r):\n\t\treturn lexSkip(lx, lexKeyEnd)\n\tcase r == eof:\n\t\treturn lx.errorf(\"unexpected EOF; expected key separator '='\")\n\tcase r == '.':\n\t\tlx.ignore()\n\t\treturn lexKeyNameStart\n\tcase r == '=':\n\t\tlx.emit(itemKeyEnd)\n\t\treturn lexSkip(lx, lexValue)\n\tdefault:\n\t\tif r == '\\n' {\n\t\t\treturn lx.errorPrevLine(fmt.Errorf(\"expected '.' or '=', but got %q instead\", r))\n\t\t}\n\t\treturn lx.errorf(\"expected '.' or '=', but got %q instead\", r)\n\t}\n}\n\n// lexValue starts the consumption of a value anywhere a value is expected.\n// lexValue will ignore whitespace.\n// After a value is lexed, the last state on the next is popped and returned.\nfunc lexValue(lx *lexer) stateFn {\n\t// We allow whitespace to precede a value, but NOT newlines.\n\t// In array syntax, the array states are responsible for ignoring newlines.\n\tr := lx.next()\n\tswitch {\n\tcase isWhitespace(r):\n\t\treturn lexSkip(lx, lexValue)\n\tcase isDigit(r):\n\t\tlx.backup() // avoid an extra state and use the same as above\n\t\treturn lexNumberOrDateStart\n\t}\n\tswitch r {\n\tcase '[':\n\t\tlx.ignore()\n\t\tlx.emit(itemArray)\n\t\treturn lexArrayValue\n\tcase '{':\n\t\tlx.ignore()\n\t\tlx.emit(itemInlineTableStart)\n\t\treturn lexInlineTableValue\n\tcase '\"':\n\t\tif lx.accept('\"') {\n\t\t\tif lx.accept('\"') {\n\t\t\t\tlx.ignore() // Ignore \"\"\"\n\t\t\t\treturn lexMultilineString\n\t\t\t}\n\t\t\tlx.backup()\n\t\t}\n\t\tlx.ignore() // ignore the '\"'\n\t\treturn lexString\n\tcase '\\'':\n\t\tif lx.accept('\\'') {\n\t\t\tif lx.accept('\\'') {\n\t\t\t\tlx.ignore() // Ignore \"\"\"\n\t\t\t\treturn lexMultilineRawString\n\t\t\t}\n\t\t\tlx.backup()\n\t\t}\n\t\tlx.ignore() // ignore the \"'\"\n\t\treturn lexRawString\n\tcase '.': // special error case, be kind to users\n\t\treturn lx.errorf(\"floats must start with a digit, not '.'\")\n\tcase 'i', 'n':\n\t\tif (lx.accept('n') && lx.accept('f')) || (lx.accept('a') && lx.accept('n')) {\n\t\t\tlx.emit(itemFloat)\n\t\t\treturn lx.pop()\n\t\t}\n\tcase '-', '+':\n\t\treturn lexDecimalNumberStart\n\t}\n\tif unicode.IsLetter(r) {\n\t\t// Be permissive here; lexBool will give a nice error if the\n\t\t// user wrote something like\n\t\t//   x = foo\n\t\t// (i.e. not 'true' or 'false' but is something else word-like.)\n\t\tlx.backup()\n\t\treturn lexBool\n\t}\n\tif r == eof {\n\t\treturn lx.errorf(\"unexpected EOF; expected value\")\n\t}\n\tif r == '\\n' {\n\t\treturn lx.errorPrevLine(fmt.Errorf(\"expected value but found %q instead\", r))\n\t}\n\treturn lx.errorf(\"expected value but found %q instead\", r)\n}\n\n// lexArrayValue consumes one value in an array. It assumes that '[' or ','\n// have already been consumed. All whitespace and newlines are ignored.\nfunc lexArrayValue(lx *lexer) stateFn {\n\tr := lx.next()\n\tswitch {\n\tcase isWhitespace(r) || isNL(r):\n\t\treturn lexSkip(lx, lexArrayValue)\n\tcase r == '#':\n\t\tlx.push(lexArrayValue)\n\t\treturn lexCommentStart\n\tcase r == ',':\n\t\treturn lx.errorf(\"unexpected comma\")\n\tcase r == ']':\n\t\treturn lexArrayEnd\n\t}\n\n\tlx.backup()\n\tlx.push(lexArrayValueEnd)\n\treturn lexValue\n}\n\n// lexArrayValueEnd consumes everything between the end of an array value and\n// the next value (or the end of the array): it ignores whitespace and newlines\n// and expects either a ',' or a ']'.\nfunc lexArrayValueEnd(lx *lexer) stateFn {\n\tswitch r := lx.next(); {\n\tcase isWhitespace(r) || isNL(r):\n\t\treturn lexSkip(lx, lexArrayValueEnd)\n\tcase r == '#':\n\t\tlx.push(lexArrayValueEnd)\n\t\treturn lexCommentStart\n\tcase r == ',':\n\t\tlx.ignore()\n\t\treturn lexArrayValue // move on to the next value\n\tcase r == ']':\n\t\treturn lexArrayEnd\n\tdefault:\n\t\treturn lx.errorf(\"expected a comma (',') or array terminator (']'), but got %s\", runeOrEOF(r))\n\t}\n}\n\n// lexArrayEnd finishes the lexing of an array.\n// It assumes that a ']' has just been consumed.\nfunc lexArrayEnd(lx *lexer) stateFn {\n\tlx.ignore()\n\tlx.emit(itemArrayEnd)\n\treturn lx.pop()\n}\n\n// lexInlineTableValue consumes one key/value pair in an inline table.\n// It assumes that '{' or ',' have already been consumed. Whitespace is ignored.\nfunc lexInlineTableValue(lx *lexer) stateFn {\n\tr := lx.next()\n\tswitch {\n\tcase isWhitespace(r):\n\t\treturn lexSkip(lx, lexInlineTableValue)\n\tcase isNL(r):\n\t\tif lx.tomlNext {\n\t\t\treturn lexSkip(lx, lexInlineTableValue)\n\t\t}\n\t\treturn lx.errorPrevLine(errLexInlineTableNL{})\n\tcase r == '#':\n\t\tlx.push(lexInlineTableValue)\n\t\treturn lexCommentStart\n\tcase r == ',':\n\t\treturn lx.errorf(\"unexpected comma\")\n\tcase r == '}':\n\t\treturn lexInlineTableEnd\n\t}\n\tlx.backup()\n\tlx.push(lexInlineTableValueEnd)\n\treturn lexKeyStart\n}\n\n// lexInlineTableValueEnd consumes everything between the end of an inline table\n// key/value pair and the next pair (or the end of the table):\n// it ignores whitespace and expects either a ',' or a '}'.\nfunc lexInlineTableValueEnd(lx *lexer) stateFn {\n\tswitch r := lx.next(); {\n\tcase isWhitespace(r):\n\t\treturn lexSkip(lx, lexInlineTableValueEnd)\n\tcase isNL(r):\n\t\tif lx.tomlNext {\n\t\t\treturn lexSkip(lx, lexInlineTableValueEnd)\n\t\t}\n\t\treturn lx.errorPrevLine(errLexInlineTableNL{})\n\tcase r == '#':\n\t\tlx.push(lexInlineTableValueEnd)\n\t\treturn lexCommentStart\n\tcase r == ',':\n\t\tlx.ignore()\n\t\tlx.skip(isWhitespace)\n\t\tif lx.peek() == '}' {\n\t\t\tif lx.tomlNext {\n\t\t\t\treturn lexInlineTableValueEnd\n\t\t\t}\n\t\t\treturn lx.errorf(\"trailing comma not allowed in inline tables\")\n\t\t}\n\t\treturn lexInlineTableValue\n\tcase r == '}':\n\t\treturn lexInlineTableEnd\n\tdefault:\n\t\treturn lx.errorf(\"expected a comma or an inline table terminator '}', but got %s instead\", runeOrEOF(r))\n\t}\n}\n\nfunc runeOrEOF(r rune) string {\n\tif r == eof {\n\t\treturn \"end of file\"\n\t}\n\treturn \"'\" + string(r) + \"'\"\n}\n\n// lexInlineTableEnd finishes the lexing of an inline table.\n// It assumes that a '}' has just been consumed.\nfunc lexInlineTableEnd(lx *lexer) stateFn {\n\tlx.ignore()\n\tlx.emit(itemInlineTableEnd)\n\treturn lx.pop()\n}\n\n// lexString consumes the inner contents of a string. It assumes that the\n// beginning '\"' has already been consumed and ignored.\nfunc lexString(lx *lexer) stateFn {\n\tr := lx.next()\n\tswitch {\n\tcase r == eof:\n\t\treturn lx.errorf(`unexpected EOF; expected '\"'`)\n\tcase isNL(r):\n\t\treturn lx.errorPrevLine(errLexStringNL{})\n\tcase r == '\\\\':\n\t\tlx.push(lexString)\n\t\treturn lexStringEscape\n\tcase r == '\"':\n\t\tlx.backup()\n\t\tif lx.esc {\n\t\t\tlx.esc = false\n\t\t\tlx.emit(itemStringEsc)\n\t\t} else {\n\t\t\tlx.emit(itemString)\n\t\t}\n\t\tlx.next()\n\t\tlx.ignore()\n\t\treturn lx.pop()\n\t}\n\treturn lexString\n}\n\n// lexMultilineString consumes the inner contents of a string. It assumes that\n// the beginning '\"\"\"' has already been consumed and ignored.\nfunc lexMultilineString(lx *lexer) stateFn {\n\tr := lx.next()\n\tswitch r {\n\tdefault:\n\t\treturn lexMultilineString\n\tcase eof:\n\t\treturn lx.errorf(`unexpected EOF; expected '\"\"\"'`)\n\tcase '\\\\':\n\t\treturn lexMultilineStringEscape\n\tcase '\"':\n\t\t/// Found \"  try to read two more \"\".\n\t\tif lx.accept('\"') {\n\t\t\tif lx.accept('\"') {\n\t\t\t\t/// Peek ahead: the string can contain \" and \"\", including at the\n\t\t\t\t/// end: \"\"\"str\"\"\"\"\"\n\t\t\t\t/// 6 or more at the end, however, is an error.\n\t\t\t\tif lx.peek() == '\"' {\n\t\t\t\t\t/// Check if we already lexed 5 's; if so we have 6 now, and\n\t\t\t\t\t/// that's just too many man!\n\t\t\t\t\t///\n\t\t\t\t\t/// Second check is for the edge case:\n\t\t\t\t\t///\n\t\t\t\t\t///            two quotes allowed.\n\t\t\t\t\t///            vv\n\t\t\t\t\t///   \"\"\"lol \\\"\"\"\"\"\"\n\t\t\t\t\t///          ^^  ^^^---- closing three\n\t\t\t\t\t///     escaped\n\t\t\t\t\t///\n\t\t\t\t\t/// But ugly, but it works\n\t\t\t\t\tif strings.HasSuffix(lx.current(), `\"\"\"\"\"`) && !strings.HasSuffix(lx.current(), `\\\"\"\"\"\"`) {\n\t\t\t\t\t\treturn lx.errorf(`unexpected '\"\"\"\"\"\"'`)\n\t\t\t\t\t}\n\t\t\t\t\tlx.backup()\n\t\t\t\t\tlx.backup()\n\t\t\t\t\treturn lexMultilineString\n\t\t\t\t}\n\n\t\t\t\tlx.backup() /// backup: don't include the \"\"\" in the item.\n\t\t\t\tlx.backup()\n\t\t\t\tlx.backup()\n\t\t\t\tlx.esc = false\n\t\t\t\tlx.emit(itemMultilineString)\n\t\t\t\tlx.next() /// Read over ''' again and discard it.\n\t\t\t\tlx.next()\n\t\t\t\tlx.next()\n\t\t\t\tlx.ignore()\n\t\t\t\treturn lx.pop()\n\t\t\t}\n\t\t\tlx.backup()\n\t\t}\n\t\treturn lexMultilineString\n\t}\n}\n\n// lexRawString consumes a raw string. Nothing can be escaped in such a string.\n// It assumes that the beginning \"'\" has already been consumed and ignored.\nfunc lexRawString(lx *lexer) stateFn {\n\tr := lx.next()\n\tswitch {\n\tdefault:\n\t\treturn lexRawString\n\tcase r == eof:\n\t\treturn lx.errorf(`unexpected EOF; expected \"'\"`)\n\tcase isNL(r):\n\t\treturn lx.errorPrevLine(errLexStringNL{})\n\tcase r == '\\'':\n\t\tlx.backup()\n\t\tlx.emit(itemRawString)\n\t\tlx.next()\n\t\tlx.ignore()\n\t\treturn lx.pop()\n\t}\n}\n\n// lexMultilineRawString consumes a raw string. Nothing can be escaped in such a\n// string. It assumes that the beginning triple-' has already been consumed and\n// ignored.\nfunc lexMultilineRawString(lx *lexer) stateFn {\n\tr := lx.next()\n\tswitch r {\n\tdefault:\n\t\treturn lexMultilineRawString\n\tcase eof:\n\t\treturn lx.errorf(`unexpected EOF; expected \"'''\"`)\n\tcase '\\'':\n\t\t/// Found '  try to read two more ''.\n\t\tif lx.accept('\\'') {\n\t\t\tif lx.accept('\\'') {\n\t\t\t\t/// Peek ahead: the string can contain ' and '', including at the\n\t\t\t\t/// end: '''str'''''\n\t\t\t\t/// 6 or more at the end, however, is an error.\n\t\t\t\tif lx.peek() == '\\'' {\n\t\t\t\t\t/// Check if we already lexed 5 's; if so we have 6 now, and\n\t\t\t\t\t/// that's just too many man!\n\t\t\t\t\tif strings.HasSuffix(lx.current(), \"'''''\") {\n\t\t\t\t\t\treturn lx.errorf(`unexpected \"''''''\"`)\n\t\t\t\t\t}\n\t\t\t\t\tlx.backup()\n\t\t\t\t\tlx.backup()\n\t\t\t\t\treturn lexMultilineRawString\n\t\t\t\t}\n\n\t\t\t\tlx.backup() /// backup: don't include the ''' in the item.\n\t\t\t\tlx.backup()\n\t\t\t\tlx.backup()\n\t\t\t\tlx.emit(itemRawMultilineString)\n\t\t\t\tlx.next() /// Read over ''' again and discard it.\n\t\t\t\tlx.next()\n\t\t\t\tlx.next()\n\t\t\t\tlx.ignore()\n\t\t\t\treturn lx.pop()\n\t\t\t}\n\t\t\tlx.backup()\n\t\t}\n\t\treturn lexMultilineRawString\n\t}\n}\n\n// lexMultilineStringEscape consumes an escaped character. It assumes that the\n// preceding '\\\\' has already been consumed.\nfunc lexMultilineStringEscape(lx *lexer) stateFn {\n\tif isNL(lx.next()) { /// \\ escaping newline.\n\t\treturn lexMultilineString\n\t}\n\tlx.backup()\n\tlx.push(lexMultilineString)\n\treturn lexStringEscape(lx)\n}\n\nfunc lexStringEscape(lx *lexer) stateFn {\n\tlx.esc = true\n\tr := lx.next()\n\tswitch r {\n\tcase 'e':\n\t\tif !lx.tomlNext {\n\t\t\treturn lx.error(errLexEscape{r})\n\t\t}\n\t\tfallthrough\n\tcase 'b':\n\t\tfallthrough\n\tcase 't':\n\t\tfallthrough\n\tcase 'n':\n\t\tfallthrough\n\tcase 'f':\n\t\tfallthrough\n\tcase 'r':\n\t\tfallthrough\n\tcase '\"':\n\t\tfallthrough\n\tcase ' ', '\\t':\n\t\t// Inside \"\"\" .. \"\"\" strings you can use \\ to escape newlines, and any\n\t\t// amount of whitespace can be between the \\ and \\n.\n\t\tfallthrough\n\tcase '\\\\':\n\t\treturn lx.pop()\n\tcase 'x':\n\t\tif !lx.tomlNext {\n\t\t\treturn lx.error(errLexEscape{r})\n\t\t}\n\t\treturn lexHexEscape\n\tcase 'u':\n\t\treturn lexShortUnicodeEscape\n\tcase 'U':\n\t\treturn lexLongUnicodeEscape\n\t}\n\treturn lx.error(errLexEscape{r})\n}\n\nfunc lexHexEscape(lx *lexer) stateFn {\n\tvar r rune\n\tfor i := 0; i < 2; i++ {\n\t\tr = lx.next()\n\t\tif !isHex(r) {\n\t\t\treturn lx.errorf(`expected two hexadecimal digits after '\\x', but got %q instead`, lx.current())\n\t\t}\n\t}\n\treturn lx.pop()\n}\n\nfunc lexShortUnicodeEscape(lx *lexer) stateFn {\n\tvar r rune\n\tfor i := 0; i < 4; i++ {\n\t\tr = lx.next()\n\t\tif !isHex(r) {\n\t\t\treturn lx.errorf(`expected four hexadecimal digits after '\\u', but got %q instead`, lx.current())\n\t\t}\n\t}\n\treturn lx.pop()\n}\n\nfunc lexLongUnicodeEscape(lx *lexer) stateFn {\n\tvar r rune\n\tfor i := 0; i < 8; i++ {\n\t\tr = lx.next()\n\t\tif !isHex(r) {\n\t\t\treturn lx.errorf(`expected eight hexadecimal digits after '\\U', but got %q instead`, lx.current())\n\t\t}\n\t}\n\treturn lx.pop()\n}\n\n// lexNumberOrDateStart processes the first character of a value which begins\n// with a digit. It exists to catch values starting with '0', so that\n// lexBaseNumberOrDate can differentiate base prefixed integers from other\n// types.\nfunc lexNumberOrDateStart(lx *lexer) stateFn {\n\tr := lx.next()\n\tswitch r {\n\tcase '0':\n\t\treturn lexBaseNumberOrDate\n\t}\n\n\tif !isDigit(r) {\n\t\t// The only way to reach this state is if the value starts\n\t\t// with a digit, so specifically treat anything else as an\n\t\t// error.\n\t\treturn lx.errorf(\"expected a digit but got %q\", r)\n\t}\n\n\treturn lexNumberOrDate\n}\n\n// lexNumberOrDate consumes either an integer, float or datetime.\nfunc lexNumberOrDate(lx *lexer) stateFn {\n\tr := lx.next()\n\tif isDigit(r) {\n\t\treturn lexNumberOrDate\n\t}\n\tswitch r {\n\tcase '-', ':':\n\t\treturn lexDatetime\n\tcase '_':\n\t\treturn lexDecimalNumber\n\tcase '.', 'e', 'E':\n\t\treturn lexFloat\n\t}\n\n\tlx.backup()\n\tlx.emit(itemInteger)\n\treturn lx.pop()\n}\n\n// lexDatetime consumes a Datetime, to a first approximation.\n// The parser validates that it matches one of the accepted formats.\nfunc lexDatetime(lx *lexer) stateFn {\n\tr := lx.next()\n\tif isDigit(r) {\n\t\treturn lexDatetime\n\t}\n\tswitch r {\n\tcase '-', ':', 'T', 't', ' ', '.', 'Z', 'z', '+':\n\t\treturn lexDatetime\n\t}\n\n\tlx.backup()\n\tlx.emitTrim(itemDatetime)\n\treturn lx.pop()\n}\n\n// lexHexInteger consumes a hexadecimal integer after seeing the '0x' prefix.\nfunc lexHexInteger(lx *lexer) stateFn {\n\tr := lx.next()\n\tif isHex(r) {\n\t\treturn lexHexInteger\n\t}\n\tswitch r {\n\tcase '_':\n\t\treturn lexHexInteger\n\t}\n\n\tlx.backup()\n\tlx.emit(itemInteger)\n\treturn lx.pop()\n}\n\n// lexOctalInteger consumes an octal integer after seeing the '0o' prefix.\nfunc lexOctalInteger(lx *lexer) stateFn {\n\tr := lx.next()\n\tif isOctal(r) {\n\t\treturn lexOctalInteger\n\t}\n\tswitch r {\n\tcase '_':\n\t\treturn lexOctalInteger\n\t}\n\n\tlx.backup()\n\tlx.emit(itemInteger)\n\treturn lx.pop()\n}\n\n// lexBinaryInteger consumes a binary integer after seeing the '0b' prefix.\nfunc lexBinaryInteger(lx *lexer) stateFn {\n\tr := lx.next()\n\tif isBinary(r) {\n\t\treturn lexBinaryInteger\n\t}\n\tswitch r {\n\tcase '_':\n\t\treturn lexBinaryInteger\n\t}\n\n\tlx.backup()\n\tlx.emit(itemInteger)\n\treturn lx.pop()\n}\n\n// lexDecimalNumber consumes a decimal float or integer.\nfunc lexDecimalNumber(lx *lexer) stateFn {\n\tr := lx.next()\n\tif isDigit(r) {\n\t\treturn lexDecimalNumber\n\t}\n\tswitch r {\n\tcase '.', 'e', 'E':\n\t\treturn lexFloat\n\tcase '_':\n\t\treturn lexDecimalNumber\n\t}\n\n\tlx.backup()\n\tlx.emit(itemInteger)\n\treturn lx.pop()\n}\n\n// lexDecimalNumber consumes the first digit of a number beginning with a sign.\n// It assumes the sign has already been consumed. Values which start with a sign\n// are only allowed to be decimal integers or floats.\n//\n// The special \"nan\" and \"inf\" values are also recognized.\nfunc lexDecimalNumberStart(lx *lexer) stateFn {\n\tr := lx.next()\n\n\t// Special error cases to give users better error messages\n\tswitch r {\n\tcase 'i':\n\t\tif !lx.accept('n') || !lx.accept('f') {\n\t\t\treturn lx.errorf(\"invalid float: '%s'\", lx.current())\n\t\t}\n\t\tlx.emit(itemFloat)\n\t\treturn lx.pop()\n\tcase 'n':\n\t\tif !lx.accept('a') || !lx.accept('n') {\n\t\t\treturn lx.errorf(\"invalid float: '%s'\", lx.current())\n\t\t}\n\t\tlx.emit(itemFloat)\n\t\treturn lx.pop()\n\tcase '0':\n\t\tp := lx.peek()\n\t\tswitch p {\n\t\tcase 'b', 'o', 'x':\n\t\t\treturn lx.errorf(\"cannot use sign with non-decimal numbers: '%s%c'\", lx.current(), p)\n\t\t}\n\tcase '.':\n\t\treturn lx.errorf(\"floats must start with a digit, not '.'\")\n\t}\n\n\tif isDigit(r) {\n\t\treturn lexDecimalNumber\n\t}\n\n\treturn lx.errorf(\"expected a digit but got %q\", r)\n}\n\n// lexBaseNumberOrDate differentiates between the possible values which\n// start with '0'. It assumes that before reaching this state, the initial '0'\n// has been consumed.\nfunc lexBaseNumberOrDate(lx *lexer) stateFn {\n\tr := lx.next()\n\t// Note: All datetimes start with at least two digits, so we don't\n\t// handle date characters (':', '-', etc.) here.\n\tif isDigit(r) {\n\t\treturn lexNumberOrDate\n\t}\n\tswitch r {\n\tcase '_':\n\t\t// Can only be decimal, because there can't be an underscore\n\t\t// between the '0' and the base designator, and dates can't\n\t\t// contain underscores.\n\t\treturn lexDecimalNumber\n\tcase '.', 'e', 'E':\n\t\treturn lexFloat\n\tcase 'b':\n\t\tr = lx.peek()\n\t\tif !isBinary(r) {\n\t\t\tlx.errorf(\"not a binary number: '%s%c'\", lx.current(), r)\n\t\t}\n\t\treturn lexBinaryInteger\n\tcase 'o':\n\t\tr = lx.peek()\n\t\tif !isOctal(r) {\n\t\t\tlx.errorf(\"not an octal number: '%s%c'\", lx.current(), r)\n\t\t}\n\t\treturn lexOctalInteger\n\tcase 'x':\n\t\tr = lx.peek()\n\t\tif !isHex(r) {\n\t\t\tlx.errorf(\"not a hexidecimal number: '%s%c'\", lx.current(), r)\n\t\t}\n\t\treturn lexHexInteger\n\t}\n\n\tlx.backup()\n\tlx.emit(itemInteger)\n\treturn lx.pop()\n}\n\n// lexFloat consumes the elements of a float. It allows any sequence of\n// float-like characters, so floats emitted by the lexer are only a first\n// approximation and must be validated by the parser.\nfunc lexFloat(lx *lexer) stateFn {\n\tr := lx.next()\n\tif isDigit(r) {\n\t\treturn lexFloat\n\t}\n\tswitch r {\n\tcase '_', '.', '-', '+', 'e', 'E':\n\t\treturn lexFloat\n\t}\n\n\tlx.backup()\n\tlx.emit(itemFloat)\n\treturn lx.pop()\n}\n\n// lexBool consumes a bool string: 'true' or 'false.\nfunc lexBool(lx *lexer) stateFn {\n\tvar rs []rune\n\tfor {\n\t\tr := lx.next()\n\t\tif !unicode.IsLetter(r) {\n\t\t\tlx.backup()\n\t\t\tbreak\n\t\t}\n\t\trs = append(rs, r)\n\t}\n\ts := string(rs)\n\tswitch s {\n\tcase \"true\", \"false\":\n\t\tlx.emit(itemBool)\n\t\treturn lx.pop()\n\t}\n\treturn lx.errorf(\"expected value but found %q instead\", s)\n}\n\n// lexCommentStart begins the lexing of a comment. It will emit\n// itemCommentStart and consume no characters, passing control to lexComment.\nfunc lexCommentStart(lx *lexer) stateFn {\n\tlx.ignore()\n\tlx.emit(itemCommentStart)\n\treturn lexComment\n}\n\n// lexComment lexes an entire comment. It assumes that '#' has been consumed.\n// It will consume *up to* the first newline character, and pass control\n// back to the last state on the stack.\nfunc lexComment(lx *lexer) stateFn {\n\tswitch r := lx.next(); {\n\tcase isNL(r) || r == eof:\n\t\tlx.backup()\n\t\tlx.emit(itemText)\n\t\treturn lx.pop()\n\tdefault:\n\t\treturn lexComment\n\t}\n}\n\n// lexSkip ignores all slurped input and moves on to the next state.\nfunc lexSkip(lx *lexer, nextState stateFn) stateFn {\n\tlx.ignore()\n\treturn nextState\n}\n\nfunc (s stateFn) String() string {\n\tname := runtime.FuncForPC(reflect.ValueOf(s).Pointer()).Name()\n\tif i := strings.LastIndexByte(name, '.'); i > -1 {\n\t\tname = name[i+1:]\n\t}\n\tif s == nil {\n\t\tname = \"<nil>\"\n\t}\n\treturn name + \"()\"\n}\n\nfunc (itype itemType) String() string {\n\tswitch itype {\n\tcase itemError:\n\t\treturn \"Error\"\n\tcase itemNIL:\n\t\treturn \"NIL\"\n\tcase itemEOF:\n\t\treturn \"EOF\"\n\tcase itemText:\n\t\treturn \"Text\"\n\tcase itemString, itemStringEsc, itemRawString, itemMultilineString, itemRawMultilineString:\n\t\treturn \"String\"\n\tcase itemBool:\n\t\treturn \"Bool\"\n\tcase itemInteger:\n\t\treturn \"Integer\"\n\tcase itemFloat:\n\t\treturn \"Float\"\n\tcase itemDatetime:\n\t\treturn \"DateTime\"\n\tcase itemTableStart:\n\t\treturn \"TableStart\"\n\tcase itemTableEnd:\n\t\treturn \"TableEnd\"\n\tcase itemKeyStart:\n\t\treturn \"KeyStart\"\n\tcase itemKeyEnd:\n\t\treturn \"KeyEnd\"\n\tcase itemArray:\n\t\treturn \"Array\"\n\tcase itemArrayEnd:\n\t\treturn \"ArrayEnd\"\n\tcase itemCommentStart:\n\t\treturn \"CommentStart\"\n\tcase itemInlineTableStart:\n\t\treturn \"InlineTableStart\"\n\tcase itemInlineTableEnd:\n\t\treturn \"InlineTableEnd\"\n\t}\n\tpanic(fmt.Sprintf(\"BUG: Unknown type '%d'.\", int(itype)))\n}\n\nfunc (item item) String() string {\n\treturn fmt.Sprintf(\"(%s, %s)\", item.typ, item.val)\n}\n\nfunc isWhitespace(r rune) bool { return r == '\\t' || r == ' ' }\nfunc isNL(r rune) bool         { return r == '\\n' || r == '\\r' }\nfunc isControl(r rune) bool { // Control characters except \\t, \\r, \\n\n\tswitch r {\n\tcase '\\t', '\\r', '\\n':\n\t\treturn false\n\tdefault:\n\t\treturn (r >= 0x00 && r <= 0x1f) || r == 0x7f\n\t}\n}\nfunc isDigit(r rune) bool  { return r >= '0' && r <= '9' }\nfunc isBinary(r rune) bool { return r == '0' || r == '1' }\nfunc isOctal(r rune) bool  { return r >= '0' && r <= '7' }\nfunc isHex(r rune) bool    { return (r >= '0' && r <= '9') || (r|0x20 >= 'a' && r|0x20 <= 'f') }\nfunc isBareKeyChar(r rune, tomlNext bool) bool {\n\treturn (r >= 'A' && r <= 'Z') || (r >= 'a' && r <= 'z') ||\n\t\t(r >= '0' && r <= '9') || r == '_' || r == '-'\n}\n"
        },
        {
          "name": "meta.go",
          "type": "blob",
          "size": 3.8828125,
          "content": "package toml\n\nimport (\n\t\"strings\"\n)\n\n// MetaData allows access to meta information about TOML data that's not\n// accessible otherwise.\n//\n// It allows checking if a key is defined in the TOML data, whether any keys\n// were undecoded, and the TOML type of a key.\ntype MetaData struct {\n\tcontext Key // Used only during decoding.\n\n\tkeyInfo map[string]keyInfo\n\tmapping map[string]any\n\tkeys    []Key\n\tdecoded map[string]struct{}\n\tdata    []byte // Input file; for errors.\n}\n\n// IsDefined reports if the key exists in the TOML data.\n//\n// The key should be specified hierarchically, for example to access the TOML\n// key \"a.b.c\" you would use IsDefined(\"a\", \"b\", \"c\"). Keys are case sensitive.\n//\n// Returns false for an empty key.\nfunc (md *MetaData) IsDefined(key ...string) bool {\n\tif len(key) == 0 {\n\t\treturn false\n\t}\n\n\tvar (\n\t\thash      map[string]any\n\t\tok        bool\n\t\thashOrVal any = md.mapping\n\t)\n\tfor _, k := range key {\n\t\tif hash, ok = hashOrVal.(map[string]any); !ok {\n\t\t\treturn false\n\t\t}\n\t\tif hashOrVal, ok = hash[k]; !ok {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\n// Type returns a string representation of the type of the key specified.\n//\n// Type will return the empty string if given an empty key or a key that does\n// not exist. Keys are case sensitive.\nfunc (md *MetaData) Type(key ...string) string {\n\tif ki, ok := md.keyInfo[Key(key).String()]; ok {\n\t\treturn ki.tomlType.typeString()\n\t}\n\treturn \"\"\n}\n\n// Keys returns a slice of every key in the TOML data, including key groups.\n//\n// Each key is itself a slice, where the first element is the top of the\n// hierarchy and the last is the most specific. The list will have the same\n// order as the keys appeared in the TOML data.\n//\n// All keys returned are non-empty.\nfunc (md *MetaData) Keys() []Key {\n\treturn md.keys\n}\n\n// Undecoded returns all keys that have not been decoded in the order in which\n// they appear in the original TOML document.\n//\n// This includes keys that haven't been decoded because of a [Primitive] value.\n// Once the Primitive value is decoded, the keys will be considered decoded.\n//\n// Also note that decoding into an empty interface will result in no decoding,\n// and so no keys will be considered decoded.\n//\n// In this sense, the Undecoded keys correspond to keys in the TOML document\n// that do not have a concrete type in your representation.\nfunc (md *MetaData) Undecoded() []Key {\n\tundecoded := make([]Key, 0, len(md.keys))\n\tfor _, key := range md.keys {\n\t\tif _, ok := md.decoded[key.String()]; !ok {\n\t\t\tundecoded = append(undecoded, key)\n\t\t}\n\t}\n\treturn undecoded\n}\n\n// Key represents any TOML key, including key groups. Use [MetaData.Keys] to get\n// values of this type.\ntype Key []string\n\nfunc (k Key) String() string {\n\t// This is called quite often, so it's a bit funky to make it faster.\n\tvar b strings.Builder\n\tb.Grow(len(k) * 25)\nouter:\n\tfor i, kk := range k {\n\t\tif i > 0 {\n\t\t\tb.WriteByte('.')\n\t\t}\n\t\tif kk == \"\" {\n\t\t\tb.WriteString(`\"\"`)\n\t\t} else {\n\t\t\tfor _, r := range kk {\n\t\t\t\t// \"Inline\" isBareKeyChar\n\t\t\t\tif !((r >= 'A' && r <= 'Z') || (r >= 'a' && r <= 'z') || (r >= '0' && r <= '9') || r == '_' || r == '-') {\n\t\t\t\t\tb.WriteByte('\"')\n\t\t\t\t\tb.WriteString(dblQuotedReplacer.Replace(kk))\n\t\t\t\t\tb.WriteByte('\"')\n\t\t\t\t\tcontinue outer\n\t\t\t\t}\n\t\t\t}\n\t\t\tb.WriteString(kk)\n\t\t}\n\t}\n\treturn b.String()\n}\n\nfunc (k Key) maybeQuoted(i int) string {\n\tif k[i] == \"\" {\n\t\treturn `\"\"`\n\t}\n\tfor _, r := range k[i] {\n\t\tif (r >= 'A' && r <= 'Z') || (r >= 'a' && r <= 'z') || (r >= '0' && r <= '9') || r == '_' || r == '-' {\n\t\t\tcontinue\n\t\t}\n\t\treturn `\"` + dblQuotedReplacer.Replace(k[i]) + `\"`\n\t}\n\treturn k[i]\n}\n\n// Like append(), but only increase the cap by 1.\nfunc (k Key) add(piece string) Key {\n\tif cap(k) > len(k) {\n\t\treturn append(k, piece)\n\t}\n\tnewKey := make(Key, len(k)+1)\n\tcopy(newKey, k)\n\tnewKey[len(k)] = piece\n\treturn newKey\n}\n\nfunc (k Key) parent() Key  { return k[:len(k)-1] } // all except the last piece.\nfunc (k Key) last() string { return k[len(k)-1] }  // last piece of this key.\n"
        },
        {
          "name": "ossfuzz",
          "type": "tree",
          "content": null
        },
        {
          "name": "parse.go",
          "type": "blob",
          "size": 21.8955078125,
          "content": "package toml\n\nimport (\n\t\"fmt\"\n\t\"math\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\t\"unicode/utf8\"\n\n\t\"github.com/BurntSushi/toml/internal\"\n)\n\ntype parser struct {\n\tlx         *lexer\n\tcontext    Key      // Full key for the current hash in scope.\n\tcurrentKey string   // Base key name for everything except hashes.\n\tpos        Position // Current position in the TOML file.\n\ttomlNext   bool\n\n\tordered []Key // List of keys in the order that they appear in the TOML data.\n\n\tkeyInfo   map[string]keyInfo  // Map keyname  info about the TOML key.\n\tmapping   map[string]any      // Map keyname  key value.\n\timplicits map[string]struct{} // Record implicit keys (e.g. \"key.group.names\").\n}\n\ntype keyInfo struct {\n\tpos      Position\n\ttomlType tomlType\n}\n\nfunc parse(data string) (p *parser, err error) {\n\t_, tomlNext := os.LookupEnv(\"BURNTSUSHI_TOML_110\")\n\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tif pErr, ok := r.(ParseError); ok {\n\t\t\t\tpErr.input = data\n\t\t\t\terr = pErr\n\t\t\t\treturn\n\t\t\t}\n\t\t\tpanic(r)\n\t\t}\n\t}()\n\n\t// Read over BOM; do this here as the lexer calls utf8.DecodeRuneInString()\n\t// which mangles stuff. UTF-16 BOM isn't strictly valid, but some tools add\n\t// it anyway.\n\tif strings.HasPrefix(data, \"\\xff\\xfe\") || strings.HasPrefix(data, \"\\xfe\\xff\") { // UTF-16\n\t\tdata = data[2:]\n\t\t//lint:ignore S1017 https://github.com/dominikh/go-tools/issues/1447\n\t} else if strings.HasPrefix(data, \"\\xef\\xbb\\xbf\") { // UTF-8\n\t\tdata = data[3:]\n\t}\n\n\t// Examine first few bytes for NULL bytes; this probably means it's a UTF-16\n\t// file (second byte in surrogate pair being NULL). Again, do this here to\n\t// avoid having to deal with UTF-8/16 stuff in the lexer.\n\tex := 6\n\tif len(data) < 6 {\n\t\tex = len(data)\n\t}\n\tif i := strings.IndexRune(data[:ex], 0); i > -1 {\n\t\treturn nil, ParseError{\n\t\t\tMessage:  \"files cannot contain NULL bytes; probably using UTF-16; TOML files must be UTF-8\",\n\t\t\tPosition: Position{Line: 1, Col: 1, Start: i, Len: 1},\n\t\t\tLine:     1,\n\t\t\tinput:    data,\n\t\t}\n\t}\n\n\tp = &parser{\n\t\tkeyInfo:   make(map[string]keyInfo),\n\t\tmapping:   make(map[string]any),\n\t\tlx:        lex(data, tomlNext),\n\t\tordered:   make([]Key, 0),\n\t\timplicits: make(map[string]struct{}),\n\t\ttomlNext:  tomlNext,\n\t}\n\tfor {\n\t\titem := p.next()\n\t\tif item.typ == itemEOF {\n\t\t\tbreak\n\t\t}\n\t\tp.topLevel(item)\n\t}\n\n\treturn p, nil\n}\n\nfunc (p *parser) panicErr(it item, err error) {\n\tpanic(ParseError{\n\t\tMessage:  err.Error(),\n\t\terr:      err,\n\t\tPosition: it.pos.withCol(p.lx.input),\n\t\tLine:     it.pos.Len,\n\t\tLastKey:  p.current(),\n\t})\n}\n\nfunc (p *parser) panicItemf(it item, format string, v ...any) {\n\tpanic(ParseError{\n\t\tMessage:  fmt.Sprintf(format, v...),\n\t\tPosition: it.pos.withCol(p.lx.input),\n\t\tLine:     it.pos.Len,\n\t\tLastKey:  p.current(),\n\t})\n}\n\nfunc (p *parser) panicf(format string, v ...any) {\n\tpanic(ParseError{\n\t\tMessage:  fmt.Sprintf(format, v...),\n\t\tPosition: p.pos.withCol(p.lx.input),\n\t\tLine:     p.pos.Line,\n\t\tLastKey:  p.current(),\n\t})\n}\n\nfunc (p *parser) next() item {\n\tit := p.lx.nextItem()\n\t//fmt.Printf(\"ITEM %-18s line %-3d  %q\\n\", it.typ, it.pos.Line, it.val)\n\tif it.typ == itemError {\n\t\tif it.err != nil {\n\t\t\tpanic(ParseError{\n\t\t\t\tMessage:  it.err.Error(),\n\t\t\t\terr:      it.err,\n\t\t\t\tPosition: it.pos.withCol(p.lx.input),\n\t\t\t\tLine:     it.pos.Line,\n\t\t\t\tLastKey:  p.current(),\n\t\t\t})\n\t\t}\n\n\t\tp.panicItemf(it, \"%s\", it.val)\n\t}\n\treturn it\n}\n\nfunc (p *parser) nextPos() item {\n\tit := p.next()\n\tp.pos = it.pos\n\treturn it\n}\n\nfunc (p *parser) bug(format string, v ...any) {\n\tpanic(fmt.Sprintf(\"BUG: \"+format+\"\\n\\n\", v...))\n}\n\nfunc (p *parser) expect(typ itemType) item {\n\tit := p.next()\n\tp.assertEqual(typ, it.typ)\n\treturn it\n}\n\nfunc (p *parser) assertEqual(expected, got itemType) {\n\tif expected != got {\n\t\tp.bug(\"Expected '%s' but got '%s'.\", expected, got)\n\t}\n}\n\nfunc (p *parser) topLevel(item item) {\n\tswitch item.typ {\n\tcase itemCommentStart: // # ..\n\t\tp.expect(itemText)\n\tcase itemTableStart: // [ .. ]\n\t\tname := p.nextPos()\n\n\t\tvar key Key\n\t\tfor ; name.typ != itemTableEnd && name.typ != itemEOF; name = p.next() {\n\t\t\tkey = append(key, p.keyString(name))\n\t\t}\n\t\tp.assertEqual(itemTableEnd, name.typ)\n\n\t\tp.addContext(key, false)\n\t\tp.setType(\"\", tomlHash, item.pos)\n\t\tp.ordered = append(p.ordered, key)\n\tcase itemArrayTableStart: // [[ .. ]]\n\t\tname := p.nextPos()\n\n\t\tvar key Key\n\t\tfor ; name.typ != itemArrayTableEnd && name.typ != itemEOF; name = p.next() {\n\t\t\tkey = append(key, p.keyString(name))\n\t\t}\n\t\tp.assertEqual(itemArrayTableEnd, name.typ)\n\n\t\tp.addContext(key, true)\n\t\tp.setType(\"\", tomlArrayHash, item.pos)\n\t\tp.ordered = append(p.ordered, key)\n\tcase itemKeyStart: // key = ..\n\t\touterContext := p.context\n\t\t/// Read all the key parts (e.g. 'a' and 'b' in 'a.b')\n\t\tk := p.nextPos()\n\t\tvar key Key\n\t\tfor ; k.typ != itemKeyEnd && k.typ != itemEOF; k = p.next() {\n\t\t\tkey = append(key, p.keyString(k))\n\t\t}\n\t\tp.assertEqual(itemKeyEnd, k.typ)\n\n\t\t/// The current key is the last part.\n\t\tp.currentKey = key.last()\n\n\t\t/// All the other parts (if any) are the context; need to set each part\n\t\t/// as implicit.\n\t\tcontext := key.parent()\n\t\tfor i := range context {\n\t\t\tp.addImplicitContext(append(p.context, context[i:i+1]...))\n\t\t}\n\t\tp.ordered = append(p.ordered, p.context.add(p.currentKey))\n\n\t\t/// Set value.\n\t\tvItem := p.next()\n\t\tval, typ := p.value(vItem, false)\n\t\tp.setValue(p.currentKey, val)\n\t\tp.setType(p.currentKey, typ, vItem.pos)\n\n\t\t/// Remove the context we added (preserving any context from [tbl] lines).\n\t\tp.context = outerContext\n\t\tp.currentKey = \"\"\n\tdefault:\n\t\tp.bug(\"Unexpected type at top level: %s\", item.typ)\n\t}\n}\n\n// Gets a string for a key (or part of a key in a table name).\nfunc (p *parser) keyString(it item) string {\n\tswitch it.typ {\n\tcase itemText:\n\t\treturn it.val\n\tcase itemString, itemStringEsc, itemMultilineString,\n\t\titemRawString, itemRawMultilineString:\n\t\ts, _ := p.value(it, false)\n\t\treturn s.(string)\n\tdefault:\n\t\tp.bug(\"Unexpected key type: %s\", it.typ)\n\t}\n\tpanic(\"unreachable\")\n}\n\nvar datetimeRepl = strings.NewReplacer(\n\t\"z\", \"Z\",\n\t\"t\", \"T\",\n\t\" \", \"T\")\n\n// value translates an expected value from the lexer into a Go value wrapped\n// as an empty interface.\nfunc (p *parser) value(it item, parentIsArray bool) (any, tomlType) {\n\tswitch it.typ {\n\tcase itemString:\n\t\treturn it.val, p.typeOfPrimitive(it)\n\tcase itemStringEsc:\n\t\treturn p.replaceEscapes(it, it.val), p.typeOfPrimitive(it)\n\tcase itemMultilineString:\n\t\treturn p.replaceEscapes(it, p.stripEscapedNewlines(stripFirstNewline(it.val))), p.typeOfPrimitive(it)\n\tcase itemRawString:\n\t\treturn it.val, p.typeOfPrimitive(it)\n\tcase itemRawMultilineString:\n\t\treturn stripFirstNewline(it.val), p.typeOfPrimitive(it)\n\tcase itemInteger:\n\t\treturn p.valueInteger(it)\n\tcase itemFloat:\n\t\treturn p.valueFloat(it)\n\tcase itemBool:\n\t\tswitch it.val {\n\t\tcase \"true\":\n\t\t\treturn true, p.typeOfPrimitive(it)\n\t\tcase \"false\":\n\t\t\treturn false, p.typeOfPrimitive(it)\n\t\tdefault:\n\t\t\tp.bug(\"Expected boolean value, but got '%s'.\", it.val)\n\t\t}\n\tcase itemDatetime:\n\t\treturn p.valueDatetime(it)\n\tcase itemArray:\n\t\treturn p.valueArray(it)\n\tcase itemInlineTableStart:\n\t\treturn p.valueInlineTable(it, parentIsArray)\n\tdefault:\n\t\tp.bug(\"Unexpected value type: %s\", it.typ)\n\t}\n\tpanic(\"unreachable\")\n}\n\nfunc (p *parser) valueInteger(it item) (any, tomlType) {\n\tif !numUnderscoresOK(it.val) {\n\t\tp.panicItemf(it, \"Invalid integer %q: underscores must be surrounded by digits\", it.val)\n\t}\n\tif numHasLeadingZero(it.val) {\n\t\tp.panicItemf(it, \"Invalid integer %q: cannot have leading zeroes\", it.val)\n\t}\n\n\tnum, err := strconv.ParseInt(it.val, 0, 64)\n\tif err != nil {\n\t\t// Distinguish integer values. Normally, it'd be a bug if the lexer\n\t\t// provides an invalid integer, but it's possible that the number is\n\t\t// out of range of valid values (which the lexer cannot determine).\n\t\t// So mark the former as a bug but the latter as a legitimate user\n\t\t// error.\n\t\tif e, ok := err.(*strconv.NumError); ok && e.Err == strconv.ErrRange {\n\t\t\tp.panicErr(it, errParseRange{i: it.val, size: \"int64\"})\n\t\t} else {\n\t\t\tp.bug(\"Expected integer value, but got '%s'.\", it.val)\n\t\t}\n\t}\n\treturn num, p.typeOfPrimitive(it)\n}\n\nfunc (p *parser) valueFloat(it item) (any, tomlType) {\n\tparts := strings.FieldsFunc(it.val, func(r rune) bool {\n\t\tswitch r {\n\t\tcase '.', 'e', 'E':\n\t\t\treturn true\n\t\t}\n\t\treturn false\n\t})\n\tfor _, part := range parts {\n\t\tif !numUnderscoresOK(part) {\n\t\t\tp.panicItemf(it, \"Invalid float %q: underscores must be surrounded by digits\", it.val)\n\t\t}\n\t}\n\tif len(parts) > 0 && numHasLeadingZero(parts[0]) {\n\t\tp.panicItemf(it, \"Invalid float %q: cannot have leading zeroes\", it.val)\n\t}\n\tif !numPeriodsOK(it.val) {\n\t\t// As a special case, numbers like '123.' or '1.e2',\n\t\t// which are valid as far as Go/strconv are concerned,\n\t\t// must be rejected because TOML says that a fractional\n\t\t// part consists of '.' followed by 1+ digits.\n\t\tp.panicItemf(it, \"Invalid float %q: '.' must be followed by one or more digits\", it.val)\n\t}\n\tval := strings.Replace(it.val, \"_\", \"\", -1)\n\tsignbit := false\n\tif val == \"+nan\" || val == \"-nan\" {\n\t\tsignbit = val == \"-nan\"\n\t\tval = \"nan\"\n\t}\n\tnum, err := strconv.ParseFloat(val, 64)\n\tif err != nil {\n\t\tif e, ok := err.(*strconv.NumError); ok && e.Err == strconv.ErrRange {\n\t\t\tp.panicErr(it, errParseRange{i: it.val, size: \"float64\"})\n\t\t} else {\n\t\t\tp.panicItemf(it, \"Invalid float value: %q\", it.val)\n\t\t}\n\t}\n\tif signbit {\n\t\tnum = math.Copysign(num, -1)\n\t}\n\treturn num, p.typeOfPrimitive(it)\n}\n\nvar dtTypes = []struct {\n\tfmt  string\n\tzone *time.Location\n\tnext bool\n}{\n\t{time.RFC3339Nano, time.Local, false},\n\t{\"2006-01-02T15:04:05.999999999\", internal.LocalDatetime, false},\n\t{\"2006-01-02\", internal.LocalDate, false},\n\t{\"15:04:05.999999999\", internal.LocalTime, false},\n\n\t// tomlNext\n\t{\"2006-01-02T15:04Z07:00\", time.Local, true},\n\t{\"2006-01-02T15:04\", internal.LocalDatetime, true},\n\t{\"15:04\", internal.LocalTime, true},\n}\n\nfunc (p *parser) valueDatetime(it item) (any, tomlType) {\n\tit.val = datetimeRepl.Replace(it.val)\n\tvar (\n\t\tt   time.Time\n\t\tok  bool\n\t\terr error\n\t)\n\tfor _, dt := range dtTypes {\n\t\tif dt.next && !p.tomlNext {\n\t\t\tcontinue\n\t\t}\n\t\tt, err = time.ParseInLocation(dt.fmt, it.val, dt.zone)\n\t\tif err == nil {\n\t\t\tif missingLeadingZero(it.val, dt.fmt) {\n\t\t\t\tp.panicErr(it, errParseDate{it.val})\n\t\t\t}\n\t\t\tok = true\n\t\t\tbreak\n\t\t}\n\t}\n\tif !ok {\n\t\tp.panicErr(it, errParseDate{it.val})\n\t}\n\treturn t, p.typeOfPrimitive(it)\n}\n\n// Go's time.Parse() will accept numbers without a leading zero; there isn't any\n// way to require it. https://github.com/golang/go/issues/29911\n//\n// Depend on the fact that the separators (- and :) should always be at the same\n// location.\nfunc missingLeadingZero(d, l string) bool {\n\tfor i, c := range []byte(l) {\n\t\tif c == '.' || c == 'Z' {\n\t\t\treturn false\n\t\t}\n\t\tif (c < '0' || c > '9') && d[i] != c {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (p *parser) valueArray(it item) (any, tomlType) {\n\tp.setType(p.currentKey, tomlArray, it.pos)\n\n\tvar (\n\t\t// Initialize to a non-nil slice to make it consistent with how S = []\n\t\t// decodes into a non-nil slice inside something like struct { S\n\t\t// []string }. See #338\n\t\tarray = make([]any, 0, 2)\n\t)\n\tfor it = p.next(); it.typ != itemArrayEnd; it = p.next() {\n\t\tif it.typ == itemCommentStart {\n\t\t\tp.expect(itemText)\n\t\t\tcontinue\n\t\t}\n\n\t\tval, typ := p.value(it, true)\n\t\tarray = append(array, val)\n\n\t\t// XXX: type isn't used here, we need it to record the accurate type\n\t\t// information.\n\t\t//\n\t\t// Not entirely sure how to best store this; could use \"key[0]\",\n\t\t// \"key[1]\" notation, or maybe store it on the Array type?\n\t\t_ = typ\n\t}\n\treturn array, tomlArray\n}\n\nfunc (p *parser) valueInlineTable(it item, parentIsArray bool) (any, tomlType) {\n\tvar (\n\t\ttopHash      = make(map[string]any)\n\t\touterContext = p.context\n\t\touterKey     = p.currentKey\n\t)\n\n\tp.context = append(p.context, p.currentKey)\n\tprevContext := p.context\n\tp.currentKey = \"\"\n\n\tp.addImplicit(p.context)\n\tp.addContext(p.context, parentIsArray)\n\n\t/// Loop over all table key/value pairs.\n\tfor it := p.next(); it.typ != itemInlineTableEnd; it = p.next() {\n\t\tif it.typ == itemCommentStart {\n\t\t\tp.expect(itemText)\n\t\t\tcontinue\n\t\t}\n\n\t\t/// Read all key parts.\n\t\tk := p.nextPos()\n\t\tvar key Key\n\t\tfor ; k.typ != itemKeyEnd && k.typ != itemEOF; k = p.next() {\n\t\t\tkey = append(key, p.keyString(k))\n\t\t}\n\t\tp.assertEqual(itemKeyEnd, k.typ)\n\n\t\t/// The current key is the last part.\n\t\tp.currentKey = key.last()\n\n\t\t/// All the other parts (if any) are the context; need to set each part\n\t\t/// as implicit.\n\t\tcontext := key.parent()\n\t\tfor i := range context {\n\t\t\tp.addImplicitContext(append(p.context, context[i:i+1]...))\n\t\t}\n\t\tp.ordered = append(p.ordered, p.context.add(p.currentKey))\n\n\t\t/// Set the value.\n\t\tval, typ := p.value(p.next(), false)\n\t\tp.setValue(p.currentKey, val)\n\t\tp.setType(p.currentKey, typ, it.pos)\n\n\t\thash := topHash\n\t\tfor _, c := range context {\n\t\t\th, ok := hash[c]\n\t\t\tif !ok {\n\t\t\t\th = make(map[string]any)\n\t\t\t\thash[c] = h\n\t\t\t}\n\t\t\thash, ok = h.(map[string]any)\n\t\t\tif !ok {\n\t\t\t\tp.panicf(\"%q is not a table\", p.context)\n\t\t\t}\n\t\t}\n\t\thash[p.currentKey] = val\n\n\t\t/// Restore context.\n\t\tp.context = prevContext\n\t}\n\tp.context = outerContext\n\tp.currentKey = outerKey\n\treturn topHash, tomlHash\n}\n\n// numHasLeadingZero checks if this number has leading zeroes, allowing for '0',\n// +/- signs, and base prefixes.\nfunc numHasLeadingZero(s string) bool {\n\tif len(s) > 1 && s[0] == '0' && !(s[1] == 'b' || s[1] == 'o' || s[1] == 'x') { // Allow 0b, 0o, 0x\n\t\treturn true\n\t}\n\tif len(s) > 2 && (s[0] == '-' || s[0] == '+') && s[1] == '0' {\n\t\treturn true\n\t}\n\treturn false\n}\n\n// numUnderscoresOK checks whether each underscore in s is surrounded by\n// characters that are not underscores.\nfunc numUnderscoresOK(s string) bool {\n\tswitch s {\n\tcase \"nan\", \"+nan\", \"-nan\", \"inf\", \"-inf\", \"+inf\":\n\t\treturn true\n\t}\n\taccept := false\n\tfor _, r := range s {\n\t\tif r == '_' {\n\t\t\tif !accept {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\n\t\t// isHexis a superset of all the permissable characters surrounding an\n\t\t// underscore.\n\t\taccept = isHex(r)\n\t}\n\treturn accept\n}\n\n// numPeriodsOK checks whether every period in s is followed by a digit.\nfunc numPeriodsOK(s string) bool {\n\tperiod := false\n\tfor _, r := range s {\n\t\tif period && !isDigit(r) {\n\t\t\treturn false\n\t\t}\n\t\tperiod = r == '.'\n\t}\n\treturn !period\n}\n\n// Set the current context of the parser, where the context is either a hash or\n// an array of hashes, depending on the value of the `array` parameter.\n//\n// Establishing the context also makes sure that the key isn't a duplicate, and\n// will create implicit hashes automatically.\nfunc (p *parser) addContext(key Key, array bool) {\n\t/// Always start at the top level and drill down for our context.\n\thashContext := p.mapping\n\tkeyContext := make(Key, 0, len(key)-1)\n\n\t/// We only need implicit hashes for the parents.\n\tfor _, k := range key.parent() {\n\t\t_, ok := hashContext[k]\n\t\tkeyContext = append(keyContext, k)\n\n\t\t// No key? Make an implicit hash and move on.\n\t\tif !ok {\n\t\t\tp.addImplicit(keyContext)\n\t\t\thashContext[k] = make(map[string]any)\n\t\t}\n\n\t\t// If the hash context is actually an array of tables, then set\n\t\t// the hash context to the last element in that array.\n\t\t//\n\t\t// Otherwise, it better be a table, since this MUST be a key group (by\n\t\t// virtue of it not being the last element in a key).\n\t\tswitch t := hashContext[k].(type) {\n\t\tcase []map[string]any:\n\t\t\thashContext = t[len(t)-1]\n\t\tcase map[string]any:\n\t\t\thashContext = t\n\t\tdefault:\n\t\t\tp.panicf(\"Key '%s' was already created as a hash.\", keyContext)\n\t\t}\n\t}\n\n\tp.context = keyContext\n\tif array {\n\t\t// If this is the first element for this array, then allocate a new\n\t\t// list of tables for it.\n\t\tk := key.last()\n\t\tif _, ok := hashContext[k]; !ok {\n\t\t\thashContext[k] = make([]map[string]any, 0, 4)\n\t\t}\n\n\t\t// Add a new table. But make sure the key hasn't already been used\n\t\t// for something else.\n\t\tif hash, ok := hashContext[k].([]map[string]any); ok {\n\t\t\thashContext[k] = append(hash, make(map[string]any))\n\t\t} else {\n\t\t\tp.panicf(\"Key '%s' was already created and cannot be used as an array.\", key)\n\t\t}\n\t} else {\n\t\tp.setValue(key.last(), make(map[string]any))\n\t}\n\tp.context = append(p.context, key.last())\n}\n\n// setValue sets the given key to the given value in the current context.\n// It will make sure that the key hasn't already been defined, account for\n// implicit key groups.\nfunc (p *parser) setValue(key string, value any) {\n\tvar (\n\t\ttmpHash    any\n\t\tok         bool\n\t\thash       = p.mapping\n\t\tkeyContext = make(Key, 0, len(p.context)+1)\n\t)\n\tfor _, k := range p.context {\n\t\tkeyContext = append(keyContext, k)\n\t\tif tmpHash, ok = hash[k]; !ok {\n\t\t\tp.bug(\"Context for key '%s' has not been established.\", keyContext)\n\t\t}\n\t\tswitch t := tmpHash.(type) {\n\t\tcase []map[string]any:\n\t\t\t// The context is a table of hashes. Pick the most recent table\n\t\t\t// defined as the current hash.\n\t\t\thash = t[len(t)-1]\n\t\tcase map[string]any:\n\t\t\thash = t\n\t\tdefault:\n\t\t\tp.panicf(\"Key '%s' has already been defined.\", keyContext)\n\t\t}\n\t}\n\tkeyContext = append(keyContext, key)\n\n\tif _, ok := hash[key]; ok {\n\t\t// Normally redefining keys isn't allowed, but the key could have been\n\t\t// defined implicitly and it's allowed to be redefined concretely. (See\n\t\t// the `valid/implicit-and-explicit-after.toml` in toml-test)\n\t\t//\n\t\t// But we have to make sure to stop marking it as an implicit. (So that\n\t\t// another redefinition provokes an error.)\n\t\t//\n\t\t// Note that since it has already been defined (as a hash), we don't\n\t\t// want to overwrite it. So our business is done.\n\t\tif p.isArray(keyContext) {\n\t\t\tp.removeImplicit(keyContext)\n\t\t\thash[key] = value\n\t\t\treturn\n\t\t}\n\t\tif p.isImplicit(keyContext) {\n\t\t\tp.removeImplicit(keyContext)\n\t\t\treturn\n\t\t}\n\t\t// Otherwise, we have a concrete key trying to override a previous key,\n\t\t// which is *always* wrong.\n\t\tp.panicf(\"Key '%s' has already been defined.\", keyContext)\n\t}\n\n\thash[key] = value\n}\n\n// setType sets the type of a particular value at a given key. It should be\n// called immediately AFTER setValue.\n//\n// Note that if `key` is empty, then the type given will be applied to the\n// current context (which is either a table or an array of tables).\nfunc (p *parser) setType(key string, typ tomlType, pos Position) {\n\tkeyContext := make(Key, 0, len(p.context)+1)\n\tkeyContext = append(keyContext, p.context...)\n\tif len(key) > 0 { // allow type setting for hashes\n\t\tkeyContext = append(keyContext, key)\n\t}\n\t// Special case to make empty keys (\"\" = 1) work.\n\t// Without it it will set \"\" rather than `\"\"`.\n\t// TODO: why is this needed? And why is this only needed here?\n\tif len(keyContext) == 0 {\n\t\tkeyContext = Key{\"\"}\n\t}\n\tp.keyInfo[keyContext.String()] = keyInfo{tomlType: typ, pos: pos}\n}\n\n// Implicit keys need to be created when tables are implied in \"a.b.c.d = 1\" and\n// \"[a.b.c]\" (the \"a\", \"b\", and \"c\" hashes are never created explicitly).\nfunc (p *parser) addImplicit(key Key)        { p.implicits[key.String()] = struct{}{} }\nfunc (p *parser) removeImplicit(key Key)     { delete(p.implicits, key.String()) }\nfunc (p *parser) isImplicit(key Key) bool    { _, ok := p.implicits[key.String()]; return ok }\nfunc (p *parser) isArray(key Key) bool       { return p.keyInfo[key.String()].tomlType == tomlArray }\nfunc (p *parser) addImplicitContext(key Key) { p.addImplicit(key); p.addContext(key, false) }\n\n// current returns the full key name of the current context.\nfunc (p *parser) current() string {\n\tif len(p.currentKey) == 0 {\n\t\treturn p.context.String()\n\t}\n\tif len(p.context) == 0 {\n\t\treturn p.currentKey\n\t}\n\treturn fmt.Sprintf(\"%s.%s\", p.context, p.currentKey)\n}\n\nfunc stripFirstNewline(s string) string {\n\tif len(s) > 0 && s[0] == '\\n' {\n\t\treturn s[1:]\n\t}\n\tif len(s) > 1 && s[0] == '\\r' && s[1] == '\\n' {\n\t\treturn s[2:]\n\t}\n\treturn s\n}\n\n// stripEscapedNewlines removes whitespace after line-ending backslashes in\n// multiline strings.\n//\n// A line-ending backslash is an unescaped \\ followed only by whitespace until\n// the next newline. After a line-ending backslash, all whitespace is removed\n// until the next non-whitespace character.\nfunc (p *parser) stripEscapedNewlines(s string) string {\n\tvar (\n\t\tb strings.Builder\n\t\ti int\n\t)\n\tb.Grow(len(s))\n\tfor {\n\t\tix := strings.Index(s[i:], `\\`)\n\t\tif ix < 0 {\n\t\t\tb.WriteString(s)\n\t\t\treturn b.String()\n\t\t}\n\t\ti += ix\n\n\t\tif len(s) > i+1 && s[i+1] == '\\\\' {\n\t\t\t// Escaped backslash.\n\t\t\ti += 2\n\t\t\tcontinue\n\t\t}\n\t\t// Scan until the next non-whitespace.\n\t\tj := i + 1\n\twhitespaceLoop:\n\t\tfor ; j < len(s); j++ {\n\t\t\tswitch s[j] {\n\t\t\tcase ' ', '\\t', '\\r', '\\n':\n\t\t\tdefault:\n\t\t\t\tbreak whitespaceLoop\n\t\t\t}\n\t\t}\n\t\tif j == i+1 {\n\t\t\t// Not a whitespace escape.\n\t\t\ti++\n\t\t\tcontinue\n\t\t}\n\t\tif !strings.Contains(s[i:j], \"\\n\") {\n\t\t\t// This is not a line-ending backslash. (It's a bad escape sequence,\n\t\t\t// but we can let replaceEscapes catch it.)\n\t\t\ti++\n\t\t\tcontinue\n\t\t}\n\t\tb.WriteString(s[:i])\n\t\ts = s[j:]\n\t\ti = 0\n\t}\n}\n\nfunc (p *parser) replaceEscapes(it item, str string) string {\n\tvar (\n\t\tb    strings.Builder\n\t\tskip = 0\n\t)\n\tb.Grow(len(str))\n\tfor i, c := range str {\n\t\tif skip > 0 {\n\t\t\tskip--\n\t\t\tcontinue\n\t\t}\n\t\tif c != '\\\\' {\n\t\t\tb.WriteRune(c)\n\t\t\tcontinue\n\t\t}\n\n\t\tif i >= len(str) {\n\t\t\tp.bug(\"Escape sequence at end of string.\")\n\t\t\treturn \"\"\n\t\t}\n\t\tswitch str[i+1] {\n\t\tdefault:\n\t\t\tp.bug(\"Expected valid escape code after \\\\, but got %q.\", str[i+1])\n\t\tcase ' ', '\\t':\n\t\t\tp.panicItemf(it, \"invalid escape: '\\\\%c'\", str[i+1])\n\t\tcase 'b':\n\t\t\tb.WriteByte(0x08)\n\t\t\tskip = 1\n\t\tcase 't':\n\t\t\tb.WriteByte(0x09)\n\t\t\tskip = 1\n\t\tcase 'n':\n\t\t\tb.WriteByte(0x0a)\n\t\t\tskip = 1\n\t\tcase 'f':\n\t\t\tb.WriteByte(0x0c)\n\t\t\tskip = 1\n\t\tcase 'r':\n\t\t\tb.WriteByte(0x0d)\n\t\t\tskip = 1\n\t\tcase 'e':\n\t\t\tif p.tomlNext {\n\t\t\t\tb.WriteByte(0x1b)\n\t\t\t\tskip = 1\n\t\t\t}\n\t\tcase '\"':\n\t\t\tb.WriteByte(0x22)\n\t\t\tskip = 1\n\t\tcase '\\\\':\n\t\t\tb.WriteByte(0x5c)\n\t\t\tskip = 1\n\t\t// The lexer guarantees the correct number of characters are present;\n\t\t// don't need to check here.\n\t\tcase 'x':\n\t\t\tif p.tomlNext {\n\t\t\t\tescaped := p.asciiEscapeToUnicode(it, str[i+2:i+4])\n\t\t\t\tb.WriteRune(escaped)\n\t\t\t\tskip = 3\n\t\t\t}\n\t\tcase 'u':\n\t\t\tescaped := p.asciiEscapeToUnicode(it, str[i+2:i+6])\n\t\t\tb.WriteRune(escaped)\n\t\t\tskip = 5\n\t\tcase 'U':\n\t\t\tescaped := p.asciiEscapeToUnicode(it, str[i+2:i+10])\n\t\t\tb.WriteRune(escaped)\n\t\t\tskip = 9\n\t\t}\n\t}\n\treturn b.String()\n}\n\nfunc (p *parser) asciiEscapeToUnicode(it item, s string) rune {\n\thex, err := strconv.ParseUint(strings.ToLower(s), 16, 32)\n\tif err != nil {\n\t\tp.bug(\"Could not parse '%s' as a hexadecimal number, but the lexer claims it's OK: %s\", s, err)\n\t}\n\tif !utf8.ValidRune(rune(hex)) {\n\t\tp.panicItemf(it, \"Escaped character '\\\\u%s' is not valid UTF-8.\", s)\n\t}\n\treturn rune(hex)\n}\n"
        },
        {
          "name": "testdata",
          "type": "tree",
          "content": null
        },
        {
          "name": "toml_test.go",
          "type": "blob",
          "size": 12.6025390625,
          "content": "package toml_test\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/BurntSushi/toml\"\n\t\"github.com/BurntSushi/toml/internal/tag\"\n\ttomltest \"github.com/BurntSushi/toml/internal/toml-test\"\n)\n\n// Test if the error message matches what we want for invalid tests. Every slice\n// entry is tested with strings.Contains.\n//\n// Filepaths are glob'd\nvar errorTests = map[string][]string{\n\t\"encoding/bad-utf8*\":            {\"invalid UTF-8 byte\"},\n\t\"encoding/utf16*\":               {\"files cannot contain NULL bytes; probably using UTF-16\"},\n\t\"string/multiline-bad-escape-2\": {`invalid escape: '\\ '`},\n}\n\n// Test metadata; all keys listed as \"keyname: type\".\nvar metaTests = map[string]string{\n\t\"implicit-and-explicit-after\": `\n\t\ta.b.c:         Hash\n\t\ta.b.c.answer:  Integer\n\t\ta:             Hash\n\t\ta.better:      Integer\n\t`,\n\t\"implicit-and-explicit-before\": `\n\t\ta:             Hash\n\t\ta.better:      Integer\n\t\ta.b.c:         Hash\n\t\ta.b.c.answer:  Integer\n\t`,\n\t\"key/case-sensitive\": `\n\t\tsectioN:       String\n\t\tsection:       Hash\n\t\tsection.name:  String\n\t\tsection.NAME:  String\n\t\tsection.Name:  String\n\t\tSection:       Hash\n\t\tSection.name:  String\n\t\tSection.\"\":   String\n\t\tSection.\"\":   String\n\t\tSection.M:     String\n\t`,\n\t\"key/dotted-1\": `\n\t\tname.first:            String\n\t\tname.last:             String\n\t\tmany.dots.dot.dot.dot: Integer\n\t`,\n\t\"key/dotted-2\": `\n\t\tcount.a: Integer\n\t\tcount.b: Integer\n\t\tcount.c: Integer\n\t\tcount.d: Integer\n\t\tcount.e: Integer\n\t\tcount.f: Integer\n\t\tcount.g: Integer\n\t\tcount.h: Integer\n\t\tcount.i: Integer\n\t\tcount.j: Integer\n\t\tcount.k: Integer\n\t\tcount.l: Integer\n\t`,\n\t\"key/dotted-3\": `\n\t\ttop.key:     Integer\n\t\ttbl:         Hash\n\t\ttbl.a.b.c:   Float\n\t\ta.few.dots:                   Hash\n\t\ta.few.dots.polka.dot:         String\n\t\ta.few.dots.polka.dance-with:  String\n\t`,\n\t\"key/dotted-4\": `\n\t\ttop.key:     Integer\n\t\tarr:         ArrayHash\n\t\tarr.a.b.c:   Integer\n\t\tarr.a.b.d:   Integer\n\t\tarr:         ArrayHash\n\t\tarr.a.b.c:   Integer\n\t\tarr.a.b.d:   Integer\n\t `,\n\t\"key/empty-1\": `\n\t\t\"\": String\n\t`,\n\t\"key/quoted-dots\": `\n\t\tplain:                          Integer\n\t\t\"with.dot\":                     Integer\n\t\tplain_table:                    Hash\n\t\tplain_table.plain:              Integer\n\t\tplain_table.\"with.dot\":         Integer\n\t\ttable.withdot:                  Hash\n\t\ttable.withdot.plain:            Integer\n\t\ttable.withdot.\"key.with.dots\":  Integer\n\t`,\n\t\"key/space\": `\n\t\t\"a b\": Integer\n\t\t\" c d \": Integer\n\t\t\" tbl \": Hash\n\t\t\" tbl \".\"\\ttab\\ttab\\t\": String\n\t`,\n\t\"key/special-chars\": \"\\n\" +\n\t\t\"\\\"=~!@$^&*()_+-`1234567890[]|/?><.,;:'=\\\": Integer\\n\",\n\n\t// TODO: \"(albums): Hash\" is missing; the problem is that this is an\n\t// \"implied key\", which is recorded in the parser in implicits, rather than\n\t// in keys. This is to allow \"redefining\" tables, for example:\n\t//\n\t//    [a.b.c]\n\t//    answer = 42\n\t//    [a]\n\t//    better = 43\n\t//\n\t// However, we need to actually pass on this information to the MetaData so\n\t// we can use it.\n\t//\n\t// Keys are supposed to be in order, for the above right now that's:\n\t//\n\t//     (a).(b).(c):           Hash\n\t//     (a).(b).(c).(answer):  Integer\n\t//     (a):                   Hash\n\t//     (a).(better):          Integer\n\t//\n\t// So if we want to add \"(a).(b): Hash\", where should this be in the order?\n\t\"table/array-implicit\": `\n\t\talbums.songs:       ArrayHash\n\t\talbums.songs.name:  String\n\t`,\n\n\t// TODO: people and people.* listed many times; not entirely sure if that's\n\t// what we want?\n\t//\n\t// It certainly causes problems, because keys is a slice, and types a map.\n\t// So if array entry 1 differs in type from array entry 2 then that won't be\n\t// recorded right. This related to the problem in the above comment.\n\t//\n\t// people:                ArrayHash\n\t//\n\t// people[0]:             Hash\n\t// people[0].first_name:  String\n\t// people[0].last_name:   String\n\t//\n\t// people[1]:             Hash\n\t// people[1].first_name:  String\n\t// people[1].last_name:   String\n\t//\n\t// people[2]:             Hash\n\t// people[2].first_name:  String\n\t// people[2].last_name:   String\n\t\"table/array-many\": `\n\t\tpeople:             ArrayHash\n\t\tpeople.first_name:  String\n\t\tpeople.last_name:   String\n\t\tpeople:             ArrayHash\n\t\tpeople.first_name:  String\n\t\tpeople.last_name:   String\n\t\tpeople:             ArrayHash\n\t\tpeople.first_name:  String\n\t\tpeople.last_name:   String\n\t`,\n\t\"table/array-nest\": `\n\t\talbums:             ArrayHash\n\t\talbums.name:        String\n\t\talbums.songs:       ArrayHash\n\t\talbums.songs.name:  String\n\t\talbums.songs:       ArrayHash\n\t\talbums.songs.name:  String\n\t\talbums:             ArrayHash\n\t\talbums.name:        String\n\t\talbums.songs:       ArrayHash\n\t\talbums.songs.name:  String\n\t\talbums.songs:       ArrayHash\n\t\talbums.songs.name:  String\n\t`,\n\t\"table/array-one\": `\n\t\tpeople:             ArrayHash\n\t\tpeople.first_name:  String\n\t\tpeople.last_name:   String\n\t`,\n\t\"table/array-table-array\": `\n\t\ta:        ArrayHash\n\t\ta.b:      ArrayHash\n\t\ta.b.c:    Hash\n\t\ta.b.c.d:  String\n\t\ta.b:      ArrayHash\n\t\ta.b.c:    Hash\n\t\ta.b.c.d:  String\n\t`,\n\t\"table/empty\": `\n\t\ta: Hash\n\t`,\n\t\"table/keyword\": `\n\t\ttrue:   Hash\n\t\tfalse:  Hash\n\t\tinf:    Hash\n\t\tnan:    Hash\n\t`,\n\t\"table/names\": `\n\t\ta.b.c:    Hash\n\t\ta.\"b.c\":  Hash\n\t\ta.\"d.e\":  Hash\n\t\ta.\" x \":  Hash\n\t\td.e.f:    Hash\n\t\tg.h.i:    Hash\n\t\tj.\"\".l:  Hash\n\t\tx.1.2:    Hash\n\t`,\n\t\"table/no-eol\": `\n\t\ttable: Hash\n\t`,\n\t\"table/sub-empty\": `\n\t\ta:    Hash\n\t\ta.b:  Hash\n\t`,\n\t\"table/whitespace\": `\n\t\t\"valid key\": Hash\n\t`,\n\t\"table/with-literal-string\": `\n\t\ta:                   Hash\n\t\ta.\"\\\"b\\\"\":           Hash\n\t\ta.\"\\\"b\\\"\".c:         Hash\n\t\ta.\"\\\"b\\\"\".c.answer:  Integer\n\t`,\n\t\"table/with-pound\": `\n\t\t\"key#group\":         Hash\n\t\t\"key#group\".answer:  Integer\n\t`,\n\t\"table/with-single-quotes\": `\n\t\ta:             Hash\n\t\ta.b:           Hash\n\t\ta.b.c:         Hash\n\t\ta.b.c.answer:  Integer\n\t`,\n\t\"table/without-super\": `\n\t\tx.y.z.w:  Hash\n\t\tx:        Hash\n\t`,\n}\n\n// TOML 1.0\nfunc TestToml(t *testing.T) {\n\trunTomlTest(t, false)\n}\n\n// TOML 1.1\nfunc TestTomlNext(t *testing.T) {\n\ttoml.WithTomlNext(func() {\n\t\trunTomlTest(t, true)\n\t})\n}\n\n// Make sure TOML 1.1 fails by default for now.\nfunc TestTomlNextFails(t *testing.T) {\n\trunTomlTest(t, true,\n\t\t\"valid/string/escape-esc\",\n\t\t\"valid/datetime/no-seconds\",\n\t\t\"valid/string/hex-escape\",\n\t\t\"valid/inline-table/newline\")\n}\n\nfunc runTomlTest(t *testing.T, includeNext bool, wantFail ...string) {\n\tfor k := range errorTests { // Make sure patterns are valid.\n\t\t_, err := filepath.Match(k, \"\")\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n\n\t// TODO: bit of a hack to make sure not all test run; without this \"-run=..\"\n\t// will still run alll tests, but just report the errors for the -run value.\n\t// This is annoying in cases where you have some debug printf.\n\t//\n\t// Need to update toml-test a bit to make this easier, but this good enough\n\t// for now.\n\tvar runTests []string\n\tfor _, a := range os.Args {\n\t\tif strings.HasPrefix(a, \"-test.run=TestToml/\") {\n\t\t\ta = strings.TrimPrefix(a, \"-test.run=TestToml/encode/\")\n\t\t\ta = strings.TrimPrefix(a, \"-test.run=TestToml/decode/\")\n\t\t\trunTests = []string{a, a + \"/*\"}\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// Make sure the keys in metaTests and errorTests actually exist; easy to\n\t// make a typo and nothing will get tested.\n\tvar (\n\t\tshouldExistValid   = make(map[string]struct{})\n\t\tshouldExistInvalid = make(map[string]struct{})\n\t)\n\tif len(runTests) == 0 {\n\t\tfor k := range metaTests {\n\t\t\tshouldExistValid[\"valid/\"+k] = struct{}{}\n\t\t}\n\t\tfor k := range errorTests {\n\t\t\tshouldExistInvalid[\"invalid/\"+k] = struct{}{}\n\t\t}\n\t}\n\n\trun := func(t *testing.T, enc bool) {\n\t\tr := tomltest.Runner{\n\t\t\tFiles:    tomltest.EmbeddedTests(),\n\t\t\tEncoder:  enc,\n\t\t\tParser:   parser{},\n\t\t\tRunTests: runTests,\n\t\t\tSkipTests: []string{\n\t\t\t\t// Will be fixed in Go 1.23: https://github.com/BurntSushi/toml/issues/407\n\t\t\t\t\"invalid/datetime/offset-overflow-hour\",\n\t\t\t\t\"invalid/datetime/offset-overflow-minute\",\n\n\t\t\t\t// These tests are fine, just doesn't deal well with empty output.\n\t\t\t\t\"valid/comment/noeol\",\n\t\t\t\t\"valid/comment/nonascii\",\n\n\t\t\t\t// TODO: fix this; we allow appending to tables, but shouldn't.\n\t\t\t\t\"invalid/array/extend-defined-aot\",\n\t\t\t\t\"invalid/inline-table/duplicate-key-3\",\n\t\t\t\t\"invalid/inline-table/overwrite-02\",\n\t\t\t\t\"invalid/inline-table/overwrite-07\",\n\t\t\t\t\"invalid/inline-table/overwrite-08\",\n\t\t\t\t\"invalid/spec/inline-table-2-0\",\n\t\t\t\t\"invalid/spec/table-9-1\",\n\t\t\t\t\"invalid/table/append-to-array-with-dotted-keys\",\n\t\t\t\t\"invalid/table/append-with-dotted-keys-1\",\n\t\t\t\t\"invalid/table/append-with-dotted-keys-2\",\n\t\t\t\t\"invalid/table/duplicate-key-dotted-table\",\n\t\t\t\t\"invalid/table/duplicate-key-dotted-table2\",\n\t\t\t\t\"invalid/table/redefine-2\",\n\t\t\t\t\"invalid/table/redefine-3\",\n\t\t\t},\n\t\t}\n\t\tif includeNext {\n\t\t\tr.Version = \"1.1.0\"\n\t\t}\n\n\t\ttests, err := r.Run()\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\tfailed := make(map[string]struct{})\n\t\tfor _, test := range tests.Tests {\n\t\t\tt.Run(test.Path, func(t *testing.T) {\n\t\t\t\tif test.Failed() {\n\t\t\t\t\tfor _, f := range wantFail {\n\t\t\t\t\t\tif f == test.Path {\n\t\t\t\t\t\t\tfailed[test.Path] = struct{}{}\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tt.Fatalf(\"\\nError:\\n%s\\n\\nInput:\\n%s\\nOutput:\\n%s\\nWant:\\n%s\\n\",\n\t\t\t\t\t\ttest.Failure, test.Input, test.Output, test.Want)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\t// Test error message.\n\t\t\t\tif test.Type() == tomltest.TypeInvalid {\n\t\t\t\t\ttestError(t, test, shouldExistInvalid)\n\t\t\t\t}\n\t\t\t\t// Test metadata\n\t\t\t\tif !enc && test.Type() == tomltest.TypeValid {\n\t\t\t\t\tdelete(shouldExistValid, test.Path)\n\t\t\t\t\ttestMeta(t, test, includeNext)\n\t\t\t\t}\n\t\t\t})\n\t\t}\n\t\tfor _, f := range wantFail {\n\t\t\tif _, ok := failed[f]; !ok {\n\t\t\t\tt.Errorf(\"expected test %q to fail but it didn't\", f)\n\t\t\t}\n\t\t}\n\n\t\tt.Logf(\"  valid: passed %d; failed %d\", tests.PassedValid, tests.FailedValid)\n\t\tt.Logf(\"invalid: passed %d; failed %d\", tests.PassedInvalid, tests.FailedInvalid)\n\t\tt.Logf(\"skipped: %d\", tests.Skipped)\n\t}\n\n\tt.Run(\"decode\", func(t *testing.T) { run(t, false) })\n\tt.Run(\"encode\", func(t *testing.T) { run(t, true) })\n\n\tif len(shouldExistValid) > 0 {\n\t\tvar s []string\n\t\tfor k := range shouldExistValid {\n\t\t\ts = append(s, k)\n\t\t}\n\t\tt.Errorf(\"the following meta tests didn't match any files: %s\", strings.Join(s, \", \"))\n\t}\n\tif len(shouldExistInvalid) > 0 {\n\t\tvar s []string\n\t\tfor k := range shouldExistInvalid {\n\t\t\ts = append(s, k)\n\t\t}\n\t\tt.Errorf(\"the following meta tests didn't match any files: %s\", strings.Join(s, \", \"))\n\t}\n}\n\nvar reCollapseSpace = regexp.MustCompile(` +`)\n\nfunc testMeta(t *testing.T, test tomltest.Test, includeNext bool) {\n\twant, ok := metaTests[strings.TrimPrefix(test.Path, \"valid/\")]\n\tif !ok {\n\t\treturn\n\t}\n\n\t// Output is slightly different due to different quoting; just skip for now.\n\tif includeNext && (test.Path == \"valid/table/names\" || test.Path == \"valid/key/case-sensitive\") {\n\t\treturn\n\t}\n\n\tvar s any\n\tmeta, err := toml.Decode(test.Input, &s)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tb := new(strings.Builder)\n\tfor i, k := range meta.Keys() {\n\t\tif i > 0 {\n\t\t\tb.WriteByte('\\n')\n\t\t}\n\t\tfmt.Fprintf(b, \"%s: %s\", k, meta.Type(k...))\n\t}\n\thave := b.String()\n\n\twant = reCollapseSpace.ReplaceAllString(strings.ReplaceAll(strings.TrimSpace(want), \"\\t\", \"\"), \" \")\n\tif have != want {\n\t\tt.Errorf(\"MetaData wrong\\nhave:\\n%s\\nwant:\\n%s\", have, want)\n\t}\n}\n\nfunc testError(t *testing.T, test tomltest.Test, shouldExist map[string]struct{}) {\n\tpath := strings.TrimPrefix(test.Path, \"invalid/\")\n\n\terrs, ok := errorTests[path]\n\tif ok {\n\t\tdelete(shouldExist, \"invalid/\"+path)\n\t}\n\tif !ok {\n\t\tfor k := range errorTests {\n\t\t\tok, _ = filepath.Match(k, path)\n\t\t\tif ok {\n\t\t\t\tdelete(shouldExist, \"invalid/\"+k)\n\t\t\t\terrs = errorTests[k]\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\tif !ok {\n\t\treturn\n\t}\n\n\tfor _, e := range errs {\n\t\tif !strings.Contains(test.Output, e) {\n\t\t\tt.Errorf(\"\\nwrong error message\\nhave: %s\\nwant: %s\", test.Output, e)\n\t\t}\n\t}\n}\n\ntype parser struct{}\n\nfunc (p parser) Encode(ctx context.Context, input string) (output string, outputIsError bool, retErr error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tswitch rr := r.(type) {\n\t\t\tcase error:\n\t\t\t\tretErr = rr\n\t\t\tdefault:\n\t\t\t\tretErr = fmt.Errorf(\"%s\", rr)\n\t\t\t}\n\t\t}\n\t}()\n\n\tvar tmp any\n\terr := json.Unmarshal([]byte(input), &tmp)\n\tif err != nil {\n\t\treturn \"\", false, err\n\t}\n\n\trm, err := tag.Remove(tmp)\n\tif err != nil {\n\t\treturn err.Error(), true, retErr\n\t}\n\n\tbuf := new(bytes.Buffer)\n\terr = toml.NewEncoder(buf).Encode(rm)\n\tif err != nil {\n\t\treturn err.Error(), true, retErr\n\t}\n\n\treturn buf.String(), false, retErr\n}\n\nfunc (p parser) Decode(ctx context.Context, input string) (output string, outputIsError bool, retErr error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tswitch rr := r.(type) {\n\t\t\tcase error:\n\t\t\t\tretErr = rr\n\t\t\tdefault:\n\t\t\t\tretErr = fmt.Errorf(\"%s\", rr)\n\t\t\t}\n\t\t}\n\t}()\n\n\tvar d any\n\tif _, err := toml.Decode(input, &d); err != nil {\n\t\treturn err.Error(), true, retErr\n\t}\n\n\tj, err := json.MarshalIndent(tag.Add(\"\", d), \"\", \"  \")\n\tif err != nil {\n\t\treturn \"\", false, err\n\t}\n\treturn string(j), false, retErr\n}\n"
        },
        {
          "name": "type_fields.go",
          "type": "blob",
          "size": 6.3232421875,
          "content": "package toml\n\n// Struct field handling is adapted from code in encoding/json:\n//\n// Copyright 2010 The Go Authors.  All rights reserved.\n// Use of this source code is governed by a BSD-style\n// license that can be found in the Go distribution.\n\nimport (\n\t\"reflect\"\n\t\"sort\"\n\t\"sync\"\n)\n\n// A field represents a single field found in a struct.\ntype field struct {\n\tname  string       // the name of the field (`toml` tag included)\n\ttag   bool         // whether field has a `toml` tag\n\tindex []int        // represents the depth of an anonymous field\n\ttyp   reflect.Type // the type of the field\n}\n\n// byName sorts field by name, breaking ties with depth,\n// then breaking ties with \"name came from toml tag\", then\n// breaking ties with index sequence.\ntype byName []field\n\nfunc (x byName) Len() int      { return len(x) }\nfunc (x byName) Swap(i, j int) { x[i], x[j] = x[j], x[i] }\nfunc (x byName) Less(i, j int) bool {\n\tif x[i].name != x[j].name {\n\t\treturn x[i].name < x[j].name\n\t}\n\tif len(x[i].index) != len(x[j].index) {\n\t\treturn len(x[i].index) < len(x[j].index)\n\t}\n\tif x[i].tag != x[j].tag {\n\t\treturn x[i].tag\n\t}\n\treturn byIndex(x).Less(i, j)\n}\n\n// byIndex sorts field by index sequence.\ntype byIndex []field\n\nfunc (x byIndex) Len() int      { return len(x) }\nfunc (x byIndex) Swap(i, j int) { x[i], x[j] = x[j], x[i] }\nfunc (x byIndex) Less(i, j int) bool {\n\tfor k, xik := range x[i].index {\n\t\tif k >= len(x[j].index) {\n\t\t\treturn false\n\t\t}\n\t\tif xik != x[j].index[k] {\n\t\t\treturn xik < x[j].index[k]\n\t\t}\n\t}\n\treturn len(x[i].index) < len(x[j].index)\n}\n\n// typeFields returns a list of fields that TOML should recognize for the given\n// type. The algorithm is breadth-first search over the set of structs to\n// include - the top struct and then any reachable anonymous structs.\nfunc typeFields(t reflect.Type) []field {\n\t// Anonymous fields to explore at the current level and the next.\n\tcurrent := []field{}\n\tnext := []field{{typ: t}}\n\n\t// Count of queued names for current level and the next.\n\tvar count map[reflect.Type]int\n\tvar nextCount map[reflect.Type]int\n\n\t// Types already visited at an earlier level.\n\tvisited := map[reflect.Type]bool{}\n\n\t// Fields found.\n\tvar fields []field\n\n\tfor len(next) > 0 {\n\t\tcurrent, next = next, current[:0]\n\t\tcount, nextCount = nextCount, map[reflect.Type]int{}\n\n\t\tfor _, f := range current {\n\t\t\tif visited[f.typ] {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tvisited[f.typ] = true\n\n\t\t\t// Scan f.typ for fields to include.\n\t\t\tfor i := 0; i < f.typ.NumField(); i++ {\n\t\t\t\tsf := f.typ.Field(i)\n\t\t\t\tif sf.PkgPath != \"\" && !sf.Anonymous { // unexported\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\topts := getOptions(sf.Tag)\n\t\t\t\tif opts.skip {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tindex := make([]int, len(f.index)+1)\n\t\t\t\tcopy(index, f.index)\n\t\t\t\tindex[len(f.index)] = i\n\n\t\t\t\tft := sf.Type\n\t\t\t\tif ft.Name() == \"\" && ft.Kind() == reflect.Ptr {\n\t\t\t\t\t// Follow pointer.\n\t\t\t\t\tft = ft.Elem()\n\t\t\t\t}\n\n\t\t\t\t// Record found field and index sequence.\n\t\t\t\tif opts.name != \"\" || !sf.Anonymous || ft.Kind() != reflect.Struct {\n\t\t\t\t\ttagged := opts.name != \"\"\n\t\t\t\t\tname := opts.name\n\t\t\t\t\tif name == \"\" {\n\t\t\t\t\t\tname = sf.Name\n\t\t\t\t\t}\n\t\t\t\t\tfields = append(fields, field{name, tagged, index, ft})\n\t\t\t\t\tif count[f.typ] > 1 {\n\t\t\t\t\t\t// If there were multiple instances, add a second,\n\t\t\t\t\t\t// so that the annihilation code will see a duplicate.\n\t\t\t\t\t\t// It only cares about the distinction between 1 or 2,\n\t\t\t\t\t\t// so don't bother generating any more copies.\n\t\t\t\t\t\tfields = append(fields, fields[len(fields)-1])\n\t\t\t\t\t}\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\t// Record new anonymous struct to explore in next round.\n\t\t\t\tnextCount[ft]++\n\t\t\t\tif nextCount[ft] == 1 {\n\t\t\t\t\tf := field{name: ft.Name(), index: index, typ: ft}\n\t\t\t\t\tnext = append(next, f)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tsort.Sort(byName(fields))\n\n\t// Delete all fields that are hidden by the Go rules for embedded fields,\n\t// except that fields with TOML tags are promoted.\n\n\t// The fields are sorted in primary order of name, secondary order\n\t// of field index length. Loop over names; for each name, delete\n\t// hidden fields by choosing the one dominant field that survives.\n\tout := fields[:0]\n\tfor advance, i := 0, 0; i < len(fields); i += advance {\n\t\t// One iteration per name.\n\t\t// Find the sequence of fields with the name of this first field.\n\t\tfi := fields[i]\n\t\tname := fi.name\n\t\tfor advance = 1; i+advance < len(fields); advance++ {\n\t\t\tfj := fields[i+advance]\n\t\t\tif fj.name != name {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif advance == 1 { // Only one field with this name\n\t\t\tout = append(out, fi)\n\t\t\tcontinue\n\t\t}\n\t\tdominant, ok := dominantField(fields[i : i+advance])\n\t\tif ok {\n\t\t\tout = append(out, dominant)\n\t\t}\n\t}\n\n\tfields = out\n\tsort.Sort(byIndex(fields))\n\n\treturn fields\n}\n\n// dominantField looks through the fields, all of which are known to\n// have the same name, to find the single field that dominates the\n// others using Go's embedding rules, modified by the presence of\n// TOML tags. If there are multiple top-level fields, the boolean\n// will be false: This condition is an error in Go and we skip all\n// the fields.\nfunc dominantField(fields []field) (field, bool) {\n\t// The fields are sorted in increasing index-length order. The winner\n\t// must therefore be one with the shortest index length. Drop all\n\t// longer entries, which is easy: just truncate the slice.\n\tlength := len(fields[0].index)\n\ttagged := -1 // Index of first tagged field.\n\tfor i, f := range fields {\n\t\tif len(f.index) > length {\n\t\t\tfields = fields[:i]\n\t\t\tbreak\n\t\t}\n\t\tif f.tag {\n\t\t\tif tagged >= 0 {\n\t\t\t\t// Multiple tagged fields at the same level: conflict.\n\t\t\t\t// Return no field.\n\t\t\t\treturn field{}, false\n\t\t\t}\n\t\t\ttagged = i\n\t\t}\n\t}\n\tif tagged >= 0 {\n\t\treturn fields[tagged], true\n\t}\n\t// All remaining fields have the same length. If there's more than one,\n\t// we have a conflict (two fields named \"X\" at the same level) and we\n\t// return no field.\n\tif len(fields) > 1 {\n\t\treturn field{}, false\n\t}\n\treturn fields[0], true\n}\n\nvar fieldCache struct {\n\tsync.RWMutex\n\tm map[reflect.Type][]field\n}\n\n// cachedTypeFields is like typeFields but uses a cache to avoid repeated work.\nfunc cachedTypeFields(t reflect.Type) []field {\n\tfieldCache.RLock()\n\tf := fieldCache.m[t]\n\tfieldCache.RUnlock()\n\tif f != nil {\n\t\treturn f\n\t}\n\n\t// Compute fields without lock.\n\t// Might duplicate effort but won't hold other computations back.\n\tf = typeFields(t)\n\tif f == nil {\n\t\tf = []field{}\n\t}\n\n\tfieldCache.Lock()\n\tif fieldCache.m == nil {\n\t\tfieldCache.m = map[reflect.Type][]field{}\n\t}\n\tfieldCache.m[t] = f\n\tfieldCache.Unlock()\n\treturn f\n}\n"
        },
        {
          "name": "type_toml.go",
          "type": "blob",
          "size": 1.8837890625,
          "content": "package toml\n\n// tomlType represents any Go type that corresponds to a TOML type.\n// While the first draft of the TOML spec has a simplistic type system that\n// probably doesn't need this level of sophistication, we seem to be militating\n// toward adding real composite types.\ntype tomlType interface {\n\ttypeString() string\n}\n\n// typeEqual accepts any two types and returns true if they are equal.\nfunc typeEqual(t1, t2 tomlType) bool {\n\tif t1 == nil || t2 == nil {\n\t\treturn false\n\t}\n\treturn t1.typeString() == t2.typeString()\n}\n\nfunc typeIsTable(t tomlType) bool {\n\treturn typeEqual(t, tomlHash) || typeEqual(t, tomlArrayHash)\n}\n\ntype tomlBaseType string\n\nfunc (btype tomlBaseType) typeString() string { return string(btype) }\nfunc (btype tomlBaseType) String() string     { return btype.typeString() }\n\nvar (\n\ttomlInteger   tomlBaseType = \"Integer\"\n\ttomlFloat     tomlBaseType = \"Float\"\n\ttomlDatetime  tomlBaseType = \"Datetime\"\n\ttomlString    tomlBaseType = \"String\"\n\ttomlBool      tomlBaseType = \"Bool\"\n\ttomlArray     tomlBaseType = \"Array\"\n\ttomlHash      tomlBaseType = \"Hash\"\n\ttomlArrayHash tomlBaseType = \"ArrayHash\"\n)\n\n// typeOfPrimitive returns a tomlType of any primitive value in TOML.\n// Primitive values are: Integer, Float, Datetime, String and Bool.\n//\n// Passing a lexer item other than the following will cause a BUG message\n// to occur: itemString, itemBool, itemInteger, itemFloat, itemDatetime.\nfunc (p *parser) typeOfPrimitive(lexItem item) tomlType {\n\tswitch lexItem.typ {\n\tcase itemInteger:\n\t\treturn tomlInteger\n\tcase itemFloat:\n\t\treturn tomlFloat\n\tcase itemDatetime:\n\t\treturn tomlDatetime\n\tcase itemString, itemStringEsc:\n\t\treturn tomlString\n\tcase itemMultilineString:\n\t\treturn tomlString\n\tcase itemRawString:\n\t\treturn tomlString\n\tcase itemRawMultilineString:\n\t\treturn tomlString\n\tcase itemBool:\n\t\treturn tomlBool\n\t}\n\tp.bug(\"Cannot infer primitive type of lex item '%s'.\", lexItem)\n\tpanic(\"unreachable\")\n}\n"
        }
      ]
    }
  ]
}