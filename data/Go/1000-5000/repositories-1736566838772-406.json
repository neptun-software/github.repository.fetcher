{
  "metadata": {
    "timestamp": 1736566838772,
    "page": 406,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "mozilla-services/heka",
      "stars": 3386,
      "defaultBranch": "dev",
      "files": [
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.107421875,
          "content": ".vagrant\ndocs/build\nbuild\ncmake/plugin_loader.cmake\netc/\npipeline/mock_*.go\nvar/\n*.sw?\nexternals\ndockerfile/*\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.3427734375,
          "content": "*.data text eol=lf\nmultiline.log text eol=lf\nlogstreamer/testdir/filehandling/2010/07/error.log text eol=lf\nlogstreamer/testdir/filehandling/2010/07/error.log.2 text eol=lf\nlogstreamer/testdir/filehandling/2013/08/access.log text eol=lf\nlogstreamer/testdir/filehandling/2013/08/error.log text eol=lf\nlogstreamer/testdir/shortlog/short.log text eol=lf\n"
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.1181640625,
          "content": "docs/build\nsandbox/lua/lua_sandbox.go.in\nbuild\ncmake/plugin_loader.cmake\netc/\npipeline/mock_*.go\nvar/\n*.sw?\nexternals\n*~\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.150390625,
          "content": "[submodule \"docs/source/_themes/mozilla\"]\n\tpath = docs/source/_themes/mozilla\n\turl = https://github.com/rafrombrc/mozilla-sphinx-theme.git\n\tbranch = heka\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.263671875,
          "content": "sudo: false\nlanguage: go\ngo:\n    - 1.4\nnotifications:\n    irc:\n        channels:\n            - \"irc.mozilla.org#heka\"\naddons:\n    apt:\n        packages:\n        - protobuf-compiler\n        - cmake\n        - libgeoip-dev\ninstall:\n    - . build.sh\nscript:\n    - make test\n"
        },
        {
          "name": "CHANGES.txt",
          "type": "blob",
          "size": 56.1796875,
          "content": "0.11.0 (2016-??-??)\n===================\n\nBackwards Incompatibilities\n---------------------------\n\n* StatAccumInput `percent_threshold` param type convert to slice.\n\n* HttpInput `user` param changed to `username` to match other HTTP plugins.\n\n* DockerLogInput changed to use `logs` API endpoint instead of `attach`. This\n  helps prevent data loss by allowing use of the `since` parameter to fetch\n  records that were generated while Heka was down, but it means this input will\n  now only work with containers using the `json-file` or `journald` logging\n  drivers.\n\n* Added PatternGroupingSplitter.\n\nBug Handling\n------------\n\n* Updated DockerEventInput to exit when the Docker event stream channel closes\n  (see https://github.com/fsouza/go-dockerclient/issues/485).\n\n* Updated Sarama dependency from pre-1.0 release fork to fork (with only test\n  code changes) of Sarama 1.5.0 release.\n\n* Fixed ESJsonEncoder generating invalid JSON when `DynamicFields` is first of\n  multiple specified fields but the message contains no dynamic fields.\n\n* Fixed bug where DockerLogInput would not reconnect when a Docker daemon\n  was down for some time (#1843).\n\n* More verbose logging from the DockerLogInput plugin (#1843).\n\nFeatures\n--------\n\n* Added `fields_from_labels`, `container_expiry_days`, and\n  `new_containers_replay_logs` options to DockerLogInput.\n\n* Added BIND query log decoder.\n\n* Added `bind_queue` option to AMQPInput.\n\n* Added time interval configurability to Unique Items filter.\n\n* Added TLS support to KafkaInput and KafkaOutput plugins.\n\n* Added decoder support to StatAccumInput.\n\n* Added `git_clone_to_path` to the cmake build to allow git repos to be cloned\n  into alternate locations; useful for relocating forks of Go packages into\n  their original import paths.\n\n* Added `initial_tail` config option to LogstreamerInput (#1482, #1801).\n\n* Added Splitter support to DockerLogInput plugin (#1843).\n\n* Added `fields_from_labels` config option to DockerLogInput (#1843).\n\n* Added DockerStatsInput plugin.\n\n* Added iowait percentage output field in filter procstat (#1888).\n\n* Added support for 'replace_dot_with' flag in ES encoders (#1947).\n\n0.10.1 (2016-??-??)\n===================\n\nFeatures\n--------\n\n* Added `check_data_interval` setting to LogstreamerInput.\n\n* Added `separator` and `maximum_depth` settings to JSON decoder (#1809).\n\n* Added `status_field` setting to http_status filter (#1876)\n\nBug Handling\n------------\n\n* Fixed conditional which was causing InfluxDB line protocol encoder to not\n  correctly honor the `source_value_field` config setting.\n\n* Don't use `os.Exit` in the pipeline's main `Run` function or else any\n  wrapping deffered functions (such as those that output the cpu and mem\n  profiles) won't get called.\n\n* Stop zero-length records with no error ending the splitter if there's\n  more data to read (#1561)\n\n* Fixed gzipped file seeking in logstreamer may cause an OOM exception.\n\n* Fixed LogstreamerInput file rotation missing newly created files with new\n  names by always triggering LogstreamSet rescan before checking location in\n  stream (#1452).\n\n* JSON decoder no longer exits when flattening the field structure fails.\n\n* Fixed bug where HttpOutput would discard the response body before trying to\n  use the response body when response returned an error status code.\n\n0.10.0 (2015-12-30)\n===================\n\nBug Handling\n------------\n\n* Fixed issue where LogstreamerInput doesn't notice when a zero-length file is\n  deleted and replaced by a new zero-length file before any data is appended\n  (#1199).\n\n0.10.0b2 (2015-11-20)\n=====================\n\nBackwards Incompatibilities\n---------------------------\n\n* StatAccumInput Input: percent_threshold param type convert to slice\n\nBug Handling\n------------\n\n* Updated Sarama dependency from pre-1.0 release fork to fork (with only test\n  code changes) of Sarama 1.5.0 release.\n\nFeatures\n--------\n\n* Added decoder support to StatAccumInput.\n\n* Added `git_clone_to_path` to the cmake build to allow git repos to be cloned\n  into alternate locations; useful for relocating forks of Go packages into\n  their original import paths.\n\n0.10.0 (2015-??-??)\n=====================\n\nBackwards Incompatibilities\n---------------------------\n\n* `DecoderRunner` interface changed `SetSendFailure` to `SetFailureHandling`.\n\nFeatures\n--------\n\n* Allow TcpOutput to re-establish the connection after a configurable number\n  of successfully delivered messages.\n\n* Added `set_hostname` option to UdpInput configuration (#1668).\n\n* Added `linux_netdev` and `linux_netstat` decoders (#1712).\n\n* Improved error output for ElasticSearchOutput HTTP failures.\n\n* Added `log_decode_failures` config value to decoders.\n\n* Adder `log_flags` to hekad config, to control the prefix for STDOUT and\n  STDERR logs.\n\nBug Handling\n------------\n\n* Fixed issue where ElasticSearchOutput was trying to send zero length requests\n  (#1783).\n\n* Fixed race condition in ElasticSearchOutput (#1786).\n\n* AMQPInput `Run` method now returns an error when the input channel closes but\n  `Stop` hasn't been called to successfully trigger restarts (#1757).\n\n* Fixed error where restarting plugins were losing specified configuration\n  (#1756).\n\n* Fixed config error where global `max_pack_idle` setting was the wrong type\n  and was being ignored (#1778).\n\n* Fixed race condition in InputRunner's default deliverer initialization.\n\n* Set hostname correctly in the Graylog decoder (#1663).\n\n* Add sample rate support for gauge type in StatsdInput.\n\n* Fixed some cases where SandboxDecoder wasn't correctly setting\n  `pack.TrustMsgBytes` to false when needed.\n\n* Fixed broken queue rolling and added test.\n\n* Force ElasticSearch index name to lower case, as required by ElasticSearch.\n\n* Fixed default buffer config values.\n\n* Updated docker configuration so docker build works again (#1634).\n\n* Add generic json lua sandbox decoder (#1651).\n\n* Fixed bug where a SandboxInput configured with a `ticker_interval` would\n  get stuck in an infinite loop on shutdown (#1705).\n\n* Fixed race condition in the BufferReader's queue file lookup code (#1639).\n\n* Changes in StatAccumInput, FileOutput, TcpInput, ProcessDirectoryInput tests\n  to minimize intermittent Travis failures.\n\n* Ensure the response is read until it is complete in the HttpOutput plugin.\n  Previously, the deferred Body.Close() may have been called on incomplete\n  responses. This resulted in the connections not returning to the client's\n  Transport connection pool.\n\n* Fixed panic that was occurring when loading a config file or directory that\n  exists but which registers no plugins (#1597).\n\n* Delay start up when a buffered plugin's buffer is at capacity to give the\n  back-pressure time to resolve (#1738).\n\n* Fixed bug where LogStreamerInput would sometimes loop infinitely reading the\n  same file over and over when reading gzipped log files.\n\n0.10.0b1 (2015-08-07)\n=====================\n\nBackwards Incompatibilities\n---------------------------\n\n* `PluginHelper.PipelinePack` method now returns `(*PipelinePack, err)` values\n  instead of just `*PipelinePack`.\n\nFeatures\n--------\n\n* Allow multiple sandbox module directories to be specified (#1525).\n\n* Add Nginx stub status lua sandbox decoder\n\n* Add Nginx stub status lua sandbox decoder.\n\n* Added support for SIGUSR2 signal for use when Heka is wedged, triggers a Heka\n  pipeline report to the console, abort and serialize of all sandboxes, and a\n  shutdown.\n\n* InputRunner and router's `Inject` methods each now return an error that can\n  be checked to verify successful message injection.\n\n* Added `SplitStreamNullSplitterToEOF` to SplitterRunner interface so input\n  plugins can avoid generating messages with whatever happens to come back from\n  a `Read()` call.\n\n* Validate the buffer max_file_size is greater than MAX_RECORD_SIZE (#1623).\n\nBug Handling\n------------\n\n* Validate the buffer max_file_size is greater than MAX_RECORD_SIZE (#1623).\n\n* Fixed ProcessInput hangs when splitter is defined (#1620, #1644).\n\n* `heka.all-report` and `heka.memstat` messages are now protobuf encoded before\n  being injected into the router (#1659).\n\n* Fixed ProcessInput not getting process's full output when NullSplitter is in\n  use (#1645).\n\n0.10.0b0 (2015-07-13)\n=====================\n\nBackwards Incompatibilities\n---------------------------\n\n* Major overhaul of filter and output plugin APIs to support disk buffering\n  (#1378).\n\n* `queue_max_buffer_size` and `queue_full_action` config options for TcpOutput\n  and ElasticSearchOutput are now moved to `max_buffer_size` and `full_action`\n  in the `buffering` subsection (#1378).\n\n* Go 1.4 now required for building.\n\n* Deprecated the read_next_field() sandbox API; it is targeted for removal in\n  0.11.0 (#1602).\n\n* Removed unused PipelinePack.Decoded attribute.\n\n* LogOutput will write data to stdout instead of stderr (#1515).\n\n* Using strftime literals for filenames during rotation in FileOutput plugin\n  (#1469).\n\n* Implemented strftime format codes in: filenames in FileOutput plugin,\n  ESJsonEncoder, ESLogstashV0Encoder, Payload encoder (#1469, #1508).\n\n* The package created by 'make deb' creates an \"heka\" user and ships an init\n  script and a systemd unit.\n\n* The 'make deb' target requires fakeroot and debhelper to be installed.\n\n* SplitterRunner interface now provides a `Done` method that should be called\n  whenever the splitter is no longer needed.\n\n* `\"Fields\"` choice for the `fields` setting renamed to `\"DynamicFields\"` for\n  both ESJsonEncoder and ESLogstashV0Encoder.\n\nFeatures\n--------\n\n* Added support for `write_message` to delete fields when passed nil values.\n\n* Added a timer_event_on_shutdown configuration option for Filter/Output\n  sandboxes (#1460).\n\n* Added `replace_dot` setting to StatFilter.\n\n* A protobuf encoding of the current message is now always stored in\n  pack.MsgBytes prior to injection into the message router (#265).\n\n* ProtobufEncoder now just copies the pack.MsgBytes into a new byte slice and\n  returns that.\n\n* Added Linux CPU Stats Decoder and CPU Stats Filter.\n\n* Centralized common functions used by the Schema Carbon Line Encoder and\n  Schema InfluxDB Line Encoder into new ts_line_protocol and field_util modules.\n\n* Added a new sandbox encoder, Schema Carbon Line Encoder, which provides\n  support for converting fields in a Heka message to metrics formatted to\n  send to Carbon/Graphite.\n\n* Added a new sandbox encoder, Schema InfluxDB Line Encoder, which updates\n  compatibility of sending data in Heka message fields to InfluxDB 0.9.0+\n  write API. It is required to use this encoder when integrating Heka with an\n  InfluxDB 0.9.0+ instance as the API to commit metrics has changed. This\n  encoder was also updated to use the line protocol which is now the default\n  series format for the write API.\n\n* Added support for abstract Unix domain sockets to the UdpInput.\n\n* Added support for `can_exit` to inputs (defaults to false, except on\n  ProcessDirectoryInput spawned processes where it defaults to true)\n\n* Added `field_mappings` setting to the ESJsonEncoder allowing custom names for\n  Heka message fields in ElasticSearch.\n\n* Termination messages are now generated for SandboxFilters that fail\n  initialization by a SandboxManagerFilter.\n\n* Added alert_throttle setting to HTTP status graph filter.\n\n* Added DockerEventInput.\n\n* Added splitters to the reports displayed by Heka after SIGUSR1 signal.\n\n* Added `graphite` module with helpers allowing to generate graphite metrics\n  for counters and timeseries (#1461).\n\n* Added Basic Auth and API key authentication to HttpListenInput (#1533).\n\n* Added SSL/TLS support to HttpListenInput (#1534)\n\n* Allow to overwrite ContainerName using a Container environment variable from\n  within the Docker container for the DockerLogInput. (#1545)\n\n* Allow extracting environment variables from a Docker container to use as\n  fields for the DockerLogInput. (#1569)\n\n* Dashboard now shows sandbox plugins in alphabetical order.\n\n* Added 'dynamic_fields' config to ESJsonEncoder for selecting a subset of\n  Fields values\n\nBug Handling\n------------\n\n* Fixed visibility of synchronous decoders in reports (#1312).\n\n* Fixed hang on SandboxFilter termination (#1509)\n\n* More ProcessInput/ProcessDirectoryInput retry logic fixes (#1412 & #1418).\n\n* ProcessInput fixed to no longer leak decoder goroutines when reconfigured\n  via ProcessDirectoryInput-driven config changes (#1444).\n\n* Check configuration, ticker_interval in Stat Accumulator Input  must be\n  greater than 0 (#1474).\n\n* Switch from unmaintained `crowdmob` fork of GoAMZ dependency to `AdRoll`\n  (#1458).\n\n* Added ability to reconnect after lost connection in `heka-flood` (#1536).\n\n* Respect ElasticSearch URL path (#1558).\n\n0.9.3 (2015-??-??)\n==================\n\nBug Handling\n------------\n\n* Correctly honor \"user-agent\" heading config in HttpInput (#1520).\n\n* Removed state from PluginMaker to remove race conditions during plugin\n  construction (#1532).\n\n* Get decoder lock before cleaning up decoders during pipeline shutdown to\n  avoid race condition panics during exit (#1531).\n\n0.9.2 (2015-04-22)\n==================\n\nBug Handling\n------------\n\n* Added bounds check for truncated inputs lines to StatsdInput.\n\n* Fixed ElasticSearch recovery after full queue when `queue_full_action` is\n  set to \"drop\" or \"block\".\n\n* Fixed TcpOutput recovery after full queue when `queue_full_action` is set to\n  \"drop\" or \"block\" (#1484).\n\n* Fixed bug where LogstreamerInput wasn't honoring `oldest_duration` setting\n  (#1437).\n\n* ElasticSearch payload encoder will ensure there is a newline in the\n  end of the payload in order for the bulk API to work correctly (#1457).\n\n* Fix a gzipped file seeking in logstreamer may cause an OOM exception.\n\n* Fixed config parsing typo bug in heka-logstreamer command (#1436).\n\n* Always check for decoder existence when a decoder is specified for an input\n  plugin (#1439).\n\n* Check `IsStoppable()` on all input, filter, output plugins if they error at\n  startup time, only shut down Heka if false.\n\n* Fixed typo causing panic in AMQPInput when splitter returns an error\n  (#1453).\n\n* Handle chunked error responses in http_output.\n\n* ElasticSearchOutput buffering now only retries messages when it's clear that\n  the problem related to failed communication with the ElasticSearch server\n  (#1401).\n\n* Added handling of incomplete/trailing data for SplitBytes() method in\n  SplitterRunner (#1455)\n\n0.9.1 (2015-03-13)\n==================\n\nFeatures\n--------\n\n* Added configurable max_message_size to heka-cat.\n\n* Added `count` setting to TokenSplitter to allow splitting on every Nth\n  instance of the given delimiter.\n\n* Added `deliver_incomplete_final` setting to SplitterRunner.\n\n* Added `max_message_size` setting to UdpOutput.\n\nBug Handling\n------------\n\n* Fix the message matcher parser to clear the yySymType structure on each call\n  (#1409).\n\n* Protect read_message(\"raw\") from reading an empty pack.MsgBytes (#1405).\n\n* Moved `SetSplitterRunner` out of the config's MakeRunner and into the\n  `NewSplitterRunner` function to make sure a splitter always has access to a\n  SplitterRunner if needed.\n\n* Fixed SplitterRunner buffer readPos so it only increments when a read call\n  doesn't return an error (#1367).\n\n* Ensured plugin list file is closed after writing to it in Dashboard plugin.\n\n* Fixed exiting / restart behavior for ProcessInput to match documentation\n  (#1395).\n\n* UdpOutput drops message if its size exceeds allowed UDP data size (#1393).\n\n0.9.0 (2015-02-25)\n==================\n\nBackwards Incompatibilities\n---------------------------\n\n* Major overhaul of Heka's configuration loading code. This doesn't impact\n  most plugins, it's only a breaking change for plugins that happen to\n  instantiate and manage the lifecycles of other embedded plugins, e.g.\n  MultiDecoder, ProcessDirectoryInput, SandboxManagerFilter.\n\n* All inputs now support `decoder`, `synchronous_decode`, and\n  `send_decode_failures` config options, automatically extracted by Heka's\n  config system.\n\n* InputRunner now handles message decoding and delivery to the router,\n  according to the specifications of the input's configuration. This is\n  accomplished either directly via the `Deliver` method or, in cases where\n  decoding might need to happen in separate goroutines, through `Deliverer`\n  objects available from the `NewDeliverer` method.\n\n* Hekad and all clients started using stdout for informational messages and\n  stderr for error messages.\n\n* Stats Accum Input treats gauge inputs as float64 rather than int64 to match\n  statsd spec and other statsd implementations (#850).\n\n* Introduction of Splitter plugins, accompanied by major changes to how input\n  plugins work to support the use of Splitter plugins. (#424)\n\n* TcpInput and UdpInput now set a non-protobuf encoded message's Type field to\n  the configured input plugin name instead of the hard-coded string\n  \"NetworkInput\".\n\nBug Handling\n------------\n\n* Fix the shutdown hang caused by a Filter/Output plugin failure (#1324).\n\n* Fix the RPM dependency errors on Centos7 (#1311).\n\n* Don't output empty messages when use_framing = true (#1326).\n\n* KafkaInput uses the oldest offset available instead of zero when no\n  checkpoint file exists and the offset method is set to manual. KafkaInput\n  also correctly closes the checkpoint file before removing it when it is\n  invalid (#1325).\n\n* Handle empty byte fields in the sandbox interface (#1284).\n\n* Reset header when discarding valid but oversized messages (#1221).\n\n* Prevent the protobuf stream encoder from creating messages over\n  MAX_MESSAGE_SIZE (#1204).\n\n* AMQPOutput now uses defined constants for delivery mode instead of hard\n  coded (and wrong) integer values (#1235).\n\n* Hekad now respects --config parameter and loads default config path\n  instead of printing help and exit (#1239).\n\n* MessageProtoParser now handles EOF gracefully, and returns all\n  complete records up to the end of the stream without having to\n  use GetRemainingData() (#1305).\n\n* HttpListenInput no longer URL unescapes the HTTP request body (#1124).\n\n* SmtpOutput now encodes email subject when necessary (#1277).\n\n* All config files are now pre-loaded before any of the config is actually\n  loaded to prevent default plugins from being registered for each separate\n  config file, possibly overriding custom config.\n\nFeatures\n--------\n\n* Added decode_message to the sandbox API (#1344).\n\n* Added a SandboxInput plugin (#1333).\n\n* Added a SandboxOutput plugin (#1303).\n\n* `heka/plugins/amqp` package now exposes `GetAmqpHub` and `NewAMQPDialer`\n  functions for use by external packages.\n\n* Added heartbeat monitoring sandbox filter plugin.\n\n* Include the new lua_sandbox with support for shared library modules.\n\n* Allow the sandbox process_message function to set the last error string\n  when it returns (#1191).\n\n* Improve the sandbox inject_* error messages (#1156).\n\n* Added ability to specify unit type and aggregation methods for stats graph\n  filter.\n\n* Added option (immediate_start) to start process immediately in ProcessInput\n  (#1131).\n\n* Added `hostname` setting to global `[hekad]` config options to allow\n  overriding the hostname value provided by Go's `os.Hostname` call (#1123).\n\n* Added 'connect_timeout' option in ElasticSearch output plugin.\n\n* Slightly improve error output in ElasticSearch plugin.\n\n* Added support for HTTP authentication to ElasticSearchOutput.\n\n* TcpOutput's disk buffering now supports specification of a max buffer size\n  and an action to take if the max size is reached, from 'shutdown', 'drop',\n  or 'block' (#1110).\n\n* Added `send_interval` setting to SmtpOutput.\n\n* Added `timestamp` format setting to ESLogstashV0Encoder (#1142).\n\n* LogstreamerInput now uses first two \"magic\" bytes to identify gzip files\n  instead of relying on `.gz` suffix.\n\n* Added on-disk buffering to ElasticSearchOutput. It is enabled by default.\n\n* Added TLS support to ElasticSearchOutput (#1259).\n\n* Added ability for HttpListenInput to capture specified HTTP request headers\n  and write them as message fields.\n\n* Added ability for Statsd input handler to treat a malformed stat line\n  one at time without skipping all the \"good\" stats in a multi-line input\n  (more like statsd itself).\n\n* Added `message_interval` setting support to heka-flood test configuration.\n\n* Added `cert_path` setting for TLS support to DockerLogInput.\n\n* Added new fields to messages generated by HttpListenInput, including\n  RemoteAddr, Path, EnvVersion, Hostname (the name of the server that\n  handled the request), and Host (the host to which the client sent the\n  request) (#1328).\n\n* Added `hostname_keep` option to RsyslogDecoder (#1338).\n\n* Added an option to Schema InfluxDB Encoder to send the data to InfluxDB as\n  a list of series rather than the default of a single series for all fields\n  in the message.\n\n* Added an option to Schema InfluxDB Encoder that excludes all base fields\n  from being sent to InfluxDB to reduce the network traffic and storage\n  demands if these fields aren't useful.\n\n* Added `read_only` setting to AMQPInput to support read-only users.\n\n* Added ability to specify MAX_MESSAGE_SIZE via configuration file of hekad\n  and heka-flood (#1208).\n\n* Changed default plugin_chansize setting from 50 to 30 (#1242).\n\n0.8.3 (2015-01-08)\n==================\n\nBug Handling\n------------\n\n* Fixed LogstreamerInput to use a separate DecoderRunner for every\n  LogstreamInput created, rather than sending all of the streams through a\n  single decoder.\n\n0.8.2 (2015-01-06)\n==================\n\nBug Handling\n------------\n\n* Fix rsyslog sandbox decoder test to use current year and location for\n  timestamp parsing, since syslog timestamp format makes that assumption.\n\n* Ensure that geoip_decoder is not included in release binaries.\n\n0.8.1 (2014-12-17)\n==================\n\nBug Handling\n------------\n\n* Fix leaky file descriptor bug on http_output.go.\n\n* Only stamp PipelinePack diagnostics in cases when a pack actually matches a\n  message matcher, instead of for every matcher every time (#1167).\n\n* StatsdInput allows to specify (via max_msg_size option) size of message read\n  from UDP (#1165).\n\n* AMQPOutput now recycles packs even when a publish error causes the output to\n  exit / restart (#1178).\n\n* Fixed HttpOutput TLS section parsing (#1163).\n\n* Fixed LogstreamInput extraneous journal saves that caused high disk IO\n  when EOF is reached.\n\n0.8.0 (2014-10-29)\n==================\n\nBackwards Incompatibilities\n---------------------------\n\n* Audited the use of Logger and Type headers on internal message (#1024). These\n  changes may break some existing message matchers with regards to\n  plugin/sandbox termination messages.\n\n* Sandbox decoder linux_cpustats has been renamed to linux_loadavg and the\n  corresponding filter cpustats was renamed to loadavg (#1094).\n\n* ESLogstashv0 encoder will now set the @type field to match the ES record\n  type specified in the `type_name` setting. This is Logstash behaviour in\n  V0. You can revert back to the old method with `use_message_type = true`\n\nBug Handling\n------------\n\n* linux_diskstats.lua will now parse a line with no leading space (#1141).\n\n* Protect globals.Stopping with a RWMutex.\n\n* Added support for `fields` config setting to ESLogstashV0Encoder; it was\n  already documented, but hadn't been implemented (#1096).\n\n* Fixed deadlock race condition in AMQPOutput shutdown sequence (#824).\n\nFeatures\n--------\n\n* Added Kafka Input/Output plugins (#1148).\n\n* Optimized prefix/suffix testing in the message matcher (#1040).\n\n* LogstreamerInput now supports seekjournal file hashing for files that are\n  less than 500 bytes in length; hash is generated against file contents with\n  0 bytes prepended to make 500 bytes of hash content (#972).\n\n* Support environment variables in config files (#1023).\n\n* Add Dockerfiles and example Docker usage to repo\n\n* Encoders can now return (nil, nil) to express that they've swallowed the\n  input message without generating any output.\n\n* SandboxEncoder now supports return value of -2 from the process_message call\n  to specify that no output is being generated.\n\n* Added schema_influx.lua encoder.\n\n* Added CBUF Librato Encoder.\n\n* Added option to disable re-using TCP connections to the ElasticSearch output\n\n* Added separate env loading file and support for NUM_JOBS env var to Windows\n  build (#971).\n\n* Added DockerLogInput (issue #1092).\n\n* Added support for \"Epoch\", \"EpochMilli\", \"EpochMicro\", and \"EpochNano\"\n  timestamp formats to the time parsing code used by the Payload*Decoder\n  plugins (#963).\n\n* Added ability to drop big message entirely or to keep first part of it (#1134)\n\n0.7.3 (2014-10-28)\n==================\n\nBug Handling\n------------\n\n* Fail gracefully on LogstreamerInput missing `file_match` setting (#1105).\n\n* Fixed issue where ProcessInput wasn't propagating environment variables and\n  working directory to repeatedly run (vs. one time, long running) processes\n  (#1108).\n\n* UdpInput now removes a Unix datagram socket file at shutdown time if one is\n  created at startup.\n\n* Fixed issue with keeping previous EOF state in LogStreamer (#1119).\n\n* ProcessInput now honors documented restart behavior (#1117).\n\n0.7.2 (2014-10-01)\n==================\n\nBug Handling\n------------\n\n* Fail more gracefully if user doesn't specify a scheme in the server URL for\n  the ElasticSearchOutput (#1069).\n\n* Correctly compute http timeout interval for ElasticSearchOutput when using\n  HTTP indexing.\n\n* Fixed issue w/ inaccurate payload sizes in heka-flood.\n\n* Allow severity to be modified by the MessageTemplate logic for use in\n  ScribbleDecoder (#1084).\n\n* Render pack diagnostic idle time in seconds (as specified) instead of\n  nanoseconds.\n\n* Prevent orphaned matchers from remaining in the router's matcher lists in\n  cases where a filter or output registered in one TOML file overrides a\n  filter or output of the same name in an earlier TOML file.\n\n0.7.1 (2014-09-02)\n==================\n\nBug Handling\n------------\n\n* Fixed handling of TcpInput and TcpOutput keep_alive_period default value\n  handling, and added docs (#1054).\n\n* Fixed OSX lua_sandbox build error.\n\n* Fixed load ordering of nested MultiDecoders (#1045).\n\n0.7.0 (2014-08-27)\n==================\n\nBackwards Incompatibilities\n---------------------------\n\n* Switched to using fork of gomock, import location changed from\n  `code.google.com/p/gomock` to `github.com/rafrombrc/gomock`.\n\n* Move *GlobalConfigStruct out of pipeline package's global namespace, it is\n  now stored as an attribute on PipelineConfig. Any code that used to call\n  pipeline.Globals() now must instead access *PipelineConfig.Globals. The\n  `WantsPipelineConfig` interface has been introduced to give plugins access\n  to the active *PipelineConfig if it's needed in the ConfigStruct or Init\n  methods (#951).\n\n* Removed deprecated `pipeline.GetHekaConfigDir` API call, which has been\n  replaced by `PrependBaseDir` and `PrependShareDir` for a few versions\n  now.\n\n* Removed the regular expression template support from the message matcher\n  (issue #960).\n\n* Updated the AMQP input / output configuration values to use underscore\n  delimited words for long config options (issue #953).\n\n* LogstreamerInput now errors on nonexistent `log_directory` instead of\n  creating the folder (issue #1066).\n\nBug Handling\n------------\n\n* Fixed the MySQL slow query grammar to handle logs with no newline.\n\n* Fixed packet tracking idle packs error output formatting.\n\n* Prevent panics during shutdown when a restarting plugin has been restarted\n  (issue #957).\n\n* Added support for a Logstreamer symbolically linked log_directory root\n  (issue #741).\n\n* Fixed lots of race conditions in the tests.\n\n* Eliminated race condition in use of global AMQPHub in AMQP input / output\n  plugins (#953).\n\nFeatures\n--------\n\n* Added StatMetric Influx Encoder.\n\n* Added RstEncoder.\n\n* Added support for '__ignore_root' tag in add_external_plugin to allow\n  external packages to be added which do not have any .go files\n  in their root directory (issue #955).\n\n* Switched from using goprotobuf to gogoprotobuf with marshal_all and\n  unmarshal_all extensions for significant performance increase.\n\n* Added stats graph sandbox filter to make it easier to generate graphs of\n  statsd / graphite metrics (issue #966).\n\n* Added support for the majority of repository URI formats when cloning external\n  Go packages (issue #937).\n\n* Added the ability to test for field existence in message matcher (issue #958).\n\n* Added support to ESJSonEncoder and ESLogstashV0Encoder to properly encode\n  field arrays.\n\n* Added a filter to monitor all process message failures (issue #948).\n\n* Added UdpOutput.\n\n* Added IrcOutput.\n\n* Added support for filter and output plugins to optionally exit without\n  causing Heka to shutdown via config option.\n\n* Added support for custom HTTP Headers in HttpListenInput and DashboardOutput.\n\n0.6.1 (2014-08-27)\n==================\n\nBug Handling\n------------\n\n* CarbonOutput using UDP transport now uses multiple packets to send stats\n  data to Carbon server when output would be longer than the 64KiB max size\n  for UDP packets (issue #1035).\n\n* StatsdInput now trims all whitespace around incoming stat names instead of\n  just trailing newlines (issue #1011).\n\n* Fixed silent failures in ElasticSearchOutput bulk indexing operations.\n\n* Fixed permanent loss of HTTP connection in certain cases when ElasticSearch\n  has been restarted (issue #1008).\n\n* Fixed default sandbox script type when loading dynamic plugins.\n\n0.6.0 (2014-07-09)\n==================\n\nBackwards Incompatibilities\n---------------------------\n\n* Go 1.3 now required for building.\n\n* Changed handling of message stream framing. Before stream framing was\n  presumed to always be required when encoding with protocol buffers, and not\n  required when using other encodings. Now all outputs support an optional\n  `use_framing` setting that will determine whether or not framing will be\n  applied when using the OutputRunner's Encode method (issue #922).\n\n* All files in a config directory that do not end in \".toml\" will now be\n  ignored and not loaded as a part of the Heka configuration (issue #750).\n\n* Removed the PayloadJsonDecoder which is replaced by the Lua sandbox cjson\n  module (issue 826).\n\n* Removed LogfileInput and LogfileDirectoryManagerInput which were replaced\n  by LogstreamerInput in 0.5.0 (issue 914).\n\n* MultiDecoder no longer sets prepends name of the decoder instance to the\n  message type value for every message. This was impacting performance, is\n  almost never what is needed, and is almost always overwritten by the nested\n  subdecoders anyway.\n\n* MultiDecoder now has a `subs` option that refers to other top level decoder\n  config definitions, instead of nested sub-configs and a separate `order`\n  option specifying the order. This makes for less typing and the ability to\n  reuse decoder definitions as both standalone decoders and across multiple\n  MultiDecoders (issue #485).\n\n* ElasticSearchOutput now uses an Encoder plugin instead of MessageFormatters.\n  Created ESJsonEncoder, ESLogstashV0Encoder, and ESPayloadEncoder\n  (implemented as a SandboxEncoder in es_payload.lua) to replicate prior\n  formatter behavior.\n\n* Changed the Lua sandbox API.  inject_message is no longer overloaded, output\n  has been renamed to add_to_payload, and inject_payload has been introduced.\n\n* Changed TcpOutput, FileOutput, and LogOutput to use Encoder plugins for\n  output formatting instead of bespoke formatting implementations.\n\n* The rsyslog decoder now further parses the %SYSLOGTAG% variable. The\n  fields.syslogtag no longer exists and is replaced by fields.programname and\n  message.Pid (issue #677).\n\n* Removed no-longer-used 'decoder_poolsize' global config setting.\n\nBug Handling\n------------\n\n* Fixed the ElasticSearchOutput to always use UTC times in the bulk API header\n  (issue #504).\n\n* Fixed the SandboxDecoder panic when failing the Decode() after successfully\n  injecting a message (issue #910).\n\n* StatsdInput no longer spins up a new goroutine for each stat (issue #359).\n\n* MultiDecoder no longer prevents shutdown if a nested SandboxDecoder crashes\n  during startup (issue #896).\n\n* MultiDecoder using `cascade_strategy = \"all\"` now passes all generated packs\n  to all nested decoders instead of skipping the remainder if an earlier pack\n  in the sequence fails to decode (issue #896).\n\n* MultiDecoder no longer tries to recycle the original pack, leaving that job\n  to the DecoderRunner as intended (issue #896).\n\n* Updated SmtpOutput to use a slice instead of a map to generate SMTP headers\n  so the order will remain consistent when using Go 1.3 or later.\n\n* Use FindProcess instead of syscall.Kill to make the 'pid_file' configuration\n  setting work on Windows (issue #807)\n\n* Fix the SandboxFilter ReportMsg panic on termination/shutdown (issue #816)\n\n* MultiDecoder with no 'order' set now fails on init instead of panicking on\n  first message.\n\n* Fix panic on SIGUSR1 caused by no reports in a given plugin category (issue\n  #832).\n\n* Fix file_match config of plugin logstreamer_input (issue #893).\n\n* StatFilter now correctly handles values from integer or float fields (issue\n  #612).\n\nFeatures\n--------\n\n* Added general purpose HttpOutput (issue #820).\n\n* Added message processing stat reporting to the MultiDecoder for each\n  subdecoder and in aggregate (issue #719).\n\n* Added memory statistics to the Heka report output, for self monitoring.\n\n* Added a message type configuration option to the rsyslog decoder (issue #907).\n\n* Added `elasticsearch` Lua module to generate BulkAPI index JSON (issue #875).\n\n* Added support for Lua sandbox preservation versioning (issue #701).\n\n* Added support for unix datagram sockets to the UdpInput using net \"unixgram\"\n  (issue #790).\n\n* Add LogstreamInput seekjournal reporting to dashboard output (issue #445).\n\n* Added a HyperLogLog library to the Lua sandbox using the Redis\n  implementation http://antirez.com/news/75.\n\n* Added an alert encoder to make the alert messages easier to read.\n\n* Introduced Encoder plugin type (issue #417).\n\n* Added a bloom filter to the Lua sandbox and created a unique items filter.\n\n* Turned the MySQL slow query log examples into a deployed decoder and filter.\n\n* Added an Nginx error log decoder (issue #785)\n\n* Added the ability to preserve the webserver log line in message payload\n  (issue #784)\n\n* Added the optional 'pid_file' configuration setting (issue #777).\n\n* Add anomaly, alert, annotation modules (issue #677)\n\n* Added 'sample_denominator' global config setting to allow tweaking the\n  sample interval when computing timing of certain operations, replacing prior\n  hard-coded DURATION_SAMPLE_DENOMINATOR constant (issue #625).\n\n* Added an Apache access log decoder based on the Apache 'LogFormat'\n  configuration directive.\n\n* Added BufferedOutput. Extracts the queuing functionality out of TcpOutput.go\n  into a general purpose lib for use in any output module. Callers get\n  messages buffered to disk while another goroutine consumes and forwards\n  data. Any errors encountered can cause the sending goroutine to backoff and\n  resend data.\n\n* Added http_timeout to elasticsearch output to prevent slow or stale\n  connections from holding up the flow. (issue #769)\n\n* Add query parameters to the Message as Fields in the HttpListenInput\n\n* Add QueueTTL option to AMQPInput to allow specifying message expiration.\n\n* Added optional tls sub-section to AMQPInput and AMQPOutput for configuring\n  AMQPS TLS settings.\n\n* Add detection and handling of gzipped files to LogstreamerInput (issue #648).\n\n* Added optional TCP Keep-Alive parameters to TcpInput/TcpOutput plugins.\n\n0.5.2 (2014-05-16)\n==================\n\nBug Handling\n------------\n\n* FileOutput no longer panics when using `format = \"text\"` and payload is nil\n  (issue #843).\n\n* Fix SandboxDecoder pass-through case so decoders that only use write_message\n  and not inject_message will emit messages correctly (issue #844).\n\n* Fixed TcpInput so it will only override the default delimiter for a\n  RegexpParser if a delimiter is specified in the config.\n\n* Fix the FileOutput panic when HUP'ed.  Modified the CheckWritePermission\n  utility function to use a unique filename for each check. (issue #808)\n\n* Terminated plugins are now removed from the SandboxManager quota (issue\n  #774).\n\n* Fixed SIGUSR1 triggered text report to stdout to work with updated\n  heka.all-report JSON data structure (issue #762).\n\n* MultiDecoder now uses message.GetType() instead of Message.Type so\n  emitted message type will be generated correctly (issue #761).\n\n* LogstreamerInput no longer causes Heka to fail to start on empty or\n  whitespace-only journal files (issue #755).\n\n* The cbufd_host_aggregator filter now properly reclaims expired hosts.\n\n* Pull in a new lua_sandbox to fix JSON encoding of empty strings in the\n  sandbox plugin output() call.\n\n* Escape regexp meta characters (notably '\\') to prevent a panic in the LogstreamerInput on Windows\n\n0.5.1 (2014-03-18)\n==================\n\nBug Handling\n------------\n\n* Skip *.bak, *.tmp, *~, and .files in a config dir as a non-breaking band-aid\n  until we require an explicit naming convention in 0.6 (see issue #750).\n\n* heka-logstreamer command now supports config directories in addition to\n  single config files, just like hekad itself (issue #742).\n\n* Logstreamer package's NewLogstreamSet function no longer lowercases the\n  match part names when constructing match translation maps since the\n  PopulateMatchParts method doesn't actually expect the names to be\n  lowercased.\n\n* Added support for use of \"missing\" value in Logstreamer translation maps to\n  allow users to place missing values at the end of the list instead of the\n  beginning (issue #735).\n\n0.5.0 (2014-03-06)\n==================\n\nBackwards Incompatibilities\n---------------------------\n\n* ProcessInput no longer supports a separate'name' config setting, it uses the\n  specified plugin name from the TOML section header like all of the other\n  plugins.\n\n* Removed Stdout_chan and Stderr_chan from ManagedCmd and CommandChain, client\n  code now has direct access to Stdout_r and Stderr_r io.Reader providers.\n\n* The PluginHelper interface DecoderRunner prototype has changed (issue #717)\n  to allow for the base name e.g. \"ProtobufDecoder\" and a full instance name\n  e.g. \"MyInput-ProtobufDecoder\" of the decoder to be specified.  This allows\n  multiple decoders of the same type to show up on the DashboardOutput and\n  sandbox decoder state preservation to work properly. Also the DecoderRunner\n  UUID interface method was removed.\n\n* FileOutput `flushinterval` config setting changed to `flush_interval` to\n  match config naming conventions.\n\n* SandboxDecoder, SandboxFilter, and SandboxManagerFilter now all use\n  `${SHARE_DIR}/lua_modules` as the default `module_directory` setting.\n  SandboxDecoder and SandboxFilter both now interpret relative paths to lua\n  source code to be relative to ${SHARE_DIR} instead of ${BASE_DIR}.\n\n* DashboardOutput `static_directory` setting now defaults to\n  `${SHARE_DIR}/dasher` instead of `${BASE_DIR}/dashboard_static`.\n\n* The sandbox preservation data is now stored in the\n  {base_dir}/sandbox_preservation directory instead of with the plugin source.\n  On the initial restart no preserved data will be restored unless it is\n  manually moved to this directory first. (issue #626)\n\n* The Heka utilities (flood, sbmgr, sbmgrload, inject) have been namespaced\n  with a `heka-` prefix for their respective binaries. I.e. Flood has been\n  renamed heka-flood., etc.\n\n* MultiDecoder now gets its name from the TOML section name like the rest of\n  the plugins, instead of a separate 'name' config option.\n\n* Major reorganization of the `pipeline` package, moving the implementation of\n  most plugins to sub-packages of a separate `plugins` package.\n\n* Removed the wrapper 'table' element from the JSON serialization (issue #525)\n  i.e., {\"table\":{\"value\":1}} is now simply {\"value\":1}.  The change also\n  removes the special '_name' metadata arribute; the top level _name element\n  should be created in the Lua structure if it is required.\n\n* In the process of removing the core sandbox code from Heka (issue #464), the\n  sandbox was streamlined to only load the base library by default. All sandbox\n  plugins must now explictly load additional libraries with the require\n  function.\n\n* Removed DecoderSet method from PluginHelper interface (and DecoderSet\n  abstraction entirely) and replaced it with Decoder and DecoderRunner methods\n  that return a Decoder or a DecoderRunner by name.\n\n* Changed Decoder interface to support one input pack generating multiple\n  output packs.\n\nBug Handling\n------------\n\n* Network parsers now return all records available in the parse buffer\n  (issue #732).\n\n* TcpInput now stops a given connection's decoder when the connection is\n  closed, preventing memory pooling (issue #713).\n\n* StatsdInput now doesn't fail with multiple stats in a single UDP packet.\n\n* Set default StatAccumInput stat namespace prefix values even when\n  `legacy_namespaces` is set to false (issue #630).\n\n* Fixed cpuprof file from being closed right after opening so no data was\n  being logged.\n\n* Fixed LogfileInput so it will only override the default delimiter for a\n  RegexpParser if a delimiter is specified in the config.\n\n* PluginWrapper will now check for the WantsName interface when creating a\n  plugin, and will set the plugin's name if appropriate.\n\n* SandboxDecoder now explicitly logs a fatal error before triggering shutdown\n  to ensure error message is actually emitted.\n\n* Message severity now defaults to the highest RFC 5424 value (i.e. 7) implies\n  low severity, rather than zero, which implies `emergency`, (issue #518).\n\n* 'flood' command now outputs every send error (even 'connection refused'), and\n  always increments 'messages sent' count even when there is a sending error\n  (so setting 'num_messages' still works even if hekad stops responding,\n  etc.).\n\n* stat_accum_input will not fail when flushing a timer where the percentile\n  is equal to the min value.\n\nFeatures\n--------\n\n* Added ProcessDirectoryInput.\n\n* InputRunners now support being specified as 'transient', meaning their\n  lifespan should be managed by the code that creates the InputRunner and not\n  Heka's pipeline code.\n\n* HttpInput: now supports configuring the HTTP method, HTTP headers and HTTP\n  Basic Authentication\n\n* TLS Listeners can specify a 'client_cafile' which limits the CAs that a\n  client cert can be chained to. This provides a mechanism for TLS Client AUTH.\n\n* TLS Senders can specify a 'root_cafile' which limits the CAs that a\n  server cert can be chained to. This provides a mechanims for TLS Server AUTH.\n\n* Added StopDecoderRunner function to PluginHelper API so inputs can manually\n  decommission decoders when they're no longer being used.\n\n* The SandboxManagerFilter can now control the sandbox usage limits (issue #95)\n\n* Added support for send_nsca to NagiosOutput as an alternative to direct http\n  submission; also a way to explicitely specify service_description and host\n  to match Nagios config\n\n* Added configurable network types to TcpInput \"tcp\", \"tcp4\", \"tcp6\", \"unix\" and\n \"unixpacket\" (issue #539)\n\n* Added configurable network types to UdpInput \"udp\", \"udp4\", \"udp6\"\n  (issue #539)\n\n* Added flush_count config setting to FileOutput to complement existing\n  flush_interval. Also added flush_operator setting which can be \"AND\" or \"OR\"\n  to specify how flush_count and flush_interval should be combined.\n\n* Introduced `share_dir` global config setting, which specifies where Heka's\n  read only resources should live. Defaults to `/usr/share/heka`. Also added\n  `pipeline.PrependShareDir()` function for use within plugin initialization\n  code.\n\n* Added an rsyslog decoder based on the rsyslog string configuration template\n  (issue #432).\n\n* Added an Nginx access log decoder based on the Nginx 'log_format'\n  configuration directive.\n\n* heka-cat: A command-line utility for counting, viewing, filtering, and\n  extracting Heka protobuf logs.\n\n* TcpOutput has been redesigned to handle unavailable endpoints and dropped\n  connections without data loss (issue #355).\n\n* CarbonOutput now supports submitting messages via UDP, persistent TCP\n  connection.\n\n* Added Logstreamer Input [LogstreamerInput]: An input that replaces the\n  Logfile and Logfile Directory Inputs and supports sequential reading of\n  logstreams that span sets of ordered logfiles (issue #372).\n\n* TcpInput, TcpOutput, and flood client now all support TLS encrypted TCP\n  connections using Go's crypto/tls package.\n\n* Added Http Listen Input [HttpListenInput]: An input that listens for\n  HTTP requests on the specified address. If a decoder is not specified the\n  input generates a message with the HTML request body as the payload.\n  This input is especially useful for consuming and processing webhooks.\n  (Issue #431)\n\n* Added support for local external packages (issue #393)\n\n* Inject: A command-line utility for injecting arbitrary messages into\n  a Heka pipeline.\n\n* Added Go ScribbleDecoder for efficient setting of purely static message\n  field values.\n\n* Exposed `write_message` API function to Lua decoders to allow mutation of\n  existing decoded message (issue #577).\n\n* HttpInput: Added urls (array) option.\n\n* HttpInput: Failed and successful HTTP GET actions produce messages of Type\n  \"heka.httpinput.data\", Logger = Request URL, and severity appropriate to\n  HTTP status 200 or not. I.e. Connections responding with a status of 200\n  produce a message with Severity 6, non-200 statuses Severity 1. Failure to\n  connect produces a message with Severity 1 and Type \"heka.httpinput.error\".\n\n* HttpInput: Fields[ResponseTime] populates with time duration in seconds for\n  HTTP GET of URL, Fields[Status] with HTTP Status, Fields[Protocol] with HTTP\n  protocol and version, Fields[StatusCode] with HTTP Response Status Code for\n  successful HTTP GETs. The Circular Buffer Graph Annotation (Alerts)\n  (https://hekad.readthedocs.io/en/latest/sandbox/graph_annotation.html) plugin\n  is compatible with the HttpInput plugin.\n\n* HttpInput: Added success_severity and error_severity options for GET actions.\n\n* HttpInput: Messages now set Logger, UUID, and Timestamp.\n\n* Added log_errors option to PayloadregexDecoder to allow skipping invalid\n  payloads.\n\n* Added \"id\" flag to elasticsearch output (issue #386).\n\n* Added SmtpOutput (issue #472)\n\n* Added preserve_data option to SandboxDecoder (issue #668).\n\n* Added delete_idle_stats to StatAccumInput.\n\n* Added sum and count_ps metrics to timers in stat_accum_input.\n\n0.4.2 (2013-12-02)\n==================\n\nBug Handling\n------------\n\n* Changed CPack configuration such that the 'make package' target no longer\n  creates deb packages, and added a new 'make deb' target that creates debs\n  with the filename expected by the deb package naming conventions (see\n  https://github.com/mozilla-services/heka/issues/545).\n\n* Doc clarifications re: required use of ProtobufDecoder (see\n  https://github.com/mozilla-services/heka/issues/550).\n\n* Explicitly exclude system level folders from those that CPack will include\n  as part of the Heka RPM (requires CMake >= 2.8.12) (see\n  https://github.com/mozilla-services/heka/issues/548).\n\n0.4.1 (2013-11-05)\n==================\n\nBug Handling\n------------\n\n* Updated Mozilla Sphinx theme submodule reference and configuration paths to\n  work around bug in ReadTheDocs rendering (see\n  https://github.com/rtfd/readthedocs.org/issues/529).\n\n* Changed default DashboardOutput.StaticDirectory value to\n  `/usr/share/heka/dasher`, to match where the packages put the files.\n\nFeatures\n--------\n\n* add require_all_fields flag to PayloadJsonDecoder\n  (issue #528)\n\n0.4.0 (2013-10-30)\n==================\n\nBackwards Incompatibilities\n---------------------------\n\n* DashboardOutput now requires a `static_directory` setting to specify where\n  the Heka dashboard source code can be found.\n\n* AMQPInput now only supports a single decoder to be specified (issue #414).\n\n* UdpInput configuration now requires a parser_type and decoder to be specified\n  (issue #411).\n\n* TcpInput configuration now requires a parser_type and decoder to be specified\n  (issue #165).\n\n* Removed the LogfileInput decoders array configuration in favor of a single\n  decoder (issue #308).\n\n* SandboxManagerFilter now auto-generates a default working directory based on\n  the plugin name, in the ${BASE_DIR}/sbxmgrs folder.\n\n* LogfileInput seek journals now support a boolean `use_seek_journal` config\n  flag, and only the name of the journal file is now settable via\n  `seek_journal_name`, replacing the `seekjournal` option which specified the\n  full path.\n\n* Build is now entirely cmake based and lives directly in the heka repository,\n  replacing the separate primarily gnu make driven separate heka-build repo.\n\n* Core Heka plugins now default to writing data to /var/cache instead of\n  /var/run since /var/run is usually deleted on server restart.\n\n* StatAccumInput now defaults to emitting stats data in the payload instead of\n  in the message fields.\n\n* Renamed LoglineDecoder to PayloadRegexDecoder.\n\nBug Handling\n------------\n\n* Added check for nil RemoteAddr value since UDP connections won't have one\n  (issue #462).\n\n* Statsd messages are now parsed manually (issue #44).\n\n* Added mDRunner so MultiDecoder will work with sub-decoders that implement\n  the WantsDecoderRunner interface.\n\n* Removed all code that attempted to catch and recover from panics in called\n  plugin code, since a) the recovery often left Heka in an undefined, broken\n  state b) the safety was a lie, any panic in a separate goroutine would not\n  be caught and c) panic traceback actually makes it easier to debug.\n\n* WhisperOutput and CarbonOutput no longer require stats to use the `stats`\n  namespace prefix.\n\n* LogfileInput now truncates and overwrites the seek journals instead of\n  appending.\n\n* `protoc` now an optional dependency for the build, only required if the\n  protobuf definition is actually changed.\n\n* MessageTemplate field name interpolation was only supporting alphabetic\n  characters for field names, now supports all \"word\" characters (i.e.\n  alphanumeric plus underscore).\n\n* ElasticSearchOutput now always sends timestamps in expected UTC time zone\n  format.\n\n* Fixed a CarbonOutput memory / socket leak.\n\n* Fixed panic caused by an invalid config file path.\n\nFeatures\n--------\n\n* Added a sandbox message field iterator (issue #460)\n\n* Added ProcessInput. (issue #406)\n\n* Replaced DashboardOutput UI with new Backbone.js-based `dasher` interface.\n  (issue #378)\n\n* Add delta output to circular buffers. (issue #467)\n\n* Added json decoding to the Lua sandbox (issue #463). If you have an old build\n  directory you will have to run make clean to pick up the new patch.\n\n* Added a 'config' variable section to the Sandbox decoder/filter plugin.\n  (issue #444)\n\n* Added StatsToFieldsDecoder that will convert a message with statsd formatted\n  string in the payload to one that also has the data available as message\n  fields, in the same format that would be generated by a StatAccumInput with\n  `emit_in_fields` set to true.\n\n* MultiDecoder now supports `cascade_strategy` config options of `first-wins`\n  and `all`, defaults to `first-wins`.\n\n* Added stream parsing to UdpInput. (issue #411)\n\n* Added stream parsing to TcpInput. (issue #165)\n\n* Added SandboxDecoder. (issue #370)\n\n* Support Heka protobuf message data in the LogfileInput plugin. (issue #261)\n\n* Added \"payload\" format option to ElasticSearchOutput to pass message payload\n  through to ES unchanged.\n\n* Allow LogfileInput to use configurable delimiters including regexp (issue #263)\n  This includes a backwards incompatible change for the journal file, old\n  journals will not be honored and the new journal will overwrite it.\n\n* Allow add_external_plugin to specify sub-packages. (issue #384)\n\n* Added `base_dir` global (i.e. `[hekad]` section) config option to specify a\n  single location Heka plugins should use to persist data to the file system.\n\n* The `hekad` commands `config` flag now supports use of a config directory in\n  addition to a single config file. If a directory path is specified, every\n  file in the directory will be parsed and they will all be merged to a single\n  running configuration.\n\n* Added LogfileDirectoryManagerInput (issue #344).\n\n* LPEG library added to Lua sandbox (issue #144).\n\n* ElasticSearchOutput now supports `logstash_v0` output format that is modeled\n  after the original Logstash ElasticSearch message schema.\n\n* Added PayloadJsonDecoder that can extract information from JSON text in a\n  message payload during decoding.\n\n* Make index type_name option for ElasticSearchOutput definable from Field value (issue #356)\n\n0.3.0 (2013-07-16)\n==================\n\n* Fixed default (and only supported, for now) sample rate in the stats\n  generated by the StatFilter.\n\n* Fixes to the platform specific build constraints around signal handling.\n\n* Added HttpInput that can make HTTP requests to a remote server, placing\n  the response body into a message payload.\n\n* Filters and outputs now require a specified message_matcher or they will\n  raise an error applying the configuration.\n\n* ticker_interval now exposed as a global config option for inputs, as well\n  as outputs and filters.\n\n* Overhaul of StatAccumInput implementation to fix bugs and allow for better\n  handling of output format options.\n\n* LoglineDecoder will now default to the current day, month, and year when\n  parsing text that contains bare timestamps w/ no date information.\n\n* Added permission checks to FileOutput and WhisperOutput plugins to fail\n  gracefully when they've been asked to write to a location where they do not\n  have write permission.\n\n* Fixed folder creation permission bugs and allow configurable folder\n  permission settings in FileOutput and WhisperOutput.\n\n* `hekad` now emits help message if started w/ no command line options.\n\n* Consistently use underscore_separated_words for plugin TOML configuration\n  options.\n\n* Use strings instead of integers to specify octal permission values in the\n  config, since TOML doesn't support octal integer values.\n\n* LoglineDecoder config now allows specification of a time zone in case the\n  parsed text contains non-UTC timestamps that don't include embedded time\n  zone information.\n\n* Removed match capture group support from the router's message matching\n  functionality, since this is better done in the decoder layer where the\n  back-pressure won't slow down all message delivery. This gets rid of the\n  `PipelineCapture` object altogether, so now filter and output plugins deal\n  w/ PipelinePacks directly.\n\n* Added ElasticSearch output.\n\n* Lua filters can now emit tables, which will be serialized to JSON and\n  put in an injected message payload.\n\n* Custom dashboard javascript now generated by Heka instead of hosted\n  remotely.\n\n* Improvements to flood, a Heka protocol load test client.\n\n* Config loading now fails if a config section specifies an unrecognized\n  configuration option.\n\n* StatAccumulator now supports stat metric messages with stats data embedded\n  in message fields as well as message payload.\n\n* Added support for plugin code to provide message_matcher and ticker_interval\n  default values.\n\n* Reimplemented StatMonitor as StatAccumInput, providing a StatAccumulator\n  interface.\n\n* SIGUSR1 signals now generate Heka report on stdout instead of sending\n  a message so it can be viewed even when message delivery is hosed.\n\n* Added explicit Close() calls to whisperdb files in WhisperOutput.\n\n* Redesigned message field metadata to use string specifiers instead of\n  an enum.\n\n* Lua filters can now emit multiple named outputs to the Heka dashboard.\n\n* LogfileInput now supports just one file per input.\n\n* Removed race conditions exposed by Go's race detector.\n\n* Improved self monitoring / dashboard output.\n\n* Improved shutdown message flushing.\n\n* Added Nagios output.\n\n* Added support for LogfileInput to resume parsing where it left off.\n\n* Added AMQP input and output plugins.\n\n* Improved control over sandbox filter message injection restrictions.\n\n* Added support for restartable plugins.\n\n* Moved regular expression and capture group parsing out of the filter layer\n  (i.e. in the TransformFilter) and into the decoder layer (i.e.\n  LoglineDecoder) to prevent back pressure from impacting the entire router.\n\n0.2.0 (2013-06-26)\n==================\n\n* Fix stat name regex to capture \".\" characters in the name.\n\n0.2.0rc2 (2013-05-23)\n=====================\n\n* Fix Lua sandbox C code to work on 32 bit systems.\n\n* Trivial release documentation ReST formatting fix.\n\n0.2.0rc1 (2013-05-21)\n=====================\n\n* Use non-https links in docs to prevent bad rendering due to mixed http/https\n  content.\n\n* A number of documentation tweaks and updates.\n\n* Static linking of cgo wrapped Lua environment.\n\n* Added LICENSE.txt and CHANGES.txt for better project hygiene.\n\n* Changed default interval for log file reading from 1ms to 500ms so we don't\n  churn the machine in default configuration.\n\n* Moved StatPacket channel setup into StatsdInput's Init method (from Run) to\n  avoid race conditions.\n\n* Added support for mingw-based Windows build.\n\n* Perform message injection in a goroutine to prevent blocking the router when\n  the plugin that is doing the injection has a full in channel.\n\n* Added required pack recycling to TcpOutput.\n\n0.2.0b1 (2013-04-30)\n====================\n\n* Initial public release\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 16.5068359375,
          "content": "# This Source Code Form is subject to the terms of the Mozilla Public\n# License, v. 2.0. If a copy of the MPL was not distributed with this\n# file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\ncmake_minimum_required(VERSION 2.8.7 FATAL_ERROR)\nproject(heka C)\nset(CPACK_PACKAGE_DESCRIPTION_SUMMARY \"High performance data gathering, analysis, monitoring, and reporting.\")\nset(CPACK_PACKAGE_VERSION_MAJOR 0)\nset(CPACK_PACKAGE_VERSION_MINOR 11)\nset(CPACK_PACKAGE_VERSION_PATCH 0)\nset(CPACK_PACKAGE_VENDOR \"Mozilla\")\nset(CPACK_RESOURCE_FILE_LICENSE \"${CMAKE_SOURCE_DIR}/LICENSE.txt\")\nset(CPACK_PACKAGE_CONTACT \"heka@mozilla.org\")\nset(CPACK_PACKAGE_NAME ${CMAKE_PROJECT_NAME})\n\nset(CMAKE_MODULE_PATH \"${CMAKE_SOURCE_DIR}/cmake\")\n\nfind_package(Go 1.4 REQUIRED)\nfind_package(Git REQUIRED)\nfind_package(Protobuf 2.3 QUIET)\nset(CPACK_PACKAGE_FILE_NAME ${CMAKE_PROJECT_NAME}-${CPACK_PACKAGE_VERSION_MAJOR}_${CPACK_PACKAGE_VERSION_MINOR}_${CPACK_PACKAGE_VERSION_PATCH}-${GO_PLATFORM}-${GO_ARCH})\nif (NOT DEFINED CMAKE_INSTALL_PREFIX)\n    set(CMAKE_INSTALL_PREFIX ${CMAKE_PROJECT_NAME})\nendif()\nset(PROJECT_PATH \"${CMAKE_BINARY_DIR}/heka\")\nset(HEKA_PATH \"${PROJECT_PATH}/src/github.com/mozilla-services/heka\")\nset(LUA_INCLUDE_PATH \"${PROJECT_PATH}/include\")\nset(LUA_LIB_PATH \"${PROJECT_PATH}/lib\")\nset(HEKA_EXE \"${PROJECT_PATH}/bin/hekad${CMAKE_EXECUTABLE_SUFFIX}\")\nset(FLOOD_EXE \"${PROJECT_PATH}/bin/heka-flood${CMAKE_EXECUTABLE_SUFFIX}\")\nset(SBMGR_EXE \"${PROJECT_PATH}/bin/heka-sbmgr${CMAKE_EXECUTABLE_SUFFIX}\")\nset(SBMGRLOAD_EXE \"${PROJECT_PATH}/bin/heka-sbmgrload${CMAKE_EXECUTABLE_SUFFIX}\")\nset(INJECT_EXE \"${PROJECT_PATH}/bin/heka-inject${CMAKE_EXECUTABLE_SUFFIX}\")\nset(LOGSTREAMER_EXE \"${PROJECT_PATH}/bin/heka-logstreamer${CMAKE_EXECUTABLE_SUFFIX}\")\nset(HEKA_CAT_EXE \"${PROJECT_PATH}/bin/heka-cat${CMAKE_EXECUTABLE_SUFFIX}\")\n\noption(INCLUDE_SANDBOX \"Include Lua sandbox\" on)\noption(INCLUDE_MOZSVC \"Include the Mozilla services plugins\" on)\noption(INCLUDE_DOCKER_PLUGINS \"Include Docker plugins\" on)\n\nfind_path(INCLUDE_GEOIP GeoIP.h /usr/local/include /usr/include /opt/local/include)\nif (NOT INCLUDE_GEOIP)\n    message(STATUS \"GeoIP.h was not found, GeoIP functionality will not be included in this build.\")\nelse()\n    message(STATUS \"GeoIP.h found. Enabling GeoIP plugin.\")\n    set(TAGS \"${TAGS} geoip\")\n    set(PLUGIN_LOADER ${PLUGIN_LOADER} \"github.com/mozilla-services/heka/plugins/geoip\")\nendif()\n\nif (INCLUDE_DOCKER_PLUGINS)\n    message(STATUS \"Docker plugins enabled.\")\n    set(PLUGIN_LOADER ${PLUGIN_LOADER} \"github.com/mozilla-services/heka/plugins/docker\")\nendif()\n\noption(BENCHMARK \"Enable the benchmark tests\" off)\nif (BENCHMARK)\n    set(BENCHMARK_FLAG -bench .)\nendif()\n\noption(COVERAGE \"Enable code coverage\" off)\nif (COVERAGE)\n    set(COVERAGE_FLAG -coverprofile coverage.out)\nendif()\n\nset(INCLUDE_DOCUMENTATION true)\nfind_program(SPHINX_BUILD_EXECUTABLE sphinx-build PATH_SUFFIXES bin)\nif (NOT SPHINX_BUILD_EXECUTABLE)\n    message(STATUS \"sphinx-build was not found, the documentation will not be generated.\")\n    set(INCLUDE_DOCUMENTATION false)\nendif()\n\nset(LUA_SHARED_LIBRARY_SUFFIX ${CMAKE_SHARED_LIBRARY_SUFFIX})\nif (MINGW)\n    set(ADDRESS_MODEL 64)\n    if (GO_ARCH STREQUAL \"386\")\n        set(ADDRESS_MODEL 32)\n    endif()\n    set(LDFLAGS \"-ldflags=\\\"-s\\\"\")\n    set(CGO_LDFLAGS \"cgo LDFLAGS: ${LUA_LIB_PATH}/libluasandbox.dll ${LUA_LIB_PATH}/libluasb.dll -lm\")\n    set(CPACK_GENERATOR \"ZIP\")\nelseif(APPLE)\n    set(CPACK_GENERATOR \"PackageMaker\")\n    set(LDFLAGS \"-ldflags=\\\"-linkmode=external\\\"\")\n    set(CGO_LDFLAGS \"cgo LDFLAGS: ${LUA_LIB_PATH}/libluasandbox.dylib ${LUA_LIB_PATH}/libluasb.dylib -ldl -lm\")\n    set(LUA_SHARED_LIBRARY_SUFFIX \".so\")\nelseif(UNIX)\n    set(CPACK_GENERATOR \"TGZ\")\n    set(LDFLAGS \"-ldflags=\\\"-s\\\"\")\n    if(NOT CMAKE_SYSTEM_NAME MATCHES \"FreeBSD\")\n        set(LINK_DL \"-ldl\")\n    endif()\n    set(CGO_LDFLAGS \"cgo LDFLAGS: -Wl,-rpath,$ORIGIN/../lib ${LUA_LIB_PATH}/libluasandbox.so ${LUA_LIB_PATH}/libluasb.so ${LINK_DL} -lm\")\n\n    find_program(DPKG_EXECUTABLE dpkg PATH_SUFFIXES bin)\n\n    find_program(RPMBUILD_EXECUTABLE rpmbuild PATH_SUFFIXES bin)\n    if (RPMBUILD_EXECUTABLE)\n        set(CPACK_GENERATOR ${CPACK_GENERATOR} \"RPM\")\n        set(CPACK_RPM_PACKAGE_LICENSE \"MPLv2.0\")\n        set(CPACK_RPM_PACKAGE_DESCRIPTION \"Heka is a tool for collecting and collating data from a number of different sources, performing 'in-flight' processing of collected data, and delivering the results to any number of destinations for further analysis.\")\n\t# todo we should pull lua_sandbox out of the heka/build and packaging\n\tset(CPACK_RPM_PACKAGE_PROVIDES \"libluasb.so.0()(64bit), libluasandbox.so.0()(64bit)\")\n\tset(CPACK_RPM_EXCLUDE_FROM_AUTO_FILELIST_ADDITION /usr/share/man)\n        set(CPACK_RPM_PACKAGE_REQUIRES_PRE \"shadow-utils\")\n        set(CPACK_RPM_PRE_INSTALL_SCRIPT_FILE \"${CMAKE_SOURCE_DIR}/rpm/heka.preinst.in\")\n        set(CPACK_RPM_POST_INSTALL_SCRIPT_FILE \"${CMAKE_SOURCE_DIR}/rpm/heka.postinst.in\")\n    endif()\nendif()\n\ninclude(CTest)\ninclude(externals)\ninclude(mocks)\n\nexecute_process(COMMAND \"${GIT_EXECUTABLE}\" submodule update --init --recursive\nWORKING_DIRECTORY \"${CMAKE_SOURCE_DIR}\"\nRESULT_VARIABLE error_code\n)\nif(error_code)\n    message(FATAL_ERROR \"Failed to init Heka submodules\")\nendif()\n\nconfigure_file(\"${CMAKE_SOURCE_DIR}/sandbox/lua/lua_sandbox.go.in\" \"${HEKA_PATH}/sandbox/lua/lua_sandbox.go\" @ONLY)\n\nif (EXISTS \"${CMAKE_BINARY_DIR}/plugin_loader.go\")\n    configure_file(\"${CMAKE_BINARY_DIR}/plugin_loader.go\" \"${HEKA_PATH}/cmd/hekad/plugin_loader.go\" COPYONLY)\nendif()\n\nadd_custom_target(clean-heka\nCOMMAND ${CMAKE_COMMAND} -E remove_directory \"${HEKA_PATH}\"\nCOMMAND ${CMAKE_COMMAND} -E remove \"${HEKA_EXE}\" \"${FLOOD_EXE}\" \"${SBMGR_EXE}\" \"${SBMGRLOAD_EXE}\" \"${INJECT_EXE}\"\nCOMMAND ${CMAKE_COMMAND} ..\nCOMMENT \"Resynchronizing the Go workspace with the Heka repository\"\n)\n\nset(MESSAGE_PROTO_OUT \"${CMAKE_SOURCE_DIR}/message/message.pb.go\")\nadd_custom_command(\nOUTPUT ${MESSAGE_PROTO_OUT}\nCOMMAND ${CMAKE_COMMAND} -DSRC_DIR=\"${CMAKE_SOURCE_DIR}\" -DPROTOBUF_EXECUTABLE=\"${PROTOBUF_EXECUTABLE}\" -P \"${CMAKE_SOURCE_DIR}/cmake/message_proto.cmake\"\nDEPENDS \"${CMAKE_SOURCE_DIR}/message/message.proto\"\nWORKING_DIRECTORY \"${CMAKE_SOURCE_DIR}/message\"\nCOMMENT \"Built ${MESSAGE_PROTO_OUT}\"\n)\n\nif(INCLUDE_SANDBOX)\nset(COPY_SANDBOX COMMAND ${CMAKE_COMMAND} -E copy_directory \"${CMAKE_SOURCE_DIR}/sandbox\" \"${HEKA_PATH}/sandbox\")\nendif()\nadd_custom_target(heka_source ALL\nCOMMAND ${CMAKE_COMMAND} -E copy_directory \"${CMAKE_SOURCE_DIR}/client\" \"${HEKA_PATH}/client\"\nCOMMAND ${CMAKE_COMMAND} -E copy_directory \"${CMAKE_SOURCE_DIR}/cmd\" \"${HEKA_PATH}/cmd\"\nCOMMAND ${CMAKE_COMMAND} -E copy_directory \"${CMAKE_SOURCE_DIR}/docs\" \"${HEKA_PATH}/docs\"\nCOMMAND ${CMAKE_COMMAND} -E copy \"${CMAKE_SOURCE_DIR}/CHANGES.txt\" \"${HEKA_PATH}/docs\"\nCOMMAND ${CMAKE_COMMAND} -E copy_directory \"${CMAKE_SOURCE_DIR}/examples\" \"${HEKA_PATH}/examples\"\nCOMMAND ${CMAKE_COMMAND} -E copy_directory \"${CMAKE_SOURCE_DIR}/message\" \"${HEKA_PATH}/message\"\nCOMMAND ${CMAKE_COMMAND} -E copy_directory \"${CMAKE_SOURCE_DIR}/pipeline\" \"${HEKA_PATH}/pipeline\"\nCOMMAND ${CMAKE_COMMAND} -E copy_directory \"${CMAKE_SOURCE_DIR}/plugins\" \"${HEKA_PATH}/plugins\"\nCOMMAND ${CMAKE_COMMAND} -E copy_directory \"${CMAKE_SOURCE_DIR}/logstreamer\" \"${HEKA_PATH}/logstreamer\"\nCOMMAND ${CMAKE_COMMAND} -E copy_directory \"${CMAKE_SOURCE_DIR}/ringbuf\" \"${HEKA_PATH}/ringbuf\"\n${COPY_SANDBOX}\nDEPENDS ${SANDBOX_PACKAGE} GoPackages ${MESSAGE_PROTO_OUT}\n)\n\nadd_custom_target(message_matcher_parser ALL\nCOMMAND ${GO_EXECUTABLE} tool yacc -l=false -o=message_matcher_parser.go message_matcher_parser.y\nDEPENDS heka_source\nWORKING_DIRECTORY \"${HEKA_PATH}/message\"\n)\nadd_dependencies(mocks message_matcher_parser)\n\nadd_custom_target(hekad ALL\n${GO_EXECUTABLE} install ${LDFLAGS} -tags=${TAGS} github.com/mozilla-services/heka/cmd/hekad\nDEPENDS mocks)\n\nif (INCLUDE_DOCUMENTATION)\n    add_custom_target(docs\n    COMMAND ${SPHINX_BUILD_EXECUTABLE} -b html -d build/doctrees source build/html\n    COMMAND ${SPHINX_BUILD_EXECUTABLE} -b man -d build/doctrees source build/man\n    WORKING_DIRECTORY \"${HEKA_PATH}/docs\"\n    DEPENDS heka_source\n    COMMENT \"Built Heka user/developer documentation\")\n\n    install(CODE \"execute_process(COMMAND ${CMAKE_BUILD_TOOL} docs)\") # always force the docs to rebuild before installing/packaging\n    install(DIRECTORY \"${HEKA_PATH}/docs/build/man/\" DESTINATION share/man/man1 FILES_MATCHING PATTERN \"*.1\")\n    install(DIRECTORY \"${HEKA_PATH}/docs/build/man/\" DESTINATION share/man/man5 FILES_MATCHING PATTERN \"*.5\")\nendif()\n\nif (INCLUDE_SANDBOX)\n    if (MINGW)\n        add_custom_command(TARGET heka_source POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy_directory \"${PROJECT_PATH}/lib/\" \"${HEKA_PATH}\"\n        COMMAND ${CMAKE_COMMAND} -E copy_directory \"${PROJECT_PATH}/lib/\" \"${HEKA_PATH}/pipeline\"\n        COMMAND ${CMAKE_COMMAND} -E copy_directory \"${PROJECT_PATH}/lib/\" \"${HEKA_PATH}/plugins\"\n        COMMAND ${CMAKE_COMMAND} -E copy_directory \"${PROJECT_PATH}/lib/\" \"${HEKA_PATH}/sandbox/lua\"\n        COMMAND ${CMAKE_COMMAND} -E copy_directory \"${PROJECT_PATH}/lib/\" \"${HEKA_PATH}/sandbox/plugins\"\n        COMMAND ${CMAKE_COMMAND} -E copy_directory \"${PROJECT_PATH}/lib/\" \"${HEKA_PATH}/cmd/hekad\"\n        COMMENT \"Install dll's for the mock generation and unit tests\")\n        install(DIRECTORY \"${PROJECT_PATH}/lib/\" DESTINATION bin PATTERN \"*.dll\" PATTERN \"luasandbox\" EXCLUDE PATTERN \"luasandbox/*\" EXCLUDE)\n    else()\n        install(DIRECTORY \"${PROJECT_PATH}/lib/\" DESTINATION lib PATTERN \"*${CMAKE_SHARED_LIBRARY_SUFFIX}\" PATTERN \"luasandbox\" EXCLUDE PATTERN \"luasandbox/*\" EXCLUDE)\n    endif()\nendif()\n\ninstall(PROGRAMS \"${HEKA_EXE}\" DESTINATION bin)\n\nadd_custom_target(flood ALL\n${GO_EXECUTABLE} install ${LDFLAGS} github.com/mozilla-services/heka/cmd/heka-flood\nDEPENDS hekad\nWORKING_DIRECTORY ${CMAKE_SOURCE_DIR})\n\ninstall(PROGRAMS \"${FLOOD_EXE}\" DESTINATION bin)\n\nadd_custom_target(inject ALL\n${GO_EXECUTABLE} install ${LDFLAGS} github.com/mozilla-services/heka/cmd/heka-inject\nDEPENDS hekad\nWORKING_DIRECTORY ${CMAKE_SOURCE_DIR})\n\ninstall(PROGRAMS \"${INJECT_EXE}\" DESTINATION bin)\n\nadd_custom_target(logstreamer ALL\n${GO_EXECUTABLE} install ${LDFLAGS} github.com/mozilla-services/heka/cmd/heka-logstreamer\nDEPENDS hekad\nWORKING_DIRECTORY ${CMAKE_SOURCE_DIR})\n\ninstall(PROGRAMS \"${LOGSTREAMER_EXE}\" DESTINATION bin)\n\nadd_custom_target(heka-cat ALL\n${GO_EXECUTABLE} install ${LDFLAGS} github.com/mozilla-services/heka/cmd/heka-cat\nDEPENDS hekad\nWORKING_DIRECTORY ${CMAKE_SOURCE_DIR})\n\ninstall(PROGRAMS \"${HEKA_CAT_EXE}\" DESTINATION bin)\n\nadd_custom_target(sbmgr ALL\n${GO_EXECUTABLE} install ${LDFLAGS} github.com/mozilla-services/heka/cmd/heka-sbmgr\nDEPENDS hekad)\n\ninstall(PROGRAMS \"${SBMGR_EXE}\" DESTINATION bin)\n\nadd_custom_target(sbmgrload ALL\n${GO_EXECUTABLE} install ${LDFLAGS} github.com/mozilla-services/heka/cmd/heka-sbmgrload\nDEPENDS hekad)\n\n## DEBIAN SPECIFIC THINGS HERE\nset(CPACK_PROJECT_CONFIG_FILE \"${CMAKE_SOURCE_DIR}/CPackConfig.cmake\")\nif (UNIX AND DPKG_EXECUTABLE)\n    get_filename_component(CMAKE_BIN_DIR ${CMAKE_COMMAND} PATH)\n    set(CPACK_COMMAND ${CMAKE_BIN_DIR}/cpack)\n\n    execute_process(COMMAND \"${DPKG_EXECUTABLE}\" --print-architecture\n        OUTPUT_VARIABLE CPACK_DEBIAN_PACKAGE_ARCHITECTURE OUTPUT_STRIP_TRAILING_WHITESPACE)\n\n    add_custom_target(deb\n        COMMAND ${CMAKE_COMMAND} -E cmake_echo_color --switch=\"$(COLOR)\" --cyan \"Run CPack packaging tool...\"\n        COMMAND ${CPACK_COMMAND} -G DEB\n        DEPENDS hekad\n        COMMENT \"Custom deb target\")\n\n    add_subdirectory(packaging/debian)\nendif()\n\n# MOVING INCLUSION OF CPACK DOWN HERE SO IT ACTUALLY GETS THE VARIABLES WE SET\ninclude(CPack)\n\nadd_test(cmd/hekad ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/cmd/hekad)\nadd_test(message ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/message)\nadd_test(pipeline ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/pipeline)\nadd_test(plugins ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/plugins)\nadd_test(plugins/amqp ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/plugins/amqp)\nadd_test(plugins/dasher ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/plugins/dasher)\nadd_test(plugins/elasticsearch ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/plugins/elasticsearch)\nadd_test(plugins/file ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/plugins/file)\nif (INCLUDE_GEOIP)\n    add_test(plugins/geoip  ${GO_EXECUTABLE} test ${LDFLAGS} -tags=${TAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/plugins/geoip)\nendif()\nadd_test(plugins/graphite ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/plugins/graphite)\nadd_test(plugins/http ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/plugins/http)\nadd_test(plugins/irc ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/plugins/irc)\nadd_test(plugins/kafka ${GO_EXECUTABLE} test -timeout 15s  ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/plugins/kafka)\nadd_test(plugins/logstreamer ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/plugins/logstreamer)\nadd_test(plugins/nagios ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/plugins/nagios)\nadd_test(plugins/payload ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/plugins/payload)\nadd_test(plugins/process ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/plugins/process)\nadd_test(plugins/smtp ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/plugins/smtp)\nadd_test(plugins/statsd ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/plugins/statsd)\nadd_test(plugins/tcp ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/plugins/tcp)\nadd_test(plugins/udp ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/plugins/udp)\nadd_test(logstreamer ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/logstreamer)\nadd_test(client ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/client)\nif(INCLUDE_SANDBOX)\n    add_test(sandbox_move_modules cmake -E copy_directory ${CMAKE_BINARY_DIR}/heka/lib/luasandbox/modules ${CMAKE_BINARY_DIR}/heka/src/github.com/mozilla-services/heka/sandbox/lua/modules)\n    add_test(sandbox ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/sandbox/lua)\n    add_test(sandbox_plugins ${GO_EXECUTABLE} test ${LDFLAGS} ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka/sandbox/plugins)\nendif()\nif (INCLUDE_MOZSVC)\n    add_test(mozsvc ${GO_EXECUTABLE} test ${BENCHMARK_FLAG} ${COVERAGE_FLAG} github.com/mozilla-services/heka-mozsvc-plugins)\nendif()\n\ninstall(FILES \"${HEKA_PATH}/cmd/heka-sbmgr/sbmgr.toml\" \"${HEKA_PATH}/cmd/heka-sbmgr/hekad.toml.sbmgr\" DESTINATION \"share/${CMAKE_PROJECT_NAME}/examples\")\ninstall(FILES \"${CMAKE_SOURCE_DIR}/LICENSE.txt\" DESTINATION \"share/${CMAKE_PROJECT_NAME}\")\ninstall(DIRECTORY \"${CMAKE_SOURCE_DIR}/dasher\" DESTINATION \"share/${CMAKE_PROJECT_NAME}\")\ninstall(DIRECTORY \"${CMAKE_SOURCE_DIR}/examples/conf/\" DESTINATION \"share/${CMAKE_PROJECT_NAME}/examples\")\nif (INCLUDE_SANDBOX)\n    install(FILES \"${HEKA_PATH}/sandbox/lua/testsupport/hekabench_cbuf_counter.lua\" DESTINATION \"share/${CMAKE_PROJECT_NAME}/examples\")\n    install(DIRECTORY \"${PROJECT_PATH}/lib/luasandbox/modules/\" DESTINATION \"share/${CMAKE_PROJECT_NAME}/lua_modules\")\n    install(DIRECTORY \"${PROJECT_PATH}/lib/luasandbox/io_modules/\" DESTINATION \"share/${CMAKE_PROJECT_NAME}/lua_io_modules\")\n    install(DIRECTORY \"${CMAKE_SOURCE_DIR}/sandbox/lua/modules/\" DESTINATION \"share/${CMAKE_PROJECT_NAME}/lua_modules\")\n    install(DIRECTORY \"${CMAKE_SOURCE_DIR}/sandbox/lua/decoders/\" DESTINATION \"share/${CMAKE_PROJECT_NAME}/lua_decoders\")\n    install(DIRECTORY \"${CMAKE_SOURCE_DIR}/sandbox/lua/filters/\" DESTINATION \"share/${CMAKE_PROJECT_NAME}/lua_filters\")\n    install(DIRECTORY \"${CMAKE_SOURCE_DIR}/sandbox/lua/encoders/\" DESTINATION \"share/${CMAKE_PROJECT_NAME}/lua_encoders\")\nendif()\n"
        },
        {
          "name": "CPackConfig.cmake",
          "type": "blob",
          "size": 0.638671875,
          "content": "# See http://www.cmake.org/Wiki/CMake:CPackPackageGenerators#Overall_usage_.28common_to_all_generators.29\n\nif(CPACK_GENERATOR MATCHES \"DEB\")\n\tset(CPACK_DEBIAN_PACKAGE_VERSION_SUFFIX \"$ENV{CPACK_DEBIAN_PACKAGE_VERSION_SUFFIX}\")\n\tset(CPACK_DEBIAN_PACKAGE_VERSION \"${CPACK_PACKAGE_VERSION_MAJOR}.${CPACK_PACKAGE_VERSION_MINOR}.${CPACK_PACKAGE_VERSION_PATCH}${CPACK_DEBIAN_PACKAGE_VERSION_SUFFIX}\")\n\tset(CPACK_PACKAGE_FILE_NAME \"${CPACK_PACKAGE_NAME}_${CPACK_DEBIAN_PACKAGE_VERSION}_${CPACK_DEBIAN_PACKAGE_ARCHITECTURE}\")\n\t# When the DEB-generator runs, we want him to run our install-script\n\tset(CPACK_INSTALL_SCRIPT ${CPACK_DEBIAN_INSTALL_SCRIPT})\nendif()\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.6015625,
          "content": "# heka_base image\nFROM golang:1.4\n\nMAINTAINER Chance Zibolski <chance.zibolski@gmail.com> (@chance)\n\nRUN     apt-get update && \\\n        apt-get install -yq --no-install-recommends \\\n        build-essential \\\n        bzr \\\n        ca-certificates \\\n        cmake \\\n        curl \\\n        git \\\n        golang-goprotobuf-dev\\\n        make \\\n        mercurial \\\n        patch \\\n        ruby-dev \\\n        protobuf-compiler \\\n        python-sphinx \\\n        wget \\\n        debhelper \\\n        fakeroot \\\n        libgeoip-dev \\\n        libgeoip1 \\\n        golang-goprotobuf-dev\n\nWORKDIR /heka\n\nEXPOSE 4352\n\nCOPY . /heka\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 0.6259765625,
          "content": "# This Source Code Form is subject to the terms of the Mozilla Public\n# License, v. 2.0. If a copy of the MPL was not distributed with this file,\n# You can obtain one at http://mozilla.org/MPL/2.0/.\n#\n# The Initial Developer of the Original Code is the Mozilla Foundation.\n# Portions created by the Initial Developer are Copyright (C) 2012\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Ben Bangert (bbangert@mozilla.com)\n#   Mike Trinkala (mtrinkala@mozilla.com)\n#   Rob Miller (rmiller@mozilla.com)\n#   Victor Ng (vng@mozilla.com)\n#   David Birdsong (david@imgix.com)\n#   Michael Gibson (michael.gibson79@gmail.com)\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 1.5576171875,
          "content": "This project is deprecated. Please see [this email]([https://mail.mozilla.org/pipermail/heka/2016-May/001059.html](https://web.archive.org/web/20230526160209/https://mail.mozilla.org/pipermail/heka/2016-May/001059.html)) for more details.\n\n# Heka\n\nData Acquisition and Processing Made Easy\n\nHeka is a tool for collecting and collating data from a number of different\nsources, performing \"in-flight\" processing of collected data, and delivering\nthe results to any number of destinations for further analysis.\n\nHeka is written in [Go](http://golang.org/), but Heka plugins can be written\nin either Go or [Lua](http://lua.org). The easiest way to compile Heka is by\nsourcing (see below) the build script in the root directory of the project,\nwhich will set up a Go environment, verify the prerequisites, and install all\nrequired dependencies. The build process also provides a mechanism for easily\nintegrating external plug-in packages into the generated `hekad`. For more\ndetails and additional installation options see\n[Installing](https://hekad.readthedocs.io/en/latest/installing.html).\n\nWARNING: YOU MUST *SOURCE* THE BUILD SCRIPT (i.e. `source build.sh`) TO\n         BUILD HEKA. Setting up the Go build environment requires changes to\n         the shell environment, if you simply execute the script (i.e.\n         `./build.sh`) these changes will not be made.\n         \nResources:\n* Heka project docs: https://hekad.readthedocs.io/\n* GoDoc package docs: http://godoc.org/github.com/mozilla-services/heka\n* Mailing list: https://mail.mozilla.org/listinfo/heka\n* IRC: #heka on irc.mozilla.org\n"
        },
        {
          "name": "build.bat",
          "type": "blob",
          "size": 0.2509765625,
          "content": "@echo off\ncall env.bat\n\nif \"%NUM_JOBS%\"==\"\" (set NUM_JOBS=1)\n\nif NOT exist %BUILD_DIR% mkdir %BUILD_DIR%\ncd %BUILD_DIR%\ncmake -DINCLUDE_MOZSVC=false -DINCLUDE_DOCKER_PLUGINS=false -DCMAKE_BUILD_TYPE=release -G\"MinGW Makefiles\" ..\nmingw32-make -j %NUM_JOBS%\n"
        },
        {
          "name": "build.sh",
          "type": "blob",
          "size": 0.1826171875,
          "content": "#!/usr/bin/env bash\n\n# set up our environment\n. ./env.sh\n\nNUM_JOBS=${NUM_JOBS:-1}\n\n# build heka\nmkdir -p $BUILD_DIR\ncd $BUILD_DIR\ncmake -DCMAKE_BUILD_TYPE=release $@ ..\nmake -j $NUM_JOBS\n"
        },
        {
          "name": "client",
          "type": "tree",
          "content": null
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "cmd",
          "type": "tree",
          "content": null
        },
        {
          "name": "coverage.txt",
          "type": "blob",
          "size": 2.1171875,
          "content": "github.com/mozilla-services/heka/cmd/hekad\t0.031s\tcoverage: 41.3% of statements\ngithub.com/mozilla-services/heka/message\t0.009s\tcoverage: 39.9% of statements\ngithub.com/mozilla-services/heka/pipeline\t0.034s\tcoverage: 48.0% of statements\ngithub.com/mozilla-services/heka/plugins\t0.021s\tcoverage: 81.7% of statements\ngithub.com/mozilla-services/heka/plugins/amqp\t0.013s\tcoverage: 52.0% of statements\ngithub.com/mozilla-services/heka/plugins/dasher\t0.007s\tcoverage: 26.9% of statements\ngithub.com/mozilla-services/heka/plugins/elasticsearch\t0.012s\tcoverage: 48.8% of statements\ngithub.com/mozilla-services/heka/plugins/file\t0.025s\tcoverage: 69.4% of statements\ngithub.com/mozilla-services/heka/plugins/geoip\t0.003s\tcoverage: 72.3% of statements\ngithub.com/mozilla-services/heka/plugins/graphite\t0.012s\tcoverage: 66.9% of statements\ngithub.com/mozilla-services/heka/plugins/http\t0.103s\tcoverage: 74.2% of statements\ngithub.com/mozilla-services/heka/plugins/irc\t0.011s\tcoverage: 89.0% of statements\ngithub.com/mozilla-services/heka/plugins/kafka\t1.520s\tcoverage: 72.6% of statements\ngithub.com/mozilla-services/heka/plugins/logstreamer\t0.006s\tcoverage: 64.3% of statements\ngithub.com/mozilla-services/heka/plugins/nagios\t0.012s\tcoverage: 82.5% of statements\ngithub.com/mozilla-services/heka/plugins/payload\t0.025s\tcoverage: 90.2% of statements\ngithub.com/mozilla-services/heka/plugins/process\t0.579s\tcoverage: 79.7% of statements\ngithub.com/mozilla-services/heka/plugins/smtp\t0.010s\tcoverage: 72.6% of statements\ngithub.com/mozilla-services/heka/plugins/statsd\t0.012s\tcoverage: 66.1% of statements\ngithub.com/mozilla-services/heka/plugins/tcp\t2.289s\tcoverage: 71.8% of statements\ngithub.com/mozilla-services/heka/plugins/udp\t0.015s\tcoverage: 70.3% of statements\ngithub.com/mozilla-services/heka/logstreamer\t0.038s\tcoverage: 68.4% of statements\ngithub.com/mozilla-services/heka/client\t0.006s\tcoverage: 58.2% of statements\ngithub.com/mozilla-services/heka/sandbox/lua\t0.033s\tcoverage: 0.0% of statements\ngithub.com/mozilla-services/heka/sandbox/plugins\t0.090s\tcoverage: 64.5% of statements\ngithub.com/mozilla-services/heka-mozsvc-plugins\t2.099s\tcoverage: 62.0% of statements\n"
        },
        {
          "name": "dasher",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "env.bat",
          "type": "blob",
          "size": 0.2802734375,
          "content": "@echo off\nset BUILD_DIR=%CD%\\build\nset CTEST_OUTPUT_ON_FAILURE=1\n\nsetlocal ENABLEDELAYEDEXPANSION\nset NEWGOPATH=%BUILD_DIR%\\heka\nif NOT \"%GOBIN%\"==\"\" (set p=!PATH:%GOBIN%;=!) else (set p=!PATH!)\nendlocal & set GOPATH=%NEWGOPATH%& set GOBIN=%NEWGOPATH%\\bin& set PATH=%p%;%NEWGOPATH%\\bin;\n"
        },
        {
          "name": "env.sh",
          "type": "blob",
          "size": 0.3916015625,
          "content": "#!/usr/bin/env bash\n\n# if the environment has been setup before clean it up\nif [ $GOBIN ]; then\n    PATH=$(echo $PATH | sed -e \"s;\\(^$GOBIN:\\|:$GOBIN$\\|:$GOBIN\\(:\\)\\);\\2;g\")\nfi\n\nBUILD_DIR=$PWD/build\nexport CTEST_OUTPUT_ON_FAILURE=1\nexport GOPATH=$BUILD_DIR/heka\nexport LD_LIBRARY_PATH=$BUILD_DIR/heka/lib\nexport DYLD_LIBRARY_PATH=$BUILD_DIR/heka/lib\nexport GOBIN=$GOPATH/bin\nexport PATH=$GOBIN:$PATH\n\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "logstreamer",
          "type": "tree",
          "content": null
        },
        {
          "name": "message",
          "type": "tree",
          "content": null
        },
        {
          "name": "packaging",
          "type": "tree",
          "content": null
        },
        {
          "name": "pipeline",
          "type": "tree",
          "content": null
        },
        {
          "name": "plugins",
          "type": "tree",
          "content": null
        },
        {
          "name": "ringbuf",
          "type": "tree",
          "content": null
        },
        {
          "name": "rpm",
          "type": "tree",
          "content": null
        },
        {
          "name": "sandbox",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}