{
  "metadata": {
    "timestamp": 1736567293405,
    "page": 893,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjkwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "mattes/migrate",
      "stars": 2288,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0595703125,
          "content": ".DS_Store\ncli/build\ncli/cli\ncli/migrate\n.coverage\n.godoc.pid\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 2.03515625,
          "content": "language: go\nsudo: required\n\ngo:\n  - 1.7\n  - 1.8\n  - 1.9\n\nenv:\n  - MIGRATE_TEST_CONTAINER_BOOT_DELAY=10\n\n# TODO: https://docs.docker.com/engine/installation/linux/ubuntu/    \n# pre-provision with travis docker setup and pin down docker version in install step\nservices:\n  - docker \n\ninstall:\n  - make deps\n  - (cd $GOPATH/src/github.com/docker/docker && git fetch --all --tags --prune && git checkout v17.05.0-ce)\n  - sudo apt-get update && sudo apt-get install docker-ce=17.05.0*\n  - go get github.com/mattn/goveralls \n\nscript:\n  - make test\n\nafter_success:\n  - goveralls -service=travis-ci -coverprofile .coverage/combined.txt\n  - make list-external-deps > dependency_tree.txt && cat dependency_tree.txt\n\nbefore_deploy:\n  - make build-cli\n  - gem install --no-ri --no-rdoc fpm \n  - fpm -s dir -t deb -n migrate -v \"$(git describe --tags 2>/dev/null | cut -c 2-)\" --license MIT -m matthias.kadenbach@gmail.com --url https://github.com/mattes/migrate --description='Database migrations' -a amd64 -p migrate.$(git describe --tags 2>/dev/null | cut -c 2-).deb --deb-no-default-config-files -f -C cli/build migrate.linux-amd64=/usr/bin/migrate\n\ndeploy:\n  - provider: releases\n    api_key:\n      secure: EFow50BI448HVb/uQ1Kk2Kq0xzmwIYq3V67YyymXIuqSCodvXEsMiBPUoLrxEknpPEIc67LEQTNdfHBgvyHk6oRINWAfie+7pr5tKrpOTF9ghyxoN1PlO8WKQCqwCvGMBCnc5ur5rvzp0bqfpV2rs5q9/nngy3kBuEvs12V7iho=\n    skip_cleanup: true\n    on:\n      go: 1.8\n      repo: mattes/migrate\n      tags: true\n    file:\n      - cli/build/migrate.linux-amd64.tar.gz\n      - cli/build/migrate.darwin-amd64.tar.gz\n      - cli/build/migrate.windows-amd64.exe.tar.gz\n      - cli/build/sha256sum.txt\n      - dependency_tree.txt\n  - provider: packagecloud\n    repository: migrate\n    username: mattes\n    token:\n      secure: RiHJ/+J9DvXUah/APYdWySWZ5uOOISYJ0wS7xddc7/BNStRVjzFzvJ9zmb67RkyZZrvGuVjPiL4T8mtDyCJCj47RmU/56wPdEHbar/FjsiUCgwvR19RlulkgbV4okBCePbwzMw6HNHRp14TzfQCPtnN4kef0lOI4gZJkImN7rtQ=\n    dist: ubuntu/xenial\n    package_glob: '*.deb'\n    skip_cleanup: true\n    on:\n      go: 1.8\n      repo: mattes/migrate\n      tags: true\n\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1.123046875,
          "content": "# Development, Testing and Contributing\n\n  1. Make sure you have a running Docker daemon\n     (Install for [MacOS](https://docs.docker.com/docker-for-mac/))\n  2. Fork this repo and `git clone` somewhere to `$GOPATH/src/github.com/%you%/migrate`\n  3. `make rewrite-import-paths` to update imports to your local fork\n  4. Confirm tests are working: `make test-short`\n  5. Write awesome code ...\n  6. `make test` to run all tests against all database versions\n  7. `make restore-import-paths` to restore import paths\n  8. Push code and open Pull Request\n \nSome more helpful commands:\n\n  * You can specify which database/ source tests to run:  \n    `make test-short SOURCE='file go-bindata' DATABASE='postgres cassandra'`\n  * After `make test`, run `make html-coverage` which opens a shiny test coverage overview.  \n  * Missing imports? `make deps`\n  * `make build-cli` builds the CLI in directory `cli/build/`.\n  * `make list-external-deps` lists all external dependencies for each package\n  * `make docs && make open-docs` opens godoc in your browser, `make kill-docs` kills the godoc server.  \n    Repeatedly call `make docs` to refresh the server.  \n"
        },
        {
          "name": "FAQ.md",
          "type": "blob",
          "size": 3.4306640625,
          "content": "# FAQ\n\n#### How is the code base structured?\n  ```\n  /          package migrate (the heart of everything)\n  /cli       the CLI wrapper\n  /database  database driver and sub directories have the actual driver implementations\n  /source    source driver and sub directories have the actual driver implementations\n  ```\n\n#### Why is there no `source/driver.go:Last()`?\n  It's not needed. And unless the source has a \"native\" way to read a directory in reversed order,\n  it might be expensive to do a full directory scan in order to get the last element.\n\n#### What is a NilMigration? NilVersion?\n  NilMigration defines a migration without a body. NilVersion is defined as const -1.\n\n#### What is the difference between uint(version) and int(targetVersion)?\n  version refers to an existing migration version coming from a source and therefor can never be negative.\n  targetVersion can either be a version OR represent a NilVersion, which equals -1.\n\n#### What's the difference between Next/Previous and Up/Down?\n  ```\n  1_first_migration.up.extension           next ->  2_second_migration.up.extension      ...\n  1_first_migration.down.extension  <- previous     2_second_migration.down.extension    ...\n  ```\n\n#### Why two separate files (up and down) for a migration?\n  It makes all of our lives easier. No new markup/syntax to learn for users\n  and existing database utility tools continue to work as expected.\n\n#### How many migrations can migrate handle?\n  Whatever the maximum positive signed integer value is for your platform.\n  For 32bit it would be 2,147,483,647 migrations. Migrate only keeps references to\n  the currently run and pre-fetched migrations in memory. Please note that some\n  source drivers need to do build a full \"directory\" tree first, which puts some\n  heat on the memory consumption.\n\n#### Are the table tests in migrate_test.go bloated?\n  Yes and no. There are duplicate test cases for sure but they don't hurt here. In fact\n  the tests are very visual now and might help new users understand expected behaviors quickly.\n  Migrate from version x to y and y is the last migration? Just check out the test for\n  that particular case and know what's going on instantly.\n\n#### What is Docker being used for?\n  Only for testing. See [testing/docker.go](testing/docker.go)\n\n#### Why not just use docker-compose?\n  It doesn't give us enough runtime control for testing. We want to be able to bring up containers fast\n  and whenever we want, not just once at the beginning of all tests.\n\n#### Can I maintain my driver in my own repository?\n  Yes, technically thats possible. We want to encourage you to contribute your driver to this respository though.\n  The driver's functionality is dictated by migrate's interfaces. That means there should really\n  just be one driver for a database/ source. We want to prevent a future where several drivers doing the exact same thing,\n  just implemented a bit differently, co-exist somewhere on Github. If users have to do research first to find the\n  \"best\" available driver for a database in order to get started, we would have failed as an open source community.\n\n#### Can I mix multiple sources during a batch of migrations?\n  No.\n\n#### What does \"dirty\" database mean?\n  Before a migration runs, each database sets a dirty flag. Execution stops if a migration fails and the dirty state persists,\n  which prevents attempts to run more migrations on top of a failed migration. You need to manually fix the error\n  and then \"force\" the expected version.\n\n\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.09375,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2016 Matthias Kadenbach\n\nhttps://github.com/mattes/migrate\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n"
        },
        {
          "name": "MIGRATIONS.md",
          "type": "blob",
          "size": 3.4736328125,
          "content": "# Migrations\r\n\r\n## Migration Filename Format\r\n\r\nA single logical migration is represented as two separate migration files, one\r\nto migrate \"up\" to the specified version from the previous version, and a second\r\nto migrate back \"down\" to the previous version.  These migrations can be provided\r\nby any one of the supported [migration sources](./README.md#migration-sources).\r\n\r\nThe ordering and direction of the migration files is determined by the filenames\r\nused for them.  `migrate` expects the filenames of migrations to have the format:\r\n\r\n    {version}_{title}.up.{extension}\r\n    {version}_{title}.down.{extension}\r\n\r\nThe `title` of each migration is unused, and is only for readability.  Similarly,\r\nthe `extension` of the migration files is not checked by the library, and should\r\nbe an appropriate format for the database in use (`.sql` for SQL variants, for\r\ninstance).\r\n\r\nVersions of migrations may be represented as any 64 bit unsigned integer.\r\nAll migrations are applied upward in order of increasing version number, and\r\ndownward by decreasing version number.\r\n\r\nCommon versioning schemes include incrementing integers:\r\n\r\n    1_initialize_schema.down.sql\r\n    1_initialize_schema.up.sql\r\n    2_add_table.down.sql\r\n    2_add_table.up.sql\r\n    ...\r\n\r\nOr timestamps at an appropriate resolution:\r\n\r\n    1500360784_initialize_schema.down.sql\r\n    1500360784_initialize_schema.up.sql\r\n    1500445949_add_table.down.sql\r\n    1500445949_add_table.up.sql\r\n    ...\r\n\r\nBut any scheme resulting in distinct, incrementing integers as versions is valid.\r\n\r\nIt is suggested that the version number of corresponding `up` and `down` migration\r\nfiles be equivalent for clarity, but they are allowed to differ so long as the\r\nrelative ordering of the migrations is preserved.\r\n\r\nThe migration files are permitted to be empty, so in the event that a migration\r\nis a no-op or is irreversible, it is recommended to still include both migration\r\nfiles, and either leaving them empty or adding a comment as appropriate.\r\n\r\n## Migration Content Format\r\n\r\nThe format of the migration files themselves varies between database systems.\r\nDifferent databases have different semantics around schema changes and when and\r\nhow they are allowed to occur (for instance, if schema changes can occur within\r\na transaction).\r\n\r\nAs such, the `migrate` library has little to no checking around the format of\r\nmigration sources.  The migration files are generally processed directly by the\r\ndrivers as raw operations.\r\n\r\n## Reversibility of Migrations\r\n\r\nBest practice for writing schema migration is that all migrations should be\r\nreversible.  It should in theory be possible for run migrations down and back up\r\nthrough any and all versions with the state being fully cleaned and recreated\r\nby doing so.\r\n\r\nBy adhering to this recommended practice, development and deployment of new code\r\nis cleaner and easier (cleaning database state for a new feature should be as\r\neasy as migrating down to a prior version, and back up to the latest).\r\n\r\nAs opposed to some other migration libraries, `migrate` represents up and down\r\nmigrations as separate files.  This prevents any non-standard file syntax from\r\nbeing introduced which may result in unintended behavior or errors, depending\r\non what database is processing the file.\r\n\r\nWhile it is technically possible for an up or down migration to exist on its own\r\nwithout an equivalently versioned counterpart, it is strongly recommended to\r\nalways include a down migration which cleans up the state of the corresponding\r\nup migration.\r\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 3.849609375,
          "content": "SOURCE ?= file go-bindata github aws-s3 google-cloud-storage\nDATABASE ?= postgres mysql redshift cassandra sqlite3 spanner cockroachdb clickhouse\nVERSION ?= $(shell git describe --tags 2>/dev/null | cut -c 2-)\nTEST_FLAGS ?=\nREPO_OWNER ?= $(shell cd .. && basename \"$$(pwd)\")\n\n\nbuild-cli: clean\n\t-mkdir ./cli/build\n\tcd ./cli && CGO_ENABLED=1 GOOS=linux GOARCH=amd64 go build -a -o build/migrate.linux-amd64 -ldflags='-X main.Version=$(VERSION)' -tags '$(DATABASE) $(SOURCE)' .\n\tcd ./cli && CGO_ENABLED=1 GOOS=darwin GOARCH=amd64 go build -a -o build/migrate.darwin-amd64 -ldflags='-X main.Version=$(VERSION)' -tags '$(DATABASE) $(SOURCE)' .\n\tcd ./cli && CGO_ENABLED=1 GOOS=windows GOARCH=amd64 go build -a -o build/migrate.windows-amd64.exe -ldflags='-X main.Version=$(VERSION)' -tags '$(DATABASE) $(SOURCE)' .\n\tcd ./cli/build && find . -name 'migrate*' | xargs -I{} tar czf {}.tar.gz {}\n\tcd ./cli/build && shasum -a 256 * > sha256sum.txt\n\tcat ./cli/build/sha256sum.txt\n\n\nclean:\n\t-rm -r ./cli/build\n\n\ntest-short:\n\tmake test-with-flags --ignore-errors TEST_FLAGS='-short'\n\n\ntest:\n\t@-rm -r .coverage\n\t@mkdir .coverage\n\tmake test-with-flags TEST_FLAGS='-v -race -covermode atomic -coverprofile .coverage/_$$(RAND).txt -bench=. -benchmem'\n\t@echo 'mode: atomic' > .coverage/combined.txt\n\t@cat .coverage/*.txt | grep -v 'mode: atomic' >> .coverage/combined.txt\n\n\ntest-with-flags:\n\t@echo SOURCE: $(SOURCE) \n\t@echo DATABASE: $(DATABASE)\n\n\t@go test $(TEST_FLAGS) .\n\t@go test $(TEST_FLAGS) ./cli/...\n\t@go test $(TEST_FLAGS) ./testing/...\n\n\t@echo -n '$(SOURCE)' | tr -s ' ' '\\n' | xargs -I{} go test $(TEST_FLAGS) ./source/{}\n\t@go test $(TEST_FLAGS) ./source/testing/...\n\t@go test $(TEST_FLAGS) ./source/stub/...\n\n\t@echo -n '$(DATABASE)' | tr -s ' ' '\\n' | xargs -I{} go test $(TEST_FLAGS) ./database/{}\n\t@go test $(TEST_FLAGS) ./database/testing/...\n\t@go test $(TEST_FLAGS) ./database/stub/...\n\n\nkill-orphaned-docker-containers:\n\tdocker rm -f $(shell docker ps -aq --filter label=migrate_test)\n\n\nhtml-coverage:\n\tgo tool cover -html=.coverage/combined.txt\n\n\ndeps:\n\t-go get -v -u ./... \n\t-go test -v -i ./...\n\t# TODO: why is this not being fetched with the command above?\n\t-go get -u github.com/fsouza/fake-gcs-server/fakestorage\n\n\nlist-external-deps:\n\t$(call external_deps,'.')\n\t$(call external_deps,'./cli/...')\n\t$(call external_deps,'./testing/...')\n\n\t$(foreach v, $(SOURCE), $(call external_deps,'./source/$(v)/...'))\n\t$(call external_deps,'./source/testing/...')\n\t$(call external_deps,'./source/stub/...')\n\n\t$(foreach v, $(DATABASE), $(call external_deps,'./database/$(v)/...'))\n\t$(call external_deps,'./database/testing/...')\n\t$(call external_deps,'./database/stub/...')\n\n\nrestore-import-paths:\n\tfind . -name '*.go' -type f -execdir sed -i '' s%\\\"github.com/$(REPO_OWNER)/migrate%\\\"github.com/mattes/migrate%g '{}' \\;\n\n\nrewrite-import-paths:\n\tfind . -name '*.go' -type f -execdir sed -i '' s%\\\"github.com/mattes/migrate%\\\"github.com/$(REPO_OWNER)/migrate%g '{}' \\;\n\n\n# example: fswatch -0 --exclude .godoc.pid --event Updated . | xargs -0 -n1 -I{} make docs\ndocs:\n\t-make kill-docs\n\tnohup godoc -play -http=127.0.0.1:6064 </dev/null >/dev/null 2>&1 & echo $$! > .godoc.pid\n\tcat .godoc.pid  \n\n\nkill-docs:\n\t@cat .godoc.pid\n\tkill -9 $$(cat .godoc.pid)\n\trm .godoc.pid\n\n\nopen-docs:\n\topen http://localhost:6064/pkg/github.com/$(REPO_OWNER)/migrate\n\n\n# example: make release V=0.0.0\nrelease:\n\tgit tag v$(V)\n\t@read -p \"Press enter to confirm and push to origin ...\" && git push origin v$(V)\n\n\ndefine external_deps\n\t@echo '-- $(1)';  go list -f '{{join .Deps \"\\n\"}}' $(1) | grep -v github.com/$(REPO_OWNER)/migrate | xargs go list -f '{{if not .Standard}}{{.ImportPath}}{{end}}'\n\nendef\n\n\n.PHONY: build-cli clean test-short test test-with-flags deps html-coverage \\\n        restore-import-paths rewrite-import-paths list-external-deps release \\\n        docs kill-docs open-docs kill-orphaned-docker-containers\n\nSHELL = /bin/bash\nRAND = $(shell echo $$RANDOM)\n\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 0.2431640625,
          "content": "# migrate\n\nDatabase migrations written in Go. Use as CLI or import as library.\n\n# DEPRECATED\n\n__mattes/migrate is now [golang-migrate/migrate](https://github.com/golang-migrate/migrate)__\n\nPlease open issues and pull requests in the new repository.\n"
        },
        {
          "name": "cli",
          "type": "tree",
          "content": null
        },
        {
          "name": "database",
          "type": "tree",
          "content": null
        },
        {
          "name": "log.go",
          "type": "blob",
          "size": 0.275390625,
          "content": "package migrate\n\n// Logger is an interface so you can pass in your own\n// logging implementation.\ntype Logger interface {\n\n\t// Printf is like fmt.Printf\n\tPrintf(format string, v ...interface{})\n\n\t// Verbose should return true when verbose logging output is wanted\n\tVerbose() bool\n}\n"
        },
        {
          "name": "migrate.go",
          "type": "blob",
          "size": 20.546875,
          "content": "// Package migrate reads migrations from sources and runs them against databases.\n// Sources are defined by the `source.Driver` and databases by the `database.Driver`\n// interface. The driver interfaces are kept \"dump\", all migration logic is kept\n// in this package.\npackage migrate\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/mattes/migrate/database\"\n\t\"github.com/mattes/migrate/source\"\n)\n\n// DefaultPrefetchMigrations sets the number of migrations to pre-read\n// from the source. This is helpful if the source is remote, but has little\n// effect for a local source (i.e. file system).\n// Please note that this setting has a major impact on the memory usage,\n// since each pre-read migration is buffered in memory. See DefaultBufferSize.\nvar DefaultPrefetchMigrations = uint(10)\n\n// DefaultLockTimeout sets the max time a database driver has to acquire a lock.\nvar DefaultLockTimeout = 15 * time.Second\n\nvar (\n\tErrNoChange    = fmt.Errorf(\"no change\")\n\tErrNilVersion  = fmt.Errorf(\"no migration\")\n\tErrLocked      = fmt.Errorf(\"database locked\")\n\tErrLockTimeout = fmt.Errorf(\"timeout: can't acquire database lock\")\n)\n\n// ErrShortLimit is an error returned when not enough migrations\n// can be returned by a source for a given limit.\ntype ErrShortLimit struct {\n\tShort uint\n}\n\n// Error implements the error interface.\nfunc (e ErrShortLimit) Error() string {\n\treturn fmt.Sprintf(\"limit %v short\", e.Short)\n}\n\ntype ErrDirty struct {\n\tVersion int\n}\n\nfunc (e ErrDirty) Error() string {\n\treturn fmt.Sprintf(\"Dirty database version %v. Fix and force version.\", e.Version)\n}\n\ntype Migrate struct {\n\tsourceName   string\n\tsourceDrv    source.Driver\n\tdatabaseName string\n\tdatabaseDrv  database.Driver\n\n\t// Log accepts a Logger interface\n\tLog Logger\n\n\t// GracefulStop accepts `true` and will stop executing migrations\n\t// as soon as possible at a safe break point, so that the database\n\t// is not corrupted.\n\tGracefulStop   chan bool\n\tisGracefulStop bool\n\n\tisLockedMu *sync.Mutex\n\tisLocked   bool\n\n\t// PrefetchMigrations defaults to DefaultPrefetchMigrations,\n\t// but can be set per Migrate instance.\n\tPrefetchMigrations uint\n\n\t// LockTimeout defaults to DefaultLockTimeout,\n\t// but can be set per Migrate instance.\n\tLockTimeout time.Duration\n}\n\n// New returns a new Migrate instance from a source URL and a database URL.\n// The URL scheme is defined by each driver.\nfunc New(sourceUrl, databaseUrl string) (*Migrate, error) {\n\tm := newCommon()\n\n\tsourceName, err := schemeFromUrl(sourceUrl)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tm.sourceName = sourceName\n\n\tdatabaseName, err := schemeFromUrl(databaseUrl)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tm.databaseName = databaseName\n\n\tsourceDrv, err := source.Open(sourceUrl)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tm.sourceDrv = sourceDrv\n\n\tdatabaseDrv, err := database.Open(databaseUrl)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tm.databaseDrv = databaseDrv\n\n\treturn m, nil\n}\n\n// NewWithDatabaseInstance returns a new Migrate instance from a source URL\n// and an existing database instance. The source URL scheme is defined by each driver.\n// Use any string that can serve as an identifier during logging as databaseName.\n// You are responsible for closing the underlying database client if necessary.\nfunc NewWithDatabaseInstance(sourceUrl string, databaseName string, databaseInstance database.Driver) (*Migrate, error) {\n\tm := newCommon()\n\n\tsourceName, err := schemeFromUrl(sourceUrl)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tm.sourceName = sourceName\n\n\tm.databaseName = databaseName\n\n\tsourceDrv, err := source.Open(sourceUrl)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tm.sourceDrv = sourceDrv\n\n\tm.databaseDrv = databaseInstance\n\n\treturn m, nil\n}\n\n// NewWithSourceInstance returns a new Migrate instance from an existing source instance\n// and a database URL. The database URL scheme is defined by each driver.\n// Use any string that can serve as an identifier during logging as sourceName.\n// You are responsible for closing the underlying source client if necessary.\nfunc NewWithSourceInstance(sourceName string, sourceInstance source.Driver, databaseUrl string) (*Migrate, error) {\n\tm := newCommon()\n\n\tdatabaseName, err := schemeFromUrl(databaseUrl)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tm.databaseName = databaseName\n\n\tm.sourceName = sourceName\n\n\tdatabaseDrv, err := database.Open(databaseUrl)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tm.databaseDrv = databaseDrv\n\n\tm.sourceDrv = sourceInstance\n\n\treturn m, nil\n}\n\n// NewWithInstance returns a new Migrate instance from an existing source and\n// database instance. Use any string that can serve as an identifier during logging\n// as sourceName and databaseName. You are responsible for closing down\n// the underlying source and database client if necessary.\nfunc NewWithInstance(sourceName string, sourceInstance source.Driver, databaseName string, databaseInstance database.Driver) (*Migrate, error) {\n\tm := newCommon()\n\n\tm.sourceName = sourceName\n\tm.databaseName = databaseName\n\n\tm.sourceDrv = sourceInstance\n\tm.databaseDrv = databaseInstance\n\n\treturn m, nil\n}\n\nfunc newCommon() *Migrate {\n\treturn &Migrate{\n\t\tGracefulStop:       make(chan bool, 1),\n\t\tPrefetchMigrations: DefaultPrefetchMigrations,\n\t\tLockTimeout:        DefaultLockTimeout,\n\t\tisLockedMu:         &sync.Mutex{},\n\t}\n}\n\n// Close closes the the source and the database.\nfunc (m *Migrate) Close() (source error, database error) {\n\tdatabaseSrvClose := make(chan error)\n\tsourceSrvClose := make(chan error)\n\n\tm.logVerbosePrintf(\"Closing source and database\\n\")\n\n\tgo func() {\n\t\tdatabaseSrvClose <- m.databaseDrv.Close()\n\t}()\n\n\tgo func() {\n\t\tsourceSrvClose <- m.sourceDrv.Close()\n\t}()\n\n\treturn <-sourceSrvClose, <-databaseSrvClose\n}\n\n// Migrate looks at the currently active migration version,\n// then migrates either up or down to the specified version.\nfunc (m *Migrate) Migrate(version uint) error {\n\tif err := m.lock(); err != nil {\n\t\treturn err\n\t}\n\n\tcurVersion, dirty, err := m.databaseDrv.Version()\n\tif err != nil {\n\t\treturn m.unlockErr(err)\n\t}\n\n\tif dirty {\n\t\treturn m.unlockErr(ErrDirty{curVersion})\n\t}\n\n\tret := make(chan interface{}, m.PrefetchMigrations)\n\tgo m.read(curVersion, int(version), ret)\n\n\treturn m.unlockErr(m.runMigrations(ret))\n}\n\n// Steps looks at the currently active migration version.\n// It will migrate up if n > 0, and down if n < 0.\nfunc (m *Migrate) Steps(n int) error {\n\tif n == 0 {\n\t\treturn ErrNoChange\n\t}\n\n\tif err := m.lock(); err != nil {\n\t\treturn err\n\t}\n\n\tcurVersion, dirty, err := m.databaseDrv.Version()\n\tif err != nil {\n\t\treturn m.unlockErr(err)\n\t}\n\n\tif dirty {\n\t\treturn m.unlockErr(ErrDirty{curVersion})\n\t}\n\n\tret := make(chan interface{}, m.PrefetchMigrations)\n\n\tif n > 0 {\n\t\tgo m.readUp(curVersion, n, ret)\n\t} else {\n\t\tgo m.readDown(curVersion, -n, ret)\n\t}\n\n\treturn m.unlockErr(m.runMigrations(ret))\n}\n\n// Up looks at the currently active migration version\n// and will migrate all the way up (applying all up migrations).\nfunc (m *Migrate) Up() error {\n\tif err := m.lock(); err != nil {\n\t\treturn err\n\t}\n\n\tcurVersion, dirty, err := m.databaseDrv.Version()\n\tif err != nil {\n\t\treturn m.unlockErr(err)\n\t}\n\n\tif dirty {\n\t\treturn m.unlockErr(ErrDirty{curVersion})\n\t}\n\n\tret := make(chan interface{}, m.PrefetchMigrations)\n\n\tgo m.readUp(curVersion, -1, ret)\n\treturn m.unlockErr(m.runMigrations(ret))\n}\n\n// Down looks at the currently active migration version\n// and will migrate all the way down (applying all down migrations).\nfunc (m *Migrate) Down() error {\n\tif err := m.lock(); err != nil {\n\t\treturn err\n\t}\n\n\tcurVersion, dirty, err := m.databaseDrv.Version()\n\tif err != nil {\n\t\treturn m.unlockErr(err)\n\t}\n\n\tif dirty {\n\t\treturn m.unlockErr(ErrDirty{curVersion})\n\t}\n\n\tret := make(chan interface{}, m.PrefetchMigrations)\n\tgo m.readDown(curVersion, -1, ret)\n\treturn m.unlockErr(m.runMigrations(ret))\n}\n\n// Drop deletes everything in the database.\nfunc (m *Migrate) Drop() error {\n\tif err := m.lock(); err != nil {\n\t\treturn err\n\t}\n\tif err := m.databaseDrv.Drop(); err != nil {\n\t\treturn m.unlockErr(err)\n\t}\n\treturn m.unlock()\n}\n\n// Run runs any migration provided by you against the database.\n// It does not check any currently active version in database.\n// Usually you don't need this function at all. Use Migrate,\n// Steps, Up or Down instead.\nfunc (m *Migrate) Run(migration ...*Migration) error {\n\tif len(migration) == 0 {\n\t\treturn ErrNoChange\n\t}\n\n\tif err := m.lock(); err != nil {\n\t\treturn err\n\t}\n\n\tcurVersion, dirty, err := m.databaseDrv.Version()\n\tif err != nil {\n\t\treturn m.unlockErr(err)\n\t}\n\n\tif dirty {\n\t\treturn m.unlockErr(ErrDirty{curVersion})\n\t}\n\n\tret := make(chan interface{}, m.PrefetchMigrations)\n\n\tgo func() {\n\t\tdefer close(ret)\n\t\tfor _, migr := range migration {\n\t\t\tif m.PrefetchMigrations > 0 && migr.Body != nil {\n\t\t\t\tm.logVerbosePrintf(\"Start buffering %v\\n\", migr.LogString())\n\t\t\t} else {\n\t\t\t\tm.logVerbosePrintf(\"Scheduled %v\\n\", migr.LogString())\n\t\t\t}\n\n\t\t\tret <- migr\n\t\t\tgo migr.Buffer()\n\t\t}\n\t}()\n\n\treturn m.unlockErr(m.runMigrations(ret))\n}\n\n// Force sets a migration version.\n// It does not check any currently active version in database.\n// It resets the dirty state to false.\nfunc (m *Migrate) Force(version int) error {\n\tif version < -1 {\n\t\tpanic(\"version must be >= -1\")\n\t}\n\n\tif err := m.lock(); err != nil {\n\t\treturn err\n\t}\n\n\tif err := m.databaseDrv.SetVersion(version, false); err != nil {\n\t\treturn m.unlockErr(err)\n\t}\n\n\treturn m.unlock()\n}\n\n// Version returns the currently active migration version.\n// If no migration has been applied, yet, it will return ErrNilVersion.\nfunc (m *Migrate) Version() (version uint, dirty bool, err error) {\n\tv, d, err := m.databaseDrv.Version()\n\tif err != nil {\n\t\treturn 0, false, err\n\t}\n\n\tif v == database.NilVersion {\n\t\treturn 0, false, ErrNilVersion\n\t}\n\n\treturn suint(v), d, nil\n}\n\n// read reads either up or down migrations from source `from` to `to`.\n// Each migration is then written to the ret channel.\n// If an error occurs during reading, that error is written to the ret channel, too.\n// Once read is done reading it will close the ret channel.\nfunc (m *Migrate) read(from int, to int, ret chan<- interface{}) {\n\tdefer close(ret)\n\n\t// check if from version exists\n\tif from >= 0 {\n\t\tif m.versionExists(suint(from)) != nil {\n\t\t\tret <- os.ErrNotExist\n\t\t\treturn\n\t\t}\n\t}\n\n\t// check if to version exists\n\tif to >= 0 {\n\t\tif m.versionExists(suint(to)) != nil {\n\t\t\tret <- os.ErrNotExist\n\t\t\treturn\n\t\t}\n\t}\n\n\t// no change?\n\tif from == to {\n\t\tret <- ErrNoChange\n\t\treturn\n\t}\n\n\tif from < to {\n\t\t// it's going up\n\t\t// apply first migration if from is nil version\n\t\tif from == -1 {\n\t\t\tfirstVersion, err := m.sourceDrv.First()\n\t\t\tif err != nil {\n\t\t\t\tret <- err\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tmigr, err := m.newMigration(firstVersion, int(firstVersion))\n\t\t\tif err != nil {\n\t\t\t\tret <- err\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tret <- migr\n\t\t\tgo migr.Buffer()\n\t\t\tfrom = int(firstVersion)\n\t\t}\n\n\t\t// run until we reach target ...\n\t\tfor from < to {\n\t\t\tif m.stop() {\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tnext, err := m.sourceDrv.Next(suint(from))\n\t\t\tif err != nil {\n\t\t\t\tret <- err\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tmigr, err := m.newMigration(next, int(next))\n\t\t\tif err != nil {\n\t\t\t\tret <- err\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tret <- migr\n\t\t\tgo migr.Buffer()\n\t\t\tfrom = int(next)\n\t\t}\n\n\t} else {\n\t\t// it's going down\n\t\t// run until we reach target ...\n\t\tfor from > to && from >= 0 {\n\t\t\tif m.stop() {\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tprev, err := m.sourceDrv.Prev(suint(from))\n\t\t\tif os.IsNotExist(err) && to == -1 {\n\t\t\t\t// apply nil migration\n\t\t\t\tmigr, err := m.newMigration(suint(from), -1)\n\t\t\t\tif err != nil {\n\t\t\t\t\tret <- err\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tret <- migr\n\t\t\t\tgo migr.Buffer()\n\t\t\t\treturn\n\n\t\t\t} else if err != nil {\n\t\t\t\tret <- err\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tmigr, err := m.newMigration(suint(from), int(prev))\n\t\t\tif err != nil {\n\t\t\t\tret <- err\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tret <- migr\n\t\t\tgo migr.Buffer()\n\t\t\tfrom = int(prev)\n\t\t}\n\t}\n}\n\n// readUp reads up migrations from `from` limitted by `limit`.\n// limit can be -1, implying no limit and reading until there are no more migrations.\n// Each migration is then written to the ret channel.\n// If an error occurs during reading, that error is written to the ret channel, too.\n// Once readUp is done reading it will close the ret channel.\nfunc (m *Migrate) readUp(from int, limit int, ret chan<- interface{}) {\n\tdefer close(ret)\n\n\t// check if from version exists\n\tif from >= 0 {\n\t\tif m.versionExists(suint(from)) != nil {\n\t\t\tret <- os.ErrNotExist\n\t\t\treturn\n\t\t}\n\t}\n\n\tif limit == 0 {\n\t\tret <- ErrNoChange\n\t\treturn\n\t}\n\n\tcount := 0\n\tfor count < limit || limit == -1 {\n\t\tif m.stop() {\n\t\t\treturn\n\t\t}\n\n\t\t// apply first migration if from is nil version\n\t\tif from == -1 {\n\t\t\tfirstVersion, err := m.sourceDrv.First()\n\t\t\tif err != nil {\n\t\t\t\tret <- err\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tmigr, err := m.newMigration(firstVersion, int(firstVersion))\n\t\t\tif err != nil {\n\t\t\t\tret <- err\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tret <- migr\n\t\t\tgo migr.Buffer()\n\t\t\tfrom = int(firstVersion)\n\t\t\tcount++\n\t\t\tcontinue\n\t\t}\n\n\t\t// apply next migration\n\t\tnext, err := m.sourceDrv.Next(suint(from))\n\t\tif os.IsNotExist(err) {\n\t\t\t// no limit, but no migrations applied?\n\t\t\tif limit == -1 && count == 0 {\n\t\t\t\tret <- ErrNoChange\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// no limit, reached end\n\t\t\tif limit == -1 {\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// reached end, and didn't apply any migrations\n\t\t\tif limit > 0 && count == 0 {\n\t\t\t\tret <- os.ErrNotExist\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// applied less migrations than limit?\n\t\t\tif count < limit {\n\t\t\t\tret <- ErrShortLimit{suint(limit - count)}\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tif err != nil {\n\t\t\tret <- err\n\t\t\treturn\n\t\t}\n\n\t\tmigr, err := m.newMigration(next, int(next))\n\t\tif err != nil {\n\t\t\tret <- err\n\t\t\treturn\n\t\t}\n\n\t\tret <- migr\n\t\tgo migr.Buffer()\n\t\tfrom = int(next)\n\t\tcount++\n\t}\n}\n\n// readDown reads down migrations from `from` limitted by `limit`.\n// limit can be -1, implying no limit and reading until there are no more migrations.\n// Each migration is then written to the ret channel.\n// If an error occurs during reading, that error is written to the ret channel, too.\n// Once readDown is done reading it will close the ret channel.\nfunc (m *Migrate) readDown(from int, limit int, ret chan<- interface{}) {\n\tdefer close(ret)\n\n\t// check if from version exists\n\tif from >= 0 {\n\t\tif m.versionExists(suint(from)) != nil {\n\t\t\tret <- os.ErrNotExist\n\t\t\treturn\n\t\t}\n\t}\n\n\tif limit == 0 {\n\t\tret <- ErrNoChange\n\t\treturn\n\t}\n\n\t// no change if already at nil version\n\tif from == -1 && limit == -1 {\n\t\tret <- ErrNoChange\n\t\treturn\n\t}\n\n\t// can't go over limit if already at nil version\n\tif from == -1 && limit > 0 {\n\t\tret <- os.ErrNotExist\n\t\treturn\n\t}\n\n\tcount := 0\n\tfor count < limit || limit == -1 {\n\t\tif m.stop() {\n\t\t\treturn\n\t\t}\n\n\t\tprev, err := m.sourceDrv.Prev(suint(from))\n\t\tif os.IsNotExist(err) {\n\t\t\t// no limit or haven't reached limit, apply \"first\" migration\n\t\t\tif limit == -1 || limit-count > 0 {\n\t\t\t\tfirstVersion, err := m.sourceDrv.First()\n\t\t\t\tif err != nil {\n\t\t\t\t\tret <- err\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tmigr, err := m.newMigration(firstVersion, -1)\n\t\t\t\tif err != nil {\n\t\t\t\t\tret <- err\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tret <- migr\n\t\t\t\tgo migr.Buffer()\n\t\t\t\tcount++\n\t\t\t}\n\n\t\t\tif count < limit {\n\t\t\t\tret <- ErrShortLimit{suint(limit - count)}\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tif err != nil {\n\t\t\tret <- err\n\t\t\treturn\n\t\t}\n\n\t\tmigr, err := m.newMigration(suint(from), int(prev))\n\t\tif err != nil {\n\t\t\tret <- err\n\t\t\treturn\n\t\t}\n\n\t\tret <- migr\n\t\tgo migr.Buffer()\n\t\tfrom = int(prev)\n\t\tcount++\n\t}\n}\n\n// runMigrations reads *Migration and error from a channel. Any other type\n// sent on this channel will result in a panic. Each migration is then\n// proxied to the database driver and run against the database.\n// Before running a newly received migration it will check if it's supposed\n// to stop execution because it might have received a stop signal on the\n// GracefulStop channel.\nfunc (m *Migrate) runMigrations(ret <-chan interface{}) error {\n\tfor r := range ret {\n\n\t\tif m.stop() {\n\t\t\treturn nil\n\t\t}\n\n\t\tswitch r.(type) {\n\t\tcase error:\n\t\t\treturn r.(error)\n\n\t\tcase *Migration:\n\t\t\tmigr := r.(*Migration)\n\n\t\t\t// set version with dirty state\n\t\t\tif err := m.databaseDrv.SetVersion(migr.TargetVersion, true); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tif migr.Body != nil {\n\t\t\t\tm.logVerbosePrintf(\"Read and execute %v\\n\", migr.LogString())\n\t\t\t\tif err := m.databaseDrv.Run(migr.BufferedBody); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// set clean state\n\t\t\tif err := m.databaseDrv.SetVersion(migr.TargetVersion, false); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tendTime := time.Now()\n\t\t\treadTime := migr.FinishedReading.Sub(migr.StartedBuffering)\n\t\t\trunTime := endTime.Sub(migr.FinishedReading)\n\n\t\t\t// log either verbose or normal\n\t\t\tif m.Log != nil {\n\t\t\t\tif m.Log.Verbose() {\n\t\t\t\t\tm.logPrintf(\"Finished %v (read %v, ran %v)\\n\", migr.LogString(), readTime, runTime)\n\t\t\t\t} else {\n\t\t\t\t\tm.logPrintf(\"%v (%v)\\n\", migr.LogString(), readTime+runTime)\n\t\t\t\t}\n\t\t\t}\n\n\t\tdefault:\n\t\t\tpanic(\"unknown type\")\n\t\t}\n\t}\n\treturn nil\n}\n\n// versionExists checks the source if either the up or down migration for\n// the specified migration version exists.\nfunc (m *Migrate) versionExists(version uint) error {\n\t// try up migration first\n\tup, _, err := m.sourceDrv.ReadUp(version)\n\tif err == nil {\n\t\tdefer up.Close()\n\t}\n\tif os.IsExist(err) {\n\t\treturn nil\n\t} else if !os.IsNotExist(err) {\n\t\treturn err\n\t}\n\n\t// then try down migration\n\tdown, _, err := m.sourceDrv.ReadDown(version)\n\tif err == nil {\n\t\tdefer down.Close()\n\t}\n\tif os.IsExist(err) {\n\t\treturn nil\n\t} else if !os.IsNotExist(err) {\n\t\treturn err\n\t}\n\n\treturn os.ErrNotExist\n}\n\n// stop returns true if no more migrations should be run against the database\n// because a stop signal was received on the GracefulStop channel.\n// Calls are cheap and this function is not blocking.\nfunc (m *Migrate) stop() bool {\n\tif m.isGracefulStop {\n\t\treturn true\n\t}\n\n\tselect {\n\tcase <-m.GracefulStop:\n\t\tm.isGracefulStop = true\n\t\treturn true\n\n\tdefault:\n\t\treturn false\n\t}\n}\n\n// newMigration is a helper func that returns a *Migration for the\n// specified version and targetVersion.\nfunc (m *Migrate) newMigration(version uint, targetVersion int) (*Migration, error) {\n\tvar migr *Migration\n\n\tif targetVersion >= int(version) {\n\t\tr, identifier, err := m.sourceDrv.ReadUp(version)\n\t\tif os.IsNotExist(err) {\n\t\t\t// create \"empty\" migration\n\t\t\tmigr, err = NewMigration(nil, \"\", version, targetVersion)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t} else if err != nil {\n\t\t\treturn nil, err\n\n\t\t} else {\n\t\t\t// create migration from up source\n\t\t\tmigr, err = NewMigration(r, identifier, version, targetVersion)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\n\t} else {\n\t\tr, identifier, err := m.sourceDrv.ReadDown(version)\n\t\tif os.IsNotExist(err) {\n\t\t\t// create \"empty\" migration\n\t\t\tmigr, err = NewMigration(nil, \"\", version, targetVersion)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t} else if err != nil {\n\t\t\treturn nil, err\n\n\t\t} else {\n\t\t\t// create migration from down source\n\t\t\tmigr, err = NewMigration(r, identifier, version, targetVersion)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t}\n\n\tif m.PrefetchMigrations > 0 && migr.Body != nil {\n\t\tm.logVerbosePrintf(\"Start buffering %v\\n\", migr.LogString())\n\t} else {\n\t\tm.logVerbosePrintf(\"Scheduled %v\\n\", migr.LogString())\n\t}\n\n\treturn migr, nil\n}\n\n// lock is a thread safe helper function to lock the database.\n// It should be called as late as possible when running migrations.\nfunc (m *Migrate) lock() error {\n\tm.isLockedMu.Lock()\n\tdefer m.isLockedMu.Unlock()\n\n\tif m.isLocked {\n\t\treturn ErrLocked\n\t}\n\n\t// create done channel, used in the timeout goroutine\n\tdone := make(chan bool, 1)\n\tdefer func() {\n\t\tdone <- true\n\t}()\n\n\t// use errchan to signal error back to this context\n\terrchan := make(chan error, 2)\n\n\t// start timeout goroutine\n\ttimeout := time.After(m.LockTimeout)\n\tgo func() {\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-done:\n\t\t\t\treturn\n\t\t\tcase <-timeout:\n\t\t\t\terrchan <- ErrLockTimeout\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}()\n\n\t// now try to acquire the lock\n\tgo func() {\n\t\tif err := m.databaseDrv.Lock(); err != nil {\n\t\t\terrchan <- err\n\t\t} else {\n\t\t\terrchan <- nil\n\t\t}\n\t\treturn\n\t}()\n\n\t// wait until we either recieve ErrLockTimeout or error from Lock operation\n\terr := <-errchan\n\tif err == nil {\n\t\tm.isLocked = true\n\t}\n\treturn err\n}\n\n// unlock is a thread safe helper function to unlock the database.\n// It should be called as early as possible when no more migrations are\n// expected to be executed.\nfunc (m *Migrate) unlock() error {\n\tm.isLockedMu.Lock()\n\tdefer m.isLockedMu.Unlock()\n\n\tif err := m.databaseDrv.Unlock(); err != nil {\n\t\t// BUG: Can potentially create a deadlock. Add a timeout.\n\t\treturn err\n\t}\n\n\tm.isLocked = false\n\treturn nil\n}\n\n// unlockErr calls unlock and returns a combined error\n// if a prevErr is not nil.\nfunc (m *Migrate) unlockErr(prevErr error) error {\n\tif err := m.unlock(); err != nil {\n\t\treturn NewMultiError(prevErr, err)\n\t}\n\treturn prevErr\n}\n\n// logPrintf writes to m.Log if not nil\nfunc (m *Migrate) logPrintf(format string, v ...interface{}) {\n\tif m.Log != nil {\n\t\tm.Log.Printf(format, v...)\n\t}\n}\n\n// logVerbosePrintf writes to m.Log if not nil. Use for verbose logging output.\nfunc (m *Migrate) logVerbosePrintf(format string, v ...interface{}) {\n\tif m.Log != nil && m.Log.Verbose() {\n\t\tm.Log.Printf(format, v...)\n\t}\n}\n"
        },
        {
          "name": "migrate_test.go",
          "type": "blob",
          "size": 29.4267578125,
          "content": "package migrate\n\nimport (\n\t\"bytes\"\n\t\"database/sql\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"os\"\n\t\"testing\"\n\n\tdStub \"github.com/mattes/migrate/database/stub\"\n\t\"github.com/mattes/migrate/source\"\n\tsStub \"github.com/mattes/migrate/source/stub\"\n)\n\n// sourceStubMigrations hold the following migrations:\n// u = up migration, d = down migration, n = version\n//  |  1  |  -  |  3  |  4  |  5  |  -  |  7  |\n//  | u d |  -  | u   | u d |   d |  -  | u d |\nvar sourceStubMigrations *source.Migrations\n\nfunc init() {\n\tsourceStubMigrations = source.NewMigrations()\n\tsourceStubMigrations.Append(&source.Migration{Version: 1, Direction: source.Up})\n\tsourceStubMigrations.Append(&source.Migration{Version: 1, Direction: source.Down})\n\tsourceStubMigrations.Append(&source.Migration{Version: 3, Direction: source.Up})\n\tsourceStubMigrations.Append(&source.Migration{Version: 4, Direction: source.Up})\n\tsourceStubMigrations.Append(&source.Migration{Version: 4, Direction: source.Down})\n\tsourceStubMigrations.Append(&source.Migration{Version: 5, Direction: source.Down})\n\tsourceStubMigrations.Append(&source.Migration{Version: 7, Direction: source.Up})\n\tsourceStubMigrations.Append(&source.Migration{Version: 7, Direction: source.Down})\n}\n\ntype DummyInstance struct{ Name string }\n\nfunc TestNew(t *testing.T) {\n\tm, err := New(\"stub://\", \"stub://\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif m.sourceName != \"stub\" {\n\t\tt.Errorf(\"expected stub, got %v\", m.sourceName)\n\t}\n\tif m.sourceDrv == nil {\n\t\tt.Error(\"expected sourceDrv not to be nil\")\n\t}\n\n\tif m.databaseName != \"stub\" {\n\t\tt.Errorf(\"expected stub, got %v\", m.databaseName)\n\t}\n\tif m.databaseDrv == nil {\n\t\tt.Error(\"expected databaseDrv not to be nil\")\n\t}\n}\n\nfunc ExampleNew() {\n\t// Read migrations from /home/mattes/migrations and connect to a local postgres database.\n\tm, err := New(\"file:///home/mattes/migrations\", \"postgres://mattes:secret@localhost:5432/database?sslmode=disable\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Migrate all the way up ...\n\tif err := m.Up(); err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\nfunc TestNewWithDatabaseInstance(t *testing.T) {\n\tdummyDb := &DummyInstance{\"database\"}\n\tdbInst, err := dStub.WithInstance(dummyDb, &dStub.Config{})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tm, err := NewWithDatabaseInstance(\"stub://\", \"stub\", dbInst)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif m.sourceName != \"stub\" {\n\t\tt.Errorf(\"expected stub, got %v\", m.sourceName)\n\t}\n\tif m.sourceDrv == nil {\n\t\tt.Error(\"expected sourceDrv not to be nil\")\n\t}\n\n\tif m.databaseName != \"stub\" {\n\t\tt.Errorf(\"expected stub, got %v\", m.databaseName)\n\t}\n\tif m.databaseDrv == nil {\n\t\tt.Error(\"expected databaseDrv not to be nil\")\n\t}\n}\n\nfunc ExampleNewWithDatabaseInstance() {\n\t// Create and use an existing database instance.\n\tdb, err := sql.Open(\"postgres\", \"postgres://mattes:secret@localhost:5432/database?sslmode=disable\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer db.Close()\n\n\t// Create driver instance from db.\n\t// Check each driver if it supports the WithInstance function.\n\t// `import \"github.com/mattes/migrate/database/postgres\"`\n\tinstance, err := dStub.WithInstance(db, &dStub.Config{})\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Read migrations from /home/mattes/migrations and connect to a local postgres database.\n\tm, err := NewWithDatabaseInstance(\"file:///home/mattes/migrations\", \"postgres\", instance)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Migrate all the way up ...\n\tif err := m.Up(); err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\nfunc TestNewWithSourceInstance(t *testing.T) {\n\tdummySource := &DummyInstance{\"source\"}\n\tsInst, err := sStub.WithInstance(dummySource, &sStub.Config{})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tm, err := NewWithSourceInstance(\"stub\", sInst, \"stub://\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif m.sourceName != \"stub\" {\n\t\tt.Errorf(\"expected stub, got %v\", m.sourceName)\n\t}\n\tif m.sourceDrv == nil {\n\t\tt.Error(\"expected sourceDrv not to be nil\")\n\t}\n\n\tif m.databaseName != \"stub\" {\n\t\tt.Errorf(\"expected stub, got %v\", m.databaseName)\n\t}\n\tif m.databaseDrv == nil {\n\t\tt.Error(\"expected databaseDrv not to be nil\")\n\t}\n}\n\nfunc ExampleNewWithSourceInstance() {\n\tdi := &DummyInstance{\"think any client required for a source here\"}\n\n\t// Create driver instance from DummyInstance di.\n\t// Check each driver if it support the WithInstance function.\n\t// `import \"github.com/mattes/migrate/source/stub\"`\n\tinstance, err := sStub.WithInstance(di, &sStub.Config{})\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Read migrations from Stub and connect to a local postgres database.\n\tm, err := NewWithSourceInstance(\"stub\", instance, \"postgres://mattes:secret@localhost:5432/database?sslmode=disable\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Migrate all the way up ...\n\tif err := m.Up(); err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\nfunc TestNewWithInstance(t *testing.T) {\n\tdummyDb := &DummyInstance{\"database\"}\n\tdbInst, err := dStub.WithInstance(dummyDb, &dStub.Config{})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tdummySource := &DummyInstance{\"source\"}\n\tsInst, err := sStub.WithInstance(dummySource, &sStub.Config{})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tm, err := NewWithInstance(\"stub\", sInst, \"stub\", dbInst)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif m.sourceName != \"stub\" {\n\t\tt.Errorf(\"expected stub, got %v\", m.sourceName)\n\t}\n\tif m.sourceDrv == nil {\n\t\tt.Error(\"expected sourceDrv not to be nil\")\n\t}\n\n\tif m.databaseName != \"stub\" {\n\t\tt.Errorf(\"expected stub, got %v\", m.databaseName)\n\t}\n\tif m.databaseDrv == nil {\n\t\tt.Error(\"expected databaseDrv not to be nil\")\n\t}\n}\n\nfunc ExampleNewWithInstance() {\n\t// See NewWithDatabaseInstance and NewWithSourceInstance for an example.\n}\n\nfunc TestClose(t *testing.T) {\n\tm, _ := New(\"stub://\", \"stub://\")\n\tsourceErr, databaseErr := m.Close()\n\tif sourceErr != nil {\n\t\tt.Error(sourceErr)\n\t}\n\tif databaseErr != nil {\n\t\tt.Error(databaseErr)\n\t}\n}\n\nfunc TestMigrate(t *testing.T) {\n\tm, _ := New(\"stub://\", \"stub://\")\n\tm.sourceDrv.(*sStub.Stub).Migrations = sourceStubMigrations\n\tdbDrv := m.databaseDrv.(*dStub.Stub)\n\tseq := newMigSeq()\n\n\ttt := []struct {\n\t\tversion       uint\n\t\texpectErr     error\n\t\texpectVersion uint\n\t\texpectSeq     migrationSequence\n\t}{\n\t\t// migrate all the way Up in single steps\n\t\t{version: 0, expectErr: os.ErrNotExist},\n\t\t{version: 1, expectErr: nil, expectVersion: 1, expectSeq: seq.add(M(1))},\n\t\t{version: 2, expectErr: os.ErrNotExist},\n\t\t{version: 3, expectErr: nil, expectVersion: 3, expectSeq: seq.add(M(3))},\n\t\t{version: 4, expectErr: nil, expectVersion: 4, expectSeq: seq.add(M(4))},\n\t\t{version: 5, expectErr: nil, expectVersion: 5, expectSeq: seq.add()}, // 5 has no up migration\n\t\t{version: 6, expectErr: os.ErrNotExist},\n\t\t{version: 7, expectErr: nil, expectVersion: 7, expectSeq: seq.add(M(7))},\n\t\t{version: 8, expectErr: os.ErrNotExist},\n\n\t\t// migrate all the way Down in single steps\n\t\t{version: 6, expectErr: os.ErrNotExist},\n\t\t{version: 5, expectErr: nil, expectVersion: 5, expectSeq: seq.add(M(7, 5))},\n\t\t{version: 4, expectErr: nil, expectVersion: 4, expectSeq: seq.add(M(5, 4))},\n\t\t{version: 3, expectErr: nil, expectVersion: 3, expectSeq: seq.add(M(4, 3))},\n\t\t{version: 2, expectErr: os.ErrNotExist},\n\t\t{version: 1, expectErr: nil, expectVersion: 1, expectSeq: seq.add()}, // 3 has no down migration\n\t\t{version: 0, expectErr: os.ErrNotExist},\n\n\t\t// migrate all the way Up in one step\n\t\t{version: 7, expectErr: nil, expectVersion: 7, expectSeq: seq.add(M(3), M(4), M(7))},\n\n\t\t// migrate all the way Down in one step\n\t\t{version: 1, expectErr: nil, expectVersion: 1, expectSeq: seq.add(M(7, 5), M(5, 4), M(4, 3), M(3, 1))},\n\n\t\t// can't migrate the same version twice\n\t\t{version: 1, expectErr: ErrNoChange},\n\t}\n\n\tfor i, v := range tt {\n\t\terr := m.Migrate(v.version)\n\t\tif (v.expectErr == os.ErrNotExist && !os.IsNotExist(err)) ||\n\t\t\t(v.expectErr != os.ErrNotExist && err != v.expectErr) {\n\t\t\tt.Errorf(\"expected err %v, got %v, in %v\", v.expectErr, err, i)\n\n\t\t} else if err == nil {\n\t\t\tversion, _, err := m.Version()\n\t\t\tif err != nil {\n\t\t\t\tt.Error(err)\n\t\t\t}\n\t\t\tif version != v.expectVersion {\n\t\t\t\tt.Errorf(\"expected version %v, got %v, in %v\", v.expectVersion, version, i)\n\t\t\t}\n\t\t\tequalDbSeq(t, i, v.expectSeq, dbDrv)\n\t\t}\n\t}\n}\n\nfunc TestMigrateDirty(t *testing.T) {\n\tm, _ := New(\"stub://\", \"stub://\")\n\tdbDrv := m.databaseDrv.(*dStub.Stub)\n\tif err := dbDrv.SetVersion(0, true); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\terr := m.Migrate(1)\n\tif _, ok := err.(ErrDirty); !ok {\n\t\tt.Fatalf(\"expected ErrDirty, got %v\", err)\n\t}\n}\n\nfunc TestSteps(t *testing.T) {\n\tm, _ := New(\"stub://\", \"stub://\")\n\tm.sourceDrv.(*sStub.Stub).Migrations = sourceStubMigrations\n\tdbDrv := m.databaseDrv.(*dStub.Stub)\n\tseq := newMigSeq()\n\n\ttt := []struct {\n\t\tn             int\n\t\texpectErr     error\n\t\texpectVersion int\n\t\texpectSeq     migrationSequence\n\t}{\n\t\t// step must be != 0\n\t\t{n: 0, expectErr: ErrNoChange},\n\n\t\t// can't go Down if ErrNilVersion\n\t\t{n: -1, expectErr: os.ErrNotExist},\n\n\t\t// migrate all the way Up\n\t\t{n: 1, expectErr: nil, expectVersion: 1, expectSeq: seq.add(M(1))},\n\t\t{n: 1, expectErr: nil, expectVersion: 3, expectSeq: seq.add(M(3))},\n\t\t{n: 1, expectErr: nil, expectVersion: 4, expectSeq: seq.add(M(4))},\n\t\t{n: 1, expectErr: nil, expectVersion: 5, expectSeq: seq.add()},\n\t\t{n: 1, expectErr: nil, expectVersion: 7, expectSeq: seq.add(M(7))},\n\t\t{n: 1, expectErr: os.ErrNotExist},\n\n\t\t// migrate all the way Down\n\t\t{n: -1, expectErr: nil, expectVersion: 5, expectSeq: seq.add(M(7, 5))},\n\t\t{n: -1, expectErr: nil, expectVersion: 4, expectSeq: seq.add(M(5, 4))},\n\t\t{n: -1, expectErr: nil, expectVersion: 3, expectSeq: seq.add(M(4, 3))},\n\t\t{n: -1, expectErr: nil, expectVersion: 1, expectSeq: seq.add(M(3, 1))},\n\t\t{n: -1, expectErr: nil, expectVersion: -1, expectSeq: seq.add(M(1, -1))},\n\n\t\t// migrate Up in bigger step\n\t\t{n: 4, expectErr: nil, expectVersion: 5, expectSeq: seq.add(M(1), M(3), M(4), M(5))},\n\n\t\t// apply one migration, then reaches out of boundary\n\t\t{n: 2, expectErr: ErrShortLimit{1}, expectVersion: 7, expectSeq: seq.add(M(7))},\n\n\t\t// migrate Down in bigger step\n\t\t{n: -4, expectErr: nil, expectVersion: 1, expectSeq: seq.add(M(7, 5), M(5, 4), M(4, 3), M(3, 1))},\n\n\t\t// apply one migration, then reaches out of boundary\n\t\t{n: -2, expectErr: ErrShortLimit{1}, expectVersion: -1, expectSeq: seq.add(M(1, -1))},\n\t}\n\n\tfor i, v := range tt {\n\t\terr := m.Steps(v.n)\n\t\tif (v.expectErr == os.ErrNotExist && !os.IsNotExist(err)) ||\n\t\t\t(v.expectErr != os.ErrNotExist && err != v.expectErr) {\n\t\t\tt.Errorf(\"expected err %v, got %v, in %v\", v.expectErr, err, i)\n\n\t\t} else if err == nil {\n\t\t\tversion, _, err := m.Version()\n\t\t\tif err != ErrNilVersion && err != nil {\n\t\t\t\tt.Error(err)\n\t\t\t}\n\t\t\tif v.expectVersion == -1 && err != ErrNilVersion {\n\t\t\t\tt.Errorf(\"expected ErrNilVersion, got %v, in %v\", version, i)\n\n\t\t\t} else if v.expectVersion >= 0 && version != uint(v.expectVersion) {\n\t\t\t\tt.Errorf(\"expected version %v, got %v, in %v\", v.expectVersion, version, i)\n\t\t\t}\n\t\t\tequalDbSeq(t, i, v.expectSeq, dbDrv)\n\t\t}\n\t}\n}\n\nfunc TestStepsDirty(t *testing.T) {\n\tm, _ := New(\"stub://\", \"stub://\")\n\tdbDrv := m.databaseDrv.(*dStub.Stub)\n\tif err := dbDrv.SetVersion(0, true); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\terr := m.Steps(1)\n\tif _, ok := err.(ErrDirty); !ok {\n\t\tt.Fatalf(\"expected ErrDirty, got %v\", err)\n\t}\n}\n\nfunc TestUpAndDown(t *testing.T) {\n\tm, _ := New(\"stub://\", \"stub://\")\n\tm.sourceDrv.(*sStub.Stub).Migrations = sourceStubMigrations\n\tdbDrv := m.databaseDrv.(*dStub.Stub)\n\tseq := newMigSeq()\n\n\t// go Up first\n\tif err := m.Up(); err != nil {\n\t\tt.Fatal(err)\n\t}\n\tequalDbSeq(t, 0, seq.add(M(1), M(3), M(4), M(5), M(7)), dbDrv)\n\n\t// go Down\n\tif err := m.Down(); err != nil {\n\t\tt.Fatal(err)\n\t}\n\tequalDbSeq(t, 1, seq.add(M(7, 5), M(5, 4), M(4, 3), M(3, 1), M(1, -1)), dbDrv)\n\n\t// go 1 Up and then all the way Up\n\tif err := m.Steps(1); err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif err := m.Up(); err != nil {\n\t\tt.Fatal(err)\n\t}\n\tequalDbSeq(t, 2, seq.add(M(1), M(3), M(4), M(5), M(7)), dbDrv)\n\n\t// go 1 Down and then all the way Down\n\tif err := m.Steps(-1); err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif err := m.Down(); err != nil {\n\t\tt.Fatal(err)\n\t}\n\tequalDbSeq(t, 0, seq.add(M(7, 5), M(5, 4), M(4, 3), M(3, 1), M(1, -1)), dbDrv)\n}\n\nfunc TestUpDirty(t *testing.T) {\n\tm, _ := New(\"stub://\", \"stub://\")\n\tdbDrv := m.databaseDrv.(*dStub.Stub)\n\tif err := dbDrv.SetVersion(0, true); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\terr := m.Up()\n\tif _, ok := err.(ErrDirty); !ok {\n\t\tt.Fatalf(\"expected ErrDirty, got %v\", err)\n\t}\n}\n\nfunc TestDownDirty(t *testing.T) {\n\tm, _ := New(\"stub://\", \"stub://\")\n\tdbDrv := m.databaseDrv.(*dStub.Stub)\n\tif err := dbDrv.SetVersion(0, true); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\terr := m.Down()\n\tif _, ok := err.(ErrDirty); !ok {\n\t\tt.Fatalf(\"expected ErrDirty, got %v\", err)\n\t}\n}\n\nfunc TestDrop(t *testing.T) {\n\tm, _ := New(\"stub://\", \"stub://\")\n\tm.sourceDrv.(*sStub.Stub).Migrations = sourceStubMigrations\n\tdbDrv := m.databaseDrv.(*dStub.Stub)\n\n\tif err := m.Drop(); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif dbDrv.MigrationSequence[len(dbDrv.MigrationSequence)-1] != dStub.DROP {\n\t\tt.Fatalf(\"expected database to DROP, got sequence %v\", dbDrv.MigrationSequence)\n\t}\n}\n\nfunc TestVersion(t *testing.T) {\n\tm, _ := New(\"stub://\", \"stub://\")\n\tdbDrv := m.databaseDrv.(*dStub.Stub)\n\n\t_, _, err := m.Version()\n\tif err != ErrNilVersion {\n\t\tt.Fatalf(\"expected ErrNilVersion, got %v\", err)\n\t}\n\n\tif err := dbDrv.Run(bytes.NewBufferString(\"1_up\")); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif err := dbDrv.SetVersion(1, false); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tv, _, err := m.Version()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif v != 1 {\n\t\tt.Fatalf(\"expected version 1, got %v\", v)\n\t}\n}\n\nfunc TestRun(t *testing.T) {\n\tm, _ := New(\"stub://\", \"stub://\")\n\n\tmx, err := NewMigration(nil, \"\", 1, 2)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif err := m.Run(mx); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tv, _, err := m.Version()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif v != 2 {\n\t\tt.Errorf(\"expected version 2, got %v\", v)\n\t}\n}\n\nfunc TestRunDirty(t *testing.T) {\n\tm, _ := New(\"stub://\", \"stub://\")\n\tdbDrv := m.databaseDrv.(*dStub.Stub)\n\tif err := dbDrv.SetVersion(0, true); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tmigr, err := NewMigration(nil, \"\", 1, 2)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\terr = m.Run(migr)\n\tif _, ok := err.(ErrDirty); !ok {\n\t\tt.Fatalf(\"expected ErrDirty, got %v\", err)\n\t}\n}\n\nfunc TestForce(t *testing.T) {\n\tm, _ := New(\"stub://\", \"stub://\")\n\tm.sourceDrv.(*sStub.Stub).Migrations = sourceStubMigrations\n\n\tif err := m.Force(7); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tv, dirty, err := m.Version()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif dirty {\n\t\tt.Errorf(\"expected dirty to be false\")\n\t}\n\tif v != 7 {\n\t\tt.Errorf(\"expected version to be 7\")\n\t}\n}\n\nfunc TestForceDirty(t *testing.T) {\n\tm, _ := New(\"stub://\", \"stub://\")\n\tdbDrv := m.databaseDrv.(*dStub.Stub)\n\tif err := dbDrv.SetVersion(0, true); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif err := m.Force(1); err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestRead(t *testing.T) {\n\tm, _ := New(\"stub://\", \"stub://\")\n\tm.sourceDrv.(*sStub.Stub).Migrations = sourceStubMigrations\n\n\ttt := []struct {\n\t\tfrom             int\n\t\tto               int\n\t\texpectErr        error\n\t\texpectMigrations migrationSequence\n\t}{\n\t\t{from: -1, to: -1, expectErr: ErrNoChange},\n\t\t{from: -1, to: 0, expectErr: os.ErrNotExist},\n\t\t{from: -1, to: 1, expectErr: nil, expectMigrations: newMigSeq(M(1))},\n\t\t{from: -1, to: 2, expectErr: os.ErrNotExist},\n\t\t{from: -1, to: 3, expectErr: nil, expectMigrations: newMigSeq(M(1), M(3))},\n\t\t{from: -1, to: 4, expectErr: nil, expectMigrations: newMigSeq(M(1), M(3), M(4))},\n\t\t{from: -1, to: 5, expectErr: nil, expectMigrations: newMigSeq(M(1), M(3), M(4), M(5))},\n\t\t{from: -1, to: 6, expectErr: os.ErrNotExist},\n\t\t{from: -1, to: 7, expectErr: nil, expectMigrations: newMigSeq(M(1), M(3), M(4), M(5), M(7))},\n\t\t{from: -1, to: 8, expectErr: os.ErrNotExist},\n\n\t\t{from: 0, to: -1, expectErr: os.ErrNotExist},\n\t\t{from: 0, to: 0, expectErr: os.ErrNotExist},\n\t\t{from: 0, to: 1, expectErr: os.ErrNotExist},\n\t\t{from: 0, to: 2, expectErr: os.ErrNotExist},\n\t\t{from: 0, to: 3, expectErr: os.ErrNotExist},\n\t\t{from: 0, to: 4, expectErr: os.ErrNotExist},\n\t\t{from: 0, to: 5, expectErr: os.ErrNotExist},\n\t\t{from: 0, to: 6, expectErr: os.ErrNotExist},\n\t\t{from: 0, to: 7, expectErr: os.ErrNotExist},\n\t\t{from: 0, to: 8, expectErr: os.ErrNotExist},\n\n\t\t{from: 1, to: -1, expectErr: nil, expectMigrations: newMigSeq(M(1, -1))},\n\t\t{from: 1, to: 0, expectErr: os.ErrNotExist},\n\t\t{from: 1, to: 1, expectErr: ErrNoChange},\n\t\t{from: 1, to: 2, expectErr: os.ErrNotExist},\n\t\t{from: 1, to: 3, expectErr: nil, expectMigrations: newMigSeq(M(3))},\n\t\t{from: 1, to: 4, expectErr: nil, expectMigrations: newMigSeq(M(3), M(4))},\n\t\t{from: 1, to: 5, expectErr: nil, expectMigrations: newMigSeq(M(3), M(4), M(5))},\n\t\t{from: 1, to: 6, expectErr: os.ErrNotExist},\n\t\t{from: 1, to: 7, expectErr: nil, expectMigrations: newMigSeq(M(3), M(4), M(5), M(7))},\n\t\t{from: 1, to: 8, expectErr: os.ErrNotExist},\n\n\t\t{from: 2, to: -1, expectErr: os.ErrNotExist},\n\t\t{from: 2, to: 0, expectErr: os.ErrNotExist},\n\t\t{from: 2, to: 1, expectErr: os.ErrNotExist},\n\t\t{from: 2, to: 2, expectErr: os.ErrNotExist},\n\t\t{from: 2, to: 3, expectErr: os.ErrNotExist},\n\t\t{from: 2, to: 4, expectErr: os.ErrNotExist},\n\t\t{from: 2, to: 5, expectErr: os.ErrNotExist},\n\t\t{from: 2, to: 6, expectErr: os.ErrNotExist},\n\t\t{from: 2, to: 7, expectErr: os.ErrNotExist},\n\t\t{from: 2, to: 8, expectErr: os.ErrNotExist},\n\n\t\t{from: 3, to: -1, expectErr: nil, expectMigrations: newMigSeq(M(3, 1), M(1, -1))},\n\t\t{from: 3, to: 0, expectErr: os.ErrNotExist},\n\t\t{from: 3, to: 1, expectErr: nil, expectMigrations: newMigSeq(M(3, 1))},\n\t\t{from: 3, to: 2, expectErr: os.ErrNotExist},\n\t\t{from: 3, to: 3, expectErr: ErrNoChange},\n\t\t{from: 3, to: 4, expectErr: nil, expectMigrations: newMigSeq(M(4))},\n\t\t{from: 3, to: 5, expectErr: nil, expectMigrations: newMigSeq(M(4), M(5))},\n\t\t{from: 3, to: 6, expectErr: os.ErrNotExist},\n\t\t{from: 3, to: 7, expectErr: nil, expectMigrations: newMigSeq(M(4), M(5), M(7))},\n\t\t{from: 3, to: 8, expectErr: os.ErrNotExist},\n\n\t\t{from: 4, to: -1, expectErr: nil, expectMigrations: newMigSeq(M(4, 3), M(3, 1), M(1, -1))},\n\t\t{from: 4, to: 0, expectErr: os.ErrNotExist},\n\t\t{from: 4, to: 1, expectErr: nil, expectMigrations: newMigSeq(M(4, 3), M(3, 1))},\n\t\t{from: 4, to: 2, expectErr: os.ErrNotExist},\n\t\t{from: 4, to: 3, expectErr: nil, expectMigrations: newMigSeq(M(4, 3))},\n\t\t{from: 4, to: 4, expectErr: ErrNoChange},\n\t\t{from: 4, to: 5, expectErr: nil, expectMigrations: newMigSeq(M(5))},\n\t\t{from: 4, to: 6, expectErr: os.ErrNotExist},\n\t\t{from: 4, to: 7, expectErr: nil, expectMigrations: newMigSeq(M(5), M(7))},\n\t\t{from: 4, to: 8, expectErr: os.ErrNotExist},\n\n\t\t{from: 5, to: -1, expectErr: nil, expectMigrations: newMigSeq(M(5, 4), M(4, 3), M(3, 1), M(1, -1))},\n\t\t{from: 5, to: 0, expectErr: os.ErrNotExist},\n\t\t{from: 5, to: 1, expectErr: nil, expectMigrations: newMigSeq(M(5, 4), M(4, 3), M(3, 1))},\n\t\t{from: 5, to: 2, expectErr: os.ErrNotExist},\n\t\t{from: 5, to: 3, expectErr: nil, expectMigrations: newMigSeq(M(5, 4), M(4, 3))},\n\t\t{from: 5, to: 4, expectErr: nil, expectMigrations: newMigSeq(M(5, 4))},\n\t\t{from: 5, to: 5, expectErr: ErrNoChange},\n\t\t{from: 5, to: 6, expectErr: os.ErrNotExist},\n\t\t{from: 5, to: 7, expectErr: nil, expectMigrations: newMigSeq(M(7))},\n\t\t{from: 5, to: 8, expectErr: os.ErrNotExist},\n\n\t\t{from: 6, to: -1, expectErr: os.ErrNotExist},\n\t\t{from: 6, to: 0, expectErr: os.ErrNotExist},\n\t\t{from: 6, to: 1, expectErr: os.ErrNotExist},\n\t\t{from: 6, to: 2, expectErr: os.ErrNotExist},\n\t\t{from: 6, to: 3, expectErr: os.ErrNotExist},\n\t\t{from: 6, to: 4, expectErr: os.ErrNotExist},\n\t\t{from: 6, to: 5, expectErr: os.ErrNotExist},\n\t\t{from: 6, to: 6, expectErr: os.ErrNotExist},\n\t\t{from: 6, to: 7, expectErr: os.ErrNotExist},\n\t\t{from: 6, to: 8, expectErr: os.ErrNotExist},\n\n\t\t{from: 7, to: -1, expectErr: nil, expectMigrations: newMigSeq(M(7, 5), M(5, 4), M(4, 3), M(3, 1), M(1, -1))},\n\t\t{from: 7, to: 0, expectErr: os.ErrNotExist},\n\t\t{from: 7, to: 1, expectErr: nil, expectMigrations: newMigSeq(M(7, 5), M(5, 4), M(4, 3), M(3, 1))},\n\t\t{from: 7, to: 2, expectErr: os.ErrNotExist},\n\t\t{from: 7, to: 3, expectErr: nil, expectMigrations: newMigSeq(M(7, 5), M(5, 4), M(4, 3))},\n\t\t{from: 7, to: 4, expectErr: nil, expectMigrations: newMigSeq(M(7, 5), M(5, 4))},\n\t\t{from: 7, to: 5, expectErr: nil, expectMigrations: newMigSeq(M(7, 5))},\n\t\t{from: 7, to: 6, expectErr: os.ErrNotExist},\n\t\t{from: 7, to: 7, expectErr: ErrNoChange},\n\t\t{from: 7, to: 8, expectErr: os.ErrNotExist},\n\n\t\t{from: 8, to: -1, expectErr: os.ErrNotExist},\n\t\t{from: 8, to: 0, expectErr: os.ErrNotExist},\n\t\t{from: 8, to: 1, expectErr: os.ErrNotExist},\n\t\t{from: 8, to: 2, expectErr: os.ErrNotExist},\n\t\t{from: 8, to: 3, expectErr: os.ErrNotExist},\n\t\t{from: 8, to: 4, expectErr: os.ErrNotExist},\n\t\t{from: 8, to: 5, expectErr: os.ErrNotExist},\n\t\t{from: 8, to: 6, expectErr: os.ErrNotExist},\n\t\t{from: 8, to: 7, expectErr: os.ErrNotExist},\n\t\t{from: 8, to: 8, expectErr: os.ErrNotExist},\n\t}\n\n\tfor i, v := range tt {\n\t\tret := make(chan interface{})\n\t\tgo m.read(v.from, v.to, ret)\n\t\tmigrations, err := migrationsFromChannel(ret)\n\n\t\tif (v.expectErr == os.ErrNotExist && !os.IsNotExist(err)) ||\n\t\t\t(v.expectErr != os.ErrNotExist && v.expectErr != err) {\n\t\t\tt.Errorf(\"expected %v, got %v, in %v\", v.expectErr, err, i)\n\t\t\tt.Logf(\"%v, in %v\", migrations, i)\n\t\t}\n\t\tif len(v.expectMigrations) > 0 {\n\t\t\tequalMigSeq(t, i, v.expectMigrations, migrations)\n\t\t}\n\t}\n}\n\nfunc TestReadUp(t *testing.T) {\n\tm, _ := New(\"stub://\", \"stub://\")\n\tm.sourceDrv.(*sStub.Stub).Migrations = sourceStubMigrations\n\n\ttt := []struct {\n\t\tfrom             int\n\t\tlimit            int // -1 means no limit\n\t\texpectErr        error\n\t\texpectMigrations migrationSequence\n\t}{\n\t\t{from: -1, limit: -1, expectErr: nil, expectMigrations: newMigSeq(M(1), M(3), M(4), M(5), M(7))},\n\t\t{from: -1, limit: 0, expectErr: ErrNoChange},\n\t\t{from: -1, limit: 1, expectErr: nil, expectMigrations: newMigSeq(M(1))},\n\t\t{from: -1, limit: 2, expectErr: nil, expectMigrations: newMigSeq(M(1), M(3))},\n\n\t\t{from: 0, limit: -1, expectErr: os.ErrNotExist},\n\t\t{from: 0, limit: 0, expectErr: os.ErrNotExist},\n\t\t{from: 0, limit: 1, expectErr: os.ErrNotExist},\n\t\t{from: 0, limit: 2, expectErr: os.ErrNotExist},\n\n\t\t{from: 1, limit: -1, expectErr: nil, expectMigrations: newMigSeq(M(3), M(4), M(5), M(7))},\n\t\t{from: 1, limit: 0, expectErr: ErrNoChange},\n\t\t{from: 1, limit: 1, expectErr: nil, expectMigrations: newMigSeq(M(3))},\n\t\t{from: 1, limit: 2, expectErr: nil, expectMigrations: newMigSeq(M(3), M(4))},\n\n\t\t{from: 2, limit: -1, expectErr: os.ErrNotExist},\n\t\t{from: 2, limit: 0, expectErr: os.ErrNotExist},\n\t\t{from: 2, limit: 1, expectErr: os.ErrNotExist},\n\t\t{from: 2, limit: 2, expectErr: os.ErrNotExist},\n\n\t\t{from: 3, limit: -1, expectErr: nil, expectMigrations: newMigSeq(M(4), M(5), M(7))},\n\t\t{from: 3, limit: 0, expectErr: ErrNoChange},\n\t\t{from: 3, limit: 1, expectErr: nil, expectMigrations: newMigSeq(M(4))},\n\t\t{from: 3, limit: 2, expectErr: nil, expectMigrations: newMigSeq(M(4), M(5))},\n\n\t\t{from: 4, limit: -1, expectErr: nil, expectMigrations: newMigSeq(M(5), M(7))},\n\t\t{from: 4, limit: 0, expectErr: ErrNoChange},\n\t\t{from: 4, limit: 1, expectErr: nil, expectMigrations: newMigSeq(M(5))},\n\t\t{from: 4, limit: 2, expectErr: nil, expectMigrations: newMigSeq(M(5), M(7))},\n\n\t\t{from: 5, limit: -1, expectErr: nil, expectMigrations: newMigSeq(M(7))},\n\t\t{from: 5, limit: 0, expectErr: ErrNoChange},\n\t\t{from: 5, limit: 1, expectErr: nil, expectMigrations: newMigSeq(M(7))},\n\t\t{from: 5, limit: 2, expectErr: ErrShortLimit{1}, expectMigrations: newMigSeq(M(7))},\n\n\t\t{from: 6, limit: -1, expectErr: os.ErrNotExist},\n\t\t{from: 6, limit: 0, expectErr: os.ErrNotExist},\n\t\t{from: 6, limit: 1, expectErr: os.ErrNotExist},\n\t\t{from: 6, limit: 2, expectErr: os.ErrNotExist},\n\n\t\t{from: 7, limit: -1, expectErr: ErrNoChange},\n\t\t{from: 7, limit: 0, expectErr: ErrNoChange},\n\t\t{from: 7, limit: 1, expectErr: os.ErrNotExist},\n\t\t{from: 7, limit: 2, expectErr: os.ErrNotExist},\n\n\t\t{from: 8, limit: -1, expectErr: os.ErrNotExist},\n\t\t{from: 8, limit: 0, expectErr: os.ErrNotExist},\n\t\t{from: 8, limit: 1, expectErr: os.ErrNotExist},\n\t\t{from: 8, limit: 2, expectErr: os.ErrNotExist},\n\t}\n\n\tfor i, v := range tt {\n\t\tret := make(chan interface{})\n\t\tgo m.readUp(v.from, v.limit, ret)\n\t\tmigrations, err := migrationsFromChannel(ret)\n\n\t\tif (v.expectErr == os.ErrNotExist && !os.IsNotExist(err)) ||\n\t\t\t(v.expectErr != os.ErrNotExist && v.expectErr != err) {\n\t\t\tt.Errorf(\"expected %v, got %v, in %v\", v.expectErr, err, i)\n\t\t\tt.Logf(\"%v, in %v\", migrations, i)\n\t\t}\n\t\tif len(v.expectMigrations) > 0 {\n\t\t\tequalMigSeq(t, i, v.expectMigrations, migrations)\n\t\t}\n\t}\n}\n\nfunc TestReadDown(t *testing.T) {\n\tm, _ := New(\"stub://\", \"stub://\")\n\tm.sourceDrv.(*sStub.Stub).Migrations = sourceStubMigrations\n\n\ttt := []struct {\n\t\tfrom             int\n\t\tlimit            int // -1 means no limit\n\t\texpectErr        error\n\t\texpectMigrations migrationSequence\n\t}{\n\t\t{from: -1, limit: -1, expectErr: ErrNoChange},\n\t\t{from: -1, limit: 0, expectErr: ErrNoChange},\n\t\t{from: -1, limit: 1, expectErr: os.ErrNotExist},\n\t\t{from: -1, limit: 2, expectErr: os.ErrNotExist},\n\n\t\t{from: 0, limit: -1, expectErr: os.ErrNotExist},\n\t\t{from: 0, limit: 0, expectErr: os.ErrNotExist},\n\t\t{from: 0, limit: 1, expectErr: os.ErrNotExist},\n\t\t{from: 0, limit: 2, expectErr: os.ErrNotExist},\n\n\t\t{from: 1, limit: -1, expectErr: nil, expectMigrations: newMigSeq(M(1, -1))},\n\t\t{from: 1, limit: 0, expectErr: ErrNoChange},\n\t\t{from: 1, limit: 1, expectErr: nil, expectMigrations: newMigSeq(M(1, -1))},\n\t\t{from: 1, limit: 2, expectErr: ErrShortLimit{1}, expectMigrations: newMigSeq(M(1, -1))},\n\n\t\t{from: 2, limit: -1, expectErr: os.ErrNotExist},\n\t\t{from: 2, limit: 0, expectErr: os.ErrNotExist},\n\t\t{from: 2, limit: 1, expectErr: os.ErrNotExist},\n\t\t{from: 2, limit: 2, expectErr: os.ErrNotExist},\n\n\t\t{from: 3, limit: -1, expectErr: nil, expectMigrations: newMigSeq(M(3, 1), M(1, -1))},\n\t\t{from: 3, limit: 0, expectErr: ErrNoChange},\n\t\t{from: 3, limit: 1, expectErr: nil, expectMigrations: newMigSeq(M(3, 1))},\n\t\t{from: 3, limit: 2, expectErr: nil, expectMigrations: newMigSeq(M(3, 1), M(1, -1))},\n\n\t\t{from: 4, limit: -1, expectErr: nil, expectMigrations: newMigSeq(M(4, 3), M(3, 1), M(1, -1))},\n\t\t{from: 4, limit: 0, expectErr: ErrNoChange},\n\t\t{from: 4, limit: 1, expectErr: nil, expectMigrations: newMigSeq(M(4, 3))},\n\t\t{from: 4, limit: 2, expectErr: nil, expectMigrations: newMigSeq(M(4, 3), M(3, 1))},\n\n\t\t{from: 5, limit: -1, expectErr: nil, expectMigrations: newMigSeq(M(5, 4), M(4, 3), M(3, 1), M(1, -1))},\n\t\t{from: 5, limit: 0, expectErr: ErrNoChange},\n\t\t{from: 5, limit: 1, expectErr: nil, expectMigrations: newMigSeq(M(5, 4))},\n\t\t{from: 5, limit: 2, expectErr: nil, expectMigrations: newMigSeq(M(5, 4), M(4, 3))},\n\n\t\t{from: 6, limit: -1, expectErr: os.ErrNotExist},\n\t\t{from: 6, limit: 0, expectErr: os.ErrNotExist},\n\t\t{from: 6, limit: 1, expectErr: os.ErrNotExist},\n\t\t{from: 6, limit: 2, expectErr: os.ErrNotExist},\n\n\t\t{from: 7, limit: -1, expectErr: nil, expectMigrations: newMigSeq(M(7, 5), M(5, 4), M(4, 3), M(3, 1), M(1, -1))},\n\t\t{from: 7, limit: 0, expectErr: ErrNoChange},\n\t\t{from: 7, limit: 1, expectErr: nil, expectMigrations: newMigSeq(M(7, 5))},\n\t\t{from: 7, limit: 2, expectErr: nil, expectMigrations: newMigSeq(M(7, 5), M(5, 4))},\n\n\t\t{from: 8, limit: -1, expectErr: os.ErrNotExist},\n\t\t{from: 8, limit: 0, expectErr: os.ErrNotExist},\n\t\t{from: 8, limit: 1, expectErr: os.ErrNotExist},\n\t\t{from: 8, limit: 2, expectErr: os.ErrNotExist},\n\t}\n\n\tfor i, v := range tt {\n\t\tret := make(chan interface{})\n\t\tgo m.readDown(v.from, v.limit, ret)\n\t\tmigrations, err := migrationsFromChannel(ret)\n\n\t\tif (v.expectErr == os.ErrNotExist && !os.IsNotExist(err)) ||\n\t\t\t(v.expectErr != os.ErrNotExist && v.expectErr != err) {\n\t\t\tt.Errorf(\"expected %v, got %v, in %v\", v.expectErr, err, i)\n\t\t\tt.Logf(\"%v, in %v\", migrations, i)\n\t\t}\n\t\tif len(v.expectMigrations) > 0 {\n\t\t\tequalMigSeq(t, i, v.expectMigrations, migrations)\n\t\t}\n\t}\n}\n\nfunc TestLock(t *testing.T) {\n\tm, _ := New(\"stub://\", \"stub://\")\n\tif err := m.lock(); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif err := m.lock(); err == nil {\n\t\tt.Fatal(\"should be locked already\")\n\t}\n}\n\nfunc migrationsFromChannel(ret chan interface{}) ([]*Migration, error) {\n\tslice := make([]*Migration, 0)\n\tfor r := range ret {\n\t\tswitch r.(type) {\n\t\tcase error:\n\t\t\treturn slice, r.(error)\n\n\t\tcase *Migration:\n\t\t\tslice = append(slice, r.(*Migration))\n\t\t}\n\t}\n\treturn slice, nil\n}\n\ntype migrationSequence []*Migration\n\nfunc newMigSeq(migr ...*Migration) migrationSequence {\n\treturn migr\n}\n\nfunc (m *migrationSequence) add(migr ...*Migration) migrationSequence {\n\t*m = append(*m, migr...)\n\treturn *m\n}\n\nfunc (m *migrationSequence) bodySequence() []string {\n\tr := make([]string, 0)\n\tfor _, v := range *m {\n\t\tif v.Body != nil {\n\t\t\tbody, err := ioutil.ReadAll(v.Body)\n\t\t\tif err != nil {\n\t\t\t\tpanic(err) // that should never happen\n\t\t\t}\n\n\t\t\t// reset body reader\n\t\t\t// TODO: is there a better/nicer way?\n\t\t\tv.Body = ioutil.NopCloser(bytes.NewReader(body))\n\n\t\t\tr = append(r, string(body[:]))\n\t\t}\n\t}\n\treturn r\n}\n\n// M is a convenience func to create a new *Migration\nfunc M(version uint, targetVersion ...int) *Migration {\n\tif len(targetVersion) > 1 {\n\t\tpanic(\"only one targetVersion allowed\")\n\t}\n\tts := int(version)\n\tif len(targetVersion) == 1 {\n\t\tts = targetVersion[0]\n\t}\n\n\tm, _ := New(\"stub://\", \"stub://\")\n\tm.sourceDrv.(*sStub.Stub).Migrations = sourceStubMigrations\n\tmigr, err := m.newMigration(version, ts)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn migr\n}\n\nfunc equalMigSeq(t *testing.T, i int, expected, got migrationSequence) {\n\tif len(expected) != len(got) {\n\t\tt.Errorf(\"expected migrations %v, got %v, in %v\", expected, got, i)\n\n\t} else {\n\t\tfor ii := 0; ii < len(expected); ii++ {\n\t\t\tif expected[ii].Version != got[ii].Version {\n\t\t\t\tt.Errorf(\"expected version %v, got %v, in %v\", expected[ii].Version, got[ii].Version, i)\n\t\t\t}\n\n\t\t\tif expected[ii].TargetVersion != got[ii].TargetVersion {\n\t\t\t\tt.Errorf(\"expected targetVersion %v, got %v, in %v\", expected[ii].TargetVersion, got[ii].TargetVersion, i)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc equalDbSeq(t *testing.T, i int, expected migrationSequence, got *dStub.Stub) {\n\tbs := expected.bodySequence()\n\tif !got.EqualSequence(bs) {\n\t\tt.Fatalf(\"\\nexpected sequence %v,\\ngot               %v, in %v\", bs, got.MigrationSequence, i)\n\t}\n}\n"
        },
        {
          "name": "migration.go",
          "type": "blob",
          "size": 4.4130859375,
          "content": "package migrate\n\nimport (\n\t\"bufio\"\n\t\"fmt\"\n\t\"io\"\n\t\"time\"\n)\n\n// DefaultBufferSize sets the in memory buffer size (in Bytes) for every\n// pre-read migration (see DefaultPrefetchMigrations).\nvar DefaultBufferSize = uint(100000)\n\n// Migration holds information about a migration.\n// It is initially created from data coming from the source and then\n// used when run against the database.\ntype Migration struct {\n\t// Identifier can be any string to help identifying\n\t// the migration in the source.\n\tIdentifier string\n\n\t// Version is the version of this migration.\n\tVersion uint\n\n\t// TargetVersion is the migration version after this migration\n\t// has been applied to the database.\n\t// Can be -1, implying that this is a NilVersion.\n\tTargetVersion int\n\n\t// Body holds an io.ReadCloser to the source.\n\tBody io.ReadCloser\n\n\t// BufferedBody holds an buffered io.Reader to the underlying Body.\n\tBufferedBody io.Reader\n\n\t// BufferSize defaults to DefaultBufferSize\n\tBufferSize uint\n\n\t// bufferWriter holds an io.WriteCloser and pipes to BufferBody.\n\t// It's an *Closer for flow control.\n\tbufferWriter io.WriteCloser\n\n\t// Scheduled is the time when the migration was scheduled/ queued.\n\tScheduled time.Time\n\n\t// StartedBuffering is the time when buffering of the migration source started.\n\tStartedBuffering time.Time\n\n\t// FinishedBuffering is the time when buffering of the migration source finished.\n\tFinishedBuffering time.Time\n\n\t// FinishedReading is the time when the migration source is fully read.\n\tFinishedReading time.Time\n\n\t// BytesRead holds the number of Bytes read from the migration source.\n\tBytesRead int64\n}\n\n// NewMigration returns a new Migration and sets the body, identifier,\n// version and targetVersion. Body can be nil, which turns this migration\n// into a \"NilMigration\". If no identifier is provided, it will default to \"<empty>\".\n// targetVersion can be -1, implying it is a NilVersion.\n//\n// What is a NilMigration?\n// Usually each migration version coming from source is expected to have an\n// Up and Down migration. This is not a hard requirement though, leading to\n// a situation where only the Up or Down migration is present. So let's say\n// the user wants to migrate up to a version that doesn't have the actual Up\n// migration, in that case we still want to apply the version, but with an empty\n// body. We are calling that a NilMigration, a migration with an empty body.\n//\n// What is a NilVersion?\n// NilVersion is a const(-1). When running down migrations and we are at the\n// last down migration, there is no next down migration, the targetVersion should\n// be nil. Nil in this case is represented by -1 (because type int).\nfunc NewMigration(body io.ReadCloser, identifier string,\n\tversion uint, targetVersion int) (*Migration, error) {\n\ttnow := time.Now()\n\tm := &Migration{\n\t\tIdentifier:    identifier,\n\t\tVersion:       version,\n\t\tTargetVersion: targetVersion,\n\t\tScheduled:     tnow,\n\t}\n\n\tif body == nil {\n\t\tif len(identifier) == 0 {\n\t\t\tm.Identifier = \"<empty>\"\n\t\t}\n\n\t\tm.StartedBuffering = tnow\n\t\tm.FinishedBuffering = tnow\n\t\tm.FinishedReading = tnow\n\t\treturn m, nil\n\t}\n\n\tbr, bw := io.Pipe()\n\tm.Body = body // want to simulate low latency? newSlowReader(body)\n\tm.BufferSize = DefaultBufferSize\n\tm.BufferedBody = br\n\tm.bufferWriter = bw\n\treturn m, nil\n}\n\n// String implements string.Stringer and is used in tests.\nfunc (m *Migration) String() string {\n\treturn fmt.Sprintf(\"%v [%v=>%v]\", m.Identifier, m.Version, m.TargetVersion)\n}\n\n// LogString returns a string describing this migration to humans.\nfunc (m *Migration) LogString() string {\n\tdirectionStr := \"u\"\n\tif m.TargetVersion < int(m.Version) {\n\t\tdirectionStr = \"d\"\n\t}\n\treturn fmt.Sprintf(\"%v/%v %v\", m.Version, directionStr, m.Identifier)\n}\n\n// Buffer buffers Body up to BufferSize.\n// Calling this function blocks. Call with goroutine.\nfunc (m *Migration) Buffer() error {\n\tif m.Body == nil {\n\t\treturn nil\n\t}\n\n\tm.StartedBuffering = time.Now()\n\n\tb := bufio.NewReaderSize(m.Body, int(m.BufferSize))\n\n\t// start reading from body, peek won't move the read pointer though\n\t// poor man's solution?\n\tb.Peek(int(m.BufferSize))\n\n\tm.FinishedBuffering = time.Now()\n\n\t// write to bufferWriter, this will block until\n\t// something starts reading from m.Buffer\n\tn, err := b.WriteTo(m.bufferWriter)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tm.FinishedReading = time.Now()\n\tm.BytesRead = n\n\n\t// close bufferWriter so Buffer knows that there is no\n\t// more data coming\n\tm.bufferWriter.Close()\n\n\t// it's safe to close the Body too\n\tm.Body.Close()\n\n\treturn nil\n}\n"
        },
        {
          "name": "migration_test.go",
          "type": "blob",
          "size": 1.5498046875,
          "content": "package migrate\n\nimport (\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"strings\"\n)\n\nfunc ExampleNewMigration() {\n\t// Create a dummy migration body, this is coming from the source usually.\n\tbody := ioutil.NopCloser(strings.NewReader(\"dumy migration that creates users table\"))\n\n\t// Create a new Migration that represents version 1486686016.\n\t// Once this migration has been applied to the database, the new\n\t// migration version will be 1486689359.\n\tmigr, err := NewMigration(body, \"create_users_table\", 1486686016, 1486689359)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tfmt.Print(migr.LogString())\n\t// Output:\n\t// 1486686016/u create_users_table\n}\n\nfunc ExampleNewMigration_nilMigration() {\n\t// Create a new Migration that represents a NilMigration.\n\t// Once this migration has been applied to the database, the new\n\t// migration version will be 1486689359.\n\tmigr, err := NewMigration(nil, \"\", 1486686016, 1486689359)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tfmt.Print(migr.LogString())\n\t// Output:\n\t// 1486686016/u <empty>\n}\n\nfunc ExampleNewMigration_nilVersion() {\n\t// Create a dummy migration body, this is coming from the source usually.\n\tbody := ioutil.NopCloser(strings.NewReader(\"dumy migration that deletes users table\"))\n\n\t// Create a new Migration that represents version 1486686016.\n\t// This is the last available down migration, so the migration version\n\t// will be -1, meaning NilVersion once this migration ran.\n\tmigr, err := NewMigration(body, \"drop_users_table\", 1486686016, -1)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tfmt.Print(migr.LogString())\n\t// Output:\n\t// 1486686016/d drop_users_table\n}\n"
        },
        {
          "name": "source",
          "type": "tree",
          "content": null
        },
        {
          "name": "testing",
          "type": "tree",
          "content": null
        },
        {
          "name": "util.go",
          "type": "blob",
          "size": 2.03515625,
          "content": "package migrate\n\nimport (\n\t\"bufio\"\n\t\"fmt\"\n\t\"io\"\n\tnurl \"net/url\"\n\t\"strings\"\n\t\"time\"\n)\n\n// MultiError holds multiple errors.\ntype MultiError struct {\n\tErrs []error\n}\n\n// NewMultiError returns an error type holding multiple errors.\nfunc NewMultiError(errs ...error) MultiError {\n\tcompactErrs := make([]error, 0)\n\tfor _, e := range errs {\n\t\tif e != nil {\n\t\t\tcompactErrs = append(compactErrs, e)\n\t\t}\n\t}\n\treturn MultiError{compactErrs}\n}\n\n// Error implements error. Mulitple errors are concatenated with 'and's.\nfunc (m MultiError) Error() string {\n\tvar strs = make([]string, 0)\n\tfor _, e := range m.Errs {\n\t\tif len(e.Error()) > 0 {\n\t\t\tstrs = append(strs, e.Error())\n\t\t}\n\t}\n\treturn strings.Join(strs, \" and \")\n}\n\n// suint safely converts int to uint\n// see https://goo.gl/wEcqof\n// see https://goo.gl/pai7Dr\nfunc suint(n int) uint {\n\tif n < 0 {\n\t\tpanic(fmt.Sprintf(\"suint(%v) expects input >= 0\", n))\n\t}\n\treturn uint(n)\n}\n\n// newSlowReader turns an io.ReadCloser into a slow io.ReadCloser.\n// Use this to simulate a slow internet connection.\nfunc newSlowReader(r io.ReadCloser) io.ReadCloser {\n\treturn &slowReader{\n\t\trx:     r,\n\t\treader: bufio.NewReader(r),\n\t}\n}\n\ntype slowReader struct {\n\trx     io.ReadCloser\n\treader *bufio.Reader\n}\n\nfunc (b *slowReader) Read(p []byte) (n int, err error) {\n\ttime.Sleep(10 * time.Millisecond)\n\tc, err := b.reader.ReadByte()\n\tif err != nil {\n\t\treturn 0, err\n\t} else {\n\t\tcopy(p, []byte{c})\n\t\treturn 1, nil\n\t}\n}\n\nfunc (b *slowReader) Close() error {\n\treturn b.rx.Close()\n}\n\nvar errNoScheme = fmt.Errorf(\"no scheme\")\n\n// schemeFromUrl returns the scheme from a URL string\nfunc schemeFromUrl(url string) (string, error) {\n\tu, err := nurl.Parse(url)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tif len(u.Scheme) == 0 {\n\t\treturn \"\", errNoScheme\n\t}\n\n\treturn u.Scheme, nil\n}\n\n// FilterCustomQuery filters all query values starting with `x-`\nfunc FilterCustomQuery(u *nurl.URL) *nurl.URL {\n\tux := *u\n\tvx := make(nurl.Values)\n\tfor k, v := range ux.Query() {\n\t\tif len(k) <= 1 || (len(k) > 1 && k[0:2] != \"x-\") {\n\t\t\tvx[k] = v\n\t\t}\n\t}\n\tux.RawQuery = vx.Encode()\n\treturn &ux\n}\n"
        },
        {
          "name": "util_test.go",
          "type": "blob",
          "size": 0.5576171875,
          "content": "package migrate\n\nimport (\n\tnurl \"net/url\"\n\t\"testing\"\n)\n\nfunc TestSuintPanicsWithNegativeInput(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r == nil {\n\t\t\tt.Fatal(\"expected suint to panic for -1\")\n\t\t}\n\t}()\n\tsuint(-1)\n}\n\nfunc TestSuint(t *testing.T) {\n\tif u := suint(0); u != 0 {\n\t\tt.Fatalf(\"expected 0, got %v\", u)\n\t}\n}\n\nfunc TestFilterCustomQuery(t *testing.T) {\n\tn, err := nurl.Parse(\"foo://host?a=b&x-custom=foo&c=d\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tnx := FilterCustomQuery(n).Query()\n\tif nx.Get(\"x-custom\") != \"\" {\n\t\tt.Fatalf(\"didn't expect x-custom\")\n\t}\n}\n"
        }
      ]
    }
  ]
}