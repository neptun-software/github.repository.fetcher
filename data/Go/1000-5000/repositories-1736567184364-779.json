{
  "metadata": {
    "timestamp": 1736567184364,
    "page": 779,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjc4MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "pressly/sup",
      "stars": 2487,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0107421875,
          "content": "bin/\n*.sw?\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.1318359375,
          "content": "sudo: false\nlanguage: go\nenv:\n  global: \n      - GO111MODULE=on\ngo:\n  - 1.13.x\n  - tip\n\ninstall:\n  - make build\n\nscript:\n  - make test\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0595703125,
          "content": "MIT License\n\nCopyright (c) 2015 Pressly Inc. www.pressly.com\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 1.05078125,
          "content": ".PHONY: all build dist test install clean tools deps update-deps\n\nall:\n\t@echo \"build         - Build sup\"\n\t@echo \"dist          - Build sup distribution binaries\"\n\t@echo \"test          - Run tests\"\n\t@echo \"install       - Install binary\"\n\t@echo \"clean         - Clean up\"\n\t@echo \"\"\n\t@echo \"tools         - Install tools\"\n\t@echo \"vendor-list   - List vendor package tree\"\n\t@echo \"vendor-update - Update vendored packages\"\n\nbuild:\n\t@mkdir -p ./bin\n\t@rm -f ./bin/*\n\tgo build -o ./bin/sup ./cmd/sup\n\ndist:\n\t@mkdir -p ./bin\n\t@rm -f ./bin/*\n\tGOOS=darwin GOARCH=amd64 go build -o ./bin/sup-darwin64 ./cmd/sup\n\tGOOS=linux GOARCH=amd64 go build -o ./bin/sup-linux64 ./cmd/sup\n\tGOOS=linux GOARCH=386 go build -o ./bin/sup-linux386 ./cmd/sup\n\tGOOS=windows GOARCH=amd64 go build -o ./bin/sup-windows64.exe ./cmd/sup\n\tGOOS=windows GOARCH=386 go build -o ./bin/sup-windows386.exe ./cmd/sup\n\ntest:\n\tgo test ./...\n\ninstall:\n\tgo install ./cmd/sup\n\nclean:\n\t@rm -rf ./bin\n\ntools:\n\tgo get -u github.com/kardianos/govendor\n\nvendor-list:\n\t@govendor list\n\nvendor-update:\n\t@govendor update +external\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.20703125,
          "content": "Stack Up\n========\n\nStack Up is a simple deployment tool that performs given set of commands on multiple hosts in parallel. It reads Supfile, a YAML configuration file, which defines networks (groups of hosts), commands and targets.\n\n# Demo\n\n[![Sup](https://github.com/pressly/sup/blob/gif/asciinema.gif?raw=true)](https://asciinema.org/a/19742?autoplay=1)\n\n*Note: Demo is based on [this example Supfile](./example/Supfile).*\n\n# Installation\n\n    $ go get -u github.com/pressly/sup/cmd/sup\n\n# Usage\n\n    $ sup [OPTIONS] NETWORK COMMAND [...]\n\n### Options\n\n| Option            | Description                      |\n|-------------------|----------------------------------|\n| `-f Supfile`      | Custom path to Supfile           |\n| `-e`, `--env=[]`  | Set environment variables        |\n| `--only REGEXP`   | Filter hosts matching regexp     |\n| `--except REGEXP` | Filter out hosts matching regexp |\n| `--debug`, `-D`   | Enable debug/verbose mode        |\n| `--disable-prefix`| Disable hostname prefix          |\n| `--help`, `-h`    | Show help/usage                  |\n| `--version`, `-v` | Print version                    |\n\n## Network\n\nA group of hosts.\n\n```yaml\n# Supfile\n\nnetworks:\n    production:\n        hosts:\n            - api1.example.com\n            - api2.example.com\n            - api3.example.com\n    staging:\n        # fetch dynamic list of hosts\n        inventory: curl http://example.com/latest/meta-data/hostname\n```\n\n`$ sup production COMMAND` will run COMMAND on `api1`, `api2` and `api3` hosts in parallel.\n\n## Command\n\nA shell command(s) to be run remotely.\n\n```yaml\n# Supfile\n\ncommands:\n    restart:\n        desc: Restart example Docker container\n        run: sudo docker restart example\n    tail-logs:\n        desc: Watch tail of Docker logs from all hosts\n        run: sudo docker logs --tail=20 -f example\n```\n\n`$ sup staging restart` will restart all staging Docker containers in parallel.\n\n`$ sup production tail-logs` will tail Docker logs from all production containers in parallel.\n\n### Serial command (a.k.a. Rolling Update)\n\n`serial: N` constraints a command to be run on `N` hosts at a time at maximum. Rolling Update for free!\n\n```yaml\n# Supfile\n\ncommands:\n    restart:\n        desc: Restart example Docker container\n        run: sudo docker restart example\n        serial: 2\n```\n\n`$ sup production restart` will restart all Docker containers, two at a time at maximum.\n\n### Once command (one host only)\n\n`once: true` constraints a command to be run only on one host. Useful for one-time tasks.\n\n```yaml\n# Supfile\n\ncommands:\n    build:\n        desc: Build Docker image and push to registry\n        run: sudo docker build -t image:latest . && sudo docker push image:latest\n        once: true # one host only\n    pull:\n        desc: Pull latest Docker image from registry\n        run: sudo docker pull image:latest\n```\n\n`$ sup production build pull` will build Docker image on one production host only and spread it to all hosts.\n\n### Local command\n\nRuns command always on localhost.\n\n```yaml\n# Supfile\n\ncommands:\n    prepare:\n        desc: Prepare to upload\n        local: npm run build\n```\n\n### Upload command\n\nUploads files/directories to all remote hosts. Uses `tar` under the hood.\n\n```yaml\n# Supfile\n\ncommands:\n    upload:\n        desc: Upload dist files to all hosts\n        upload:\n          - src: ./dist\n            dst: /tmp/\n```\n\n### Interactive Bash on all hosts\n\nDo you want to interact with multiple hosts at once? Sure!\n\n```yaml\n# Supfile\n\ncommands:\n    bash:\n        desc: Interactive Bash on all hosts\n        stdin: true\n        run: bash\n```\n\n```bash\n$ sup production bash\n#\n# type in commands and see output from all hosts!\n# ^C\n```\n\nPassing prepared commands to all hosts:\n```bash\n$ echo 'sudo apt-get update -y' | sup production bash\n\n# or:\n$ sup production bash <<< 'sudo apt-get update -y'\n\n# or:\n$ cat <<EOF | sup production bash\nsudo apt-get update -y\ndate\nuname -a\nEOF\n```\n\n### Interactive Docker Exec on all hosts\n\n```yaml\n# Supfile\n\ncommands:\n    exec:\n        desc: Exec into Docker container on all hosts\n        stdin: true\n        run: sudo docker exec -i $CONTAINER bash\n```\n\n```bash\n$ sup production exec\nps aux\nstrace -p 1 # trace system calls and signals on all your production hosts\n```\n\n## Target\n\nTarget is an alias for multiple commands. Each command will be run on all hosts in parallel,\n`sup` will check return status from all hosts, and run subsequent commands on success only\n(thus any error on any host will interrupt the process).\n\n```yaml\n# Supfile\n\ntargets:\n    deploy:\n        - build\n        - pull\n        - migrate-db-up\n        - stop-rm-run\n        - health\n        - slack-notify\n        - airbrake-notify\n```\n\n`$ sup production deploy`\n\nis equivalent to\n\n`$ sup production build pull migrate-db-up stop-rm-run health slack-notify airbrake-notify`\n\n# Supfile\n\nSee [example Supfile](./example/Supfile).\n\n### Basic structure\n\n```yaml\n# Supfile\n---\nversion: 0.4\n\n# Global environment variables\nenv:\n  NAME: api\n  IMAGE: example/api\n\nnetworks:\n  local:\n    hosts:\n      - localhost\n  staging:\n    hosts:\n      - stg1.example.com\n  production:\n    hosts:\n      - api1.example.com\n      - api2.example.com\n\ncommands:\n  echo:\n    desc: Print some env vars\n    run: echo $NAME $IMAGE $SUP_NETWORK\n  date:\n    desc: Print OS name and current date/time\n    run: uname -a; date\n\ntargets:\n  all:\n    - echo\n    - date\n```\n\n### Default environment variables available in Supfile\n\n- `$SUP_HOST` - Current host.\n- `$SUP_NETWORK` - Current network.\n- `$SUP_USER` - User who invoked sup command.\n- `$SUP_TIME` - Date/time of sup command invocation.\n- `$SUP_ENV` - Environment variables provided on sup command invocation. You can pass `$SUP_ENV` to another `sup` or `docker` commands in your Supfile.\n\n# Running sup from Supfile\n\nSupfile doesn't let you import another Supfile. Instead, it lets you run `sup` sub-process from inside your Supfile. This is how you can structure larger projects:\n\n```\n./Supfile\n./database/Supfile\n./services/scheduler/Supfile\n```\n\nTop-level Supfile calls `sup` with Supfiles from sub-projects:\n```yaml\n restart-scheduler:\n    desc: Restart scheduler\n    local: >\n      sup -f ./services/scheduler/Supfile $SUP_ENV $SUP_NETWORK restart\n db-up:\n    desc: Migrate database\n    local: >\n      sup -f ./database/Supfile $SUP_ENV $SUP_NETWORK up\n```\n\n# Common SSH Problem\n\nif for some reason sup doesn't connect and you get the following error,\n\n```bash\nconnecting to clients failed: connecting to remote host failed: Connect(\"myserver@xxx.xxx.xxx.xxx\"): ssh: handshake failed: ssh: unable to authenticate, attempted methods [none publickey], no supported methods remain\n```\n\nit means that your `ssh-agent` dosen't have access to your public and private keys. in order to fix this issue, follow the below instructions:\n\n- run the following command and make sure you have a key register with `ssh-agent`\n\n```bash\nssh-add -l\n```\n\nif you see something like `The agent has no identities.` it means that you need to manually add your key to `ssh-agent`.\nin order to do that, run the following command\n\n```bash\nssh-add ~/.ssh/id_rsa\n```\n\nyou should now be able to use sup with your ssh key.\n\n\n# Development\n\n    fork it, hack it..\n\n    $ make build\n\n    create new Pull Request\n\nWe'll be happy to review & accept new Pull Requests!\n\n# License\n\nLicensed under the [MIT License](./LICENSE).\n"
        },
        {
          "name": "client.go",
          "type": "blob",
          "size": 0.3046875,
          "content": "package sup\n\nimport (\n\t\"io\"\n\t\"os\"\n)\n\ntype Client interface {\n\tConnect(host string) error\n\tRun(task *Task) error\n\tWait() error\n\tClose() error\n\tPrefix() (string, int)\n\tWrite(p []byte) (n int, err error)\n\tWriteClose() error\n\tStdin() io.WriteCloser\n\tStderr() io.Reader\n\tStdout() io.Reader\n\tSignal(os.Signal) error\n}\n"
        },
        {
          "name": "cmd",
          "type": "tree",
          "content": null
        },
        {
          "name": "colors.go",
          "type": "blob",
          "size": 0.2001953125,
          "content": "package sup\n\nvar (\n\tColors = []string{\n\t\t\"\\033[32m\", // green\n\t\t\"\\033[33m\", // yellow\n\t\t\"\\033[36m\", // cyan\n\t\t\"\\033[35m\", // magenta\n\t\t\"\\033[31m\", // red\n\t\t\"\\033[34m\", // blue\n\t}\n\tResetColor = \"\\033[0m\"\n)\n"
        },
        {
          "name": "dist",
          "type": "tree",
          "content": null
        },
        {
          "name": "example",
          "type": "tree",
          "content": null
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.4560546875,
          "content": "module github.com/pressly/sup\n\ngo 1.13\n\nrequire (\n\tgithub.com/goware/prefixer v0.0.0-20160118172347-395022866408\n\tgithub.com/kr/pretty v0.2.0 // indirect\n\tgithub.com/mikkeloscar/sshconfig v0.0.0-20190102082740-ec0822bcc4f4\n\tgithub.com/pkg/errors v0.9.1\n\tgolang.org/x/crypto v0.0.0-20200208060501-ecb85df21340\n\tgolang.org/x/sys v0.0.0-20200202164722-d101bd2416d5 // indirect\n\tgopkg.in/check.v1 v1.0.0-20190902080502-41f04d3bba15 // indirect\n\tgopkg.in/yaml.v2 v2.2.8\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 3.3203125,
          "content": "github.com/goware/prefixer v0.0.0-20160118172347-395022866408 h1:Y9iQJfEqnN3/Nce9cOegemcy/9Ai5k3huT6E80F3zaw=\ngithub.com/goware/prefixer v0.0.0-20160118172347-395022866408/go.mod h1:PE1ycukgRPJ7bJ9a1fdfQ9j8i/cEcRAoLZzbxYpNB/s=\ngithub.com/kr/pretty v0.2.0 h1:s5hAObm+yFO5uHYt5dYjxi2rXrsnmRpJx4OYvIWUaQs=\ngithub.com/kr/pretty v0.2.0/go.mod h1:ipq/a2n7PKx3OHsz4KJII5eveXtPO4qwEXGdVfWzfnI=\ngithub.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=\ngithub.com/kr/text v0.1.0 h1:45sCR5RtlFHMR4UwH9sdQ5TC8v0qDQCHnXt+kaKSTVE=\ngithub.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=\ngithub.com/mikkeloscar/sshconfig v0.0.0-20161223095632-fc5e37b16b68 h1:Z1BVWGqEm0aveMz9ffiFnJthFjM5+YFdFqFklQ/hPBI=\ngithub.com/mikkeloscar/sshconfig v0.0.0-20161223095632-fc5e37b16b68/go.mod h1:GvQCIGDpivPr+e8cuBt3c4+NTOJm66zpBrMjkit8jmw=\ngithub.com/mikkeloscar/sshconfig v0.0.0-20190102082740-ec0822bcc4f4 h1:6mjPKnEtYKqYTqIXAraugfl5bkaW+A6wJAupYKAWMXM=\ngithub.com/mikkeloscar/sshconfig v0.0.0-20190102082740-ec0822bcc4f4/go.mod h1:GvQCIGDpivPr+e8cuBt3c4+NTOJm66zpBrMjkit8jmw=\ngithub.com/pkg/errors v0.7.1-0.20160627222352-a2d6902c6d2a h1:dKpZ0nc8i7prliB4AIfJulQxsX7whlVwi6j5HqaYUl4=\ngithub.com/pkg/errors v0.7.1-0.20160627222352-a2d6902c6d2a/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pkg/errors v0.9.1 h1:FEBLx1zS214owpjy7qsBeixbURkuhQAwrK5UwLGTwt4=\ngithub.com/pkg/errors v0.9.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngolang.org/x/crypto v0.0.0-20160804082612-7a1054f3ac58 h1:ytej7jB0ejb21kF+TjEWykw7n4sG85mxyjgYHgF/7ZQ=\ngolang.org/x/crypto v0.0.0-20160804082612-7a1054f3ac58/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20200208060501-ecb85df21340 h1:KOcEaR10tFr7gdJV2GCKw8Os5yED1u1aOqHjOAb6d2Y=\ngolang.org/x/crypto v0.0.0-20200208060501-ecb85df21340/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d h1:+R4KGOnez64A81RvjARKc4UT5/tI9ujCIVX+P5KiHuI=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200202164722-d101bd2416d5 h1:LfCXLvNmTYH9kEmVgqbnsWfruoXZIrh4YBgqVHtDvw0=\ngolang.org/x/sys v0.0.0-20200202164722-d101bd2416d5/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20190902080502-41f04d3bba15 h1:YR8cESwS4TdDjEe65xsg0ogRM/Nc3DYOhEAlW+xobZo=\ngopkg.in/check.v1 v1.0.0-20190902080502-41f04d3bba15/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/yaml.v2 v2.0.0-20160301204022-a83829b6f129 h1:RBgb9aPUbZ9nu66ecQNIBNsA7j3mB5h8PNDIfhPjaJg=\ngopkg.in/yaml.v2 v2.0.0-20160301204022-a83829b6f129/go.mod h1:JAlM8MvJe8wmxCU4Bli9HhUf9+ttbYbLASfIpnQbh74=\ngopkg.in/yaml.v2 v2.2.8 h1:obN1ZagJSUGI0Ek/LBmuj4SNLPfIny3KsKFopxRdj10=\ngopkg.in/yaml.v2 v2.2.8/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\n"
        },
        {
          "name": "localhost.go",
          "type": "blob",
          "size": 2.1298828125,
          "content": "package sup\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"os/exec\"\n\t\"os/user\"\n\n\t\"github.com/pkg/errors\"\n)\n\n// Client is a wrapper over the SSH connection/sessions.\ntype LocalhostClient struct {\n\tcmd     *exec.Cmd\n\tuser    string\n\tstdin   io.WriteCloser\n\tstdout  io.Reader\n\tstderr  io.Reader\n\trunning bool\n\tenv     string //export FOO=\"bar\"; export BAR=\"baz\";\n}\n\nfunc (c *LocalhostClient) Connect(_ string) error {\n\tu, err := user.Current()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tc.user = u.Username\n\treturn nil\n}\n\nfunc (c *LocalhostClient) Run(task *Task) error {\n\tvar err error\n\n\tif c.running {\n\t\treturn fmt.Errorf(\"Command already running\")\n\t}\n\n\tcmd := exec.Command(\"bash\", \"-c\", c.env+task.Run)\n\tc.cmd = cmd\n\n\tc.stdout, err = cmd.StdoutPipe()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tc.stderr, err = cmd.StderrPipe()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tc.stdin, err = cmd.StdinPipe()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := c.cmd.Start(); err != nil {\n\t\treturn ErrTask{task, err.Error()}\n\t}\n\n\tc.running = true\n\treturn nil\n}\n\nfunc (c *LocalhostClient) Wait() error {\n\tif !c.running {\n\t\treturn fmt.Errorf(\"Trying to wait on stopped command\")\n\t}\n\terr := c.cmd.Wait()\n\tc.running = false\n\treturn err\n}\n\nfunc (c *LocalhostClient) Close() error {\n\treturn nil\n}\n\nfunc (c *LocalhostClient) Stdin() io.WriteCloser {\n\treturn c.stdin\n}\n\nfunc (c *LocalhostClient) Stderr() io.Reader {\n\treturn c.stderr\n}\n\nfunc (c *LocalhostClient) Stdout() io.Reader {\n\treturn c.stdout\n}\n\nfunc (c *LocalhostClient) Prefix() (string, int) {\n\thost := c.user + \"@localhost\" + \" | \"\n\treturn ResetColor + host, len(host)\n}\n\nfunc (c *LocalhostClient) Write(p []byte) (n int, err error) {\n\treturn c.stdin.Write(p)\n}\n\nfunc (c *LocalhostClient) WriteClose() error {\n\treturn c.stdin.Close()\n}\n\nfunc (c *LocalhostClient) Signal(sig os.Signal) error {\n\treturn c.cmd.Process.Signal(sig)\n}\n\nfunc ResolveLocalPath(cwd, path, env string) (string, error) {\n\t// Check if file exists first. Use bash to resolve $ENV_VARs.\n\tcmd := exec.Command(\"bash\", \"-c\", env+\"echo -n \"+path)\n\tcmd.Dir = cwd\n\tresolvedFilename, err := cmd.Output()\n\tif err != nil {\n\t\treturn \"\", errors.Wrap(err, \"resolving path failed\")\n\t}\n\n\treturn string(resolvedFilename), nil\n}\n"
        },
        {
          "name": "ssh.go",
          "type": "blob",
          "size": 6.5615234375,
          "content": "package sup\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"net\"\n\t\"os\"\n\t\"os/user\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"sync\"\n\n\t\"golang.org/x/crypto/ssh\"\n\t\"golang.org/x/crypto/ssh/agent\"\n)\n\n// Client is a wrapper over the SSH connection/sessions.\ntype SSHClient struct {\n\tconn         *ssh.Client\n\tsess         *ssh.Session\n\tuser         string\n\thost         string\n\tremoteStdin  io.WriteCloser\n\tremoteStdout io.Reader\n\tremoteStderr io.Reader\n\tconnOpened   bool\n\tsessOpened   bool\n\trunning      bool\n\tenv          string //export FOO=\"bar\"; export BAR=\"baz\";\n\tcolor        string\n}\n\ntype ErrConnect struct {\n\tUser   string\n\tHost   string\n\tReason string\n}\n\nfunc (e ErrConnect) Error() string {\n\treturn fmt.Sprintf(`Connect(\"%v@%v\"): %v`, e.User, e.Host, e.Reason)\n}\n\n// parseHost parses and normalizes <user>@<host:port> from a given string.\nfunc (c *SSHClient) parseHost(host string) error {\n\tc.host = host\n\n\t// Remove extra \"ssh://\" schema\n\tif len(c.host) > 6 && c.host[:6] == \"ssh://\" {\n\t\tc.host = c.host[6:]\n\t}\n\n\t// Split by the last \"@\", since there may be an \"@\" in the username.\n\tif at := strings.LastIndex(c.host, \"@\"); at != -1 {\n\t\tc.user = c.host[:at]\n\t\tc.host = c.host[at+1:]\n\t}\n\n\t// Add default user, if not set\n\tif c.user == \"\" {\n\t\tu, err := user.Current()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tc.user = u.Username\n\t}\n\n\tif strings.Index(c.host, \"/\") != -1 {\n\t\treturn ErrConnect{c.user, c.host, \"unexpected slash in the host URL\"}\n\t}\n\n\t// Add default port, if not set\n\tif strings.Index(c.host, \":\") == -1 {\n\t\tc.host += \":22\"\n\t}\n\n\treturn nil\n}\n\nvar initAuthMethodOnce sync.Once\nvar authMethod ssh.AuthMethod\n\n// initAuthMethod initiates SSH authentication method.\nfunc initAuthMethod() {\n\tvar signers []ssh.Signer\n\n\t// If there's a running SSH Agent, try to use its Private keys.\n\tsock, err := net.Dial(\"unix\", os.Getenv(\"SSH_AUTH_SOCK\"))\n\tif err == nil {\n\t\tagent := agent.NewClient(sock)\n\t\tsigners, _ = agent.Signers()\n\t}\n\n\t// Try to read user's SSH private keys form the standard paths.\n\tfiles, _ := filepath.Glob(os.Getenv(\"HOME\") + \"/.ssh/id_*\")\n\tfor _, file := range files {\n\t\tif strings.HasSuffix(file, \".pub\") {\n\t\t\tcontinue // Skip public keys.\n\t\t}\n\t\tdata, err := ioutil.ReadFile(file)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\t\tsigner, err := ssh.ParsePrivateKey(data)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\t\tsigners = append(signers, signer)\n\n\t}\n\tauthMethod = ssh.PublicKeys(signers...)\n}\n\n// SSHDialFunc can dial an ssh server and return a client\ntype SSHDialFunc func(net, addr string, config *ssh.ClientConfig) (*ssh.Client, error)\n\n// Connect creates SSH connection to a specified host.\n// It expects the host of the form \"[ssh://]host[:port]\".\nfunc (c *SSHClient) Connect(host string) error {\n\treturn c.ConnectWith(host, ssh.Dial)\n}\n\n// ConnectWith creates a SSH connection to a specified host. It will use dialer to establish the\n// connection.\n// TODO: Split Signers to its own method.\nfunc (c *SSHClient) ConnectWith(host string, dialer SSHDialFunc) error {\n\tif c.connOpened {\n\t\treturn fmt.Errorf(\"Already connected\")\n\t}\n\n\tinitAuthMethodOnce.Do(initAuthMethod)\n\n\terr := c.parseHost(host)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tconfig := &ssh.ClientConfig{\n\t\tUser: c.user,\n\t\tAuth: []ssh.AuthMethod{\n\t\t\tauthMethod,\n\t\t},\n\t\tHostKeyCallback: ssh.InsecureIgnoreHostKey(),\n\t}\n\n\tc.conn, err = dialer(\"tcp\", c.host, config)\n\tif err != nil {\n\t\treturn ErrConnect{c.user, c.host, err.Error()}\n\t}\n\tc.connOpened = true\n\n\treturn nil\n}\n\n// Run runs the task.Run command remotely on c.host.\nfunc (c *SSHClient) Run(task *Task) error {\n\tif c.running {\n\t\treturn fmt.Errorf(\"Session already running\")\n\t}\n\tif c.sessOpened {\n\t\treturn fmt.Errorf(\"Session already connected\")\n\t}\n\n\tsess, err := c.conn.NewSession()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tc.remoteStdin, err = sess.StdinPipe()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tc.remoteStdout, err = sess.StdoutPipe()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tc.remoteStderr, err = sess.StderrPipe()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif task.TTY {\n\t\t// Set up terminal modes\n\t\tmodes := ssh.TerminalModes{\n\t\t\tssh.ECHO:          0,     // disable echoing\n\t\t\tssh.TTY_OP_ISPEED: 14400, // input speed = 14.4kbaud\n\t\t\tssh.TTY_OP_OSPEED: 14400, // output speed = 14.4kbaud\n\t\t}\n\t\t// Request pseudo terminal\n\t\tif err := sess.RequestPty(\"xterm\", 80, 40, modes); err != nil {\n\t\t\treturn ErrTask{task, fmt.Sprintf(\"request for pseudo terminal failed: %s\", err)}\n\t\t}\n\t}\n\n\t// Start the remote command.\n\tif err := sess.Start(c.env + task.Run); err != nil {\n\t\treturn ErrTask{task, err.Error()}\n\t}\n\n\tc.sess = sess\n\tc.sessOpened = true\n\tc.running = true\n\treturn nil\n}\n\n// Wait waits until the remote command finishes and exits.\n// It closes the SSH session.\nfunc (c *SSHClient) Wait() error {\n\tif !c.running {\n\t\treturn fmt.Errorf(\"Trying to wait on stopped session\")\n\t}\n\n\terr := c.sess.Wait()\n\tc.sess.Close()\n\tc.running = false\n\tc.sessOpened = false\n\n\treturn err\n}\n\n// DialThrough will create a new connection from the ssh server sc is connected to. DialThrough is an SSHDialer.\nfunc (sc *SSHClient) DialThrough(net, addr string, config *ssh.ClientConfig) (*ssh.Client, error) {\n\tconn, err := sc.conn.Dial(net, addr)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tc, chans, reqs, err := ssh.NewClientConn(conn, addr, config)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn ssh.NewClient(c, chans, reqs), nil\n\n}\n\n// Close closes the underlying SSH connection and session.\nfunc (c *SSHClient) Close() error {\n\tif c.sessOpened {\n\t\tc.sess.Close()\n\t\tc.sessOpened = false\n\t}\n\tif !c.connOpened {\n\t\treturn fmt.Errorf(\"Trying to close the already closed connection\")\n\t}\n\n\terr := c.conn.Close()\n\tc.connOpened = false\n\tc.running = false\n\n\treturn err\n}\n\nfunc (c *SSHClient) Stdin() io.WriteCloser {\n\treturn c.remoteStdin\n}\n\nfunc (c *SSHClient) Stderr() io.Reader {\n\treturn c.remoteStderr\n}\n\nfunc (c *SSHClient) Stdout() io.Reader {\n\treturn c.remoteStdout\n}\n\nfunc (c *SSHClient) Prefix() (string, int) {\n\thost := c.user + \"@\" + c.host + \" | \"\n\treturn c.color + host + ResetColor, len(host)\n}\n\nfunc (c *SSHClient) Write(p []byte) (n int, err error) {\n\treturn c.remoteStdin.Write(p)\n}\n\nfunc (c *SSHClient) WriteClose() error {\n\treturn c.remoteStdin.Close()\n}\n\nfunc (c *SSHClient) Signal(sig os.Signal) error {\n\tif !c.sessOpened {\n\t\treturn fmt.Errorf(\"session is not open\")\n\t}\n\n\tswitch sig {\n\tcase os.Interrupt:\n\t\t// TODO: Turns out that .Signal(ssh.SIGHUP) doesn't work for me.\n\t\t// Instead, sending \\x03 to the remote session works for me,\n\t\t// which sounds like something that should be fixed/resolved\n\t\t// upstream in the golang.org/x/crypto/ssh pkg.\n\t\t// https://github.com/golang/go/issues/4115#issuecomment-66070418\n\t\tc.remoteStdin.Write([]byte(\"\\x03\"))\n\t\treturn c.sess.Signal(ssh.SIGINT)\n\tdefault:\n\t\treturn fmt.Errorf(\"%v not supported\", sig)\n\t}\n}\n"
        },
        {
          "name": "sup.go",
          "type": "blob",
          "size": 5.935546875,
          "content": "package sup\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"os/signal\"\n\t\"strings\"\n\t\"sync\"\n\n\t\"github.com/goware/prefixer\"\n\t\"github.com/pkg/errors\"\n\t\"golang.org/x/crypto/ssh\"\n)\n\nconst VERSION = \"0.5\"\n\ntype Stackup struct {\n\tconf   *Supfile\n\tdebug  bool\n\tprefix bool\n}\n\nfunc New(conf *Supfile) (*Stackup, error) {\n\treturn &Stackup{\n\t\tconf: conf,\n\t}, nil\n}\n\n// Run runs set of commands on multiple hosts defined by network sequentially.\n// TODO: This megamoth method needs a big refactor and should be split\n//       to multiple smaller methods.\nfunc (sup *Stackup) Run(network *Network, envVars EnvList, commands ...*Command) error {\n\tif len(commands) == 0 {\n\t\treturn errors.New(\"no commands to be run\")\n\t}\n\n\tenv := envVars.AsExport()\n\n\t// Create clients for every host (either SSH or Localhost).\n\tvar bastion *SSHClient\n\tif network.Bastion != \"\" {\n\t\tbastion = &SSHClient{}\n\t\tif err := bastion.Connect(network.Bastion); err != nil {\n\t\t\treturn errors.Wrap(err, \"connecting to bastion failed\")\n\t\t}\n\t}\n\n\tvar wg sync.WaitGroup\n\tclientCh := make(chan Client, len(network.Hosts))\n\terrCh := make(chan error, len(network.Hosts))\n\n\tfor i, host := range network.Hosts {\n\t\twg.Add(1)\n\t\tgo func(i int, host string) {\n\t\t\tdefer wg.Done()\n\n\t\t\t// Localhost client.\n\t\t\tif host == \"localhost\" {\n\t\t\t\tlocal := &LocalhostClient{\n\t\t\t\t\tenv: env + `export SUP_HOST=\"` + host + `\";`,\n\t\t\t\t}\n\t\t\t\tif err := local.Connect(host); err != nil {\n\t\t\t\t\terrCh <- errors.Wrap(err, \"connecting to localhost failed\")\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tclientCh <- local\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// SSH client.\n\t\t\tremote := &SSHClient{\n\t\t\t\tenv:   env + `export SUP_HOST=\"` + host + `\";`,\n\t\t\t\tuser:  network.User,\n\t\t\t\tcolor: Colors[i%len(Colors)],\n\t\t\t}\n\n\t\t\tif bastion != nil {\n\t\t\t\tif err := remote.ConnectWith(host, bastion.DialThrough); err != nil {\n\t\t\t\t\terrCh <- errors.Wrap(err, \"connecting to remote host through bastion failed\")\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif err := remote.Connect(host); err != nil {\n\t\t\t\t\terrCh <- errors.Wrap(err, \"connecting to remote host failed\")\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t\tclientCh <- remote\n\t\t}(i, host)\n\t}\n\twg.Wait()\n\tclose(clientCh)\n\tclose(errCh)\n\n\tmaxLen := 0\n\tvar clients []Client\n\tfor client := range clientCh {\n\t\tif remote, ok := client.(*SSHClient); ok {\n\t\t\tdefer remote.Close()\n\t\t}\n\t\t_, prefixLen := client.Prefix()\n\t\tif prefixLen > maxLen {\n\t\t\tmaxLen = prefixLen\n\t\t}\n\t\tclients = append(clients, client)\n\t}\n\tfor err := range errCh {\n\t\treturn errors.Wrap(err, \"connecting to clients failed\")\n\t}\n\n\t// Run command or run multiple commands defined by target sequentially.\n\tfor _, cmd := range commands {\n\t\t// Translate command into task(s).\n\t\ttasks, err := sup.createTasks(cmd, clients, env)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"creating task failed\")\n\t\t}\n\n\t\t// Run tasks sequentially.\n\t\tfor _, task := range tasks {\n\t\t\tvar writers []io.Writer\n\t\t\tvar wg sync.WaitGroup\n\n\t\t\t// Run tasks on the provided clients.\n\t\t\tfor _, c := range task.Clients {\n\t\t\t\tvar prefix string\n\t\t\t\tvar prefixLen int\n\t\t\t\tif sup.prefix {\n\t\t\t\t\tprefix, prefixLen = c.Prefix()\n\t\t\t\t\tif len(prefix) < maxLen { // Left padding.\n\t\t\t\t\t\tprefix = strings.Repeat(\" \", maxLen-prefixLen) + prefix\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\terr := c.Run(task)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn errors.Wrap(err, prefix+\"task failed\")\n\t\t\t\t}\n\n\t\t\t\t// Copy over tasks's STDOUT.\n\t\t\t\twg.Add(1)\n\t\t\t\tgo func(c Client) {\n\t\t\t\t\tdefer wg.Done()\n\t\t\t\t\t_, err := io.Copy(os.Stdout, prefixer.New(c.Stdout(), prefix))\n\t\t\t\t\tif err != nil && err != io.EOF {\n\t\t\t\t\t\t// TODO: io.Copy() should not return io.EOF at all.\n\t\t\t\t\t\t// Upstream bug? Or prefixer.WriteTo() bug?\n\t\t\t\t\t\tfmt.Fprintf(os.Stderr, \"%v\", errors.Wrap(err, prefix+\"reading STDOUT failed\"))\n\t\t\t\t\t}\n\t\t\t\t}(c)\n\n\t\t\t\t// Copy over tasks's STDERR.\n\t\t\t\twg.Add(1)\n\t\t\t\tgo func(c Client) {\n\t\t\t\t\tdefer wg.Done()\n\t\t\t\t\t_, err := io.Copy(os.Stderr, prefixer.New(c.Stderr(), prefix))\n\t\t\t\t\tif err != nil && err != io.EOF {\n\t\t\t\t\t\tfmt.Fprintf(os.Stderr, \"%v\", errors.Wrap(err, prefix+\"reading STDERR failed\"))\n\t\t\t\t\t}\n\t\t\t\t}(c)\n\n\t\t\t\twriters = append(writers, c.Stdin())\n\t\t\t}\n\n\t\t\t// Copy over task's STDIN.\n\t\t\tif task.Input != nil {\n\t\t\t\tgo func() {\n\t\t\t\t\twriter := io.MultiWriter(writers...)\n\t\t\t\t\t_, err := io.Copy(writer, task.Input)\n\t\t\t\t\tif err != nil && err != io.EOF {\n\t\t\t\t\t\tfmt.Fprintf(os.Stderr, \"%v\", errors.Wrap(err, \"copying STDIN failed\"))\n\t\t\t\t\t}\n\t\t\t\t\t// TODO: Use MultiWriteCloser (not in Stdlib), so we can writer.Close() instead?\n\t\t\t\t\tfor _, c := range clients {\n\t\t\t\t\t\tc.WriteClose()\n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t}\n\n\t\t\t// Catch OS signals and pass them to all active clients.\n\t\t\ttrap := make(chan os.Signal, 1)\n\t\t\tsignal.Notify(trap, os.Interrupt)\n\t\t\tgo func() {\n\t\t\t\tfor {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase sig, ok := <-trap:\n\t\t\t\t\t\tif !ok {\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfor _, c := range task.Clients {\n\t\t\t\t\t\t\terr := c.Signal(sig)\n\t\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t\tfmt.Fprintf(os.Stderr, \"%v\", errors.Wrap(err, \"sending signal failed\"))\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}()\n\n\t\t\t// Wait for all I/O operations first.\n\t\t\twg.Wait()\n\n\t\t\t// Make sure each client finishes the task, return on failure.\n\t\t\tfor _, c := range task.Clients {\n\t\t\t\twg.Add(1)\n\t\t\t\tgo func(c Client) {\n\t\t\t\t\tdefer wg.Done()\n\t\t\t\t\tif err := c.Wait(); err != nil {\n\t\t\t\t\t\tvar prefix string\n\t\t\t\t\t\tif sup.prefix {\n\t\t\t\t\t\t\tvar prefixLen int\n\t\t\t\t\t\t\tprefix, prefixLen = c.Prefix()\n\t\t\t\t\t\t\tif len(prefix) < maxLen { // Left padding.\n\t\t\t\t\t\t\t\tprefix = strings.Repeat(\" \", maxLen-prefixLen) + prefix\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif e, ok := err.(*ssh.ExitError); ok && e.ExitStatus() != 15 {\n\t\t\t\t\t\t\t// TODO: Store all the errors, and print them after Wait().\n\t\t\t\t\t\t\tfmt.Fprintf(os.Stderr, \"%s%v\\n\", prefix, e)\n\t\t\t\t\t\t\tos.Exit(e.ExitStatus())\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfmt.Fprintf(os.Stderr, \"%s%v\\n\", prefix, err)\n\n\t\t\t\t\t\t// TODO: Shouldn't os.Exit(1) here. Instead, collect the exit statuses for later.\n\t\t\t\t\t\tos.Exit(1)\n\t\t\t\t\t}\n\t\t\t\t}(c)\n\t\t\t}\n\n\t\t\t// Wait for all commands to finish.\n\t\t\twg.Wait()\n\n\t\t\t// Stop catching signals for the currently active clients.\n\t\t\tsignal.Stop(trap)\n\t\t\tclose(trap)\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (sup *Stackup) Debug(value bool) {\n\tsup.debug = value\n}\n\nfunc (sup *Stackup) Prefix(value bool) {\n\tsup.prefix = value\n}\n"
        },
        {
          "name": "supfile.go",
          "type": "blob",
          "size": 8.0908203125,
          "content": "package sup\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"os/exec\"\n\t\"strings\"\n\n\t\"github.com/pkg/errors\"\n\n\t\"gopkg.in/yaml.v2\"\n)\n\n// Supfile represents the Stack Up configuration YAML file.\ntype Supfile struct {\n\tNetworks Networks `yaml:\"networks\"`\n\tCommands Commands `yaml:\"commands\"`\n\tTargets  Targets  `yaml:\"targets\"`\n\tEnv      EnvList  `yaml:\"env\"`\n\tVersion  string   `yaml:\"version\"`\n}\n\n// Network is group of hosts with extra custom env vars.\ntype Network struct {\n\tEnv       EnvList  `yaml:\"env\"`\n\tInventory string   `yaml:\"inventory\"`\n\tHosts     []string `yaml:\"hosts\"`\n\tBastion   string   `yaml:\"bastion\"` // Jump host for the environment\n\n\t// Should these live on Hosts too? We'd have to change []string to struct, even in Supfile.\n\tUser         string // `yaml:\"user\"`\n\tIdentityFile string // `yaml:\"identity_file\"`\n}\n\n// Networks is a list of user-defined networks\ntype Networks struct {\n\tNames []string\n\tnets  map[string]Network\n}\n\nfunc (n *Networks) UnmarshalYAML(unmarshal func(interface{}) error) error {\n\terr := unmarshal(&n.nets)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvar items yaml.MapSlice\n\terr = unmarshal(&items)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tn.Names = make([]string, len(items))\n\tfor i, item := range items {\n\t\tn.Names[i] = item.Key.(string)\n\t}\n\n\treturn nil\n}\n\nfunc (n *Networks) Get(name string) (Network, bool) {\n\tnet, ok := n.nets[name]\n\treturn net, ok\n}\n\n// Command represents command(s) to be run remotely.\ntype Command struct {\n\tName   string   `yaml:\"-\"`      // Command name.\n\tDesc   string   `yaml:\"desc\"`   // Command description.\n\tLocal  string   `yaml:\"local\"`  // Command(s) to be run locally.\n\tRun    string   `yaml:\"run\"`    // Command(s) to be run remotelly.\n\tScript string   `yaml:\"script\"` // Load command(s) from script and run it remotelly.\n\tUpload []Upload `yaml:\"upload\"` // See Upload struct.\n\tStdin  bool     `yaml:\"stdin\"`  // Attach localhost STDOUT to remote commands' STDIN?\n\tOnce   bool     `yaml:\"once\"`   // The command should be run \"once\" (on one host only).\n\tSerial int      `yaml:\"serial\"` // Max number of clients processing a task in parallel.\n\n\t// API backward compatibility. Will be deprecated in v1.0.\n\tRunOnce bool `yaml:\"run_once\"` // The command should be run once only.\n}\n\n// Commands is a list of user-defined commands\ntype Commands struct {\n\tNames []string\n\tcmds  map[string]Command\n}\n\nfunc (c *Commands) UnmarshalYAML(unmarshal func(interface{}) error) error {\n\terr := unmarshal(&c.cmds)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvar items yaml.MapSlice\n\terr = unmarshal(&items)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tc.Names = make([]string, len(items))\n\tfor i, item := range items {\n\t\tc.Names[i] = item.Key.(string)\n\t}\n\n\treturn nil\n}\n\nfunc (c *Commands) Get(name string) (Command, bool) {\n\tcmd, ok := c.cmds[name]\n\treturn cmd, ok\n}\n\n// Targets is a list of user-defined targets\ntype Targets struct {\n\tNames   []string\n\ttargets map[string][]string\n}\n\nfunc (t *Targets) UnmarshalYAML(unmarshal func(interface{}) error) error {\n\terr := unmarshal(&t.targets)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvar items yaml.MapSlice\n\terr = unmarshal(&items)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tt.Names = make([]string, len(items))\n\tfor i, item := range items {\n\t\tt.Names[i] = item.Key.(string)\n\t}\n\n\treturn nil\n}\n\nfunc (t *Targets) Get(name string) ([]string, bool) {\n\tcmds, ok := t.targets[name]\n\treturn cmds, ok\n}\n\n// Upload represents file copy operation from localhost Src path to Dst\n// path of every host in a given Network.\ntype Upload struct {\n\tSrc string `yaml:\"src\"`\n\tDst string `yaml:\"dst\"`\n\tExc string `yaml:\"exclude\"`\n}\n\n// EnvVar represents an environment variable\ntype EnvVar struct {\n\tKey   string\n\tValue string\n}\n\nfunc (e EnvVar) String() string {\n\treturn e.Key + `=` + e.Value\n}\n\n// AsExport returns the environment variable as a bash export statement\nfunc (e EnvVar) AsExport() string {\n\treturn `export ` + e.Key + `=\"` + e.Value + `\";`\n}\n\n// EnvList is a list of environment variables that maps to a YAML map,\n// but maintains order, enabling late variables to reference early variables.\ntype EnvList []*EnvVar\n\nfunc (e EnvList) Slice() []string {\n\tenvs := make([]string, len(e))\n\tfor i, env := range e {\n\t\tenvs[i] = env.String()\n\t}\n\treturn envs\n}\n\nfunc (e *EnvList) UnmarshalYAML(unmarshal func(interface{}) error) error {\n\titems := []yaml.MapItem{}\n\n\terr := unmarshal(&items)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t*e = make(EnvList, 0, len(items))\n\n\tfor _, v := range items {\n\t\te.Set(fmt.Sprintf(\"%v\", v.Key), fmt.Sprintf(\"%v\", v.Value))\n\t}\n\n\treturn nil\n}\n\n// Set key to be equal value in this list.\nfunc (e *EnvList) Set(key, value string) {\n\tfor i, v := range *e {\n\t\tif v.Key == key {\n\t\t\t(*e)[i].Value = value\n\t\t\treturn\n\t\t}\n\t}\n\n\t*e = append(*e, &EnvVar{\n\t\tKey:   key,\n\t\tValue: value,\n\t})\n}\n\nfunc (e *EnvList) ResolveValues() error {\n\tif len(*e) == 0 {\n\t\treturn nil\n\t}\n\n\texports := \"\"\n\tfor i, v := range *e {\n\t\texports += v.AsExport()\n\n\t\tcmd := exec.Command(\"bash\", \"-c\", exports+\"echo -n \"+v.Value+\";\")\n\t\tcwd, err := os.Getwd()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcmd.Dir = cwd\n\t\tresolvedValue, err := cmd.Output()\n\t\tif err != nil {\n\t\t\treturn errors.Wrapf(err, \"resolving env var %v failed\", v.Key)\n\t\t}\n\n\t\t(*e)[i].Value = string(resolvedValue)\n\t}\n\n\treturn nil\n}\n\nfunc (e *EnvList) AsExport() string {\n\t// Process all ENVs into a string of form\n\t// `export FOO=\"bar\"; export BAR=\"baz\";`.\n\texports := ``\n\tfor _, v := range *e {\n\t\texports += v.AsExport() + \" \"\n\t}\n\treturn exports\n}\n\ntype ErrMustUpdate struct {\n\tMsg string\n}\n\ntype ErrUnsupportedSupfileVersion struct {\n\tMsg string\n}\n\nfunc (e ErrMustUpdate) Error() string {\n\treturn fmt.Sprintf(\"%v\\n\\nPlease update sup by `go get -u github.com/pressly/sup/cmd/sup`\", e.Msg)\n}\n\nfunc (e ErrUnsupportedSupfileVersion) Error() string {\n\treturn fmt.Sprintf(\"%v\\n\\nCheck your Supfile version (available latest version: v0.5)\", e.Msg)\n}\n\n// NewSupfile parses configuration file and returns Supfile or error.\nfunc NewSupfile(data []byte) (*Supfile, error) {\n\tvar conf Supfile\n\n\tif err := yaml.Unmarshal(data, &conf); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// API backward compatibility. Will be deprecated in v1.0.\n\tswitch conf.Version {\n\tcase \"\":\n\t\tconf.Version = \"0.1\"\n\t\tfallthrough\n\n\tcase \"0.1\":\n\t\tfor _, cmd := range conf.Commands.cmds {\n\t\t\tif cmd.RunOnce {\n\t\t\t\treturn nil, ErrMustUpdate{\"command.run_once is not supported in Supfile v\" + conf.Version}\n\t\t\t}\n\t\t}\n\t\tfallthrough\n\n\tcase \"0.2\":\n\t\tfor _, cmd := range conf.Commands.cmds {\n\t\t\tif cmd.Once {\n\t\t\t\treturn nil, ErrMustUpdate{\"command.once is not supported in Supfile v\" + conf.Version}\n\t\t\t}\n\t\t\tif cmd.Local != \"\" {\n\t\t\t\treturn nil, ErrMustUpdate{\"command.local is not supported in Supfile v\" + conf.Version}\n\t\t\t}\n\t\t\tif cmd.Serial != 0 {\n\t\t\t\treturn nil, ErrMustUpdate{\"command.serial is not supported in Supfile v\" + conf.Version}\n\t\t\t}\n\t\t}\n\t\tfor _, network := range conf.Networks.nets {\n\t\t\tif network.Inventory != \"\" {\n\t\t\t\treturn nil, ErrMustUpdate{\"network.inventory is not supported in Supfile v\" + conf.Version}\n\t\t\t}\n\t\t}\n\t\tfallthrough\n\n\tcase \"0.3\":\n\t\tvar warning string\n\t\tfor key, cmd := range conf.Commands.cmds {\n\t\t\tif cmd.RunOnce {\n\t\t\t\twarning = \"Warning: command.run_once was deprecated by command.once in Supfile v\" + conf.Version + \"\\n\"\n\t\t\t\tcmd.Once = true\n\t\t\t\tconf.Commands.cmds[key] = cmd\n\t\t\t}\n\t\t}\n\t\tif warning != \"\" {\n\t\t\tfmt.Fprintf(os.Stderr, warning)\n\t\t}\n\n\t\tfallthrough\n\n\tcase \"0.4\", \"0.5\":\n\n\tdefault:\n\t\treturn nil, ErrUnsupportedSupfileVersion{\"unsupported Supfile version \" + conf.Version}\n\t}\n\n\treturn &conf, nil\n}\n\n// ParseInventory runs the inventory command, if provided, and appends\n// the command's output lines to the manually defined list of hosts.\nfunc (n Network) ParseInventory() ([]string, error) {\n\tif n.Inventory == \"\" {\n\t\treturn nil, nil\n\t}\n\n\tcmd := exec.Command(\"/bin/sh\", \"-c\", n.Inventory)\n\tcmd.Env = os.Environ()\n\tcmd.Env = append(cmd.Env, n.Env.Slice()...)\n\tcmd.Stderr = os.Stderr\n\toutput, err := cmd.Output()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar hosts []string\n\tbuf := bytes.NewBuffer(output)\n\tfor {\n\t\thost, err := buf.ReadString('\\n')\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn nil, err\n\t\t}\n\n\t\thost = strings.TrimSpace(host)\n\t\t// skip empty lines and comments\n\t\tif host == \"\" || host[:1] == \"#\" {\n\t\t\tcontinue\n\t\t}\n\n\t\thosts = append(hosts, host)\n\t}\n\treturn hosts, nil\n}\n"
        },
        {
          "name": "tar.go",
          "type": "blob",
          "size": 1.2822265625,
          "content": "package sup\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"os/exec\"\n\t\"strings\"\n\n\t\"github.com/pkg/errors\"\n)\n\n// Copying dirs/files over SSH using TAR.\n// tar -C . -cvzf - $SRC | ssh $HOST \"tar -C $DST -xvzf -\"\n\n// RemoteTarCommand returns command to be run on remote SSH host\n// to properly receive the created TAR stream.\n// TODO: Check for relative directory.\nfunc RemoteTarCommand(dir string) string {\n\treturn fmt.Sprintf(\"tar -C \\\"%s\\\" -xzf -\", dir)\n}\n\nfunc LocalTarCmdArgs(path, exclude string) []string {\n\targs := []string{}\n\n\t// Added pattens to exclude from tar compress\n\texcludes := strings.Split(exclude, \",\")\n\tfor _, exclude := range excludes {\n\t\ttrimmed := strings.TrimSpace(exclude)\n\t\tif trimmed != \"\" {\n\t\t\targs = append(args, `--exclude=`+trimmed)\n\t\t}\n\t}\n\n\targs = append(args, \"-C\", \".\", \"-czf\", \"-\", path)\n\treturn args\n}\n\n// NewTarStreamReader creates a tar stream reader from a local path.\n// TODO: Refactor. Use \"archive/tar\" instead.\nfunc NewTarStreamReader(cwd, path, exclude string) (io.Reader, error) {\n\tcmd := exec.Command(\"tar\", LocalTarCmdArgs(path, exclude)...)\n\tcmd.Dir = cwd\n\tstdout, err := cmd.StdoutPipe()\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"tar: stdout pipe failed\")\n\t}\n\n\tif err := cmd.Start(); err != nil {\n\t\treturn nil, errors.Wrap(err, \"tar: starting cmd failed\")\n\t}\n\n\treturn stdout, nil\n}\n"
        },
        {
          "name": "task.go",
          "type": "blob",
          "size": 3.416015625,
          "content": "package sup\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"os\"\n\n\t\"github.com/pkg/errors\"\n)\n\n// Task represents a set of commands to be run.\ntype Task struct {\n\tRun     string\n\tInput   io.Reader\n\tClients []Client\n\tTTY     bool\n}\n\nfunc (sup *Stackup) createTasks(cmd *Command, clients []Client, env string) ([]*Task, error) {\n\tvar tasks []*Task\n\n\tcwd, err := os.Getwd()\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"resolving CWD failed\")\n\t}\n\n\t// Anything to upload?\n\tfor _, upload := range cmd.Upload {\n\t\tuploadFile, err := ResolveLocalPath(cwd, upload.Src, env)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"upload: \"+upload.Src)\n\t\t}\n\t\tuploadTarReader, err := NewTarStreamReader(cwd, uploadFile, upload.Exc)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"upload: \"+upload.Src)\n\t\t}\n\n\t\ttask := Task{\n\t\t\tRun:   RemoteTarCommand(upload.Dst),\n\t\t\tInput: uploadTarReader,\n\t\t\tTTY:   false,\n\t\t}\n\n\t\tif cmd.Once {\n\t\t\ttask.Clients = []Client{clients[0]}\n\t\t\ttasks = append(tasks, &task)\n\t\t} else if cmd.Serial > 0 {\n\t\t\t// Each \"serial\" task client group is executed sequentially.\n\t\t\tfor i := 0; i < len(clients); i += cmd.Serial {\n\t\t\t\tj := i + cmd.Serial\n\t\t\t\tif j > len(clients) {\n\t\t\t\t\tj = len(clients)\n\t\t\t\t}\n\t\t\t\tcopy := task\n\t\t\t\tcopy.Clients = clients[i:j]\n\t\t\t\ttasks = append(tasks, &copy)\n\t\t\t}\n\t\t} else {\n\t\t\ttask.Clients = clients\n\t\t\ttasks = append(tasks, &task)\n\t\t}\n\t}\n\n\t// Script. Read the file as a multiline input command.\n\tif cmd.Script != \"\" {\n\t\tf, err := os.Open(cmd.Script)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"can't open script\")\n\t\t}\n\t\tdata, err := ioutil.ReadAll(f)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"can't read script\")\n\t\t}\n\n\t\ttask := Task{\n\t\t\tRun: string(data),\n\t\t\tTTY: true,\n\t\t}\n\t\tif sup.debug {\n\t\t\ttask.Run = \"set -x;\" + task.Run\n\t\t}\n\t\tif cmd.Stdin {\n\t\t\ttask.Input = os.Stdin\n\t\t}\n\t\tif cmd.Once {\n\t\t\ttask.Clients = []Client{clients[0]}\n\t\t\ttasks = append(tasks, &task)\n\t\t} else if cmd.Serial > 0 {\n\t\t\t// Each \"serial\" task client group is executed sequentially.\n\t\t\tfor i := 0; i < len(clients); i += cmd.Serial {\n\t\t\t\tj := i + cmd.Serial\n\t\t\t\tif j > len(clients) {\n\t\t\t\t\tj = len(clients)\n\t\t\t\t}\n\t\t\t\tcopy := task\n\t\t\t\tcopy.Clients = clients[i:j]\n\t\t\t\ttasks = append(tasks, &copy)\n\t\t\t}\n\t\t} else {\n\t\t\ttask.Clients = clients\n\t\t\ttasks = append(tasks, &task)\n\t\t}\n\t}\n\n\t// Local command.\n\tif cmd.Local != \"\" {\n\t\tlocal := &LocalhostClient{\n\t\t\tenv: env + `export SUP_HOST=\"localhost\";`,\n\t\t}\n\t\tlocal.Connect(\"localhost\")\n\t\ttask := &Task{\n\t\t\tRun:     cmd.Local,\n\t\t\tClients: []Client{local},\n\t\t\tTTY:     true,\n\t\t}\n\t\tif sup.debug {\n\t\t\ttask.Run = \"set -x;\" + task.Run\n\t\t}\n\t\tif cmd.Stdin {\n\t\t\ttask.Input = os.Stdin\n\t\t}\n\t\ttasks = append(tasks, task)\n\t}\n\n\t// Remote command.\n\tif cmd.Run != \"\" {\n\t\ttask := Task{\n\t\t\tRun: cmd.Run,\n\t\t\tTTY: true,\n\t\t}\n\t\tif sup.debug {\n\t\t\ttask.Run = \"set -x;\" + task.Run\n\t\t}\n\t\tif cmd.Stdin {\n\t\t\ttask.Input = os.Stdin\n\t\t}\n\t\tif cmd.Once {\n\t\t\ttask.Clients = []Client{clients[0]}\n\t\t\ttasks = append(tasks, &task)\n\t\t} else if cmd.Serial > 0 {\n\t\t\t// Each \"serial\" task client group is executed sequentially.\n\t\t\tfor i := 0; i < len(clients); i += cmd.Serial {\n\t\t\t\tj := i + cmd.Serial\n\t\t\t\tif j > len(clients) {\n\t\t\t\t\tj = len(clients)\n\t\t\t\t}\n\t\t\t\tcopy := task\n\t\t\t\tcopy.Clients = clients[i:j]\n\t\t\t\ttasks = append(tasks, &copy)\n\t\t\t}\n\t\t} else {\n\t\t\ttask.Clients = clients\n\t\t\ttasks = append(tasks, &task)\n\t\t}\n\t}\n\n\treturn tasks, nil\n}\n\ntype ErrTask struct {\n\tTask   *Task\n\tReason string\n}\n\nfunc (e ErrTask) Error() string {\n\treturn fmt.Sprintf(`Run(\"%v\"): %v`, e.Task, e.Reason)\n}\n"
        }
      ]
    }
  ]
}