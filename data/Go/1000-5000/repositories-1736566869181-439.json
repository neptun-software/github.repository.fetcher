{
  "metadata": {
    "timestamp": 1736566869181,
    "page": 439,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQ0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "rubenv/sql-migrate",
      "stars": 3258,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.0556640625,
          "content": "*\n!go.mod\n!go.sum\n!*.go\n!sql-migrate/*.go\n!sqlparse/*.go\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.072265625,
          "content": ".*.swp\n*.test\n.idea\n/vendor/\n\n/sql-migrate/test.db\n/test.db\n.vscode/\nbin/\n"
        },
        {
          "name": ".golangci.yaml",
          "type": "blob",
          "size": 2.6611328125,
          "content": "linters-settings:\n  gocritic:\n    disabled-checks:\n      - ifElseChain\n  goimports:\n    local-prefixes: github.com/rubenv/sql-migrate\n  govet:\n    enable-all: true\n    disable:\n      - fieldalignment\n  depguard:\n    rules:\n      main:\n        allow:\n          - $gostd\n          - github.com/denisenkom/go-mssqldb\n          - github.com/go-sql-driver/mysql\n          - github.com/go-gorp/gorp/v3\n          - github.com/lib/pq\n          - github.com/mattn/go-sqlite3\n          - github.com/mitchellh/cli\n          - github.com/olekukonko/tablewriter\n          - github.com/rubenv/sql-migrate\n  exhaustive:\n    default-signifies-exhaustive: true\n  nolintlint:\n    allow-unused: false\n    allow-leading-space: false\n    allow-no-explanation:\n      - depguard\n    require-explanation: true\n    require-specific: true\n  revive:\n    enable-all-rules: false\n    rules:\n      - name: atomic\n      - name: blank-imports\n      - name: bool-literal-in-expr\n      - name: call-to-gc\n      - name: constant-logical-expr\n      - name: context-as-argument\n      - name: context-keys-type\n      - name: dot-imports\n      - name: duplicated-imports\n      - name: empty-block\n      - name: empty-lines\n      - name: error-naming\n      - name: error-return\n      - name: error-strings\n      - name: errorf\n      - name: exported\n      - name: identical-branches\n      - name: imports-blacklist\n      - name: increment-decrement\n      - name: indent-error-flow\n      - name: modifies-parameter\n      - name: modifies-value-receiver\n      - name: package-comments\n      - name: range\n      - name: range-val-address\n      - name: range-val-in-closure\n      - name: receiver-naming\n      - name: string-format\n      - name: string-of-int\n      - name: struct-tag\n      - name: time-naming\n      - name: unconditional-recursion\n      - name: unexported-naming\n      - name: unexported-return\n      - name: superfluous-else\n      - name: unreachable-code\n      - name: var-declaration\n      - name: waitgroup-by-value\n      - name: unused-receiver\n      - name: unnecessary-stmt\n      - name: unused-parameter\nrun:\n  tests: true\n  timeout: 1m\nlinters:\n  disable-all: true\n  enable:\n    - asciicheck\n    - depguard\n    - errcheck\n    - exhaustive\n    - gocritic\n    - gofmt\n    - gofumpt\n    - goimports\n    - govet\n    - ineffassign\n    - nolintlint\n    - revive\n    - staticcheck\n    - typecheck\n    - unused\n    - whitespace\n    - errorlint\n    - gosimple\n    - unparam\nissues:\n  exclude:\n    - 'declaration of \"err\" shadows declaration at' # Allow shadowing of `err` because it's so common\n    - 'error-strings: error strings should not be capitalized or end with punctuation or a newline'\n  max-same-issues: 10000\n  max-issues-per-linter: 10000\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.640625,
          "content": "ARG GO_VERSION=1.20.6\nARG ALPINE_VERSION=3.12\n\n### Vendor\nFROM golang:${GO_VERSION} as vendor\nCOPY . /project\nWORKDIR /project\nRUN go mod tidy && go mod vendor\n\n### Build binary\nFROM golang:${GO_VERSION} as build-binary\nCOPY . /project\nCOPY --from=vendor /project/vendor /project/vendor\nWORKDIR /project\nRUN GOOS=linux GOARCH=amd64 CGO_ENABLED=0 GO111MODULE=on go build \\\n    -v \\\n    -mod vendor \\\n    -o /project/bin/sql-migrate \\\n        /project/sql-migrate\n\n### Image\nFROM alpine:${ALPINE_VERSION} as image\nCOPY --from=build-binary /project/bin/sql-migrate /usr/local/bin/sql-migrate\nRUN chmod +x /usr/local/bin/sql-migrate\nENTRYPOINT [\"sql-migrate\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.076171875,
          "content": "MIT License\n\nCopyright (C) 2014-2021 by Ruben Vermeersch <ruben@rocketeer.be>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.1650390625,
          "content": ".PHONY: test lint build\n\ntest:\n\tgo test ./...\n\nlint:\n\tgolangci-lint run --fix --config .golangci.yaml\n\nbuild:\n\tmkdir -p bin\n\tgo build -o ./bin/sql-migrate ./sql-migrate\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 12.21875,
          "content": "# sql-migrate\n\n> SQL Schema migration tool for [Go](https://golang.org/). Based on [gorp](https://github.com/go-gorp/gorp) and [goose](https://bitbucket.org/liamstask/goose).\n\n[![Test](https://github.com/rubenv/sql-migrate/actions/workflows/test.yml/badge.svg)](https://github.com/rubenv/sql-migrate/actions/workflows/test.yml) [![Go Reference](https://pkg.go.dev/badge/github.com/rubenv/sql-migrate.svg)](https://pkg.go.dev/github.com/rubenv/sql-migrate)\n\n## Features\n\n- Usable as a CLI tool or as a library\n- Supports SQLite, PostgreSQL, MySQL, MSSQL and Oracle databases (through [gorp](https://github.com/go-gorp/gorp))\n- Can embed migrations into your application\n- Migrations are defined with SQL for full flexibility\n- Atomic migrations\n- Up/down migrations to allow rollback\n- Supports multiple database types in one project\n- Works great with other libraries such as [sqlx](https://jmoiron.github.io/sqlx/)\n- Supported on go1.13+\n\n## Installation\n\nTo install the library and command line program, use the following:\n\n```bash\ngo get -v github.com/rubenv/sql-migrate/...\n```\n\nFor Go version from 1.18, use:\n\n```bash\ngo install github.com/rubenv/sql-migrate/...@latest\n```\n\n## Usage\n\n### As a standalone tool\n\n```\n$ sql-migrate --help\nusage: sql-migrate [--version] [--help] <command> [<args>]\n\nAvailable commands are:\n    down      Undo a database migration\n    new       Create a new migration\n    redo      Reapply the last migration\n    status    Show migration status\n    up        Migrates the database to the most recent version available\n```\n\nEach command requires a configuration file (which defaults to `dbconfig.yml`, but can be specified with the `-config` flag). This config file should specify one or more environments:\n\n```yml\ndevelopment:\n  dialect: sqlite3\n  datasource: test.db\n  dir: migrations/sqlite3\n\nproduction:\n  dialect: postgres\n  datasource: dbname=myapp sslmode=disable\n  dir: migrations/postgres\n  table: migrations\n```\n\n(See more examples for different set ups [here](test-integration/dbconfig.yml))\n\nAlso one can obtain env variables in datasource field via `os.ExpandEnv` embedded call for the field.\nThis may be useful if one doesn't want to store credentials in file:\n\n```yml\nproduction:\n  dialect: postgres\n  datasource: host=prodhost dbname=proddb user=${DB_USER} password=${DB_PASSWORD} sslmode=require\n  dir: migrations\n  table: migrations\n```\n\nThe `table` setting is optional and will default to `gorp_migrations`.\n\nThe environment that will be used can be specified with the `-env` flag (defaults to `development`).\n\nUse the `--help` flag in combination with any of the commands to get an overview of its usage:\n\n```\n$ sql-migrate up --help\nUsage: sql-migrate up [options] ...\n\n  Migrates the database to the most recent version available.\n\nOptions:\n\n  -config=dbconfig.yml   Configuration file to use.\n  -env=\"development\"     Environment.\n  -limit=0               Limit the number of migrations (0 = unlimited).\n  -version               Run migrate up to a specific version, eg: the version number of migration 1_initial.sql is 1.\n  -dryrun                Don't apply migrations, just print them.\n```\n\nThe `new` command creates a new empty migration template using the following pattern `<current time>-<name>.sql`.\n\nThe `up` command applies all available migrations. By contrast, `down` will only apply one migration by default. This behavior can be changed for both by using the `-limit` parameter, and the `-version` parameter. Note `-version` has higher priority than `-limit` if you try to use them both.\n\nThe `redo` command will unapply the last migration and reapply it. This is useful during development, when you're writing migrations.\n\nUse the `status` command to see the state of the applied migrations:\n\n```bash\n$ sql-migrate status\n+---------------+-----------------------------------------+\n|   MIGRATION   |                 APPLIED                 |\n+---------------+-----------------------------------------+\n| 1_initial.sql | 2014-09-13 08:19:06.788354925 +0000 UTC |\n| 2_record.sql  | no                                      |\n+---------------+-----------------------------------------+\n```\n\n#### Running Test Integrations\n\nYou can see how to run setups for different setups by executing the `.sh` files in [test-integration](test-integration/)\n\n```bash\n# Run mysql-env.sh example (you need to be in the project root directory)\n\n./test-integration/mysql-env.sh\n```\n\n### MySQL Caveat\n\nIf you are using MySQL, you must append `?parseTime=true` to the `datasource` configuration. For example:\n\n```yml\nproduction:\n  dialect: mysql\n  datasource: root@/dbname?parseTime=true\n  dir: migrations/mysql\n  table: migrations\n```\n\nSee [here](https://github.com/go-sql-driver/mysql#parsetime) for more information.\n\n### Oracle (oci8)\n\nOracle Driver is [oci8](https://github.com/mattn/go-oci8), it is not pure Go code and relies on Oracle Office Client ([Instant Client](https://www.oracle.com/database/technologies/instant-client/downloads.html)), more detailed information is in the [oci8 repo](https://github.com/mattn/go-oci8).\n\n#### Install with Oracle support\n\nTo install the library and command line program, use the following:\n\n```bash\ngo get -tags oracle -v github.com/rubenv/sql-migrate/...\n```\n\n```yml\ndevelopment:\n  dialect: oci8\n  datasource: user/password@localhost:1521/sid\n  dir: migrations/oracle\n  table: migrations\n```\n\n### Oracle (godror)\n\nOracle Driver is [godror](https://github.com/godror/godror), it is not pure Go code and relies on Oracle Office Client ([Instant Client](https://www.oracle.com/database/technologies/instant-client/downloads.html)), more detailed information is in the [godror repository](https://github.com/godror/godror).\n\n#### Install with Oracle support\n\nTo install the library and command line program, use the following:\n\n1. Install sql-migrate\n\n```bash\ngo get -tags godror -v github.com/rubenv/sql-migrate/...\n```\n\n2. Download Oracle Office Client(e.g. macos, click [Instant Client](https://www.oracle.com/database/technologies/instant-client/downloads.html) if you are other system)\n\n```bash\nwget https://download.oracle.com/otn_software/mac/instantclient/193000/instantclient-basic-macos.x64-19.3.0.0.0dbru.zip\n```\n\n3. Configure environment variables `LD_LIBRARY_PATH`\n\n```\nexport LD_LIBRARY_PATH=your_oracle_office_path/instantclient_19_3\n```\n\n```yml\ndevelopment:\n  dialect: godror\n  datasource: user/password@localhost:1521/sid\n  dir: migrations/oracle\n  table: migrations\n```\n\n### As a library\n\nImport sql-migrate into your application:\n\n```go\nimport \"github.com/rubenv/sql-migrate\"\n```\n\nSet up a source of migrations, this can be from memory, from a set of files, from bindata (more on that later), or from any library that implements [`http.FileSystem`](https://godoc.org/net/http#FileSystem):\n\n```go\n// Hardcoded strings in memory:\nmigrations := &migrate.MemoryMigrationSource{\n    Migrations: []*migrate.Migration{\n        &migrate.Migration{\n            Id:   \"123\",\n            Up:   []string{\"CREATE TABLE people (id int)\"},\n            Down: []string{\"DROP TABLE people\"},\n        },\n    },\n}\n\n// OR: Read migrations from a folder:\nmigrations := &migrate.FileMigrationSource{\n    Dir: \"db/migrations\",\n}\n\n// OR: Use migrations from a packr box\n// Note: Packr is no longer supported, your best option these days is [embed](https://pkg.go.dev/embed)\nmigrations := &migrate.PackrMigrationSource{\n    Box: packr.New(\"migrations\", \"./migrations\"),\n}\n\n// OR: Use pkger which implements `http.FileSystem`\nmigrationSource := &migrate.HttpFileSystemMigrationSource{\n    FileSystem: pkger.Dir(\"/db/migrations\"),\n}\n\n// OR: Use migrations from bindata:\nmigrations := &migrate.AssetMigrationSource{\n    Asset:    Asset,\n    AssetDir: AssetDir,\n    Dir:      \"migrations\",\n}\n\n// OR: Read migrations from a `http.FileSystem`\nmigrationSource := &migrate.HttpFileSystemMigrationSource{\n    FileSystem: httpFS,\n}\n```\n\nThen use the `Exec` function to upgrade your database:\n\n```go\ndb, err := sql.Open(\"sqlite3\", filename)\nif err != nil {\n    // Handle errors!\n}\n\nn, err := migrate.Exec(db, \"sqlite3\", migrations, migrate.Up)\nif err != nil {\n    // Handle errors!\n}\nfmt.Printf(\"Applied %d migrations!\\n\", n)\n```\n\nNote that `n` can be greater than `0` even if there is an error: any migration that succeeded will remain applied even if a later one fails.\n\nCheck [the GoDoc reference](https://godoc.org/github.com/rubenv/sql-migrate) for the full documentation.\n\n## Writing migrations\n\nMigrations are defined in SQL files, which contain a set of SQL statements. Special comments are used to distinguish up and down migrations.\n\n```sql\n-- +migrate Up\n-- SQL in section 'Up' is executed when this migration is applied\nCREATE TABLE people (id int);\n\n\n-- +migrate Down\n-- SQL section 'Down' is executed when this migration is rolled back\nDROP TABLE people;\n```\n\nYou can put multiple statements in each block, as long as you end them with a semicolon (`;`).\n\nYou can alternatively set up a separator string that matches an entire line by setting `sqlparse.LineSeparator`. This\ncan be used to imitate, for example, MS SQL Query Analyzer functionality where commands can be separated by a line with\ncontents of `GO`. If `sqlparse.LineSeparator` is matched, it will not be included in the resulting migration scripts.\n\nIf you have complex statements which contain semicolons, use `StatementBegin` and `StatementEnd` to indicate boundaries:\n\n```sql\n-- +migrate Up\nCREATE TABLE people (id int);\n\n-- +migrate StatementBegin\nCREATE OR REPLACE FUNCTION do_something()\nreturns void AS $$\nDECLARE\n  create_query text;\nBEGIN\n  -- Do something here\nEND;\n$$\nlanguage plpgsql;\n-- +migrate StatementEnd\n\n-- +migrate Down\nDROP FUNCTION do_something();\nDROP TABLE people;\n```\n\nThe order in which migrations are applied is defined through the filename: sql-migrate will sort migrations based on their name. It's recommended to use an increasing version number or a timestamp as the first part of the filename.\n\nNormally each migration is run within a transaction in order to guarantee that it is fully atomic. However some SQL commands (for example creating an index concurrently in PostgreSQL) cannot be executed inside a transaction. In order to execute such a command in a migration, the migration can be run using the `notransaction` option:\n\n```sql\n-- +migrate Up notransaction\nCREATE UNIQUE INDEX CONCURRENTLY people_unique_id_idx ON people (id);\n\n-- +migrate Down\nDROP INDEX people_unique_id_idx;\n```\n\n## Embedding migrations with [embed](https://pkg.go.dev/embed)\n\nIf you like your Go applications self-contained (that is: a single binary): use [embed](https://pkg.go.dev/embed) to embed the migration files.\n\nJust write your migration files as usual, as a set of SQL files in a folder.\n\nImport the embed package into your application and point it to your migrations:\n\n```go\nimport \"embed\"\n\n//go:embed migrations/*\nvar dbMigrations embed.FS\n```\n\nUse the `EmbedFileSystemMigrationSource` in your application to find the migrations:\n\n```go\nmigrations := migrate.EmbedFileSystemMigrationSource{\n\tFileSystem: dbMigrations,\n\tRoot:       \"migrations\",\n}\n```\n\nOther options such as [packr](https://github.com/gobuffalo/packr) or [go-bindata](https://github.com/shuLhan/go-bindata) are no longer recommended.\n\n## Embedding migrations with libraries that implement `http.FileSystem`\n\nYou can also embed migrations with any library that implements `http.FileSystem`, like [`vfsgen`](https://github.com/shurcooL/vfsgen), [`parcello`](https://github.com/phogolabs/parcello), or [`go-resources`](https://github.com/omeid/go-resources).\n\n```go\nmigrationSource := &migrate.HttpFileSystemMigrationSource{\n    FileSystem: httpFS,\n}\n```\n\n## Extending\n\nAdding a new migration source means implementing `MigrationSource`.\n\n```go\ntype MigrationSource interface {\n    FindMigrations() ([]*Migration, error)\n}\n```\n\nThe resulting slice of migrations will be executed in the given order, so it should usually be sorted by the `Id` field.\n\n## Usage with [sqlx](https://jmoiron.github.io/sqlx/)\n\nThis library is compatible with sqlx. When calling migrate just dereference the DB from your `*sqlx.DB`:\n\n```\nn, err := migrate.Exec(db.DB, \"sqlite3\", migrations, migrate.Up)\n                    //   ^^^ <-- Here db is a *sqlx.DB, the db.DB field is the plain sql.DB\nif err != nil {\n    // Handle errors!\n}\n```\n\n## Questions or Feedback?\n\nYou can use Github Issues for feedback or questions.\n\n## License\n\nThis library is distributed under the [MIT](LICENSE) license.\n"
        },
        {
          "name": "bindata_test.go",
          "type": "blob",
          "size": 4.4658203125,
          "content": "package migrate\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"fmt\"\n\t\"io\"\n\t\"strings\"\n)\n\nfunc bindata_read(data []byte, name string) ([]byte, error) {\n\tgz, err := gzip.NewReader(bytes.NewBuffer(data))\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Read %q: %w\", name, err)\n\t}\n\n\tvar buf bytes.Buffer\n\t_, err = io.Copy(&buf, gz)\n\tif err := gz.Close(); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Read %q: %w\", name, err)\n\t}\n\n\treturn buf.Bytes(), nil\n}\n\nfunc test_migrations_1_initial_sql() ([]byte, error) {\n\treturn bindata_read([]byte{\n\t\t0x1f, 0x8b, 0x08, 0x00, 0x00, 0x09, 0x6e, 0x88, 0x00, 0xff, 0x8c, 0xcd,\n\t\t0x3d, 0x0e, 0x82, 0x40, 0x10, 0x05, 0xe0, 0x7e, 0x4e, 0xf1, 0x3a, 0x34,\n\t\t0x86, 0x13, 0x50, 0xa1, 0xd0, 0x91, 0xa8, 0x08, 0x07, 0x40, 0x76, 0x22,\n\t\t0x13, 0xd7, 0xdd, 0x09, 0xac, 0xc1, 0xe3, 0xbb, 0xc4, 0x68, 0xb4, 0xb3,\n\t\t0x7c, 0x6f, 0x7e, 0xbe, 0x34, 0xc5, 0xe6, 0x26, 0x97, 0xb1, 0x0b, 0x8c,\n\t\t0x56, 0x29, 0xc6, 0xd3, 0xb1, 0x82, 0x38, 0x4c, 0xdc, 0x07, 0xf1, 0x0e,\n\t\t0x49, 0xab, 0x09, 0x64, 0x02, 0x3f, 0xb8, 0xbf, 0x07, 0x36, 0x98, 0x07,\n\t\t0x76, 0x08, 0x43, 0xac, 0x5e, 0x77, 0xcb, 0x52, 0x0c, 0x9d, 0xaa, 0x15,\n\t\t0x36, 0xb4, 0xab, 0xcb, 0xbc, 0x29, 0xd1, 0xe4, 0xdb, 0xaa, 0x84, 0xb2,\n\t\t0x57, 0xcb, 0x58, 0x89, 0x89, 0x2f, 0xc3, 0x3a, 0x23, 0xa2, 0x6f, 0xb0,\n\t\t0xf0, 0xb3, 0x7b, 0x93, 0x1f, 0x6f, 0x29, 0xff, 0x12, 0x47, 0x6f, 0x6d,\n\t\t0x9c, 0x9e, 0xbb, 0xfe, 0x4a, 0x45, 0xbd, 0x3f, 0xfc, 0x98, 0x19, 0x3d,\n\t\t0x03, 0x00, 0x00, 0xff, 0xff, 0x0d, 0x70, 0x5e, 0xf9, 0xda, 0x00, 0x00,\n\t\t0x00,\n\t},\n\t\t\"test-migrations/1_initial.sql\",\n\t)\n}\n\nfunc test_migrations_2_record_sql() ([]byte, error) {\n\treturn bindata_read([]byte{\n\t\t0x1f, 0x8b, 0x08, 0x00, 0x00, 0x09, 0x6e, 0x88, 0x00, 0xff, 0xd2, 0xd5,\n\t\t0x55, 0xd0, 0xce, 0xcd, 0x4c, 0x2f, 0x4a, 0x2c, 0x49, 0x55, 0x08, 0x2d,\n\t\t0xe0, 0xf2, 0xf4, 0x0b, 0x76, 0x0d, 0x0a, 0x51, 0xf0, 0xf4, 0x0b, 0xf1,\n\t\t0x57, 0x28, 0x48, 0xcd, 0x2f, 0xc8, 0x49, 0x55, 0xd0, 0xc8, 0x4c, 0xd1,\n\t\t0x54, 0x08, 0x73, 0xf4, 0x09, 0x75, 0x0d, 0x56, 0xd0, 0x30, 0xd4, 0xb4,\n\t\t0xe6, 0xe2, 0x42, 0xd6, 0xe3, 0x92, 0x5f, 0x9e, 0xc7, 0xe5, 0xe2, 0xea,\n\t\t0xe3, 0x1a, 0xe2, 0xaa, 0xe0, 0x16, 0xe4, 0xef, 0x0b, 0xd3, 0x15, 0xee,\n\t\t0xe1, 0x1a, 0xe4, 0xaa, 0x90, 0x99, 0x62, 0x6b, 0x68, 0xcd, 0x05, 0x08,\n\t\t0x00, 0x00, 0xff, 0xff, 0xf4, 0x3a, 0x7b, 0xae, 0x64, 0x00, 0x00, 0x00,\n\t},\n\t\t\"test-migrations/2_record.sql\",\n\t)\n}\n\n// Asset loads and returns the asset for the given name.\n// It returns an error if the asset could not be found or\n// could not be loaded.\nfunc Asset(name string) ([]byte, error) {\n\tcanonicalName := strings.ReplaceAll(name, \"\\\\\", \"/\")\n\tif f, ok := _bindata[canonicalName]; ok {\n\t\treturn f()\n\t}\n\treturn nil, fmt.Errorf(\"Asset %s not found\", name)\n}\n\n// AssetNames returns the names of the assets.\nfunc AssetNames() []string {\n\tnames := make([]string, 0, len(_bindata))\n\tfor name := range _bindata {\n\t\tnames = append(names, name)\n\t}\n\treturn names\n}\n\n// _bindata is a table, holding each asset generator, mapped to its name.\nvar _bindata = map[string]func() ([]byte, error){\n\t\"test-migrations/1_initial.sql\": test_migrations_1_initial_sql,\n\t\"test-migrations/2_record.sql\":  test_migrations_2_record_sql,\n}\n\n// AssetDir returns the file names below a certain\n// directory embedded in the file by go-bindata.\n// For example if you run go-bindata on data/... and data contains the\n// following hierarchy:\n//\n//\tdata/\n//\t  foo.txt\n//\t  img/\n//\t    a.png\n//\t    b.png\n//\n// then AssetDir(\"data\") would return []string{\"foo.txt\", \"img\"}\n// AssetDir(\"data/img\") would return []string{\"a.png\", \"b.png\"}\n// AssetDir(\"foo.txt\") and AssetDir(\"notexist\") would return an error\n// AssetDir(\"\") will return []string{\"data\"}.\nfunc AssetDir(name string) ([]string, error) {\n\tnode := _bintree\n\tif len(name) != 0 {\n\t\tcanonicalName := strings.ReplaceAll(name, \"\\\\\", \"/\")\n\t\tpathList := strings.Split(canonicalName, \"/\")\n\t\tfor _, p := range pathList {\n\t\t\tnode = node.Children[p]\n\t\t\tif node == nil {\n\t\t\t\treturn nil, fmt.Errorf(\"Asset %s not found\", name)\n\t\t\t}\n\t\t}\n\t}\n\tif node.Func != nil {\n\t\treturn nil, fmt.Errorf(\"Asset %s not found\", name)\n\t}\n\trv := make([]string, 0, len(node.Children))\n\tfor name := range node.Children {\n\t\trv = append(rv, name)\n\t}\n\treturn rv, nil\n}\n\ntype _bintree_t struct {\n\tFunc     func() ([]byte, error)\n\tChildren map[string]*_bintree_t\n}\n\nvar _bintree = &_bintree_t{nil, map[string]*_bintree_t{\n\t\"test-migrations\": {nil, map[string]*_bintree_t{\n\t\t\"1_initial.sql\": {test_migrations_1_initial_sql, map[string]*_bintree_t{}},\n\t\t\"2_record.sql\":  {test_migrations_2_record_sql, map[string]*_bintree_t{}},\n\t}},\n}}\n"
        },
        {
          "name": "doc.go",
          "type": "blob",
          "size": 7.431640625,
          "content": "/*\nSQL Schema migration tool for Go.\n\nKey features:\n\n  - Usable as a CLI tool or as a library\n  - Supports SQLite, PostgreSQL, MySQL, MSSQL and Oracle databases (through gorp)\n  - Can embed migrations into your application\n  - Migrations are defined with SQL for full flexibility\n  - Atomic migrations\n  - Up/down migrations to allow rollback\n  - Supports multiple database types in one project\n\n# Installation\n\nTo install the library and command line program, use the following:\n\n\tgo get -v github.com/rubenv/sql-migrate/...\n\n# Command-line tool\n\nThe main command is called sql-migrate.\n\n\t$ sql-migrate --help\n\tusage: sql-migrate [--version] [--help] <command> [<args>]\n\n\tAvailable commands are:\n\t\tdown      Undo a database migration\n\t\tnew       Create a new migration\n\t\tredo      Reapply the last migration\n\t\tstatus    Show migration status\n\t\tup        Migrates the database to the most recent version available\n\nEach command requires a configuration file (which defaults to dbconfig.yml, but can be specified with the -config flag). This config file should specify one or more environments:\n\n\tdevelopment:\n\t\tdialect: sqlite3\n\t\tdatasource: test.db\n\t\tdir: migrations/sqlite3\n\n\tproduction:\n\t\tdialect: postgres\n\t\tdatasource: dbname=myapp sslmode=disable\n\t\tdir: migrations/postgres\n\t\ttable: migrations\n\nThe `table` setting is optional and will default to `gorp_migrations`.\n\nThe environment that will be used can be specified with the -env flag (defaults to development).\n\nUse the --help flag in combination with any of the commands to get an overview of its usage:\n\n\t$ sql-migrate up --help\n\tUsage: sql-migrate up [options] ...\n\n\t  Migrates the database to the most recent version available.\n\n\tOptions:\n\n\t  -config=config.yml   Configuration file to use.\n\t  -env=\"development\"   Environment.\n\t  -limit=0             Limit the number of migrations (0 = unlimited).\n\t  -dryrun              Don't apply migrations, just print them.\n\nThe up command applies all available migrations. By contrast, down will only apply one migration by default. This behavior can be changed for both by using the -limit parameter.\n\nThe redo command will unapply the last migration and reapply it. This is useful during development, when you're writing migrations.\n\nUse the status command to see the state of the applied migrations:\n\n\t$ sql-migrate status\n\t+---------------+-----------------------------------------+\n\t|   MIGRATION   |                 APPLIED                 |\n\t+---------------+-----------------------------------------+\n\t| 1_initial.sql | 2014-09-13 08:19:06.788354925 +0000 UTC |\n\t| 2_record.sql  | no                                      |\n\t+---------------+-----------------------------------------+\n\n# MySQL Caveat\n\nIf you are using MySQL, you must append ?parseTime=true to the datasource configuration. For example:\n\n\tproduction:\n\t\tdialect: mysql\n\t\tdatasource: root@/dbname?parseTime=true\n\t\tdir: migrations/mysql\n\t\ttable: migrations\n\nSee https://github.com/go-sql-driver/mysql#parsetime for more information.\n\n# Library\n\nImport sql-migrate into your application:\n\n\timport \"github.com/rubenv/sql-migrate\"\n\nSet up a source of migrations, this can be from memory, from a set of files or from bindata (more on that later):\n\n\t// Hardcoded strings in memory:\n\tmigrations := &migrate.MemoryMigrationSource{\n\t\tMigrations: []*migrate.Migration{\n\t\t\t&migrate.Migration{\n\t\t\t\tId:   \"123\",\n\t\t\t\tUp:   []string{\"CREATE TABLE people (id int)\"},\n\t\t\t\tDown: []string{\"DROP TABLE people\"},\n\t\t\t},\n\t\t},\n\t}\n\n\t// OR: Read migrations from a folder:\n\tmigrations := &migrate.FileMigrationSource{\n\t\tDir: \"db/migrations\",\n\t}\n\n\t// OR: Use migrations from bindata:\n\tmigrations := &migrate.AssetMigrationSource{\n\t\tAsset:    Asset,\n\t\tAssetDir: AssetDir,\n\t\tDir:      \"migrations\",\n\t}\n\nThen use the Exec function to upgrade your database:\n\n\tdb, err := sql.Open(\"sqlite3\", filename)\n\tif err != nil {\n\t\t// Handle errors!\n\t}\n\n\tn, err := migrate.Exec(db, \"sqlite3\", migrations, migrate.Up)\n\tif err != nil {\n\t\t// Handle errors!\n\t}\n\tfmt.Printf(\"Applied %d migrations!\\n\", n)\n\nNote that n can be greater than 0 even if there is an error: any migration that succeeded will remain applied even if a later one fails.\n\nThe full set of capabilities can be found in the API docs below.\n\n# Writing migrations\n\nMigrations are defined in SQL files, which contain a set of SQL statements. Special comments are used to distinguish up and down migrations.\n\n\t-- +migrate Up\n\t-- SQL in section 'Up' is executed when this migration is applied\n\tCREATE TABLE people (id int);\n\n\n\t-- +migrate Down\n\t-- SQL section 'Down' is executed when this migration is rolled back\n\tDROP TABLE people;\n\nYou can put multiple statements in each block, as long as you end them with a semicolon (;).\n\nIf you have complex statements which contain semicolons, use StatementBegin and StatementEnd to indicate boundaries:\n\n\t-- +migrate Up\n\tCREATE TABLE people (id int);\n\n\t-- +migrate StatementBegin\n\tCREATE OR REPLACE FUNCTION do_something()\n\treturns void AS $$\n\tDECLARE\n\t  create_query text;\n\tBEGIN\n\t  -- Do something here\n\tEND;\n\t$$\n\tlanguage plpgsql;\n\t-- +migrate StatementEnd\n\n\t-- +migrate Down\n\tDROP FUNCTION do_something();\n\tDROP TABLE people;\n\nThe order in which migrations are applied is defined through the filename: sql-migrate will sort migrations based on their name. It's recommended to use an increasing version number or a timestamp as the first part of the filename.\n\nNormally each migration is run within a transaction in order to guarantee that it is fully atomic. However some SQL commands (for example creating an index concurrently in PostgreSQL) cannot be executed inside a transaction. In order to execute such a command in a migration, the migration can be run using the notransaction option:\n\n\t-- +migrate Up notransaction\n\tCREATE UNIQUE INDEX people_unique_id_idx CONCURRENTLY ON people (id);\n\n\t-- +migrate Down\n\tDROP INDEX people_unique_id_idx;\n\n# Embedding migrations with packr\n\nIf you like your Go applications self-contained (that is: a single binary): use packr (https://github.com/gobuffalo/packr) to embed the migration files.\n\nJust write your migration files as usual, as a set of SQL files in a folder.\n\nUse the PackrMigrationSource in your application to find the migrations:\n\n\tmigrations := &migrate.PackrMigrationSource{\n\t\tBox: packr.NewBox(\"./migrations\"),\n\t}\n\nIf you already have a box and would like to use a subdirectory:\n\n\tmigrations := &migrate.PackrMigrationSource{\n\t\tBox: myBox,\n\t\tDir: \"./migrations\",\n\t}\n\n# Embedding migrations with bindata\n\nAs an alternative, but slightly less maintained, you can use bindata (https://github.com/shuLhan/go-bindata) to embed the migration files.\n\nJust write your migration files as usual, as a set of SQL files in a folder.\n\nThen use bindata to generate a .go file with the migrations embedded:\n\n\tgo-bindata -pkg myapp -o bindata.go db/migrations/\n\nThe resulting bindata.go file will contain your migrations. Remember to regenerate your bindata.go file whenever you add/modify a migration (go generate will help here, once it arrives).\n\nUse the AssetMigrationSource in your application to find the migrations:\n\n\tmigrations := &migrate.AssetMigrationSource{\n\t\tAsset:    Asset,\n\t\tAssetDir: AssetDir,\n\t\tDir:      \"db/migrations\",\n\t}\n\nBoth Asset and AssetDir are functions provided by bindata.\n\nThen proceed as usual.\n\n# Extending\n\nAdding a new migration source means implementing MigrationSource.\n\n\ttype MigrationSource interface {\n\t\tFindMigrations() ([]*Migration, error)\n\t}\n\nThe resulting slice of migrations will be executed in the given order, so it should usually be sorted by the Id field.\n*/\npackage migrate\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 1.8544921875,
          "content": "module github.com/rubenv/sql-migrate\n\ngo 1.21\n\nrequire (\n\tgithub.com/denisenkom/go-mssqldb v0.9.0\n\tgithub.com/go-gorp/gorp/v3 v3.1.0\n\tgithub.com/go-sql-driver/mysql v1.6.0\n\tgithub.com/godror/godror v0.40.4\n\tgithub.com/lib/pq v1.10.7\n\tgithub.com/mattn/go-oci8 v0.1.1\n\tgithub.com/mattn/go-sqlite3 v1.14.19\n\tgithub.com/mitchellh/cli v1.1.5\n\tgithub.com/olekukonko/tablewriter v0.0.5\n\tgopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c\n\tgopkg.in/yaml.v2 v2.4.0\n)\n\nrequire (\n\tgithub.com/Masterminds/goutils v1.1.1 // indirect\n\tgithub.com/Masterminds/semver/v3 v3.2.0 // indirect\n\tgithub.com/Masterminds/sprig/v3 v3.2.3 // indirect\n\tgithub.com/armon/go-radix v1.0.0 // indirect\n\tgithub.com/bgentry/speakeasy v0.1.0 // indirect\n\tgithub.com/fatih/color v1.13.0 // indirect\n\tgithub.com/go-logfmt/logfmt v0.6.0 // indirect\n\tgithub.com/godror/knownpb v0.1.1 // indirect\n\tgithub.com/golang-sql/civil v0.0.0-20190719163853-cb61b32ac6fe // indirect\n\tgithub.com/google/uuid v1.3.0 // indirect\n\tgithub.com/hashicorp/errwrap v1.1.0 // indirect\n\tgithub.com/hashicorp/go-multierror v1.1.1 // indirect\n\tgithub.com/huandu/xstrings v1.4.0 // indirect\n\tgithub.com/imdario/mergo v0.3.13 // indirect\n\tgithub.com/kr/pretty v0.3.1 // indirect\n\tgithub.com/kr/text v0.2.0 // indirect\n\tgithub.com/mattn/go-colorable v0.1.13 // indirect\n\tgithub.com/mattn/go-isatty v0.0.17 // indirect\n\tgithub.com/mattn/go-runewidth v0.0.9 // indirect\n\tgithub.com/mitchellh/copystructure v1.2.0 // indirect\n\tgithub.com/mitchellh/reflectwalk v1.0.2 // indirect\n\tgithub.com/posener/complete v1.2.3 // indirect\n\tgithub.com/rogpeppe/go-internal v1.9.0 // indirect\n\tgithub.com/shopspring/decimal v1.3.1 // indirect\n\tgithub.com/spf13/cast v1.5.0 // indirect\n\tgolang.org/x/crypto v0.31.0 // indirect\n\tgolang.org/x/exp v0.0.0-20230905200255-921286631fa9 // indirect\n\tgolang.org/x/sys v0.28.0 // indirect\n\tgoogle.golang.org/protobuf v1.33.0 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 15.8125,
          "content": "github.com/Masterminds/goutils v1.1.1 h1:5nUrii3FMTL5diU80unEVvNevw1nH4+ZV4DSLVJLSYI=\ngithub.com/Masterminds/goutils v1.1.1/go.mod h1:8cTjp+g8YejhMuvIA5y2vz3BpJxksy863GQaJW2MFNU=\ngithub.com/Masterminds/semver/v3 v3.1.1/go.mod h1:VPu/7SZ7ePZ3QOrcuXROw5FAcLl4a0cBrbBpGY/8hQs=\ngithub.com/Masterminds/semver/v3 v3.2.0 h1:3MEsd0SM6jqZojhjLWWeBY+Kcjy9i6MQAeY7YgDP83g=\ngithub.com/Masterminds/semver/v3 v3.2.0/go.mod h1:qvl/7zhW3nngYb5+80sSMF+FG2BjYrf8m9wsX0PNOMQ=\ngithub.com/Masterminds/sprig/v3 v3.2.1/go.mod h1:UoaO7Yp8KlPnJIYWTFkMaqPUYKTfGFPhxNuwnnxkKlk=\ngithub.com/Masterminds/sprig/v3 v3.2.3 h1:eL2fZNezLomi0uOLqjQoN6BfsDD+fyLtgbJMAj9n6YA=\ngithub.com/Masterminds/sprig/v3 v3.2.3/go.mod h1:rXcFaZ2zZbLRJv/xSysmlgIM1u11eBaRMhvYXJNkGuM=\ngithub.com/UNO-SOFT/zlog v0.8.1 h1:TEFkGJHtUfTRgMkLZiAjLSHALjwSBdw6/zByMC5GJt4=\ngithub.com/UNO-SOFT/zlog v0.8.1/go.mod h1:yqFOjn3OhvJ4j7ArJqQNA+9V+u6t9zSAyIZdWdMweWc=\ngithub.com/armon/go-radix v0.0.0-20180808171621-7fddfc383310/go.mod h1:ufUuZ+zHj4x4TnLV4JWEpy2hxWSpsRywHrMgIH9cCH8=\ngithub.com/armon/go-radix v1.0.0 h1:F4z6KzEeeQIMeLFa97iZU6vupzoecKdU5TX24SNppXI=\ngithub.com/armon/go-radix v1.0.0/go.mod h1:ufUuZ+zHj4x4TnLV4JWEpy2hxWSpsRywHrMgIH9cCH8=\ngithub.com/bgentry/speakeasy v0.1.0 h1:ByYyxL9InA1OWqxJqqp2A5pYHUrCiAL6K3J+LKSsQkY=\ngithub.com/bgentry/speakeasy v0.1.0/go.mod h1:+zsyZBPWlz7T6j88CTgSN5bM796AkVf0kBD4zp0CCIs=\ngithub.com/creack/pty v1.1.9/go.mod h1:oKZEueFk5CKHvIhNR5MUki03XCEU+Q6VDXinZuGJ33E=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/denisenkom/go-mssqldb v0.9.0 h1:RSohk2RsiZqLZ0zCjtfn3S4Gp4exhpBWHyQ7D0yGjAk=\ngithub.com/denisenkom/go-mssqldb v0.9.0/go.mod h1:xbL0rPBG9cCiLr28tMa8zpbdarY27NDyej4t/EjAShU=\ngithub.com/fatih/color v1.7.0/go.mod h1:Zm6kSWBoL9eyXnKyktHP6abPY2pDugNf5KwzbycvMj4=\ngithub.com/fatih/color v1.13.0 h1:8LOYc1KYPPmyKMuN8QV2DNRWNbLo6LZ0iLs8+mlH53w=\ngithub.com/fatih/color v1.13.0/go.mod h1:kLAiJbzzSOZDVNGyDpeOxJ47H46qBXwg5ILebYFFOfk=\ngithub.com/frankban/quicktest v1.14.3 h1:FJKSZTDHjyhriyC81FLQ0LY93eSai0ZyR/ZIkd3ZUKE=\ngithub.com/frankban/quicktest v1.14.3/go.mod h1:mgiwOwqx65TmIk1wJ6Q7wvnVMocbUorkibMOrVTHZps=\ngithub.com/go-gorp/gorp/v3 v3.1.0 h1:ItKF/Vbuj31dmV4jxA1qblpSwkl9g1typ24xoe70IGs=\ngithub.com/go-gorp/gorp/v3 v3.1.0/go.mod h1:dLEjIyyRNiXvNZ8PSmzpt1GsWAUK8kjVhEpjH8TixEw=\ngithub.com/go-logfmt/logfmt v0.6.0 h1:wGYYu3uicYdqXVgoYbvnkrPVXkuLM1p1ifugDMEdRi4=\ngithub.com/go-logfmt/logfmt v0.6.0/go.mod h1:WYhtIu8zTZfxdn5+rREduYbwxfcBr/Vr6KEVveWlfTs=\ngithub.com/go-logr/logr v1.2.4 h1:g01GSCwiDw2xSZfjJ2/T9M+S6pFdcNtFYsp+Y43HYDQ=\ngithub.com/go-logr/logr v1.2.4/go.mod h1:jdQByPbusPIv2/zmleS9BjJVeZ6kBagPoEUsqbVz/1A=\ngithub.com/go-sql-driver/mysql v1.6.0 h1:BCTh4TKNUYmOmMUcQ3IipzF5prigylS7XXjEkfCHuOE=\ngithub.com/go-sql-driver/mysql v1.6.0/go.mod h1:DCzpHaOWr8IXmIStZouvnhqoel9Qv2LBy8hT2VhHyBg=\ngithub.com/godror/godror v0.40.4 h1:X1e7hUd02GDaLWKZj40Z7L0CP0W9TrGgmPQZw6+anBg=\ngithub.com/godror/godror v0.40.4/go.mod h1:i8YtVTHUJKfFT3wTat4A9UoqScUtZXiYB9Rf3SVARgc=\ngithub.com/godror/knownpb v0.1.1 h1:A4J7jdx7jWBhJm18NntafzSC//iZDHkDi1+juwQ5pTI=\ngithub.com/godror/knownpb v0.1.1/go.mod h1:4nRFbQo1dDuwKnblRXDxrfCFYeT4hjg3GjMqef58eRE=\ngithub.com/golang-sql/civil v0.0.0-20190719163853-cb61b32ac6fe h1:lXe2qZdvpiX5WZkZR4hgp4KJVfY3nMkvmwbVkpv1rVY=\ngithub.com/golang-sql/civil v0.0.0-20190719163853-cb61b32ac6fe/go.mod h1:8vg3r2VgvsThLBIFL93Qb5yWzgyZWhEmBwUJWevAkK0=\ngithub.com/google/go-cmp v0.5.8 h1:e6P7q2lk1O+qJJb4BtCQXlK8vWEO8V1ZeuEdJNOqZyg=\ngithub.com/google/go-cmp v0.5.8/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/google/uuid v1.1.1/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/google/uuid v1.1.2/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/google/uuid v1.3.0 h1:t6JiXgmwXMjEs8VusXIJk2BXHsn+wx8BZdTaoZ5fu7I=\ngithub.com/google/uuid v1.3.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/hashicorp/errwrap v1.0.0/go.mod h1:YH+1FKiLXxHSkmPseP+kNlulaMuP3n2brvKWEqk/Jc4=\ngithub.com/hashicorp/errwrap v1.1.0 h1:OxrOeh75EUXMY8TBjag2fzXGZ40LB6IKw45YeGUDY2I=\ngithub.com/hashicorp/errwrap v1.1.0/go.mod h1:YH+1FKiLXxHSkmPseP+kNlulaMuP3n2brvKWEqk/Jc4=\ngithub.com/hashicorp/go-multierror v1.0.0/go.mod h1:dHtQlpGsu+cZNNAkkCN/P3hoUDHhCYQXV3UM06sGGrk=\ngithub.com/hashicorp/go-multierror v1.1.1 h1:H5DkEtf6CXdFp0N0Em5UCwQpXMWke8IA0+lD48awMYo=\ngithub.com/hashicorp/go-multierror v1.1.1/go.mod h1:iw975J/qwKPdAO1clOe2L8331t/9/fmwbPZ6JB6eMoM=\ngithub.com/huandu/xstrings v1.3.1/go.mod h1:y5/lhBue+AyNmUVz9RLU9xbLR0o4KIIExikq4ovT0aE=\ngithub.com/huandu/xstrings v1.3.2/go.mod h1:y5/lhBue+AyNmUVz9RLU9xbLR0o4KIIExikq4ovT0aE=\ngithub.com/huandu/xstrings v1.3.3/go.mod h1:y5/lhBue+AyNmUVz9RLU9xbLR0o4KIIExikq4ovT0aE=\ngithub.com/huandu/xstrings v1.4.0 h1:D17IlohoQq4UcpqD7fDk80P7l+lwAmlFaBHgOipl2FU=\ngithub.com/huandu/xstrings v1.4.0/go.mod h1:y5/lhBue+AyNmUVz9RLU9xbLR0o4KIIExikq4ovT0aE=\ngithub.com/imdario/mergo v0.3.11/go.mod h1:jmQim1M+e3UYxmgPu/WyfjB3N3VflVyUjjjwH0dnCYA=\ngithub.com/imdario/mergo v0.3.13 h1:lFzP57bqS/wsqKssCGmtLAb8A0wKjLGrve2q3PPVcBk=\ngithub.com/imdario/mergo v0.3.13/go.mod h1:4lJ1jqUDcsbIECGy0RUJAXNIhg+6ocWgb1ALK2O4oXg=\ngithub.com/kr/pretty v0.2.1/go.mod h1:ipq/a2n7PKx3OHsz4KJII5eveXtPO4qwEXGdVfWzfnI=\ngithub.com/kr/pretty v0.3.1 h1:flRD4NNwYAUpkphVc1HcthR4KEIFJ65n8Mw5qdRn3LE=\ngithub.com/kr/pretty v0.3.1/go.mod h1:hoEshYVHaxMs3cyo3Yncou5ZscifuDolrwPKZanG3xk=\ngithub.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=\ngithub.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=\ngithub.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=\ngithub.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=\ngithub.com/lib/pq v1.10.7 h1:p7ZhMD+KsSRozJr34udlUrhboJwWAgCg34+/ZZNvZZw=\ngithub.com/lib/pq v1.10.7/go.mod h1:AlVN5x4E4T544tWzH6hKfbfQvm3HdbOxrmggDNAPY9o=\ngithub.com/mattn/go-colorable v0.0.9/go.mod h1:9vuHe8Xs5qXnSaW/c/ABM9alt+Vo+STaOChaDxuIBZU=\ngithub.com/mattn/go-colorable v0.1.9/go.mod h1:u6P/XSegPjTcexA+o6vUJrdnUu04hMope9wVRipJSqc=\ngithub.com/mattn/go-colorable v0.1.13 h1:fFA4WZxdEF4tXPZVKMLwD8oUnCTTo08duU7wxecdEvA=\ngithub.com/mattn/go-colorable v0.1.13/go.mod h1:7S9/ev0klgBDR4GtXTXX8a3vIGJpMovkB8vQcUbaXHg=\ngithub.com/mattn/go-isatty v0.0.3/go.mod h1:M+lRXTBqGeGNdLjl/ufCoiOlB5xdOkqRJdNxMWT7Zi4=\ngithub.com/mattn/go-isatty v0.0.12/go.mod h1:cbi8OIDigv2wuxKPP5vlRcQ1OAZbq2CE4Kysco4FUpU=\ngithub.com/mattn/go-isatty v0.0.14/go.mod h1:7GGIvUiUoEMVVmxf/4nioHXj79iQHKdU27kJ6hsGG94=\ngithub.com/mattn/go-isatty v0.0.16/go.mod h1:kYGgaQfpe5nmfYZH+SKPsOc2e4SrIfOl2e/yFXSvRLM=\ngithub.com/mattn/go-isatty v0.0.17 h1:BTarxUcIeDqL27Mc+vyvdWYSL28zpIhv3RoTdsLMPng=\ngithub.com/mattn/go-isatty v0.0.17/go.mod h1:kYGgaQfpe5nmfYZH+SKPsOc2e4SrIfOl2e/yFXSvRLM=\ngithub.com/mattn/go-oci8 v0.1.1 h1:aEUDxNAyDG0tv8CA3TArnDQNyc4EhnWlsfxRgDHABHM=\ngithub.com/mattn/go-oci8 v0.1.1/go.mod h1:wjDx6Xm9q7dFtHJvIlrI99JytznLw5wQ4R+9mNXJwGI=\ngithub.com/mattn/go-runewidth v0.0.9 h1:Lm995f3rfxdpd6TSmuVCHVb/QhupuXlYr8sCI/QdE+0=\ngithub.com/mattn/go-runewidth v0.0.9/go.mod h1:H031xJmbD/WCDINGzjvQ9THkh0rPKHF+m2gUSrubnMI=\ngithub.com/mattn/go-sqlite3 v1.14.19 h1:fhGleo2h1p8tVChob4I9HpmVFIAkKGpiukdrgQbWfGI=\ngithub.com/mattn/go-sqlite3 v1.14.19/go.mod h1:2eHXhiwb8IkHr+BDWZGa96P6+rkvnG63S2DGjv9HUNg=\ngithub.com/mitchellh/cli v1.1.5 h1:OxRIeJXpAMztws/XHlN2vu6imG5Dpq+j61AzAX5fLng=\ngithub.com/mitchellh/cli v1.1.5/go.mod h1:v8+iFts2sPIKUV1ltktPXMCC8fumSKFItNcD2cLtRR4=\ngithub.com/mitchellh/copystructure v1.0.0/go.mod h1:SNtv71yrdKgLRyLFxmLdkAbkKEFWgYaq1OVrnRcwhnw=\ngithub.com/mitchellh/copystructure v1.2.0 h1:vpKXTN4ewci03Vljg/q9QvCGUDttBOGBIa15WveJJGw=\ngithub.com/mitchellh/copystructure v1.2.0/go.mod h1:qLl+cE2AmVv+CoeAwDPye/v+N2HKCj9FbZEVFJRxO9s=\ngithub.com/mitchellh/reflectwalk v1.0.0/go.mod h1:mSTlrgnPZtwu0c4WaC2kGObEpuNDbx0jmZXqmk4esnw=\ngithub.com/mitchellh/reflectwalk v1.0.2 h1:G2LzWKi524PWgd3mLHV8Y5k7s6XUvT0Gef6zxSIeXaQ=\ngithub.com/mitchellh/reflectwalk v1.0.2/go.mod h1:mSTlrgnPZtwu0c4WaC2kGObEpuNDbx0jmZXqmk4esnw=\ngithub.com/oklog/ulid/v2 v2.0.2 h1:r4fFzBm+bv0wNKNh5eXTwU7i85y5x+uwkxCUTNVQqLc=\ngithub.com/oklog/ulid/v2 v2.0.2/go.mod h1:mtBL0Qe/0HAx6/a4Z30qxVIAL1eQDweXq5lxOEiwQ68=\ngithub.com/olekukonko/tablewriter v0.0.5 h1:P2Ga83D34wi1o9J6Wh1mRuqd4mF/x/lgBS7N7AbDhec=\ngithub.com/olekukonko/tablewriter v0.0.5/go.mod h1:hPp6KlRPjbx+hW8ykQs1w3UBbZlj6HuIJcUGPhkA7kY=\ngithub.com/pkg/diff v0.0.0-20210226163009-20ebb0f2a09e/go.mod h1:pJLUxLENpZxwdsKMEsNbx1VGcRFpLqf3715MtcvvzbA=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/posener/complete v1.1.1/go.mod h1:em0nMJCgc9GFtwrmVmEMR/ZL6WyhyjMBndrE9hABlRI=\ngithub.com/posener/complete v1.2.3 h1:NP0eAhjcjImqslEwo/1hq7gpajME0fTLTezBKDqfXqo=\ngithub.com/posener/complete v1.2.3/go.mod h1:WZIdtGGp+qx0sLrYKtIRAruyNpv6hFCicSgv7Sy7s/s=\ngithub.com/poy/onpar v1.1.2 h1:QaNrNiZx0+Nar5dLgTVp5mXkyoVFIbepjyEoGSnhbAY=\ngithub.com/poy/onpar v1.1.2/go.mod h1:6X8FLNoxyr9kkmnlqpK6LSoiOtrO6MICtWwEuWkLjzg=\ngithub.com/rogpeppe/go-internal v1.9.0 h1:73kH8U+JUqXU8lRuOHeVHaa/SZPifC7BkcraZVejAe8=\ngithub.com/rogpeppe/go-internal v1.9.0/go.mod h1:WtVeX8xhTBvf0smdhujwtBcq4Qrzq/fJaraNFVN+nFs=\ngithub.com/shopspring/decimal v1.2.0/go.mod h1:DKyhrW/HYNuLGql+MJL6WCR6knT2jwCFRcu2hWCYk4o=\ngithub.com/shopspring/decimal v1.3.1 h1:2Usl1nmF/WZucqkFZhnfFYxxxu8LG21F6nPQBE5gKV8=\ngithub.com/shopspring/decimal v1.3.1/go.mod h1:DKyhrW/HYNuLGql+MJL6WCR6knT2jwCFRcu2hWCYk4o=\ngithub.com/spf13/cast v1.3.1/go.mod h1:Qx5cxh0v+4UWYiBimWS+eyWzqEqokIECu5etghLkUJE=\ngithub.com/spf13/cast v1.5.0 h1:rj3WzYc11XZaIZMPKmwP96zkFEnnAmV8s6XbB2aY32w=\ngithub.com/spf13/cast v1.5.0/go.mod h1:SpXXQ5YoyJw6s3/6cMTQuxvgRl3PCJiyaX9p6b155UU=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/testify v1.2.2/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=\ngithub.com/stretchr/testify v1.4.0/go.mod h1:j7eGeouHqKxXV5pUuKE4zz7dFj8WfuZ+81PSLYec5m4=\ngithub.com/stretchr/testify v1.5.1/go.mod h1:5W2xD1RspED5o8YsWQXVCued0rvSQ+mT+I5cxcmMvtA=\ngithub.com/stretchr/testify v1.6.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.8.0 h1:pSgiaMZlXftHpm5L7V1+rVB+AZJydKsMxsQBIJw4PKk=\ngithub.com/stretchr/testify v1.8.0/go.mod h1:yNjHg4UonilssWZ8iaSj1OCr/vHnekPRkoO+kdMU+MU=\ngithub.com/yuin/goldmark v1.4.13/go.mod h1:6yULJ656Px+3vBD8DxQVa3kxgyrAnzto9xy5taEt/CY=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20190325154230-a5d413f7728c/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20200414173820-0848c9571904/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/crypto v0.0.0-20200820211705-5c72a883971a/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/crypto v0.0.0-20210921155107-089bfa567519/go.mod h1:GvvjBRRGRdwPK5ydBHafDWAxML/pGHZbMvKqRZ5+Abc=\ngolang.org/x/crypto v0.3.0/go.mod h1:hebNnKkNXi2UzZN1eVRvBB7co0a+JxK6XbPiWVs/3J4=\ngolang.org/x/crypto v0.31.0 h1:ihbySMvVjLAeSH1IbfcRTkD/iNscyz8rGzjF/E5hV6U=\ngolang.org/x/crypto v0.31.0/go.mod h1:kDsLvtWBEx7MV9tJOj9bnXsPbxwJQ6csT/x4KIN4Ssk=\ngolang.org/x/exp v0.0.0-20230905200255-921286631fa9 h1:GoHiUyI/Tp2nVkLI2mCxVkOjsbSXD66ic0XW0js0R9g=\ngolang.org/x/exp v0.0.0-20230905200255-921286631fa9/go.mod h1:S2oDrQGGwySpoQPVqRShND87VCbxmc6bL1Yd2oYrm6k=\ngolang.org/x/mod v0.6.0-dev.0.20220419223038-86c51ed26bb4/go.mod h1:jJ57K6gSWd91VN4djpZkiMVwK6gcyfeH4XE8wZrZaV4=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20210226172049-e18ecbb05110/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=\ngolang.org/x/net v0.0.0-20220722155237-a158d28d115b/go.mod h1:XRhObCWvk6IyKnWLug+ECip1KBveYUHfp+8e9klMJ9c=\ngolang.org/x/net v0.2.0/go.mod h1:KqCZLdyyvdV855qA2rE3GC2aiw5xGR5TEjj8smXukLY=\ngolang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20220722155255-886fb9371eb4 h1:uVc8UZUe6tr40fFVnUP5Oj+veunVezqYl9z7DYw9xzw=\ngolang.org/x/sync v0.0.0-20220722155255-886fb9371eb4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200116001909-b77594299b42/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200223170610-d5e6a3e2c0ae/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210615035016-665e8c7367d1/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20210630005230-0f9fa26af87c/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220520151302-bc2c85ada10a/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220722155257-8c9f86f7a55f/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220811171246-fbc7d0a398ab/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.2.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.28.0 h1:Fksou7UEQUWlKvIdsqzJmUmCX3cZuD2+P3XyyzwMhlA=\ngolang.org/x/sys v0.28.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=\ngolang.org/x/term v0.0.0-20210927222741-03fcf44c2211/go.mod h1:jbD1KX2456YbFQfuXm/mYQcufACuNUgVhRMnK/tPxf8=\ngolang.org/x/term v0.2.0/go.mod h1:TVmDHMZPmdnySmBfhjOoOdhjzdE1h4u1VwSiw2l1Nuc=\ngolang.org/x/term v0.27.0 h1:WP60Sv1nlK1T6SupCHbXzSaN0b9wUmsPoRS9b61A23Q=\ngolang.org/x/term v0.27.0/go.mod h1:iMsnZpn0cago0GOrHO2+Y7u7JPn5AylBrcoWkElMTSM=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.7/go.mod h1:u+2+/6zg+i71rQMx5EYifcz6MCKuco9NR6JIITiCfzQ=\ngolang.org/x/text v0.4.0/go.mod h1:mrYo+phRRbMaCq/xk9113O4dZlRixOauAjOtrjsXDZ8=\ngolang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.1.12/go.mod h1:hNGJHUnrk76NpqgfD5Aqm5Crs+Hm0VOH/i9J2+nxYbc=\ngolang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngoogle.golang.org/protobuf v1.33.0 h1:uNO2rsAINq/JlFpSdYEKIZ0uKD/R9cpdv0T+yoGwGmI=\ngoogle.golang.org/protobuf v1.33.0/go.mod h1:c6P6GXX6sHbq/GpV6MGZEdwhWPcYBgnhAHhKbcUYpos=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c h1:Hei/4ADfdWqJk1ZMxUNpqntNwaWcugrBjAiHlqqRiVk=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c/go.mod h1:JHkPIbrfpd72SG/EVd6muEfDQjcINNoR0C8j2r3qZ4Q=\ngopkg.in/yaml.v2 v2.2.2/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.3.0/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.4.0 h1:D8xgwECY7CYvx+Y2n4sBz93Jn9JRvxdiyyo8CTfuKaY=\ngopkg.in/yaml.v2 v2.4.0/go.mod h1:RDklbk79AGWmwhnvt/jBztapEOGDOx6ZbXqjP6csGnQ=\ngopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.0/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\n"
        },
        {
          "name": "init_test.go",
          "type": "blob",
          "size": 0.140625,
          "content": "package migrate\n\nimport (\n\t\"testing\"\n\n\t//revive:disable-next-line:dot-imports\n\t. \"gopkg.in/check.v1\"\n)\n\nfunc Test(t *testing.T) { TestingT(t) }\n"
        },
        {
          "name": "migrate.go",
          "type": "blob",
          "size": 24.279296875,
          "content": "package migrate\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"database/sql\"\n\t\"embed\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"os\"\n\t\"path\"\n\t\"regexp\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/go-gorp/gorp/v3\"\n\n\t\"github.com/rubenv/sql-migrate/sqlparse\"\n)\n\ntype MigrationDirection int\n\nconst (\n\tUp MigrationDirection = iota\n\tDown\n)\n\n// MigrationSet provides database parameters for a migration execution\ntype MigrationSet struct {\n\t// TableName name of the table used to store migration info.\n\tTableName string\n\t// SchemaName schema that the migration table be referenced.\n\tSchemaName string\n\t// IgnoreUnknown skips the check to see if there is a migration\n\t// ran in the database that is not in MigrationSource.\n\t//\n\t// This should be used sparingly as it is removing a safety check.\n\tIgnoreUnknown bool\n\t// DisableCreateTable disable the creation of the migration table\n\tDisableCreateTable bool\n}\n\nvar migSet = MigrationSet{}\n\n// NewMigrationSet returns a parametrized Migration object\nfunc (ms MigrationSet) getTableName() string {\n\tif ms.TableName == \"\" {\n\t\treturn \"gorp_migrations\"\n\t}\n\treturn ms.TableName\n}\n\nvar numberPrefixRegex = regexp.MustCompile(`^(\\d+).*$`)\n\n// PlanError happens where no migration plan could be created between the sets\n// of already applied migrations and the currently found. For example, when the database\n// contains a migration which is not among the migrations list found for an operation.\ntype PlanError struct {\n\tMigration    *Migration\n\tErrorMessage string\n}\n\nfunc newPlanError(migration *Migration, errorMessage string) error {\n\treturn &PlanError{\n\t\tMigration:    migration,\n\t\tErrorMessage: errorMessage,\n\t}\n}\n\nfunc (p *PlanError) Error() string {\n\treturn fmt.Sprintf(\"Unable to create migration plan because of %s: %s\",\n\t\tp.Migration.Id, p.ErrorMessage)\n}\n\n// TxError is returned when any error is encountered during a database\n// transaction. It contains the relevant *Migration and notes it's Id in the\n// Error function output.\ntype TxError struct {\n\tMigration *Migration\n\tErr       error\n}\n\nfunc newTxError(migration *PlannedMigration, err error) error {\n\treturn &TxError{\n\t\tMigration: migration.Migration,\n\t\tErr:       err,\n\t}\n}\n\nfunc (e *TxError) Error() string {\n\treturn e.Err.Error() + \" handling \" + e.Migration.Id\n}\n\n// Set the name of the table used to store migration info.\n//\n// Should be called before any other call such as (Exec, ExecMax, ...).\nfunc SetTable(name string) {\n\tif name != \"\" {\n\t\tmigSet.TableName = name\n\t}\n}\n\n// SetSchema sets the name of a schema that the migration table be referenced.\nfunc SetSchema(name string) {\n\tif name != \"\" {\n\t\tmigSet.SchemaName = name\n\t}\n}\n\n// SetDisableCreateTable sets the boolean to disable the creation of the migration table\nfunc SetDisableCreateTable(disable bool) {\n\tmigSet.DisableCreateTable = disable\n}\n\n// SetIgnoreUnknown sets the flag that skips database check to see if there is a\n// migration in the database that is not in migration source.\n//\n// This should be used sparingly as it is removing a safety check.\nfunc SetIgnoreUnknown(v bool) {\n\tmigSet.IgnoreUnknown = v\n}\n\ntype Migration struct {\n\tId   string\n\tUp   []string\n\tDown []string\n\n\tDisableTransactionUp   bool\n\tDisableTransactionDown bool\n}\n\nfunc (m Migration) Less(other *Migration) bool {\n\tswitch {\n\tcase m.isNumeric() && other.isNumeric() && m.VersionInt() != other.VersionInt():\n\t\treturn m.VersionInt() < other.VersionInt()\n\tcase m.isNumeric() && !other.isNumeric():\n\t\treturn true\n\tcase !m.isNumeric() && other.isNumeric():\n\t\treturn false\n\tdefault:\n\t\treturn m.Id < other.Id\n\t}\n}\n\nfunc (m Migration) isNumeric() bool {\n\treturn len(m.NumberPrefixMatches()) > 0\n}\n\nfunc (m Migration) NumberPrefixMatches() []string {\n\treturn numberPrefixRegex.FindStringSubmatch(m.Id)\n}\n\nfunc (m Migration) VersionInt() int64 {\n\tv := m.NumberPrefixMatches()[1]\n\tvalue, err := strconv.ParseInt(v, 10, 64)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"Could not parse %q into int64: %s\", v, err))\n\t}\n\treturn value\n}\n\ntype PlannedMigration struct {\n\t*Migration\n\n\tDisableTransaction bool\n\tQueries            []string\n}\n\ntype byId []*Migration\n\nfunc (b byId) Len() int           { return len(b) }\nfunc (b byId) Swap(i, j int)      { b[i], b[j] = b[j], b[i] }\nfunc (b byId) Less(i, j int) bool { return b[i].Less(b[j]) }\n\ntype MigrationRecord struct {\n\tId        string    `db:\"id\"`\n\tAppliedAt time.Time `db:\"applied_at\"`\n}\n\ntype OracleDialect struct {\n\tgorp.OracleDialect\n}\n\nfunc (OracleDialect) IfTableNotExists(command, _, _ string) string {\n\treturn command\n}\n\nfunc (OracleDialect) IfSchemaNotExists(command, _ string) string {\n\treturn command\n}\n\nfunc (OracleDialect) IfTableExists(command, _, _ string) string {\n\treturn command\n}\n\nvar MigrationDialects = map[string]gorp.Dialect{\n\t\"sqlite3\":   gorp.SqliteDialect{},\n\t\"postgres\":  gorp.PostgresDialect{},\n\t\"mysql\":     gorp.MySQLDialect{Engine: \"InnoDB\", Encoding: \"UTF8\"},\n\t\"mssql\":     gorp.SqlServerDialect{},\n\t\"oci8\":      OracleDialect{},\n\t\"godror\":    OracleDialect{},\n\t\"snowflake\": gorp.SnowflakeDialect{},\n}\n\ntype MigrationSource interface {\n\t// Finds the migrations.\n\t//\n\t// The resulting slice of migrations should be sorted by Id.\n\tFindMigrations() ([]*Migration, error)\n}\n\n// A hardcoded set of migrations, in-memory.\ntype MemoryMigrationSource struct {\n\tMigrations []*Migration\n}\n\nvar _ MigrationSource = (*MemoryMigrationSource)(nil)\n\nfunc (m MemoryMigrationSource) FindMigrations() ([]*Migration, error) {\n\t// Make sure migrations are sorted. In order to make the MemoryMigrationSource safe for\n\t// concurrent use we should not mutate it in place. So `FindMigrations` would sort a copy\n\t// of the m.Migrations.\n\tmigrations := make([]*Migration, len(m.Migrations))\n\tcopy(migrations, m.Migrations)\n\tsort.Sort(byId(migrations))\n\treturn migrations, nil\n}\n\n// A set of migrations loaded from an http.FileServer\n\ntype HttpFileSystemMigrationSource struct {\n\tFileSystem http.FileSystem\n}\n\nvar _ MigrationSource = (*HttpFileSystemMigrationSource)(nil)\n\nfunc (f HttpFileSystemMigrationSource) FindMigrations() ([]*Migration, error) {\n\treturn findMigrations(f.FileSystem, \"/\")\n}\n\n// A set of migrations loaded from a directory.\ntype FileMigrationSource struct {\n\tDir string\n}\n\nvar _ MigrationSource = (*FileMigrationSource)(nil)\n\nfunc (f FileMigrationSource) FindMigrations() ([]*Migration, error) {\n\tfilesystem := http.Dir(f.Dir)\n\treturn findMigrations(filesystem, \"/\")\n}\n\nfunc findMigrations(dir http.FileSystem, root string) ([]*Migration, error) {\n\tmigrations := make([]*Migration, 0)\n\n\tfile, err := dir.Open(root)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfiles, err := file.Readdir(0)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, info := range files {\n\t\tif strings.HasSuffix(info.Name(), \".sql\") {\n\t\t\tmigration, err := migrationFromFile(dir, root, info)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tmigrations = append(migrations, migration)\n\t\t}\n\t}\n\n\t// Make sure migrations are sorted\n\tsort.Sort(byId(migrations))\n\n\treturn migrations, nil\n}\n\nfunc migrationFromFile(dir http.FileSystem, root string, info os.FileInfo) (*Migration, error) {\n\tpath := path.Join(root, info.Name())\n\tfile, err := dir.Open(path)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Error while opening %s: %w\", info.Name(), err)\n\t}\n\tdefer func() { _ = file.Close() }()\n\n\tmigration, err := ParseMigration(info.Name(), file)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Error while parsing %s: %w\", info.Name(), err)\n\t}\n\treturn migration, nil\n}\n\n// Migrations from a bindata asset set.\ntype AssetMigrationSource struct {\n\t// Asset should return content of file in path if exists\n\tAsset func(path string) ([]byte, error)\n\n\t// AssetDir should return list of files in the path\n\tAssetDir func(path string) ([]string, error)\n\n\t// Path in the bindata to use.\n\tDir string\n}\n\nvar _ MigrationSource = (*AssetMigrationSource)(nil)\n\nfunc (a AssetMigrationSource) FindMigrations() ([]*Migration, error) {\n\tmigrations := make([]*Migration, 0)\n\n\tfiles, err := a.AssetDir(a.Dir)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, name := range files {\n\t\tif strings.HasSuffix(name, \".sql\") {\n\t\t\tfile, err := a.Asset(path.Join(a.Dir, name))\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tmigration, err := ParseMigration(name, bytes.NewReader(file))\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tmigrations = append(migrations, migration)\n\t\t}\n\t}\n\n\t// Make sure migrations are sorted\n\tsort.Sort(byId(migrations))\n\n\treturn migrations, nil\n}\n\n// A set of migrations loaded from an go1.16 embed.FS\ntype EmbedFileSystemMigrationSource struct {\n\tFileSystem embed.FS\n\n\tRoot string\n}\n\nvar _ MigrationSource = (*EmbedFileSystemMigrationSource)(nil)\n\nfunc (f EmbedFileSystemMigrationSource) FindMigrations() ([]*Migration, error) {\n\treturn findMigrations(http.FS(f.FileSystem), f.Root)\n}\n\n// Avoids pulling in the packr library for everyone, mimicks the bits of\n// packr.Box that we need.\ntype PackrBox interface {\n\tList() []string\n\tFind(name string) ([]byte, error)\n}\n\n// Migrations from a packr box.\ntype PackrMigrationSource struct {\n\tBox PackrBox\n\n\t// Path in the box to use.\n\tDir string\n}\n\nvar _ MigrationSource = (*PackrMigrationSource)(nil)\n\nfunc (p PackrMigrationSource) FindMigrations() ([]*Migration, error) {\n\tmigrations := make([]*Migration, 0)\n\titems := p.Box.List()\n\n\tprefix := \"\"\n\tdir := path.Clean(p.Dir)\n\tif dir != \".\" {\n\t\tprefix = fmt.Sprintf(\"%s/\", dir)\n\t}\n\n\tfor _, item := range items {\n\t\tif !strings.HasPrefix(item, prefix) {\n\t\t\tcontinue\n\t\t}\n\t\tname := strings.TrimPrefix(item, prefix)\n\t\tif strings.Contains(name, \"/\") {\n\t\t\tcontinue\n\t\t}\n\n\t\tif strings.HasSuffix(name, \".sql\") {\n\t\t\tfile, err := p.Box.Find(item)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tmigration, err := ParseMigration(name, bytes.NewReader(file))\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tmigrations = append(migrations, migration)\n\t\t}\n\t}\n\n\t// Make sure migrations are sorted\n\tsort.Sort(byId(migrations))\n\n\treturn migrations, nil\n}\n\n// Migration parsing\nfunc ParseMigration(id string, r io.ReadSeeker) (*Migration, error) {\n\tm := &Migration{\n\t\tId: id,\n\t}\n\n\tparsed, err := sqlparse.ParseMigration(r)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Error parsing migration (%s): %w\", id, err)\n\t}\n\n\tm.Up = parsed.UpStatements\n\tm.Down = parsed.DownStatements\n\n\tm.DisableTransactionUp = parsed.DisableTransactionUp\n\tm.DisableTransactionDown = parsed.DisableTransactionDown\n\n\treturn m, nil\n}\n\ntype SqlExecutor interface {\n\tExec(query string, args ...interface{}) (sql.Result, error)\n\tInsert(list ...interface{}) error\n\tDelete(list ...interface{}) (int64, error)\n}\n\n// Execute a set of migrations\n//\n// Returns the number of applied migrations.\nfunc Exec(db *sql.DB, dialect string, m MigrationSource, dir MigrationDirection) (int, error) {\n\treturn ExecMaxContext(context.Background(), db, dialect, m, dir, 0)\n}\n\n// Returns the number of applied migrations.\nfunc (ms MigrationSet) Exec(db *sql.DB, dialect string, m MigrationSource, dir MigrationDirection) (int, error) {\n\treturn ms.ExecMaxContext(context.Background(), db, dialect, m, dir, 0)\n}\n\n// Execute a set of migrations with an input context.\n//\n// Returns the number of applied migrations.\nfunc ExecContext(ctx context.Context, db *sql.DB, dialect string, m MigrationSource, dir MigrationDirection) (int, error) {\n\treturn ExecMaxContext(ctx, db, dialect, m, dir, 0)\n}\n\n// Returns the number of applied migrations.\nfunc (ms MigrationSet) ExecContext(ctx context.Context, db *sql.DB, dialect string, m MigrationSource, dir MigrationDirection) (int, error) {\n\treturn ms.ExecMaxContext(ctx, db, dialect, m, dir, 0)\n}\n\n// Execute a set of migrations\n//\n// Will apply at most `max` migrations. Pass 0 for no limit (or use Exec).\n//\n// Returns the number of applied migrations.\nfunc ExecMax(db *sql.DB, dialect string, m MigrationSource, dir MigrationDirection, max int) (int, error) {\n\treturn migSet.ExecMax(db, dialect, m, dir, max)\n}\n\n// Execute a set of migrations with an input context.\n//\n// Will apply at most `max` migrations. Pass 0 for no limit (or use Exec).\n//\n// Returns the number of applied migrations.\nfunc ExecMaxContext(ctx context.Context, db *sql.DB, dialect string, m MigrationSource, dir MigrationDirection, max int) (int, error) {\n\treturn migSet.ExecMaxContext(ctx, db, dialect, m, dir, max)\n}\n\n// Execute a set of migrations\n//\n// Will apply at the target `version` of migration. Cannot be a negative value.\n//\n// Returns the number of applied migrations.\nfunc ExecVersion(db *sql.DB, dialect string, m MigrationSource, dir MigrationDirection, version int64) (int, error) {\n\treturn ExecVersionContext(context.Background(), db, dialect, m, dir, version)\n}\n\n// Execute a set of migrations with an input context.\n//\n// Will apply at the target `version` of migration. Cannot be a negative value.\n//\n// Returns the number of applied migrations.\nfunc ExecVersionContext(ctx context.Context, db *sql.DB, dialect string, m MigrationSource, dir MigrationDirection, version int64) (int, error) {\n\tif version < 0 {\n\t\treturn 0, fmt.Errorf(\"target version %d should not be negative\", version)\n\t}\n\treturn migSet.ExecVersionContext(ctx, db, dialect, m, dir, version)\n}\n\n// Returns the number of applied migrations.\nfunc (ms MigrationSet) ExecMax(db *sql.DB, dialect string, m MigrationSource, dir MigrationDirection, max int) (int, error) {\n\treturn ms.ExecMaxContext(context.Background(), db, dialect, m, dir, max)\n}\n\n// Returns the number of applied migrations, but applies with an input context.\nfunc (ms MigrationSet) ExecMaxContext(ctx context.Context, db *sql.DB, dialect string, m MigrationSource, dir MigrationDirection, max int) (int, error) {\n\tmigrations, dbMap, err := ms.PlanMigration(db, dialect, m, dir, max)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\treturn ms.applyMigrations(ctx, dir, migrations, dbMap)\n}\n\n// Returns the number of applied migrations.\nfunc (ms MigrationSet) ExecVersion(db *sql.DB, dialect string, m MigrationSource, dir MigrationDirection, version int64) (int, error) {\n\treturn ms.ExecVersionContext(context.Background(), db, dialect, m, dir, version)\n}\n\nfunc (ms MigrationSet) ExecVersionContext(ctx context.Context, db *sql.DB, dialect string, m MigrationSource, dir MigrationDirection, version int64) (int, error) {\n\tmigrations, dbMap, err := ms.PlanMigrationToVersion(db, dialect, m, dir, version)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\treturn ms.applyMigrations(ctx, dir, migrations, dbMap)\n}\n\n// Applies the planned migrations and returns the number of applied migrations.\nfunc (MigrationSet) applyMigrations(ctx context.Context, dir MigrationDirection, migrations []*PlannedMigration, dbMap *gorp.DbMap) (int, error) {\n\tapplied := 0\n\tfor _, migration := range migrations {\n\t\tvar executor SqlExecutor\n\t\tvar err error\n\n\t\tif migration.DisableTransaction {\n\t\t\texecutor = dbMap.WithContext(ctx)\n\t\t} else {\n\t\t\te, err := dbMap.Begin()\n\t\t\tif err != nil {\n\t\t\t\treturn applied, newTxError(migration, err)\n\t\t\t}\n\t\t\texecutor = e.WithContext(ctx)\n\t\t}\n\n\t\tfor _, stmt := range migration.Queries {\n\t\t\t// remove the semicolon from stmt, fix ORA-00922 issue in database oracle\n\t\t\tstmt = strings.TrimSuffix(stmt, \"\\n\")\n\t\t\tstmt = strings.TrimSuffix(stmt, \" \")\n\t\t\tstmt = strings.TrimSuffix(stmt, \";\")\n\t\t\tif _, err := executor.Exec(stmt); err != nil {\n\t\t\t\tif trans, ok := executor.(*gorp.Transaction); ok {\n\t\t\t\t\t_ = trans.Rollback()\n\t\t\t\t}\n\n\t\t\t\treturn applied, newTxError(migration, err)\n\t\t\t}\n\t\t}\n\n\t\tswitch dir {\n\t\tcase Up:\n\t\t\terr = executor.Insert(&MigrationRecord{\n\t\t\t\tId:        migration.Id,\n\t\t\t\tAppliedAt: time.Now(),\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\tif trans, ok := executor.(*gorp.Transaction); ok {\n\t\t\t\t\t_ = trans.Rollback()\n\t\t\t\t}\n\n\t\t\t\treturn applied, newTxError(migration, err)\n\t\t\t}\n\t\tcase Down:\n\t\t\t_, err := executor.Delete(&MigrationRecord{\n\t\t\t\tId: migration.Id,\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\tif trans, ok := executor.(*gorp.Transaction); ok {\n\t\t\t\t\t_ = trans.Rollback()\n\t\t\t\t}\n\n\t\t\t\treturn applied, newTxError(migration, err)\n\t\t\t}\n\t\tdefault:\n\t\t\tpanic(\"Not possible\")\n\t\t}\n\n\t\tif trans, ok := executor.(*gorp.Transaction); ok {\n\t\t\tif err := trans.Commit(); err != nil {\n\t\t\t\treturn applied, newTxError(migration, err)\n\t\t\t}\n\t\t}\n\n\t\tapplied++\n\t}\n\n\treturn applied, nil\n}\n\n// Plan a migration.\nfunc PlanMigration(db *sql.DB, dialect string, m MigrationSource, dir MigrationDirection, max int) ([]*PlannedMigration, *gorp.DbMap, error) {\n\treturn migSet.PlanMigration(db, dialect, m, dir, max)\n}\n\n// Plan a migration to version.\nfunc PlanMigrationToVersion(db *sql.DB, dialect string, m MigrationSource, dir MigrationDirection, version int64) ([]*PlannedMigration, *gorp.DbMap, error) {\n\treturn migSet.PlanMigrationToVersion(db, dialect, m, dir, version)\n}\n\n// Plan a migration.\nfunc (ms MigrationSet) PlanMigration(db *sql.DB, dialect string, m MigrationSource, dir MigrationDirection, max int) ([]*PlannedMigration, *gorp.DbMap, error) {\n\treturn ms.planMigrationCommon(db, dialect, m, dir, max, -1)\n}\n\n// Plan a migration to version.\nfunc (ms MigrationSet) PlanMigrationToVersion(db *sql.DB, dialect string, m MigrationSource, dir MigrationDirection, version int64) ([]*PlannedMigration, *gorp.DbMap, error) {\n\treturn ms.planMigrationCommon(db, dialect, m, dir, 0, version)\n}\n\n// A common method to plan a migration.\nfunc (ms MigrationSet) planMigrationCommon(db *sql.DB, dialect string, m MigrationSource, dir MigrationDirection, max int, version int64) ([]*PlannedMigration, *gorp.DbMap, error) {\n\tdbMap, err := ms.getMigrationDbMap(db, dialect)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tmigrations, err := m.FindMigrations()\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tvar migrationRecords []MigrationRecord\n\t_, err = dbMap.Select(&migrationRecords, fmt.Sprintf(\"SELECT * FROM %s\", dbMap.Dialect.QuotedTableForQuery(ms.SchemaName, ms.getTableName())))\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Sort migrations that have been run by Id.\n\tvar existingMigrations []*Migration\n\tfor _, migrationRecord := range migrationRecords {\n\t\texistingMigrations = append(existingMigrations, &Migration{\n\t\t\tId: migrationRecord.Id,\n\t\t})\n\t}\n\tsort.Sort(byId(existingMigrations))\n\n\t// Make sure all migrations in the database are among the found migrations which\n\t// are to be applied.\n\tif !ms.IgnoreUnknown {\n\t\tmigrationsSearch := make(map[string]struct{})\n\t\tfor _, migration := range migrations {\n\t\t\tmigrationsSearch[migration.Id] = struct{}{}\n\t\t}\n\t\tfor _, existingMigration := range existingMigrations {\n\t\t\tif _, ok := migrationsSearch[existingMigration.Id]; !ok {\n\t\t\t\treturn nil, nil, newPlanError(existingMigration, \"unknown migration in database\")\n\t\t\t}\n\t\t}\n\t}\n\n\t// Get last migration that was run\n\trecord := &Migration{}\n\tif len(existingMigrations) > 0 {\n\t\trecord = existingMigrations[len(existingMigrations)-1]\n\t}\n\n\tresult := make([]*PlannedMigration, 0)\n\n\t// Add missing migrations up to the last run migration.\n\t// This can happen for example when merges happened.\n\tif len(existingMigrations) > 0 {\n\t\tresult = append(result, ToCatchup(migrations, existingMigrations, record)...)\n\t}\n\n\t// Figure out which migrations to apply\n\ttoApply := ToApply(migrations, record.Id, dir)\n\ttoApplyCount := len(toApply)\n\n\tif version >= 0 {\n\t\ttargetIndex := 0\n\t\tfor targetIndex < len(toApply) {\n\t\t\ttempVersion := toApply[targetIndex].VersionInt()\n\t\t\tif dir == Up && tempVersion > version || dir == Down && tempVersion < version {\n\t\t\t\treturn nil, nil, newPlanError(&Migration{}, fmt.Errorf(\"unknown migration with version id %d in database\", version).Error())\n\t\t\t}\n\t\t\tif tempVersion == version {\n\t\t\t\ttoApplyCount = targetIndex + 1\n\t\t\t\tbreak\n\t\t\t}\n\t\t\ttargetIndex++\n\t\t}\n\t\tif targetIndex == len(toApply) {\n\t\t\treturn nil, nil, newPlanError(&Migration{}, fmt.Errorf(\"unknown migration with version id %d in database\", version).Error())\n\t\t}\n\t} else if max > 0 && max < toApplyCount {\n\t\ttoApplyCount = max\n\t}\n\tfor _, v := range toApply[0:toApplyCount] {\n\t\tif dir == Up {\n\t\t\tresult = append(result, &PlannedMigration{\n\t\t\t\tMigration:          v,\n\t\t\t\tQueries:            v.Up,\n\t\t\t\tDisableTransaction: v.DisableTransactionUp,\n\t\t\t})\n\t\t} else if dir == Down {\n\t\t\tresult = append(result, &PlannedMigration{\n\t\t\t\tMigration:          v,\n\t\t\t\tQueries:            v.Down,\n\t\t\t\tDisableTransaction: v.DisableTransactionDown,\n\t\t\t})\n\t\t}\n\t}\n\n\treturn result, dbMap, nil\n}\n\n// Skip a set of migrations\n//\n// Will skip at most `max` migrations. Pass 0 for no limit.\n//\n// Returns the number of skipped migrations.\nfunc SkipMax(db *sql.DB, dialect string, m MigrationSource, dir MigrationDirection, max int) (int, error) {\n\tmigrations, dbMap, err := PlanMigration(db, dialect, m, dir, max)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\t// Skip migrations\n\tapplied := 0\n\tfor _, migration := range migrations {\n\t\tvar executor SqlExecutor\n\n\t\tif migration.DisableTransaction {\n\t\t\texecutor = dbMap\n\t\t} else {\n\t\t\texecutor, err = dbMap.Begin()\n\t\t\tif err != nil {\n\t\t\t\treturn applied, newTxError(migration, err)\n\t\t\t}\n\t\t}\n\n\t\terr = executor.Insert(&MigrationRecord{\n\t\t\tId:        migration.Id,\n\t\t\tAppliedAt: time.Now(),\n\t\t})\n\t\tif err != nil {\n\t\t\tif trans, ok := executor.(*gorp.Transaction); ok {\n\t\t\t\t_ = trans.Rollback()\n\t\t\t}\n\n\t\t\treturn applied, newTxError(migration, err)\n\t\t}\n\n\t\tif trans, ok := executor.(*gorp.Transaction); ok {\n\t\t\tif err := trans.Commit(); err != nil {\n\t\t\t\treturn applied, newTxError(migration, err)\n\t\t\t}\n\t\t}\n\n\t\tapplied++\n\t}\n\n\treturn applied, nil\n}\n\n// Filter a slice of migrations into ones that should be applied.\nfunc ToApply(migrations []*Migration, current string, direction MigrationDirection) []*Migration {\n\tindex := -1\n\tif current != \"\" {\n\t\tfor index < len(migrations)-1 {\n\t\t\tindex++\n\t\t\tif migrations[index].Id == current {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\tif direction == Up {\n\t\treturn migrations[index+1:]\n\t} else if direction == Down {\n\t\tif index == -1 {\n\t\t\treturn []*Migration{}\n\t\t}\n\n\t\t// Add in reverse order\n\t\ttoApply := make([]*Migration, index+1)\n\t\tfor i := 0; i < index+1; i++ {\n\t\t\ttoApply[index-i] = migrations[i]\n\t\t}\n\t\treturn toApply\n\t}\n\n\tpanic(\"Not possible\")\n}\n\nfunc ToCatchup(migrations, existingMigrations []*Migration, lastRun *Migration) []*PlannedMigration {\n\tmissing := make([]*PlannedMigration, 0)\n\tfor _, migration := range migrations {\n\t\tfound := false\n\t\tfor _, existing := range existingMigrations {\n\t\t\tif existing.Id == migration.Id {\n\t\t\t\tfound = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif !found && migration.Less(lastRun) {\n\t\t\tmissing = append(missing, &PlannedMigration{\n\t\t\t\tMigration:          migration,\n\t\t\t\tQueries:            migration.Up,\n\t\t\t\tDisableTransaction: migration.DisableTransactionUp,\n\t\t\t})\n\t\t}\n\t}\n\treturn missing\n}\n\nfunc GetMigrationRecords(db *sql.DB, dialect string) ([]*MigrationRecord, error) {\n\treturn migSet.GetMigrationRecords(db, dialect)\n}\n\nfunc (ms MigrationSet) GetMigrationRecords(db *sql.DB, dialect string) ([]*MigrationRecord, error) {\n\tdbMap, err := ms.getMigrationDbMap(db, dialect)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar records []*MigrationRecord\n\tquery := fmt.Sprintf(\"SELECT * FROM %s ORDER BY %s ASC\", dbMap.Dialect.QuotedTableForQuery(ms.SchemaName, ms.getTableName()), dbMap.Dialect.QuoteField(\"id\"))\n\t_, err = dbMap.Select(&records, query)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn records, nil\n}\n\nfunc (ms MigrationSet) getMigrationDbMap(db *sql.DB, dialect string) (*gorp.DbMap, error) {\n\td, ok := MigrationDialects[dialect]\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"Unknown dialect: %s\", dialect)\n\t}\n\n\t// When using the mysql driver, make sure that the parseTime option is\n\t// configured, otherwise it won't map time columns to time.Time. See\n\t// https://github.com/rubenv/sql-migrate/issues/2\n\tif dialect == \"mysql\" {\n\t\tvar out *time.Time\n\t\terr := db.QueryRow(\"SELECT NOW()\").Scan(&out)\n\t\tif err != nil {\n\t\t\tif err.Error() == \"sql: Scan error on column index 0: unsupported driver -> Scan pair: []uint8 -> *time.Time\" ||\n\t\t\t\terr.Error() == \"sql: Scan error on column index 0: unsupported Scan, storing driver.Value type []uint8 into type *time.Time\" ||\n\t\t\t\terr.Error() == \"sql: Scan error on column index 0, name \\\"NOW()\\\": unsupported Scan, storing driver.Value type []uint8 into type *time.Time\" {\n\t\t\t\treturn nil, errors.New(`Cannot parse dates.\n\nMake sure that the parseTime option is supplied to your database connection.\nCheck https://github.com/go-sql-driver/mysql#parsetime for more info.`)\n\t\t\t}\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\t// Create migration database map\n\tdbMap := &gorp.DbMap{Db: db, Dialect: d}\n\ttable := dbMap.AddTableWithNameAndSchema(MigrationRecord{}, ms.SchemaName, ms.getTableName()).SetKeys(false, \"Id\")\n\n\tif dialect == \"oci8\" || dialect == \"godror\" {\n\t\ttable.ColMap(\"Id\").SetMaxSize(4000)\n\t}\n\n\tif ms.DisableCreateTable {\n\t\treturn dbMap, nil\n\t}\n\n\terr := dbMap.CreateTablesIfNotExists()\n\tif err != nil {\n\t\t// Oracle database does not support `if not exists`, so use `ORA-00955:` error code\n\t\t// to check if the table exists.\n\t\tif (dialect == \"oci8\" || dialect == \"godror\") && strings.Contains(err.Error(), \"ORA-00955:\") {\n\t\t\treturn dbMap, nil\n\t\t}\n\t\treturn nil, err\n\t}\n\n\treturn dbMap, nil\n}\n\n// TODO: Run migration + record insert in transaction.\n"
        },
        {
          "name": "migrate_test.go",
          "type": "blob",
          "size": 24.75,
          "content": "package migrate\n\nimport (\n\t\"context\"\n\t\"database/sql\"\n\t\"embed\"\n\t\"net/http\"\n\t\"time\"\n\n\t\"github.com/go-gorp/gorp/v3\"\n\t//revive:disable-next-line:dot-imports\n\t. \"gopkg.in/check.v1\"\n\n\t_ \"github.com/mattn/go-sqlite3\"\n)\n\nvar sqliteMigrations = []*Migration{\n\t{\n\t\tId:   \"123\",\n\t\tUp:   []string{\"CREATE TABLE people (id int)\"},\n\t\tDown: []string{\"DROP TABLE people\"},\n\t},\n\t{\n\t\tId:   \"124\",\n\t\tUp:   []string{\"ALTER TABLE people ADD COLUMN first_name text\"},\n\t\tDown: []string{\"SELECT 0\"}, // Not really supported\n\t},\n}\n\ntype SqliteMigrateSuite struct {\n\tDb    *sql.DB\n\tDbMap *gorp.DbMap\n}\n\nvar _ = Suite(&SqliteMigrateSuite{})\n\nfunc (s *SqliteMigrateSuite) SetUpTest(c *C) {\n\tvar err error\n\tdb, err := sql.Open(\"sqlite3\", \":memory:\")\n\tc.Assert(err, IsNil)\n\n\ts.Db = db\n\ts.DbMap = &gorp.DbMap{Db: db, Dialect: &gorp.SqliteDialect{}}\n}\n\nfunc (s *SqliteMigrateSuite) TestRunMigration(c *C) {\n\tmigrations := &MemoryMigrationSource{\n\t\tMigrations: sqliteMigrations[:1],\n\t}\n\n\t// Executes one migration\n\tn, err := Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 1)\n\n\t// Can use table now\n\t_, err = s.DbMap.Exec(\"SELECT * FROM people\")\n\tc.Assert(err, IsNil)\n\n\t// Shouldn't apply migration again\n\tn, err = Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 0)\n}\n\nfunc (s *SqliteMigrateSuite) TestRunMigrationEscapeTable(c *C) {\n\tmigrations := &MemoryMigrationSource{\n\t\tMigrations: sqliteMigrations[:1],\n\t}\n\n\tSetTable(`my migrations`)\n\n\t// Executes one migration\n\tn, err := Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 1)\n}\n\nfunc (s *SqliteMigrateSuite) TestMigrateMultiple(c *C) {\n\tmigrations := &MemoryMigrationSource{\n\t\tMigrations: sqliteMigrations[:2],\n\t}\n\n\t// Executes two migrations\n\tn, err := Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 2)\n\n\t// Can use column now\n\t_, err = s.DbMap.Exec(\"SELECT first_name FROM people\")\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *SqliteMigrateSuite) TestMigrateIncremental(c *C) {\n\tmigrations := &MemoryMigrationSource{\n\t\tMigrations: sqliteMigrations[:1],\n\t}\n\n\t// Executes one migration\n\tn, err := Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 1)\n\n\t// Execute a new migration\n\tmigrations = &MemoryMigrationSource{\n\t\tMigrations: sqliteMigrations[:2],\n\t}\n\tn, err = Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 1)\n\n\t// Can use column now\n\t_, err = s.DbMap.Exec(\"SELECT first_name FROM people\")\n\tc.Assert(err, IsNil)\n}\n\nfunc (s *SqliteMigrateSuite) TestFileMigrate(c *C) {\n\tmigrations := &FileMigrationSource{\n\t\tDir: \"test-migrations\",\n\t}\n\n\t// Executes two migrations\n\tn, err := Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 2)\n\n\t// Has data\n\tid, err := s.DbMap.SelectInt(\"SELECT id FROM people\")\n\tc.Assert(err, IsNil)\n\tc.Assert(id, Equals, int64(1))\n}\n\nfunc (s *SqliteMigrateSuite) TestHttpFileSystemMigrate(c *C) {\n\tmigrations := &HttpFileSystemMigrationSource{\n\t\tFileSystem: http.Dir(\"test-migrations\"),\n\t}\n\n\t// Executes two migrations\n\tn, err := Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 2)\n\n\t// Has data\n\tid, err := s.DbMap.SelectInt(\"SELECT id FROM people\")\n\tc.Assert(err, IsNil)\n\tc.Assert(id, Equals, int64(1))\n}\n\nfunc (s *SqliteMigrateSuite) TestAssetMigrate(c *C) {\n\tmigrations := &AssetMigrationSource{\n\t\tAsset:    Asset,\n\t\tAssetDir: AssetDir,\n\t\tDir:      \"test-migrations\",\n\t}\n\n\t// Executes two migrations\n\tn, err := Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 2)\n\n\t// Has data\n\tid, err := s.DbMap.SelectInt(\"SELECT id FROM people\")\n\tc.Assert(err, IsNil)\n\tc.Assert(id, Equals, int64(1))\n}\n\nfunc (s *SqliteMigrateSuite) TestMigrateMax(c *C) {\n\tmigrations := &FileMigrationSource{\n\t\tDir: \"test-migrations\",\n\t}\n\n\t// Executes one migration\n\tn, err := ExecMax(s.Db, \"sqlite3\", migrations, Up, 1)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 1)\n\n\tid, err := s.DbMap.SelectInt(\"SELECT COUNT(*) FROM people\")\n\tc.Assert(err, IsNil)\n\tc.Assert(id, Equals, int64(0))\n}\n\nfunc (s *SqliteMigrateSuite) TestMigrateVersionInt(c *C) {\n\tmigrations := &FileMigrationSource{\n\t\tDir: \"test-migrations\",\n\t}\n\n\t// Executes migration with target version 1\n\tn, err := ExecVersion(s.Db, \"sqlite3\", migrations, Up, 1)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 1)\n\n\tid, err := s.DbMap.SelectInt(\"SELECT COUNT(*) FROM people\")\n\tc.Assert(err, IsNil)\n\tc.Assert(id, Equals, int64(0))\n}\n\nfunc (s *SqliteMigrateSuite) TestMigrateVersionInt2(c *C) {\n\tmigrations := &FileMigrationSource{\n\t\tDir: \"test-migrations\",\n\t}\n\n\t// Executes migration with target version 2\n\tn, err := ExecVersion(s.Db, \"sqlite3\", migrations, Up, 2)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 2)\n\n\tid, err := s.DbMap.SelectInt(\"SELECT COUNT(*) FROM people\")\n\tc.Assert(err, IsNil)\n\tc.Assert(id, Equals, int64(1))\n}\n\nfunc (s *SqliteMigrateSuite) TestMigrateVersionIntFailedWithNotExistingVerion(c *C) {\n\tmigrations := &FileMigrationSource{\n\t\tDir: \"test-migrations\",\n\t}\n\n\t// Executes migration with not existing version 3\n\t_, err := ExecVersion(s.Db, \"sqlite3\", migrations, Up, 3)\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *SqliteMigrateSuite) TestMigrateVersionIntFailedWithInvalidVerion(c *C) {\n\tmigrations := &FileMigrationSource{\n\t\tDir: \"test-migrations\",\n\t}\n\n\t// Executes migration with invalid version -1\n\t_, err := ExecVersion(s.Db, \"sqlite3\", migrations, Up, -1)\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *SqliteMigrateSuite) TestMigrateDown(c *C) {\n\tmigrations := &FileMigrationSource{\n\t\tDir: \"test-migrations\",\n\t}\n\n\tn, err := Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 2)\n\n\t// Has data\n\tid, err := s.DbMap.SelectInt(\"SELECT id FROM people\")\n\tc.Assert(err, IsNil)\n\tc.Assert(id, Equals, int64(1))\n\n\t// Undo the last one\n\tn, err = ExecMax(s.Db, \"sqlite3\", migrations, Down, 1)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 1)\n\n\t// No more data\n\tid, err = s.DbMap.SelectInt(\"SELECT COUNT(*) FROM people\")\n\tc.Assert(err, IsNil)\n\tc.Assert(id, Equals, int64(0))\n\n\t// Remove the table.\n\tn, err = ExecMax(s.Db, \"sqlite3\", migrations, Down, 1)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 1)\n\n\t// Cannot query it anymore\n\t_, err = s.DbMap.SelectInt(\"SELECT COUNT(*) FROM people\")\n\tc.Assert(err, Not(IsNil))\n\n\t// Nothing left to do.\n\tn, err = ExecMax(s.Db, \"sqlite3\", migrations, Down, 1)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 0)\n}\n\nfunc (s *SqliteMigrateSuite) TestMigrateDownFull(c *C) {\n\tmigrations := &FileMigrationSource{\n\t\tDir: \"test-migrations\",\n\t}\n\n\tn, err := Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 2)\n\n\t// Has data\n\tid, err := s.DbMap.SelectInt(\"SELECT id FROM people\")\n\tc.Assert(err, IsNil)\n\tc.Assert(id, Equals, int64(1))\n\n\t// Undo the last one\n\tn, err = Exec(s.Db, \"sqlite3\", migrations, Down)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 2)\n\n\t// Cannot query it anymore\n\t_, err = s.DbMap.SelectInt(\"SELECT COUNT(*) FROM people\")\n\tc.Assert(err, Not(IsNil))\n\n\t// Nothing left to do.\n\tn, err = Exec(s.Db, \"sqlite3\", migrations, Down)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 0)\n}\n\nfunc (s *SqliteMigrateSuite) TestMigrateTransaction(c *C) {\n\tmigrations := &MemoryMigrationSource{\n\t\tMigrations: []*Migration{\n\t\t\tsqliteMigrations[0],\n\t\t\tsqliteMigrations[1],\n\t\t\t{\n\t\t\t\tId:   \"125\",\n\t\t\t\tUp:   []string{\"INSERT INTO people (id, first_name) VALUES (1, 'Test')\", \"SELECT fail\"},\n\t\t\t\tDown: []string{}, // Not important here\n\t\t\t},\n\t\t},\n\t}\n\n\t// Should fail, transaction should roll back the INSERT.\n\tn, err := Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, Not(IsNil))\n\tc.Assert(n, Equals, 2)\n\n\t// INSERT should be rolled back\n\tcount, err := s.DbMap.SelectInt(\"SELECT COUNT(*) FROM people\")\n\tc.Assert(err, IsNil)\n\tc.Assert(count, Equals, int64(0))\n}\n\nfunc (s *SqliteMigrateSuite) TestPlanMigration(c *C) {\n\tmigrations := &MemoryMigrationSource{\n\t\tMigrations: []*Migration{\n\t\t\t{\n\t\t\t\tId:   \"1_create_table.sql\",\n\t\t\t\tUp:   []string{\"CREATE TABLE people (id int)\"},\n\t\t\t\tDown: []string{\"DROP TABLE people\"},\n\t\t\t},\n\t\t\t{\n\t\t\t\tId:   \"2_alter_table.sql\",\n\t\t\t\tUp:   []string{\"ALTER TABLE people ADD COLUMN first_name text\"},\n\t\t\t\tDown: []string{\"SELECT 0\"}, // Not really supported\n\t\t\t},\n\t\t\t{\n\t\t\t\tId:   \"10_add_last_name.sql\",\n\t\t\t\tUp:   []string{\"ALTER TABLE people ADD COLUMN last_name text\"},\n\t\t\t\tDown: []string{\"ALTER TABLE people DROP COLUMN last_name\"},\n\t\t\t},\n\t\t},\n\t}\n\tn, err := Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 3)\n\n\tmigrations.Migrations = append(migrations.Migrations, &Migration{\n\t\tId:   \"11_add_middle_name.sql\",\n\t\tUp:   []string{\"ALTER TABLE people ADD COLUMN middle_name text\"},\n\t\tDown: []string{\"ALTER TABLE people DROP COLUMN middle_name\"},\n\t})\n\n\tplannedMigrations, _, err := PlanMigration(s.Db, \"sqlite3\", migrations, Up, 0)\n\tc.Assert(err, IsNil)\n\tc.Assert(plannedMigrations, HasLen, 1)\n\tc.Assert(plannedMigrations[0].Migration, Equals, migrations.Migrations[3])\n\n\tplannedMigrations, _, err = PlanMigration(s.Db, \"sqlite3\", migrations, Down, 0)\n\tc.Assert(err, IsNil)\n\tc.Assert(plannedMigrations, HasLen, 3)\n\tc.Assert(plannedMigrations[0].Migration, Equals, migrations.Migrations[2])\n\tc.Assert(plannedMigrations[1].Migration, Equals, migrations.Migrations[1])\n\tc.Assert(plannedMigrations[2].Migration, Equals, migrations.Migrations[0])\n}\n\nfunc (s *SqliteMigrateSuite) TestSkipMigration(c *C) {\n\tmigrations := &MemoryMigrationSource{\n\t\tMigrations: []*Migration{\n\t\t\t{\n\t\t\t\tId:   \"1_create_table.sql\",\n\t\t\t\tUp:   []string{\"CREATE TABLE people (id int)\"},\n\t\t\t\tDown: []string{\"DROP TABLE people\"},\n\t\t\t},\n\t\t\t{\n\t\t\t\tId:   \"2_alter_table.sql\",\n\t\t\t\tUp:   []string{\"ALTER TABLE people ADD COLUMN first_name text\"},\n\t\t\t\tDown: []string{\"SELECT 0\"}, // Not really supported\n\t\t\t},\n\t\t\t{\n\t\t\t\tId:   \"10_add_last_name.sql\",\n\t\t\t\tUp:   []string{\"ALTER TABLE people ADD COLUMN last_name text\"},\n\t\t\t\tDown: []string{\"ALTER TABLE people DROP COLUMN last_name\"},\n\t\t\t},\n\t\t},\n\t}\n\tn, err := SkipMax(s.Db, \"sqlite3\", migrations, Up, 0)\n\t// there should be no errors\n\tc.Assert(err, IsNil)\n\t// we should have detected and skipped 3 migrations\n\tc.Assert(n, Equals, 3)\n\t// should not actually have the tables now since it was skipped\n\t// so this query should fail\n\t_, err = s.DbMap.Exec(\"SELECT * FROM people\")\n\tc.Assert(err, NotNil)\n\t// run the migrations again, should execute none of them since we pegged the db level\n\t// in the skip command\n\tn2, err2 := Exec(s.Db, \"sqlite3\", migrations, Up)\n\t// there should be no errors\n\tc.Assert(err2, IsNil)\n\t// we should not have executed any migrations\n\tc.Assert(n2, Equals, 0)\n}\n\nfunc (s *SqliteMigrateSuite) TestPlanMigrationWithHoles(c *C) {\n\tup := \"SELECT 0\"\n\tdown := \"SELECT 1\"\n\tmigrations := &MemoryMigrationSource{\n\t\tMigrations: []*Migration{\n\t\t\t{\n\t\t\t\tId:   \"1\",\n\t\t\t\tUp:   []string{up},\n\t\t\t\tDown: []string{down},\n\t\t\t},\n\t\t\t{\n\t\t\t\tId:   \"3\",\n\t\t\t\tUp:   []string{up},\n\t\t\t\tDown: []string{down},\n\t\t\t},\n\t\t},\n\t}\n\tn, err := Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 2)\n\n\tmigrations.Migrations = append(migrations.Migrations, &Migration{\n\t\tId:   \"2\",\n\t\tUp:   []string{up},\n\t\tDown: []string{down},\n\t})\n\n\tmigrations.Migrations = append(migrations.Migrations, &Migration{\n\t\tId:   \"4\",\n\t\tUp:   []string{up},\n\t\tDown: []string{down},\n\t})\n\n\tmigrations.Migrations = append(migrations.Migrations, &Migration{\n\t\tId:   \"5\",\n\t\tUp:   []string{up},\n\t\tDown: []string{down},\n\t})\n\n\t// apply all the missing migrations\n\tplannedMigrations, _, err := PlanMigration(s.Db, \"sqlite3\", migrations, Up, 0)\n\tc.Assert(err, IsNil)\n\tc.Assert(plannedMigrations, HasLen, 3)\n\tc.Assert(plannedMigrations[0].Migration.Id, Equals, \"2\")\n\tc.Assert(plannedMigrations[0].Queries[0], Equals, up)\n\tc.Assert(plannedMigrations[1].Migration.Id, Equals, \"4\")\n\tc.Assert(plannedMigrations[1].Queries[0], Equals, up)\n\tc.Assert(plannedMigrations[2].Migration.Id, Equals, \"5\")\n\tc.Assert(plannedMigrations[2].Queries[0], Equals, up)\n\n\t// first catch up to current target state 123, then migrate down 1 step to 12\n\tplannedMigrations, _, err = PlanMigration(s.Db, \"sqlite3\", migrations, Down, 1)\n\tc.Assert(err, IsNil)\n\tc.Assert(plannedMigrations, HasLen, 2)\n\tc.Assert(plannedMigrations[0].Migration.Id, Equals, \"2\")\n\tc.Assert(plannedMigrations[0].Queries[0], Equals, up)\n\tc.Assert(plannedMigrations[1].Migration.Id, Equals, \"3\")\n\tc.Assert(plannedMigrations[1].Queries[0], Equals, down)\n\n\t// first catch up to current target state 123, then migrate down 2 steps to 1\n\tplannedMigrations, _, err = PlanMigration(s.Db, \"sqlite3\", migrations, Down, 2)\n\tc.Assert(err, IsNil)\n\tc.Assert(plannedMigrations, HasLen, 3)\n\tc.Assert(plannedMigrations[0].Migration.Id, Equals, \"2\")\n\tc.Assert(plannedMigrations[0].Queries[0], Equals, up)\n\tc.Assert(plannedMigrations[1].Migration.Id, Equals, \"3\")\n\tc.Assert(plannedMigrations[1].Queries[0], Equals, down)\n\tc.Assert(plannedMigrations[2].Migration.Id, Equals, \"2\")\n\tc.Assert(plannedMigrations[2].Queries[0], Equals, down)\n}\n\nfunc (*SqliteMigrateSuite) TestLess(c *C) {\n\tc.Assert((Migration{Id: \"1\"}).Less(&Migration{Id: \"2\"}), Equals, true)           // 1 less than 2\n\tc.Assert((Migration{Id: \"2\"}).Less(&Migration{Id: \"1\"}), Equals, false)          // 2 not less than 1\n\tc.Assert((Migration{Id: \"1\"}).Less(&Migration{Id: \"a\"}), Equals, true)           // 1 less than a\n\tc.Assert((Migration{Id: \"a\"}).Less(&Migration{Id: \"1\"}), Equals, false)          // a not less than 1\n\tc.Assert((Migration{Id: \"a\"}).Less(&Migration{Id: \"a\"}), Equals, false)          // a not less than a\n\tc.Assert((Migration{Id: \"1-a\"}).Less(&Migration{Id: \"1-b\"}), Equals, true)       // 1-a less than 1-b\n\tc.Assert((Migration{Id: \"1-b\"}).Less(&Migration{Id: \"1-a\"}), Equals, false)      // 1-b not less than 1-a\n\tc.Assert((Migration{Id: \"1\"}).Less(&Migration{Id: \"10\"}), Equals, true)          // 1 less than 10\n\tc.Assert((Migration{Id: \"10\"}).Less(&Migration{Id: \"1\"}), Equals, false)         // 10 not less than 1\n\tc.Assert((Migration{Id: \"1_foo\"}).Less(&Migration{Id: \"10_bar\"}), Equals, true)  // 1_foo not less than 1\n\tc.Assert((Migration{Id: \"10_bar\"}).Less(&Migration{Id: \"1_foo\"}), Equals, false) // 10 not less than 1\n\t// 20160126_1100 less than 20160126_1200\n\tc.Assert((Migration{Id: \"20160126_1100\"}).\n\t\tLess(&Migration{Id: \"20160126_1200\"}), Equals, true)\n\t// 20160126_1200 not less than 20160126_1100\n\tc.Assert((Migration{Id: \"20160126_1200\"}).\n\t\tLess(&Migration{Id: \"20160126_1100\"}), Equals, false)\n}\n\nfunc (s *SqliteMigrateSuite) TestPlanMigrationWithUnknownDatabaseMigrationApplied(c *C) {\n\tmigrations := &MemoryMigrationSource{\n\t\tMigrations: []*Migration{\n\t\t\t{\n\t\t\t\tId:   \"1_create_table.sql\",\n\t\t\t\tUp:   []string{\"CREATE TABLE people (id int)\"},\n\t\t\t\tDown: []string{\"DROP TABLE people\"},\n\t\t\t},\n\t\t\t{\n\t\t\t\tId:   \"2_alter_table.sql\",\n\t\t\t\tUp:   []string{\"ALTER TABLE people ADD COLUMN first_name text\"},\n\t\t\t\tDown: []string{\"SELECT 0\"}, // Not really supported\n\t\t\t},\n\t\t\t{\n\t\t\t\tId:   \"10_add_last_name.sql\",\n\t\t\t\tUp:   []string{\"ALTER TABLE people ADD COLUMN last_name text\"},\n\t\t\t\tDown: []string{\"ALTER TABLE people DROP COLUMN last_name\"},\n\t\t\t},\n\t\t},\n\t}\n\tn, err := Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 3)\n\n\t// Note that migration 10_add_last_name.sql is missing from the new migrations source\n\t// so it is considered an \"unknown\" migration for the planner.\n\tmigrations.Migrations = append(migrations.Migrations[:2], &Migration{\n\t\tId:   \"10_add_middle_name.sql\",\n\t\tUp:   []string{\"ALTER TABLE people ADD COLUMN middle_name text\"},\n\t\tDown: []string{\"ALTER TABLE people DROP COLUMN middle_name\"},\n\t})\n\n\t_, _, err = PlanMigration(s.Db, \"sqlite3\", migrations, Up, 0)\n\tc.Assert(err, NotNil, Commentf(\"Up migrations should not have been applied when there \"+\n\t\t\"is an unknown migration in the database\"))\n\tc.Assert(err, FitsTypeOf, &PlanError{})\n\n\t_, _, err = PlanMigration(s.Db, \"sqlite3\", migrations, Down, 0)\n\tc.Assert(err, NotNil, Commentf(\"Down migrations should not have been applied when there \"+\n\t\t\"is an unknown migration in the database\"))\n\tc.Assert(err, FitsTypeOf, &PlanError{})\n}\n\nfunc (s *SqliteMigrateSuite) TestPlanMigrationWithIgnoredUnknownDatabaseMigrationApplied(c *C) {\n\tmigrations := &MemoryMigrationSource{\n\t\tMigrations: []*Migration{\n\t\t\t{\n\t\t\t\tId:   \"1_create_table.sql\",\n\t\t\t\tUp:   []string{\"CREATE TABLE people (id int)\"},\n\t\t\t\tDown: []string{\"DROP TABLE people\"},\n\t\t\t},\n\t\t\t{\n\t\t\t\tId:   \"2_alter_table.sql\",\n\t\t\t\tUp:   []string{\"ALTER TABLE people ADD COLUMN first_name text\"},\n\t\t\t\tDown: []string{\"SELECT 0\"}, // Not really supported\n\t\t\t},\n\t\t\t{\n\t\t\t\tId:   \"10_add_last_name.sql\",\n\t\t\t\tUp:   []string{\"ALTER TABLE people ADD COLUMN last_name text\"},\n\t\t\t\tDown: []string{\"ALTER TABLE people DROP COLUMN last_name\"},\n\t\t\t},\n\t\t},\n\t}\n\tSetIgnoreUnknown(true)\n\tn, err := Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 3)\n\n\t// Note that migration 10_add_last_name.sql is missing from the new migrations source\n\t// so it is considered an \"unknown\" migration for the planner.\n\tmigrations.Migrations = append(migrations.Migrations[:2], &Migration{\n\t\tId:   \"10_add_middle_name.sql\",\n\t\tUp:   []string{\"ALTER TABLE people ADD COLUMN middle_name text\"},\n\t\tDown: []string{\"ALTER TABLE people DROP COLUMN middle_name\"},\n\t})\n\n\t_, _, err = PlanMigration(s.Db, \"sqlite3\", migrations, Up, 0)\n\tc.Assert(err, IsNil)\n\n\t_, _, err = PlanMigration(s.Db, \"sqlite3\", migrations, Down, 0)\n\tc.Assert(err, IsNil)\n\tSetIgnoreUnknown(false) // Make sure we are not breaking other tests as this is globaly set\n}\n\nfunc (s *SqliteMigrateSuite) TestPlanMigrationToVersion(c *C) {\n\tmigrations := &MemoryMigrationSource{\n\t\tMigrations: []*Migration{\n\t\t\t{\n\t\t\t\tId:   \"1_create_table.sql\",\n\t\t\t\tUp:   []string{\"CREATE TABLE people (id int)\"},\n\t\t\t\tDown: []string{\"DROP TABLE people\"},\n\t\t\t},\n\t\t\t{\n\t\t\t\tId:   \"2_alter_table.sql\",\n\t\t\t\tUp:   []string{\"ALTER TABLE people ADD COLUMN first_name text\"},\n\t\t\t\tDown: []string{\"SELECT 0\"}, // Not really supported\n\t\t\t},\n\t\t\t{\n\t\t\t\tId:   \"10_add_last_name.sql\",\n\t\t\t\tUp:   []string{\"ALTER TABLE people ADD COLUMN last_name text\"},\n\t\t\t\tDown: []string{\"ALTER TABLE people DROP COLUMN last_name\"},\n\t\t\t},\n\t\t},\n\t}\n\tn, err := Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 3)\n\n\tmigrations.Migrations = append(migrations.Migrations, &Migration{\n\t\tId:   \"11_add_middle_name.sql\",\n\t\tUp:   []string{\"ALTER TABLE people ADD COLUMN middle_name text\"},\n\t\tDown: []string{\"ALTER TABLE people DROP COLUMN middle_name\"},\n\t})\n\n\tplannedMigrations, _, err := PlanMigrationToVersion(s.Db, \"sqlite3\", migrations, Up, 11)\n\tc.Assert(err, IsNil)\n\tc.Assert(plannedMigrations, HasLen, 1)\n\tc.Assert(plannedMigrations[0].Migration, Equals, migrations.Migrations[3])\n\n\tplannedMigrations, _, err = PlanMigrationToVersion(s.Db, \"sqlite3\", migrations, Down, 1)\n\tc.Assert(err, IsNil)\n\tc.Assert(plannedMigrations, HasLen, 3)\n\tc.Assert(plannedMigrations[0].Migration, Equals, migrations.Migrations[2])\n\tc.Assert(plannedMigrations[1].Migration, Equals, migrations.Migrations[1])\n\tc.Assert(plannedMigrations[2].Migration, Equals, migrations.Migrations[0])\n}\n\n// TestExecWithUnknownMigrationInDatabase makes sure that problems found with planning the\n// migrations are propagated and returned by Exec.\nfunc (s *SqliteMigrateSuite) TestExecWithUnknownMigrationInDatabase(c *C) {\n\tmigrations := &MemoryMigrationSource{\n\t\tMigrations: sqliteMigrations[:2],\n\t}\n\n\t// Executes two migrations\n\tn, err := Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 2)\n\n\t// Then create a new migration source with one of the migrations missing\n\tnewSqliteMigrations := []*Migration{\n\t\t{\n\t\t\tId:   \"124_other\",\n\t\t\tUp:   []string{\"ALTER TABLE people ADD COLUMN middle_name text\"},\n\t\t\tDown: []string{\"ALTER TABLE people DROP COLUMN middle_name\"},\n\t\t},\n\t\t{\n\t\t\tId:   \"125\",\n\t\t\tUp:   []string{\"ALTER TABLE people ADD COLUMN age int\"},\n\t\t\tDown: []string{\"ALTER TABLE people DROP COLUMN age\"},\n\t\t},\n\t}\n\tmigrations = &MemoryMigrationSource{\n\t\tMigrations: append(sqliteMigrations[:1], newSqliteMigrations...),\n\t}\n\n\tn, err = Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, NotNil, Commentf(\"Migrations should not have been applied when there \"+\n\t\t\"is an unknown migration in the database\"))\n\tc.Assert(err, FitsTypeOf, &PlanError{})\n\tc.Assert(n, Equals, 0)\n\n\t// Make sure the new columns are not actually created\n\t_, err = s.DbMap.Exec(\"SELECT middle_name FROM people\")\n\tc.Assert(err, NotNil)\n\t_, err = s.DbMap.Exec(\"SELECT age FROM people\")\n\tc.Assert(err, NotNil)\n}\n\nfunc (s *SqliteMigrateSuite) TestRunMigrationObjDefaultTable(c *C) {\n\tmigrations := &MemoryMigrationSource{\n\t\tMigrations: sqliteMigrations[:1],\n\t}\n\n\tms := MigrationSet{}\n\t// Executes one migration\n\tn, err := ms.Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 1)\n\n\t// Can use table now\n\t_, err = s.DbMap.Exec(\"SELECT * FROM people\")\n\tc.Assert(err, IsNil)\n\n\t// Uses default tableName\n\t_, err = s.DbMap.Exec(\"SELECT * FROM gorp_migrations\")\n\tc.Assert(err, IsNil)\n\n\t// Shouldn't apply migration again\n\tn, err = ms.Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 0)\n}\n\nfunc (s *SqliteMigrateSuite) TestRunMigrationObjOtherTable(c *C) {\n\tmigrations := &MemoryMigrationSource{\n\t\tMigrations: sqliteMigrations[:1],\n\t}\n\n\tms := MigrationSet{TableName: \"other_migrations\"}\n\t// Executes one migration\n\tn, err := ms.Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 1)\n\n\t// Can use table now\n\t_, err = s.DbMap.Exec(\"SELECT * FROM people\")\n\tc.Assert(err, IsNil)\n\n\t// Uses default tableName\n\t_, err = s.DbMap.Exec(\"SELECT * FROM other_migrations\")\n\tc.Assert(err, IsNil)\n\n\t// Shouldn't apply migration again\n\tn, err = ms.Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 0)\n}\n\nfunc (*SqliteMigrateSuite) TestSetDisableCreateTable(c *C) {\n\tc.Assert(migSet.DisableCreateTable, Equals, false)\n\n\tSetDisableCreateTable(true)\n\tc.Assert(migSet.DisableCreateTable, Equals, true)\n\n\tSetDisableCreateTable(false)\n\tc.Assert(migSet.DisableCreateTable, Equals, false)\n}\n\nfunc (s *SqliteMigrateSuite) TestGetMigrationDbMapWithDisableCreateTable(c *C) {\n\tSetDisableCreateTable(false)\n\n\t_, err := migSet.getMigrationDbMap(s.Db, \"postgres\")\n\tc.Assert(err, IsNil)\n}\n\n// If ms.DisableCreateTable == true, then the the migrations table should not be\n// created, regardless of the global migSet.DisableCreateTable setting.\nfunc (s *SqliteMigrateSuite) TestGetMigrationObjDbMapWithDisableCreateTableTrue(c *C) {\n\tSetDisableCreateTable(false)\n\tms := MigrationSet{\n\t\tDisableCreateTable: true,\n\t\tTableName:          \"silly_example_table\",\n\t}\n\tc.Assert(migSet.DisableCreateTable, Equals, false)\n\tc.Assert(ms.DisableCreateTable, Equals, true)\n\n\tdbMap, err := ms.getMigrationDbMap(s.Db, \"sqlite3\")\n\tc.Assert(err, IsNil)\n\tc.Assert(dbMap, NotNil)\n\n\ttableNameIfExists, err := s.DbMap.SelectNullStr(\n\t\t\"SELECT name FROM sqlite_master WHERE type='table' AND name=$1\",\n\t\tms.TableName,\n\t)\n\tc.Assert(err, IsNil)\n\tc.Assert(tableNameIfExists.Valid, Equals, false)\n}\n\n// If ms.DisableCreateTable == false, then the the migrations table should not be\n// created, regardless of the global migSet.DisableCreateTable setting.\nfunc (s *SqliteMigrateSuite) TestGetMigrationObjDbMapWithDisableCreateTableFalse(c *C) {\n\tSetDisableCreateTable(true)\n\tdefer SetDisableCreateTable(false) // reset the global state when the test ends.\n\tms := MigrationSet{\n\t\tDisableCreateTable: false,\n\t\tTableName:          \"silly_example_table\",\n\t}\n\tc.Assert(migSet.DisableCreateTable, Equals, true)\n\tc.Assert(ms.DisableCreateTable, Equals, false)\n\n\tdbMap, err := ms.getMigrationDbMap(s.Db, \"sqlite3\")\n\tc.Assert(err, IsNil)\n\tc.Assert(dbMap, NotNil)\n\n\ttableNameIfExists, err := s.DbMap.SelectNullStr(\n\t\t\"SELECT name FROM sqlite_master WHERE type='table' AND name=$1\",\n\t\tms.TableName,\n\t)\n\tc.Assert(err, IsNil)\n\tc.Assert(tableNameIfExists.Valid, Equals, true)\n\tc.Assert(tableNameIfExists.String, Equals, ms.TableName)\n}\n\nfunc (s *SqliteMigrateSuite) TestContextTimeout(c *C) {\n\t// This statement will run for a long time: 1,000,000 iterations of the fibonacci sequence\n\tfibonacciLoopStmt := `WITH RECURSIVE\n\t   fibo (curr, next)\n\t AS\n\t   ( SELECT 1,1\n\t     UNION ALL\n\t     SELECT next, curr+next FROM fibo\n\t     LIMIT 1000000 )\n\t SELECT group_concat(curr) FROM fibo;\n\t`\n\tmigrations := &MemoryMigrationSource{\n\t\tMigrations: []*Migration{\n\t\t\tsqliteMigrations[0],\n\t\t\tsqliteMigrations[1],\n\t\t\t{\n\t\t\t\tId:   \"125\",\n\t\t\t\tUp:   []string{fibonacciLoopStmt},\n\t\t\t\tDown: []string{}, // Not important here\n\t\t\t},\n\t\t\t{\n\t\t\t\tId:   \"125\",\n\t\t\t\tUp:   []string{\"INSERT INTO people (id, first_name) VALUES (1, 'Test')\", \"SELECT fail\"},\n\t\t\t\tDown: []string{}, // Not important here\n\t\t\t},\n\t\t},\n\t}\n\n\t// Should never run the insert\n\tctx, cancelFunc := context.WithTimeout(context.Background(), 10*time.Millisecond)\n\tdefer cancelFunc()\n\tn, err := ExecContext(ctx, s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, Not(IsNil))\n\tc.Assert(n, Equals, 2)\n}\n\n//go:embed test-migrations/*\nvar testEmbedFS embed.FS\n\nfunc (s *SqliteMigrateSuite) TestEmbedSource(c *C) {\n\tmigrations := EmbedFileSystemMigrationSource{\n\t\tFileSystem: testEmbedFS,\n\t\tRoot:       \"test-migrations\",\n\t}\n\n\t// Executes two migrations\n\tn, err := Exec(s.Db, \"sqlite3\", migrations, Up)\n\tc.Assert(err, IsNil)\n\tc.Assert(n, Equals, 2)\n\n\t// Has data\n\tid, err := s.DbMap.SelectInt(\"SELECT id FROM people\")\n\tc.Assert(err, IsNil)\n\tc.Assert(id, Equals, int64(1))\n}\n"
        },
        {
          "name": "sort_test.go",
          "type": "blob",
          "size": 0.9345703125,
          "content": "package migrate\n\nimport (\n\t\"sort\"\n\n\t//revive:disable-next-line:dot-imports\n\t. \"gopkg.in/check.v1\"\n)\n\ntype SortSuite struct{}\n\nvar _ = Suite(&SortSuite{})\n\nfunc (*SortSuite) TestSortMigrations(c *C) {\n\tmigrations := byId([]*Migration{\n\t\t{Id: \"10_abc\", Up: nil, Down: nil},\n\t\t{Id: \"120_cde\", Up: nil, Down: nil},\n\t\t{Id: \"1_abc\", Up: nil, Down: nil},\n\t\t{Id: \"efg\", Up: nil, Down: nil},\n\t\t{Id: \"2_cde\", Up: nil, Down: nil},\n\t\t{Id: \"35_cde\", Up: nil, Down: nil},\n\t\t{Id: \"3_efg\", Up: nil, Down: nil},\n\t\t{Id: \"4_abc\", Up: nil, Down: nil},\n\t})\n\n\tsort.Sort(migrations)\n\tc.Assert(migrations, HasLen, 8)\n\tc.Assert(migrations[0].Id, Equals, \"1_abc\")\n\tc.Assert(migrations[1].Id, Equals, \"2_cde\")\n\tc.Assert(migrations[2].Id, Equals, \"3_efg\")\n\tc.Assert(migrations[3].Id, Equals, \"4_abc\")\n\tc.Assert(migrations[4].Id, Equals, \"10_abc\")\n\tc.Assert(migrations[5].Id, Equals, \"35_cde\")\n\tc.Assert(migrations[6].Id, Equals, \"120_cde\")\n\tc.Assert(migrations[7].Id, Equals, \"efg\")\n}\n"
        },
        {
          "name": "sql-migrate",
          "type": "tree",
          "content": null
        },
        {
          "name": "sqlparse",
          "type": "tree",
          "content": null
        },
        {
          "name": "test-integration",
          "type": "tree",
          "content": null
        },
        {
          "name": "test-migrations",
          "type": "tree",
          "content": null
        },
        {
          "name": "toapply_test.go",
          "type": "blob",
          "size": 2.939453125,
          "content": "package migrate\n\nimport (\n\t\"sort\"\n\n\t//revive:disable-next-line:dot-imports\n\t. \"gopkg.in/check.v1\"\n)\n\nvar toapplyMigrations = []*Migration{\n\t{Id: \"abc\", Up: nil, Down: nil},\n\t{Id: \"cde\", Up: nil, Down: nil},\n\t{Id: \"efg\", Up: nil, Down: nil},\n}\n\ntype ToApplyMigrateSuite struct{}\n\nvar _ = Suite(&ToApplyMigrateSuite{})\n\nfunc (*ToApplyMigrateSuite) TestGetAll(c *C) {\n\ttoApply := ToApply(toapplyMigrations, \"\", Up)\n\tc.Assert(toApply, HasLen, 3)\n\tc.Assert(toApply[0], Equals, toapplyMigrations[0])\n\tc.Assert(toApply[1], Equals, toapplyMigrations[1])\n\tc.Assert(toApply[2], Equals, toapplyMigrations[2])\n}\n\nfunc (*ToApplyMigrateSuite) TestGetAbc(c *C) {\n\ttoApply := ToApply(toapplyMigrations, \"abc\", Up)\n\tc.Assert(toApply, HasLen, 2)\n\tc.Assert(toApply[0], Equals, toapplyMigrations[1])\n\tc.Assert(toApply[1], Equals, toapplyMigrations[2])\n}\n\nfunc (*ToApplyMigrateSuite) TestGetCde(c *C) {\n\ttoApply := ToApply(toapplyMigrations, \"cde\", Up)\n\tc.Assert(toApply, HasLen, 1)\n\tc.Assert(toApply[0], Equals, toapplyMigrations[2])\n}\n\nfunc (*ToApplyMigrateSuite) TestGetDone(c *C) {\n\ttoApply := ToApply(toapplyMigrations, \"efg\", Up)\n\tc.Assert(toApply, HasLen, 0)\n\n\ttoApply = ToApply(toapplyMigrations, \"zzz\", Up)\n\tc.Assert(toApply, HasLen, 0)\n}\n\nfunc (*ToApplyMigrateSuite) TestDownDone(c *C) {\n\ttoApply := ToApply(toapplyMigrations, \"\", Down)\n\tc.Assert(toApply, HasLen, 0)\n}\n\nfunc (*ToApplyMigrateSuite) TestDownCde(c *C) {\n\ttoApply := ToApply(toapplyMigrations, \"cde\", Down)\n\tc.Assert(toApply, HasLen, 2)\n\tc.Assert(toApply[0], Equals, toapplyMigrations[1])\n\tc.Assert(toApply[1], Equals, toapplyMigrations[0])\n}\n\nfunc (*ToApplyMigrateSuite) TestDownAbc(c *C) {\n\ttoApply := ToApply(toapplyMigrations, \"abc\", Down)\n\tc.Assert(toApply, HasLen, 1)\n\tc.Assert(toApply[0], Equals, toapplyMigrations[0])\n}\n\nfunc (*ToApplyMigrateSuite) TestDownAll(c *C) {\n\ttoApply := ToApply(toapplyMigrations, \"efg\", Down)\n\tc.Assert(toApply, HasLen, 3)\n\tc.Assert(toApply[0], Equals, toapplyMigrations[2])\n\tc.Assert(toApply[1], Equals, toapplyMigrations[1])\n\tc.Assert(toApply[2], Equals, toapplyMigrations[0])\n\n\ttoApply = ToApply(toapplyMigrations, \"zzz\", Down)\n\tc.Assert(toApply, HasLen, 3)\n\tc.Assert(toApply[0], Equals, toapplyMigrations[2])\n\tc.Assert(toApply[1], Equals, toapplyMigrations[1])\n\tc.Assert(toApply[2], Equals, toapplyMigrations[0])\n}\n\nfunc (*ToApplyMigrateSuite) TestAlphaNumericMigrations(c *C) {\n\tmigrations := byId([]*Migration{\n\t\t{Id: \"10_abc\", Up: nil, Down: nil},\n\t\t{Id: \"1_abc\", Up: nil, Down: nil},\n\t\t{Id: \"efg\", Up: nil, Down: nil},\n\t\t{Id: \"2_cde\", Up: nil, Down: nil},\n\t\t{Id: \"35_cde\", Up: nil, Down: nil},\n\t})\n\n\tsort.Sort(migrations)\n\n\ttoApplyUp := ToApply(migrations, \"2_cde\", Up)\n\tc.Assert(toApplyUp, HasLen, 3)\n\tc.Assert(toApplyUp[0].Id, Equals, \"10_abc\")\n\tc.Assert(toApplyUp[1].Id, Equals, \"35_cde\")\n\tc.Assert(toApplyUp[2].Id, Equals, \"efg\")\n\n\ttoApplyDown := ToApply(migrations, \"2_cde\", Down)\n\tc.Assert(toApplyDown, HasLen, 2)\n\tc.Assert(toApplyDown[0].Id, Equals, \"2_cde\")\n\tc.Assert(toApplyDown[1].Id, Equals, \"1_abc\")\n}\n"
        }
      ]
    }
  ]
}