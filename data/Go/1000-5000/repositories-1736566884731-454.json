{
  "metadata": {
    "timestamp": 1736566884731,
    "page": 454,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQ2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "hashicorp/go-memdb",
      "stars": 3230,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.2666015625,
          "content": "# Compiled Object files, Static and Dynamic libs (Shared Objects)\n*.o\n*.a\n*.so\n\n# Folders\n_obj\n_test\n\n# Architecture specific extensions/prefixes\n*.[568vq]\n[568vq].out\n\n*.cgo1.go\n*.cgo2.c\n_cgo_defun.c\n_cgo_gotypes.go\n_cgo_export.*\n\n_testmain.go\n\n*.exe\n*.test\n*.prof\n\n.idea\n"
        },
        {
          "name": "CODEOWNERS",
          "type": "blob",
          "size": 0.533203125,
          "content": "# Each line is a file pattern followed by one or more owners.\n# More on CODEOWNERS files: https://help.github.com/en/github/creating-cloning-and-archiving-repositories/about-code-owners\n\n# Default owner\n* @hashicorp/team-ip-compliance @hashicorp/raft-force\n\n# Add override rules below. Each line is a file/folder pattern followed by one or more owners.\n# Being an owner means those groups or individuals will be added as reviewers to PRs affecting\n# those areas of the code.\n# Examples:\n# /docs/  @docs-team\n# *.js    @js-team\n# *.go    @go-team\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 15.583984375,
          "content": "Copyright (c) 2015 HashiCorp, Inc.\n\nMozilla Public License, version 2.0\n\n1. Definitions\n\n1.1. \"Contributor\"\n\n     means each individual or legal entity that creates, contributes to the\n     creation of, or owns Covered Software.\n\n1.2. \"Contributor Version\"\n\n     means the combination of the Contributions of others (if any) used by a\n     Contributor and that particular Contributor's Contribution.\n\n1.3. \"Contribution\"\n\n     means Covered Software of a particular Contributor.\n\n1.4. \"Covered Software\"\n\n     means Source Code Form to which the initial Contributor has attached the\n     notice in Exhibit A, the Executable Form of such Source Code Form, and\n     Modifications of such Source Code Form, in each case including portions\n     thereof.\n\n1.5. \"Incompatible With Secondary Licenses\"\n     means\n\n     a. that the initial Contributor has attached the notice described in\n        Exhibit B to the Covered Software; or\n\n     b. that the Covered Software was made available under the terms of\n        version 1.1 or earlier of the License, but not also under the terms of\n        a Secondary License.\n\n1.6. \"Executable Form\"\n\n     means any form of the work other than Source Code Form.\n\n1.7. \"Larger Work\"\n\n     means a work that combines Covered Software with other material, in a\n     separate file or files, that is not Covered Software.\n\n1.8. \"License\"\n\n     means this document.\n\n1.9. \"Licensable\"\n\n     means having the right to grant, to the maximum extent possible, whether\n     at the time of the initial grant or subsequently, any and all of the\n     rights conveyed by this License.\n\n1.10. \"Modifications\"\n\n     means any of the following:\n\n     a. any file in Source Code Form that results from an addition to,\n        deletion from, or modification of the contents of Covered Software; or\n\n     b. any new file in Source Code Form that contains any Covered Software.\n\n1.11. \"Patent Claims\" of a Contributor\n\n      means any patent claim(s), including without limitation, method,\n      process, and apparatus claims, in any patent Licensable by such\n      Contributor that would be infringed, but for the grant of the License,\n      by the making, using, selling, offering for sale, having made, import,\n      or transfer of either its Contributions or its Contributor Version.\n\n1.12. \"Secondary License\"\n\n      means either the GNU General Public License, Version 2.0, the GNU Lesser\n      General Public License, Version 2.1, the GNU Affero General Public\n      License, Version 3.0, or any later versions of those licenses.\n\n1.13. \"Source Code Form\"\n\n      means the form of the work preferred for making modifications.\n\n1.14. \"You\" (or \"Your\")\n\n      means an individual or a legal entity exercising rights under this\n      License. For legal entities, \"You\" includes any entity that controls, is\n      controlled by, or is under common control with You. For purposes of this\n      definition, \"control\" means (a) the power, direct or indirect, to cause\n      the direction or management of such entity, whether by contract or\n      otherwise, or (b) ownership of more than fifty percent (50%) of the\n      outstanding shares or beneficial ownership of such entity.\n\n\n2. License Grants and Conditions\n\n2.1. Grants\n\n     Each Contributor hereby grants You a world-wide, royalty-free,\n     non-exclusive license:\n\n     a. under intellectual property rights (other than patent or trademark)\n        Licensable by such Contributor to use, reproduce, make available,\n        modify, display, perform, distribute, and otherwise exploit its\n        Contributions, either on an unmodified basis, with Modifications, or\n        as part of a Larger Work; and\n\n     b. under Patent Claims of such Contributor to make, use, sell, offer for\n        sale, have made, import, and otherwise transfer either its\n        Contributions or its Contributor Version.\n\n2.2. Effective Date\n\n     The licenses granted in Section 2.1 with respect to any Contribution\n     become effective for each Contribution on the date the Contributor first\n     distributes such Contribution.\n\n2.3. Limitations on Grant Scope\n\n     The licenses granted in this Section 2 are the only rights granted under\n     this License. No additional rights or licenses will be implied from the\n     distribution or licensing of Covered Software under this License.\n     Notwithstanding Section 2.1(b) above, no patent license is granted by a\n     Contributor:\n\n     a. for any code that a Contributor has removed from Covered Software; or\n\n     b. for infringements caused by: (i) Your and any other third party's\n        modifications of Covered Software, or (ii) the combination of its\n        Contributions with other software (except as part of its Contributor\n        Version); or\n\n     c. under Patent Claims infringed by Covered Software in the absence of\n        its Contributions.\n\n     This License does not grant any rights in the trademarks, service marks,\n     or logos of any Contributor (except as may be necessary to comply with\n     the notice requirements in Section 3.4).\n\n2.4. Subsequent Licenses\n\n     No Contributor makes additional grants as a result of Your choice to\n     distribute the Covered Software under a subsequent version of this\n     License (see Section 10.2) or under the terms of a Secondary License (if\n     permitted under the terms of Section 3.3).\n\n2.5. Representation\n\n     Each Contributor represents that the Contributor believes its\n     Contributions are its original creation(s) or it has sufficient rights to\n     grant the rights to its Contributions conveyed by this License.\n\n2.6. Fair Use\n\n     This License is not intended to limit any rights You have under\n     applicable copyright doctrines of fair use, fair dealing, or other\n     equivalents.\n\n2.7. Conditions\n\n     Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in\n     Section 2.1.\n\n\n3. Responsibilities\n\n3.1. Distribution of Source Form\n\n     All distribution of Covered Software in Source Code Form, including any\n     Modifications that You create or to which You contribute, must be under\n     the terms of this License. You must inform recipients that the Source\n     Code Form of the Covered Software is governed by the terms of this\n     License, and how they can obtain a copy of this License. You may not\n     attempt to alter or restrict the recipients' rights in the Source Code\n     Form.\n\n3.2. Distribution of Executable Form\n\n     If You distribute Covered Software in Executable Form then:\n\n     a. such Covered Software must also be made available in Source Code Form,\n        as described in Section 3.1, and You must inform recipients of the\n        Executable Form how they can obtain a copy of such Source Code Form by\n        reasonable means in a timely manner, at a charge no more than the cost\n        of distribution to the recipient; and\n\n     b. You may distribute such Executable Form under the terms of this\n        License, or sublicense it under different terms, provided that the\n        license for the Executable Form does not attempt to limit or alter the\n        recipients' rights in the Source Code Form under this License.\n\n3.3. Distribution of a Larger Work\n\n     You may create and distribute a Larger Work under terms of Your choice,\n     provided that You also comply with the requirements of this License for\n     the Covered Software. If the Larger Work is a combination of Covered\n     Software with a work governed by one or more Secondary Licenses, and the\n     Covered Software is not Incompatible With Secondary Licenses, this\n     License permits You to additionally distribute such Covered Software\n     under the terms of such Secondary License(s), so that the recipient of\n     the Larger Work may, at their option, further distribute the Covered\n     Software under the terms of either this License or such Secondary\n     License(s).\n\n3.4. Notices\n\n     You may not remove or alter the substance of any license notices\n     (including copyright notices, patent notices, disclaimers of warranty, or\n     limitations of liability) contained within the Source Code Form of the\n     Covered Software, except that You may alter any license notices to the\n     extent required to remedy known factual inaccuracies.\n\n3.5. Application of Additional Terms\n\n     You may choose to offer, and to charge a fee for, warranty, support,\n     indemnity or liability obligations to one or more recipients of Covered\n     Software. However, You may do so only on Your own behalf, and not on\n     behalf of any Contributor. You must make it absolutely clear that any\n     such warranty, support, indemnity, or liability obligation is offered by\n     You alone, and You hereby agree to indemnify every Contributor for any\n     liability incurred by such Contributor as a result of warranty, support,\n     indemnity or liability terms You offer. You may include additional\n     disclaimers of warranty and limitations of liability specific to any\n     jurisdiction.\n\n4. Inability to Comply Due to Statute or Regulation\n\n   If it is impossible for You to comply with any of the terms of this License\n   with respect to some or all of the Covered Software due to statute,\n   judicial order, or regulation then You must: (a) comply with the terms of\n   this License to the maximum extent possible; and (b) describe the\n   limitations and the code they affect. Such description must be placed in a\n   text file included with all distributions of the Covered Software under\n   this License. Except to the extent prohibited by statute or regulation,\n   such description must be sufficiently detailed for a recipient of ordinary\n   skill to be able to understand it.\n\n5. Termination\n\n5.1. The rights granted under this License will terminate automatically if You\n     fail to comply with any of its terms. However, if You become compliant,\n     then the rights granted under this License from a particular Contributor\n     are reinstated (a) provisionally, unless and until such Contributor\n     explicitly and finally terminates Your grants, and (b) on an ongoing\n     basis, if such Contributor fails to notify You of the non-compliance by\n     some reasonable means prior to 60 days after You have come back into\n     compliance. Moreover, Your grants from a particular Contributor are\n     reinstated on an ongoing basis if such Contributor notifies You of the\n     non-compliance by some reasonable means, this is the first time You have\n     received notice of non-compliance with this License from such\n     Contributor, and You become compliant prior to 30 days after Your receipt\n     of the notice.\n\n5.2. If You initiate litigation against any entity by asserting a patent\n     infringement claim (excluding declaratory judgment actions,\n     counter-claims, and cross-claims) alleging that a Contributor Version\n     directly or indirectly infringes any patent, then the rights granted to\n     You by any and all Contributors for the Covered Software under Section\n     2.1 of this License shall terminate.\n\n5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user\n     license agreements (excluding distributors and resellers) which have been\n     validly granted by You or Your distributors under this License prior to\n     termination shall survive termination.\n\n6. Disclaimer of Warranty\n\n   Covered Software is provided under this License on an \"as is\" basis,\n   without warranty of any kind, either expressed, implied, or statutory,\n   including, without limitation, warranties that the Covered Software is free\n   of defects, merchantable, fit for a particular purpose or non-infringing.\n   The entire risk as to the quality and performance of the Covered Software\n   is with You. Should any Covered Software prove defective in any respect,\n   You (not any Contributor) assume the cost of any necessary servicing,\n   repair, or correction. This disclaimer of warranty constitutes an essential\n   part of this License. No use of  any Covered Software is authorized under\n   this License except under this disclaimer.\n\n7. Limitation of Liability\n\n   Under no circumstances and under no legal theory, whether tort (including\n   negligence), contract, or otherwise, shall any Contributor, or anyone who\n   distributes Covered Software as permitted above, be liable to You for any\n   direct, indirect, special, incidental, or consequential damages of any\n   character including, without limitation, damages for lost profits, loss of\n   goodwill, work stoppage, computer failure or malfunction, or any and all\n   other commercial damages or losses, even if such party shall have been\n   informed of the possibility of such damages. This limitation of liability\n   shall not apply to liability for death or personal injury resulting from\n   such party's negligence to the extent applicable law prohibits such\n   limitation. Some jurisdictions do not allow the exclusion or limitation of\n   incidental or consequential damages, so this exclusion and limitation may\n   not apply to You.\n\n8. Litigation\n\n   Any litigation relating to this License may be brought only in the courts\n   of a jurisdiction where the defendant maintains its principal place of\n   business and such litigation shall be governed by laws of that\n   jurisdiction, without reference to its conflict-of-law provisions. Nothing\n   in this Section shall prevent a party's ability to bring cross-claims or\n   counter-claims.\n\n9. Miscellaneous\n\n   This License represents the complete agreement concerning the subject\n   matter hereof. If any provision of this License is held to be\n   unenforceable, such provision shall be reformed only to the extent\n   necessary to make it enforceable. Any law or regulation which provides that\n   the language of a contract shall be construed against the drafter shall not\n   be used to construe this License against a Contributor.\n\n\n10. Versions of the License\n\n10.1. New Versions\n\n      Mozilla Foundation is the license steward. Except as provided in Section\n      10.3, no one other than the license steward has the right to modify or\n      publish new versions of this License. Each version will be given a\n      distinguishing version number.\n\n10.2. Effect of New Versions\n\n      You may distribute the Covered Software under the terms of the version\n      of the License under which You originally received the Covered Software,\n      or under the terms of any subsequent version published by the license\n      steward.\n\n10.3. Modified Versions\n\n      If you create software not governed by this License, and you want to\n      create a new license for such software, you may create and use a\n      modified version of this License if you rename the license and remove\n      any references to the name of the license steward (except to note that\n      such modified license differs from this License).\n\n10.4. Distributing Source Code Form that is Incompatible With Secondary\n      Licenses If You choose to distribute Source Code Form that is\n      Incompatible With Secondary Licenses under the terms of this version of\n      the License, the notice described in Exhibit B of this License must be\n      attached.\n\nExhibit A - Source Code Form License Notice\n\n      This Source Code Form is subject to the\n      terms of the Mozilla Public License, v.\n      2.0. If a copy of the MPL was not\n      distributed with this file, You can\n      obtain one at\n      http://mozilla.org/MPL/2.0/.\n\nIf it is not possible or desirable to put the notice in a particular file,\nthen You may include the notice in a location (such as a LICENSE file in a\nrelevant directory) where a recipient would be likely to look for such a\nnotice.\n\nYou may add additional accurate notices of copyright ownership.\n\nExhibit B - \"Incompatible With Secondary Licenses\" Notice\n\n      This Source Code Form is \"Incompatible\n      With Secondary Licenses\", as defined by\n      the Mozilla Public License, v. 2.0.\n\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 3.85546875,
          "content": "# go-memdb [![CircleCI](https://circleci.com/gh/hashicorp/go-memdb/tree/master.svg?style=svg)](https://circleci.com/gh/hashicorp/go-memdb/tree/master)\n\nProvides the `memdb` package that implements a simple in-memory database\nbuilt on immutable radix trees. The database provides Atomicity, Consistency\nand Isolation from ACID. Being that it is in-memory, it does not provide durability.\nThe database is instantiated with a schema that specifies the tables and indices\nthat exist and allows transactions to be executed.\n\nThe database provides the following:\n\n* Multi-Version Concurrency Control (MVCC) - By leveraging immutable radix trees\n  the database is able to support any number of concurrent readers without locking,\n  and allows a writer to make progress.\n\n* Transaction Support - The database allows for rich transactions, in which multiple\n  objects are inserted, updated or deleted. The transactions can span multiple tables,\n  and are applied atomically. The database provides atomicity and isolation in ACID\n  terminology, such that until commit the updates are not visible.\n\n* Rich Indexing - Tables can support any number of indexes, which can be simple like\n  a single field index, or more advanced compound field indexes. Certain types like\n  UUID can be efficiently compressed from strings into byte indexes for reduced\n  storage requirements.\n\n* Watches - Callers can populate a watch set as part of a query, which can be used to\n  detect when a modification has been made to the database which affects the query\n  results. This lets callers easily watch for changes in the database in a very general\n  way.\n\nFor the underlying immutable radix trees, see [go-immutable-radix](https://github.com/hashicorp/go-immutable-radix).\n\nDocumentation\n=============\n\nThe full documentation is available on [Godoc](https://pkg.go.dev/github.com/hashicorp/go-memdb).\n\nExample\n=======\n\nBelow is a [simple example](https://play.golang.org/p/gCGE9FA4og1) of usage\n\n```go\n// Create a sample struct\ntype Person struct {\n\tEmail string\n\tName  string\n\tAge   int\n}\n\n// Create the DB schema\nschema := &memdb.DBSchema{\n\tTables: map[string]*memdb.TableSchema{\n\t\t\"person\": &memdb.TableSchema{\n\t\t\tName: \"person\",\n\t\t\tIndexes: map[string]*memdb.IndexSchema{\n\t\t\t\t\"id\": &memdb.IndexSchema{\n\t\t\t\t\tName:    \"id\",\n\t\t\t\t\tUnique:  true,\n\t\t\t\t\tIndexer: &memdb.StringFieldIndex{Field: \"Email\"},\n\t\t\t\t},\n\t\t\t\t\"age\": &memdb.IndexSchema{\n\t\t\t\t\tName:    \"age\",\n\t\t\t\t\tUnique:  false,\n\t\t\t\t\tIndexer: &memdb.IntFieldIndex{Field: \"Age\"},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t},\n}\n\n// Create a new data base\ndb, err := memdb.NewMemDB(schema)\nif err != nil {\n\tpanic(err)\n}\n\n// Create a write transaction\ntxn := db.Txn(true)\n\n// Insert some people\npeople := []*Person{\n\t&Person{\"joe@aol.com\", \"Joe\", 30},\n\t&Person{\"lucy@aol.com\", \"Lucy\", 35},\n\t&Person{\"tariq@aol.com\", \"Tariq\", 21},\n\t&Person{\"dorothy@aol.com\", \"Dorothy\", 53},\n}\nfor _, p := range people {\n\tif err := txn.Insert(\"person\", p); err != nil {\n\t\tpanic(err)\n\t}\n}\n\n// Commit the transaction\ntxn.Commit()\n\n// Create read-only transaction\ntxn = db.Txn(false)\ndefer txn.Abort()\n\n// Lookup by email\nraw, err := txn.First(\"person\", \"id\", \"joe@aol.com\")\nif err != nil {\n\tpanic(err)\n}\n\n// Say hi!\nfmt.Printf(\"Hello %s!\\n\", raw.(*Person).Name)\n\n// List all the people\nit, err := txn.Get(\"person\", \"id\")\nif err != nil {\n\tpanic(err)\n}\n\nfmt.Println(\"All the people:\")\nfor obj := it.Next(); obj != nil; obj = it.Next() {\n\tp := obj.(*Person)\n\tfmt.Printf(\"  %s\\n\", p.Name)\n}\n\n// Range scan over people with ages between 25 and 35 inclusive\nit, err = txn.LowerBound(\"person\", \"age\", 25)\nif err != nil {\n\tpanic(err)\n}\n\nfmt.Println(\"People aged 25 - 35:\")\nfor obj := it.Next(); obj != nil; obj = it.Next() {\n\tp := obj.(*Person)\n\tif p.Age > 35 {\n\t\tbreak\n\t}\n\tfmt.Printf(\"  %s is aged %d\\n\", p.Name, p.Age)\n}\n// Output:\n// Hello Joe!\n// All the people:\n//   Dorothy\n//   Joe\n//   Lucy\n//   Tariq\n// People aged 25 - 35:\n//   Joe is aged 30\n//   Lucy is aged 35\n```\n\n"
        },
        {
          "name": "changes.go",
          "type": "blob",
          "size": 1.041015625,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage memdb\n\n// Changes describes a set of mutations to memDB tables performed during a\n// transaction.\ntype Changes []Change\n\n// Change describes a mutation to an object in a table.\ntype Change struct {\n\tTable  string\n\tBefore interface{}\n\tAfter  interface{}\n\n\t// primaryKey stores the raw key value from the primary index so that we can\n\t// de-duplicate multiple updates of the same object in the same transaction\n\t// but we don't expose this implementation detail to the consumer.\n\tprimaryKey []byte\n}\n\n// Created returns true if the mutation describes a new object being inserted.\nfunc (m *Change) Created() bool {\n\treturn m.Before == nil && m.After != nil\n}\n\n// Updated returns true if the mutation describes an existing object being\n// updated.\nfunc (m *Change) Updated() bool {\n\treturn m.Before != nil && m.After != nil\n}\n\n// Deleted returns true if the mutation describes an existing object being\n// deleted.\nfunc (m *Change) Deleted() bool {\n\treturn m.Before != nil && m.After == nil\n}\n"
        },
        {
          "name": "filter.go",
          "type": "blob",
          "size": 1.2236328125,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage memdb\n\n// FilterFunc is a function that takes the results of an iterator and returns\n// whether the result should be filtered out.\ntype FilterFunc func(interface{}) bool\n\n// FilterIterator is used to wrap a ResultIterator and apply a filter over it.\ntype FilterIterator struct {\n\t// filter is the filter function applied over the base iterator.\n\tfilter FilterFunc\n\n\t// iter is the iterator that is being wrapped.\n\titer ResultIterator\n}\n\n// NewFilterIterator wraps a ResultIterator. The filter function is applied\n// to each value returned by a call to iter.Next.\n//\n// See the documentation for ResultIterator to understand the behaviour of the\n// returned FilterIterator.\nfunc NewFilterIterator(iter ResultIterator, filter FilterFunc) *FilterIterator {\n\treturn &FilterIterator{\n\t\tfilter: filter,\n\t\titer:   iter,\n\t}\n}\n\n// WatchCh returns the watch channel of the wrapped iterator.\nfunc (f *FilterIterator) WatchCh() <-chan struct{} { return f.iter.WatchCh() }\n\n// Next returns the next non-filtered result from the wrapped iterator.\nfunc (f *FilterIterator) Next() interface{} {\n\tfor {\n\t\tif value := f.iter.Next(); value == nil || !f.filter(value) {\n\t\t\treturn value\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "filter_test.go",
          "type": "blob",
          "size": 2.5322265625,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage memdb\n\nimport \"testing\"\n\n// Test that the iterator meets the required interface\nfunc TestFilterIterator_Interface(t *testing.T) {\n\tvar _ ResultIterator = &FilterIterator{}\n}\n\nfunc TestFilterIterator(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(true)\n\n\tobj1 := &TestObject{\n\t\tID:  \"a\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\"},\n\t}\n\tobj2 := &TestObject{\n\t\tID:  \"medium-length\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\tobj3 := &TestObject{\n\t\tID:  \"super-long-unique-identifier\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\n\terr := txn.Insert(\"main\", obj1)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj2)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj3)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\tfilterFactory := func(idLengthLimit int) func(interface{}) bool {\n\t\tlimit := idLengthLimit\n\t\treturn func(raw interface{}) bool {\n\t\t\tobj, ok := raw.(*TestObject)\n\t\t\tif !ok {\n\t\t\t\treturn true\n\t\t\t}\n\n\t\t\treturn len(obj.ID) > limit\n\t\t}\n\t}\n\n\tcheckResult := func(txn *Txn) {\n\t\t// Attempt a row scan on the ID\n\t\tresult, err := txn.Get(\"main\", \"id\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\t// Wrap the iterator and try various filters\n\t\tfilter := NewFilterIterator(result, filterFactory(6))\n\t\tif raw := filter.Next(); raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t\t}\n\n\t\tif raw := filter.Next(); raw != nil {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, nil)\n\t\t}\n\n\t\tresult, err = txn.Get(\"main\", \"id\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\tfilter = NewFilterIterator(result, filterFactory(15))\n\t\tif raw := filter.Next(); raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t\t}\n\n\t\tif raw := filter.Next(); raw != obj2 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj2)\n\t\t}\n\n\t\tif raw := filter.Next(); raw != nil {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, nil)\n\t\t}\n\n\t\tresult, err = txn.Get(\"main\", \"id\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\tfilter = NewFilterIterator(result, filterFactory(150))\n\t\tif raw := filter.Next(); raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t\t}\n\n\t\tif raw := filter.Next(); raw != obj2 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj2)\n\t\t}\n\n\t\tif raw := filter.Next(); raw != obj3 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj3)\n\t\t}\n\n\t\tif raw := filter.Next(); raw != nil {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, nil)\n\t\t}\n\t}\n\n\t// Check the results within the txn\n\tcheckResult(txn)\n\n\t// Commit and start a new read transaction\n\ttxn.Commit()\n\ttxn = db.Txn(false)\n\n\t// Check the results in a new txn\n\tcheckResult(txn)\n}\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.1552734375,
          "content": "module github.com/hashicorp/go-memdb\n\ngo 1.13\n\nrequire (\n\tgithub.com/hashicorp/go-immutable-radix v1.3.1\n\tgithub.com/hashicorp/golang-lru v0.5.4 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 0.6318359375,
          "content": "github.com/hashicorp/go-immutable-radix v1.3.1 h1:DKHmCUm2hRBK510BaiZlwvpD40f8bJFeZnpfm2KLowc=\ngithub.com/hashicorp/go-immutable-radix v1.3.1/go.mod h1:0y9vanUI8NX6FsYoO3zeMjhV/C5i9g4Q3DwcSNZ4P60=\ngithub.com/hashicorp/go-uuid v1.0.0 h1:RS8zrF7PhGwyNPOtxSClXXj9HA8feRnJzgnI1RJCSnM=\ngithub.com/hashicorp/go-uuid v1.0.0/go.mod h1:6SBZvOh/SIDV7/2o3Jml5SYk/TvGqwFJ/bN7x4byOro=\ngithub.com/hashicorp/golang-lru v0.5.0/go.mod h1:/m3WP610KZHVQ1SGc6re/UDhFvYD7pJ4Ao+sR/qLZy8=\ngithub.com/hashicorp/golang-lru v0.5.4 h1:YDjusn29QI/Das2iO9M0BHnIbxPeyuCHsjMW+lJfyTc=\ngithub.com/hashicorp/golang-lru v0.5.4/go.mod h1:iADmTwqILo4mZ8BN3D2Q6+9jd8WM5uGBxy+E8yxSoD4=\n"
        },
        {
          "name": "index.go",
          "type": "blob",
          "size": 25.1044921875,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage memdb\n\nimport (\n\t\"encoding/binary\"\n\t\"encoding/hex\"\n\t\"errors\"\n\t\"fmt\"\n\t\"reflect\"\n\t\"strconv\"\n\t\"strings\"\n)\n\n// Indexer is an interface used for defining indexes. Indexes are used\n// for efficient lookup of objects in a MemDB table. An Indexer must also\n// implement one of SingleIndexer or MultiIndexer.\n//\n// Indexers are primarily responsible for returning the lookup key as\n// a byte slice. The byte slice is the key data in the underlying data storage.\ntype Indexer interface {\n\t// FromArgs is called to build the exact index key from a list of arguments.\n\tFromArgs(args ...interface{}) ([]byte, error)\n}\n\n// SingleIndexer is an interface used for defining indexes that generate a\n// single value per object\ntype SingleIndexer interface {\n\t// FromObject extracts the index value from an object. The return values\n\t// are whether the index value was found, the index value, and any error\n\t// while extracting the index value, respectively.\n\tFromObject(raw interface{}) (bool, []byte, error)\n}\n\n// MultiIndexer is an interface used for defining indexes that generate\n// multiple values per object. Each value is stored as a seperate index\n// pointing to the same object.\n//\n// For example, an index that extracts the first and last name of a person\n// and allows lookup based on eitherd would be a MultiIndexer. The FromObject\n// of this example would split the first and last name and return both as\n// values.\ntype MultiIndexer interface {\n\t// FromObject extracts index values from an object. The return values\n\t// are the same as a SingleIndexer except there can be multiple index\n\t// values.\n\tFromObject(raw interface{}) (bool, [][]byte, error)\n}\n\n// PrefixIndexer is an optional interface on top of an Indexer that allows\n// indexes to support prefix-based iteration.\ntype PrefixIndexer interface {\n\t// PrefixFromArgs is the same as FromArgs for an Indexer except that\n\t// the index value returned should return all prefix-matched values.\n\tPrefixFromArgs(args ...interface{}) ([]byte, error)\n}\n\n// StringFieldIndex is used to extract a field from an object\n// using reflection and builds an index on that field.\ntype StringFieldIndex struct {\n\tField     string\n\tLowercase bool\n}\n\nfunc (s *StringFieldIndex) FromObject(obj interface{}) (bool, []byte, error) {\n\tv := reflect.ValueOf(obj)\n\tv = reflect.Indirect(v) // Dereference the pointer if any\n\n\tfv := v.FieldByName(s.Field)\n\tisPtr := fv.Kind() == reflect.Ptr\n\tfv = reflect.Indirect(fv)\n\tif !isPtr && !fv.IsValid() {\n\t\treturn false, nil,\n\t\t\tfmt.Errorf(\"field '%s' for %#v is invalid %v \", s.Field, obj, isPtr)\n\t}\n\n\tif isPtr && !fv.IsValid() {\n\t\tval := \"\"\n\t\treturn false, []byte(val), nil\n\t}\n\n\tval := fv.String()\n\tif val == \"\" {\n\t\treturn false, nil, nil\n\t}\n\n\tif s.Lowercase {\n\t\tval = strings.ToLower(val)\n\t}\n\n\t// Add the null character as a terminator\n\tval += \"\\x00\"\n\treturn true, []byte(val), nil\n}\n\nfunc (s *StringFieldIndex) FromArgs(args ...interface{}) ([]byte, error) {\n\tif len(args) != 1 {\n\t\treturn nil, fmt.Errorf(\"must provide only a single argument\")\n\t}\n\targ, ok := args[0].(string)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"argument must be a string: %#v\", args[0])\n\t}\n\tif s.Lowercase {\n\t\targ = strings.ToLower(arg)\n\t}\n\t// Add the null character as a terminator\n\targ += \"\\x00\"\n\treturn []byte(arg), nil\n}\n\nfunc (s *StringFieldIndex) PrefixFromArgs(args ...interface{}) ([]byte, error) {\n\tval, err := s.FromArgs(args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Strip the null terminator, the rest is a prefix\n\tn := len(val)\n\tif n > 0 {\n\t\treturn val[:n-1], nil\n\t}\n\treturn val, nil\n}\n\n// StringSliceFieldIndex builds an index from a field on an object that is a\n// string slice ([]string). Each value within the string slice can be used for\n// lookup.\ntype StringSliceFieldIndex struct {\n\tField     string\n\tLowercase bool\n}\n\nfunc (s *StringSliceFieldIndex) FromObject(obj interface{}) (bool, [][]byte, error) {\n\tv := reflect.ValueOf(obj)\n\tv = reflect.Indirect(v) // Dereference the pointer if any\n\n\tfv := v.FieldByName(s.Field)\n\tif !fv.IsValid() {\n\t\treturn false, nil,\n\t\t\tfmt.Errorf(\"field '%s' for %#v is invalid\", s.Field, obj)\n\t}\n\n\tif fv.Kind() != reflect.Slice || fv.Type().Elem().Kind() != reflect.String {\n\t\treturn false, nil, fmt.Errorf(\"field '%s' is not a string slice\", s.Field)\n\t}\n\n\tlength := fv.Len()\n\tvals := make([][]byte, 0, length)\n\tfor i := 0; i < fv.Len(); i++ {\n\t\tval := fv.Index(i).String()\n\t\tif val == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\tif s.Lowercase {\n\t\t\tval = strings.ToLower(val)\n\t\t}\n\n\t\t// Add the null character as a terminator\n\t\tval += \"\\x00\"\n\t\tvals = append(vals, []byte(val))\n\t}\n\tif len(vals) == 0 {\n\t\treturn false, nil, nil\n\t}\n\treturn true, vals, nil\n}\n\nfunc (s *StringSliceFieldIndex) FromArgs(args ...interface{}) ([]byte, error) {\n\tif len(args) != 1 {\n\t\treturn nil, fmt.Errorf(\"must provide only a single argument\")\n\t}\n\targ, ok := args[0].(string)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"argument must be a string: %#v\", args[0])\n\t}\n\tif s.Lowercase {\n\t\targ = strings.ToLower(arg)\n\t}\n\t// Add the null character as a terminator\n\targ += \"\\x00\"\n\treturn []byte(arg), nil\n}\n\nfunc (s *StringSliceFieldIndex) PrefixFromArgs(args ...interface{}) ([]byte, error) {\n\tval, err := s.FromArgs(args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Strip the null terminator, the rest is a prefix\n\tn := len(val)\n\tif n > 0 {\n\t\treturn val[:n-1], nil\n\t}\n\treturn val, nil\n}\n\n// StringMapFieldIndex is used to extract a field of type map[string]string\n// from an object using reflection and builds an index on that field.\n//\n// Note that although FromArgs in theory supports using either one or\n// two arguments, there is a bug: FromObject only creates an index\n// using key/value, and does not also create an index using key. This\n// means a lookup using one argument will never actually work.\n//\n// It is currently left as-is to prevent backwards compatibility\n// issues.\n//\n// TODO: Fix this in the next major bump.\ntype StringMapFieldIndex struct {\n\tField     string\n\tLowercase bool\n}\n\nvar MapType = reflect.MapOf(reflect.TypeOf(\"\"), reflect.TypeOf(\"\")).Kind()\n\nfunc (s *StringMapFieldIndex) FromObject(obj interface{}) (bool, [][]byte, error) {\n\tv := reflect.ValueOf(obj)\n\tv = reflect.Indirect(v) // Dereference the pointer if any\n\n\tfv := v.FieldByName(s.Field)\n\tif !fv.IsValid() {\n\t\treturn false, nil, fmt.Errorf(\"field '%s' for %#v is invalid\", s.Field, obj)\n\t}\n\n\tif fv.Kind() != MapType {\n\t\treturn false, nil, fmt.Errorf(\"field '%s' is not a map[string]string\", s.Field)\n\t}\n\n\tlength := fv.Len()\n\tvals := make([][]byte, 0, length)\n\tfor _, key := range fv.MapKeys() {\n\t\tk := key.String()\n\t\tif k == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\tval := fv.MapIndex(key).String()\n\n\t\tif s.Lowercase {\n\t\t\tk = strings.ToLower(k)\n\t\t\tval = strings.ToLower(val)\n\t\t}\n\n\t\t// Add the null character as a terminator\n\t\tk += \"\\x00\" + val + \"\\x00\"\n\n\t\tvals = append(vals, []byte(k))\n\t}\n\tif len(vals) == 0 {\n\t\treturn false, nil, nil\n\t}\n\treturn true, vals, nil\n}\n\n// WARNING: Because of a bug in FromObject, this function will never return\n// a value when using the single-argument version.\nfunc (s *StringMapFieldIndex) FromArgs(args ...interface{}) ([]byte, error) {\n\tif len(args) > 2 || len(args) == 0 {\n\t\treturn nil, fmt.Errorf(\"must provide one or two arguments\")\n\t}\n\tkey, ok := args[0].(string)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"argument must be a string: %#v\", args[0])\n\t}\n\tif s.Lowercase {\n\t\tkey = strings.ToLower(key)\n\t}\n\t// Add the null character as a terminator\n\tkey += \"\\x00\"\n\n\tif len(args) == 2 {\n\t\tval, ok := args[1].(string)\n\t\tif !ok {\n\t\t\treturn nil, fmt.Errorf(\"argument must be a string: %#v\", args[1])\n\t\t}\n\t\tif s.Lowercase {\n\t\t\tval = strings.ToLower(val)\n\t\t}\n\t\t// Add the null character as a terminator\n\t\tkey += val + \"\\x00\"\n\t}\n\n\treturn []byte(key), nil\n}\n\n// IntFieldIndex is used to extract an int field from an object using\n// reflection and builds an index on that field.\ntype IntFieldIndex struct {\n\tField string\n}\n\nfunc (i *IntFieldIndex) FromObject(obj interface{}) (bool, []byte, error) {\n\tv := reflect.ValueOf(obj)\n\tv = reflect.Indirect(v) // Dereference the pointer if any\n\n\tfv := v.FieldByName(i.Field)\n\tif !fv.IsValid() {\n\t\treturn false, nil,\n\t\t\tfmt.Errorf(\"field '%s' for %#v is invalid\", i.Field, obj)\n\t}\n\n\t// Check the type\n\tk := fv.Kind()\n\tsize, ok := IsIntType(k)\n\tif !ok {\n\t\treturn false, nil, fmt.Errorf(\"field %q is of type %v; want an int\", i.Field, k)\n\t}\n\n\t// Get the value and encode it\n\tval := fv.Int()\n\tbuf := encodeInt(val, size)\n\n\treturn true, buf, nil\n}\n\nfunc (i *IntFieldIndex) FromArgs(args ...interface{}) ([]byte, error) {\n\tif len(args) != 1 {\n\t\treturn nil, fmt.Errorf(\"must provide only a single argument\")\n\t}\n\n\tv := reflect.ValueOf(args[0])\n\tif !v.IsValid() {\n\t\treturn nil, fmt.Errorf(\"%#v is invalid\", args[0])\n\t}\n\n\tk := v.Kind()\n\tsize, ok := IsIntType(k)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"arg is of type %v; want a int\", k)\n\t}\n\n\tval := v.Int()\n\tbuf := encodeInt(val, size)\n\n\treturn buf, nil\n}\n\nfunc encodeInt(val int64, size int) []byte {\n\tbuf := make([]byte, size)\n\n\t// This bit flips the sign bit on any sized signed twos-complement integer,\n\t// which when truncated to a uint of the same size will bias the value such\n\t// that the maximum negative int becomes 0, and the maximum positive int\n\t// becomes the maximum positive uint.\n\tscaled := val ^ int64(-1<<(size*8-1))\n\n\tswitch size {\n\tcase 1:\n\t\tbuf[0] = uint8(scaled)\n\tcase 2:\n\t\tbinary.BigEndian.PutUint16(buf, uint16(scaled))\n\tcase 4:\n\t\tbinary.BigEndian.PutUint32(buf, uint32(scaled))\n\tcase 8:\n\t\tbinary.BigEndian.PutUint64(buf, uint64(scaled))\n\tdefault:\n\t\tpanic(fmt.Sprintf(\"unsupported int size parameter: %d\", size))\n\t}\n\n\treturn buf\n}\n\n// IsIntType returns whether the passed type is a type of int and the number\n// of bytes needed to encode the type.\nfunc IsIntType(k reflect.Kind) (size int, okay bool) {\n\tswitch k {\n\tcase reflect.Int:\n\t\treturn strconv.IntSize / 8, true\n\tcase reflect.Int8:\n\t\treturn 1, true\n\tcase reflect.Int16:\n\t\treturn 2, true\n\tcase reflect.Int32:\n\t\treturn 4, true\n\tcase reflect.Int64:\n\t\treturn 8, true\n\tdefault:\n\t\treturn 0, false\n\t}\n}\n\n// UintFieldIndex is used to extract a uint field from an object using\n// reflection and builds an index on that field.\ntype UintFieldIndex struct {\n\tField string\n}\n\nfunc (u *UintFieldIndex) FromObject(obj interface{}) (bool, []byte, error) {\n\tv := reflect.ValueOf(obj)\n\tv = reflect.Indirect(v) // Dereference the pointer if any\n\n\tfv := v.FieldByName(u.Field)\n\tif !fv.IsValid() {\n\t\treturn false, nil,\n\t\t\tfmt.Errorf(\"field '%s' for %#v is invalid\", u.Field, obj)\n\t}\n\n\t// Check the type\n\tk := fv.Kind()\n\tsize, ok := IsUintType(k)\n\tif !ok {\n\t\treturn false, nil, fmt.Errorf(\"field %q is of type %v; want a uint\", u.Field, k)\n\t}\n\n\t// Get the value and encode it\n\tval := fv.Uint()\n\tbuf := encodeUInt(val, size)\n\n\treturn true, buf, nil\n}\n\nfunc (u *UintFieldIndex) FromArgs(args ...interface{}) ([]byte, error) {\n\tif len(args) != 1 {\n\t\treturn nil, fmt.Errorf(\"must provide only a single argument\")\n\t}\n\n\tv := reflect.ValueOf(args[0])\n\tif !v.IsValid() {\n\t\treturn nil, fmt.Errorf(\"%#v is invalid\", args[0])\n\t}\n\n\tk := v.Kind()\n\tsize, ok := IsUintType(k)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"arg is of type %v; want a uint\", k)\n\t}\n\n\tval := v.Uint()\n\tbuf := encodeUInt(val, size)\n\n\treturn buf, nil\n}\n\nfunc encodeUInt(val uint64, size int) []byte {\n\tbuf := make([]byte, size)\n\n\tswitch size {\n\tcase 1:\n\t\tbuf[0] = uint8(val)\n\tcase 2:\n\t\tbinary.BigEndian.PutUint16(buf, uint16(val))\n\tcase 4:\n\t\tbinary.BigEndian.PutUint32(buf, uint32(val))\n\tcase 8:\n\t\tbinary.BigEndian.PutUint64(buf, val)\n\tdefault:\n\t\tpanic(fmt.Sprintf(\"unsupported uint size parameter: %d\", size))\n\t}\n\n\treturn buf\n}\n\n// IsUintType returns whether the passed type is a type of uint and the number\n// of bytes needed to encode the type.\nfunc IsUintType(k reflect.Kind) (size int, okay bool) {\n\tswitch k {\n\tcase reflect.Uint:\n\t\treturn strconv.IntSize / 8, true\n\tcase reflect.Uint8:\n\t\treturn 1, true\n\tcase reflect.Uint16:\n\t\treturn 2, true\n\tcase reflect.Uint32:\n\t\treturn 4, true\n\tcase reflect.Uint64:\n\t\treturn 8, true\n\tdefault:\n\t\treturn 0, false\n\t}\n}\n\n// BoolFieldIndex is used to extract an boolean field from an object using\n// reflection and builds an index on that field.\ntype BoolFieldIndex struct {\n\tField string\n}\n\nfunc (i *BoolFieldIndex) FromObject(obj interface{}) (bool, []byte, error) {\n\tv := reflect.ValueOf(obj)\n\tv = reflect.Indirect(v) // Dereference the pointer if any\n\n\tfv := v.FieldByName(i.Field)\n\tif !fv.IsValid() {\n\t\treturn false, nil,\n\t\t\tfmt.Errorf(\"field '%s' for %#v is invalid\", i.Field, obj)\n\t}\n\n\t// Check the type\n\tk := fv.Kind()\n\tif k != reflect.Bool {\n\t\treturn false, nil, fmt.Errorf(\"field %q is of type %v; want a bool\", i.Field, k)\n\t}\n\n\t// Get the value and encode it\n\tbuf := make([]byte, 1)\n\tif fv.Bool() {\n\t\tbuf[0] = 1\n\t}\n\n\treturn true, buf, nil\n}\n\nfunc (i *BoolFieldIndex) FromArgs(args ...interface{}) ([]byte, error) {\n\treturn fromBoolArgs(args)\n}\n\n// UUIDFieldIndex is used to extract a field from an object\n// using reflection and builds an index on that field by treating\n// it as a UUID. This is an optimization to using a StringFieldIndex\n// as the UUID can be more compactly represented in byte form.\ntype UUIDFieldIndex struct {\n\tField string\n}\n\nfunc (u *UUIDFieldIndex) FromObject(obj interface{}) (bool, []byte, error) {\n\tv := reflect.ValueOf(obj)\n\tv = reflect.Indirect(v) // Dereference the pointer if any\n\n\tfv := v.FieldByName(u.Field)\n\tif !fv.IsValid() {\n\t\treturn false, nil,\n\t\t\tfmt.Errorf(\"field '%s' for %#v is invalid\", u.Field, obj)\n\t}\n\n\tval := fv.String()\n\tif val == \"\" {\n\t\treturn false, nil, nil\n\t}\n\n\tbuf, err := u.parseString(val, true)\n\treturn true, buf, err\n}\n\nfunc (u *UUIDFieldIndex) FromArgs(args ...interface{}) ([]byte, error) {\n\tif len(args) != 1 {\n\t\treturn nil, fmt.Errorf(\"must provide only a single argument\")\n\t}\n\tswitch arg := args[0].(type) {\n\tcase string:\n\t\treturn u.parseString(arg, true)\n\tcase []byte:\n\t\tif len(arg) != 16 {\n\t\t\treturn nil, fmt.Errorf(\"byte slice must be 16 characters\")\n\t\t}\n\t\treturn arg, nil\n\tdefault:\n\t\treturn nil,\n\t\t\tfmt.Errorf(\"argument must be a string or byte slice: %#v\", args[0])\n\t}\n}\n\nfunc (u *UUIDFieldIndex) PrefixFromArgs(args ...interface{}) ([]byte, error) {\n\tif len(args) != 1 {\n\t\treturn nil, fmt.Errorf(\"must provide only a single argument\")\n\t}\n\tswitch arg := args[0].(type) {\n\tcase string:\n\t\treturn u.parseString(arg, false)\n\tcase []byte:\n\t\treturn arg, nil\n\tdefault:\n\t\treturn nil,\n\t\t\tfmt.Errorf(\"argument must be a string or byte slice: %#v\", args[0])\n\t}\n}\n\n// parseString parses a UUID from the string. If enforceLength is false, it will\n// parse a partial UUID. An error is returned if the input, stripped of hyphens,\n// is not even length.\nfunc (u *UUIDFieldIndex) parseString(s string, enforceLength bool) ([]byte, error) {\n\t// Verify the length\n\tl := len(s)\n\tif enforceLength && l != 36 {\n\t\treturn nil, fmt.Errorf(\"UUID must be 36 characters\")\n\t} else if l > 36 {\n\t\treturn nil, fmt.Errorf(\"Invalid UUID length. UUID have 36 characters; got %d\", l)\n\t}\n\n\thyphens := strings.Count(s, \"-\")\n\tif hyphens > 4 {\n\t\treturn nil, fmt.Errorf(`UUID should have maximum of 4 \"-\"; got %d`, hyphens)\n\t}\n\n\t// The sanitized length is the length of the original string without the \"-\".\n\tsanitized := strings.Replace(s, \"-\", \"\", -1)\n\tsanitizedLength := len(sanitized)\n\tif sanitizedLength%2 != 0 {\n\t\treturn nil, fmt.Errorf(\"Input (without hyphens) must be even length\")\n\t}\n\n\tdec, err := hex.DecodeString(sanitized)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Invalid UUID: %v\", err)\n\t}\n\n\treturn dec, nil\n}\n\n// FieldSetIndex is used to extract a field from an object using reflection and\n// builds an index on whether the field is set by comparing it against its\n// type's nil value.\ntype FieldSetIndex struct {\n\tField string\n}\n\nfunc (f *FieldSetIndex) FromObject(obj interface{}) (bool, []byte, error) {\n\tv := reflect.ValueOf(obj)\n\tv = reflect.Indirect(v) // Dereference the pointer if any\n\n\tfv := v.FieldByName(f.Field)\n\tif !fv.IsValid() {\n\t\treturn false, nil,\n\t\t\tfmt.Errorf(\"field '%s' for %#v is invalid\", f.Field, obj)\n\t}\n\n\tif fv.Interface() == reflect.Zero(fv.Type()).Interface() {\n\t\treturn true, []byte{0}, nil\n\t}\n\n\treturn true, []byte{1}, nil\n}\n\nfunc (f *FieldSetIndex) FromArgs(args ...interface{}) ([]byte, error) {\n\treturn fromBoolArgs(args)\n}\n\n// ConditionalIndex builds an index based on a condition specified by a passed\n// user function. This function may examine the passed object and return a\n// boolean to encapsulate an arbitrarily complex conditional.\ntype ConditionalIndex struct {\n\tConditional ConditionalIndexFunc\n}\n\n// ConditionalIndexFunc is the required function interface for a\n// ConditionalIndex.\ntype ConditionalIndexFunc func(obj interface{}) (bool, error)\n\nfunc (c *ConditionalIndex) FromObject(obj interface{}) (bool, []byte, error) {\n\t// Call the user's function\n\tres, err := c.Conditional(obj)\n\tif err != nil {\n\t\treturn false, nil, fmt.Errorf(\"ConditionalIndexFunc(%#v) failed: %v\", obj, err)\n\t}\n\n\tif res {\n\t\treturn true, []byte{1}, nil\n\t}\n\n\treturn true, []byte{0}, nil\n}\n\nfunc (c *ConditionalIndex) FromArgs(args ...interface{}) ([]byte, error) {\n\treturn fromBoolArgs(args)\n}\n\n// fromBoolArgs is a helper that expects only a single boolean argument and\n// returns a single length byte array containing either a one or zero depending\n// on whether the passed input is true or false respectively.\nfunc fromBoolArgs(args []interface{}) ([]byte, error) {\n\tif len(args) != 1 {\n\t\treturn nil, fmt.Errorf(\"must provide only a single argument\")\n\t}\n\n\tif val, ok := args[0].(bool); !ok {\n\t\treturn nil, fmt.Errorf(\"argument must be a boolean type: %#v\", args[0])\n\t} else if val {\n\t\treturn []byte{1}, nil\n\t}\n\n\treturn []byte{0}, nil\n}\n\n// CompoundIndex is used to build an index using multiple sub-indexes\n// Prefix based iteration is supported as long as the appropriate prefix\n// of indexers support it. All sub-indexers are only assumed to expect\n// a single argument.\ntype CompoundIndex struct {\n\tIndexes []Indexer\n\n\t// AllowMissing results in an index based on only the indexers\n\t// that return data. If true, you may end up with 2/3 columns\n\t// indexed which might be useful for an index scan. Otherwise,\n\t// the CompoundIndex requires all indexers to be satisfied.\n\tAllowMissing bool\n}\n\nfunc (c *CompoundIndex) FromObject(raw interface{}) (bool, []byte, error) {\n\tvar out []byte\n\tfor i, idxRaw := range c.Indexes {\n\t\tidx, ok := idxRaw.(SingleIndexer)\n\t\tif !ok {\n\t\t\treturn false, nil, fmt.Errorf(\"sub-index %d error: %s\", i, \"sub-index must be a SingleIndexer\")\n\t\t}\n\t\tok, val, err := idx.FromObject(raw)\n\t\tif err != nil {\n\t\t\treturn false, nil, fmt.Errorf(\"sub-index %d error: %v\", i, err)\n\t\t}\n\t\tif !ok {\n\t\t\tif c.AllowMissing {\n\t\t\t\tbreak\n\t\t\t} else {\n\t\t\t\treturn false, nil, nil\n\t\t\t}\n\t\t}\n\t\tout = append(out, val...)\n\t}\n\treturn true, out, nil\n}\n\nfunc (c *CompoundIndex) FromArgs(args ...interface{}) ([]byte, error) {\n\tif len(args) != len(c.Indexes) {\n\t\treturn nil, fmt.Errorf(\"non-equivalent argument count and index fields\")\n\t}\n\tvar out []byte\n\tfor i, arg := range args {\n\t\tval, err := c.Indexes[i].FromArgs(arg)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"sub-index %d error: %v\", i, err)\n\t\t}\n\t\tout = append(out, val...)\n\t}\n\treturn out, nil\n}\n\nfunc (c *CompoundIndex) PrefixFromArgs(args ...interface{}) ([]byte, error) {\n\tif len(args) > len(c.Indexes) {\n\t\treturn nil, fmt.Errorf(\"more arguments than index fields\")\n\t}\n\tvar out []byte\n\tfor i, arg := range args {\n\t\tif i+1 < len(args) {\n\t\t\tval, err := c.Indexes[i].FromArgs(arg)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"sub-index %d error: %v\", i, err)\n\t\t\t}\n\t\t\tout = append(out, val...)\n\t\t} else {\n\t\t\tprefixIndexer, ok := c.Indexes[i].(PrefixIndexer)\n\t\t\tif !ok {\n\t\t\t\treturn nil, fmt.Errorf(\"sub-index %d does not support prefix scanning\", i)\n\t\t\t}\n\t\t\tval, err := prefixIndexer.PrefixFromArgs(arg)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"sub-index %d error: %v\", i, err)\n\t\t\t}\n\t\t\tout = append(out, val...)\n\t\t}\n\t}\n\treturn out, nil\n}\n\n// CompoundMultiIndex is used to build an index using multiple\n// sub-indexes.\n//\n// Unlike CompoundIndex, CompoundMultiIndex can have both\n// SingleIndexer and MultiIndexer sub-indexers. However, each\n// MultiIndexer adds considerable overhead/complexity in terms of\n// the number of indexes created under-the-hood. It is not suggested\n// to use more than one or two, if possible.\n//\n// Another change from CompoundIndexer is that if AllowMissing is\n// set, not only is it valid to have empty index fields, but it will\n// still create index values up to the first empty index. This means\n// that if you have a value with an empty field, rather than using a\n// prefix for lookup, you can simply pass in less arguments. As an\n// example, if {Foo, Bar} is indexed but Bar is missing for a value\n// and AllowMissing is set, an index will still be created for {Foo}\n// and it is valid to do a lookup passing in only Foo as an argument.\n// Note that the ordering isn't guaranteed -- it's last-insert wins,\n// but this is true if you have two objects that have the same\n// indexes not using AllowMissing anyways.\n//\n// Because StringMapFieldIndexers can take a varying number of args,\n// it is currently a requirement that whenever it is used, two\n// arguments must _always_ be provided for it. In theory we only\n// need one, except a bug in that indexer means the single-argument\n// version will never work. You can leave the second argument nil,\n// but it will never produce a value. We support this for whenever\n// that bug is fixed, likely in a next major version bump.\n//\n// Prefix-based indexing is not currently supported.\ntype CompoundMultiIndex struct {\n\tIndexes []Indexer\n\n\t// AllowMissing results in an index based on only the indexers\n\t// that return data. If true, you may end up with 2/3 columns\n\t// indexed which might be useful for an index scan. Otherwise,\n\t// CompoundMultiIndex requires all indexers to be satisfied.\n\tAllowMissing bool\n}\n\nfunc (c *CompoundMultiIndex) FromObject(raw interface{}) (bool, [][]byte, error) {\n\t// At each entry, builder is storing the results from the next index\n\tbuilder := make([][][]byte, 0, len(c.Indexes))\n\nforloop:\n\t// This loop goes through each indexer and adds the value(s) provided to the next\n\t// entry in the slice. We can then later walk it like a tree to construct the indices.\n\tfor i, idxRaw := range c.Indexes {\n\t\tswitch idx := idxRaw.(type) {\n\t\tcase SingleIndexer:\n\t\t\tok, val, err := idx.FromObject(raw)\n\t\t\tif err != nil {\n\t\t\t\treturn false, nil, fmt.Errorf(\"single sub-index %d error: %v\", i, err)\n\t\t\t}\n\t\t\tif !ok {\n\t\t\t\tif c.AllowMissing {\n\t\t\t\t\tbreak forloop\n\t\t\t\t} else {\n\t\t\t\t\treturn false, nil, nil\n\t\t\t\t}\n\t\t\t}\n\t\t\tbuilder = append(builder, [][]byte{val})\n\n\t\tcase MultiIndexer:\n\t\t\tok, vals, err := idx.FromObject(raw)\n\t\t\tif err != nil {\n\t\t\t\treturn false, nil, fmt.Errorf(\"multi sub-index %d error: %v\", i, err)\n\t\t\t}\n\t\t\tif !ok {\n\t\t\t\tif c.AllowMissing {\n\t\t\t\t\tbreak forloop\n\t\t\t\t} else {\n\t\t\t\t\treturn false, nil, nil\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Add each of the new values to each of the old values\n\t\t\tbuilder = append(builder, vals)\n\n\t\tdefault:\n\t\t\treturn false, nil, fmt.Errorf(\"sub-index %d does not satisfy either SingleIndexer or MultiIndexer\", i)\n\t\t}\n\t}\n\n\t// Start with something higher to avoid resizing if possible\n\tout := make([][]byte, 0, len(c.Indexes)^3)\n\n\t// We are walking through the builder slice essentially in a depth-first fashion,\n\t// building the prefix and leaves as we go. If AllowMissing is false, we only insert\n\t// these full paths to leaves. Otherwise, we also insert each prefix along the way.\n\t// This allows for lookup in FromArgs when AllowMissing is true that does not contain\n\t// the full set of arguments. e.g. for {Foo, Bar} where an object has only the Foo\n\t// field specified as \"abc\", it is valid to call FromArgs with just \"abc\".\n\tvar walkVals func([]byte, int)\n\twalkVals = func(currPrefix []byte, depth int) {\n\t\tif depth >= len(builder) {\n\t\t\treturn\n\t\t}\n\n\t\tif depth == len(builder)-1 {\n\t\t\t// These are the \"leaves\", so append directly\n\t\t\tfor _, v := range builder[depth] {\n\t\t\t\toutcome := make([]byte, len(currPrefix))\n\t\t\t\tcopy(outcome, currPrefix)\n\t\t\t\tout = append(out, append(outcome, v...))\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tfor _, v := range builder[depth] {\n\t\t\tnextPrefix := append(currPrefix, v...)\n\t\t\tif c.AllowMissing {\n\t\t\t\tout = append(out, nextPrefix)\n\t\t\t}\n\t\t\twalkVals(nextPrefix, depth+1)\n\t\t}\n\t}\n\n\twalkVals(nil, 0)\n\n\treturn true, out, nil\n}\n\nfunc (c *CompoundMultiIndex) FromArgs(args ...interface{}) ([]byte, error) {\n\tvar stringMapCount int\n\tvar argCount int\n\tfor _, index := range c.Indexes {\n\t\tif argCount >= len(args) {\n\t\t\tbreak\n\t\t}\n\t\tif _, ok := index.(*StringMapFieldIndex); ok {\n\t\t\t// We require pairs for StringMapFieldIndex, but only got one\n\t\t\tif argCount+1 >= len(args) {\n\t\t\t\treturn nil, errors.New(\"invalid number of arguments\")\n\t\t\t}\n\t\t\tstringMapCount++\n\t\t\targCount += 2\n\t\t} else {\n\t\t\targCount++\n\t\t}\n\t}\n\targCount = 0\n\n\tswitch c.AllowMissing {\n\tcase true:\n\t\tif len(args) > len(c.Indexes)+stringMapCount {\n\t\t\treturn nil, errors.New(\"too many arguments\")\n\t\t}\n\n\tdefault:\n\t\tif len(args) != len(c.Indexes)+stringMapCount {\n\t\t\treturn nil, errors.New(\"number of arguments does not equal number of indexers\")\n\t\t}\n\t}\n\n\tvar out []byte\n\tvar val []byte\n\tvar err error\n\tfor i, idx := range c.Indexes {\n\t\tif argCount >= len(args) {\n\t\t\t// We're done; should only hit this if AllowMissing\n\t\t\tbreak\n\t\t}\n\t\tif _, ok := idx.(*StringMapFieldIndex); ok {\n\t\t\tif args[argCount+1] == nil {\n\t\t\t\tval, err = idx.FromArgs(args[argCount])\n\t\t\t} else {\n\t\t\t\tval, err = idx.FromArgs(args[argCount : argCount+2]...)\n\t\t\t}\n\t\t\targCount += 2\n\t\t} else {\n\t\t\tval, err = idx.FromArgs(args[argCount])\n\t\t\targCount++\n\t\t}\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"sub-index %d error: %v\", i, err)\n\t\t}\n\t\tout = append(out, val...)\n\t}\n\treturn out, nil\n}\n"
        },
        {
          "name": "index_test.go",
          "type": "blob",
          "size": 31.037109375,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage memdb\n\nimport (\n\t\"bytes\"\n\tcrand \"crypto/rand\"\n\t\"encoding/binary\"\n\t\"fmt\"\n\t\"math/rand\"\n\t\"reflect\"\n\t\"sort\"\n\t\"strings\"\n\t\"testing\"\n\t\"testing/quick\"\n\t\"time\"\n)\n\ntype TestObject struct {\n\tID       string\n\tFoo      string\n\tFu       *string\n\tBoo      *string\n\tBar      int\n\tBaz      string\n\tBam      *bool\n\tEmpty    string\n\tQux      []string\n\tQuxEmpty []string\n\tZod      map[string]string\n\tZodEmpty map[string]string\n\tInt      int\n\tInt8     int8\n\tInt16    int16\n\tInt32    int32\n\tInt64    int64\n\tUint     uint\n\tUint8    uint8\n\tUint16   uint16\n\tUint32   uint32\n\tUint64   uint64\n\tBool     bool\n}\n\nfunc String(s string) *string {\n\treturn &s\n}\n\nfunc testObj() *TestObject {\n\tb := true\n\tobj := &TestObject{\n\t\tID:  \"my-cool-obj\",\n\t\tFoo: \"Testing\",\n\t\tFu:  String(\"Fu\"),\n\t\tBoo: nil,\n\t\tBar: 42,\n\t\tBaz: \"yep\",\n\t\tBam: &b,\n\t\tQux: []string{\"Test\", \"Test2\"},\n\t\tZod: map[string]string{\n\t\t\t\"Role\":          \"Server\",\n\t\t\t\"instance_type\": \"m3.medium\",\n\t\t\t\"\":              \"asdf\",\n\t\t},\n\t\tInt:    int(1),\n\t\tInt8:   int8(-1 << 7),\n\t\tInt16:  int16(-1 << 15),\n\t\tInt32:  int32(-1 << 31),\n\t\tInt64:  int64(-1 << 63),\n\t\tUint:   uint(1),\n\t\tUint8:  uint8(1<<8 - 1),\n\t\tUint16: uint16(1<<16 - 1),\n\t\tUint32: uint32(1<<32 - 1),\n\t\tUint64: uint64(1<<64 - 1),\n\t\tBool:   false,\n\t}\n\treturn obj\n}\n\nfunc TestStringFieldIndex_FromObject(t *testing.T) {\n\tobj := testObj()\n\tindexer := StringFieldIndex{\"Foo\", false}\n\n\tok, val, err := indexer.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif string(val) != \"Testing\\x00\" {\n\t\tt.Fatalf(\"bad: %s\", val)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"should be ok\")\n\t}\n\n\tlower := StringFieldIndex{\"Foo\", true}\n\tok, val, err = lower.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif string(val) != \"testing\\x00\" {\n\t\tt.Fatalf(\"bad: %s\", val)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"should be ok\")\n\t}\n\n\tbadField := StringFieldIndex{\"NA\", true}\n\tok, val, err = badField.FromObject(obj)\n\tif err == nil {\n\t\tt.Fatalf(\"should get error\")\n\t}\n\n\temptyField := StringFieldIndex{\"Empty\", true}\n\tok, val, err = emptyField.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif ok {\n\t\tt.Fatalf(\"should not ok\")\n\t}\n\n\tpointerField := StringFieldIndex{\"Fu\", false}\n\tok, val, err = pointerField.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif string(val) != \"Fu\\x00\" {\n\t\tt.Fatalf(\"bad: %s\", val)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"should be ok\")\n\t}\n\n\tpointerField = StringFieldIndex{\"Boo\", false}\n\tok, val, err = pointerField.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif string(val) != \"\" {\n\t\tt.Fatalf(\"bad: %s\", val)\n\t}\n\tif ok {\n\t\tt.Fatalf(\"should be not ok\")\n\t}\n}\n\nfunc TestStringFieldIndex_FromArgs(t *testing.T) {\n\tindexer := StringFieldIndex{\"Foo\", false}\n\t_, err := indexer.FromArgs()\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\t_, err = indexer.FromArgs(42)\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\tval, err := indexer.FromArgs(\"foo\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif string(val) != \"foo\\x00\" {\n\t\tt.Fatalf(\"foo\")\n\t}\n\n\tlower := StringFieldIndex{\"Foo\", true}\n\tval, err = lower.FromArgs(\"Foo\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif string(val) != \"foo\\x00\" {\n\t\tt.Fatalf(\"foo\")\n\t}\n}\n\nfunc TestStringFieldIndex_PrefixFromArgs(t *testing.T) {\n\tindexer := StringFieldIndex{\"Foo\", false}\n\t_, err := indexer.FromArgs()\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\t_, err = indexer.PrefixFromArgs(42)\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\tval, err := indexer.PrefixFromArgs(\"foo\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif string(val) != \"foo\" {\n\t\tt.Fatalf(\"foo\")\n\t}\n\n\tlower := StringFieldIndex{\"Foo\", true}\n\tval, err = lower.PrefixFromArgs(\"Foo\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif string(val) != \"foo\" {\n\t\tt.Fatalf(\"foo\")\n\t}\n}\n\nfunc TestStringSliceFieldIndex_FromObject(t *testing.T) {\n\tobj := testObj()\n\n\tindexer := StringSliceFieldIndex{\"Qux\", false}\n\tok, vals, err := indexer.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif len(vals) != 2 {\n\t\tt.Fatal(\"bad result length\")\n\t}\n\tif string(vals[0]) != \"Test\\x00\" {\n\t\tt.Fatalf(\"bad: %s\", vals[0])\n\t}\n\tif string(vals[1]) != \"Test2\\x00\" {\n\t\tt.Fatalf(\"bad: %s\", vals[1])\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"should be ok\")\n\t}\n\n\tlower := StringSliceFieldIndex{\"Qux\", true}\n\tok, vals, err = lower.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif len(vals) != 2 {\n\t\tt.Fatal(\"bad result length\")\n\t}\n\tif string(vals[0]) != \"test\\x00\" {\n\t\tt.Fatalf(\"bad: %s\", vals[0])\n\t}\n\tif string(vals[1]) != \"test2\\x00\" {\n\t\tt.Fatalf(\"bad: %s\", vals[1])\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"should be ok\")\n\t}\n\n\tbadField := StringSliceFieldIndex{\"NA\", true}\n\tok, vals, err = badField.FromObject(obj)\n\tif err == nil {\n\t\tt.Fatalf(\"should get error\")\n\t}\n\n\temptyField := StringSliceFieldIndex{\"QuxEmpty\", true}\n\tok, vals, err = emptyField.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif ok {\n\t\tt.Fatalf(\"should not ok\")\n\t}\n}\n\nfunc TestStringSliceFieldIndex_FromArgs(t *testing.T) {\n\tindexer := StringSliceFieldIndex{\"Qux\", false}\n\t_, err := indexer.FromArgs()\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\t_, err = indexer.FromArgs(42)\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\tval, err := indexer.FromArgs(\"foo\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif string(val) != \"foo\\x00\" {\n\t\tt.Fatalf(\"foo\")\n\t}\n\n\tlower := StringSliceFieldIndex{\"Qux\", true}\n\tval, err = lower.FromArgs(\"Foo\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif string(val) != \"foo\\x00\" {\n\t\tt.Fatalf(\"foo\")\n\t}\n}\n\nfunc TestStringSliceFieldIndex_PrefixFromArgs(t *testing.T) {\n\tindexer := StringSliceFieldIndex{\"Qux\", false}\n\t_, err := indexer.FromArgs()\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\t_, err = indexer.PrefixFromArgs(42)\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\tval, err := indexer.PrefixFromArgs(\"foo\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif string(val) != \"foo\" {\n\t\tt.Fatalf(\"foo\")\n\t}\n\n\tlower := StringSliceFieldIndex{\"Qux\", true}\n\tval, err = lower.PrefixFromArgs(\"Foo\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif string(val) != \"foo\" {\n\t\tt.Fatalf(\"foo\")\n\t}\n}\n\nfunc TestStringMapFieldIndex_FromObject(t *testing.T) {\n\t// Helper function to put the result in a deterministic order\n\tfromObjectSorted := func(index MultiIndexer, obj *TestObject) (bool, []string, error) {\n\t\tok, v, err := index.FromObject(obj)\n\t\tvar vals []string\n\t\tfor _, s := range v {\n\t\t\tvals = append(vals, string(s))\n\t\t}\n\t\tsort.Strings(vals)\n\t\treturn ok, vals, err\n\t}\n\n\tobj := testObj()\n\n\tindexer := StringMapFieldIndex{\"Zod\", false}\n\tok, vals, err := fromObjectSorted(&indexer, obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif len(vals) != 2 {\n\t\tt.Fatalf(\"bad result length of %d\", len(vals))\n\t}\n\tif string(vals[0]) != \"Role\\x00Server\\x00\" {\n\t\tt.Fatalf(\"bad: %s\", vals[0])\n\t}\n\tif string(vals[1]) != \"instance_type\\x00m3.medium\\x00\" {\n\t\tt.Fatalf(\"bad: %s\", vals[1])\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"should be ok\")\n\t}\n\n\tlower := StringMapFieldIndex{\"Zod\", true}\n\tok, vals, err = fromObjectSorted(&lower, obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif len(vals) != 2 {\n\t\tt.Fatal(\"bad result length\")\n\t}\n\tif string(vals[0]) != \"instance_type\\x00m3.medium\\x00\" {\n\t\tt.Fatalf(\"bad: %s\", vals[0])\n\t}\n\tif string(vals[1]) != \"role\\x00server\\x00\" {\n\t\tt.Fatalf(\"bad: %s\", vals[1])\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"should be ok\")\n\t}\n\n\tbadField := StringMapFieldIndex{\"NA\", true}\n\tok, _, err = badField.FromObject(obj)\n\tif err == nil {\n\t\tt.Fatalf(\"should get error\")\n\t}\n\n\temptyField := StringMapFieldIndex{\"ZodEmpty\", true}\n\tok, _, err = emptyField.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif ok {\n\t\tt.Fatalf(\"should not ok\")\n\t}\n}\n\nfunc TestStringMapFieldIndex_FromArgs(t *testing.T) {\n\tindexer := StringMapFieldIndex{\"Zod\", false}\n\t_, err := indexer.FromArgs()\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\t_, err = indexer.FromArgs(42)\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\tval, err := indexer.FromArgs(\"Role\", \"Server\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif string(val) != \"Role\\x00Server\\x00\" {\n\t\tt.Fatalf(\"bad: %v\", string(val))\n\t}\n\n\tlower := StringMapFieldIndex{\"Zod\", true}\n\tval, err = lower.FromArgs(\"Role\", \"Server\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif string(val) != \"role\\x00server\\x00\" {\n\t\tt.Fatalf(\"bad: %v\", string(val))\n\t}\n}\n\nfunc TestUUIDFeldIndex_parseString(t *testing.T) {\n\tu := &UUIDFieldIndex{}\n\t_, err := u.parseString(\"invalid\", true)\n\tif err == nil {\n\t\tt.Fatalf(\"should error\")\n\t}\n\n\tbuf, uuid := generateUUID()\n\n\tout, err := u.parseString(uuid, true)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\tif !bytes.Equal(out, buf) {\n\t\tt.Fatalf(\"bad: %#v %#v\", out, buf)\n\t}\n\n\t_, err = u.parseString(\"1-2-3-4-5-6\", false)\n\tif err == nil {\n\t\tt.Fatalf(\"should error\")\n\t}\n\n\t// Parse an empty string.\n\tout, err = u.parseString(\"\", false)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\texpected := []byte{}\n\tif !bytes.Equal(out, expected) {\n\t\tt.Fatalf(\"bad: %#v %#v\", out, expected)\n\t}\n\n\t// Parse an odd length UUID.\n\tinput := \"f23\"\n\tout, err = u.parseString(input, false)\n\tif err == nil {\n\t\tt.Fatalf(\"expect error\")\n\t}\n\n\t// Parse an even length UUID with hyphen.\n\tinput = \"20d8c509-3940-\"\n\tout, err = u.parseString(input, false)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\texpected = []byte{0x20, 0xd8, 0xc5, 0x09, 0x39, 0x40}\n\tif !bytes.Equal(out, expected) {\n\t\tt.Fatalf(\"bad: %#v %#v\", out, expected)\n\t}\n}\n\nfunc TestUUIDFieldIndex_FromObject(t *testing.T) {\n\tobj := testObj()\n\tuuidBuf, uuid := generateUUID()\n\tobj.Foo = uuid\n\tindexer := &UUIDFieldIndex{\"Foo\"}\n\n\tok, val, err := indexer.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif !bytes.Equal(uuidBuf, val) {\n\t\tt.Fatalf(\"bad: %s\", val)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"should be ok\")\n\t}\n\n\tbadField := &UUIDFieldIndex{\"NA\"}\n\tok, val, err = badField.FromObject(obj)\n\tif err == nil {\n\t\tt.Fatalf(\"should get error\")\n\t}\n\n\temptyField := &UUIDFieldIndex{\"Empty\"}\n\tok, val, err = emptyField.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif ok {\n\t\tt.Fatalf(\"should not ok\")\n\t}\n}\n\nfunc TestUUIDFieldIndex_FromArgs(t *testing.T) {\n\tindexer := &UUIDFieldIndex{\"Foo\"}\n\t_, err := indexer.FromArgs()\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\t_, err = indexer.FromArgs(42)\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\tuuidBuf, uuid := generateUUID()\n\n\tval, err := indexer.FromArgs(uuid)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif !bytes.Equal(uuidBuf, val) {\n\t\tt.Fatalf(\"foo\")\n\t}\n\n\tval, err = indexer.FromArgs(uuidBuf)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif !bytes.Equal(uuidBuf, val) {\n\t\tt.Fatalf(\"foo\")\n\t}\n}\n\nfunc TestUUIDFieldIndex_PrefixFromArgs(t *testing.T) {\n\tindexer := UUIDFieldIndex{\"Foo\"}\n\t_, err := indexer.FromArgs()\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\t_, err = indexer.PrefixFromArgs(42)\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\tuuidBuf, uuid := generateUUID()\n\n\t// Test full length.\n\tval, err := indexer.PrefixFromArgs(uuid)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif !bytes.Equal(uuidBuf, val) {\n\t\tt.Fatalf(\"foo\")\n\t}\n\n\tval, err = indexer.PrefixFromArgs(uuidBuf)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif !bytes.Equal(uuidBuf, val) {\n\t\tt.Fatalf(\"foo\")\n\t}\n\n\t// Test partial.\n\tval, err = indexer.PrefixFromArgs(uuid[:6])\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif !bytes.Equal(uuidBuf[:3], val) {\n\t\tt.Fatalf(\"PrefixFromArgs returned %#v;\\nwant %#v\", val, uuidBuf[:3])\n\t}\n\n\tval, err = indexer.PrefixFromArgs(uuidBuf[:9])\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif !bytes.Equal(uuidBuf[:9], val) {\n\t\tt.Fatalf(\"foo\")\n\t}\n}\n\nfunc BenchmarkUUIDFieldIndex_parseString(b *testing.B) {\n\t_, uuid := generateUUID()\n\tindexer := &UUIDFieldIndex{}\n\tfor i := 0; i < b.N; i++ {\n\t\t_, err := indexer.parseString(uuid, true)\n\t\tif err != nil {\n\t\t\tb.FailNow()\n\t\t}\n\t}\n}\n\nfunc generateUUID() ([]byte, string) {\n\tbuf := make([]byte, 16)\n\tif _, err := crand.Read(buf); err != nil {\n\t\tpanic(fmt.Errorf(\"failed to read random bytes: %v\", err))\n\t}\n\tuuid := fmt.Sprintf(\"%08x-%04x-%04x-%04x-%12x\",\n\t\tbuf[0:4],\n\t\tbuf[4:6],\n\t\tbuf[6:8],\n\t\tbuf[8:10],\n\t\tbuf[10:16])\n\treturn buf, uuid\n}\n\nfunc TestIntFieldIndex_FromObject(t *testing.T) {\n\tobj := testObj()\n\n\teint := make([]byte, 8)\n\teint8 := make([]byte, 1)\n\teint16 := make([]byte, 2)\n\teint32 := make([]byte, 4)\n\teint64 := make([]byte, 8)\n\tbinary.BigEndian.PutUint64(eint, 1<<63+1)\n\teint8[0] = 0\n\tbinary.BigEndian.PutUint16(eint16, 0)\n\tbinary.BigEndian.PutUint32(eint32, 0)\n\tbinary.BigEndian.PutUint64(eint64, 0)\n\n\tcases := []struct {\n\t\tField         string\n\t\tExpected      []byte\n\t\tErrorContains string\n\t}{\n\t\t{\n\t\t\tField:    \"Int\",\n\t\t\tExpected: eint,\n\t\t},\n\t\t{\n\t\t\tField:    \"Int8\",\n\t\t\tExpected: eint8,\n\t\t},\n\t\t{\n\t\t\tField:    \"Int16\",\n\t\t\tExpected: eint16,\n\t\t},\n\t\t{\n\t\t\tField:    \"Int32\",\n\t\t\tExpected: eint32,\n\t\t},\n\t\t{\n\t\t\tField:    \"Int64\",\n\t\t\tExpected: eint64,\n\t\t},\n\t\t{\n\t\t\tField:         \"IntGarbage\",\n\t\t\tErrorContains: \"is invalid\",\n\t\t},\n\t\t{\n\t\t\tField:         \"ID\",\n\t\t\tErrorContains: \"want an int\",\n\t\t},\n\t}\n\n\tfor _, c := range cases {\n\t\tt.Run(c.Field, func(t *testing.T) {\n\t\t\tindexer := IntFieldIndex{c.Field}\n\t\t\tok, val, err := indexer.FromObject(obj)\n\t\t\tif err != nil {\n\t\t\t\tif ok {\n\t\t\t\t\tt.Fatalf(\"okay and error\")\n\t\t\t\t}\n\n\t\t\t\tif c.ErrorContains != \"\" && strings.Contains(err.Error(), c.ErrorContains) {\n\t\t\t\t\treturn\n\t\t\t\t} else {\n\t\t\t\t\tt.Fatalf(\"Unexpected error %v\", err)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif !ok {\n\t\t\t\tt.Fatalf(\"not okay and no error\")\n\t\t\t}\n\n\t\t\tif !bytes.Equal(val, c.Expected) {\n\t\t\t\tt.Fatalf(\"bad: %#v %#v\", val, c.Expected)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestIntFieldIndex_FromArgs(t *testing.T) {\n\tindexer := IntFieldIndex{\"Foo\"}\n\t_, err := indexer.FromArgs()\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\t_, err = indexer.FromArgs(int(1), int(2))\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\t_, err = indexer.FromArgs(\"foo\")\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\tobj := testObj()\n\teint := make([]byte, 8)\n\teint8 := make([]byte, 1)\n\teint16 := make([]byte, 2)\n\teint32 := make([]byte, 4)\n\teint64 := make([]byte, 8)\n\tbinary.BigEndian.PutUint64(eint, 1<<63+1)\n\teint8[0] = 0\n\tbinary.BigEndian.PutUint16(eint16, 0)\n\tbinary.BigEndian.PutUint32(eint32, 0)\n\tbinary.BigEndian.PutUint64(eint64, 0)\n\n\tval, err := indexer.FromArgs(obj.Int)\n\tif err != nil {\n\t\tt.Fatalf(\"bad: %v\", err)\n\t}\n\tif !bytes.Equal(val, eint) {\n\t\tt.Fatalf(\"bad: %#v %#v\", val, eint)\n\t}\n\n\tval, err = indexer.FromArgs(obj.Int8)\n\tif err != nil {\n\t\tt.Fatalf(\"bad: %v\", err)\n\t}\n\tif !bytes.Equal(val, eint8) {\n\t\tt.Fatalf(\"bad: %#v %#v\", val, eint8)\n\t}\n\n\tval, err = indexer.FromArgs(obj.Int16)\n\tif err != nil {\n\t\tt.Fatalf(\"bad: %v\", err)\n\t}\n\tif !bytes.Equal(val, eint16) {\n\t\tt.Fatalf(\"bad: %#v %#v\", val, eint16)\n\t}\n\n\tval, err = indexer.FromArgs(obj.Int32)\n\tif err != nil {\n\t\tt.Fatalf(\"bad: %v\", err)\n\t}\n\tif !bytes.Equal(val, eint32) {\n\t\tt.Fatalf(\"bad: %#v %#v\", val, eint32)\n\t}\n\n\tval, err = indexer.FromArgs(obj.Int64)\n\tif err != nil {\n\t\tt.Fatalf(\"bad: %v\", err)\n\t}\n\tif !bytes.Equal(val, eint64) {\n\t\tt.Fatalf(\"bad: %#v %#v\", val, eint64)\n\t}\n}\n\nfunc TestIntFieldIndexSortability(t *testing.T) {\n\ttestCases := []struct {\n\t\ti8l      int8\n\t\ti8r      int8\n\t\ti16l     int16\n\t\ti16r     int16\n\t\ti32l     int32\n\t\ti32r     int32\n\t\ti64l     int64\n\t\ti64r     int64\n\t\til       int\n\t\tir       int\n\t\texpected int\n\t\tname     string\n\t}{\n\t\t{0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \"zero\"},\n\t\t{1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, \"small eq\"},\n\t\t{0, 1, 0, 1, 0, 1, 0, 1, 0, 1, -1, \"small lt\"},\n\t\t{2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, \"small gt\"},\n\t\t{-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, \"small neg eq\"},\n\t\t{-2, -1, -2, -1, -2, -1, -2, -1, -2, -1, -1, \"small neg lt\"},\n\t\t{-1, -2, -1, -2, -1, -2, -1, -2, -1, -2, 1, \"small neg gt\"},\n\t\t{-1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, \"neg vs pos\"},\n\t\t{-128, 127, -32768, 32767, -2147483648, 2147483647, -9223372036854775808, 9223372036854775807, -9223372036854775808, 9223372036854775807, -1, \"max conditions\"},\n\t\t{100, 127, 1000, 2000, 1000000000, 2000000000, 10000000000, 20000000000, 1000000000, 2000000000, -1, \"large lt\"},\n\t\t{100, 99, 1000, 999, 1000000000, 999999999, 10000000000, 9999999999, 1000000000, 999999999, 1, \"large gt\"},\n\t\t{126, 127, 255, 256, 65535, 65536, 4294967295, 4294967296, 65535, 65536, -1, \"edge conditions\"},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tcompareEncoded(t, &IntFieldIndex{\"Foo\"}, tc.i8l, tc.i8r, tc.expected)\n\t\t\tcompareEncoded(t, &IntFieldIndex{\"Foo\"}, tc.i16l, tc.i16r, tc.expected)\n\t\t\tcompareEncoded(t, &IntFieldIndex{\"Foo\"}, tc.i32l, tc.i32r, tc.expected)\n\t\t\tcompareEncoded(t, &IntFieldIndex{\"Foo\"}, tc.i64l, tc.i64r, tc.expected)\n\t\t\tcompareEncoded(t, &IntFieldIndex{\"Foo\"}, tc.il, tc.ir, tc.expected)\n\t\t})\n\t}\n}\n\nfunc TestUintFieldIndex_FromObject(t *testing.T) {\n\tobj := testObj()\n\n\teuint := make([]byte, 8)\n\teuint8 := make([]byte, 1)\n\teuint16 := make([]byte, 2)\n\teuint32 := make([]byte, 4)\n\teuint64 := make([]byte, 8)\n\tbinary.BigEndian.PutUint64(euint, uint64(obj.Uint))\n\teuint8[0] = obj.Uint8\n\tbinary.BigEndian.PutUint16(euint16, obj.Uint16)\n\tbinary.BigEndian.PutUint32(euint32, obj.Uint32)\n\tbinary.BigEndian.PutUint64(euint64, obj.Uint64)\n\n\tcases := []struct {\n\t\tField         string\n\t\tExpected      []byte\n\t\tErrorContains string\n\t}{\n\t\t{\n\t\t\tField:    \"Uint\",\n\t\t\tExpected: euint,\n\t\t},\n\t\t{\n\t\t\tField:    \"Uint8\",\n\t\t\tExpected: euint8,\n\t\t},\n\t\t{\n\t\t\tField:    \"Uint16\",\n\t\t\tExpected: euint16,\n\t\t},\n\t\t{\n\t\t\tField:    \"Uint32\",\n\t\t\tExpected: euint32,\n\t\t},\n\t\t{\n\t\t\tField:    \"Uint64\",\n\t\t\tExpected: euint64,\n\t\t},\n\t\t{\n\t\t\tField:         \"UintGarbage\",\n\t\t\tErrorContains: \"is invalid\",\n\t\t},\n\t\t{\n\t\t\tField:         \"ID\",\n\t\t\tErrorContains: \"want a uint\",\n\t\t},\n\t}\n\n\tfor _, c := range cases {\n\t\tt.Run(c.Field, func(t *testing.T) {\n\t\t\tindexer := UintFieldIndex{c.Field}\n\t\t\tok, val, err := indexer.FromObject(obj)\n\t\t\tif err != nil {\n\t\t\t\tif ok {\n\t\t\t\t\tt.Fatalf(\"okay and error\")\n\t\t\t\t}\n\n\t\t\t\tif c.ErrorContains != \"\" && strings.Contains(err.Error(), c.ErrorContains) {\n\t\t\t\t\treturn\n\t\t\t\t} else {\n\t\t\t\t\tt.Fatalf(\"Unexpected error %v\", err)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif !ok {\n\t\t\t\tt.Fatalf(\"not okay and no error\")\n\t\t\t}\n\n\t\t\tif !bytes.Equal(val, c.Expected) {\n\t\t\t\tt.Fatalf(\"bad: %#v %#v\", val, c.Expected)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestUintFieldIndex_FromArgs(t *testing.T) {\n\tindexer := UintFieldIndex{\"Foo\"}\n\t_, err := indexer.FromArgs()\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\t_, err = indexer.FromArgs(uint(1), uint(2))\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\t_, err = indexer.FromArgs(\"foo\")\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\tobj := testObj()\n\teuint := make([]byte, 8)\n\teuint8 := make([]byte, 1)\n\teuint16 := make([]byte, 2)\n\teuint32 := make([]byte, 4)\n\teuint64 := make([]byte, 8)\n\tbinary.BigEndian.PutUint64(euint, uint64(obj.Uint))\n\teuint8[0] = obj.Uint8\n\tbinary.BigEndian.PutUint16(euint16, obj.Uint16)\n\tbinary.BigEndian.PutUint32(euint32, obj.Uint32)\n\tbinary.BigEndian.PutUint64(euint64, obj.Uint64)\n\n\tval, err := indexer.FromArgs(obj.Uint)\n\tif err != nil {\n\t\tt.Fatalf(\"bad: %v\", err)\n\t}\n\tif !bytes.Equal(val, euint) {\n\t\tt.Fatalf(\"bad: %#v %#v\", val, euint)\n\t}\n\n\tval, err = indexer.FromArgs(obj.Uint8)\n\tif err != nil {\n\t\tt.Fatalf(\"bad: %v\", err)\n\t}\n\tif !bytes.Equal(val, euint8) {\n\t\tt.Fatalf(\"bad: %#v %#v\", val, euint8)\n\t}\n\n\tval, err = indexer.FromArgs(obj.Uint16)\n\tif err != nil {\n\t\tt.Fatalf(\"bad: %v\", err)\n\t}\n\tif !bytes.Equal(val, euint16) {\n\t\tt.Fatalf(\"bad: %#v %#v\", val, euint16)\n\t}\n\n\tval, err = indexer.FromArgs(obj.Uint32)\n\tif err != nil {\n\t\tt.Fatalf(\"bad: %v\", err)\n\t}\n\tif !bytes.Equal(val, euint32) {\n\t\tt.Fatalf(\"bad: %#v %#v\", val, euint32)\n\t}\n\n\tval, err = indexer.FromArgs(obj.Uint64)\n\tif err != nil {\n\t\tt.Fatalf(\"bad: %v\", err)\n\t}\n\tif !bytes.Equal(val, euint64) {\n\t\tt.Fatalf(\"bad: %#v %#v\", val, euint64)\n\t}\n}\n\nfunc TestUIntFieldIndexSortability(t *testing.T) {\n\ttestCases := []struct {\n\t\tu8l      uint8\n\t\tu8r      uint8\n\t\tu16l     uint16\n\t\tu16r     uint16\n\t\tu32l     uint32\n\t\tu32r     uint32\n\t\tu64l     uint64\n\t\tu64r     uint64\n\t\tul       uint\n\t\tur       uint\n\t\texpected int\n\t\tname     string\n\t}{\n\t\t{0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \"zero\"},\n\t\t{1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, \"small eq\"},\n\t\t{0, 1, 0, 1, 0, 1, 0, 1, 0, 1, -1, \"small lt\"},\n\t\t{2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, \"small gt\"},\n\t\t{100, 200, 1000, 2000, 1000000000, 2000000000, 10000000000, 20000000000, 1000000000, 2000000000, -1, \"large lt\"},\n\t\t{100, 99, 1000, 999, 1000000000, 999999999, 10000000000, 9999999999, 1000000000, 999999999, 1, \"large gt\"},\n\t\t{127, 128, 255, 256, 65535, 65536, 4294967295, 4294967296, 65535, 65536, -1, \"edge conditions\"},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tcompareEncoded(t, &UintFieldIndex{\"Foo\"}, tc.u8l, tc.u8r, tc.expected)\n\t\t\tcompareEncoded(t, &UintFieldIndex{\"Foo\"}, tc.u16l, tc.u16r, tc.expected)\n\t\t\tcompareEncoded(t, &UintFieldIndex{\"Foo\"}, tc.u32l, tc.u32r, tc.expected)\n\t\t\tcompareEncoded(t, &UintFieldIndex{\"Foo\"}, tc.u64l, tc.u64r, tc.expected)\n\t\t\tcompareEncoded(t, &UintFieldIndex{\"Foo\"}, tc.ul, tc.ur, tc.expected)\n\t\t})\n\t}\n}\n\nfunc compareEncoded(t *testing.T, indexer Indexer, l interface{}, r interface{}, expected int) {\n\tlBytes, err := indexer.FromArgs(l)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to encode %d: %s\", l, err)\n\t}\n\trBytes, err := indexer.FromArgs(r)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to encode %d: %s\", r, err)\n\t}\n\n\tif bytes.Compare(lBytes, rBytes) != expected {\n\t\tt.Fatalf(\"Compare(%#v, %#v) != %d\", lBytes, rBytes, expected)\n\t}\n}\n\nfunc TestBoolFieldIndex_FromObject(t *testing.T) {\n\tobj := testObj()\n\tindexer := BoolFieldIndex{Field: \"Bool\"}\n\n\tobj.Bool = false\n\tok, val, err := indexer.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"should be ok\")\n\t}\n\tif len(val) != 1 || val[0] != 0 {\n\t\tt.Fatalf(\"bad: %v\", val)\n\t}\n\n\tobj.Bool = true\n\tok, val, err = indexer.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"should be ok\")\n\t}\n\tif len(val) != 1 || val[0] != 1 {\n\t\tt.Fatalf(\"bad: %v\", val)\n\t}\n\n\tindexer = BoolFieldIndex{Field: \"NA\"}\n\tok, val, err = indexer.FromObject(obj)\n\tif err == nil {\n\t\tt.Fatalf(\"should get error\")\n\t}\n\n\tindexer = BoolFieldIndex{Field: \"ID\"}\n\tok, val, err = indexer.FromObject(obj)\n\tif err == nil {\n\t\tt.Fatalf(\"should get error\")\n\t}\n}\n\nfunc TestBoolFieldIndex_FromArgs(t *testing.T) {\n\tindexer := BoolFieldIndex{Field: \"Bool\"}\n\n\tval, err := indexer.FromArgs()\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\tval, err = indexer.FromArgs(42)\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\tval, err = indexer.FromArgs(true)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif len(val) != 1 || val[0] != 1 {\n\t\tt.Fatalf(\"bad: %v\", val)\n\t}\n\n\tval, err = indexer.FromArgs(false)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif len(val) != 1 || val[0] != 0 {\n\t\tt.Fatalf(\"bad: %v\", val)\n\t}\n}\n\nfunc TestFieldSetIndex_FromObject(t *testing.T) {\n\tobj := testObj()\n\tindexer := FieldSetIndex{\"Bam\"}\n\n\tok, val, err := indexer.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"should be ok\")\n\t}\n\tif len(val) != 1 || val[0] != 1 {\n\t\tt.Fatalf(\"bad: %v\", val)\n\t}\n\n\temptyIndexer := FieldSetIndex{\"Empty\"}\n\tok, val, err = emptyIndexer.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"should be ok\")\n\t}\n\tif len(val) != 1 || val[0] != 0 {\n\t\tt.Fatalf(\"bad: %v\", val)\n\t}\n\n\tsetIndexer := FieldSetIndex{\"Bar\"}\n\tok, val, err = setIndexer.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif len(val) != 1 || val[0] != 1 {\n\t\tt.Fatalf(\"bad: %v\", val)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"should be ok\")\n\t}\n\n\tbadField := FieldSetIndex{\"NA\"}\n\tok, val, err = badField.FromObject(obj)\n\tif err == nil {\n\t\tt.Fatalf(\"should get error\")\n\t}\n\n\tobj.Bam = nil\n\tnilIndexer := FieldSetIndex{\"Bam\"}\n\tok, val, err = nilIndexer.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"should be ok\")\n\t}\n\tif len(val) != 1 || val[0] != 0 {\n\t\tt.Fatalf(\"bad: %v\", val)\n\t}\n}\n\nfunc TestFieldSetIndex_FromArgs(t *testing.T) {\n\tindexer := FieldSetIndex{\"Bam\"}\n\t_, err := indexer.FromArgs()\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\t_, err = indexer.FromArgs(42)\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\tval, err := indexer.FromArgs(true)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif len(val) != 1 || val[0] != 1 {\n\t\tt.Fatalf(\"bad: %v\", val)\n\t}\n\n\tval, err = indexer.FromArgs(false)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif len(val) != 1 || val[0] != 0 {\n\t\tt.Fatalf(\"bad: %v\", val)\n\t}\n}\n\n// A conditional that checks if TestObject.Bar == 42\nvar conditional = func(obj interface{}) (bool, error) {\n\ttest, ok := obj.(*TestObject)\n\tif !ok {\n\t\treturn false, fmt.Errorf(\"Expect only TestObj types\")\n\t}\n\n\tif test.Bar != 42 {\n\t\treturn false, nil\n\t}\n\n\treturn true, nil\n}\n\nfunc TestConditionalIndex_FromObject(t *testing.T) {\n\tobj := testObj()\n\tindexer := ConditionalIndex{conditional}\n\tobj.Bar = 42\n\tok, val, err := indexer.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"should be ok\")\n\t}\n\tif len(val) != 1 || val[0] != 1 {\n\t\tt.Fatalf(\"bad: %v\", val)\n\t}\n\n\t// Change the object so it should return false.\n\tobj.Bar = 2\n\tok, val, err = indexer.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"should be ok\")\n\t}\n\tif len(val) != 1 || val[0] != 0 {\n\t\tt.Fatalf(\"bad: %v\", val)\n\t}\n\n\t// Pass an invalid type.\n\tok, val, err = indexer.FromObject(t)\n\tif err == nil {\n\t\tt.Fatalf(\"expected an error when passing invalid type\")\n\t}\n}\n\nfunc TestConditionalIndex_FromArgs(t *testing.T) {\n\tindexer := ConditionalIndex{conditional}\n\t_, err := indexer.FromArgs()\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\t_, err = indexer.FromArgs(42)\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\tval, err := indexer.FromArgs(true)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif len(val) != 1 || val[0] != 1 {\n\t\tt.Fatalf(\"bad: %v\", val)\n\t}\n\n\tval, err = indexer.FromArgs(false)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif len(val) != 1 || val[0] != 0 {\n\t\tt.Fatalf(\"bad: %v\", val)\n\t}\n}\n\nfunc TestCompoundIndex_FromObject(t *testing.T) {\n\tobj := testObj()\n\tindexer := &CompoundIndex{\n\t\tIndexes: []Indexer{\n\t\t\t&StringFieldIndex{\"ID\", false},\n\t\t\t&StringFieldIndex{\"Foo\", false},\n\t\t\t&StringFieldIndex{\"Baz\", false},\n\t\t},\n\t\tAllowMissing: false,\n\t}\n\n\tok, val, err := indexer.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif string(val) != \"my-cool-obj\\x00Testing\\x00yep\\x00\" {\n\t\tt.Fatalf(\"bad: %s\", val)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"should be ok\")\n\t}\n\n\tmissing := &CompoundIndex{\n\t\tIndexes: []Indexer{\n\t\t\t&StringFieldIndex{\"ID\", false},\n\t\t\t&StringFieldIndex{\"Foo\", true},\n\t\t\t&StringFieldIndex{\"Empty\", false},\n\t\t},\n\t\tAllowMissing: true,\n\t}\n\tok, val, err = missing.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif string(val) != \"my-cool-obj\\x00testing\\x00\" {\n\t\tt.Fatalf(\"bad: %s\", val)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"should be ok\")\n\t}\n\n\t// Test when missing not allowed\n\tmissing.AllowMissing = false\n\tok, _, err = missing.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif ok {\n\t\tt.Fatalf(\"should not be okay\")\n\t}\n}\n\nfunc TestCompoundIndex_FromArgs(t *testing.T) {\n\tindexer := &CompoundIndex{\n\t\tIndexes: []Indexer{\n\t\t\t&StringFieldIndex{\"ID\", false},\n\t\t\t&StringFieldIndex{\"Foo\", false},\n\t\t\t&StringFieldIndex{\"Baz\", false},\n\t\t},\n\t\tAllowMissing: false,\n\t}\n\t_, err := indexer.FromArgs()\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\t_, err = indexer.FromArgs(42, 42, 42)\n\tif err == nil {\n\t\tt.Fatalf(\"should get err\")\n\t}\n\n\tval, err := indexer.FromArgs(\"foo\", \"bar\", \"baz\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif string(val) != \"foo\\x00bar\\x00baz\\x00\" {\n\t\tt.Fatalf(\"bad: %s\", val)\n\t}\n}\n\nfunc TestCompoundIndex_PrefixFromArgs(t *testing.T) {\n\tindexer := &CompoundIndex{\n\t\tIndexes: []Indexer{\n\t\t\t&UUIDFieldIndex{\"ID\"},\n\t\t\t&StringFieldIndex{\"Foo\", false},\n\t\t\t&StringFieldIndex{\"Baz\", false},\n\t\t},\n\t\tAllowMissing: false,\n\t}\n\tval, err := indexer.PrefixFromArgs()\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif len(val) != 0 {\n\t\tt.Fatalf(\"bad: %s\", val)\n\t}\n\n\tuuidBuf, uuid := generateUUID()\n\tval, err = indexer.PrefixFromArgs(uuid, \"foo\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif !bytes.Equal(val[:16], uuidBuf) {\n\t\tt.Fatalf(\"bad prefix\")\n\t}\n\tif string(val[16:]) != \"foo\" {\n\t\tt.Fatalf(\"bad: %s\", val)\n\t}\n\n\tval, err = indexer.PrefixFromArgs(uuid, \"foo\", \"ba\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif !bytes.Equal(val[:16], uuidBuf) {\n\t\tt.Fatalf(\"bad prefix\")\n\t}\n\tif string(val[16:]) != \"foo\\x00ba\" {\n\t\tt.Fatalf(\"bad: %s\", val)\n\t}\n\n\t_, err = indexer.PrefixFromArgs(uuid, \"foo\", \"bar\", \"nope\")\n\tif err == nil {\n\t\tt.Fatalf(\"expected an error when passing too many arguments\")\n\t}\n}\n\nfunc TestCompoundMultiIndex_FromObject(t *testing.T) {\n\t// handle sub-indexer case unique to MultiIndexer\n\tobj := &TestObject{\n\t\tID:       \"obj1-uuid\",\n\t\tFoo:      \"Foo1\",\n\t\tBaz:      \"yep\",\n\t\tQux:      []string{\"Test\", \"Test2\"},\n\t\tQuxEmpty: []string{\"Qux\", \"Qux2\"},\n\t}\n\tindexer := &CompoundMultiIndex{\n\t\tIndexes: []Indexer{\n\t\t\t&StringFieldIndex{Field: \"Foo\"},\n\t\t\t&StringSliceFieldIndex{Field: \"Qux\"},\n\t\t\t&StringSliceFieldIndex{Field: \"QuxEmpty\"},\n\t\t},\n\t}\n\n\tok, vals, err := indexer.FromObject(obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"should be ok\")\n\t}\n\twant := []string{\n\t\t\"Foo1\\x00Test\\x00Qux\\x00\",\n\t\t\"Foo1\\x00Test\\x00Qux2\\x00\",\n\t\t\"Foo1\\x00Test2\\x00Qux\\x00\",\n\t\t\"Foo1\\x00Test2\\x00Qux2\\x00\",\n\t}\n\tgot := make([]string, len(vals))\n\tfor i, v := range vals {\n\t\tgot[i] = string(v)\n\t}\n\tif !reflect.DeepEqual(got, want) {\n\t\tt.Fatalf(\"\\ngot:  %+v\\nwant: %+v\\n\", got, want)\n\t}\n}\n\nfunc TestCompoundMultiIndex_FromObject_IndexUniquenessProperty(t *testing.T) {\n\tindexPermutations := [][]string{\n\t\t{\"Foo\", \"Qux\", \"QuxEmpty\"},\n\t\t{\"Foo\", \"QuxEmpty\", \"Qux\"},\n\t\t{\"QuxEmpty\", \"Qux\", \"Foo\"},\n\t\t{\"QuxEmpty\", \"Foo\", \"Qux\"},\n\t\t{\"Qux\", \"QuxEmpty\", \"Foo\"},\n\t\t{\"Qux\", \"Foo\", \"QuxEmpty\"},\n\t}\n\n\tfn := func(o TestObject) bool {\n\t\tfor _, perm := range indexPermutations {\n\t\t\tindexer := indexerFromFieldNameList(perm)\n\t\t\tok, vals, err := indexer.FromObject(o)\n\t\t\tif err != nil {\n\t\t\t\tt.Logf(\"err: %v\", err)\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tif !ok {\n\t\t\t\tt.Logf(\"should be ok\")\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tif !assertAllUnique(t, vals) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\treturn true\n\t}\n\tseed := time.Now().UnixNano()\n\tt.Logf(\"Using seed %v\", seed)\n\tcfg := quick.Config{Rand: rand.New(rand.NewSource(seed))}\n\tif err := quick.Check(fn, &cfg); err != nil {\n\t\tt.Fatalf(\"property not held: %v\", err)\n\t}\n}\n\nfunc assertAllUnique(t *testing.T, vals [][]byte) bool {\n\tt.Helper()\n\ts := make(map[string]struct{}, len(vals))\n\tfor _, index := range vals {\n\t\ts[string(index)] = struct{}{}\n\t}\n\n\tif l := len(s); l != len(vals) {\n\t\tt.Logf(\"expected %d unique indexes, got %v\", len(vals), l)\n\t\treturn false\n\t}\n\treturn true\n}\n\nfunc indexerFromFieldNameList(keys []string) *CompoundMultiIndex {\n\tindexer := &CompoundMultiIndex{AllowMissing: true}\n\tfor _, key := range keys {\n\t\tif key == \"Foo\" || key == \"Baz\" {\n\t\t\tindexer.Indexes = append(indexer.Indexes, &StringFieldIndex{Field: key})\n\t\t\tcontinue\n\t\t}\n\t\tindexer.Indexes = append(indexer.Indexes, &StringSliceFieldIndex{Field: key})\n\t}\n\treturn indexer\n}\n\nfunc BenchmarkCompoundMultiIndex_FromObject(b *testing.B) {\n\tobj := &TestObject{\n\t\tID:       \"obj1-uuid\",\n\t\tFoo:      \"Foo1\",\n\t\tBaz:      \"yep\",\n\t\tQux:      []string{\"Test\", \"Test2\"},\n\t\tQuxEmpty: []string{\"Qux\", \"Qux2\"},\n\t}\n\tindexer := &CompoundMultiIndex{\n\t\tIndexes: []Indexer{\n\t\t\t&StringFieldIndex{Field: \"Foo\"},\n\t\t\t&StringSliceFieldIndex{Field: \"Qux\"},\n\t\t\t&StringSliceFieldIndex{Field: \"QuxEmpty\"},\n\t\t},\n\t}\n\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tok, vals, err := indexer.FromObject(obj)\n\t\tif err != nil {\n\t\t\tb.Fatalf(\"expected no error, got: %v\", err)\n\t\t}\n\t\tif !ok {\n\t\t\tb.Fatalf(\"should be ok\")\n\t\t}\n\t\tif l := len(vals); l != 4 {\n\t\t\tb.Fatalf(\"expected 4 indexes, got %v\", l)\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "integ_test.go",
          "type": "blob",
          "size": 12.083984375,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage memdb\n\nimport (\n\t\"reflect\"\n\t\"testing\"\n\t\"time\"\n)\n\n// Test that multiple concurrent transactions are isolated from each other\nfunc TestTxn_Isolation(t *testing.T) {\n\tdb := testDB(t)\n\ttxn1 := db.Txn(true)\n\n\tobj := &TestObject{\n\t\tID:  \"my-object\",\n\t\tFoo: \"abc\",\n\t\tQux: []string{\"abc1\", \"abc2\"},\n\t}\n\tobj2 := &TestObject{\n\t\tID:  \"my-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\tobj3 := &TestObject{\n\t\tID:  \"my-other-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\n\terr := txn1.Insert(\"main\", obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn1.Insert(\"main\", obj2)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn1.Insert(\"main\", obj3)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// Results should show up in this transaction\n\traw, err := txn1.First(\"main\", \"id\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw == nil {\n\t\tt.Fatalf(\"bad: %#v\", raw)\n\t}\n\n\t// Create a new transaction, current one is NOT committed\n\ttxn2 := db.Txn(false)\n\n\t// Nothing should show up in this transaction\n\traw, err = txn2.First(\"main\", \"id\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw != nil {\n\t\tt.Fatalf(\"bad: %#v\", raw)\n\t}\n\n\t// Commit txn1, txn2 should still be isolated\n\ttxn1.Commit()\n\n\t// Nothing should show up in this transaction\n\traw, err = txn2.First(\"main\", \"id\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw != nil {\n\t\tt.Fatalf(\"bad: %#v\", raw)\n\t}\n\n\t// Create a new txn\n\ttxn3 := db.Txn(false)\n\n\t// Results should show up in this transaction\n\traw, err = txn3.First(\"main\", \"id\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw == nil {\n\t\tt.Fatalf(\"bad: %#v\", raw)\n\t}\n}\n\n// Test that an abort clears progress\nfunc TestTxn_Abort(t *testing.T) {\n\tdb := testDB(t)\n\ttxn1 := db.Txn(true)\n\n\tobj := &TestObject{\n\t\tID:  \"my-object\",\n\t\tFoo: \"abc\",\n\t\tQux: []string{\"abc1\", \"abc2\"},\n\t}\n\tobj2 := &TestObject{\n\t\tID:  \"my-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\tobj3 := &TestObject{\n\t\tID:  \"my-other-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\n\terr := txn1.Insert(\"main\", obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn1.Insert(\"main\", obj2)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn1.Insert(\"main\", obj3)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// Abort the txn\n\ttxn1.Abort()\n\ttxn1.Commit()\n\n\t// Create a new transaction\n\ttxn2 := db.Txn(false)\n\n\t// Nothing should show up in this transaction\n\traw, err := txn2.First(\"main\", \"id\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw != nil {\n\t\tt.Fatalf(\"bad: %#v\", raw)\n\t}\n}\n\nfunc TestComplexDB(t *testing.T) {\n\tdb := testComplexDB(t)\n\ttestPopulateData(t, db)\n\ttxn := db.Txn(false) // read only\n\n\t// Get using a full name\n\traw, err := txn.First(\"people\", \"name\", \"Armon\", \"Dadgar\")\n\tnoErr(t, err)\n\tif raw == nil {\n\t\tt.Fatalf(\"should get person\")\n\t}\n\n\t// Get using a prefix\n\traw, err = txn.First(\"people\", \"name_prefix\", \"Armon\")\n\tnoErr(t, err)\n\tif raw == nil {\n\t\tt.Fatalf(\"should get person\")\n\t}\n\n\traw, err = txn.First(\"people\", \"id_prefix\", raw.(*TestPerson).ID[:4])\n\tnoErr(t, err)\n\tif raw == nil {\n\t\tt.Fatalf(\"should get person\")\n\t}\n\n\t// Get based on field set.\n\tresult, err := txn.Get(\"people\", \"sibling\", true)\n\tnoErr(t, err)\n\tif raw == nil {\n\t\tt.Fatalf(\"should get person\")\n\t}\n\n\texp := map[string]bool{\"Alex\": true, \"Armon\": true}\n\tact := make(map[string]bool, 2)\n\tfor i := result.Next(); i != nil; i = result.Next() {\n\t\tp, ok := i.(*TestPerson)\n\t\tif !ok {\n\t\t\tt.Fatalf(\"should get person\")\n\t\t}\n\t\tact[p.First] = true\n\t}\n\n\tif !reflect.DeepEqual(act, exp) {\n\t\tt.Fatalf(\"Got %#v; want %#v\", act, exp)\n\t}\n\n\traw, err = txn.First(\"people\", \"sibling\", false)\n\tnoErr(t, err)\n\tif raw == nil {\n\t\tt.Fatalf(\"should get person\")\n\t}\n\tif raw.(*TestPerson).First != \"Mitchell\" {\n\t\tt.Fatalf(\"wrong person!\")\n\t}\n\n\traw, err = txn.First(\"people\", \"age\", uint8(23))\n\tnoErr(t, err)\n\tif raw == nil {\n\t\tt.Fatalf(\"should get person\")\n\t}\n\n\traw, err = txn.First(\"people\", \"negative_age\", int8(-23))\n\tnoErr(t, err)\n\tif raw == nil {\n\t\tt.Fatalf(\"should get person\")\n\t}\n\n\tperson := raw.(*TestPerson)\n\tif person.First != \"Alex\" {\n\t\tt.Fatalf(\"wrong person!\")\n\t}\n\n\t// Where in the world is mitchell hashimoto?\n\traw, err = txn.First(\"people\", \"name_prefix\", \"Mitchell\")\n\tnoErr(t, err)\n\tif raw == nil {\n\t\tt.Fatalf(\"should get person\")\n\t}\n\n\tperson = raw.(*TestPerson)\n\tif person.First != \"Mitchell\" {\n\t\tt.Fatalf(\"wrong person!\")\n\t}\n\n\traw, err = txn.First(\"visits\", \"id_prefix\", person.ID)\n\tnoErr(t, err)\n\tif raw == nil {\n\t\tt.Fatalf(\"should get visit\")\n\t}\n\n\tvisit := raw.(*TestVisit)\n\n\traw, err = txn.First(\"places\", \"id\", visit.Place)\n\tnoErr(t, err)\n\tif raw == nil {\n\t\tt.Fatalf(\"should get place\")\n\t}\n\n\tplace := raw.(*TestPlace)\n\tif place.Name != \"Maui\" {\n\t\tt.Fatalf(\"bad place (but isn't anywhere else really?): %v\", place)\n\t}\n\n\traw, err = txn.First(\"places\", \"name_tags\", \"HashiCorp\", \"North America\")\n\tnoErr(t, err)\n\tif raw == nil {\n\t\tt.Fatalf(\"should get place\")\n\t}\n\tplace = raw.(*TestPlace)\n\tif place.Name != \"HashiCorp\" {\n\t\tt.Fatalf(\"bad place (but isn't anywhere else really?): %v\", place)\n\t}\n\n\traw, err = txn.First(\"places\", \"name_tags\", \"Maui\")\n\tnoErr(t, err)\n\tif raw == nil {\n\t\tt.Fatalf(\"should get place\")\n\t}\n\tplace = raw.(*TestPlace)\n\tif place.Name != \"Maui\" {\n\t\tt.Fatalf(\"bad place (but isn't anywhere else really?): %v\", place)\n\t}\n\n\traw, err = txn.First(\"places\", \"name_tags_name_meta\", \"HashiCorp\", \"North America\", \"HashiCorp\", \"Food\", \"Pretty Good\")\n\tnoErr(t, err)\n\tif raw == nil {\n\t\tt.Fatalf(\"should get place\")\n\t}\n\tplace = raw.(*TestPlace)\n\tif place.Tags[1] != \"USA\" {\n\t\tt.Fatalf(\"bad place: %v\", place)\n\t}\n\n\traw, err = txn.First(\"places\", \"name_tags_name_meta\", \"HashiCorp\", \"North America\", \"HashiCorp\", \"Piers\", \"Pretty Salty\")\n\tnoErr(t, err)\n\tif raw == nil {\n\t\tt.Fatalf(\"should get place\")\n\t}\n\tplace = raw.(*TestPlace)\n\tif place.Tags[1] != \"Earth\" {\n\t\tt.Fatalf(\"bad place: %v\", place)\n\t}\n}\n\nfunc TestWatchUpdate(t *testing.T) {\n\tdb := testComplexDB(t)\n\ttestPopulateData(t, db)\n\ttxn := db.Txn(false) // read only\n\n\twatchSetIter := NewWatchSet()\n\twatchSetSpecific := NewWatchSet()\n\twatchSetPrefix := NewWatchSet()\n\n\t// Get using an iterator.\n\titer, err := txn.Get(\"people\", \"name\", \"Armon\", \"Dadgar\")\n\tnoErr(t, err)\n\twatchSetIter.Add(iter.WatchCh())\n\tif raw := iter.Next(); raw == nil {\n\t\tt.Fatalf(\"should get person\")\n\t}\n\n\t// Get using a full name.\n\twatch, raw, err := txn.FirstWatch(\"people\", \"name\", \"Armon\", \"Dadgar\")\n\tnoErr(t, err)\n\tif raw == nil {\n\t\tt.Fatalf(\"should get person\")\n\t}\n\twatchSetSpecific.Add(watch)\n\n\t// Get using a prefix.\n\twatch, raw, err = txn.FirstWatch(\"people\", \"name_prefix\", \"Armon\")\n\tnoErr(t, err)\n\tif raw == nil {\n\t\tt.Fatalf(\"should get person\")\n\t}\n\twatchSetPrefix.Add(watch)\n\n\t// Write to a snapshot.\n\tsnap := db.Snapshot()\n\ttxn2 := snap.Txn(true) // write\n\tnoErr(t, txn2.Delete(\"people\", raw))\n\ttxn2.Commit()\n\n\t// None of the watches should trigger since we didn't alter the\n\t// primary.\n\twait := 100 * time.Millisecond\n\tif timeout := watchSetIter.Watch(time.After(wait)); !timeout {\n\t\tt.Fatalf(\"should timeout\")\n\t}\n\tif timeout := watchSetSpecific.Watch(time.After(wait)); !timeout {\n\t\tt.Fatalf(\"should timeout\")\n\t}\n\tif timeout := watchSetPrefix.Watch(time.After(wait)); !timeout {\n\t\tt.Fatalf(\"should timeout\")\n\t}\n\n\t// Write to the primary.\n\ttxn3 := db.Txn(true) // write\n\tnoErr(t, txn3.Delete(\"people\", raw))\n\ttxn3.Commit()\n\n\t// All three watches should trigger!\n\twait = time.Second\n\tif timeout := watchSetIter.Watch(time.After(wait)); timeout {\n\t\tt.Fatalf(\"should not timeout\")\n\t}\n\tif timeout := watchSetSpecific.Watch(time.After(wait)); timeout {\n\t\tt.Fatalf(\"should not timeout\")\n\t}\n\tif timeout := watchSetPrefix.Watch(time.After(wait)); timeout {\n\t\tt.Fatalf(\"should not timeout\")\n\t}\n}\n\nfunc testPopulateData(t *testing.T, db *MemDB) {\n\t// Start write txn\n\ttxn := db.Txn(true)\n\n\t// Create some data\n\tperson1 := testPerson()\n\n\tperson2 := testPerson()\n\tperson2.First = \"Mitchell\"\n\tperson2.Last = \"Hashimoto\"\n\tperson2.Age = 27\n\tperson2.NegativeAge = -27\n\n\tperson3 := testPerson()\n\tperson3.First = \"Alex\"\n\tperson3.Last = \"Dadgar\"\n\tperson3.Age = 23\n\tperson3.NegativeAge = -23\n\n\tperson1.Sibling = person3\n\tperson3.Sibling = person1\n\n\tplace1 := testPlace()\n\tplace1.Tags = []string{\"North America\", \"USA\"}\n\tplace1.Meta = map[string]string{\"Food\": \"Pretty Good\"}\n\tplace2 := testPlace()\n\tplace2.Name = \"Maui\"\n\tplace3 := testPlace()\n\tplace3.Tags = []string{\"North America\", \"Earth\"}\n\tplace3.Meta = map[string]string{\"Piers\": \"Pretty Salty\"}\n\n\tvisit1 := &TestVisit{person1.ID, place1.ID}\n\tvisit2 := &TestVisit{person2.ID, place2.ID}\n\n\t// Insert it all\n\tnoErr(t, txn.Insert(\"people\", person1))\n\tnoErr(t, txn.Insert(\"people\", person2))\n\tnoErr(t, txn.Insert(\"people\", person3))\n\tnoErr(t, txn.Insert(\"places\", place1))\n\tnoErr(t, txn.Insert(\"places\", place2))\n\tnoErr(t, txn.Insert(\"places\", place3))\n\tnoErr(t, txn.Insert(\"visits\", visit1))\n\tnoErr(t, txn.Insert(\"visits\", visit2))\n\n\t// Commit\n\ttxn.Commit()\n}\n\nfunc expectErr(t *testing.T, err error) {\n\tt.Helper()\n\tif err == nil {\n\t\tt.Fatal(\"expected error\")\n\t}\n}\n\nfunc noErr(t *testing.T, err error) {\n\tt.Helper()\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n}\n\ntype TestPerson struct {\n\tID          string\n\tFirst       string\n\tLast        string\n\tAge         uint8\n\tNegativeAge int8\n\tSibling     *TestPerson\n}\n\ntype TestPlace struct {\n\tID   string\n\tName string\n\tTags []string\n\tMeta map[string]string\n}\n\ntype TestVisit struct {\n\tPerson string\n\tPlace  string\n}\n\nfunc testComplexSchema() *DBSchema {\n\treturn &DBSchema{\n\t\tTables: map[string]*TableSchema{\n\t\t\t\"people\": &TableSchema{\n\t\t\t\tName: \"people\",\n\t\t\t\tIndexes: map[string]*IndexSchema{\n\t\t\t\t\t\"id\": &IndexSchema{\n\t\t\t\t\t\tName:    \"id\",\n\t\t\t\t\t\tUnique:  true,\n\t\t\t\t\t\tIndexer: &UUIDFieldIndex{Field: \"ID\"},\n\t\t\t\t\t},\n\t\t\t\t\t\"name\": &IndexSchema{\n\t\t\t\t\t\tName:   \"name\",\n\t\t\t\t\t\tUnique: true,\n\t\t\t\t\t\tIndexer: &CompoundIndex{\n\t\t\t\t\t\t\tIndexes: []Indexer{\n\t\t\t\t\t\t\t\t&StringFieldIndex{Field: \"First\"},\n\t\t\t\t\t\t\t\t&StringFieldIndex{Field: \"Last\"},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t\"age\": &IndexSchema{\n\t\t\t\t\t\tName:    \"age\",\n\t\t\t\t\t\tUnique:  false,\n\t\t\t\t\t\tIndexer: &UintFieldIndex{Field: \"Age\"},\n\t\t\t\t\t},\n\t\t\t\t\t\"negative_age\": &IndexSchema{\n\t\t\t\t\t\tName:    \"negative_age\",\n\t\t\t\t\t\tUnique:  false,\n\t\t\t\t\t\tIndexer: &IntFieldIndex{Field: \"NegativeAge\"},\n\t\t\t\t\t},\n\t\t\t\t\t\"sibling\": &IndexSchema{\n\t\t\t\t\t\tName:    \"sibling\",\n\t\t\t\t\t\tUnique:  false,\n\t\t\t\t\t\tIndexer: &FieldSetIndex{Field: \"Sibling\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"places\": &TableSchema{\n\t\t\t\tName: \"places\",\n\t\t\t\tIndexes: map[string]*IndexSchema{\n\t\t\t\t\t\"id\": &IndexSchema{\n\t\t\t\t\t\tName:    \"id\",\n\t\t\t\t\t\tUnique:  true,\n\t\t\t\t\t\tIndexer: &UUIDFieldIndex{Field: \"ID\"},\n\t\t\t\t\t},\n\t\t\t\t\t\"name\": &IndexSchema{\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t\tUnique:  true,\n\t\t\t\t\t\tIndexer: &StringFieldIndex{Field: \"Name\"},\n\t\t\t\t\t},\n\t\t\t\t\t\"name_tags\": &IndexSchema{\n\t\t\t\t\t\tName:         \"name_tags\",\n\t\t\t\t\t\tUnique:       true,\n\t\t\t\t\t\tAllowMissing: true,\n\t\t\t\t\t\tIndexer: &CompoundMultiIndex{\n\t\t\t\t\t\t\tAllowMissing: true,\n\t\t\t\t\t\t\tIndexes: []Indexer{\n\t\t\t\t\t\t\t\t&StringFieldIndex{Field: \"Name\"},\n\t\t\t\t\t\t\t\t&StringSliceFieldIndex{Field: \"Tags\"},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t\"name_tags_name_meta\": &IndexSchema{\n\t\t\t\t\t\tName:         \"name_tags_name_meta\",\n\t\t\t\t\t\tUnique:       true,\n\t\t\t\t\t\tAllowMissing: true,\n\t\t\t\t\t\tIndexer: &CompoundMultiIndex{\n\t\t\t\t\t\t\tAllowMissing: true,\n\t\t\t\t\t\t\tIndexes: []Indexer{\n\t\t\t\t\t\t\t\t&StringFieldIndex{Field: \"Name\"},\n\t\t\t\t\t\t\t\t&StringSliceFieldIndex{Field: \"Tags\"},\n\t\t\t\t\t\t\t\t&StringFieldIndex{Field: \"Name\"},\n\t\t\t\t\t\t\t\t&StringMapFieldIndex{Field: \"Meta\"},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"visits\": &TableSchema{\n\t\t\t\tName: \"visits\",\n\t\t\t\tIndexes: map[string]*IndexSchema{\n\t\t\t\t\t\"id\": &IndexSchema{\n\t\t\t\t\t\tName:   \"id\",\n\t\t\t\t\t\tUnique: true,\n\t\t\t\t\t\tIndexer: &CompoundIndex{\n\t\t\t\t\t\t\tIndexes: []Indexer{\n\t\t\t\t\t\t\t\t&UUIDFieldIndex{Field: \"Person\"},\n\t\t\t\t\t\t\t\t&UUIDFieldIndex{Field: \"Place\"},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n}\n\nfunc testComplexDB(t *testing.T) *MemDB {\n\tdb, err := NewMemDB(testComplexSchema())\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\treturn db\n}\n\nfunc testPerson() *TestPerson {\n\t_, uuid := generateUUID()\n\tobj := &TestPerson{\n\t\tID:          uuid,\n\t\tFirst:       \"Armon\",\n\t\tLast:        \"Dadgar\",\n\t\tAge:         26,\n\t\tNegativeAge: -26,\n\t}\n\treturn obj\n}\n\nfunc testPlace() *TestPlace {\n\t_, uuid := generateUUID()\n\tobj := &TestPlace{\n\t\tID:   uuid,\n\t\tName: \"HashiCorp\",\n\t}\n\treturn obj\n}\n"
        },
        {
          "name": "isolation_test.go",
          "type": "blob",
          "size": 7.7294921875,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage memdb\n\nimport (\n\t\"testing\"\n)\n\nfunc TestMemDB_Isolation(t *testing.T) {\n\n\tid1 := \"object-one\"\n\tid2 := \"object-two\"\n\tid3 := \"object-three\"\n\n\tmustNoError := func(t *testing.T, err error) {\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unexpected test error: %v\", err)\n\t\t}\n\t}\n\n\tsetup := func(t *testing.T) *MemDB {\n\t\tt.Helper()\n\n\t\tdb, err := NewMemDB(testValidSchema())\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\t// Add two objects (with a gap between their IDs)\n\t\tobj1a := testObj()\n\t\tobj1a.ID = id1\n\t\ttxn := db.Txn(true)\n\t\tmustNoError(t, txn.Insert(\"main\", obj1a))\n\n\t\tobj3 := testObj()\n\t\tobj3.ID = id3\n\t\tmustNoError(t, txn.Insert(\"main\", obj3))\n\t\ttxn.Commit()\n\t\treturn db\n\t}\n\n\tt.Run(\"snapshot dirty read\", func(t *testing.T) {\n\t\tdb := setup(t)\n\t\tdb2 := db.Snapshot()\n\n\t\t// Update an object\n\t\tobj1b := testObj()\n\t\tobj1b.ID = id1\n\t\ttxn1 := db.Txn(true)\n\t\tobj1b.Baz = \"nope\"\n\t\tmustNoError(t, txn1.Insert(\"main\", obj1b))\n\n\t\t// Insert an object\n\t\tobj2 := testObj()\n\t\tobj2.ID = id2\n\t\tmustNoError(t, txn1.Insert(\"main\", obj2))\n\n\t\ttxn2 := db2.Txn(false)\n\t\tout, err := txn2.First(\"main\", \"id\", id1)\n\t\tmustNoError(t, err)\n\t\tif out == nil {\n\t\t\tt.Fatalf(\"should exist\")\n\t\t}\n\t\tif out.(*TestObject).Baz == \"nope\" {\n\t\t\tt.Fatalf(\"read from snapshot should not observe uncommitted update (dirty read)\")\n\t\t}\n\n\t\tout, err = txn2.First(\"main\", \"id\", id2)\n\t\tmustNoError(t, err)\n\t\tif out != nil {\n\t\t\tt.Fatalf(\"read from snapshot should not observe uncommitted insert (dirty read)\")\n\t\t}\n\n\t\t// New snapshot should not observe uncommitted writes\n\t\tdb3 := db.Snapshot()\n\t\ttxn3 := db3.Txn(false)\n\t\tout, err = txn3.First(\"main\", \"id\", id1)\n\t\tmustNoError(t, err)\n\t\tif out == nil {\n\t\t\tt.Fatalf(\"should exist\")\n\t\t}\n\t\tif out.(*TestObject).Baz == \"nope\" {\n\t\t\tt.Fatalf(\"read from new snapshot should not observe uncommitted writes\")\n\t\t}\n\t})\n\n\tt.Run(\"transaction dirty read\", func(t *testing.T) {\n\t\tdb := setup(t)\n\n\t\t// Update an object\n\t\tobj1b := testObj()\n\t\tobj1b.ID = id1\n\t\ttxn1 := db.Txn(true)\n\t\tobj1b.Baz = \"nope\"\n\t\tmustNoError(t, txn1.Insert(\"main\", obj1b))\n\n\t\t// Insert an object\n\t\tobj2 := testObj()\n\t\tobj2.ID = id2\n\t\tmustNoError(t, txn1.Insert(\"main\", obj2))\n\n\t\ttxn2 := db.Txn(false)\n\t\tout, err := txn2.First(\"main\", \"id\", id1)\n\t\tmustNoError(t, err)\n\t\tif out == nil {\n\t\t\tt.Fatalf(\"should exist\")\n\t\t}\n\t\tif out.(*TestObject).Baz == \"nope\" {\n\t\t\tt.Fatalf(\"read from transaction should not observe uncommitted update (dirty read)\")\n\t\t}\n\n\t\tout, err = txn2.First(\"main\", \"id\", id2)\n\t\tmustNoError(t, err)\n\t\tif out != nil {\n\t\t\tt.Fatalf(\"read from transaction should not observe uncommitted insert (dirty read)\")\n\t\t}\n\t})\n\n\tt.Run(\"snapshot non-repeatable read\", func(t *testing.T) {\n\t\tdb := setup(t)\n\t\tdb2 := db.Snapshot()\n\n\t\t// Update an object\n\t\tobj1b := testObj()\n\t\tobj1b.ID = id1\n\t\ttxn1 := db.Txn(true)\n\t\tobj1b.Baz = \"nope\"\n\t\tmustNoError(t, txn1.Insert(\"main\", obj1b))\n\n\t\t// Insert an object\n\t\tobj2 := testObj()\n\t\tobj2.ID = id3\n\t\tmustNoError(t, txn1.Insert(\"main\", obj2))\n\n\t\t// Commit\n\t\ttxn1.Commit()\n\n\t\ttxn2 := db2.Txn(false)\n\t\tout, err := txn2.First(\"main\", \"id\", id1)\n\t\tmustNoError(t, err)\n\t\tif out == nil {\n\t\t\tt.Fatalf(\"should exist\")\n\t\t}\n\t\tif out.(*TestObject).Baz == \"nope\" {\n\t\t\tt.Fatalf(\"read from snapshot should not observe committed write from another transaction (non-repeatable read)\")\n\t\t}\n\n\t\tout, err = txn2.First(\"main\", \"id\", id2)\n\t\tmustNoError(t, err)\n\t\tif out != nil {\n\t\t\tt.Fatalf(\"read from snapshot should not observe committed write from another transaction (non-repeatable read)\")\n\t\t}\n\n\t})\n\n\tt.Run(\"transaction non-repeatable read\", func(t *testing.T) {\n\t\tdb := setup(t)\n\n\t\t// Update an object\n\t\tobj1b := testObj()\n\t\tobj1b.ID = id1\n\t\ttxn1 := db.Txn(true)\n\t\tobj1b.Baz = \"nope\"\n\t\tmustNoError(t, txn1.Insert(\"main\", obj1b))\n\n\t\t// Insert an object\n\t\tobj2 := testObj()\n\t\tobj2.ID = id3\n\t\tmustNoError(t, txn1.Insert(\"main\", obj2))\n\n\t\ttxn2 := db.Txn(false)\n\n\t\t// Commit\n\t\ttxn1.Commit()\n\n\t\tout, err := txn2.First(\"main\", \"id\", id1)\n\t\tmustNoError(t, err)\n\t\tif out == nil {\n\t\t\tt.Fatalf(\"should exist\")\n\t\t}\n\t\tif out.(*TestObject).Baz == \"nope\" {\n\t\t\tt.Fatalf(\"read from transaction should not observe committed write from another transaction (non-repeatable read)\")\n\t\t}\n\n\t\tout, err = txn2.First(\"main\", \"id\", id2)\n\t\tmustNoError(t, err)\n\t\tif out != nil {\n\t\t\tt.Fatalf(\"read from transaction should not observe committed write from another transaction (non-repeatable read)\")\n\t\t}\n\n\t})\n\n\tt.Run(\"snapshot phantom read\", func(t *testing.T) {\n\t\tdb := setup(t)\n\t\tdb2 := db.Snapshot()\n\n\t\ttxn2 := db2.Txn(false)\n\t\titer, err := txn2.Get(\"main\", \"id_prefix\", \"object\")\n\t\tmustNoError(t, err)\n\t\tout := iter.Next()\n\t\tif out == nil || out.(*TestObject).ID != id1 {\n\t\t\tt.Fatal(\"missing expected object 'object-one'\")\n\t\t}\n\n\t\t// Insert an object and commit\n\t\ttxn1 := db.Txn(true)\n\t\tobj2 := testObj()\n\t\tobj2.ID = id2\n\t\tmustNoError(t, txn1.Insert(\"main\", obj2))\n\t\ttxn1.Commit()\n\n\t\tout = iter.Next()\n\t\tif out == nil {\n\t\t\tt.Fatal(\"expected 2 objects\")\n\t\t}\n\t\tif out.(*TestObject).ID == id2 {\n\t\t\tt.Fatalf(\"read from snapshot should not observe new objects in set (phantom read)\")\n\t\t}\n\n\t\tout = iter.Next()\n\t\tif out != nil {\n\t\t\tt.Fatal(\"expected only 2 objects: read from snapshot should not observe new objects in set (phantom read)\")\n\t\t}\n\n\t\t// Remove an object using an outdated pointer\n\t\ttxn1 = db.Txn(true)\n\t\tobj1, err := txn1.First(\"main\", \"id\", id1)\n\t\tmustNoError(t, err)\n\t\tmustNoError(t, txn1.Delete(\"main\", obj1))\n\t\ttxn1.Commit()\n\n\t\titer, err = txn2.Get(\"main\", \"id_prefix\", \"object\")\n\t\tmustNoError(t, err)\n\n\t\tout = iter.Next()\n\t\tif out == nil || out.(*TestObject).ID != id1 {\n\t\t\tt.Fatal(\"missing expected object 'object-one': read from snapshot should not observe deletes (phantom read)\")\n\t\t}\n\t\tout = iter.Next()\n\t\tif out == nil || out.(*TestObject).ID != id3 {\n\t\t\tt.Fatal(\"missing expected object 'object-three': read from snapshot should not observe deletes (phantom read)\")\n\t\t}\n\n\t})\n\n\tt.Run(\"transaction phantom read\", func(t *testing.T) {\n\t\tdb := setup(t)\n\n\t\ttxn2 := db.Txn(false)\n\t\titer, err := txn2.Get(\"main\", \"id_prefix\", \"object\")\n\t\tmustNoError(t, err)\n\t\tout := iter.Next()\n\t\tif out == nil || out.(*TestObject).ID != id1 {\n\t\t\tt.Fatal(\"missing expected object 'object-one'\")\n\t\t}\n\n\t\t// Insert an object and commit\n\t\ttxn1 := db.Txn(true)\n\t\tobj2 := testObj()\n\t\tobj2.ID = id2\n\t\tmustNoError(t, txn1.Insert(\"main\", obj2))\n\t\ttxn1.Commit()\n\n\t\tout = iter.Next()\n\t\tif out == nil {\n\t\t\tt.Fatal(\"expected 2 objects\")\n\t\t}\n\t\tif out.(*TestObject).ID == id2 {\n\t\t\tt.Fatalf(\"read from transaction should not observe new objects in set (phantom read)\")\n\t\t}\n\n\t\tout = iter.Next()\n\t\tif out != nil {\n\t\t\tt.Fatal(\"expected only 2 objects: read from transaction should not observe new objects in set (phantom read)\")\n\t\t}\n\n\t\t// Remove an object using an outdated pointer\n\t\ttxn1 = db.Txn(true)\n\t\tobj1, err := txn1.First(\"main\", \"id\", id1)\n\t\tmustNoError(t, err)\n\t\tmustNoError(t, txn1.Delete(\"main\", obj1))\n\t\ttxn1.Commit()\n\n\t\titer, err = txn2.Get(\"main\", \"id_prefix\", \"object\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\tout = iter.Next()\n\t\tif out == nil || out.(*TestObject).ID != id1 {\n\t\t\tt.Fatal(\"missing expected object 'object-one': read from transaction should not observe deletes (phantom read)\")\n\t\t}\n\t\tout = iter.Next()\n\t\tif out == nil || out.(*TestObject).ID != id3 {\n\t\t\tt.Fatal(\"missing expected object 'object-three': read from transaction should not observe deletes (phantom read)\")\n\t\t}\n\n\t})\n\n\tt.Run(\"snapshot commits are unobservable\", func(t *testing.T) {\n\t\tdb := setup(t)\n\t\tdb2 := db.Snapshot()\n\n\t\ttxn2 := db2.Txn(true)\n\t\tobj1 := testObj()\n\t\tobj1.ID = id1\n\t\tobj1.Baz = \"also\"\n\t\tmustNoError(t, txn2.Insert(\"main\", obj1))\n\t\ttxn2.Commit()\n\n\t\ttxn1 := db.Txn(false)\n\t\tout, err := txn1.First(\"main\", \"id\", id1)\n\t\tmustNoError(t, err)\n\t\tif out == nil {\n\t\t\tt.Fatalf(\"should exist\")\n\t\t}\n\t\tif out.(*TestObject).Baz == \"also\" {\n\t\t\tt.Fatalf(\"commit from snapshot should never be observed\")\n\t\t}\n\t})\n}\n"
        },
        {
          "name": "memdb.go",
          "type": "blob",
          "size": 3.3046875,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\n// Package memdb provides an in-memory database that supports transactions\n// and MVCC.\npackage memdb\n\nimport (\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"unsafe\"\n\n\t\"github.com/hashicorp/go-immutable-radix\"\n)\n\n// MemDB is an in-memory database providing Atomicity, Consistency, and\n// Isolation from ACID. MemDB doesn't provide Durability since it is an\n// in-memory database.\n//\n// MemDB provides a table abstraction to store objects (rows) with multiple\n// indexes based on inserted values. The database makes use of immutable radix\n// trees to provide transactions and MVCC.\n//\n// Objects inserted into MemDB are not copied. It is **extremely important**\n// that objects are not modified in-place after they are inserted since they\n// are stored directly in MemDB. It remains unsafe to modify inserted objects\n// even after they've been deleted from MemDB since there may still be older\n// snapshots of the DB being read from other goroutines.\ntype MemDB struct {\n\tschema  *DBSchema\n\troot    unsafe.Pointer // *iradix.Tree underneath\n\tprimary bool\n\n\t// There can only be a single writer at once\n\twriter sync.Mutex\n}\n\n// NewMemDB creates a new MemDB with the given schema.\nfunc NewMemDB(schema *DBSchema) (*MemDB, error) {\n\t// Validate the schema\n\tif err := schema.Validate(); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Create the MemDB\n\tdb := &MemDB{\n\t\tschema:  schema,\n\t\troot:    unsafe.Pointer(iradix.New()),\n\t\tprimary: true,\n\t}\n\tif err := db.initialize(); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn db, nil\n}\n\n// DBSchema returns schema in use for introspection.\n//\n// The method is intended for *read-only* debugging use cases,\n// returned schema should *never be modified in-place*.\nfunc (db *MemDB) DBSchema() *DBSchema {\n\treturn db.schema\n}\n\n// getRoot is used to do an atomic load of the root pointer\nfunc (db *MemDB) getRoot() *iradix.Tree {\n\troot := (*iradix.Tree)(atomic.LoadPointer(&db.root))\n\treturn root\n}\n\n// Txn is used to start a new transaction in either read or write mode.\n// There can only be a single concurrent writer, but any number of readers.\nfunc (db *MemDB) Txn(write bool) *Txn {\n\tif write {\n\t\tdb.writer.Lock()\n\t}\n\ttxn := &Txn{\n\t\tdb:      db,\n\t\twrite:   write,\n\t\trootTxn: db.getRoot().Txn(),\n\t}\n\treturn txn\n}\n\n// Snapshot is used to capture a point-in-time snapshot  of the database that\n// will not be affected by any write operations to the existing DB.\n//\n// If MemDB is storing reference-based values (pointers, maps, slices, etc.),\n// the Snapshot will not deep copy those values. Therefore, it is still unsafe\n// to modify any inserted values in either DB.\nfunc (db *MemDB) Snapshot() *MemDB {\n\tclone := &MemDB{\n\t\tschema:  db.schema,\n\t\troot:    unsafe.Pointer(db.getRoot()),\n\t\tprimary: false,\n\t}\n\treturn clone\n}\n\n// initialize is used to setup the DB for use after creation. This should\n// be called only once after allocating a MemDB.\nfunc (db *MemDB) initialize() error {\n\troot := db.getRoot()\n\tfor tName, tableSchema := range db.schema.Tables {\n\t\tfor iName := range tableSchema.Indexes {\n\t\t\tindex := iradix.New()\n\t\t\tpath := indexPath(tName, iName)\n\t\t\troot, _, _ = root.Insert(path, index)\n\t\t}\n\t}\n\tdb.root = unsafe.Pointer(root)\n\treturn nil\n}\n\n// indexPath returns the path from the root to the given table index\nfunc indexPath(table, index string) []byte {\n\treturn []byte(table + \".\" + index)\n}\n"
        },
        {
          "name": "memdb_test.go",
          "type": "blob",
          "size": 1.490234375,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage memdb\n\nimport (\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestMemDB_SingleWriter_MultiReader(t *testing.T) {\n\tdb, err := NewMemDB(testValidSchema())\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\ttx1 := db.Txn(true)\n\ttx2 := db.Txn(false) // Should not block!\n\ttx3 := db.Txn(false) // Should not block!\n\ttx4 := db.Txn(false) // Should not block!\n\n\tdoneCh := make(chan struct{})\n\tgo func() {\n\t\tdefer close(doneCh)\n\t\tdb.Txn(true)\n\t}()\n\n\tselect {\n\tcase <-doneCh:\n\t\tt.Fatalf(\"should not allow another writer\")\n\tcase <-time.After(10 * time.Millisecond):\n\t}\n\n\ttx1.Abort()\n\ttx2.Abort()\n\ttx3.Abort()\n\ttx4.Abort()\n\n\tselect {\n\tcase <-doneCh:\n\tcase <-time.After(10 * time.Millisecond):\n\t\tt.Fatalf(\"should allow another writer\")\n\t}\n}\n\nfunc TestMemDB_Snapshot(t *testing.T) {\n\tdb, err := NewMemDB(testValidSchema())\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// Add an object\n\tobj := testObj()\n\ttxn := db.Txn(true)\n\ttxn.Insert(\"main\", obj)\n\ttxn.Commit()\n\n\t// Clone the db\n\tdb2 := db.Snapshot()\n\n\t// Remove the object\n\ttxn = db.Txn(true)\n\ttxn.Delete(\"main\", obj)\n\ttxn.Commit()\n\n\t// Object should exist in second snapshot but not first\n\ttxn = db.Txn(false)\n\tout, err := txn.First(\"main\", \"id\", obj.ID)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif out != nil {\n\t\tt.Fatalf(\"should not exist %#v\", out)\n\t}\n\n\ttxn = db2.Txn(true)\n\tout, err = txn.First(\"main\", \"id\", obj.ID)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif out == nil {\n\t\tt.Fatalf(\"should exist\")\n\t}\n}\n"
        },
        {
          "name": "schema.go",
          "type": "blob",
          "size": 2.888671875,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage memdb\n\nimport \"fmt\"\n\n// DBSchema is the schema to use for the full database with a MemDB instance.\n//\n// MemDB will require a valid schema. Schema validation can be tested using\n// the Validate function. Calling this function is recommended in unit tests.\ntype DBSchema struct {\n\t// Tables is the set of tables within this database. The key is the\n\t// table name and must match the Name in TableSchema.\n\tTables map[string]*TableSchema\n}\n\n// Validate validates the schema.\nfunc (s *DBSchema) Validate() error {\n\tif s == nil {\n\t\treturn fmt.Errorf(\"schema is nil\")\n\t}\n\n\tif len(s.Tables) == 0 {\n\t\treturn fmt.Errorf(\"schema has no tables defined\")\n\t}\n\n\tfor name, table := range s.Tables {\n\t\tif name != table.Name {\n\t\t\treturn fmt.Errorf(\"table name mis-match for '%s'\", name)\n\t\t}\n\n\t\tif err := table.Validate(); err != nil {\n\t\t\treturn fmt.Errorf(\"table %q: %s\", name, err)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// TableSchema is the schema for a single table.\ntype TableSchema struct {\n\t// Name of the table. This must match the key in the Tables map in DBSchema.\n\tName string\n\n\t// Indexes is the set of indexes for querying this table. The key\n\t// is a unique name for the index and must match the Name in the\n\t// IndexSchema.\n\tIndexes map[string]*IndexSchema\n}\n\n// Validate is used to validate the table schema\nfunc (s *TableSchema) Validate() error {\n\tif s.Name == \"\" {\n\t\treturn fmt.Errorf(\"missing table name\")\n\t}\n\n\tif len(s.Indexes) == 0 {\n\t\treturn fmt.Errorf(\"missing table indexes for '%s'\", s.Name)\n\t}\n\n\tif _, ok := s.Indexes[\"id\"]; !ok {\n\t\treturn fmt.Errorf(\"must have id index\")\n\t}\n\n\tif !s.Indexes[\"id\"].Unique {\n\t\treturn fmt.Errorf(\"id index must be unique\")\n\t}\n\n\tif _, ok := s.Indexes[\"id\"].Indexer.(SingleIndexer); !ok {\n\t\treturn fmt.Errorf(\"id index must be a SingleIndexer\")\n\t}\n\n\tfor name, index := range s.Indexes {\n\t\tif name != index.Name {\n\t\t\treturn fmt.Errorf(\"index name mis-match for '%s'\", name)\n\t\t}\n\n\t\tif err := index.Validate(); err != nil {\n\t\t\treturn fmt.Errorf(\"index %q: %s\", name, err)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// IndexSchema is the schema for an index. An index defines how a table is\n// queried.\ntype IndexSchema struct {\n\t// Name of the index. This must be unique among a tables set of indexes.\n\t// This must match the key in the map of Indexes for a TableSchema.\n\tName string\n\n\t// AllowMissing if true ignores this index if it doesn't produce a\n\t// value. For example, an index that extracts a field that doesn't\n\t// exist from a structure.\n\tAllowMissing bool\n\n\tUnique  bool\n\tIndexer Indexer\n}\n\nfunc (s *IndexSchema) Validate() error {\n\tif s.Name == \"\" {\n\t\treturn fmt.Errorf(\"missing index name\")\n\t}\n\tif s.Indexer == nil {\n\t\treturn fmt.Errorf(\"missing index function for '%s'\", s.Name)\n\t}\n\tswitch s.Indexer.(type) {\n\tcase SingleIndexer:\n\tcase MultiIndexer:\n\tdefault:\n\t\treturn fmt.Errorf(\"indexer for '%s' must be a SingleIndexer or MultiIndexer\", s.Name)\n\t}\n\treturn nil\n}\n"
        },
        {
          "name": "schema_test.go",
          "type": "blob",
          "size": 2.1591796875,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage memdb\n\nimport \"testing\"\n\nfunc testValidSchema() *DBSchema {\n\treturn &DBSchema{\n\t\tTables: map[string]*TableSchema{\n\t\t\t\"main\": &TableSchema{\n\t\t\t\tName: \"main\",\n\t\t\t\tIndexes: map[string]*IndexSchema{\n\t\t\t\t\t\"id\": &IndexSchema{\n\t\t\t\t\t\tName:    \"id\",\n\t\t\t\t\t\tUnique:  true,\n\t\t\t\t\t\tIndexer: &StringFieldIndex{Field: \"ID\"},\n\t\t\t\t\t},\n\t\t\t\t\t\"foo\": &IndexSchema{\n\t\t\t\t\t\tName:    \"foo\",\n\t\t\t\t\t\tIndexer: &StringFieldIndex{Field: \"Foo\"},\n\t\t\t\t\t},\n\t\t\t\t\t\"qux\": &IndexSchema{\n\t\t\t\t\t\tName:    \"qux\",\n\t\t\t\t\t\tIndexer: &StringSliceFieldIndex{Field: \"Qux\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n}\n\nfunc TestDBSchema_Validate(t *testing.T) {\n\ts := &DBSchema{}\n\terr := s.Validate()\n\tif err == nil {\n\t\tt.Fatalf(\"should not validate, empty\")\n\t}\n\n\ts.Tables = map[string]*TableSchema{\n\t\t\"foo\": &TableSchema{Name: \"foo\"},\n\t}\n\terr = s.Validate()\n\tif err == nil {\n\t\tt.Fatalf(\"should not validate, no indexes\")\n\t}\n\n\tvalid := testValidSchema()\n\terr = valid.Validate()\n\tif err != nil {\n\t\tt.Fatalf(\"should validate: %v\", err)\n\t}\n}\n\nfunc TestTableSchema_Validate(t *testing.T) {\n\ts := &TableSchema{}\n\terr := s.Validate()\n\tif err == nil {\n\t\tt.Fatalf(\"should not validate, empty\")\n\t}\n\n\ts.Indexes = map[string]*IndexSchema{\n\t\t\"foo\": &IndexSchema{Name: \"foo\"},\n\t}\n\terr = s.Validate()\n\tif err == nil {\n\t\tt.Fatalf(\"should not validate, no indexes\")\n\t}\n\n\tvalid := &TableSchema{\n\t\tName: \"main\",\n\t\tIndexes: map[string]*IndexSchema{\n\t\t\t\"id\": &IndexSchema{\n\t\t\t\tName:    \"id\",\n\t\t\t\tUnique:  true,\n\t\t\t\tIndexer: &StringFieldIndex{Field: \"ID\", Lowercase: true},\n\t\t\t},\n\t\t},\n\t}\n\terr = valid.Validate()\n\tif err != nil {\n\t\tt.Fatalf(\"should validate: %v\", err)\n\t}\n}\n\nfunc TestIndexSchema_Validate(t *testing.T) {\n\ts := &IndexSchema{}\n\terr := s.Validate()\n\tif err == nil {\n\t\tt.Fatalf(\"should not validate, empty\")\n\t}\n\n\ts.Name = \"foo\"\n\terr = s.Validate()\n\tif err == nil {\n\t\tt.Fatalf(\"should not validate, no indexer\")\n\t}\n\n\ts.Indexer = &StringFieldIndex{Field: \"Foo\", Lowercase: false}\n\terr = s.Validate()\n\tif err != nil {\n\t\tt.Fatalf(\"should validate: %v\", err)\n\t}\n\n\ts.Indexer = &StringSliceFieldIndex{Field: \"Qux\", Lowercase: false}\n\terr = s.Validate()\n\tif err != nil {\n\t\tt.Fatalf(\"should validate: %v\", err)\n\t}\n}\n"
        },
        {
          "name": "txn.go",
          "type": "blob",
          "size": 30.7705078125,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage memdb\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"strings\"\n\t\"sync/atomic\"\n\t\"unsafe\"\n\n\tiradix \"github.com/hashicorp/go-immutable-radix\"\n)\n\nconst (\n\tid = \"id\"\n)\n\nvar (\n\t// ErrNotFound is returned when the requested item is not found\n\tErrNotFound = fmt.Errorf(\"not found\")\n)\n\n// tableIndex is a tuple of (Table, Index) used for lookups\ntype tableIndex struct {\n\tTable string\n\tIndex string\n}\n\n// Txn is a transaction against a MemDB.\n// This can be a read or write transaction.\ntype Txn struct {\n\tdb      *MemDB\n\twrite   bool\n\trootTxn *iradix.Txn\n\tafter   []func()\n\n\t// changes is used to track the changes performed during the transaction. If\n\t// it is nil at transaction start then changes are not tracked.\n\tchanges Changes\n\n\tmodified map[tableIndex]*iradix.Txn\n}\n\n// TrackChanges enables change tracking for the transaction. If called at any\n// point before commit, subsequent mutations will be recorded and can be\n// retrieved using ChangeSet. Once this has been called on a transaction it\n// can't be unset. As with other Txn methods it's not safe to call this from a\n// different goroutine than the one making mutations or committing the\n// transaction.\nfunc (txn *Txn) TrackChanges() {\n\tif txn.changes == nil {\n\t\ttxn.changes = make(Changes, 0, 1)\n\t}\n}\n\n// readableIndex returns a transaction usable for reading the given index in a\n// table. If the transaction is a write transaction with modifications, a clone of the\n// modified index will be returned.\nfunc (txn *Txn) readableIndex(table, index string) *iradix.Txn {\n\t// Look for existing transaction\n\tif txn.write && txn.modified != nil {\n\t\tkey := tableIndex{table, index}\n\t\texist, ok := txn.modified[key]\n\t\tif ok {\n\t\t\treturn exist.Clone()\n\t\t}\n\t}\n\n\t// Create a read transaction\n\tpath := indexPath(table, index)\n\traw, _ := txn.rootTxn.Get(path)\n\tindexTxn := raw.(*iradix.Tree).Txn()\n\treturn indexTxn\n}\n\n// writableIndex returns a transaction usable for modifying the\n// given index in a table.\nfunc (txn *Txn) writableIndex(table, index string) *iradix.Txn {\n\tif txn.modified == nil {\n\t\ttxn.modified = make(map[tableIndex]*iradix.Txn)\n\t}\n\n\t// Look for existing transaction\n\tkey := tableIndex{table, index}\n\texist, ok := txn.modified[key]\n\tif ok {\n\t\treturn exist\n\t}\n\n\t// Start a new transaction\n\tpath := indexPath(table, index)\n\traw, _ := txn.rootTxn.Get(path)\n\tindexTxn := raw.(*iradix.Tree).Txn()\n\n\t// If we are the primary DB, enable mutation tracking. Snapshots should\n\t// not notify, otherwise we will trigger watches on the primary DB when\n\t// the writes will not be visible.\n\tindexTxn.TrackMutate(txn.db.primary)\n\n\t// Keep this open for the duration of the txn\n\ttxn.modified[key] = indexTxn\n\treturn indexTxn\n}\n\n// Abort is used to cancel this transaction.\n// This is a noop for read transactions,\n// already aborted or commited transactions.\nfunc (txn *Txn) Abort() {\n\t// Noop for a read transaction\n\tif !txn.write {\n\t\treturn\n\t}\n\n\t// Check if already aborted or committed\n\tif txn.rootTxn == nil {\n\t\treturn\n\t}\n\n\t// Clear the txn\n\ttxn.rootTxn = nil\n\ttxn.modified = nil\n\ttxn.changes = nil\n\n\t// Release the writer lock since this is invalid\n\ttxn.db.writer.Unlock()\n}\n\n// Commit is used to finalize this transaction.\n// This is a noop for read transactions,\n// already aborted or committed transactions.\nfunc (txn *Txn) Commit() {\n\t// Noop for a read transaction\n\tif !txn.write {\n\t\treturn\n\t}\n\n\t// Check if already aborted or committed\n\tif txn.rootTxn == nil {\n\t\treturn\n\t}\n\n\t// Commit each sub-transaction scoped to (table, index)\n\tfor key, subTxn := range txn.modified {\n\t\tpath := indexPath(key.Table, key.Index)\n\t\tfinal := subTxn.CommitOnly()\n\t\ttxn.rootTxn.Insert(path, final)\n\t}\n\n\t// Update the root of the DB\n\tnewRoot := txn.rootTxn.CommitOnly()\n\tatomic.StorePointer(&txn.db.root, unsafe.Pointer(newRoot))\n\n\t// Now issue all of the mutation updates (this is safe to call\n\t// even if mutation tracking isn't enabled); we do this after\n\t// the root pointer is swapped so that waking responders will\n\t// see the new state.\n\tfor _, subTxn := range txn.modified {\n\t\tsubTxn.Notify()\n\t}\n\ttxn.rootTxn.Notify()\n\n\t// Clear the txn\n\ttxn.rootTxn = nil\n\ttxn.modified = nil\n\n\t// Release the writer lock since this is invalid\n\ttxn.db.writer.Unlock()\n\n\t// Run the deferred functions, if any\n\tfor i := len(txn.after); i > 0; i-- {\n\t\tfn := txn.after[i-1]\n\t\tfn()\n\t}\n}\n\n// Insert is used to add or update an object into the given table.\n//\n// When updating an object, the obj provided should be a copy rather\n// than a value updated in-place. Modifying values in-place that are already\n// inserted into MemDB is not supported behavior.\nfunc (txn *Txn) Insert(table string, obj interface{}) error {\n\tif !txn.write {\n\t\treturn fmt.Errorf(\"cannot insert in read-only transaction\")\n\t}\n\n\t// Get the table schema\n\ttableSchema, ok := txn.db.schema.Tables[table]\n\tif !ok {\n\t\treturn fmt.Errorf(\"invalid table '%s'\", table)\n\t}\n\n\t// Get the primary ID of the object\n\tidSchema := tableSchema.Indexes[id]\n\tidIndexer := idSchema.Indexer.(SingleIndexer)\n\tok, idVal, err := idIndexer.FromObject(obj)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to build primary index: %v\", err)\n\t}\n\tif !ok {\n\t\treturn fmt.Errorf(\"object missing primary index\")\n\t}\n\n\t// Lookup the object by ID first, to see if this is an update\n\tidTxn := txn.writableIndex(table, id)\n\texisting, update := idTxn.Get(idVal)\n\n\t// On an update, there is an existing object with the given\n\t// primary ID. We do the update by deleting the current object\n\t// and inserting the new object.\n\tfor name, indexSchema := range tableSchema.Indexes {\n\t\tindexTxn := txn.writableIndex(table, name)\n\n\t\t// Determine the new index value\n\t\tvar (\n\t\t\tok   bool\n\t\t\tvals [][]byte\n\t\t\terr  error\n\t\t)\n\t\tswitch indexer := indexSchema.Indexer.(type) {\n\t\tcase SingleIndexer:\n\t\t\tvar val []byte\n\t\t\tok, val, err = indexer.FromObject(obj)\n\t\t\tvals = [][]byte{val}\n\t\tcase MultiIndexer:\n\t\t\tok, vals, err = indexer.FromObject(obj)\n\t\t}\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to build index '%s': %v\", name, err)\n\t\t}\n\n\t\t// Handle non-unique index by computing a unique index.\n\t\t// This is done by appending the primary key which must\n\t\t// be unique anyways.\n\t\tif ok && !indexSchema.Unique {\n\t\t\tfor i := range vals {\n\t\t\t\tvals[i] = append(vals[i], idVal...)\n\t\t\t}\n\t\t}\n\n\t\t// Handle the update by deleting from the index first\n\t\tif update {\n\t\t\tvar (\n\t\t\t\tokExist   bool\n\t\t\t\tvalsExist [][]byte\n\t\t\t\terr       error\n\t\t\t)\n\t\t\tswitch indexer := indexSchema.Indexer.(type) {\n\t\t\tcase SingleIndexer:\n\t\t\t\tvar valExist []byte\n\t\t\t\tokExist, valExist, err = indexer.FromObject(existing)\n\t\t\t\tvalsExist = [][]byte{valExist}\n\t\t\tcase MultiIndexer:\n\t\t\t\tokExist, valsExist, err = indexer.FromObject(existing)\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"failed to build index '%s': %v\", name, err)\n\t\t\t}\n\t\t\tif okExist {\n\t\t\t\tfor i, valExist := range valsExist {\n\t\t\t\t\t// Handle non-unique index by computing a unique index.\n\t\t\t\t\t// This is done by appending the primary key which must\n\t\t\t\t\t// be unique anyways.\n\t\t\t\t\tif !indexSchema.Unique {\n\t\t\t\t\t\tvalExist = append(valExist, idVal...)\n\t\t\t\t\t}\n\n\t\t\t\t\t// If we are writing to the same index with the same value,\n\t\t\t\t\t// we can avoid the delete as the insert will overwrite the\n\t\t\t\t\t// value anyways.\n\t\t\t\t\tif i >= len(vals) || !bytes.Equal(valExist, vals[i]) {\n\t\t\t\t\t\tindexTxn.Delete(valExist)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// If there is no index value, either this is an error or an expected\n\t\t// case and we can skip updating\n\t\tif !ok {\n\t\t\tif indexSchema.AllowMissing {\n\t\t\t\tcontinue\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"missing value for index '%s'\", name)\n\t\t\t}\n\t\t}\n\n\t\t// Update the value of the index\n\t\tfor _, val := range vals {\n\t\t\tindexTxn.Insert(val, obj)\n\t\t}\n\t}\n\tif txn.changes != nil {\n\t\ttxn.changes = append(txn.changes, Change{\n\t\t\tTable:      table,\n\t\t\tBefore:     existing, // might be nil on a create\n\t\t\tAfter:      obj,\n\t\t\tprimaryKey: idVal,\n\t\t})\n\t}\n\treturn nil\n}\n\n// Delete is used to delete a single object from the given table.\n// This object must already exist in the table.\nfunc (txn *Txn) Delete(table string, obj interface{}) error {\n\tif !txn.write {\n\t\treturn fmt.Errorf(\"cannot delete in read-only transaction\")\n\t}\n\n\t// Get the table schema\n\ttableSchema, ok := txn.db.schema.Tables[table]\n\tif !ok {\n\t\treturn fmt.Errorf(\"invalid table '%s'\", table)\n\t}\n\n\t// Get the primary ID of the object\n\tidSchema := tableSchema.Indexes[id]\n\tidIndexer := idSchema.Indexer.(SingleIndexer)\n\tok, idVal, err := idIndexer.FromObject(obj)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to build primary index: %v\", err)\n\t}\n\tif !ok {\n\t\treturn fmt.Errorf(\"object missing primary index\")\n\t}\n\n\t// Lookup the object by ID first, check if we should continue\n\tidTxn := txn.writableIndex(table, id)\n\texisting, ok := idTxn.Get(idVal)\n\tif !ok {\n\t\treturn ErrNotFound\n\t}\n\n\t// Remove the object from all the indexes\n\tfor name, indexSchema := range tableSchema.Indexes {\n\t\tindexTxn := txn.writableIndex(table, name)\n\n\t\t// Handle the update by deleting from the index first\n\t\tvar (\n\t\t\tok   bool\n\t\t\tvals [][]byte\n\t\t\terr  error\n\t\t)\n\t\tswitch indexer := indexSchema.Indexer.(type) {\n\t\tcase SingleIndexer:\n\t\t\tvar val []byte\n\t\t\tok, val, err = indexer.FromObject(existing)\n\t\t\tvals = [][]byte{val}\n\t\tcase MultiIndexer:\n\t\t\tok, vals, err = indexer.FromObject(existing)\n\t\t}\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to build index '%s': %v\", name, err)\n\t\t}\n\t\tif ok {\n\t\t\t// Handle non-unique index by computing a unique index.\n\t\t\t// This is done by appending the primary key which must\n\t\t\t// be unique anyways.\n\t\t\tfor _, val := range vals {\n\t\t\t\tif !indexSchema.Unique {\n\t\t\t\t\tval = append(val, idVal...)\n\t\t\t\t}\n\t\t\t\tindexTxn.Delete(val)\n\t\t\t}\n\t\t}\n\t}\n\tif txn.changes != nil {\n\t\ttxn.changes = append(txn.changes, Change{\n\t\t\tTable:      table,\n\t\t\tBefore:     existing,\n\t\t\tAfter:      nil, // Now nil indicates deletion\n\t\t\tprimaryKey: idVal,\n\t\t})\n\t}\n\treturn nil\n}\n\n// DeletePrefix is used to delete an entire subtree based on a prefix.\n// The given index must be a prefix index, and will be used to perform a scan and enumerate the set of objects to delete.\n// These will be removed from all other indexes, and then a special prefix operation will delete the objects from the given index in an efficient subtree delete operation.\n// This is useful when you have a very large number of objects indexed by the given index, along with a much smaller number of entries in the other indexes for those objects.\nfunc (txn *Txn) DeletePrefix(table string, prefix_index string, prefix string) (bool, error) {\n\tif !txn.write {\n\t\treturn false, fmt.Errorf(\"cannot delete in read-only transaction\")\n\t}\n\n\tif !strings.HasSuffix(prefix_index, \"_prefix\") {\n\t\treturn false, fmt.Errorf(\"Index name for DeletePrefix must be a prefix index, Got %v \", prefix_index)\n\t}\n\n\tdeletePrefixIndex := strings.TrimSuffix(prefix_index, \"_prefix\")\n\n\t// Get an iterator over all of the keys with the given prefix.\n\tentries, err := txn.Get(table, prefix_index, prefix)\n\tif err != nil {\n\t\treturn false, fmt.Errorf(\"failed kvs lookup: %s\", err)\n\t}\n\t// Get the table schema\n\ttableSchema, ok := txn.db.schema.Tables[table]\n\tif !ok {\n\t\treturn false, fmt.Errorf(\"invalid table '%s'\", table)\n\t}\n\n\tfoundAny := false\n\tfor entry := entries.Next(); entry != nil; entry = entries.Next() {\n\t\tif !foundAny {\n\t\t\tfoundAny = true\n\t\t}\n\t\t// Get the primary ID of the object\n\t\tidSchema := tableSchema.Indexes[id]\n\t\tidIndexer := idSchema.Indexer.(SingleIndexer)\n\t\tok, idVal, err := idIndexer.FromObject(entry)\n\t\tif err != nil {\n\t\t\treturn false, fmt.Errorf(\"failed to build primary index: %v\", err)\n\t\t}\n\t\tif !ok {\n\t\t\treturn false, fmt.Errorf(\"object missing primary index\")\n\t\t}\n\t\tif txn.changes != nil {\n\t\t\t// Record the deletion\n\t\t\tidTxn := txn.writableIndex(table, id)\n\t\t\texisting, ok := idTxn.Get(idVal)\n\t\t\tif ok {\n\t\t\t\ttxn.changes = append(txn.changes, Change{\n\t\t\t\t\tTable:      table,\n\t\t\t\t\tBefore:     existing,\n\t\t\t\t\tAfter:      nil, // Now nil indicates deletion\n\t\t\t\t\tprimaryKey: idVal,\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\t\t// Remove the object from all the indexes except the given prefix index\n\t\tfor name, indexSchema := range tableSchema.Indexes {\n\t\t\tif name == deletePrefixIndex {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tindexTxn := txn.writableIndex(table, name)\n\n\t\t\t// Handle the update by deleting from the index first\n\t\t\tvar (\n\t\t\t\tok   bool\n\t\t\t\tvals [][]byte\n\t\t\t\terr  error\n\t\t\t)\n\t\t\tswitch indexer := indexSchema.Indexer.(type) {\n\t\t\tcase SingleIndexer:\n\t\t\t\tvar val []byte\n\t\t\t\tok, val, err = indexer.FromObject(entry)\n\t\t\t\tvals = [][]byte{val}\n\t\t\tcase MultiIndexer:\n\t\t\t\tok, vals, err = indexer.FromObject(entry)\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\treturn false, fmt.Errorf(\"failed to build index '%s': %v\", name, err)\n\t\t\t}\n\n\t\t\tif ok {\n\t\t\t\t// Handle non-unique index by computing a unique index.\n\t\t\t\t// This is done by appending the primary key which must\n\t\t\t\t// be unique anyways.\n\t\t\t\tfor _, val := range vals {\n\t\t\t\t\tif !indexSchema.Unique {\n\t\t\t\t\t\tval = append(val, idVal...)\n\t\t\t\t\t}\n\t\t\t\t\tindexTxn.Delete(val)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t}\n\tif foundAny {\n\t\tindexTxn := txn.writableIndex(table, deletePrefixIndex)\n\t\tok = indexTxn.DeletePrefix([]byte(prefix))\n\t\tif !ok {\n\t\t\tpanic(fmt.Errorf(\"prefix %v matched some entries but DeletePrefix did not delete any \", prefix))\n\t\t}\n\t\treturn true, nil\n\t}\n\treturn false, nil\n}\n\n// DeleteAll is used to delete all the objects in a given table\n// matching the constraints on the index\nfunc (txn *Txn) DeleteAll(table, index string, args ...interface{}) (int, error) {\n\tif !txn.write {\n\t\treturn 0, fmt.Errorf(\"cannot delete in read-only transaction\")\n\t}\n\n\t// Get all the objects\n\titer, err := txn.Get(table, index, args...)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\t// Put them into a slice so there are no safety concerns while actually\n\t// performing the deletes\n\tvar objs []interface{}\n\tfor {\n\t\tobj := iter.Next()\n\t\tif obj == nil {\n\t\t\tbreak\n\t\t}\n\n\t\tobjs = append(objs, obj)\n\t}\n\n\t// Do the deletes\n\tnum := 0\n\tfor _, obj := range objs {\n\t\tif err := txn.Delete(table, obj); err != nil {\n\t\t\treturn num, err\n\t\t}\n\t\tnum++\n\t}\n\treturn num, nil\n}\n\n// FirstWatch is used to return the first matching object for\n// the given constraints on the index along with the watch channel.\n//\n// Note that all values read in the transaction form a consistent snapshot\n// from the time when the transaction was created.\n//\n// The watch channel is closed when a subsequent write transaction\n// has updated the result of the query. Since each read transaction\n// operates on an isolated snapshot, a new read transaction must be\n// started to observe the changes that have been made.\n//\n// If the value of index ends with \"_prefix\", FirstWatch will perform a prefix\n// match instead of full match on the index. The registered indexer must implement\n// PrefixIndexer, otherwise an error is returned.\nfunc (txn *Txn) FirstWatch(table, index string, args ...interface{}) (<-chan struct{}, interface{}, error) {\n\t// Get the index value\n\tindexSchema, val, err := txn.getIndexValue(table, index, args...)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Get the index itself\n\tindexTxn := txn.readableIndex(table, indexSchema.Name)\n\n\t// Do an exact lookup\n\tif indexSchema.Unique && val != nil && indexSchema.Name == index {\n\t\twatch, obj, ok := indexTxn.GetWatch(val)\n\t\tif !ok {\n\t\t\treturn watch, nil, nil\n\t\t}\n\t\treturn watch, obj, nil\n\t}\n\n\t// Handle non-unique index by using an iterator and getting the first value\n\titer := indexTxn.Root().Iterator()\n\twatch := iter.SeekPrefixWatch(val)\n\t_, value, _ := iter.Next()\n\treturn watch, value, nil\n}\n\n// LastWatch is used to return the last matching object for\n// the given constraints on the index along with the watch channel.\n//\n// Note that all values read in the transaction form a consistent snapshot\n// from the time when the transaction was created.\n//\n// The watch channel is closed when a subsequent write transaction\n// has updated the result of the query. Since each read transaction\n// operates on an isolated snapshot, a new read transaction must be\n// started to observe the changes that have been made.\n//\n// If the value of index ends with \"_prefix\", LastWatch will perform a prefix\n// match instead of full match on the index. The registered indexer must implement\n// PrefixIndexer, otherwise an error is returned.\nfunc (txn *Txn) LastWatch(table, index string, args ...interface{}) (<-chan struct{}, interface{}, error) {\n\t// Get the index value\n\tindexSchema, val, err := txn.getIndexValue(table, index, args...)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Get the index itself\n\tindexTxn := txn.readableIndex(table, indexSchema.Name)\n\n\t// Do an exact lookup\n\tif indexSchema.Unique && val != nil && indexSchema.Name == index {\n\t\twatch, obj, ok := indexTxn.GetWatch(val)\n\t\tif !ok {\n\t\t\treturn watch, nil, nil\n\t\t}\n\t\treturn watch, obj, nil\n\t}\n\n\t// Handle non-unique index by using an iterator and getting the last value\n\titer := indexTxn.Root().ReverseIterator()\n\twatch := iter.SeekPrefixWatch(val)\n\t_, value, _ := iter.Previous()\n\treturn watch, value, nil\n}\n\n// First is used to return the first matching object for\n// the given constraints on the index.\n//\n// Note that all values read in the transaction form a consistent snapshot\n// from the time when the transaction was created.\nfunc (txn *Txn) First(table, index string, args ...interface{}) (interface{}, error) {\n\t_, val, err := txn.FirstWatch(table, index, args...)\n\treturn val, err\n}\n\n// Last is used to return the last matching object for\n// the given constraints on the index.\n//\n// Note that all values read in the transaction form a consistent snapshot\n// from the time when the transaction was created.\nfunc (txn *Txn) Last(table, index string, args ...interface{}) (interface{}, error) {\n\t_, val, err := txn.LastWatch(table, index, args...)\n\treturn val, err\n}\n\n// LongestPrefix is used to fetch the longest prefix match for the given\n// constraints on the index. Note that this will not work with the memdb\n// StringFieldIndex because it adds null terminators which prevent the\n// algorithm from correctly finding a match (it will get to right before the\n// null and fail to find a leaf node). This should only be used where the prefix\n// given is capable of matching indexed entries directly, which typically only\n// applies to a custom indexer. See the unit test for an example.\n//\n// Note that all values read in the transaction form a consistent snapshot\n// from the time when the transaction was created.\nfunc (txn *Txn) LongestPrefix(table, index string, args ...interface{}) (interface{}, error) {\n\t// Enforce that this only works on prefix indexes.\n\tif !strings.HasSuffix(index, \"_prefix\") {\n\t\treturn nil, fmt.Errorf(\"must use '%s_prefix' on index\", index)\n\t}\n\n\t// Get the index value.\n\tindexSchema, val, err := txn.getIndexValue(table, index, args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// This algorithm only makes sense against a unique index, otherwise the\n\t// index keys will have the IDs appended to them.\n\tif !indexSchema.Unique {\n\t\treturn nil, fmt.Errorf(\"index '%s' is not unique\", index)\n\t}\n\n\t// Find the longest prefix match with the given index.\n\tindexTxn := txn.readableIndex(table, indexSchema.Name)\n\tif _, value, ok := indexTxn.Root().LongestPrefix(val); ok {\n\t\treturn value, nil\n\t}\n\treturn nil, nil\n}\n\n// getIndexValue is used to get the IndexSchema and the value\n// used to scan the index given the parameters. This handles prefix based\n// scans when the index has the \"_prefix\" suffix. The index must support\n// prefix iteration.\nfunc (txn *Txn) getIndexValue(table, index string, args ...interface{}) (*IndexSchema, []byte, error) {\n\t// Get the table schema\n\ttableSchema, ok := txn.db.schema.Tables[table]\n\tif !ok {\n\t\treturn nil, nil, fmt.Errorf(\"invalid table '%s'\", table)\n\t}\n\n\t// Check for a prefix scan\n\tprefixScan := false\n\tif strings.HasSuffix(index, \"_prefix\") {\n\t\tindex = strings.TrimSuffix(index, \"_prefix\")\n\t\tprefixScan = true\n\t}\n\n\t// Get the index schema\n\tindexSchema, ok := tableSchema.Indexes[index]\n\tif !ok {\n\t\treturn nil, nil, fmt.Errorf(\"invalid index '%s'\", index)\n\t}\n\n\t// Hot-path for when there are no arguments\n\tif len(args) == 0 {\n\t\treturn indexSchema, nil, nil\n\t}\n\n\t// Special case the prefix scanning\n\tif prefixScan {\n\t\tprefixIndexer, ok := indexSchema.Indexer.(PrefixIndexer)\n\t\tif !ok {\n\t\t\treturn indexSchema, nil,\n\t\t\t\tfmt.Errorf(\"index '%s' does not support prefix scanning\", index)\n\t\t}\n\n\t\tval, err := prefixIndexer.PrefixFromArgs(args...)\n\t\tif err != nil {\n\t\t\treturn indexSchema, nil, fmt.Errorf(\"index error: %v\", err)\n\t\t}\n\t\treturn indexSchema, val, err\n\t}\n\n\t// Get the exact match index\n\tval, err := indexSchema.Indexer.FromArgs(args...)\n\tif err != nil {\n\t\treturn indexSchema, nil, fmt.Errorf(\"index error: %v\", err)\n\t}\n\treturn indexSchema, val, err\n}\n\n// ResultIterator is used to iterate over a list of results from a query on a table.\n//\n// When a ResultIterator is created from a write transaction, the results from\n// Next will reflect a snapshot of the table at the time the ResultIterator is\n// created.\n// This means that calling Insert or Delete on a transaction while iterating is\n// allowed, but the changes made by Insert or Delete will not be observed in the\n// results returned from subsequent calls to Next. For example if an item is deleted\n// from the index used by the iterator it will still be returned by Next. If an\n// item is inserted into the index used by the iterator, it will not be returned\n// by Next. However, an iterator created after a call to Insert or Delete will\n// reflect the modifications.\n//\n// When a ResultIterator is created from a write transaction, and there are already\n// modifications to the index used by the iterator, the modification cache of the\n// index will be invalidated. This may result in some additional allocations if\n// the same node in the index is modified again.\ntype ResultIterator interface {\n\tWatchCh() <-chan struct{}\n\t// Next returns the next result from the iterator. If there are no more results\n\t// nil is returned.\n\tNext() interface{}\n}\n\n// Get is used to construct a ResultIterator over all the rows that match the\n// given constraints of an index. The index values must match exactly (this\n// is not a range-based or prefix-based lookup) by default.\n//\n// Prefix lookups: if the named index implements PrefixIndexer, you may perform\n// prefix-based lookups by appending \"_prefix\" to the index name. In this\n// scenario, the index values given in args are treated as prefix lookups. For\n// example, a StringFieldIndex will match any string with the given value\n// as a prefix: \"mem\" matches \"memdb\".\n//\n// See the documentation for ResultIterator to understand the behaviour of the\n// returned ResultIterator.\nfunc (txn *Txn) Get(table, index string, args ...interface{}) (ResultIterator, error) {\n\tindexIter, val, err := txn.getIndexIterator(table, index, args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Seek the iterator to the appropriate sub-set\n\twatchCh := indexIter.SeekPrefixWatch(val)\n\n\t// Create an iterator\n\titer := &radixIterator{\n\t\titer:    indexIter,\n\t\twatchCh: watchCh,\n\t}\n\treturn iter, nil\n}\n\n// GetReverse is used to construct a Reverse ResultIterator over all the\n// rows that match the given constraints of an index.\n// The returned ResultIterator's Next() will return the next Previous value.\n//\n// See the documentation on Get for details on arguments.\n//\n// See the documentation for ResultIterator to understand the behaviour of the\n// returned ResultIterator.\nfunc (txn *Txn) GetReverse(table, index string, args ...interface{}) (ResultIterator, error) {\n\tindexIter, val, err := txn.getIndexIteratorReverse(table, index, args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Seek the iterator to the appropriate sub-set\n\twatchCh := indexIter.SeekPrefixWatch(val)\n\n\t// Create an iterator\n\titer := &radixReverseIterator{\n\t\titer:    indexIter,\n\t\twatchCh: watchCh,\n\t}\n\treturn iter, nil\n}\n\n// LowerBound is used to construct a ResultIterator over all the the range of\n// rows that have an index value greater than or equal to the provide args.\n// Calling this then iterating until the rows are larger than required allows\n// range scans within an index. It is not possible to watch the resulting\n// iterator since the radix tree doesn't efficiently allow watching on lower\n// bound changes. The WatchCh returned will be nill and so will block forever.\n//\n// If the value of index ends with \"_prefix\", LowerBound will perform a prefix match instead of\n// a full match on the index. The registered index must implement PrefixIndexer,\n// otherwise an error is returned.\n//\n// See the documentation for ResultIterator to understand the behaviour of the\n// returned ResultIterator.\nfunc (txn *Txn) LowerBound(table, index string, args ...interface{}) (ResultIterator, error) {\n\tindexIter, val, err := txn.getIndexIterator(table, index, args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Seek the iterator to the appropriate sub-set\n\tindexIter.SeekLowerBound(val)\n\n\t// Create an iterator\n\titer := &radixIterator{\n\t\titer: indexIter,\n\t}\n\treturn iter, nil\n}\n\n// ReverseLowerBound is used to construct a Reverse ResultIterator over all the\n// the range of rows that have an index value less than or equal to the\n// provide args.  Calling this then iterating until the rows are lower than\n// required allows range scans within an index. It is not possible to watch the\n// resulting iterator since the radix tree doesn't efficiently allow watching\n// on lower bound changes. The WatchCh returned will be nill and so will block\n// forever.\n//\n// See the documentation for ResultIterator to understand the behaviour of the\n// returned ResultIterator.\nfunc (txn *Txn) ReverseLowerBound(table, index string, args ...interface{}) (ResultIterator, error) {\n\tindexIter, val, err := txn.getIndexIteratorReverse(table, index, args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Seek the iterator to the appropriate sub-set\n\tindexIter.SeekReverseLowerBound(val)\n\n\t// Create an iterator\n\titer := &radixReverseIterator{\n\t\titer: indexIter,\n\t}\n\treturn iter, nil\n}\n\n// objectID is a tuple of table name and the raw internal id byte slice\n// converted to a string. It's only converted to a string to make it comparable\n// so this struct can be used as a map index.\ntype objectID struct {\n\tTable    string\n\tIndexVal string\n}\n\n// mutInfo stores metadata about mutations to allow collapsing multiple\n// mutations to the same object into one.\ntype mutInfo struct {\n\tfirstBefore interface{}\n\tlastIdx     int\n}\n\n// Changes returns the set of object changes that have been made in the\n// transaction so far. If change tracking is not enabled it wil always return\n// nil. It can be called before or after Commit. If it is before Commit it will\n// return all changes made so far which may not be the same as the final\n// Changes. After abort it will always return nil. As with other Txn methods\n// it's not safe to call this from a different goroutine than the one making\n// mutations or committing the transaction. Mutations will appear in the order\n// they were performed in the transaction but multiple operations to the same\n// object will be collapsed so only the effective overall change to that object\n// is present. If transaction operations are dependent (e.g. copy object X to Y\n// then delete X) this might mean the set of mutations is incomplete to verify\n// history, but it is complete in that the net effect is preserved (Y got a new\n// value, X got removed).\nfunc (txn *Txn) Changes() Changes {\n\tif txn.changes == nil {\n\t\treturn nil\n\t}\n\n\t// De-duplicate mutations by key so all take effect at the point of the last\n\t// write but we keep the mutations in order.\n\tdups := make(map[objectID]mutInfo)\n\tfor i, m := range txn.changes {\n\t\toid := objectID{\n\t\t\tTable:    m.Table,\n\t\t\tIndexVal: string(m.primaryKey),\n\t\t}\n\t\t// Store the latest mutation index for each key value\n\t\tmi, ok := dups[oid]\n\t\tif !ok {\n\t\t\t// First entry for key, store the before value\n\t\t\tmi.firstBefore = m.Before\n\t\t}\n\t\tmi.lastIdx = i\n\t\tdups[oid] = mi\n\t}\n\tif len(dups) == len(txn.changes) {\n\t\t// No duplicates found, fast path return it as is\n\t\treturn txn.changes\n\t}\n\n\t// Need to remove the duplicates\n\tcs := make(Changes, 0, len(dups))\n\tfor i, m := range txn.changes {\n\t\toid := objectID{\n\t\t\tTable:    m.Table,\n\t\t\tIndexVal: string(m.primaryKey),\n\t\t}\n\t\tmi := dups[oid]\n\t\tif mi.lastIdx == i {\n\t\t\t// This was the latest value for this key copy it with the before value in\n\t\t\t// case it's different. Note that m is not a pointer so we are not\n\t\t\t// modifying the txn.changeSet here - it's already a copy.\n\t\t\tm.Before = mi.firstBefore\n\n\t\t\t// Edge case - if the object was inserted and then eventually deleted in\n\t\t\t// the same transaction, then the net affect on that key is a no-op. Don't\n\t\t\t// emit a mutation with nil for before and after as it's meaningless and\n\t\t\t// might violate expectations and cause a panic in code that assumes at\n\t\t\t// least one must be set.\n\t\t\tif m.Before == nil && m.After == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tcs = append(cs, m)\n\t\t}\n\t}\n\t// Store the de-duped version in case this is called again\n\ttxn.changes = cs\n\treturn cs\n}\n\nfunc (txn *Txn) getIndexIterator(table, index string, args ...interface{}) (*iradix.Iterator, []byte, error) {\n\t// Get the index value to scan\n\tindexSchema, val, err := txn.getIndexValue(table, index, args...)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Get the index itself\n\tindexTxn := txn.readableIndex(table, indexSchema.Name)\n\tindexRoot := indexTxn.Root()\n\n\t// Get an iterator over the index\n\tindexIter := indexRoot.Iterator()\n\treturn indexIter, val, nil\n}\n\nfunc (txn *Txn) getIndexIteratorReverse(table, index string, args ...interface{}) (*iradix.ReverseIterator, []byte, error) {\n\t// Get the index value to scan\n\tindexSchema, val, err := txn.getIndexValue(table, index, args...)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Get the index itself\n\tindexTxn := txn.readableIndex(table, indexSchema.Name)\n\tindexRoot := indexTxn.Root()\n\n\t// Get an interator over the index\n\tindexIter := indexRoot.ReverseIterator()\n\treturn indexIter, val, nil\n}\n\n// Defer is used to push a new arbitrary function onto a stack which\n// gets called when a transaction is committed and finished. Deferred\n// functions are called in LIFO order, and only invoked at the end of\n// write transactions.\nfunc (txn *Txn) Defer(fn func()) {\n\ttxn.after = append(txn.after, fn)\n}\n\n// radixIterator is used to wrap an underlying iradix iterator.\n// This is much more efficient than a sliceIterator as we are not\n// materializing the entire view.\ntype radixIterator struct {\n\titer    *iradix.Iterator\n\twatchCh <-chan struct{}\n}\n\nfunc (r *radixIterator) WatchCh() <-chan struct{} {\n\treturn r.watchCh\n}\n\nfunc (r *radixIterator) Next() interface{} {\n\t_, value, ok := r.iter.Next()\n\tif !ok {\n\t\treturn nil\n\t}\n\treturn value\n}\n\ntype radixReverseIterator struct {\n\titer    *iradix.ReverseIterator\n\twatchCh <-chan struct{}\n}\n\nfunc (r *radixReverseIterator) Next() interface{} {\n\t_, value, ok := r.iter.Previous()\n\tif !ok {\n\t\treturn nil\n\t}\n\treturn value\n}\n\nfunc (r *radixReverseIterator) WatchCh() <-chan struct{} {\n\treturn r.watchCh\n}\n\n// Snapshot creates a snapshot of the current state of the transaction.\n// Returns a new read-only transaction or nil if the transaction is already\n// aborted or committed.\nfunc (txn *Txn) Snapshot() *Txn {\n\tif txn.rootTxn == nil {\n\t\treturn nil\n\t}\n\n\tsnapshot := &Txn{\n\t\tdb:      txn.db,\n\t\trootTxn: txn.rootTxn.Clone(),\n\t}\n\n\t// Commit sub-transactions into the snapshot\n\tfor key, subTxn := range txn.modified {\n\t\tpath := indexPath(key.Table, key.Index)\n\t\tfinal := subTxn.CommitOnly()\n\t\tsnapshot.rootTxn.Insert(path, final)\n\t}\n\n\treturn snapshot\n}\n"
        },
        {
          "name": "txn_test.go",
          "type": "blob",
          "size": 45.294921875,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage memdb\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n\t\"strings\"\n\t\"testing\"\n)\n\nfunc testDB(t *testing.T) *MemDB {\n\tdb, err := NewMemDB(testValidSchema())\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\treturn db\n}\n\nfunc TestTxn_Read_AbortCommit(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(false) // Readonly\n\n\ttxn.Abort()\n\ttxn.Abort()\n\ttxn.Commit()\n\ttxn.Commit()\n}\n\nfunc TestTxn_Write_AbortCommit(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(true) // Write\n\n\ttxn.Abort()\n\ttxn.Abort()\n\ttxn.Commit()\n\ttxn.Commit()\n\n\ttxn = db.Txn(true) // Write\n\n\ttxn.Commit()\n\ttxn.Commit()\n\ttxn.Abort()\n\ttxn.Abort()\n}\n\nfunc TestTxn_Insert_First(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(true)\n\n\tobj := testObj()\n\terr := txn.Insert(\"main\", obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\traw, err := txn.First(\"main\", \"id\", obj.ID)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\tif raw != obj {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj)\n\t}\n}\n\nfunc TestTxn_InsertUpdate_First(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(true)\n\n\tobj := &TestObject{\n\t\tID:  \"my-object\",\n\t\tFoo: \"abc\",\n\t\tQux: []string{\"abc1\", \"abc2\"},\n\t}\n\terr := txn.Insert(\"main\", obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\traw, err := txn.First(\"main\", \"id\", obj.ID)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\tif raw != obj {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj)\n\t}\n\n\t// Update the object\n\tobj2 := &TestObject{\n\t\tID:  \"my-object\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\terr = txn.Insert(\"main\", obj2)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\traw, err = txn.First(\"main\", \"id\", obj.ID)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\tif raw != obj2 {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj)\n\t}\n}\n\nfunc TestTxn_InsertUpdate_First_NonUnique(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(true)\n\n\tobj := &TestObject{\n\t\tID:  \"my-object\",\n\t\tFoo: \"abc\",\n\t\tQux: []string{\"abc1\", \"abc2\"},\n\t}\n\terr := txn.Insert(\"main\", obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\traw, err := txn.First(\"main\", \"foo\", obj.Foo)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\tif raw != obj {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj)\n\t}\n\n\t// Update the object\n\tobj2 := &TestObject{\n\t\tID:  \"my-object\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\terr = txn.Insert(\"main\", obj2)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\traw, err = txn.First(\"main\", \"foo\", obj2.Foo)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\tif raw != obj2 {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj2)\n\t}\n\n\t// Lookup of the old value should fail\n\traw, err = txn.First(\"main\", \"foo\", obj.Foo)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\tif raw != nil {\n\t\tt.Fatalf(\"bad: %#v\", raw)\n\t}\n}\n\nfunc TestTxn_InsertUpdate_First_MultiIndex(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(true)\n\n\tobj := &TestObject{\n\t\tID:  \"my-object\",\n\t\tFoo: \"abc\",\n\t\tQux: []string{\"abc1\", \"abc2\"},\n\t}\n\terr := txn.Insert(\"main\", obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\traw, err := txn.First(\"main\", \"qux\", obj.Qux[0])\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\tif raw != obj {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj)\n\t}\n\n\traw, err = txn.First(\"main\", \"qux\", obj.Qux[1])\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\tif raw != obj {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj)\n\t}\n\n\t// Update the object\n\tobj2 := &TestObject{\n\t\tID:  \"my-object\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\terr = txn.Insert(\"main\", obj2)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\traw, err = txn.First(\"main\", \"qux\", obj2.Qux[0])\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\tif raw != obj2 {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj2)\n\t}\n\n\traw, err = txn.First(\"main\", \"qux\", obj2.Qux[1])\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\tif raw != obj2 {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj2)\n\t}\n\n\t// Lookup of the old value should fail\n\traw, err = txn.First(\"main\", \"qux\", obj.Qux[0])\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\tif raw != nil {\n\t\tt.Fatalf(\"bad: %#v\", raw)\n\t}\n\n\traw, err = txn.First(\"main\", \"qux\", obj.Qux[1])\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\tif raw != nil {\n\t\tt.Fatalf(\"bad: %#v\", raw)\n\t}\n}\n\nfunc TestTxn_First_NonUnique_Multiple(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(true)\n\n\tobj := &TestObject{\n\t\tID:  \"my-object\",\n\t\tFoo: \"abc\",\n\t\tQux: []string{\"abc1\", \"abc2\"},\n\t}\n\tobj2 := &TestObject{\n\t\tID:  \"my-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\tobj3 := &TestObject{\n\t\tID:  \"my-other-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\n\terr := txn.Insert(\"main\", obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj2)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj3)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// The first object has a unique secondary value\n\traw, err := txn.First(\"main\", \"foo\", obj.Foo)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw != obj {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj)\n\t}\n\n\t// Second and third object share secondary value,\n\t// but the primary ID of obj2 should be first\n\traw, err = txn.First(\"main\", \"foo\", obj2.Foo)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw != obj2 {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj2)\n\t}\n}\n\nfunc TestTxn_First_MultiIndex_Multiple(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(true)\n\n\tobj := &TestObject{\n\t\tID:  \"my-object\",\n\t\tFoo: \"abc\",\n\t\tQux: []string{\"abc1\", \"abc2\"},\n\t}\n\tobj2 := &TestObject{\n\t\tID:  \"my-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\tobj3 := &TestObject{\n\t\tID:  \"my-other-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\n\terr := txn.Insert(\"main\", obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj2)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj3)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// The first object has a unique secondary value\n\traw, err := txn.First(\"main\", \"qux\", obj.Qux[0])\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw != obj {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj)\n\t}\n\n\t// Second and third object share secondary value,\n\t// but the primary ID of obj2 should be first\n\traw, err = txn.First(\"main\", \"qux\", obj2.Qux[0])\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw != obj2 {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj2)\n\t}\n}\n\nfunc TestTxn_Last_NonUnique_Multiple(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(true)\n\n\tobj := &TestObject{\n\t\tID:  \"my-object\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"abc1\", \"abc2\"},\n\t}\n\tobj2 := &TestObject{\n\t\tID:  \"my-cool-thing\",\n\t\tFoo: \"abc\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\tobj3 := &TestObject{\n\t\tID:  \"my-other-cool-thing\",\n\t\tFoo: \"abc\",\n\t\tQux: []string{\"xyz1\", \"xyz2\", \"xyz3\"},\n\t}\n\n\terr := txn.Insert(\"main\", obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj2)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj3)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// The last object has a unique secondary value\n\traw, err := txn.Last(\"main\", \"foo\", obj.Foo)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw != obj {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj)\n\t}\n\n\t// Second and third object share secondary value,\n\t// but the primary ID of obj3 should be last\n\traw, err = txn.Last(\"main\", \"foo\", obj3.Foo)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw != obj3 {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj3)\n\t}\n}\n\nfunc TestTxn_Last_MultiIndex_Multiple(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(true)\n\n\tobj := &TestObject{\n\t\tID:  \"my-object\",\n\t\tFoo: \"abc\",\n\t\tQux: []string{\"abc1\", \"abc2\"},\n\t}\n\tobj2 := &TestObject{\n\t\tID:  \"my-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\tobj3 := &TestObject{\n\t\tID:  \"my-other-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\", \"zyx1\"},\n\t}\n\n\terr := txn.Insert(\"main\", obj)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj2)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj3)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// The last object has a unique secondary value\n\traw, err := txn.Last(\"main\", \"qux\", obj3.Qux[2])\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw != obj3 {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj)\n\t}\n\n\t// Second and third object share secondary value,\n\t// but the primary ID of obj2 should be first\n\traw, err = txn.Last(\"main\", \"qux\", obj3.Qux[0])\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw != obj3 {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj3)\n\t}\n}\nfunc TestTxn_InsertDelete_Simple(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(true)\n\n\tobj1 := &TestObject{\n\t\tID:  \"my-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\tobj2 := &TestObject{\n\t\tID:  \"my-other-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\n\terr := txn.Insert(\"main\", obj1)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj2)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// Check the shared secondary value,\n\t// but the primary ID of obj2 should be first\n\traw, err := txn.First(\"main\", \"foo\", obj2.Foo)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw != obj1 {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t}\n\n\t// Commit and start a new transaction\n\ttxn.Commit()\n\ttxn = db.Txn(true)\n\n\t// Delete obj1\n\terr = txn.Delete(\"main\", obj1)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// Delete obj1 again and expect ErrNotFound\n\terr = txn.Delete(\"main\", obj1)\n\tif err != ErrNotFound {\n\t\tt.Fatalf(\"expected err to be %v, got %v\", ErrNotFound, err)\n\t}\n\n\t// Lookup of the primary obj1 should fail\n\traw, err = txn.First(\"main\", \"id\", obj1.ID)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw != nil {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t}\n\n\t// Commit and start a new read transaction\n\ttxn.Commit()\n\ttxn = db.Txn(false)\n\n\t// Lookup of the primary obj1 should fail\n\traw, err = txn.First(\"main\", \"id\", obj1.ID)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw != nil {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t}\n\n\t// Check the shared secondary value,\n\t// but the primary ID of obj2 should be first\n\traw, err = txn.First(\"main\", \"foo\", obj2.Foo)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw != obj2 {\n\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj2)\n\t}\n}\n\nfunc TestTxn_InsertGet_Simple(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(true)\n\n\tobj1 := &TestObject{\n\t\tID:  \"my-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\"},\n\t}\n\tobj2 := &TestObject{\n\t\tID:  \"my-other-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\n\terr := txn.Insert(\"main\", obj1)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj2)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\tcheckResult := func(txn *Txn) {\n\t\t// Attempt a row scan on the ID\n\t\tresult, err := txn.Get(\"main\", \"id\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj2 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj2)\n\t\t}\n\n\t\tif raw := result.Next(); raw != nil {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, nil)\n\t\t}\n\n\t\t// Attempt a row scan on the ID with specific ID\n\t\tresult, err = txn.Get(\"main\", \"id\", obj1.ID)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t\t}\n\n\t\tif raw := result.Next(); raw != nil {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, nil)\n\t\t}\n\n\t\t// Attempt a row scan secondary index\n\t\tresult, err = txn.Get(\"main\", \"foo\", obj1.Foo)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj2 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj2)\n\t\t}\n\n\t\tif raw := result.Next(); raw != nil {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, nil)\n\t\t}\n\n\t\t// Attempt a row scan multi index\n\t\tresult, err = txn.Get(\"main\", \"qux\", obj1.Qux[0])\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj2 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj2)\n\t\t}\n\n\t\tif raw := result.Next(); raw != nil {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, nil)\n\t\t}\n\n\t\tresult, err = txn.Get(\"main\", \"qux\", obj2.Qux[1])\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj2 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj2)\n\t\t}\n\n\t\tif raw := result.Next(); raw != nil {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, nil)\n\t\t}\n\t}\n\n\t// Check the results within the txn\n\tcheckResult(txn)\n\n\t// Commit and start a new read transaction\n\ttxn.Commit()\n\ttxn = db.Txn(false)\n\n\t// Check the results in a new txn\n\tcheckResult(txn)\n}\n\nfunc TestTxn_InsertGetReverse_Simple(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(true)\n\n\tobj1 := &TestObject{\n\t\tID:  \"my-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\tobj2 := &TestObject{\n\t\tID:  \"my-other-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\"},\n\t}\n\n\terr := txn.Insert(\"main\", obj1)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj2)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\tcheckResult := func(txn *Txn) {\n\t\t// Attempt a row scan on the ID\n\t\tresult, err := txn.GetReverse(\"main\", \"id\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj2 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj2)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t\t}\n\n\t\tif raw := result.Next(); raw != nil {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, nil)\n\t\t}\n\n\t\t// Attempt a row scan on the ID with specific ID\n\t\tresult, err = txn.GetReverse(\"main\", \"id\", obj1.ID)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t\t}\n\n\t\tif raw := result.Next(); raw != nil {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, nil)\n\t\t}\n\n\t\t// Attempt a row scan secondary index\n\t\tresult, err = txn.GetReverse(\"main\", \"foo\", obj2.Foo)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj2 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj2)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t\t}\n\n\t\tif raw := result.Next(); raw != nil {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, nil)\n\t\t}\n\n\t\t// Attempt a row scan multi index\n\t\tresult, err = txn.GetReverse(\"main\", \"qux\", obj2.Qux[0])\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj2 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj2)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t\t}\n\n\t\tif raw := result.Next(); raw != nil {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, nil)\n\t\t}\n\n\t\tresult, err = txn.GetReverse(\"main\", \"qux\", obj1.Qux[1])\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t\t}\n\n\t\tif raw := result.Next(); raw != nil {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, nil)\n\t\t}\n\t}\n\n\t// Check the results within the txn\n\tcheckResult(txn)\n\n\t// Commit and start a new read transaction\n\ttxn.Commit()\n\ttxn = db.Txn(false)\n\n\t// Check the results in a new txn\n\tcheckResult(txn)\n}\n\nfunc TestTxn_DeleteAll_Simple(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(true)\n\n\tobj1 := &TestObject{\n\t\tID:  \"my-object\",\n\t\tFoo: \"abc\",\n\t\tQux: []string{\"abc1\", \"abc1\"},\n\t}\n\tobj2 := &TestObject{\n\t\tID:  \"my-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\tobj3 := &TestObject{\n\t\tID:  \"my-other-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\n\terr := txn.Insert(\"main\", obj1)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj2)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj3)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// Do a delete that doesn't hit any objects\n\tnum, err := txn.DeleteAll(\"main\", \"id\", \"dogs\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif num != 0 {\n\t\tt.Fatalf(\"bad: %d\", num)\n\t}\n\n\t// Delete a specific ID\n\tnum, err = txn.DeleteAll(\"main\", \"id\", obj1.ID)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif num != 1 {\n\t\tt.Fatalf(\"bad: %d\", num)\n\t}\n\n\t// Ensure we cannot lookup\n\traw, err := txn.First(\"main\", \"id\", obj1.ID)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw != nil {\n\t\tt.Fatalf(\"bad: %#v\", raw)\n\t}\n\n\t// Delete an entire secondary range\n\tnum, err = txn.DeleteAll(\"main\", \"foo\", obj2.Foo)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif num != 2 {\n\t\tt.Fatalf(\"Bad: %d\", num)\n\t}\n\n\t// Ensure we cannot lookup\n\traw, err = txn.First(\"main\", \"foo\", obj2.Foo)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw != nil {\n\t\tt.Fatalf(\"bad: %#v\", raw)\n\t}\n\n\t// Insert some more\n\terr = txn.Insert(\"main\", obj1)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj2)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj3)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// Delete an entire multiindex range\n\tnum, err = txn.DeleteAll(\"main\", \"qux\", obj2.Qux[0])\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif num != 2 {\n\t\tt.Fatalf(\"Bad: %d\", num)\n\t}\n\n\t// Ensure we cannot lookup\n\traw, err = txn.First(\"main\", \"qux\", obj2.Qux[0])\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw != nil {\n\t\tt.Fatalf(\"bad: %#v\", raw)\n\t}\n}\n\nfunc TestTxn_DeleteAll_Prefix(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(true)\n\n\tobj1 := &TestObject{\n\t\tID:  \"my-object\",\n\t\tFoo: \"abc\",\n\t\tQux: []string{\"abc1\", \"abc1\"},\n\t}\n\tobj2 := &TestObject{\n\t\tID:  \"my-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\tobj3 := &TestObject{\n\t\tID:  \"my-other-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\n\terr := txn.Insert(\"main\", obj1)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj2)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj3)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// Delete a prefix\n\tnum, err := txn.DeleteAll(\"main\", \"id_prefix\", \"my-\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif num != 3 {\n\t\tt.Fatalf(\"bad: %d\", num)\n\t}\n\n\t// Ensure we cannot lookup\n\traw, err := txn.First(\"main\", \"id_prefix\", \"my-\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw != nil {\n\t\tt.Fatalf(\"bad: %#v\", raw)\n\t}\n}\n\nfunc TestTxn_DeletePrefix(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(true)\n\n\tobj1 := &TestObject{\n\t\tID:  \"my-object\",\n\t\tFoo: \"abc\",\n\t\tQux: []string{\"abc1\", \"abc1\"},\n\t}\n\tobj2 := &TestObject{\n\t\tID:  \"my-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\tobj3 := &TestObject{\n\t\tID:  \"my-other-cool-thing\",\n\t\tFoo: \"xyz\",\n\t\tQux: []string{\"xyz1\", \"xyz2\"},\n\t}\n\n\terr := txn.Insert(\"main\", obj1)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj2)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj3)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// Lookup by qux field index\n\titerator, err := txn.Get(\"main\", \"qux\", \"abc1\")\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %v\", err)\n\t}\n\tvar objects []TestObject\n\tfor obj := iterator.Next(); obj != nil; obj = iterator.Next() {\n\t\tobject := obj.(*TestObject)\n\t\tobjects = append(objects, *object)\n\t}\n\tif len(objects) != 1 {\n\t\tt.Fatalf(\"Expected exactly one object\")\n\t}\n\texpectedID := \"my-object\"\n\tif objects[0].ID != expectedID {\n\t\tt.Fatalf(\"Unexpected id, expected %v, but got %v\", expectedID, objects[0].ID)\n\t}\n\n\t// Delete a prefix\n\tdeleted, err := txn.DeletePrefix(\"main\", \"id_prefix\", \"my-\")\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected err: %v\", err)\n\t}\n\tif !deleted {\n\t\tt.Fatalf(\"Expected DeletePrefix to return true\")\n\t}\n\n\t// Ensure we cannot lookup by id field index\n\traw, err := txn.First(\"main\", \"id_prefix\", \"my-\")\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %v\", err)\n\t}\n\tif raw != nil {\n\t\tt.Fatalf(\"Unexpected value in tree: %#v\", raw)\n\t}\n\n\t// Ensure we cannot lookup by qux or foo field indexes either anymore\n\tverifyNoResults(t, txn, \"main\", \"qux\", \"abc1\")\n\tverifyNoResults(t, txn, \"main\", \"foo\", \"abc\")\n}\nfunc verifyNoResults(t *testing.T, txn *Txn, table string, index string, value string) {\n\titerator, err := txn.Get(table, index, value)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %v\", err)\n\t}\n\tif iterator != nil {\n\t\tnext := iterator.Next()\n\t\tif next != nil {\n\t\t\tt.Fatalf(\"Unexpected values in tree, expected to be empty\")\n\t\t}\n\t}\n}\n\nfunc TestTxn_InsertGet_Prefix(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(true)\n\n\tobj1 := &TestObject{\n\t\tID:  \"my-cool-thing\",\n\t\tFoo: \"foobarbaz\",\n\t\tQux: []string{\"foobarbaz\", \"fooqux\"},\n\t}\n\tobj2 := &TestObject{\n\t\tID:  \"my-other-cool-thing\",\n\t\tFoo: \"foozipzap\",\n\t\tQux: []string{\"foozipzap\"},\n\t}\n\n\terr := txn.Insert(\"main\", obj1)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj2)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\tcheckResult := func(txn *Txn) {\n\t\t// Attempt a row scan on the ID Prefix\n\t\tresult, err := txn.Get(\"main\", \"id_prefix\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj2 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj2)\n\t\t}\n\n\t\tif raw := result.Next(); raw != nil {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, nil)\n\t\t}\n\n\t\t// Attempt a row scan on the ID with specific ID prefix\n\t\tresult, err = txn.Get(\"main\", \"id_prefix\", \"my-c\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t\t}\n\n\t\tif raw := result.Next(); raw != nil {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, nil)\n\t\t}\n\n\t\t// Attempt a row scan secondary index\n\t\tresult, err = txn.Get(\"main\", \"foo_prefix\", \"foo\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj2 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj2)\n\t\t}\n\n\t\tif raw := result.Next(); raw != nil {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, nil)\n\t\t}\n\n\t\t// Attempt a row scan secondary index, tigher prefix\n\t\tresult, err = txn.Get(\"main\", \"foo_prefix\", \"foob\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t\t}\n\n\t\tif raw := result.Next(); raw != nil {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, nil)\n\t\t}\n\n\t\t// Attempt a row scan multiindex\n\t\tresult, err = txn.Get(\"main\", \"qux_prefix\", \"foo\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t\t}\n\n\t\t// second index entry for obj1 (fooqux)\n\t\tif raw := result.Next(); raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj2 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj2)\n\t\t}\n\n\t\tif raw := result.Next(); raw != nil {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, nil)\n\t\t}\n\n\t\t// Attempt a row scan multiindex, tigher prefix\n\t\tresult, err = txn.Get(\"main\", \"qux_prefix\", \"foob\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\tif raw := result.Next(); raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, obj1)\n\t\t}\n\n\t\tif raw := result.Next(); raw != nil {\n\t\t\tt.Fatalf(\"bad: %#v %#v\", raw, nil)\n\t\t}\n\t}\n\n\t// Check the results within the txn\n\tcheckResult(txn)\n\n\t// Commit and start a new read transaction\n\ttxn.Commit()\n\ttxn = db.Txn(false)\n\n\t// Check the results in a new txn\n\tcheckResult(txn)\n}\n\n// CustomIndex is a simple custom indexer that doesn't add any suffixes to its\n// object keys; this is compatible with the LongestPrefixMatch algorithm.\ntype CustomIndex struct{}\n\n// FromObject takes the Foo field of a TestObject and prepends a null.\nfunc (*CustomIndex) FromObject(obj interface{}) (bool, []byte, error) {\n\tt, ok := obj.(*TestObject)\n\tif !ok {\n\t\treturn false, nil, fmt.Errorf(\"not a test object\")\n\t}\n\n\t// Prepend a null so we can address an empty Foo field.\n\tout := \"\\x00\" + t.Foo\n\treturn true, []byte(out), nil\n}\n\n// FromArgs always returns an error.\nfunc (*CustomIndex) FromArgs(args ...interface{}) ([]byte, error) {\n\treturn nil, fmt.Errorf(\"only prefix lookups are supported\")\n}\n\n// Prefix from args takes the argument as a string and prepends a null.\nfunc (*CustomIndex) PrefixFromArgs(args ...interface{}) ([]byte, error) {\n\tif len(args) != 1 {\n\t\treturn nil, fmt.Errorf(\"must provide only a single argument\")\n\t}\n\targ, ok := args[0].(string)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"argument must be a string: %#v\", args[0])\n\t}\n\targ = \"\\x00\" + arg\n\treturn []byte(arg), nil\n}\n\nfunc TestTxn_InsertGet_LongestPrefix(t *testing.T) {\n\tschema := &DBSchema{\n\t\tTables: map[string]*TableSchema{\n\t\t\t\"main\": &TableSchema{\n\t\t\t\tName: \"main\",\n\t\t\t\tIndexes: map[string]*IndexSchema{\n\t\t\t\t\t\"id\": &IndexSchema{\n\t\t\t\t\t\tName:   \"id\",\n\t\t\t\t\t\tUnique: true,\n\t\t\t\t\t\tIndexer: &StringFieldIndex{\n\t\t\t\t\t\t\tField: \"ID\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t\"foo\": &IndexSchema{\n\t\t\t\t\t\tName:    \"foo\",\n\t\t\t\t\t\tUnique:  true,\n\t\t\t\t\t\tIndexer: &CustomIndex{},\n\t\t\t\t\t},\n\t\t\t\t\t\"nope\": &IndexSchema{\n\t\t\t\t\t\tName:    \"nope\",\n\t\t\t\t\t\tIndexer: &CustomIndex{},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tdb, err := NewMemDB(schema)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\ttxn := db.Txn(true)\n\n\tobj1 := &TestObject{\n\t\tID:  \"object1\",\n\t\tFoo: \"foo\",\n\t}\n\tobj2 := &TestObject{\n\t\tID:  \"object2\",\n\t\tFoo: \"foozipzap\",\n\t}\n\tobj3 := &TestObject{\n\t\tID:  \"object3\",\n\t\tFoo: \"\",\n\t}\n\n\terr = txn.Insert(\"main\", obj1)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj2)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\terr = txn.Insert(\"main\", obj3)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\tcheckResult := func(txn *Txn) {\n\t\traw, err := txn.LongestPrefix(\"main\", \"foo_prefix\", \"foo\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\t\tif raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v\", raw)\n\t\t}\n\n\t\traw, err = txn.LongestPrefix(\"main\", \"foo_prefix\", \"foobar\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\t\tif raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v\", raw)\n\t\t}\n\n\t\traw, err = txn.LongestPrefix(\"main\", \"foo_prefix\", \"foozip\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\t\tif raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v\", raw)\n\t\t}\n\n\t\traw, err = txn.LongestPrefix(\"main\", \"foo_prefix\", \"foozipza\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\t\tif raw != obj1 {\n\t\t\tt.Fatalf(\"bad: %#v\", raw)\n\t\t}\n\n\t\traw, err = txn.LongestPrefix(\"main\", \"foo_prefix\", \"foozipzap\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\t\tif raw != obj2 {\n\t\t\tt.Fatalf(\"bad: %#v\", raw)\n\t\t}\n\n\t\traw, err = txn.LongestPrefix(\"main\", \"foo_prefix\", \"foozipzapzone\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\t\tif raw != obj2 {\n\t\t\tt.Fatalf(\"bad: %#v\", raw)\n\t\t}\n\n\t\traw, err = txn.LongestPrefix(\"main\", \"foo_prefix\", \"funky\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\t\tif raw != obj3 {\n\t\t\tt.Fatalf(\"bad: %#v\", raw)\n\t\t}\n\n\t\traw, err = txn.LongestPrefix(\"main\", \"foo_prefix\", \"\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\t\tif raw != obj3 {\n\t\t\tt.Fatalf(\"bad: %#v\", raw)\n\t\t}\n\t}\n\n\t// Check the results within the txn\n\tcheckResult(txn)\n\n\t// Commit and start a new read transaction\n\ttxn.Commit()\n\ttxn = db.Txn(false)\n\n\t// Check the results in a new txn\n\tcheckResult(txn)\n\n\t// Try some disallowed index types.\n\t_, err = txn.LongestPrefix(\"main\", \"foo\", \"\")\n\tif err == nil || !strings.Contains(err.Error(), \"must use 'foo_prefix' on index\") {\n\t\tt.Fatalf(\"bad: %v\", err)\n\t}\n\t_, err = txn.LongestPrefix(\"main\", \"nope_prefix\", \"\")\n\tif err == nil || !strings.Contains(err.Error(), \"index 'nope_prefix' is not unique\") {\n\t\tt.Fatalf(\"bad: %v\", err)\n\t}\n}\n\nfunc TestTxn_Defer(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(true)\n\tres := \"\"\n\n\t// Defer a few functions\n\ttxn.Defer(func() {\n\t\tres += \"c\"\n\t})\n\ttxn.Defer(func() {\n\t\tres += \"b\"\n\t})\n\ttxn.Defer(func() {\n\t\tres += \"a\"\n\t})\n\n\t// Commit the txn\n\ttxn.Commit()\n\n\t// Check the result. All functions should have run, and should\n\t// have been executed in LIFO order.\n\tif res != \"abc\" {\n\t\tt.Fatalf(\"bad: %q\", res)\n\t}\n}\n\nfunc TestTxn_Defer_Abort(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(true)\n\tres := \"\"\n\n\t// Defer a function\n\ttxn.Defer(func() {\n\t\tres += \"nope\"\n\t})\n\n\t// Commit the txn\n\ttxn.Abort()\n\n\t// Ensure deferred did not run\n\tif res != \"\" {\n\t\tt.Fatalf(\"bad: %q\", res)\n\t}\n}\n\nfunc TestTxn_LowerBound(t *testing.T) {\n\n\tbasicRows := []TestObject{\n\t\t{ID: \"00001\", Foo: \"1\", Qux: []string{\"a\"}},\n\t\t{ID: \"00002\", Foo: \"2\", Qux: []string{\"a\"}},\n\t\t{ID: \"00004\", Foo: \"3\", Qux: []string{\"a\"}},\n\t\t{ID: \"00005\", Foo: \"4\", Qux: []string{\"a\"}},\n\t\t{ID: \"00010\", Foo: \"5\", Qux: []string{\"a\"}},\n\t\t{ID: \"10010\", Foo: \"6\", Qux: []string{\"a\"}},\n\t}\n\n\tcases := []struct {\n\t\tName   string\n\t\tRows   []TestObject\n\t\tSearch string\n\t\tWant   []TestObject\n\t}{\n\t\t{\n\t\t\tName:   \"all\",\n\t\t\tRows:   basicRows,\n\t\t\tSearch: \"0\",\n\t\t\tWant:   basicRows,\n\t\t},\n\t\t{\n\t\t\tName:   \"subset existing bound\",\n\t\t\tRows:   basicRows,\n\t\t\tSearch: \"00005\",\n\t\t\tWant: []TestObject{\n\t\t\t\t{ID: \"00005\", Foo: \"4\", Qux: []string{\"a\"}},\n\t\t\t\t{ID: \"00010\", Foo: \"5\", Qux: []string{\"a\"}},\n\t\t\t\t{ID: \"10010\", Foo: \"6\", Qux: []string{\"a\"}},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName:   \"subset non-existent bound\",\n\t\t\tRows:   basicRows,\n\t\t\tSearch: \"00006\",\n\t\t\tWant: []TestObject{\n\t\t\t\t{ID: \"00010\", Foo: \"5\", Qux: []string{\"a\"}},\n\t\t\t\t{ID: \"10010\", Foo: \"6\", Qux: []string{\"a\"}},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName:   \"empty subset\",\n\t\t\tRows:   basicRows,\n\t\t\tSearch: \"99999\",\n\t\t\tWant:   []TestObject{},\n\t\t},\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.Name, func(t *testing.T) {\n\t\t\tdb := testDB(t)\n\n\t\t\ttxn := db.Txn(true)\n\t\t\tfor _, row := range tc.Rows {\n\n\t\t\t\terr := txn.Insert(\"main\", row)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"err inserting: %s\", err)\n\t\t\t\t}\n\t\t\t}\n\t\t\ttxn.Commit()\n\n\t\t\ttxn = db.Txn(false)\n\t\t\tdefer txn.Abort()\n\t\t\titerator, err := txn.LowerBound(\"main\", \"id\", tc.Search)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"err lower bound: %s\", err)\n\t\t\t}\n\n\t\t\t// Now range scan and built a result set\n\t\t\tresult := []TestObject{}\n\t\t\tfor obj := iterator.Next(); obj != nil; obj = iterator.Next() {\n\t\t\t\tresult = append(result, obj.(TestObject))\n\t\t\t}\n\n\t\t\tif !reflect.DeepEqual(result, tc.Want) {\n\t\t\t\tt.Fatalf(\" got: %#v\\nwant: %#v\", result, tc.Want)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestTxn_ReverseLowerBound(t *testing.T) {\n\n\tbasicRows := []TestObject{\n\t\t{ID: \"00101\", Foo: \"1\", Qux: []string{\"a\"}},\n\t\t{ID: \"00102\", Foo: \"2\", Qux: []string{\"a\"}},\n\t\t{ID: \"00104\", Foo: \"3\", Qux: []string{\"a\"}},\n\t\t{ID: \"00105\", Foo: \"4\", Qux: []string{\"a\"}},\n\t\t{ID: \"00110\", Foo: \"5\", Qux: []string{\"a\"}},\n\t\t{ID: \"10010\", Foo: \"6\", Qux: []string{\"a\"}},\n\t}\n\n\treverse := func(rows []TestObject) []TestObject {\n\t\tfor i := 0; i < len(rows)/2; i++ {\n\t\t\tj := len(rows) - i - 1\n\t\t\trows[i], rows[j] = rows[j], rows[i]\n\t\t}\n\t\treturn rows\n\t}\n\n\tcases := []struct {\n\t\tName   string\n\t\tRows   []TestObject\n\t\tSearch string\n\t\tWant   []TestObject\n\t}{\n\t\t{\n\t\t\tName:   \"all\",\n\t\t\tRows:   basicRows,\n\t\t\tSearch: \"99999\",\n\t\t\tWant:   reverse(basicRows),\n\t\t},\n\t\t{\n\t\t\tName:   \"subset existing bound\",\n\t\t\tRows:   basicRows,\n\t\t\tSearch: \"00105\",\n\t\t\tWant: []TestObject{\n\t\t\t\t{ID: \"00105\", Foo: \"4\", Qux: []string{\"a\"}},\n\t\t\t\t{ID: \"00104\", Foo: \"3\", Qux: []string{\"a\"}},\n\t\t\t\t{ID: \"00102\", Foo: \"2\", Qux: []string{\"a\"}},\n\t\t\t\t{ID: \"00101\", Foo: \"1\", Qux: []string{\"a\"}},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName:   \"subset non-existent bound\",\n\t\t\tRows:   basicRows,\n\t\t\tSearch: \"00103\",\n\t\t\tWant: []TestObject{\n\t\t\t\t{ID: \"00102\", Foo: \"2\", Qux: []string{\"a\"}},\n\t\t\t\t{ID: \"00101\", Foo: \"1\", Qux: []string{\"a\"}},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName:   \"empty subset\",\n\t\t\tRows:   basicRows,\n\t\t\tSearch: \"0\",\n\t\t\tWant:   []TestObject{},\n\t\t},\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.Name, func(t *testing.T) {\n\t\t\tdb := testDB(t)\n\n\t\t\ttxn := db.Txn(true)\n\t\t\tfor _, row := range tc.Rows {\n\n\t\t\t\terr := txn.Insert(\"main\", row)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"err inserting: %s\", err)\n\t\t\t\t}\n\t\t\t}\n\t\t\ttxn.Commit()\n\n\t\t\ttxn = db.Txn(false)\n\t\t\tdefer txn.Abort()\n\t\t\titerator, err := txn.ReverseLowerBound(\"main\", \"id\", tc.Search)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"err lower bound: %s\", err)\n\t\t\t}\n\n\t\t\t// Now range scan and built a result set\n\t\t\tresult := []TestObject{}\n\t\t\tfor obj := iterator.Next(); obj != nil; obj = iterator.Next() {\n\t\t\t\tresult = append(result, obj.(TestObject))\n\t\t\t}\n\n\t\t\tif !reflect.DeepEqual(result, tc.Want) {\n\t\t\t\tt.Fatalf(\" got: %#v\\nwant: %#v\", result, tc.Want)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestTxn_Snapshot(t *testing.T) {\n\tdb := testDB(t)\n\ttxn := db.Txn(true)\n\n\terr := txn.Insert(\"main\", &TestObject{\n\t\tID:  \"one\",\n\t\tFoo: \"abc\",\n\t\tQux: []string{\"abc1\", \"abc2\"},\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\tsnapshot := txn.Snapshot()\n\n\terr = txn.Insert(\"main\", &TestObject{\n\t\tID:  \"two\",\n\t\tFoo: \"def\",\n\t\tQux: []string{\"def1\", \"def2\"},\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\ttxn.Commit()\n\n\traw, err := snapshot.First(\"main\", \"id\", \"one\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw == nil || raw.(*TestObject).ID != \"one\" {\n\t\tt.Fatalf(\"TestObject one not found\")\n\t}\n\n\traw, err = snapshot.First(\"main\", \"id\", \"two\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw != nil {\n\t\tt.Fatalf(\"TestObject two found\")\n\t}\n\n\ttxn = db.Txn(false)\n\tsnapshot = txn.Snapshot()\n\n\traw, err = snapshot.First(\"main\", \"id\", \"one\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw == nil || raw.(*TestObject).ID != \"one\" {\n\t\tt.Fatalf(\"TestObject one not found\")\n\t}\n\n\traw, err = snapshot.First(\"main\", \"id\", \"two\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif raw == nil || raw.(*TestObject).ID != \"two\" {\n\t\tt.Fatalf(\"TestObject two not found\")\n\t}\n}\n\nfunc TestStringFieldIndexerEmptyPointerFromArgs(t *testing.T) {\n\tt.Run(\"does not error with AllowMissing\", func(t *testing.T) {\n\t\tschema := &DBSchema{\n\t\t\tTables: map[string]*TableSchema{\n\t\t\t\t\"main\": &TableSchema{\n\t\t\t\t\tName: \"main\",\n\t\t\t\t\tIndexes: map[string]*IndexSchema{\n\t\t\t\t\t\t\"id\": &IndexSchema{\n\t\t\t\t\t\t\tName:   \"id\",\n\t\t\t\t\t\t\tUnique: true,\n\t\t\t\t\t\t\tIndexer: &StringFieldIndex{\n\t\t\t\t\t\t\t\tField: \"ID\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"fu\": &IndexSchema{\n\t\t\t\t\t\t\tName: \"fu\",\n\t\t\t\t\t\t\tIndexer: &StringFieldIndex{\n\t\t\t\t\t\t\t\tField: \"Fu\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tAllowMissing: true,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\tdb, err := NewMemDB(schema)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\ttxn := db.Txn(true)\n\n\t\ts1 := \"foo1\"\n\t\tobj1 := &TestObject{\n\t\t\tID: \"object1\",\n\t\t\tFu: &s1,\n\t\t}\n\n\t\tobj2 := &TestObject{\n\t\t\tID: \"object2\",\n\t\t\tFu: nil,\n\t\t}\n\n\t\terr = txn.Insert(\"main\", obj1)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\terr = txn.Insert(\"main\", obj2)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"errors without AllowMissing\", func(t *testing.T) {\n\t\tschema := &DBSchema{\n\t\t\tTables: map[string]*TableSchema{\n\t\t\t\t\"main\": &TableSchema{\n\t\t\t\t\tName: \"main\",\n\t\t\t\t\tIndexes: map[string]*IndexSchema{\n\t\t\t\t\t\t\"id\": &IndexSchema{\n\t\t\t\t\t\t\tName:   \"id\",\n\t\t\t\t\t\t\tUnique: true,\n\t\t\t\t\t\t\tIndexer: &StringFieldIndex{\n\t\t\t\t\t\t\t\tField: \"ID\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"fu\": &IndexSchema{\n\t\t\t\t\t\t\tName: \"fu\",\n\t\t\t\t\t\t\tIndexer: &StringFieldIndex{\n\t\t\t\t\t\t\t\tField: \"Fu\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tAllowMissing: false,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\tdb, err := NewMemDB(schema)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\ttxn := db.Txn(true)\n\n\t\ts1 := \"foo1\"\n\t\tobj1 := &TestObject{\n\t\t\tID: \"object1\",\n\t\t\tFu: &s1,\n\t\t}\n\n\t\tobj2 := &TestObject{\n\t\t\tID: \"object2\",\n\t\t\tFu: nil,\n\t\t}\n\n\t\terr = txn.Insert(\"main\", obj1)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %v\", err)\n\t\t}\n\n\t\terr = txn.Insert(\"main\", obj2)\n\t\tif err == nil {\n\t\t\tt.Fatalf(\"expected err not to be nil\")\n\t\t}\n\t})\n}\n\nfunc TestTxn_Changes(t *testing.T) {\n\n\t// Create a schmea that exercises all mutation code paths (i.e. has a prefix\n\t// index as well as primary and multple tables).\n\tschema := &DBSchema{\n\t\tTables: map[string]*TableSchema{\n\t\t\t\"one\": &TableSchema{\n\t\t\t\tName: \"one\",\n\t\t\t\tIndexes: map[string]*IndexSchema{\n\t\t\t\t\t\"id\": &IndexSchema{\n\t\t\t\t\t\tName:   \"id\",\n\t\t\t\t\t\tUnique: true,\n\t\t\t\t\t\tIndexer: &StringFieldIndex{\n\t\t\t\t\t\t\tField: \"ID\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t\"foo\": &IndexSchema{\n\t\t\t\t\t\tName: \"foo\",\n\t\t\t\t\t\tIndexer: &StringFieldIndex{\n\t\t\t\t\t\t\tField: \"Foo\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\tAllowMissing: true,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"two\": &TableSchema{\n\t\t\t\tName: \"two\",\n\t\t\t\tIndexes: map[string]*IndexSchema{\n\t\t\t\t\t\"id\": &IndexSchema{\n\t\t\t\t\t\tName:   \"id\",\n\t\t\t\t\t\tUnique: true,\n\t\t\t\t\t\tIndexer: &StringFieldIndex{\n\t\t\t\t\t\t\tField: \"ID\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tbasicRows := []TestObject{\n\t\t{ID: \"00001\", Foo: \"aaaaaaa\"},\n\t\t{ID: \"00002\", Foo: \"aaaaaab\"},\n\t\t{ID: \"00004\", Foo: \"aaabbbb\"},\n\t\t{ID: \"00005\", Foo: \"aabbbcc\"},\n\t\t{ID: \"00010\", Foo: \"bbccccc\"},\n\t\t{ID: \"10010\", Foo: \"ccccddd\"},\n\t}\n\n\tmutatedRows := []TestObject{\n\t\t{ID: \"00001\", Foo: \"changed\"},\n\t\t{ID: \"00002\", Foo: \"changed\"},\n\t\t{ID: \"00004\", Foo: \"changed\"},\n\t\t{ID: \"00005\", Foo: \"changed\"},\n\t\t{ID: \"00010\", Foo: \"changed\"},\n\t\t{ID: \"10010\", Foo: \"changed\"},\n\t}\n\n\tmutated2Rows := []TestObject{\n\t\t{ID: \"00001\", Foo: \"changed again\"},\n\t}\n\n\tcases := []struct {\n\t\tName            string\n\t\tTrackingEnabled bool\n\t\tOneRows         []TestObject\n\t\tTwoRows         []TestObject\n\t\tMutate          func(t *testing.T, tx *Txn)\n\t\tAbort           bool\n\t\tWantChanges     Changes\n\t}{\n\t\t{\n\t\t\tName:            \"tracking disabled\",\n\t\t\tTrackingEnabled: false,\n\t\t\tOneRows:         nil,\n\t\t\tTwoRows:         nil,\n\t\t\tMutate: func(t *testing.T, tx *Txn) {\n\t\t\t\terr := tx.Insert(\"one\", basicRows[0])\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t\terr = tx.Insert(\"one\", basicRows[1])\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t\terr = tx.Insert(\"two\", basicRows[2])\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t},\n\t\t\tWantChanges: nil,\n\t\t},\n\t\t{\n\t\t\tName:            \"tracking enabled, basic inserts\",\n\t\t\tTrackingEnabled: true,\n\t\t\tOneRows:         nil,\n\t\t\tTwoRows:         nil,\n\t\t\tMutate: func(t *testing.T, tx *Txn) {\n\t\t\t\terr := tx.Insert(\"one\", basicRows[0])\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t\terr = tx.Insert(\"one\", basicRows[1])\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t\terr = tx.Insert(\"two\", basicRows[2])\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t},\n\t\t\tWantChanges: Changes{\n\t\t\t\tChange{\n\t\t\t\t\tTable:  \"one\",\n\t\t\t\t\tBefore: nil,\n\t\t\t\t\tAfter:  basicRows[0],\n\t\t\t\t},\n\t\t\t\tChange{\n\t\t\t\t\tTable:  \"one\",\n\t\t\t\t\tBefore: nil,\n\t\t\t\t\tAfter:  basicRows[1],\n\t\t\t\t},\n\t\t\t\tChange{\n\t\t\t\t\tTable:  \"two\",\n\t\t\t\t\tBefore: nil,\n\t\t\t\t\tAfter:  basicRows[2],\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName:            \"tracking enabled, tx aborts\",\n\t\t\tTrackingEnabled: true,\n\t\t\tOneRows:         nil,\n\t\t\tTwoRows:         nil,\n\t\t\tMutate: func(t *testing.T, tx *Txn) {\n\t\t\t\terr := tx.Insert(\"one\", basicRows[0])\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t\terr = tx.Insert(\"one\", basicRows[1])\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t\terr = tx.Insert(\"two\", basicRows[2])\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t},\n\t\t\tAbort:       true,\n\t\t\tWantChanges: nil,\n\t\t},\n\t\t{\n\t\t\tName:            \"mixed insert, update, delete\",\n\t\t\tTrackingEnabled: true,\n\t\t\tOneRows:         []TestObject{basicRows[0]},\n\t\t\tTwoRows:         []TestObject{basicRows[2]},\n\t\t\tMutate: func(t *testing.T, tx *Txn) {\n\t\t\t\t// Insert a new row\n\t\t\t\terr := tx.Insert(\"one\", basicRows[1])\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t\t// Update an existing row\n\t\t\t\terr = tx.Insert(\"one\", mutatedRows[0])\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t\t// Delete an existing row\n\t\t\t\terr = tx.Delete(\"two\", basicRows[2])\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t},\n\t\t\tWantChanges: Changes{\n\t\t\t\tChange{\n\t\t\t\t\tTable:  \"one\",\n\t\t\t\t\tBefore: nil,\n\t\t\t\t\tAfter:  basicRows[1],\n\t\t\t\t},\n\t\t\t\tChange{\n\t\t\t\t\tTable:  \"one\",\n\t\t\t\t\tBefore: basicRows[0],\n\t\t\t\t\tAfter:  mutatedRows[0],\n\t\t\t\t},\n\t\t\t\tChange{\n\t\t\t\t\tTable:  \"two\",\n\t\t\t\t\tBefore: basicRows[2],\n\t\t\t\t\tAfter:  nil,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName:            \"mutate rows in same txn\",\n\t\t\tTrackingEnabled: true,\n\t\t\tOneRows:         []TestObject{},\n\t\t\tTwoRows:         []TestObject{},\n\t\t\tMutate: func(t *testing.T, tx *Txn) {\n\t\t\t\t// Insert a new row\n\t\t\t\terr := tx.Insert(\"one\", basicRows[0])\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t\t// Mutate same row again\n\t\t\t\terr = tx.Insert(\"one\", mutatedRows[0])\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t\t// Mutate same row again\n\t\t\t\terr = tx.Insert(\"one\", mutated2Rows[0])\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t},\n\t\t\tWantChanges: Changes{\n\t\t\t\t// Changes should only include a single object mutation going from\n\t\t\t\t// nothing before to the final value.\n\t\t\t\tChange{\n\t\t\t\t\tTable:  \"one\",\n\t\t\t\t\tBefore: nil,\n\t\t\t\t\tAfter:  mutated2Rows[0],\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName:            \"mutate and delete in same txn\",\n\t\t\tTrackingEnabled: true,\n\t\t\tOneRows:         []TestObject{basicRows[0]},\n\t\t\tTwoRows:         []TestObject{},\n\t\t\tMutate: func(t *testing.T, tx *Txn) {\n\t\t\t\t// Update a new row\n\t\t\t\terr := tx.Insert(\"one\", mutatedRows[0])\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t\t// Mutate same row again\n\t\t\t\terr = tx.Delete(\"one\", mutatedRows[0])\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t},\n\t\t\tWantChanges: Changes{\n\t\t\t\t// Changes should only include a single delete\n\t\t\t\tChange{\n\t\t\t\t\tTable:  \"one\",\n\t\t\t\t\tBefore: basicRows[0],\n\t\t\t\t\tAfter:  nil,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName:            \"delete prefix\",\n\t\t\tTrackingEnabled: true,\n\t\t\tOneRows:         basicRows,\n\t\t\tTwoRows:         []TestObject{},\n\t\t\tMutate: func(t *testing.T, tx *Txn) {\n\t\t\t\t// Delete Prefix\n\t\t\t\t_, err := tx.DeletePrefix(\"one\", \"foo_prefix\", \"aaa\")\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t},\n\t\t\tWantChanges: Changes{\n\t\t\t\t// First three rows should be removed\n\t\t\t\tChange{\n\t\t\t\t\tTable:  \"one\",\n\t\t\t\t\tBefore: basicRows[0],\n\t\t\t\t\tAfter:  nil,\n\t\t\t\t},\n\t\t\t\tChange{\n\t\t\t\t\tTable:  \"one\",\n\t\t\t\t\tBefore: basicRows[1],\n\t\t\t\t\tAfter:  nil,\n\t\t\t\t},\n\t\t\t\tChange{\n\t\t\t\t\tTable:  \"one\",\n\t\t\t\t\tBefore: basicRows[2],\n\t\t\t\t\tAfter:  nil,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName:            \"delete all\",\n\t\t\tTrackingEnabled: true,\n\t\t\tOneRows:         mutatedRows,\n\t\t\tTwoRows:         mutatedRows,\n\t\t\tMutate: func(t *testing.T, tx *Txn) {\n\t\t\t\t// Delete All rows\n\t\t\t\t_, err := tx.DeleteAll(\"one\", \"foo\", \"changed\")\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t},\n\t\t\tWantChanges: Changes{\n\t\t\t\t// All rows should be removed\n\t\t\t\tChange{\n\t\t\t\t\tTable:  \"one\",\n\t\t\t\t\tBefore: mutatedRows[0],\n\t\t\t\t\tAfter:  nil,\n\t\t\t\t},\n\t\t\t\tChange{\n\t\t\t\t\tTable:  \"one\",\n\t\t\t\t\tBefore: mutatedRows[1],\n\t\t\t\t\tAfter:  nil,\n\t\t\t\t},\n\t\t\t\tChange{\n\t\t\t\t\tTable:  \"one\",\n\t\t\t\t\tBefore: mutatedRows[2],\n\t\t\t\t\tAfter:  nil,\n\t\t\t\t},\n\t\t\t\tChange{\n\t\t\t\t\tTable:  \"one\",\n\t\t\t\t\tBefore: mutatedRows[3],\n\t\t\t\t\tAfter:  nil,\n\t\t\t\t},\n\t\t\t\tChange{\n\t\t\t\t\tTable:  \"one\",\n\t\t\t\t\tBefore: mutatedRows[4],\n\t\t\t\t\tAfter:  nil,\n\t\t\t\t},\n\t\t\t\tChange{\n\t\t\t\t\tTable:  \"one\",\n\t\t\t\t\tBefore: mutatedRows[5],\n\t\t\t\t\tAfter:  nil,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName:            \"delete all partial\",\n\t\t\tTrackingEnabled: true,\n\t\t\tOneRows: []TestObject{\n\t\t\t\t// Half the rows have unique Foo values half have \"changed\"\n\t\t\t\tbasicRows[0], basicRows[1],\n\t\t\t\tmutatedRows[2], mutatedRows[3],\n\t\t\t},\n\t\t\tTwoRows: mutatedRows,\n\t\t\tMutate: func(t *testing.T, tx *Txn) {\n\t\t\t\t// Delete All rows\n\t\t\t\t_, err := tx.DeleteAll(\"one\", \"foo\", \"changed\")\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t},\n\t\t\tWantChanges: Changes{\n\t\t\t\t// Only the matching rows should be removed\n\t\t\t\tChange{\n\t\t\t\t\tTable:  \"one\",\n\t\t\t\t\tBefore: mutatedRows[2],\n\t\t\t\t\tAfter:  nil,\n\t\t\t\t},\n\t\t\t\tChange{\n\t\t\t\t\tTable:  \"one\",\n\t\t\t\t\tBefore: mutatedRows[3],\n\t\t\t\t\tAfter:  nil,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName:            \"insert and then delete same item in one txn\",\n\t\t\tTrackingEnabled: true,\n\t\t\tMutate: func(t *testing.T, tx *Txn) {\n\t\t\t\t// Insert a new row\n\t\t\t\terr := tx.Insert(\"one\", basicRows[0])\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t\t// Delete the same row again\n\t\t\t\terr = tx.Delete(\"one\", basicRows[0])\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Err: %s\", err)\n\t\t\t\t}\n\t\t\t},\n\t\t\tWantChanges: Changes{\n\t\t\t\t// Whole transaction is a big no-op. Initial implementation missed this\n\t\t\t\t// edge case and emitted a mutation where both before and after were nil\n\t\t\t\t// which violates expectations in caller.\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, tc := range cases {\n\t\ttc := tc\n\t\tt.Run(tc.Name, func(t *testing.T) {\n\t\t\tdb, err := NewMemDB(schema)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Failed to create DB: %s\", err)\n\t\t\t}\n\n\t\t\t// Insert initial rows\n\t\t\ttx := db.Txn(true)\n\t\t\tfor i, r := range tc.OneRows {\n\t\t\t\terr = tx.Insert(\"one\", r)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Failed to insert OneRows[%d]: %s\", i, err)\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor i, r := range tc.TwoRows {\n\t\t\t\terr = tx.Insert(\"two\", r)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Failed to insert TwoRows[%d]: %s\", i, err)\n\t\t\t\t}\n\t\t\t}\n\t\t\ttx.Commit()\n\n\t\t\t// Do test mutation\n\t\t\ttx2 := db.Txn(true)\n\n\t\t\tif tc.TrackingEnabled {\n\t\t\t\ttx2.TrackChanges()\n\t\t\t}\n\n\t\t\ttc.Mutate(t, tx2)\n\n\t\t\tif tc.Abort {\n\t\t\t\ttx2.Abort()\n\t\t\t\tgotAfterCommit := tx2.Changes()\n\t\t\t\tif !reflect.DeepEqual(gotAfterCommit, tc.WantChanges) {\n\t\t\t\t\tt.Fatalf(\"\\n gotAfterCommit: %#v\\n           want: %#v\",\n\t\t\t\t\t\tgotAfterCommit, tc.WantChanges)\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tgotBeforeCommit := tx2.Changes()\n\t\t\ttx2.Commit()\n\t\t\tgotAfterCommit := tx2.Changes()\n\n\t\t\t// nil out the keys in Wanted since those are an implementation detail\n\t\t\tfor i := range gotBeforeCommit {\n\t\t\t\tgotBeforeCommit[i].primaryKey = nil\n\t\t\t}\n\t\t\tfor i := range gotAfterCommit {\n\t\t\t\tgotAfterCommit[i].primaryKey = nil\n\t\t\t}\n\n\t\t\tif !reflect.DeepEqual(gotBeforeCommit, tc.WantChanges) {\n\t\t\t\tt.Fatalf(\"\\n gotBeforeCommit: %#v\\n            want: %#v\",\n\t\t\t\t\tgotBeforeCommit, tc.WantChanges)\n\t\t\t}\n\t\t\tif !reflect.DeepEqual(gotAfterCommit, tc.WantChanges) {\n\t\t\t\tt.Fatalf(\"\\n gotAfterCommit: %#v\\n           want: %#v\",\n\t\t\t\t\tgotAfterCommit, tc.WantChanges)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestTxn_GetIterAndDelete(t *testing.T) {\n\tschema := &DBSchema{\n\t\tTables: map[string]*TableSchema{\n\t\t\t\"main\": {\n\t\t\t\tName: \"main\",\n\t\t\t\tIndexes: map[string]*IndexSchema{\n\t\t\t\t\t\"id\": {\n\t\t\t\t\t\tName:    \"id\",\n\t\t\t\t\t\tUnique:  true,\n\t\t\t\t\t\tIndexer: &StringFieldIndex{Field: \"ID\"},\n\t\t\t\t\t},\n\t\t\t\t\t\"foo\": {\n\t\t\t\t\t\tName:    \"foo\",\n\t\t\t\t\t\tIndexer: &StringFieldIndex{Field: \"Foo\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\tdb, err := NewMemDB(schema)\n\tassertNilError(t, err)\n\n\tkey := \"aaaa\"\n\ttxn := db.Txn(true)\n\tassertNilError(t, txn.Insert(\"main\", &TestObject{ID: \"1\", Foo: key}))\n\tassertNilError(t, txn.Insert(\"main\", &TestObject{ID: \"123\", Foo: key}))\n\tassertNilError(t, txn.Insert(\"main\", &TestObject{ID: \"2\", Foo: key}))\n\ttxn.Commit()\n\n\ttxn = db.Txn(true)\n\t// Delete something\n\tassertNilError(t, txn.Delete(\"main\", &TestObject{ID: \"123\", Foo: key}))\n\n\titer, err := txn.Get(\"main\", \"foo\", key)\n\tassertNilError(t, err)\n\n\tfor obj := iter.Next(); obj != nil; obj = iter.Next() {\n\t\tassertNilError(t, txn.Delete(\"main\", obj))\n\t}\n\n\ttxn.Commit()\n}\n\nfunc assertNilError(t *testing.T, err error) {\n\tt.Helper()\n\tif err != nil {\n\t\tt.Fatalf(\"expected nil error, got %v\", err)\n\t}\n}\n"
        },
        {
          "name": "watch-gen",
          "type": "tree",
          "content": null
        },
        {
          "name": "watch.go",
          "type": "blob",
          "size": 3.9873046875,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage memdb\n\nimport (\n\t\"context\"\n\t\"time\"\n)\n\n// WatchSet is a collection of watch channels. The zero value is not usable.\n// Use NewWatchSet to create a WatchSet.\ntype WatchSet map[<-chan struct{}]struct{}\n\n// NewWatchSet constructs a new watch set.\nfunc NewWatchSet() WatchSet {\n\treturn make(map[<-chan struct{}]struct{})\n}\n\n// Add appends a watchCh to the WatchSet if non-nil.\nfunc (w WatchSet) Add(watchCh <-chan struct{}) {\n\tif w == nil {\n\t\treturn\n\t}\n\n\tif _, ok := w[watchCh]; !ok {\n\t\tw[watchCh] = struct{}{}\n\t}\n}\n\n// AddWithLimit appends a watchCh to the WatchSet if non-nil, and if the given\n// softLimit hasn't been exceeded. Otherwise, it will watch the given alternate\n// channel. It's expected that the altCh will be the same on many calls to this\n// function, so you will exceed the soft limit a little bit if you hit this, but\n// not by much.\n//\n// This is useful if you want to track individual items up to some limit, after\n// which you watch a higher-level channel (usually a channel from start of\n// an iterator higher up in the radix tree) that will watch a superset of items.\nfunc (w WatchSet) AddWithLimit(softLimit int, watchCh <-chan struct{}, altCh <-chan struct{}) {\n\t// This is safe for a nil WatchSet so we don't need to check that here.\n\tif len(w) < softLimit {\n\t\tw.Add(watchCh)\n\t} else {\n\t\tw.Add(altCh)\n\t}\n}\n\n// Watch blocks until one of the channels in the watch set is closed, or\n// timeoutCh sends a value.\n// Returns true if timeoutCh is what caused Watch to unblock.\nfunc (w WatchSet) Watch(timeoutCh <-chan time.Time) bool {\n\tif w == nil {\n\t\treturn false\n\t}\n\n\t// Create a context that gets cancelled when the timeout is triggered\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\n\tgo func() {\n\t\tselect {\n\t\tcase <-timeoutCh:\n\t\t\tcancel()\n\t\tcase <-ctx.Done():\n\t\t}\n\t}()\n\n\treturn w.WatchCtx(ctx) == context.Canceled\n}\n\n// WatchCtx blocks until one of the channels in the watch set is closed, or\n// ctx is done (cancelled or exceeds the deadline). WatchCtx returns an error\n// if the ctx causes it to unblock, otherwise returns nil.\n//\n// WatchCtx should be preferred over Watch.\nfunc (w WatchSet) WatchCtx(ctx context.Context) error {\n\tif w == nil {\n\t\treturn nil\n\t}\n\n\tif n := len(w); n <= aFew {\n\t\tidx := 0\n\t\tchunk := make([]<-chan struct{}, aFew)\n\t\tfor watchCh := range w {\n\t\t\tchunk[idx] = watchCh\n\t\t\tidx++\n\t\t}\n\t\treturn watchFew(ctx, chunk)\n\t}\n\n\treturn w.watchMany(ctx)\n}\n\n// watchMany is used if there are many watchers.\nfunc (w WatchSet) watchMany(ctx context.Context) error {\n\t// Cancel all watcher goroutines when return.\n\twatcherCtx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\t// Set up a goroutine for each watcher.\n\ttriggerCh := make(chan struct{}, 1)\n\twatcher := func(chunk []<-chan struct{}) {\n\t\tif err := watchFew(watcherCtx, chunk); err == nil {\n\t\t\tselect {\n\t\t\tcase triggerCh <- struct{}{}:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t}\n\n\t// Apportion the watch channels into chunks we can feed into the\n\t// watchFew helper.\n\tidx := 0\n\tchunk := make([]<-chan struct{}, aFew)\n\tfor watchCh := range w {\n\t\tsubIdx := idx % aFew\n\t\tchunk[subIdx] = watchCh\n\t\tidx++\n\n\t\t// Fire off this chunk and start a fresh one.\n\t\tif idx%aFew == 0 {\n\t\t\tgo watcher(chunk)\n\t\t\tchunk = make([]<-chan struct{}, aFew)\n\t\t}\n\t}\n\n\t// Make sure to watch any residual channels in the last chunk.\n\tif idx%aFew != 0 {\n\t\tgo watcher(chunk)\n\t}\n\n\t// Wait for a channel to trigger or timeout.\n\tselect {\n\tcase <-triggerCh:\n\t\treturn nil\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\t}\n}\n\n// WatchCh returns a channel that is used to wait for any channel of the watch set to trigger\n// or for the context to be cancelled. WatchCh creates a new goroutine each call, so\n// callers may need to cache the returned channel to avoid creating extra goroutines.\nfunc (w WatchSet) WatchCh(ctx context.Context) <-chan error {\n\t// Create the outgoing channel\n\ttriggerCh := make(chan error, 1)\n\n\t// Create a goroutine to collect the error from WatchCtx\n\tgo func() {\n\t\ttriggerCh <- w.WatchCtx(ctx)\n\t}()\n\n\treturn triggerCh\n}\n"
        },
        {
          "name": "watch_few.go",
          "type": "blob",
          "size": 1.4609375,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage memdb\n\n//go:generate sh -c \"go run watch-gen/main.go >watch_few.go\"\n\nimport (\n\t\"context\"\n)\n\n// aFew gives how many watchers this function is wired to support. You must\n// always pass a full slice of this length, but unused channels can be nil.\nconst aFew = 32\n\n// watchFew is used if there are only a few watchers as a performance\n// optimization.\nfunc watchFew(ctx context.Context, ch []<-chan struct{}) error {\n\tselect {\n\n\tcase <-ch[0]:\n\t\treturn nil\n\n\tcase <-ch[1]:\n\t\treturn nil\n\n\tcase <-ch[2]:\n\t\treturn nil\n\n\tcase <-ch[3]:\n\t\treturn nil\n\n\tcase <-ch[4]:\n\t\treturn nil\n\n\tcase <-ch[5]:\n\t\treturn nil\n\n\tcase <-ch[6]:\n\t\treturn nil\n\n\tcase <-ch[7]:\n\t\treturn nil\n\n\tcase <-ch[8]:\n\t\treturn nil\n\n\tcase <-ch[9]:\n\t\treturn nil\n\n\tcase <-ch[10]:\n\t\treturn nil\n\n\tcase <-ch[11]:\n\t\treturn nil\n\n\tcase <-ch[12]:\n\t\treturn nil\n\n\tcase <-ch[13]:\n\t\treturn nil\n\n\tcase <-ch[14]:\n\t\treturn nil\n\n\tcase <-ch[15]:\n\t\treturn nil\n\n\tcase <-ch[16]:\n\t\treturn nil\n\n\tcase <-ch[17]:\n\t\treturn nil\n\n\tcase <-ch[18]:\n\t\treturn nil\n\n\tcase <-ch[19]:\n\t\treturn nil\n\n\tcase <-ch[20]:\n\t\treturn nil\n\n\tcase <-ch[21]:\n\t\treturn nil\n\n\tcase <-ch[22]:\n\t\treturn nil\n\n\tcase <-ch[23]:\n\t\treturn nil\n\n\tcase <-ch[24]:\n\t\treturn nil\n\n\tcase <-ch[25]:\n\t\treturn nil\n\n\tcase <-ch[26]:\n\t\treturn nil\n\n\tcase <-ch[27]:\n\t\treturn nil\n\n\tcase <-ch[28]:\n\t\treturn nil\n\n\tcase <-ch[29]:\n\t\treturn nil\n\n\tcase <-ch[30]:\n\t\treturn nil\n\n\tcase <-ch[31]:\n\t\treturn nil\n\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\t}\n}\n"
        },
        {
          "name": "watch_test.go",
          "type": "blob",
          "size": 6.7822265625,
          "content": "// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage memdb\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"fmt\"\n\t\"runtime/pprof\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n)\n\n// testWatch makes a bunch of watch channels based on the given size and fires\n// the one at the given fire index to make sure it's detected (or a timeout\n// occurs if the fire index isn't hit). useCtx parameterizes whether the context\n// based watch is used or timer based.\nfunc testWatch(size, fire int, useCtx bool) error {\n\tshouldTimeout := true\n\tws := NewWatchSet()\n\tfor i := 0; i < size; i++ {\n\t\twatchCh := make(chan struct{})\n\t\tws.Add(watchCh)\n\t\tif fire == i {\n\t\t\tclose(watchCh)\n\t\t\tshouldTimeout = false\n\t\t}\n\t}\n\n\tvar timeoutCh chan time.Time\n\tvar ctx context.Context\n\tvar cancelFn context.CancelFunc\n\tif useCtx {\n\t\tctx, cancelFn = context.WithCancel(context.Background())\n\t\tdefer cancelFn()\n\t} else {\n\t\ttimeoutCh = make(chan time.Time)\n\t}\n\n\tdoneCh := make(chan bool, 1)\n\tgo func() {\n\t\tif useCtx {\n\t\t\tdoneCh <- ws.WatchCtx(ctx) != nil\n\t\t} else {\n\t\t\tdoneCh <- ws.Watch(timeoutCh)\n\t\t}\n\t}()\n\n\tif shouldTimeout {\n\t\tselect {\n\t\tcase <-doneCh:\n\t\t\treturn fmt.Errorf(\"should not trigger\")\n\t\tdefault:\n\t\t}\n\n\t\tif useCtx {\n\t\t\tcancelFn()\n\t\t} else {\n\t\t\tclose(timeoutCh)\n\t\t}\n\t\tselect {\n\t\tcase didTimeout := <-doneCh:\n\t\t\tif !didTimeout {\n\t\t\t\treturn fmt.Errorf(\"should have timed out\")\n\t\t\t}\n\t\tcase <-time.After(10 * time.Second):\n\t\t\treturn fmt.Errorf(\"should have timed out\")\n\t\t}\n\t} else {\n\t\tselect {\n\t\tcase didTimeout := <-doneCh:\n\t\t\tif didTimeout {\n\t\t\t\treturn fmt.Errorf(\"should not have timed out\")\n\t\t\t}\n\t\tcase <-time.After(10 * time.Second):\n\t\t\treturn fmt.Errorf(\"should have triggered\")\n\t\t}\n\t\tif useCtx {\n\t\t\tcancelFn()\n\t\t} else {\n\t\t\tclose(timeoutCh)\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc TestWatch(t *testing.T) {\n\ttestFactory := func(useCtx bool) func(t *testing.T) {\n\t\treturn func(t *testing.T) {\n\t\t\t// Sweep through a bunch of chunks to hit the various cases of dividing\n\t\t\t// the work into watchFew calls.\n\t\t\tfor size := 0; size < 3*aFew; size++ {\n\t\t\t\t// Fire each possible channel slot.\n\t\t\t\tfor fire := 0; fire < size; fire++ {\n\t\t\t\t\tif err := testWatch(size, fire, useCtx); err != nil {\n\t\t\t\t\t\tt.Fatalf(\"err %d %d: %v\", size, fire, err)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Run a timeout case as well.\n\t\t\t\tfire := -1\n\t\t\t\tif err := testWatch(size, fire, useCtx); err != nil {\n\t\t\t\t\tt.Fatalf(\"err %d %d: %v\", size, fire, err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tt.Run(\"Timer\", testFactory(false))\n\tt.Run(\"Context\", testFactory(true))\n}\n\nfunc testWatchCh(size, fire int) error {\n\tshouldTimeout := true\n\tws := NewWatchSet()\n\tfor i := 0; i < size; i++ {\n\t\twatchCh := make(chan struct{})\n\t\tws.Add(watchCh)\n\t\tif fire == i {\n\t\t\tclose(watchCh)\n\t\t\tshouldTimeout = false\n\t\t}\n\t}\n\n\tctx, cancelFn := context.WithCancel(context.Background())\n\tdefer cancelFn()\n\n\tdoneCh := make(chan bool, 1)\n\tgo func() {\n\t\terr := <-ws.WatchCh(ctx)\n\t\tdoneCh <- err != nil\n\t}()\n\n\tif shouldTimeout {\n\t\tselect {\n\t\tcase <-doneCh:\n\t\t\treturn fmt.Errorf(\"should not trigger\")\n\t\tdefault:\n\t\t}\n\n\t\tcancelFn()\n\t\tselect {\n\t\tcase didTimeout := <-doneCh:\n\t\t\tif !didTimeout {\n\t\t\t\treturn fmt.Errorf(\"should have timed out\")\n\t\t\t}\n\t\tcase <-time.After(10 * time.Second):\n\t\t\treturn fmt.Errorf(\"should have timed out\")\n\t\t}\n\t} else {\n\t\tselect {\n\t\tcase didTimeout := <-doneCh:\n\t\t\tif didTimeout {\n\t\t\t\treturn fmt.Errorf(\"should not have timed out\")\n\t\t\t}\n\t\tcase <-time.After(10 * time.Second):\n\t\t\treturn fmt.Errorf(\"should have triggered\")\n\t\t}\n\t\tcancelFn()\n\t}\n\treturn nil\n}\n\nfunc TestWatchChan(t *testing.T) {\n\n\t// Sweep through a bunch of chunks to hit the various cases of dividing\n\t// the work into watchFew calls.\n\tfor size := 0; size < 3*aFew; size++ {\n\t\t// Fire each possible channel slot.\n\t\tfor fire := 0; fire < size; fire++ {\n\t\t\tif err := testWatchCh(size, fire); err != nil {\n\t\t\t\tt.Fatalf(\"err %d %d: %v\", size, fire, err)\n\t\t\t}\n\t\t}\n\n\t\t// Run a timeout case as well.\n\t\tfire := -1\n\t\tif err := testWatchCh(size, fire); err != nil {\n\t\t\tt.Fatalf(\"err %d %d: %v\", size, fire, err)\n\t\t}\n\t}\n}\n\nfunc TestWatch_AddWithLimit(t *testing.T) {\n\t// Make sure nil doesn't crash.\n\t{\n\t\tvar ws WatchSet\n\t\tch := make(chan struct{})\n\t\tws.AddWithLimit(10, ch, ch)\n\t}\n\n\t// Run a case where we trigger a channel that should be in\n\t// there.\n\t{\n\t\tws := NewWatchSet()\n\t\tinCh := make(chan struct{})\n\t\taltCh := make(chan struct{})\n\t\tws.AddWithLimit(1, inCh, altCh)\n\n\t\tnopeCh := make(chan struct{})\n\t\tws.AddWithLimit(1, nopeCh, altCh)\n\n\t\tclose(inCh)\n\t\tdidTimeout := ws.Watch(time.After(1 * time.Second))\n\t\tif didTimeout {\n\t\t\tt.Fatalf(\"bad\")\n\t\t}\n\t}\n\n\t// Run a case where we trigger the alt channel that should have\n\t// been added.\n\t{\n\t\tws := NewWatchSet()\n\t\tinCh := make(chan struct{})\n\t\taltCh := make(chan struct{})\n\t\tws.AddWithLimit(1, inCh, altCh)\n\n\t\tnopeCh := make(chan struct{})\n\t\tws.AddWithLimit(1, nopeCh, altCh)\n\n\t\tclose(altCh)\n\t\tdidTimeout := ws.Watch(time.After(1 * time.Second))\n\t\tif didTimeout {\n\t\t\tt.Fatalf(\"bad\")\n\t\t}\n\t}\n\n\t// Run a case where we trigger the nope channel that should not have\n\t// been added.\n\t{\n\t\tws := NewWatchSet()\n\t\tinCh := make(chan struct{})\n\t\taltCh := make(chan struct{})\n\t\tws.AddWithLimit(1, inCh, altCh)\n\n\t\tnopeCh := make(chan struct{})\n\t\tws.AddWithLimit(1, nopeCh, altCh)\n\n\t\tclose(nopeCh)\n\t\tdidTimeout := ws.Watch(time.After(1 * time.Second))\n\t\tif !didTimeout {\n\t\t\tt.Fatalf(\"bad\")\n\t\t}\n\t}\n}\n\nfunc TestWatchCtxLeak(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\n\t// We add a large number of channels to a WatchSet then\n\t// call WatchCtx. If one of those channels fires, we\n\t// expect to see all the goroutines spawned by WatchCtx\n\t// cleaned up.\n\tpprof.Do(ctx, pprof.Labels(\"foo\", \"bar\"), func(ctx context.Context) {\n\t\tws := NewWatchSet()\n\t\tfireCh := make(chan struct{})\n\t\tws.Add(fireCh)\n\t\tfor i := 0; i < 10000; i++ {\n\t\t\twatchCh := make(chan struct{})\n\t\t\tws.Add(watchCh)\n\t\t}\n\t\tresult := make(chan error)\n\t\tgo func() {\n\t\t\tresult <- ws.WatchCtx(ctx)\n\t\t}()\n\n\t\tfireCh <- struct{}{}\n\n\t\tif err := <-result; err != nil {\n\t\t\tt.Fatalf(\"expected no err got: %v\", err)\n\t\t}\n\t})\n\n\tnumRetries := 3\n\tvar gced bool\n\tfor i := 0; i < numRetries; i++ {\n\t\tvar pb bytes.Buffer\n\t\tprofiler := pprof.Lookup(\"goroutine\")\n\t\tif profiler == nil {\n\t\t\tt.Fatal(\"unable to find profile\")\n\t\t}\n\t\terr := profiler.WriteTo(&pb, 1)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to read profile: %v\", err)\n\t\t}\n\t\t// If the debug profile dump contains the string \"foo\",\n\t\t// it means one of the goroutines spawned in pprof.Do above\n\t\t// still appears in the capture.\n\t\tif !strings.Contains(pb.String(), \"foo\") {\n\t\t\tgced = true\n\t\t\tbreak\n\t\t} else {\n\t\t\tt.Log(\"retrying\")\n\t\t\ttime.Sleep(1 * time.Second)\n\t\t}\n\t}\n\tif !gced {\n\t\tt.Errorf(\"goroutines were not garbage collected after %d retries\", numRetries)\n\t}\n}\n\nfunc BenchmarkWatch(b *testing.B) {\n\tws := NewWatchSet()\n\tfor i := 0; i < 1024; i++ {\n\t\twatchCh := make(chan struct{})\n\t\tws.Add(watchCh)\n\t}\n\n\ttimeoutCh := make(chan time.Time)\n\tclose(timeoutCh)\n\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tws.Watch(timeoutCh)\n\t}\n}\n"
        }
      ]
    }
  ]
}