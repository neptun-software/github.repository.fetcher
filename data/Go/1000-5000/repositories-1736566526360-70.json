{
  "metadata": {
    "timestamp": 1736566526360,
    "page": 70,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjcw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "rosedblabs/rosedb",
      "stars": 4667,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.025390625,
          "content": ".idea/\n.vscode/\n.DS_Store\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 5.1396484375,
          "content": "# Release 2.3.9(2024-10-06)\n## ğŸ„ Enhancements\n* fix `DefaultOptions`: just return a temp dir name instead of creating it.\n\n# Release 2.3.8(2024-07-06)\n## ğŸ Bug Fixes\n* fix concurrent read\n\n# Release 2.3.7(2024-06-28)\n## ğŸ„ Enhancements\n* Update wal, imporve the iterate performance, and remove block cache.\n## ğŸ  Community\n* Thanks to @yinheli\n  * fix typo (https://github.com/rosedblabs/rosedb/commit/e51d6dc6dbba3d3e9c5a1c98de93df4b611b8755)\n\n# Release 2.3.6(2024-04-05)\n## ğŸ Bug Fixes\n* Fix index lock\n## ğŸ  Community\n* Thanks to @Sora233\n  * perf: improve batch performance #303\n\n# Release 2.3.5(2024-03-03)\n## ğŸ Bug Fixes\n* Fix index Less function panic.\n\n# Release 2.3.4(2024-01-07)\n\n## ğŸ„ Enhancements\n* use wal write batch to optimize performance.\n* optimize memory usage.\n\n## ğŸ  Community\n* Thanks to @LindaSummer\n  * add auto merge(https://github.com/rosedblabs/rosedb/commit/f31d45ef0cc3e738bbfe547df41fdfc23817bc4a)\n* Thanks to @justforward\n  * clarify file error(https://github.com/rosedblabs/rosedb/commit/b00612621aa9c27e79b4a012b53f5f1af1dd41bd)\n* Thanks to @lyonzhi\n  * approce test case for windows(https://github.com/rosedblabs/rosedb/commit/7d8c6c0e09bd556b65f11b37eca12cfdcb81b567)\n* Thanks to @246859\n  * fix(watch): make channnel that DB.Watch returns is readonly (https://github.com/rosedblabs/rosedb/pull/294)\n\n# Release 2.3.3(2023-09-16)\n## ğŸš€ New Features\n* add filterExpired for ascend/descend keys\n* Add persist function to remove the TTL of the key\n\n# Release 2.3.2(2023-08-30)\n## ğŸš€ New Features\n* add AscendKeys and DescnedKeys\n* Add Expire and TTL functions (https://github.com/rosedblabs/rosedb/pull/278)\n\n## ğŸ„ Enhancements\n* fix expire bug and add examples\n* add iterate examples\n\n## ğŸ  Community\n* Thanks to @Jeremy-Run \n    * Delete expired key of the index (https://github.com/rosedblabs/rosedb/pull/269)\n    * New: Delete Expired Keys (https://github.com/rosedblabs/rosedb/pull/280)\n* Thanks to @LEAVING-7 \n    * Fix potential deadlock in merge.go (https://github.com/rosedblabs/rosedb/pull/279)\n\n## ğŸ Bug Fixes\n* fix reput ttl bug\n\n# Release 2.3.1(2023-08-21)\n## ğŸš€ New Features\n* Support key expire\n  * You can call `PutWithTTL` to set the expire time for a key.\n\n## ğŸ  Community\n* Thanks to @weijiew \n    * Add more BTree functions #264\n\n# Release 2.3.0(2023-08-18)\n## ğŸš€ New Features\n* use BTree as the default memory data structure.\n  * the old Radix will be removed, and the iterator too.\n\n## ğŸ  Community\n* Thanks to @Jeremy-Run \n    * remove merge file after tests (https://github.com/rosedblabs/rosedb/pull/250)\n    * replace original file and rebuilt index after merge (https://github.com/rosedblabs/rosedb/pull/255)\n* Thanks to @SYaoJun \n    * fix: single quote error in README (https://github.com/rosedblabs/rosedb/pull/256)\n* Thanks to @weijiew \n    * add btree Ascendã€Descend method and unitest. (https://github.com/rosedblabs/rosedb/pull/257)\n\n# Release 2.2.2(2023-08-05)\n## ğŸš€ New Features\n* Watch Key [feature support watch event by key #227](https://github.com/rosedblabs/rosedb/issues/227) @Jeremy-Run \n\n## ğŸ„ Enhancements\n\n* Batch Optimiztion [use sync.Pool to optimize db.Put operation #235](https://github.com/rosedblabs/rosedb/issues/235)\n* Optimize memory usage [enhancement: high memory usage of rosedb #236](https://github.com/rosedblabs/rosedb/issues/236)\n\n## ğŸ  Community\n* Thanks to @kebukeYi \n    * Change Variable name in openMergeDB (https://github.com/rosedblabs/rosedb/pull/228)\n    * Avoid parsing wal files repeatedly. (https://github.com/rosedblabs/rosedb/pull/229)\n* Thanks to @Jeremy-Run \n    * Deleted data cannot exist in the index (https://github.com/rosedblabs/rosedb/pull/232)\n    * fix: solve data race (https://github.com/rosedblabs/rosedb/pull/234)\n    * fix: destFile may be not exist (https://github.com/rosedblabs/rosedb/pull/243)\n* Thanks to @rfyiamcool \n    * fix: format code comment for rand_kv (https://github.com/rosedblabs/rosedb/pull/240)\n\n# Release 2.2.1(2023-07-03)\n\n## ğŸ  Community\n* Thanks to @rfyiamcool for PR\n  * feature: Add rollback function to discard all buffered data and release the lock([#217](https://github.com/rosedblabs/rosedb/pull/217))\n  * fix: clear db after benchmark ([#224](https://github.com/rosedblabs/rosedb/pull/224))\n\n\n# Release 2.2.0(2023-06-21)\n\n## ğŸš€ New Features\n* Support Merge operation, to reclaim disk space.\n  * `Merge` will rewrite all the valid data into new file, and delete the old files.\n  * It maybe a very time-consuming operation, so it is recommended to use it when the database is idle.\n* Add tests in windows, with worlflow.\n\n# Release 2.1.0(2023-06-15)\n\n## ğŸš€ New Features\n\n* Support iterator in rosedb, it can traverse the data in database in order.\n  And the methods are as follows:\n\n  * Rewind\n  * Seek\n  * Next\n  * Key\n  * Value\n  * Close\n\nAnd the prefix scan is also supported.\n\n## ğŸBug Fix\n\n* Thanks to @rfyiamcool for PR\n  * [#216](https://github.com/rosedblabs/rosedb/pull/216) fix: update committed flag after batch commit\n\n# Release 2.0.0(2023-06-13)\n\n## ğŸš€ New Features\n* Basic operations, `Put/Get/Delete/Exist` key value pairs.\n* Batch operations, `Put/Get/Delete/Exist` key value pairs, and `Commit`.\n* DB functions, `Open/Close/Sync/Stat`.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 9.9345703125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n"
        },
        {
          "name": "README-CN.md",
          "type": "blob",
          "size": 6.0791015625,
          "content": "<div align=\"center\">\n<strong>\n<samp>\n\n[English](https://github.com/rosedblabs/rosedb/blob/main/README.md) Â· [ç®€ä½“ä¸­æ–‡](https://github.com/rosedblabs/rosedb/blob/main/README-CN.md)\n\n</samp>\n</strong>\n</div>\n\n## ROSEDB æ˜¯ä»€ä¹ˆï¼Ÿ\nRoseDB æ˜¯ä¸€ä¸ªåŸºäº [Bitcask](https://riak.com/assets/bitcask-intro.pdf) å­˜å‚¨æ¨¡å‹ï¼Œè½»é‡ã€å¿«é€Ÿã€å¯é çš„ KV å­˜å‚¨å¼•æ“ã€‚\n\nBitcask å­˜å‚¨æ¨¡å‹çš„è®¾è®¡ä¸»è¦å—åˆ°æ—¥å¿—ç»“æ„åŒ–çš„æ–‡ä»¶ç³»ç»Ÿå’Œæ—¥å¿—æ–‡ä»¶åˆå¹¶çš„å¯å‘ã€‚\n\n## çŠ¶æ€\nRoseDB ç»è¿‡å……åˆ†æµ‹è¯•ï¼Œå¯æ”¾å¿ƒåœ¨ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ã€‚ç›®å‰æœ‰ä¸€äº›ç”¨æˆ·å·²ç»åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨ RoseDB ä½œä¸ºå­˜å‚¨å¼•æ“ã€‚\n\n**æ²¡æœ‰æ‰¾åˆ°æ‚¨æƒ³è¦çš„åŠŸèƒ½ï¼Ÿ è¯·æå‡º issue æˆ– PRï¼Œé¡¹ç›®ç›®å‰å¤„äºç§¯æç»´æŠ¤çŠ¶æ€ï¼Œå°†ä¼šä»¥æœ€å¿«çš„é€Ÿåº¦å“åº”ä½ çš„éœ€æ±‚**\n\n## è®¾è®¡æ¦‚è¿°\n\n![](https://github.com/rosedblabs/rosedb/blob/main/docs/imgs/design-overview-rosedb.png)\n\nRoseDB å­˜å‚¨æ•°æ®çš„æ–‡ä»¶ä½¿ç”¨é¢„å†™æ—¥å¿—ï¼ˆWrite Ahead Logï¼‰ï¼Œè¿™äº›æ—¥å¿—æ–‡ä»¶æ˜¯å…·æœ‰ block ç¼“å­˜çš„åªè¿½åŠ å†™å…¥ï¼ˆappend-onlyï¼‰æ–‡ä»¶ã€‚\n\n> wal: https://github.com/rosedblabs/wal\n\n## ä¸»è¦ç‰¹ç‚¹\n### ä¼˜åŠ¿\n\n<details>\n    <summary><b>è¯»å†™ä½å»¶è¿Ÿ</b></summary>\n    è¿™æ˜¯ç”±äº Bitcask å­˜å‚¨æ¨¡å‹æ–‡ä»¶çš„è¿½åŠ å†™å…¥ç‰¹æ€§ï¼Œå……åˆ†åˆ©ç”¨é¡ºåº IO çš„ä¼˜åŠ¿ã€‚\n</details>\n\n<details>\n    <summary><b>é«˜ååé‡ï¼Œå³ä½¿æ•°æ®å®Œå…¨æ— åº</b></summary>\n    å†™å…¥ RoseDB çš„æ•°æ®ä¸éœ€è¦åœ¨ç£ç›˜ä¸Šæ’åºï¼ŒBitcask çš„æ—¥å¿—ç»“æ„æ–‡ä»¶è®¾è®¡åœ¨å†™å…¥è¿‡ç¨‹ä¸­å‡å°‘äº†ç£ç›˜ç£å¤´çš„ç§»åŠ¨ã€‚\n</details>\n\n<details>\n    <summary><b>èƒ½å¤Ÿå¤„ç†å¤§äºå†…å­˜çš„æ•°æ®é›†ï¼Œæ€§èƒ½ç¨³å®š</b></summary>\n    RoseDB çš„æ•°æ®è®¿é—®æ¶‰åŠå¯¹å†…å­˜ä¸­çš„ç´¢å¼•æ•°æ®ç»“æ„è¿›è¡Œç›´æ¥æŸ¥æ‰¾ï¼Œè¿™ä½¿å¾—å³ä½¿æ•°æ®é›†éå¸¸å¤§ï¼ŒæŸ¥æ‰¾æ•°æ®ä¹Ÿéå¸¸é«˜æ•ˆã€‚\n</details>\n\n<details>\n    <summary><b>ä¸€æ¬¡ç£ç›˜ IO å¯ä»¥è·å–ä»»æ„é”®å€¼å¯¹</b></summary>\n    RoseDB çš„å†…å­˜ç´¢å¼•æ•°æ®ç»“æ„ç›´æ¥æŒ‡å‘æ•°æ®æ‰€åœ¨çš„ç£ç›˜ä½ç½®ï¼Œä¸éœ€è¦å¤šæ¬¡ç£ç›˜å¯»å€æ¥è¯»å–ä¸€ä¸ªå€¼ï¼Œæœ‰æ—¶ç”šè‡³ä¸éœ€è¦å¯»å€ï¼Œè¿™å½’åŠŸäºæ“ä½œç³»ç»Ÿçš„æ–‡ä»¶ç³»ç»Ÿç¼“å­˜ä»¥åŠ WAL çš„ block ç¼“å­˜ã€‚\n</details>\n\n<details>\n    <summary><b>æ€§èƒ½å¿«é€Ÿç¨³å®š</b></summary>\n    RoseDB å†™å…¥æ“ä½œæœ€å¤šéœ€è¦ä¸€æ¬¡å¯¹å½“å‰æ‰“å¼€æ–‡ä»¶çš„å°¾éƒ¨çš„å¯»å€ï¼Œç„¶åè¿›è¡Œè¿½åŠ å†™å…¥ï¼Œå†™å…¥åä¼šæ›´æ–°å†…å­˜ã€‚è¿™ä¸ªæµç¨‹ä¸ä¼šå—åˆ°æ•°æ®åº“æ•°æ®é‡å¤§å°çš„å½±å“ï¼Œå› æ­¤æ€§èƒ½ç¨³å®šã€‚\n</details>\n\n<details>\n    <summary><b>å´©æºƒæ¢å¤å¿«é€Ÿ</b></summary>\n    ä½¿ç”¨ RoseDB çš„å´©æºƒæ¢å¤å¾ˆå®¹æ˜“ä¹Ÿå¾ˆå¿«ï¼Œå› ä¸º RoseDB æ–‡ä»¶æ˜¯åªè¿½åŠ å†™å…¥ä¸€æ¬¡çš„ã€‚æ¢å¤æ“ä½œéœ€è¦æ£€æŸ¥è®°å½•å¹¶éªŒè¯CRCæ•°æ®ï¼Œä»¥ç¡®ä¿æ•°æ®ä¸€è‡´ã€‚\n</details>\n\n<details>\n    <summary><b>å¤‡ä»½ç®€å•</b></summary>\n    åœ¨å¤§å¤šæ•°ç³»ç»Ÿä¸­ï¼Œå¤‡ä»½å¯èƒ½éå¸¸å¤æ‚ã€‚RoseDB é€šè¿‡å…¶åªè¿½åŠ å†™å…¥ä¸€æ¬¡çš„ç£ç›˜æ ¼å¼ç®€åŒ–äº†æ­¤è¿‡ç¨‹ã€‚ä»»ä½•æŒ‰ç£ç›˜å—é¡ºåºå­˜æ¡£æˆ–å¤åˆ¶æ–‡ä»¶çš„å·¥å…·éƒ½å°†æ­£ç¡®å¤‡ä»½æˆ–å¤åˆ¶ RoseDB æ•°æ®åº“ã€‚\n</details>\n\n<details>\n    <summary><b>æ‰¹å¤„ç†æ“ä½œå¯ä»¥ä¿è¯åŸå­æ€§ã€ä¸€è‡´æ€§å’ŒæŒä¹…æ€§</b></summary>\n    RoseDB æ”¯æŒæ‰¹å¤„ç†æ“ä½œï¼Œè¿™äº›æ“ä½œæ˜¯åŸå­ã€ä¸€è‡´å’ŒæŒä¹…çš„ã€‚æ‰¹å¤„ç†ä¸­çš„æ–°å†™å…¥æ“ä½œåœ¨æäº¤ä¹‹å‰è¢«ç¼“å­˜åœ¨å†…å­˜ä¸­ã€‚å¦‚æœæ‰¹å¤„ç†æˆåŠŸæäº¤ï¼Œæ‰¹å¤„ç†ä¸­çš„æ‰€æœ‰å†™å…¥æ“ä½œå°†æŒä¹…ä¿å­˜åˆ°ç£ç›˜ã€‚å¦‚æœæ‰¹å¤„ç†å¤±è´¥ï¼Œæ‰¹å¤„ç†ä¸­çš„æ‰€æœ‰å†™å…¥æ“ä½œå°†è¢«ä¸¢å¼ƒã€‚\n    å³ä¸€ä¸ªæ‰¹å¤„ç†æ“ä½œä¸­çš„æ‰€æœ‰å†™å…¥æ“ä½œè¦ä¹ˆå…¨éƒ¨æˆåŠŸï¼Œè¦ä¹ˆå…¨éƒ¨å¤±è´¥ã€‚\n</details>\n\n<details>\n    <summary><b>æ”¯æŒå¯ä»¥åå‘å’Œæ­£å‘è¿­ä»£çš„è¿­ä»£å™¨</b></summary>\n    RoseDB æ”¯æŒæ­£å‘å’Œåå‘è¿­ä»£å™¨ï¼Œè¿™äº›è¿­ä»£å™¨å¯ä»¥åœ¨æ•°æ®åº“ä¸­çš„ä»»ä½•ä½ç½®å¼€å§‹è¿­ä»£ã€‚è¿­ä»£å™¨å¯ä»¥ç”¨äºæ‰«ææ•°æ®åº“ä¸­çš„æ‰€æœ‰é”®å€¼å¯¹ï¼Œä¹Ÿå¯ä»¥ç”¨äºæ‰«ææ•°æ®åº“ä¸­çš„æŸä¸ªèŒƒå›´çš„é”®å€¼å¯¹ï¼Œè¿­ä»£å™¨ä»ç´¢å¼•ä¸­è·å–ä½ç½®ä¿¡æ¯ï¼Œç„¶åç›´æ¥ä»ç£ç›˜ä¸­è¯»å–æ•°æ®ï¼Œå› æ­¤è¿­ä»£å™¨çš„æ€§èƒ½éå¸¸é«˜ã€‚\n</details>\n\n<details>\n    <summary><b>æ”¯æŒ Watch åŠŸèƒ½</b></summary>\n    RoseDB æ”¯æŒ Watch åŠŸèƒ½ï¼ŒDB ä¸­çš„ key å‘ç”Ÿå˜åŒ–æ—¶ä½ å¯ä»¥å¾—åˆ°ä¸€ä¸ªäº‹ä»¶é€šçŸ¥ã€‚\n</details>\n\n<details>\n    <summary><b>æ”¯æŒ Key çš„è¿‡æœŸæ—¶é—´</b></summary>\n    RoseDB æ”¯æŒä¸º key è®¾ç½®è¿‡æœŸæ—¶é—´ï¼Œè¿‡æœŸå key å°†è¢«è‡ªåŠ¨åˆ é™¤ã€‚\n</details>\n\n### ç¼ºç‚¹\n\n<details>\n    <summary><b>æ‰€æœ‰çš„ key å¿…é¡»åœ¨å†…å­˜ä¸­ç»´æŠ¤</b></summary>\n    RoseDB å§‹ç»ˆå°†æ‰€æœ‰ key ä¿ç•™åœ¨å†…å­˜ä¸­ï¼Œè¿™æ„å‘³ç€æ‚¨çš„ç³»ç»Ÿå¿…é¡»å…·æœ‰è¶³å¤Ÿçš„å†…å­˜æ¥å®¹çº³æ‰€æœ‰çš„ keyã€‚\n</details>\n\n## å¿«é€Ÿä¸Šæ‰‹\n\n### åŸºæœ¬æ“ä½œ\n\n```go\npackage main\n\nimport \"github.com/rosedblabs/rosedb/v2\"\n\nfunc main() {\n\t// æŒ‡å®šé€‰é¡¹\n\toptions := rosedb.DefaultOptions\n\toptions.DirPath = \"/tmp/rosedb_basic\"\n\n\t// æ‰“å¼€æ•°æ®åº“\n\tdb, err := rosedb.Open(options)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer func() {\n\t\t_ = db.Close()\n\t}()\n\n\t// è®¾ç½®é”®å€¼å¯¹\n\terr = db.Put([]byte(\"name\"), []byte(\"rosedb\"))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\t// è·å–é”®å€¼å¯¹\n\tval, err := db.Get([]byte(\"name\"))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tprintln(string(val))\n\n\t// åˆ é™¤é”®å€¼å¯¹\n\terr = db.Delete([]byte(\"name\"))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n}\n```\n\n### æ‰¹å¤„ç†æ“ä½œ\n```go\n\t// åˆ›å»ºæ‰¹å¤„ç†\n\tbatch := db.NewBatch(rosedb.DefaultBatchOptions)\n\n\t// è®¾ç½®é”®å€¼å¯¹\n\t_ = batch.Put([]byte(\"name\"), []byte(\"rosedb\"))\n\n\t// è·å–é”®å€¼å¯¹\n\tval, _ := batch.Get([]byte(\"name\"))\n\tprintln(string(val))\n\n\t// åˆ é™¤é”®å€¼å¯¹\n\t_ = batch.Delete([]byte(\"name\"))\n\n\t// æäº¤æ‰¹å¤„ç†\n\t_ = batch.Commit()\n```\nå®Œæ•´ä»£ç å¯æŸ¥çœ‹ [examples ç¤ºä¾‹ä»£ç ](https://github.com/rosedblabs/rosedb/tree/main/examples)ã€‚\n\n## ç¤¾åŒº\næ¬¢è¿åŠ å…¥ [Slack](https://join.slack.com/t/rosedblabs/shared_invite/zt-19oj8ecqb-V02ycMV0BH1~Tn6tfeTz6A) é¢‘é“å’Œ [Discussions](https://github.com/orgs/rosedblabs/discussions) å’Œå…¶ä»– RoseDB å¼€å‘è€…å’Œä½¿ç”¨è€…è¿›è¡Œäº¤æµã€‚\n\n**å¾®ä¿¡ç¾¤ï¼š**\n\nå¯æ‰«æä¸‹æ–¹äºŒç»´ç ï¼Œé‚€è¯·ä½ åŠ å…¥ RoseDB ç¤¾åŒºäº¤æµç¾¤ï¼Œè¯·å¤‡æ³¨ **rosedb**\n| <img src=\"https://i.loli.net/2021/05/06/tGTH7SXg8w95slA.jpg\" width=\"200px\" align=\"left\"/> |\n| ------------------------------------------------------------ |\n\n## è´¡çŒ®è€…\n[![](https://opencollective.com/rosedb/contributors.svg?width=890&button=false)](https://github.com/rosedblabs/rosedb/graphs/contributors)\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 6.0869140625,
          "content": "<div align=\"center\">\n<strong>\n<samp>\n\n[English](https://github.com/rosedblabs/rosedb/blob/main/README.md) Â· [ç®€ä½“ä¸­æ–‡](https://github.com/rosedblabs/rosedb/blob/main/README-CN.md)\n\n</samp>\n</strong>\n</div>\n\n## What is ROSEDB\n\nrosedb is a lightweight, fast and reliable key/value storage engine based on [Bitcask](https://riak.com/assets/bitcask-intro.pdf) storage model.\n\nThe design of Bitcask was inspired, in part, by log-structured filesystems and log file merging.\n\n## Status\nrosedb is well tested and ready for production use. There are serveral projects using rosedb in production as a storage engine.\n\n**Didn't find the feature you want? Feel free to open an issue or PR, we are in active development.**\n\n## Design overview\n\n![](https://github.com/rosedblabs/rosedb/blob/main/docs/imgs/design-overview-rosedb.png)\n\nRoseDB log files are using the WAL(Write Ahead Log) as backend, which are append-only files with block cache.\n\n> wal: https://github.com/rosedblabs/wal\n\n## Key features\n\n### Strengths\n\n<details>\n    <summary><b>Low latency per item read or written</b></summary>\n    This is due to the write-once, append-only nature of Bitcask database files.\n</details>\n\n<details>\n    <summary><b>High throughput, especially when writing an incoming stream of random items</b></summary>\n    Write operations to RoseDB generally saturate I/O and disk bandwidth, which is a good thing from a performance perspective. This saturation occurs for two reasons: because (1) data that is written to RoseDB doesn't need to be ordered on disk, and (2) the log-structured design of Bitcask allows for minimal disk head movement during writes.\n</details>    \n\n<details>\n    <summary><b>Ability to handle datasets larger than RAM without degradation</b></summary>\n    Access to data in RoseDB involves direct lookup from an in-memory index data structure. This makes finding data very efficient, even when datasets are very large.\n</details>\n\n<details>\n    <summary><b>Single seek to retrieve any value</b></summary>\n    RoseDB's in-memory index data structure of keys points directly to locations on disk where the data lives. RoseDB never uses more than one disk seek to read a value and sometimes even that isn't necessary due to filesystem caching done by the operating system.\n</details>\n\n<details>\n    <summary><b>Predictable lookup and insert performance</b></summary>\n    For the reasons listed above, read operations from RoseDB have fixed, predictable behavior. This is also true of writes to RoseDB because write operations require, at most, one seek to the end of the current open file followed by and append to that file.\n</details>\n\n<details>\n    <summary><b>Fast, bounded crash recovery</b></summary>\n    Crash recovery is easy and fast with RoseDB because RoseDB files are append only and write once. The only items that may be lost are partially written records at the tail of the last file that was opened for writes. Recovery operations need to review the record and verify CRC data to ensure that the data is consistent.\n</details>\n\n<details>\n    <summary><b>Easy Backup</b></summary>\n    In most systems, backup can be very complicated. RoseDB simplifies this process due to its append-only, write-once disk format. Any utility that archives or copies files in disk-block order will properly back up or copy a RoseDB database.\n</details>\n\n<details>\n    <summary><b>Batch options which guarantee atomicity, consistency, and durability</b></summary>\n\tRoseDB supports batch operations which are atomic, consistent, and durable. The new writes in batch are cached in memory before committing. If the batch is committed successfully, all the writes in the batch will be persisted to disk. If the batch fails, all the writes in the batch will be discarded.\n</details>\n\n<details>\n    <summary><b>Support iterator for forward and backward</b></summary>\n\tRoseDB supports iterator for forward and backward. The iterator is based on the in-memory index data structure of keys, which points directly to locations on disk where the data lives. The iterator is very efficient, even when datasets are very large.\n</details>\n\n<details>\n    <summary><b>Support key watch</b></summary>\n\tRoseDB supports key watch, you can get the notification if keys changed in db.\n</details>\n\n<details>\n    <summary><b>Support key expire</b></summary>\n\tRoseDB supports key expire, you can set the expire time for keys.\n</details>\n\n### Weaknesses\n\n<details>\n    <summary><b>Keys must fit in memory</b></summary>\n    RoseDB keeps all keys in memory at all times, which means that your system must have enough memory to contain your entire keyspace, plus additional space for other operational components and operating- system-resident filesystem buffer space.\n</details>\n\n## Gettings Started\n\n### Basic operations\n\n```go\npackage main\n\nimport \"github.com/rosedblabs/rosedb/v2\"\n\nfunc main() {\n\t// specify the options\n\toptions := rosedb.DefaultOptions\n\toptions.DirPath = \"/tmp/rosedb_basic\"\n\n\t// open a database\n\tdb, err := rosedb.Open(options)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer func() {\n\t\t_ = db.Close()\n\t}()\n\n\t// set a key\n\terr = db.Put([]byte(\"name\"), []byte(\"rosedb\"))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\t// get a key\n\tval, err := db.Get([]byte(\"name\"))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tprintln(string(val))\n\n\t// delete a key\n\terr = db.Delete([]byte(\"name\"))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n}\n```\n\n### Batch operations\n\n```go\n\t// create a batch\n\tbatch := db.NewBatch(rosedb.DefaultBatchOptions)\n\n\t// set a key\n\t_ = batch.Put([]byte(\"name\"), []byte(\"rosedb\"))\n\n\t// get a key\n\tval, _ := batch.Get([]byte(\"name\"))\n\tprintln(string(val))\n\n\t// delete a key\n\t_ = batch.Delete([]byte(\"name\"))\n\n\t// commit the batch\n\t_ = batch.Commit()\n```\n\nsee the [examples](https://github.com/rosedblabs/rosedb/tree/main/examples) for more details.\n\n## Community\nWelcome to join the [Slack](https://join.slack.com/t/rosedblabs/shared_invite/zt-19oj8ecqb-V02ycMV0BH1~Tn6tfeTz6A) channel and [Discussions](https://github.com/orgs/rosedblabs/discussions) to connect with RoseDB team developers and other users.\n\n## Contributors\n[![](https://opencollective.com/rosedb/contributors.svg?width=890&button=false)](https://github.com/rosedblabs/rosedb/graphs/contributors)\n"
        },
        {
          "name": "batch.go",
          "type": "blob",
          "size": 13.931640625,
          "content": "package rosedb\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"github.com/rosedblabs/rosedb/v2/utils\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/bwmarrin/snowflake\"\n\t\"github.com/valyala/bytebufferpool\"\n)\n\n// Batch is a batch operations of the database.\n// If readonly is true, you can only get data from the batch by Get method.\n// An error will be returned if you try to use Put or Delete method.\n//\n// If readonly is false, you can use Put and Delete method to write data to the batch.\n// The data will be written to the database when you call Commit method.\n//\n// Batch is not a transaction, it does not guarantee isolation.\n// But it can guarantee atomicity, consistency and durability(if the Sync options is true).\n//\n// You must call Commit method to commit the batch, otherwise the DB will be locked.\ntype Batch struct {\n\tdb               *DB\n\tpendingWrites    []*LogRecord     // save the data to be written\n\tpendingWritesMap map[uint64][]int // map record hash key to index, fast lookup to pendingWrites\n\toptions          BatchOptions\n\tmu               sync.RWMutex\n\tcommitted        bool // whether the batch has been committed\n\trollbacked       bool // whether the batch has been rollbacked\n\tbatchId          *snowflake.Node\n\tbuffers          []*bytebufferpool.ByteBuffer\n}\n\n// NewBatch creates a new Batch instance.\nfunc (db *DB) NewBatch(options BatchOptions) *Batch {\n\tbatch := &Batch{\n\t\tdb:         db,\n\t\toptions:    options,\n\t\tcommitted:  false,\n\t\trollbacked: false,\n\t}\n\tif !options.ReadOnly {\n\t\tnode, err := snowflake.NewNode(1)\n\t\tif err != nil {\n\t\t\tpanic(fmt.Sprintf(\"snowflake.NewNode(1) failed: %v\", err))\n\t\t}\n\t\tbatch.batchId = node\n\t}\n\tbatch.lock()\n\treturn batch\n}\n\nfunc newBatch() interface{} {\n\tnode, err := snowflake.NewNode(1)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"snowflake.NewNode(1) failed: %v\", err))\n\t}\n\treturn &Batch{\n\t\toptions: DefaultBatchOptions,\n\t\tbatchId: node,\n\t}\n}\n\nfunc newRecord() interface{} {\n\treturn &LogRecord{}\n}\n\nfunc (b *Batch) init(rdonly, sync bool, db *DB) *Batch {\n\tb.options.ReadOnly = rdonly\n\tb.options.Sync = sync\n\tb.db = db\n\tb.lock()\n\treturn b\n}\n\nfunc (b *Batch) reset() {\n\tb.db = nil\n\tb.pendingWrites = b.pendingWrites[:0]\n\tb.pendingWritesMap = nil\n\tb.committed = false\n\tb.rollbacked = false\n\t// put all buffers back to the pool\n\tfor _, buf := range b.buffers {\n\t\tbytebufferpool.Put(buf)\n\t}\n\tb.buffers = b.buffers[:0]\n}\n\nfunc (b *Batch) lock() {\n\tif b.options.ReadOnly {\n\t\tb.db.mu.RLock()\n\t} else {\n\t\tb.db.mu.Lock()\n\t}\n}\n\nfunc (b *Batch) unlock() {\n\tif b.options.ReadOnly {\n\t\tb.db.mu.RUnlock()\n\t} else {\n\t\tb.db.mu.Unlock()\n\t}\n}\n\n// Put adds a key-value pair to the batch for writing.\nfunc (b *Batch) Put(key []byte, value []byte) error {\n\tif len(key) == 0 {\n\t\treturn ErrKeyIsEmpty\n\t}\n\tif b.db.closed {\n\t\treturn ErrDBClosed\n\t}\n\tif b.options.ReadOnly {\n\t\treturn ErrReadOnlyBatch\n\t}\n\n\tb.mu.Lock()\n\t// write to pendingWrites\n\tvar record = b.lookupPendingWrites(key)\n\tif record == nil {\n\t\t// if the key does not exist in pendingWrites, write a new record\n\t\t// the record will be put back to the pool when the batch is committed or rollbacked\n\t\trecord = b.db.recordPool.Get().(*LogRecord)\n\t\tb.appendPendingWrites(key, record)\n\t}\n\n\trecord.Key, record.Value = key, value\n\trecord.Type, record.Expire = LogRecordNormal, 0\n\tb.mu.Unlock()\n\n\treturn nil\n}\n\n// PutWithTTL adds a key-value pair with ttl to the batch for writing.\nfunc (b *Batch) PutWithTTL(key []byte, value []byte, ttl time.Duration) error {\n\tif len(key) == 0 {\n\t\treturn ErrKeyIsEmpty\n\t}\n\tif b.db.closed {\n\t\treturn ErrDBClosed\n\t}\n\tif b.options.ReadOnly {\n\t\treturn ErrReadOnlyBatch\n\t}\n\n\tb.mu.Lock()\n\t// write to pendingWrites\n\tvar record = b.lookupPendingWrites(key)\n\tif record == nil {\n\t\t// if the key does not exist in pendingWrites, write a new record\n\t\t// the record will be put back to the pool when the batch is committed or rollbacked\n\t\trecord = b.db.recordPool.Get().(*LogRecord)\n\t\tb.appendPendingWrites(key, record)\n\t}\n\n\trecord.Key, record.Value = key, value\n\trecord.Type, record.Expire = LogRecordNormal, time.Now().Add(ttl).UnixNano()\n\tb.mu.Unlock()\n\n\treturn nil\n}\n\n// Get retrieves the value associated with a given key from the batch.\nfunc (b *Batch) Get(key []byte) ([]byte, error) {\n\tif len(key) == 0 {\n\t\treturn nil, ErrKeyIsEmpty\n\t}\n\tif b.db.closed {\n\t\treturn nil, ErrDBClosed\n\t}\n\n\tnow := time.Now().UnixNano()\n\t// get from pendingWrites\n\tb.mu.RLock()\n\tvar record = b.lookupPendingWrites(key)\n\tb.mu.RUnlock()\n\n\t// if the record is in pendingWrites, return the value directly\n\tif record != nil {\n\t\tif record.Type == LogRecordDeleted || record.IsExpired(now) {\n\t\t\treturn nil, ErrKeyNotFound\n\t\t}\n\t\treturn record.Value, nil\n\t}\n\n\t// get key/value from data file\n\tchunkPosition := b.db.index.Get(key)\n\tif chunkPosition == nil {\n\t\treturn nil, ErrKeyNotFound\n\t}\n\tchunk, err := b.db.dataFiles.Read(chunkPosition)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// check if the record is deleted or expired\n\trecord = decodeLogRecord(chunk)\n\tif record.Type == LogRecordDeleted {\n\t\tpanic(\"Deleted data cannot exist in the index\")\n\t}\n\tif record.IsExpired(now) {\n\t\tb.db.index.Delete(record.Key)\n\t\treturn nil, ErrKeyNotFound\n\t}\n\treturn record.Value, nil\n}\n\n// Delete marks a key for deletion in the batch.\nfunc (b *Batch) Delete(key []byte) error {\n\tif len(key) == 0 {\n\t\treturn ErrKeyIsEmpty\n\t}\n\tif b.db.closed {\n\t\treturn ErrDBClosed\n\t}\n\tif b.options.ReadOnly {\n\t\treturn ErrReadOnlyBatch\n\t}\n\n\tb.mu.Lock()\n\t// only need key and type when deleting a value.\n\tvar exist bool\n\tvar record = b.lookupPendingWrites(key)\n\tif record != nil {\n\t\trecord.Type = LogRecordDeleted\n\t\trecord.Value = nil\n\t\trecord.Expire = 0\n\t\texist = true\n\t}\n\tif !exist {\n\t\trecord = &LogRecord{\n\t\t\tKey:  key,\n\t\t\tType: LogRecordDeleted,\n\t\t}\n\t\tb.appendPendingWrites(key, record)\n\t}\n\tb.mu.Unlock()\n\n\treturn nil\n}\n\n// Exist checks if the key exists in the database.\nfunc (b *Batch) Exist(key []byte) (bool, error) {\n\tif len(key) == 0 {\n\t\treturn false, ErrKeyIsEmpty\n\t}\n\tif b.db.closed {\n\t\treturn false, ErrDBClosed\n\t}\n\n\tnow := time.Now().UnixNano()\n\t// check if the key exists in pendingWrites\n\tb.mu.RLock()\n\tvar record = b.lookupPendingWrites(key)\n\tb.mu.RUnlock()\n\n\tif record != nil {\n\t\treturn record.Type != LogRecordDeleted && !record.IsExpired(now), nil\n\t}\n\n\t// check if the key exists in index\n\tposition := b.db.index.Get(key)\n\tif position == nil {\n\t\treturn false, nil\n\t}\n\n\t// check if the record is deleted or expired\n\tchunk, err := b.db.dataFiles.Read(position)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\trecord = decodeLogRecord(chunk)\n\tif record.Type == LogRecordDeleted || record.IsExpired(now) {\n\t\tb.db.index.Delete(record.Key)\n\t\treturn false, nil\n\t}\n\treturn true, nil\n}\n\n// Expire sets the ttl of the key.\nfunc (b *Batch) Expire(key []byte, ttl time.Duration) error {\n\tif len(key) == 0 {\n\t\treturn ErrKeyIsEmpty\n\t}\n\tif b.db.closed {\n\t\treturn ErrDBClosed\n\t}\n\tif b.options.ReadOnly {\n\t\treturn ErrReadOnlyBatch\n\t}\n\n\tb.mu.Lock()\n\tdefer b.mu.Unlock()\n\n\tvar record = b.lookupPendingWrites(key)\n\n\t// if the key exists in pendingWrites, update the expiry time directly\n\tif record != nil {\n\t\t// return key not found if the record is deleted or expired\n\t\tif record.Type == LogRecordDeleted || record.IsExpired(time.Now().UnixNano()) {\n\t\t\treturn ErrKeyNotFound\n\t\t}\n\t\trecord.Expire = time.Now().Add(ttl).UnixNano()\n\t\treturn nil\n\t}\n\t// if the key does not exist in pendingWrites, get the value from wal\n\tposition := b.db.index.Get(key)\n\tif position == nil {\n\t\treturn ErrKeyNotFound\n\t}\n\tchunk, err := b.db.dataFiles.Read(position)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tnow := time.Now()\n\trecord = decodeLogRecord(chunk)\n\t// if the record is deleted or expired, we can assume that the key does not exist,\n\t// and delete the key from the index\n\tif record.Type == LogRecordDeleted || record.IsExpired(now.UnixNano()) {\n\t\tb.db.index.Delete(key)\n\t\treturn ErrKeyNotFound\n\t}\n\t// now we get the value from wal, update the expiry time\n\t// and rewrite the record to pendingWrites\n\trecord.Expire = now.Add(ttl).UnixNano()\n\tb.appendPendingWrites(key, record)\n\n\treturn nil\n}\n\n// TTL returns the ttl of the key.\nfunc (b *Batch) TTL(key []byte) (time.Duration, error) {\n\tif len(key) == 0 {\n\t\treturn -1, ErrKeyIsEmpty\n\t}\n\tif b.db.closed {\n\t\treturn -1, ErrDBClosed\n\t}\n\n\tnow := time.Now()\n\tb.mu.Lock()\n\tdefer b.mu.Unlock()\n\n\tvar record = b.lookupPendingWrites(key)\n\tif record != nil {\n\t\tif record.Expire == 0 {\n\t\t\treturn -1, nil\n\t\t}\n\t\t// return key not found if the record is deleted or expired\n\t\tif record.Type == LogRecordDeleted || record.IsExpired(now.UnixNano()) {\n\t\t\treturn -1, ErrKeyNotFound\n\t\t}\n\t\t// now we get the valid expiry time, we can calculate the ttl\n\t\treturn time.Duration(record.Expire - now.UnixNano()), nil\n\t}\n\n\t// if the key does not exist in pendingWrites, get the value from wal\n\tposition := b.db.index.Get(key)\n\tif position == nil {\n\t\treturn -1, ErrKeyNotFound\n\t}\n\tchunk, err := b.db.dataFiles.Read(position)\n\tif err != nil {\n\t\treturn -1, err\n\t}\n\n\t// return key not found if the record is deleted or expired\n\trecord = decodeLogRecord(chunk)\n\tif record.Type == LogRecordDeleted {\n\t\treturn -1, ErrKeyNotFound\n\t}\n\tif record.IsExpired(now.UnixNano()) {\n\t\tb.db.index.Delete(key)\n\t\treturn -1, ErrKeyNotFound\n\t}\n\n\t// now we get the valid expiry time, we can calculate the ttl\n\tif record.Expire > 0 {\n\t\treturn time.Duration(record.Expire - now.UnixNano()), nil\n\t}\n\n\treturn -1, nil\n}\n\n// Persist removes the ttl of the key.\nfunc (b *Batch) Persist(key []byte) error {\n\tif len(key) == 0 {\n\t\treturn ErrKeyIsEmpty\n\t}\n\tif b.db.closed {\n\t\treturn ErrDBClosed\n\t}\n\tif b.options.ReadOnly {\n\t\treturn ErrReadOnlyBatch\n\t}\n\n\tb.mu.Lock()\n\tdefer b.mu.Unlock()\n\n\t// if the key exists in pendingWrites, update the expiry time directly\n\tvar record = b.lookupPendingWrites(key)\n\tif record != nil {\n\t\tif record.Type == LogRecordDeleted && record.IsExpired(time.Now().UnixNano()) {\n\t\t\treturn ErrKeyNotFound\n\t\t}\n\t\trecord.Expire = 0\n\t\treturn nil\n\t}\n\n\t// check if the key exists in index\n\tposition := b.db.index.Get(key)\n\tif position == nil {\n\t\treturn ErrKeyNotFound\n\t}\n\tchunk, err := b.db.dataFiles.Read(position)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\trecord = decodeLogRecord(chunk)\n\tnow := time.Now().UnixNano()\n\t// check if the record is deleted or expired\n\tif record.Type == LogRecordDeleted || record.IsExpired(now) {\n\t\tb.db.index.Delete(record.Key)\n\t\treturn ErrKeyNotFound\n\t}\n\t// if the expiration time is 0, it means that the key has no expiration time,\n\t// so we can return directly\n\tif record.Expire == 0 {\n\t\treturn nil\n\t}\n\n\t// set the expiration time to 0, and rewrite the record to wal\n\trecord.Expire = 0\n\tb.appendPendingWrites(key, record)\n\n\treturn nil\n}\n\n// Commit commits the batch, if the batch is readonly or empty, it will return directly.\n//\n// It will iterate the pendingWrites and write the data to the database,\n// then write a record to indicate the end of the batch to guarantee atomicity.\n// Finally, it will write the index.\nfunc (b *Batch) Commit() error {\n\tdefer b.unlock()\n\tif b.db.closed {\n\t\treturn ErrDBClosed\n\t}\n\n\tif b.options.ReadOnly || len(b.pendingWrites) == 0 {\n\t\treturn nil\n\t}\n\n\tb.mu.Lock()\n\tdefer b.mu.Unlock()\n\n\t// check if committed or rollbacked\n\tif b.committed {\n\t\treturn ErrBatchCommitted\n\t}\n\tif b.rollbacked {\n\t\treturn ErrBatchRollbacked\n\t}\n\n\tbatchId := b.batchId.Generate()\n\tnow := time.Now().UnixNano()\n\t// write to wal buffer\n\tfor _, record := range b.pendingWrites {\n\t\tbuf := bytebufferpool.Get()\n\t\tb.buffers = append(b.buffers, buf)\n\t\trecord.BatchId = uint64(batchId)\n\t\tencRecord := encodeLogRecord(record, b.db.encodeHeader, buf)\n\t\tb.db.dataFiles.PendingWrites(encRecord)\n\t}\n\n\t// write a record to indicate the end of the batch\n\tbuf := bytebufferpool.Get()\n\tb.buffers = append(b.buffers, buf)\n\tendRecord := encodeLogRecord(&LogRecord{\n\t\tKey:  batchId.Bytes(),\n\t\tType: LogRecordBatchFinished,\n\t}, b.db.encodeHeader, buf)\n\tb.db.dataFiles.PendingWrites(endRecord)\n\n\t// write to wal file\n\tchunkPositions, err := b.db.dataFiles.WriteAll()\n\tif err != nil {\n\t\tb.db.dataFiles.ClearPendingWrites()\n\t\treturn err\n\t}\n\tif len(chunkPositions) != len(b.pendingWrites)+1 {\n\t\tpanic(\"chunk positions length is not equal to pending writes length\")\n\t}\n\n\t// flush wal if necessary\n\tif b.options.Sync && !b.db.options.Sync {\n\t\tif err := b.db.dataFiles.Sync(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// write to index\n\tfor i, record := range b.pendingWrites {\n\t\tif record.Type == LogRecordDeleted || record.IsExpired(now) {\n\t\t\tb.db.index.Delete(record.Key)\n\t\t} else {\n\t\t\tb.db.index.Put(record.Key, chunkPositions[i])\n\t\t}\n\n\t\tif b.db.options.WatchQueueSize > 0 {\n\t\t\te := &Event{Key: record.Key, Value: record.Value, BatchId: record.BatchId}\n\t\t\tif record.Type == LogRecordDeleted {\n\t\t\t\te.Action = WatchActionDelete\n\t\t\t} else {\n\t\t\t\te.Action = WatchActionPut\n\t\t\t}\n\t\t\tb.db.watcher.putEvent(e)\n\t\t}\n\t\t// put the record back to the pool\n\t\tb.db.recordPool.Put(record)\n\t}\n\n\tb.committed = true\n\treturn nil\n}\n\n// Rollback discards an uncommitted batch instance.\n// the discard operation will clear the buffered data and release the lock.\nfunc (b *Batch) Rollback() error {\n\tdefer b.unlock()\n\n\tif b.db.closed {\n\t\treturn ErrDBClosed\n\t}\n\n\tif b.committed {\n\t\treturn ErrBatchCommitted\n\t}\n\tif b.rollbacked {\n\t\treturn ErrBatchRollbacked\n\t}\n\n\tfor _, buf := range b.buffers {\n\t\tbytebufferpool.Put(buf)\n\t}\n\n\tif !b.options.ReadOnly {\n\t\t// clear pendingWrites\n\t\tfor _, record := range b.pendingWrites {\n\t\t\tb.db.recordPool.Put(record)\n\t\t}\n\t\tb.pendingWrites = b.pendingWrites[:0]\n\t\tfor key := range b.pendingWritesMap {\n\t\t\tdelete(b.pendingWritesMap, key)\n\t\t}\n\t}\n\n\tb.rollbacked = true\n\treturn nil\n}\n\n// lookupPendingWrites if the key exists in pendingWrites, update the value directly\nfunc (b *Batch) lookupPendingWrites(key []byte) *LogRecord {\n\tif len(b.pendingWritesMap) == 0 {\n\t\treturn nil\n\t}\n\n\thashKey := utils.MemHash(key)\n\tfor _, entry := range b.pendingWritesMap[hashKey] {\n\t\tif bytes.Compare(b.pendingWrites[entry].Key, key) == 0 {\n\t\t\treturn b.pendingWrites[entry]\n\t\t}\n\t}\n\treturn nil\n}\n\n// add new record to pendingWrites and pendingWritesMap.\nfunc (b *Batch) appendPendingWrites(key []byte, record *LogRecord) {\n\tb.pendingWrites = append(b.pendingWrites, record)\n\tif b.pendingWritesMap == nil {\n\t\tb.pendingWritesMap = make(map[uint64][]int)\n\t}\n\thashKey := utils.MemHash(key)\n\tb.pendingWritesMap[hashKey] = append(b.pendingWritesMap[hashKey], len(b.pendingWrites)-1)\n}\n"
        },
        {
          "name": "batch_test.go",
          "type": "blob",
          "size": 5.380859375,
          "content": "package rosedb\n\nimport (\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/rosedblabs/rosedb/v2/utils\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc destroyDB(db *DB) {\n\t_ = db.Close()\n\t_ = os.RemoveAll(db.options.DirPath)\n\t_ = os.RemoveAll(mergeDirPath(db.options.DirPath))\n}\n\nfunc TestBatch_Put_Normal(t *testing.T) {\n\t// value 128B\n\tbatchPutAndIterate(t, 1*GB, 10000, 128)\n\t// value 1KB\n\tbatchPutAndIterate(t, 1*GB, 10000, KB)\n\t// value 32KB\n\tbatchPutAndIterate(t, 1*GB, 1000, 32*KB)\n}\n\nfunc TestBatch_Put_IncrSegmentFile(t *testing.T) {\n\tbatchPutAndIterate(t, 64*MB, 2000, 32*KB)\n\toptions := DefaultOptions\n\toptions.SegmentSize = 64 * MB\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tgenerateData(t, db, 1, 2000, 32*KB)\n\n\t// write more data to rotate new segment file\n\tbatch := db.NewBatch(DefaultBatchOptions)\n\tfor i := 0; i < 1000; i++ {\n\t\terr := batch.Put(utils.GetTestKey(i*100), utils.RandomValue(32*KB))\n\t\tassert.Nil(t, err)\n\t}\n\terr = batch.Commit()\n\tassert.Nil(t, err)\n}\n\nfunc TestBatch_Get_Normal(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tbatch1 := db.NewBatch(DefaultBatchOptions)\n\terr = batch1.Put(utils.GetTestKey(12), utils.RandomValue(128))\n\tassert.Nil(t, err)\n\tval1, err := batch1.Get(utils.GetTestKey(12))\n\tassert.Nil(t, err)\n\tassert.NotNil(t, val1)\n\t_ = batch1.Commit()\n\n\tgenerateData(t, db, 400, 500, 4*KB)\n\n\tbatch2 := db.NewBatch(DefaultBatchOptions)\n\terr = batch2.Delete(utils.GetTestKey(450))\n\tassert.Nil(t, err)\n\tval, err := batch2.Get(utils.GetTestKey(450))\n\tassert.Nil(t, val)\n\tassert.Equal(t, ErrKeyNotFound, err)\n\t_ = batch2.Commit()\n\n\t// reopen\n\t_ = db.Close()\n\tdb2, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer func() {\n\t\t_ = db2.Close()\n\t}()\n\tassertKeyExistOrNot(t, db2, utils.GetTestKey(12), true)\n\tassertKeyExistOrNot(t, db2, utils.GetTestKey(450), false)\n}\n\nfunc TestBatch_Delete_Normal(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\terr = db.Delete([]byte(\"not exist\"))\n\tassert.Nil(t, err)\n\n\tgenerateData(t, db, 1, 100, 128)\n\terr = db.Delete(utils.GetTestKey(99))\n\tassert.Nil(t, err)\n\n\texist, err := db.Exist(utils.GetTestKey(99))\n\tassert.Nil(t, err)\n\tassert.False(t, exist)\n\n\tbatch := db.NewBatch(DefaultBatchOptions)\n\terr = batch.Put(utils.GetTestKey(200), utils.RandomValue(100))\n\tassert.Nil(t, err)\n\terr = batch.Delete(utils.GetTestKey(200))\n\tassert.Nil(t, err)\n\texist1, err := batch.Exist(utils.GetTestKey(200))\n\tassert.Nil(t, err)\n\tassert.False(t, exist1)\n\t_ = batch.Commit()\n\n\t// reopen\n\t_ = db.Close()\n\tdb2, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer func() {\n\t\t_ = db2.Close()\n\t}()\n\tassertKeyExistOrNot(t, db2, utils.GetTestKey(200), false)\n}\n\nfunc TestBatch_Exist_Normal(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tgenerateData(t, db, 1, 100, 128)\n\tbatch := db.NewBatch(DefaultBatchOptions)\n\tok1, err := batch.Exist(utils.GetTestKey(99))\n\tassert.Nil(t, err)\n\tassert.True(t, ok1)\n\tok2, err := batch.Exist(utils.GetTestKey(5000))\n\tassert.Nil(t, err)\n\tassert.False(t, ok2)\n\t_ = batch.Commit()\n\n\t_ = db.Close()\n\tdb2, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer func() {\n\t\t_ = db2.Close()\n\t}()\n\tassertKeyExistOrNot(t, db2, utils.GetTestKey(99), true)\n}\n\nfunc generateData(t *testing.T, db *DB, start, end int, valueLen int) {\n\tfor ; start < end; start++ {\n\t\terr := db.Put(utils.GetTestKey(start), utils.RandomValue(valueLen))\n\t\tassert.Nil(t, err)\n\t}\n}\n\nfunc batchPutAndIterate(t *testing.T, segmentSize int64, size int, valueLen int) {\n\toptions := DefaultOptions\n\toptions.SegmentSize = segmentSize\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tbatch := db.NewBatch(BatchOptions{})\n\n\tfor i := 0; i < size; i++ {\n\t\terr := batch.Put(utils.GetTestKey(i), utils.RandomValue(valueLen))\n\t\tassert.Nil(t, err)\n\t}\n\terr = batch.Commit()\n\tassert.Nil(t, err)\n\n\tfor i := 0; i < size; i++ {\n\t\tvalue, err := db.Get(utils.GetTestKey(i))\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, len(utils.RandomValue(valueLen)), len(value))\n\t}\n\n\t// reopen\n\t_ = db.Close()\n\tdb2, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer func() {\n\t\t_ = db2.Close()\n\t}()\n\tfor i := 0; i < size; i++ {\n\t\tvalue, err := db2.Get(utils.GetTestKey(i))\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, len(utils.RandomValue(valueLen)), len(value))\n\t}\n}\n\nfunc assertKeyExistOrNot(t *testing.T, db *DB, key []byte, exist bool) {\n\tval, err := db.Get(key)\n\tif exist {\n\t\tassert.Nil(t, err)\n\t\tassert.NotNil(t, val)\n\t} else {\n\t\tassert.Nil(t, val)\n\t\tassert.Equal(t, ErrKeyNotFound, err)\n\t}\n}\n\nfunc TestBatch_Rollback(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tkey := []byte(\"rosedb\")\n\tvalue := []byte(\"val\")\n\n\tbatcher := db.NewBatch(DefaultBatchOptions)\n\terr = batcher.Put(key, value)\n\tassert.Nil(t, err)\n\n\terr = batcher.Rollback()\n\tassert.Nil(t, err)\n\n\tresp, err := db.Get(key)\n\tassert.Equal(t, ErrKeyNotFound, err)\n\tassert.Empty(t, resp)\n}\n\nfunc TestBatch_SetTwice(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tbatch := db.NewBatch(DefaultBatchOptions)\n\tkey := []byte(\"rosedb\")\n\tvalue1 := []byte(\"val1\")\n\tvalue2 := []byte(\"val2\")\n\t_ = batch.Put(key, value1)\n\t_ = batch.Put(key, value2)\n\n\tres, err := batch.Get(key)\n\tassert.Nil(t, err)\n\tassert.Equal(t, res, value2)\n\n\t_ = batch.Commit()\n\tres2, err := db.Get(key)\n\tassert.Nil(t, err)\n\tassert.Equal(t, res2, value2)\n}\n"
        },
        {
          "name": "benchmark",
          "type": "tree",
          "content": null
        },
        {
          "name": "db.go",
          "type": "blob",
          "size": 19.7763671875,
          "content": "package rosedb\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/bwmarrin/snowflake\"\n\t\"github.com/gofrs/flock\"\n\t\"github.com/robfig/cron/v3\"\n\t\"github.com/rosedblabs/rosedb/v2/index\"\n\t\"github.com/rosedblabs/rosedb/v2/utils\"\n\t\"github.com/rosedblabs/wal\"\n)\n\nconst (\n\tfileLockName       = \"FLOCK\"\n\tdataFileNameSuffix = \".SEG\"\n\thintFileNameSuffix = \".HINT\"\n\tmergeFinNameSuffix = \".MERGEFIN\"\n)\n\n// DB represents a ROSEDB database instance.\n// It is built on the bitcask model, which is a log-structured storage.\n// It uses WAL to write data, and uses an in-memory index to store the key\n// and the position of the data in the WAL,\n// the index will be rebuilt when the database is opened.\n//\n// The main advantage of ROSEDB is that it is very fast to write, read, and delete data.\n// Because it only needs one disk IO to complete a single operation.\n//\n// But since we should store all keys and their positions(index) in memory,\n// our total data size is limited by the memory size.\n//\n// So if your memory can almost hold all the keys, ROSEDB is the perfect storage engine for you.\ntype DB struct {\n\tdataFiles        *wal.WAL // data files are a sets of segment files in WAL.\n\thintFile         *wal.WAL // hint file is used to store the key and the position for fast startup.\n\tindex            index.Indexer\n\toptions          Options\n\tfileLock         *flock.Flock\n\tmu               sync.RWMutex\n\tclosed           bool\n\tmergeRunning     uint32 // indicate if the database is merging\n\tbatchPool        sync.Pool\n\trecordPool       sync.Pool\n\tencodeHeader     []byte\n\twatchCh          chan *Event // user consume channel for watch events\n\twatcher          *Watcher\n\texpiredCursorKey []byte     // the location to which DeleteExpiredKeys executes.\n\tcronScheduler    *cron.Cron // cron scheduler for auto merge task\n}\n\n// Stat represents the statistics of the database.\ntype Stat struct {\n\t// Total number of keys\n\tKeysNum int\n\t// Total disk size of database directory\n\tDiskSize int64\n}\n\n// Open a database with the specified options.\n// If the database directory does not exist, it will be created automatically.\n//\n// Multiple processes can not use the same database directory at the same time,\n// otherwise it will return ErrDatabaseIsUsing.\n//\n// It will open the wal files in the database directory and load the index from them.\n// Return the DB instance, or an error if any.\nfunc Open(options Options) (*DB, error) {\n\t// check options\n\tif err := checkOptions(options); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// create data directory if not exist\n\tif _, err := os.Stat(options.DirPath); err != nil {\n\t\tif err := os.MkdirAll(options.DirPath, os.ModePerm); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\t// create file lock, prevent multiple processes from using the same database directory\n\tfileLock := flock.New(filepath.Join(options.DirPath, fileLockName))\n\thold, err := fileLock.TryLock()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !hold {\n\t\treturn nil, ErrDatabaseIsUsing\n\t}\n\n\t// load merge files if exists\n\tif err = loadMergeFiles(options.DirPath); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// init DB instance\n\tdb := &DB{\n\t\tindex:        index.NewIndexer(),\n\t\toptions:      options,\n\t\tfileLock:     fileLock,\n\t\tbatchPool:    sync.Pool{New: newBatch},\n\t\trecordPool:   sync.Pool{New: newRecord},\n\t\tencodeHeader: make([]byte, maxLogRecordHeaderSize),\n\t}\n\n\t// open data files\n\tif db.dataFiles, err = db.openWalFiles(); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// load index\n\tif err = db.loadIndex(); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// enable watch\n\tif options.WatchQueueSize > 0 {\n\t\tdb.watchCh = make(chan *Event, 100)\n\t\tdb.watcher = NewWatcher(options.WatchQueueSize)\n\t\t// run a goroutine to synchronize event information\n\t\tgo db.watcher.sendEvent(db.watchCh)\n\t}\n\n\t// enable auto merge task\n\tif len(options.AutoMergeCronExpr) > 0 {\n\t\tdb.cronScheduler = cron.New(\n\t\t\tcron.WithParser(\n\t\t\t\tcron.NewParser(cron.SecondOptional | cron.Minute | cron.Hour |\n\t\t\t\t\tcron.Dom | cron.Month | cron.Dow | cron.Descriptor),\n\t\t\t),\n\t\t)\n\t\t_, err = db.cronScheduler.AddFunc(options.AutoMergeCronExpr, func() {\n\t\t\t// maybe we should deal with different errors with different logic, but a background task can't omit its error.\n\t\t\t// after auto merge, we should close and reopen the db.\n\t\t\t_ = db.Merge(true)\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tdb.cronScheduler.Start()\n\t}\n\n\treturn db, nil\n}\n\nfunc (db *DB) openWalFiles() (*wal.WAL, error) {\n\t// open data files from WAL\n\twalFiles, err := wal.Open(wal.Options{\n\t\tDirPath:        db.options.DirPath,\n\t\tSegmentSize:    db.options.SegmentSize,\n\t\tSegmentFileExt: dataFileNameSuffix,\n\t\tSync:           db.options.Sync,\n\t\tBytesPerSync:   db.options.BytesPerSync,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn walFiles, nil\n}\n\nfunc (db *DB) loadIndex() error {\n\t// load index frm hint file\n\tif err := db.loadIndexFromHintFile(); err != nil {\n\t\treturn err\n\t}\n\t// load index from data files\n\tif err := db.loadIndexFromWAL(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\n// Close the database, close all data files and release file lock.\n// Set the closed flag to true.\n// The DB instance cannot be used after closing.\nfunc (db *DB) Close() error {\n\tdb.mu.Lock()\n\tdefer db.mu.Unlock()\n\n\tif err := db.closeFiles(); err != nil {\n\t\treturn err\n\t}\n\n\t// release file lock\n\tif err := db.fileLock.Unlock(); err != nil {\n\t\treturn err\n\t}\n\n\t// close watch channel\n\tif db.options.WatchQueueSize > 0 {\n\t\tclose(db.watchCh)\n\t}\n\n\t// close auto merge cron scheduler\n\tif db.cronScheduler != nil {\n\t\tdb.cronScheduler.Stop()\n\t}\n\n\tdb.closed = true\n\treturn nil\n}\n\n// closeFiles close all data files and hint file\nfunc (db *DB) closeFiles() error {\n\t// close wal\n\tif err := db.dataFiles.Close(); err != nil {\n\t\treturn err\n\t}\n\t// close hint file if exists\n\tif db.hintFile != nil {\n\t\tif err := db.hintFile.Close(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// Sync all data files to the underlying storage.\nfunc (db *DB) Sync() error {\n\tdb.mu.Lock()\n\tdefer db.mu.Unlock()\n\n\treturn db.dataFiles.Sync()\n}\n\n// Stat returns the statistics of the database.\nfunc (db *DB) Stat() *Stat {\n\tdb.mu.Lock()\n\tdefer db.mu.Unlock()\n\n\tdiskSize, err := utils.DirSize(db.options.DirPath)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"rosedb: get database directory size error: %v\", err))\n\t}\n\n\treturn &Stat{\n\t\tKeysNum:  db.index.Size(),\n\t\tDiskSize: diskSize,\n\t}\n}\n\n// Put a key-value pair into the database.\n// Actually, it will open a new batch and commit it.\n// You can think the batch has only one Put operation.\nfunc (db *DB) Put(key []byte, value []byte) error {\n\tbatch := db.batchPool.Get().(*Batch)\n\tdefer func() {\n\t\tbatch.reset()\n\t\tdb.batchPool.Put(batch)\n\t}()\n\t// This is a single put operation, we can set Sync to false.\n\t// Because the data will be written to the WAL,\n\t// and the WAL file will be synced to disk according to the DB options.\n\tbatch.init(false, false, db)\n\tif err := batch.Put(key, value); err != nil {\n\t\t_ = batch.Rollback()\n\t\treturn err\n\t}\n\treturn batch.Commit()\n}\n\n// PutWithTTL a key-value pair into the database, with a ttl.\n// Actually, it will open a new batch and commit it.\n// You can think the batch has only one PutWithTTL operation.\nfunc (db *DB) PutWithTTL(key []byte, value []byte, ttl time.Duration) error {\n\tbatch := db.batchPool.Get().(*Batch)\n\tdefer func() {\n\t\tbatch.reset()\n\t\tdb.batchPool.Put(batch)\n\t}()\n\t// This is a single put operation, we can set Sync to false.\n\t// Because the data will be written to the WAL,\n\t// and the WAL file will be synced to disk according to the DB options.\n\tbatch.init(false, false, db)\n\tif err := batch.PutWithTTL(key, value, ttl); err != nil {\n\t\t_ = batch.Rollback()\n\t\treturn err\n\t}\n\treturn batch.Commit()\n}\n\n// Get the value of the specified key from the database.\n// Actually, it will open a new batch and commit it.\n// You can think the batch has only one Get operation.\nfunc (db *DB) Get(key []byte) ([]byte, error) {\n\tbatch := db.batchPool.Get().(*Batch)\n\tbatch.init(true, false, db)\n\tdefer func() {\n\t\t_ = batch.Commit()\n\t\tbatch.reset()\n\t\tdb.batchPool.Put(batch)\n\t}()\n\treturn batch.Get(key)\n}\n\n// Delete the specified key from the database.\n// Actually, it will open a new batch and commit it.\n// You can think the batch has only one Delete operation.\nfunc (db *DB) Delete(key []byte) error {\n\tbatch := db.batchPool.Get().(*Batch)\n\tdefer func() {\n\t\tbatch.reset()\n\t\tdb.batchPool.Put(batch)\n\t}()\n\t// This is a single delete operation, we can set Sync to false.\n\t// Because the data will be written to the WAL,\n\t// and the WAL file will be synced to disk according to the DB options.\n\tbatch.init(false, false, db)\n\tif err := batch.Delete(key); err != nil {\n\t\t_ = batch.Rollback()\n\t\treturn err\n\t}\n\treturn batch.Commit()\n}\n\n// Exist checks if the specified key exists in the database.\n// Actually, it will open a new batch and commit it.\n// You can think the batch has only one Exist operation.\nfunc (db *DB) Exist(key []byte) (bool, error) {\n\tbatch := db.batchPool.Get().(*Batch)\n\tbatch.init(true, false, db)\n\tdefer func() {\n\t\t_ = batch.Commit()\n\t\tbatch.reset()\n\t\tdb.batchPool.Put(batch)\n\t}()\n\treturn batch.Exist(key)\n}\n\n// Expire sets the ttl of the key.\nfunc (db *DB) Expire(key []byte, ttl time.Duration) error {\n\tbatch := db.batchPool.Get().(*Batch)\n\tdefer func() {\n\t\tbatch.reset()\n\t\tdb.batchPool.Put(batch)\n\t}()\n\t// This is a single expire operation, we can set Sync to false.\n\t// Because the data will be written to the WAL,\n\t// and the WAL file will be synced to disk according to the DB options.\n\tbatch.init(false, false, db)\n\tif err := batch.Expire(key, ttl); err != nil {\n\t\t_ = batch.Rollback()\n\t\treturn err\n\t}\n\treturn batch.Commit()\n}\n\n// TTL get the ttl of the key.\nfunc (db *DB) TTL(key []byte) (time.Duration, error) {\n\tbatch := db.batchPool.Get().(*Batch)\n\tbatch.init(true, false, db)\n\tdefer func() {\n\t\t_ = batch.Commit()\n\t\tbatch.reset()\n\t\tdb.batchPool.Put(batch)\n\t}()\n\treturn batch.TTL(key)\n}\n\n// Persist removes the ttl of the key.\n// If the key does not exist or expired, it will return ErrKeyNotFound.\nfunc (db *DB) Persist(key []byte) error {\n\tbatch := db.batchPool.Get().(*Batch)\n\tdefer func() {\n\t\tbatch.reset()\n\t\tdb.batchPool.Put(batch)\n\t}()\n\t// This is a single persist operation, we can set Sync to false.\n\t// Because the data will be written to the WAL,\n\t// and the WAL file will be synced to disk according to the DB options.\n\tbatch.init(false, false, db)\n\tif err := batch.Persist(key); err != nil {\n\t\t_ = batch.Rollback()\n\t\treturn err\n\t}\n\treturn batch.Commit()\n}\n\nfunc (db *DB) Watch() (<-chan *Event, error) {\n\tif db.options.WatchQueueSize <= 0 {\n\t\treturn nil, ErrWatchDisabled\n\t}\n\treturn db.watchCh, nil\n}\n\n// Ascend calls handleFn for each key/value pair in the db in ascending order.\nfunc (db *DB) Ascend(handleFn func(k []byte, v []byte) (bool, error)) {\n\tdb.mu.RLock()\n\tdefer db.mu.RUnlock()\n\n\tdb.index.Ascend(func(key []byte, pos *wal.ChunkPosition) (bool, error) {\n\t\tchunk, err := db.dataFiles.Read(pos)\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\tif value := db.checkValue(chunk); value != nil {\n\t\t\treturn handleFn(key, value)\n\t\t}\n\t\treturn true, nil\n\t})\n}\n\n// AscendRange calls handleFn for each key/value pair in the db within the range [startKey, endKey] in ascending order.\nfunc (db *DB) AscendRange(startKey, endKey []byte, handleFn func(k []byte, v []byte) (bool, error)) {\n\tdb.mu.RLock()\n\tdefer db.mu.RUnlock()\n\n\tdb.index.AscendRange(startKey, endKey, func(key []byte, pos *wal.ChunkPosition) (bool, error) {\n\t\tchunk, err := db.dataFiles.Read(pos)\n\t\tif err != nil {\n\t\t\treturn false, nil\n\t\t}\n\t\tif value := db.checkValue(chunk); value != nil {\n\t\t\treturn handleFn(key, value)\n\t\t}\n\t\treturn true, nil\n\t})\n}\n\n// AscendGreaterOrEqual calls handleFn for each key/value pair in the db with keys greater than or equal to the given key.\nfunc (db *DB) AscendGreaterOrEqual(key []byte, handleFn func(k []byte, v []byte) (bool, error)) {\n\tdb.mu.RLock()\n\tdefer db.mu.RUnlock()\n\n\tdb.index.AscendGreaterOrEqual(key, func(key []byte, pos *wal.ChunkPosition) (bool, error) {\n\t\tchunk, err := db.dataFiles.Read(pos)\n\t\tif err != nil {\n\t\t\treturn false, nil\n\t\t}\n\t\tif value := db.checkValue(chunk); value != nil {\n\t\t\treturn handleFn(key, value)\n\t\t}\n\t\treturn true, nil\n\t})\n}\n\n// AscendKeys calls handleFn for each key in the db in ascending order.\n// Since our expiry time is stored in the value, if you want to filter expired keys,\n// you need to set parameter filterExpired to true. But the performance will be affected.\n// Because we need to read the value of each key to determine if it is expired.\nfunc (db *DB) AscendKeys(pattern []byte, filterExpired bool, handleFn func(k []byte) (bool, error)) {\n\tdb.mu.RLock()\n\tdefer db.mu.RUnlock()\n\n\tvar reg *regexp.Regexp\n\tif len(pattern) > 0 {\n\t\treg = regexp.MustCompile(string(pattern))\n\t}\n\n\tdb.index.Ascend(func(key []byte, pos *wal.ChunkPosition) (bool, error) {\n\t\tif reg == nil || reg.Match(key) {\n\t\t\tvar invalid bool\n\t\t\tif filterExpired {\n\t\t\t\tchunk, err := db.dataFiles.Read(pos)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn false, err\n\t\t\t\t}\n\t\t\t\tif value := db.checkValue(chunk); value == nil {\n\t\t\t\t\tinvalid = true\n\t\t\t\t}\n\t\t\t}\n\t\t\tif invalid {\n\t\t\t\treturn true, nil\n\t\t\t}\n\t\t\treturn handleFn(key)\n\t\t}\n\t\treturn true, nil\n\t})\n}\n\n// Descend calls handleFn for each key/value pair in the db in descending order.\nfunc (db *DB) Descend(handleFn func(k []byte, v []byte) (bool, error)) {\n\tdb.mu.RLock()\n\tdefer db.mu.RUnlock()\n\n\tdb.index.Descend(func(key []byte, pos *wal.ChunkPosition) (bool, error) {\n\t\tchunk, err := db.dataFiles.Read(pos)\n\t\tif err != nil {\n\t\t\treturn false, nil\n\t\t}\n\t\tif value := db.checkValue(chunk); value != nil {\n\t\t\treturn handleFn(key, value)\n\t\t}\n\t\treturn true, nil\n\t})\n}\n\n// DescendRange calls handleFn for each key/value pair in the db within the range [startKey, endKey] in descending order.\nfunc (db *DB) DescendRange(startKey, endKey []byte, handleFn func(k []byte, v []byte) (bool, error)) {\n\tdb.mu.RLock()\n\tdefer db.mu.RUnlock()\n\n\tdb.index.DescendRange(startKey, endKey, func(key []byte, pos *wal.ChunkPosition) (bool, error) {\n\t\tchunk, err := db.dataFiles.Read(pos)\n\t\tif err != nil {\n\t\t\treturn false, nil\n\t\t}\n\t\tif value := db.checkValue(chunk); value != nil {\n\t\t\treturn handleFn(key, value)\n\t\t}\n\t\treturn true, nil\n\t})\n}\n\n// DescendLessOrEqual calls handleFn for each key/value pair in the db with keys less than or equal to the given key.\nfunc (db *DB) DescendLessOrEqual(key []byte, handleFn func(k []byte, v []byte) (bool, error)) {\n\tdb.mu.RLock()\n\tdefer db.mu.RUnlock()\n\n\tdb.index.DescendLessOrEqual(key, func(key []byte, pos *wal.ChunkPosition) (bool, error) {\n\t\tchunk, err := db.dataFiles.Read(pos)\n\t\tif err != nil {\n\t\t\treturn false, nil\n\t\t}\n\t\tif value := db.checkValue(chunk); value != nil {\n\t\t\treturn handleFn(key, value)\n\t\t}\n\t\treturn true, nil\n\t})\n}\n\n// DescendKeys calls handleFn for each key in the db in descending order.\n// Since our expiry time is stored in the value, if you want to filter expired keys,\n// you need to set parameter filterExpired to true. But the performance will be affected.\n// Because we need to read the value of each key to determine if it is expired.\nfunc (db *DB) DescendKeys(pattern []byte, filterExpired bool, handleFn func(k []byte) (bool, error)) {\n\tdb.mu.RLock()\n\tdefer db.mu.RUnlock()\n\n\tvar reg *regexp.Regexp\n\tif len(pattern) > 0 {\n\t\treg = regexp.MustCompile(string(pattern))\n\t}\n\n\tdb.index.Descend(func(key []byte, pos *wal.ChunkPosition) (bool, error) {\n\t\tif reg == nil || reg.Match(key) {\n\t\t\tvar invalid bool\n\t\t\tif filterExpired {\n\t\t\t\tchunk, err := db.dataFiles.Read(pos)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn false, err\n\t\t\t\t}\n\t\t\t\tif value := db.checkValue(chunk); value == nil {\n\t\t\t\t\tinvalid = true\n\t\t\t\t}\n\t\t\t}\n\t\t\tif invalid {\n\t\t\t\treturn true, nil\n\t\t\t}\n\t\t\treturn handleFn(key)\n\t\t}\n\t\treturn true, nil\n\t})\n}\n\nfunc (db *DB) checkValue(chunk []byte) []byte {\n\trecord := decodeLogRecord(chunk)\n\tnow := time.Now().UnixNano()\n\tif record.Type != LogRecordDeleted && !record.IsExpired(now) {\n\t\treturn record.Value\n\t}\n\treturn nil\n}\n\nfunc checkOptions(options Options) error {\n\tif options.DirPath == \"\" {\n\t\treturn errors.New(\"database dir path is empty\")\n\t}\n\tif options.SegmentSize <= 0 {\n\t\treturn errors.New(\"database data file size must be greater than 0\")\n\t}\n\n\tif len(options.AutoMergeCronExpr) > 0 {\n\t\tif _, err := cron.NewParser(cron.SecondOptional | cron.Minute | cron.Hour | cron.Dom | cron.Month | cron.Dow | cron.Descriptor).\n\t\t\tParse(options.AutoMergeCronExpr); err != nil {\n\t\t\treturn fmt.Errorf(\"database auto merge cron expression is invalid, err: %s\", err)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// loadIndexFromWAL loads index from WAL.\n// It will iterate over all the WAL files and read data\n// from them to rebuild the index.\nfunc (db *DB) loadIndexFromWAL() error {\n\tmergeFinSegmentId, err := getMergeFinSegmentId(db.options.DirPath)\n\tif err != nil {\n\t\treturn err\n\t}\n\tindexRecords := make(map[uint64][]*IndexRecord)\n\tnow := time.Now().UnixNano()\n\t// get a reader for WAL\n\treader := db.dataFiles.NewReader()\n\tdb.dataFiles.SetIsStartupTraversal(true)\n\tfor {\n\t\t// if the current segment id is less than the mergeFinSegmentId,\n\t\t// we can skip this segment because it has been merged,\n\t\t// and we can load index from the hint file directly.\n\t\tif reader.CurrentSegmentId() <= mergeFinSegmentId {\n\t\t\treader.SkipCurrentSegment()\n\t\t\tcontinue\n\t\t}\n\n\t\tchunk, position, err := reader.Next()\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\t// decode and get log record\n\t\trecord := decodeLogRecord(chunk)\n\n\t\t// if we get the end of a batch,\n\t\t// all records in this batch are ready to be indexed.\n\t\tif record.Type == LogRecordBatchFinished {\n\t\t\tbatchId, err := snowflake.ParseBytes(record.Key)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tfor _, idxRecord := range indexRecords[uint64(batchId)] {\n\t\t\t\tif idxRecord.recordType == LogRecordNormal {\n\t\t\t\t\tdb.index.Put(idxRecord.key, idxRecord.position)\n\t\t\t\t}\n\t\t\t\tif idxRecord.recordType == LogRecordDeleted {\n\t\t\t\t\tdb.index.Delete(idxRecord.key)\n\t\t\t\t}\n\t\t\t}\n\t\t\t// delete indexRecords according to batchId after indexing\n\t\t\tdelete(indexRecords, uint64(batchId))\n\t\t} else if record.Type == LogRecordNormal && record.BatchId == mergeFinishedBatchID {\n\t\t\t// if the record is a normal record and the batch id is 0,\n\t\t\t// it means that the record is involved in the merge operation.\n\t\t\t// so put the record into index directly.\n\t\t\tdb.index.Put(record.Key, position)\n\t\t} else {\n\t\t\t// expired records should not be indexed\n\t\t\tif record.IsExpired(now) {\n\t\t\t\tdb.index.Delete(record.Key)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\t// put the record into the temporary indexRecords\n\t\t\tindexRecords[record.BatchId] = append(indexRecords[record.BatchId],\n\t\t\t\t&IndexRecord{\n\t\t\t\t\tkey:        record.Key,\n\t\t\t\t\trecordType: record.Type,\n\t\t\t\t\tposition:   position,\n\t\t\t\t})\n\t\t}\n\t}\n\tdb.dataFiles.SetIsStartupTraversal(false)\n\treturn nil\n}\n\n// DeleteExpiredKeys scan the entire index in ascending order to delete expired keys.\n// It is a time-consuming operation, so we need to specify a timeout\n// to prevent the DB from being unavailable for a long time.\nfunc (db *DB) DeleteExpiredKeys(timeout time.Duration) error {\n\t// set timeout\n\tctx, cancel := context.WithTimeout(context.Background(), timeout)\n\tdefer cancel()\n\tdone := make(chan struct{}, 1)\n\n\tvar innerErr error\n\tnow := time.Now().UnixNano()\n\tgo func(ctx context.Context) {\n\t\tdb.mu.Lock()\n\t\tdefer db.mu.Unlock()\n\t\tfor {\n\t\t\t// select 100 keys from the db.index\n\t\t\tpositions := make([]*wal.ChunkPosition, 0, 100)\n\t\t\tdb.index.AscendGreaterOrEqual(db.expiredCursorKey, func(k []byte, pos *wal.ChunkPosition) (bool, error) {\n\t\t\t\tpositions = append(positions, pos)\n\t\t\t\tif len(positions) >= 100 {\n\t\t\t\t\treturn false, nil\n\t\t\t\t}\n\t\t\t\treturn true, nil\n\t\t\t})\n\n\t\t\t// If keys in the db.index has been traversed, len(positions) will be 0.\n\t\t\tif len(positions) == 0 {\n\t\t\t\tdb.expiredCursorKey = nil\n\t\t\t\tdone <- struct{}{}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// delete from index if the key is expired.\n\t\t\tfor _, pos := range positions {\n\t\t\t\tchunk, err := db.dataFiles.Read(pos)\n\t\t\t\tif err != nil {\n\t\t\t\t\tinnerErr = err\n\t\t\t\t\tdone <- struct{}{}\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\trecord := decodeLogRecord(chunk)\n\t\t\t\tif record.IsExpired(now) {\n\t\t\t\t\tdb.index.Delete(record.Key)\n\t\t\t\t}\n\t\t\t\tdb.expiredCursorKey = record.Key\n\t\t\t}\n\t\t}\n\t}(ctx)\n\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn innerErr\n\tcase <-done:\n\t\treturn innerErr\n\t}\n}\n"
        },
        {
          "name": "db_test.go",
          "type": "blob",
          "size": 19.6708984375,
          "content": "package rosedb\n\nimport (\n\t\"errors\"\n\t\"io\"\n\t\"math/rand\"\n\t\"os\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/rosedblabs/rosedb/v2/utils\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestDB_Put_Normal(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tfor i := 0; i < 100; i++ {\n\t\terr := db.Put(utils.GetTestKey(rand.Int()), utils.RandomValue(128))\n\t\tassert.Nil(t, err)\n\t\terr = db.Put(utils.GetTestKey(rand.Int()), utils.RandomValue(KB))\n\t\tassert.Nil(t, err)\n\t\terr = db.Put(utils.GetTestKey(rand.Int()), utils.RandomValue(5*KB))\n\t\tassert.Nil(t, err)\n\t}\n\n\t// reopen\n\terr = db.Close()\n\tassert.Nil(t, err)\n\tdb2, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer func() {\n\t\t_ = db2.Close()\n\t}()\n\tstat := db2.Stat()\n\tassert.Equal(t, 300, stat.KeysNum)\n}\n\nfunc TestDB_Get_Normal(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\t// not exist\n\tval1, err := db.Get([]byte(\"not-exist\"))\n\tassert.Nil(t, val1)\n\tassert.Equal(t, ErrKeyNotFound, err)\n\n\tgenerateData(t, db, 1, 100, 128)\n\tfor i := 1; i < 100; i++ {\n\t\tval, err := db.Get(utils.GetTestKey(i))\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, len(val), len(utils.RandomValue(128)))\n\t}\n\tgenerateData(t, db, 200, 300, KB)\n\tfor i := 200; i < 300; i++ {\n\t\tval, err := db.Get(utils.GetTestKey(i))\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, len(val), len(utils.RandomValue(KB)))\n\t}\n\tgenerateData(t, db, 400, 500, 4*KB)\n\tfor i := 400; i < 500; i++ {\n\t\tval, err := db.Get(utils.GetTestKey(i))\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, len(val), len(utils.RandomValue(4*KB)))\n\t}\n}\n\nfunc TestDB_Close_Sync(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\terr = db.Sync()\n\tassert.Nil(t, err)\n}\n\nfunc TestDB_Concurrent_Put(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\twg := sync.WaitGroup{}\n\tm := sync.Map{}\n\twg.Add(10)\n\tfor i := 0; i < 10; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor i := 0; i < 10000; i++ {\n\t\t\t\tkey := utils.GetTestKey(rand.Int())\n\t\t\t\tm.Store(string(key), struct{}{})\n\t\t\t\te := db.Put(key, utils.RandomValue(128))\n\t\t\t\tassert.Nil(t, e)\n\t\t\t}\n\t\t}()\n\t}\n\twg.Wait()\n\n\tvar count int\n\tm.Range(func(key, value any) bool {\n\t\tcount++\n\t\treturn true\n\t})\n\tassert.Equal(t, count, db.index.Size())\n}\n\nfunc TestDB_Concurrent_Get(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tfor i := 0; i < 10000; i++ {\n\t\terr = db.Put(utils.GetTestKey(i), utils.RandomValue(128))\n\t\tassert.Nil(t, err)\n\t}\n\tfor i := 10000; i < 20000; i++ {\n\t\terr = db.Put(utils.GetTestKey(i), utils.RandomValue(4096))\n\t\tassert.Nil(t, err)\n\t}\n\n\tvar wg sync.WaitGroup\n\twg.Add(50)\n\tfor i := 0; i < 50; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tdb.Ascend(func(key []byte, value []byte) (bool, error) {\n\t\t\t\tassert.NotNil(t, key)\n\t\t\t\tassert.NotNil(t, value)\n\t\t\t\treturn true, nil\n\t\t\t})\n\t\t}()\n\t}\n\twg.Wait()\n}\n\nfunc TestDB_Ascend(t *testing.T) {\n\t// Create a test database instance\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\t// Insert some test data\n\tdata := []struct {\n\t\tkey   []byte\n\t\tvalue []byte\n\t}{\n\t\t{[]byte(\"key1\"), []byte(\"value1\")},\n\t\t{[]byte(\"key2\"), []byte(\"value2\")},\n\t\t{[]byte(\"key3\"), []byte(\"value3\")},\n\t}\n\n\tfor _, d := range data {\n\t\tif err := db.Put(d.key, d.value); err != nil {\n\t\t\tt.Fatalf(\"Failed to put data: %v\", err)\n\t\t}\n\t}\n\n\t// Test Ascend function\n\tvar result []string\n\tdb.Ascend(func(k []byte, v []byte) (bool, error) {\n\t\tresult = append(result, string(k))\n\t\treturn true, nil // No error here\n\t})\n\n\tif err != nil {\n\t\tt.Errorf(\"Ascend returned an error: %v\", err)\n\t}\n\n\texpected := []string{\"key1\", \"key2\", \"key3\"}\n\tif len(result) != len(expected) {\n\t\tt.Errorf(\"Unexpected number of results. Expected: %v, Got: %v\", expected, result)\n\t} else {\n\t\tfor i, val := range expected {\n\t\t\tif result[i] != val {\n\t\t\t\tt.Errorf(\"Unexpected result at index %d. Expected: %v, Got: %v\", i, val, result[i])\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc TestDB_Descend(t *testing.T) {\n\t// Create a test database instance\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\t// Insert some test data\n\tdata := []struct {\n\t\tkey   []byte\n\t\tvalue []byte\n\t}{\n\t\t{[]byte(\"key1\"), []byte(\"value1\")},\n\t\t{[]byte(\"key2\"), []byte(\"value2\")},\n\t\t{[]byte(\"key3\"), []byte(\"value3\")},\n\t}\n\n\tfor _, d := range data {\n\t\tif err := db.Put(d.key, d.value); err != nil {\n\t\t\tt.Fatalf(\"Failed to put data: %v\", err)\n\t\t}\n\t}\n\n\t// Test Descend function\n\tvar result []string\n\tdb.Descend(func(k []byte, v []byte) (bool, error) {\n\t\tresult = append(result, string(k))\n\t\treturn true, nil\n\t})\n\n\tif err != nil {\n\t\tt.Errorf(\"Descend returned an error: %v\", err)\n\t}\n\n\texpected := []string{\"key3\", \"key2\", \"key1\"}\n\tif len(result) != len(expected) {\n\t\tt.Errorf(\"Unexpected number of results. Expected: %v, Got: %v\", expected, result)\n\t} else {\n\t\tfor i, val := range expected {\n\t\t\tif result[i] != val {\n\t\t\t\tt.Errorf(\"Unexpected result at index %d. Expected: %v, Got: %v\", i, val, result[i])\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc TestDB_AscendRange(t *testing.T) {\n\t// Create a test database instance\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\t// Insert some test data\n\tdata := []struct {\n\t\tkey   []byte\n\t\tvalue []byte\n\t}{\n\t\t{[]byte(\"apple\"), []byte(\"value1\")},\n\t\t{[]byte(\"banana\"), []byte(\"value2\")},\n\t\t{[]byte(\"cherry\"), []byte(\"value3\")},\n\t\t{[]byte(\"date\"), []byte(\"value4\")},\n\t\t{[]byte(\"grape\"), []byte(\"value5\")},\n\t\t{[]byte(\"kiwi\"), []byte(\"value6\")},\n\t}\n\n\tfor _, d := range data {\n\t\tif err := db.Put(d.key, d.value); err != nil {\n\t\t\tt.Fatalf(\"Failed to put data: %v\", err)\n\t\t}\n\t}\n\n\t// Test AscendRange\n\tvar resultAscendRange []string\n\tdb.AscendRange([]byte(\"banana\"), []byte(\"grape\"), func(k []byte, v []byte) (bool, error) {\n\t\tresultAscendRange = append(resultAscendRange, string(k))\n\t\treturn true, nil\n\t})\n\tassert.Equal(t, []string{\"banana\", \"cherry\", \"date\"}, resultAscendRange)\n}\n\nfunc TestDB_DescendRange(t *testing.T) {\n\t// Create a test database instance\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\t// Insert some test data\n\tdata := []struct {\n\t\tkey   []byte\n\t\tvalue []byte\n\t}{\n\t\t{[]byte(\"apple\"), []byte(\"value1\")},\n\t\t{[]byte(\"banana\"), []byte(\"value2\")},\n\t\t{[]byte(\"cherry\"), []byte(\"value3\")},\n\t\t{[]byte(\"date\"), []byte(\"value4\")},\n\t\t{[]byte(\"grape\"), []byte(\"value5\")},\n\t\t{[]byte(\"kiwi\"), []byte(\"value6\")},\n\t}\n\n\tfor _, d := range data {\n\t\tif err := db.Put(d.key, d.value); err != nil {\n\t\t\tt.Fatalf(\"Failed to put data: %v\", err)\n\t\t}\n\t}\n\n\t// Test DescendRange\n\tvar resultDescendRange []string\n\tdb.DescendRange([]byte(\"grape\"), []byte(\"cherry\"), func(k []byte, v []byte) (bool, error) {\n\t\tresultDescendRange = append(resultDescendRange, string(k))\n\t\treturn true, nil\n\t})\n\tassert.Equal(t, []string{\"grape\", \"date\"}, resultDescendRange)\n}\n\nfunc TestDB_AscendGreaterOrEqual(t *testing.T) {\n\t// Create a test database instance\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\t// Insert some test data\n\tdata := []struct {\n\t\tkey   []byte\n\t\tvalue []byte\n\t}{\n\t\t{[]byte(\"apple\"), []byte(\"value1\")},\n\t\t{[]byte(\"banana\"), []byte(\"value2\")},\n\t\t{[]byte(\"cherry\"), []byte(\"value3\")},\n\t\t{[]byte(\"date\"), []byte(\"value4\")},\n\t\t{[]byte(\"grape\"), []byte(\"value5\")},\n\t\t{[]byte(\"kiwi\"), []byte(\"value6\")},\n\t}\n\n\tfor _, d := range data {\n\t\tif err := db.Put(d.key, d.value); err != nil {\n\t\t\tt.Fatalf(\"Failed to put data: %v\", err)\n\t\t}\n\t}\n\n\t// Test AscendGreaterOrEqual\n\tvar resultAscendGreaterOrEqual []string\n\tdb.AscendGreaterOrEqual([]byte(\"date\"), func(k []byte, v []byte) (bool, error) {\n\t\tresultAscendGreaterOrEqual = append(resultAscendGreaterOrEqual, string(k))\n\t\treturn true, nil\n\t})\n\tassert.Equal(t, []string{\"date\", \"grape\", \"kiwi\"}, resultAscendGreaterOrEqual)\n}\n\nfunc TestDB_DescendLessOrEqual(t *testing.T) {\n\t// Create a test database instance\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\t// Insert some test data\n\tdata := []struct {\n\t\tkey   []byte\n\t\tvalue []byte\n\t}{\n\t\t{[]byte(\"apple\"), []byte(\"value1\")},\n\t\t{[]byte(\"banana\"), []byte(\"value2\")},\n\t\t{[]byte(\"cherry\"), []byte(\"value3\")},\n\t\t{[]byte(\"date\"), []byte(\"value4\")},\n\t\t{[]byte(\"grape\"), []byte(\"value5\")},\n\t\t{[]byte(\"kiwi\"), []byte(\"value6\")},\n\t}\n\n\tfor _, d := range data {\n\t\tif err := db.Put(d.key, d.value); err != nil {\n\t\t\tt.Fatalf(\"Failed to put data: %v\", err)\n\t\t}\n\t}\n\n\t// Test DescendLessOrEqual\n\tvar resultDescendLessOrEqual []string\n\tdb.DescendLessOrEqual([]byte(\"grape\"), func(k []byte, v []byte) (bool, error) {\n\t\tresultDescendLessOrEqual = append(resultDescendLessOrEqual, string(k))\n\t\treturn true, nil\n\t})\n\tassert.Equal(t, []string{\"grape\", \"date\", \"cherry\", \"banana\", \"apple\"}, resultDescendLessOrEqual)\n}\n\nfunc TestDB_AscendKeys(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\terr = db.Put([]byte(\"aacd\"), utils.RandomValue(10))\n\tassert.Nil(t, err)\n\n\tvalidate := func(target [][]byte, pattern []byte) {\n\t\tvar keys [][]byte\n\t\tdb.AscendKeys(pattern, false, func(k []byte) (bool, error) {\n\t\t\tkeys = append(keys, k)\n\t\t\treturn true, nil\n\t\t})\n\t\tassert.Equal(t, keys, target)\n\t}\n\n\tvalidate([][]byte{[]byte(\"aacd\")}, nil)\n\n\terr = db.Put([]byte(\"bbde\"), utils.RandomValue(10))\n\tassert.Nil(t, err)\n\terr = db.Put([]byte(\"cdea\"), utils.RandomValue(10))\n\tassert.Nil(t, err)\n\terr = db.Put([]byte(\"bcae\"), utils.RandomValue(10))\n\tassert.Nil(t, err)\n\n\tvalidate([][]byte{[]byte(\"aacd\"), []byte(\"bbde\"), []byte(\"bcae\"), []byte(\"cdea\")}, nil)\n}\n\nfunc TestDB_AscendKeysExpired(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tvalidate := func(target [][]byte, pattern []byte) {\n\t\tvar keys [][]byte\n\t\tdb.AscendKeys(pattern, true, func(k []byte) (bool, error) {\n\t\t\tkeys = append(keys, k)\n\t\t\treturn true, nil\n\t\t})\n\t\tassert.Equal(t, keys, target)\n\t}\n\n\terr = db.PutWithTTL([]byte(\"bbde\"), utils.RandomValue(10), time.Millisecond*500)\n\tassert.Nil(t, err)\n\terr = db.Put([]byte(\"cdea\"), utils.RandomValue(10))\n\tassert.Nil(t, err)\n\terr = db.Put([]byte(\"bcae\"), utils.RandomValue(10))\n\tassert.Nil(t, err)\n\ttime.Sleep(time.Millisecond * 600)\n\n\tvalidate([][]byte{[]byte(\"bcae\"), []byte(\"cdea\")}, nil)\n}\n\nfunc TestDB_DescendKeys(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\terr = db.Put([]byte(\"aacd\"), utils.RandomValue(10))\n\tassert.Nil(t, err)\n\n\tvalidate := func(target [][]byte, pattern []byte) {\n\t\tvar keys [][]byte\n\t\tdb.DescendKeys(pattern, false, func(k []byte) (bool, error) {\n\t\t\tkeys = append(keys, k)\n\t\t\treturn true, nil\n\t\t})\n\t\tassert.Equal(t, keys, target)\n\t}\n\n\tvalidate([][]byte{[]byte(\"aacd\")}, nil)\n\n\terr = db.Put([]byte(\"bbde\"), utils.RandomValue(10))\n\tassert.Nil(t, err)\n\terr = db.Put([]byte(\"cdea\"), utils.RandomValue(10))\n\tassert.Nil(t, err)\n\terr = db.Put([]byte(\"bcae\"), utils.RandomValue(10))\n\tassert.Nil(t, err)\n\n\tvalidate([][]byte{[]byte(\"cdea\"), []byte(\"bcae\"), []byte(\"bbde\"), []byte(\"aacd\")}, nil)\n}\n\nfunc TestDB_DescendKeysExpired(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tvalidate := func(target [][]byte, pattern []byte) {\n\t\tvar keys [][]byte\n\t\tdb.DescendKeys(pattern, true, func(k []byte) (bool, error) {\n\t\t\tkeys = append(keys, k)\n\t\t\treturn true, nil\n\t\t})\n\t\tassert.Equal(t, keys, target)\n\t}\n\n\terr = db.Put([]byte(\"bbde\"), utils.RandomValue(10))\n\tassert.Nil(t, err)\n\terr = db.PutWithTTL([]byte(\"cdea\"), utils.RandomValue(10), time.Millisecond*500)\n\tassert.Nil(t, err)\n\terr = db.PutWithTTL([]byte(\"bcae\"), utils.RandomValue(10), time.Millisecond*500)\n\tassert.Nil(t, err)\n\n\ttime.Sleep(time.Millisecond * 600)\n\n\tvalidate([][]byte{[]byte(\"bbde\")}, nil)\n}\n\nfunc TestDB_PutWithTTL(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\terr = db.PutWithTTL(utils.GetTestKey(1), utils.RandomValue(128), time.Millisecond*100)\n\tassert.Nil(t, err)\n\tval1, err := db.Get(utils.GetTestKey(1))\n\tassert.Nil(t, err)\n\tassert.NotNil(t, val1)\n\ttime.Sleep(time.Millisecond * 200)\n\tval2, err := db.Get(utils.GetTestKey(1))\n\tassert.Equal(t, err, ErrKeyNotFound)\n\tassert.Nil(t, val2)\n\n\terr = db.PutWithTTL(utils.GetTestKey(2), utils.RandomValue(128), time.Millisecond*200)\n\tassert.Nil(t, err)\n\t// rewrite\n\terr = db.Put(utils.GetTestKey(2), utils.RandomValue(128))\n\tassert.Nil(t, err)\n\ttime.Sleep(time.Millisecond * 200)\n\tval3, err := db.Get(utils.GetTestKey(2))\n\tassert.Nil(t, err)\n\tassert.NotNil(t, val3)\n\n\terr = db.Close()\n\tassert.Nil(t, err)\n\n\tdb2, err := Open(options)\n\tassert.Nil(t, err)\n\n\tval4, err := db2.Get(utils.GetTestKey(1))\n\tassert.Equal(t, err, ErrKeyNotFound)\n\tassert.Nil(t, val4)\n\n\tval5, err := db2.Get(utils.GetTestKey(2))\n\tassert.Nil(t, err)\n\tassert.NotNil(t, val5)\n\n\t_ = db2.Close()\n}\n\nfunc TestDB_RePutWithTTL(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\terr = db.Put(utils.GetTestKey(10), utils.RandomValue(10))\n\tassert.Nil(t, err)\n\terr = db.PutWithTTL(utils.GetTestKey(10), utils.RandomValue(10), time.Millisecond*100)\n\tassert.Nil(t, err)\n\ttime.Sleep(time.Second * 1) // wait for expired\n\n\tval1, err := db.Get(utils.GetTestKey(10))\n\tassert.Equal(t, err, ErrKeyNotFound)\n\tassert.Nil(t, val1)\n\n\terr = db.Merge(true)\n\tassert.Nil(t, err)\n\n\tval2, err := db.Get(utils.GetTestKey(10))\n\tassert.Equal(t, err, ErrKeyNotFound)\n\tassert.Nil(t, val2)\n}\n\nfunc TestDB_PutWithTTL_Merge(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\tfor i := 0; i < 100; i++ {\n\t\terr = db.PutWithTTL(utils.GetTestKey(i), utils.RandomValue(10), time.Second*2)\n\t\tassert.Nil(t, err)\n\t}\n\tfor i := 100; i < 150; i++ {\n\t\terr = db.PutWithTTL(utils.GetTestKey(i), utils.RandomValue(10), time.Second*20)\n\t\tassert.Nil(t, err)\n\t}\n\ttime.Sleep(time.Second * 3)\n\n\terr = db.Merge(true)\n\tassert.Nil(t, err)\n\n\tfor i := 0; i < 100; i++ {\n\t\tval, err := db.Get(utils.GetTestKey(i))\n\t\tassert.Nil(t, val)\n\t\tassert.Equal(t, err, ErrKeyNotFound)\n\t}\n\tfor i := 100; i < 150; i++ {\n\t\tval, err := db.Get(utils.GetTestKey(i))\n\t\tassert.Nil(t, err)\n\t\tassert.NotNil(t, val)\n\t}\n}\n\nfunc TestDB_Expire(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\terr = db.Put(utils.GetTestKey(1), utils.RandomValue(10))\n\tassert.Nil(t, err)\n\n\terr = db.Expire(utils.GetTestKey(1), time.Second*100)\n\tassert.Nil(t, err)\n\ttt1, err := db.TTL(utils.GetTestKey(1))\n\tassert.Nil(t, err)\n\tassert.True(t, tt1.Seconds() > 90)\n\n\terr = db.PutWithTTL(utils.GetTestKey(2), utils.RandomValue(10), time.Second*1)\n\tassert.Nil(t, err)\n\n\ttt2, err := db.TTL(utils.GetTestKey(2))\n\tassert.Nil(t, err)\n\tassert.True(t, tt2.Microseconds() > 500)\n\n\terr = db.Close()\n\tassert.Nil(t, err)\n\n\tdb2, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer func() {\n\t\t_ = db2.Close()\n\t}()\n\n\ttt3, err := db2.TTL(utils.GetTestKey(1))\n\tassert.Nil(t, err)\n\tassert.True(t, tt3.Seconds() > 90)\n\n\ttime.Sleep(time.Second)\n\ttt4, err := db2.TTL(utils.GetTestKey(2))\n\tassert.Equal(t, tt4, time.Duration(-1))\n\tassert.Equal(t, err, ErrKeyNotFound)\n}\n\nfunc TestDB_Expire2(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\t// expire an expired key\n\t_ = db.PutWithTTL(utils.GetTestKey(1), utils.RandomValue(10), time.Second*1)\n\t_ = db.Put(utils.GetTestKey(2), utils.RandomValue(10))\n\terr = db.Expire(utils.GetTestKey(2), time.Second*2)\n\tassert.Nil(t, err)\n\n\ttime.Sleep(time.Second * 2)\n\t_ = db.Close()\n\n\tdb2, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer func() {\n\t\t_ = db2.Close()\n\t}()\n\terr = db2.Expire(utils.GetTestKey(1), time.Second)\n\tassert.Equal(t, err, ErrKeyNotFound)\n\terr = db2.Expire(utils.GetTestKey(2), time.Second)\n\tassert.Equal(t, err, ErrKeyNotFound)\n}\n\nfunc TestDB_DeleteExpiredKeys(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tfor i := 0; i < 100001; i++ {\n\t\terr = db.PutWithTTL(utils.GetTestKey(i), utils.RandomValue(10), time.Second*1)\n\t\tassert.Nil(t, err)\n\t}\n\n\t// wait for key to expire\n\ttime.Sleep(time.Second * 2)\n\n\terr = db.DeleteExpiredKeys(time.Second * 2)\n\tassert.Nil(t, err)\n\tassert.Equal(t, 0, db.Stat().KeysNum)\n\n}\n\nfunc TestDB_Multi_DeleteExpiredKeys(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tfor i := 0; i < 3; i++ {\n\t\tfor i := 0; i < 10000; i++ {\n\t\t\terr = db.Put(utils.GetTestKey(i), utils.RandomValue(10))\n\t\t\tassert.Nil(t, err)\n\t\t}\n\t\tfor i := 10000; i < 100001; i++ {\n\t\t\terr = db.PutWithTTL(utils.GetTestKey(i), utils.RandomValue(10), time.Second*1)\n\t\t\tassert.Nil(t, err)\n\t\t}\n\n\t\t// wait for key to expire\n\t\ttime.Sleep(time.Second * 2)\n\n\t\terr = db.DeleteExpiredKeys(time.Second * 2)\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, 10000, db.Stat().KeysNum)\n\t}\n}\n\nfunc TestDB_Persist(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\t// not exist\n\terr = db.Persist(utils.GetTestKey(1))\n\tassert.Equal(t, err, ErrKeyNotFound)\n\n\terr = db.PutWithTTL(utils.GetTestKey(1), utils.RandomValue(10), time.Second*1)\n\tassert.Nil(t, err)\n\n\t// exist\n\terr = db.Persist(utils.GetTestKey(1))\n\tassert.Nil(t, err)\n\ttime.Sleep(time.Second * 2)\n\t// check ttl\n\tttl, err := db.TTL(utils.GetTestKey(1))\n\tassert.Nil(t, err)\n\tassert.Equal(t, ttl, time.Duration(-1))\n\tval1, err := db.Get(utils.GetTestKey(1))\n\tassert.Nil(t, err)\n\tassert.NotNil(t, val1)\n\n\t// restart\n\terr = db.Close()\n\tassert.Nil(t, err)\n\n\tdb2, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer func() {\n\t\t_ = db2.Close()\n\t}()\n\n\tttl2, err := db2.TTL(utils.GetTestKey(1))\n\tassert.Nil(t, err)\n\tassert.Equal(t, ttl2, time.Duration(-1))\n\tval2, err := db2.Get(utils.GetTestKey(1))\n\tassert.Nil(t, err)\n\tassert.NotNil(t, val2)\n}\n\nfunc TestDB_Invalid_Cron_Expression(t *testing.T) {\n\toptions := DefaultOptions\n\toptions.AutoMergeCronExpr = \"*/1 * * * * * *\"\n\t_, err := Open(options)\n\tassert.NotNil(t, err)\n}\n\nfunc TestDB_Valid_Cron_Expression(t *testing.T) {\n\toptions := DefaultOptions\n\t{\n\t\toptions.AutoMergeCronExpr = \"* */1 * * * *\"\n\t\tdb, err := Open(options)\n\t\tassert.Nil(t, err)\n\t\tdestroyDB(db)\n\t}\n\n\t{\n\t\toptions.AutoMergeCronExpr = \"*/1 * * * *\"\n\t\tdb, err := Open(options)\n\t\tassert.Nil(t, err)\n\t\tdestroyDB(db)\n\t}\n\n\t{\n\t\toptions.AutoMergeCronExpr = \"5 0 * 8 *\"\n\t\tdb, err := Open(options)\n\t\tassert.Nil(t, err)\n\t\tdestroyDB(db)\n\t}\n\n\t{\n\t\toptions.AutoMergeCronExpr = \"*/2 14 1 * *\"\n\t\tdb, err := Open(options)\n\t\tassert.Nil(t, err)\n\t\tdestroyDB(db)\n\t}\n\n\t{\n\t\toptions.AutoMergeCronExpr = \"@hourly\"\n\t\tdb, err := Open(options)\n\t\tassert.Nil(t, err)\n\t\tdestroyDB(db)\n\t}\n}\n\nfunc TestDB_Auto_Merge(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tfor i := 0; i < 2000; i++ {\n\t\tdelKey := utils.GetTestKey(rand.Int())\n\t\terr := db.Put(delKey, utils.RandomValue(128))\n\t\tassert.Nil(t, err)\n\t\terr = db.Put(utils.GetTestKey(rand.Int()), utils.RandomValue(2*KB))\n\t\tassert.Nil(t, err)\n\t\terr = db.Delete(delKey)\n\t\tassert.Nil(t, err)\n\t}\n\n\t{\n\t\treader := db.dataFiles.NewReader()\n\t\tvar keyCnt int\n\t\tfor {\n\t\t\tif _, _, err := reader.Next(); errors.Is(err, io.EOF) {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tkeyCnt++\n\t\t}\n\t\t// each record has one data wal and commit at end of batch with wal\n\t\t// so totally is 2000 * 3 * 2 = 12000\n\t\tassert.Equal(t, 12000, keyCnt)\n\t}\n\n\tmergeDirPath := mergeDirPath(options.DirPath)\n\tif _, err := os.Stat(mergeDirPath); err != nil {\n\t\tassert.True(t, os.IsNotExist(err))\n\t}\n\tassert.NoError(t, db.Close())\n\n\t{\n\t\toptions.AutoMergeCronExpr = \"* * * * * *\" // every second\n\t\tdb2, err := Open(options)\n\t\tassert.Nil(t, err)\n\t\t{\n\t\t\t<-time.After(time.Second * 2)\n\t\t\treader := db2.dataFiles.NewReader()\n\t\t\tvar keyCnt int\n\t\t\tfor {\n\t\t\t\tif _, _, err := reader.Next(); errors.Is(err, io.EOF) {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\tkeyCnt++\n\t\t\t}\n\t\t\t// after merge records are only valid data, so totally is 2000\n\t\t\tassert.Equal(t, 2000, keyCnt)\n\t\t}\n\t\t_ = db2.Close()\n\t}\n}\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "errors.go",
          "type": "blob",
          "size": 0.58984375,
          "content": "package rosedb\n\nimport \"errors\"\n\nvar (\n\tErrKeyIsEmpty      = errors.New(\"the key is empty\")\n\tErrKeyNotFound     = errors.New(\"key not found in database\")\n\tErrDatabaseIsUsing = errors.New(\"the database directory is used by another process\")\n\tErrReadOnlyBatch   = errors.New(\"the batch is read only\")\n\tErrBatchCommitted  = errors.New(\"the batch is committed\")\n\tErrBatchRollbacked = errors.New(\"the batch is rollbacked\")\n\tErrDBClosed        = errors.New(\"the database is closed\")\n\tErrMergeRunning    = errors.New(\"the merge operation is running\")\n\tErrWatchDisabled   = errors.New(\"the watch is disabled\")\n)\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.5966796875,
          "content": "module github.com/rosedblabs/rosedb/v2\n\ngo 1.21\n\nrequire (\n\tgithub.com/google/btree v1.1.2\n\tgithub.com/rosedblabs/wal v1.3.8\n\tgithub.com/valyala/bytebufferpool v1.0.0\n)\n\nrequire (\n\tgithub.com/davecgh/go-spew v1.1.1 // indirect\n\tgithub.com/kr/text v0.2.0 // indirect\n\tgithub.com/pmezard/go-difflib v1.0.0 // indirect\n\tgolang.org/x/sys v0.11.0 // indirect\n\tgopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c // indirect\n\tgopkg.in/yaml.v3 v3.0.1 // indirect\n)\n\nrequire (\n\tgithub.com/bwmarrin/snowflake v0.3.0\n\tgithub.com/gofrs/flock v0.8.1\n\tgithub.com/robfig/cron/v3 v3.0.0\n\tgithub.com/stretchr/testify v1.9.0\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 2.6650390625,
          "content": "github.com/bwmarrin/snowflake v0.3.0 h1:xm67bEhkKh6ij1790JB83OujPR5CzNe8QuQqAgISZN0=\ngithub.com/bwmarrin/snowflake v0.3.0/go.mod h1:NdZxfVWX+oR6y2K0o6qAYv6gIOP9rjG0/E9WsDpxqwE=\ngithub.com/creack/pty v1.1.9/go.mod h1:oKZEueFk5CKHvIhNR5MUki03XCEU+Q6VDXinZuGJ33E=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/gofrs/flock v0.8.1 h1:+gYjHKf32LDeiEEFhQaotPbLuUXjY5ZqxKgXy7n59aw=\ngithub.com/gofrs/flock v0.8.1/go.mod h1:F1TvTiK9OcQqauNUHlbJvyl9Qa1QvF/gOUDKA14jxHU=\ngithub.com/google/btree v1.1.2 h1:xf4v41cLI2Z6FxbKm+8Bu+m8ifhj15JuZ9sa0jZCMUU=\ngithub.com/google/btree v1.1.2/go.mod h1:qOPhT0dTNdNzV6Z/lhRX0YXUafgPLFUh+gZMl761Gm4=\ngithub.com/kr/pretty v0.2.1 h1:Fmg33tUaq4/8ym9TJN1x7sLJnHVwhP33CNkpYV/7rwI=\ngithub.com/kr/pretty v0.2.1/go.mod h1:ipq/a2n7PKx3OHsz4KJII5eveXtPO4qwEXGdVfWzfnI=\ngithub.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=\ngithub.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=\ngithub.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=\ngithub.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/robfig/cron/v3 v3.0.0 h1:kQ6Cb7aHOHTSzNVNEhmp8EcWKLb4CbiMW9h9VyIhO4E=\ngithub.com/robfig/cron/v3 v3.0.0/go.mod h1:eQICP3HwyT7UooqI/z+Ov+PtYAWygg1TEWWzGIFLtro=\ngithub.com/rosedblabs/wal v1.3.8 h1:tErpD9JT/ICiyV3mv5l7qUH6lybn5XF1TbI0e8kvH8M=\ngithub.com/rosedblabs/wal v1.3.8/go.mod h1:DFvhrmTTeiXvn2btXXT2MW9Nvu99PU0g/pKGgh0+T+o=\ngithub.com/stretchr/testify v1.9.0 h1:HtqpIVDClZ4nwg75+f6Lvsy/wHu+3BoSGCbBAcpTsTg=\ngithub.com/stretchr/testify v1.9.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=\ngithub.com/valyala/bytebufferpool v1.0.0 h1:GqA5TC/0021Y/b9FG4Oi9Mr3q7XYx6KllzawFIhcdPw=\ngithub.com/valyala/bytebufferpool v1.0.0/go.mod h1:6bBcMArwyJ5K/AmCkWv1jt77kVWyCJ6HpOuEn7z0Csc=\ngolang.org/x/sys v0.11.0 h1:eG7RXZHdqOJ1i+0lgLgCpSXAp6M3LYlAo6osgSi0xOM=\ngolang.org/x/sys v0.11.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c h1:Hei/4ADfdWqJk1ZMxUNpqntNwaWcugrBjAiHlqqRiVk=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c/go.mod h1:JHkPIbrfpd72SG/EVd6muEfDQjcINNoR0C8j2r3qZ4Q=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\n"
        },
        {
          "name": "index",
          "type": "tree",
          "content": null
        },
        {
          "name": "merge.go",
          "type": "blob",
          "size": 9.9921875,
          "content": "package rosedb\n\nimport (\n\t\"encoding/binary\"\n\t\"fmt\"\n\t\"io\"\n\t\"math\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"github.com/rosedblabs/rosedb/v2/index\"\n\t\"github.com/rosedblabs/wal\"\n\t\"github.com/valyala/bytebufferpool\"\n)\n\nconst (\n\tmergeDirSuffixName   = \"-merge\"\n\tmergeFinishedBatchID = 0\n)\n\n// Merge merges all the data files in the database.\n// It will iterate all the data files, find the valid data,\n// and rewrite the data to the new data file.\n//\n// Merge operation maybe a very time-consuming operation when the database is large.\n// So it is recommended to perform this operation when the database is idle.\n//\n// If reopenAfterDone is true, the original file will be replaced by the merge file,\n// and db's index will be rebuilt after the merge completes.\nfunc (db *DB) Merge(reopenAfterDone bool) error {\n\tif err := db.doMerge(); err != nil {\n\t\treturn err\n\t}\n\tif !reopenAfterDone {\n\t\treturn nil\n\t}\n\n\tdb.mu.Lock()\n\tdefer db.mu.Unlock()\n\n\t// close current files\n\t_ = db.closeFiles()\n\n\t// replace original file\n\terr := loadMergeFiles(db.options.DirPath)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// open data files\n\tif db.dataFiles, err = db.openWalFiles(); err != nil {\n\t\treturn err\n\t}\n\n\t// discard the old index first.\n\tdb.index = index.NewIndexer()\n\t// rebuild index\n\tif err = db.loadIndex(); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nfunc (db *DB) doMerge() error {\n\tdb.mu.Lock()\n\t// check if the database is closed\n\tif db.closed {\n\t\tdb.mu.Unlock()\n\t\treturn ErrDBClosed\n\t}\n\t// check if the data files is empty\n\tif db.dataFiles.IsEmpty() {\n\t\tdb.mu.Unlock()\n\t\treturn nil\n\t}\n\t// check if the merge operation is running\n\tif atomic.LoadUint32(&db.mergeRunning) == 1 {\n\t\tdb.mu.Unlock()\n\t\treturn ErrMergeRunning\n\t}\n\t// set the mergeRunning flag to true\n\tatomic.StoreUint32(&db.mergeRunning, 1)\n\t// set the mergeRunning flag to false when the merge operation is completed\n\tdefer atomic.StoreUint32(&db.mergeRunning, 0)\n\n\tprevActiveSegId := db.dataFiles.ActiveSegmentID()\n\t// rotate the write-ahead log, create a new active segment file.\n\t// so all the older segment files will be merged.\n\tif err := db.dataFiles.OpenNewActiveSegment(); err != nil {\n\t\tdb.mu.Unlock()\n\t\treturn err\n\t}\n\n\t// we can unlock the mutex here, because the write-ahead log files has been rotated,\n\t// and the new active segment file will be used for the subsequent writes.\n\t// Our Merge operation will only read from the older segment files.\n\tdb.mu.Unlock()\n\n\t// open a merge db to write the data to the new data file.\n\t// delete the merge directory if it exists and create a new one.\n\tmergeDB, err := db.openMergeDB()\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer func() {\n\t\t_ = mergeDB.Close()\n\t}()\n\n\tbuf := bytebufferpool.Get()\n\tnow := time.Now().UnixNano()\n\tdefer bytebufferpool.Put(buf)\n\n\t// iterate all the data files, and write the valid data to the new data file.\n\treader := db.dataFiles.NewReaderWithMax(prevActiveSegId)\n\tfor {\n\t\tbuf.Reset()\n\t\tchunk, position, err := reader.Next()\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\trecord := decodeLogRecord(chunk)\n\t\t// Only handle the normal log record, LogRecordDeleted and LogRecordBatchFinished\n\t\t// will be ignored, because they are not valid data.\n\t\tif record.Type == LogRecordNormal && (record.Expire == 0 || record.Expire > now) {\n\t\t\tdb.mu.RLock()\n\t\t\tindexPos := db.index.Get(record.Key)\n\t\t\tdb.mu.RUnlock()\n\t\t\tif indexPos != nil && positionEquals(indexPos, position) {\n\t\t\t\t// clear the batch id of the record,\n\t\t\t\t// all data after merge will be valid data, so the batch id should be 0.\n\t\t\t\trecord.BatchId = mergeFinishedBatchID\n\t\t\t\t// Since the mergeDB will never be used for any read or write operations,\n\t\t\t\t// it is not necessary to update the index.\n\t\t\t\tnewPosition, err := mergeDB.dataFiles.Write(encodeLogRecord(record, mergeDB.encodeHeader, buf))\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\t// And now we should write the new position to the write-ahead log,\n\t\t\t\t// which is so-called HINT FILE in bitcask paper.\n\t\t\t\t// The HINT FILE will be used to rebuild the index quickly when the database is restarted.\n\t\t\t\t_, err = mergeDB.hintFile.Write(encodeHintRecord(record.Key, newPosition))\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// After rewrite all the data, we should add a file to indicate that the merge operation is completed.\n\t// So when we restart the database, we can know that the merge is completed if the file exists,\n\t// otherwise, we will delete the merge directory and redo the merge operation again.\n\tmergeFinFile, err := mergeDB.openMergeFinishedFile()\n\tif err != nil {\n\t\treturn err\n\t}\n\t_, err = mergeFinFile.Write(encodeMergeFinRecord(prevActiveSegId))\n\tif err != nil {\n\t\treturn err\n\t}\n\t// close the merge finished file\n\tif err := mergeFinFile.Close(); err != nil {\n\t\treturn err\n\t}\n\n\t// all done successfully, return nil\n\treturn nil\n}\n\nfunc (db *DB) openMergeDB() (*DB, error) {\n\tmergePath := mergeDirPath(db.options.DirPath)\n\t// delete the merge directory if it exists\n\tif err := os.RemoveAll(mergePath); err != nil {\n\t\treturn nil, err\n\t}\n\toptions := db.options\n\t// we don't need to use the original sync policy,\n\t// because we can sync the data file manually after the merge operation is completed.\n\toptions.Sync, options.BytesPerSync = false, 0\n\toptions.DirPath = mergePath\n\tmergeDB, err := Open(options)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// open the hint files to write the new position of the data.\n\thintFile, err := wal.Open(wal.Options{\n\t\tDirPath: options.DirPath,\n\t\t// we don't need to rotate the hint file, just write all data to a single file.\n\t\tSegmentSize:    math.MaxInt64,\n\t\tSegmentFileExt: hintFileNameSuffix,\n\t\tSync:           false,\n\t\tBytesPerSync:   0,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tmergeDB.hintFile = hintFile\n\treturn mergeDB, nil\n}\n\nfunc mergeDirPath(dirPath string) string {\n\tdir := filepath.Dir(filepath.Clean(dirPath))\n\tbase := filepath.Base(dirPath)\n\treturn filepath.Join(dir, base+mergeDirSuffixName)\n}\n\nfunc (db *DB) openMergeFinishedFile() (*wal.WAL, error) {\n\treturn wal.Open(wal.Options{\n\t\tDirPath:        db.options.DirPath,\n\t\tSegmentSize:    GB,\n\t\tSegmentFileExt: mergeFinNameSuffix,\n\t\tSync:           false,\n\t\tBytesPerSync:   0,\n\t})\n}\n\nfunc positionEquals(a, b *wal.ChunkPosition) bool {\n\treturn a.SegmentId == b.SegmentId &&\n\t\ta.BlockNumber == b.BlockNumber &&\n\t\ta.ChunkOffset == b.ChunkOffset\n}\n\n// loadMergeFiles loads all the merge files, and copy the data to the original data directory.\n// If there is no merge files, or the merge operation is not completed, it will return nil.\nfunc loadMergeFiles(dirPath string) error {\n\t// check if there is a merge directory\n\tmergeDirPath := mergeDirPath(dirPath)\n\tif _, err := os.Stat(mergeDirPath); err != nil {\n\t\t// does not exist, just return.\n\t\tif os.IsNotExist(err) {\n\t\t\treturn nil\n\t\t}\n\t\treturn err\n\t}\n\n\t// remove the merge directory at last\n\tdefer func() {\n\t\t_ = os.RemoveAll(mergeDirPath)\n\t}()\n\n\tcopyFile := func(suffix string, fileId uint32, force bool) {\n\t\tsrcFile := wal.SegmentFileName(mergeDirPath, suffix, fileId)\n\t\tstat, err := os.Stat(srcFile)\n\t\tif os.IsNotExist(err) {\n\t\t\treturn\n\t\t}\n\t\tif err != nil {\n\t\t\tpanic(fmt.Sprintf(\"loadMergeFiles: failed to get src file stat %v\", err))\n\t\t}\n\t\tif !force && stat.Size() == 0 {\n\t\t\treturn\n\t\t}\n\t\tdestFile := wal.SegmentFileName(dirPath, suffix, fileId)\n\t\t_ = os.Rename(srcFile, destFile)\n\t}\n\n\t// get the merge finished segment id\n\tmergeFinSegmentId, err := getMergeFinSegmentId(mergeDirPath)\n\tif err != nil {\n\t\treturn err\n\t}\n\t// now we get the merge finished segment id, so all the segment id less than the merge finished segment id\n\t// should be moved to the original data directory, and the original data files should be deleted.\n\tfor fileId := uint32(1); fileId <= mergeFinSegmentId; fileId++ {\n\t\tdestFile := wal.SegmentFileName(dirPath, dataFileNameSuffix, fileId)\n\t\t// will have bug here if continue, check it later.todo\n\n\t\t// If we call Merge multiple times, some segment files will be deleted earlier, so just skip them.\n\t\t// if _, err = os.Stat(destFile); os.IsNotExist(err) {\n\t\t// \tcontinue\n\t\t// } else if err != nil {\n\t\t// \treturn err\n\t\t// }\n\n\t\t// remove the original data file\n\t\tif _, err = os.Stat(destFile); err == nil {\n\t\t\tif err = os.Remove(destFile); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\t// move the merge data file to the original data directory\n\t\tcopyFile(dataFileNameSuffix, fileId, false)\n\t}\n\n\t// copy MERGEFINISHED and HINT files to the original data directory\n\t// there is only one merge finished file, so the file id is always 1,\n\t// the same as the hint file.\n\tcopyFile(mergeFinNameSuffix, 1, true)\n\tcopyFile(hintFileNameSuffix, 1, true)\n\n\treturn nil\n}\n\nfunc getMergeFinSegmentId(mergePath string) (wal.SegmentID, error) {\n\t// check if the merge operation is completed\n\tmergeFinFile, err := os.Open(wal.SegmentFileName(mergePath, mergeFinNameSuffix, 1))\n\tif err != nil {\n\t\t// if the merge finished file does not exist, it means that the merge operation is not completed.\n\t\t// so we should remove the merge directory and return nil.\n\t\treturn 0, nil\n\t}\n\tdefer func() {\n\t\t_ = mergeFinFile.Close()\n\t}()\n\n\t// Only 4 bytes are needed to store the segment id.\n\t// And the first 7 bytes are chunk header.\n\tmergeFinBuf := make([]byte, 4)\n\tif _, err := mergeFinFile.ReadAt(mergeFinBuf, 7); err != nil {\n\t\treturn 0, err\n\t}\n\tmergeFinSegmentId := binary.LittleEndian.Uint32(mergeFinBuf)\n\treturn mergeFinSegmentId, nil\n}\n\nfunc (db *DB) loadIndexFromHintFile() error {\n\thintFile, err := wal.Open(wal.Options{\n\t\tDirPath: db.options.DirPath,\n\t\t// we don't need to rotate the hint file, just write all data to the same file.\n\t\tSegmentSize:    math.MaxInt64,\n\t\tSegmentFileExt: hintFileNameSuffix,\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer func() {\n\t\t_ = hintFile.Close()\n\t}()\n\n\t// read all the hint records from the hint file\n\treader := hintFile.NewReader()\n\thintFile.SetIsStartupTraversal(true)\n\tfor {\n\t\tchunk, _, err := reader.Next()\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\n\t\tkey, position := decodeHintRecord(chunk)\n\t\t// All the hint records are valid because it is generated by the merge operation.\n\t\t// So just put them into the index without checking.\n\t\tdb.index.Put(key, position)\n\t}\n\thintFile.SetIsStartupTraversal(false)\n\treturn nil\n}\n"
        },
        {
          "name": "merge_test.go",
          "type": "blob",
          "size": 6.037109375,
          "content": "package rosedb\n\nimport (\n\t\"math/rand\"\n\t\"os\"\n\t\"sync\"\n\t\"testing\"\n\n\t\"github.com/rosedblabs/rosedb/v2/utils\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestDB_Merge_1_Empty(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\terr = db.Merge(false)\n\tassert.Nil(t, err)\n}\n\nfunc TestDB_Merge_2_All_Invalid(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tfor i := 0; i < 100000; i++ {\n\t\terr := db.Put(utils.GetTestKey(i), utils.RandomValue(128))\n\t\tassert.Nil(t, err)\n\t}\n\tfor i := 0; i < 100000; i++ {\n\t\terr := db.Delete(utils.GetTestKey(i))\n\t\tassert.Nil(t, err)\n\t}\n\n\terr = db.Merge(false)\n\tassert.Nil(t, err)\n\n\t_ = db.Close()\n\tdb2, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer func() {\n\t\t_ = db2.Close()\n\t}()\n\n\tstat := db2.Stat()\n\tassert.Equal(t, 0, stat.KeysNum)\n}\n\nfunc TestDB_Merge_3_All_Valid(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tfor i := 0; i < 100000; i++ {\n\t\terr := db.Put(utils.GetTestKey(i), utils.RandomValue(128))\n\t\tassert.Nil(t, err)\n\t}\n\n\terr = db.Merge(false)\n\tassert.Nil(t, err)\n\n\t_ = db.Close()\n\tdb2, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer func() {\n\t\t_ = db2.Close()\n\t}()\n\n\tfor i := 0; i < 100000; i++ {\n\t\tval, err := db2.Get(utils.GetTestKey(i))\n\t\tassert.Nil(t, err)\n\t\tassert.NotNil(t, val)\n\t}\n}\n\nfunc TestDB_Merge_4_Twice(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tfor i := 0; i < 100000; i++ {\n\t\terr := db.Put(utils.GetTestKey(i), utils.RandomValue(128))\n\t\tassert.Nil(t, err)\n\t}\n\n\terr = db.Merge(false)\n\tassert.Nil(t, err)\n\terr = db.Merge(false)\n\tassert.Nil(t, err)\n\n\t_ = db.Close()\n\tdb2, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer func() {\n\t\t_ = db2.Close()\n\t}()\n\n\tfor i := 0; i < 100000; i++ {\n\t\tval, err := db2.Get(utils.GetTestKey(i))\n\t\tassert.Nil(t, err)\n\t\tassert.NotNil(t, val)\n\t}\n}\n\nfunc TestDB_Merge_5_Mixed(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tfor i := 0; i < 100000; i++ {\n\t\terr := db.Put(utils.GetTestKey(i), utils.RandomValue(128))\n\t\tassert.Nil(t, err)\n\t}\n\tfor i := 0; i < 100000; i++ {\n\t\terr := db.Put(utils.GetTestKey(i), utils.RandomValue(128))\n\t\tassert.Nil(t, err)\n\t}\n\tfor i := 100000; i < 300000; i++ {\n\t\terr := db.Put(utils.GetTestKey(i), utils.RandomValue(128))\n\t\tassert.Nil(t, err)\n\t}\n\tfor i := 100000; i < 200000; i++ {\n\t\terr := db.Delete(utils.GetTestKey(i))\n\t\tassert.Nil(t, err)\n\t}\n\n\terr = db.Merge(false)\n\tassert.Nil(t, err)\n\n\t_ = db.Close()\n\tdb2, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer func() {\n\t\t_ = db2.Close()\n\t}()\n\tstat := db2.Stat()\n\tassert.Equal(t, 200000, stat.KeysNum)\n}\n\nfunc TestDB_Merge_6_Appending(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tfor i := 0; i < 100000; i++ {\n\t\terr := db.Put(utils.GetTestKey(i), utils.RandomValue(128))\n\t\tassert.Nil(t, err)\n\t}\n\tfor i := 0; i < 100000; i++ {\n\t\terr := db.Put(utils.GetTestKey(i), utils.RandomValue(128))\n\t\tassert.Nil(t, err)\n\t}\n\tfor i := 100000; i < 300000; i++ {\n\t\terr := db.Put(utils.GetTestKey(i), utils.RandomValue(128))\n\t\tassert.Nil(t, err)\n\t}\n\tfor i := 100000; i < 200000; i++ {\n\t\terr := db.Delete(utils.GetTestKey(i))\n\t\tassert.Nil(t, err)\n\t}\n\n\twg := sync.WaitGroup{}\n\tm := sync.Map{}\n\twg.Add(10)\n\tfor i := 0; i < 10; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor i := 0; i < 10000; i++ {\n\t\t\t\tkey := utils.GetTestKey(rand.Int())\n\t\t\t\tm.Store(string(key), struct{}{})\n\t\t\t\te := db.Put(key, utils.RandomValue(128))\n\t\t\t\tassert.Nil(t, e)\n\t\t\t}\n\t\t}()\n\t}\n\n\terr = db.Merge(false)\n\tassert.Nil(t, err)\n\n\twg.Wait()\n\n\t_ = db.Close()\n\tdb2, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer func() {\n\t\t_ = db2.Close()\n\t}()\n\tstat := db2.Stat()\n\tvar count int\n\tm.Range(func(key, value any) bool {\n\t\tcount++\n\t\treturn true\n\t})\n\tassert.Equal(t, 200000+count, stat.KeysNum)\n}\n\nfunc TestDB_Multi_Open_Merge(t *testing.T) {\n\toptions := DefaultOptions\n\tkvs := make(map[string][]byte)\n\tfor i := 0; i < 5; i++ {\n\t\tdb, err := Open(options)\n\t\tassert.Nil(t, err)\n\n\t\tfor i := 0; i < 10000; i++ {\n\t\t\tkey := utils.GetTestKey(rand.Int())\n\t\t\tvalue := utils.RandomValue(128)\n\t\t\tkvs[string(key)] = value\n\t\t\terr = db.Put(key, value)\n\t\t\tassert.Nil(t, err)\n\t\t}\n\n\t\terr = db.Merge(false)\n\t\tassert.Nil(t, err)\n\t\terr = db.Close()\n\t\tassert.Nil(t, err)\n\t}\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tfor key, value := range kvs {\n\t\tv, err := db.Get([]byte(key))\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, value, v)\n\t}\n\tassert.Equal(t, len(kvs), db.index.Size())\n}\n\nfunc TestDB_Merge_ReopenAfterDone(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tkvs := make(map[string][]byte)\n\tfor i := 0; i < 200000; i++ {\n\t\tkey := utils.GetTestKey(i)\n\t\tvalue := utils.RandomValue(128)\n\t\tkvs[string(key)] = value\n\t\terr := db.Put(key, value)\n\t\tassert.Nil(t, err)\n\t}\n\n\terr = db.Merge(true)\n\tassert.Nil(t, err)\n\t_, err = os.Stat(mergeDirPath(options.DirPath))\n\tassert.Equal(t, true, os.IsNotExist(err))\n\n\tfor key, value := range kvs {\n\t\tv, err := db.Get([]byte(key))\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, value, v)\n\t}\n\tassert.Equal(t, len(kvs), db.index.Size())\n}\n\nfunc TestDB_Merge_Concurrent_Put(t *testing.T) {\n\toptions := DefaultOptions\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\twg := sync.WaitGroup{}\n\tm := sync.Map{}\n\twg.Add(11)\n\tfor i := 0; i < 10; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor i := 0; i < 10000; i++ {\n\t\t\t\tkey := utils.GetTestKey(rand.Int())\n\t\t\t\tvalue := utils.RandomValue(128)\n\t\t\t\tm.Store(string(key), value)\n\t\t\t\te := db.Put(key, value)\n\t\t\t\tassert.Nil(t, e)\n\t\t\t}\n\t\t}()\n\t}\n\tgo func() {\n\t\tdefer wg.Done()\n\t\terr = db.Merge(true)\n\t\tassert.Nil(t, err)\n\t}()\n\twg.Wait()\n\n\t_, err = os.Stat(mergeDirPath(options.DirPath))\n\tassert.Equal(t, true, os.IsNotExist(err))\n\n\tvar count int\n\tm.Range(func(key, value any) bool {\n\t\tv, err := db.Get([]byte(key.(string)))\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, value, v)\n\t\tcount++\n\t\treturn true\n\t})\n\tassert.Equal(t, count, db.index.Size())\n\n}\n"
        },
        {
          "name": "options.go",
          "type": "blob",
          "size": 2.4111328125,
          "content": "package rosedb\n\nimport (\n\t\"math/rand\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"time\"\n)\n\n// Options specifies the options for opening a database.\ntype Options struct {\n\t// DirPath specifies the directory path where the WAL segment files will be stored.\n\tDirPath string\n\n\t// SegmentSize specifies the maximum size of each segment file in bytes.\n\tSegmentSize int64\n\n\t// Sync is whether to synchronize writes through os buffer cache and down onto the actual disk.\n\t// Setting sync is required for durability of a single write operation, but also results in slower writes.\n\t//\n\t// If false, and the machine crashes, then some recent writes may be lost.\n\t// Note that if it is just the process that crashes (machine does not) then no writes will be lost.\n\t//\n\t// In other words, Sync being false has the same semantics as a write\n\t// system call. Sync being true means write followed by fsync.\n\tSync bool\n\n\t// BytesPerSync specifies the number of bytes to write before calling fsync.\n\tBytesPerSync uint32\n\n\t// WatchQueueSize the cache length of the watch queue.\n\t// if the size greater than 0, which means enable the watch.\n\tWatchQueueSize uint64\n\n\t// AutoMergeEnable enable the auto merge.\n\t// auto merge will be triggered when cron expr is satisfied.\n\t// cron expression follows the standard cron expression.\n\t// e.g. \"0 0 * * *\" means merge at 00:00:00 every day.\n\t// it also supports seconds optionally.\n\t// when enable the second field, the cron expression will be like this: \"0/10 * * * * *\" (every 10 seconds).\n\t// when auto merge is enabled, the db will be closed and reopened after merge done.\n\t// do not set this shecule too frequently, it will affect the performance.\n\t// refer to https://en.wikipedia.org/wiki/Cron\n\tAutoMergeCronExpr string\n}\n\n// BatchOptions specifies the options for creating a batch.\ntype BatchOptions struct {\n\t// Sync has the same semantics as Options.Sync.\n\tSync bool\n\t// ReadOnly specifies whether the batch is read only.\n\tReadOnly bool\n}\n\nconst (\n\tB  = 1\n\tKB = 1024 * B\n\tMB = 1024 * KB\n\tGB = 1024 * MB\n)\n\nvar DefaultOptions = Options{\n\tDirPath:           tempDBDir(),\n\tSegmentSize:       1 * GB,\n\tSync:              false,\n\tBytesPerSync:      0,\n\tWatchQueueSize:    0,\n\tAutoMergeCronExpr: \"\",\n}\n\nvar DefaultBatchOptions = BatchOptions{\n\tSync:     true,\n\tReadOnly: false,\n}\n\nvar nameRand = rand.NewSource(time.Now().UnixNano())\n\nfunc tempDBDir() string {\n\treturn filepath.Join(os.TempDir(), \"rosedb-temp\"+strconv.Itoa(int(nameRand.Int63())))\n}\n"
        },
        {
          "name": "record.go",
          "type": "blob",
          "size": 4.4619140625,
          "content": "package rosedb\n\nimport (\n\t\"encoding/binary\"\n\t\"github.com/rosedblabs/wal\"\n\t\"github.com/valyala/bytebufferpool\"\n)\n\n// LogRecordType is the type of the log record.\ntype LogRecordType = byte\n\nconst (\n\t// LogRecordNormal is the normal log record type.\n\tLogRecordNormal LogRecordType = iota\n\t// LogRecordDeleted is the deleted log record type.\n\tLogRecordDeleted\n\t// LogRecordBatchFinished is the batch finished log record type.\n\tLogRecordBatchFinished\n)\n\n// type batchId keySize valueSize expire\n//\n//\t1  +  10  +   5   +   5   +    10  = 31\nconst maxLogRecordHeaderSize = binary.MaxVarintLen32*2 + binary.MaxVarintLen64*2 + 1\n\n// LogRecord is the log record of the key/value pair.\n// It contains the key, the value, the record type and the batch id\n// It will be encoded to byte slice and written to the wal.\ntype LogRecord struct {\n\tKey     []byte\n\tValue   []byte\n\tType    LogRecordType\n\tBatchId uint64\n\tExpire  int64\n}\n\n// IsExpired checks whether the log record is expired.\nfunc (lr *LogRecord) IsExpired(now int64) bool {\n\treturn lr.Expire > 0 && lr.Expire <= now\n}\n\n// IndexRecord is the index record of the key.\n// It contains the key, the record type and the position of the record in the wal.\n// Only used in start up to rebuild the index.\ntype IndexRecord struct {\n\tkey        []byte\n\trecordType LogRecordType\n\tposition   *wal.ChunkPosition\n}\n\n// +-------------+-------------+-------------+--------------+---------------+---------+--------------+\n// |    type     |  batch id   |   key size  |   value size |     expire    |  key    |      value   |\n// +-------------+-------------+-------------+--------------+---------------+--------+--------------+\n//\n//\t1 byte\t      varint(max 10) varint(max 5)  varint(max 5) varint(max 10)  varint      varint\nfunc encodeLogRecord(logRecord *LogRecord, header []byte, buf *bytebufferpool.ByteBuffer) []byte {\n\theader[0] = logRecord.Type\n\tvar index = 1\n\n\t// batch id\n\tindex += binary.PutUvarint(header[index:], logRecord.BatchId)\n\t// key size\n\tindex += binary.PutVarint(header[index:], int64(len(logRecord.Key)))\n\t// value size\n\tindex += binary.PutVarint(header[index:], int64(len(logRecord.Value)))\n\t// expire\n\tindex += binary.PutVarint(header[index:], logRecord.Expire)\n\n\t// copy header\n\t_, _ = buf.Write(header[:index])\n\t// copy key\n\t_, _ = buf.Write(logRecord.Key)\n\t// copy value\n\t_, _ = buf.Write(logRecord.Value)\n\n\treturn buf.Bytes()\n}\n\n// decodeLogRecord decodes the log record from the given byte slice.\nfunc decodeLogRecord(buf []byte) *LogRecord {\n\trecordType := buf[0]\n\n\tvar index uint32 = 1\n\t// batch id\n\tbatchId, n := binary.Uvarint(buf[index:])\n\tindex += uint32(n)\n\n\t// key size\n\tkeySize, n := binary.Varint(buf[index:])\n\tindex += uint32(n)\n\n\t// value size\n\tvalueSize, n := binary.Varint(buf[index:])\n\tindex += uint32(n)\n\n\t// expire\n\texpire, n := binary.Varint(buf[index:])\n\tindex += uint32(n)\n\n\t// copy key\n\tkey := make([]byte, keySize)\n\tcopy(key[:], buf[index:index+uint32(keySize)])\n\tindex += uint32(keySize)\n\n\t// copy value\n\tvalue := make([]byte, valueSize)\n\tcopy(value[:], buf[index:index+uint32(valueSize)])\n\n\treturn &LogRecord{Key: key, Value: value, Expire: expire,\n\t\tBatchId: batchId, Type: recordType}\n}\n\nfunc encodeHintRecord(key []byte, pos *wal.ChunkPosition) []byte {\n\t// SegmentId BlockNumber ChunkOffset ChunkSize\n\t//    5          5           10          5      =    25\n\t// see binary.MaxVarintLen64 and binary.MaxVarintLen32\n\tbuf := make([]byte, 25)\n\tvar idx = 0\n\n\t// SegmentId\n\tidx += binary.PutUvarint(buf[idx:], uint64(pos.SegmentId))\n\t// BlockNumber\n\tidx += binary.PutUvarint(buf[idx:], uint64(pos.BlockNumber))\n\t// ChunkOffset\n\tidx += binary.PutUvarint(buf[idx:], uint64(pos.ChunkOffset))\n\t// ChunkSize\n\tidx += binary.PutUvarint(buf[idx:], uint64(pos.ChunkSize))\n\n\t// key\n\tresult := make([]byte, idx+len(key))\n\tcopy(result, buf[:idx])\n\tcopy(result[idx:], key)\n\treturn result\n}\n\nfunc decodeHintRecord(buf []byte) ([]byte, *wal.ChunkPosition) {\n\tvar idx = 0\n\t// SegmentId\n\tsegmentId, n := binary.Uvarint(buf[idx:])\n\tidx += n\n\t// BlockNumber\n\tblockNumber, n := binary.Uvarint(buf[idx:])\n\tidx += n\n\t// ChunkOffset\n\tchunkOffset, n := binary.Uvarint(buf[idx:])\n\tidx += n\n\t// ChunkSize\n\tchunkSize, n := binary.Uvarint(buf[idx:])\n\tidx += n\n\t// Key\n\tkey := buf[idx:]\n\n\treturn key, &wal.ChunkPosition{\n\t\tSegmentId:   wal.SegmentID(segmentId),\n\t\tBlockNumber: uint32(blockNumber),\n\t\tChunkOffset: int64(chunkOffset),\n\t\tChunkSize:   uint32(chunkSize),\n\t}\n}\n\nfunc encodeMergeFinRecord(segmentId wal.SegmentID) []byte {\n\tbuf := make([]byte, 4)\n\tbinary.LittleEndian.PutUint32(buf, segmentId)\n\treturn buf\n}\n"
        },
        {
          "name": "utils",
          "type": "tree",
          "content": null
        },
        {
          "name": "watch.go",
          "type": "blob",
          "size": 1.853515625,
          "content": "package rosedb\n\nimport (\n\t\"sync\"\n\t\"time\"\n)\n\ntype WatchActionType = byte\n\nconst (\n\tWatchActionPut WatchActionType = iota\n\tWatchActionDelete\n)\n\n// Event is the event that occurs when the database is modified.\n// It is used to synchronize the watch of the database.\ntype Event struct {\n\tAction  WatchActionType\n\tKey     []byte\n\tValue   []byte\n\tBatchId uint64\n}\n\n// Watcher temporarily stores event information,\n// as it is generated until it is synchronized to DB's watch.\n//\n// If the event is overflow, It will remove the oldest data,\n// even if event hasn't been read yet.\ntype Watcher struct {\n\tqueue eventQueue\n\tmu    sync.RWMutex\n}\n\nfunc NewWatcher(capacity uint64) *Watcher {\n\treturn &Watcher{\n\t\tqueue: eventQueue{\n\t\t\tEvents:   make([]*Event, capacity),\n\t\t\tCapacity: capacity,\n\t\t},\n\t}\n}\n\nfunc (w *Watcher) putEvent(e *Event) {\n\tw.mu.Lock()\n\tw.queue.push(e)\n\tif w.queue.isFull() {\n\t\tw.queue.frontTakeAStep()\n\t}\n\tw.mu.Unlock()\n}\n\n// getEvent if queue is empty, it will return nil.\nfunc (w *Watcher) getEvent() *Event {\n\tw.mu.RLock()\n\tdefer w.mu.RUnlock()\n\tif w.queue.isEmpty() {\n\t\treturn nil\n\t}\n\treturn w.queue.pop()\n}\n\n// sendEvent send events to DB's watch\nfunc (w *Watcher) sendEvent(c chan *Event) {\n\tfor {\n\t\tevent := w.getEvent()\n\t\tif event == nil {\n\t\t\ttime.Sleep(100 * time.Millisecond)\n\t\t\tcontinue\n\t\t}\n\t\tc <- event\n\t}\n}\n\ntype eventQueue struct {\n\tEvents   []*Event\n\tCapacity uint64\n\tFront    uint64 // read point\n\tBack     uint64 // write point\n}\n\nfunc (eq *eventQueue) push(e *Event) {\n\teq.Events[eq.Back] = e\n\teq.Back = (eq.Back + 1) % eq.Capacity\n}\n\nfunc (eq *eventQueue) pop() *Event {\n\te := eq.Events[eq.Front]\n\teq.frontTakeAStep()\n\treturn e\n}\n\nfunc (eq *eventQueue) isFull() bool {\n\treturn (eq.Back+1)%eq.Capacity == eq.Front\n}\n\nfunc (eq *eventQueue) isEmpty() bool {\n\treturn eq.Back == eq.Front\n}\n\nfunc (eq *eventQueue) frontTakeAStep() {\n\teq.Front = (eq.Front + 1) % eq.Capacity\n}\n"
        },
        {
          "name": "watch_test.go",
          "type": "blob",
          "size": 3.0693359375,
          "content": "package rosedb\n\nimport (\n\t\"math/rand\"\n\t\"testing\"\n\n\t\"github.com/rosedblabs/rosedb/v2/utils\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestWatch_Insert_Scan(t *testing.T) {\n\tcapacity := 1000\n\t// There are two spaces to determine whether the queue is full and overwrite the write.\n\tsize := capacity - 2\n\tq := make([][2][]byte, 0, size)\n\tw := NewWatcher(uint64(capacity))\n\tfor i := 0; i < size; i++ {\n\t\tkey := utils.GetTestKey(rand.Int())\n\t\tvalue := utils.RandomValue(128)\n\t\tq = append(q, [2][]byte{key, value})\n\t\tw.putEvent(&Event{\n\t\t\tAction:  WatchActionPut,\n\t\t\tKey:     key,\n\t\t\tValue:   value,\n\t\t\tBatchId: 0,\n\t\t})\n\t}\n\n\tfor i := 0; i < size; i++ {\n\t\te := w.getEvent()\n\t\tassert.NotEmpty(t, e)\n\t\tkey := q[i][0]\n\t\tassert.Equal(t, key, e.Key)\n\t\tvalue := q[i][1]\n\t\tassert.Equal(t, value, e.Value)\n\t}\n}\n\nfunc TestWatch_Rotate_Insert_Scan(t *testing.T) {\n\tcapacity := 1000\n\tq := make([][2][]byte, capacity)\n\tw := NewWatcher(uint64(capacity))\n\tfor i := 0; i < 2500; i++ {\n\t\tkey := utils.GetTestKey(rand.Int())\n\t\tvalue := utils.RandomValue(128)\n\t\tw.putEvent(&Event{\n\t\t\tAction:  WatchActionPut,\n\t\t\tKey:     key,\n\t\t\tValue:   value,\n\t\t\tBatchId: 0,\n\t\t})\n\t\tsub := i % capacity\n\t\tq[sub] = [2][]byte{key, value}\n\t}\n\n\tsub := int(w.queue.Front)\n\tfor {\n\t\te := w.getEvent()\n\t\tif e == nil {\n\t\t\tbreak\n\t\t}\n\t\tkey := q[sub][0]\n\t\tassert.Equal(t, key, e.Key)\n\t\tvalue := q[sub][1]\n\t\tassert.Equal(t, value, e.Value)\n\t\tsub = (sub + 1) % capacity\n\t}\n\n}\n\nfunc TestWatch_Put_Watch(t *testing.T) {\n\toptions := DefaultOptions\n\toptions.WatchQueueSize = 10\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tw, err := db.Watch()\n\tassert.Nil(t, err)\n\tfor i := 0; i < 50; i++ {\n\t\tkey := utils.GetTestKey(rand.Int())\n\t\tvalue := utils.RandomValue(128)\n\t\terr = db.Put(key, value)\n\t\tassert.Nil(t, err)\n\t\tevent := <-w\n\t\tassert.Equal(t, WatchActionPut, event.Action)\n\t\tassert.Equal(t, key, event.Key)\n\t\tassert.Equal(t, value, event.Value)\n\t}\n}\n\nfunc TestWatch_Put_Delete_Watch(t *testing.T) {\n\toptions := DefaultOptions\n\toptions.WatchQueueSize = 10\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tw, err := db.Watch()\n\tassert.Nil(t, err)\n\n\tkey := utils.GetTestKey(rand.Int())\n\tvalue := utils.RandomValue(128)\n\terr = db.Put(key, value)\n\tassert.Nil(t, err)\n\terr = db.Delete(key)\n\tassert.Nil(t, err)\n\n\tfor i := 0; i < 2; i++ {\n\t\tevent := <-w\n\t\tassert.Equal(t, key, event.Key)\n\t\tif event.Action == WatchActionPut {\n\t\t\tassert.Equal(t, value, event.Value)\n\t\t} else if event.Action == WatchActionDelete {\n\t\t\tassert.Equal(t, 0, len(event.Value))\n\t\t}\n\t}\n}\n\nfunc TestWatch_Batch_Put_Watch(t *testing.T) {\n\toptions := DefaultOptions\n\toptions.WatchQueueSize = 1000\n\tdb, err := Open(options)\n\tassert.Nil(t, err)\n\tdefer destroyDB(db)\n\n\tw, err := db.Watch()\n\tassert.Nil(t, err)\n\n\ttimes := 100\n\tbatch := db.NewBatch(DefaultBatchOptions)\n\tfor i := 0; i < times; i++ {\n\t\terr = batch.Put(utils.GetTestKey(rand.Int()), utils.RandomValue(128))\n\t\tassert.Nil(t, err)\n\t}\n\terr = batch.Commit()\n\tassert.Nil(t, err)\n\n\tvar batchId uint64\n\tfor i := 0; i < times; i++ {\n\t\tevent := <-w\n\t\tif i == 0 {\n\t\t\tbatchId = event.BatchId\n\t\t}\n\t\tassert.Equal(t, batchId, event.BatchId)\n\t}\n}\n"
        }
      ]
    }
  ]
}