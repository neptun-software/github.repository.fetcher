{
  "metadata": {
    "timestamp": 1736566989593,
    "page": 570,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjU3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "montanaflynn/stats",
      "stars": 2941,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.078125,
          "content": "coverage.out\ncoverage.txt\nrelease-notes.txt\n.directory\n.chglog\n.vscode\n.DS_Store"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 15.228515625,
          "content": "<a name=\"unreleased\"></a>\n## [Unreleased]\n\n\n<a name=\"v0.7.1\"></a>\n## [v0.7.1] - 2023-05-11\n### Add\n- Add describe functions ([#77](https://github.com/montanaflynn/stats/issues/77))\n\n### Update\n- Update .gitignore\n- Update README.md, LICENSE and DOCUMENTATION.md files\n- Update github action go workflow to run on push\n\n\n<a name=\"v0.7.0\"></a>\n## [v0.7.0] - 2023-01-08\n### Add\n- Add geometric distribution functions ([#75](https://github.com/montanaflynn/stats/issues/75))\n- Add GitHub action go workflow\n\n### Remove\n- Remove travis CI config\n\n### Update\n- Update changelog with v0.7.0 changes\n- Update changelog with v0.7.0 changes\n- Update github action go workflow\n- Update geometric distribution tests\n\n\n<a name=\"v0.6.6\"></a>\n## [v0.6.6] - 2021-04-26\n### Add\n- Add support for string and io.Reader in LoadRawData (pr [#68](https://github.com/montanaflynn/stats/issues/68))\n- Add latest versions of Go to test against\n\n### Update\n- Update changelog with v0.6.6 changes\n\n### Use\n- Use math.Sqrt in StandardDeviation (PR [#64](https://github.com/montanaflynn/stats/issues/64))\n\n\n<a name=\"v0.6.5\"></a>\n## [v0.6.5] - 2021-02-21\n### Add\n- Add Float64Data.Quartiles documentation\n- Add Quartiles method to Float64Data type (issue [#60](https://github.com/montanaflynn/stats/issues/60))\n\n### Fix\n- Fix make release changelog command and add changelog history\n\n### Update\n- Update changelog with v0.6.5 changes\n- Update changelog with v0.6.4 changes\n- Update README.md links to CHANGELOG.md and DOCUMENTATION.md\n- Update README.md and Makefile with new release commands\n\n\n<a name=\"v0.6.4\"></a>\n## [v0.6.4] - 2021-01-13\n### Fix\n- Fix failing tests due to precision errors on arm64 ([#58](https://github.com/montanaflynn/stats/issues/58))\n\n### Update\n- Update changelog with v0.6.4 changes\n- Update examples directory to include a README.md used for synopsis\n- Update go.mod to include go version where modules are enabled by default\n- Update changelog with v0.6.3 changes\n\n\n<a name=\"v0.6.3\"></a>\n## [v0.6.3] - 2020-02-18\n### Add\n- Add creating and committing changelog to Makefile release directive\n- Add release-notes.txt and .chglog directory to .gitignore\n\n### Update\n- Update exported tests to use import for better example documentation\n- Update documentation using godoc2md\n- Update changelog with v0.6.2 release\n\n\n<a name=\"v0.6.2\"></a>\n## [v0.6.2] - 2020-02-18\n### Fix\n- Fix linting errcheck warnings in go benchmarks\n\n### Update\n- Update Makefile release directive to use correct release name\n\n\n<a name=\"v0.6.1\"></a>\n## [v0.6.1] - 2020-02-18\n### Add\n- Add StableSample function signature to readme\n\n### Fix\n- Fix linting warnings for normal distribution functions formatting and tests\n\n### Update\n- Update documentation links and rename DOC.md to DOCUMENTATION.md\n- Update README with link to pkg.go.dev reference and release section\n- Update Makefile with new changelog, docs, and release directives\n- Update DOC.md links to GitHub source code\n- Update doc.go comment and add DOC.md package reference file\n- Update changelog using git-chglog\n\n\n<a name=\"v0.6.0\"></a>\n## [v0.6.0] - 2020-02-17\n### Add\n- Add Normal Distribution Functions ([#56](https://github.com/montanaflynn/stats/issues/56))\n- Add previous versions of Go to travis CI config\n- Add check for distinct values in Mode function ([#51](https://github.com/montanaflynn/stats/issues/51))\n- Add StableSample function ([#48](https://github.com/montanaflynn/stats/issues/48))\n- Add doc.go file to show description and usage on godoc.org\n- Add comments to new error and legacy error variables\n- Add ExampleRound function to tests\n- Add go.mod file for module support\n- Add Sigmoid, SoftMax and Entropy methods and tests\n- Add Entropy documentation, example and benchmarks\n- Add Entropy function ([#44](https://github.com/montanaflynn/stats/issues/44))\n\n### Fix\n- Fix percentile when only one element ([#47](https://github.com/montanaflynn/stats/issues/47))\n- Fix AutoCorrelation name in comments and remove unneeded Sprintf\n\n### Improve\n- Improve documentation section with command comments\n\n### Remove\n- Remove very old versions of Go in travis CI config\n- Remove boolean comparison to get rid of gometalinter warning\n\n### Update\n- Update license dates\n- Update Distance functions signatures to use Float64Data\n- Update Sigmoid examples\n- Update error names with backward compatibility\n\n### Use\n- Use relative link to examples/main.go\n- Use a single var block for exported errors\n\n\n<a name=\"v0.5.0\"></a>\n## [v0.5.0] - 2019-01-16\n### Add\n- Add Sigmoid and Softmax functions\n\n### Fix\n- Fix syntax highlighting and add CumulativeSum func\n\n\n<a name=\"v0.4.0\"></a>\n## [v0.4.0] - 2019-01-14\n### Add\n- Add goreport badge and documentation section to README.md\n- Add Examples to test files\n- Add AutoCorrelation and nist tests\n- Add String method to statsErr type\n- Add Y coordinate error for ExponentialRegression\n- Add syntax highlighting ([#43](https://github.com/montanaflynn/stats/issues/43))\n- Add CumulativeSum ([#40](https://github.com/montanaflynn/stats/issues/40))\n- Add more tests and rename distance files\n- Add coverage and benchmarks to azure pipeline\n- Add go tests to azure pipeline\n\n### Change\n- Change travis tip alias to master\n- Change codecov to coveralls for code coverage\n\n### Fix\n- Fix a few lint warnings\n- Fix example error\n\n### Improve\n- Improve test coverage of distance functions\n\n### Only\n- Only run travis on stable and tip versions\n- Only check code coverage on tip\n\n### Remove\n- Remove azure CI pipeline\n- Remove unnecessary type conversions\n\n### Return\n- Return EmptyInputErr instead of EmptyInput\n\n### Set\n- Set up CI with Azure Pipelines\n\n\n<a name=\"0.3.0\"></a>\n## [0.3.0] - 2017-12-02\n### Add\n- Add Chebyshev, Manhattan, Euclidean and Minkowski distance functions ([#35](https://github.com/montanaflynn/stats/issues/35))\n- Add function for computing chebyshev distance. ([#34](https://github.com/montanaflynn/stats/issues/34))\n- Add support for time.Duration\n- Add LoadRawData to docs and examples\n- Add unit test for edge case that wasn't covered\n- Add unit tests for edge cases that weren't covered\n- Add pearson alias delegating to correlation\n- Add CovariancePopulation to Float64Data\n- Add pearson product-moment correlation coefficient\n- Add population covariance\n- Add random slice benchmarks\n- Add all applicable functions as methods to Float64Data type\n- Add MIT license badge\n- Add link to examples/methods.go\n- Add Protips for usage and documentation sections\n- Add tests for rounding up\n- Add webdoc target and remove linting from test target\n- Add example usage and consolidate contributing information\n\n### Added\n- Added MedianAbsoluteDeviation\n\n### Annotation\n- Annotation spelling error\n\n### Auto\n- auto commit\n- auto commit\n\n### Calculate\n- Calculate correlation with sdev and covp\n\n### Clean\n- Clean up README.md and add info for offline docs\n\n### Consolidated\n- Consolidated all error values.\n\n### Fix\n- Fix Percentile logic\n- Fix InterQuartileRange method test\n- Fix zero percent bug and add test\n- Fix usage example output typos\n\n### Improve\n- Improve bounds checking in Percentile\n- Improve error log messaging\n\n### Imput\n- Imput -> Input\n\n### Include\n- Include alternative way to set Float64Data in example\n\n### Make\n- Make various changes to README.md\n\n### Merge\n- Merge branch 'master' of github.com:montanaflynn/stats\n- Merge master\n\n### Mode\n- Mode calculation fix and tests\n\n### Realized\n- Realized the obvious efficiency gains of ignoring the unique numbers at the beginning of the slice.  Benchmark joy ensued.\n\n### Refactor\n- Refactor testing of Round()\n- Refactor setting Coordinate y field using Exp in place of Pow\n- Refactor Makefile and add docs target\n\n### Remove\n- Remove deep links to types and functions\n\n### Rename\n- Rename file from types to data\n\n### Retrieve\n- Retrieve InterQuartileRange for the Float64Data.\n\n### Split\n- Split up stats.go into separate files\n\n### Support\n- Support more types on LoadRawData() ([#36](https://github.com/montanaflynn/stats/issues/36))\n\n### Switch\n- Switch default and check targets\n\n### Update\n- Update Readme\n- Update example methods and some text\n- Update README and include Float64Data type method examples\n\n### Pull Requests\n- Merge pull request [#32](https://github.com/montanaflynn/stats/issues/32) from a-robinson/percentile\n- Merge pull request [#30](https://github.com/montanaflynn/stats/issues/30) from montanaflynn/fix-test\n- Merge pull request [#29](https://github.com/montanaflynn/stats/issues/29) from edupsousa/master\n- Merge pull request [#27](https://github.com/montanaflynn/stats/issues/27) from andrey-yantsen/fix-percentile-out-of-bounds\n- Merge pull request [#25](https://github.com/montanaflynn/stats/issues/25) from kazhuravlev/patch-1\n- Merge pull request [#22](https://github.com/montanaflynn/stats/issues/22) from JanBerktold/time-duration\n- Merge pull request [#24](https://github.com/montanaflynn/stats/issues/24) from alouche/master\n- Merge pull request [#21](https://github.com/montanaflynn/stats/issues/21) from brydavis/master\n- Merge pull request [#19](https://github.com/montanaflynn/stats/issues/19) from ginodeis/mode-bug\n- Merge pull request [#17](https://github.com/montanaflynn/stats/issues/17) from Kunde21/master\n- Merge pull request [#3](https://github.com/montanaflynn/stats/issues/3) from montanaflynn/master\n- Merge pull request [#2](https://github.com/montanaflynn/stats/issues/2) from montanaflynn/master\n- Merge pull request [#13](https://github.com/montanaflynn/stats/issues/13) from toashd/pearson\n- Merge pull request [#12](https://github.com/montanaflynn/stats/issues/12) from alixaxel/MAD\n- Merge pull request [#1](https://github.com/montanaflynn/stats/issues/1) from montanaflynn/master\n- Merge pull request [#11](https://github.com/montanaflynn/stats/issues/11) from Kunde21/modeMemReduce\n- Merge pull request [#10](https://github.com/montanaflynn/stats/issues/10) from Kunde21/ModeRewrite\n\n\n<a name=\"0.2.0\"></a>\n## [0.2.0] - 2015-10-14\n### Add\n- Add Makefile with gometalinter, testing, benchmarking and coverage report targets\n- Add comments describing functions and structs\n- Add Correlation func\n- Add Covariance func\n- Add tests for new function shortcuts\n- Add StandardDeviation function as a shortcut to StandardDeviationPopulation\n- Add Float64Data and Series types\n\n### Change\n- Change Sample to return a standard []float64 type\n\n### Fix\n- Fix broken link to Makefile\n- Fix broken link and simplify code coverage reporting command\n- Fix go vet warning about printf type placeholder\n- Fix failing codecov test coverage reporting\n- Fix link to CHANGELOG.md\n\n### Fixed\n- Fixed typographical error, changed accomdate to accommodate in README.\n\n### Include\n- Include Variance and StandardDeviation shortcuts\n\n### Pass\n- Pass gometalinter\n\n### Refactor\n- Refactor Variance function to be the same as population variance\n\n### Release\n- Release version 0.2.0\n\n### Remove\n- Remove unneeded do packages and update cover URL\n- Remove sudo from pip install\n\n### Reorder\n- Reorder functions and sections\n\n### Revert\n- Revert to legacy containers to preserve go1.1 testing\n\n### Switch\n- Switch from legacy to container-based CI infrastructure\n\n### Update\n- Update contributing instructions and mention Makefile\n\n### Pull Requests\n- Merge pull request [#5](https://github.com/montanaflynn/stats/issues/5) from orthographic-pedant/spell_check/accommodate\n\n\n<a name=\"0.1.0\"></a>\n## [0.1.0] - 2015-08-19\n### Add\n- Add CONTRIBUTING.md\n\n### Rename\n- Rename functions while preserving backwards compatibility\n\n\n<a name=\"0.0.9\"></a>\n## 0.0.9 - 2015-08-18\n### Add\n- Add HarmonicMean func\n- Add GeometricMean func\n- Add .gitignore to avoid commiting test coverage report\n- Add Outliers stuct and QuantileOutliers func\n- Add Interquartile Range, Midhinge and Trimean examples\n- Add Trimean\n- Add Midhinge\n- Add Inter Quartile Range\n- Add a unit test to check for an empty slice error\n- Add Quantiles struct and Quantile func\n- Add more tests and fix a typo\n- Add Golang 1.5 to build tests\n- Add a standard MIT license file\n- Add basic benchmarking\n- Add regression models\n- Add codecov token\n- Add codecov\n- Add check for slices with a single item\n- Add coverage tests\n- Add back previous Go versions to Travis CI\n- Add Travis CI\n- Add GoDoc badge\n- Add Percentile and Float64ToInt functions\n- Add another rounding test for whole numbers\n- Add build status badge\n- Add code coverage badge\n- Add test for NaN, achieving 100% code coverage\n- Add round function\n- Add standard deviation function\n- Add sum function\n\n### Add\n- add tests for sample\n- add sample\n\n### Added\n- Added sample and population variance and deviation functions\n- Added README\n\n### Adjust\n- Adjust API ordering\n\n### Avoid\n- Avoid unintended consequence of using sort\n\n### Better\n- Better performing min/max\n- Better description\n\n### Change\n- Change package path to potentially fix a bug in earlier versions of Go\n\n### Clean\n- Clean up README and add some more information\n- Clean up test error\n\n### Consistent\n- Consistent empty slice error messages\n- Consistent var naming\n- Consistent func declaration\n\n### Convert\n- Convert ints to floats\n\n### Duplicate\n- Duplicate packages for all versions\n\n### Export\n- Export Coordinate struct fields\n\n### First\n- First commit\n\n### Fix\n- Fix copy pasta mistake testing the wrong function\n- Fix error message\n- Fix usage output and edit API doc section\n- Fix testing edgecase where map was in wrong order\n- Fix usage example\n- Fix usage examples\n\n### Include\n- Include the Nearest Rank method of calculating percentiles\n\n### More\n- More commenting\n\n### Move\n- Move GoDoc link to top\n\n### Redirect\n- Redirect kills newer versions of Go\n\n### Refactor\n- Refactor code and error checking\n\n### Remove\n- Remove unnecassary typecasting in sum func\n- Remove cover since it doesn't work for later versions of go\n- Remove golint and gocoveralls\n\n### Rename\n- Rename StandardDev to StdDev\n- Rename StandardDev to StdDev\n\n### Return\n- Return errors for all functions\n\n### Run\n- Run go fmt to clean up formatting\n\n### Simplify\n- Simplify min/max function\n\n### Start\n- Start with minimal tests\n\n### Switch\n- Switch wercker to travis and update todos\n\n### Table\n- table testing style\n\n### Update\n- Update README and move the example main.go into it's own file\n- Update TODO list\n- Update README\n- Update usage examples and todos\n\n### Use\n- Use codecov the recommended way\n- Use correct string formatting types\n\n### Pull Requests\n- Merge pull request [#4](https://github.com/montanaflynn/stats/issues/4) from saromanov/sample\n\n\n[Unreleased]: https://github.com/montanaflynn/stats/compare/v0.7.1...HEAD\n[v0.7.1]: https://github.com/montanaflynn/stats/compare/v0.7.0...v0.7.1\n[v0.7.0]: https://github.com/montanaflynn/stats/compare/v0.6.6...v0.7.0\n[v0.6.6]: https://github.com/montanaflynn/stats/compare/v0.6.5...v0.6.6\n[v0.6.5]: https://github.com/montanaflynn/stats/compare/v0.6.4...v0.6.5\n[v0.6.4]: https://github.com/montanaflynn/stats/compare/v0.6.3...v0.6.4\n[v0.6.3]: https://github.com/montanaflynn/stats/compare/v0.6.2...v0.6.3\n[v0.6.2]: https://github.com/montanaflynn/stats/compare/v0.6.1...v0.6.2\n[v0.6.1]: https://github.com/montanaflynn/stats/compare/v0.6.0...v0.6.1\n[v0.6.0]: https://github.com/montanaflynn/stats/compare/v0.5.0...v0.6.0\n[v0.5.0]: https://github.com/montanaflynn/stats/compare/v0.4.0...v0.5.0\n[v0.4.0]: https://github.com/montanaflynn/stats/compare/0.3.0...v0.4.0\n[0.3.0]: https://github.com/montanaflynn/stats/compare/0.2.0...0.3.0\n[0.2.0]: https://github.com/montanaflynn/stats/compare/0.1.0...0.2.0\n[0.1.0]: https://github.com/montanaflynn/stats/compare/0.0.9...0.1.0\n"
        },
        {
          "name": "DOCUMENTATION.md",
          "type": "blob",
          "size": 40.7138671875,
          "content": "\n\n# stats\n`import \"github.com/montanaflynn/stats\"`\n\n* [Overview](#pkg-overview)\n* [Index](#pkg-index)\n* [Examples](#pkg-examples)\n* [Subdirectories](#pkg-subdirectories)\n\n## <a name=\"pkg-overview\">Overview</a>\nPackage stats is a well tested and comprehensive\nstatistics library package with no dependencies.\n\nExample Usage:\n\n\n\t// start with some source data to use\n\tdata := []float64{1.0, 2.1, 3.2, 4.823, 4.1, 5.8}\n\t\n\t// you could also use different types like this\n\t// data := stats.LoadRawData([]int{1, 2, 3, 4, 5})\n\t// data := stats.LoadRawData([]interface{}{1.1, \"2\", 3})\n\t// etc...\n\t\n\tmedian, _ := stats.Median(data)\n\tfmt.Println(median) // 3.65\n\t\n\troundedMedian, _ := stats.Round(median, 0)\n\tfmt.Println(roundedMedian) // 4\n\nMIT License Copyright (c) 2014-2020 Montana Flynn (<a href=\"https://montanaflynn.com\">https://montanaflynn.com</a>)\n\n\n\n\n## <a name=\"pkg-index\">Index</a>\n* [Variables](#pkg-variables)\n* [func AutoCorrelation(data Float64Data, lags int) (float64, error)](#AutoCorrelation)\n* [func ChebyshevDistance(dataPointX, dataPointY Float64Data) (distance float64, err error)](#ChebyshevDistance)\n* [func Correlation(data1, data2 Float64Data) (float64, error)](#Correlation)\n* [func Covariance(data1, data2 Float64Data) (float64, error)](#Covariance)\n* [func CovariancePopulation(data1, data2 Float64Data) (float64, error)](#CovariancePopulation)\n* [func CumulativeSum(input Float64Data) ([]float64, error)](#CumulativeSum)\n* [func Entropy(input Float64Data) (float64, error)](#Entropy)\n* [func EuclideanDistance(dataPointX, dataPointY Float64Data) (distance float64, err error)](#EuclideanDistance)\n* [func ExpGeom(p float64) (exp float64, err error)](#ExpGeom)\n* [func GeometricMean(input Float64Data) (float64, error)](#GeometricMean)\n* [func HarmonicMean(input Float64Data) (float64, error)](#HarmonicMean)\n* [func InterQuartileRange(input Float64Data) (float64, error)](#InterQuartileRange)\n* [func ManhattanDistance(dataPointX, dataPointY Float64Data) (distance float64, err error)](#ManhattanDistance)\n* [func Max(input Float64Data) (max float64, err error)](#Max)\n* [func Mean(input Float64Data) (float64, error)](#Mean)\n* [func Median(input Float64Data) (median float64, err error)](#Median)\n* [func MedianAbsoluteDeviation(input Float64Data) (mad float64, err error)](#MedianAbsoluteDeviation)\n* [func MedianAbsoluteDeviationPopulation(input Float64Data) (mad float64, err error)](#MedianAbsoluteDeviationPopulation)\n* [func Midhinge(input Float64Data) (float64, error)](#Midhinge)\n* [func Min(input Float64Data) (min float64, err error)](#Min)\n* [func MinkowskiDistance(dataPointX, dataPointY Float64Data, lambda float64) (distance float64, err error)](#MinkowskiDistance)\n* [func Mode(input Float64Data) (mode []float64, err error)](#Mode)\n* [func Ncr(n, r int) int](#Ncr)\n* [func NormBoxMullerRvs(loc float64, scale float64, size int) []float64](#NormBoxMullerRvs)\n* [func NormCdf(x float64, loc float64, scale float64) float64](#NormCdf)\n* [func NormEntropy(loc float64, scale float64) float64](#NormEntropy)\n* [func NormFit(data []float64) [2]float64](#NormFit)\n* [func NormInterval(alpha float64, loc float64, scale float64) [2]float64](#NormInterval)\n* [func NormIsf(p float64, loc float64, scale float64) (x float64)](#NormIsf)\n* [func NormLogCdf(x float64, loc float64, scale float64) float64](#NormLogCdf)\n* [func NormLogPdf(x float64, loc float64, scale float64) float64](#NormLogPdf)\n* [func NormLogSf(x float64, loc float64, scale float64) float64](#NormLogSf)\n* [func NormMean(loc float64, scale float64) float64](#NormMean)\n* [func NormMedian(loc float64, scale float64) float64](#NormMedian)\n* [func NormMoment(n int, loc float64, scale float64) float64](#NormMoment)\n* [func NormPdf(x float64, loc float64, scale float64) float64](#NormPdf)\n* [func NormPpf(p float64, loc float64, scale float64) (x float64)](#NormPpf)\n* [func NormPpfRvs(loc float64, scale float64, size int) []float64](#NormPpfRvs)\n* [func NormSf(x float64, loc float64, scale float64) float64](#NormSf)\n* [func NormStats(loc float64, scale float64, moments string) []float64](#NormStats)\n* [func NormStd(loc float64, scale float64) float64](#NormStd)\n* [func NormVar(loc float64, scale float64) float64](#NormVar)\n* [func Pearson(data1, data2 Float64Data) (float64, error)](#Pearson)\n* [func Percentile(input Float64Data, percent float64) (percentile float64, err error)](#Percentile)\n* [func PercentileNearestRank(input Float64Data, percent float64) (percentile float64, err error)](#PercentileNearestRank)\n* [func PopulationVariance(input Float64Data) (pvar float64, err error)](#PopulationVariance)\n* [func ProbGeom(a int, b int, p float64) (prob float64, err error)](#ProbGeom)\n* [func Round(input float64, places int) (rounded float64, err error)](#Round)\n* [func Sample(input Float64Data, takenum int, replacement bool) ([]float64, error)](#Sample)\n* [func SampleVariance(input Float64Data) (svar float64, err error)](#SampleVariance)\n* [func Sigmoid(input Float64Data) ([]float64, error)](#Sigmoid)\n* [func SoftMax(input Float64Data) ([]float64, error)](#SoftMax)\n* [func StableSample(input Float64Data, takenum int) ([]float64, error)](#StableSample)\n* [func StandardDeviation(input Float64Data) (sdev float64, err error)](#StandardDeviation)\n* [func StandardDeviationPopulation(input Float64Data) (sdev float64, err error)](#StandardDeviationPopulation)\n* [func StandardDeviationSample(input Float64Data) (sdev float64, err error)](#StandardDeviationSample)\n* [func StdDevP(input Float64Data) (sdev float64, err error)](#StdDevP)\n* [func StdDevS(input Float64Data) (sdev float64, err error)](#StdDevS)\n* [func Sum(input Float64Data) (sum float64, err error)](#Sum)\n* [func Trimean(input Float64Data) (float64, error)](#Trimean)\n* [func VarGeom(p float64) (exp float64, err error)](#VarGeom)\n* [func VarP(input Float64Data) (sdev float64, err error)](#VarP)\n* [func VarS(input Float64Data) (sdev float64, err error)](#VarS)\n* [func Variance(input Float64Data) (sdev float64, err error)](#Variance)\n* [type Coordinate](#Coordinate)\n  * [func ExpReg(s []Coordinate) (regressions []Coordinate, err error)](#ExpReg)\n  * [func LinReg(s []Coordinate) (regressions []Coordinate, err error)](#LinReg)\n  * [func LogReg(s []Coordinate) (regressions []Coordinate, err error)](#LogReg)\n* [type Float64Data](#Float64Data)\n  * [func LoadRawData(raw interface{}) (f Float64Data)](#LoadRawData)\n  * [func (f Float64Data) AutoCorrelation(lags int) (float64, error)](#Float64Data.AutoCorrelation)\n  * [func (f Float64Data) Correlation(d Float64Data) (float64, error)](#Float64Data.Correlation)\n  * [func (f Float64Data) Covariance(d Float64Data) (float64, error)](#Float64Data.Covariance)\n  * [func (f Float64Data) CovariancePopulation(d Float64Data) (float64, error)](#Float64Data.CovariancePopulation)\n  * [func (f Float64Data) CumulativeSum() ([]float64, error)](#Float64Data.CumulativeSum)\n  * [func (f Float64Data) Entropy() (float64, error)](#Float64Data.Entropy)\n  * [func (f Float64Data) GeometricMean() (float64, error)](#Float64Data.GeometricMean)\n  * [func (f Float64Data) Get(i int) float64](#Float64Data.Get)\n  * [func (f Float64Data) HarmonicMean() (float64, error)](#Float64Data.HarmonicMean)\n  * [func (f Float64Data) InterQuartileRange() (float64, error)](#Float64Data.InterQuartileRange)\n  * [func (f Float64Data) Len() int](#Float64Data.Len)\n  * [func (f Float64Data) Less(i, j int) bool](#Float64Data.Less)\n  * [func (f Float64Data) Max() (float64, error)](#Float64Data.Max)\n  * [func (f Float64Data) Mean() (float64, error)](#Float64Data.Mean)\n  * [func (f Float64Data) Median() (float64, error)](#Float64Data.Median)\n  * [func (f Float64Data) MedianAbsoluteDeviation() (float64, error)](#Float64Data.MedianAbsoluteDeviation)\n  * [func (f Float64Data) MedianAbsoluteDeviationPopulation() (float64, error)](#Float64Data.MedianAbsoluteDeviationPopulation)\n  * [func (f Float64Data) Midhinge(d Float64Data) (float64, error)](#Float64Data.Midhinge)\n  * [func (f Float64Data) Min() (float64, error)](#Float64Data.Min)\n  * [func (f Float64Data) Mode() ([]float64, error)](#Float64Data.Mode)\n  * [func (f Float64Data) Pearson(d Float64Data) (float64, error)](#Float64Data.Pearson)\n  * [func (f Float64Data) Percentile(p float64) (float64, error)](#Float64Data.Percentile)\n  * [func (f Float64Data) PercentileNearestRank(p float64) (float64, error)](#Float64Data.PercentileNearestRank)\n  * [func (f Float64Data) PopulationVariance() (float64, error)](#Float64Data.PopulationVariance)\n  * [func (f Float64Data) Quartile(d Float64Data) (Quartiles, error)](#Float64Data.Quartile)\n  * [func (f Float64Data) QuartileOutliers() (Outliers, error)](#Float64Data.QuartileOutliers)\n  * [func (f Float64Data) Quartiles() (Quartiles, error)](#Float64Data.Quartiles)\n  * [func (f Float64Data) Sample(n int, r bool) ([]float64, error)](#Float64Data.Sample)\n  * [func (f Float64Data) SampleVariance() (float64, error)](#Float64Data.SampleVariance)\n  * [func (f Float64Data) Sigmoid() ([]float64, error)](#Float64Data.Sigmoid)\n  * [func (f Float64Data) SoftMax() ([]float64, error)](#Float64Data.SoftMax)\n  * [func (f Float64Data) StandardDeviation() (float64, error)](#Float64Data.StandardDeviation)\n  * [func (f Float64Data) StandardDeviationPopulation() (float64, error)](#Float64Data.StandardDeviationPopulation)\n  * [func (f Float64Data) StandardDeviationSample() (float64, error)](#Float64Data.StandardDeviationSample)\n  * [func (f Float64Data) Sum() (float64, error)](#Float64Data.Sum)\n  * [func (f Float64Data) Swap(i, j int)](#Float64Data.Swap)\n  * [func (f Float64Data) Trimean(d Float64Data) (float64, error)](#Float64Data.Trimean)\n  * [func (f Float64Data) Variance() (float64, error)](#Float64Data.Variance)\n* [type Outliers](#Outliers)\n  * [func QuartileOutliers(input Float64Data) (Outliers, error)](#QuartileOutliers)\n* [type Quartiles](#Quartiles)\n  * [func Quartile(input Float64Data) (Quartiles, error)](#Quartile)\n* [type Series](#Series)\n  * [func ExponentialRegression(s Series) (regressions Series, err error)](#ExponentialRegression)\n  * [func LinearRegression(s Series) (regressions Series, err error)](#LinearRegression)\n  * [func LogarithmicRegression(s Series) (regressions Series, err error)](#LogarithmicRegression)\n\n#### <a name=\"pkg-examples\">Examples</a>\n* [AutoCorrelation](#example_AutoCorrelation)\n* [ChebyshevDistance](#example_ChebyshevDistance)\n* [Correlation](#example_Correlation)\n* [CumulativeSum](#example_CumulativeSum)\n* [Entropy](#example_Entropy)\n* [ExpGeom](#example_ExpGeom)\n* [LinearRegression](#example_LinearRegression)\n* [LoadRawData](#example_LoadRawData)\n* [Max](#example_Max)\n* [Median](#example_Median)\n* [Min](#example_Min)\n* [ProbGeom](#example_ProbGeom)\n* [Round](#example_Round)\n* [Sigmoid](#example_Sigmoid)\n* [SoftMax](#example_SoftMax)\n* [Sum](#example_Sum)\n* [VarGeom](#example_VarGeom)\n\n#### <a name=\"pkg-files\">Package files</a>\n[correlation.go](/src/github.com/montanaflynn/stats/correlation.go) [cumulative_sum.go](/src/github.com/montanaflynn/stats/cumulative_sum.go) [data.go](/src/github.com/montanaflynn/stats/data.go) [deviation.go](/src/github.com/montanaflynn/stats/deviation.go) [distances.go](/src/github.com/montanaflynn/stats/distances.go) [doc.go](/src/github.com/montanaflynn/stats/doc.go) [entropy.go](/src/github.com/montanaflynn/stats/entropy.go) [errors.go](/src/github.com/montanaflynn/stats/errors.go) [geometric_distribution.go](/src/github.com/montanaflynn/stats/geometric_distribution.go) [legacy.go](/src/github.com/montanaflynn/stats/legacy.go) [load.go](/src/github.com/montanaflynn/stats/load.go) [max.go](/src/github.com/montanaflynn/stats/max.go) [mean.go](/src/github.com/montanaflynn/stats/mean.go) [median.go](/src/github.com/montanaflynn/stats/median.go) [min.go](/src/github.com/montanaflynn/stats/min.go) [mode.go](/src/github.com/montanaflynn/stats/mode.go) [norm.go](/src/github.com/montanaflynn/stats/norm.go) [outlier.go](/src/github.com/montanaflynn/stats/outlier.go) [percentile.go](/src/github.com/montanaflynn/stats/percentile.go) [quartile.go](/src/github.com/montanaflynn/stats/quartile.go) [ranksum.go](/src/github.com/montanaflynn/stats/ranksum.go) [regression.go](/src/github.com/montanaflynn/stats/regression.go) [round.go](/src/github.com/montanaflynn/stats/round.go) [sample.go](/src/github.com/montanaflynn/stats/sample.go) [sigmoid.go](/src/github.com/montanaflynn/stats/sigmoid.go) [softmax.go](/src/github.com/montanaflynn/stats/softmax.go) [sum.go](/src/github.com/montanaflynn/stats/sum.go) [util.go](/src/github.com/montanaflynn/stats/util.go) [variance.go](/src/github.com/montanaflynn/stats/variance.go) \n\n\n\n## <a name=\"pkg-variables\">Variables</a>\n``` go\nvar (\n    // ErrEmptyInput Input must not be empty\n    ErrEmptyInput = statsError{\"Input must not be empty.\"}\n    // ErrNaN Not a number\n    ErrNaN = statsError{\"Not a number.\"}\n    // ErrNegative Must not contain negative values\n    ErrNegative = statsError{\"Must not contain negative values.\"}\n    // ErrZero Must not contain zero values\n    ErrZero = statsError{\"Must not contain zero values.\"}\n    // ErrBounds Input is outside of range\n    ErrBounds = statsError{\"Input is outside of range.\"}\n    // ErrSize Must be the same length\n    ErrSize = statsError{\"Must be the same length.\"}\n    // ErrInfValue Value is infinite\n    ErrInfValue = statsError{\"Value is infinite.\"}\n    // ErrYCoord Y Value must be greater than zero\n    ErrYCoord = statsError{\"Y Value must be greater than zero.\"}\n)\n```\nThese are the package-wide error values.\nAll error identification should use these values.\n<a href=\"https://github.com/golang/go/wiki/Errors#naming\">https://github.com/golang/go/wiki/Errors#naming</a>\n\n``` go\nvar (\n    EmptyInputErr = ErrEmptyInput\n    NaNErr        = ErrNaN\n    NegativeErr   = ErrNegative\n    ZeroErr       = ErrZero\n    BoundsErr     = ErrBounds\n    SizeErr       = ErrSize\n    InfValue      = ErrInfValue\n    YCoordErr     = ErrYCoord\n    EmptyInput    = ErrEmptyInput\n)\n```\nLegacy error names that didn't start with Err\n\n\n\n## <a name=\"AutoCorrelation\">func</a> [AutoCorrelation](/correlation.go?s=853:918#L38)\n``` go\nfunc AutoCorrelation(data Float64Data, lags int) (float64, error)\n```\nAutoCorrelation is the correlation of a signal with a delayed copy of itself as a function of delay\n\n\n\n## <a name=\"ChebyshevDistance\">func</a> [ChebyshevDistance](/distances.go?s=368:456#L20)\n``` go\nfunc ChebyshevDistance(dataPointX, dataPointY Float64Data) (distance float64, err error)\n```\nChebyshevDistance computes the Chebyshev distance between two data sets\n\n\n\n## <a name=\"Correlation\">func</a> [Correlation](/correlation.go?s=112:171#L8)\n``` go\nfunc Correlation(data1, data2 Float64Data) (float64, error)\n```\nCorrelation describes the degree of relationship between two sets of data\n\n\n\n## <a name=\"Covariance\">func</a> [Covariance](/variance.go?s=1284:1342#L53)\n``` go\nfunc Covariance(data1, data2 Float64Data) (float64, error)\n```\nCovariance is a measure of how much two sets of data change\n\n\n\n## <a name=\"CovariancePopulation\">func</a> [CovariancePopulation](/variance.go?s=1864:1932#L81)\n``` go\nfunc CovariancePopulation(data1, data2 Float64Data) (float64, error)\n```\nCovariancePopulation computes covariance for entire population between two variables.\n\n\n\n## <a name=\"CumulativeSum\">func</a> [CumulativeSum](/cumulative_sum.go?s=81:137#L4)\n``` go\nfunc CumulativeSum(input Float64Data) ([]float64, error)\n```\nCumulativeSum calculates the cumulative sum of the input slice\n\n\n\n## <a name=\"Entropy\">func</a> [Entropy](/entropy.go?s=77:125#L6)\n``` go\nfunc Entropy(input Float64Data) (float64, error)\n```\nEntropy provides calculation of the entropy\n\n\n\n## <a name=\"EuclideanDistance\">func</a> [EuclideanDistance](/distances.go?s=836:924#L36)\n``` go\nfunc EuclideanDistance(dataPointX, dataPointY Float64Data) (distance float64, err error)\n```\nEuclideanDistance computes the Euclidean distance between two data sets\n\n\n\n## <a name=\"ExpGeom\">func</a> [ExpGeom](/geometric_distribution.go?s=652:700#L27)\n``` go\nfunc ExpGeom(p float64) (exp float64, err error)\n```\nProbGeom generates the expectation or average number of trials\nfor a geometric random variable with parameter p\n\n\n\n## <a name=\"GeometricMean\">func</a> [GeometricMean](/mean.go?s=319:373#L18)\n``` go\nfunc GeometricMean(input Float64Data) (float64, error)\n```\nGeometricMean gets the geometric mean for a slice of numbers\n\n\n\n## <a name=\"HarmonicMean\">func</a> [HarmonicMean](/mean.go?s=717:770#L40)\n``` go\nfunc HarmonicMean(input Float64Data) (float64, error)\n```\nHarmonicMean gets the harmonic mean for a slice of numbers\n\n\n\n## <a name=\"InterQuartileRange\">func</a> [InterQuartileRange](/quartile.go?s=821:880#L45)\n``` go\nfunc InterQuartileRange(input Float64Data) (float64, error)\n```\nInterQuartileRange finds the range between Q1 and Q3\n\n\n\n## <a name=\"ManhattanDistance\">func</a> [ManhattanDistance](/distances.go?s=1277:1365#L50)\n``` go\nfunc ManhattanDistance(dataPointX, dataPointY Float64Data) (distance float64, err error)\n```\nManhattanDistance computes the Manhattan distance between two data sets\n\n\n\n## <a name=\"Max\">func</a> [Max](/max.go?s=78:130#L8)\n``` go\nfunc Max(input Float64Data) (max float64, err error)\n```\nMax finds the highest number in a slice\n\n\n\n## <a name=\"Mean\">func</a> [Mean](/mean.go?s=77:122#L6)\n``` go\nfunc Mean(input Float64Data) (float64, error)\n```\nMean gets the average of a slice of numbers\n\n\n\n## <a name=\"Median\">func</a> [Median](/median.go?s=85:143#L6)\n``` go\nfunc Median(input Float64Data) (median float64, err error)\n```\nMedian gets the median number in a slice of numbers\n\n\n\n## <a name=\"MedianAbsoluteDeviation\">func</a> [MedianAbsoluteDeviation](/deviation.go?s=125:197#L6)\n``` go\nfunc MedianAbsoluteDeviation(input Float64Data) (mad float64, err error)\n```\nMedianAbsoluteDeviation finds the median of the absolute deviations from the dataset median\n\n\n\n## <a name=\"MedianAbsoluteDeviationPopulation\">func</a> [MedianAbsoluteDeviationPopulation](/deviation.go?s=360:442#L11)\n``` go\nfunc MedianAbsoluteDeviationPopulation(input Float64Data) (mad float64, err error)\n```\nMedianAbsoluteDeviationPopulation finds the median of the absolute deviations from the population median\n\n\n\n## <a name=\"Midhinge\">func</a> [Midhinge](/quartile.go?s=1075:1124#L55)\n``` go\nfunc Midhinge(input Float64Data) (float64, error)\n```\nMidhinge finds the average of the first and third quartiles\n\n\n\n## <a name=\"Min\">func</a> [Min](/min.go?s=78:130#L6)\n``` go\nfunc Min(input Float64Data) (min float64, err error)\n```\nMin finds the lowest number in a set of data\n\n\n\n## <a name=\"MinkowskiDistance\">func</a> [MinkowskiDistance](/distances.go?s=2152:2256#L75)\n``` go\nfunc MinkowskiDistance(dataPointX, dataPointY Float64Data, lambda float64) (distance float64, err error)\n```\nMinkowskiDistance computes the Minkowski distance between two data sets\n\nArguments:\n\n\n\tdataPointX: First set of data points\n\tdataPointY: Second set of data points. Length of both data\n\t            sets must be equal.\n\tlambda:     aka p or city blocks; With lambda = 1\n\t            returned distance is manhattan distance and\n\t            lambda = 2; it is euclidean distance. Lambda\n\t            reaching to infinite - distance would be chebysev\n\t            distance.\n\nReturn:\n\n\n\tDistance or error\n\n\n\n## <a name=\"Mode\">func</a> [Mode](/mode.go?s=85:141#L4)\n``` go\nfunc Mode(input Float64Data) (mode []float64, err error)\n```\nMode gets the mode [most frequent value(s)] of a slice of float64s\n\n\n\n## <a name=\"Ncr\">func</a> [Ncr](/norm.go?s=7384:7406#L239)\n``` go\nfunc Ncr(n, r int) int\n```\nNcr is an N choose R algorithm.\nAaron Cannon's algorithm.\n\n\n\n## <a name=\"NormBoxMullerRvs\">func</a> [NormBoxMullerRvs](/norm.go?s=667:736#L23)\n``` go\nfunc NormBoxMullerRvs(loc float64, scale float64, size int) []float64\n```\nNormBoxMullerRvs generates random variates using the Box–Muller transform.\nFor more information please visit: <a href=\"http://mathworld.wolfram.com/Box-MullerTransformation.html\">http://mathworld.wolfram.com/Box-MullerTransformation.html</a>\n\n\n\n## <a name=\"NormCdf\">func</a> [NormCdf](/norm.go?s=1826:1885#L52)\n``` go\nfunc NormCdf(x float64, loc float64, scale float64) float64\n```\nNormCdf is the cumulative distribution function.\n\n\n\n## <a name=\"NormEntropy\">func</a> [NormEntropy](/norm.go?s=5773:5825#L180)\n``` go\nfunc NormEntropy(loc float64, scale float64) float64\n```\nNormEntropy is the differential entropy of the RV.\n\n\n\n## <a name=\"NormFit\">func</a> [NormFit](/norm.go?s=6058:6097#L187)\n``` go\nfunc NormFit(data []float64) [2]float64\n```\nNormFit returns the maximum likelihood estimators for the Normal Distribution.\nTakes array of float64 values.\nReturns array of Mean followed by Standard Deviation.\n\n\n\n## <a name=\"NormInterval\">func</a> [NormInterval](/norm.go?s=6976:7047#L221)\n``` go\nfunc NormInterval(alpha float64, loc float64, scale float64) [2]float64\n```\nNormInterval finds endpoints of the range that contains alpha percent of the distribution.\n\n\n\n## <a name=\"NormIsf\">func</a> [NormIsf](/norm.go?s=4330:4393#L137)\n``` go\nfunc NormIsf(p float64, loc float64, scale float64) (x float64)\n```\nNormIsf is the inverse survival function (inverse of sf).\n\n\n\n## <a name=\"NormLogCdf\">func</a> [NormLogCdf](/norm.go?s=2016:2078#L57)\n``` go\nfunc NormLogCdf(x float64, loc float64, scale float64) float64\n```\nNormLogCdf is the log of the cumulative distribution function.\n\n\n\n## <a name=\"NormLogPdf\">func</a> [NormLogPdf](/norm.go?s=1590:1652#L47)\n``` go\nfunc NormLogPdf(x float64, loc float64, scale float64) float64\n```\nNormLogPdf is the log of the probability density function.\n\n\n\n## <a name=\"NormLogSf\">func</a> [NormLogSf](/norm.go?s=2423:2484#L67)\n``` go\nfunc NormLogSf(x float64, loc float64, scale float64) float64\n```\nNormLogSf is the log of the survival function.\n\n\n\n## <a name=\"NormMean\">func</a> [NormMean](/norm.go?s=6560:6609#L206)\n``` go\nfunc NormMean(loc float64, scale float64) float64\n```\nNormMean is the mean/expected value of the distribution.\n\n\n\n## <a name=\"NormMedian\">func</a> [NormMedian](/norm.go?s=6431:6482#L201)\n``` go\nfunc NormMedian(loc float64, scale float64) float64\n```\nNormMedian is the median of the distribution.\n\n\n\n## <a name=\"NormMoment\">func</a> [NormMoment](/norm.go?s=4694:4752#L146)\n``` go\nfunc NormMoment(n int, loc float64, scale float64) float64\n```\nNormMoment approximates the non-central (raw) moment of order n.\nFor more information please visit: <a href=\"https://math.stackexchange.com/questions/1945448/methods-for-finding-raw-moments-of-the-normal-distribution\">https://math.stackexchange.com/questions/1945448/methods-for-finding-raw-moments-of-the-normal-distribution</a>\n\n\n\n## <a name=\"NormPdf\">func</a> [NormPdf](/norm.go?s=1357:1416#L42)\n``` go\nfunc NormPdf(x float64, loc float64, scale float64) float64\n```\nNormPdf is the probability density function.\n\n\n\n## <a name=\"NormPpf\">func</a> [NormPpf](/norm.go?s=2854:2917#L75)\n``` go\nfunc NormPpf(p float64, loc float64, scale float64) (x float64)\n```\nNormPpf is the point percentile function.\nThis is based on Peter John Acklam's inverse normal CDF.\nalgorithm: <a href=\"http://home.online.no/~pjacklam/notes/invnorm/\">http://home.online.no/~pjacklam/notes/invnorm/</a> (no longer visible).\nFor more information please visit: <a href=\"https://stackedboxes.org/2017/05/01/acklams-normal-quantile-function/\">https://stackedboxes.org/2017/05/01/acklams-normal-quantile-function/</a>\n\n\n\n## <a name=\"NormPpfRvs\">func</a> [NormPpfRvs](/norm.go?s=247:310#L12)\n``` go\nfunc NormPpfRvs(loc float64, scale float64, size int) []float64\n```\nNormPpfRvs generates random variates using the Point Percentile Function.\nFor more information please visit: <a href=\"https://demonstrations.wolfram.com/TheMethodOfInverseTransforms/\">https://demonstrations.wolfram.com/TheMethodOfInverseTransforms/</a>\n\n\n\n## <a name=\"NormSf\">func</a> [NormSf](/norm.go?s=2250:2308#L62)\n``` go\nfunc NormSf(x float64, loc float64, scale float64) float64\n```\nNormSf is the survival function (also defined as 1 - cdf, but sf is sometimes more accurate).\n\n\n\n## <a name=\"NormStats\">func</a> [NormStats](/norm.go?s=5277:5345#L162)\n``` go\nfunc NormStats(loc float64, scale float64, moments string) []float64\n```\nNormStats returns the mean, variance, skew, and/or kurtosis.\nMean(‘m’), variance(‘v’), skew(‘s’), and/or kurtosis(‘k’).\nTakes string containing any of 'mvsk'.\nReturns array of m v s k in that order.\n\n\n\n## <a name=\"NormStd\">func</a> [NormStd](/norm.go?s=6814:6862#L216)\n``` go\nfunc NormStd(loc float64, scale float64) float64\n```\nNormStd is the standard deviation of the distribution.\n\n\n\n## <a name=\"NormVar\">func</a> [NormVar](/norm.go?s=6675:6723#L211)\n``` go\nfunc NormVar(loc float64, scale float64) float64\n```\nNormVar is the variance of the distribution.\n\n\n\n## <a name=\"Pearson\">func</a> [Pearson](/correlation.go?s=655:710#L33)\n``` go\nfunc Pearson(data1, data2 Float64Data) (float64, error)\n```\nPearson calculates the Pearson product-moment correlation coefficient between two variables\n\n\n\n## <a name=\"Percentile\">func</a> [Percentile](/percentile.go?s=98:181#L8)\n``` go\nfunc Percentile(input Float64Data, percent float64) (percentile float64, err error)\n```\nPercentile finds the relative standing in a slice of floats\n\n\n\n## <a name=\"PercentileNearestRank\">func</a> [PercentileNearestRank](/percentile.go?s=1079:1173#L54)\n``` go\nfunc PercentileNearestRank(input Float64Data, percent float64) (percentile float64, err error)\n```\nPercentileNearestRank finds the relative standing in a slice of floats using the Nearest Rank method\n\n\n\n## <a name=\"PopulationVariance\">func</a> [PopulationVariance](/variance.go?s=828:896#L31)\n``` go\nfunc PopulationVariance(input Float64Data) (pvar float64, err error)\n```\nPopulationVariance finds the amount of variance within a population\n\n\n\n## <a name=\"ProbGeom\">func</a> [ProbGeom](/geometric_distribution.go?s=258:322#L10)\n``` go\nfunc ProbGeom(a int, b int, p float64) (prob float64, err error)\n```\nProbGeom generates the probability for a geometric random variable\nwith parameter p to achieve success in the interval of [a, b] trials\nSee <a href=\"https://en.wikipedia.org/wiki/Geometric_distribution\">https://en.wikipedia.org/wiki/Geometric_distribution</a> for more information\n\n\n\n## <a name=\"Round\">func</a> [Round](/round.go?s=88:154#L6)\n``` go\nfunc Round(input float64, places int) (rounded float64, err error)\n```\nRound a float to a specific decimal place or precision\n\n\n\n## <a name=\"Sample\">func</a> [Sample](/sample.go?s=112:192#L9)\n``` go\nfunc Sample(input Float64Data, takenum int, replacement bool) ([]float64, error)\n```\nSample returns sample from input with replacement or without\n\n\n\n## <a name=\"SampleVariance\">func</a> [SampleVariance](/variance.go?s=1058:1122#L42)\n``` go\nfunc SampleVariance(input Float64Data) (svar float64, err error)\n```\nSampleVariance finds the amount of variance within a sample\n\n\n\n## <a name=\"Sigmoid\">func</a> [Sigmoid](/sigmoid.go?s=228:278#L9)\n``` go\nfunc Sigmoid(input Float64Data) ([]float64, error)\n```\nSigmoid returns the input values in the range of -1 to 1\nalong the sigmoid or s-shaped curve, commonly used in\nmachine learning while training neural networks as an\nactivation function.\n\n\n\n## <a name=\"SoftMax\">func</a> [SoftMax](/softmax.go?s=206:256#L8)\n``` go\nfunc SoftMax(input Float64Data) ([]float64, error)\n```\nSoftMax returns the input values in the range of 0 to 1\nwith sum of all the probabilities being equal to one. It\nis commonly used in machine learning neural networks.\n\n\n\n## <a name=\"StableSample\">func</a> [StableSample](/sample.go?s=974:1042#L50)\n``` go\nfunc StableSample(input Float64Data, takenum int) ([]float64, error)\n```\nStableSample like stable sort, it returns samples from input while keeps the order of original data.\n\n\n\n## <a name=\"StandardDeviation\">func</a> [StandardDeviation](/deviation.go?s=695:762#L27)\n``` go\nfunc StandardDeviation(input Float64Data) (sdev float64, err error)\n```\nStandardDeviation the amount of variation in the dataset\n\n\n\n## <a name=\"StandardDeviationPopulation\">func</a> [StandardDeviationPopulation](/deviation.go?s=892:969#L32)\n``` go\nfunc StandardDeviationPopulation(input Float64Data) (sdev float64, err error)\n```\nStandardDeviationPopulation finds the amount of variation from the population\n\n\n\n## <a name=\"StandardDeviationSample\">func</a> [StandardDeviationSample](/deviation.go?s=1250:1323#L46)\n``` go\nfunc StandardDeviationSample(input Float64Data) (sdev float64, err error)\n```\nStandardDeviationSample finds the amount of variation from a sample\n\n\n\n## <a name=\"StdDevP\">func</a> [StdDevP](/legacy.go?s=339:396#L14)\n``` go\nfunc StdDevP(input Float64Data) (sdev float64, err error)\n```\nStdDevP is a shortcut to StandardDeviationPopulation\n\n\n\n## <a name=\"StdDevS\">func</a> [StdDevS](/legacy.go?s=497:554#L19)\n``` go\nfunc StdDevS(input Float64Data) (sdev float64, err error)\n```\nStdDevS is a shortcut to StandardDeviationSample\n\n\n\n## <a name=\"Sum\">func</a> [Sum](/sum.go?s=78:130#L6)\n``` go\nfunc Sum(input Float64Data) (sum float64, err error)\n```\nSum adds all the numbers of a slice together\n\n\n\n## <a name=\"Trimean\">func</a> [Trimean](/quartile.go?s=1320:1368#L65)\n``` go\nfunc Trimean(input Float64Data) (float64, error)\n```\nTrimean finds the average of the median and the midhinge\n\n\n\n## <a name=\"VarGeom\">func</a> [VarGeom](/geometric_distribution.go?s=885:933#L37)\n``` go\nfunc VarGeom(p float64) (exp float64, err error)\n```\nProbGeom generates the variance for number for a\ngeometric random variable with parameter p\n\n\n\n## <a name=\"VarP\">func</a> [VarP](/legacy.go?s=59:113#L4)\n``` go\nfunc VarP(input Float64Data) (sdev float64, err error)\n```\nVarP is a shortcut to PopulationVariance\n\n\n\n## <a name=\"VarS\">func</a> [VarS](/legacy.go?s=193:247#L9)\n``` go\nfunc VarS(input Float64Data) (sdev float64, err error)\n```\nVarS is a shortcut to SampleVariance\n\n\n\n## <a name=\"Variance\">func</a> [Variance](/variance.go?s=659:717#L26)\n``` go\nfunc Variance(input Float64Data) (sdev float64, err error)\n```\nVariance the amount of variation in the dataset\n\n\n\n\n## <a name=\"Coordinate\">type</a> [Coordinate](/regression.go?s=143:183#L9)\n``` go\ntype Coordinate struct {\n    X, Y float64\n}\n\n```\nCoordinate holds the data in a series\n\n\n\n\n\n\n\n### <a name=\"ExpReg\">func</a> [ExpReg](/legacy.go?s=791:856#L29)\n``` go\nfunc ExpReg(s []Coordinate) (regressions []Coordinate, err error)\n```\nExpReg is a shortcut to ExponentialRegression\n\n\n### <a name=\"LinReg\">func</a> [LinReg](/legacy.go?s=643:708#L24)\n``` go\nfunc LinReg(s []Coordinate) (regressions []Coordinate, err error)\n```\nLinReg is a shortcut to LinearRegression\n\n\n### <a name=\"LogReg\">func</a> [LogReg](/legacy.go?s=944:1009#L34)\n``` go\nfunc LogReg(s []Coordinate) (regressions []Coordinate, err error)\n```\nLogReg is a shortcut to LogarithmicRegression\n\n\n\n\n\n## <a name=\"Float64Data\">type</a> [Float64Data](/data.go?s=80:106#L4)\n``` go\ntype Float64Data []float64\n```\nFloat64Data is a named type for []float64 with helper methods\n\n\n\n\n\n\n\n### <a name=\"LoadRawData\">func</a> [LoadRawData](/load.go?s=145:194#L12)\n``` go\nfunc LoadRawData(raw interface{}) (f Float64Data)\n```\nLoadRawData parses and converts a slice of mixed data types to floats\n\n\n\n\n\n### <a name=\"Float64Data.AutoCorrelation\">func</a> (Float64Data) [AutoCorrelation](/data.go?s=3257:3320#L91)\n``` go\nfunc (f Float64Data) AutoCorrelation(lags int) (float64, error)\n```\nAutoCorrelation is the correlation of a signal with a delayed copy of itself as a function of delay\n\n\n\n\n### <a name=\"Float64Data.Correlation\">func</a> (Float64Data) [Correlation](/data.go?s=3058:3122#L86)\n``` go\nfunc (f Float64Data) Correlation(d Float64Data) (float64, error)\n```\nCorrelation describes the degree of relationship between two sets of data\n\n\n\n\n### <a name=\"Float64Data.Covariance\">func</a> (Float64Data) [Covariance](/data.go?s=4801:4864#L141)\n``` go\nfunc (f Float64Data) Covariance(d Float64Data) (float64, error)\n```\nCovariance is a measure of how much two sets of data change\n\n\n\n\n### <a name=\"Float64Data.CovariancePopulation\">func</a> (Float64Data) [CovariancePopulation](/data.go?s=4983:5056#L146)\n``` go\nfunc (f Float64Data) CovariancePopulation(d Float64Data) (float64, error)\n```\nCovariancePopulation computes covariance for entire population between two variables\n\n\n\n\n### <a name=\"Float64Data.CumulativeSum\">func</a> (Float64Data) [CumulativeSum](/data.go?s=883:938#L28)\n``` go\nfunc (f Float64Data) CumulativeSum() ([]float64, error)\n```\nCumulativeSum returns the cumulative sum of the data\n\n\n\n\n### <a name=\"Float64Data.Entropy\">func</a> (Float64Data) [Entropy](/data.go?s=5480:5527#L162)\n``` go\nfunc (f Float64Data) Entropy() (float64, error)\n```\nEntropy provides calculation of the entropy\n\n\n\n\n### <a name=\"Float64Data.GeometricMean\">func</a> (Float64Data) [GeometricMean](/data.go?s=1332:1385#L40)\n``` go\nfunc (f Float64Data) GeometricMean() (float64, error)\n```\nGeometricMean returns the median of the data\n\n\n\n\n### <a name=\"Float64Data.Get\">func</a> (Float64Data) [Get](/data.go?s=129:168#L7)\n``` go\nfunc (f Float64Data) Get(i int) float64\n```\nGet item in slice\n\n\n\n\n### <a name=\"Float64Data.HarmonicMean\">func</a> (Float64Data) [HarmonicMean](/data.go?s=1460:1512#L43)\n``` go\nfunc (f Float64Data) HarmonicMean() (float64, error)\n```\nHarmonicMean returns the mode of the data\n\n\n\n\n### <a name=\"Float64Data.InterQuartileRange\">func</a> (Float64Data) [InterQuartileRange](/data.go?s=3755:3813#L106)\n``` go\nfunc (f Float64Data) InterQuartileRange() (float64, error)\n```\nInterQuartileRange finds the range between Q1 and Q3\n\n\n\n\n### <a name=\"Float64Data.Len\">func</a> (Float64Data) [Len](/data.go?s=217:247#L10)\n``` go\nfunc (f Float64Data) Len() int\n```\nLen returns length of slice\n\n\n\n\n### <a name=\"Float64Data.Less\">func</a> (Float64Data) [Less](/data.go?s=318:358#L13)\n``` go\nfunc (f Float64Data) Less(i, j int) bool\n```\nLess returns if one number is less than another\n\n\n\n\n### <a name=\"Float64Data.Max\">func</a> (Float64Data) [Max](/data.go?s=645:688#L22)\n``` go\nfunc (f Float64Data) Max() (float64, error)\n```\nMax returns the maximum number in the data\n\n\n\n\n### <a name=\"Float64Data.Mean\">func</a> (Float64Data) [Mean](/data.go?s=1005:1049#L31)\n``` go\nfunc (f Float64Data) Mean() (float64, error)\n```\nMean returns the mean of the data\n\n\n\n\n### <a name=\"Float64Data.Median\">func</a> (Float64Data) [Median](/data.go?s=1111:1157#L34)\n``` go\nfunc (f Float64Data) Median() (float64, error)\n```\nMedian returns the median of the data\n\n\n\n\n### <a name=\"Float64Data.MedianAbsoluteDeviation\">func</a> (Float64Data) [MedianAbsoluteDeviation](/data.go?s=1630:1693#L46)\n``` go\nfunc (f Float64Data) MedianAbsoluteDeviation() (float64, error)\n```\nMedianAbsoluteDeviation the median of the absolute deviations from the dataset median\n\n\n\n\n### <a name=\"Float64Data.MedianAbsoluteDeviationPopulation\">func</a> (Float64Data) [MedianAbsoluteDeviationPopulation](/data.go?s=1842:1915#L51)\n``` go\nfunc (f Float64Data) MedianAbsoluteDeviationPopulation() (float64, error)\n```\nMedianAbsoluteDeviationPopulation finds the median of the absolute deviations from the population median\n\n\n\n\n### <a name=\"Float64Data.Midhinge\">func</a> (Float64Data) [Midhinge](/data.go?s=3912:3973#L111)\n``` go\nfunc (f Float64Data) Midhinge(d Float64Data) (float64, error)\n```\nMidhinge finds the average of the first and third quartiles\n\n\n\n\n### <a name=\"Float64Data.Min\">func</a> (Float64Data) [Min](/data.go?s=536:579#L19)\n``` go\nfunc (f Float64Data) Min() (float64, error)\n```\nMin returns the minimum number in the data\n\n\n\n\n### <a name=\"Float64Data.Mode\">func</a> (Float64Data) [Mode](/data.go?s=1217:1263#L37)\n``` go\nfunc (f Float64Data) Mode() ([]float64, error)\n```\nMode returns the mode of the data\n\n\n\n\n### <a name=\"Float64Data.Pearson\">func</a> (Float64Data) [Pearson](/data.go?s=3455:3515#L96)\n``` go\nfunc (f Float64Data) Pearson(d Float64Data) (float64, error)\n```\nPearson calculates the Pearson product-moment correlation coefficient between two variables.\n\n\n\n\n### <a name=\"Float64Data.Percentile\">func</a> (Float64Data) [Percentile](/data.go?s=2696:2755#L76)\n``` go\nfunc (f Float64Data) Percentile(p float64) (float64, error)\n```\nPercentile finds the relative standing in a slice of floats\n\n\n\n\n### <a name=\"Float64Data.PercentileNearestRank\">func</a> (Float64Data) [PercentileNearestRank](/data.go?s=2869:2939#L81)\n``` go\nfunc (f Float64Data) PercentileNearestRank(p float64) (float64, error)\n```\nPercentileNearestRank finds the relative standing using the Nearest Rank method\n\n\n\n\n### <a name=\"Float64Data.PopulationVariance\">func</a> (Float64Data) [PopulationVariance](/data.go?s=4495:4553#L131)\n``` go\nfunc (f Float64Data) PopulationVariance() (float64, error)\n```\nPopulationVariance finds the amount of variance within a population\n\n\n\n\n### <a name=\"Float64Data.Quartile\">func</a> (Float64Data) [Quartile](/data.go?s=3610:3673#L101)\n``` go\nfunc (f Float64Data) Quartile(d Float64Data) (Quartiles, error)\n```\nQuartile returns the three quartile points from a slice of data\n\n\n\n\n### <a name=\"Float64Data.QuartileOutliers\">func</a> (Float64Data) [QuartileOutliers](/data.go?s=2542:2599#L71)\n``` go\nfunc (f Float64Data) QuartileOutliers() (Outliers, error)\n```\nQuartileOutliers finds the mild and extreme outliers\n\n\n\n\n### <a name=\"Float64Data.Quartiles\">func</a> (Float64Data) [Quartiles](/data.go?s=5628:5679#L167)\n``` go\nfunc (f Float64Data) Quartiles() (Quartiles, error)\n```\nQuartiles returns the three quartile points from instance of Float64Data\n\n\n\n\n### <a name=\"Float64Data.Sample\">func</a> (Float64Data) [Sample](/data.go?s=4208:4269#L121)\n``` go\nfunc (f Float64Data) Sample(n int, r bool) ([]float64, error)\n```\nSample returns sample from input with replacement or without\n\n\n\n\n### <a name=\"Float64Data.SampleVariance\">func</a> (Float64Data) [SampleVariance](/data.go?s=4652:4706#L136)\n``` go\nfunc (f Float64Data) SampleVariance() (float64, error)\n```\nSampleVariance finds the amount of variance within a sample\n\n\n\n\n### <a name=\"Float64Data.Sigmoid\">func</a> (Float64Data) [Sigmoid](/data.go?s=5169:5218#L151)\n``` go\nfunc (f Float64Data) Sigmoid() ([]float64, error)\n```\nSigmoid returns the input values along the sigmoid or s-shaped curve\n\n\n\n\n### <a name=\"Float64Data.SoftMax\">func</a> (Float64Data) [SoftMax](/data.go?s=5359:5408#L157)\n``` go\nfunc (f Float64Data) SoftMax() ([]float64, error)\n```\nSoftMax returns the input values in the range of 0 to 1\nwith sum of all the probabilities being equal to one.\n\n\n\n\n### <a name=\"Float64Data.StandardDeviation\">func</a> (Float64Data) [StandardDeviation](/data.go?s=2026:2083#L56)\n``` go\nfunc (f Float64Data) StandardDeviation() (float64, error)\n```\nStandardDeviation the amount of variation in the dataset\n\n\n\n\n### <a name=\"Float64Data.StandardDeviationPopulation\">func</a> (Float64Data) [StandardDeviationPopulation](/data.go?s=2199:2266#L61)\n``` go\nfunc (f Float64Data) StandardDeviationPopulation() (float64, error)\n```\nStandardDeviationPopulation finds the amount of variation from the population\n\n\n\n\n### <a name=\"Float64Data.StandardDeviationSample\">func</a> (Float64Data) [StandardDeviationSample](/data.go?s=2382:2445#L66)\n``` go\nfunc (f Float64Data) StandardDeviationSample() (float64, error)\n```\nStandardDeviationSample finds the amount of variation from a sample\n\n\n\n\n### <a name=\"Float64Data.Sum\">func</a> (Float64Data) [Sum](/data.go?s=764:807#L25)\n``` go\nfunc (f Float64Data) Sum() (float64, error)\n```\nSum returns the total of all the numbers in the data\n\n\n\n\n### <a name=\"Float64Data.Swap\">func</a> (Float64Data) [Swap](/data.go?s=425:460#L16)\n``` go\nfunc (f Float64Data) Swap(i, j int)\n```\nSwap switches out two numbers in slice\n\n\n\n\n### <a name=\"Float64Data.Trimean\">func</a> (Float64Data) [Trimean](/data.go?s=4059:4119#L116)\n``` go\nfunc (f Float64Data) Trimean(d Float64Data) (float64, error)\n```\nTrimean finds the average of the median and the midhinge\n\n\n\n\n### <a name=\"Float64Data.Variance\">func</a> (Float64Data) [Variance](/data.go?s=4350:4398#L126)\n``` go\nfunc (f Float64Data) Variance() (float64, error)\n```\nVariance the amount of variation in the dataset\n\n\n\n\n## <a name=\"Outliers\">type</a> [Outliers](/outlier.go?s=73:139#L4)\n``` go\ntype Outliers struct {\n    Mild    Float64Data\n    Extreme Float64Data\n}\n\n```\nOutliers holds mild and extreme outliers found in data\n\n\n\n\n\n\n\n### <a name=\"QuartileOutliers\">func</a> [QuartileOutliers](/outlier.go?s=197:255#L10)\n``` go\nfunc QuartileOutliers(input Float64Data) (Outliers, error)\n```\nQuartileOutliers finds the mild and extreme outliers\n\n\n\n\n\n## <a name=\"Quartiles\">type</a> [Quartiles](/quartile.go?s=75:136#L6)\n``` go\ntype Quartiles struct {\n    Q1 float64\n    Q2 float64\n    Q3 float64\n}\n\n```\nQuartiles holds the three quartile points\n\n\n\n\n\n\n\n### <a name=\"Quartile\">func</a> [Quartile](/quartile.go?s=205:256#L13)\n``` go\nfunc Quartile(input Float64Data) (Quartiles, error)\n```\nQuartile returns the three quartile points from a slice of data\n\n\n\n\n\n## <a name=\"Series\">type</a> [Series](/regression.go?s=76:100#L6)\n``` go\ntype Series []Coordinate\n```\nSeries is a container for a series of data\n\n\n\n\n\n\n\n### <a name=\"ExponentialRegression\">func</a> [ExponentialRegression](/regression.go?s=1089:1157#L50)\n``` go\nfunc ExponentialRegression(s Series) (regressions Series, err error)\n```\nExponentialRegression returns an exponential regression on data series\n\n\n### <a name=\"LinearRegression\">func</a> [LinearRegression](/regression.go?s=262:325#L14)\n``` go\nfunc LinearRegression(s Series) (regressions Series, err error)\n```\nLinearRegression finds the least squares linear regression on data series\n\n\n### <a name=\"LogarithmicRegression\">func</a> [LogarithmicRegression](/regression.go?s=1903:1971#L85)\n``` go\nfunc LogarithmicRegression(s Series) (regressions Series, err error)\n```\nLogarithmicRegression returns an logarithmic regression on data series\n\n\n\n\n\n\n\n\n\n- - -\nGenerated by [godoc2md](http://godoc.org/github.com/davecheney/godoc2md)\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0859375,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2014-2023 Montana Flynn (https://montanaflynn.com)\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.6494140625,
          "content": ".PHONY: all\n\ndefault: test lint\n\nformat: \n\tgo fmt .\n\ntest:\n\tgo test -race \n\t\ncheck: format test\n\nbenchmark:\n\tgo test -bench=. -benchmem\n\ncoverage:\n\tgo test -coverprofile=coverage.out\n\tgo tool cover -html=\"coverage.out\"\n\nlint: format\n\tgolangci-lint run .\n\ndocs:\n\tgodoc2md github.com/montanaflynn/stats | sed -e s#src/target/##g > DOCUMENTATION.md\n\nrelease:\n\tgit-chglog --output CHANGELOG.md --next-tag ${TAG}\n\tgit add CHANGELOG.md\n\tgit commit -m \"Update changelog with ${TAG} changes\"\n\tgit tag ${TAG}\n\tgit-chglog $(TAG) | tail -n +4 | gsed '1s/^/$(TAG)\\n/gm' > release-notes.txt\n\tgit push origin master ${TAG}\n\thub release create --copy -F release-notes.txt ${TAG}\n\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 11.0048828125,
          "content": "# Stats - Golang Statistics Package\n\n[![][action-svg]][action-url] [![][codecov-svg]][codecov-url] [![][goreport-svg]][goreport-url] [![][godoc-svg]][godoc-url] [![][pkggodev-svg]][pkggodev-url] [![][license-svg]][license-url]\n\nA well tested and comprehensive Golang statistics library / package / module with no dependencies.\n\nIf you have any suggestions, problems or bug reports please [create an issue](https://github.com/montanaflynn/stats/issues) and I'll do my best to accommodate you. In addition simply starring the repo would show your support for the project and be very much appreciated!\n\n## Installation\n\n```\ngo get github.com/montanaflynn/stats\n```\n\n## Example Usage\n\nAll the functions can be seen in [examples/main.go](examples/main.go) but here's a little taste:\n\n```go\n// start with some source data to use\ndata := []float64{1.0, 2.1, 3.2, 4.823, 4.1, 5.8}\n\n// you could also use different types like this\n// data := stats.LoadRawData([]int{1, 2, 3, 4, 5})\n// data := stats.LoadRawData([]interface{}{1.1, \"2\", 3})\n// etc...\n\nmedian, _ := stats.Median(data)\nfmt.Println(median) // 3.65\n\nroundedMedian, _ := stats.Round(median, 0)\nfmt.Println(roundedMedian) // 4\n```\n\n## Documentation\n\nThe entire API documentation is available on [GoDoc.org](http://godoc.org/github.com/montanaflynn/stats) or [pkg.go.dev](https://pkg.go.dev/github.com/montanaflynn/stats).\n\nYou can also view docs offline with the following commands:\n\n```\n# Command line\ngodoc .              # show all exported apis\ngodoc . Median       # show a single function\ngodoc -ex . Round    # show function with example\ngodoc . Float64Data  # show the type and methods\n\n# Local website\ngodoc -http=:4444    # start the godoc server on port 4444\nopen http://localhost:4444/pkg/github.com/montanaflynn/stats/\n```\n\nThe exported API is as follows:\n\n```go\nvar (\n    ErrEmptyInput = statsError{\"Input must not be empty.\"}\n    ErrNaN        = statsError{\"Not a number.\"}\n    ErrNegative   = statsError{\"Must not contain negative values.\"}\n    ErrZero       = statsError{\"Must not contain zero values.\"}\n    ErrBounds     = statsError{\"Input is outside of range.\"}\n    ErrSize       = statsError{\"Must be the same length.\"}\n    ErrInfValue   = statsError{\"Value is infinite.\"}\n    ErrYCoord     = statsError{\"Y Value must be greater than zero.\"}\n)\n\nfunc Round(input float64, places int) (rounded float64, err error) {}\n\ntype Float64Data []float64\n\nfunc LoadRawData(raw interface{}) (f Float64Data) {}\n\nfunc AutoCorrelation(data Float64Data, lags int) (float64, error) {}\nfunc ChebyshevDistance(dataPointX, dataPointY Float64Data) (distance float64, err error) {}\nfunc Correlation(data1, data2 Float64Data) (float64, error) {}\nfunc Covariance(data1, data2 Float64Data) (float64, error) {}\nfunc CovariancePopulation(data1, data2 Float64Data) (float64, error) {}\nfunc CumulativeSum(input Float64Data) ([]float64, error) {}\nfunc Describe(input Float64Data, allowNaN bool, percentiles *[]float64) (*Description, error) {}\nfunc DescribePercentileFunc(input Float64Data, allowNaN bool, percentiles *[]float64, percentileFunc func(Float64Data, float64) (float64, error)) (*Description, error) {}\nfunc Entropy(input Float64Data) (float64, error) {}\nfunc EuclideanDistance(dataPointX, dataPointY Float64Data) (distance float64, err error) {}\nfunc GeometricMean(input Float64Data) (float64, error) {}\nfunc HarmonicMean(input Float64Data) (float64, error) {}\nfunc InterQuartileRange(input Float64Data) (float64, error) {}\nfunc ManhattanDistance(dataPointX, dataPointY Float64Data) (distance float64, err error) {}\nfunc Max(input Float64Data) (max float64, err error) {}\nfunc Mean(input Float64Data) (float64, error) {}\nfunc Median(input Float64Data) (median float64, err error) {}\nfunc MedianAbsoluteDeviation(input Float64Data) (mad float64, err error) {}\nfunc MedianAbsoluteDeviationPopulation(input Float64Data) (mad float64, err error) {}\nfunc Midhinge(input Float64Data) (float64, error) {}\nfunc Min(input Float64Data) (min float64, err error) {}\nfunc MinkowskiDistance(dataPointX, dataPointY Float64Data, lambda float64) (distance float64, err error) {}\nfunc Mode(input Float64Data) (mode []float64, err error) {}\nfunc NormBoxMullerRvs(loc float64, scale float64, size int) []float64 {}\nfunc NormCdf(x float64, loc float64, scale float64) float64 {}\nfunc NormEntropy(loc float64, scale float64) float64 {}\nfunc NormFit(data []float64) [2]float64{}\nfunc NormInterval(alpha float64, loc float64,  scale float64 ) [2]float64 {}\nfunc NormIsf(p float64, loc float64, scale float64) (x float64) {}\nfunc NormLogCdf(x float64, loc float64, scale float64) float64 {}\nfunc NormLogPdf(x float64, loc float64, scale float64) float64 {}\nfunc NormLogSf(x float64, loc float64, scale float64) float64 {}\nfunc NormMean(loc float64, scale float64) float64 {}\nfunc NormMedian(loc float64, scale float64) float64 {}\nfunc NormMoment(n int, loc float64, scale float64) float64 {}\nfunc NormPdf(x float64, loc float64, scale float64) float64 {}\nfunc NormPpf(p float64, loc float64, scale float64) (x float64) {}\nfunc NormPpfRvs(loc float64, scale float64, size int) []float64 {}\nfunc NormSf(x float64, loc float64, scale float64) float64 {}\nfunc NormStats(loc float64, scale float64, moments string) []float64 {}\nfunc NormStd(loc float64, scale float64) float64 {}\nfunc NormVar(loc float64, scale float64) float64 {}\nfunc Pearson(data1, data2 Float64Data) (float64, error) {}\nfunc Percentile(input Float64Data, percent float64) (percentile float64, err error) {}\nfunc PercentileNearestRank(input Float64Data, percent float64) (percentile float64, err error) {}\nfunc PopulationVariance(input Float64Data) (pvar float64, err error) {}\nfunc Sample(input Float64Data, takenum int, replacement bool) ([]float64, error) {}\nfunc SampleVariance(input Float64Data) (svar float64, err error) {}\nfunc Sigmoid(input Float64Data) ([]float64, error) {}\nfunc SoftMax(input Float64Data) ([]float64, error) {}\nfunc StableSample(input Float64Data, takenum int) ([]float64, error) {}\nfunc StandardDeviation(input Float64Data) (sdev float64, err error) {}\nfunc StandardDeviationPopulation(input Float64Data) (sdev float64, err error) {}\nfunc StandardDeviationSample(input Float64Data) (sdev float64, err error) {}\nfunc StdDevP(input Float64Data) (sdev float64, err error) {}\nfunc StdDevS(input Float64Data) (sdev float64, err error) {}\nfunc Sum(input Float64Data) (sum float64, err error) {}\nfunc Trimean(input Float64Data) (float64, error) {}\nfunc VarP(input Float64Data) (sdev float64, err error) {}\nfunc VarS(input Float64Data) (sdev float64, err error) {}\nfunc Variance(input Float64Data) (sdev float64, err error) {}\nfunc ProbGeom(a int, b int, p float64) (prob float64, err error) {}\nfunc ExpGeom(p float64) (exp float64, err error) {}\nfunc VarGeom(p float64) (exp float64, err error) {}\n\ntype Coordinate struct {\n    X, Y float64\n}\n\ntype Series []Coordinate\n\nfunc ExponentialRegression(s Series) (regressions Series, err error) {}\nfunc LinearRegression(s Series) (regressions Series, err error) {}\nfunc LogarithmicRegression(s Series) (regressions Series, err error) {}\n\ntype Outliers struct {\n    Mild    Float64Data\n    Extreme Float64Data\n}\n\ntype Quartiles struct {\n    Q1 float64\n    Q2 float64\n    Q3 float64\n}\n\nfunc Quartile(input Float64Data) (Quartiles, error) {}\nfunc QuartileOutliers(input Float64Data) (Outliers, error) {}\n```\n\n## Contributing\n\nPull request are always welcome no matter how big or small. I've included a [Makefile](https://github.com/montanaflynn/stats/blob/master/Makefile) that has a lot of helper targets for common actions such as linting, testing, code coverage reporting and more.\n\n1. Fork the repo and clone your fork\n2. Create new branch (`git checkout -b some-thing`)\n3. Make the desired changes\n4. Ensure tests pass (`go test -cover` or `make test`)\n5. Run lint and fix problems (`go vet .` or `make lint`)\n6. Commit changes (`git commit -am 'Did something'`)\n7. Push branch (`git push origin some-thing`)\n8. Submit pull request\n\nTo make things as seamless as possible please also consider the following steps:\n\n- Update `examples/main.go` with a simple example of the new feature\n- Update `README.md` documentation section with any new exported API\n- Keep 100% code coverage (you can check with `make coverage`)\n- Squash commits into single units of work with `git rebase -i new-feature`\n\n## Releasing\n\nThis is not required by contributors and mostly here as a reminder to myself as the maintainer of this repo. To release a new version we should update the [CHANGELOG.md](/CHANGELOG.md) and [DOCUMENTATION.md](/DOCUMENTATION.md).\n\nFirst install the tools used to generate the markdown files and release:\n\n```\ngo install github.com/davecheney/godoc2md@latest\ngo install github.com/golangci/golangci-lint/cmd/golangci-lint@latest\nbrew tap git-chglog/git-chglog\nbrew install gnu-sed hub git-chglog\n```\n\nThen you can run these `make` directives:\n\n```\n# Generate DOCUMENTATION.md\nmake docs\n```\n\nThen we can create a [CHANGELOG.md](/CHANGELOG.md) a new git tag and a github release:\n\n```\nmake release TAG=v0.x.x\n```\n\nTo authenticate `hub` for the release you will need to create a personal access token and use it as the password when it's requested.\n\n## MIT License\n\nCopyright (c) 2014-2023 Montana Flynn (https://montanaflynn.com)\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORpublicS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n[action-url]: https://github.com/montanaflynn/stats/actions\n[action-svg]: https://img.shields.io/github/actions/workflow/status/montanaflynn/stats/go.yml\n\n[codecov-url]: https://app.codecov.io/gh/montanaflynn/stats\n[codecov-svg]: https://img.shields.io/codecov/c/github/montanaflynn/stats?token=wnw8dActnH\n\n[goreport-url]: https://goreportcard.com/report/github.com/montanaflynn/stats\n[goreport-svg]: https://goreportcard.com/badge/github.com/montanaflynn/stats\n\n[godoc-url]: https://godoc.org/github.com/montanaflynn/stats\n[godoc-svg]: https://godoc.org/github.com/montanaflynn/stats?status.svg\n\n[pkggodev-url]: https://pkg.go.dev/github.com/montanaflynn/stats\n[pkggodev-svg]: https://gistcdn.githack.com/montanaflynn/b02f1d78d8c0de8435895d7e7cd0d473/raw/17f2a5a69f1323ecd42c00e0683655da96d9ecc8/badge.svg\n\n[license-url]: https://github.com/montanaflynn/stats/blob/master/LICENSE\n[license-svg]: https://img.shields.io/badge/license-MIT-blue.svg\n"
        },
        {
          "name": "correlation.go",
          "type": "blob",
          "size": 1.287109375,
          "content": "package stats\n\nimport (\n\t\"math\"\n)\n\n// Correlation describes the degree of relationship between two sets of data\nfunc Correlation(data1, data2 Float64Data) (float64, error) {\n\n\tl1 := data1.Len()\n\tl2 := data2.Len()\n\n\tif l1 == 0 || l2 == 0 {\n\t\treturn math.NaN(), EmptyInputErr\n\t}\n\n\tif l1 != l2 {\n\t\treturn math.NaN(), SizeErr\n\t}\n\n\tsdev1, _ := StandardDeviationPopulation(data1)\n\tsdev2, _ := StandardDeviationPopulation(data2)\n\n\tif sdev1 == 0 || sdev2 == 0 {\n\t\treturn 0, nil\n\t}\n\n\tcovp, _ := CovariancePopulation(data1, data2)\n\treturn covp / (sdev1 * sdev2), nil\n}\n\n// Pearson calculates the Pearson product-moment correlation coefficient between two variables\nfunc Pearson(data1, data2 Float64Data) (float64, error) {\n\treturn Correlation(data1, data2)\n}\n\n// AutoCorrelation is the correlation of a signal with a delayed copy of itself as a function of delay\nfunc AutoCorrelation(data Float64Data, lags int) (float64, error) {\n\tif len(data) < 1 {\n\t\treturn 0, EmptyInputErr\n\t}\n\n\tmean, _ := Mean(data)\n\n\tvar result, q float64\n\n\tfor i := 0; i < lags; i++ {\n\t\tv := (data[0] - mean) * (data[0] - mean)\n\t\tfor i := 1; i < len(data); i++ {\n\t\t\tdelta0 := data[i-1] - mean\n\t\t\tdelta1 := data[i] - mean\n\t\t\tq += (delta0*delta1 - q) / float64(i+1)\n\t\t\tv += (delta1*delta1 - v) / float64(i+1)\n\t\t}\n\n\t\tresult = q / v\n\t}\n\n\treturn result, nil\n}\n"
        },
        {
          "name": "correlation_test.go",
          "type": "blob",
          "size": 1.94921875,
          "content": "package stats_test\n\nimport (\n\t\"fmt\"\n\t\"math\"\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc ExampleCorrelation() {\n\ts1 := []float64{1, 2, 3, 4, 5}\n\ts2 := []float64{1, 2, 3, 5, 6}\n\ta, _ := stats.Correlation(s1, s2)\n\trounded, _ := stats.Round(a, 5)\n\tfmt.Println(rounded)\n\t// Output: 0.99124\n}\n\nfunc TestCorrelation(t *testing.T) {\n\ts1 := []float64{1, 2, 3, 4, 5}\n\ts2 := []float64{10, -51.2, 8}\n\ts3 := []float64{1, 2, 3, 5, 6}\n\ts4 := []float64{}\n\ts5 := []float64{0, 0, 0}\n\ttestCases := []struct {\n\t\tname   string\n\t\tinput  [][]float64\n\t\toutput float64\n\t\terr    error\n\t}{\n\t\t{\"Empty Slice Error\", [][]float64{s4, s4}, math.NaN(), stats.EmptyInputErr},\n\t\t{\"Different Length Error\", [][]float64{s1, s2}, math.NaN(), stats.SizeErr},\n\t\t{\"Correlation Value\", [][]float64{s1, s3}, 0.9912407071619302, nil},\n\t\t{\"Same Input Value\", [][]float64{s5, s5}, 0.00, nil},\n\t}\n\tfor _, tc := range testCases {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\ta, err := stats.Correlation(tc.input[0], tc.input[1])\n\t\t\tif err != nil {\n\t\t\t\tif err != tc.err {\n\t\t\t\t\tt.Errorf(\"Should have returned error %s\", tc.err)\n\t\t\t\t}\n\t\t\t} else if !veryclose(a, tc.output) {\n\t\t\t\tt.Errorf(\"Result %.08f should be %.08f\", a, tc.output)\n\t\t\t}\n\t\t\ta2, err2 := stats.Pearson(tc.input[0], tc.input[1])\n\t\t\tif err2 != nil {\n\t\t\t\tif err2 != tc.err {\n\t\t\t\t\tt.Errorf(\"Should have returned error %s\", tc.err)\n\t\t\t\t}\n\t\t\t} else if !veryclose(a2, tc.output) {\n\t\t\t\tt.Errorf(\"Result %.08f should be %.08f\", a2, tc.output)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc ExampleAutoCorrelation() {\n\ts1 := []float64{1, 2, 3, 4, 5}\n\ta, _ := stats.AutoCorrelation(s1, 1)\n\tfmt.Println(a)\n\t// Output: 0.4\n}\n\nfunc TestAutoCorrelation(t *testing.T) {\n\ts1 := []float64{1, 2, 3, 4, 5}\n\ts2 := []float64{}\n\n\ta, err := stats.AutoCorrelation(s1, 1)\n\tif err != nil {\n\t\tt.Errorf(\"Should not have returned an error\")\n\t}\n\tif a != 0.4 {\n\t\tt.Errorf(\"Should have returned 0.4\")\n\t}\n\n\t_, err = stats.AutoCorrelation(s2, 1)\n\tif err != stats.EmptyInputErr {\n\t\tt.Errorf(\"Should have returned empty input error\")\n\t}\n}\n"
        },
        {
          "name": "cumulative_sum.go",
          "type": "blob",
          "size": 0.37109375,
          "content": "package stats\n\n// CumulativeSum calculates the cumulative sum of the input slice\nfunc CumulativeSum(input Float64Data) ([]float64, error) {\n\n\tif input.Len() == 0 {\n\t\treturn Float64Data{}, EmptyInput\n\t}\n\n\tcumSum := make([]float64, input.Len())\n\n\tfor i, val := range input {\n\t\tif i == 0 {\n\t\t\tcumSum[i] = val\n\t\t} else {\n\t\t\tcumSum[i] = cumSum[i-1] + val\n\t\t}\n\t}\n\n\treturn cumSum, nil\n}\n"
        },
        {
          "name": "cumulative_sum_test.go",
          "type": "blob",
          "size": 1.1982421875,
          "content": "package stats_test\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc ExampleCumulativeSum() {\n\tdata := []float64{1.0, 2.1, 3.2, 4.823, 4.1, 5.8}\n\tcsum, _ := stats.CumulativeSum(data)\n\tfmt.Println(csum)\n\t// Output: [1 3.1 6.300000000000001 11.123000000000001 15.223 21.023]\n}\n\nfunc TestCumulativeSum(t *testing.T) {\n\tfor _, c := range []struct {\n\t\tin  []float64\n\t\tout []float64\n\t}{\n\t\t{[]float64{1, 2, 3}, []float64{1, 3, 6}},\n\t\t{[]float64{1.0, 1.1, 1.2, 2.2}, []float64{1.0, 2.1, 3.3, 5.5}},\n\t\t{[]float64{-1, -1, 2, -3}, []float64{-1, -2, 0, -3}},\n\t} {\n\t\tgot, err := stats.CumulativeSum(c.in)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"Returned an error\")\n\t\t}\n\t\tif !reflect.DeepEqual(c.out, got) {\n\t\t\tt.Errorf(\"CumulativeSum(%.1f) => %.1f != %.1f\", c.in, got, c.out)\n\t\t}\n\t}\n\t_, err := stats.CumulativeSum([]float64{})\n\tif err == nil {\n\t\tt.Errorf(\"Empty slice should have returned an error\")\n\t}\n}\n\nfunc BenchmarkCumulativeSumSmallFloatSlice(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.CumulativeSum(makeFloatSlice(5))\n\t}\n}\n\nfunc BenchmarkCumulativeSumLargeFloatSlice(b *testing.B) {\n\tlf := makeFloatSlice(100000)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.CumulativeSum(lf)\n\t}\n}\n"
        },
        {
          "name": "data.go",
          "type": "blob",
          "size": 5.5703125,
          "content": "package stats\n\n// Float64Data is a named type for []float64 with helper methods\ntype Float64Data []float64\n\n// Get item in slice\nfunc (f Float64Data) Get(i int) float64 { return f[i] }\n\n// Len returns length of slice\nfunc (f Float64Data) Len() int { return len(f) }\n\n// Less returns if one number is less than another\nfunc (f Float64Data) Less(i, j int) bool { return f[i] < f[j] }\n\n// Swap switches out two numbers in slice\nfunc (f Float64Data) Swap(i, j int) { f[i], f[j] = f[j], f[i] }\n\n// Min returns the minimum number in the data\nfunc (f Float64Data) Min() (float64, error) { return Min(f) }\n\n// Max returns the maximum number in the data\nfunc (f Float64Data) Max() (float64, error) { return Max(f) }\n\n// Sum returns the total of all the numbers in the data\nfunc (f Float64Data) Sum() (float64, error) { return Sum(f) }\n\n// CumulativeSum returns the cumulative sum of the data\nfunc (f Float64Data) CumulativeSum() ([]float64, error) { return CumulativeSum(f) }\n\n// Mean returns the mean of the data\nfunc (f Float64Data) Mean() (float64, error) { return Mean(f) }\n\n// Median returns the median of the data\nfunc (f Float64Data) Median() (float64, error) { return Median(f) }\n\n// Mode returns the mode of the data\nfunc (f Float64Data) Mode() ([]float64, error) { return Mode(f) }\n\n// GeometricMean returns the median of the data\nfunc (f Float64Data) GeometricMean() (float64, error) { return GeometricMean(f) }\n\n// HarmonicMean returns the mode of the data\nfunc (f Float64Data) HarmonicMean() (float64, error) { return HarmonicMean(f) }\n\n// MedianAbsoluteDeviation the median of the absolute deviations from the dataset median\nfunc (f Float64Data) MedianAbsoluteDeviation() (float64, error) {\n\treturn MedianAbsoluteDeviation(f)\n}\n\n// MedianAbsoluteDeviationPopulation finds the median of the absolute deviations from the population median\nfunc (f Float64Data) MedianAbsoluteDeviationPopulation() (float64, error) {\n\treturn MedianAbsoluteDeviationPopulation(f)\n}\n\n// StandardDeviation the amount of variation in the dataset\nfunc (f Float64Data) StandardDeviation() (float64, error) {\n\treturn StandardDeviation(f)\n}\n\n// StandardDeviationPopulation finds the amount of variation from the population\nfunc (f Float64Data) StandardDeviationPopulation() (float64, error) {\n\treturn StandardDeviationPopulation(f)\n}\n\n// StandardDeviationSample finds the amount of variation from a sample\nfunc (f Float64Data) StandardDeviationSample() (float64, error) {\n\treturn StandardDeviationSample(f)\n}\n\n// QuartileOutliers finds the mild and extreme outliers\nfunc (f Float64Data) QuartileOutliers() (Outliers, error) {\n\treturn QuartileOutliers(f)\n}\n\n// Percentile finds the relative standing in a slice of floats\nfunc (f Float64Data) Percentile(p float64) (float64, error) {\n\treturn Percentile(f, p)\n}\n\n// PercentileNearestRank finds the relative standing using the Nearest Rank method\nfunc (f Float64Data) PercentileNearestRank(p float64) (float64, error) {\n\treturn PercentileNearestRank(f, p)\n}\n\n// Correlation describes the degree of relationship between two sets of data\nfunc (f Float64Data) Correlation(d Float64Data) (float64, error) {\n\treturn Correlation(f, d)\n}\n\n// AutoCorrelation is the correlation of a signal with a delayed copy of itself as a function of delay\nfunc (f Float64Data) AutoCorrelation(lags int) (float64, error) {\n\treturn AutoCorrelation(f, lags)\n}\n\n// Pearson calculates the Pearson product-moment correlation coefficient between two variables.\nfunc (f Float64Data) Pearson(d Float64Data) (float64, error) {\n\treturn Pearson(f, d)\n}\n\n// Quartile returns the three quartile points from a slice of data\nfunc (f Float64Data) Quartile(d Float64Data) (Quartiles, error) {\n\treturn Quartile(d)\n}\n\n// InterQuartileRange finds the range between Q1 and Q3\nfunc (f Float64Data) InterQuartileRange() (float64, error) {\n\treturn InterQuartileRange(f)\n}\n\n// Midhinge finds the average of the first and third quartiles\nfunc (f Float64Data) Midhinge(d Float64Data) (float64, error) {\n\treturn Midhinge(d)\n}\n\n// Trimean finds the average of the median and the midhinge\nfunc (f Float64Data) Trimean(d Float64Data) (float64, error) {\n\treturn Trimean(d)\n}\n\n// Sample returns sample from input with replacement or without\nfunc (f Float64Data) Sample(n int, r bool) ([]float64, error) {\n\treturn Sample(f, n, r)\n}\n\n// Variance the amount of variation in the dataset\nfunc (f Float64Data) Variance() (float64, error) {\n\treturn Variance(f)\n}\n\n// PopulationVariance finds the amount of variance within a population\nfunc (f Float64Data) PopulationVariance() (float64, error) {\n\treturn PopulationVariance(f)\n}\n\n// SampleVariance finds the amount of variance within a sample\nfunc (f Float64Data) SampleVariance() (float64, error) {\n\treturn SampleVariance(f)\n}\n\n// Covariance is a measure of how much two sets of data change\nfunc (f Float64Data) Covariance(d Float64Data) (float64, error) {\n\treturn Covariance(f, d)\n}\n\n// CovariancePopulation computes covariance for entire population between two variables\nfunc (f Float64Data) CovariancePopulation(d Float64Data) (float64, error) {\n\treturn CovariancePopulation(f, d)\n}\n\n// Sigmoid returns the input values along the sigmoid or s-shaped curve\nfunc (f Float64Data) Sigmoid() ([]float64, error) {\n\treturn Sigmoid(f)\n}\n\n// SoftMax returns the input values in the range of 0 to 1\n// with sum of all the probabilities being equal to one.\nfunc (f Float64Data) SoftMax() ([]float64, error) {\n\treturn SoftMax(f)\n}\n\n// Entropy provides calculation of the entropy\nfunc (f Float64Data) Entropy() (float64, error) {\n\treturn Entropy(f)\n}\n\n// Quartiles returns the three quartile points from instance of Float64Data\nfunc (f Float64Data) Quartiles() (Quartiles, error) {\n\treturn Quartile(f)\n}\n"
        },
        {
          "name": "data_test.go",
          "type": "blob",
          "size": 6.8115234375,
          "content": "package stats_test\n\nimport (\n\t\"math\"\n\t\"math/rand\"\n\t\"reflect\"\n\t\"runtime\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nvar data1 = stats.Float64Data{-10, -10.001, 5, 1.1, 2, 3, 4.20, 5}\nvar data2 = stats.Float64Data{-9, -9.001, 4, .1, 1, 2, 3.20, 5}\n\nfunc getFunctionName(i interface{}) string {\n\treturn runtime.FuncForPC(reflect.ValueOf(i).Pointer()).Name()\n}\n\nfunc checkResult(result float64, err error, name string, f float64, t *testing.T) {\n\tif err != nil {\n\t\tt.Errorf(\"%s returned an error\", name)\n\t}\n\tif !veryclose(result, f) {\n\t\tt.Errorf(\"%s() => %v != %v\", name, result, f)\n\t}\n}\n\n// makeFloatSlice makes a slice of float64s\nfunc makeFloatSlice(c int) []float64 {\n\tlf := make([]float64, 0, c)\n\tfor i := 0; i < c; i++ {\n\t\tf := float64(i * 100)\n\t\tlf = append(lf, f)\n\t}\n\treturn lf\n}\n\nfunc makeRandFloatSlice(c int) []float64 {\n\tlf := make([]float64, 0, c)\n\trand.Seed(time.Now().UTC().UnixNano())\n\tfor i := 0; i < c; i++ {\n\t\tf := float64(i * 100)\n\t\tlf = append(lf, f)\n\t}\n\treturn lf\n}\n\nfunc TestInterfaceMethods(t *testing.T) {\n\t// Test Get\n\ta := data1.Get(1)\n\tif a != -10.001 {\n\t\tt.Errorf(\"Get(2) => %.1f != %.1f\", a, -10.001)\n\t}\n\n\t// Test Len\n\tl := data1.Len()\n\tif l != 8 {\n\t\tt.Errorf(\"Len() => %v != %v\", l, 8)\n\t}\n\n\t// Test Less\n\tb := data1.Less(0, 5)\n\tif !b {\n\t\tt.Errorf(\"Less() => %v != %v\", b, true)\n\t}\n\n\t// Test Swap\n\tdata1.Swap(0, 2)\n\tif data1.Get(0) != 5 {\n\t\tt.Errorf(\"Len() => %v != %v\", l, 8)\n\t}\n}\n\nfunc TestHelperMethods(t *testing.T) {\n\n\t// Test Min\n\tm, _ := data1.Min()\n\tif m != -10.001 {\n\t\tt.Errorf(\"Min() => %v != %v\", m, -10.001)\n\t}\n\n\t// Test Max\n\tm, _ = data1.Max()\n\tif m != 5 {\n\t\tt.Errorf(\"Max() => %v != %v\", m, 5)\n\t}\n\n\t// Test Sum\n\tm, _ = data1.Sum()\n\tif m != 0.2990000000000004 {\n\t\tt.Errorf(\"Sum() => %v != %v\", m, 0.2990000000000004)\n\t}\n\n\t// Test CumulativeSum\n\tcs, _ := data1.CumulativeSum()\n\twant := []float64{5, -5.0009999999999994, -15.001, -13.901, -11.901, -8.901, -4.701, 0.2990000000000004}\n\tif !reflect.DeepEqual(cs, want) {\n\t\tt.Errorf(\"CumulativeSum() => %v != %v\", cs, want)\n\t}\n\n\t// Test Mean\n\tm, _ = data1.Mean()\n\tif m != 0.03737500000000005 {\n\t\tt.Errorf(\"Mean() => %v != %v\", m, 0.03737500000000005)\n\t}\n\n\t// Test GeometricMean\n\tm, _ = data1.GeometricMean()\n\tif m != 4.028070682618703 {\n\t\tt.Errorf(\"GeometricMean() => %v != %v\", m, 4.028070682618703)\n\t}\n\n\t// Test HarmonicMean\n\tm, _ = data1.HarmonicMean()\n\tif !math.IsNaN(m) {\n\t\tt.Errorf(\"HarmonicMean() => %v != %v\", m, math.NaN())\n\t}\n\n\t// Test Median\n\tm, _ = data1.Median()\n\tif m != 2.5 {\n\t\tt.Errorf(\"Median() => %v != %v\", m, 2.5)\n\t}\n\n\t// Test Mode\n\tmo, _ := data1.Mode()\n\tif !reflect.DeepEqual(mo, []float64{5.0}) {\n\t\tt.Errorf(\"Mode() => %.1f != %.1f\", mo, []float64{5.0})\n\t}\n\n\t// Test InterQuartileRange\n\tiqr, _ := data1.InterQuartileRange()\n\tif iqr != 9.05 {\n\t\tt.Errorf(\"InterQuartileRange() => %v != %v\", iqr, 9.05)\n\t}\n}\n\nfunc assertFloat64(fn func() (float64, error), f float64, t *testing.T) {\n\tres, err := fn()\n\tcheckResult(res, err, getFunctionName(fn), f, t)\n}\n\nfunc TestMedianAbsoluteDeviationMethods(t *testing.T) {\n\tassertFloat64(data1.MedianAbsoluteDeviation, 2.1, t)\n\tassertFloat64(data1.MedianAbsoluteDeviationPopulation, 2.1, t)\n}\n\nfunc TestStandardDeviationMethods(t *testing.T) {\n\tassertFloat64(data1.StandardDeviation, 5.935684731720091, t)\n\tassertFloat64(data1.StandardDeviationPopulation, 5.935684731720091, t)\n\tassertFloat64(data1.StandardDeviationSample, 6.345513892000508, t)\n}\n\nfunc TestVarianceMethods(t *testing.T) {\n\tassertFloat64(data1.Variance, 35.232353234375005, t)\n\tassertFloat64(data1.PopulationVariance, 35.232353234375005, t)\n\tassertFloat64(data1.SampleVariance, 40.26554655357143, t)\n\n}\n\nfunc assertPercentiles(fn func(i float64) (float64, error), i float64, f float64, t *testing.T) {\n\tres, err := fn(i)\n\tcheckResult(res, err, getFunctionName(fn), f, t)\n}\n\nfunc TestPercentileMethods(t *testing.T) {\n\tassertPercentiles(data1.Percentile, 75, 4.2, t)\n\tassertPercentiles(data1.PercentileNearestRank, 75, 4.2, t)\n\n}\n\nfunc assertOtherDataMethods(fn func(d stats.Float64Data) (float64, error), d stats.Float64Data, f float64, t *testing.T) {\n\tres, err := fn(d)\n\tcheckResult(res, err, getFunctionName(fn), f, t)\n}\n\nfunc TestOtherDataMethods(t *testing.T) {\n\tassertOtherDataMethods(data1.Correlation, data2, 0.20875473597605448, t)\n\tassertOtherDataMethods(data1.Pearson, data2, 0.20875473597605448, t)\n\tassertOtherDataMethods(data1.Midhinge, data2, -0.42500000000000004, t)\n\tassertOtherDataMethods(data1.Trimean, data2, 0.5375, t)\n\tassertOtherDataMethods(data1.Covariance, data2, 7.3814215535714265, t)\n\tassertOtherDataMethods(data1.CovariancePopulation, data2, 6.458743859374998, t)\n}\n\nfunc TestAutoCorrelationMethod(t *testing.T) {\n\t_, err := data1.AutoCorrelation(1)\n\tif err != nil {\n\t\tt.Error(\"stats.Float64Data.AutoCorrelation returned an error\")\n\t}\n}\n\nfunc TestSampleMethod(t *testing.T) {\n\t// Test Sample method\n\t_, err := data1.Sample(5, true)\n\tif err != nil {\n\t\tt.Errorf(\"%s returned an error\", getFunctionName(data1.Sample))\n\t}\n}\n\nfunc TestQuartileMethods(t *testing.T) {\n\t// Test QuartileOutliers method\n\t_, err := data1.QuartileOutliers()\n\tif err != nil {\n\t\tt.Errorf(\"%s returned an error\", getFunctionName(data1.QuartileOutliers))\n\t}\n\n\t// Test Quartile method\n\t_, err = data1.Quartile(data2)\n\tif err != nil {\n\t\tt.Errorf(\"%s returned an error\", getFunctionName(data1.Quartile))\n\t}\n}\n\nfunc TestSigmoidMethod(t *testing.T) {\n\td := stats.LoadRawData([]float64{3.0, 1.0, 2.1})\n\ta := []float64{0.9525741268224334, 0.7310585786300049, 0.8909031788043871}\n\ts, _ := d.Sigmoid()\n\tif !reflect.DeepEqual(s, a) {\n\t\tt.Errorf(\"Sigmoid() => %g != %g\", s, a)\n\t}\n}\n\nfunc TestSoftMaxMethod(t *testing.T) {\n\td := stats.LoadRawData([]float64{3.0, 1.0, 0.2})\n\ta := []float64{0.8360188027814407, 0.11314284146556013, 0.05083835575299916}\n\ts, _ := d.SoftMax()\n\tif !reflect.DeepEqual(s, a) {\n\t\tt.Errorf(\"SoftMax() => %g != %g\", s, a)\n\t}\n}\n\nfunc TestEntropyMethod(t *testing.T) {\n\td := stats.LoadRawData([]float64{3.0, 1.0, 0.2})\n\ta := 0.7270013625470586\n\te, _ := d.Entropy()\n\tif e != a {\n\t\tt.Errorf(\"Entropy() => %v != %v\", e, a)\n\t}\n}\n\n// Here we show the regular way of doing it\n// with a plain old slice of float64s\nfunc BenchmarkRegularAPI(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tdata := []float64{-10, -7, -3.11, 5, 1.1, 2, 3, 4.20, 5, 18}\n\t\t_, _ = stats.Min(data)\n\t\t_, _ = stats.Max(data)\n\t\t_, _ = stats.Sum(data)\n\t\t_, _ = stats.Mean(data)\n\t\t_, _ = stats.Median(data)\n\t\t_, _ = stats.Mode(data)\n\t}\n}\n\n// Here's where things get interesting\n// and we start to use the included\n// stats.Float64Data type and methods\nfunc BenchmarkMethodsAPI(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tdata := stats.Float64Data{-10, -7, -3.11, 5, 1.1, 2, 3, 4.20, 5, 18}\n\t\t_, _ = data.Min()\n\t\t_, _ = data.Max()\n\t\t_, _ = data.Sum()\n\t\t_, _ = data.Mean()\n\t\t_, _ = data.Median()\n\t\t_, _ = data.Mode()\n\t}\n}\n\nfunc TestQuartilesMethods(t *testing.T) {\n\t_, err := data1.Quartiles()\n\tif err != nil {\n\t\tt.Errorf(\"%s returned an error\", getFunctionName(data1.Quartiles))\n\t}\n}\n"
        },
        {
          "name": "describe.go",
          "type": "blob",
          "size": 2.5498046875,
          "content": "package stats\n\nimport \"fmt\"\n\n// Holds information about the dataset provided to Describe\ntype Description struct {\n\tCount                  int\n\tMean                   float64\n\tStd                    float64\n\tMax                    float64\n\tMin                    float64\n\tDescriptionPercentiles []descriptionPercentile\n\tAllowedNaN             bool\n}\n\n// Specifies percentiles to be computed\ntype descriptionPercentile struct {\n\tPercentile float64\n\tValue      float64\n}\n\n// Describe generates descriptive statistics about a provided dataset, similar to python's pandas.describe()\nfunc Describe(input Float64Data, allowNaN bool, percentiles *[]float64) (*Description, error) {\n\treturn DescribePercentileFunc(input, allowNaN, percentiles, Percentile)\n}\n\n// Describe generates descriptive statistics about a provided dataset, similar to python's pandas.describe()\n// Takes in a function to use for percentile calculation\nfunc DescribePercentileFunc(input Float64Data, allowNaN bool, percentiles *[]float64, percentileFunc func(Float64Data, float64) (float64, error)) (*Description, error) {\n\tvar description Description\n\tdescription.AllowedNaN = allowNaN\n\tdescription.Count = input.Len()\n\n\tif description.Count == 0 && !allowNaN {\n\t\treturn &description, ErrEmptyInput\n\t}\n\n\t// Disregard error, since it cannot be thrown if Count is > 0 and allowNaN is false, else NaN is accepted\n\tdescription.Std, _ = StandardDeviation(input)\n\tdescription.Max, _ = Max(input)\n\tdescription.Min, _ = Min(input)\n\tdescription.Mean, _ = Mean(input)\n\n\tif percentiles != nil {\n\t\tfor _, percentile := range *percentiles {\n\t\t\tif value, err := percentileFunc(input, percentile); err == nil || allowNaN {\n\t\t\t\tdescription.DescriptionPercentiles = append(description.DescriptionPercentiles, descriptionPercentile{Percentile: percentile, Value: value})\n\t\t\t}\n\t\t}\n\t}\n\n\treturn &description, nil\n}\n\n/*\nRepresents the Description instance in a string format with specified number of decimals\n\n\tcount   3\n\tmean    2.00\n\tstd     0.82\n\tmax     3.00\n\tmin     1.00\n\t25.00%  NaN\n\t50.00%  1.50\n\t75.00%  2.50\n\tNaN OK  true\n*/\nfunc (d *Description) String(decimals int) string {\n\tvar str string\n\n\tstr += fmt.Sprintf(\"count\\t%d\\n\", d.Count)\n\tstr += fmt.Sprintf(\"mean\\t%.*f\\n\", decimals, d.Mean)\n\tstr += fmt.Sprintf(\"std\\t%.*f\\n\", decimals, d.Std)\n\tstr += fmt.Sprintf(\"max\\t%.*f\\n\", decimals, d.Max)\n\tstr += fmt.Sprintf(\"min\\t%.*f\\n\", decimals, d.Min)\n\tfor _, percentile := range d.DescriptionPercentiles {\n\t\tstr += fmt.Sprintf(\"%.2f%%\\t%.*f\\n\", percentile.Percentile, decimals, percentile.Value)\n\t}\n\tstr += fmt.Sprintf(\"NaN OK\\t%t\", d.AllowedNaN)\n\treturn str\n}\n"
        },
        {
          "name": "describe_test.go",
          "type": "blob",
          "size": 2.169921875,
          "content": "package stats_test\n\nimport (\n\t\"math\"\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc TestDescribeValidDataset(t *testing.T) {\n\t_, err := stats.Describe([]float64{1.0, 2.0, 3.0}, false, &[]float64{25.0, 50.0, 75.0})\n\tif err != nil {\n\t\tt.Errorf(\"Returned an error\")\n\t}\n}\n\nfunc TestDescribeEmptyDataset(t *testing.T) {\n\t_, err := stats.Describe([]float64{}, false, nil)\n\tif err != stats.ErrEmptyInput {\n\t\tt.Errorf(\"Did not return empty input error\")\n\t}\n}\n\nfunc TestDescribeEmptyDatasetNaN(t *testing.T) {\n\tdescribe, err := stats.Describe([]float64{}, true, nil)\n\tif err != nil {\n\t\tt.Errorf(\"Returned an error\")\n\t}\n\n\tif !math.IsNaN(describe.Max) || !math.IsNaN(describe.Mean) || !math.IsNaN(describe.Min) || !math.IsNaN(describe.Std) {\n\t\tt.Errorf(\"Was not NaN\")\n\t}\n}\n\nfunc TestDescribeValidDatasetNaN(t *testing.T) {\n\tdescribe, err := stats.Describe([]float64{1.0, 2.0, 3.0}, true, &[]float64{25.0, 50.0, 75.0})\n\tif err != nil {\n\t\tt.Errorf(\"Returned an error\")\n\t}\n\n\tif math.IsNaN(describe.Max) {\n\t\tt.Errorf(\"Was NaN\")\n\t}\n}\n\nfunc TestDescribeValues(t *testing.T) {\n\tdataSet := []float64{1.0, 2.0, 3.0}\n\tpercentiles := []float64{25.0, 50.0, 75.0}\n\tdescribe, _ := stats.Describe(dataSet, true, &percentiles)\n\tif describe.Count != len(dataSet) {\n\t\tt.Errorf(\"Count was not == length of dataset\")\n\t}\n\tif len(describe.DescriptionPercentiles) != len(percentiles) {\n\t\tt.Errorf(\"Percentiles length was not == length of input percentiles\")\n\t}\n\n\tmax, _ := stats.Max(dataSet)\n\tif max != describe.Max {\n\t\tt.Errorf(\"Max was not equal to Max(dataset)\")\n\t}\n\n\tmin, _ := stats.Min(dataSet)\n\tif min != describe.Min {\n\t\tt.Errorf(\"Min was not equal to Min(dataset)\")\n\t}\n\n\tmean, _ := stats.Mean(dataSet)\n\tif mean != describe.Mean {\n\t\tt.Errorf(\"Mean was not equal to Mean(dataset)\")\n\t}\n\n\tstd, _ := stats.StandardDeviation(dataSet)\n\tif std != describe.Std {\n\t\tt.Errorf(\"Std was not equal to StandardDeviation(dataset)\")\n\t}\n}\n\nfunc TestDescribeString(t *testing.T) {\n\tdescribe, _ := stats.Describe([]float64{1.0, 2.0, 3.0}, true, &[]float64{25.0, 50.0, 75.0})\n\tif describe.String(2) != \"count\\t3\\nmean\\t2.00\\nstd\\t0.82\\nmax\\t3.00\\nmin\\t1.00\\n25.00%\\tNaN\\n50.00%\\t1.50\\n75.00%\\t2.50\\nNaN OK\\ttrue\" {\n\t\tt.Errorf(\"String output is not correct\")\n\t}\n}\n"
        },
        {
          "name": "deviation.go",
          "type": "blob",
          "size": 1.484375,
          "content": "package stats\n\nimport \"math\"\n\n// MedianAbsoluteDeviation finds the median of the absolute deviations from the dataset median\nfunc MedianAbsoluteDeviation(input Float64Data) (mad float64, err error) {\n\treturn MedianAbsoluteDeviationPopulation(input)\n}\n\n// MedianAbsoluteDeviationPopulation finds the median of the absolute deviations from the population median\nfunc MedianAbsoluteDeviationPopulation(input Float64Data) (mad float64, err error) {\n\tif input.Len() == 0 {\n\t\treturn math.NaN(), EmptyInputErr\n\t}\n\n\ti := copyslice(input)\n\tm, _ := Median(i)\n\n\tfor key, value := range i {\n\t\ti[key] = math.Abs(value - m)\n\t}\n\n\treturn Median(i)\n}\n\n// StandardDeviation the amount of variation in the dataset\nfunc StandardDeviation(input Float64Data) (sdev float64, err error) {\n\treturn StandardDeviationPopulation(input)\n}\n\n// StandardDeviationPopulation finds the amount of variation from the population\nfunc StandardDeviationPopulation(input Float64Data) (sdev float64, err error) {\n\n\tif input.Len() == 0 {\n\t\treturn math.NaN(), EmptyInputErr\n\t}\n\n\t// Get the population variance\n\tvp, _ := PopulationVariance(input)\n\n\t// Return the population standard deviation\n\treturn math.Sqrt(vp), nil\n}\n\n// StandardDeviationSample finds the amount of variation from a sample\nfunc StandardDeviationSample(input Float64Data) (sdev float64, err error) {\n\n\tif input.Len() == 0 {\n\t\treturn math.NaN(), EmptyInputErr\n\t}\n\n\t// Get the sample variance\n\tvs, _ := SampleVariance(input)\n\n\t// Return the sample standard deviation\n\treturn math.Sqrt(vs), nil\n}\n"
        },
        {
          "name": "deviation_test.go",
          "type": "blob",
          "size": 2.080078125,
          "content": "package stats_test\n\nimport (\n\t\"math\"\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc TestMedianAbsoluteDeviation(t *testing.T) {\n\t_, err := stats.MedianAbsoluteDeviation([]float64{1, 2, 3})\n\tif err != nil {\n\t\tt.Errorf(\"Returned an error\")\n\t}\n}\n\nfunc TestMedianAbsoluteDeviationPopulation(t *testing.T) {\n\ts, _ := stats.MedianAbsoluteDeviation([]float64{1, 2, 3})\n\tm, err := stats.Round(s, 2)\n\tif err != nil {\n\t\tt.Errorf(\"Returned an error\")\n\t}\n\tif m != 1.00 {\n\t\tt.Errorf(\"%.10f != %.10f\", m, 1.00)\n\t}\n\n\ts, _ = stats.MedianAbsoluteDeviation([]float64{-2, 0, 4, 5, 7})\n\tm, err = stats.Round(s, 2)\n\tif err != nil {\n\t\tt.Errorf(\"Returned an error\")\n\t}\n\tif m != 3.00 {\n\t\tt.Errorf(\"%.10f != %.10f\", m, 3.00)\n\t}\n\n\tm, _ = stats.MedianAbsoluteDeviation([]float64{})\n\tif !math.IsNaN(m) {\n\t\tt.Errorf(\"%.1f != %.1f\", m, math.NaN())\n\t}\n}\n\nfunc TestStandardDeviation(t *testing.T) {\n\t_, err := stats.StandardDeviation([]float64{1, 2, 3})\n\tif err != nil {\n\t\tt.Errorf(\"Returned an error\")\n\t}\n}\n\nfunc TestStandardDeviationPopulation(t *testing.T) {\n\ts, _ := stats.StandardDeviationPopulation([]float64{1, 2, 3})\n\tm, err := stats.Round(s, 2)\n\tif err != nil {\n\t\tt.Errorf(\"Returned an error\")\n\t}\n\tif m != 0.82 {\n\t\tt.Errorf(\"%.10f != %.10f\", m, 0.82)\n\t}\n\ts, _ = stats.StandardDeviationPopulation([]float64{-1, -2, -3.3})\n\tm, err = stats.Round(s, 2)\n\tif err != nil {\n\t\tt.Errorf(\"Returned an error\")\n\t}\n\tif m != 0.94 {\n\t\tt.Errorf(\"%.10f != %.10f\", m, 0.94)\n\t}\n\n\tm, _ = stats.StandardDeviationPopulation([]float64{})\n\tif !math.IsNaN(m) {\n\t\tt.Errorf(\"%.1f != %.1f\", m, math.NaN())\n\t}\n}\n\nfunc TestStandardDeviationSample(t *testing.T) {\n\ts, _ := stats.StandardDeviationSample([]float64{1, 2, 3})\n\tm, err := stats.Round(s, 2)\n\tif err != nil {\n\t\tt.Errorf(\"Returned an error\")\n\t}\n\tif m != 1.0 {\n\t\tt.Errorf(\"%.10f != %.10f\", m, 1.0)\n\t}\n\ts, _ = stats.StandardDeviationSample([]float64{-1, -2, -3.3})\n\tm, err = stats.Round(s, 2)\n\tif err != nil {\n\t\tt.Errorf(\"Returned an error\")\n\t}\n\tif m != 1.15 {\n\t\tt.Errorf(\"%.10f != %.10f\", m, 1.15)\n\t}\n\n\tm, _ = stats.StandardDeviationSample([]float64{})\n\tif !math.IsNaN(m) {\n\t\tt.Errorf(\"%.1f != %.1f\", m, math.NaN())\n\t}\n}\n"
        },
        {
          "name": "distances.go",
          "type": "blob",
          "size": 2.51953125,
          "content": "package stats\n\nimport (\n\t\"math\"\n)\n\n// Validate data for distance calculation\nfunc validateData(dataPointX, dataPointY Float64Data) error {\n\tif len(dataPointX) == 0 || len(dataPointY) == 0 {\n\t\treturn EmptyInputErr\n\t}\n\n\tif len(dataPointX) != len(dataPointY) {\n\t\treturn SizeErr\n\t}\n\treturn nil\n}\n\n// ChebyshevDistance computes the Chebyshev distance between two data sets\nfunc ChebyshevDistance(dataPointX, dataPointY Float64Data) (distance float64, err error) {\n\terr = validateData(dataPointX, dataPointY)\n\tif err != nil {\n\t\treturn math.NaN(), err\n\t}\n\tvar tempDistance float64\n\tfor i := 0; i < len(dataPointY); i++ {\n\t\ttempDistance = math.Abs(dataPointX[i] - dataPointY[i])\n\t\tif distance < tempDistance {\n\t\t\tdistance = tempDistance\n\t\t}\n\t}\n\treturn distance, nil\n}\n\n// EuclideanDistance computes the Euclidean distance between two data sets\nfunc EuclideanDistance(dataPointX, dataPointY Float64Data) (distance float64, err error) {\n\n\terr = validateData(dataPointX, dataPointY)\n\tif err != nil {\n\t\treturn math.NaN(), err\n\t}\n\tdistance = 0\n\tfor i := 0; i < len(dataPointX); i++ {\n\t\tdistance = distance + ((dataPointX[i] - dataPointY[i]) * (dataPointX[i] - dataPointY[i]))\n\t}\n\treturn math.Sqrt(distance), nil\n}\n\n// ManhattanDistance computes the Manhattan distance between two data sets\nfunc ManhattanDistance(dataPointX, dataPointY Float64Data) (distance float64, err error) {\n\terr = validateData(dataPointX, dataPointY)\n\tif err != nil {\n\t\treturn math.NaN(), err\n\t}\n\tdistance = 0\n\tfor i := 0; i < len(dataPointX); i++ {\n\t\tdistance = distance + math.Abs(dataPointX[i]-dataPointY[i])\n\t}\n\treturn distance, nil\n}\n\n// MinkowskiDistance computes the Minkowski distance between two data sets\n//\n// Arguments:\n//\n//\tdataPointX: First set of data points\n//\tdataPointY: Second set of data points. Length of both data\n//\t            sets must be equal.\n//\tlambda:     aka p or city blocks; With lambda = 1\n//\t            returned distance is manhattan distance and\n//\t            lambda = 2; it is euclidean distance. Lambda\n//\t            reaching to infinite - distance would be chebysev\n//\t            distance.\n//\n// Return:\n//\n//\tDistance or error\nfunc MinkowskiDistance(dataPointX, dataPointY Float64Data, lambda float64) (distance float64, err error) {\n\terr = validateData(dataPointX, dataPointY)\n\tif err != nil {\n\t\treturn math.NaN(), err\n\t}\n\tfor i := 0; i < len(dataPointY); i++ {\n\t\tdistance = distance + math.Pow(math.Abs(dataPointX[i]-dataPointY[i]), lambda)\n\t}\n\tdistance = math.Pow(distance, 1/lambda)\n\tif math.IsInf(distance, 1) {\n\t\treturn math.NaN(), InfValue\n\t}\n\treturn distance, nil\n}\n"
        },
        {
          "name": "distances_test.go",
          "type": "blob",
          "size": 2.4345703125,
          "content": "package stats_test\n\nimport (\n\t\"fmt\"\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\ntype distanceFunctionType func(stats.Float64Data, stats.Float64Data) (float64, error)\n\nvar minkowskiDistanceTestMatrix = []struct {\n\tdataPointX []float64\n\tdataPointY []float64\n\tlambda     float64\n\tdistance   float64\n}{\n\t{[]float64{2, 3, 4, 5, 6, 7, 8}, []float64{8, 7, 6, 5, 4, 3, 2}, 1, 24},\n\t{[]float64{2, 3, 4, 5, 6, 7, 8}, []float64{8, 7, 6, 5, 4, 3, 2}, 2, 10.583005244258363},\n\t{[]float64{2, 3, 4, 5, 6, 7, 8}, []float64{8, 7, 6, 5, 4, 3, 2}, 99, 6},\n}\n\nvar distanceTestMatrix = []struct {\n\tdataPointX       []float64\n\tdataPointY       []float64\n\tdistance         float64\n\tdistanceFunction distanceFunctionType\n}{\n\t{[]float64{2, 3, 4, 5, 6, 7, 8}, []float64{8, 7, 6, 5, 4, 3, 2}, 6, stats.ChebyshevDistance},\n\t{[]float64{2, 3, 4, 5, 6, 7, 8}, []float64{8, 7, 6, 5, 4, 3, 2}, 24, stats.ManhattanDistance},\n\t{[]float64{2, 3, 4, 5, 6, 7, 8}, []float64{8, 7, 6, 5, 4, 3, 2}, 10.583005244258363, stats.EuclideanDistance},\n}\n\nfunc TestDataSetDistances(t *testing.T) {\n\n\t// Test Minkowski Distance with different lambda values.\n\tfor _, testData := range minkowskiDistanceTestMatrix {\n\t\tdistance, err := stats.MinkowskiDistance(testData.dataPointX, testData.dataPointY, testData.lambda)\n\t\tif err != nil && distance != testData.distance {\n\t\t\tt.Errorf(\"Failed to compute Minkowski distance.\")\n\t\t}\n\n\t\t_, err = stats.MinkowskiDistance([]float64{}, []float64{}, 3)\n\t\tif err == nil {\n\t\t\tt.Errorf(\"Empty slices should have resulted in an error\")\n\t\t}\n\n\t\t_, err = stats.MinkowskiDistance([]float64{1, 2, 3}, []float64{1, 4}, 3)\n\t\tif err == nil {\n\t\t\tt.Errorf(\"Different length slices should have resulted in an error\")\n\t\t}\n\n\t\t_, err = stats.MinkowskiDistance([]float64{999, 999, 999}, []float64{1, 1, 1}, 1000)\n\t\tif err == nil {\n\t\t\tt.Errorf(\"Infinite distance should have resulted in an error\")\n\t\t}\n\t}\n\n\t// Compute distance with the help of all algorithms.\n\tfor _, testSet := range distanceTestMatrix {\n\t\tdistance, err := testSet.distanceFunction(testSet.dataPointX, testSet.dataPointY)\n\t\tif err != nil && testSet.distance != distance {\n\t\t\tt.Errorf(\"Failed to compute distance.\")\n\t\t}\n\n\t\t_, err = testSet.distanceFunction([]float64{}, []float64{})\n\t\tif err == nil {\n\t\t\tt.Errorf(\"Empty slices should have resulted in an error\")\n\t\t}\n\t}\n}\n\nfunc ExampleChebyshevDistance() {\n\td1 := []float64{2, 3, 4, 5, 6, 7, 8}\n\td2 := []float64{8, 7, 6, 5, 4, 3, 2}\n\tcd, _ := stats.ChebyshevDistance(d1, d2)\n\tfmt.Println(cd)\n\t// Output: 6\n}\n"
        },
        {
          "name": "doc.go",
          "type": "blob",
          "size": 0.6005859375,
          "content": "/*\nPackage stats is a well tested and comprehensive\nstatistics library package with no dependencies.\n\nExample Usage:\n\n\t// start with some source data to use\n\tdata := []float64{1.0, 2.1, 3.2, 4.823, 4.1, 5.8}\n\n\t// you could also use different types like this\n\t// data := stats.LoadRawData([]int{1, 2, 3, 4, 5})\n\t// data := stats.LoadRawData([]interface{}{1.1, \"2\", 3})\n\t// etc...\n\n\tmedian, _ := stats.Median(data)\n\tfmt.Println(median) // 3.65\n\n\troundedMedian, _ := stats.Round(median, 0)\n\tfmt.Println(roundedMedian) // 4\n\nMIT License Copyright (c) 2014-2020 Montana Flynn (https://montanaflynn.com)\n*/\npackage stats\n"
        },
        {
          "name": "entropy.go",
          "type": "blob",
          "size": 0.572265625,
          "content": "package stats\n\nimport \"math\"\n\n// Entropy provides calculation of the entropy\nfunc Entropy(input Float64Data) (float64, error) {\n\tinput, err := normalize(input)\n\tif err != nil {\n\t\treturn math.NaN(), err\n\t}\n\tvar result float64\n\tfor i := 0; i < input.Len(); i++ {\n\t\tv := input.Get(i)\n\t\tif v == 0 {\n\t\t\tcontinue\n\t\t}\n\t\tresult += (v * math.Log(v))\n\t}\n\treturn -result, nil\n}\n\nfunc normalize(input Float64Data) (Float64Data, error) {\n\tsum, err := input.Sum()\n\tif err != nil {\n\t\treturn Float64Data{}, err\n\t}\n\tfor i := 0; i < input.Len(); i++ {\n\t\tinput[i] = input[i] / sum\n\t}\n\treturn input, nil\n}\n"
        },
        {
          "name": "entropy_test.go",
          "type": "blob",
          "size": 1.0556640625,
          "content": "package stats_test\n\nimport (\n\t\"fmt\"\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc ExampleEntropy() {\n\td := []float64{1.1, 2.2, 3.3}\n\te, _ := stats.Entropy(d)\n\tfmt.Println(e)\n\t// Output: 1.0114042647073518\n}\n\nfunc TestEntropy(t *testing.T) {\n\tfor _, c := range []struct {\n\t\tin  stats.Float64Data\n\t\tout float64\n\t}{\n\t\t{stats.Float64Data{4, 8, 5, 1}, 1.2110440167801229},\n\t\t{stats.Float64Data{0.8, 0.01, 0.4}, 0.6791185708986585},\n\t\t{stats.Float64Data{0.8, 1.1, 0, 5}, 0.7759393943707658},\n\t} {\n\t\tgot, err := stats.Entropy(c.in)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"Returned an error\")\n\t\t}\n\t\tif !veryclose(got, c.out) {\n\t\t\tt.Errorf(\"Max(%.1f) => %.1f != %.1f\", c.in, got, c.out)\n\t\t}\n\t}\n\t_, err := stats.Entropy([]float64{})\n\tif err == nil {\n\t\tt.Errorf(\"Empty slice didn't return an error\")\n\t}\n}\n\nfunc BenchmarkEntropySmallFloatSlice(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Entropy(makeFloatSlice(5))\n\t}\n}\n\nfunc BenchmarkEntropyLargeFloatSlice(b *testing.B) {\n\tlf := makeFloatSlice(100000)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Entropy(lf)\n\t}\n}\n"
        },
        {
          "name": "errors.go",
          "type": "blob",
          "size": 1.03515625,
          "content": "package stats\n\ntype statsError struct {\n\terr string\n}\n\nfunc (s statsError) Error() string {\n\treturn s.err\n}\n\nfunc (s statsError) String() string {\n\treturn s.err\n}\n\n// These are the package-wide error values.\n// All error identification should use these values.\n// https://github.com/golang/go/wiki/Errors#naming\nvar (\n\t// ErrEmptyInput Input must not be empty\n\tErrEmptyInput = statsError{\"Input must not be empty.\"}\n\t// ErrNaN Not a number\n\tErrNaN = statsError{\"Not a number.\"}\n\t// ErrNegative Must not contain negative values\n\tErrNegative = statsError{\"Must not contain negative values.\"}\n\t// ErrZero Must not contain zero values\n\tErrZero = statsError{\"Must not contain zero values.\"}\n\t// ErrBounds Input is outside of range\n\tErrBounds = statsError{\"Input is outside of range.\"}\n\t// ErrSize Must be the same length\n\tErrSize = statsError{\"Must be the same length.\"}\n\t// ErrInfValue Value is infinite\n\tErrInfValue = statsError{\"Value is infinite.\"}\n\t// ErrYCoord Y Value must be greater than zero\n\tErrYCoord = statsError{\"Y Value must be greater than zero.\"}\n)\n"
        },
        {
          "name": "errors_test.go",
          "type": "blob",
          "size": 0.26953125,
          "content": "package stats\n\nimport (\n\t\"testing\"\n)\n\nfunc TestError(t *testing.T) {\n\terr := statsError{\"test error\"}\n\tif err.Error() != \"test error\" {\n\t\tt.Errorf(\"Error method message didn't match\")\n\t}\n\tif err.String() != \"test error\" {\n\t\tt.Errorf(\"String method message didn't match\")\n\t}\n}\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples_test.go",
          "type": "blob",
          "size": 4.681640625,
          "content": "package stats_test\n\n// import (\n// \t\"fmt\"\n// \t\"testing\"\n\n// \t\"github.com/montanaflynn/stats\"\n// )\n\n// func Example() {\n// \t// t.Parallel()\n// \tt.Run(\"LoadRawData\", func(t *testing.T) {\n// \t\t// t.Parallel()\n// \t\tdata := stats.LoadRawData([]interface{}{1.1, \"2\", 3})\n// \t\tfmt.Println(data)\n// \t\t// Output: 1.1, 2.0, 3.0, 4\n// \t})\n// }\n\n// // func Example() {\n\n// // \t// start with some source data to use\n// // \tdata := []float64{1.0, 2.1, 3.2, 4.823, 4.1, 5.8}\n// // \t// you could also use different types like this\n// // \t// data := stats.LoadRawData([]int{1, 2, 3, 4, 5})\n// // \t// data := stats.LoadRawData([]interface{}{1.1, \"2\", 3})\n// // \t// etc...\n\n// // \tmedian, _ := Median(data)\n// // \tfmt.Println(median)\n// // \t// Output: 3.65\n\n// // \troundedMedian, _ := Round(median, 0)\n// // \tfmt.Println(roundedMedian)\n// // \t// Output: 4\n\n// // \ta, _ := Mean([]float64{1, 2, 3, 4, 5})\n// // \tfmt.Println(a)\n// // \t// Output: 3\n\n// // \ta, _ = Median([]float64{1, 2, 3, 4, 5, 6, 7})\n// // \tfmt.Println(a)\n// // \t// Output: 4\n\n// // \tm, _ := Mode([]float64{5, 5, 3, 3, 4, 2, 1})\n// // \tfmt.Println(m)\n// // \t// Output: [5 3]\n\n// // \ta, _ = PopulationVariance([]float64{1, 2, 3, 4, 5})\n// // \tfmt.Println(a)\n// // \t// Output: 2\n\n// // \ta, _ = SampleVariance([]float64{1, 2, 3, 4, 5})\n// // \tfmt.Println(a)\n// // \t// Output: 2.5\n\n// // \ta, _ = MedianAbsoluteDeviationPopulation([]float64{1, 2, 3})\n// // \tfmt.Println(a)\n// // \t// Output: 1\n\n// // \ta, _ = StandardDeviationPopulation([]float64{1, 2, 3})\n// // \tfmt.Println(a)\n// // \t// Output: 0.816496580927726\n\n// // \ta, _ = StandardDeviationSample([]float64{1, 2, 3})\n// // \tfmt.Println(a)\n// // \t// Output: 1\n\n// // \ta, _ = Percentile([]float64{1, 2, 3, 4, 5}, 75)\n// // \tfmt.Println(a)\n// // \t// Output: 4\n\n// // \ta, _ = PercentileNearestRank([]float64{35, 20, 15, 40, 50}, 75)\n// // \tfmt.Println(a)\n// // \t// Output: 40\n\n// // \tc := []Coordinate{\n// // \t\t{1, 2.3},\n// // \t\t{2, 3.3},\n// // \t\t{3, 3.7},\n// // \t\t{4, 4.3},\n// // \t\t{5, 5.3},\n// // \t}\n\n// // \tr, _ := LinearRegression(c)\n// // \tfmt.Println(r)\n// // \t// Output: [{1 2.3800000000000026} {2 3.0800000000000014} {3 3.7800000000000002} {4 4.479999999999999} {5 5.179999999999998}]\n\n// // \tr, _ = ExponentialRegression(c)\n// // \tfmt.Println(r)\n// // \t// Output: [{1 2.5150181024736638} {2 3.032084111136781} {3 3.6554544271334493} {4 4.406984298281804} {5 5.313022222665875}]\n\n// // \tr, _ = LogarithmicRegression(c)\n// // \tfmt.Println(r)\n// // \t// Output: [{1 2.1520822363811702} {2 3.3305559222492214} {3 4.019918836568674} {4 4.509029608117273} {5 4.888413396683663}]\n\n// // \ts, _ := Sample([]float64{0.1, 0.2, 0.3, 0.4}, 3, false)\n// // \tfmt.Println(s)\n// // \t// Output: [0.2,0.4,0.3]\n\n// // \ts, _ = Sample([]float64{0.1, 0.2, 0.3, 0.4}, 10, true)\n// // \tfmt.Println(s)\n// // \t// Output: [0.2,0.2,0.4,0.1,0.2,0.4,0.3,0.2,0.2,0.1]\n\n// // \tq, _ := Quartile([]float64{7, 15, 36, 39, 40, 41})\n// // \tfmt.Println(q)\n// // \t// Output: {15 37.5 40}\n\n// // \tiqr, _ := InterQuartileRange([]float64{102, 104, 105, 107, 108, 109, 110, 112, 115, 116, 118})\n// // \tfmt.Println(iqr)\n// // \t// Output: 10\n\n// // \tmh, _ := Midhinge([]float64{1, 3, 4, 4, 6, 6, 6, 6, 7, 7, 7, 8, 8, 9, 9, 10, 11, 12, 13})\n// // \tfmt.Println(mh)\n// // \t// Output: 7.5\n\n// // \ttr, _ := Trimean([]float64{1, 3, 4, 4, 6, 6, 6, 6, 7, 7, 7, 8, 8, 9, 9, 10, 11, 12, 13})\n// // \tfmt.Println(tr)\n// // \t// Output: 7.25\n\n// // \to, _ := QuartileOutliers([]float64{-1000, 1, 3, 4, 4, 6, 6, 6, 6, 7, 8, 15, 18, 100})\n// // \tfmt.Printf(\"%+v\\n\", o)\n// // \t// Output:  {Mild:[15 18] Extreme:[-1000 100]}\n\n// // \tgm, _ := GeometricMean([]float64{10, 51.2, 8})\n// // \tfmt.Println(gm)\n// // \t// Output: 15.999999999999991\n\n// // \thm, _ := HarmonicMean([]float64{1, 2, 3, 4, 5})\n// // \tfmt.Println(hm)\n// // \t// Output: 2.18978102189781\n\n// // \ta, _ = Round(2.18978102189781, 3)\n// // \tfmt.Println(a)\n// // \t// Output: 2.189\n\n// // \te, _ := ChebyshevDistance([]float64{2, 3, 4, 5, 6, 7, 8}, []float64{8, 7, 6, 5, 4, 3, 2})\n// // \tfmt.Println(e)\n// // \t// Output: 6\n\n// // \te, _ = ManhattanDistance([]float64{2, 3, 4, 5, 6, 7, 8}, []float64{8, 7, 6, 5, 4, 3, 2})\n// // \tfmt.Println(e)\n// // \t// Output: 24\n\n// // \te, _ = EuclideanDistance([]float64{2, 3, 4, 5, 6, 7, 8}, []float64{8, 7, 6, 5, 4, 3, 2})\n// // \tfmt.Println(e)\n// // \t// Output: 10.583005244258363\n\n// // \te, _ = MinkowskiDistance([]float64{2, 3, 4, 5, 6, 7, 8}, []float64{8, 7, 6, 5, 4, 3, 2}, float64(1))\n// // \tfmt.Println(e)\n// // \t// Output: 24\n\n// // \te, _ = MinkowskiDistance([]float64{2, 3, 4, 5, 6, 7, 8}, []float64{8, 7, 6, 5, 4, 3, 2}, float64(2))\n// // \tfmt.Println(e)\n// // \t// Output: 10.583005244258363\n\n// // \te, _ = MinkowskiDistance([]float64{2, 3, 4, 5, 6, 7, 8}, []float64{8, 7, 6, 5, 4, 3, 2}, float64(99))\n// // \tfmt.Println(e)\n// // \t// Output: 6\n// // }\n"
        },
        {
          "name": "geometric_distribution.go",
          "type": "blob",
          "size": 1.0126953125,
          "content": "package stats\n\nimport (\n\t\"math\"\n)\n\n// ProbGeom generates the probability for a geometric random variable\n// with parameter p to achieve success in the interval of [a, b] trials\n// See https://en.wikipedia.org/wiki/Geometric_distribution for more information\nfunc ProbGeom(a int, b int, p float64) (prob float64, err error) {\n\tif (a > b) || (a < 1) {\n\t\treturn math.NaN(), ErrBounds\n\t}\n\n\tprob = 0\n\tq := 1 - p // probability of failure\n\n\tfor k := a + 1; k <= b; k++ {\n\t\tprob = prob + p*math.Pow(q, float64(k-1))\n\t}\n\n\treturn prob, nil\n}\n\n// ProbGeom generates the expectation or average number of trials\n// for a geometric random variable with parameter p\nfunc ExpGeom(p float64) (exp float64, err error) {\n\tif (p > 1) || (p < 0) {\n\t\treturn math.NaN(), ErrNegative\n\t}\n\n\treturn 1 / p, nil\n}\n\n// ProbGeom generates the variance for number for a\n// geometric random variable with parameter p\nfunc VarGeom(p float64) (exp float64, err error) {\n\tif (p > 1) || (p < 0) {\n\t\treturn math.NaN(), ErrNegative\n\t}\n\treturn (1 - p) / math.Pow(p, 2), nil\n}\n"
        },
        {
          "name": "geometric_distribution_test.go",
          "type": "blob",
          "size": 1.84765625,
          "content": "package stats_test\n\nimport (\n\t\"fmt\"\n\t\"math\"\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc ExampleProbGeom() {\n\tp := 0.5\n\ta := 1\n\tb := 2\n\tchance, _ := stats.ProbGeom(a, b, p)\n\tfmt.Println(chance)\n\t// Output: 0.25\n}\n\nfunc TestProbGeomLarge(t *testing.T) {\n\tp := 0.5\n\ta := 1\n\tb := 10000\n\tchance, err := stats.ProbGeom(a, b, p)\n\tif err != nil {\n\t\tt.Errorf(\"Returned an error\")\n\t}\n\tif chance != 0.5 {\n\t\tt.Errorf(\"ProbGeom(%d, %d, %.01f) => %.1f != %.1f\", a, b, p, chance, 0.5)\n\t}\n}\n\nfunc TestErrBoundsProbGeom(t *testing.T) {\n\tp := 0.5\n\ta := -1\n\tb := 4\n\tchance, err := stats.ProbGeom(a, b, p)\n\tif err == nil {\n\t\tt.Errorf(\"Did not return an error when expected\")\n\t}\n\tif !math.IsNaN(chance) {\n\t\tt.Errorf(\"ProbGeom(%d, %d, %.01f) => %.1f != %.1f\", a, b, p, chance, math.NaN())\n\t}\n}\n\nfunc ExampleExpGeom() {\n\tp := 0.5\n\texp, _ := stats.ExpGeom(p)\n\tfmt.Println(exp)\n\t// Output: 2\n}\n\nfunc TestExpGeom(t *testing.T) {\n\tp := 0.5\n\texp, err := stats.ExpGeom(p)\n\tif err != nil {\n\t\tt.Errorf(\"Returned an error when not expected\")\n\t}\n\tif exp != 2.0 {\n\t\tt.Errorf(\"ExpGeom(%.01f) => %.1f != %.1f\", p, exp, 2.0)\n\t}\n}\n\nfunc TestErrExpGeom(t *testing.T) {\n\tp := -1.0\n\texp, err := stats.ExpGeom(p)\n\tif err == nil {\n\t\tt.Errorf(\"Did not return an error\")\n\t}\n\tif !math.IsNaN(exp) {\n\t\tt.Errorf(\"ExpGeom(%.01f) => %.1f != %.1f\", p, exp, math.NaN())\n\t}\n}\n\nfunc ExampleVarGeom() {\n\tp := 0.5\n\tvari, _ := stats.VarGeom(p)\n\tfmt.Println(vari)\n\t// Output: 2\n}\n\nfunc TestVarGeom(t *testing.T) {\n\tp := 0.25\n\tvari, err := stats.VarGeom(p)\n\tif err != nil {\n\t\tt.Errorf(\"Returned an error when not expected\")\n\t}\n\tif vari != 12.0 {\n\t\tt.Errorf(\"VarGeom(%.01f) => %.1f != %.1f\", p, vari, 12.0)\n\t}\n}\n\nfunc TestErrVarGeom(t *testing.T) {\n\tp := -1.0\n\tvari, err := stats.VarGeom(p)\n\tif err == nil {\n\t\tt.Errorf(\"Did not return an error\")\n\t}\n\tif !math.IsNaN(vari) {\n\t\tt.Errorf(\"VarGeom(%.01f) => %.1f != %.1f\", p, vari, math.NaN())\n\t}\n}\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.044921875,
          "content": "module github.com/montanaflynn/stats\n\ngo 1.13\n"
        },
        {
          "name": "legacy.go",
          "type": "blob",
          "size": 1.3212890625,
          "content": "package stats\n\n// VarP is a shortcut to PopulationVariance\nfunc VarP(input Float64Data) (sdev float64, err error) {\n\treturn PopulationVariance(input)\n}\n\n// VarS is a shortcut to SampleVariance\nfunc VarS(input Float64Data) (sdev float64, err error) {\n\treturn SampleVariance(input)\n}\n\n// StdDevP is a shortcut to StandardDeviationPopulation\nfunc StdDevP(input Float64Data) (sdev float64, err error) {\n\treturn StandardDeviationPopulation(input)\n}\n\n// StdDevS is a shortcut to StandardDeviationSample\nfunc StdDevS(input Float64Data) (sdev float64, err error) {\n\treturn StandardDeviationSample(input)\n}\n\n// LinReg is a shortcut to LinearRegression\nfunc LinReg(s []Coordinate) (regressions []Coordinate, err error) {\n\treturn LinearRegression(s)\n}\n\n// ExpReg is a shortcut to ExponentialRegression\nfunc ExpReg(s []Coordinate) (regressions []Coordinate, err error) {\n\treturn ExponentialRegression(s)\n}\n\n// LogReg is a shortcut to LogarithmicRegression\nfunc LogReg(s []Coordinate) (regressions []Coordinate, err error) {\n\treturn LogarithmicRegression(s)\n}\n\n// Legacy error names that didn't start with Err\nvar (\n\tEmptyInputErr = ErrEmptyInput\n\tNaNErr        = ErrNaN\n\tNegativeErr   = ErrNegative\n\tZeroErr       = ErrZero\n\tBoundsErr     = ErrBounds\n\tSizeErr       = ErrSize\n\tInfValue      = ErrInfValue\n\tYCoordErr     = ErrYCoord\n\tEmptyInput    = ErrEmptyInput\n)\n"
        },
        {
          "name": "legacy_test.go",
          "type": "blob",
          "size": 1.408203125,
          "content": "package stats_test\n\nimport (\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\n// Create working sample data to test if the legacy\n// functions cause a runtime crash or return an error\nfunc TestLegacy(t *testing.T) {\n\n\t// Slice of data\n\ts := []float64{-10, -10.001, 5, 1.1, 2, 3, 4.20, 5}\n\n\t// Slice of coordinates\n\td := []stats.Coordinate{\n\t\t{1, 2.3},\n\t\t{2, 3.3},\n\t\t{3, 3.7},\n\t\t{4, 4.3},\n\t\t{5, 5.3},\n\t}\n\n\t// VarP rename compatibility\n\t_, err := stats.VarP(s)\n\tif err != nil {\n\t\tt.Errorf(\"VarP not successfully returning PopulationVariance.\")\n\t}\n\n\t// VarS rename compatibility\n\t_, err = stats.VarS(s)\n\tif err != nil {\n\t\tt.Errorf(\"VarS not successfully returning SampleVariance.\")\n\t}\n\n\t// StdDevP rename compatibility\n\t_, err = stats.StdDevP(s)\n\tif err != nil {\n\t\tt.Errorf(\"StdDevP not successfully returning StandardDeviationPopulation.\")\n\t}\n\n\t// StdDevS rename compatibility\n\t_, err = stats.StdDevS(s)\n\tif err != nil {\n\t\tt.Errorf(\"StdDevS not successfully returning StandardDeviationSample.\")\n\t}\n\n\t// LinReg rename compatibility\n\t_, err = stats.LinReg(d)\n\tif err != nil {\n\t\tt.Errorf(\"LinReg not successfully returning LinearRegression.\")\n\t}\n\n\t// ExpReg rename compatibility\n\t_, err = stats.ExpReg(d)\n\tif err != nil {\n\t\tt.Errorf(\"ExpReg not successfully returning ExponentialRegression.\")\n\t}\n\n\t// LogReg rename compatibility\n\t_, err = stats.LogReg(d)\n\tif err != nil {\n\t\tt.Errorf(\"LogReg not successfully returning LogarithmicRegression.\")\n\t}\n}\n"
        },
        {
          "name": "load.go",
          "type": "blob",
          "size": 3.4287109375,
          "content": "package stats\n\nimport (\n\t\"bufio\"\n\t\"io\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n)\n\n// LoadRawData parses and converts a slice of mixed data types to floats\nfunc LoadRawData(raw interface{}) (f Float64Data) {\n\tvar r []interface{}\n\tvar s Float64Data\n\n\tswitch t := raw.(type) {\n\tcase []interface{}:\n\t\tr = t\n\tcase []uint:\n\t\tfor _, v := range t {\n\t\t\ts = append(s, float64(v))\n\t\t}\n\t\treturn s\n\tcase []uint8:\n\t\tfor _, v := range t {\n\t\t\ts = append(s, float64(v))\n\t\t}\n\t\treturn s\n\tcase []uint16:\n\t\tfor _, v := range t {\n\t\t\ts = append(s, float64(v))\n\t\t}\n\t\treturn s\n\tcase []uint32:\n\t\tfor _, v := range t {\n\t\t\ts = append(s, float64(v))\n\t\t}\n\t\treturn s\n\tcase []uint64:\n\t\tfor _, v := range t {\n\t\t\ts = append(s, float64(v))\n\t\t}\n\t\treturn s\n\tcase []bool:\n\t\tfor _, v := range t {\n\t\t\tif v {\n\t\t\t\ts = append(s, 1.0)\n\t\t\t} else {\n\t\t\t\ts = append(s, 0.0)\n\t\t\t}\n\t\t}\n\t\treturn s\n\tcase []float64:\n\t\treturn Float64Data(t)\n\tcase []int:\n\t\tfor _, v := range t {\n\t\t\ts = append(s, float64(v))\n\t\t}\n\t\treturn s\n\tcase []int8:\n\t\tfor _, v := range t {\n\t\t\ts = append(s, float64(v))\n\t\t}\n\t\treturn s\n\tcase []int16:\n\t\tfor _, v := range t {\n\t\t\ts = append(s, float64(v))\n\t\t}\n\t\treturn s\n\tcase []int32:\n\t\tfor _, v := range t {\n\t\t\ts = append(s, float64(v))\n\t\t}\n\t\treturn s\n\tcase []int64:\n\t\tfor _, v := range t {\n\t\t\ts = append(s, float64(v))\n\t\t}\n\t\treturn s\n\tcase []string:\n\t\tfor _, v := range t {\n\t\t\tr = append(r, v)\n\t\t}\n\tcase []time.Duration:\n\t\tfor _, v := range t {\n\t\t\tr = append(r, v)\n\t\t}\n\tcase map[int]int:\n\t\tfor i := 0; i < len(t); i++ {\n\t\t\ts = append(s, float64(t[i]))\n\t\t}\n\t\treturn s\n\tcase map[int]int8:\n\t\tfor i := 0; i < len(t); i++ {\n\t\t\ts = append(s, float64(t[i]))\n\t\t}\n\t\treturn s\n\tcase map[int]int16:\n\t\tfor i := 0; i < len(t); i++ {\n\t\t\ts = append(s, float64(t[i]))\n\t\t}\n\t\treturn s\n\tcase map[int]int32:\n\t\tfor i := 0; i < len(t); i++ {\n\t\t\ts = append(s, float64(t[i]))\n\t\t}\n\t\treturn s\n\tcase map[int]int64:\n\t\tfor i := 0; i < len(t); i++ {\n\t\t\ts = append(s, float64(t[i]))\n\t\t}\n\t\treturn s\n\tcase map[int]string:\n\t\tfor i := 0; i < len(t); i++ {\n\t\t\tr = append(r, t[i])\n\t\t}\n\tcase map[int]uint:\n\t\tfor i := 0; i < len(t); i++ {\n\t\t\ts = append(s, float64(t[i]))\n\t\t}\n\t\treturn s\n\tcase map[int]uint8:\n\t\tfor i := 0; i < len(t); i++ {\n\t\t\ts = append(s, float64(t[i]))\n\t\t}\n\t\treturn s\n\tcase map[int]uint16:\n\t\tfor i := 0; i < len(t); i++ {\n\t\t\ts = append(s, float64(t[i]))\n\t\t}\n\t\treturn s\n\tcase map[int]uint32:\n\t\tfor i := 0; i < len(t); i++ {\n\t\t\ts = append(s, float64(t[i]))\n\t\t}\n\t\treturn s\n\tcase map[int]uint64:\n\t\tfor i := 0; i < len(t); i++ {\n\t\t\ts = append(s, float64(t[i]))\n\t\t}\n\t\treturn s\n\tcase map[int]bool:\n\t\tfor i := 0; i < len(t); i++ {\n\t\t\tif t[i] {\n\t\t\t\ts = append(s, 1.0)\n\t\t\t} else {\n\t\t\t\ts = append(s, 0.0)\n\t\t\t}\n\t\t}\n\t\treturn s\n\tcase map[int]float64:\n\t\tfor i := 0; i < len(t); i++ {\n\t\t\ts = append(s, t[i])\n\t\t}\n\t\treturn s\n\tcase map[int]time.Duration:\n\t\tfor i := 0; i < len(t); i++ {\n\t\t\tr = append(r, t[i])\n\t\t}\n\tcase string:\n\t\tfor _, v := range strings.Fields(t) {\n\t\t\tr = append(r, v)\n\t\t}\n\tcase io.Reader:\n\t\tscanner := bufio.NewScanner(t)\n\t\tfor scanner.Scan() {\n\t\t\tl := scanner.Text()\n\t\t\tfor _, v := range strings.Fields(l) {\n\t\t\t\tr = append(r, v)\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, v := range r {\n\t\tswitch t := v.(type) {\n\t\tcase int:\n\t\t\ta := float64(t)\n\t\t\tf = append(f, a)\n\t\tcase uint:\n\t\t\tf = append(f, float64(t))\n\t\tcase float64:\n\t\t\tf = append(f, t)\n\t\tcase string:\n\t\t\tfl, err := strconv.ParseFloat(t, 64)\n\t\t\tif err == nil {\n\t\t\t\tf = append(f, fl)\n\t\t\t}\n\t\tcase bool:\n\t\t\tif t {\n\t\t\t\tf = append(f, 1.0)\n\t\t\t} else {\n\t\t\t\tf = append(f, 0.0)\n\t\t\t}\n\t\tcase time.Duration:\n\t\t\tf = append(f, float64(t))\n\t\t}\n\t}\n\treturn f\n}\n"
        },
        {
          "name": "load_test.go",
          "type": "blob",
          "size": 4.8076171875,
          "content": "package stats_test\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc ExampleLoadRawData() {\n\tdata := stats.LoadRawData([]interface{}{1.1, \"2\", 3})\n\tfmt.Println(data)\n\t// Output: [1.1 2 3]\n}\n\nvar allTestData = []struct {\n\tactual   interface{}\n\texpected stats.Float64Data\n}{\n\t{\n\t\t[]interface{}{1.0, \"2\", 3.0, uint(4), \"4.0\", 5, time.Duration(6), time.Duration(-7)},\n\t\tstats.Float64Data{1.0, 2.0, 3.0, 4.0, 4.0, 5.0, 6.0, -7.0},\n\t},\n\t{\n\t\t[]interface{}{\"-345\", \"223\", \"-654.4\", \"194\", \"898.3\"},\n\t\tstats.Float64Data{-345.0, 223.0, -654.4, 194.0, 898.3},\n\t},\n\t{\n\t\t[]interface{}{7862, 4234, 9872.1, 8794},\n\t\tstats.Float64Data{7862.0, 4234.0, 9872.1, 8794.0},\n\t},\n\t{\n\t\t[]interface{}{true, false, true, false, false},\n\t\tstats.Float64Data{1.0, 0.0, 1.0, 0.0, 0.0},\n\t},\n\t{\n\t\t[]interface{}{14.3, 26, 17.7, \"shoe\"},\n\t\tstats.Float64Data{14.3, 26.0, 17.7},\n\t},\n\t{\n\t\t[]bool{true, false, true, true, false},\n\t\tstats.Float64Data{1.0, 0.0, 1.0, 1.0, 0.0},\n\t},\n\t{\n\t\t[]float64{10230.9823, 93432.9384, 23443.945, 12374.945},\n\t\tstats.Float64Data{10230.9823, 93432.9384, 23443.945, 12374.945},\n\t},\n\t{\n\t\t[]time.Duration{-843, 923, -398, 1000},\n\t\tstats.Float64Data{-843.0, 923.0, -398.0, 1000.0},\n\t},\n\t{\n\t\t[]string{\"-843.2\", \"923\", \"hello\", \"-398\", \"1000.5\"},\n\t\tstats.Float64Data{-843.2, 923.0, -398.0, 1000.5},\n\t},\n\t{\n\t\t[]uint{34, 12, 65, 230, 30},\n\t\tstats.Float64Data{34.0, 12.0, 65.0, 230.0, 30.0},\n\t},\n\t{\n\t\t[]uint8{34, 12, 65, 23, 255},\n\t\tstats.Float64Data{34.0, 12.0, 65.0, 23.0, 255.0},\n\t},\n\t{\n\t\t[]uint16{34, 12, 65, 230, 65535},\n\t\tstats.Float64Data{34.0, 12.0, 65.0, 230.0, 65535.0},\n\t},\n\t{\n\t\t[]uint32{34, 12, 65, 230, 4294967295},\n\t\tstats.Float64Data{34.0, 12.0, 65.0, 230.0, 4294967295.0},\n\t},\n\t{\n\t\t[]uint64{34, 12, 65, 230, 18446744073709551615},\n\t\tstats.Float64Data{34.0, 12.0, 65.0, 230.0, 18446744073709552000.0},\n\t},\n\t{\n\t\t[]int{-843, 923, -398, 1000},\n\t\tstats.Float64Data{-843.0, 923.0, -398.0, 1000.0},\n\t},\n\t{\n\t\t[]int8{-43, 23, -128, 127},\n\t\tstats.Float64Data{-43.0, 23.0, -128.0, 127.0},\n\t},\n\t{\n\t\t[]int16{-843, 923, -32768, 32767},\n\t\tstats.Float64Data{-843.0, 923.0, -32768.0, 32767.0},\n\t},\n\t{\n\t\t[]int32{-843, 923, -2147483648, 2147483647},\n\t\tstats.Float64Data{-843.0, 923.0, -2147483648.0, 2147483647.0},\n\t},\n\t{\n\t\t[]int64{-843, 923, -9223372036854775808, 9223372036854775807, 9223372036854775800},\n\t\tstats.Float64Data{-843.0, 923.0, -9223372036854776000.0, 9223372036854776000.0, 9223372036854776000.0},\n\t},\n\t{\n\t\tmap[int]bool{0: true, 1: true, 2: false, 3: true, 4: false},\n\t\tstats.Float64Data{1.0, 1.0, 0.0, 1.0, 0.0},\n\t},\n\t{\n\t\tmap[int]float64{0: 68.6, 1: 72.1, 2: -33.3, 3: -99.2},\n\t\tstats.Float64Data{68.6, 72.1, -33.3, -99.2},\n\t},\n\t{\n\t\tmap[int]time.Duration{0: -843, 1: 923, 2: -398, 3: 1000},\n\t\tstats.Float64Data{-843.0, 923.0, -398.0, 1000.0},\n\t},\n\t{\n\t\tmap[int]string{0: \"456\", 1: \"758\", 2: \"-9874\", 3: \"-1981\", 4: \"68.6\", 5: \"72.1\", 6: \"-33.3\", 7: \"-99.2\"},\n\t\tstats.Float64Data{456.0, 758.0, -9874.0, -1981.0, 68.6, 72.1, -33.3, -99.2},\n\t},\n\t{\n\t\tmap[int]uint{0: 4567, 1: 7580, 2: 98742, 3: 19817},\n\t\tstats.Float64Data{4567.0, 7580.0, 98742.0, 19817.0},\n\t},\n\t{\n\t\tmap[int]uint8{0: 34, 1: 12, 2: 65, 3: 23, 4: 255},\n\t\tstats.Float64Data{34.0, 12.0, 65.0, 23.0, 255.0},\n\t},\n\t{\n\t\tmap[int]uint16{0: 34, 1: 12, 2: 65, 3: 230, 4: 65535},\n\t\tstats.Float64Data{34.0, 12.0, 65.0, 230.0, 65535.0},\n\t},\n\t{\n\t\tmap[int]uint32{0: 34, 1: 12, 2: 65, 3: 230, 4: 4294967295},\n\t\tstats.Float64Data{34.0, 12.0, 65.0, 230.0, 4294967295.0},\n\t},\n\t{\n\t\tmap[int]uint64{0: 34, 1: 12, 2: 65, 3: 230, 4: 18446744073709551615},\n\t\tstats.Float64Data{34.0, 12.0, 65.0, 230.0, 18446744073709552000.0},\n\t},\n\t{\n\t\tmap[int]int{0: 456, 1: 758, 2: -9874, 3: -1981},\n\t\tstats.Float64Data{456.0, 758.0, -9874.0, -1981.0},\n\t},\n\t{\n\t\tmap[int]int8{0: -43, 1: 23, 2: -128, 3: 127},\n\t\tstats.Float64Data{-43.0, 23.0, -128.0, 127.0},\n\t},\n\t{\n\t\tmap[int]int16{0: -843, 1: 923, 2: -32768, 3: 32767},\n\t\tstats.Float64Data{-843.0, 923.0, -32768.0, 32767.0},\n\t},\n\t{\n\t\tmap[int]int32{0: -843, 1: 923, 2: -2147483648, 3: 2147483647},\n\t\tstats.Float64Data{-843.0, 923.0, -2147483648.0, 2147483647.0},\n\t},\n\t{\n\t\tmap[int]int64{0: -843, 1: 923, 2: -9223372036854775808, 3: 9223372036854775807, 4: 9223372036854775800},\n\t\tstats.Float64Data{-843.0, 923.0, -9223372036854776000.0, 9223372036854776000.0, 9223372036854776000.0},\n\t},\n\t{\n\t\t\"1\\n\\n2 3.3\\n  4.4\",\n\t\tstats.Float64Data{1.0, 2, 3.3, 4.4},\n\t},\n\t{\n\t\tstrings.NewReader(\"1\\n\\n2 3.3\\n  4.4\"),\n\t\tstats.Float64Data{1.0, 2, 3.3, 4.4},\n\t},\n}\n\nfunc equal(actual, expected stats.Float64Data) bool {\n\tif len(actual) != len(expected) {\n\t\treturn false\n\t}\n\n\tfor k, actualVal := range actual {\n\t\tif actualVal != expected[k] {\n\t\t\treturn false\n\t\t}\n\t}\n\n\treturn true\n}\n\nfunc TestLoadRawData(t *testing.T) {\n\tfor _, data := range allTestData {\n\t\tactual := stats.LoadRawData(data.actual)\n\t\tif !equal(actual, data.expected) {\n\t\t\tt.Fatalf(\"Transform(%v). Expected [%v], Actual [%v]\", data.actual, data.expected, actual)\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "max.go",
          "type": "blob",
          "size": 0.4423828125,
          "content": "package stats\n\nimport (\n\t\"math\"\n)\n\n// Max finds the highest number in a slice\nfunc Max(input Float64Data) (max float64, err error) {\n\n\t// Return an error if there are no numbers\n\tif input.Len() == 0 {\n\t\treturn math.NaN(), EmptyInputErr\n\t}\n\n\t// Get the first value as the starting point\n\tmax = input.Get(0)\n\n\t// Loop and replace higher values\n\tfor i := 1; i < input.Len(); i++ {\n\t\tif input.Get(i) > max {\n\t\t\tmax = input.Get(i)\n\t\t}\n\t}\n\n\treturn max, nil\n}\n"
        },
        {
          "name": "max_test.go",
          "type": "blob",
          "size": 0.970703125,
          "content": "package stats_test\n\nimport (\n\t\"fmt\"\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc ExampleMax() {\n\td := []float64{1.1, 2.3, 3.2, 4.0, 4.01, 5.09}\n\ta, _ := stats.Max(d)\n\tfmt.Println(a)\n\t// Output: 5.09\n}\n\nfunc TestMax(t *testing.T) {\n\tfor _, c := range []struct {\n\t\tin  []float64\n\t\tout float64\n\t}{\n\t\t{[]float64{1, 2, 3, 4, 5}, 5.0},\n\t\t{[]float64{10.5, 3, 5, 7, 9}, 10.5},\n\t\t{[]float64{-20, -1, -5.5}, -1.0},\n\t\t{[]float64{-1.0}, -1.0},\n\t} {\n\t\tgot, err := stats.Max(c.in)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"Returned an error\")\n\t\t}\n\t\tif got != c.out {\n\t\t\tt.Errorf(\"Max(%.1f) => %.1f != %.1f\", c.in, got, c.out)\n\t\t}\n\t}\n\t_, err := stats.Max([]float64{})\n\tif err == nil {\n\t\tt.Errorf(\"Empty slice didn't return an error\")\n\t}\n}\n\nfunc BenchmarkMaxSmallFloatSlice(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Max(makeFloatSlice(5))\n\t}\n}\n\nfunc BenchmarkMaxLargeFloatSlice(b *testing.B) {\n\tlf := makeFloatSlice(100000)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Max(lf)\n\t}\n}\n"
        },
        {
          "name": "mean.go",
          "type": "blob",
          "size": 1.1328125,
          "content": "package stats\n\nimport \"math\"\n\n// Mean gets the average of a slice of numbers\nfunc Mean(input Float64Data) (float64, error) {\n\n\tif input.Len() == 0 {\n\t\treturn math.NaN(), EmptyInputErr\n\t}\n\n\tsum, _ := input.Sum()\n\n\treturn sum / float64(input.Len()), nil\n}\n\n// GeometricMean gets the geometric mean for a slice of numbers\nfunc GeometricMean(input Float64Data) (float64, error) {\n\n\tl := input.Len()\n\tif l == 0 {\n\t\treturn math.NaN(), EmptyInputErr\n\t}\n\n\t// Get the product of all the numbers\n\tvar p float64\n\tfor _, n := range input {\n\t\tif p == 0 {\n\t\t\tp = n\n\t\t} else {\n\t\t\tp *= n\n\t\t}\n\t}\n\n\t// Calculate the geometric mean\n\treturn math.Pow(p, 1/float64(l)), nil\n}\n\n// HarmonicMean gets the harmonic mean for a slice of numbers\nfunc HarmonicMean(input Float64Data) (float64, error) {\n\n\tl := input.Len()\n\tif l == 0 {\n\t\treturn math.NaN(), EmptyInputErr\n\t}\n\n\t// Get the sum of all the numbers reciprocals and return an\n\t// error for values that cannot be included in harmonic mean\n\tvar p float64\n\tfor _, n := range input {\n\t\tif n < 0 {\n\t\t\treturn math.NaN(), NegativeErr\n\t\t} else if n == 0 {\n\t\t\treturn math.NaN(), ZeroErr\n\t\t}\n\t\tp += (1 / n)\n\t}\n\n\treturn float64(l) / p, nil\n}\n"
        },
        {
          "name": "mean_test.go",
          "type": "blob",
          "size": 1.9814453125,
          "content": "package stats_test\n\nimport (\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc TestMean(t *testing.T) {\n\tfor _, c := range []struct {\n\t\tin  []float64\n\t\tout float64\n\t}{\n\t\t{[]float64{1, 2, 3, 4, 5}, 3.0},\n\t\t{[]float64{1, 2, 3, 4, 5, 6}, 3.5},\n\t\t{[]float64{1}, 1.0},\n\t} {\n\t\tgot, _ := stats.Mean(c.in)\n\t\tif got != c.out {\n\t\t\tt.Errorf(\"Mean(%.1f) => %.1f != %.1f\", c.in, got, c.out)\n\t\t}\n\t}\n\t_, err := stats.Mean([]float64{})\n\tif err == nil {\n\t\tt.Errorf(\"Empty slice should have returned an error\")\n\t}\n}\n\nfunc BenchmarkMeanSmallFloatSlice(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Mean(makeFloatSlice(5))\n\t}\n}\n\nfunc BenchmarkMeanLargeFloatSlice(b *testing.B) {\n\tlf := makeFloatSlice(100000)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Mean(lf)\n\t}\n}\n\nfunc TestGeometricMean(t *testing.T) {\n\ts1 := []float64{2, 18}\n\ts2 := []float64{10, 51.2, 8}\n\ts3 := []float64{1, 3, 9, 27, 81}\n\n\tfor _, c := range []struct {\n\t\tin  []float64\n\t\tout float64\n\t}{\n\t\t{s1, 6},\n\t\t{s2, 16},\n\t\t{s3, 9},\n\t} {\n\t\tgm, err := stats.GeometricMean(c.in)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"Should not have returned an error\")\n\t\t}\n\n\t\tgm, _ = stats.Round(gm, 0)\n\t\tif gm != c.out {\n\t\t\tt.Errorf(\"Geometric Mean %v != %v\", gm, c.out)\n\t\t}\n\t}\n\n\t_, err := stats.GeometricMean([]float64{})\n\tif err == nil {\n\t\tt.Errorf(\"Empty slice should have returned an error\")\n\t}\n}\n\nfunc TestHarmonicMean(t *testing.T) {\n\ts1 := []float64{1, 2, 3, 4, 5}\n\ts2 := []float64{10, -51.2, 8}\n\ts3 := []float64{1, 0, 9, 27, 81}\n\n\thm, err := stats.HarmonicMean(s1)\n\tif err != nil {\n\t\tt.Errorf(\"Should not have returned an error\")\n\t}\n\n\thm, _ = stats.Round(hm, 2)\n\tif hm != 2.19 {\n\t\tt.Errorf(\"Geometric Mean %v != %v\", hm, 2.19)\n\t}\n\n\t_, err = stats.HarmonicMean(s2)\n\tif err == nil {\n\t\tt.Errorf(\"Should have returned a negative number error\")\n\t}\n\n\t_, err = stats.HarmonicMean(s3)\n\tif err == nil {\n\t\tt.Errorf(\"Should have returned a zero number error\")\n\t}\n\n\t_, err = stats.HarmonicMean([]float64{})\n\tif err == nil {\n\t\tt.Errorf(\"Empty slice should have returned an error\")\n\t}\n}\n"
        },
        {
          "name": "median.go",
          "type": "blob",
          "size": 0.572265625,
          "content": "package stats\n\nimport \"math\"\n\n// Median gets the median number in a slice of numbers\nfunc Median(input Float64Data) (median float64, err error) {\n\n\t// Start by sorting a copy of the slice\n\tc := sortedCopy(input)\n\n\t// No math is needed if there are no numbers\n\t// For even numbers we add the two middle numbers\n\t// and divide by two using the mean function above\n\t// For odd numbers we just use the middle number\n\tl := len(c)\n\tif l == 0 {\n\t\treturn math.NaN(), EmptyInputErr\n\t} else if l%2 == 0 {\n\t\tmedian, _ = Mean(c[l/2-1 : l/2+1])\n\t} else {\n\t\tmedian = c[l/2]\n\t}\n\n\treturn median, nil\n}\n"
        },
        {
          "name": "median_test.go",
          "type": "blob",
          "size": 1.1552734375,
          "content": "package stats_test\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc ExampleMedian() {\n\tdata := []float64{1.0, 2.1, 3.2, 4.823, 4.1, 5.8}\n\tmedian, _ := stats.Median(data)\n\tfmt.Println(median)\n\t// Output: 3.65\n}\n\nfunc TestMedian(t *testing.T) {\n\tfor _, c := range []struct {\n\t\tin  []float64\n\t\tout float64\n\t}{\n\t\t{[]float64{5, 3, 4, 2, 1}, 3.0},\n\t\t{[]float64{6, 3, 2, 4, 5, 1}, 3.5},\n\t\t{[]float64{1}, 1.0},\n\t} {\n\t\tgot, _ := stats.Median(c.in)\n\t\tif got != c.out {\n\t\t\tt.Errorf(\"Median(%.1f) => %.1f != %.1f\", c.in, got, c.out)\n\t\t}\n\t}\n\t_, err := stats.Median([]float64{})\n\tif err == nil {\n\t\tt.Errorf(\"Empty slice should have returned an error\")\n\t}\n}\n\nfunc BenchmarkMedianSmallFloatSlice(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Median(makeFloatSlice(5))\n\t}\n}\n\nfunc BenchmarkMedianLargeFloatSlice(b *testing.B) {\n\tlf := makeFloatSlice(100000)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Median(lf)\n\t}\n}\n\nfunc TestMedianSortSideEffects(t *testing.T) {\n\ts := []float64{0.1, 0.3, 0.2, 0.4, 0.5}\n\ta := []float64{0.1, 0.3, 0.2, 0.4, 0.5}\n\t_, _ = stats.Median(s)\n\tif !reflect.DeepEqual(s, a) {\n\t\tt.Errorf(\"%.1f != %.1f\", s, a)\n\t}\n}\n"
        },
        {
          "name": "min.go",
          "type": "blob",
          "size": 0.49609375,
          "content": "package stats\n\nimport \"math\"\n\n// Min finds the lowest number in a set of data\nfunc Min(input Float64Data) (min float64, err error) {\n\n\t// Get the count of numbers in the slice\n\tl := input.Len()\n\n\t// Return an error if there are no numbers\n\tif l == 0 {\n\t\treturn math.NaN(), EmptyInputErr\n\t}\n\n\t// Get the first value as the starting point\n\tmin = input.Get(0)\n\n\t// Iterate until done checking for a lower value\n\tfor i := 1; i < l; i++ {\n\t\tif input.Get(i) < min {\n\t\t\tmin = input.Get(i)\n\t\t}\n\t}\n\treturn min, nil\n}\n"
        },
        {
          "name": "min_test.go",
          "type": "blob",
          "size": 1.33984375,
          "content": "package stats_test\n\nimport (\n\t\"fmt\"\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc ExampleMin() {\n\td := stats.LoadRawData([]interface{}{1.1, \"2\", 3.0, 4, \"5\"})\n\ta, _ := stats.Min(d)\n\tfmt.Println(a)\n\t// Output: 1.1\n}\n\nfunc TestMin(t *testing.T) {\n\tfor _, c := range []struct {\n\t\tin  []float64\n\t\tout float64\n\t}{\n\t\t{[]float64{1.1, 2, 3, 4, 5}, 1.1},\n\t\t{[]float64{10.534, 3, 5, 7, 9}, 3.0},\n\t\t{[]float64{-5, 1, 5}, -5.0},\n\t\t{[]float64{5}, 5},\n\t} {\n\t\tgot, err := stats.Min(c.in)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"Returned an error\")\n\t\t}\n\t\tif got != c.out {\n\t\t\tt.Errorf(\"Min(%.1f) => %.1f != %.1f\", c.in, got, c.out)\n\t\t}\n\t}\n\t_, err := stats.Min([]float64{})\n\tif err == nil {\n\t\tt.Errorf(\"Empty slice didn't return an error\")\n\t}\n}\n\nfunc BenchmarkMinSmallFloatSlice(b *testing.B) {\n\ttestData := makeFloatSlice(5)\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Min(testData)\n\t}\n}\n\nfunc BenchmarkMinSmallRandFloatSlice(b *testing.B) {\n\ttestData := makeRandFloatSlice(5)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Min(testData)\n\t}\n}\n\nfunc BenchmarkMinLargeFloatSlice(b *testing.B) {\n\ttestData := makeFloatSlice(100000)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Min(testData)\n\t}\n}\n\nfunc BenchmarkMinLargeRandFloatSlice(b *testing.B) {\n\ttestData := makeRandFloatSlice(100000)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Min(testData)\n\t}\n}\n"
        },
        {
          "name": "mode.go",
          "type": "blob",
          "size": 0.9990234375,
          "content": "package stats\n\n// Mode gets the mode [most frequent value(s)] of a slice of float64s\nfunc Mode(input Float64Data) (mode []float64, err error) {\n\t// Return the input if there's only one number\n\tl := input.Len()\n\tif l == 1 {\n\t\treturn input, nil\n\t} else if l == 0 {\n\t\treturn nil, EmptyInputErr\n\t}\n\n\tc := sortedCopyDif(input)\n\t// Traverse sorted array,\n\t// tracking the longest repeating sequence\n\tmode = make([]float64, 5)\n\tcnt, maxCnt := 1, 1\n\tfor i := 1; i < l; i++ {\n\t\tswitch {\n\t\tcase c[i] == c[i-1]:\n\t\t\tcnt++\n\t\tcase cnt == maxCnt && maxCnt != 1:\n\t\t\tmode = append(mode, c[i-1])\n\t\t\tcnt = 1\n\t\tcase cnt > maxCnt:\n\t\t\tmode = append(mode[:0], c[i-1])\n\t\t\tmaxCnt, cnt = cnt, 1\n\t\tdefault:\n\t\t\tcnt = 1\n\t\t}\n\t}\n\tswitch {\n\tcase cnt == maxCnt:\n\t\tmode = append(mode, c[l-1])\n\tcase cnt > maxCnt:\n\t\tmode = append(mode[:0], c[l-1])\n\t\tmaxCnt = cnt\n\t}\n\n\t// Since length must be greater than 1,\n\t// check for slices of distinct values\n\tif maxCnt == 1 || len(mode)*maxCnt == l && maxCnt != l {\n\t\treturn Float64Data{}, nil\n\t}\n\n\treturn mode, nil\n}\n"
        },
        {
          "name": "mode_test.go",
          "type": "blob",
          "size": 1.6572265625,
          "content": "package stats_test\n\nimport (\n\t\"reflect\"\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc TestMode(t *testing.T) {\n\tfor _, c := range []struct {\n\t\tin  []float64\n\t\tout []float64\n\t}{\n\t\t{[]float64{2, 2, 2, 2}, []float64{2}},\n\t\t{[]float64{5, 3, 4, 2, 1}, []float64{}},\n\t\t{[]float64{5, 5, 3, 3, 4, 4, 2, 2, 1, 1}, []float64{}},\n\t\t{[]float64{5, 5, 3, 4, 2, 1}, []float64{5}},\n\t\t{[]float64{5, 5, 3, 3, 4, 2, 1}, []float64{3, 5}},\n\t\t{[]float64{1}, []float64{1}},\n\t\t{[]float64{-50, -46.325, -46.325, -.87, 1, 2.1122, 3.20, 5, 15, 15, 15.0001}, []float64{-46.325, 15}},\n\t\t{[]float64{1, 2, 3, 4, 4, 4, 4, 4, 5, 3, 6, 7, 5, 0, 8, 8, 7, 6, 9, 9}, []float64{4}},\n\t\t{[]float64{76, 76, 110, 76, 76, 76, 76, 119, 76, 76, 76, 76, 31, 31, 31, 31, 83, 83, 83, 78, 78, 78, 78, 78, 78, 78, 78}, []float64{76}},\n\t} {\n\t\tgot, err := stats.Mode(c.in)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"Returned an error\")\n\t\t}\n\t\tif !reflect.DeepEqual(c.out, got) {\n\t\t\tt.Errorf(\"Mode(%.1f) => %.1f != %.1f\", c.in, got, c.out)\n\t\t}\n\t}\n\t_, err := stats.Mode([]float64{})\n\tif err == nil {\n\t\tt.Errorf(\"Empty slice should have returned an error\")\n\t}\n}\n\nfunc BenchmarkModeSmallFloatSlice(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Mode(makeFloatSlice(5))\n\t}\n}\n\nfunc BenchmarkModeSmallRandFloatSlice(b *testing.B) {\n\tlf := makeRandFloatSlice(5)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Mode(lf)\n\t}\n}\n\nfunc BenchmarkModeLargeFloatSlice(b *testing.B) {\n\tlf := makeFloatSlice(100000)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Mode(lf)\n\t}\n}\n\nfunc BenchmarkModeLargeRandFloatSlice(b *testing.B) {\n\tlf := makeRandFloatSlice(100000)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Mode(lf)\n\t}\n}\n"
        },
        {
          "name": "nist_test.go",
          "type": "blob",
          "size": 23.7587890625,
          "content": "package stats_test\n\nimport (\n\t\"math\"\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nvar (\n\tlew = stats.Float64Data{\n\t\t-213, -564, -35, -15, 141, 115, -420, -360, 203, -338, -431, 194,\n\t\t-220, -513, 154, -125, -559, 92, -21, -579, -52, 99, -543, -175,\n\t\t162, -457, -346, 204, -300, -474, 164, -107, -572, -8, 83, -541,\n\t\t-224, 180, -420, -374, 201, -236, -531, 83, 27, -564, -112, 131,\n\t\t-507, -254, 199, -311, -495, 143, -46, -579, -90, 136, -472, -338,\n\t\t202, -287, -477, 169, -124, -568, 17, 48, -568, -135, 162, -430,\n\t\t-422, 172, -74, -577, -13, 92, -534, -243, 194, -355, -465, 156,\n\t\t-81, -578, -64, 139, -449, -384, 193, -198, -538, 110, -44, -577,\n\t\t-6, 66, -552, -164, 161, -460, -344, 205, -281, -504, 134, -28,\n\t\t-576, -118, 156, -437, -381, 200, -220, -540, 83, 11, -568, -160,\n\t\t172, -414, -408, 188, -125, -572, -32, 139, -492, -321, 205, -262,\n\t\t-504, 142, -83, -574, 0, 48, -571, -106, 137, -501, -266, 190,\n\t\t-391, -406, 194, -186, -553, 83, -13, -577, -49, 103, -515, -280,\n\t\t201, 300, -506, 131, -45, -578, -80, 138, -462, -361, 201, -211,\n\t\t-554, 32, 74, -533, -235, 187, -372, -442, 182, -147, -566, 25,\n\t\t68, -535, -244, 194, -351, -463, 174, -125, -570, 15, 72, -550,\n\t\t-190, 172, -424, -385, 198, -218, -536, 96}\n\n\tlottery = stats.Float64Data{\n\t\t162, 671, 933, 414, 788, 730, 817, 33, 536, 875, 670, 236, 473, 167,\n\t\t877, 980, 316, 950, 456, 92, 517, 557, 956, 954, 104, 178, 794, 278,\n\t\t147, 773, 437, 435, 502, 610, 582, 780, 689, 562, 964, 791, 28, 97,\n\t\t848, 281, 858, 538, 660, 972, 671, 613, 867, 448, 738, 966, 139, 636,\n\t\t847, 659, 754, 243, 122, 455, 195, 968, 793, 59, 730, 361, 574, 522,\n\t\t97, 762, 431, 158, 429, 414, 22, 629, 788, 999, 187, 215, 810, 782,\n\t\t47, 34, 108, 986, 25, 644, 829, 630, 315, 567, 919, 331, 207, 412,\n\t\t242, 607, 668, 944, 749, 168, 864, 442, 533, 805, 372, 63, 458, 777,\n\t\t416, 340, 436, 140, 919, 350, 510, 572, 905, 900, 85, 389, 473, 758,\n\t\t444, 169, 625, 692, 140, 897, 672, 288, 312, 860, 724, 226, 884, 508,\n\t\t976, 741, 476, 417, 831, 15, 318, 432, 241, 114, 799, 955, 833, 358,\n\t\t935, 146, 630, 830, 440, 642, 356, 373, 271, 715, 367, 393, 190, 669,\n\t\t8, 861, 108, 795, 269, 590, 326, 866, 64, 523, 862, 840, 219, 382,\n\t\t998, 4, 628, 305, 747, 247, 34, 747, 729, 645, 856, 974, 24, 568, 24,\n\t\t694, 608, 480, 410, 729, 947, 293, 53, 930, 223, 203, 677, 227, 62,\n\t\t455, 387, 318, 562, 242, 428, 968}\n\n\tmavro = stats.Float64Data{\n\t\t2.00180, 2.00170, 2.00180, 2.00190, 2.00180, 2.00170, 2.00150,\n\t\t2.00140, 2.00150, 2.00150, 2.00170, 2.00180, 2.00180, 2.00190,\n\t\t2.00190, 2.00210, 2.00200, 2.00160, 2.00140, 2.00130, 2.00130,\n\t\t2.00150, 2.00150, 2.00160, 2.00150, 2.00140, 2.00130, 2.00140,\n\t\t2.00150, 2.00140, 2.00150, 2.00160, 2.00150, 2.00160, 2.00190,\n\t\t2.00200, 2.00200, 2.00210, 2.00220, 2.00230, 2.00240, 2.00250,\n\t\t2.00270, 2.00260, 2.00260, 2.00260, 2.00270, 2.00260, 2.00250,\n\t\t2.00240}\n\n\tmichelson = stats.Float64Data{\n\t\t299.85, 299.74, 299.90, 300.07, 299.93, 299.85, 299.95, 299.98,\n\t\t299.98, 299.88, 300.00, 299.98, 299.93, 299.65, 299.76, 299.81,\n\t\t300.00, 300.00, 299.96, 299.96, 299.96, 299.94, 299.96, 299.94,\n\t\t299.88, 299.80, 299.85, 299.88, 299.90, 299.84, 299.83, 299.79,\n\t\t299.81, 299.88, 299.88, 299.83, 299.80, 299.79, 299.76, 299.80,\n\t\t299.88, 299.88, 299.88, 299.86, 299.72, 299.72, 299.62, 299.86,\n\t\t299.97, 299.95, 299.88, 299.91, 299.85, 299.87, 299.84, 299.84,\n\t\t299.85, 299.84, 299.84, 299.84, 299.89, 299.81, 299.81, 299.82,\n\t\t299.80, 299.77, 299.76, 299.74, 299.75, 299.76, 299.91, 299.92,\n\t\t299.89, 299.86, 299.88, 299.72, 299.84, 299.85, 299.85, 299.78,\n\t\t299.89, 299.84, 299.78, 299.81, 299.76, 299.81, 299.79, 299.81,\n\t\t299.82, 299.85, 299.87, 299.87, 299.81, 299.74, 299.81, 299.94,\n\t\t299.95, 299.80, 299.81, 299.87}\n\n\tpidigits = stats.Float64Data{\n\t\t3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8,\n\t\t9, 7, 9, 3, 2, 3, 8, 4, 6, 2, 6, 4, 3, 3, 8, 3, 2, 7, 9, 5, 0, 2,\n\t\t8, 8, 4, 1, 9, 7, 1, 6, 9, 3, 9, 9, 3, 7, 5, 1, 0, 5, 8, 2, 0, 9,\n\t\t7, 4, 9, 4, 4, 5, 9, 2, 3, 0, 7, 8, 1, 6, 4, 0, 6, 2, 8, 6, 2, 0,\n\t\t8, 9, 9, 8, 6, 2, 8, 0, 3, 4, 8, 2, 5, 3, 4, 2, 1, 1, 7, 0, 6, 7,\n\t\t9, 8, 2, 1, 4, 8, 0, 8, 6, 5, 1, 3, 2, 8, 2, 3, 0, 6, 6, 4, 7, 0,\n\t\t9, 3, 8, 4, 4, 6, 0, 9, 5, 5, 0, 5, 8, 2, 2, 3, 1, 7, 2, 5, 3, 5,\n\t\t9, 4, 0, 8, 1, 2, 8, 4, 8, 1, 1, 1, 7, 4, 5, 0, 2, 8, 4, 1, 0, 2,\n\t\t7, 0, 1, 9, 3, 8, 5, 2, 1, 1, 0, 5, 5, 5, 9, 6, 4, 4, 6, 2, 2, 9,\n\t\t4, 8, 9, 5, 4, 9, 3, 0, 3, 8, 1, 9, 6, 4, 4, 2, 8, 8, 1, 0, 9, 7,\n\t\t5, 6, 6, 5, 9, 3, 3, 4, 4, 6, 1, 2, 8, 4, 7, 5, 6, 4, 8, 2, 3, 3,\n\t\t7, 8, 6, 7, 8, 3, 1, 6, 5, 2, 7, 1, 2, 0, 1, 9, 0, 9, 1, 4, 5, 6,\n\t\t4, 8, 5, 6, 6, 9, 2, 3, 4, 6, 0, 3, 4, 8, 6, 1, 0, 4, 5, 4, 3, 2,\n\t\t6, 6, 4, 8, 2, 1, 3, 3, 9, 3, 6, 0, 7, 2, 6, 0, 2, 4, 9, 1, 4, 1,\n\t\t2, 7, 3, 7, 2, 4, 5, 8, 7, 0, 0, 6, 6, 0, 6, 3, 1, 5, 5, 8, 8, 1,\n\t\t7, 4, 8, 8, 1, 5, 2, 0, 9, 2, 0, 9, 6, 2, 8, 2, 9, 2, 5, 4, 0, 9,\n\t\t1, 7, 1, 5, 3, 6, 4, 3, 6, 7, 8, 9, 2, 5, 9, 0, 3, 6, 0, 0, 1, 1,\n\t\t3, 3, 0, 5, 3, 0, 5, 4, 8, 8, 2, 0, 4, 6, 6, 5, 2, 1, 3, 8, 4, 1,\n\t\t4, 6, 9, 5, 1, 9, 4, 1, 5, 1, 1, 6, 0, 9, 4, 3, 3, 0, 5, 7, 2, 7,\n\t\t0, 3, 6, 5, 7, 5, 9, 5, 9, 1, 9, 5, 3, 0, 9, 2, 1, 8, 6, 1, 1, 7,\n\t\t3, 8, 1, 9, 3, 2, 6, 1, 1, 7, 9, 3, 1, 0, 5, 1, 1, 8, 5, 4, 8, 0,\n\t\t7, 4, 4, 6, 2, 3, 7, 9, 9, 6, 2, 7, 4, 9, 5, 6, 7, 3, 5, 1, 8, 8,\n\t\t5, 7, 5, 2, 7, 2, 4, 8, 9, 1, 2, 2, 7, 9, 3, 8, 1, 8, 3, 0, 1, 1,\n\t\t9, 4, 9, 1, 2, 9, 8, 3, 3, 6, 7, 3, 3, 6, 2, 4, 4, 0, 6, 5, 6, 6,\n\t\t4, 3, 0, 8, 6, 0, 2, 1, 3, 9, 4, 9, 4, 6, 3, 9, 5, 2, 2, 4, 7, 3,\n\t\t7, 1, 9, 0, 7, 0, 2, 1, 7, 9, 8, 6, 0, 9, 4, 3, 7, 0, 2, 7, 7, 0,\n\t\t5, 3, 9, 2, 1, 7, 1, 7, 6, 2, 9, 3, 1, 7, 6, 7, 5, 2, 3, 8, 4, 6,\n\t\t7, 4, 8, 1, 8, 4, 6, 7, 6, 6, 9, 4, 0, 5, 1, 3, 2, 0, 0, 0, 5, 6,\n\t\t8, 1, 2, 7, 1, 4, 5, 2, 6, 3, 5, 6, 0, 8, 2, 7, 7, 8, 5, 7, 7, 1,\n\t\t3, 4, 2, 7, 5, 7, 7, 8, 9, 6, 0, 9, 1, 7, 3, 6, 3, 7, 1, 7, 8, 7,\n\t\t2, 1, 4, 6, 8, 4, 4, 0, 9, 0, 1, 2, 2, 4, 9, 5, 3, 4, 3, 0, 1, 4,\n\t\t6, 5, 4, 9, 5, 8, 5, 3, 7, 1, 0, 5, 0, 7, 9, 2, 2, 7, 9, 6, 8, 9,\n\t\t2, 5, 8, 9, 2, 3, 5, 4, 2, 0, 1, 9, 9, 5, 6, 1, 1, 2, 1, 2, 9, 0,\n\t\t2, 1, 9, 6, 0, 8, 6, 4, 0, 3, 4, 4, 1, 8, 1, 5, 9, 8, 1, 3, 6, 2,\n\t\t9, 7, 7, 4, 7, 7, 1, 3, 0, 9, 9, 6, 0, 5, 1, 8, 7, 0, 7, 2, 1, 1,\n\t\t3, 4, 9, 9, 9, 9, 9, 9, 8, 3, 7, 2, 9, 7, 8, 0, 4, 9, 9, 5, 1, 0,\n\t\t5, 9, 7, 3, 1, 7, 3, 2, 8, 1, 6, 0, 9, 6, 3, 1, 8, 5, 9, 5, 0, 2,\n\t\t4, 4, 5, 9, 4, 5, 5, 3, 4, 6, 9, 0, 8, 3, 0, 2, 6, 4, 2, 5, 2, 2,\n\t\t3, 0, 8, 2, 5, 3, 3, 4, 4, 6, 8, 5, 0, 3, 5, 2, 6, 1, 9, 3, 1, 1,\n\t\t8, 8, 1, 7, 1, 0, 1, 0, 0, 0, 3, 1, 3, 7, 8, 3, 8, 7, 5, 2, 8, 8,\n\t\t6, 5, 8, 7, 5, 3, 3, 2, 0, 8, 3, 8, 1, 4, 2, 0, 6, 1, 7, 1, 7, 7,\n\t\t6, 6, 9, 1, 4, 7, 3, 0, 3, 5, 9, 8, 2, 5, 3, 4, 9, 0, 4, 2, 8, 7,\n\t\t5, 5, 4, 6, 8, 7, 3, 1, 1, 5, 9, 5, 6, 2, 8, 6, 3, 8, 8, 2, 3, 5,\n\t\t3, 7, 8, 7, 5, 9, 3, 7, 5, 1, 9, 5, 7, 7, 8, 1, 8, 5, 7, 7, 3, 0,\n\t\t5, 3, 2, 1, 7, 1, 2, 2, 6, 8, 0, 6, 6, 1, 3, 0, 0, 1, 9, 2, 7, 8,\n\t\t7, 6, 6, 1, 1, 1, 9, 5, 9, 0, 9, 2, 1, 6, 4, 2, 0, 1, 9, 8, 9, 3,\n\t\t8, 0, 9, 5, 2, 5, 7, 2, 0, 1, 0, 6, 5, 4, 8, 5, 8, 6, 3, 2, 7, 8,\n\t\t8, 6, 5, 9, 3, 6, 1, 5, 3, 3, 8, 1, 8, 2, 7, 9, 6, 8, 2, 3, 0, 3,\n\t\t0, 1, 9, 5, 2, 0, 3, 5, 3, 0, 1, 8, 5, 2, 9, 6, 8, 9, 9, 5, 7, 7,\n\t\t3, 6, 2, 2, 5, 9, 9, 4, 1, 3, 8, 9, 1, 2, 4, 9, 7, 2, 1, 7, 7, 5,\n\t\t2, 8, 3, 4, 7, 9, 1, 3, 1, 5, 1, 5, 5, 7, 4, 8, 5, 7, 2, 4, 2, 4,\n\t\t5, 4, 1, 5, 0, 6, 9, 5, 9, 5, 0, 8, 2, 9, 5, 3, 3, 1, 1, 6, 8, 6,\n\t\t1, 7, 2, 7, 8, 5, 5, 8, 8, 9, 0, 7, 5, 0, 9, 8, 3, 8, 1, 7, 5, 4,\n\t\t6, 3, 7, 4, 6, 4, 9, 3, 9, 3, 1, 9, 2, 5, 5, 0, 6, 0, 4, 0, 0, 9,\n\t\t2, 7, 7, 0, 1, 6, 7, 1, 1, 3, 9, 0, 0, 9, 8, 4, 8, 8, 2, 4, 0, 1,\n\t\t2, 8, 5, 8, 3, 6, 1, 6, 0, 3, 5, 6, 3, 7, 0, 7, 6, 6, 0, 1, 0, 4,\n\t\t7, 1, 0, 1, 8, 1, 9, 4, 2, 9, 5, 5, 5, 9, 6, 1, 9, 8, 9, 4, 6, 7,\n\t\t6, 7, 8, 3, 7, 4, 4, 9, 4, 4, 8, 2, 5, 5, 3, 7, 9, 7, 7, 4, 7, 2,\n\t\t6, 8, 4, 7, 1, 0, 4, 0, 4, 7, 5, 3, 4, 6, 4, 6, 2, 0, 8, 0, 4, 6,\n\t\t6, 8, 4, 2, 5, 9, 0, 6, 9, 4, 9, 1, 2, 9, 3, 3, 1, 3, 6, 7, 7, 0,\n\t\t2, 8, 9, 8, 9, 1, 5, 2, 1, 0, 4, 7, 5, 2, 1, 6, 2, 0, 5, 6, 9, 6,\n\t\t6, 0, 2, 4, 0, 5, 8, 0, 3, 8, 1, 5, 0, 1, 9, 3, 5, 1, 1, 2, 5, 3,\n\t\t3, 8, 2, 4, 3, 0, 0, 3, 5, 5, 8, 7, 6, 4, 0, 2, 4, 7, 4, 9, 6, 4,\n\t\t7, 3, 2, 6, 3, 9, 1, 4, 1, 9, 9, 2, 7, 2, 6, 0, 4, 2, 6, 9, 9, 2,\n\t\t2, 7, 9, 6, 7, 8, 2, 3, 5, 4, 7, 8, 1, 6, 3, 6, 0, 0, 9, 3, 4, 1,\n\t\t7, 2, 1, 6, 4, 1, 2, 1, 9, 9, 2, 4, 5, 8, 6, 3, 1, 5, 0, 3, 0, 2,\n\t\t8, 6, 1, 8, 2, 9, 7, 4, 5, 5, 5, 7, 0, 6, 7, 4, 9, 8, 3, 8, 5, 0,\n\t\t5, 4, 9, 4, 5, 8, 8, 5, 8, 6, 9, 2, 6, 9, 9, 5, 6, 9, 0, 9, 2, 7,\n\t\t2, 1, 0, 7, 9, 7, 5, 0, 9, 3, 0, 2, 9, 5, 5, 3, 2, 1, 1, 6, 5, 3,\n\t\t4, 4, 9, 8, 7, 2, 0, 2, 7, 5, 5, 9, 6, 0, 2, 3, 6, 4, 8, 0, 6, 6,\n\t\t5, 4, 9, 9, 1, 1, 9, 8, 8, 1, 8, 3, 4, 7, 9, 7, 7, 5, 3, 5, 6, 6,\n\t\t3, 6, 9, 8, 0, 7, 4, 2, 6, 5, 4, 2, 5, 2, 7, 8, 6, 2, 5, 5, 1, 8,\n\t\t1, 8, 4, 1, 7, 5, 7, 4, 6, 7, 2, 8, 9, 0, 9, 7, 7, 7, 7, 2, 7, 9,\n\t\t3, 8, 0, 0, 0, 8, 1, 6, 4, 7, 0, 6, 0, 0, 1, 6, 1, 4, 5, 2, 4, 9,\n\t\t1, 9, 2, 1, 7, 3, 2, 1, 7, 2, 1, 4, 7, 7, 2, 3, 5, 0, 1, 4, 1, 4,\n\t\t4, 1, 9, 7, 3, 5, 6, 8, 5, 4, 8, 1, 6, 1, 3, 6, 1, 1, 5, 7, 3, 5,\n\t\t2, 5, 5, 2, 1, 3, 3, 4, 7, 5, 7, 4, 1, 8, 4, 9, 4, 6, 8, 4, 3, 8,\n\t\t5, 2, 3, 3, 2, 3, 9, 0, 7, 3, 9, 4, 1, 4, 3, 3, 3, 4, 5, 4, 7, 7,\n\t\t6, 2, 4, 1, 6, 8, 6, 2, 5, 1, 8, 9, 8, 3, 5, 6, 9, 4, 8, 5, 5, 6,\n\t\t2, 0, 9, 9, 2, 1, 9, 2, 2, 2, 1, 8, 4, 2, 7, 2, 5, 5, 0, 2, 5, 4,\n\t\t2, 5, 6, 8, 8, 7, 6, 7, 1, 7, 9, 0, 4, 9, 4, 6, 0, 1, 6, 5, 3, 4,\n\t\t6, 6, 8, 0, 4, 9, 8, 8, 6, 2, 7, 2, 3, 2, 7, 9, 1, 7, 8, 6, 0, 8,\n\t\t5, 7, 8, 4, 3, 8, 3, 8, 2, 7, 9, 6, 7, 9, 7, 6, 6, 8, 1, 4, 5, 4,\n\t\t1, 0, 0, 9, 5, 3, 8, 8, 3, 7, 8, 6, 3, 6, 0, 9, 5, 0, 6, 8, 0, 0,\n\t\t6, 4, 2, 2, 5, 1, 2, 5, 2, 0, 5, 1, 1, 7, 3, 9, 2, 9, 8, 4, 8, 9,\n\t\t6, 0, 8, 4, 1, 2, 8, 4, 8, 8, 6, 2, 6, 9, 4, 5, 6, 0, 4, 2, 4, 1,\n\t\t9, 6, 5, 2, 8, 5, 0, 2, 2, 2, 1, 0, 6, 6, 1, 1, 8, 6, 3, 0, 6, 7,\n\t\t4, 4, 2, 7, 8, 6, 2, 2, 0, 3, 9, 1, 9, 4, 9, 4, 5, 0, 4, 7, 1, 2,\n\t\t3, 7, 1, 3, 7, 8, 6, 9, 6, 0, 9, 5, 6, 3, 6, 4, 3, 7, 1, 9, 1, 7,\n\t\t2, 8, 7, 4, 6, 7, 7, 6, 4, 6, 5, 7, 5, 7, 3, 9, 6, 2, 4, 1, 3, 8,\n\t\t9, 0, 8, 6, 5, 8, 3, 2, 6, 4, 5, 9, 9, 5, 8, 1, 3, 3, 9, 0, 4, 7,\n\t\t8, 0, 2, 7, 5, 9, 0, 0, 9, 9, 4, 6, 5, 7, 6, 4, 0, 7, 8, 9, 5, 1,\n\t\t2, 6, 9, 4, 6, 8, 3, 9, 8, 3, 5, 2, 5, 9, 5, 7, 0, 9, 8, 2, 5, 8,\n\t\t2, 2, 6, 2, 0, 5, 2, 2, 4, 8, 9, 4, 0, 7, 7, 2, 6, 7, 1, 9, 4, 7,\n\t\t8, 2, 6, 8, 4, 8, 2, 6, 0, 1, 4, 7, 6, 9, 9, 0, 9, 0, 2, 6, 4, 0,\n\t\t1, 3, 6, 3, 9, 4, 4, 3, 7, 4, 5, 5, 3, 0, 5, 0, 6, 8, 2, 0, 3, 4,\n\t\t9, 6, 2, 5, 2, 4, 5, 1, 7, 4, 9, 3, 9, 9, 6, 5, 1, 4, 3, 1, 4, 2,\n\t\t9, 8, 0, 9, 1, 9, 0, 6, 5, 9, 2, 5, 0, 9, 3, 7, 2, 2, 1, 6, 9, 6,\n\t\t4, 6, 1, 5, 1, 5, 7, 0, 9, 8, 5, 8, 3, 8, 7, 4, 1, 0, 5, 9, 7, 8,\n\t\t8, 5, 9, 5, 9, 7, 7, 2, 9, 7, 5, 4, 9, 8, 9, 3, 0, 1, 6, 1, 7, 5,\n\t\t3, 9, 2, 8, 4, 6, 8, 1, 3, 8, 2, 6, 8, 6, 8, 3, 8, 6, 8, 9, 4, 2,\n\t\t7, 7, 4, 1, 5, 5, 9, 9, 1, 8, 5, 5, 9, 2, 5, 2, 4, 5, 9, 5, 3, 9,\n\t\t5, 9, 4, 3, 1, 0, 4, 9, 9, 7, 2, 5, 2, 4, 6, 8, 0, 8, 4, 5, 9, 8,\n\t\t7, 2, 7, 3, 6, 4, 4, 6, 9, 5, 8, 4, 8, 6, 5, 3, 8, 3, 6, 7, 3, 6,\n\t\t2, 2, 2, 6, 2, 6, 0, 9, 9, 1, 2, 4, 6, 0, 8, 0, 5, 1, 2, 4, 3, 8,\n\t\t8, 4, 3, 9, 0, 4, 5, 1, 2, 4, 4, 1, 3, 6, 5, 4, 9, 7, 6, 2, 7, 8,\n\t\t0, 7, 9, 7, 7, 1, 5, 6, 9, 1, 4, 3, 5, 9, 9, 7, 7, 0, 0, 1, 2, 9,\n\t\t6, 1, 6, 0, 8, 9, 4, 4, 1, 6, 9, 4, 8, 6, 8, 5, 5, 5, 8, 4, 8, 4,\n\t\t0, 6, 3, 5, 3, 4, 2, 2, 0, 7, 2, 2, 2, 5, 8, 2, 8, 4, 8, 8, 6, 4,\n\t\t8, 1, 5, 8, 4, 5, 6, 0, 2, 8, 5, 0, 6, 0, 1, 6, 8, 4, 2, 7, 3, 9,\n\t\t4, 5, 2, 2, 6, 7, 4, 6, 7, 6, 7, 8, 8, 9, 5, 2, 5, 2, 1, 3, 8, 5,\n\t\t2, 2, 5, 4, 9, 9, 5, 4, 6, 6, 6, 7, 2, 7, 8, 2, 3, 9, 8, 6, 4, 5,\n\t\t6, 5, 9, 6, 1, 1, 6, 3, 5, 4, 8, 8, 6, 2, 3, 0, 5, 7, 7, 4, 5, 6,\n\t\t4, 9, 8, 0, 3, 5, 5, 9, 3, 6, 3, 4, 5, 6, 8, 1, 7, 4, 3, 2, 4, 1,\n\t\t1, 2, 5, 1, 5, 0, 7, 6, 0, 6, 9, 4, 7, 9, 4, 5, 1, 0, 9, 6, 5, 9,\n\t\t6, 0, 9, 4, 0, 2, 5, 2, 2, 8, 8, 7, 9, 7, 1, 0, 8, 9, 3, 1, 4, 5,\n\t\t6, 6, 9, 1, 3, 6, 8, 6, 7, 2, 2, 8, 7, 4, 8, 9, 4, 0, 5, 6, 0, 1,\n\t\t0, 1, 5, 0, 3, 3, 0, 8, 6, 1, 7, 9, 2, 8, 6, 8, 0, 9, 2, 0, 8, 7,\n\t\t4, 7, 6, 0, 9, 1, 7, 8, 2, 4, 9, 3, 8, 5, 8, 9, 0, 0, 9, 7, 1, 4,\n\t\t9, 0, 9, 6, 7, 5, 9, 8, 5, 2, 6, 1, 3, 6, 5, 5, 4, 9, 7, 8, 1, 8,\n\t\t9, 3, 1, 2, 9, 7, 8, 4, 8, 2, 1, 6, 8, 2, 9, 9, 8, 9, 4, 8, 7, 2,\n\t\t2, 6, 5, 8, 8, 0, 4, 8, 5, 7, 5, 6, 4, 0, 1, 4, 2, 7, 0, 4, 7, 7,\n\t\t5, 5, 5, 1, 3, 2, 3, 7, 9, 6, 4, 1, 4, 5, 1, 5, 2, 3, 7, 4, 6, 2,\n\t\t3, 4, 3, 6, 4, 5, 4, 2, 8, 5, 8, 4, 4, 4, 7, 9, 5, 2, 6, 5, 8, 6,\n\t\t7, 8, 2, 1, 0, 5, 1, 1, 4, 1, 3, 5, 4, 7, 3, 5, 7, 3, 9, 5, 2, 3,\n\t\t1, 1, 3, 4, 2, 7, 1, 6, 6, 1, 0, 2, 1, 3, 5, 9, 6, 9, 5, 3, 6, 2,\n\t\t3, 1, 4, 4, 2, 9, 5, 2, 4, 8, 4, 9, 3, 7, 1, 8, 7, 1, 1, 0, 1, 4,\n\t\t5, 7, 6, 5, 4, 0, 3, 5, 9, 0, 2, 7, 9, 9, 3, 4, 4, 0, 3, 7, 4, 2,\n\t\t0, 0, 7, 3, 1, 0, 5, 7, 8, 5, 3, 9, 0, 6, 2, 1, 9, 8, 3, 8, 7, 4,\n\t\t4, 7, 8, 0, 8, 4, 7, 8, 4, 8, 9, 6, 8, 3, 3, 2, 1, 4, 4, 5, 7, 1,\n\t\t3, 8, 6, 8, 7, 5, 1, 9, 4, 3, 5, 0, 6, 4, 3, 0, 2, 1, 8, 4, 5, 3,\n\t\t1, 9, 1, 0, 4, 8, 4, 8, 1, 0, 0, 5, 3, 7, 0, 6, 1, 4, 6, 8, 0, 6,\n\t\t7, 4, 9, 1, 9, 2, 7, 8, 1, 9, 1, 1, 9, 7, 9, 3, 9, 9, 5, 2, 0, 6,\n\t\t1, 4, 1, 9, 6, 6, 3, 4, 2, 8, 7, 5, 4, 4, 4, 0, 6, 4, 3, 7, 4, 5,\n\t\t1, 2, 3, 7, 1, 8, 1, 9, 2, 1, 7, 9, 9, 9, 8, 3, 9, 1, 0, 1, 5, 9,\n\t\t1, 9, 5, 6, 1, 8, 1, 4, 6, 7, 5, 1, 4, 2, 6, 9, 1, 2, 3, 9, 7, 4,\n\t\t8, 9, 4, 0, 9, 0, 7, 1, 8, 6, 4, 9, 4, 2, 3, 1, 9, 6, 1, 5, 6, 7,\n\t\t9, 4, 5, 2, 0, 8, 0, 9, 5, 1, 4, 6, 5, 5, 0, 2, 2, 5, 2, 3, 1, 6,\n\t\t0, 3, 8, 8, 1, 9, 3, 0, 1, 4, 2, 0, 9, 3, 7, 6, 2, 1, 3, 7, 8, 5,\n\t\t5, 9, 5, 6, 6, 3, 8, 9, 3, 7, 7, 8, 7, 0, 8, 3, 0, 3, 9, 0, 6, 9,\n\t\t7, 9, 2, 0, 7, 7, 3, 4, 6, 7, 2, 2, 1, 8, 2, 5, 6, 2, 5, 9, 9, 6,\n\t\t6, 1, 5, 0, 1, 4, 2, 1, 5, 0, 3, 0, 6, 8, 0, 3, 8, 4, 4, 7, 7, 3,\n\t\t4, 5, 4, 9, 2, 0, 2, 6, 0, 5, 4, 1, 4, 6, 6, 5, 9, 2, 5, 2, 0, 1,\n\t\t4, 9, 7, 4, 4, 2, 8, 5, 0, 7, 3, 2, 5, 1, 8, 6, 6, 6, 0, 0, 2, 1,\n\t\t3, 2, 4, 3, 4, 0, 8, 8, 1, 9, 0, 7, 1, 0, 4, 8, 6, 3, 3, 1, 7, 3,\n\t\t4, 6, 4, 9, 6, 5, 1, 4, 5, 3, 9, 0, 5, 7, 9, 6, 2, 6, 8, 5, 6, 1,\n\t\t0, 0, 5, 5, 0, 8, 1, 0, 6, 6, 5, 8, 7, 9, 6, 9, 9, 8, 1, 6, 3, 5,\n\t\t7, 4, 7, 3, 6, 3, 8, 4, 0, 5, 2, 5, 7, 1, 4, 5, 9, 1, 0, 2, 8, 9,\n\t\t7, 0, 6, 4, 1, 4, 0, 1, 1, 0, 9, 7, 1, 2, 0, 6, 2, 8, 0, 4, 3, 9,\n\t\t0, 3, 9, 7, 5, 9, 5, 1, 5, 6, 7, 7, 1, 5, 7, 7, 0, 0, 4, 2, 0, 3,\n\t\t3, 7, 8, 6, 9, 9, 3, 6, 0, 0, 7, 2, 3, 0, 5, 5, 8, 7, 6, 3, 1, 7,\n\t\t6, 3, 5, 9, 4, 2, 1, 8, 7, 3, 1, 2, 5, 1, 4, 7, 1, 2, 0, 5, 3, 2,\n\t\t9, 2, 8, 1, 9, 1, 8, 2, 6, 1, 8, 6, 1, 2, 5, 8, 6, 7, 3, 2, 1, 5,\n\t\t7, 9, 1, 9, 8, 4, 1, 4, 8, 4, 8, 8, 2, 9, 1, 6, 4, 4, 7, 0, 6, 0,\n\t\t9, 5, 7, 5, 2, 7, 0, 6, 9, 5, 7, 2, 2, 0, 9, 1, 7, 5, 6, 7, 1, 1,\n\t\t6, 7, 2, 2, 9, 1, 0, 9, 8, 1, 6, 9, 0, 9, 1, 5, 2, 8, 0, 1, 7, 3,\n\t\t5, 0, 6, 7, 1, 2, 7, 4, 8, 5, 8, 3, 2, 2, 2, 8, 7, 1, 8, 3, 5, 2,\n\t\t0, 9, 3, 5, 3, 9, 6, 5, 7, 2, 5, 1, 2, 1, 0, 8, 3, 5, 7, 9, 1, 5,\n\t\t1, 3, 6, 9, 8, 8, 2, 0, 9, 1, 4, 4, 4, 2, 1, 0, 0, 6, 7, 5, 1, 0,\n\t\t3, 3, 4, 6, 7, 1, 1, 0, 3, 1, 4, 1, 2, 6, 7, 1, 1, 1, 3, 6, 9, 9,\n\t\t0, 8, 6, 5, 8, 5, 1, 6, 3, 9, 8, 3, 1, 5, 0, 1, 9, 7, 0, 1, 6, 5,\n\t\t1, 5, 1, 1, 6, 8, 5, 1, 7, 1, 4, 3, 7, 6, 5, 7, 6, 1, 8, 3, 5, 1,\n\t\t5, 5, 6, 5, 0, 8, 8, 4, 9, 0, 9, 9, 8, 9, 8, 5, 9, 9, 8, 2, 3, 8,\n\t\t7, 3, 4, 5, 5, 2, 8, 3, 3, 1, 6, 3, 5, 5, 0, 7, 6, 4, 7, 9, 1, 8,\n\t\t5, 3, 5, 8, 9, 3, 2, 2, 6, 1, 8, 5, 4, 8, 9, 6, 3, 2, 1, 3, 2, 9,\n\t\t3, 3, 0, 8, 9, 8, 5, 7, 0, 6, 4, 2, 0, 4, 6, 7, 5, 2, 5, 9, 0, 7,\n\t\t0, 9, 1, 5, 4, 8, 1, 4, 1, 6, 5, 4, 9, 8, 5, 9, 4, 6, 1, 6, 3, 7,\n\t\t1, 8, 0, 2, 7, 0, 9, 8, 1, 9, 9, 4, 3, 0, 9, 9, 2, 4, 4, 8, 8, 9,\n\t\t5, 7, 5, 7, 1, 2, 8, 2, 8, 9, 0, 5, 9, 2, 3, 2, 3, 3, 2, 6, 0, 9,\n\t\t7, 2, 9, 9, 7, 1, 2, 0, 8, 4, 4, 3, 3, 5, 7, 3, 2, 6, 5, 4, 8, 9,\n\t\t3, 8, 2, 3, 9, 1, 1, 9, 3, 2, 5, 9, 7, 4, 6, 3, 6, 6, 7, 3, 0, 5,\n\t\t8, 3, 6, 0, 4, 1, 4, 2, 8, 1, 3, 8, 8, 3, 0, 3, 2, 0, 3, 8, 2, 4,\n\t\t9, 0, 3, 7, 5, 8, 9, 8, 5, 2, 4, 3, 7, 4, 4, 1, 7, 0, 2, 9, 1, 3,\n\t\t2, 7, 6, 5, 6, 1, 8, 0, 9, 3, 7, 7, 3, 4, 4, 4, 0, 3, 0, 7, 0, 7,\n\t\t4, 6, 9, 2, 1, 1, 2, 0, 1, 9, 1, 3, 0, 2, 0, 3, 3, 0, 3, 8, 0, 1,\n\t\t9, 7, 6, 2, 1, 1, 0, 1, 1, 0, 0, 4, 4, 9, 2, 9, 3, 2, 1, 5, 1, 6,\n\t\t0, 8, 4, 2, 4, 4, 4, 8, 5, 9, 6, 3, 7, 6, 6, 9, 8, 3, 8, 9, 5, 2,\n\t\t2, 8, 6, 8, 4, 7, 8, 3, 1, 2, 3, 5, 5, 2, 6, 5, 8, 2, 1, 3, 1, 4,\n\t\t4, 9, 5, 7, 6, 8, 5, 7, 2, 6, 2, 4, 3, 3, 4, 4, 1, 8, 9, 3, 0, 3,\n\t\t9, 6, 8, 6, 4, 2, 6, 2, 4, 3, 4, 1, 0, 7, 7, 3, 2, 2, 6, 9, 7, 8,\n\t\t0, 2, 8, 0, 7, 3, 1, 8, 9, 1, 5, 4, 4, 1, 1, 0, 1, 0, 4, 4, 6, 8,\n\t\t2, 3, 2, 5, 2, 7, 1, 6, 2, 0, 1, 0, 5, 2, 6, 5, 2, 2, 7, 2, 1, 1,\n\t\t1, 6, 6, 0, 3, 9, 6, 6, 6, 5, 5, 7, 3, 0, 9, 2, 5, 4, 7, 1, 1, 0,\n\t\t5, 5, 7, 8, 5, 3, 7, 6, 3, 4, 6, 6, 8, 2, 0, 6, 5, 3, 1, 0, 9, 8,\n\t\t9, 6, 5, 2, 6, 9, 1, 8, 6, 2, 0, 5, 6, 4, 7, 6, 9, 3, 1, 2, 5, 7,\n\t\t0, 5, 8, 6, 3, 5, 6, 6, 2, 0, 1, 8, 5, 5, 8, 1, 0, 0, 7, 2, 9, 3,\n\t\t6, 0, 6, 5, 9, 8, 7, 6, 4, 8, 6, 1, 1, 7, 9, 1, 0, 4, 5, 3, 3, 4,\n\t\t8, 8, 5, 0, 3, 4, 6, 1, 1, 3, 6, 5, 7, 6, 8, 6, 7, 5, 3, 2, 4, 9,\n\t\t4, 4, 1, 6, 6, 8, 0, 3, 9, 6, 2, 6, 5, 7, 9, 7, 8, 7, 7, 1, 8, 5,\n\t\t5, 6, 0, 8, 4, 5, 5, 2, 9, 6, 5, 4, 1, 2, 6, 6, 5, 4, 0, 8, 5, 3,\n\t\t0, 6, 1, 4, 3, 4, 4, 4, 3, 1, 8, 5, 8, 6, 7, 6, 9, 7, 5, 1, 4, 5,\n\t\t6, 6, 1, 4, 0, 6, 8, 0, 0, 7, 0, 0, 2, 3, 7, 8, 7, 7, 6, 5, 9, 1,\n\t\t3, 4, 4, 0, 1, 7, 1, 2, 7, 4, 9, 4, 7, 0, 4, 2, 0, 5, 6, 2, 2, 3,\n\t\t0, 5, 3, 8, 9, 9, 4, 5, 6, 1, 3, 1, 4, 0, 7, 1, 1, 2, 7, 0, 0, 0,\n\t\t4, 0, 7, 8, 5, 4, 7, 3, 3, 2, 6, 9, 9, 3, 9, 0, 8, 1, 4, 5, 4, 6,\n\t\t6, 4, 6, 4, 5, 8, 8, 0, 7, 9, 7, 2, 7, 0, 8, 2, 6, 6, 8, 3, 0, 6,\n\t\t3, 4, 3, 2, 8, 5, 8, 7, 8, 5, 6, 9, 8, 3, 0, 5, 2, 3, 5, 8, 0, 8,\n\t\t9, 3, 3, 0, 6, 5, 7, 5, 7, 4, 0, 6, 7, 9, 5, 4, 5, 7, 1, 6, 3, 7,\n\t\t7, 5, 2, 5, 4, 2, 0, 2, 1, 1, 4, 9, 5, 5, 7, 6, 1, 5, 8, 1, 4, 0,\n\t\t0, 2, 5, 0, 1, 2, 6, 2, 2, 8, 5, 9, 4, 1, 3, 0, 2, 1, 6, 4, 7, 1,\n\t\t5, 5, 0, 9, 7, 9, 2, 5, 9, 2, 3, 0, 9, 9, 0, 7, 9, 6, 5, 4, 7, 3,\n\t\t7, 6, 1, 2, 5, 5, 1, 7, 6, 5, 6, 7, 5, 1, 3, 5, 7, 5, 1, 7, 8, 2,\n\t\t9, 6, 6, 6, 4, 5, 4, 7, 7, 9, 1, 7, 4, 5, 0, 1, 1, 2, 9, 9, 6, 1,\n\t\t4, 8, 9, 0, 3, 0, 4, 6, 3, 9, 9, 4, 7, 1, 3, 2, 9, 6, 2, 1, 0, 7,\n\t\t3, 4, 0, 4, 3, 7, 5, 1, 8, 9, 5, 7, 3, 5, 9, 6, 1, 4, 5, 8, 9, 0,\n\t\t1, 9, 3, 8, 9, 7, 1, 3, 1, 1, 1, 7, 9, 0, 4, 2, 9, 7, 8, 2, 8, 5,\n\t\t6, 4, 7, 5, 0, 3, 2, 0, 3, 1, 9, 8, 6, 9, 1, 5, 1, 4, 0, 2, 8, 7,\n\t\t0, 8, 0, 8, 5, 9, 9, 0, 4, 8, 0, 1, 0, 9, 4, 1, 2, 1, 4, 7, 2, 2,\n\t\t1, 3, 1, 7, 9, 4, 7, 6, 4, 7, 7, 7, 2, 6, 2, 2, 4, 1, 4, 2, 5, 4,\n\t\t8, 5, 4, 5, 4, 0, 3, 3, 2, 1, 5, 7, 1, 8, 5, 3, 0, 6, 1, 4, 2, 2,\n\t\t8, 8, 1, 3, 7, 5, 8, 5, 0, 4, 3, 0, 6, 3, 3, 2, 1, 7, 5, 1, 8, 2,\n\t\t9, 7, 9, 8, 6, 6, 2, 2, 3, 7, 1, 7, 2, 1, 5, 9, 1, 6, 0, 7, 7, 1,\n\t\t6, 6, 9, 2, 5, 4, 7, 4, 8, 7, 3, 8, 9, 8, 6, 6, 5, 4, 9, 4, 9, 4,\n\t\t5, 0, 1, 1, 4, 6, 5, 4, 0, 6, 2, 8, 4, 3, 3, 6, 6, 3, 9, 3, 7, 9,\n\t\t0, 0, 3, 9, 7, 6, 9, 2, 6, 5, 6, 7, 2, 1, 4, 6, 3, 8, 5, 3, 0, 6,\n\t\t7, 3, 6, 0, 9, 6, 5, 7, 1, 2, 0, 9, 1, 8, 0, 7, 6, 3, 8, 3, 2, 7,\n\t\t1, 6, 6, 4, 1, 6, 2, 7, 4, 8, 8, 8, 8, 0, 0, 7, 8, 6, 9, 2, 5, 6,\n\t\t0, 2, 9, 0, 2, 2, 8, 4, 7, 2, 1, 0, 4, 0, 3, 1, 7, 2, 1, 1, 8, 6,\n\t\t0, 8, 2, 0, 4, 1, 9, 0, 0, 0, 4, 2, 2, 9, 6, 6, 1, 7, 1, 1, 9, 6,\n\t\t3, 7, 7, 9, 2, 1, 3, 3, 7, 5, 7, 5, 1, 1, 4, 9, 5, 9, 5, 0, 1, 5,\n\t\t6, 6, 0, 4, 9, 6, 3, 1, 8, 6, 2, 9, 4, 7, 2, 6, 5, 4, 7, 3, 6, 4,\n\t\t2, 5, 2, 3, 0, 8, 1, 7, 7, 0, 3, 6, 7, 5, 1, 5, 9, 0, 6, 7, 3, 5,\n\t\t0, 2, 3, 5, 0, 7, 2, 8, 3, 5, 4, 0, 5, 6, 7, 0, 4, 0, 3, 8, 6, 7,\n\t\t4, 3, 5, 1, 3, 6, 2, 2, 2, 2, 4, 7, 7, 1, 5, 8, 9, 1, 5, 0, 4, 9,\n\t\t5, 3, 0, 9, 8, 4, 4, 4, 8, 9, 3, 3, 3, 0, 9, 6, 3, 4, 0, 8, 7, 8,\n\t\t0, 7, 6, 9, 3, 2, 5, 9, 9, 3, 9, 7, 8, 0, 5, 4, 1, 9, 3, 4, 1, 4,\n\t\t4, 7, 3, 7, 7, 4, 4, 1, 8, 4, 2, 6, 3, 1, 2, 9, 8, 6, 0, 8, 0, 9,\n\t\t9, 8, 8, 8, 6, 8, 7, 4, 1, 3, 2, 6, 0, 4, 7, 2}\n\tnumacc1 = stats.Float64Data{10000001, 10000003, 10000002}\n\tnumacc2 = make(stats.Float64Data, 1001)\n\tnumacc3 = make(stats.Float64Data, 1001)\n\tnumacc4 = make(stats.Float64Data, 1001)\n)\n\nfunc init() {\n\tnumacc2[0] = 1.2\n\tnumacc3[0] = 1000000.2\n\tnumacc4[0] = 10000000.2\n\tfor i := 1; i < 1000; i += 2 {\n\t\tnumacc2[i] = 1.1\n\t\tnumacc2[i+1] = 1.3\n\t\tnumacc3[i] = 1000000.1\n\t\tnumacc3[i+1] = 1000000.3\n\t\tnumacc4[i] = 10000000.1\n\t\tnumacc4[i+1] = 10000000.3\n\t}\n}\n\nfunc TestLewData(t *testing.T) {\n\tr, e := stats.Mean(lew)\n\ttest(\"Lew Mean\", r, -177.435000000000, 1e-15, e, t)\n\n\tr, e = stats.StandardDeviationSample(lew)\n\ttest(\"Lew Standard Deviation\", r, 277.332168044316, 1e-15, e, t)\n\n\tr, e = stats.AutoCorrelation(lew, 1)\n\ttest(\"Lew AutoCorrelate1\", r, -0.307304800605679, 1e-14, e, t)\n}\n\nfunc TestLotteryData(t *testing.T) {\n\tr, e := stats.Mean(lottery)\n\ttest(\"Lottery Mean\", r, 518.958715596330, 1e-15, e, t)\n\n\tr, e = stats.StandardDeviationSample(lottery)\n\ttest(\"Lottery Standard Deviation\", r, 291.699727470969, 1e-15, e, t)\n\n\tr, e = stats.AutoCorrelation(lottery, 1)\n\ttest(\"Lottery AutoCorrelate1\", r, -0.120948622967393, 1e-14, e, t)\n}\n\nfunc TestMavroData(t *testing.T) {\n\tr, e := stats.Mean(mavro)\n\ttest(\"Mavro Mean\", r, 2.00185600000000, 1e-15, e, t)\n\n\tr, e = stats.StandardDeviationSample(mavro)\n\ttest(\"Mavro Standard Deviation\", r, 0.000429123454003053, 1e-13, e, t)\n\n\tr, e = stats.AutoCorrelation(mavro, 1)\n\ttest(\"Mavro AutoCorrelate1\", r, 0.937989183438248, 1e-13, e, t)\n}\n\nfunc TestMichelsonData(t *testing.T) {\n\tr, e := stats.Mean(michelson)\n\ttest(\"Michelson Mean\", r, 299.852400000000, 1e-15, e, t)\n\n\tr, e = stats.StandardDeviationSample(michelson)\n\ttest(\"Michelson Standard Deviation\", r, 0.0790105478190518, 1e-13, e, t)\n\n\tr, e = stats.AutoCorrelation(michelson, 1)\n\ttest(\"Michelson AutoCorrelate1\", r, 0.535199668621283, 1e-13, e, t)\n}\n\nfunc TestPidigitsData(t *testing.T) {\n\tr, e := stats.Mean(pidigits)\n\ttest(\"Pidigits Mean\", r, 4.53480000000000, 1e-14, e, t)\n\n\tr, e = stats.StandardDeviationSample(pidigits)\n\ttest(\"Pidigits Standard Deviation\", r, 2.86733906028871, 1e-14, e, t)\n\n\tr, e = stats.AutoCorrelation(pidigits, 1)\n\ttest(\"Pidigits AutoCorrelate1\", r, -0.00355099287237972, 1e-13, e, t)\n}\n\nfunc TestNumacc1Data(t *testing.T) {\n\tr, e := stats.Mean(numacc1)\n\ttest(\"numacc1 Mean\", r, 10000002.0, 1e-14, e, t)\n\n\tr, e = stats.StandardDeviationSample(numacc1)\n\ttest(\"numacc1 Standard Deviation\", r, 1.0, 1e-13, e, t)\n\n\tr, e = stats.AutoCorrelation(numacc1, 1)\n\ttest(\"Lew AutoCorrelateNumacc1\", r, -0.5, 1e-15, e, t)\n\n}\n\nfunc TestNumacc2Data(t *testing.T) {\n\tr, e := stats.Mean(numacc2)\n\ttest(\"numacc2 Mean\", r, 1.2, 1e-10, e, t)\n\n\tr, e = stats.StandardDeviationSample(numacc2)\n\ttest(\"numacc2 Standard Deviation\", r, 0.1, 1e-10, e, t)\n\n\tr, e = stats.AutoCorrelation(numacc2, 1)\n\ttest(\"Lew AutoCorrelateNumacc2\", r, -0.999, 1e-10, e, t)\n}\n\nfunc TestNumacc3Data(t *testing.T) {\n\tr, e := stats.Mean(numacc3)\n\ttest(\"numacc3 Mean\", r, 1000000.2, 1e-15, e, t)\n\n\tr, e = stats.StandardDeviationSample(numacc3)\n\ttest(\"numacc3 Standard Deviation\", r, 0.1, 1e-9, e, t)\n\n\tr, e = stats.AutoCorrelation(numacc3, 1)\n\ttest(\"Lew AutoCorrelateNumacc3\", r, -0.999, 1e-10, e, t)\n}\n\nfunc TestNumacc4Data(t *testing.T) {\n\tr, e := stats.Mean(numacc4)\n\ttest(\"numacc4 Mean\", r, 10000000.2, 1e-10, e, t)\n\n\tr, e = stats.StandardDeviationSample(numacc4)\n\ttest(\"numacc4 Standard Deviation\", r, 0.1, 1e-7, e, t)\n\n\tr, e = stats.AutoCorrelation(numacc4, 1)\n\ttest(\"Lew AutoCorrelateNumacc4\", r, -0.999, 1e-7, e, t)\n}\n\nfunc bench(d stats.Float64Data) {\n\t_, _ = stats.Mean(d)\n\t_, _ = stats.StdDevS(d)\n\t_, _ = stats.AutoCorrelation(d, 1)\n}\n\nfunc BenchmarkNistLew(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tbench(lew)\n\t}\n}\n\nfunc BenchmarkNistLottery(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tbench(lottery)\n\t}\n}\n\nfunc BenchmarkNistMavro(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tbench(mavro)\n\t}\n}\n\nfunc BenchmarkNistMichelson(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tbench(michelson)\n\t}\n}\n\nfunc BenchmarkNistPidigits(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tbench(pidigits)\n\t}\n}\n\nfunc BenchmarkNistNumacc1(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tbench(numacc1)\n\t}\n}\n\nfunc BenchmarkNistNumacc2(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tbench(numacc2)\n\t}\n}\n\nfunc BenchmarkNistNumacc3(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tbench(numacc3)\n\t}\n}\n\nfunc BenchmarkNistNumacc4(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tbench(numacc4)\n\t}\n}\n\nfunc BenchmarkNistAll(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tbench(lew)\n\t\tbench(lottery)\n\t\tbench(mavro)\n\t\tbench(michelson)\n\t\tbench(pidigits)\n\t\tbench(numacc1)\n\t\tbench(numacc2)\n\t\tbench(numacc3)\n\t\tbench(numacc4)\n\t}\n}\n\nfunc test(d string, r, a, v float64, e error, t *testing.T) {\n\tif e != nil {\n\t\tt.Error(e)\n\t}\n\n\tvar failure bool\n\tif math.IsNaN(r) || math.IsNaN(a) {\n\t\tfailure = math.IsNaN(r) != math.IsNaN(a)\n\t} else if math.IsInf(r, 0) || math.IsInf(a, 0) {\n\t\tfailure = math.IsInf(r, 0) != math.IsInf(a, 0)\n\t} else if a != 0 {\n\t\tfailure = math.Abs(r-a)/math.Abs(a) > v\n\t} else {\n\t\tfailure = math.Abs(r) > v\n\t}\n\n\tif failure {\n\t\tt.Errorf(\"%s => %v != %v\", d, r, a)\n\t}\n}\n"
        },
        {
          "name": "norm.go",
          "type": "blob",
          "size": 7.4619140625,
          "content": "package stats\n\nimport (\n\t\"math\"\n\t\"math/rand\"\n\t\"strings\"\n\t\"time\"\n)\n\n// NormPpfRvs generates random variates using the Point Percentile Function.\n// For more information please visit: https://demonstrations.wolfram.com/TheMethodOfInverseTransforms/\nfunc NormPpfRvs(loc float64, scale float64, size int) []float64 {\n\trand.Seed(time.Now().UnixNano())\n\tvar toReturn []float64\n\tfor i := 0; i < size; i++ {\n\t\ttoReturn = append(toReturn, NormPpf(rand.Float64(), loc, scale))\n\t}\n\treturn toReturn\n}\n\n// NormBoxMullerRvs generates random variates using the Box–Muller transform.\n// For more information please visit: http://mathworld.wolfram.com/Box-MullerTransformation.html\nfunc NormBoxMullerRvs(loc float64, scale float64, size int) []float64 {\n\trand.Seed(time.Now().UnixNano())\n\tvar toReturn []float64\n\tfor i := 0; i < int(float64(size/2)+float64(size%2)); i++ {\n\t\t// u1 and u2 are uniformly distributed random numbers between 0 and 1.\n\t\tu1 := rand.Float64()\n\t\tu2 := rand.Float64()\n\t\t// x1 and x2 are normally distributed random numbers.\n\t\tx1 := loc + (scale * (math.Sqrt(-2*math.Log(u1)) * math.Cos(2*math.Pi*u2)))\n\t\ttoReturn = append(toReturn, x1)\n\t\tif (i+1)*2 <= size {\n\t\t\tx2 := loc + (scale * (math.Sqrt(-2*math.Log(u1)) * math.Sin(2*math.Pi*u2)))\n\t\t\ttoReturn = append(toReturn, x2)\n\t\t}\n\t}\n\treturn toReturn\n}\n\n// NormPdf is the probability density function.\nfunc NormPdf(x float64, loc float64, scale float64) float64 {\n\treturn (math.Pow(math.E, -(math.Pow(x-loc, 2))/(2*math.Pow(scale, 2)))) / (scale * math.Sqrt(2*math.Pi))\n}\n\n// NormLogPdf is the log of the probability density function.\nfunc NormLogPdf(x float64, loc float64, scale float64) float64 {\n\treturn math.Log((math.Pow(math.E, -(math.Pow(x-loc, 2))/(2*math.Pow(scale, 2)))) / (scale * math.Sqrt(2*math.Pi)))\n}\n\n// NormCdf is the cumulative distribution function.\nfunc NormCdf(x float64, loc float64, scale float64) float64 {\n\treturn 0.5 * (1 + math.Erf((x-loc)/(scale*math.Sqrt(2))))\n}\n\n// NormLogCdf is the log of the cumulative distribution function.\nfunc NormLogCdf(x float64, loc float64, scale float64) float64 {\n\treturn math.Log(0.5 * (1 + math.Erf((x-loc)/(scale*math.Sqrt(2)))))\n}\n\n// NormSf is the survival function (also defined as 1 - cdf, but sf is sometimes more accurate).\nfunc NormSf(x float64, loc float64, scale float64) float64 {\n\treturn 1 - 0.5*(1+math.Erf((x-loc)/(scale*math.Sqrt(2))))\n}\n\n// NormLogSf is the log of the survival function.\nfunc NormLogSf(x float64, loc float64, scale float64) float64 {\n\treturn math.Log(1 - 0.5*(1+math.Erf((x-loc)/(scale*math.Sqrt(2)))))\n}\n\n// NormPpf is the point percentile function.\n// This is based on Peter John Acklam's inverse normal CDF.\n// algorithm: http://home.online.no/~pjacklam/notes/invnorm/ (no longer visible).\n// For more information please visit: https://stackedboxes.org/2017/05/01/acklams-normal-quantile-function/\nfunc NormPpf(p float64, loc float64, scale float64) (x float64) {\n\tconst (\n\t\ta1 = -3.969683028665376e+01\n\t\ta2 = 2.209460984245205e+02\n\t\ta3 = -2.759285104469687e+02\n\t\ta4 = 1.383577518672690e+02\n\t\ta5 = -3.066479806614716e+01\n\t\ta6 = 2.506628277459239e+00\n\n\t\tb1 = -5.447609879822406e+01\n\t\tb2 = 1.615858368580409e+02\n\t\tb3 = -1.556989798598866e+02\n\t\tb4 = 6.680131188771972e+01\n\t\tb5 = -1.328068155288572e+01\n\n\t\tc1 = -7.784894002430293e-03\n\t\tc2 = -3.223964580411365e-01\n\t\tc3 = -2.400758277161838e+00\n\t\tc4 = -2.549732539343734e+00\n\t\tc5 = 4.374664141464968e+00\n\t\tc6 = 2.938163982698783e+00\n\n\t\td1 = 7.784695709041462e-03\n\t\td2 = 3.224671290700398e-01\n\t\td3 = 2.445134137142996e+00\n\t\td4 = 3.754408661907416e+00\n\n\t\tplow  = 0.02425\n\t\tphigh = 1 - plow\n\t)\n\n\tif p < 0 || p > 1 {\n\t\treturn math.NaN()\n\t} else if p == 0 {\n\t\treturn -math.Inf(0)\n\t} else if p == 1 {\n\t\treturn math.Inf(0)\n\t}\n\n\tif p < plow {\n\t\tq := math.Sqrt(-2 * math.Log(p))\n\t\tx = (((((c1*q+c2)*q+c3)*q+c4)*q+c5)*q + c6) /\n\t\t\t((((d1*q+d2)*q+d3)*q+d4)*q + 1)\n\t} else if phigh < p {\n\t\tq := math.Sqrt(-2 * math.Log(1-p))\n\t\tx = -(((((c1*q+c2)*q+c3)*q+c4)*q+c5)*q + c6) /\n\t\t\t((((d1*q+d2)*q+d3)*q+d4)*q + 1)\n\t} else {\n\t\tq := p - 0.5\n\t\tr := q * q\n\t\tx = (((((a1*r+a2)*r+a3)*r+a4)*r+a5)*r + a6) * q /\n\t\t\t(((((b1*r+b2)*r+b3)*r+b4)*r+b5)*r + 1)\n\t}\n\n\te := 0.5*math.Erfc(-x/math.Sqrt2) - p\n\tu := e * math.Sqrt(2*math.Pi) * math.Exp(x*x/2)\n\tx = x - u/(1+x*u/2)\n\n\treturn x*scale + loc\n}\n\n// NormIsf is the inverse survival function (inverse of sf).\nfunc NormIsf(p float64, loc float64, scale float64) (x float64) {\n\tif -NormPpf(p, loc, scale) == 0 {\n\t\treturn 0\n\t}\n\treturn -NormPpf(p, loc, scale)\n}\n\n// NormMoment approximates the non-central (raw) moment of order n.\n// For more information please visit: https://math.stackexchange.com/questions/1945448/methods-for-finding-raw-moments-of-the-normal-distribution\nfunc NormMoment(n int, loc float64, scale float64) float64 {\n\ttoReturn := 0.0\n\tfor i := 0; i < n+1; i++ {\n\t\tif (n-i)%2 == 0 {\n\t\t\ttoReturn += float64(Ncr(n, i)) * (math.Pow(loc, float64(i))) * (math.Pow(scale, float64(n-i))) *\n\t\t\t\t(float64(factorial(n-i)) / ((math.Pow(2.0, float64((n-i)/2))) *\n\t\t\t\t\tfloat64(factorial((n-i)/2))))\n\t\t}\n\t}\n\treturn toReturn\n}\n\n// NormStats returns the mean, variance, skew, and/or kurtosis.\n// Mean(‘m’), variance(‘v’), skew(‘s’), and/or kurtosis(‘k’).\n// Takes string containing any of 'mvsk'.\n// Returns array of m v s k in that order.\nfunc NormStats(loc float64, scale float64, moments string) []float64 {\n\tvar toReturn []float64\n\tif strings.ContainsAny(moments, \"m\") {\n\t\ttoReturn = append(toReturn, loc)\n\t}\n\tif strings.ContainsAny(moments, \"v\") {\n\t\ttoReturn = append(toReturn, math.Pow(scale, 2))\n\t}\n\tif strings.ContainsAny(moments, \"s\") {\n\t\ttoReturn = append(toReturn, 0.0)\n\t}\n\tif strings.ContainsAny(moments, \"k\") {\n\t\ttoReturn = append(toReturn, 0.0)\n\t}\n\treturn toReturn\n}\n\n// NormEntropy is the differential entropy of the RV.\nfunc NormEntropy(loc float64, scale float64) float64 {\n\treturn math.Log(scale * math.Sqrt(2*math.Pi*math.E))\n}\n\n// NormFit returns the maximum likelihood estimators for the Normal Distribution.\n// Takes array of float64 values.\n// Returns array of Mean followed by Standard Deviation.\nfunc NormFit(data []float64) [2]float64 {\n\tsum := 0.00\n\tfor i := 0; i < len(data); i++ {\n\t\tsum += data[i]\n\t}\n\tmean := sum / float64(len(data))\n\tstdNumerator := 0.00\n\tfor i := 0; i < len(data); i++ {\n\t\tstdNumerator += math.Pow(data[i]-mean, 2)\n\t}\n\treturn [2]float64{mean, math.Sqrt((stdNumerator) / (float64(len(data))))}\n}\n\n// NormMedian is the median of the distribution.\nfunc NormMedian(loc float64, scale float64) float64 {\n\treturn loc\n}\n\n// NormMean is the mean/expected value of the distribution.\nfunc NormMean(loc float64, scale float64) float64 {\n\treturn loc\n}\n\n// NormVar is the variance of the distribution.\nfunc NormVar(loc float64, scale float64) float64 {\n\treturn math.Pow(scale, 2)\n}\n\n// NormStd is the standard deviation of the distribution.\nfunc NormStd(loc float64, scale float64) float64 {\n\treturn scale\n}\n\n// NormInterval finds endpoints of the range that contains alpha percent of the distribution.\nfunc NormInterval(alpha float64, loc float64, scale float64) [2]float64 {\n\tq1 := (1.0 - alpha) / 2\n\tq2 := (1.0 + alpha) / 2\n\ta := NormPpf(q1, loc, scale)\n\tb := NormPpf(q2, loc, scale)\n\treturn [2]float64{a, b}\n}\n\n// factorial is the naive factorial algorithm.\nfunc factorial(x int) int {\n\tif x == 0 {\n\t\treturn 1\n\t}\n\treturn x * factorial(x-1)\n}\n\n// Ncr is an N choose R algorithm.\n// Aaron Cannon's algorithm.\nfunc Ncr(n, r int) int {\n\tif n <= 1 || r == 0 || n == r {\n\t\treturn 1\n\t}\n\tif newR := n - r; newR < r {\n\t\tr = newR\n\t}\n\tif r == 1 {\n\t\treturn n\n\t}\n\tret := int(n - r + 1)\n\tfor i, j := ret+1, int(2); j <= r; i, j = i+1, j+1 {\n\t\tret = ret * i / j\n\t}\n\treturn ret\n}\n"
        },
        {
          "name": "norm_test.go",
          "type": "blob",
          "size": 4.646484375,
          "content": "package stats_test\n\nimport (\n\t\"math\"\n\t\"reflect\"\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc TestNormPpf(t *testing.T) {\n\tif stats.NormPpf(0.5, 0, 1) != 0 {\n\t\tt.Error(\"Input 0.5, Expected 0\")\n\t}\n\tif !veryclose(stats.NormPpf(0.1, 0, 1), -1.2815515655446004) {\n\t\tt.Error(\"Input 0.1, Expected -1.2815515655446004\")\n\t}\n\tif stats.NormPpf(0.002423, 0, 1) != -2.817096255323953 {\n\t\tt.Error(\"Input 0.002423, Expected -2.817096255323953\")\n\t}\n\tif !close(stats.NormPpf(1-0.002423, 0, 1), 2.817096255323956) {\n\t\tt.Error(\"Input 1 - 0.002423, Expected 2.817096255323956\")\n\t}\n\n\tif !math.IsNaN(stats.NormPpf(1.1, 0, 1)) {\n\t\tt.Error(\"Input 1.1, Expected NaN\")\n\t}\n\tif !math.IsNaN(stats.NormPpf(-1.1, 0, 1)) {\n\t\tt.Error(\"Input -0.1, Expected Nan\")\n\t}\n\tif stats.NormPpf(0, 0, 1) != -math.Inf(1) {\n\t\tt.Error(\"Input 0, Expected -Inf\")\n\t}\n\tif stats.NormPpf(1, 0, 1) != math.Inf(1) {\n\t\tt.Error(\"Input 1, Expected Inf\")\n\t}\n}\n\nfunc TestNormCdf(t *testing.T) {\n\tif stats.NormCdf(0, 0, 1) != 0.5 {\n\t\tt.Error(\"Input 0, Expected 0.5\")\n\t}\n\tif stats.NormCdf(0.5, 0, 1) != 0.6914624612740131 {\n\t\tt.Error(\"Input 0.5, Expected 0.6914624612740131\")\n\t}\n\tif stats.NormCdf(-0.5, 0, 1) != 0.3085375387259869 {\n\t\tt.Error(\"Input -0.5, Expected 0.3085375387259869\")\n\t}\n}\n\nfunc TestNormPdf(t *testing.T) {\n\tif stats.NormPdf(0.5, 0, 1) != 0.35206532676429947 {\n\t\tt.Error(\"Input 0.5, Expected 0.35206532676429947\")\n\t}\n\tif stats.NormPdf(0, 0, 1) != 0.3989422804014327 {\n\t\tt.Error(\"Input 0, Expected 0.3989422804014327\")\n\t}\n\tif stats.NormPdf(-0.5, 0, 1) != 0.35206532676429947 {\n\t\tt.Error(\"Input -0.5, Expected 0.35206532676429947\")\n\t}\n}\n\nfunc TestNormLogPdf(t *testing.T) {\n\tif stats.NormLogPdf(0, 0, 1) != -0.9189385332046727 {\n\t\tt.Error(\"Input 0, Expected -0.9189385332046727\")\n\t}\n\tif stats.NormPdf(0, 0, 1) != 0.3989422804014327 {\n\t\tt.Error(\"Input 0, Expected 0.3989422804014327\")\n\t}\n\tif stats.NormPdf(-0.5, 0, 1) != 0.35206532676429947 {\n\t\tt.Error(\"Input -0.5, Expected 0.35206532676429947\")\n\t}\n}\n\nfunc TestNormLogCdf(t *testing.T) {\n\tif stats.NormLogCdf(0.5, 0, 1) != -0.36894641528865635 {\n\t\tt.Error(\"Input 0.5, Expected -0.36894641528865635\")\n\t}\n}\n\nfunc TestNormIsf(t *testing.T) {\n\tif stats.NormIsf(0.5, 0, 1) != 0 {\n\t\tt.Error(\"Input 0.5, Expected 0\")\n\t}\n\tif !veryclose(stats.NormIsf(0.1, 0, 1), 1.2815515655446004) {\n\t\tt.Error(\"Input 0.1, Expected 1.2815515655446004\")\n\t}\n}\n\nfunc TestNormSf(t *testing.T) {\n\tif stats.NormSf(0.5, 0, 1) != 0.3085375387259869 {\n\t\tt.Error(\"Input 0.5, Expected 0.3085375387259869\")\n\t}\n}\n\nfunc TestNormLogSf(t *testing.T) {\n\tif stats.NormLogSf(0.5, 0, 1) != -1.1759117615936185 {\n\t\tt.Error(\"Input 0.5, Expected -1.1759117615936185\")\n\t}\n}\n\nfunc TestNormMoment(t *testing.T) {\n\tif stats.NormMoment(4, 0, 1) != 3 {\n\t\tt.Error(\"Input 3, Expected 3\")\n\t}\n\tif stats.NormMoment(4, 0, 1) != 3 {\n\t\tt.Error(\"Input 3, Expected 3\")\n\t}\n}\n\nfunc TestNormStats(t *testing.T) {\n\tif !reflect.DeepEqual(stats.NormStats(0, 1, \"m\"), []float64{0}) {\n\t\tt.Error(\"Input 'm' , Expected 0\")\n\t}\n\tif !reflect.DeepEqual(stats.NormStats(0, 1, \"v\"), []float64{1}) {\n\t\tt.Error(\"Input 'v' , Expected 1\")\n\t}\n\tif !reflect.DeepEqual(stats.NormStats(0, 1, \"s\"), []float64{0}) {\n\t\tt.Error(\"Input 's' , Expected 0\")\n\t}\n\tif !reflect.DeepEqual(stats.NormStats(0, 1, \"k\"), []float64{0}) {\n\t\tt.Error(\"Input 'k' , Expected 0\")\n\t}\n}\n\nfunc TestNormEntropy(t *testing.T) {\n\tif stats.NormEntropy(0, 1) != 1.4189385332046727 {\n\t\tt.Error(\"Input ( 0 , 1 ), Expected 1.4189385332046727\")\n\t}\n}\n\nfunc TestNormFit(t *testing.T) {\n\tif !reflect.DeepEqual(stats.NormFit([]float64{0, 2, 3, 4}), [2]float64{2.25, 1.479019945774904}) {\n\t\tt.Error(\"Input (0,2,3,4), Expected {2.25, 1.479019945774904}\")\n\t}\n}\n\nfunc TestNormInterval(t *testing.T) {\n\tif !reflect.DeepEqual(stats.NormInterval(0.5, 0, 1), [2]float64{-0.6744897501960818, 0.674489750196082}) {\n\t\tt.Error(\"Input (50 % ), Expected {-0.6744897501960818, 0.674489750196082}\")\n\t}\n}\n\nfunc TestNormMean(t *testing.T) {\n\tif stats.NormMean(0, 1) != 0 {\n\t\tt.Error(\"Input (0, 1), Expected 0\")\n\t}\n}\n\nfunc TestNormMedian(t *testing.T) {\n\tif stats.NormMedian(0, 1) != 0 {\n\t\tt.Error(\"Input (0, 1), Expected 0\")\n\t}\n}\n\nfunc TestNormVar(t *testing.T) {\n\tif stats.NormVar(0, 1) != 1 {\n\t\tt.Error(\"Input (0, 1), Expected 1\")\n\t}\n}\n\nfunc TestNormStd(t *testing.T) {\n\tif stats.NormStd(0, 1) != 1 {\n\t\tt.Error(\"Input (0, 1), Expected 1\")\n\t}\n}\n\nfunc TestNormPpfRvs(t *testing.T) {\n\tif len(stats.NormPpfRvs(0, 1, 101)) != 101 {\n\t\tt.Error(\"Input size=101, Expected 101\")\n\t}\n}\n\nfunc TestNormBoxMullerRvs(t *testing.T) {\n\tif len(stats.NormBoxMullerRvs(0, 1, 101)) != 101 {\n\t\tt.Error(\"Input size=101, Expected 101\")\n\t}\n}\n\nfunc TestNcr(t *testing.T) {\n\tif stats.Ncr(4, 1) != 4 {\n\t\tt.Error(\"Input 4 choose 1, Expected 4\")\n\t}\n\tif stats.Ncr(4, 3) != 4 {\n\t\tt.Error(\"Input 4 choose 3, Expected 4\")\n\t}\n}\n"
        },
        {
          "name": "outlier.go",
          "type": "blob",
          "size": 1.0400390625,
          "content": "package stats\n\n// Outliers holds mild and extreme outliers found in data\ntype Outliers struct {\n\tMild    Float64Data\n\tExtreme Float64Data\n}\n\n// QuartileOutliers finds the mild and extreme outliers\nfunc QuartileOutliers(input Float64Data) (Outliers, error) {\n\tif input.Len() == 0 {\n\t\treturn Outliers{}, EmptyInputErr\n\t}\n\n\t// Start by sorting a copy of the slice\n\tcopy := sortedCopy(input)\n\n\t// Calculate the quartiles and interquartile range\n\tqs, _ := Quartile(copy)\n\tiqr, _ := InterQuartileRange(copy)\n\n\t// Calculate the lower and upper inner and outer fences\n\tlif := qs.Q1 - (1.5 * iqr)\n\tuif := qs.Q3 + (1.5 * iqr)\n\tlof := qs.Q1 - (3 * iqr)\n\tuof := qs.Q3 + (3 * iqr)\n\n\t// Find the data points that are outside of the\n\t// inner and upper fences and add them to mild\n\t// and extreme outlier slices\n\tvar mild Float64Data\n\tvar extreme Float64Data\n\tfor _, v := range copy {\n\n\t\tif v < lof || v > uof {\n\t\t\textreme = append(extreme, v)\n\t\t} else if v < lif || v > uif {\n\t\t\tmild = append(mild, v)\n\t\t}\n\t}\n\n\t// Wrap them into our struct\n\treturn Outliers{mild, extreme}, nil\n}\n"
        },
        {
          "name": "outlier_test.go",
          "type": "blob",
          "size": 0.67578125,
          "content": "package stats_test\n\nimport (\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc TestQuartileOutliers(t *testing.T) {\n\ts1 := []float64{-1000, 1, 3, 4, 4, 6, 6, 6, 6, 7, 8, 15, 18, 100}\n\to, _ := stats.QuartileOutliers(s1)\n\n\tif o.Mild[0] != 15 {\n\t\tt.Errorf(\"First Mild Outlier %v != 15\", o.Mild[0])\n\t}\n\n\tif o.Mild[1] != 18 {\n\t\tt.Errorf(\"Second Mild Outlier %v != 18\", o.Mild[1])\n\t}\n\n\tif o.Extreme[0] != -1000 {\n\t\tt.Errorf(\"First Extreme Outlier %v != -1000\", o.Extreme[0])\n\t}\n\n\tif o.Extreme[1] != 100 {\n\t\tt.Errorf(\"Second Extreme Outlier %v != 100\", o.Extreme[1])\n\t}\n\n\t_, err := stats.QuartileOutliers([]float64{})\n\tif err == nil {\n\t\tt.Errorf(\"Empty slice should have returned an error\")\n\t}\n}\n"
        },
        {
          "name": "percentile.go",
          "type": "blob",
          "size": 1.759765625,
          "content": "package stats\n\nimport (\n\t\"math\"\n)\n\n// Percentile finds the relative standing in a slice of floats\nfunc Percentile(input Float64Data, percent float64) (percentile float64, err error) {\n\tlength := input.Len()\n\tif length == 0 {\n\t\treturn math.NaN(), EmptyInputErr\n\t}\n\n\tif length == 1 {\n\t\treturn input[0], nil\n\t}\n\n\tif percent <= 0 || percent > 100 {\n\t\treturn math.NaN(), BoundsErr\n\t}\n\n\t// Start by sorting a copy of the slice\n\tc := sortedCopy(input)\n\n\t// Multiply percent by length of input\n\tindex := (percent / 100) * float64(len(c))\n\n\t// Check if the index is a whole number\n\tif index == float64(int64(index)) {\n\n\t\t// Convert float to int\n\t\ti := int(index)\n\n\t\t// Find the value at the index\n\t\tpercentile = c[i-1]\n\n\t} else if index > 1 {\n\n\t\t// Convert float to int via truncation\n\t\ti := int(index)\n\n\t\t// Find the average of the index and following values\n\t\tpercentile, _ = Mean(Float64Data{c[i-1], c[i]})\n\n\t} else {\n\t\treturn math.NaN(), BoundsErr\n\t}\n\n\treturn percentile, nil\n\n}\n\n// PercentileNearestRank finds the relative standing in a slice of floats using the Nearest Rank method\nfunc PercentileNearestRank(input Float64Data, percent float64) (percentile float64, err error) {\n\n\t// Find the length of items in the slice\n\til := input.Len()\n\n\t// Return an error for empty slices\n\tif il == 0 {\n\t\treturn math.NaN(), EmptyInputErr\n\t}\n\n\t// Return error for less than 0 or greater than 100 percentages\n\tif percent < 0 || percent > 100 {\n\t\treturn math.NaN(), BoundsErr\n\t}\n\n\t// Start by sorting a copy of the slice\n\tc := sortedCopy(input)\n\n\t// Return the last item\n\tif percent == 100.0 {\n\t\treturn c[il-1], nil\n\t}\n\n\t// Find ordinal ranking\n\tor := int(math.Ceil(float64(il) * percent / 100))\n\n\t// Return the item that is in the place of the ordinal rank\n\tif or == 0 {\n\t\treturn c[0], nil\n\t}\n\treturn c[or-1], nil\n\n}\n"
        },
        {
          "name": "percentile_test.go",
          "type": "blob",
          "size": 3.361328125,
          "content": "package stats_test\n\nimport (\n\t\"reflect\"\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc TestPercentile(t *testing.T) {\n\tm, _ := stats.Percentile([]float64{43, 54, 56, 61, 62, 66}, 90)\n\tif m != 64.0 {\n\t\tt.Errorf(\"%.1f != %.1f\", m, 64.0)\n\t}\n\tm, _ = stats.Percentile([]float64{43}, 90)\n\tif m != 43.0 {\n\t\tt.Errorf(\"%.1f != %.1f\", m, 43.0)\n\t}\n\tm, _ = stats.Percentile([]float64{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, 50)\n\tif m != 5.0 {\n\t\tt.Errorf(\"%.1f != %.1f\", m, 5.0)\n\t}\n\tm, _ = stats.Percentile([]float64{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, 99.9)\n\tif m != 9.5 {\n\t\tt.Errorf(\"%.1f != %.1f\", m, 9.5)\n\t}\n\tm, _ = stats.Percentile([]float64{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, 100)\n\tif m != 10.0 {\n\t\tt.Errorf(\"%.1f != %.1f\", m, 10.0)\n\t}\n\t_, err := stats.Percentile([]float64{}, 99.9)\n\tif err != stats.EmptyInputErr {\n\t\tt.Errorf(\"Empty slice didn't return expected error; got %v\", err)\n\t}\n\t_, err = stats.Percentile([]float64{1, 2, 3, 4, 5}, 0)\n\tif err != stats.BoundsErr {\n\t\tt.Errorf(\"Zero percent didn't return expected error; got %v\", err)\n\t}\n\t_, err = stats.Percentile([]float64{1, 2, 3, 4, 5}, 0.13)\n\tif err != stats.BoundsErr {\n\t\tt.Errorf(\"Too low percent didn't return expected error; got %v\", err)\n\t}\n\t_, err = stats.Percentile([]float64{1, 2, 3, 4, 5}, 101)\n\tif err != stats.BoundsErr {\n\t\tt.Errorf(\"Too high percent didn't return expected error; got %v\", err)\n\t}\n}\n\nfunc TestPercentileSortSideEffects(t *testing.T) {\n\ts := []float64{43, 54, 56, 44, 62, 66}\n\ta := []float64{43, 54, 56, 44, 62, 66}\n\t_, _ = stats.Percentile(s, 90)\n\tif !reflect.DeepEqual(s, a) {\n\t\tt.Errorf(\"%.1f != %.1f\", s, a)\n\t}\n}\n\nfunc BenchmarkPercentileSmallFloatSlice(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Percentile(makeFloatSlice(5), 50)\n\t}\n}\n\nfunc BenchmarkPercentileLargeFloatSlice(b *testing.B) {\n\tlf := makeFloatSlice(100000)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Percentile(lf, 50)\n\t}\n}\n\nfunc TestPercentileNearestRank(t *testing.T) {\n\tf1 := []float64{35, 20, 15, 40, 50}\n\tf2 := []float64{20, 6, 7, 8, 8, 10, 13, 15, 16, 3}\n\tf3 := makeFloatSlice(101)\n\n\tfor _, c := range []struct {\n\t\tsample  []float64\n\t\tpercent float64\n\t\tresult  float64\n\t}{\n\t\t{f1, 30, 20},\n\t\t{f1, 40, 20},\n\t\t{f1, 50, 35},\n\t\t{f1, 75, 40},\n\t\t{f1, 95, 50},\n\t\t{f1, 99, 50},\n\t\t{f1, 99.9, 50},\n\t\t{f1, 100, 50},\n\t\t{f2, 25, 7},\n\t\t{f2, 50, 8},\n\t\t{f2, 75, 15},\n\t\t{f2, 100, 20},\n\t\t{f3, 1, 100},\n\t\t{f3, 99, 9900},\n\t\t{f3, 100, 10000},\n\t\t{f3, 0, 0},\n\t} {\n\t\tgot, err := stats.PercentileNearestRank(c.sample, c.percent)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"Should not have returned an error\")\n\t\t}\n\t\tif got != c.result {\n\t\t\tt.Errorf(\"%v != %v\", got, c.result)\n\t\t}\n\t}\n\n\t_, err := stats.PercentileNearestRank([]float64{}, 50)\n\tif err == nil {\n\t\tt.Errorf(\"Should have returned an empty slice error\")\n\t}\n\n\t_, err = stats.PercentileNearestRank([]float64{1, 2, 3, 4, 5}, -0.01)\n\tif err == nil {\n\t\tt.Errorf(\"Should have returned an percentage must be above 0 error\")\n\t}\n\n\t_, err = stats.PercentileNearestRank([]float64{1, 2, 3, 4, 5}, 110)\n\tif err == nil {\n\t\tt.Errorf(\"Should have returned an percentage must not be above 100 error\")\n\t}\n\n}\n\nfunc BenchmarkPercentileNearestRankSmallFloatSlice(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.PercentileNearestRank(makeFloatSlice(5), 50)\n\t}\n}\n\nfunc BenchmarkPercentileNearestRankLargeFloatSlice(b *testing.B) {\n\tlf := makeFloatSlice(100000)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.PercentileNearestRank(lf, 50)\n\t}\n}\n"
        },
        {
          "name": "quartile.go",
          "type": "blob",
          "size": 1.4892578125,
          "content": "package stats\n\nimport \"math\"\n\n// Quartiles holds the three quartile points\ntype Quartiles struct {\n\tQ1 float64\n\tQ2 float64\n\tQ3 float64\n}\n\n// Quartile returns the three quartile points from a slice of data\nfunc Quartile(input Float64Data) (Quartiles, error) {\n\n\til := input.Len()\n\tif il == 0 {\n\t\treturn Quartiles{}, EmptyInputErr\n\t}\n\n\t// Start by sorting a copy of the slice\n\tcopy := sortedCopy(input)\n\n\t// Find the cutoff places depeding on if\n\t// the input slice length is even or odd\n\tvar c1 int\n\tvar c2 int\n\tif il%2 == 0 {\n\t\tc1 = il / 2\n\t\tc2 = il / 2\n\t} else {\n\t\tc1 = (il - 1) / 2\n\t\tc2 = c1 + 1\n\t}\n\n\t// Find the Medians with the cutoff points\n\tQ1, _ := Median(copy[:c1])\n\tQ2, _ := Median(copy)\n\tQ3, _ := Median(copy[c2:])\n\n\treturn Quartiles{Q1, Q2, Q3}, nil\n\n}\n\n// InterQuartileRange finds the range between Q1 and Q3\nfunc InterQuartileRange(input Float64Data) (float64, error) {\n\tif input.Len() == 0 {\n\t\treturn math.NaN(), EmptyInputErr\n\t}\n\tqs, _ := Quartile(input)\n\tiqr := qs.Q3 - qs.Q1\n\treturn iqr, nil\n}\n\n// Midhinge finds the average of the first and third quartiles\nfunc Midhinge(input Float64Data) (float64, error) {\n\tif input.Len() == 0 {\n\t\treturn math.NaN(), EmptyInputErr\n\t}\n\tqs, _ := Quartile(input)\n\tmh := (qs.Q1 + qs.Q3) / 2\n\treturn mh, nil\n}\n\n// Trimean finds the average of the median and the midhinge\nfunc Trimean(input Float64Data) (float64, error) {\n\tif input.Len() == 0 {\n\t\treturn math.NaN(), EmptyInputErr\n\t}\n\n\tc := sortedCopy(input)\n\tq, _ := Quartile(c)\n\n\treturn (q.Q1 + (q.Q2 * 2) + q.Q3) / 4, nil\n}\n"
        },
        {
          "name": "quartile_test.go",
          "type": "blob",
          "size": 1.744140625,
          "content": "package stats_test\n\nimport (\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc TestQuartile(t *testing.T) {\n\ts1 := []float64{6, 7, 15, 36, 39, 40, 41, 42, 43, 47, 49}\n\ts2 := []float64{7, 15, 36, 39, 40, 41}\n\n\tfor _, c := range []struct {\n\t\tin []float64\n\t\tQ1 float64\n\t\tQ2 float64\n\t\tQ3 float64\n\t}{\n\t\t{s1, 15, 40, 43},\n\t\t{s2, 15, 37.5, 40},\n\t} {\n\t\tquartiles, err := stats.Quartile(c.in)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"Should not have returned an error\")\n\t\t}\n\n\t\tif quartiles.Q1 != c.Q1 {\n\t\t\tt.Errorf(\"Q1 %v != %v\", quartiles.Q1, c.Q1)\n\t\t}\n\t\tif quartiles.Q2 != c.Q2 {\n\t\t\tt.Errorf(\"Q2 %v != %v\", quartiles.Q2, c.Q2)\n\t\t}\n\t\tif quartiles.Q3 != c.Q3 {\n\t\t\tt.Errorf(\"Q3 %v != %v\", quartiles.Q3, c.Q3)\n\t\t}\n\t}\n\n\t_, err := stats.Quartile([]float64{})\n\tif err == nil {\n\t\tt.Errorf(\"Empty slice should have returned an error\")\n\t}\n}\n\nfunc TestInterQuartileRange(t *testing.T) {\n\ts1 := []float64{102, 104, 105, 107, 108, 109, 110, 112, 115, 116, 118}\n\tiqr, _ := stats.InterQuartileRange(s1)\n\n\tif iqr != 10 {\n\t\tt.Errorf(\"IQR %v != 10\", iqr)\n\t}\n\n\t_, err := stats.InterQuartileRange([]float64{})\n\tif err == nil {\n\t\tt.Errorf(\"Empty slice should have returned an error\")\n\t}\n}\n\nfunc TestMidhinge(t *testing.T) {\n\ts1 := []float64{1, 3, 4, 4, 6, 6, 6, 6, 7, 7, 7, 8, 8, 9, 9, 10, 11, 12, 13}\n\tmh, _ := stats.Midhinge(s1)\n\n\tif mh != 7.5 {\n\t\tt.Errorf(\"Midhinge %v != 7.5\", mh)\n\t}\n\n\t_, err := stats.Midhinge([]float64{})\n\tif err == nil {\n\t\tt.Errorf(\"Empty slice should have returned an error\")\n\t}\n}\n\nfunc TestTrimean(t *testing.T) {\n\ts1 := []float64{1, 3, 4, 4, 6, 6, 6, 6, 7, 7, 7, 8, 8, 9, 9, 10, 11, 12, 13}\n\ttr, _ := stats.Trimean(s1)\n\n\tif tr != 7.25 {\n\t\tt.Errorf(\"Trimean %v != 7.25\", tr)\n\t}\n\n\t_, err := stats.Trimean([]float64{})\n\tif err == nil {\n\t\tt.Errorf(\"Empty slice should have returned an error\")\n\t}\n}\n"
        },
        {
          "name": "ranksum.go",
          "type": "blob",
          "size": 5.3955078125,
          "content": "package stats\n\n// import \"math\"\n//\n// // WilcoxonRankSum tests the null hypothesis that two sets\n// // of data are drawn from the same distribution. It does\n// // not handle ties between measurements in x and y.\n// //\n// // Parameters:\n// //    data1 Float64Data: First set of data points.\n// //    data2 Float64Data: Second set of data points.\n// //    Length of both data samples must be equal.\n// //\n// // Return:\n// //    statistic float64: The test statistic under the\n// //                       large-sample approximation that the\n// //                       rank sum statistic is normally distributed.\n// //    pvalue float64: The two-sided p-value of the test\n// //    err error: Any error from the input data parameters\n// //\n// // https://en.wikipedia.org/wiki/Wilcoxon_rank-sum_test\n// func WilcoxonRankSum(data1, data2 Float64Data) (float64, float64, error) {\n//\n// \tl1 := data1.Len()\n// \tl2 := data2.Len()\n//\n// \tif l1 == 0 || l2 == 0 {\n// \t\treturn math.NaN(), math.NaN(), EmptyInputErr\n// \t}\n//\n// \tif l1 != l2 {\n// \t\treturn math.NaN(), math.NaN(), SizeErr\n// \t}\n//\n// \talldata := Float64Data{}\n// \talldata = append(alldata, data1...)\n// \talldata = append(alldata, data2...)\n//\n// \t// ranked :=\n//\n// \treturn 0.0, 0.0, nil\n// }\n//\n// //     x, y = map(np.asarray, (x, y))\n// //     n1 = len(x)\n// //     n2 = len(y)\n// //     alldata = np.concatenate((x, y))\n// //     ranked = rankdata(alldata)\n// //     x = ranked[:n1]\n// //     s = np.sum(x, axis=0)\n// //     expected = n1 * (n1+n2+1) / 2.0\n// //     z = (s - expected) / np.sqrt(n1*n2*(n1+n2+1)/12.0)\n// //     prob = 2 * distributions.norm.sf(abs(z))\n// //\n// //     return RanksumsResult(z, prob)\n//\n// // def rankdata(a, method='average'):\n// //     \"\"\"\n// //     Assign ranks to data, dealing with ties appropriately.\n// //     Ranks begin at 1.  The `method` argument controls how ranks are assigned\n// //     to equal values.  See [1]_ for further discussion of ranking methods.\n// //     Parameters\n// //     ----------\n// //     a : array_like\n// //         The array of values to be ranked.  The array is first flattened.\n// //     method : str, optional\n// //         The method used to assign ranks to tied elements.\n// //         The options are 'average', 'min', 'max', 'dense' and 'ordinal'.\n// //         'average':\n// //             The average of the ranks that would have been assigned to\n// //             all the tied values is assigned to each value.\n// //         'min':\n// //             The minimum of the ranks that would have been assigned to all\n// //             the tied values is assigned to each value.  (This is also\n// //             referred to as \"competition\" ranking.)\n// //         'max':\n// //             The maximum of the ranks that would have been assigned to all\n// //             the tied values is assigned to each value.\n// //         'dense':\n// //             Like 'min', but the rank of the next highest element is assigned\n// //             the rank immediately after those assigned to the tied elements.\n// //         'ordinal':\n// //             All values are given a distinct rank, corresponding to the order\n// //             that the values occur in `a`.\n// //         The default is 'average'.\n// //     Returns\n// //     -------\n// //     ranks : ndarray\n// //          An array of length equal to the size of `a`, containing rank\n// //          scores.\n// //     References\n// //     ----------\n// //     .. [1] \"Ranking\", https://en.wikipedia.org/wiki/Ranking\n// //     Examples\n// //     --------\n// //     >>> from scipy.stats import rankdata\n// //     >>> rankdata([0, 2, 3, 2])\n// //     array([ 1. ,  2.5,  4. ,  2.5])\n// //     \"\"\"\n// //\n// //     arr = np.ravel(np.asarray(a))\n// //     algo = 'quicksort'\n// //     sorter = np.argsort(arr, kind=algo)\n// //\n// //     inv = np.empty(sorter.size, dtype=np.intp)\n// //     inv[sorter] = np.arange(sorter.size, dtype=np.intp)\n// //\n// //\n// //     arr = arr[sorter]\n// //     obs = np.r_[True, arr[1:] != arr[:-1]]\n// //     dense = obs.cumsum()[inv]\n// //\n// //\n// //     # cumulative counts of each unique value\n// //     count = np.r_[np.nonzero(obs)[0], len(obs)]\n// //\n// //     # average method\n// //     return .5 * (count[dense] + count[dense - 1] + 1)\n//\n// type rankable interface {\n// \tLen() int\n// \tRankEqual(int, int) bool\n// }\n//\n// func StandardRank(d rankable) []float64 {\n// \tr := make([]float64, d.Len())\n// \tvar k int\n// \tfor i := range r {\n// \t\tif i == 0 || !d.RankEqual(i, i-1) {\n// \t\t\tk = i + 1\n// \t\t}\n// \t\tr[i] = float64(k)\n// \t}\n// \treturn r\n// }\n//\n// func ModifiedRank(d rankable) []float64 {\n// \tr := make([]float64, d.Len())\n// \tfor i := range r {\n// \t\tk := i + 1\n// \t\tfor j := i + 1; j < len(r) && d.RankEqual(i, j); j++ {\n// \t\t\tk = j + 1\n// \t\t}\n// \t\tr[i] = float64(k)\n// \t}\n// \treturn r\n// }\n//\n// func DenseRank(d rankable) []float64 {\n// \tr := make([]float64, d.Len())\n// \tvar k int\n// \tfor i := range r {\n// \t\tif i == 0 || !d.RankEqual(i, i-1) {\n// \t\t\tk++\n// \t\t}\n// \t\tr[i] = float64(k)\n// \t}\n// \treturn r\n// }\n//\n// func OrdinalRank(d rankable) []float64 {\n// \tr := make([]float64, d.Len())\n// \tfor i := range r {\n// \t\tr[i] = float64(i + 1)\n// \t}\n// \treturn r\n// }\n//\n// func FractionalRank(d rankable) []float64 {\n// \tr := make([]float64, d.Len())\n// \tfor i := 0; i < len(r); {\n// \t\tvar j int\n// \t\tf := float64(i + 1)\n// \t\tfor j = i + 1; j < len(r) && d.RankEqual(i, j); j++ {\n// \t\t\tf += float64(j + 1)\n// \t\t}\n// \t\tf /= float64(j - i)\n// \t\tfor ; i < j; i++ {\n// \t\t\tr[i] = f\n// \t\t}\n// \t}\n// \treturn r\n// }\n"
        },
        {
          "name": "ranksum_test.go",
          "type": "blob",
          "size": 0.9765625,
          "content": "package stats_test\n\n// import (\n// \t\"testing\"\n// )\n//\n// //   >>> y1=[125,115,130,140,140,115,140,125,140,135]\n// // >>> y2=[110,122,125,120,140,124,123,137,135,145]\n// // >>> ss.wilcoxon(y1, y2)\n// // (18.0, 0.5936305914425295)\n//\n// // func ExampleWilcoxonRankSum() {\n// // \tt, p, err := WilcoxonRankSum([]float64{3.0, 1.0, 0.2}, []float64{3.1, 1.2, 1.2})\n// // \tfmt.Println(t, p, err)\n// // \t// Output: 18.0, 0.5936305914425295, nil\n// //\n// // }\n//\n// func TestRanked(t *testing.T) {\n//\n// \tvar data = []float64{0.1, 3.2, 3.2}\n//\n// \tStandardRank(data)\n// \t// show := func(name string, fn func(rankable) []float64) {\n// \t// \tfmt.Println(name, \"Ranking:\")\n// \t// \tr := fn(data)\n// \t// \tfor i, d := range data {\n// \t// \t\tfmt.Printf(\"%4v\\n\", r[i])\n// \t// \t}\n// \t// }\n// \t//\n// \t// sort.Sort(data)\n// \t// show(\"Standard\", StandardRank)\n// \t// show(\"\\nModified\", ModifiedRank)\n// \t// show(\"\\nDense\", DenseRank)\n// \t// show(\"\\nOrdinal\", OrdinalRank)\n// \t// show(\"\\nFractional\", FractionalRank)\n//\n// }\n"
        },
        {
          "name": "regression.go",
          "type": "blob",
          "size": 2.421875,
          "content": "package stats\n\nimport \"math\"\n\n// Series is a container for a series of data\ntype Series []Coordinate\n\n// Coordinate holds the data in a series\ntype Coordinate struct {\n\tX, Y float64\n}\n\n// LinearRegression finds the least squares linear regression on data series\nfunc LinearRegression(s Series) (regressions Series, err error) {\n\n\tif len(s) == 0 {\n\t\treturn nil, EmptyInputErr\n\t}\n\n\t// Placeholder for the math to be done\n\tvar sum [5]float64\n\n\t// Loop over data keeping index in place\n\ti := 0\n\tfor ; i < len(s); i++ {\n\t\tsum[0] += s[i].X\n\t\tsum[1] += s[i].Y\n\t\tsum[2] += s[i].X * s[i].X\n\t\tsum[3] += s[i].X * s[i].Y\n\t\tsum[4] += s[i].Y * s[i].Y\n\t}\n\n\t// Find gradient and intercept\n\tf := float64(i)\n\tgradient := (f*sum[3] - sum[0]*sum[1]) / (f*sum[2] - sum[0]*sum[0])\n\tintercept := (sum[1] / f) - (gradient * sum[0] / f)\n\n\t// Create the new regression series\n\tfor j := 0; j < len(s); j++ {\n\t\tregressions = append(regressions, Coordinate{\n\t\t\tX: s[j].X,\n\t\t\tY: s[j].X*gradient + intercept,\n\t\t})\n\t}\n\n\treturn regressions, nil\n}\n\n// ExponentialRegression returns an exponential regression on data series\nfunc ExponentialRegression(s Series) (regressions Series, err error) {\n\n\tif len(s) == 0 {\n\t\treturn nil, EmptyInputErr\n\t}\n\n\tvar sum [6]float64\n\n\tfor i := 0; i < len(s); i++ {\n\t\tif s[i].Y < 0 {\n\t\t\treturn nil, YCoordErr\n\t\t}\n\t\tsum[0] += s[i].X\n\t\tsum[1] += s[i].Y\n\t\tsum[2] += s[i].X * s[i].X * s[i].Y\n\t\tsum[3] += s[i].Y * math.Log(s[i].Y)\n\t\tsum[4] += s[i].X * s[i].Y * math.Log(s[i].Y)\n\t\tsum[5] += s[i].X * s[i].Y\n\t}\n\n\tdenominator := (sum[1]*sum[2] - sum[5]*sum[5])\n\ta := math.Pow(math.E, (sum[2]*sum[3]-sum[5]*sum[4])/denominator)\n\tb := (sum[1]*sum[4] - sum[5]*sum[3]) / denominator\n\n\tfor j := 0; j < len(s); j++ {\n\t\tregressions = append(regressions, Coordinate{\n\t\t\tX: s[j].X,\n\t\t\tY: a * math.Exp(b*s[j].X),\n\t\t})\n\t}\n\n\treturn regressions, nil\n}\n\n// LogarithmicRegression returns an logarithmic regression on data series\nfunc LogarithmicRegression(s Series) (regressions Series, err error) {\n\n\tif len(s) == 0 {\n\t\treturn nil, EmptyInputErr\n\t}\n\n\tvar sum [4]float64\n\n\ti := 0\n\tfor ; i < len(s); i++ {\n\t\tsum[0] += math.Log(s[i].X)\n\t\tsum[1] += s[i].Y * math.Log(s[i].X)\n\t\tsum[2] += s[i].Y\n\t\tsum[3] += math.Pow(math.Log(s[i].X), 2)\n\t}\n\n\tf := float64(i)\n\ta := (f*sum[1] - sum[2]*sum[0]) / (f*sum[3] - sum[0]*sum[0])\n\tb := (sum[2] - a*sum[0]) / f\n\n\tfor j := 0; j < len(s); j++ {\n\t\tregressions = append(regressions, Coordinate{\n\t\t\tX: s[j].X,\n\t\t\tY: b + a*math.Log(s[j].X),\n\t\t})\n\t}\n\n\treturn regressions, nil\n}\n"
        },
        {
          "name": "regression_test.go",
          "type": "blob",
          "size": 2.7236328125,
          "content": "package stats_test\n\nimport (\n\t\"fmt\"\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc ExampleLinearRegression() {\n\tdata := []stats.Coordinate{\n\t\t{1, 2.3},\n\t\t{2, 3.3},\n\t\t{3, 3.7},\n\t}\n\n\tr, _ := stats.LinearRegression(data)\n\tfmt.Println(r)\n\t// Output: [{1 2.400000000000001} {2 3.1} {3 3.7999999999999994}]\n}\n\nfunc TestLinearRegression(t *testing.T) {\n\tdata := []stats.Coordinate{\n\t\t{1, 2.3},\n\t\t{2, 3.3},\n\t\t{3, 3.7},\n\t\t{4, 4.3},\n\t\t{5, 5.3},\n\t}\n\n\tr, _ := stats.LinearRegression(data)\n\ta := 2.3800000000000026\n\tif !close(r[0].Y, a) {\n\t\tt.Errorf(\"%v != %v\", r[0].Y, a)\n\t}\n\ta = 3.0800000000000014\n\tif !veryclose(r[1].Y, a) {\n\t\tt.Errorf(\"%v != %v\", r[1].Y, a)\n\t}\n\ta = 3.7800000000000002\n\tif r[2].Y != a {\n\t\tt.Errorf(\"%v != %v\", r[2].Y, a)\n\t}\n\ta = 4.479999999999999\n\tif !veryclose(r[3].Y, a) {\n\t\tt.Errorf(\"%v != %v\", r[3].Y, a)\n\t}\n\ta = 5.179999999999998\n\tif !veryclose(r[4].Y, a) {\n\t\tt.Errorf(\"%v != %v\", r[4].Y, a)\n\t}\n\n\t_, err := stats.LinearRegression([]stats.Coordinate{})\n\tif err == nil {\n\t\tt.Errorf(\"Empty slice should have returned an error\")\n\t}\n}\n\nfunc TestExponentialRegression(t *testing.T) {\n\tdata := []stats.Coordinate{\n\t\t{1, 2.3},\n\t\t{2, 3.3},\n\t\t{3, 3.7},\n\t\t{4, 4.3},\n\t\t{5, 5.3},\n\t}\n\n\tr, _ := stats.ExponentialRegression(data)\n\ta, _ := stats.Round(r[0].Y, 3)\n\tif a != 2.515 {\n\t\tt.Errorf(\"%v != %v\", r[0].Y, 2.515)\n\t}\n\ta, _ = stats.Round(r[1].Y, 3)\n\tif a != 3.032 {\n\t\tt.Errorf(\"%v != %v\", r[1].Y, 3.032)\n\t}\n\ta, _ = stats.Round(r[2].Y, 3)\n\tif a != 3.655 {\n\t\tt.Errorf(\"%v != %v\", r[2].Y, 3.655)\n\t}\n\ta, _ = stats.Round(r[3].Y, 3)\n\tif a != 4.407 {\n\t\tt.Errorf(\"%v != %v\", r[3].Y, 4.407)\n\t}\n\ta, _ = stats.Round(r[4].Y, 3)\n\tif a != 5.313 {\n\t\tt.Errorf(\"%v != %v\", r[4].Y, 5.313)\n\t}\n\n\t_, err := stats.ExponentialRegression([]stats.Coordinate{})\n\tif err == nil {\n\t\tt.Errorf(\"Empty slice should have returned an error\")\n\t}\n}\n\nfunc TestExponentialRegressionYCoordErr(t *testing.T) {\n\tc := []stats.Coordinate{{1, -5}, {4, 25}, {6, 5}}\n\t_, err := stats.ExponentialRegression(c)\n\tif err != stats.YCoordErr {\n\t\tt.Errorf(err.Error())\n\t}\n}\n\nfunc TestLogarithmicRegression(t *testing.T) {\n\tdata := []stats.Coordinate{\n\t\t{1, 2.3},\n\t\t{2, 3.3},\n\t\t{3, 3.7},\n\t\t{4, 4.3},\n\t\t{5, 5.3},\n\t}\n\n\tr, _ := stats.LogarithmicRegression(data)\n\ta := 2.1520822363811702\n\tif !close(r[0].Y, a) {\n\t\tt.Errorf(\"%v != %v\", r[0].Y, a)\n\t}\n\ta = 3.3305559222492214\n\tif !veryclose(r[1].Y, a) {\n\t\tt.Errorf(\"%v != %v\", r[1].Y, a)\n\t}\n\ta = 4.019918836568674\n\tif !veryclose(r[2].Y, a) {\n\t\tt.Errorf(\"%v != %v\", r[2].Y, a)\n\t}\n\ta = 4.509029608117273\n\tif !veryclose(r[3].Y, a) {\n\t\tt.Errorf(\"%v != %v\", r[3].Y, a)\n\t}\n\ta = 4.888413396683663\n\tif !veryclose(r[4].Y, a) {\n\t\tt.Errorf(\"%v != %v\", r[4].Y, a)\n\t}\n\n\t_, err := stats.LogarithmicRegression([]stats.Coordinate{})\n\tif err == nil {\n\t\tt.Errorf(\"Empty slice should have returned an error\")\n\t}\n}\n"
        },
        {
          "name": "round.go",
          "type": "blob",
          "size": 0.888671875,
          "content": "package stats\n\nimport \"math\"\n\n// Round a float to a specific decimal place or precision\nfunc Round(input float64, places int) (rounded float64, err error) {\n\n\t// If the float is not a number\n\tif math.IsNaN(input) {\n\t\treturn math.NaN(), NaNErr\n\t}\n\n\t// Find out the actual sign and correct the input for later\n\tsign := 1.0\n\tif input < 0 {\n\t\tsign = -1\n\t\tinput *= -1\n\t}\n\n\t// Use the places arg to get the amount of precision wanted\n\tprecision := math.Pow(10, float64(places))\n\n\t// Find the decimal place we are looking to round\n\tdigit := input * precision\n\n\t// Get the actual decimal number as a fraction to be compared\n\t_, decimal := math.Modf(digit)\n\n\t// If the decimal is less than .5 we round down otherwise up\n\tif decimal >= 0.5 {\n\t\trounded = math.Ceil(digit)\n\t} else {\n\t\trounded = math.Floor(digit)\n\t}\n\n\t// Finally we do the math to actually create a rounded number\n\treturn rounded / precision * sign, nil\n}\n"
        },
        {
          "name": "round_test.go",
          "type": "blob",
          "size": 0.796875,
          "content": "package stats_test\n\nimport (\n\t\"fmt\"\n\t\"math\"\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc ExampleRound() {\n\trounded, _ := stats.Round(1.534424, 1)\n\tfmt.Println(rounded)\n\t// Output: 1.5\n}\n\nfunc TestRound(t *testing.T) {\n\tfor _, c := range []struct {\n\t\tnumber   float64\n\t\tdecimals int\n\t\tresult   float64\n\t}{\n\t\t{0.1111, 1, 0.1},\n\t\t{-0.1111, 2, -0.11},\n\t\t{5.3253, 3, 5.325},\n\t\t{5.3258, 3, 5.326},\n\t\t{5.3253, 0, 5.0},\n\t\t{5.55, 1, 5.6},\n\t} {\n\t\tm, err := stats.Round(c.number, c.decimals)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"Returned an error\")\n\t\t}\n\t\tif m != c.result {\n\t\t\tt.Errorf(\"%.1f != %.1f\", m, c.result)\n\t\t}\n\n\t}\n\t_, err := stats.Round(math.NaN(), 2)\n\tif err == nil {\n\t\tt.Errorf(\"Round should error on NaN\")\n\t}\n}\n\nfunc BenchmarkRound(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Round(0.1111, 1)\n\t}\n}\n"
        },
        {
          "name": "sample.go",
          "type": "blob",
          "size": 1.3935546875,
          "content": "package stats\n\nimport (\n\t\"math/rand\"\n\t\"sort\"\n)\n\n// Sample returns sample from input with replacement or without\nfunc Sample(input Float64Data, takenum int, replacement bool) ([]float64, error) {\n\n\tif input.Len() == 0 {\n\t\treturn nil, EmptyInputErr\n\t}\n\n\tlength := input.Len()\n\tif replacement {\n\n\t\tresult := Float64Data{}\n\t\trand.Seed(unixnano())\n\n\t\t// In every step, randomly take the num for\n\t\tfor i := 0; i < takenum; i++ {\n\t\t\tidx := rand.Intn(length)\n\t\t\tresult = append(result, input[idx])\n\t\t}\n\n\t\treturn result, nil\n\n\t} else if !replacement && takenum <= length {\n\n\t\trand.Seed(unixnano())\n\n\t\t// Get permutation of number of indexies\n\t\tperm := rand.Perm(length)\n\t\tresult := Float64Data{}\n\n\t\t// Get element of input by permutated index\n\t\tfor _, idx := range perm[0:takenum] {\n\t\t\tresult = append(result, input[idx])\n\t\t}\n\n\t\treturn result, nil\n\n\t}\n\n\treturn nil, BoundsErr\n}\n\n// StableSample like stable sort, it returns samples from input while keeps the order of original data.\nfunc StableSample(input Float64Data, takenum int) ([]float64, error) {\n\tif input.Len() == 0 {\n\t\treturn nil, EmptyInputErr\n\t}\n\n\tlength := input.Len()\n\n\tif takenum <= length {\n\n\t\trand.Seed(unixnano())\n\n\t\tperm := rand.Perm(length)\n\t\tperm = perm[0:takenum]\n\t\t// Sort perm before applying\n\t\tsort.Ints(perm)\n\t\tresult := Float64Data{}\n\n\t\tfor _, idx := range perm {\n\t\t\tresult = append(result, input[idx])\n\t\t}\n\n\t\treturn result, nil\n\n\t}\n\n\treturn nil, BoundsErr\n}\n"
        },
        {
          "name": "sample_test.go",
          "type": "blob",
          "size": 1.576171875,
          "content": "package stats_test\n\nimport (\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc TestSample(t *testing.T) {\n\t_, err := stats.Sample([]float64{}, 10, false)\n\tif err == nil {\n\t\tt.Errorf(\"should return an error\")\n\t}\n\n\t_, err = stats.Sample([]float64{0.1, 0.2}, 10, false)\n\tif err == nil {\n\t\tt.Errorf(\"should return an error\")\n\t}\n}\n\nfunc TestSampleWithoutReplacement(t *testing.T) {\n\tarr := []float64{0.1, 0.2, 0.3, 0.4, 0.5}\n\tresult, _ := stats.Sample(arr, 5, false)\n\tchecks := map[float64]bool{}\n\tfor _, res := range result {\n\t\t_, ok := checks[res]\n\t\tif ok {\n\t\t\tt.Errorf(\"%v already seen\", res)\n\t\t}\n\t\tchecks[res] = true\n\t}\n}\n\nfunc TestSampleWithReplacement(t *testing.T) {\n\tarr := []float64{0.1, 0.2, 0.3, 0.4, 0.5}\n\tnumsamples := 100\n\tresult, _ := stats.Sample(arr, numsamples, true)\n\tif len(result) != numsamples {\n\t\tt.Errorf(\"%v != %v\", len(result), numsamples)\n\t}\n}\n\nfunc TestStableSample(t *testing.T) {\n\t_, err := stats.StableSample(stats.Float64Data{}, 10)\n\tif err != stats.EmptyInputErr {\n\t\tt.Errorf(\"should return EmptyInputError when sampling an empty data\")\n\t}\n\t_, err = stats.StableSample(stats.Float64Data{1.0, 2.0}, 10)\n\tif err != stats.BoundsErr {\n\t\tt.Errorf(\"should return BoundsErr when sampling size exceeds the maximum element size of data\")\n\t}\n\tarr := []float64{1.0, 3.0, 2.0, -1.0, 5.0}\n\tlocations := map[float64]int{\n\t\t1.0:  0,\n\t\t3.0:  1,\n\t\t2.0:  2,\n\t\t-1.0: 3,\n\t\t5.0:  4,\n\t}\n\tret, _ := stats.StableSample(arr, 3)\n\tif len(ret) != 3 {\n\t\tt.Errorf(\"returned wrong sample size\")\n\t}\n\tfor i := 1; i < 3; i++ {\n\t\tif locations[ret[i]] < locations[ret[i-1]] {\n\t\t\tt.Errorf(\"doesn't keep order\")\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "sigmoid.go",
          "type": "blob",
          "size": 0.4443359375,
          "content": "package stats\n\nimport \"math\"\n\n// Sigmoid returns the input values in the range of -1 to 1\n// along the sigmoid or s-shaped curve, commonly used in\n// machine learning while training neural networks as an\n// activation function.\nfunc Sigmoid(input Float64Data) ([]float64, error) {\n\tif input.Len() == 0 {\n\t\treturn Float64Data{}, EmptyInput\n\t}\n\ts := make([]float64, len(input))\n\tfor i, v := range input {\n\t\ts[i] = 1 / (1 + math.Exp(-v))\n\t}\n\treturn s, nil\n}\n"
        },
        {
          "name": "sigmoid_test.go",
          "type": "blob",
          "size": 0.78125,
          "content": "package stats_test\n\nimport (\n\t\"fmt\"\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc ExampleSigmoid() {\n\ts, _ := stats.Sigmoid([]float64{3.0, 1.0, 2.1})\n\tfmt.Println(s)\n\t// Output: [0.9525741268224334 0.7310585786300049 0.8909031788043871]\n}\n\nfunc TestSigmoidEmptyInput(t *testing.T) {\n\t_, err := stats.Sigmoid([]float64{})\n\tif err != stats.EmptyInputErr {\n\t\tt.Errorf(\"Should have returned empty input error\")\n\t}\n}\n\nfunc TestSigmoid(t *testing.T) {\n\tsm, err := stats.Sigmoid([]float64{-0.54761371, 17.04850603, 4.86054302})\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\ta := 0.3664182235138545\n\tif sm[0] != a {\n\t\tt.Errorf(\"%v != %v\", sm[0], a)\n\t}\n\n\ta = 0.9999999605608187\n\tif sm[1] != a {\n\t\tt.Errorf(\"%v != %v\", sm[1], a)\n\t}\n\n\ta = 0.9923132671908277\n\tif sm[2] != a {\n\t\tt.Errorf(\"%v != %v\", sm[2], a)\n\t}\n}\n"
        },
        {
          "name": "softmax.go",
          "type": "blob",
          "size": 0.5048828125,
          "content": "package stats\n\nimport \"math\"\n\n// SoftMax returns the input values in the range of 0 to 1\n// with sum of all the probabilities being equal to one. It\n// is commonly used in machine learning neural networks.\nfunc SoftMax(input Float64Data) ([]float64, error) {\n\tif input.Len() == 0 {\n\t\treturn Float64Data{}, EmptyInput\n\t}\n\n\ts := 0.0\n\tc, _ := Max(input)\n\tfor _, e := range input {\n\t\ts += math.Exp(e - c)\n\t}\n\n\tsm := make([]float64, len(input))\n\tfor i, v := range input {\n\t\tsm[i] = math.Exp(v-c) / s\n\t}\n\n\treturn sm, nil\n}\n"
        },
        {
          "name": "softmax_test.go",
          "type": "blob",
          "size": 0.7646484375,
          "content": "package stats_test\n\nimport (\n\t\"fmt\"\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc ExampleSoftMax() {\n\tsm, _ := stats.SoftMax([]float64{3.0, 1.0, 0.2})\n\tfmt.Println(sm)\n\t// Output: [0.8360188027814407 0.11314284146556013 0.05083835575299916]\n}\n\nfunc TestSoftMaxEmptyInput(t *testing.T) {\n\t_, err := stats.SoftMax([]float64{})\n\tif err != stats.EmptyInputErr {\n\t\tt.Errorf(\"Should have returned empty input error\")\n\t}\n}\n\nfunc TestSoftMax(t *testing.T) {\n\tsm, err := stats.SoftMax([]float64{3.0, 1.0, 0.2})\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\ta := 0.8360188027814407\n\tif sm[0] != a {\n\t\tt.Errorf(\"%v != %v\", sm[0], a)\n\t}\n\n\ta = 0.11314284146556013\n\tif sm[1] != a {\n\t\tt.Errorf(\"%v != %v\", sm[1], a)\n\t}\n\n\ta = 0.05083835575299916\n\tif sm[2] != a {\n\t\tt.Errorf(\"%v != %v\", sm[1], a)\n\t}\n}\n"
        },
        {
          "name": "sum.go",
          "type": "blob",
          "size": 0.2646484375,
          "content": "package stats\n\nimport \"math\"\n\n// Sum adds all the numbers of a slice together\nfunc Sum(input Float64Data) (sum float64, err error) {\n\n\tif input.Len() == 0 {\n\t\treturn math.NaN(), EmptyInputErr\n\t}\n\n\t// Add em up\n\tfor _, n := range input {\n\t\tsum += n\n\t}\n\n\treturn sum, nil\n}\n"
        },
        {
          "name": "sum_test.go",
          "type": "blob",
          "size": 0.9521484375,
          "content": "package stats_test\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc ExampleSum() {\n\td := []float64{1.1, 2.2, 3.3}\n\ta, _ := stats.Sum(d)\n\tfmt.Println(a)\n\t// Output: 6.6\n}\n\nfunc TestSum(t *testing.T) {\n\tfor _, c := range []struct {\n\t\tin  []float64\n\t\tout float64\n\t}{\n\t\t{[]float64{1, 2, 3}, 6},\n\t\t{[]float64{1.0, 1.1, 1.2, 2.2}, 5.5},\n\t\t{[]float64{1, -1, 2, -3}, -1},\n\t} {\n\t\tgot, err := stats.Sum(c.in)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"Returned an error\")\n\t\t}\n\t\tif !reflect.DeepEqual(c.out, got) {\n\t\t\tt.Errorf(\"Sum(%.1f) => %.1f != %.1f\", c.in, got, c.out)\n\t\t}\n\t}\n\t_, err := stats.Sum([]float64{})\n\tif err == nil {\n\t\tt.Errorf(\"Empty slice should have returned an error\")\n\t}\n}\n\nfunc BenchmarkSumSmallFloatSlice(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Sum(makeFloatSlice(5))\n\t}\n}\n\nfunc BenchmarkSumLargeFloatSlice(b *testing.B) {\n\tlf := makeFloatSlice(100000)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_, _ = stats.Sum(lf)\n\t}\n}\n"
        },
        {
          "name": "test_utils_test.go",
          "type": "blob",
          "size": 0.66796875,
          "content": "package stats_test\n\n// Approximate float comparisons\n// Taken from the standard library's math/all_test.go\nfunc tolerance(a, b, e float64) bool {\n\t// Multiplying by e here can underflow denormal values to zero.\n\t// Check a==b so that at least if a and b are small and identical\n\t// we say they match.\n\tif a == b {\n\t\treturn true\n\t}\n\td := a - b\n\tif d < 0 {\n\t\td = -d\n\t}\n\n\t// note: b is correct (expected) value, a is actual value.\n\t// make error tolerance a fraction of b, not a.\n\tif b != 0 {\n\t\te = e * b\n\t\tif e < 0 {\n\t\t\te = -e\n\t\t}\n\t}\n\treturn d < e\n}\nfunc close(a, b float64) bool     { return tolerance(a, b, 1e-14) }\nfunc veryclose(a, b float64) bool { return tolerance(a, b, 4e-16) }\n"
        },
        {
          "name": "util.go",
          "type": "blob",
          "size": 0.900390625,
          "content": "package stats\n\nimport (\n\t\"sort\"\n\t\"time\"\n)\n\n// float64ToInt rounds a float64 to an int\nfunc float64ToInt(input float64) (output int) {\n\tr, _ := Round(input, 0)\n\treturn int(r)\n}\n\n// unixnano returns nanoseconds from UTC epoch\nfunc unixnano() int64 {\n\treturn time.Now().UTC().UnixNano()\n}\n\n// copyslice copies a slice of float64s\nfunc copyslice(input Float64Data) Float64Data {\n\ts := make(Float64Data, input.Len())\n\tcopy(s, input)\n\treturn s\n}\n\n// sortedCopy returns a sorted copy of float64s\nfunc sortedCopy(input Float64Data) (copy Float64Data) {\n\tcopy = copyslice(input)\n\tsort.Float64s(copy)\n\treturn\n}\n\n// sortedCopyDif returns a sorted copy of float64s\n// only if the original data isn't sorted.\n// Only use this if returned slice won't be manipulated!\nfunc sortedCopyDif(input Float64Data) (copy Float64Data) {\n\tif sort.Float64sAreSorted(input) {\n\t\treturn input\n\t}\n\tcopy = copyslice(input)\n\tsort.Float64s(copy)\n\treturn\n}\n"
        },
        {
          "name": "util_test.go",
          "type": "blob",
          "size": 0.294921875,
          "content": "package stats\n\nimport (\n\t\"testing\"\n)\n\nfunc TestFloat64ToInt(t *testing.T) {\n\tm := float64ToInt(234.0234)\n\tif m != 234 {\n\t\tt.Errorf(\"%x != %x\", m, 234)\n\t}\n\tm = float64ToInt(-234.0234)\n\tif m != -234 {\n\t\tt.Errorf(\"%x != %x\", m, -234)\n\t}\n\tm = float64ToInt(1)\n\tif m != 1 {\n\t\tt.Errorf(\"%x != %x\", m, 1)\n\t}\n}\n"
        },
        {
          "name": "variance.go",
          "type": "blob",
          "size": 2.2421875,
          "content": "package stats\n\nimport \"math\"\n\n// _variance finds the variance for both population and sample data\nfunc _variance(input Float64Data, sample int) (variance float64, err error) {\n\n\tif input.Len() == 0 {\n\t\treturn math.NaN(), EmptyInputErr\n\t}\n\n\t// Sum the square of the mean subtracted from each number\n\tm, _ := Mean(input)\n\n\tfor _, n := range input {\n\t\tvariance += (n - m) * (n - m)\n\t}\n\n\t// When getting the mean of the squared differences\n\t// \"sample\" will allow us to know if it's a sample\n\t// or population and wether to subtract by one or not\n\treturn variance / float64((input.Len() - (1 * sample))), nil\n}\n\n// Variance the amount of variation in the dataset\nfunc Variance(input Float64Data) (sdev float64, err error) {\n\treturn PopulationVariance(input)\n}\n\n// PopulationVariance finds the amount of variance within a population\nfunc PopulationVariance(input Float64Data) (pvar float64, err error) {\n\n\tv, err := _variance(input, 0)\n\tif err != nil {\n\t\treturn math.NaN(), err\n\t}\n\n\treturn v, nil\n}\n\n// SampleVariance finds the amount of variance within a sample\nfunc SampleVariance(input Float64Data) (svar float64, err error) {\n\n\tv, err := _variance(input, 1)\n\tif err != nil {\n\t\treturn math.NaN(), err\n\t}\n\n\treturn v, nil\n}\n\n// Covariance is a measure of how much two sets of data change\nfunc Covariance(data1, data2 Float64Data) (float64, error) {\n\n\tl1 := data1.Len()\n\tl2 := data2.Len()\n\n\tif l1 == 0 || l2 == 0 {\n\t\treturn math.NaN(), EmptyInputErr\n\t}\n\n\tif l1 != l2 {\n\t\treturn math.NaN(), SizeErr\n\t}\n\n\tm1, _ := Mean(data1)\n\tm2, _ := Mean(data2)\n\n\t// Calculate sum of squares\n\tvar ss float64\n\tfor i := 0; i < l1; i++ {\n\t\tdelta1 := (data1.Get(i) - m1)\n\t\tdelta2 := (data2.Get(i) - m2)\n\t\tss += (delta1*delta2 - ss) / float64(i+1)\n\t}\n\n\treturn ss * float64(l1) / float64(l1-1), nil\n}\n\n// CovariancePopulation computes covariance for entire population between two variables.\nfunc CovariancePopulation(data1, data2 Float64Data) (float64, error) {\n\n\tl1 := data1.Len()\n\tl2 := data2.Len()\n\n\tif l1 == 0 || l2 == 0 {\n\t\treturn math.NaN(), EmptyInputErr\n\t}\n\n\tif l1 != l2 {\n\t\treturn math.NaN(), SizeErr\n\t}\n\n\tm1, _ := Mean(data1)\n\tm2, _ := Mean(data2)\n\n\tvar s float64\n\tfor i := 0; i < l1; i++ {\n\t\tdelta1 := (data1.Get(i) - m1)\n\t\tdelta2 := (data2.Get(i) - m2)\n\t\ts += delta1 * delta2\n\t}\n\n\treturn s / float64(l1), nil\n}\n"
        },
        {
          "name": "variance_test.go",
          "type": "blob",
          "size": 2.1865234375,
          "content": "package stats_test\n\nimport (\n\t\"math\"\n\t\"testing\"\n\n\t\"github.com/montanaflynn/stats\"\n)\n\nfunc TestVariance(t *testing.T) {\n\t_, err := stats.Variance([]float64{1, 2, 3})\n\tif err != nil {\n\t\tt.Errorf(\"Returned an error\")\n\t}\n}\n\nfunc TestPopulationVariance(t *testing.T) {\n\te, err := stats.PopulationVariance([]float64{})\n\tif !math.IsNaN(e) {\n\t\tt.Errorf(\"%.1f != %.1f\", e, math.NaN())\n\t}\n\tif err != stats.EmptyInputErr {\n\t\tt.Errorf(\"%v != %v\", err, stats.EmptyInputErr)\n\t}\n\n\tpv, _ := stats.PopulationVariance([]float64{1, 2, 3})\n\ta, err := stats.Round(pv, 1)\n\tif err != nil {\n\t\tt.Errorf(\"Returned an error\")\n\t}\n\tif a != 0.7 {\n\t\tt.Errorf(\"%.1f != %.1f\", a, 0.7)\n\t}\n}\n\nfunc TestSampleVariance(t *testing.T) {\n\tm, err := stats.SampleVariance([]float64{})\n\tif !math.IsNaN(m) {\n\t\tt.Errorf(\"%.1f != %.1f\", m, math.NaN())\n\t}\n\tif err != stats.EmptyInputErr {\n\t\tt.Errorf(\"%v != %v\", err, stats.EmptyInputErr)\n\t}\n\tm, _ = stats.SampleVariance([]float64{1, 2, 3})\n\tif m != 1.0 {\n\t\tt.Errorf(\"%.1f != %.1f\", m, 1.0)\n\t}\n}\n\nfunc TestCovariance(t *testing.T) {\n\ts1 := []float64{1, 2, 3, 4, 5}\n\ts2 := []float64{10, -51.2, 8}\n\ts3 := []float64{1, 2, 3, 5, 6}\n\ts4 := []float64{}\n\n\t_, err := stats.Covariance(s1, s2)\n\tif err == nil {\n\t\tt.Errorf(\"Mismatched slice lengths should have returned an error\")\n\t}\n\n\ta, err := stats.Covariance(s1, s3)\n\tif err != nil {\n\t\tt.Errorf(\"Should not have returned an error\")\n\t}\n\n\tif a != 3.2499999999999996 {\n\t\tt.Errorf(\"Covariance %v != %v\", a, 3.2499999999999996)\n\t}\n\n\t_, err = stats.Covariance(s1, s4)\n\tif err == nil {\n\t\tt.Errorf(\"Empty slice should have returned an error\")\n\t}\n}\n\nfunc TestCovariancePopulation(t *testing.T) {\n\ts1 := []float64{1, 2, 3.5, 3.7, 8, 12}\n\ts2 := []float64{10, -51.2, 8}\n\ts3 := []float64{0.5, 1, 2.1, 3.4, 3.4, 4}\n\ts4 := []float64{}\n\n\t_, err := stats.CovariancePopulation(s1, s2)\n\tif err == nil {\n\t\tt.Errorf(\"Mismatched slice lengths should have returned an error\")\n\t}\n\n\ta, err := stats.CovariancePopulation(s1, s3)\n\tif err != nil {\n\t\tt.Errorf(\"Should not have returned an error\")\n\t}\n\n\tif a != 4.191666666666666 {\n\t\tt.Errorf(\"CovariancePopulation %v != %v\", a, 4.191666666666666)\n\t}\n\n\t_, err = stats.CovariancePopulation(s1, s4)\n\tif err == nil {\n\t\tt.Errorf(\"Empty slice should have returned an error\")\n\t}\n}\n"
        }
      ]
    }
  ]
}