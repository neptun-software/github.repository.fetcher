{
  "metadata": {
    "timestamp": 1736568176648,
    "page": 4,
    "hasNextPage": false,
    "endCursor": "Y3Vyc29yOjQ=",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "ollama/ollama",
      "stars": 106892,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.0634765625,
          "content": ".vscode\nollama\napp\nmacapp\ndist\n.env\n.cache\ntest_data\nllama/build\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.2822265625,
          "content": "llama/**/*.cpp linguist-vendored\nllama/**/*.hpp linguist-vendored\nllama/**/*.h linguist-vendored\nllama/**/*.c linguist-vendored\nllama/**/*.cu linguist-vendored\nllama/**/*.cuh linguist-vendored\nllama/**/*.m linguist-vendored\nllama/**/*.metal linguist-vendored\n\n* text=auto\n*.go text eol=lf\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.115234375,
          "content": ".DS_Store\n.vscode\n.env\n.venv\n.swp\ndist\nollama\n.cache\n*.exe\n.idea\ntest_data\n*.crt\nllama/build\n__debug_bin*\nllama/vendor"
        },
        {
          "name": ".golangci.yaml",
          "type": "blob",
          "size": 0.693359375,
          "content": "run:\n  timeout: 5m\nlinters:\n  enable:\n    - asasalint\n    - bidichk\n    - bodyclose\n    - containedctx\n    - contextcheck\n    - errcheck\n    - gocheckcompilerdirectives\n    - gofmt\n    - gofumpt\n    - gosimple\n    - govet\n    - ineffassign\n    - intrange\n    - makezero\n    - misspell\n    - nilerr\n    - nolintlint\n    - nosprintfhostport\n    - staticcheck\n    - tenv\n    - unconvert\n    - unused\n    - usestdlibvars\n    - wastedassign\n    - whitespace\nlinters-settings:\n  staticcheck:\n    checks:\n      - all\n      - -SA1019 # omit Deprecated check\nseverity:\n  default-severity: error\n  rules:\n    - linters:\n        - gofmt\n        - goimports\n        - intrange\n        - usestdlibvars\n      severity: info\n"
        },
        {
          "name": ".prettierrc.json",
          "type": "blob",
          "size": 0.1748046875,
          "content": "{\n  \"trailingComma\": \"es5\",\n  \"tabWidth\": 2,\n  \"useTabs\": false,\n  \"semi\": false,\n  \"singleQuote\": true,\n  \"jsxSingleQuote\": true,\n  \"printWidth\": 120,\n  \"arrowParens\": \"avoid\"\n}\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 2.314453125,
          "content": "# Contributing to Ollama\n\nThank you for your interest in contributing to Ollama! Here are a few guidelines to help get you started.\n\n## Set up\n\nSee the [development documentation](./docs/development.md) for instructions on how to build and run Ollama locally.\n\n## Pull requests\n\n### Ideal issues\n\n* [Bugs](https://github.com/ollama/ollama/issues?q=is%3Aissue+is%3Aopen+label%3Abug): issues where Ollama stops working or where it results in an unexpected error.\n* [Performance](https://github.com/ollama/ollama/issues?q=is%3Aissue+is%3Aopen+label%3Aperformance): issues to make Ollama faster at model inference, downloading or uploading.\n* [Security](https://github.com/ollama/ollama/blob/main/SECURITY.md): issues that could lead to a security vulnerability. As mentioned in [SECURITY.md](https://github.com/ollama/ollama/blob/main/SECURITY.md), please do not disclose security vulnerabilities publicly.\n\n### Issues that are harder to review\n\n* New features: new features (e.g. API fields, environment variables) add surface area to Ollama and make it harder to maintain in the long run as they cannot be removed without potentially breaking users in the future.\n* Refactoring: large code improvements are important, but can be harder or take longer to review and merge.\n* Documentation: small updates to fill in or correct missing documentation is helpful, however large documentation additions can be hard to maintain over time.\n\n### Issues that may not be accepted\n\n* Changes that break backwards compatibility in Ollama's API (including the OpenAI-compatible API)\n* Changes that add significant friction to the user experience\n* Changes that create a large future maintenance burden for maintainers and contributors\n\n### Best practices\n\n* Commit messages: please leave both a title and a description in your commit messages. The title should be a short summary of the changes, with a leading word that explains the section of the code being changed (e.g. `api: fix parsing of prompt field`) . In the description, leave a short 2-3 sentences that explain more about the change and its impact.\n* Tests: please add test coverage to changes where possible.\n* Minimize dependencies: avoid adding new dependencies unless absolutely necessary.\n\n## Need help?\n\nIf you need help with anything, feel free to reach out to us on our [Discord server](https://discord.gg/ollama).\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 8.2919921875,
          "content": "ARG GOLANG_VERSION=1.22.8\nARG CUDA_VERSION_11=11.3.1\nARG CUDA_VERSION_12=12.4.0\nARG ROCM_VERSION=6.1.2\nARG JETPACK_6=r36.2.0\nARG JETPACK_5=r35.4.1\n\n### To create a local image for building linux binaries on mac or windows with efficient incremental builds\n#\n# docker build --platform linux/amd64 -t builder-amd64 -f Dockerfile --target unified-builder-amd64 .\n# docker run --platform linux/amd64 --rm -it -v $(pwd):/go/src/github.com/ollama/ollama/ builder-amd64\n#\n### Then incremental builds will be much faster in this container\n#\n# make -j 10 dist\n#\nFROM --platform=linux/amd64 rocm/dev-centos-7:${ROCM_VERSION}-complete AS unified-builder-amd64\nARG GOLANG_VERSION\nARG CUDA_VERSION_11\nARG CUDA_VERSION_12\nCOPY ./scripts/rh_linux_deps.sh /\nENV PATH /opt/rh/devtoolset-10/root/usr/bin:/usr/local/cuda/bin:$PATH\nENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/cuda/lib64\nRUN GOLANG_VERSION=${GOLANG_VERSION} sh /rh_linux_deps.sh\nRUN yum-config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/rhel7/x86_64/cuda-rhel7.repo && \\\n    dnf clean all && \\\n    dnf install -y \\\n    zsh \\\n    cuda-toolkit-$(echo ${CUDA_VERSION_11} | cut -f1-2 -d. | sed -e \"s/\\./-/g\") \\\n    cuda-toolkit-$(echo ${CUDA_VERSION_12} | cut -f1-2 -d. | sed -e \"s/\\./-/g\")\n# TODO intel oneapi goes here...\nENV GOARCH amd64\nENV CGO_ENABLED 1\nWORKDIR /go/src/github.com/ollama/ollama/\nENTRYPOINT [ \"zsh\" ]\n\n### To create a local image for building linux binaries on mac or linux/arm64 with efficient incremental builds\n# Note: this does not contain jetson variants\n#\n# docker build --platform linux/arm64 -t builder-arm64 -f Dockerfile --target unified-builder-arm64 .\n# docker run --platform linux/arm64 --rm -it -v $(pwd):/go/src/github.com/ollama/ollama/ builder-arm64\n#\nFROM --platform=linux/arm64 rockylinux:8 AS unified-builder-arm64\nARG GOLANG_VERSION\nARG CUDA_VERSION_11\nARG CUDA_VERSION_12\nCOPY ./scripts/rh_linux_deps.sh /\nRUN GOLANG_VERSION=${GOLANG_VERSION} sh /rh_linux_deps.sh\nRUN yum-config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/rhel8/sbsa/cuda-rhel8.repo && \\\n    dnf config-manager --set-enabled appstream && \\\n    dnf clean all && \\\n    dnf install -y \\\n    zsh \\\n    cuda-toolkit-$(echo ${CUDA_VERSION_11} | cut -f1-2 -d. | sed -e \"s/\\./-/g\") \\\n    cuda-toolkit-$(echo ${CUDA_VERSION_12} | cut -f1-2 -d. | sed -e \"s/\\./-/g\")\nENV PATH /opt/rh/gcc-toolset-10/root/usr/bin:$PATH:/usr/local/cuda/bin\nENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/cuda/lib64\nENV LIBRARY_PATH=/usr/local/cuda/lib64/stubs:/opt/amdgpu/lib64\nENV GOARCH arm64\nENV CGO_ENABLED 1\nWORKDIR /go/src/github.com/ollama/ollama/\nENTRYPOINT [ \"zsh\" ]\n\nFROM --platform=linux/amd64 unified-builder-amd64 AS build-amd64\nCOPY . .\nARG OLLAMA_SKIP_CUDA_GENERATE\nARG OLLAMA_SKIP_ROCM_GENERATE\nARG OLLAMA_FAST_BUILD\nARG VERSION\nARG CUSTOM_CPU_FLAGS\nRUN --mount=type=cache,target=/root/.ccache \\\n    if grep \"^flags\" /proc/cpuinfo|grep avx>/dev/null; then \\\n        make -j $(nproc) dist ; \\\n    else \\\n        make -j 5 dist ; \\\n    fi\nRUN cd dist/linux-$GOARCH && \\\n    tar -cf - . | pigz --best > ../ollama-linux-$GOARCH.tgz\nRUN if [ -z ${OLLAMA_SKIP_ROCM_GENERATE} ] ; then \\\n    cd dist/linux-$GOARCH-rocm && \\\n    tar -cf - . | pigz --best > ../ollama-linux-$GOARCH-rocm.tgz ;\\\n    fi\n\n# Jetsons need to be built in discrete stages\nFROM --platform=linux/arm64 nvcr.io/nvidia/l4t-jetpack:${JETPACK_5} AS runners-jetpack5-arm64\nARG GOLANG_VERSION\nRUN apt-get update && apt-get install -y git curl ccache && \\\n    curl -s -L https://dl.google.com/go/go${GOLANG_VERSION}.linux-arm64.tar.gz | tar xz -C /usr/local && \\\n    ln -s /usr/local/go/bin/go /usr/local/bin/go && \\\n    ln -s /usr/local/go/bin/gofmt /usr/local/bin/gofmt && \\\n    apt-get clean && rm -rf /var/lib/apt/lists/*\nWORKDIR /go/src/github.com/ollama/ollama/\nCOPY . .\nARG CGO_CFLAGS\nENV GOARCH arm64\nARG VERSION\nRUN --mount=type=cache,target=/root/.ccache \\\n    make -j 5 dist_cuda_v11 \\\n        CUDA_ARCHITECTURES=\"72;87\" \\\n        GPU_RUNNER_VARIANT=_jetpack5 \\\n        DIST_LIB_DIR=/go/src/github.com/ollama/ollama/dist/linux-arm64-jetpack5/lib/ollama \\\n        DIST_GPU_RUNNER_DEPS_DIR=/go/src/github.com/ollama/ollama/dist/linux-arm64-jetpack5/lib/ollama/cuda_jetpack5\n\nFROM --platform=linux/arm64 nvcr.io/nvidia/l4t-jetpack:${JETPACK_6} AS runners-jetpack6-arm64\nARG GOLANG_VERSION\nRUN apt-get update && apt-get install -y git curl ccache && \\\n    curl -s -L https://dl.google.com/go/go${GOLANG_VERSION}.linux-arm64.tar.gz | tar xz -C /usr/local && \\\n    ln -s /usr/local/go/bin/go /usr/local/bin/go && \\\n    ln -s /usr/local/go/bin/gofmt /usr/local/bin/gofmt && \\\n    apt-get clean && rm -rf /var/lib/apt/lists/*\nWORKDIR /go/src/github.com/ollama/ollama/\nCOPY . .\nARG CGO_CFLAGS\nENV GOARCH arm64\nARG VERSION\nRUN --mount=type=cache,target=/root/.ccache \\\n    make -j 5 dist_cuda_v12 \\\n        CUDA_ARCHITECTURES=\"87\" \\\n        GPU_RUNNER_VARIANT=_jetpack6 \\\n        DIST_LIB_DIR=/go/src/github.com/ollama/ollama/dist/linux-arm64-jetpack6/lib/ollama \\\n        DIST_GPU_RUNNER_DEPS_DIR=/go/src/github.com/ollama/ollama/dist/linux-arm64-jetpack6/lib/ollama/cuda_jetpack6\n\nFROM --platform=linux/arm64 unified-builder-arm64 AS build-arm64\nCOPY . .\nARG OLLAMA_SKIP_CUDA_GENERATE\nARG OLLAMA_FAST_BUILD\nARG VERSION\nRUN --mount=type=cache,target=/root/.ccache \\\n    make -j 5 dist\nCOPY --from=runners-jetpack5-arm64 /go/src/github.com/ollama/ollama/dist/ dist/\nCOPY --from=runners-jetpack6-arm64 /go/src/github.com/ollama/ollama/dist/ dist/\nRUN cd dist/linux-$GOARCH && \\\n    tar -cf - . | pigz --best > ../ollama-linux-$GOARCH.tgz\nRUN cd dist/linux-$GOARCH-jetpack5 && \\\n    tar -cf - . | pigz --best > ../ollama-linux-$GOARCH-jetpack5.tgz\nRUN cd dist/linux-$GOARCH-jetpack6 && \\\n    tar -cf - . | pigz --best > ../ollama-linux-$GOARCH-jetpack6.tgz\n\nFROM --platform=linux/amd64 scratch AS dist-amd64\nCOPY --from=build-amd64 /go/src/github.com/ollama/ollama/dist/ollama-linux-*.tgz /\nFROM --platform=linux/arm64 scratch AS dist-arm64\nCOPY --from=build-arm64 /go/src/github.com/ollama/ollama/dist/ollama-linux-*.tgz /\nFROM dist-$TARGETARCH AS dist\n\n\n# For amd64 container images, filter out cuda/rocm to minimize size\nFROM build-amd64 AS runners-cuda-amd64\nRUN rm -rf \\\n    ./dist/linux-amd64/lib/ollama/libggml_hipblas.so \\\n    ./dist/linux-amd64/lib/ollama/runners/rocm*\n\nFROM build-amd64 AS runners-rocm-amd64\nRUN rm -rf \\\n    ./dist/linux-amd64/lib/ollama/libggml_cuda*.so \\\n    ./dist/linux-amd64/lib/ollama/libcu*.so* \\\n    ./dist/linux-amd64/lib/ollama/runners/cuda*\n\nFROM --platform=linux/amd64 ubuntu:22.04 AS runtime-amd64\nRUN apt-get update && \\\n    apt-get install -y ca-certificates && \\\n    apt-get clean && rm -rf /var/lib/apt/lists/*\nCOPY --from=build-amd64 /go/src/github.com/ollama/ollama/dist/linux-amd64/bin/ /bin/\nCOPY --from=runners-cuda-amd64 /go/src/github.com/ollama/ollama/dist/linux-amd64/lib/ /lib/\n\nFROM --platform=linux/arm64 ubuntu:22.04 AS runtime-arm64\nRUN apt-get update && \\\n    apt-get install -y ca-certificates && \\\n    apt-get clean && rm -rf /var/lib/apt/lists/*\nCOPY --from=build-arm64 /go/src/github.com/ollama/ollama/dist/linux-arm64/bin/ /bin/\nCOPY --from=build-arm64 /go/src/github.com/ollama/ollama/dist/linux-arm64/lib/ /lib/\nCOPY --from=runners-jetpack5-arm64 /go/src/github.com/ollama/ollama/dist/linux-arm64-jetpack5/lib/ /lib/\nCOPY --from=runners-jetpack6-arm64 /go/src/github.com/ollama/ollama/dist/linux-arm64-jetpack6/lib/ /lib/\n\n\n# ROCm libraries larger so we keep it distinct from the CPU/CUDA image\nFROM --platform=linux/amd64 ubuntu:22.04 AS runtime-rocm\n# Frontload the rocm libraries which are large, and rarely change to increase chance of a common layer\n# across releases\nCOPY --from=build-amd64 /go/src/github.com/ollama/ollama/dist/linux-amd64-rocm/lib/ /lib/\nRUN apt-get update && \\\n    apt-get install -y ca-certificates && \\\n    apt-get clean && rm -rf /var/lib/apt/lists/*\nCOPY --from=build-amd64 /go/src/github.com/ollama/ollama/dist/linux-amd64/bin/ /bin/\nCOPY --from=runners-rocm-amd64 /go/src/github.com/ollama/ollama/dist/linux-amd64/lib/ /lib/\n\nEXPOSE 11434\nENV OLLAMA_HOST 0.0.0.0\n\nENTRYPOINT [\"/bin/ollama\"]\nCMD [\"serve\"]\n\nFROM runtime-$TARGETARCH\nEXPOSE 11434\nENV OLLAMA_HOST 0.0.0.0\nENV PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nENV LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64\nENV NVIDIA_DRIVER_CAPABILITIES=compute,utility\nENV NVIDIA_VISIBLE_DEVICES=all\n\nENTRYPOINT [\"/bin/ollama\"]\nCMD [\"serve\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.033203125,
          "content": "MIT License\n\nCopyright (c) Ollama\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 3.1455078125,
          "content": "# top level makefile for Ollama\ninclude make/common-defs.make\n\n\n# Determine which if any GPU runners we should build\ninclude make/cuda-v11-defs.make\ninclude make/cuda-v12-defs.make\ninclude make/rocm-defs.make\n\nifeq ($(CUSTOM_CPU_FLAGS),)\nifeq ($(ARCH),amd64)\n\tRUNNER_TARGETS=cpu\nendif\n# Without CUSTOM_CPU_FLAGS we default to build both v11 and v12 if present\nifeq ($(OLLAMA_SKIP_CUDA_GENERATE),)\nifneq ($(CUDA_11_COMPILER),)\n\tRUNNER_TARGETS += cuda_v11\nendif\nifneq ($(CUDA_12_COMPILER),)\n\tRUNNER_TARGETS += cuda_v12\nendif\nendif\nelse # CUSTOM_CPU_FLAGS is set, we'll build only the latest cuda version detected\nifneq ($(CUDA_12_COMPILER),)\n\tRUNNER_TARGETS += cuda_v12\nelse ifneq ($(CUDA_11_COMPILER),)\n\tRUNNER_TARGETS += cuda_v11\nendif\nendif\n\nifeq ($(OLLAMA_SKIP_ROCM_GENERATE),)\nifneq ($(HIP_COMPILER),)\n\tRUNNER_TARGETS += rocm\nendif\nendif\n\n\nall: runners exe\n\ndist: $(addprefix dist_, $(RUNNER_TARGETS)) dist_exe\n\ndist_%:\n\t@$(MAKE) --no-print-directory -f make/Makefile.$* dist\n\nrunners: $(RUNNER_TARGETS)\n\n$(RUNNER_TARGETS):\n\t@$(MAKE) --no-print-directory -f make/Makefile.$@\n\nexe dist_exe:\n\t@$(MAKE) --no-print-directory -f make/Makefile.ollama $@\n\nhelp-sync apply-patches create-patches sync sync-clean:\n\t@$(MAKE) --no-print-directory -f make/Makefile.sync $@\n\ntest integration lint:\n\t@$(MAKE) --no-print-directory -f make/Makefile.test $@\n\nclean:\n\trm -rf $(BUILD_DIR) $(DIST_LIB_DIR) $(OLLAMA_EXE) $(DIST_OLLAMA_EXE)\n\tgo clean -cache\n\nhelp:\n\t@echo \"The following make targets will help you build Ollama\"\n\t@echo \"\"\n\t@echo \"\tmake all   \t\t# (default target) Build Ollama llm subprocess runners, and the primary ollama executable\"\n\t@echo \"\tmake runners\t\t# Build Ollama llm subprocess runners; after you may use 'go build .' to build the primary ollama exectuable\"\n\t@echo \"\tmake <runner>\t\t# Build specific runners. Enabled: '$(RUNNER_TARGETS)'\"\n\t@echo \"\tmake dist\t\t# Build the runners and primary ollama executable for distribution\"\n\t@echo \"\tmake help-sync \t\t# Help information on vendor update targets\"\n\t@echo \"\tmake help-runners \t# Help information on runner targets\"\n\t@echo \"\"\n\t@echo \"The following make targets will help you test Ollama\"\n\t@echo \"\"\n\t@echo \"\tmake test   \t\t# Run unit tests\"\n\t@echo \"\tmake integration\t# Run integration tests.  You must 'make all' first\"\n\t@echo \"\tmake lint   \t\t# Run lint and style tests\"\n\t@echo \"\"\n\t@echo \"For more information see 'docs/development.md'\"\n\t@echo \"\"\n\n\nhelp-runners:\n\t@echo \"The following runners will be built based on discovered GPU libraries: '$(RUNNER_TARGETS)'\"\n\t@echo \"\"\n\t@echo \"GPU Runner CPU Flags: '$(GPU_RUNNER_CPU_FLAGS)'  (Override with CUSTOM_CPU_FLAGS)\"\n\t@echo \"\"\n\t@echo \"# CUDA_PATH sets the location where CUDA toolkits are present\"\n\t@echo \"CUDA_PATH=$(CUDA_PATH)\"\n\t@echo \"\tCUDA_11_PATH=$(CUDA_11_PATH)\"\n\t@echo \"\tCUDA_11_COMPILER=$(CUDA_11_COMPILER)\"\n\t@echo \"\tCUDA_12_PATH=$(CUDA_12_PATH)\"\n\t@echo \"\tCUDA_12_COMPILER=$(CUDA_12_COMPILER)\"\n\t@echo \"\"\n\t@echo \"# HIP_PATH sets the location where the ROCm toolkit is present\"\n\t@echo \"HIP_PATH=$(HIP_PATH)\"\n\t@echo \"\tHIP_COMPILER=$(HIP_COMPILER)\"\n\n.PHONY: all exe dist help help-sync help-runners test integration lint runners clean $(RUNNER_TARGETS)\n\n# Handy debugging for make variables\nprint-%:\n\t@echo '$*=$($*)'\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 29.326171875,
          "content": "<div align=\"center\">\nÂ  <a href=\"https://ollama.com\" />\n    <img alt=\"ollama\" height=\"200px\" src=\"https://github.com/ollama/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7\">\n  </a>\n</div>\n\n# Ollama\n\n[Discord](https://discord.gg/ollama)\n\nGet up and running with large language models.\n\n### macOS\n\n[Download](https://ollama.com/download/Ollama-darwin.zip)\n\n### Windows\n\n[Download](https://ollama.com/download/OllamaSetup.exe)\n\n### Linux\n\n```\ncurl -fsSL https://ollama.com/install.sh | sh\n```\n\n[Manual install instructions](https://github.com/ollama/ollama/blob/main/docs/linux.md)\n\n### Docker\n\nThe official [Ollama Docker image](https://hub.docker.com/r/ollama/ollama) `ollama/ollama` is available on Docker Hub.\n\n### Libraries\n\n- [ollama-python](https://github.com/ollama/ollama-python)\n- [ollama-js](https://github.com/ollama/ollama-js)\n\n## Quickstart\n\nTo run and chat with [Llama 3.2](https://ollama.com/library/llama3.2):\n\n```\nollama run llama3.2\n```\n\n## Model library\n\nOllama supports a list of models available on [ollama.com/library](https://ollama.com/library 'ollama model library')\n\nHere are some example models that can be downloaded:\n\n| Model              | Parameters | Size  | Download                         |\n| ------------------ | ---------- | ----- | -------------------------------- |\n| Llama 3.3          | 70B        | 43GB  | `ollama run llama3.3`            |\n| Llama 3.2          | 3B         | 2.0GB | `ollama run llama3.2`            |\n| Llama 3.2          | 1B         | 1.3GB | `ollama run llama3.2:1b`         |\n| Llama 3.2 Vision   | 11B        | 7.9GB | `ollama run llama3.2-vision`     |\n| Llama 3.2 Vision   | 90B        | 55GB  | `ollama run llama3.2-vision:90b` |\n| Llama 3.1          | 8B         | 4.7GB | `ollama run llama3.1`            |\n| Llama 3.1          | 405B       | 231GB | `ollama run llama3.1:405b`       |\n| Phi 4              | 14B        | 9.1GB | `ollama run phi4`                |\n| Phi 3 Mini         | 3.8B       | 2.3GB | `ollama run phi3`                |\n| Gemma 2            | 2B         | 1.6GB | `ollama run gemma2:2b`           |\n| Gemma 2            | 9B         | 5.5GB | `ollama run gemma2`              |\n| Gemma 2            | 27B        | 16GB  | `ollama run gemma2:27b`          |\n| Mistral            | 7B         | 4.1GB | `ollama run mistral`             |\n| Moondream 2        | 1.4B       | 829MB | `ollama run moondream`           |\n| Neural Chat        | 7B         | 4.1GB | `ollama run neural-chat`         |\n| Starling           | 7B         | 4.1GB | `ollama run starling-lm`         |\n| Code Llama         | 7B         | 3.8GB | `ollama run codellama`           |\n| Llama 2 Uncensored | 7B         | 3.8GB | `ollama run llama2-uncensored`   |\n| LLaVA              | 7B         | 4.5GB | `ollama run llava`               |\n| Solar              | 10.7B      | 6.1GB | `ollama run solar`               |\n\n> [!NOTE]\n> You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.\n\n## Customize a model\n\n### Import from GGUF\n\nOllama supports importing GGUF models in the Modelfile:\n\n1. Create a file named `Modelfile`, with a `FROM` instruction with the local filepath to the model you want to import.\n\n   ```\n   FROM ./vicuna-33b.Q4_0.gguf\n   ```\n\n2. Create the model in Ollama\n\n   ```\n   ollama create example -f Modelfile\n   ```\n\n3. Run the model\n\n   ```\n   ollama run example\n   ```\n\n### Import from Safetensors\n\nSee the [guide](docs/import.md) on importing models for more information.\n\n### Customize a prompt\n\nModels from the Ollama library can be customized with a prompt. For example, to customize the `llama3.2` model:\n\n```\nollama pull llama3.2\n```\n\nCreate a `Modelfile`:\n\n```\nFROM llama3.2\n\n# set the temperature to 1 [higher is more creative, lower is more coherent]\nPARAMETER temperature 1\n\n# set the system message\nSYSTEM \"\"\"\nYou are Mario from Super Mario Bros. Answer as Mario, the assistant, only.\n\"\"\"\n```\n\nNext, create and run the model:\n\n```\nollama create mario -f ./Modelfile\nollama run mario\n>>> hi\nHello! It's your friend Mario.\n```\n\nFor more examples, see the [examples](examples) directory. For more information on working with a Modelfile, see the [Modelfile](docs/modelfile.md) documentation.\n\n## CLI Reference\n\n### Create a model\n\n`ollama create` is used to create a model from a Modelfile.\n\n```\nollama create mymodel -f ./Modelfile\n```\n\n### Pull a model\n\n```\nollama pull llama3.2\n```\n\n> This command can also be used to update a local model. Only the diff will be pulled.\n\n### Remove a model\n\n```\nollama rm llama3.2\n```\n\n### Copy a model\n\n```\nollama cp llama3.2 my-model\n```\n\n### Multiline input\n\nFor multiline input, you can wrap text with `\"\"\"`:\n\n```\n>>> \"\"\"Hello,\n... world!\n... \"\"\"\nI'm a basic program that prints the famous \"Hello, world!\" message to the console.\n```\n\n### Multimodal models\n\n```\nollama run llava \"What's in this image? /Users/jmorgan/Desktop/smile.png\"\nThe image features a yellow smiley face, which is likely the central focus of the picture.\n```\n\n### Pass the prompt as an argument\n\n```\n$ ollama run llama3.2 \"Summarize this file: $(cat README.md)\"\n Ollama is a lightweight, extensible framework for building and running language models on the local machine. It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.\n```\n\n### Show model information\n\n```\nollama show llama3.2\n```\n\n### List models on your computer\n\n```\nollama list\n```\n\n### List which models are currently loaded\n\n```\nollama ps\n```\n\n### Stop a model which is currently running\n\n```\nollama stop llama3.2\n```\n\n### Start Ollama\n\n`ollama serve` is used when you want to start ollama without running the desktop application.\n\n## Building\n\nSee the [developer guide](https://github.com/ollama/ollama/blob/main/docs/development.md)\n\n### Running local builds\n\nNext, start the server:\n\n```\n./ollama serve\n```\n\nFinally, in a separate shell, run a model:\n\n```\n./ollama run llama3.2\n```\n\n## REST API\n\nOllama has a REST API for running and managing models.\n\n### Generate a response\n\n```\ncurl http://localhost:11434/api/generate -d '{\n  \"model\": \"llama3.2\",\n  \"prompt\":\"Why is the sky blue?\"\n}'\n```\n\n### Chat with a model\n\n```\ncurl http://localhost:11434/api/chat -d '{\n  \"model\": \"llama3.2\",\n  \"messages\": [\n    { \"role\": \"user\", \"content\": \"why is the sky blue?\" }\n  ]\n}'\n```\n\nSee the [API documentation](./docs/api.md) for all endpoints.\n\n## Community Integrations\n\n### Web & Desktop\n\n- [Open WebUI](https://github.com/open-webui/open-webui)\n- [Enchanted (macOS native)](https://github.com/AugustDev/enchanted)\n- [Hollama](https://github.com/fmaclen/hollama)\n- [Lollms-Webui](https://github.com/ParisNeo/lollms-webui)\n- [LibreChat](https://github.com/danny-avila/LibreChat)\n- [Bionic GPT](https://github.com/bionic-gpt/bionic-gpt)\n- [HTML UI](https://github.com/rtcfirefly/ollama-ui)\n- [Saddle](https://github.com/jikkuatwork/saddle)\n- [Chatbot UI](https://github.com/ivanfioravanti/chatbot-ollama)\n- [Chatbot UI v2](https://github.com/mckaywrigley/chatbot-ui)\n- [Typescript UI](https://github.com/ollama-interface/Ollama-Gui?tab=readme-ov-file)\n- [Minimalistic React UI for Ollama Models](https://github.com/richawo/minimal-llm-ui)\n- [Ollamac](https://github.com/kevinhermawan/Ollamac)\n- [big-AGI](https://github.com/enricoros/big-AGI/blob/main/docs/config-local-ollama.md)\n- [Cheshire Cat assistant framework](https://github.com/cheshire-cat-ai/core)\n- [Amica](https://github.com/semperai/amica)\n- [chatd](https://github.com/BruceMacD/chatd)\n- [Ollama-SwiftUI](https://github.com/kghandour/Ollama-SwiftUI)\n- [Dify.AI](https://github.com/langgenius/dify)\n- [MindMac](https://mindmac.app)\n- [NextJS Web Interface for Ollama](https://github.com/jakobhoeg/nextjs-ollama-llm-ui)\n- [Msty](https://msty.app)\n- [Chatbox](https://github.com/Bin-Huang/Chatbox)\n- [WinForm Ollama Copilot](https://github.com/tgraupmann/WinForm_Ollama_Copilot)\n- [NextChat](https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web) with [Get Started Doc](https://docs.nextchat.dev/models/ollama)\n- [Alpaca WebUI](https://github.com/mmo80/alpaca-webui)\n- [OllamaGUI](https://github.com/enoch1118/ollamaGUI)\n- [OpenAOE](https://github.com/InternLM/OpenAOE)\n- [Odin Runes](https://github.com/leonid20000/OdinRunes)\n- [LLM-X](https://github.com/mrdjohnson/llm-x) (Progressive Web App)\n- [AnythingLLM (Docker + MacOs/Windows/Linux native app)](https://github.com/Mintplex-Labs/anything-llm)\n- [Ollama Basic Chat: Uses HyperDiv Reactive UI](https://github.com/rapidarchitect/ollama_basic_chat)\n- [Ollama-chats RPG](https://github.com/drazdra/ollama-chats)\n- [IntelliBar](https://intellibar.app/) (AI-powered assistant for macOS)\n- [QA-Pilot](https://github.com/reid41/QA-Pilot) (Interactive chat tool that can leverage Ollama models for rapid understanding and navigation of GitHub code repositories)\n- [ChatOllama](https://github.com/sugarforever/chat-ollama) (Open Source Chatbot based on Ollama with Knowledge Bases)\n- [CRAG Ollama Chat](https://github.com/Nagi-ovo/CRAG-Ollama-Chat) (Simple Web Search with Corrective RAG)\n- [RAGFlow](https://github.com/infiniflow/ragflow) (Open-source Retrieval-Augmented Generation engine based on deep document understanding)\n- [StreamDeploy](https://github.com/StreamDeploy-DevRel/streamdeploy-llm-app-scaffold) (LLM Application Scaffold)\n- [chat](https://github.com/swuecho/chat) (chat web app for teams)\n- [Lobe Chat](https://github.com/lobehub/lobe-chat) with [Integrating Doc](https://lobehub.com/docs/self-hosting/examples/ollama)\n- [Ollama RAG Chatbot](https://github.com/datvodinh/rag-chatbot.git) (Local Chat with multiple PDFs using Ollama and RAG)\n- [BrainSoup](https://www.nurgo-software.com/products/brainsoup) (Flexible native client with RAG & multi-agent automation)\n- [macai](https://github.com/Renset/macai) (macOS client for Ollama, ChatGPT, and other compatible API back-ends)\n- [RWKV-Runner](https://github.com/josStorer/RWKV-Runner) (RWKV offline LLM deployment tool, also usable as a client for ChatGPT and Ollama)\n- [Ollama Grid Search](https://github.com/dezoito/ollama-grid-search) (app to evaluate and compare models)\n- [Olpaka](https://github.com/Otacon/olpaka) (User-friendly Flutter Web App for Ollama)\n- [OllamaSpring](https://github.com/CrazyNeil/OllamaSpring) (Ollama Client for macOS)\n- [LLocal.in](https://github.com/kartikm7/llocal) (Easy to use Electron Desktop Client for Ollama)\n- [Shinkai Desktop](https://github.com/dcSpark/shinkai-apps) (Two click install Local AI using Ollama + Files + RAG)\n- [AiLama](https://github.com/zeyoyt/ailama) (A Discord User App that allows you to interact with Ollama anywhere in discord )\n- [Ollama with Google Mesop](https://github.com/rapidarchitect/ollama_mesop/) (Mesop Chat Client implementation with Ollama)\n- [R2R](https://github.com/SciPhi-AI/R2R) (Open-source RAG engine)\n- [Ollama-Kis](https://github.com/elearningshow/ollama-kis) (A simple easy to use GUI with sample custom LLM for Drivers Education)\n- [OpenGPA](https://opengpa.org) (Open-source offline-first Enterprise Agentic Application)\n- [Painting Droid](https://github.com/mateuszmigas/painting-droid) (Painting app with AI integrations)\n- [Kerlig AI](https://www.kerlig.com/) (AI writing assistant for macOS)\n- [AI Studio](https://github.com/MindWorkAI/AI-Studio)\n- [Sidellama](https://github.com/gyopak/sidellama) (browser-based LLM client)\n- [LLMStack](https://github.com/trypromptly/LLMStack) (No-code multi-agent framework to build LLM agents and workflows)\n- [BoltAI for Mac](https://boltai.com) (AI Chat Client for Mac)\n- [Harbor](https://github.com/av/harbor) (Containerized LLM Toolkit with Ollama as default backend)\n- [PyGPT](https://github.com/szczyglis-dev/py-gpt) (AI desktop assistant for Linux, Windows and Mac)\n- [Alpaca](https://github.com/Jeffser/Alpaca) (An Ollama client application for linux and macos made with GTK4 and Adwaita)\n- [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT/blob/master/docs/content/platform/ollama.md) (AutoGPT Ollama integration)\n- [Go-CREW](https://www.jonathanhecl.com/go-crew/) (Powerful Offline RAG in Golang)\n- [PartCAD](https://github.com/openvmp/partcad/) (CAD model generation with OpenSCAD and CadQuery)\n- [Ollama4j Web UI](https://github.com/ollama4j/ollama4j-web-ui) - Java-based Web UI for Ollama built with Vaadin, Spring Boot and Ollama4j\n- [PyOllaMx](https://github.com/kspviswa/pyOllaMx) - macOS application capable of chatting with both Ollama and Apple MLX models.\n- [Claude Dev](https://github.com/saoudrizwan/claude-dev) - VSCode extension for multi-file/whole-repo coding\n- [Cherry Studio](https://github.com/kangfenmao/cherry-studio) (Desktop client with Ollama support)\n- [ConfiChat](https://github.com/1runeberg/confichat) (Lightweight, standalone, multi-platform, and privacy focused LLM chat interface with optional encryption)\n- [Archyve](https://github.com/nickthecook/archyve) (RAG-enabling document library)\n- [crewAI with Mesop](https://github.com/rapidarchitect/ollama-crew-mesop) (Mesop Web Interface to run crewAI with Ollama)\n- [Tkinter-based client](https://github.com/chyok/ollama-gui) (Python tkinter-based Client for Ollama)\n- [LLMChat](https://github.com/trendy-design/llmchat) (Privacy focused, 100% local, intuitive all-in-one chat interface)\n- [Local Multimodal AI Chat](https://github.com/Leon-Sander/Local-Multimodal-AI-Chat) (Ollama-based LLM Chat with support for multiple features, including PDF RAG, voice chat, image-based interactions, and integration with OpenAI.)\n- [ARGO](https://github.com/xark-argo/argo) (Locally download and run Ollama and Huggingface models with RAG on Mac/Windows/Linux)\n- [OrionChat](https://github.com/EliasPereirah/OrionChat) - OrionChat is a web interface for chatting with different AI providers\n- [G1](https://github.com/bklieger-groq/g1) (Prototype of using prompting strategies to improve the LLM's reasoning through o1-like reasoning chains.)\n- [Web management](https://github.com/lemonit-eric-mao/ollama-web-management) (Web management page)\n- [Promptery](https://github.com/promptery/promptery) (desktop client for Ollama.)\n- [Ollama App](https://github.com/JHubi1/ollama-app) (Modern and easy-to-use multi-platform client for Ollama)\n- [SpaceLlama](https://github.com/tcsenpai/spacellama) (Firefox and Chrome extension to quickly summarize web pages with ollama in a sidebar)\n- [YouLama](https://github.com/tcsenpai/youlama) (Webapp to quickly summarize any YouTube video, supporting Invidious as well)\n- [DualMind](https://github.com/tcsenpai/dualmind) (Experimental app allowing two models to talk to each other in the terminal or in a web interface)\n- [ollamarama-matrix](https://github.com/h1ddenpr0cess20/ollamarama-matrix) (Ollama chatbot for the Matrix chat protocol)\n- [ollama-chat-app](https://github.com/anan1213095357/ollama-chat-app) (Flutter-based chat app)\n- [Perfect Memory AI](https://www.perfectmemory.ai/) (Productivity AI assists personalized by what you have seen on your screen, heard and said in the meetings)\n- [Hexabot](https://github.com/hexastack/hexabot) (A conversational AI builder)\n- [Reddit Rate](https://github.com/rapidarchitect/reddit_analyzer) (Search and Rate Reddit topics with a weighted summation)\n- [OpenTalkGpt](https://github.com/adarshM84/OpenTalkGpt) (Chrome Extension to manage open-source models supported by Ollama, create custom models, and chat with models from a user-friendly UI)\n- [VT](https://github.com/vinhnx/vt.ai) (A minimal multimodal AI chat app, with dynamic conversation routing. Supports local models via Ollama)\n- [Nosia](https://github.com/nosia-ai/nosia) (Easy to install and use RAG platform based on Ollama)\n- [Witsy](https://github.com/nbonamy/witsy) (An AI Desktop application available for Mac/Windows/Linux)\n- [Abbey](https://github.com/US-Artificial-Intelligence/abbey) (A configurable AI interface server with notebooks, document storage, and YouTube support)\n- [Minima](https://github.com/dmayboroda/minima) (RAG with on-premises or fully local workflow)\n- [aidful-ollama-model-delete](https://github.com/AidfulAI/aidful-ollama-model-delete) (User interface for simplified model cleanup)\n- [Perplexica](https://github.com/ItzCrazyKns/Perplexica) (An AI-powered search engine & an open-source alternative to Perplexity AI)\n\n### Cloud\n\n- [Google Cloud](https://cloud.google.com/run/docs/tutorials/gpu-gemma2-with-ollama)\n- [Fly.io](https://fly.io/docs/python/do-more/add-ollama/)\n- [Koyeb](https://www.koyeb.com/deploy/ollama)\n\n### Terminal\n\n- [oterm](https://github.com/ggozad/oterm)\n- [Ellama Emacs client](https://github.com/s-kostyaev/ellama)\n- [Emacs client](https://github.com/zweifisch/ollama)\n- [neollama](https://github.com/paradoxical-dev/neollama) UI client for interacting with models from within Neovim\n- [gen.nvim](https://github.com/David-Kunz/gen.nvim)\n- [ollama.nvim](https://github.com/nomnivore/ollama.nvim)\n- [ollero.nvim](https://github.com/marco-souza/ollero.nvim)\n- [ollama-chat.nvim](https://github.com/gerazov/ollama-chat.nvim)\n- [ogpt.nvim](https://github.com/huynle/ogpt.nvim)\n- [gptel Emacs client](https://github.com/karthink/gptel)\n- [Oatmeal](https://github.com/dustinblackman/oatmeal)\n- [cmdh](https://github.com/pgibler/cmdh)\n- [ooo](https://github.com/npahlfer/ooo)\n- [shell-pilot](https://github.com/reid41/shell-pilot)(Interact with models via pure shell scripts on Linux or macOS)\n- [tenere](https://github.com/pythops/tenere)\n- [llm-ollama](https://github.com/taketwo/llm-ollama) for [Datasette's LLM CLI](https://llm.datasette.io/en/stable/).\n- [typechat-cli](https://github.com/anaisbetts/typechat-cli)\n- [ShellOracle](https://github.com/djcopley/ShellOracle)\n- [tlm](https://github.com/yusufcanb/tlm)\n- [podman-ollama](https://github.com/ericcurtin/podman-ollama)\n- [gollama](https://github.com/sammcj/gollama)\n- [ParLlama](https://github.com/paulrobello/parllama)\n- [Ollama eBook Summary](https://github.com/cognitivetech/ollama-ebook-summary/)\n- [Ollama Mixture of Experts (MOE) in 50 lines of code](https://github.com/rapidarchitect/ollama_moe)\n- [vim-intelligence-bridge](https://github.com/pepo-ec/vim-intelligence-bridge) Simple interaction of \"Ollama\" with the Vim editor\n- [x-cmd ollama](https://x-cmd.com/mod/ollama)\n- [bb7](https://github.com/drunkwcodes/bb7)\n- [SwollamaCLI](https://github.com/marcusziade/Swollama) bundled with the Swollama Swift package. [Demo](https://github.com/marcusziade/Swollama?tab=readme-ov-file#cli-usage)\n- [aichat](https://github.com/sigoden/aichat) All-in-one LLM CLI tool featuring Shell Assistant, Chat-REPL, RAG, AI tools & agents, with access to OpenAI, Claude, Gemini, Ollama, Groq, and more.\n- [PowershAI](https://github.com/rrg92/powershai) PowerShell module that brings AI to terminal on Windows, including support for Ollama\n- [orbiton](https://github.com/xyproto/orbiton) Configuration-free text editor and IDE with support for tab completion with Ollama.\n\n### Apple Vision Pro\n\n- [Enchanted](https://github.com/AugustDev/enchanted)\n\n### Database\n\n- [pgai](https://github.com/timescale/pgai) - PostgreSQL as a vector database (Create and search embeddings from Ollama models using pgvector)\n   - [Get started guide](https://github.com/timescale/pgai/blob/main/docs/vectorizer-quick-start.md)\n- [MindsDB](https://github.com/mindsdb/mindsdb/blob/staging/mindsdb/integrations/handlers/ollama_handler/README.md) (Connects Ollama models with nearly 200 data platforms and apps)\n- [chromem-go](https://github.com/philippgille/chromem-go/blob/v0.5.0/embed_ollama.go) with [example](https://github.com/philippgille/chromem-go/tree/v0.5.0/examples/rag-wikipedia-ollama)\n- [Kangaroo](https://github.com/dbkangaroo/kangaroo) (AI-powered SQL client and admin tool for popular databases)\n\n### Package managers\n\n- [Pacman](https://archlinux.org/packages/extra/x86_64/ollama/)\n- [Gentoo](https://github.com/gentoo/guru/tree/master/app-misc/ollama)\n- [Helm Chart](https://artifacthub.io/packages/helm/ollama-helm/ollama)\n- [Guix channel](https://codeberg.org/tusharhero/ollama-guix)\n- [Nix package](https://search.nixos.org/packages?channel=24.05&show=ollama&from=0&size=50&sort=relevance&type=packages&query=ollama)\n- [Flox](https://flox.dev/blog/ollama-part-one)\n\n### Libraries\n\n- [LangChain](https://python.langchain.com/docs/integrations/llms/ollama) and [LangChain.js](https://js.langchain.com/docs/integrations/chat/ollama/) with [example](https://js.langchain.com/docs/tutorials/local_rag/)\n- [Firebase Genkit](https://firebase.google.com/docs/genkit/plugins/ollama)\n- [crewAI](https://github.com/crewAIInc/crewAI)\n- [Yacana](https://remembersoftwares.github.io/yacana/) (User-friendly multi-agent framework for brainstorming and executing predetermined flows with built-in tool integration)\n- [Spring AI](https://github.com/spring-projects/spring-ai) with [reference](https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html) and [example](https://github.com/tzolov/ollama-tools)\n- [LangChainGo](https://github.com/tmc/langchaingo/) with [example](https://github.com/tmc/langchaingo/tree/main/examples/ollama-completion-example)\n- [LangChain4j](https://github.com/langchain4j/langchain4j) with [example](https://github.com/langchain4j/langchain4j-examples/tree/main/ollama-examples/src/main/java)\n- [LangChainRust](https://github.com/Abraxas-365/langchain-rust) with [example](https://github.com/Abraxas-365/langchain-rust/blob/main/examples/llm_ollama.rs)\n- [LLPhant](https://github.com/theodo-group/LLPhant?tab=readme-ov-file#ollama)\n- [LlamaIndex](https://docs.llamaindex.ai/en/stable/examples/llm/ollama/) and [LlamaIndexTS](https://ts.llamaindex.ai/modules/llms/available_llms/ollama)\n- [LiteLLM](https://github.com/BerriAI/litellm)\n- [OllamaFarm for Go](https://github.com/presbrey/ollamafarm)\n- [OllamaSharp for .NET](https://github.com/awaescher/OllamaSharp)\n- [Ollama for Ruby](https://github.com/gbaptista/ollama-ai)\n- [Ollama-rs for Rust](https://github.com/pepperoni21/ollama-rs)\n- [Ollama-hpp for C++](https://github.com/jmont-dev/ollama-hpp)\n- [Ollama4j for Java](https://github.com/ollama4j/ollama4j)\n- [ModelFusion Typescript Library](https://modelfusion.dev/integration/model-provider/ollama)\n- [OllamaKit for Swift](https://github.com/kevinhermawan/OllamaKit)\n- [Ollama for Dart](https://github.com/breitburg/dart-ollama)\n- [Ollama for Laravel](https://github.com/cloudstudio/ollama-laravel)\n- [LangChainDart](https://github.com/davidmigloz/langchain_dart)\n- [Semantic Kernel - Python](https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/ai/ollama)\n- [Haystack](https://github.com/deepset-ai/haystack-integrations/blob/main/integrations/ollama.md)\n- [Elixir LangChain](https://github.com/brainlid/langchain)\n- [Ollama for R - rollama](https://github.com/JBGruber/rollama)\n- [Ollama for R - ollama-r](https://github.com/hauselin/ollama-r)\n- [Ollama-ex for Elixir](https://github.com/lebrunel/ollama-ex)\n- [Ollama Connector for SAP ABAP](https://github.com/b-tocs/abap_btocs_ollama)\n- [Testcontainers](https://testcontainers.com/modules/ollama/)\n- [Portkey](https://portkey.ai/docs/welcome/integration-guides/ollama)\n- [PromptingTools.jl](https://github.com/svilupp/PromptingTools.jl) with an [example](https://svilupp.github.io/PromptingTools.jl/dev/examples/working_with_ollama)\n- [LlamaScript](https://github.com/Project-Llama/llamascript)\n- [llm-axe](https://github.com/emirsahin1/llm-axe) (Python Toolkit for Building LLM Powered Apps)\n- [Gollm](https://docs.gollm.co/examples/ollama-example)\n- [Gollama for Golang](https://github.com/jonathanhecl/gollama)\n- [Ollamaclient for Golang](https://github.com/xyproto/ollamaclient)\n- [High-level function abstraction in Go](https://gitlab.com/tozd/go/fun)\n- [Ollama PHP](https://github.com/ArdaGnsrn/ollama-php)\n- [Agents-Flex for Java](https://github.com/agents-flex/agents-flex) with [example](https://github.com/agents-flex/agents-flex/tree/main/agents-flex-llm/agents-flex-llm-ollama/src/test/java/com/agentsflex/llm/ollama)\n- [Parakeet](https://github.com/parakeet-nest/parakeet) is a GoLang library, made to simplify the development of small generative AI applications with Ollama.\n- [Haverscript](https://github.com/andygill/haverscript) with [examples](https://github.com/andygill/haverscript/tree/main/examples)\n- [Ollama for Swift](https://github.com/mattt/ollama-swift)\n- [Swollama for Swift](https://github.com/marcusziade/Swollama) with [DocC](https://marcusziade.github.io/Swollama/documentation/swollama/)\n- [GoLamify](https://github.com/prasad89/golamify)\n- [Ollama for Haskell](https://github.com/tusharad/ollama-haskell)\n- [multi-llm-ts](https://github.com/nbonamy/multi-llm-ts) (A Typescript/JavaScript library allowing access to different LLM in unified API)\n\n### Mobile\n\n- [Enchanted](https://github.com/AugustDev/enchanted)\n- [Maid](https://github.com/Mobile-Artificial-Intelligence/maid)\n- [Ollama App](https://github.com/JHubi1/ollama-app) (Modern and easy-to-use multi-platform client for Ollama)\n- [ConfiChat](https://github.com/1runeberg/confichat) (Lightweight, standalone, multi-platform, and privacy focused LLM chat interface with optional encryption)\n\n### Extensions & Plugins\n\n- [Raycast extension](https://github.com/MassimilianoPasquini97/raycast_ollama)\n- [Discollama](https://github.com/mxyng/discollama) (Discord bot inside the Ollama discord channel)\n- [Continue](https://github.com/continuedev/continue)\n- [Vibe](https://github.com/thewh1teagle/vibe) (Transcribe and analyze meetings with Ollama)\n- [Obsidian Ollama plugin](https://github.com/hinterdupfinger/obsidian-ollama)\n- [Logseq Ollama plugin](https://github.com/omagdy7/ollama-logseq)\n- [NotesOllama](https://github.com/andersrex/notesollama) (Apple Notes Ollama plugin)\n- [Dagger Chatbot](https://github.com/samalba/dagger-chatbot)\n- [Discord AI Bot](https://github.com/mekb-turtle/discord-ai-bot)\n- [Ollama Telegram Bot](https://github.com/ruecat/ollama-telegram)\n- [Hass Ollama Conversation](https://github.com/ej52/hass-ollama-conversation)\n- [Rivet plugin](https://github.com/abrenneke/rivet-plugin-ollama)\n- [Obsidian BMO Chatbot plugin](https://github.com/longy2k/obsidian-bmo-chatbot)\n- [Cliobot](https://github.com/herval/cliobot) (Telegram bot with Ollama support)\n- [Copilot for Obsidian plugin](https://github.com/logancyang/obsidian-copilot)\n- [Obsidian Local GPT plugin](https://github.com/pfrankov/obsidian-local-gpt)\n- [Open Interpreter](https://docs.openinterpreter.com/language-model-setup/local-models/ollama)\n- [Llama Coder](https://github.com/ex3ndr/llama-coder) (Copilot alternative using Ollama)\n- [Ollama Copilot](https://github.com/bernardo-bruning/ollama-copilot) (Proxy that allows you to use ollama as a copilot like Github copilot)\n- [twinny](https://github.com/rjmacarthy/twinny) (Copilot and Copilot chat alternative using Ollama)\n- [Wingman-AI](https://github.com/RussellCanfield/wingman-ai) (Copilot code and chat alternative using Ollama and Hugging Face)\n- [Page Assist](https://github.com/n4ze3m/page-assist) (Chrome Extension)\n- [Plasmoid Ollama Control](https://github.com/imoize/plasmoid-ollamacontrol) (KDE Plasma extension that allows you to quickly manage/control Ollama model)\n- [AI Telegram Bot](https://github.com/tusharhero/aitelegrambot) (Telegram bot using Ollama in backend)\n- [AI ST Completion](https://github.com/yaroslavyaroslav/OpenAI-sublime-text) (Sublime Text 4 AI assistant plugin with Ollama support)\n- [Discord-Ollama Chat Bot](https://github.com/kevinthedang/discord-ollama) (Generalized TypeScript Discord Bot w/ Tuning Documentation)\n- [ChatGPTBox: All in one browser extension](https://github.com/josStorer/chatGPTBox) with [Integrating Tutorial](https://github.com/josStorer/chatGPTBox/issues/616#issuecomment-1975186467)\n- [Discord AI chat/moderation bot](https://github.com/rapmd73/Companion) Chat/moderation bot written in python. Uses Ollama to create personalities.\n- [Headless Ollama](https://github.com/nischalj10/headless-ollama) (Scripts to automatically install ollama client & models on any OS for apps that depends on ollama server)\n- [Terraform AWS Ollama & Open WebUI](https://github.com/xuyangbocn/terraform-aws-self-host-llm) (A Terraform module to deploy on AWS a ready-to-use Ollama service, together with its front end Open WebUI service.)\n- [node-red-contrib-ollama](https://github.com/jakubburkiewicz/node-red-contrib-ollama)\n- [Local AI Helper](https://github.com/ivostoykov/localAI) (Chrome and Firefox extensions that enable interactions with the active tab and customisable API endpoints. Includes secure storage for user prompts.)\n- [vnc-lm](https://github.com/jake83741/vnc-lm) (Discord bot for messaging with LLMs through Ollama and LiteLLM. Seamlessly move between local and flagship models.)\n- [LSP-AI](https://github.com/SilasMarvin/lsp-ai) (Open-source language server for AI-powered functionality)\n- [QodeAssist](https://github.com/Palm1r/QodeAssist) (AI-powered coding assistant plugin for Qt Creator)\n- [Obsidian Quiz Generator plugin](https://github.com/ECuiDev/obsidian-quiz-generator)\n- [AI Summmary Helper plugin](https://github.com/philffm/ai-summary-helper)\n- [TextCraft](https://github.com/suncloudsmoon/TextCraft) (Copilot in Word alternative using Ollama)\n- [Alfred Ollama](https://github.com/zeitlings/alfred-ollama) (Alfred Workflow)\n- [TextLLaMA](https://github.com/adarshM84/TextLLaMA) A Chrome Extension that helps you write emails, correct grammar, and translate into any language\n\n### Supported backends\n\n- [llama.cpp](https://github.com/ggerganov/llama.cpp) project founded by Georgi Gerganov.\n\n### Observability\n\n- [OpenLIT](https://github.com/openlit/openlit) is an OpenTelemetry-native tool for monitoring Ollama Applications & GPUs using traces and metrics.\n- [HoneyHive](https://docs.honeyhive.ai/integrations/ollama) is an AI observability and evaluation platform for AI agents. Use HoneyHive to evaluate agent performance, interrogate failures, and monitor quality in production. \n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.9814453125,
          "content": "# Security\n\nThe Ollama maintainer team takes security seriously and will actively work to resolve security issues.\n\n## Reporting a vulnerability\n\nIf you discover a security vulnerability, please do not open a public issue. Instead, please report it by emailing hello@ollama.com. We ask that you give us sufficient time to investigate and address the vulnerability before disclosing it publicly.\n\nPlease include the following details in your report:\n- A description of the vulnerability\n- Steps to reproduce the issue\n- Your assessment of the potential impact\n- Any possible mitigations\n\n## Security best practices\n\nWhile the maintainer team does their best to secure Ollama, users are encouraged to implement their own security best practices, such as:\n\n- Regularly updating to the latest version of Ollama\n- Securing access to hosted instances of Ollama\n- Monitoring systems for unusual activity\n\n## Contact\n\nFor any other questions or concerns related to security, please contact us at hello@ollama.com\n"
        },
        {
          "name": "api",
          "type": "tree",
          "content": null
        },
        {
          "name": "app",
          "type": "tree",
          "content": null
        },
        {
          "name": "auth",
          "type": "tree",
          "content": null
        },
        {
          "name": "cmd",
          "type": "tree",
          "content": null
        },
        {
          "name": "convert",
          "type": "tree",
          "content": null
        },
        {
          "name": "discover",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "envconfig",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "format",
          "type": "tree",
          "content": null
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 2.9580078125,
          "content": "module github.com/ollama/ollama\n\ngo 1.23.4\n\nrequire (\n\tgithub.com/containerd/console v1.0.3\n\tgithub.com/gin-gonic/gin v1.10.0\n\tgithub.com/golang/protobuf v1.5.4 // indirect\n\tgithub.com/google/uuid v1.6.0\n\tgithub.com/olekukonko/tablewriter v0.0.5\n\tgithub.com/spf13/cobra v1.7.0\n\tgithub.com/stretchr/testify v1.9.0\n\tgithub.com/x448/float16 v0.8.4\n\tgolang.org/x/sync v0.10.0\n)\n\nrequire (\n\tgithub.com/agnivade/levenshtein v1.1.1\n\tgithub.com/d4l3k/go-bfloat16 v0.0.0-20211005043715-690c3bdd05f1\n\tgithub.com/emirpasic/gods/v2 v2.0.0-alpha\n\tgithub.com/google/go-cmp v0.6.0\n\tgithub.com/mattn/go-runewidth v0.0.14\n\tgithub.com/nlpodyssey/gopickle v0.3.0\n\tgithub.com/pdevine/tensor v0.0.0-20240510204454-f88f4562727c\n\tgolang.org/x/image v0.22.0\n)\n\nrequire (\n\tgithub.com/apache/arrow/go/arrow v0.0.0-20211112161151-bc219186db40 // indirect\n\tgithub.com/bytedance/sonic/loader v0.1.1 // indirect\n\tgithub.com/chewxy/hm v1.0.0 // indirect\n\tgithub.com/chewxy/math32 v1.11.0 // indirect\n\tgithub.com/cloudwego/base64x v0.1.4 // indirect\n\tgithub.com/cloudwego/iasm v0.2.0 // indirect\n\tgithub.com/davecgh/go-spew v1.1.1 // indirect\n\tgithub.com/gogo/protobuf v1.3.2 // indirect\n\tgithub.com/google/flatbuffers v24.3.25+incompatible // indirect\n\tgithub.com/kr/text v0.2.0 // indirect\n\tgithub.com/pkg/errors v0.9.1 // indirect\n\tgithub.com/pmezard/go-difflib v1.0.0 // indirect\n\tgithub.com/rivo/uniseg v0.2.0 // indirect\n\tgithub.com/xtgo/set v1.0.0 // indirect\n\tgo4.org/unsafe/assume-no-moving-gc v0.0.0-20231121144256-b99613f794b6 // indirect\n\tgolang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1 // indirect\n\tgonum.org/v1/gonum v0.15.0 // indirect\n\tgorgonia.org/vecf32 v0.9.0 // indirect\n\tgorgonia.org/vecf64 v0.9.0 // indirect\n)\n\nrequire (\n\tgithub.com/bytedance/sonic v1.11.6 // indirect\n\tgithub.com/gabriel-vasile/mimetype v1.4.3 // indirect\n\tgithub.com/gin-contrib/cors v1.7.2\n\tgithub.com/gin-contrib/sse v0.1.0 // indirect\n\tgithub.com/go-playground/locales v0.14.1 // indirect\n\tgithub.com/go-playground/universal-translator v0.18.1 // indirect\n\tgithub.com/go-playground/validator/v10 v10.20.0 // indirect\n\tgithub.com/goccy/go-json v0.10.2 // indirect\n\tgithub.com/inconshreveable/mousetrap v1.1.0 // indirect\n\tgithub.com/json-iterator/go v1.1.12 // indirect\n\tgithub.com/klauspost/cpuid/v2 v2.2.7 // indirect\n\tgithub.com/leodido/go-urn v1.4.0 // indirect\n\tgithub.com/mattn/go-isatty v0.0.20 // indirect\n\tgithub.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd // indirect\n\tgithub.com/modern-go/reflect2 v1.0.2 // indirect\n\tgithub.com/pelletier/go-toml/v2 v2.2.2 // indirect\n\tgithub.com/spf13/pflag v1.0.5 // indirect\n\tgithub.com/twitchyliquid64/golang-asm v0.15.1 // indirect\n\tgithub.com/ugorji/go/codec v1.2.12 // indirect\n\tgolang.org/x/arch v0.8.0 // indirect\n\tgolang.org/x/crypto v0.31.0\n\tgolang.org/x/exp v0.0.0-20231110203233-9a3e6036ecaa\n\tgolang.org/x/net v0.25.0 // indirect\n\tgolang.org/x/sys v0.28.0\n\tgolang.org/x/term v0.27.0\n\tgolang.org/x/text v0.21.0\n\tgoogle.golang.org/protobuf v1.34.1\n\tgopkg.in/yaml.v3 v3.0.1 // indirect\n)\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 34.359375,
          "content": "cloud.google.com/go v0.26.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=\ncloud.google.com/go v0.34.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=\ndmitri.shuralyov.com/gpu/mtl v0.0.0-20190408044501-666a987793e9/go.mod h1:H6x//7gZCb22OMCxBHrMx7a5I7Hp++hsVxbQ4BYO7hU=\ngioui.org v0.0.0-20210308172011-57750fc8a0a6/go.mod h1:RSH6KIUZ0p2xy5zHDxgAM4zumjgTw83q2ge/PI+yyw8=\ngithub.com/BurntSushi/toml v0.3.1/go.mod h1:xHWCNGjB5oqiDr8zfno3MHue2Ht5sIBksp03qcyfWMU=\ngithub.com/BurntSushi/xgb v0.0.0-20160522181843-27f122750802/go.mod h1:IVnqGOEym/WlBOVXweHU+Q+/VP0lqqI8lqeDx9IjBqo=\ngithub.com/agnivade/levenshtein v1.1.1 h1:QY8M92nrzkmr798gCo3kmMyqXFzdQVpxLlGPRBij0P8=\ngithub.com/agnivade/levenshtein v1.1.1/go.mod h1:veldBMzWxcCG2ZvUTKD2kJNRdCk5hVbJomOvKkmgYbo=\ngithub.com/ajstarks/svgo v0.0.0-20180226025133-644b8db467af/go.mod h1:K08gAheRH3/J6wwsYMMT4xOr94bZjxIelGM0+d/wbFw=\ngithub.com/antihax/optional v1.0.0/go.mod h1:uupD/76wgC+ih3iEmQUL+0Ugr19nfwCT1kdvxnR2qWY=\ngithub.com/apache/arrow/go/arrow v0.0.0-20211112161151-bc219186db40 h1:q4dksr6ICHXqG5hm0ZW5IHyeEJXoIJSOZeBLmWPNeIQ=\ngithub.com/apache/arrow/go/arrow v0.0.0-20211112161151-bc219186db40/go.mod h1:Q7yQnSMnLvcXlZ8RV+jwz/6y1rQTqbX6C82SndT52Zs=\ngithub.com/arbovm/levenshtein v0.0.0-20160628152529-48b4e1c0c4d0 h1:jfIu9sQUG6Ig+0+Ap1h4unLjW6YQJpKZVmUzxsD4E/Q=\ngithub.com/arbovm/levenshtein v0.0.0-20160628152529-48b4e1c0c4d0/go.mod h1:t2tdKJDJF9BV14lnkjHmOQgcvEKgtqs5a1N3LNdJhGE=\ngithub.com/boombuler/barcode v1.0.0/go.mod h1:paBWMcWSl3LHKBqUq+rly7CNSldXjb2rDl3JlRe0mD8=\ngithub.com/bytedance/sonic v1.11.6 h1:oUp34TzMlL+OY1OUWxHqsdkgC/Zfc85zGqw9siXjrc0=\ngithub.com/bytedance/sonic v1.11.6/go.mod h1:LysEHSvpvDySVdC2f87zGWf6CIKJcAvqab1ZaiQtds4=\ngithub.com/bytedance/sonic/loader v0.1.1 h1:c+e5Pt1k/cy5wMveRDyk2X4B9hF4g7an8N3zCYjJFNM=\ngithub.com/bytedance/sonic/loader v0.1.1/go.mod h1:ncP89zfokxS5LZrJxl5z0UJcsk4M4yY2JpfqGeCtNLU=\ngithub.com/census-instrumentation/opencensus-proto v0.2.1/go.mod h1:f6KPmirojxKA12rnyqOA5BBL4O983OfeGPqjHWSTneU=\ngithub.com/chewxy/hm v1.0.0 h1:zy/TSv3LV2nD3dwUEQL2VhXeoXbb9QkpmdRAVUFiA6k=\ngithub.com/chewxy/hm v1.0.0/go.mod h1:qg9YI4q6Fkj/whwHR1D+bOGeF7SniIP40VweVepLjg0=\ngithub.com/chewxy/math32 v1.0.0/go.mod h1:Miac6hA1ohdDUTagnvJy/q+aNnEk16qWUdb8ZVhvCN0=\ngithub.com/chewxy/math32 v1.11.0 h1:8sek2JWqeaKkVnHa7bPVqCEOUPbARo4SGxs6toKyAOo=\ngithub.com/chewxy/math32 v1.11.0/go.mod h1:dOB2rcuFrCn6UHrze36WSLVPKtzPMRAQvBvUwkSsLqs=\ngithub.com/client9/misspell v0.3.4/go.mod h1:qj6jICC3Q7zFZvVWo7KLAzC3yx5G7kyvSDkc90ppPyw=\ngithub.com/cloudwego/base64x v0.1.4 h1:jwCgWpFanWmN8xoIUHa2rtzmkd5J2plF/dnLS6Xd/0Y=\ngithub.com/cloudwego/base64x v0.1.4/go.mod h1:0zlkT4Wn5C6NdauXdJRhSKRlJvmclQ1hhJgA0rcu/8w=\ngithub.com/cloudwego/iasm v0.2.0 h1:1KNIy1I1H9hNNFEEH3DVnI4UujN+1zjpuk6gwHLTssg=\ngithub.com/cloudwego/iasm v0.2.0/go.mod h1:8rXZaNYT2n95jn+zTI1sDr+IgcD2GVs0nlbbQPiEFhY=\ngithub.com/cncf/udpa/go v0.0.0-20191209042840-269d4d468f6f/go.mod h1:M8M6+tZqaGXZJjfX53e64911xZQV5JYwmTeXPW+k8Sc=\ngithub.com/cncf/udpa/go v0.0.0-20201120205902-5459f2c99403/go.mod h1:WmhPx2Nbnhtbo57+VJT5O0JRkEi1Wbu0z5j0R8u5Hbk=\ngithub.com/cncf/xds/go v0.0.0-20210312221358-fbca930ec8ed/go.mod h1:eXthEFrGJvWHgFFCl3hGmgk+/aYT6PnTQLykKQRLhEs=\ngithub.com/containerd/console v1.0.3 h1:lIr7SlA5PxZyMV30bDW0MGbiOPXwc63yRuCP0ARubLw=\ngithub.com/containerd/console v1.0.3/go.mod h1:7LqA/THxQ86k76b8c/EMSiaJ3h1eZkMkXar0TQ1gf3U=\ngithub.com/cpuguy83/go-md2man/v2 v2.0.2/go.mod h1:tgQtvFlXSQOSOSIRvRPT7W67SCa46tRHOmNcaadrF8o=\ngithub.com/creack/pty v1.1.9/go.mod h1:oKZEueFk5CKHvIhNR5MUki03XCEU+Q6VDXinZuGJ33E=\ngithub.com/d4l3k/go-bfloat16 v0.0.0-20211005043715-690c3bdd05f1 h1:cBzrdJPAFBsgCrDPnZxlp1dF2+k4r1kVpD7+1S1PVjY=\ngithub.com/d4l3k/go-bfloat16 v0.0.0-20211005043715-690c3bdd05f1/go.mod h1:uw2gLcxEuYUlAd/EXyjc/v55nd3+47YAgWbSXVxPrNI=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/dgryski/trifles v0.0.0-20200323201526-dd97f9abfb48 h1:fRzb/w+pyskVMQ+UbP35JkH8yB7MYb4q/qhBarqZE6g=\ngithub.com/dgryski/trifles v0.0.0-20200323201526-dd97f9abfb48/go.mod h1:if7Fbed8SFyPtHLHbg49SI7NAdJiC5WIA09pe59rfAA=\ngithub.com/emirpasic/gods/v2 v2.0.0-alpha h1:dwFlh8pBg1VMOXWGipNMRt8v96dKAIvBehtCt6OtunU=\ngithub.com/emirpasic/gods/v2 v2.0.0-alpha/go.mod h1:W0y4M2dtBB9U5z3YlghmpuUhiaZT2h6yoeE+C1sCp6A=\ngithub.com/envoyproxy/go-control-plane v0.9.0/go.mod h1:YTl/9mNaCwkRvm6d1a2C3ymFceY/DCBVvsKhRF0iEA4=\ngithub.com/envoyproxy/go-control-plane v0.9.1-0.20191026205805-5f8ba28d4473/go.mod h1:YTl/9mNaCwkRvm6d1a2C3ymFceY/DCBVvsKhRF0iEA4=\ngithub.com/envoyproxy/go-control-plane v0.9.4/go.mod h1:6rpuAdCZL397s3pYoYcLgu1mIlRU8Am5FuJP05cCM98=\ngithub.com/envoyproxy/go-control-plane v0.9.9-0.20201210154907-fd9021fe5dad/go.mod h1:cXg6YxExXjJnVBQHBLXeUAgxn2UodCpnH306RInaBQk=\ngithub.com/envoyproxy/go-control-plane v0.9.9-0.20210217033140-668b12f5399d/go.mod h1:cXg6YxExXjJnVBQHBLXeUAgxn2UodCpnH306RInaBQk=\ngithub.com/envoyproxy/go-control-plane v0.9.9-0.20210512163311-63b5d3c536b0/go.mod h1:hliV/p42l8fGbc6Y9bQ70uLwIvmJyVE5k4iMKlh8wCQ=\ngithub.com/envoyproxy/protoc-gen-validate v0.1.0/go.mod h1:iSmxcyjqTsJpI2R4NaDN7+kN2VEUnK/pcBlmesArF7c=\ngithub.com/fogleman/gg v1.2.1-0.20190220221249-0403632d5b90/go.mod h1:R/bRT+9gY/C5z7JzPU0zXsXHKM4/ayA+zqcVNZzPa1k=\ngithub.com/fogleman/gg v1.3.0/go.mod h1:R/bRT+9gY/C5z7JzPU0zXsXHKM4/ayA+zqcVNZzPa1k=\ngithub.com/gabriel-vasile/mimetype v1.4.3 h1:in2uUcidCuFcDKtdcBxlR0rJ1+fsokWf+uqxgUFjbI0=\ngithub.com/gabriel-vasile/mimetype v1.4.3/go.mod h1:d8uq/6HKRL6CGdk+aubisF/M5GcPfT7nKyLpA0lbSSk=\ngithub.com/ghodss/yaml v1.0.0/go.mod h1:4dBDuWmgqj2HViK6kFavaiC9ZROes6MMH2rRYeMEF04=\ngithub.com/gin-contrib/cors v1.7.2 h1:oLDHxdg8W/XDoN/8zamqk/Drgt4oVZDvaV0YmvVICQw=\ngithub.com/gin-contrib/cors v1.7.2/go.mod h1:SUJVARKgQ40dmrzgXEVxj2m7Ig1v1qIboQkPDTQ9t2E=\ngithub.com/gin-contrib/sse v0.1.0 h1:Y/yl/+YNO8GZSjAhjMsSuLt29uWRFHdHYUb5lYOV9qE=\ngithub.com/gin-contrib/sse v0.1.0/go.mod h1:RHrZQHXnP2xjPF+u1gW/2HnVO7nvIa9PG3Gm+fLHvGI=\ngithub.com/gin-gonic/gin v1.10.0 h1:nTuyha1TYqgedzytsKYqna+DfLos46nTv2ygFy86HFU=\ngithub.com/gin-gonic/gin v1.10.0/go.mod h1:4PMNQiOhvDRa013RKVbsiNwoyezlm2rm0uX/T7kzp5Y=\ngithub.com/go-fonts/dejavu v0.1.0/go.mod h1:4Wt4I4OU2Nq9asgDCteaAaWZOV24E+0/Pwo0gppep4g=\ngithub.com/go-fonts/latin-modern v0.2.0/go.mod h1:rQVLdDMK+mK1xscDwsqM5J8U2jrRa3T0ecnM9pNujks=\ngithub.com/go-fonts/liberation v0.1.1/go.mod h1:K6qoJYypsmfVjWg8KOVDQhLc8UDgIK2HYqyqAO9z7GY=\ngithub.com/go-fonts/stix v0.1.0/go.mod h1:w/c1f0ldAUlJmLBvlbkvVXLAD+tAMqobIIQpmnUIzUY=\ngithub.com/go-gl/glfw v0.0.0-20190409004039-e6da0acd62b1/go.mod h1:vR7hzQXu2zJy9AVAgeJqvqgH9Q5CA+iKCZ2gyEVpxRU=\ngithub.com/go-latex/latex v0.0.0-20210118124228-b3d85cf34e07/go.mod h1:CO1AlKB2CSIqUrmQPqA0gdRIlnLEY0gK5JGjh37zN5U=\ngithub.com/go-playground/assert/v2 v2.2.0 h1:JvknZsQTYeFEAhQwI4qEt9cyV5ONwRHC+lYKSsYSR8s=\ngithub.com/go-playground/assert/v2 v2.2.0/go.mod h1:VDjEfimB/XKnb+ZQfWdccd7VUvScMdVu0Titje2rxJ4=\ngithub.com/go-playground/locales v0.14.1 h1:EWaQ/wswjilfKLTECiXz7Rh+3BjFhfDFKv/oXslEjJA=\ngithub.com/go-playground/locales v0.14.1/go.mod h1:hxrqLVvrK65+Rwrd5Fc6F2O76J/NuW9t0sjnWqG1slY=\ngithub.com/go-playground/universal-translator v0.18.1 h1:Bcnm0ZwsGyWbCzImXv+pAJnYK9S473LQFuzCbDbfSFY=\ngithub.com/go-playground/universal-translator v0.18.1/go.mod h1:xekY+UJKNuX9WP91TpwSH2VMlDf28Uj24BCp08ZFTUY=\ngithub.com/go-playground/validator/v10 v10.20.0 h1:K9ISHbSaI0lyB2eWMPJo+kOS/FBExVwjEviJTixqxL8=\ngithub.com/go-playground/validator/v10 v10.20.0/go.mod h1:dbuPbCMFw/DrkbEynArYaCwl3amGuJotoKCe95atGMM=\ngithub.com/goccy/go-json v0.10.2 h1:CrxCmQqYDkv1z7lO7Wbh2HN93uovUHgrECaO5ZrCXAU=\ngithub.com/goccy/go-json v0.10.2/go.mod h1:6MelG93GURQebXPDq3khkgXZkazVtN9CRI+MGFi0w8I=\ngithub.com/gogo/protobuf v1.3.2 h1:Ov1cvc58UF3b5XjBnZv7+opcTcQFZebYjWzi34vdm4Q=\ngithub.com/gogo/protobuf v1.3.2/go.mod h1:P1XiOD3dCwIKUDQYPy72D8LYyHL2YPYrpS2s69NZV8Q=\ngithub.com/golang/freetype v0.0.0-20170609003504-e2365dfdc4a0/go.mod h1:E/TSTwGwJL78qG/PmXZO1EjYhfJinVAhrmmHX6Z8B9k=\ngithub.com/golang/glog v0.0.0-20160126235308-23def4e6c14b/go.mod h1:SBH7ygxi8pfUlaOkMMuAQtPIUF8ecWP5IEl/CR7VP2Q=\ngithub.com/golang/mock v1.1.1/go.mod h1:oTYuIxOrZwtPieC+H1uAHpcLFnEyAGVDL/k47Jfbm0A=\ngithub.com/golang/protobuf v1.2.0/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.2/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.3/go.mod h1:vzj43D7+SQXF/4pzW/hwtAqwc6iTitCiVSaWz5lYuqw=\ngithub.com/golang/protobuf v1.4.0-rc.1/go.mod h1:ceaxUfeHdC40wWswd/P6IGgMaK3YpKi5j83Wpe3EHw8=\ngithub.com/golang/protobuf v1.4.0-rc.1.0.20200221234624-67d41d38c208/go.mod h1:xKAWHe0F5eneWXFV3EuXVDTCmh+JuBKY0li0aMyXATA=\ngithub.com/golang/protobuf v1.4.0-rc.2/go.mod h1:LlEzMj4AhA7rCAGe4KMBDvJI+AwstrUpVNzEA03Pprs=\ngithub.com/golang/protobuf v1.4.0-rc.4.0.20200313231945-b860323f09d0/go.mod h1:WU3c8KckQ9AFe+yFwt9sWVRKCVIyN9cPHBJSNnbL67w=\ngithub.com/golang/protobuf v1.4.0/go.mod h1:jodUvKwWbYaEsadDk5Fwe5c77LiNKVO9IDvqG2KuDX0=\ngithub.com/golang/protobuf v1.4.1/go.mod h1:U8fpvMrcmy5pZrNK1lt4xCsGvpyWQ/VVv6QDs8UjoX8=\ngithub.com/golang/protobuf v1.4.2/go.mod h1:oDoupMAO8OvCJWAcko0GGGIgR6R6ocIYbsSw735rRwI=\ngithub.com/golang/protobuf v1.4.3/go.mod h1:oDoupMAO8OvCJWAcko0GGGIgR6R6ocIYbsSw735rRwI=\ngithub.com/golang/protobuf v1.5.0/go.mod h1:FsONVRAS9T7sI+LIUmWTfcYkHO4aIWwzhcaSAoJOfIk=\ngithub.com/golang/protobuf v1.5.2/go.mod h1:XVQd3VNwM+JqD3oG2Ue2ip4fOMUkwXdXDdiuN0vRsmY=\ngithub.com/golang/protobuf v1.5.4 h1:i7eJL8qZTpSEXOPTxNKhASYpMn+8e5Q6AdndVa1dWek=\ngithub.com/golang/protobuf v1.5.4/go.mod h1:lnTiLA8Wa4RWRcIUkrtSVa5nRhsEGBg48fD6rSs7xps=\ngithub.com/golang/snappy v0.0.3 h1:fHPg5GQYlCeLIPB9BZqMVR5nR9A+IM5zcgeTdjMYmLA=\ngithub.com/golang/snappy v0.0.3/go.mod h1:/XxbfmMg8lxefKM7IXC3fBNl/7bRcc72aCRzEWrmP2Q=\ngithub.com/google/flatbuffers v2.0.0+incompatible/go.mod h1:1AeVuKshWv4vARoZatz6mlQ0JxURH0Kv5+zNeJKJCa8=\ngithub.com/google/flatbuffers v24.3.25+incompatible h1:CX395cjN9Kke9mmalRoL3d81AtFUxJM+yDthflgJGkI=\ngithub.com/google/flatbuffers v24.3.25+incompatible/go.mod h1:1AeVuKshWv4vARoZatz6mlQ0JxURH0Kv5+zNeJKJCa8=\ngithub.com/google/go-cmp v0.2.0/go.mod h1:oXzfMopK8JAjlY9xF4vHSVASa0yLyX7SntLO5aqRK0M=\ngithub.com/google/go-cmp v0.3.0/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.3.1/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.4.0/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.0/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.5/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.6/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.6.0 h1:ofyhxvXcZhMsU5ulbFiLKl/XBFqE1GSq7atu8tAmTRI=\ngithub.com/google/go-cmp v0.6.0/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/google/gofuzz v1.0.0/go.mod h1:dBl0BpW6vV/+mYPU4Po3pmUjxk6FQPldtuIdl/M65Eg=\ngithub.com/google/uuid v1.1.2/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/google/uuid v1.6.0 h1:NIvaJDMOsjHA8n1jAhLSgzrAzy1Hgr+hNrb57e+94F0=\ngithub.com/google/uuid v1.6.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/grpc-ecosystem/grpc-gateway v1.16.0/go.mod h1:BDjrQk3hbvj6Nolgz8mAMFbcEtjT1g+wF4CSlocrBnw=\ngithub.com/inconshreveable/mousetrap v1.1.0 h1:wN+x4NVGpMsO7ErUn/mUI3vEoE6Jt13X2s0bqwp9tc8=\ngithub.com/inconshreveable/mousetrap v1.1.0/go.mod h1:vpF70FUmC8bwa3OWnCshd2FqLfsEA9PFc4w1p2J65bw=\ngithub.com/json-iterator/go v1.1.12 h1:PV8peI4a0ysnczrg+LtxykD8LfKY9ML6u2jnxaEnrnM=\ngithub.com/json-iterator/go v1.1.12/go.mod h1:e30LSqwooZae/UwlEbR2852Gd8hjQvJoHmT4TnhNGBo=\ngithub.com/jung-kurt/gofpdf v1.0.0/go.mod h1:7Id9E/uU8ce6rXgefFLlgrJj/GYY22cpxn+r32jIOes=\ngithub.com/jung-kurt/gofpdf v1.0.3-0.20190309125859-24315acbbda5/go.mod h1:7Id9E/uU8ce6rXgefFLlgrJj/GYY22cpxn+r32jIOes=\ngithub.com/kisielk/errcheck v1.5.0/go.mod h1:pFxgyoBC7bSaBwPgfKdkLd5X25qrDl4LWUI2bnpBCr8=\ngithub.com/kisielk/gotool v1.0.0/go.mod h1:XhKaO+MFFWcvkIS/tQcRk01m1F5IRFswLeQ+oQHNcck=\ngithub.com/klauspost/compress v1.13.1 h1:wXr2uRxZTJXHLly6qhJabee5JqIhTRoLBhDOA74hDEQ=\ngithub.com/klauspost/compress v1.13.1/go.mod h1:8dP1Hq4DHOhN9w426knH3Rhby4rFm6D8eO+e+Dq5Gzg=\ngithub.com/klauspost/cpuid/v2 v2.0.9/go.mod h1:FInQzS24/EEf25PyTYn52gqo7WaD8xa0213Md/qVLRg=\ngithub.com/klauspost/cpuid/v2 v2.2.7 h1:ZWSB3igEs+d0qvnxR/ZBzXVmxkgt8DdzP6m9pfuVLDM=\ngithub.com/klauspost/cpuid/v2 v2.2.7/go.mod h1:Lcz8mBdAVJIBVzewtcLocK12l3Y+JytZYpaMropDUws=\ngithub.com/knz/go-libedit v1.10.1/go.mod h1:MZTVkCWyz0oBc7JOWP3wNAzd002ZbM/5hgShxwh4x8M=\ngithub.com/kr/pretty v0.3.0 h1:WgNl7dwNpEZ6jJ9k1snq4pZsg7DOEN8hP9Xw0Tsjwk0=\ngithub.com/kr/pretty v0.3.0/go.mod h1:640gp4NfQd8pI5XOwp5fnNeVWj67G7CFk/SaSQn7NBk=\ngithub.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=\ngithub.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=\ngithub.com/leodido/go-urn v1.4.0 h1:WT9HwE9SGECu3lg4d/dIA+jxlljEa1/ffXKmRjqdmIQ=\ngithub.com/leodido/go-urn v1.4.0/go.mod h1:bvxc+MVxLKB4z00jd1z+Dvzr47oO32F/QSNjSBOlFxI=\ngithub.com/mattn/go-isatty v0.0.20 h1:xfD0iDuEKnDkl03q4limB+vH+GxLEtL/jb4xVJSWWEY=\ngithub.com/mattn/go-isatty v0.0.20/go.mod h1:W+V8PltTTMOvKvAeJH7IuucS94S2C6jfK/D7dTCTo3Y=\ngithub.com/mattn/go-runewidth v0.0.9/go.mod h1:H031xJmbD/WCDINGzjvQ9THkh0rPKHF+m2gUSrubnMI=\ngithub.com/mattn/go-runewidth v0.0.14 h1:+xnbZSEeDbOIg5/mE6JF0w6n9duR1l3/WmbinWVwUuU=\ngithub.com/mattn/go-runewidth v0.0.14/go.mod h1:Jdepj2loyihRzMpdS35Xk/zdY8IAYHsh153qUoGf23w=\ngithub.com/modern-go/concurrent v0.0.0-20180228061459-e0a39a4cb421/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=\ngithub.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd h1:TRLaZ9cD/w8PVh93nsPXa1VrQ6jlwL5oN8l14QlcNfg=\ngithub.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=\ngithub.com/modern-go/reflect2 v1.0.2 h1:xBagoLtFs94CBntxluKeaWgTMpvLxC4ur3nMaC9Gz0M=\ngithub.com/modern-go/reflect2 v1.0.2/go.mod h1:yWuevngMOJpCy52FWWMvUC8ws7m/LJsjYzDa0/r8luk=\ngithub.com/nlpodyssey/gopickle v0.3.0 h1:BLUE5gxFLyyNOPzlXxt6GoHEMMxD0qhsE4p0CIQyoLw=\ngithub.com/nlpodyssey/gopickle v0.3.0/go.mod h1:f070HJ/yR+eLi5WmM1OXJEGaTpuJEUiib19olXgYha0=\ngithub.com/olekukonko/tablewriter v0.0.5 h1:P2Ga83D34wi1o9J6Wh1mRuqd4mF/x/lgBS7N7AbDhec=\ngithub.com/olekukonko/tablewriter v0.0.5/go.mod h1:hPp6KlRPjbx+hW8ykQs1w3UBbZlj6HuIJcUGPhkA7kY=\ngithub.com/pdevine/tensor v0.0.0-20240510204454-f88f4562727c h1:GwiUUjKefgvSNmv3NCvI/BL0kDebW6Xa+kcdpdc1mTY=\ngithub.com/pdevine/tensor v0.0.0-20240510204454-f88f4562727c/go.mod h1:PSojXDXF7TbgQiD6kkd98IHOS0QqTyUEaWRiS8+BLu8=\ngithub.com/pelletier/go-toml/v2 v2.2.2 h1:aYUidT7k73Pcl9nb2gScu7NSrKCSHIDE89b3+6Wq+LM=\ngithub.com/pelletier/go-toml/v2 v2.2.2/go.mod h1:1t835xjRzz80PqgE6HHgN2JOsmgYu/h4qDAS4n929Rs=\ngithub.com/phpdave11/gofpdf v1.4.2/go.mod h1:zpO6xFn9yxo3YLyMvW8HcKWVdbNqgIfOOp2dXMnm1mY=\ngithub.com/phpdave11/gofpdi v1.0.12/go.mod h1:vBmVV0Do6hSBHC8uKUQ71JGW+ZGQq74llk/7bXwjDoI=\ngithub.com/pierrec/lz4/v4 v4.1.8 h1:ieHkV+i2BRzngO4Wd/3HGowuZStgq6QkPsD1eolNAO4=\ngithub.com/pierrec/lz4/v4 v4.1.8/go.mod h1:gZWDp/Ze/IJXGXf23ltt2EXimqmTUXEy0GFuRQyBid4=\ngithub.com/pkg/errors v0.8.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pkg/errors v0.9.1 h1:FEBLx1zS214owpjy7qsBeixbURkuhQAwrK5UwLGTwt4=\ngithub.com/pkg/errors v0.9.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/prometheus/client_model v0.0.0-20190812154241-14fe0d1b01d4/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6Tm2C1GtYGdfGttqA=\ngithub.com/rivo/uniseg v0.2.0 h1:S1pD9weZBuJdFmowNwbpi7BJ8TNftyUImj/0WQi72jY=\ngithub.com/rivo/uniseg v0.2.0/go.mod h1:J6wj4VEh+S6ZtnVlnTBMWIodfgj8LQOQFoIToxlJtxc=\ngithub.com/rogpeppe/fastuuid v1.2.0/go.mod h1:jVj6XXZzXRy/MSR5jhDC/2q6DgLz+nrA6LYCDYWNEvQ=\ngithub.com/rogpeppe/go-internal v1.8.0 h1:FCbCCtXNOY3UtUuHUYaghJg4y7Fd14rXifAYUAtL9R8=\ngithub.com/rogpeppe/go-internal v1.8.0/go.mod h1:WmiCO8CzOY8rg0OYDC4/i/2WRWAB6poM+XZ2dLUbcbE=\ngithub.com/russross/blackfriday/v2 v2.1.0/go.mod h1:+Rmxgy9KzJVeS9/2gXHxylqXiyQDYRxCVz55jmeOWTM=\ngithub.com/ruudk/golang-pdf417 v0.0.0-20181029194003-1af4ab5afa58/go.mod h1:6lfFZQK844Gfx8o5WFuvpxWRwnSoipWe/p622j1v06w=\ngithub.com/spf13/cobra v1.7.0 h1:hyqWnYt1ZQShIddO5kBpj3vu05/++x6tJ6dg8EC572I=\ngithub.com/spf13/cobra v1.7.0/go.mod h1:uLxZILRyS/50WlhOIKD7W6V5bgeIt+4sICxh6uRMrb0=\ngithub.com/spf13/pflag v1.0.5 h1:iy+VFUOCP1a+8yFto/drg2CJ5u0yRoB7fZw3DKv/JXA=\ngithub.com/spf13/pflag v1.0.5/go.mod h1:McXfInJRrz4CZXVZOBLb0bTZqETkiAhM9Iw0y3An2Bg=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.4.0/go.mod h1:YvHI0jy2hoMjB+UWwv71VJQ9isScKT/TqJzVSSt89Yw=\ngithub.com/stretchr/objx v0.5.0/go.mod h1:Yh+to48EsGEfYuaHDzXPcE3xhTkx73EhmCGUpEOglKo=\ngithub.com/stretchr/objx v0.5.2/go.mod h1:FRsXN1f5AsAjCGJKqEizvkpNtU+EGNCLh3NxZ/8L+MA=\ngithub.com/stretchr/testify v1.1.4/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=\ngithub.com/stretchr/testify v1.2.2/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=\ngithub.com/stretchr/testify v1.3.0/go.mod h1:M5WIy9Dh21IEIfnGCwXGc5bZfKNJtfHm1UVUgZn+9EI=\ngithub.com/stretchr/testify v1.5.1/go.mod h1:5W2xD1RspED5o8YsWQXVCued0rvSQ+mT+I5cxcmMvtA=\ngithub.com/stretchr/testify v1.7.0/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.7.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.8.0/go.mod h1:yNjHg4UonilssWZ8iaSj1OCr/vHnekPRkoO+kdMU+MU=\ngithub.com/stretchr/testify v1.8.1/go.mod h1:w2LPCIKwWwSfY2zedu0+kehJoqGctiVI29o6fzry7u4=\ngithub.com/stretchr/testify v1.8.4/go.mod h1:sz/lmYIOXD/1dqDmKjjqLyZ2RngseejIcXlSw2iwfAo=\ngithub.com/stretchr/testify v1.9.0 h1:HtqpIVDClZ4nwg75+f6Lvsy/wHu+3BoSGCbBAcpTsTg=\ngithub.com/stretchr/testify v1.9.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=\ngithub.com/twitchyliquid64/golang-asm v0.15.1 h1:SU5vSMR7hnwNxj24w34ZyCi/FmDZTkS4MhqMhdFk5YI=\ngithub.com/twitchyliquid64/golang-asm v0.15.1/go.mod h1:a1lVb/DtPvCB8fslRZhAngC2+aY1QWCk3Cedj/Gdt08=\ngithub.com/ugorji/go/codec v1.2.12 h1:9LC83zGrHhuUA9l16C9AHXAqEV/2wBQ4nkvumAE65EE=\ngithub.com/ugorji/go/codec v1.2.12/go.mod h1:UNopzCgEMSXjBc6AOMqYvWC1ktqTAfzJZUZgYf6w6lg=\ngithub.com/x448/float16 v0.8.4 h1:qLwI1I70+NjRFUR3zs1JPUCgaCXSh3SW62uAKT1mSBM=\ngithub.com/x448/float16 v0.8.4/go.mod h1:14CWIYCyZA/cWjXOioeEpHeN/83MdbZDRQHoFcYsOfg=\ngithub.com/xtgo/set v1.0.0 h1:6BCNBRv3ORNDQ7fyoJXRv+tstJz3m1JVFQErfeZz2pY=\ngithub.com/xtgo/set v1.0.0/go.mod h1:d3NHzGzSa0NmB2NhFyECA+QdRp29oEn2xbT+TpeFoM8=\ngithub.com/yuin/goldmark v1.1.27/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngithub.com/yuin/goldmark v1.2.1/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngithub.com/yuin/goldmark v1.3.5/go.mod h1:mwnBkeHKe2W/ZEtQ+71ViKU8L12m81fl3OWwC1Zlc8k=\ngo.opentelemetry.io/proto/otlp v0.7.0/go.mod h1:PqfVotwruBrMGOCsRd/89rSnXhoiJIqeYNgFYFoEGnI=\ngo4.org/unsafe/assume-no-moving-gc v0.0.0-20231121144256-b99613f794b6 h1:lGdhQUN/cnWdSH3291CUuxSEqc+AsGTiDxPP3r2J0l4=\ngo4.org/unsafe/assume-no-moving-gc v0.0.0-20231121144256-b99613f794b6/go.mod h1:FftLjUGFEDu5k8lt0ddY+HcrH/qU/0qk+H8j9/nTl3E=\ngolang.org/x/arch v0.0.0-20210923205945-b76863e36670/go.mod h1:5om86z9Hs0C8fWVUuoMHwpExlXzs5Tkyp9hOrfG7pp8=\ngolang.org/x/arch v0.8.0 h1:3wRIsP3pM4yUptoR96otTUOXI367OS0+c9eeRi9doIc=\ngolang.org/x/arch v0.8.0/go.mod h1:FEVrYAQjsQXMVJ1nsMoVVXPZg6p2JE2mx8psSWTDQys=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20190510104115-cbcb75029529/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20191011191535-87dc89f01550/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20200622213623-75b288015ac9/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/crypto v0.31.0 h1:ihbySMvVjLAeSH1IbfcRTkD/iNscyz8rGzjF/E5hV6U=\ngolang.org/x/crypto v0.31.0/go.mod h1:kDsLvtWBEx7MV9tJOj9bnXsPbxwJQ6csT/x4KIN4Ssk=\ngolang.org/x/exp v0.0.0-20180321215751-8460e604b9de/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\ngolang.org/x/exp v0.0.0-20180807140117-3d87b88a115f/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\ngolang.org/x/exp v0.0.0-20190121172915-509febef88a4/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\ngolang.org/x/exp v0.0.0-20190125153040-c74c464bbbf2/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\ngolang.org/x/exp v0.0.0-20190306152737-a1d7652674e8/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\ngolang.org/x/exp v0.0.0-20191002040644-a1355ae1e2c3/go.mod h1:NOZ3BPKG0ec/BKJQgnvsSFpcKLM5xXVWnvZS97DWHgE=\ngolang.org/x/exp v0.0.0-20231110203233-9a3e6036ecaa h1:FRnLl4eNAQl8hwxVVC17teOw8kdjVDVAiFMtgUdTSRQ=\ngolang.org/x/exp v0.0.0-20231110203233-9a3e6036ecaa/go.mod h1:zk2irFbV9DP96SEBUUAy67IdHUaZuSnrz1n472HUCLE=\ngolang.org/x/image v0.0.0-20180708004352-c73c2afc3b81/go.mod h1:ux5Hcp/YLpHSI86hEcLt0YII63i6oz57MZXIpbrjZUs=\ngolang.org/x/image v0.0.0-20190227222117-0694c2d4d067/go.mod h1:kZ7UVZpmo3dzQBMxlp+ypCbDeSB+sBbTgSJuh5dn5js=\ngolang.org/x/image v0.0.0-20190802002840-cff245a6509b/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\ngolang.org/x/image v0.0.0-20190910094157-69e4b8554b2a/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\ngolang.org/x/image v0.0.0-20200119044424-58c23975cae1/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\ngolang.org/x/image v0.0.0-20200430140353-33d19683fad8/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\ngolang.org/x/image v0.0.0-20200618115811-c13761719519/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\ngolang.org/x/image v0.0.0-20201208152932-35266b937fa6/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\ngolang.org/x/image v0.0.0-20210216034530-4410531fe030/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\ngolang.org/x/image v0.22.0 h1:UtK5yLUzilVrkjMAZAZ34DXGpASN8i8pj8g+O+yd10g=\ngolang.org/x/image v0.22.0/go.mod h1:9hPFhljd4zZ1GNSIZJ49sqbp45GKK9t6w+iXvGqZUz4=\ngolang.org/x/lint v0.0.0-20181026193005-c67002cb31c3/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=\ngolang.org/x/lint v0.0.0-20190227174305-5b3e6a55c961/go.mod h1:wehouNa3lNwaWXcvxsM5YxQ5yQlVC4a0KAMCusXpPoU=\ngolang.org/x/lint v0.0.0-20190313153728-d0100b6bd8b3/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/lint v0.0.0-20210508222113-6edffad5e616/go.mod h1:3xt1FjdF8hUf6vQPIChWIBhFzV8gjjsPE/fR3IyQdNY=\ngolang.org/x/mobile v0.0.0-20190719004257-d2bd2a29d028/go.mod h1:E/iHnbuqvinMTCcRqshq8CkpyQDoeVncDDYHnLhea+o=\ngolang.org/x/mod v0.1.0/go.mod h1:0QHyrYULN0/3qlju5TqG8bIK38QM8yzMo5ekMj3DlcY=\ngolang.org/x/mod v0.1.1-0.20191105210325-c90efee705ee/go.mod h1:QqPTAvyqsEbceGzBzNggFXnrqF1CaUcvgkdR5Ot7KZg=\ngolang.org/x/mod v0.2.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/mod v0.3.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/mod v0.4.2/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/net v0.0.0-20180724234803-3673e40ba225/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20180826012351-8a410e7b638d/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190108225652-1e06a53dbb7e/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190213061140-3a22650c66bd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190311183353-d8887717615a/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200226121028-0de0cce0169b/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200822124328-c89045814202/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=\ngolang.org/x/net v0.0.0-20201021035429-f5854403a974/go.mod h1:sp8m0HH+o8qH0wwXwYZr8TS3Oi6o0r6Gce1SSxlDquU=\ngolang.org/x/net v0.0.0-20210405180319-a5a99cb37ef4/go.mod h1:p54w0d4576C0XHj96bSt6lcn1PtDYWL6XObtHCRCNQM=\ngolang.org/x/net v0.0.0-20210614182718-04defd469f4e/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=\ngolang.org/x/net v0.25.0 h1:d/OCCoBEUq33pjydKrGQhw7IlUPI2Oylr+8qLx49kac=\ngolang.org/x/net v0.25.0/go.mod h1:JkAGAh7GEvH74S6FOH42FLoXpXbE/aqXSrIQjXgsiwM=\ngolang.org/x/oauth2 v0.0.0-20180821212333-d2e6202438be/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=\ngolang.org/x/oauth2 v0.0.0-20200107190931-bf48bf16ab8d/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\ngolang.org/x/sync v0.0.0-20180314180146-1d60e4601c6f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20181108010431-42b317875d0f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20181221193216-37e7f081c4d4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190911185100-cd5d95a43a6e/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20201020160332-67f06af15bc9/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20210220032951-036812b2e83c/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.10.0 h1:3NQrjDixjgGwUOCaF8w2+VYHv0Ve/vGYSbdkTa98gmQ=\ngolang.org/x/sync v0.10.0/go.mod h1:Czt+wKu1gCyEFDUtn0jG5QVvpJ6rzVqr5aXyt9drQfk=\ngolang.org/x/sys v0.0.0-20180830151530-49385e6e1522/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190312061237-fead79001313/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200323222414-85ca7c5b95cd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200930185726-fdedc70b468f/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210124154548-22da62e12c0c/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210304124612-50617c2ba197/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210330210617-4fbd30eecc44/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210423082822-04245dca01da/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210510120138-977fb7262007/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20210630005230-0f9fa26af87c/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.5.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.6.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.28.0 h1:Fksou7UEQUWlKvIdsqzJmUmCX3cZuD2+P3XyyzwMhlA=\ngolang.org/x/sys v0.28.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=\ngolang.org/x/term v0.27.0 h1:WP60Sv1nlK1T6SupCHbXzSaN0b9wUmsPoRS9b61A23Q=\ngolang.org/x/term v0.27.0/go.mod h1:iMsnZpn0cago0GOrHO2+Y7u7JPn5AylBrcoWkElMTSM=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.5/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.6/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.21.0 h1:zyQAAkrwaneQ066sspRyJaG9VNi/YJ1NfzcGB3hZ/qo=\ngolang.org/x/text v0.21.0/go.mod h1:4IBbMaMmOPCJ8SecivzSH54+73PCFmPWxNTLm+vZkEQ=\ngolang.org/x/tools v0.0.0-20180525024113-a5b4c53f6e8b/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190114222345-bf090417da8b/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190206041539-40960b6deb8e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190226205152-f727befe758c/go.mod h1:9Yl7xja0Znq3iFh3HoIrodX9oNMXvdceNzlUR8zjMvY=\ngolang.org/x/tools v0.0.0-20190311212946-11955173bddd/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190524140312-2c0ae7006135/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=\ngolang.org/x/tools v0.0.0-20190927191325-030b2cf1153e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20200130002326-2f3ba24bd6e7/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200619180055-7c47624df98f/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\ngolang.org/x/tools v0.0.0-20210106214847-113979e3529a/go.mod h1:emZCQorbCU4vsT4fOWvOPXz4eW1wZW4PmDk9uLelYpA=\ngolang.org/x/tools v0.1.4/go.mod h1:o0xws9oXOQQZyjljx8fwUC0k7L1pTE6eaCbjGeHmOkk=\ngolang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1 h1:go1bK/D/BFZV2I8cIQd1NKEZ+0owSTG1fDTci4IqFcE=\ngolang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngonum.org/v1/gonum v0.0.0-20180816165407-929014505bf4/go.mod h1:Y+Yx5eoAFn32cQvJDxZx5Dpnq+c3wtXuadVZAcxbbBo=\ngonum.org/v1/gonum v0.8.2/go.mod h1:oe/vMfY3deqTw+1EZJhuvEW2iwGF1bW9wwu7XCu0+v0=\ngonum.org/v1/gonum v0.9.3/go.mod h1:TZumC3NeyVQskjXqmyWt4S3bINhy7B4eYwW69EbyX+0=\ngonum.org/v1/gonum v0.15.0 h1:2lYxjRbTYyxkJxlhC+LvJIx3SsANPdRybu1tGj9/OrQ=\ngonum.org/v1/gonum v0.15.0/go.mod h1:xzZVBJBtS+Mz4q0Yl2LJTk+OxOg4jiXZ7qBoM0uISGo=\ngonum.org/v1/netlib v0.0.0-20190313105609-8cb42192e0e0/go.mod h1:wa6Ws7BG/ESfp6dHfk7C6KdzKA7wR7u/rKwOGE66zvw=\ngonum.org/v1/plot v0.0.0-20190515093506-e2840ee46a6b/go.mod h1:Wt8AAjI+ypCyYX3nZBvf6cAIx93T+c/OS2HFAYskSZc=\ngonum.org/v1/plot v0.9.0/go.mod h1:3Pcqqmp6RHvJI72kgb8fThyUnav364FOsdDo2aGW5lY=\ngoogle.golang.org/appengine v1.1.0/go.mod h1:EbEs0AVv82hx2wNQdGPgUI5lhzA/G0D9YwlJXL52JkM=\ngoogle.golang.org/appengine v1.4.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=\ngoogle.golang.org/genproto v0.0.0-20180817151627-c66870c02cf8/go.mod h1:JiN7NxoALGmiZfu7CAH4rXhgtRTLTxftemlI0sWmxmc=\ngoogle.golang.org/genproto v0.0.0-20190819201941-24fa4b261c55/go.mod h1:DMBHOl98Agz4BDEuKkezgsaosCRResVns1a3J2ZsMNc=\ngoogle.golang.org/genproto v0.0.0-20200513103714-09dca8ec2884/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200526211855-cb27e3aa2013/go.mod h1:NbSheEEYHJ7i3ixzK3sjbqSGDJWnxyFXZblF3eUsNvo=\ngoogle.golang.org/genproto v0.0.0-20210630183607-d20f26d13c79/go.mod h1:yiaVoXHpRzHGyxV3o4DktVWY4mSUErTKaeEOq6C3t3U=\ngoogle.golang.org/grpc v1.19.0/go.mod h1:mqu4LbDTu4XGKhr4mRzUsmM4RtVoemTSY81AxZiDr8c=\ngoogle.golang.org/grpc v1.23.0/go.mod h1:Y5yQAOtifL1yxbo5wqy6BxZv8vAUGQwXBOALyacEbxg=\ngoogle.golang.org/grpc v1.25.1/go.mod h1:c3i+UQWmh7LiEpx4sFZnkU36qjEYZ0imhYfXVyQciAY=\ngoogle.golang.org/grpc v1.27.0/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8abTk=\ngoogle.golang.org/grpc v1.33.1/go.mod h1:fr5YgcSWrqhRRxogOsw7RzIpsmvOZ6IcH4kBYTpR3n0=\ngoogle.golang.org/grpc v1.36.0/go.mod h1:qjiiYl8FncCW8feJPdyg3v6XW24KsRHe+dy9BAGRRjU=\ngoogle.golang.org/grpc v1.38.0/go.mod h1:NREThFqKR1f3iQ6oBuvc5LadQuXVGo9rkm5ZGrQdJfM=\ngoogle.golang.org/grpc v1.39.0/go.mod h1:PImNr+rS9TWYb2O4/emRugxiyHZ5JyHW5F+RPnDzfrE=\ngoogle.golang.org/protobuf v0.0.0-20200109180630-ec00e32a8dfd/go.mod h1:DFci5gLYBciE7Vtevhsrf46CRTquxDuWsQurQQe4oz8=\ngoogle.golang.org/protobuf v0.0.0-20200221191635-4d8936d0db64/go.mod h1:kwYJMbMJ01Woi6D6+Kah6886xMZcty6N08ah7+eCXa0=\ngoogle.golang.org/protobuf v0.0.0-20200228230310-ab0ca4ff8a60/go.mod h1:cfTl7dwQJ+fmap5saPgwCLgHXTUD7jkjRqWcaiX5VyM=\ngoogle.golang.org/protobuf v1.20.1-0.20200309200217-e05f789c0967/go.mod h1:A+miEFZTKqfCUM6K7xSMQL9OKL/b6hQv+e19PK+JZNE=\ngoogle.golang.org/protobuf v1.21.0/go.mod h1:47Nbq4nVaFHyn7ilMalzfO3qCViNmqZ2kzikPIcrTAo=\ngoogle.golang.org/protobuf v1.22.0/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngoogle.golang.org/protobuf v1.23.0/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngoogle.golang.org/protobuf v1.23.1-0.20200526195155-81db48ad09cc/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngoogle.golang.org/protobuf v1.25.0/go.mod h1:9JNX74DMeImyA3h4bdi1ymwjUzf21/xIlbajtzgsN7c=\ngoogle.golang.org/protobuf v1.26.0-rc.1/go.mod h1:jlhhOSvTdKEhbULTjvd4ARK9grFBp09yW+WbY/TyQbw=\ngoogle.golang.org/protobuf v1.26.0/go.mod h1:9q0QmTI4eRPtz6boOQmLYwt+qCgq0jsYwAQnmE0givc=\ngoogle.golang.org/protobuf v1.27.1/go.mod h1:9q0QmTI4eRPtz6boOQmLYwt+qCgq0jsYwAQnmE0givc=\ngoogle.golang.org/protobuf v1.34.1 h1:9ddQBjfCyZPOHPUiPxpYESBLc+T8P3E+Vo4IbKZgFWg=\ngoogle.golang.org/protobuf v1.34.1/go.mod h1:c6P6GXX6sHbq/GpV6MGZEdwhWPcYBgnhAHhKbcUYpos=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c h1:Hei/4ADfdWqJk1ZMxUNpqntNwaWcugrBjAiHlqqRiVk=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c/go.mod h1:JHkPIbrfpd72SG/EVd6muEfDQjcINNoR0C8j2r3qZ4Q=\ngopkg.in/yaml.v2 v2.2.2/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.3/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngorgonia.org/vecf32 v0.9.0 h1:PClazic1r+JVJ1dEzRXgeiVl4g1/Hf/w+wUSqnco1Xg=\ngorgonia.org/vecf32 v0.9.0/go.mod h1:NCc+5D2oxddRL11hd+pCB1PEyXWOyiQxfZ/1wwhOXCA=\ngorgonia.org/vecf64 v0.9.0 h1:bgZDP5x0OzBF64PjMGC3EvTdOoMEcmfAh1VCUnZFm1A=\ngorgonia.org/vecf64 v0.9.0/go.mod h1:hp7IOWCnRiVQKON73kkC/AUMtEXyf9kGlVrtPQ9ccVA=\nhonnef.co/go/tools v0.0.0-20190102054323-c2f93a96b099/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190523083050-ea95bdfd59fc/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nnullprogram.com/x/optparse v1.0.0/go.mod h1:KdyPE+Igbe0jQUrVfMqDMeJQIJZEuyV7pjYmp6pbG50=\nrsc.io/pdf v0.1.1/go.mod h1:n8OzWcQ6Sp37PL01nO98y4iUCRdTGarVfzxY20ICaU4=\n"
        },
        {
          "name": "integration",
          "type": "tree",
          "content": null
        },
        {
          "name": "llama",
          "type": "tree",
          "content": null
        },
        {
          "name": "llm",
          "type": "tree",
          "content": null
        },
        {
          "name": "macapp",
          "type": "tree",
          "content": null
        },
        {
          "name": "main.go",
          "type": "blob",
          "size": 0.17578125,
          "content": "package main\n\nimport (\n\t\"context\"\n\n\t\"github.com/spf13/cobra\"\n\n\t\"github.com/ollama/ollama/cmd\"\n)\n\nfunc main() {\n\tcobra.CheckErr(cmd.NewCLI().ExecuteContext(context.Background()))\n}\n"
        },
        {
          "name": "make",
          "type": "tree",
          "content": null
        },
        {
          "name": "model",
          "type": "tree",
          "content": null
        },
        {
          "name": "openai",
          "type": "tree",
          "content": null
        },
        {
          "name": "parser",
          "type": "tree",
          "content": null
        },
        {
          "name": "progress",
          "type": "tree",
          "content": null
        },
        {
          "name": "readline",
          "type": "tree",
          "content": null
        },
        {
          "name": "runners",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "server",
          "type": "tree",
          "content": null
        },
        {
          "name": "template",
          "type": "tree",
          "content": null
        },
        {
          "name": "types",
          "type": "tree",
          "content": null
        },
        {
          "name": "util",
          "type": "tree",
          "content": null
        },
        {
          "name": "version",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}