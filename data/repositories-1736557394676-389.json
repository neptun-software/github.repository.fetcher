{
  "metadata": {
    "timestamp": 1736557394676,
    "page": 389,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "apache/spark",
      "stars": 40318,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".asf.yaml",
          "type": "blob",
          "size": 1.33,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements. See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License. You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# https://cwiki.apache.org/confluence/display/INFRA/git+-+.asf.yaml+features\n---\ngithub:\n  description: \"Apache Spark - A unified analytics engine for large-scale data processing\"\n  homepage: https://spark.apache.org/\n  labels:\n    - python\n    - scala\n    - r\n    - java\n    - big-data\n    - jdbc\n    - sql\n    - spark\n  enabled_merge_buttons:\n    merge: false\n    squash: true\n    rebase: true\n  ghp_branch: master\n  ghp_path: /docs\n\nnotifications:\n  pullrequests: reviews@spark.apache.org\n  issues: reviews@spark.apache.org\n  commits: commits@spark.apache.org\n  jira_options: link label\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.13,
          "content": "*.bat text eol=crlf\n*.cmd text eol=crlf\n*.java text eol=lf\n*.scala text eol=lf\n*.xml text eol=lf\n*.py text eol=lf\n*.R text eol=lf\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.92,
          "content": "*#*#\n*.#*\n*.iml\n*.ipr\n*.iws\n*.pyc\n*.pyo\n*.swp\n*~\n.java-version\n.python-version\n.DS_Store\n.ammonite\n.bloop\n.bsp/\n.cache\n.classpath\n.ensime\n.ensime_cache/\n.ensime_lucene\n.generated-mima*\n.idea/\n.idea_modules/\n.metals\n.project\n.pydevproject\n.scala_dependencies\n.settings\n.vscode\nartifacts/\n/lib/\nR-unit-tests.log\nR/unit-tests.out\nR/cran-check.out\nR/pkg/vignettes/sparkr-vignettes.html\nR/pkg/tests/fulltests/Rplots.pdf\nbuild/*.jar\nbuild/apache-maven*\nbuild/scala*\ncache\ncheckpoint\nconf/*.cmd\nconf/*.conf\nconf/*.properties\nconf/*.sh\nconf/*.xml\nconf/java-opts\nconf/slaves\ndependency-reduced-pom.xml\nderby.log\ndev/create-release/*final\ndev/create-release/*txt\ndev/pr-deps/\ndist/\ndocs/_generated/\ndocs/_site/\ndocs/api\ndocs/.local_ruby_bundle\nsql/docs\nsql/site\nlib_managed/\nlint-r-report.log\nlint-js-report.log\nlog/\nlogs/\nmetals.sbt\nout/\nproject/boot/\nproject/build/target/\nproject/plugins/lib_managed/\nproject/plugins/project/build.properties\nproject/plugins/src_managed/\nproject/plugins/target/\npython/lib/pyspark.zip\npython/.eggs/\npython/coverage.xml\npython/deps\npython/docs/_site/\npython/docs/source/development/errors.rst\npython/docs/source/reference/**/api/\npython/docs/source/user_guide/pandas_on_spark/supported_pandas_api.rst\npython/test_coverage/coverage_data\npython/test_coverage/htmlcov\npython/pyspark/python\n.mypy_cache/\nreports/\nscalastyle-on-compile.generated.xml\nscalastyle-output.xml\nscalastyle.txt\nspark-*-bin-*.tgz\nspark-tests.log\nsrc_managed/\nstreaming-tests.log\ntarget/\nunit-tests.log\nwork/\ndocs/.jekyll-metadata\ndocs/.jekyll-cache\n\n# For Hive\nTempStatsStore/\nmetastore/\nmetastore_db/\nsql/hive-thriftserver/test_warehouses\nwarehouse/\nspark-warehouse/\n\n# For R session data\n.RData\n.RHistory\n.Rhistory\n*.Rproj\n*.Rproj.*\n\n.Rproj.user\n\n# For SBT\n.jvmopts\n\n# For Node.js\nnode_modules\n\n# For Antlr\nsql/api/gen/\nsql/api/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBaseLexer.tokens\nsql/api/src/main/antlr4/org/apache/spark/sql/catalyst/parser/gen/\n"
        },
        {
          "name": ".nojekyll",
          "type": "blob",
          "size": 0,
          "content": null
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.97,
          "content": "## Contributing to Spark\n\n*Before opening a pull request*, review the \n[Contributing to Spark guide](https://spark.apache.org/contributing.html). \nIt lists steps that are required before creating a PR. In particular, consider:\n\n- Is the change important and ready enough to ask the community to spend time reviewing?\n- Have you searched for existing, related JIRAs and pull requests?\n- Is this a new feature that can stand alone as a [third party project](https://spark.apache.org/third-party-projects.html) ?\n- Is the change being proposed clearly explained and motivated?\n\nWhen you contribute code, you affirm that the contribution is your original work and that you \nlicense the work to the project under the project's open source license. Whether or not you \nstate this explicitly, by submitting any copyrighted material via pull request, email, or \nother means you agree to license the material under the project's open source license and \nwarrant that you have the legal authority to do so.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 13.23,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n\n------------------------------------------------------------------------------------\nThis product bundles various third-party components under other open source licenses.\nThis section summarizes those components and their licenses. See licenses/\nfor text of these licenses.\n\n\nApache Software Foundation License 2.0\n--------------------------------------\n\ncommon/network-common/src/main/java/org/apache/spark/network/util/LimitedInputStream.java\ncore/src/main/java/org/apache/spark/util/collection/TimSort.java\ncore/src/main/resources/org/apache/spark/ui/static/bootstrap*\ncore/src/main/resources/org/apache/spark/ui/static/vis*\ndocs/js/vendor/bootstrap.js\nconnector/spark-ganglia-lgpl/src/main/java/com/codahale/metrics/ganglia/GangliaReporter.java\ncore/src/main/resources/org/apache/spark/ui/static/d3-flamegraph.min.js\ncore/src/main/resources/org/apache/spark/ui/static/d3-flamegraph.css\n\nPython Software Foundation License\n----------------------------------\n\npython/pyspark/loose_version.py\n\nBSD 3-Clause\n------------\n\npython/lib/py4j-*-src.zip\npython/pyspark/cloudpickle/*.py\npython/pyspark/join.py\n\nThe CSS style for the navigation sidebar of the documentation was originally\nsubmitted by Óscar Nájera for the scikit-learn project. The scikit-learn project\nis distributed under the 3-Clause BSD license.\n\n\nMIT License\n-----------\n\ncore/src/main/resources/org/apache/spark/ui/static/dagre-d3.min.js\ncore/src/main/resources/org/apache/spark/ui/static/*dataTables*\ncore/src/main/resources/org/apache/spark/ui/static/graphlib-dot.min.js\ncore/src/main/resources/org/apache/spark/ui/static/jquery*\ncore/src/main/resources/org/apache/spark/ui/static/sorttable.js\ndocs/js/vendor/anchor.min.js\ndocs/js/vendor/jquery*\ndocs/js/vendor/modernizer*\n\nISC License\n-----------\n\ncore/src/main/resources/org/apache/spark/ui/static/d3.min.js\n\n\nCreative Commons CC0 1.0 Universal Public Domain Dedication\n-----------------------------------------------------------\n(see LICENSE-CC0.txt)\n\ndata/mllib/images/kittens/29.5.a_b_EGDP022204.jpg\ndata/mllib/images/kittens/54893.jpg\ndata/mllib/images/kittens/DP153539.jpg\ndata/mllib/images/kittens/DP802813.jpg\ndata/mllib/images/multi-channel/chr30.4.184.jpg\n"
        },
        {
          "name": "LICENSE-binary",
          "type": "blob",
          "size": 21.78,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n------------------------------------------------------------------------------------\nThis project bundles some components that are also licensed under the Apache\nLicense Version 2.0:\n\ncom.clearspring.analytics:stream\ncom.fasterxml.jackson.core:jackson-annotations\ncom.fasterxml.jackson.core:jackson-core\ncom.fasterxml.jackson.core:jackson-databind\ncom.fasterxml.jackson.dataformat:jackson-dataformat-yaml\ncom.fasterxml.jackson.datatype:jackson-datatype-jsr310\ncom.fasterxml.jackson.module:jackson-module-scala_2.13\ncom.github.joshelser:dropwizard-metrics-hadoop-metrics2-reporter\ncom.google.code.findbugs:jsr305\ncom.google.code.gson:gson\ncom.google.crypto.tink:tink\ncom.google.flatbuffers:flatbuffers-java\ncom.google.guava:guava\ncom.jamesmurty.utils:java-xmlbuilder\ncom.ning:compress-lzf\ncom.squareup.okhttp3:logging-interceptor\ncom.squareup.okhttp3:okhttp\ncom.squareup.okio:okio\ncom.tdunning:json\ncom.twitter:chill-java\ncom.twitter:chill_2.13\ncom.univocity:univocity-parsers\ncom.zaxxer.HikariCP\ncommons-cli:commons-cli\ncommons-codec:commons-codec\ncommons-collections:commons-collections\ncommons-dbcp:commons-dbcp\ncommons-io:commons-io\ncommons-lang:commons-lang\ncommons-pool:commons-pool\nio.airlift:aircompressor\nio.dropwizard.metrics:metrics-core\nio.dropwizard.metrics:metrics-graphite\nio.dropwizard.metrics:metrics-jmx\nio.dropwizard.metrics:metrics-json\nio.dropwizard.metrics:metrics-jvm\nio.fabric8:kubernetes-client\nio.fabric8:kubernetes-client-api\nio.fabric8:kubernetes-httpclient-okhttp\nio.fabric8:kubernetes-model-admissionregistration\nio.fabric8:kubernetes-model-apiextensions\nio.fabric8:kubernetes-model-apps\nio.fabric8:kubernetes-model-autoscaling\nio.fabric8:kubernetes-model-batch\nio.fabric8:kubernetes-model-certificates\nio.fabric8:kubernetes-model-common\nio.fabric8:kubernetes-model-coordination\nio.fabric8:kubernetes-model-core\nio.fabric8:kubernetes-model-discovery\nio.fabric8:kubernetes-model-events\nio.fabric8:kubernetes-model-extensions\nio.fabric8:kubernetes-model-flowcontrol\nio.fabric8:kubernetes-model-gatewayapi\nio.fabric8:kubernetes-model-metrics\nio.fabric8:kubernetes-model-networking\nio.fabric8:kubernetes-model-node\nio.fabric8:kubernetes-model-policy\nio.fabric8:kubernetes-model-rbac\nio.fabric8:kubernetes-model-resource\nio.fabric8:kubernetes-model-scheduling\nio.fabric8:kubernetes-model-storageclass\nio.fabric8:zjsonpatch\nio.github.java-diff-utils:java-diff-utils\nio.jsonwebtoken:jjwt-api\nio.netty:netty-all\nio.netty:netty-buffer\nio.netty:netty-codec\nio.netty:netty-codec-http\nio.netty:netty-codec-http2\nio.netty:netty-codec-socks\nio.netty:netty-common\nio.netty:netty-handler\nio.netty:netty-handler-proxy\nio.netty:netty-resolver\nio.netty:netty-tcnative-boringssl-static\nio.netty:netty-tcnative-classes\nio.netty:netty-transport\nio.netty:netty-transport-classes-epoll\nio.netty:netty-transport-classes-kqueue\nio.netty:netty-transport-native-epoll\nio.netty:netty-transport-native-kqueue\nio.netty:netty-transport-native-unix-common\nio.vertx:vertx-auth-common\nio.vertx:vertx-core\nio.vertx:vertx-web-client\nio.vertx:vertx-web-common\njakarta.inject:jakarta.inject-api\njakarta.validation:jakarta.validation-api\njavax.jdo:jdo-api\njoda-time:joda-time\nnet.java.dev.jna:jna\nnet.sf.opencsv:opencsv\nnet.sf.supercsv:super-csv\nnet.sf.jpam:jpam\norg.apache.arrow:arrow-format\norg.apache.arrow:arrow-memory-core\norg.apache.arrow:arrow-memory-netty\norg.apache.arrow:arrow-memory-netty-buffer-patch\norg.apache.arrow:arrow-vector\norg.apache.avro:avro\norg.apache.avro:avro-ipc\norg.apache.avro:avro-mapred\norg.apache.commons:commons-collections4\norg.apache.commons:commons-compress\norg.apache.commons:commons-crypto\norg.apache.commons:commons-lang3\norg.apache.commons:commons-math3\norg.apache.commons:commons-text\norg.apache.curator:curator-client\norg.apache.curator:curator-framework\norg.apache.curator:curator-recipes\norg.apache.derby:derby\norg.apache.derby:derbyshared\norg.apache.derby:derbytools\norg.apache.datasketches:datasketches-java\norg.apache.datasketches:datasketches-memory\norg.apache.hadoop:hadoop-client-api\norg.apache.hadoop:hadoop-client-runtime\norg.apache.hive:hive-beeline\norg.apache.hive:hive-cli\norg.apache.hive:hive-common\norg.apache.hive:hive-exec\norg.apache.hive:hive-jdbc\norg.apache.hive:hive-llap-common\norg.apache.hive:hive-metastore\norg.apache.hive:hive-serde\norg.apache.hive:hive-service-rpc\norg.apache.hive:hive-shims-0.23\norg.apache.hive:hive-shims\norg.apache.hive:hive-shims-common\norg.apache.hive:hive-shims-scheduler\norg.apache.hive:hive-storage-api\norg.apache.httpcomponents:httpclient\norg.apache.httpcomponents:httpcore\norg.apache.ivy:ivy\norg.apache.logging.log4j:log4j-1.2-api\norg.apache.logging.log4j:log4j-api\norg.apache.logging.log4j:log4j-core\norg.apache.logging.log4j:log4j-layout-template-json\norg.apache.logging.log4j:log4j-slf4j-impl\norg.apache.orc:orc-core\norg.apache.orc:orc-format\norg.apache.orc:orc-mapreduce\norg.apache.orc:orc-shims\norg.apache.parquet:parquet-column\norg.apache.parquet:parquet-common\norg.apache.parquet:parquet-encoding\norg.apache.parquet:parquet-format-structures\norg.apache.parquet:parquet-hadoop\norg.apache.parquet:parquet-jackson\norg.apache.thrift:libfb303\norg.apache.thrift:libthrift\norg.apache.ws.xmlschema:xmlschema-core\norg.apache.xbean:xbean-asm9-shaded\norg.apache.yetus:audience-annotations\norg.apache.zookeeper:zookeeper\norg.apache.zookeeper:zookeeper-jute\norg.codehaus.jackson:jackson-core-asl\norg.codehaus.jackson:jackson-mapper-asl\norg.datanucleus:datanucleus-api-jdo\norg.datanucleus:datanucleus-core\norg.datanucleus:datanucleus-rdbms\norg.datanucleus:javax.jdo\norg.eclipse.jetty:jetty-client\norg.eclipse.jetty:jetty-http\norg.eclipse.jetty:jetty-io\norg.eclipse.jetty:jetty-plus\norg.eclipse.jetty:jetty-proxy\norg.eclipse.jetty:jetty-security\norg.eclipse.jetty:jetty-server\norg.eclipse.jetty:jetty-servlet\norg.eclipse.jetty:jetty-servlets\norg.eclipse.jetty:jetty-util\norg.glassfish.jersey.containers:jersey-container-servlet\norg.glassfish.jersey.containers:jersey-container-servlet-core\norg.glassfish.jersey.core:jersey-client\norg.glassfish.jersey.core:jersey-common\norg.glassfish.jersey.core:jersey-server\norg.glassfish.jersey.inject:jersey-hk2\norg.json4s:json4s-ast_2.13\norg.json4s:json4s-core_2.13\norg.json4s:json4s-jackson-core_2.13\norg.json4s:json4s-jackson_2.13\norg.json4s:json4s-scalap_2.13\norg.lz4:lz4-java\norg.objenesis:objenesis\norg.roaringbitmap:RoaringBitmap\norg.rocksdb:rocksdbjni\norg.scala-lang:scala-compiler\norg.scala-lang:scala-library\norg.scala-lang:scala-reflect\norg.scala-lang.modules:scala-collection-compat_2.13\norg.scala-lang.modules:scala-parallel-collections_2.13\norg.scala-lang.modules:scala-parser-combinators_2.13\norg.scala-lang.modules:scala-xml_2.13\norg.scalanlp:breeze-macros_2.13\norg.scalanlp:breeze_2.13\norg.snakeyaml:snakeyaml-engine\norg.xerial.snappy:snappy-java\norg.yaml:snakeyaml\noro:oro\nstax:stax-api\n\ncore/src/main/java/org/apache/spark/util/collection/TimSort.java\ncore/src/main/resources/org/apache/spark/ui/static/bootstrap*\ncore/src/main/resources/org/apache/spark/ui/static/vis*\ncore/src/main/resources/org/apache/spark/ui/static/d3-flamegraph.min.js\ncore/src/main/resources/org/apache/spark/ui/static/d3-flamegraph.css\n\n\n------------------------------------------------------------------------------------\nThis product bundles various third-party components under other open source licenses.\nThis section summarizes those components and their licenses. See licenses-binary/\nfor text of these licenses.\n\n\nPython Software Foundation License\n----------------------------------\npython/pyspark/loose_version.py\n\n\nBSD 0-Clause\n------------\norg.tukaani:xz\n\n\nBSD 2-Clause\n------------\ncom.github.luben:zstd-jni\ncom.github.wendykierp:JTransforms\njavolution:javolution\njline:jline\norg.jodd:jodd-core\npl.edu.icm:JLargeArrays\n\n\nBSD 3-Clause\n------------\ncom.esotericsoftware:kryo-shaded\ncom.esotericsoftware:minlog\ncom.esotericsoftware:reflectasm\ncom.google.protobuf:protobuf-java\ncom.thoughtworks.paranamer:paranamer\nnet.sf.py4j:py4j\nnet.sourceforge.f2j:arpack_combined_all\norg.antlr:ST4\norg.antlr:antlr-runtime\norg.antlr:antlr4-runtime\norg.codehaus.janino:commons-compiler\norg.codehaus.janino:janino\norg.fusesource.leveldbjni:leveldbjni-all\norg.jline:jline\norg.jpmml:pmml-model\norg.threeten:threeten-extra\n\npython/lib/py4j-*-src.zip\npython/pyspark/cloudpickle.py\npython/pyspark/join.py\n\nThe CSS style for the navigation sidebar of the documentation was originally\nsubmitted by Óscar Nájera for the scikit-learn project. The scikit-learn project\nis distributed under the 3-Clause BSD license.\n\n\nMIT License\n-----------\ncom.github.scopt:scopt_2.13\ndev.ludovic.netlib:blas\ndev.ludovic.netlib:arpack\ndev.ludovic.netlib:lapack\nnet.razorvine:pickle\norg.checkerframework:checker-qual\norg.typelevel:algebra_2.13:jar\norg.typelevel:cats-kernel_2.13\norg.typelevel:spire_2.13\norg.typelevel:spire-macros_2.13\norg.typelevel:spire-platform_2.13\norg.typelevel:spire-util_2.13\norg.slf4j:jcl-over-slf4j\norg.slf4j:jul-to-slf4j\norg.slf4j:slf4j-api\n\ncore/src/main/resources/org/apache/spark/ui/static/dagre-d3.min.js\ncore/src/main/resources/org/apache/spark/ui/static/*dataTables*\ncore/src/main/resources/org/apache/spark/ui/static/graphlib-dot.min.js\ncore/src/main/resources/org/apache/spark/ui/static/jquery*\ncore/src/main/resources/org/apache/spark/ui/static/sorttable.js\n\n\nISC License\n-----------\ncore/src/main/resources/org/apache/spark/ui/static/d3.min.js\n\n\nCommon Development and Distribution License (CDDL) 1.0\n------------------------------------------------------\njavax.activation:activation  http://www.oracle.com/technetwork/java/javase/tech/index-jsp-138795.html\njavax.transaction:transaction-api\n\n\nCommon Development and Distribution License (CDDL) 1.1\n------------------------------------------------------\njavax.transaction:jta http://www.oracle.com/technetwork/java/index.html\njavax.xml.bind:jaxb-api    https://github.com/javaee/jaxb-v2\n\n\n\nEclipse Distribution License (EDL) 1.0\n--------------------------------------\ncom.sun.istack:istack-commons-runtime\njakarta.xml.bind:jakarta.xml.bind-api\norg.glassfish.jaxb:jaxb-runtime\n\nEclipse Public License (EPL) 2.0\n--------------------------------\njakarta.annotation:jakarta.annotation-api https://projects.eclipse.org/projects/ee4j.ca\njakarta.servlet:jakarta.servlet-api https://projects.eclipse.org/projects/ee4j.servlet\njakarta.ws.rs:jakarta.ws.rs-api https://github.com/eclipse-ee4j/jaxrs-api\norg.glassfish.hk2.external:aopalliance-repackaged\norg.glassfish.hk2:hk2-api\norg.glassfish.hk2:hk2-locator\norg.glassfish.hk2:hk2-utils\norg.glassfish.hk2:osgi-resource-locator\n\nCreative Commons CC0 1.0 Universal Public Domain Dedication\n-----------------------------------------------------------\n(see LICENSE-CC0.txt)\n\ndata/mllib/images/kittens/29.5.a_b_EGDP022204.jpg\ndata/mllib/images/kittens/54893.jpg\ndata/mllib/images/kittens/DP153539.jpg\ndata/mllib/images/kittens/DP802813.jpg\ndata/mllib/images/multi-channel/chr30.4.184.jpg\n\nUnicode/ICU License\n-------------------\ncom.ibm.icu:icu4j\n"
        },
        {
          "name": "NOTICE",
          "type": "blob",
          "size": 1.96,
          "content": "Apache Spark\nCopyright 2014 and onwards The Apache Software Foundation.\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nExport Control Notice\n---------------------\n\nThis distribution includes cryptographic software. The country in which you currently reside may have\nrestrictions on the import, possession, use, and/or re-export to another country, of encryption software.\nBEFORE using any encryption software, please check your country's laws, regulations and policies concerning\nthe import, possession, or use, and re-export of encryption software, to see if this is permitted. See\n<http://www.wassenaar.org/> for more information.\n\nThe U.S. Government Department of Commerce, Bureau of Industry and Security (BIS), has classified this\nsoftware as Export Commodity Control Number (ECCN) 5D002.C.1, which includes information security software\nusing or performing cryptographic functions with asymmetric algorithms. The form and manner of this Apache\nSoftware Foundation distribution makes it eligible for export under the License Exception ENC Technology\nSoftware Unrestricted (TSU) exception (see the BIS Export Administration Regulations, Section 740.13) for\nboth object code and source code.\n\nThe following provides more details on the included cryptographic software:\n\nThis software uses Apache Commons Crypto (https://commons.apache.org/proper/commons-crypto/) to\nsupport authentication, and encryption and decryption of data sent across the network between\nservices.\n\n\nMetrics\nCopyright 2010-2013 Coda Hale and Yammer, Inc.\n\nThis product includes software developed by Coda Hale and Yammer, Inc.\n\nThis product includes code derived from the JSR-166 project (ThreadLocalRandom, Striped64,\nLongAdder), which was released with the following comments:\n\n    Written by Doug Lea with assistance from members of JCP JSR-166\n    Expert Group and released to the public domain, as explained at\n    http://creativecommons.org/publicdomain/zero/1.0/"
        },
        {
          "name": "NOTICE-binary",
          "type": "blob",
          "size": 50.6,
          "content": "Apache Spark\nCopyright 2014 and onwards The Apache Software Foundation.\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nExport Control Notice\n---------------------\n\nThis distribution includes cryptographic software. The country in which you currently reside may have\nrestrictions on the import, possession, use, and/or re-export to another country, of encryption software.\nBEFORE using any encryption software, please check your country's laws, regulations and policies concerning\nthe import, possession, or use, and re-export of encryption software, to see if this is permitted. See\n<http://www.wassenaar.org/> for more information.\n\nThe U.S. Government Department of Commerce, Bureau of Industry and Security (BIS), has classified this\nsoftware as Export Commodity Control Number (ECCN) 5D002.C.1, which includes information security software\nusing or performing cryptographic functions with asymmetric algorithms. The form and manner of this Apache\nSoftware Foundation distribution makes it eligible for export under the License Exception ENC Technology\nSoftware Unrestricted (TSU) exception (see the BIS Export Administration Regulations, Section 740.13) for\nboth object code and source code.\n\nThe following provides more details on the included cryptographic software:\n\nThis software uses Apache Commons Crypto (https://commons.apache.org/proper/commons-crypto/) to\nsupport authentication, and encryption and decryption of data sent across the network between\nservices.\n\n\n// ------------------------------------------------------------------\n// NOTICE file corresponding to the section 4d of The Apache License,\n// Version 2.0, in this case for\n// ------------------------------------------------------------------\n\n=== NOTICE FOR com.clearspring.analytics:streams ===\nstream-api\nCopyright 2016 AddThis\n\nThis product includes software developed by AddThis.\n=== END OF NOTICE FOR com.clearspring.analytics:streams ===\n\nApache Avro\nCopyright 2009-2014 The Apache Software Foundation\n\nThis product currently only contains code developed by authors\nof specific components, as identified by the source code files;\nif such notes are missing files have been created by\nTatu Saloranta.\n\nFor additional credits (generally to people who reported problems)\nsee CREDITS file.\n\nApache Commons Compress\nCopyright 2002-2012 The Apache Software Foundation\n\nThis product includes software developed by\nThe Apache Software Foundation (http://www.apache.org/).\n\nApache Avro Mapred API\nCopyright 2009-2014 The Apache Software Foundation\n\nApache Avro IPC\nCopyright 2009-2014 The Apache Software Foundation\n\nObjenesis\nCopyright 2006-2013 Joe Walnes, Henri Tremblay, Leonardo Mesquita\n\nApache XBean :: ASM shaded (repackaged)\nCopyright 2005-2019 The Apache Software Foundation\n\n--------------------------------------\n\nThis product includes software developed at\nOW2 Consortium (http://asm.ow2.org/)\n\nThis product includes software developed by The Apache Software\nFoundation (http://www.apache.org/).\n\nThe binary distribution of this product bundles binaries of\norg.iq80.leveldb:leveldb-api (https://github.com/dain/leveldb), which has the\nfollowing notices:\n* Copyright 2011 Dain Sundstrom <dain@iq80.com>\n* Copyright 2011 FuseSource Corp. http://fusesource.com\n\nThe binary distribution of this product bundles binaries of\norg.fusesource.hawtjni:hawtjni-runtime (https://github.com/fusesource/hawtjni),\nwhich has the following notices:\n* This product includes software developed by FuseSource Corp.\n  http://fusesource.com\n* This product includes software developed at\n  Progress Software Corporation and/or its  subsidiaries or affiliates.\n* This product includes software developed by IBM Corporation and others.\n\nThe binary distribution of this product bundles binaries of\nGson 2.2.4,\nwhich has the following notices:\n\n\n                            The Netty Project\n                            =================\n\nPlease visit the Netty web site for more information:\n\n  * http://netty.io/\n\nCopyright 2014 The Netty Project\n\nThe Netty Project licenses this file to you under the Apache License,\nversion 2.0 (the \"License\"); you may not use this file except in compliance\nwith the License. You may obtain a copy of the License at:\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\nWARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\nLicense for the specific language governing permissions and limitations\nunder the License.\n\nAlso, please refer to each LICENSE.<component>.txt file, which is located in\nthe 'license' directory of the distribution file, for the license terms of the\ncomponents that this product depends on.\n\n-------------------------------------------------------------------------------\nThis product contains the extensions to Java Collections Framework which has\nbeen derived from the works by JSR-166 EG, Doug Lea, and Jason T. Greene:\n\n  * LICENSE:\n    * license/LICENSE.jsr166y.txt (Public Domain)\n  * HOMEPAGE:\n    * http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/\n    * http://viewvc.jboss.org/cgi-bin/viewvc.cgi/jbosscache/experimental/jsr166/\n\nThis product contains a modified portion of 'Webbit', an event based\nWebSocket and HTTP server, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.webbit.txt (BSD License)\n  * HOMEPAGE:\n    * https://github.com/joewalnes/webbit\n\nThis product contains a modified portion of 'SLF4J', a simple logging\nfacade for Java, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.slf4j.txt (MIT License)\n  * HOMEPAGE:\n    * http://www.slf4j.org/\n\nThis product contains a modified portion of 'Apache Harmony', an open source\nJava SE, which can be obtained at:\n\n  * NOTICE:\n    * license/NOTICE.harmony.txt\n  * LICENSE:\n    * license/LICENSE.harmony.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * http://archive.apache.org/dist/harmony/\n\nThis product contains a modified portion of 'jbzip2', a Java bzip2 compression\nand decompression library written by Matthew J. Francis. It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.jbzip2.txt (MIT License)\n  * HOMEPAGE:\n    * https://code.google.com/p/jbzip2/\n\nThis product contains a modified portion of 'libdivsufsort', a C API library to construct\nthe suffix array and the Burrows-Wheeler transformed string for any input string of\na constant-size alphabet written by Yuta Mori. It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.libdivsufsort.txt (MIT License)\n  * HOMEPAGE:\n    * https://github.com/y-256/libdivsufsort\n\nThis product contains a modified portion of Nitsan Wakart's 'JCTools', Java Concurrency Tools for the JVM,\n which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.jctools.txt (ASL2 License)\n  * HOMEPAGE:\n    * https://github.com/JCTools/JCTools\n\nThis product optionally depends on 'JZlib', a re-implementation of zlib in\npure Java, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.jzlib.txt (BSD style License)\n  * HOMEPAGE:\n    * http://www.jcraft.com/jzlib/\n\nThis product optionally depends on 'Compress-LZF', a Java library for encoding and\ndecoding data in LZF format, written by Tatu Saloranta. It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.compress-lzf.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://github.com/ning/compress\n\nThis product optionally depends on 'lz4', a LZ4 Java compression\nand decompression library written by Adrien Grand. It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.lz4.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://github.com/jpountz/lz4-java\n\nThis product optionally depends on 'lzma-java', a LZMA Java compression\nand decompression library, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.lzma-java.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://github.com/jponge/lzma-java\n\nThis product contains a modified portion of 'jfastlz', a Java port of FastLZ compression\nand decompression library written by William Kinney. It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.jfastlz.txt (MIT License)\n  * HOMEPAGE:\n    * https://code.google.com/p/jfastlz/\n\nThis product contains a modified portion of and optionally depends on 'Protocol Buffers', Google's data\ninterchange format, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.protobuf.txt (New BSD License)\n  * HOMEPAGE:\n    * https://github.com/google/protobuf\n\nThis product optionally depends on 'Bouncy Castle Crypto APIs' to generate\na temporary self-signed X.509 certificate when the JVM does not provide the\nequivalent functionality.  It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.bouncycastle.txt (MIT License)\n  * HOMEPAGE:\n    * http://www.bouncycastle.org/\n\nThis product optionally depends on 'Snappy', a compression library produced\nby Google Inc, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.snappy.txt (New BSD License)\n  * HOMEPAGE:\n    * https://github.com/google/snappy\n\nThis product optionally depends on 'JBoss Marshalling', an alternative Java\nserialization API, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.jboss-marshalling.txt (GNU LGPL 2.1)\n  * HOMEPAGE:\n    * http://www.jboss.org/jbossmarshalling\n\nThis product optionally depends on 'Caliper', Google's micro-\nbenchmarking framework, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.caliper.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://github.com/google/caliper\n\nThis product optionally depends on 'Apache Log4J', a logging framework, which\ncan be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.log4j.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * http://logging.apache.org/log4j/\n\nThis product optionally depends on 'Aalto XML', an ultra-high performance\nnon-blocking XML processor, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.aalto-xml.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * http://wiki.fasterxml.com/AaltoHome\n\nThis product contains a modified version of 'HPACK', a Java implementation of\nthe HTTP/2 HPACK algorithm written by Twitter. It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.hpack.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://github.com/twitter/hpack\n\nThis product contains a modified portion of 'Apache Commons Lang', a Java library\nprovides utilities for the java.lang API, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.commons-lang.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://commons.apache.org/proper/commons-lang/\n\n\nThis product contains the Maven wrapper scripts from 'Maven Wrapper', that provides an easy way to ensure a user has everything necessary to run the Maven build.\n\n  * LICENSE:\n    * license/LICENSE.mvn-wrapper.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://github.com/takari/maven-wrapper\n\n\nThe binary distribution of this product bundles binaries of\nCommons Codec 1.4,\nwhich has the following notices:\n * src/test/org/apache/commons/codec/language/DoubleMetaphoneTest.javacontains test data from http://aspell.net/test/orig/batch0.tab.Copyright (C) 2002 Kevin Atkinson (kevina@gnu.org)\n  ===============================================================================\n  The content of package org.apache.commons.codec.language.bm has been translated\n  from the original php source code available at http://stevemorse.org/phoneticinfo.htm\n  with permission from the original authors.\n  Original source copyright:Copyright (c) 2008 Alexander Beider & Stephen P. Morse.\n\nThe binary distribution of this product bundles binaries of\nCommons Lang 2.6,\nwhich has the following notices:\n * This product includes software from the Spring Framework,under the Apache License 2.0 (see: StringUtils.containsWhitespace())\n\nThe binary distribution of this product bundles binaries of\nApache Log4j 1.2.17,\nwhich has the following notices:\n * ResolverUtil.java\n    Copyright 2005-2006 Tim Fennell\n  Dumbster SMTP test server\n    Copyright 2004 Jason Paul Kitchen\n  TypeUtil.java\n    Copyright 2002-2012 Ramnivas Laddad, Juergen Hoeller, Chris Beams\n\nThe binary distribution of this product bundles binaries of\nJetty 11.0.20,\nwhich has the following notices:\n=========================\nNotices for Eclipse Jetty\n=========================\nThis content is produced and maintained by the Eclipse Jetty project.\n\nProject home: https://eclipse.dev/jetty/\n\nTrademarks\n----------\nEclipse Jetty, and Jetty are trademarks of the Eclipse Foundation.\n\nCopyright\n---------\nAll contributions are the property of the respective authors or of\nentities to which copyright has been assigned by the authors (eg. employer).\n\nDeclared Project Licenses\n-------------------------\nThis artifacts of this project are made available under the terms of:\n\n  * the Eclipse Public License v2.0\n    https://www.eclipse.org/legal/epl-2.0\n    SPDX-License-Identifier: EPL-2.0\n\n  or\n\n  * the Apache License, Version 2.0\n    https://www.apache.org/licenses/LICENSE-2.0\n    SPDX-License-Identifier: Apache-2.0\n\nThe following dependencies are EPL.\n * org.eclipse.jetty.orbit:org.eclipse.jdt.core\n\nThe following dependencies are EPL and ASL2.\n * org.eclipse.jetty.orbit:javax.security.auth.message\n\nThe following dependencies are EPL and CDDL 1.0.\n * org.eclipse.jetty.orbit:javax.mail.glassfish\n\nThe following dependencies are CDDL + GPLv2 with classpath exception.\nhttps://glassfish.dev.java.net/nonav/public/CDDL+GPL.html\n\n * jakarta.servlet:jakarta.servlet-api\n * javax.annotation:javax.annotation-api\n * javax.transaction:javax.transaction-api\n * javax.websocket:javax.websocket-api\n\nThe following dependencies are licensed by the OW2 Foundation according to the\nterms of http://asm.ow2.org/license.html\n\n * org.ow2.asm:asm-commons\n * org.ow2.asm:asm\n\nThe following dependencies are ASL2 licensed.\n\n * org.apache.taglibs:taglibs-standard-spec\n * org.apache.taglibs:taglibs-standard-impl\n\nThe following dependencies are ASL2 licensed.  Based on selected classes from\nfollowing Apache Tomcat jars, all ASL2 licensed.\n\n * org.mortbay.jasper:apache-jsp\n * org.apache.tomcat:tomcat-jasper\n * org.apache.tomcat:tomcat-juli\n * org.apache.tomcat:tomcat-jsp-api\n * org.apache.tomcat:tomcat-el-api\n * org.apache.tomcat:tomcat-jasper-el\n * org.apache.tomcat:tomcat-api\n * org.apache.tomcat:tomcat-util-scan\n * org.apache.tomcat:tomcat-util\n * org.mortbay.jasper:apache-el\n * org.apache.tomcat:tomcat-jasper-el\n * org.apache.tomcat:tomcat-el-api\n\nThe following artifacts are CDDL + GPLv2 with classpath exception.\nhttps://glassfish.dev.java.net/nonav/public/CDDL+GPL.html\n\n * org.eclipse.jetty.toolchain:jetty-schemas\n\nCryptography\n------------\nContent may contain encryption software. The country in which you are currently\nmay have restrictions on the import, possession, and use, and/or re-export to\nanother country, of encryption software. BEFORE using any encryption software,\nplease check the country's laws, regulations and policies concerning the import,\npossession, or use, and re-export of encryption software, to see if this is\npermitted.\n\nThe UnixCrypt.java code implements the one way cryptography used by\nUnix systems for simple password protection.  Copyright 1996 Aki Yoshida,\nmodified April 2001  by Iris Van den Broeke, Daniel Deville.\nPermission to use, copy, modify and distribute UnixCrypt\nfor non-commercial or commercial purposes and without fee is\ngranted provided that the copyright notice appears in all copies.\n\nThe binary distribution of this product bundles binaries of\nSnappy for Java 1.0.4.1,\nwhich has the following notices:\n * This product includes software developed by Google\n    Snappy: http://code.google.com/p/snappy/ (New BSD License)\n\n   This product includes software developed by Apache\n    PureJavaCrc32C from apache-hadoop-common http://hadoop.apache.org/\n    (Apache 2.0 license)\n\n   This library contains statically linked libstdc++. This inclusion is allowed by\n   \"GCC RUntime Library Exception\"\n   http://gcc.gnu.org/onlinedocs/libstdc++/manual/license.html\n\n   == Contributors ==\n     * Tatu Saloranta\n       * Providing benchmark suite\n     * Alec Wysoker\n       * Performance and memory usage improvement\n\nApache Commons Collections\nCopyright 2001-2015 The Apache Software Foundation\n\nApache Commons Configuration\nCopyright 2001-2008 The Apache Software Foundation\n\nApache Jakarta Commons Digester\nCopyright 2001-2006 The Apache Software Foundation\n\nApache Commons BeanUtils\nCopyright 2000-2008 The Apache Software Foundation\n\nCurator Client\nCopyright 2011-2015 The Apache Software Foundation\n\n# Jackson JSON processor\n\nJackson is a high-performance, Free/Open Source JSON processing library.\nIt was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has\nbeen in development since 2007.\nIt is currently developed by a community of developers, as well as supported\ncommercially by FasterXML.com.\n\n## Licensing\n\nJackson core and extension components may licensed under different licenses.\nTo find the details that apply to this artifact see the accompanying LICENSE file.\nFor more information, including possible other licensing options, contact\nFasterXML.com (http://fasterxml.com).\n\n## Credits\n\nA list of contributors may be found from CREDITS file, which is included\nin some artifacts (usually source distributions); but is always available\nfrom the source code management (SCM) system project uses.\n\nApache HttpCore\nCopyright 2005-2017 The Apache Software Foundation\n\nCurator Recipes\nCopyright 2011-2015 The Apache Software Foundation\n\nCurator Framework\nCopyright 2011-2015 The Apache Software Foundation\n\nApache Commons Lang\nCopyright 2001-2016 The Apache Software Foundation\n\nThis product includes software from the Spring Framework,\nunder the Apache License 2.0 (see: StringUtils.containsWhitespace())\n\nApache Commons Math\nCopyright 2001-2015 The Apache Software Foundation\n\nThis product includes software developed for Orekit by\nCS Systèmes d'Information (http://www.c-s.fr/)\nCopyright 2010-2012 CS Systèmes d'Information\n\nApache log4j\nCopyright 2007 The Apache Software Foundation\n\n# Compress LZF\n\nThis library contains efficient implementation of LZF compression format,\nas well as additional helper classes that build on JDK-provided gzip (deflat)\ncodec.\n\nLibrary is licensed under Apache License 2.0, as per accompanying LICENSE file.\n\n## Credit\n\nLibrary has been written by Tatu Saloranta (tatu.saloranta@iki.fi).\nIt was started at Ning, inc., as an official Open Source process used by\nplatform backend, but after initial versions has been developed outside of\nNing by supporting community.\n\nOther contributors include:\n\n* Jon Hartlaub (first versions of streaming reader/writer; unit tests)\n* Cedrik Lime: parallel LZF implementation\n\nVarious community members have contributed bug reports, and suggested minor\nfixes; these can be found from file \"VERSION.txt\" in SCM.\n\nApache Commons Net\nCopyright 2001-2012 The Apache Software Foundation\n\n\nJackson core and extension components may be licensed under different licenses.\nTo find the details that apply to this artifact see the accompanying LICENSE file.\nFor more information, including possible other licensing options, contact\nFasterXML.com (http://fasterxml.com).\n\nApache Ivy (TM)\nCopyright 2007-2014 The Apache Software Foundation\n\nPortions of Ivy were originally developed at\nJayasoft SARL (http://www.jayasoft.fr/)\nand are licensed to the Apache Software Foundation under the\n\"Software Grant License Agreement\"\n\nSSH and SFTP support is provided by the JCraft JSch package,\nwhich is open source software, available under\nthe terms of a BSD style license.\nThe original software and related information is available\nat http://www.jcraft.com/jsch/.\n\n\nORC Core\nCopyright 2013-2018 The Apache Software Foundation\n\nApache Commons Lang\nCopyright 2001-2011 The Apache Software Foundation\n\nORC MapReduce\nCopyright 2013-2018 The Apache Software Foundation\n\nApache Parquet Format\nCopyright 2017 The Apache Software Foundation\n\nArrow Vectors\nCopyright 2017 The Apache Software Foundation\n\nArrow Format\nCopyright 2017 The Apache Software Foundation\n\nArrow Memory\nCopyright 2017 The Apache Software Foundation\n\nApache Commons CLI\nCopyright 2001-2009 The Apache Software Foundation\n\nApache Commons Daemon\nCopyright 1999-2019 The Apache Software Foundation\n\nApache Commons IO\nCopyright 2002-2012 The Apache Software Foundation\n\nApache Parquet Hadoop Bundle (Incubating)\nCopyright 2015 The Apache Software Foundation\n\nApache Extras Companion for log4j 1.2.\nCopyright 2007 The Apache Software Foundation\n\nHive Metastore\nCopyright 2016 The Apache Software Foundation\n\nApache Commons Logging\nCopyright 2003-2013 The Apache Software Foundation\n\n=========================================================================\n==  NOTICE file corresponding to section 4(d) of the Apache License,   ==\n==  Version 2.0, in this case for the DataNucleus distribution.        ==\n=========================================================================\n\n===================================================================\nThis product includes software developed by many individuals,\nincluding the following:\n===================================================================\nErik Bengtson\nAndy Jefferson\n\n===================================================================\nThis product has included contributions from some individuals,\nincluding the following:\n===================================================================\n\n===================================================================\nThis product includes software developed by many individuals,\nincluding the following:\n===================================================================\nAndy Jefferson\nErik Bengtson\nJoerg von Frantzius\nMarco Schulze\n\n===================================================================\nThis product has included contributions from some individuals,\nincluding the following:\n===================================================================\nBarry Haddow\nRalph Ullrich\nDavid Ezzio\nBrendan de Beer\nDavid Eaves\nMartin Taal\nTony Lai\nRoland Szabo\nAnton Troshin (Timesten)\n\n===================================================================\nThis product also includes software developed by the TJDO project\n(http://tjdo.sourceforge.net/).\n===================================================================\n\n===================================================================\nThis product also includes software developed by the Apache Commons project\n(http://commons.apache.org/).\n===================================================================\n\nApache Commons Pool\nCopyright 1999-2009 The Apache Software Foundation\n\nApache Commons DBCP\nCopyright 2001-2010 The Apache Software Foundation\n\nApache Java Data Objects (JDO)\nCopyright 2005-2006 The Apache Software Foundation\n\nApache Jakarta HttpClient\nCopyright 1999-2007 The Apache Software Foundation\n\nApache HttpClient\nCopyright 1999-2017 The Apache Software Foundation\n\nApache Commons Codec\nCopyright 2002-2014 The Apache Software Foundation\n\nsrc/test/org/apache/commons/codec/language/DoubleMetaphoneTest.java\ncontains test data from http://aspell.net/test/orig/batch0.tab.\nCopyright (C) 2002 Kevin Atkinson (kevina@gnu.org)\n\n===============================================================================\n\nThe content of package org.apache.commons.codec.language.bm has been translated\nfrom the original php source code available at http://stevemorse.org/phoneticinfo.htm\nwith permission from the original authors.\nOriginal source copyright:\nCopyright (c) 2008 Alexander Beider & Stephen P. Morse.\n\n=============================================================================\n= NOTICE file corresponding to section 4d of the Apache License Version 2.0 =\n=============================================================================\nThis product includes software developed by\nJoda.org (http://www.joda.org/).\n\n===================================================================\nThis product has included contributions from some individuals,\nincluding the following:\n===================================================================\nJoerg von Frantzius\nThomas Marti\nBarry Haddow\nMarco Schulze\nRalph Ullrich\nDavid Ezzio\nBrendan de Beer\nDavid Eaves\nMartin Taal\nTony Lai\nRoland Szabo\nMarcus Mennemeier\nXuan Baldauf\nEric Sultan\n\nApache Thrift\nCopyright 2006-2010 The Apache Software Foundation.\n\n=========================================================================\n==  NOTICE file corresponding to section 4(d) of the Apache License,\n==  Version 2.0, in this case for the Apache Derby distribution.\n==\n==  DO NOT EDIT THIS FILE DIRECTLY. IT IS GENERATED\n==  BY THE buildnotice TARGET IN THE TOP LEVEL build.xml FILE.\n==\n=========================================================================\n\nApache Derby\nCopyright 2004-2015 The Apache Software Foundation\n\n=========================================================================\n\nPortions of Derby were originally developed by\nInternational Business Machines Corporation and are\nlicensed to the Apache Software Foundation under the\n\"Software Grant and Corporate Contribution License Agreement\",\ninformally known as the \"Derby CLA\".\nThe following copyright notice(s) were affixed to portions of the code\nwith which this file is now or was at one time distributed\nand are placed here unaltered.\n\n(C) Copyright 1997,2004 International Business Machines Corporation.  All rights reserved.\n\n(C) Copyright IBM Corp. 2003.\n\nThe portion of the functionTests under 'nist' was originally\ndeveloped by the National Institute of Standards and Technology (NIST),\nan agency of the United States Department of Commerce, and adapted by\nInternational Business Machines Corporation in accordance with the NIST\nSoftware Acknowledgment and Redistribution document at\nhttp://www.itl.nist.gov/div897/ctg/sql_form.htm\n\nThe JDBC apis for small devices and JDBC3 (under java/stubs/jsr169 and\njava/stubs/jdbc3) were produced by trimming sources supplied by the\nApache Harmony project. In addition, the Harmony SerialBlob and\nSerialClob implementations are used. The following notice covers the Harmony sources:\n\nPortions of Harmony were originally developed by\nIntel Corporation and are licensed to the Apache Software\nFoundation under the \"Software Grant and Corporate Contribution\nLicense Agreement\", informally known as the \"Intel Harmony CLA\".\n\nThe Derby build relies on source files supplied by the Apache Felix\nproject. The following notice covers the Felix files:\n\n  Apache Felix Main\n  Copyright 2008 The Apache Software Foundation\n\n  I. Included Software\n\n  This product includes software developed at\n  The Apache Software Foundation (http://www.apache.org/).\n  Licensed under the Apache License 2.0.\n\n  This product includes software developed at\n  The OSGi Alliance (http://www.osgi.org/).\n  Copyright (c) OSGi Alliance (2000, 2007).\n  Licensed under the Apache License 2.0.\n\n  This product includes software from http://kxml.sourceforge.net.\n  Copyright (c) 2002,2003, Stefan Haustein, Oberhausen, Rhld., Germany.\n  Licensed under BSD License.\n\n  II. Used Software\n\n  This product uses software developed at\n  The OSGi Alliance (http://www.osgi.org/).\n  Copyright (c) OSGi Alliance (2000, 2007).\n  Licensed under the Apache License 2.0.\n\n  III. License Summary\n  - Apache License 2.0\n  - BSD License\n\nThe Derby build relies on jar files supplied by the Apache Lucene\nproject. The following notice covers the Lucene files:\n\nApache Lucene\nCopyright 2013 The Apache Software Foundation\n\nIncludes software from other Apache Software Foundation projects,\nincluding, but not limited to:\n - Apache Ant\n - Apache Jakarta Regexp\n - Apache Commons\n - Apache Xerces\n\nICU4J, (under analysis/icu) is licensed under an MIT styles license\nand Copyright (c) 1995-2008 International Business Machines Corporation and others\n\nSome data files (under analysis/icu/src/data) are derived from Unicode data such\nas the Unicode Character Database. See http://unicode.org/copyright.html for more\ndetails.\n\nThe Google Code Prettify is Apache License 2.0.\nSee http://code.google.com/p/google-code-prettify/\n\nJUnit (junit-4.10) is licensed under the Common Public License v. 1.0\nSee http://junit.sourceforge.net/cpl-v10.html\n\nThis product includes code (JaspellTernarySearchTrie) from Java Spelling Checkin\ng Package (jaspell): http://jaspell.sourceforge.net/\nLicense: The BSD License (http://www.opensource.org/licenses/bsd-license.php)\n\nThis product includes software developed by the JDOM Project (http://www.jdom.org/)\nLicense: https://raw.githubusercontent.com/hunterhacker/jdom/master/LICENSE.txt\n\nThe snowball stemmers in\n  analysis/common/src/java/net/sf/snowball\nwere developed by Martin Porter and Richard Boulton.\nThe snowball stopword lists in\n  analysis/common/src/resources/org/apache/lucene/analysis/snowball\nwere developed by Martin Porter and Richard Boulton.\nThe full snowball package is available from\n  http://snowball.tartarus.org/\n\nThe KStem stemmer in\n  analysis/common/src/org/apache/lucene/analysis/en\nwas developed by Bob Krovetz and Sergio Guzman-Lara (CIIR-UMass Amherst)\nunder the BSD-license.\n\nThe Arabic,Persian,Romanian,Bulgarian, and Hindi analyzers (common) come with a default\nstopword list that is BSD-licensed created by Jacques Savoy.  These files reside in:\nanalysis/common/src/resources/org/apache/lucene/analysis/ar/stopwords.txt,\nanalysis/common/src/resources/org/apache/lucene/analysis/fa/stopwords.txt,\nanalysis/common/src/resources/org/apache/lucene/analysis/ro/stopwords.txt,\nanalysis/common/src/resources/org/apache/lucene/analysis/bg/stopwords.txt,\nanalysis/common/src/resources/org/apache/lucene/analysis/hi/stopwords.txt\nSee http://members.unine.ch/jacques.savoy/clef/index.html.\n\nThe German,Spanish,Finnish,French,Hungarian,Italian,Portuguese,Russian and Swedish light stemmers\n(common) are based on BSD-licensed reference implementations created by Jacques Savoy and\nLjiljana Dolamic. These files reside in:\nanalysis/common/src/java/org/apache/lucene/analysis/de/GermanLightStemmer.java\nanalysis/common/src/java/org/apache/lucene/analysis/de/GermanMinimalStemmer.java\nanalysis/common/src/java/org/apache/lucene/analysis/es/SpanishLightStemmer.java\nanalysis/common/src/java/org/apache/lucene/analysis/fi/FinnishLightStemmer.java\nanalysis/common/src/java/org/apache/lucene/analysis/fr/FrenchLightStemmer.java\nanalysis/common/src/java/org/apache/lucene/analysis/fr/FrenchMinimalStemmer.java\nanalysis/common/src/java/org/apache/lucene/analysis/hu/HungarianLightStemmer.java\nanalysis/common/src/java/org/apache/lucene/analysis/it/ItalianLightStemmer.java\nanalysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseLightStemmer.java\nanalysis/common/src/java/org/apache/lucene/analysis/ru/RussianLightStemmer.java\nanalysis/common/src/java/org/apache/lucene/analysis/sv/SwedishLightStemmer.java\n\nThe Stempel analyzer (stempel) includes BSD-licensed software developed\nby the Egothor project http://egothor.sf.net/, created by Leo Galambos, Martin Kvapil,\nand Edmond Nolan.\n\nThe Polish analyzer (stempel) comes with a default\nstopword list that is BSD-licensed created by the Carrot2 project. The file resides\nin stempel/src/resources/org/apache/lucene/analysis/pl/stopwords.txt.\nSee http://project.carrot2.org/license.html.\n\nThe SmartChineseAnalyzer source code (smartcn) was\nprovided by Xiaoping Gao and copyright 2009 by www.imdict.net.\n\nWordBreakTestUnicode_*.java (under modules/analysis/common/src/test/)\nis derived from Unicode data such as the Unicode Character Database.\nSee http://unicode.org/copyright.html for more details.\n\nThe Morfologik analyzer (morfologik) includes BSD-licensed software\ndeveloped by Dawid Weiss and Marcin Miłkowski (http://morfologik.blogspot.com/).\n\nMorfologik uses data from Polish ispell/myspell dictionary\n(http://www.sjp.pl/slownik/en/) licenced on the terms of (inter alia)\nLGPL and Creative Commons ShareAlike.\n\nMorfologic includes data from BSD-licensed dictionary of Polish (SGJP)\n(http://sgjp.pl/morfeusz/)\n\nServlet-api.jar and javax.servlet-*.jar are under the CDDL license, the original\nsource code for this can be found at http://www.eclipse.org/jetty/downloads.php\n\n===========================================================================\nKuromoji Japanese Morphological Analyzer - Apache Lucene Integration\n===========================================================================\n\nThis software includes a binary and/or source version of data from\n\n  mecab-ipadic-2.7.0-20070801\n\nwhich can be obtained from\n\n  http://atilika.com/releases/mecab-ipadic/mecab-ipadic-2.7.0-20070801.tar.gz\n\nor\n\n  http://jaist.dl.sourceforge.net/project/mecab/mecab-ipadic/2.7.0-20070801/mecab-ipadic-2.7.0-20070801.tar.gz\n\n===========================================================================\nmecab-ipadic-2.7.0-20070801 Notice\n===========================================================================\n\nNara Institute of Science and Technology (NAIST),\nthe copyright holders, disclaims all warranties with regard to this\nsoftware, including all implied warranties of merchantability and\nfitness, in no event shall NAIST be liable for\nany special, indirect or consequential damages or any damages\nwhatsoever resulting from loss of use, data or profits, whether in an\naction of contract, negligence or other tortuous action, arising out\nof or in connection with the use or performance of this software.\n\nA large portion of the dictionary entries\noriginate from ICOT Free Software.  The following conditions for ICOT\nFree Software applies to the current dictionary as well.\n\nEach User may also freely distribute the Program, whether in its\noriginal form or modified, to any third party or parties, PROVIDED\nthat the provisions of Section 3 (\"NO WARRANTY\") will ALWAYS appear\non, or be attached to, the Program, which is distributed substantially\nin the same form as set out herein and that such intended\ndistribution, if actually made, will neither violate or otherwise\ncontravene any of the laws and regulations of the countries having\njurisdiction over the User or the intended distribution itself.\n\nNO WARRANTY\n\nThe program was produced on an experimental basis in the course of the\nresearch and development conducted during the project and is provided\nto users as so produced on an experimental basis.  Accordingly, the\nprogram is provided without any warranty whatsoever, whether express,\nimplied, statutory or otherwise.  The term \"warranty\" used herein\nincludes, but is not limited to, any warranty of the quality,\nperformance, merchantability and fitness for a particular purpose of\nthe program and the nonexistence of any infringement or violation of\nany right of any third party.\n\nEach user of the program will agree and understand, and be deemed to\nhave agreed and understood, that there is no warranty whatsoever for\nthe program and, accordingly, the entire risk arising from or\notherwise connected with the program is assumed by the user.\n\nTherefore, neither ICOT, the copyright holder, or any other\norganization that participated in or was otherwise related to the\ndevelopment of the program and their respective officials, directors,\nofficers and other employees shall be held liable for any and all\ndamages, including, without limitation, general, special, incidental\nand consequential damages, arising out of or otherwise in connection\nwith the use or inability to use the program or any product, material\nor result produced or otherwise obtained by using the program,\nregardless of whether they have been advised of, or otherwise had\nknowledge of, the possibility of such damages at any time during the\nproject or thereafter.  Each user will be deemed to have agreed to the\nforegoing by his or her commencement of use of the program.  The term\n\"use\" as used herein includes, but is not limited to, the use,\nmodification, copying and distribution of the program and the\nproduction of secondary products from the program.\n\nIn the case where the program, whether in its original form or\nmodified, was distributed or delivered to or received by a user from\nany person, organization or entity other than ICOT, unless it makes or\ngrants independently of ICOT any specific warranty to the user in\nwriting, such person, organization or entity, will also be exempted\nfrom and not be held liable to the user for any such damages as noted\nabove as far as the program is concerned.\n\nThe Derby build relies on a jar file supplied by the JSON Simple\nproject, hosted at https://code.google.com/p/json-simple/.\nThe JSON simple jar file is licensed under the Apache 2.0 License.\n\nHive CLI\nCopyright 2016 The Apache Software Foundation\n\nHive JDBC\nCopyright 2016 The Apache Software Foundation\n\n\nChill is a set of Scala extensions for Kryo.\nCopyright 2012 Twitter, Inc.\n\nThird Party Dependencies:\n\nKryo 2.17\nBSD 3-Clause License\nhttp://code.google.com/p/kryo\n\nCommons-Codec 1.7\nApache Public License 2.0\nhttp://hadoop.apache.org\n\n\n\nBreeze is distributed under an Apache License V2.0 (See LICENSE)\n\n===============================================================================\n\nProximal algorithms outlined in Proximal.scala (package breeze.optimize.proximal)\nare based on https://github.com/cvxgrp/proximal (see LICENSE for details) and distributed with\nCopyright (c) 2014 by Debasish Das (Verizon), all rights reserved.\n\n===============================================================================\n\nQuadraticMinimizer class in package breeze.optimize.proximal is distributed with Copyright (c)\n2014, Debasish Das (Verizon), all rights reserved.\n\n===============================================================================\n\nNonlinearMinimizer class in package breeze.optimize.proximal is distributed with Copyright (c)\n2015, Debasish Das (Verizon), all rights reserved.\n\n\nstream-lib\nCopyright 2016 AddThis\n\nThis product includes software developed by AddThis.\n\nThis product also includes code adapted from:\n\nApache Solr (http://lucene.apache.org/solr/)\nCopyright 2014 The Apache Software Foundation\n\nApache Mahout (http://mahout.apache.org/)\nCopyright 2014 The Apache Software Foundation\n\nscala-xml\nCopyright (c) 2002-2019 EPFL\nCopyright (c) 2011-2019 Lightbend, Inc.\n\nscala-xml includes software developed at\nLAMP/EPFL (https://lamp.epfl.ch/) and\nLightbend, Inc. (https://www.lightbend.com/).\n\nLicensed under the Apache License, Version 2.0 (the \"License\").\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\ndropwizard-metrics-hadoop-metrics2-reporter\nCopyright 2016 Josh Elser\n\nHive Beeline\nCopyright 2019 The Apache Software Foundation\n\nHive CLI\nCopyright 2019 The Apache Software Foundation\n\nHive Common\nCopyright 2019 The Apache Software Foundation\n\nHive JDBC\nCopyright 2019 The Apache Software Foundation\n\nHive Query Language\nCopyright 2019 The Apache Software Foundation\n\nHive Llap Common\nCopyright 2019 The Apache Software Foundation\n\nHive Metastore\nCopyright 2019 The Apache Software Foundation\n\nHive Serde\nCopyright 2019 The Apache Software Foundation\n\nHive Service RPC\nCopyright 2019 The Apache Software Foundation\n\nHive Shims\nCopyright 2019 The Apache Software Foundation\n\nHive Shims 0.23\nCopyright 2019 The Apache Software Foundation\n\nHive Shims Common\nCopyright 2019 The Apache Software Foundation\n\nHive Shims Scheduler\nCopyright 2019 The Apache Software Foundation\n\nHive Storage API\nCopyright 2018 The Apache Software Foundation\n\nHive Vector-Code-Gen Utilities\nCopyright 2019 The Apache Software Foundation\n\n\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   Copyright 2015-2015 DataNucleus\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\nAndroid JSON library\nCopyright (C) 2010 The Android Open Source Project\n\nThis product includes software developed by\nThe Android Open Source Project\n\nApache Yetus - Audience Annotations\nCopyright 2015-2017 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\nEhcache V3\nCopyright 2014-2016 Terracotta, Inc.\n\nThe product includes software from the Apache Commons Lang project,\nunder the Apache License 2.0 (see: org.ehcache.impl.internal.classes.commonslang)\n\nApache Geronimo JCache Spec 1.0\nCopyright 2003-2014 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\n\n\nToken provider\nCopyright 2014-2017 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nMetrics\nCopyright 2010-2013 Coda Hale and Yammer, Inc.\n\nThis product includes software developed by Coda Hale and Yammer, Inc.\n\nThis product includes code derived from the JSR-166 project (ThreadLocalRandom, Striped64,\nLongAdder), which was released with the following comments:\n\n    Written by Doug Lea with assistance from members of JCP JSR-166\n    Expert Group and released to the public domain, as explained at\n    http://creativecommons.org/publicdomain/zero/1.0/"
        },
        {
          "name": "R",
          "type": "tree",
          "content": null
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 4.37,
          "content": "# Apache Spark\n\nSpark is a unified analytics engine for large-scale data processing. It provides\nhigh-level APIs in Scala, Java, Python, and R, and an optimized engine that\nsupports general computation graphs for data analysis. It also supports a\nrich set of higher-level tools including Spark SQL for SQL and DataFrames,\npandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing,\nand Structured Streaming for stream processing.\n\n- Official version: <https://spark.apache.org/>\n- Development version: <https://apache.github.io/spark/>\n\n[![GitHub Actions Build](https://github.com/apache/spark/actions/workflows/build_main.yml/badge.svg)](https://github.com/apache/spark/actions/workflows/build_main.yml)\n[![PySpark Coverage](https://codecov.io/gh/apache/spark/branch/master/graph/badge.svg)](https://codecov.io/gh/apache/spark)\n[![PyPI Downloads](https://static.pepy.tech/personalized-badge/pyspark?period=month&units=international_system&left_color=black&right_color=orange&left_text=PyPI%20downloads)](https://pypi.org/project/pyspark/)\n\n\n## Online Documentation\n\nYou can find the latest Spark documentation, including a programming\nguide, on the [project web page](https://spark.apache.org/documentation.html).\nThis README file only contains basic setup instructions.\n\n## Building Spark\n\nSpark is built using [Apache Maven](https://maven.apache.org/).\nTo build Spark and its example programs, run:\n\n```bash\n./build/mvn -DskipTests clean package\n```\n\n(You do not need to do this if you downloaded a pre-built package.)\n\nMore detailed documentation is available from the project site, at\n[\"Building Spark\"](https://spark.apache.org/docs/latest/building-spark.html).\n\nFor general development tips, including info on developing Spark using an IDE, see [\"Useful Developer Tools\"](https://spark.apache.org/developer-tools.html).\n\n## Interactive Scala Shell\n\nThe easiest way to start using Spark is through the Scala shell:\n\n```bash\n./bin/spark-shell\n```\n\nTry the following command, which should return 1,000,000,000:\n\n```scala\nscala> spark.range(1000 * 1000 * 1000).count()\n```\n\n## Interactive Python Shell\n\nAlternatively, if you prefer Python, you can use the Python shell:\n\n```bash\n./bin/pyspark\n```\n\nAnd run the following command, which should also return 1,000,000,000:\n\n```python\n>>> spark.range(1000 * 1000 * 1000).count()\n```\n\n## Example Programs\n\nSpark also comes with several sample programs in the `examples` directory.\nTo run one of them, use `./bin/run-example <class> [params]`. For example:\n\n```bash\n./bin/run-example SparkPi\n```\n\nwill run the Pi example locally.\n\nYou can set the MASTER environment variable when running examples to submit\nexamples to a cluster. This can be spark:// URL,\n\"yarn\" to run on YARN, and \"local\" to run\nlocally with one thread, or \"local[N]\" to run locally with N threads. You\ncan also use an abbreviated class name if the class is in the `examples`\npackage. For instance:\n\n```bash\nMASTER=spark://host:7077 ./bin/run-example SparkPi\n```\n\nMany of the example programs print usage help if no params are given.\n\n## Running Tests\n\nTesting first requires [building Spark](#building-spark). Once Spark is built, tests\ncan be run using:\n\n```bash\n./dev/run-tests\n```\n\nPlease see the guidance on how to\n[run tests for a module, or individual tests](https://spark.apache.org/developer-tools.html#individual-tests).\n\nThere is also a Kubernetes integration test, see resource-managers/kubernetes/integration-tests/README.md\n\n## A Note About Hadoop Versions\n\nSpark uses the Hadoop core library to talk to HDFS and other Hadoop-supported\nstorage systems. Because the protocols have changed in different versions of\nHadoop, you must build Spark against the same version that your cluster runs.\n\nPlease refer to the build documentation at\n[\"Specifying the Hadoop Version and Enabling YARN\"](https://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version-and-enabling-yarn)\nfor detailed guidance on building for a particular distribution of Hadoop, including\nbuilding for particular Hive and Hive Thriftserver distributions.\n\n## Configuration\n\nPlease refer to the [Configuration Guide](https://spark.apache.org/docs/latest/configuration.html)\nin the online documentation for an overview on how to configure Spark.\n\n## Contributing\n\nPlease review the [Contribution to Spark guide](https://spark.apache.org/contributing.html)\nfor information on how to get started contributing to the project.\n"
        },
        {
          "name": "assembly",
          "type": "tree",
          "content": null
        },
        {
          "name": "bin",
          "type": "tree",
          "content": null
        },
        {
          "name": "binder",
          "type": "tree",
          "content": null
        },
        {
          "name": "build",
          "type": "tree",
          "content": null
        },
        {
          "name": "common",
          "type": "tree",
          "content": null
        },
        {
          "name": "conf",
          "type": "tree",
          "content": null
        },
        {
          "name": "connector",
          "type": "tree",
          "content": null
        },
        {
          "name": "core",
          "type": "tree",
          "content": null
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "dev",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "graphx",
          "type": "tree",
          "content": null
        },
        {
          "name": "hadoop-cloud",
          "type": "tree",
          "content": null
        },
        {
          "name": "launcher",
          "type": "tree",
          "content": null
        },
        {
          "name": "licenses-binary",
          "type": "tree",
          "content": null
        },
        {
          "name": "licenses",
          "type": "tree",
          "content": null
        },
        {
          "name": "mllib-local",
          "type": "tree",
          "content": null
        },
        {
          "name": "mllib",
          "type": "tree",
          "content": null
        },
        {
          "name": "pom.xml",
          "type": "blob",
          "size": 131.23,
          "content": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!--\n  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n  ~ contributor license agreements.  See the NOTICE file distributed with\n  ~ this work for additional information regarding copyright ownership.\n  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n  ~ (the \"License\"); you may not use this file except in compliance with\n  ~ the License.  You may obtain a copy of the License at\n  ~\n  ~    http://www.apache.org/licenses/LICENSE-2.0\n  ~\n  ~ Unless required by applicable law or agreed to in writing, software\n  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  ~ See the License for the specific language governing permissions and\n  ~ limitations under the License.\n  -->\n\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n  <parent>\n    <groupId>org.apache</groupId>\n    <artifactId>apache</artifactId>\n    <version>18</version>\n  </parent>\n  <groupId>org.apache.spark</groupId>\n  <artifactId>spark-parent_2.13</artifactId>\n  <version>4.0.0-SNAPSHOT</version>\n  <packaging>pom</packaging>\n  <name>Spark Project Parent POM</name>\n  <url>https://spark.apache.org/</url>\n  <licenses>\n    <license>\n      <name>Apache-2.0</name>\n      <url>http://www.apache.org/licenses/LICENSE-2.0.html</url>\n      <distribution>repo</distribution>\n    </license>\n  </licenses>\n  <scm>\n    <connection>scm:git:git@github.com:apache/spark.git</connection>\n    <developerConnection>scm:git:https://gitbox.apache.org/repos/asf/spark.git</developerConnection>\n    <url>scm:git:git@github.com:apache/spark.git</url>\n    <tag>HEAD</tag>\n  </scm>\n  <organization>\n    <name>Apache Software Foundation</name>\n    <url>https://www.apache.org</url>\n  </organization>\n  <issueManagement>\n    <system>JIRA</system>\n    <url>https://issues.apache.org/jira/browse/SPARK</url>\n  </issueManagement>\n\n  <mailingLists>\n    <mailingList>\n      <name>Dev Mailing List</name>\n      <post>dev@spark.apache.org</post>\n      <subscribe>dev-subscribe@spark.apache.org</subscribe>\n      <unsubscribe>dev-unsubscribe@spark.apache.org</unsubscribe>\n    </mailingList>\n\n    <mailingList>\n      <name>User Mailing List</name>\n      <post>user@spark.apache.org</post>\n      <subscribe>user-subscribe@spark.apache.org</subscribe>\n      <unsubscribe>user-unsubscribe@spark.apache.org</unsubscribe>\n    </mailingList>\n\n    <mailingList>\n      <name>Commits Mailing List</name>\n      <post>commits@spark.apache.org</post>\n      <subscribe>commits-subscribe@spark.apache.org</subscribe>\n      <unsubscribe>commits-unsubscribe@spark.apache.org</unsubscribe>\n    </mailingList>\n  </mailingLists>\n\n  <modules>\n    <module>common/sketch</module>\n    <module>common/kvstore</module>\n    <module>common/network-common</module>\n    <module>common/network-shuffle</module>\n    <module>common/unsafe</module>\n    <module>common/utils</module>\n    <module>common/variant</module>\n    <module>common/tags</module>\n    <module>sql/connect/shims</module>\n    <module>core</module>\n    <module>graphx</module>\n    <module>mllib</module>\n    <module>mllib-local</module>\n    <module>tools</module>\n    <module>streaming</module>\n    <module>sql/api</module>\n    <module>sql/catalyst</module>\n    <module>sql/core</module>\n    <module>sql/hive</module>\n    <module>sql/connect/server</module>\n    <module>sql/connect/common</module>\n    <module>assembly</module>\n    <module>examples</module>\n    <module>repl</module>\n    <module>launcher</module>\n    <module>connector/kafka-0-10-token-provider</module>\n    <module>connector/kafka-0-10</module>\n    <module>connector/kafka-0-10-assembly</module>\n    <module>connector/kafka-0-10-sql</module>\n    <module>connector/avro</module>\n    <module>connector/connect/client/jvm</module>\n    <module>connector/protobuf</module>\n    <!-- See additional modules enabled by profiles below -->\n  </modules>\n\n  <properties>\n    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n    <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>\n    <java.version>17</java.version>\n    <maven.compiler.release>${java.version}</maven.compiler.release>\n    <maven.version>3.9.9</maven.version>\n    <exec-maven-plugin.version>3.2.0</exec-maven-plugin.version>\n    <sbt.project.name>spark</sbt.project.name>\n    <asm.version>9.7.1</asm.version>\n    <slf4j.version>2.0.16</slf4j.version>\n    <log4j.version>2.24.3</log4j.version>\n    <!-- make sure to update IsolatedClientLoader whenever this version is changed -->\n    <hadoop.version>3.4.1</hadoop.version>\n    <!-- SPARK-41247: When updating `protobuf.version`, also need to update `protoVersion` in `SparkBuild.scala` -->\n    <protobuf.version>4.29.1</protobuf.version>\n    <protoc-jar-maven-plugin.version>3.11.4</protoc-jar-maven-plugin.version>\n    <zookeeper.version>3.9.3</zookeeper.version>\n    <curator.version>5.7.1</curator.version>\n    <hive.group>org.apache.hive</hive.group>\n    <hive.classifier>core</hive.classifier>\n    <!-- Version used in Maven Hive dependency -->\n    <hive.version>2.3.10</hive.version>\n    <!-- note that this should be compatible with Kafka brokers version 0.10 and up -->\n    <kafka.version>3.9.0</kafka.version>\n    <!-- After 10.17.1.0, the minimum required version is JDK19 -->\n    <derby.version>10.16.1.1</derby.version>\n    <parquet.version>1.15.0</parquet.version>\n    <orc.version>2.1.0</orc.version>\n    <orc.classifier>shaded-protobuf</orc.classifier>\n    <jetty.version>11.0.24</jetty.version>\n    <jakartaservlet.version>5.0.0</jakartaservlet.version>\n    <!-- SPARK-46938: Required by Hive / LibThrift libs -->\n    <javaxservlet.version>4.0.1</javaxservlet.version>\n    <chill.version>0.10.0</chill.version>\n    <ivy.version>2.5.2</ivy.version>\n    <oro.version>2.0.8</oro.version>\n    <!--\n    If you change codahale.metrics.version, you also need to change\n    the link to metrics.dropwizard.io in docs/monitoring.md.\n    -->\n    <codahale.metrics.version>4.2.29</codahale.metrics.version>\n    <!-- Should be consistent with SparkBuild.scala and docs -->\n    <avro.version>1.12.0</avro.version>\n    <aws.kinesis.client.version>1.12.0</aws.kinesis.client.version>\n    <!-- Should be consistent with Kinesis client dependency -->\n    <aws.java.sdk.version>1.11.655</aws.java.sdk.version>\n    <aws.java.sdk.v2.version>2.24.6</aws.java.sdk.v2.version>\n    <!-- the producer is used in tests -->\n    <aws.kinesis.producer.version>0.12.8</aws.kinesis.producer.version>\n    <!-- Do not use 3.0.0: https://github.com/GoogleCloudDataproc/hadoop-connectors/issues/1114 -->\n    <gcs-connector.version>hadoop3-2.2.25</gcs-connector.version>\n    <!--  org.apache.httpcomponents/httpclient-->\n    <commons.httpclient.version>4.5.14</commons.httpclient.version>\n    <commons.httpcore.version>4.4.16</commons.httpcore.version>\n    <commons.math3.version>3.6.1</commons.math3.version>\n    <!-- managed up from 3.2.1 for SPARK-11652 -->\n    <commons.collections.version>3.2.2</commons.collections.version>\n    <commons.collections4.version>4.4</commons.collections4.version>\n    <scala.version>2.13.15</scala.version>\n    <scala.binary.version>2.13</scala.binary.version>\n    <scalatest-maven-plugin.version>2.2.0</scalatest-maven-plugin.version>\n    <scala-maven-plugin.version>4.9.2</scala-maven-plugin.version>\n    <maven.scaladoc.skip>false</maven.scaladoc.skip>\n    <versions-maven-plugin.version>2.16.2</versions-maven-plugin.version>\n    <!-- for now, not running scalafmt as part of default verify pipeline -->\n    <scalafmt.skip>true</scalafmt.skip>\n    <scalafmt.validateOnly>true</scalafmt.validateOnly>\n    <scalafmt.changedOnly>true</scalafmt.changedOnly>\n    <codehaus.jackson.version>1.9.13</codehaus.jackson.version>\n    <fasterxml.jackson.version>2.18.2</fasterxml.jackson.version>\n    <fasterxml.jackson.databind.version>2.18.2</fasterxml.jackson.databind.version>\n    <ws.xmlschema.version>2.3.1</ws.xmlschema.version>\n    <snappy.version>1.1.10.7</snappy.version>\n    <netlib.ludovic.dev.version>3.0.3</netlib.ludovic.dev.version>\n    <commons-codec.version>1.17.2</commons-codec.version>\n    <commons-compress.version>1.27.1</commons-compress.version>\n    <commons-io.version>2.18.0</commons-io.version>\n    <!-- To support Hive UDF jars built by Hive 2.0.0 ~ 2.3.9 and 3.0.0 ~ 3.1.3. -->\n    <commons-lang2.version>2.6</commons-lang2.version>\n    <!-- org.apache.commons/commons-lang3/-->\n    <commons-lang3.version>3.17.0</commons-lang3.version>\n    <!-- org.apache.commons/commons-pool2/-->\n    <commons-pool2.version>2.12.0</commons-pool2.version>\n    <datanucleus-core.version>4.1.17</datanucleus-core.version>\n    <guava.version>33.3.1-jre</guava.version>\n    <gson.version>2.11.0</gson.version>\n    <janino.version>3.1.9</janino.version>\n    <jersey.version>3.0.16</jersey.version>\n    <joda.version>2.13.0</joda.version>\n    <jodd.version>3.5.2</jodd.version>\n    <jsr305.version>3.0.0</jsr305.version>\n    <jaxb.version>2.2.11</jaxb.version>\n    <libthrift.version>0.16.0</libthrift.version>\n    <antlr4.version>4.13.1</antlr4.version>\n    <jpam.version>1.1</jpam.version>\n    <selenium.version>4.21.0</selenium.version>\n    <htmlunit3-driver.version>4.21.0</htmlunit3-driver.version>\n    <maven-antrun.version>3.1.0</maven-antrun.version>\n    <commons-crypto.version>1.1.0</commons-crypto.version>\n    <commons-cli.version>1.9.0</commons-cli.version>\n    <bouncycastle.version>1.79</bouncycastle.version>\n    <tink.version>1.16.0</tink.version>\n    <datasketches.version>6.1.1</datasketches.version>\n    <netty.version>4.1.115.Final</netty.version>\n    <netty-tcnative.version>2.0.69.Final</netty-tcnative.version>\n    <icu4j.version>76.1</icu4j.version>\n    <junit-jupiter.version>5.11.4</junit-jupiter.version>\n    <junit-platform.version>1.11.4</junit-platform.version>\n    <!--\n      SPARK-50299: When updating `sbt-jupiter-interface.version`,\n      also need to update the version in `SparkBuild.scala` and `plugins.sbt`.\n    -->\n    <sbt-jupiter-interface.version>0.13.3</sbt-jupiter-interface.version>\n    <!--\n    If you are changing Arrow version specification, please check\n    ./python/pyspark/sql/pandas/utils.py, ./python/packaging/classic/setup.py\n    and ./python/packaging/connect/setup.py too.\n    -->\n    <arrow.version>18.1.0</arrow.version>\n    <ammonite.version>3.0.0</ammonite.version>\n    <jjwt.version>0.12.6</jjwt.version>\n\n    <!-- org.fusesource.leveldbjni will be used except on arm64 platform. -->\n    <leveldbjni.group>org.fusesource.leveldbjni</leveldbjni.group>\n    <kubernetes-client.version>7.0.1</kubernetes-client.version>\n\n    <test.java.home>${java.home}</test.java.home>\n\n    <!-- Some UI tests require Chrome and Chrome driver installed so those tests are disabled by default. -->\n    <test.default.exclude.tags>org.apache.spark.tags.ChromeUITest</test.default.exclude.tags>\n    <test.exclude.tags></test.exclude.tags>\n    <test.include.tags></test.include.tags>\n\n    <test.jdwp.address>localhost:0</test.jdwp.address>\n    <test.jdwp.suspend>y</test.jdwp.suspend>\n    <test.jdwp.server>y</test.jdwp.server>\n    <test.debug.suite>false</test.debug.suite>\n\n    <!-- Package to use when relocating shaded classes. -->\n    <spark.shade.packageName>org.sparkproject</spark.shade.packageName>\n\n    <!-- Modules that copy jars to the build directory should do so under this location. -->\n    <jars.target.dir>${project.build.directory}/scala-${scala.binary.version}/jars</jars.target.dir>\n\n    <!-- Allow modules to enable / disable certain build plugins easily. -->\n    <build.testJarPhase>prepare-package</build.testJarPhase>\n    <build.copyDependenciesPhase>none</build.copyDependenciesPhase>\n\n    <!--\n      Dependency scopes that can be overridden by enabling certain profiles. These profiles are\n      declared in the projects that build assemblies.\n\n      For other projects the scope should remain as \"compile\", otherwise they are not available\n      during compilation if the dependency is transitive (e.g. \"graphx/\" depending on \"core/\" and\n      needing Hadoop classes in the classpath to compile).\n    -->\n    <derby.deps.scope>compile</derby.deps.scope>\n    <hadoop.deps.scope>compile</hadoop.deps.scope>\n    <hive.deps.scope>compile</hive.deps.scope>\n    <hive.storage.version>2.8.1</hive.storage.version>\n    <hive.storage.scope>compile</hive.storage.scope>\n    <hive.jackson.scope>compile</hive.jackson.scope>\n    <hive.common.scope>compile</hive.common.scope>\n    <hive.llap.scope>compile</hive.llap.scope>\n    <hive.serde.scope>compile</hive.serde.scope>\n    <hive.shims.scope>compile</hive.shims.scope>\n    <orc.deps.scope>compile</orc.deps.scope>\n    <parquet.deps.scope>compile</parquet.deps.scope>\n    <parquet.test.deps.scope>test</parquet.test.deps.scope>\n    <jjwt.deps.scope>test</jjwt.deps.scope>\n\n    <spark.yarn.isHadoopProvided>false</spark.yarn.isHadoopProvided>\n\n    <!--\n      Overridable test home. So that you can call individual pom files directly without\n      things breaking.\n    -->\n    <spark.test.home>${session.executionRootDirectory}</spark.test.home>\n    <spark.test.webdriver.chrome.driver></spark.test.webdriver.chrome.driver>\n    <spark.test.docker.keepContainer>false</spark.test.docker.keepContainer>\n    <spark.test.docker.removePulledImage>true</spark.test.docker.removePulledImage>\n\n    <!-- Version used in Connect -->\n    <connect.guava.version>33.3.1-jre</connect.guava.version>\n    <guava.failureaccess.version>1.0.2</guava.failureaccess.version>\n    <io.grpc.version>1.67.1</io.grpc.version>\n    <mima.version>1.1.4</mima.version>\n    <tomcat.annotations.api.version>6.0.53</tomcat.annotations.api.version>\n\n    <!-- Version used in Profiler -->\n    <ap-loader.version>3.0-9</ap-loader.version>\n\n    <CodeCacheSize>128m</CodeCacheSize>\n    <!-- Needed for consistent times -->\n    <maven.build.timestamp.format>yyyy-MM-dd HH:mm:ss z</maven.build.timestamp.format>\n\n    <!-- SPARK-36796 for JDK-17 test-->\n    <extraJavaTestArgs>\n      -XX:+IgnoreUnrecognizedVMOptions\n      --add-modules=jdk.incubator.vector\n      --add-opens=java.base/java.lang=ALL-UNNAMED\n      --add-opens=java.base/java.lang.invoke=ALL-UNNAMED\n      --add-opens=java.base/java.lang.reflect=ALL-UNNAMED\n      --add-opens=java.base/java.io=ALL-UNNAMED\n      --add-opens=java.base/java.net=ALL-UNNAMED\n      --add-opens=java.base/java.nio=ALL-UNNAMED\n      --add-opens=java.base/java.util=ALL-UNNAMED\n      --add-opens=java.base/java.util.concurrent=ALL-UNNAMED\n      --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED\n      --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED\n      --add-opens=java.base/sun.nio.ch=ALL-UNNAMED\n      --add-opens=java.base/sun.nio.cs=ALL-UNNAMED\n      --add-opens=java.base/sun.security.action=ALL-UNNAMED\n      --add-opens=java.base/sun.util.calendar=ALL-UNNAMED\n      -Djdk.reflect.useDirectMethodHandle=false\n      -Dio.netty.tryReflectionSetAccessible=true\n    </extraJavaTestArgs>\n    <mariadb.java.client.version>2.7.12</mariadb.java.client.version>\n    <mysql.connector.version>9.1.0</mysql.connector.version>\n    <postgresql.version>42.7.4</postgresql.version>\n    <db2.jcc.version>11.5.9.0</db2.jcc.version>\n    <mssql.jdbc.version>12.8.1.jre11</mssql.jdbc.version>\n    <ojdbc17.version>23.6.0.24.10</ojdbc17.version>\n    <!-- Used for SBT build to retrieve the Spark version -->\n    <spark.version>${project.version}</spark.version>\n  </properties>\n  <repositories>\n    <repository>\n      <id>gcs-maven-central-mirror</id>\n      <!--\n        Google Mirror of Maven Central, placed first so that it's used instead of flaky Maven Central.\n        See https://storage-download.googleapis.com/maven-central/index.html\n      -->\n      <name>GCS Maven Central mirror</name>\n      <url>https://maven-central.storage-download.googleapis.com/maven2/</url>\n      <releases>\n        <enabled>true</enabled>\n      </releases>\n      <snapshots>\n        <enabled>false</enabled>\n      </snapshots>\n    </repository>\n    <repository>\n      <!--\n        This is used as a fallback when the first try fails.\n      -->\n      <id>central</id>\n      <name>Maven Repository</name>\n      <url>https://repo.maven.apache.org/maven2</url>\n      <releases>\n        <enabled>true</enabled>\n      </releases>\n      <snapshots>\n        <enabled>false</enabled>\n      </snapshots>\n    </repository>\n  </repositories>\n  <pluginRepositories>\n    <pluginRepository>\n      <id>gcs-maven-central-mirror</id>\n      <!--\n        Google Mirror of Maven Central, placed first so that it's used instead of flaky Maven Central.\n        See https://storage-download.googleapis.com/maven-central/index.html\n      -->\n      <name>GCS Maven Central mirror</name>\n      <url>https://maven-central.storage-download.googleapis.com/maven2/</url>\n      <releases>\n        <enabled>true</enabled>\n      </releases>\n      <snapshots>\n        <enabled>false</enabled>\n      </snapshots>\n    </pluginRepository>\n    <pluginRepository>\n      <id>central</id>\n      <url>https://repo.maven.apache.org/maven2</url>\n      <releases>\n        <enabled>true</enabled>\n      </releases>\n      <snapshots>\n        <enabled>false</enabled>\n      </snapshots>\n    </pluginRepository>\n  </pluginRepositories>\n  <dependencies>\n    <!--\n      This is a dummy dependency that is used to trigger the maven-shade plugin so that Spark's\n      published POMs are flattened and do not contain variables. Without this dependency, some\n      subprojects' published POMs would contain variables like ${scala.binary.version} that will\n      be substituted according to the default properties instead of the ones determined by the\n      profiles that were active during publishing, causing the Scala 2.10 build's POMs to have 2.11\n      dependencies due to the incorrect substitutions. By ensuring that maven-shade runs for all\n      subprojects, we eliminate this problem because the substitutions are baked into the final POM.\n\n      For more details, see SPARK-3812 and MNG-2971.\n    -->\n    <dependency>\n      <groupId>org.spark-project.spark</groupId>\n      <artifactId>unused</artifactId>\n      <version>1.0.0</version>\n    </dependency>\n    <!--\n         This is needed by the scalatest plugin, and so is declared here to be available in\n         all child modules, just as scalatest is run in all children\n    -->\n    <dependency>\n      <groupId>org.scalatest</groupId>\n      <artifactId>scalatest_${scala.binary.version}</artifactId>\n      <scope>test</scope>\n    </dependency>\n    <dependency>\n      <groupId>org.scalatestplus</groupId>\n      <artifactId>scalacheck-1-18_${scala.binary.version}</artifactId>\n      <scope>test</scope>\n    </dependency>\n    <dependency>\n      <groupId>org.scalatestplus</groupId>\n      <artifactId>mockito-5-12_${scala.binary.version}</artifactId>\n      <scope>test</scope>\n    </dependency>\n    <dependency>\n      <groupId>org.scalatestplus</groupId>\n      <artifactId>selenium-4-21_${scala.binary.version}</artifactId>\n      <scope>test</scope>\n    </dependency>\n    <dependency>\n      <groupId>org.junit.jupiter</groupId>\n      <artifactId>junit-jupiter</artifactId>\n      <scope>test</scope>\n    </dependency>\n    <dependency>\n      <groupId>com.github.sbt.junit</groupId>\n      <artifactId>jupiter-interface</artifactId>\n      <scope>test</scope>\n    </dependency>\n  </dependencies>\n  <dependencyManagement>\n    <dependencies>\n      <dependency>\n        <groupId>org.apache.spark</groupId>\n        <artifactId>spark-tags_${scala.binary.version}</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.spark</groupId>\n        <artifactId>spark-tags_${scala.binary.version}</artifactId>\n        <version>${project.version}</version>\n        <type>test-jar</type>\n      </dependency>\n      <dependency>\n        <groupId>org.scala-lang.modules</groupId>\n        <artifactId>scala-parallel-collections_${scala.binary.version}</artifactId>\n        <version>1.0.4</version>\n      </dependency>\n      <dependency>\n        <groupId>com.twitter</groupId>\n        <artifactId>chill_${scala.binary.version}</artifactId>\n        <version>${chill.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>org.apache.xbean</groupId>\n            <artifactId>xbean-asm7-shaded</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>com.twitter</groupId>\n        <artifactId>chill-java</artifactId>\n        <version>${chill.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>com.github.jnr</groupId>\n        <artifactId>jnr-posix</artifactId>\n        <version>3.1.15</version>\n        <scope>test</scope>\n      </dependency>\n      <!-- This artifact is a shaded version of ASM 9.x. The POM that was used to produce this\n           is at https://github.com/apache/geronimo-xbean/tree/trunk/xbean-asm9-shaded\n           For context on why we shade ASM, see SPARK-782 and SPARK-6152. -->\n      <dependency>\n        <groupId>org.apache.xbean</groupId>\n        <artifactId>xbean-asm9-shaded</artifactId>\n        <version>4.26</version>\n      </dependency>\n\n      <!-- Shaded deps marked as provided. These are promoted to compile scope\n           in the modules where we want the shaded classes to appear in the\n           associated jar. -->\n      <dependency>\n        <groupId>org.eclipse.jetty</groupId>\n        <artifactId>jetty-http</artifactId>\n        <version>${jetty.version}</version>\n        <scope>provided</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.eclipse.jetty</groupId>\n        <artifactId>jetty-servlet</artifactId>\n        <version>${jetty.version}</version>\n        <scope>provided</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.eclipse.jetty</groupId>\n        <artifactId>jetty-servlets</artifactId>\n        <version>${jetty.version}</version>\n        <scope>provided</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.eclipse.jetty</groupId>\n        <artifactId>jetty-proxy</artifactId>\n        <version>${jetty.version}</version>\n        <scope>provided</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.eclipse.jetty</groupId>\n        <artifactId>jetty-client</artifactId>\n        <version>${jetty.version}</version>\n        <scope>provided</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.eclipse.jetty</groupId>\n        <artifactId>jetty-util</artifactId>\n        <version>${jetty.version}</version>\n        <scope>provided</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.eclipse.jetty</groupId>\n        <artifactId>jetty-security</artifactId>\n        <version>${jetty.version}</version>\n        <scope>provided</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.eclipse.jetty</groupId>\n        <artifactId>jetty-plus</artifactId>\n        <version>${jetty.version}</version>\n        <scope>provided</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.eclipse.jetty</groupId>\n        <artifactId>jetty-server</artifactId>\n        <version>${jetty.version}</version>\n        <scope>provided</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.eclipse.jetty</groupId>\n        <artifactId>jetty-webapp</artifactId>\n        <version>${jetty.version}</version>\n        <scope>provided</scope>\n      </dependency>\n      <dependency>\n        <groupId>com.google.guava</groupId>\n        <artifactId>guava</artifactId>\n        <version>${guava.version}</version>\n        <scope>provided</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.jpmml</groupId>\n        <artifactId>pmml-model</artifactId>\n        <version>1.4.8</version>\n        <scope>provided</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>org.jpmml</groupId>\n            <artifactId>pmml-agent</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n\n      <!-- End of shaded deps -->\n\n      <dependency>\n        <groupId>com.google.code.gson</groupId>\n        <artifactId>gson</artifactId>\n        <version>${gson.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>com.google.errorprone</groupId>\n            <artifactId>error_prone_annotations</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n\n      <!-- Provide a JAXB impl; no longer auto available in Java 9+ in the JDK -->\n      <dependency>\n        <groupId>org.glassfish.jaxb</groupId>\n        <artifactId>jaxb-runtime</artifactId>\n        <version>2.3.2</version>\n        <scope>compile</scope>\n        <exclusions>\n          <!-- for now, we only write XML in PMML export, and these can be excluded -->\n          <exclusion>\n            <groupId>com.sun.xml.fastinfoset</groupId>\n            <artifactId>FastInfoset</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.glassfish.jaxb</groupId>\n            <artifactId>txw2</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.jvnet.staxex</groupId>\n            <artifactId>stax-ex</artifactId>\n          </exclusion>\n          <!--\n            SPARK-27611: Exclude redundant javax.activation implementation, which\n            conflicts with the existing javax.activation:activation:1.1.1 dependency.\n            -->\n          <exclusion>\n            <groupId>jakarta.activation</groupId>\n            <artifactId>jakarta.activation-api</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.commons</groupId>\n        <artifactId>commons-lang3</artifactId>\n        <version>${commons-lang3.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.commons</groupId>\n        <artifactId>commons-text</artifactId>\n        <version>1.13.0</version>\n      </dependency>\n      <dependency>\n        <groupId>commons-lang</groupId>\n        <artifactId>commons-lang</artifactId>\n        <version>${commons-lang2.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>commons-io</groupId>\n        <artifactId>commons-io</artifactId>\n        <version>${commons-io.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>commons-codec</groupId>\n        <artifactId>commons-codec</artifactId>\n        <version>${commons-codec.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.commons</groupId>\n        <artifactId>commons-compress</artifactId>\n        <version>${commons-compress.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>commons-io</groupId>\n            <artifactId>commons-io</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.commons</groupId>\n            <artifactId>commons-lang3</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.commons</groupId>\n        <artifactId>commons-math3</artifactId>\n        <version>${commons.math3.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>commons-collections</groupId>\n        <artifactId>commons-collections</artifactId>\n        <version>${commons.collections.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.commons</groupId>\n        <artifactId>commons-collections4</artifactId>\n        <version>${commons.collections4.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.ivy</groupId>\n        <artifactId>ivy</artifactId>\n        <version>${ivy.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>io.jsonwebtoken</groupId>\n        <artifactId>jjwt-api</artifactId>\n        <version>${jjwt.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>io.jsonwebtoken</groupId>\n        <artifactId>jjwt-impl</artifactId>\n        <version>${jjwt.version}</version>\n        <scope>${jjwt.deps.scope}</scope>\n      </dependency>\n      <dependency>\n        <groupId>io.jsonwebtoken</groupId>\n        <artifactId>jjwt-jackson</artifactId>\n        <version>${jjwt.version}</version>\n        <scope>${jjwt.deps.scope}</scope>\n      </dependency>\n      <dependency>\n        <groupId>com.google.code.findbugs</groupId>\n        <artifactId>jsr305</artifactId>\n        <version>${jsr305.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.httpcomponents</groupId>\n        <artifactId>httpclient</artifactId>\n        <version>${commons.httpclient.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>commons-logging</groupId>\n            <artifactId>commons-logging</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.httpcomponents</groupId>\n        <artifactId>httpmime</artifactId>\n        <version>${commons.httpclient.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.httpcomponents</groupId>\n        <artifactId>httpcore</artifactId>\n        <version>${commons.httpcore.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.rocksdb</groupId>\n        <artifactId>rocksdbjni</artifactId>\n        <version>9.7.3</version>\n      </dependency>\n      <dependency>\n        <groupId>${leveldbjni.group}</groupId>\n        <artifactId>leveldbjni-all</artifactId>\n        <version>1.8</version>\n      </dependency>\n      <dependency>\n        <groupId>org.seleniumhq.selenium</groupId>\n        <artifactId>selenium-java</artifactId>\n        <version>${selenium.version}</version>\n        <scope>test</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>com.google.guava</groupId>\n            <artifactId>guava</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>com.google.auto.service</groupId>\n            <artifactId>*</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>*</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>net.bytebuddy</groupId>\n            <artifactId>byte-buddy</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.seleniumhq.selenium</groupId>\n        <artifactId>htmlunit3-driver</artifactId>\n        <version>${htmlunit3-driver.version}</version>\n        <scope>test</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>commons-logging</groupId>\n            <artifactId>commons-logging</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n\n      <!-- log4j -->\n      <dependency>\n        <groupId>org.slf4j</groupId>\n        <artifactId>slf4j-api</artifactId>\n        <version>${slf4j.version}</version>\n        <scope>${hadoop.deps.scope}</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.slf4j</groupId>\n        <artifactId>jul-to-slf4j</artifactId>\n        <version>${slf4j.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.slf4j</groupId>\n        <artifactId>jcl-over-slf4j</artifactId>\n        <version>${slf4j.version}</version>\n        <!-- runtime scope is appropriate, but causes SBT build problems -->\n      </dependency>\n\n      <dependency>\n        <groupId>org.apache.logging.log4j</groupId>\n        <artifactId>log4j-slf4j2-impl</artifactId>\n        <version>${log4j.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.logging.log4j</groupId>\n        <artifactId>log4j-api</artifactId>\n        <version>${log4j.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.logging.log4j</groupId>\n        <artifactId>log4j-core</artifactId>\n        <version>${log4j.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.logging.log4j</groupId>\n        <artifactId>log4j-layout-template-json</artifactId>\n        <version>${log4j.version}</version>\n      </dependency>\n      <dependency>\n        <!-- API bridge between log4j 1 and 2 -->\n        <groupId>org.apache.logging.log4j</groupId>\n        <artifactId>log4j-1.2-api</artifactId>\n        <version>${log4j.version}</version>\n      </dependency>\n\n      <!-- end -->\n\n      <dependency>\n        <groupId>com.ning</groupId>\n        <artifactId>compress-lzf</artifactId>\n        <version>1.1.2</version>\n      </dependency>\n      <dependency>\n        <groupId>org.xerial.snappy</groupId>\n        <artifactId>snappy-java</artifactId>\n        <version>${snappy.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.lz4</groupId>\n        <artifactId>lz4-java</artifactId>\n        <version>1.8.0</version>\n      </dependency>\n      <dependency>\n        <groupId>com.github.luben</groupId>\n        <artifactId>zstd-jni</artifactId>\n        <version>1.5.6-9</version>\n      </dependency>\n      <dependency>\n        <groupId>com.clearspring.analytics</groupId>\n        <artifactId>stream</artifactId>\n        <version>2.9.8</version>\n        <exclusions>\n          <!-- Only HyperLogLogPlus is used, which doesn't depend on fastutil -->\n          <exclusion>\n            <groupId>it.unimi.dsi</groupId>\n            <artifactId>fastutil</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>com.google.protobuf</groupId>\n        <artifactId>protobuf-java</artifactId>\n        <version>${protobuf.version}</version>\n        <scope>provided</scope>\n      </dependency>\n      <dependency>\n        <groupId>com.google.protobuf</groupId>\n        <artifactId>protobuf-java-util</artifactId>\n        <version>${protobuf.version}</version>\n        <scope>provided</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.roaringbitmap</groupId>\n        <artifactId>RoaringBitmap</artifactId>\n        <version>1.3.0</version>\n      </dependency>\n\n      <!-- Netty Begin -->\n      <dependency>\n        <groupId>io.netty</groupId>\n        <artifactId>netty-all</artifactId>\n        <version>${netty.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-codec-dns</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-codec-haproxy</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-codec-memcache</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-codec-mqtt</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-codec-redis</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-codec-smtp</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-codec-stomp</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-codec-xml</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-resolver-dns</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-resolver-dns-classes-macos</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-resolver-dns-native-macos</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-transport-rxtx</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-transport-sctp</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-transport-udt</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-handler-ssl-ocsp</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.jctools</groupId>\n            <artifactId>jctools-core</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <!-- SPARK-38885: After Netty 4.1.76, add the following `Netty` dependencies explicitly\n           to ensure `./dev/test-dependencies.sh` produce the same results on Linux and MacOS.\n      -->\n      <dependency>\n        <groupId>io.netty</groupId>\n        <artifactId>netty-transport-native-epoll</artifactId>\n        <version>${netty.version}</version>\n        <classifier>linux-x86_64</classifier>\n      </dependency>\n      <dependency>\n        <groupId>io.netty</groupId>\n        <artifactId>netty-transport-native-epoll</artifactId>\n        <version>${netty.version}</version>\n        <classifier>linux-aarch_64</classifier>\n      </dependency>\n      <dependency>\n        <groupId>io.netty</groupId>\n        <artifactId>netty-transport-native-kqueue</artifactId>\n        <version>${netty.version}</version>\n        <classifier>osx-aarch_64</classifier>\n      </dependency>\n      <dependency>\n        <groupId>io.netty</groupId>\n        <artifactId>netty-transport-native-kqueue</artifactId>\n        <version>${netty.version}</version>\n        <classifier>osx-x86_64</classifier>\n      </dependency>\n      <dependency>\n        <groupId>io.netty</groupId>\n        <artifactId>netty-tcnative-boringssl-static</artifactId>\n        <version>${netty-tcnative.version}</version>\n        <classifier>linux-x86_64</classifier>\n      </dependency>\n      <dependency>\n        <groupId>io.netty</groupId>\n        <artifactId>netty-tcnative-boringssl-static</artifactId>\n        <version>${netty-tcnative.version}</version>\n        <classifier>linux-aarch_64</classifier>\n      </dependency>\n      <dependency>\n        <groupId>io.netty</groupId>\n        <artifactId>netty-tcnative-boringssl-static</artifactId>\n        <version>${netty-tcnative.version}</version>\n        <classifier>osx-aarch_64</classifier>\n      </dependency>\n      <dependency>\n        <groupId>io.netty</groupId>\n        <artifactId>netty-tcnative-boringssl-static</artifactId>\n        <version>${netty-tcnative.version}</version>\n        <classifier>osx-x86_64</classifier>\n      </dependency>\n      <!-- Netty End -->\n\n      <dependency>\n        <groupId>org.apache.derby</groupId>\n        <artifactId>derby</artifactId>\n        <version>${derby.version}</version>\n        <scope>${derby.deps.scope}</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.derby</groupId>\n        <artifactId>derbytools</artifactId>\n        <version>${derby.version}</version>\n        <scope>${derby.deps.scope}</scope>\n      </dependency>\n      <dependency>\n        <groupId>io.dropwizard.metrics</groupId>\n        <artifactId>metrics-core</artifactId>\n        <version>${codahale.metrics.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>io.dropwizard.metrics</groupId>\n        <artifactId>metrics-jvm</artifactId>\n        <version>${codahale.metrics.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>io.dropwizard.metrics</groupId>\n        <artifactId>metrics-json</artifactId>\n        <version>${codahale.metrics.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>io.dropwizard.metrics</groupId>\n        <artifactId>metrics-graphite</artifactId>\n        <version>${codahale.metrics.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>io.dropwizard.metrics</groupId>\n        <artifactId>metrics-jmx</artifactId>\n        <version>${codahale.metrics.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>com.fasterxml.jackson.core</groupId>\n        <artifactId>jackson-core</artifactId>\n        <version>${fasterxml.jackson.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>com.fasterxml.jackson.core</groupId>\n        <artifactId>jackson-databind</artifactId>\n        <version>${fasterxml.jackson.databind.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>com.fasterxml.jackson.core</groupId>\n        <artifactId>jackson-annotations</artifactId>\n        <version>${fasterxml.jackson.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>com.fasterxml.jackson.datatype</groupId>\n        <artifactId>jackson-datatype-jsr310</artifactId>\n        <version>${fasterxml.jackson.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>com.fasterxml.jackson.module</groupId>\n        <artifactId>jackson-module-scala_${scala.binary.version}</artifactId>\n        <version>${fasterxml.jackson.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.ws.xmlschema</groupId>\n        <artifactId>xmlschema-core</artifactId>\n        <version>${ws.xmlschema.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.glassfish.jersey.core</groupId>\n        <artifactId>jersey-server</artifactId>\n        <version>${jersey.version}</version>\n        <!-- SPARK-28765 Unused JDK11-specific dependency -->\n        <exclusions>\n          <exclusion>\n            <groupId>jakarta.xml.bind</groupId>\n            <artifactId>jakarta.xml.bind-api</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.glassfish.jersey.core</groupId>\n        <artifactId>jersey-common</artifactId>\n        <version>${jersey.version}</version>\n        <!-- SPARK-28765 Unused JDK11-specific dependency -->\n        <exclusions>\n          <exclusion>\n            <groupId>com.sun.activation</groupId>\n            <artifactId>jakarta.activation</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.glassfish.jersey.core</groupId>\n        <artifactId>jersey-client</artifactId>\n        <version>${jersey.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.glassfish.jersey.containers</groupId>\n        <artifactId>jersey-container-servlet</artifactId>\n        <version>${jersey.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.glassfish.jersey.containers</groupId>\n        <artifactId>jersey-container-servlet-core</artifactId>\n        <version>${jersey.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.glassfish.jersey.inject</groupId>\n        <artifactId>jersey-hk2</artifactId>\n        <version>${jersey.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.glassfish.jersey.test-framework.providers</groupId>\n        <artifactId>jersey-test-framework-provider-simple</artifactId>\n        <version>${jersey.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.glassfish.jersey</groupId>\n        <artifactId>jersey-client</artifactId>\n        <version>${jersey.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>javax.xml.bind</groupId>\n        <artifactId>jaxb-api</artifactId>\n        <version>${jaxb.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.scalanlp</groupId>\n        <artifactId>breeze_${scala.binary.version}</artifactId>\n        <version>2.1.0</version>\n        <exclusions>\n          <exclusion>\n            <groupId>org.apache.commons</groupId>\n            <artifactId>commons-math3</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.json4s</groupId>\n        <artifactId>json4s-jackson_${scala.binary.version}</artifactId>\n        <version>4.0.7</version>\n        <exclusions>\n          <exclusion>\n            <groupId>com.fasterxml.jackson.core</groupId>\n            <artifactId>*</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.scala-lang.modules</groupId>\n        <artifactId>scala-xml_${scala.binary.version}</artifactId>\n        <version>2.3.0</version>\n      </dependency>\n      <dependency>\n        <groupId>org.scala-lang</groupId>\n        <artifactId>scala-compiler</artifactId>\n        <version>${scala.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>org.scala-lang.modules</groupId>\n            <artifactId>scala-xml_2.13</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.scala-lang</groupId>\n        <artifactId>scala-reflect</artifactId>\n        <version>${scala.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.scala-lang</groupId>\n        <artifactId>scala-library</artifactId>\n        <version>${scala.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.scala-lang.modules</groupId>\n        <artifactId>scala-parser-combinators_${scala.binary.version}</artifactId>\n        <version>2.4.0</version>\n      </dependency>\n      <dependency>\n        <groupId>jline</groupId>\n        <artifactId>jline</artifactId>\n        <version>2.14.6</version>\n      </dependency>\n      <dependency>\n        <groupId>org.scalatest</groupId>\n        <artifactId>scalatest_${scala.binary.version}</artifactId>\n        <version>3.2.19</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.scalatestplus</groupId>\n        <artifactId>scalacheck-1-18_${scala.binary.version}</artifactId>\n        <version>3.2.19.0</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.scalatestplus</groupId>\n        <artifactId>mockito-5-12_${scala.binary.version}</artifactId>\n        <version>3.2.19.0</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.scalatestplus</groupId>\n        <artifactId>selenium-4-21_${scala.binary.version}</artifactId>\n        <version>3.2.19.0</version>\n        <scope>test</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>org.seleniumhq.selenium</groupId>\n            <artifactId>htmlunit-driver</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.mockito</groupId>\n        <artifactId>mockito-core</artifactId>\n        <version>5.12.0</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>net.bytebuddy</groupId>\n        <artifactId>byte-buddy</artifactId>\n        <version>1.14.17</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>net.bytebuddy</groupId>\n        <artifactId>byte-buddy-agent</artifactId>\n        <version>1.14.17</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.jmock</groupId>\n        <artifactId>jmock-junit5</artifactId>\n        <scope>test</scope>\n        <version>2.13.1</version>\n      </dependency>\n      <dependency>\n        <groupId>org.scalacheck</groupId>\n        <artifactId>scalacheck_${scala.binary.version}</artifactId>\n        <version>1.18.0</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.junit.jupiter</groupId>\n        <artifactId>junit-jupiter</artifactId>\n        <version>${junit-jupiter.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.junit.jupiter</groupId>\n        <artifactId>junit-jupiter-api</artifactId>\n        <version>${junit-jupiter.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.junit.jupiter</groupId>\n        <artifactId>junit-jupiter-engine</artifactId>\n        <version>${junit-jupiter.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.junit.jupiter</groupId>\n        <artifactId>junit-jupiter-params</artifactId>\n        <version>${junit-jupiter.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.junit.platform</groupId>\n        <artifactId>junit-platform-commons</artifactId>\n        <version>${junit-platform.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.junit.platform</groupId>\n        <artifactId>junit-platform-engine</artifactId>\n        <version>${junit-platform.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.junit.platform</groupId>\n        <artifactId>junit-platform-launcher</artifactId>\n        <version>${junit-platform.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>com.github.sbt.junit</groupId>\n        <artifactId>jupiter-interface</artifactId>\n        <version>${sbt-jupiter-interface.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>com.github.docker-java</groupId>\n        <artifactId>docker-java</artifactId>\n        <version>3.4.0</version>\n        <scope>test</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>commons-logging</groupId>\n            <artifactId>commons-logging</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>com.github.docker-java</groupId>\n            <artifactId>docker-java-transport-netty</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>com.github.docker-java</groupId>\n            <artifactId>docker-java-transport-jersey</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>com.github.docker-java</groupId>\n        <artifactId>docker-java-transport-zerodep</artifactId>\n        <version>3.4.0</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>com.mysql</groupId>\n        <artifactId>mysql-connector-j</artifactId>\n        <version>${mysql.connector.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.mariadb.jdbc</groupId>\n        <artifactId>mariadb-java-client</artifactId>\n        <version>${mariadb.java.client.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.postgresql</groupId>\n        <artifactId>postgresql</artifactId>\n        <version>${postgresql.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>com.ibm.db2</groupId>\n        <artifactId>jcc</artifactId>\n        <version>${db2.jcc.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>com.microsoft.sqlserver</groupId>\n        <artifactId>mssql-jdbc</artifactId>\n        <version>${mssql.jdbc.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>com.oracle.database.jdbc</groupId>\n        <artifactId>ojdbc17</artifactId>\n        <version>${ojdbc17.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.curator</groupId>\n        <artifactId>curator-recipes</artifactId>\n        <version>${curator.version}</version>\n        <scope>${hadoop.deps.scope}</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>org.jboss.netty</groupId>\n            <artifactId>netty</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>jline</groupId>\n            <artifactId>jline</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-api</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-log4j12</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>log4j</groupId>\n            <artifactId>log4j</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.curator</groupId>\n        <artifactId>curator-client</artifactId>\n        <version>${curator.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.curator</groupId>\n        <artifactId>curator-framework</artifactId>\n        <version>${curator.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.curator</groupId>\n        <artifactId>curator-test</artifactId>\n        <version>${curator.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <!-- Hadoop 3.x dependencies -->\n      <dependency>\n        <groupId>org.apache.hadoop</groupId>\n        <artifactId>hadoop-client-api</artifactId>\n        <version>${hadoop.version}</version>\n        <scope>${hadoop.deps.scope}</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hadoop</groupId>\n        <artifactId>hadoop-client-runtime</artifactId>\n        <version>${hadoop.version}</version>\n        <scope>${hadoop.deps.scope}</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>commons-logging</groupId>\n            <artifactId>commons-logging</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hadoop</groupId>\n        <artifactId>hadoop-client-minicluster</artifactId>\n        <version>${hadoop.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <!-- End of Hadoop 3.x dependencies -->\n      <dependency>\n        <groupId>org.apache.hadoop</groupId>\n        <artifactId>hadoop-minikdc</artifactId>\n        <version>${hadoop.version}</version>\n        <scope>test</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>org.apache.directory.api</groupId>\n            <artifactId>api-ldap-schema-data</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>log4j</groupId>\n            <artifactId>log4j</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-log4j12</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-reload4j</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>junit</groupId>\n            <artifactId>junit</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.bouncycastle</groupId>\n        <artifactId>bcprov-jdk18on</artifactId>\n        <version>${bouncycastle.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.bouncycastle</groupId>\n        <artifactId>bcpkix-jdk18on</artifactId>\n        <version>${bouncycastle.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.avro</groupId>\n        <artifactId>avro</artifactId>\n        <version>${avro.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>commons-io</groupId>\n            <artifactId>commons-io</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.commons</groupId>\n            <artifactId>commons-lang3</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.avro</groupId>\n        <artifactId>avro-mapred</artifactId>\n        <version>${avro.version}</version>\n        <scope>${hive.deps.scope}</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>org.apache.avro</groupId>\n            <artifactId>avro-ipc-jetty</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.mortbay.jetty</groupId>\n            <artifactId>jetty</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.mortbay.jetty</groupId>\n            <artifactId>jetty-util</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.mortbay.jetty</groupId>\n            <artifactId>servlet-api</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.velocity</groupId>\n            <artifactId>velocity-engine-core</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>javax.annotation</groupId>\n            <artifactId>javax.annotation-api</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>com.github.luben</groupId>\n            <artifactId>zstd-jni</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>commons-io</groupId>\n            <artifactId>commons-io</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.commons</groupId>\n            <artifactId>commons-lang3</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <!--\n        SPARK-41031: `xz` is marked as optional in the dependency tree of `avro`,\n        we need to manually check `xz` version when upgrading `avro`.\n      -->\n      <dependency>\n        <groupId>org.tukaani</groupId>\n        <artifactId>xz</artifactId>\n        <version>1.10</version>\n      </dependency>\n      <!-- See SPARK-23654 for info on this dependency;\n      It is used to keep javax.activation at v1.1.1 after dropping\n      jets3t as a dependency.\n       -->\n      <dependency>\n        <groupId>javax.activation</groupId>\n        <artifactId>activation</artifactId>\n        <version>1.1.1</version>\n        <scope>${hadoop.deps.scope}</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.zookeeper</groupId>\n        <artifactId>zookeeper</artifactId>\n        <version>${zookeeper.version}</version>\n        <scope>${hadoop.deps.scope}</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>org.jboss.netty</groupId>\n            <artifactId>netty</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>jline</groupId>\n            <artifactId>jline</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-handler</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-transport-native-epoll</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-tcnative-boringssl-static</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>com.github.spotbugs</groupId>\n            <artifactId>spotbugs-annotations</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-api</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-log4j12</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>log4j</groupId>\n            <artifactId>log4j</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>ch.qos.logback</groupId>\n            <artifactId>logback-classic</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>ch.qos.logback</groupId>\n            <artifactId>logback-core</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <!-- Hive 2.3 need this to init Hive's FunctionRegistry -->\n      <dependency>\n        <groupId>org.codehaus.jackson</groupId>\n        <artifactId>jackson-core-asl</artifactId>\n        <version>${codehaus.jackson.version}</version>\n        <scope>${hive.jackson.scope}</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.codehaus.jackson</groupId>\n        <artifactId>jackson-mapper-asl</artifactId>\n        <version>${codehaus.jackson.version}</version>\n        <scope>${hive.jackson.scope}</scope>\n      </dependency>\n      <dependency>\n        <groupId>${hive.group}</groupId>\n        <artifactId>hive-beeline</artifactId>\n        <version>${hive.version}</version>\n        <scope>${hive.deps.scope}</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-common</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-exec</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-jdbc</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-metastore</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-service</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-service-rpc</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-shims</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.thrift</groupId>\n            <artifactId>libthrift</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-api</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-log4j12</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>log4j</groupId>\n            <artifactId>log4j</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>commons-logging</groupId>\n            <artifactId>commons-logging</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>${hive.group}</groupId>\n        <artifactId>hive-cli</artifactId>\n        <version>${hive.version}</version>\n        <scope>${hive.deps.scope}</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-common</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-exec</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-jdbc</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-metastore</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-serde</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-service</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-shims</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.thrift</groupId>\n            <artifactId>libthrift</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-api</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-log4j12</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>log4j</groupId>\n            <artifactId>log4j</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>commons-logging</groupId>\n            <artifactId>commons-logging</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>${hive.group}</groupId>\n        <artifactId>hive-common</artifactId>\n        <version>${hive.version}</version>\n        <scope>${hive.deps.scope}</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-shims</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.ant</groupId>\n            <artifactId>ant</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-common</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-auth</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.zookeeper</groupId>\n            <artifactId>zookeeper</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-api</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-log4j12</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>log4j</groupId>\n            <artifactId>log4j</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>commons-logging</groupId>\n            <artifactId>commons-logging</artifactId>\n          </exclusion>\n          <!--\n            ORC is needed, but the version should be consistent with the `sql/core` ORC data source.\n            Looks like this is safe, please see the major changes from ORC 1.3.3 to 1.5.4:\n            HIVE-17631 and HIVE-19465\n          -->\n          <exclusion>\n            <groupId>org.apache.orc</groupId>\n            <artifactId>orc-core</artifactId>\n          </exclusion>\n          <!-- jetty-all conflict with Spark's built-in Jetty version -->\n          <exclusion>\n            <groupId>org.eclipse.jetty.aggregate</groupId>\n            <artifactId>jetty-all</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.logging.log4j</groupId>\n            <artifactId>*</artifactId>\n          </exclusion>\n          <!-- Hive includes javax.servlet to fix the Hive on Spark test failure; see HIVE-12783 -->\n          <exclusion>\n            <groupId>org.eclipse.jetty.orbit</groupId>\n            <artifactId>javax.servlet</artifactId>\n          </exclusion>\n          <!-- hive-storage-api is needed and must be explicitly included later -->\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-storage-api</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n\n      <dependency>\n        <groupId>${hive.group}</groupId>\n        <artifactId>hive-exec</artifactId>\n        <classifier>${hive.classifier}</classifier>\n        <version>${hive.version}</version>\n        <scope>${hive.deps.scope}</scope>\n        <exclusions>\n\n          <!-- pull this in when needed; the explicit definition culls the surplus-->\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-metastore</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-shims</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-ant</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-vector-code-gen</artifactId>\n          </exclusion>\n          <!-- break the loop -->\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>spark-client</artifactId>\n          </exclusion>\n\n          <!-- excluded dependencies & transitive.\n           Some may be needed to be explicitly included-->\n          <exclusion>\n            <groupId>ant</groupId>\n            <artifactId>ant</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.ant</groupId>\n            <artifactId>ant</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>com.esotericsoftware.kryo</groupId>\n            <artifactId>kryo</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>commons-codec</groupId>\n            <artifactId>commons-codec</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.avro</groupId>\n            <artifactId>avro-mapred</artifactId>\n          </exclusion>\n          <!--  Do not need Calcite because we disabled hive.cbo.enable -->\n          <exclusion>\n            <groupId>org.apache.calcite</groupId>\n            <artifactId>calcite-core</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.calcite</groupId>\n            <artifactId>calcite-avatica</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.curator</groupId>\n            <artifactId>apache-curator</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.curator</groupId>\n            <artifactId>curator-client</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.curator</groupId>\n            <artifactId>curator-framework</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.thrift</groupId>\n            <artifactId>libthrift</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.thrift</groupId>\n            <artifactId>libfb303</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.zookeeper</groupId>\n            <artifactId>zookeeper</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-api</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-log4j12</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>log4j</groupId>\n            <artifactId>log4j</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>commons-logging</groupId>\n            <artifactId>commons-logging</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.codehaus.groovy</groupId>\n            <artifactId>groovy-all</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>jline</groupId>\n            <artifactId>jline</artifactId>\n          </exclusion>\n          <!-- Cat X license now; see SPARK-18262 -->\n          <exclusion>\n            <groupId>org.json</groupId>\n            <artifactId>json</artifactId>\n          </exclusion>\n          <!-- Do not need Tez -->\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-llap-tez</artifactId>\n          </exclusion>\n          <!-- Do not need Calcite, see SPARK-27054 -->\n          <exclusion>\n            <groupId>org.apache.calcite</groupId>\n            <artifactId>calcite-druid</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.calcite.avatica</groupId>\n            <artifactId>avatica</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.logging.log4j</groupId>\n            <artifactId>*</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>net.hydromatic</groupId>\n            <artifactId>eigenbase-properties</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.codehaus.janino</groupId>\n            <artifactId>commons-compiler</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.codehaus.janino</groupId>\n            <artifactId>janino</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>net.hydromatic</groupId>\n            <artifactId>aggdesigner-algorithm</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>${hive.group}</groupId>\n        <artifactId>hive-jdbc</artifactId>\n        <version>${hive.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-common</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-metastore</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-serde</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-service</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-service-rpc</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-shims</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.curator</groupId>\n            <artifactId>curator-framework</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.thrift</groupId>\n            <artifactId>libthrift</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.thrift</groupId>\n            <artifactId>libfb303</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.zookeeper</groupId>\n            <artifactId>zookeeper</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-api</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-log4j12</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>log4j</groupId>\n            <artifactId>log4j</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>commons-logging</groupId>\n            <artifactId>commons-logging</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.codehaus.groovy</groupId>\n            <artifactId>groovy-all</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>com.lmax</groupId>\n            <artifactId>disruptor</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n\n      <dependency>\n        <groupId>${hive.group}</groupId>\n        <artifactId>hive-metastore</artifactId>\n        <version>${hive.version}</version>\n        <scope>${hive.deps.scope}</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-serde</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-shims</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.thrift</groupId>\n            <artifactId>libfb303</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.thrift</groupId>\n            <artifactId>libthrift</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.mortbay.jetty</groupId>\n            <artifactId>servlet-api</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>com.google.guava</groupId>\n            <artifactId>guava</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-api</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-log4j12</artifactId>\n          </exclusion>\n          <!-- Hive removes the HBase Metastore; see HIVE-17234 -->\n          <exclusion>\n            <groupId>org.apache.hbase</groupId>\n            <artifactId>hbase-client</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>co.cask.tephra</groupId>\n            <artifactId>*</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>com.jolbox</groupId>\n            <artifactId>bonecp</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n\n      <dependency>\n        <groupId>${hive.group}</groupId>\n        <artifactId>hive-serde</artifactId>\n        <version>${hive.version}</version>\n        <scope>${hive.deps.scope}</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-common</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-shims</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>commons-codec</groupId>\n            <artifactId>commons-codec</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>com.google.code.findbugs</groupId>\n            <artifactId>jsr305</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.avro</groupId>\n            <artifactId>avro</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.thrift</groupId>\n            <artifactId>libthrift</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.thrift</groupId>\n            <artifactId>libfb303</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-api</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-log4j12</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>log4j</groupId>\n            <artifactId>log4j</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>commons-logging</groupId>\n            <artifactId>commons-logging</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.codehaus.groovy</groupId>\n            <artifactId>groovy-all</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-service-rpc</artifactId>\n          </exclusion>\n          <!--\n            Parquet is needed, but the version should be consistent with\n            the `sql/core` Parquet data source.\n            -->\n          <exclusion>\n            <groupId>org.apache.parquet</groupId>\n            <artifactId>parquet-hadoop-bundle</artifactId>\n          </exclusion>\n          <!-- Do not need Jasper, see HIVE-19799 -->\n          <exclusion>\n            <groupId>tomcat</groupId>\n            <artifactId>jasper-compiler</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>tomcat</groupId>\n            <artifactId>jasper-runtime</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n\n      <dependency>\n        <groupId>${hive.group}</groupId>\n        <artifactId>hive-service-rpc</artifactId>\n        <version>4.0.0</version>\n        <exclusions>\n          <exclusion>\n            <groupId>*</groupId>\n            <artifactId>*</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>net.sf.jpam</groupId>\n        <artifactId>jpam</artifactId>\n        <scope>${hive.deps.scope}</scope>\n        <version>${jpam.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>javax.servlet</groupId>\n            <artifactId>servlet-api</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n\n      <!-- hive shims pulls in hive 0.23 and a transitive dependency of the Hadoop version\n        Hive was built against. This dependency cuts out the YARN/hadoop dependency, which\n        is needed by Hive to submit work to a YARN cluster.-->\n      <dependency>\n        <groupId>${hive.group}</groupId>\n        <artifactId>hive-shims</artifactId>\n        <version>${hive.version}</version>\n        <scope>${hive.deps.scope}</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>com.google.guava</groupId>\n            <artifactId>guava</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-yarn-server-resourcemanager</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.curator</groupId>\n            <artifactId>curator-framework</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.thrift</groupId>\n            <artifactId>libthrift</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.zookeeper</groupId>\n            <artifactId>zookeeper</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-api</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-log4j12</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>log4j</groupId>\n            <artifactId>log4j</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>commons-logging</groupId>\n            <artifactId>commons-logging</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.codehaus.groovy</groupId>\n            <artifactId>groovy-all</artifactId>\n          </exclusion>\n          <!-- Exclude log4j-slf4j-impl, otherwise throw NCDFE when starting spark-shell -->\n          <exclusion>\n            <groupId>org.apache.logging.log4j</groupId>\n            <artifactId>log4j-slf4j-impl</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n\n      <!-- hive-llap-common is needed when registering UDFs in Hive 2.3.\n         We add it here, otherwise -Phive-provided won't work. -->\n      <dependency>\n        <groupId>${hive.group}</groupId>\n        <artifactId>hive-llap-common</artifactId>\n        <version>${hive.version}</version>\n        <scope>${hive.deps.scope}</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-common</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-serde</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-api</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <!-- hive-llap-client is needed when run MapReduce test in Hive 2.3. -->\n      <dependency>\n        <groupId>${hive.group}</groupId>\n        <artifactId>hive-llap-client</artifactId>\n        <version>${hive.version}</version>\n        <scope>test</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-common</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-serde</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-llap-common</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.curator</groupId>\n            <artifactId>curator-framework</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.curator</groupId>\n            <artifactId>apache-curator</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.zookeeper</groupId>\n            <artifactId>zookeeper</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-api</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n\n      <dependency>\n        <groupId>org.apache.orc</groupId>\n        <artifactId>orc-format</artifactId>\n        <version>1.0.0</version>\n        <classifier>${orc.classifier}</classifier>\n        <scope>${orc.deps.scope}</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.orc</groupId>\n        <artifactId>orc-core</artifactId>\n        <version>${orc.version}</version>\n        <classifier>${orc.classifier}</classifier>\n        <scope>${orc.deps.scope}</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>org.apache.orc</groupId>\n            <artifactId>orc-format</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>com.github.luben</groupId>\n            <artifactId>zstd-jni</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>com.aayushatharva.brotli4j</groupId>\n            <artifactId>brotli4j</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-common</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-hdfs</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-client-api</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-storage-api</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>io.airlift</groupId>\n        <artifactId>aircompressor</artifactId>\n        <version>2.0.2</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.orc</groupId>\n        <artifactId>orc-mapreduce</artifactId>\n        <version>${orc.version}</version>\n        <classifier>${orc.classifier}</classifier>\n        <scope>${orc.deps.scope}</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-common</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-mapreduce-client-core</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.orc</groupId>\n            <artifactId>orc-core</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>${hive.group}</groupId>\n            <artifactId>hive-storage-api</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId> com.esotericsoftware</groupId>\n            <artifactId>kryo-shaded</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.parquet</groupId>\n        <artifactId>parquet-column</artifactId>\n        <version>${parquet.version}</version>\n        <scope>${parquet.deps.scope}</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.parquet</groupId>\n        <artifactId>parquet-encoding</artifactId>\n        <version>${parquet.version}</version>\n        <scope>${parquet.test.deps.scope}</scope>\n        <classifier>tests</classifier>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.parquet</groupId>\n        <artifactId>parquet-common</artifactId>\n        <version>${parquet.version}</version>\n        <scope>${parquet.test.deps.scope}</scope>\n        <classifier>tests</classifier>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.parquet</groupId>\n        <artifactId>parquet-column</artifactId>\n        <version>${parquet.version}</version>\n        <scope>${parquet.test.deps.scope}</scope>\n        <classifier>tests</classifier>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.parquet</groupId>\n        <artifactId>parquet-hadoop</artifactId>\n        <version>${parquet.version}</version>\n        <scope>${parquet.deps.scope}</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>commons-pool</groupId>\n            <artifactId>commons-pool</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>javax.annotation</groupId>\n            <artifactId>javax.annotation-api</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>com.github.luben</groupId>\n            <artifactId>zstd-jni</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.parquet</groupId>\n        <artifactId>parquet-avro</artifactId>\n        <version>${parquet.version}</version>\n        <scope>${parquet.test.deps.scope}</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.codehaus.janino</groupId>\n        <artifactId>janino</artifactId>\n        <version>${janino.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.codehaus.janino</groupId>\n        <artifactId>commons-compiler</artifactId>\n        <version>${janino.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>joda-time</groupId>\n        <artifactId>joda-time</artifactId>\n        <version>${joda.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.jodd</groupId>\n        <artifactId>jodd-core</artifactId>\n        <version>${jodd.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.datanucleus</groupId>\n        <artifactId>datanucleus-core</artifactId>\n        <version>${datanucleus-core.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.thrift</groupId>\n        <artifactId>libthrift</artifactId>\n        <version>${libthrift.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-api</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>javax.annotation</groupId>\n            <artifactId>javax.annotation-api</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.thrift</groupId>\n        <artifactId>libfb303</artifactId>\n        <version>0.9.3</version>\n        <exclusions>\n          <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-api</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.antlr</groupId>\n        <artifactId>antlr4-runtime</artifactId>\n        <version>${antlr4.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>com.ibm.icu</groupId>\n        <artifactId>icu4j</artifactId>\n        <version>${icu4j.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.commons</groupId>\n        <artifactId>commons-crypto</artifactId>\n        <version>${commons-crypto.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>net.java.dev.jna</groupId>\n            <artifactId>jna</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>com.google.crypto.tink</groupId>\n        <artifactId>tink</artifactId>\n        <version>${tink.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>com.google.errorprone</groupId>\n            <artifactId>error_prone_annotations</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>com.google.http-client</groupId>\n            <artifactId>google-http-client</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.arrow</groupId>\n        <artifactId>arrow-vector</artifactId>\n        <version>${arrow.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>com.fasterxml.jackson.core</groupId>\n            <artifactId>jackson-annotations</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>com.fasterxml.jackson.core</groupId>\n            <artifactId>jackson-core</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-common</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.arrow</groupId>\n        <artifactId>arrow-memory-netty</artifactId>\n        <version>${arrow.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-buffer</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>io.netty</groupId>\n            <artifactId>netty-common</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>com.univocity</groupId>\n        <artifactId>univocity-parsers</artifactId>\n        <version>2.9.1</version>\n      </dependency>\n      <dependency>\n        <groupId>${hive.group}</groupId>\n        <artifactId>hive-storage-api</artifactId>\n        <version>${hive.storage.version}</version>\n        <scope>${hive.storage.scope}</scope>\n        <exclusions>\n          <exclusion>\n            <groupId>commons-lang</groupId>\n            <artifactId>commons-lang</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>commons-cli</groupId>\n        <artifactId>commons-cli</artifactId>\n        <version>${commons-cli.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>dev.ludovic.netlib</groupId>\n        <artifactId>blas</artifactId>\n        <version>${netlib.ludovic.dev.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>dev.ludovic.netlib</groupId>\n        <artifactId>lapack</artifactId>\n        <version>${netlib.ludovic.dev.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>dev.ludovic.netlib</groupId>\n        <artifactId>arpack</artifactId>\n        <version>${netlib.ludovic.dev.version}</version>\n      </dependency>\n      <!-- SPARK-16484 add `datasketches-java` for support Datasketches HllSketch -->\n      <dependency>\n        <groupId>org.apache.datasketches</groupId>\n        <artifactId>datasketches-java</artifactId>\n        <version>${datasketches.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>jakarta.servlet</groupId>\n        <artifactId>jakarta.servlet-api</artifactId>\n        <version>${jakartaservlet.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>javax.servlet</groupId>\n        <artifactId>javax.servlet-api</artifactId>\n        <version>${javaxservlet.version}</version>\n      </dependency>\n    </dependencies>\n  </dependencyManagement>\n\n  <build>\n    <pluginManagement>\n      <plugins>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-enforcer-plugin</artifactId>\n          <version>3.4.1</version>\n          <executions>\n            <execution>\n              <id>enforce-versions</id>\n              <goals>\n                <goal>enforce</goal>\n              </goals>\n              <configuration>\n                <rules>\n                  <requireMavenVersion>\n                    <version>${maven.version}</version>\n                  </requireMavenVersion>\n                  <requireJavaVersion>\n                    <version>${java.version}</version>\n                  </requireJavaVersion>\n                  <bannedDependencies>\n                    <excludes>\n                      <exclude>org.apache.hadoop:hadoop-common</exclude>\n                      <exclude>org.apache.hadoop:hadoop-hdfs-client</exclude>\n                      <exclude>org.apache.hadoop:hadoop-mapreduce-client-core</exclude>\n                      <exclude>org.apache.hadoop:hadoop-mapreduce-client-jobclient</exclude>\n                      <exclude>org.jboss.netty</exclude>\n                      <exclude>org.codehaus.groovy</exclude>\n                      <exclude>com.amazonaws:aws-java-sdk-bundle</exclude>\n                      <exclude>*:*_2.12</exclude>\n                      <exclude>*:*_2.11</exclude>\n                      <exclude>*:*_2.10</exclude>\n                    </excludes>\n                    <searchTransitive>true</searchTransitive>\n                  </bannedDependencies>\n                  <enforceBytecodeVersion>\n                    <maxJdkVersion>${java.version}</maxJdkVersion>\n                    <ignoredScopes>test</ignoredScopes>\n                    <ignoredScopes>provided</ignoredScopes>\n                    <ignoreClasses>\n                      <!--\n                        The package `org.jline.terminal.impl.ffm.*` contains some class files\n                        that are not compatible with JDK17 (only JDK21 is supported).\n                        However, it will not cause problems for use. See: https://github.com/scala/bug/issues/12994\n                      -->\n                      <ignoreClass>org.jline.terminal.impl.ffm.*</ignoreClass>\n                    </ignoreClasses>\n                  </enforceBytecodeVersion>\n                </rules>\n              </configuration>\n            </execution>\n            <execution>\n              <id>enforce-no-duplicate-dependencies</id>\n              <goals>\n                <goal>enforce</goal>\n              </goals>\n              <configuration>\n                <rules>\n                  <banDuplicatePomDependencyVersions/>\n                </rules>\n              </configuration>\n            </execution>\n          </executions>\n          <dependencies>\n            <dependency>\n              <groupId>org.codehaus.mojo</groupId>\n              <artifactId>extra-enforcer-rules</artifactId>\n              <version>1.8.0</version>\n            </dependency>\n          </dependencies>\n        </plugin>\n        <plugin>\n          <groupId>org.codehaus.mojo</groupId>\n          <artifactId>build-helper-maven-plugin</artifactId>\n          <version>3.5.0</version>\n          <executions>\n            <execution>\n              <id>module-timestamp-property</id>\n              <phase>validate</phase>\n              <goals>\n                <goal>timestamp-property</goal>\n              </goals>\n              <configuration>\n                <name>module.build.timestamp</name>\n                <pattern>${maven.build.timestamp.format}</pattern>\n                <timeSource>current</timeSource>\n                <timeZone>America/Los_Angeles</timeZone>\n              </configuration>\n            </execution>\n            <execution>\n              <id>local-timestamp-property</id>\n              <phase>validate</phase>\n              <goals>\n                <goal>timestamp-property</goal>\n              </goals>\n              <configuration>\n                <name>local.build.timestamp</name>\n                <pattern>${maven.build.timestamp.format}</pattern>\n                <timeSource>build</timeSource>\n                <timeZone>America/Los_Angeles</timeZone>\n              </configuration>\n            </execution>\n          </executions>\n        </plugin>\n        <plugin>\n          <groupId>net.alchim31.maven</groupId>\n          <artifactId>scala-maven-plugin</artifactId>\n          <version>${scala-maven-plugin.version}</version>\n          <executions>\n            <execution>\n              <id>eclipse-add-source</id>\n              <goals>\n                <goal>add-source</goal>\n              </goals>\n            </execution>\n            <execution>\n              <id>scala-compile-first</id>\n              <goals>\n                <goal>compile</goal>\n              </goals>\n            </execution>\n            <execution>\n              <id>scala-test-compile-first</id>\n              <goals>\n                <goal>testCompile</goal>\n              </goals>\n            </execution>\n            <execution>\n              <id>attach-scaladocs</id>\n              <phase>verify</phase>\n              <goals>\n                <goal>doc-jar</goal>\n              </goals>\n              <configuration>\n                <skip>${maven.scaladoc.skip}</skip>\n              </configuration>\n            </execution>\n          </executions>\n          <configuration>\n            <scalaVersion>${scala.version}</scalaVersion>\n            <checkMultipleScalaVersions>true</checkMultipleScalaVersions>\n            <failOnMultipleScalaVersions>true</failOnMultipleScalaVersions>\n            <recompileMode>incremental</recompileMode>\n            <args>\n              <arg>-unchecked</arg>\n              <arg>-deprecation</arg>\n              <arg>-feature</arg>\n              <arg>-explaintypes</arg>\n              <arg>-release</arg>\n              <arg>17</arg>\n              <arg>-Wconf:any:e</arg>\n              <arg>-Wconf:cat=deprecation:wv</arg>\n              <arg>-Wunused:imports</arg>\n              <arg>-Wconf:cat=scaladoc:wv</arg>\n              <arg>-Wconf:msg=^(?=.*?method|value|type|object|trait|inheritance)(?=.*?deprecated)(?=.*?since 2.13).+$:e</arg>\n              <arg>-Wconf:msg=^(?=.*?Widening conversion from)(?=.*?is deprecated because it loses precision).+$:e</arg>\n              <!-- SPARK-45610 Convert \"Auto-application to `()` is deprecated\" to compile error, as it will become a compile error in Scala 3. -->\n              <arg>-Wconf:cat=deprecation&amp;msg=Auto-application to \\`\\(\\)\\` is deprecated:e</arg>\n              <!--\n                SPARK-35574 Prevent the recurrence of compilation warnings related to\n                `procedure syntax is deprecated`\n              -->\n              <arg>-Wconf:cat=deprecation&amp;msg=procedure syntax is deprecated:e</arg>\n              <!--\n                SPARK-45627 Symbol literals are deprecated in Scala 2.13 and it's a compile error in Scala 3.\n              -->\n              <arg>-Wconf:cat=deprecation&amp;msg=symbol literal is deprecated:e</arg>\n              <!--\n                SPARK-45627 `enum`, `export` and `given` will become keywords in Scala 3,\n                so they are prohibited from being used as variable names in Scala 2.13 to\n                reduce the cost of migration in subsequent versions.\n              -->\n              <arg>-Wconf:cat=deprecation&amp;msg=it will become a keyword in Scala 3:e</arg>\n              <!--\n                SPARK-49937 ban call the method `SparkThrowable#getErrorClass`\n              -->\n              <arg>-Wconf:cat=deprecation&amp;msg=method getErrorClass in trait SparkThrowable is deprecated:e</arg>\n            </args>\n            <jvmArgs>\n              <jvmArg>-Xss128m</jvmArg>\n              <jvmArg>-Xms4g</jvmArg>\n              <jvmArg>-Xmx4g</jvmArg>\n              <jvmArg>-XX:MaxMetaspaceSize=2g</jvmArg>\n              <jvmArg>-XX:ReservedCodeCacheSize=${CodeCacheSize}</jvmArg>\n            </jvmArgs>\n            <javacArgs>\n              <javacArg>--release</javacArg>\n              <javacArg>${java.version}</javacArg>\n              <javacArg>-Xlint:all,-serial,-path,-try</javacArg>\n            </javacArgs>\n          </configuration>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-compiler-plugin</artifactId>\n          <version>3.13.0</version>\n          <configuration>\n            <skipMain>true</skipMain> <!-- skip compile -->\n            <skip>true</skip> <!-- skip testCompile -->\n          </configuration>\n        </plugin>\n        <plugin>\n          <groupId>org.antlr</groupId>\n          <artifactId>antlr4-maven-plugin</artifactId>\n          <version>${antlr4.version}</version>\n        </plugin>\n        <!-- Surefire runs all Java tests -->\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-surefire-plugin</artifactId>\n          <version>3.2.5</version>\n          <!-- Note config is repeated in scalatest config -->\n          <configuration>\n            <includes>\n              <include>**/Test*.java</include>\n              <include>**/*Test.java</include>\n              <include>**/*TestCase.java</include>\n              <include>**/*Suite.java</include>\n            </includes>\n            <reportsDirectory>${project.build.directory}/surefire-reports</reportsDirectory>\n            <argLine>-ea -Xmx4g -Xss4m -XX:MaxMetaspaceSize=2g -XX:ReservedCodeCacheSize=${CodeCacheSize} ${extraJavaTestArgs}</argLine>\n            <environmentVariables>\n              <!--\n                Setting SPARK_DIST_CLASSPATH is a simple way to make sure any child processes\n                launched by the tests have access to the correct test-time classpath.\n              -->\n              <SPARK_DIST_CLASSPATH>${test_classpath}</SPARK_DIST_CLASSPATH>\n              <SPARK_PREPEND_CLASSES>1</SPARK_PREPEND_CLASSES>\n              <SPARK_SCALA_VERSION>${scala.binary.version}</SPARK_SCALA_VERSION>\n              <SPARK_TESTING>1</SPARK_TESTING>\n              <JAVA_HOME>${test.java.home}</JAVA_HOME>\n              <SPARK_BEELINE_OPTS>-DmyKey=yourValue</SPARK_BEELINE_OPTS>\n            </environmentVariables>\n            <systemPropertyVariables>\n              <log4j.configurationFile>file:src/test/resources/log4j2.properties</log4j.configurationFile>\n              <derby.system.durability>test</derby.system.durability>\n              <java.awt.headless>true</java.awt.headless>\n              <java.io.tmpdir>${project.build.directory}/tmp</java.io.tmpdir>\n              <spark.test.home>${spark.test.home}</spark.test.home>\n              <spark.testing>1</spark.testing>\n              <spark.master.rest.enabled>false</spark.master.rest.enabled>\n              <spark.ui.enabled>false</spark.ui.enabled>\n              <spark.ui.showConsoleProgress>false</spark.ui.showConsoleProgress>\n              <spark.unsafe.exceptionOnMemoryLeak>true</spark.unsafe.exceptionOnMemoryLeak>\n              <spark.memory.debugFill>true</spark.memory.debugFill>\n              <!-- Needed by sql/hive tests. -->\n              <test.src.tables>src</test.src.tables>\n              <hive.conf.validation>false</hive.conf.validation>\n            </systemPropertyVariables>\n            <failIfNoTests>false</failIfNoTests>\n            <failIfNoSpecifiedTests>false</failIfNoSpecifiedTests>\n            <excludedGroups>${test.exclude.tags}</excludedGroups>\n            <groups>${test.include.tags}</groups>\n          </configuration>\n          <executions>\n            <execution>\n              <id>test</id>\n              <goals>\n                <goal>test</goal>\n              </goals>\n            </execution>\n          </executions>\n        </plugin>\n        <!-- Scalatest runs all Scala tests -->\n        <plugin>\n          <groupId>org.scalatest</groupId>\n          <artifactId>scalatest-maven-plugin</artifactId>\n          <version>${scalatest-maven-plugin.version}</version>\n          <!-- Note config is repeated in surefire config -->\n          <configuration>\n            <reportsDirectory>${project.build.directory}/surefire-reports</reportsDirectory>\n            <junitxml>.</junitxml>\n            <filereports>SparkTestSuite.txt</filereports>\n            <argLine>-ea -Xmx4g -Xss4m -XX:MaxMetaspaceSize=2g -XX:ReservedCodeCacheSize=${CodeCacheSize} ${extraJavaTestArgs}</argLine>\n            <stderr/>\n            <environmentVariables>\n              <!--\n                Setting SPARK_DIST_CLASSPATH is a simple way to make sure any child processes\n                launched by the tests have access to the correct test-time classpath.\n              -->\n              <SPARK_DIST_CLASSPATH>${test_classpath}</SPARK_DIST_CLASSPATH>\n              <SPARK_PREPEND_CLASSES>1</SPARK_PREPEND_CLASSES>\n              <SPARK_SCALA_VERSION>${scala.binary.version}</SPARK_SCALA_VERSION>\n              <SPARK_TESTING>1</SPARK_TESTING>\n              <JAVA_HOME>${test.java.home}</JAVA_HOME>\n            </environmentVariables>\n            <systemProperties>\n              <log4j.configurationFile>file:src/test/resources/log4j2.properties</log4j.configurationFile>\n              <derby.system.durability>test</derby.system.durability>\n              <java.awt.headless>true</java.awt.headless>\n              <java.io.tmpdir>${project.build.directory}/tmp</java.io.tmpdir>\n              <spark.test.home>${spark.test.home}</spark.test.home>\n              <spark.testing>1</spark.testing>\n              <spark.ui.enabled>false</spark.ui.enabled>\n              <spark.ui.showConsoleProgress>false</spark.ui.showConsoleProgress>\n              <spark.unsafe.exceptionOnMemoryLeak>true</spark.unsafe.exceptionOnMemoryLeak>\n              <spark.test.webdriver.chrome.driver>${spark.test.webdriver.chrome.driver}</spark.test.webdriver.chrome.driver>\n              <spark.test.docker.keepContainer>${spark.test.docker.keepContainer}</spark.test.docker.keepContainer>\n              <spark.test.docker.removePulledImage>${spark.test.docker.removePulledImage}</spark.test.docker.removePulledImage>\n              <!-- Needed by sql/hive tests. -->\n              <test.src.tables>__not_used__</test.src.tables>\n            </systemProperties>\n            <tagsToExclude>${test.exclude.tags},${test.default.exclude.tags}</tagsToExclude>\n            <tagsToInclude>${test.include.tags}</tagsToInclude>\n          </configuration>\n          <executions>\n            <execution>\n              <id>test</id>\n              <goals>\n                <goal>test</goal>\n              </goals>\n            </execution>\n          </executions>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-jar-plugin</artifactId>\n          <version>3.4.0</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-antrun-plugin</artifactId>\n          <version>${maven-antrun.version}</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-source-plugin</artifactId>\n          <version>3.3.1</version>\n          <configuration>\n            <attach>true</attach>\n          </configuration>\n          <executions>\n            <execution>\n              <id>create-source-jar</id>\n              <goals>\n                <goal>jar-no-fork</goal>\n                <goal>test-jar-no-fork</goal>\n              </goals>\n            </execution>\n          </executions>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-clean-plugin</artifactId>\n          <version>3.3.2</version>\n          <configuration>\n            <filesets>\n              <fileset>\n                <directory>work</directory>\n              </fileset>\n              <fileset>\n                <directory>checkpoint</directory>\n              </fileset>\n              <fileset>\n                <directory>lib_managed</directory>\n              </fileset>\n              <fileset>\n                <directory>metastore_db</directory>\n              </fileset>\n              <fileset>\n                <directory>spark-warehouse</directory>\n              </fileset>\n              <fileset>\n                <directory>dist</directory>\n              </fileset>\n            </filesets>\n          </configuration>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-javadoc-plugin</artifactId>\n          <version>3.6.3</version>\n          <configuration>\n            <additionalJOptions>\n              <additionalJOption>-Xdoclint:all</additionalJOption>\n              <additionalJOption>-Xdoclint:-missing</additionalJOption>\n            </additionalJOptions>\n            <tags>\n              <tag>\n                <name>example</name>\n                <placement>a</placement>\n                <head>Example:</head>\n              </tag>\n              <tag>\n                <name>note</name>\n                <placement>a</placement>\n                <head>Note:</head>\n              </tag>\n              <tag>\n                <name>group</name>\n                <placement>X</placement>\n              </tag>\n              <tag>\n                <name>tparam</name>\n                <placement>X</placement>\n              </tag>\n              <tag>\n                <name>constructor</name>\n                <placement>X</placement>\n              </tag>\n              <tag>\n                <name>todo</name>\n                <placement>X</placement>\n              </tag>\n              <tag>\n                <name>groupname</name>\n                <placement>X</placement>\n              </tag>\n            </tags>\n          </configuration>\n        </plugin>\n        <plugin>\n          <groupId>org.codehaus.mojo</groupId>\n          <artifactId>exec-maven-plugin</artifactId>\n          <version>${exec-maven-plugin.version}</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-assembly-plugin</artifactId>\n          <version>3.7.1</version>\n          <configuration>\n            <tarLongFileMode>posix</tarLongFileMode>\n          </configuration>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-shade-plugin</artifactId>\n          <version>3.5.2</version>\n          <dependencies>\n            <dependency>\n              <groupId>org.ow2.asm</groupId>\n              <artifactId>asm</artifactId>\n              <version>${asm.version}</version>\n            </dependency>\n            <dependency>\n              <groupId>org.ow2.asm</groupId>\n              <artifactId>asm-commons</artifactId>\n              <version>${asm.version}</version>\n            </dependency>\n          </dependencies>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-install-plugin</artifactId>\n          <version>3.1.2</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-deploy-plugin</artifactId>\n          <version>3.1.2</version>\n          <configuration>\n            <retryFailedDeploymentCount>3</retryFailedDeploymentCount>\n          </configuration>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-dependency-plugin</artifactId>\n          <version>3.6.1</version>\n          <executions>\n            <execution>\n              <id>default-cli</id>\n              <goals>\n                 <goal>build-classpath</goal>\n              </goals>\n              <configuration>\n                <!-- This includes dependencies with 'runtime' and 'compile' scopes;\n                     see the docs for includeScope for more details -->\n                <includeScope>runtime</includeScope>\n              </configuration>\n            </execution>\n          </executions>\n        </plugin>\n        <plugin>\n          <groupId>org.codehaus.mojo</groupId>\n          <artifactId>versions-maven-plugin</artifactId>\n          <version>${versions-maven-plugin.version}</version>\n        </plugin>\n      </plugins>\n    </pluginManagement>\n\n    <plugins>\n      <!-- This plugin dumps the test classpath into a file -->\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-dependency-plugin</artifactId>\n        <executions>\n          <execution>\n            <id>generate-test-classpath</id>\n            <phase>test-compile</phase>\n            <goals>\n              <goal>build-classpath</goal>\n            </goals>\n            <configuration>\n              <includeScope>test</includeScope>\n              <outputProperty>test_classpath</outputProperty>\n            </configuration>\n          </execution>\n          <execution>\n            <id>copy-module-dependencies</id>\n            <phase>${build.copyDependenciesPhase}</phase>\n            <goals>\n              <goal>copy-dependencies</goal>\n            </goals>\n            <configuration>\n              <includeScope>runtime</includeScope>\n              <outputDirectory>${jars.target.dir}</outputDirectory>\n            </configuration>\n          </execution>\n        </executions>\n      </plugin>\n\n      <!--\n        The shade plug-in is used here to create effective pom's (see SPARK-3812), and also\n        remove references from the shaded libraries from artifacts published by Spark.\n      -->\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-shade-plugin</artifactId>\n        <configuration>\n          <shadedArtifactAttached>false</shadedArtifactAttached>\n          <artifactSet>\n            <includes>\n              <include>org.spark-project.spark:unused</include>\n              <include>com.google.guava:guava</include>\n              <include>com.google.guava:failureaccess</include>\n              <include>org.jpmml:*</include>\n            </includes>\n          </artifactSet>\n          <relocations>\n            <relocation>\n              <pattern>org.eclipse.jetty</pattern>\n              <shadedPattern>${spark.shade.packageName}.jetty</shadedPattern>\n              <includes>\n                <include>org.eclipse.jetty.**</include>\n              </includes>\n            </relocation>\n            <relocation>\n              <pattern>com.google.common</pattern>\n              <shadedPattern>${spark.shade.packageName}.guava</shadedPattern>\n            </relocation>\n            <relocation>\n              <pattern>org.dmg.pmml</pattern>\n              <shadedPattern>${spark.shade.packageName}.dmg.pmml</shadedPattern>\n            </relocation>\n            <relocation>\n              <pattern>org.jpmml</pattern>\n              <shadedPattern>${spark.shade.packageName}.jpmml</shadedPattern>\n            </relocation>\n          </relocations>\n        </configuration>\n        <executions>\n          <execution>\n            <phase>package</phase>\n            <goals>\n              <goal>shade</goal>\n            </goals>\n          </execution>\n        </executions>\n      </plugin>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-enforcer-plugin</artifactId>\n      </plugin>\n      <plugin>\n        <groupId>net.alchim31.maven</groupId>\n        <artifactId>scala-maven-plugin</artifactId>\n      </plugin>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-source-plugin</artifactId>\n      </plugin>\n      <plugin>\n        <groupId>org.scalastyle</groupId>\n        <artifactId>scalastyle-maven-plugin</artifactId>\n        <version>1.0.0</version>\n        <configuration>\n          <verbose>false</verbose>\n          <failOnViolation>true</failOnViolation>\n          <includeTestSourceDirectory>false</includeTestSourceDirectory>\n          <failOnWarning>false</failOnWarning>\n          <sourceDirectory>${basedir}/src/main/scala</sourceDirectory>\n          <testSourceDirectory>${basedir}/src/test/scala</testSourceDirectory>\n          <configLocation>scalastyle-config.xml</configLocation>\n          <outputFile>${basedir}/target/scalastyle-output.xml</outputFile>\n          <inputEncoding>${project.build.sourceEncoding}</inputEncoding>\n          <outputEncoding>${project.reporting.outputEncoding}</outputEncoding>\n        </configuration>\n        <executions>\n          <execution>\n            <goals>\n              <goal>check</goal>\n            </goals>\n          </execution>\n        </executions>\n      </plugin>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-checkstyle-plugin</artifactId>\n        <version>3.3.1</version>\n        <configuration>\n          <failOnViolation>false</failOnViolation>\n          <includeTestSourceDirectory>true</includeTestSourceDirectory>\n          <sourceDirectories>\n            <directory>${basedir}/src/main/java</directory>\n            <directory>${basedir}/src/main/scala</directory>\n          </sourceDirectories>\n          <testSourceDirectories>\n            <directory>${basedir}/src/test/java</directory>\n          </testSourceDirectories>\n          <configLocation>dev/checkstyle.xml</configLocation>\n          <outputFile>${basedir}/target/checkstyle-output.xml</outputFile>\n          <inputEncoding>${project.build.sourceEncoding}</inputEncoding>\n          <outputEncoding>${project.reporting.outputEncoding}</outputEncoding>\n        </configuration>\n        <dependencies>\n          <dependency>\n            <!--\n              If you are changing the dependency setting for checkstyle plugin,\n              please check project/plugins.sbt too.\n            -->\n            <groupId>com.puppycrawl.tools</groupId>\n            <artifactId>checkstyle</artifactId>\n            <version>10.20.2</version>\n          </dependency>\n        </dependencies>\n        <executions>\n          <execution>\n            <goals>\n              <goal>check</goal>\n            </goals>\n          </execution>\n        </executions>\n      </plugin>\n\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-antrun-plugin</artifactId>\n        <executions>\n          <execution>\n            <id>create-tmp-dir</id>\n            <phase>generate-test-resources</phase>\n            <goals>\n              <goal>run</goal>\n            </goals>\n            <configuration>\n              <target>\n                <mkdir dir=\"${project.build.directory}/tmp\" />\n              </target>\n            </configuration>\n          </execution>\n        </executions>\n      </plugin>\n\n      <!-- Enable surefire and scalatest in all children, in one place: -->\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-surefire-plugin</artifactId>\n      </plugin>\n      <plugin>\n        <groupId>org.scalatest</groupId>\n        <artifactId>scalatest-maven-plugin</artifactId>\n      </plugin>\n      <!-- Build test-jar's for all projects, since some projects depend on tests from others -->\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-jar-plugin</artifactId>\n        <executions>\n          <execution>\n            <id>prepare-test-jar</id>\n            <phase>${build.testJarPhase}</phase>\n            <goals>\n              <goal>test-jar</goal>\n            </goals>\n            <configuration>\n              <excludes>\n                <exclude>log4j2.properties</exclude>\n              </excludes>\n            </configuration>\n          </execution>\n        </executions>\n      </plugin>\n      <plugin>\n        <groupId>org.antipathy</groupId>\n        <artifactId>mvn-scalafmt_${scala.binary.version}</artifactId>\n        <version>1.1.1713302731.c3d0074</version>\n        <configuration>\n          <validateOnly>${scalafmt.validateOnly}</validateOnly> <!-- (Optional) skip formatting -->\n          <skipSources>${scalafmt.skip}</skipSources>\n          <skipTestSources>${scalafmt.skip}</skipTestSources>\n          <configLocation>dev/.scalafmt.conf</configLocation> <!-- (Optional) config location -->\n          <onlyChangedFiles>${scalafmt.changedOnly}</onlyChangedFiles>\n        </configuration>\n        <executions>\n          <execution>\n            <phase>validate</phase>\n            <goals>\n              <goal>format</goal>\n            </goals>\n          </execution>\n        </executions>\n      </plugin>\n      <!--\n        Couple of dependencies are coming in bundle format (bundle is just a normal jar which\n        contains OSGi metadata in the manifest). If one don't use OSGi, then a bundle will work as\n        any other jar. Since maven doesn't have native bundle support it needs an external plugin\n        handle it. If the plugin is not added then the build can't resolve bundle dependencies.\n      -->\n      <plugin>\n        <groupId>org.apache.felix</groupId>\n        <artifactId>maven-bundle-plugin</artifactId>\n        <version>4.2.0</version>\n        <extensions>true</extensions>\n      </plugin>\n      <plugin>\n        <groupId>org.cyclonedx</groupId>\n        <artifactId>cyclonedx-maven-plugin</artifactId>\n        <version>2.8.0</version>\n        <executions>\n          <execution>\n            <phase>package</phase>\n            <goals>\n              <goal>makeBom</goal>\n            </goals>\n          </execution>\n        </executions>\n      </plugin>\n    </plugins>\n  </build>\n\n  <profiles>\n\n    <!--\n      This profile is enabled automatically by the sbt build. It changes the scope for shaded\n      dependencies, since we don't shade it in the artifacts generated by the sbt build.\n    -->\n    <profile>\n      <id>sbt</id>\n      <dependencies>\n        <dependency>\n          <groupId>com.google.guava</groupId>\n          <artifactId>guava</artifactId>\n          <scope>compile</scope>\n        </dependency>\n        <dependency>\n          <groupId>org.jpmml</groupId>\n          <artifactId>pmml-model</artifactId>\n          <scope>compile</scope>\n        </dependency>\n      </dependencies>\n    </profile>\n\n    <!-- Ganglia integration is not included by default due to LGPL-licensed code -->\n    <profile>\n      <id>spark-ganglia-lgpl</id>\n      <modules>\n        <module>connector/spark-ganglia-lgpl</module>\n      </modules>\n    </profile>\n\n    <!-- Kinesis integration is not included by default due to ASL-licensed code -->\n    <profile>\n      <id>kinesis-asl</id>\n      <modules>\n        <module>connector/kinesis-asl</module>\n        <module>connector/kinesis-asl-assembly</module>\n      </modules>\n    </profile>\n\n    <profile>\n      <id>docker-integration-tests</id>\n      <modules>\n        <module>connector/docker-integration-tests</module>\n      </modules>\n    </profile>\n\n    <!-- A series of build profiles where customizations for particular Hadoop releases can be made -->\n\n    <!-- Hadoop-a.b.c dependencies can be found at\n    http://hadoop.apache.org/docs/ra.b.c/hadoop-project-dist/hadoop-common/dependency-analysis.html\n    -->\n\n    <profile>\n      <id>hadoop-3</id>\n      <!-- Default hadoop profile. Uses global properties. -->\n    </profile>\n\n    <profile>\n      <id>yarn</id>\n      <modules>\n        <module>resource-managers/yarn</module>\n        <module>common/network-yarn</module>\n      </modules>\n    </profile>\n\n    <profile>\n      <id>kubernetes</id>\n      <modules>\n        <module>resource-managers/kubernetes/core</module>\n      </modules>\n    </profile>\n\n    <!-- generally not enabled for automated builds, but will run k8s tests -->\n    <profile>\n      <id>kubernetes-integration-tests</id>\n      <modules>\n        <module>resource-managers/kubernetes/integration-tests</module>\n      </modules>\n    </profile>\n\n    <profile>\n      <id>hive-thriftserver</id>\n      <modules>\n        <module>sql/hive-thriftserver</module>\n      </modules>\n    </profile>\n\n    <profile>\n      <id>hadoop-cloud</id>\n      <modules>\n        <module>hadoop-cloud</module>\n      </modules>\n    </profile>\n\n    <profile>\n      <id>jvm-profiler</id>\n      <modules>\n        <module>connector/profiler</module>\n      </modules>\n    </profile>\n\n    <profile>\n      <id>test-java-home</id>\n      <activation>\n        <property><name>env.JAVA_HOME</name></property>\n      </activation>\n      <properties>\n        <test.java.home>${env.JAVA_HOME}</test.java.home>\n      </properties>\n    </profile>\n\n    <!--\n     SPARK-34774 Add this property to ensure change-scala-version.sh can replace the public `scala.version`\n     property correctly.\n    -->\n    <!--\n    <profile>\n      <id>scala-2.13</id>\n      <properties>\n        <scala.version>2.13.11</scala.version>\n      </properties>\n      <build>\n        <pluginManagement>\n          <plugins>\n          </plugins>\n        </pluginManagement>\n      </build>\n    </profile>\n    -->\n\n    <!--\n     This is a profile to enable the use of the ASF snapshot and staging repositories\n     during a build. It is useful when testing against nightly or RC releases of dependencies.\n     It MUST NOT be used when building copies of Spark to use in production of for distribution,\n     -->\n    <profile>\n      <id>snapshots-and-staging</id>\n      <properties>\n        <!-- override point for ASF staging/snapshot repos -->\n        <asf.staging>https://repository.apache.org/content/groups/staging/</asf.staging>\n        <asf.snapshots>https://repository.apache.org/content/repositories/snapshots/</asf.snapshots>\n      </properties>\n\n      <pluginRepositories>\n        <pluginRepository>\n          <id>ASF Staging</id>\n          <url>${asf.staging}</url>\n        </pluginRepository>\n        <pluginRepository>\n          <id>ASF Snapshots</id>\n          <url>${asf.snapshots}</url>\n          <snapshots>\n            <enabled>true</enabled>\n          </snapshots>\n          <releases>\n            <enabled>false</enabled>\n          </releases>\n        </pluginRepository>\n\n      </pluginRepositories>\n      <repositories>\n        <repository>\n          <id>ASF Staging</id>\n          <url>${asf.staging}</url>\n        </repository>\n        <repository>\n          <id>ASF Snapshots</id>\n          <url>${asf.snapshots}</url>\n          <snapshots>\n            <enabled>true</enabled>\n          </snapshots>\n          <releases>\n            <enabled>false</enabled>\n          </releases>\n        </repository>\n      </repositories>\n    </profile>\n\n    <!--\n      These empty profiles are available in some sub-modules. Declare them here so that\n      maven does not complain when they're provided on the command line for a sub-module\n      that does not have them.\n    -->\n    <profile>\n      <id>hadoop-provided</id>\n      <properties>\n        <spark.yarn.isHadoopProvided>true</spark.yarn.isHadoopProvided>\n      </properties>\n    </profile>\n    <profile>\n      <id>derby-provided</id>\n    </profile>\n    <profile>\n      <id>hive-provided</id>\n    </profile>\n    <profile>\n      <id>orc-provided</id>\n    </profile>\n    <profile>\n      <id>parquet-provided</id>\n    </profile>\n    <profile>\n      <id>sparkr</id>\n    </profile>\n    <profile>\n      <id>jjwt</id>\n    </profile>\n    <!-- use org.openlabtesting.leveldbjni on aarch64 platform except MacOS -->\n    <profile>\n      <id>aarch64</id>\n      <properties>\n        <leveldbjni.group>org.openlabtesting.leveldbjni</leveldbjni.group>\n      </properties>\n      <activation>\n        <os>\n          <family>linux</family>\n          <arch>aarch64</arch>\n        </os>\n      </activation>\n    </profile>\n    <profile>\n      <id>applesilicon</id>\n      <properties>\n        <test.default.exclude.tags>org.apache.spark.tags.ChromeUITest,org.apache.spark.tags.ExtendedLevelDBTest</test.default.exclude.tags>\n      </properties>\n      <activation>\n        <os>\n          <family>mac</family>\n          <arch>aarch64</arch>\n        </os>\n      </activation>\n    </profile>\n    <profile>\n      <id>jdwp-test-debug</id>\n      <properties>\n        <jdwp.arg.line>-agentlib:jdwp=transport=dt_socket,suspend=${test.jdwp.suspend},server=${test.jdwp.server},address=${test.jdwp.address}</jdwp.arg.line>\n        <debugArgLine>${jdwp.arg.line}</debugArgLine>\n        <maven.surefire.debug>${jdwp.arg.line}</maven.surefire.debug>\n        <debugForkedProcess>${test.debug.suite}</debugForkedProcess>\n      </properties>\n    </profile>\n    <profile>\n      <id>only-eclipse</id>\n      <activation>\n        <property>\n          <!-- Eclipse M2E plugin exports this property and auto-activates this profile -->\n          <name>m2e.version</name>\n        </property>\n      </activation>\n      <build>\n        <pluginManagement>\n          <plugins>\n            <!-- This plugin's configuration is used to store Eclipse m2e settings only. -->\n            <!-- It has no influence on the Maven build itself. -->\n            <plugin>\n              <groupId>org.eclipse.m2e</groupId>\n              <artifactId>lifecycle-mapping</artifactId>\n              <version>1.0.0</version>\n              <configuration>\n                <lifecycleMappingMetadata>\n                  <pluginExecutions>\n                    <pluginExecution>\n                      <pluginExecutionFilter>\n                        <groupId>org.apache.maven.plugins</groupId>\n                        <artifactId>maven-dependency-plugin</artifactId>\n                        <versionRange>[2.8,)</versionRange>\n                        <goals>\n                          <goal>build-classpath</goal>\n                        </goals>\n                      </pluginExecutionFilter>\n                      <action>\n                        <ignore></ignore>\n                      </action>\n                    </pluginExecution>\n                    <pluginExecution>\n                      <pluginExecutionFilter>\n                        <groupId>org.apache.maven.plugins</groupId>\n                        <artifactId>maven-jar-plugin</artifactId>\n                        <versionRange>3.4.0</versionRange>\n                        <goals>\n                          <goal>test-jar</goal>\n                        </goals>\n                      </pluginExecutionFilter>\n                      <action>\n                        <ignore></ignore>\n                      </action>\n                    </pluginExecution>\n                    <pluginExecution>\n                      <pluginExecutionFilter>\n                        <groupId>org.apache.maven.plugins</groupId>\n                        <artifactId>maven-antrun-plugin</artifactId>\n                        <versionRange>[${maven-antrun.version},)</versionRange>\n                        <goals>\n                          <goal>run</goal>\n                        </goals>\n                      </pluginExecutionFilter>\n                      <action>\n                        <ignore></ignore>\n                      </action>\n                    </pluginExecution>\n                  </pluginExecutions>\n                </lifecycleMappingMetadata>\n              </configuration>\n            </plugin>\n          </plugins>\n        </pluginManagement>\n      </build>\n    </profile>\n  </profiles>\n</project>\n"
        },
        {
          "name": "project",
          "type": "tree",
          "content": null
        },
        {
          "name": "python",
          "type": "tree",
          "content": null
        },
        {
          "name": "repl",
          "type": "tree",
          "content": null
        },
        {
          "name": "resource-managers",
          "type": "tree",
          "content": null
        },
        {
          "name": "sbin",
          "type": "tree",
          "content": null
        },
        {
          "name": "scalastyle-config.xml",
          "type": "blob",
          "size": 24.64,
          "content": "<!--\n  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n  ~ contributor license agreements.  See the NOTICE file distributed with\n  ~ this work for additional information regarding copyright ownership.\n  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n  ~ (the \"License\"); you may not use this file except in compliance with\n  ~ the License.  You may obtain a copy of the License at\n  ~\n  ~    http://www.apache.org/licenses/LICENSE-2.0\n  ~\n  ~ Unless required by applicable law or agreed to in writing, software\n  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  ~ See the License for the specific language governing permissions and\n  ~ limitations under the License.\n  -->\n<!--\n\nIf you wish to turn off checking for a section of code, you can put a comment in the source\nbefore and after the section, with the following syntax:\n\n  // scalastyle:off\n  ...  // stuff that breaks the styles\n  // scalastyle:on\n\nYou can also disable only one rule, by specifying its rule id, as specified in:\n  http://www.scalastyle.org/rules-0.7.0.html\n\n  // scalastyle:off no.finalize\n  override def finalize(): Unit = ...\n  // scalastyle:on no.finalize\n\nThis file is divided into 3 sections:\n (1) rules that we enforce.\n (2) rules that we would like to enforce, but haven't cleaned up the codebase to turn on yet\n     (or we need to make the scalastyle rule more configurable).\n (3) rules that we don't want to enforce.\n-->\n\n<scalastyle>\n  <name>Scalastyle standard configuration</name>\n\n  <!-- ================================================================================ -->\n  <!--                               rules we enforce                                   -->\n  <!-- ================================================================================ -->\n\n  <check level=\"error\" class=\"org.scalastyle.file.FileTabChecker\" enabled=\"true\"></check>\n\n  <check level=\"error\" class=\"org.scalastyle.file.HeaderMatchesChecker\" enabled=\"true\">\n    <parameters>\n       <parameter name=\"header\"><![CDATA[/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *    http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */]]></parameter>\n    </parameters>\n  </check>\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.SpacesAfterPlusChecker\" enabled=\"true\"></check>\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.SpacesBeforePlusChecker\" enabled=\"true\"></check>\n\n  <check level=\"error\" class=\"org.scalastyle.file.WhitespaceEndOfLineChecker\" enabled=\"true\"></check>\n\n  <check level=\"error\" class=\"org.scalastyle.file.FileLineLengthChecker\" enabled=\"true\">\n    <parameters>\n      <parameter name=\"maxLineLength\"><![CDATA[100]]></parameter>\n      <parameter name=\"tabSize\"><![CDATA[2]]></parameter>\n      <parameter name=\"ignoreImports\">true</parameter>\n    </parameters>\n  </check>\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.ClassNamesChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\"><![CDATA[[A-Z][A-Za-z]*]]></parameter></parameters>\n  </check>\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.ObjectNamesChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\"><![CDATA[(config|[A-Z][A-Za-z]*)]]></parameter></parameters>\n  </check>\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.PackageObjectNamesChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\"><![CDATA[^[a-z][A-Za-z]*$]]></parameter></parameters>\n  </check>\n\n  <check customId=\"argcount\" level=\"error\" class=\"org.scalastyle.scalariform.ParameterNumberChecker\" enabled=\"true\">\n    <parameters><parameter name=\"maxParameters\"><![CDATA[10]]></parameter></parameters>\n  </check>\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.NoFinalizeChecker\" enabled=\"true\"></check>\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.CovariantEqualsChecker\" enabled=\"true\"></check>\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.StructuralTypeChecker\" enabled=\"true\"></check>\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.UppercaseLChecker\" enabled=\"true\"></check>\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.IfBraceChecker\" enabled=\"true\">\n    <parameters>\n      <parameter name=\"singleLineAllowed\"><![CDATA[true]]></parameter>\n      <parameter name=\"doubleLineAllowed\"><![CDATA[true]]></parameter>\n    </parameters>\n  </check>\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.PublicMethodsHaveTypeChecker\" enabled=\"true\"></check>\n\n  <check level=\"error\" class=\"org.scalastyle.file.NewLineAtEofChecker\" enabled=\"true\"></check>\n\n  <check customId=\"nonascii\" level=\"error\" class=\"org.scalastyle.scalariform.NonASCIICharacterChecker\" enabled=\"true\"></check>\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.SpaceAfterCommentStartChecker\" enabled=\"true\"></check>\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.EnsureSingleSpaceBeforeTokenChecker\" enabled=\"true\">\n   <parameters>\n     <parameter name=\"tokens\">ARROW, EQUALS, ELSE, TRY, CATCH, FINALLY, LARROW, RARROW</parameter>\n   </parameters>\n  </check>\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.EnsureSingleSpaceAfterTokenChecker\" enabled=\"true\">\n    <parameters>\n     <parameter name=\"tokens\">ARROW, EQUALS, COMMA, COLON, IF, ELSE, DO, WHILE, FOR, MATCH, TRY, CATCH, FINALLY, LARROW, RARROW</parameter>\n    </parameters>\n  </check>\n\n  <!-- ??? usually shouldn't be checked into the code base. -->\n  <check level=\"error\" class=\"org.scalastyle.scalariform.NotImplementedErrorUsage\" enabled=\"true\"></check>\n\n  <!-- As of SPARK-7558, all tests in Spark should extend o.a.s.SparkFunSuite instead of AnyFunSuite directly -->\n  <check customId=\"funsuite\" level=\"error\" class=\"org.scalastyle.scalariform.TokenChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">^AnyFunSuite[A-Za-z]*$</parameter></parameters>\n    <customMessage>Tests must extend org.apache.spark.SparkFunSuite instead.</customMessage>\n  </check>\n\n  <!-- As of SPARK-7977 all printlns need to be wrapped in '// scalastyle:off/on println' -->\n  <check customId=\"println\" level=\"error\" class=\"org.scalastyle.scalariform.TokenChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">^println$</parameter></parameters>\n    <customMessage><![CDATA[Are you sure you want to println? If yes, wrap the code block with\n      // scalastyle:off println\n      println(...)\n      // scalastyle:on println]]></customMessage>\n  </check>\n\n  <check customId=\"invalidMDC\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">s\".*\\$\\{MDC\\(</parameter></parameters>\n    <customMessage><![CDATA[MDC should be used in string interpolation log\"...\" instead of s\"...\"]]></customMessage>\n  </check>\n\n  <check customId=\"hadoopconfiguration\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">spark(.sqlContext)?.sparkContext.hadoopConfiguration</parameter></parameters>\n    <customMessage><![CDATA[\n      Are you sure that you want to use sparkContext.hadoopConfiguration? In most cases, you should use\n      spark.sessionState.newHadoopConf() instead, so that the hadoop configurations specified in Spark session\n      configuration will come into effect.\n      If you must use sparkContext.hadoopConfiguration, wrap the code block with\n      // scalastyle:off hadoopconfiguration\n      spark.sparkContext.hadoopConfiguration...\n      // scalastyle:on hadoopconfiguration\n    ]]></customMessage>\n  </check>\n\n  <check customId=\"visiblefortesting\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">@VisibleForTesting</parameter></parameters>\n    <customMessage><![CDATA[\n      @VisibleForTesting causes classpath issues. Please note this in the java doc instead (SPARK-11615).\n    ]]></customMessage>\n  </check>\n\n  <check customId=\"runtimeaddshutdownhook\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">Runtime\\.getRuntime\\.addShutdownHook</parameter></parameters>\n    <customMessage><![CDATA[\n      Are you sure that you want to use Runtime.getRuntime.addShutdownHook? In most cases, you should use\n      ShutdownHookManager.addShutdownHook instead.\n      If you must use Runtime.getRuntime.addShutdownHook, wrap the code block with\n      // scalastyle:off runtimeaddshutdownhook\n      Runtime.getRuntime.addShutdownHook(...)\n      // scalastyle:on runtimeaddshutdownhook\n    ]]></customMessage>\n  </check>\n\n  <check customId=\"mutablesynchronizedbuffer\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">mutable\\.SynchronizedBuffer</parameter></parameters>\n    <customMessage><![CDATA[\n      Are you sure that you want to use mutable.SynchronizedBuffer? In most cases, you should use\n      java.util.concurrent.ConcurrentLinkedQueue instead.\n      If you must use mutable.SynchronizedBuffer, wrap the code block with\n      // scalastyle:off mutablesynchronizedbuffer\n      mutable.SynchronizedBuffer[...]\n      // scalastyle:on mutablesynchronizedbuffer\n    ]]></customMessage>\n  </check>\n\n  <check customId=\"classforname\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">Class\\.forName</parameter></parameters>\n    <customMessage><![CDATA[\n      Are you sure that you want to use Class.forName? In most cases, you should use Utils.classForName instead.\n      If you must use Class.forName, wrap the code block with\n      // scalastyle:off classforname\n      Class.forName(...)\n      // scalastyle:on classforname\n    ]]></customMessage>\n  </check>\n\n  <check customId=\"awaitresult\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">Await\\.result</parameter></parameters>\n    <customMessage><![CDATA[\n      Are you sure that you want to use Await.result? In most cases, you should use ThreadUtils.awaitResult instead.\n      If you must use Await.result, wrap the code block with\n      // scalastyle:off awaitresult\n      Await.result(...)\n      // scalastyle:on awaitresult\n    ]]></customMessage>\n  </check>\n\n  <check customId=\"awaitready\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">Await\\.ready</parameter></parameters>\n    <customMessage><![CDATA[\n      Are you sure that you want to use Await.ready? In most cases, you should use ThreadUtils.awaitReady instead.\n      If you must use Await.ready, wrap the code block with\n      // scalastyle:off awaitready\n      Await.ready(...)\n      // scalastyle:on awaitready\n    ]]></customMessage>\n  </check>\n\n  <check customId=\"parvector\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">new.*ParVector</parameter></parameters>\n    <customMessage><![CDATA[\n      Are you sure you want to create a ParVector? It will not automatically propagate Spark ThreadLocals or the\n      active SparkSession for the submitted tasks. In most cases, you should use ThreadUtils.parmap instead.\n      If you must use ParVector, then wrap your creation of the ParVector with\n      // scalastyle:off parvector\n      ...ParVector...\n      // scalastyle:on parvector\n    ]]></customMessage>\n  </check>\n\n  <check customId=\"caselocale\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">(\\.toUpperCase|\\.toLowerCase)(?!(\\(|\\(Locale.ROOT\\)))</parameter></parameters>\n    <customMessage><![CDATA[\n      Are you sure that you want to use toUpperCase or toLowerCase without the root locale? In most cases, you\n      should use toUpperCase(Locale.ROOT) or toLowerCase(Locale.ROOT) instead.\n      If you must use toUpperCase or toLowerCase without the root locale, wrap the code block with\n      // scalastyle:off caselocale\n      .toUpperCase\n      .toLowerCase\n      // scalastyle:on caselocale\n    ]]></customMessage>\n  </check>\n\n  <check customId=\"throwerror\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">throw new \\w+Error\\(</parameter></parameters>\n    <customMessage><![CDATA[\n      Are you sure that you want to throw Error? In most cases, you should use appropriate Exception instead.\n      If you must throw Error, wrap the code block with\n      // scalastyle:off throwerror\n      throw new XXXError(...)\n      // scalastyle:on throwerror\n    ]]></customMessage>\n  </check>\n\n  <!-- As of SPARK-45338 JavaConversions should be replaced with CollectionConverters -->\n  <check customId=\"javaconversions\" level=\"error\" class=\"org.scalastyle.scalariform.TokenChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">JavaConversions</parameter></parameters>\n    <customMessage>Instead of importing implicits in scala.collection.JavaConversions._, import\n      scala.jdk.CollectionConverters._ and use .asScala / .asJava methods</customMessage>\n  </check>\n\n  <!-- As of SPARK-45338 JavaConverters should be replaced with CollectionConverters -->\n  <check customId=\"javaconverters\" level=\"error\" class=\"org.scalastyle.scalariform.TokenChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">JavaConverters</parameter></parameters>\n    <customMessage>Instead of importing implicits in scala.collection.JavaConverters._, import\n      scala.jdk.CollectionConverters._ and use .asScala / .asJava methods</customMessage>\n  </check>\n\n  <check customId=\"commonslang2\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">org\\.apache\\.commons\\.lang\\.</parameter></parameters>\n    <customMessage>Use Commons Lang 3 classes (package org.apache.commons.lang3.*) instead\n    of Commons Lang 2 (package org.apache.commons.lang.*)</customMessage>\n  </check>\n\n  <check customId=\"uribuilder\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">UriBuilder\\.fromUri</parameter></parameters>\n    <customMessage>Use Utils.getUriBuilder instead.</customMessage>\n  </check>\n\n  <check customId=\"executioncontextglobal\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">scala\\.concurrent\\.ExecutionContext\\.Implicits\\.global</parameter></parameters>\n    <customMessage> User queries can use global thread pool, causing starvation and eventual OOM.\n      Thus, Spark-internal APIs should not use this thread pool</customMessage>\n  </check>\n\n  <check customId=\"FileSystemGet\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">FileSystem.get\\([a-zA-Z_$][a-zA-Z_$0-9]*\\)</parameter></parameters>\n    <customMessage><![CDATA[\n      Are you sure that you want to use \"FileSystem.get(Configuration conf)\"? If the input\n      configuration is not set properly, a default FileSystem instance will be returned. It can\n      lead to errors when you deal with multiple file systems. Please consider using\n      \"FileSystem.get(URI uri, Configuration conf)\" or \"Path.getFileSystem(Configuration conf)\" instead.\n      If you must use the method \"FileSystem.get(Configuration conf)\", wrap the code block with\n      // scalastyle:off FileSystemGet\n      FileSystem.get(...)\n      // scalastyle:on FileSystemGet\n    ]]></customMessage>\n  </check>\n\n  <check customId=\"extractopt\" level=\"error\" class=\"org.scalastyle.scalariform.TokenChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">extractOpt</parameter></parameters>\n    <customMessage>Use jsonOption(x).map(.extract[T]) instead of .extractOpt[T], as the latter\n    is slower.  </customMessage>\n  </check>\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.ImportOrderChecker\" enabled=\"true\">\n    <parameters>\n      <parameter name=\"groups\">java,scala,3rdParty,spark</parameter>\n      <parameter name=\"group.java\">javax?\\..*</parameter>\n      <parameter name=\"group.scala\">scala\\..*</parameter>\n      <parameter name=\"group.3rdParty\">(?!(javax?\\.|scala\\.|org\\.apache\\.spark\\.)).*</parameter>\n      <parameter name=\"group.spark\">org\\.apache\\.spark\\..*</parameter>\n    </parameters>\n  </check>\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.DisallowSpaceBeforeTokenChecker\" enabled=\"true\">\n    <parameters>\n      <parameter name=\"tokens\">COMMA</parameter>\n    </parameters>\n  </check>\n\n  <!-- SPARK-3854: Single Space between ')' and '{' -->\n  <check customId=\"SingleSpaceBetweenRParenAndLCurlyBrace\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">\\)\\{</parameter></parameters>\n    <customMessage><![CDATA[\n      Single Space between ')' and `{`.\n    ]]></customMessage>\n  </check>\n\n  <check customId=\"NoScalaDoc\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">(?m)^(\\s*)/[*][*].*$(\\r|)\\n^\\1  [*]</parameter></parameters>\n    <customMessage>Use Javadoc style indentation for multiline comments</customMessage>\n  </check>\n\n  <check customId=\"OmitBracesInCase\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">case[^\\n>]*=>\\s*\\{</parameter></parameters>\n    <customMessage>Omit braces in case clauses.</customMessage>\n  </check>\n\n  <check level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">new (java\\.lang\\.)?(Byte|Integer|Long|Short)\\(</parameter></parameters>\n    <customMessage>Use static factory 'valueOf' or 'parseXXX' instead of the deprecated constructors.</customMessage>\n  </check>\n\n  <!-- SPARK-16877: Avoid Java annotations -->\n  <check level=\"error\" class=\"org.scalastyle.scalariform.OverrideJavaChecker\" enabled=\"true\"></check>\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.DeprecatedJavaChecker\" enabled=\"true\"></check>\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.IllegalImportsChecker\" enabled=\"true\">\n    <parameters><parameter name=\"illegalImports\"><![CDATA[scala.collection.Seq,scala.collection.IndexedSeq]]></parameter></parameters>\n    <customMessage><![CDATA[\n      Don't import scala.collection.Seq and scala.collection.IndexedSeq as it may bring some problems with cross-build between Scala 2.12 and 2.13.\n\n      Please refer below page to see the details of changes around Seq / IndexedSeq.\n      https://docs.scala-lang.org/overviews/core/collections-migration-213.html\n\n      If you really need to use scala.collection.Seq or scala.collection.IndexedSeq, please use the fully-qualified name instead.\n    ]]></customMessage>\n  </check>\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.IllegalImportsChecker\" enabled=\"true\">\n    <parameters><parameter name=\"illegalImports\"><![CDATA[collection]]></parameter></parameters>\n    <customMessage>Please use scala.collection instead.</customMessage>\n  </check>\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.IllegalImportsChecker\" enabled=\"true\">\n    <parameters><parameter name=\"illegalImports\"><![CDATA[org.apache.log4j]]></parameter></parameters>\n    <customMessage>Please use Apache Log4j 2 instead.</customMessage>\n  </check>\n\n\n  <!-- ================================================================================ -->\n  <!--       rules we'd like to enforce, but haven't cleaned up the codebase yet        -->\n  <!-- ================================================================================ -->\n\n  <!-- We cannot turn the following two on, because it'd fail a lot of string interpolation use cases. -->\n  <!-- Ideally the following two rules should be configurable to rule out string interpolation. -->\n  <check level=\"error\" class=\"org.scalastyle.scalariform.NoWhitespaceBeforeLeftBracketChecker\" enabled=\"false\"></check>\n  <check level=\"error\" class=\"org.scalastyle.scalariform.NoWhitespaceAfterLeftBracketChecker\" enabled=\"false\"></check>\n\n  <!-- This breaks symbolic method names so we don't turn it on. -->\n  <!-- Maybe we should update it to allow basic symbolic names, and then we are good to go. -->\n  <check level=\"error\" class=\"org.scalastyle.scalariform.MethodNamesChecker\" enabled=\"false\">\n    <parameters>\n    <parameter name=\"regex\"><![CDATA[^[a-z][A-Za-z0-9]*$]]></parameter>\n    </parameters>\n  </check>\n\n  <!-- Should turn this on, but we have a few places that need to be fixed first -->\n  <check level=\"error\" class=\"org.scalastyle.scalariform.EqualsHashCodeChecker\" enabled=\"true\"></check>\n\n  <!-- ================================================================================ -->\n  <!--                               rules we don't want                                -->\n  <!-- ================================================================================ -->\n\n  <check level=\"error\" class=\"org.scalastyle.scalariform.IllegalImportsChecker\" enabled=\"false\">\n    <parameters><parameter name=\"illegalImports\"><![CDATA[sun._,java.awt._]]></parameter></parameters>\n  </check>\n\n  <!-- We want the opposite of this: NewLineAtEofChecker -->\n  <check level=\"error\" class=\"org.scalastyle.file.NoNewLineAtEofChecker\" enabled=\"false\"></check>\n\n  <!-- This one complains about all kinds of random things. Disable. -->\n  <check level=\"error\" class=\"org.scalastyle.scalariform.SimplifyBooleanExpressionChecker\" enabled=\"false\"></check>\n\n  <!-- We use return quite a bit for control flows and guards -->\n  <check level=\"error\" class=\"org.scalastyle.scalariform.ReturnChecker\" enabled=\"false\"></check>\n\n  <!-- We use null a lot in low level code and to interface with 3rd party code -->\n  <check level=\"error\" class=\"org.scalastyle.scalariform.NullChecker\" enabled=\"false\"></check>\n\n  <!-- Doesn't seem super big deal here ... -->\n  <check level=\"error\" class=\"org.scalastyle.scalariform.NoCloneChecker\" enabled=\"false\"></check>\n\n  <!-- Doesn't seem super big deal here ... -->\n  <check level=\"error\" class=\"org.scalastyle.file.FileLengthChecker\" enabled=\"false\">\n    <parameters><parameter name=\"maxFileLength\">800></parameter></parameters>\n  </check>\n\n  <!-- Doesn't seem super big deal here ... -->\n  <check level=\"error\" class=\"org.scalastyle.scalariform.NumberOfTypesChecker\" enabled=\"false\">\n    <parameters><parameter name=\"maxTypes\">30</parameter></parameters>\n  </check>\n\n  <!-- Doesn't seem super big deal here ... -->\n  <check level=\"error\" class=\"org.scalastyle.scalariform.CyclomaticComplexityChecker\" enabled=\"false\">\n    <parameters><parameter name=\"maximum\">10</parameter></parameters>\n  </check>\n\n  <!-- Doesn't seem super big deal here ... -->\n  <check level=\"error\" class=\"org.scalastyle.scalariform.MethodLengthChecker\" enabled=\"false\">\n    <parameters><parameter name=\"maxLength\">50</parameter></parameters>\n  </check>\n\n  <!-- Not exactly feasible to enforce this right now. -->\n  <!-- It is also infrequent that somebody introduces a new class with a lot of methods. -->\n  <check level=\"error\" class=\"org.scalastyle.scalariform.NumberOfMethodsInTypeChecker\" enabled=\"false\">\n    <parameters><parameter name=\"maxMethods\"><![CDATA[30]]></parameter></parameters>\n  </check>\n\n  <!-- Doesn't seem super big deal here, and we have a lot of magic numbers ... -->\n  <check level=\"error\" class=\"org.scalastyle.scalariform.MagicNumberChecker\" enabled=\"false\">\n    <parameters><parameter name=\"ignore\">-1,0,1,2,3</parameter></parameters>\n  </check>\n\n  <check customId=\"byteCountToDisplaySize\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">byteCountToDisplaySize</parameter></parameters>\n    <customMessage>Use Utils.bytesToString instead of byteCountToDisplaySize for consistency.</customMessage>\n  </check>\n\n  <check customId=\"pathfromuri\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">new Path\\(new URI\\(</parameter></parameters>\n    <customMessage><![CDATA[\n      Are you sure that this string is uri encoded? Please be careful when converting hadoop Paths\n      and URIs to and from String. If possible, please use SparkPath.\n    ]]></customMessage>\n  </check>\n\n  <check customId=\"URLConstructor\" level=\"error\" class=\"org.scalastyle.file.RegexChecker\" enabled=\"true\">\n    <parameters><parameter name=\"regex\">new URL\\(</parameter></parameters>\n    <customMessage>Use URI.toURL or URL.of instead of URL constructors.</customMessage>\n  </check>\n</scalastyle>\n"
        },
        {
          "name": "sql",
          "type": "tree",
          "content": null
        },
        {
          "name": "streaming",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "ui-test",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}