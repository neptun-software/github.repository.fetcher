{
  "metadata": {
    "timestamp": 1736557639017,
    "page": 726,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjc1MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "apache/kafka",
      "stars": 29214,
      "defaultBranch": "trunk",
      "files": [
        {
          "name": ".asf.yaml",
          "type": "blob",
          "size": 1.31,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\nnotifications:\n  commits: commits@kafka.apache.org\n  issues: jira@kafka.apache.org\n  pullrequests: jira@kafka.apache.org\n  jira_options: link label\n\n# This list allows you to triage pull requests and trigger workflow runs on GitHub Actions. It can have a maximum of 10 collaborators.\n# Read more here: https://github.com/apache/infrastructure-asfyaml\ngithub:\n  collaborators:\n    - FrankYang0529\n    - kirktrue\n    - brandboat\n    - AndrewJSchofield\n    - OmniaGM\n    - nizhikov\n    - dongnuo123\n    - gaurav-narula\n    - apourchet\n    - apoorvmittal10\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.7,
          "content": "dist\n*classes\n*.class\ntarget/\nbuild/\nbuild_eclipse/\nout/\n.gradle/\n.vscode/\nlib_managed/\nsrc_managed/\nproject/boot/\nproject/plugins/project/\npatch-process/*\n.idea\n.svn\n.classpath\n/.metadata\n/.recommenders\n*~\n*#\n.#*\nrat.out\nTAGS\n*.iml\n.project\n.settings\n*.ipr\n*.iws\n.vagrant\nVagrantfile.local\n/logs\n.DS_Store\n\nconfig/server-*\nconfig/zookeeper-*\ngradle/wrapper/*.jar\ngradlew.bat\n\nresults\ntests/results\n.ducktape\ntests/.ducktape\ntests/venv\n.cache\n\ndocs/generated/\n\n.release-settings.json\n\nkafkatest.egg-info/\nsystest/\n*.swp\njmh-benchmarks/generated\njmh-benchmarks/src/main/generated\n**/.jqwik-database\n**/src/generated\n**/src/generated-test\nstorage/kafka-tiered-storage/\n\ndocker/test/report_*.html\nkafka.Kafka\n__pycache__\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.7,
          "content": "## Contributing to Kafka\n\n*Before opening a pull request*, review the [Contributing](https://kafka.apache.org/contributing.html) and [Contributing Code Changes](https://cwiki.apache.org/confluence/display/KAFKA/Contributing+Code+Changes) pages.\n\nIt lists steps that are required before creating a PR.\n\nWhen you contribute code, you affirm that the contribution is your original work and that you\nlicense the work to the project under the project's open source license. Whether or not you\nstate this explicitly, by submitting any copyrighted material via pull request, email, or\nother means you agree to license the material under the project's open source license and\nwarrant that you have the legal authority to do so.\n"
        },
        {
          "name": "HEADER",
          "type": "blob",
          "size": 0.74,
          "content": "Licensed to the Apache Software Foundation (ASF) under one or more\ncontributor license agreements.  See the NOTICE file distributed with\nthis work for additional information regarding copyright ownership.\nThe ASF licenses this file to You under the Apache License, Version 2.0\n(the \"License\"); you may not use this file except in compliance with\nthe License.  You may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.09,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "LICENSE-binary",
          "type": "blob",
          "size": 14.67,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n-------------------------------------------------------------------------------\nThis project bundles some components that are also licensed under the Apache\nLicense Version 2.0:\n\naudience-annotations-0.12.0\ncaffeine-3.1.1\ncommons-beanutils-1.9.4\ncommons-collections-3.2.2\ncommons-digester-2.1\ncommons-lang3-3.12.0\ncommons-logging-1.3.2\ncommons-validator-1.9.0\nerror_prone_annotations-2.14.0\njackson-annotations-2.16.2\njackson-core-2.16.2\njackson-databind-2.16.2\njackson-dataformat-csv-2.16.2\njackson-dataformat-yaml-2.16.2\njackson-datatype-jdk8-2.16.2\njackson-jakarta-rs-base-2.16.2\njackson-jakarta-rs-json-provider-2.16.2\njackson-jaxrs-base-2.16.2\njackson-jaxrs-json-provider-2.16.2\njackson-module-blackbird-2.16.2\njackson-module-jakarta-xmlbind-annotations-2.16.2\njackson-module-jaxb-annotations-2.16.2\njackson-module-scala_2.13-2.16.2\njakarta.inject-api-2.0.1\njakarta.validation-api-3.0.2\njavassist-3.29.2-GA\njetty-alpn-client-12.0.15\njetty-client-12.0.15\njetty-continuation-9.4.56.v20240826\njetty-ee10-servlet-12.0.15\njetty-ee10-servlets-12.0.15\njetty-http-12.0.15\njetty-io-12.0.15\njetty-security-12.0.15\njetty-server-12.0.15\njetty-servlet-9.4.56.v20240826\njetty-servlets-9.4.56.v20240826\njetty-session-12.0.15\njetty-util-12.0.15\njetty-util-ajax-9.4.56.v20240826\njose4j-0.9.4\nlog4j-api-2.24.1\nlog4j-core-2.24.1\nlog4j-core-test-2.24.1\nlog4j-slf4j-impl-2.24.1\nlog4j-1.2-api-2.24.1\nlz4-java-1.8.0\nmaven-artifact-3.9.6\nmetrics-core-4.1.12.1\nmetrics-core-2.2.0\nopentelemetry-proto-1.0.0-alpha\nplexus-utils-3.5.1\nrocksdbjni-9.7.3\nscala-library-2.13.15\nscala-logging_2.13-3.9.5\nscala-reflect-2.13.15\nsnappy-java-1.1.10.5\nsnakeyaml-2.2\nswagger-annotations-2.2.25\n\n===============================================================================\nThis product bundles various third-party components under other open source\nlicenses. This section summarizes those components and their licenses.\nSee licenses/ for text of these licenses.\n\n---------------------------------------\nEclipse Distribution License - v 1.0\nsee: licenses/eclipse-distribution-license-1.0\n\njakarta.activation-api-2.1.0\njakarta.xml.bind-api-3.0.1\n\n---------------------------------------\nEclipse Public License - v 2.0\nsee: licenses/eclipse-public-license-2.0\n\njakarta.annotation-api-2.1.1\njakarta.ws.rs-api-3.1.0\nhk2-api-3.0.6\nhk2-locator-3.0.6\nhk2-utils-3.0.6\nosgi-resource-locator-1.0.3\naopalliance-repackaged-3.0.6\njakarta.inject-2.6.1\njersey-client-3.1.9\njersey-common-3.1.9\njersey-container-servlet-3.1.9\njersey-container-servlet-core-3.1.9\njersey-hk2-3.1.9\njersey-server-3.1.9\n\n---------------------------------------\nCDDL 1.1 + GPLv2 with classpath exception\nsee: licenses/CDDL+GPL-1.1\n\njakarta.servlet-api-6.0.0\njavax.activation-api-1.2.0\njavax.annotation-api-1.3.2\njavax.servlet-api-3.1.0\njaxb-api-2.3.1\nactivation-1.1.1\n\n---------------------------------------\nMIT License\n\nargparse4j-0.7.0, see: licenses/argparse-MIT\nclassgraph-4.8.173, see: licenses/classgraph-MIT\njopt-simple-5.0.4, see: licenses/jopt-simple-MIT\nslf4j-api-1.7.36, see: licenses/slf4j-MIT\npcollections-4.0.1, see: licenses/pcollections-MIT\n\n---------------------------------------\nBSD 2-Clause\n\nzstd-jni-1.5.6-6 see: licenses/zstd-jni-BSD-2-clause\nHdrHistogram-2.2.2 see: licenses/hdrHistogram-BSD-2-clause\n\n---------------------------------------\nBSD 3-Clause\n\njline-3.25.1, see: licenses/jline-BSD-3-clause\njsr305-3.0.2, see: licenses/jsr305-BSD-3-clause\nparanamer-2.8, see: licenses/paranamer-BSD-3-clause\nprotobuf-java-3.25.5, see: licenses/protobuf-java-BSD-3-clause\njakarta.activation-2.0.1, see: licenses/jakarta-BSD-3-clause\n\n---------------------------------------\nGo License\n\nre2j-1.7 see: licenses/re2j-GO\n"
        },
        {
          "name": "NOTICE",
          "type": "blob",
          "size": 0.87,
          "content": "Apache Kafka\nCopyright 2025 The Apache Software Foundation.\n\nThis product includes software developed at\nThe Apache Software Foundation (https://www.apache.org/).\n\nThis distribution has a binary dependency on jersey, which is available under the CDDL\nLicense. The source code of jersey can be found at https://github.com/jersey/jersey/.\n\nThis distribution has a binary test dependency on jqwik, which is available under\nthe Eclipse Public License 2.0. The source code can be found at\nhttps://github.com/jlink/jqwik.\n\nThe streams-scala (streams/streams-scala) module was donated by Lightbend and the original code was copyrighted by them:\nCopyright (C) 2018 Lightbend Inc. <https://www.lightbend.com>\nCopyright (C) 2017-2018 Alexis Seigneurin.\n\nThis project contains the following code copied from Apache Hive:\nstreams/src/main/java/org/apache/kafka/streams/state/internals/Murmur3.java\n"
        },
        {
          "name": "NOTICE-binary",
          "type": "blob",
          "size": 26.19,
          "content": "Apache Kafka\nCopyright 2021 The Apache Software Foundation.\n\nThis product includes software developed at\nThe Apache Software Foundation (https://www.apache.org/).\n\nThis distribution has a binary dependency on jersey, which is available under the CDDL\nLicense. The source code of jersey can be found at https://github.com/jersey/jersey/.\n\nThis distribution has a binary test dependency on jqwik, which is available under\nthe Eclipse Public License 2.0. The source code can be found at\nhttps://github.com/jlink/jqwik.\n\nThe streams-scala (streams/streams-scala) module was donated by Lightbend and the original code was copyrighted by them:\nCopyright (C) 2018 Lightbend Inc. <https://www.lightbend.com>\nCopyright (C) 2017-2018 Alexis Seigneurin.\n\nThis project contains the following code copied from Apache Hive:\nstreams/src/main/java/org/apache/kafka/streams/state/internals/Murmur3.java\n\n// ------------------------------------------------------------------\n// NOTICE file corresponding to the section 4d of The Apache License,\n// Version 2.0, in this case for\n// ------------------------------------------------------------------\n\n# Notices for Eclipse GlassFish\n\nThis content is produced and maintained by the Eclipse GlassFish project.\n\n* Project home: https://projects.eclipse.org/projects/ee4j.glassfish\n\n## Trademarks\n\nEclipse GlassFish, and GlassFish are trademarks of the Eclipse Foundation.\n\n## Copyright\n\nAll content is the property of the respective authors or their employers. For\nmore information regarding authorship of content, please consult the listed\nsource code repository logs.\n\n## Declared Project Licenses\n\nThis program and the accompanying materials are made available under the terms\nof the Eclipse Public License v. 2.0 which is available at\nhttp://www.eclipse.org/legal/epl-2.0. This Source Code may also be made\navailable under the following Secondary Licenses when the conditions for such\navailability set forth in the Eclipse Public License v. 2.0 are satisfied: GNU\nGeneral Public License, version 2 with the GNU Classpath Exception which is\navailable at https://www.gnu.org/software/classpath/license.html.\n\nSPDX-License-Identifier: EPL-2.0 OR GPL-2.0 WITH Classpath-exception-2.0\n\n## Source Code\n\nThe project maintains the following source code repositories:\n\n* https://github.com/eclipse-ee4j/glassfish-ha-api\n* https://github.com/eclipse-ee4j/glassfish-logging-annotation-processor\n* https://github.com/eclipse-ee4j/glassfish-shoal\n* https://github.com/eclipse-ee4j/glassfish-cdi-porting-tck\n* https://github.com/eclipse-ee4j/glassfish-jsftemplating\n* https://github.com/eclipse-ee4j/glassfish-hk2-extra\n* https://github.com/eclipse-ee4j/glassfish-hk2\n* https://github.com/eclipse-ee4j/glassfish-fighterfish\n\n## Third-party Content\n\nThis project leverages the following third party content.\n\nNone\n\n## Cryptography\n\nContent may contain encryption software. The country in which you are currently\nmay have restrictions on the import, possession, and use, and/or re-export to\nanother country, of encryption software. BEFORE using any encryption software,\nplease check the country's laws, regulations and policies concerning the import,\npossession, or use, and re-export of encryption software, to see if this is\npermitted.\n\n\nApache Yetus - Audience Annotations\nCopyright 2015-2017 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nApache Commons CLI\nCopyright 2001-2017 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nApache Commons IO\nCopyright 2002-2021 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (https://www.apache.org/).\n\n\nApache Commons Lang\nCopyright 2001-2018 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\n# Jackson JSON processor\n\nJackson is a high-performance, Free/Open Source JSON processing library.\nIt was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has\nbeen in development since 2007.\nIt is currently developed by a community of developers, as well as supported\ncommercially by FasterXML.com.\n\n## Licensing\n\nJackson core and extension components may licensed under different licenses.\nTo find the details that apply to this artifact see the accompanying LICENSE file.\nFor more information, including possible other licensing options, contact\nFasterXML.com (http://fasterxml.com).\n\n## Credits\n\nA list of contributors may be found from CREDITS file, which is included\nin some artifacts (usually source distributions); but is always available\nfrom the source code management (SCM) system project uses.\n\n\n# Notices for Eclipse Project for JAF\n\nThis content is produced and maintained by the Eclipse Project for JAF project.\n\n* Project home: https://projects.eclipse.org/projects/ee4j.jaf\n\n## Copyright\n\nAll content is the property of the respective authors or their employers. For\nmore information regarding authorship of content, please consult the listed\nsource code repository logs.\n\n## Declared Project Licenses\n\nThis program and the accompanying materials are made available under the terms\nof the Eclipse Distribution License v. 1.0,\nwhich is available at http://www.eclipse.org/org/documents/edl-v10.php.\n\nSPDX-License-Identifier: BSD-3-Clause\n\n## Source Code\n\nThe project maintains the following source code repositories:\n\n* https://github.com/eclipse-ee4j/jaf\n\n## Third-party Content\n\nThis project leverages the following third party content.\n\nJUnit (4.12)\n\n* License: Eclipse Public License\n\n\n# Notices for Jakarta Annotations\n\nThis content is produced and maintained by the Jakarta Annotations project.\n\n * Project home: https://projects.eclipse.org/projects/ee4j.ca\n\n## Trademarks\n\nJakarta Annotations is a trademark of the Eclipse Foundation.\n\n## Declared Project Licenses\n\nThis program and the accompanying materials are made available under the terms\nof the Eclipse Public License v. 2.0 which is available at\nhttp://www.eclipse.org/legal/epl-2.0. This Source Code may also be made\navailable under the following Secondary Licenses when the conditions for such\navailability set forth in the Eclipse Public License v. 2.0 are satisfied: GNU\nGeneral Public License, version 2 with the GNU Classpath Exception which is\navailable at https://www.gnu.org/software/classpath/license.html.\n\nSPDX-License-Identifier: EPL-2.0 OR GPL-2.0 WITH Classpath-exception-2.0\n\n## Source Code\n\nThe project maintains the following source code repositories:\n\n * https://github.com/eclipse-ee4j/common-annotations-api\n\n## Third-party Content\n\n## Cryptography\n\nContent may contain encryption software. The country in which you are currently\nmay have restrictions on the import, possession, and use, and/or re-export to\nanother country, of encryption software. BEFORE using any encryption software,\nplease check the country's laws, regulations and policies concerning the import,\npossession, or use, and re-export of encryption software, to see if this is\npermitted.\n\n\n# Notices for the Jakarta RESTful Web Services Project\n\nThis content is produced and maintained by the **Jakarta RESTful Web Services**\nproject.\n\n* Project home: https://projects.eclipse.org/projects/ee4j.jaxrs\n\n## Trademarks\n\n**Jakarta RESTful Web Services** is a trademark of the Eclipse Foundation.\n\n## Copyright\n\nAll content is the property of the respective authors or their employers. For\nmore information regarding authorship of content, please consult the listed\nsource code repository logs.\n\n## Declared Project Licenses\n\nThis program and the accompanying materials are made available under the terms\nof the Eclipse Public License v. 2.0 which is available at\nhttp://www.eclipse.org/legal/epl-2.0. This Source Code may also be made\navailable under the following Secondary Licenses when the conditions for such\navailability set forth in the Eclipse Public License v. 2.0 are satisfied: GNU\nGeneral Public License, version 2 with the GNU Classpath Exception which is\navailable at https://www.gnu.org/software/classpath/license.html.\n\nSPDX-License-Identifier: EPL-2.0 OR GPL-2.0 WITH Classpath-exception-2.0\n\n## Source Code\n\nThe project maintains the following source code repositories:\n\n* https://github.com/eclipse-ee4j/jaxrs-api\n\n## Third-party Content\n\nThis project leverages the following third party content.\n\njavaee-api (7.0)\n\n* License: Apache-2.0 AND W3C\n\nJUnit (4.11)\n\n* License: Common Public License 1.0\n\nMockito (2.16.0)\n\n* Project: http://site.mockito.org\n* Source: https://github.com/mockito/mockito/releases/tag/v2.16.0\n\n## Cryptography\n\nContent may contain encryption software. The country in which you are currently\nmay have restrictions on the import, possession, and use, and/or re-export to\nanother country, of encryption software. BEFORE using any encryption software,\nplease check the country's laws, regulations and policies concerning the import,\npossession, or use, and re-export of encryption software, to see if this is\npermitted.\n\n\n# Notices for Eclipse Project for JAXB\n\nThis content is produced and maintained by the Eclipse Project for JAXB project.\n\n* Project home: https://projects.eclipse.org/projects/ee4j.jaxb\n\n## Trademarks\n\nEclipse Project for JAXB is a trademark of the Eclipse Foundation.\n\n## Copyright\n\nAll content is the property of the respective authors or their employers. For\nmore information regarding authorship of content, please consult the listed\nsource code repository logs.\n\n## Declared Project Licenses\n\nThis program and the accompanying materials are made available under the terms\nof the Eclipse Distribution License v. 1.0 which is available\nat http://www.eclipse.org/org/documents/edl-v10.php.\n\nSPDX-License-Identifier: BSD-3-Clause\n\n## Source Code\n\nThe project maintains the following source code repositories:\n\n* https://github.com/eclipse-ee4j/jaxb-api\n\n## Third-party Content\n\nThis project leverages the following third party content.\n\nNone\n\n## Cryptography\n\nContent may contain encryption software. The country in which you are currently\nmay have restrictions on the import, possession, and use, and/or re-export to\nanother country, of encryption software. BEFORE using any encryption software,\nplease check the country's laws, regulations and policies concerning the import,\npossession, or use, and re-export of encryption software, to see if this is\npermitted.\n\n\n# Notice for Jersey\nThis content is produced and maintained by the Eclipse Jersey project.\n\n*  Project home: https://projects.eclipse.org/projects/ee4j.jersey\n\n## Trademarks\nEclipse Jersey is a trademark of the Eclipse Foundation.\n\n## Copyright\n\nAll content is the property of the respective authors or their employers. For\nmore information regarding authorship of content, please consult the listed\nsource code repository logs.\n\n## Declared Project Licenses\n\nThis program and the accompanying materials are made available under the terms\nof the Eclipse Public License v. 2.0 which is available at\nhttp://www.eclipse.org/legal/epl-2.0. This Source Code may also be made\navailable under the following Secondary Licenses when the conditions for such\navailability set forth in the Eclipse Public License v. 2.0 are satisfied: GNU\nGeneral Public License, version 2 with the GNU Classpath Exception which is\navailable at https://www.gnu.org/software/classpath/license.html.\n\nSPDX-License-Identifier: EPL-2.0 OR GPL-2.0 WITH Classpath-exception-2.0\n\n## Source Code\nThe project maintains the following source code repositories:\n\n* https://github.com/eclipse-ee4j/jersey\n\n## Third-party Content\n\nAngular JS, v1.6.6\n* License MIT (http://www.opensource.org/licenses/mit-license.php)\n* Project: http://angularjs.org\n* Coyright: (c) 2010-2017 Google, Inc.\n\naopalliance Version 1\n* License: all the source code provided by AOP Alliance is Public Domain.\n* Project: http://aopalliance.sourceforge.net\n* Copyright: Material in the public domain is not protected by copyright\n\nBean Validation API 2.0.2\n* License: Apache License, 2.0\n* Project: http://beanvalidation.org/1.1/\n* Copyright: 2009, Red Hat, Inc. and/or its affiliates, and individual contributors\n* by the @authors tag.\n\nHibernate Validator CDI, 6.1.2.Final\n* License: Apache License, 2.0\n* Project: https://beanvalidation.org/\n* Repackaged in org.glassfish.jersey.server.validation.internal.hibernate\n\nBootstrap v3.3.7\n* License: MIT license (https://github.com/twbs/bootstrap/blob/master/LICENSE)\n* Project: http://getbootstrap.com\n* Copyright: 2011-2016 Twitter, Inc\n\nGoogle Guava Version 18.0\n* License: Apache License, 2.0\n* Copyright (C) 2009 The Guava Authors\n\njavax.inject Version: 1\n* License: Apache License, 2.0\n* Copyright (C) 2009 The JSR-330 Expert Group\n\nJavassist Version 3.25.0-GA\n* License: Apache License, 2.0\n* Project: http://www.javassist.org/\n* Copyright (C) 1999- Shigeru Chiba. All Rights Reserved.\n\nJackson JAX-RS Providers Version 2.10.1\n* License: Apache License, 2.0\n* Project: https://github.com/FasterXML/jackson-jaxrs-providers\n* Copyright: (c) 2009-2011 FasterXML, LLC. All rights reserved unless otherwise indicated.\n\njQuery v1.12.4\n* License: jquery.org/license\n* Project: jquery.org\n* Copyright: (c) jQuery Foundation\n\njQuery Barcode plugin 0.3\n* License: MIT & GPL (http://www.opensource.org/licenses/mit-license.php & http://www.gnu.org/licenses/gpl.html)\n* Project:  http://www.pasella.it/projects/jQuery/barcode\n* Copyright: (c) 2009 Antonello Pasella antonello.pasella@gmail.com\n\nJSR-166 Extension - JEP 266\n* License: CC0\n* No copyright\n* Written by Doug Lea with assistance from members of JCP JSR-166 Expert Group and released to the public domain, as explained at http://creativecommons.org/publicdomain/zero/1.0/\n\nKineticJS, v4.7.1\n* License: MIT license (http://www.opensource.org/licenses/mit-license.php)\n* Project: http://www.kineticjs.com, https://github.com/ericdrowell/KineticJS\n* Copyright: Eric Rowell\n\norg.objectweb.asm Version 8.0\n* License: Modified BSD (http://asm.objectweb.org/license.html)\n* Copyright (c) 2000-2011 INRIA, France Telecom. All rights reserved.\n\norg.osgi.core version 6.0.0\n* License: Apache License, 2.0\n* Copyright (c) OSGi Alliance (2005, 2008). All Rights Reserved.\n\norg.glassfish.jersey.server.internal.monitoring.core\n* License: Apache License, 2.0\n* Copyright (c) 2015-2018 Oracle and/or its affiliates. All rights reserved.\n* Copyright 2010-2013 Coda Hale and Yammer, Inc.\n\nW3.org documents\n* License: W3C License\n* Copyright: Copyright (c) 1994-2001 World Wide Web Consortium, (Massachusetts Institute of Technology, Institut National de Recherche en Informatique et en Automatique, Keio University). All Rights Reserved. http://www.w3.org/Consortium/Legal/\n\n\n==============================================================\n Jetty Web Container\n Copyright 1995-2018 Mort Bay Consulting Pty Ltd.\n==============================================================\n\nThe Jetty Web Container is Copyright Mort Bay Consulting Pty Ltd\nunless otherwise noted.\n\nJetty is dual licensed under both\n\n  * The Apache 2.0 License\n    http://www.apache.org/licenses/LICENSE-2.0.html\n\n      and\n\n  * The Eclipse Public 1.0 License\n    http://www.eclipse.org/legal/epl-v10.html\n\nJetty may be distributed under either license.\n\n------\nEclipse\n\nThe following artifacts are EPL.\n * org.eclipse.jetty.orbit:org.eclipse.jdt.core\n\nThe following artifacts are EPL and ASL2.\n * org.eclipse.jetty.orbit:javax.security.auth.message\n\n\nThe following artifacts are EPL and CDDL 1.0.\n * org.eclipse.jetty.orbit:javax.mail.glassfish\n\n\n------\nOracle\n\nThe following artifacts are CDDL + GPLv2 with classpath exception.\nhttps://glassfish.dev.java.net/nonav/public/CDDL+GPL.html\n\n * javax.servlet:javax.servlet-api\n * javax.annotation:javax.annotation-api\n * javax.transaction:javax.transaction-api\n * javax.websocket:javax.websocket-api\n\n------\nOracle OpenJDK\n\nIf ALPN is used to negotiate HTTP/2 connections, then the following\nartifacts may be included in the distribution or downloaded when ALPN\nmodule is selected.\n\n * java.sun.security.ssl\n\nThese artifacts replace/modify OpenJDK classes.  The modififications\nare hosted at github and both modified and original are under GPL v2 with\nclasspath exceptions.\nhttp://openjdk.java.net/legal/gplv2+ce.html\n\n\n------\nOW2\n\nThe following artifacts are licensed by the OW2 Foundation according to the\nterms of http://asm.ow2.org/license.html\n\norg.ow2.asm:asm-commons\norg.ow2.asm:asm\n\n\n------\nApache\n\nThe following artifacts are ASL2 licensed.\n\norg.apache.taglibs:taglibs-standard-spec\norg.apache.taglibs:taglibs-standard-impl\n\n\n------\nMortBay\n\nThe following artifacts are ASL2 licensed.  Based on selected classes from\nfollowing Apache Tomcat jars, all ASL2 licensed.\n\norg.mortbay.jasper:apache-jsp\n  org.apache.tomcat:tomcat-jasper\n  org.apache.tomcat:tomcat-juli\n  org.apache.tomcat:tomcat-jsp-api\n  org.apache.tomcat:tomcat-el-api\n  org.apache.tomcat:tomcat-jasper-el\n  org.apache.tomcat:tomcat-api\n  org.apache.tomcat:tomcat-util-scan\n  org.apache.tomcat:tomcat-util\n\norg.mortbay.jasper:apache-el\n  org.apache.tomcat:tomcat-jasper-el\n  org.apache.tomcat:tomcat-el-api\n\n\n------\nMortbay\n\nThe following artifacts are CDDL + GPLv2 with classpath exception.\n\nhttps://glassfish.dev.java.net/nonav/public/CDDL+GPL.html\n\norg.eclipse.jetty.toolchain:jetty-schemas\n\n------\nAssorted\n\nThe UnixCrypt.java code implements the one way cryptography used by\nUnix systems for simple password protection.  Copyright 1996 Aki Yoshida,\nmodified April 2001  by Iris Van den Broeke, Daniel Deville.\nPermission to use, copy, modify and distribute UnixCrypt\nfor non-commercial or commercial purposes and without fee is\ngranted provided that the copyright notice appears in all copies.\n\n\nApache log4j\nCopyright 2007 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nMaven Artifact\nCopyright 2001-2024 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nThis product includes software developed by the Indiana University\n  Extreme! Lab (http://www.extreme.indiana.edu/).\n\nThis product includes software developed by\nThe Apache Software Foundation (http://www.apache.org/).\n\nThis product includes software developed by\nThoughtWorks (http://www.thoughtworks.com).\n\nThis product includes software developed by\njavolution (http://javolution.org/).\n\nThis product includes software developed by\nRome (https://rome.dev.java.net/).\n\n\nScala\nCopyright (c) 2002-2020 EPFL\nCopyright (c) 2011-2020 Lightbend, Inc.\n\nScala includes software developed at\nLAMP/EPFL (https://lamp.epfl.ch/) and\nLightbend, Inc. (https://www.lightbend.com/).\n\nLicensed under the Apache License, Version 2.0 (the \"License\").\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nThis software includes projects with other licenses -- see `doc/LICENSE.md`.\n\n\n-------------------------------------------------------------------------------\nThis product contains the extensions to Java Collections Framework which has\nbeen derived from the works by JSR-166 EG, Doug Lea, and Jason T. Greene:\n\n  * LICENSE:\n    * license/LICENSE.jsr166y.txt (Public Domain)\n  * HOMEPAGE:\n    * http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/\n    * http://viewvc.jboss.org/cgi-bin/viewvc.cgi/jbosscache/experimental/jsr166/\n\nThis product contains a modified version of Robert Harder's Public Domain\nBase64 Encoder and Decoder, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.base64.txt (Public Domain)\n  * HOMEPAGE:\n    * http://iharder.sourceforge.net/current/java/base64/\n\nThis product contains a modified portion of 'Webbit', an event based\nWebSocket and HTTP server, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.webbit.txt (BSD License)\n  * HOMEPAGE:\n    * https://github.com/joewalnes/webbit\n\nThis product contains a modified portion of 'SLF4J', a simple logging\nfacade for Java, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.slf4j.txt (MIT License)\n  * HOMEPAGE:\n    * https://www.slf4j.org/\n\nThis product contains a modified portion of 'Apache Harmony', an open source\nJava SE, which can be obtained at:\n\n  * NOTICE:\n    * license/NOTICE.harmony.txt\n  * LICENSE:\n    * license/LICENSE.harmony.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://archive.apache.org/dist/harmony/\n\nThis product contains a modified portion of 'jbzip2', a Java bzip2 compression\nand decompression library written by Matthew J. Francis. It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.jbzip2.txt (MIT License)\n  * HOMEPAGE:\n    * https://code.google.com/p/jbzip2/\n\nThis product contains a modified portion of 'libdivsufsort', a C API library to construct\nthe suffix array and the Burrows-Wheeler transformed string for any input string of\na constant-size alphabet written by Yuta Mori. It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.libdivsufsort.txt (MIT License)\n  * HOMEPAGE:\n    * https://github.com/y-256/libdivsufsort\n\nThis product contains a modified portion of Nitsan Wakart's 'JCTools', Java Concurrency Tools for the JVM,\n which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.jctools.txt (ASL2 License)\n  * HOMEPAGE:\n    * https://github.com/JCTools/JCTools\n\nThis product optionally depends on 'JZlib', a re-implementation of zlib in\npure Java, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.jzlib.txt (BSD style License)\n  * HOMEPAGE:\n    * http://www.jcraft.com/jzlib/\n\nThis product optionally depends on 'Compress-LZF', a Java library for encoding and\ndecoding data in LZF format, written by Tatu Saloranta. It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.compress-lzf.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://github.com/ning/compress\n\nThis product optionally depends on 'lz4', a LZ4 Java compression\nand decompression library written by Adrien Grand. It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.lz4.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://github.com/jpountz/lz4-java\n\nThis product optionally depends on 'lzma-java', a LZMA Java compression\nand decompression library, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.lzma-java.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://github.com/jponge/lzma-java\n\nThis product contains a modified portion of 'jfastlz', a Java port of FastLZ compression\nand decompression library written by William Kinney. It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.jfastlz.txt (MIT License)\n  * HOMEPAGE:\n    * https://code.google.com/p/jfastlz/\n\nThis product contains a modified portion of and optionally depends on 'Protocol Buffers', Google's data\ninterchange format, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.protobuf.txt (New BSD License)\n  * HOMEPAGE:\n    * https://github.com/google/protobuf\n\nThis product optionally depends on 'Bouncy Castle Crypto APIs' to generate\na temporary self-signed X.509 certificate when the JVM does not provide the\nequivalent functionality.  It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.bouncycastle.txt (MIT License)\n  * HOMEPAGE:\n    * https://www.bouncycastle.org/\n\nThis product optionally depends on 'Snappy', a compression library produced\nby Google Inc, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.snappy.txt (New BSD License)\n  * HOMEPAGE:\n    * https://github.com/google/snappy\n\nThis product optionally depends on 'JBoss Marshalling', an alternative Java\nserialization API, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.jboss-marshalling.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://github.com/jboss-remoting/jboss-marshalling\n\nThis product optionally depends on 'Caliper', Google's micro-\nbenchmarking framework, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.caliper.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://github.com/google/caliper\n\nThis product optionally depends on 'Apache Commons Logging', a logging\nframework, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.commons-logging.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://commons.apache.org/logging/\n\nThis product optionally depends on 'Apache Log4J', a logging framework, which\ncan be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.log4j.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://logging.apache.org/log4j/\n\nThis product optionally depends on 'Aalto XML', an ultra-high performance\nnon-blocking XML processor, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.aalto-xml.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * http://wiki.fasterxml.com/AaltoHome\n\nThis product contains a modified version of 'HPACK', a Java implementation of\nthe HTTP/2 HPACK algorithm written by Twitter. It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.hpack.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://github.com/twitter/hpack\n\nThis product contains a modified version of 'HPACK', a Java implementation of\nthe HTTP/2 HPACK algorithm written by Cory Benfield. It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.hyper-hpack.txt (MIT License)\n  * HOMEPAGE:\n    * https://github.com/python-hyper/hpack/\n\nThis product contains a modified version of 'HPACK', a Java implementation of\nthe HTTP/2 HPACK algorithm written by Tatsuhiro Tsujikawa. It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.nghttp2-hpack.txt (MIT License)\n  * HOMEPAGE:\n    * https://github.com/nghttp2/nghttp2/\n\nThis product contains a modified portion of 'Apache Commons Lang', a Java library\nprovides utilities for the java.lang API, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.commons-lang.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://commons.apache.org/proper/commons-lang/\n\n\nThis product contains the Maven wrapper scripts from 'Maven Wrapper', that provides an easy way to ensure a user has everything necessary to run the Maven build.\n\n  * LICENSE:\n    * license/LICENSE.mvn-wrapper.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://github.com/takari/maven-wrapper\n\nThis product contains the dnsinfo.h header file, that provides a way to retrieve the system DNS configuration on MacOS.\nThis private header is also used by Apple's open source\n mDNSResponder (https://opensource.apple.com/tarballs/mDNSResponder/).\n\n * LICENSE:\n    * license/LICENSE.dnsinfo.txt (Apple Public Source License 2.0)\n  * HOMEPAGE:\n    * https://www.opensource.apple.com/source/configd/configd-453.19/dnsinfo/dnsinfo.h\n"
        },
        {
          "name": "PULL_REQUEST_TEMPLATE.md",
          "type": "blob",
          "size": 0.56,
          "content": "*More detailed description of your change,\nif necessary. The PR title and PR message become\nthe squashed commit message, so use a separate\ncomment to ping reviewers.*\n\n*Summary of testing strategy (including rationale)\nfor the feature or bug fix. Unit and/or integration\ntests are expected for any behaviour change and\nsystem tests should be considered for larger changes.*\n\n### Committer Checklist (excluded from commit message)\n- [ ] Verify design and implementation \n- [ ] Verify test coverage and CI build status\n- [ ] Verify documentation (including upgrade notes)\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 13.55,
          "content": "<p align=\"center\">\n<picture>\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"docs/images/kafka-logo-readme-light.svg\">\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/kafka-logo-readme-dark.svg\">\n  <img src=\"docs/images/kafka-logo-readme-light.svg\" alt=\"Kafka Logo\" width=\"50%\"> \n</picture>\n</p>\n\n[![CI](https://github.com/apache/kafka/actions/workflows/ci.yml/badge.svg?branch=trunk&event=push)](https://github.com/apache/kafka/actions/workflows/ci.yml?query=event%3Apush+branch%3Atrunk)\n[![Flaky Test Report](https://github.com/apache/kafka/actions/workflows/generate-reports.yml/badge.svg?branch=trunk&event=schedule)](https://github.com/apache/kafka/actions/workflows/generate-reports.yml?query=event%3Aschedule+branch%3Atrunk)\n\n[**Apache Kafka**](https://kafka.apache.org) is an open-source distributed event streaming platform used by thousands of\n\ncompanies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.\n\nYou need to have [Java](http://www.oracle.com/technetwork/java/javase/downloads/index.html) installed.\n\nWe build and test Apache Kafka with 17 and 23. The `release` parameter in javac is set to `11` for the clients \nand streams modules, and `17` for the rest, ensuring compatibility with their respective\nminimum Java versions. Similarly, the `release` parameter in scalac is set to `11` for the streams modules and `17`\nfor the rest.\n\nScala 2.13 is the only supported version in Apache Kafka.\n\n### Build a jar and run it ###\n    ./gradlew jar\n\nFollow instructions in https://kafka.apache.org/quickstart\n\n### Build source jar ###\n    ./gradlew srcJar\n\n### Build aggregated javadoc ###\n    ./gradlew aggregatedJavadoc\n\n### Build javadoc and scaladoc ###\n    ./gradlew javadoc\n    ./gradlew javadocJar # builds a javadoc jar for each module\n    ./gradlew scaladoc\n    ./gradlew scaladocJar # builds a scaladoc jar for each module\n    ./gradlew docsJar # builds both (if applicable) javadoc and scaladoc jars for each module\n\n### Run unit/integration tests ###\n    ./gradlew test  # runs both unit and integration tests\n    ./gradlew unitTest\n    ./gradlew integrationTest\n    ./gradlew quarantinedTest  # runs the quarantined tests\n\n    \n### Force re-running tests without code change ###\n    ./gradlew test --rerun-tasks\n    ./gradlew unitTest --rerun-tasks\n    ./gradlew integrationTest --rerun-tasks\n\n### Running a particular unit/integration test ###\n    ./gradlew clients:test --tests RequestResponseTest\n\n### Repeatedly running a particular unit/integration test with specific times by setting N ###\n    N=500; I=0; while [ $I -lt $N ] && ./gradlew clients:test --tests RequestResponseTest --rerun --fail-fast; do (( I=$I+1 )); echo \"Completed run: $I\"; sleep 1; done\n\n### Running a particular test method within a unit/integration test ###\n    ./gradlew core:test --tests kafka.api.ProducerFailureHandlingTest.testCannotSendToInternalTopic\n    ./gradlew clients:test --tests org.apache.kafka.clients.MetadataTest.testTimeToNextUpdate\n\n### Running a particular unit/integration test with log4j output ###\nBy default, there will be only small number of logs output while testing. You can adjust it by changing the `log4j2.yml` file in the module's `src/test/resources` directory.\n\nFor example, if you want to see more logs for clients project tests, you can modify [the line](https://github.com/apache/kafka/blob/trunk/clients/src/test/resources/log4j2.yml#L35) in `clients/src/test/resources/log4j2.yml` \nto `level: INFO` and then run:\n    \n    ./gradlew cleanTest clients:test --tests NetworkClientTest   \n\nAnd you should see `INFO` level logs in the file under the `clients/build/test-results/test` directory.\n\n### Specifying test retries ###\nRetries are disabled by default, but you can set maxTestRetryFailures and maxTestRetries to enable retries.\n\nThe following example declares -PmaxTestRetries=1 and -PmaxTestRetryFailures=3 to enable a failed test to be retried once, with a total retry limit of 3.\n\n    ./gradlew test -PmaxTestRetries=1 -PmaxTestRetryFailures=3\n\nThe quarantinedTest task also has no retries by default, but you can set maxQuarantineTestRetries and maxQuarantineTestRetryFailures to enable retries, similar to the test task.\n\n    ./gradlew quarantinedTest -PmaxQuarantineTestRetries=3 -PmaxQuarantineTestRetryFailures=20\n\nSee [Test Retry Gradle Plugin](https://github.com/gradle/test-retry-gradle-plugin) for and [build.yml](.github/workflows/build.yml) more details.\n\n### Generating test coverage reports ###\nGenerate coverage reports for the whole project:\n\n    ./gradlew reportCoverage -PenableTestCoverage=true -Dorg.gradle.parallel=false\n\nGenerate coverage for a single module, i.e.: \n\n    ./gradlew clients:reportCoverage -PenableTestCoverage=true -Dorg.gradle.parallel=false\n    \n### Building a binary release gzipped tar ball ###\n    ./gradlew clean releaseTarGz\n\nThe release file can be found inside `./core/build/distributions/`.\n\n### Building auto generated messages ###\nSometimes it is only necessary to rebuild the RPC auto-generated message data when switching between branches, as they could\nfail due to code changes. You can just run:\n \n    ./gradlew processMessages processTestMessages\n\n### Running a Kafka broker\n\nUsing compiled files:\n\n    KAFKA_CLUSTER_ID=\"$(./bin/kafka-storage.sh random-uuid)\"\n    ./bin/kafka-storage.sh format --standalone -t $KAFKA_CLUSTER_ID -c config/kraft/reconfig-server.properties\n    ./bin/kafka-server-start.sh config/kraft/reconfig-server.properties\n\nUsing docker image:\n\n    docker run -p 9092:9092 apache/kafka:3.7.0\n\n### Cleaning the build ###\n    ./gradlew clean\n\n### Running a task for a specific project ###\nThis is for `core`, `examples` and `clients`\n\n    ./gradlew core:jar\n    ./gradlew core:test\n\nStreams has multiple sub-projects, but you can run all the tests:\n\n    ./gradlew :streams:testAll\n\n### Listing all gradle tasks ###\n    ./gradlew tasks\n\n### Building IDE project ####\n*Note Please ensure that JDK17 is used when developing Kafka.*\n\nIntelliJ supports Gradle natively and it will automatically check Java syntax and compatibility for each module, even if\nthe Java version shown in the `Structure > Project Settings > Modules` may not be the correct one.\n\nWhen it comes to Eclipse, run:\n\n    ./gradlew eclipse\n\nThe `eclipse` task has been configured to use `${project_dir}/build_eclipse` as Eclipse's build directory. Eclipse's default\nbuild directory (`${project_dir}/bin`) clashes with Kafka's scripts directory and we don't use Gradle's build directory\nto avoid known issues with this configuration.\n\n### Publishing the streams quickstart archetype artifact to maven ###\nFor the Streams archetype project, one cannot use gradle to upload to maven; instead the `mvn deploy` command needs to be called at the quickstart folder:\n\n    cd streams/quickstart\n    mvn deploy\n\nPlease note for this to work you should create/update user maven settings (typically, `${USER_HOME}/.m2/settings.xml`) to assign the following variables\n\n    <settings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0\n                           https://maven.apache.org/xsd/settings-1.0.0.xsd\">\n    ...                           \n    <servers>\n       ...\n       <server>\n          <id>apache.snapshots.https</id>\n          <username>${maven_username}</username>\n          <password>${maven_password}</password>\n       </server>\n       <server>\n          <id>apache.releases.https</id>\n          <username>${maven_username}</username>\n          <password>${maven_password}</password>\n        </server>\n        ...\n     </servers>\n     ...\n\n### Installing all projects to the local Maven repository ###\n\n    ./gradlew -PskipSigning=true publishToMavenLocal\n\n### Installing specific projects to the local Maven repository ###\n\n    ./gradlew -PskipSigning=true :streams:publishToMavenLocal\n    \n### Building the test jar ###\n    ./gradlew testJar\n\n### Running code quality checks ###\nThere are two code quality analysis tools that we regularly run, spotbugs and checkstyle.\n\n#### Checkstyle ####\nCheckstyle enforces a consistent coding style in Kafka.\nYou can run checkstyle using:\n\n    ./gradlew checkstyleMain checkstyleTest spotlessCheck\n\nThe checkstyle warnings will be found in `reports/checkstyle/reports/main.html` and `reports/checkstyle/reports/test.html` files in the\nsubproject build directories. They are also printed to the console. The build will fail if Checkstyle fails.\nFor experiments (or regression testing purposes) add `-PcheckstyleVersion=X.y.z` switch (to override project-defined checkstyle version).\n\n#### Spotless ####\nThe import order is a part of static check. please call `spotlessApply` to optimize the imports of Java codes before filing pull request.\n\n    ./gradlew spotlessApply\n\n#### Spotbugs ####\nSpotbugs uses static analysis to look for bugs in the code.\nYou can run spotbugs using:\n\n    ./gradlew spotbugsMain spotbugsTest -x test\n\nThe spotbugs warnings will be found in `reports/spotbugs/main.html` and `reports/spotbugs/test.html` files in the subproject build\ndirectories.  Use -PxmlSpotBugsReport=true to generate an XML report instead of an HTML one.\n\n### JMH microbenchmarks ###\nWe use [JMH](https://openjdk.java.net/projects/code-tools/jmh/) to write microbenchmarks that produce reliable results in the JVM.\n    \nSee [jmh-benchmarks/README.md](https://github.com/apache/kafka/blob/trunk/jmh-benchmarks/README.md) for details on how to run the microbenchmarks.\n\n### Dependency Analysis ###\n\nThe gradle [dependency debugging documentation](https://docs.gradle.org/current/userguide/viewing_debugging_dependencies.html) mentions using the `dependencies` or `dependencyInsight` tasks to debug dependencies for the root project or individual subprojects.\n\nAlternatively, use the `allDeps` or `allDepInsight` tasks for recursively iterating through all subprojects:\n\n    ./gradlew allDeps\n\n    ./gradlew allDepInsight --configuration runtimeClasspath --dependency com.fasterxml.jackson.core:jackson-databind\n\nThese take the same arguments as the builtin variants.\n\n### Determining if any dependencies could be updated ###\n    ./gradlew dependencyUpdates\n\n### Common build options ###\n\nThe following options should be set with a `-P` switch, for example `./gradlew -PmaxParallelForks=1 test`.\n\n* `commitId`: sets the build commit ID as .git/HEAD might not be correct if there are local commits added for build purposes.\n* `mavenUrl`: sets the URL of the maven deployment repository (`file://path/to/repo` can be used to point to a local repository).\n* `maxParallelForks`: maximum number of test processes to start in parallel. Defaults to the number of processors available to the JVM.\n* `maxScalacThreads`: maximum number of worker threads for the scalac backend. Defaults to the lowest of `8` and the number of processors\navailable to the JVM. The value must be between 1 and 16 (inclusive). \n* `ignoreFailures`: ignore test failures from junit\n* `showStandardStreams`: shows standard out and standard error of the test JVM(s) on the console.\n* `skipSigning`: skips signing of artifacts.\n* `testLoggingEvents`: unit test events to be logged, separated by comma. For example `./gradlew -PtestLoggingEvents=started,passed,skipped,failed test`.\n* `xmlSpotBugsReport`: enable XML reports for spotBugs. This also disables HTML reports as only one can be enabled at a time.\n* `maxTestRetries`: maximum number of retries for a failing test case.\n* `maxTestRetryFailures`: maximum number of test failures before retrying is disabled for subsequent tests.\n* `enableTestCoverage`: enables test coverage plugins and tasks, including bytecode enhancement of classes required to track said\ncoverage. Note that this introduces some overhead when running tests and hence why it's disabled by default (the overhead\nvaries, but 15-20% is a reasonable estimate).\n* `keepAliveMode`: configures the keep alive mode for the Gradle compilation daemon - reuse improves start-up time. The values should \nbe one of `daemon` or `session` (the default is `daemon`). `daemon` keeps the daemon alive until it's explicitly stopped while\n`session` keeps it alive until the end of the build session. This currently only affects the Scala compiler, see\nhttps://github.com/gradle/gradle/pull/21034 for a PR that attempts to do the same for the Java compiler.\n* `scalaOptimizerMode`: configures the optimizing behavior of the scala compiler, the value should be one of `none`, `method`, `inline-kafka` or\n`inline-scala` (the default is `inline-kafka`). `none` is the scala compiler default, which only eliminates unreachable code. `method` also\nincludes method-local optimizations. `inline-kafka` adds inlining of methods within the kafka packages. Finally, `inline-scala` also\nincludes inlining of methods within the scala library (which avoids lambda allocations for methods like `Option.exists`). `inline-scala` is\nonly safe if the Scala library version is the same at compile time and runtime. Since we cannot guarantee this for all cases (for example, users\nmay depend on the kafka jar for integration tests where they may include a scala library with a different version), we don't enable it by\ndefault. See https://www.lightbend.com/blog/scala-inliner-optimizer for more details.\n\n### Running system tests ###\n\nSee [tests/README.md](tests/README.md).\n\n### Running in Vagrant ###\n\nSee [vagrant/README.md](vagrant/README.md).\n\n### Contribution ###\n\nApache Kafka is interested in building the community; we would welcome any thoughts or [patches](https://issues.apache.org/jira/browse/KAFKA). You can reach us [on the Apache mailing lists](http://kafka.apache.org/contact.html).\n\nTo contribute follow the instructions here:\n * https://kafka.apache.org/contributing.html \n"
        },
        {
          "name": "Vagrantfile",
          "type": "blob",
          "size": 8.07,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# -*- mode: ruby -*-\n# vi: set ft=ruby :\n\nrequire 'socket'\n\n# Vagrantfile API/syntax version. Don't touch unless you know what you're doing!\nVAGRANTFILE_API_VERSION = \"2\"\n\n# General config\nenable_dns = false\n# Override to false when bringing up a cluster on AWS\nenable_hostmanager = true\nenable_jmx = false\nnum_zookeepers = 1\nnum_brokers = 3\nnum_workers = 0 # Generic workers that get the code, but don't start any services\nram_megabytes = 1280\nbase_box = \"ubuntu/trusty64\"\n\n# EC2\nec2_access_key = ENV['AWS_ACCESS_KEY']\nec2_secret_key = ENV['AWS_SECRET_KEY']\nec2_session_token = ENV['AWS_SESSION_TOKEN']\nec2_keypair_name = nil\nec2_keypair_file = nil\n\nec2_region = \"us-east-1\"\nec2_az = nil # Uses set by AWS\nec2_ami = \"ami-29ebb519\"\nec2_instance_type = \"m3.medium\"\nec2_spot_instance = ENV['SPOT_INSTANCE'] ? ENV['SPOT_INSTANCE'] == 'true' : true\nec2_spot_max_price = \"0.113\"  # On-demand price for instance type\nec2_user = \"ubuntu\"\nec2_instance_name_prefix = \"kafka-vagrant\"\nec2_security_groups = nil\nec2_subnet_id = nil\n# Only override this by setting it to false if you're running in a VPC and you\n# are running Vagrant from within that VPC as well.\nec2_associate_public_ip = nil\nec2_iam_instance_profile_name = nil\n\nebs_volume_type = 'gp3'\n\njdk_major = '17'\njdk_full = '17-linux-x64'\n\nlocal_config_file = File.join(File.dirname(__FILE__), \"Vagrantfile.local\")\nif File.exist?(local_config_file) then\n  eval(File.read(local_config_file), binding, \"Vagrantfile.local\")\nend\n\n# override any instance type set by Vagrantfile.local or above via an environment variable\nif ENV['INSTANCE_TYPE'] then\n  ec2_instance_type = ENV['INSTANCE_TYPE']\nend\n\n# choose size based on overridden size\nif ec2_instance_type.start_with?(\"m3\") then\n  ebs_volume_size = 20\nelse\n  ebs_volume_size = 40\nend\n\n# TODO(ksweeney): RAM requirements are not empirical and can probably be significantly lowered.\nVagrant.configure(VAGRANTFILE_API_VERSION) do |config|\n  config.hostmanager.enabled = enable_hostmanager\n  config.hostmanager.manage_host = enable_dns\n  config.hostmanager.include_offline = false\n\n  ## Provider-specific global configs\n  config.vm.provider :virtualbox do |vb,override|\n    override.vm.box = base_box\n\n    override.hostmanager.ignore_private_ip = false\n\n    # Brokers started with the standard script currently set Xms and Xmx to 1G,\n    # plus we need some extra head room.\n    vb.customize [\"modifyvm\", :id, \"--memory\", ram_megabytes.to_s]\n\n    if Vagrant.has_plugin?(\"vagrant-cachier\")\n      override.cache.scope = :box\n    end\n  end\n\n  config.vm.provider :aws do |aws,override|\n    # The \"box\" is specified as an AMI\n    override.vm.box = \"dummy\"\n    override.vm.box_url = \"https://github.com/mitchellh/vagrant-aws/raw/master/dummy.box\"\n\n    cached_addresses = {}\n    # Use a custom resolver that SSH's into the machine and finds the IP address\n    # directly. This lets us get at the private IP address directly, avoiding\n    # some issues with using the default IP resolver, which uses the public IP\n    # address.\n    override.hostmanager.ip_resolver = proc do |vm, resolving_vm|\n      if !cached_addresses.has_key?(vm.name)\n        state_id = vm.state.id\n        if state_id != :not_created && state_id != :stopped && vm.communicate.ready?\n          contents = ''\n          vm.communicate.execute(\"/sbin/ifconfig eth0 | grep 'inet addr' | tail -n 1 | egrep -o '[0-9\\.]+' | head -n 1 2>&1\") do |type, data|\n            contents << data\n          end\n          cached_addresses[vm.name] = contents.split(\"\\n\").first[/(\\d+\\.\\d+\\.\\d+\\.\\d+)/, 1]\n        else\n          cached_addresses[vm.name] = nil\n        end\n      end\n      cached_addresses[vm.name]\n    end\n\n    override.ssh.username = ec2_user\n    override.ssh.private_key_path = ec2_keypair_file\n\n    aws.access_key_id = ec2_access_key\n    aws.secret_access_key = ec2_secret_key\n    aws.session_token = ec2_session_token\n    aws.keypair_name = ec2_keypair_name\n\n    aws.region = ec2_region\n    aws.availability_zone = ec2_az\n    aws.instance_type = ec2_instance_type\n\n    aws.ami = ec2_ami\n    aws.security_groups = ec2_security_groups\n    aws.subnet_id = ec2_subnet_id\n    aws.block_device_mapping = [{ 'DeviceName' => '/dev/sda1', 'Ebs.VolumeType' => ebs_volume_type, 'Ebs.VolumeSize' => ebs_volume_size }]\n    # If a subnet is specified, default to turning on a public IP unless the\n    # user explicitly specifies the option. Without a public IP, Vagrant won't\n    # be able to SSH into the hosts unless Vagrant is also running in the VPC.\n    if ec2_associate_public_ip.nil?\n      aws.associate_public_ip = true unless ec2_subnet_id.nil?\n    else\n      aws.associate_public_ip = ec2_associate_public_ip\n    end\n    aws.region_config ec2_region do |region|\n      region.spot_instance = ec2_spot_instance\n      region.spot_max_price = ec2_spot_max_price\n    end\n    aws.iam_instance_profile_name = ec2_iam_instance_profile_name\n\n    # Exclude some directories that can grow very large from syncing\n    override.vm.synced_folder \".\", \"/vagrant\", type: \"rsync\", rsync__exclude: ['.git', 'core/data/', 'logs/', 'tests/results/', 'results/']\n  end\n\n  def name_node(node, name, ec2_instance_name_prefix)\n    node.vm.hostname = name\n    node.vm.provider :aws do |aws|\n      aws.tags = {\n        'Name' => ec2_instance_name_prefix + \"-\" + Socket.gethostname + \"-\" + name,\n        'JenkinsBuildUrl' => ENV['BUILD_URL']\n      }\n    end\n  end\n\n  def assign_local_ip(node, ip_address)\n    node.vm.provider :virtualbox do |vb,override|\n      override.vm.network :private_network, ip: ip_address\n    end\n  end\n\n  ## Cluster definition\n  zookeepers = []\n  (1..num_zookeepers).each { |i|\n    name = \"zk\" + i.to_s\n    zookeepers.push(name)\n    config.vm.define name do |zookeeper|\n      name_node(zookeeper, name, ec2_instance_name_prefix)\n      ip_address = \"192.168.50.\" + (10 + i).to_s\n      assign_local_ip(zookeeper, ip_address)\n      zookeeper.vm.provision \"shell\", path: \"vagrant/base.sh\", env: {\"JDK_MAJOR\" => jdk_major, \"JDK_FULL\" => jdk_full}\n      zk_jmx_port = enable_jmx ? (8000 + i).to_s : \"\"\n      zookeeper.vm.provision \"shell\", path: \"vagrant/zk.sh\", :args => [i.to_s, num_zookeepers, zk_jmx_port]\n    end\n  }\n\n  (1..num_brokers).each { |i|\n    name = \"broker\" + i.to_s\n    config.vm.define name do |broker|\n      name_node(broker, name, ec2_instance_name_prefix)\n      ip_address = \"192.168.50.\" + (50 + i).to_s\n      assign_local_ip(broker, ip_address)\n      # We need to be careful about what we list as the publicly routable\n      # address since this is registered in ZK and handed out to clients. If\n      # host DNS isn't setup, we shouldn't use hostnames -- IP addresses must be\n      # used to support clients running on the host.\n      zookeeper_connect = zookeepers.map{ |zk_addr| zk_addr + \":2181\"}.join(\",\")\n      broker.vm.provision \"shell\", path: \"vagrant/base.sh\", env: {\"JDK_MAJOR\" => jdk_major, \"JDK_FULL\" => jdk_full}\n      kafka_jmx_port = enable_jmx ? (9000 + i).to_s : \"\"\n      broker.vm.provision \"shell\", path: \"vagrant/broker.sh\", :args => [i.to_s, enable_dns ? name : ip_address, zookeeper_connect, kafka_jmx_port]\n    end\n  }\n\n  (1..num_workers).each { |i|\n    name = \"worker\" + i.to_s\n    config.vm.define name do |worker|\n      name_node(worker, name, ec2_instance_name_prefix)\n      ip_address = \"192.168.50.\" + (100 + i).to_s\n      assign_local_ip(worker, ip_address)\n      worker.vm.provision \"shell\", path: \"vagrant/base.sh\", env: {\"JDK_MAJOR\" => jdk_major, \"JDK_FULL\" => jdk_full}\n    end\n  }\n\nend\n"
        },
        {
          "name": "bin",
          "type": "tree",
          "content": null
        },
        {
          "name": "build.gradle",
          "type": "blob",
          "size": 119.57,
          "content": "// Licensed to the Apache Software Foundation (ASF) under one or more\n// contributor license agreements.  See the NOTICE file distributed with\n// this work for additional information regarding copyright ownership.\n// The ASF licenses this file to You under the Apache License, Version 2.0\n// (the \"License\"); you may not use this file except in compliance with\n// the License.  You may obtain a copy of the License at\n//\n//    http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\nimport org.ajoberstar.grgit.Grgit\nimport org.gradle.api.JavaVersion\n\nimport java.nio.charset.StandardCharsets\n\nbuildscript {\n  repositories {\n    mavenCentral()\n  }\n  apply from: \"$rootDir/gradle/dependencies.gradle\"\n\n  dependencies {\n    // For Apache Rat plugin to ignore non-Git files\n    classpath \"org.ajoberstar.grgit:grgit-core:$versions.grgit\"\n  }\n}\n\nplugins {\n  id 'com.github.ben-manes.versions' version '0.48.0'\n  id 'idea'\n  id 'jacoco'\n  id 'java-library'\n  id 'org.owasp.dependencycheck' version '8.2.1'\n  id 'org.nosphere.apache.rat' version \"0.8.1\"\n  id \"io.swagger.core.v3.swagger-gradle-plugin\" version \"${swaggerVersion}\"\n\n  id \"com.github.spotbugs\" version '6.0.25' apply false\n  id 'org.scoverage' version '8.0.3' apply false\n  id 'io.github.goooler.shadow' version '8.1.3' apply false\n  id 'com.diffplug.spotless' version \"6.25.0\"\n}\n\next {\n  gradleVersion = versions.gradle\n  minClientJavaVersion = 11\n  minNonClientJavaVersion = 17\n  modulesNeedingJava11 = [\":clients\", \":generator\", \":streams\", \":streams:test-utils\", \":streams-scala\", \":test-common:test-common-runtime\"]\n\n  buildVersionFileName = \"kafka-version.properties\"\n\n  defaultMaxHeapSize = \"2g\"\n  defaultJvmArgs = [\"-Xss4m\", \"-XX:+UseParallelGC\"]\n\n  // \"JEP 403: Strongly Encapsulate JDK Internals\" causes some tests to fail when they try\n  // to access internals (often via mocking libraries). We use `--add-opens` as a workaround\n  // for now and we'll fix it properly (where possible) via KAFKA-13275.\n  if (JavaVersion.current().isCompatibleWith(JavaVersion.VERSION_16))\n    defaultJvmArgs.addAll(\n      \"--add-opens=java.base/java.io=ALL-UNNAMED\",\n      \"--add-opens=java.base/java.lang=ALL-UNNAMED\",\n      \"--add-opens=java.base/java.nio=ALL-UNNAMED\",\n      \"--add-opens=java.base/java.nio.file=ALL-UNNAMED\",\n      \"--add-opens=java.base/java.util=ALL-UNNAMED\",\n      \"--add-opens=java.base/java.util.concurrent=ALL-UNNAMED\",\n      \"--add-opens=java.base/java.util.regex=ALL-UNNAMED\",\n      \"--add-opens=java.base/java.util.stream=ALL-UNNAMED\",\n      \"--add-opens=java.base/java.text=ALL-UNNAMED\",\n      \"--add-opens=java.base/java.time=ALL-UNNAMED\",\n      \"--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED\"\n    )\n\n  maxTestForks = project.hasProperty('maxParallelForks') ? maxParallelForks.toInteger() : Runtime.runtime.availableProcessors()\n  maxScalacThreads = project.hasProperty('maxScalacThreads') ? maxScalacThreads.toInteger() :\n      Math.min(Runtime.runtime.availableProcessors(), 8)\n  userIgnoreFailures = project.hasProperty('ignoreFailures') ? ignoreFailures.toBoolean() : false\n\n  userMaxTestRetries = project.hasProperty('maxTestRetries') ? maxTestRetries.toInteger() : 0\n  userMaxTestRetryFailures = project.hasProperty('maxTestRetryFailures') ? maxTestRetryFailures.toInteger() : 0\n\n  userMaxQuarantineTestRetries = project.hasProperty('maxQuarantineTestRetries') ? maxQuarantineTestRetries.toInteger() : 0\n  userMaxQuarantineTestRetryFailures = project.hasProperty('maxQuarantineTestRetryFailures') ? maxQuarantineTestRetryFailures.toInteger() : 0\n\n  skipSigning = project.hasProperty('skipSigning') && skipSigning.toBoolean()\n  shouldSign = !skipSigning && !version.endsWith(\"SNAPSHOT\")\n\n  mavenUrl = project.hasProperty('mavenUrl') ? project.mavenUrl : ''\n  mavenUsername = project.hasProperty('mavenUsername') ? project.mavenUsername : ''\n  mavenPassword = project.hasProperty('mavenPassword') ? project.mavenPassword : ''\n\n  userShowStandardStreams = project.hasProperty(\"showStandardStreams\") ? showStandardStreams : null\n\n  userTestLoggingEvents = project.hasProperty(\"testLoggingEvents\") ? Arrays.asList(testLoggingEvents.split(\",\")) : null\n\n  userEnableTestCoverage = project.hasProperty(\"enableTestCoverage\") ? enableTestCoverage : false\n\n  userKeepAliveModeString = project.hasProperty(\"keepAliveMode\") ? keepAliveMode : \"daemon\"\n  userKeepAliveMode = KeepAliveMode.values().find(m -> m.name().toLowerCase().equals(userKeepAliveModeString))\n  if (userKeepAliveMode == null) {\n    def keepAliveValues = KeepAliveMode.values().collect(m -> m.name.toLowerCase())\n    throw new GradleException(\"Unexpected value for keepAliveMode property. Expected one of $keepAliveValues, but received: $userKeepAliveModeString\")\n  }\n\n  // See README.md for details on this option and the reasoning for the default\n  userScalaOptimizerMode = project.hasProperty(\"scalaOptimizerMode\") ? scalaOptimizerMode : \"inline-kafka\"\n  def scalaOptimizerValues = [\"none\", \"method\", \"inline-kafka\", \"inline-scala\"]\n  if (!scalaOptimizerValues.contains(userScalaOptimizerMode))\n    throw new GradleException(\"Unexpected value for scalaOptimizerMode property. Expected one of $scalaOptimizerValues, but received: $userScalaOptimizerMode\")\n\n  generatedDocsDir = new File(\"${project.rootDir}/docs/generated\")\n  repo = file(\"$rootDir/.git\").isDirectory() ? Grgit.open(currentDir: project.getRootDir()) : null\n\n  commitId = determineCommitId()\n\n  configureJavaCompiler = { name, options, projectPath ->\n    // -parameters generates arguments with parameter names in TestInfo#getDisplayName.\n    // ref: https://github.com/junit-team/junit5/blob/4c0dddad1b96d4a20e92a2cd583954643ac56ac0/junit-jupiter-params/src/main/java/org/junit/jupiter/params/ParameterizedTest.java#L161-L164\n\n    def releaseVersion = modulesNeedingJava11.any { projectPath == it } ? minClientJavaVersion : minNonClientJavaVersion\n\n    options.compilerArgs << \"-encoding\" << \"UTF-8\"\n    options.release = releaseVersion\n\n    if (name in [\"compileTestJava\", \"compileTestScala\"]) {\n      options.compilerArgs << \"-parameters\"\n    } else if (name in [\"compileJava\", \"compileScala\"]) {\n      options.compilerArgs << \"-Xlint:-rawtypes\"\n      options.compilerArgs << \"-Xlint:all\"\n      options.compilerArgs << \"-Xlint:-serial\"\n      options.compilerArgs << \"-Xlint:-try\"\n      options.compilerArgs << \"-Werror\"\n    }\n  }\n\n  runtimeTestLibs = [\n    libs.slf4jLog4j2,\n    libs.junitPlatformLanucher,\n    project(\":test-common:test-common-runtime\")\n  ]\n\n  log4jRuntimeLibs = [\n    libs.log4j1Bridge2Api,\n    libs.jacksonDatabindYaml\n  ]\n\n  log4jLibs = [\n    libs.slf4jApi,\n    libs.slf4jLog4j2,\n    libs.log4j2Api,\n    libs.log4j2Core\n  ]\n}\n\nallprojects {\n\n  repositories {\n    mavenCentral()\n  }\n\n  dependencyUpdates {\n    revision=\"release\"\n    resolutionStrategy {\n      componentSelection { rules ->\n        rules.all { ComponentSelection selection ->\n          boolean rejected = ['snap', 'alpha', 'beta', 'rc', 'cr', 'm'].any { qualifier ->\n            selection.candidate.version ==~ /(?i).*[.-]${qualifier}[.\\d-]*/\n          }\n          if (rejected) {\n            selection.reject('Release candidate')\n          }\n        }\n      }\n    }\n  }\n\n  configurations.all {\n    // zinc is the Scala incremental compiler, it has a configuration for its own dependencies\n    // that are unrelated to the project dependencies, we should not change them\n    if (name != \"zinc\") {\n      resolutionStrategy {\n        force(\n          // be explicit about the javassist dependency version instead of relying on the transitive version\n          libs.javassist,\n          // ensure we have a single version in the classpath despite transitive dependencies\n          libs.scalaLibrary,\n          libs.scalaReflect,\n          libs.jacksonAnnotations,\n          libs.jacksonDatabindYaml,\n          libs.log4j2Api,\n          libs.log4j2Core,\n          libs.log4j1Bridge2Api\n        )\n      }\n    }\n  }\n  task printAllDependencies(type: DependencyReportTask) {}\n\n  tasks.withType(Javadoc) {\n    options.charSet = 'UTF-8'\n    options.docEncoding = 'UTF-8'\n    options.encoding = 'UTF-8'\n    options.memberLevel = JavadocMemberLevel.PUBLIC  // Document only public members/API\n    // Turn off doclint for now, see https://blog.joda.org/2014/02/turning-off-doclint-in-jdk-8-javadoc.html for rationale\n    options.addStringOption('Xdoclint:none', '-quiet')\n    // Javadoc warnings should fail the build in JDK 15+ https://bugs.openjdk.org/browse/JDK-8200363\n    options.addBooleanOption('Werror', JavaVersion.current().isCompatibleWith(JavaVersion.VERSION_15))\n    options.links \"https://docs.oracle.com/en/java/javase/${JavaVersion.current().majorVersion}/docs/api/\"\n  }\n\n  tasks.withType(Checkstyle) {\n    minHeapSize = \"200m\"\n    maxHeapSize = \"1g\"\n  }\n\n  clean {\n    delete \"${projectDir}/src/generated\"\n    delete \"${projectDir}/src/generated-test\"\n  }\n}\n\ndef determineCommitId() {\n  def takeFromHash = 16\n  if (project.hasProperty('commitId')) {\n    commitId.take(takeFromHash)\n  } else if (repo != null) {\n    repo.head().id.take(takeFromHash)\n  } else {\n    \"unknown\"\n  }\n}\n\n/**\n * For a given Project, compute a nice dash separated directory name\n * to store the JUnit XML files in. E.g., Project \":connect:api\" -> \"connect-api\"\n */\nstatic def projectToJUnitXmlPath(project) {\n  var p = project\n  var projectNames = []\n  while (p != null) {\n    projectNames.push(p.name)\n    p = p.parent\n    if (p.name == \"kafka\") {\n      break\n    }\n  }\n  return projectNames.join(\"/\")\n}\n\n\napply from: file('wrapper.gradle')\n\nif (repo != null) {\n  rat {\n    dependsOn subprojects.collect {\n      it.tasks.matching {\n        it.name == \"processMessages\" || it.name == \"processTestMessages\"\n      }\n    }\n\n    verbose.set(true)\n    reportDir.set(project.file('build/rat'))\n    stylesheet.set(file('gradle/resources/rat-output-to-html.xsl'))\n\n    // Exclude everything under the directory that git should be ignoring via .gitignore or that isn't checked in. These\n    // restrict us only to files that are checked in or are staged.\n    excludes = new ArrayList<String>(repo.clean(ignore: false, directories: true, dryRun: true))\n    // And some of the files that we have checked in should also be excluded from this check\n    excludes.addAll([\n        '**/.git/**',\n        '**/build/**',\n        'CONTRIBUTING.md',\n        'PULL_REQUEST_TEMPLATE.md',\n        'gradlew',\n        'gradlew.bat',\n        'gradle/wrapper/gradle-wrapper.properties',\n        'trogdor/README.md',\n        '**/README.md',\n        '**/id_rsa',\n        '**/id_rsa.pub',\n        'checkstyle/suppressions.xml',\n        'streams/quickstart/java/src/test/resources/projects/basic/goal.txt',\n        'streams/streams-scala/logs/*',\n        'licenses/*',\n        '**/generated/**',\n        'clients/src/test/resources/serializedData/*',\n        'docker/test/fixtures/secrets/*',\n        'docker/examples/fixtures/secrets/*',\n        'docker/docker_official_images/.gitkeep'\n    ])\n  }\n} else {\n  rat.enabled = false\n}\nprintln(\"Starting build with version $version (commit id ${commitId == null ? \"null\" : commitId.take(8)}) using Gradle $gradleVersion, Java ${JavaVersion.current()} and Scala ${versions.scala}\")\nprintln(\"Build properties: ignoreFailures=$userIgnoreFailures, maxParallelForks=$maxTestForks, maxScalacThreads=$maxScalacThreads, maxTestRetries=$userMaxTestRetries\")\n\nsubprojects {\n\n  // enable running :dependencies task recursively on all subprojects\n  // eg: ./gradlew allDeps\n  task allDeps(type: DependencyReportTask) {}\n  // enable running :dependencyInsight task recursively on all subprojects\n  // eg: ./gradlew allDepInsight --configuration runtime --dependency com.fasterxml.jackson.core:jackson-databind\n  task allDepInsight(type: DependencyInsightReportTask) {showingAllVariants = false} doLast {}\n\n  apply plugin: 'java-library'\n  apply plugin: 'checkstyle'\n  apply plugin: \"com.github.spotbugs\"\n\n  // We use the shadow plugin for the jmh-benchmarks module and the `-all` jar can get pretty large, so\n  // don't publish it\n  def shouldPublish = !project.name.equals('jmh-benchmarks')\n  def shouldPublishWithShadow = (['clients'].contains(project.name))\n\n  if (shouldPublish) {\n    apply plugin: 'maven-publish'\n    apply plugin: 'signing'\n\n    // Add aliases for the task names used by the maven plugin for backwards compatibility\n    // The maven plugin was replaced by the maven-publish plugin in Gradle 7.0\n    tasks.register('install').configure { dependsOn(publishToMavenLocal) }\n    tasks.register('uploadArchives').configure { dependsOn(publish) }\n  }\n\n  // apply the eclipse plugin only to subprojects that hold code. 'connect' is just a folder.\n  if (!project.name.equals('connect')) {\n    apply plugin: 'eclipse'\n    fineTuneEclipseClasspathFile(eclipse, project)\n  }\n\n  java {\n    consistentResolution {\n      // resolve the compileClasspath and then \"inject\" the result of resolution as strict constraints into the runtimeClasspath\n      useCompileClasspathVersions()\n    }\n  }\n\n  tasks.withType(JavaCompile) {\n    configureJavaCompiler(name, options, project.path)\n  }\n\n  if (shouldPublish) {\n\n    publishing {\n      repositories {\n        // To test locally, invoke gradlew with `-PmavenUrl=file:///some/local/path`\n        maven {\n          url = mavenUrl\n          credentials {\n            username = mavenUsername\n            password = mavenPassword\n          }\n        }\n      }\n      publications {\n        mavenJava(MavenPublication) {\n          if (!shouldPublishWithShadow) {\n            from components.java\n          } else {\n            apply plugin: 'io.github.goooler.shadow'\n            project.shadow.component(mavenJava)\n\n            // Fix for avoiding inclusion of runtime dependencies marked as 'shadow' in MANIFEST Class-Path.\n            // https://github.com/johnrengelman/shadow/issues/324\n            afterEvaluate {\n              pom.withXml { xml ->\n                if (xml.asNode().get('dependencies') == null) {\n                  xml.asNode().appendNode('dependencies')\n                }\n                def dependenciesNode = xml.asNode().get('dependencies').get(0)\n                project.configurations.shadowed.allDependencies.each {\n                  def dependencyNode = dependenciesNode.appendNode('dependency')\n                  dependencyNode.appendNode('groupId', it.group)\n                  dependencyNode.appendNode('artifactId', it.name)\n                  dependencyNode.appendNode('version', it.version)\n                  dependencyNode.appendNode('scope', 'runtime')\n                }\n              }\n            }\n          }\n\n          afterEvaluate {\n            [\"srcJar\", \"javadocJar\", \"scaladocJar\", \"testJar\", \"testSrcJar\"].forEach { taskName ->\n              def task = tasks.findByName(taskName)\n              if (task != null)\n                artifact task\n            }\n\n            artifactId = base.archivesName.get()\n            pom {\n              name = 'Apache Kafka'\n              url = 'https://kafka.apache.org'\n              licenses {\n                license {\n                  name = 'The Apache License, Version 2.0'\n                  url = 'http://www.apache.org/licenses/LICENSE-2.0.txt'\n                  distribution = 'repo'\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n\n    if (shouldSign) {\n      signing {\n        sign publishing.publications.mavenJava\n      }\n    }\n  }\n\n  def testLoggingEvents = [\"passed\", \"skipped\", \"failed\"]\n  def testShowStandardStreams = false\n  def testExceptionFormat = 'full'\n  // Gradle built-in logging only supports sending test output to stdout, which generates a lot\n  // of noise, especially for passing tests. We really only want output for failed tests. This\n  // hooks into the output and logs it (so we don't have to buffer it all in memory) and only\n  // saves the output for failing tests. Directory and filenames are such that you can, e.g.,\n  // create a Jenkins rule to collect failed test output.\n  def logTestStdout = {\n    def testId = { TestDescriptor descriptor ->\n      \"${descriptor.className}.${descriptor.name}\".toString()\n    }\n\n    def logFiles = new HashMap<String, File>()\n    def logStreams = new HashMap<String, FileOutputStream>()\n    beforeTest { TestDescriptor td ->\n      def tid = testId(td)\n      // truncate the file name if it's too long\n      def logFile = new File(\n              \"${projectDir}/build/reports/testOutput/${tid.substring(0, Math.min(tid.size(),240))}.test.stdout\"\n      )\n      logFile.parentFile.mkdirs()\n      logFiles.put(tid, logFile)\n      logStreams.put(tid, new FileOutputStream(logFile))\n    }\n    onOutput { TestDescriptor td, TestOutputEvent toe ->\n      def tid = testId(td)\n      // Some output can happen outside the context of a specific test (e.g. at the class level)\n      // and beforeTest/afterTest seems to not be invoked for these cases (and similarly, there's\n      // a TestDescriptor hierarchy that includes the thread executing the test, Gradle tasks,\n      // etc). We see some of these in practice and it seems like something buggy in the Gradle\n      // test runner since we see it *before* any tests and it is frequently not related to any\n      // code in the test (best guess is that it is tail output from last test). We won't have\n      // an output file for these, so simply ignore them. If they become critical for debugging,\n      // they can be seen with showStandardStreams.\n      if (td.name == td.className || td.className == null) {\n        // silently ignore output unrelated to specific test methods\n        return\n      } else if (logStreams.get(tid) == null) {\n        println \"WARNING: unexpectedly got output for a test [${tid}]\" +\n                \" that we didn't previously see in the beforeTest hook.\" +\n                \" Message for debugging: [\" + toe.message + \"].\"\n        return\n      }\n      try {\n        logStreams.get(tid).write(toe.message.getBytes(StandardCharsets.UTF_8))\n      } catch (Exception e) {\n        println \"ERROR: Failed to write output for test ${tid}\"\n        e.printStackTrace()\n      }\n    }\n    afterTest { TestDescriptor td, TestResult tr ->\n      def tid = testId(td)\n      try {\n        logStreams.get(tid).close()\n        if (tr.resultType != TestResult.ResultType.FAILURE) {\n          logFiles.get(tid).delete()\n        } else {\n          def file = logFiles.get(tid)\n          println \"${tid} failed, log available in ${file}\"\n        }\n      } catch (Exception e) {\n        println \"ERROR: Failed to close stdout file for ${tid}\"\n        e.printStackTrace()\n      } finally {\n        logFiles.remove(tid)\n        logStreams.remove(tid)\n      }\n    }\n  }\n\n  // The suites are for running sets of tests in IDEs.\n  // Gradle will run each test class, so we exclude the suites to avoid redundantly running the tests twice.\n  def testsToExclude = ['**/*Suite.class']\n\n  test {\n    ext {\n      isGithubActions = System.getenv('GITHUB_ACTIONS') != null\n      hadFailure = false  // Used to track if any tests failed, see afterSuite below\n    }\n\n    maxParallelForks = maxTestForks\n    ignoreFailures = userIgnoreFailures || ext.isGithubActions\n\n    maxHeapSize = defaultMaxHeapSize\n    jvmArgs = defaultJvmArgs\n\n    // KAFKA-17433 Used by deflake.yml github action to repeat individual tests\n    systemProperty(\"kafka.cluster.test.repeat\", project.findProperty(\"kafka.cluster.test.repeat\"))\n    systemProperty(\"kafka.test.catalog.file\", project.findProperty(\"kafka.test.catalog.file\"))\n    systemProperty(\"kafka.test.run.quarantined\", \"false\")\n\n    testLogging {\n      events = userTestLoggingEvents ?: testLoggingEvents\n      showStandardStreams = userShowStandardStreams ?: testShowStandardStreams\n      exceptionFormat = testExceptionFormat\n      displayGranularity = 0\n    }\n    logTestStdout.rehydrate(delegate, owner, this)()\n\n    exclude testsToExclude\n\n    useJUnitPlatform {\n      includeEngines 'junit-jupiter'\n      excludeTags 'flaky'\n    }\n\n    develocity {\n      testRetry {\n        maxRetries = userMaxTestRetries\n        maxFailures = userMaxTestRetryFailures\n      }\n    }\n    \n    // As we process results, check if there were any test failures.\n    afterSuite { desc, result ->\n      if (result.resultType == TestResult.ResultType.FAILURE) {\n        ext.hadFailure = true\n      }\n    }\n\n    // This closure will copy JUnit XML files out of the sub-project's build directory and into\n    // a top-level build/junit-xml directory. This is necessary to avoid reporting on tests which\n    // were not run, but instead were restored via FROM-CACHE. See KAFKA-17479 for more details.\n    doLast {\n      if (ext.isGithubActions) {\n        def moduleDirPath = projectToJUnitXmlPath(project)\n        def dest = rootProject.layout.buildDirectory.dir(\"junit-xml/${moduleDirPath}/test\").get().asFile\n        println \"Copy JUnit XML for ${project.name} to $dest\"\n        ant.copy(todir: \"$dest\") {\n          ant.fileset(dir: \"${test.reports.junitXml.entryPoint}\")\n        }\n\n        // If there were any test failures, we want to fail the task to prevent the failures\n        // from being cached.\n        if (ext.hadFailure) {\n          throw new GradleException(\"Failing this task since '${project.name}:${name}' had test failures.\")\n        }\n      }\n    }\n  }\n\n  task quarantinedTest(type: Test, dependsOn: compileJava) {\n    ext {\n      isGithubActions = System.getenv('GITHUB_ACTIONS') != null\n      hadFailure = false  // Used to track if any tests failed, see afterSuite below\n    }\n\n    // Disable caching and up-to-date for this task. We always want quarantined tests\n    // to run and never want to cache their results. Since we do this, we can avoid\n    // explicitly failing the build like we do in \"test\" with ext.hadFailure.\n    outputs.upToDateWhen { false }\n    outputs.cacheIf { false }\n\n    maxParallelForks = maxTestForks\n    ignoreFailures = userIgnoreFailures || ext.isGithubActions\n\n    maxHeapSize = defaultMaxHeapSize\n    jvmArgs = defaultJvmArgs\n\n    // KAFKA-17433 Used by deflake.yml github action to repeat individual tests\n    systemProperty(\"kafka.cluster.test.repeat\", project.findProperty(\"kafka.cluster.test.repeat\"))\n    systemProperty(\"kafka.test.catalog.file\", project.findProperty(\"kafka.test.catalog.file\"))\n    systemProperty(\"kafka.test.run.quarantined\", \"true\")\n\n    testLogging {\n      events = userTestLoggingEvents ?: testLoggingEvents\n      showStandardStreams = userShowStandardStreams ?: testShowStandardStreams\n      exceptionFormat = testExceptionFormat\n      displayGranularity = 0\n    }\n    logTestStdout.rehydrate(delegate, owner, this)()\n\n    useJUnitPlatform {\n      includeEngines 'junit-jupiter'\n    }\n\n    develocity {\n      testRetry {\n        maxRetries = userMaxQuarantineTestRetries\n        maxFailures = userMaxQuarantineTestRetryFailures\n      }\n    }\n\n    // As we process results, check if there were any test failures.\n    afterSuite { desc, result ->\n      if (result.resultType == TestResult.ResultType.FAILURE) {\n        ext.hadFailure = true\n      }\n    }\n\n    // This closure will copy JUnit XML files out of the sub-project's build directory and into\n    // a top-level build/junit-xml directory. This is necessary to avoid reporting on tests which\n    // were not run, but instead were restored via FROM-CACHE. See KAFKA-17479 for more details.\n    doLast {\n      if (ext.isGithubActions) {\n        def moduleDirPath = projectToJUnitXmlPath(project)\n        def dest = rootProject.layout.buildDirectory.dir(\"junit-xml/${moduleDirPath}/quarantinedTest\").get().asFile\n        println \"Copy JUnit XML for ${project.name} to $dest\"\n        ant.copy(todir: \"$dest\", failonerror: \"false\") {\n          ant.fileset(dir: \"${quarantinedTest.reports.junitXml.entryPoint}\") {\n            ant.include(name: \"**/*.xml\")\n          }\n        }\n        // If there were any test failures, we want to fail the task to prevent the failures\n        // from being cached.\n        if (ext.hadFailure) {\n          throw new GradleException(\"Failing this task since '${project.name}:${name}' had test failures.\")\n        }\n      }\n    }\n  }\n\n  task integrationTest(type: Test, dependsOn: compileJava) {\n    maxParallelForks = maxTestForks\n    ignoreFailures = userIgnoreFailures\n\n    // Increase heap size for integration tests\n    maxHeapSize = \"2560m\"\n    jvmArgs = defaultJvmArgs\n\n\n    testLogging {\n      events = userTestLoggingEvents ?: testLoggingEvents\n      showStandardStreams = userShowStandardStreams ?: testShowStandardStreams\n      exceptionFormat = testExceptionFormat\n      displayGranularity = 0\n    }\n    logTestStdout.rehydrate(delegate, owner, this)()\n\n    exclude testsToExclude\n\n    useJUnitPlatform {\n      includeTags \"integration\"\n      includeEngines 'junit-jupiter'\n    }\n\n    develocity {\n      testRetry {\n        maxRetries = userMaxTestRetries\n        maxFailures = userMaxTestRetryFailures\n      }\n    }\n  }\n\n  task unitTest(type: Test, dependsOn: compileJava) {\n    maxParallelForks = maxTestForks\n    ignoreFailures = userIgnoreFailures\n\n    maxHeapSize = defaultMaxHeapSize\n    jvmArgs = defaultJvmArgs\n\n    testLogging {\n      events = userTestLoggingEvents ?: testLoggingEvents\n      showStandardStreams = userShowStandardStreams ?: testShowStandardStreams\n      exceptionFormat = testExceptionFormat\n      displayGranularity = 0\n    }\n    logTestStdout.rehydrate(delegate, owner, this)()\n\n    exclude testsToExclude\n\n    useJUnitPlatform {\n      excludeTags \"integration\"\n      includeEngines 'junit-jupiter'\n    }\n\n    develocity {\n      testRetry {\n        maxRetries = userMaxTestRetries\n        maxFailures = userMaxTestRetryFailures\n      }\n    }\n  }\n\n  // remove test output from all test types\n  tasks.withType(Test).all { t ->\n    cleanTest {\n      delete t.reports.junitXml.outputLocation\n      delete t.reports.html.outputLocation\n    }\n  }\n\n  jar {\n    from \"$rootDir/LICENSE\"\n    from \"$rootDir/NOTICE\"\n  }\n\n  task srcJar(type: Jar) {\n    archiveClassifier = 'sources'\n    from \"$rootDir/LICENSE\"\n    from \"$rootDir/NOTICE\"\n    from sourceSets.main.allSource\n  }\n\n  task javadocJar(type: Jar, dependsOn: javadoc) {\n    archiveClassifier = 'javadoc'\n    from \"$rootDir/LICENSE\"\n    from \"$rootDir/NOTICE\"\n    from javadoc.destinationDir\n  }\n\n  task docsJar(dependsOn: javadocJar)\n\n  test.dependsOn('javadoc')\n\n  task systemTestLibs(dependsOn: jar)\n\n  if (!sourceSets.test.allSource.isEmpty()) {\n    task testJar(type: Jar) {\n      archiveClassifier = 'test'\n      from \"$rootDir/LICENSE\"\n      from \"$rootDir/NOTICE\"\n      from sourceSets.test.output\n      // The junit-platform.properties file is used for configuring and customizing the behavior of the JUnit platform.\n      // It should only apply to Kafka's own JUnit tests, and should not exist in the test JAR.\n      // If we include it in the test JAR, it could lead to conflicts with user configurations.\n      exclude 'junit-platform.properties'\n    }\n\n    task testSrcJar(type: Jar, dependsOn: testJar) {\n      archiveClassifier = 'test-sources'\n      from \"$rootDir/LICENSE\"\n      from \"$rootDir/NOTICE\"\n      from sourceSets.test.allSource\n    }\n\n  }\n\n  plugins.withType(ScalaPlugin) {\n\n    scala {\n      zincVersion = versions.zinc\n    }\n\n    task scaladocJar(type:Jar, dependsOn: scaladoc) {\n      archiveClassifier = 'scaladoc'\n      from \"$rootDir/LICENSE\"\n      from \"$rootDir/NOTICE\"\n      from scaladoc.destinationDir\n    }\n\n    //documentation task should also trigger building scala doc jar\n    docsJar.dependsOn scaladocJar\n\n  }\n\n  tasks.withType(ScalaCompile) {\n    def releaseVersion = modulesNeedingJava11.any { project.path == it } ? minClientJavaVersion : minNonClientJavaVersion\n    scalaCompileOptions.keepAliveMode = userKeepAliveMode\n\n    scalaCompileOptions.additionalParameters = [\n      \"-deprecation:false\",\n      \"-unchecked\",\n      \"-encoding\", \"utf8\",\n      \"-Xlog-reflective-calls\",\n      \"-feature\",\n      \"-language:postfixOps\",\n      \"-language:implicitConversions\",\n      \"-language:existentials\",\n      \"-Ybackend-parallelism\", maxScalacThreads.toString(),\n      \"-Xlint:constant\",\n      \"-Xlint:delayedinit-select\",\n      \"-Xlint:doc-detached\",\n      \"-Xlint:missing-interpolator\",\n      \"-Xlint:nullary-unit\",\n      \"-Xlint:option-implicit\",\n      \"-Xlint:package-object-classes\",\n      \"-Xlint:poly-implicit-overload\",\n      \"-Xlint:private-shadow\",\n      \"-Xlint:stars-align\",\n      \"-Xlint:type-parameter-shadow\",\n      \"-Xlint:unused\"\n    ]\n\n    // See README.md for details on this option and the meaning of each value\n    if (userScalaOptimizerMode.equals(\"method\"))\n      scalaCompileOptions.additionalParameters += [\"-opt:l:method\"]\n    else if (userScalaOptimizerMode.startsWith(\"inline-\")) {\n      List<String> inlineFrom = [\"-opt-inline-from:org.apache.kafka.**\"]\n      if (project.name.equals('core'))\n        inlineFrom.add(\"-opt-inline-from:kafka.**\")\n      if (userScalaOptimizerMode.equals(\"inline-scala\"))\n        inlineFrom.add(\"-opt-inline-from:scala.**\")\n\n      scalaCompileOptions.additionalParameters += [\"-opt:l:inline\"]\n      scalaCompileOptions.additionalParameters += inlineFrom\n    }\n\n    scalaCompileOptions.additionalParameters += [\"-opt-warnings\", \"-Xlint:strict-unsealed-patmat\"]\n    // Scala 2.13.2 introduces compiler warnings suppression, which is a pre-requisite for -Xfatal-warnings\n    scalaCompileOptions.additionalParameters += [\"-Xfatal-warnings\"]\n    scalaCompileOptions.additionalParameters += [\"--release\", String.valueOf(releaseVersion)]\n\n    // Gradle does not support the `release` configuration when performing joint Java-Scala compilation.\n    // For more details, refer to https://github.com/gradle/gradle/issues/13762.\n    // As a result, we need to explicitly configure the Scala compiler with this setting.\n    options.compilerArgs += [\"--release\", String.valueOf(releaseVersion)]\n\n    configureJavaCompiler(name, options, project.path)\n\n    configure(scalaCompileOptions.forkOptions) {\n      memoryMaximumSize = defaultMaxHeapSize\n      jvmArgs = defaultJvmArgs\n    }\n  }\n\n  checkstyle {\n    configDirectory = rootProject.layout.projectDirectory.dir(\"checkstyle\")\n    configProperties = checkstyleConfigProperties(\"import-control.xml\")\n    toolVersion = versions.checkstyle\n  }\n\n  configure(checkstyleMain) {\n    group = 'Verification'\n    description = 'Run checkstyle on all main Java sources'\n  }\n\n  configure(checkstyleTest) {\n    group = 'Verification'\n    description = 'Run checkstyle on all test Java sources'\n  }\n\n  test.dependsOn('checkstyleMain', 'checkstyleTest')\n\n  spotbugs {\n    toolVersion = versions.spotbugs\n    excludeFilter = file(\"$rootDir/gradle/spotbugs-exclude.xml\")\n    ignoreFailures = false\n  }\n  test.dependsOn('spotbugsMain')\n\n  tasks.withType(com.github.spotbugs.snom.SpotBugsTask).configureEach {\n    reports.configure {\n      // Continue supporting `xmlFindBugsReport` for compatibility\n      xml.enabled(project.hasProperty('xmlSpotBugsReport') || project.hasProperty('xmlFindBugsReport'))\n      html.enabled(!project.hasProperty('xmlSpotBugsReport') && !project.hasProperty('xmlFindBugsReport'))\n    }\n    maxHeapSize = defaultMaxHeapSize\n    jvmArgs = defaultJvmArgs\n  }\n\n  // Ignore core since its a scala project\n  if (it.path != ':core') {\n    if (userEnableTestCoverage) {\n      apply plugin: \"jacoco\"\n\n      jacoco {\n        toolVersion = versions.jacoco\n      }\n\n      jacocoTestReport {\n        dependsOn tasks.test\n        sourceSets sourceSets.main\n        reports {\n          html.required = true\n          xml.required = true\n          csv.required = false\n        }\n      }\n\n    }\n  }\n\n  if (userEnableTestCoverage) {\n    def coverageGen = it.path == ':core' ? 'reportTestScoverage' : 'jacocoTestReport'\n    tasks.register('reportCoverage').configure { dependsOn(coverageGen) }\n  }\n\n  dependencyCheck {\n    suppressionFile = \"$rootDir/gradle/resources/dependencycheck-suppressions.xml\"\n    skipProjects = [ \":jmh-benchmarks\", \":trogdor\" ]\n    skipConfigurations = [ \"zinc\" ]\n  }\n  apply plugin: 'com.diffplug.spotless'\n  spotless {\n    java {\n      targetExclude('**/generated/**/*.java','**/generated-test/**/*.java')\n      importOrder('kafka', 'org.apache.kafka', 'com', 'net', 'org', 'java', 'javax', '', '\\\\#')\n      removeUnusedImports()\n    }\n  }\n}\n\ngradle.taskGraph.whenReady { taskGraph ->\n  taskGraph.getAllTasks().findAll { it.name.contains('spotbugsScoverage') || it.name.contains('spotbugsTest') }.each { task ->\n    task.enabled = false\n  }\n}\n\ndef fineTuneEclipseClasspathFile(eclipse, project) {\n  eclipse.classpath.file {\n    beforeMerged { cp ->\n      cp.entries.clear()\n      // for the core project add the directories defined under test/scala as separate source directories\n      if (project.name.equals('core')) {\n        cp.entries.add(new org.gradle.plugins.ide.eclipse.model.SourceFolder(\"src/test/scala/integration\", null))\n        cp.entries.add(new org.gradle.plugins.ide.eclipse.model.SourceFolder(\"src/test/scala/other\", null))\n        cp.entries.add(new org.gradle.plugins.ide.eclipse.model.SourceFolder(\"src/test/scala/unit\", null))\n      }\n    }\n    whenMerged { cp ->\n      // for the core project exclude the separate sub-directories defined under test/scala. These are added as source dirs above\n      if (project.name.equals('core')) {\n        cp.entries.findAll { it.kind == \"src\" && it.path.equals(\"src/test/scala\") }*.excludes = [\"integration/\", \"other/\", \"unit/\"]\n      }\n      /*\n       * Set all eclipse build output to go to 'build_eclipse' directory. This is to ensure that gradle and eclipse use different\n       * build output directories, and also avoid using the eclipse default of 'bin' which clashes with some of our script directories.\n       * https://discuss.gradle.org/t/eclipse-generated-files-should-be-put-in-the-same-place-as-the-gradle-generated-files/6986/2\n       */\n      cp.entries.findAll { it.kind == \"output\" }*.path = \"build_eclipse\"\n      /*\n       * Some projects have explicitly added test output dependencies. These are required for the gradle build but not required\n       * in Eclipse since the dependent projects are added as dependencies. So clean up these from the generated classpath.\n       */\n      cp.entries.removeAll { it.kind == \"lib\" && it.path.matches(\".*/build/(classes|resources)/test\") }\n    }\n  }\n}\n\ndef checkstyleConfigProperties(configFileName) {\n  [importControlFile: \"$configFileName\"]\n}\n\nif (userEnableTestCoverage) {\n  tasks.register('reportCoverage').configure { dependsOn(subprojects.reportCoverage) }\n}\n\ndef connectPkgs = [\n    'connect:api',\n    'connect:basic-auth-extension',\n    'connect:file',\n    'connect:json',\n    'connect:runtime',\n    'connect:test-plugins',\n    'connect:transforms',\n    'connect:mirror',\n    'connect:mirror-client'\n]\n\ntasks.create(name: \"jarConnect\", dependsOn: connectPkgs.collect { it + \":jar\" }) {}\n\ntasks.create(name: \"testConnect\", dependsOn: connectPkgs.collect { it + \":test\" }) {}\n\nproject(':server') {\n  base {\n    archivesName = \"kafka-server\"\n  }\n\n  dependencies {\n    implementation project(':clients')\n    implementation project(':metadata')\n    implementation project(':server-common')\n    implementation project(':storage')\n    implementation project(':group-coordinator')\n    implementation project(':transaction-coordinator')\n    implementation project(':raft')\n    implementation libs.jacksonDatabind\n    implementation libs.metrics\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation project(':clients').sourceSets.test.output\n\n    testImplementation libs.mockitoCore\n    testImplementation libs.junitJupiter\n\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  task createVersionFile() {\n    def receiptFile = file(\"${layout.buildDirectory.get().asFile.path}/kafka/$buildVersionFileName\")\n    inputs.property \"commitId\", commitId\n    inputs.property \"version\", version\n    outputs.file receiptFile\n    outputs.cacheIf { true }\n\n    doLast {\n      def data = [\n        commitId: commitId,\n        version: version,\n      ]\n\n      receiptFile.parentFile.mkdirs()\n      def content = data.entrySet().collect { \"$it.key=$it.value\" }.sort().join(\"\\n\")\n      receiptFile.setText(content, \"ISO-8859-1\")\n    }\n  }\n\n  jar {\n    dependsOn createVersionFile\n    from(\"${layout.buildDirectory.get().asFile.path}\") {\n      include \"kafka/$buildVersionFileName\"\n    }\n  }\n\n  clean.doFirst {\n    delete \"${layout.buildDirectory.get().asFile.path}/kafka/\"\n  }\n\n  checkstyle {\n    configProperties = checkstyleConfigProperties(\"import-control-server.xml\")\n  }\n\n  javadoc {\n    enabled = false\n  }\n}\n\nproject(':share') {\n  base {\n    archivesName = \"kafka-share\"\n  }\n\n  dependencies {\n    implementation project(':server-common')\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation project(':server-common').sourceSets.test.output\n\n    testImplementation libs.junitJupiter\n    testImplementation libs.mockitoCore\n\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  checkstyle {\n    configProperties = checkstyleConfigProperties(\"import-control-share.xml\")\n  }\n\n  javadoc {\n    enabled = false\n  }\n}\n\nproject(':core') {\n  apply plugin: 'scala'\n\n  // scaladoc generation is configured at the sub-module level with an artifacts\n  // block (cf. see streams-scala). If scaladoc generation is invoked explicitly\n  // for the `core` module, this ensures the generated jar doesn't include scaladoc\n  // files since the `core` module doesn't include public APIs.\n  scaladoc {\n    enabled = false\n  }\n  if (userEnableTestCoverage)\n    apply plugin: \"org.scoverage\"\n\n  base {\n    archivesName = \"kafka_${versions.baseScala}\"\n  }\n\n  dependencies {\n    // `core` is often used in users' tests, define the following dependencies as `api` for backwards compatibility\n    // even though the `core` module doesn't expose any public API\n    api project(':clients')\n    api libs.scalaLibrary\n\n    implementation project(':server-common')\n    implementation project(':group-coordinator:group-coordinator-api')\n    implementation project(':group-coordinator')\n    implementation project(':transaction-coordinator')\n    implementation project(':metadata')\n    implementation project(':storage:storage-api')\n    implementation project(':tools:tools-api')\n    implementation project(':raft')\n    implementation project(':storage')\n    implementation project(':server')\n    implementation project(':coordinator-common')\n    implementation project(':share')\n    implementation project(':share-coordinator')\n\n    implementation libs.argparse4j\n    implementation libs.commonsValidator\n    implementation libs.jacksonDatabind\n    implementation libs.jacksonModuleScala\n    implementation libs.jacksonDataformatCsv\n    implementation libs.jacksonJDK8Datatypes\n    implementation libs.joptSimple\n    implementation libs.jose4j\n    implementation libs.metrics\n    // only needed transitively, but set it explicitly to ensure it has the same version as scala-library\n    implementation libs.scalaReflect\n    implementation libs.scalaLogging\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation project(':group-coordinator').sourceSets.test.output\n    testImplementation project(':share-coordinator').sourceSets.test.output\n    testImplementation project(':metadata').sourceSets.test.output\n    testImplementation project(':raft').sourceSets.test.output\n    testImplementation project(':server-common').sourceSets.test.output\n    testImplementation project(':storage:storage-api').sourceSets.test.output\n    testImplementation project(':server').sourceSets.test.output\n    testImplementation project(':share').sourceSets.test.output\n    testImplementation project(':test-common')\n    testImplementation project(':test-common:test-common-api')\n    testImplementation libs.bcpkix\n    testImplementation libs.mockitoCore\n    testImplementation(libs.apacheda) {\n      exclude group: 'xml-apis', module: 'xml-apis'\n      // `mina-core` is a transitive dependency for `apacheds` and `apacheda`.\n      // It is safer to use from `apacheds` since that is the implementation.\n      exclude module: 'mina-core'\n    }\n    testImplementation libs.apachedsCoreApi\n    testImplementation libs.apachedsInterceptorKerberos\n    testImplementation libs.apachedsProtocolShared\n    testImplementation libs.apachedsProtocolKerberos\n    testImplementation libs.apachedsProtocolLdap\n    testImplementation libs.apachedsLdifPartition\n    testImplementation libs.apachedsMavibotPartition\n    testImplementation libs.apachedsJdbmPartition\n    testImplementation libs.junitJupiter\n    testImplementation libs.caffeine\n\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  if (userEnableTestCoverage) {\n    scoverage {\n      scoverageVersion = versions.scoverage\n      if (versions.baseScala == '2.13') {\n        scoverageScalaVersion = '2.13.9' // there's no newer 2.13 artifact, org.scoverage:scalac-scoverage-plugin_2.13.9:2.0.11 is the latest as of now\n      }\n      reportDir = file(\"${rootProject.buildDir}/scoverage\")\n      highlighting = false\n      minimumRate = 0.0\n    }\n  }\n\n  configurations {\n    // manually excludes some unnecessary dependencies\n    implementation.exclude module: 'javax'\n    implementation.exclude module: 'jline'\n    implementation.exclude module: 'jms'\n    implementation.exclude module: 'jmxri'\n    implementation.exclude module: 'jmxtools'\n    implementation.exclude module: 'mail'\n    // To prevent a UniqueResourceException due the same resource existing in both\n    // org.apache.directory.api/api-all and org.apache.directory.api/api-ldap-schema-data\n    testImplementation.exclude module: 'api-ldap-schema-data'\n  }\n\n  tasks.create(name: \"copyDependantLibs\", type: Copy) {\n    from (configurations.runtimeClasspath) {\n      exclude('kafka-clients*')\n    }\n    into \"${layout.buildDirectory.get().asFile.path}/dependant-libs-${versions.scala}\"\n    duplicatesStrategy 'exclude'\n  }\n\n  task genProtocolErrorDocs(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.common.protocol.Errors'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"protocol_errors.html\").newOutputStream()\n  }\n\n  task genProtocolTypesDocs(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.common.protocol.types.Type'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"protocol_types.html\").newOutputStream()\n  }\n\n  task genProtocolApiKeyDocs(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.common.protocol.ApiKeys'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"protocol_api_keys.html\").newOutputStream()\n  }\n\n  task genProtocolMessageDocs(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.common.protocol.Protocol'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"protocol_messages.html\").newOutputStream()\n  }\n\n  task genAdminClientConfigDocs(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.clients.admin.AdminClientConfig'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"admin_client_config.html\").newOutputStream()\n  }\n\n  task genProducerConfigDocs(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.clients.producer.ProducerConfig'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"producer_config.html\").newOutputStream()\n  }\n\n  task genConsumerConfigDocs(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.clients.consumer.ConsumerConfig'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"consumer_config.html\").newOutputStream()\n  }\n\n  task genKafkaConfigDocs(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'kafka.server.KafkaConfig'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"kafka_config.html\").newOutputStream()\n  }\n\n  task genTopicConfigDocs(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.storage.internals.log.LogConfig'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"topic_config.html\").newOutputStream()\n  }\n\n  task genConsumerMetricsDocs(type: JavaExec) {\n    classpath = sourceSets.test.runtimeClasspath\n    mainClass = 'org.apache.kafka.clients.consumer.internals.ConsumerMetrics'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"consumer_metrics.html\").newOutputStream()\n  }\n\n  task genProducerMetricsDocs(type: JavaExec) {\n    classpath = sourceSets.test.runtimeClasspath\n    mainClass = 'org.apache.kafka.clients.producer.internals.ProducerMetrics'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"producer_metrics.html\").newOutputStream()\n  }\n\n  task siteDocsTar(dependsOn: ['genProtocolErrorDocs', 'genProtocolTypesDocs', 'genProtocolApiKeyDocs', 'genProtocolMessageDocs',\n                               'genAdminClientConfigDocs', 'genProducerConfigDocs', 'genConsumerConfigDocs',\n                               'genKafkaConfigDocs', 'genTopicConfigDocs',\n                               ':connect:runtime:genConnectConfigDocs', ':connect:runtime:genConnectTransformationDocs',\n                               ':connect:runtime:genConnectPredicateDocs',\n                               ':connect:runtime:genSinkConnectorConfigDocs', ':connect:runtime:genSourceConnectorConfigDocs',\n                               ':streams:genStreamsConfigDocs', 'genConsumerMetricsDocs', 'genProducerMetricsDocs',\n                               ':connect:runtime:genConnectMetricsDocs', ':connect:runtime:genConnectOpenAPIDocs',\n                               ':connect:mirror:genMirrorSourceConfigDocs', ':connect:mirror:genMirrorCheckpointConfigDocs',\n                               ':connect:mirror:genMirrorHeartbeatConfigDocs', ':connect:mirror:genMirrorConnectorConfigDocs',\n                               ':storage:genRemoteLogManagerConfigDoc', ':storage:genRemoteLogMetadataManagerConfigDoc'], type: Tar) {\n    archiveClassifier = 'site-docs'\n    compression = Compression.GZIP\n    from project.file(\"$rootDir/docs\")\n    into 'site-docs'\n    duplicatesStrategy 'exclude'\n  }\n\n  tasks.create(name: \"releaseTarGz\", dependsOn: configurations.archives.artifacts, type: Tar) {\n    into \"kafka_${versions.baseScala}-${archiveVersion.get()}\"\n    compression = Compression.GZIP\n    from(project.file(\"$rootDir/bin\")) { into \"bin/\" }\n    from(project.file(\"$rootDir/config\")) { into \"config/\" }\n    from(project.file(\"$rootDir/licenses\")) { into \"licenses/\" }\n    from \"$rootDir/LICENSE-binary\" rename {String filename -> filename.replace(\"-binary\", \"\")}\n    from \"$rootDir/NOTICE-binary\" rename {String filename -> filename.replace(\"-binary\", \"\")}\n    from(configurations.runtimeClasspath) { into(\"libs/\") }\n    from(configurations.archives.artifacts.files) { into(\"libs/\") }\n    from(project.siteDocsTar) { into(\"site-docs/\") }\n    from(project(':tools').jar) { into(\"libs/\") }\n    from(project(':tools').configurations.runtimeClasspath) { into(\"libs/\") }\n    from(project(':trogdor').jar) { into(\"libs/\") }\n    from(project(':trogdor').configurations.runtimeClasspath) { into(\"libs/\") }\n    from(project(':shell').jar) { into(\"libs/\") }\n    from(project(':shell').configurations.runtimeClasspath) { into(\"libs/\") }\n    from(project(':connect:api').jar) { into(\"libs/\") }\n    from(project(':connect:api').configurations.runtimeClasspath) { into(\"libs/\") }\n    from(project(':connect:runtime').jar) { into(\"libs/\") }\n    from(project(':connect:runtime').configurations.runtimeClasspath) { into(\"libs/\") }\n    from(project(':connect:transforms').jar) { into(\"libs/\") }\n    from(project(':connect:transforms').configurations.runtimeClasspath) { into(\"libs/\") }\n    from(project(':connect:json').jar) { into(\"libs/\") }\n    from(project(':connect:json').configurations.runtimeClasspath) { into(\"libs/\") }\n    from(project(':connect:file').jar) { into(\"libs/\") }\n    from(project(':connect:file').configurations.runtimeClasspath) { into(\"libs/\") }\n    from(project(':connect:basic-auth-extension').jar) { into(\"libs/\") }\n    from(project(':connect:basic-auth-extension').configurations.runtimeClasspath) { into(\"libs/\") }\n    from(project(':connect:mirror').jar) { into(\"libs/\") }\n    from(project(':connect:mirror').configurations.runtimeClasspath) { into(\"libs/\") }\n    from(project(':connect:mirror-client').jar) { into(\"libs/\") }\n    from(project(':connect:mirror-client').configurations.runtimeClasspath) { into(\"libs/\") }\n    from(project(':streams').jar) { into(\"libs/\") }\n    from(project(':streams').configurations.runtimeClasspath) { into(\"libs/\") }\n    from(project(':streams:streams-scala').jar) { into(\"libs/\") }\n    from(project(':streams:streams-scala').configurations.runtimeClasspath) { into(\"libs/\") }\n    from(project(':streams:test-utils').jar) { into(\"libs/\") }\n    from(project(':streams:test-utils').configurations.runtimeClasspath) { into(\"libs/\") }\n    from(project(':streams:examples').jar) { into(\"libs/\") }\n    from(project(':streams:examples').configurations.runtimeClasspath) { into(\"libs/\") }\n    from(project(':tools:tools-api').jar) { into(\"libs/\") }\n    from(project(':tools:tools-api').configurations.runtimeClasspath) { into(\"libs/\") }\n    duplicatesStrategy 'exclude'\n  }\n\n  jar {\n    dependsOn copyDependantLibs\n  }\n\n  jar.manifest {\n    attributes(\n      'Version': \"${version}\"\n    )\n  }\n\n  tasks.create(name: \"copyDependantTestLibs\", type: Copy) {\n    from (configurations.testRuntimeClasspath) {\n      include('*.jar')\n    }\n    into \"${layout.buildDirectory.get().asFile.path}/dependant-testlibs\"\n    //By default gradle does not handle test dependencies between the sub-projects\n    //This line is to include clients project test jar to dependant-testlibs\n    from (project(':clients').testJar ) { \"${layout.buildDirectory.get().asFile.path}/dependant-testlibs\" }\n    duplicatesStrategy 'exclude'\n  }\n\n  systemTestLibs.dependsOn('jar', 'testJar', 'copyDependantTestLibs')\n\n  checkstyle {\n    configProperties = checkstyleConfigProperties(\"import-control-core.xml\")\n  }\n\n  sourceSets {\n    // Set java/scala source folders in the `scala` block to enable joint compilation\n    main {\n      java {\n        srcDirs = []\n      }\n      scala {\n        srcDirs = [\"src/main/java\", \"src/main/scala\"]\n      }\n    }\n    test {\n      java {\n        srcDirs = []\n      }\n      scala {\n        srcDirs = [\"src/test/java\", \"src/test/scala\"]\n      }\n    }\n  }\n}\n\nproject(':metadata') {\n  base {\n    archivesName = \"kafka-metadata\"\n  }\n\n  configurations {\n    generator\n  }\n\n  dependencies {\n    implementation project(':server-common')\n    implementation project(':clients')\n    implementation project(':raft')\n    implementation libs.jacksonDatabind\n    implementation libs.jacksonJDK8Datatypes\n    implementation libs.metrics\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation libs.junitJupiter\n    testImplementation libs.jqwik\n    testImplementation libs.mockitoCore\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation project(':raft').sourceSets.test.output\n    testImplementation project(':server-common').sourceSets.test.output\n\n    testRuntimeOnly runtimeTestLibs\n\n    generator project(':generator')\n  }\n\n  task processMessages(type:JavaExec) {\n    mainClass = \"org.apache.kafka.message.MessageGenerator\"\n    classpath = configurations.generator\n    args = [ \"-p\", \"org.apache.kafka.common.metadata\",\n             \"-o\", \"${projectDir}/build/generated/main/java/org/apache/kafka/common/metadata\",\n             \"-i\", \"src/main/resources/common/metadata\",\n             \"-m\", \"MessageDataGenerator\", \"JsonConverterGenerator\",\n             \"-t\", \"MetadataRecordTypeGenerator\", \"MetadataJsonConvertersGenerator\"\n           ]\n    inputs.dir(\"src/main/resources/common/metadata\")\n        .withPropertyName(\"messages\")\n        .withPathSensitivity(PathSensitivity.RELATIVE)\n    outputs.cacheIf { true }\n    outputs.dir(\"${projectDir}/build/generated/main/java/org/apache/kafka/common/metadata\")\n  }\n\n  compileJava.dependsOn 'processMessages'\n  srcJar.dependsOn 'processMessages'\n\n  sourceSets {\n    main {\n      java {\n        srcDirs = [\"src/main/java\", \"${projectDir}/build/generated/main/java\"]\n      }\n    }\n    test {\n      java {\n        srcDirs = [\"src/test/java\"]\n      }\n    }\n  }\n\n  javadoc {\n    enabled = false\n  }\n\n  checkstyle {\n    configProperties = checkstyleConfigProperties(\"import-control-metadata.xml\")\n  }\n}\n\nproject(':group-coordinator:group-coordinator-api') {\n  base {\n    archivesName = \"kafka-group-coordinator-api\"\n  }\n\n  dependencies {\n    implementation project(':clients')\n  }\n\n  task createVersionFile() {\n    def receiptFile = file(\"${layout.buildDirectory.get().asFile.path}/kafka/$buildVersionFileName\")\n    inputs.property \"commitId\", commitId\n    inputs.property \"version\", version\n    outputs.file receiptFile\n    outputs.cacheIf { true }\n\n    doLast {\n      def data = [\n              commitId: commitId,\n              version: version,\n      ]\n\n      receiptFile.parentFile.mkdirs()\n      def content = data.entrySet().collect { \"$it.key=$it.value\" }.sort().join(\"\\n\")\n      receiptFile.setText(content, \"ISO-8859-1\")\n    }\n  }\n\n  jar {\n    dependsOn createVersionFile\n    from(\"${layout.buildDirectory.get().asFile.path}\") {\n      include \"kafka/$buildVersionFileName\"\n    }\n  }\n\n  clean.doFirst {\n    delete \"${layout.buildDirectory.get().asFile.path}/kafka/\"\n  }\n\n  javadoc {\n    include \"**/org/apache/kafka/coordinator/group/api/**\"\n  }\n\n  checkstyle {\n    configProperties = checkstyleConfigProperties(\"import-control-group-coordinator.xml\")\n  }\n}\n\nproject(':group-coordinator') {\n  base {\n    archivesName = \"kafka-group-coordinator\"\n  }\n\n  configurations {\n    generator\n  }\n\n  dependencies {\n    implementation project(':server-common')\n    implementation project(':clients')\n    implementation project(':metadata')\n    implementation project(':group-coordinator:group-coordinator-api')\n    implementation project(':storage')\n    implementation project(':coordinator-common')\n    implementation libs.jacksonDatabind\n    implementation libs.jacksonJDK8Datatypes\n    implementation libs.metrics\n    implementation libs.hdrHistogram\n    implementation libs.re2j\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation project(':server-common').sourceSets.test.output\n    testImplementation project(':coordinator-common').sourceSets.test.output\n    testImplementation libs.jacksonDatabindYaml\n    testImplementation libs.junitJupiter\n    testImplementation libs.mockitoCore\n\n    testRuntimeOnly runtimeTestLibs\n\n    generator project(':generator')\n  }\n\n  sourceSets {\n    main {\n      java {\n        srcDirs = [\"src/main/java\", \"${projectDir}/build/generated/main/java\"]\n      }\n    }\n    test {\n      java {\n        srcDirs = [\"src/test/java\"]\n      }\n    }\n  }\n\n  javadoc {\n    enabled = false\n  }\n\n  checkstyle {\n    configProperties = checkstyleConfigProperties(\"import-control-group-coordinator.xml\")\n  }\n\n  task processMessages(type:JavaExec) {\n    mainClass = \"org.apache.kafka.message.MessageGenerator\"\n    classpath = configurations.generator\n    args = [ \"-p\", \"org.apache.kafka.coordinator.group.generated\",\n             \"-o\", \"${projectDir}/build/generated/main/java/org/apache/kafka/coordinator/group/generated\",\n             \"-i\", \"src/main/resources/common/message\",\n             \"-m\", \"MessageDataGenerator\", \"JsonConverterGenerator\",\n             \"-t\", \"CoordinatorRecordTypeGenerator\", \"CoordinatorRecordJsonConvertersGenerator\"\n    ]\n    inputs.dir(\"src/main/resources/common/message\")\n        .withPropertyName(\"messages\")\n        .withPathSensitivity(PathSensitivity.RELATIVE)\n    outputs.cacheIf { true }\n    outputs.dir(\"${projectDir}/build/generated/main/java/org/apache/kafka/coordinator/group/generated\")\n  }\n\n  compileJava.dependsOn 'processMessages'\n  srcJar.dependsOn 'processMessages'\n}\n\nproject(':test-common') {\n  // Test framework stuff. Implementations that support test-common-api\n  base {\n    archivesName = \"kafka-test-common\"\n  }\n\n  dependencies {\n    implementation project(':core')\n    implementation project(':metadata')\n    implementation project(':server')\n    implementation project(':raft')\n    implementation project(':storage')\n    implementation project(':server-common')\n    implementation libs.jacksonDatabindYaml\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation libs.junitJupiter\n    testImplementation libs.mockitoCore\n\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  checkstyle {\n    configProperties = checkstyleConfigProperties(\"import-control-test-common.xml\")\n  }\n\n  javadoc {\n    enabled = false\n  }\n}\n\nproject(':test-common:test-common-api') {\n  // Interfaces, config classes, and other test APIs\n  base {\n    archivesName = \"kafka-test-common-api\"\n  }\n\n  dependencies {\n    implementation project(':clients')\n    implementation project(':core')\n    implementation project(':group-coordinator')\n    implementation project(':metadata')\n    implementation project(':raft')\n    implementation project(':server')\n    implementation project(':server-common')\n    implementation project(':storage')\n    implementation project(':test-common')\n    implementation libs.junitJupiterApi\n\n    testImplementation libs.junitJupiter\n    testImplementation libs.mockitoCore\n\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  checkstyle {\n    configProperties = checkstyleConfigProperties(\"import-control-test-common-api.xml\")\n  }\n\n  javadoc {\n    enabled = false\n  }\n}\n\nproject(':test-common:test-common-runtime') {\n  // Runtime-only test code including JUnit extentions\n  base {\n    archivesName = \"kafka-test-common-runtime\"\n  }\n\n  dependencies {\n    implementation libs.junitPlatformLanucher\n    implementation libs.junitJupiterApi\n    implementation libs.junitJupiter\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n  }\n\n  checkstyle {\n    configProperties = checkstyleConfigProperties(\"import-control-test-common-api.xml\")\n  }\n\n  javadoc {\n    enabled = false\n  }\n}\n\nproject(':transaction-coordinator') {\n  base {\n    archivesName = \"kafka-transaction-coordinator\"\n  }\n\n  configurations {\n    generator\n  }\n\n  dependencies {\n    implementation libs.jacksonDatabind\n    implementation project(':clients')\n    implementation project(':server-common')\n    implementation project(':coordinator-common')\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation libs.junitJupiter\n    testImplementation libs.mockitoCore\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation project(':test-common')\n    testImplementation project(':test-common:test-common-api')\n\n    testRuntimeOnly runtimeTestLibs\n\n    generator project(':generator')\n  }\n\n  sourceSets {\n    main {\n      java {\n        srcDirs = [\"src/main/java\", \"${projectDir}/build/generated/main/java\"]\n      }\n    }\n    test {\n      java {\n        srcDirs = [\"src/test/java\"]\n      }\n    }\n  }\n\n  checkstyle {\n    configProperties = checkstyleConfigProperties(\"import-control-transaction-coordinator.xml\")\n  }\n\n  task processMessages(type:JavaExec) {\n    mainClass = \"org.apache.kafka.message.MessageGenerator\"\n    classpath = configurations.generator\n    args = [ \"-p\", \"org.apache.kafka.coordinator.transaction.generated\",\n             \"-o\", \"${projectDir}/build/generated/main/java/org/apache/kafka/coordinator/transaction/generated\",\n             \"-i\", \"src/main/resources/common/message\",\n             \"-m\", \"MessageDataGenerator\", \"JsonConverterGenerator\"\n    ]\n    inputs.dir(\"src/main/resources/common/message\")\n            .withPropertyName(\"messages\")\n            .withPathSensitivity(PathSensitivity.RELATIVE)\n    outputs.cacheIf { true }\n    outputs.dir(\"${projectDir}/build/generated/main/java/org/apache/kafka/coordinator/transaction/generated\")\n  }\n\n  compileJava.dependsOn 'processMessages'\n  srcJar.dependsOn 'processMessages'\n\n  javadoc {\n    enabled = false\n  }\n}\n\nproject(':coordinator-common') {\n  base {\n    archivesName = \"kafka-coordinator-common\"\n  }\n\n  dependencies {\n    implementation project(':clients')\n    implementation project(':server-common')\n    implementation project(':metadata')\n    implementation project(':storage')\n    implementation log4jLibs\n    implementation libs.metrics\n    implementation libs.hdrHistogram\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation project(':server-common').sourceSets.test.output\n    testImplementation libs.junitJupiter\n    testImplementation libs.mockitoCore\n\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  checkstyle {\n    configProperties = checkstyleConfigProperties(\"import-control-coordinator-common.xml\")\n  }\n\n  javadoc {\n    enabled = false\n  }\n}\n\nproject(':share-coordinator') {\n  base {\n    archivesName = \"kafka-share-coordinator\"\n  }\n\n  configurations {\n    generator\n  }\n\n  dependencies {\n    implementation libs.jacksonDatabind\n    implementation project(':clients')\n    implementation project(':coordinator-common')\n    implementation project(':metadata')\n    implementation project(':server')\n    implementation project(':server-common')\n    implementation project(':share')\n    implementation libs.metrics\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation project(':server-common').sourceSets.test.output\n    testImplementation project(':coordinator-common').sourceSets.test.output\n    testImplementation libs.junitJupiter\n    testImplementation libs.mockitoCore\n\n    testRuntimeOnly runtimeTestLibs\n\n    generator project(':generator')\n  }\n\n  sourceSets {\n    main {\n      java {\n        srcDirs = [\"src/main/java\", \"${projectDir}/build/generated/main/java\"]\n      }\n    }\n    test {\n      java {\n        srcDirs = [\"src/test/java\"]\n      }\n    }\n  }\n\n  checkstyle {\n    configProperties = checkstyleConfigProperties(\"import-control-share-coordinator.xml\")\n  }\n\n  task processMessages(type:JavaExec) {\n    mainClass = \"org.apache.kafka.message.MessageGenerator\"\n    classpath = configurations.generator\n    args = [ \"-p\", \"org.apache.kafka.coordinator.share.generated\",\n             \"-o\", \"${projectDir}/build/generated/main/java/org/apache/kafka/coordinator/share/generated\",\n             \"-i\", \"src/main/resources/common/message\",\n             \"-m\", \"MessageDataGenerator\", \"JsonConverterGenerator\",\n             \"-t\", \"CoordinatorRecordTypeGenerator\", \"CoordinatorRecordJsonConvertersGenerator\"\n    ]\n    inputs.dir(\"src/main/resources/common/message\")\n            .withPropertyName(\"messages\")\n            .withPathSensitivity(PathSensitivity.RELATIVE)\n    outputs.cacheIf { true }\n    outputs.dir(\"${projectDir}/build/generated/main/java/org/apache/kafka/coordinator/share/generated\")\n  }\n\n  compileJava.dependsOn 'processMessages'\n  srcJar.dependsOn 'processMessages'\n\n  javadoc {\n    enabled = false\n  }\n}\n\nproject(':examples') {\n  base {\n    archivesName = \"kafka-examples\"\n  }\n\n  dependencies {\n    implementation project(':clients')\n  }\n\n  javadoc {\n    enabled = false\n  }\n\n  checkstyle {\n    configProperties = checkstyleConfigProperties(\"import-control-core.xml\")\n  }\n}\n\nproject(':generator') {\n  dependencies {\n    implementation libs.argparse4j\n    implementation libs.jacksonDatabind\n    implementation libs.jacksonJDK8Datatypes\n    implementation libs.jacksonJakartarsJsonProvider\n\n    implementation 'org.eclipse.jgit:org.eclipse.jgit:6.4.0.202211300538-r'\n    // SSH support for JGit based on Apache MINA sshd\n    implementation 'org.eclipse.jgit:org.eclipse.jgit.ssh.apache:6.4.0.202211300538-r'\n    // GPG support for JGit based on BouncyCastle (commit signing)\n    implementation 'org.eclipse.jgit:org.eclipse.jgit.gpg.bc:6.4.0.202211300538-r'\n\n    testImplementation libs.junitJupiter\n\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  javadoc {\n    enabled = false\n  }\n}\n\nproject(':clients') {\n  base {\n    archivesName = \"kafka-clients\"\n  }\n\n  configurations {\n    generator\n    shadowed\n  }\n\n  dependencies {\n    implementation libs.zstd\n    implementation libs.lz4\n    implementation libs.snappy\n    implementation libs.opentelemetryProto\n    implementation libs.protobuf\n    implementation libs.slf4jApi\n\n    // libraries which should be added as runtime dependencies in generated pom.xml should be defined here:\n    shadowed libs.zstd\n    shadowed libs.lz4\n    shadowed libs.snappy\n    shadowed libs.slf4jApi\n\n    compileOnly libs.jacksonDatabind // for SASL/OAUTHBEARER bearer token parsing\n    compileOnly libs.jacksonJDK8Datatypes\n    compileOnly libs.jose4j          // for SASL/OAUTHBEARER JWT validation; only used by broker\n\n\n    testImplementation libs.bcpkix\n    testImplementation libs.jacksonJakartarsJsonProvider\n    testImplementation libs.jose4j\n    testImplementation libs.junitJupiter\n    testImplementation libs.spotbugs\n    testImplementation libs.mockitoCore\n    testImplementation libs.mockitoJunitJupiter // supports MockitoExtension\n    testImplementation log4jLibs\n\n    testCompileOnly libs.bndlib\n\n    testRuntimeOnly libs.jacksonDatabind\n    testRuntimeOnly libs.jacksonJDK8Datatypes\n    testRuntimeOnly runtimeTestLibs\n    testRuntimeOnly log4jRuntimeLibs\n\n    generator project(':generator')\n  }\n\n  task createVersionFile() {\n    def receiptFile = file(\"${layout.buildDirectory.get().asFile.path}/kafka/$buildVersionFileName\")\n    inputs.property \"commitId\", commitId\n    inputs.property \"version\", version\n    outputs.file receiptFile\n    outputs.cacheIf { true }\n\n    doLast {\n      def data = [\n        commitId: commitId,\n        version: version,\n      ]\n\n      receiptFile.parentFile.mkdirs()\n      def content = data.entrySet().collect { \"$it.key=$it.value\" }.sort().join(\"\\n\")\n      receiptFile.setText(content, \"ISO-8859-1\")\n    }\n  }\n\n  shadowJar {\n    dependsOn createVersionFile\n    // archiveClassifier defines the classifier for the shadow jar, the default is 'all'.\n    // We don't want to use the default classifier because it will cause the shadow jar to\n    // overwrite the original jar. We also don't want to use the 'shadow' classifier because\n    // it will cause the shadow jar to be named kafka-clients-shadow.jar. We want to use the\n    // same name as the original jar, kafka-clients.jar.\n    archiveClassifier = null\n    // KIP-714: move shaded dependencies to a shaded location\n    relocate('io.opentelemetry.proto', 'org.apache.kafka.shaded.io.opentelemetry.proto')\n    relocate('com.google.protobuf', 'org.apache.kafka.shaded.com.google.protobuf')\n\n    // dependencies excluded from the final jar, since they are declared as runtime dependencies\n    dependencies {\n      project.configurations.shadowed.allDependencies.each {\n        exclude(dependency(it.group + ':' + it.name))\n      }\n      // exclude proto files from the jar\n      exclude \"**/opentelemetry/proto/**/*.proto\"\n      exclude \"**/google/protobuf/*.proto\"\n    }\n\n    from(\"${layout.buildDirectory.get().asFile.path}\") {\n      include \"kafka/$buildVersionFileName\"\n    }\n\n    from \"$rootDir/LICENSE\"\n    from \"$rootDir/NOTICE\"\n  }\n\n  jar {\n    enabled false\n    dependsOn 'shadowJar'\n  }\n\n  clean.doFirst {\n    delete \"${layout.buildDirectory.get().asFile.path}/kafka/\"\n  }\n\n  task processMessages(type:JavaExec) {\n    mainClass = \"org.apache.kafka.message.MessageGenerator\"\n    classpath = configurations.generator\n    args = [ \"-p\", \"org.apache.kafka.common.message\",\n             \"-o\", \"${projectDir}/build/generated/main/java/org/apache/kafka/common/message\",\n             \"-i\", \"src/main/resources/common/message\",\n             \"-t\", \"ApiMessageTypeGenerator\",\n             \"-m\", \"MessageDataGenerator\", \"JsonConverterGenerator\"\n           ]\n    inputs.dir(\"src/main/resources/common/message\")\n        .withPropertyName(\"messages\")\n        .withPathSensitivity(PathSensitivity.RELATIVE)\n    outputs.cacheIf { true }\n    outputs.dir(\"${projectDir}/build/generated/main/java/org/apache/kafka/common/message\")\n  }\n\n  task processTestMessages(type:JavaExec) {\n    mainClass = \"org.apache.kafka.message.MessageGenerator\"\n    classpath = configurations.generator\n    args = [ \"-p\", \"org.apache.kafka.common.message\",\n             \"-o\", \"${projectDir}/build/generated/test/java/org/apache/kafka/common/message\",\n             \"-i\", \"src/test/resources/common/message\",\n             \"-m\", \"MessageDataGenerator\", \"JsonConverterGenerator\"\n           ]\n    inputs.dir(\"src/test/resources/common/message\")\n        .withPropertyName(\"testMessages\")\n        .withPathSensitivity(PathSensitivity.RELATIVE)\n    outputs.cacheIf { true }\n    outputs.dir(\"${projectDir}/build/generated/test/java/org/apache/kafka/common/message\")\n  }\n\n  sourceSets {\n    main {\n      java {\n        srcDirs = [\"src/main/java\", \"${projectDir}/build/generated/main/java\"]\n      }\n    }\n    test {\n      java {\n        srcDirs = [\"src/test/java\", \"${projectDir}/build/generated/test/java\"]\n      }\n    }\n  }\n\n  compileJava.dependsOn 'processMessages'\n  srcJar.dependsOn 'processMessages'\n\n  compileTestJava.dependsOn 'processTestMessages'\n\n  javadoc {\n    include \"**/org/apache/kafka/clients/admin/*\"\n    include \"**/org/apache/kafka/clients/consumer/*\"\n    include \"**/org/apache/kafka/clients/producer/*\"\n    include \"**/org/apache/kafka/common/*\"\n    include \"**/org/apache/kafka/common/acl/*\"\n    include \"**/org/apache/kafka/common/annotation/*\"\n    include \"**/org/apache/kafka/common/errors/*\"\n    include \"**/org/apache/kafka/common/header/*\"\n    include \"**/org/apache/kafka/common/metrics/*\"\n    include \"**/org/apache/kafka/common/metrics/stats/*\"\n    include \"**/org/apache/kafka/common/quota/*\"\n    include \"**/org/apache/kafka/common/resource/*\"\n    include \"**/org/apache/kafka/common/serialization/*\"\n    include \"**/org/apache/kafka/common/config/*\"\n    include \"**/org/apache/kafka/common/config/provider/*\"\n    include \"**/org/apache/kafka/common/security/auth/*\"\n    include \"**/org/apache/kafka/common/security/plain/*\"\n    include \"**/org/apache/kafka/common/security/scram/*\"\n    include \"**/org/apache/kafka/common/security/token/delegation/*\"\n    include \"**/org/apache/kafka/common/security/oauthbearer/*\"\n    include \"**/org/apache/kafka/common/security/oauthbearer/secured/*\"\n    include \"**/org/apache/kafka/server/authorizer/*\"\n    include \"**/org/apache/kafka/server/policy/*\"\n    include \"**/org/apache/kafka/server/quota/*\"\n    include \"**/org/apache/kafka/server/telemetry/*\"\n  }\n}\n\nproject(':raft') {\n  base {\n    archivesName = \"kafka-raft\"\n  }\n\n  configurations {\n    generator\n  }\n\n  dependencies {\n    implementation project(':server-common')\n    implementation project(':clients')\n    implementation libs.jacksonDatabind\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation project(':server-common')\n    testImplementation project(':server-common').sourceSets.test.output\n    testImplementation project(':clients')\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation libs.jacksonDatabindYaml\n    testImplementation libs.junitJupiter\n    testImplementation libs.mockitoCore\n    testImplementation libs.jqwik\n\n    testRuntimeOnly runtimeTestLibs\n\n    generator project(':generator')\n  }\n\n  task createVersionFile() {\n    def receiptFile = file(\"${layout.buildDirectory.get().asFile.path}/kafka/$buildVersionFileName\")\n    inputs.property \"commitId\", commitId\n    inputs.property \"version\", version\n    outputs.file receiptFile\n    outputs.cacheIf { true }\n\n    doLast {\n      def data = [\n        commitId: commitId,\n        version: version,\n      ]\n\n      receiptFile.parentFile.mkdirs()\n      def content = data.entrySet().collect { \"$it.key=$it.value\" }.sort().join(\"\\n\")\n      receiptFile.setText(content, \"ISO-8859-1\")\n    }\n  }\n\n  task processMessages(type:JavaExec) {\n    mainClass = \"org.apache.kafka.message.MessageGenerator\"\n    classpath = configurations.generator\n    args = [ \"-p\", \"org.apache.kafka.raft.generated\",\n             \"-o\", \"${projectDir}/build/generated/main/java/org/apache/kafka/raft/generated\",\n             \"-i\", \"src/main/resources/common/message\",\n             \"-m\", \"MessageDataGenerator\", \"JsonConverterGenerator\"]\n    inputs.dir(\"src/main/resources/common/message\")\n        .withPropertyName(\"messages\")\n        .withPathSensitivity(PathSensitivity.RELATIVE)\n    outputs.cacheIf { true }\n    outputs.dir(\"${projectDir}/build/generated/main/java/org/apache/kafka/raft/generated\")\n  }\n\n  sourceSets {\n    main {\n      java {\n        srcDirs = [\"src/main/java\", \"${projectDir}/build/generated/main/java\"]\n      }\n    }\n    test {\n      java {\n        srcDirs = [\"src/test/java\"]\n      }\n    }\n  }\n\n  compileJava.dependsOn 'processMessages'\n  srcJar.dependsOn 'processMessages'\n\n  jar {\n    dependsOn createVersionFile\n    from(\"${layout.buildDirectory.get().asFile.path}\") {\n        include \"kafka/$buildVersionFileName\"\n    }\n  }\n\n  test {\n    useJUnitPlatform {\n      includeEngines 'jqwik', 'junit-jupiter'\n    }\n  }\n\n  clean.doFirst {\n    delete \"${layout.buildDirectory.get().asFile.path}/kafka/\"\n  }\n\n  javadoc {\n    enabled = false\n  }\n}\n\nproject(':server-common') {\n  base {\n    archivesName = \"kafka-server-common\"\n  }\n\n  dependencies {\n    api project(':clients')\n    implementation libs.metrics\n    implementation libs.joptSimple\n    implementation libs.jacksonDatabind\n    implementation libs.pcollections\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation project(':clients')\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation libs.jacksonDatabindYaml\n    testImplementation libs.junitJupiter\n    testImplementation libs.mockitoCore\n\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  task createVersionFile() {\n    def receiptFile = file(\"${layout.buildDirectory.get().asFile.path}/kafka/$buildVersionFileName\")\n    inputs.property \"commitId\", commitId\n    inputs.property \"version\", version\n    outputs.file receiptFile\n    outputs.cacheIf { true }\n\n    doLast {\n      def data = [\n              commitId: commitId,\n              version: version,\n      ]\n\n      receiptFile.parentFile.mkdirs()\n      def content = data.entrySet().collect { \"$it.key=$it.value\" }.sort().join(\"\\n\")\n      receiptFile.setText(content, \"ISO-8859-1\")\n    }\n  }\n\n  jar {\n    dependsOn createVersionFile\n    from(\"${layout.buildDirectory.get().asFile.path}\") {\n      include \"kafka/$buildVersionFileName\"\n    }\n  }\n\n  clean.doFirst {\n    delete \"${layout.buildDirectory.get().asFile.path}/kafka/\"\n  }\n\n  checkstyle {\n    configProperties = checkstyleConfigProperties(\"import-control-server-common.xml\")\n  }\n\n  javadoc {\n    enabled = false\n  }\n}\n\nproject(':storage:storage-api') {\n  base {\n    archivesName = \"kafka-storage-api\"\n  }\n\n  dependencies {\n    implementation project(':clients')\n    implementation project(':server-common')\n    implementation libs.metrics\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation project(':clients')\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation libs.junitJupiter\n    testImplementation libs.mockitoCore\n\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  task createVersionFile() {\n    def receiptFile = file(\"${layout.buildDirectory.get().asFile.path}/kafka/$buildVersionFileName\")\n    inputs.property \"commitId\", commitId\n    inputs.property \"version\", version\n    outputs.file receiptFile\n    outputs.cacheIf { true }\n\n    doLast {\n      def data = [\n              commitId: commitId,\n              version: version,\n      ]\n\n      receiptFile.parentFile.mkdirs()\n      def content = data.entrySet().collect { \"$it.key=$it.value\" }.sort().join(\"\\n\")\n      receiptFile.setText(content, \"ISO-8859-1\")\n    }\n  }\n\n  jar {\n    dependsOn createVersionFile\n    from(\"${layout.buildDirectory.get().asFile.path}\") {\n      include \"kafka/$buildVersionFileName\"\n    }\n  }\n\n  clean.doFirst {\n    delete \"${layout.buildDirectory.get().asFile.path}/kafka/\"\n  }\n\n  javadoc {\n    include \"**/org/apache/kafka/server/log/remote/storage/*\"\n  }\n\n  checkstyle {\n    configProperties = checkstyleConfigProperties(\"import-control-storage.xml\")\n  }\n}\n\nproject(':storage') {\n  base {\n    archivesName = \"kafka-storage\"\n  }\n\n  configurations {\n    generator\n  }\n\n  dependencies {\n    implementation project(':storage:storage-api')\n    implementation project(':server-common')\n    implementation project(':clients')\n    implementation(libs.caffeine) {\n      exclude group: 'org.checkerframework', module: 'checker-qual'\n    }\n    implementation log4jLibs\n    implementation libs.jacksonDatabind\n    implementation libs.metrics\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation project(':clients')\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation project(':core')\n    testImplementation project(':core').sourceSets.test.output\n    testImplementation project(':test-common:test-common-api')\n    testImplementation project(':server')\n    testImplementation project(':server-common')\n    testImplementation project(':server-common').sourceSets.test.output\n    testImplementation libs.hamcrest\n    testImplementation libs.jacksonDatabindYaml\n    testImplementation libs.junitJupiter\n    testImplementation libs.mockitoCore\n    testImplementation libs.bcpkix\n\n    testRuntimeOnly runtimeTestLibs\n\n    generator project(':generator')\n  }\n\n  task createVersionFile() {\n    def receiptFile = file(\"${layout.buildDirectory.get().asFile.path}/kafka/$buildVersionFileName\")\n    inputs.property \"commitId\", commitId\n    inputs.property \"version\", version\n    outputs.file receiptFile\n    outputs.cacheIf { true }\n\n    doLast {\n      def data = [\n              commitId: commitId,\n              version: version,\n      ]\n\n      receiptFile.parentFile.mkdirs()\n      def content = data.entrySet().collect { \"$it.key=$it.value\" }.sort().join(\"\\n\")\n      receiptFile.setText(content, \"ISO-8859-1\")\n    }\n  }\n\n  task processMessages(type:JavaExec) {\n    mainClass = \"org.apache.kafka.message.MessageGenerator\"\n    classpath = configurations.generator\n    args = [ \"-p\", \"org.apache.kafka.server.log.remote.metadata.storage.generated\",\n             \"-o\", \"${projectDir}/build/generated/main/java/org/apache/kafka/server/log/remote/metadata/storage/generated\",\n             \"-i\", \"src/main/resources/message\",\n             \"-m\", \"MessageDataGenerator\", \"JsonConverterGenerator\",\n             \"-t\", \"MetadataRecordTypeGenerator\", \"MetadataJsonConvertersGenerator\" ]\n    inputs.dir(\"src/main/resources/message\")\n        .withPropertyName(\"messages\")\n        .withPathSensitivity(PathSensitivity.RELATIVE)\n    outputs.cacheIf { true }\n    outputs.dir(\"${projectDir}/build/generated/main/java/org/apache/kafka/server/log/remote/metadata/storage/generated\")\n  }\n\n  task genRemoteLogManagerConfigDoc(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"remote_log_manager_config.html\").newOutputStream()\n  }\n\n  task genRemoteLogMetadataManagerConfigDoc(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManagerConfig'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"remote_log_metadata_manager_config.html\").newOutputStream()\n  }\n\n  sourceSets {\n    main {\n      java {\n        srcDirs = [\"src/main/java\", \"${projectDir}/build/generated/main/java\"]\n      }\n    }\n    test {\n      java {\n        srcDirs = [\"src/test/java\"]\n      }\n    }\n  }\n\n  compileJava.dependsOn 'processMessages'\n  srcJar.dependsOn 'processMessages'\n\n  jar {\n    dependsOn createVersionFile\n    from(\"${layout.buildDirectory.get().asFile.path}\") {\n      include \"kafka/$buildVersionFileName\"\n    }\n  }\n\n  clean.doFirst {\n    delete \"${layout.buildDirectory.get().asFile.path}/kafka/\"\n  }\n\n  javadoc {\n    enabled = false\n  }\n\n  checkstyle {\n    configProperties = checkstyleConfigProperties(\"import-control-storage.xml\")\n  }\n}\n\nproject(':tools:tools-api') {\n  base {\n    archivesName = \"kafka-tools-api\"\n  }\n\n  dependencies {\n    implementation project(':clients')\n    testImplementation libs.junitJupiter\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  task createVersionFile() {\n    def receiptFile = file(\"${layout.buildDirectory.get().asFile.path}/kafka/$buildVersionFileName\")\n    inputs.property \"commitId\", commitId\n    inputs.property \"version\", version\n    outputs.file receiptFile\n    outputs.cacheIf { true }\n\n    doLast {\n      def data = [\n              commitId: commitId,\n              version: version,\n      ]\n\n      receiptFile.parentFile.mkdirs()\n      def content = data.entrySet().collect { \"$it.key=$it.value\" }.sort().join(\"\\n\")\n      receiptFile.setText(content, \"ISO-8859-1\")\n    }\n  }\n\n  jar {\n    dependsOn createVersionFile\n    from(\"${layout.buildDirectory.get().asFile.path}\") {\n      include \"kafka/$buildVersionFileName\"\n    }\n  }\n\n  clean.doFirst {\n    delete \"${layout.buildDirectory.get().asFile.path}/kafka/\"\n  }\n\n  javadoc {\n    include \"**/org/apache/kafka/tools/api/*\"\n  }\n}\n\nproject(':tools') {\n  base {\n    archivesName = \"kafka-tools\"\n  }\n\n  dependencies {\n    implementation project(':clients')\n    implementation project(':metadata')\n    implementation project(':storage')\n    implementation project(':server')\n    implementation project(':server-common')\n    implementation project(':connect:runtime')\n    implementation project(':tools:tools-api')\n    implementation project(':transaction-coordinator')\n    implementation project(':group-coordinator')\n    implementation project(':coordinator-common')\n    implementation project(':share-coordinator')\n    implementation project(':share')\n    implementation libs.argparse4j\n    implementation libs.jacksonDatabind\n    implementation libs.jacksonDataformatCsv\n    implementation libs.jacksonJDK8Datatypes\n    implementation libs.joptSimple\n    implementation log4jLibs\n    implementation libs.re2j\n\n    implementation libs.jose4j                    // for SASL/OAUTHBEARER JWT validation\n    implementation libs.jacksonJakartarsJsonProvider\n\n    runtimeOnly log4jRuntimeLibs\n\n    compileOnly libs.spotbugs\n\n    testImplementation project(':clients')\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation project(':server')\n    testImplementation project(':server').sourceSets.test.output\n    testImplementation project(':core')\n    testImplementation project(':core').sourceSets.test.output\n    testImplementation project(':test-common:test-common-api')\n    testImplementation project(':server-common')\n    testImplementation project(':server-common').sourceSets.test.output\n    testImplementation project(':connect:api')\n    testImplementation project(':connect:runtime')\n    testImplementation project(':connect:runtime').sourceSets.test.output\n    testImplementation project(':storage:storage-api').sourceSets.main.output\n    testImplementation project(':storage').sourceSets.test.output\n    testImplementation project(':streams')\n    testImplementation project(':streams').sourceSets.test.output\n    testImplementation project(':streams:integration-tests').sourceSets.test.output\n    testImplementation project(':test-common')\n    testImplementation libs.junitJupiter\n    testImplementation libs.mockitoCore\n    testImplementation libs.mockitoJunitJupiter // supports MockitoExtension\n    testImplementation libs.bcpkix // required by the clients test module, but we have to specify it explicitly as gradle does not include the transitive test dependency automatically\n    testImplementation(libs.jfreechart) {\n      exclude group: 'junit', module: 'junit'\n    }\n    testImplementation libs.apachedsCoreApi\n    testImplementation libs.apachedsInterceptorKerberos\n    testImplementation libs.apachedsProtocolShared\n    testImplementation libs.apachedsProtocolKerberos\n    testImplementation libs.apachedsProtocolLdap\n    testImplementation libs.apachedsLdifPartition\n\n    testRuntimeOnly runtimeTestLibs\n    testRuntimeOnly libs.hamcrest\n  }\n\n  javadoc {\n    enabled = false\n  }\n\n  tasks.create(name: \"copyDependantLibs\", type: Copy) {\n    from (configurations.runtimeClasspath) {\n      exclude('kafka-clients*')\n    }\n    into \"${layout.buildDirectory.get().asFile.path}/dependant-libs-${versions.scala}\"\n    duplicatesStrategy 'exclude'\n  }\n\n  jar {\n    dependsOn 'copyDependantLibs'\n  }\n}\n\nproject(':trogdor') {\n  base {\n    archivesName = \"trogdor\"\n  }\n\n  dependencies {\n    implementation project(':clients')\n    implementation libs.argparse4j\n    implementation libs.jacksonDatabind\n    implementation libs.jacksonJDK8Datatypes\n    implementation log4jLibs\n\n    implementation libs.jacksonJakartarsJsonProvider\n    implementation libs.jerseyContainerServlet\n    implementation libs.jerseyHk2\n    implementation libs.jaxbApi // Jersey dependency that was available in the JDK before Java 9\n    implementation libs.activation // Jersey dependency that was available in the JDK before Java 9\n    implementation (libs.jettyServer) {\n      exclude group: 'org.slf4j', module: 'slf4j-api'\n    }\n    implementation (libs.jettyServlet) {\n      exclude group: 'org.slf4j', module: 'slf4j-api'\n    }\n    implementation (libs.jettyServlets) {\n      exclude group: 'org.slf4j', module: 'slf4j-api'\n    }\n\n    implementation project(':group-coordinator')\n    implementation project(':group-coordinator:group-coordinator-api')\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation project(':clients')\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation project(':group-coordinator')\n    testImplementation libs.junitJupiter\n    testImplementation libs.mockitoCore\n\n    testRuntimeOnly runtimeTestLibs\n    testRuntimeOnly libs.junitPlatformLanucher\n  }\n\n  javadoc {\n    enabled = false\n  }\n\n  tasks.create(name: \"copyDependantLibs\", type: Copy) {\n    from (configurations.runtimeClasspath) {\n      exclude('kafka-clients*')\n    }\n    into \"${layout.buildDirectory.get().asFile.path}/dependant-libs-${versions.scala}\"\n    duplicatesStrategy 'exclude'\n  }\n\n  jar {\n    dependsOn 'copyDependantLibs'\n  }\n}\n\nproject(':shell') {\n  base {\n    archivesName = \"kafka-shell\"\n  }\n\n  dependencies {\n    implementation libs.argparse4j\n    implementation libs.jacksonDatabind\n    implementation libs.jacksonJDK8Datatypes\n    implementation libs.jline\n    implementation log4jLibs\n    implementation project(':server-common')\n    implementation project(':clients')\n    implementation project(':core')\n    implementation project(':metadata')\n    implementation project(':raft')\n\n    implementation libs.jose4j                    // for SASL/OAUTHBEARER JWT validation\n    implementation libs.jacksonJakartarsJsonProvider\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation project(':clients')\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation project(':core')\n    testImplementation project(':server-common')\n    testImplementation project(':server-common').sourceSets.test.output\n    testImplementation libs.jacksonDatabindYaml\n    testImplementation libs.junitJupiter\n\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  javadoc {\n    enabled = false\n  }\n\n  tasks.create(name: \"copyDependantLibs\", type: Copy) {\n    from (configurations.runtimeClasspath) {\n      include('jline-*jar')\n    }\n    into \"${layout.buildDirectory.get().asFile.path}/dependant-libs-${versions.scala}\"\n    duplicatesStrategy 'exclude'\n  }\n\n  jar {\n    dependsOn 'copyDependantLibs'\n  }\n}\n\nproject(':streams') {\n  base {\n    archivesName = \"kafka-streams\"\n  }\n\n  ext.buildStreamsVersionFileName = \"kafka-streams-version.properties\"\n\n  configurations {\n    generator\n  }\n\n  dependencies {\n    api project(path: ':clients', configuration: 'shadow')\n    // `org.rocksdb.Options` is part of Kafka Streams public api via `RocksDBConfigSetter`\n    api libs.rocksDBJni\n\n    implementation libs.jacksonAnnotations\n    implementation libs.jacksonDatabind\n    implementation libs.slf4jApi\n\n    // testCompileOnly prevents streams from exporting a dependency on test-utils, which would cause a dependency cycle\n    testCompileOnly project(':streams:test-utils')\n    testCompileOnly libs.bndlib\n\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation libs.jacksonDatabindYaml\n    testImplementation libs.junitJupiter\n    testImplementation libs.bcpkix\n    testImplementation libs.hamcrest\n    testImplementation libs.mockitoCore\n    testImplementation libs.mockitoJunitJupiter // supports MockitoExtension\n    testImplementation libs.junitPlatformSuiteEngine // supports suite test\n    testImplementation log4jLibs\n\n    testRuntimeOnly project(':streams:test-utils')\n    testRuntimeOnly runtimeTestLibs\n    testRuntimeOnly log4jRuntimeLibs\n\n    generator project(':generator')\n  }\n\n  task processMessages(type:JavaExec) {\n    mainClass = \"org.apache.kafka.message.MessageGenerator\"\n    classpath = configurations.generator\n    args = [ \"-p\", \"org.apache.kafka.streams.internals.generated\",\n             \"-o\", \"${projectDir}/build/generated/main/java/org/apache/kafka/streams/internals/generated\",\n             \"-i\", \"src/main/resources/common/message\",\n             \"-m\", \"MessageDataGenerator\"\n           ]\n    inputs.dir(\"src/main/resources/common/message\")\n        .withPropertyName(\"messages\")\n        .withPathSensitivity(PathSensitivity.RELATIVE)\n    outputs.cacheIf { true }\n    outputs.dir(\"${projectDir}/build/generated/main/java/org/apache/kafka/streams/internals/generated\")\n  }\n\n  sourceSets {\n    main {\n      java {\n        srcDirs = [\"src/main/java\", \"${projectDir}/build/generated/main/java\"]\n      }\n    }\n    test {\n      java {\n        srcDirs = [\"src/test/java\"]\n      }\n    }\n  }\n\n  compileJava.dependsOn 'processMessages'\n  srcJar.dependsOn 'processMessages'\n\n  javadoc {\n    include \"**/org/apache/kafka/streams/**\"\n    exclude \"**/org/apache/kafka/streams/internals/**\", \"**/org/apache/kafka/streams/**/internals/**\"\n  }\n\n  tasks.create(name: \"copyDependantLibs\", type: Copy) {\n    from (configurations.runtimeClasspath) {\n      exclude('kafka-clients*')\n    }\n    into \"${layout.buildDirectory.get().asFile.path}/dependant-libs-${versions.scala}\"\n    duplicatesStrategy 'exclude'\n  }\n\n  task createStreamsVersionFile() {\n    def receiptFile = file(\"${layout.buildDirectory.get().asFile.path}/kafka/$buildStreamsVersionFileName\")\n    inputs.property \"commitId\", commitId\n    inputs.property \"version\", version\n    outputs.file receiptFile\n\n    doLast {\n      def data = [\n              commitId: commitId,\n              version: version,\n      ]\n\n      receiptFile.parentFile.mkdirs()\n      def content = data.entrySet().collect { \"$it.key=$it.value\" }.sort().join(\"\\n\")\n      receiptFile.setText(content, \"ISO-8859-1\")\n    }\n  }\n\n  jar {\n    dependsOn 'createStreamsVersionFile'\n    from(\"${layout.buildDirectory.get().asFile.path}\") {\n      include \"kafka/$buildStreamsVersionFileName\"\n    }\n    dependsOn 'copyDependantLibs'\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n\n  task genStreamsConfigDocs(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.streams.StreamsConfig'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"streams_config.html\").newOutputStream()\n  }\n\n  task testAll(\n    dependsOn: [\n            ':streams:test',\n            ':streams:integration-tests:test',\n            ':streams:test-utils:test',\n            ':streams:streams-scala:test',\n            ':streams:upgrade-system-tests-0110:test',\n            ':streams:upgrade-system-tests-10:test',\n            ':streams:upgrade-system-tests-11:test',\n            ':streams:upgrade-system-tests-20:test',\n            ':streams:upgrade-system-tests-21:test',\n            ':streams:upgrade-system-tests-22:test',\n            ':streams:upgrade-system-tests-23:test',\n            ':streams:upgrade-system-tests-24:test',\n            ':streams:upgrade-system-tests-25:test',\n            ':streams:upgrade-system-tests-26:test',\n            ':streams:upgrade-system-tests-27:test',\n            ':streams:upgrade-system-tests-28:test',\n            ':streams:upgrade-system-tests-30:test',\n            ':streams:upgrade-system-tests-31:test',\n            ':streams:upgrade-system-tests-32:test',\n            ':streams:upgrade-system-tests-33:test',\n            ':streams:upgrade-system-tests-34:test',\n            ':streams:upgrade-system-tests-35:test',\n            ':streams:upgrade-system-tests-36:test',\n            ':streams:upgrade-system-tests-37:test',\n            ':streams:upgrade-system-tests-38:test',\n            ':streams:upgrade-system-tests-39:test',\n            ':streams:examples:test'\n    ]\n  )\n}\n\nproject(':streams:streams-scala') {\n  apply plugin: 'scala'\n\n  base {\n    archivesName = \"kafka-streams-scala_${versions.baseScala}\"\n  }\n\n  dependencies {\n    api project(':streams')\n\n    api libs.scalaLibrary\n    testImplementation project(':streams').sourceSets.test.output\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation project(':streams:test-utils')\n\n    testImplementation libs.jacksonDatabindYaml\n    testImplementation libs.junitJupiter\n    testImplementation libs.mockitoJunitJupiter // supports MockitoExtension\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  javadoc {\n    include \"**/org/apache/kafka/streams/scala/**\"\n  }\n\n  scaladoc {\n    scalaDocOptions.additionalParameters = [\"-no-link-warnings\"]\n  }\n\n  tasks.create(name: \"copyDependantLibs\", type: Copy) {\n    from (configurations.runtimeClasspath) {\n      exclude('kafka-streams*')\n    }\n    into \"${layout.buildDirectory.get().asFile.path}/dependant-libs-${versions.scala}\"\n    duplicatesStrategy 'exclude'\n  }\n\n  jar {\n    dependsOn 'copyDependantLibs'\n  }\n\n  apply plugin: 'com.diffplug.spotless'\n  spotless {\n    scala {\n      target '**/*.scala'\n      scalafmt(\"$versions.scalafmt\").configFile('../../checkstyle/.scalafmt.conf').scalaMajorVersion(versions.baseScala)\n      licenseHeaderFile '../../checkstyle/java.header', 'package'\n    }\n  }\n}\n\nproject(':streams:integration-tests') {\n  apply plugin: 'scala'\n\n  base {\n    archivesName = \"kafka-streams-integration-tests\"\n  }\n\n  dependencies {\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation project(':group-coordinator')\n    testImplementation project(':server')\n    testImplementation project(':server-common')\n    testImplementation project(':server-common').sourceSets.test.output\n    testImplementation project(':storage')\n    testImplementation project(':streams').sourceSets.test.output\n    testImplementation project(':streams:streams-scala')\n    testImplementation project(':test-common')\n    testImplementation project(':tools')\n    testImplementation project(':transaction-coordinator')\n    testImplementation libs.bcpkix\n    testImplementation libs.hamcrest\n    testImplementation libs.junitJupiter\n    testImplementation libs.junitPlatformSuiteEngine // supports suite test\n    testImplementation libs.mockitoCore\n    testImplementation project(':streams:test-utils')\n\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  sourceSets {\n    // Set java/scala source folders in the `scala` block to enable joint compilation\n    main {\n      java {\n        srcDirs = []\n      }\n      scala {\n        srcDirs = []\n      }\n    }\n    test {\n      java {\n        srcDirs = []\n      }\n      scala {\n        srcDirs = [\"src/test/java\", \"src/test/scala\"]\n      }\n    }\n  }\n}\n\nproject(':streams:test-utils') {\n  base {\n    archivesName = \"kafka-streams-test-utils\"\n  }\n\n  dependencies {\n    api project(':streams')\n    api project(':clients')\n\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation libs.jacksonDatabindYaml\n    testImplementation libs.junitJupiter\n    testImplementation libs.mockitoCore\n    testImplementation libs.hamcrest\n\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  tasks.create(name: \"copyDependantLibs\", type: Copy) {\n    from (configurations.runtimeClasspath) {\n      exclude('kafka-streams*')\n    }\n    into \"${layout.buildDirectory.get().asFile.path}/dependant-libs-${versions.scala}\"\n    duplicatesStrategy 'exclude'\n  }\n\n  jar {\n    dependsOn 'copyDependantLibs'\n  }\n\n}\n\nproject(':streams:examples') {\n  base {\n    archivesName = \"kafka-streams-examples\"\n  }\n\n  dependencies {\n    // this dependency should be removed after we unify data API\n    implementation(project(':connect:json'))\n    implementation project(':streams')\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation project(':streams:test-utils')\n    testImplementation project(':clients').sourceSets.test.output // for org.apache.kafka.test.IntegrationTest\n    testImplementation libs.junitJupiter\n    testImplementation libs.hamcrest\n\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  javadoc {\n    enabled = false\n  }\n\n  tasks.create(name: \"copyDependantLibs\", type: Copy) {\n    from (configurations.runtimeClasspath) {\n      exclude('kafka-streams*')\n    }\n    into \"${layout.buildDirectory.get().asFile.path}/dependant-libs-${versions.scala}\"\n    duplicatesStrategy 'exclude'\n  }\n\n  jar {\n    dependsOn 'copyDependantLibs'\n  }\n}\n\nproject(':streams:upgrade-system-tests-0110') {\n  base{\n    archivesName = \"kafka-streams-upgrade-system-tests-0110\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_0110\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-10') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-10\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_10\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-11') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-11\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_11\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-20') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-20\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_20\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-21') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-21\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_21\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-22') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-22\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_22\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-23') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-23\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_23\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-24') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-24\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_24\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-25') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-25\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_25\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-26') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-26\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_26\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-27') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-27\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_27\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-28') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-28\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_28\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-30') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-30\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_30\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-31') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-31\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_31\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-32') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-32\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_32\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-33') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-33\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_33\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-34') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-34\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_34\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-35') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-35\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_35\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-36') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-36\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_36\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-37') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-37\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_37\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-38') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-38\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_38\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':streams:upgrade-system-tests-39') {\n  base {\n    archivesName = \"kafka-streams-upgrade-system-tests-39\"\n  }\n\n  dependencies {\n    testImplementation libs.kafkaStreams_39\n    testRuntimeOnly libs.junitJupiter\n  }\n\n  systemTestLibs {\n    dependsOn testJar\n  }\n}\n\nproject(':jmh-benchmarks') {\n\n  apply plugin: 'io.github.goooler.shadow'\n\n  shadowJar {\n    archiveBaseName = 'kafka-jmh-benchmarks'\n  }\n\n  dependencies {\n    implementation(project(':core')) {\n      // jmh requires jopt 4.x while `core` depends on 5.0, they are not binary compatible\n      exclude group: 'net.sf.jopt-simple', module: 'jopt-simple'\n    }\n    implementation project(':server-common')\n    implementation project(':server')\n    implementation project(':raft')\n    implementation project(':clients')\n    implementation project(':coordinator-common')\n    implementation project(':group-coordinator')\n    implementation project(':group-coordinator:group-coordinator-api')\n    implementation project(':metadata')\n    implementation project(':storage')\n    implementation project(':streams')\n    implementation project(':transaction-coordinator')\n    implementation project(':core')\n    implementation project(':connect:api')\n    implementation project(':connect:transforms')\n    implementation project(':connect:json')\n    implementation project(':clients').sourceSets.test.output\n    implementation project(':core').sourceSets.test.output\n    implementation project(':server-common').sourceSets.test.output\n\n    implementation libs.jmhCore\n    annotationProcessor libs.jmhGeneratorAnnProcess\n    implementation libs.jmhCoreBenchmarks\n    implementation libs.jacksonDatabind\n    implementation libs.metrics\n    implementation libs.mockitoCore\n    implementation libs.scalaLibrary\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n  }\n\n  tasks.withType(JavaCompile) {\n    // Suppress warning caused by code generated by jmh: `warning: [cast] redundant cast to long`\n    options.compilerArgs << \"-Xlint:-cast\"\n  }\n\n  jar {\n    manifest {\n      attributes \"Main-Class\": \"org.openjdk.jmh.Main\"\n    }\n  }\n\n  checkstyle {\n    configProperties = checkstyleConfigProperties(\"import-control-jmh-benchmarks.xml\")\n  }\n\n  task jmh(type: JavaExec, dependsOn: [':jmh-benchmarks:clean', ':jmh-benchmarks:shadowJar']) {\n\n    mainClass = \"-jar\"\n\n    doFirst {\n      if (System.getProperty(\"jmhArgs\")) {\n          args System.getProperty(\"jmhArgs\").split(' ')\n      }\n      args = [shadowJar.archivePath, *args]\n    }\n  }\n\n  javadoc {\n     enabled = false\n  }\n}\n\nproject(':connect:api') {\n  base {\n    archivesName = \"connect-api\"\n  }\n\n  dependencies {\n    api project(':clients')\n    implementation libs.jakartaRsApi\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation libs.junitJupiter\n    testImplementation project(':clients').sourceSets.test.output\n\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  javadoc {\n    include \"**/org/apache/kafka/connect/**\" // needed for the `aggregatedJavadoc` task\n  }\n\n  tasks.create(name: \"copyDependantLibs\", type: Copy) {\n    from (configurations.runtimeClasspath) {\n      exclude('kafka-clients*')\n      exclude('connect-*')\n    }\n    into \"${layout.buildDirectory.get().asFile.path}/dependant-libs\"\n    duplicatesStrategy 'exclude'\n  }\n\n  jar {\n    dependsOn copyDependantLibs\n  }\n}\n\nproject(':connect:transforms') {\n  base {\n    archivesName = \"connect-transforms\"\n  }\n\n  dependencies {\n    api project(':connect:api')\n\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation libs.junitJupiter\n    testImplementation project(':clients').sourceSets.test.output\n\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  javadoc {\n    enabled = false\n  }\n\n  tasks.create(name: \"copyDependantLibs\", type: Copy) {\n    from (configurations.runtimeClasspath) {\n      exclude('kafka-clients*')\n      exclude('connect-*')\n    }\n    into \"${layout.buildDirectory.get().asFile.path}/dependant-libs\"\n    duplicatesStrategy 'exclude'\n  }\n\n  jar {\n    dependsOn copyDependantLibs\n  }\n}\n\nproject(':connect:json') {\n  base {\n    archivesName = \"connect-json\"\n  }\n\n  dependencies {\n    api project(':connect:api')\n\n    api libs.jacksonDatabind\n    api libs.jacksonJDK8Datatypes\n    api libs.jacksonBlackbird\n\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation libs.junitJupiter\n\n    testImplementation project(':clients').sourceSets.test.output\n\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  javadoc {\n    enabled = false\n  }\n\n  tasks.create(name: \"copyDependantLibs\", type: Copy) {\n    from (configurations.runtimeClasspath) {\n      exclude('kafka-clients*')\n      exclude('connect-*')\n    }\n    into \"${layout.buildDirectory.get().asFile.path}/dependant-libs\"\n    duplicatesStrategy 'exclude'\n  }\n\n  jar {\n    dependsOn copyDependantLibs\n  }\n}\n\nproject(':connect:runtime') {\n  configurations {\n    swagger\n  }\n\n  base {\n    archivesName = \"connect-runtime\"\n  }\n\n  dependencies {\n    // connect-runtime is used in tests, use `api` for modules below for backwards compatibility even though\n    // applications should generally not depend on `connect-runtime`\n    api project(':connect:api')\n    api project(':clients')\n    api project(':connect:json')\n    api project(':connect:transforms')\n\n    implementation log4jLibs\n    implementation libs.jose4j                    // for SASL/OAUTHBEARER JWT validation\n    implementation libs.jacksonAnnotations\n    implementation libs.jacksonJakartarsJsonProvider\n    implementation libs.jerseyContainerServlet\n    implementation libs.jerseyHk2\n    implementation libs.jaxbApi // Jersey dependency that was available in the JDK before Java 9\n    implementation libs.activation // Jersey dependency that was available in the JDK before Java 9\n    implementation (libs.jettyServer) {\n      exclude group: 'org.slf4j', module: 'slf4j-api'\n    }\n    implementation (libs.jettyServlet) {\n      exclude group: 'org.slf4j', module: 'slf4j-api'\n    }\n    implementation (libs.jettyServlets) {\n      exclude group: 'org.slf4j', module: 'slf4j-api'\n    }\n    implementation (libs.jettyClient) {\n      exclude group: 'org.slf4j', module: 'slf4j-api'\n    }\n    implementation libs.classgraph\n    implementation libs.mavenArtifact\n    implementation libs.swaggerAnnotations\n\n    compileOnly libs.bndlib\n    compileOnly libs.spotbugs\n\n    runtimeOnly log4jRuntimeLibs\n\n    // We use this library to generate OpenAPI docs for the REST API, but we don't want or need it at compile\n    // or run time. So, we add it to a separate configuration, which we use later on during docs generation\n    swagger libs.jakartaServletApi\n    swagger libs.jaxrs2Jakarta\n\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation project(':core')\n    testImplementation project(':server')\n    testImplementation project(':metadata')\n    testImplementation project(':server-common')\n    testImplementation project(':test-common')\n    testImplementation project(':server-common')\n    testImplementation project(':server')\n    testImplementation project(':group-coordinator')\n    testImplementation project(':storage')\n    testImplementation project(':connect:test-plugins')\n    testImplementation project(':server-common').sourceSets.test.output\n    testImplementation project(':test-common:test-common-api')\n\n    testImplementation libs.jacksonDatabindYaml\n    testImplementation libs.junitJupiter\n    testImplementation libs.mockitoCore\n    testImplementation libs.mockitoJunitJupiter\n    testImplementation libs.httpclient\n\n    testCompileOnly libs.bndlib\n\n    testRuntimeOnly libs.bcpkix\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  javadoc {\n    enabled = false\n  }\n\n  tasks.create(name: \"copyDependantLibs\", type: Copy) {\n    from (configurations.runtimeClasspath) {\n      exclude('kafka-clients*')\n      exclude('connect-*')\n    }\n    into \"${layout.buildDirectory.get().asFile.path}/dependant-libs\"\n    duplicatesStrategy 'exclude'\n  }\n\n  jar {\n    dependsOn copyDependantLibs\n  }\n\n  task genConnectConfigDocs(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.connect.runtime.distributed.DistributedConfig'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"connect_config.html\").newOutputStream()\n  }\n\n  task genSinkConnectorConfigDocs(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.connect.runtime.SinkConnectorConfig'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"sink_connector_config.html\").newOutputStream()\n  }\n\n  task genSourceConnectorConfigDocs(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.connect.runtime.SourceConnectorConfig'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"source_connector_config.html\").newOutputStream()\n  }\n\n  task genConnectTransformationDocs(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.connect.tools.TransformationDoc'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"connect_transforms.html\").newOutputStream()\n  }\n\n  task genConnectPredicateDocs(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.connect.tools.PredicateDoc'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"connect_predicates.html\").newOutputStream()\n  }\n\n  task genConnectMetricsDocs(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.connect.runtime.ConnectMetrics'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"connect_metrics.html\").newOutputStream()\n  }\n\n  task setVersionInOpenAPISpec(type: Copy) {\n    from \"$rootDir/gradle/openapi.template\"\n    into \"${layout.buildDirectory.get().asFile.path}/resources/docs\"\n    rename ('openapi.template', 'openapi.yaml')\n    expand(kafkaVersion: \"$rootProject.version\")\n  }\n\n  task genConnectOpenAPIDocs(type: io.swagger.v3.plugins.gradle.tasks.ResolveTask, dependsOn: setVersionInOpenAPISpec) {\n    classpath = sourceSets.main.runtimeClasspath\n\n    buildClasspath = classpath + configurations.swagger\n    outputFileName = 'connect_rest'\n    outputFormat = 'YAML'\n    prettyPrint = 'TRUE'\n    sortOutput = 'TRUE'\n    openApiFile = file(\"${layout.buildDirectory.get().asFile.path}/resources/docs/openapi.yaml\")\n    resourcePackages = ['org.apache.kafka.connect.runtime.rest.resources']\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    outputDir = file(generatedDocsDir)\n  }\n\n}\n\nproject(':connect:file') {\n  base {\n    archivesName = \"connect-file\"\n  }\n\n  dependencies {\n    implementation project(':connect:api')\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation libs.junitJupiter\n    testImplementation libs.mockitoCore\n\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation project(':connect:runtime')\n    testImplementation project(':connect:runtime').sourceSets.test.output\n    testImplementation project(':core')\n    testImplementation project(':test-common')\n    testImplementation project(':server-common').sourceSets.test.output\n\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  javadoc {\n    enabled = false\n  }\n\n  tasks.create(name: \"copyDependantLibs\", type: Copy) {\n    from (configurations.runtimeClasspath) {\n      exclude('kafka-clients*')\n      exclude('connect-*')\n    }\n    into \"${layout.buildDirectory.get().asFile.path}/dependant-libs\"\n    duplicatesStrategy 'exclude'\n  }\n\n  jar {\n    dependsOn copyDependantLibs\n  }\n}\n\nproject(':connect:basic-auth-extension') {\n  base {\n    archivesName = \"connect-basic-auth-extension\"\n  }\n\n  dependencies {\n    implementation project(':connect:api')\n\n    implementation log4jLibs\n    implementation libs.jakartaRsApi\n    implementation libs.jaxAnnotationApi\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation libs.bcpkix\n    testImplementation libs.mockitoCore\n    testImplementation libs.junitJupiter\n    testImplementation project(':clients').sourceSets.test.output\n\n    testRuntimeOnly libs.jerseyContainerServlet\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  javadoc {\n    enabled = false\n  }\n\n  tasks.create(name: \"copyDependantLibs\", type: Copy) {\n    from (configurations.runtimeClasspath) {\n      exclude('kafka-clients*')\n      exclude('connect-*')\n    }\n    into \"${layout.buildDirectory.get().asFile.path}/dependant-libs\"\n    duplicatesStrategy 'exclude'\n  }\n\n  jar {\n    dependsOn copyDependantLibs\n  }\n}\n\nproject(':connect:mirror') {\n  base {\n    archivesName = \"connect-mirror\"\n  }\n\n  dependencies {\n    implementation project(':connect:api')\n    implementation project(':connect:runtime')\n    implementation project(':connect:mirror-client')\n    implementation project(':clients')\n\n    implementation libs.argparse4j\n    implementation log4jLibs\n    implementation libs.jacksonAnnotations\n    implementation libs.jacksonJakartarsJsonProvider\n    implementation libs.jerseyContainerServlet\n    implementation libs.jerseyHk2\n    implementation libs.jaxbApi // Jersey dependency that was available in the JDK before Java 9\n    implementation libs.activation // Jersey dependency that was available in the JDK before Java 9\n    implementation (libs.jettyServer) {\n      exclude group: 'org.slf4j', module: 'slf4j-api'\n    }\n    implementation (libs.jettyServlet) {\n      exclude group: 'org.slf4j', module: 'slf4j-api'\n    }\n    implementation (libs.jettyServlets) {\n      exclude group: 'org.slf4j', module: 'slf4j-api'\n    }\n    implementation (libs.jettyClient) {\n      exclude group: 'org.slf4j', module: 'slf4j-api'\n    }\n    implementation libs.swaggerAnnotations\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation libs.junitJupiter\n    testImplementation libs.bndlib\n    testImplementation libs.mockitoCore\n    testImplementation project(':clients').sourceSets.test.output\n    testImplementation project(':connect:runtime').sourceSets.test.output\n    testImplementation project(':core')\n    testImplementation project(':test-common')\n    testImplementation project(':server')\n    testImplementation project(':server-common').sourceSets.test.output\n\n\n    testRuntimeOnly project(':connect:runtime')\n    testRuntimeOnly libs.bcpkix\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  javadoc {\n    enabled = false\n  }\n\n  tasks.create(name: \"copyDependantLibs\", type: Copy) {\n    from (configurations.runtimeClasspath) {\n      exclude('kafka-clients*')\n      exclude('connect-*')\n    }\n    into \"${layout.buildDirectory.get().asFile.path}/dependant-libs\"\n    duplicatesStrategy 'exclude'\n  }\n\n  task genMirrorConnectorConfigDocs(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.connect.mirror.MirrorConnectorConfig'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"mirror_connector_config.html\").newOutputStream()\n  }\n\n  task genMirrorSourceConfigDocs(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.connect.mirror.MirrorSourceConfig'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"mirror_source_config.html\").newOutputStream()\n  }\n\n  task genMirrorCheckpointConfigDocs(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.connect.mirror.MirrorCheckpointConfig'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"mirror_checkpoint_config.html\").newOutputStream()\n  }\n\n  task genMirrorHeartbeatConfigDocs(type: JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'org.apache.kafka.connect.mirror.MirrorHeartbeatConfig'\n    if( !generatedDocsDir.exists() ) { generatedDocsDir.mkdirs() }\n    standardOutput = new File(generatedDocsDir, \"mirror_heartbeat_config.html\").newOutputStream()\n  }\n\n  jar {\n    dependsOn copyDependantLibs\n  }\n}\n\nproject(':connect:mirror-client') {\n  base {\n    archivesName = \"connect-mirror-client\"\n  }\n\n  dependencies {\n    implementation project(':clients')\n    implementation log4jLibs\n\n    runtimeOnly log4jRuntimeLibs\n\n    testImplementation libs.junitJupiter\n    testImplementation project(':clients').sourceSets.test.output\n\n    testRuntimeOnly runtimeTestLibs\n  }\n\n  javadoc {\n    enabled = true\n  }\n\n  tasks.create(name: \"copyDependantLibs\", type: Copy) {\n    from (configurations.runtimeClasspath) {\n      exclude('kafka-clients*')\n      exclude('connect-*')\n    }\n    into \"${layout.buildDirectory.get().asFile.path}/dependant-libs\"\n    duplicatesStrategy 'exclude'\n  }\n\n  jar {\n    dependsOn copyDependantLibs\n  }\n}\n\nproject(':connect:test-plugins') {\n  base {\n    archivesName = \"connect-test-plugins\"\n  }\n\n  dependencies {\n    api project(':connect:api')\n\n    implementation project(':server-common')\n    implementation log4jLibs\n    implementation libs.jacksonDatabind\n\n    runtimeOnly log4jRuntimeLibs\n  }\n}\n\ntask aggregatedJavadoc(type: Javadoc, dependsOn: compileJava) {\n  def projectsWithJavadoc = subprojects.findAll { it.javadoc.enabled }\n  source = projectsWithJavadoc.collect { it.sourceSets.main.allJava }\n  classpath = files(projectsWithJavadoc.collect { it.sourceSets.main.compileClasspath })\n  includes = projectsWithJavadoc.collectMany { it.javadoc.getIncludes() }\n  excludes = projectsWithJavadoc.collectMany { it.javadoc.getExcludes() }\n}\n"
        },
        {
          "name": "checkstyle",
          "type": "tree",
          "content": null
        },
        {
          "name": "clients",
          "type": "tree",
          "content": null
        },
        {
          "name": "committer-tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "config",
          "type": "tree",
          "content": null
        },
        {
          "name": "connect",
          "type": "tree",
          "content": null
        },
        {
          "name": "coordinator-common",
          "type": "tree",
          "content": null
        },
        {
          "name": "core",
          "type": "tree",
          "content": null
        },
        {
          "name": "doap_Kafka.rdf",
          "type": "blob",
          "size": 3.01,
          "content": "<?xml version=\"1.0\"?>\n<?xml-stylesheet type=\"text/xsl\"?>\n<rdf:RDF xml:lang=\"en\"\n         xmlns=\"http://usefulinc.com/ns/doap#\"\n         xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n         xmlns:asfext=\"http://projects.apache.org/ns/asfext#\"\n         xmlns:foaf=\"http://xmlns.com/foaf/0.1/\">\n<!--\n    Licensed to the Apache Software Foundation (ASF) under one or more\n    contributor license agreements.  See the NOTICE file distributed with\n    this work for additional information regarding copyright ownership.\n    The ASF licenses this file to You under the Apache License, Version 2.0\n    (the \"License\"); you may not use this file except in compliance with\n    the License.  You may obtain a copy of the License at\n\n         http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n-->\n  <Project rdf:about=\"https://kafka.apache.org/\">\n    <created>2014-04-12</created>\n    <license rdf:resource=\"http://usefulinc.com/doap/licenses/asl20\" />\n    <name>Apache Kafka</name>\n    <homepage rdf:resource=\"https://kafka.apache.org/\" />\n    <asfext:pmc rdf:resource=\"https://kafka.apache.org\" />\n    <shortdesc>Apache Kafka is a distributed, fault tolerant, publish-subscribe messaging.</shortdesc>\n    <description>A single Kafka broker can handle hundreds of megabytes of reads and writes per second from thousands of clients. Kafka is designed to allow a single cluster to serve as the central data backbone for a large organization. It can be elastically and transparently expanded without downtime. Data streams are partitioned and spread over a cluster of machines to allow data streams larger than the capability of any single machine and to allow clusters of co-ordinated consumers. Kafka has a modern cluster-centric design that offers strong durability and fault-tolerance guarantees. Messages are persisted on disk and replicated within the cluster to prevent data loss. Each broker can handle terabytes of messages without performance impact.</description>\n    <bug-database rdf:resource=\"https://issues.apache.org/jira/browse/KAFKA\" />\n    <mailing-list rdf:resource=\"https://kafka.apache.org/contact.html\" />\n    <download-page rdf:resource=\"https://kafka.apache.org/downloads.html\" />\n    <programming-language>Scala</programming-language>\n    <category rdf:resource=\"http://projects.apache.org/category/big-data\" />\n    <repository>\n      <SVNRepository>\n        <location rdf:resource=\"https://gitbox.apache.org/repos/asf/kafka.git\"/>\n        <browse rdf:resource=\"https://github.com/apache/kafka\"/>\n      </SVNRepository>\n    </repository>\n    <maintainer>\n      <foaf:Person>\n        <foaf:name>Jun Rao</foaf:name>\n          <foaf:mbox rdf:resource=\"mailto:junrao@apache.org\"/>\n      </foaf:Person>\n    </maintainer>\n  </Project>\n</rdf:RDF>\n"
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "generator",
          "type": "tree",
          "content": null
        },
        {
          "name": "gradle.properties",
          "type": "blob",
          "size": 1.41,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\ngroup=org.apache.kafka\n# NOTE: When you change this version number, you should also make sure to update\n# the version numbers in\n#  - docs/js/templateData.js\n#  - tests/kafkatest/__init__.py\n#  - tests/kafkatest/version.py (variable DEV_VERSION)\n#  - kafka-merge-pr.py\n#  - streams/quickstart/pom.xml\n#  - streams/quickstart/java/src/main/resources/archetype-resources/pom.xml\n#  - streams/quickstart/java/pom.xml\nversion=4.1.0-SNAPSHOT\nscalaVersion=2.13.15\n# Adding swaggerVersion in gradle.properties to have a single version in place for swagger\nswaggerVersion=2.2.25\ntask=build\norg.gradle.jvmargs=-Xmx4g -Xss4m -XX:+UseParallelGC\norg.gradle.parallel=true\n"
        },
        {
          "name": "gradle",
          "type": "tree",
          "content": null
        },
        {
          "name": "gradlew",
          "type": "blob",
          "size": 8.96,
          "content": "#!/bin/sh\n\n#\n# Copyright © 2015-2021 the original authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n##############################################################################\n#\n#   Gradle start up script for POSIX generated by Gradle.\n#\n#   Important for running:\n#\n#   (1) You need a POSIX-compliant shell to run this script. If your /bin/sh is\n#       noncompliant, but you have some other compliant shell such as ksh or\n#       bash, then to run this script, type that shell name before the whole\n#       command line, like:\n#\n#           ksh Gradle\n#\n#       Busybox and similar reduced shells will NOT work, because this script\n#       requires all of these POSIX shell features:\n#         * functions;\n#         * expansions «$var», «${var}», «${var:-default}», «${var+SET}»,\n#           «${var#prefix}», «${var%suffix}», and «$( cmd )»;\n#         * compound commands having a testable exit status, especially «case»;\n#         * various built-in commands including «command», «set», and «ulimit».\n#\n#   Important for patching:\n#\n#   (2) This script targets any POSIX shell, so it avoids extensions provided\n#       by Bash, Ksh, etc; in particular arrays are avoided.\n#\n#       The \"traditional\" practice of packing multiple parameters into a\n#       space-separated string is a well documented source of bugs and security\n#       problems, so this is (mostly) avoided, by progressively accumulating\n#       options in \"$@\", and eventually passing that to Java.\n#\n#       Where the inherited environment variables (DEFAULT_JVM_OPTS, JAVA_OPTS,\n#       and GRADLE_OPTS) rely on word-splitting, this is performed explicitly;\n#       see the in-line comments for details.\n#\n#       There are tweaks for specific operating systems such as AIX, CygWin,\n#       Darwin, MinGW, and NonStop.\n#\n#   (3) This script is generated from the Groovy template\n#       https://github.com/gradle/gradle/blob/HEAD/subprojects/plugins/src/main/resources/org/gradle/api/internal/plugins/unixStartScript.txt\n#       within the Gradle project.\n#\n#       You can find Gradle at https://github.com/gradle/gradle/.\n#\n##############################################################################\n\n# Attempt to set APP_HOME\n\n# Resolve links: $0 may be a link\napp_path=$0\n\n# Need this for daisy-chained symlinks.\nwhile\n    APP_HOME=${app_path%\"${app_path##*/}\"}  # leaves a trailing /; empty if no leading path\n    [ -h \"$app_path\" ]\ndo\n    ls=$( ls -ld \"$app_path\" )\n    link=${ls#*' -> '}\n    case $link in             #(\n      /*)   app_path=$link ;; #(\n      *)    app_path=$APP_HOME$link ;;\n    esac\ndone\n\n# This is normally unused\n# shellcheck disable=SC2034\nAPP_BASE_NAME=${0##*/}\n# Discard cd standard output in case $CDPATH is set (https://github.com/gradle/gradle/issues/25036)\nAPP_HOME=$( cd \"${APP_HOME:-./}\" > /dev/null && pwd -P ) || exit\n\n# Use the maximum available, or set MAX_FD != -1 to use that value.\nMAX_FD=maximum\n\nwarn () {\n    echo \"$*\"\n} >&2\n\ndie () {\n    echo\n    echo \"$*\"\n    echo\n    exit 1\n} >&2\n\n# OS specific support (must be 'true' or 'false').\ncygwin=false\nmsys=false\ndarwin=false\nnonstop=false\ncase \"$( uname )\" in                #(\n  CYGWIN* )         cygwin=true  ;; #(\n  Darwin* )         darwin=true  ;; #(\n  MSYS* | MINGW* )  msys=true    ;; #(\n  NONSTOP* )        nonstop=true ;;\nesac\n\n\n# Loop in case we encounter an error.\nfor attempt in 1 2 3; do\n  if [ ! -e \"$APP_HOME/gradle/wrapper/gradle-wrapper.jar\" ]; then\n    if ! curl -s -S --retry 3 -L -o \"$APP_HOME/gradle/wrapper/gradle-wrapper.jar\" \"https://raw.githubusercontent.com/gradle/gradle/v8.10.2/gradle/wrapper/gradle-wrapper.jar\"; then\n      rm -f \"$APP_HOME/gradle/wrapper/gradle-wrapper.jar\"\n      # Pause for a bit before looping in case the server throttled us.\n      sleep 5\n      continue\n    fi\n  fi\ndone\n\nCLASSPATH=$APP_HOME/gradle/wrapper/gradle-wrapper.jar\n\n\n# Determine the Java command to use to start the JVM.\nif [ -n \"$JAVA_HOME\" ] ; then\n    if [ -x \"$JAVA_HOME/jre/sh/java\" ] ; then\n        # IBM's JDK on AIX uses strange locations for the executables\n        JAVACMD=$JAVA_HOME/jre/sh/java\n    else\n        JAVACMD=$JAVA_HOME/bin/java\n    fi\n    if [ ! -x \"$JAVACMD\" ] ; then\n        die \"ERROR: JAVA_HOME is set to an invalid directory: $JAVA_HOME\n\nPlease set the JAVA_HOME variable in your environment to match the\nlocation of your Java installation.\"\n    fi\nelse\n    JAVACMD=java\n    if ! command -v java >/dev/null 2>&1\n    then\n        die \"ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH.\n\nPlease set the JAVA_HOME variable in your environment to match the\nlocation of your Java installation.\"\n    fi\nfi\n\n# Increase the maximum file descriptors if we can.\nif ! \"$cygwin\" && ! \"$darwin\" && ! \"$nonstop\" ; then\n    case $MAX_FD in #(\n      max*)\n        # In POSIX sh, ulimit -H is undefined. That's why the result is checked to see if it worked.\n        # shellcheck disable=SC2039,SC3045\n        MAX_FD=$( ulimit -H -n ) ||\n            warn \"Could not query maximum file descriptor limit\"\n    esac\n    case $MAX_FD in  #(\n      '' | soft) :;; #(\n      *)\n        # In POSIX sh, ulimit -n is undefined. That's why the result is checked to see if it worked.\n        # shellcheck disable=SC2039,SC3045\n        ulimit -n \"$MAX_FD\" ||\n            warn \"Could not set maximum file descriptor limit to $MAX_FD\"\n    esac\nfi\n\n# Collect all arguments for the java command, stacking in reverse order:\n#   * args from the command line\n#   * the main class name\n#   * -classpath\n#   * -D...appname settings\n#   * --module-path (only if needed)\n#   * DEFAULT_JVM_OPTS, JAVA_OPTS, and GRADLE_OPTS environment variables.\n\n# For Cygwin or MSYS, switch paths to Windows format before running java\nif \"$cygwin\" || \"$msys\" ; then\n    APP_HOME=$( cygpath --path --mixed \"$APP_HOME\" )\n    CLASSPATH=$( cygpath --path --mixed \"$CLASSPATH\" )\n\n    JAVACMD=$( cygpath --unix \"$JAVACMD\" )\n\n    # Now convert the arguments - kludge to limit ourselves to /bin/sh\n    for arg do\n        if\n            case $arg in                                #(\n              -*)   false ;;                            # don't mess with options #(\n              /?*)  t=${arg#/} t=/${t%%/*}              # looks like a POSIX filepath\n                    [ -e \"$t\" ] ;;                      #(\n              *)    false ;;\n            esac\n        then\n            arg=$( cygpath --path --ignore --mixed \"$arg\" )\n        fi\n        # Roll the args list around exactly as many times as the number of\n        # args, so each arg winds up back in the position where it started, but\n        # possibly modified.\n        #\n        # NB: a `for` loop captures its iteration list before it begins, so\n        # changing the positional parameters here affects neither the number of\n        # iterations, nor the values presented in `arg`.\n        shift                   # remove old arg\n        set -- \"$@\" \"$arg\"      # push replacement arg\n    done\nfi\n\n\n# Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.\nDEFAULT_JVM_OPTS='\"-Xmx64m\" \"-Xms64m\"'\n\n# Collect all arguments for the java command:\n#   * DEFAULT_JVM_OPTS, JAVA_OPTS, JAVA_OPTS, and optsEnvironmentVar are not allowed to contain shell fragments,\n#     and any embedded shellness will be escaped.\n#   * For example: A user cannot expect ${Hostname} to be expanded, as it is an environment variable and will be\n#     treated as '${Hostname}' itself on the command line.\n\nset -- \\\n        \"-Dorg.gradle.appname=$APP_BASE_NAME\" \\\n        -classpath \"$CLASSPATH\" \\\n        org.gradle.wrapper.GradleWrapperMain \\\n        \"$@\"\n\n# Stop when \"xargs\" is not available.\nif ! command -v xargs >/dev/null 2>&1\nthen\n    die \"xargs is not available\"\nfi\n\n# Use \"xargs\" to parse quoted args.\n#\n# With -n1 it outputs one arg per line, with the quotes and backslashes removed.\n#\n# In Bash we could simply go:\n#\n#   readarray ARGS < <( xargs -n1 <<<\"$var\" ) &&\n#   set -- \"${ARGS[@]}\" \"$@\"\n#\n# but POSIX shell has neither arrays nor command substitution, so instead we\n# post-process each arg (as a line of input to sed) to backslash-escape any\n# character that might be a shell metacharacter, then use eval to reverse\n# that process (while maintaining the separation between arguments), and wrap\n# the whole thing up as a single \"set\" statement.\n#\n# This will of course break if any of these variables contains a newline or\n# an unmatched quote.\n#\n\neval \"set -- $(\n        printf '%s\\n' \"$DEFAULT_JVM_OPTS $JAVA_OPTS $GRADLE_OPTS\" |\n        xargs -n1 |\n        sed ' s~[^-[:alnum:]+,./:=@_]~\\\\&~g; ' |\n        tr '\\n' ' '\n    )\" '\"$@\"'\n\nexec \"$JAVACMD\" \"$@\"\n"
        },
        {
          "name": "gradlewAll",
          "type": "blob",
          "size": 1.24,
          "content": "#!/usr/bin/env sh\n\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Convenient way to invoke a gradle command with all Scala versions supported\n# by default\n# This script was originally designed to support multiple Scala versions (2.12 and 2.13),\n# but as Scala 2.12 is no longer supported, this script is no longer necessary.\n# We are keeping it for backwards compatibility. It will be removed in a future release.\necho \"Warning: This script is deprecated and will be removed in a future release.\"\n./gradlew \"$@\" -PscalaVersion=2.13\n\n"
        },
        {
          "name": "group-coordinator",
          "type": "tree",
          "content": null
        },
        {
          "name": "jmh-benchmarks",
          "type": "tree",
          "content": null
        },
        {
          "name": "licenses",
          "type": "tree",
          "content": null
        },
        {
          "name": "metadata",
          "type": "tree",
          "content": null
        },
        {
          "name": "raft",
          "type": "tree",
          "content": null
        },
        {
          "name": "release",
          "type": "tree",
          "content": null
        },
        {
          "name": "server-common",
          "type": "tree",
          "content": null
        },
        {
          "name": "server",
          "type": "tree",
          "content": null
        },
        {
          "name": "settings.gradle",
          "type": "blob",
          "size": 3.66,
          "content": "// Licensed to the Apache Software Foundation (ASF) under one or more\n// contributor license agreements.  See the NOTICE file distributed with\n// this work for additional information regarding copyright ownership.\n// The ASF licenses this file to You under the Apache License, Version 2.0\n// (the \"License\"); you may not use this file except in compliance with\n// the License.  You may obtain a copy of the License at\n//\n//    http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\nplugins {\n    id 'com.gradle.develocity' version '3.17.6'\n    id 'com.gradle.common-custom-user-data-gradle-plugin' version '2.0.2'\n}\n\ndef isGithubActions = System.getenv('GITHUB_ACTIONS') != null\ndef currentJvm = JavaVersion.current()\n\ndevelocity {\n    server = \"https://ge.apache.org\"\n    projectId = \"kafka\"\n    buildScan {\n        uploadInBackground = !isGithubActions\n        publishing.onlyIf { it.authenticated }\n        obfuscation {\n            // This obfuscates the IP addresses of the build machine in the build scan.\n            // Alternatively, the build scan will provide the hostname for troubleshooting host-specific issues.\n            ipAddresses { addresses -> addresses.collect { address -> \"0.0.0.0\"} }\n        }\n        if (isGithubActions) {\n            tag \"github\"\n        } else {\n            tag \"local\"\n        }\n        tag \"JDK$currentJvm\"\n    }\n}\n\nbuildCache {\n    local {\n        // This allows the build cache to be used locally or on GitHub Actions.\n        // Using the cache on GH should be safe since each job is run on a new VM\n        enabled = true\n    }\n\n    remote(develocity.buildCache) {\n        enabled = false\n    }\n}\n\ninclude 'clients',\n    'connect:api',\n    'connect:basic-auth-extension',\n    'connect:file',\n    'connect:json',\n    'connect:mirror',\n    'connect:mirror-client',\n    'connect:runtime',\n    'connect:test-plugins',\n    'connect:transforms',\n    'coordinator-common',\n    'core',\n    'examples',\n    'generator',\n    'group-coordinator',\n    'group-coordinator:group-coordinator-api',\n    'jmh-benchmarks',\n    'metadata',\n    'raft',\n    'server',\n    'server-common',\n    'share',\n    'share-coordinator',\n    'shell',\n    'storage',\n    'storage:api',\n    'streams',\n    'streams:examples',\n    'streams:integration-tests',\n    'streams:streams-scala',\n    'streams:test-utils',\n    'streams:upgrade-system-tests-0110',\n    'streams:upgrade-system-tests-10',\n    'streams:upgrade-system-tests-11',\n    'streams:upgrade-system-tests-20',\n    'streams:upgrade-system-tests-21',\n    'streams:upgrade-system-tests-22',\n    'streams:upgrade-system-tests-23',\n    'streams:upgrade-system-tests-24',\n    'streams:upgrade-system-tests-25',\n    'streams:upgrade-system-tests-26',\n    'streams:upgrade-system-tests-27',\n    'streams:upgrade-system-tests-28',\n    'streams:upgrade-system-tests-30',\n    'streams:upgrade-system-tests-31',\n    'streams:upgrade-system-tests-32',\n    'streams:upgrade-system-tests-33',\n    'streams:upgrade-system-tests-34',\n    'streams:upgrade-system-tests-35',\n    'streams:upgrade-system-tests-36',\n    'streams:upgrade-system-tests-37',\n    'streams:upgrade-system-tests-38',\n    'streams:upgrade-system-tests-39',\n    'tools',\n    'tools:tools-api',\n    'transaction-coordinator',\n    'trogdor',\n    'test-common',\n    'test-common:test-common-api',\n    'test-common:test-common-runtime'\n\nproject(\":storage:api\").name = \"storage-api\"\nrootProject.name = 'kafka'\n\n"
        },
        {
          "name": "share-coordinator",
          "type": "tree",
          "content": null
        },
        {
          "name": "share",
          "type": "tree",
          "content": null
        },
        {
          "name": "shell",
          "type": "tree",
          "content": null
        },
        {
          "name": "storage",
          "type": "tree",
          "content": null
        },
        {
          "name": "streams",
          "type": "tree",
          "content": null
        },
        {
          "name": "test-common",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "transaction-coordinator",
          "type": "tree",
          "content": null
        },
        {
          "name": "trogdor",
          "type": "tree",
          "content": null
        },
        {
          "name": "vagrant",
          "type": "tree",
          "content": null
        },
        {
          "name": "wrapper.gradle",
          "type": "blob",
          "size": 3.71,
          "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\n// This file contains tasks for the gradle wrapper generation.\n\n// Ensure the wrapper script is generated based on the version defined in the project\n// and not the version installed on the machine running the task.\n// Read more about the wrapper here: https://docs.gradle.org/current/userguide/gradle_wrapper.html\nwrapper {\n    gradleVersion = project.gradleVersion\n    distributionType = Wrapper.DistributionType.ALL\n}\n\n// Custom task to inject support for downloading the gradle wrapper jar if it doesn't exist.\n// This allows us to avoid checking in the jar to our repository.\n// Additionally adds a license header to the wrapper while editing the file contents.\ntask bootstrapWrapper() {\n    // In the doLast block so this runs when the task is called and not during project configuration.\n    doLast {\n        def wrapperBasePath = \"\\$APP_HOME/gradle/wrapper\"\n        def wrapperJarPath = wrapperBasePath + \"/gradle-wrapper.jar\"\n\n        // Add a trailing zero to the version if needed.\n        def fullVersion = project.gradleVersion.count(\".\") == 1 ? \"${project.gradleVersion}.0\" : versions.gradle\n        // Leverages the wrapper jar checked into the gradle project on github because the jar isn't\n        // available elsewhere. Using raw.githubusercontent.com instead of github.com because\n        // github.com servers deprecated TLSv1/TLSv1.1 support some time ago, so older versions\n        // of curl (built against OpenSSL library that doesn't support TLSv1.2) would fail to\n        // fetch the jar.\n        def wrapperBaseUrl = \"https://raw.githubusercontent.com/gradle/gradle/v$fullVersion/gradle/wrapper\"\n        def wrapperJarUrl = wrapperBaseUrl + \"/gradle-wrapper.jar\"\n\n        def bootstrapString = \"\"\"\n      # Loop in case we encounter an error.\n      for attempt in 1 2 3; do\n        if [ ! -e \"$wrapperJarPath\" ]; then\n          if ! curl -s -S --retry 3 -L -o \"$wrapperJarPath\" \"$wrapperJarUrl\"; then\n            rm -f \"$wrapperJarPath\"\n            # Pause for a bit before looping in case the server throttled us.\n            sleep 5\n            continue\n          fi\n        fi\n      done\n      \"\"\".stripIndent()\n\n        def wrapperScript = wrapper.scriptFile\n        def wrapperLines = wrapperScript.readLines()\n        wrapperScript.withPrintWriter { out ->\n            def bootstrapWritten = false\n            wrapperLines.each { line ->\n                // Print the wrapper bootstrap before the first usage of the wrapper jar.\n                if (!bootstrapWritten && line.contains(\"gradle-wrapper.jar\")) {\n                    out.println(bootstrapString)\n                    bootstrapWritten = true\n                }\n                out.print(line)\n                out.println()\n            }\n        }\n    }\n}\nwrapper.finalizedBy bootstrapWrapper\n\n// Remove the generated batch file since we don't test building in the Windows environment.\ntask removeWindowsScript(type: Delete) {\n    delete \"$rootDir/gradlew.bat\"\n}\nwrapper.finalizedBy removeWindowsScript\n"
        }
      ]
    }
  ]
}